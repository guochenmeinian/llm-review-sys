# Regression under demographic parity constraints via unlabeled post-processing

 Gayane Taturyan

IRT SystemX, Universite Gustave Eiffel,

Universite Paul-Sabatier

gayane.taturyan@univ-eiffel.fr

Evgenii Chzhen

CNRS, Universite Paris-Saclay

evgenii.chzhen@cnrs.fr

Mohamed Hebiri

Universite Gustave Eiffel

mohamed.hebiri@univ-eiffel.fr

###### Abstract

We address the problem of performing regression while ensuring demographic parity, even without access to sensitive attributes during inference. We present a general-purpose post-processing algorithm that, using accurate estimates of the regression function and a sensitive attribute predictor, generates predictions that meet the demographic parity constraint. Our method involves discretization and stochastic minimization of a smooth convex function. It is suitable for online post-processing and multi-class classification tasks only involving unlabeled data for the post-processing. Unlike prior methods, our approach is fully theory-driven. We require precise control over the gradient norm of the convex function, and thus, we rely on more advanced techniques than standard stochastic gradient descent. Our algorithm is backed by finite-sample analysis and post-processing bounds, with experimental results validating our theoretical findings.

## 1 Introduction

Algorithmic fairness is an umbrella term for a subset of machine learning research that aims to better understand, quantify, mitigate, evaluate, and conceptualize negative and/or positive effects of data-driven algorithms on the society. At least one direction in this field falls within theoretical machine learning, where a form of fairness constraint, mainly inspired by common sense and formalized within mathematical framework, is proposed as an arguably reasonable proxy for a definition of ethical and non-discriminatory prediction. Even more particular sub-field of this research direction is formalized within a paradigm of group fairness, that aims at mitigating negative impact (or provide equal treatment to) towards sub-populations that share a common sensitive characteristic. Many works fall within this category (Barocas et al., 2018; Calders et al., 2009; Chiappa et al., 2020; Dwork et al., 2011; Feldman et al., 2015; Gordaliza et al., 2019; Hardt et al., 2016; Jiang et al., 2020; Lum and Johndrow, 2016; Zafar et al., 2017; Zemel et al., 2013, just to name a few).

Even without going into debates on the relevance of a given definition of fairness, many, purely mathematical and algorithmic questions remain unanswered in this field. The best theoretical understanding of the problem is available for the demographic parity constraint in case of _awareness_--the situation when the sensitive attribute is available at inference time (Agarwal et al., 2019; Chiappa et al., 2020; Chzhen and Schreuder, 2020; Chzhen et al., 2019; Denis et al., 2024; Gaucher et al., 2023; Le Gouic et al., 2020). The latter case is well studies both in classification and regression setups. This is no longer the case for other fairness constraints or the _unawareness_ setup--the situation when the sensitive attribute is not available at inference time. In particular, while the case ofclassification has been studied before from algorithmic and mathematical perspectives (Chzhen et al., 2019; Gaucher et al., 2023; Gordaliza et al., 2019; Hardt et al., 2016), the regression setup remains largely under explored and many methods lack strong theoretical evidences. In particular, to date, none of previous works effectively build computationally-efficient, fully theory-driven algorithm for the problem of regression under the demographic parity constraint in the case of unawareness. The present work fills this gap. Relying on previous ideas of discretization that goes back to Agarwal et al. (2019), we design a smooth convex objective function whose exact solution yields a fair and optimal prediction function. It turns out that this objective admits a first-order stochastic oracle that can be evaluated using only one independent sample of feature vector, thus allowing for stochastic optimization approach. Furthermore, despite the convexity, we show that the key quantity to control is the gradient (or rather a gradient-map) of this objective function, deviating from the more common setup of controlling the optimization error measured by the objective function. We deploy recent machinery of Allen-Zhu (2021) and Foster et al. (2019) that allows to achieve this goal, properly setting all the hyper-parameters and recovering the usual statistical rate \(1/\sqrt{T}\) for both fairness and risk guarantees -- \(T\) being the number of samples.

Our work falls withing the realm of post-processing methods--another umbrella term that combines all the methods that perform a refitting of a base estimator to satisfy a certain constraint.

Importantly, due to the careful design of the above mentioned objective function, we can perform this post-processing in an online manner using a stream of i.i.d. _unlabeled_ data without keeping it in memory, making it attractive in practice. Our approach is based on a combination of ideas from previous contributions to fairness from Agarwal et al. (2019) and Chzhen et al. (2020) and recent stochastic optimization literature (Allen-Zhu, 2021; Foster et al., 2019) that deals with stationary point-type guarantees in the case of convex optimization.

ContributionsOur contribution is three-fold: **i)** we significantly enhance the discretization strategy of Chzhen et al. (2020) accommodating multiple sensitive features, relaxed fairness constraints, and unawareness setup; we introduce entropic regularization for this problem and design a dual convex objective from it; **ii)** we design a semi-supervised post-processing algorithm and show that it enjoys strong theoretical guarantees; **iii)** we perform numerical simulations demonstrating the relevance of our approach in practice.

Organization.This paper is organized as follows: in Section 2 we present the problem setup and introduce main problem-related notation; in Section 3 we describe our methodology step-by-step and highlight main challenges and relations to other results; in Section 4 we gives technical details of the proposed approach; Section 5 contains main theoretical results of the work; finally, Section 6 contains empirical evaluation of our method. All the proofs are postponed to the appendix.

Notation.Let us present generic notation that is used throughout this work. For a positive integer \(K\), we write \([K]\) to denote \(\{1,\ldots,K\}\) and \(\llbracket K\rrbracket\) to denote \(\{-K,\ldots,0,\ldots,K\}\). For \(a>0\) denote by \(\lfloor a\rfloor\) largest non-negative integer that is smaller or equal to \(a\). For a univariate probability measure \(\mu\), we denote by \(\operatorname{supp}(\mu)\) its support. For every \(\beta>0,m\in\mathbb{N}\), and \(\bm{w}=(w_{1},\ldots,w_{m})^{\top}\in\mathbb{R}^{m}\), we denote by \(\operatorname{LSE}_{\beta}:\mathbb{R}^{m}\to\mathbb{R}\) the log-sum-exp function, defined as

\[\operatorname{LSE}_{\beta}(\bm{w})=\beta^{-1}\log\big{(}\sum_{j=1}^{m} \exp(\beta w_{j})\big{)}\,.\]

For every \(m\in\mathbb{N}\), \(\bm{w}=(w_{1},\ldots,w_{m})^{\top}\in\mathbb{R}^{m}\), we denote by \(\bm{\sigma}=(\sigma_{1},\ldots,\sigma_{m}):\mathbb{R}^{m}\to\mathbb{R}^{m}\) the soft-argmax as \(\sigma_{j}(\bm{w})=\exp(w_{j})/(\sum_{i=1}^{m}\exp(w_{i}))\). For any matrix \(\mathbf{A}\), the notation \(\mathbf{A}\geq 0\) means that \(\mathbf{A}\) is positive coordinate-wise. For any \(a\in\mathbb{R}\) and \(\bm{w}\in\mathbb{R}^{m}\) we set \((a)_{+}=\max\{0,a\}\) and \((\bm{w})_{+}=((w_{1})_{+},\ldots,(w_{m})_{+})^{\top}\). The notation \(\widetilde{\mathcal{O}}\) hides (unimportant) constants and polylogarithmic factors. For a pair of random elements \((A,B)\), we denote by \(\operatorname{Law}(A)\), the law of \(A\), by \(\operatorname{Law}(A\mid B)\), the conditional law of \(A\) given \(B\), and we write \(A\perp B\) to denote that variables \(A\) and \(B\) are independent. For two vectors \(\bm{w},\bm{w}^{\prime}\in\mathbb{R}^{m}\), we write \(\bm{w}/\bm{w}^{\prime}=(w_{j}/w^{\prime}_{j})_{j\in[m]}\in\mathbb{R}^{m}\) to denote element-wise division. The Euclidean norm of a vector and the Frobenius norm of a matrix are denoted by \(\|\cdot\|\), while the spectral norm of a matrix is denoted by \(\|\cdot\|_{\mathrm{op}}\). We denote by \(\mathcal{B}(\mathbb{R})\), the Borel sigma-algebra on \(\mathbb{R}\), induced by the usual topology. We write \(\log\) to denote the natural logarithm and \(\log_{a}\), the base \(a>0\) logarithm.

## 2 Problem setup

Let \((\bm{X},S,Y)\) be a triplet of nominally non-sensitive, nominally sensitive, and output characteristics, taking values in \(\mathbb{R}^{d}\times[K]\times\mathbb{R}\) for some \(K\geqslant 2\). We assume that \((\bm{X},S,Y)\sim\mathbb{P}\), for some unknown distribution \(\mathbb{P}\). The main quantities of interest are the following: the _regression function_\(\eta(\bm{x})\stackrel{{\text{def}}}{{=}}\mathbb{E}[Y\mid\bm{X}= \bm{x}]\); the marginal distribution of sensitive vectors \(\bm{p}\stackrel{{\text{def}}}{{=}}(p_{s})_{s\in[K]}\) with \(p_{s}\stackrel{{\text{def}}}{{=}}\mathbb{P}(S=s)\); the conditional distribution of \(S\) given \(\bm{X}\), defined as \(\bm{\tau}(\bm{x})\stackrel{{\text{def}}}{{=}}(\tau_{s}(\bm{x}))_ {s\in[K]}\) with \(\tau_{s}(\bm{x})\stackrel{{\text{def}}}{{=}}\mathbb{P}(S=s\mid \bm{X}=\bm{x})\). A _randomized_ prediction function is a map \(\pi:\mathcal{B}(\mathbb{R})\times\mathbb{R}^{d}\to[0,1]\) such that the map \(B\mapsto\pi(B\mid\bm{x})\) for \(B\in\mathcal{B}(\mathbb{R})\) is a probability measure on \((\mathbb{R},\mathcal{B}(\mathbb{R}))\) for all \(\bm{x}\in\mathbb{R}^{d}\). For any prediction \(\pi\) we define a random variable \(\widehat{Y}_{\pi}\) as

\[\operatorname{Law}\left(\widehat{Y}_{\pi}\mid\bm{X}=\bm{x},S=s\right)=\pi( \cdot\mid\bm{x})\quad\bm{x}\in\mathbb{R}^{d},s\in[K]\,.\]

**Remark 2.1**.: _Note that if \(\pi(\cdot\mid\bm{x})\) is a Dirac measure for all \(\bm{x}\in\mathbb{R}^{d}\), the above condition just means that \(\widehat{Y}_{\pi}=g(\bm{X})\) almost surely for some deterministic \(g:\mathbb{R}^{d}\to\mathbb{R}\). The above condition is not to be confused with the fairness constraint, which is not formulated point-wise. It is only viewed as an extension of the unawareness framework to the case of randomized predictions. The above condition completely specifies the distribution of the triplet \((\bm{X},S,\widehat{Y}_{\pi})\) but leaves the relation between \(\widehat{Y}_{\pi}\) and \(Y\) ambiguous. To be more formal, one needs to add the condition \((\widehat{Y}_{\pi}\perp\bm{Y})\mid(\bm{X},S)\), that is, the prediction \(\widehat{Y}_{\pi}\) is independent from the true label \(Y\), conditionally on \((\bm{X},S)\). That would define a complete joint distribution of \((\bm{X},S,Y,\widehat{Y}_{\pi})\sim\mathbb{P}_{\pi}=\mathbb{P}_{(\bm{X},S)} \otimes\mathbb{P}_{Y|(\bm{X},S)}\otimes\pi(\cdot\mid\bm{X})\)._

We consider the following risk of a prediction function \(\pi\)

\[\mathcal{R}(\pi)\stackrel{{\text{def}}}{{=}}\mathbb{E}[(\widehat {Y}_{\pi}-\eta(\bm{X}))^{2}]=\mathbb{E}\left[\int_{\mathbb{R}}(\widehat{y}- \eta(\bm{X}))^{2}\pi(\mathrm{d}\,\widehat{y}\mid\bm{X})\right]\,.\]

A prediction function \(\pi\) is said to satisfy the _demographic parity constraint_, if \(\widehat{Y}_{\pi}\perp S\).

That is, \(\widehat{Y}_{\pi}\) is stochastically _independent_ of \(S\) viewed from the perspective of the joint distribution of \((\bm{X}\,,S,\widehat{Y}_{\pi})\). On the high-level, the goal in this setup is to find a prediction function \(\pi\), whose risk is small and whose violation of the demographic parity constraint is controlled as quantified by some measure of unfairness. The above problem is well understood in the case of _awareness_--the situation when \(\pi\) is expressed as \(\pi(\cdot\mid\bm{x},s)\)(Chiappa et al., 2020; Chzhen et al., 2020, 2021; Jiang et al., 2020; Le Gouic et al., 2020)--revealing an intimate connection of this problem with Wasserstein barycenters. Yet, when the sensitive attribute is not an input of the prediction function, the situation is drastically different. Some attempts have been made to either (so far only partially) characterise the optimal prediction function (Chzhen and Schreuder, 2020; Gaucher et al., 2023; Zhao, 2021) or to design efficient algorithms for this problem (Agarwal et al., 2019; Maheshwari and Perrot, 2022; Narasimhan et al., 2020) that are only partially supported by a sound theory. One of the principal goals of this work is to design a computationally efficient algorithm that admits a (near) end-to-end theoretical guarantees. The main difficulty of the problem lies in very different natures of the risk and the fairness constraint--the latter involves image measures, while the former is a simple linear functional of \(\pi\). In the case of awareness this issue can be bypassed by lifting the problem in the space of measures, working there directly and, then, returning to the initial space of prediction functions. Crucially, this is achieved only thanks to the fact that \(S\) is known at inference time, which is not the case for the considered problem.

**Remark 2.2**.: _In what follows we will exclusively focus on the squared risk and the regression setup. However, one can observe that the proposed methodology can be extended or even simplified for \(\mathcal{R}(\pi)=\mathbb{E}[r(\bm{X},\widehat{Y}_{\pi})]\) and multi-class classification respectively under the demographic parity constraint. Here \(r(\bm{x},\widehat{y})\) quantifies fit of \(\widehat{y}\) for an individual \(\bm{x}\) and can be either known or unknown._

## 3 Our methodology

The starting point of our work is similar to the one of Chzhen et al. (2020) and relies on a simple observation--if \(|\operatorname{supp}(\pi(\cdot\mid\bm{x}))|<\infty\) and stays the same for all \(\bm{x}\), the independence constraintis reduced to a finite amount of constraints that only involve the image of \(\pi(\cdot\mid\bm{x})\). In particular, assuming that \(\operatorname{supp}(\pi(\cdot\mid\bm{x}))=\widehat{\mathcal{Y}}\subset\mathbb{R}\) for all \(\bm{x}\in\mathbb{R}^{d}\), \(\widehat{Y}_{\pi}\) is independent from \(S\) iff \(\mathbb{P}(\widehat{Y}_{\pi}=\widehat{y}\mid S=s)=\mathbb{P}(\widehat{Y}_{\pi} =\widehat{y})\) for all \(s\in[K]\) and all \(\widehat{y}\in\widehat{\mathcal{Y}}\). In view of the definition of \(\widehat{Y}_{\pi}\), the latter is equivalent to

\[\mathbb{E}[\pi(\widehat{y}\mid\bm{X})\mid S]=\mathbb{E}[\pi(\widehat{y}\mid \bm{X})]\qquad s\in[K],\,\widehat{y}\in\widehat{\mathcal{Y}}\,,\] (1)

which, assuming that \(\widehat{\mathcal{Y}}\) is fixed, correspond to linear constraints on \(\pi\). Combined with the observation that \(\pi\mapsto\mathcal{R}(\pi)\) is also linear, we end up with a problem that is significantly easier to handle. Furthermore, again assuming that \(\widehat{\mathcal{Y}}\) is fixed, the sketched direction gives a natural way to introduce some slack to the independence constraint--simply requiring an approximate equality in (1). Set

\[\mathcal{U}_{s}(\pi,\widehat{y})\stackrel{{\mathrm{def}}}{{=}}| \mathbb{E}\left[\pi(\widehat{y}\mid\bm{X})\mid S=s\right]-\mathbb{E}\left[\pi (\widehat{y}\mid\bm{X})\right]|\,\] (2)

for all \(s\in[K]\) and \(\widehat{y}\in\widehat{\mathcal{Y}}\). Thus, for a fixed support (whose choice will be discussed in the next paragraph) and a fixed vector \(\bm{\varepsilon}\stackrel{{\mathrm{def}}}{{=}}(\varepsilon_{1}, \ldots,\varepsilon_{K})^{\top}\), our goal is to build an estimator of a solution to

\[\min_{\pi:\mathcal{R}(\bm{\delta})\times\mathbb{R}^{d}\to[0,1]}\left\{ \mathcal{R}(\pi)\,:\,\operatorname{supp}(\pi(\cdot\mid\bm{x}))=\widehat{ \mathcal{Y}}\text{ for }\bm{x}\in\mathbb{R}^{d},\quad\mathcal{U}_{s}(\pi, \widehat{y})\leqslant\varepsilon_{s}\text{ for }\widehat{y}\in\widehat{ \mathcal{Y}},s\in[K]\right\}\,.\] (3)

Let us now describe the methodology for selecting \(\widehat{\mathcal{Y}}\) and the trade-offs that are introduced.

Introducing discretization.Having in mind the above discussion, for every integer \(L\geqslant 0\) and real \(B>0\), we introduce a uniform grid \(\widehat{\mathcal{Y}}_{L}\stackrel{{\mathrm{def}}}{{=}}B\cdot \llbracket L\rrbracket/L\) on \([-B,B]\), so that \(|\widehat{\mathcal{Y}}_{L}|=2L+1\), which is viewed as a support of prediction functions \(\pi(\cdot\mid\bm{x})\). For the sake of simplicity, we will assume that the regression function \(\eta(\cdot)\) is bounded in \([-B,B]\) for some known \(B>0\).

**Assumption 3.1** (Bounded signal).: _There exists \(B>0\) such that \(|\eta(\bm{X})|\leqslant B\) almost surely._

Thus, for a given \(B\), the main parameter to tune is \(L\geqslant 1\)--the higher the \(L\) is, the more accurate prediction functions can be produced, while lower values of \(L\) ensure that the demographic parity requirement reduces to a small number of constraints. Thus, there is a trade-off that is introduced by \(L\). A natural attempt to tackle the problem of fairness in this context would be to estimate a solution to (3) with \(\widehat{\mathcal{Y}}=\widehat{\mathcal{Y}}_{L}\). Of course, \(L\) needs to be chosen so that the aforementioned solution attains the risk that is close to the risk of some benchmark prediction function that does not involve any discretization. This will be discussed later in the text. For now, let us address another subtle issue. Even assuming a complete knowledge of the underlying distribution \(\mathbb{P}\), solving (3) requires solving a linear program in dimension \(\Omega(LK)\) which can be infeasible in practice for large values of \(L\) and \(K\). Instead of (3), we rather focus on the entropic regularized version of it. For \(\beta>0\), we consider

\[\min_{\pi:\mathcal{R}(\bm{\delta})\times\mathbb{R}^{d}\to[0,1]}\left\{ \mathcal{R}_{\beta}(\pi)\,:\,\operatorname{supp}(\pi(\cdot\mid\bm{x}))= \widehat{\mathcal{Y}}\text{ for }\bm{x}\in\mathbb{R}^{d},\quad\mathcal{U}_{s}(\pi, \widehat{y})\leqslant\varepsilon_{s}\text{ for }\widehat{y}\in\widehat{ \mathcal{Y}},s\in[K]\right\}\,,\] (4)

where \(\mathcal{R}_{\beta}(\pi)=\mathcal{R}(\pi)+\frac{1}{\beta}\mathbb{E}[\Psi(\pi( \cdot\mid\bm{X}))]\) and for any discrete univariate distribution \(\mu\), we define its negative entropy \(\Psi(\mu)\stackrel{{\mathrm{def}}}{{=}}\sum_{\widehat{y} \in\operatorname{supp}(\mu)}\mu(\widehat{y})\log(\mu(\widehat{y}))\).

**Remark 3.1** (On abuse of notation).: _Note that for every \(\widehat{y}\in\widehat{\mathcal{Y}}_{L}\) there is a unique \(\ell\in\llbracket L\rrbracket\) such that \(\widehat{y}=\ell B/L\) and we will write \(\pi(\ell\mid\bm{x})\) instead of \(\pi(\widehat{y}\mid\bm{x})\). Similarly, we write \(\mathcal{U}_{s}(\pi,\ell)\) instead of \(\mathcal{U}_{s}(\pi,\widehat{y})\), defined in (2), when no confusion is possible and the support \(\widehat{\mathcal{Y}}_{L}\) is fixed._

An extremely attractive feature of the problem in (4) is the fact that the solution to it can be written explicitly as a function of optimal dual variables, with the latter being a solution of a stochastic convex program with Lipschitz gradient--the main observation of our approach, that shares many similarities with the smoothing technique of Nesterov (2005). This is summarized in the following lemma.

**Lemma 3.1**.: _Let \(L\in\mathbb{N}\) and \(\beta>0\). Let \(\bm{\Lambda}^{\star}=(\bm{\lambda}^{\star}_{\ell s})_{\ell\in\llbracket L \rrbracket,s\in[K]}\) and \(\bm{\mathsf{V}}^{\star}=(\nu^{\star}_{\ell s})_{\ell\in\llbracket L\rrbracket,s \in[K]}\) be two matrices that are solutions to_

\[\min_{\bm{\Lambda},\bm{\mathsf{V}}\geqslant 0}\left\{F(\bm{\Lambda},\bm{\mathsf{V}}) \stackrel{{\mathrm{def}}}{{=}}\mathbb{E}\left[\operatorname{LSE}_{ \beta}\left(\big{(}\langle\bm{\lambda}_{\ell}-\bm{\nu}_{\ell},\,\bm{t}(\bm{X}) \rangle-r_{\ell}(\bm{X})\big{)}_{\ell\in\llbracket L\rrbracket}\right)\right]+ \sum_{\ell\in\llbracket L\rrbracket}\langle\bm{\lambda}_{\ell}+\bm{\nu}_{\ell},\,\bm{\varepsilon}\rangle\,\right\},\] (5)

_where \(\bm{t}(\bm{x})\stackrel{{\mathrm{def}}}{{=}}1-\frac{\tau(\bm{x}) }{\bm{p}}\), \(r_{\ell}(\bm{x})\stackrel{{\mathrm{def}}}{{=}}\left(\eta(\bm{x})- \frac{\ell B}{L}\right)^{2}\), and \(\bm{\lambda}_{\ell}=(\lambda_{\ell s})_{s\in[K]}\), \(\bm{\nu}_{\ell}=(\nu_{\ell s})_{s\in[K]}\). Then, (4) admits a solution in the form_

\[\pi_{\bm{\Lambda}^{\star},\bm{\mathsf{V}}^{\star}}(\ell\mid\bm{x})\stackrel{{ \mathrm{def}}}{{=}}\sigma_{\ell}\left(\beta\left(\langle\bm{\lambda}^{\star}_{ \ell^{\prime}}-\bm{\nu}^{\star}_{\ell^{\prime}},\,\bm{t}(\bm{x})\rangle-r_{\ell ^{\prime}}(\bm{x})\right)_{\ell^{\prime}\in\llbracket L\rrbracket}\right)\text{ for }\ell\in\llbracket L\rrbracket\,.\] (6)Assuming perfect knowledge of \(\eta\) and \(\tau\), the above lemma suggests a natural approach to estimating the \(\pi_{\mathbf{A}^{\star},\mathbf{V}^{\star}}\)--we can run a (version of) stochastic gradient descent on \(F(\cdot,\cdot)\) and then plug-in the resulting dual variables in the formula for \(\pi_{\mathbf{A}^{\star},\mathbf{V}^{\star}}\). Notably, a stochastic gradient of \(F(\cdot,\cdot)\) can be obtained by simply sampling one \(\bm{X}\) from \(\mathbb{P}_{\mathbf{X}}\)--it does not require labels for this step. Yet, even in the above idealized case, it is not clear which optimization criteria would allow us to prove that the resulting solution would yield good properties in terms of risk and fairness. As we will see, despite the problem in (5) being convex with Lipschitz gradient, it is crucial to control the norm of the gradient of \(F\) for good statisitcal properties of the algorithm. That goes without saying that this relaxation has its price--the smaller the regularization parameter \(\beta\) the less accurate the resulting solution, but the resulting dual optimization problem is easier and vice-versa.

Properties of \(F\) and \(\pi_{\mathbf{A}^{\star},\mathbf{V}^{\star}}\).Let us summarized key properties of the objects introduced in Lemma 3.1. The first two results concern the population properties of \(\pi_{\mathbf{A}^{\star},\mathbf{V}^{\star}}\):

**Lemma 3.2** (Fairness quantification).: _Let \(L\in\mathbb{N}\), \(\bm{\varepsilon}=(\varepsilon_{s})_{s\in[K]}\in[0,1]^{K},\beta>0\), and \(\pi_{\mathbf{A}^{\star},\mathbf{V}^{\star}}\) be defined in Lemma 3.1. Then, \(\mathcal{U}_{s}(\pi_{\mathbf{A}^{\star},\mathbf{V}^{\star}},\ell)\leqslant \varepsilon_{s}\) for all \(s\in[K],\ell\in[L]\)._

In words, the optimal entropic-regularized prediction function is feasible for (3), that is, it satisfies the relaxed fairness constraints as quantified by (2). Furthermore, we can show that its risk is also controlled by the regularization parameter \(\beta>0\).

**Lemma 3.3** (Risk gain).: _Let \(L\in\mathbb{N},\beta>0\), and \(\pi_{\mathbf{A}^{\star},\mathbf{V}^{\star}}\) be defined in Lemma 3.1. For any \(\pi:\mathcal{B}(\mathbb{R})\times\mathbb{R}^{d}\to[0,1]\) that is feasible for (3), we have_

\[\mathcal{R}(\pi_{\mathbf{A}^{\star},\mathbf{V}^{\star}})\leqslant\mathcal{R}( \pi)+\tfrac{\log|\widehat{\mathcal{Y}}_{L}|}{\beta}\,.\]

The above result is rather instructive, it quantifies the price of the introduced regularization. Intuitively, one wants to set \(\beta\) high enough, so that the additive term in the above bound is vanishing. Unfortunately, we cannot set it arbitrarily high, since it will introduce instabilities from the optimization perspective--the function \(F\) becomes less regular as \(\beta\) growth. This is summarized below.

**Lemma 3.4** (Regularity of \(F\)).: _Let \(\sigma^{2}\stackrel{{\text{def}}}{{=}}2\sum_{s\in[K]}\tfrac{1-p_ {s}}{p_{s}}\). The objective function in (5) is convex and its gradient is \((\beta\sigma^{2})\)-Lipschitz._

As mentioned, we see that the larger the \(\beta\) is, the less regular the function \(F\) is, making it harder to minimize. Thus, \(\beta\geqslant 0\) controls the trade-off between the optimization error and statistical bias.

Gradient of \(F\) is crucial.Let us show that the control of the gradient of \(F\) is the most important and non-trivial part that allows to demonstrate strong statistical properties of the plug-in rule derived from the above strategy.

To this end, let us introduce parametric family of prediction functions, defined for any \(\mathbf{\Lambda},\mathbf{V}\geqslant 0\) as

\[\pi_{\mathbf{\Lambda},\mathbf{V}}(\ell\mid\bm{x})\stackrel{{\text{ def}}}{{=}}\sigma_{\ell}\left(\beta\left(\left\langle\bm{\lambda}_{\ell^{ \prime}}-\bm{\nu}_{\ell^{\prime}},\,\bm{t}(\bm{x})\right\rangle-r_{\ell^{ \prime}}(\bm{x})\right)_{\ell^{\prime}\in[L]}\right)\text{ for }\ell\in[L]\,.\] (7)

We want to show that if \(\mathbf{\Lambda},\mathbf{V}\geqslant 0\) is nearly stationary point of \(F\), then \(\pi_{\mathbf{\Lambda},\mathbf{V}}\) is nearly optimal in terms of risk and its violation of the demographic parity constraint is controlled. Note that the optimization problem in (5) is constrained, thus, unless the minimum lies in the interior of the domain, we cannot hope for the gradient of \(F\) to go to zero. Instead, we introduce gradient mapping--a quantity that shares many properties of the gradient in the case of constraint optimization problem. For \(\alpha>0\),

\[\bm{G}_{\alpha}\left(\mathbf{\Lambda},\mathbf{V}\right)\stackrel{{ \text{def}}}{{=}}\frac{\left(\mathbf{\Lambda},\mathbf{V}\right)- \left(\left(\mathbf{\Lambda},\mathbf{V}\right)-\alpha\nabla F\left(\mathbf{ \Lambda},\mathbf{V}\right)\right)_{+}}{\alpha}\,.\] (8)

Our main observation is summarized in the next lemma.

**Lemma 3.5**.: _Let \(\sigma^{2}\stackrel{{\text{def}}}{{=}}2\sum_{s\in[K]}\tfrac{1-p_ {s}}{p_{s}}\), \(L\in\mathbb{N}\), \(\mathbf{\Lambda},\mathbf{V}\geqslant 0\), then for any \(\alpha>0,\beta>0\), the unfairness of \(\pi_{\mathbf{\Lambda},\mathbf{V}}\) satisfies_

\[\sum_{\ell\in[L]\leqslant[K]}\left(\mathcal{U}_{s}\big{(}\pi_{\mathbf{ \Lambda},\mathbf{V}},\ell\big{)}-\varepsilon_{s}\right)_{+}^{2}\leqslant\left\| \bm{G}_{\alpha}(\mathbf{\Lambda},\mathbf{V})\right\|^{2}\,.\]

_Furthermore,_

\[\mathcal{R}(\pi_{\mathbf{\Lambda},\mathbf{V}})\leqslant\mathcal{R}(\pi_{ \mathbf{\Lambda}^{\star},\mathbf{V}^{\star}})+\left(\left\|(\mathbf{\Lambda}, \mathbf{V})\right\|+\alpha\left\{\sigma+\left\|\bm{\varepsilon}\right\|\sqrt{2 |\widehat{\mathcal{Y}}_{L}|}\right\}\right)\left\|\bm{G}_{\alpha}(\mathbf{ \Lambda},\mathbf{V})\right\|+\frac{\log|\widehat{\mathcal{Y}}_{L}|}{\beta}\,.\]Lemma 3.5 is very instructive on its own--we can obtain a good estimator of \(\pi_{\mathbf{\Lambda}^{*},\mathbf{V}^{*}}\) in terms of risk and unfairness by performing stochastic optimization on \(F\) and controlling the norm of gradient mapping for a suitable parameter \(\alpha>0\). The final choice of the parameter \(\alpha\) will depend on the optimization algorithm used and will be purely theoretical. In particular, for our purposes, it is sufficient to guarantee an existence of some value of \(\alpha>0\) that yields desired statistical properties. A naive approach in doing so relies on a well-known relation between \(F(\mathbf{\Lambda},\mathbf{V})-F(\mathbf{\Lambda}^{*},\mathbf{V}^{*})\) and \(\|\bm{G}_{\alpha}(\mathbf{\Lambda},\mathbf{V})\|^{2}\) using the Lipshitzness of the gradient of \(F\) (see e.g., Beck, 2014, Lemma 9.11). More concretely, forgetting about the constraints1, one has

Footnote 1: Constraints introduce additional challenges, but are not relevant for this discussion.

\[\|\nabla F(\mathbf{\Lambda},\mathbf{V})\|^{2}\leqslant 2M\big{(}F(\mathbf{ \Lambda},\mathbf{V})-F(\mathbf{\Lambda}^{*},\mathbf{V}^{*})\big{)}\,,\] (9)

where \(M\) is the Lipschitz constant of \(\nabla F\). Thus, the above inequality suggests that it is sufficient to control the standard optimization error in order to control the norm of the gradient. Unfortunately this approach is deemed to fail for two reasons: the first being that we control only the squared norm of the gradient map and not the norm itself, thus loosing in the rate of convergence; the second, and more subtle reason, is the separation of the purely "statistical" rate that depends only on the variance of the stochastic gradient and scales as \(1/\sqrt{T}\), with \(T\) being the number of future samples from \(\mathbb{P}_{\bm{X}}\), and "optimization" rate of convergence that depends on \(M\) and the diameter of the problem and typically scales as \(1/T\) or even \(1/T^{2}\) if acceleration is used.

Indeed, in our setup, Lipschitz constant \(M\) of \(\nabla F\) is not a fixed constant, but a parameter to be set--it relates to \(\beta\) (cf. Lemma 3.4). Ideally, seeing Lemma 3.3, we want to set \(\beta=\Theta(\sqrt{T})\), leading to \(M=\Omega(\sqrt{T})\). Thus, in view of (9), a term of the form \(M/\sqrt{T}\) appears in the convergence rate, which destroys consistency of the resulting estimator. Arguably, this is less of an issue in case of convex optimization with constant Lipschitz constant \(M\), especially if we only want the norm to go to zero. This discussion highlights that it is crucial to keep the separation between the statistical part of the rate and the optimization part of the rate, while controlling the norm of the gradient. Lucky for us, it is known that for convex problems one can indeed control the gradient mapping keeping this separation of the rate (Allen-Zhu, 2021, Foster et al., 2019). Note that it is not the case for non-convex problems as demonstrated by Arjevani et al. (2023).

Summary of our approach and why is it different from others.Now, keeping in mind the above, rather long justification, we are in position to sketch our approach and the formal presentation is deferred to the next section. For well selected parameters \(\beta>0\), \(L\in\mathbb{N}\), we are going to perform stochastic optimization of \(F\), relying on the SGD3 algorithm of Allen-Zhu (2021). In order to compute the stochastic gradient of \(F\), we are simply going to sample one \(\mathbb{P}_{\bm{X}}\) and it appears that this stochastic gradient has a well-behaved variance (see Appendix B-C for details). To make our approach completely data-driven (or at least to understand the order of magnitude of the parameters), we will compute or bound all the oracle quantities that appear in the used optimization algorithm (essentially related to the step-size tuning). We will show that for any sufficiently small \(\alpha>0\), the term \(\mathbb{E}\|\bm{G}_{\alpha}(\widehat{\mathbf{\Lambda}},\widehat{\mathbf{V}})\| ^{2}\) is controlled and then rely on Lemma 3.5 and some additional results to demonstrate that the resulting \(\pi_{\widehat{\mathbf{\Lambda}},\widehat{\mathbf{V}}}\) possesses good statistical properties.

**Remark 3.2** (On the dynamic of algorithm).: _Note that for \(\mathbf{\Lambda}=\mathbf{V}=\mathbf{0}\), the corresponding_

\[\big{(}\pi_{\mathbf{0},\mathbf{0}}(\ell\mid\bm{x})\big{)}_{\ell\in[L]}=\bm{ \sigma}\left(\beta\left(-(\eta(\bm{x})-\ell^{\prime}B/L)^{2}\right)_{\ell^{ \prime}\in[L]}\right)\,.\]

_That is, the above prediction puts the most amount of mass on the atom \(\ell\) which minimizes \((\eta(\bm{x})-\ell B/L)^{2}\)--the most accurate, but unfair prediction. Since our algorithm is based on a SGD-type algorithm, initialized at \(\mathbf{\Lambda}_{0}=\mathbf{V}_{0}=\mathbf{0}\), then we expect that during the dynamic of the algorithm, the risk of \(\pi_{\mathbf{\Lambda}_{i},\mathbf{V}_{i}}\) increases, while the unfairness decreases. This phenomena coincides with the intuition of post-processing--we want to gain in fairness, while sacrificing some accuracy._

As it has been already mentioned, the idea of discretizing the image of (randomized) predictions is not novel and has been successfully deployed by Agarwal et al. (2019) for an in-processing estimator and by Chzhen et al. (2020) for a post-processing estimator. We use this insight as a building block, but significantly deviate from both algorithms. Compared to Agarwal et al. (2019), our algorithm is positioned in the realm of post-processing and even _online_ post-processing, where i.i.d. samplesfrom \(\mathbb{P}_{\bm{X}}\) comes in a stream and we do not need to store them in memory. Also, while their algorithm is partially inspired by theory, the same theory suggests that this algorithm is not computationally efficient and it relies on some black-box parts that assume perfect solutions to some optimization problems. That being said, the algorithm of Agarwal et al. (2019) seem to be the gold standard method for the generic in-processing method in this problem. Compared to Chzhen et al. (2020), we have made a sequence of improvements. First, our setup is unawareness, which is not the case in their paper; second, our algorithm is able to handle multiple protected attributes as well as approximate fairness constraints; finally, and most importantly, we do not make black-box assumptions about having access to exact minimizers of convex problems and provide an end-to-end analysis of out approach. Let us also remark that our method cannot be considered as a simple extension of Chzhen et al. (2020) as we rely on different phenomenons and provide a very different algorithm. On a more subjective note, we believe that our approach is a nice example of a real convex optimization problem, where the norm of the gradient plays the central role, while the optimization error in term of the objective function does not matter2. This is precisely the phenomena highlighted by Nesterov (2012).

Footnote 2: To be more precise, the optimization error is automatically handled by the control of the gradient.

```
1:Input: discretization parameter \(L\geqslant 1\); regularization \(\beta>0\), number of stochastic gradient evaluations \(T\geqslant 1\); marginal distribution \(\bm{p}\) of \(S\); regression function \(\eta\); conditional distribution \(\bm{\tau}\) of \(S\mid\bm{X}\); bound \(B>0\) on \(\eta\).
2:Build uniform grid \(\widehat{\mathcal{Y}}_{L}\) over \([-B,B]\);
3:Set parameters: \(\sigma^{2}=2\sum_{s\in[K]}\frac{1-p_{s}}{p_{s}}\), \(M=\beta\sigma^{2}\);
4:Set \((\bm{\Lambda},\mathbf{V})\mapsto F(\bm{\Lambda},\mathbf{V})\) as defined in Lemma 3.1
5:Run a black-box optimizer \(\mathcal{A}(F,\sigma^{2},M,T)\) on function \(F\) having access to \(T\) stochastic gradient evaluations (see (11)) with variance \(\sigma^{2}\) and smoothness parameter \(M\) to obtain \((\widehat{\bm{\Lambda}},\widehat{\mathbf{V}})\);
6:return\(\pi_{(\widehat{\bm{\Lambda}},\widehat{\mathbf{V}})}(\cdot\mid\cdot)\) as defined in (7); ```

**Algorithm 1**DP post-processing\((L,T,\beta,\bm{p},B,\eta,\bm{\tau})\)

In this section, we provide all the details about the proposed algorithm in case \(\eta\) and \(\bm{\tau}\) are known. If they are unknown, these quantities are replaced by their estimates \(\widehat{\eta}\) and \(\widehat{\bm{\tau}}\) that are constructed on a separate labeled dataset. First, for \(\bm{\Lambda}=(\lambda_{\ell s})_{\ell\in[\bm{l}],s\in[K]}\), \(\mathbf{V}=(\nu_{\ell s})_{\ell\in[\bm{l}],s\in[K]}\), let us provide the expression for the gradient of \(F\):

\[\nabla_{\square_{\ell s}}F(\bm{\Lambda},\mathbf{V})=\triangle\mathbb{E}\left[ \sigma_{\ell}\left(\beta\left(\langle\bm{\lambda}_{\ell^{\prime}}-\bm{\nu}_{ \ell^{\prime}},\,\bm{t}(\bm{X})\rangle-r_{\ell^{\prime}}(\bm{X})\right)_{\ell^ {\prime}=-L}^{L}\right)t_{s}(\bm{X})\right]+\varepsilon_{s}\,,\] (10)

where \(\square\in\{\lambda,\nu\}\) and \(\triangle=1\) if \(\square=\lambda\) and \(\triangle=-1\) otherwise. Thus, a _stochastic gradient_\(\bm{g}(\bm{\Lambda},\mathbf{V})=(g_{\lambda_{\ell s}}(\bm{\Lambda},\mathbf{ V}),g_{\nu_{\ell s}}(\bm{\Lambda},\mathbf{V}))_{\ell\in[\bm{l}],s\in[K]}\) of \(F\) at a point \((\bm{\Lambda},\mathbf{V})\) can be computed by erasing expectation in (10), _i.e._, by sampling one \(\bm{X}\sim\mathbb{P}_{\bm{X}}\), using the same convention as above about \(\square\), \(\triangle\):

\[g_{\square_{\ell s}}(\bm{\Lambda},\mathbf{V})=\triangle\sigma_{\ell}\left( \beta\left(\langle\bm{\lambda}_{\ell^{\prime}}-\bm{\nu}_{\ell^{\prime}},\, \bm{t}(\bm{X})\rangle-r_{\ell^{\prime}}(\bm{X})\right)_{\ell^{\prime}=-L}^{L} \right)t_{s}(\bm{X})+\varepsilon_{s}\,.\] (11)

The next result controls the variance of the above stochastic gradient.

**Lemma 4.1**.: _Let \(\sigma^{2}\stackrel{{\text{def}}}{{=}}2\sum_{s\in[K]}\frac{1-p_{ s}}{p_{s}}\). It holds that \(\mathbb{E}\|\bm{g}(\bm{\Lambda},\mathbf{V})-\nabla F(\bm{\Lambda},\mathbf{V})\|^ {2}\leqslant\sigma^{2}\)._

The proposed method is summarized in Algorithm 1. It uses a black-box stochastic optimization algorithm \(\mathcal{A}\), that operates on a convex function \(F\) and a stochastic first-order oracle. The stochastic-first order oracle is implemented by (11) and only requires to sample \(\bm{X}\sim\mathbb{P}\) in an i.i.d. manner. We also pass two additional parameters to this algorithm: namely, we pass the variance \(\sigma^{2}\) from Lemma 4.1 and the Lipschitz constant of the gradient of \(F\) from Lemma 3.4. Then one can use any such algorithm. However, as shown in Lemma 3.5, those algorithms that are tailored to control expected norm of gradient mapping are preferred. For example, one can use SGD3 of Allen-Zhu (2021) or an improved version of Foster et al. (2019) that relies on restarted accelerated SGD of Ghadimi and Lan (2012).

Theoretical guarantees.

Let us first provide main results for Algorithm 1 assuming that \(\eta\) and \(\bm{\tau}\) are known. Note that Algorithm 1 can rely on any optimization algorithm. We provide a complete analysis using a refined version of SGD3 algorithm of Allen-Zhu (2021) that is due to Foster et al. (2019) with additional modifications taking into account the specific structure of our problem. We state the main result in existential form and postpone all the details on the implementation of the algorithm and a primer on optimization to the supplementary material (Appendix C-D).

**Theorem 5.1**.: _Let \(\bm{\varepsilon}=(\varepsilon_{s})_{s\in[K]}\in[0,1]^{K}\) and \(\sigma^{2}=2\sum_{s\in[K]}(1-p_{s})/p_{s}\). Setting \(\beta=\frac{T}{8\log_{2}(T)}\) and \(L=\sqrt{T}\), there exists an optimizer \(\mathcal{A}\) to be used in Algorithm 1 that, for \(T\) larger than some absolute constant, ensures_

\[\mathbf{E}^{\sfrac{1}{2}}\bigg{[}\sum_{\ell\in[L]\bm{s}\in[K]}\big{(}\mathcal{ U}_{s}\big{(}\pi_{\bm{\Lambda},\mathbf{V}},\ell\big{)}-\varepsilon_{s}\big{)}_{+} ^{2}\bigg{]}\leqslant\widetilde{\mathcal{O}}\left(\frac{\sigma}{\sqrt{T}} \left(1+\frac{\sigma}{\sqrt{T}}\left\|(\bm{\Lambda}^{\star},\mathbf{V}^{\star} )\right\|\right)\right)\,.\]

_Furthermore, if Assumption 3.1 is satisfied and let_

\[\mathcal{R}^{\star}\stackrel{{\text{def}}}{{=}}\inf_{n:\Re^{ \star}\to[-B,B]}\left\{\mathcal{R}(h)\,:\,\sup_{t\in R}|\mathbb{P}(h(\bm{X}) \leqslant t\mid S=s)-\mathbb{P}(h(\bm{X})\leqslant t)|\leqslant\frac{ \varepsilon_{s}}{2},\quad\forall s\in[K]\right\}\] (12)

_and \(\mathcal{E}(\pi_{\widehat{\bm{\Lambda}},\widehat{\mathbf{V}}})\stackrel{{ \text{def}}}{{=}}\mathbb{E}\left[\mathcal{R}(\pi_{\widehat{\bm{\Lambda}}, \widehat{\mathbf{V}}})\right]-\mathcal{R}^{\star}\), then for the same algorithm_

\[\mathcal{E}(\pi_{\widehat{\bm{\Lambda}},\widehat{\mathbf{V}}})\leqslant \widetilde{\mathcal{O}}\left(\left(\frac{\sigma}{\sqrt{T}}\mathbf{E}^{\sfrac{ 1}{2}}\left[\|(\widehat{\bm{\Lambda}},\widehat{\mathbf{V}})\|^{2}\right]+ \frac{\|\bm{\varepsilon}\|}{T^{\sfrac{1}{4}}}\right)\left(1+\frac{\sigma}{ \sqrt{T}}\left\|(\bm{\Lambda}^{\star},\mathbf{V}^{\star})\right\|\right)+ \frac{B}{\sqrt{T}}\right)\,.\]

Theorem 5.1 gives two results: the first one being on the unfairness of the proposed estimator and the second one on the risk of thereof compared to a benchmark prediction function in (12). The benchmark that we pick is rather natural, we compare to the risk of a deterministic prediction that minimizes the risk and whose unfairness is controlled by a Kolmogorov-Smirnov distance. One first main observation is that both fairness and risk decrease at the rate \(1/\sqrt{T}\) and \(T\) is the number of unlabeled data. From our numerical experiments, we observed that we can keep the number of unlabeled data unchanged and iterate several times through them. As a result, we increase artificially \(T\)--without generating new data--which gives a significant empirical improvement. We also remark that \(\sigma\) is the parameter that depends on the number of groups. For example, in the case of uniform distribution of sensitive groups \(\sigma=O(K)\). We finally remark that both bounds involve a single unknown quantity--\(\|(\bm{\Lambda}^{\star},\mathbf{V}^{\star})\|\), which from standard duality argument can be shown to be bounded by \(O(1/\min_{s\in[K]}\{\varepsilon_{s}\})\)(see e.g., Nedic and Ozdaglar, 2009, Lemma 3). Thus, having this norm multiplied by \(T^{-1/2}\) is a very attractive property of the bound. It allows to set \(\varepsilon\approx T^{-1/2}\) without damaging the parametric convergence rate.

To derive the above result, we slightly extend the analysis of Foster et al. (2019), who, relying on the SGD3 algorithm of Allen-Zhu (2021), gave an optimal algorithm that controls the expected norm of the gradient in the convex case. More concretely, we incorporate a projection step into their analysis and extend the control to the squared norm of the gradient map. Interestingly, due to our smoothing step and the choice of the parameter \(\beta\), we noticed that there is no need to restart the accelerated SGD as it is done by Foster et al. (2019) because it leads to identical statistical convergence rates. The interested reader can take a closer look into the Appendix C, where all the optimization results are either recalled or derived for the sake of completeness. Finally, having a control of the squared norm of the gradient map, the proof of Theorem 5.1 follows from Lemma 3.5 and a careful and practical choice of all the parameters of the algorithm.

Extension to unknown \(\eta\) and \(\tau\).In this part we show that if we replace \(\eta\) and \(\bm{\tau}\) with their estimates \(\widehat{\eta}\) and \(\widehat{\bm{\tau}}\) and run DP post-processing\((L,T,\beta,\bm{p},B,\widehat{\eta},\widehat{\bm{\tau}})\) algorithm with the same choice of parameters, Theorem 5.1 remains if we pay additional price for the estimation of \(\eta\) and \(\bm{\tau}\). From now on, we assume that \(\widehat{\eta}\) and \(\widehat{\bm{\tau}}\) are provided and are trained on its own labeled data sample, while the refitting is performed on an independent stream of i.i.d. data from \(\mathbb{P}_{\bm{X}}\). So, we essentially treat \(\widehat{\eta}\) and \(\widehat{\bm{\tau}}\) as deterministic functions. Let us introduce a family of prediction functions

\[\widehat{\pi}_{\bm{\Lambda},\mathbf{V}}(\ell\mid\bm{x})\stackrel{{ \text{def}}}{{=}}\sigma_{\ell}\left(\beta\left(\left\langle\bm{\lambda}_{ \ell^{\prime}}-\bm{\nu}_{\ell^{\prime}},\,\widehat{\bm{t}}(\bm{x})\right\rangle -\widehat{r}_{\ell^{\prime}}(\bm{x})\right)_{\ell^{\prime}\in[L]}\right)\text{ for }\ell\in[L]\,.\] (13)

[MISSING_PAGE_FAIL:9]

Comparison with Agarwal et al. (2019).Surprisingly, we were unable to find many open source competitors that target regression with demographic parity constraint in unaware setting, even the FairLearn--a popular python package--does not deal with the demographic parity constraint in regression. The only easily accessible algorithm that deals with our problem was kindly provided by Agarwal et al. (2019) (from now on referenced as ADW). We train ADW method in two ways: we use \(\mathcal{D}_{\mathrm{train}}\) and \(\mathcal{D}_{\mathrm{unlabeled}}\) as training set for ADW-1, whereas for ADW-2 we use only \(\mathcal{D}_{\mathrm{train}}\). The second situation is realistic, when unlabeled data is available and unlike ADW, our approach is able to take advantage of it. We take the set \(\{(2^{-i},2^{-i})_{i\in\mathcal{I}}\}\), where \(\mathcal{I}=\{1,2,4,8,16\}\) as unfairness thresholds for training both datasets. We train ADW-1 and ADW-2 for each pair of epsilons for 10 times. With our available computing power and the code provided by the authors, the algorithm runs for 13.5 hours (see Appendix G for additional details).4

Footnote 4: The experiments are conducted on a Processor 11th Gen Intel(R) Core(TM) i7-1195G7 2.90GHz with 16GB RAM.

On Figure 2 we illustrate the comparison of risk and unfairness between ADW-1, ADW-2, base (LinearRegression) and our model. We plot the mean and standard deviation of risk and unfairness for each epsilon threshold on both datasets. We observe that our method is competitive or eventually outperforms ADW in both training regimes.

## 7 Conclusion

Deriving a dual convex surrogate, we have provided a generic way to build a post-processing estimator of any off-the-shelf method that achieves the demographic parity constraint. Our approach is fully data and theory driven, revealing a key role of stationary point guarantees in stochastic convex optimization. Following Remark 2.2, we intend to extend our approach, which is general enough, to other learning problems, beyond algorithmic fairness.

Limitations.From the theoretical perspective, the knowledge of \(B\) seems to be the main limitation. While it is available for many applications, it does not have to be the case all the time. Replacing this assumption with some tail conditions, could be more realistic. From the applied perspective, it would be beneficial to further investigate stationary point guarantees for convex optimization to yield a better practical performance.

AcknowledgementsThe work of Gayane Taturyan has been supported by the French government under the "France 2030" program, as part of the SystemX Technological Research Institute within the Confinance.ai project.

Figure 1: Risk and unfairness of our estimator on _Communities and Crime_ and _Law School_ datasets.

Figure 2: Comparison with ADW model on _Communities and Crime_ and _Law School_ datasets.

## References

* Agarwal et al. (2019) A. Agarwal, M. Dudik, and Z. S. Wu. Fair regression: Quantitative definitions and reduction-based algorithms. In _International Conference on Machine Learning_, 2019.
* Allen-Zhu (2021) Z. Allen-Zhu. How to make the gradients small stochastically: Even faster convex and nonconvex sgd, 2021.
* Arjevani et al. (2023) Y. Arjevani, Y. Carmon, J. Duchi, D. Foster, N. Srebro, and B. Woodworth. Lower bounds for non-convex stochastic optimization. _Mathematical Programming_, 199(1-2):165-214, 2023.
* Barocas et al. (2018) S. Barocas, M. Hardt, and A. Narayanan. _Fairness and Machine Learning_. fairmlbook.org, 2018.
* Beck (2014) A. Beck. _Introduction to nonlinear optimization: Theory, algorithms, and applications with MATLAB_. SIAM, 2014.
* Bhatia and Davis (2000) R. Bhatia and C. Davis. A better bound on the variance. _The American Mathematical Monthly_, 107(4):353-357, 2000. doi: 10.1080/00029890.2000.12005203.
* Boyd and Vandenberghe (2004) S. Boyd and L. Vandenberghe. _Convex optimization_. Cambridge university press, 2004.
* Calders et al. (2009) T. Calders, F. Kamiran, and M. Pechenizkiy. Building classifiers with independency constraints. In _IEEE international conference on Data mining_, 2009.
* Chiappa et al. (2020) S. Chiappa, R. Jiang, T. Stepleton, A. Pacchiano, H. Jiang, and J. Aslanides. A general approach to fairness with optimal transport. In _AAAI_, 2020.
* Chzhen and Schreuder (2020a) E. Chzhen and N. Schreuder. An example of prediction which complies with demographic parity and equalizes group-wise risks in the context of regression. _arXiv preprint arXiv:2011.07158_, 2020a.
* Chzhen and Schreuder (2020b) E. Chzhen and N. Schreuder. A minimax framework for quantifying risk-fairness trade-off in regression. _arXiv preprint arXiv:2007.14265v2_, 2020b.
* Chzhen et al. (2019) E. Chzhen, C. Denis, M. Hebiri, L. Oneto, and M. Pontil. Leveraging labeled and unlabeled data for consistent fair binary classification. In _Advances in Neural Information Processing Systems_, 2019.
* Chzhen et al. (2020a) E. Chzhen, C. Denis, M. Hebiri, L. Oneto, and M. Pontil. Fair regression with wasserstein barycenters. _NeurIPS 2020_, 2020a.
* Chzhen et al. (2020b) E. Chzhen, M. Denis, C.and Hebiri, L. Oneto, and M. Pontil. Fair regression via plug-in estimator and recalibration. _NeurIPS 2020_, 2020b.
* Chzhen et al. (2021) E. Chzhen, C. Denis, and M. Hebiri. Minimax semi-supervised set-valued approach to multi-class classification. _Bernoulli_, 2021.
* Denis et al. (2024) C. Denis, R. Elie, M. Hebiri, and F. Hu. Fairness guarantees in multi-class classification with demographic parity. _Journal of Machine Learning Research_, 25(130):1-46, 2024.
* Dwork et al. (2011) C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and R. Zemel. Fairness through awareness, 2011. URL https://arxiv.org/abs/1104.3913.
* Feldman et al. (2015) M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, and S. Venkatasubramanian. Certifying and removing disparate impact. In _International Conference on Knowledge Discovery and Data Mining_, 2015.
* Foster et al. (2019) D. Foster, A. Sekhari, O. Shamir, N. Srebro, K. Sridharan, and B. Woodworth. The complexity of making the gradient small in stochastic convex optimization. In _Conference on Learning Theory_, pages 1319-1345. PMLR, 2019.
* Gao and Pavel (2017) B. Gao and L. Pavel. On the properties of the softmax function with application in game theory and reinforcement learning. _arXiv preprint arXiv:1704.00805_, 2017.
* Gaucher et al. (2023) S. Gaucher, N. Schreuder, and E. Chzhen. Fair learning with wasserstein barycenters for non-decomposable performance measures. In _Proceedings of The 26th International Conference on Artificial Intelligence and Statistics_, volume 206 of _Proceedings of Machine Learning Research_, pages 2436-2459. PMLR, 25-27 Apr 2023. URL https://proceedings.mlr.press/v206/gaucher23a.html.
* Ghadimi and Lan (2012) S. Ghadimi and G. Lan. Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization i: A generic algorithmic framework. _SIAM Journal on Optimization_, 22(4):1469-1492, 2012.
* Gordaliza et al. (2019) P. Gordaliza, E. Del Barrio, G. Fabrice, and J. M. Loubes. Obtaining fairness using optimal transport theory. In _International Conference on Machine Learning_, 2019.
* Gordaliza et al. (2019)M. Hardt, E. Price, and N. Srebro. Equality of opportunity in supervised learning. _Advances in neural information processing systems_, 29, 2016.
* Jiang et al. [2020] R. Jiang, A. Pacchiano, T. Stepleton, H. Jiang, and S. Chiappa. Wasserstein fair classification. _Uncertainty in Artificial Intelligence Conference_, 2020.
* Le Gouic et al. [2020] T. Le Gouic, J.-M. Loubes, and P. Rigollet. Projection to fairness in statistical learning. _arXiv preprint arXiv:2005.11720_, 2020.
* Lichman [2013] M. Lichman. Adult. UCI Machine Learning Repository, 2013. URL http://archive.ics.uci.edu/ml.
* Lum and Johndrow [2016] K. Lum and J. Johndrow. A statistical framework for fair predictive algorithms. _arXiv preprint arXiv:1610.08077_, 2016.
* Maheshwari and Perrot [2022] G. Maheshwari and M. Perrot. Fairgrad: Fairness aware gradient descent. _arXiv preprint arXiv:2206.10923_, 2022.
* Narasimhan et al. [2020] H. Narasimhan, A. Cotter, M. Gupta, and S. Wang. Pairwise fairness for ranking and regression. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 34, pages 5248-5255, 2020.
* Nedic and Ozdaglar [2009] A Nedic and A Ozdaglar. Subgradient methods for saddle-point problems. _Journal of Optimization Theory and Applications_, 142(1):205-228, 2009.
* Nesterov [2005] Y. Nesterov. Smooth minimization of non-smooth functions. _Mathematical programming_, 103(3):127-152, 2005.
* Nesterov [2012] Y. Nesterov. How to make the gradients small. _Optima. Mathematical Optimization Society Newsletter_, (88):10-11, 2012.
* Redmond [2009] M. Redmond. Communities and Crime. UCI Machine Learning Repository, 2009. DOI: https://doi.org/10.24432/C53W3X.
* Wightman [1998] L. Wightman. Lsac national longitudinal bar passage study. lsac research report series. 1998. URL https://api.semanticscholar.org/CorpusID:151073942.
* Zafar et al. [2017] M. Zafar, I. Valera, M. Gomez Rodriguez, and K. Gummadi. Fairness beyond disparate treatment & disparate impact: Learning classification without disparate mistreatment. In _International Conference on World Wide Web_, 2017.
* Zemel et al. [2013] R. Zemel, Y. Wu, K. Swersky, T. Pitassi, and C. Dwork. Learning fair representations. In _International Conference on Machine Learning_, 2013.
* Zhao [2021] H. Zhao. Costs and benefits of fair regression. _arXiv preprint arXiv:2106.08812_, 2021.

Proofs for results in Section 3

First we explicit the first order optimality conditions for the problem in (5).

**Lemma A.1**.: _Let \((\bm{\Lambda}^{\star},\bm{\nabla}^{\star})\geqslant 0\) be any minimizer of (5) and \(\pi^{\star}=\pi_{\bm{\Lambda}^{\star},\bm{\nabla}^{\star}}\) be defined in (6). Then, there exist \(\bm{\Gamma}=(\gamma_{\ell s})_{\ell\in[\![L]\!],s\in[\![K]\!]},\bm{\Gamma}^{ \prime}=(\gamma^{\prime}_{\ell s})_{\ell\in[\![L]\!],s\in[\![K]\!]}\)--element-wise non-negative matrices such that_

\[\left\{\begin{array}{l}\mathbb{E}_{\bm{X}}\left[\pi^{\star}(\ell\mid\bm{X}) \bm{t}(\bm{X})\right]=-\varepsilon+\bm{\gamma}_{\ell}\\ \mathbb{E}_{\bm{X}}\left[\pi^{\star}(\ell\mid\bm{X})\bm{t}(\bm{X})\right]= \varepsilon-\bm{\gamma}^{\prime}_{\ell}\\ \gamma_{\ell s}\lambda^{\star}_{\ell s}=0\\ \gamma^{\prime}_{\ell s}\nu^{\star}_{\ell s}=0\end{array}\right.\qquad\forall \ell\in[\![L]\!],s\in[K]\,,\] (14)

_where \(\bm{\gamma}_{\ell}=(\gamma_{\ell s})_{s\in[K]},\bm{\gamma}^{\prime}_{\ell}=( \gamma^{\prime}_{\ell s})_{s\in[K]}\)._

Proof.: We first observe that the optimization problem in (5) is convex and smooth. Thus, Karush-Kuhn-Tucker conditions are sufficient for optimally. Furthermore, since Slatter's condition is satisfied, the latter is also necessary, as the strong duality holds. In particular, there exist \(\bm{\Gamma}=(\gamma_{\ell s})_{\ell\in[\![L]\!],s\in[\![K]\!]},\bm{\Gamma}^{ \prime}=(\gamma^{\prime}_{\ell s})_{\ell\in[\![L]\!],s\in[\![K]\!]}\)--element-wise non-negative matrices such that

\[\left\{\begin{array}{l}\nabla_{\bm{\Lambda}}F(\bm{\Lambda}^{\star},\bm{ \nabla}^{\star})-\bm{\Gamma}=\bm{0}\\ \nabla_{\bm{\nabla}}F(\bm{\Lambda}^{\star},\bm{\nabla}^{\star})-\bm{\Gamma}^{ \prime}=\bm{0}\\ \bm{\Lambda}^{\star},\bm{\nabla}^{\star}\geqslant 0\\ \gamma_{\ell s}\lambda^{\star}_{\ell s}=0\\ \gamma^{\prime}_{\ell s}\nu^{\star}_{\ell s}=0\end{array}\right.\qquad\qquad \forall\ell\in[\![L]\!],s\in[L]\,.\]

To conclude, it is sufficient to evaluate the gradient on \(F\), whose expression is given in (10) and use the definition of \(\pi^{\star}\). 

Proof of Lemma 3.1.: To prove this result, we introduce the Lagrangian for the problem in (4).

\[\mathcal{L}(\pi,\bm{\Lambda},\bm{\nabla})=\mathcal{R}_{\beta}(\pi)+\mathbb{E} _{\bm{X}}\left[\sum_{\ell\in[\![L]\!]}\left\langle\bm{\nu}_{\ell}-\bm{\lambda }_{\ell},\,\bm{t}(\bm{X})\right\rangle\pi(\ell\mid\bm{X})\right]-\sum_{\ell \in[\![L]\!]}\left\langle\bm{\lambda}_{\ell}+\bm{\nu}_{\ell},\,\varepsilon \right\rangle\,,\]

where we used the fact, that using the definition of \(\mathcal{U}_{s}\), for any randomized prediction function \(\pi\), we can write

\[\mathcal{U}_{s}(\pi,\ell)=\left|\frac{\mathbb{E}_{\bm{X}}\left[\pi(\ell\mid \bm{X})\mathbb{I}(S=s)\right]}{\mathbb{P}(S=s)}-\mathbb{E}_{\bm{X}}\left[\pi( \ell\mid\bm{X})\right]\right|=\left|\mathbb{E}_{\bm{X}}\left[\pi(\ell\mid \bm{X})t_{s}(\bm{X})\right]\right|\,.\] (15)

Thus, denoting by \((\star)\) the value in (4), we have

\[(\star)=\min_{\pi}\max_{\bm{\Lambda},\bm{\nabla}\geqslant 0}\mathcal{L}(\pi,\bm{ \Lambda},\bm{\nabla})=\max_{\bm{\Lambda},\bm{\nabla}\geqslant 0}\min_{\pi} \mathcal{L}(\pi,\bm{\Lambda},\bm{\nabla})\,,\]

where the second equality holds thanks to Sion's minmax theorem. Let us solve the inner minimization problem on the right-hand-side. We can write

\[\mathcal{L}(\pi,\bm{\Lambda},\bm{\nabla})=\mathbb{E}_{\bm{X}} \left[\sum_{\ell\in[\![L]\!]}\left(r_{\ell}(\bm{X})-\left\langle\bm{\lambda}_{ \ell}-\bm{\nu}_{\ell},\,\bm{t}(\bm{X})\right\rangle\right)\pi(\ell\mid\bm{X} )+\frac{1}{\beta}\Psi(\pi(\cdot\mid\bm{X}))\right]\] (16) \[-\sum_{\ell\in[\![L]\!]}\left\langle\bm{\lambda}_{\ell}+\bm{\nu} _{\ell},\,\varepsilon\right\rangle\,.\]

Thus, using the variational representation of \(\mathrm{LSE}_{\beta}\), recalled in Lemma F.1, we have

\[\min_{\pi}\mathcal{L}(\pi,\bm{\Lambda},\bm{\nabla}) =-\max_{\pi}\left\{\mathbb{E}_{\bm{X}}\left[\sum_{\ell\in[\![L] \!]}\left(\left\langle\bm{\lambda}_{\ell}-\bm{\nu}_{\ell},\,\bm{t}(\bm{X}) \right\rangle-r_{\ell}(\bm{X})\right)\pi(\ell\mid\bm{X})-\frac{1}{\beta}\Psi( \pi(\cdot\mid\bm{X}))\right]\right.\] \[\qquad\qquad\qquad+\sum_{\ell\in[\![L]\!]}\left\langle\bm{\lambda} _{\ell}+\bm{\nu}_{\ell},\,\varepsilon\right\rangle\Bigg{\}}\] \[=-\mathbb{E}_{\bm{X}}\left[\mathrm{LSE}_{\beta}\left(\left\langle \left\langle\bm{\lambda}_{\ell}-\bm{\nu}_{\ell},\,\bm{t}(\bm{X})\right\rangle-r _{\ell}(\bm{X})\right\rangle_{\ell\in[\![L]\!]}\right)\right]-\sum_{\ell\in[ \![L]\!]}\left\langle\bm{\lambda}_{\ell}+\bm{\nu}_{\ell},\,\varepsilon \right\rangle\,,\]and the optimum in the above problem for every \(\bm{\Lambda},\mathbf{V}\geqslant 0\) is achieved by \(\pi_{\bm{\Lambda},\mathbf{V}}\), defined in (7). Thus, we have

\[(\star)=\max_{\bm{\Lambda},\mathbf{V}\geqslant 0}\left\{-F(\bm{\Lambda},\mathbf{V} )\right\}=\mathcal{R}_{\beta}(\pi_{\bm{\Lambda}^{\star},\mathbf{V}^{\star}})\,.\] (17)

The proof is concluded. 

Proof of Lemma 3.2.: As shown in (15), for any randomized prediction function \(\pi\), we can write

\[\mathcal{U}_{s}(\pi,\ell)=\left|\mathbb{E}_{\bm{X}}\left[\pi(\ell\mid\bm{X})t_ {s}(\bm{X})\right]\right|\,.\]

Our goal is to show that \(\pi^{\star}\) satisfies the required fairness constraints. We are going to rely on Lemma A.1 Subtracting the first equation in (14) from the second one, we deduce that \(\bm{\gamma}_{\ell}+\bm{\gamma}_{\ell}^{\prime}=2\varepsilon\). Since \(\bm{\gamma}_{\ell},\bm{\gamma}_{\ell}^{\prime}\geqslant 0\), then we conclude that \(\gamma_{\ell s},\gamma_{\ell s}^{\prime}\in[0,2\varepsilon_{s}]\). The above implies that

\[-\varepsilon_{s}\leqslant\mathbb{E}_{\bm{X}}\left[\pi^{\star}(\ell\mid\bm{X} )t_{s}(\bm{X})\right]=\mathcal{U}_{s}(\pi^{\star},\ell)\leqslant\varepsilon_{ s}\,,\]

as claimed. 

Proof of Lemma 3.3.: Fix some randomized prediction function \(\pi\) that is feasible for the problem in (3). In particular, it must be supported on \(\widehat{\mathcal{Y}}\). Then, we can bound its negative risk as follows

\[-\mathcal{R}(\pi) =-\mathbb{E}_{\bm{X}}\left[\sum_{\ell\in[\![L]\!]}r_{\ell}(\bm{X} )\pi(\ell\mid\bm{X})\right]\] (18) \[\overset{(a)}{\leqslant}\mathbb{E}_{\bm{X}}\left[\sum_{\ell\in[ \![L]\!]}\left(\left\langle\bm{\lambda}_{\ell}^{\star}-\bm{\nu}_{\ell}^{\star},\,\bm{t}(\bm{X})\right\rangle-r_{\ell}(\bm{X})\right)\pi(\ell\mid\bm{X}) \right]+\sum_{\ell\in[\![L]\!]}\left\langle\bm{\lambda}_{\ell}^{\star}+\bm{ \nu}_{\ell}^{\star},\,\bm{\varepsilon}\right\rangle\] \[\overset{(b)}{\leqslant}\mathbb{E}_{\bm{X}}\left[\mathrm{LSE}_{ \beta}\left(\left(\left\langle\bm{\lambda}_{\ell}^{\star}-\bm{\nu}_{\ell}^{ \star},\,\bm{t}(\bm{X})\right\rangle-r_{\ell}(\bm{X})\right)_{\ell=-L}^{L} \right)\right]+\sum_{\ell\in[\![L]\!]}\left\langle\bm{\lambda}_{\ell}^{\star}+ \bm{\nu}_{\ell}^{\star},\,\bm{\varepsilon}\right\rangle\] \[\overset{(c)}{=}\mathbb{E}_{\bm{X}}\left[\sum_{\ell\in[L]\!]} \left(\left\langle\bm{\lambda}_{\ell}^{\star}-\bm{\nu}_{\ell}^{\star},\,t(\bm {X})\right\rangle-r_{\ell}(\bm{X})\right)\pi^{\star}(\ell\mid\bm{X})-\frac{1}{ \beta}\Psi(\pi^{\star}(\cdot\mid\bm{X}))\right]+\sum_{\ell\in[\![L]\!]}\left\langle \bm{\lambda}_{\ell}^{\star}+\bm{\nu}_{\ell}^{\star},\,\bm{\varepsilon}\right\rangle\] \[\overset{(d)}{\leqslant}\mathbb{E}_{\bm{X}}\left[\sum_{\ell\in[ \![L]\!]}\left(\left\langle\bm{\lambda}_{\ell}^{\star}-\bm{\nu}_{\ell}^{\star}, \,\bm{t}(\bm{X})\right\rangle-r_{\ell}(\bm{X})\right)\pi^{\star}(\ell\mid\bm{X })\right]+\sum_{\ell\in[\![L]\!]}\left\langle\bm{\lambda}_{\ell}^{\star}+\bm{ \nu}_{\ell}^{\star},\,\bm{\varepsilon}\right\rangle+\frac{\log(2L+1)}{\beta}\] \[\overset{(e)}{=}-\mathcal{R}(\pi^{\star})+\frac{\log(2L+1)}{\beta }\,,\]

for (a) we used the assumption that \(\pi\) is fair (_i.e._, \(\mathcal{U}_{s}(\pi,\ell)\leqslant\varepsilon_{s}\)), which due to the fact that \(\bm{\Lambda}^{\star},\mathbf{V}^{\star}\geqslant 0\) implies

\[\sum_{\ell\in[\![L]\!]}\left\langle\bm{\lambda}_{\ell}^{\star},\,\mathbb{E}_{ \bm{X}}\left[\bm{t}(\bm{X})\pi(\ell\mid\bm{X})\right]+\bm{\varepsilon}\right\rangle +\sum_{\ell\in[\![L]\!]}\left\langle\bm{\nu}_{\ell}^{\star},\,-\mathbb{E}_{ \bm{X}}\left[\bm{t}(\bm{X})\pi(\ell\mid\bm{X})\right]+\bm{\varepsilon} \right\rangle\geqslant 0\,,\]

since every term in the summation is non-negative; (b) uses the fact that \(\mathrm{LSE}_{\beta}(\bm{w})\geqslant\left\langle\bm{w},\,\bm{p}\right\rangle\) for any probability vector \(\bm{p}\) (see Lemma F.1 for details); (c) relies on the variational representation of the \(\mathrm{LSE}_{\beta}\), recalled in Lemma F.1 and the definition of \(\pi^{\star}(\cdot\mid\bm{X})\); (d) uses the uniform bound on the entropy; (e) the last equality relies on the complementary slackness condition (14) of Lemma A.1. It ensures that

\[\begin{cases}\lambda_{\ell s}^{\star}\mathbb{E}_{\bm{X}}\left[\pi^{\star}(\ell \mid\bm{X})t_{s}(\bm{X})\right]=-\lambda_{s}^{\star}\varepsilon_{s}\\ \nu_{\ell s}^{\star}\mathbb{E}_{\bm{X}}\left[\pi^{\star}(\ell\mid\bm{X})t_{s}( \bm{X})\right]=\nu_{\ell s}^{\star}\varepsilon_{s}\end{cases}\forall\ell\in[ \![L]\!],s\in[K]\,,\]

implying that

\[\mathbb{E}_{\bm{X}}\left[\sum_{\ell\in[\![L]\!]}\left\langle\bm{\lambda}_{\ell}^ {\star}-\bm{\nu}_{\ell}^{\star},\,\bm{t}(\bm{X})\right\rangle\pi^{\star}(\ell \mid\bm{X})\right]+\sum_{\ell\in[\![L]\!]}\left\langle\bm{\lambda}_{\ell}^{ \star}+\bm{\nu}_{\ell}^{\star},\,\bm{\varepsilon}\right\rangle=0\,.\]

The proof is concluded.

Proof of Lemma 3.5.: Fix arbitrary \(\mathbf{\Lambda},\mathbf{V}\geqslant 0\) and consider \(\pi_{\mathbf{\Lambda},\mathbf{V}}\), defined in (7). To ease the notation, in this proof, we write \(\pi\) instead of \(\pi_{\mathbf{\Lambda},\mathbf{V}}\).

**Part I.** Let us first recall the definition of the gradient map \(\bm{G}_{\alpha}\) given in (8). We have the following expression

\[\bm{G}_{\alpha}\left(\mathbf{\Lambda},\mathbf{V}\right)=\frac{(\mathbf{ \Lambda},\mathbf{V})-\left((\mathbf{\Lambda},\mathbf{V})-\alpha\nabla F\left( \mathbf{\Lambda},\mathbf{V}\right)\right)_{+}}{\alpha}\,,\]

where \((\cdot)_{+}\) is to be understood entry-wise. Observing that for any \(\alpha,a\geqslant 0\) and \(b\in\mathbb{R}\), we have

\[\left|\frac{a-(a-\alpha b)_{+}}{\alpha}\right|=\left|\frac{a-\max\{0;a-\alpha b \}}{\alpha}\right|=\left|\min\left\{\frac{a}{\alpha};b\right\}\right|\geqslant \left|\min\left\{0;b\right\}\right|\geqslant\left(-b\right)_{+}\,,\]

we deduce that

\[\left\|(-\nabla F(\mathbf{\Lambda},\mathbf{V}))_{+}\right\|\leqslant\left\| \bm{G}_{\alpha}(\mathbf{\Lambda},\mathbf{V})\right\|\qquad\forall\mathbf{ \Lambda},\mathbf{V}\geqslant 0\,.\] (19)

Relying on (10) and the expression for \(\pi\) in (7), we observe that

\[\nabla_{\lambda_{\ell_{s}}}F(\mathbf{\Lambda},\mathbf{V})=\mathbb{ E}_{\mathbf{X}}\left[\pi(\ell\mid\bm{X})t_{s}(\bm{X})\right]+\varepsilon_{s}\] (20) \[\nabla_{\nu_{\ell_{s}}}F(\mathbf{\Lambda},\mathbf{V})=-\mathbb{E}_ {\bm{X}}\left[\pi(\ell\mid\bm{X})t_{s}(\bm{X})\right]+\varepsilon_{s}\]

and that \(\mathcal{U}_{s}(\pi,\ell)=\left|\mathbb{E}\left[\pi(\ell\mid\bm{X})t_{s}(\bm{ X})\right]\right|\) as it is shown in (15). Using the fact that \((|a|-c)_{+}^{2}=(-a-c)_{+}^{2}+(a-c)_{+}^{2}\) for all \(a\in\mathbb{R}\) and \(c\geqslant 0\), we deduce from above

\[\left(\mathcal{U}_{s}(\pi_{\mathbf{\Lambda},\mathbf{V}},\ell)- \varepsilon_{s}\right)_{+}^{2}=\left(-\nabla_{\lambda_{\ell_{s}}}F(\mathbf{ \Lambda},\mathbf{V})\right)_{+}^{2}+\left(-\nabla_{\nu_{\ell_{s}}}F(\mathbf{ \Lambda},\mathbf{V})\right)_{+}^{2}\qquad\forall\ell\in\llbracket L\rrbracket,s\in[K]\,.\] (21)

Thus, we have shown

\[\sum_{\begin{subarray}{c}\ell\in\llbracket L\rrbracket\\ s\in[K]\end{subarray}}\left(\mathcal{U}_{s}(\pi,\ell)-\varepsilon_{s}\right)_ {+}^{2}=\left\|(-\nabla F(\mathbf{\Lambda},\mathbf{V}))_{+}\right\|^{2}\,,\]

and (19) yields the claim.

**Part II.** We note that \(\pi_{(\mathbf{\Lambda},\mathbf{V})}\) is a unique solution to

\[\min_{\pi}\mathcal{L}(\pi,\mathbf{\Lambda},\mathbf{V})\,,\]

where \(\mathcal{L}\) is the Lagrangian defined in (16). Furthermore, \(\min_{\pi}\mathcal{L}(\pi,\mathbf{\Lambda},\mathbf{V})=-F(\mathbf{\Lambda}, \mathbf{V})=\mathcal{L}(\pi_{(\mathbf{\Lambda},\mathbf{V})},\mathbf{\Lambda}, \mathbf{V})\). Hence,

\[\mathcal{R}_{\beta}(\pi_{(\mathbf{\Lambda},\mathbf{V})})+F( \mathbf{\Lambda},\mathbf{V}) =\sum_{\ell\in\llbracket L\rrbracket,s\in[K]}\lambda_{\ell_{s}} \nabla_{\lambda_{\ell_{s}}}F(\mathbf{\Lambda},\mathbf{V})+\sum_{\ell\in \llbracket L\rrbracket,s\in[K]}\nu_{\ell s}\nabla_{\nu_{\ell_{s}}}F(\mathbf{ \Lambda},\mathbf{V})\] \[=\left\langle(\mathbf{\Lambda},\mathbf{V})\,,\,\nabla F\left( \mathbf{\Lambda},\mathbf{V}\right)\right\rangle\,.\]

For the sake of simplicity let us denote by \(\bm{u}\stackrel{{\rm def}}{{=}}(\mathbf{\Lambda},\mathbf{V})\in \mathbb{R}^{2K(2L+1)}\) and recall the definition of gradient mapping \(\bm{G}_{\alpha}\) given in (8). For any \(j\in[2K(2L+1)]\) and \(\alpha>0\), we have

\[\bm{G}_{\alpha j}(\bm{u})=\begin{cases}u_{j}/\alpha&\text{if }\alpha\partial_{j}F(\bm{u})>u_{j}\,,\\ \partial_{j}F(\bm{u})&\text{if }\partial_{j}F(\bm{u})\leqslant u_{j}\,.\end{cases}\]

To bound \(\left\langle\bm{u},\,\nabla F(\bm{u})\right\rangle\), let us examine each term of the scalar product. Denoting by \(\widetilde{\bm{u}}\stackrel{{\rm def}}{{=}}\bm{u}-\alpha\nabla F( \bm{u})\in\mathbb{R}^{2K(2L+1)}\), for any \(j\in[2K(2L+1)]\) and \(\alpha>0\), we have

\[u_{j}\partial_{j}F(\bm{u})=\alpha\partial_{j}F(\bm{u})\bm{G}_{\alpha j}(\bm{u}) \mathds{I}\{\widetilde{u}_{j}<0\}+u_{j}\bm{G}_{\alpha j}(\bm{u})\mathds{I}\{ \widetilde{u}_{j}\geqslant 0\}\,.\]

Thus, it holds that

\[\left\langle\bm{u},\,\nabla F(\bm{u})\right\rangle \leqslant\sum_{j\in[2K(2L+1)]}\left(\alpha|\partial_{j}F(\bm{u}) \bm{G}_{\alpha j}(\bm{u})|+|u_{j}\bm{G}_{\alpha j}(\bm{u})|\right)\leqslant \left(\left\|\bm{u}\right\|+\alpha\left\|\nabla F(\bm{u})\right\|\right)\left\| \bm{G}_{\alpha}(\bm{u})\right\|\] \[\leqslant\left(\left\|\bm{u}\right\|+\alpha\sigma+\alpha\left\| \varepsilon\right\|\sqrt{2(2L+1)}\right)\left\|\bm{G}_{\alpha}(\bm{u})\right\|\,,\]

where the last inequality follows from Lemma F.5 that bounds \(\left\|\nabla F(\bm{u})\right\|\).

To conclude the proof, we use the fact that It remains to observe that \(\min_{\mathbf{\Lambda},\mathbf{V}}F(\mathbf{\Lambda},\mathbf{V})=-\mathcal{R}_{ \beta}(\pi_{(\mathbf{\Lambda}^{*},\mathbf{V}^{*})})\), the bound (19) on \(\left\|(-\nabla F(\mathbf{\Lambda},\mathbf{V}))_{+}\right\|\) and the fact that \(\mathcal{R}_{\beta}(\pi)\leqslant\mathcal{R}(\pi)+\frac{\log(2L+1)}{\beta}\) for all \(\pi\).

## Appendix B Bound on the variance of the stochastic gradient and its' smoothness

Proof of Lemma 4.1.: We have

\[\mathbb{E}_{\bm{X}}\left\|g_{\bm{\Lambda},\mathbf{V}}(\bm{X})- \nabla_{\bm{\Lambda},\mathbf{V}}F\left(\bm{\Lambda},\mathbf{V}\right)\right\|^{2}\] \[\leqslant 2\mathbb{E}_{\bm{X}}\left\|\left(\sigma_{\ell}\left( \beta\left(\left\langle\lambda_{\ell^{\prime}}-\nu_{\ell^{\prime}},\,t(\bm{X}) \right\rangle-r_{\ell^{\prime}}(\bm{X})\right\rangle_{\ell^{\prime}=-L}^{L} \right)t_{s}(\bm{X})\right)_{\ell\in[L],s\in[K]}\right\|^{2}\] \[\leqslant 2\mathbb{E}_{\bm{X}}\left[\sum_{s\in[K]}t_{s}^{2}(\bm{X} )\right]\leqslant 2\sum_{s\in[K]}\frac{1-p_{s}}{p_{s}}\overset{\text{def}}{=} \sigma^{2}\,,\]

where the first inequality follows from the expressions of \(g_{\bm{\Lambda},\mathbf{V}}\) and \(\nabla_{\bm{\Lambda},\mathbf{V}}F\left(\bm{\Lambda},\mathbf{V}\right)\), and the fact that \(\mathrm{Var}(X+a)=\mathrm{Var}(X)\leqslant\mathbb{E}[X^{2}]\); the second inequality follows from the facts that \(\left\|(a_{i}b_{j})_{i,j}\right\|_{2}^{2}=\left\|\bm{a}\right\|_{2}^{2}\left\| \bm{b}\right\|_{2}^{2}\leqslant\left\|\bm{a}\right\|_{1}^{2}\left\|\bm{b} \right\|_{2}^{2}\) and that \(\left\|\sigma(\cdot)\right\|_{1}=1\); and the last inequality follows from Lemma F.4. 

Proof of Lemma 3.4.: The goal of this proof is to show that the gradient of \((\bm{\Lambda},\mathbf{V})\mapsto F(\bm{\Lambda},\mathbf{V})\) is \(M\)-Lipschitz. To this end, we first introduce some, rather heavy, but convenient, notation which will allow us to derive the announced result.

Introducing notation.We first vectorize the variables \((\bm{\Lambda},\mathbf{V})\) and express them as

\[\bm{z}\overset{\text{def}}{=}\underbrace{(\lambda_{-L1},\cdots \lambda_{-LK})}_{=\lambda_{-L}},\cdots\cdots,\underbrace{\lambda_{L1},\cdots \lambda_{LK}}_{=\lambda_{L}},\underbrace{\nu_{-L1},\cdots\nu_{-LK}}_{=\nu_{-L }},\cdots\cdots,\underbrace{\nu_{L1},\cdots\nu_{LK}}_{=\nu_{L}}\in\mathbb{R}^ {2K(2L+1)}\,.\]

Furthermore, for each \(\bm{x}\in\mathbb{R}^{d}\), we introduce a matrix \(\mathbf{A}(\bm{x})\in\mathbb{R}^{(2L+1)\times 2K(2L+1)}\) defined as

\[\mathbf{A}(\bm{x})\overset{\text{def}}{=}\begin{pmatrix}\bm{t}(\bm{x})^{ \top}&0\cdots 0&\cdots&0\cdots 0&-\bm{t}(\bm{x})^{\top}&0\cdots 0&\cdots&0 \cdots 0\\ 0\cdots 0&\bm{t}(\bm{x})^{\top}&\cdots&0\cdots 0&0\cdots 0&-\bm{t}(\bm{x})^{\top}& \cdots&0\cdots 0\\ \vdots&\vdots&\ddots&\vdots&\vdots&\vdots&\ddots&\vdots\\ 0\cdots 0&0\cdots 0&\cdots&\bm{t}(\bm{x})^{\top}&0\cdots 0&0\cdots 0&\cdots&-\bm{t}(\bm{x})^{ \top}\end{pmatrix}\,,\]

as well as

\[\bm{b}(\bm{x}) \overset{\text{def}}{=}\left(r_{-L}(\bm{X}),\cdots,r_{L}(\bm{X} )\right)^{\top}\in\mathbb{R}^{2L+1}\qquad\text{and}\] \[\bm{c} \overset{\text{def}}{=}\left(\varepsilon_{1},\cdots,\varepsilon_ {K},\varepsilon_{1},\cdots,\varepsilon_{K},\cdots\cdots,\varepsilon_{1}, \cdots,\varepsilon_{K}\right)^{\top}\in\mathbb{R}^{2K(2L+1)}\,.\]

Hessian of \(F\) in the introduced notation.With the above introduce notation, we can express the function \(F\) as

\[F\left(\bm{\Lambda},\mathbf{V}\right)=F(\bm{z})=\mathbb{E}_{\bm{X}}\left[ \operatorname{LSE}_{\beta}(\mathbf{A}(\bm{X})\bm{z}-\bm{b}(\bm{X}))\right]+ \left\langle\bm{c},\,\bm{z}\right\rangle\,.\]

That is, \(F\) is obtained from the \(\operatorname{LSE}_{\beta}\) by a point-wise affine transformation of the coordinates plus a linear term. Chain rule yields the following expressions for the Hessian of \(F\):

\[\nabla^{2}F(\bm{z})=\mathbb{E}_{\bm{X}}\left[\mathbf{A}(\bm{X})^{\top}\nabla^{ 2}\operatorname{LSE}_{\beta}(\mathbf{A}(\bm{X})\bm{z}-\bm{b}(\bm{X}))\mathbf{ A}(\bm{X})\right]\,.\]

Bounding the operator norm of the Hessian of \(F\).To conclude the proof, we provide a uniform upper bound on the operator (spectral) norm of the Hessian of \(F\). Using the Jensen's inequality and the fact that the operator norm is subordinate, we deduce that

\[\|\nabla^{2}F(\bm{z})\|_{\mathrm{op}} =\|\mathbb{E}_{\bm{X}}\left[\mathbf{A}(\bm{X})^{\top}\nabla^{2} \operatorname{LSE}_{\beta}(\mathbf{A}(\bm{X})\bm{z}-\bm{b}(\bm{X}))\mathbf{ A}(\bm{X})\right]\|_{\mathrm{op}}\] \[\leqslant\mathbb{E}_{\bm{X}}\left[\|\mathbf{A}(\bm{X})^{\top} \nabla^{2}\operatorname{LSE}_{\beta}(\mathbf{A}(\bm{X})\bm{z}-\bm{b}(\bm{X})) \mathbf{A}(\bm{X})\|_{\mathrm{op}}\right]\] \[\leqslant\mathbb{E}_{\bm{X}}\left[\|\mathbf{A}(\bm{X})\|_{\mathrm{ op}}\|\nabla^{2}\operatorname{LSE}_{\beta}(\mathbf{A}(\bm{X})\bm{z}-\bm{b}(\bm{X}))\|_{ \mathrm{op}}\|\mathbf{A}(\bm{X})\|_{\mathrm{op}}\right]\,.\]

Lemma F.2, implies that \(\|\nabla^{2}\operatorname{LSE}_{\beta}(\mathbf{A}(\bm{X})\bm{z}-\bm{b}(\bm{X})) \|_{\mathrm{op}}\leqslant\beta\) almost surely and for all \(\bm{z}\). Thus, it remains to bound \(\mathbb{E}_{\bm{X}}\|\mathbf{A}(\bm{X})\|_{\mathrm{op}}^{2}\) to conclude the proof. To this end, consider a vector \(\bm{u}\), expressed "block-wise" as

\[\bm{u}=\big{(}\underbrace{u_{-L1}^{\lambda},\cdots u_{-LK}^{\lambda}}_{ \overset{\text{def}}{=}\bm{u}_{u_{-L}}^{\lambda}},\cdots\cdots,\underbrace{u_{ L1}^{\lambda},\cdots u_{LK}^{\lambda}}_{\overset{\text{def}}{=}\bm{u}_{u_{L}}^{\lambda}}, \underbrace{u_{-L1}^{\nu},\cdots u_{-LK}^{\nu}}_{\overset{\text{def}}{=}\bm{u}_{u_{-L }}^{\nu}},\cdots\cdots,\underbrace{u_{L1}^{\nu},\cdots u_{LK}^{\nu}}_{ \overset{\text{def}}{=}\bm{u}_{u_{L}}^{\nu}}\big{)}^{\top}\in\mathbb{R}^{2K(2L+1)}\,.\]Using the definition of the operator norm and the expression for \(\mathbf{A}(\bm{X})\), we deduce that

\[\mathbb{E}_{\bm{X}}\|\mathbf{A}(\bm{X})\|_{\mathrm{op}}^{2} =\mathbb{E}_{\bm{X}}\sup_{\|\bm{u}\|_{2}^{2}=1}\|\mathbf{A}(\bm{X} )\bm{u}\|_{2}^{2}\] \[=\mathbb{E}_{\bm{X}}\sup_{\|\bm{u}\|_{2}^{2}=1}\sum_{\ell=-L}^{L} \big{(}\big{\langle}\bm{u}_{\ell}^{\lambda}-\bm{u}_{\ell}^{\nu},\,t(\bm{X}) \big{\rangle}\big{)}^{2}\] \[\leqslant 2\mathbb{E}_{\bm{X}}\left[\big{\|}t(\bm{X})\big{\|}_{2}^ {2}\right]\sup_{\|\bm{u}\|_{2}^{2}=1}\sum_{\ell\in[\![L]\!]}\left(\left\|\bm {u}_{\ell}^{\lambda}\right\|_{2}^{2}+\|\bm{u}_{\ell}^{\nu}\|_{2}^{2}\right)\,,\]

where the last inequality combines the Cauchy-Schwartz inequality and the fact that \(\|\bm{v}-\bm{w}\|_{2}^{2}\leqslant 2(\|\bm{v}\|_{2}^{2}+\|\bm{w}\|_{2}^{2})\) for all \(\bm{v},\bm{w}\in\mathbb{R}^{m}\). The proof is concluded using Lemma F.4 to bound \(\mathbb{E}_{\bm{X}}\,\|t(\bm{X})\|_{2}^{2}\). 

**Lemma B.1** (Price of discretization).: _Let Assumption 3.1 be satisfied. Let \(\beta,B>0,L\in\mathbb{N}\). Consider_

\[\mathcal{R}^{\star}\stackrel{{\text{def}}}{{=}}\inf_{h:\mathbb{R }^{d}\to\mathbb{R}}\left\{\mathbb{E}(h(\bm{X})-\eta(\bm{X}))^{2}\,:\,\sup_{t \in\mathbb{R}}|\mathbb{P}(h(\bm{X})\leqslant t\mid S=s)-\mathbb{P}(h(\bm{X}) \leqslant t)|\leqslant\varepsilon_{s}/2,\quad\forall s\in[K]\right\}\,.\]

_Then, it holds that_

\[\mathcal{R}(\pi_{\bm{\Lambda}^{\star},\mathbf{V}^{\star}})\leqslant\mathcal{ R}^{\star}+\frac{4B}{L}+\frac{1}{L^{2}}+\frac{\log(2L+1)}{\beta}\,.\]

Proof.: Let us assume that \(\mathcal{R}^{\star}=\mathbb{E}(h^{\star}(\bm{X})-\eta(\bm{X}))\) for some \(h^{\star}:\mathbb{R}^{d}\to[-B,B]\). If it is not the case, the standard argument based on the minimizing sequence yields the same result.

Consider an operator \(T_{L}\), which maps a deterministic classifier \(h:\mathbb{R}^{d}\to[-B,B]\) onto a deterministic classifier \(T_{L}(h):\mathbb{R}^{d}\to\widehat{\mathcal{Y}}_{L}\), which is defined point-wise as follows

\[(T_{L}(h))(\bm{x})=\lfloor Lh(\bm{x})/B\rfloor B/L\qquad\forall\bm{x}\in \mathbb{R}^{d}\,,\]

where \(\lfloor a\rfloor\) is the closest integer smaller or equal to \(a\in\mathbb{R}\) in absolute value. Notice, that for any \(\ell\in\{-L,\ldots,L-1\}\) and any \(x\in\mathbb{R}^{d}\), we have

\[(T_{L}(h^{\star}))(\bm{x})=\frac{\ell B}{L}\quad\iff\quad h^{\star}(\bm{x}) \in\left[\frac{\ell B}{L},\frac{(\ell+1)B}{L}\right)\,.\]

Moreover,

\[(T_{L}(h^{\star}))(\bm{x})=B\quad\iff\quad h^{\star}(\bm{x})=B\,.\]

Since \(h^{\star}\) satisfies \((\varepsilon/2)\)-fairness constraints, one checks that for all \(\ell\in[\![L]\!],s\in[K]\)

\[\mathcal{U}_{\mathrm{s}}(T_{L}(h^{\star}),\ell)\leqslant\varepsilon_{s}\,.\]

That is, \(T_{L}(h^{\star})\) is feasible for the problem in (4). Therefore, Lemma 3.3 implies that

\[\mathcal{R}(\pi_{\bm{\Lambda}^{\star},\mathbf{V}^{\star}})\leqslant\mathcal{ R}(T_{L}(h^{\star}))+\frac{\log(2L+1)}{\beta}\,.\]

Furthermore, since \(|T_{L}(h^{\star})(\bm{x})-h^{\star}(\bm{x})|\leqslant 1/L\) and \(|\eta(\bm{x})-h^{\star}(\bm{x})|\leqslant 2B\), we have

\[\mathcal{R}(T_{L}(h^{\star}))=\mathbb{E}\left(\eta(\bm{X})-T_{L}(h^{\star})( \bm{X})\right)^{2}\leqslant\mathcal{R}(h^{\star})+\frac{4B}{L}+\frac{1}{L^{2}}\,.\]

The proof is concluded.

## Appendix C Additional details on the algorithm

In this part of the appendix, we provide the analysis for the proposed algorithm. First, we introduce required notation and recall a result of Foster et al. (2019), who provided an algorithm for convex stochastic optimization. The provided algorithm is a refined version of the SDG3 algorithm of Allen-Zhu (2021). We note that Foster et al. (2019) give a control of the expected norm of a gradient, while we require a control of the expected squared norm of the gradient mapping. We introduce projection to the algorithm of Foster et al. (2019) based on the original algorithm of Ghadimi and Lan (2012) and provide a control of the expected squared norm of the gradient mapping of the final estimated solution.

The setup and notation.Consider \(f:\mathbb{R}^{d}\times\mathcal{Z}\to\mathbb{R}\), such that \(\bm{w}\mapsto f(\bm{w},z)\) is convex for each \(z\in\mathcal{Z}\). Let \(W\subset\mathbb{R}^{d}\) be a closed convex set. Let

\[F(\bm{w})\stackrel{{\text{def}}}{{=}}\int f(\bm{w},z)\mathrm{d} \,P(z)\]

for some probability distribution \(P\) on \(\mathcal{Z}\). In what follows, we assume that

\[\bm{w}^{\star}\in\operatorname*{arg\,min}_{\bm{w}\in W}\,F(\bm{w})\]

always exists.

**Assumption C.1**.: _We assume that \(F\) is \(M\)-smooth and the variance of \(\nabla_{\bm{w}}f(\bm{w},z)\) is bounded. That is, for some \(M>0\) and \(\sigma>0\)_

\[\forall\bm{w},\bm{w}^{\prime}\in W\qquad\left\|\nabla F(\bm{w})- \nabla F(\bm{w}^{\prime})\right\|\leqslant M\left\|\bm{w}-\bm{w}^{\prime} \right\|\qquad\text{and}\] \[\forall\bm{w}\in W\qquad\int\left[\left\|\nabla_{\bm{w}}f(\bm{w},z)-\nabla F(\bm{w})\right\|^{2}\right]\mathrm{d}\,P(z)\leqslant\sigma^{2}\,.\]

Let us also define gradient mapping as

\[\bm{G}_{F,\alpha}(\bm{w})\stackrel{{\text{def}}}{{=}}\frac{\bm{ w}-\bm{w}_{+}}{\alpha}\quad\text{with}\quad\bm{w}_{+}\in\operatorname*{arg\,min}_{\bm{w}^{ \prime}\in W}\,\left\{\left\langle\nabla F(\bm{w}),\,\bm{w}^{\prime}\right\rangle +\frac{1}{2\alpha}\left\|\bm{w}^{\prime}-\bm{w}\right\|^{2}\right\}\,.\]

Let \(\text{Proj}_{W}(\cdot)\) be the Euclidean projection onto closed convex \(W\).

### Some known results.

We start by introducing the original AC-SA algorithm of Ghadimi and Lan (2012) and recall some of their results for the sake of completeness.

**Theorem C.1**.: _(_Ghadimi and Lan_,_ 2012_, Proposition 9)_ _Let \(\bm{w}^{\star}\in\operatorname*{arg\,min}_{\bm{w}\in W}F(\bm{w})\), \(\bm{w}_{0}\in W\) a starting vector. If \(F\) is \(\mu-\)strongly convex and \(T\geqslant 1\) then with_

\[\alpha_{t}=\frac{2}{t+1}\quad\text{and}\quad\gamma_{t}=\frac{4M}{t(t+1)}, \quad\forall t>1\]

\(\texttt{AC-SA}(F,\bm{w}_{0},\mu,M,T)\)_, defined in Algorithm 2, outputs \(\widehat{\bm{w}}_{T}\) satisfying_

\[\mathbb{E}[F(\widehat{\bm{w}}_{T})]-F(\bm{w}^{\star})\leqslant\frac{2M\left\| \bm{w}_{0}-\bm{w}^{\star}\right\|^{2}}{T^{2}}+\frac{8\sigma^{2}}{\mu T}\,.\]

Foster et al. (2019) propose another version of \(\texttt{AC-SA}\), called \(\texttt{AC-SA}^{2}\), which resets the stepsize halfway through the process.

**Lemma C.1**.: _(_Foster et al._,_ 2019_, Lemma 1)_ _Let \(W=\mathbb{R}^{d}\), \(\bm{w}^{\star}\in\operatorname*{arg\,min}_{\bm{w}\in W}F(\bm{w})\), \(\bm{w}_{0}\in\mathbb{R}^{d}\) a starting vector. If \(\mu>0\), \(M\geqslant 0\) and \(T\geqslant 1\) then \(\texttt{AC-SA}^{2}(F,\bm{w}_{0},\mu,M,T)\), defined in Algorithm 3, outputs \(\widehat{\bm{w}}\) satisfying_

\[\mathbb{E}[F(\widehat{\bm{w}})]-F(\bm{w}^{\star})\leqslant\frac{128M^{2}\left\| \bm{w}_{0}-\bm{w}^{\star}\right\|^{2}}{\mu T^{4}}+\frac{256M\sigma^{2}}{\mu^{2 }T^{3}}+\frac{16\sigma^{2}}{\mu T}\,.\]

**Remark C.1**.: _Foster et al. (2019) do not consider constrained optimization throughout their work. However, the proof of Lemma C.1 follows analogous arguments._

Foster et al. (2019) also introduce a refined version of algorithm SGD3 of Allen-Zhu (2021).

In what follows, we will show that Algorithm 4, after \(T\) evaluations of the stochastic gradient, produces a point \(\widehat{\bm{w}}\) such that \(\mathbb{E}\|\bm{G}_{F,\alpha}(\widehat{\bm{w}})\|^{2}\) is controlled. This is a, rather mild, extension of Foster et al. (2019) and Allen-Zhu (2021).

```
1:Input: function \(F\); initial vector \(\bm{w}_{0}\); parameters \(0<\mu\leqslant M\); number of iterations \(T\geqslant\Omega\left(\frac{M}{\mu}\log_{2}\frac{M}{\mu}\right)\)
2:\(F^{(0)}(\bm{w})\gets F(\bm{w})+\frac{\mu}{2}\left\|\bm{w}-\bm{w}_{0}\right\| ^{2};\widehat{\bm{w}}_{0}\leftarrow\bm{w}_{0};\mu_{0}\leftarrow\mu\)
3:for\(j=1\)to\(J=\left\lfloor\log\frac{M}{\mu}\right\rfloor\)do
4:\(\widehat{\bm{w}}_{j}\leftarrow\texttt{AC-SA}^{2}(F^{(j-1)},\widehat{\bm{w}}_{j -1},\mu_{j-1},2(M+\mu),\frac{T}{J})\)
5:\(\mu_{j}\gets 2\mu_{j-1}\)
6:\(F^{(j)}(\bm{w})\stackrel{{\text{def}}}{{=}}F^{(j-1)}(\bm{w})+ \frac{\mu_{j}}{2}\left\|\bm{w}-\widehat{\bm{w}}_{j}\right\|^{2}\)
7:endfor
8:return\(\widehat{\bm{w}}_{J}\) ```

**Algorithm 4**SGD3-refined\((F,\bm{w}_{0},\mu,M,T)\)

### Control of the expected squared norm

Most of the proof techniques are already present in the original contribution of Allen-Zhu (2021) and Foster et al. (2019), we slightly extend their proof, introducing modifications related to the control of the squared norm and the projection step. For some \(J\geqslant 1\), to be fixed later on, introduce

\[F_{\widehat{\mu}}(\bm{w})\stackrel{{\text{def}}}{{=}}F(\bm{w})+ \sum_{j=1}^{J}\frac{\mu_{j}}{2}\left\|\bm{w}-\widehat{\bm{w}}_{j}\right\|^{2} \quad\text{and}\quad\bm{w}_{\widehat{\mu}}^{\star}\in\operatorname*{arg\,min}_{ \bm{w}\in W}F_{\widehat{\mu}}(\bm{w})\,.\] (22)By construction, \(F_{\widetilde{\mu}}\) is \(\widetilde{\mu}\)\(\stackrel{{\mathrm{def}}}{{=}}\sum_{j=1}^{J}\mu_{j}\)-strongly convex and \((M+\widetilde{\mu})\)-smooth. Let us also define \(F^{(0)}\stackrel{{\mathrm{def}}}{{=}}F(\bm{w})\) and \(F^{(j)}(\bm{w})\stackrel{{\mathrm{def}}}{{=}}F^{(j-1)}(\bm{w})+ \frac{\mu_{j}}{2}\left\lVert\bm{w}-\widehat{\bm{w}}_{j}\right\rVert^{2}\), for \(j=1,2,\ldots,J\). We will use the following results of Allen-Zhu (2021).

**Lemma C.2**.: _(Allen-Zhu, 2021, Lemma 2.3) Let \(\widetilde{F}\) be an \(\widetilde{M}\)-smooth and \(\widetilde{\mu}\)-strongly convex function. Let \(\bm{w},\bm{w}^{\prime}\in W\) and \(\bm{w}^{+}=\bm{w}-\alpha\cdot\bm{G}_{\widetilde{F},\alpha}(\bm{w})\). For any \(\alpha\in\left(0,\frac{1}{M}\right]\), we have_

\[\widetilde{F}(\bm{w}^{\prime})\geqslant\widetilde{F}(\bm{w}^{+})+\left\langle \bm{G}_{\widetilde{F},\alpha}(\bm{w}),\,\bm{w}^{\prime}-\bm{w}\right\rangle+ \frac{\alpha}{2}\left\lVert\bm{G}_{\widetilde{F},\alpha}(\bm{w})\right\rVert^ {2}+\frac{\widetilde{\mu}}{2}\left\lVert\bm{w}^{\prime}-\bm{w}\right\rVert^{2}\,.\]

**Lemma C.3**.: _(Allen-Zhu, 2021, Lemma 5.1) Consider \(F_{\widetilde{\mu}}\) and \(\bm{w}^{\star}_{\widetilde{\mu}}\) as defined in (22) and \(\bm{w}\in W\). For any \(\alpha\in\left(0,\frac{1}{M+\widetilde{\mu}}\right]\), we have_

\[\left\lVert\bm{G}_{F,\alpha}(\bm{w})\right\rVert\leqslant\sum_{j=1}^{J}\mu_{j }\left\lVert\bm{w}^{\star}_{\widetilde{\mu}}-\widehat{\bm{w}}_{j}\right\rVert+ 3\left\lVert\bm{G}_{F_{\widetilde{\mu}},\alpha}(\bm{w})\right\rVert\,.\]

**Claim C.1**.: _(Allen-Zhu, 2021, Claim 6.2) Suppose for every \(j=1,\ldots,J\) the iterates \(\widehat{\bm{w}}_{j}\) of Algorithm 4 satisfy_

\[\mathbf{E}\left[F^{(j-1)}\left(\widehat{\bm{w}}_{j}\right)-F^{(j-1)}\left( \bm{w}^{\star}_{j-1}\right)\right]\leqslant\delta_{j}\quad\text{ where }\quad\bm{w}^{\star}_{j-1}\in\operatorname*{arg\,min}_{\bm{w}}\,\left\{F^{(j- 1)}(\bm{w})\right\},\]

_then,_

1. _for every_ \(j\geqslant 1\) _we have_ \(\mathbf{E}\left[\left\lVert\widehat{\bm{w}}_{j}-\bm{w}^{\star}_{j-1}\right\rVert \right]^{2}\leqslant\mathbf{E}\left[\left\lVert\widehat{\bm{w}}_{j}-\bm{w}^{ \star}_{j-1}\right\rVert^{2}\right]\leqslant\frac{\delta_{j}}{\mu_{j-1}}\)_;_
2. _for every_ \(j\geqslant 1\) _we have_ \(\mathbf{E}\left[\left\lVert\widehat{\bm{w}}_{j}-\bm{w}^{\star}_{j}\right\rVert \right]^{2}\leqslant\mathbf{E}\left[\left\lVert\widehat{\bm{w}}_{j}-\bm{w}^{ \star}_{j}\right\rVert^{2}\right]\leqslant\frac{\delta_{j}}{\mu_{j}}\)_;_
3. _if_ \(\mu_{j}=2\mu_{j-1}\)_, then for all_ \(j\geqslant 1\) _we have_ \(\mathbf{E}\left[\sum_{j=1}^{J}\mu_{j}\left\lVert\widehat{\bm{w}}_{j}-\bm{w}^{ \star}_{j}\right\rVert\right]\leqslant 4\sum_{j=1}^{J}\sqrt{\delta_{j}\mu_{j}}\)_._

In addition to Claim C.1, we prove the following lemma.

**Lemma C.4**.: _Suppose for every \(j=1,\ldots,J\), \(\mu_{j}=2\mu_{j-1}\) and the iterates \(\widehat{\bm{w}}_{j}\) of Algorithm 4 satisfy_

\[\mathbf{E}\left[F^{(j-1)}\left(\widehat{\bm{w}}_{j}\right)-F^{(j-1)}\left(\bm{ w}^{\star}_{j-1}\right)\right]\leqslant\delta_{j}\quad\text{ where }\quad\bm{w}^{\star}_{j-1}\in\operatorname*{arg\,min}_{\bm{w}}\,\left\{F^{(j-1)}(\bm{w}) \right\},\]

_then,_

\[\mathbf{E}\left[\left(\sum_{j=1}^{J}\mu_{j}\left\lVert\bm{w}^{\star}_{j}- \widehat{\bm{w}}_{j}\right\rVert\right)^{2}\right]\leqslant 16J\sum_{j=1}^{J}\mu_{j}\delta_{j}\,.\]

Proof.: Let \(P_{j}\stackrel{{\mathrm{def}}}{{=}}\sum_{t=1}^{j}\mu_{t}\left\lVert \bm{w}^{\star}_{j}-\widehat{\bm{w}}_{t}\right\rVert\), yielding that \(P_{J}=\sum_{j=1}^{J}(P_{j}-P_{j-1})\), with the agreement that \(P_{0}=0\). Cauchy-Schwartz inequality gives

\[P_{J}^{2}=\left(\sum_{j=1}^{J}(P_{j}-P_{j-1})\right)^{2}\leqslant J\sum_{j=1}^{J }(P_{j}-P_{j-1})^{2}\,.\] (23)

Since \(P_{j}\) is non-decreasing, to bound the above quantity, it suffices to bound each increment of the form \(P_{j}-P_{j-1}\). One can write

\[P_{j}-P_{j-1} \stackrel{{(a)}}{{\leqslant}}\mu_{j}\left\lVert \bm{w}^{\star}_{j}-\widehat{\bm{w}}_{j}\right\rVert+\sum_{t=1}^{j-1}\mu_{t}( \left\lVert\bm{w}^{\star}_{j}-\widehat{\bm{w}}_{t}\right\rVert-\left\lVert\bm {w}^{\star}_{j-1}-\widehat{\bm{w}}_{t}\right\rVert)\] \[\stackrel{{(b)}}{{\leqslant}}\mu_{j}\left\lVert \bm{w}^{\star}_{j}-\widehat{\bm{w}}_{j}\right\rVert+\left(\sum_{t=1}^{j-1}\mu_{t} \right)\left\lVert\bm{w}^{\star}_{j}-\bm{w}^{\star}_{j-1}\right\rVert\] \[\stackrel{{(c)}}{{\leqslant}}\mu_{j}(2\left\lVert \bm{w}^{\star}_{j}-\widehat{\bm{w}}_{j}\right\rVert+\left\lVert\bm{w}^{\star}_{j-1 }-\widehat{\bm{w}}_{j}\right\rVert)\,,\]where (a) follows from the definition of \(P_{j}\), (b) from reverse triangle inequality and (c) uses triangle inequality and the fact that \(\sum_{i=1}^{j-1}\mu_{t}\leqslant\mu_{j}\) as \(\mu_{j}=2\mu_{j-1}\). Therefore, using the fact that \((a+b)^{2}\leqslant 2a^{2}+2b^{2}\), we deduce from the above that

\[(P_{j}-P_{j-1})^{2}\leqslant 2\mu_{j}^{2}(4\left\lVert\bm{w}_{j}^{\star}- \widehat{\bm{w}}_{j}\right\rVert^{2}+\left\lVert\bm{w}_{j-1}^{\star}-\widehat {\bm{w}}_{j}\right\rVert^{2})\,.\]

Taking the expectation and applying Claim C.1(a) and Claim C.1(b), the latter is bounded as

\[\mathbf{E}\left[(P_{j}-P_{j-1})^{2}\right]\leqslant 8\mu_{j}^{2} \mathbf{E}[\left\lVert\bm{w}_{j}^{\star}-\widehat{\bm{w}}_{j}\right\rVert^{2} ]+2\mu_{j}^{2}\mathbf{E}[\left\lVert\bm{w}_{j-1}^{\star}-\widehat{\bm{w}}_{j} \right\rVert^{2}]\leqslant 8\mu_{j}^{2}\frac{\delta_{j}}{\mu_{j}}+2\mu_{j}^{2} \frac{2\delta_{j}}{\mu_{j-1}}=16\mu_{j}\delta_{j}\,.\] (24)

Plugging (24) into (23) yields the claimed bound. 

**Remark C.2**.: _Notice, that in Algorithm 4 we apply \(\mathsf{AC}\)-\(\mathsf{SA}^{2}\) to \(F^{(j-1)}\) with starting point \(\widehat{\bm{w}}_{j-1}\) and \(T/J\) iterations. Since \(F^{(j-1)}\) is \(M+\sum_{t=1}^{j-1}\mu_{t}\leqslant 2M-\)smooth and \(\mu_{j}-\)strongly convex, applying Lemma C.1 and Claim C.1(b), we get \(\mathbf{E}\left[F^{(j-1)}\left(\widehat{\bm{w}}_{j}\right)-F^{(j-1)}\left(\bm {w}_{j-1}^{\star}\right)\right]\leqslant\delta_{j}\) and_

\[\delta_{j} \leqslant\frac{128(2M)^{2}\mathbf{E}\left\lVert\widehat{\bm{w}}_ {j-1}-\bm{w}_{j-1}^{\star}\right\rVert^{2}}{\mu_{j-1}(T/J)^{4}}+\frac{256(2M) \sigma^{2}}{\mu_{j-1}^{2}(T/J)^{3}}+\frac{16\sigma^{2}}{\mu_{j-1}(T/J)}\] \[\leqslant\frac{2^{9}M^{2}\delta_{j-1}}{\mu_{j-1}^{2}(T/J)^{4}}+ \frac{2^{9}M\sigma^{2}}{\mu_{j-1}^{2}(T/J)^{3}}+\frac{2^{4}\sigma^{2}}{\mu_{j -1}(T/J)}\,.\]

We are in position to prove the main ingredient of this section.

**Theorem C.2** (Control of the expected squared norm).: _Let \(\bm{w}^{\star}\in\arg\min_{\bm{w}\in W}F(\bm{w})\), \(\bm{w}_{0}\in\mathbb{R}^{d}\) a starting vector. When \(\mu\in(0,M]\) and \(T>2^{11/4}\sqrt{\frac{M}{\mu}}\left\lvert\log_{2}\frac{M}{\mu}\right\rvert\), then for \(\alpha=\frac{1}{2^{J+2}\mu}\), with \(J=\left\lvert\log_{2}\frac{M}{\mu}\right\rvert\), \(\mathsf{SGD3-refined}(F,\bm{w}_{0},\mu,M,T)\) outputs \(\widehat{\bm{w}}\) satisfying_

\[\mathbf{E}\left[\left\lVert\bm{G}_{F,\alpha}(\widehat{\bm{w}}) \right\rVert^{2}\right] \leqslant\left(\frac{3^{4}\cdot 2^{16}M^{2}}{T^{4}}\log_{2}^{5} \frac{M}{\mu}+2\mu^{2}\right)\left\lVert\bm{w}_{0}-\bm{w}_{\mu}^{\star} \right\rVert^{2}\] \[+\frac{3^{4}\cdot 2^{17}M\sigma^{2}}{\mu T^{3}}\log_{2}^{4} \frac{M}{\mu}+\frac{3^{4}\cdot 2^{11}\sigma^{2}}{T}\log_{2}^{3}\frac{M}{\mu}\,.\]

Proof.: **Part I.** At first, let us assume that \(F\) is \(\mu_{0}\)-strongly convex. Since the definition of \(F\) satisfies the definition given in (22) with \(J-1\), applying Lemma C.3 and using the fact that \((a+b)^{2}\leqslant 2a^{2}+2b^{2}\), we get that for any \(\alpha\in\left(0,(M+\sum_{j=1}^{J-1}\mu_{j})^{-1}\right]\), it holds that

\[\mathbf{E}\left[\left\lVert\bm{G}_{F,\alpha}(\widehat{\bm{w}}_{J })\right\rVert^{2}\right] \leqslant\mathbf{E}\left[\left(3\left\lVert\bm{G}_{F^{(J-1)}, \alpha}(\widehat{\bm{w}}_{J})\right\rVert+\sum_{j=1}^{J-1}\mu_{j}\left\lVert\bm {w}_{J-1}^{\star}-\widehat{\bm{w}}_{j}\right\rVert\right)^{2}\right]\] \[\leqslant 2\mathbf{E}\left[9\left\lVert\bm{G}_{F^{(J-1)},\alpha}( \widehat{\bm{w}}_{J})\right\rVert^{2}+\left(\sum_{j=1}^{J-1}\mu_{j}\left\lVert \bm{w}_{J-1}^{\star}-\widehat{\bm{w}}_{j}\right\rVert\right)^{2}\right]\,.\] (25)

Note, that due to definition of \(\mu_{j}\), we have \(\sum_{j=1}^{J-1}\mu_{j}\leqslant M\), thus, the derived inequality holds for any \(\alpha\in\left(0,(2M)^{-1}\right]\subset\left(0,(M+\sum_{j=1}^{J-1}\mu_{j})^{-1}\right]\). Lemma C.4 provides a control of the second term of (25). To control the first term, let us apply Lemma C.2 with \(F^{(J-1)}\) and \(\bm{w}=\bm{w}^{\prime}=\widehat{\bm{w}}_{J}\), getting \(\frac{\alpha}{2}\left\lVert\bm{G}_{F^{(J-1)},\alpha}(\widehat{\bm{w}}_{J}) \right\rVert^{2}\leqslant F^{(J-1)}(\widehat{\bm{w}}_{J})-F^{(J-1)}(\widehat{ \bm{w}}_{J}^{\star})\leqslant F^{(J-1)}(\widehat{\bm{w}}_{J})-F^{(J-1)}(\bm{w} _{J-1}^{\star}),\forall\alpha\in(0,\frac{1}{2M}]\). Meaning, that \(\left\lVert\bm{G}_{F^{(J-1)},\alpha}(\widehat{\bm{w}}_{J})\right\rVert^{2} \leqslant\frac{2\delta_{J}}{\alpha}\). Let us recall, that \(J=\left\lvert\log_{2}\frac{M}{\mu_{0}}\right\rvert\) and \(\mu_{J}=2^{J}\mu_{0}\leqslant M\leqslant 2\mu_{J}\). Hence, choosing \(\alpha=\frac{1}{4\mu_{J}}\) and substituting the derived bound into (25), we deduce that

\[\mathbf{E}\left[\left\lVert G_{F,\alpha}(\widehat{\bm{w}}_{J})\right\rVert^{2} \right]\leqslant\frac{36\delta_{J}}{\alpha}+32(J-1)\sum_{j=1}^{J-1}\mu_{j} \delta_{j}\leqslant 144J\sum_{j=1}^{J}\mu_{j}\delta_{j}\,.\]Now, let us substitute the bound on \(\delta_{j}\) from Remark C.2 and replicate the steps of Foster et al. (2019) to control the above. We get

\[\sum_{j=1}^{J}\mu_{j}\delta_{j} \leqslant\frac{2^{10}M^{2}\left\|\bm{w}_{0}-\bm{w}^{*}\right\|^{2} }{(T/J)^{4}}+\frac{2^{10}M\sigma^{2}}{\mu_{0}(T/J)^{3}}+\frac{2^{5}\sigma^{2}}{ (T/J)}+\sum_{j=2}^{J}\left(\frac{2^{10}M^{2}\delta_{j-1}}{\mu_{j-1}(T/J)^{4}}+ \frac{2^{10}M\sigma^{2}}{\mu_{j-1}(T/J)^{3}}+\frac{2^{5}\sigma^{2}}{(T/J)}\right)\] \[\leqslant\frac{2^{10}M^{2}\left\|\bm{w}_{0}-\bm{w}^{*}\right\|^{ 2}J^{4}}{T^{4}}+\frac{2^{10}M\sigma^{2}J^{3}}{\mu_{0}T^{3}}\sum_{j=1}^{J} \frac{1}{2^{j-1}}+\frac{2^{5}\sigma^{2}J^{2}}{T}+\frac{2^{10}M^{2}J^{4}}{T^{4 }}\sum_{j=2}^{J}\frac{\delta_{j-1}}{\mu_{j-1}}\] \[\leqslant\frac{2^{10}M^{2}\left\|\bm{w}_{0}-\bm{w}^{*}\right\|^{ 2}J^{4}}{T^{4}}+\frac{2^{11}M\sigma^{2}J^{3}}{\mu_{0}T^{3}}+\frac{2^{5}\sigma^ {2}J^{2}}{T}+\frac{2^{10}M^{2}J^{4}}{\mu_{0}^{2}T^{4}}\sum_{j=1}^{J}\mu_{j} \delta_{j}\,,\]

where the last inequality comes from the facts that \(\sum_{j=1}^{J}\frac{1}{2^{j-1}}\leqslant 2\) and \(\sum_{j=2}^{J}\frac{\delta_{j-1}}{\mu_{j-1}}\leqslant\sum_{j=1}^{J}\frac{ \delta_{j}}{\mu_{j}}\leqslant\frac{1}{\mu_{0}^{2}}\sum_{j=1}^{J}\mu_{j}\delta_ {j}\). Rearranging the terms and multiplying both sides by \(144J\), we get

\[144J\sum_{j=1}^{J}\mu_{j}\delta_{j}\leqslant\frac{9}{1-\frac{2^{10}M^{2}J^{4 }}{\mu_{0}^{2}T^{4}}}\left(\frac{2^{14}M^{2}\left\|\bm{w}_{0}-\bm{w}^{*}\right\| ^{2}J^{5}}{T^{4}}+\frac{2^{15}M\sigma^{2}J^{4}}{\mu_{0}T^{3}}+\frac{2^{9} \sigma^{2}J^{3}}{T}\right)\,.\]

Choosing \(T>2^{1/4}J\sqrt{\frac{M}{\mu_{0}}}\) ensures that \(\frac{1}{1-\frac{2^{10}M^{2}J^{4}}{\nu_{0}^{2}T^{4}}}\leqslant 2\). Finally, substituting the derived bounds and the value of \(J=\left\lfloor\log_{2}\frac{M}{\mu_{0}}\right\rfloor\), we conclude that

\[\mathbf{E}\left[\left\|\bm{G}_{F,\alpha}(\widehat{\bm{w}})\right\|^{2}\right] \leqslant\frac{9\cdot 2^{15}M^{2}\left\|\bm{w}_{0}-\bm{w}^{*}\right\|^{2}}{T^{4 }}\log_{2}^{5}\frac{M}{\mu_{0}}+\frac{9\cdot 2^{16}M\sigma^{2}}{\mu_{0}T^{3}} \log_{2}^{4}\frac{M}{\mu_{0}}+\frac{9\cdot 2^{10}\sigma^{2}}{T}\log_{2}^{ 3}\frac{M}{\mu_{0}}\,.\] (26)

**Part II.** When \(F\) is not strongly convex, let \(F_{\mu}(\bm{w})\stackrel{{\text{def}}}{{=}}F(\bm{w})+\frac{\mu}{2 }\left\|\bm{w}-\bm{w}_{0}\right\|^{2}\) and \(\bm{w}_{\mu}^{\star}\in\arg\min_{\bm{w}}\left\{F_{\mu}(\bm{w})\right\}\). Applying (26) and Lemma C.3 with \(J=1\) and \(\widehat{\bm{w}}_{1}=\bm{w}_{0}\), we get

\[\mathbf{E}\left[\left\|\bm{G}_{F,\alpha}(\widehat{\bm{w}})\right\|^{2}\right] \leqslant\left(\frac{3^{4}\cdot 2^{16}M^{2}}{T^{4}}\log_{2}^{5} \frac{M}{\mu}+2\mu^{2}\right)\left\|\bm{w}_{0}-\bm{w}_{\mu}^{*}\right\|^{2}\] \[\quad+\frac{3^{4}\cdot 2^{17}M\sigma^{2}}{\mu T^{3}}\log_{2}^{4} \frac{M}{\mu}+\frac{3^{4}\cdot 2^{11}\sigma^{2}}{T}\log_{2}^{3}\frac{M}{\mu}\,.\]

Since \(\frac{\mu}{2}\left\|\bm{w}^{*}-\bm{w}_{0}\right\|^{2}-\frac{\mu}{2}\left\|\bm{ w}_{\mu}^{*}-\bm{w}_{0}\right\|^{2}=(F_{\mu}(\bm{w}^{*})-F(\bm{w}^{*}))+(F(\bm{w}_{ \mu}^{*})-F_{\mu}(\bm{w}_{\mu}^{*}))\geqslant 0\), then \(\left\|\bm{w}_{\mu}^{\star}-\bm{w}_{0}\right\|^{2}\leqslant\left\|\bm{w}^{*}- \bm{w}_{0}\right\|^{2}\). The proof is concluded. 

**Remark C.3**.: _Notice, that in Algorithm 4 we apply AC-SA to \(F^{(j-1)}\) with starting point \(\widehat{\bm{w}}_{j-1}\) and \(T/J\) iterations. Since \(F^{(j-1)}\) is \(M+\sum_{t=1}^{j-1}\mu_{t}\leqslant 2M-\)smooth and \(\mu_{j-1}-\)strongly convex, applying Lemma C.1 and Claim C.1(b), we get \(\mathbf{E}\left[F^{(j-1)}\left(\widehat{\bm{w}}_{j}\right)-F^{(j-1)}\left(\bm{ w}_{j-1}^{*}\right)\right]\leqslant\delta_{j}\) and_

\[\delta_{j}\leqslant\frac{2(2M)\mathbf{E}\left\|\widehat{\bm{w}}_{j-1}-\bm{w}_{j-1 }^{*}\right\|^{2}}{(T/J)^{2}}+\frac{8\sigma^{2}}{\mu_{j-1}(T/J)}\leqslant\frac{ 4M\delta_{j-1}}{\mu_{j-1}(T/J)^{2}}+\frac{8\sigma^{2}}{\mu_{j-1}(T/J)}\,.\]

**Theorem C.3** (Control of the expected squared norm).: _Let \(\bm{w}^{*}\in\arg\min_{\bm{w}\in W}F(\bm{w})\), \(\bm{w}_{0}\in\mathbb{R}^{d}\) a starting vector. When \(\mu\in(0,M]\) and \(T>4\sqrt{\frac{M}{\mu}}\left\lfloor\log_{2}\frac{M}{\mu}\right\rfloor\), then for \(\alpha=\frac{1}{2^{J+2}\mu}\), with \(J=\left\lfloor\log_{2}\frac{M}{\mu}\right\rfloor\), SGD3-refined\(\!(F,\bm{w}_{0},\mu,M,T)\) with AC-SA outputs \(\widehat{\bm{w}}\) satisfying_

\[\mathbf{E}\left[\left\|\bm{G}_{F,\alpha}(\widehat{\bm{w}})\right\|^{2}\right] \leqslant\left(\frac{3^{4}2^{9}M\mu}{T^{2}}\log_{2}^{3}\frac{M}{\mu}+2\mu^ {2}\right)\left\|\bm{w}_{0}-\bm{w}^{*}\right\|^{2}+\frac{3^{4}2^{11}\sigma^{2} }{T}\log_{2}^{3}\frac{M}{\mu}\,.\]Proof.: **Part I.** At first, let us assume that \(F\) is \(\mu_{0}\)-strongly convex. Applying Lemma C.3 and using the fact that \((a+b)^{2}\leqslant 2a^{2}+2b^{2}\), we get

\[\mathbf{E}\left[\|\bm{G}_{F,\alpha}(\widehat{\bm{w}}_{J})\|^{2}\right] \leqslant\mathbf{E}\left[\left(3\left\|\bm{G}_{F^{(J-1)},\alpha}( \widehat{\bm{w}}_{J})\right\|+\sum_{j=1}^{J-1}\mu_{j}\left\|\bm{w}_{J-1}^{ \star}-\widehat{\bm{w}}_{j}\right\|\right)^{2}\right]\] \[\leqslant 2\mathbf{E}\left[9\left\|\bm{G}_{F^{(J-1)},\alpha}( \widehat{\bm{w}}_{J})\right\|^{2}+\left(\sum_{j=1}^{J-1}\mu_{j}\left\|\bm{w}_{ J-1}^{\star}-\widehat{\bm{w}}_{j}\right\|\right)^{2}\right]\,.\] (27)

Lemma C.4 provides a control of the second term of the above inequality. To control the first term, let us apply Lemma C.2 with \(F^{(J-1)}\) and \(\bm{w}=\bm{w}^{\prime}=\widehat{\bm{w}}_{J}\), getting \(\frac{\alpha}{2}\left\|\bm{G}_{F^{(J-1)},\alpha}(\widehat{\bm{w}}_{J})\right\| ^{2}\leqslant F^{(J-1)}(\widehat{\bm{w}}_{J})-F^{(J-1)}(\widehat{\bm{w}}_{J}^ {\star})\leqslant F^{(J-1)}(\widehat{\bm{w}}_{J})-F^{(J-1)}(\bm{w}_{J-1}^{ \star}),\forall\alpha\in(0,\frac{1}{2M}]\). Meaning, that \(\left\|\bm{G}_{F^{(J-1)},\alpha}(\widehat{\bm{w}}_{J})\right\|^{2}\leqslant \frac{2\delta_{J}}{\alpha}\). Let us recall, that \(J=\left\lfloor\log_{2}\frac{M}{\mu_{0}}\right\rfloor\) and \(\mu_{J}=2^{J}\mu_{0}\leqslant M\leqslant 2\mu_{J}\). Hence, choosing \(\alpha=\frac{1}{4\mu_{J}}\) and substituting the derived bound into (27), we deduce that

\[\mathbf{E}\left[\left\|G_{F,\alpha}(\widehat{\bm{w}}_{J})\right\|^{2}\right] \leqslant\frac{36\delta_{J}}{\alpha}+32(J-1)\sum_{j=1}^{J-1}\mu_{j}\delta_{j} \leqslant 144J\sum_{j=1}^{J}\mu_{j}\delta_{j}\,.\]

Let us substitute the bound on \(\delta_{j}\) from Remark C.2 to control the above. We get

\[\sum_{j=1}^{J}\mu_{j}\delta_{j} \leqslant\frac{4M\left\|\bm{w}_{0}-\bm{w}^{\star}\right\|^{2} \mu_{1}}{(T/J)^{2}}+\frac{8\sigma^{2}\mu_{1}}{(T/J)\mu_{0}}+\sum_{j=2}^{J} \left(\frac{8M\delta_{j-1}}{(T/J)^{2}}+\frac{16\sigma^{2}}{(T/J)}\right)\] \[\leqslant\frac{8M\mu_{0}\left\|\bm{w}_{0}-\bm{w}^{\star}\right\|^ {2}J^{2}}{T^{2}}+\frac{32\sigma^{2}J^{2}}{T}+\frac{8MJ^{2}}{T^{2}}\sum_{j=2}^{ J}\delta_{j-1}\] \[\leqslant\frac{8M\mu_{0}\left\|\bm{w}_{0}-\bm{w}^{\star}\right\|^ {2}J^{2}}{T^{2}}+\frac{32\sigma^{2}J^{2}}{T}+\frac{8MJ^{2}}{\mu_{0}T^{2}}\sum_{ j=2}^{J}\mu_{j-1}\delta_{j-1}\] \[\leqslant\frac{8M\mu_{0}\left\|\bm{w}_{0}-\bm{w}^{\star}\right\|^ {2}J^{2}}{T^{2}}+\frac{32\sigma^{2}J^{2}}{T}+\frac{8MJ^{2}}{\mu_{0}T^{2}}\sum_{ j=1}^{J}\mu_{j}\delta_{j}\,.\]

Rearranging the terms and multiplying both sides by \(144J\), we get

\[144J\sum_{j=1}^{J}\mu_{j}\delta_{j}\leqslant\frac{1152}{1-\frac{8MJ^{2}}{\mu _{0}T^{2}}}\left(\frac{M\mu_{0}\left\|\bm{w}_{0}-\bm{w}^{\star}\right\|^{2}J^ {3}}{T^{2}}+\frac{4\sigma^{2}J^{3}}{T}\right)\,.\]

Choosing \(T>4J\sqrt{\frac{M}{\mu_{0}}}\) ensures that \(\frac{1}{1-\frac{8MJ^{2}}{\mu_{0}T^{2}}}\leqslant 2\). Finally, substituting the derived bounds and the value of \(J=\left\lfloor\log_{2}\frac{M}{\mu_{0}}\right\rfloor\), we conclude that

\[\mathbf{E}\left[\left\|\bm{G}_{F,\alpha}(\widehat{\bm{w}}_{J})\right\|^{2} \right]\leqslant 2304\log_{2}^{3}\frac{M}{\mu_{0}}\left(\frac{M\mu_{0}\left\|\bm{ w}_{0}-\bm{w}^{\star}\right\|^{2}}{T^{2}}+\frac{4\sigma^{2}}{T}\right)\,.\] (28)

**Part II.** When \(F\) is not strongly convex, let \(F_{\mu}(\bm{w})\overset{\text{def}}{=}F(\bm{w})+\frac{\mu}{2}\left\|\bm{w}-\bm{ w}_{0}\right\|^{2}\) and \(\bm{w}_{\mu}^{\star}\in\operatorname*{arg\,min}_{\bm{w}}\left\{F_{\mu}(\bm{w})\right\}\). Applying (26) and Lemma C.3 with \(J=1\) and \(\widehat{\bm{w}}_{1}=\bm{w}_{0}\), we get

\[\mathbf{E}\left[\left\|\bm{G}_{F,\alpha}(\widehat{\bm{w}})\right\|^{2}\right] \leqslant\left(\frac{3^{4}2^{9}M\mu}{T^{2}}\log_{2}^{3}\frac{M}{\mu}+2\mu^{2} \right)\left\|\bm{w}_{0}-\bm{w}_{\mu}^{\star}\right\|^{2}+\frac{3^{4}2^{11} \sigma^{2}}{T}\log_{2}^{3}\frac{M}{\mu}\,.\]

Since \(\frac{\mu}{2}\left\|\bm{w}^{\star}-\bm{w}_{0}\right\|^{2}-\frac{\mu}{2}\left\| \bm{w}_{\mu}^{\star}-\bm{w}_{0}\right\|^{2}=(F_{\mu}(\bm{w}^{\star})-F(\bm{w}^{ \star}))+(F(\bm{w}_{\mu}^{\star})-F_{\mu}(\bm{w}_{\mu}^{\star}))\geqslant 0\), then \(\left\|\bm{w}_{\mu}^{\star}-\bm{w}_{0}\right\|^{2}\leqslant\left\|\bm{w}^{ \star}-\bm{w}_{0}\right\|^{2}\). The proof is concluded.

Proofs of statistical guarantees

In order to derive statistical guarantees for the proposed method, we are going to instantiate the extension provided in the previous appendix.

Proof of Theorem 5.1.: Let us instantiate Theorem C.2. According to Lemma 4.1 and Lemma 3.4 we have that \(\sigma^{2}=2\sum_{s\in[S]}\frac{1-p_{s}}{p_{s}}\) and \(M=\beta\sigma^{2}\). Setting \(\beta=\frac{T}{8\log_{2}T}\) and \(\mu=\sigma^{2}/\beta\), ensures that \(\mu\leqslant M\) and that \(T>4\sqrt{\frac{M}{\mu}}\left\lfloor\log_{2}\frac{M}{\mu}\right\rfloor=\frac{T} {\log_{2}T}\left\lfloor\log_{2}\frac{T}{8\log_{2}T}\right\rfloor\),\(\forall T\geqslant 2\). For \(T\) larger than some large enough absolute constant, the conditions of Theorem C.2 are satisfied for the function \(F\).

**Fairness guarantee.** Theorem C.2 yields

\[\mathbf{E}\left[\left\|\bm{G}_{F,\alpha}(\widehat{\bm{w}})\right\| ^{2}\right]\] \[+\frac{3^{4}2^{11}\sigma^{2}}{T\log_{2}^{2}T}\log_{2}^{4}\frac{T^ {2}}{64\log_{2}^{2}T}+\frac{3^{4}2^{11}\sigma^{2}}{T}\log_{2}^{3}\frac{T^{2}}{ 64\log_{2}^{2}T}\,.\]

Therefore, we have shown that

\[\mathbf{E}\left[\left\|\bm{G}_{\alpha}(\widehat{\bm{\Lambda}}, \widehat{\bm{\nabla}})\right\|^{2}\right]\leqslant\widetilde{\mathcal{O}} \left(\frac{\sigma^{2}}{T}\left(1+\frac{\sigma^{2}}{T}\left\|(\bm{\Lambda}^{ \star},\mathbf{V}^{\star})\right\|^{2}\right)\right)\] (29)

Hence, the first part of Lemma 3.5 implies the fairness guarantee.

**Fairness guarantee with AC-SA.** Theorem C.3 yields

\[\mathbf{E}\left[\left\|\bm{G}_{F,\alpha}(\widehat{\bm{w}})\right\| ^{2}\right]\] \[+\frac{3^{4}2^{11}\sigma^{2}}{T}\log_{2}^{3}\frac{T^{2}}{64\log_ {2}^{2}T}\,.\]

Therefore, we have shown that

\[\mathbf{E}\left[\left\|\bm{G}_{\alpha}(\widehat{\bm{\Lambda}}, \widehat{\bm{\nabla}})\right\|^{2}\right]\] (30)

Hence, the first part of Lemma 3.5 implies the fairness guarantee.

**Risk guarantee.** The second part of Lemma 3.5 states that

\[\mathcal{R}(\pi_{\widehat{\bm{\Lambda}},\widehat{\bm{\nabla}}})-\mathcal{R}( \pi_{\bm{\Lambda}^{\star},\mathbf{V}^{\star}})\leqslant\left(\left\|( \widehat{\bm{\Lambda}},\widehat{\bm{\nabla}})\right\|+\alpha\sigma+\alpha \left\|\bm{\varepsilon}\right\|\sqrt{2(2L+1)}\right)\cdot\left\|\bm{G}_{ \alpha}(\widehat{\bm{\Lambda}},\widehat{\bm{\nabla}})\right\|+\frac{\log(2L+1 )}{\beta}\,.\]

Taking the expectation and applying the Cauchy-Schwartz inequality, we obtain

\[\mathbf{E}\left[\mathcal{R}(\pi_{\widehat{\bm{\Lambda}},\widehat {\bm{\nabla}}})\right]-\mathcal{R}(\pi_{\bm{\Lambda}^{\star},\mathbf{V}^{ \star}}) \leqslant\left(\sqrt{\mathbf{E}\left[\left\|(\widehat{\bm{\Lambda}},\widehat{\bm{\nabla}})\right\|^{2}\right]}+\alpha\sigma+\alpha\left\|\bm{ \varepsilon}\right\|\sqrt{2(2L+1)}\right)\] \[\cdot\sqrt{\mathbf{E}\left[\left\|\bm{G}_{\alpha}(\widehat{\bm{ \Lambda}},\widehat{\bm{\nabla}})\right\|^{2}\right]}+\frac{\log(2L+1)}{\sqrt{T }}\,.\]

Recalling the value of \(\alpha=\frac{1}{2^{J+2}\mu_{J}}\leqslant\frac{1}{2M}\) from Theorems C.2 and C.3 and the fact that \(M=\beta\sigma^{2}\), we get \(\alpha\sigma\leqslant\frac{1}{2\beta\sigma}\). Finally, applying (29)-(30) and setting \(L=\sqrt{T}\), we obtain

\[\mathbf{E}\left[\mathcal{R}(\pi_{\widehat{\bm{\Lambda}},\widehat{ \bm{\nabla}}})\right]-\mathcal{R}(\pi_{\bm{\Lambda}^{\star},\mathbf{V}^{\star}})\] \[\leqslant\widetilde{\mathcal{O}}\left(\frac{\sigma}{\sqrt{T}} \left(1+\frac{\sigma}{\sqrt{T}}\left\|(\bm{\Lambda}^{\star},\mathbf{V}^{\star} )\right\|\right)\left(\mathbf{E}^{\sfrac{1}{2}}\left[\left\|(\widehat{\bm{ \Lambda}},\widehat{\bm{\nabla}})\right\|^{2}\right]+\frac{1}{T\sigma}+\frac{ \left\|\bm{\varepsilon}\right\|}{T^{3/4}\sigma}\right)+\frac{\log(\sqrt{T})}{ \sqrt{T}}\right)\,.\]

Above combined with Lemma B.1 yields the claimed bound.

Unknown \(\eta\) and \(\tau\)

In this section we consider the case, when \(\eta\) and \(\tau\) are unknown and estimated by \(\widehat{\eta}\) and \(\widehat{\tau}\). We denote by \(\widehat{\bm{\mathcal{U}}}(\bm{x})\stackrel{{\text{def}}}{{=}}1- \frac{\widehat{\bm{\nu}}(\bm{x})}{\bm{p}}\) and \(\widehat{r}_{\ell}(\bm{x})\stackrel{{\text{def}}}{{=}}\left( \widehat{\eta}(\bm{x})-\frac{\ell B}{L}\right)^{2}\). We consider the plug-in version of (5), defined as

\[\min_{\bm{\Lambda},\mathbf{V}\geqslant 0}\left\{\mathbb{E}_{\bm{X}}\left[ \operatorname{LSE}_{\beta}\left(\left(\left\langle\bm{\lambda}_{\ell}-\bm{ \nu}_{\ell},\,\widehat{\bm{\mathcal{U}}}(\bm{X})\right\rangle-\widehat{r}_{ \ell}(\bm{X})\right\rangle_{\ell=-L}^{L}\right)\right]+\sum_{\ell=-L}^{L} \left\langle\bm{\lambda}_{\ell}+\bm{\nu}_{\ell},\,\bm{\varepsilon}\right\rangle \right\}\,.\] ( \[\widehat{\bm{\mathcal{P}}}_{LSE}\] )

Let us denote by \(\widehat{F}\), the objective function of the above problem and introduce

\[\widehat{\bm{\mathcal{R}}}_{\beta}(\pi)\stackrel{{\text{def}}}{{= }}\mathbb{E}_{\bm{X}}\left[\sum_{\ell\in[\![L]\!]}\widehat{r}_{\ell}(\bm{X}) \pi(\ell\mid\bm{X})+\frac{1}{\beta}\Psi(\pi(\cdot\mid\bm{X}))\right]\,.\]

The gradient of \(\widehat{F}\) is given for any \(\bm{\Lambda},\mathbf{V}\geqslant 0\) by

\[\begin{split}\nabla_{\lambda_{\ell s}}\widehat{F}(\bm{\Lambda}, \mathbf{V})&=\mathbb{E}_{\bm{X}}\left[\sigma_{\ell}\left(\beta \left(\left\langle\bm{\lambda}_{\ell^{\prime}}-\bm{\nu}_{\ell^{\prime}},\, \widehat{\bm{\mathcal{U}}}(\bm{X})\right\rangle-\widehat{r}_{\ell^{\prime}}( \bm{X})\right)_{\ell^{\prime}=-L}^{L}\right)\widehat{t}_{s}(\bm{X})\right]+ \varepsilon_{s}\,,\\ \nabla_{\nu_{\ell s}}\widehat{F}(\bm{\Lambda},\mathbf{V})& =-\mathbb{E}_{\bm{X}}\left[\sigma_{\ell}\left(\beta\left(\left\langle\bm{ \lambda}_{\ell^{\prime}}-\bm{\nu}_{\ell^{\prime}},\,\widehat{\bm{\mathcal{U}} }(\bm{X})\right\rangle-\widehat{r}_{\ell^{\prime}}(\bm{X})\right)_{\ell^{ \prime}=-L}^{L}\right)\widehat{t}_{s}(\bm{X})\right]+\varepsilon_{s}\,,\end{split}\] (31)

for \(\ell\in[\![L]\!],s\in[K]\). Let us denote by \(\widehat{\bm{g}}(\bm{\Lambda},\mathbf{V})\) the stochastic gradient of \(\widehat{F}\), defined as

\[\begin{split}\widehat{g}_{\lambda_{\ell s}}(\bm{\Lambda}, \mathbf{V})&=\sigma_{\ell}\left(\beta\left(\left\langle\bm{ \lambda}_{\ell^{\prime}}-\bm{\nu}_{\ell^{\prime}},\,\widehat{\bm{\mathcal{U}} }(\bm{X})\right\rangle-\widehat{r}_{\ell^{\prime}}(\bm{X})\right)_{\ell^{ \prime}=-L}^{L}\right)\widehat{t}_{s}(\bm{X})+\varepsilon_{s}\,,\\ \widehat{g}_{\nu_{\ell s}}(\bm{\Lambda},\mathbf{V})&=- \sigma_{\ell}\left(\beta\left(\left\langle\bm{\lambda}_{\ell^{\prime}}-\bm{ \nu}_{\ell^{\prime}},\,\widehat{\bm{\mathcal{U}}}(\bm{X})\right\rangle- \widehat{r}_{\ell^{\prime}}(\bm{X})\right)_{\ell^{\prime}=-L}^{L}\right) \widehat{t}_{s}(\bm{X})+\varepsilon_{s}\,,\end{split}\] (32)

for \(\bm{X}\sim\mathbb{P}_{\bm{X}}\) and \(\ell\in[\![L]\!],s\in[K]\). We also define, by the analogy with the main body, a family of plug-in estimators

\[\widehat{\pi}_{\bm{\Lambda},\mathbf{V}}(\ell\mid\bm{x})\stackrel{{ \text{def}}}{{=}}\sigma_{\ell}\left(\beta\left(\left\langle\bm{\lambda}_{ \ell}-\bm{\nu}_{\ell},\,\widehat{\bm{\mathcal{U}}}(\bm{x})\right\rangle- \widehat{r}_{\ell}(\bm{x})\right)_{\ell=-L}^{L}\right)\qquad\bm{\Lambda}, \mathbf{V}\geqslant 0\,.\] (33)

Our goal is to derive analogous optimization results for the new plug-in objective. Inspecting the proofs of Lemma 4.1 and Lemma 3.4, which bound variance of and the Lipschitz constant of the gradient respectively, we observe that those proofs only depend on the nature of \(\widehat{\bm{\mathcal{U}}}\) via Lemma F.4. In particular, the key quantity to control is

\[\widehat{\sigma}^{2}=2\sum_{s\in[K]}\frac{\mathbb{E}_{\bm{X}}(p_{s}-\widehat{ \tau}_{s}(\bm{X}))^{2}}{p_{s}^{2}}\,.\]

Before, when we assumed the perfect knowledge of \(\tau\), the above was controlled by the Bhatia-Davis inequality, leveraging the fact that variance of \(\tau_{s}(\bm{X})\) appears in the numerator. It is no longer the case here. However, if one can build calibrated estimators, that is, estimators for which \(\mathbb{E}_{\bm{X}}[\widehat{\tau}_{s}(\bm{X})]=p_{s}\), the same machinery is applicable. In any case, even without requiring calibrated predictions, one can have a reasonable control of \(\widehat{\sigma}^{2}\) building sufficiently accurate estimator \(\widehat{\tau}_{s}\).

That being said, results of Lemma 4.1 and Lemma 3.4 generalize line-by-line, replacing \(\sigma^{2}\) by \(\widehat{\sigma}^{2}\) and give

\[\sup_{\bm{\Lambda},\mathbf{V}\geqslant 0}\mathbb{E}_{\bm{X}}\left\|\widehat{g}_{\bm{ \Lambda},\mathbf{V}}(\bm{X})-\nabla_{\bm{\Lambda},\mathbf{V}}\widehat{F}\left( \bm{\Lambda},\mathbf{V}\right)\right\|^{2}\leqslant\widehat{\sigma}^{2}\quad \text{and}\quad\sup_{\bm{\Lambda},\mathbf{V}}\left\|\nabla^{2}\widehat{F}(\bm{ \Lambda},\mathbf{V})\right\|_{\mathrm{op}}\leqslant\beta\widehat{\sigma}^{2}\,.\]

Moreover, the result of Lemma F.5 generalizes as well and gives \(\sup_{\bm{\Lambda},\mathbf{V}\geqslant 0}\left\|\nabla_{\bm{\Lambda},\mathbf{V}} \widehat{F}\left(\bm{\Lambda},\mathbf{V}\right)\right\|\leqslant\widehat{\sigma}\).

As in (19), we can show that

\[\left\|\left(-\nabla\widehat{F}(\bm{\Lambda},\mathbf{V})\right)_{+}\right\| \leqslant\left\|\bm{G}_{\widehat{F},\alpha}(\bm{\Lambda},\mathbf{V})\right\| \qquad\forall\bm{\Lambda},\mathbf{V}\geqslant 0\,,\] (34)

where the gradient mapping \(\bm{G}_{\widehat{F},\alpha}\) is defined by analogy with \(\bm{G}_{\alpha}=\bm{G}_{F,\alpha}\), discussed in the main body.

Considering the SGD3 algorithm with the same choice of parameters, but replacing \(\sigma^{2}\) by \(\widehat{\sigma}^{2}\), results in a control of \(\left\|\bm{G}_{\widehat{F},\alpha}(\widehat{\bm{\Lambda}},\widehat{\mathbf{V}})\right\|\).

Proof of Lemma 5.1.: Fix \(\mathbf{\Lambda},\mathbf{V}\geqslant 0\). To ease the notation, we write \(\widehat{\pi}\) to denote \(\widehat{\pi}_{\mathbf{\Lambda},\mathbf{V}}\) within this proof. Similarly to the proof of (21) from Lemma 3.5, one shows that for all \(\mathbf{\Lambda},\mathbf{V}\geqslant 0\)

Recalling that \(\mathcal{U}_{s}(\widehat{\pi},\ell)=\left\|\mathbb{E}\left[\widehat{\pi}(\ell \mid\boldsymbol{X})t_{s}(\boldsymbol{X})\right]\right|\), triangle's inequality combined with the above yields

\[\sqrt{\sum_{\ell\in[L]s\in[K]}\left(\mathcal{U}_{s}(\widehat{\pi},\ell)- \varepsilon_{s}\right)_{+}^{2}}\leqslant\left\|(-\nabla\widehat{F}(\mathbf{ \Lambda},\mathbf{V}))_{+}\right\|+\sqrt{\sum_{\ell\in[L]s\in[K]}\left\{\mathbb{ E}[\widehat{\pi}(\ell\mid\boldsymbol{X})|\widehat{t}_{s}(\boldsymbol{X})-t_{s}( \boldsymbol{X})|]\right\}^{2}}\,.\]

Cauchy-Schwartz inequality gives

\[\sum_{\ell\in[\![L]\!]s\in[K]}\left\{\mathbb{E}[\widehat{\pi}(\ell\mid \boldsymbol{X})|\widehat{t}_{s}(\boldsymbol{X})-t_{s}(\boldsymbol{X})|] \right\}^{2}\leqslant\sum_{s\in[K]}\mathbb{E}\left[\left(\sum_{\ell\in[\![L] \!]}\widehat{\pi}(\ell\mid\boldsymbol{X})^{2}\right)|\widehat{t}_{s}( \boldsymbol{X})-t_{s}(\boldsymbol{X})|^{2}\right]\,.\]

Since \(\sum_{\ell\in[\![L]\!]}\widehat{\pi}(\ell\mid\boldsymbol{X})=1\), then \(\sum_{\ell\in[\![L]\!]}\widehat{\pi}(\ell\mid\boldsymbol{X})^{2}\leqslant 1\). Thus, we have shown that

\[\sqrt{\sum_{\ell\in[\![L]\!]s\in[K]}\left(\mathcal{U}_{s}(\widehat{\pi}_{ \mathbf{\Lambda},\mathbf{V}},\ell)-\varepsilon_{s}\right)_{+}^{2}}\leqslant \left\|\left(-\nabla\widehat{F}(\mathbf{\Lambda},\mathbf{V})\right)_{+} \right\|+\mathbb{E}^{\nicefrac{{1}}{{2}}}\|\widehat{t}(\boldsymbol{X})-t( \boldsymbol{X})\|^{2}\,.\]

We conclude using (34). 

Proof of Lemma 5.2.: Fix \(\mathbf{\Lambda},\mathbf{V}\geqslant 0\). To ease the notation, we write \(\widehat{\pi}\stackrel{{\text{def}}}{{=}}\widehat{\pi}_{ \mathbf{\Lambda},\mathbf{V}}\) and \(\pi^{\star}\stackrel{{\text{def}}}{{=}}\pi_{\mathbf{\Lambda}^{ \star},\mathbf{V}^{\star}}\), within this proof.

As in the second part of the proof of Lemma 3.5, we have

\[\widehat{\mathcal{R}}_{\beta}(\widehat{\pi})+\widehat{F}(\mathbf{\Lambda}, \mathbf{V})\leqslant\left(\left\|(\mathbf{\Lambda},\mathbf{V})\right\|+ \alpha\widehat{\sigma}+\alpha\left\|\varepsilon\right\|\sqrt{2(2L+1)}\right) \left\|\boldsymbol{G}_{\widehat{P},\alpha}(\mathbf{\Lambda},\mathbf{V}) \right\|\,.\] (35)

Furthermore, since \(\|\nabla\operatorname{LSE}_{\beta}(\cdot)\|_{1}\equiv 1\), we have

\[\left|\widehat{F}(\mathbf{\Lambda},\mathbf{V})-F(\mathbf{\Lambda},\mathbf{V}) \right|\leqslant\mathbb{E}\left[\max_{\ell\in[\![L]\!]}\left\{\left|r_{\ell}( \boldsymbol{X})-\widehat{r}_{\ell}(\boldsymbol{X})\right|+\left\|\boldsymbol{ \lambda}_{\ell}-\boldsymbol{\nu}_{\ell}\right\|\left\|t(\boldsymbol{X})- \widehat{t}(\boldsymbol{X})\right\|\right\}\right]\,,\]

and \(\left|\widehat{\mathcal{R}}_{\beta}(\widehat{\pi})-\mathcal{R}_{\beta}( \widehat{\pi})\right|\leqslant\mathbb{E}[\max_{\ell\in[\![L]\!]}\left\{\left|r _{\ell}(\boldsymbol{X})-\widehat{r}_{\ell}(\boldsymbol{X})\right|\right\}]\). The last two displays combined with (35), gives

\[\mathcal{R}_{\beta}(\widehat{\pi})+F(\mathbf{\Lambda},\mathbf{V}) \leqslant\mathbb{E}\left[2\max_{\ell\in[\![L]\!]}\left\{\left|r_{ \ell}(\boldsymbol{X})-\widehat{r}_{\ell}(\boldsymbol{X})\right|+\left\| \boldsymbol{\lambda}_{\ell}-\boldsymbol{\nu}_{\ell}\right\|\left\|t( \boldsymbol{X})-\widehat{t}(\boldsymbol{X})\right\|\right\}\right]\] \[\quad+\left(\left\|(\mathbf{\Lambda},\mathbf{V})\right\|+\alpha \widehat{\sigma}+\alpha\left\|\varepsilon\right\|\sqrt{2(2L+1)}\right)\left\| \boldsymbol{G}_{\widehat{P},\alpha}(\mathbf{\Lambda},\mathbf{V})\right\|\,.\]

Observe that \(\min_{\mathbf{\Lambda},\mathbf{V}\geqslant 0}F(\mathbf{\Lambda},\mathbf{V})=- \mathcal{R}_{\beta}(\pi^{\star})\). Using triangle's inequality and the fact that \(\max_{\ell\in[\![L]\!]}\left\|\boldsymbol{\lambda}_{\ell}-\boldsymbol{\nu}_{ \ell}\right\|\leqslant\sqrt{2}\|(\mathbf{\Lambda},\mathbf{V})\|\), we conclude recalling that \(\mathcal{R}(\pi)+\frac{\log(2L+1)}{\beta}\geqslant\mathcal{R}_{\beta}(\pi)\geqslant \mathcal{R}(\pi)\) for any randomized prediction function.

Auxilliary results

In this appendix, we collect some standard auxiliary results, that are used to derive main claims of the paper.

**Lemma F.1** (Boyd and Vandenberghe (2004)).: _It holds that_

\[\operatorname{LSE}_{\beta}(\bm{w})=\max_{\bm{p}\in\Delta}\left\{\langle\bm{w}, \,\bm{p}\rangle-\frac{1}{\beta}\Psi(\bm{p})\right\}\,,\]

_where \(\Delta\) is the probability simplex in \(\mathbb{R}^{m}\) and \(\Psi(\bm{p})=\sum_{i=1}^{m}p_{i}\log(p_{i})\). Furthermore, \(-\Psi(\bm{p})\in[0,\log(m)]\) and the optimum in the above optimization problem is achieved at \(\bm{p}^{\star}=\sigma(\beta\bm{w})\)._

**Lemma F.2** (Gao and Pavel (2017)).: _Let \(\bm{a}=(a_{1},\cdots,a_{m})\) and \(\beta>0\). Define log-sum-exp and softmax functions respectively as_

\[\operatorname{LSE}_{\beta}(\bm{a})\stackrel{{\text{def}}}{{=}} \frac{1}{\beta}\log\left(\sum_{i=1}^{m}\exp(\beta a_{i})\right)\text{ and }\sigma_{j}(\beta\bm{a})\stackrel{{\text{def}}}{{=}}\frac{\exp( \beta a_{j})}{\sum_{i=1}^{m}\exp(\beta a_{i})}\quad j\in[m]\,.\]

_The LSE property is as follows_

\[\max\{a_{1},\cdots,a_{m}\}\leqslant\operatorname{LSE}_{\beta}(\bm{a})\leqslant \max\{a_{1},\cdots,a_{m}\}+\frac{\log(m)}{\beta}\,.\]

_Moreover, \(\sigma(\beta\bm{a})=\nabla\operatorname{LSE}_{\beta}(\bm{a})\), and \(\sigma(\beta\bm{a})\) is \(\beta\)-Lipschitz._

**Lemma F.3** (Bhatia and Davis (2000)).: _Let \(m\) and \(M\) be the lower and upper bounds, respectively, for a set of real numbers \(a_{1},\cdots,a_{n}\), with a particular probability distribution. Let \(\mu\) and \(\sigma^{2}\) be respectively the expected value and the variance of this distribution. Then the Bhatia-Davis inequality states:_

\[\sigma^{2}\leqslant(M-\mu)(\mu-m)\,.\]

**Lemma F.4**.: _It holds that_

\[\mathbb{E}_{\bm{X}}\left[\sum_{s\in[K]}t_{s}^{2}(\bm{X})\right]\leqslant\sum_ {s\in[K]}\frac{1-p_{s}}{p_{s}}\,,\]

_where \(t_{s}(x)=1-\frac{\tau_{s}(x)}{p_{s}}\)._

Proof.: We have \(\mathbb{E}_{\bm{X}}[\tau_{s}(\bm{X})]=p_{s}\) and \(0\leqslant\tau_{s}(\bm{X})\leqslant 1\) almost surely. Using Bhatia-Davis inequality written in Lemma F.3, we deduce that

\[\mathbb{E}_{\bm{X}}\left[\sum_{s\in[K]}t_{s}^{2}(\bm{X})\right]=\sum_{s\in[K] }\operatorname{Var}\left(\frac{\tau_{s}(\bm{X})}{p_{s}}\right)=\sum_{s\in[K]} \frac{1}{p_{s}^{2}}\operatorname{Var}\left(\tau_{s}(\bm{X})\right)\leqslant \sum_{s\in[K]}\frac{1-p_{s}}{p_{s}}\,.\]

The proof is concluded. 

**Lemma F.5**.: _Let \(\sigma^{2}\stackrel{{\text{def}}}{{=}}2\sum_{s\in[K]}\frac{1-p_{ s}}{p_{s}}\). It holds that \(\left\|\nabla_{\bm{\Lambda},\bm{\mathrm{V}}}F(\bm{\Lambda},\bm{\mathrm{V}}) \right\|\leqslant\sigma+\sqrt{2(2L+1)}\left\|\bm{\varepsilon}\right\|\)._

Proof.: By Jensen's inequality

\[\left\|\nabla_{\bm{\Lambda},\bm{\mathrm{V}}}F(\bm{\Lambda},\bm{\mathrm{V}}) \right\|^{2}=\left\|\mathbb{E}_{\bm{X}}[g_{\bm{\Lambda},\bm{\mathrm{V}}}(\bm{ X})]\right\|^{2}\leqslant\mathbb{E}_{\bm{X}}[\left\|g_{\bm{\Lambda},\bm{ \mathrm{V}}}(\bm{X})\right\|^{2}]\,.\]

Recalling the definition of \(g_{\bm{\Lambda},\bm{\mathrm{V}}}\), given in (11), we have

\[\mathbb{E}_{\bm{X}}[\left\|g_{\bm{\Lambda},\bm{\mathrm{V}}}(\bm{X} )\right\|^{2}] =\mathbb{E}_{\bm{X}}\sum_{\ell\in[L]s\in[K]}\left((\sigma_{\ell}( \cdot)t_{s}(\bm{X})+\varepsilon_{s})^{2}+(-\sigma_{\ell}(\cdot)t_{s}(\bm{X})+ \varepsilon_{s})^{2}\right)\] \[=2\mathbb{E}_{\bm{X}}\sum_{\ell\in[L]s\in[K]}\left(\sigma_{\ell}^ {2}(\cdot)t_{s}^{2}(\bm{X})+\varepsilon_{s}^{2}\right)\leqslant\sigma^{2}+2(2 L+1)\left\|\bm{\varepsilon}\right\|^{2}\,,\]

where the last inequality comes from the proof of Lemma 4.1.

The proof is concluded.

Additional details on experiments

Evaluation measures.We use \(\mathcal{D}_{\mathrm{test}}=\{(\bm{x}_{i}^{\prime},s_{i}^{\prime},y_{i}^{\prime}) \}_{i=1}^{m}\) to collect the following statistics of any (randomized) prediction \(\pi\)

\[\widehat{\mathcal{R}}(\pi) \stackrel{{\text{def}}}{{=}}\frac{1}{m}\sum_{i=1}^{m }\int_{-\infty}^{+\infty}\left(\widehat{y}-y_{i}^{\prime}\right)^{2}\pi(\mathrm{ d}\,\widehat{y}\mid\bm{x}_{i}^{\prime})\,,\] \[\widehat{U}_{s}(\pi) \stackrel{{\text{def}}}{{=}}\sup_{t\in\mathbb{R}} \left|\frac{1}{m_{s}}\sum_{i=1}^{m}\int_{-\infty}^{t}\pi(\mathrm{d}\,\widehat{ y}\mid\bm{x}_{i}^{\prime})\mathbb{I}\{s_{i}^{\prime}=s\}-\frac{1}{m}\sum_{i=1}^{m }\int_{-\infty}^{t}\pi(\mathrm{d}\,\widehat{y}\mid\bm{x}_{i}^{\prime})\right|\,,\]

which correspond to the empirical risk and the empirical group-wise unfairness quantified by the Kolmogorov-Smirnov distance of a randomized. We note that our classifier is supported on a finite grid, thus all the integrals involved transform into weighted sums.

Agarwal et al. (2019) build multi-class classifiers \(h_{k}:\mathbb{R}^{d}\mapsto\Theta\), where \(\Theta\) is some finite grid over \(\mathbb{R}\) and \(k=1,\ldots,K\), that come with weights \((w_{1},\ldots,w_{K})^{\top}\) such that \(w_{k}\geqslant 0\) and \(\sum_{k=1}^{K}w_{k}=1\). Then, they build a randomized classifier \(\pi(\cdot\mid\cdot)\) such that \(\mathrm{supp}(\pi(\cdot\mid\bm{x}))=\Theta\) and for each \(\theta\in\Theta\)

\[\mathbb{P}(\widehat{Y}_{\pi}=\theta\mid\bm{X}=\bm{x})=\sum_{k=1}^{K}w_{k} \mathbb{I}\{h_{k}(\bm{x})=\theta\}\,.\]

Thus, integrals appearing in \(\widehat{\mathcal{R}}\) and \(\widehat{U}_{s}\) reduced to finite sums for both methods.

Additional details on the experiments on _Communities and Crime_ and _Law School_ datasets._Communities and Crime_ dataset has 1994 instances, however we use 1984 examples with 120 features after preprocessing. _Law School_ dataset has 20649 instances, thus we use a smaller sub-sample of 2000 points with 11 features after preprocessing.

We take the sets of unfairness thresholds \(\{(2^{-i},2^{-i})_{i\in\mathcal{I}}\}\), where \(\mathcal{I}=\{1,2,4,5,6,8,16,32,128,512\}\) for _Communities and Crime_ dataset, and \(\mathcal{I}=\{0,1,2,4,5,6,8,16,32,64,128\}\) for _Law School_ dataset. We train _Communities and Crime_ dataset for N=15000 iterations and _Law School_ dataset for N=5000 iterations for each pair of epsilons. We use parameters \(L=\sqrt{T}\), \(\beta=\sqrt{T}\log\sqrt{T}\) and \(B=1\) for both datasets. We repeat the aforementioned pipeline 10 times to ensure more reliable statistical summary.

Discussion on other algorithms.We conduct additional experiments to observe the behaviors of the more straightforward algorithms discussed in Appendix C. We illustrate the comparison in Figure 3. In conclusion, all of the algorithms perform similarly in the middle to high unfairness regime, while those based on SGD3 are more stable in the low unfairness (high fairness) regime.

Additional experiments on _Adult_ dataset.We conduct further experiments on _Adult_ dataset (Lichman (2013)). Classically, _Adult_ is used for classification, however we use it to predict individual's age on a scale of \(0\) to \(100\), normalized to \([0,1]\). We factor in sex as a sensitive attribute, distinguishing between male and female individuals. _Adult_ dataset has \(48842\) instances, however we clean and preprocess it, and use a smaller sub-sample of 2000 points with 8 features throughout our experiments.

The pipleline of the experiments is the same as the one for _Law School_ and _Communities and Crime_ datasets in the main body. We randomly split the data into training, unlabeled and testing sets

Figure 3: Comparison of SDG, ACSA, ACSA2, SDG3+ACSA and SDG3+ACSA2 algorithms on _Communities and Crime_ and _Law School_ datasets.

with proportions of \(0.4\times 0.4\times 0.2\). We use \(\mathcal{D}_{\mathrm{train}}=\{(\bm{x}_{i},s_{i},y_{i})_{i=1}^{n}\}\) to train a base (unfair) regressor to estimate \(\eta\) and to train a classifier to estimate \(\tau\). We use simple _LinearRegression_ and _LogisticRegression_ from _scikit-learn_ for training the regressor and the classifier, and give them to Algorithm 1 with \(\mathcal{D}_{\mathrm{unlabeled}}=(\bm{x})_{i=n+1}^{n+T}\) for \(N=10000\) iterations. We use \(\mathcal{D}_{\mathrm{test}}=\{(\bm{x}_{i}^{\prime},s_{i}^{\prime},y_{i}^{ \prime})\}_{i=1}^{m}\) to collect statistics. We take the sets of unfairness thresholds \(\{(2^{-i},2^{-i})_{i\in\mathcal{I}}\}\), where \(\mathcal{I}=\{0,1,2,4,5,6,8,16,32,64,128\}\) for. As in the experiments in the main body, we set \(L=\sqrt{T}\), \(\beta=\sqrt{T}/\log\sqrt{T}\) and \(B=1\). We repeat the pipeline 10 times.

We compare our method with the ADW method. We train ADW 2 times: we use \(\mathcal{D}_{\mathrm{train}}\) and \(\mathcal{D}_{\mathrm{unlabeled}}\) as training set for ADW-1, whereas for ADW-2 we use only \(\mathcal{D}_{\mathrm{train}}\). We take the set \(\{(2^{-i},2^{-i})_{i\in\mathcal{I}}\}\), where \(\mathcal{I}=\{1,2,4,8,16\}\) as unfairness thresholds for training both datasets. We train ADW-1 and ADW-2 for each pair of epsilons for 10 times.

In Figure 4 we illustrate the convergence of the risk and the unfairness for convergence for \(\varepsilon=(2^{-8},2^{-8})\) unfairness threshold. We also illustrate the comparison of our model with ADW-1, ADW-2 and base models.

Running time.Additional details about training time for _Communities and Crime_, _Law School_ and _Adult_ datasets are presented in Table 1.

Additional experiments on a synthetic dataset.We conduct an additional experiment to demonstrate the results of Algorithm 1 in the case of multiple sensitive attributes. We generate a synthetic dataset \(\mathcal{D}_{n}=(\bm{X}_{i},S_{i},y_{i})_{i=1}^{n}\) of \(n=2000\) points, where \((\bm{X}_{i})_{i}^{n}=(X_{i1},X_{i2},X_{i2})_{i}^{n}\sim\mathcal{N}(0,1)\). We choose \(S_{i}=0\) if \(X_{i1}\leqslant-0.7\), \(S_{i}=1\) if \(X_{i1}<0\), \(S_{i}=2\) if \(X_{i1}<0.7\) and \(S_{i}=4\) if \(X_{i1}\geqslant-0.7\). For \(i\in[n]\), we generate \(y_{i}=4\sum_{j=1}^{3}X_{ij}+X_{i1}+\xi_{i}\), where \(\bm{\xi}=(\xi_{i})_{i}^{n}\sim\mathcal{N}(0,1)\). We split \(\mathcal{D}_{n}\) into _train_, _unlabeled_ and _test_ datasets with proportions of \(0.4\times 0.4\times 0.2\). We use \((\bm{X}_{train},\bm{y}_{train})\) to train the base estimator, \((\bm{X}_{train},\bm{S}_{train})\) to train the classifier and \(\bm{X}_{unlab}\) to train the fair regression model. We evaluate our model on _test_ dataset. In Figure 5 we illustrate the distributions of the predictions (scaled to \([-1,1]\)) of the fair and base models.

This experiment is for visual representation of the Algorithm 1 in the case of multiple sensitive attributes, thus we do not collect further statistics.

\begin{table}
\begin{tabular}{l l l l} \hline \hline  & DP-postproc & ADW-1 & ADW-2 \\ \hline communities & \(5.89\pm 0.47\) & \(378.39\pm 263.77\) & \(199.05\pm 161.18\) \\ law school & \(0.78\pm 0.08\) & \(240.53\pm 178.68\) & \(136.3\pm 96.73\) \\ adult & \(3.7\pm 0.34\) & \(174.57\pm 91.7\) & \(96.78\pm 61.35\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: The average training time (in seconds) for one \(\varepsilon\) threshold.

Figure 4: Experiment on _Adult_ dataset: risk convergence, unfairness convergence and comparison with ADW.

Figure 5: The distributions of the (scaled) predictions of the fair and base models.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: We translate the fairness problem to a smooth and convex problem as stated in Lemma 3.1. Theorem 5.1 gives the main theoretical control on fairness and risk and Section 6 illustrates the performance of the method and a comparison to a state-of-the-art method. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: A limitation section is included in the paper. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [Yes] Justification: We extensively developed our methodology in the main body and decided to postpone all the proofs to the Appendix. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: All the experiments are reproducible. We provide the link to the source code in Section 6. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: All the datasets that are used are benchmark datasets. Moreover, as previously mentioned, we point to a GitHub link in Section 6 to make our experiments reproducible. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Section 6 gives all necessary information on the datasets splits and on the tuning parameters. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: All our experiments include and illustrate the standard deviations reported over \(10\) repetitions. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.

* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We reported all this information in a footnote in Section 6. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We only used open source data and codes. Therefore, we believe that there are no issues form the ethical point of view. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: The contribution falls within the scope of fairness and the goal is to mitigate bias in decision making. The paper focus on the general notion of approximate fairness -- \(\varepsilon\)-fairness. While approximate fairness is desired in general, this setting allows for a control of the amount of unfairness that we allow or accept. From this point of view, providing the control on the fairness to some user may generate ethical issues.

Guidelines:

* The answer NA means that there is no societal impact of the work performed.
* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA]. Justification: All the datasets are open source and widely used by the fairness community. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We provided references for the two datasets we are using. In addition, we also referred the papers that we considered for a numerical comparison. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset.

* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: The main contribution is a novel approach for imposing demographic parity fairness in the unawareness case. This is challenging problem for which we spend the whole core of the paper to explain the method and its new considerations. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA]. Justification: The paper considered public data that does not involve human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [No] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.

* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.