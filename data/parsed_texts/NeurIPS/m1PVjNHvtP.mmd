# GLinSAT: The General Linear Satisfiability Neural Network Layer By Accelerated Gradient Descent

 Hongtai Zeng\({}^{1}\) Chao Yang\({}^{2}\) Yanzhen Zhou\({}^{1}\) Cheng Yang\({}^{2}\) Qinglai Guo\({}^{1}\)

\({}^{1}\) State Key Laboratory of Power Systems, Department of

Electrical Engineering, Tsinghua University

\({}^{2}\) Decision Intelligence Lab, Alibaba DAMO Academy

zenght20@mails.tsinghua.edu.cn, xiuxin.yc@alibaba-inc.com, zhouyzh@126.com, charis.yangc@alibaba-inc.com, guoqinglai@tsinghua.edu.cn

Corresponding author.

###### Abstract

Ensuring that the outputs of neural networks satisfy specific constraints is crucial for applying neural networks to real-life decision-making problems. In this paper, we consider making a batch of neural network outputs satisfy bounded and general linear constraints. We first reformulate the neural network output projection problem as an entropy-regularized linear programming problem. We show that such a problem can be equivalently transformed into an unconstrained convex optimization problem with Lipschitz continuous gradient according to the duality theorem. Then, based on an accelerated gradient descent algorithm with numerical performance enhancement, we present our architecture, GLinSAT, to solve the problem. To the best of our knowledge, this is the first general linear satisfiability layer in which all the operations are differentiable and matrix-factorization-free. Despite the fact that we can explicitly perform backpropagation based on automatic differentiation mechanism, we also provide an alternative approach in GLinSAT to calculate the derivatives based on implicit differentiation of the optimality condition. Experimental results on constrained traveling salesman problems, partial graph matching with outliers, predictive portfolio allocation and power system unit commitment demonstrate the advantages of GLinSAT over existing satisfiability layers. Our implementation is available at https://github.com/HunterTracer/GLinSAT.

## 1 Introduction

Constrained decision-making problems are pervasive across various disciplines. For example, logistics companies need to arrange delivery routes to minimize transportation costs while ensuring that all orders are delivered on time. Power system operators need to decide how to allocate electricity production between different power plants to meet ever-changing electricity demand while maintaining system stability. Unfortunately, directly solving these complex constrained decision-making problems via commercial optimization solvers requires a large amount of time. As a result, in scenarios that require rapid response, traditional solvers may not be suitable due to their long computation time. With the development of deep learning, it is hopeful that neural networks can capture the domain characteristics and complex relationships involved in constrained decision-making problems through their powerful expressive capability and the solution time can be thus reduced. In recent years, research on how to use neural networks to solve constrained decision-making problems has become a topic of general interest. Despite the great success of neural networks on classification and regression tasks, making the outputs of neural networks satisfy specific constraints is not straightforward, which still needs to be further investigated.

A natural idea to impose constraints on the neural network outputs is to penalize the constraint violation in the training stage of supervised learning or reinforcement learning [1; 2; 3]. However, such an approach requires a careful selection of each penalty coefficient to achieve a balance between decision objectives and constraint violations. As the complexity of constraints increases, choosing appropriate penalty factors may require a large number of attempts, which is time-consuming. Moreover, it is often difficult to theoretically guarantee the boundedness of constraint violations [4], which makes penalty-based methods less attractive. Ref. [5] managed to determine the width of neural networks required for ensuring feasibility by modeling these networks using binary variables and solving a complex mixed-integer bilevel programming. However, this approach necessitates shrinking the original feasible region and can only handle inequality constraints, which limits its broader application. There are also methods in the literature that are better suited for inequality constraint satisfaction. Ref. [6] uses gauge function to map the neural network outputs from a \(\ell^{\infty}\)-norm unit ball into a given polyhedral. Despite its success in the field of control, this method may encounter difficulties in handling equality constraints since the polyhedral need to contain the origin as an interior point. Ref. [7] first calculates a reference point within the interior of a convex region using convex programming in the offline stage, and then computes a feasible point based on this reference point through simple arithmetic operations in the online stage. Despite its efficiency potentially being affected when constraints are not fixed, the method may encounter difficulties in satisfying equality constraints, as it requires computing the null space of the equality constraints. Since the basis for the null space of a matrix is typically dense, calculating the null space for large matrices may present both efficiency and memory challenges. Another way to encode constraints in neural networks is to reformulate the original problem as a Markov decision problem [8; 9]. During the solution process, the decision variables are generated one by one and the value range of the next variable is determined by the value of the current variable so that constraints can be satisfied compulsorily. However, not all decision-making problems can be equivalently converted to Markov decision problems which limits the application of such an approach.

Due to the limitations of the above approaches, many researchers want to use a more reliable way to ensure that the outputs of neural networks satisfy specific constraints. A promising way is to integrate optimization solvers as neural network layers. When we embed a solver for end-to-end learning, we need to pay special attention to the following two issues: the first one is the _supported constraint types_, and the second one is the _efficiency_.

As for the issue of supported constraint types, some frameworks can directly impose combinatorial constraints on neural network outputs through integrating black-box commercial mixed-integer programming solvers at the cost of inexact gradient estimates and poor utilization of GPUs (since modern commercial solvers are CPU-based) [10; 11; 12]. These approaches need to solve combinatorial optimization problems in both training and inference stages, which is time-consuming. Instead of directly handling the combinatorial constraints, some researchers manage to make neural network outputs satisfy constraints obtained from the continuous relaxation of the original problem, e.g. the widely used double stochastic matrix constraint in Ref. [13; 14; 15] solved by Sinkhorn algorithm [16; 17; 18]. Another example is the positive semi-definite (PSD) matrix constraint with unit diagonals as a continuous relaxation of the original MAXSAT problem [19]. However, both of the above methods can only express specific constraints, which limits their application. Recently, LinSAT, which is based on a generalized Sinkhorn algorithm, is proposed to impose positive linear constraints on neural network outputs [20]. However, the requirement for all elements in constraints to be non-negative limits the application of LinSAT. For example, even for a simple constraint \(x\leq y\), namely \(x-y\leq 0\), LinSAT cannot be used due to the negative coefficient in front of \(y\), which shows the limited expressiveness of LinSAT. Decision variables with negative constraint coefficients occur a lot in real-life decision-making problems, such as the bin packing problem [21], chemical process scheduling [22], power system unit commitment [23], etc.

To deal with general linear constraints in a differentiable way, currently, there are two main approaches, CvxpyLayers [24] and OptNet [25]. However, when solving a batch of problems, both of them may encounter efficiency issues. Although CvxpyLayers can achieve parallelism through multiprocessing on the CPU, there are only a dozen of cores in one CPU, leading to limited parallelism performance. On the other hand, OptNet presents a GPU-based batch quadratic programming interior point solver where batch matrix factorization are performed to accelerate the solution process. Unfortunately, batch matrix factorization may be still a computational bottleneck even when GPU is used. Although some scholars have also studied how to parallelize parts of operations in matrix factorization on the GPU [26; 27], the degree of parallelism still highly depend on the structure of the matrix and its elimination tree. Two nodes in the elimination tree can be computed in parallel only when there is no direct branch connecting them. As a result, matrix factorization cannot fully utilize the parallel computing ability of the GPU due to the sequential characteristics in the elimination tree [28].

In this paper, we investigate how to apply bounded and general linear constraints to neural network outputs in a differentiable way while ensuring batch processing can be performed efficiently on the GPU.

**The contributions of this paper include:**

1) To impose general linear and bounded constraints on neural network outputs in a differentiable way, we formulate the corresponding projection problem as an entropy-regularized linear programming where negative logistic entropic regularization terms are added into the objective function. We show that such an entropy-regularized linear programming problem can be transformed into an unconstrained convex optimization problem with Lipschitz continuous gradient, and thus can be solved by gradient descent based algorithms where no matrix factorization operation is required.

2) We design GLinSAT, a general linear satisfiability layer to impose linear constraints on neural network outputs based on a state-of-the-art accelerated gradient descent algorithm with numerical performance enhancement. Since the main operations in GLinSAT is matrix-vector product and no matrix factorization is involved, it is convenient to execute these operations in parallel on the GPU. Although all the operations involved in GLinSAT are differentiable which means that we can directly use the automatic differentiation mechanism to perform back propagation, we also provide an alternative way for derivative calculation based on the optimality condition to reduce the memory consumption.

3) We then provide experimental results to demonstrate the capabilities of our proposed method. Experiments on constrained traveling salesman problems, partial graph matching with outliers, predictive portfolio allocation and power system unit commitment show the efficacy of our proposed method and advantages over existing methods. A comparison of methodologies for imposing constraints on neural networks outputs is presented in Table 1. A pipeline that shows how our approach works is provided in Fig. 1.

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline Ref. & Abbr. of & Constraint & GPU & Matrix & Exact & Explicit & Implicit \\  & approach & & type & comput- & factorization free & ent & propagation & propagation \\ \hline
[10; 11; 12] & Perturbed & combination & – & – & – & ✗ & ✗ & ✓ \\
[13; 14; 15] & Spinkhorn & double & ✓ & ✓ & ✓ & ✓ & ✗ \\  & & & stochastic & & ✓ & ✓ & ✓ & ✗ \\  & & matrix & & & & & & \\  & & PSD matrix & & & & & & \\
[19] & SATNet & with unit & ✓ & ✓ & ✓ & ✗ & ✓ \\  & & diagonals & & & & & & \\
[20] & LinSAT & positive & ✓ & ✓ & ✓ & ✓ & ✗ \\  & & linear & & & & & \\
[24] & CvxpyLayers & & cone & ✗ & ✓ & ✗ & ✓ \\
[25] & OptNet & linear & ✓ & ✗ & ✓ & ✗ & ✓ \\ \hline This & & & & & & & \\ article & GLinSAT & linear & ✓ & ✓ & ✓ & ✓ & ✓ \\ \hline \hline \end{tabular} Note: Explicit/Implicit backpropagation means that this algorithm performs backward propagation based on automatic differentiation mechanism/implicit differentiation. **-** means that this algorithm feature is dependent on the implementation of the backend solver.

\end{table}
Table 1: Comparison with existing optimizer layers for imposing constraints on the outputs of neural networks

## 2 Methodology

Sec. 2.1 formulates the neural network output projection problem as an entropy-regularized linear programming by introducing logistic entropy regularization terms in the objective function. Based on duality theorem, the original problem can be transformed into an unconstrained convex optimization problem with Lipschitz continuous gradient. Then, in Sec. 2.2, based on a variant of accelerated gradient descent method, we design GLinSAT, which solves the projection problem using a GPU-friendly algorithm with several numerical enhancements. The corresponding time complexity is also provided in Sec. 2.2. Moreover, although all the operations in the forward pass of GLinSAT are differentiable, in Sec. 2.3, we provide an alternative way based on the optimality condition to calculate the derivatives for memory saving.

### Reformulation of the neural network output projection problem

Here, we want to use a differentiable way to project the output of the neural network \(\bm{c}^{\prime}\in\mathbb{R}^{n^{\prime}}\) into variables \(\bm{x}^{\prime}\in\mathbb{R}^{n^{\prime}}\) that are as similar as possible but satisfy the following constraints (1).

\[\bm{A}_{1}^{\prime}\bm{x}^{\prime}\leq\bm{b}_{1}^{\prime}\] (1a) \[\bm{A}_{2}^{\prime}\bm{x}^{\prime}\geq\bm{b}_{2}^{\prime}\] (1b) \[\bm{A}_{3}^{\prime}\bm{x}^{\prime}=\bm{b}_{3}^{\prime}\] (1c) \[\bm{l}^{\prime}\leq\bm{x}^{\prime}\leq\bm{u}^{\prime}\] (1d)

where \(\bm{A}_{1}^{\prime}\in\mathbb{R}^{m_{1}^{\prime}\times n^{\prime}}\), \(\bm{A}_{2}^{\prime}\in\mathbb{R}^{m_{2}^{\prime}\times n^{\prime}}\), \(\bm{A}_{3}^{\prime}\in\mathbb{R}^{m_{3}^{\prime}\times n^{\prime}}\), \(\bm{b}_{1}^{\prime}\in\mathbb{R}^{m_{1}^{\prime}}\), \(\bm{b}_{2}^{\prime}\in\mathbb{R}^{m_{2}^{\prime}}\), \(\bm{b}_{3}^{\prime}\in\mathbb{R}^{m_{3}^{\prime}}\), \(\bm{l}^{\prime},\bm{u}^{\prime}\in\mathbb{R}^{n^{\prime}}\). Moreover, we also suppose that the feasible region in (1) is non-empty.

Apparently, any general linear constraints with bounded variables like (1) can be converted to the standard form like (2) by shifting bounds and introducing slack variables (see Appendix A.4):

\[\bm{Ax}=\bm{b}\] (2a) \[\bm{0}\leq\bm{x}\leq\bm{u}\] (2b)

where \(m=m_{1}^{\prime}+m_{2}^{\prime}+m_{3}^{\prime}\), \(n=n^{\prime}+m_{1}^{\prime}+m_{2}^{\prime}\), \(\bm{A}\in\mathbb{R}^{m\times n}\), \(\bm{b}\in\mathbb{R}^{m}\), \(\bm{u}\in\mathbb{R}^{n}_{+}\). Here, we denote the vector obtained from padding \((m_{1}^{\prime}+m_{2}^{\prime})\) zeros after the original vector \(\bm{c}^{\prime}\) as \(\bm{c}\). Now, the original problem is transformed into a problem of projecting \(\bm{c}\in\mathbb{R}^{n}\) onto \(\bm{x}\in\mathbb{R}^{n}\) that satisfy constraints (2). In the following sections, we mainly focus on such a transformed problem in standard form.

In this paper, we aim for the vector \(\bm{x}\) after projection to be as close as possible to the vector \(\bm{c}\) prior to projection, while adhering to specified constraints. Here, we use the dot product as a measure of vector similarity. Consequently, our objective function becomes that of maximizing the dot product of vectors \(\bm{c}\) and \(\bm{x}\), which is equivalently described as minimizing the dot product of \(-\bm{c}\) and \(\bm{x}\). Besides, as pointed by [29], the optimal solution to an linear programming may not be differentiable (or even continuous) with respect to its parameters. Therefore, additional regularization terms need to be included in the objective to make the optimization problem differentiable. Inspired by entropy-regularized optimal transport, here we formulate the projection problem as an entropy-regularized linear programming to make the entire problem differentiable. Logistic entropy regularization terms

Figure 1: A pipeline that shows how GLinSAT layer works.

are added into the objective as follows:

\[\min_{\bm{0}\leq\bm{x}\leq\bm{u}}f\left(\bm{x}\right)=\min_{\bm{0} \leq\bm{x}\leq\bm{u}}-\bm{c}^{T}\bm{x}+\frac{1}{\theta}\sum_{j=1}^{n}\left( \frac{x_{j}}{u_{j}}\log\frac{x_{j}}{u_{j}}+\left(1-\frac{x_{j}}{u_{j}}\right) \log\left(1-\frac{x_{j}}{u_{j}}\right)\right)\] (3a) \[\mathrm{s.t.}\ \bm{A}\bm{x}=\bm{b}\] (3b)

where \(\theta>0\) is the inverse temperature parameter that controls the approximation degree between the entropy-regularized problem and the original linear programming. The regularization coefficient \(1/\theta\) controls the smoothness of the outputs. The smaller \(1/\theta\) is, the more the outputs tend to be at the extreme point of the feasible region. As \(\theta\rightarrow+\infty\), the optimal solution of the entropy-regularized problem should approach that of the original linear programming.

**Remark 1**.: _It is noteworthy that unlike entropy-regularized optimal transport problems where only regularization terms in the form of \(x\log x\) are involved in the objective, here logistic entropy regularization terms with respect to both \(x/u\) and its complement \(1-x/u\) are added into the objective. **Actually, additionally incorporating the complementary entropy regularization terms is the most important part for the derivation of the Lagrange dual problem.** Otherwise, we cannot obtain a simple closed-form expression of the dual objective in the following derivation. Similarly, if we use the common \(\ell^{2}\)-norm as the regularization term, we cannot obtain an analytical expression either._

If we denote the dual variables with respect to the equality constraints (3b) as \(\bm{y}\), the Lagrange dual function for (3) can be expressed as follows:

\[g\left(\bm{y}\right)=\inf_{\bm{0}\leq\bm{x}\leq\bm{u}}\left(-\bm{c}^{T}\bm{x} +\frac{1}{\theta}\bm{1}^{T}\left(\frac{\bm{x}}{\bm{u}}\circ\bm{\log\frac{\bm{ x}}{\bm{u}}+\left(\bm{1}-\frac{\bm{x}}{\bm{u}}\right)\circ\bm{\log\left(\bm{1}- \frac{\bm{x}}{\bm{u}}\right)\right)-\bm{y}^{T}\bm{A}\bm{x}\right)+\bm{b}^{T} \bm{y}\] (4)

where \(\bm{a}\circ\bm{b},\frac{\bm{b}}{\bm{a}}\) represents the element-wise multiplication and division of vector \(\bm{a}\) and \(\bm{b}\) respectively. Since the derivative magnitude of \(x\log x+\left(1-x\right)\log\left(1-x\right)\) tends to infinity when \(x\to 0^{+}\) or \(x\to 1^{-}\), the infimum in (4) can be attained only on a stationary point instead of a boundary point. When the infimum in (4) is attained, by making the derivative of the inner function equal to zero, we have:

\[-\bm{c}-\bm{A}^{T}\bm{y}+\frac{\bm{1}}{\theta\bm{u}}\circ\bm{\log\frac{\bm{x} }{\bm{u}-\bm{x}}=\bm{0}}\] (5)

After simplifying the above formula, we can get that when the infimum in (4) is attained, the optimal value of \(\bm{x}\left(\bm{y}\right)\) can be expressed as:

\[\bm{x}\left(\bm{y}\right)=\bm{u}\circ\bm{\sigma}\left(-\theta\bm{u}\circ \left(-\bm{c}-\bm{A}^{T}\bm{y}\right)\right)\] (6)

where \(\bm{\sigma}\left(\cdot\right)\) is the sigmoid function. Substituting equation (6) into equation (4), we have:

\[g\left(\bm{y}\right)=\frac{1}{\theta}\bm{1}^{T}\bm{\log\sigma}\left(\theta \bm{u}\circ\left(-\bm{c}-\bm{A}^{T}\bm{y}\right)\right)+\bm{b}^{T}\bm{y}\] (7)

Since \(\bm{\log\sigma}\left(\cdot\right)\) is a strictly concave function, by minimizing the opposite of \(g\left(\bm{y}\right)\), we can obtain the following Lagrange dual problem (8), which is exactly an unconstrained convex optimization problem.

\[\min_{\bm{y}\in\mathbb{R}^{m}}-g\left(\bm{y}\right)=\min_{\bm{y}\in\mathbb{R} ^{m}}-\frac{1}{\theta}\bm{1}^{T}\bm{\log\sigma}\left(\theta\bm{u}\circ\left( -\bm{c}-\bm{A}^{T}\bm{y}\right)\right)-\bm{b}^{T}\bm{y}\] (8)

We can easily show that \(f\left(\bm{x}\right)\) is a strongly convex function and \(-g\left(\bm{y}\right)\) has Lipschitz continuous gradient (see explanations in Appendix A.5). Therefore, gradient descent based algorithms can be directly applied to solve such a problem.

### Forward pass in GLinSAT

In the previous section, we have shown that the original entropy-regularized linear programming problem (3) can be equivalently converted into an unconstrained convex optimization problem (8) with Lipschitz continuous gradient. Theoretically, it can be solved readily through gradient descent based method. However, in the actual calculation process, it will be hard to choose a suitable step size if we just use vanilla gradient descent method. If the step size is much greater than the local Lipschitz constant, the algorithm may diverge. Otherwise, the convergence may be too slow.

Considering the strong convexity property of the entropy regularization terms, here we use a variant of accelerated gradient descent method, adaptive primal-dual accelerated gradient descent (APDAGD), which can adaptively approximate the local Lipschitz constant [30]. The detailed procedure of solving the entropy-regularized linear programming problem (3) in GLinSAT is provided in Algorithm 1.

Compared with the original version of APDDAGD, here we improve the numerical performance of Algorithm 1 from the following two aspects. First, we use a smoother way to update the approximation of the local Lipschitz constant \(M\) in GLinSAT. In Algorithm 1, \(M\) is decreased only when the decrease of the dual objective satisfies the corresponding condition for at least two consecutive times. As a result, when \(M\) is already a good estimate of the local Lipschitz constant, the frequency of needless updates can be reduced, which will lead to less computation time. Second, to handle the round-off error, we also use a small number \(\delta\) to relax the criterion for the decrease of the objective function. Otherwise, due to the existence of numerical error, the criterion of sufficient decrease in objective may be never satisfied. If we do not relax the criterion, \(M\) may become a large number and the algorithm will get stuck.

In addition, it is noteworthy that most of the operations involved in Algorithm 1 are calculation of matrix-vector products, vector-vector element-wise products and unary functions. Therefore, it is convenient to execute these operations in parallel on the GPU for solving a batch of entropy-regularized linear programming problems.

As for the time complexity of Algorithm 1, based on Theorem 1 and Theorem 2 in the supplementary material of [30], it can be easily proved that the number of iterations required by Algorithm 1 is roughly proportional to \(\sqrt{\theta}\) and inversely proportional to \(\sqrt{\varepsilon}\). The corresponding result is given in Corollary 1 and the detailed discussions can be found in Appendix A.6.

``` Input:\(\bm{A}\in\mathbb{R}^{m\times n}\), \(\bm{b}\in\mathbb{R}^{m}\), \(\bm{c}\in\mathbb{R}^{n}\), \(\bm{u}\in\mathbb{R}^{n}_{+}\), inverse temperature \(\theta>0\), tolerance \(\varepsilon>0\),  initial estimate of Lipschitz constant \(L^{(0)}\), initial estimate of dual variables \(\bm{y}^{(0)}\),  numerical precision \(\delta>0\)  Set \(k=0\), \(M^{(0)}=L^{(0)}\), \(\bm{\eta}^{(0)}=\bm{\zeta}^{(0)}=\bm{y}^{(0)}\), \(\bm{x}^{(0)}=\bm{u}\circ\bm{\sigma}\left(-\theta\bm{u}\circ\left(-\bm{c}-\bm{ A}^{T}\bm{y}^{(0)}\right)\right)\), \(\beta^{(0)}=\alpha^{(0)}=0\), \(f=\texttt{False}\); while\(\left\|\bm{A}\bm{x}^{(k)}-\bm{b}\right\|_{2}>\varepsilon\)do  Set \(\alpha^{(k+1)}=\left(1+\sqrt{1+4M^{(k)}\beta^{(k)}}\right)/\left(2M^{(k)}\right)\);  Set \(\beta^{(k+1)}=\beta^{(k)}+\alpha^{(k+1)}\);  Set \(\tau^{(k+1)}=\alpha^{(k+1)}/\beta^{(k+1)}\);  Set \(\bm{\lambda}^{(k+1)}=\bm{\eta}^{(k)}+\tau^{(k+1)}\left(\bm{\zeta}^{(k)}-\bm{ \eta}^{(k)}\right)\);  Set \(\bm{x}\left(\bm{\lambda}^{(k+1)}\right)=\bm{u}\circ\bm{\sigma}\left(-\theta \bm{u}\circ\left(-\bm{c}-\bm{A}^{T}\bm{\lambda}^{(k+1)}\right)\right)\);  Set \(\bm{\zeta}^{(k+1)}=\bm{\zeta}^{(k)}-\alpha^{(k+1)}\left(\bm{A}\bm{x}\left(\bm{ \lambda}^{(k+1)}\right)-\bm{b}\right)\);  Set \(\bm{\eta}^{(k+1)}=\bm{\eta}^{(k)}+\tau^{(k+1)}\left(\bm{\zeta}^{(k+1)}-\bm{ \eta}^{(k)}\right)\); if\(\left(-g\left(\bm{\eta}^{(k+1)}\right)\right)-\left(-g\left(\bm{ \lambda}^{(k+1)}\right)\right)-\delta\leq-\left\|\bm{A}\bm{x}\left(\bm{\lambda }^{(k+1)}\right)-b\right\|_{2}^{2}/\left(2M^{(k)}\right)\)then if\(f=\texttt{True}\)then  Set \(M^{(k+1)}=M^{(k)}/2\); else  Set \(M^{(k+1)}=M^{(k)}\);  end if  Set \(k=k+1\); else  Set \(M^{(k)}=2M^{(k)}\), \(f=\texttt{False}\);  end if  end while Output: Optimal primal variables \(\bm{x}^{(k)}\), Optimal dual variables \(\bm{\eta}^{(k)}\) ```

**Algorithm 1**Solving the entropy-regularized linear programming problem in GLinSAT

**Corollary 1**.: _Assume that the optimal dual solution \(\bm{y}^{*}\) of problem (3) satisfies \(\left\|\bm{y}^{*}\right\|_{2}\leq R\). Then, for given tolerance \(\varepsilon>0\), the number of required iterations is \(O\left(\left\|\bm{A}\right\|_{2}\max\left(\bm{u}\right)\sqrt{\theta R/ \varepsilon}\right)\)._

### Backward pass in GLinSAT

Since all the operations involved in Algorithm 1 are differentiable with respect to \(\bm{c}\), a natural idea is to directly use the auto differential mechanism to calculate the derivatives in the backward pass. However, directly backward propagation may require ever growing memory to store computational graphs and may cost much time when the forward pass requires a lot of iteration steps. To save the memory usage and accelerate the derivative calculation, we also provide an alternative way based on the optimality condition to calculate the derivatives in GLinSAT.

First, by calculating the derivative of \(-g\left(\bm{y}\right)\), we can obtain the optimality condition as follows:

\[\bm{h}\left(\bm{y}\right)=\bm{A}\left(\bm{u}\circ\bm{\sigma}\left(-\theta \bm{u}\circ\left(-\bm{c}-\bm{A}^{T}\bm{y}\right)\right)\right)-\bm{b}=\bm{0}\] (9)

According to implicit differentiation and chain rule, differentiating equation (9), we can get:

\[\frac{\partial\bm{y}}{\partial\bm{c}}=-\left(\frac{\partial\bm{h}}{\partial \bm{y}}\right)^{-1}\frac{\partial\bm{h}}{\partial\bm{c}}\] (10)

Furthermore, according to equation (6), the derivative of loss function \(l\) with respect to \(\bm{c}\) can be calculated as:

\[\frac{\partial l}{\partial\bm{c}}=\frac{\partial l}{\partial\bm{x}}\frac{ \partial\bm{x}}{\partial\bm{c}}+\frac{\partial l}{\partial\bm{x}}\frac{ \partial\bm{x}}{\partial y}\frac{\partial\bm{y}}{\partial\bm{c}}+\frac{ \partial l}{\partial\bm{y}}\frac{\partial\bm{y}}{\partial\bm{c}}=\frac{ \partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial\bm{c}}-\left(\frac{ \partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial\bm{y}}+\frac{ \partial l}{\partial\bm{y}}\right)\left(\frac{\partial\bm{h}}{\partial\bm{y} }\right)^{-1}\frac{\partial\bm{h}}{\partial\bm{c}}\] (11)

In the actual implementation of GLinSAT, we do not explicitly form these Jacobian matrices \(\frac{\partial\bm{x}}{\partial\bm{c}},\frac{\partial\bm{x}}{\partial\bm{y}},\left(\frac{\partial\bm{h}}{\partial\bm{c}}\right)^{-1}\frac{\partial\bm{h }}{\partial\bm{c}}\). Instead, we directly form the matrix-vector products \(\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial\bm{c}},\frac {\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial\bm{y}}\). In addition, since the jacobian matrix \(\frac{\partial\bm{h}}{\partial\bm{y}}\) is positive semi-definite (see derivations in Appendix A.7), we can use conjugate gradient method to calculate the inverse-matrix-vector products in GLinSAT. Therefore, only matrix-vector product operations are involved in the calculation of derivatives. Moreover, for the sake of completeness, in GLinSAT, we also implement derivatives with respect to \(\bm{A}\), \(\bm{b}\), \(\bm{u}\) for future potential usage. The detailed derivation process of all derivatives is provided in Appendix A.7.

## 3 Experimental Results

In this section, experiments on constrained traveling salesman problems, partial graph matching with outliers, predictive portfolio allocation and power system unit commitment are used to demonstrate the advantages of GLinSAT through comparison with the state-of-the-art linear satisfiability layers LinSAT [20], CvxypLayers [24] and OptNet [25]. For OptNet, LinSAT and GLinSAT, the regularization coefficients of nonlinear terms are all set to \(1/\theta\). For CvxypLayers, the projection problem to be solved is set to the same as (3). The first three experiments originate from Ref. [20]. The last experiment is the unit commitment problem in actual power systems. In the following sections, GLinSAT-(Dense/Sparse)-(Explicit/Implicit) means that GLinSAT is used with dense/sparse matrix and backpropagation is performed using automatic differential/implicit differential. LinSAT-(Dense/Sparse)-(100/500) means that LinSAT is used with dense/sparse matrix and maximum iteration number is set to 100/500. The reason we cannot set the maximum iteration number in LinSAT to \(+\infty\), as we do in GLinSAT, is that LinSAT may iterate endlessly and get stuck in such a case. All the experiments are conducted on a computer with a 24-core Intel(R) Xeon(R) Platinum 8360H CPU and a NVIDIA Tesla A100 GPU through Pytorch 2.2. Our code is provided in https://github.com/HunterTracer/GLinSAT.

### Constrained traveling salesman problem

Using the traveling salesman problem (TSP) dataset in [20], here we test the performance of each satisfiability layer through experiments on TSP with starting and ending cities constraint and priority constraint respectively. The mathematical formulation of TSP with starting and ending cities constraint (TSP-StartEnd) and TSP with priority constraint (TSP-Priority) is provided in AppendixA.8. The detailed experimental settings are provided in Appendix A.8. We report the average batch processing performance in Table 2 where \(\frac{1}{\theta}\) is set to 0.1. The results when \(\frac{1}{\theta}\) is set to 10\({}^{\text{-2}}\) are similar therefore we display the results in Table A.1 and Table A.2 in Appendix A.8.

From Table 2, it can be seen that GLinSAT-Dense-Implicit outperforms all the other methods with minimum total storage and shortest total computation time. We can also find that our proposed GLinSAT is memory-efficient. Even though we choose the GLinSAT-Dense-Explicit method which will cost the most memory among all versions of GLinSAT, the total memory usage is still less than that of LinSAT-Sparse-100. We also attempted to set the maximum number of iterations for LinSAT to \(+\infty\), but at this point LinSAT will get stuck and we cannot obtain a reasonable result. Contrarily, for our proposed GLinSAT, the convergence is guaranteed, so setting the maximum iteration number to \(+\infty\) will not affect the result.

To obtain feasible tours, we exploit two kinds of post-processing methods in the validation stage [20]. The first one is rounding and the second one is beam search where the width of the beam is set to 2048. Table 3 shows the average tour length and feasibility ratio of each method. Since CvxpLyayers and OptNet are hundreds of times slower than LinSAT and GLinSAT, we are unable to obtain trained models within reasonable time and thus the results are not included.

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \hline  & \multicolumn{4}{c}{TSP-StartEnd} & \multicolumn{4}{c}{TSP-Priority} \\ \cline{2-9}  & GPU Mem./MB & \multicolumn{2}{c}{Time/s} & GPU Mem./MB & \multicolumn{2}{c}{Time/s} \\ \cline{2-9} Layer & Proj. & Backprop. & Proj. & Backprop. & Proj. & Backprop. & Proj. & Backprop. \\ \hline CvxpLyayers & — & — & 112.1 & 18.39 & — & — & 116.5 & 19.94 \\ OptNet & 14305 & 5005 & 18.92 & 0.929 & 14333 & 5005 & 20.26 & 1.136 \\ LinSAT-Dense-100 & 14977 & 181.2 & **0.278** & 0.417 & 15009 & 180.9 & **0.276** & 0.418 \\ LinSAT-Dense-500 & 74108 & 181.2 & 1.323 & 1.927 & 74272 & 180.9 & 1.317 & 1.929 \\ GLinSAT-Dense-Explicit & 4380 & **4.868** & 0.382 & 0.240 & 4898 & **4.880** & 0.440 & 0.270 \\ GLinSAT-Dense-Implicit & **13.35** & 532.33 & 0.306 & **0.143** & **13.36** & 53.22 & 0.349 & **0.146** \\ LinSAT-Sparse-100 & 7971 & 132.0 & 0.281 & 0.358 & 8026 & 132.6 & 0.286 & 0.368 \\ LinSAT-Sparse-500 & 39020 & 133.5 & 1.356 & 1.614 & 39309 & 133 & 1.397 & 1.645 \\ GLinSAT-Sparse-Explicit & 2787 & 5.426 & 0.603 & 0.326 & 3127 & 5.983 & 0.652 & 0.355 \\ GLinSAT-Sparse-Implicit & 62.95 & 24.71 & 0.454 & 0.158 & 63.27 & 24.51 & 0.495 & 0.165 \\ \hline \hline \end{tabular} Note: The GPU memory used by CvxpLyayers is not counted since CvxpLyayers use the CPU parallel mechanism. Statistics of CvxpLyayers and OptNet are based on the first epoch since we cannot obtain a well-trained model in reasonable time.

\end{table}
Table 2: Average allocated GPU memory and solution time of different satisfiability layers during batch processing of projection and backpropagation when \(\frac{1}{\theta}\) is set to 0.1 in TSP training phase

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline  & \multicolumn{4}{c}{TSP-StartEnd} & \multicolumn{4}{c}{TSP-Priority} \\ \cline{2-9}  & \multicolumn{2}{c}{Rounding} & \multicolumn{2}{c}{Beamsearch} & \multicolumn{2}{c}{Rounding} & \multicolumn{2}{c}{Beamsearch} \\  & with \(\frac{1}{\theta}\) = 10\({}^{\text{-2}}\) & & with \(\frac{1}{\theta}\) = 10\({}^{\text{-1}}\) & & with \(\frac{1}{\theta}\) = 10\({}^{\text{-2}}\) & & with \(\frac{1}{\theta}\) = 10\({}^{\text{-1}}\) \\ \cline{2-9} Layer & Mean & Feas. & Mean & Feas. & Mean & Feas. & Mean & Feas. \\  & Length & Ratio & Length & Ratio & Length & Ratio & Length & Ratio \\ \hline LinSAT-Dense-100 & 4.007 & 15.3\% & 3.843 & **100\%** & 4.114 & 41.6\% & 3.952 & **100\%** \\ LinSAT-Dense-500 & 3.926 & 93.6\% & 3.823 & **100\%** & 4.098 & 91.5\% & 3.947 & **100\%** \\ GLinSAT-Dense-Explicit & 3.939 & 94.2\% & 3.817 & **100\%** & 4.079 & **93.5\%** & 3.934 & **100\%** \\ GLinSAT-Dense-Implicit & **3.922** & 94.2\% & **3.811** & **100\%** & **4.068** & 93.4\% & **3.927** & **100\%** \\ LinSAT-Sparse-100 & — & — & 3.843 & **100\%** & — & — & 4.567 & **100\%** \\ LinSAT-Sparse-500 & — & — & 3.818 & **100\%** & — & — & 4.400 & **100\%** \\ GLinSAT-Sparse-Explicit & 3.939 & 94.2\% & 3.817 & **100\%** & 4.078 & 92.6\% & 3.935 & **100\%** \\ GLinSAT-Sparse-Implicit & 3.929 & **94.6\%** & 3.818 & **100\%** & 4.073 & 93.4\% & 3.933 & **100\%** \\ \hline \hline \end{tabular} Note: The output of LinSAT-Sparse when \(1/\theta\) = 10\({}^{\text{-2}}\) is not a real number so that the results are not shown.

\end{table}
Table 3: Mean tour length and feasibility ratio obtained from using different \(\frac{1}{\theta}\) and post-processing methods in TSP validation stage From Table 3, we can see that GLinSAT-Dense-Implicit results in the shortest mean tour length when beamsearch is used. It is also noteworthy that LinSAT will produce poor solution when we apply rounding to the results and the max iteration number is set to 100. Although setting the maximum number of iterations to 500 can improve LinSAT's performance, LinSAT's performance is still not as good as GLinSAT. Considering that the total computation time of LinSAT is more than five times that of GLinSAT at this time, it makes LinSAT less competitive.

### Partial graph matching with outliers

The detailed mathematical formulation of partial graph matching with outliers is provided in A.9. We carry out experiments on Pascal VOC Keypoint dataset [31] with Berkeley annotations [32] under the unfiltered setting [20; 33].

Considering there are graphs with different sizes in one batch, we stack constraints as block diagonal matrices and forward them to LinSAT and GLinSAT. However, CvxpyLayers and OptNet currently cannot handle large block diagonal matrices. Disciplined parameterized programming compilation in CvxpyLayers and matrix factorization of large matrices in OptNet will cost a significant amount of time. Therefore, we can only use a for-loop to handle a batch with different sizes separately. The average GPU memory usage and solution time across different satisfiability layers is provided in Table A.3 of Appendix A.9. In the validation stage, we use Hungarian algorithm and greedy strategy for obtaining feasible integer solutions [20]. We regard the cost of matching a pair of nodes as the outputs of satisfiability layers, then use Hungarian algorithm to obtain a maximum matching. Finally, we use greedy strategy to preserve pairs with top-\(p\) matching scores for constraint satisfaction. The matching F1 scores between graph pairs across various satisfiability layers are shown in Table 4. The result of LinSAT-Dense-500 is not given due to out-of-memory (OOM) issues. According to Table 4, we can find GLinSAT yields the highest F1 scores across all satisfiability layers.

### Predictive portfolio allocation

In this section, we use the predictive portfolio allocation dataset in [20]. Denote \(x_{i}\in[0,1]\) as the predicted portfolio decision variable of asset \(i\), \(\mathcal{S}\) as the preferred portfolio asset. Our portfolio allocation needs to maximize the Sharpe ratio [34] while ensuring decision variables satisfy constraints \(\sum_{i=1}^{n}x_{i}=1\), \(\sum_{i\in\mathcal{S}}x_{i}\geq q\) where \(q\) is a pre-defined positive constant. The details of experiments are provided in Appendix A.10. The average memory usage and solution time is shown in Table A.4 of Appendix A.10. According to Table A.4, we can find that our proposed GLinSAT is the fastest layer among all layers. In Table 5, we show the mean Sharpe ratio obtained from different satisfiability layers. Our proposed method always yields a high Sharpe ratio whether \(\theta\) takes \(10^{-1}\) or \(10^{-2}\).

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline  & \(\frac{1}{\theta}\) = 10\({}^{-1}\) & \(\frac{1}{\theta}\) = 10\({}^{-2}\) & & \(\frac{1}{\theta}\) = 10\({}^{-1}\) & \(\frac{1}{\theta}\) = 10\({}^{-2}\) \\ \cline{2-6} Layer & Mean F1 & Mean F1 & Layer & Mean F1 & Mean F1 \\ \hline CvxpyLayers & 0.616 & 0.605 & OptNet & 0.619 & 0.613 \\ LinSAT-Dense-100 & 0.619 & 0.614 & LinSAT-Dense-500 & \(\times\) & \(\times\) \\ GLinSAT-Dense-Explicit & **0.620** & **0.620** & GLinSAT-Dense-Implicit & 0.619 & **0.620** \\ LinSAT-Sparse-100 & **0.620** & 0.618 & LinSAT-Sparse-500 & 0.619 & 0.611 \\ GLinSAT-Sparse-Explicit & 0.619 & **0.620** & GLinSAT-Sparse-Implicit & **0.620** & **0.620** \\ \hline \hline \end{tabular}
\end{table}
Table 4: Mean F1 scores across different satisfiability layers in partial graph matching problem

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline  & \(\frac{1}{\theta}\) = 10\({}^{-1}\) & \(\frac{1}{\theta}\) = 10\({}^{-2}\) & & \(\frac{1}{\theta}\) = 10\({}^{-1}\) & \(\frac{1}{\theta}\) = 10\({}^{-2}\) \\ \cline{2-6} Layer & S. Ratio & S. Ratio & Layer & S. Ratio & S. Ratio \\ \hline CvxpyLayers & 2.535 & **2.600** & OptNet & **2.553** & 2.381 \\ LinSAT-Dense-100 & 2.245 & 2.409 & LinSAT-Dense-500 & 2.245 & 2.409 \\ GLinSAT-Dense-Explicit & 2.535 & **2.608** & GLinSAT-Dense-Implicit & 2.535 & **2.608** \\ LinSAT-Sparse-100 & 2.245 & 2.409 & LinSAT-Sparse-500 & 2.245 & 2.409 \\ GLinSAT-Sparse-Explicit & 2.535 & **2.608** & GLinSAT-Sparse-Implicit & 2.535 & **2.608** \\ \hline \hline \end{tabular}
\end{table}
Table 5: Mean Sharpe ratio obtained from different satisfiability layers in portfolio allocation problem 

### Power system unit commitment

In this section, we carry out experiments about the unit commitment problem on a real provincial power system. In the unit commitment problem, there are hard constraints and soft constraints. Generally, constraints directly related to generators are regarded as hard constraints, e.g. the generator logical constraints, generator minimum up-time and down-time constraints. Constraints related to the section power and load balance are usually regarded as soft constraints where violation with large penalty coefficient is introduced in the objective [35]. The unit commitment problem can be formulated into a mixed-integer linear programming (MILP) problem, which is detailed in Appendix A.11. Based on one-year power system load data, we first use Gurobi [36] to solve the MILP within a 0.1% optimality gap.

After obtaining the integer solution of the unit commitment problem, we then use supervised learning to train neural networks with satisfiability layers so that they can predict the optimal state of a unit while satisfying logical constraints, minimum up-time and down-time constraints. As pointed by [37], when we consider logical constraints and minimum up-time and down-time constraints, these constraints formulate a convex hull so that the extreme points of the corresponding feasible region are binary. As a result, we could expect that the outputs of satisfiability layers tend to be binary when \(1/\theta\to 0\), thereby making all constraints, including integer constraints, more likely to be satisfied after rounding operations. Once we obtain the predicted integer commitment status of the generators, we can fix the integer variables in the unit commitment problem and solve the corresponding linear programming problem, thereby providing a good initial point for the original mixed-integer programming problem.

Since negative coefficients occur in constraints, LinSAT cannot be used. In Table A.5 of Appendix A.11, we compare the performance of batch processing with different layers. When we stack constraints into block diagonal form to exploit parallelism, there are about 1000000 rows and 2000000 columns in the matrix. GLinSAT-Sparse-Implicit is the only way that will not report out-of-memory issues when we use GLinSAT. Both CvxpyLayers and OptNet cannot directly handle such a giant matrix within reasonable time thus we can only use a sequential way instead.

We train neural networks with \(\frac{1}{\theta}=0.1\). Table 6 shows the feasibility ratio and average gap on feasible solutions obtained from fixing unit state variables to rounded outputs of neural networks and then solving the continuous unit commitment problem in validation stage. Since CvxpyLayers and OptNet are significantly slower than GLinSAT, we are unable to obtain trained models within reasonable time and the results are not included in Table 6. Table 6 shows that if we use sigmoid function to replace the satisfiability layer in training and validation, we cannot obtain any feasible solution. As \(\frac{1}{\theta}\to 0\), the feasibility ratio increases. When using GLinSAT with \(\frac{1}{\theta}\leq 0.0005\), the feasibility ratio reaches 100%. In addition, when we set \(\frac{1}{\theta}\) to exactly zero and solve the resulted projection problem in the form of linear programming (LP) via Gurobi, 100% feasible solutions are also found.

## 4 Conclusion

In this paper, we reformulate the neural network output projection problem into a convex optimization problem with Lipschitz continuous gradient. We then propose GLinSAT, a general linear satisfiability layer to impose linear constraints on neural network outputs where all the operations are differentiable and matrix-factorization-free. GLinSAT can fully leverage the parallel computing capabilities of the GPU. We showcase four applications of GLinSAT and the advantages of our proposed framework over existing satisfiability layers are illustrated.

\begin{table}
\begin{tabular}{c c c c c} \hline \hline Training final layer & Validation final layer & \(1/\theta\) & Feasibility Ratio & Average Gap \\ \hline Sigmoid & Sigmoid & — & 0\% & — \\ GLinSAT-Sparse-Implicit & GLinSAT-Sparse-Implicit & 0.01 & 86.23\% & 0.1119\% \\ GLinSAT-Sparse-Implicit & GLinSAT-Sparse-Implicit & 0.005 & 95.41\% & 0.1381\% \\ GLinSAT-Sparse-Implicit & GLinSAT-Sparse-Implicit & 0.001 & 98.17\% & **0.1109\%** \\ GLinSAT-Sparse-Implicit & GLinSAT-Sparse-Implicit & 0.0005 & **100\%** & 0.1114\% \\ GLinSAT-Sparse-Implicit & GLinSAT-Sparse-Implicit & 0.0001 & **100\%** & 0.1114\% \\ GLinSAT-Sparse-Implicit & Gurobi-LP & 0 & **100\%** & 0.1114\% \\ \hline \hline \end{tabular}
\end{table}
Table 6: Feasibility ratio and average gap obtained from using different \(1/\theta\) in validation

## Acknowledgments and Disclosure of Funding

This work was supported in part by the National Natural Science Foundation of China under Grant U22B2097, 52321004 and in part by Alibaba Innovative Research Program. We would like to express our sincerest gratitude to the anonymous reviewers for their insightful feedback on our work. We are also immensely thankful to Wotao Yin for his invaluable support throughout the research process.

## References

* [1] Nikolaos Karalias and Andreas Loukas. Erdos goes neural: an unsupervised learning framework for combinatorial optimization on graphs. _Advances in Neural Information Processing Systems_, 33:6659-6672, 2020.
* [2] Steven Bohez, Abbas Abdolmaleki, Michael Neunert, Jonas Buchli, Nicolas Heess, and Raia Hadsell. Value constrained model-free continuous control. _arXiv preprint arXiv:1902.04623_, 2019.
* [3] Abhinav Bhatia, Pradeep Varakantham, and Akshat Kumar. Resource constrained deep reinforcement learning. In _Proceedings of the International Conference on Automated Planning and Scheduling_, volume 29, pages 610-620, 2019.
* [4] Runzhong Wang, Li Shen, Yiting Chen, Xiaokang Yang, Dacheng Tao, and Junchi Yan. Towards one-shot neural combinatorial solvers: Theoretical and empirical notes on the cardinality-constrained case. In _The Eleventh International Conference on Learning Representations_, 2022.
* [5] Tianyu Zhao, Xiang Pan, Minghua Chen, and Steven H Low. Ensuring dnn solution feasibility for optimization problems with convex constraints and its application to dc optimal power flow problems. _The Eleventh International Conference on Learning Representations_, 2023.
* [6] Daniel Tabas and Baosen Zhang. Computationally efficient safe reinforcement learning for power systems. In _2022 American Control Conference (ACC)_, pages 3303-3310. IEEE, 2022.
* [7] Jesus Tordesillas, Jonathan P How, and Marco Hutter. Rayen: Imposition of hard convex constraints on neural networks. _arXiv preprint arXiv:2307.08336_, 2023.
* [8] Irwan Bello, Hieu Pham, Quoc V Le, Mohammad Norouzi, and Samy Bengio. Neural combinatorial optimization with reinforcement learning. _arXiv preprint arXiv:1611.09940_, 2016.
* [9] Elias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and Le Song. Learning combinatorial optimization algorithms over graphs. _Advances in neural information processing systems_, 30, 2017.
* [10] Marin Vlastelica Pogancic, Anselm Paulus, Vit Musil, Georg Martius, and Michal Rolinek. Differentiation of blackbox combinatorial solvers. In _International Conference on Learning Representations_, 2019.
* [11] Quentin Berthet, Mathieu Blondel, Olivier Teboul, Marco Cuturi, Jean-Philippe Vert, and Francis Bach. Learning with differentiable pertubed optimizers. _Advances in neural information processing systems_, 33:9508-9519, 2020.
* [12] Anselm Paulus, Michal Rolinek, Vit Musil, Brandon Amos, and Georg Martius. Comboptnet: Fit the right np-hard problem by learning integer programming constraints. In _International Conference on Machine Learning_, pages 8443-8453. PMLR, 2021.
* [13] Rodrigo Santa Cruz, Basura Fernando, Anoop Cherian, and Stephen Gould. Deeppermnet: Visual permutation learning. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_, pages 3949-3957, 2017.
* [14] Runzhong Wang, Junchi Yan, and Xiaokang Yang. Learning combinatorial embedding networks for deep graph matching. In _Proceedings of the IEEE/CVF international conference on computer vision_, pages 3056-3065, 2019.

* Cuturi et al. [2019] Marco Cuturi, Olivier Teboul, and Jean-Philippe Vert. Differentiable ranking and sorting using optimal transport. _Advances in neural information processing systems_, 32, 2019.
* Sinkhorn and Knopp [1967] Richard Sinkhorn and Paul Knopp. Concerning nonnegative matrices and doubly stochastic matrices. _Pacific Journal of Mathematics_, 21(2):343-348, 1967.
* Cuturi [2013] Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. _Advances in neural information processing systems_, 26, 2013.
* Chakrabarty and Khanna [2021] Deeparnab Chakrabarty and Sanjeev Khanna. Better and simpler error analysis of the sinkhorn-knopp algorithm for matrix scaling. _Mathematical Programming_, 188(1):395-407, 2021.
* Wang et al. [2019] Po-Wei Wang, Priya Donti, Bryan Wilder, and Zico Kolter. Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver. In _International Conference on Machine Learning_, pages 6545-6554. PMLR, 2019.
* Wang et al. [2023] Runzhong Wang, Yunhao Zhang, Ziao Guo, Tianyi Chen, Xiaokang Yang, and Junchi Yan. Linsatnet: the positive linear satisfiability neural networks. In _International Conference on Machine Learning_, pages 36605-36625. PMLR, 2023.
* Mezghani et al. [2023] Salma Mezghani, Boukhir Haddar, and Habib Chabchoub. The evolution of the rectangular bin packing problem-a review of research topics, applications, and cited papers. 2023.
* Floudas and Lin [2005] Christodoulos A Floudas and Xiaoxia Lin. Mixed integer linear programming in process scheduling: Modeling, algorithms, and applications. _Annals of Operations Research_, 139:131-162, 2005.
* Knueven et al. [2020] Bernard Knueven, James Ostrowski, and Jean-Paul Watson. On mixed-integer programming formulations for the unit commitment problem. _INFORMS Journal on Computing_, 32(4):857-876, 2020.
* Agrawal et al. [2019] Akshay Agrawal, Brandon Amos, Shane Barratt, Stephen Boyd, Steven Diamond, and J Zico Kolter. Differentiable convex optimization layers. _Advances in neural information processing systems_, 32, 2019.
* Amos and Kolter [2017] Brandon Amos and J Zico Kolter. Optnet: Differentiable optimization as a layer in neural networks. In _International Conference on Machine Learning_, pages 136-145. PMLR, 2017.
* Rennich et al. [2016] Steven C Rennich, Darko Stosic, and Timothy A Davis. Accelerating sparse cholesky factorization on gpus. _Parallel Computing_, 59:140-150, 2016.
* Tang et al. [2017] Meng Tang, Mohamed Gadou, and Sanjay Ranka. A multithreaded algorithm for sparse cholesky factorization on hybrid multicore architectures. _Procedia Computer Science_, 108:616-625, 2017.
* Davis et al. [2016] Timothy A Davis, Sivasankaran Rajamanickam, and Wissam M Sid-Lakhdar. A survey of direct methods for sparse linear systems. _Acta Numerica_, 25:383-566, 2016.
* Wilder et al. [2019] Bryan Wilder, Bistra Dilkina, and Milind Tambe. Melding the data-decisions pipeline: Decision-focused learning for combinatorial optimization. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 33, pages 1658-1665, 2019.
* Dvurechensky et al. [2018] Pavel Dvurechensky, Alexander Gasnikov, and Alexey Kroshnin. Computational optimal transport: Complexity by accelerated gradient descent is better than by sinkhorn's algorithm. In _International conference on machine learning_, pages 1367-1376. PMLR, 2018.
* Everingham et al. [2010] Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. The pascal visual object classes (voc) challenge. _International journal of computer vision_, 88:303-338, 2010.
* Bourdev and Malik [2009] Lubomir Bourdev and Jitendra Malik. Poselets: Body part detectors trained using 3d human pose annotations. In _2009 IEEE 12th international conference on computer vision_, pages 1365-1372. IEEE, 2009.

* [33] Michal Rolinek, Paul Swoboda, Dominik Zietlow, Anselm Paulus, Vit Musil, and Georg Martius. Deep graph matching via blackbox differentiation of combinatorial solvers. In _Computer Vision-ECCV 2020: 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part XXVIII 16_, pages 407-424. Springer, 2020.
* [34] William F Sharpe. The sharpe ratio. _Streetwise-the Best of the Journal of Portfolio Management_, 3:169-185, 1998.
* [35] Jianghua Wu, Peter B Luh, Yonghong Chen, Mikhail A Bragin, and Bing Yan. A novel optimization approach for sub-hourly unit commitment with large numbers of units and virtual transactions. _IEEE Transactions on Power Systems_, 37(5):3716-3725, 2021.
* [36] Gurobi optimization. [Online]. Available: https://www.gurobi.com.
* [37] Deepak Rajan, Samer Takriti, et al. Minimum up/down polytopes of the unit commitment problem with start-up costs. _IBM Res. Rep_, 23628:1-14, 2005.
* [38] Martin WP Savelsbergh. Preprocessing and probing techniques for mixed integer programming problems. _ORSA Journal on Computing_, 6(4):445-454, 1994.
* [39] Armin Fugenschuh and Alexander Martin. Computational integer programming and cutting planes. _Handbooks in Operations Research and Management Science_, 12:69-121, 2005.
* [40] Tobias Achterberg. Constraint integer programming. 2007.
* [41] Tobias Achterberg, Robert E Bixby, Zonghao Gu, Edward Rothberg, and Dieter Weninger. Presolve reductions in mixed integer programming. _INFORMS Journal on Computing_, 32(2):473-506, 2020.
* [42] Ambros Gleixner, Leona Gottwald, and Alexander Hoen. Papilo: A parallel presolving library for integer and linear optimization with multiprecision support. _INFORMS Journal on Computing_, 35(6):1329-1341, 2023.
* [43] Runzhong Wang, Junchi Yan, and Xiaokang Yang. Neural graph matching network: Learning lawler's quadratic assignment problem with extension to hypergraph and multiple-graph matching. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 44(9):5261-5279, 2021.
* [44] Defu Cao, Yujing Wang, Juanyong Duan, Ce Zhang, Xia Zhu, Congrui Huang, Yunhai Tong, Bixiong Xu, Jing Bai, Jie Tong, et al. Spectral temporal graph neural network for multivariate time-series forecasting. _Advances in neural information processing systems_, 33:17766-17778, 2020.

Appendix

### Related Work

**Constraints handling paradigm in neural networks for decision making**. Some simple constraints can be directly encoded by neural network activation functions, e.g., ReLU function for non-negative constraints, sigmoid function for bounded constraints, softmax function for sum-to-one constraints. However, it is difficult for neural network outputs to satisfy complicated constraints by only using these activation functions. For a few problems with special structures, the constraints can be directly handled by the well-designed action space of sequential decisions in reinforcement learning [8; 9]. However, as the complexity of constraints increases, it will be hard to design a suitable action space. Considering the difficulty for agents to find feasible solutions through random exploration, the resulting sparse rewards may also lead to slow convergence. Another common way to deal with constraint violation is to penalize such violation in the training stage. Ref. [1] incorporates the constraint violation in the loss function of supervised learning. Ref. [2; 3] augment the reward function in reinforcement learning with the sum of the constraint violation penalty weighted by the Lagrange multipliers. However, it cannot be guaranteed that the constraints can be always satisfied by directly penalizing the constraint violation, see Ref. [4]. Ref. [5; 6; 7] are better suited for inequality constraint satisfaction. These methods may encounter difficulties in satisfying equality constraints, either in terms of efficiency or expressiveness. Another way to handle constraints is to incorporate optimization solvers into neural network layers, which is detailed in the next paragraph.

**Optimizers as neural network layers for constraint satisfaction**. To integrate optimizers into neural networks, it is necessary to calculate derivatives with respect to the parameters and perform batch processing efficiently. Ref. [10; 11; 12] exploit black-box solvers to impose combinatorial constraints on decision variables. However, only approximated gradients can be obtained through perturbations on the problem. Ref [19] relax the original combinatorial constraint into the positive semi-definite matrix constraint with unit diagonals and integrates GPU-based MAXSAT solver into neural network layers. In Ref. [13; 14; 15], Sinkhorn algorithm [16; 17; 18] is used to make neural network outputs satisfy the double stochastic matrix constraint, which is a linear relaxation of permutation, matching and sorting constraints. Since Sinkhorn algorithm only involves iterative normalization of rows and columns in matrices, it is straightforward to parallel the operations on GPUs and calculate the derivatives based on automatic differential mechanism. Ref. [25] presents OptNet, a neural network layer that integrates a GPU-based batched quadratic programming solver, qpth. The forward pass exploits a primal-dual interior point method to find the solution and the derivatives are calculated based on the matrix factorization obtained from the forward propagation. Ref. [24] further presents CvxpyLayers to incorporate convex programming into neural network layers. Although CvxpyLayers can represent more optimization problems, it relies on CPUs for parallelism which may lead to efficiency issues if a large batch of optimization problems needs solving. Ref. [20] designs LinSAT, a differentiable layer to encode the positive linear constraints based on a multi-set Sinkhorn algorithm. Although such an algorithm is easy to be parallel on GPUs, it can only imposing positive linear constraints on neural network outputs.

### Broader Impacts

This paper is aimed at making the outputs of neural networks satisfy bounded and general linear constraints. The proposed framework GLinSAT can be used for end-to-end neural network training while ensuring the feasibility of neural network outputs, providing a promising approach for applying neural networks to decision-making problems. There is no foreseeable negative societal consequence that is a direct result of the proposed method.

### Limitations

In this paper, we manage to impose bounded and linear constraints on neural network outputs. Considering that real-life decision variables often have finite upper and lower bounds simultaneously, our proposed method can actually be applied to a lot of decision-making problems. However, for variables with one-sided boundary or no explicit boundary, our method cannot be directly used. A possible workaround is to manually calculate the implicit bounds of these variables through domain propagation, see [38; 39; 40; 41; 42]. In addition, it should be noted that currently our algorithm can only deal with linear constraints. In the future, we need to conduct further research on neural network layers that can efficiently handle cone constraints on GPUs.

### Reformulation of general linear constraints with bounded variables into standard form

Denote \(\bm{c}^{\prime}\in\mathbb{R}^{n^{\prime}}\) as the output of an neural network. In this section, we consider projecting the output of the neural network \(\bm{x}^{\prime}\in\mathbb{R}^{n^{\prime}}\) into variables \(\bm{x}^{\prime}\in\mathbb{R}^{n^{\prime}}\) that satisfy the following linear constraints and bounded constraints:

\[\bm{A}_{1}^{\prime}\bm{x}^{\prime} \leq\bm{b}_{1}^{\prime}\] (A.1a) \[\bm{A}_{2}^{\prime}\bm{x}^{\prime} \geq\bm{b}_{2}^{\prime}\] (A.1b) \[\bm{A}_{3}^{\prime}\bm{x}^{\prime} =\bm{b}_{3}^{\prime}\] (A.1c) \[\bm{l}^{\prime} \leq\bm{x}^{\prime}\leq\bm{u}^{\prime}\] (A.1d)

where \(\bm{A}_{1}^{\prime}\in\mathbb{R}^{m_{1}^{\prime}\times n^{\prime}}\), \(\bm{b}_{1}^{\prime}\in\mathbb{R}^{m_{1}^{\prime}}\), \(\bm{A}_{2}^{\prime}\in\mathbb{R}^{m_{2}^{\prime}\times n^{\prime}}\), \(\bm{b}_{2}^{\prime}\in\mathbb{R}^{m_{2}^{\prime}}\), \(\bm{A}_{3}^{\prime}\in\mathbb{R}^{m_{3}^{\prime}\times n^{\prime}}\), \(\bm{b}_{3}^{\prime}\in\mathbb{R}^{m_{3}^{\prime}}\), \(\bm{l}\in\mathbb{R}^{n^{\prime}}\), \(\bm{u}^{\prime}\in\mathbb{R}^{n^{\prime}}\).

Obviously, we can convert all inequality constraints into equality constraints by introducing bounded slack variables as follows:

\[\bm{A}_{1}^{\prime}\bm{x}^{\prime}+\bm{s}_{1}^{\prime} =\bm{b}_{1}\] (A.2a) \[\bm{A}_{2}^{\prime}\bm{x}^{\prime}-\bm{s}_{2}^{\prime} =\bm{b}_{2}\] (A.2b) \[\bm{A}_{3}^{\prime}\bm{x}^{\prime} =\bm{b}_{3}^{\prime}\] (A.2c) \[\bm{l}^{\prime} \leq\bm{x}^{\prime}\leq\bm{u}^{\prime}\] (A.2d) \[\bm{0} \leq\bm{s}_{1}^{\prime} \leq\overline{\bm{s}_{1}^{\prime}}\] (A.2e) \[\bm{0} \leq\bm{s}_{2}^{\prime}\leq\overline{\bm{s}_{2}^{\prime}}\] (A.2f)

where \(\overline{\bm{s}_{1}^{\prime}}=\bm{b}_{1}-\bm{A}_{1}^{+^{\prime}}\bm{l}^{ \prime}-\bm{A}_{1}^{-^{\prime}}\bm{u}^{\prime}\), \(\overline{\bm{s}_{2}^{\prime}}=\bm{A}_{2}^{+^{\prime}}\bm{u}^{\prime}+\bm{A}_ {2}^{-^{\prime}}\bm{l}^{\prime}-\bm{b}_{2}\), \(\bm{A}_{1+}^{\prime},\bm{A}_{2+}^{\prime}\) and \(\bm{A}_{1-}^{\prime},\bm{A}_{2-}^{\prime}\) are the positive and negative parts of matrix \(\bm{A}_{1}^{\prime},\bm{A}_{2}^{\prime}\) respectively.

We use the following notation:

\[\bm{x}=\left[\begin{array}{c}\bm{x}^{\prime}-\bm{l}^{\prime}\\ \bm{s}_{1}^{\prime}\\ \bm{s}_{2}^{\prime}\end{array}\right],\bm{A}=\left[\begin{array}{cc}\bm{A}_ {1}^{\prime}&\bm{I}\\ \bm{A}_{2}^{\prime}&-\bm{I}\\ \bm{A}_{3}^{\prime}&\end{array}\right],\bm{b}=\left[\begin{array}{c}\bm{b}_ {1}^{\prime}-\bm{A}_{1}^{\prime}\bm{l}^{\prime}\\ \bm{b}_{2}^{\prime}-\bm{A}_{2}^{\prime}\bm{l}^{\prime}\\ \bm{b}_{3}^{\prime}\end{array}\right],\bm{c}=\left[\begin{array}{c}\bm{c}^{ \prime}\\ \bm{0}\\ \bm{0}\end{array}\right],\bm{u}=\left[\begin{array}{c}\bm{u}^{\prime}-\bm{l}^ {\prime}\\ \overline{\bm{s}_{1}^{\prime}}\\ \overline{\bm{s}_{2}^{\prime}}\end{array}\right]\]

Then, the original problem is transformed into a problem of projecting \(\bm{c}\in\mathbb{R}^{n^{\prime}+m_{1}^{\prime}+m_{2}^{\prime}}\) onto variables \(\bm{x}\in\mathbb{R}^{n^{\prime}+m_{1}^{\prime}+m_{2}^{\prime}}\) that satisfy the following linear constraints and bounded constraints:

\[\bm{A}\bm{x}=\bm{b}\] (A.3a) \[\bm{0}\leq\bm{x}\leq\bm{u}\] (A.3b)

### Property of the primal and dual objective function

We first show that the primal objective function \(f\left(\bm{x}\right)\) is strongly convex, where \(f\left(\bm{x}\right)\) is:

\[f\left(\bm{x}\right)=-\bm{c}^{T}\bm{x}+\frac{1}{\theta}\sum_{j=1}^{n}\left( \frac{x_{j}}{u_{j}}\log\frac{x_{j}}{u_{j}}+\left(1-\frac{x_{j}}{u_{j}}\right) \log\left(1-\frac{x_{j}}{u_{j}}\right)\right)\] (A.4)

The second order derivative of \(f\left(\bm{x}\right)\) can be expressed as follows:

\[\nabla^{2}f\left(\bm{x}\right)=\frac{1}{\theta}\mathbf{diag}\left(\frac{\bm{1}} {\bm{x}\circ\left(\bm{u}-\bm{x}\right)}\right)\] (A.5)

where \(\mathbf{diag}\left(\cdot\right)\) maps a vector to its corresponding diagonal matrix, \(\circ\) represents the element-wise product, \(\frac{1}{\bm{z}}\) represents the element-wise reciprocal of vector \(\bm{z}\).

Since we have \(\bm{0}\leq\bm{x}\leq\bm{u}\), we have \(\bm{x}\circ\left(\bm{u}-\bm{x}\right)\leq\frac{\bm{u}}{2}\circ\frac{\bm{u}}{2}= \frac{1}{4}\bm{u}\circ\bm{u}\). As a result, we have \(\nabla^{2}f\left(\bm{x}\right)\succeq\frac{4}{\theta\max\left(\bm{u}\right)^{2} }\bm{I}\), which means \(f\) is a \(\frac{4}{\theta\max\left(\bm{u}\right)^{2}}\)-strongly convex function.

We next show that the gradient of the opposite dual objective function \(\nabla\left(-g\left(\bm{y}\right)\right)\) is Lipschitz continuous, where \(-g\left(\bm{y}\right)\) is:

\[-g\left(\bm{y}\right)=-\frac{1}{\theta}\bm{1}^{T}\mathbf{log}\,\bm{\sigma} \left(\theta\bm{u}\circ\left(-\bm{c}-\bm{A}^{T}\bm{y}\right)\right)-\bm{b}^{T }\bm{y}\] (A.6)

The first order derivative of \(-g\left(\bm{y}\right)\) can be expressed as follows:

\[\nabla\left(-g\left(\bm{y}\right)\right)=\bm{A}\bm{x}\left(\bm{y}\right)-\bm{b}\] (A.7)

where \(\bm{x}\left(\bm{y}\right)=\bm{u}\circ\bm{\sigma}\left(-\theta\bm{u}\circ\left( -\bm{c}-\bm{A}^{T}\bm{y}\right)\right)\).

Using the first order derivative of \(-g\left(\bm{y}\right)\), we have:

\[\left\|\nabla\left(-g\left(\bm{y}_{1}\right)\right)-\nabla\left(-g\left(\bm{ y}_{2}\right)\right)\right\|_{2}=\left\|\bm{A}\left(\bm{x}\left(\bm{y}_{1} \right)-\bm{x}\left(\bm{y}_{2}\right)\right)\right\|_{2}\leq\left\|\bm{A} \right\|_{2}\left\|\bm{x}\left(\bm{y}_{1}\right)-\bm{x}\left(\bm{y}_{2} \right)\right\|_{2}\] (A.8)

According to equation the strong convexity of \(f\left(\bm{x}\right)\), we have:

\[\begin{split}&\frac{4}{\theta\max\left(\bm{u}\right)^{2}}\|\bm{x} \left(\bm{y}_{1}\right)-\bm{x}\left(\bm{y}_{2}\right)\|_{2}^{2}\leq\left( \nabla f\left(\bm{x}\left(\bm{y}_{1}\right)\right)-\nabla f\left(\bm{x}\left( \bm{y}_{2}\right)\right)\right)^{T}\left(\bm{x}\left(\bm{y}_{1}\right)-\bm{x} \left(\bm{y}_{2}\right)\right)\\ &=\left(\left(-\bm{c}+\frac{\bm{1}}{\theta\bm{u}}\circ\mathbf{ log}\,\frac{\bm{x}\left(\bm{y}_{1}\right)}{\bm{u}-\bm{x}\left(\bm{y}_{1}\right)} \right)-\left(-\bm{c}+\frac{\bm{1}}{\theta\bm{u}}\circ\mathbf{log}\,\frac{\bm{ x}\left(\bm{y}_{2}\right)}{\bm{u}-\bm{x}\left(\bm{y}_{2}\right)}\right) \right)^{T}\left(\bm{x}\left(\bm{y}_{1}\right)-\bm{x}\left(\bm{y}_{2}\right) \right)\\ &=\left(\bm{A}\left(\bm{y}_{1}-\bm{y}_{2}\right)\right)^{T}\left( \bm{x}\left(\bm{y}_{1}\right)-\bm{x}\left(\bm{y}_{2}\right)\right)\leq\left\| \bm{A}\right\|_{2}\left\|\bm{y}_{1}-\bm{y}_{2}\right\|_{2}\left\|\bm{x}\left( \bm{y}_{1}\right)-\bm{x}\left(\bm{y}_{2}\right)\right\|_{2}\end{split}\] (A.9)

which implies:

\[\left\|\bm{x}\left(\bm{y}_{1}\right)-\bm{x}\left(\bm{y}_{2}\right)\right\|_{2} \leq\frac{\theta\max\left(\bm{u}\right)^{2}\left\|\bm{A}\right\|_{2}}{4} \left\|\bm{y}_{1}-\bm{y}_{2}\right\|_{2}\] (A.10)

Combining equation (A.8) and (A.10), we have:

\[\left\|\nabla\left(-g\left(\bm{y}_{1}\right)\right)-\nabla\left(-g\left(\bm{ y}_{2}\right)\right)\right\|_{2}\leq\frac{\theta\max\left(\bm{u}\right)^{2} \left\|\bm{A}\right\|_{2}^{2}}{4}\left\|\bm{y}_{1}-\bm{y}_{2}\right\|_{2}\] (A.11)

which means that \(\nabla\left(-g\left(\bm{y}\right)\right)\) is \(\frac{\theta\max\left(\bm{u}\right)^{2}\left\|\bm{A}\right\|_{2}^{2}}{4}\)-Lipschitz continuous.

### Time Complexity of Algorithm 1

According to Theorem 2 in the supplementary material of [30], the \(l_{2}\)-norm of \(\bm{A}\bm{x}^{\left(k\right)}-\bm{b}\) at the \(k\)-th iteration is bounded by \(16LR/k^{2}\), where \(L\) is the Lipschitz constant of the gradient of the dual objective function, \(R\) is the upper bound of \(l_{2}\)-norm of the optimal dual variables. Since we have shown that \(\nabla\left(-g\left(\bm{y}\right)\right)\) is \(\frac{\theta\max\left(\bm{u}\right)^{2}\left\|\bm{A}\right\|_{2}^{2}}{4}\)-Lipschitz in Appendix A.5, we can see that:

\[\left\|\bm{A}\bm{x}^{\left(k\right)}-\bm{b}\right\|_{2}\leq\frac{4\theta\max \left(\bm{u}\right)^{2}\left\|\bm{A}\right\|_{2}^{2}R}{k^{2}}\] (A.12)

Let \(\left\|\bm{A}\bm{x}^{\left(k\right)}-\bm{b}\right\|_{2}=\varepsilon\), We can obtain the upper bound of outer cycle iteration number as follows:

\[k\leq 2\max\left(\bm{u}\right)\left\|\bm{A}\right\|_{2}\sqrt{\frac{\theta R}{ \varepsilon}}\] (A.13)

According to Theorem 1 in the supplementary material of [30], the number of all the iterations after an iteration \(k\) is \(O\left(k\right)\). Therefore, the time complexity of Algorithm 1 is \(O\left(\max\left(\bm{u}\right)\left\|\bm{A}\right\|_{2}\sqrt{\theta R/\varepsilon}\right)\). As a result, for optimization problems that with similar upper bounds of dual variables, the required iteration number is approximately proportional to \(\sqrt{\theta/\varepsilon}\). Such time complexity is better than the complexity of sinkhorn-based algorithms, in which the iteration number is approximately proportional to \(\theta/\varepsilon^{2}\), see [18, 20].

### Derivative Calculation in the backward pass of GLinSAT

The optimality condition can be expressed as follows:

\[\bm{h}\left(\bm{y}\right)=\bm{A}\left(\bm{u}\circ\bm{\sigma}\left(-\theta\bm{u} \circ\left(-\bm{c}-\bm{A}^{T}\bm{y}\right)\right)\right)-\bm{b}=\bm{0}\] (A.14)

Let \(\bm{v}=\bm{A}\) or \(\bm{b}\) or \(\bm{c}\) or \(\bm{u}\), according to chain rule, we have:

\[\frac{\partial l}{\partial\bm{v}}=\frac{\partial l}{\partial\bm{x}}\frac{ \partial\bm{x}}{\partial\bm{v}}+\frac{\partial l}{\partial\bm{x}}\frac{ \partial\bm{x}}{\partial\bm{y}}\frac{\partial\bm{y}}{\partial\bm{v}}+\frac{ \partial l}{\partial\bm{y}}\frac{\partial\bm{y}}{\partial\bm{v}}=\frac{ \partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial\bm{v}}-\left(\frac{ \partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial\bm{y}}+\frac{ \partial l}{\partial\bm{y}}\right)\left(\frac{\partial\bm{h}}{\partial\bm{y}} \right)^{-1}\frac{\partial\bm{h}}{\partial\bm{v}}\] (A.15)

where \(\bm{x}\left(\bm{y}\right)=\bm{u}\circ\bm{\sigma}\left(-\theta\bm{u}\circ\left( -\bm{c}-\bm{A}^{T}\bm{y}\right)\right)\).

We can first calculate \(\frac{\partial x_{q}}{\partial y_{p}}\) as follows:

\[\frac{\partial x_{q}}{\partial y_{p}}=\theta x_{q}(u_{q}-x_{q})A_{pq}\] (A.16)

By writing the above equation into matrix form, we have:

\[\frac{\partial\bm{x}}{\partial\bm{y}}=\textbf{diag}(\theta\bm{x}\circ(\bm{u}- \bm{x}))\bm{A}^{T}\] (A.17)

In the actual computation process, the matrix \(\frac{\partial\bm{x}}{\partial\bm{y}}\) is not explicitly formulated for saving GPU memory. Instead, we directly formulate the derivatives \(\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial A_{pq}}\), \(\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial b_{p}}\), \(\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial c_{q}}\), \(\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial u_{q}}\), \(\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial y_{p}}\) in (A.15) as follows:

\[\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial A _{pq}}=\frac{\partial l}{\partial x_{q}}\frac{\partial x_{q}}{\partial A_{pq}}= \frac{\partial l}{\partial x_{q}}\theta x_{q}\left(u_{q}-x_{q}\right)y_{p}\] (A.18a) \[\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial b _{p}}=0\] (A.18b) \[\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial c _{q}}=\frac{\partial l}{\partial x_{q}}\frac{\partial x_{q}}{\partial c_{q}}= \frac{\partial l}{\partial x_{q}}\theta x_{q}\left(u_{q}-x_{q}\right)\] (A.18c) \[\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial u _{q}}=\frac{\partial l}{\partial x_{q}}\frac{\partial x_{q}}{\partial u_{q}}= \frac{\partial l}{\partial x_{q}}\frac{x_{q}-\theta x_{q}\left(u_{q}-x_{q} \right)\left(-c_{q}-\sum\limits_{i=1}^{m}y_{i}A_{iq}\right)}{u_{q}}\] (A.18d) \[\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial y _{p}}=\sum\limits_{q=1}^{n}\frac{\partial l}{\partial x_{q}}\frac{\partial x_{ q}}{\partial y_{p}}=\sum\limits_{q=1}^{n}\frac{\partial l}{\partial x_{q}} \theta x_{q}\left(u_{q}-x_{q}\right)A_{pq}\] (A.18e)

By writing the above equations into matrix form, we have:

\[\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial\bm{A}} =\bm{y}\left(\frac{\partial l}{\partial\bm{x}}\circ\theta\bm{x} \circ(\bm{u}-\bm{x})\right)^{T}\] (A.19a) \[\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial\bm {b}} =\bm{0}\] (A.19b) \[\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial\bm {c}} =\frac{\partial l}{\partial\bm{x}}\circ\theta\bm{x}\circ(\bm{u}-\bm{x})\] (A.19c) \[\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial\bm {u}} =\frac{\partial l}{\partial\bm{x}}\circ\left(\frac{\bm{x}-\theta\bm{x} \circ(\bm{u}-\bm{x})\circ\left(-\bm{c}-\bm{A}^{T}\bm{y}\right)}{\bm{u}}\right)\] (A.19d) \[\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial\bm {y}} =\bm{A}\left(\frac{\partial l}{\partial\bm{x}}\circ\theta\bm{x}\circ(\bm{u}- \bm{x})\right)\] (A.19e)

We then calculate \(\frac{\partial h_{p}}{\partial y_{q}}\) as follows:

\[\frac{\partial h_{p}}{\partial y_{q}}=\sum\limits_{j=1}^{n}A_{pj}\theta x_{j} \left(u_{j}-x_{j}\right)A_{qj}\] (A.20)By writing the above equations into matrix form, we have:

\[\frac{\partial\bm{h}}{\partial\bm{y}}=\bm{A}\mathbf{diag}\left(\theta\bm{x} \circ\left(\bm{u}-\bm{x}\right)\right)\bm{A}^{T}\] (A.21)

where \(\mathbf{diag}\left(\cdot\right)\) maps a vector to its corresponding diagonal matrix. When \(\bm{x}\) is the optimal solution, we have \(\bm{0}<\bm{x}<\bm{u}\). Therefore, \(\bm{A}\mathbf{diag}\left(\theta\bm{x}\circ\left(\bm{u}-\bm{x}\right)\right) \bm{A}^{T}\) is a positive semi-definite matrix.

Here, we denote \(\left(\frac{\partial l}{\partial\bm{x}}\frac{\partial\bm{x}}{\partial\bm{y}}+ \frac{\partial l}{\partial\bm{y}}\right)\left(\frac{\partial\bm{h}}{\partial \bm{y}}\right)^{-1}\) as \(\frac{\partial l}{\partial\bm{h}}\). After we finish the calculation of \(\frac{\partial l}{\partial\bm{h}}\) by conjugate gradient method, we can calculate \(\frac{\partial l}{\partial\bm{h}}\frac{\partial\bm{h}}{\partial A_{pq}}\), \(\frac{\partial l}{\partial\bm{h}}\frac{\partial\bm{h}}{\partial b_{p}}\), \(\frac{\partial l}{\partial\bm{h}}\frac{\partial\bm{h}}{\partial c_{q}}\), \(\frac{\partial l}{\partial\bm{h}}\frac{\partial\bm{h}}{\partial u_{q}}\) as follows:

\[\frac{\partial l}{\partial\bm{h}}\frac{\partial\bm{h}}{\partial A _{pq}}=\sum_{i=1}^{m}\frac{\partial l}{\partial h_{i}}\frac{\partial h_{i}}{ \partial A_{pq}}=\frac{\partial l}{\partial h_{p}}x_{q}+y_{p}\left(\sum_{i=1} ^{m}\frac{\partial l}{\partial h_{i}}A_{iq}\right)\theta x_{q}\left(u_{q}-x_{ q}\right)\] (A.22a) \[\frac{\partial l}{\partial\bm{h}}\frac{\partial\bm{h}}{\partial b _{p}}=\frac{\partial l}{\partial h_{p}}\frac{\partial h_{p}}{\partial b_{p}}=- \frac{\partial l}{\partial h_{p}}\] (A.22b) \[\frac{\partial l}{\partial\bm{h}}\frac{\partial\bm{h}}{\partial c _{q}}=\sum_{i=1}^{m}\frac{\partial l}{\partial h_{i}}\frac{\partial h_{i}}{ \partial c_{q}}=\left(\sum_{i=1}^{m}\frac{\partial l}{\partial h_{i}}A_{iq} \right)\theta x_{q}\left(u_{q}-x_{q}\right)\] (A.22c) \[\frac{\partial l}{\partial\bm{h}}\frac{\partial\bm{h}}{\partial u _{q}}=\sum_{i=1}^{m}\frac{\partial l}{\partial h_{i}}\frac{\partial h_{i}}{ \partial u_{q}}=\left(\sum_{i=1}^{m}\frac{\partial l}{\partial h_{i}}A_{iq} \right)\frac{x_{q}-\theta x_{q}\left(u_{q}-x_{q}\right)\left(-c_{q}-\sum_{i=1} ^{m}y_{i}A_{iq}\right)}{u_{q}}\] (A.22d)

By writing the above equations into matrix form, we have:

\[\frac{\partial l}{\partial\bm{h}}\frac{\partial\bm{h}}{\partial\bm {A}} =\frac{\partial l}{\partial\bm{h}}\bm{x}^{T}+\bm{y}\left(\left(\bm{A}^{T} \frac{\partial l}{\partial\bm{h}}\right)\circ\left(\theta\bm{x}\circ\left( \bm{u}-\bm{x}\right)\right)\right)^{T}\] (A.23a) \[\frac{\partial l}{\partial\bm{h}}\frac{\partial\bm{h}}{\partial \bm{b}} =-\frac{\partial l}{\partial\bm{h}}\] (A.23b) \[\frac{\partial l}{\partial\bm{h}}\frac{\partial\bm{h}}{\partial c } =\left(\bm{A}^{T}\frac{\partial l}{\partial\bm{h}}\right)\circ\left( \theta\bm{x}\circ\left(\bm{u}-\bm{x}\right)\right)\] (A.23c) \[\frac{\partial l}{\partial\bm{h}}\frac{\partial\bm{h}}{\partial \bm{u}} =\left(\bm{A}^{T}\frac{\partial l}{\partial\bm{h}}\right)\circ\left( \frac{\bm{x}-\theta\bm{x}\circ\left(\bm{u}-\bm{x}\right)\circ\left(-\bm{c}- \bm{A}^{T}\bm{y}\right)}{\bm{u}}\right)\] (A.23d)

Finally, by substituting equations (A.19) and (A.23) into (A.15), we can obtain the corresponding gradient as follows:

\[\frac{\partial l}{\partial\bm{A}} =\bm{y}\left(\left(\frac{\partial l}{\partial\bm{x}}-\bm{A}^{T} \frac{\partial l}{\partial\bm{h}}\right)\circ\left(\theta\bm{x}\circ\left( \bm{u}-\bm{x}\right)\right)\right)^{T}-\frac{\partial l}{\partial\bm{h}}\bm{x }^{T}\] (A.24a) \[\frac{\partial l}{\partial\bm{b}} =\frac{\partial l}{\partial\bm{h}}\] (A.24b) \[\frac{\partial l}{\partial\bm{c}} =\left(\frac{\partial l}{\partial\bm{x}}\circ\theta\bm{x}\circ \left(\bm{u}-\bm{x}\right)\right)-\left(\bm{A}^{T}\frac{\partial l}{ \partial\bm{h}}\right)\circ\left(\theta\bm{x}\circ\left(\bm{u}-\bm{x}\right)\right)\] (A.24c) \[\frac{\partial l}{\partial\bm{u}} =\left(\frac{\partial l}{\partial\bm{x}}-\bm{A}^{T}\frac{\partial l }{\partial\bm{h}}\right)\circ\left(\frac{\bm{x}-\theta\bm{x}\circ\left(\bm{u} -\bm{x}\right)\circ\left(-\bm{c}-\bm{A}^{T}\bm{y}\right)}{\bm{u}}\right)\] (A.24d)

### Experimental details about constrained traveling salesman problem

Here, we first provide the mathematical formulation of TSP with starting and ending cities constraint (TSP-StartEnd) and TSP with priority constraint (TSP-Priority). We first focus on TSP-StartEnd, which can be modeled as follows:

\[\min_{\bm{X}\in\left\{0,1\right\}^{n\times n}} \sum_{i=1}^{n}\sum_{j=1}^{n}D_{i,j}\sum_{k=1}^{n-1}X_{i,k}X_{j,k+1}\] (A.25a) \[\mathrm{s.t.} X_{s,1}=1,X_{e,n}=1,\] (A.25b) \[\bm{X}^{T}\mathbf{1}_{n}=\mathbf{1}_{n},\bm{X}\mathbf{1}_{n}= \mathbf{1}_{n}\] (A.25c)where \(X_{i,j}=1\) means city \(i\) is the \(j\)-th visited city in a tour, \(D_{i,j}\) refers to the distance between city \(i\) and city \(j\).

On the basis of problem (A.25), the TSP-Priority problem can be obtained by introducing the following priority constraints:

\[\sum_{j=1}^{m+1}X_{p,j}=1\] (A.26)

where \(p\) is the city that needs to be visited in the first \(m\) steps.

Due to the focus of this experiment on comparing the performance of each satisfiability layer, designing a better network structure is beyond the scope of this paper. Therefore, we directly used the SOTA network structure in solving TSP, which consists of a three-layers Transformer, followed by a three-layer MLP with ReLU activation [20]. The hidden sizes are all set to 256 and the number of multi-head attention is set to 8. All the training and test data is consisted of 20 nodes that are uniformly sampled from a unit square. For all satisfiability layers, the constraints are the continuous relaxation of the original TSP problem and all the common settings are the same as follows. The learning rate is set to 10\({}^{-4}\). The batch size is set to 1024. When we stack constraints into block diagonal form to exploit parallelism, there are about 40,000 rows and 400,000 columns in the whole matrix. The training epoch number is set to 50. The constraint tolerance is set to \(10^{-3}\). For GLinSAT, the initial estimate of the dual variable is set to zero vector, the numerical precision is set to \(10\epsilon_{\mathrm{machine}}\), where \(\epsilon_{\mathrm{machine}}\) is the machine epsilon. In each epoch, we generate 256000 random cases as the training set. In the training stage, the objective function in (A.25a) is used as the loss function. In the validation stage, we use two kinds of post-processing methods. The first one is rounding. The second one is beam search where the width of the beam is set to 2048. All the experiments are conducted on a computer with a Intel(R) Xeon(R) Platinum 8360H CPU and a NVIDIA Tesla A100 GPU with 80GB memory through Pytorch 2.2.

Here, we additionally show the training performance when \(1/\theta\) is set to \(10^{-2}\) as follows:

From Table A.1, we can see GLinSAT-Dense-Implicit is the most memory efficient satisfiability layer among all these layers. As to the solution time, we can find that GLinSAT is slightly slower than LinSAT-Dense-100. **The reason LinSAT has a fast calculation speed is that the algorithm terminates due to reaching the maximum number of iterations rather than because of convergence.** Actually we find that LinSAT often reports warnings like "non-zero constraint violation

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \hline  & \multicolumn{4}{c}{TSP-StartEnd} & \multicolumn{4}{c}{TSP-Priority} \\ \cline{2-9}  & \multicolumn{2}{c}{GPU Mem./MB} & \multicolumn{2}{c}{Time/s} & \multicolumn{2}{c}{GPU Mem./MB} & \multicolumn{2}{c}{Time/s} \\ \cline{2-9} Satisfiability layer & Proj. & Backprop. & Proj. & Backprop. & Proj. & Backprop. & Proj. & Backprop. \\ \hline CvxpyLayers & — & — & 107.3 & 31.12 & — & — & 107.4 & 30.22 \\ OptNet & 14305 & 5005 & 18.89 & 0.930 & 14333 & 5005 & 20.40 & 1.125 \\ LinSAT-Dense-100 & 14977 & 181.2 & **0.278** & 0.417 & 15009 & 180.9 & **0.277** & 0.419 \\ LinSAT-Dense-500 & 74108 & 181.2 & 1.339 & 1.930 & 74272 & 180.9 & 1.318 & 1.932 \\ GLinSAT-Dense-Explicit & 11095 & **4.852** & 0.976 & 0.552 & 11155 & **4.857** & 0.965 & 0.555 \\ \hline GLinSAT-Dense-Implicit & **13.34** & 53.23 & 0.888 & **0.072** & **13.36** & 53.22 & 1.096 & **0.078** \\ \hline LinSAT-Sparse-100 & — & — & — & — & — & — & — & — \\ LinSAT-Sparse-500 & — & — & — & — & — & — & — \\ GLinSAT-Sparse-Explicit & 7085 & 5.051 & 1.552 & 0.774 & 7007 & 5.519 & 1.508 & 0.812 \\ GLinSAT-Sparse-Implicit & 62.95 & 24.71 & 1.355 & 0.078 & 63.27 & 24.51 & 1.721 & 0.083 \\ \hline \hline \end{tabular}

* Note: LinSAT-(Dense/Sparse)-(100/500) means that LinSAT is used with dense/sparse matrix and max iteration number is set to 100/500. GLinSAT-(Dense/Sparse)-(Explicit/Implicit) means that GLinSAT is used with dense/sparse matrix and backpropagation is performed using automatic differential/implicit differential. The GPU memory used by CvxpyLayers is not counted since CvxpyLayers is CPU-based. Note: The output of LinSAT-Sparse when \(1/\theta=0.01\) is not a real number so that the results are not shown.

\end{table}
Table A.1: Average allocated GPU memory and solution time of different satisfiability layers during batch processing of projection and backpropagation when \(1/\theta\) is set to \(10^{-2}\) in TSP training phase within max iterations", which indicates the algorithm has not converged. After we increase the max iteration number to 500, the number of warnings has decreased, but there are still some warnings that indicate the algorithm has not converged. When we set maximum iteration number to \(+\infty\), the algorithm progress will stuck. Compared with LinSAT, our proposed GLinSAT is more reliable and is guaranteed to converge. Table A.2 shows the corresponding validation results about the mean tour length and feasibility ratio. From Table A.2, we can see that the performance of GLinSAT is superior to that of LinSAT.

### Experimental details about partial graph matching with outliers

Here, we first provide the mathematical formulation of partial graph matching with outliers. Denote \(m,n\) as the number of nodes of two graphs respectively. The partial graph matching problem with \(p\) inliers can be expressed as follows:

\[\bm{X}^{T}\mathbf{1}_{m}\leq\mathbf{1}_{n}\] (A.27a) \[\bm{X}\mathbf{1}_{n}\leq\mathbf{1}_{m}\] (A.27b) \[\mathbf{1}_{m}^{T}\bm{X}\mathbf{1}_{n}=p\] (A.27c) \[\bm{X}\in\{0,1\}^{m\times n}\] (A.27d)

where \(X_{i,j}=1\) means the \(i\)-th node in the left graph matches the \(j\)-th node in the right graph.

When we use GLinSAT as the satisfiability layer, it is necessary to canonize the original inequality constraints. By introducing bounded slack variables into equations (A.27a) and (A.27b), we can reformulate constraints (A.27) into the standard form as follows:

\[\bm{X}^{T}\mathbf{1}_{m}+\bm{s}_{n}=\mathbf{1}_{n}\] (A.28a) \[\bm{X}\mathbf{1}_{n}+\bm{t}_{m}=\mathbf{1}_{m}\] (A.28b) \[\bm{1}_{m}^{T}\bm{X}\mathbf{1}_{n}=p\] (A.28c) \[\bm{X}\in\{0,1\}^{m\times n}\] (A.28d)

where \(\mathbf{0}_{n}\leq\bm{s}_{n}\leq\mathbf{1}_{n},\mathbf{0}_{m}\leq\bm{t}_{m}\leq \mathbf{1}_{m}\).

In the training stage, we follow the experimental codes in Ref. [20] where the neural networks are trained on the basis of a pretrained SOTA graph matching NGMv2 model [43] named "pretrained_params_vgg16_ngmv2_afat-i_voc". Different satisfiability layers are used to make the outputs satisfy the continuous relaxation of constraints (A.27).

It is noteworthy that since the sizes of graphs differ a lot in one batch, we stack constraints into block diagonal forms in LinSAT and GLinSAT to exploit parallelism of the GPU. However, it is difficult

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline  & \multicolumn{4}{c}{TSP-StartEnd} & \multicolumn{4}{c}{TSP-Priority} \\ \cline{2-9}  & \multicolumn{2}{c}{Rounding} & \multicolumn{2}{c}{Beamsearch} & \multicolumn{2}{c}{Rounding} & \multicolumn{2}{c}{Beamsearch} \\  & with \(1/\theta=10^{3}\) & & \multicolumn{2}{c}{with \(1/\theta=0.1\)} & \multicolumn{2}{c}{with \(1/\theta=10^{3}\)} & \multicolumn{2}{c}{with \(1/\theta=0.1\)} \\ \cline{2-9} Layer & \begin{tabular}{c} Mean \\ Length \\ \end{tabular} & \begin{tabular}{c} Feas. \\ Ratio \\ \end{tabular} & \begin{tabular}{c} Mean \\ Length \\ \end{tabular} & \begin{tabular}{c} Feas. \\ Ratio \\ \end{tabular} & \begin{tabular}{c} Mean \\ Length \\ \end{tabular} & \begin{tabular}{c} Feas. \\ Ratio \\ \end{tabular} & \begin{tabular}{c} Mean \\ Length \\ \end{tabular} & 
\begin{tabular}{c} Feas. \\ Ratio \\ \end{tabular} \\ \hline LinSAT-Dense-100 & — & — & 8.090 & **100\%** & — & — & 7.031 & **100\%** \\ LinSAT-Dense-500 & — & — & 3.873 & **100\%** & — & — & 4.011 & **100\%** \\ GLinSAT-Dense-Explicit & 4.030 & 92.77 & 3.869 & **100\%** & 4.171 & 91.5\% & 3.983 & **100\%** \\ \hline GLinSAT-Dense-Implicit & **3.930** & 94.1\% & **3.790** & **100\%** & **4.053** & **94.6\%** & **3.924** & **100\%** \\ \hline LinSAT-Sparse-100 & — & — & — & — & — & — & — \\ LinSAT-Sparse-500 & — & — & — & — & — & — & — \\ GLinSAT-Sparse-Explicit & 4.022 & 92.6\% & 3.859 & **100\%** & 4.078 & 92.6\% & 3.935 & **100\%** \\ GLinSAT-Sparse-Implicit & 3.926 & **94.8\%** & 3.803 & **100\%** & 4.073 & 93.4\% & 3.933 & **100\%** \\ \hline \hline \end{tabular}

* Note: The output of LinSAT-Sparse when \(\frac{1}{\theta}=10^{2}\) is not a real number so that we cannot obtain any trained model. The output of LinSAT-Dense when \(\frac{1}{\theta}=10^{3}\) is not a real number so that the results are not shown.

\end{table}
Table A.2: Mean tour length and feasibility ratio obtained from using different \(1/\theta\) and post-processing methods in TSP validation stage for CvxpyLayers and OptNet to directly handle large block diagonal matrices since disciplined parameterized programming compilation and matrix factorization of large matrices will cost a large amount of time. Therefore, we can only use a sequential way to handle batched graphs with different sizes for CvxpyLayers and OptNet. The batch size is set to 128 across all the experiments. When we stack constraints into block diagonal form to exploit parallelism, there are about 2,500 rows and 13,000 columns in the whole matrix. The constraint tolerance is set to \(10^{\text{-3}}\). In the training stage, binary cross entropy loss is used as the loss function. For experiments about OptNet and GLinSAT-Explicit, we use double-precision floating-point numbers during projection. If single-precision floating-point numbers are used, OptNet will encounter numerical issues in its forward pass while reporting warnings like "Returning an inaccurate and potentially incorrect solution". GLinSAT-Explicit will not encounter numerical issues in its forward pass. However, sometimes the gradient calculated by auto differential may be not a real number. We believe the problem is that single-precision floating-point numbers amplify the cumulative error of backpropagation. When we use double-precision floating-point numbers, everything works fine. As a result, we use single-precision floating-point numbers on all the other layers except OptNet and GLinSAT-Explicit.

In the validation stage, we use Hungarian algorithm and greedy strategy for post-processing [20]. We can regard the cost of matching a pair of nodes as the outputs of satisfiability layers, then use Hungarian algorithm to obtain a maximum matching. Finally, we can use greedy strategy to preserve pairs with \(p\)-highest matching scores and obtain the solution.

All the experiments are conducted on a computer with a Intel(R) Xeon(R) Platinum 8360H CPU and a NVIDIA Tesla A100 GPU with 80GB memory through Pytorch 2.2. For GLinSAT, the initial estimate of Lipschitz constant is set to \(\theta\), the initial estimate of the dual variable is set to zero vector, the numerical precision is set to \(10\epsilon_{\text{machine}}\), where \(\epsilon_{\text{machine}}\) is the machine epsilon. Here, we show the average memory usage and the solution time of different satisfiability layers in Table A.3.

In Table A.3, although LinSAT-100 seems to be the fastest method, the price is that the required constraints are not satisfied at all. When we set the maximum iteration number of LinSAT to 100, almost every batch LinSAT will report warnings like "non-zero constraint violation within max iterations". When we set the maximum iteration number to 500, LinSAT-Dense will soon run out of memory while LinSAT-Sparse will still display the warning message in almost every epoch. Notably, the computational speed of LinSAT at this point has already fallen behind that of GLinSAT. If we set the maximum iteration number to \(+\infty\) in LinSAT-Sparse, the algorithm will get stuck. Compared with our proposed GLinSAT, when the maximum iteration number is set to \(+\infty\), the convergence of GLinSAT is guaranteed. In summary, we can conclude that our proposed GLinSAT is the fastest satisfiability layer while ensuring the outputs satisfy the linear and bounded constraints from the results shown in Table A.3.

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \hline  & \multicolumn{4}{c}{\(\frac{1}{\theta}\) = 10\({}^{\text{-1}}\)} & \multicolumn{4}{c}{\(\frac{1}{\theta}\) = 10\({}^{\text{-2}}\)} \\ \cline{2-9}  & \multicolumn{2}{c}{GPU Mem./MB} & \multicolumn{2}{c}{Time/s} & \multicolumn{2}{c}{GPU Mem./MB} & \multicolumn{2}{c}{Time/s} \\ \cline{2-9} Layer & Proj. & Backprop. & Proj. & Backprop. & Proj. & Backprop. & Proj. & Backprop. \\ \hline CvxpyLayers & — & — & 64.26 & 16.09 & — & — & 12.76 & 15.07 \\ OptNet & 167.3 & 826.2 & 4.290 & **3.712** & 167.2 & 826.3 & 4.437 & 3.726 \\ LinSAT-Dense-100\({}^{\text{*}}\) & 23944 & 322.1 & 0.611 & 3.887 & 23944 & 322.1 & 0.611 & 3.887 \\ LinSAT-Dense-500 & \(\times\) & \(\times\) & \(\times\) & \(\times\) & \(\times\) & \(\times\) & \(\times\) & \(\times\) \\ GLinSAT-Dense-Explicit & 1249 & **0.997** & 1.891 & 4.418 & 1311 & **1.052** & 1.991 & 4.147 \\ GLinSAT-Dense-Implicit & 129.0 & 736.5 & **1.333** & 3.995 & 129.0 & 736.4 & **1.302** & **3.515** \\ \hline LinSAT-Sparse-100\({}^{\text{*}}\) & 803.0 & 397.7 & 1.593 & 3.906 & 803.6 & 397.7 & 1.615 & 3.877 \\ LinSAT-Sparse-500\({}^{\text{*}}\) & 2772 & 304.3 & 2.922 & 5.534 & 2772 & 304.3 & 2.923 & 5.292 \\ GLinSAT-Sparse-Explicit & 648.7 & 172.9 & 1.794 & 4.435 & 687.6 & 139.8 & 1.986 & 4.620 \\ GLinSAT-Sparse-Implicit & **0.001** & 862.1 & 1.544 & 3.884 & **0.001** & 862.1 & 1.449 & 3.865 \\ \hline \hline \end{tabular} Note: The GPU memory used by CvxpyLayers is not counted since CvxpyLayers is CPU-based.

Note: The symbol “\({}^{\text{*}}\)” means the outputs of this satisfiability layer cannot meet constraints. The symbol “\(\times\)” means the layer leads to out-of-memory (OOM) issues.

\end{table}
Table A.3: Average allocated GPU memory and solution time of different satisfiability layers during batch processing of projection and backpropagation in the training phase of partial graph matching 

### Experimental details about predictive portfolio allocation

Here, we first restate the mathematical formulation of predictive portfolio allocation. We denote \(x_{i}\) as the predicted portfolio decision variable of asset \(i\) and \(\mathcal{S}\) as the preferred portfolio asset. The portfolio allocation needs to maximize the Sharpe ratio [34] while satisfying the following constraints:

\[\sum_{i=1}^{n}x_{i}=1,\sum_{i\in\mathcal{S}}x_{i}\geq q\] (A.29a) \[0\leq x_{i}\leq 1,\forall 1\leq i\leq n\] (A.29b)

where \(q\) is a pre-defined positive constant. Following the codes in [20], here we set \(q\) as 0.5 and set \(C\) as {AAPL, MSFT, AMZN, TSLA, GOOGL}. We also use the first 120-day historical data to train a neural network that could maximize the Sharpe ratio for the future 120 days where StemGNN [44] are used as the network backbone to extract the features.

When we use GLinSAT as the satisfiability layer, it is necessary to canonize the original inequality constraints. By introducing bounded slack variables into constraints (A.29a), we can reformulate constraints (A.29) into the standard form as follows:

\[\sum_{i=1}^{n}x_{i}=1,\sum_{i\in\mathcal{S}}x_{i}-w=q\] (A.30a) \[0\leq w\leq|\mathcal{S}|-q,0\leq x_{i}\leq 1,\forall 1\leq i\leq n\] (A.30b)

where \(|\mathcal{S}|\) refers to the number of elements in the preference set \(\mathcal{S}\).

To conduct fair comparison, we train 50 epochs with a batch size of 128, a learning rate of 10-5 and a constraint tolerance of 10-3 across all satisfiability layers. When we stack constraints into block diagonal form to exploit parallelism, there are about 250 rows and 60,000 columns in the whole matrix. In the training stage, a weighted sum of prediction MSE error on future asset prices and the opposite of Sharpe ratio is used as the loss function. All the experiments are conducted on a computer with a Intel(R) Xeon(R) Platinum 8360H CPU and a NVIDIA Tesla A100 GPU with 80GB memory through Pytorch 2.2. For GLinSAT, the initial estimate of Lipschitz constant is set to \(\theta\), the initial estimate of the dual variable is set to zero vector, the numerical precision is set to \(10\epsilon_{\mathrm{machine}}\), where \(\epsilon_{\mathrm{machine}}\) is the machine epsilon. In the main text, we have reported the mean Sharpe ratio of each method in Table 5. Here, we provide the results related to the training performance in Table A.4. From Table A.4, we can see that the total memory usage is similar between each variant of LinSAT and GLinSAT since there are only two constraints in the original problem. The projection time of LinSAT and GLinSAT is significantly less than that of CvxpyLayers and OptNet while GLinSAT-Dense-Implicit use the shortest total calculation time among all satisfiability layers.

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \hline  & \multicolumn{4}{c}{\(\frac{1}{\theta}\) = 10-1} & \multicolumn{4}{c}{\(\frac{1}{\theta}\) = 10-2} \\ \cline{2-9}  & GPU Mem./MB & \multicolumn{2}{c}{Time/s} & \multicolumn{2}{c}{GPU Mem./MB} & \multicolumn{2}{c}{Time/s} \\ \cline{2-9} Layer & Proj. & Backprop. & Proj. & Backprop. & Proj. & Backprop. & Proj. & Backprop. \\ \hline CvxpyLayers & — & — & 12.85 & 1.476 & — & — & 12.27 & 1.423 \\ OptNet & 2012 & 765.0 & 5.599 & 1.035 & 2012 & 765.0 & 4.606 & 1.279 \\ LinSAT-Dense-100 & 81.34 & 434.9 & 0.091 & 0.393 & 105.8 & 410.5 & 0.127 & 0.413 \\ LinSAT-Dense-500 & 81.34 & 434.9 & 0.266 & 0.386 & 136.6 & 385.6 & 0.315 & 0.413 \\ GLinSAT-Dense-Explicit & 112.9 & 402.6 & 0.143 & 0.376 & 107.9 & 407.2 & 0.148 & 0.377 \\ GLinSAT-Dense-Implicit & **1.565** & 514.1 & **0.090** & 0.320 & **1.565** & 513.6 & **0.090** & 0.322 \\ \hline LinSAT-Sparse-100 & 223.6 & **295.0** & 0.113 & 0.400 & 290.7 & 227.6 & 0.161 & 0.421 \\ LinSAT-Sparse-500 & 223.6 & **295.0** & 0.114 & 0.398 & 371.1 & **224.1** & 0.225 & 0.442 \\ GLinSAT-Sparse-Explicit & 78.24 & 437.7 & 0.211 & 0.391 & 74.80 & 440.8 & 0.213 & 0.392 \\ GLinSAT-Sparse-Implicit & 4.501 & 512.0 & 0.143 & **0.316** & 4.501 & 511.7 & 0.139 & **0.315** \\ \hline \hline \end{tabular}
\end{table}
Table A.4: Average allocated GPU memory and solution time of different satisfiability layers during batch processing of projection and backpropagation in the training phase of predictive portfolio allocation

### Experimental details about power system unit commitment

In this section, we carry out experiments on power system unit commitment where the data comes from a real provincial power system.

We first briefly introduce the unit commitment problem. Unit commitment problem is a core optimization problem in power system operation and planning. It mainly involves deciding how to most economically and safely arrange the startup-shutdown status and output power of generators while ensuring constraints related to equipment and grid operation can be satisfied. Generally, constraints can be divided into soft constraints and hard constraints. In general, constraints directly related to generators are often regarded as hard constraints, e.g. the generator minimum up-time and down-time constraints. Constraints related to the section power and load balance are usually regarded as soft constraints. For these constraints, we often penalize the corresponding violation in the objective [35].

Next, we will use the common three-binary formulation [23] to model the unit commitment problem. Let \(T\) denote the total number of time steps that considered in unit commitment problem. \(G\) is the total number of generators. We denote \(\mathcal{T}=\left\{1,\cdots,T\right\}\) and \(\mathcal{G}=\left\{1,\cdots,G\right\}\). Let \(u_{g}(t)\) denote whether the generator \(g\) is on at time \(t\), \(v_{g}(t)\) denote whether the generator is turned on at time \(t\), and \(w_{g}(t)\) denote if the generator is turned off at time \(t\). Then, \(u_{g}\left(t\right),v_{g}\left(t\right),w_{g}\left(t\right)\) satisfy the following logical constraints:

\[u_{g}\left(t\right)-u_{g}\left(t-1\right)=v_{g}\left(t\right)-w_{g}\left(t \right),t\in\mathcal{T}\] (A.31)

where \(T\) is the total number of time steps that considered in the unit commitment problem.

Units need to satisfy minimum up-time constraints and down-time constraints as follows:

\[\sum_{i=t-UT_{g}+1}^{t}v_{g}\left(i\right)\leq u_{g}\left(t\right),g\in \mathcal{G},t=UT_{g},\cdots T\] (A.32a) \[\sum_{i=t-DT_{g}+1}^{t}w_{g}\left(i\right)\leq 1-u_{g}\left(t\right),g\in \mathcal{G},t=DT_{g},\cdots T\] (A.32b)

where \(UT_{g},DT_{g}\) are the minimum up-time and minimum down-time for generator \(g\) respectively.

Let \(p_{g}\left(t\right)\) denote the power produced by generator \(g\) at time \(t\). Let \(\underline{p_{g}},\overline{p_{g}}\) denote the lower bound and upper bound of generator \(g\). Then, we have constraints related to the bound of generator output as follows:

\[\underline{p_{g}}u_{g}\left(t\right)\leq p_{g}\left(t\right)\leq\overline{p_ {g}}u_{g}\left(t\right),g\in\mathcal{G},t\in\mathcal{T}\] (A.33)

We also need to consider the ramping capability of each generator. The ramping constraints can be formulated as follows:

\[p_{g}\left(t\right)-p_{g}\left(t-1\right)\leq-RU_{g}v_{g}\left(t\right)+ \left(\underline{p_{g}}+RU_{g}\right)u_{g}\left(t\right)-\underline{p_{g}}u_{ g}\left(t-1\right),g\in\mathcal{G},t\in\mathcal{T}\] (A.34a) \[p_{g}\left(t-1\right)-p_{g}\left(t\right)\leq-RD_{g}w_{g}\left(t \right)+\left(\underline{p_{g}}+RD_{g}\right)u_{g}\left(t-1\right)-\underline{p_ {g}}u_{g}\left(t\right),g\in\mathcal{G},t\in\mathcal{T}\] (A.34b)

where \(RU_{g},RD_{g}\) denote the ramp-up rate and ramp-down rate of generator \(g\).

The load generation balance constraint is modeled as the following soft constraint form:

\[\sum_{g\in\mathcal{G}}p_{g}\left(t\right)+s^{+}\left(t\right)-s^{-}\left(t \right)=\sum_{d\in\mathcal{D}}l_{d}\left(t\right),t\in\mathcal{T}\] (A.35)

where \(\mathcal{D}\) is the set of all loads, \(l_{d}\left(t\right)\) represents the \(d\)-th load at time \(t\), \(s^{+}\left(t\right)\geq 0,s^{-}\left(t\right)\geq 0\) are the non-negative slack variables at time \(t\) which will be later penalized in the objective.

We denote the set of sections as \(\mathcal{K}\). The soft constraints on section power are provided as follows:

\[\underline{F_{k}}\leq\sum_{g\in\mathcal{G}}H_{kg}p_{g}\left(t\right)-\sum_{d \in\mathcal{D}}H_{kd}l_{d}\left(t\right)+s_{k}^{+}\left(t\right)-s_{k}^{-} \left(t\right)\leq\overline{F_{k}},k\in\mathcal{K},t\in\mathcal{T}\] (A.36)

where \(\underline{F_{k}},\overline{F_{k}}\) are the lower bound and upper bound of the \(k\)-th section power, \(H_{kg}\) is the generation shift factor that indicates the change of the \(k\)-th section power with respect to a change in injectionat generator \(g\), \(H_{kg}\) is the load shift factor that indicates the change of the \(k\)-th section power with respect to a change in injection at load \(d\), \(s_{k}^{+}\left(t\right)\geq 0,s_{k}^{-}\left(t\right)\geq 0\) are the non-negative slack variables related to the \(k\)-th section at time \(t\) which will be later penalized in the objective.

Finally, we want to minimize the system operation cost and we can obtain the optimization problem as follows:

\[\min \sum_{t\in\mathcal{T}}\sum_{g\in\mathcal{G}}\left(c_{g}p_{g}\left(t \right)+c_{g}^{SU}v_{g}\left(t\right)\right)+\sum_{t\in\mathcal{T}}M\left(s^{ +}\left(t\right)+s^{-}\left(t\right)\right)+\sum_{t\in\mathcal{T}}\sum_{k\in \mathcal{K}}M_{k}\left(s_{k}^{+}\left(t\right)+s_{k}^{-}\left(t\right)\right)\] (A.37a) \[\mathrm{s.t.}\] (A.37b) \[u_{g}\left(t\right)\in\left\{0,1\right\},v_{g}\left(t\right) \in\left\{0,1\right\},w_{g}\left(t\right)\in\left\{0,1\right\},g\in\mathcal{G },t\in\mathcal{T},\] (A.37c) \[s_{k}^{+}\left(t\right)\geq 0,s_{k}^{-}\left(t\right)\geq 0,t \in\mathcal{T},\] (A.37d) \[s^{+}\left(t\right)\geq 0,s^{-}\left(t\right)\geq 0,k\in \mathcal{K},t\in\mathcal{T}\]

where \(M,M_{k}\) are pre-defined penalty coefficients, \(c_{g}\) is the generator cost coefficient, \(c_{g}^{SU}\) is the generator start-up cost.

The power system we use in this article contains about 360 units. We set the total number of time steps \(T\) as 96 where the interval between two adjacent time steps is set to 15 minutes. More than 1,400 sections need to be considered in the unit commitment problem. The penalty coefficient for load imbalance is set to 10\({}^{11}\) and the penalty coefficient for section power violation is set to 10\({}^{7}\). Based on the one-year load data, we solve the unit commitment problem via Gurobi within a 0.1% optimality gap. We can then obtain the optimal unit states for further supervised learning.

In supervised learning, we want to predict the optimal value of \(u_{g}\) as accurately as possible so that we can fix these binary variables and quickly obtain a high-quality solution from solving a linear programming problem. Therefore, we should require the predicted variables \(u_{g}\) to satisfy the hard constraints (A.31) and (A.32), namely the logical constraint and the minimum up-time and down-time constraints. In addition, \(u_{g}\left(t\right),v_{g}\left(t\right),w_{g}\left(t\right)\) should be in the range between 0 and 1. We use satisfiability layers to ensure the above constraints can be satisfied.

When we use GLinSAT as the satisfiability layer, it is necessary to canonize the original inequality constraints. By introducing bounded slack variables into constraints (A.29a), we can reformulate constraints (A.29) into the standard form as follows:

\[\sum_{i=t-UT_{g}+1}^{t}v_{g}\left(i\right)+sv_{g}\left(t\right)=u _{g}\left(t\right),g\in\mathcal{G},t=UT_{g},\cdots T\] (A.38a) \[\sum_{i=t-DT_{g}+1}^{t}w_{g}\left(i\right)+sw_{g}\left(t\right)=1-u _{g}\left(t\right),g\in\mathcal{G},t=DT_{g},\cdots T\] (A.38b)

Since we have \(u_{g}\left(t\right)\in\left[0,1\right],v_{g}\left(t\right)\in\left[0,1\right], w_{g}\left(t\right)\in\left[0,1\right]\), the value range of variables \(sv_{g}\left(t\right)\) and \(sw_{g}\left(t\right)\) can be quickly inferred, which is exactly \(sv_{g}\left(t\right)\in\left[0,1\right],sw_{g}\left(t\right)\in\left[0,1\right]\).

We use a MLP-based neural network to learn the optimal unit states. The loads at each time-step are forwarded to a 2-layer MLP where the hidden sizes are set to 32. Then, we concatenate the embeddings at all time steps, and forward the concatenated embedding to a 1-layer MLP where the hidden size is set to 3072. Finally, we use a 2-layer MLP to read out the optimal unit states where the hidden size is set to 512. We use ReLU as the activation function in the hidden layers. We set the learning rate to 10\({}^{3}\) and train neural networks for 100 epochs. We use 70% of one-year data as the training set and the other as the validation set. In the training stage, binary cross entropy loss is used as the loss function. For all satisfiability layers, the batch size is set to 16 and the regularization parameter \(\frac{1}{\theta}\) is set to 0.1. It is worth noting that although the batch size is not that large, the scale of the optimization problem in each batch is still quite large. Each instance involves nearly 360 projection problems, and each projection problem involves about 160 constraints and 350 variables. When we stack constraints into block diagonal form to exploit parallelism, there are about 1,000,000 rows and 2,000,000 columns in the whole matrix. GLinSAT-Sparse-Implicit is the only way that will not report out-of-memory issues when we use GLinSAT. For GLinSAT, the initial estimate of Lipschitz constant is set to \(\theta\), the initial estimate of the dual variable is set to zero vector, the numerical precision is set to \(10\epsilon_{\mathrm{machine}}\), where \(\epsilon_{\mathrm{machine}}\) is the machine epsilon. As to CvxpyLayers and OptNet, neither of them can directly handle such a giant matrix within reasonable time thus we can only use a sequential way instead. The performance of each satisfibility layer is provided in Table A.5. The results of LinSAT layers are not reported in Table A.5 since LinSAT layers only support positive linear constraints. All the experiments are conducted on a computer with a Intel(R) Xeon(R) Platinum 8360H CPU and a NVIDIA Tesla A100 GPU with 80GB memory through Pytorch 2.2.

In the validation stage, we use different values of \(\frac{1}{\theta}\) to test their performance. When \(\frac{1}{\theta}\) is set to \(10^{-3}\), we use the double-precision floating-point numbers during projection to avoid potential numerical issues. When \(\frac{1}{\theta}\) is set to 0, the projection problem turns into a linear programming problem and we solve it via Gurobi. After we have obtained the outputs of satisfiability layers, we round the outputs of final layers to 0 or 1 and then fix the unit state variables \(u_{g}\) using these rounded outputs. Once we fix all unit state variables to 0 or 1, the original mixed-integer linear programming (MILP) problem turns to a linear programming (LP) problem. We use Gurobi to solve such an LP problem and record whether the problem with fixed unit states is feasible and record the optimal solution if exists. We also compare the optimal objective obtained from fixing variables with the original optimal objective. The corresponding average gaps between them are shown in Table 6.

To illustrate the importance of the satisfiable layer, we additionally substitute the original satisfiability layer with a simple sigmoid activation function in both training and validation stages and report the corresponding result in Table 6. We can easily see that satisfiability layers are essential to produce feasible unit states.

\begin{table}
\begin{tabular}{c c c c c} \hline \hline  & \multicolumn{2}{c}{GPU Mem./MB} & \multicolumn{2}{c}{Time/s} \\ \cline{2-5} Layer & Proj. & Backprop. & Proj. & Backprop. \\ \hline CvxpyLayers & — & — & 2771 & 684.0 \\ OptNet & 33012 & 96.64 & 257.4 & 23.60 \\ GLinSAT-Sparse-Implicit & **930.7** & **76.86** & **26.78** & **1.636** \\ \hline \hline \end{tabular} Note: Statistics of CvxpyLayers and OptNet are based on the first epoch since we cannot obtain a well-trained model in reasonable time.

\end{table}
Table A.5: Average allocated GPU memory and solution time of different satisfiability layers during batch processing of projection and backpropagation in the training stage of predicting unit states

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: In this paper, we consider making a batch of neural network outputs satisfy bounded and general linear constraints. We present GLinSAT, which is the first general linear satisfiability layer in which all the operations are differentiable and matrix-factorization-free. Experimental results demonstrate the advantages of GLinSAT over existing methods. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We have discussed our limitations in Appendix A.3. For variables with one-sided boundary or no explicit boundary, our method cannot be directly used. A possible workaround is to manually calculate the implicit bounds of these variables through domain propagation but we have not implemented such an algorithm in GLinSAT. Also, currently our proposed framework cannot deal with conic constraints. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.

3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: In the derivation process, we always assume the feasible region is non-empty as shown in Sec. 2.1. The derivation process of our results can be found in Sec. 2.1, Appendix A.5, A.6 and A.7. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We have detailed our experimental settings in Appendix A.8, A.9, A.10 and A.11 and the code released in github can be also be used as a reference. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).

4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We provide our codes and instructions on the first three experiments, but currently we are unable to open source the data and code about the unit commitment problem in a real power system due to data security issues and confidentiality agreements. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We have detailed our experimental settings in Appendix A.8, A.9, A.10 and A.11 and the code released in github can be also be used as a reference. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [No] Justification: Error bars are not reported because it would be too computationally expensive. Guidelines:* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: All the experiments are conducted on a computer with a Intel(R) Xeon(R) Platinum 8360H CPU and a NVIDIA Tesla A100 GPU with 80GB memory through Pytorch 2.2. We also provide the batch processing performance in Table 2, Table A.1, Table A.3, Table A.4, Table A.5. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research conducted in the paper conform with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?Answer: [Yes] Justification: We have discussed potential impacts in Appendix A.2. Guidelines:

* The answer NA means that there is no societal impact of the work performed.
* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

11. [leftmargin=*]
1. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This paper poses no risk for misusing our proposed method. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We have properly credited the used Pascal VOC Keypoint dataset [31] with Berkeley annotations [32] under the unfiltered setting [20, 33]. We also cite the TSP dataset and portfolio allocation dataset provided in Ref. [20]. Guidelines: * The answer NA means that the paper does not use existing assets.

* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This paper does not release new assets. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects.

Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.