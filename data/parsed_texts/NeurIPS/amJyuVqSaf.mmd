# Markovian Flow Matching: Accelerating MCMC with Continuous Normalizing Flows

Alberto Cabezas

Department of Mathematics and Statistics

Lancaster University, UK

a.cabezasgonzalez@lancaster.ac.uk

Equal contribution

Louis Sharrock

Department of Mathematics and Statistics

Lancaster University, UK

l.sharrock@lancaster.ac.uk

Equal contribution

###### Abstract

Continuous normalizing flows (CNFs) learn the probability path between a reference distribution and a target distribution by modeling the vector field generating said path using neural networks. Recently, Lipman et al. [45] introduced a simple and inexpensive method for training CNFs in generative modeling, termed flow matching (FM). In this paper, we repurpose this method for probabilistic inference by incorporating Markovian sampling methods in evaluating the FM objective, and using the learned CNF to improve Monte Carlo sampling. Specifically, we propose an adaptive Markov chain Monte Carlo (MCMC) algorithm, which combines a local Markov transition kernel with a non-local, flow-informed transition kernel, defined using a CNF. This CNF is adapted on-the-fly using samples from the Markov chain, which are used to specify the probability path for the FM objective. Our method also includes an adaptive tempering mechanism that allows the discovery of multiple modes in the target distribution. Under mild assumptions, we establish convergence of our method to a local optimum of the FM objective. We then benchmark our approach on several synthetic and real-world examples, achieving similar performance to other state-of-the-art methods, but often at a significantly lower computational cost.

## 1 Introduction

The task of sampling from a probability distribution known only up to a normalization constant is a fundamental problem arising in a wide variety of fields, including statistical physics [51], Bayesian inference [25], and molecular dynamics [43]. In particular, let \(\pi(\mathrm{d}x)\) be a target probability distribution on \(\mathbb{R}^{d}\) with density \(\pi(x)\) with respect to the Lebesgue measure of the form1

Footnote 1: In a slight abuse of notation, we use \(\pi\) to denote both the target distribution and its density.

\[\pi(x)=\frac{\hat{\pi}(x)}{Z}, \tag{1}\]

where \(\hat{\pi}:\mathbb{R}^{d}\rightarrow\mathbb{R}_{+}\) is a continuously differentiable function which can be evaluated pointwise, and \(Z=\int_{\mathbb{R}^{d}}\hat{\pi}(x)\mathrm{d}x\) is an unknown normalizing constant. We are interested in generating samples from the target distribution \(\pi\) in order to approximate integrals of the form \(\pi[f]=\mathbb{E}_{\pi}[f(x)]\), where \(f:\mathbb{R}^{d}\rightarrow\mathbb{R}\).

A standard solution to this problem is Markov chain Monte Carlo (MCMC) [12; 64], which relies on the construction of a Markov process which admits the target \(\pi\) as its invariant distribution. One of the most broadly applicable and widely studied MCMC methods is the Metropolis-Hastings (MH) algorithm [32], which proceeds in two steps. First, given a current sample \(x\), a new sample \(y\) is proposed according to some proposal distribution \(q(\cdot|x)\). Then, this sample is accepted with probability \(\alpha(x,y)=\min\left\{1,\frac{\pi(y|q(x|y)|}{\pi(x)q(y|x)}\right\}\). This strategy generates a Markov chain with the desired stationary distribution and, under mild conditions on the proposal and the target, also ensures that the Markov chain is ergodic [65]. However, for high-dimensional, multi-modal settings, such methods can easily get stuck in local modes, and suffer from very slow mixing times [e.g., 48].

Naturally, the choice of proposal distribution \(q(\cdot|x)\) is critical to ensuring that MH MCMC algorithms explore the target distribution within a reasonable number of iterations. A key goal is to obtain proposal distributions with fast mixing times, which can be applied generically to any target distribution. This is particularly challenging in the face of complex, multi-modal (or metastable) distributions, which commonly arise in applications such as genetics [38], protein folding [41], astrophysics [22], and sensor network localization [37]. On the one hand, local proposals, such as those employed in the Metropolis-Adjusted Langevin Algorithm (MALA) [66] or Hamiltonian Monte Carlo (HMC) [20; 56] struggle to transition between regions of high-probability, resulting in very long decorrelation times and few effective independent samples [e.g., 49]. On the other hand, global proposal distributions must be very carefully designed in order to avoid high rejection rates, particularly in high dimensions [17; 47].

Another popular approach to sampling is variational inference (VI) [10; 34; 61; 79], which obtains a parametric approximation \(\pi_{\theta^{*}}(x)\approx\pi(x)\) to the target by minimising the Kullback-Leibler (KL) divergence to the target over a parameterized family of distributions \(\mathcal{D}_{\theta}=\{\pi_{\theta}:\theta\in\Theta\}\). State-of-the-art VI methods use normalizing flows (NFs), which consist of a sequence of invertible transformations between a reference and a target distribution, to define a flexible variational family [62]. There has also been growing interest in the use of continuous normalizing flows (CNFs), which define a path between distributions using ordinary differential equations [15; 27; 45]. CNFs avoid the need for strong constraints on the flow but, until recently, have been hampered by expensive maximum likelihood training.

In recent years, several works have sought hybrid methods which utilize NFs to enhance the performance of MCMC algorithms; see, e.g., [28] for a recent review. For example, NFs have been successfully used to precondition complex Bayesian posteriors, significantly improving the performance of existing MCMC methods [e.g., 33; 39; 59; 68]. The synergy between local MCMC proposals and global, flow-informed proposals has also been explored, leading to enhanced mixing rates and effective estimation of multimodal targets [e.g., 24; 67].

Our contributionsIn this paper, we continue this promising line of work, introducing a new probabilistic inference scheme which integrates CNFs with MCMC sampling techniques. Our approach utilizes flow matching (FM), a scalable, simulation-free training objective for CNFs recently introduced by Lipman et al. [45]. This enables, for the first time, the incorporation of CNFs into an adaptive MCMC algorithm. Concretely, our approach augments a local, gradient-based Markov transition kernel with a non-local, flow-informed transition kernel, defined using a CNF. This CNF, and the corresponding transition kernel, are adapted on-the-fly using samples from the chain, which are used to define the probability path for the FM objective. Our scheme also includes an adaptive tempering mechanism, which is essential for discovering multiple modes in complex target distributions. Under mild assumptions, we establish that the flow-network parameters output by our method converge to a local optimum of the FM objective. We then demonstrate empirically the performance of our approach on several synthetic and real-world examples, illustrating comparable or superior performance to other state-of-the-art sampling methods.

## 2 Preliminaries

Continuous Normalizing FlowsA continuous normalizing flow (CNF) is a continuous-time generative model which is trained to map samples from a base distribution \(p_{0}\) to a given target distribution [15]. Let \(v_{t}\) be a time-dependent vector field that runs continuously in the unit interval. Under mild conditions, this vector field can be used to construct a time-dependent diffeomorphic map called a flow \(\phi:[0,1]\times\mathbb{R}^{d}\to\mathbb{R}^{d}\), defined via the ordinary differential equation (ODE):

\[\frac{\mathrm{d}}{\mathrm{d}t}\phi_{t}(x)=v_{t}(\phi_{t}(x)),\quad\phi_{0}(x)=x. \tag{2}\]

Given a reference density \(p_{0}:\mathbb{R}^{d}\to\mathbb{R}_{+}\), and the flow \(\phi\), we can generate a probability density path \(p:[0,1]\times\mathbb{R}^{d}\to\mathbb{R}_{+}\) as the pushforward of \(p_{0}\) under \(\phi\), viz \(p_{t}:=[\phi_{t}]_{\sharp}p_{0}\), for \(t\in[0,1]\). This yields, via the instantaneous change-of-variables formula (e.g., [14])

\[\log p_{t}(x_{t})=\log p_{0}(x)-\int_{0}^{t}\nabla\cdot v_{s}(x_{s})\mathrm{d}s, \tag{3}\]

where \(x_{s}:=\phi_{s}(x)\), and where \(\nabla\) is the divergence operator, i.e. the trace of the Jacobian matrix. In modern applications, the vector field \(v_{t}\) is often parameterized using a neural network \(v_{t}^{\theta}\), in which case the ODE in (2) is referred to as a neural ODE [15]. In turn, this yields a deep parametric model \(\phi_{t}^{\theta}\) for the flow \(\phi_{t}\), known as a CNF [27].

Flow MatchingOne would typically like to learn a CNF which maps between a given reference density \(p_{0}\) and a target density \(\pi\). Given samples from the target, one approach is to maximize the log-likelihood \(\mathbb{E}_{x\sim\pi}\left[\log p_{t}^{\theta}(x)\right]\). In practice, however, maximum likelihood training is very slow as both sampling and likelihood evaluation require multiple network passes to solve the ODE in (2).

Flow Matching (FM) provides an alternative, simulation-free method for training CNFs [45]. Let \(p_{t}(x)\) be a target probability density path such that \(p_{0}=p\) is a simple reference distribution, and \(p_{1}\approx\pi\) is approximately equal to the target distribution. Let \(v_{t}(x)\) be a vector field which generates this \(p_{t}(x)\). Then the FM objective for the CNF vector field \(v_{t}^{\theta}(x)\) is defined as

\[\mathcal{L}(\theta;\pi)=\mathbb{E}_{t\sim\mathcal{U}(0,1)}\mathbb{E}_{x\sim p_ {t}}\left[\|v_{t}^{\theta}(x)-v_{t}(x)\|_{2}^{2}\right]. \tag{4}\]

In practice, we do not have direct access to the target vector field, \(v_{t}(x)\), and so we cannot minimize (4) directly. However, as shown in Lipman et al. [45, Theorem 2], it is equivalent to minimize the conditional flow-matching (CFM) loss

\[\mathcal{J}(\theta;\pi)=\mathbb{E}_{t\sim\mathcal{U}(0,1)}\mathbb{E}_{x_{1} \sim\pi}\mathbb{E}_{x\sim p_{t}(\cdot|x_{1})}\left[\|v_{t}^{\theta}(x)-v_{t}( x|x_{1})\|_{2}^{2}\right], \tag{5}\]

where \(p_{t}(\cdot|x_{1})\) is a conditional probability density path satisfying \(p_{0}(x|x_{1})=p_{0}\) and \(p_{1}(x|x_{1})\approx\delta_{x_{1}}\), and \(v_{t}(\cdot|x_{1}):\mathbb{R}^{d}\to\mathbb{R}^{d}\) is a conditional vector field that generates \(p_{t}(\cdot|x_{1})\). There are various choices for \(p_{t}(\cdot|x_{1})\) and \(v_{t}(\cdot|x_{1})\). For simplicity, we here assume that the conditional probability path is Gaussian, viz \(p_{t}(x|x_{1})=\mathcal{N}(x|m_{t}(x_{1}),s_{t}(x_{1})^{2}\mathbb{I}_{d})\), where \(m:[0,1]\times\mathbb{R}^{d}\to\mathbb{R}^{d}\) denotes a time-dependent mean, and \(s:[0,1]\times\mathbb{R}\to\mathbb{R}_{+}\) a time-dependent scalar standard deviation. For our experiments, we further adopt the optimal transport conditional probability path introduced in [45], setting \(m_{t}(x_{1})=tx_{1}\) and \(s_{t}(x_{1})=1-(1-\sigma_{\min})t\) for some \(\sigma_{\min}\ll 1\). In this case, the conditional vector field assumes the particularly simple form \(v_{t}(x|x_{1})=\frac{x_{1}-(1-\sigma_{\min})x}{1-(1-\sigma_{\min})t}\).

## 3 Markovian Flow Matching

In this section, we present our main contribution, an adaptive MCMC algorithm which combines a non-local, flow-informed transition kernel trained via FM; a local, gradient-based Markov transition kernel; and an adaptive annealing schedule. We begin by describing how CNFs can be used within a MH MCMC algorithm.

### MCMC with Flow Matching

Suppose, for now, that we have access to a CNF \((\phi_{t}^{\theta})_{t\in[0,1]}\), trained (e.g.) via flow-matching, with corresponding vector field \((v_{t}^{\theta})_{t\in[0,1]}\), which generates a probability path \((p_{t}^{\theta})_{t\in[0,1]}\) between a reference density \(p_{0}\) and an approximation of the target density \(\pi\). Given a point \(x_{0}\in\mathbb{R}^{d}\) on the reference space, we can evaluate the log-density of the pullback of the target distribution \(\pi\) as

\[\log[\phi_{1}^{\theta}]^{\sharp}\pi(x_{0})=\log\pi(\phi_{1}^{\theta}(x_{0}))- \int_{1}^{0}\nabla\cdot v_{t}^{\theta}(\phi_{t}^{\theta}(x_{0}))\mathrm{d}t. \tag{6}\]Under the assumption that the CNF approximately transports samples from \(p_{0}\) to \(\pi\), we expect that \([\phi_{1}^{\theta}]_{i}p_{0}\approx\pi\) in the target space, and that \([\phi_{1}^{\theta}]^{\pi}\pi\approx p_{0}\) in the reference space. Given that the reference distribution \(p_{0}\) is chosen such that it is easy to sample from, this suggests the following strategy, sometimes referred to as _neural trasport MCMC_ or _neutrinoMCMC_[28, 33, 44, 59]. First, transform initial positions \(x_{1}\) from the target space to the reference space by solving

\[\begin{bmatrix}x_{0}\\ \log p_{1}^{\theta}(x_{1})-\log p_{0}(x_{0})\end{bmatrix}=\begin{bmatrix}x_{1} \\ 0\end{bmatrix}+\int_{1}^{0}\begin{bmatrix}v_{t}^{\theta}(x_{t})\\ -\nabla\cdot v_{t}^{\theta}(x_{t})\end{bmatrix}\mathrm{d}t, \tag{7}\]

which integrates the combined dynamics of \(x_{t}\) and the log-density of the sample backwards in time. Then, generate MCMC proposals \(y_{0}\) in the reference space using any standard MCMC scheme which targets the pullback of the target distribution, as defined in (6). Finally, transform accepted proposals back to target space using the forward dynamics, viz

\[\begin{bmatrix}y_{1}\\ \log p_{1}^{\theta}(y_{1})-\log p_{0}(y_{0})\end{bmatrix}=\begin{bmatrix}y_{0} \\ 0\end{bmatrix}+\int_{0}^{1}\begin{bmatrix}v_{t}^{\theta}(y_{t})\\ -\nabla\cdot v_{t}^{\theta}(y_{t})\end{bmatrix}\mathrm{d}t. \tag{8}\]

This corresponds to using a transformation-informed proposal in a Markov transition step, an approach which has been successfully applied using (discrete) normalizing flows [28, 33, 44, 59].

There are various possible choices for the proposal distribution on the reference space (see Appendix A). For example, [23] consider an independent MH (IMH) proposal, where i.i.d. samples are drawn from the reference distribution. Here we focus on a flow-informed random-walk, motivated largely by its superior empirical performance in numerical experiments. This proposal performs particularly well on high-dimensional problems, where overfitting of the CNF can be corrected with stochastic steps, while exacerbated by independent proposals [39]. Concretely, our flow-informed random-walk transition kernel, summarized in Algorithm 2 (see Appendix A), can be written as

\[P(x,\mathrm{d}y;\pi,\theta)=\alpha(x,y)\rho_{\theta}(\mathrm{d}y|x)+(1-b(x)) \delta_{x}(\mathrm{d}y), \tag{9}\]

where \(\rho_{\theta}(\mathrm{d}y|x)\) is the distribution defined by the transition

\[x_{0}=x+\int_{1}^{0}v_{t}^{\theta}(\phi_{t}^{\theta}(x))\mathrm{d}t,\quad y_{ 0}\sim\mathcal{N}(x_{0},\sigma_{\mathrm{opt}}^{2}),\quad y=y_{0}+\int_{0}^{1} v_{t}^{\theta}(\phi_{t}^{\theta}(y_{0}))\mathrm{d}t, \tag{10}\]

and \(\alpha(x,y)=\min\left\{1,\frac{\pi(y)\rho_{\theta}(x|y)}{\pi(x)\rho_{\theta}( y|x)}\right\}\) and \(b(x)=\int_{\mathbb{R}^{d}}\alpha(x,y)\rho_{\theta}(\mathrm{d}y|x)\).

Training the CNFThus far, we have assumed that it is possible to train a CNF which maps samples from the reference distribution \(p_{0}\) to (an approximation of) the target distribution \(\pi\). Clearly, however, the CFM objective is not immediately applicable in our setting, since we do not have access to samples from the target \(\pi\).

Tong et al. [72] propose two alternatives in this case: (i) use an importance sampling reweighted objective function, or (ii) use samples from a long-run MCMC algorithm (e.g., MALA) as approximate target samples. Both of these approaches, however, have limitations. The former is unlikely to succeed when the proposal distribution differs significantly from the target distribution, while the latter will only perform well when the chosen MCMC method mixes well.

In this paper, we adopt a different approach, updating the parameters of a CNF based on a dynamic estimate of the CFM objective obtained via an adaptive MCMC algorithm. This is similar in spirit to other recent flow-informed MCMC algorithms [24, 35, 67], and the _Markovian score climbing_ algorithm in [54].

### Adaptive MCMC with Flow Matching

OverviewOur adaptive MCMC scheme combines a non-local, flow-informed transition kernel (e.g., a flow informed random-walk) and a local transition kernel (e.g., MALA), which generate new samples from a sequence of annealed target distributions. These new samples are used to define a new estimate of the CFM objective in (5), which is optimized to define a new CNF. These steps are repeated until the samples converge in distribution to the target \(\pi\), and the flow-network parameters converge to a local minima of the flow matching objective (see Proposition 3.1). This scheme, which we refer to as _Markovian Flow Matching_ (MFM), is summarized in Algorithm 1.

SamplingThere is significant freedom regarding the choice of both the local and the non-local MCMC algorithms. In our experiments, we adopt the Metropolis-Adjusted Langevin Algorithm (MALA) as the local algorithm. Thus, the local Markov kernel \(Q\) is given by

\[Q(x,\mathrm{d}y;\pi)=\alpha(x,y)q(\mathrm{d}y|x)+(1-b(x))\delta_{x}(\mathrm{d}y), \tag{11}\]

where \(q(\mathrm{d}y|x)\) is given by

\[q(\mathrm{d}y|x)\propto\exp\left(-\frac{1}{4\tau}\|y-x-\tau\nabla\log\pi(x)\|^{ 2}\right)\mathrm{d}y, \tag{12}\]

and where, as elsewhere, \(\alpha(x,y)=\min\left\{1,\frac{\pi(y)q(x|y)}{\pi(x)q(y|x)}\right\}\) and \(b(x)=\int_{\mathbb{R}^{d}}\alpha(x,y)q(\mathrm{d}y|x)\). In principle, however, other choices such as HMC could also be used.

Meanwhile, for the non-local MCMC algorithm, we adopt the flow-informed random walk with non-local Markov kernel \(P\) defined in (9). Together, assuming alternate local and non-local steps, these two kernels define a Markov chain with Markov transition kernel \(R:=P\circ Q\), given explicitly by \(R(x,\mathrm{d}y;\pi,\theta)=\int_{\mathcal{Z}}Q(x,\mathrm{d}z;\pi)P(z,\mathrm{ d}y;\pi,\theta)\). In practice, the balance between local and non-local moves is controlled by the hyperparameter \(k_{Q}\), which sets the number of local steps before a global step.

TrainingFollowing each MCMC step, the parameters of the flow-informed Markov transition kernel \(P\) are updated based on a new estimate of \(\mathcal{J}(\theta;\pi)\). To be precise, suppose we write \(\mu_{t}:=\mu_{0}R^{k}(\cdot,\cdot;\pi,\theta)\) for the distribution of the Markov chain with kernel \(R(\cdot,\cdot;\pi,\theta)\) after \(k\in\mathbb{N}\) steps, starting from initialization \(\mu_{0}\), where \(R^{k}=R\circ R\cdots\circ R\). Our objective function is then given by

\[\mathcal{J}(\theta;\mu_{k})=\mathbb{E}_{t\sim\mathcal{U}(0,1)}\mathbb{E}_{x_{1 }\sim\mu_{k}}\mathbb{E}_{x\sim p_{t}(\cdot|x_{1})}\left[\|v_{t}^{\theta}(x)-v_ {t}(x|x_{1})\|_{2}^{2}\right]. \tag{13}\]

For our choice of conditional probability path (i.e., the optimal transport path), we can in fact rewrite this objective as [45, Section 4.1]

\[\mathcal{J}(\theta;\mu_{k},\sigma_{\min})=\mathbb{E}_{t\sim\mathcal{U}(0,1)} \mathbb{E}_{x_{1}\sim\mu_{k}}\mathbb{E}_{x_{0}\sim p_{0}}\left[\left|\left|v_ {t}^{\theta}(\phi_{t}(x_{0}|x_{1}))-v_{t}(\phi_{t}(x_{0}|x_{1})|x_{1})\right| \right|_{2}^{2}\right], \tag{14}\]

where \(v_{t}(x|x_{1})=\frac{x_{1}-(1-\sigma_{\min})x}{1-(1-\sigma_{\min})t}\) and \(\phi_{t}(x|x_{1})=(1-(1-\sigma_{\min}t)x+tx_{1}\). In practice, we will optimize a Monte Carlo estimate of this objective, namely,

\[\mathcal{J}(\theta;\{x^{i}(k)\}_{i=1}^{N},\sigma_{\min})=\frac{1}{N}\sum_{i=1} ^{N}\left|\left|v_{t_{i}}^{\theta}(\phi_{t_{i}}(x_{0}^{i}|x^{i}(k)))-v_{t_{i}} (\phi_{t_{i}}(x_{0}^{i}|x^{i}(k))|x^{i}(k))\right|\right|_{2}^{2}, \tag{15}\]

where \(\mathbb{E}_{t\sim\mathcal{U}(0,1)}^{N}\)\(\mathbb{E}_{t\sim\mathcal{U}(0,1)}^{N}\) are the samples from \(N\) chains of our MCMC algorithm after \(k\in\mathbb{N}\) iterations, \(x_{0}^{i}\stackrel{{ i.e.\ref{eq:mcmc}}}{{\sim}}p_{0}\), and \(t_{i}\sim\mathcal{U}(0,1)\). The use of \(N\) particles allow the state's mutation to \(N\) computing cores running in parallel at each iteration. Sampling steps can be run in parallel using modern vector-oriented libraries, before each particle is used to approximate the loss and update the parameters. Thus, the speedup gained by using more than one core scales linearly with the number of cores as long as there are as many cores as there are particles.

AnnealingFor complex (e.g., multimodal) target distributions, it can be challenging to learn a CNF that successfully maps between the reference \(p_{0}\) and the target \(\pi\). For example, if the locations of the modes of the target are not known a priori, and the MCMC chains are initialized far from one or more of the modes, it is unlikely that the local MCMC kernel, and therefore the trained flow, will ever discover these modes [e.g., 24, Section IV.C]. To alleviate this problem, one approach is to iteratively target a sequence of annealed densities \(\{\pi_{k}(x)\}_{k=0:K}\), which smoothly interpolate between a simple base distribution \(\pi_{0}(x)\) (e.g., a standard Gaussian), and the target distribution \(\pi_{K}(x):=\pi(x)\). This idea is central to other Monte Carlo sampling methods such as Sequential Monte Carlo (SMC) [18] and Annealed Importance Sampling (AIS) [55], as well as sampling methods used in score-based generative modelling [e.g., 70]. In our case, the annealed targets act as intermediary steps within the flow-informed MCMC scheme.

A standard way in which to construct the sequence \(\{\pi_{k}(x)\}_{k=0:K}\) is to use a geometric interpolation, defining

\[\pi_{k}(x)=\pi_{K}(x)^{\beta_{k}}\pi_{0}(x)^{1-\beta_{k}}, \tag{16}\]where \(\beta_{0:K}\) is a sequence of temperatures which satisfies \(0=\beta_{0}<\beta_{1}<\cdots<\beta_{K}=1\) [e.g., 55]. In practice, it can be difficult to choose a good sequence of temperatures that provides a smooth transition between densities. One heuristic for adaptively setting this sequence is based on the effective sample size (ESS). In particular, by setting the ESS to a user-specified percentage \(\alpha\) of the number of particles \(N\), the next temperature \(\beta_{k}\) in the schedule can be determined by solving the recursive equation [9]

\[\beta_{k}=\inf\bigg{\{}\beta_{k-1}<\beta\leq 1:\frac{\Big{[}\frac{1}{N}\sum_{i=1} ^{N}w_{i}^{\beta_{k-1}}(\beta)\Big{]}^{2}}{\frac{1}{N}\sum_{i=1}^{N}w_{i}^{ \beta_{k-1}}(\beta)^{2}}=\alpha\bigg{\}}, \tag{17}\]

where \(w_{i}^{\beta_{k-1}}(\beta)=\left[\pi_{K}(x^{i})^{\beta}\pi_{0}(x^{i})^{1-\beta }\right]/\left[\pi_{K}(x^{i})^{\beta_{k-1}}\pi_{0}(x^{i})^{1-\beta_{k-1}}\right] =[\pi_{K}(x^{i})/\pi_{0}(x^{i})]^{\beta-\beta_{k-1}}\) are new importance weights given the current temperature \(\beta_{k-1}\). In practice, we find that the inclusion of this adaptive tempering scheme is essential in the presence of highly multimodal target distributions, enabling the discovery of modes which are not known _a priori_.

ConvergenceThe output of Algorithm 1 is a vector of parameters \(\theta_{K}\) which defines a CNF \((\phi_{t}^{\theta_{K}})_{t\in[0,1]}\). Under the assumption that the parameter estimate converges, that is, \(\theta_{K}\rightarrow\theta_{\text{global}}^{*}\) as \(K\rightarrow\infty\), where \(\theta_{\text{global}}^{*}=\arg\min_{\theta\in\Theta}\mathcal{J}(\theta;\pi)\) is the global minimizer of the CFM objective \(\mathcal{J}(\theta;\pi)\) in (5), this CNF is guaranteed to generate a probability path \((p_{t}^{\theta})_{t\in[0,1]}\) which transports samples from the reference \(p_{0}\) to the true target \(\pi\) [e.g., 45].

In practice, the objective \(\mathcal{J}(\theta;\pi)\) is highly non-convex, and thus it is not possible to establish a convergence result of this type without imposing unreasonably strong assumptions on the vector field \((v_{t}^{\theta})_{t\in[0,1]}\). This being said, it is reasonable to ask whether \(\theta_{K}\) converges to a local optimum of the CFM objective. We now answer this question in the affirmative. In particular, under mild regularity conditions, Proposition 3.1 guarantees that \(\theta_{K}\rightarrow\theta^{*}\) almost surely as \(K\rightarrow\infty\), where \(\theta^{*}\) denotes a local minimum of the CFM objective. This proposition closely mirrors [54, Proposition 1]. Its proof, which relies on a classical result in [6, Theorem 3.17], is provided in Appendix B.

**Proposition 3.1**.: _Assume that Assumptions B.1 - B.6 hold (see Appendix B). Assume also that \((\theta_{K})_{K\in\mathbb{N}}\) is a bounded sequence, which almost surely visits a compact subset of the domain of attraction of \(\theta^{*}\) infinitely often. Then \(\theta_{K}\rightarrow\theta^{*}\) almost surely._

## 4 Related work

In recent years, a number of works have proposed algorithms which combine MCMC techniques with NFs; see, e.g., [2, 28] for recent surveys. Broadly speaking, these algorithms fall into two distinct categories. _NeutraMCMC_ methods leverage NFs as reparameterization maps which simplify the geometry of the target distribution, before running (local) MCMC samplers in the latent space. This technique was pioneered in the seminal paper [59], and since been investigated in a number of different works [e.g., 13, 33, 44, 54, 58, 68, 82, 84]. _Flow MCMC_ methods, meanwhile, utilize the pushforward of the base distribution through the NF as an (independent) proposal within an MCMC scheme. This approach was first studied by [3], and further extended in [4, 31, 57].

More recently, [24, 67] have introduced adaptive MCMC schemes which combine local MCMC samplers (e.g., MALA or HMC), with a non-local, flow-informed proposal (IMH or i-SIR); see also [35]. Our algorithm combines aspects of both _neutraMCMC_ and _flow MCMC_ methods and, unlike any existing approach, make use of a CNF (as opposed to a discrete NF), by leveraging the conditional flow matching objective. The use of NFs within other Monte Carlo algorithms has also been the subject of recent interest. For example, [5, 50] consider augmenting SMC with NFs, while [19, 52] use NFs (or diffusion models) within AIS.

Although less directly comparable to our own approach, several other recent works have proposed to use (controlled) diffusion processes to sample from unnormalized probability distributions. Such works include Zhang and Chen [85], who introduce the _path integral sampler_, Vargas et al. [75], who propose the _denoising diffusion sampler_, and Zhang et al. [83], who introduce _generative flow samplers_. Some other relevant contributions in this direction include [1, 8, 16, 60, 63, 69, 73, 74, 75, 76, 77, 78].

## 5 Experiments

In this section, we evaluate the performance of MFM (Algorithm 1) on two synthetic and two real data examples. Our method is benchmarked against four relevant methods. The Denoising Diffusion Sampler [DDS; 75] is a VI method which approximates the reversed diffusion process from a reference distribution to an extended target distribution by minimizing the KL divergence. Adaptive Monte Carlo with Normalizing Flows [NF-MCMC; 24] is an augmented MCMC scheme which uses a mixture of MALA and adaptive transition kernels learned using discrete NFs. Flow Annealed Importance Sampling Bootstrap [FAB; 52] is an augmented AIS scheme minimizing the mass-covering \(\alpha\)-divergence with \(\alpha=2\). Finally, Adaptive Tempered SMC (AT-SMC), i.e. the SMC algorithm described in [18] using a MALA transition kernel and a sequence of annealed distributions chosen adaptively by solving (17).

For each experiment, all MALA kernels use the same step size, targeting an acceptance rate of close to 1 since we estimate expectations, e.g. in (14), using the current ensemble of particles, rather than a single long chain. Following [85], we parameterize the vector field as

\[\text{NN}^{*}(t;\theta_{3})v_{t}^{\theta}(x)=\text{NN}(x,t;\theta_{1})+\text{ NN}(t;\theta_{2})\times\nabla\log\pi(x), \tag{18}\]

where the neural networks are standard MLPs with 2 hidden layers, using a Fourier feature augmentation for \(t\)[71], and where NN\({}^{*}\) outputs a real value that reweights the vector field output using the time component. This architecture is also used by DDS [75, Section 4]. Meanwhile, FAB and NF-MCMC use rational quadratic splines [21]. Flows are trained using Adam [40] with a linear decay schedule terminating at \(\varepsilon_{K}=0\). We report results for all methods averaged over 10 independent runs with varying random seeds. Code to reproduce the experiments is provided at [https://github.com/albcab/mfm](https://github.com/albcab/mfm).

### 4-mode Gaussian mixture

Our first example is a mixture of four Gaussians, evenly spaced and equally weighted, in two-dimensional space. The four mixture components have means \((8,8)\), \((-8,8)\), \((8,-8)\), \((-8,-8)\), and all have identity covariance. This ensures that the modes are sufficiently separated to mean that jumping between modes requires trajectories over sets with close to null probability. Given the synthetic nature of the problem, we can measure approximation quality using the Maximum Mean Discrepancy (MMD) [e.g., 29]; see Appendix C.1 for details. We can also include, as a benchmark, the results for an approximation learned using FM with true target samples. Diagnostics for all models are presented in Table 1, and learned flow samples in Figure 1. Further algorithmic details and results are provided in Appendix C.2.

In this experiment, only our method (Figure 0(a)) and DDS (Figure 0(c)) learn the fully separated modes, reflecting the greater expressivity of CNFs in comparison to the discrete NFs used in, e.g., NF-MCMC(Figure 0(d)). It is worth noting that DDS provides a closer approximation to the real target than MFM and, notably, even FM trained using true target samples (top row). Given that both methods use the same network architecture but a different learning objective, this suggests a potential limitation with the FM objective, at least when using this network architecture. This being said, MFM is notably more efficient than DDS (as well as the other methods) in terms of total computation time. While this is not a critical consideration in this synthetic, low-dimensional setting, it is a significant advantage of MFM in higher-dimensional settings involving real data (e.g., Section 5.3 and Section 5.4).

### 16-mode Gaussian mixture

The second experiment is a mixture of bivariate Gaussians with 16 mixture components. This is a modification of the 4-mode example, with contrasting qualities that illustrate other characteristics of each of the presented methods. In this case, the modes are evenly distributed on \([-16,16]^{2}\), with random log-normal variances. The number of modes reduces the size of sets of (near) null probability between the modes, making jumping between them easier. To increase the difficulty of this model, all methods are initialized on a concentrated region of the sampling space. Diagnostics are presented in Table 1 and learned flow samples in Figure 2. Further details are provided in Appendix C.3.

In this example, DDS collapses to the modes closest to the initial positions while our method captures the whole target. Since the modes are no longer separated by areas of near-zero probability, the discrete NF methods are now able to accurately capture the target density. In this case, FAB marginally outperforms MFM as measured by the MMD, but this slight improvement in performance comes at the cost of a much higher run-time.

### Field system

Our first real-world example considers the stochastic Allen-Cahn model [7], used as a benchmark in [24], and described in Appendix C.5. This fundamental reaction-diffusion equation is central to the study of phase transitions in condensed matter systems. Incorporating random forcing terms or thermal fluctuations allows for a stochastic treatment of the dynamics, capturing the inherent randomness and uncertainties in physical systems. This model leads to a discretized target density

\begin{table}
\begin{tabular}{l|c c|c c}  & \multicolumn{2}{c|}{4-mode} & \multicolumn{2}{c}{16-mode} \\ \hline \hline  & MMD & seconds & MMD & seconds \\ \hline \hline FM w/ \(\pi\) samples & \(3.69\)e-4\(\pm 1.84\)e-4 & \(22.3\pm 0.64\) & \(1.35\)e-3\(\pm 6.66\)e-4 & \(22.4\pm 1.01\) \\ \hline MFM \(k_{Q}=K\) & \(2.37\)e-3\(\pm 2.29\)e-3 & \(27.9\pm 1.27\) & \(1.88\)e-2\(\pm 3.67\)e-3 & \(28.2\pm 2.84\) \\ MFM \(k_{Q}=10\) & \(8.13\)e-4\(\pm 4.41\)e-4 & \(117.\pm 5.65\) & \(2.87\)e-3\(\pm 9.67\)e-4 & \(89.6\pm 5.19\) \\ DDS & \(1.76\)e-4\(\pm 2.32\)e-4 & \(114.\pm 0.68\) & \(1.02\)e-1\(\pm 4.10\)e-2 & \(115.\pm 0.64\) \\ NF-MCMC & \(5.85\)e-3\(\pm 3.91\)e-3 & \(72.0\pm 11.7\) & \(8.05\)e-3\(\pm 1.42\)e-2 & \(67.0\pm 12.3\) \\ FAB & \(2.69\)e-4\(\pm 2.06\)e-4 & \(101.\pm 3.24\) & \(1.51\)e-3\(\pm 1.06\)e-3 & \(102.\pm 4.32\) \\ AT-SMC & \(3.95\)e-2\(\pm 2.90\)e-2 & \(2.18\pm 0.26\) & \(1.73\)e-2\(\pm 5.30\)e-3 & \(2.19\pm 0.21\) \\ \hline \end{tabular}
\end{table}
Table 1: Diagnostics for the two synthetic examples. MMD is the Maximum Mean Discrepancy between real samples from the target and samples generated from the learned flow. Results are averaged and empirical 95% confidence intervals over 10 independent runs.

Figure 1: Comparison between MFM, FAB, DDS, and NF-MCMC. Samples from the target density for the 4-mode Gaussian mixture example.

which takes the form

\[\log\pi(x)=-\beta\bigg{(}\frac{a}{2\Delta s}\sum_{i=1}^{d+1}(x_{i}-x_{i-1})^{2}+ \frac{b\Delta s}{4}\sum_{i=1}^{d}(1-x_{i}^{2})^{2}\bigg{)}, \tag{19}\]

with \(\Delta s=\frac{1}{d}\), and boundary conditions \(x_{0}=x_{d+1}=0\). In our experiments, we take \(d=64\). Meanwhile, following [24], other parameter values are chosen to ensure bimodality at \(x=\pm 1\): \(a=0.1\), \(b=1/a=10\), and \(\beta=20\). The bimodality induced by the two global minima complicates mixing when using traditional MCMC updates. Learning the global geometry of the target and using that information to propose transitions facilitates movement between modes. Unlike previous work [e.g., 24], we deliberately choose not to employ an informed base measure. Instead, we opt for a standard Gaussian with no additional information, making the problem significantly more challenging. This choice illustrates the robustness of our approach.

Numerical diagnostics for each method are presented in Table 2. In this case, we use the Kernelized Stein Discrepancy (KSD) as a measure of sample quality [e.g., 26, 46]; see Appendix C.1 for details. While this is not a perfect metric, it does allow us to qualitatively compare the different methods considered.

In this case, the tempering mechanism of our method is crucial for ensuring that the learned flow does not collapse on one of the modes and instead explores both global minima. This is confirmed when plotting the samples generated in the grid in Figure 3. This experiment demonstrates the ability of our method to capture complex multi-modal densities, even without an informed base measure, at a _significantly_ lower computational cost (e.g., 10-25x faster) than competing methods. Indeed, while FAB was the best performing method in this experiment as measured by the KSD, it failed to capture both of the modes in the target distribution, and required a much greater total computation time (see Table 2).

It is worth noting that MFM (and the other two benchmarks, DDS and FAB) significantly outperformed NF-MCMC in this example, despite the similarities between MFM and NF-MCMC. While we tested various hyperparameter configurations for NF-MCMC, we were not able to find a setting that achieved comparable results in the absence of an informed base measure.

Figure 3: Comparison between MFM, FAB, DDS, and NF-MCMC. Representative samples from the target density for the Field system example.

Figure 2: Comparison between MFM, FAB, DDS, and NF-MCMC. Samples from the target density for the 16-mode Gaussian mixture example.

### Log-Gaussian Cox process

Bayesian inference for high-dimensional spatial models is known to be challenging. One such model is the log-Gaussian Cox process (LGCP) introduced in [53], which is used to model the locations of 126 Scots pine saplings in a natural forest in Finland. See Appendix C.6 for full details. The target space is discretized to a \(M=40\times 40\) regular grid, rendering the target dimension \(d=1600\). In Table 2, we report diagnostics for each algorithm.

In this case, the lack of multimodality in the target makes it a good fit for non-tempered schemes. Similar to the previous example, NF-MCMC is unable to obtain an accurate approximation to the target distribution. We suspect that this may be a result of non-convergence: due to memory issues, it was not possible to run NF-MCMC (or FAB) for more than \(K=10^{3}\) iterations. This also explains the (relatively) smaller run times of these algorithms in this example. By a small margin, DDS provides the best approximation of the target, slightly outperforming MFM and FAB. Meanwhile, MFM provides a good approximation to the target at a lower computational cost with respect to its competitors.

## 6 Conclusion

**Summary**. In this paper, we introduced Markovian Flow Matching, a new approach to sampling from unnormalized probability distributions that augments MCMC with CNFs. Our method combines a local Markov kernel with a non-local, flow-informed Markov kernel, which is adaptively learned during sampling using FM. It also incorporates an adaptive tempering mechanism, which allows for the discovery of multiple target modes. Under mild assumptions, we established convergence of the flow network parameters output by our algorithm to a local optimum of the FM objective. We also benchmarked the performance of our algorithm on several examples, illustrating comparable performance to other state-of-the-art methods, often at a fraction of the computational cost.

**Limitations and Future Work**. We highlight three limitations of our work. First, our theoretical result established convergence of the flow network parameters obtained via MFM to a _local_ minimum of the FM objective. Further work is required to understand how well these local minima generalize, in order to accurately quantify how accurately the corresponding CNF captures the target posterior. Second, we did not establish non-asymptotic convergence rates for our method. Finally, since it was not the main focus of this work, we did not explore in great detail other choices of architecture for the flow network. We expect that, for certain targets, this could have a significant impact on the performance of MFM. Indeed, a promising avenue for further research lies in developing tailored CNFs designed for particular posterior distributions. This approach would go beyond the current practice of including the gradient of the log-posterior and instead exploit unique characteristics intrinsic to each model when constructing the flow.

## Acknowledgments and Disclosure of Funding

LS and CN were supported by the Engineering and Physical Sciences Research Council (EPSRC), grant number EP/V022636/1. CN acknowledges further support from the EPSRC, grant numbers EP/S00159X/1 and EP/Y028783/1.

\begin{table}
\begin{tabular}{l|c c c c|c c c}  & \multicolumn{4}{c}{Field system} & \multicolumn{4}{c}{Log-Gaussian Cox} \\ \hline \hline \(K=10^{4}\) & KSD U-stat. & KSD V-stat. & seconds & KSD U-stat. & KSD V-stat. & seconds \\ \hline \hline MFM \(k_{Q}=K\) & \(2.61\pm 2.00\) & \(20.9\pm 2.49\) & \(52.3\pm 1.23\) & \(1.13\)e-\(1\pm.05\) & \(28.1\pm 0.24\) & \(117\pm 4.19\) \\ MFM \(k_{Q}=10^{3}\) & \(2.67\pm 2.16\) & \(21.0\pm 2.66\) & \(53.6\pm 1.33\) & \(1.12\)e-\(1\pm.04\) & \(28.1\pm 0.23\) & \(143\pm 14.5\) \\ DDS & \(15.2\pm 35.9\) & \(18.0\pm 36.9\) & \(2400\pm 8.65\) & \(7.59\)e-\(2\pm.02\) & \(24.7\pm 0.08\) & \(3260\pm 8.41\) \\ NF-MCMC & \(548\pm 325\) & \(549\pm 325\) & \(2000\pm 15.6\) & \(11.8\pm 7.55\) & \(89.0\pm 238\) & \(215\pm 46.4\) \\ FAB & \(0.14\pm 0.42\) & \(1.78\pm 0.42\) & \(3880\pm 7.19\) & \(1.55\)e-\(1\pm.06\) & \(52.3\pm 2.02\) & \(1040\pm 2.78\) \\ AT-SMC & \(1.61\pm 2.33\) & \(18.4\pm 2.35\) & \(4.13\pm 0.30\) & \(1.39\)e-\(2\pm.01\) & \(25.0\pm 0.12\) & \(6.11\pm 0.44\) \\ \hline \hline \end{tabular}
\end{table}
Table 2: Diagnostics for the two real data examples. KSD U-stat and V-stat are the Kernel Stein Discrepancy U- and V-statistics between the target and samples generated from the learned flow. Results are averaged and empirical 95% confidence intervals over 10 independent runs.

## References

* [1] T. Akhound-Sadegh, J. Rector-Brooks, A. J. Bose, S. Mittal, P. Lemos, C.-H. Liu, M. Sendera, S. Ravanbakhsh, G. Gidel, Y. Bengio, et al. Iterated denoising energy matching for sampling from Boltzmann densities. In _Proceedings of the 41st International Conference on Machine Learning (ICML)_, 2024.
* [2] M. S. Albergo and E. Vanden-Eijnden. Learning to sample better. _arXiv preprint arXiv:2310.11232_, 2023.
* [3] M. S. Albergo, G. Kanwar, and P. E. Shanahan. Flow-based generative models for Markov chain Monte Carlo in lattice field theory. _Physical Review D_, 100(3):034515, 2019.
* [4] M. S. Albergo, G. Kanwar, S. Racaniere, D. J. Rezende, J. M. Urban, D. Boyda, K. Cranmer, D. C. Hackett, and P. E. Shanahan. Flow-based sampling for fermionic lattice field theories. _Physical Review D_, 104:114507, 2021. doi: 10.1103/PhysRevD.104.114507.
* [5] M. Arbel, A. Matthews, and A. Doucet. Annealed flow transport Monte Carlo. In _Proceedings of the 38th International Conference on Machine Learning (ICML)_, 2021.
* [6] A. Benveniste, M. Metivier, and P. Priouret. _Adaptive Algorithms and Stochastic Approximations_. Springer-Verlag, Berlin, Heidelberg, 1990. doi: 10.1007/978-3-642-75894-2.
* 27, 2017. doi: 10.1214/17-EJP60.
* [8] J. Berner, L. Richter, and K. Ullrich. An optimal control perspective on diffusion-based generative modeling. _Transaction on Machine Learning Research (TMLR)_, 2024.
* [9] A. Beskos, A. Jasra, N. Kantas, and A. Thiery. On the convergence of adaptive sequential Monte Carlo methods. _Annals of Applied Probability_, 26(2):1111-1146, 2016. doi: 10.1214/15-AAP1113.
* [10] D. M. Blei, A. Kucukelbir, and J. D. McAuliffe. Variational inference: a review for statisticians. _Journal of the American Statistical Association_, 112(518):859-877, 2017. doi: 10.1080/01621459.2017.1285773.
* [11] J. Bradbury, R. Frostig, P. Hawkins, M. J. Johnson, C. Leary, D. Maclaurin, G. Necula, A. Paszke, J. VanderPlas, S. Wanderman-Milne, and Q. Zhang. JAX: composable transformations of Python+NumPy programs, 2018. URL [http://github.com/google/jax](http://github.com/google/jax).
* [12] S. Brooks, A. Gelman, G. Jones, and X.-L. Meng. _Handbook of Markov Chain Monte Carlo_. Chapman and Hall/CRC, 1st edition, 2011. doi: 10.1201/b10905.
* [13] A. Cabezas and C. Nemeth. Transport elliptical slice sampling. In _Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS)_, 2023.
* [14] R. Chen and Y. Lipman. Flow matching on general geometries. In _Proceedings of the 12th International Conference on Learning Representations (ICLR)_, 2024.
* [15] R. T. Chen, Y. Rubanova, J. Bettencourt, and D. K. Duvenaud. Neural ordinary differential equations. In _Proceedings of the 32nd Annual Conference on Neural Information Processing Systems (NeurIPS)_, 2018.
* [16] V. De Bortoli, M. Hutchinson, P. Wirmsberger, and A. Doucet. Target score matching. _arXiv preprint arXiv:2402.08667_, 2024.
* [17] L. Del Debbio, J. Marsh Rossney, and M. Wilson. Efficient modeling of trivializing maps for lattice \(\phi\) 4 theory using normalizing flows: a first look at scalability. _Physical Review D_, 104(9):094507, 2021. doi: 10.1103/PhysRevD.104.094507.
* [18] P. Del Moral, A. Doucet, and A. Jasra. Sequential Monte Carlo samplers. _Journal of the Royal Statistical Society Series B: Statistical Methodology_, 68(3):411-436, 2006.

* Doucet et al. [2022] A. Doucet, W. Grathwohl, A. G. Matthews, and H. Strathmann. Score-based diffusion meets annealed importance sampling. In _Proceedings of the 36th Annual Conference on Neural Information Processing Systems (NeurIPS)_, 2022.
* Duane et al. [1987] S. Duane, A. D. Kennedy, B. J. Pendleton, and D. Roweth. Hybrid Monte Carlo. _Physics letters B_, 195(2):216-222, 1987. doi: 10.1016/0370-2693(87)91197-X.
* Durkan et al. [2019] C. Durkan, A. Bekasov, I. Murray, and G. Papamakarios. Neural spline flows. In _Proceedings of the 33rd Annual Conference on Neural Information Processing Systems (NeurIPS)_, 2019.
* Feroz et al. [2009] F. Feroz, M. Hobson, and M. Bridges. MultiNest: an efficient and robust Bayesian inference tool for cosmology and particle physics. _Monthly Notices of the Royal Astronomical Society_, 398(4):1601-1614, 2009.
* Gabrie et al. [2021] M. Gabrie, G. M. Rotskoff, and E. Vanden-Eijnden. Efficient Bayesian sampling using normalizing flows to assist Markov chain Monte Carlo methods. In _Proceedings of the 38th International Conference on Machine Learning (ICML): 3rd Workshop on Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models_, 2021.
* Gabrie et al. [2022] M. Gabrie, G. M. Rotskoff, and E. Vanden-Eijnden. Adaptive Monte Carlo augmented with normalizing flows. _Proceedings of the National Academy of Sciences_, 119(10):e2109420119, 2022. doi: 10.1073/pnas.2109420119.
* Gelman et al. [1995] A. Gelman, J. B. Carlin, H. S. Stern, and D. B. Rubin. _Bayesian data analysis_. Chapman and Hall/CRC, 1995.
* Gorham and Mackey [2017] J. Gorham and L. Mackey. Measuring sample quality with kernels. In _Proceedings of the Proceedings of the 34th International Conference on Machine Learning (ICML)_, 2017.
* Grathwohl et al. [2018] W. Grathwohl, R. T. Chen, J. Bettencourt, I. Sutskever, and D. Duvenaud. FFJORD: Free-form continuous dynamics for scalable reversible generative models. In _Proceedings of the 7th International Conference on Learning Representations (ICLR)_, 2018.
* Grenioux et al. [2023] L. Grenioux, A. Durmus, E. Moulines, and M. Gabrie. On sampling with approximate transport maps. In _Proceedings of the 40th International Conference on Machine Learning (ICML)_, 2023.
* Gretton et al. [2012] A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Schoolkopf, and A. Smola. A kernel two-sample test. _Journal of Machine Learning Research (JMLR)_, 13:723-773, 2012.
* Gu and Kong [1998] M. G. Gu and F. H. Kong. A stochastic approximation algorithm with Markov chain Monte-Carlo method for incomplete data estimation problems. _Proceedings of the National Academy of Sciences_, 95(13):7270-7274, 1998. doi: 10.1073/pnas.95.13.7270.
* Hackett et al. [2021] D. C. Hackett, C.-C. Hsieh, M. S. Albergo, D. Boyda, J.-W. Chen, K.-F. Chen, K. Cranmer, G. Kanwar, and P. E. Shanahan. Flow-based sampling for multimodal distributions in lattice field theory. _arXiv preprint arXiv:2107.00734_, 2021.
* Hastings [1970] W. K. Hastings. Monte Carlo sampling methods using Markov chains and their applications. _Biometrika_, 57(1):97-109, 1970. doi: 10.1093/biomet/57.1.97.
* Hoffman et al. [2019] M. Hoffman, P. Sountsov, J. V. Dillon, I. Langmore, D. Tran, and S. Vasudevan. Neutra-lizing bad geometry in Hamiltonian Monte Carlo using neural transport. In _Proceedings of the 1st Symposium on Advances in Approximate Bayesian Inference (AABI)_, 2019.
* Hoffman et al. [2013] M. D. Hoffman, D. M. Blei, C. Wang, and J. Paisley. Stochastic variational inference. _Journal of Machine Learning Research_, 14(1):1303-1347, 2013.
* Hunt-Smith et al. [2024] N. T. Hunt-Smith, W. Melnitchouk, F. Ringer, N. Sato, A. W. Thomas, and M. J. White. Accelerating Markov chain Monte Carlo sampling with diffusion models. _Computer Physics Communications_, 296:109059, 2024. doi: 10.1016/j.cpc.2023.109059.
* Hutchinson [1989] M. F. Hutchinson. A stochastic estimator of the trace of the influence matrix for Laplacian smoothing splines. _Communications in Statistics-Simulation and Computation_, 18(3):1059-1076, 1989.

* [37] A. Ihler, J. Fisher III, R. Moses, and A. Willsky. Nonparametric belief propagation for self-localization of sensor networks. _IEEE Journal on Selected Areas in Communications_, 23(4), 2005. doi: 10.1109/JSAC.2005.843548.
* [38] S. T. Jensen, X. S. Liu, Q. Zhou, and J. S. Liu. Computational discovery of gene regulatory binding motifs: a Bayesian perspective. _Statistical Science_, 19(1):188-204, 2004. doi: 10.1214/08834230400000107.
* [39] M. Karamanis, F. Beutler, J. A. Peacock, D. Nabergoj, and U. Seljak. Accelerating astronomical and cosmological inference with preconditioned Monte Carlo. _Monthly Notices of the Royal Astronomical Society_, 516(2):1644-1653, 2022. doi: 10.1093/mnras/stac2272.
* [40] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In _Proceedings of the 3rd International Conference on Learning Representations (ICLR)_, 2015.
* [41] S. Kou, J. Oh, and W. H. Wong. A study of density of states and ground states in hydrophobic-hydrophilic protein folding models by equi-energy sampling. _The Journal of Chemical Physics_, 124(24), 2006. doi: 10.1063/1.2208607.
* [42] A. Lee. _U-Statistics: Theory and Practice_. Taylor & Francis, 1st edition, 1990. doi: 10.1201/9780203734520.
* [43] B. Leimkuhler and C. Matthews. Molecular dynamics. _Interdisciplinary Applied Mathematics_, 39:443, 2015. doi: 10.1007/978-3-319-16375-8.
* [44] S.-H. Li and L. Wang. Neural network renormalization group. _Physical Review Letters_, 121:260601, 2018. doi: 10.1103/PhysRevLett.121.260601.
* [45] Y. Lipman, R. T. Chen, H. Ben-Hamu, M. Nickel, and M. Le. Flow matching for generative modeling. In _Proceedings of the 11th International Conference on Learning Representations (ICLR)_, 2023.
* [46] Q. Liu, J. Lee, and M. Jordan. A kernelized Stein discrepancy for goodness-of-fit tests. In _Proceedings of the 33rd International Conference on Machine Learning (ICML)_, 2016.
* [47] A. H. Mahmoud, M. Masters, S. J. Lee, and M. A. Lill. Accurate sampling of macromolecular conformations using adaptive deep learning and coarse-grained representation. _Journal of Chemical Information and Modeling_, 62(7):1602-1617, 2022. doi: 10.1021/acs.jcim.1c01438.
* [48] O. Mangoubi, N. S. Pillai, and A. Smith. Does Hamiltonian Monte Carlo mix faster than a random walk on multimodal densities? _arXiv preprint arXiv:1808.03230_, 2018.
* [49] O. Mangoubi, N. Pillai, and A. Smith. Simple conditions for metastability of continuous Markov chains. _Journal of Applied Probability_, 58(1):83-105, 2021. doi: 10.1017/jpr.2020.83.
* [50] A. Matthews, M. Arbel, D. J. Rezende, and A. Doucet. Continual repeated annealed flow transport Monte Carlo. In _Proceedings of the 39th International Conference on Machine Learning (ICML)_, 2022.
* [51] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and E. Teller. Equation of state calculations by fast computing machines. _The Journal of Chemical Physics_, 21(6):1087-1092, 1953.
* [52] L. I. Midgley, V. Stimper, G. N. Simm, B. Scholkopf, and J. M. Hernandez-Lobato. Flow annealed importance sampling bootstrap. In _Proceedings of the 11th International Conference on Learning Representations (ICLR)_, 2023.
* [53] J. Moller, A. R. Syversveen, and R. P. Waagepetersen. Log Gaussian Cox processes. _Scandinavian Journal of Statistics_, 25(3):451-482, 1998. doi: 10.1111/1467-9469.00115.
* [54] C. Naesseth, F. Lindsten, and D. Blei. Markovian score climbing: variational inference with KL(pllq). _Proceedings of the 34th Annual Conference on Neural Information Processing Systems (NeurIPS)_, 2020.

* [55] R. M. Neal. Annealed importance sampling. _Statistics and Computing_, 11:125-139, 2001. doi: 10.1023/A:1008923215028.
* [56] R. M. Neal et al. MCMC using Hamiltonian dynamics. _Handbook of Markov chain Monte Carlo_, 2(11):2, 2011.
* [57] K. A. Nicoli, S. Nakajima, N. Strodthoff, W. Samek, K.-R. Muller, and P. Kessel. Asymptotically unbiased estimation of physical observables with neural samplers. _Physical Review E_, 101(2):023304, 2020. doi: 10.1103/PhysRevE.101.023304.
* [58] F. Noe, S. Olsson, J. Kohler, and H. Wu. Boltzmann generators: Sampling equilibrium states of many-body systems with deep learning. _Science_, 365(6457), 2019. doi: 10.1126/science.aaw1147.
* [59] M. D. Parno and Y. M. Marzouk. Transport map accelerated Markov chain Monte Carlo. _SIAM/ASA Journal on Uncertainty Quantification_, 6(2):645-682, 2018. doi: 10.1137/17M1134640.
* [60] A. Phillips, H.-D. Dau, M. J. Hutchinson, V. D. Bortoli, G. Deligiannidis, and A. Doucet. Particle denoising diffusion sampler. In _Proceedings of the 41st International Conference on Machine Learning (ICML)_, 2024.
* [61] R. Ranganath, S. Gerrish, and D. Blei. Black box variational inference. In _Proceedings of the 17th International Conference on Artificial Intelligence and Statistics (AISTATS)_, 2014.
* [62] D. Rezende and S. Mohamed. Variational inference with normalizing flows. In _Proceedings of the 32nd International Conference on Machine Learning (ICML)_, 2015.
* [63] L. Richter, J. Berner, and G.-H. Liu. Improved sampling via learned diffusions. In _Proceedings of the 12th International Conference on Learning Representations (ICLR)_, 2024.
* [64] C. P. Robert and G. Casella. _Monte Carlo Statistical Methods_. Springer-Verlag, New York, 2nd edition, 2004. doi: 10.1007/978-1-4757-4145-22.
* 71, 2004. doi: 10.1214/154957804100000024.
* [66] G. O. Roberts and R. L. Tweedie. Exponential convergence of Langevin distributions and their discrete approximations. _Bernoulli_, 2(4):341-363, 1996.
* [67] S. Samsonov, E. Lagutin, M. Gabrie, A. Durmus, A. Naumov, and E. Moulines. Local-global MCMC kernels: the best of both worlds. In _Proceedings of the 36th Annual Conference on Neural Information Processing Systems (NeurIPS)_, 2022.
* [68] C. Schonle and M. Gabrie. Optimizing Markov chain Monte Carlo convergence with normalizing flows and Gibbs sampling. In _Proceedings of the 37th Annual Conference on Neural Information Processing Systems (NeurIPS): AI for Science Workshop_, 2023.
* [69] M. Sendera, M. Kim, S. Mittal, P. Lemos, L. Scimeca, J. Rector-Brooks, A. Adam, Y. Bengio, and N. Malkin. Improved off-policy training of diffusion samplers. _arXiv preprint arXiv:2402.05098_, 2024.
* [70] Y. Song and S. Ermon. Generative modeling by estimating gradients of the data distribution. In _Proceedings of the 33rd Annual Conference on Neural Information Processing Systems (NeurIPS)_, 2019.
* [71] M. Tancik, P. Srinivasan, B. Mildenhall, S. Fridovich-Keil, N. Raghavan, U. Singhal, R. Ramamoorthi, J. Barron, and R. Ng. Fourier features let networks learn high frequency functions in low dimensional domains. In _Proceedings of the 34th Annual Conference on Neural Information Processing Systems (NeurIPS)_, 2020.
* [72] A. Tong, N. Malkin, G. Huguet, Y. Zhang, J. Rector-Brooks, K. Fatras, G. Wolf, and Y. Bengio. Improving and generalizing flow-based generative models with minibatch optimal transport. _Transactions on Machine Learning Research (TMLR)_, 2024.

* [73] B. Tzen and M. Raginsky. Theoretical guarantees for sampling and inference in generative models with latent diffusions. In _Proceedings of the 32nd Annual Conference on Learning Theory (COLT)_, 2019.
* [74] F. Vargas and N. Nusken. Transport, variational inference and diffusions: with applications to annealed flows and Schrodinger bridges. _Proceedings of the 40th International Conference on Machine Learning (ICML): Workshop on New Frontiers in Learning, Control, and Dynamical Systems_, 2023.
* [75] F. Vargas, W. Grathwohl, and A. Doucet. Denoising diffusion samplers. In _Proceedings of the 11th International Conference on Learning Representations (ICLR)_, 2023.
* [76] F. Vargas, A. Ovsianas, D. Fernandes, M. Girolami, N. D. Lawrence, and N. Nusken. Bayesian learning via neural Schrodinger-Follmer flows. _Statistics and Computing_, 33(1):3, 2023. doi: 10.1007/s11222-022-10172-5.
* [77] F. Vargas, T. Reu, and A. Kerekes. Expressiveness remarks for denoising diffusion models and samplers. In _Proceedings of the 5th Symposium on Advances in Approximate Bayesian Inference (AABI)_, 2023.
* [78] F. Vargas, S. Padhy, D. Blessing, and N. Nusken. Transport meets variational inference: controlled Monte Carlo diffusions. In _Proceedings of the 12th International Conference on Learning Representations (ICLR)_, 2024.
* [79] M. J. Wainwright, M. I. Jordan, et al. Graphical models, exponential families, and variational inference. _Foundations and Trends(r) in Machine Learning_, 1(1-2):1-305, 2008. doi: 10.1561/220000001.
* [80] K. W. K. Wong, M. Gabrie, and D. Foreman-Mackey. flowMC: Normalizing flow enhanced sampling package for probabilistic inference in JAX. _Journal of Open Source Software_, 8(83):5021, 2023.
* [81] H. Wu, J. Kohler, and F. Noe. Stochastic normalizing flows. _Advances in Neural Information Processing Systems_, 33:5933-5944, 2020.
* [82] B. J. Zhang, Y. M. Marzouk, and K. Spiliopoulos. Transport map unadjusted Langevin algorithms. _arXiv preprint arXiv:2302.07227_, 2023.
* [83] D. Zhang, R. T. Q. Chen, C.-H. Liu, A. Courville, and Y. Bengio. Diffusion generative flow samplers: Improving learning signals through partial trajectory optimization. In _Proceedings of the 12th International Conference on Learning Representations (ICLR)_, 2024.
* [84] L. Zhang, D. M. Blei, and C. A. Naesseth. Transport score climbing: variational inference using forward kl and adaptive neural transport. _Transactions on Machine Learning Research (TMLR)_, 2023.
* [85] Q. Zhang and Y. Chen. Path integral sampler: a stochastic control approach for sampling. In _Proceedings of the 10th International Conference on Learning Representations (ICLR)_, 2022.

Flow-Informed Markov Chain Monte Carlo Methods

```
1:Input: initial \(x\), target density \(\pi\), vector field \(v_{t}^{\theta}\), reference density \(p_{0}\), flow parameters \(\theta\).
2:Output:\(x^{\prime}\)
3:\(\sigma_{opt}\gets 2.38/\sqrt{d}\)
4:\(\phi_{1}(x)=x_{t=1}\gets x\)
5:\(\begin{bmatrix}x_{0}\\ \Delta\log p(x_{0})\end{bmatrix}\leftarrow\begin{bmatrix}x\\ 0\end{bmatrix}+\int_{1}^{0}\begin{bmatrix}v_{t}^{\theta}(\phi_{t}(x))\\ -\nabla\cdot v_{t}^{\theta}(\phi_{t}(x))\end{bmatrix}\mathrm{d}t\)
6:\(y_{0}\sim\mathcal{N}(\cdot|x_{0},\sigma_{opt}^{2})\)
7:\(\begin{bmatrix}y_{1}\\ \Delta\log p(y_{1})\end{bmatrix}\leftarrow\begin{bmatrix}y_{0}\\ 0\end{bmatrix}+\int_{0}^{1}\begin{bmatrix}v_{t}^{\theta}(\phi_{t}(y))\\ -\nabla\cdot v_{t}^{\theta}(\phi_{t}(y))\end{bmatrix}\mathrm{d}t\)
8:\(\alpha\leftarrow\min\left\{1,\frac{\pi(y_{1})\exp(-\Delta\log p(y_{1}))}{\pi(x _{1})\exp(\Delta\log p(x_{0}))}\right\}\)
9: With probability \(\alpha\) make \(x^{\prime}\gets y_{1}\) else \(x^{\prime}\gets x\)
```

**Algorithm 2** Flow-informed Random Walk Metropolis Hastings

```
1:Input: initial \(x\), target density \(\pi\), vector field \(v_{t}^{\theta}\), reference density \(p_{0}\), flow parameters \(\theta\).
2:Output:\(x^{\prime}\)
3:\(\phi_{1}(u)=u_{t=1}\gets x\)
4:\(\begin{bmatrix}u_{0}\\ \Delta\log p(u_{0})\end{bmatrix}\leftarrow\begin{bmatrix}u_{1}\\ 0\end{bmatrix}+\int_{1}^{0}\begin{bmatrix}v_{t}^{\theta}(\phi_{t}(u))\\ -\nabla\cdot v_{t}^{\theta}(\phi_{t}(u))\end{bmatrix}\mathrm{d}t\)
5:\(w_{0}\leftarrow\frac{\pi(u_{1})}{p_{0}(u_{0})\exp(-\Delta\log p(u_{0}))}\)
6:\(x^{(0)}\gets x\)
7:for\(k=1:K\)do
8:\(\phi_{0}(x)=x_{t=0}\sim q_{0}\)
9:\(\begin{bmatrix}x_{1}\\ \log p(x_{1})\end{bmatrix}\leftarrow\begin{bmatrix}x_{0}\\ \log p_{0}(x_{0})\end{bmatrix}+\int_{0}^{1}\begin{bmatrix}v_{t}^{\theta}(\phi_ {t}(x))\\ -\nabla\cdot v_{t}^{\theta}(\phi_{t}(x))\end{bmatrix}\mathrm{d}t\)
10:\(w_{k}\leftarrow\frac{\pi(x_{1})}{\exp(\log p(x_{1}))}\)
11:\(x^{(k)}\gets x_{1}\)
12:endfor
13: Choose \(k^{\prime}\) with probability \(P(k^{\prime}=k)\propto w_{k}\), then make \(x^{\prime}\gets x^{(k^{\prime})}\)
```

**Algorithm 3** Flow-informed Independent Metropolis Hastings
Proof of Proposition 3.1

Our proof follows closely the proof of [54, Proposition 1]. Let \(\theta^{*}\) be a minimizer of the CFM objective in (4), which is given by

\[\mathcal{J}(\theta;\pi)=\mathbb{E}_{x_{1}\sim\pi}\mathbb{E}_{t\sim\mathcal{U}(0,1)}\mathbb{E}_{x\sim p_{t}(\cdot|x_{1})}\left[||v_{t}^{\theta}(x)-v_{t}(x|x_{ 1})||^{2}\right]:=\mathbb{E}_{x_{1}\sim\pi}\left[j(\theta,x_{1})\right] \tag{20}\]

where we have defined \(j(\theta,x_{1})=\mathbb{E}_{t\sim\mathcal{U}(0,1)}\mathbb{E}_{x\sim p_{t}( \cdot|x_{1})}\left[||v_{t}^{\theta}(x)-v_{t}(x|x_{1})||^{2}\right]\). Now, consider the ordinary differential equation (ODE) given by

\[\frac{\mathrm{d}}{\mathrm{d}t}\theta(t)=\nabla\mathcal{J}_{\theta}(\theta(t); \pi),\quad\theta(0)=\theta_{0},\quad t\geq 0. \tag{21}\]

We say that \(\hat{\theta}\) is stability point of this ODE if, given the initial condition \(\theta(0)=\hat{\theta}\), the ODE admits the unique solution \(\theta(t)=\hat{\theta}\) for all \(t\geq 0\). Naturally, the minimizer \(\theta^{*}\) is a stability point of this ODE, since \(\nabla_{\theta}\mathcal{J}(\theta;\pi)|_{\theta=\theta^{*}}=0\). Meanwhile, we call \(\Theta\) the domain of attraction of \(\theta^{*}\) if, given the initial condition \(\theta(0)\in\Theta\), the solution \(\theta(t)\in\Theta\) for all \(t\geq 0\), and \(\theta(t)\) converges to \(\theta^{*}\) as \(t\to\infty\).

Let \(x_{k}\in\mathbb{R}^{d_{x}}\), and \(\mathcal{X}\subseteq\mathbb{R}^{d_{x}}\) be an open subset of \(\mathbb{R}^{d_{x}}\). Let \(\Theta\subseteq\mathbb{R}^{d_{\theta}}\) be an open set in \(\mathbb{R}^{d_{\theta}}\), and \(\Theta_{c}\subseteq\Theta\) be a compact subset of \(\Theta\). Consider the Markov transition kernel \(M:=P\circ Q^{k}\) given by a cycle of \(k_{Q}\) repeated transitions of a MALA transition kernel and a flow-informed RWMH transition kernel, viz

\[M_{\pi,\theta}(x,\mathrm{d}y)=\int\cdots\int Q(x,\mathrm{d}x_{1};\theta)Q(x_{ 1},\mathrm{d}x_{2})\ldots Q(x_{k_{Q}-1},\mathrm{d}x_{k_{Q}};\theta)P(x_{k_{Q} },\mathrm{d}y;\pi,\theta). \tag{22}\]

This transition kernel is \(\pi\)-invariant since both \(P\) and \(Q\) are \(\pi\)-invariant. In addition, let \(M^{k}_{\pi,\theta}(x,\mathrm{d}y)\) be the repeated application of this Markov transition kernel, namely,

\[M^{k}_{\pi,\theta}(x,\mathrm{d}y)=\int\cdots\int M_{\pi,\theta}(x,\mathrm{d}x_ {1})M_{\pi,\theta}(x_{1},\mathrm{d}x_{2})\cdots M_{\pi,\theta}(x_{k-2}, \mathrm{d}x_{k-1})M_{\pi,\theta}(x_{k-1},\mathrm{d}y). \tag{23}\]

Following [30, 54], we impose the following assumptions, for some sufficiently large positive real number \(q>1\).

**Assumption B.1** (Robbins-Monro Condition).: The step size sequence \((\varepsilon_{k})_{k=1}^{\infty}\) satisfies the following requirements:

\[\sum_{k=1}^{\infty}\varepsilon_{k}=\infty,\quad\sum_{k=1}^{\infty}\varepsilon _{k}^{2}<\infty. \tag{24}\]

**Assumption B.2** (Integrability).: There exists a constant \(C_{1}>0\) such that for, any \(\theta\in\Theta\), \(x\in\mathcal{X}\) and \(k\geq 1\),

\[\int(1+|y|^{q})M^{k}_{\pi,\theta}(x,\mathrm{d}y)\leq C_{1}(1+|x|^{q}). \tag{25}\]

**Assumption B.3** (Convergence of the Markov Chain).: For each \(\theta\in\Theta\), it holds that

\[\lim_{k\to\infty}\sup_{x\in\mathcal{X}}\frac{1}{1+|x|^{q}}\int(1+|y|^{q})|M^{k }_{\pi,\theta}(x,\mathrm{d}y)-\pi(\mathrm{d}y)|=0. \tag{26}\]

**Assumption B.4** (Continuity in \(\theta\)).: There exists a constant \(C_{2}\) such that for all \(\theta,\theta^{\prime}\in\Theta_{c}\),

\[\left|\int(1+|y|^{q})(M^{k}_{\pi,\theta}(x,\mathrm{d}y)-M^{k}_{\pi,\theta^{ \prime}}(x,\mathrm{d}y))\right|\leq C_{2}|\theta-\theta^{\prime}|(1+|x|^{q}). \tag{27}\]

**Assumption B.5** (Continuity in \(x\)).: There exists a constant \(C_{3}\) such that for all \(x_{1},x_{2}\in\mathcal{X}\),

\[\sup_{\theta\in\Theta}\left|\int(1+|y|^{q+1})(M^{k}_{\pi,\theta}(x_{1}, \mathrm{d}y)-M^{k}_{\pi,\theta}(x_{2},\mathrm{d}y))\right|\leq C_{3}|x_{1}-x_ {2}|(1+|x_{1}|^{q}+|x_{2}|^{q}). \tag{28}\]

**Assumption B.6** (Conditions on the Objective Function).: For any compact subset \(\Theta_{c}\subset\Theta\), there exist positive constants \(p,K_{1},K_{2},K_{3}\) and \(v>1/2\) such that for all \(\theta,\theta^{\prime}\in\Theta_{c}\) and \(x,x_{1},x_{2}\in\mathcal{X}\),

\[|\nabla_{\theta}j(\theta,x_{1})| \leq K_{1}(1+|x_{1}|^{p+1}), \tag{29}\] \[|\nabla_{\theta}j(\theta,x_{1})-\nabla_{\theta}j(\theta,x_{1}^{ \prime}) \leq K_{2}|x_{1}-x_{1}^{\prime}|(1+|x_{1}|^{p}+|x_{2}|^{p}),\] (30) \[|\nabla_{\theta}j(\theta,x_{1})-\nabla_{\theta}j(\theta^{\prime}, x_{1}) \leq K_{3}|\theta-\theta^{\prime}|^{v}(1+|x_{1}|^{p+1}). \tag{31}\]

With the above assumptions, the result follows from Theorem 1 of [30] by setting \(x\to x_{1}\), \(\Pi_{\theta}\to M_{\pi,\theta},H(\theta,x)\to\nabla_{\theta}j(\theta,x_{1})\).

Additional Experimental Details

Code for the numerical experiments is written in Python with array computations handled by JAX [11]. The implementation of relevant methods for comparison is sourced from open source repositories: DDS using franciscovargas/denoising_diffusion_samplers, NF-MCMC using kazewong/flowMC [80], and FAB using lollcat/fab-jax [52]. All experiments are run on an NVIDIA V100 GPU with 32GB of memory. In the following subsections, we will give more details on the modelling and hyperparameter choices for each experiment, along with additional results.

### Diagnostics

Let \(\pi\) and \(\nu\) be two probability measures. Let \(\mathcal{F}\) denote the unit ball in a reproducing kernel Hilbert space (RKHS) \(\mathcal{H}\), associated with the positive definite kernel \(k:\mathbb{R}^{d}\times\mathbb{R}^{d}\rightarrow\mathbb{R}\). Then the maximum mean discrepancy (MMD) between \(\pi\) and \(\nu\) is defined as [29, Section 2.2]

\[\text{MMD}^{2}_{k}(\pi,\nu)=\|m_{\pi}-m_{\nu}\|_{\mathcal{F}}^{2}, \tag{32}\]

where \(m_{\pi}\) is the mean embedding of \(\pi\), defined via \(\mathbb{E}_{\pi}[f]=\langle f,m_{\pi}\rangle_{\mathcal{H}}\) for all \(f\in\mathcal{H}\). Using standard properties of the RKHS, the squared MMD can be written as [29, Lemma 6]

\[\text{MMD}^{2}_{k}(\pi,\nu)=\mathbb{E}_{x,x^{\prime}\sim\pi}\left[k(x,x^{ \prime})\right]-2\mathbb{E}_{x\sim\pi,y\sim\nu}\left[k(x,y)\right]+\mathbb{E}_ {y\sim\nu,y^{\prime}\sim\nu}\left[k(y,y^{\prime})\right]. \tag{33}\]

Thus, given samples \((x_{i})_{i=1}^{m}\sim\pi\) and \((y_{i})_{i=1}^{m}\sim\nu\), an unbiased estimate of the squared MMD can be computed as

\[\widehat{\text{MMD}}^{2}_{k}(\pi,\nu) =\frac{1}{m(m-1)}\sum_{i=1}^{m}\sum_{i\neq j}^{m}k(x_{i},x_{j})- \frac{2}{m^{2}}\sum_{i=1}^{m}\sum_{j=1}^{m}k(x_{i},y_{j})\] \[+\frac{1}{m(m-1)}\sum_{i=1}^{m}\sum_{j\neq i}^{m}k(y_{i},y_{j}). \tag{34}\]

For a kernel \(k\), the kernel Stein discrepancy (KSD) between \(\pi\) and \(\nu\) is defined as the MMD between \(\pi\) and \(\nu\), using the Stein kernel \(k_{\pi}\) associated with \(k\), which is defined as

\[k_{\pi}(x,x^{\prime}) =\nabla_{x}\cdot\nabla_{x^{\prime}}k(x,x^{\prime})+\nabla_{x}k(x, x^{\prime})\cdot\nabla_{x^{\prime}}\log\pi(x^{\prime})\] \[+\nabla_{x^{\prime}}k(x,x^{\prime})\cdot\nabla_{x}\log\pi(x)+k(x, x^{\prime})\nabla_{x}\log\pi(x)\cdot\nabla_{x^{\prime}}\log\pi(x), \tag{35}\]

and satisfies the Stein identity \(\mathbb{E}_{\pi}\left[k_{\pi}(x,\cdot)\right]=0\). We thus have that

\[\text{KSD}^{2}_{k}(\pi,\nu) =\text{MMD}^{2}_{k_{\pi}}(\pi,\nu) \tag{36}\] \[=\mathbb{E}_{x,x^{\prime}\sim\pi}\left[k_{\pi}(x,x^{\prime}) \right]-2\mathbb{E}_{x\sim\pi,y\sim\nu}\left[k_{\pi}(x,y)\right]+\mathbb{E}_ {y\sim\nu,y^{\prime}\sim\nu}\left[k_{\pi}(y,y^{\prime})\right]\] (37) \[=\mathbb{E}_{y\sim\nu,y^{\prime}\sim\nu}\left[k_{\pi}(y,y^{ \prime})\right]. \tag{38}\]

We can obtain estimates of the KSD by using U-statistics or V-statistics. In particular, an unbiased estimate of \(\text{KSD}^{2}_{k}(\pi,\nu)\) is given by the U-statistic [42]

\[\widehat{\text{KSD}}^{2}_{k,U}(\pi,\nu)=\frac{1}{n(n-1)}\sum_{i=1}^{n}\sum_{i \neq j}^{n}k_{\pi}(y_{i},y_{i}^{\prime}). \tag{39}\]

Alternatively, we can estimate \(\text{KSD}^{2}_{k}(\pi,\nu)\) using a biased (but non-negative) V-statistic of the form [46, Section 4]

\[\widehat{\text{KSD}}^{2}_{k,V}(\pi,\nu)=\frac{1}{n^{2}}\sum_{i=1}^{n}\sum_{j= 1}^{n}k_{\pi}(y_{i},y_{i}^{\prime}). \tag{40}\]

In all of our numerical experiments, we calculate the U- and V- statistics using the inverse multi-quadratic kernel \(k(x,x^{\prime})=(1+(x-x^{\prime})^{T}(x-x^{\prime}))^{\beta}\) due to its favourable convergence properties [26, Theorem 8], setting \(\beta=-\frac{1}{2}\).

### 4-mode Gaussian mixture

For this experiment, all methods use \(N=128\) parallel chains for training and \(128\) hidden dimensions for all neural networks. Methods with a MALA kernel use a step size of \(0.2\), and methods with splines use 4 coupling layers with 8 bins and range limited to \([-16,16]\).

In Table 3, we present results for \(K=10^{3}\) iterations. Since MFM is much more efficient than other methods, we also report results for a great number of total iterations. Table 4 contains results for \(K=5\cdot 10^{3}\) iterations for MFM and AT-SMC. In the main text, we present results for \(K=5\cdot 10^{3}\) learning iterations for MFM and AT-SMC, and \(K=10^{3}\) iterations for the other algorithms, since this renders the total computational cost of all algorithms somewhat comparable.

For both choices of \(K\), we also present results using Hutchinson's trace estimator (HTE) [27; 36] to calculate the MH acceptance probability in the flow-informed Markov transition kernel. As expected, its effect on sample quality becomes more apparent as \(k_{Q}\) increases. However, its effect on computation time is less significant than in larger dimensional examples.

### 16-mode Gaussian Mixture

Like the 4-mode example, all methods use \(N=128\) parallel chains for training and \(128\) hidden dimensions for all neural networks. Methods with a MALA kernel use a step size of \(0.2\), and methods with splines use 4 coupling layers with 8 bins and range limited to \([-16,16]\). In Table 5 we present results for \(K=10^{3}\) iterations. In Table 6, we provide results for MFM and AT-SMC for \(K=5\times 10^{3}\) learning iterations. In the main text, we present results for \(K=5\cdot 10^{3}\) learning iterations for MFM and AT-SMC and \(K=10^{3}\) iterations for all other algorithms, which yields a more comparable total computation time.

\begin{table}
\begin{tabular}{l|r r r r r} \hline \(K=5\cdot 10^{3}\) & \(\mathbb{E}_{[\phi_{1}]\neq\pi\rho_{0}}\log\pi\) & \multicolumn{1}{c}{KSD U-stat.} & \multicolumn{1}{c}{KSD V-stat.} & \multicolumn{1}{c}{MMD} & \multicolumn{1}{c}{seconds} \\ \hline FM w/\(\pi\) samples & \(-4.22\pm 0.04\) & \(1.50\)e-\(3\)\(\pm\)\(6.38\)e-4 & 1.81e-\(3\)\(\pm\)\(6.33\)e-4 & 3.69e-\(\pm\)\(4.18\)e-4e & \(22.3\pm 0.64\) \\ \hline MFM \(k_{Q}=K\) & \(-4.47\pm 0.05\) & \(3.15\)e-\(3\)\(\pm\)\(2.10\)e-3 & 3.50e-\(3.21\)e-3 & 2.37e-\(3\)\(\pm\)\(2.29\)e-3 & \(27.9\pm 1.27\) \\ MFM \(k_{Q}=10^{2}\) & \(-4.45\pm 0.04\) & \(3.61\)e-\(3.20\)e-3 & 3.96e-\(3.21\)e-3 & 1.05e-\(3.89\)e-4 & \(39.2\pm 1.74\) \\ \(-w\)/ HTE & \(-4.48\pm 0.09\) & 3.50e-\(3.22\)e-3 & 3.86e-\(3.22\)e-3 & 1.88e-\(3.19\)e-3 & \(41.2\pm 1.65\) \\ MFM \(k_{Q}=10\) & \(-4.44\pm 0.07\) & 3.15e-\(3\)\(\pm\)\(2.28\)e-3 & 3.49e-\(3.22\)e-3 & 8.13e-\(4\)\(\pm\)\(4.14\)e-4 & \(117.\pm 5.65\) \\ \(-w\)/ HTE & \(-4.46\pm 0.06\) & 4.80e-\(3\)\(\pm\)\(3.17\)e-3 & 5.15e-\(3\)\(\pm\)\(3.17\)e-3 & 1.37e-\(3\)\(\pm\)\(9.65\)e-4 & \(147.\pm 9.44\) \\ AT-SMC & \(-4.48\pm 0.04\) & 4.07e-\(3\)\(\pm\)\(1.24\)e-3 & 4.42e-\(3\)\(\pm\)\(1.24\)e-3 & 3.95e-\(2\)\(\pm\)\(2.90\)e-2 & \(2.18\pm 0.26\) \\ \hline \end{tabular}
\end{table}
Table 4: Diagnostics for the 4-mode Gaussian mixture with \(K=5\cdot 10^{3}\). \(\mathbb{E}_{[\phi_{1}]\neq\rho_{0}}\log\pi\) is the Monte Carlo approximation of the log-target density using the learned flow to generate samples; KSD U-stat and V-stat are the Kernel Stein Discrepancy U- and V-statistics between the target and samples generated from the learned flow; MMD is the Maximum Mean Discrepancy between real samples from the target and samples generated from the learned flow. Results are averaged and empirical 95% confidence intervals over 10 independent runs.

\begin{table}
\begin{tabular}{l|r r r r r} \hline \(K=10^{3}\) & \(\mathbb{E}_{[\phi_{1}]\neq\pi\rho_{0}}\log\pi\) & \multicolumn{1}{c}{KSD U-stat.} & \multicolumn{1}{c}{KSD V-stat.} & \multicolumn{1}{c}{MMD} & \multicolumn{1}{c}{seconds} \\ \hline FM w/\(\pi\) samples & \(-4.20\pm 0.08\) & \(6.85\)e-\(3\)\(\pm\)\(3.75\)e-3 & 7.16e-\(3\)\(\pm\)\(3.75\)e-3 & 1.90e-\(3\)\(\pm\)\(1.16\)e-3 & \(6.46\pm 0.32\) \\ \hline MFM \(k_{Q}=K\) & \(-4.55\pm 0.16\) & \(7.62\)e-\(3\)\(\pm\)\(7.46\)e-3 & 7.98e-\(3\)\(\pm\)\(7.45\)e-3 & 3.00e-\(3\)\(\pm\)\(2.20\)e-3 & \(10.4\pm 0.66\) \\ MFM \(k_{Q}=10^{2}\) & \(-4.50\pm 0.14\) & \(5.36\)e-\(3\)\(\pm\)\(3.18\)e-3 & 5.71e-\(3\)\(\pm\)\(3.19\)e-3 & 2.03e-\(3\)\(\pm\)\(2.12\)e-3 & \(12.1\pm 0.65\) \\ \(-w\)/ HTE & \(-4.52\pm 0.15\) & \(4.77\)e-\(3\)\(\pm\)\(1.93\)e-3 & 5.12e-\(3\)\(\pm\)\(3.19\)e-3 & 2.27e-\(3\)\(\pm\)\(1.30\)e-3 & \(13.9\pm 0.33\) \\ MFM \(k_{Q}=10\) & \(-4.49\pm 0.08\) & \(7.01\)e-\(3\)\(\pm\)\(3.49\)e-3 & 7.36e-\(3\)\(\pm\)\(3.49\)e-3 & 1.62e-\(3\)\(\pm\)\(7.61\)e-4 & \(24.8\pm 1.38\) \\ \(-w\)/ HTE & \(-4.53\pm 0.12\) & \(1.10\)e-\(\pm\)\(6.80\)e-3 & 1.14e-\(2\)\(\pm\)\(6.81\)e-3 & 2.64e-\(3\)\(\pm\)\(1.03\)e-3 & \(30.0\pm 1.70\) \\ DDS & \(-4.22\pm 0.03\) & \(9.89\)e-\(4\)\(\pm\)\(1.05\)e-3 & 1.30e-\(3\)\(\pm\)\(1.05\)e-3 & 1.76e-\(4\)\(\pm\)\(2.32\)e-4 & \(114.\pm 0.68\) \\ NF-MCMC & \(-4.37\pm 0.21\) & \(1.80\)e-\(2.14\)e-\(1.42\)e-3 & 1.86e-\(2\)\(\pm\)\(1.44\)e-4 & 5.85e-\(3\)\(\pm\)\(3.91\)e-3 & \(72.0\pm 1.17\) \\ FAB & \(-4.67\pm 0.16\) & \(2.31\)e-\(3\)\(\pm\)\(1.19\)e-3 & 2.69e-\(3\)\(\pm\)\(1.21\)e-3 & 2.69e-\(4\)\(\pm\)\(2.06\)e-4 & \(101.\pm 3.24\) \\ AT-SMC & \(-4.47\pm 0.04\) & \(3.95\)e-\(3\)\(\pm\)\(2.06\)e-3 & 4.30e-\(3\)\(\pm\)\(2.06\)e-3 & 2.98e-\(2\)\(\pm\)\(4.08\)e-2 & \(1.38\pm 0.08\) \\ \hline \end{tabular}
\end{table}
Table 3: Diagnostics for the 4-mode Gaussian mixture with \(K=10^{3}\). \(\mathbb{E}_{[\phi_{1}]\neq\rho_{0}}\log\pi\) is the Monte Carlo approximation of the log-target density using the learned flow to generate samples; KSD U-stat and V-stat are the Kernel Stein Discrepancy U- and V-statistics between the target and samples generated from the learned flow; MMD is the Maximum Mean Discrepancy between real samples from the target and samples generated from the learned flow. Results are averaged and empirical 95% confidence intervals over 10 independent runs.

### Many Well

We also present a synthetic problem approximating the 32-dimensional Many Well distribution given by the product of 16 copies of the 2-dimensional Double Well distribution (e.g., 52; 58; 81),

\[\log p(x_{1},x_{2})=-x_{1}^{4}+6x_{1}^{2}+\frac{1}{2}x_{1}-\frac{1}{2}x_{2}^{2}+ \mathrm{constant}, \tag{41}\]

where each copy of the Double Well is evaluated on a different pair of the 32 inputs. The 32-dimensional Many Well has \(2^{16}=65536\) modes, one for each possible choice of mode in each of the 16 copies of the double well. We can obtain exact samples from the Many Well by sampling each independent copy of the Double Well.

Like previous synthetic examples, all methods use \(N=128\) parallel chains for training and \(128\) hidden dimensions for all neural networks. Methods with a MALA kernel use a step size of \(0.1\), and methods with splines use 4 coupling layers with 8 bins and a range limited to \([-16,16]\). Table 7 presents results for \(K=10^{3}\) iterations. In Table 8, we provide results for MFM and AT-SMC for \(K=5\times 10^{3}\) learning iterations. In the main text, we present results for \(K=5\cdot 10^{3}\) learning iterations for MFM and AT-SMC and \(K=10^{3}\) iterations for all other algorithms, which yields a more comparable total computation time.

### Field system

The stochastic Allen-Cahn equation is defined in terms of a random field \(\phi:[0,1]\rightarrow\mathbb{R}\) satisfying the following stochastic partial differential equation (e.g., 24, Section V):

\[\frac{\partial\phi}{\partial t}=a\frac{\partial^{2}\phi}{\partial s^{2}}+a^{-1 }(\phi-\phi^{3})+\sqrt{2\beta^{-1}}\eta(t,s), \tag{42}\]

\begin{table}
\begin{tabular}{l|r r r r r} \hline \(K=5\cdot 10^{3}\) & \(\mathbb{E}_{[0_{1}]\neq p_{0}}\log\pi\) & KSD U-stat. & KSD V-stat. & MMD & seconds \\ \hline FM w/ \(\pi\) samples & \(-5.74\pm 0.11\) & 2.91e-3\(\pm\)1.23e-3 & 3.26e-3\(\pm\)1.24e-3 & 1.35e-3\(\pm\)6.66e-4 & \(22.4\pm 1.01\) \\ \hline MFM \(k_{Q}=K\) & \(-6.09\pm 0.10\) & 3.00e-3\(\pm\)7.87e-4 & 3.34e-3\(\pm\)7.95e-4 & 1.88e-2\(\pm\)3.67e-3 & \(28.2\pm 2.84\) \\ MFM \(k_{Q}=10^{2}\) & \(-5.90\pm 0.08\) & 5.37e-3\(\pm\)2.00e-3 & 5.74e-3\(\pm\)2.01e-3 & 2.98e-3\(\pm\)1.37e-3 & \(34.8\pm 1.95\) \\ \(-\) w/ HTE & \(-5.88\pm 0.12\) & 5.43e-3\(\pm\)3.22e-3 & 5.80e-3\(\pm\)2.33e-3 & 3.86e-3\(\pm\)1.23e-3 & \(38.7\pm 2.53\) \\ MFM \(k_{Q}=10\) & \(-5.98\pm 0.13\) & 5.48e-3\(\pm\)2.07e-3 & 5.86e-3\(\pm\)2.09e-3 & 2.87e-3\(\pm\)6.97e-4 & \(89.6\pm 5.19\) \\ \(-\) w/ HTE & \(-5.92\pm 0.09\) & 9.18e-3\(\pm\)4.48e-3 & 9.57e-3\(\pm\)4.50e-3 & 8.58e-3\(\pm\)1.00e-3 & \(110.\pm 6.77\) \\ AT-SMC & \(-5.84\pm 0.05\) & 2.09e-3\(\pm\)8.53e-4 & 2.40e-3\(\pm\)8.56e-4 & 1.73e-2\(\pm\)5.30e-3 & \(2.19\pm 0.21\) \\ \hline \end{tabular}
\end{table}
Table 6: Diagnostics for the 16-mode Gaussian mixture with \(K=5\cdot 10^{3}\). \(\mathbb{E}_{[\phi_{1}]\neq p_{0}}\log\pi\) is the Monte Carlo approximation of the log-target density using the learned flow to generate samples; KSD U-stat and V-stat are the Kernel Stein Discrepancy U- and V-statistics between the target and samples generated from the learned flow; MMD is the Maximum Mean Discrepancy between real samples from the target and samples generated from the learned flow. Results are averaged and empirical 95% confidence intervals over 10 independent runs.

\begin{table}
\begin{tabular}{l|r r r r r} \hline \(K=10^{3}\) & \(\mathbb{E}_{[0_{1}]\neq p_{0}}\log\pi\) & KSD U-stat. & KSD V-stat. & MMD & seconds \\ \hline FM w/ \(\pi\) samples & \(-7.09\pm 0.31\) & 2.94e-21.32e-2 & 2.99e-21.32e-2 & 8.89e-3\(\pm\)1.79e-3 & \(6.67\pm 0.19\) \\ \hline MFM \(k_{Q}=K\) & \(-6.95\pm 0.47\) & 1.67e-21.14e-2 & 1.71e-21.15e-2 & 3.71e-24.81e-3 & \(10.4\pm 0.64\) \\ MFM \(k_{Q}=10^{2}\) & \(-7.21\pm 0.73\) & 1.80e-29.31e-3 & 1.85e-29.43e-3 & 1.81e-2\(\pm\)8.97e-3 & \(11.4\pm 0.74\) \\ \(-\) w/ HTE & \(-7.34\pm 0.81\) & 2.10e-28.65e-3 & 2.15e-28.75e-3 & 1.74e-28.12e-3 & \(13.0\pm 0.83\) \\ MFM \(k_{Q}=10\) & \(-7.21\pm 0.58\) & 2.95e-21.03e-2 & 3.01e-21.04e-2 & 1.06e-22.76e-3 & \(20.3\pm 1.17\) \\ \(-\) w/ HTE & \(-7.18\pm 0.85\) & 3.17e-21.97e-3 & 2.32e-21.99e-3 & 1.30e-23.33e-3 & \(22.5\pm 1.81\) \\ DDS & \(-5.86\pm 0.20\) & 6.65e-3\(\pm\)6.69e-3 & 6.94e-3+6.69e-3 & 1.02e-11.40e-2 & \(11.5\pm 0.64\) \\ NF-MCMC & \(-5.74\pm 0.35\) & 1.23e-21.71e-2 & 1.26e-21.72e-2 & 8.05e-3\(\pm\)1.42e-2 & \(67.0\pm 12.3\) \\ FAB & \(-5.89\pm 0.28\) & 4.22e-3\(\pm\)3.31e-3 & 4.58e-3\(\pm\)3.34e-3 & 1.51e-3\(\pm\)1.06e-3 & \(102.\pm 4.32\) \\ AT-SMC & \(-5.91\pm 0.07\) & 2.07e-3\(\pm\)1.03e-3 & 2.38e-3\(\pm\)1.04e-3 & 3.72e-2\(\pm\)4.45e-3 & \(1.36\pm 0.20\) \\ \hline \end{tabular}
\end{table}
Table 5: Diagnostics for the 16-mode Gaussian mixture with \(K=10^{3}\). \(\mathbb{E}_{[\phi_{1}]\neq p_{0}}\log\pi\) is the Monte Carlo approximation of the log-target density using the learned flow to generate samples; KSD U-stat and V-stat are the Kernel Stein Discrepancy U- and V-statistics between the target and samples generated from the learned flow; MMD is the Maximum Mean Discrepancy between real samples from the target and samples generated from the learned flow. Results are averaged and empirical 95% confidence intervals over 10 independent runs.

where \(a>0\) is a parameter, \(\beta\) is the inverse temperature, \(s\in[0,1]\) denotes the spatial variable, and \(\eta\) is spatiotemporal white noise. We impose Dirichlet boundary conditions throughout, so that \(\phi(s=0)=\phi(s=1)=0\).

The associated Hamiltonian, reflecting a spatial coupling term penalizing changes in \(\phi\), takes the form:

\[U_{*}[\phi]=\beta\int_{0}^{1}\left[\frac{a}{2}\left(\frac{\partial\phi}{ \partial s}\right)^{2}+\frac{1}{4a}\left(1-\phi^{2}(s)\right)^{2}\right]ds. \tag{43}\]

At low temperatures, this coupling induces alignment of the field in either the positive or negative direction, leading to two global minima, \(\phi_{+}\) and \(\phi_{-}\), with typical values of \(\pm 1\).

For this example, all methods use \(N=1024\) parallel chains for training and \(256\) hidden dimensions for all neural networks. Methods with a MALA kernel use a step size of \(0.0001\), and methods with splines use 8 coupling layers with 8 bins and range limited to \([-5,5]\). Results for \(K=10^{4}\) learning iterations are presented in Table 9. In the main text, we present results for \(k_{Q}=10^{2}\) for MFM.

Interestingly, in high-dimensional problems such as this and the following, the version of the algorithm using Hutchinson's trace estimator [27, 36] to calculate the MH acceptance probability has little apparent effect on the approximation quality. It does, however, have a significant impact on the computation time.

### Log-Gaussian Cox process

The original \(10\times 10\) square meter plot is standardized to the unit square. We discretize the unit square \([0,1]^{2}\) into a \(M=40\times 40\) regular grid. The latent intensity process \(\Lambda=\{\Lambda_{m}\}_{m\in M}\) is specified as \(\Lambda_{m}=\exp(X_{m})\), where \(X=\{X_{m}\}_{m\in M}\) is a Gaussian process with a constant mean \(\mu_{0}\in\mathbb{R}\) and exponential covariance function \(\Sigma_{0}(m,n)=\sigma^{2}\exp\left(-|m-n|/(40\beta)\right)\) for \(m,n\in M\)

\begin{table}
\begin{tabular}{l|r r r r r} \hline \hline \(K=10^{3}\) & \(\mathbb{E}_{[\phi_{1}]\neq 0_{P}}\log\pi\) & KSD U-stat. & KSD V-stat. & MMD & seconds \\ \hline FM w/\(\pi\) samples & \(86.6\pm 1.88\) & \(17.4\pm 6.24\) & \(19.3\pm 6.25\) & \(1.24\)e-\(\pm 8.11\)e-\(8\) & \(6.95\pm 0.31\) \\ \hline MFM \(k_{Q}=K\) & \(101.\pm 0.70\) & \(0.12\pm 0.12\) & \(0.77\pm 0.13\) & \(2.28\)e-\(\pm 8.15\)e-\(8\) & \(11.1\pm 0.67\) \\ MFM \(k_{Q}=10^{2}\) & \(101.\pm 0.70\) & \(0.12\pm 0.11\) & \(0.77\pm 0.13\) & \(2.28\)e-\(\pm 1.57\)e-\(8\) & \(12.0\pm 17.6\) \\ \(-\)w HTE & \(101.\pm 0.70\) & \(0.11\pm 0.12\) & \(0.77\pm 0.13\) & \(2.28\)e-\(\pm 8.15\)e-\(8\) & \(35.6\pm 3.95\) \\ MFM \(k_{Q}=10\) & \(101.\pm 0.77\) & \(0.11\pm 0.11\) & \(0.76\pm 0.12\) & \(2.28\)e-\(\pm 8.15\)e-\(8\) & \(1100.9\pm 90.2\) \\ \(-\)w HTE & \(101.\pm 0.69\) & \(0.11\pm 0.09\) & \(0.76\pm 0.10\) & \(2.27\)e-\(\pm 8.15\)e-\(8\) & \(259.1\pm 7.6\) \\ DDS & \(133.\pm 3.92\) & \(0.13\pm 0.14\) & \(0.61\pm 0.13\) & \(1.49\)e-\(\pm 5.20\)e-\(35\) & \(227.0\pm 0.91\) \\ NF-MCMC & \(39.2\pm 1.61\) & \(1.17\pm 0.65\) & \(2.29\pm 0.66\) & \(4.79\)e-\(7\pm 2.41\)e-\(7\) & \(184.\pm 44.1\) \\ FAB & \(137.\pm 0.33\) & \(4.79\)e-\(3\pm 2.55\)e-\(2\) & \(4.32\)e-\(1\pm 4.14\)e-\(2\) & \(3.87\)e-\(7\pm 2.90\)e-\(37\) & \(304.\pm 3.64\) \\ AT-SMC & \(130.\pm 2.93\) & \(0.02\pm 0.03\) & \(0.57\pm 0.03\) & \(1.75\)e-\(5\pm 1.19\)e-\(5\) & \(1.35\pm 0.36\) \\ \hline \hline \end{tabular}
\end{table}
Table 7: Diagnostics for the many well with \(K=10^{3}\). \(\mathbb{E}_{[\phi_{1}]\neq 0_{P}}\log\pi\) is the Monte Carlo approximation of the log-target density using the learned flow to generate samples; KSD U-stat and V-stat are the Kernel Stein Discrepancy U- and V-statistics between the target and samples generated from the learned flow; MMD is the Maximum Mean Discrepancy between real samples from the target and samples generated from the learned flow. Results are averaged and empirical 95% confidence intervals over 10 independent runs.

\begin{table}
\begin{tabular}{l|r r r r r} \hline \hline \(K=5\cdot 10^{3}\) & \(\mathbb{E}_{[\phi_{1}]\neq 0_{P}}\log\pi\) & KSD U-stat. & KSD V-stat. & MMD & seconds \\ \hline FM w/\(\pi\) samples & \(98.6\pm 5.32\) & \(2.57\pm 4.07\) & \(4.56\pm 4.07\) & \(-1.13\)e-\(9\pm 2.81\)e-\(8\) & \(25.6\pm 0.48\) \\ \hline MFM \(k_{Q}=K\) & \(101.\pm 0.64\) & \(1.02\)e-\(1\)e-\(9.03\)e-\(2\) & \(7.64\)e-\(1\)e-\(9.78\)e-\(2\) & \(2.28\)e-\(8.15\)e-\(8\) & \(29.7\pm 1.03\) \\ MFM \(k_{Q}=10^{2}\) & \(101.\pm 0.63\) & \(1.02\)e-\(1\)e-\(9.05\)e-\(2\) & \(7.64\)e-\(1\)e-\(9.78\)e-\(2\) & \(2.28\)e-\(8.15\)e-\(8\) & \(587.\pm 27.0\) \\ \(-\)w HTE & \(102.\pm 0.78\) & \(1.02\)e-\(1\)e-\(8.32\)e-\(2\) & \(7.62\)e-\(1\)e-\(8.91\)e-\(2\) & \(2.27\)e-\(8.15\)e-\(8\) & \(154.\pm 7.51\) \\ MFM \(k_{Q}=10\) & \(102.\pm 0.81\) & \(9.93\)e-\(2\)+\(7.24\)e-\(2\) & \(7.63\)e-\(1\)e-\(15.2\) & \(2.27\)e-\(8.15\)e-\(8\) & \(1530.\pm 104\) \\ \(-\)w HTE & \(103.\pm 2.20\) & \(3.85\)e-\(1\)e-\(2\).69e-\(1\) & \(1.05\pm 0.27\) & \(2.21\)e-\(8.15\)e-\(8\) & \(1190.\pm 27.6\) \\ AT-SMC & \(130.\pm 3.17\) & \(2.44\)e-\(2\)+\(5.99\)e-\(2\) & \(5.79\)e-\(1\)e-\(6.76\)e-\(2\) & \(1.52\)e-\(5\)e-\(1.00\)e-\(5\) & \(2.59\pm 0.27\) \\ \hline \hline \end{tabular}
\end{table}
Table 8: Diagnostics for the many well with \(K=5\cdot 10^{3}\). \(\mathbb{E}_{[\phi_{1}]\neq 0_{P}}\log\pi\) is the Monte Carlo approximation of the log-target density using the learned flow to generate samples; KSD U-stat and V-stat are the Kernel Stein Discrepancy U- and V-statistics between the target and samples generated from the learned flow; MMD is the Maximum Mean Discrepancy between real samples from the target and samples generated from the learned flow. Results are averaged and empirical 95% confidence intervals over 10 independent runs.

i.e. \(X\sim\mathcal{N}(\mu_{0}1_{d},\Sigma_{0})\) for \(1_{d}=[1,\ldots,1]^{T}\in\mathbb{R}^{d}\) with dimension \(d=1600\). The chosen parameter values are \(\sigma^{2}=1.91\), \(\beta=1/33\), and \(\mu_{0}=\log(126)-\sigma^{2}/2\), corresponding to the values estimated in [53]. The number of points in each grid cell \(Y=\{Y_{m}\}_{m\in M}\in\mathbb{N}^{40\times 40}\) are modelled as conditionally independent and Poisson distributed with means \(a\Lambda_{m}\),

\[\mathcal{L}(Y|X)=\prod_{m\in[1:30]^{2}}\exp(x_{m}y_{m}-a\exp(x_{m})), \tag{44}\]

where \(a=1/40^{2}\) represents the area of each grid cell. For this example, all methods use \(N=128\) parallel chains for training and \(1024\) hidden dimensions for all neural networks. Methods with a MALA kernel use a step size of \(0.01\), and methods with splines use 8 coupling layers with 8 bins and range limited to \([-10,10]\). Results for \(K=10^{4}\) learning iterations are presented in Table 10. In the main text, we present results for \(k_{Q}=10^{3}\) for MFM. We were unable to run NF-MCMC and FAB for \(K=10^{4}\) iterations because of memory issues; instead, we present results for \(K=10^{3}\) iterations only for the models using discrete normalizing flows.

\begin{table}
\begin{tabular}{l|c c c c} \hline \(K=10^{4}\) & \(\mathbb{E}_{[\phi_{1}]_{\#P_{0}}}\log\pi\) & KSD U-stat. & KSD V-stat. & seconds \\ \hline \hline MFM \(k_{Q}=K\) & \(-1960\pm 10.8\) & \(1.13\)e-\(1\pm 5.18\)e-\(2\) & \(28.1\pm 0.246\) & \(117\pm 4.19\) \\ MFM \(k_{Q}=10^{3}\) & \(-1960\pm 10.8\) & \(1.14\)e-\(1\pm 5.13\)e-\(2\) & \(28.1\pm 0.241\) & \(1690\pm 870\) \\ – w/ HTE & \(-1960\pm 12.2\) & \(1.12\)e-\(1\pm 4.93\)e-\(2\) & \(28.1\pm 0.236\) & \(143\pm 14.5\) \\ MFM \(k_{Q}=10^{2}\) & \(-1960\pm 12.6\) & \(1.15\)e-\(1\pm 5.12\)e-\(2\) & \(28.0\pm 0.265\) & \(17300\pm 9970\) \\ – w/ HTE & \(-1960\pm 11.1\) & \(1.15\)e-\(1\pm 5.17\)e-\(2\) & \(28.1\pm 0.239\) & \(394\pm 157\) \\ DDS & \(-1850\pm 8.59\) & \(7.59\)e-\(2\pm 2.24\)e-\(2\) & \(24.7\pm 0.08\) & \(3260\pm 8.41\) \\ NF-MCMC & \(-1410\pm 53.8\) & \(11.8\pm 7.55\) & \(89.0\pm 238\) & \(215\pm 46.4\) \\ FAB & \(-3070\pm 80.7\) & \(1.55\)e-\(1\pm 6.12\)e-\(2\) & \(52.3\pm 2.02\) & \(1040\pm 2.78\) \\ AT-SMC & \(-1910\pm 4.21\) & \(1.39\)e-\(2\pm 1.14\)e-\(2\) & \(25.0\pm 0.12\) & \(6.11\pm 0.44\) \\ \hline \hline \end{tabular}
\end{table}
Table 10: Log Gaussian Cox point process diagnostics for \(K=10^{4}\) where \(\mathbb{E}_{[\phi_{1}]_{\#P_{0}}}\log\pi\) is the Monte Carlo approximation of the log-target density using the learned flow to generate samples; KSD U-stat and V-stat are the Kernelized Stein discrepancy’s U- and V-statistics between the target and samples generated from the learned flow. Results are averaged and empirical 95% confidence intervals over 10 independent runs.

\begin{table}
\begin{tabular}{l|c c c c} \hline \(K=10^{4}\) & \(\mathbb{E}_{[\phi_{1}]_{\#P_{0}}}\log\pi\) & KSD U-stat. & KSD V-stat. & seconds \\ \hline \hline MFM \(k_{Q}=K\) & \(-74.7\pm 5.67\) & \(2.61\pm 2.00\) & \(20.9\pm 2.49\) & \(52.3\pm 1.23\) \\ MFM \(k_{Q}=K/10\) & \(-69.6\pm 6.07\) & \(2.90\pm 2.50\) & \(21.2\pm 3.16\) & \(61.7\pm 4.37\) \\ – w/ HTE & \(-74.2\pm 6.51\) & \(2.67\pm 2.16\) & \(21.0\pm 2.66\) & \(53.6\pm 1.33\) \\ MFM \(k_{Q}=K/100\) & \(-55.4\pm 4.19\) & \(2.84\pm 3.31\) & \(20.9\pm 3.33\) & \(180\pm 42.2\) \\ – w/ HTE & \(-72.1\pm 11.6\) & \(3.84\pm 3.04\) & \(22.6\pm 4.26\) & \(71.5\pm 6.93\) \\ DDS & \(-76.3\pm 17.4\) & \(15.2\pm 35.9\) & \(18.0\pm 36.9\) & \(2400\pm 8.65\) \\ NF-MCMC & \(-26.9\pm 9.62\) & \(548\pm 325\) & \(549\pm 325\) & \(2000\pm 15.6\) \\ FAB & \(-50.4\pm 0.14\) & \(0.14\pm 0.42\) & \(1.78\pm 0.42\) & \(3880\pm 7.19\) \\ AT-SMC & \(-63.5\pm 9.91\) & \(1.61\pm 2.33\) & \(18.4\pm 2.35\) & \(4.13\pm 0.30\) \\ \hline \hline \end{tabular}
\end{table}
Table 9: Diagnostics for the field system with \(K=10^{4}\). \(\mathbb{E}_{[\phi_{1}]_{\#P_{0}}}\log\pi\) is the Monte Carlo approximation of the log-target density using the learned flow to generate samples; KSD U-stat and V-stat are the Kernel Stein Discrepancy U- and V-statistics between the target and samples generated from the learned flow. Results are averaged and empirical 95% confidence intervals over 10 independent runs.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The claims made in the abstract and the introduction provide an accurate reflection of the theoretical, methodological, and experiment contributions in the paper. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The final section includes a discussion of the limitations of this work, including the computational efficiency of the proposed method, situations in which the proposed method may be outperformed by other baselines, and hyperparameters which may strongly influence the performance of the proposed method. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs**Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: Our theoretical result (Proposition 3.1 in Section 3) is accompanied by a full set of assumptions and a complete proof (in Appendix B). Any results upon which the proof relies are properly cited. In addition, all of the theorems, formulas, and proofs in the paper are numbered and cross-referenced. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The paper includes full details of the algorithm used to obtain the experimental results in the paper, including all of the hyper-parameter settings for each of the different numerical experiments. Our code is also made publicly available on GitHub (see Section 5). Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). *4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: Our code is made publicly available on GitHub (see Section 5). Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We provide all of the training and test details, including hyperparameter settings, train-test splits, choice of optimizer, etc., necessary to understand and reproduce our experimental results. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We report error bars for all of our numerical experiments (see Section 5). In the text, we provide full details regarding how these error bars are calculated, as well as the factors which vary between each experimental run.

Guidelines:

* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We include full details of the type of compute workers used in the main text (see Appendix C). We also include details of the running time for each of the main numerical experiments, for both our proposed method and the relevant baselines. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines?](https://neurips.cc/public/EthicsGuidelines?) Answer: [Yes] Justification: The research conducted in the paper conforms with NeurIPS Code of Ethics in every respect, including with regards to _Potential Harms Caused by the Research Process, Societal Impact and Potential Harmful Consequences_, and _Impact Mitigation Measures_. All of the authors have read and reviewed the NeurIPS Code of Ethics to ensure that the research conducted in this paper conforms with the guidelines. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).

10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: This paper contains foundational research on a new method for approximate statistical inference. It is not tied to any particular applications and, as such, these are not directly discussed in the main text. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper does not include any datasets or models associated with a high risk of misuse. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes]Justification: The creators and original owners of assets used in the paper (e.g., code for relevant baselines) are properly credited (see Section 5). We both cite the original papers that produced these assets, and include URLs to the code. Guidelines:

* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release any new assets. Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing experiments or any research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects**Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?

Answer: [NA]

Justification: The paper does not involve crowdsourcing experiments or any research with human subjects.

Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.