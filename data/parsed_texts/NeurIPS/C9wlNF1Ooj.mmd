# Bicriteria Multidimensional Mechanism Design with Side Information

 Maria-Florina Balcan

School of Computer Science

Carnegie Mellon University

ninamf@cs.cmu.edu &Siddharth Prasad

Computer Science Department

Carnegie Mellon University

sprasad2@cs.cmu.edu &Tuomas Sandholm

Computer Science Department

Carnegie Mellon University

Strategy Robot, Inc.

Strategic Machine, Inc.

sandholm@cs.cmu.edu

###### Abstract

We develop a versatile new methodology for multidimensional mechanism design that incorporates side information about agent types to generate high social welfare and high revenue simultaneously. Prominent sources of side information in practice include predictions from a machine-learning model trained on historical agent data, advice from domain experts, and even the mechanism designer's own gut instinct. In this paper we adopt a prior-free perspective that makes no assumptions on the correctness, accuracy, or source of the side information. First, we design a meta-mechanism that integrates input side information with an improvement of the classical VCG mechanism. The welfare, revenue, and incentive properties of our meta-mechanism are characterized by novel constructions we introduce based on the notion of a _weakest competitor_, which is an agent that has the smallest impact on welfare. We show that our meta-mechanism, when carefully instantiated, simultaneously achieves strong welfare and revenue guarantees parameterized by errors in the side information. When the side information is highly informative and accurate, our mechanism achieves welfare and revenue competitive with the total social surplus, and its performance decays continuously and gradually as the quality of the side information decreases. Finally, we apply our meta-mechanism to a setting where each agent's type is determined by a constant number of parameters. Specifically, agent types lie on constant-dimensional subspaces (of the potentially high-dimensional ambient type space) that are known to the mechanism designer. We use our meta-mechanism to obtain the first known welfare and revenue guarantees in this setting.

## 1 Introduction

Mechanism design is a high-impact branch of economics and computer science that studies the implementation of socially desirable outcomes among strategic self-interested agents. Major real-world use cases include combinatorial auctions (_e.g._, strategic sourcing, radio spectrum auctions), matching markets (_e.g._, housing allocation, ridesharing), project fundraisers, and many more. The two most commonly studied objectives in mechanism design are _welfare maximization_ and _revenue maximization_. In many settings, welfare maximization, or _efficiency_, is achieved by the classicVickrey-Clarke-Groves (VCG) mechanism [19; 28; 50]. Revenue maximization is a much more elusive problem that is only understood in very special cases. The seminal work of Myerson [42] characterized the revenue-optimal mechanism for the sale of a single item in the Bayesian setting, but it is not even known how to optimally sell two items. It is known that welfare and revenue are generally at odds and optimizing one can come at the great expense of the other [1; 4; 7; 23; 33].

In this paper we study how _side information_ (or _predictions_) about the agents can help with _bicriteria_ optimization of both welfare and revenue. Side information can come from a variety of sources that are abundantly available in practice such as predictions from a machine-learning model trained on historical agent data, advice from domain experts, or even the mechanism designer's own gut instinct. Machine learning approaches that exploit the proliferation of agent data have in particular witnessed a great deal of success both in theory [8; 10; 38; 41] and in practice [24; 25; 46; 52]. In contrast to the typical Bayesian approach to mechanism design that views side information through the lens of a prior distribution over agents, we adopt a prior-free perspective that makes no assumptions on the correctness, accuracy, or source of the side information. A nascent line of work (part of a larger agenda on learning-augmented algorithms [40]) has begun to examine the challenge of exploiting predictions when agents are self-interested, but only for fairly specific problem settings [3; 13; 14; 15; 26; 53]. We contribute to this area with a general side-information-dependent meta-mechanism for a wide swath of multidimensional mechanism design problems that aim for high social welfare and high revenue.

### Our contributions

Our main contribution is a versatile meta-mechanism that integrates side information about agent types with the bicriteria goal of simultaneously optimizing welfare and revenue.

In Section 2 we formally define the components of multidimensional mechanism design with side information. The abstraction of multidimensional mechanism design is a rich language that allows our theory to apply to many real-world settings including combinatorial auctions, matching markets, project fundraisers, and more--we expand on this list of examples further in Section 2. We also present the weakest-competitor VCG mechanism introduced by Krishna and Perry [34] and prove that it is revenue-optimal among all efficient mechanisms in the prior-free setting (extending their work which was in the Bayesian setting for a fixed known prior).

In Section 3 we present our meta-mechanism for mechanism design with side information. It generalizes the mechanism of Krishna and Perry [34]. We introduce the notion of a weakest-competitor set and a weakest-competitor hull, which are constructions that are crucial to understanding the payments and incentive properties of our meta-mechanism.

In Section 4 we prove that our meta-mechanism--when carefully instantiated--achieves strong welfare and revenue guarantees that are parameterized by errors in the side information. Our mechanism works by independently expanding the input predictions, where the expansion radius for each prediction is drawn randomly from a logarithmic discretization of the diameter of the ambient type space. Our mechanism achieves the efficient welfare \(\mathsf{OPT}\) and revenue _at least_\(\Omega(\mathsf{OPT}/\log H)\) when the side information is highly informative and accurate, where \(H\) is an upper bound on any agent's value for any outcome. Its revenue approaches \(\mathsf{OPT}\) if its initialization parameters are chosen wisely. Its performance decays gradually as the quality of the side information decreases (whereas naive approaches suffer from huge discontinuous drops in performance). _Prior-free efficient welfare \(\mathsf{OPT}\), or total social surplus, is the strongest possible benchmark for both welfare and revenue._ Finally, we extend our methods to a more general, more expressive side information language.

In Section 5 we use our meta-mechanism to derive new results in a setting where each agent's type is determined by a constant number of parameters. Specifically, agent types lie on constant-dimensional subspaces (of the potentially high-dimensional ambient type space) that are known to the mechanism designer. _For example, a real-estate agent might infer a buyers' relative property values based on value per square foot._ When each agent's true type is known to lie in a particular \(k\)-dimensional subspace of the ambient type space, we show how to use our meta-mechanism to guarantee revenue at least \(\Omega(\mathsf{OPT}/k(\log H)^{k})\) while simultaneously guaranteeing welfare at least \(\mathsf{OPT}/\log H\).

Traditionally it is known that welfare and revenue are at odds and maximizing one objective comes at the expense of the other. Our results show that side information can help mitigate this difficulty.

### Related work

_Side information in mechanism design._ Various mechanism design settings have been studied under the assumption that some form of public side information is available. Medina and Vassilvitskii [38] study single-item (unlimited supply) single-bidder posted-price auctions with bid predictions. Devanur et al. [22] study the sample complexity of (single-parameter) auctions when the mechanism designer receives a distinguishing signal for each bidder. More generally, the active field of _algorithms with predictions_ aims to improve the quality of classical algorithms when machine-learning predictions about the solution are available [40]. There have been recent explicit connections of this paradigm to settings with strategic agents [13, 14, 15, 26, 3]. Most related to our work, Xu and Lu [53] study auctions for the sale of a (single copy of a) single item when the mechanism designer receives point predictions on the bidders' values. Unlike our approach, they focus on _deterministic_ modifications of a second-price auction. An important drawback of determinism is that revenue guarantees do not decay continuously as prediction quality degrades. For agents with value capped at \(H\) there is an error threshold after which, in the worst case, only a \(1/H\)-fraction of revenue can be guaranteed (this is not even competitive with a vanilla second-price auction). Xu and Lu [53] prove that such a revenue drop is unavoidable by deterministic mechanisms. Finally, our setting is distinct from, but similar to in spirit, work that uses public attributes for market segmentation to improve revenue [8, 11].

_Welfare-revenue tradeoffs in auctions._ Welfare and revenue relationships in Bayesian auctions have been widely studied since the seminal work of Bulow and Klemperer [17]. Welfare-revenue tradeoffs for second-price auctions with reserve prices in the single item setting have been quantified [31, 21], with some approximate understanding of the Pareto frontier [23]. Anshelevich et al. [4] study welfare-revenue tradeoffs in large markets, Aggarwal et al. [2] study the efficiency of revenue-optimal mechanisms, and Abhishek and Hajek [1] study the efficiency loss of revenue-optimal mechanisms.

_Constant-parameter mechanism design._ Revenue-optimal mechanism design for settings where each agent's type space is of a constant dimension has been studied previously in certain specific settings. Single-parameter mechanism design is a well-studied topic dating back to the seminal work of Myerson [42], who (1) characterized the set of all truthful allocation rules and (2) derived the Bayesian optimal auction based on virtual values (a quantity that is highly dependent on knowledge of the agents' value distributions). Archer and Tardos [5] also characterize the set of allocation rules that can be implemented truthfully in the single-parameter setting, and use this to derive polynomial-time mechanisms with strong revenue approximation guarantees in various settings. Kleinberg and Yuan [33] prove revenue guarantees for a variety of single-parameter settings that depend on distributional parameters. Constrained buyers with two-parameter values have also been studied [36, 43].

_Combinatorial auctions for limited supply._ Our mechanism when agent types lie on known linear subspaces can be seen as a generalization of the well-known logarithmic revenue approximation that is achieved by a second-price auction with a random reserve price in the single-item setting [27]. Similar revenue approximations have been derived in multi-item settings for various classes of bidder valuation functions such as unit-demand [30], additive [48, 35], and subadditive [9, 18]. To the best of our knowledge, no previous techniques handle agent types on low-dimensional subspaces. Furthermore, our results are not restricted to combinatorial auctions unlike most previous research.

## 2 Problem formulation, example applications, and weakest-competitor VCG

We consider a general multidimensional mechanism design setting with a finite allocation space \(\Gamma\) and \(n\) agents. \(\Theta_{i}\) is the type space of agent \(i\). Agent \(i\)'s true private type \(\theta_{i}\in\Theta_{i}\) determines her value \(v(\theta_{i},\alpha)\) for allocation \(\alpha\in\Gamma\). We will interpret \(\Theta_{i}\) as a subset of \(\mathbb{R}^{\Gamma}\), so \(\theta_{i}[\alpha]=v(\theta_{i},\alpha)\). We use \(\boldsymbol{\theta}\in\bigtimes_{i=1}^{n}\Theta_{i}\) to denote a profile of types and \(\boldsymbol{\theta}_{-i}\in\Theta_{-i}:=\bigtimes_{j\neq i}\Theta_{i}\) to denote a profile of types excluding agent \(i\). We now introduce our model of side information. For each agent, the mechanism designer receives a subset of the type space predicting that the subset contains the agent's true yet-to-be-revealed type. Formally, the mechanism designer receives additional information about each agent in the form of a refinement of each agent's type space, given by \(\widetilde{\Theta}_{1}\subseteq\Theta_{1},\ldots,\widetilde{\Theta}_{n} \subseteq\Theta_{n}\). These refinements postulate that the true type of bidder \(i\) is actually contained in \(\widetilde{\Theta}_{i}\) (though the mechanism designer does not necessarily know whether or not these predictions are valid). We refer to the \(\widetilde{\Theta}_{i}\) as _side-information sets_ or _predictions_. To simplify exposition, we assume that priorto receiving side information the mechanism designer has no differentiating information about the agents' types, that is, \(\Theta_{1}=\cdots=\Theta_{n}\). Let \(\Theta\) denote this common _ambient type space_.

A mechanism with side information is specified by an allocation rule \(\alpha(\bm{\theta};\widetilde{\Theta}_{1},\ldots,\widetilde{\Theta}_{n})\in\Gamma\) and a payment rule \(p_{i}(\bm{\theta};\widetilde{\Theta}_{1},\ldots,\widetilde{\Theta}_{n})\in \mathbb{R}\) for each agent \(i\). We assume agents have quasilinear utilities. A mechanism is _incentive compatible (IC)_ if \(\theta_{i}\in\operatorname*{argmax}_{\theta^{\prime}_{i}\in\Theta_{i}}\theta_{ i}[\alpha(\theta^{\prime}_{i},\bm{\theta}_{-i};\widetilde{\Theta}_{1},\ldots, \widetilde{\Theta}_{n})]-p_{i}(\theta^{\prime}_{i},\bm{\theta}_{-i};\widetilde {\Theta}_{1},\ldots,\widetilde{\Theta}_{n})\) holds for all \(i,\theta_{i}\in\Theta_{i},\bm{\theta}_{-i}\in\Theta_{-i},\widetilde{\Theta}_{ 1}\subseteq\Theta_{i},\ldots,\widetilde{\Theta}_{n}\subseteq\Theta_{n}\), that is, agents are incentivized to report their true type regardless of what other agents report and regardless of the side information used by the mechanism (this definition is equivalent to the usual notion of dominant-strategy IC and simply stipulates that side information ought to be used in an IC manner). A mechanism is _individually rational (IR)_ if \(\theta_{i}[\alpha(\theta_{i},\bm{\theta}_{-i};\widetilde{\Theta}_{1},\ldots, \widetilde{\Theta}_{n})]-p_{i}(\theta_{i},\bm{\theta}_{-i};\widetilde{\Theta}_ {1},\ldots,\widetilde{\Theta}_{n})\geq 0\) holds for all \(i,\theta_{i},\bm{\theta}_{-i},\widetilde{\Theta}_{1},\ldots,\widetilde{\Theta} _{n}\). We will analyze a variety of randomized mechanisms that randomize over IC and IR mechanisms. Such randomized mechanisms are thus IC and IR in the strongest possible sense (as supposed to weaker in-expectation IC/IR). _An important note: no assumptions are made on the veracity of \(\widetilde{\Theta}_{i}\), and agent \(i\)'s misreporting space is the ambient type space \(\Theta_{i}\)._

#### Example applications

Our model of side information within the rich language of multidimensional mechanism design allows us to capture a variety of different problem scenarios where both welfare and revenue are desired objectives. We list a few examples of different multidimensional mechanism settings along with examples of different varieties of side information sets.

* Combinatorial auctions: There are \(m\) indivisible items to be allocated among \(n\) agents (or to no one). The allocation space \(\Gamma\) is the set of \((n+1)^{m}\) allocations of the items and \(\theta_{i}[\alpha]\) is agent \(i\)'s value for the bundle of items she is allocated by \(\alpha\). Let X and Y denote two of the items for sale. The set \(\widetilde{\Theta}_{i}=\{\theta_{i}:\theta_{i}[\{\text{X},\text{Y}\}]\geq 9, \theta_{i}[\{\text{X}\}]+\theta_{i}[\{\text{Y}\}]\geq 10\}\) represents the prediction that agent \(i\)'s values for X and Y individually sum up to at least $10, and her value for the bundle is at least $9. Here, \(\widetilde{\Theta}_{i}\) is the intersection of linear constraints.
* Matching markets: There are \(m\) items (_e.g._, houses) to be matched to \(n\) buyers. The allocation space \(\Gamma\) is the set of matchings on the bipartite graph \(K_{m,n}\) and \(\theta_{i}[\alpha]\) is buyer \(i\)'s value for the item \(\alpha\) assigns her. Let \(\alpha_{1},\alpha_{2},\alpha_{3}\) denote three matchings that match house 1, house 2, and house 3 to agent \(i\), respectively. The set \(\widetilde{\Theta}_{i}=\{\theta_{i}:\theta_{i}[\alpha_{1}]=2\cdot\theta_{i}[ \alpha_{2}]=0.75\cdot\theta_{i}[\alpha_{3}]\}\) represents the information that agent \(i\) values house 1 twice as much as house 2, and \(3/4\) as much as house 3. Here, \(\widetilde{\Theta}_{i}\) is the linear space given by \(\operatorname*{span}(\langle 1,1/2,4/3\rangle)\).
* Fundraising for a common amenity: A multi-story office building that houses several companies is opening a new cafeteria on a to-be-determined floor and is raising construction funds. The allocation space \(\Gamma\) is the set of floors of the building and \(\theta_{i}[\alpha]\) is the (inverse of the) cost incurred by building-occupant \(i\) for traveling to floor \(\alpha\). The set \(\widetilde{\Theta}_{i}=\{\theta_{i}:\|\theta_{i}-\theta_{i}^{*}\|_{p}\leq k\}\) postulates that \(i\)'s true type is no more than \(k\) away from \(\theta_{i}^{*}\) in \(\ell_{p}\)-distance, which might be derived from an estimate of the range of floors agent \(i\) works on based on the company agent \(i\) represents. Here, \(\widetilde{\Theta}_{i}\) is given by a (potentially nonlinear) distance constraint.
* Bidding for a shared outcome: A delivery service that offers multiple delivery rates (priced proportionally) needs to decide on a delivery route to serve \(n\) customers. The allocation space \(\Gamma\) is the set of feasible routes and \(\theta_{i}[\alpha]\) is agent \(i\)'s value for receiving her packages after the driving delay specified by \(\alpha\). Let \(\alpha_{t}\) denote an allocation that imposes a driving delay of \(t\) on agent \(i\). The set \(\widetilde{\Theta}_{i}=\{\theta_{i}:\theta_{i}[\alpha_{0}]\geq 50,\theta_{i}[ \alpha_{t+1}]\geq f_{t}(\theta_{i}[\alpha_{t}])\ \forall t\}\) is the prediction that agent \(i\) is willing to pay $50 to receive her package as soon as possible, and is at worst a time discounter determined by (potentially nonlinear) discount functions \(f_{t}\). Here, the complexity of \(\widetilde{\Theta}_{i}\) is determined by the \(f_{t}\).

In our results we will assume that \(\Theta=[0,H]^{\Gamma}\) imposing a cap \(H\) on any agent's value for any allocation. This is the only problem-specific parameter in our results. In the above four bulleted examples \(H\) represents the maximum value any agent has for the grand bundle of items, any available house, the cafeteria opening on her floor, and receiving her packages with no delay, respectively.

### The weakest-competitor VCG mechanism

The VCG mechanism can generally be highly suboptimal when it comes to revenue [7; 39; 49] (and conversely mechanisms that shoot for high revenue can be highly welfare suboptimal). However, if efficiency is enforced as a constraint of the mechanism design, then the _weakest-competitor VCG (WCVCG) mechanism_ introduced by Krishna and Perry [34] is in fact revenue optimal (they call it the generalized VCG mechanism). While VCG payments are based on participation externalities, WCVCG payments are based on agents being replaced by _weakest competitors_ who have the smallest impact on welfare. This approach yields a strict revenue improvement over vanilla VCG. Krishna and Perry [34] proved that the Bayesian version of WCVCG is revenue optimal among all efficient, IC, and IR mechanisms. The (prior-free) WCVCG mechanism works as follows. Given reported types \(\bm{\theta}\), it uses the efficient allocation \(\alpha^{*}=\operatorname*{argmax}_{\alpha\in\Gamma}\sum_{i=1}^{n}\theta_{i} [\alpha]\). The payments are given by \(p_{i}(\bm{\theta})=\min_{\widetilde{\theta}_{i}\in\Theta_{i}}(\max_{\alpha \in\Gamma}\sum_{j\neq i}\theta_{j}[\alpha]+\widetilde{\theta}_{i}[\alpha])- \sum_{j\neq i}\theta_{j}[\alpha^{*}]\). Here, \(\Theta_{i}\) is the ambient type space of agent \(i\). If \(0\in\Theta_{i}\), \(p_{i}\) is the vanilla VCG payment. Krishna and Perry [34] prove the following result in the Bayesian setting, which we reproduce in a stronger prior-free form for completeness.

**Theorem 2.1**.: _Weakest-competitor VCG is revenue-optimal subject to efficiency, IC, and IR._

Proofs of all results in this paper are in Appendix A. Our meta-mechanism (Section 3) is a generalization of WCVCG that uses side information sets rather than the ambient type space to determine payments. (Misreporting is not limited to side information sets.) Our meta-mechanism relaxes efficiency in order to use the side information to boost revenue.

## 3 Weakest-competitor sets and our meta-mechanism

In this section we present our meta-mechanism for mechanism design with side information. Our meta-mechanism generalizes the WCVCG mechanism. We begin by introducing some new constructions based on the concept of a weakest competitor. These constructions are the key ingredients in understanding the role of side information in our meta-mechanism. Let \(\theta\preceq\theta^{\prime}\) if \(\theta[\alpha]\leq\theta^{\prime}[\alpha]\) for all \(\alpha\in\Gamma\). Let \(\theta\preccurlyeq\theta^{\prime}\) if \(\theta[\alpha]\leq\theta^{\prime}[\alpha]\) for all \(\alpha\in\Gamma\) and there exists \(\alpha^{\prime}\in\Gamma\) with \(\theta[\alpha^{\prime}]<\theta^{\prime}[\alpha^{\prime}]\). Let \(\theta\prec\theta^{\prime}\) if \(\theta[\alpha]<\theta^{\prime}[\alpha]\) for all \(\alpha\in\Gamma\). We assume \(\Theta_{i}=\Theta=[0,H]^{\Gamma}\) for all \(i\), that is, all agents share a common ambient type space with no up-front differentiating information.

**Definition 3.1**.: The _extended weakest-competitor set_ of a closed set \(\widetilde{\Theta}_{i}\), denoted by \(\overline{\mathsf{WC}}(\widetilde{\Theta}_{i})\), is the subset of all weakest competitors in \(\widetilde{\Theta}_{i}\) over all possible type profiles of the other agents. Formally, \(\overline{\mathsf{WC}}(\widetilde{\Theta}_{i}):=\{\operatorname*{argmin}_{ \widetilde{\theta}_{i}\in\widetilde{\Theta}_{i}}(\max_{\alpha\in\Gamma}\sum_{ j\neq i}\theta_{j}[\alpha]+\widetilde{\theta}_{i}[\alpha]):\bm{\theta}_{-i}\in\Theta_{-i}\}\). The _weakest-competitor set_ of \(\widetilde{\Theta}_{i}\), denoted by \(\mathsf{WC}(\widetilde{\Theta}_{i})\), is the subset of \(\overline{\mathsf{WC}}(\widetilde{\Theta}_{i})\) where ties in the argmin are broken by discarding any \(\theta^{\prime}\) in the argmin if there exists \(\theta\) also in the argmin with \(\theta\prec\theta^{\prime}\). We call members of both \(\overline{\mathsf{WC}}(\widetilde{\Theta}_{i})\) and \(\mathsf{WC}(\widetilde{\Theta}_{i})\)_weakes competitors_ and say \(\widehat{\theta}_{i}\) is a _weakest competitor relative to \(\bm{\theta}_{-i}\)_ if \(\widehat{\theta}_{i}\in\operatorname*{argmin}_{\widetilde{\theta}_{i}\in \widetilde{\Theta}_{i}}\max_{\alpha\in\Gamma}\sum_{j\neq i}\theta_{j}[\alpha]+ \widetilde{\theta}_{i}[\alpha]\).

The weakest-competitor set is a natural notion of a lower bound corresponding to a given predicted type set. From the perspective of WCVCG, the payment of an agent with true type in \(\widetilde{\Theta}_{i}\) only depends on \(\mathsf{WC}(\widetilde{\Theta}_{i})\) and not on \(\widetilde{\Theta}_{i}\). Motivated by this observation, we define the weakest-competitor hull, which can be viewed as a "weakest-competitor relaxation".

**Definition 3.2**.: The _weakest-competitor hull_ of \(\widetilde{\Theta}_{i}\), denoted by \(\mathsf{WCH}(\widetilde{\Theta}_{i})\), is the maximal set \(S\) such that \(\mathsf{WC}(S)=\mathsf{WC}(\widetilde{\Theta}_{i})\) (no \(T\supset S\) satisfies \(\mathsf{WC}(T)=\mathsf{WC}(\widetilde{\Theta}_{i})\)).

Weakest-competitor sets and hulls can be simply characterized without explicit reference to the mechanics of WCVCG. Figure 1 displays examples in a two-dimensional type space.

**Theorem 3.3**.: _Let \(\Theta=[0,H]^{\Gamma}\) and let \(\widetilde{\Theta}\subseteq\Theta\) be closed. Then \(\overline{\mathsf{WC}}(\widetilde{\Theta})=\{\theta\in\widetilde{\Theta}:\{ \theta^{\prime}\in\widetilde{\Theta}:\theta^{\prime}\prec\theta\}=\emptyset\}\), \(\mathsf{WC}(\widetilde{\Theta})=\{\theta\in\widetilde{\Theta}:\{\theta^{\prime} \in\widetilde{\Theta}:\theta^{\prime}\prec\theta\}=\emptyset\},\) and \(\mathsf{WCH}(\widetilde{\Theta})=\{\theta\in\Theta:\exists\theta^{\prime}\in \widetilde{\Theta}\) s.t. \(\theta\succeq\theta^{\prime}\}\) is the upwards closure of \(\widetilde{\Theta}\)._

We now present our meta-mechanism, which we denote by \(\mathcal{M}\). It uses the efficient allocation, but that allocation is enjoyed only by the subset of agents able to compete with the weakest competitors in the side information set. \(\mathcal{M}\) then implements the weakest-competitor payments on those agents.

The input subsets \(\widetilde{\Theta}_{1},\ldots,\widetilde{\Theta}_{n}\) represent the side information/predictions given to the mechanism designer that postulate that \(\theta_{i}\in\widetilde{\Theta}_{i}\).

Meta-mechanism \(\mathcal{M}\)

Input: subsets \(\widetilde{\Theta}_{1},\ldots,\widetilde{\Theta}_{n}\subseteq\Theta\) given to mechanism designer.

* Based on \(\widetilde{\Theta}_{1},\ldots,\widetilde{\Theta}_{n}\), come up with \(\widehat{\Theta}_{1},\ldots,\widehat{\Theta}_{n}\). Agents asked to reveal types \(\theta_{1},\ldots,\theta_{n}\).
* Let \(\alpha^{*}=\operatorname*{argmax}_{\alpha\in\Gamma}\sum_{i=1}^{n}\theta_{i}[ \alpha]\) and for each \(i\) let \[p_{i}=\min_{\widetilde{\theta}_{i}\in\mathsf{WC}(\widetilde{\Theta}_{i})} \left(\max_{\alpha\in\Gamma}\sum_{j\neq i}\theta_{j}[\alpha]+\widetilde{\theta }_{i}[\alpha]\right)-\sum_{j\neq i}\theta_{j}[\alpha^{*}].\]
* Let \(\mathcal{I}=\{i:\theta_{i}[\alpha^{*}]-p_{i}\geq 0\}\). If agent \(i\notin\mathcal{I}\), \(i\) is excluded and receives zero utility (zero value and zero payment).* If agent \(i\in\mathcal{I}\), \(i\) enjoys allocation \(\alpha^{*}\) and pays \(p_{i}\).

Meta-mechanism \(\mathcal{M}\) generates welfare equal to \(\sum_{i\in\mathcal{I}}\theta_{i}[\alpha^{*}]\) and revenue equal to \(\sum_{i\in\mathcal{I}}p_{i}\). \(\mathcal{M}\) does not specify how to set \(\widehat{\Theta}_{1},\ldots,\widehat{\Theta}_{n}\) based on \(\widetilde{\Theta}_{1},\ldots,\widetilde{\Theta}_{n}\) (hence the "meta" label). This challenge is the subject of the later sections where we will describe, based on the setting, how to set the \(\widetilde{\Theta}_{i}\) in order to generate high welfare and high revenue. We now establish the incentive properties of \(\mathcal{M}\).

**Theorem 3.4**.: \(\mathcal{M}\) _is IC and IR._

Next we show that \(\mathsf{WCH}\) precisely captures the set of agent types that never violate IR. This consideration does not arise in \(\mathsf{WCVCG}\) since in that setting misreporting is limited to the set used in the weakest-competitor minimization, and hence IR is never violated. In our setting, we make no assumptions on the veracity of the sets \(\widehat{\Theta}_{i}\) and must therefore reckon with the possibility that an agent is unable to compete with the weakest competitors in \(\mathsf{WC}(\widehat{\Theta}_{i})\).

**Theorem 3.5**.: _Let \(\theta_{i}\) denote the true type of agent \(i\) and let \(\widehat{\Theta}_{1},\ldots,\widehat{\Theta}_{n}\) denote the side information sets used by \(\mathcal{M}\). Then \(i\in\mathcal{I}\) for all \(\boldsymbol{\theta}_{-i}\iff\theta_{i}\in\mathsf{WCH}(\widehat{\Theta}_{i})\)._

Theorem 3.5 shows that \(i\) is guaranteed to participate in \(\mathcal{M}\) regardless of other agents' types if and only if \(\theta_{i}\in\mathsf{WCH}(\widehat{\Theta}_{i})\). We capitalize on this observation when we derive revenue guarantees for \(\mathcal{M}\), since the welfare of \(\mathcal{M}\) is at least \(\sum_{i:\theta_{i}\in\mathsf{WCH}(\widehat{\Theta}_{i})}\theta_{i}[\alpha^{*}]\) and its revenue is at least \(\sum_{i:\theta_{i}\in\mathsf{WCH}(\widehat{\Theta}_{i})}p_{i}\).

Before we proceed to our main analyses of the key properties and guarantees of \(\mathcal{M}\), we briefly discuss its computational complexity. We consider the special case where the side-information sets are polytopes. Let \(size(\widehat{\Theta}_{i})\) denote the encoding size of the constraints defining \(\widehat{\Theta}_{i}\).

**Theorem 3.6**.: _Let \(\widehat{\Theta}_{i}\) be a polytope. Payment \(p_{i}\) in \(\mathcal{M}\) can be computed in \(poly(|\Gamma|,size(\widehat{\Theta}_{i}),n)\) time. Furthermore, determining membership in \(\mathsf{WCH}(\widehat{\Theta}_{i})\) can be done in \(poly(|\Gamma|,size(\widehat{\Theta}_{i}))\) time._Main guarantees of the mechanism in terms of prediction quality

In this section we prove our main guarantees on our meta-mechanism \(\mathcal{M}\) in terms of the quality of the side information \(\widetilde{\Theta}_{1},\ldots,\widetilde{\Theta}_{n}\). We will largely refer to the side information as _predictions_ in this section to emphasize that \(\widetilde{\Theta}_{i}\) could be wildly incorrect/inaccurate. To state our results we need the following notation which will be used throughout the remainder of the paper. Given agent types \(\theta_{1},\ldots,\theta_{n}\), let \(\alpha_{\mathsf{opt}}\) denote the efficient allocation among the \(n\) agents and let \(\mathsf{OPT}=\max_{\alpha\in\Gamma}\sum_{i=1}^{n}\theta_{i}[\alpha]=\sum_{i=1} ^{n}\theta_{i}[\alpha_{\mathsf{opt}}]\) denote the welfare of the efficient allocation (also called the total social surplus). Let \(\mathsf{VCG}\) denote VCG revenue on the \(n\) agents.

The following lemma shows that payment \(p_{i}\) in \(\mathcal{M}\) can be related to agent \(i\)'s value for \(\alpha_{\mathsf{opt}}\) if \(i\) has a valid side information set \((\theta_{i}\in\mathsf{WCH}(\widehat{\Theta}_{i}))\). We incur a loss term equal to the \(\ell_{\infty}\)-Hausdorff distance from the true type \(\theta_{i}\) to \(\mathsf{WC}(\widehat{\Theta}_{i})\), defined as \(d_{H}(\theta_{i},\mathsf{WC}(\widehat{\Theta}_{i})):=\max_{\widetilde{\theta}_ {i}\in\mathsf{WC}(\widehat{\Theta}_{i})}\|\theta_{i}-\widetilde{\theta}_{i}\|_ {\infty}\).

**Lemma 4.1**.: _Run \(\mathcal{M}\) with \(\widehat{\Theta}_{i}\). If \(i\) is such that \(\theta_{i}\in\mathsf{WCH}(\widehat{\Theta}_{i})\), then \(p_{i}\geq\theta_{i}[\alpha_{\mathsf{opt}}]-d_{H}(\theta_{i},\mathsf{WC}( \widehat{\Theta}_{i}))\)._

_Measuring the error of a prediction._ Before instantiating \(\mathcal{M}\) with specific rules to determine the \(\widehat{\Theta}_{i}\) from the \(\widetilde{\Theta}_{i}\), we define our notions of prediction error, which are motivated by Lemma 4.1.

**Definition 4.2**.: The _involatility_ of a prediction \(\widetilde{\Theta}_{i}\), denoted by \(\gamma_{i}^{V}\), is the distance from the true type \(\theta_{i}\) of agent \(i\) to \(\mathsf{WCH}(\widetilde{\Theta}_{i})\): \(\gamma_{i}^{V}:=d(\theta_{i},\mathsf{WCH}(\widetilde{\Theta}_{i}))=\min_{ \widetilde{\theta}_{i}\in\mathsf{WCH}(\widetilde{\Theta}_{i})}\|\theta_{i}- \widetilde{\theta}_{i}\|_{\infty}\).

**Definition 4.3**.: The _inaccuracy_ of a prediction \(\widetilde{\Theta}_{i}\) is the quantity \(\gamma_{i}^{A}:=d_{H}(\theta_{i},\mathsf{WC}(\widetilde{\Theta}_{i}))\).

We say that a prediction \(\widetilde{\Theta}_{i}\) is _valid_ if \(\gamma_{i}^{V}=0\), that is, \(\theta_{i}\in\mathsf{WCH}(\widetilde{\Theta}_{i})\). We say that a prediction is _perfect_ if \(\gamma_{i}^{A}=0\) or, equivalently, \(\mathsf{WC}(\widetilde{\Theta}_{i})=\{\theta_{i}\}\). If a prediction is perfect, then it is also valid. Our main results will depend on these error measures. See Figure 1 for an illustration.

_Consistency and robustness._ We say a mechanism is \((a,b)\)_-consistent_ and \((c,d)\)_-robust_ if when predictions are perfect it satisfies \(\mathbb{E}[\text{welfare}]\geq a\cdot\mathsf{OPT}\), \(\mathbb{E}[\text{revenue}]\geq b\cdot\mathsf{OPT}\), and satisfies \(\mathbb{E}[\text{welfare}]\geq c\cdot\mathsf{OPT},\mathbb{E}[\text{revenue}] \geq d\cdot\mathsf{VCG}\) independent of the prediction quality. Consistency demands near-optimal performance when the side information is perfect, and therefore we compete with the total social surplus \(\mathsf{OPT}\) on both the welfare and revenue fronts. Robustness deals with the case of arbitrarily bad side information, in which case we would like our mechanism's performance to be competitive with vanilla VCG, which already obtains welfare equal to \(\mathsf{OPT}\). High consistency and robustness ratios are in fact trivial to achieve, and we will thus largely not be too concerned with these measures--our main goal is to design high-performance mechanisms that degrade gracefully as the prediction errors increase. In Appendix B we show that the trivial mechanism that discards all side information with probability \(\beta\) and trusts the side information completely with probability \(1-\beta\) is \((1,1-\beta)\)-consistent and \((\beta,\beta)\)-robust, but suffers from huge discontinuous drops in performance even when predictions are nearly perfect.

_Random expansion mechanism._ Our guarantees will depend on \(H\); an upper bound on any agent's values. This is the only problem-domain-specific parameter in our results (examples are in Section 2). \(H=\max_{\theta_{1},\theta_{2}\in\mathbb{O}}\|\theta_{1}-\theta_{2}\|_{\infty}\) is the \(\ell_{\infty}\)-diameter of \(\Theta\). For a point \(\theta\), let \(\mathcal{B}(\theta,r)=\{\theta^{\prime}:\|\theta-\theta^{\prime}\|_{\infty}\leq r\}\) be the closed \(\ell_{\infty}\)-ball centered at \(\theta\) with radius \(r\). For a set \(\widetilde{\Theta}\), let \(\mathcal{B}(\widetilde{\Theta},r)=\cup_{\widetilde{\theta}\in\widetilde{ \Theta}}\mathcal{B}(\widetilde{\theta},r)\) denote the \(\ell_{\infty}\)-expansion of \(\widetilde{\Theta}\) by \(r\). For \(\zeta_{i}\geq 0,\lambda_{i}>0\), and \(K_{i}:=\lceil\log_{2}((H-\zeta_{i})/\lambda_{i})\rceil\), let \(\mathcal{M}_{\zeta,\lambda}\) denote the mechanism that for each \(i\) independently sets

\[\boxed{\widehat{\Theta}_{i}=\mathcal{B}(\widetilde{\Theta}_{i},\zeta_{i}+2^{k_{ i}}\cdot\lambda_{i}),\text{ where }k_{i}\sim_{\text{unif. }}\{0,1,\ldots,K_{i}\}.}\]

We now state and discuss our main welfare and revenue guarantees on \(M_{\zeta,\lambda}\). Define \(\log^{+}:\mathbb{R}\rightarrow\mathbb{R}_{\geq 0}\) by \(\log^{+}(x)=0\) if \(x\leq 0\) and \(\log^{+}(x)=\max\{0,\log(x)\}\) if \(x>0\).

**Theorem 4.4**.: \(\mathbb{E}[\text{welfare}]\geq\max\{(1-\max_{i}\frac{\lceil\log_{2}^{+}(( \gamma_{i}^{V}-\zeta_{i})/\lambda_{i})\rceil}{1+\lceil\log_{2}((H-\zeta_{i})/ \lambda_{i})\rceil}),\frac{1}{1+\lceil\max_{i}\log_{2}((H-\zeta_{i})/\lambda_{ i})\rceil}\}\mathsf{OPT}\)_._

**Theorem 4.5** (Revenue bound 1).: _Let \(\rho_{i}=2(\gamma_{i}^{V}-\zeta_{i})\mathbf{1}(\zeta_{i}+\lambda_{i}<\gamma_{i} ^{V})+\lambda_{i}\mathbf{1}(\zeta_{i}+\lambda_{i}\geq\gamma_{i}^{V})\). Then \(\mathbb{E}[\text{revenue}]\geq\frac{1}{1+\lceil\max_{i}\log_{2}((H-\zeta_{i})/ \lambda_{i})\rceil}(\mathsf{OPT}-\sum_{i=1}^{n}(\gamma_{i}^{A}+\zeta_{i}+\rho_{ i}))\)._

**Theorem 4.6** (Revenue bound 2).: \(\mathbb{E}[\text{revenue}]\geq(1-\max_{i}\frac{\lceil\log_{2}^{+}((\gamma_{i}^{V}- \zeta_{i})/\lambda_{i})\rceil}{1+\lceil\log_{2}((H-\zeta_{i})/\lambda_{i}) \rceil})(\mathsf{OPT}-\sum_{i=1}^{n}(\gamma_{i}^{A}+\zeta_{i}))-\sum_{i=1}^{n} \frac{4H}{1+\lceil\log_{2}((H-\zeta_{i})/\lambda_{i})\rceil}\)._Proof sketch.: \(\mathcal{M}_{\zeta,\lambda}\) in essence performs a doubling search with initial hop \(\zeta_{i}\) and \(\lambda_{i}\) controlling how fine-grained the search proceeds. The bounds are proven (Appendix A.3) by controlling participation probabilities \(\Pr(\theta_{i}\in\widehat{\Theta}_{i})\) and accounting for conditional payments via Lemma 4.1. 

First, consider constant \(\zeta,\lambda\). Our welfare guarantee degrades from \(\mathsf{OPT}\) to \(\Omega(\mathsf{OPT}/\log H)\) as the invalidity of the predictions increase. Revenue bound 1 degrades from \(\Omega(\mathsf{OPT}/\log H)\) as both the invalidity and inaccuracy of the predictions increase. Revenue bound 2 illustrates that we can obtain significantly better performance if the parameters \(\zeta,\lambda\) are chosen appropriately. In particular, for any \(\varepsilon\), \(\zeta_{i}=\gamma_{i}^{V}\) and \(\lambda_{i}\leq O((H-\zeta_{i})/2^{H/\varepsilon})\) yields \(\mathbb{E}|revenue|\geq\mathsf{OPT}-\sum_{i=1}^{n}(\gamma_{i}^{A}+\gamma_{i}^{V }+\varepsilon)\), a bound that is only additively worse than the total social surplus (and recovers the total social surplus as \(\lambda_{i}\downarrow 0\) if the predictions are perfect). This bound degrades gradually as \(\zeta_{i},\lambda_{i}\) deviate.

To summarize, if the side information is of very high quality, the best parameters \(\zeta,\lambda\) nearly recover the total social surplus \(\mathsf{OPT}\) as welfare _and_ revenue, and revenue degrades gradually as the chosen parameters \(\zeta,\lambda\) worsen. If the side information is of questionable quality, the best parameters \(\zeta,\lambda\) still obtain \(\mathsf{OPT}\) as welfare, with revenue suffering additively by the prediction errors. As the parameter selection worsens, welfare and revenue degrade to \(\Omega(\mathsf{OPT}/\log H)\) with revenue suffering the same additive loss. Effective parameters can be, for example, learned from data [32]. We briefly discuss the consistency and robustness of \(\mathcal{M}_{\zeta,\lambda}\) in Appendix B.3, where we show the worst case performance of \(\mathcal{M}_{\zeta,\lambda}\) independent of prediction quality is not much worse than vanilla VCG.

### More expressive forms of side information

In this subsection we establish two avenues for richer and more expressive side information languages. The first deals with uncertainty and the second with joint multi-agent predictions.

Uncertainty.We now show that the techniques we have developed so far readily extend to an even larger more expressive form of side information that allows one to express varying degrees of uncertainty. A _side information structure_ corresponding to agent \(i\) is given by a partition \((A_{1}^{i},\ldots,A_{m}^{i})\) of the ambient type space \(\Theta_{i}\) into disjoint sets, probabilities \(\mu_{1}^{i},\ldots,\mu_{m}^{i}\geq 0;\sum_{j}\mu_{j}^{i}=1\) corresponding to each partition element, and for each partition element an optional probability density function \(f_{j}^{i_{\cdot}}\!\int_{A_{j}^{i}}f_{j}^{i}=1\). The side information structure represents (1) a belief over what partition element \(A_{j}^{i}\) the true type \(\theta_{i}\) lies in and (2) if a density is specified, the precise nature of uncertainty over the true type within \(A_{j}^{i}\). Our model of side information sets \(\widetilde{\Theta}_{i}\) considered earlier in the paper corresponds to the partition \((\widetilde{\Theta}_{i},\Theta_{i}\setminus\widetilde{\Theta}_{i})\) with \(\mu(\widetilde{\Theta}_{i})=1\) and no specified densities. The richer model allows side information to convey finer-grained beliefs; for example one can express quantiles of certainty, precise distributional beliefs, and arbitrary mixtures of these.

Our notions of prediction error (invalidity and inaccuracy) can be naturally generalized. We define \(\overline{\gamma}_{i}^{V}=\sum_{j}\mu_{j}^{i}\gamma_{i}^{V}(A_{j}^{i};f_{j}^{ i})\) and \(\overline{\gamma}_{i}^{A}=\sum_{j}\mu_{j}^{i}\gamma_{i}^{A}(A_{j}^{i};f_{j}^{ i})\), where \(\gamma_{i}^{V}(A_{j}^{i};f_{j}^{i})=d(\theta_{i},\mathsf{WCH}(A_{j}^{i}))\) if \(f_{j}^{i}=\mathsf{None}\) and \(\gamma_{i}^{V}(A_{j}^{i};f_{j}^{i})=\mathbb{E}_{\widetilde{\Theta}_{i}\sim f _{j}^{i}}[d(\theta_{i},\mathsf{WCH}(\{\widetilde{\theta}_{i}\})]\) if \(f_{j}^{i}\) is a well-defined density. Similarly \(\gamma_{i}^{A}(A_{j}^{i};f_{j}^{i})=d_{H}(\theta_{i},\mathsf{WCH}(A_{j}^{i}))\) if \(f_{j}^{i}=\mathsf{None}\) and \(\gamma_{i}^{A}(A_{j}^{i};f_{j}^{i})=\mathbb{E}_{\widetilde{\theta}_{i}\sim f _{j}^{i}}[d(\theta_{i},\widetilde{\theta}_{i})]\) otherwise.

Our generalized version of \(M_{\zeta,\lambda}\) first samples a partition element \(A_{j}^{i}\) according to \((\mu_{1}^{i},\ldots,\mu_{m}^{i})\), and draws \(k_{i}\sim_{\text{unif.}}\{0,\ldots,K_{i}\}\) where \(K_{i}\) is defined as before. If \(f_{j}^{i}=\mathsf{None}\), it sets \(\widehat{\Theta}_{i}=\mathcal{B}(A_{j}^{i},\zeta_{i}+2^{k_{i}}\lambda_{i})\). Otherwise, it samples \(\widetilde{\theta}_{i}\sim f_{j}^{i}\) and sets \(\widehat{\Theta}_{i}=\mathcal{B}(\{\widetilde{\theta}_{i}\},\zeta_{i}+2^{k_{i }}\lambda_{i})\). Versions of Theorems 4.4, 4.5, and 4.6 carry forward with \(\overline{\gamma}_{i}^{V}\) and \(\overline{\gamma}_{i}^{A}\) as the error measures. In Appendix C we provide the derivations, and also take the expressive power one step further by specifying a probability space over \(\Theta_{i}\); its \(\sigma\)-algebra captures the granularity of knowledge being conveyed and its probability measure captures the uncertainty.

Joint side information.So far, side information has been independent across agents. Specifically, the mechanism designer receives sets \(\widetilde{\Theta}_{i}\subseteq\Theta_{i}\) for each agent \(i\) postulating that \(\boldsymbol{\theta}=(\theta_{1},\ldots,\theta_{n})\in\widetilde{\Theta}_{1} \times\cdots\times\widetilde{\Theta}_{n}\). We show that our techniques extend to a more expressive form of side information that allows one to express predictions involving multiple agents. Let \(\boldsymbol{\Theta}=\Theta_{1}\times\cdots\times\Theta_{n}\). The mechanism designer receives as side information a set \(\widetilde{\boldsymbol{\Theta}}\subseteq\boldsymbol{\Theta}\) postulating that \(\boldsymbol{\theta}=(\theta_{1},\ldots,\theta_{n})\in\widetilde{\boldsymbol{ \Theta}}\). Givenan agent \(i\), a side information set \(\widetilde{\bm{\Theta}}\subseteq\bm{\Theta}\), and \(\widetilde{\bm{\Theta}}_{-i}\subseteq\bigtimes_{j\neq i}\Theta_{j}\), let \(\operatorname{proj}_{i}(\widetilde{\bm{\Theta}};\widetilde{\bm{\Theta}}_{-i})= \{\widetilde{\theta}_{i}\in\Theta_{i}:\exists\bm{\theta}_{-i}\in\widetilde{ \bm{\Theta}}_{-i}\text{ s.t. }(\widetilde{\theta}_{i},\bm{\theta}_{-i})\in \widetilde{\bm{\Theta}}\}\) be the \(i\)th _projection_ of \(\widetilde{\bm{\Theta}}\) with respect to \(\widetilde{\bm{\Theta}}_{-i}\). The projection is the set of types for agent \(i\) consistent with \(\widetilde{\bm{\Theta}}\) given that the realizations of the other agents' true types are contained in \(\widetilde{\bm{\Theta}}_{-i}\). First, if \(\widetilde{\bm{\Theta}}\) is known to be a valid prediction, that is, the true type profile \(\bm{\theta}\) is guaranteed apri to lie in \(\widetilde{\bm{\Theta}}\) (equivalently, the joint misreporting space is limited to \(\widetilde{\bm{\Theta}}\)), we generalize the weakest-competitor VCG mechanism as follows. First, agents are asked to reveal their true types \(\bm{\theta}=(\theta_{1},\ldots,\theta_{n})\). The allocation used is \(\alpha^{*}=\operatorname{argmax}_{\alpha\in\Gamma}\sum_{i=1}^{n}\theta_{i}[ \alpha]\) and agent \(i\) pays

\[p_{i}=\min_{\widetilde{\theta}_{i}\in\operatorname{proj}_{i}(\widetilde{\bm{ \Theta}};\bm{\theta}_{-i})}\left(\max_{\alpha\in\Gamma}\sum_{j\neq i}\theta_{j} [\alpha]+\widetilde{\theta}_{i}[\alpha]\right)-\sum_{j\neq i}\theta_{j}[ \alpha^{*}].\]

This generalized weakest-competitor VCG mechanism is IC, IR, and revenue optimal subject to efficiency in the joint information setting for the same reason that weakest-competitor VCG is in the independent information setting.

More generally, given side information set \(\widetilde{\bm{\Theta}}\), our random expansion mechanism can be generalized as follows. Agents first reveal their true types \(\theta_{1},\ldots,\theta_{n}\). For each agent \(i\), independently set \(\widehat{\Theta}_{i}=\mathcal{B}(\operatorname{proj}_{i}(\widetilde{\bm{ \Theta}},\bm{\theta}_{-i}),\zeta_{i}+2^{k_{i}}\lambda_{i})\). The same guarantees we derived previously hold, with appropriately modified quality measures: invalidity is \(\gamma_{i}^{V}=d(\theta_{i},\mathsf{WCH}(\operatorname{proj}_{i}(\widetilde{ \bm{\Theta}},\bm{\theta}_{-i})))\) and inaccuracy is \(\gamma_{i}^{A}=d_{H}(\theta_{i},\mathsf{WC}(\operatorname{proj}_{i}(\widetilde {\bm{\Theta}},\bm{\theta}_{-i})))\). An important idea highlighted by these mechanisms for joint side information is that the true types of all agents _other than \(i\)_ can be heavily utilized in determining \(p_{i}\). This model of side information affords significantly more expressive power than the agent-independent model with product structure considered previously. For example, the mechanism designer might know that sum of the valuations of two customers for a cup of coffee exceeds a particular threshold, but does not know who has the higher value. Joint side information enables such a belief to be precisely expressed. It allows the mechanism designer to refine his beliefs on one agent based on the realized true type of the other agent (which was not possible in our previous framework).

We conclude this section with the observation that these mechanisms can loosely be interpreted as prior-free quantitative analogues of the seminal total-surplus-extraction Bayesian mechanism of Cremer and McLean [20] for correlated agents (generalized to infinite type spaces by McAfee and Reny [37]). This is an interesting connection to explore further in future research.

## 5 Constant-parameter agents: types on low-dimensional subspaces

In this section we show how the theory we have developed so far can be used to derive new revenue approximation results when the mechanism designer knows that each agent's type belongs to some low-dimensional subspace of \(\mathbb{R}^{\Gamma}\) (these subspaces can be different for each agent).

This is a slightly different setup from the previous sections. So far, we have assumed that \(\Theta_{i}=\Theta\) for all \(i\), that is, there is an ambient type space that is common to all the agents. Side information sets \(\widetilde{\Theta}_{i}\) are given as input to the mechanism designer, with no assumptions on quality/correctness (and our guarantees in Section 4 were parameterized by quality). Here, we assume the side information that each agent's type lies in a particular subspace is guaranteed to be valid. Two equivalent ways of stating this setup are (1) that \(\Theta_{i}\) is the corresponding subspace for agent \(i\) and the mechanism designer receives no additional prediction set \(\widetilde{\Theta}_{i}\) or (2) \(\Theta_{i}=\Theta\) for all \(i\), \(\widetilde{\Theta}_{i}=\Theta\cap U_{i}\) where \(U_{i}\) is a subspace of \(\mathbb{R}^{\Gamma}\), and the mechanism designer has the additional guarantee that \(\theta_{i}\in U_{i}\) (so \(\widetilde{\Theta}_{i}\) is a _valid_ side-information set). We shall use the language of the second interpretation.

In this setting, while the side information is valid, the inaccuracy errors \(\gamma_{i}^{A}\) of the sets \(\widetilde{\Theta}_{i}=\bm{\Theta}\cap U_{i}\) can be too large to meaningfully use our previous guarantees. In this section we show how to fruitfully use the information provided by the subspaces \(U_{1},\ldots,U_{n}\) within the framework of our meta-mechanism. We assume \(\Theta=[1,H]^{\Gamma}\), thereby imposing a lower bound of \(1\) on agent values (this choice of lower bound is not important, but the knowledge of some lower bound is needed).

Formally, for each \(i\), the mechanism designer knows that \(\theta_{i}\) lies in a \(k\)-dimensional subspace \(U_{i}=\text{span}(u_{i,1},\ldots,u_{i,k})\) of \(\mathbb{R}^{\Gamma}\) where each \(u_{i,j}\in\mathbb{R}^{\Gamma}_{\geq 0}\) lies in the non-negative orthant and \(\{u_{i,1},\ldots,u_{i,k}\}\) is an orthonormal basis for \(U_{i}\). For simplicity, assume \(H=2^{a}\) for some positive integer \(a\). Let \(\mathcal{L}_{i,j}=\{\lambda u_{i,j}:\lambda\geq 0\}\cap[0,H]^{\Gamma}\) be the line segment that is the portion of the ray generated by \(u_{i,j}\) that lies in \([0,H]^{\Gamma}\). Let \(y_{i,j}\) be the endpoint of \(\mathcal{L}_{i,j}\) with \(\|y_{i,j}\|_{\infty}=H\) (the other endpoint of \(\mathcal{L}_{i,j}\) is the origin). Let \(z^{1}_{i,j}=y_{i,j}/2\) be the midpoint of \(\mathcal{L}_{i,j}\), and for \(\ell=2,\ldots,\log_{2}H\) let \(z^{\ell}_{i,j}=z^{\ell-1}_{i,j}/2\) be the midpoint of \(0z^{\ell-1}_{i,j}\). So \(\|z^{\log_{2}H}_{i,j}\|_{\infty}=1\). We terminate the halving of \(\mathcal{L}_{i,j}\) after \(\log_{2}H\) steps due to the assumption that \(\theta_{i}\in[1,H]^{\Gamma}\). For every \(k\)-tuple \((\ell_{1},\ldots,\ell_{k})\in\{1,\ldots,\log_{2}H\}^{k}\), let \(\widetilde{\theta}_{i}(\ell_{1},\ldots,\ell_{k})=\sum_{j=1}^{k}z^{\ell_{i,j}}_ {i,j}\). Furthermore, let \(W_{\ell}=\{(\ell_{1},\ldots,\ell_{k})\in\{1,\ldots,\log_{2}H\}^{k}:\min_{j} \ell_{j}=\ell\}\). The sets \(W_{1},\ldots,W_{\log_{2}H}\) partition \(\{1,\ldots,\log_{2}H\}^{k}\) into levels, where \(W_{\ell}\) is the set of points with \(\ell_{\infty}\)-distance \(H/2^{\ell}\) from the origin. For each agent \(i\), our mechanism \(\mathcal{M}_{k}\) independently sets

\[\boxed{\widetilde{\Theta}_{i}=\{\widetilde{\theta}_{i}(\ell_{i,1},\ldots, \ell_{i,k})\}\text{ where }\ell_{i}\sim_{\text{unif. }}\{1,\ldots,\log_{2}H\}\text{ and }(\ell_{i,1},\ldots,\ell_{i,k})\sim_{\text{unif. }}W_{\ell_{i,}}}\]

**Theorem 5.1**.: \(\mathcal{M}_{k}\) _satisfies \(\mathbb{E}[\text{welfare}]\geq\mathsf{OPT}/\log_{2}H\) and \(\mathbb{E}[\text{revenue}]\geq\mathsf{OPT}/(2k(\log_{2}H)^{k})\)._

As mentioned in Section 1, \(\mathcal{M}_{k}\) can be viewed as a generalization of the \(\log H\) revenue approximation in the single-item limited-supply setting that is achieved by a second-price auction with a uniformly random reserve price from \(\{H/2,H/4,\ldots,1\}\)[27]. Our results apply not only to auctions but to general multidimensional mechanism design problems such as the examples presented in Section 2.

## 6 Conclusions and future research

We developed a versatile new methodology for multidimensional mechanism design that incorporates side information about agent types with the bicriteria goal of generating high social welfare and high revenue simultaneously. We designed a side-information-dependent meta-mechanism. This mechanism generalizes the weakest-competitor VCG mechanism of Krishna and Perry [34]. Careful instantiations of our meta-mechanism simultaneously achieved strong welfare and revenue guarantees that were parameterized by errors in the side information, and additionally proved to be fruitful in a setting where each agent's type lies on a constant-dimensional subspace (of the potentially high-dimensional ambient type space) that is known to the mechanism designer.

There are many new research directions that stem from our work. First, how far off are our mechanisms from the welfare-versus-revenue Pareto frontier? The weakest-competitor VCG mechanism is one extreme point, but what does the rest of the frontier look like? One possible approach here would be to extend our theory beyond VCG to the larger class of affine maximizers (which are known to contain high-revenue mechanisms)--we provide some initial ideas in Appendix D.

_Computational complexity:_ An important facet that we have largely ignored is computational complexity. The computations in our mechanism involving weakest competitors scale with the description complexity of \(\widetilde{\Theta}_{i}\) (_e.g._, the number of constraints, the complexity of constraints, and so on). An important question here is to understand the computational complexity of our mechanisms as a function of the differing (potentially problem-specific) language structures used to describe the side-information sets \(\widetilde{\Theta}_{i}\). In particular, the classes of side-information sets that are accurate, natural/interpretable, and easy to describe might depend on the specific mechanism design domain. Expressive bidding languages for combinatorial auctions have been extensively studied with massive impact in practice [46; 47]. Can a similar methodology be developed for side information?

_Improved analysis when there is a known prior:_ Another direction is to improve the Bayesian revenue analysis of Krishna and Perry when there is a known prior over agents' types. Here, the benchmark would be efficient welfare in expectation over the prior. The (Bayesian) WCVCG mechanism of Krishna and Perry uses weakest competitors with respect to the prior's support to guarantee efficient welfare in expectation, but its revenue could potentially be boosted significantly by compromising on welfare as in our random expansion mechanism. Another direction here is to study the setting when the given prior might be inaccurate. Can our random expansion mechanism be used to derive guarantees that depend on the closeness of the given prior to the true prior? Such questions are thematically related to _robust mechanism design_[16]. Another direction along this vein is to generalize our mechanisms to depend on a known prior over prediction errors.

Finally, the WCVCG mechanism of Krishna and Perry is a strict improvement over the vanilla VCG mechanism, yet it appears to not have been further studied nor applied since its discovery. The weakest-competitor paradigm could have applications in economics and computation more broadly.

## Acknowledgments and Disclosure of Funding

This material is based on work supported by the NSF under grants IIS-1901403, CCF-1733556, CCF-1910321, and SES-1919453, by the ARO under award W911NF2210266, and by Defense Advanced Research Projects Agency under cooperative agreement HR00112020003. S. Prasad thanks Morgan McCarthy for helpful discussions about real-world use cases of multidimensional mechanism design and Misha Khodak for detailed feedback on an earlier draft.

## References

* [1] Vineet Abhishek and Bruce Hajek. Efficiency loss in revenue optimal auctions. In _49th IEEE Conference on Decision and Control (CDC)_. IEEE, 2010.
* [2] Gagan Aggarwal, Gagan Goel, and Aranyak Mehta. Efficiency of (revenue-)optimal mechanisms. In _Proceedings of the 10th ACM Conference on Electronic Commerce (EC)_, 2009.
* [3] Priyank Agrawal, Eric Balkanski, Vasilis Gkatzelis, Tingting Ou, and Xizhi Tan. Learning-augmented mechanism design: Leveraging predictions for facility location. In _Proceedings of the 23rd ACM Conference on Economics and Computation (EC)_, 2022.
* [4] Elliot Anshelevich, Koushik Kar, and Shreyas Sekar. Pricing to maximize revenue and welfare simultaneously in large markets. In _International Conference on Web and Internet Economics (WINE)_. Springer, 2016.
* [5] Aaron Archer and Eva Tardos. Truthful mechanisms for one-parameter agents. In _IEEE Symposium on Foundations of Computer Science (FOCS)_, 2001.
* [6] Lawrence Ausubel and Paul Milgrom. Ascending auctions with package bidding. _The BE Journal of Theoretical Economics_, 2002.
* [7] Lawrence Ausubel and Paul Milgrom. The lovely but lonely vickrey auction. _Combinatorial auctions_, 2006.
* [8] Maria-Florina Balcan, Avrim Blum, Jason D Hartline, and Yishay Mansour. Mechanism design via machine learning. In _IEEE Symposium on Foundations of Computer Science (FOCS)_. IEEE, 2005.
* [9] Maria-Florina Balcan, Avrim Blum, and Yishay Mansour. Item pricing for revenue maximization. In _ACM Conference on Electronic Commerce (EC)_, 2008.
* [10] Maria-Florina Balcan, Tuomas Sandholm, and Ellen Vitercik. A general theory of sample complexity for multi-item profit maximization. In _ACM Conference on Economics and Computation (EC)_, 2018.
* [11] Maria-Florina Balcan, Siddharth Prasad, and Tuomas Sandholm. Efficient algorithms for learning revenue-maximizing two-part tariffs. In _Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI)_, 2020.
* [12] Maria-Florina Balcan, Siddharth Prasad, and Tuomas Sandholm. Maximizing revenue under market shrinkage and market uncertainty. _Advances in Neural Information Processing Systems (NeurIPS)_, 2022.
* [13] Eric Balkanski, Vasilis Gkatzelis, and Xizhi Tan. Strategyproof scheduling with predictions. In _Innovations in Theoretical Computer Science (ITCS)_, 2023.
* [14] Santiago Balseiro, Christian Kroer, and Rachitesh Kumar. Single-leg revenue management with advice. _arXiv preprint arXiv:2202.10939_, 2022.
* [15] Siddhartha Banerjee, Vasilis Gkatzelis, Artur Gorokh, and Billy Jin. Online nash social welfare maximization with predictions. In _Proceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)_. SIAM, 2022.
* [16] Dirk Bergemann and Stephen Morris. Robust mechanism design. _Econometrica_, pages 1771-1813, 2005.

* [17] Jeremy Bulow and Paul Klemperer. Auctions versus negotiations. _The American Economic Review_, 1996.
* [18] Tanmoy Chakraborty, Zhiyi Huang, and Sanjeev Khanna. Dynamic and nonuniform pricing strategies for revenue maximization. _SIAM Journal on Computing_, 2013.
* [19] Ed H. Clarke. Multipart pricing of public goods. _Public Choice_, 1971.
* [20] Jacques Cremer and Richard P McLean. Full extraction of the surplus in bayesian and dominant strategy auctions. _Econometrica: Journal of the Econometric Society_, pages 1247-1257, 1988.
* [21] Constantinos Daskalakis and George Pierrakos. Simple, optimal and efficient auctions. In _International Workshop on Internet and Network Economics (WINE)_. Springer, 2011.
* [22] Nikhil R Devanur, Zhiyi Huang, and Christos-Alexandros Psomas. The sample complexity of auctions with side information. In _ACM Symposium on Theory of Computing (STOC)_, 2016.
* [23] Ilias Diakonikolas, Christos Papadimitriou, George Pierrakos, and Yaron Singer. Efficiency-revenue trade-offs in auctions. In _International Colloquium on Automata, Languages, and Programming (ICALP)_, 2012.
* [24] Paul Dutting, Zhe Feng, Harikrishna Narasimhan, David Parkes, and Sai Srivatsa Ravindranath. Optimal auctions through deep learning. In _International Conference on Machine Learning (ICML)_, pages 1706-1715. PMLR, 2019.
* [25] Benjamin Edelman, Michael Ostrovsky, and Michael Schwarz. Internet advertising and the generalized second-price auction: Selling billions of dollars worth of keywords. _American economic review_, 97(1):242-259, 2007.
* [26] Vasilis Gkatzelis, Kostas Kollias, Alkmini Sgouritsa, and Xizhi Tan. Improved price of anarchy via predictions. In _Proceedings of the 23rd ACM Conference on Economics and Computation (EC)_, 2022.
* [27] Andrew V. Goldberg, Jason D. Hartline, and Andrew Wright. Competitive auctions and digital goods. In _ACM-SIAM Symposium on Discrete Algorithms (SODA)_, 2001.
* [28] Theodore Groves. Incentives in teams. _Econometrica_, 1973.
* [29] Faruk Gul and Ennio Stacchetti. Walrasian equilibrium with gross substitutes. _Journal of Economic theory_, 87(1):95-124, 1999.
* [30] Venkatesan Guruswami, Jason D Hartline, Anna R Karlin, David Kempe, Claire Kenyon, and Frank McSherry. On profit-maximizing envy-free pricing. In _ACM-SIAM Symposium on Discrete Algorithms (SODA)_, 2005.
* [31] Jason D Hartline and Tim Roughgarden. Simple versus optimal mechanisms. In _Proceedings of the 10th ACM conference on Electronic commerce_, pages 225-234, 2009.
* [32] Misha Khodak, Maria-Florina Balcan, Ameet Talwalkar, and Sergei Vassilvitskii. Learning predictions for algorithms with predictions. _Advances in Neural Information Processing Systems_, 35:3542-3555, 2022.
* [33] Robert Kleinberg and Yang Yuan. On the ratio of revenue to welfare in single-parameter mechanism design. In _Proceedings of the Fourteenth ACM Conference on Electronic Commerce (EC)_, 2013.
* [34] Vijay Krishna and Motty Perry. Efficient mechanism design. _Available at SSRN 64934_, 1998.
* [35] Anton Likhodedov, Tuomas Sandholm, et al. Approximating revenue-maximizing combinatorial auctions. In _AAAI_, volume 5, pages 267-274, 2005.
* [36] Alexey Malakhov and Rakesh V Vohra. An optimal auction for capacity constrained bidders: a network perspective. _Economic Theory_, 2009.

* [37] R Preston McAfee and Philip J Reny. Correlated information and mechanism design. _Econometrica: Journal of the Econometric Society_, pages 395-421, 1992.
* [38] Andres Munoz Medina and Sergei Vassilvitskii. Revenue optimization with approximate bid predictions. _Advances in Neural Information Processing Systems (NeurIPS)_, 2017.
* [39] Cade Metz. Facebook doesn't make as much money as it could--on purpose. _Wired_, 2015.
* [40] Michael Mitzenmacher and Sergei Vassilvitskii. Algorithms with predictions. _Communications of the ACM_, 2022.
* [41] Jamie Morgenstern and Tim Roughgarden. Learning simple auctions. In _Conference on Learning Theory (COLT)_, 2016.
* [42] Roger Myerson. Optimal auction design. _Mathematics of operations research_, 1981.
* [43] Mallesh M Pai and Rakesh Vohra. Optimal auctions with financially constrained buyers. _Journal of Economic Theory_, 150:383-425, 2014.
* [44] Baharak Rastegari, Anne Condon, and Kevin Leyton-Brown. Revenue monotonicity in deterministic, dominant-strategy combinatorial auctions. _Artificial Intelligence_, 2011.
* [45] Kevin Roberts. The characterization of implementable social choice rules. In J-J Laffont, editor, _Aggregation and Revelation of Preferences_. North-Holland Publishing Company, 1979.
* [46] Tuomas Sandholm. Expressive commerce and its application to sourcing: How we conducted $35 billion of generalized combinatorial auctions. _AI Magazine_, 28(3):45-45, 2007.
* [47] Tuomas Sandholm. Very-large-scale generalized combinatorial multi-attribute auctions: Lessons from conducting $60 billion of sourcing. In Zvika Neeman, Alvin Roth, and Nir Vulkan, editors, _Handbook of Market Design_. Oxford University Press, 2013.
* [48] Tuomas Sandholm and Anton Likhodedov. Automated design of revenue-maximizing combinatorial auctions. _Operations Research_, 2015.
* [49] Hal R Varian and Christopher Harris. The vcg auction in theory and practice. _American Economic Review_, 2014.
* [50] William Vickrey. Counterspeculation, auctions, and competitive sealed tenders. _Journal of Finance_, 1961.
* [51] Rakesh V Vohra. _Mechanism design: a linear programming approach_, volume 47. Cambridge University Press, 2011.
* [52] William E Walsh, David C Parkes, Tuomas Sandholm, and Craig Boutilier. Computing reserve prices and identifying the value distribution in real-world auctions with market disruptions. In _AAAI_, pages 1499-1502, 2008.
* [53] Chenyang Xu and Pinyan Lu. Mechanism design with predictions. In _Proceedings of the 31st International Joint Conference on Artificial Intelligence (IJCAI)_, 2022.
* [54] Makoto Yokoo, Yuko Sakurai, and Shigeo Matsubara. The effect of false-name bids in combinatorial auctions: New fraud in internet auctions. _Games and Economic Behavior_, 46(1):174-188, 2004.

Proofs of results

We provide complete proofs of all results from the main body of the paper.

### Omitted proofs from Section 2

Proof of Theorem 2.1.: Weakest-competitor VCG is incentive compatible for the same reason that VCG is incentive compatible: the minimization in the payment formula (the _pivot_ term) is independent of bidder \(i\)'s reported type. Concretely, if \(\alpha^{\prime}\) is the welfare-maximizing allocation when bidder \(i\) reports \(\theta_{i}^{\prime}\), bidder \(i\)'s utility from reporting \(\theta_{i}^{\prime}\) is \(\sum_{j=1}^{n}\theta_{j}[\alpha^{\prime}]-\min_{\widetilde{\theta}_{i}\in \Theta_{i}}(\max_{\alpha}\sum_{j\neq i}\theta_{j}[\alpha]+\widetilde{\theta}_{ i}[\alpha])\), which is maximized at \(\alpha^{\prime}=\alpha^{*}\) (which proves incentive compatibility). Furthermore, for each \(i\), \(\sum_{j=1}^{n}\theta_{j}[\alpha^{*}]-\min_{\widetilde{\theta}_{i}\in\Theta_{i }}(\max_{\alpha}\sum_{j\neq i}\theta_{j}[\alpha]+\widetilde{\theta}_{i}[\alpha ])\geq\sum_{j=1}^{n}\theta_{j}[\alpha^{*}]-\max_{\alpha}\sum_{j=1}^{n}\theta _{j}[\alpha]=0\), which proves individual rationality. The proof that weakest-competitor VCG is revenue optimal follows from the revenue equivalence theorem; the necessary ingredients may be found in the monograph by Vohra [51]. Let \(p_{i}(\bm{\theta})\) be the weakest-competitor VCG payment rule, and let \(p_{i}^{\prime}(\bm{\theta})\) be any other payment rule that also implements the efficient allocation rule. By revenue equivalence, for each \(i\), there exists \(h_{i}(\bm{\theta}_{-i})\) such that \(p_{i}^{\prime}(\theta_{i},\bm{\theta}_{-i})=p_{i}(\theta_{i},\bm{\theta}_{-i}) +h_{i}(\bm{\theta}_{-i})\). Suppose \(\bm{\theta}\) is a profile of types such that \(p_{i}^{\prime}\) generates strictly greater revenue than \(p_{i}\), that is, \(\sum_{i=1}^{n}p_{i}^{\prime}(\bm{\theta})>\sum_{i=1}^{n}p_{i}(\bm{\theta})\). Equivalently \(\sum_{i=1}^{n}p_{i}(\theta,\bm{\theta}_{-i})+h_{i}(\bm{\theta}_{-i})>\sum_{i= 1}^{n}p_{i}(\theta_{i},\bm{\theta}_{-i})\). Thus, there exists \(i^{*}\) such that \(h_{i^{*}}(\bm{\theta}_{-i^{*}})>0\). Now, let

\[\widetilde{\theta}_{i^{*}}=\operatorname*{argmin}_{\theta_{i}^{ \prime}\in\Theta_{i^{*}}}\max_{\alpha\in\Gamma}\sum_{j\neq i}\theta_{j}[ \alpha]+\theta_{i^{*}}^{\prime}[\alpha]\]

be the _weakest competitor_ with respect to \(\bm{\theta}_{-i^{*}}\). If weakest-competitor VCG is run on the type profile \((\widetilde{\theta}_{i^{*}},\bm{\theta}_{-i^{*}})\), the agent with type \(\widetilde{\theta}_{i^{*}}\) pays their value for the efficient allocation. In other words, the individual rationality constraint is binding for \(\widetilde{\theta}_{i^{*}}\). Since \(h_{i^{*}}(\bm{\theta}_{-i^{*}})>0\), \(p_{i}^{\prime}\) violates individual rationality, which completes the proof. 

### Omitted proofs from Section 3

Proof of Theorem 3.3.: Let \(i\) denote the index of the agent under consideration with type space \(\widetilde{\Theta}\). Let \(\theta\in\widetilde{\Theta}\) be a point such that there exists \(\theta^{\prime}\in\widetilde{\Theta}\) with \(\theta^{\prime}\prec\theta\). Then,

\[\max_{\alpha\in\Gamma}\sum_{j\neq i}\theta_{j}[\alpha]+\theta^{ \prime}[\alpha]<\max_{\alpha\in\Gamma}\sum_{j\neq i}\theta_{j}[\alpha]+\theta[\alpha]\]

for all \(\bm{\theta}_{-i}\in\Theta_{-i}\). So \(\theta\notin\overline{\mathsf{WC}}(\widetilde{\Theta})\), which shows that \(\overline{\mathsf{WC}}(\widetilde{\Theta})\subseteq\{\theta\in\widetilde{ \Theta}:\{\theta^{\prime}\in\widetilde{\Theta}:\theta^{\prime}\prec\theta\}=\emptyset\}\). To show the reverse containment, let \(\theta\in\widetilde{\Theta}\) be such that \(\{\theta^{\prime}\in\widetilde{\Theta}:\theta^{\prime}\prec\theta\}=\emptyset\). Consider any \(\bm{\theta}_{-i}=(\theta_{1},\ldots,\theta_{i-1},\theta_{i+1},\ldots,\theta_{ n})\) such that

\[\sum_{j\neq i}\theta_{j}[\alpha_{1}]+\theta[\alpha_{1}]=\sum_{j \neq i}\theta_{j}[\alpha_{2}]+\theta[\alpha_{2}]=\cdots=\sum_{j\neq i}\theta_{j }[\alpha_{|\Gamma|}]+\theta[\alpha_{|\Gamma|}].\]

The existence of such a \(\bm{\theta}_{-i}\) can be shown explicitly as follows. Let \(j\neq i\) be arbitrary. For all \(k\notin\{i,j\}\) set \(\theta_{k}=(0,\ldots,0)\). Without loss of generality relabel the allocations in \(\Gamma\) such that \(\theta[\alpha_{1}]\geq\theta[\alpha_{2}]\geq\cdots\geq\theta[\alpha_{|\Gamma|}]\). Then, set

\[\theta_{j}=\left(0,\theta[\alpha_{1}]-\theta[\alpha_{2}],\ldots, \theta[\alpha_{1}]-\theta[\alpha_{|\Gamma|}]\right)\in[0,H]^{\Gamma}.\]

Then, \(\theta\) minimizes

\[\max\left\{\sum_{j\neq i}\theta_{j}[\alpha_{1}]+\theta[\alpha_{1}],\sum_{j \neq i}\theta_{j}[\alpha_{2}]+\theta[\alpha_{2}],\ldots,\sum_{j\neq i}\theta_{ j}[\alpha_{|\Gamma|}]+\theta[\alpha_{|\Gamma|}]\right\}\]

since any \(\theta^{\prime}\) that attains a strictly smaller value must satisfy \(\theta^{\prime}\prec\theta\) (and no such \(\theta^{\prime}\) exists, by assumption). So \(\theta\in\overline{\mathsf{WC}}(\widetilde{\Theta})\), which proves the reverse containment. The characterizations of \(\mathsf{WC}\) and \(\mathsf{WCH}\) follow immediately.

Proof of Theorem 3.4.: \(\mathcal{M}\) is incentive compatible for the exact same reason weakest-competitor VCG is incentive compatible (Theorem 2.1). Individual rationality is an immediate consequence of how \(\mathcal{M}\) is defined: all agents with potential individual-rationality violations (those not in \(\mathcal{I}\)) do not participate and receive zero utility. 

Proof of Theorem 3.5.: Let \(\theta_{i}\) denote the true type of agent \(i\) and let \(\boldsymbol{\theta}_{-i}=(\theta_{1},\ldots,\theta_{i-1},\theta_{i+1},\ldots, \theta_{n})\) denote the reported types of the other agents. Suppose \(\theta_{i}\notin\mathsf{WCH}(\widehat{\Theta}_{i})\). Then, there exists \(\widetilde{\theta}_{i}\in\overline{\mathsf{W}\mathsf{C}}(\widehat{\Theta}_{i})\) such that \(\widetilde{\theta}_{i}\succ\theta_{i}\), and there exists \(\boldsymbol{\theta}_{-i}\) such that \(\widetilde{\theta}_{i}\in\operatorname*{argmin}_{\widetilde{\theta}_{i}\in \widehat{\Theta}_{i}}\max_{\alpha\in\Gamma}\sum_{j\neq i}\theta_{j}[\alpha]+ \widehat{\theta}_{i}[\alpha]\) is a weakest competitor relative to \(\boldsymbol{\theta}_{-i}\) (the existence of \(\boldsymbol{\theta}_{-i}\) follows from the same reasoning as in the proof of Theorem 3.3). As \(\widetilde{\theta}_{i}\succ\theta_{i}\), agent \(i\)'s overall utility will be negative. The utility is unchanged and remains negative if \(\widetilde{\theta}_{i}\) is replaced by \(\theta_{i}^{*}\in\mathsf{WIC}(\widehat{\Theta}_{i})\) that is also a weakest competitor relative to \(\boldsymbol{\theta}_{-i}\). So we have shown there exists \(\boldsymbol{\theta}_{-i}\) such that \(i\notin\mathcal{I}\).

Conversely suppose \(\theta_{i}\in\mathsf{WCH}(\widehat{\Theta}_{i})\). Then, there exists \(\theta_{i}^{\prime}\in\mathsf{WC}(\widehat{\Theta}_{i})\) such that \(\theta_{i}\succeq\theta_{i}^{\prime}\). Let \(\boldsymbol{\theta}_{-i}\) be arbitrary. Agent \(i\)'s utility is \(\sum_{j=1}^{n}\theta_{j}[\alpha^{*}]-\min_{\widetilde{\theta}_{i}\in\mathsf{WC }(\widehat{\Theta}_{i})}(\max_{\alpha}\sum_{j\neq i}\theta_{j}[\alpha]+ \widetilde{\theta}_{i}[\alpha])\geq\sum_{j=1}^{n}\theta_{j}[\alpha^{*}]-(\max _{\alpha}\sum_{j\neq i}\theta_{j}[\alpha]+\theta_{i}[\alpha])=0\), so \(i\in\mathcal{I}\), as desired. 

Proof of Theorem 3.6.: The weakest competitor in \(\widehat{\Theta}_{i}\) relative to \(\boldsymbol{\theta}_{-i}\) is the solution \(\widetilde{\theta}_{i}\in\mathbb{R}^{\Gamma}\) to the linear program

\[\min\left\{\gamma\ :\ \begin{array}{l}\widetilde{\theta}_{i}[\alpha]+\sum_{j \neq i}\theta_{j}[\alpha]\leq\gamma\ \ \forall\alpha\in\Gamma,\\ \widetilde{\theta}_{i}\in\widehat{\Theta}_{i},\gamma\geq 0\end{array}\right\}\]

with \(|\Gamma|+1\) variables and \(|\Gamma|+size(\widehat{\Theta}_{i})\) constraints. Generating the first set of constraints requires computing \(\sum_{j\neq i}\theta_{j}[\alpha]\) for each \(\alpha\in\Gamma\), which takes time \(\leq n|\Gamma|\).

Checking membership of \(\theta_{i}\) in \(\mathsf{WCH}(\widehat{\Theta}_{i})\) is equivalent to checking feasibility of a polytope

\[\theta_{i}\in\mathsf{WCH}(\widehat{\Theta}_{i})\ \Longleftrightarrow\ \left\{\widetilde{\theta}_{i}:\widetilde{\theta}_{i}\in\widehat{\Theta}_{i}, \theta_{i}[\alpha]\geq\widetilde{\theta}_{i}[\alpha]\ \forall\alpha\in\Gamma\right\}\neq\emptyset\]

defined by \(size(\widehat{\Theta}_{i})+|\Gamma|\) constraints. 

More generally, the complexity of the above two mathematical programs is determined by the complexity of constraints needed to define \(\widetilde{\Theta}_{i}\): for example, if \(\widetilde{\Theta}_{i}\) is a convex set then they are convex programs. Naturally, a major caveat of this brief discussion on computational complexity is that \(|\Gamma|\) can be very large (for example, \(|\Gamma|\) is exponential in combinatorial auctions).

### Omitted proofs from Section 4

Proof of Lemma 4.1.: Let \(p_{i}\) denote the payment collected from agent \(i\), where \(i\) is an agent such that \(\theta_{i}\in\widehat{\Theta}_{i}\). Let \(\theta_{i}^{*}\) be the weakest competitor in \(\widehat{\Theta}_{i}\) with respect to \(\boldsymbol{\theta}_{-i}\). The utility for agent \(i\) under \(\mathcal{M}\) is

\[\theta_{i}[\alpha_{\mathsf{opt}}]-p_{i} =\sum_{j=1}^{n}\theta_{j}[\alpha_{\mathsf{opt}}]-\min_{\widehat{ \theta}_{i}\in\widehat{\Theta}_{i}}\left(\max_{\alpha\in\Gamma}\sum_{j\neq i} \theta_{j}[\alpha]+\widehat{\theta}_{i}[\alpha]\right)\] \[=\sum_{j=1}^{n}\theta_{j}[\alpha_{\mathsf{opt}}]-\left(\max_{ \alpha\in\Gamma}\sum_{j\neq i}\theta_{j}[\alpha]+\theta_{i}^{*}[\alpha]\right)\] \[\leq\sum_{j=1}^{n}\theta_{j}[\alpha_{\mathsf{opt}}]-\left(\sum_ {j\neq i}\theta_{j}[\alpha_{\mathsf{opt}}]+\theta_{i}^{*}[\alpha_{\mathsf{opt}}]\right)\] \[=\theta_{i}[\alpha_{\mathsf{opt}}]-\theta_{i}^{*}[\alpha_{\mathsf{ opt}}]\] \[\leq\max_{\widehat{\theta}_{i}\in\mathsf{WC}(\widehat{\Theta}_{i} )}\bigl{\|}\boldsymbol{\theta}_{i}-\widehat{\theta}_{i}\bigr{\|}_{\infty}=d_{H}( \theta_{i},\mathsf{WC}(\widehat{\Theta}_{i})),\]as desired. 

Proof of Theorem 4.4.: For each agent \(i\), let \(k_{i}^{*}\) be the smallest \(k\in\{0,\ldots,K_{i}\}\) such that \(\theta_{i}\in\mathsf{WCH}(\mathcal{B}(\widehat{\Theta}_{i},\zeta_{i}+2^{k^{*}} \lambda_{i}))\). Equivalently, \(k_{i}^{*}\) is the minimal \(k\) such that \(\gamma_{i}^{V}\leq\zeta_{i}+2^{k}\lambda_{i}\). So \(k_{i}^{*}=\lceil\log_{2}^{+}((\gamma_{i}^{V}-\zeta_{i})/\lambda_{i})\rceil\). We have, using the fact that \(\theta_{i}\in\widehat{\Theta}_{i}\implies i\in\mathcal{I}\) (Theorem 3.5),

\[\mathbb{E}[\text{welfare}]=\mathbb{E}\bigg{[}\sum_{i=1}^{n}\theta_{i}[\alpha_ {\mathsf{opt}}]\cdot\mathbf{1}(i\in\mathcal{I})\bigg{]}\geq\mathbb{E}\bigg{[} \sum_{i=1}^{n}\theta_{i}[\alpha_{\mathsf{opt}}]\cdot\mathbf{1}(\theta_{i}\in \widehat{\Theta}_{i})\bigg{]}=\sum_{i=1}^{n}\theta_{i}[\alpha_{\mathsf{opt}}] \cdot\Pr(\theta_{i}\in\widehat{\Theta}_{i})\]

and

\[\Pr(\theta_{i}\in\widehat{\Theta}_{i})=\Pr(k_{i}\geq k_{i}^{*})=1-\Pr(k_{i}< k_{i}^{*})=1-\frac{k_{i}^{*}}{1+K_{i}}=1-\frac{\lceil\log_{2}^{+}((\gamma_{i}^{V} -\zeta_{i})/\lambda_{i})\rceil}{1+\lceil\log_{2}((H-\zeta_{i})/\lambda_{i}) \rceil}.\]

Therefore

\[\mathbb{E}[\text{welfare}]\geq\left(1-\max_{i}\frac{\lceil\log_{2}^{+}(( \gamma_{i}^{V}-\zeta_{i})/\lambda_{i})\rceil}{1+\lceil\log_{2}((H-\zeta_{i})/ \lambda_{i})\rceil}\right)\cdot\mathsf{OPT}.\]

If all predictions are valid, we get \(\mathbb{E}[\text{welfare}]=\mathsf{OPT}\). The other term of the bound follows from \(\Pr(\theta_{i}\in\widehat{\Theta}_{i})\geq\Pr(k_{i}=k_{i}^{*})=\frac{1}{1+K_{ i}}\). 

Proof of Theorem 4.5.: Let \(k_{i}^{*}\) be defined as in the proof of Theorem 4.4. We compute expected revenue by computing \(\mathbb{E}[p_{i}]\) for each agent \(i\). Let \(S=\{i:\theta_{i}\in\widehat{\Theta}_{i}\}\) be the (random) set of agents with valid predictions post expansion. We have

\[\mathbb{E}[p_{i}]\geq\mathbb{E}[p_{i}\mid k_{i}=k_{i}^{*}]\cdot\Pr(k_{i}=k_{i }^{*})=\frac{1}{1+K_{i}}\cdot\mathbb{E}[p_{i}\mid k_{i}=k_{i}^{*}].\]

Now \(k_{i}=k_{i}^{*}\implies i\in S\), so we may apply the payment bound of Lemma 4.1:

\[\mathbb{E}[p_{i}\mid k_{i}=k_{i}^{*}] \geq\mathbb{E}\left[\theta_{i}[\alpha_{\mathsf{opt}}]-d_{H}( \theta_{i},\mathsf{WC}(\mathcal{B}(\widetilde{\Theta}_{i},\zeta_{i}+2^{k_{i}^ {*}}\lambda_{i})))\mid k_{i}=k_{i}^{*}\right]\] \[=\theta_{i}[\alpha_{\mathsf{opt}}]-d_{H}(\theta_{i},\mathsf{WC}( \mathcal{B}(\widetilde{\Theta}_{i},\zeta_{i}+2^{k_{i}^{*}}\lambda_{i}))).\]

Next, we bound \(d_{H}(\theta_{i},\mathsf{WC}(\mathcal{B}(\widetilde{\Theta}_{i},\zeta_{i}+2^{ k_{i}^{*}}\lambda_{i})))\). Let \(\widetilde{\theta}_{i}\in\mathsf{WC}(\mathcal{B}(\widetilde{\Theta}_{i},\zeta_ {i}+2^{k_{i}^{*}}\lambda_{i}))\) be arbitrary. By Lemma A.1 (the statement and proof are at the end of Appendix A.3), \(\widetilde{\theta}_{i}\in\mathsf{WC}(\mathcal{B}(\mathsf{WC}(\widetilde{ \Theta}_{i}),\zeta_{i}+2^{k_{i}^{*}}\lambda_{i}))\), so there exists \(\theta_{i}^{\prime}\in\mathsf{WC}(\widetilde{\Theta}_{i})\) such that \(\|\widetilde{\theta}_{i}-\theta_{i}^{\prime}\|_{\infty}\leq\zeta_{i}+2^{k_{i}^ {*}}\lambda\). Moreover, \(\|\theta_{i}-\theta_{i}^{\prime}\|_{\infty}\leq\gamma_{i}^{A}\) by definition of \(\gamma_{i}^{A}\). The triangle inequality therefore yields

\[\big{\|}\theta_{i}-\widetilde{\theta}_{i}\big{\|}_{\infty}\leq\big{\|} \widetilde{\theta}_{i}-\theta_{i}^{\prime}\big{\|}_{\infty}+\big{\|}\theta_{i} -\theta_{i}^{\prime}\big{\|}_{\infty}\leq\gamma_{i}^{A}+\zeta_{i}+2^{k_{i}^{*} }\lambda_{i},\]

so, as \(\widetilde{\theta}_{i}\in\mathsf{WC}(\mathcal{B}(\widetilde{\Theta}_{i},\zeta_ {i}+2^{k_{i}^{*}}\lambda_{i}))\) was arbitrary, \(d_{H}(\theta_{i},\mathsf{WC}(\mathcal{B}(\widetilde{\Theta}_{i},\zeta_{i}+2^{k _{i}^{*}}\lambda_{i}))\leq\gamma_{i}^{A}+\zeta_{i}+2^{k_{i}^{*}}\lambda_{i}\). Now, we claim \(2^{k_{i}^{*}}\lambda_{i}\leq\rho_{i}\). To show this, consider two cases. If \(\zeta_{i}+\lambda_{i}\geq\gamma_{i}^{V}\), that is, \(k_{i}^{*}=0\), then \(2^{k_{i}^{*}}\lambda_{i}=\lambda_{i}=\rho_{i}\). If \(\zeta_{i}+\lambda_{i}<\gamma_{i}^{V}\), then \(k_{i}^{*}>0\) and we have \(\zeta_{i}+2^{k_{i}^{*}-1}\lambda_{i}<\gamma_{i}^{V}\leq\zeta+2^{k_{i}^{*}} \lambda_{i}\), so \(2^{k_{i}^{*}}\lambda<2(\gamma_{i}^{V}-\zeta_{i})=\rho_{i}\). So

\[d_{H}(\theta_{i},\mathsf{WC}(\mathcal{B}(\widetilde{\Theta}_{i},\zeta_{i}+2^{k_{i} ^{*}}\lambda_{i})))\leq\gamma_{i}^{A}+\zeta_{i}+\rho_{i}.\]

Finally, we have

\[\mathbb{E}[p_{i}]\geq\frac{1}{1+K_{i}}\left(\theta_{i}[\alpha_{\mathsf{opt}}]-( \gamma_{i}^{A}+\zeta_{i}+\rho_{i})\right),\]

so

\[\mathbb{E}[\text{revenue}]=\mathbb{E}\bigg{[}\sum_{i=1}^{n}p_{i} \bigg{]}=\sum_{i=1}^{n}\mathbb{E}[p_{i}] \geq\sum_{i=1}^{n}\frac{1}{1+K_{i}}\left(\theta_{i}[\alpha_{\mathsf{ opt}}]-(\gamma_{i}^{A}+\zeta_{i}+\rho_{i})\right)\] \[\geq\frac{1}{1+\lceil\max_{i}\log_{2}(\frac{H-\zeta_{i}}{\lambda_{i} })\rceil}\left(\mathsf{OPT}-\sum_{i=1}^{n}(\gamma_{i}^{A}+\zeta_{i}+\rho_{i}) \right),\]

as desired.

Proof of Theorem 4.6.: Let \(k_{i}^{*}\) be defined as in Theorems 4.4 and 4.5. We bound \(\mathbb{E}[p_{i}]\) similarly to the approach in the proof of Theorem 4.5, but account for all possible values of \(k_{i}\) (rather than only conditioning on \(k_{i}=k_{i}^{*}\)). If \(k_{i}<k_{i}^{*}\), then agent \(i\) does not participate and pays nothing. We have

\[\mathbb{E}[p_{i}]=\sum_{k=k_{i}^{*}}^{K_{i}}\mathbb{E}[p_{i}|k_{i} =k]\cdot\Pr(k_{i}=k) \geq\frac{1}{1+K_{i}}\sum_{k=k_{i}^{*}}^{K_{i}}\left(\theta_{i}[ \alpha_{\mathsf{opt}}]-d_{H}(\theta_{i},\mathsf{WC}(\mathcal{B}(\widetilde{ \Theta}_{i},\zeta_{i}+2^{k}\cdot\lambda_{i})))\right)\] \[\geq\frac{1}{1+K_{i}}\sum_{k=k_{i}^{*}}^{K_{i}}\left(\theta_{i}[ \alpha_{\mathsf{opt}}]-(\gamma_{i}^{A}+\zeta_{i}+2^{k}\cdot\lambda_{i})\right)\] \[=\left(1-\frac{k_{i}^{*}}{1+K_{i}}\right)\left(\theta_{i}[\alpha_ {\mathsf{opt}}]-\gamma_{i}^{A}-\zeta_{i}\right)-\frac{\lambda_{i}}{1+K_{i}} \sum_{k=k_{i}^{*}}^{K_{i}}2^{k}\] \[\geq\left(1-\frac{k_{i}^{*}}{1+K_{i}}\right)\left(\theta_{i}[ \alpha_{\mathsf{opt}}]-\gamma_{i}^{A}-\zeta_{i}\right)-\frac{\lambda 2^{K_{i}+1}}{1+K_{i}}\]

where in the second inequality we have used the the bound \(d_{H}(\theta_{i},\mathsf{WC}(\mathcal{B}(\widetilde{\Theta}_{i},\zeta_{i}+2^{ k}\lambda_{i})))\leq\gamma_{i}^{A}+\zeta_{i}+2^{k}\lambda_{i}\), which was derived in the proof of Theorem 4.5. We have \(2^{K_{i}+1}\leq\lambda_{i}(4(H-\zeta_{i})/\lambda_{i})\leq 4H\). Substituting and summing over agents yields the desired revenue bound. 

**Lemma A.1**.: \(\mathsf{WC}(\mathcal{B}(\widetilde{\Theta},r))=\mathsf{WC}(\mathcal{B}( \mathsf{WC}(\widetilde{\Theta}),r))\)_._

Proof.: We first prove the forwards containment. For the sake of contradiction suppose there exists \(\widetilde{\theta}\in\mathsf{WC}(\mathcal{B}(\widetilde{\Theta},r))\) such that \(\widetilde{\theta}\notin\mathsf{WC}(\mathcal{B}(\mathsf{WC}(\widetilde{\Theta} ),r))\). Then, there exists \(\theta^{\prime}\in\mathcal{B}(\mathsf{WC}(\widetilde{\Theta}),r)\) such that \(\theta^{\prime}\preccurlyeq\widetilde{\theta}\). But

\[\mathsf{WC}(\widetilde{\Theta})\subseteq\widetilde{\Theta}\implies\mathcal{B }(\mathsf{WC}(\widetilde{\Theta}),r)\subseteq\mathcal{B}(\widetilde{\Theta},r),\]

so \(\theta^{\prime}\in\mathcal{B}(\widetilde{\Theta},r)\) and \(\theta^{\prime}\preccurlyeq\widetilde{\theta}\) which contradicts the assumption that \(\widetilde{\theta}\in\mathsf{WC}(\mathcal{B}(\widetilde{\Theta},r))\).

We now prove the reverse containment. For the sake of contradiction suppose there exists \(\widetilde{\theta}\in\mathsf{WC}(\mathcal{B}(\mathsf{WC}(\widetilde{\Theta} ),r))\) such that \(\widetilde{\theta}\notin\mathsf{WC}(\mathcal{B}(\widetilde{\Theta},r))\). Then, there exists \(\theta^{\prime}\in\mathcal{B}(\widetilde{\Theta},r)\) such that \(\theta^{\prime}\preccurlyeq\widetilde{\theta}\). Furthermore, if \(\theta^{\prime}\notin\mathsf{WC}(\mathcal{B}(\widetilde{\Theta},r))\), there exists \(\theta^{\prime\prime}\in\mathsf{WC}(\mathcal{B}(\widetilde{\Theta},r))\) such that \(\theta^{\prime\prime}\preccurlyeq\theta^{\prime}\preccurlyeq\theta^{\prime}\) (if \(\theta^{\prime}\in\mathsf{WC}(\mathcal{B}(\widetilde{\Theta},r))\), set \(\theta^{\prime\prime}=\theta^{\prime}\)). From the forward inclusion, we have

\[\mathsf{WC}(\mathcal{B}(\widetilde{\Theta},r))\subseteq\mathsf{WC}(\mathcal{B }(\mathsf{WC}(\widetilde{\Theta}),r))\subseteq\mathcal{B}(\mathsf{WC}( \widetilde{\Theta}),r),\]

so \(\theta^{\prime\prime}\in\mathcal{B}(\mathsf{WC}(\widetilde{\Theta}),r)\) and \(\theta^{\prime\prime}\preccurlyeq\widetilde{\theta}\) which contradicts the assumption that \(\widetilde{\theta}\in\mathsf{WC}(\mathcal{B}(\mathsf{WC}(\widetilde{\Theta} ),r))\). 

### Omitted proofs from Section 5

To prove Theorem 5.1 we need the following more direct bound on \(p_{i}\) in terms of the weakest competitor's value.

**Lemma A.2**.: _Run \(\mathcal{M}\) with \(\widehat{\Theta}_{i}\). If \(i\) is such that \(\theta_{i}\in\mathsf{WCH}(\widehat{\Theta}_{i})\), then \(p_{i}\geq\widetilde{\theta}_{i}[\alpha_{\mathsf{opt}}]\) where \(\widetilde{\theta}_{i}\) is the weakest competitor in \(\widehat{\Theta}_{i}\) relative to \(\boldsymbol{\theta}_{-i}\)._

Proof of Lemma a.2.: Truncating the proof of Lemma 4.1 yields the desired statement. 

Proof of Theorem 5.1.: We have \(\mathbb{E}[\text{welfare}]\geq\sum_{i=1}^{n}\theta_{i}[\alpha_{\mathsf{opt}}] \cdot\Pr(\theta_{i}\in\widehat{\Theta}_{i})\geq\sum_{i=1}^{n}\theta_{i}[ \alpha_{\mathsf{opt}}]\cdot\Pr(\ell_{i}=\log_{2}H)=\frac{1}{\log_{2}H}\cdot \mathsf{OPT}\) (since \(\theta_{i}\succeq\widetilde{\theta}_{i}(\log_{2}H,\ldots,\log_{2}H)\)). The proof of the revenue guarantee relies on the following key claim: for each agent \(i\), there exists \(\ell_{i,1}^{*},\ldots,\ell_{i,k}^{*}\in\{1,\ldots,\log_{2}H\}\) such that \(\widetilde{\theta}(\ell_{i,1}^{*},\ldots,\ell_{i,k}^{*})\succeq\frac{1}{2} \theta_{i}\). To show this, let \(\theta_{i}^{j}\) denote the projection of \(\theta_{i}\) onto \(u_{j}\), so \(\theta_{i}=\sum_{j=1}^{k}\theta_{i}^{j}\) since \(\{u_{i,1},\ldots,u_{i,k}\}\) is an orthonormal basis. Let \(\ell_{i,j}^{*}=\min\{\ell:\theta_{i}^{j}\succeq z_{i,j}^{\ell}\}\). Then, \(z_{i,j}^{\ell_{i,j}^{*}}\succeq\frac{1}{2}\theta_{i}^{j}\), so

\[\widetilde{\theta}(\ell_{i,1}^{*},\ldots,\ell_{i,k}^{*})=\sum_{j=1}^{k}z_{i,j}^{ \ell_{i,j}^{*}}\succeq\sum_{j=1}^{k}\frac{1}{2}\theta_{i}^{j}=\frac{1}{2} \theta_{i}.\]We now bound the expected payment of agent \(i\) as in the previous results. Let \(\ell_{i}^{*}=\min_{j}\ell_{i,j}^{*}\). We have

\[\mathbb{E}[p_{i}] \geq\mathbb{E}\big{[}p_{i}\mid(\ell_{i,1},\ldots,\ell_{i,k})=( \ell_{i,1}^{*},\ldots,\ell_{i,k}^{*})\big{]}\cdot\Pr\big{(}(\ell_{i,1},\ldots, \ell_{i,k})=(\ell_{i,1}^{*},\ldots,\ell_{i,k}^{*})\big{)}\] \[=\frac{1}{|W_{\ell_{i}^{*}}|\log_{2}H}\cdot\mathbb{E}\big{[}p_{i} \mid(\ell_{i,1},\ldots,\ell_{i,k})=(\ell_{i,1}^{*},\ldots,\ell_{i,k}^{*})\big{]}\] \[\geq\frac{1}{\log_{2}H((\log_{2}H)^{k}-(\log_{2}H-1)^{k})}\cdot \mathbb{E}\big{[}p_{i}\mid(\ell_{i,1},\ldots,\ell_{i,k})=(\ell_{i,1}^{*},\ldots,\ell_{i,k}^{*})\big{]}\] \[\geq\frac{1}{k(\log_{2}H)^{k}}\cdot\mathbb{E}\big{[}p_{i}\mid( \ell_{i,1},\ldots,\ell_{i,k})=(\ell_{i,1}^{*},\ldots,\ell_{i,k}^{*})\big{]}\]

since the probability of obtaining the correct weakest competitor \(\widetilde{\theta}(\ell_{i,1}^{*},\ldots,\ell_{i,k}^{*})\) can be written as the probability of drawing the correct "level" \(\ell_{i}^{*}\in\{1,\ldots,\log_{2}H\}\) times the probability of drawing the correct weakest competitor within the correct level \(W_{\ell_{i}^{*}}\). We bound the conditional expectation with Lemma A.2,

\[\mathbb{E}\big{[}p_{i}\mid(\ell_{i,1},\ldots,\ell_{i,k})=(\ell_{i,1}^{*}, \ldots,\ell_{i,k}^{*})\big{]}\geq\widetilde{\theta}_{i}(\ell_{i,1}^{*},\ldots,\ell_{i,k}^{*})[\alpha_{\mathsf{opt}}]\geq\frac{1}{2}\cdot\theta_{i}[\alpha_ {\mathsf{opt}}].\]

Finally,

\[\mathbb{E}[\text{revenue}]=\sum_{i=1}^{n}\mathbb{E}[p_{i}]\geq\frac{1}{2k( \log_{2}H)^{k}}\cdot\sum_{i=1}^{n}\theta_{i}[\alpha_{\mathsf{opt}}]=\frac{1}{ 2k(\log_{2}H)^{k}}\cdot\mathsf{OPT},\]

as desired. 

## Appendix B Consistency and robustness

In this section we show that it is trivial to obtain high consistency and robustness ratios with an otherwise undesirable mechanism that yields poor revenue even if predictions are nearly perfect. We also discuss the consistency and robustness of our main mechanism \(\mathcal{M}_{\zeta,\lambda}\).

For \(S\subseteq\{1,\ldots,n\}\), let \(\mathsf{OPT}_{S}=\sum_{i\in S}\theta_{i}[\alpha_{\mathsf{opt}}]\) be the welfare generated by the efficient allocation restricted to agents in \(S\). Let \(\mathsf{VCG}(S)\) denote the revenue of the vanilla VCG mechanism when run among the agents in \(S\). Let \(\mathsf{VCG}(\beta)=\mathbb{E}[\mathsf{VCG}(S)]\) where \(S\subseteq\{1,\ldots,n\}\) is sampled by including each agent in \(S\) independently with probability \(\beta\). In general, \(S\subseteq T\not\Rightarrow\mathsf{VCG}(S)\leq\mathsf{VCG}(T)\)[44], so \(\mathsf{VCG}(\beta)\) need not be increasing in \(\beta\), but there are various sufficient conditions when revenue monotonicity does hold [6, 29, 54].

### First approach: trust predictions completely

The first basic instantiation of our meta mechanism \(\mathcal{M}\) is the following: the mechanism designer simply sets \(\widehat{\Theta}_{i}=\mathsf{WCH}(\widehat{\Theta}_{i})\) for all \(i\). Let \(V=\{i:\theta_{i}\in\mathsf{WCH}(\widehat{\Theta}_{i})\}=\{i:\gamma_{i}^{V}=0\}\) denote the set of agents with valid predictions. The welfare of this mechanism is simply \(\mathsf{OPT}_{V}\) and its revenue is bounded by Lemma 4.1. If all predictions are valid and perfect, that is, \(\mathsf{WC}(\widehat{\Theta}_{i})=\{\theta_{i}\}\) for all \(i\), both welfare and revenue are equal to \(\mathsf{OPT}\). However, if all predictions are such that \(\theta_{i}\notin\mathsf{WCH}(\widehat{\Theta}_{i})\), both welfare and revenue potentially drop to \(0\). So this mechanism is \((1,1)\)-consistent and \((0,0)\)-robust.

### Second approach: discard predictions randomly

The issue with the above mechanism is that if all predictions are invalid, it generates no welfare and no revenue. We show how randomization can quell that issue. One trivial solution is to discard all predictions with probability \(\beta\), and trust all predictions completely with probability \((1-\beta)\). That is, with probability \(\beta\) set \((\widehat{\Theta}_{1},\ldots,\widehat{\Theta}_{n})=(\Theta,\ldots,\Theta)\) and with probability \(1-\beta\) set \((\widehat{\Theta}_{1},\ldots,\widehat{\Theta}_{n})=(\mathsf{WCH}(\widehat{ \Theta}_{1}),\ldots,\mathsf{WCH}(\widehat{\Theta}_{n}))\), and then run \(\mathcal{M}\). This mechanism achieves strong consistency and robustness ratios. Let \(V=\{i:\theta_{i}\in\mathsf{WCH}(\widehat{\Theta}_{i})\}\) be the set of valid predictions. From Lemma 4.1, we have \(\mathbb{E}[\text{welfare}]=\beta\cdot\mathsf{OPT}+(1-\beta)\cdot\mathsf{OPT} _{V}\) and \(\mathbb{E}[\text{revenue}]\geq\mathbb{E}[\text{revenue}]\).

\(\beta\cdot\mathsf{VCG}(1)+(1-\beta)\cdot\left(\mathsf{OPT}_{V}-\sum_{i\in V}\gamma_{i }^{A}\right)\), and thus obtain \((1,1-\beta)\)-consistency and \((\beta,\beta)\)-robustness.

This approach suffers from a major issue: its revenue drops drastically the moment predictions are invalid (\(\gamma_{i}^{V}>0\)). In particular, if predictions are highly accurate but very slightly invalid (such as the blue prediction in Figure 1), this approach completely misses out on any payments from such agents and drops to the revenue of VCG (which can be drastically smaller than \(\mathsf{OPT}\)). But, a tiny expansion of these predictions would have sufficed to increase revenue significantly and perform competitively with \(\mathsf{OPT}\). One simple approach is to set \(\widehat{\Theta}_{i}\) to be an expansion of \(\widehat{\Theta}_{i}\) by a parameter \(\eta_{i}\) with some probability, and discard the prediction with complementary probability. If \(\gamma_{i}^{V}\leq\eta_{i}\) for all \(i\), then such a mechanism would perform well. The main issue with such an approach is that the moment \(\gamma_{i}^{V}>\eta_{i}\), our expansion by \(\eta_{i}\) fails to capture the true type \(\theta_{i}\) and the performance drastically drops. Our main mechanism \(\mathcal{M}_{\zeta,\lambda}\) essentially selects the \(\eta_{i}\) randomly from a suitable discretization of the ambient type space to be able to capture \(\theta_{i}\) with reasonable probability.

### Consistency and robustness of \(\mathcal{M}_{\zeta,\lambda}\)

In this discussion we assume constant \(\zeta,\lambda>0\). Assuming revenue monotonicity, since \(\theta_{i}\in\widehat{\Theta}_{i}\) with probability at least \(\Omega(1/\log H)\), the revenue of our mechanism is never worse than \(\mathsf{VCG}(\Omega(1/\log H))\). Thus, in the language of algorithms-with-predictions, \(\mathcal{M}_{\zeta,\lambda}\) is \((1,\Omega(1/\log H))\)-consistent and, assuming revenue monotonicity, \((\Omega(1/\log H),\mathsf{VCG}(\Omega(1/\log H)))/\mathsf{VCG}(1))\)-robust. If VCG revenue is submodular, the robustness ratio is \(\geq\Omega(1/\log H)\) (but in general revenue can shrink by more than this ratio [12]). In contrast to the trivial approach that either trusted the side information completely or discarded predictions completely, our random expansion approach does not suffer from large discontinuous drops in welfare nor revenue.

Furthermore, the previous approaches had no way of gracefully dealing with invalid prediction sets. In particular, if \(\widehat{\Theta}_{i}\) is an invalid prediction, even if a tiny expansion of \(\widetilde{\Theta}_{i}\) would have captured \(\theta_{i}\) (such as the blue set in Figure 1), we gave up on getting any meaningful revenue from agent \(i\). When all predictions were invalid (that is, \(\gamma_{i}^{V}>0\) for all \(i\)), our guarantee dropped to \(\beta\cdot\mathsf{VCG}(1)\). The random expansion of predictions remedies these issues. Its revenue is nearly \(\log H\)-competitive with \(\mathsf{OPT}\) as long as \(\sum_{i}\gamma_{i}^{A}+2\gamma_{i}^{V}\) is not too large. In particular, if we have high-accuracy but invalid predictions that are just a small expansion away from capturing \(\theta_{i}\), the mechanism in this section is nearly \(\log H\)-competitive with \(\mathsf{OPT}\) whereas the mechanism from the previous section is compared to vanilla VCG due to invalid predictions.

## Appendix C An expressive language for side information

A _side information structure_ is a probability space \((\Theta,\mathcal{F},\mu)\) where the ambient type space \(\Theta\) is the sample space, \(\mathcal{F}\) is a \(\sigma\)-algebra on \(\Theta\), and \(\mu\) is a probability measure. (We suppress the agent index for brevity.)

\(\mathcal{F}\) induces a partition of \(\Theta\) into equivalence classes where \(\theta\equiv\theta^{\prime}\) if \(\mathbf{1}(\theta\in A)=\mathbf{1}(\theta^{\prime}\in A)\) for all \(A\in\mathcal{F}\) (so the side-information structure does not distinguish between \(\theta\) and \(\theta^{\prime}\)). Let \(A_{\theta}=\{\theta^{\prime}:\theta\equiv\theta^{\prime}\}\in\mathcal{F}\) be the equivalence class of \(\theta\). In this way the \(\sigma\)-algebra determines the granularity of knowledge being conveyed by the side information structure, and the probability measure \(\mu:\mathcal{F}\rightarrow[0,1]\) establishes uncertainty over this knowledge.

We define invalidity and inaccuracy of a side information structure in the natural way. Define random variables \(X_{i}^{V},X_{i}^{A}:\Theta\rightarrow\mathbb{R}_{\geq 0}\) by

\[X_{i}^{V}(\theta)=\gamma_{i}^{V}(A_{\theta})=d(\theta_{i},\mathsf{WCH}(A_{\theta }))\]

and

\[X_{i}^{A}(\theta)=\gamma_{i}^{A}(A_{\theta})=d_{H}(\theta_{i},\mathsf{WC}(A_{ \theta})).\]

\(X_{i}^{V}\) and \(X_{i}^{A}\) are \(\mathcal{F}\)-measurable since they are (by definition) constant on all atoms of \(\mathcal{F}\) (sets \(A\in\mathcal{F}\) such that no nonempty \(B\subsetneq A\) is in \(\mathcal{F}\)). The invalidity/inaccuracy distributions on \(\mathbb{R}_{\geq 0}\) are given by

\[\Pr(a\leq X_{i}^{V}\leq b)=\mu(\{\theta\in\Theta:a\leq\gamma_{i}^{V}(A_{ \theta})\leq b\})=\mu(\cup\{A_{\theta}:a\leq\gamma_{i}^{V}(A_{\theta})\leq b\}).\]The generalized version of \(M_{\zeta,\lambda}\) that receives as input a side information structure for each agent \(i\) given by \((\Theta_{i},\mathcal{F}_{i},\mu_{i})\) works as follows. It samples \(\widetilde{\theta}_{i}\sim\Theta_{i}\) according to \((\mathcal{F}_{i},\mu_{i})\) and draws \(k_{i}\sim_{\text{unif.}}\{0,\ldots,K_{i}\}\) where \(K_{i}\) is defined as before. It then sets

\[\widehat{\Theta}_{i}=\mathcal{B}\left(A_{\widetilde{\theta}_{i}},\zeta_{i}+2^ {k_{i}}\lambda_{i}\right).\]

Executing the same analysis in the proofs of Theorems 4.4, 4.5, and 4.6 for a fixed \(\widetilde{\theta}_{i}\), then taking expectation over the draw of \(\widetilde{\theta}_{i}\) yields similar guarantees with \(\gamma_{i}^{V}\) and \(\gamma_{i}^{A}\) replaced by \(\mathbb{E}[X_{i}^{V}]\) and \(\mathbb{E}[X_{i}^{A}]\), respectively. To show this, we loosen the bounds in Theorems 4.4, 4.5, and 4.6 slightly to make the multiplicative terms convex. As \(X_{i}^{V}\geq 0\), we have

\[\left\lceil\log_{2}^{+}\left(\frac{X_{i}^{V}-\zeta_{i}}{\lambda_{i}}\right) \right\rceil=\left\lceil\max\left(0,\log_{2}\left(\frac{X_{i}^{V}-\zeta_{i}}{ \lambda_{i}}\right)\right)\right\rceil\leq 1+\log_{2}\left(1+\frac{X_{i}^{V}- \zeta_{i}}{\lambda_{i}}\right)\]

and therefore

\[\mathbb{E}\left[1-\frac{\lceil\log_{2}^{+}((X_{i}^{V}-\zeta_{i})/ \lambda_{i})\rceil}{1+\lceil\log_{2}((H-\zeta_{i})/\lambda_{i})\rceil}\right] \geq\mathbb{E}\left[1-\frac{1+\log_{2}(1+(X_{i}^{V}-\zeta_{i})/ \lambda_{i})}{1+\lceil\log_{2}((H-\zeta_{i})/\lambda_{i})\rceil}\right]\] \[\geq 1-\frac{1+\log_{2}(1+(\mathbb{E}[X_{i}^{V}]-\zeta_{i})/ \lambda_{i})}{1+\lceil\log_{2}((H-\zeta_{i})/\lambda_{i})\rceil}\]

by Jensen's inequality. The corresponding versions of Theorems 4.4, 4.5, and 4.6 follow.

**Theorem C.1**.: \(\mathbb{E}[\text{welfare}]\geq\max\{(1-\max_{i}\frac{1+\log_{2}(1+(\mathbb{E} [X_{i}^{V}]-\zeta_{i})/\lambda_{i})}{1+\lceil\log_{2}((H-\zeta_{i})/\lambda_{ i})\rceil}),\frac{1}{1+\lceil\max_{i}\log_{2}((H-\zeta_{i})/\lambda_{i}) \rceil}\}\mathsf{OPT}\)_._

**Theorem C.2** (Revenue bound 1).: _Let \(\rho_{i}=\mathbb{E}[2{X_{i}^{V}}-\zeta_{i})\mathbf{1}(\zeta_{i}+\lambda_{i}<X_ {i}^{V})+\lambda_{i}\mathbf{1}(\zeta_{i}+\lambda_{i}\geq X_{i}^{V})]\). Then \(\mathbb{E}[\text{revenue}]\geq\frac{1}{1+\lceil\max_{i}\log_{2}((H-\zeta_{i})/ \lambda_{i})\rceil}(\mathsf{OPT}-\sum_{i=1}^{n}(\mathbb{E}[X_{i}^{A}]+\zeta_{ i}+\mathbb{E}[\rho_{i}]))\)._

**Theorem C.3** (Revenue bound 2).: \(\mathbb{E}[\text{revenue}]\geq(1-\max_{i}\frac{1+\log_{2}(1+(\mathbb{E}[X_{i}^{ V}]-\zeta_{i})/\lambda_{i})}{1+\lceil\log_{2}((H-\zeta_{i})/\lambda_{i}) \rceil})(\mathsf{OPT}-\sum_{i=1}^{n}(\gamma_{i}^{A}+\zeta_{i}))-\sum_{i=1}^{n} \frac{4H}{1+\lceil\log_{2}((H-\zeta_{i})/\lambda_{i})\rceil}\)_._

## Appendix D Beyond the VCG mechanism: affine maximizers

Given agent-specific multipliers \(\omega=(\omega_{1},\ldots,\omega_{n})\in\mathbb{R}_{\geq 0}\) and an allocation-based boost function \(\lambda:\Gamma\to\mathbb{R}_{\geq 0}\), we define the following meta-mechanism \(\mathcal{M}(\omega,\lambda)\) which is a generalization of our meta-mechanism \(\mathcal{M}\). The mechanism designer receives as input \(\widetilde{\Theta}_{1},\ldots,\widetilde{\Theta}_{n}\), and based on these decides on prediction sets \(\widehat{\Theta}_{1},\ldots,\widehat{\Theta}_{n}\). The agents are then asked to reveal their true types \(\theta_{1},\ldots,\theta_{n}\). The allocation used is

\[\alpha_{\omega,\lambda}=\operatorname*{argmax}_{\alpha\in\Gamma}\sum_{i=1}^{n} \omega_{i}\theta_{i}[\alpha]+\lambda(\alpha).\]

Let

\[p_{i}=\frac{1}{\omega_{i}}\left[\min_{\theta_{i}\in\Theta_{i}}\left(\max_{ \alpha\in\Gamma}\sum_{j\neq i}\omega_{j}\theta_{j}[\alpha]+\omega_{i}\widetilde {\theta}_{i}[\alpha]+\lambda(\alpha)\right)-\left(\sum_{j\neq i}\omega_{j} \theta_{j}[\alpha_{\omega,\lambda}]+\lambda(\alpha_{\omega,\lambda})\right) \right].\]

Let

\[\mathcal{I}=\{i:\theta_{i}[\alpha_{\omega,\lambda}]-p_{i}\geq 0\}.\]

Agents in \(i\) enjoy allocation \(\alpha_{\omega,\lambda}\) and pay \(p_{i}\). Agents not in \(i\) do not participate and receive zero utility.

This mechanism is the natural generalization of the affine-maximizer mechanism [45] parameterized by \(\omega,\lambda\) to our setting. The special case where agent misreporting is limited to \(\widehat{\Theta}_{i}\) is the natural generalization of the weakest-competitor VCG mechanism of Krishna and Perry [34] to affine-maximizer mechanisms. The following is a simple consequence of the proofs that \(\mathcal{M}\) and the affine-maximizer mechanism parameterized by \(\omega,\lambda\) are incentive compatible and individually rational.

**Theorem D.1**.: _For any \(\omega\in\mathbb{R}_{\geq 0}^{n}\) and \(\lambda:\Gamma\to\mathbb{R}_{\geq 0}\), \(\mathcal{M}(\omega,\lambda)\) is incentive compatible and individually rational._Let \(\mathsf{OPT}(\omega,\lambda)=\sum_{i=1}^{n}\theta_{i}[\alpha_{\omega,\lambda}]\) be the welfare of the \((\omega,\lambda)\)-efficient allocation. All of the guarantees satisfied by \(\mathcal{M}\) carry over to \(\mathcal{M}(\omega,\lambda)\), the only difference being the modified benchmark of \(\mathsf{OPT}(\omega,\lambda)\). Of course, \(\mathsf{OPT}(\omega,\lambda)\leq\mathsf{OPT}\) is a weaker benchmark than the welfare of the efficient allocation. However, the class of affine maximizer mechanisms is known to achieve much higher revenue than the vanilla VCG mechanism. We leave it as a compelling open question to derive even stronger guarantees on mechanisms of the form \(\mathcal{M}(\omega,\lambda)\) when the underlying affine maximizer is known to achieve greater revenue than vanilla VCG.