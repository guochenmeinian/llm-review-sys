# PRIOR: Personalized Prior for Reactivating the Information Overlooked in Federated Learning.

 Mingjia Shi\({}^{1}\)1 &Yuhao Zhou\({}^{1}\) &Kai Wang\({}^{2}\) &Huiazheng Zhang

**Shudong Huang\({}^{1}\)** &Qing Ye\({}^{1}\)2 &Jiangcheng Lv\({}^{1}\)3

\({}^{1}\)Sichuan University &National University of Singapore

Footnote 1: 3101ihs@gmail.com

Footnote 2: Equal Corresponding Authors {yeqing, lvjiancheng}@scu.edu.cn

###### Abstract

Classical federated learning (FL) enables training machine learning models without sharing data for privacy preservation, but heterogeneous data characteristic degrades the performance of the localized model. Personalized FL (PFL) addresses this by synthesizing personalized models from a global model via training on local data. Such a global model may overlook the specific information that the clients have been sampled. In this paper, we propose a novel scheme to inject personalized prior knowledge into the global model in each client, which attempts to mitigate the introduced incomplete information problem in PFL. At the heart of our proposed approach is a framework, the _PFL with Bregman Divergence_ (pFedBreD), decoupling the personalized prior from the local objective function regularized by Bregman divergence for greater adaptability in personalized scenarios. We also relax the mirror descent (RMD) to extract the prior explicitly to provide optional strategies. Additionally, our pFedBreD is backed up by a convergence analysis. Sufficient experiments demonstrate that our method reaches the _state-of-the-art_ performances on 5 datasets and outperforms other methods by up to 3.5% across 8 benchmarks. Extensive analyses verify the robustness and necessity of proposed designs. https://github.com/BDeMo/pFedBreD_public

## 1 Introduction

Federated learning (FL) [53] has achieved significant success in many fields [72, 43, 71, 76, 69, 59, 32, 5, 34, 49], which include recommendation systems utilized by e-commerce platforms [71], prophylactic maintenance for industrial machinery [76], disease prognosis employed in healthcare [69]. Data heterogeneity is a fundamental characteristic of FL, leading to challenges such as inconsistent training and testing data (data drift) [36]. An efficient solution to these challenges is to fine-tune the global model locally for adaptation on local data [3, 74, 35]. This solution is straightforward and pioneering, but presents a fundamental limitation when dealing with highly heterogeneous data. For examples, heterogeneous data drift may introduce substantial noise [29] and the resulted model may not generalize well to new sample [20, 12]. Thus, heterogeneous data in FL is still challenging [66].

Recently, personalized FL (PFL) is proposed to mitigate the aforementioned negative impact of heterogeneous data [66]. To improve the straightforward solution mentioned above, Per-FedAvg [20] is introduced to train a global model that is easier to fine-tune. Another paper on the similar topic, FedProx [45], aims to resolve the issue of personalized models drifting too far from the global model during training with a dynamic regularizer in the objective during local training. This issue could occur especially in post-training fine-tuning methods without regularization (_e.g._, Per-FedAvg [20]). Moreover, pFedMe [65], another regularization method modeling local problems using Moreauenvelopes, replaces FedProx's personalized model aggregation method with an interpretable approach for aggregating local models [45]. It also accommodates first-order Per-FedAvg [20].

Although the existing PFL methods have achieved promising results, the prior knowledge from single global model for local training [66] hinders the development of PFL. Specifically, we analyze the shortcomings of current PFL methods as follows: 1) utilizing the same global model for direct local training could potentially disregard the client's sampling information. As shown in Figure 1, a single global model provides global knowledge directly for local training, which overlooks the client-sampling information when the global knowledge is transferred to specific clients. 2) Explicitly extracting prior knowledge can be a challenging task. Most of the insightful works [17, 52] propose assumptions for recovering this incomplete information, but these assumptions are implicit, which limits the way to use the information to develop personalized strategies.

To address the former issue above, we propose framework pFedBreD to inject personalized prior knowledge into the one provided by a global model. As shown in Figure 1, it is injected in the \(2^{nd}\) step and the local knowledge is transferred into global model via local models instead of directly aggregating personalized models [45]. To address the latter, we introduce _relaxed mirror descent_ RMD to explicitly extract the prior for exploring personalized strategies.

Our method is backed up with direct theoretical support from Bayesian modeling in Section 4 and a convergence analysis in Section 5, which provides a linear bound \(\mathcal{O}(1/TN)\) with aggregation noise and a quadratic speedup \(\mathcal{O}(1/(TNR)^{2})\) without.3 Meanwhile, the existence and validity of the injection and extraction aforementioned information is verified in Section 6.2. The remarkable performance of the implements of the proposed method is tested on 5 datasets and 8 benchmarks. Consistently, our method reach the _state-of-the-art_. Especially, the improvement of accuracy on task DNN-FEMNIST [11] is up to 3.5%. Extensive ablation study demonstrate that parts of the hybrid strategy \(\mathbf{mh}\) are complementary to each other. Our contributions can be summarized as follows:

Footnote 3: \(TN\) and \(TNR\): total global / local epoch in FL system. See Appendix A.1.

* The problem of overlooking client-sampling information at prior knowledge being transferred is introduced in this paper, and we first investigate the possibility of explicitly expressing the prior knowledge of the information and design personalized strategies on it.
* To express the personalized prior, we model PFL into a Bayesian optimization problem, _Global-MLE and Local-MAP_. A novel framework, pFedBreD, is proposed for computing the modeled problem, and RMD is introduced to explicitly extract prior information.
* Sufficient experiments demonstrate our method surpasses most baselines on public benchmarks, thereby showcasing its robustness to data heterogeneity, particularly in cases involving small aggregation ratios and non-convex local objective settings.

Figure 1: pFedBreD framework: Global-MLE and Local-MAP. The personalized prior knowledge is injected into the global model of the global problem (MLE) in the \(2^{nd}\) step for local training. The local knowledge is extracted from the local problem (MAP) in the \(4^{th}\) step for aggregation.

Related Works

RegularizationResearchers have developed a variety of approaches based on regularization to handle the PFL challenge in recent years (_e.g._, FedU [18], pFedMe [65], FedAMP [31], HeurFedAMP [31]). All of these approaches' personalized objective functions can be expressed as \(J(\theta)+R(\theta;\mu)\) where \(J(\theta)\) is the loss function of the local problem and \(R(\theta;\mu)\) is the regularization term used to restrict the deviation between \(\theta\) and \(\mu\) (_e.g._, \(R(\theta;\mu)=\frac{1}{2}\|\theta-\mu\|^{2}\) in pFedMe).

Meta LearningOne of the most representative meta-learning based single-model PFL approach is the well-known Per-FedAvg [20], aiming to find an initialization that is easy to fine-tune. That is, the global model in the FL setting is regarded as a meta model in MAML [21; 19], where the objective function of the local problem is \(J(\theta-\eta\nabla J(\theta))\). Researchers also show the connections between FedAvg [53] and Reptile [60], another meta learning framework. [35] shows how to improve personalization of FL via Reptile. Proximal updating is also used in meta-learning based algorithms such as [79]. One of our strategies \(\mathbf{meg}\) is the one motivated by MAML.

Expectation MaximizationTwo EM-based [15] methods are proposed, _e.g._, FedSparse in [50] and FedEM in [17]. Both of them focus on communication compression. The latter provides a variance reduce version and assumes complete information (or data) of the global model obeys distribution in X-family. Another FedEM [52] combines Bayesian modeling, Federated Multi-task learning (FTML) and EM. Our framework pFedBreD is a expectation maximuzatioin and maximum a posteriori estimate (EM-MAP) [17] algorithm with personalized prior specified.

Bayesian FLIn recent years, studies of PFL with Bayesian learning have been proposed. In related approaches, FLOA [48] and pFedGP [1] are proposed with KL divergence regularization in the loss function, which is comparable to applying specific assumption of X-family prior in pFedBreD see Appendix B.2 for details. Our implementation doesn't use a Bayesian neural network (BNN) model as an inferential model as others do (_e.g._, pFedGP uses a Gaussian process tree and pFedBayes [77] uses BNN). Instead, to eliminate weight sampling cost in Bayesian methods, prior knowledge is introduced through regularization term.

## 3 Preliminary

Overlooked Information in Prior KnowledgeFrom a Bayesian and info. perspective, the global knowledge transferred in conventional method with single global model has no mutual information (MI) with client sampling \(i\), i.e., formally, \(w=\mathbf{E}_{i}w_{i}=\mathbf{E}_{i}w_{i}|i\Rightarrow\text{MI }I(w;i)=0\), in particular when applying reg. \(R(w^{(t)};...)\) or local init. \(w^{(t)}_{i,0}\gets w\) where \(w_{i}\) is the local model on the \(i^{th}\) client. This makes the specific model on each client have to re-obtain this information from scratch solely from the data during training, especially impacted on hard-to-learn representations and datasets.

Bregman-Moreau EnvelopeBregman divergence [10] is employed as a general regular term in our local objective that exactly satisfies the computational requirements and prior assumption, and is formally defined in Eq. (1).

\[\mathcal{D}_{g}(x,y): =g(x)-g(y)-\langle\nabla g(y),x-y\rangle\] (1)

where \(g\) is a convex function. For convenience, \(g\) is assumed to be strictly convex, proper and differentiable such that Bregman divergence is well-defined. To utilize the computational properties of Bregman Divergence in optimization problems, we introduce the following definition in Eq. (2) [7; 8]: Bregman proximal mapping, Bregman-Moreau envelope, and the relationship between them.

\[\mathcal{D}\mathbf{prox}_{g,\lambda^{-1}}f(x) :=\arg\min_{\theta}\{f(\theta)+\lambda\mathcal{D}_{g}(\theta,x)\},\] (2) \[\mathcal{D}\mathbf{env}_{g,\lambda^{-1}}f(x) :=\min_{\theta}\{f(\theta)+\lambda\mathcal{D}_{g}(\theta,x)\},\] \[\nabla\mathcal{D}\mathbf{env}_{g,\lambda^{-1}}f(x) =\lambda\nabla^{2}g(x)[x-\mathcal{D}\mathbf{prox}_{g,\lambda^{-1 }}f(x)],\]

where \(\lambda>0\) denotes the regular intensity in general and the variance of the prior in our modeling.

Exponential FamilyThe regular exponential family (X-family) is a relatively large family that facilitates calculations. Therefore, to yield the prior, we employ the X-family [6]defined in Eq. (3).

\[\mathbf{P}_{ef}(\mathcal{V};s,g)=h(\mathcal{V})\exp\{\langle\mathcal{V},s\rangle- g(s)\}=h(\mathcal{V})\exp\{-\mathcal{D}_{g^{*}}(\mathcal{V},\mu)+g^{*}(\mathcal{V})\},\] (3)

where \(g\) is assumed to be convex, \(\mathcal{D}_{g}(\cdot,\cdot)\) is the Bregman divergence, and \(g^{*}\) is the Fenchel Conjugate of \(g\). In Eq. (3), \(s\), \(h(\mathcal{V})\) and \(g(s)\) are respectively the natural parameter, potential measure and logarithmic normalization factor, where we have the mean parameter \(\mu=\nabla g(s)\). Additionally, to highlight the variance, the scaled exponential family (SX-family) is introduced in Eq. (4)

\[\mathbf{P}_{sef}(\mathcal{V};\lambda,s,g)=h_{\mathcal{V}}(\mathcal{V})\exp\{ \lambda[(\mathcal{V},s)-g(s)]\}=h_{\lambda}(\mathcal{V})\exp\{-\lambda \mathcal{D}_{g^{*}}(\mathcal{V},\mu)+\lambda g^{*}(\mathcal{V})\},\] (4)

where \(\log h_{\lambda}(\mathcal{V})\) is the scaled potential measure, and the scale parameter \(\lambda\) is employed to highlight the variance. Moreover, \(\mathcal{V}\) is assumed to be the minimal sufficient statistic of the complete information for local inference, details of which can be found in Section 4.

## 4 Methodology

In this section4, we introduce missing client-sampling information based on classic FL, use EM to reduce the computational cost of the information-introduced FL problem, and propose RMD, a class of prior selection strategies, based on the E-step in EM. The general FL classification problem with KL divergence could be formulated as Eq. (5) [53; 66].

Footnote 4: More details of equations are in Appendix B.

\[\arg\min_{w}\mathbf{E}_{i}\mathbf{E}_{d_{i}}\mathbf{KL}(\mathbf{P}(y_{i}|x_{i} )||\hat{\mathbf{P}}(y_{i}|x_{i},w))=\arg\max_{w}\mathbf{E}_{i}\mathbf{E}_{d_{ i}}\mathbf{E}_{y_{i}|x_{i}}\log\hat{\mathbf{P}}(y_{i}|x_{i},w),(x_{i},y_{i}) \in d_{i},\] (5)

where we rewrite the discriminant model as an maximum likelihood estimation (MLE) problem [41] of \(y_{i}|x_{i}\) in the right hand side (R.H.S.) of Eq. (5). \((x_{i},y_{i})\) represent the pairs of input and label respectively in dataset \(d_{i}\) on the \(i^{th}\) client, and \(\hat{\mathbf{P}}(y_{i}|x_{i},w)\) is the inferential model parameterized by \(w\). Each local data distribution is presuppose to be unique, so using the global model with local data for inference and training could overlook the fact that the client has been sampled before transmitting the global model, and the prior knowledge transmitted directly via the global model as the local training prior knowledge (_e.g._ via initial points, penalty points in dynamic regular terms, etc.) has no mutual information with the client sampling, _i.e._, the global model \(w=\mathbf{E}_{i}w_{i}=\mathbf{E}_{i}w_{i}|i\). Thus, to reduce the potential impact of the overlooked information, the complete information \(\Theta_{i}\) on the \(i^{th}\) client is introduced which turns Eq. (5) into Eq. (6).

\[\arg\max_{w}\mathbf{E}\log\int_{\Theta_{i}}\hat{\mathbf{P}}(y_{i}|x_{i}, \Theta_{i},w)\mathbf{P}(\Theta_{i}|x_{i},w)d\Theta_{i},\] (6)

where \(\mathbf{E}=\mathbf{E}_{i}\mathbf{E}_{d_{i}}\mathbf{E}_{y_{i}|x_{i}}\) and the direct calculation of this is computationally expensive [14].

Framework: Leveraging Expectation Maximization for Prior Parameter ExtractionThe integral term in Eq. (6) makes direct computation impossible [14], so we employ EM to approximate the likelihood with unobserved variables [15] as shown in Eq. (7), where \(\mathbf{Q}(\Theta_{i})\) is any probability measure.

\[\sum_{i}\log\hat{\mathbf{P}}(y_{i}|x_{i},w)\geq\sum_{i}\mathbf{E}_{\mathbf{Q}( \Theta_{i})}[\log\hat{\mathbf{P}}(y_{i}|x_{i},\Theta_{i},w)+\mathbf{E}_{y_{i}| x_{i},w}\log\mathbf{P}(\Theta_{i}|d_{i},w)].\] (7)

Assuming that prior \(\Theta_{i}|d_{i},w\sim\hat{\mathbf{P}}_{sef}(\Theta_{i};\lambda,s_{i}(w;d_{i} ),g)\)5 and the local loss function on the \(i^{th}\) client \(f_{i}(\Theta_{i},w)\) is \(\mathbf{E}_{d_{i}}[-\log\mathbf{P}(y_{i}|x_{i},\Theta_{i},w)]\), we have the left hand side (L.H.S.) of the Eq. (8) from (7). Here is an assumption for simplification that \(\theta_{i}\) contains all the information for local inference, _i.e._\(\theta_{i}=\Theta_{i}\) and \(\mathbf{P}(y_{i}|x_{i},\Theta_{i},w)=\mathbf{P}(y_{i}|x_{i},\Theta_{i})\). It happens when \(\theta_{i}\) is all the parameters of the personalized model and we only use the personalized model for inference. Thus, \(f_{i}(\theta_{i})=\mathbf{E}_{d_{i}}[-\log\hat{\mathbf{P}}(y_{i}|x_{i},\theta_ {i})]\). Thus, we can optimize an upper bound as a bi-level optimization problem as shown in the R.H.S. of the Eq. (8) to solve Eq. (5) approximately, where mean parameter \(\mu_{i}=\nabla g\circ s_{i}\)6[9]. And, we can derivate our framework as shown in Section 5.

Footnote 5: A-posteriori distribution for local client whose prior knowledge is from global model. See Appendix B.

Footnote 6: The following \(d_{i}\) is omitted with the same footnote \(i\) in \(\mu_{i}\) for simplification (\(\mu_{i}(\cdot)\leftarrow\mu_{i}(\cdot;d_{i})\)).

\[-\max_{w,\{\theta_{i}\}}\mathbf{E}_{i}\{-f_{i}(\theta_{i})-\lambda\mathcal{D} _{g^{*}}(\theta_{i},\mu_{i}(w))\}\leq\min_{w}\mathbf{E}_{i}\boxed{\overline{ \min_{\{\theta_{i}\}}}\{f_{i}(\theta_{i})+\lambda\mathcal{D}_{g^{*}}(\theta_{i},\mu_{i}(\overline{w}))\}}.\] (8)Strategies: Relaxing Mirror Descent for Prior SelectionTo extract the prior strategies and implement \(\mu_{i}\) E-step of EM in close-form, we propose a method called relaxed mirror descent (RMD), where the mirror descent (MD) is EM in X-family [40]. MD can be generally written as Eq. (9) from the old \(\hat{w}\) to the new one \(\hat{w}^{+}\) in each iteration [54, 40].

\[\hat{w}^{+}\leftarrow\arg\min_{\hat{\theta}}\{f(\hat{w})+\langle\nabla f(\hat {w}),\hat{\theta}-\hat{w}\rangle+\hat{\lambda}\mathcal{D}_{\hat{g}}(\hat{ \theta},\hat{w})\}.\] (9)

According to the Lagrangian dual, we rewrite the problem into a more general variant shown in Eq. (10) with relaxed restrictions and superfluous parameter.

\[\arg\min_{\hat{\theta},\hat{\mu}}\{\Psi(\hat{\theta},\hat{w})+\langle\nabla \Phi(\hat{w}),\hat{\mu}-\hat{w}\rangle+\lambda\mathcal{D}_{g^{*}}(\hat{\theta },\hat{\mu})+(2\eta)^{-1}||\hat{\mu}-\hat{w}||^{2}\}.\] (10)

We can transform Eq. (10) back into Eq. (9) by setting \(\Phi(\hat{w})\) to satisfy \(\nabla\Phi(\hat{w})=\nabla f(\hat{w})\), and defining \(\Psi(\hat{\theta},\hat{w})\) as a function with \(f(\hat{w})\) and a penalty term to make \(\hat{\theta}\) and \(\hat{w}\) close as possible (_e.g._, \(\hat{\lambda}\mathcal{D}_{\hat{g}}(\hat{\theta},\hat{w})\)). This provides us a way to extract \(\mu_{\Phi}\) the function to generate mean parameter of the prior, as shown in Eq. (11), which is minimizing an upper bound of the problem in Eq. (10).

\[\begin{split}\mathcal{D}\mathbf{env}_{g^{*},\lambda^{-1}}\Psi( \cdot,w)(\mu_{\Phi}(w))&=\min_{\theta}\{\Psi(\theta,w)+\lambda \mathcal{D}_{g^{*}}(\theta,\mu_{\Phi}(w))\}\\ \boxed{\mu_{\Phi}(w)}&=\arg\min_{\mu}\{\langle \nabla\Phi(w),\mu-w\rangle+(2\eta)^{-1}||\mu-w||^{2}\}.\end{split}\] (11)

By optimality condition, we have \(\mu_{\Phi}(w)=w-\eta\nabla\Phi(w)\), which can be specified by \(\Phi\). The remaining part is a Bregman-Moreau envelope. Thus, we can optimize the upper bound with an EM-MAP method, alternately computing \(\mu_{\Phi}(w)\) and \(\mathcal{D}\mathbf{prox}_{g^{*},\lambda^{-1}}\Psi(\cdot,w)(\mu_{\Phi}(w))\).

## 5 Framework Design

Problem Formulation that Highlights Personalized PriorInspired by the aforementioned motivation, the personalized models \(\theta_{i}\) and mean parameters are respectively the solution of \(\mathcal{D}\mathbf{env}_{g^{*},\lambda^{-1}}f_{i}(\mu_{i}(w))\) and \(\mu_{i}(w)\) on the \(i^{th}\) client, where \(w\) is the global model. We assume that personalized model contains all the local information required for inference on the \(i^{th}\) client, and satisfies \(\theta_{i}|d_{i},w\sim\mathbf{P}_{sef}(\theta_{i};\lambda,s_{i}(w),g)\). The global problem can be written as Eq. (12).

\[\min_{w}\mathbf{E}_{i}\{F_{i}(w):=\mathcal{D}\mathbf{env}_{g^{*},\lambda^{-1} }f_{i}(\boxed{\mu_{i}(w)})\}.\] (12)

The given \(g\) is strictly convex, \(\lambda>0\), \(f_{i}\) is the local loss function, \(s_{i}(w)\) is the natural parameter and \(\mu_{i}(w)=\mathbf{E}_{\theta_{i}|x_{i},w}\theta_{i}=\nabla g(s_{i}(w))\) is the mean (or expectation) parameter in Eq. (12).

Framework: pFedBreDTo solve the optimization problem in Eq. (12), we use gradient-based methods to solve the global problem using the gradient of \(F_{i}\):

\[\nabla F_{i}(w)=\lambda\mathbf{D}\mu_{i}(w)\nabla^{2}g^{*}(\mu_{i}(w))[\mu_{ i}(w)-\mathcal{D}\mathbf{prox}_{g^{*},\lambda^{-1}}f_{i}(\mu_{i}(w))],\] (13)

where \(\mathbf{D}\) is the gradient operator of the vector value function, and \(\nabla^{2}\) is the Hessian operator.7 The framework is shown as Algorithm 1, where \(\mathcal{I}\) is the client selecting strategy for global model aggregation; \(w_{init}\) and \(\theta_{init}\) are the initialization strategies on the \(i^{th}\) client; \(\alpha_{m}\) is the main problem step-size; \(T\), \(R\), \(N\) are respectively the total number of iterations, local iterations, and clients. \(\beta\) is used in the same trick as [37, 65]. The strategies to derive the initialization points of \(w_{i}\) and \(\theta_{i}\) at each local epoch are \(w_{i,0}^{(t)}\gets w^{(t-1)}\) and \(\theta_{i,0}^{(t)}\leftarrow\theta_{i,R}^{(t-1)}\).

Footnote 7: The details of first-order methods is in Appendix A.7.

Implementation: Maximum Entropy and Meta-StepPractically, two main parts of the pFedBreD are needed to be implemented:

* \(g\), the function used to derive the logarithmic normalization factor, determines the type of prior to be used;
* \(\{s_{i}\}\) or \(\{\mu_{i}\}\), the functions used to derive the natural parameter and mean parameter for the personalized local prior, determine which particular prior is used.

[MISSING_PAGE_EMPTY:6]

**Theorem 2** (pFedBreD\({}_{ns}\)'s first-order personalization bound).: _Under the same conditions as in Theorem 1, with prior assumption of a spherical Gaussian and first-order approximation, the bound for the gap between the personalized approximate model and global model in the Euclidean space is:_

\[\mathbf{E}|\ddot{\theta}_{i}(\bar{w}^{T})-w^{*}||^{2}\leq\mathcal{O}(\dot{ \delta}_{p})+\mathcal{O}[\dot{c}_{p}\mathcal{D}_{F}(\bar{w}^{(T)},w^{*})]\]

_where \(\dot{\delta}_{p}=\frac{2}{\dot{\mu}_{F,\cdot}^{2}}([\frac{\dot{\epsilon}_{F}^{ 2}}{|\dot{d}_{\cdot}|}+\hat{\epsilon}^{2})+\frac{2}{\lambda^{2}}\epsilon_{1}^{2 }+\frac{4}{\lambda^{2}}\sigma_{F,*}^{2}+\frac{1}{2}\eta^{2}\mathcal{G}_{\Phi}^ {2}\), and \(\dot{c}_{p}=(\frac{32}{\lambda^{2}}\hat{L}_{F}+\frac{8}{\dot{\mu}_{F,\cdot}})\)._

**Remark 1**.: _Theorem 1 shows the main factors that affect the convergence of a global model are as follows: random mini-batch size, client drift error, aggregation error, heterogeneous data, dual space selection, local approximation error, and selection strategy for exponential family prior mean and variance. These can be divided into four categories based on their computational complexity. The first and second term shows that the proper fixed \(\tilde{\alpha}_{m}\) can linearly reduce the influence of initial error \(\mathbf{\Delta}^{(0)}\) and the global model converges to a ball near the optimal point. The radius of this ball is determined by the personalized strategy and local errors (including local data randomness and envelope approximation errors). The third term implies that a linear convergence rate \(\mathcal{O}(1/(NT))\) can be obtained w.r.t. the total global epoch \(NT\) in the presence of aggregation noise. Without client sampling \(N=S\), according to the fourth term, the quadratic rate \(\mathcal{O}(1/(TNR)^{2})\) can be obtained with \(\beta=\mathcal{O}(N)\) or \(\beta=\mathcal{O}(N\sqrt{R})\) (Note that the number of local epoch \(R\) cannot be too large due to client drift, according to \(2^{R}\)). Theorem 2 shows that, with spherical Gaussian prior assumption and first-order methods, the radius of the neighborhood range for the minimum that includes the personalized model on \(i^{th}\) client, \(\mathcal{O}(C_{\Phi,F,f,d}+\frac{1}{\lambda^{2}}(\epsilon_{1}^{2}+\sigma_{F,* }^{2}+\frac{BL_{F}}{\dot{\mu}_{F}})+\lambda^{2}\frac{\lambda}{\dot{\mu}_{F, \cdot}})\), can be trade-off by \(\lambda\), and is affected by the prior selection strategies and first-order approximate error besides the elements in Theorem 1. (Note that the Euclidean space is self-dual.)_

## 6 Experiments

### General Settings

**Tricks, Datasets and Models:** our experiments include several tasks: CNN [28] on CIFAR-10 [18; 39], LSTM [27] on Sent140 [11] and MCLR/DNN on FEMNIST [11]/FMNIST [65; 67]/MNIST[65; 42]. The details of tricks (FT, AM), data heterogeneity and models are in Appendix C.

**Baselines:** we choose following algorithms as our baselines: FedAvg [53], Per-FedAvg [20], pFedMe [65], FedAMP [31], pFedBayes [77] and FedEM [52]. These baselines are respectively classical FL, MAML-based meta learning, regularization based, FTML methods, variational inference PFL and FMTL with EM.

**Global Test and Local Test:** the global and personalized model, represented by **G** and **P**, are evaluated with global and local tests respectively. Global test means all the test data is used in the test. Local test means only the local data is used for the local test and the weight of the sum in local test is the ratio of the number of data. The results of average accuracy per client are shown in Table 1. Each experiment is repeated 5 times. More details are in Appendix C. For readability, we only give the error bar in the main Table 1 and Table 2, and keep one decimal except for the main Table 1.

Hyperparameter SettingsThe step-size of the main problem, \(\alpha_{m}\), and the personalized step-size, \(\alpha\), for all methods are 0.01. \(\beta\) is 1, and the number of local epochs, \(R\), is 20 for all datasets. \(\lambda\) is chosen from 15.0 to 60.0. The batch sizes of Sent140 and the other datasets are 400 and 20, respectively, and the aggregation strategy, \(\mathcal{I}\), is uniform sampling. The ratios of aggregated clients per global epoch are 40%, 10%, and 20% for Sent140, FEMNIST, and the other datasets, respectively. The numbers of total clients, \(N\), are 10, 198, 20, and 100 for Sent140, FEMNIST, CIFAR-10, and other datasets. The number of proximal iterations is 5 for all settings with proximal mapping. In our implementations, \(\eta_{\alpha}\) and \(\eta\) are respectively 0.01 and 0.05.

Summarizing the Effects of Hyper-parametersWe test the hyper-parameter effect of \(\eta\) and \(\lambda\) in our implementation pFedBreD\({}_{ns,\mathbf{mh}}\). The details are in Appendix C. From the results, we find that it will degrade the test accuracy if the values of \(\lambda\) or \(\eta\) are too large or too small. The test accuracy of personalized model is more sensitive than the ones of global model. The test accuracy of personalizedmodel is more sensitive to \(\eta\) than to \(\lambda\). Note that the hyper-parameters are roughly tuned, which shows the insensitivity of \(\mathbf{m}\mathbf{h}\), and better tuning could improve the performance in the Table 1.

### Analysis

Comparative Analysis of PerformanceWe compare our methods and the baselines from different perspectives, including convex or non-convex problems, easy or hard tasks, and text tasks. Additionally, we briefly discuss the absence of BNN on hard tasks.

**Convex or non-convex:** on non-convex problems, especially in hard tasks, our method significantly outperforms other methods by at least 3.06% employing some simple tricks. On convex problem, FedAMP outperforms our method somewhat on convex problems with simple data sets. One explanation is that the learning lansecap is simple in shape for these problems and FedAMP converges faster for this case. One possible reason for this is that since FedAMP uses the distance between models as a similarity in the penalty point selection, giving greater weight to the model that is most similar to the local one. In the later stages of training, since there is only one global optimum, this penalty point tends not to change, and thus the method degenerates into a non-dynamic regular term. Compounding intuition, this method will not be as advantageous for non-convex problems and harder convex problems, as penalty point tends to fall into the local optimum and lead to degradation of the dynamic regular term.

**From easy to difficult task:** from the difference between the statistics of Avg and \(\mathbf{H.Avg}\) in Table 1, it can be observed that meta-step methods perform most consistently, with all other methods dropping at least 10%. This is due to the simple and effective local loss design of MAML, with its learning-to-learning design philosophy that enables the method to be more stable in complex situations [19; 20].

**Personalized prior on text:** text tasks, as opposed to image tasks, generally have relatively rugged learning landscape. [55; 16; 13] This understanding is manifested in specific ways, such as parameter sensitivity, slow convergence, and struggling during the process. Thus, the overlooked prior information seems to be more important, which means that each local iteration not only obtains local knowledge from the data, but also the prior itself already contains some local knowledge. Therefore, there is no need to re-obtain this knowledge from scratch solely from the data during training.

**Absence of BNN on hard tasks:** complex BNN is not in Table 1, such as LSTM in pFedBayes, because it is difficult to conduct comparative experiments by fixing elements, _e.g._, inferential models, tricks and optimization methods. In pFedBayes, training often crashes on hard tasks and large datasets, as mentioned in [77]. Our one-step-further research shows that it may be caused by the reparameterization tricks and vanilla Gaussian sampling. If we add tricks on it, the implementation will be very different from the original pFedBayes, and it is beyond this analysis.

Ablation Analysis of Personalized PriorWe conduct ablation experiments by dropping the gradient of the Bregman-Moreau envelope, the local loss function, or both, from the personalized

\begin{table}
\begin{tabular}{l l l l l l l l l l l l l l} \hline \hline \multicolumn{1}{c}{**Method / Datasets**} & \multicolumn{2}{c}{FEMNIST} & \multicolumn{2}{c}{**FBNN**} & \multicolumn{2}{c}{**MNIST**} & \multicolumn{2}{c}{**CIFAR-10**} & \multicolumn{2}{c}{**Sent100**} & \multicolumn{2}{c}{**Sentros**} \\ \multicolumn{1}{c}{Names - **Models**} & \multicolumn{1}{c}{**MCLR**} & \multicolumn{1}{c}{**DNN**} & \multicolumn{1}{c}{**MCLR**} & \multicolumn{1}{c}{**DNN**} & \multicolumn{1}{c}{**MCLR**} & \multicolumn{1}{c}{**DNN**} & \multicolumn{1}{c}{**CERN**} & \multicolumn{1}{c}{**LSTM**} & \multicolumn{1}{c}{**Avg**} & \multicolumn{1}{c}{**Sent**} & \multicolumn{1}{c}{**H.Avg**} & \multicolumn{1}{c}{**H.Avg**} & \multicolumn{1}{c}{**H.Avg**} \\ \hline PolarB [7] & 54.31\(\pm\)0.5 & 57.04\(\pm\)0.0 & 58.27\(\pm\)50.0 & 80.09\(\pm\)0.0 & 86.56\(\pm\)0.0 & 88.26\(\pm\)0.0 & 89.31\(\pm\)0.6 & 57.51\(\pm\)0.0 & 76.50\(\pm\)0.0 & 76.16\(\pm\)0.0 & 78.45\(\pm\)0.0 & 67.98\(\pm\)0.0 & 7.58 \\ FedAMP-M [6] & 53.34\(\pm\)0.0 & 59.03\(\pm\)0.0 & 59.03\(\pm\)0.0 & 58.31\(\pm\)0.0 & 58.04\(\pm\)0.0 & 59.31\(\pm\)0.0 & 57.94\(\pm\)0.0 & 57.67\(\pm\)0.0 & 77.63\(\pm\)0.0 & 66.72\(\pm\)0.0 & 71.81\(\pm\)0.0 & 61.42\(\pm\)0.0 & 62.6 & 7.30 \\ FedAMP-M [7] & 40.75\(\pm\)0.0 & 45.71\(\pm\)0.0 & 59.78\(\pm\)0.0 & 59.42\(\pm\)0.0 & 58.57\(\pm\)0.0 & 58.49\(\pm\)0.0 & 59.49\(\pm\)0.0 & 57.67\(\pm\)0.0 & 66.72\(\pm\)0.0 & 71.88\(\pm\)0.0 & 22.28\(\pm\)0.0 & 56.62 & 10.66 \\ pFedBayes [7] & 47.96\(\pm\)0.0 & 46.94\(\pm\)0.0 & 59.46\(\pm\)0.0 & 59.46\(\pm\)0.0 & 59.46\(\pm\)0.0 & 59.46\(\pm\)0.0 & 59.46\(\pm\)0.0 & 49.46\(\pm\)0.0 & 49.58\(\pm\)0.0 & 11.80\(\pm\)0.0 & 152.1\(\pm\)0.0 & 71.34 & 5.46 \\ FedAMP-M [7] & 60.04\(\pm\)0.0 & 66.79\(\pm\)0.0 & **58.63\(\pm\)0.0** & 68.72\(\pm\)0.0 & **59.22\(\pm\)0.0** & 59.31\(\pm\)0.0 & 72.21\(\pm\)0.0 & 67.23\(\pm\)0.0 & 69.53\(\pm\)0.0 & 31.00\(\pm\)0.0 & 17.68\(\pm\)0.0 & 19.65\(\pm\)0.0 & 10.06 \\ pFedBayes-M [7] & 59.04\(\pm\)0.0 & 15.35\(\pm\)0.0 & 53.21\(\pm\)0.0 & 67.03\(\pm\)0.0 & 58.96\(\pm\)0.0 & 59.41\(\pm\)0.0 & 57.11\(\pm\)0.0 & 67.18\(\pm\)0.0 & 67.28\(\pm\)0.0 & 79.13\(\pm\)0.0 & 16.53\(\pm\)0.0 & 66.61 & 10.96 \\ pFedBayes-M [7] & 58.55\(\pm\)0.0 & 60.08\(\pm\)0.0 & 60.06\(\pm\)0.0 & 57.75\(\pm\)0.0 & 59.46\(\strategy \(\mathbf{m}\mathbf{h}\) as shown in Table 2. The relationship among the three strategies mentioned in Eq. (14) is that \(\mathbf{m}\mathbf{h}\) consists of \(\mathbf{lg}\) and \(\mathbf{m}\mathbf{e}\mathbf{g}\). Moreover, pFedMe can be regarded in our framework as the one which takes the spherical Gaussian as prior and uses vanilla prior selection strategy \(\mu_{i}=I\) without personalization. Thus, pFedMe and the three implementations of pFedBreD are compared. The results reveal the instability of our implementation \(\mathbf{lg}\) and the introduction of \(\mathbf{m}\mathbf{e}\mathbf{g}\) on difficult tasks is about the same as not introducing it. However, introducing both \(\mathbf{lg}\) and \(\mathbf{m}\mathbf{e}\mathbf{g}\) (i.e., \(\mathbf{m}\mathbf{h}\)) together shows remarkable performance. This indicates that \(\mathbf{lg}\) and \(\mathbf{m}\mathbf{e}\mathbf{g}\) complement each other. **To explain these results**, by observing the error bars, in most of the settings, \(\mathbf{m}\mathbf{e}\mathbf{g}\) is significantly more stable compared to methods that do not use personalized priors, while \(\mathbf{lg}\) is relatively less stable. Based on this observation, we have reason to believe that \(\mathbf{m}\mathbf{e}\mathbf{g}\) weakens the influence of potential noise, while \(\mathbf{lg}\) introduces new noise. Therefore, we can infer that while the mean parameters are steadily biased towards the personalized model, the introduction of new noise finds a path that is more likely to escape from local optima or saddle points, based on implicit regularization [61, 58, 57].

Generalized Coherence Analysis of Information Injection and ExtractionThe generalized coherence estimate (GCE) [25] of vectors from personalized to local model (_i.e._, the envelope gradients in pFedMe and ours) among clients on each global epoch are shown in Figure 2. The smaller the GCE, the less coherent the envelope gradient between individual nodes and the greater the diversity of information in the global model update. As shown in Figure 2, we can observe that during the convergence phase, using a personalized prior method has significantly greater information diversity than not using a personalized prior method, which proves the success of injecting personalized prior knowledge into the global model and extracting local knowledge from the local training.

Variable-Control Analysis of RobustnessWe analyze the impact of aggregation noise and data heterogeneity [29] on our method, mainly \(\mathbf{m}\mathbf{h}\), by controlling variables. Results are in Table 3 and Table 4. (Details are in Appendix C.8.) We test the performance of global model on different aggregation ratios, where all hyper-parameters except for the aggregation ratios are fixed. Meanwhile, we test the performance of both global and the personalized model on different data heterogeneity settings, where full aggregation (sample client equals total number of clients, \(S=N\)) and one-step local update (local epoch \(R=1\)) are employed to get rid of the effects of aggregation noise and client drift. The experiments demonstrate the instability of the global model in \(\mathbf{m}\mathbf{h}\) at small aggregation ratios, which most of the other PFL methods have, by comparing their performances on different aggregation numbers. Comparing to the baselines, the experiments also demonstrate the relative robustness of our method to extreme data heterogeneity.

\begin{table}
\begin{tabular}{l c c c c c c c c c c} \hline \multirow{2}{*}{**Methods**} & \multicolumn{2}{c}{FEMNIST} & \multicolumn{2}{c}{FMNIST} & \multicolumn{2}{c}{CFAP-10} & \multicolumn{2}{c}{Semi.40} & \multicolumn{2}{c}{Statistics} & \multirow{2}{*}{AC4PP} \\  & MCL & DNN & MCL & DNN & & MCL & DNN & & \multicolumn{2}{c}{CNN} & \multicolumn{2}{c}{LSTM} & \multicolumn{1}{c}{Avg} \\ \hline Non-PP & \(507.8_{\pm 0.10}\) & \(53.6_{\pm 0.12}\) & \(97.6_{\pm 0.03}\) & \(98.6_{\pm 0.02}\) & \(88.2_{\pm 0.05}\) & \(90.5_{\pm 0.04}\) & \(72.2_{\pm 0.06}\) & \(69.4_{\pm 0.02}\) & \(77.6\) & \(65.1\) & None \\ \hline \(\mathbf{lg}\) (ours) & \(50.8_{\pm 0.05}\) & \(49.1_{\pm 0.33}\) & \(98.9_{\pm 0.02}\) & \(98.4_{\pm 0.02}\) & \(88.4_{\pm 0.01}\) & \(91.9_{\pm 0.00}\) & \(65.7_{\pm 0.06}^{\dagger}\) & \(60.7_{\pm 0.1}\) & \(75.3\) & \(58.5\) & Grad \(\times\) R \\ meg (ours) & \(50.3_{\pm 0.07}\) & \(53.9_{\pm 0.06}\) & \(97.8_{\pm 0.00}\) & \(98.6_{\pm 0.01}\) & \(88.4_{\pm 0.01}\) & \(90.6_{\pm 0.01}\) & \(78.3_{\pm 0.06}\) & \(69.4_{\pm 0.02}\) & \(72.9\) & \(65.7\) & Adl. \(\times\) R \\ m (ours) & \(\mathbf{56.3}_{\pm 0.00}\) & \(\mathbf{64.9}_{\pm 0.00}\) & \(\mathbf{98.4}_{\pm 0.01}\) & \(\mathbf{98.7}_{\pm 0.00}\) & \(\mathbf{89.9}_{\pm 0.02}\) & \(\mathbf{92.0}_{\pm 0.01}\) & \(\mathbf{79.4}_{\pm 0.00}\) & \(\mathbf{81.5}\) & \(\mathbf{72.1}\) & Both above \\ \hline \end{tabular}
\end{table}
Table 2: Average local test accuracy of personalized model (%) in ablation experiments.(\(\uparrow\)\(\downarrow\): average accuracy is increased/reduced; AC4PP: Additional cost for personalized prior; Grad. and Add.: cost about calculate gradient and addition; Other notations are the same in Table 1.)Deviation Analysis of Personalization

Deviation represents the difference between an individual and the mean value. We use the deviation of the loss function to reflect the personalization. **On global test**, the lower the deviation, the better the personalized model performance on the corresponding local data. **On local test**, the model is only tested on its own dataset, and because of multiple local iterations, the local test deviation converges to almost the same value, as shown in MNIST-MCLR-L and MNIST-DNN-L in Figure 3. Furthermore, since the local test has a loss of 0 on missing classes, a higher deviation on missing classes reflects a lower mean on these classes. Thus, the lower loss in local testing and better performance are reflected from both of the almost equal deviation in local testing and the higher deviation on missing class. **Summary:** based on Figure 3, we can see that our method has higher deviation on missing classes in local testing and lower deviation in global testing. This means that our method has better personalized performance.

## 7 Conclusion and Discussion

ConclusionTo address the issue of neglecting client-sampling information while providing prior knowledge to local training via direct use of a global model, we propose a general concept: the personalized prior. In this paper, we propose a general framework, pFedBreD, for exploring PFL strategies under the SX-family prior assumption and computation, the RMD to explicitly extract the prior information, and three optional meta-step strategies to personalize the prior. We analyze our proposal both theoretically and empirically. Our strategy **mh** shows remarkable improvement in personalization and robustness to data heterogeneity on non-i.i.d. datasets and the LEAF benchmark [11] with MCLR / DNN / CNN / LSTM as inferential model, which conduct convex / non-convex problems, and image / language benchmarks.

Limitations and Future WorkAlthough **mh** shows remarkable performance and robustness, there is still instability in the global model with aggregation noise. Furthermore, it should be noted that the superficial reason for the improvement of **mh** seems to be that \(\eta_{\alpha}\) and \(\eta\) and (which are similar to each other) are used simultaneously, resulting in a magnitude in **mh** that is twice as large as the ones in the other two implementations and leading to better performance. However, empirically, simply doubling \(\eta_{\alpha}\) in **lg** or \(\eta\) in **meg** does not improve performance, and using one more **meg** step used in **lg** significant improvement. Our theoretical analysis cannot explain this phenomenon, and more detailed modeling is needed.

\begin{table}
\begin{tabular}{l c c c c c c} \hline \hline \multicolumn{1}{c}{**Numes**} & small & \multicolumn{1}{c}{\(\longrightarrow\)} & large & Avg \\ \hline FedAvg-**G** & 18.2 & 14.8 & 14.5 & 11.9 & 11.3 & 11.2 & 13.7 \\ pFedMe-**P** & 89.5 & 58.2 & 24.2 & 12.3 & 11.8 & 10.6 & 34.4 \\ pFedMe-**G** & 17.0 & 14.3 & 14.1 & 12.3 & 10.8 & 10.9 & 13.2 \\
**mh**(ours)-**P** & **89.6** & **58.7** & **25.2** & **13.1** & 11.1 & 11.0 & **34.8** \\
**mh**(ours)-**G** & 17.1 & 14.6 & 14.6 & 12.4 & **11.9** & **11.9** & 13.8 \\ \hline \end{tabular}
\end{table}
Table 4: The local test accuracy (%) of the personalized model on FMNIST-DNN setting with different data heterogeneity (Non-IID) settings \(\alpha\in\{0.01,0.1,1,10,100,1000\}\)(\(\alpha\downarrow\), Non-IID\(\uparrow\)) [29]. The **bolded** means the best.

Figure 3: The loss deviation of experiments in Section 6 on the first client, whose major data are on \(0^{th}\) classes. The lower deviation of the available class on global tests and the higher deviation of the unavailable class on local tests demonstrate the superior personalization ability of our methods.

## Acknowledge

This work is supported by the Key Program of National Science Foundation of China (Grant No. 61836006) from College of Computer Science (Sichuan University) and Engineering Research Center of Machine Learning and Industry Intelligence (Ministry of Education), Chengdu 610065, P. R. China. This research is also supported by the National Research Foundation, Singapore under its AI Singapore Programme (AISG Award No: AISG2-PhD-2021-08-008).

## References

* [1]I. Achituve, A. Shamsian, A. Navon, G. Chechik, and E. Fetaya (2021) Personalized federated learning with gaussian processes. Proceedings of the NeurIPS34, pp. 8392-8406. Cited by: SS1.
* [2]C. Andrieu, N. De Freitas, A. Doucet, and M. I. Jordan (2003) An introduction to mcmc for machine learning. MACH LEARN50 (1), pp. 5-43. Cited by: SS1.
* [3]M. Ghuhan Arivazhagan, V. Aggarwal, A. Kimar Singh, and S. Choudhary (2019) Federated learning with personalization layers. arXiv:1912.00818. Cited by: SS1.
* [4]Y. Arjevani, O. Shamir, and N. Srebro (2020-08 Feb 11 Feb 2020) A tight convergence analysis for stochastic gradient descent with delayed updates. In Proceedings of the ICALT, pp. 111-132. Cited by: SS1.
* [5]U. M. Aivodji, S. Gambs, and A. Martin (2019) Iotfla : a secured and privacy-preserving smart home architecture implementing federated learning. In 2019 IEEE SPW, pp. 175-180. Cited by: SS1.
* [6]A. Banerjee, S. Merugu, I. S. Dhillon, J. Ghosh, and J. Lafferty (2005) Clustering with bregman divergences. JMLR6 (10). Cited by: SS1.
* [7]H. Bauschke, P. Combettes, and D. Noll (2006) Joint minimization with alternating bregman proximity operators. PAC J OPTIM. Cited by: SS1.
* [8]H. H. Bauschke, J. M. Borwein, and P. L Combettes (2003) Bregman monotone optimization algorithms. SIAM J CONTROL OPTIM42 (2), pp. 596-636. Cited by: SS1.
* [9]A. Ben-Tal, L. El Ghaoui, and A. Nemirovski (2009) Robust optimization. Vol. 28, Princeton university press. Cited by: SS1.
* [10]L. M. Bregman (1967) The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming. COMP MATH MATH PHYS+7 (3), pp. 200-217. Cited by: SS1.
* [11]S. Caldas, S. M. K. Duddu, P. Wu, T. Li, J. Konecny, H. Brendan McMahan, V. Smith, and A. Talwalkar (2018) Leaf: a benchmark for federated settings. arXiv:1812.01097. Cited by: SS1.
* [12]G. Cheng, K. Chadha, and J. Duchi (2022) Federated asymptotics: a model to compare federated learning algorithms. arXiv:2108.07313. Cited by: SS1.
* [13]R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa (2011) Natural Language Processing (Almost) from Scratch. NLP. Cited by: SS1.
* [14]K. Csillery, M. G.B. Blum, O. E. Gaggiotti, and O. Francois (2010) Approximate bayesian computation (abc) in practice. TRENDS ECOL EVOL25 (7), pp. 410-418. Cited by: SS1.
* [15]A. P. Dempster, N. M. Laird, and D. B. Rubin (1977) Maximum likelihood from incomplete data via the em algorithm. J R STAT SOC B39 (1), pp. 1-22. Cited by: SS1.
* [16]J. Deng, W. Dong, R. Socher, L. Li, K. Li, and L. Fei-Fei (2009) Imagenet: a large-scale hierarchical image database. In the Proceedings of the CVPR, pp. 248-255. Cited by: SS1.

* Dieuleveut et al. [2021] Aymeric Dieuleveut, Gersende Fort, Eric Moulines, and Genevieve Robin. Federated-em with heterogeneity mitigation and variance reduction. _Proceedings of the NeurIPS_, 34:29553-29566, 2021.
* Dinh et al. [2021] Canh T Dinh, Tung T Vu, Nguyen H Tran, Minh N Dao, and Hongyu Zhang. Fedu: A unified framework for federated multi-task learning with laplacian regularization. _arXiv:2102.07148_, 2021.
* Fallah et al. [2020] Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. On the convergence theory of gradient-based model-agnostic meta-learning algorithms. In _Proceedings of the AISTATS_, pages 1082-1092. PMLR, 2020.
* Fallah et al. [2020] Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning with theoretical guarantees: A model-agnostic meta-learning approach. _Proceedings of the NeurIPS_, 33:3557-3568, 2020.
* Finn et al. [2017] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks. In _Proceedings of the ICML_, pages 1126-1135, July 2017. ISSN: 2640-3498.
* Friedman and Shimony [1971] Kenneth Friedman and Abner Shimony. Jaynes's maximum entropy prescription and probability theory. _J STAT PHYS_, 3(4):381-384, 1971.
* Gelman and Shalizi [2013] Andrew Gelman and Cosma Rohilla Shalizi. Philosophy and the practice of bayesian statistics. _BRIT J MATH STAT PSY_, 66(1):8-38, 2013.
* Genest and Zidek [1986] Christian Genest and James V Zidek. Combining probability distributions: A critique and an annotated bibliography. _STAT SCI_, 1(1):114-135, 1986.
* Gish and Cochran [1988] H. Gish and D. Cochran. Generalized coherence (signal detection). In _ICASSP-88_, pages 2745-2748 vol.5, 1988.
* Gower et al. [2019] Robert Mansel Gower, Nicolas Loizou, Xun Qian, Alibek Sailanbayev, Egor Shulgin, and Peter Richtarik. SGD: General Analysis and Improved Rates. In _Proceedings of the ICML_, pages 5200-5209, May 2019. ISSN: 2640-3498.
* Hochreiter and Schmidhuber [1997] Sepp Hochreiter and Jurgen Schmidhuber. Long short-term memory. _NEURAL COMPUT_, 9(8):1735-1780, 1997.
* Hosang et al. [2015] Jan Hosang, Mohamed Omran, Rodrigo Benenson, and Bernt Schiele. Taking a deeper look at pedestrians. In _Proceedings of the CVPR_, pages 4073-4082, 2015.
* Hsu et al. [2019] Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the Effects of Non-Identical Data Distribution for Federated Visual Classification. _arXiv:1909.06335_, 2019.
* Huang et al. [2023] Chenxi Huang, Liang Xie, Yibo Yang, Wenxiao Wang, Binbin Lin, and Deng Cai. Neural collapse inspired federated learning with non-iid data. _arXiv:22303.16066_, 2023.
* Huang et al. [2021] Yutao Huang, Lingyang Chu, Zirui Zhou, Lanjun Wang, Jiangchuan Liu, Jian Pei, and Yong Zhang. Personalized cross-silo federated learning on non-iid data. _AAAI_, 35:7865-7873, 2021.
* Imteaj et al. [2022] Ahmed Imteaj, Urmish Thakker, Shiqiang Wang, Jian Li, and M. Hadi Amini. A survey on federated learning for resource-constrained iot devices. _IEEE INTERNET THINGS_, 9(1):1-24, 2022.
* Jaynes [1957] Edwin T Jaynes. Information theory and statistical mechanics. _PHYS REV_, 106(4):620, 1957.
* Jiang et al. [2020] Ji Chu Jiang, Burak Kantarci, Sema Oktug, and Tolga Soyata. Federated learning in smart city sensing: Challenges and opportunities. _Sensors_, 20(21), 2020.
* Jiang et al. [2019] Yihan Jiang, Jakub Konecny, Keith Rush, and Sreeram Kannan. Improving federated learning personalization via model agnostic meta learning. _arXiv:1909.12488_, 2019.

* [36] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurelien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open problems in federated learning. _Foundations and Trends(r) in Machine Learning_, 14(1-2):1-210, 2021.
* [37] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In _Proceedings of the ICML_, pages 5132-5143. PMLR, 2020.
* [38] Robert E Kass and Larry Wasserman. The selection of prior distributions by formal rules. _J AM STAT ASSOC_, 91(435):1343-1370, 1996.
* [39] A Krizhevsky. Learning multiple layers of features from tiny images. _Master's thesis, University of Tront_, 2009.
* [40] Frederik Kunstner, Raunak Kumar, and Mark Schmidt. Homeomorphic-invariance of em: Non-asymptotic convergence in kl divergence for exponential families via mirror descent. In _Proceedings of the AISTATS_, pages 3295-3303. PMLR, 2021.
* [41] L. Le Cam. Maximum Likelihood: An Introduction. _INT STAT REV_, 58(2):153-171, 1990. Wiley, ISI.
* [42] Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. _Proceedings of the IEEE_, 86(11):2278-2324, 1998.
* [43] Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang, Yuan Li, Xu Liu, and Bingsheng He. A survey on federated learning systems: Vision, hype and reality for data privacy and protection. _IEEE T KNOWLED DATA EN_, 35(4):3347-3366, 2023.
* [44] Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. Ditto: Fair and robust federated learning through personalization. In _Proceedings of the ICML_, pages 6357-6368. PMLR, 2021.
* [45] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated Optimization in Heterogeneous Networks. _Proceedings of MLSys_, 2:429-450, March 2020.
* [46] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the Convergence of FedAvg on Non-IID Data. In _Proceedings of the ICLR_, April 2020.
* [47] Zexi Li, Xinyi Shang, Rui He, Tao Lin, and Chao Wu. No fear of classifier biases: Neural collapse inspired federated learning with synthetic and fixed classifier. _arXiv:2303.10058_, 2023.
* [48] Liangxi Liu, Feng Zheng, Hong Chen, Guo-Jun Qi, Heng Huang, and Ling Shao. A bayesian federated learning framework with online laplace approximation. _arXiv:2102.01936_, 2021.
* [49] Guodong Long, Yue Tan, Jing Jiang, and Chengqi Zhang. Federated Learning for Open Banking. In Qiang Yang, Lixin Fan, and Han Yu, editors, _Federated Learning: Privacy and Incentive_, pages 240-254. Springer International Publishing, Cham, 2020.
* [50] Christos Louizos, Matthias Reisser, Joseph Soriaga, and Max Welling. An expectation-maximization perspective on federated learning. _arXiv:2111.10192_, 2021.
* [51] Andrew L Maas, Awni Y Hannun, Andrew Y Ng, et al. Rectifier nonlinearities improve neural network acoustic models. In _Proceedings of the ICML_, volume 30, page 3. Citeseer, 2013.
* [52] Othmane Marfou, Giovanni Neglia, Aurelien Bellet, Laetitia Kameni, and Richard Vidal. Federated Multi-Task Learning under a Mixture of Distributions. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P. S. Liang, and J. Wortman Vaughan, editors, _Proceedings of the NeurIPS_, volume 34, pages 15434-15447, 2021.
* [53] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In _Proceedings of the AISTATS_, pages 1273-1282. PMLR, 2017.

* [54] H Brendan McMahan. A survey of algorithms and analysis for adaptive online learning. _The JMLR_, 18(1):3117-3166, 2017.
* [55] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed Representations of Words and Phrases and their Compositionality. In C. J. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, _Proceedings of the NeurIPS_, volume 26, 2013.
* [56] Thomas P. Minka. Expectation propagation for approximate bayesian inference. _arXiv:1301.2294_, 2001.
* [57] Behnam Neyshabur. Implicit regularization in deep learning. _arXiv:1709.01953_, 2017.
* [58] Behnam Neyshabur, Ryota Tomioka, Ruslan Salakhutdinov, and Nathan Srebro. Geometry of optimization and implicit regularization in deep learning. _arXiv:1705.03071_, 2017.
* [59] Dinh C. Nguyen, Ming Ding, Pubudu N. Pathirana, Aruna Seneviratne, Jun Li, and H. Vincent Poor. Federated learning for internet of things: A comprehensive survey. _IEEE COMMUN SURVEY TUT_, 23(3):1622-1658, 2021.
* [60] Alex Nichol, Joshua Achiam, and John Schulman. On first-order meta-learning algorithms. _arXiv:1803.02999_, 2018.
* [61] Noam Razin, Asaf Maman, and Nadav Cohen. Implicit regularization in tensor factorization. In Marina Meila and Tong Zhang, editors, _Proceedings of the ICML_, volume 139 of _PMLR_, pages 8913-8924, 18-24 Jul 2021.
* [62] Abraham. Savitzky and M. J. E. Golay. Smoothing and Differentiation of Data by Simplified Least Squares Procedures. _ANAL CHEM_, 36(8):1627-1639, July 1964. American Chemical Society.
* [63] Teddy Seidenfeld. Why i am not an objective bayesian; some reflections prompted by rosenkrantz. _THEOR DECIS_, 11(4):413-440, 1979.
* [64] Aviv Shamsian, Aviv Navon, Ethan Fetaya, and Gal Chechik. Personalized federated learning using hypernetworks. In _Proceedings of the ICML_, pages 9489-9502. PMLR, 2021.
* [65] Canh T Dinh, Nguyen Tran, and Josh Nguyen. Personalized federated learning with moreau envelopes. _Proceedings of the NeurIPS_, 33:21394-21405, 2020.
* [66] Alysa Ziying Tan, Han Yu, Lizhen Cui, and Qiang Yang. Towards personalized federated learning. _TNNLS_, 2022.
* [67] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. _arXiv:1708.07747_, 2017.
* [68] Jian Xu, Xinyi Tong, and Shao-Lun Huang. Personalized federated learning with feature alignment and classifier collaboration. In _Proceedings of the ICLR_, 2023.
* [69] Jie Xu, Benjamin S. Glicksberg, Chang Su, Peter Walker, Jiang Bian, and Fei Wang. Federated Learning for Healthcare Informatics. _JHIR_, 5(1):1-19, March 2021.
* [70] Beining Yang, Kai Wang, Qingyun Sun, Cheng Ji, Xingcheng Fu, Hao Tang, Yang You, and Jianxin Li. Does graph distillation see like vision dataset counterpart? In _Proceedings of the NeurIPS_, 2023.
* [71] Liu Yang, Ben Tan, Vincent W. Zheng, Kai Chen, and Qiang Yang. Federated Recommendation Systems. In Qiang Yang, Lixin Fan, and Han Yu, editors, _Federated Learning: Privacy and Incentive_, pages 225-239. Springer International Publishing, Cham, 2020.
* [72] Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept and applications. _TIST_, 10(2), jan 2019.
* [73] Lei Zhang, Guanyu Gao, and Huaizheng Zhang. Spatial-temporal federated learning for lifelong person re-identification on distributed edges. _arXiv:2207.11759_, 2022.

* [74] Lin Zhang, Li Shen, Liang Ding, Dacheng Tao, and Ling-Yu Duan. Fine-tuning global model via data-free knowledge distillation for non-iid federated learning. In _Proceedings of the CVPR_, pages 10174-10183, June 2022.
* [75] Michael Zhang, Karan Sapra, Sanja Fidler, Serena Yeung, and Jose M Alvarez. Personalized federated learning with first order model optimization. In _Proceedings of the ICLR_, 2020.
* [76] Wei Zhang, Xiang Li, Hui Ma, Zhong Luo, and Xu Li. Federated learning for machinery fault diagnosis with dynamic validation and self-supervision. _KBS_, 213:106679, 2021.
* [77] Xu Zhang, Yinchuan Li, Wenpeng Li, Kaiyang Guo, and Yunfeng Shao. Personalized federated learning via variational bayesian inference. In _Proceedings of the ICML_, pages 26293-26310. PMLR, 2022.
* [78] Yifan Zhang, Daquan Zhou, Bryan Hooi, Kai Wang, and Jiashi Feng. Expanding small-scale datasets with guided imagination. _arXiv:2211.13976_, 2022.
* [79] Pan Zhou, Xiaotong Yuan, Huan Xu, Shuicheng Yan, and Jiashi Feng. Efficient meta learning via minibatch proximal update. _Proceedings of the NeurIPS_, 32, 2019.
* [80] Yuhao Zhou, Mingjia Shi, Yuanxi Li, Yanan Sun, Qing Ye, and Jiancheng Lv. Communication-efficient federated learning with single-step synthetic features compressor for faster convergence. In _Proceedings of the ICCV_, pages 5031-5040, 2023.