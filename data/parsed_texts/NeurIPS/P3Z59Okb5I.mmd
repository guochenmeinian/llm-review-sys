# EvoFed: Leveraging Evolutionary Strategies for Communication-Efficient Federated Learning

 Mohammad Mahdi Rahimi Hasnain Irshad Bhatti Younghyun Park Humaira Kousar Jaekyun Moon KAIST

{mahi,hasnain,dnffk7369,humanikousar32}@kaist.ac.kr

jmoon@kaist.edu

###### Abstract

Federated Learning (FL) is a decentralized machine learning paradigm that enables collaborative model training across dispersed nodes without having to force individual nodes to share data. However, its broad adoption is hindered by the high communication costs of transmitting a large number of model parameters. This paper presents EvoFed, a novel approach that integrates Evolutionary Strategies (ES) with FL to address these challenges. EvoFed employs a concept of 'fitness-based information sharing', deviating significantly from the conventional model-based FL. Rather than exchanging the actual updated model parameters, each node transmits a distance-based similarity measure between the locally updated model and each member of the noise-perturbed model population. Each node, as well as the server, generates an identical population set of perturbed models in a completely synchronized fashion using the same random seeds. With properly chosen noise variance and population size, perturbed models can be combined to closely reflect the actual model updated using the local dataset, allowing the transmitted similarity measures (or fitness values) to carry nearly the complete information about the model parameters. As the population size is typically much smaller than the number of model parameters, the savings in communication load is large. The server aggregates these fitness values and is able to update the global model. This global fitness vector is then disseminated back to the nodes, each of which applies the same update to be synchronized to the global model. Our analysis shows that EvoFed converges, and our experimental results validate that at the cost of increased local processing loads, EvoFed achieves performance comparable to FedAvg while reducing overall communication requirements drastically in various practical settings.

## 1 Introduction

Federated Learning (FL) provides a decentralized machine learning framework that enables model training across many devices, known as clients, without needing to collect and process sensitive client data on the centralized server [1]. The typical FL process begins with each client downloading an identical initialized model from a central server, performing model updates with local data, and then uploading the updated local model for the next communication round. Subsequently, the server combines the uploaded models to refine the global model, typically using a technique like FedAvg [2]. This iterative cycle repeats for a fixed number of rounds, ensuring collaborative model improvement across clients.

Although FL provides notable benefits, such as a certain level of privacy preservation and the utilization of diverse data sources, one of the major challenges associated with FL is the significantcommunication overhead involved in transmitting model updates between clients and the server, especially when dealing with models that have a large number of parameters.

Various strategies have been developed to mitigate the communication burden in FL. These techniques can be broadly classified into three categories: i) Compressing updates: sparsification [1], structured updates [3], and quantization [4; 5] reduce the size of transmitted model updates, ii) Local computation: performing multiple local epochs at the clients [6] lessens the frequency of communication with the server, and iii) Advanced aggregation methods and client selection: MOCHA [7] enhances the efficacy of update aggregation and [8; 9] reduce communication by only selecting a subset of clients to participate in each training round.

Existing FL techniques primarily rely on transmitting gradient signals or model updates, which are computed through backpropagation (BP). On the other hand, Evolutionary Strategies (ES) [10; 11; 12] update model parameters by utilizing fitness values obtained from evaluating a population of models. This approach eliminates the need for a gradient signal, as depicted in Fig. 1. Recent advances in neuroevolution have shown promise in supervised settings and competitive performance with reinforcement learning in control tasks [13; 14; 15; 16; 17; 18]. In this context, ES offers a distinct advantage compared to traditional BP methods. This paradigm shift opens up the possibility of searching for novel solutions beyond the gradient-based methods. However, it is critical to note that ES, despite its potential, still lags behind gradient-based methods in certain problems like supervised learning. Fig. 2(a) reveals the performance gap between ES and BP. This emphasizes the need for a balanced approach that would leverage the strengths of both ES and gradient-based methods to achieve optimal results.

Our proposed method operates on the premise of incorporating high-quality gradient signals into the evaluation process of ES. The process can be formalized as follows:

Given a base model, denoted by \(\theta\), we instantiate a population \(P\) comprised of \(N\) model samples. Each individual sample, \(\theta^{i}\), is derived by adding random perturbations to \(\theta\). Unlike traditional ES, where the fitness of \(\theta^{i}\) corresponds to its performance on the task, we instead assess the fitness of each sample \(\theta^{i}\) by measuring its similarity to \(\theta^{\prime}\), the model parameters updated through gradient descent steps. This operation effectively exploits the gradient signal to construct a fitness vector, a process we term Population-Based Gradient Encoding (PBGE). Fig. 2(b) shows the results of a representative experimental setting where PBGE is able to follow BP closely on the FMNIST dataset while maintaining an effective compression rate of over 98.8%. In particular, this method significantly outperforms sparsification strategies at equivalent compression rates.

In the context of FL, the gradient signal can be encoded into a fitness vector for the population of models and communicated to the server. For global synchronization, a well-established approach like FedAvg would involve reconstruction and aggregation of the clients' models and sharing of the aggregated model with the clients. However, by utilizing shared random seeds, we can ensure uniformity in the generated populations between clients and the server. This allows us to transmit and aggregate only the small fitness vectors without reconstructing the models, reinforcing communication efficiency. In addition, there is an advantage in implementing extra privacy measures. When encryption is desired, the required overhead would be much smaller with the fitness vectors than with the model parameter vectors because of the size difference. A brief overview of EvoFed is shown in Fig. 3 (the detailed methodology is provided in Section 4).

Figure 1: ES follows an iterative ask, evaluate, and tell approach for optimization. The strategy starts by generating candidate solutions of a base model(_ask_), which are then assessed using a fitness measure (_evaluate_). The base model is updated towards a better solution using the evaluation results (_tell_).

Figure 2: Test accuracy on FMNIST dataset comparing (a) ES against BP, and (b) PBGE with BP and Sparse with 98.8% compression.

**Contributions.** To summarize, our main contribution is to introduce a novel concept of Population-Based Gradient Encoding (PBGE), which allows an accurate representation of the large local gradient vector using a relatively small fitness vector, significantly reducing the communication burden as well as the encryption overhead in FL environments. We also propose and verify the EvoFed framework that integrates PBGE into federated learning based on the exchange and aggregation of the fitness vectors between clients and the server.

Our approach achieves similar performance to FedAvg on both FMNIST and CIFAR-10 datasets. The advantage is that our scheme achieves very high compression, exceeding 98.8% on FMNIST and 99.7% on CIFAR-10 in key practical settings. Significantly, our EvoFed model also outperforms traditional compression methods, offering superior results at similar compression rates. The price we pay is the overhead of generating a population of perturbed models and computing similarity measures. This overhead could be substantial in the form of increased local processing time depending on the size of the population, but the client computational load can be traded with local memory space by employing parallel processing. In addition, as discussed later, reduce population size without affecting performance.

## 2 Related Work

**Federated Learning.** Several techniques have been proposed to alleviate the communication overhead in FL, such as model compression [19; 1; 20], distillation techniques [21; 22; 23; 24; 25], and client update subsampling [26; 27]. However, these approaches often come with trade-offs, including increased convergence time, lower accuracy, or additional computational requirements. More importantly, they still require the exchange of model parameters, which requires substantial communication bandwidth. Furthermore, [28] shows that the gradient sparsity of all participants has a negative impact on global convergence and communication complexity in FL.

**Evolutionary Strategies.** ES are black-box optimization algorithms inspired by biological evolution [29]. ES algorithms iteratively refine a population of solutions based on fitness evaluations. Natural Evolution Strategies (NES) is a specific variant of ES [30; 12; 31; 32; 33; 34; 35]. Within the NES framework, the distribution \(p_{\psi}(\theta)\), parameterized by \(\psi\), is adopted to represent the population and maximize the average objective value \(\mathbb{E}_{\theta\sim p_{\psi}}[f(\theta)]\) via stochastic gradient ascent, where \(f(\theta)\) is the fitness function. NES algorithms leverage a score function estimator as in [10]. Our method follows the guidelines provided by [36], where the parameter distribution \(p_{\psi}\) is a factored Gaussian. Accordingly, we can represent \(\mathbb{E}_{\theta\sim p_{\psi}}[f(\theta)]\) using the mean parameter vector \(\theta\), such that \(\mathbb{E}_{\theta\sim p_{\psi}}[f(\theta)]=\mathbb{E}_{\epsilon\sim\mathcal{ N}(0,I)}[f(\theta+\sigma\epsilon)]\). Given a differentiable function estimator, the well-known conversion procedure allows optimization over \(\theta\) to be rewritten as (see, for example, [37; 11; 38])

\[\nabla_{\theta}\mathbb{E}_{\epsilon\sim\mathcal{N}(0,I)}[f(\theta+\sigma \epsilon)]=\frac{1}{\sigma}\mathbb{E}_{\epsilon\sim\mathcal{N}(0,I)}\{f( \theta+\sigma\epsilon)\epsilon\}.\] (1)

The strategy of sharing seeds for random number generators to synchronize parallel processes and maintain consistency is a well-established practice in areas ranging from parallel simulations to cryptographic protocols [39]. The appeal of shared random seeds stems from their ability to offer deterministic randomness, ensuring that multiple entities, operating independently, can produce synchronized and identical random outputs. Within the realm of ES, this concept was effectively harnessed by [36] to address the challenge of scalability. We also utilize the shared random seeds to

Figure 3: Overview of the proposed EvoFed: (1) Using the shared random seed, each client generates a population of perturbations around the local model. Each client also performs a gradient update of the local model using the local data as in conventional FL. (2) Each client evaluates the fitness of each perturbed model with respect to the updated model. The fitness values are communicated to the server. (3) The server aggregates the fitness values. Clients update their local models using broadcast aggregated fitness.

scale down the communication load in a distributed setting. However, the key difference is that the work of [36] distributes the perturbations into multiple workers dealing with a single global objective, whereas our method generates identical perturbations across all clients, with each having a distinct objective. An important consequence is that with our method, each client only needs to communicate \(N\) fitness values to update the model, instead of \(MN\) values in [36] with \(M\) denoting the number of nodes, enabling scalability regardless of the number of clients.

**Federated Learning and Evolutionary Strategies.** Several studies have explored the optimization of FL using ES. For instance, [40] introduced an evolutionary approach for network architecture search (NAS) in real-time FL, which minimizes local payload while optimizing model performance. Sparse evolutionary training (SET) [41] substitutes fully connected layers in neural networks with sparse layers to decrease the number of model parameters. Furthermore, [42] presented the SET algorithm that optimizes neural networks in FL via a bi-objective method to maximize accuracy performance while minimizing communication overhead. Additionally, [43] introduces the MOEA/D framework [44] to the environment of FL and FLEA [45] utilized Evolutionary Algorithms in FL setup at the client-level to evolve models.

While these studies have made significant contributions, the present work establishes a unique way of using ES as a method to reduce communication overhead in FL by transmitting fitness values instead of model parameters. In particular, the new gradient-driven fitness function essentially separates our work from the traditional utilization of ES for compression.

## 3 Population-Based Gradient Encoding

This work focuses on the process of encoding gradient information through an identical population of models generated at both ends of some network link. Population distribution is a zero mean isotropic multivariate Gaussian with fixed covariance \(\sigma^{2}I\). We also adopt'mirrored sampling' [46; 47] for variance reduction where the Gaussian noise vector \(\epsilon\) is instantiated with pairs of perturbations \(\epsilon\), \(-\epsilon\).

Given the reference point \(\theta^{\prime}=\theta-\eta\nabla L(\theta)\) where \(\eta\) is the learning rate in the BP-based gradient update and \(\nabla L(\theta)\) represents the gradient derived from the data, we define the fitness function \(f(\theta)\) to measure the similarity between the model parameters \(\theta\) and \(\theta^{\prime}\): \(f(\theta)=-||\theta-\theta^{\prime}||_{2}^{2}\). This choice ensures that the gradient of the expectation, \(\nabla_{\theta}\mathbb{E}_{\epsilon\sim\mathcal{N}(0,I)}[f(\theta+\sigma \epsilon)]\), aligns with the actual gradient \(\nabla L(\theta)\), effectively encoding the gradient information in the fitness values:

\[\nabla_{\theta}\mathbb{E}_{\epsilon\sim\mathcal{N}(0,I)}[-||(\theta+\sigma \epsilon)-\theta^{\prime}||_{2}^{2}]=-\nabla_{\theta}||\theta-\theta^{\prime} ||_{2}^{2}=2(\theta-\theta^{\prime})\] (2)

where the first equality simply follows from the assumption that \(\epsilon\) is zero-mean. The visual representation of this process is illustrated in Fig. 4. Eq. 2 gives \(\theta^{\prime}=\theta-\frac{1}{2}\nabla_{\theta}\mathbb{E}_{\epsilon}[-||( \theta+\sigma\epsilon)-\theta^{\prime}||_{2}^{2}]\), and comparing with the BP operation \(\theta^{\prime}=\theta-\eta\nabla L(\theta)\), we have

\[\eta\nabla_{\theta}L(\theta)=\frac{1}{2}\nabla_{\theta}\mathbb{E}_{\epsilon \sim\mathcal{N}(0,I)}[-||(\theta+\sigma\epsilon)-\theta^{\prime}||_{2}^{2}].\]

Now also utilizing Eq. 1, we write

\[\eta\nabla_{\theta}L(\theta)=\frac{1}{2\sigma}\mathbb{E}_{\epsilon\sim \mathcal{N}(0,I)}\{f(\theta+\sigma\epsilon)\epsilon\}\] (3)

Figure 4: Illustration of one update step of typical ES and the proposed Population-Based Gradient Encoding (PBGE) strategy. **Left**: using loss value \(L(\theta)\) directly for the fitness \(f(\theta)\), as in existing ES, leads to an inherently noisy estimate of the gradient signal \(\nabla_{\theta}\mathbb{E}_{\epsilon}[f(\theta+\sigma\epsilon)]\) due to the noisy loss surface. **Right**: PBGE defines fitness as the distance to the updated model \(\theta^{\prime}\) obtained through BP (i.e., \(f(\theta)=-||\theta-\theta^{\prime}||_{2}^{2}\)). This enables the reliable estimate of \(\theta^{\prime}\) on the convex surface. By sampling a sufficient number of perturbations \(\epsilon_{i}\), a decent gradient signal can be obtained, which aligns to the true gradient signal \(\nabla_{\theta}L(\theta)\) computed from the BP.

where \(f\) is the specific distance-based fitness function defined above. Approximating the expectation by sampling, we further write

\[\eta\nabla_{\theta}L(\theta)\approx\frac{1}{2N\sigma}\sum_{i=1}^{N}f(\theta+ \sigma\epsilon_{i})\epsilon_{i}\] (4)

which shows how the gradient update information can be encoded using the fitness values \(f(\theta+\sigma\epsilon_{i})\) corresponding to the perturbations \(\epsilon_{i}\). Consequently, this removes the need to evaluate each perturbation with the dataset, as is done in existing ES, and the entire update process is encoded with low-cost distance measurement.

Finally, the update on \(\theta\) itself based on the fitness values is naturally given by

\[\theta^{\prime}\approx\theta+\frac{1}{2N\sigma}\sum_{i=1}^{N}f(\theta+\sigma \epsilon_{i})\epsilon_{i}\] (5)

allowing a remote model update based on the transmitted \(f(\theta+\sigma\epsilon_{i})\) values with the shared knowledge of the \(\epsilon_{i}\) values.

The implemented algorithm consistently executes three steps: (i) Compute the target \(\theta^{\prime}\) through gradient descent, (ii) Implement perturbations to the model parameters and assess the perturbed parameters by computing their Euclidean distance to \(\theta^{\prime}\), and (iii) Utilize the assessment results and encode the gradient with the fitness measures.

**Partitioning.** In the context of PBGE, the fitness function indicates the model distance, not the model performance on client data. This feature enables a unique partition-based approach for handling a large number of model parameters. Here, the parameters, flattened into a vector \(\theta\), are split into \(K\) partitions: \(\theta[1],\theta[2],...,\theta[K]\). Each partition is then effectively encoded individually using PBGE, which is advantageous when working with large models, as storing a large population of those may be burdensome for clients with limited memory. Partitioning allows us to compute \(K\) fitness values per each perturbation, providing \(K\) times more reference points to encode the gradient information given a population size. Hence, even with a small population size (requiring less memory), we achieve robust performance as validated by the empirical results provided in Supplementary Materials. Essentially, partitioning provides a tradeoff of memory with communication as more fitness values now need to be communicated per each perturbation. This partitioning process is visualized in Fig. 5. Notably, this partitioning technique can be used with any model architecture, regardless of its specific design, providing a practical and efficient means of compressing large models.

## 4 EvoFed

EvoFed operates on the principle that the evolutionary update step depends only on the fitness values given the perturbation samples. In the FL context, we can leverage this characteristic to devise an accurate yet communication-efficient strategy for model updates. This section provides a detailed exposition of our methodology, breaking it down into stages for clarity. This iterative process, as outlined in Algorithm 1, aims to gradually converge the model parameters at all nodes to an optimal solution while minimizing data transmission during each update. An overall view of our proposed methodology is depicted in Fig. 3.

Figure 5: Partition-based Model Parameter Compression. Illustration of dividing model parameters \(\theta\) into \(K\) partitions and compressing them individually using PBGE.

### Initial Setup

The initialization of the server and clients in EvoFed begins with the same baseline model, denoted by \(\theta_{0}\). A key assumption is that the server and all clients share the same seed (e.g., via broadcasting) for identical random population generation. This approach ensures consistent baseline models and populations across all nodes.

In this step, a population of candidate solutions (in this case, models) is generated by adding random perturbations to the current best solution (the baseline model). The generation of an \(i\)-th member of the model population can be formulated as follows:

\[\theta_{t}^{i}=\theta_{t}+\mathcal{N}(0,\sigma I)\] (6)

Here, \(\mathcal{N}(0,\sigma I)\) represents the perturbations sampled from a multivariate normal distribution with zero mean and a shared covariance matrix \(\sigma I\). We also denote the population at each node at any given time \(t\) as \(\mathbf{P}_{t}=\{\theta_{t}^{1},\theta_{t}^{2},...,\theta_{t}^{N}\}\), where \(\theta_{t}^{i}\) represents the \(i\)-th model in the population generated by adding the \(i\)-th perturbation to the baseline model parameters, and \(N\) is the size of the population.

### Local Updates and Fitness Evaluation

Each client node begins by executing BP on its local dataset, using the baseline model, \(\theta_{t}\), resulting in an updated model, \(\theta_{t}^{\prime}\). Following this, the fitness of each member \(\theta_{t}^{i}\) in the local population, \(\mathbf{P}_{t}\), is evaluated. This evaluation is done by measuring the similarity between \(\theta_{t}^{\prime}\) and \(\theta_{t}^{i}\). The L2 norm or Euclidean distance serves as the measure of this similarity. The fitness of \(\theta_{t}^{i}\) is represented as \(f(\theta_{t}^{i})\):

\[f(\theta_{t}^{i})=-||\theta_{t}^{\prime}-\theta_{t}^{i}||_{2}^{2}\] (7)

The process of local update and fitness evaluation is illustrated in Fig. 6. The fitness values are the only information that needs to be communicated among nodes. The fitness vectors are significantly smaller in size compared to the model parameter vectors, which helps reduce the communication overhead. Hence, each client sends a fitness vector, \(\mathbf{f}_{t}=\{f(\theta_{t}^{1}),f(\theta_{t}^{2}),...,f(\theta_{t}^{N})\}\) corresponding to all population members, to the server.

### Server-side Aggregation and Update

The server's responsibility is to aggregate the fitness values reported by all client nodes, forming a global fitness vector \(\mathbf{F}_{t}\) comprising \(N\) elements, with \(\mathbf{F}_{t}^{i}\) representing the fitness value of the \(i^{th}\) member of the population. Each client's contribution to \(\mathbf{F}_{t}\) is weighted by their respective batch size \(b_{j}\), giving a larger influence to clients with potentially more accurate local updates.

The global fitness vector \(\mathbf{F}_{t}\) is computed as follows:

\[\mathbf{F}_{t}=\frac{1}{\sum_{j=1}^{M}b_{j}}\sum_{j=1}^{M}b_{j}\mathbf{f}_{t,j}\] (8)

where \(M\) is the total number of clients and \(\mathbf{f}_{t,j}\) is the fitness value vector from client \(j\) at time \(t\). After the aggregation, the server broadcasts \(\mathbf{F}_{t}\) so that each client updates the baseline model \(\theta_{t}\).

Figure 6: Local Updates and Fitness Evaluation (left) and Server/Client-side Update (right). Left: Client performs BP on local data \(\theta_{t}\) to obtain \(\theta_{t,j}^{\prime}\), evaluates fitness \(f_{t,j}^{i}\) by distance measure (e.g. L2) with \(\theta_{t}^{i}\), and uploads \(\mathbf{f}_{t,j}\) to the server. Right: After obtaining the aggregated fitness \(\mathbf{F}_{t}\), all nodes update the baseline model \(\theta_{t}\) according to Eq. 9.

### Broadcasting Fitness

Once the aggregation is complete, the server broadcasts \(\mathbf{F}_{t}\) to all client nodes, maintaining synchronicity across the network. This only involves the transmission of the fitness vector, again reducing communication overhead. The aggregated fitness vector can be used by the local clients (as well as by the server, if needed) to update the local models.

### Client-side Update

When the global fitness vector \(\mathbf{F}_{t}\) is received from the server, the clients can update their local model following Eq. 5. This strategy involves the addition of a weighted sum of noise vectors to the current model parameters, where the weights are aggregated fitness values:

\[\theta_{t+1}=\theta_{t}+\frac{\alpha}{N\sigma}\sum_{i=1}^{N}\mathbf{F}_{t}^{i }\cdot\epsilon_{t}^{i}\] (9)

where \(\epsilon_{t}^{i}\) is the \(i\)-th noise vector from the population at time \(t\).

Notably, the right side of Eq. 9 can be shown equivalent to the average of all locally updated models akin to FedAvg, i.e., it is straightforward to show that

\[\theta_{t+1}=\frac{1}{\sum_{j}^{M}b_{j}}\sum_{j=1}^{M}b_{j}\theta_{t+1,j}\] (10)

where \(\theta_{t+1,j}\) is the updated model of client \(j\) at time \(t+1\) defined as

\[\theta_{t+1,j}=\theta_{t}+\frac{\alpha}{N\sigma}\sum_{i=1}^{N}f_{t,j}^{i} \cdot\epsilon_{t}^{i}.\] (11)

### Convergence Analysis

**Theorem 1**.: _Suppose that \(L_{j}(\theta)\) is the \(\beta\)-smooth function, i.e., \(\|\nabla L_{j}(u)-\nabla L_{j}(v)\|\leq\beta\|u-v\|\) for any \(u,v\), and also suppose that the variance of the stochastic gradient of \(D_{j}\) is bounded, i.e., \(\mathbb{E}\|\nabla L_{j}(\theta)-\widetilde{\nabla}L_{j}(\theta)\|^{2}\leq B^ {2}\) for all \(j\). When perturbation \(\epsilon^{i}\) is sampled, a conditioned mirrored sampling is applied such that \(\frac{1}{N}\sum_{i=1}^{N}\epsilon^{i}=0,\ \frac{1}{N}\sum_{i=1}^{N}\left( \epsilon^{i}\right)^{2}\leq G^{2},\ \frac{1}{N}\sum_{i=1}^{N}\left( \epsilon^{i}\right)^{3}=0\). Given a decreasing learning rate \(\eta_{t}<\frac{1}{4\alpha\beta}\), EvoFed converges in the sense of_

\[\frac{1}{H_{T}}\sum_{t=0}^{T-1}\eta_{t}\mathbb{E}\left[\left\|\nabla L(\theta _{t})\right\|^{2}\right]\leq\frac{\mathbb{E}\left[L(\theta_{0})\right]-L^{*} }{\alpha G^{2}H_{T}}+4\alpha\beta B^{2}\left(\frac{1}{H_{T}}\sum_{t=0}^{T-1} \eta_{t}^{2}\right)\]_where \(H_{T}=\sum_{t=0}^{T-1}\eta_{t}\), and \(L^{*}\) represents the minimum value of \(L(\theta)\)._

Given a decreasing learning rate (e.g., \(\eta_{t}=\frac{\eta_{0}}{1+t}\)), it can be seen that \(H_{T}=\sum_{t=0}^{T-1}\eta_{t}\rightarrow\infty\) as \(T\) increases, while \(\sum_{t=0}^{T-1}\eta_{t}^{2}<\infty\). Consequently, the upper bound stated in Theorem 1 approaches \(0\) as \(T\) grows, ensuring convergence towards a stationary point. The detailed discussions and the proof can be found in Supplementary Materials.

### EvoFed and Privacy Enhancements

Unlike other FL methods, EvoFed operates on fitness measures. Encryption on smaller fitness vectors requires a lower overhead compared to encryption on large model parameter vectors. Fig. 7 shows Fully Homomorphic Encryption (FHE) [48; 49; 50] that allows aggregation of encrypted data on the server while keeping individual client data confidential. For the decryption of the aggregated fitness vector, EvoFed can leverage third-party Trusted Execution Environments (TEEs), such as Intel SGX [51], providing a secure space for sensitive computations.

### Partial Client Participation

When FL has to operate with a large client pool, a typical practice is to select only a subset of clients in each global round. In EvoFed, this means that the newly joined clients in a given round can either download the latest model or else the last \(k\) fitness vectors from the server, where \(k\) is the time gap from the last participation. In the latter case, the model updates from Eq. (9) can be modified to accommodate \(k\)-step updates:

\[\theta_{t}=\theta_{t-k}+\frac{\alpha}{N\sigma}\sum_{l=1}^{k}\sum_{i=1}^{N} \mathbf{F}_{t-l}^{i}\cdot\epsilon_{t-l}^{i}.\] (12)

Note that even in the former case where the latest model is downloaded by the newly joined clients, the level of security is not compromised as far as the client-to-server messages are concerned.

## 5 Experiments

Our algorithm's effectiveness is assessed on three image classification datasets: FMNIST [52], MNIST [53], and CIFAR-10 [54]. Both MNIST and FMNIST contain 60,000 training samples and 10,000 test samples, whereas CIFAR-10 is composed of 50,000 training samples and 10,000 test samples. We employ a CNN model having 11k parameters for the MNIST and FMNIST datasets and a more substantial model with 2.3M parameters for CIFAR-10. A grid search has been conducted to identify the optimal performance hyperparameters for each baseline, as outlined in the results section. We take into account both global accuracy and communication costs to ascertain hyperparameters that maximize accuracy while minimizing communication overhead.

**Data Distribution.** We distribute the training set of each dataset among clients for model training, and the performance of the final global model is evaluated using the original test set. Our experimental setup contains \(M\) = 5 clients with non-IID data distribution (assigning two classes to each client).

**Implementation Details.** Our EvoFed framework is built using JAX [55], which facilitates extensive parallelization and, in particular, consistent random number generation across a large number of nodes. We have implemented our framework on the Evosax [56] library, a convenient tool for the ES algorithm. EvoFed is configured with a population size of 128 and a mini-batch size of 256 for MNIST / FMNIST and 64 for CIFAR-10. We perform ten local epochs (performing ten BP steps before fitness calculation) and train over 1,000 global rounds.

**Baselines.** We compare the performance of the proposed EvoFed with BP, FedAvg, ES, FedAvg with quantization (Fed-quant), and FedAvg with Sparsification (Fed-sparse). In each scenario, we push

Figure 7: Privacy enhancement through Fully Homomorphic Encryption and Trusted Execution Environments.

for maximum compression, stopping right before the model starts to show performance degradation relative to FedAvg with no compression. BP provides the upper-performance baseline, while ES serves as a reference emphasizing the significance of PBGE.

## 6 Results and Discussions

In this section, we discuss the experimental results in detail and provide further insights into the performance of EvoFed. The accuracy of EvoFed, compared with multiple baseline methods and different datasets, is shown in Fig. 8 (a), (b), and (c). Efficiently encoding and exchanging gradient information, EvoFed enhances the effectiveness of the ES algorithm across all tasks, delivering results comparable to FedAvg. Also, EvoFed achieves superior accuracy at an equivalent compression rate compared to sparsification. This suggests that utilizing a shared population of samples can reduce the information necessary for gradient compression, thereby enhancing the efficiency of the process. Fig. 8 (d), (e), and (f) shows the performance of each method as a function of communication load for all three datasets. It can be seen that EvoFed tends to utilize significantly less communication resources as compared to other high-accuracy techniques.

Table 1 summarizes the performance of different schemes on MNIST, FMNIST, and CIFAR-10 datasets, focusing on communication cost and accuracy. EvoFed achieves significantly lower communication costs compared to FedAvg while maintaining competitive accuracy levels. In the MNIST dataset, EvoFed achieves an accuracy of 97.62% with a mere 9.2 MB of communication load, while FedAvg achieves 98.09% accuracy at a considerably high communication cost of 73.7 MB. The effective compression achieved is an impressive 98.8% which indicates that the gradient vector is condensed into just 1.2% of the fitness vector that is communicated between clients and the server. Similarly, for the FMNIST dataset, EvoFed achieves an accuracy of 84.72% with only 7.78 MB of communication, whereas FedAvg's accuracy is 85.53% with a communication cost of 40.99 MB. The efficiency of EvoFed becomes even more apparent in the CIFAR-10 dataset where the model compression is over 99.7%. EvoFed achieves an accuracy of 54.12% with a low communication cost of only 0.023 GB, surpassing FedAvg, which performs 50.22% at a communication cost of 2.134 GB. The simpler ES method actually gives better performance as well as higher communication efficiency than EvoFed for MNIST but its accuracy for other data sets is highly limited.

**Additional Experiments**. Fig. 9 illustrates the performance of EvoFed with varying numbers of samples \(N\) within the population and a varying number of clients \(M\). The model's performance is

Figure 8: Performance comparison of EvoFed and baseline methods on MNIST, FMNIST, and CIFAR-10 datasets. The top row displays the accuracy achieved by each method on the respective datasets, while the bottom row illustrates the communication cost associated with each method.

significantly influenced by the population size, which directly affects the algorithm's exploration capability and compression rate. We observe a performance improvement as we increase the population size, although at the cost of increased computation and memory usage. Nonetheless, this improvement is not linear and plateaus once sufficient samples are generated to explore the parameter space. For instance, in the case of the FMNIST dataset and a model with 11K parameters, any performance enhancement beyond a generated sample size of 128 is marginal.

Fig. 9(b) showcases EvoFed's performance trend as the number of clients increases. A minor performance decline is observable for some larger values of M relative to M=5. This decline could potentially be attributed to the limited data available per client and the increased variance associated with local training. Nonetheless, we believe that carefully tuning the hyperparameters based on data distribution could assist in achieving more robust performance.

Supplementary Materials provide further details regarding hyperparameters, model architectures, and experiments. We also include a detailed ablation study with different evolutionary strategies, the population size, and the number of partitions, as well as detailed communication and computational complexity analyses.

## 7 Conclusion

EvoFed, the novel paradigm presented herein, unites FL and ES to offer an efficient decentralized machine learning strategy. By exchanging compact fitness values instead of extensive model parameters, EvoFed significantly curtails communication costs. Its performance parallels FedAvg while demonstrating an impressive equivalent model compression of over 98.8% on FMNIST and 99.7% on CIFAR-10 in representative experimental settings. Consequently, EvoFed represents a substantial stride forward in FL, successfully tackling the critical issue of high communication overhead.

## Acknowledgments

A special acknowledgment goes to Do-yeon Kim for the valuable discussions on the convergence analysis presented in Section 4. This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korean government (MSIT) (No. NRF-2019R1I1A2A02061135), and by IITP funds from MSIT of Korea (No. 2020-0-00626).

## References

* [1] Jakub Konecny, H Brendan McMahan, Felix X Yu, Peter Richtarik, Ananda Theertha Suresh, and Dave Bacon. Federated learning: Strategies for improving communication efficiency. _arXiv preprint arXiv:1610.05492_, 2016.

\begin{table}
\begin{tabular}{l|c|c|c|c|c|c|c|c} \hline \multicolumn{3}{c}{**MNIST**} & \multicolumn{3}{c}{**FMNIST**} & \multicolumn{3}{c}{**CIFAR-10**} \\ \cline{2-10}  & **Comm. Cost (MB)** & **Max** & **Comm. Cost (MB)** & **Max** & **Comm. Cost (GB)** & **Max** \\ \cline{2-10}
**Methods** & **90\% Acc.** & **Max Acc.** & **Acc.** & **70\% Acc.** & **Max Acc.** & **Acc.** & **45\% Acc.** & **Max Acc.** \\ \hline ES & 0.1 & 4.6 & 98.30\% & 0.48 & 4.85 & 76.86\% & - & 0.021 & 37.47\% \\ FedAvg & 4.2 & 73.7 & 98.90\% & 0.87 & 40.99 & 85.53\% & 0.266 & 2.134 & 50.22\% \\ Fed-quant & 1.7 & 41.8 & 98.15\% & 0.94 & 37.98 & 83.23\% & 0.086 & 0.800 & 49.78\% \\ Fed-sparse & - & 1.0 & 67.85\% & 2.78 & 17.13 & 73.17\% & 0.129 & 0.671 & 47.36\% \\ EvoFed (our) & 0.8 & 0.2 & 97.62\% & 0.75 & 7.78 & 84.72\% & 0.004 & 0.023 & 54.12\% \\ \hline \end{tabular}
\end{table}
Table 1: Performance of different schemes presented in tabular form, corresponding to Fig. 8.

Figure 9: Effect of population size (left) and number of clients (right) on EvoFed

* [2] H Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. _arXiv preprint arXiv:1602.05629_, 2016.
* [3] Jianyu Wang, Ananda Theertha Yu, and Gregory Wornell. Federated learning with matched averaging. _arXiv preprint arXiv:2002.06440_, 2020.
* [4] Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic. Qsgd: Communication-efficient sgd via gradient quantization and encoding. In _Advances in Neural Information Processing Systems_, pages 1709-1720, 2017.
* [5] Yuzhu Mao, Zihao Zhao, Guangfeng Yan, Yang Liu, Tian Lan, Linqi Song, and Wenbo Ding. Communication-efficient federated learning with adaptive quantization. _ACM Transactions on Intelligent Systems and Technology (TIST)_, 13(4):1-26, 2022.
* [6] Sebastian U Stich. Local sgd converges fast and communicates little. _arXiv preprint arXiv:1805.09767_, 2018.
* [7] Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet S Talwalkar. Federated multi-task learning. In _Advances in Neural Information Processing Systems_, pages 4424-4434, 2017.
* [8] Felix Sattler, Simon Wiedemann, Klaus-Robert Muller, and Wojciech Samek. Robust and communication-efficient federated learning from non-iid data. In _IEEE transactions on neural networks and learning systems_, 2019.
* [9] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Fair resource allocation in federated learning. _arXiv preprint arXiv:1905.10497_, 2020.
* [10] Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. _Reinforcement learning_, pages 5-32, 1992.
* [11] Frank Sehnke, Christian Osendorfer, Thomas Ruckstiess, Alex Graves, Jan Peters, and Jurgen Schmidhuber. Parameter-exploring policy gradients. _Neural Networks_, 23(4):551-559, 2010.
* [12] Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun, Jan Peters, and Jurgen Schmidhuber. Natural evolution strategies. _The Journal of Machine Learning Research_, 15(1):949-980, 2014.
* [13] Xin Yao. Evolving artificial neural networks. _Proceedings of the IEEE_, 87(9):1423-1447, 1999.
* [14] Joel Lehman and Risto Miikkulainen. Neuroevolution. _Scholarpedia_, 8(6):30977, 2013.
* [15] Sebastian Risi and Julian Togelius. Neuroevolution in games: State of the art and open challenges. _CoRR_, abs/1410.7326, 2014.
* [16] Sebastian Risi and Julian Togelius. Neuroevolution in games: State of the art and open challenges. _IEEE Transactions on Computational Intelligence and AI in Games_, 9(1):25-41, 2015.
* [17] Daniel Golovin, John Karro, Greg Kochanski, Chansoo Lee, Xingyou Song, and Qiuyi Zhang. Gradientless descent: High-dimensional zeroth-order optimization. _arXiv preprint arXiv:1911.06317_, 2019.
* [18] Robert Tjarko Lange, Tom Schaul, Yutian Chen, Chris Lu, Tom Zahavy, Valentin Dalibard, and Sebastian Flennerhag. Discovering attention-based genetic algorithms via meta-black-box optimization. _arXiv preprint arXiv:2304.03995_, 2023.
* [19] Felix Sattler, Simon Wiedemann, Klaus-Robert Muller, and Wojciech Samek. Sparse binary compression: Towards distributed deep learning with minimal communication. In _2019 International Joint Conference on Neural Networks (IJCNN)_, pages 1-8. IEEE, 2019.
* [20] Jinjin Xu, Wenli Du, Yaochu Jin, Wangli He, and Ran Cheng. Ternary compression for communication-efficient federated learning. _IEEE Transactions on Neural Networks and Learning Systems_, 2020.

* [21] Eunjeong Jeong, Seungeun Oh, Hyesung Kim, Jihong Park, Mehdi Bennis, and Seong-Lyun Kim. Communication-efficient on-device machine learning: Federated distillation and augmentation under non-iid private data. _arXiv preprint arXiv:1811.11479_, 2018.
* [22] Sohei Itahara, Takayuki Nishio, Yusuke Koda, Masahiro Morikura, and Koji Yamamoto. Distillation-based semi-supervised federated learning for communication-efficient collaborative training with non-iid private data. _arXiv preprint arXiv:2008.06180_, 2020.
* [23] Felix Sattler, Arturo Marban, Roman Rischke, and Wojciech Samek. Communication-efficient federated distillation. _arXiv preprint arXiv:2012.00632_, 2020.
* [24] Tao Lin, Lingjing Kong, Sebastian U Stich, and Martin Jaggi. Ensemble distillation for robust model fusion in federated learning. _Advances in Neural Information Processing Systems_, 33:2351-2363, 2020.
* [25] Chuhan Wu, Fangzhao Wu, Lingjuan Lyu, Yongfeng Huang, and Xing Xie. Communication-efficient federated learning via knowledge distillation. _Nature communications_, 13(1):1-8, 2022.
* [26] Mingzhe Chen, Nir Shlezinger, H Vincent Poor, Yonina C Eldar, and Shuguang Cui. Communication-efficient federated learning. _Proceedings of the National Academy of Sciences_, 118(17):e2024789118, 2021.
* [27] Takayuki Nishio and Ryo Yonetani. Client selection for federated learning with heterogeneous resources in mobile edge. In _ICC 2019-2019 IEEE international conference on communications (ICC)_, pages 1-7. IEEE, 2019.
* [28] Canh T Dinh, Nguyen H Tran, Minh NH Nguyen, Choong Seon Hong, Wei Bao, Albert Y Zomaya, and Vincent Gramoli. Federated learning over wireless networks: Convergence analysis and resource allocation. _IEEE/ACM Transactions on Networking_, 29(1):398-409, 2020.
* [29] Ingo Rechenberg. Evolutionsstrategie : Optimierung technischer systeme nach prinzipien der biologischen evolution. 1973.
* [30] Daan Wierstra, Tom Schaul, Jan Peters, and Jurgen Schmidhuber. Fitness expectation maximization. In _Parallel Problem Solving from Nature-PPSN X: 10th International Conference, Dortmund, Germany, September 13-17, 2008. Proceedings 10_, pages 337-346. Springer, 2008.
* [31] Sun Yi, Daan Wierstra, Tom Schaul, and Jurgen Schmidhuber. Stochastic search using the natural gradient. In _Proceedings of the 26th Annual International Conference on Machine Learning_, pages 1161-1168, 2009.
* [32] Yi Sun, Daan Wierstra, Tom Schaul, and Jurgen Schmidhuber. Efficient natural evolution strategies. In _Proceedings of the 11th Annual conference on Genetic and evolutionary computation_, pages 539-546, 2009.
* [33] Tobias Glasmachers, Tom Schaul, and Jurgen Schmidhuber. A natural evolution strategy for multi-objective optimization. In _Parallel Problem Solving from Nature, PPSN XI: 11th International Conference, Krakow, Poland, September 11-15, 2010, Proceedings, Part I 11_, pages 627-636. Springer, 2010.
* [34] Tobias Glasmachers, Tom Schaul, Sun Yi, Daan Wierstra, and Jurgen Schmidhuber. Exponential natural evolution strategies. In _Proceedings of the 12th annual conference on Genetic and evolutionary computation_, pages 393-400, 2010.
* [35] Tom Schaul, Tobias Glasmachers, and Jurgen Schmidhuber. High dimensions and heavy tails for natural evolution strategies. In _Proceedings of the 13th annual conference on Genetic and evolutionary computation_, pages 845-852, 2011.
* [36] Tim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor, and Ilya Sutskever. Evolution strategies as a scalable alternative to reinforcement learning. _arXiv preprint arXiv:1703.03864_, 2017.

* [37] James C Spall. Multivariate stochastic approximation using a simultaneous perturbation gradient approximation. _IEEE transactions on automatic control_, 37(3):332-341, 1992.
* [38] Yurii Nesterov and Vladimir Spokoiny. Random gradient-free minimization of convex functions. _Foundations of Computational Mathematics_, 17:527-566, 2017.
* [39] W. Diffie and M. Hellman. New directions in cryptography. _IEEE Transactions on Information Theory_, 22(6):644-654, 1976. doi: 10.1109/TIT.1976.1055638.
* [40] Hangyu Zhu and Yaochu Jin. Real-time federated evolutionary neural architecture search. _IEEE Transactions on Evolutionary Computation_, 26(2):364-378, 2021.
* [41] Decebal Constantin Mocanu, Elena Mocanu, Peter Stone, Phuong H Nguyen, Madeleine Gibescu, and Antonio Liotta. Scalable training of artificial neural networks with adaptive sparse connectivity inspired by network science. _Nature communications_, 9(1):1-12, 2018.
* [42] Hangyu Zhu and Yaochu Jin. Multi-objective evolutionary federated learning. _IEEE transactions on neural networks and learning systems_, 31(4):1310-1322, 2019.
* [43] Zheng-yi Chai, Chuan-dong Yang, and Ya-lun Li. Communication efficiency optimization in federated learning based on multi-objective evolutionary algorithm. _Evolutionary Intelligence_, pages 1-12, 2022.
* [44] Qingfu Zhang and Hui Li. Moea/d: A multiobjective evolutionary algorithm based on decomposition. _IEEE Transactions on evolutionary computation_, 11(6):712-731, 2007.
* [45] Ivanoe De Falco, Antonio Della Cioppa, Tomas Koutny, Martin Ubl, Michal Krcma, Umberto Scafuri, and Ernesto Tarantino. A federated learning-inspired evolutionary algorithm: Application to glucose prediction. _Sensors_, 23(6):2957, 2023.
* [46] John Geweke. Antithetic acceleration of monte carlo integration in bayesian inference. _Journal of Econometrics_, 38(1-2):73-89, 1988.
* [47] Dimo Brockhoff, Anne Auger, Nikolaus Hansen, Dirk V Arnold, and Tim Hohm. Mirrored sampling and sequential selection for evolution strategies. In _Parallel Problem Solving from Nature, PPSN XI: 11th International Conference, Krakow, Poland, September 11-15, 2010. Proceedings, Part I 11_, pages 11-21. Springer, 2010.
* [48] Masahiro Yagisawa. Fully homomorphic encryption without bootstrapping. _Cryptology ePrint Archive_, 2015.
* [49] Hao Chen, Kim Laine, and Rachel Player. Simple encrypted arithmetic library-seal v2. 1. In _Financial Cryptography and Data Security: FC 2017 International Workshops, WAHC, BITCOIN, VOTING, WTSC, and TA, Sliema, Malta, April 7, 2017, Revised Selected Papers 21_, pages 3-18. Springer, 2017.
* [50] Junfeng Fan and Frederik Vercauteren. Somewhat practical fully homomorphic encryption. _Cryptology ePrint Archive_, 2012.
* [51] Ittai Anati, Shay Gueron, Simon Johnson, and Vincent Scarlata. Innovative technology for cpu based attestation and sealing. In _Proceedings of the 2nd international workshop on hardware and architectural support for security and privacy_, volume 13. ACM New York, NY, USA, 2013.
* [52] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. _arXiv preprint arXiv:1708.07747_, 2017.
* [53] Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. _Proceedings of the IEEE_, 86(11):2278-2324, 1998.
* [54] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.

* Bradbury et al. [2018] James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composable transformations of Python+NumPy programs, 2018. URL http://github.com/google/jax.
* Lange [2022] Robert Tjarko Lange. evosax: Jax-based evolution strategies. _arXiv preprint arXiv:2212.04180_, 2022.