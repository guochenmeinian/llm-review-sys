# This Too Shall Pass: Removing Stale Observations in Dynamic Bayesian Optimization

 Anthony Bardou

IC, EPFL

Lausanne, Switzerland

anthony.bardou@epfl.ch

&Patrick Thiran

IC, EPFL

Lausanne, Switzerland

patrick.thiran@epfl.ch

&Giovanni Ranieri

IC, EPFL

Lausanne, Switzerland

giovanni.ranieri@epfl.ch

###### Abstract

Bayesian Optimization (BO) has proven to be very successful at optimizing a static, noisy, costly-to-evaluate black-box function \(f:\mathcal{S}\to\mathbb{R}\). However, optimizing a black-box which is also a function of time (_i.e._, a _dynamic_ function) \(f:\mathcal{S}\times\mathcal{T}\to\mathbb{R}\) remains a challenge, since a dynamic Bayesian Optimization (DBO) algorithm has to keep track of the optimum over time. This changes the nature of the optimization problem in at least three aspects: (i) querying an arbitrary point in \(\mathcal{S}\times\mathcal{T}\) is impossible, (ii) past observations become less and less relevant for keeping track of the optimum as time goes by and (iii) the DBO algorithm must have a high sampling frequency so it can collect enough relevant observations to keep track of the optimum through time. In this paper, we design a Wasserstein distance-based criterion able to quantify the relevancy of an observation with respect to future predictions. Then, we leverage this criterion to build W-DBO, a DBO algorithm able to remove irrelevant observations from its dataset on the fly, thus maintaining simultaneously a good predictive performance and a high sampling frequency, even in continuous-time optimization tasks with unknown horizon. Numerical experiments establish the superiority of W-DBO, which outperforms state-of-the-art methods by a comfortable margin.

## 1 Introduction

Many real-world problems require the optimization of a costly-to-evaluate objective function \(f:\mathcal{S}\subseteq\mathbb{R}^{d}\to\mathbb{R}\) with an unknown closed form (_i.e._, either the closed form expression of \(f\) exists but remains unknown to the user, or it does not exist). Such a setting occurs frequently, and examples can be found in hyperparameters tuning [1], networking [2; 3], robotics [4] or computational biology [5]. In such applications, \(f\) can be seen as a black-box and cannot be optimized by usual first-order approaches. Bayesian Optimization (BO) is an effective framework for black-box optimization. Its core idea is to leverage a surrogate model, usually a Gaussian Process (GP), to query \(f\) at specific inputs. By doing so, a BO algorithm is able to simultaneously discover and optimize the objective function.

Since its inception, BO has proven to be very effective at optimizing black-boxes in a variety of contexts, such as high-dimensional input spaces [6; 7; 8], batch mode [9] or multi-objective optimization [10]. However, few works study BO in dynamic contexts (_i.e._, with a time-varying objective function), despite its critical importance. Indeed, dynamic black-box optimization problems arise whenever an optimization task is conducted within an environment that comprises exogenous factors that may vary with time and significantly impact the objective function. Dynamic black-boxes are found in network management [11], unmanned aerial vehicles tasks [12], hyperparameter tuning in online deep learning [13], online clustering [14] or crossing waypoints location in air routes [15].

In a dynamic context, \(f:\mathcal{S}\times\mathcal{T}\to\mathbb{R}\) is a time-varying, black-box, costly-to-evaluate objective function with spatial domain \(\mathcal{S}\subseteq\mathbb{R}^{d}\) and temporal domain \(\mathcal{T}\subseteq\mathbb{R}\). Unlike common black-box

[MISSING_PAGE_FAIL:2]

Exploiting the usual acquisition functions in a dynamic context is also straightforward. Since a DBO algorithm can only query an input at the current running time \(t_{0}\), the next queried input is simply \((\bm{x}_{n+1},t_{0})\), with \(\bm{x}_{n+1}=\operatorname*{arg\,max}_{\bm{x}\in\mathcal{S}}\varphi(\bm{x},t_{0})\). Some DBO algorithms (e.g., [20]) extend the querying horizon to the near future, that is, from \(t_{0}\) to a time interval \([t_{0},t_{0}+\delta_{t}]\). In that case, the next queried input is \((\bm{x}_{n+1},t_{n+1})=\operatorname*{arg\,max}_{(\bm{x},t)\in\mathcal{S}\times [t_{0},t_{0}+\delta_{t}]}\varphi(\bm{x},t)\).

BO is an active field of research, but relatively few works address DBO, despite the natural extension of BO to dynamic problems described above. We conclude this section by reviewing them. In [21], the objective function is allowed to evolve in time according to a simple Markov model, controlled by a hyperparameter \(\epsilon\in[0,1]\). On the one hand, the authors propose R-GP-UCB, which handles data staleness by resisting the dataset every \(N(\epsilon)\) iterations. On the other hand, the authors also propose TV-GP-UCB that incorporates data staleness by weighing the covariance of two queries \(\bm{q}_{i}=(\bm{x}_{i},t_{i})\) and \(\bm{q}_{j}=(\bm{x}_{j},t_{j})\) by \((1-\epsilon)^{|i-j|/2}\). In [22], the authors use the same model with an event-triggered reset of the dataset. Although less relevant to this work, let us mention [23] and [24] for the sake of completeness. Under frequentist assumptions, they also propose DBO algorithms that forget irrelevant observations by either resetting their datasets or by using decreasing covariance weights. However, they assume that the variational budget of the objective function is fixed, which has the drawback of requiring the objective function to become asymptotically static. This is a very different setting than the one of interest in this paper, which does not make this requirement.

The aforementioned algorithms all work with discrete, evenly-spaced time steps. This setting simplifies the regret analysis of DBO algorithms through the use of proof techniques similar to the ones used for static BO. However, it also overlooks a critical effect of the response times of their algorithms. In fact, the response time of a BO algorithm heavily depends on its dataset size \(n\), since BO inference is in \(\mathcal{O}(n^{3})\). Although it is reasonable to ignore this for classical BO because the objective function \(f\) is static, DBO algorithms cannot make this simplification as it directly impacts their ability to track the optimal argument of the objective function through time. Many algorithms (e.g., see [21; 23; 24]) recommend to keep all the collected observations in their datasets, whereas in practice, their response times would asymptotically become prohibitive. Other algorithms (e.g., see [21; 22; 23]) propose to reset their datasets, either periodically or once an event is triggered. This probably deletes some relevant observations in the process. More importantly, these algorithms necessarily estimate their covariance function hyperparameters beforehand and keep them fixed during the optimization. This lack of adaptivity of the estimation might lead to severely under-optimal characterization of the function by the hyperparameters, especially when optimizing an ever-changing objective function on an infinite time horizon.

To the best of our knowledge, only one work acknowledges these problems. It proposes ABO [20], an algorithm that uses a decomposable spatio-temporal covariance function \(k((\bm{x},t),(\bm{x}^{\prime},t^{\prime}))=k_{S}(||\bm{x}-\bm{x}^{\prime}||_{2} )k_{T}(|t-t^{\prime}|)\) to accurately model complex spatio-temporal correlations and samples the objective function only when deemed necessary. Although this reduces the size of ABO's dataset, ABO does not propose a way to remove stale observations, it only adds new observations less frequently. Therefore, using ABO will still become prohibitive in the long run.

The most relevant methods to quantify the relevancy of an observation can be found in the sparse GPs literature (e.g., see [25; 26]). However, they require non-trivial adjustments to account for the particular nature of the time dimension. As far as we know, there is no method in the DBO literature able to quantify the relevancy of an observation in an online setting. As mentioned before, such a method is much needed as it would allow a DBO algorithm to remove stale data on the fly while preserving the predictive performance of the algorithm. We bridge this gap by providing a sound criterion to measure the relevancy of an observation and an algorithm exploiting this criterion to remove stale data from its dataset.

## 3 A Wasserstein Distance-Based Criterion

### Core Assumptions

To address the DBO problem under suitable smoothness conditions, let us make the usual assumption of BO, using a Gaussian Process (GP) as a surrogate model for \(f\) (see [16]).

**Assumption 3.1**.: \(f\) _is a \(\mathcal{GP}\left(0,k((\bm{x},t)\,,(\bm{x}^{\prime},t^{\prime}))\right)\), whose mean is \(0\) (without loss of generality) and whose covariance function is denoted by \(k:\mathcal{S}\times\mathcal{T}\times\mathcal{S}\times\mathcal{T}\to \mathbb{R}_{+}\)._In order to accurately model complex spatio-temporal dynamics, we make the same assumption on the decomposition and isotropy in time and space of the covariance function \(k\) as in [20].

**Assumption 3.2**.: \[k((\bm{x},t),(\bm{x}^{\prime},t^{\prime}))=\lambda k_{S}(||\bm{x}-\bm{x}^{\prime }||_{2},l_{S})k_{T}(|t-t^{\prime}|,l_{T}),\] (5)

with \(\lambda>0\), \(k_{S}:\mathbb{R}_{+}\to[0,1]\) and \(k_{T}:\mathbb{R}_{+}\to[0,1]\) two positive correlation functions, parameterized by lengthscales \(l_{S}>0\) and \(l_{T}>0\), respectively. The factor \(\lambda>0\) scales the product of the two correlation functions and hence, controls the magnitude of the covariance function \(k\). The lengthscales \(l_{S}\) and \(l_{T}\) control the correlation lengths of the GP (see [27] for more details) in space and in time, respectively.

Although the covariance function \(k\) is able to model temporal correlations with \(k_{T}\), it does not accurately measure the relevancy of an observation. The next section addresses this question.

### Measuring the Relevancy of an Observation

By definition, when an irrelevant observation gets removed from the dataset, the GP posterior experiences hardly any change. Therefore, we propose to measure the relevancy of an observation \(\bm{o}_{i}=((\bm{x}_{i},t_{i}),y_{i})\) by measuring the impact that the removal of \(\bm{o}_{i}\) has on the GP posterior.

Let \(\mathcal{GP_{D}}\) be the GP conditioned on the dataset \(\mathcal{D}=\left\{((\bm{x}_{i},t_{i}),y_{i})\right\}_{i\in\llbracket 1,n\rrbracket}\), with \((\bm{x}_{i},t_{i})\in\mathcal{S}\times\mathcal{T}\) and \(y_{i}=f(\bm{x}_{i},t_{i})+\epsilon,\epsilon\sim\mathcal{N}\left(0,\sigma^{2}\right)\). Without loss of generality, let us measure the impact of removing \(((\bm{x}_{1},t_{1}),y_{1})\) from the dataset on the GP posterior. Clearly, the measure should be defined on the domain of future predictions at time \(t_{0}\), denoted by \(\mathcal{F}_{t_{0}}\), which must include the whole space \(\mathcal{S}\) and only the future time interval \([t_{0},+\infty)\):

\[\mathcal{F}_{t_{0}}=\mathcal{S}\times[t_{0},+\infty).\] (6)

We compare a GP conditioned on the whole dataset, denoted by \(\mathcal{GP_{D}}\), with a GP conditioned on \(\tilde{\mathcal{D}}\), the dataset without \((\bm{x}_{1},t_{1},y_{1})\), denoted by \(\mathcal{GP_{\tilde{D}}}\). For an arbitrary point \((\bm{x},t)\in\mathcal{F}_{t_{0}}\), \(\mathcal{GP_{D}}\) provides a posterior distribution \(\mathcal{N_{D}}(\bm{x},t)=\mathcal{N}\left(\mu_{\mathcal{D}}(\bm{x},t), \sigma_{\mathcal{D}}^{2}(\bm{x},t)\right)\), and so does \(\mathcal{GP_{\tilde{D}}}\) with \(\mathcal{N_{\tilde{D}}}(\bm{x},t)=\mathcal{N}\left(\mu_{\tilde{\mathcal{D}}} (\bm{x},t),\sigma_{\tilde{\mathcal{D}}}^{2}(\bm{x},t)\right)\). We compare these two distributions by using the 2-Wasserstein distance [28], given by

\[W_{2}\left(\mathcal{N_{D}}(\bm{x},t),\mathcal{N_{\tilde{D}}}(\bm{x},t)\right) =\left(\left(\mu_{\mathcal{D}}(\bm{x},t)-\mu_{\tilde{\mathcal{D}}}(\bm{x},t) \right)^{2}+\left(\sigma_{\mathcal{D}}(\bm{x},t)-\sigma_{\tilde{\mathcal{D}}} (\bm{x},t)\right)^{2}\right)^{\frac{1}{2}}.\] (7)

A natural extension of the 2-Wasserstein distance from a point \((\bm{x},t)\in\mathcal{F}_{t_{0}}\) to the domain \(\mathcal{F}_{t_{0}}\) is

\[W_{2}\left(\mathcal{GP_{D}},\mathcal{GP_{\tilde{D}}}\right)=\left(\oint_{ \mathcal{S}}\int_{t_{0}}^{\infty}W_{2}^{2}\left(\mathcal{N_{D}}(\bm{x},t), \mathcal{N_{\tilde{D}}}(\bm{x},t)\right)d\bm{x}dt\right)^{\frac{1}{2}}.\] (8)

Observe that (8) is a criterion that effectively captures the impact of removing the observation \(\bm{o}_{1}=((\bm{x}_{1},t_{1}),y_{1})\) from the dataset on the GP posterior. However, as discussed in Appendix F, the covariance function hyperparameters \(\bm{\theta}=(\lambda,l_{S},l_{T})\) control the magnitude of (8). This is illustrated by Figure 1, which depicts two couples of GP posteriors that achieve the same value (8). Depending on the lengthscale magnitude, the posteriors may be quite different or, conversely, very similar. As a result, (8) cannot be directly used as a gauge of observation relevancy.

To remove this ambiguity, we normalize (8) by \(W_{2}(\mathcal{GP_{D}},\mathcal{GP_{\emptyset}})\) (_i.e._, the 2-Wasserstein distance between the GP conditioned on \(\mathcal{D}\) and the prior GP), and we obtain the ratio

\[R(\mathcal{GP_{D}},\mathcal{GP_{\tilde{D}}})=\frac{W_{2}(\mathcal{GP_{D}}, \mathcal{GP_{\tilde{D}}})}{W_{2}(\mathcal{GP_{D}},\mathcal{GP_{\emptyset}})}.\] (9)

Intuitively, \(W_{2}(\mathcal{GP_{D}},\mathcal{GP_{\emptyset}})\) measures the impact of resetting the whole dataset \(\mathcal{D}\) on the GP posterior and serves as a baseline that puts into perspective the distance measured by (8). Technically, taking the ratio (9) successfully cancels out the influence of the covariance function hyperparameters on the magnitude of the Wasserstein distances, as further discussed in Appendix F. As a direct consequence,Figure 2: Normalized Wasserstein distances. Similarly to Figure 1, a few couples of GP posterior means \((\mu_{\mathcal{D}},\mu_{\tilde{\mathcal{D}}})\) are depicted. The top (resp., bottom) row depicts couples of posteriors that yield a small (resp., large) ratio (9). The left (resp., right) column depicts couples of posteriors controlled by a small (resp., large) lengthscale. The prior GP mean \(\mu_{\tilde{\mathcal{D}}}=0\) is shown as a black dashed line, and the Wasserstein distance between the posterior and the prior as a gray shaded area.

Figure 1: Similar values of Wasserstein distance, different effect on posteriors. For visualization purposes, only the posterior means of two posterior GPs (blue for \(\mu_{\mathcal{D}}\) and orange for \(\mu_{\tilde{\mathcal{D}}}\)) are depicted, along a single dimension (e.g., time). The Wasserstein distance between the two posteriors is shown by the green shaded area. The GPs have a small lengthscale (left) or, conversely, a large lengthscale (right) for the chosen dimension.

(9) is an unambiguous indication of how relevant an observation is. This is illustrated by Figure 2, which depicts couples of GP posteriors under different contexts. When (9) is small (resp., large), the posteriors are similar (resp., dissimilar) regardless of the magnitude of the lengthscale.

Exploiting this criterion is straightforward. When (9) is small, one can infer that the observation \(\bm{o}_{1}\) can be safely removed from the dataset since it will have virtually no impact on the posterior. Conversely, when (9) is large, one can infer that removing \(\bm{o}_{1}\) would alter the posterior too much, and conclude that it is a relevant observation that must remain in the dataset. The exploitation of (9) is discussed in more details in Section 4.2.

The criterion (9) is useful for a DBO algorithm if and only if it can be computed on the fly, in an online setting. In the next section, we show that (9) can be approximated efficiently, and we describe a DBO algorithm able to exploit the criterion.

## 4 Using the Criterion in Practice

### Computational Tractability

In [29], the authors provide an algorithm to approximate the 2-Wasserstein distance between two GPs up to an arbitrary precision level. However, the computational cost of this algorithm is too expensive in an online setting, where it is crucial to keep the per-iteration cost as small as possible to ensure a high sampling frequency. In this section, we put this issue to rest by deriving an explicit approximation of (9). These formulas are computationally cheap enough to be exploited on the fly.

In Appendix A, we show that (7) can be computed efficiently. Next, in Appendix B, we apply these results to obtain an upper bound of (8). The key observation for deriving this result is to approximate the integrals in (8) by a convolution of the covariance functions with themselves in space and time. The same trick can be used for approximating \(W_{2}(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\emptyset})\).

**Theorem 4.1**.: _Let \(t_{0}\) be the present time and \(\mathcal{D}=\left\{((\bm{x}_{i},t_{i}),y_{i})\right\}_{i\in[\![1,n]\!]}\) be a dataset of observations made before \(t_{0}\). Let \(\tilde{\mathcal{D}}=\left\{((\bm{x}_{i},t_{i}),y_{i})\right\}_{i\in[\![2,n]\!]}\) be the dataset without the first observation and \(\mathcal{F}_{t_{0}}=\mathcal{S}\times[t_{0},+\infty)\) be the domain of future predictions. Then, an upper bound for \(W_{2}^{2}(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\tilde{\mathcal{D}}})\) on \(\mathcal{F}_{t_{0}}\) is_

\[\begin{split}\hat{W}_{2}^{2}\left(\mathcal{GP}_{\mathcal{D}}, \mathcal{GP}_{\tilde{\mathcal{D}}}\right)=\lambda^{2}(a^{2}+\bm{E})C((\bm{x}_{ 1},t_{1}),&(\bm{x}_{1},t_{1})\right)+\lambda^{2}(2a\bm{b}+\bm{c}) C((\bm{x}_{1},t_{1}),\tilde{\mathcal{D}})\\ &+\lambda^{2}\operatorname{tr}\left((\bm{b}\bm{b}^{\top}+\bm{M} )\,C(\tilde{\mathcal{D}},\tilde{\mathcal{D}})\right)\end{split}\] (10)

_where \(C(\mathcal{X},\mathcal{Y})=\left((k_{S}*k_{S})(\bm{x}_{j}-\bm{x}_{i})\cdot(k_{ T}*k_{T})_{t_{0}-t_{i}}^{+\infty}(t_{j}-t_{i})\right)_{\begin{subarray}{c}(\bm{x}_{i},t_{i}) \in\mathcal{X},\\ (\bm{x}_{j},t_{j})\in\mathcal{Y}\end{subarray}}\), where \((f*g)\) denotes the convolution between \(f\) and \(g\), and \((f*g)_{\bm{a}}^{b}\) denotes the convolution between \(f\) and \(g\) restricted to the interval \([a,b]\). The terms \(a\), \(\bm{b}\), \(\bm{c}\), \(\bm{E}\) and \(\bm{M}\) are explicited in Appendices A and B._

_Moreover, an upper bound for \(W_{2}^{2}(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\emptyset})\) on \(\mathcal{F}_{t_{0}}\) is_

\[\hat{W}_{2}^{2}\left(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\emptyset} \right)=\lambda^{2}\left(\bm{y}^{\top}\bm{\Delta}^{-\top}C\left(\mathcal{D}, \mathcal{D}\right)\bm{\Delta}^{-1}\bm{y}+\operatorname{tr}\left(\bm{\Delta}^ {-1}C\left(\mathcal{D},\mathcal{D}\right)\right)\right).\] (11)

This theorem provides the analytic form of an upper bound for the Wasserstein distance between \(\mathcal{GP}_{\mathcal{D}}\) and \(\mathcal{GP}_{\tilde{\mathcal{D}}}\) and the Wasserstein distance between \(\mathcal{GP}_{\mathcal{D}}\) and \(\mathcal{GP}_{\emptyset}\) on the domain of future predictions \(\mathcal{F}_{t_{0}}\). Using it, we can compute an approximation \(\hat{R}\) of the relative criterion (9), that is

\[\hat{R}(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\tilde{\mathcal{D}}})=\frac{ \hat{W}_{2}(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\tilde{\mathcal{D}}})}{ \hat{W}_{2}(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\emptyset})}.\] (12)

In Appendix C, we study the error between the criterion (9) and the approximation (12). In essence, we bound the approximation error caused by estimating the integrals in (8) by a self-convolution of the covariance functions \(k_{S}\) and \(k_{T}\) (i.e., \(k_{S}*k_{S}\) and \(k_{T}*k_{T}\)). Furthermore, we provide numerical evidence that the approximation errors in the numerator and the denominator of (12) compensate each other at least in part, making (12) a decent approximation for (9).

In practice, the upper bounds (10) and (11) can only be computed efficiently if the convolutions of the covariance functions can themselves be computed efficiently. The analytic forms for the convolution of two usual covariance functions listed in Table 1, namely Squared-Exponential (SE) and Matern [30], are provided in Appendix D together with Tables 3 and 4 that list the self-convolutions for the spatial (resp., temporal) covariance function. Their detailed computations are also provided in this appendix. In a nutshell, the formulas are obtained first in the Fourier domain by computing the square of the spectral densities of the covariance functions, and next by computing their inverse Fourier transform.

Together, Tables 3, 4 in Appendix D and Theorem 4.1 show that the approximation of (9) given by (12) can be computed efficiently in an online setting. In an effort to generalize our results to a class of covariance functions that extends beyond Assumption 3.2, we also discuss how to compute the self-convolution of an anisotropic spatial SE covariance function in Appendix E. We now leverage (12) to propose a DBO algorithm able to pinpoint and remove irrelevant observations in its dataset.

### W-Dbo

The metric (9) and its approximation (12) can be seen as a relative error (or drift), expressed as a percentage, that separates \(\mathcal{GP}_{\mathcal{D}}\) and \(\mathcal{GP}_{\widehat{\mathcal{D}}}\). Indeed, the Wasserstein distance \(W\left(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\widehat{\mathcal{D}}}\right)\) is scaled by the Wasserstein distance \(W\left(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\emptyset}\right)\), that is, the distance between \(\mathcal{GP}_{\mathcal{D}}\) and the prior. In other words, (9) and its approximation (12) measure the relative drift from \(\mathcal{GP}_{\mathcal{D}}\) to \(\mathcal{GP}_{\widehat{\mathcal{D}}}\) caused by the removal of one observation. When removing multiple observations, the relative drifts naturally accumulate in a multiplicative way (similarly to the way relative errors accumulate). As a consequence, removing multiple observations could, in the worst case, make \(\mathcal{GP}_{\widehat{\mathcal{D}}}\) drift exponentially fast from \(\mathcal{GP}_{\mathcal{D}}\). To keep this exponential drift under control, one can use a removal budget \(b(t)=(1+\alpha)^{t}\) that allows a maximal relative drift from \(\mathcal{GP}_{\mathcal{D}}\) of \(\alpha\) per unit of time (e.g., if \(\alpha=0.1\), the allowed maximal drift is 10 % per unit of time). The cost of removing an observation is given by (12).

Algorithm 1 describes W-DBO, a DBO algorithm exploiting (12) to remove irrelevant observations on the fly. As described above, the removal budget is controlled by a single hyperparameter \(\alpha\) and grows exponentially as time goes by (see line 24). At each iteration, (12) is used to compute the relevancy of each observation in the dataset (see lines 10-13). The relevancy of the least relevant observation is then compared to the removal budget, and the observation is removed if the budget allows it (see lines 14-17). This process is repeated until all the budget is consumed. Such a greedy observation removal policy causes W-DBO to overestimate the impact of removing multiple observations3. We discuss and motivate the expression of the removal budget in Appendix G. The sensitivity analysis conducted in Section 5.1 supports this removal budget, by showing that the same value of the hyperparameter \(\alpha\) is valid for a large set of different objective functions.

Footnote 3: To prevent this, the criterion (12) could be computed on every element of \(2^{|\mathcal{D}|}\) at each iteration. Unfortunately, this policy does not scale well with the dataset size \(|\mathcal{D}|\).

Finally, note that using (12) to remove irrelevant observations on the fly can be performed in conjunction with any BO algorithm, because it can be appended at the end of each optimization step as a simple post-processing stage. This agnostic property of W-DBO is supported by the ability of Algorithm 1 to take as inputs any GP model \(\mathcal{GP}\) and any acquisition function \(\varphi\). Similarly, observe that lines 5-8 in Algorithm 1 describe the usual BO optimization loop, without any modification.

## 5 Numerical Results

In this section, we study the empirical performance of W-DBO. To measure the quality of the queries made by the DBO solutions, we compute the average regret (lower is better). For the sake of realistic evaluation, two iterations of a solution are seperated by its response time (_i.e._, the time taken to infer its hyperparameters and optimize its acquisition function). Furthermore, all covariance function

\begin{table}
\begin{tabular}{l c} \hline \hline Covariance Function & \(k(\bm{x})\) \\ \hline Squared-Exponential (\(l\)) & \(e^{-\frac{||\bm{x}||_{2}^{2}}{2l^{2}}}\) \\ Matern (\(\nu,l\)) & \(\frac{2^{1-\nu}}{\Gamma(\nu)}\left(\frac{\sqrt{2\nu}||\bm{x}||_{2}}{l_{S}} \right)^{\nu}K_{\nu}\left(\frac{\sqrt{2\nu}||\bm{x}||_{2}}{l_{S}}\right)\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Usual covariance functions. \(\Gamma\) is the Gamma function and \(K_{\nu}\) is a modified Bessel function of the second kind of order \(\nu\).

parameters and the noise level are estimated on the fly. Please refer to Appendix H.1 for further experimental details, and to Appendix H.2 for a detailed description of the dynamic benchmarks.

### Sensitivity Analysis

We start by studying the impact of the W-DBO hyperparameter \(\alpha\) on the average regret. Recall that we take into account the response time of the algorithm. This evaluation protocol reveals that a trade-off must be achieved between having an accurate model of the objective function (which requires a large dataset) and being able to track the optimal argument of the function as it evolves (which requires a high sampling frequency, thus a moderately-sized dataset).

Figure 3: (Left) Sensitivity analysis on the Eggholder function. (Right) Aggregation of sensitivity analyses of W-DBO made on 10 synthetic functions and a real-world experiment. For aggregation purposes, the average regrets in each experiment have been normalized between 0 (lowest average regret) and 1 (largest average regret). The average performance of W-DBO over all the experiments is shown in black. Standard errors are depicted with colored bars (left) and shaded areas (right).

To study this trade-off, we compare the performance of W-DBO with several values of its hyperparameter \(\alpha\), as illustrated by the left side of Figure 3. We apply this protocol on 11 different benchmarks (described in Appendix H.2). The aggregated results (see the right side of Figure 3) show that achieving a trade-off between the size of the dataset and the sampling frequency can significantly improve the performance of W-DBO. Clearly, the sweet spot is reached for \(\alpha=\frac{1}{4}\). This hyperparameter value is used to evaluate W-DBO in the next section.

### Comparison with Baselines

The competing baselines are the relevant algorithms reported in Section 2, namely R-GP-UCB and TV-GP-UCB [21], ET-GP-UCB [22] and ABO [20]. We also consider vanilla BO with the GP-UCB acquisition function, which only considers spatial correlations. For comparison purposes, all the results are gathered in Table 2. The benchmarks comprise ten synthetic functions and two real-world experiments. All figures (including standard errors) are provided in Appendix H.2, and the performance of each DBO solution is discussed at length in Appendix H.3. Furthermore, the provided supplementary animated visualizations are discussed in Appendix H.4.

In this section. we only depict the performance of the DBO solutions on the Ackley synthetic function in Figure 4, because it illustrates best the singularity of W-DBO. The Ackley function is known for its almost flat outer region (with lots of local minima) and its deep hole at the center of its domain. Observe that most DBO solutions miss that hole, as their average regrets skyrocket between 200 and

\begin{table}
\begin{tabular}{c c c c c c c} \hline Experiment (\(d+1\)) & GP-UCB & R-GP-UCB & TV-GP-UCB & ET-GP-UCB & ABO & W-DBO \\ \hline Rastrigin (5) & \(\mathbf{17.81}\) & \(53.67\) & \(26.50\) & \(19.54\) & \(36.16\) & \(18.54\) \\ Schwefel (4) & \(469.10\) & \(954.03\) & \(520.40\) & \(428.97\) & \(662.32\) & \(\mathbf{290.34}\) \\ StyblinskiTang (4) & \(18.83\) & \(45.82\) & \(15.74\) & \(22.16\) & \(58.40\) & \(\mathbf{13.04}\) \\ Eggholder (2) & \(542.53\) & \(273.60\) & \(287.01\) & \(559.61\) & \(256.92\) & \(\mathbf{225.68}\) \\ Ackley (4) & \(4.10\) & \(4.45\) & \(3.27\) & \(3.96\) & \(3.63\) & \(\mathbf{2.24}\) \\ Rosenbrock (3) & \(31.37\) & \(25.99\) & \(17.55\) & \(28.79\) & \(171.04\) & \(\mathbf{3.81}\) \\ Shekel (4) & \(2.56\) & \(2.21\) & \(2.03\) & \(2.70\) & \(2.06\) & \(\mathbf{1.72}\) \\ Hartmann3 (3) & \(1.17\) & \(\mathbf{0.26}\) & \(0.82\) & \(1.06\) & \(0.55\) & \(0.35\) \\ Hartmann6 (6) & \(1.33\) & \(1.25\) & \(0.44\) & \(1.46\) & \(0.61\) & \(\mathbf{0.32}\) \\ Powell (4) & \(1992.1\) & \(1167.6\) & \(1223.4\) & \(534.2\) & \(9888.6\) & \(\mathbf{428.1}\) \\ \hline Temperature (3) & \(1.02\) & \(0.69\) & \(1.36\) & \(1.25\) & \(1.21\) & \(\mathbf{0.68}\) \\ WLAN (5) & \(1.46\) & \(4.84\) & \(1.33\) & \(4.98\) & \(12.94\) & \(\mathbf{1.19}\) \\ \hline Avg. Perf. & \(0.48\) & \(0.47\) & \(0.29\) & \(0.54\) & \(0.62\) & \(\mathbf{0.01}\) \\ \hline \end{tabular}
\end{table}
Table 2: Comparison of W-DBO with competing methods. The average regret over 10 independent replications is reported (lower is better). The performance of the best algorithm is written in **bold text**. The performance of algorithms whose confidence intervals overlap the best performing algorithmâ€™s confidence interval is underlined.

Figure 4: (Left) Average regrets of the DBO solutions during the optimization of the Ackley synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Ackley function.

400 seconds. In contrast, W-DBO manages to rapidly exploit the hole at the center of the function domain, thereby maintaining a low average regret.

This performance gap can be explained by studying the dataset size of W-DBO (see the right side of Figure 4). At first, the dataset size increases since most collected observations are relevant to predict the outer region of the Ackley function. After \(200\) seconds, the dataset size plateaus as W-DBO begins to realize that some previously collected observations are irrelevant to predict the shape of the hole that lies ahead. Between \(300\) and \(400\) seconds, the dataset size is halved because most previously collected observations are deemed irrelevant. Eventually, after \(400\) seconds, W-DBO explores the flatter outer region of the Ackley function again. Consequently, its dataset size increases again.

For a summary of the performance of the DBO solutions across all our benchmarks, please refer to the last row of Table 2, and to the visual summary in Figure 5. In our experimental setting, ABO and ET-GP-UCB obtain roughly the same performance as vanilla BO. R-GP-UCB shows slightly better average performance than GP-UCB, while TV-GP-UCB appears significantly better than the aforementioned algorithms. Remarkably, W-DBO shows significantly better performance than TV-GP-UCB and outperforms the other DBO solutions by a comfortable margin. In fact, it obtains the lowest average regret on almost every benchmark.

## 6 Conclusion

The ability to remove irrelevant observations from the dataset of a DBO algorithm is essential to ensure a high sampling frequency while preserving its predictive performance. To address this difficult problem, we have proposed (i) a criterion based on the Wasserstein distance to measure the relevancy of an observation, (ii) a computationally tractable approximation of this criterion to allow its use in an online setting and (iii) a DBO algorithm, W-DBO, that exploits this approximation. We have evaluated W-DBO against the state-of-the-art of DBO on a variety of benchmarks comprising synthetic functions and real-world experiments. The evaluation was conducted in the most challenging settings, where time is continuous, the time horizon is unknown, as well as the covariance functions hyperparameters. We observe that W-DBO outperforms the state-of-the-art of DBO by a comfortable margin. We explain this significant performance gap by the ability of W-DBO to quantify the relevancy of each of its observations, which is not shared with any other DBO algorithm, to the best of our knowledge. As a result, W-DBO can remove irrelevant observations in a smoother and more appropriate way than by simply triggering the erasure of the whole dataset. By doing so, W-DBO simultaneously ensures a high sampling frequency and a very good predictive performance.

In addition to its impact on DBO itself, we believe that W-DBO can have a significant impact on the fields that make heavy use of DBO (e.g., computer networks, robotics). As a future work, we plan on exploring these applications of W-DBO. Furthermore, we plan on better understanding the excellent performance of W-DBO by addressing the difficult problem of deriving a regret bound that holds in a continuous time setting and incorporates the effect of the sampling frequency of the DBO algorithm as well as the deletion of irrelevant observations.

Figure 5: Visual summary of the results reported in Table 2. For aggregation purposes, the average regrets in each experiment have been normalized between 0 (lowest average regret) and 1 (largest average regret). The average performance of the DBO solutions is shown in black.

## References

* [1] James Bergstra, Daniel Yamins, and David Cox. Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures. In _International conference on machine learning_, pages 115-123. PMLR, 2013.
* [2] Gregory Hornby, Al Globus, Derek Linden, and Jason Lohn. Automated antenna design with evolutionary algorithms. In _American Institute of Aeronautics and Astronautics_, 2006.
* [3] Anthony Bardou and Thomas Begin. INSPIRE: Distributed Bayesian Optimization for Improv-iNg SPatlal REuse in Dense WLANs. In _Proceedings of the 25th International ACM Conference on Modeling Analysis and Simulation of Wireless and Mobile Systems_, pages 133-142, 2022.
* [4] Daniel Lizotte, Tao Wang, Michael Bowling, and Dale Schuurmans. Automatic gait optimization with gaussian process regression. In _Proceedings of the 20th International Joint Conference on Artifical Intelligence_, IJCAI'07, page 944-949, San Francisco, CA, USA, 2007. Morgan Kaufmann Publishers Inc.
* [5] Javier Gonzalez, Joseph Longworth, David C. James, and Neil D. Lawrence. Bayesian optimization for synthetic gene design. In _NIPS Workshop on Bayesian Optimization in Academia and Industry_, 2014.
* [6] David Eriksson, Michael Pearce, Jacob Gardner, Ryan D Turner, and Matthias Poloczek. Scalable global optimization via local bayesian optimization. In _Advances in Neural Information Processing Systems_, volume 32. Curran Associates, Inc., 2019.
* [7] Johannes Kirschner, Mojmir Mutny, Nicole Hiller, Rasmus Ischebeck, and Andreas Krause. Adaptive and safe bayesian optimization in high dimensions via one-dimensional subspaces. In _International Conference on Machine Learning_, pages 3429-3438. PMLR, 2019.
* [8] Anthony Bardou, Patrick Thiran, and Thomas Begin. Relaxing the additivity constraints in decentralized no-regret high-dimensional bayesian optimization. In _The Twelfth International Conference on Learning Representations_, 2024.
* [9] Javier Gonzalez, Zhenwen Dai, Philipp Hennig, and Neil Lawrence. Batch bayesian optimization via local penalization. In _Artificial intelligence and statistics_, pages 648-657. PMLR, 2016.
* [10] Samuel Daulton, David Eriksson, Maximilian Balandat, and Eytan Bakshy. Multi-objective bayesian optimization over high-dimensional search spaces. In _Uncertainty in Artificial Intelligence_, pages 507-517. PMLR, 2022.
* [11] Seokhyun Kim, Kimin Lee, Yeonkeun Kim, Jinwoo Shin, Seungwon Shin, and Song Chong. Dynamic control for on-demand interference-managed wlan infrastructures. _IEEE/ACM Transactions on Networking_, 28(1):84-97, 2019.
* [12] Aurelio G Melo, Milena F Pinto, Andre LM Marcato, Leonardo M Honorio, and Fabricio O Coelho. Dynamic optimization and heuristics based online coverage path planning in 3d environment for uavs. _Sensors_, 21(4):1108, 2021.
* [13] Doyen Sahoo, Quang Pham, Jing Lu, and Steven CH Hoi. Online deep learning: learning deep neural networks on the fly. In _Proceedings of the 27th International Joint Conference on Artificial Intelligence_, pages 2660-2666, 2018.
* [14] Charu C Aggarwal, Jiawei Han, Jianyong Wang, and Philip S Yu. A framework for projected clustering of high dimensional data streams. In _Proceedings of the Thirtieth international conference on Very large data bases-Volume 30_, pages 852-863, 2004.
* [15] Xiao Mingming, Zhang Jun, Cai Kaiquan, Cao Xianbin, and Tang Ke. Cooperative co-evolution with weighted random grouping for large-scale crossing waypoints locating in air route network. In _2011 IEEE 23rd International Conference on Tools with Artificial Intelligence_, pages 215-222. IEEE, 2011.
* [16] Christopher Williams and Carl Rasmussen. Gaussian processes for regression. _Advances in neural information processing systems_, 8, 1995.
* [17] Niranjan Srinivas, Andreas Krause, Sham M. Kakade, and Matthias W. Seeger. Information-theoretic regret bounds for gaussian process optimization in the bandit setting. _IEEE Transactions on Information Theory_, 58(5):3250-3265, 2012.
* [18] Jonas Mockus. Application of bayesian approach to numerical methods of global and stochastic optimization. _Journal of Global Optimization_, 4:347-365, 1994.

* [19] Donald R. Jones, Matthias Schonlau, and William J. Welch. Efficient global optimization of expensive black-box functions. _Journal of Global optimization_, 13(4):455-492, 1998.
* [20] Favour M Nyikosa, Michael A Osborne, and Stephen J Roberts. Bayesian optimization for dynamic problems. _arXiv preprint arXiv:1803.03432_, 2018.
* [21] Ilija Bogunovic, Jonathan Scarlett, and Volkan Cevher. Time-varying gaussian process bandit optimization. In _Artificial Intelligence and Statistics_, pages 314-323. PMLR, 2016.
* [22] Paul Brunzema, Alexander von Rohr, Friedrich Solowjow, and Sebastian Trimpe. Event-triggered time-varying bayesian optimization. _arXiv preprint arXiv:2208.10790_, 2022.
* [23] Xingyu Zhou and Ness Shroff. No-regret algorithms for time-varying bayesian optimization. In _2021 55th Annual Conference on Information Sciences and Systems (CISS)_, pages 1-6. IEEE, 2021.
* [24] Yuntian Deng, Xingyu Zhou, Baekjin Kim, Ambuj Tewari, Abhishek Gupta, and Ness Shroff. Weighted gaussian process bandits for non-stationary environments. In _International Conference on Artificial Intelligence and Statistics_, pages 6909-6932. PMLR, 2022.
* [25] Joaquin Quinonero-Candela and Carl Edward Rasmussen. A unifying view of sparse approximate gaussian process regression. _The Journal of Machine Learning Research_, 6:1939-1959, 2005.
* [26] Henry B Moss, Sebastian W Ober, and Victor Picheny. Inducing point allocation for sparse gaussian processes in high-throughput bayesian optimisation. In _International Conference on Artificial Intelligence and Statistics_, pages 5213-5230. PMLR, 2023.
* [27] Christopher KI Williams and Carl Edward Rasmussen. _Gaussian processes for machine learning_, volume 2. MIT press Cambridge, MA, 2006.
* [28] Leonid V Kantorovich. Mathematical methods of organizing and planning production. _Management science_, 6(4):366-422, 1960.
* [29] Anton Mallasto and Aasa Feragen. Learning from uncertain curves: The 2-wasserstein metric for gaussian processes. _Advances in Neural Information Processing Systems_, 30, 2017.
* [30] Emilio Porcu, Moreno Bevilacqua, Robert Schaback, and Chris J Oates. The mat\'ern model: A journey through statistics, numerical analysis and machine learning. _arXiv preprint arXiv:2303.02759_, 2023.
* [31] Izrail Solomonovich Gradshteyn and Iosif Moiseevich Ryzhik. _Table of integrals, series, and products_. Academic press, 2014.
* [32] Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, Andrew Gordon Wilson, and Eytan Bakshy. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization. In _Advances in Neural Information Processing Systems 33_, 2020.
* seamless operability between c++11 and python, 2017. https://github.com/pybind/pybind11.
* [34] JHB Kemperman. On the shannon capacity of an arbitrary channel. In _Indagationes Mathematicae (Proceedings)_, volume 77, pages 101-115. North-Holland, 1974.

## Appendix A Wasserstein Distance at a Point in \(\mathcal{F}_{t_{0}}\)

At the core of (8) lies (7). In this appendix, we provide explicit expressions for (7). Let us start by proving the following lemma.

**Lemma A.1**.: \[\bm{\Delta}_{\mathcal{D}}^{-1}=\begin{pmatrix}\bm{E}&\bm{G}\\ \bm{H}&\bm{F}\end{pmatrix}\] (13)

_with \(\bm{\Delta}_{\mathcal{D}}=\bm{k}(\mathcal{D},\mathcal{D})+\sigma^{2}\bm{I}\) and \(\bm{E},\bm{F},\bm{G},\bm{H}\) defined as_

\[\bm{E} =\left(\lambda+\sigma^{2}-\bm{k}^{\top}\left((\bm{x}_{1},t_{1}), \tilde{\mathcal{D}}\right)\bm{\Delta}_{\tilde{\mathcal{D}}}^{-1}\bm{k}\left(( \bm{x}_{1},t_{1}),\tilde{\mathcal{D}}\right)\right)^{-1},\] (14) \[\bm{F} =\left(\bm{\Delta}_{\tilde{\mathcal{D}}}-\frac{1}{\lambda+\sigma ^{2}}\bm{k}\left((\bm{x}_{1},t_{1}),\tilde{\mathcal{D}}\right)\bm{k}^{\top} \left((\bm{x}_{1},t_{1}),\tilde{\mathcal{D}}\right)\right)^{-1},\] (15) \[\bm{G} =-\bm{E}\bm{k}^{\top}\left((\bm{x}_{1},t_{1}),\tilde{\mathcal{D} }\right)\bm{\Delta}_{\tilde{\mathcal{D}}}^{-1},\] (16) \[\bm{H} =-\frac{1}{\lambda+\sigma^{2}}\bm{F}\bm{k}\left((\bm{x}_{1},t_{1 }),\tilde{\mathcal{D}}\right),\] (17)

_where \(\bm{k}\left(\mathcal{X},\mathcal{Y}\right)=\left(k\left(\left(\bm{x}_{i},t_{i} \right),\left(\bm{x}_{j},t_{j}\right)\right)\right)_{\begin{subarray}{c}(\bm {x}_{i},t_{i})\in\mathcal{X}\\ (\bm{x}_{j},t_{j})\in\mathcal{Y}\end{subarray}}\) and \(\bm{\Delta}_{\tilde{\mathcal{D}}}=\bm{k}(\tilde{\mathcal{D}},\tilde{\mathcal{D }})+\sigma^{2}\bm{I}\)._

Proof.: The proof is trivial using the inverse of a block matrix:

\[\begin{pmatrix}\bm{A}&\bm{B}\\ \bm{C}&\bm{D}\end{pmatrix}^{-1} =\begin{pmatrix}\left(\bm{A}-\bm{B}\bm{D}^{-1}\bm{C}\right)^{-1}& \bm{0}\\ \bm{0}&\left(\bm{D}-\bm{C}\bm{A}^{-1}\bm{B}\right)^{-1}\end{pmatrix}\begin{pmatrix} \bm{I}&-\bm{B}\bm{D}^{-1}\\ -\bm{C}\bm{A}^{-1}&\bm{I}\end{pmatrix}\] \[=\begin{pmatrix}\left(\bm{A}-\bm{B}\bm{D}^{-1}\bm{C}\right)^{-1}& -\left(\bm{A}-\bm{B}\bm{D}^{-1}\bm{C}\right)^{-1}\bm{B}\bm{D}^{-1}\\ -\left(\bm{D}-\bm{C}\bm{A}^{-1}\bm{B}\right)^{-1}\bm{C}\bm{A}^{-1}&\left(\bm{D} -\bm{C}\bm{A}^{-1}\bm{B}\right)^{-1}\end{pmatrix}.\] (18)

Note that \(\bm{A}\) and \(\bm{D}\) must be invertible.

We can use (18) to write \(\bm{\Delta}_{\mathcal{D}}^{-1}\) as a function of \(\bm{\Delta}_{\tilde{\mathcal{D}}}^{-1}\), since

\[\bm{\Delta}_{\mathcal{D}}^{-1} =\begin{pmatrix}k((\bm{x}_{1},t_{1}),(\bm{x}_{1},t_{1}))+\sigma^{ 2}&\bm{k}^{\top}((\bm{x}_{1},t_{1}),\tilde{\mathcal{D}})\\ \bm{k}((\bm{x}_{1},t_{1}),\tilde{\mathcal{D}})&\bm{\Delta}_{\tilde{\mathcal{D }}}\end{pmatrix}^{-1}\] \[=\begin{pmatrix}\lambda+\sigma^{2}&\bm{k}^{\top}((\bm{x}_{1},t_{1 }),\tilde{\mathcal{D}})\\ \bm{k}((\bm{x}_{1},t_{1}),\tilde{\mathcal{D}})&\bm{\Delta}_{\tilde{\mathcal{D }}}\end{pmatrix}^{-1}.\] (19)

Note that, in (19), \(\lambda+\sigma^{2}\) and \(\bm{\Delta}_{\tilde{\mathcal{D}}}\) are invertible. Therefore, (18) can be applied to (19), and this yields the desired result. 

To compute (7), we provide the following results.

**Proposition A.2**.: \[\mu_{\mathcal{D}}(\bm{x},t)-\mu_{\tilde{\mathcal{D}}}(\bm{x},t)=ak((\bm{x},t), (\bm{x}_{1},t_{1}))+\bm{b}\bm{k}\left((\bm{x},t),\tilde{\mathcal{D}}\right),\] (20)

_with \(a=\bm{E}y_{1}+\bm{G}\tilde{\bm{y}}\), \(\bm{b}^{\top}=\bm{H}^{\top}y_{1}+\tilde{\bm{y}}^{\top}\left(\bm{F}-\bm{\Delta} _{\tilde{\mathcal{D}}}^{-1}\right)\) and \(\tilde{\bm{y}}=(y_{2},\cdots,y_{n})\)._

**Proposition A.3**.: \[\begin{split}(\sigma_{\mathcal{D}}(\bm{x},t)-\sigma_{\tilde{ \mathcal{D}}}(\bm{x},t))^{2}\leq\bm{E}k((\bm{x},t),(\bm{x}_{1},t_{1}))^{2}& +k((\bm{x},t),(\bm{x}_{1},t_{1}))\bm{ck}((\bm{x},t),\tilde{\mathcal{D}})\\ &+\bm{k}^{\top}((\bm{x},t),\tilde{\mathcal{D}})\bm{M}\bm{k}((\bm{x},t ),\tilde{\mathcal{D}}),\end{split}\] (21)

_with \(\bm{c}=\bm{G}+\bm{H}^{\top}\) and \(\bm{M}=\bm{F}-\bm{\Delta}_{\tilde{\mathcal{D}}}^{-1}\)._

We now prove Proposition A.2.

Proof.: According to (3)

\[\mu_{\tilde{\mathcal{D}}}(\bm{x},t)=\bm{k}^{\top}((\bm{x},t),\tilde{\mathcal{D}}) \bm{\Delta}_{\tilde{\mathcal{D}}}^{-1}\tilde{\bm{y}}.\] (22)

Applying the same definition for \(\mu_{\mathcal{D}}(\bm{x},t)\) we have

\[\mu_{\mathcal{D}}(\bm{x},t) =\left(k((\bm{x},t),(\bm{x}_{1},t_{1})),k^{\top}((\bm{x},t), \tilde{\mathcal{D}})\right)\bm{\Delta}_{\mathcal{D}}^{-1}\bm{y}\] \[=\left(k((\bm{x},t),(\bm{x}_{1},t_{1})),k^{\top}((\bm{x},t), \tilde{\mathcal{D}})\right)\begin{pmatrix}\bm{E}&\bm{G}\\ \bm{H}&\bm{F}\end{pmatrix}\bm{y}\] (23) \[=\left(k((\bm{x},t),(\bm{x}_{1},t_{1})),k^{\top}((\bm{x},t), \tilde{\mathcal{D}})\right)\begin{pmatrix}\bm{E}y_{1}+\bm{G}\tilde{\bm{y}}\\ \bm{H}y_{1}+\bm{F}\tilde{\bm{y}}\end{pmatrix}\] \[=k((\bm{x},t),(\bm{x}_{1},t_{1}))\left(\bm{E}y_{1}+\bm{G}\tilde{ \bm{y}}\right)+k^{\top}((\bm{x},t),\tilde{\mathcal{D}})\left(\bm{H}y_{1}+\bm{ F}\tilde{\bm{y}}\right),\] (24)

where (23) follows from Lemma A.1.

Finally, we have

\[\mu_{\mathcal{D}}(\bm{x},t)-\mu_{\tilde{\mathcal{D}}}(\bm{x},t)=k ((\bm{x},t),(\bm{x}_{1},t_{1}))\left(\bm{E}y_{1}+\bm{G}\tilde{\bm{y}}\right) +\bm{k}^{\top}((\bm{x},t),\tilde{\mathcal{D}})\left(\bm{H}y_{1}+\bm{F} \tilde{\bm{y}}\right)\] \[-\bm{k}^{\top}((\bm{x},t),\tilde{\mathcal{D}})\bm{\Delta}_{ \tilde{\mathcal{D}}}^{-1}\tilde{\bm{y}}\]

which can be reduced to

\[\mu_{\mathcal{D}}(\bm{x},t)-\mu_{\tilde{\mathcal{D}}}(\bm{x},t)=ak((\bm{x},t), (\bm{x}_{1},t_{1}))+\bm{b}\bm{k}((\bm{x},t),\tilde{\mathcal{D}})\] (25)

with \(a=\bm{E}y_{1}+\bm{G}\tilde{\bm{y}}\) and \(\bm{b}^{\top}=\bm{H}^{\top}y_{1}+\tilde{\bm{y}}^{\top}\left(\bm{F}-\bm{\Delta }_{\tilde{\mathcal{D}}}^{-1}\right)\). This concludes the proof. 

Finally, we prove Proposition A.3.

Proof.: As \((\sigma_{\mathcal{D}}(\bm{x},t)-\sigma_{\tilde{\mathcal{D}}}(\bm{x},t))^{2}\) is hard to integrate, to get (8), we upper bound it by

\[(\sigma_{\mathcal{D}}(\bm{x},t)-\sigma_{\tilde{\mathcal{D}}}(\bm{ x},t))^{2} =\sigma_{\mathcal{D}}^{2}(\bm{x},t)+\sigma_{\tilde{\mathcal{D}}}^{2}(\bm{x},t)-2 \sigma_{\mathcal{D}}(\bm{x},t)\sigma_{\tilde{\mathcal{D}}}(\bm{x},t)\] \[\leq\sigma_{\mathcal{D}}^{2}(\bm{x},t)+\sigma_{\tilde{\mathcal{D }}}^{2}(\bm{x},t)-2\sigma_{\mathcal{D}}^{2}(\bm{x},t)\] (26) \[=\sigma_{\tilde{\mathcal{D}}}^{2}(\bm{x},t)-\sigma_{\mathcal{D}}^ {2}(\bm{x},t)\] (27)

where (26) follows from \(\sigma_{\mathcal{D}}(\bm{x},t)\leq\sigma_{\tilde{\mathcal{D}}}(\bm{x},t)\).

Now, (4) yields that for \(\bm{X}=\tilde{\mathcal{D}}\),

\[\sigma_{\tilde{\mathcal{D}}}^{2}(\bm{x},t)=\lambda-\bm{k}^{\top}((\bm{x},t), \tilde{\mathcal{D}})\bm{\Delta}_{\tilde{\mathcal{D}}}^{-1}\bm{k}((\bm{x},t), \tilde{\mathcal{D}}).\] (28)

and for \(\bm{X}=\mathcal{D}=\tilde{\mathcal{D}}\cup\{(\bm{x}_{1},t_{1})\}\)

\[\sigma_{\mathcal{D}}^{2}(\bm{x},t) =\lambda-\left(k((\bm{x},t),(\bm{x}_{1},t_{1})),\bm{k}^{\top}(( \bm{x},t),\tilde{\mathcal{D}})\right)\bm{\Delta}_{\mathcal{D}}^{-1}\begin{pmatrix} k((\bm{x},t),(\bm{x}_{1},t_{1}))\\ \bm{k}((\bm{x},t),\tilde{\mathcal{D}})\end{pmatrix}\] \[=\lambda-\left(k((\bm{x},t),(\bm{x}_{1},t_{1})),\bm{k}^{\top}(( \bm{x},t),\tilde{\mathcal{D}})\right)\begin{pmatrix}\bm{E}&\bm{G}\\ \bm{H}&\bm{F}\end{pmatrix}\begin{pmatrix}k((\bm{x},t),(\bm{x}_{1},t_{1}))\\ \bm{k}((\bm{x},t),\tilde{\mathcal{D}})\end{pmatrix}\] (29) \[=\lambda-\left(k((\bm{x},t),(\bm{x}_{1},t_{1})),\bm{k}^{\top}(( \bm{x},t),\tilde{\mathcal{D}})\right)\begin{pmatrix}\bm{E}k((\bm{x},t),(\bm{x}_{1 },t_{1}))+\bm{G}\bm{k}((\bm{x},t),\tilde{\mathcal{D}})\\ \bm{H}k((\bm{x},t),(\bm{x}_{1},t_{1}))+\bm{F}\bm{k}((\bm{x},t),\tilde{\mathcal{ D}})\end{pmatrix}\] (30)

where (29) follows from Lemma A.1. Developing the dot product in (30), we have

\[\sigma_{\mathcal{D}}^{2}(\bm{x},t)=\lambda-\bm{E}k^{2}((\bm{x},t),(\bm{x}_{1},t _{1}))-k((\bm{x},t),(\bm{x}_{1},t_{1}))\bm{G}\bm{k}((\bm{x},t),\tilde{\mathcal{D}})\] (31) \[\qquad\qquad\qquad\qquad\qquad-k((\bm{x},t),(\bm{x}_{1},t_{1})) \bm{H}^{\top}\bm{k}((\bm{x},t),\tilde{\mathcal{D}})-\bm{k}^{\top}((\bm{x},t), \tilde{\mathcal{D}})\bm{F}\bm{k}((\bm{x},t),\tilde{\mathcal{D}}).\]

Combining (28) and (31), we get

\[\sigma_{\tilde{\mathcal{D}}}^{2}(\bm{x},t)-\sigma_{\mathcal{D}}^{2}(\bm{x},t)= \bm{E}k((\bm{x},t),(\bm{x}_{1},t_{1}))^{2} +k((\bm{x},t),(\bm{x}_{1},t_{1}))c\bm{k}((\bm{x},t),\tilde{\mathcal{D}})\] (32) \[+\bm{k}^{\top}((\bm{x},t),\tilde{\mathcal{D}})\bm{M}\bm{k}((\bm{ x},t),\tilde{\mathcal{D}})\]

where \(\bm{c}=\bm{G}+\bm{H}^{\top}\) and \(\bm{M}=\bm{F}-\bm{\Delta}_{\tilde{\mathcal{D}}}^{-1}\).

Combining (27) and (32) concludes the proof.

[MISSING_PAGE_FAIL:15]

[MISSING_PAGE_FAIL:16]

By linearity of the integral, the RHS of (44) can be split into three different integrals \(A\), \(B\) and \(C\) where

\[A =\oint_{\mathcal{S}}\int_{t_{0}}^{\infty}\bm{E}k((\bm{x},t),(\bm{x}_ {1},t_{1}))^{2}d\bm{x}dt\] \[B =\oint_{\mathcal{S}}\int_{t_{0}}^{\infty}k((\bm{x},t),(\bm{x}_{1},t_{1}))\bm{ck}((\bm{x},t),\tilde{\mathcal{D}})d\bm{x}dt\] \[C =\oint_{\mathcal{S}}\int_{t_{0}}^{\infty}\bm{k}^{\top}((\bm{x},t),\tilde{\mathcal{D}})\bm{Mk}((\bm{x},t),\tilde{\mathcal{D}})d\bm{x}dt\]

Once again, Lemma B.1 can be used to compute an upper bound for \(A\), \(B\) and \(C\). In fact,

\[A \leq\lambda^{2}\bm{E}C((\bm{x}_{1},t_{1}),(\bm{x}_{1},t_{1}))\] (45) \[B \leq\lambda^{2}\bm{c}C((\bm{x}_{1},t_{1}),\tilde{\mathcal{D}})\] (46) \[C \leq\lambda^{2}\bm{1}^{\top}\left(\bm{M}\odot C(\tilde{\mathcal{ D}},\tilde{\mathcal{D}})\right)\bm{1}\] \[=\operatorname{tr}\left(\bm{M}C(\tilde{\mathcal{D}},\tilde{ \mathcal{D}})\right),\] (47)

where \(\odot\) is the Hadamard product and \(\bm{1}\) is the conformable vector of ones.

Adding (45), (46) and (47) together concludes the proof. 

Together, Lemmas B.1, B.2 and B.3 yield the first part of Theorem 4.1. For the second part of Theorem 4.1, we prove the following lemma.

**Lemma B.4**.: _Let \(t_{0}\) be the present time and \(\mathcal{D}=\left\{\left((\bm{x}_{i},t_{i}),y_{i}\right)\right\}_{i\in[1,n]}\) be a dataset of observations before \(t_{0}\). Let \(\mathcal{F}_{t_{0}}=\mathcal{S}\times[t_{0},+\infty)\) the domain of future predictions. Then, we have_

\[W_{2}^{2}(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\emptyset})\leq\lambda^{2} \left(\bm{a}^{\top}C\left(\mathcal{D},\mathcal{D}\right)\bm{a}+\operatorname {tr}\left(\bm{\Delta}^{-1}C\left(\mathcal{D},\mathcal{D}\right)\right)\right)\] (48)

_with \(\bm{a}=\bm{\Delta}^{-1}\bm{y}\) and \(C(\mathcal{X},\mathcal{Y})=\left((k_{S}*k_{S})(\bm{x}_{j}-\bm{x}_{i})(k_{T}*k _{T})_{t_{0}-t_{i}}^{+\infty}(t_{j}-t_{i})\right)_{\begin{subarray}{c}(\bm{ x}_{i},t_{i})\in\mathcal{X},\\ (\bm{x}_{j},t_{j})\in\mathcal{Y}\end{subarray}}(f*g)\) the convolution between \(f\) and \(g\) restricted to the interval \([a,b]\)._

Proof.: Recall that, according to \(\mathcal{GP}_{\emptyset}\), \(f(\bm{x},t)\sim\mathcal{N}\left(0,\lambda\right)\) for any point \((\bm{x},t)\in\mathcal{F}_{t_{0}}\). Consequently,

\[W_{2}(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\emptyset})=\left(\oint_{ \mathcal{S}}\int_{t_{0}}^{\infty}\mu_{\mathcal{D}}^{2}(\bm{x},t)d\bm{x}dt+ \oint_{\mathcal{S}}\int_{t_{0}}^{\infty}\left(\sqrt{\lambda}-\sigma_{\mathcal{ D}}(\bm{x},t)\right)^{2}d\bm{x}dt\right)^{\frac{1}{2}}.\] (49)

These two integrals in (49) can be computed with the same techniques as above. For the mean integral, we have

\[\oint_{\mathcal{S}}\int_{t_{0}}^{\infty}\mu_{\mathcal{D}}^{2}(\bm {x},t)d\bm{x}dt =\oint_{\mathcal{S}}\int_{t_{0}}^{\infty}\bm{y}^{\top}\bm{\Delta} ^{-\top}\bm{k}^{\top}((\bm{x},t),\mathcal{D})\bm{k}((\bm{x},t),\mathcal{D}) \bm{\Delta}^{-1}\bm{y}d\bm{x}dt\] \[=\bm{y}^{\top}\bm{\Delta}^{-\top}\left(\oint_{\mathcal{S}}\int_{t _{0}}^{\infty}\bm{k}^{\top}((\bm{x},t),\mathcal{D})\bm{k}((\bm{x},t),\mathcal{D })d\bm{x}dt\right)\bm{\Delta}^{-1}\bm{y}\] \[\leq\lambda^{2}\bm{y}^{\top}\bm{\Delta}^{-\top}C(\mathcal{D}, \mathcal{D})\bm{\Delta}^{-1}\bm{y}.\] (50)

Regarding the variance integral in (49), we have

\[\oint_{\mathcal{S}}\int_{t_{0}}^{\infty}\left(\sqrt{\lambda}- \sigma_{\mathcal{D}}(\bm{x},t)\right)^{2}d\bm{x}dt =\oint_{\mathcal{S}}\int_{t_{0}}^{\infty}\left(\lambda-2\sqrt{ \lambda}\sigma_{\mathcal{D}}(\bm{x},t)+\sigma_{\mathcal{D}}^{2}(\bm{x},t) \right)d\bm{x}dt\] \[\leq\oint_{\mathcal{S}}\int_{t_{0}}^{\infty}\left(\lambda-\sigma_{ \mathcal{D}}^{2}(\bm{x},t)\right)d\bm{x}dt\] (51) \[=\oint_{\mathcal{S}}\int_{t_{0}}^{\infty}\bm{k}^{\top}((\bm{x},t),\mathcal{D})\bm{\Delta}^{-1}\bm{k}((\bm{x},t),\mathcal{D})d\bm{x}dt\] (52) \[\leq\lambda^{2}\operatorname{tr}\left(\bm{\Delta}^{-1}C\left( \mathcal{D},\mathcal{D}\right)\right)\] (53)where (51) holds because \(\sqrt{\lambda}\sigma_{\mathcal{D}}(\bm{x},t)\geq\sigma_{\mathcal{D}}^{2}(\bm{x},t)\) and (52) holds because of (4).

Together, (50) and (53) conclude the proof. 

By combining Lemmas B.2 and B.3, the proof of Theorem 4.1 is immediate.

## Appendix C Approximation Error

In Appendix B, we provided a computationally tractable upper bound of \(W_{2}(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\tilde{\mathcal{D}}})\) and \(W_{2}(\mathcal{GP}_{\mathcal{D}},\mathcal{GP}_{\emptyset})\). In this appendix, we provide the expression of the corresponding approximation error and we study its magnitude with the Squared-Exponential (SE) covariance function.

First, and without loss of generality, assume \(\mathcal{S}=[0,1]^{d}\). In Appendix B, we have to approximate the Wasserstein distance because the integration over \(\mathcal{S}\) in (34) is difficult to compute. The upper bound proposed in (35) is

\[\oint_{[0,1]^{d}}k_{S}(||\bm{x}-\bm{x}_{i}||_{2})k_{S}(||\bm{x}-\bm{x}_{j}||_{ 2})d\bm{x}\leq\oint_{\mathbb{R}^{d}}k_{S}(||\bm{x}-\bm{x}_{i}||_{2})k_{S}(|| \bm{x}-\bm{x}_{j}||_{2})d\bm{x}.\] (54)

Recall that the upper bounded quantity is a product of functions which are decreasing exponentially (see Table 1). As a consequence, their product decreases exponentially as well, so that extending the integration from \(\mathcal{S}=[0,1]^{d}\) to \(\mathbb{R}^{d}\) has a bounded impact on the result. Clearly, a first absolute approximation error for (54) is

\[\oint_{(\mathbb{R}\setminus[0,1]^{d}}k_{S}(||\bm{x}-\bm{x}_{i}||_{2})k_{S}(|| \bm{x}-\bm{x}_{j}||_{2})d\bm{x}.\]

Because the upper bounded quantity is a product of two correlation functions \(k_{S}\) on a hypercube of volume \(1\), the upper bound can be capped to \(1\) as well. This leads to the more refined absolute approximation error:

\[\begin{split} A(\bm{x}_{i},\bm{x}_{j};l_{S})=\min\left\{\oint_{( \mathbb{R}\setminus[0,1]^{d})}k_{S}(||\bm{x}-\bm{x}_{i}||_{2})k_{S}(||\bm{x}- \bm{x}_{j}||_{2})d\bm{x},\right.\\ \left.1-\oint_{[0,1]^{d}}k_{S}(||\bm{x}-\bm{x}_{i}||_{2})k_{S}(|| \bm{x}-\bm{x}_{j}||_{2})d\bm{x}\right\}.\end{split}\] (55)

Obtaining a closed-form for the approximation error (55) is difficult. However, because the spatial lengthscale controls the correlation lengths in the spatial domain, it is clear that the left term in (55) is an increasing function with respect to \(l_{S}\). Conversely, the right term in (55) is a decreasing function with respect to \(l_{S}\). This observation allows us to derive the spatial lengthscale for which (55) is maximal.

**Proposition C.1**.: _Let \((\bm{x}_{i},\bm{x}_{j})\in\mathcal{S}^{2}\), with \(\mathcal{S}=[0,1]^{d}\). Let \(k_{S}\) be a SE kernel with lengthscale \(l_{S}\). Then,_

\[\operatorname*{arg\,max}_{l_{S}\in\mathbb{R}^{+}}A(\bm{x}_{i},\bm{x}_{j};l_{S} )=\frac{1}{\sqrt{\pi}}e^{\frac{1}{2}W_{0}\left(\frac{\sigma||\bm{x}_{i}-\bm{x} _{j}||_{2}^{2}}{2d}\right)},\] (56)

_with \(W_{0}\) the principal branch of the Lambert function._

Proof.: Because the two terms in (55) are respectively increasing and decreasing with respect to the spatial lengthscale \(l_{S}\), (55) is maximal when both terms are equal. Therefore, from (55), we have the following relation

\[\oint_{(\mathbb{R}\setminus[0,1]^{d}}k_{S}(||\bm{x}-\bm{x}_{i}||_ {2})k_{S}(||\bm{x}-\bm{x}_{j}||_{2})d\bm{x} =1-\oint_{[0,1]^{d}}k_{S}(||\bm{x}-\bm{x}_{i}||_{2})k_{S}(||\bm{x}-\bm{x}_{j} ||_{2})d\bm{x},\] \[\oint_{\mathbb{R}^{d}}k_{S}(||\bm{x}-\bm{x}_{i}||_{2})k_{S}(||\bm {x}-\bm{x}_{j}||_{2})d\bm{x} =1,\] \[\pi^{\frac{d}{2}}l_{S}^{d}e^{-\frac{||\bm{x}_{i}-\bm{x}_{j}||_{2}^{ 2}}{4l_{S}^{3}}} =1,\] (57)where (57) uses a result derived in Appendix D and reported in Table 3. Solving for \(l_{S}\) concludes the proof. 

Let us illustrate (55) and Proposition C.1 by plotting the relative approximation error (55) with respect to the spatial lengthscale \(l_{S}\). The integral over \(\mathcal{S}\) is computed with a Monte-Carlo numerical integration technique. The results are shown in Figure 6. Looking at the top row, we see that the absolute approximation error peaks at a spatial lengthscale \(l_{S}^{*}\) given by (56), as anticipated above. For \(l_{S}<l_{S}^{*}\), the error is given by the first error term in (55), and conversely, the error is given by the second error term in (55) for \(l_{S}>l_{S}^{*}\). The bottom row of Figure 6 shows that the same observations apply to the relative errors.

Figure 6 shows that even though it is bounded, the approximation error of the upper bound (54) is non-negligible. This is particularly noticeable when looking at the relative errors in the bottom row of Figure 6, which clearly increases in magnitude with the dimensionality of the spatial domain.

Nevertheless, recall that we seek to approximate the ratio (9) with a ratio of upper bounded Wasserstein distances (12) that involve (54) both in the numerator and in the denominator. Because the spatial lengthscale \(l_{S}\) does not vary when computing the numerator and the denominator, the errors are of similar magnitude and point in the same direction (both the numerator and the denominator are upper

Figure 6: (Top row) Absolute approximation error (55) with respect to the spatial lengthscale \(l_{S}\) for a \(1\), \(3\) and \(5\)-dimensional spatial domain. Both error terms in (55) are shown in orange and green dashed lines, respectively. Finally, the critical lengthscale (56) is shown as a red vertical line. In this example, \(k_{S}\) is a SE correlation function. (Bottom row) Relative approximation error with respect to the spatial lengthscale \(l_{S}\). The color codes are the same.

Figure 7: Relative error between the criterion (9) and its approximation (12), with respect to the spatial lengthscale \(l_{S}\) for a \(1\), \(3\) and \(5\)-dimensional spatial domain. The relative error computed with both terms in (55) are shown as orange and green dashed lines, respectively. In this example, \(k_{S}\) is a SE correlation function.

bounds). As a consequence, the approximation errors compensate each other (at least in part) when computing (12). To verify this observation numerically, we compute the relative approximation error between the criterion (9) and its approximation (12). The results are shown in Figure 7. Although the approximation errors in the numerator and the denominator do not entirely compensate each other, the approximation (12) appears to have lost most of its dependency to the dimensionality of the spatial domain and to the spatial lengthscale, making (12) a decent approximation of (9) regardless of \(d\) or \(l_{S}\). In the main paper, Section 5 corroborates this observation by demonstrating the usefulness of the approximation (12) in practice.

## Appendix D Convolutions of Usual Covariance Functions

In this appendix, we derive the analytic forms of the convolution of usual covariance functions listed in Tables 3 and 4, which are used to compute the criterion (12).

### Spatial Covariance Functions

In this subsection, we compute specifically the analytic forms for the convolution of usual spatial covariance functions. We rely on a direct consequence of the convolution theorem, that is \((k*k)(\bm{x})=\mathcal{F}^{-1}\left(\mathcal{F}^{2}\left(k\right)\right)(\bm {x})\), with \(\mathcal{F}(f)\) denoting the Fourier transform of \(f\) and \(\mathcal{F}^{-1}(f)\) the inverse Fourier transform of \(f\).

The Fourier transform \(\mathcal{F}(k)\) of a stationary covariance function \(k\) is called the spectral density of \(k\), and is usually denoted \(S\). Both functions are Fourier duals of each other (see [27] for more details). Furthermore, it is known that if \(k\) is isotropic (_i.e._ it can be written as a function of \(r=||\bm{x}||_{2}\)), then its spectral density \(S(\bm{s})\) can be written as a function of \(s=||\bm{s}||_{2}\). In that case, the two functions are linked by the pair of transforms (see [27])

\[k(r) =\frac{2\pi}{r^{\frac{d}{2}-1}}\int_{0}^{\infty}S(s)J_{\frac{d}{2 }-1}(2\pi rs)^{s\frac{d}{2}}ds\] (58) \[S(s) =\frac{2\pi}{s^{\frac{d}{2}-1}}\int_{0}^{\infty}k(r)J_{\frac{d}{2 }-1}(2\pi rs)r^{\frac{d}{2}}dr\] (59)

where \(J_{\frac{d}{2}-1}\) is a Bessel function of the first kind and of order \(d/2-1\).

As an immediate consequence of (58), (59) and the convolution theorem, we have the following corollary.

\begin{table}
\begin{tabular}{l c} \hline Covariance Function \(k_{T}\) & \((k_{T}*k_{T})_{t_{0}-t_{i}}^{+\infty}(t_{j}-t_{i})\) \\ \hline Squared-Exponential (\(l_{T}\)) & \(\frac{\sqrt{\pi}l_{T}}{2}e^{\frac{-(t_{i}-t_{j})^{2}}{2l_{T}^{2}}}\left(1- \text{erf}\left(\frac{2t_{0}-t_{i}-t_{j}}{2l_{T}}\right)\right)\) \\ MatÃ©rn (\(\nu=p+\frac{1}{2},l_{T}\)) & \(\sum_{k_{1}=0}^{p}\sum_{k_{2}=0}^{p}C_{k_{1}k_{2}}e^{\frac{-\sqrt{2\pi l(2t_{0 }-t_{i}-t_{j})}}{l_{T}}}P_{k_{1}k_{2}}(t_{0},t_{i},t_{j})\) \\ \hline \end{tabular}
\end{table}
Table 4: Analytic forms for the convolution of usual temporal covariance functions on the interval \([t_{0}-t_{i},+\infty)\). Note that erf is the error function. Also, for the sake of brevity, the terms \(C_{k_{1}k_{2}}\), \(P_{k_{1}k_{2}}\) and \(Q_{k_{1}k_{2}}\) are defined in Appendix D.2.2.

\begin{table}
\begin{tabular}{l c} \hline Covariance Function \(k_{S}\) & \((k_{S}*k_{S})(\bm{x})\) \\ \hline Squared-Exponential (\(l_{S}\)) & \(\pi^{\frac{d}{2}}l_{S}^{\frac{-||\bm{x}||_{2}^{2}}{4l_{S}^{2}}}\) \\ MatÃ©rn (\(\nu,l_{S}\)) & \(\frac{2^{\frac{d}{2}-2\nu+1}*\frac{\pi}{8}\Gamma(\nu+\frac{d}{2})^{2}}{\Gamma( \nu)^{2}\Gamma(2\nu+d)}\left(\frac{\sqrt{2\nu}}{l_{S}}\right)^{2\nu-\frac{d} {2}}||\bm{x}||_{2}^{2\nu+\frac{d}{2}}K_{2\nu+\frac{d}{2}}\left(\frac{||\bm{x}|| _{2}\sqrt{2\nu}}{l_{S}}\right)\) \\ \hline \end{tabular}
\end{table}
Table 3: Analytic forms for the convolution of usual spatial covariance functions. \(\Gamma\) is the Gamma function, \(J_{\alpha}\) is a Bessel function of the first kind of order \(\alpha\), \(K_{\alpha}\) is a modified Bessel function of the second kind of order \(\alpha\).

**Corollary D.1**.: _Let \(k\) be a stationary, isotropic covariance function with spectral density \(S\). Let \(r=||\bm{x}||_{2}\) and \(s=||\bm{s}||_{2}\). Then,_

\[(k*k)(r)=\frac{2\pi}{r^{\frac{d}{2}-1}}\int_{0}^{\infty}S^{2}(s)J_{\frac{d}{2}-1 }(2\pi rs)s^{\frac{d}{2}}ds\] (60)

_where \(J_{\frac{d}{2}-1}\) is a Bessel function of the first kind and of order \(d/2-1\)._

We now derive the analytic forms for the convolutions of usual spatial covariance functions \(k_{S}\).

#### d.1.1 Squared-Exponential Covariance Function

**Lemma D.2**.: _Let \(k_{S}\) be a Squared-Exponential covariance function (see Table 1), with lengthscale \(l_{S}>0\). Then,_

\[(k_{S}*k_{S})(\bm{x})=\pi^{\frac{d}{2}}l_{S}^{2}e^{\frac{-||\bm{x}||_{2}^{2}}{ 4l_{S}^{2}}}.\] (61)

Proof.: The spectral density of a Squared-Exponential covariance function \(k_{S}\) is (see [27])

\[S(s)=(2\pi l_{S}^{2})^{\frac{d}{2}}e^{-2\pi^{2}l_{S}^{2}s^{2}}.\] (62)

According to Corollary D.1, we have

\[(k_{S}*k_{S})(\bm{x}) =\frac{2\pi}{r^{\frac{d}{2}-1}}\int_{0}^{\infty}S^{2}(s)J_{\frac {d}{2}-1}(2\pi rs)s^{\frac{d}{2}}ds\] \[=\frac{2\pi}{r^{\frac{d}{2}-1}}\int_{0}^{\infty}(2\pi l_{S}^{2}) ^{d}e^{-4\pi^{2}l_{S}^{2}s^{2}}J_{\frac{d}{2}-1}(2\pi rs)s^{\frac{d}{2}}ds\] \[=\frac{(2\pi)^{d+1}\,l_{S}^{2d}}{r^{\frac{d}{2}-1}}\int_{0}^{ \infty}e^{-4\pi^{2}l_{S}^{2}s^{2}}J_{\frac{d}{2}-1}(2\pi rs)s^{\frac{d}{2}}ds\] (63)

where \(r=||\bm{x}||_{2}\) and \(J_{\frac{d}{2}-1}\) is a Bessel function of the first kind of order \(\frac{d}{2}-1\).

It is known (see [31]) that

\[\int_{0}^{\infty}e^{-\alpha x^{2}}x^{\nu+1}J_{\nu}(\beta x)dx=\frac{\beta^{ \nu}}{(2\alpha)^{\nu+1}}e^{\frac{-\beta^{2}}{4\alpha}}.\]

Therefore,

\[(k_{S}*k_{S})(\bm{x}) =\frac{(2\pi)^{d+1}\,l_{S}^{2d}}{r^{\frac{d}{2}-1}}\frac{(2\pi r) ^{\frac{d}{2}-1}}{(8\pi^{2}l_{S}^{2})^{\frac{d}{2}}}e^{\frac{-4\pi^{2}s^{2}} {16\pi^{2}l_{S}^{2}}}\] \[=\pi^{\frac{d}{2}}l_{S}^{d}e^{\frac{-r^{2}}{4l_{S}^{2}}}.\] (64)

Replacing \(r\) by \(||\bm{x}||_{2}\) in (64) concludes the proof. 

#### d.1.2 Matern Covariance Function

**Lemma D.3**.: _Let \(k_{S}\) be a Matern covariance function (see Table 1), with smoothness parameter \(\nu>0\) and lengthscale \(l_{S}>0\). Then,_

\[(k_{S}*k_{S})(\bm{x})=\frac{2^{\frac{d}{2}-2\nu+1}\pi^{\frac{d}{2}}\Gamma(\nu +\frac{d}{2})^{2}}{\Gamma(\nu)^{2}\Gamma(2\nu+d)}\left(\frac{\sqrt{2\nu}}{l_ {S}}\right)^{2\nu-\frac{d}{2}}||\bm{x}||_{2}^{2\nu+\frac{d}{2}}K_{2\nu+\frac{d }{2}}\left(\frac{||\bm{x}||_{2}\sqrt{2\nu}}{l_{S}}\right),\] (65)

_where \(\Gamma\) is the Gamma function and \(K_{\alpha}\) is a modified Bessel function of the second kind of order \(\alpha\)._

Proof.: The spectral density of a Matern covariance function \(k_{S}\) is (see [27])

\[S(s)=\frac{2^{d}\pi^{\frac{d}{2}}\Gamma(\nu+\frac{d}{2})(2\nu)^{\nu}}{\Gamma( \nu)l_{S}^{2\nu}}\left(\frac{2\nu}{l_{S}^{2}}+4\pi^{2}s^{2}\right)^{-\nu-\frac {d}{2}}\] (66)where \(\Gamma\) is the Gamma function.

According to Corollary D.1, we have

\[(k_{S}*k_{S})(\bm{x}) =\frac{2\pi}{r^{\frac{d}{2}-1}}\int_{0}^{\infty}S^{2}(s)J_{\frac{d}{ 2}-1}(2\pi rs)s^{\frac{d}{2}}ds\] \[=\frac{2\pi}{r^{\frac{d}{2}-1}}\int_{0}^{\infty}\frac{2^{2d}\pi^{ d}\Gamma^{2}(\nu+\frac{d}{2})(2\nu)^{2\nu}}{\Gamma^{2}(\nu)l_{S}^{4\nu}}\left( \frac{2\nu}{l_{S}^{2}}+4\pi^{2}s^{2}\right)^{-2\nu-d}J_{\frac{d}{2}-1}(2\pi rs )s^{\frac{d}{2}}ds\] \[=\frac{2^{2d+1}\pi^{d+1}\Gamma^{2}(\nu+\frac{d}{2})(2\nu)^{2\nu} }{\Gamma^{2}(\nu)l_{S}^{4\nu}r^{\frac{d}{2}-1}}\int_{0}^{\infty}\left(\frac{2 \nu}{l_{S}^{2}}+4\pi^{2}s^{2}\right)^{-2\nu-d}J_{\frac{d}{2}-1}(2\pi rs)s^{ \frac{d}{2}}ds\] \[=\frac{2^{\frac{3d}{2}}\pi^{\frac{d}{2}}\Gamma^{2}(\nu+\frac{d}{2 })(2\nu)^{2\nu}}{\Gamma^{2}(\nu)l_{S}^{4\nu}r^{\frac{d}{2}-1}}\int_{0}^{\infty }\left(\frac{2\nu}{l_{S}^{2}}+u^{2}\right)^{-2\nu-d}J_{\frac{d}{2}-1}(ru)u^{ \frac{d}{2}}du\] (67)

where \(J_{\frac{d}{2}-1}\) is a Bessel function of the first kind of order \(\frac{d}{2}-1\), and (67) comes from the change of variable \(u=2\pi s\).

It is known (see [31]) that

\[\int_{0}^{\infty}(a^{2}+x^{2})^{-(\mu+1)}J_{\alpha}(bx)x^{\alpha+1}dx=\frac{a ^{\alpha-\mu}b^{\mu}}{2^{\mu}\Gamma(\mu+1)}K_{\mu-\alpha}(ab)\]

where \(K_{\mu-\alpha}\) is a modified Bessel function of the second kind of order \(\mu-\alpha\).

Therefore,

\[(k_{S}*k_{S})(\bm{x}) =\frac{2^{\frac{3d}{2}}\pi^{\frac{d}{2}}\Gamma^{2}(\nu+\frac{d}{ 2})(2\nu)^{2\nu}}{\Gamma^{2}(\nu)l_{S}^{4\nu}r^{\frac{d}{2}-1}}\left(\frac{ \sqrt{2\nu}}{l_{S}}\right)^{-2\nu-\frac{d}{2}}\frac{r^{2\nu+d-1}}{2^{2\nu+d-1 }\Gamma(2\nu+d)}K_{2\nu+\frac{d}{2}}\left(\frac{r\sqrt{2\nu}}{l_{S}}\right)\] \[=\frac{2^{\frac{d}{2}-2\nu+1}\pi^{\frac{d}{2}}\Gamma(\nu+\frac{d} {2})^{2}}{\Gamma(\nu)^{2}\Gamma(2\nu+d)}\left(\frac{\sqrt{2\nu}}{l_{S}} \right)^{2\nu-\frac{d}{2}}r^{2\nu+\frac{d}{2}}K_{2\nu+\frac{d}{2}}\left(\frac{ r\sqrt{2\nu}}{l_{S}}\right).\] (68)

Replacing \(r\) by \(||\bm{x}||_{2}\) in (68) concludes the proof. 

### Temporal Covariance Functions

In this section, we derive the analytic expression of the convolutions of the most popular temporal covariance functions \(k_{T}\) restricted to the interval \([t_{0}-t_{i},+\infty)\). Therefore, we compute many integrals of the form

\[\int_{t_{0}-t_{i}}^{+\infty}k_{T}(|t|)k_{T}(|t_{j}-t_{i}-t|)dt,\]

which can be rewritten as

\[\int_{t_{0}-t_{i}}^{+\infty}k_{T}(t)k_{T}(t+t_{i}-t_{j})dt.\] (69)

since \(t\geq 0\) and \(t_{j}-t_{i}-t\leq 0\) for all \(t\in[t_{0}-t_{i},+\infty)\). The form (69) will be used in every proof of this section.

#### d.2.1 Squared-Exponential Covariance Function

**Lemma D.4**.: _Let \(k_{T}\) be a Squared-Exponential covariance function (see Table 1), with lengthscale \(l_{S}>0\). Then,_

\[(k_{T}*k_{T})_{t_{0}-t_{i}}^{+\infty}(t_{i}-t_{j})=\frac{\sqrt{\pi}l_{T}}{2}e^{ \frac{-(t_{i}-t_{j})^{2}}{2l_{T}^{2}}}\left(1-\text{erf}\left(\frac{2t_{0}-t_{i} -t_{j}}{2l_{T}}\right)\right)\] (70)

_where erf is the error function._Proof.: Since \(k_{T}\) is a Squared-Exponential function, (69) becomes

\[\int_{t_{0}-t_{i}}^{+\infty}e^{\frac{-(t-t_{j}+t_{i})^{2}}{2t_{T}^{2} }}e^{-\frac{(t-t_{j}+t_{i})^{2}}{2t_{T}^{2}}}dt\] \[= \int_{t_{0}-t_{i}}^{+\infty}e^{\frac{-(2t^{2}-2(t_{j}-t_{i})t+t_{ j}^{2}+t_{j}^{2}-2t_{i}t_{j})}{2t_{T}^{2}}}dt.\] (71)

It is known (see [31]) that

\[\int e^{-(ax^{2}+2bx+c)}dx=\frac{1}{2}\sqrt{\frac{\pi}{a}}e^{\frac{b^{2}-ac}{a }}\text{erf}\left(\sqrt{a}x+\frac{b}{\sqrt{a}}\right)\]

where erf is the error function.

Therefore, (71) becomes

\[\frac{\sqrt{\pi}l_{T}}{2}e^{\frac{-(t_{i}-t_{j})^{2}}{2t_{T}^{2}}}\left(1- \text{erf}\left(\frac{2t_{0}-t_{i}-t_{j}}{2l_{T}}\right)\right).\]

#### d.2.2 Matern Covariance Function

**Lemma D.5**.: _Let \(k_{T}\) be a Matern covariance function (see Table 1), with smoothness parameter \(\nu=p+\frac{1}{2},p\in\mathbb{N}\) and lengthscale \(l_{T}>0\). Then,_

\[(k_{T}*k_{T})_{t_{0}-t_{i}}^{l_{T}+t_{0}-t_{i}}(t_{i}-t_{j})=\sum_{k_{1}=0}^{ p}\sum_{k_{2}=0}^{p}C_{k_{1}k_{2}}e^{\frac{-\sqrt{2p+1}(2t_{0}-t_{i}-t_{j})}{l_{T }}}P_{k_{1}k_{2}}(t_{0},t_{i},t_{j})\] (72)

_where_

\[C_{k_{1}k_{2}} =\left(\frac{p!}{(2p)!}\right)^{2}\frac{(p+k_{1})!(p+k_{2})!}{k_{1 }!k_{2}!(p-k_{1})!(p-k_{2})!}\left(\frac{2\sqrt{2p+1}}{l_{T}}\right)^{2p-k_{1 }-k_{2}-1},\] (73) \[P_{k_{1}k_{2}}(t_{0},t_{i},t_{j}) =\sum_{k_{3}=0}^{2p-k_{1}-k_{2}}\left(\frac{l_{T}}{2\sqrt{2p+1}} \right)^{k_{3}}P^{(k_{3})}(t_{0}-t_{i}),\] (74) \[P(t) =t^{p-k_{1}}(t-t_{j}+t_{i})^{p-k_{2}}\] (75)

_and \(P^{(k)}\) the \(k\)th derivative of \(P(t)\) with respect to \(t\)._

Proof.: The Matern covariance function has a simpler form when its smoothness parameter \(\nu\) is a half-integer, that is \(\nu=p+\frac{1}{2},p\in\mathbb{N}\) (see [30]). In that case,

\[k_{T}(t)=e^{\frac{-\sqrt{2p+1}t_{i}}{l_{T}}}\frac{p!}{(2p)!}\sum_{k_{1}=0}^{p} \frac{(p+k_{1})!}{k_{1}!(p-k_{1})!}\left(\frac{2\sqrt{2p+1}t}{l_{T}}\right)^{p -k_{1}}.\]

Therefore,

\[k_{T}(t)k_{T}(t+t_{i}-t_{j})=\frac{2\sqrt{2p+1}}{l_{T}}\sum_{k_{1}=0}^{p} \sum_{k_{2}=0}^{p}C_{k_{1}k_{2}}e^{\frac{-\sqrt{2p+1}(2t-t_{j}+t_{j})}{l_{T}}} P(t)\] (76)

with \(C_{k_{1}k_{2}}\) defined in (73) and \(P(t)\) defined in (75).

Integrating (76), we get

\[\frac{2\sqrt{2p+1}}{l_{T}}\sum_{k_{1}=0}^{p}\sum_{k_{2}=0}^{p}C_{k_{1}k_{2}}e^ {\frac{-\sqrt{2p+1}(t_{i}-t_{j})}{l_{T}}}\int_{t_{0}-t_{i}}^{+\infty}e^{\frac {-2\sqrt{2p+1}t}{l_{T}}}P(t)dt\] (77)

thanks to the linearity of the integral.

It is known (see [31]) that

\[\int P(x)e^{ax}dx=\frac{e^{ax}}{a}\sum_{k=0}^{m}(-1)^{k}\frac{P_{m}^{(k)}(x)}{a^{k}}\]

where \(P_{m}\) is a polynomial of degree \(m\) and \(P_{m}^{(k)}\) is the \(k\)th derivative of \(P_{m}\).

Therefore,

\[\int e^{\frac{-2\sqrt{2p+1}t}{t_{T}}}P(t)dt=-\frac{l_{T}}{2\sqrt{2p+1}}e^{- \frac{2\sqrt{2p+1}t}{l_{T}}}\sum_{k_{3}=0}^{2p-k_{1}-k_{2}}\frac{P^{(k_{3})}(t )l_{T}^{k_{3}}}{\left(2\sqrt{2p+1}\right)^{k_{3}}}\] (78)

Combining (77) and (78) we get

\[(k_{T}*k_{T})_{t_{0}-t_{i}}^{+\infty}(t_{i}-t_{j})=\sum_{k_{1}=0}^{p}\sum_{k_{ 2}=0}^{p}C_{k_{1}k_{2}}e^{\frac{-\sqrt{2p+1}(2t_{0}-t_{i}-t_{j})}{l_{T}}}P_{k_ {1}k_{2}}(t_{0},t_{i},t_{j})\]

with \(C_{k_{1}k_{2}}\) defined in (73) and \(P_{k_{1}k_{2}}\) defined in (74).

This concludes the proof. 

## Appendix E Extension to Anisotropic Spatial Kernels

In this appendix, we illustrate how Theorem 4.1 could be extended to anisotropic spatial kernels by considering an Automatic Relevance Detection (ARD) Squared-Exponential (SE). It has the following form:

\[k_{S}(\bm{x},\bm{y})=e^{-\frac{1}{2}(\bm{x}-\bm{y})^{\top}\bm{M}^{-2}(\bm{x}- \bm{y})}\] (79)

where \(\bm{M}=\text{diag}\,(l_{1},\cdots,l_{d})\) is a diagonal matrix that gathers a different lengthscale for each dimension. Observe that the isotropic SE with lengthscale \(l_{S}\) is retrieved by setting \(\bm{M}=l_{S}\bm{I}\).

Because the ARD SE kernel (79) is anisotropic, the convolution with itself

\[(k_{S}*k_{S})(\bm{x}-\bm{y})=\oint_{\mathbb{R}^{d}}k_{S}(\bm{x},\bm{z})k_{S}( \bm{y},\bm{z})d\bm{z}\] (80)

cannot be simplified to a one-dimensional integral through a change to polar coordinates, as done in Corollary D.1. The integral becomes more complex, but can still be computed exactly for some kernel such as the ARD SE.

**Lemma E.1**.: _Let \(k_{S}\) be an ARD SE covariance function with parameter \(\bm{M}\). Then,_

\[(k_{S}*k_{S})(\bm{x}-\bm{y})=\pi^{\frac{d}{2}}\det\left(\bm{M}\right)e^{- \frac{1}{4}(\bm{x}-\bm{y})^{\top}\bm{M}^{-2}(\bm{x}-\bm{y})}.\] (81)

Proof.: For the ARD SE kernel with parameter \(\bm{M}=\text{diag}\,(l_{1},\cdots,l_{d})\), the convolution (80) is

\[(k_{S}*k_{S})(\bm{x}-\bm{y}) =\oint_{\mathbb{R}^{d}}e^{-\frac{1}{2}(\bm{x}-\bm{z})^{\top}\bm{ M}^{-2}(\bm{x}-\bm{z})}e^{-\frac{1}{2}(\bm{y}-\bm{z})^{\top}\bm{M}^{-2}(\bm{y}- \bm{z})}d\bm{z}\] \[=e^{-\frac{1}{2}\left(\bm{x}\bm{M}^{-2}\bm{x}+\bm{y}\bm{M}^{-2} \bm{y}\right)}\oint_{\mathbb{R}^{d}}e^{-\bm{z}^{\top}\bm{M}^{-2}\bm{z}+\bm{z} ^{\top}\bm{M}^{-2}(\bm{x}+\bm{y})}d\bm{z}\] \[=e^{-\frac{1}{2}\left(\bm{x}\bm{M}^{-2}\bm{x}+\bm{y}\bm{M}^{-2} \bm{y}\right)}\oint_{\mathbb{R}^{d}}e^{\sum_{k=1}^{d}z_{k}(x_{k}+y_{k}-z_{k})/ l_{k}^{2}}dz_{1}\cdots dz_{d}\] \[=e^{-\frac{1}{2}\left(\bm{x}\bm{M}^{-2}\bm{x}+\bm{y}\bm{M}^{-2} \bm{y}\right)}\prod_{k=1}^{d}\int_{-\infty}^{+\infty}e^{z_{k}(x_{k}+y_{k}-z_{k })/l_{k}^{2}}dz_{k}.\] (82)

Integrating the \(k\)-th term in (82), we get

\[\int_{-\infty}^{+\infty}e^{z_{k}(x_{k}+y_{k}-z_{k})/l_{k}^{2}}dz_ {k} =\frac{1}{2}\sqrt{\pi}l_{k}e^{\frac{(x_{k}+y_{k})^{2}}{4l_{k}^{2} }}\left[\text{erf}\left(\frac{t}{l_{k}}+\frac{x_{k}+y_{k}}{2l_{k}}\right) \right]_{-\infty}^{+\infty}\] \[=\sqrt{\pi}l_{k}e^{\frac{(x_{k}+y_{k})^{2}}{4l_{k}^{2}}}.\] (83)Injecting (83) into (82), we have

\[(k_{S}*k_{S})(\bm{x}-\bm{y}) =e^{-\frac{1}{2}\left(\bm{x}\bm{M}^{-2}\bm{x}+\bm{y}\bm{M}^{-2}\bm{ y}\right)}\prod_{k=1}^{d}\sqrt{\pi}l_{k}e^{\frac{(x_{k}+y_{k})^{2}}{4l_{k}^{2}}}\] \[=\pi^{\frac{d}{2}}\det\left(\bm{M}\right)e^{\frac{1}{4}\left(\bm {x}+\bm{y}\right)M^{-2}\left(\bm{x}+\bm{y}\right)-\frac{1}{2}\left(\bm{x}\bm{ M}^{-2}\bm{x}+\bm{y}\bm{M}^{-2}\bm{y}\right)}\] (84) \[=\pi^{\frac{d}{2}}\det\left(\bm{M}\right)e^{-\frac{1}{4}\left(\bm {x}-\bm{y}\right)^{\top}M^{-2}\left(\bm{x}-\bm{y}\right)}\] (85)

where (84) holds because the determinant of a diagonal matrix is the product of its diagonal elements. 

As a safety check, observe that Lemma D.2 is a special case of Lemma E.1 where \(\bm{M}=l_{S}\bm{I}\), that is, when \(k_{S}\) is an isotropic SE kernel.

## Appendix F Relative Quantification of Relevancy

In this appendix, we discuss how (9) and its approximation (12) address the dependency on the covariance function hyperparameters introduced by (8). For the sake of this discussion, we take \(k_{S}\) and \(k_{T}\) as two Squared-Exponential (SE) covariance functions (see Table 1). A similar reasoning can be conducted with Matern covariance functions.

Let us start by rewriting the product of spatial and temporal convolutions \(C((\bm{x},t),(\bm{x}^{\prime},t^{\prime}))\) with the formulas provided in Tables 3 and 4 for the SE covariance functions. We get

\[C((\bm{x},t),(\bm{x}^{\prime},t^{\prime})) =\pi^{\frac{d}{2}}l_{S}^{d}e^{-\frac{||\bm{x}-\bm{x}^{\prime}||_{ 2}^{2}}{4l_{S}^{2}}}\frac{\sqrt{\pi}}{2}l_{T}e^{\frac{-(t-t^{\prime})^{2}}{2l_ {T}^{2}}}\left(1-\text{erf}\left(\frac{2t_{0}-t-t^{\prime}}{2l_{T}}\right)\right)\] \[=\frac{1}{2}\pi^{\frac{d+1}{2}}l_{S}^{d}l_{T}e^{-\frac{||\bm{x}- \bm{x}^{\prime}||_{2}^{2}}{4l_{S}^{2}}-\frac{-(t-t^{\prime})^{2}}{2l_{T}^{2}} }\left(1-\text{erf}\left(\frac{2t_{0}-t-t^{\prime}}{2l_{T}}\right)\right)\] \[=\frac{1}{2}\pi^{\frac{d+1}{2}}l_{S}^{d}l_{T}C^{*}((\bm{x},t),( \bm{x}^{\prime},t^{\prime})).\] (86)

The dependency on the covariance function hyperparameters \(\lambda,l_{S},l_{T}\) appears clearly in (86). Both \(l_{S}\) and \(l_{T}\) are used, not only to scale the spatial distance \(\|\bm{x}-\bm{x}^{\prime}\|_{2}\) and the temporal distance \(|t-t^{\prime}|\) in \(C^{*}\), but also as a scaling constant of the magnitude of the output of the product of convolutions itself. Because \(C((\bm{x},t),(\bm{x}^{\prime},t^{\prime}))\) is involved in every term of (10) and (11) in Theorem 4.1, \(\frac{1}{2}\pi^{\frac{d+1}{2}}l_{S}^{d}l_{T}\) can be factored out of (10) and (11). Overall, both equations have in common the factor \(\frac{1}{2}\pi^{\frac{d+1}{2}}\lambda^{2}l_{S}^{d}l_{T}\). Clearly, this shows how the covariance function hyperparameters \(\bm{\theta}=(\lambda,l_{S},l_{T})\) may control the magnitude of the Wasserstein distances.

To capture the intrinsic relevancy of an observation regardless of the hyperparameters values, one can compute (12), that is the ratio between (10) and (11). Doing so, the factors which are common to the two equations cancel out. Considering the application of Theorem 4.1 with \(k_{S}\) and \(k_{T}\) being SE covariance functions, the undesirable factor \(\frac{1}{2}\pi^{\frac{d+1}{2}}\lambda^{2}l_{S}^{d}l_{T}\) is removed. Clearly, (12) remains a function of \(l_{S}\) and \(l_{T}\), but the hyperparameters are only used to scale the spatial and temporal distances, that is to control correlation lengths. However, the undesirable scaling exposed in (86) no longer exists.

## Appendix G Removal Budget

In this appendix, we discuss why the removal budget of W-DBO (see Algorithm 1), denoted \(b_{t}\) at a given time \(t\), has the form

\[\begin{cases}b_{0}&=1,\\ b_{t+\Delta t}&=b_{t}(1+\alpha)^{\Delta t/l_{T}}\end{cases}\] (87)

with \(l_{T}\) the temporal lengthscale (see Assumption 3.2) and \(\alpha\) the hyperparameter of W-DBO. Crucially, \(l_{T}\) and \(t\) must be expressed in the same unit of time.

First, note that the expression of the budget is intuitive because (9) measures a ratio, expressed as a percentage. Therefore, the budget must accumulate in a multiplicative way, leading to the exponential form (87).

More interestingly, let us discuss the exponent \(\Delta t/l_{T}\). Arguably, an alternative, more intuitive form of the removal budget would be

\[\begin{cases}b_{0}&=1,\\ b_{t+\Delta t}&=b_{t}(1+\alpha)^{\Delta t}\end{cases}.\] (88)

Although easier to understand, the budget (88) presents a major problem since it depends on arbitrary choices made by the user. This is illustrated by Table 5, where the same synthetic function (Hartmann3d) is optimized under three different durations. When the duration varies, the removal budget (88), which depends on the number of elapsed seconds only, also varies. Conversely, the budget (87) remains the same. This is because the number of temporal lengthscales elapsed during the experiment remains constant, regardless of the experiment duration.

Using the removal budget (88) becomes really troublesome when it comes to making a recommendation for the hyperparameter \(\alpha\). If the analysis in Section 5.1 had used the budget (88), its recommendation \(\alpha^{*}\) would have been a function of the temporal lengthscale, and it would have been valid only for experiments with the same duration (e.g., ten minutes). Any other experiment duration would have required another sensitivity analysis.

Conversely, the recommendation made in Section 5.1, using the budget (87), is a single number that is valid regardless of experiment duration. This is a much more general insight.

## Appendix H Empirical Results

### Experimental Settings

In each experiment, the \(d\)-dimensional spatial domain is scaled in \(\mathcal{S}^{\prime}=[0,1]^{d}\) and the temporal domain (viewed as the \((d+1)\)th dimension) is normalized in \([0,1]\). Additionally, each optimization task lasts 600 seconds (10 minutes).

Unless stated otherwise, each DBO algorithm exploits a Matern-5/2 kernel as its spatial covariance function. GP-UCB, R-GP-UCB and ET-GP-UCB do not explicitly take into account temporal correlations, while TV-GP-UCB uses its own temporal covariance function. Eventually, ABO and W-DBO exploits a Matern-3/2 kernel as their temporal covariance function.

Each DBO algorithm begins its optimization task with 15 initial observations, uniformly sampled in \(\mathcal{S}^{\prime}\times\left[0,\frac{1}{40}\right]\). At each iteration (at time \(t\)), (i) the noise level as well as the kernel parameters are estimated, and (ii) the GP-UCB acquisition function is optimized to get the next query. The sum of the times taken to perform tasks (i) and (ii) is the _response time_ of the DBO algorithm, denoted by \(\Delta t\). Clearly, \(\Delta t\) is a function of the dataset size of the DBO algorithm. Consequently, it varies throughout the optimization, getting larger when the DBO algorithm adds a new observation to its dataset, and getting smaller when the DBO algorithm removes at least one point. Once (i) and (ii) are performed, the objective function is immediately sampled (except for ABO which can decide to sample \(f\) at a specific time in the future) and a Gaussian noise with variance equal to 5 % of the signal variance is added. Then, the next iteration begins at time \(t+\Delta t\) (except for ABO if it decides to sample \(f\) later).

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline Duration \(D\) & 1 Second & Lengthscale \(l_{T}\) & Lengthscale \(l_{T}\) & Budget (87) & Budget (88) \\ (seconds) & (axis unit) & (axis unit) & (seconds) & \((1+\alpha)^{D/l_{T}}\) & \((1+\alpha)^{D}\) \\ \hline
300 & \(1/300\) & \(3/5\) & 180 & \((1+\alpha)^{5/3}\) & \((1+\alpha)^{300}\) \\
600 & \(1/600\) & \(3/5\) & 480 & \((1+\alpha)^{5/3}\) & \((1+\alpha)^{600}\) \\
1800 & \(1/1800\) & \(3/5\) & 1080 & \((1+\alpha)^{5/3}\) & \((1+\alpha)^{1800}\) \\ \hline \hline \end{tabular}
\end{table}
Table 5: Comparison of removal budgets (87) and (88) when doing experiments of different durations on the Hartmann3d synthetic function. All experiments use the same time domain \([0,1]\).

For the sake of benchmarking fairness, all the solutions have been implemented using the same popular BO Python library, namely BOTorch [32] (MIT License). To comply with the technical choices (_i.e._, Python front-end, C++ back-end), the computationally-heavy part of W-DBO (_i.e._, the evaluation of the formulas in Section 4) have been implemented in C++ and bound to the Python code with PyBind11 [33] (BSD License). All experiments have been independently replicated 10 times on a laptop equipped with an Intel Core i9-9980HK @ 2.40 GHz with 8 cores (16 threads).

### Benchmarks and Figures

We provide here a detailed description of each implemented benchmark and the associated figures. There are two figures associated with each benchmark, showing their average regrets and the size of their datasets throughout the experiment.

In the following, the synthetic benchmarks will be described as functions of a point \(\bm{z}\) in the \(d+1\)-dimensional spatio-temporal domain \(\mathcal{S}\times\mathcal{T}\). More precisely, the point \(\bm{z}\) is explicitly given by \(\bm{z}=(x_{1},\cdots,x_{d},t)\). Also, we will write \(d^{\prime}=d+1\) for the sake of brevity.

Rastrigin.The Rastrigin function is \(d^{\prime}\)-dimensional, and has the form

\[f(\bm{z})=ad^{\prime}+\sum_{i=1}^{d^{\prime}}z_{i}^{2}-a\cos\left(2\pi z_{i} \right).\]

For the numerical evaluation, we set \(a=10\), \(d^{\prime}=5\) and we optimized the function on the domain \([-4,4]^{d^{\prime}}\). The results are provided in Figure 8.

Schwefel.The Schwefel function is \(d^{\prime}\)-dimensional, and has the form

\[f(\bm{z})=418.9829d^{\prime}-\sum_{i=1}^{d^{\prime}}z_{i}\sin\left(\sqrt{|z_{i }|}\right).\]

For the numerical evaluation, we set \(d^{\prime}=4\) and we optimized the function on the domain \([-500,500]^{d^{\prime}}\). The results are provided in Figure 9. This benchmark has also been used to replicate our results using the ARD covariance function studied in Appendix E. The results are provided in Figure 10.

Styblinski-Tang.The Syblinski-Tang function is \(d^{\prime}\)-dimensional, and has the form

\[f(\bm{z})=\frac{1}{2}\sum_{i=1}^{d^{\prime}}z_{i}^{4}-16z_{i}^{2}+5z_{i}.\]

Figure 8: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Rastrigin synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Rastrigin synthetic function.

For the numerical evaluation, we set \(d^{\prime}=4\) and we optimized the function on the domain \([-5,5]^{d^{\prime}}\). The results are provided in Figure 11.

Eggholder.The Eggholder function is \(2\)-dimensional, and has the form

\[f(\bm{z})=-(z_{2}+47)\sin\left(\sqrt{|z_{2}+\frac{z_{1}}{2}+47|}\right)-z_{1} \sin\left(\sqrt{|z_{1}-z_{2}-47|}\right).\]

For the numerical evaluation, we optimized the function on the domain \([-512,512]^{2}\). The results are provided in Figure 12.

Ackley.The Ackley function is \(d^{\prime}\)-dimensional, and has the form

\[f(\bm{z})=-a\exp\left(-b\sqrt{\frac{1}{d^{\prime}}\sum_{i=1}^{d^{\prime}}z_{i} ^{2}}\right)-\exp\left(\frac{1}{d^{\prime}}\sum_{i=1}^{d^{\prime}}\cos(cz_{i}) \right)+a+\exp(1).\]

For the numerical evaluation, we set \(a=20\), \(b=0.2\), \(c=2\pi\), \(d^{\prime}=4\) and we optimized the function on the domain \([-32,32]^{d^{\prime}}\). The results are provided in Figure 13. This benchmark has also been used to replicate our results using the ARD covariance function studied in Appendix E. The results are provided in Figure 14.

Figure 10: (Left) Average response time and average regrets of the DBO solutions using an ARD SE kernel during the optimization of the Schwefel synthetic function. (Right) Dataset sizes of the DBO solutions using an ARD SE kernel during the optimization of the Schwefel synthetic function.

Figure 9: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Schwefel synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Schwefel synthetic function.

Rosenbrock.The Rosenbrock function is \(d^{\prime}\)-dimensional, and has the form

\[f(\bm{z})=\sum_{i=1}^{d^{\prime}-1}100(z_{i+1}-z_{i}^{2})^{2}+(z_{i}-1)^{2}.\]

For the numerical evaluation, we set \(d^{\prime}=3\) and we optimized the function on the domain \([-1,1.5]^{d^{\prime}}\). The results are provided in Figure 15.

Shekel.The Shekel function is \(4\)-dimensional, and has the form

\[f(\bm{z})=-\sum_{i=1}^{m}\left(\sum_{j=1}^{4}(z_{j}-C_{ji})^{2}+\beta_{i} \right)^{-1}.\]

For the numerical evaluation, we set \(m=10\), \(\bm{\beta}=\frac{1}{10}\left(1,2,2,4,4,6,3,7,5,5\right)\),

\[\bm{C}=\begin{pmatrix}4&1&8&6&3&2&5&8&6&7\\ 4&1&8&6&7&9&3&1&2&3.6\\ 4&1&8&6&3&2&5&8&6&7\\ 4&1&8&6&7&9&3&1&2&3.6\end{pmatrix},\]

and we optimized the function on the domain \([0,10]^{4}\). The results are provided in Figure 16.

Figure 11: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Styblinski-Tang synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Styblinski-Tang synthetic function.

Figure 12: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Eggholder synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Eggholder synthetic function.

Hartmann-3.The Hartmann-3 function is \(3\)-dimensional, and has the form

\[f(\bm{z})=-\sum_{i=1}^{4}\alpha_{i}\exp\left(-\sum_{j=1}^{3}A_{ij}(z_{j}-P_{ij})^{ 2}\right).\]

For the numerical evaluation, we set \(\bm{\alpha}=(1.0,1.2,3.0,3.2)\),

\[\bm{A}=\begin{pmatrix}3&10&30\\ 0.1&10&35\\ 3&10&30\\ 0.1&10&35\end{pmatrix},\bm{P}=10^{-4}\begin{pmatrix}3689&1170&2673\\ 4699&4387&7470\\ 1091&8732&5547\\ 381&5743&8828\end{pmatrix},\]

and we optimized the function on the domain \([0,1]^{3}\). The results are provided in Figure 17.

Hartmann-6.The Hartmann-6 function is \(6\)-dimensional, and has the form

\[f(\bm{z})=-\sum_{i=1}^{4}\alpha_{i}\exp\left(-\sum_{j=1}^{6}A_{ij}(z_{j}-P_{ij })^{2}\right).\]

Figure 14: (Left) Average response time and average regrets of the DBO solutions using an ARD SE kernel during the optimization of the Ackley synthetic function. (Right) Dataset sizes of the DBO solutions using an ARD SE kernel during the optimization of the Ackley synthetic function.

Figure 13: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Ackley synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Ackley synthetic function.

[MISSING_PAGE_EMPTY:31]

For the numerical evaluation, we used the first day of data. The results are provided in Figure 20.

Wlan.This benchmark aims at maximizing the throughput of a Wireless Local Area Network (WLAN). 18 moving end-users are associated with one of 4 fixed nodes and continuously stream a large amount of data. As they move in space, they change the radio environment of the network, which should adapt accordingly to improve its performance. To do so, each node has a power level that can be tuned for the purpose of reaching the best trade-off between serving all its users and not causing interference for the neighboring nodes.

The performance of the network is computed as the sum of the Shannon capacities for each pair of node and associated end-users. The Shannon capacity [34] sets a theoretical upper bound on the throughput of a wireless communication. We denote it \(C(i,j)\), we express it in bits per second (bps). It depends on \(S_{ij}\) the Signal-to-Interference plus Noise Ratio (SINR) of the communication between node \(i\) and end-user \(j\), as well as on \(W\), the bandwidth of the radio channel (in Hz):

\[C_{ij}(\bm{x},t)=W\log_{2}(1+S_{ij}(\bm{x},t)).\]

Then, the objective function is

\[f(\bm{x},t)=\sum_{i=1}^{4}\sum_{j\in\mathcal{N}_{i}}C_{ij}(\bm{x},t),\]

with \(\mathcal{N}_{i}\) the end-users associated with node \(i\).

Figure 17: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Hartmann-3 synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Hartmann-3 synthetic function.

Figure 18: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Hartmann-6 synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Hartmann-6 synthetic function.

For the numerical evaluation, we optimized the power levels \(\bm{x}\) in the domain \([10^{0.1},10^{2.5}]^{4}\). For this experiment, the DBO solutions were evaluated with a Matern-5/2 for the spatial covariance function and a Matern-1/2 for the temporal covariance function. The results are provided in Figure 21.

### Discussion on Empirical Performance

In this section, we discuss the performance achieved by all the DBO solutions on the benchmarks introduced in the previous section.

Gp-Ucb.This baseline, which does not take into account temporal correlations, obtains surprisingly good performance in this experimental setting (continuous time, hyperparameters estimated on the fly). Its simple behavior (_i.e._, keep all observations in the dataset until the end of the experiment) hampers its response time, but this drawback is balanced by the fact that it has only three parameters to estimate with MLE (_i.e._, \(\lambda,l_{S},\sigma^{2}\)). Overall, it is dominated by R-GP-UCB, TV-GP-UCB and W-DBO, but behaves surprisingly well against ABO and ET-GP-UCB (see Figure 5).

Abo.ABO performs poorly in this experimental setting. We explain this poor performance by the fact that the hyperparameters (including the spatial and temporal lengthscales) have to be estimated on the fly. Since ABO can decide to postpone its next query to the near future (a fraction of the temporal lengthscale \(l_{T}\) away), overestimating \(l_{T}\) may cause ABO to wait for a long time before querying \(f\) again. This interpretation is supported by the fact that the functions ABO performs the poorest on are the ones with the largest temporal lengthscales \(l_{T}\), e.g., Rosenbrock (see Figure 15) and Powell (see Figure 19). Conversely, ABO obtains competitive performance on functions with

Figure 19: (Left) Average response time and average regrets of the DBO solutions during the optimization of the Powell synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Powell synthetic function.

Figure 20: (Left) Average response time and average regrets of the DBO solutions during the Temperature real-world experiment. (Right) Dataset sizes of the DBO solutions during the Temperature real-world experiment.

[MISSING_PAGE_FAIL:34]

variations are more pronounced, the dataset size of W-DBO experiences sudden drops, as can be seen with Ackley (see Figure 13), Shekel (see Figure 16) or Temperature (see Figure 20). This suggests that W-DBO is also able to "reset" its dataset, although in a more refined way as it is able to keep the few observations still relevant for future predictions. Thanks to its ability to adapt in very different contexts, W-DBO outperforms state-of-the-art DBO solutions by a comfortable margin. This performance gap can be seen in its average performance across all benchmarks (see Figure 5), but also on most of the benchmarks themselves, e.g., Schwefel (see Figure 9), Ackley (see Figure 13), Shekel (see Figure 16), Hartmann-6 (see Figure 18) or Powell (see Figure 19).

### Animated Visualizations

In this section, we describe and discuss the two animated visualizations provided as supplementary material for the paper. These videos show W-DBO optimizing two 2-dimensional synthetic functions. They depict W-DBO's predictions, collected observations and deleted observations into the spatio-temporal domains of the functions.

One of the videos depict the optimization of the Six-Hump Camel function4 on the domain \([-2,2]^{2}\). The SHC function is

Footnote 4: The video is accessible at https://abardou.github.io/assets/vid/PermSix-Hump_Camel_25.0_240.mp4

\[\text{SHC}(x,t)=\left(4-2.1x^{2}+\frac{x^{4}}{3}\right)x^{2}+xt+\left(-4+4t^{ 2}\right)t^{2}.\]

To study how W-DBO reacts to sudden changes in the objective function, the other video depict the optimization of the piecewise function

\[f(x,t)=\begin{cases}\text{SHC}(x,t)&\text{if }t<-\frac{1}{2},\\ \text{SHC}(t,x)&\text{otherwise.}\end{cases}\]

A snapshot from the latter can be found in Figure 22. It illustrates that the benefits brought by W-DBO are substantial, since the algorithm is able to track \(\max_{x\in\mathcal{S}}f(x,t)\) over the time \(t\) while

Figure 22: Snapshot from one of the videos showing the optimization conducted by W-DBO. The normalized temporal dimension is shown on the x-axis and the normalized spatial dimension is shown on the y-axis. The observations that are in the dataset are depicted as red dots, while the deleted observations are depicted as black crosses. The maximal arguments \(\{\arg\max_{x\in\mathcal{S}}f(x,t),t\in\mathcal{T}\}\) are depicted with a cyan curve. The predictions of W-DBO are shown with a contour plot. Finally, the present time is depicted as a black vertical line labelled \(t_{0}\).

simultaneously deleting a significant portion of collected observations. Indeed, many observations are deemed irrelevant, either because (i) they have become stale (there are only a few observations collected at the start of the experiment that have been kept in the dataset) or because (ii) they are redundant with observations that are already in the dataset (many observations are located near the maximal argument, and many of them are deleted soon after being collected).

## Appendix I Limitations

For the sake of completeness, we explicitly discuss the limitations of W-DBO in this appendix. Four limitations were identified:

* As for any BO algorithm, W-DBO exploits a GP as a surrogate model (see Assumption 3.1). If the objective function \(f\) cannot be properly approximated by a GP, we expect the performance of W-DBO to decline.
* As for any BO algorithm, W-DBO conducts GP inference, which causes it to manipulate inverses of Gram matrices that scale with the dataset size. Although the main motivation of introducing W-DBO is to reduce the dataset size, the cubic complexity of matrix inversion algorithms can still constitute a limitation if too many observations are kept in the dataset.
* We also introduce a structure for spatio-temporal correlations with Assumption 3.2. Although less restrictive than the one enforced by [21, 22], equivalent to the one in [20] and partially relaxed in Appendix E, this is still a limitation since we expect the performance of W-DBO to worsen if the objective function does not meet this assumption.
* Finally, W-DBO is not exempt from the effects of the sampling frequency. In fact, as for any DBO algorithm, the performance of W-DBO will drop if the function varies too much between observations. As an example, if \(f\) evolves so rapidly that two successive observations become basically independent, W-DBO will not be able to infer anything meaningful about the objective function.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The abstract states that the paper introduces a criterion that measures the relevancy of the observations and a DBO algorithm that exploits the criterion to improve upon state-of-the-art. These contributions can be found in Sections 3, 4 and 5. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The limitations are explicitly discussed in Appendix I and the approximation error of our proposed upper bounds is discussed at length in Appendix C. Guidelines:* The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.
* The authors are encouraged to create a separate "Limitations" section in their paper.
* The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.
* The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.
* The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.
* The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.
* If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.
* While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: The assumptions are explicitly given in the main text (see Section 3), and the proofs for each result are provided in Appendices A, B and D. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The experimental details are discussed briefly in the main paper (see Section 5) and discussed at length in Appendix H.1. Furthermore, the benchmarks are detailed in Appendix H.2. Guidelines: * The answer NA means that the paper does not include experiments.

* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: A GitHub repository with a minimal working example and a detailed documentation is provided along with the camera-ready version.f Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). ** Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: As previously mentioned, all experimental details are discussed in Appendix H. A sensitivity study and a discussion about the hyperparameter of W-DBO are also provided in Section 5.1 and Appendix G, respectively. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Standard errors are depicted graphically in Section 5 and Appendix H.2. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The computing resources are described in Appendix H.1. Guidelines: * The answer NA means that the paper does not include experiments.

* The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.
* The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.
* The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research conducted in this paper does not violate the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: This paper proposes a DBO algorithm that can be applied to many different applied research areas (e.g., robotics, computer networks, biology). These impacts are briefly mentioned in Section 6. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?Answer: [NA] Justification: In our opinion, the paper poses no such risks. Guidelines:

* The answer NA means that the paper poses no such risks.
* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: The paper uses BOTorch and PyBind11, which are explicitly mentioned in Appendix H.1 and whose licenses allow free exploitation for scientific research purposes. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not introduce new assets yet. Upon acceptance, a GitHub repository with a detailed documentation will be provided. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.

14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The research does not involve crowdsourcing nor human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The research does not involve crowdsourcing nor human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. * We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. * For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.