# Almost Minimax Optimal Best Arm Identification in Piecewise Stationary Linear Bandits

 Yunlong Hou

Department of Mathematics

National University of Singapore

yhou@u.nus.edu

&Vincent Y. F. Tan

Department of Mathematics

Department of Electrical and Computer Engineering

National University of Singapore

vtan@nus.edu.sg

&Zixin Zhong

Data Science and Analytics Thrust

Hong Kong University of Science and Technology (Guangzhou)

zixinzhong@hkust-gz.edu.cn

###### Abstract

We propose a _novel_ piecewise stationary linear bandit (PSLB) model, where the environment randomly samples a context from an unknown probability distribution at each changepoint, and the quality of an arm is measured by its return averaged over all contexts. The contexts and their distribution, as well as the changepoints are unknown to the agent. We design _Piecewise-Stationary \(\varepsilon\)-Best Arm Identification\({}^{+}\)_ (PS\(\varepsilon\)BAI\({}^{+}\)), an algorithm that is guaranteed to identify an \(\varepsilon\)-optimal arm with probability \(\geq 1-\delta\) and with a minimal number of samples. PS\(\varepsilon\)BAI\({}^{+}\) consists of two subroutines, PS\(\varepsilon\)BAI and Naive\(\varepsilon\)-BAI (N\(\varepsilon\)BAI), which are executed in parallel. PS\(\varepsilon\)BAI actively detects changepoints and aligns contexts to facilitate the arm identification process. When PS\(\varepsilon\)BAI and N\(\varepsilon\)BAI are utilized judiciously in parallel, PS\(\varepsilon\)BAI\({}^{+}\) is shown to have a finite expected sample complexity. By proving a lower bound, we show the expected sample complexity of PS\(\varepsilon\)BAI\({}^{+}\) is optimal up to a logarithmic factor. We compare PS\(\varepsilon\)BAI\({}^{+}\) to baseline algorithms using numerical experiments which demonstrate its efficiency. Both our analytical and numerical results corroborate that the efficacy of PS\(\varepsilon\)BAI\({}^{+}\) is due to the delicate change detection and context alignment procedures embedded in PS\(\varepsilon\)BAI.

## 1 Introduction

In stochastic _multi-armed bandits_ (MABs), an agent interacts with the environment at each time step. The agent pulls an arm and observes the corresponding return provided by the environment. The classical MAB framework assumes a _stationary_ environment where the expected return of each arm remains unchanged over time. However, we usually face ever-changing environments in real life. For instance, in investment option selection and portfolio management, fund managers want to select a subset of good candidate portfolios. However, the market may be bullish, bearish, or in some other state. The transition between these states can be well-modelled as being stochastic. We wish to select portfolios that yield the best long-term option under such a piecewise stationary environment. Further examples such as one based on agriculture in the face of stochastically changing weather patterns are discussed in detail in Appendix A. These motivate us to formulate and investigate a _piecewise stationary linear bandit_ (PSLB) model.

Our PSLB model is equipped with an _arm set_\(\mathcal{X}\), a _context set_\(\Theta\) and a deterministic but unknown sequence of _changepoints_\(\mathcal{C}\). At each changepoint, the environment samples a context \(\theta\in\Theta\) from anunknown probability distribution \(P_{\theta}\), and the returns of arms may change when the context changes. The return of each arm under each context is determined by its feature \(x\in\mathcal{X}\) and the context \(\theta\). In particular, the expected return of an arm is the weighted sum \(\mu_{x}=\mathbb{E}_{P_{\theta}}[x^{\top}\theta]\). While the sequence of changepoints, as well as the distribution and latent vectors of contexts are not known, the agent samples an arm and observes the corresponding return at each time step so that it can identify the best arm \(\operatorname*{arg\,max}_{x}\mu_{x}\) up to some tolerance \(\varepsilon\) with probability \(\geq 1-\delta\) and with as few samples as possible. The agent's behavior does not affect the sequence of contexts that is drawn from \(P_{\theta}\).

**Main Contributions.** We are the _first_ to study the fixed-confidence _best arm identification_ (BAI) problem in _piecewise stationary bandits_ (PSB). Given \(\delta>0\), we say the arm with the highest expected return \(\mu^{*}\) is the _best_, and an arm is \(\varepsilon\)-optimal if its expected return is at least \(\mu^{*}-\varepsilon\). We seek to design an \((\varepsilon,\delta)\)-PAC algorithm which can identify an \(\varepsilon\)-optimal arm with probability \(\geq 1-\delta\) in as few time steps as possible, i.e., with minimal sample complexity.

Our **first** contribution concerns the formulation of a _novel_ PSLB model, where we measure the quality of an arm \(x\) according to its _expected return_\(\mu_{x}=\mathbb{E}_{\theta\sim P_{\theta}}[x^{\top}\theta]\) for the following reasons. Consider that an arm is measured by its average return across time, which is a generalization of the definition in _stationary bandits_ (SB). A notable feature of PSB models is that the context changes as time evolves, and hence the arm's average return across time also changes, in general. Hence, we aim to identify an arm whose _average return across contexts_ is high, and benefits the agent for interacting with the environment _in the long run_ after the arm identification task. We are thus inspired to introduce the distribution of contexts under the PSLB model, define the expected return \(\mu_{x}\) for each arm, and use this ensemble (non-time varying) statistic as the benchmark for what we seek to learn. The BAI task using this statistic is meaningful but challenging, as the agent needs to reliably estimate the context vectors, changepoints, and context distribution.

**Secondly,** we propose Piecewise-Stationary \(\varepsilon\)-BAI\({}^{+}\) (PS\(\varepsilon\)BAI\({}^{+}\)), an algorithm designed to tackle the BAI problem in our PSLB model. We prove that it is \((\varepsilon,\delta)\)-PAC and bound its sample complexity. PS\(\varepsilon\)BAI\({}^{+}\) samples arms according to a suitably defined G-optimal allocation, and runs two algorithms: Naive\(\varepsilon\)-BAI (N\(\varepsilon\)BAI) and PS\(\varepsilon\)BAI as subroutines in parallel to achieve efficiency and attain a bound on the sample complexity in expectation.

\(\bullet\) Being a baseline but naive algorithm, the complexity of N\(\varepsilon\)BAI grows linearly with the maximum length between two changepoints \(L_{\max}\), motivating us to design a more efficient algorithm, PS\(\varepsilon\)BAI, to reduce the impact of \(L_{\max}\).

\(\bullet\) PS\(\varepsilon\)BAI is equipped with two delicately designed subroutines Linear-Change Detection (LCD) and Linear-Context Alignment (LCA) to actively detect changepoints and align contexts with those observed in the previous time steps respectively. Concretely, **in terms of the design**, PS\(\varepsilon\)BAI determines whether samples from two intervals are under the identical context via a sliding window mechanism, and detects changepoints and aligns contexts accordingly; this facilitates the estimation of context vectors and their distribution. Combining these elements into the design of PS\(\varepsilon\)BAI and analyzing them requires some care. **On the theoretical side**, we prove PS\(\varepsilon\)BAI identifies an \(\varepsilon\)-optimal arm faster than N\(\varepsilon\)BAI with high probability. The success of PS\(\varepsilon\)BAI relies on the LCD and LCA subroutines, while a minor drawback is that they require a non-vanishing failure probability budget which does not allow us to bound the sample complexity of PS\(\varepsilon\)BAI in expectation. To achieve a complete theoretical understanding, we delicately design the PS\(\varepsilon\)BAI\({}^{+}\) algorithm whose efficiency is inherited via the LCD and LCA procedures in PS\(\varepsilon\)BAI as well as the effective utilization of running PS\(\varepsilon\)BAI and N\(\varepsilon\)BAI in parallel.

**Thirdly,** we derive a lower bound on the complexity of any \((\varepsilon,\delta)\)-PAC algorithm in PSLB models. To derive this bound, we first lower bound the complexity of an algorithm when the contextual information (and changepoints) are available, and then quantify the number of arm samples (and realized contexts) required to reliably infer an \(\varepsilon\)-best arm.We compare the upper bound of PS\(\varepsilon\)BAI\({}^{+}\) and this generic lower bound in several instances. The matching (up to logarithmic terms) of bounds illustrate that our PS\(\varepsilon\)BAI\({}^{+}\) algorithm is almost asymptotically optimal.

**Lastly,** we demonstrate the efficiency of PS\(\varepsilon\)BAI\({}^{+}\) with numerical experiments. The first half of our experiment shows that PS\(\varepsilon\)BAI\({}^{+}\) is \((\varepsilon,\delta)\)-PAC and with significantly lower sample complexity compared to N\(\varepsilon\)BAI, corroborating our theoretical findings. In the second half, we compare PS\(\varepsilon\)BAI\({}^{+}\) to N\(\varepsilon\)BAI, and two other benchmarks Distribution \(\varepsilon\)-BAI (D\(\varepsilon\)BAI) and D\(\varepsilon\)BAI\({}_{\beta}\).While contexts and changepoints are not available to PS\(\varepsilon\)BAI\({}^{+}\) and N\(\varepsilon\)BAI, they are observed by D\(\varepsilon\)BAI and D\(\varepsilon\)BAI\({}_{\beta}\). Nevertheless, PS\(\varepsilon\)BAI\({}^{+}\) is still competitive compared to D\(\varepsilon\)BAI and D\(\varepsilon\)BAI\({}_{\beta}\) in our empirical experiments. Hence, both experiments justify the necessity of the change detection and context alignment procedures for boosting the learning of contexts and their distributions, as well as the identification of the best arm. We also show empirically that misspecifications to the knowledge of \(L_{\min}\) and \(L_{\max}\) do not affect the performance of our algorithm significantly.

**Related work.**_Best arm identification_ (BAI) and _regret minimization_ (RM) are two fundamental problems in multi-armed bandits. In stationary linear bandits, [1; 2] focus on BAI and [3; 4] aim to solve the RM problem. An efficient algorithm can choose the G-optimal allocation or \(\mathcal{X}\mathcal{Y}\)-allocation rule to quickly identify a good arm [1; 5]. Besides, [6; 7] focus on \(\varepsilon\)-optimal arm identification, which is a generalization of the standard BAI problem.

The BAI and RM problems are also studied in thr _non-stationary bandits_ (NSB), where in contrast to the SB model, the context varies with time [8; 9; 10]. NSB can be largely divided into two classes: the drifting bandit (DB) model, where the context changes at each step [8], and PSB, where the context changes less frequently [10]. [11] provides an extensive discussion on the definition of NSB models.

On one hand, the RM problem have been investigated extensively in DB models [12; 13]. On the other hand, concerning the BAI task in DB models, [14] investigated BAI with a _fixed-horizon_, where the best arm has the highest average return over this horizon; [15] assumes the best arm remains unchanged after certain time step and explores the _fixed-confidence_ setting. Besides, when the contextual information in NSB models is available, NSB models are known as _contextual bandit_ (CB) models [16; 17; 18]. [16] showed that the contextual information accelerates the best arm identification process. More discussions on DB and CB models are presented in Appendix C.

Moreover, the context can drift dramatically in a DB model while it remains unvarying in a SB model. Straddling between the DB and SB models, PSB models assume there is an interim stationary interval between each two consecutive changepoints, where the context remains unchanged. The context changes can be characterized in different ways and affect the performance of proposed algorithms in PSB models. For instance, a changepoint signals the return of at least one arm shift as in [10], and indicates the best arm changes as in [19].

In PSB models, a large body of works focus on RM. While [10; 20; 21; 22] equip their algorithms with changepoint detection techniques to handle the context changes, [23] actively checks the quality of each arm. However, there is no existing work on the fixed-confidence BAI problem in a PSB model. To fill this gap in the literature, we design PS\(\varepsilon\)BAI\({}^{+}\) for \(\varepsilon\)-optimal arm identification in our proposed PSLB model. We show PS\(\varepsilon\)BAI\({}^{+}\) is almost asymptotically optimal by comparing its complexity to a generic lower bound of all algorithms, and validate its efficiency through numerical experiments.

## 2 Problem Setup

For \(m\in\mathbb{N}\), let \([m]:=\{1,2,\ldots,m\}\). For a finite set \(S\), let \(\mathbf{\Delta}_{S}\) denote the \(|S|\)-dim probability simplex on \(S\). Let \(A(\mathbf{q}):=\sum_{x\in\mathcal{X}}q_{x}xx^{\top}\) be the matrix induced by \(\mathbf{q}\in\mathbf{\Delta}_{\mathcal{X}}\) with \(\mathcal{X}\subset\mathbb{R}^{d}\). An instance of _piecewise stationary linear bandit_ is a tuple \(\Lambda=(\mathcal{X},\Theta,P_{\theta},\mathcal{C})\). Specifically, \(x\in\mathbb{R}^{d}\) is an arm (vector) and the arm set \(\mathcal{X}\subset\mathbb{R}^{d}\) is composed of \(|\mathcal{X}|=K\) arms that spans \(\mathbb{R}^{d}\). The latent vector matrix \(\Theta=(\theta_{1}^{*},\ldots,\theta_{N}^{*})\in\mathbb{R}^{d\times N}\) contains \(N\) latent column vectors where the \(j^{\mathrm{th}}\) column \(\theta_{j}^{*}\) is associated with context \(j\in[N]\). For the sake of normalization, we assume \(|x^{\top}\theta_{j}^{*}|\leq 1\) for all \(x\in\mathcal{X},j\in[N]\). Let \(P_{\theta}\) denote the distribution (probability mass function) of the latent vectors and \(p_{j}=P_{\theta}[\theta_{j}^{*}]\). We represent the probabilities of latent vectors as \(\mathbf{p}=(p_{1},\ldots,p_{N})\in\Delta_{N}\). The fixed but unknown sequence of changepoints \(\mathcal{C}:=(c_{1},c_{2},\ldots)\) is an sequence of increasing positive integers \(1=c_{1}<c_{2}<\ldots\), characterizing all the changepoints (time steps).

The _return_ of arm \(x\) under latent context \(j\) is a random variable \(Y=x^{\top}\theta_{j}^{*}+\eta\), where \(\eta\) is a zero-mean random variable (noise) supported on \([-1,1]\), and the _expected return_ of arm \(x\) is \(\mu_{x}:=\mathbb{E}_{\theta\sim P_{\theta}}[x^{\top}\theta]=\sum_{j=1}^{N}P_{ \theta}[\theta_{j}^{*}]x^{\top}\theta_{j}^{*}\). The _best arm_, which we assume is unique, is denoted as \(x^{*}:=\arg\max_{x\in\mathcal{X}}\mu_{x}\) with mean \(\mu^{*}:=\mu_{x^{*}}\). Given a slackness parameter \(\varepsilon>0\), we define the set of \(\varepsilon\)_-best arms_\(\mathcal{X}_{\varepsilon}:=\{x\in\mathcal{X}:\mu_{x}\geq\mu^{*}-\varepsilon\}\). For each pair of arms \((x,\tilde{x})\in\mathcal{X}^{2}\), define the _contextual mean gap_ between \(x\) and \(\tilde{x}\) under latent context \(j\) as \(\Delta_{j}(x,\tilde{x}):=(x-\tilde{x})^{\top}\theta_{j}^{*}\) and the _mean gap_ between \(x\) and \(\tilde{x}\) as \(\Delta(x,\tilde{x}):=\mu_{x}-\mu_{\tilde{x}}\).

Given \(l\in\mathbb{N}\), the interval \((c_{l},\ldots,c_{l+1}-1)\) is known as the \(l^{\mathrm{th}}\)_stationary segment_ and its length is \(L_{l}:=c_{l+1}-c_{l}\). We assume \(L_{\min}\leq L_{l}\leq L_{\max}\). Let \(l_{t}:=\max\{l:c_{l}\leq t\}\) denote the number of stationary segments up to time step \(t\). At time step \(t\in[T]\) (see Dynamics 1),

**(i)** If \(t\in\mathcal{C}\), the environment samples a latent vector \(\theta^{*}_{t_{i}}\) according to \(P_{\theta}\), that is, it generates a (latent) _context sample_ with \(P_{\theta}\); otherwise the latent vector remains unchanged, i.e., \(\theta^{*}_{j_{t}}=\theta^{*}_{j_{t-1}}\). The contexts \(\{\theta^{*}_{j_{cl}}\}_{l\in\mathbb{N}}\) are sampled i.i.d. from \(P_{\theta}\) at each changepoint \(\{c_{t}\}_{l\in\mathbb{N}}\).

**(ii)** The agent pulls an arm \(x_{t}\) and observes the stochastic return \(Y_{t,x_{t}}=x_{t}^{\top}\theta^{*}_{j_{t}}+\eta_{t}\), where \(\eta_{t}\) is drawn independently from a distribution supported on \([-1,1]\).

The agent uses an _online_ algorithm \(\pi:=\{(\pi_{t},\tau_{t},r_{t})\}_{t\in\mathbb{N}}\) to actively interact with the instance \(\Lambda\) and only has access to the arm set \(\mathcal{X}\), number of latent vectors \(N\), the bounds on the length of each segment \(L_{\min}\) and \(L_{\max}\), the slackness parameter \(\varepsilon\), and the confidence parameter \(\delta\).

\(\bullet\) sampling rule \(\pi_{t}:\mathcal{H}^{\pi}_{t}:=\left((x_{s}^{\pi},Y_{s,x_{s}^{\pi}})\right)_{ \delta\in[t-1]}\to\mathcal{X}\) samples an arm \(x_{t}^{\pi}\) based on the observation history \(\mathcal{H}^{\pi}_{t}\) and observe the corresponding random return \(Y_{t,x_{t}^{\pi}}\);

\(\bullet\) stopping rule \(\tau_{t}:\mathcal{H}^{\pi}_{t+1}\to\{\text{STOP},\text{CONTINUE}\}\) decides whether to stop or continue to execute given the observation history \(\mathcal{H}^{\pi}_{t+1}\). The stopping time under algorithm \(\pi\) is denoted as \(\tau^{\pi}\);

\(\bullet\) recommendation rule \(r_{t}:\mathcal{H}^{\pi}_{\tau+1}\to\mathcal{X}\) recommends an arm \(\hat{x}^{\pi}\) based on \(\mathcal{H}^{\pi}_{\tau+1}\) upon termination.

The stopping time \(\tau^{\pi}\) is the _sample complexity_ of the algorithm \(\pi\) under instance \(\Lambda\). The _expected sample complexity_ is \(\mathbb{E}[\tau^{\pi}]\), where the expectation is taken w.r.t. the random returns, the realization of the contexts governed by the latent vector distribution \(P_{\theta}\), and the randomness of the algorithm \(\pi\).

An algorithm \(\pi\) is \((\varepsilon,\delta)\)_-PAC_ (Probably Approximately-Correct) if

\[\mathbb{P}[\hat{x}^{\pi}\in\mathcal{X}_{\varepsilon}]\geq 1-\delta.\]

Our overarching goal in this paper is to devise an \((\varepsilon,\delta)\)-PAC algorithm that minimizes \(\tau^{\pi}\) with high probability (w.h.p.) and in expectation.

## 3 Algorithms

### A Naive Baseline: N\(\varepsilon\)BAI

We first devise the Naive \(\varepsilon\)-Best Arm Identification (or N\(\varepsilon\)BAI) algorithm (presented in Algorithm 2). In the design of N\(\varepsilon\)BAI, only the choice of confidence radius \(\tilde{\rho}_{t}\) takes the potential context changes into consideration. Even though N\(\varepsilon\)BAI does not attempt to detect potential changes in the context, it can identify an \(\varepsilon\)-optimal arm w.h.p. and is with a finite expected sample complexity.

**Proposition 3.1**.: _Let \(\Delta_{\min}=\min_{x\neq x^{*}}\Delta(x^{*},x)\),_

\[T_{\mathrm{V}}^{\mathrm{N}}=\frac{d}{\left(\varepsilon+\Delta_{\min}\right)^{ 2}}\ln\frac{1}{\delta}\qquad\text{and}\qquad T_{\mathrm{D}}^{\mathrm{N}}= \frac{L_{\max}}{\left(\varepsilon+\Delta_{\min}\right)^{2}}\ln\frac{1}{\delta}.\]

_The N\(\varepsilon\)BAI algorithm is \((\varepsilon,\delta)\)-PAC and its expected sample complexity is \(\tilde{O}(T_{\mathrm{V}}^{\mathrm{N}}+T_{\mathrm{D}}^{\mathrm{N}})\)._

The upper bound in Proposition 3.1 (also see Appendix F) consists of two main terms. (i) As N\(\varepsilon\)BAI samples arms according to the G-optimal allocation (see Appendix D), the amount of samples needed to estimate the average of latent vectors \(\sum_{s=1}^{t}\theta^{*}_{j_{s}}/t\) contributes to \(T_{\mathrm{V}}^{\mathrm{N}}\). (ii) \(T_{\mathrm{D}}^{\mathrm{N}}\) quantifies how fast \(\sum_{s=1}^{t}\theta^{*}_{j_{s}}/t\) converges to the expectation of context vectors \(\sum_{j=1}^{t}p_{j}\theta^{*}_{j}\).

The sample complexity of N\(\varepsilon\)BAI grows linearly with \(L_{\max}\), but we surmise that the sample complexity of a close-to-optimal algorithm should have a _reduced dependence on_\(L_{\max}\).

### Piecewise-Stationary \(\varepsilon\)-Best Arm Identification

The algorithm Piecewise-Stationary \(\varepsilon\)-Best Arm Identification (or PS\(\varepsilon\)BAI) is presented in Algorithm 1. By using a sliding window mechanism, PS\(\varepsilon\)BAI actively detects the changepoints and aligns the current latent context with contexts observed in the previous time steps via Linear-Change Detection (or LCD) and Linear-Context Alignment (or LCA), which are presented in Algorithms 3 and 4 (see App. D.2.2), respectively. PS\(\varepsilon\)BAI consists of three phases:

(i) _Exploration phase_ (Exp): Estimate latent vectors and their distribution \(P_{\theta}\) (Lines 8 to 11 and 25);

(ii) _Change Detection phase_ (CD): Detect changepoints (Lines 12 to 16);

(iii) _Context Alignment phase_ (CA): Evaluate the current context and align it with the contexts observed in previous time steps (Lines 17 to 21).

At time \(t\), we estimate \(\Theta\) and \(\mathbf{p}\) with \(\hat{\Theta}_{t}=(\hat{\theta}_{t,1},\dots,\hat{\theta}_{t,N})\) and \(\hat{\mathbf{p}}_{t}=(\hat{p}_{t,1},\dots,\hat{p}_{t,N})^{\top}\), respectively.1 We denote the empirical mean gap between \(x\) and \(\tilde{x}\) under context \(j\) as \(\hat{\Delta}_{t,j}(x,\tilde{x}):=(x-\tilde{x})^{\top}\hat{\theta}_{t,j}\).

Footnote 1: The empirical latent vector-probability pairs \([(\hat{\theta}_{t,j},\hat{p}_{t,j})]_{j=1}^{N}\) can only approximate the unknown pairs \([(\theta^{*}_{\sigma(j)},p_{\sigma(j)})]_{j=1}^{N}\) up to a permutation \(\sigma:[N]\rightarrow[N]\), which is determined by the occurrence order of latent vectors. Thus we assume the latent vectors appear in order of increasing indices.

PS\(\varepsilon\)BAI first computes the G-optimal allocation [1]\(\lambda^{*}\) on the arm set \(\mathcal{X}\) and its maximum possible stopping time \(\tau^{*}\) (Line 2). It initializes \(\mathrm{CD}_{\mathrm{sample}}\) and \(\mathrm{CA}_{\mathrm{id}}\). \(\mathrm{CD}_{\mathrm{sample}}\) collects samples to detect changepoints and \(\mathrm{CA}_{\mathrm{id}}\) maintains a dictionary of \([\text{latent context index : identification samples}]\) pairs (Line 3);2\(\mathrm{CA}_{\mathrm{id}}[j]\) is the sequence of CD samples used to _identify_ latent context \(j\). It also initializes \(\mathcal{T}_{t,j}\), the collection of time indices in \([t]\) in the Exp phases under estimated context \(j\). Define

Footnote 2: A sample in \(\mathrm{CD}_{\mathrm{sample}}\) is a CD sample; A dictionary has a pairing structure {key:value} and dictionary[key] = value. \([a_{i}]_{i=1}^{n}\) denotes a sequence of elements \(a_{1},\dots,a_{n}\).

\[\mathcal{T}_{t}=\bigcup_{j\in[N]}\mathcal{T}_{t,j},\qquad T_{t}=|\mathcal{T}_ {t}|,\qquad T_{t,j}=|\mathcal{T}_{t,j}|,\qquad\forall j\in[N].\] (3.1)

```
1:Input: arm set \(\mathcal{X}\), size of the set of latent vectors \(N\), bounds on the segment lengths \(L_{\min}\) and \(L_{\max}\), slackness parameter \(\varepsilon\), confidence parameter \(\delta\), sampling parameter \(\gamma\) and window size \(w\), threshold \(b\).
2:Initialize: Compute the G-optimal allocation \(\lambda^{*}\) and \(\tau^{*}=\frac{38400\ln(80)NL_{\max}}{\varepsilon^{2}}\ln\frac{N^{2}KL_{\max} }{\delta\varepsilon^{2}}\).
3: Set \(\mathrm{CD}_{\mathrm{sample}}=[\;]\), \(\mathrm{CA}_{\mathrm{id}}=\{\;\}\). Set \(t_{\mathrm{CD}}=+\infty\).
4: Set \(\mathcal{T}_{t,j}=\emptyset\) and initialize \(\mathcal{T}_{t}\), \(T_{t,j}\), \(T_{t}\) with (3.1) for all \(t\leq\tau^{*}\), \(j\in[N]\).
5: Sample \(\frac{w}{2}\) arms \(\{x_{s}\}_{s=1}^{\frac{w}{2}}\sim\lambda^{*}\) and observe the associated returns \(\{Y_{s,x_{s}}\}_{s=1}^{\frac{w}{2}},t=\frac{w}{2},t_{\mathrm{CA}}=\frac{w}{2}\).
6:\(\mathrm{CA}_{\mathrm{id}}=\{1:[(x_{s},Y_{s,x_{s}})]_{s=1}^{\frac{w}{2}}\}\), \(\hat{j}_{t}=1\).
7:while\(t\leq\tau^{*}\)do
8:\(t=t+1\)
9: Sample an arm \(x_{t}\sim\lambda^{*}\) and observe return \(Y_{t,x_{t}}\).
10:if\(\mod(t-t_{\mathrm{CA}},\gamma)\neq 0\)then
11: Update \(\hat{j}_{t}=\hat{j}_{t-1}\), \(\mathcal{T}_{t,\hat{j}_{t}}=\mathcal{T}_{t-1,\hat{j}_{t}}\cup\{t\},\mathcal{T} _{t,j}=\mathcal{T}_{t-1,j}\) for \(j\neq\hat{j}_{t}\).
12:else
13:\(\mathrm{CD}_{\mathrm{sample}}=\mathrm{CD}_{\mathrm{sample}}+[(x_{t},Y_{t,x_{t}} )]\). ```

**Algorithm 1** Piecewise-Stationary \(\varepsilon\)-Best \(\mathtt{Arm}\) Identification (PS\(\varepsilon\)BAI)

It then collects \(\frac{w}{2}\) samples and stores them in \(\mathrm{CA}_{\mathrm{id}}\), which is then used to identify the first latent context (Lines 5 to 6).

In the Exp phase, PS\(\varepsilon\)BAI **firstly** samples an arm \(x_{t}\) with \(\lambda^{*}\) and observes the return \(Y_{t,x_{t}}=x_{t}^{\top}\theta^{*}_{\hat{j}_{t}}+\eta_{t}\) (Line 9). It **then** updates the estimated context index and time collectors (Line 11). It also updates the estimates of value and probability of each context \(j\) (Line 25) with

\[\hat{\theta}_{t,j}=\frac{1}{T_{t,j}}\sum_{s\in\mathcal{T}_{t,j}}A(\lambda^{*} )^{-1}x_{s}Y_{s,x_{s}}\qquad\text{and}\qquad\hat{p}_{t,j}=\frac{T_{t,j}}{T_{t}},\] (3.2)where \(\hat{\theta}_{t,j}=\mathbf{0}\) if \(T_{t,j}=0\). We define \(\alpha_{t}\), \(\xi_{t}\), \(\beta_{t,j}\), and \(\ \hat{\Delta}_{t,j}^{\mathrm{clip}_{2}}(x,\tilde{x})\) in Appendix D.2.1. For each pairs of arms \((x,\tilde{x})\), the confidence radius of \(\Delta(x,\tilde{x})\) at time step \(t\) is

\[\rho_{t}(x,\tilde{x}):=2(\alpha_{t}+\xi_{t})+\sum_{j=1}^{N}\beta_{t,j}|\hat{ \Delta}_{t,j}^{\mathrm{clip}_{2}}(x,\tilde{x})+\zeta_{t}(x,\tilde{x})|;\] (3.3)

PS\(\varepsilon\)BAI actively enters the CD phase every \(\gamma\) time steps (Line 12). It **firstly** adds a CD sample to \(\mathrm{CD_{sample}}\) (Line 13). **Next**, if there are sufficient CD samples (Line 15), the LCD subroutine (presented in Algorithm 3) is called and utilizes the most recent \(w\) CD samples to check whether a changepoint just occurred (Line 16). PS\(\varepsilon\)BAI steps into the CA phase if a changepoint is detected, and skips the CA phase otherwise, which is illustrated by Figures 1(b) and 1(a) respectively.

In the CA phase, PS\(\varepsilon\)BAI **starts** by resetting \(\mathrm{CD_{sample}}\) (Line 17), updating the count of time steps and recording the ending time of this CA phase (Line 18). **Thereafter**, the CA subroutine (presented in Algorithm 4) is invoked, which estimates the current latent context index \(\hat{j}_{t}\) and updates \(\mathrm{CA_{id}}\) (Line 19). If \(\hat{j}_{t}=N+1\), i.e., PS\(\varepsilon\)BAI identifies \(N+1\) latent contexts, which is incorrect under instance \(\Lambda\), it terminates and fails to identify an \(\varepsilon\)-optimal arm (Line 20). **Lastly**, all empirical statistics are reverted to those from \((w(\gamma+1)/2)\) time steps ago, i.e., the most recent \((w\gamma/2)\) samples in the Exp phases are abandoned (Line 21).

The stopping rule is described in Lines 26 to 32. **(I)** If the following condition is satisfied (Line 26):

\[\min_{x:x\neq x_{t}^{\top}}\hat{\Delta}_{t}(x_{t}^{\top},x)-\rho_{t}(x_{t}^{ \top},x)\geq-\varepsilon\quad\text{and}\quad T_{t}\geq\frac{2L_{\max}}{9} \ln\left(\frac{2}{\delta_{d,T_{t}}}\right)\] (3.4)

where the empirical mean gap \(\hat{\Delta}_{t}(x_{t}^{\top},x):=(x_{t}^{\top}-x)^{\top}\hat{\Theta}_{t} \hat{\mathbf{p}}_{t}\) and \(x_{t}^{\top}:=\operatorname*{arg\,max}_{x\in\mathcal{X}}x^{\top}\hat{\Theta}_ {t}\hat{\mathbf{p}}_{t}\), PS\(\varepsilon\)BAI records the arm with the highest empirical mean as \(\hat{x}_{\varepsilon}\) and the number of CD samples \(t_{\mathrm{CD}}\) (Lines 27 and 28) but does not terminate immediately. Besides, a mild forced arm pull procedure is in the second line of (3.4), which is inspired by Lemma E.1 and to ensure the performance of PS\(\varepsilon\)BAI. **(II)** PS\(\varepsilon\)BAI will execute for another \((w\gamma/2)\) time steps in which \(w/2\) CD samples are collected; if no changepoint is detected with these \(w/2\) CD samples, the recorded arm \(\hat{x}_{\varepsilon}\) is recommended and PS\(\varepsilon\)BAI terminates (Lines 29 to 30). Part **(II)** of the stopping rule assures PS\(\varepsilon\)BAI does not terminate when a changepoint has occurred but has not been detected, as PS\(\varepsilon\)BAI may fail to identify an \(\varepsilon\)-optimal arm otherwise.

We remark that even though PS\(\varepsilon\)BAI uses the knowledge of \(L_{\max}\), our experiments show that the performance of PS\(\varepsilon\)BAI is robust to small misspecifications in \(L_{\max}\) (see Appendix O.2). Furthermore, the computational complexity of PS\(\varepsilon\)BAI is computed in detail in Appendix D.4. The derived computational complexity indicates the proposed algorithm depends in a natural manner on the problem parameters such as \(d,K,N\), and \(\gamma\). Lastly, thanks to the LCD and LCA subroutines, a slightly modified variant of PS\(\varepsilon\)BAI can also solve the "\(\varepsilon\)-Best Arm Tuple identification problem", which aims to identify an \(\varepsilon\)-best arm _under each context_; see Appendix Q for details.

Figure 1: (a) No change alarm is raised during a stationary segment. The active CD samples are the input to the LCD subroutine at current time step \(t\). (b) A changepoint is detected by LCD, followed by a CA phase and a statistics reversion step.

#### 3.2.1 Theoretical guarantee of PS\(\varepsilon\)BAI

To facilitate the analysis of PS\(\varepsilon\)BAI, we propose the following assumptions. Note that our PS\(\varepsilon\)BAI algorithm may still succeed to identify an \(\varepsilon\)-optimal arm w.h.p. when the assumptions do not hold.

**Assumption 1** (Distinguishability Condition).: _The agent can choose \(w\), \(\gamma\) and \(b\) such that (1) \(2b\leq\Delta_{c}\) where \(\Delta_{c}:=\min_{\theta^{*}_{j}\neq\theta^{*}_{j}}\max_{x\in\mathcal{X}}|x^{ \top}(\theta^{*}_{j}-\theta^{*}_{j})|\) is the minimum gap between two contexts; and (2) \(3w\gamma\leq L_{\min}\). A possible choice is_

\[b =\!\frac{8d}{3w}\ln\frac{2}{\delta_{\mathrm{FAE}}}\!+\!\sqrt{\Big{(}\frac{8d }{3w}\ln\frac{2}{\delta_{\mathrm{FAE}}}\Big{)}^{2}\!+\!\frac{24d}{w}\ln\frac{ 2}{\delta_{\mathrm{FAE}}}}\quad\text{where}\quad\delta_{\mathrm{FAE}}=\frac{ \gamma\delta}{4(\tau^{*})^{2}K}.\] (3.5)

This assumption guarantees (i) PS\(\varepsilon\)BAI will not abandon all samples during the reversion procedure (Line 21 of Algorithm 1); (ii) each two latent vectors can be distinguished if the window size \(w\) is sufficiently large (e.g., \(L_{\min}/6\)). We clarify that this assumption is only for the rigor of theoretical guarantees and it holds provided that each stationary segment is sufficiently long; this is a feature of PSB models and similar assumptions are also present in existing works for their analyses [21, 10, 22]. We demonstrate the robustness of PS\(\varepsilon\)BAI to these parameters using experiments in Section 6.

**Theorem 3.2**.: _Define the context distribution estimation (DE) hardness parameter_

\[\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x):=\frac{L_{\max}}{\left(\Delta(x^{* },x)+\varepsilon\right)^{2}}\bar{H}(x_{\varepsilon},x)\]

_where \(\bar{H}(x_{\varepsilon},x):=\big{(}\sum_{j=1}^{N}\sqrt{\min\left\{16p_{j},1/4 \right\}}|\Delta_{j}(x_{\varepsilon},x)+\varepsilon|\big{)}^{2}\). Under Assumption 1, with probability at least \(1-\delta\), PS\(\varepsilon\)BAI identifies an \(\varepsilon\)-optimal arm and its sample complexity is_

\[\tilde{O}\Bigg{(}\max_{\begin{subarray}{c}x_{\varepsilon}\in\mathcal{X}_{ \varepsilon}\\ x\neq x_{\varepsilon},x^{*}\end{subarray}}\underbrace{\frac{d}{\left(\Delta(x^ {*},x)+\varepsilon\right)^{2}}\ln\frac{1}{\delta}}_{T_{\mathrm{V}}(x)}\!\! +\underbrace{\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x)\ln\frac{1}{\delta}}_ {T_{\mathrm{D}}(x_{\varepsilon},x)}+\underbrace{\frac{NL_{\max}}{\Delta(x^{* },x)+\varepsilon}\ln\frac{1}{\delta}}_{T_{\mathrm{R}}(x)}\Bigg{)}.\] (3.6)

The upper bound comprises three terms which serve distinct purposes:

(i) _Latent vector estimation_ (VE): \(\tilde{O}\left(T_{\mathrm{V}}(x)\right)\) quantifies the bulk of samples needed to obtain a good estimate of latent context vectors such that the returns of \(x_{\varepsilon}\) and \(x\) can be distinguished, where \(x_{\varepsilon}\) is an \(\varepsilon\)-best arm and \(x\notin\mathcal{X}_{\varepsilon}\) is a suboptimal arm. \(T_{\mathrm{V}}(x)\) recovers the sample complexity in the stationary linear bandits in [1], indicating that PS\(\varepsilon\)BAI estimates latent vectors efficiently.

(ii) _Context distribution estimation_ (DE): \(\tilde{O}\left(T_{\mathrm{D}}(x_{\varepsilon},x)\right)\) characterizes the bulk of samples needed to learn the distribution of latent context vectors.

(iii) _Residual estimation_ (RE): \(\tilde{O}\left(T_{\mathrm{R}}(x)\right)\) counts the remaining samples needed for VE and DE, in addition to \(\tilde{O}\left(T_{\mathrm{V}}+T_{\mathrm{D}}\right)\).

Besides, the \(\max\) operator is applied to exclude all suboptimal arms. We also see that \(T_{\mathrm{V}}(x)\) and \(T_{\mathrm{D}}(x_{\varepsilon},x)\) are similar to \(T_{\mathrm{V}}^{\mathrm{N}}\) and \(T_{\mathrm{D}}^{\mathrm{N}}\) in Proposition 3.1 respectively.

**Firstly,** the bound in (3.6) implies that, in an instance with smaller _relaxed mean gap_\(\Delta(x^{*},x)+\varepsilon\), PS\(\varepsilon\)BAI terminates after a larger number of time steps; in other words, it is more difficult to identify an \(\varepsilon\)-optimal arm. In difficult instances with small \(\Delta(x^{*},x)+\varepsilon\), the different orders of this term in \(T_{\mathrm{V}}(x)\), \(T_{\mathrm{D}}(x_{\varepsilon},x)\) and \(T_{\mathrm{R}}(x)\) indicate that, \(T_{\mathrm{R}}(x)\) is small compared to \(T_{\mathrm{V}}(x)\) and \(T_{\mathrm{D}}(x_{\varepsilon},x)\).

**Secondly,** DE solely utilizes context samples generated with \(P_{\theta}\) and they are generated _only_ at changepoints in \(\mathcal{C}\), while all the observations in Exp phases facilitate VE. From this perspective, there are less samples that can be used for DE than for VE as PS\(\varepsilon\)BAI processes, and hence \(T_{\mathrm{D}}(x_{\varepsilon},x)\) is supposed to be with larger order than \(T_{\mathrm{V}}(x)\).

**Moreover,** for the purpose of DE, PS\(\varepsilon\)BAI needs to observe context samples at \(\tilde{O}\big{(}\frac{\bar{H}(x_{\varepsilon},x)}{(\Delta(x^{*},x^{*})+ \varepsilon)^{2}}\ln\frac{1}{\delta}\big{)}=\tilde{O}\big{(}\frac{\mathrm{H}_{ \mathrm{DE}}(x_{\varepsilon},x)}{L_{\max}}\ln\frac{1}{\delta}\big{)}\) changepoints where \(L_{\max}\) is the maximum length of a stationary segment, leading us to \(T_{\mathrm{D}}(x_{\varepsilon},x)\). Close examination of the definition of \(\bar{H}(x_{\varepsilon},x)\) reveals that _both_ the vectors and their probabilities influence the number of samples needed for DE. The comparison between \(T_{\mathrm{D}}(x_{\varepsilon},x)\) and \(T_{\mathrm{D}}^{\mathrm{N}}\) in Proposition 3.1 clearly indicates that PS\(\varepsilon\)BAI mitigates the influence of \(L_{\max}\) by detecting changepoints and aligning the detected context with observed ones, while N\(\varepsilon\)BAI does not do so.

### Ps\(\varepsilon\)Bai\({}^{+}=\) Ps\(\varepsilon\)Bai\(\,\cup\) N\(\varepsilon\)Bai

We have provided a _high-probability_ result for PS\(\varepsilon\)BAI in Theorem 3.2. The design of PS\(\varepsilon\)BAI (Line 7 of Algorithm 1) indicates that PS\(\varepsilon\)BAI will not recommend any arm if it does not terminate at time \(\tau^{*}\). This result is nontrivial, as the high-probability result in Theorem 3.2 depends on the success of change detection (Algorithm 3) and context alignment (Algorithm 4), which requires a non-vanishing failure probability (e.g., \(\delta/2\)). Thus, we cannot derive an upper bound on the expected sample complexity of PS\(\varepsilon\)BAI. We devise a solution by designing the Piecewise-Stationary \(\varepsilon\)-Best \(\underline{\Delta\mathrm{rm}}\) Identification\({}^{+}\) (PS\(\varepsilon\)BAI\({}^{+}\)) algorithm with a simple but effective trick.

The PS\(\varepsilon\)BAI\({}^{+}\) algorithm samples _one_ arm with the G-optimal allocation \(\lambda^{*}\) at each time step, with which Algorithms 1 and 2 are executed in parallel (detailed in Algorithm 5). This is feasible since PS\(\varepsilon\)BAI and N\(\varepsilon\)BAI algorithms have the same sampling rule.

**Theorem 3.3**.: _The PS\(\varepsilon\)BAI\({}^{+}\) algorithm is \((\varepsilon,\delta)\)-PAC and its expected sample complexity is_

\[\tilde{O}\bigg{(}\min\bigg{\{}\max_{x_{\varepsilon}\in\mathcal{X}_{ \varepsilon},x\neq x_{\varepsilon},x^{*}}T_{\mathrm{V}}(x)+T_{\mathrm{D}}(x_{ \varepsilon},x)+T_{\mathrm{R}}(x),\,T_{\mathrm{V}}^{\mathrm{N}}+T_{\mathrm{D}} ^{\mathrm{N}}\bigg{\}}\bigg{)}.\]

PS\(\varepsilon\)BAI\({}^{+}\) inherits the superiority of PS\(\varepsilon\)BAI to adapt to the piecewise stationary environment, and employs the stopping rule of N\(\varepsilon\)BAI to maintain a finite expected sample complexity. As a result, the expected complexity of PS\(\varepsilon\)BAI\({}^{+}\) in Theorem 3.3 is of the same order as the high-probability one of PS\(\varepsilon\)BAI in Theorem 3.2 and is not larger than the complexity of N\(\varepsilon\)BAI in Proposition 3.1. We show how our results particularize to the _stationary_ linear bandits BAI problem, as well as additional discussions on the upper bound, in Appendix P.

## 4 Lower Bound on the Sample Complexity

Given \(\Lambda=(\mathcal{X},\Theta,P_{\theta},\mathcal{C})\), define the alternative instance \(\Lambda^{\prime}=(\mathcal{X},\Theta^{\prime},P_{\theta^{\prime}},\mathcal{C})\) w.r.t. \(\Lambda\), where \(\Theta^{\prime}=(\theta_{1}^{\prime},\ldots,\theta_{n}^{\prime})\in\mathbb{R} ^{d\times N}\), \(P_{\theta^{\prime}}[\theta_{j}^{\prime}]=P_{\theta}[\theta_{j}^{*}]\), and there exists \(x\in\mathcal{X}\setminus\mathcal{X}_{\varepsilon}\), such that \(x_{\varepsilon}^{\top}\mathbb{E}_{\theta^{\prime}\sim P_{\theta^{\prime}}}[ \theta^{\prime}]<x^{\top}\mathbb{E}_{\theta^{\prime}\sim P_{\theta^{\prime}}} [\theta^{\prime}]-\epsilon\) for all \(x_{\varepsilon}\in\mathcal{X}_{\varepsilon}\). Let \(\mathrm{Alt}_{\Theta}(\Lambda)\) be set of all alternative instances (w.r.t. \(\Lambda\)).

**Theorem 4.1**.: _For all \((\varepsilon,\delta)\)-PAC algorithm \(\pi\), there exists an instance \(\Lambda=(\mathcal{X},\Theta,P_{\theta},\mathcal{C})\) such that_

\[\mathbb{E}[\tau_{\pi}]\geq\max\left\{T_{\varepsilon}(\Lambda)\ln\frac{1}{2.4 \delta},\,c_{N_{\mathcal{C}}}\right\},\]

_where_

\[T_{\varepsilon}(\Lambda)^{-1}:=\max_{\{v_{j}\}_{j=1}^{N}\Lambda^{ \prime}\in\mathrm{Alt}_{\Theta}(\Lambda)}\sum_{j,x}p_{j}v_{j,x}\frac{(x^{\top}( \theta_{j}^{*}-\theta_{j}^{\prime}))^{2}}{2},\quad\text{and}\] \[N_{\mathcal{C}}:=\max_{x\neq x^{*}}\frac{\sum_{j}p_{j}(\Delta_{j}( x^{*},x)+\varepsilon)^{2}}{(\Delta(x^{*},x)+\varepsilon)^{2}}\ln\frac{1}{4\delta}.\]

Recall that \(c_{N_{\mathcal{C}}}\) is the \(N_{\mathcal{C}}\)-th changepoint in the changepoint sequence \(\mathcal{C}\), which is lower bounded by \(N_{\mathcal{C}}L_{\min}\) and is \(N_{\mathcal{C}}L_{\max}\) in the worst case. To derive the lower bound in Theorem 4.1, we investigate two environments different from the one defined in Section 2 (and as in Dynamics 1):

\(\bullet\) Dynamics 2: the agent observes the index of current context \(j_{t}\) (i.e., contextual linear bandits);

\(\bullet\) Dynamics 3: the agent observes the changepoints in \(\mathcal{C}\) and context vector \(\theta_{j_{t}}^{*}\)'s, and hence she solely needs to estimate the distribution of contexts.

We bound the sample complexity of an \((\varepsilon,\delta)\)-BAI algorithm in Dynamics 2 and 3 respectively, which when combined, yield the lower bound in Theorem 4.1; this is detailed in Appendix M.

Note that \(T_{\varepsilon}(\Lambda)^{-1}\) in the lower bound generalizes [16] to the setting of linear bandits. In addition, Theorem 4.1 can be reduced to a bound in stationary linear bandits with one latent vector [24] (see the discussion leading to (M.15)).

## 5 On the Asymptotic Optimality of PS\(\varepsilon\)Bai\({}^{+}\)

To illustrate the efficiency of our PS\(\varepsilon\)BAI\({}^{+}\) algorithm, we compare the upper bound on its expected sample complexity in Theorem 3.3 and the generic lower bound in Theorem 4.1 under specific instances below and in Appendix N. We also gain further insight into our PS\(\varepsilon\)BAI\({}^{+}\) algorithm.

**Example 1**.: _Instance \(\Lambda=(\mathcal{X},\Theta,P_{\theta},\mathcal{C})\) is with (i) \(2d-1\) arms: \(x_{(1)}=\mathbf{e}_{1},x_{(i)}=\mathbf{e}_{i},x_{(d+i-1)}=\mathbf{e}_{1}\cos \phi+\mathbf{e}_{i}\sin\phi\) for all \(i\in\{2,\ldots,d\}\) where \(\phi\in[0,\pi/4)\), (ii) \(2d-2\) contexts: \(\theta^{*}_{j\pm}=\mathbf{e}_{1}\cos\phi\pm\mathbf{e}_{j+1}\sin\phi\) for all \(j\in[d-1],\) (iii) Context distribution: \(p_{j}=1/N\) for all \(j\in[N]\)._

Under the instance defined in Example 1, \(x_{(i)}\) for all \(i\neq 1\) is inferior to \(x_{(1)}\) under all contexts and \(x_{(i+d)}\) for all \(i\in[d-1]\) is marginally better than \(x_{(1)}\) by \(1-\cos\phi\) only under context \(\theta^{*}_{i+}\) and \(\Delta(x_{(1)},x_{(i+d)})=\cos\phi-\cos^{2}\phi\). We expect PS\(\varepsilon\)BAI\({}^{+}\) to discover this feature of the instances and quickly identify an \(\varepsilon\)-optimal arm with a course estimation of the context distribution.

**Corollary 5.1**.: _For the instance defined in Example 1, we have \(\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x)=\tilde{O}(NL_{\max})\) for all \((x_{\varepsilon},x)\in\mathcal{X}_{\varepsilon}\times(\mathcal{X}\setminus \mathcal{X}_{\varepsilon})\). In addition, if \(\varepsilon<(\cos\phi)(1-\cos\phi)\), we have_

\[\frac{\mathbb{E}[\tau]^{*}}{\ln(1/\delta)}\in\ \tilde{\Theta}\bigg{(}(1 \!+\!f(\phi))\cdot\frac{d}{(\Delta_{x_{(1)},x_{(d+1)}}\!+\!\varepsilon)^{2}} \bigg{)},\] (5.1)

_where \(\mathbb{E}[\tau]^{*}\) is the minimal expected sample complexity over all \((\varepsilon,\delta)\)-PAC algorithms and \(f:\mathbb{R}\to\mathbb{R}\) satisfies \(f(\phi)\to 0\) as \(\phi\to 0^{+}\). The upper bound in (5.1) is achieved by PS\(\varepsilon\)BAI\({}^{+}\)._

The order of \(\mathrm{H}_{\mathrm{DE}}\) in Corollary 5.1 indicates that \(T_{\mathrm{D}}(x_{(1)},x_{(d+1)})=\tilde{O}(NL_{\max}\ln(1/\delta))\) is not dominating the sample complexity of PS\(\varepsilon\)BAI\({}^{+}\), suggesting that a coarse estimation of the context distribution is sufficient when \(\phi\) is small. In other words, PS\(\varepsilon\)BAI\({}^{+}\) exploits the feature of instances and utilize samples mostly for estimate context vectors, which is again expected.

Corollary 5.1 implies that under such instances, the upper and lower bounds on the sample complexity of PS\(\varepsilon\)BAI\({}^{+}\) match up to logarithmic factors, that is, the performance PS\(\varepsilon\)BAI\({}^{+}\) is near optimal. Besides, the bound of N\(\varepsilon\)BAI in Proposition 3.1 is with an extra additive term \(L_{\max}\) compared to the lower bound in Corollary 5.1, illustrating that N\(\varepsilon\)BAI is suboptimal and again emphasizing the significance of detecting changes and aligning contexts for PS\(\varepsilon\)BAI\({}^{+}\) to reduce the impact of \(L_{\max}\).

## 6 Numerical Experiments

We now evaluate the empirical performance of PS\(\varepsilon\)BAI\({}^{+}\). We utilize the instance defined in Example 1 with \(d=2\), \(\phi=\pi/8\), We generate a changepoint sequence \(\mathcal{C}\) such that \(c_{l+1}=c_{l}+L_{l}\) with \(L_{\min}=3\times 10^{4}\), \(L_{\max}=5\times 10^{4}\), \(\mathbb{P}[L_{l}=L_{\min}]=0.8\), \(\mathbb{P}[L_{l}=L_{\max}]=0.2\), and fix it throughout the whole set of experiments. We set the confidence parameter \(\delta=0.05\) and vary the slackness parameter \(\varepsilon\) from \(0.04\) to \(0.6\) (i.e., \(\varepsilon=0.03\times 1.35^{k}\) for \(k\in[12]\)). We set \(\gamma=6\), the window size \(w=L_{\min}/(3\gamma)\) and compute \(b\) via (3.5) in Assumption 1.3 For each choice of algorithm and instance, we run \(20\) independent trials. All the code to reproduce our experiments can be found at https://github.com/Y-Hou/BAI-in-PSLB.git.

Footnote 3: We clarify that (3.5) in Assumption 1 is only for our theoretical guarantees. In practice, our algorithm has shown robustness w.r.t. the parameters and we can safely neglect the constants in the formula.

We **first** compare PS\(\varepsilon\)BAI\({}^{+}\) and N\(\varepsilon\)BAI. Both algorithms succeed to identify an \(\varepsilon\)-optimal arm, while empirically, the complexity of PS\(\varepsilon\)BAI\({}^{+}\) is \(\leq 1\%\) of that of N\(\varepsilon\)BAI. The empirical averages and standard deviations of the sample complexities of both algorithms are presented in Figure 2(a).

Figure 2: Experimental resultsFigure 2(a) illustrates that empirically, the termination and arm recommendation of PS\(\varepsilon\)BAI\({}^{+}\) are determined by the execution of PS\(\varepsilon\)BAI as a subroutine, suggesting that in Theorem 3.3, the first term resulting from PS\(\varepsilon\)BAI actually determines the complexity of PS\(\varepsilon\)BAI\({}^{+}\).

**Next,** we test the efficacy of PS\(\varepsilon\)BAI\({}^{+}\) to learn and exploit the latent vectors and the distribution of contexts. Specifically, we run PS\(\varepsilon\)BAI\({}^{+}\) and N\(\varepsilon\)BAI under Dynamics 1 where neither the index nor the vector of current context is visible to the agent. We also run benchmark algorithms: D\(\varepsilon\)BAI and its variant D\(\varepsilon\)BAI\({}_{\beta}\) under Dynamics 3 where context vectors and changepoints are all observed; these two algorithms are detailed and analyzed in Appendix O.4.

As the changepoint sequence \(\mathcal{C}\) is fixed in a given instance and \(t/L_{\max}\leq l_{t}\leq t/L_{\min}\) for all \(t\in\mathbb{N}\), we regard the number of context samples \(l_{\tau}\) as a proxy of the sample complexity \(\tau\). We present the number of context samples need by PS\(\varepsilon\)BAI\({}^{+}\), N\(\varepsilon\)BAI, D\(\varepsilon\)BAI and D\(\varepsilon\)BAI\({}_{\beta}\) for arm identification w.r.t. \(1/(\Delta_{\min}+\varepsilon)^{2}\) in Figure 2(b).

Figure 2(b) contains three messages. First, the complexity of PS\(\varepsilon\)BAI\({}^{+}\) scales as \(1/(\Delta_{\min}+\varepsilon)^{2}\), corroborating Theorem 3.3. Second, although PS\(\varepsilon\)BAI\({}^{+}\) has access to neither context vectors nor changepoints, it needs roughly the same number of context samples as D\(\varepsilon\)BAI and D\(\varepsilon\)BAI\({}_{\beta}\), suggesting that it is competitive compared to these algorithms that have oracle information about the environment. Third, D\(\varepsilon\)BAI\({}_{\beta}\) uses the confidence radius in (3.3) and terminates with fewer context samples compared to D\(\varepsilon\)BAI, implying that the confidence radius is well-designed.

**Furthermore,** when \(\varepsilon\) decreases from \(0.03\times 1.35^{12}\) to \(0.03\times 1.35^{9}\), the complexity of PS\(\varepsilon\)BAI almost remains unchanged while that of N\(\varepsilon\)BAI increases rapidly as presented in instances \(9\) to \(12\) in Figure 2(a). Meanwhile, the number of context samples need by two algorithms are shown to be with the same pattern in Figure 2(b). This contrast indicates that the cost of distribution estimation (\(T_{\mathrm{D}}\) in (3.6)) for PS\(\varepsilon\)BAI\({}^{+}\) has been significantly minimized compared to N\(\varepsilon\)BAI.

**To summarize,** we emphasize that the empirical superiority of PS\(\varepsilon\)BAI\({}^{+}\) over N\(\varepsilon\)BAI implies that _the efficacy of_ PS\(\varepsilon\)BAI\({}^{+}\)_is inherited from_ PS\(\varepsilon\)BAI. Our experiments show that actively exploiting the context information, via changepoint detection and context alignment (as in PS\(\varepsilon\)BAI\({}^{+}\) and PS\(\varepsilon\)BAI) facilitates identifying the \(\varepsilon\)-optimal arm efficiently.

Similar to many existing algorithms in piecewise-stationary bandits [21; 10; 22], our algorithm requires Assumption 1 and the knowledge of \(L_{\max}\). These may not be available in practice. Thus, we conduct more experiments in Appendix O.2 to exhibit the robustness of PS\(\varepsilon\)BAI\({}^{+}\). Specifically, in Appendix O.2, we conduct experiments for the case in which \(L_{\max}\) is _misspecified_. In Appendix O.3, we alter the change detection frequency \(\gamma\) so that \(w\) and \(b\) change accordingly. In both sets of experiments, the overall sample complexity of PS\(\varepsilon\)BAI\({}^{+}\) does not vary significantly and retains its superiority over N\(\varepsilon\)BAI. We conclude that PS\(\varepsilon\)BAI\({}^{+}\) is robust to slight misspecifications in these parameters, as long as Assumption 1 is not severely violated. Please refer to Appendix O for further details and experiments.

## 7 Conclusion and Future Work

We proposed a novel PSLB model and designed the PS\(\varepsilon\)BAI\({}^{+}\) algorithm to identify an \(\varepsilon\)-optimal arm with probability \(\geq 1-\delta\). The efficacy of PS\(\varepsilon\)BAI\({}^{+}\) has been demonstrated both empirically and theoretically. We argued that this is due to the embedded change detection and context alignment procedures. There are several directions for further exploration.

**Firstly,** our PS\(\varepsilon\)BAI\({}^{+}\) algorithm provides a fairly general _framework_ for algorithm design. For instance, in addition to utilization the G-optimal allocation to sample arms as in PS\(\varepsilon\)BAI\({}^{+}\), the \(\mathcal{X}\mathcal{Y}\)-allocation and adaptive \(\mathcal{X}\mathcal{Y}\)-allocation [1] can also be considered. In other words, our PS\(\varepsilon\)BAI\({}^{+}\) algorithm can be generalized to form an entire class of algorithms for BAI in PSLB models. In addition, deriving instance-dependent guarantees is also of great interest.

**Secondly,** most of the literature on piecewise-stationary bandits [21; 10; 22] make assumptions to provide theoretical guarantees. It would be interesting to remove or reduce these assumptions under our \(\varepsilon\)-BAI problem setup, and yet still be able to provide similar theoretical guarantees.

**Finally,** we believe that it is possible to adapt our PS\(\varepsilon\)BAI\({}^{+}\) algorithm to the fixed-budget setting, i.e., to identify an \(\varepsilon\)-optimal arm with high probability in a fixed time horizon in PSLB models.

Acknowledgements:This work is funded by the Singapore Ministry of Education AcRF Tier 2 grant (A-8000423-00-00) and Tier 1 grants (A-8000189-01-00 and A-8000980-00-00).

## References

* [1] Marta Soare, Alessandro Lazaric, and Remi Munos. Best-arm identification in linear bandits. In _Proceedings of the 27th Advances in Neural Information Processing Systems_, volume 27, pages 828-836, 2014.
* [2] Junwen Yang and Vincent Tan. Minimax optimal fixed-budget best arm identification in linear bandits. _Proceedings of the 36th Advances in Neural Information Processing Systems_, 35:12253-12266, 2022.
* [3] Yasin Abbasi-yadkori, David Pal, and Csaba Szepesvari. Improved algorithms for linear stochastic bandits. In _Proceedings of the 24th Advances in Neural Information Processing Systems_, volume 24. Curran Associates, Inc., 2011.
* [4] Marc Abeille and Alessandro Lazaric. Linear thompson sampling revisited. In _Proceedings of the 20th International Conference on Artificial Intelligence and Statistics_, pages 176-184. PMLR, 2017.
* [5] Tanner Fiez, Lalit Jain, Kevin G Jamieson, and Lillian Ratliff. Sequential experimental design for transductive linear bandits. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alche-Buc, E. Fox, and R. Garnett, editors, _Proceedings of the 32nd Advances in Neural Information Processing Systems_, volume 32. Curran Associates, Inc., 2019.
* [6] Marc Jourdan, Remy Degenne, and Emilie Kaufmann. An \(\varepsilon\)-best-arm identification algorithm for fixed-confidence and beyond, November 2023. arXiv:2305.16041.
* [7] Remy Degenne and Wouter M Koolen. Pure exploration with multiple correct answers. _Proceedings of the 32nd Advances in Neural Information Processing Systems_, 32, 2019.
* [8] Omar Besbes, Yonatan Gur, and Assaf Zeevi. Stochastic multi-armed-bandit problem with non-stationary rewards. In Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K.Q. Weinberger, editors, _Proceedings of the 27th Advances in Neural Information Processing Systems_, volume 27. Curran Associates, Inc., 2014.
* [9] Aurelien Garivier and Eric Moulines. On upper-confidence bound policies for switching bandit problems. In Jyrki Kivinen, Csaba Szepesvari, Esko Ukkonen, and Thomas Zeugmann, editors, _The 22nd International conference on Algorithmic learning theory_, pages 174-188, Berlin, Heidelberg, 2011. Springer Berlin Heidelberg.
* [10] Yang Cao, Zheng Wen, Branislav Kveton, and Yao Xie. Nearly optimal adaptive procedure with change detection for piecewise-stationary bandit. In _Proceedings of the 22nd International Conference on Artificial Intelligence and Statistics_, pages 418-427. PMLR, 2019.
* [11] Yueyang Liu, Xu Kuang, and Benjamin Van Roy. A definition of non-stationary bandits, Feb 2023. arXiv:2302.12202.
* [12] Wang Chi Cheung, David Simchi-Levi, and Ruihao Zhu. Learning to optimize under non-stationarity. In _The 22nd International Conference on Artificial Intelligence and Statistics_, pages 1079-1087. PMLR, 2019.
* [13] Jonathan Shapiro, Carlos M Carvalho, and Pradeep Ravikumar. Thompson sampling in switching environments with bayesian online change point detection. In _Proceedings of the 16th International Conference on Artificial Intelligence and Statistics_, pages 442-450. Microtome Publishing, 2013.
* [14] Zhihan Xiong, Romain Camilleri, Maryam Fazel, Lalit Jain, and Kevin Jamieson. A/B testing and best-arm identification for linear bandits with robustness to non-stationarity. In _Proceedings of The 27th International Conference on Artificial Intelligence and Statistics, PMLR 238_, pages 1585-1593. PMLR, 2023.

* [15] Robin Allesiardo, Raphael Feraud, and Odalric-Ambrym Maillard. The non-stationary stochastic multi-armed bandit problem. _International Journal of Data Science and Analytics_, 3:267-283, 2017.
* [16] Masahiro Kato and Kaito Ariu. The role of contextual information in best arm identification, 2021. arXiv:2106.14077.
* [17] Yoan Russac, Christina Katsimerou, Dennis Bohle, Olivier Cappe, Aurelien Garivier, and Wouter M Koolen. A/B/n testing with control in the presence of subpopulations. _Proceedings of the 34th Advances in Neural Information Processing Systems_, 34:25100-25110, 2021.
* [18] Andrea Zanette, Kefan Dong, Jonathan N Lee, and Emma Brunskill. Design of experiments for stochastic contextual linear bandits. _Proceedings of the 34th Advances in Neural Information Processing Systems_, 34:22720-22731, 2021.
* [19] Yasin Abbasi-Yadkori, Andras Gyorgy, and Nevena Lazic. A new look at dynamic regret for non-stationary stochastic bandits. _Journal of Machine Learning Research_, 24(288):1-37, 2023.
* [20] Jia Yuan Yu and Shie Mannor. Piecewise-stationary bandit problems with side observations. In _Proceedings of the 26th International Conference on Machine Learning_, ICML '09, page 1177-1184. Association for Computing Machinery, 2009.
* [21] Fang Liu, Joohyun Lee, and Ness Shroff. A change-detection based framework for piecewise-stationary multi-armed bandit problem. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 32, 2018.
* [22] Lilian Besson, Emilie Kaufmann, Odalric-Ambrym Maillard, and Julien Seznec. Efficient change-point detection for tackling piecewise-stationary bandits. _The Journal of Machine Learning Research_, 23(1):3337-3376, 2022.
* [23] Peter Auer, Pratik Gajane, and Ronald Ortner. Adaptively tracking the best bandit arm with an unknown number of distribution changes. In _Proceedings of the 32nd Conference on Learning Theory_, pages 138-158. PMLR, 2019.
* [24] Yassir Jedra and Alexandre Proutiere. Optimal best-arm identification in linear bandits. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, _Proceedings of the 34th Advances in Neural Information Processing Systems_, volume 33, pages 10007-10017. Curran Associates, Inc., 2020.
* [25] Peng Zhao, Lijun Zhang, Yuan Jiang, and Zhi-Hua Zhou. A simple approach for non-stationary linear bandits. In _The 23rd International Conference on Artificial Intelligence and Statistics_, pages 746-755. PMLR, 2020.
* [26] Masahiro Kato, Masaaki Imaizumi, Takuya Ishihara, and Toru Kitagawa. Asymptotically optimal fixed-budget best arm identification with variance-dependent bounds, 2023. arXiv:2302.02988.
* [27] Chao Qin and Daniel Russo. On adaptivity and confounding in contextual bandit experiments. In _NeurIPS 2021 Workshop on Distribution Shifts: Connecting Methods and Applications_, 2021.
* [28] Yasin Abbasi-Yadkori, Peter Bartlett, Victor Gabillon, Alan Malek, and Michal Valko. Best of both worlds: Stochastic & adversarial best-arm identification. In _Proceedings of the 31st Conference on Learning Theory_, pages 918-949. PMLR, 2018.
* [29] Tor Lattimore and Csaba Szepesvari. _Bandit Algorithms_. Cambridge University Press, 2020.
* [30] Kwang-Sung Jun, Kevin G Jamieson, Robert D Nowak, and Xiaojin Zhu. Top arm identification in multi-armed bandits with batch arm pulls. In _Proceedings of the 19th International Conference on Artificial Intelligence and Statistics_, pages 139-148, 2016.
* [31] Emilie Kaufmann, Olivier Cappe, and Aurelien Garivier. On the complexity of best arm identification in multi-armed bandit models. _Journal of Machine Learning Research_, 17:1-42, 2016.

* [32] Marc Jourdan and Remy Degenne. Choosing answers in epsilon-best-answer identification for linear bandits. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, _Proceedings of the 39th International Conference on Machine Learning_, volume 162 of _Proceedings of Machine Learning Research_, pages 10384-10430. PMLR, 17-23 Jul 2022.
* [33] Michael J. Todd. _Minimum-Volume Ellipsoids: Theory and Algorithms_. SIAM, 2016.

**Appendices**

The contents of the appendices are organized as follows:

* In Appendix A, we provide further motivating examples for our problem.
* In Appendix B, we discuss the limitations of our method.
* In Appendix C, we review more related works on drifting and contextual bandits.
* In Appendix D, we provide more details about our algorithms
* Appendix D.1: pseudo-code of N\(\varepsilon\)BAI in Algorithm 2.
* Appendix D.2: more details of PS\(\varepsilon\)BAI including the precise definition of the confidence radius \(\rho_{t}\) and details of LCD and LCA subroutines.
* Appendix D.3: pseudo-code of PS\(\varepsilon\)BAI\({}^{+}\) in Algorithm 5.
* Appendix D.4: the computational complexity of PS\(\varepsilon\)BAI in Algorithm 1.
* In Appendix E: we provide a useful lemma for estimating the expected return of any arm in linear bandits when the sampling rule is according to the G-optimal allocation.
* In Appendix F: we proof the upper bound on the expected sample complexity of N\(\varepsilon\)BAI.
* In Appendices G to K: we detail the analysis of PS\(\varepsilon\)BAI, i.e., we provide the proof of the upper bound on its complexity in Theorem 3.2.
* Appendix G: outline of the proof.
* Appendix H: analysis of the Change Detection (CD) and Context Alignment (CA) procedures.
* Appendix I: analysis of the estimation error by decomposing it into three terms: Vector-Estimation Error (VE), Distribution-Estimation Error (DE), and Residual Estimation Error (RE).
* Appendix J: proof of Theorem 3.2 based on the analysis above.
* Appendix K: proof of technical lemmas that are utilized in the analysis of PS\(\varepsilon\)BAI.
* In Appendix L: we prove the upper bound on the expected sample complexity of PS\(\varepsilon\)BAI\({}^{+}\) based on the analysis of N\(\varepsilon\)BAI and PS\(\varepsilon\)BAI.
* In Appendix M: we derive the lower bound on the expected sample complexity of any algorithm, i.e., proof Theorem 4.1.
* In Appendix N: we provide more examples to compare the derived upper and lower bounds on the expected sample complexity, and illustrate the efficacy of our PS\(\varepsilon\)BAI\({}^{+}\) algorithm.
* In Appendix O: we provide more details of numerical experiments.
* In Appendix P: we provide more discussions on
* the related methods for BAI in nonstationary bandits,
* the instance-dependent upper bound,
* the connection between the piecewise-stationary linear bandits model to the stationary linear bandits model,
* the special case where \(N=1\).
* In Appendix Q: we provide analytical results on the "Best Arm Tuple Identification Problem".

## Appendix A Further Motivating Examples

We elaborate on the some concrete real-life examples that motivate our problem setup of identifying the ensemble best arm in piecewise-stationary linear bandits.

In scenarios such as investment option selection and portfolio management also mentioned by [10, 20], there is a multitude of options for fund managers to choose from and typically, they want to find, in the initial pure exploration process, a small subset of candidate portfolios (or even the "best" portfolio) based on various economic indicators and the market performance of individual stocks before further exploitation. In a bearish market, more portfolios tend to incur losses; while in a bullish market, more portfolios tend to generate gains. The transition between these two contexts can be effected by stochastic factors, e.g., the weather, or the outbreak of a pandemic, making the market conditions (contexts) stochastic. In the face of these uncertainties (in the contexts and rewards), we wish to design and analyze algorithms that selected portfolio to yield the best long-term option under such a piecewise-stationary environment.

Crop rotation is another example. Since crop yields can be influenced by various factors, such as weather conditions (analogous to our stochastically generated contexts), selecting the most suitable crop to grow and harvest from is crucial. Given several candidate crops, crops of similar types (e.g., potatoes and sweet potatoes) are correlated as they tend to favor similar conditions, thus, they can bemodelled by bandits with a linear reward structure. Contextual factors, like weather conditions, are well-modelled as being stochastic. A fixed weather condition will last a period of time and it will not change suddenly. Domain knowledge from historical data/records provides us with prior knowledge on \(L_{\min}\) and \(L_{\max}\). These observations dovetail with our model. Our objective is to choose the crop that offers the near-highest yield potential over a long time period (an ensemble \(\varepsilon\)-best arm) and is adaptable to local environment factors, such as weather patterns.

## Appendix B Limitations

Similar to existing works on piecewise stationary bandits [21; 10; 22], we introduced some assumptions to provide theoretical guarantees for PS\(\varepsilon\)BAI\({}^{+}\) although PS\(\varepsilon\)BAI\({}^{+}\) has shown to be robust even in the absence of these assumptions. Since an algorithm may not need to differentiate two contexts with close latent vectors for identifying an \(\varepsilon\)-optimal arm, we surmise it is possible to weaken these assumptions. For this purpose, we will consider clustering the contexts into a few classes based on the distances between their latent vectors and design an algorithm that only aims to detect the change of context class, instead of the change of context.

## Appendix C More Related Work

In **drifting bandits** (DB), the regrets of algorithms are affected by the level of nonstationarity of the environment, which can be measured by various quantities, such as the total variation of the context sequence and the number of time steps when the return of at least one arm changes [23; 25].

In **contextual bandits** (CB), where the contextual information is visible to the agent, [16; 26; 17; 27] aim to identify the best arm with the assumption that the context changes at every time step according to a fixed distribution, and the return of an arm is averaged across all contexts. We see that the context distribution is involved to measure the quality of arms. However, while the agent in CB models can observe the context information, the agent has no access to the contexts but still aims to identify an \(\varepsilon\)-optimal arm in our piecewise stationary linear bandit (PSLB) model.

**In adversarial bandits**, existing works pertaining to the BAI problem only explored the fixed-horizon setting [28]. Due to the difference between the fixed-confidence and fixed-horizon setting and the difference between adversarial and piecewise stationary bandits, their results cannot be trivially extended to solve the fixed-confidence BAI problem in piecewise stationary bandits.

Appendix D More Details of Algorithms N\(\varepsilon\)BAI, PS\(\varepsilon\)BAI and PS\(\varepsilon\)BAI\({}^{+}\)

All proposed algorithms make use of the well known G-optimal allocation (design) [1; 29], which is widely used in the linear bandits literature. The G-optimal allocation minimizes the maximal mean-squared prediction error in all directions [1]. Given an arm set \(\mathcal{X}\), the G-optimal allocation \(\lambda^{*}\) is a distribution over the arm set, which is the minimizer of \(g(\lambda)=\max_{\varepsilon\in\mathcal{X}}\|x\|_{A(\lambda)^{-1}}^{2}\), where \(A(\lambda)=\sum_{x\in\mathcal{X}}\lambda(x)xx^{\top}\) and \(\lambda\in\Delta_{\mathcal{X}}\). Interested readers may refer to Chapter \(21\) in [29].

### The Naive \(\varepsilon\)-Best Arm Identification (N\(\varepsilon\)BAI) Algorithm

As presented in Algorithm 2, N\(\varepsilon\)BAI samples an arm with the G-optimal allocation at each time steps; its stopping rule is grounded on the property of G-optimal allocation (see Lemma E.1) and affected by the maximum length of a single stationary segment \(L_{\max}\).

```
1:Input: the arm set \(\mathcal{X}\), the phase length bounds \(L_{\min},L_{\max}\), the slackness parameter \(\varepsilon\), the confidence parameter \(\delta\).
2:Initialize: Compute the G-optimal allocation \(\lambda^{*}\).
3: Compute \(C_{3}=\sum_{n=1}^{\infty}n^{-3}\) and \(t^{*}=3d\ln(6dKC_{3}/\delta)\).
4: Sample \(t^{*}\) arms \(\{x_{s}\}_{s=1}^{t^{*}}\sim\lambda^{*}\) and observe the associated returns \(\{Y_{s,x_{s}}\}_{s=1}^{t^{*}}\). Let \(t=t^{*}\).
5: Compute \[\tilde{\theta}_{t} =\frac{1}{t}\sum_{s=1}^{t}A(\lambda^{*})^{-1}x_{s}Y_{s,x_{s}}, \quad\dot{x}_{t}=\operatorname*{arg\,max}_{x\in\mathcal{X}}x^{\top}\tilde{ \theta}_{t},\] (D.1) \[\tilde{\rho}_{t} =\sqrt{\frac{8L_{\max}}{t}\ln\frac{4KC_{3}t^{3}}{\delta}}+5\sqrt {\frac{d}{t}\ln\frac{4KC_{3}t^{3}}{\delta}}.\]
6:while\(\dot{x}_{t}^{\top}\tilde{\theta}_{t}-\tilde{\rho}_{t}+\varepsilon<\max_{x\neq\dot {x}_{t}}x^{\top}\tilde{\theta}_{t}+\tilde{\rho}_{t}\)do
7: Sample an arm \(x_{t}\sim\lambda^{*}\) and observe return \(Y_{t,x_{t}}\) and let \(t=t+1\).
8: Update \(\tilde{\theta}_{t}\), \(\dot{x}_{t}\) and \(\tilde{\rho}_{t}\) with (D.1).
9:endwhile
10: Recommend arm \(\dot{x}_{\varepsilon}=\dot{x}_{t}\). ```

**Algorithm 2**Naive \(\varepsilon\)-Best Arm Identification (N\(\varepsilon\)BAI)

### Details about \(\mathrm{PS}\varepsilon\mathrm{BAI}\)

#### d.2.1 Confidence radius utilized in \(\mathrm{PS}\varepsilon\mathrm{BAI}\)

For each pair of arms \((x,\tilde{x})\), the confidence radius of \(\Delta(x,\tilde{x})\) at time step \(t\) is

\[\rho_{t}(x,\tilde{x}):=2(\alpha_{t}+\xi_{t})+\sum_{j=1}^{N}\beta_{t,j}|\hat{ \Delta}_{t,j}^{\mathrm{clip}_{2}}(x,\tilde{x})+\zeta_{t}(x,\tilde{x})|,\]

where \(a^{\mathrm{clip}_{2}}:=\min\{\max\{a,-2\},2\}\) denotes the value of \(a\) that is clipped to the interval \([-2,2]\) and

\[\alpha_{t}:=5\sqrt{\frac{d}{T_{t}}\ln\frac{2}{\delta_{v,T_{t}}}},\ \xi_{t}:=25\sqrt{2}\frac{NL_{\max}}{T_{t}}\ln\frac{2}{\delta_{m,T_{t}}},\] \[\beta_{t,j}:=\min\left\{\frac{5}{2}\sqrt{\frac{2\phi_{t,j}L_{\max }}{T_{t}}}\ln\frac{2}{\delta_{d,T_{t}}},\ 1\right\},\] \[\phi_{t,j}:=\min\left\{4\max\left\{\hat{p}_{t,j},\frac{25}{4} \frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\right\},\,\frac{1}{4} \right\},\] \[\delta_{v,T_{t}}=\frac{\delta}{15KT_{t}^{3}},\,\delta_{m,T_{t}}= \frac{\delta}{15KT_{t}^{3}},\,\delta_{d,T_{t}}=\frac{\delta}{15NT_{t}^{3}}.\]

\(\zeta_{t}(x,\tilde{x})\) minimizes the last summation. In the final theoretical upper bound on the sample complexity, we take \(\zeta_{t}(x,\tilde{x})=\varepsilon\) for simplicity. In the experiment, we utilize

\[\zeta_{t}(x,\tilde{x})=\operatorname*{arg\,min}_{\zeta_{t}(x,\tilde{x})\in \mathbb{R}}\sum_{j=1}^{N}\beta_{t,j}(\hat{\Delta}_{t,j}(x,\tilde{x})+\zeta_{t} (x,\tilde{x}))^{2}=-\frac{\sum_{j=1}^{N}\beta_{t,j}\hat{\Delta}_{t,j}(x,\tilde {x})}{\sum_{j=1}^{N}\beta_{t,j}}\]

for a simple and effective analytic expression in the experiment.

#### d.2.2 Subroutines of \(\mathrm{PS}\varepsilon\mathrm{BAI}\)

In the LCD subroutine (Algorithm 3), two estimates \(\tilde{\theta}_{1}\) and \(\tilde{\theta}_{2}\) of the latent vectors are independently computed from the first and second halves of the input CD samples (Line 2). LCD only raises an alarm of changepoint (Line 4) when the difference between \(\tilde{\theta}_{1}\) and \(\tilde{\theta}_{2}\) is sufficiently large (Line 3) and indicates a changepoint occurs w.h.p.

The LCA subroutine (Algorithm 4) estimates the latent vector of current context and updates the dictionary \(\mathrm{CA}_{\mathrm{id}}\). Specifically, it **firstly** samples \(w/2\) samples with \(\lambda^{*}\) (Line 2). It **then** checkswhether the current latent context has been visited in previous time steps by scanning through \(\mathrm{CA}_{\mathrm{id}}\) (Line 3). In order to learn if the current context can be aligned with context \(j\), the LCD subroutine is called with the \(w/2\) recent samples and \(\mathrm{CA}_{\mathrm{id}}[j]\) as input:

**(i)** If the current context is aligned with \(\mathrm{CA}_{\mathrm{id}}[j]\) (Line 4), the current latent context is \(j\) w.h.p. Thus the LCA subroutine updates \(\mathrm{CA}_{\mathrm{id}}[j]\) and returns the index \(j\) (Lines 5 to 6), which would be \(\hat{j}_{t}\) in Line 19 of Algorithm 1. Note that in Lines \(10\) and \(11\) of Algorithm 1, all the collected samples will be assigned to context \(\hat{j}_{t}\) (until the next changing alarm) and will be used to estimate \(\theta_{\hat{j}_{t}}^{*}\) and all \(p_{j}\)'s. Therefore, _aligning_ contexts allows PS\(\varepsilon\)BAI to make good use of observation history.

**(ii)** If the current context is not aligned with any observed context, i.e., it has not been visited, \(\mathrm{CA}_{\mathrm{id}}\) gets extended with a new index-samples pair and is returned along with the new index (Lines 9 to 11).

The Piecewise-Stationary \(\varepsilon\)-Best Arm Identification\({}^{+}\) (Ps\(\varepsilon\)BAI\({}^{+}\)) Algorithm

To help understand PS\(\varepsilon\)BAI\({}^{+}\) algorithm, we highlight the differences between PS\(\varepsilon\)BAI and PS\(\varepsilon\)BAI\({}^{+}\), and the differences between subroutines Linear-Context Alignment (LCA) and Linear-Context Alignment\({}^{+}\) (LCA\({}^{+}\)).

```
1:Input: arm set \(\mathcal{X}\), number of latent vectors \(N\), bounds on the segment lengths \(L_{\min}\) and \(L_{\max}\), slackness parameter \(\varepsilon\), confidence parameter \(\delta\), sampling parameter \(\gamma\), window size \(w\) and threshold \(b\).
2:Initialize: Compute the G-optimal allocation \(\lambda^{*}\) and \(\tau^{*}=\frac{38400\ln(80)NL_{\max}}{\varepsilon^{2}}\ln\frac{N^{2}KL_{\max}} {\delta\varepsilon^{2}}\).
3:Set \(\mathrm{CD}_{\mathrm{sample}}=[\;]\), \(\mathrm{CA}_{\mathrm{id}}=\{\;\}\), \(t_{\mathrm{CD}}=+\infty\). Set \(\mathcal{T}_{t,j}=\emptyset\) and initialize \(\mathcal{T}_{t}\), \(T_{t,j}\), \(T_{t}\) with (3.2) for all \(t\leq\tau^{*}\), \(j\in[N]\).
4:Compute \(C_{3}=\sum_{n=1}^{\infty}n^{-3}\) and \(t^{*}=3d\ln(6dKC_{3}/\delta)\).
5:Sample \(w/2\) arms \(\{x_{s}\}_{s=1}^{w/2}\sim\lambda^{*}\) and observe the associated returns \(\{Y_{s,x_{s}}\}_{s=1}^{w/2}\).
6:Set \(t=\frac{w}{2}\), \(t_{\mathrm{CA}}=w/2\), \(\mathrm{CA}_{\mathrm{id}}=\{1:[(x_{s},Y_{s,x_{s}})]_{s=1}^{w/2}\}\), \(\hat{j}_{t}=1\).
7:Set \(\dot{x}_{t}=0\), \(\tilde{\rho}_{t}=2\varepsilon\) and \(\dot{x}_{\varepsilon}=-\infty\). Compute \(\hat{\theta}_{t}\) with (D.1).
8:whileTruc do
9:\(t=t+1\)
10:Sample an arm \(x_{t}\sim\lambda^{*}\) and observe return \(Y_{t,x_{t}}\).
11:Compute \(\tilde{\theta}_{t},\;\dot{x}_{t},\;\tilde{\rho}_{t}=\mathrm{EU}(t,\tilde{ \theta}_{t-1},t^{*},C_{3})\).
12:if \(\dot{x}_{t}^{\top}\tilde{\theta}_{t}-\tilde{\rho}_{t}+\varepsilon\geq\max_{x \neq\dot{x}_{t}}x^{\top}\tilde{\theta}_{t}+\tilde{\rho}_{t}\) then
13:\(\dot{x}_{\varepsilon}=\dot{x}_{t}\).
14:Break
15:endif
16:if\(t>\tau^{*}\) then
17:Continue
18:endif
19:if\(\mod(t-t_{\mathrm{CA}},\gamma)\neq 0\)then
20:Update \(\hat{j}_{t}=\hat{j}_{t-1}\), \(\mathcal{T}_{t,\hat{j}_{t}}=\mathcal{T}_{t-1,\hat{j}_{t}}\cup\{t\},\mathcal{T }_{t,j}=\mathcal{T}_{t-1,j}\) for \(j\neq\hat{j}_{t}\).
21:else
22:\(\mathrm{CD}_{\mathrm{sample}}=\mathrm{CD}_{\mathrm{sample}}+[(x_{t},Y_{t,x_{t }})]\).
23:if\(|\mathrm{CD}_{\mathrm{sample}}|\geq w\)then
24:if\(\mathrm{LCD}(\mathcal{X},w,b,\mathrm{CD}_{\mathrm{sample}}[-w:])\)then
25:\(\mathrm{CD}_{\mathrm{sample}}=[\;]\).
26:\(t=t+\frac{w}{2},t_{\mathrm{CA}}=t,t_{\mathrm{CD}}=+\infty\).
27:\(\hat{j}_{t},\mathrm{CA}_{\mathrm{id}}=\mathrm{LCA}^{+}(\mathcal{X},w,b, \mathrm{CA}_{\mathrm{id}})\)
28:if\(\hat{j}_{t}=N+1\)thenbreak
29: Revert \(\mathcal{T}_{t,j}=\mathcal{T}_{t-\frac{w(\gamma+1)}{2},j}\) for all \(j\in[N]\).
30:endif
31:endif
32:endif
33:if\(\dot{x}_{\varepsilon}\neq-\infty\) then
34:Break
35:endif
36: Update the empirical estimates by (3.2) and (3.3).
37:ifcondition (3.4) is met and \(t_{\mathrm{CD}}=+\infty\)then
38: Record \(\dot{x}_{\varepsilon}=\arg\max_{x\in\mathcal{X}}x^{\top}\hat{\Theta}_{t}\hat{ \mathbf{p}}_{t}\).
39:\(t_{\mathrm{CD}}=|\mathrm{CD}_{\mathrm{sample}}|\).
40:elseif\(t_{\mathrm{CD}}=|\mathrm{CD}_{\mathrm{sample}}|-\frac{w}{2}\)then
41:\(\dot{x}_{\varepsilon}=\dot{x}_{\varepsilon}\)
42:Break
43:endif
44:endwhile
45:Recommend \(\dot{x}_{\varepsilon}=\dot{x}_{\varepsilon}\). ```

**Algorithm 5** Piecewise-Stationary \(\varepsilon\)-Best Arm Identification\({}^{+}\) (PS\(\varepsilon\)BAI\({}^{+}\))

The Piecewise-Stationary \(\varepsilon\)-Best Arm Identification\({}^{+}\) (Ps\(\varepsilon\)BAI\({}^{+}\)) Algorithm

To help understand PS\(\varepsilon\)BAI\({}^{+}\) algorithm, we highlight the differences between PS\(\varepsilon\)BAI and PS\(\varepsilon\)BAI\({}^{+}\), and the differences between subroutines Linear-Context Alignment (LCA) and Linear-Context Alignment\({}^{+}\) (LCA\({}^{+}\)).

```
1:Input: arm set \(\mathcal{X}\), number of latent vectors \(N\), bounds on the segment lengths \(L_{\min}\) and \(L_{\max}\), slackness parameter \(\varepsilon\), confidence parameter \(\delta\), sampling parameter \(\gamma\), window size \(w\) and threshold \(b\).
2:Initialize: Compute the G-optimal allocation \(\lambda^{*}\) and \(\tau^{*}=\frac{38400\ln(80)NL_{\max}}{\varepsilon^{2}}\ln\frac{N^{2}KL_{\max}} {\delta\varepsilon^{2}}\).
3:Set \(\mathrm{CD}_{\mathrm{sample}}=[\;]\), \(\mathrm{CA}_{\mathrm{id}}=\{\;\}\), \(t_{\mathrm{CD}}=+\infty\). Set \(\mathcal{T}_{t,j}=\emptyset\) and initialize \(\mathcal{T}_{t}\), \(T_{t,j}\), \(T_{t}\) with (3.2) for all \(t\leq\tau^{*}\), \(j\in[N]\).
4:Compute \(C_{3}=\sum_{n=1}^{\infty}n^{-3}\) and \(t^{*}=3d\ln(6dKC_{3}/\delta)\).
5:Sample \(w/2\) arms \(\{x_{s}\}_{s=1}^{w/2}\sim\lambda^{*}\) and observe the associated returns \(\{Y_{s,x_{s}}\}_{s=1}^{```
1:Input: time step \(t\), vector \(\tilde{\theta}_{t-1}\), threshold \(t^{*}\) and constant \(C_{3}\).
2:Compute \(\tilde{\theta}_{t}=\frac{1}{t}\left[(t-1)\tilde{\theta}_{t-1}+A(\lambda^{*})^{-1 }x_{t}Y_{s,x_{t}}\right],\;\dot{x}_{t}=0,\;\tilde{\rho}_{t}=2\varepsilon\).
3:if\(t\geq t^{*}\)then
4: Compute \(\dot{x}_{t}=\underset{x\in\mathcal{X}}{\arg\max}\,x^{\top}\tilde{\theta}_{t}, \;\tilde{\rho}_{t}=\sqrt{\frac{8L_{\max}}{t}\ln\frac{4KC_{3}t^{3}}{\delta}}+5 \sqrt{\frac{d}{t}\ln\frac{4KC_{3}t^{3}}{\delta}}\).
5:endif
6:Return\(\tilde{\theta}_{t},\;\dot{x}_{t},\;\tilde{\rho}_{t}\). ```

**Algorithm 6** Estimate Update (EU)

```
1:Input: arm set \(\mathcal{X}\), detection window \(w\), threshold \(b\), context ids \(\mathrm{CA}_{\mathrm{id}}\), time step \(t\), vector \(\tilde{\theta}_{t}\), threshold \(t^{*}\) and constant \(C_{3}\).
2:Set \(s=0,\dot{x}_{\varepsilon}=-\infty\).
3:for\(s\leq w/2\)do
4:\(s=s+1,t=t+1\).
5: Sample an arm \(\dot{x}_{s}\sim\lambda^{*}\) and observe return \(Y_{s,\dot{x}_{s}}\).
6: Set \((x_{t},Y_{\dot{t},x_{s}})=(\ddot{x}_{s},Y_{s,\dot{x}_{s}})\).
7: Compute \(\tilde{\theta}_{t},\;\dot{x}_{t},\;\tilde{\rho}_{t}=\text{EU}(t,\tilde{\theta} _{t-1},t^{*},C_{3})\).
8:if\(\dot{x}_{t}^{\top}\tilde{\theta}_{t}-\tilde{\rho}_{t}+\varepsilon\geq\max_{x \neq\dot{x}_{t},\;x^{\top}\tilde{\theta}_{t}+\tilde{\rho}_{t}}\)then
9:\(\dot{x}_{\varepsilon}=\dot{x}_{t}\), \(\mathrm{index}=\mathrm{len}(\mathrm{CA}_{\mathrm{id}})+1\).
10:Return\(\mathrm{index},\mathrm{CA}_{\mathrm{id}},\dot{x}_{\varepsilon},\tilde{ \theta}_{t}\).
11:endif
12:endfor
13:for\(j\in\mathrm{CA}_{\mathrm{id}}\)do
14:if not \(\mathrm{LCD}(w,b,[(\ddot{x}_{s},Y_{s,\dot{x}_{s}})]_{s=1}^{\frac{w}{2}}, \mathrm{CA}_{\mathrm{id}}[j])\) then
15:\(\mathrm{CA}_{\mathrm{id}}[j]=[(\ddot{x}_{s},Y_{s,\dot{x}_{s}})]_{s=1}^{\frac{w}{ 2}}\).
16:Return\(j,\mathrm{CA}_{\mathrm{id}}\).
17:endif
18:endfor
19:\(\mathrm{index}=\mathrm{len}(\mathrm{CA}_{\mathrm{id}})+1\).
20:\(\mathrm{CA}_{\mathrm{id}}[\mathrm{index}]=[(\ddot{x}_{s},Y_{s,\dot{x}_{s}})]_{s=1}^ {\frac{w}{2}}\).
21:Return index, \(\mathrm{CA}_{\mathrm{id}},\dot{x}_{\varepsilon},\tilde{\theta}_{t}\). ```

**Algorithm 7** Linear-Context Alignment\({}^{+}\) (LCA\({}^{+}\))

### Computational Complexity of PS\(\varepsilon\)BAI

We provide analysis for the computational complexity of PS\(\varepsilon\)BAI in this subsection.

We consider the number of these operations: arithmetic (addition and multiplication) operations, logic operations and comparison operations and we also regard \(\ln(\cdot)\), \(\sqrt{\cdot}\) and sampling from a distribution as one step of operation.

We decompose the main loop of Algorithm 1 as follows, where the lines with \(O(1)\) operations are omitted:

* Exploration phase (Lines 8 to 11): \(O(1)\).
* Change Detection phase (Lines 12 to 16):
* The \(LCD\) subroutine in Line 16 needs \(O(wd^{2}+Kd)\) operations.
* Context Alignment phase (Lines 17 to 21):
* The \(LCA\) subroutine in Line 19 needs \(O((wd^{2}+Kd)N)\) operations, as the \(LCD\) subroutine will be invoked \(N\) times in the worst case in Line 4 of \(LCA\).
* The reversion procedure in Line 21 needs \(O(\gamma wd)\) operations.
* The updating procedure and the stopping rule checking (Lines 25 to 32):
* Updating \(\hat{\theta}_{t,j}\) needs \(O(d^{2})\) operations, as we need to incorporate the latest sample into the estimate.
* Updating \(\hat{p}_{t,j},j\in[N]\) requires \(N\) operations.
* Updating the confidence radius and the empirical best arm need \(O(KN)\) operations.
* The stopping condition in Equation (3.4) requires \(O(K)\) operations.

We remark that some intermediate results can be stored to avoid repeated computations and we believe the algorithm is efficient overall. In particular, since the reward structure is linear, there are \(K\) arms, and \(N\) contexts, \(O(d^{2})\), \(O(K)\), and \(O(N)\) operations probably cannot be be avoided.

From the above analysis, in the decreasing order of the number of operations:

* The Change Detection phase requires the most budget as it will be invoked every \(\gamma\) time steps.
* The Context Alignment phase requires the second many operations. While it requires many operations when it is implemented, it will not be called during a stationary segment.
* The updating procedure uses small portion of the operations, as \(w\) is usually much greater than \(K\) and \(N\).
* The exploration phase demands constant operations in each loop.

## Appendix E Auxiliary results

**Lemma E.1**.: _Let \(X_{s}\) be the arm drawn with the G-optimal allocation \(\lambda^{*}\) at time step \(s\) and \(Y_{s,x_{s}}=x_{s}^{\top}\theta_{j_{s}}^{*}+\eta_{s}\) be the corresponding return with \(\mathbb{E}\eta_{s}=0\), \(|x_{s}^{\top}\theta_{j_{s}}^{*}|\leq 1\) and \(|\eta_{s}|\leq 1\). Then we have_

\[\mathbb{P}\left[\frac{1}{n}\left|\sum_{s=1}^{n}x^{\top}A(\lambda^{*})^{-1}x_{ s}Y_{s,x_{s}}-x^{\top}\theta_{j_{s}}^{*}\right|\geq\epsilon\right]\leq\delta\]

_for all \(\epsilon\geq\frac{d}{n}\ln\frac{2}{\delta}+\sqrt{\left(\frac{d}{n}\ln\frac{2}{ \delta}\right)^{2}+\frac{4d}{n}\ln\frac{2}{\delta}}\). In addition, if \(n\geq\frac{d}{4}\ln\frac{2}{\delta}\), we have_

\[\mathbb{P}\left[\frac{1}{n}\left|\sum_{s=1}^{n}x^{\top}A(\lambda^{*})^{-1}x_{ s}Y_{s,x_{s}}-x^{\top}\theta_{j_{s}}^{*}\right|\geq 5\sqrt{\frac{d}{n}\ln\frac{2}{ \delta}}\;\right]\leq\delta\]

Proof.: Note that the arms are selected according to the G-optimal design, and thus \(\mathbb{E}_{x\sim\lambda^{*}}[xx^{\top}]=A(\lambda^{*})\). Therefore, for all \(s\in[n]\),

\[\mathbb{E}\left[x^{\top}A(\lambda^{*})^{-1}x_{s}Y_{s,x_{s}}-x^{\top}\theta_{j _{s}}^{*}\right]=0\] (E.1)

and

\[\left|x^{\top}A(\lambda^{*})^{-1}x_{s}Y_{s,x_{s}}-x^{\top}\theta_{ j_{s}}^{*}\right|\] (E.2) \[\leq\left|x^{\top}A(\lambda^{*})^{-1}x_{s}x_{s}^{\top}\theta_{j_{ s}}^{*}\right|+\left|x^{\top}A(\lambda^{*})^{-1}x_{s}\eta_{s}\right|+1\] \[\leq\left|x^{\top}A(\lambda^{*})^{-1}x_{s}\big{|}\big{|}x_{s}^{ \top}\theta_{j_{s}}^{*}\big{|}+\left|x^{\top}A(\lambda^{*})^{-1}x_{s}\big{|} \big{|}\eta_{s}\right|+1\] \[\leq 2\big{|}x^{\top}A(\lambda^{*})^{-1}x_{s}\big{|}+1\] \[\leq 2\|x\|_{A(\lambda^{*})^{-1}}\|x_{s}\|_{A(\lambda^{*})^{-1}}+1\] \[\leq 3d\]

where we make use of the property of the G-optimal allocation in the last inequality

\[\|x\|_{A(\lambda^{*})^{-1}}^{2}\leq d,\;\forall x\in\mathcal{X}.\] (E.3)

Additionally,

\[\mathbb{E}\left[\left(x^{\top}A(\lambda^{*})^{-1}x_{s}Y_{s,x_{s}} \right)^{2}\right]\] (E.4) \[=\mathbb{E}\left[\left(x^{\top}A(\lambda^{*})^{-1}x_{s}(x_{s}^{ \top}\theta_{j_{s}}^{*}+\eta_{s})\right)^{2}\right]\] \[=\mathbb{E}\left[\left(x^{\top}A(\lambda^{*})^{-1}x_{s}x_{s}^{ \top}\theta_{j_{s}}^{*}\right)^{2}\right]+\mathbb{E}\left[(x^{\top}A(\lambda^{* })^{-1}x_{s}\eta_{s})^{2}\right]\] \[\qquad\qquad+2\mathbb{E}\left[x^{\top}A(\lambda^{*})^{-1}x_{s}x_{ s}^{\top}\theta_{j_{s}}^{*}\cdot x^{\top}A(\lambda^{*})^{-1}x_{s}\eta_{s}\right]\] \[\stackrel{{(a)}}{{=}}\mathbb{E}\left[\left(x^{\top}A( \lambda^{*})^{-1}x_{s}\right)^{2}\left(x_{s}^{\top}\theta_{j_{s}}^{*}\right)^{2 }\right]+\mathbb{E}\left[\eta_{s}^{2}\left(x^{\top}A(\lambda^{*})^{-1}x_{s} \right)^{2}\right]\]\[\begin{split}&\overset{(b)}{\leq}2\mathbb{E}\left[\left(x^{\top}A( \lambda^{*})^{-1}x_{s}\right)^{2}\right]\\ &\overset{(c)}{=}2\,x^{\top}A(\lambda^{*})^{-1}x\\ &\overset{(d)}{\leq}2d\end{split}\]

where we make use of the fact that \(\eta_{t}\) is zero-mean and is independent of other random variables in \((a)\); \(|x_{s}^{\top}\theta_{j_{s}}^{*}|\leq 1\) and \(\mathbb{P}\left[\eta_{s}^{2}\leq 1\right]=1\) in \((b)\); \(x_{s}\sim\lambda^{*}\) in \((c)\); and the property of the G-optimal allocation (E.3) in \((d)\).

According to the Bernstein's inequality with (E.1), (E.2) and (E.4),

\[\begin{split}&\mathbb{P}\left[\frac{1}{n}\bigg{|}\sum_{s=1}^{n}x^{ \top}A(\lambda^{*})^{-1}x_{s}Y_{s,x_{s}}-x^{\top}\theta_{j_{s}}^{*}\right|\geq \epsilon\right]\\ &\leq 2\exp\left(-\frac{\frac{1}{2}(n\epsilon)^{2}}{n\cdot 2d+dn \epsilon}\right)\\ &=2\exp\left(-\frac{n\epsilon^{2}}{4d+2d\epsilon}\right).\end{split}\]

In order to upper bound the error probability by \(\delta\), we need

\[\begin{split}& 2\exp\left(-\frac{n\epsilon^{2}}{4d+2d\epsilon} \right)\leq\delta\\ \Rightarrow&\epsilon\geq\frac{d}{n}\ln\frac{2}{ \delta}+\sqrt{\left(\frac{d}{n}\ln\frac{2}{\delta}\right)^{2}+\frac{4d}{n}\ln \frac{2}{\delta}}.\end{split}\]

In addition, if \(n\geq\frac{d}{4}\ln\frac{2}{\delta}\), we have

\[5\sqrt{\frac{d}{n}\ln\frac{2}{\delta}}=\frac{5}{2}\max\left\{\frac{d}{n}\ln \frac{2}{\delta},\sqrt{\frac{4d}{n}\ln\frac{2}{\delta}}\right\}\geq\frac{d}{n} \ln\frac{2}{\delta}+\sqrt{\left(\frac{d}{n}\ln\frac{2}{\delta}\right)^{2}+ \frac{4d}{n}\ln\frac{2}{\delta}}.\]

This finishes the proof. 

## Appendix F Analysis of N\(\varepsilon\)Bai

To analyze the theoretical performance of N\(\varepsilon\)BAI, we first show that it can identify an \(\varepsilon\)-optimal arm with probability \(1-\delta\) and derive a high-probability upper bound on its stopping time in Lemma F.1.

**Lemma F.1** (High-probability upper bound of N\(\varepsilon\)Bai).: _With probability \(1-\delta\), the N\(\varepsilon\)BAI algorithm identifies an \(\varepsilon\)-optimal arm after at most_

\[\tilde{O}\left(\frac{L_{\max}+d}{\left(\varepsilon+\Delta_{\min}\right)^{2}} \ln\frac{1}{\delta}\right)\]

_time steps, where \(\Delta_{\min}=\min\limits_{i\neq i^{*}}\Delta(x^{*}-x_{i})\)._

Next, we prove that after a sufficiently large number of time steps, the probability that N\(\varepsilon\)BAI does not terminate is small in Lemma F.2.

**Lemma F.2**.: _Let_

\[T_{0}=\frac{768(8L_{\max}+25d)}{\left(\varepsilon+\Delta_{\min}\right)^{2}} \ln\frac{768KC_{3}(8L_{\max}+25d)}{\left(\varepsilon+\Delta_{\min}\right)^{2} \delta}\]

_with \(C_{3}=\sum_{j=1}^{\infty}n^{-3}\). For \(t\geq T_{0}\), the probability that N\(\varepsilon\)BAI does not terminate before \(t\) time steps is \(\frac{\delta}{(\alpha-1)C_{3}(t/2)^{2}}\)._

Lastly, we apply Lemmas F.1 and F.2 to prove Proposition 3.1.

**Proposition 3.1**.: _Let \(\Delta_{\min}=\min_{x\neq x^{*}}\Delta(x^{*},x)\),_

\[T_{V}^{\rm N}=\frac{d}{(\varepsilon+\Delta_{\min})^{2}}\ln\frac{1}{\delta} \qquad\text{and}\qquad T_{D}^{\rm N}=\frac{L_{\max}}{(\varepsilon+\Delta_{\min} )^{2}}\ln\frac{1}{\delta}.\]

_The \({\rm N}\varepsilon\text{BAI}\) algorithm is \((\varepsilon,\delta)\)-PAC and its expected sample complexity is \(\tilde{O}(T_{V}^{\rm N}+T_{D}^{\rm N})\)._

The detailed analysis is presented as below.

### Detailed analysis of \({\rm N}\varepsilon\text{BAI}\)

_Proof of Lemma F.1._ The result is to be proven with the following procedures.

**First step**: Prove \(\left|x^{\top}\mathbb{E}_{\theta\sim P_{\theta}}\theta-x^{\top}\tilde{\theta }_{t}\right|\) can be bounded with high probability.

Let \(\bar{\theta}_{t}=\frac{1}{t}\sum_{s=1}^{t}\theta_{j_{s}}^{*}\). (i) For all \(\varepsilon>0\), we have,

\[\mathbb{P}\left[\ \left|x^{\top}\mathbb{E}_{\theta\sim P_{\theta}} \theta_{t}-x^{\top}\bar{\theta}\right|>\varepsilon\right]=\mathbb{P}\left[\ \left|tx^{\top}\mathbb{E}_{\theta\sim P_{\theta}}\theta-x^{\top}\left(\sum_{ l=1}^{N_{t}}L_{l}\theta^{*}j_{c_{l}}\right)\right|>t\varepsilon\right]\] \[=\mathbb{P}\left[\ \left|\sum_{l=1}^{N_{t}}L_{l}\left(x^{\top} \mathbb{E}_{\theta\sim P_{\theta}}\theta-L_{l}x^{\top}\theta^{*}j_{c_{l}} \right)\right|>t\varepsilon\right]\overset{(a)}{\leq}2\exp\left(-\frac{t^{2} \varepsilon^{2}}{2\sum_{l=1}^{N_{t}}(2L_{l})^{2}}\right)\] \[\overset{(b)}{\leq}2\exp\left(-\frac{t\varepsilon^{2}}{8L_{\max }}\right).\]

Since \(|x^{\top}\mathbb{E}_{\theta\sim P_{\theta}}\theta|\leq 1\) and \(x^{\top}\theta^{*}j_{c_{l}}|\leq 1\) for all \(l\), we obtain (a) by applying Hoeffding's inequality. We obtain (b) from the fact that \(\sum_{l=1}^{N_{t}}L_{l}=t\) and \(L_{l}\leq L_{\max}\) for all \(l\). In other words, for all \(\delta>0\),

\[\mathbb{P}\left[\ \left|x^{\top}\mathbb{E}_{\theta\sim P_{\theta}}\theta-x^{ \top}\bar{\theta}\right|>\sqrt{\frac{8L_{\max}}{t}\ln\frac{2}{\delta}}\ \right]\leq\delta.\]

(ii) Besides, according to Lemma E.1, if \(t\geq\frac{d}{4}\ln\frac{2}{\delta}\), we have

\[\mathbb{P}\left[\left|x^{\top}\tilde{\theta}_{t}-x^{\top}\bar{\theta}_{t} \right|\geq 5\sqrt{\frac{d}{t}\ln\frac{2}{\delta}}\ \right]=\mathbb{P}\left[\frac{1}{t}\left|\sum_{s=1}^{t}x^{\top}A(\lambda^{*} )^{-1}x_{s}Y_{s,x_{s}}-x^{\top}\theta_{j_{s}}^{*}\right|\geq 5\sqrt{\frac{d}{t}\ln \frac{2}{\delta}}\ \right]\leq\delta.\]

(iii) For all \(t>0\), all \(x\in\mathcal{X}\), since

\[\left|x^{\top}\mathbb{E}_{\theta\sim P_{\theta}}\theta-x^{\top}\tilde{\theta }_{t}\right|\leq\left|x^{\top}\mathbb{E}_{\theta\sim P_{\theta}}\theta-x^{ \top}\bar{\theta}\right|+\left|x^{\top}\tilde{\theta}_{t}-x^{\top}\bar{ \theta}_{t}\right|,\]

we have

\[\mathbb{P}\left[\left|x^{\top}\mathbb{E}_{\theta\sim P_{\theta}}\theta-x^{ \top}\bar{\theta}_{t}\right|>\tilde{\rho}_{t}(\alpha)\right]\leq\frac{\delta} {KC_{\alpha}t^{\alpha}}\quad\text{when}\quad t\geq\frac{d}{4}\ln\frac{4KC_{ \alpha}t^{\alpha}}{\delta},\]

where

\[\tilde{\rho}_{t}(\alpha)=\sqrt{\frac{8L_{\max}}{t}\ln\frac{4KC_{\alpha}t^{ \alpha}}{\delta}}+5\sqrt{\frac{d}{t}\ln\frac{4KC_{\alpha}t^{\alpha}}{\delta}},\quad C_{\alpha}=\sum_{n=1}^{\infty}n^{-\alpha},\quad\alpha>2.\]

For simplicity, we set \(\alpha=3\) and write \(\tilde{\rho}_{t}(3)\) as \(\tilde{\rho}_{t}\) in the following analysis. We now show that \(t\geq\frac{d}{4}\ln\frac{4KC_{\alpha}t^{\alpha}}{\delta}\) holds when \(t\geq 3d\ln\frac{6dKC_{\alpha}}{\delta}\) with the following lemma (the proof of which is presented by the end of Appendix F.1).

**Lemma F.3**.: _Let \(a,b,c>0\) and \(ac\geq 1/2\), then_

\[t\geq\max\{2a\ln b,\,4ac\ln(2ac)\}\ \Rightarrow\ t\geq a\ln(b^{c}).\]

With

\[a=\frac{d}{4},\quad b=\frac{4KC_{\alpha}}{\delta}=\frac{4KC_{3}}{\delta}, \quad c=\alpha=3,\]Lemma F.3 implies that

\[t\geq 4ac\ln(2abc)=3d\ln\frac{6dKC_{3}}{\delta}\;\Rightarrow\;t\geq\max\{2a\ln b,\,4ac\ln(2ac)\}\;\Rightarrow\;t\geq a\ln(bt^{c}).\]

Define event \(\tilde{E}_{t}=\bigcap\limits_{x\in\mathcal{X}}\left\{\left|x^{\top}\mathbb{E}_ {\theta\sim P_{9}}\theta-x^{\top}\tilde{\theta}_{t}\right|\leq\tilde{\rho}_{t} (\alpha)\right\}\) for \(t\geq t^{*}\) and \(\tilde{E}=\bigcap\limits_{t\geq t^{*}}\tilde{E}_{t}\). We have

\[\mathbb{P}\left[\tilde{E}_{t}^{\star}\right]\leq\sum\limits_{x\in\mathcal{X}} \frac{\delta}{KC_{\alpha}t^{\alpha}}=\frac{\delta}{C_{\alpha}t^{\alpha}},\quad \mathbb{P}\left[\tilde{E}^{\star}\right]\leq\sum\limits_{t=t^{*}}^{\infty} \mathbb{P}\left[\tilde{E}_{t}^{\star}\right]\leq\sum\limits_{t=1}^{\infty} \frac{\delta}{C_{\alpha}t^{\alpha}}=\delta.\]

We assume \(\tilde{E}\) holds in the second and third steps in this proof.

**Second step**: Prove N\(\varepsilon\)BAI recommends an \(\varepsilon\)-optimal arm when it stops.

If the algorithm terminates and returns \(\dot{x}_{\varepsilon}\neq x^{*}\), we have

\[\dot{x}_{\varepsilon}^{\top}\tilde{\theta}_{t}-\tilde{\rho}_{t}+\varepsilon \geq\max\limits_{x\neq\dot{x}_{\varepsilon}}x^{\top}\tilde{\theta}_{t}+\tilde {\rho}_{t}.\]

Since

\[\dot{x}_{\varepsilon}^{\top}\mathbb{E}_{\theta\sim P_{9}}\theta+\varepsilon \geq\dot{x}_{\varepsilon}^{\top}\tilde{\theta}_{t}-\tilde{\rho}_{t}+ \varepsilon\quad\text{and}\quad\max\limits_{x\neq\dot{x}_{\varepsilon}}x^{ \top}\tilde{\theta}_{t}+\tilde{\rho}_{t}\geq\max\limits_{x\neq\dot{x}_{ \varepsilon}}x^{\top}\mathbb{E}_{\theta\sim P_{9}}\theta\geq{x^{*}}^{\top} \mathbb{E}_{\theta\sim P_{9}}\theta,\]

we have

\[\dot{x}_{\varepsilon}^{\top}\mathbb{E}_{\theta\sim P_{9}}\theta+\varepsilon \geq{x^{*}}^{\top}\mathbb{E}_{\theta\sim P_{9}}\theta,\]

implying that \(\dot{x}_{\varepsilon}\in\mathcal{X}_{\varepsilon}\). Hence, we always have \(\dot{x}_{\varepsilon}\in\mathcal{X}_{\varepsilon}\).

**Third step**: Derive the stopping time of N\(\varepsilon\)BAI.

(i) Let \(x_{(2)}=\arg\max_{x\neq x^{*}}x^{\top}\mathbb{E}_{\theta\sim P_{9}}\theta\) and \(\Delta_{\min}=\min_{x\neq x^{*}}\Delta(x^{*}-x)=(x^{*}-x_{(2)})^{\top}\mathbb{ E}_{\theta\sim P_{9}}\theta\). We apply the following lemma to show that N\(\varepsilon\)BAI stops when \(\tilde{\rho}_{t}\) is sufficiently small.

**Lemma F.4** ([30, Lemma 3]).: _Denote by \(\hat{i}\) the index of the item with empirical mean is \(i\)-th largest: i.e., \(\hat{w}(\hat{1})\geq\ldots\geq\hat{w}(\hat{L})\). Assume that the empirical means of the arms are controlled by \(\varepsilon:\) i.e., \(\forall i,|\hat{w}(i)-w(i)|<\varepsilon\). Then,_

\[\forall i,w(i)-\varepsilon\leq\hat{w}(\hat{i})\leq w(i)+\varepsilon.\]

Lemma F.4 implies that

\[\dot{x}_{t}^{\top}\tilde{\theta}_{t}-\tilde{\rho}_{t}+\varepsilon \geq{x^{*}}^{\top}\mathbb{E}_{\theta\sim P_{9}}\theta-2\tilde{\rho}_{t}+ \varepsilon=x_{(2)}^{\top}\mathbb{E}_{\theta\sim P_{9}}\theta-2\tilde{\rho}_ {t}+\varepsilon+\Delta_{\min}\quad\text{and}\] \[\max\limits_{x\neq\dot{x}_{t}}x^{\top}\tilde{\theta}_{t}+\tilde {\rho}_{t}\leq x_{(2)}^{\top}\mathbb{E}_{\theta\sim P_{9}}\theta+2\tilde{ \rho}_{t}.\]

When \(\tilde{\rho}_{t}\leq(\varepsilon+\Delta_{\min})/4\), we have

\[\dot{x}_{t}^{\top}\tilde{\theta}_{t}-\tilde{\rho}_{t}+\varepsilon\geq x_{(2 )}^{\top}\tilde{\theta}_{t}+\frac{\varepsilon+\Delta_{\min}}{2}\geq x_{(2)}^{ \top}\tilde{\theta}_{t}+2\tilde{\rho}_{t}\geq\max\limits_{x\neq\dot{x}_{t}}x^ {\top}\tilde{\theta}_{t}+\tilde{\rho}_{t},\]

which will lead to the termination of N\(\varepsilon\)BAI.

(ii) According to the definition of \(\tilde{\rho}_{t}\), we have

\[\tilde{\rho}_{t}(\alpha)\leq(\varepsilon+\Delta_{\min})/4\] \[\Leftrightarrow \sqrt{\frac{8L_{\max}}{t}\ln\frac{4KC_{\alpha}t^{\alpha}}{\delta}} +5\sqrt{\frac{d}{t}\ln\frac{4KC_{\alpha}t^{\alpha}}{\delta}}\leq(\varepsilon+ \Delta_{\min})/4\] \[\Leftrightarrow \sqrt{\frac{1}{t}\ln\frac{4KC_{\alpha}t^{\alpha}}{\delta}} \left(\sqrt{8L_{\max}}+5\sqrt{d}\right)\leq(\varepsilon+\Delta_{\min})/4\] \[\Leftrightarrow t\geq\frac{\left(\sqrt{8L_{\max}}+5\sqrt{d}\right)^{2}}{\left( \varepsilon+\Delta_{\min}\right)^{2}/16}\ln\frac{4KC_{\alpha}t^{\alpha}}{\delta}\] \[\Leftarrow t\geq\frac{32(8L_{\max}+25d)}{\left(\varepsilon+ \Delta_{\min}\right)^{2}}\ln\frac{4KC_{\alpha}t^{\alpha}}{\delta}\]\[\Leftarrow\,t\geq\frac{192(8L_{\max}+25d)}{\left(\varepsilon+\Delta_{\min}\right)^ {2}}\ln\frac{768KC_{3}(8L_{\max}+25d)}{\left(\varepsilon+\Delta_{\min}\right)^ {2}\delta}.\]

We apply Lemma F.3 to invert the last line above. With

\[a=\frac{32(8L_{\max}+25d)}{\left(\varepsilon+\Delta_{\min}\right)^{2}},\quad b= \frac{4KC_{\alpha}}{\delta},\quad c=\alpha=3,\]

Lemma F.3 indicates that

\[t\geq 4ac\ln(2abc)=\frac{384(8L_{\max}+25d)}{\left(\varepsilon+ \Delta_{\min}\right)^{2}}\ln\frac{768KC_{3}(8L_{\max}+25d)}{\left(\varepsilon+ \Delta_{\min}\right)^{2}\delta}\] \[\Rightarrow\ t\geq\max\{2a\ln b,\,4ac\ln(2ac)\}\ \Rightarrow\ t\geq a\ln(bt^{c}).\]

**Altogether**, we show that with probability \(1-\delta\), N\(\varepsilon\)BAI identifies an \(\varepsilon\)-optimal arm after at most

\[\frac{384(8L_{\max}+25d)}{\left(\varepsilon+\Delta_{\min}\right)^{2}}\ln \frac{768KC_{3}(8L_{\max}+25d)}{\left(\varepsilon+\Delta_{\min}\right)^{2}\delta}\]

time steps.

Proof of Lemma f.2.: To begin with, let

\[T_{0}=\frac{768(8L_{\max}+25d)}{\left(\varepsilon+\Delta_{\min}\right)^{2}}\ln \frac{768KC_{3}(8L_{\max}+25d)}{\left(\varepsilon+\Delta_{\min}\right)^{2}\delta}\]

For any \(T\geq T_{0}\), let \(\bar{T}=\left\lceil T/2\right\rceil\).

**(I)** If N\(\varepsilon\)BAI terminates within \(\bar{T}\) time steps, there is nothing to prove.

**(II)** Assume N\(\varepsilon\)BAI does not terminates within \(\bar{T}\) time steps. According to the analysis in the proof of Lemma F.1, if N\(\varepsilon\)BAI does not terminate before \(T\) time steps, i.e., the stopping time \(\tau\) satisfies that \(\tau\geq\bar{T}\), then event \(\bigcap\limits_{t=\bar{T}+1}^{T-1}\tilde{E}_{t}\) does not hold. This indicates

\[\mathbb{P}\left[\tau\geq T|\tau\geq\bar{T}\right] \leq\mathbb{P}\left[\bigcup\limits_{t=\bar{T}+1}^{T-1}\tilde{E}_{ t}^{\epsilon}\right]\leq\sum\limits_{t=\bar{T}}^{T-1}\mathbb{P}\left[\tilde{E}_{t}^{ \epsilon}\right]\leq\sum\limits_{t=\bar{T}}^{T-1}\frac{\delta}{C_{\alpha}t^{ \alpha}}\leq\frac{\delta}{C_{\alpha}}\int_{\bar{T}}^{T}t^{-\alpha}\;\mathrm{ d}t\] \[\leq\frac{\delta}{(\alpha-1)C_{\alpha}}\left(\frac{1}{(\bar{T})^ {\alpha-1}}-\frac{1}{T^{\alpha}}\right)\overset{(a)}{\leq}\frac{\delta}{( \alpha-1)C_{\alpha}(T/2)^{\alpha-1}}.\]

(a) results from the fact that \(\bar{T}\geq T/2\).

**Altogether**, for \(T\geq T_{0}\), the probability N\(\varepsilon\)BAI does not terminate before \(T\) time steps is \(\frac{\delta}{(\alpha-1)C_{\alpha}(T/2)^{\alpha-1}}\).

Proof of Proposition 3.1.: First, Tonelli's Theorem implies that

\[\mathbb{E}[\tau]=\mathbb{E}\left[\int_{0}^{\tau}1\;\mathrm{d}x\right]=\mathbb{ E}\left[\int_{0}^{+\infty}\mathbb{I}(\tau>x)\;\mathrm{d}x\right]=\int_{0}^{+ \infty}\mathbb{E}\left[\mathbb{I}(\tau>x)\right]\;\mathrm{d}x=\int_{0}^{+ \infty}\mathbb{P}(\tau>x)\;\mathrm{d}x.\]

Next, we apply Lemma F.2 to show

\[\mathbb{E}\tau \leq T_{0}+\mathbb{E}[\tau|\tau\geq T_{0}+1]\cdot\mathbb{P}[\tau \geq T_{0}+1]\leq T_{0}+\int_{T_{0}}^{+\infty}\mathbb{P}(\tau\geq x)\; \mathrm{d}x\] \[\leq T_{0}+\int_{T_{0}}^{+\infty}\frac{\delta}{(\alpha-1)C_{\alpha }(x/2)^{\alpha-1}}\;\mathrm{d}x=T_{0}+\frac{\delta}{(\alpha-1)(\alpha-2)(T_{0} /2)^{\alpha-2}}.\] (F.1)

Besides, Lemma F.1 indicates that N\(\varepsilon\)BAI can identify an \(\varepsilon\)-optimal arm with probability \(1-\delta\)Proof of Lemma 13.: For \(x>0\), let

\[f(x)=x-a\ln(bx^{c})=x-a\ln b-ac\ln x=x\left(1-\frac{a\ln b}{x}-\frac{ac\ln x}{x} \right).\]

Since

\[f(x)\geq 0\ \Leftarrow\ \left\{\begin{array}{l}\frac{a\ln b}{x} \leq\frac{1}{2}\\ \frac{ac\ln x}{x}\leq\frac{1}{2}\end{array}\right.\ \ \Leftrightarrow\ \left\{ \begin{array}{l}x\geq 2a\ln b\\ x\geq 2ac\ln x\end{array}\right..\]

Let \(d=2ac\), \(x=d\ln(dy)\), then

\[x\geq 2ac\ln x=d\ln x\ \Leftrightarrow\ d\ln(dy)\geq d\ln(d\ln(dy))\ \Leftrightarrow\ \ln(dy)\geq\ln(d\ln(dy))\ \Leftrightarrow\ y\geq\ln(dy).\]

Since \(z^{0.4}\geq\ln z\) for all \(z\geq 1\), we have \(\ln(dy)\leq(dy)^{0.4}\leq\sqrt{dy}\) and

\[y\geq\ln(dy)\ \Leftarrow\ y\geq\sqrt{dy}\ \Leftarrow\ y\geq d\]

when \(yd\geq 1\). Hence, when \(ac\geq 1/2\), \(y\geq d=2ac\geq 1\), we have \(y\geq\ln(dy)\). Furthermore, for \(x\) such that \(x\geq\max\{2a\ln b,\,4ac\ln(2ac)\}\), we have \(f(x)\geq 0\).

## Appendix G Proof Outline of Theorem 3.2

A proof outline of Theorem 3.2 is provided in this section. It consists of three steps:

**Step 1:** PS\(\varepsilon\)BAI (Algorithm 1) depends on the success of change detection and context alignment (Algorithm 3 and 4). We firstly upper bound the failure probability of these two subroutines via Lemma 11, Lemma 12, Lemma 13 and summarized in Lemma 14. More details about these two subroutines are provided in Appendix D.2.2 and the proof of the Lemmas are postponed to Appendix H.

**Step 2:** Subsequently, conditioned on their success, we provide a theoretical guarantee for the choice of the confidence radius \(\rho_{t}(x,\tilde{x})\) for \(\Delta(x,\tilde{x})\) at time step \(t\) in Lemma 15. The proof is detailed in Appendix I.

**Step 3:** Lastly, utilizing the above elements, we provide a sufficient condition for the stopping rule, and upper bound the number of time steps in Exp phases \(T_{\tau}\) via Lemma 16 whose proof is presented in Appendix J. As the total number of time steps \(\tau\) is upper bounded by a constant multiple of \(T_{\tau}\), the high-probability upper bound on the stopping time \(\tau\) is obtained. This finishes the proof of Theorem 3.2 (please refer to Appendix J).

**Step 1:** We borrow the terminology in hypothesis testing to define the errors. Let the null hypothesis be: _the algorithm has undergone a changepoint within the last \(w\) CD samples_. For Algorithm 3, we will characterize the type I error: _the algorithm has experienced a changepoint within the last \(w\) CD samples but it fails to raise a changing alarm_, and the type II error: _a changepoint has not occurred but Algorithm 3 raises a changing alarm_. We refer to the event Failed Alarm (FA) and the event False Alarm Error (FAE) as that a type I error occurs and that a type II error occurs, respectively:

\[\mathrm{FA}_{l}:=\{\text{a type I error occurs at changepoint $c_{l}$}\},l\in\mathbb{N},\] \[\mathrm{FAE}_{t}:=\{\text{a type II error occurs time step $t$}\},t\in \mathcal{T}_{\mathrm{FAE}},\] \[\mathrm{FA}:=\bigcup_{\{l:c_{l}\leq\tau\}}\mathrm{FA}_{l}\ \ \ \text{ and }\ \ \ \mathrm{FAE}:=\bigcup_{t\in\mathcal{T}_{\mathrm{FAE}}}\mathrm{FAE}_{t},\]

where \(\mathcal{T}_{\mathrm{FAE}}:=\{t:t\text{ in CD phase},t\leq\tau,[t-w\gamma,t] \cap\mathcal{C}=\emptyset\}\) and \(\tau\) is the stopping time. In term of Algorithm 4, define the event \(\mathrm{MI}_{l}:=\{\text{Algorithm 4 misidentifies }\theta_{j_{t}}^{*}\},\ l\in\mathbb{N}\) and \(\mathrm{MI}:=\bigcup_{\{l:c_{l}\leq\tau\}}\mathrm{MI}_{l}\). Define the good event

\[\mathrm{Good}:=\{\mathrm{FA}^{c}\cap\mathrm{FAE}^{c}\cap\mathrm{MI}^{c}\}.\] (17)

We upper bound the failure probability of Goodin Lemma 11, Lemma 12, Lemma 13 and conclude the results in Lemma 14.

**Lemma G.1**.: _For any \(\delta_{\mathrm{FAE}}\in(0,1)\), with \(b\geq\frac{8d}{3w}\ln\frac{2}{\delta_{\mathrm{FAE}}}+\sqrt{\left(\frac{8d}{3w} \ln\frac{2}{\delta_{\mathrm{FAE}}}\right)^{2}+\frac{24}{w}d\ln\frac{2}{\delta_{ \mathrm{FAE}}}}\), LCD makes no false alarm before the stopping time \(\tau\) with probability at least_

\[\mathbb{P}[\mathrm{FAE}^{c}]\geq 1-\frac{\tau}{\gamma}K\delta_{\mathrm{FAE}}.\]

Lemma G.1 can also be stated as, fix \(b\),

\[\mathbb{P}\left[\mathrm{FAE}^{c}\right]\geq 1-\frac{\tau}{\gamma}2K\exp\left(- \min\left\{\frac{3wb}{20d},\frac{wb^{2}}{150d}\right\}\right),\]

which indicates we can always decrease the error probability by enlarging the window size \(w\).

Assume \(c_{l}\) is observable, i.e., \(\theta^{*}_{j_{c_{l}}}\neq\theta^{*}_{j_{c_{l+1}}}\), and denote \(\hat{c}_{l}\) as the alarm time of \(c_{l}\) from Algorithm 3.

**Lemma G.2**.: _Conditional on \(\mathrm{FAE}^{c}\), for any \(\delta_{\mathrm{FA}}\in(0,1)\), if \(\frac{\Delta_{\varepsilon}-b}{2}\geq\frac{d}{w}\ln\frac{2}{\delta_{\mathrm{FA} }}+\sqrt{\left(\frac{d}{w}\ln\frac{2}{\delta_{\mathrm{FA}}}\right)^{2}+\frac{4 d}{w}\ln\frac{2}{\delta_{\mathrm{FA}}}}\)._

\[\mathbb{P}\left[c_{l}\leq\hat{c}_{l}\leq c_{l}+\frac{w\gamma}{2}\big{|}\hat{c }_{l}\geq c_{l}\right]\geq 1-\delta_{\mathrm{FA}}.\]

_In addition, \(\mathbb{P}\left[\mathrm{FA}\big{|}\mathrm{FAE}^{c}\right]\leq l_{\tau}\delta_ {\mathrm{FA}}\)._

Lemma G.2 guarantees a prompt change alarm will be raised within \(\frac{w\gamma}{2}\) time steps after a changepoint occurs. This also explains why \(\frac{w\gamma}{2}\) samples are abandoned at line \(16\) of Algorithm 1 so that \(\mathcal{T}_{t,j}\) only keeps samples from context \(j\).

**Lemma G.3**.: _Conditional on \(\mathrm{FAE}^{c}\) and \(\mathrm{FA}^{c}\), based on the conditions in Lemma G.1 and Lemma G.2,_

\[\mathbb{P}\left[\mathrm{MI}|\mathrm{FAE}^{c},\mathrm{FA}^{c}\right]\leq l_{ \tau}\left[(N-1)\delta_{\mathrm{FA}}+K\delta_{\mathrm{FAE}}\right].\]

The intuition of Lemma G.3 is simple: change alarm should not be raised when the samples are from the same context and, change alarms should be raised when the samples are from the other \((N-1)\) contexts. The error made by Algorithm 3 and 4 can be concluded as follows

**Lemma G.4**.: _Assume the instance satisfies Assumption 1,_

\[\mathbb{P}\left[\mathrm{Good}\right]\geq 1-\frac{\delta}{2\tau^{*}}\geq 1-\frac{ \delta}{2}.\]

**Step 2:** To give an upper bound on \(T_{\tau}\), we firstly prove that the estimate of \(\Delta(x,\tilde{x})\) at time \(t\) is within distance \(\rho_{t}(x,\tilde{x})\) from the ground truth w.h.p. Define the event \(\mathrm{CI}\) as the estimates of all the mean gaps locate in the high-probability Confidence Interval

\[\mathrm{CI}_{t}:=\left\{\big{|}\hat{\Delta}_{t}(x,\tilde{x})-\Delta(x,\tilde{ x})\big{|}\leq\rho_{t}(x,\tilde{x}),\forall x,\tilde{x}\in\mathcal{X}\right\}\]

and \(\mathrm{CI}:=\bigcap_{t}\mathrm{CI}_{t}\), where \(\rho_{t}\) is defined in (3.3).

**Lemma G.5**.: _If \(T_{t}\geq\frac{2L_{\max}}{9}\ln\frac{2}{\delta_{t,T_{t}}}\),_

\[\mathbb{P}\left[\mathrm{CI}_{t}\big{|}\mathrm{Good}\right]\geq 1-\left(K \delta_{v,T_{t}}+N\delta_{d,T_{t}}+KN\delta_{m,T_{t}}\right).\]

_In addition,_

\[\mathbb{P}\left[\mathrm{CI}\big{|}\mathrm{Good}\right]\geq 1-\frac{\delta}{2}.\]

In addition to an estimation over the latent vector which is sufficient under the stationary case (\(\alpha_{t}\) in \(\rho_{t}\)), we also need to control the derivation between the empirical distribution \(\hat{\mathbf{p}}_{t}\) and the ground truth \(\mathbf{p}\) (\(\beta_{t}\) in \(\rho_{t}\)), as well as the interactions between the latent vectors and the distribution (\(\xi_{t}\) in \(\rho_{t}\)). This is reflected by \(K\delta_{v,T_{t}},N\delta_{d,T_{t}}\) and \(KN\delta_{m,T_{t}}\) which bound the the failure probability of Vector Estimation, Distribution Estimation and Residual Estimation, respectively.

**Step 3:**

**Lemma G.6**.: _Conditional on \(\mathrm{Good}\) and \(\mathrm{CI}\), the recommended arm \(\hat{x}_{\varepsilon}\in\mathcal{X}_{\varepsilon}\) and when Algorithm 1 terminates, the order of \(T_{t}\) is upper bounded by (3.6)._

The detailed proof is presented in Appendix J.

[MISSING_PAGE_FAIL:27]

\(k\gamma+i,\hat{c}_{1}\in\Gamma_{i}(t)]\) is a geometric distribution with parameter upper bounded by \(K\delta_{FAE}\). We have

\[\mathbb{P}\left[\hat{c}_{1}\in\Gamma_{i}(t)\right]\leq 1-\left(1-K\delta_{\mathrm{ FAE}}\right)^{|\Gamma_{i}(t)|}.\]

Hence, the cumulative false alarm error is

\[\mathbb{P}[\mathrm{FAE}] =\mathbb{P}\left[\hat{c}_{1}\leq t\right]\] \[=\sum_{i=0}^{w-1}\left[1-\left(1-K\delta_{\mathrm{FAE}}\right)^{ |\Gamma_{i}(t)|}\right]\] \[\leq\sum_{i=0}^{w-1}|\Gamma_{i}(t)|K\delta_{\mathrm{FAE}}\] \[\leq\frac{t}{\gamma}K\delta_{\mathrm{FAE}}.\]

Proof of Lemma h.1.: According to Algorithm 3, given \(w\) CD samples from the same context \([(\tilde{x}_{s},Y_{s,\tilde{x}_{s}})]_{s=1}^{w}\) and \(x\in\mathcal{X}\), we need to bound

\[\mathbb{P}\left[\bigg{|}\sum_{s=1}^{\frac{w}{2}}x^{\top}A(\lambda^{*})^{-1} \tilde{x}_{s}Y_{s,\tilde{x}_{s}}-\sum_{s=\frac{w}{2}+1}^{w}x^{\top}A(\lambda^{ *})^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}}\bigg{|}\geq\frac{w}{2}b\right].\]

The proof is similar to Lemma E.1. For any \(s\in[\frac{w}{2}]\) and \(\tilde{s}=s+\frac{w}{2}\)

\[\mathbb{E}\left[x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}}-x^ {\top}A(\lambda^{*})^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}}\right]=0\]

and

\[\left|x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}} -x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}}\right|\] \[\leq\left|x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{s}\tilde{x}_{s}^ {\top}\theta_{j_{s}}^{*}\right|+\left|x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{s} \eta_{s}\right|+\left|x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{s}\tilde{x}_{\tilde {x}}^{\top}\theta_{j_{s}}^{*}\right|+\left|x^{\top}A(\lambda^{*})^{-1}\tilde{x} _{s}\eta_{s}\right|\] \[\leq 4d.\]

By making use of (E.4),

\[\mathbb{E}\left[\left(x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{s}Y_ {s,\tilde{x}_{s}}-x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{\tilde{s}}Y_{s,\tilde{ x}_{s}}\right)^{2}\right]\] \[=\mathbb{E}\left[(x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{s}Y_{s, \tilde{x}_{s}})^{2}\right]+\mathbb{E}\left[(x^{\top}A(\lambda^{*})^{-1}\tilde {x}_{s}Y_{s,\tilde{x}_{s}})^{2}\right]\] \[\qquad-2\mathbb{E}\left[x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{s}Y _{s,\tilde{x}_{s}}\cdot x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{\tilde{s}}Y_{s, \tilde{x}_{s}}\right]\] \[\leq 4d+2\mathbb{E}\left[|x^{\top}\theta_{j_{s}}^{*}\cdot x^{\top} \theta_{j_{s}}^{*}|\right]\] \[\leq 6d.\]

According to the Bernstein's inequality,

\[\mathbb{P}\left[\bigg{|}\sum_{s=1}^{\frac{w}{2}}\left(x^{\top}A( \lambda^{*})^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}}-x^{\top}A(\lambda^{*})^{-1} \tilde{x}_{s+\frac{w}{2}}Y_{s+\frac{w}{2},\tilde{x}_{s+\frac{w}{2}}}\right) \bigg{|}\geq\frac{w}{2}\epsilon\right]\] \[\leq 2\exp\left(-\frac{\frac{1}{2}\left(\frac{w}{2}\epsilon \right)^{2}}{\frac{w}{2}\cdot 6d+\frac{4d}{3}\frac{w}{2}\epsilon}\right)\] \[=2\exp\left(-\frac{\frac{w}{2}\epsilon^{2}}{12d+\frac{8d}{3} \epsilon}\right).\]

In order to upper bound the error probability by \(\delta_{\mathrm{FAE}}\), we need

\[2\exp\left(-\frac{\frac{w}{2}\epsilon^{2}}{12d+\frac{8d}{3}\epsilon}\right)\leq \delta_{FAE}\]\[\Rightarrow \epsilon\geq\frac{4d}{3\cdot\frac{w}{2}}\ln\frac{2}{\delta_{\mathrm{FAE}} }+\sqrt{\left(\frac{4d}{3\cdot\frac{w}{2}}\ln\frac{2}{\delta_{\mathrm{FAE}}} \right)^{2}+12\cdot\frac{2}{w}d\ln\frac{2}{\delta_{\mathrm{FAE}}}}.\]

By the choice of \(b\geq\frac{8d}{3w}\ln\frac{2}{\delta_{\mathrm{FAE}}}+\sqrt{\left(\frac{8d}{3w} \ln\frac{2}{\delta_{\mathrm{FAE}}}\right)^{2}+\frac{24}{w}d\ln\frac{2}{\delta_ {\mathrm{FAE}}}}\), we have

\[\mathbb{P}\left[\left|\frac{2}{w}\sum_{s=1}^{\frac{w}{2}}x^{\top}A(\lambda^{*} )^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}}-\frac{2}{w}\sum_{s=\frac{w}{2}+1}^{w}x^{ \top}A(\lambda^{*})^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}}\right|\geq b\right] \leq\delta_{\mathrm{FAE}}.\]

A union bound over the \(K\) arms yields the final result. 

### Failed Alarm

**Lemma G.2**.: _Conditional on \(\mathrm{FAE}^{c}\), for any \(\delta_{\mathrm{FA}}\in(0,1)\), if \(\frac{\Delta_{c}-b}{2}\geq\frac{d}{w}\ln\frac{2}{\delta_{\mathrm{FA}}}+\sqrt{ \left(\frac{d}{w}\ln\frac{2}{\delta_{\mathrm{FA}}}\right)^{2}+\frac{4d}{w}\ln \frac{2}{\delta_{\mathrm{FA}}}}\),_

\[\mathbb{P}\left[c_{l}\leq\hat{c}_{l}\leq c_{l}+\frac{w\gamma}{2}\big{|}\hat{c} _{l}\geq c_{l}\right]\geq 1-\delta_{\mathrm{FA}}.\]

_In addition, \(\mathbb{P}\left[\mathrm{FA}\big{|}\mathrm{FAE}^{c}\right]\leq l_{\tau}\delta_ {\mathrm{FA}}\)._

Proof of Lemma G.2.: Conditioned on \(\mathrm{FAE}^{c}\), the detection at the changepoints is independent. Thus we can assume there is only one changepoint \(c_{1}\) within a certain number of consecutive time steps.

Algorithm 3 is given \(w\) CD samples which are collected under two different context. Without loss of generality, we assume the sample selected at time \(c_{1}\) is among the CD samples (otherwise, we can regard the time step of the first sample from the second context as \(c_{1}\)). We wish to bound

\[\mathbb{P}\left[c_{1}\leq\hat{c}_{1}\leq c_{1}+\frac{\gamma w}{2}\big{|}\hat{ c}_{1}\geq c_{1}\right]\]

which is the probability of the event that, after a changepoint occurs, a changing alarm will be raised within \(\frac{w\gamma}{2}\) time steps (or \(\frac{w}{2}\) CD samples). Here, \(\hat{c}_{1}\geq c_{1}\) can be guaranteed as we are conditioning on that there is no false alarm error (\(\mathrm{FAE}^{c}\)).

The event \(c_{1}\leq\hat{c}_{1}\leq c_{1}+\frac{\gamma w}{2}\) indicates, at least one of the CD sample list in

\[\left\{\left[(x_{c_{1}+(s-k)\gamma},Y_{c_{1}+(s-k)\gamma,x_{c_{1}+(s-k)\gamma }})\right]_{s=1}^{w}\right\}_{k=\frac{w}{2}+1}^{w}\]

will trigger the changing alarm in Algorithm 3. In particular, in Lemma H.2, we consider the failed arm probability when the CD samples are composed by exactly half samples from each contexts, \(\left[(x_{c_{1}+(s-1-\frac{w}{2})\gamma},Y_{c_{1}+(s-1-\frac{w}{2})\gamma}) \right]_{s=1}^{w}\).

**Lemma H.2**.: _Given \(w\) CD samples from the two different contexts \([(\tilde{x}_{s},Y_{s,\tilde{x}_{s}})]_{s=1}^{w}\) in a CD phase, where \([(\tilde{x}_{s},Y_{s,\tilde{x}_{s}})]_{s=1}^{\frac{w}{2}}\) is from latent vector \(\theta_{j}^{*}\) and \([(\tilde{x}_{s},Y_{s,\tilde{x}_{s}})]_{s=\frac{w}{2}+1}^{w}\) is from latent vector \(\theta_{j}^{*}\), Algorithm 3 raises a changing alarm with probability lower bounded by_

\[1-\delta_{\mathrm{FA}}\]

_if \(\frac{\Delta_{c}-b}{2}\geq\frac{d}{w}\ln\frac{2}{\delta_{\mathrm{FA}}}+\sqrt{ \left(\frac{d}{w}\ln\frac{2}{\delta_{\mathrm{FA}}}\right)^{2}+\frac{4d}{w}\ln \frac{2}{\delta_{\mathrm{FA}}}}\) where \(\Delta_{c}:=\max_{x\in\mathcal{X}}|x^{\top}(\theta_{j}^{*}-\theta_{j}^{*})|\) and it is assumed to be greater than \(b\)._

By making use of Lemma H.2,

\[\mathbb{P}\left[c_{1}\leq\hat{c}_{1}\leq c_{1}+\frac{w\gamma}{2 }\big{|}\hat{c}_{1}\geq c_{1}\right]\] \[=\mathbb{P}\left[\exists k\in\{\frac{w}{2}+1,\ldots,w\},\] \[\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad \qquad\[\geq\mathbb{P}\left[\text{LCD}\left(w,b,[(x_{c_{1}+(s-1-\frac{w}{2}) \gamma},Y_{c_{1}+(s-1-\frac{w}{2})\gamma,x_{c_{1}+(s-1-\frac{w}{2})\gamma}})]_{s =1}^{w}\right)=\text{True}\big{|}\hat{c}_{1}\geq c_{1}\right]\] \[\geq 1-\delta_{\text{FA}}\]

where \(\Delta_{c}=\max_{x\in\mathcal{X}}|x^{\top}(\theta_{j}^{*}-\theta_{j}^{*})|\) and \(\theta_{j}^{*},\theta_{j}^{*}\) are the latent vectors. Hence,

\[\mathbb{P}\left[\text{FA}\big{|}\text{FAE}^{c}\right]=1-\mathbb{P}\left[\text {FA}^{c}\big{|}\text{FAE}^{c}\right]\leq 1-(1-\delta_{\text{FA}})^{l_{\tau}}\leq l_{ \tau}\delta_{\text{FA}}\]

Proof of Lemma h.2.: According to the design of LCD, there exists an \(x\in\mathcal{X}\),

\[\mathbb{P}\left[\ \left|\frac{2}{w}\sum_{s=1}^{\frac{w}{2}}x^{\top}A( \lambda^{*})^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}}-\frac{2}{w}\sum_{s=\frac{w}{ 2}+1}^{w}x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}}\right| \geq b\ \right]\] \[\geq 1-\mathbb{P}\Bigg{[}\ \left|\sum_{s=1}^{\frac{w}{2}}x^{\top}A( \lambda^{*})^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}}-\sum_{s=\frac{w}{2}+1}^{w}x^ {\top}A(\lambda^{*})^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}}-\frac{w}{2}x^{\top}( \theta_{j}^{*}-\theta_{j}^{*})\right|\] \[\geq\Big{|}\frac{w}{2}b-\frac{w}{2}x^{\top}(\theta_{j}^{*}-\theta _{j}^{*})\big{|}\ \Bigg{]}\] \[=1-\mathbb{P}\Bigg{[}\ \left|\sum_{s=1}^{\frac{w}{2}}\left(x^{\top}A( \lambda^{*})^{-1}\tilde{x}_{s}Y_{s,\tilde{x}_{s}}-x^{\top}\theta_{j}^{*} \right)-\sum_{s=\frac{w}{2}+1}^{w}\left(x^{\top}A(\lambda^{*})^{-1}\tilde{x}_{ s}Y_{s,\tilde{x}_{s}}-x^{\top}\theta_{j}^{*}\right)\right|\] \[\geq\Big{|}\frac{w}{2}b-\frac{w}{2}x^{\top}(\theta_{j}^{*}-\theta _{j}^{*})\Big{|}\ \Bigg{]}\] \[\geq 1-\delta_{\text{FA}}\]

where the last inequality holds as \(\frac{\Delta_{c}-b}{2}\geq\frac{d}{w}\ln\frac{2}{\delta_{\text{FA}}}+\sqrt{ \left(\frac{d}{w}\ln\frac{2}{\delta_{\text{FA}}}\right)^{2}+\frac{4d}{w}\ln \frac{2}{\delta_{\text{FA}}}}\). 

### Context Alignment

**Lemma G.3**.: _Conditional on \(\mathrm{FAE}^{c}\) and \(\mathrm{FA}^{c}\), based on the conditions in Lemma G.1 and Lemma G.2,_

\[\mathbb{P}\left[\mathrm{MI}|\mathrm{FAE}^{c},\mathrm{FA}^{c}\right]\leq l_{ \tau}\left[(N-1)\delta_{\text{FA}}+K\delta_{\text{FAE}}\right].\]

Proof of Lemma g.3.: The error of the context alignment procedure can be derived from the FAE and FA analyses. Conditioned on \(\mathrm{FAE}^{c},\mathrm{FA}^{c}\) and that the previous \(l-1\) contexts are correctly identified, i.e., \(\bigcap_{k=1}^{l-1}\mathrm{MI}_{k}^{c}\), we have the following statements.

Firstly, according to Lemma H.1, the change alarm at Line \(4\) in Algorithm 4 will not be triggered with probability at least \((1-K\delta_{\text{FAE}})\) if the current context is context \(j\). This error has been taken into account in the FAE (see Remark H.3).

Secondly, if the current context is not \(j\) (which will occur at most \(N-1\) times), a change alarm will be raised with probability at least \(1-\delta_{\text{FA}}\) by Lemma G.2.

Therefore, the error probability at \(c_{l}\) is upper bounded by

\[\mathbb{P}\left[\mathrm{MI}_{l}|\mathrm{FAE}^{c},\mathrm{FA}^{c},\cap_{k=1}^{l -1}\mathrm{MI}_{k}^{c}\right]\leq(N-1)\delta_{\text{FA}}+K\delta_{\text{FAE}}\]

and by a union bound, the cumulative error probability bounded by

\[\mathbb{P}\left[\mathrm{MI}|\mathrm{FAE}^{c},\mathrm{FA}^{c}\right] =1-\mathbb{P}\left[\mathrm{MI}^{c}|\mathrm{FAE}^{c},\mathrm{FA}^{c}\right]\] (H.1) \[\leq 1-(1-(N-1)\delta_{\text{FA}}-K\delta_{\text{FAE}})^{l_{\tau}}\] \[\leq l_{\tau}\left((N-1)\delta_{\text{FA}}+K\delta_{\text{FAE}} \right).\]

**Remark H.3**.: _Note that (1) we will only bound the FAE when the CD samples are from the same context; (2) in the analysis of FAE, we bound the error probability on the whole horizon up to time _as we assume there is no changepoint. In particular, there will be unused and redundant \(\frac{w}{2}K\delta_{\mathrm{FAE}}\) errors budget for \(\mathrm{FAE}\) at each changepoint, which accumulates to \(l_{\tau}\frac{w}{2}K\delta_{\mathrm{FAE}}\) before time step \(\tau\). Therefore, the second error term in (H.1), \(l_{\tau}K\delta_{\mathrm{FAE}}\), can be covered by the unused \(l_{\tau}\frac{w}{2}K\delta_{\mathrm{FAE}}\) error budget from \(\mathrm{FAE}\), and thus it can be neglected in (H.1)._

Proof of Lemma g.4.: According to Lemma g.1, G.2, G.3, Assumption 1 and Remark H.3, given a time \(\tau\), the total failure probability is upper bounded by

\[\mathbb{P}\left[\mathrm{Good}^{c}\right] =\mathbb{P}\left[\mathrm{FAE}\cup\mathrm{FA}\cup\mathrm{MI}\right]\] (H.2) \[\leq\frac{\tau}{\gamma}K\delta_{\mathrm{FAE}}+l_{\tau}\delta_{ \mathrm{FA}}+l_{\tau}\cdot(N-1)\delta_{\mathrm{FA}}\] \[=\frac{\tau}{\gamma}K\delta_{\mathrm{FAE}}+l_{\tau}N\delta_{ \mathrm{FA}}.\]

In particular, when \(\tau\) is upper bounded by \(\tau^{*}\) in Line \(2\) of Algorithm 1

\[\tau\leq\tau^{*}=c_{0}\frac{NL_{\mathrm{max}}}{\varepsilon^{2}}\ln\frac{N^{2} KL_{\mathrm{max}}/\varepsilon^{2}}{\delta}\]

where \(c_{0}=3\cdot 6400\ln 6400\). The number of changepoints till \(\tau\) is upper bounded by \(l_{\tau^{*}}\leq\frac{\tau^{*}}{L_{\mathrm{min}}}\).

By Assumption 1, when \(b=\frac{8d}{3w}\ln\frac{2}{\delta_{\mathrm{FAE}}}+\sqrt{\left(\frac{8d}{3w}\ln \frac{2}{\delta_{\mathrm{FAE}}}\right)^{2}+\frac{24}{w}d\ln\frac{2}{\delta_{ \mathrm{FAE}}}}\) and \(\delta_{\mathrm{FAE}}=\frac{\gamma\delta}{4(\tau^{*})^{2}K}\), the conditions of Lemma G.1 are met. And we can upper bound \(\frac{\gamma}{\gamma}K\delta_{\mathrm{FAE}}\) by \(\frac{\delta}{4\tau^{*}}\leq\frac{\delta}{4}\).

By making use of Assumption 1 and setting \(\delta_{\mathrm{FA}}=\frac{\delta}{4Nl_{\tau^{*}}\tau^{*}}\), we have \(\delta_{\mathrm{FA}}>\delta_{\mathrm{FAE}}\) and

\[\frac{\Delta_{c}-b}{2}\geq\frac{b}{2} \geq\frac{4d}{3w}\ln\frac{2}{\delta_{\mathrm{FAE}}}+\sqrt{\left( \frac{4d}{3w}\ln\frac{2}{\delta_{\mathrm{FAE}}}\right)^{2}+\frac{6}{w}d\ln \frac{2}{\delta_{\mathrm{FAE}}}}\] \[\geq\frac{d}{w}\ln\frac{2}{\delta_{\mathrm{FA}}}+\sqrt{\left( \frac{d}{w}\ln\frac{2}{\delta_{\mathrm{FA}}}\right)^{2}+\frac{4d}{w}\ln\frac{ 2}{\delta_{\mathrm{FA}}}}.\]

Thus, Lemma G.2 can be applied. \(l_{\tau^{*}}N\delta_{\mathrm{FA}}\) can be upper bounded by \(\frac{\delta}{4\tau^{*}}\leq\frac{\delta}{4}\).

Therefore, according to (H.2), \(\mathbb{P}[\mathrm{Good}]\geq 1-\frac{\delta}{2\tau^{*}}\geq 1-\frac{\delta}{2}\).

## Appendix I Analysis of \(\mathrm{PS}\varepsilon\mathrm{BAI}\): Estimation Error

Lemma G.5 is proved in this section. We will upper bound these three error terms (see (I.1)): VE error in App I.1, DE error in App I.2, RE error in App I.3, and finally we will prove Lemma G.5 which upper bounds the failure probability of CI at the end of this section.

**Lemma G.5**.: _If \(T_{t}\geq\frac{2L_{\mathrm{max}}}{9}\ln\frac{2}{\delta_{d,T_{t}}}\),_

\[\mathbb{P}\left[\mathrm{CI}_{t}\big{|}\mathrm{Good}\right]\geq 1-\left(K \delta_{v,T_{t}}+N\delta_{d,T_{t}}+KN\delta_{m,T_{t}}\right).\]

_In addition,_

\[\mathbb{P}\left[\mathrm{CI}\big{|}\mathrm{Good}\right]\geq 1-\frac{ \delta}{2}.\]

Given any two arms \(x,\tilde{x}\in\mathcal{X}\), by the triangular inequality, the deviation between \(\hat{\Delta}_{t}(x,\tilde{x})\) and \(\Delta(x,\tilde{x})\) can be upper bounded by three terms: the Vector-Estimation Error (VE) term, the Distribution-Estimation Error (DE) term, and the Residual Estimation Error (RE) term:

\[\begin{split}&|\hat{\Delta}_{t}(x,\tilde{x})-\Delta(x,\tilde{x})|\\ &=|(x-\tilde{x})^{\top}\hat{\Theta}_{t}\hat{\mathfrak{p}}_{t}-(x- \tilde{x})^{\top}\Theta\mathbf{p}|\end{split}\] (I.1)\[\leq\underbrace{\Big{|}\sum_{j=1}^{N}\left(\hat{\Delta}_{t,j}(x, \tilde{x})-\Delta_{j}(x,\tilde{x})\right)\hat{p}_{t,j}\Big{|}}_{\text{VE term}}+\underbrace{\Big{|}\sum_{j=1}^{N}\hat{\Delta}_{t,j}^{\text{clip}_{2}}(x, \tilde{x})(\hat{p}_{t,j}-p_{j})\Big{|}}_{\text{DE term}}\] \[\qquad+\underbrace{\Big{|}\sum_{j=1}^{N}\left(\Delta_{j}(x, \tilde{x})-\hat{\Delta}_{t,j}^{\text{clip}_{2}}(x,\tilde{x})\right)(\hat{p}_{ t,j}-p_{j})\Big{|}}_{\text{RE term}},\]

where \(a^{\text{clip}_{2}}:=\text{clip}_{2}(a):=\min\{\max\{a,-2\},2\}\) is a shorthand notation for the value of \(a\) that is clipped to the interval \([-2,2]\). The reason the value \(\hat{\Delta}_{t,j}(x,\tilde{x})\) is clipped is the ground truth \(|\Delta_{t,j}(x,\tilde{x})|\leq 2\).

Recall the event \(\mathrm{CI}\)

\[\mathrm{CI}_{t} :=\{\big{|}\hat{\Delta}_{t}(x,\tilde{x})-\Delta(x,\tilde{x}) \big{|}\leq\rho_{t}(x,\tilde{x}),\forall x,\tilde{x}\in\mathcal{X}\},\] \[\mathrm{CI} :=\bigcap_{t}\mathrm{CI}_{t},\]

and the confidence radius

\[\rho_{t}(x,\tilde{x}):=2(\alpha_{t}+\xi_{t})+\sum_{j=1}^{N}\beta _{t,j}|\hat{\Delta}_{t,j}^{\text{clip}_{2}}(x,\tilde{x})+\zeta_{t}(x,\tilde{x })|,\] (I.2)

where \[\alpha_{t}:=5\sqrt{\frac{d}{T_{t}}\ln\frac{2}{\delta_{v,T_{t}}}}, \quad\beta_{t,j}:=\frac{5}{2}\sqrt{\frac{2\phi_{t,j}L_{\max}}{T_{t}}\ln\frac{ 2}{\delta_{d,T_{t}}}},\] \[\xi_{t}:=25\sqrt{2}\frac{NL_{\max}}{T_{t}}\ln\frac{2}{\delta_{m, T_{t}}},\quad\phi_{t,j}:=\min\left\{4\max\left\{\hat{p}_{t,j},\frac{25}{4}\frac{L_{ \max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\right\},\frac{1}{4}\right\},\]

and \(\zeta_{t}(x,\tilde{x})\in\mathbb{R}\) can be any value. In particular, it can be the value that minimizes \(\sum_{j=1}^{N}\beta_{t,j}|\hat{\Delta}_{t,j}(x,\tilde{x})+\zeta_{t}(x,\tilde{ x})|\) or it can be taken as \(\varepsilon\). For simplicity, we will take \(\zeta_{t}(x,\tilde{x})=\arg\min_{\zeta_{t}(x,\tilde{x})\in\mathbb{R}}\sum_{j=1 }^{N}\beta_{t,j}(\hat{\Delta}_{t,j}(x,\tilde{x})+\zeta_{t}(x,\tilde{x}))^{2}=- \frac{\sum_{j=1}^{N}\beta_{t,j}\hat{\Delta}_{t,j}(x,\tilde{x})}{\sum_{j=1}^{N }\beta_{t,j}}\) for a simple and effective analytic expression in the algorithm.

### Vector-Estimation Error

For the VE term \(\Big{|}\sum_{j=1}^{N}\left(\hat{\Delta}_{t,j}(x,\tilde{x})-\Delta_{j}(x, \tilde{x})\right)\hat{p}_{t,j}\Big{|}\), note that

\[\Big{|}\sum_{j=1}^{N}\left(\hat{\Delta}_{t,j}(x,\tilde{x})-\Delta_{j}(x, \tilde{x})\right)\hat{p}_{t,j}\Big{|}\leq|x^{\top}(\hat{\Theta}_{t}-\Theta) \hat{p}_{t}|+|\tilde{x}^{\top}(\hat{\Theta}_{t}-\Theta)\hat{p}_{t}|\]

**Lemma I.1**.: _Given \(x\in\mathcal{X}\) and \(T_{t}\geq\frac{d}{4}\ln\frac{2}{\delta_{v,T_{t}}}\),_

\[\mathbb{P}\left[|x^{\top}(\hat{\Theta}_{t}-\Theta)\hat{\mathbf{p}}_{t}|\geq \alpha_{t}\big{|}\text{Good}\right]\leq\delta_{v,T_{t}}\]

Proof of Lemma I.1.: By the definition of the estimators in (3.2),

\[x^{\top}(\hat{\Theta}_{t}-\Theta)\hat{\mathbf{p}}_{t} =\sum_{j=1}^{N}x^{\top}(\hat{\theta}_{t,j}-\theta_{j}^{*})\hat{ \mathbf{p}}_{t,j}\] \[=\sum_{j=1}^{N}x^{\top}\left(\frac{1}{T_{t,j}}\sum_{s\in \mathcal{T}_{t,j}}A(\lambda^{*})^{-1}x_{s}Y_{s,x_{s}}-\theta_{j}^{*}\right) \frac{T_{t,j}}{T_{t}}\] \[=\frac{1}{T_{t}}\sum_{j=1}^{N}\sum_{s\in\mathcal{T}_{t,j}}x^{\top }A(\lambda^{*})^{-1}x_{s}Y_{s,x_{s}}-x^{\top}\theta_{j}^{*}\]By Lemma E.1,

\[\mathbb{P}\left[|x^{\top}(\hat{\Theta}_{t}-\Theta)\hat{\mathbf{p}}_{t}|\geq \alpha_{t}\big{|}\theta_{1:\infty},\mathrm{Good}\right]\leq\delta_{v,T_{t}}\]

By the property of conditional probability, we have the desired result. 

Therefore, conditional on Good, with probability at least \(1-K\delta_{v,T_{t}}\), \(\mathrm{VE}\leq 2\alpha_{t}\) for any \(x,\tilde{x}\in\mathcal{X}\).

### Distribution-Estimation Error

**Lemma I.2**.: _Given Good and \(T_{t}\geq\frac{2L_{\max}}{9}\ln\frac{2}{\delta_{d,T_{t}}}\), for any \(j\in[N]\),_

\[\mathbb{P}\left[|\hat{p}_{t,j}-p_{j}|\geq\beta_{t,j}\big{|}\mathrm{Good}\right] \leq\delta_{d,T_{t}}.\]

_Additionally, with probability \(1-N\delta_{d,T_{t}}\),_

\[\Big{|}\sum_{j=1}^{N}\hat{\Delta}_{t,j}^{\mathrm{clip}_{2}}(x,\tilde{x})(\hat {p}_{t,j}-p_{j})\Big{|}\leq\sum_{j=1}^{N}\beta_{t,j}|\hat{\Delta}_{t,j}^{ \mathrm{clip}_{2}}(x,\tilde{x})+\zeta_{t}(x,\tilde{x})|\]

_where \(\zeta_{t}(x,\tilde{x})\) can be any value._

Proof of Lemma I.2.: Given any \(j\in[N]\), and the stationary segment \(l\), we denote \(X_{j,l}:=\hat{L}_{l}\mathbbm{1}\{\theta_{j_{l}}^{*}=\theta_{j}^{*}\}-p_{j}\hat {L}_{l}\), where \(\hat{L}_{l}\) is the total length of the Exp phases in the \(l\)th stationary segment. Note that \(\mathbb{E}[X_{j,l}|\{\hat{L}_{l}\}_{l=1}^{l_{t}},\mathrm{Good}]=0,|X_{j,l}| \leq L_{\max}\)\(a.s.\) and \(\mathrm{Var}[X_{j,l}|\{\hat{L}_{l}\}_{l=1}^{l_{t}},\mathrm{Good}]=p_{j}(1-p_{j}) \hat{L}_{l}^{2}\leq p_{j}(1-p_{j})\hat{L}_{l}L_{\max}\). By Bernstein's inequality,

\[\mathbb{P}\left[|\sum_{l=1}^{l_{t}}X_{j,l}|\geq\epsilon\big{|}\{ \hat{L}_{l}\}_{l=1}^{l_{t}},\mathrm{Good}\right]\leq 2\exp\left(-\frac{\epsilon^{2} }{2\sum_{l=1}^{l_{t}}\mathrm{Var}[X_{j,l}|\mathrm{Good}]+\frac{2}{3}L_{\max} \epsilon}\right)\] \[\Rightarrow \mathbb{P}\left[|\frac{1}{T_{t}}\sum_{l=1}^{l_{t}}X_{j,l}|\geq \epsilon\big{|}\{\hat{L}_{l}\}_{l=1}^{l_{t}},\mathrm{Good}\right]\leq 2\exp \left(-\frac{T_{t}^{2}\epsilon^{2}}{2\sum_{l=1}^{l_{t}}\mathrm{Var}[X_{j,l}| \mathrm{Good}]+\frac{2}{3}L_{\max}T_{t}\epsilon}\right)\]

As \(T_{t,j}=\sum_{l=1}^{l_{t}}\hat{L}_{l}\mathbbm{1}\{\theta_{j_{l}}^{*}=\theta_{j }^{*}\},T_{t}=\sum_{l=1}^{l_{t}}\hat{L}_{l}\) and \(\sum_{l=1}^{l_{t}}\hat{L}_{l}=T_{t}\), we have

\[\mathbb{P}\left[|\hat{p}_{t,j}-p_{j}|\geq\epsilon\big{|}\{\hat{L }_{l}\}_{l=1}^{l_{t}},\mathrm{Good}\right] \leq 2\exp\left(-\frac{T_{t}^{2}\epsilon^{2}}{2\sum_{l=1}^{l_{t}} \mathrm{Var}[X_{j,l}|\{\hat{L}_{l}\}_{l=1}^{l_{t}},\mathrm{Good}]+\frac{2}{3}L _{\max}T_{t}\epsilon}\right)\] \[\leq 2\exp\left(-\frac{T_{t}^{2}\epsilon^{2}}{2\sum_{l=1}^{l_{t}} p_{j}(1-p_{j})\hat{L}_{l}L_{\max}+\frac{2}{3}L_{\max}T_{t}\epsilon}\right)\] \[\leq 2\exp\left(-\frac{T_{t}\epsilon^{2}}{2p_{j}(1-p_{j})L_{\max}+ \frac{2}{3}L_{\max}\epsilon}\right)\]

As the last bound is independent of \(\{\hat{L}_{l}\}_{l=1}^{l_{t}}\), we have

\[\mathbb{P}\left[|\hat{p}_{t,j}-p_{j}|\geq\epsilon\big{|}\mathrm{Good}\right] \leq 2\exp\left(-\frac{T_{t}\epsilon^{2}}{2p_{j}(1-p_{j})L_{\max}+\frac{2}{3}L_{ \max}\epsilon}\right)\]

If we want to upper bound the above by \(\delta_{d,T_{t}}\in(0,1)\), i.e.,

\[2\exp\left(-\frac{T_{t}\epsilon^{2}}{2p_{j}(1-p_{j})L_{\max}+\frac{2}{3}L_{ \max}\epsilon}\right)\leq\delta_{d,T_{t}}\]

we require

\[\epsilon\geq\frac{\frac{1}{3}L_{\max}\ln\frac{2}{\delta_{d,T_{t}}}+\sqrt{\left( \frac{1}{3}L_{\max}\ln\frac{2}{\delta_{d,T_{t}}}\right)^{2}+2T_{t}p_{j}(1-p_{j} )L_{\max}\ln\frac{2}{\delta_{d,T_{t}}}}}{T_{t}}\] (I.3)In particular,

\[\epsilon=\tilde{\beta}_{t,j}:=\frac{5}{2}\max\left\{\frac{L_{\max}}{3T_{t}}\ln \frac{2}{\delta_{d,T_{t}}},\sqrt{\frac{2p_{j}(1-p_{j})L_{\max}}{T_{t}}}\ln\frac{ 2}{\delta_{d,T_{t}}}\right\}\]

satisfies the condition, we have

\[\mathbb{P}\left[|\hat{p}_{t,j}-p_{j}|\geq\tilde{\beta}_{t,j}\big{|}\mathrm{ Good}\right]\leq\delta_{d,T_{t}}.\] (I.4)

A problem here is we do not have access to \(p_{j}\) during the dynamics, therefore, we adopt Lemma K.1 to further upper bound \(\tilde{\beta}_{t,j}\) by \(\beta_{t,j}\).

**Lemma K.1**.: _Given any \(j\in[N]\) and \(T_{t}\geq\frac{2L_{\max}}{9}\ln\frac{2}{\delta_{d,T_{t}}}\), \(\tilde{\beta}_{t,j}\leq\beta_{t,j}\)._

Therefore,

\[\mathbb{P}\left[|\hat{p}_{t,j}-p_{j}|\geq\beta_{t,j}\big{|} \mathrm{Good}\right]\leq\delta_{d,T_{t}}.\]

In addition, with probability at least \(1-N\delta_{d,T_{t}}\), we can upper bound DE term as:

\[\Big{|}\sum_{j=1}^{N}\hat{\Delta}_{t,j}^{\mathrm{clip}_{2}}(x, \tilde{x})(\hat{p}_{t,j}-p_{j})\Big{|} =\Big{|}\sum_{j=1}^{N}\left(\hat{\Delta}_{t,j}^{\mathrm{clip}_{2} }(x,\tilde{x})+\zeta_{t}(x,\tilde{x})\right)(\hat{p}_{t,j}-p_{j})\Big{|}\] (I.5) \[\leq\sum_{j=1}^{N}\beta_{t,j}\big{|}\hat{\Delta}_{t,j}^{\mathrm{ clip}_{2}}(x,\tilde{x})+\zeta_{t}(x,\tilde{x})\big{|}\]

where \(\zeta_{t}(x,\tilde{x})\in\mathbb{R}\) can be any value. 

### Residual-Estimation Error

RE is composed by the product of two deviations, i.e., \(\left(\Delta_{j}(x,\tilde{x})-\hat{\Delta}_{t,j}^{\mathrm{clip}_{2}}(x, \tilde{x})\right)\) and \((\hat{p}_{t,j}-p_{j})\), as the time step \(t\) becomes large, we expect it will converge to zero fast. Thus, it is sufficient to have a coarse estimation of it.

**Lemma I.3**.: _For any \(x\in\mathcal{X}\), conditional on that \(|\hat{p}_{t,j}-p_{j}|\leq\beta_{t,j},\forall j\in[N]\),_

\[\mathbb{P}\left[\Big{|}\sum_{j=1}^{N}\left(\Delta_{j}(x,\tilde{x} )-\hat{\Delta}_{t,j}^{\mathrm{clip}_{2}}(x,\tilde{x})\right)(\hat{p}_{t,j}-p_ {j})\Big{|}\geq\xi_{t}\bigg{|}\mathrm{Good}\right]\leq N\delta_{m,T_{t}}\]

_where \(\xi_{t}:=25\sqrt{2}\frac{NL_{\max}}{T_{t}}\ln\frac{2}{\delta_{m,T_{t}}}\)._

Proof of Lemma I.3.: According to Lemma E.1, for any \(x\in\mathcal{X},j\in[N]\) we have

\[\mathbb{P}\left[|x^{\top}(\theta_{j}^{*}-\hat{\theta}_{t,j})|\geq 5\sqrt{ \frac{d}{T_{t,j}}\ln\frac{2}{\delta_{m,T_{t}}}}|\mathrm{Good}\right]\leq \delta_{m,T_{t}}\] (I.6)

if \(T_{t,j}\geq\frac{d}{4}\ln\frac{2}{\delta_{m,T_{t}}}\). Note the fact that \(\Delta_{j}(x,\tilde{x})\in[-2,2]\), hence,

\[\Big{|}\Delta_{j}(x,\tilde{x})-\hat{\Delta}_{t,j}^{\mathrm{clip}_{2}}(x, \tilde{x})\Big{|}\leq\Big{|}\Delta_{j}(x,\tilde{x})-\hat{\Delta}_{t,j}(x, \tilde{x})\Big{|}\leq|x^{\top}(\theta_{j}^{*}-\hat{\theta}_{t,j})|+|\tilde{x}^ {\top}(\theta_{j}^{*}-\hat{\theta}_{t,j})|.\] (I.7)

And \(|x^{\top}(\theta_{j}^{*}-\hat{\theta}_{t,j})|\leq 3d\) with probability \(1\). Denote

\[\psi_{t,j,1}:=\max\left\{\hat{p}_{t,j},\frac{d}{4T_{t}}\ln\frac{2}{\delta_{m,T _{t}}}\right\},\;\psi_{t,j,2}:=\max\left\{\hat{p}_{t,j},\frac{25}{4}\frac{L_{ \max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\right\}.\] (I.8)We have5

Footnote 5: The last inequality can be loose. When each context has been visited at least once, the first summation in (I.10) can be ignored. For empirical performance, (I.10) should be used, while \(\xi\) is adopted for theoretical guarantees.

\[\Big{|}\sum_{j=1}^{N}\left(\Delta_{j}(x,\tilde{x})-\hat{\Delta}_{t,j}^{\text{ clip}_{2}}(x,\tilde{x})\right)(\hat{p}_{t,j}-p_{j})\Big{|}\] \[\leq\sum_{j:\psi_{t,j,1}>\hat{p}_{t,j}}\Big{|}\left(\Delta_{j}(x, \tilde{x})-\hat{\Delta}_{t,j}^{\text{clip}_{2}}(x,\tilde{x})\right)\beta_{t,j} \Big{|}+\sum_{\begin{subarray}{c}j:\psi_{t,j,1}=\hat{p}_{t,j},\\ \psi_{t,j,2}>\hat{p}_{t,j}\end{subarray}}\Big{|}\left(\Delta_{j}(x,\tilde{x})- \hat{\Delta}_{t,j,2}^{\text{clip}_{2}}(x,\tilde{x})\right)\beta_{t,j}\Big{|}\]

\[+\sum_{j:\psi_{t,j,2}=\hat{p}_{t,j}}\Big{|}\left(\Delta_{j}(x, \tilde{x})-\hat{\Delta}_{t,j}^{\text{clip}_{2}}(x,\tilde{x})\right)\beta_{t,j} \Big{|}\] \[\overset{(a)}{\leq}\sum_{j:\psi_{t,j,1}>\hat{p}_{t,j}}\Big{|} \left(\Delta_{j}(x,\tilde{x})-\hat{\Delta}_{t,j}^{\text{clip}_{2}}(x,\tilde{ x})\right)\beta_{t,j}\Big{|}+\sum_{\begin{subarray}{c}j:\psi_{t,j,1}=\hat{p}_{t,j},\\ \psi_{t,j,2}>\hat{p}_{t,j}\end{subarray}}\Big{|}\left(\Delta_{j}(x,\tilde{x}) -\hat{\Delta}_{t,j,2}^{\text{clip}_{2}}(x,\tilde{x})\right)\beta_{t,j}\Big{|}\]

\[+\sum_{j:\psi_{t,j,2}=\hat{p}_{t,j}}|x^{\top}(\theta_{j}^{*}-\hat{ \theta}_{t,j})\beta_{t,j}|+|\tilde{x}^{\top}(\theta_{j}^{*}-\hat{\theta}_{t, j})\beta_{t,j}|\] (I.9) \[\overset{(b)}{\leq}\sum_{j:\psi_{t,j,1}>\hat{p}_{t,j}}4\cdot \frac{5}{2}\cdot\frac{5\sqrt{2}}{2}\frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\] \[+\sum_{\begin{subarray}{c}j:\psi_{t,j,1}=\hat{p}_{t,j},\\ \psi_{t,j,2}>\hat{p}_{t,j}\end{subarray}}\min\left\{4,2\cdot 5\sqrt{\frac{d}{T_{t,j}}\ln \frac{2}{\delta_{m,T_{t}}}}\right\}\cdot\frac{5}{2}\cdot\frac{5\sqrt{2}}{2} \frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\] \[+\sum_{j:\psi_{t,j,3}=\hat{p}_{t,j}}2\cdot 5\sqrt{\frac{d}{T_{t,j}} \ln\frac{2}{\delta_{m,T_{t}}}}\cdot\frac{5}{2}\sqrt{\frac{8\hat{p}_{t,j}L_{ \max}}{T_{t}}}\ln\frac{2}{\delta_{d,T_{t}}}\] \[\leq\sum_{j:\psi_{t,j,1}>\hat{p}_{t,j}}25\sqrt{2}\frac{L_{\max}}{ T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\] \[+\sum_{\begin{subarray}{c}j:\psi_{t,j,1}=\hat{p}_{t,j},\\ \psi_{t,j,2}>\hat{p}_{t,j}\end{subarray}}\min\left\{4,10\sqrt{\frac{d}{T_{t,j }}\ln\frac{2}{\delta_{m,T_{t}}}}\right\}\cdot\frac{25\sqrt{2}}{4}\frac{L_{\max} }{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\] \[+\sum_{j:\psi_{t,j,2}=\hat{p}_{t,j}}50\sqrt{2}\frac{\sqrt{dL_{ \max}}}{T_{t}}\ln\frac{2}{\delta_{m,T_{t}}}\] (I.10) \[\leq 50\sqrt{2}\frac{NL_{\max}}{T_{t}}\ln\frac{2}{\delta_{m,T_{t}}}= 2\xi_{t}\]

where \((a)\) adopts (I.7) and \((b)\) is obtained by the following derivations:

(1) \(\psi_{t,j,1}>\hat{p}_{t,j}\) indicates \(\hat{p}_{t,j}<\frac{d}{4T_{t}}\ln\frac{2}{\delta_{m,T_{t}}}<\frac{25}{4}\frac{L _{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\), and thus \(\beta_{t,j}\leq\frac{5}{2}\cdot\frac{5\sqrt{2}}{2}\frac{L_{\max}}{T_{t}}\ln \frac{2}{\delta_{d,T_{t}}}\).In addition,6,

Footnote 6: This demonstrates the usefulness of the clipping technique. Without the clipping technique, we can only get an upper bound of \(6d\) by utilizing (E.2) which introduces another \(d\) factor in \(\xi_{t}\).

\[\Big{|}\Delta_{j}(x,\tilde{x})-\hat{\Delta}_{t,j}^{\text{clip}_{2}}(x,\tilde{x} )\Big{|}\leq 4.\]

(2) \(\psi_{t,j,1}=\hat{p}_{t,j}\) indicates \(\hat{p}_{t,j}\leq\frac{d}{4T_{t}}\ln\frac{2}{\delta_{m,T_{t}}}\) and \(\psi_{t,j,2}>\hat{p}_{t,j}\) implies \(\hat{p}_{t,j}<\frac{25}{4}\frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\), thus (I.6) can be applied and \(\beta_{t,j}\leq\frac{5}{2}\cdot\frac{5\sqrt{2}}{2}\frac{L_{\max}}{T_{t}}\ln\frac{ 2}{\delta_{d,T_{t}}}\).

(3) \(\psi_{t,j,2}=\hat{p}_{t,j}\) indicates \(\hat{p}_{t,j}\geq\frac{25}{16}\frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}} \geq\frac{d}{4T_{t}}\ln\frac{2}{\delta_{m,T_{t}}}\), thus (I.6) can be applied and \(\beta_{t,j}\leq\frac{5}{2}\sqrt{\frac{8\hat{p}_{t,j}L_{\max}}{T_{t}}\ln\frac{2} {\delta}}\).

Therefore, conditional on Good, with probability at least \(1-KN\delta_{m,T_{t}},\mathrm{RE}\leq 2\xi_{t}\). 

Proof of Lemma G.5.: By Lemma I.1, I.2 and I.3, conditional on Good, with probability at least \(1-(K\delta_{v,T_{t}}+N\delta_{d,T_{t}}+KN\delta_{m,T_{t}})\), \(\left|\hat{\Delta}_{t}(x,\tilde{x})-\Delta(x,\tilde{x})\right|\leq\rho_{t}(x, \tilde{x})\). This finishes the proof of the first result in Lemma G.5.

We then accumulates all the error probabilities. By the choices of \(\delta_{v,T_{t}}=\frac{\delta}{15KT_{t}^{3}},\delta_{d,T_{t}}=\frac{\delta}{ 15NT_{t}^{3}},\delta_{m,T_{t}}=\frac{\delta}{15KNT_{t}^{3}}\),

\[\sum_{T_{t}=1}^{\infty}K\delta_{v,T_{t}}+N\delta_{d,T_{t}}+KN \delta_{m,T_{t}} =\sum_{T_{t}=1}^{\infty}K\cdot\frac{\delta}{15KT_{t}^{3}}+N\cdot \frac{\delta}{15NT_{t}^{3}}+KN\cdot\frac{\delta}{15KNT_{t}^{3}}\] \[=\sum_{T_{t}=1}^{\infty}\frac{3\delta}{15T_{t}^{3}}\] \[\leq\frac{\delta}{4}\]

Note that there is an reversion step at Line \(18\) Algorithm 1, for each \(T\in\mathbb{N}\), there are at most two time steps \(t_{1}<t_{2}\) with \(T_{t_{1}}=T_{t_{2}}\). Therefore,

\[\sum_{t=1}^{\infty}K\delta_{v,T_{t}}+N\delta_{d,T_{t}}+KN\delta_{m,T_{t}}\leq 2 \sum_{T_{t}=1}^{\infty}K\delta_{v,T_{t}}+N\delta_{d,T_{t}}+KN\delta_{m,T_{t}} \leq\frac{\delta}{2}\]

This proves the second statement. 

## Appendix J Upper Bound of \(\mathrm{PS}\varepsilon\mathrm{BAI}\): Proof of Theorem 3.2

Theorem 3.2 is proved in this section by three steps.

* Firstly, we show that the recommended arm \(\hat{x}_{\varepsilon}\) is an \(\varepsilon\)-best arm upon the termination of the algorithm in Lemma J.1.
* Secondly, we present a sufficient condition for the termination of the algorithm in terms of \(T_{t}\) in Lemma G.6.
* Lastly, we show that \(T_{\tau}\) is bounded by a constant fraction of \(\tau\) and thus, obtain an upper bound on \(\tau\).

**Step 1:**

According to Lemma G.5, \(\mathrm{CI}_{t}\) holds with probability \(1-(K\delta_{v,T_{t}}+N\delta_{d,T_{t}}+KN\delta_{m,T_{t}})\). Conditional on the good event Good in (G.1) and the event \(\mathrm{CI}_{t}\) (the mean gaps are well approximated at time step \(t\)), we expect the recommended arm will be an \(\varepsilon\)-optimal arm. This is formalized in the following lemma.

**Lemma J.1**.: _Conditional on Good and \(\mathrm{CI}_{t}\), if the algorithm stops at time step \(t\), the recommended arm \(\hat{x}_{\varepsilon}=x_{t}^{*}\) is an \(\varepsilon\)-best arm._

Proof of Lemma J.1.: If \(\hat{x}_{\varepsilon}=x^{*}\), the lemma holds.

If \(\hat{x}_{\varepsilon}\neq x^{*}\), according to the termination condition (3.4)

\[\min_{x:x\neq\hat{x}_{\varepsilon}}\hat{\Delta}_{t}(\hat{x}_{\varepsilon},x)- \rho_{t}(\hat{x}_{\varepsilon},x)>-\varepsilon\]

we have

\[\Delta(\hat{x}_{\varepsilon},x^{*})\geq\hat{\Delta}_{t}(\hat{x}_{\varepsilon},x ^{*})-\rho_{t}(\hat{x}_{\varepsilon},x^{*})\geq\min_{x:x\neq\hat{x}_{ \varepsilon}}\hat{\Delta}_{t}(\hat{x}_{\varepsilon},x)-\rho_{t}(\hat{x}_{ \varepsilon},x)>-\varepsilon\]

where the first inequality holds due to \(\mathrm{CI}_{t}\). This indicates \(\Delta(x^{*},\hat{x}_{\varepsilon})\leq\varepsilon\) and thus the recommended arm \(\hat{x}_{\varepsilon}=x_{t}^{*}\) is an \(\varepsilon\)-best arm.

**Step 2:**

**Lemma G.6**.: _Conditional on_ Good _and_ CI_, the recommended arm \(\hat{x}_{\varepsilon}\in\mathcal{X}_{\varepsilon}\) and when Algorithm 1 terminates, the order of \(T_{t}\) is upper bounded by (3.6)._

Proof of Lemma G.6.: By Lemma J.1, \(\hat{x}_{\varepsilon}\in\mathcal{X}_{\varepsilon}\). Note that for any \(x\neq\hat{x}_{\varepsilon}\), when

\[\begin{cases}2\rho_{t}(x,\hat{x}_{\varepsilon})\leq\Delta(x,\hat{x}_{ \varepsilon})+\varepsilon,\quad\hat{x}_{\varepsilon}\neq x^{*}\text{ and }x=x^{*},\\ \rho_{t}(\hat{x}_{\varepsilon},x)+\rho_{t}(x^{*},x)\leq\Delta(x^{*},x)+ \varepsilon,\quad\text{otherwise}.\end{cases}\] (J.1)

By utilizing \(\mathrm{CI}_{t}\), we have

\[\begin{cases}\hat{\Delta}_{t}(\hat{x}_{\varepsilon},x^{*})-\rho_{t}(\hat{x}_ {\varepsilon},x^{*})\geq\hat{\Delta}_{t}(x^{*},\hat{x}_{\varepsilon})-\rho_{ t}(\hat{x}_{\varepsilon},x^{*})\geq\Delta_{t}(x^{*},\hat{x}_{\varepsilon})-2 \rho_{t}(x^{*},\hat{x}_{\varepsilon})\geq-\varepsilon,\\ \hat{x}_{\varepsilon}\neq x^{*}\text{ and }x=x^{*},\\ \end{cases}\]

\[\hat{\Delta}_{t}(\hat{x}_{\varepsilon},x)-\rho_{t}(\hat{x}_{\varepsilon},x) \geq\hat{\Delta}_{t}(x^{*},x)-\rho_{t}(\hat{x}_{\varepsilon},x)\geq\Delta(x^{ *},x)-\rho_{t}(x^{*},x)-\rho_{t}(\hat{x}_{\varepsilon},x)\geq-\varepsilon,\\ \text{otherwise}.\]

Therefore, if (J.1) hold for all \(x\neq\hat{x}_{\varepsilon}\), the algorithm must have stopped, i.e., it is sufficient to have the following for any \(x\neq\hat{x}_{\varepsilon}\):

\[\begin{cases}\rho_{t}(x^{*},\hat{x}_{\varepsilon})\leq\frac{\Delta(x^{*},\hat{ x}_{\varepsilon})+\varepsilon}{2},\quad\hat{x}_{\varepsilon}\neq x^{*}\text{ and }x=x^{*},\\ \rho_{t}(\hat{x}_{\varepsilon},x)\leq\frac{\Delta(x^{*},x)+ \varepsilon}{2}\,\rho_{t}(x^{*},x)\leq\frac{\Delta(x^{*},x)+ \varepsilon}{2},\quad\text{otherwise}.\end{cases}\]

Lemma J.2 gives an upper bound on the total number of time steps in Exp phases at which (J.1) must hold for any two arms \(x_{\varepsilon}\in\mathcal{X}_{\varepsilon},x\in\mathcal{X}\setminus\{x_{ \varepsilon}\}\).

**Lemma J.2**.: _For any two arms \((x_{\varepsilon},x)\), where \(x\neq x_{\varepsilon},x^{*}\), when_

\[T_{t} =\frac{6400\ln 6400\cdot d}{\left(\Delta(x^{*},x)+\varepsilon \right)^{2}}\ln\frac{Kd/\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}{\delta}\] \[\qquad\qquad+6400\ln 6400\cdot\mathrm{H}_{\mathrm{DE}}(x_{ \varepsilon},x)\ln\frac{N\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x)}{\delta}\] \[\qquad\qquad+\frac{3200\sqrt{2}\ln 3200\sqrt{2}\cdot NL_{\max}}{ \Delta(x^{*},x)+\varepsilon}\ln\frac{\frac{KN_{\max}}{\Delta(x^{*},x)+ \varepsilon}}{\delta}\] (J.2) \[=\tilde{O}\left(\frac{d}{\left(\Delta(x^{*},x)+\varepsilon\right) ^{2}}\ln\frac{1}{\delta}+\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x)\ln\frac{1 }{\delta}+\frac{NL_{\max}}{\Delta(x^{*},x)+\varepsilon}\ln\frac{1}{\delta}\right)\]

_where_

\[\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x):=\frac{L_{\max}}{\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}\left(\sum_{j=1}^{N}\sqrt{\min\left\{16p_{j},\frac{1 }{4}\right\}}|\Delta_{j}(x_{\varepsilon},x)+\varepsilon|\right)^{2},\]

_we must have_

\[\rho_{t}(x_{\varepsilon},x)\leq\frac{\Delta(x^{*},x)+\varepsilon}{2}\]

By taking the maximum of (J.2) over all \(\varepsilon\)-best arms and the suboptimal arms, we get

\[\tilde{T}:= \max_{x_{\varepsilon}\in\mathcal{X}_{\varepsilon},x\neq x_{ \varepsilon},x^{*}}\frac{6400\ln 6400\cdot d}{\left(\Delta(x^{*},x)+\varepsilon \right)^{2}}\ln\frac{Kd/\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}{\delta}\] \[\qquad+6400\ln 6400\cdot\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x)\ln \frac{N\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x)}{\delta}\] \[\qquad+\frac{3200\sqrt{2}\ln 3200\sqrt{2}\cdot NL_{\max}}{\Delta(x^{*},x )+\varepsilon}\ln\frac{\frac{KN_{\max}}{\Delta(x^{*},x)+\varepsilon}}{\delta}\] (J.3) \[=\tilde{O}\left(\max_{x_{\varepsilon}\in\mathcal{X}_{\varepsilon},x \neq x_{\varepsilon},x^{*}}\frac{d}{\left(\Delta(x^{*},x)+\varepsilon\right)^{2} }\ln\frac{1}{\delta}+\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x)\ln\frac{1}{ \delta}+\frac{NL_{\max}}{\Delta(x^{*},x)+\varepsilon}\ln\frac{1}{\delta} \right).\]Proof of Lemma J.2.: Let \(c_{v},c_{d},c_{m}\in(0,1)\) be constants, satisfying \(c_{v}+c_{d}+2c_{m}=1\). By the definition of \(\rho_{t}(x_{\varepsilon},x)\) in (3.3), it is sufficient to have

\[\left\{\begin{aligned} & 2\alpha_{t}\leq c_{v}\frac{\Delta(x^{*},x)+ \varepsilon}{2}\\ &\sum_{j=1}^{N}\beta_{t,j}|\hat{\Delta}_{t,j}^{\operatorname{ clip}_{2}}(x_{\varepsilon},x)+\zeta_{t}(x_{\varepsilon},x)|\leq(c_{d}+c_{m}) \frac{\Delta(x^{*},x)+\varepsilon}{2}\\ & 2\xi_{t}\leq c_{m}\frac{\Delta(x^{*},x)+\varepsilon}{2}\end{aligned}\right.\]

where we take \(\zeta_{t}(x_{\varepsilon},x)=\varepsilon\) for theoretical simplicity, but we adopt \(\zeta_{t}(x,\tilde{x})=\arg\min_{\zeta_{t}(x,\tilde{x})\in\mathbb{R}}\sum_{j= 1}^{N}\beta_{t,j}(\hat{\Delta}_{t,j}(x,\tilde{x})+\zeta_{t}(x,\tilde{x}))^{2} =-\frac{\sum_{j=1}^{N}\beta_{t,j}\hat{\Delta}_{t,j}(x,\tilde{x})}{\sum_{j=1}^ {N}\beta_{t,j}}\) in the algorithm, which still enjoys the theoretical guarantee.

**VE Term** According to the definition of \(\alpha_{t}\), we need to bound:

\[\alpha_{t}\leq c_{v}\frac{\Delta(x^{*},x)+\varepsilon}{4}\] \[\Leftrightarrow 5\sqrt{\frac{d}{T_{t}}\ln\frac{2}{\delta_{v,T_{t}}}}\leq c_{v} \frac{\Delta(x^{*},x)+\varepsilon}{4}\]

By a coarse estimation, it is sufficient to have

\[T_{t}\geq\frac{\bar{c}_{v}d}{\left(\Delta(x^{*},x)+\varepsilon \right)^{2}}\ln\frac{Kd/\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}{\delta }=O\left(\frac{d}{\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}\ln\frac{Kd/ \left(\Delta(x^{*},x)+\varepsilon\right)^{2}}{\delta}\right)\]

where \(\bar{c}_{v}=\frac{6400}{c_{v}^{2}}\ln\frac{6400}{c_{v}^{2}}\).

**DE Term** The difficulty lies at the DE term.

\[\sum_{j=1}^{N}\beta_{t,j}|\hat{\Delta}_{t,j}^{\operatorname{clip }_{2}}(x_{\varepsilon},x)+\zeta_{t}(x_{\varepsilon},x)|\] \[\leq\sum_{j=1}^{N}\beta_{t,j}|\hat{\Delta}_{t,j}^{\operatorname{ clip}_{2}}(x_{\varepsilon},x)+\varepsilon|\] \[\leq\sum_{j:\psi_{t,j}>\hat{p}_{t,j}}\beta_{t,j}|\hat{\Delta}_{t, j}^{\operatorname{clip}_{2}}(x_{\varepsilon},x)+\varepsilon|\] \[\quad+\sum_{j:\psi_{t,j}=\hat{p}_{t,j}}\beta_{t,j}|\Delta_{j}(x_{ \varepsilon},x)+\varepsilon|+\beta_{t,j}|\hat{\Delta}_{t,j}^{\operatorname{ clip}_{2}}(x_{\varepsilon},x)-\Delta_{j}(x_{\varepsilon},x)|\] \[\leq\sum_{j:\psi_{t,j}>\hat{p}_{t,j}}\beta_{t,j}(2+\varepsilon)+ \sum_{j:\psi_{t,j}=\hat{p}_{t,j}}\beta_{t,j}|\hat{\Delta}_{t,j}^{\operatorname{ clip}_{2}}(x_{\varepsilon},x)-\Delta_{j}(x_{\varepsilon},x)|\] \[\quad+\sum_{j:\psi_{t,j}=\hat{p}_{t,j}}\beta_{t,j}|\Delta_{j}(x_{ \varepsilon},x)+\varepsilon|\] \[\leq 2\xi_{t}+\sum_{j:\psi_{t,j}=\hat{p}_{t,j}}\beta_{t,j}|\Delta_{j }(x_{\varepsilon},x)+\varepsilon|\]

We will upper bound \(2\xi_{t}\) by \(c_{m}\frac{\Delta(x^{*},x)+\varepsilon}{2}\) first; the second term will be included in the RE term and analyzed later. Therefore, it is sufficient to have

\[\sum_{j:\psi_{t,j}=\hat{p}_{t,j}}\beta_{t,j}|\Delta_{j}(x_{\varepsilon},x)+ \varepsilon|\leq c_{d}\frac{\Delta(x^{*},x)+\varepsilon}{2}\] (J.4)By the definition of \(\beta_{t,j}\) in (I.2) and Lemma K.3, we get

\[\beta_{t,j}=\frac{5}{2}\sqrt{\frac{2\phi_{t,j}L_{\max}}{T_{t}}\ln\frac{2}{\delta_ {d,T_{t}}}}\leq\frac{5}{2}\sqrt{\frac{2\min\left\{16p_{j},\frac{1}{4}\right\}L_ {\max}}{T_{t}}}\ln\frac{2}{\delta_{d,T_{t}}}\] (J.5)

**Lemma K.3**.: _If \(\psi_{t,j}=\hat{p}_{t,j}\), then_

\[\phi_{t,j}\leq\min\left\{16p_{j},\frac{1}{4}\right\}.\]

Therefore, in order for (J.4) to hold, it is sufficient to have

\[\sum_{j:\psi_{t,j,2}=\hat{p}_{t,j}}\frac{5}{2}\sqrt{\frac{2\min \left\{16p_{j},\frac{1}{4}\right\}L_{\max}}{T_{t}}}\ln\frac{2}{\delta_{d,T_{t} }}|\Delta_{j}(x_{\varepsilon},x)+\varepsilon|\leq c_{d}\frac{\Delta(x^{*},x)+ \varepsilon}{2}\] \[\Leftrightarrow \frac{5}{2}\sqrt{\frac{2L_{\max}}{T_{t}}}\ln\frac{2}{\delta_{d,T _{t}}}\sum_{j:\psi_{t,j,2}=\hat{p}_{t,j}}\sqrt{\min\left\{16p_{j},\frac{1}{4} \right\}}|\Delta_{j}(x_{\varepsilon},x)+\varepsilon|\leq c_{d}\frac{\Delta(x^ {*},x)+\varepsilon}{2}\] \[\Leftarrow \frac{5}{2}\sqrt{\frac{2L_{\max}}{T_{t}}}\ln\frac{2}{\delta_{d,T _{t}}}\sum_{j=1}^{N}\sqrt{\min\left\{16p_{j},\frac{1}{4}\right\}}|\Delta_{j}(x _{\varepsilon},x)+\varepsilon|\leq c_{d}\frac{\Delta(x^{*},x)+\varepsilon}{2}\] \[\Leftarrow T_{t}\geq\bar{c}_{d}\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x) \ln\frac{N\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x)}{\delta}=O\left(\mathrm{H }_{\mathrm{DE}}(x_{\varepsilon},x)\ln\frac{N\mathrm{H}_{\mathrm{DE}}(x_{ \varepsilon},x)}{\delta}\right)\]

where \(\bar{c}_{d}=\frac{100}{c_{d}^{2}}\ln\frac{100}{c_{d}^{2}}\).

**RE Term** By the definition of \(\xi_{t}\) in (I.2), it is sufficient to have

\[25\sqrt{2}\frac{NL_{\max}}{T_{t}}\ln\frac{2}{\delta_{m,T_{t}}} \leq c_{m}\frac{\Delta(x^{*},x)+\varepsilon}{2}\] \[\Leftarrow T_{t}\geq\frac{\bar{c}_{m}\cdot NL_{\max}}{\Delta(x^{*},x)+ \varepsilon}\ln\frac{\frac{KNL_{\max}}{\Delta(x^{*},x)+\varepsilon}}{\delta}=O \left(\frac{NL_{\max}}{\Delta(x^{*},x)+\varepsilon}\ln\frac{\frac{KNL_{\max} }{\Delta(x^{*},x)+\varepsilon}}{\delta}\right)\]

where \(\bar{c}_{m}=\frac{400\sqrt{2}}{c_{m}}\ln\frac{400\sqrt{2}}{c_{m}}\).

By taking \(c_{v}=\frac{3}{4},c_{d}=\frac{1}{8}\) and \(c_{m}=\frac{1}{8}\), the upper bound on \(T_{t}\) can be concluded as

\[T_{t}=\frac{6400\ln 6400\cdot d}{\left(\Delta(x^{*},x)+ \varepsilon\right)^{2}}\ln\frac{Kd/\left(\Delta(x^{*},x)+\varepsilon\right)^{ 2}}{\delta}+6400\ln 6400\cdot\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x)\ln\frac{N \mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x)}{\delta}\] \[\qquad\qquad+\frac{3200\sqrt{2}\ln 3200\sqrt{2}\cdot NL_{\max}}{ \Delta(x^{*},x)+\varepsilon}\ln\frac{\frac{KNL_{\max}}{\Delta(x^{*},x)+ \varepsilon}}{\delta}\] \[=O\left(\frac{d}{\left(\Delta(x^{*},x)+\varepsilon\right)^{2}} \ln\frac{Kd/\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}{\delta}\right.\] \[\qquad\qquad\left.+\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x) \ln\frac{N\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x)}{\delta}+\frac{NL_{ \max}}{\Delta(x^{*},x)+\varepsilon}\ln\frac{\frac{KNL_{\max}}{\Delta(x^{*},x)+ \varepsilon}}{\delta}\right)\] \[=\tilde{O}\left(\frac{d}{\left(\Delta(x^{*},x)+\varepsilon \right)^{2}}\ln\frac{1}{\delta}+\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x) \ln\frac{1}{\delta}+\frac{NL_{\max}}{\Delta(x^{*},x)+\varepsilon}\ln\frac{1 }{\delta}\right).\]

**Step 3:**

**Theorem 3.2**.: _Define the context distribution estimation (DE) hardness parameter_

\[\mathrm{H}_{\mathrm{DE}}(x_{\varepsilon},x):=\frac{L_{\max}}{\left(\Delta(x^{* },x)+\varepsilon\right)^{2}}\bar{H}(x_{\varepsilon},x)\]_where \(\bar{H}(x_{x},x):=\big{(}\sum_{j=1}^{N}\sqrt{\min\left\{16p_{j},1/4\right\}}|\Delta_ {j}(x_{x},x)+\varepsilon|\big{)}^{2}\). Under Assumption 1, with probability at least \(1-\delta\), \(\text{PS\'{e}BAI}\) identifies an \(\varepsilon\)-optimal arm and its sample complexity is_

\[\tilde{O}\Bigg{(}\max_{\begin{subarray}{c}x_{x}\in\mathcal{X}_{t}\\ x\neq x_{x},x^{*}\end{subarray}}\underbrace{\frac{d}{\left(\Delta(x^{*},x)+ \varepsilon\right)^{2}}\ln\frac{1}{\delta}}_{T_{\text{V}}(x)}+\underbrace{ \operatorname{H}_{\text{DE}}(x_{\varepsilon},x)\ln\frac{1}{\delta}}_{T_{\text {D}}(x_{\varepsilon},x)}+\underbrace{\frac{NL_{\max}}{\Delta(x^{*},x)+ \varepsilon}\ln\frac{1}{\delta}}_{T_{\text{R}}(x)}\Bigg{)}.\] (3.6)

Proof of Theorem 3.2.: By Assumption 1, and the choice of the parameters, Lemma G.4 indicates Good is guaranteed with probability at least \(1-\frac{\delta}{2}\).

Note that some arm pulls are not counted in \(T_{t}\):

* In every \(\gamma\) time steps, Algorithm 1 enters the CD phase to select a CD sample.
* When a changepoint is detected, Algorithm 1 steps into the CA phase, where \(\frac{w}{2}\) arms are sampled in Algorithm 4.
* During the CA phase, we abandon \(\frac{w\gamma}{2}\) samples.

Therefore, when \(t\) is large (or after the first stationary segment)

\[t\leq T_{t}\cdot\frac{\gamma}{\gamma-1}\frac{L_{\min}}{L_{\min}-w\gamma-\frac{ w}{2}}\leq T_{t}\cdot\frac{\gamma}{\gamma-1}\frac{L_{\min}}{L_{\min}-\frac{3w \gamma}{2}}.\] (J.6)

As \(\gamma\geq 2\) and \(w\gamma\) are set to be upper bounded by \(\frac{L_{\min}}{3}\), so the fractions above is upper bounded by an absolute constant \(4\), e.g., with \(\gamma=2\) and \(w=\frac{L_{\min}}{6}\), the constant is \(4\). Therefore, \(t\) is of the same order as \(T_{t}\). By Lemma G.6, (3.6) holds with probability \(1-\delta\). 

## Appendix K Analysis of \(\text{PS\'{e}BAI}\): Technical Lemmas

**Lemma K.1**.: _Given any \(j\in[N]\) and \(T_{t}\geq\frac{2L_{\max}}{9}\ln\frac{2}{\delta_{d,T_{t}}}\), \(\tilde{\beta}_{t,j}\leq\beta_{t,j}\)._

Proof of Lemma k.1.: Recall

\[\phi_{t,j}=\min\left\{4\max\left\{\tilde{p}_{t,j},\frac{25}{4}\frac{L_{\max} }{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\right\},\frac{1}{4}\right\}\]

The proof is scheduled in \(2\) steps.

**Step 1**: Upper bound \(\sqrt{\frac{2p_{j}(1-p_{j})L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}\).

When \(\frac{L_{\max}}{3T_{t}^{2}}\ln\frac{2}{\delta_{d,T_{t}}}\leq\sqrt{\frac{2p_{j} (1-p_{j})L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}\), we have

\[\tilde{\beta}_{t,j}=\frac{5}{2}\sqrt{\frac{2p_{j}(1-p_{j})L_{\max}}{T_{t}}\ln \frac{2}{\delta_{d,T_{t}}}}\]

As \(p_{j}(1-p_{j})\leq\frac{1}{4},\forall p_{j}\in(0,1)\), this naive bound gives \(\tilde{\beta}_{t,j}\leq\frac{5}{2}\sqrt{\frac{2\cdot\frac{1}{4}\cdot L_{\max} }{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}\).

If \(T_{t,j}>0\), according to Lemma K.2,

\[\tilde{\beta}_{t,j} =\frac{5}{2}\sqrt{\frac{2p_{j}(1-p_{j})L_{\max}}{T_{t}}\ln\frac{2} {\delta_{d,T_{t}}}}\] \[\leq\frac{5}{2}\sqrt{\frac{2p_{j}T_{t,j}L_{\max}}{T_{t}T_{t,j}} \ln\frac{2}{\delta_{d,T_{t}}}}\] \[\leq\frac{5}{2}\sqrt{\frac{2\tilde{p}_{t,j}L_{\max}}{T_{t}}\cdot 4 \max\left\{1,\frac{25}{4}\frac{L_{\max}}{T_{t,j}}\ln\frac{2}{\delta_{d,T_{t}}} \right\}\ln\frac{2}{\delta_{d,T_{t}}}},\]thus we have

\[\tilde{\beta}_{t,j}\leq\frac{5}{2}\sqrt{\frac{2\phi_{t,j}L_{\max}}{T_{t}}\ln\frac{ 2}{\delta_{d,T_{t}}}}\] (K.1)

If \(T_{t,j}=0\), i.e., the latent context \(j\) has never been observed and \(\hat{p}_{t,j}=0\), we have

\[\tilde{\beta}_{t,j} =\frac{5}{2}\sqrt{\frac{2p_{j}(1-p_{j})L_{\max}}{T_{t}}\ln\frac{ 2}{\delta_{d,T_{t}}}}\] \[\leq\frac{5}{2}\sqrt{\frac{2\tilde{\beta}_{t,j}(1-\tilde{\beta} _{t,j})L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}\] \[\Rightarrow \tilde{\beta}_{j}(t,\delta)\leq\frac{\frac{25}{8}L_{\max}\ln\frac {2}{\delta_{d,T_{t}}}}{T_{t}+\frac{25}{8}L_{\max}\ln\frac{2}{\delta_{d,T_{t}}} }\leq\frac{25}{8}\frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\]

Take the trivial bound into consideration and observe that \(\phi_{t,j}=\min\{\frac{25L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}},\frac{ 1}{4}\}\) and that

\[\frac{25}{8}\frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\leq\frac{25 \sqrt{2}L_{\max}}{2T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}=\frac{5}{2}\sqrt{\frac {2\phi_{t,j}L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}.\]

Thus, (K.1) also holds for \(T_{t,j}=0\).

To conclude, we have

\[\tilde{\beta}_{t,j} =\frac{5}{2}\max\left\{\frac{L_{\max}}{3T_{t}}\ln\frac{2}{\delta _{d,T_{t}}},\sqrt{\frac{2p_{j}(1-p_{j})L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T _{t}}}}\right\}\] \[\leq\frac{5}{2}\max\left\{\frac{L_{\max}}{3T_{t}}\ln\frac{2}{ \delta_{d,T_{t}}},\sqrt{\frac{2\phi_{t,j}L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}\right\}\]

**Step 2**: Simplify the bound. Recall that

\[\phi_{t,j}=\min\left\{4\max\left\{\hat{p}_{t,j},\frac{25}{4}\frac{L_{\max}}{T _{t}}\ln\frac{2}{\delta_{d,T_{t}}}\right\},\frac{1}{4}\right\}\]

As \(T_{t}\geq\frac{2L_{\max}}{9}\ln\frac{2}{\delta_{d,T_{t}}}\), we have

\[\frac{L_{\max}}{3T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\leq\sqrt{\frac{2\cdot \frac{1}{4}L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}\]

According to the definition of \(\phi\), if \(\hat{p}_{t,j}\geq\frac{25}{4}\frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\), we have

\[\frac{L_{\max}}{3T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\leq\frac{5\sqrt{2}L_{ \max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\leq\sqrt{\frac{2\cdot 4\hat{p}_{t,j}L_{ \max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}\]

If \(\hat{p}_{t,j}\leq\frac{25}{4}\frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\), we have

\[\frac{L_{\max}}{3T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\leq\frac{25\sqrt{2}L_{ \max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}=\sqrt{\frac{2L_{\max}}{T_{t}}\ln \frac{2}{\delta_{d,T_{t}}}\cdot 25\frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}\]

Thus

\[\max\left\{\frac{L_{\max}}{3T_{t}}\ln\frac{2}{\delta_{d,T_{t}}},\sqrt{\frac{2 \phi_{t,j}L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}\right\}=\sqrt{\frac{2 \phi_{t,j}L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}\]

This gives us the desired result. 

**Lemma K.2**.: _When \(\tilde{\beta}_{t,j}=\frac{5}{4}\sqrt{\frac{2p_{j}(1-p_{j})L_{\max}}{T_{t}}\ln \frac{2}{\delta_{d,T_{t}}}}\) and \(T_{t,j}>0\), we have_

\[\frac{p_{j}}{T_{t,j}}\leq\frac{4}{T_{t}}\max\left\{1,\frac{25}{16}\frac{L_{ \max}}{T_{t,j}}\ln\frac{2}{\delta_{d,T_{t}}}\right\}\]Proof of Lemma k.2.: \[\frac{p_{j}}{T_{t,j}} =\frac{p_{j}T_{t}}{T_{t,j}T_{t}}\] \[\leq\frac{\hat{p}_{t,j}T_{t}+\frac{5}{4}\sqrt{2p_{j}(1-p_{j})L_{ \max}T_{t}\ln\frac{2}{\delta_{d,T_{t}}}}}{T_{t,j}T_{t}}\] \[=\frac{1}{T_{t}}+\frac{5}{4}\sqrt{\frac{p_{j}}{T_{t,j}}}\cdot \sqrt{\frac{1}{T_{t,j}}-\frac{p_{j}}{T_{t,j}}}\cdot\sqrt{\frac{2L_{\max}}{T_{t }}\ln\frac{2}{\delta_{d,T_{t}}}}\] \[\Rightarrow \frac{p_{j}}{T_{t,j}}\leq\frac{4}{T_{t}}\max\left\{1,\frac{25}{16 }\frac{L_{\max}}{T_{t,j}}\ln\frac{2}{\delta_{d,T_{t}}}\right\}\]

**Lemma k.3**.: _If \(\psi_{t,j}=\hat{p}_{t,j}\), then_

\[\phi_{t,j}\leq\min\left\{16p_{j},\frac{1}{4}\right\}.\]

Proof of Lemma k.3.: Recall to the definition of \(\phi_{t,j}\) in (I.2) and \(\psi_{t,j}\) in (I.8),

\[\phi_{t,j}=\min\left\{4\max\left\{\hat{p}_{t,j},\frac{25}{4}\frac{L_{\max}}{T_ {t}}\ln\frac{2}{\delta_{d,T_{t}}}\right\},\frac{1}{4}\right\},\;\psi_{t,j}= \max\left\{\hat{p}_{t,j},\frac{25}{4}\frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta _{d,T_{t}}}\right\},\]

we have

\[\hat{p}_{t,j}\geq\frac{25}{4}\frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t} }},\quad\phi_{t,j}=\min\left\{4\hat{p}_{t,j},\frac{1}{4}\right\}\]

We only need to upper bound \(\hat{p}_{t,j}\).

By (I.4),

\[\psi_{t,j} =\hat{p}_{t,j}\leq p_{j}+\frac{5}{2}\max\left\{\frac{L_{\max}}{3T _{t}}\ln\frac{2}{\delta_{d,T_{t}}},\sqrt{\frac{2p_{j}(1-p_{j})L_{\max}}{T_{t} }\ln\frac{2}{\delta_{d,T_{t}}}}\right\}\] \[\Rightarrow \psi_{t,j} \leq p_{j}+\frac{5}{2}\max\left\{\frac{4}{75}\psi_{t,j},\sqrt{p_{j }(1-p_{j})\frac{8}{25}\psi_{t,j}}\right\}\] \[=p_{j}+\max\left\{\frac{4}{15}\psi_{t,j},\sqrt{2p_{j}(1-p_{j}) \psi_{t,j}}\right\}\] \[\Rightarrow \psi_{t,j}\leq 4p_{j}\]

Thus \(\hat{p}_{t,j}=\psi_{t,j}\leq 4p_{j}\), and \(\phi_{t,j}\leq\min\left\{16p_{j},\frac{1}{4}\right\}\). 

## Appendix L Upper Bound of \(\text{PS}\varepsilon\text{BAI}^{+}\): Proof of Theorem 3.3

**Theorem 3.3**.: _The \(\text{PS}\varepsilon\text{BAI}^{+}\) algorithm is \((\varepsilon,\delta)\)-PAC and its expected sample complexity is_

\[\bar{O}\bigg{(}\min\left\{\max_{x_{\varepsilon}\in\mathcal{X}_{\varepsilon},x \neq x_{\varepsilon},x^{*}}T_{\mathrm{V}}(x)+T_{\mathrm{D}}(x_{\varepsilon},x) +T_{\mathrm{R}}(x),\,T_{\mathrm{V}}^{\mathrm{N}}+T_{\mathrm{D}}^{\mathrm{N}} \right\}\bigg{)}.\]

Proof.: We let \(\tau_{1}\) denote the stopping time of \(\text{PS}\varepsilon\text{BAI}\), \(\tau_{2}\) denote the stopping time of \(\text{N}\varepsilon\text{BAI}\), and \(\tau\) denote the stopping time of \(\text{PS}\varepsilon\text{BAI}^{+}\) when an identical sequence of samples and returns are applied to them. By the design of these algorithms, we have

\[\tau\leq\min\{\tau_{1},\tau_{2}\}.\]

\(\underline{\text{Part I}}\): Prove that \(\mathbb{P}(\hat{x}_{\varepsilon}\notin\mathcal{X}_{\varepsilon})\leq\delta\).

Let event \(\mathcal{E}_{1}=\mathbbm{1}\{\tau_{1}<\tau_{2}\}\cap 1\{\text{PS}\varepsilon\text{BAI}\) returns arm \(x_{\varepsilon}\) when it terminates\(\}\). Recall that \(\hat{x}_{\varepsilon}\) denotes the recommended arm of \(\text{N}\varepsilon\text{BAI}\) when it terminates and \(\hat{x}_{\varepsilon}\) denotes the recommended arm of PS\(\varepsilon\)BAI\({}^{+}\) when it terminates. The design of algorithms indicates that:

\[\dot{x}_{\varepsilon}=x_{\varepsilon}\text{ when }\mathcal{E}_{1}\text{ occurs, and }\dot{x}_{ \varepsilon}=\dot{x}_{\varepsilon}\text{ when }\mathcal{E}_{1}^{c}\text{ occurs.}\]

Moreover, with the performance guarantees of N\(\varepsilon\)BAI and PS\(\varepsilon\)BAI(shown in Proposition 3.1 and Theorem 3.2 individually), we have

\[\mathbb{P}[\dot{x}_{\varepsilon}\notin\mathcal{X}_{\varepsilon}] =\mathbb{P}[\dot{x}_{\varepsilon}\notin\mathcal{X}_{\varepsilon} |\mathcal{E}_{1}]\cdot\mathbb{P}[\mathcal{E}_{1}]+\mathbb{P}[\dot{x}_{ \varepsilon}\notin\mathcal{X}_{\varepsilon}|\mathcal{E}_{1}^{c}]\cdot\mathbb{ P}[\mathcal{E}_{1}^{c}]\] \[\leq\delta\cdot\mathbb{P}[\mathcal{E}_{1}]+\delta\cdot\mathbb{P} [\mathcal{E}_{1}^{c}]=\delta\cdot(\mathbb{P}[\mathcal{E}_{1}]+\mathbb{P}[ \mathcal{E}_{1}^{c}])=\delta.\]

**Part II**: Derive the expected sample complexity of PS\(\varepsilon\)BAI\({}^{+}\).

**We first derive the conditional expectation of the stopping time of** PS\(\varepsilon\)BAI. By the same argument as in (J.6), \(T_{t}\leq t\leq 4T_{t}\) for any \(t\). Therefore, it is sufficient to upper bound \(\mathbb{E}[T_{\tau_{1}}]\) and \(\mathbb{E}[\tau_{1}]\) can be upper bounded by \(4\mathbb{E}[T_{\tau_{1}}]\).

According to Lemma G.6 and Lemma G.6, when both events Good and CI occur, PS\(\varepsilon\)BAI terminates with \(T_{\tau_{1}}\) satisfying \(T_{\tau_{1}}\leq\tilde{T}\), where \(\tilde{T}\) is defined in (J.3) and as below:

\[\tilde{T}:=\max_{x_{\varepsilon}\in\mathcal{X}_{\varepsilon},x\neq x_{ \varepsilon},x^{*}}\frac{6400\ln 6400\cdot d}{\left(\Delta(x^{*},x)+\varepsilon \right)^{2}}\ln\frac{Kd/\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}{\delta}\]

Given time step \(t\) with \(T_{t}\geq 2\tilde{T}\) (thus \(t\geq 8\tilde{T}\)), we will upper bound \(\mathbb{P}[\tau_{1}>t]\) in the following. We firstly upper bound \(\mathbb{P}\left[T_{\tau_{1}}>T_{t}\right]\). Note that

\[\mathbb{P}\left[T_{\tau_{1}}>T_{t}\right] =\mathbb{P}\left[T_{\tau_{1}}>T_{t}|T_{\tau_{1}}\geq\frac{T_{t}}{ 2}+1\right]\mathbb{P}\left[T_{\tau_{1}}\geq\frac{T_{t}}{2}+1\right]\] \[\qquad+\mathbb{P}\left[T_{\tau_{1}}>T_{t}|T_{\tau_{1}}<\frac{T_{t }}{2}+1\right]\mathbb{P}\left[T_{\tau_{1}}<\frac{T_{t}}{2}+1\right]\] \[\leq\mathbb{P}\left[T_{\tau_{1}}>T_{t}|T_{\tau_{1}}\geq\frac{T_{t }}{2}+1\right].\]

If PS\(\varepsilon\)BAI fails to terminate with \(T_{\tau_{1}}\leq\frac{T_{t}}{2}\), it implies that event \(\mathrm{Good}\bigcap\left(\bigcap_{s\in\mathcal{I}}\mathrm{CI}_{s}\right)\) fails, where \(\mathcal{I}=\{s:\frac{T_{t}}{2}+1\leq T_{s}\leq T_{t}\}\). Hence,

\[\mathbb{P}\left[T_{\tau_{1}}>T_{t}\right] \leq\mathbb{P}\left[T_{\tau_{1}}>T_{t}\middle|T_{\tau_{1}}\geq \frac{T_{t}}{2}+1\right]\] \[\leq\mathbb{P}\left[\mathrm{Good}^{c}\bigcup\left(\bigcup_{s\in \mathcal{I}}\mathrm{CI}_{s}^{c}\right)\right]\] \[\leq\mathbb{P}\left[\mathrm{Good}^{c}\right]+\mathbb{P}\left[ \mathrm{Good}\bigcap\left(\bigcup_{s\in\mathcal{I}}\mathrm{CI}_{s}^{c}\right)\right]\] \[\leq\mathbb{P}\left[\mathrm{Good}^{c}\right]+\mathbb{P}\left[ \left(\bigcup_{s\in\mathcal{I}}\mathrm{CI}_{s}^{c}\right)\middle|\mathrm{Good}\right]\] \[\overset{(a)}{\leq}\frac{\delta}{2\tau^{*}}+2\sum_{T_{s}=T_{t}/ 2+1}^{T_{t}}\left(K\delta_{v,T_{s}}+N\delta_{d,T_{s}}+KN\delta_{m,T_{s}}\right)\] \[\overset{(b)}{\leq}\frac{\delta}{2\tau^{*}}+2\sum_{T_{s}=T_{t}/ 2+1}^{T_{t}}\frac{\delta}{5T_{s}^{3}}\leq\frac{\delta}{2\tau^{*}}+2\int_{T_{t}/ 2}^{T_{t}}\frac{\delta}{5x^{3}}\;\mathrm{d}x=\frac{\delta}{2\tau^{*}}+\frac{3 \delta}{5T_{t}^{2}},\]where \((a)\) is obtained by applying Lemma G.5 to time steps in \(\mathcal{I}\cap\mathcal{T}_{t}\) (i.e., the Exp time steps in \(\mathcal{I}\)) and note that there are at most two time steps \(t_{1}<t_{2}\) with \(T_{t_{1}}=T_{t_{2}}\) due to the reversion step; \((b)\) is derived by substituting \(\delta_{v,T_{t}}=\frac{\delta}{5KT_{t}^{2}},\delta_{d,T_{t}}=\frac{\delta}{18NT _{t}^{2}},\delta_{m,T_{t}}=\frac{\delta}{15KT_{t}^{3}}\) which are used to define the confidence radius \(\rho\) in (3.3). By using the fact that \(4T_{\tau_{1}}\geq\tau_{1}\), for any \(T_{t}\geq 2\tilde{T}\), we have

\[\mathbb{P}\left[\tau_{1}>4T_{t}\right]\leq\mathbb{P}\left[T_{\tau _{1}}>T_{t}\right]\leq\frac{\delta}{2\tau^{*}}+\frac{3\delta}{5T_{t}^{2}}\] \[\Rightarrow \mathbb{P}\left[\tau_{1}>4T_{t}+i\right]\leq\frac{\delta}{2\tau^ {*}}+\frac{3\delta}{5T_{t}^{2}},\quad i=0,1,2,3\] \[\Rightarrow \mathbb{P}\left[\tau_{1}>t\right]\leq\frac{\delta}{2\tau^{*}}+ \frac{48\delta}{5(t-4)^{2}},\quad\forall 8\tilde{T}\leq t\leq\tau^{*}.\]

This indicates for \(t\geq 8\tilde{T}\), the probability that PS\(\varepsilon\)BAI does not stop after \(t\) time steps is \(\frac{\delta}{2\tau^{*}}+\frac{48\delta}{5(t-4)^{2}}\). Therefore, by Tonelli's Theorem, we have

\[\mathbb{E}[\tau_{1}|8\tilde{T}<\tau_{1}\leq\tau^{*}] \leq\sum_{t=8\tilde{T}}^{\tau^{*}-1}\mathbb{P}[\tau_{1}>t]\leq\sum _{t=8\tilde{T}}^{\tau^{*}-1}\left(\frac{\delta}{2\tau^{*}}+\frac{48\delta}{5(t -4)^{2}}\right)\] \[\leq 1+\int_{8\tilde{T}-1}^{\tau^{*}-1}\frac{48\delta}{5(t-4)^{2}} \;\mathrm{d}t\leq 2.\] (L.1)

**Next, we bound \(\mathbb{E}\tau\), the expected sample complexity of PS\(\varepsilon\)BAI\({}^{+}\).**\(\mathbb{E}\tau\) can be decomposed as below:

\[\mathbb{E}\tau\leq 8\tilde{T}+\mathbb{E}[\tau|8\tilde{T}<\tau\leq\tau^{*} ]+\mathbb{E}[\tau|\tau>\tau^{*}].\] (L.2)

Since \(\tau=\min\{\tau_{1},\tau_{2}\}\) and \(\mathbb{P}[\min\{\tau_{1},\tau_{2}\}>t]\leq\mathbb{P}[\tau_{1}>t]\) for all \(t\), we have

\[\mathbb{E}[\tau|8\tilde{T}<\tau\leq\tau^{*}] =\sum_{t=8\tilde{T}}^{\tau^{*}-1}\mathbb{P}[\tau>t]=\sum_{t=8 \tilde{T}}^{\tau^{*}-1}\mathbb{P}[\min\{\tau_{1},\tau_{2}\}>t]\] \[\leq\sum_{t=8\tilde{T}}^{\tau^{*}-1}\mathbb{P}[\tau_{1}>t]= \mathbb{E}[\tau_{1}|8\tilde{T}<\tau_{1}\leq\tau^{*}].\] (L.3)

Besides, since PS\(\varepsilon\)BAI will terminate after \(\tau^{*}\) time steps, i.e., \(\mathbb{P}(\tau_{1}\leq\tau^{*})=1\). We have

\[\mathbb{E}[\tau|\tau\geq\tau^{*}]=\sum_{t=\tau^{*}}^{\infty} \mathbb{P}[\tau\geq t]\leq 1+\sum_{t=\tau^{*}+1}^{\infty}\mathbb{P}[\tau_{2} \geq t]=1+\mathbb{E}[\tau_{2}|\tau_{2}>\tau^{*}].\] (L.4)

Lemma F.1 indicates that \(\mathbb{P}[\tau_{2}\geq t]\leq\frac{\delta}{(\alpha-1)C_{3}(t/2)^{2}}\) for all \(t\geq T_{0}\), where

\[T_{0}=\frac{768(8L_{\max}+25d)}{\left(\varepsilon+\Delta_{\min }\right)^{2}}\ln\frac{768KC_{3}(8L_{\max}+25d)}{\left(\varepsilon+\Delta_{\min }\right)^{2}\delta},\quad C_{3}=\sum_{n=1}^{\infty}n^{-3}.\]

Since the order of \(T_{0}\) is apparently larger than \(\tau^{*}\), we have \(T_{0}\leq\tau^{*}\). Then, with the same method as in the proof of Proposition 3.1, the conditional sample complexity of N\(\varepsilon\)BAI can be bounded as follows:

\[\mathbb{E}[\tau_{2}|\tau_{2}>\tau^{*}]\leq\int_{\tau^{*}}^{+\infty }\mathbb{P}(\tau_{2}\geq x)\;\mathrm{d}x\leq\int_{\tau^{*}}^{+\infty}\frac{ \delta}{(\alpha-1)C_{3}(x/2)^{2}}\;\mathrm{d}x=\frac{\delta}{C_{3}\tau^{*}}.\] (L.5)

Substituting terms in (L.2) with (L.1), (L.3), (L.4) and (L.5), we have

\[\mathbb{E}\tau\leq 8\tilde{T}+3+\frac{\delta}{C_{3}\tau^{*}}.\]

Besides,

\[\mathbb{E}\tau\leq\mathbb{E}\tau_{2}\stackrel{{(a)}}{{\leq}}T_{0} +\frac{\delta}{(\alpha-1)(\alpha-2)(T_{0}/2)^{\alpha-2}},\]

Where (a) is shown in (F.1).

**Altogether**, we have

\[\mathbb{E}\tau\leq\min\left\{8\tilde{T}+3+\frac{\delta}{C_{3}\tau^{*}},\,8\tilde{ T}+3+\frac{\delta}{C_{3}\tau^{*}}\right\}.\]

## Appendix M Analysis of Lower Bound: Proof of Theorem 4.1

The dynamics for under our PSLB model is displayed in Dynamics 1.

```
1: The instance: \(\Lambda=(\mathcal{X},\Theta,P_{\theta},\mathcal{C})\)
2:while the algorithm does not stop at time step \(t\)do
3:if\(t\in\mathcal{C}\)then
4: The environment samples \(\theta^{*}_{j_{t}}\sim P_{\theta}\)
5:else
6:\(\theta^{*}_{j_{t}}=\theta^{*}_{j_{t-1}}\) (the environment does not change)
7:endif
8: The agent samples an arm \(x_{t}\) based on the history up to time \(t-1\).
9: The reward \(Y_{t,x_{t}}=x_{t}^{\top}\theta^{*}_{j_{t}}+\eta_{t}\) is revealed to the agent.
10:endwhile
11: Recommend an \(\varepsilon\)-best arm \(\hat{x}_{\varepsilon}\). ```

**Algorithm 1** Dynamics for piecewise-stationary linear bandits

To derive the lower bound in Theorem 4.1, we investigate two environments different from the one defined in Section 2 (and as in Dynamics 1):

\(\bullet\) Dynamics 2: the agent observes the index of current context \(j_{t}\), and the environment reduces to contextual linear bandits; the definition of Dynamics 2 and the lower bound under it are detailed in Appendix M.1.

\(\bullet\) Dynamics 3: the agent observes the changepoints in \(\mathcal{C}\) and context vector \(\theta^{*}_{j_{t}}\)'s, and hence she solely needs to estimate the distribution of contexts; the definition of Dynamics 3 and the lower bound under it are detailed in Appendix M.2.

We **first** derive a lower bound for \((\varepsilon,\delta)\)-BAI algorithms in Dynamics 2, that is, in contextual linear bandits.

**Corollary M.1**.: _For any \((\varepsilon,\delta)\)-PAC algorithm \(\pi\), there exists an instance \(\Lambda=(\mathcal{X},\Theta,P_{\theta},\mathcal{C})\) with Dynamics 2 such that_

\[\mathbb{E}[\tau]\geq T_{\varepsilon}(\Lambda)\log\frac{1}{2.4\delta}.\]

\[\text{where }\quad T_{\varepsilon}(\Lambda)^{-1}=\max_{\{v_{j}\in \boldsymbol{\Delta}_{\mathcal{X}}\}_{j=1}^{N}}\min_{\Lambda^{\prime}\in \operatorname{Alt}_{\Theta}(\Lambda)}\sum_{j=1}^{N}p_{j}\sum_{x\in\mathcal{X }}v_{j,x}\frac{(x^{\top}(\theta^{*}_{j}-\theta^{\prime}_{j}))^{2}}{2}\]

_is defined in Theorem 4.1. In addition, when \(|\mathcal{X}_{\varepsilon}|=1\),_

\[T_{\varepsilon}(\Lambda)=\min_{\{v_{j}\in\boldsymbol{\Delta}_{\mathcal{X}}\}_ {j=1}^{N}}\max_{x\neq x^{*}}\frac{\sum_{j=1}^{N}p_{j}\|x^{*}-x\|_{A(v_{j})^{-1 }}^{2}}{\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}.\]

This lower bound generalizes the result of [16] to the linear bandit setting.

We **next** study Dynamics 3. In this setting, the agent solely needs to estimate the distribution of contexts \(P_{\theta}\) with context samples. Once the agent obtains a good estimate of \(P_{\theta}\), she can identify an \(\varepsilon\)-optimal arm w.h.p. Hence, the lower bound on the complexity of an \((\varepsilon,\delta)\)-BAI algorithm is the product of the minimum length of a stationary segment and the minimum number of context samples/changepoints needed for distribution estimation.

**Corollary M.2**.: _For any \((\varepsilon,\delta)\)-PAC algorithm \(\pi\), there exists an instance \(\Lambda=(\mathcal{X},\Theta,P_{\theta},\mathcal{C})\) with Dynamics 3 such that \(\mathbb{E}\tau\geq c_{N_{\mathcal{C}}}\), where \(c_{N_{\mathcal{C}}}\) is the \(N_{\mathcal{C}}^{th}\) changepoint in the changepoint sequence \(\mathcal{C}\)._

**Altogether,** the sample complexity of an \((\varepsilon,\delta)\)-BAI algorithm in Dynamics 2 and 3 build up the lower bound in Theorem 4.1.

### Lower Bound for \(\varepsilon\)-BAI in Contextual Linear Bandits

In this section, we consider a sub-problem where the index of the current context \(j_{t}\) is revealed at each time step \(t\). The original piecewise-stationary problem becomes a contextual problem whose dynamics is presented in Algorithm 2.

```
1:The instance: \(\Lambda=(\mathcal{X},\Theta,P_{\theta},\mathcal{C})\)
2:while the algorithm does not stop at time step \(t\)do
3:if\(t\in\mathcal{C}\)then
4: The environment samples \(\theta_{j_{t}}^{*}\sim P_{\theta}\)
5:else
6:\(\theta_{j_{t}}^{*}=\theta_{j_{t-1}}^{*}\) (the environment does not change)
7:endif
8: Reveal \(j_{t}\) to the agent.
9: The agent samples an arm \(x_{t}\) based on the history up to time \(t-1\).
10: The reward \(Y_{t,x_{t}}=x_{t}^{\top}\theta_{j_{t}}^{*}+\eta_{t}\) is revealed to the agent.
11:endwhile
12: Recommend an \(\varepsilon\)-best arm \(\hat{x}_{\varepsilon}\). ```

**Dynamics 2** Dynamics for contextual linear bandits

**Corollary M.1**.: _For any \((\varepsilon,\delta)\)-PAC algorithm \(\pi\), there exists an instance \(\Lambda=(\mathcal{X},\Theta,P_{\theta},\mathcal{C})\) with Dynamics 2 such that_

\[\mathbb{E}[\tau]\geq T_{\varepsilon}(\Lambda)\log\frac{1}{2.4 \delta}.\] \[\text{where }\quad T_{\varepsilon}(\Lambda)^{-1}=\max_{\{v_{j} \in\mathbf{\Delta}_{\mathcal{X}}\}_{j=1}^{N}\Lambda^{\prime}\in\mathrm{Alt}_{ \Theta}(\Lambda)}\sum_{j=1}^{N}p_{j}\sum_{x\in\mathcal{X}}v_{j,x}\frac{(x^{ \top}(\theta_{j}^{*}-\theta_{j}^{\prime}))^{2}}{2}\]

_is defined in Theorem 4.1. In addition, when \(|\mathcal{X}_{\varepsilon}|=1\),_

\[T_{\varepsilon}(\Lambda)=\min_{\{v_{j}\in\mathbf{\Delta}_{\mathcal{X}}\}_{j=1 }^{N}}\max_{x\neq x^{*}}\frac{\sum_{j=1}^{N}p_{j}\|x^{*}-x\|_{A(v_{j})^{-1}}^{ 2}}{(\Delta(x^{*},x)+\varepsilon)^{2}}.\]

For simplicity, we consider the noise model is the Clipped Gaussian Distribution \(CN(1)\), i.e., \(\eta\sim CN(1)\) or \(P_{\eta}=CN(1)\).

**Definition M.3**.: _A random variable \(x\) follows the Clipped Gaussian Distribution with parameter \(\sigma\), denoted by \(x\sim CN(\sigma)\), if it has the probability distribution function_

\[f(x)=\frac{1}{(2\Phi(\sigma)-1)\cdot\sqrt{2\pi\sigma^{2}}}\exp\left(-\frac{x^{ 2}}{2\sigma^{2}}\right),\quad\forall x\in[-1,1]\]

_where \(\Phi(x)\) is the cumulative distribution function of the standard Gaussian distribution._

Some notations are introduced here:

* Given an instance \(\Lambda=(\mathcal{X},\Theta,P_{\theta},\mathcal{C})\), define the alternative instance \(\Lambda^{\prime}=(\mathcal{X},\Theta^{\prime},P_{\theta^{\prime}},\mathcal{C})\) with respect to \(\Lambda\), where \(\Theta^{\prime}=(\theta_{1}^{\prime},\ldots,\theta_{n}^{\prime})\in\mathbb{R}^ {d\times N}\) and \(P_{\theta^{\prime}}[\theta_{j}^{\prime}]=P_{\theta}[\theta_{j}^{*}]\), s.t. there \(\exists x\in\mathcal{X}\setminus\mathcal{X}_{\varepsilon},\forall x_{ \varepsilon}\in\mathcal{X}_{\varepsilon},s.t.,x_{\varepsilon}^{\top}\mathbb{ E}_{\theta^{\prime}\sim P_{\theta^{\prime}}}<x^{\top}\mathbb{E}_{\theta^{\prime}\sim P _{\theta^{\prime}}}-\varepsilon\). We denote the set containing all the alternative instance (w.r.t. \(\Lambda\)) as \(\mathrm{Alt}_{\Theta}(\Lambda)\).
* \(\mathcal{H}_{t}=(x_{s},Y_{s,x_{\varepsilon}},j_{s})_{s=1}^{d}\) is the observation history up to but not include time \(t\).
* \(N_{j,x}(t)=\sum_{s=1}^{t}\mathbbm{1}\{x_{s}=x,j_{s}=j\}\) is the number of times arm in which \(x\) is sampled under context \(j\). And \(N_{j}(t):=\sum_{x\in\mathcal{X}}N_{j,x}(t)\) is the number of times in which context \(j\) appears.
* \(\mathrm{kl}(p,q)=\mathrm{KL}(\mathrm{Bern}(p),\mathrm{Bern}(q))\) is the \(\mathrm{KL}\) divergence between two Bernoulli distributions with parameters \(p\) and \(q\).

Therefore, the probability of the observation history \(\mathcal{H}_{t+1}=\left(x_{s},Y_{s,x_{s}},j_{s}\right)_{s=1}^{t}\) is

\[P_{\pi\Lambda}\left[\left(x_{s},Y_{s,x_{s}},j_{s}\right)_{s=1}^{t}\right]=\prod_ {l=1}^{l_{t}}P_{\theta}[\theta_{j_{c_{l}}}^{*}]\prod_{s=0}^{L_{l}-1}\pi(x_{c_{l }+s}|\mathcal{H}_{c_{l}+s})P_{\eta}(Y_{c_{l}+s,x_{c_{l}+s}}|x_{c_{l}+s},\theta _{j_{c_{l}}}^{*})\]

Then the log-likelihood between the two instance up to time \(t\), given the observed data, is

\[L_{t}\left[\left(x_{s},Y_{s,x_{s}},j_{s}\right)_{s=1}^{t}\right]\] \[=\log\frac{P_{\pi\Lambda}\left[\left(x_{s},Y_{s,x_{s}},j_{s} \right)_{s=1}^{t}\right]}{P_{\pi\Lambda^{\prime}}\left[\left(x_{s},Y_{s,x_{s} },j_{s}\right)_{s=1}^{t}\right]}\] \[\overset{(a)}{=}\log\left(\frac{\prod_{l=1}^{l_{t}}P_{\theta}[ \theta_{j_{c_{l}}}^{*}]\prod_{s=0}^{L_{l}-1}\pi(x_{c_{l}+s}|\mathcal{H}_{c_{l }+s})P(Y_{c_{l}+s,x_{c_{l}+s}}|x_{c_{l}+s},\theta_{j_{c_{l}}}^{*})}{\prod_{l=1 }^{l_{t}}P_{\theta^{\prime}}[\theta_{j_{c_{l}}}^{*}]\prod_{s=0}^{L_{l}-1}\pi(x _{c_{l}+s}|\mathcal{H}_{c_{l}+s})P(Y_{c_{l}+s,x_{c_{l}+s}}|x_{c_{l}+s},\theta _{j_{c_{l}}}^{*})}\right)\] \[=\log\left(\frac{\prod_{l=1}^{l_{t}}\prod_{s=0}^{L_{l}-1}P_{\eta} (Y_{c_{l}+s,x_{c_{l}+s}}-x_{c_{l}+s}^{\top}\theta_{j_{c_{l}}}^{*})}{\prod_{l=1 }^{l_{t}}\prod_{s=0}^{L_{l}-1}P_{\eta}(Y_{c_{l}+s,x_{c_{l}+s}}-x_{c_{l}+s}^{ \top}\theta_{j_{c_{l}}}^{*})}\right)\] \[=\prod_{l=1}^{l_{t}}\sum_{s=0}^{L_{l}-1}\log\left(\frac{\exp(- \eta_{c_{l}+s}^{2}/2)}{\exp(-(\eta_{c_{l}+s}^{2})^{2}/2)}\right)\] \[\overset{(b)}{=}\sum_{l=1}^{l_{t}}\sum_{s=0}^{L_{l}-1}\frac{-(Y_ {c_{l}+s,x_{c_{l}+s}}-x_{c_{l}+s}^{\top}\theta_{j_{c_{l}}}^{*})^{2}+(Y_{c_{l}+ s,x_{c_{l}+s}}-x_{c_{l}+s}^{\top}\theta_{j_{c_{l}}}^{\prime})^{2}}{2}\] \[\overset{(c)}{=}\sum_{l=1}^{L_{l}}\sum_{s=0}^{L_{l}-1}\frac{x_{c _{l}+s}^{\top}\vartheta_{j_{c_{l}}}(2\eta_{c_{l}+s}+x_{c_{l}+s}^{\top}\vartheta _{j_{c_{l}}})}{2}\]

where \((a)\) utilizes \(P_{\theta}[\theta_{j_{c_{l}}}^{*}]=P_{\theta^{\prime}}[\theta_{j_{c_{l}}}^{*}]\), \((b)\) makes use of the relationship between the arm and observation and in \((c)\)\(\vartheta_{j_{c_{l}}}:=\theta_{j_{c_{l}}}^{*}-\theta_{j_{c_{l}}}^{\prime}\). Thus, the expectation of the log-likelihood is (in the following, the expectation is taken under instance \(\Lambda\) and algorithm \(\pi\))

\[\mathbb{E}[L_{t}] =\mathbb{E}\left[\sum_{l=1}^{l_{t}}\sum_{s=0}^{L_{l}-1}\frac{x_{c _{l}+s}^{\top}\vartheta_{j_{c_{l}}}(2\eta_{c_{l}+s}+x_{c_{l}+s}^{\top}\vartheta _{j_{c_{l}}})}{2}\right]\] \[=\mathbb{E}\left[\sum_{l=1}^{l_{t}}\sum_{s=0}^{L_{l}-1}\frac{ \vartheta_{j_{c_{l}}}^{\top}x_{c_{l}+s}x_{c_{l}+s}^{\top}\vartheta_{j_{c_{l}}} }{2}\right]\] \[=\frac{1}{2}\mathbb{E}\left[\sum_{l=1}^{l_{t}}\vartheta_{j_{c_{l} }}^{\top}\left(\sum_{s=0}^{L_{l}-1}x_{c_{l}+s}x_{c_{l}+s}^{\top}\right) \vartheta_{j_{c_{l}}}\right]\] \[=\frac{1}{2}\mathbb{E}\left[\sum_{x\in\mathcal{X}}\mathbbm{1}\{x _{c_{l}+s}=x\}\sum_{j=1}^{N}\mathbbm{1}\{j_{c_{l}}=j\}\sum_{l=1}^{l_{t}} \vartheta_{j_{c_{l}}}^{\top}\left(\sum_{s=0}^{L_{l}-1}x_{c_{l}+s}x_{c_{l}+s}^{ \top}\right)\vartheta_{j_{c_{l}}}\right]\] \[=\frac{1}{2}\sum_{x\in\mathcal{X}}\sum_{j=1}^{N}\mathbb{E}\left[N _{j,x}(t)\right]\vartheta_{j}^{\top}xx^{\top}\vartheta_{j}\] \[=\frac{1}{2}\mathbb{E}[t]\sum_{j=1}^{N}\frac{\mathbb{E}[N_{j}(t)] }{\mathbb{E}[t]}\sum_{x\in\mathcal{X}}\frac{\mathbb{E}\left[N_{j,x}(t)\right] }{\mathbb{E}[N_{j}(t)]}\vartheta_{j}^{\top}xx^{\top}\vartheta_{j}\] (M.8)

As the lengths of all the stationary phases are upper bounded, i.e., \(L_{l}\leq L_{\max},\forall l\in\mathbb{N}\), then by Wald's Lemma,

\[\frac{\mathbb{E}[N_{j}(t)]}{\mathbb{E}[t]}=\frac{\mathbb{E}[t]P_{\theta}[ \theta_{j}^{*}]}{\mathbb{E}[t]}=P_{\theta}[\theta_{j}^{*}]=p_{j}\] (M.9)The above also holds for \(t=\tau\) where \(\tau\) is a stopping time. According to Lemma 19 in [31],

\[\mathbb{E}[L_{\tau}]\geq\sup_{\mathcal{E}\in\mathcal{F}_{\tau}} \operatorname{kl}(P_{\pi\Lambda}[\mathcal{E}],P_{\pi\Lambda^{\prime}}[ \mathcal{E}])\] (M.10)

where \(\mathcal{F}_{\tau}=\sigma(\mathcal{H}_{\tau+1})\). In addition, let \(\mathcal{E}=\{\text{the recommended arm }\hat{x}_{\varepsilon}\notin\mathcal{X}_{ \varepsilon}\}\), as the algorithm \(\pi\) is \(\delta\)-PAC, then

\[\operatorname{kl}(P_{\pi\Lambda}[\mathcal{E}],P_{\pi\Lambda^{ \prime}}[\mathcal{E}])\geq\operatorname{kl}(1-\delta,\delta)\geq\log\frac{1} {2.4\delta}\] (M.11)

From (M.8), (M.9), (M.10) and (M.11), we conclude that

\[\frac{1}{2}\mathbb{E}[\tau]\sum_{j=1}^{N}p_{j}\sum_{x\in\mathcal{ X}}\frac{\mathbb{E}\left[N_{j,x}(\tau)\right]}{\mathbb{E}[N_{j}(\tau)]}\vartheta _{j}^{\top}xx^{\top}\vartheta_{j}\geq\log\frac{1}{2.4\delta}\] \[\Rightarrow \min_{\Lambda^{\prime}\in\operatorname{Alt}\Theta(\Lambda)}\frac {1}{2}\mathbb{E}[\tau]\sum_{j=1}^{N}p_{j}\sum_{x\in\mathcal{X}}\frac{\mathbb{E} \left[N_{j,x}(\tau)\right]}{\mathbb{E}[N_{j}(\tau)]}\vartheta_{j}^{\top}xx^{ \top}\vartheta_{j}\geq\log\frac{1}{2.4\delta}\] \[\Rightarrow \max_{\{v_{j}\in\mathbf{\Delta}_{X}\}_{j=1}^{N}}\min_{\Lambda^{ \prime}\in\operatorname{Alt}\Theta(\Lambda)}\frac{1}{2}\mathbb{E}[\tau]\sum_{ j=1}^{N}p_{j}\sum_{x\in\mathcal{X}}v_{j,x}\vartheta_{j}^{\top}xx^{\top} \vartheta_{j}\geq\log\frac{1}{2.4\delta}\] \[\Leftrightarrow \mathbb{E}[\tau]\geq T_{\varepsilon}(\Lambda)\log\frac{1}{2.4\delta}\]

where

\[T_{\varepsilon}(\Lambda)^{-1}=\max_{\{v_{j}\in\mathbf{\Delta}_{ X}\}_{j=1}^{N}}\min_{\Lambda^{\prime}\in\operatorname{Alt}\Theta(\Lambda)} \frac{1}{2}\sum_{j=1}^{N}p_{j}\sum_{x\in\mathcal{X}}v_{j,x}\vartheta_{j}^{\top }xx^{\top}\vartheta_{j}.\]

The solution to the above optimization problem is in general intractable, even for the stationary case [32]. We can establish a connection of the above problem to the stationary \(\varepsilon\)-best identification problem in linear bandits when we assume the change of the latent vectors are the same, i.e., \(\vartheta_{1}=\ldots=\vartheta_{N}\).

#### d.1.1 Connection with the Stationary Case

In the alternative instance \(\operatorname{Alt}_{\Theta}(\Lambda)\), \(\exists x\in\mathcal{X}\setminus\mathcal{X}_{\varepsilon}\), for any arm \(x_{\varepsilon}\in\mathcal{X}_{\varepsilon}\), s.t.

\[\sum_{j=1}^{N}p_{j}x_{\varepsilon}^{\top}\theta_{j}^{\prime}+ \varepsilon<\sum_{j=1}^{N}p_{j}x^{\top}\theta_{j}^{\prime}\] \[\Leftrightarrow \sum_{j=1}^{N}p_{j}(x_{\varepsilon}-x)^{\top}\theta_{j}^{\prime} +\varepsilon<0\] \[\Leftrightarrow -\sum_{j=1}^{N}p_{j}(x_{\varepsilon}-x)^{\top}\theta_{j}^{\prime }+\sum_{j=1}^{N}p_{j}(x_{\varepsilon}-x)^{\top}\theta_{j}^{*}>\sum_{j=1}^{N}p_ {j}(x_{\varepsilon}-x)^{\top}\theta_{j}^{*}+\varepsilon\] \[\Leftrightarrow \sum_{j=1}^{N}p_{j}(x_{\varepsilon}-x)^{\top}\vartheta_{j}>\sum_ {j=1}^{N}p_{j}(x_{\varepsilon}-x)^{\top}\theta_{j}^{*}+\varepsilon=\Delta(x_ {\varepsilon},x)+\varepsilon\]

Thus,

\[\operatorname{Alt}_{\Theta}(\Lambda)\] \[=\left\{(\mathcal{X},\Theta^{\prime},P_{\theta},\mathcal{C}): \theta_{j}^{\prime}=\theta_{j}^{*}-\vartheta_{j},\exists x\in\mathcal{X} \setminus\mathcal{X}_{\varepsilon},\sum_{j=1}^{N}p_{j}(x_{\varepsilon}-x)^{ \top}\vartheta_{j}>\Delta(x_{\varepsilon},x)+\varepsilon,\forall x_{\varepsilon} \in\mathcal{X}_{\varepsilon}\right\}.\]

Define \(\operatorname{Alt}(\Lambda)_{\text{restricted}}\subset\operatorname{Alt}_{ \Theta}(\Lambda)\), with the additional constraint that \(\vartheta_{1}=\vartheta_{2}=\cdots=\vartheta_{N}\). Then we have

\[\operatorname{Alt}(\Lambda)_{\text{restricted}}\]\[=\left\{(\mathcal{X},\Theta^{\prime},P_{\theta},\mathcal{C}):\theta^{ \prime}_{j}=\theta^{*}_{j}-\vartheta_{1},\exists x\in\mathcal{X}\setminus \mathcal{X}_{\varepsilon},\sum_{j=1}^{N}p_{j}(x_{\varepsilon}-x)^{\top} \vartheta_{j}>\Delta(x_{\varepsilon},x)+\varepsilon,\forall x_{\varepsilon} \in\mathcal{X}_{\varepsilon}\right\}.\]

Note that in stationary linear bandits, the instance can be characterized by the arm set \(\mathcal{X}\subset\mathbb{R}^{d}\) and the latent vector \(\theta\in\mathbb{R}^{d}\). Define the alternative instance in linear bandits [32] for the instance \((\mathcal{X},\mathbb{E}_{\theta\sim P_{\theta}}\theta))_{\rm stationary}\)

\[\mathrm{Alt}((\mathcal{X},\mathbb{E}_{\theta\sim P_{\theta}} \theta))_{\rm stationary}\] \[=\left\{(\mathcal{X},\theta^{\prime}):\theta^{\prime}=\mathbb{E}_ {\theta\sim P_{\theta}}\theta-\vartheta_{1},(x_{\varepsilon}-x)^{\top} \vartheta_{1}>(x_{\varepsilon}-x)^{\top}\mathbb{E}_{\theta\sim P_{\theta}}+ \varepsilon,\forall x_{\varepsilon}\in\mathcal{X}_{\varepsilon}\right\}.\]

Note that

\[\max_{\{v_{j}\in\bm{\Delta}_{\mathcal{X}}\}_{j=1}^{N}}\min_{ \Lambda^{\prime}\in\mathrm{Alt}(\Lambda)}\frac{1}{2}\mathbb{E}[\tau]\sum_{j= 1}^{N}p_{j}\sum_{x\in\mathcal{X}}v_{j,x}\vartheta_{j}^{\top}xx^{\top}\vartheta _{j}\] \[\leq\max_{\{v_{j}\in\bm{\Delta}_{\mathcal{X}}\}_{j=1}^{N}}\min_{ \Lambda^{\prime}\in\mathrm{Alt}(\Lambda)_{\rm restricted}}\frac{1}{2}\mathbb{E }[\tau]\vartheta_{1}^{\top}\left(\sum_{x\in\mathcal{X}}\left(\sum_{j=1}^{N}p_ {j}v_{j,x}\right)xx^{\top}\right)\vartheta_{1}\] \[\stackrel{{(a)}}{{=}}\max_{\bar{v}\in\bm{\Delta}_{ \mathcal{X}}}\min_{\Lambda^{\prime}\in\mathrm{Alt}(\Lambda)_{\rm restricted}} \frac{1}{2}\mathbb{E}[\tau]\vartheta_{1}^{\top}\left(\sum_{x\in\mathcal{X}} \bar{v}_{i}xx^{\top}\right)\vartheta_{1}\] \[=\max_{\bar{v}\in\bm{\Delta}_{\mathcal{X}}}\min_{\Lambda^{\prime }\in\mathrm{Alt}((\mathcal{X},\mathbb{E}_{\theta\sim P_{\theta}}\theta))_{ \rm stationary}}\frac{1}{2}\mathbb{E}[\tau]\vartheta_{1}^{\top}\left(\sum_{x\in \mathcal{X}}\bar{v}_{i}xx^{\top}\right)\vartheta_{1}\]

where in \((a)\) we denote \(\bar{v}:=\sum_{j=1}^{N}p_{j}v_{j}\) as a mixture of \(\{v_{j}\}_{j=1}^{N}\). In other words, the max-min problem becomes the one for the \(\varepsilon\)-best arm identification problem in stationary linear bandits. According to [32], the solution to the last optimization problem above is in general intractable.

However, the optimization problem can be simplified under some simple cases, e.g., the set of \(\varepsilon\)-best arm is a singleton [32]. In the next subsection, a lower bound for the original problem with \(\mathcal{X}_{\varepsilon}\) being a singleton will be derived.

#### a.1.2 A Simple Case: \(|\mathcal{X}_{\varepsilon}|=1\)

Assume that the set of \(\varepsilon\)-best arm is a singleton, i.e., \(\mathcal{X}_{\varepsilon}=\{x^{*}\}\), we will solve the original optimization problem:

\[\min_{\Lambda^{\prime}\in\mathrm{Alt}_{\Theta}(\Lambda)}\frac{1}{2}\sum_{j=1}^ {N}p_{j}\sum_{x\in\mathcal{X}}v_{j,x}\vartheta_{j}^{\top}xx^{\top}\vartheta_{j}\]

we extend the procedures in [1] to the piecewise-stationary setup.

**Lemma M.4**.: \[\min_{\Lambda^{\prime}\in\mathrm{Alt}_{\Theta}(\Lambda)}\frac{1}{2}\sum_{j=1}^ {N}p_{j}\sum_{x\in\mathcal{X}}v_{j,x}\vartheta_{j}^{\top}xx^{\top}\vartheta_{j }\geq\frac{1}{2}\min_{x\neq x^{*}}\frac{(\Delta(x^{*},x))^{2}}{\sum_{j=1}^{N}p_ {j}\|x^{*}-x\|_{\Lambda(v_{j})^{-1}}^{2}}\]

Proof.: Note that \(\Lambda^{\prime}\) differs from \(\Lambda\) in the context matrix \(\Theta\). By the derivations in (M.12), there exists arm \(x\neq x^{*}\), s.t.,

\[\sum_{j=1}^{N}p_{j}(x^{*}-x)^{\top}\vartheta_{j}>\Delta(x_{\varepsilon},x)+\varepsilon\]

Therefore, the optimization problem becomes

\[\min_{\vartheta_{1},\ldots,\vartheta_{N}}\frac{1}{2}\sum_{j=1}^{N}p _{j}\sum_{x\in\mathcal{X}}v_{j,x}\vartheta_{j}^{\top}xx^{\top}\vartheta_{j}\] \[\text{s.t.} \exists x\in\mathcal{X}\setminus\{x^{*}\},\sum_{j=1}^{N}p_{j}(x^{ *}-x)^{\top}\vartheta_{j}\geq\Delta(x^{*},x)+\varepsilon+a=:\Delta_{a+ \varepsilon}(x^{*},x)\] (M.13)where \(a>0\). The Lagrangian function for this problem is

\[L(\vartheta_{1},\ldots,\vartheta_{N},\lambda)=\frac{1}{2}\sum_{j=1}^{N}p_{j}\sum_ {x\in\mathcal{X}}v_{j,x}\vartheta_{j}^{\top}xx^{\top}\vartheta_{j}+\lambda(- \sum_{j=1}^{N}p_{j}(x^{*}-x)^{\top}\vartheta_{j}+\Delta_{a+\varepsilon}(x^{*},x))\]

Then

\[\frac{\partial L}{\partial\vartheta_{j}}=0\;\Rightarrow\;p_{j}\sum_{x\in \mathcal{X}}v_{j,x}xx^{\top}\vartheta_{j}-\lambda p_{j}(x^{*}-x)=0\;\Rightarrow \;A(v_{j})^{1/2}\vartheta_{j}=\lambda A(v_{j})^{-1/2}(x^{*}-x)\]

\[\frac{\partial L}{\partial\lambda}=0\;\Rightarrow\;\sum_{j=1}^{N}p_{j}(x^{*} -x)^{\top}\vartheta_{j}=\Delta_{a+\varepsilon}(x^{*},x)\]

This indicates that

\[\sum_{j=1}^{N}p_{j}\sum_{x\in\mathcal{X}}v_{j,x}\vartheta_{j}^{ \top}xx^{\top}\vartheta_{j} =\sum_{j=1}^{N}p_{j}\|\vartheta_{j}\|_{A(v_{j})}^{2}\] \[\geq\frac{\left(\sum_{j=1}^{N}p_{j}\|\vartheta_{j}\|_{A(v_{j})}\| x^{*}-x\|_{A(v_{j})^{-1}}\right)^{2}}{\sum_{j=1}^{N}w_{j}\|x^{*}-x\|_{A(v_{j})^{-1}}^{ 2}}\] \[=\frac{\left(\sum_{j=1}^{N}p_{j}\vartheta_{j}^{\top}(x^{*}-x) \right)^{2}}{\sum_{j=1}^{N}p_{j}\|x^{*}-x\|_{A(v_{j})^{-1}}^{2}}\] \[=\frac{\left(\Delta_{a+\varepsilon}(x^{*},x)\right)^{2}}{\sum_{j= 1}^{N}p_{j}\|x^{*}-x\|_{A(v_{j})^{-1}}^{2}}\]

Let \(a\to 0\), we have

\[\sum_{j=1}^{N}p_{j}\sum_{x\in\mathcal{X}}v_{j,x}\vartheta_{j}^{\top}xx^{\top} \vartheta_{j}\geq\frac{\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}{\sum_{j= 1}^{N}p_{j}\|x^{*}-x\|_{A(v_{j})^{-1}}^{2}}\]

Due to (M.13), we only require there exists \(x\neq x^{*}\), such that the constraint is satisfied, therefore,

\[\frac{1}{2}\sum_{j=1}^{N}p_{j}\|\vartheta_{j}\|_{A(v_{j})}^{2}\geq\frac{1}{2} \min_{x\neq x^{*}}\frac{\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}{\sum_{j= 1}^{N}p_{j}\|x^{*}-x\|_{A(v_{j})^{-1}}^{2}}\]

By Lemma M.4, the stopping time can be lower bounded as

\[\mathbb{E}[\tau]\geq 2\log\frac{1}{2.4\delta}\min_{\{v_{j}\in\Delta_{X}\}_{j=1}^ {N}}\max_{x\neq x^{*}}\frac{\sum_{j=1}^{N}p_{j}\|x^{*}-x\|_{A(v_{j})^{-1}}^{2 }}{\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}\]

This lower bound indicates that, (1) a good algorithm should actively detects and makes use of the contextual information to facilitate the arm identification process. (2) our lower bound extends the result of [16] to the linear bandits case.

The above lower bound can be further lower bounded if we restrict \(v_{1}=\ldots=v_{N}\).

**Lemma M.5**.: _Let \(\mathrm{SPD}(d):=\{A:A\in\mathbb{R}^{d\times d},A>0\}\) denote the set of SPD matrices of dimension \(d\times d\). Given any \(x\in\mathbb{R}^{d}\), define the function \(f:\mathrm{SPD}(d)\to\mathbb{R},f(A)=x^{\top}A^{-1}x\), then \(f\) is convex._

Proof of Lemma M.5.: Given any \(A,B\in\mathrm{SPD}(d)\), define

\[g:\{t\in\mathbb{R}:A+tB\in\mathrm{SPD}(d)\}\to\mathbb{R},g(t)=x^{\top}(A+tB)^ {-1}x\]

It is suffice to prove \(g\) is convex.

\[g^{\prime}(t) =-x^{\top}(A+tB)^{-1}B(A+tB)^{-1}x\] \[g^{\prime\prime}(t) =2x^{\top}(A+tB)^{-1}B(A+tB)^{-1}B(A+tB)^{-1}x\]\[=2\left(x^{\top}(A+tB)^{-1}B\right)(A+tB)^{-1}\left(B(A+tB)^{-1}x\right)\geq 0\]

Therefore, \(g\) is convex. 

Given Lemma M.5, we have

\[\sum_{j=1}^{N}p_{j}\|x^{*}-x\|_{A(v_{j})^{-1}}^{2} =\left(x^{*}-x\right)^{\top}\left(\sum_{j=1}^{N}p_{j}A(v_{j})^{-1 }\right)(x^{*}-x)\] \[\geq\left(x^{*}-x\right)^{\top}\left(\sum_{j=1}^{N}p_{j}A(v_{j}) \right)^{-1}(x^{*}-x)\] \[=\left(x^{*}-x\right)^{\top}\left(\sum_{j=1}^{N}p_{j}\sum_{x\in \mathcal{X}}v_{j,x}{xx^{\top}}\right)^{-1}(x^{*}-x)\] \[=\left(x^{*}-x\right)^{\top}\left(\sum_{x\in\mathcal{X}}\left( \sum_{j=1}^{N}p_{j}v_{j,x}\right){xx^{\top}}\right)^{-1}(x^{*}-x)\] \[=\left(x^{*}-x\right)^{\top}A(\bar{v})^{-1}(x^{*}-x)\]

where \(\bar{v}:=\sum_{j=1}^{N}p_{j}v_{j}\in\mathbf{\Delta}_{\mathcal{X}}\) and the inequality becomes equality when \(v_{1}=\cdots=v_{n}\). Thus,

\[\mathbb{E}[\tau] \geq 2\log\frac{1}{2.4\delta}\min_{\{v_{j}\in\mathbf{\Delta}_{ \mathcal{X}}\}_{j=1}^{N}}\max_{x\neq x^{*}}\frac{\sum_{j=1}^{N}p_{j}\|x^{*}-x\| _{A(v_{j})^{-1}}^{2}}{\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}\] \[\geq 2\log\frac{1}{2.4\delta}\min_{\bar{v}\in\mathbf{\Delta}_{ \mathcal{X}}}\max_{x\neq x^{*}}\frac{\|x^{*}-x\|_{A(\bar{v})^{-1}}^{2}}{\left( \Delta(x^{*},x)+\varepsilon\right)^{2}}.\] (M.14)

The last term mimics the lower bound in the stationary linear bandits with the latent vector \(\mathbb{E}_{\theta\sim P_{\theta}}\theta\). In addition, if we let \(p_{1}=1\) and \(p_{j}=0\) for all \(j\neq 1\) in the instance, our lower bound can be simplified to the lower bound in stationary linear bandits with latent vector \(\theta_{1}^{*}\)[24]

\[\mathbb{E}[\tau] \geq 2\log\frac{1}{2.4\delta}\min_{\{v_{j}\in\mathbf{\Delta}_{ \mathcal{X}}\}_{j=1}^{N}}\max_{x\neq x^{*}}\frac{\sum_{j=1}^{N}p_{j}\|x^{*}-x\| _{A(v_{j})^{-1}}^{2}}{\left(\Delta(x^{*},x)+\varepsilon\right)^{2}}\] \[=2\log\frac{1}{2.4\delta}\min_{v_{1}\in\mathbf{\Delta}_{\mathcal{ X}}}\max_{x\neq x^{*}}\frac{\|x^{*}-x\|_{A(v_{1})^{-1}}^{2}}{\left(\Delta_{1}(x^ {*},x)+\varepsilon\right)^{2}}.\] (M.15)

### Lower Bound on the Number of changepoints

In this section, we consider an even easier problem: all the contextual information is known to the agent, except for the distribution \(P_{\theta}\). The dynamics is displayed in Dynamics 3.

```
1:The instance: \(\Lambda=(\mathcal{X},\Theta,P_{\theta},\mathcal{C})\)
2:while the algorithm does not stop at time step \(t\)do
3:if\(t\in\mathcal{C}\)then
4: The agent acknowledges \(t\in\mathcal{C}\).
5: The environment samples \(\theta_{j_{t}}^{*}\sim P_{\theta}\)
6:else
7:\(\theta_{j_{t}}^{*}=\theta_{j_{t-1}}^{*}\) (the environment does not change)
8:endif
9: The agent observes \(\theta_{j_{t}}^{*}\)
10:endwhile
11:Recommend an \(\varepsilon\)-best arm \(\hat{x}_{\varepsilon}\). ```

**Dynamics 3** Dynamics for an easier problem
We are going to consider the alternative instances with to the distribution on, i.e.,. where. Denote the set of all the alternative instance (w.r.t. ) as. According to the Pinsker's inequality, let the recommended arm, then for any -PAC algorithm,

(M.16)

We will give an upper bound on the denominator. Note that

(M.17)

where is an alternative instance with distribution.

Given any, we denote the shorthand notation. We have

Fix which is sufficiently small, we have the following optimization problem:

If such alternative distribution exists, let denote the augmented Lagrangian function

(M.18)

By the KKT conditions, we have:

(M.19)

or for some, which indicates some conditions are not satisfied. The equations above give

(M.20)By solving

\[\sum_{j=1}^{N}\frac{p_{j}}{1+\sum_{x_{\varepsilon}\in\mathcal{X}_{ \varepsilon}}\lambda_{x_{\varepsilon}}(\Delta_{j}(x_{\varepsilon},x)+ \varepsilon+a)}-1=0\] (M.20)

which is a polynomial with \(N-1\) degree. Thus, an explicit solution for any instance is not applicable. However, there are some cases where we can get an estimate of \(\lambda_{x_{\varepsilon}}\)

**Lemma M.6**.: _Denote \(j_{0}=\operatorname*{arg\,min}_{j\in[N]}\Delta_{j}(x^{*},x)\) and \(j_{1}=\operatorname*{arg\,max}_{j\in[N]}\Delta_{j}(x^{*},x)\). When \(|\mathcal{X}_{\varepsilon}|=1\), \(-\Delta_{j_{0}}(x^{*},x)-2\varepsilon>\Delta_{j_{1}}(x^{*},x)>\varepsilon\) and \(\sum_{j=1}^{N}p_{j}(\Delta_{j}(x^{*},x)+\varepsilon+a)^{3}\leq 0\), the solution to (M.20) is upper bounded by_

\[\lambda_{i^{*}}\leq\frac{\Delta(x^{*},x)+\varepsilon+a}{\sum_{j=1 }^{N}p_{j}(\Delta_{j}(x^{*},x)+\varepsilon+a)^{2}}\]

Proof of Lemma M.6.: When the \(\varepsilon\)-best arm set is a singleton, (M.20) becomes (where \(a\) is sufficiently small)

\[\sum_{j=1}^{N}\frac{p_{j}}{1+\lambda_{x^{*}}(\Delta_{j}(x^{*},x) +\varepsilon+a)}-1=0\]

As (M.19) is a probability distribution, we need \(1+\lambda_{x^{*}}(\Delta_{j_{0}}(x^{*},x)+\varepsilon+a)\geq 0\), which indicates \(\lambda_{x^{*}}\leq\frac{-1}{\Delta_{j}(x^{*},x)+\varepsilon+a}\). By the condition on \(j_{0}\) and \(j_{1}\), \(0<\lambda_{x^{*}}(\Delta_{j}(x^{*},x)+\varepsilon+a)<1,\forall j\in[N]\).

Therefore, by using \(\frac{1}{1+x}=1-x+x^{2}-x^{3}+\frac{x^{4}}{1+x}\) for \(|x|<1\), we can expand the equation as follows

\[1 =\sum_{j=1}^{N}\frac{p_{j}}{1+\lambda_{x^{*}}(\Delta_{j}(x^{*},x) +\varepsilon+a)}\] \[\geq\sum_{j=1}^{N}p_{j}\left(\left(1-\lambda_{x^{*}}(\Delta_{j}( x^{*},x)+\varepsilon+a)+(\lambda_{x^{*}}(\Delta_{j}(x^{*},x)+\varepsilon+a))^{2}\right.\right.\] \[\left.\left.-(\lambda_{x^{*}}(\Delta_{j}(x^{*},x)+\varepsilon+a) )^{3}\right)\right)\] \[\Leftrightarrow 0\geq-\lambda_{x^{*}}^{2}\sum_{j=1}^{N}p_{j}(\Delta_{j}(x^{*}, x)+\varepsilon+a)^{3}+\lambda_{x^{*}}\sum_{j=1}^{N}p_{j}(\Delta_{j}(x^{*},x)+ \varepsilon+a)^{2}\] \[\qquad-\sum_{j=1}^{N}p_{j}(\Delta_{j}(x^{*},x)+\varepsilon+a)\] \[\Rightarrow \lambda_{x^{*}}\leq\frac{\sum_{j=1}^{N}p_{j}(\Delta_{j}(x^{*},x) +\varepsilon+a)}{\sum_{j=1}^{N}p_{j}(\Delta_{j}(x^{*},x)+\varepsilon+a)^{2}}= \frac{\Delta(x^{*},x)+\varepsilon+a}{\sum_{j=1}^{N}p_{j}(\Delta_{j}(x^{*},x)+ \varepsilon+a)^{2}}.\]

In general, when we get the \(\{\lambda_{x_{\varepsilon}}\}_{x_{\varepsilon}\in\mathcal{X}_{\varepsilon}}\) and plug it in (M.19), the alternative distribution \(q\) is obtained. Finally, we let \(a\to 0\).

This gives the lower bound for the number of changepoints that need to be observed. A coarse estimation of the KL divergence without solving (M.20) can be done as follows

\[\sum_{j=1}^{N}p_{j}\ln\frac{p_{j}}{q_{j}} =\sum_{j=1}^{N}p_{j}\ln\left(1+\sum_{x_{\varepsilon}\in\mathcal{ X}_{\varepsilon}}\lambda_{x_{\varepsilon}}(\Delta_{j}(x_{\varepsilon},x)+ \varepsilon)\right)\] \[\leq\sum_{j=1}^{N}p_{j}\sum_{x_{\varepsilon}\in\mathcal{X}_{ \varepsilon}}\lambda_{x_{\varepsilon}}(\Delta_{j}(x_{\varepsilon},x)+\varepsilon)\] \[=\sum_{x_{\varepsilon}\in\mathcal{X}_{\varepsilon}}\lambda_{x_{ \varepsilon}}(\Delta(x_{\varepsilon},x)+\varepsilon).\]Note that the solution of \(\lambda_{x_{\varepsilon}}\) depends on \(\Delta(x_{\varepsilon},x)\) (e.g. Lemma M.6), so the final solution is of order \((\Delta(x_{\varepsilon},x)+\varepsilon)^{2}\) for a given \(x\notin\mathcal{X}\). This is the solution to the inside minimization problem in (M.17). The final lower bound will be

\[\min_{\Lambda^{\prime}\in\operatorname{Alt}_{P}(\Lambda)}\operatorname{KL}(P_ {\theta},P_{\theta}^{\prime}) =\min_{x\in\mathcal{X}\setminus\mathcal{X}_{\varepsilon}}\min_{ \Lambda_{x}}\operatorname{KL}(P_{\theta},P_{\theta}^{x})\] \[\leq\min_{x\notin\mathcal{X}_{\varepsilon}}\sum_{x_{\varepsilon }\in\mathcal{X}_{\varepsilon}}\lambda_{x_{\varepsilon}}(\Delta(x_{ \varepsilon},x)+\varepsilon).\]

The lower bound is

\[\mathbb{E}[l_{t}]\geq\max_{x\notin\mathcal{X}_{\varepsilon}}\frac{1}{\sum_{x_{ \varepsilon}\in\mathcal{X}_{\varepsilon}}\lambda_{x_{\varepsilon}}(\Delta(x_ {\varepsilon},x)+\varepsilon)}\ln\frac{1}{4\delta}\]

where \(\lambda_{x_{\varepsilon}}\) is the solution to (M.20).

With the setup in Lemma M.6, we have

\[\min_{\Lambda^{\prime}\in\operatorname{Alt}_{P}(\Lambda)} \operatorname{KL}(P_{\theta},P_{\theta}^{\prime}) =\min_{x\in\mathcal{X}\setminus\mathcal{X}_{\varepsilon}}\min_{ \Lambda_{x}}\operatorname{KL}(P_{\theta},P_{\theta}^{x})\] \[\leq\min_{x\neq x_{\varepsilon}}\frac{(\Delta(x^{*},x)+\varepsilon )^{2}}{\sum_{j=1}^{N}p_{j}(\Delta_{j}(x^{*},x)+\varepsilon)^{2}}\]

and the lower bound is

\[\mathbb{E}[l_{t}]\geq\max_{x\neq x_{\varepsilon}}\frac{\sum_{j=1}^{N}p_{j}( \Delta_{j}(x^{*},x)+\varepsilon)^{2}}{(\Delta(x^{*},x)+\varepsilon)^{2}}\ln \frac{1}{4\delta}.\]

**Remark M.7**.: _We give some comments on the existence and uniqueness of the solution to (M.20)._

_Existence:_

* _It is possible that (_M.20_) does not have a solution. For instance, consider a three-arm instance:_ \(x_{(1)}=(1,0.5),x_{(2)}=(0.5,1),x_{(3)}=(0.6,0.6),\theta_{1}^{*}=(1,0),\theta_ {2}^{*}=(0,1),P_{\theta}=(0.5,0.5),\varepsilon=0.1\)_. We have_ \(x_{(1)}{}^{\top}\mathbb{E}_{\theta\sim P_{\theta}}=x_{(2)}{}^{\top}\mathbb{E}_ {\theta\sim P_{\theta}}=0.75\) _and_ \(x_{(3)}{}^{\top}\mathbb{E}_{\theta\sim P_{\theta}}=0.6\)_, thus_ \(x_{(3)}\) _is not an_ \(\varepsilon\)_-best arm. Furthermore, there does not exist an alternative distribution_ \(q\)_, such that_ \(x_{(3)}\) _is the best arm and neither_ \(x_{(1)},x_{(2)}\) _is_ \(\varepsilon\)_-best. Under such case, the lower bound on_ \(\mathbb{E}[l_{t}]\) _is_ \(0\) _(we regard_ \(\min_{x\in\emptyset}f(x)=+\infty\) _by convention)._
* _It is possible that (_M.20_) does not have a solution and it is unnecessary to estimate_ \(P_{\theta}\)_. For instance, consider a two-arm instance:_ \(x_{(1)}=(1,0.5),x_{(2)}=(0.5,0.1),\theta_{1}^{*}=(1,0),\theta_{2}^{*}=(0,1),P_ {\theta}=(0.5,0.5),\varepsilon=0.1\)_. Arm_ \(x_{(1)}\) _is better than arm_ \(x_{(2)}\) _under all contexts. Therefore, no matter what_ \(P_{\theta}\) _is, arm_ \(x_{(1)}\) _is the_ \(\varepsilon\)_-best arm. Under such cases, there may exist an algorithm and it is sufficient for it to determine the best arm if the context vectors are well-approximated. There is no need to estimate_ \(P_{\theta}\)_._
* _A necessary condition for the existence of the solution of (_M.20_) is: there exists_ \(x\notin\mathcal{X}_{\varepsilon}\)_, for any_ \(x_{\varepsilon}\in\mathcal{X}_{\varepsilon}\)_, there_ \(\exists j(x_{\varepsilon})\in[N]\)_,_ \(s.t.\Delta_{j(x_{\varepsilon})}(x_{\varepsilon},x)<-\varepsilon\)_. In other words, for each_ \(\varepsilon\)_-best arm_ \(x_{\varepsilon}\)_, there is at least one context in which the alternative arm_ \(x\) _is better than_ \(x_{\varepsilon}\) _by at least_ \(\varepsilon\)_._
* _A sufficient condition for the existence of the solution of (_M.20_) is: there exists_ \(x\notin\mathcal{X}_{\varepsilon}\) _and_ \(j\in[N]\)_,_ \(s.t.\Delta_{j}(x_{\varepsilon},x)<-\varepsilon\)_,_ \(\forall x_{\varepsilon}\in\mathcal{X}_{\varepsilon}\)_. In other words,_ \(x\) _is better than any_ \(\varepsilon\)_-best arm under context_ \(j\)_. In the alternative instance, we can lift_ \(P_{\theta}^{\prime}[\theta_{j}^{*}]\) _close to_ \(1\) _so that arm_ \(x\) _becomes the_ \(\varepsilon\)_-best arm and_ \(\mathcal{X}_{\varepsilon}^{\prime}\cap\mathcal{X}_{\varepsilon}=\emptyset\)_._

_Uniqueness:_

* _The uniqueness of the solution is not guaranteed, as the KKT conditions (_M.18_) is only a necessary condition for the solution. We need to look for the solution that minimizes the_ \(\operatorname{KL}\) _divergence._
* _A sufficient condition for the uniqueness of the solution is (if it exists, which indicates_ \(\exists j\in[N],s.t.\Delta_{j}(x^{*},x)<-\varepsilon\)_):_ \(|\mathcal{X}_{\varepsilon}|=1\)_. Specifically, denote_ \(f(\lambda_{x^{*}}):=\sum_{j=1}^{N}\frac{p_{j}}{1+\lambda_{x^{*}}(\Delta_{j}(x^{*},x)+\varepsilon+a)}\)_, we have_ \[\frac{\partial f}{\partial\lambda_{x^{*}}}=\sum_{j=1}^{N}\frac{-p_{j}(1+\lambda_{x^ {*}}(\Delta_{j}(x^{*},x)+\varepsilon+a))}{1+\lambda_{x^{*}}(\Delta_{j}(x^{*},x) +\varepsilon+a)}\]\[\frac{\partial^{2}f}{\partial\lambda_{x^{*}}^{2}}=\sum_{j=1}^{N}\frac{2p_{j}(1+ \lambda_{x^{*}}(\Delta_{j}(x^{*},x)+\varepsilon+a))^{2}}{1+\lambda_{x^{*}}( \Delta_{j}(x^{*},x)+\varepsilon+a)}>0\]

_As \(f(0)=1\), \(\frac{\partial f}{\partial\lambda_{x^{*}}}(0)=-1\) and \(\frac{\partial^{2}f}{\partial\lambda_{x^{*}}^{2}}>0\), so there is exactly \(1\) solution \(\lambda_{x^{*}}>0\)._

## Appendix N More Examples and Details

In this section, we **firstly** provide one more example to illustrate the tightness of our derived upper bound lower bounds, indicating the efficiency of our PS\(\varepsilon\)BAI\({}^{+}\) algorithm. In addition, we can observe how the upper and lower bounds are affected by the level of piecewise non-stationarity and whether our PS\(\varepsilon\)BAI\({}^{+}\) algorithm can reduce the influence manifested by \(L_{\max}\). **After that**, we present a proof sketch of the results in Corollaries 5.1 and N.1 in Appendix N.1.

**Example 2**.: _Instance \(\Lambda=(\mathcal{X},\Theta,P_{\theta},\mathcal{C})\) is with_

* \(d\) _arms:_ \(x_{(i)}=\mathbf{e}_{i},i\in[d]\)_._
* \(N=d\) _contexts:_ \(\theta_{1}^{\star}=(a,0,0,\ldots,0)^{\top}\)_,_ \(\theta_{2}^{\star}=(a,b,b,\ldots,b)^{\top}-b\mathbf{e}_{j},j\geq 2\)_, where_ \(b>a>\varepsilon,b-a>\varepsilon\)__
* _Context distribution:_ \(p_{j}=p,j\geq 2\) _and_ \(p_{1}=1-(N-1)p\)_, where_ \(p\in(0,\frac{a-\varepsilon}{(N-2)b})\)_._

Under Example 2, we have

\[\Delta(x_{(1)},x_{(i)})=(1-(N-2)p)\cdot a-(N-2)p\cdot(b-a)>\varepsilon\] \[\Delta_{j}(x_{(1)},x_{(i)})=-b+a<-\varepsilon,\quad i\geq 2,j\neq 1,i\]

Thus, (1) \(x_{(1)}\) is the unique \(\varepsilon\)-best arm; (2) \(\{x_{(i)}\}_{i\geq 2}\) are equivalent, and \(\Delta_{\min}:=\Delta(x_{(1)},x_{(i)})\); (3) for any \(i\geq 2\), \(x_{(i)}\) can be an \(\varepsilon\)-optimal arm under some alternative distributions.

**Corollary N.1**.: _Firstly, for the instances defined in Example 2, we have_

\[\mathrm{H}_{\mathrm{DE}}\leq\frac{16(N-2)L_{\max}}{\left(\Delta_{\min}+ \varepsilon\right)^{2}}\Bigg{(}(a+\varepsilon)^{2}+(b-a-\varepsilon)^{2} \Bigg{)},\]

_and the sample complexity of the PS\(\varepsilon\)BAI\({}^{+}\) is tight up to \((NL_{\max}/L_{\min})\) and logarithmic factors. We also further observe some specific instances: (i) when \(p\to 0^{+}\), with \(\Delta_{\min}=\min_{x\neq x^{*}}\Delta(x^{*},x)\), we have_

\[\frac{\mathbb{E}[\tau]^{*}}{\ln(1/\delta)}\in\tilde{O}\Bigg{(} \min\Bigg{\{}\frac{d}{\left(\Delta_{\min}+\varepsilon\right)^{2}}+\frac{NL_{ \max}}{\Delta_{\min}+\varepsilon},\ \frac{L_{\max}+d}{\left(\Delta_{\min}+\varepsilon\right)^{2}}\Bigg{\}}\Bigg{)}\] \[\bigcap\Omega\left\{\max\Bigg{\{}\frac{d}{\left(\Delta_{\min}+ \varepsilon\right)^{2}},\frac{L_{\min}(b-a-\varepsilon)}{\Delta_{\min}+ \varepsilon}\Bigg{\}}\right\}.\]

_(ii) When \(p\to\left(\frac{a-\varepsilon}{(N-2)b}\right)^{-}\) and \((a+\varepsilon)^{2}+(b-a-\varepsilon)^{2}=\Omega(1)\), we have \(\mathrm{H}_{\mathrm{DE}}=\frac{NL_{\max}}{\left(\Delta(x_{(1)},x_{(i)})+ \varepsilon\right)^{2}}\) and_

_The upper bounds are achieved by the PS\(\varepsilon\)BAI\({}^{+}\) algorithm._

We can observe from Corollary N.1 that

* In case (i), when \(p\to 0^{+}\), \(p_{1}\to 1-\frac{(N-1)(a-\varepsilon)}{(N-2)b}\) and \(p_{j}\to\left(\frac{a-\varepsilon}{(N-2)b}\right)\), and thus the instance tends to be non-stationary and \(\Delta_{\min}\to\varepsilon\). We will obtain \[\frac{\mathbb{E}\tau}{\ln(1/\delta)}\in\tilde{\Theta}\left(\frac{d}{(\Delta_{ \min}+\varepsilon)^{2}}\right),\] indicating that our algorithm can also reduce the impact of \(L_{\max}\).

[MISSING_PAGE_FAIL:56]

Hence, the upper bound is

\[\mathbb{E}[\tau] =\tilde{O}\left(\frac{d}{(\Delta_{\min}+\varepsilon)^{2}}\ln\frac{1} {\delta}+NL_{\max}\ln\frac{1}{\delta}+\frac{NL_{\max}}{\Delta_{\min}+ \varepsilon}\ln\frac{1}{\delta}\right)\] \[=\tilde{O}\left(\frac{d}{(\Delta_{\min}+\varepsilon)^{2}}\ln\frac {1}{\delta}+\frac{NL_{\max}}{\Delta_{\min}+\varepsilon}\ln\frac{1}{\delta} \right).\]

As \(\phi\to 0\), the first term (the VE term) dominates and it matches the lower bound in (N.1). Therefore, the upper bound is asymptotically tight up to logarithmic terms. 

**Corollary N.1**.: _Firstly, for the instances defined in Example 2, we have_

\[\mathrm{H}_{\mathrm{DE}}\leq\frac{16(N-2)L_{\max}}{\left(\Delta_{\min}+ \varepsilon\right)^{2}}\Bigg{(}(a+\varepsilon)^{2}+(b-a-\varepsilon)^{2} \Bigg{)},\]

_and the sample complexity of the \(\textsc{PS}\varepsilon\textsc{BAI}^{+}\) is tight up to \((NL_{\max}/L_{\min})\) and logarithmic factors. We also further observe some specific instances: (i) when \(p\to 0^{+}\), with \(\Delta_{\min}=\min_{x\neq x^{*}}\Delta(x^{*},x)\), we have_

\[\frac{\mathbb{E}[\tau]^{*}}{\ln(1/\delta)}\in\tilde{O}\Bigg{(} \min\Bigg{\{}\frac{d}{\left(\Delta_{\min}+\varepsilon\right)^{2}}+\frac{NL_{ \max}}{\Delta_{\min}+\varepsilon},\ \frac{L_{\max}+d}{\left(\Delta_{\min}+ \varepsilon\right)^{2}}\Bigg{\}}\Bigg{)}\] \[\bigcap\Omega\left\{\max\Bigg{\{}\frac{d}{\left(\Delta_{\min}+ \varepsilon\right)^{2}},\frac{L_{\min}(b-a-\varepsilon)}{\Delta_{\min}+ \varepsilon}\Bigg{\}}\right\}.\]

_(ii) When \(p\to\left(\frac{a-\varepsilon)}{(N-2)b}\right)^{-}\) and \((a+\varepsilon)^{2}+(b-a-\varepsilon)^{2}=\Omega(1)\), we have \(\mathrm{H}_{\mathrm{DE}}=\frac{NL_{\max}}{\left(\Delta(x_{(1)},x_{(i)})+ \varepsilon\right)^{2}}\) and_

\[\frac{\mathbb{E}[\tau]^{*}}{\ln(1/\delta)}\in\tilde{O}\Bigg{(}\min\left\{ \mathrm{H}_{\mathrm{DE}},\frac{d+L_{\max}}{\varepsilon^{2}}\right\}\Bigg{)} \bigcap\Omega\left(\frac{d+L_{\min}}{\varepsilon^{2}}\right).\]

_The upper bounds are achieved by the \(\textsc{PS}\varepsilon\textsc{BAI}^{+}\) algorithm._

Proof of Corollary N.1.: Under Example 2, we have

\[\Delta(x_{(1)},x_{(i)})=(1-(N-2)p)\cdot a-(N-2)p\cdot(b-a)>\varepsilon\] \[\Delta_{j}(x_{(1)},x_{(i)})=-b+a<-\varepsilon,\quad i\geq 2,j\neq 1,i\]

Thus, (1) \(x_{(1)}\) is the unique \(\varepsilon\)-best arm; (2) \(\{x_{(i)}\}_{i\geq 2}\) are equivalent, and \(\Delta_{\min}:=\Delta(x_{(1)},x_{(i)})\); (3) for any \(i\geq 2\), \(x_{(i)}\) can be an \(\varepsilon\)-best arm under some alternative distributions.

For any \(i\geq 2\), by solving (M.20) with \(x_{\varepsilon}=x_{(1)},x=x_{(i)}\), we obtain \(\lambda_{x_{(1)}}=\frac{\Delta(x_{(1)},x_{(i)})+\varepsilon}{(a+\varepsilon)( b-a-\varepsilon)}\) and the alternative distribution

\[P_{\theta}^{\prime}[\theta_{j}^{*}]=\frac{p_{j}}{1+\lambda_{x_{(1)}}(\Delta_{j} (x_{(1)},x_{(i)})+\varepsilon)}.\]

The lower bound on the expected number of changepoints is

\[\mathbb{E}[l_{\tau}]\geq\frac{(a+\varepsilon)(b-a-\varepsilon)}{\left( \Delta(x_{(1)},x_{(i)})+\varepsilon\right)^{2}}\ln\frac{4}{\delta}.\]

Thus the time complexity is lower bounded by

\[\mathbb{E}[\tau]\geq L_{\min}\cdot\frac{(a+\varepsilon)(b-a-\varepsilon)}{ \left(\Delta(x_{(1)},x_{(i)})+\varepsilon\right)^{2}}\ln\frac{4}{\delta}.\]

Furthermore, by solving (M.14), we obtain the lower bound on the expected sample complexity when the context index \(j_{t}\) is revealed:

\[\mathbb{E}[\tau] \geq 2\log\frac{1}{2.4\delta}\min_{i\in\Delta_{K}}\max_{i\neq 1} \frac{\frac{1}{\delta_{1}}+\frac{1}{\delta_{i}}}{\left(\Delta(x_{(1)},x_{(i)})+ \varepsilon\right)^{2}}\geq 2\log\frac{1}{2.4\delta}\frac{(\sqrt{d-1}+1)^{2}}{ \left(\Delta(x_{(1)},x_{(i)})+\varepsilon\right)^{2}}\] \[\geq\frac{d}{\left(\Delta(x_{(1)},x_{(i)})+\varepsilon\right)^{2 }}\cdot 2\log\frac{1}{2.4\delta}.\]We get the lower bound on the expected sample complexity:

\[\mathbb{E}[\tau]\geq\max\left\{\frac{d}{\left(\Delta_{\min}+\varepsilon\right)^{2 }}\cdot 2\log\frac{1}{2.4\delta},\frac{L_{\min}(a+\varepsilon)(b-a-\varepsilon )}{\left(\Delta_{\min}+\varepsilon\right)^{2}}\ln\frac{4}{\delta}\right\}.\] (N.2)

According to Theorem 3.3, the upper bound on the expected sample complexity is

\[\tilde{O}\Bigg{(}\min\left\{\frac{d}{\left(\Delta_{\min}+ \varepsilon\right)^{2}}\ln\frac{1}{\delta}+\mathrm{H}_{\mathrm{DE}}\ln\frac{1 }{\delta}+\frac{NL_{\max}}{\Delta_{\min}+\varepsilon}\ln\frac{1}{\delta},\ \frac{L_{\max}+d}{\left(\Delta_{\min}+ \varepsilon\right)^{2}}\ln\frac{1}{\delta}\right\}\Bigg{)}\] (N.3) \[\leq\tilde{O}\Bigg{(}\min\left\{\frac{d}{\left(\Delta_{\min}+ \varepsilon\right)^{2}}\ln\frac{1}{\delta}+\frac{NL_{\max}\Big{(}(a+ \varepsilon)^{2}+(b-a-\varepsilon)^{2}\Big{)}}{\left(\Delta_{\min}+ \varepsilon\right)^{2}}\ln\frac{1}{\delta}\right.\] \[\qquad\qquad+\left.\frac{NL_{\max}}{\Delta_{\min}+\varepsilon }\ln\frac{1}{\delta},\ \frac{L_{\max}+d}{\left(\Delta_{\min}+\varepsilon\right)^{2}}\ln\frac{1}{ \delta}\right\}\Bigg{)}\]

where we utilize

\[\mathrm{H}_{\mathrm{DE}} =\frac{L_{\max}}{\left(\Delta_{\min}+\varepsilon\right)^{2}} \Bigg{(}\sqrt{\min\left\{16p_{j},\frac{1}{4}\right\}}|a+\varepsilon|+\sqrt{ \min\left\{16p,\frac{1}{4}\right\}}|a+\varepsilon|\] \[\quad+(N-2)\sqrt{\min\left\{16p,\frac{1}{4}\right\}}|b-a- \varepsilon|\Bigg{)}^{2}\] \[\leq\frac{16(N-2)L_{\max}}{\left(\Delta_{\min}+\varepsilon \right)^{2}}\Bigg{(}(a+\varepsilon)^{2}+(b-a-\varepsilon)^{2}\Bigg{)}.\] (N.4)

By comparing the lower bound in (N.2) and the upper bound (N.3), we conclude that

* the sample complexity of PS\(\varepsilon\)BAI\({}^{+}\) is tight up to \(\frac{NL_{\max}}{L_{\min}}\) and logarithmic factors.
* When the mean gap is small, the sample complexity of PS\(\varepsilon\)BAI\({}^{+}\) is dominated by the former term, i.e., the design of PS\(\varepsilon\)BAI.
* When \(p\to 0^{+}\), then \(p_{1}\to 1,p_{j}\to 0\) for \(j\geq 2\), so the instance tends to be stationary and \(\Delta_{\min}\to a\). The lower bound in (N.2) becomes \[\mathbb{E}[\tau]\geq\max\left\{\frac{d}{\left(\Delta_{\min}+\varepsilon\right) ^{2}}\cdot 2\log\frac{1}{2.4\delta},\frac{L_{\min}(b-a-\varepsilon)}{ \Delta_{\min}+\varepsilon}\ln\frac{4}{\delta}\right\}\] and the upper bound in (N.3) turns into \[\tilde{O}\Bigg{(}\min\left\{\frac{d}{\left(\Delta_{\min}+\varepsilon\right) ^{2}}\ln\frac{1}{\delta}+\frac{NL_{\max}}{\Delta_{\min}+\varepsilon}\ln\frac {1}{\delta},\ \frac{L_{\max}+d}{\left(\Delta_{\min}+\varepsilon\right)^{2}}\ln\frac{1}{ \delta}\right\}\Bigg{)}.\] The vector estimation term dominates the sample complexity and our upper bound is tight.
* When \(p\rightarrow\left(\frac{a-\varepsilon}{(N-2)b}\right)^{-}\), then \(p_{1}\to 1-\frac{(N-1)(a-\varepsilon}{(N-2)b}\) and \(p_{j}\rightarrow\left(\frac{a-\varepsilon}{(N-2)b}\right)\), so the instance tends to be non-stationary and \(\Delta_{\min}\rightarrow\varepsilon\). The lower bound in (N.2) becomes \[\mathbb{E}[\tau]\geq\max\left\{\frac{d}{4\varepsilon^{2}}\cdot 2\log\frac{1}{2.4 \delta},\ \frac{L_{\min}(a+\varepsilon)(b-a-\varepsilon)}{4 \varepsilon^{2}}\ln\frac{4}{\delta}\right\}\] and the upper bound in (N.3) turns into \[\tilde{O}\Bigg{(}\min\left\{\frac{d}{4\varepsilon^{2}}\ln\frac{1}{\delta}+ \mathrm{H}_{\mathrm{DE}}\cdot\ln\frac{1}{\delta}+\frac{NL_{\max}}{2 \varepsilon}\ln\frac{1}{\delta},\ \frac{L_{\max}+d}{4\varepsilon^{2}}\ln\frac{1}{\delta}\right\}\Bigg{)}\] where \(\mathrm{H}_{\mathrm{DE}}\) is upper bounded by (N.4). (1) If \(\left((a+\varepsilon)^{2}+(b-a-\varepsilon)^{2}\right)=O(4\varepsilon^{2}+NL_{ \max})\), DE is independent of \(\varepsilon\) and VE increases as \(\varepsilon\) decreases, thus the expected sample complexity is dominated by vector estimation term when \(\varepsilon\) is small; (2) If \(\left((a+\varepsilon)^{2}+(b-a-\varepsilon)^{2}\right)=\Omega(1)\), the expected sample complexity is dominated by distribution estimation term.

Under both scenarios, our upper bound is tight.

## Appendix O Experimental Details

For the computation of the G-optimal allocation, we adopt the Wolfe-Atwood Algorithm with the Kumar-Yildirim start introduced in [33], where the input to the function is the arm set and the output is the G-optimal allocation. All experiments are conducted via MATLAB R2021b on a MacBook Pro with Apple M1 Pro chip and 16 GB memory.

To shorten the execution time,

* Before PS\(\varepsilon\)BAI stops, PS\(\varepsilon\)BAI and N\(\varepsilon\)BAI are conducted in parallel (i.e., we run PS\(\varepsilon\)BAI\({}^{+}\)). After PS\(\varepsilon\)BAI stops, N\(\varepsilon\)BAI continues and is run in a batch manner, i.e., we sample \(L_{\min}\) samples according to the G-optimal allocation one time and update the statistics. As the sample complexity of N\(\varepsilon\)BAI is of order at least \(10^{7}\) and each stationary segment is of order \(10^{4}\), the effect of this batch sampling procedure can be largely ignored.
* D\(\varepsilon\)BAI and D\(\varepsilon\)BAI\({}_{\beta}\) are both conducted in segments, because the latent context vector can be observed by the two algorithms and the latent vector does not change within a stationary segment.
* As the experiment in Section 6 illustrates that PS\(\varepsilon\)BAI outperforms N\(\varepsilon\)BAI and dominates the PS\(\varepsilon\)BAI\({}^{+}\) algorithm, we run PS\(\varepsilon\)BAI instead of PS\(\varepsilon\)BAI\({}^{+}\) for the addition experiments in Section O.2 and Section O.3.

To increase the robustness of the algorithm, the window size for LCD is doubled. Note that this will only influence an absolute constant in the sample complexity of the proposed algorithm and the order of the sample complexity remains.

### Modification of Confidence Radii in PS\(\varepsilon\)BAI and PS\(\varepsilon\)BAI\({}^{+}\)

During the proof of the upper bound, we have relaxed the absolute constants in the confidence radii to simplify the proof and increase the readability. In the experiments, we utilize the tighter confidence radii to gain better empirical performance. Note that when these tighter confidence radii are utilized by our algorithm, it still enjoys the current theoretical guarantee. The choice of confidence radii are as follows:

* \(\alpha_{t}\): according to Lemma I.1 and Lemma E.1, \(\alpha\) can be tightened to be \[\alpha_{t}^{\text{alg}}=\frac{d}{T_{t}}\ln\frac{2}{\delta_{v,T_{t}}}+\sqrt{ \left(\frac{d}{T_{t}}\ln\frac{2}{\delta_{v,T_{t}}}\right)^{2}+\frac{4d}{T_{t} }\ln\frac{2}{\delta_{v,T_{t}}}}\leq 5\sqrt{\frac{d}{T_{t}}\ln\frac{2}{ \delta_{v,T_{t}}}}.\]
* \(\beta_{t,j}\): according to (I.3) and Lemma K.1, \(\beta_{t,j}\) can be tightened to be \[\beta_{t,j}^{\text{alg}}=\min\left\{\frac{\frac{1}{3}L_{\max}\ln\frac{2}{ \delta_{d,T_{t}}}+\sqrt{\left(\frac{1}{3}L_{\max}\ln\frac{2}{\delta_{d,T_{t}} }\right)^{2}+\frac{2\phi_{t,j}L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}},\;1\right\},\] where \(\phi_{t,j}:=\min\left\{4\max\left\{\hat{p}_{t,j},\frac{25}{4}\frac{L_{\max} }{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\right\},\;\frac{1}{4}\right\}.\)
* \(\xi_{t}\): instead of using \(25\sqrt{2}\frac{NL_{\max}}{T_{t}}\ln\frac{2}{\delta_{m,T_{t}}}\), we turn to bound the residual error by (I.9): \[\xi_{t}^{\text{alg}}=\sum_{j:\psi_{t,j,1}>\hat{p}_{t,j}}4\cdot\beta_{t,j}^{ \text{alg}}+\sum_{\begin{subarray}{c}j:\psi_{t,j,1}=\hat{p}_{t,j},\\ \psi_{t,j,2}>\hat{p}_{t,j}\end{subarray}}\min\left\{4,2\hat{\xi}_{t,j}^{ \text{alg}}\right\}\cdot\beta_{t,j}^{\text{alg}}\] \[+\sum_{j:\psi_{t,j,3}=\hat{p}_{t,j}}10\sqrt{\frac{d}{T_{t,j}}\ln \frac{2}{\delta_{m,T_{t}}}}\cdot\beta_{t,j}^{\text{alg}}\]where

\[\psi_{t,j,1}:=\max\left\{\hat{p}_{t,j},\frac{d}{4T_{t}}\ln\frac{2}{ \delta_{m,T_{t}}}\right\},\:\psi_{t,j,2}:=\max\left\{\hat{p}_{t,j},\frac{25}{4} \frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\right\},\] \[\tilde{\xi}_{t,j}^{\rm alg}=\frac{d}{T_{t,j}}\ln\frac{2}{\delta_{ m,T_{t}}}+\sqrt{\left(\frac{d}{T_{t,j}}\ln\frac{2}{\delta_{m,T_{t}}}\right)^{2}+ \frac{4d}{T_{t,j}}\ln\frac{2}{\delta_{m,T_{t}}}}\leq 5\sqrt{\frac{d}{T_{t,j}} \ln\frac{2}{\delta_{m,T_{t}}}}.\]

\(\tilde{\xi}_{t,j}^{\rm alg}\) is obtained in a similar manner as \(\alpha_{t}^{\rm alg}\). \(\xi_{t}^{\rm alg}\) characterizes the confidence radii of each context at a finer level.

These finer confidence bounds can save a constant of \(2.5\) when \(t\) is large.

### Misspecified \(L_{\max}\) and \(L_{\min}\)

As PS\(\varepsilon\)BAI\({}^{+}\) requires the knowledge of \(L_{\max}\), we empirically test the robustness of the algorithm towards \(L_{\max}\) on the instances in section 6. We run PS\(\varepsilon\)BAI with \(\tilde{L}_{\min}=\nu L_{\min}\) and \(\tilde{L}_{\max}=\nu L_{\max}\) where \(\nu=0.8\) or \(1.2\). An \(\varepsilon\)-best arm is recommended in all experiments. The sample complexities are presented in Figure 3. The result indicates that PS\(\varepsilon\)BAI (thus PS\(\varepsilon\)BAI\({}^{+}\)) is robust towards the knowledge of \(L_{\max}\) and its superiority over N\(\varepsilon\)BAI is maintained.

### Robustness towards \(w\) and \(b\)

According to the distinguishability condition (Assumption 1), point (2) indicates we can set \(w=\frac{L_{\min}}{3\gamma}\), where \(\gamma\) is the change detection frequency, and (3.5) indicates \(w\) and \(b\) are coupled. We denote \(\tilde{w}:=\frac{L_{\min}}{18}\).

To exam the robustness towards \(w\) and \(b\), we choose to vary the choice of \(\gamma\), thus, \(w\) and \(b\) will change accordingly. Specifically, we select \(\gamma\in\{2,3,6,12\}\) and the corresponding \(w\in\{3\tilde{w},2\tilde{w},\tilde{w},\frac{w}{2}\}\). The other parameters remain unchanged. The experiment result is presented in Figure 4. When \(\gamma=18,w=\frac{\tilde{w}}{3}\), Assumption 1 is severely violated and the result is not desirable.

The result indicates that, while smaller \(\gamma\) and greater \(w\) can result in slightly greater sample complexity, the overall sample complexity does not vary much and the superiority of our algorithm over the naive uniform sampling algorithm N\(\varepsilon\)BAI is maintained. We conclude that our algorithm is robust against these choices, as long as Assumption 1 is not severely violated.

Figure 3: Misspecicied \(L_{\max}\) and \(L_{\min}\).

### Benchmarks: \(\mathrm{D}\varepsilon\mathrm{BAI}\)and \(\mathrm{D}\varepsilon\mathrm{BAI}_{\beta}\)

We present the Distribution \(\varepsilon\)-Best Arm Identification (D\(\varepsilon\mathrm{BAI}\)) in Algorithm 8 and its variant \(\mathrm{D}\varepsilon\mathrm{BAI}_{\beta}\) in Algorithm 9. According to Dynamics 3, the agent has access to the context vector \(\theta^{*}_{j_{t}}\) and the changepoint \(t\in\mathcal{C}\). Thus only the distribution \(P_{\theta}\) remains unknown and the agent needs to estimate it via the observed contexts.

```
1:Input: the arm set \(\mathcal{X}\), the latent vector matrix \(\Theta\), the slackness parameter \(\varepsilon\), the confidence parameter \(\delta\).
2:Initialize: Compute the G-optimal allocation \(\lambda^{*}\).
3: Compute \(C_{3}=\sum_{n=1}^{\infty}n^{-3}\).
4: Observe \(\theta^{*}_{j_{1}}\).
5: Compute \[\ddot{p}_{t,j}=\sum_{l_{s}=1}^{l_{t}}\frac{\mathbbm{1}\{c_{l_{s}}= c_{j}\}}{l_{t}},\quad\ddot{x}_{t}=\operatorname*{arg\,max}_{x\in\mathcal{X}}x^{ \top}\Theta\ddot{p}_{t}\] (O.1) \[\ddot{\beta}_{t}=\sqrt{\frac{1}{2l_{t}}\ln\frac{2C_{3}Nl_{t}^{3}} {\delta}},\quad\ddot{\rho}_{t}(\ddot{x}_{t},x)=\ddot{\beta}_{t}\min_{\zeta( \ddot{x}_{t},x)\in\mathbb{R}}\sum_{j=1}^{N}|\Delta_{j}(\ddot{x}_{t},x)+\zeta( \ddot{x}_{t},x)|\]
6:while\(\min_{x\neq\dot{x}_{t}}(\ddot{x}_{t}-x)^{\top}\Theta\ddot{p}_{t}-\ddot{\rho}_{t}<-\varepsilon\) or \(t\notin\mathcal{C}\)do
7: Observe \(\theta^{*}_{j_{t}}\) and \(\mathbbm{1}\{t\in\mathcal{C}\}\) update \(t=t+1\).
8: Update \(\ddot{x}_{t}\) and \(\ddot{\rho}_{t}\) with (O.1) and update \(l_{t}\) if \(t\in\mathcal{C}\).
9:endwhile
10: Recommend arm \(\ddot{x}_{\varepsilon}=\ddot{x}_{t}\). ```

**Algorithm 8** Distribution \(\varepsilon\)-Best Arm Identification (D\(\varepsilon\mathrm{BAI}\))

The design is straightforward except for \(\zeta(\ddot{x}_{t},x)\). It minimizes the summation \(\zeta(\ddot{x}_{t},x):=\operatorname*{arg\,min}_{y\in\mathbb{R}}\sum_{j=1}^{N} |\Delta_{j}(\ddot{x}_{t},x)+\zeta(\ddot{x}_{t},x)|\). This trick has also been utilized in the design of PS\(\varepsilon\)BAI (see (I.5)). It helps to better exploit the structure of the latent vectors \(\Theta\) and facilitates the identification process. For easy implementation, we choose a proxy \(\zeta(\ddot{x}_{t},x)=\operatorname*{arg\,min}_{y\in\mathbb{R}}\sum_{j=1}^{N}( \Delta_{j}(\ddot{x}_{t},x)+\zeta(\ddot{x}_{t},x))^{2}=-\frac{1}{N}\sum_{j=1}^{N }\Delta_{j}(\ddot{x}_{t},x)\)

Figure 4: Robustness towards \(w\) and \(b\).

D\(\varepsilon\)BAI\({}_{\beta}\) utilizes the techniques we have used to bound the deviation between the true distribution \(p_{j}\) and the estimated ones \(\overset{\circ}{p}_{t,j}\) for all \(j\in[N]\). Similarly, we let \(\zeta(\overset{\circ}{x},x)=\arg\min_{\zeta(\overset{\circ}{x},x)\in\mathbb{R}} \sum_{j=1}^{N}\overset{\circ}{\beta}_{t,j}(\Delta_{j}(\overset{\circ}{x}_{t},x )+\zeta(\overset{\circ}{x},x))^{2}=-\frac{\sum_{j=1}^{N}\overset{\circ}{\beta }_{t,j}\Delta_{j}(\overset{\circ}{x}_{t},x)}{\sum_{j=1}^{N}\overset{\circ}{ \beta}_{t,j}}\) for efficient computing.

As the theoretical guarantee of D\(\varepsilon\)BAI\({}_{\beta}\) can be derived following a similar manner as the proof of the DE term of PS\(\varepsilon\)BAI in Appendix I.2 and in the proof of Lemma G.6, for simplicity, we just present the result and omit the proof here here.

**Theorem 0.1**.: D\(\varepsilon\)BAI\({}_{\beta}\) _identifies an \(\varepsilon\)-best arm within_

\[\tilde{O}\left(\max_{x_{\varepsilon}\in\mathcal{X},x\neq x_{\varepsilon},x^{ \ast}}\frac{L_{\max}\overset{\circ}{H}^{2}(x_{\varepsilon},x)}{(\Delta_{\min }+\varepsilon)^{2}}\ln\frac{1}{\delta}\right),\]

_time steps with probability at least \(1-\delta\) and in expectation, where_

\[\overset{\circ}{H}(x_{\varepsilon},x):=\min_{\zeta(\overset{\circ}{x},x) \in\mathbb{R}}\sum_{j=1}^{N}\sqrt{\min\{16p_{j},\frac{1}{4}\}}|\Delta_{j}( \overset{\circ}{x}_{\varepsilon},x)+\zeta(\overset{\circ}{x}_{\varepsilon}, x)|.\]

We present a theorem, along with a proof sketch, for the theoretical guarantee of D\(\varepsilon\)BAI below.

**Theorem 0.2**.: D\(\varepsilon\)BAI _identifies an \(\varepsilon\)-best arm within_

\[\tilde{O}\left(\max_{x_{\varepsilon}\in\mathcal{X},x\neq x_{\varepsilon},x^{ \ast}}\frac{L_{\max}\ddot{H}^{2}(x_{\varepsilon},x)}{(\Delta_{\min}+ \varepsilon)^{2}}\ln\frac{1}{\delta}\right),\]

_time steps with probability at least \(1-\delta\) and in expectation, where \(\ddot{H}(x_{\varepsilon},x):=\min_{\zeta(\overset{\circ}{x},x)\in\mathbb{R}} \sum_{j=1}^{N}|\Delta_{j}(\overset{\circ}{x}_{\varepsilon},x)+\zeta(\overset {\circ}{x}_{\varepsilon},x)|\)._Proof.: For the sake of conciseness and simplicity, only a proof sketch is provided for this Theorem. Similar results can be found in the referred contents. The proof is composed by \(4\) steps.

* Step 1: bound the deviation of \(P_{\theta}[\theta_{j}^{*}]\) by Lemma O.3 and Remark O.4.
* Step 2: prove the recommended arm is an \(\varepsilon\)-best arm. Conditional on Step \(1\), we can prove this following the procedures in Lemma J.1.
* Step \(3\): give a sufficient condition and then obtain a high probability upper bound. This can be seen from (J.1) and by solving \[\ddot{\rho}_{t}(\ddot{x}_{t},x)=\ddot{\beta}_{t}\sum_{j=1}^{N}| \Delta_{j}(\ddot{x}_{t},x)+\zeta(\ddot{x}_{t},x)|\leq\frac{\Delta_{\min}+ \varepsilon}{2}\] \[\Rightarrow l_{t}=\tilde{O}\left(\frac{\ddot{H}^{2}(x_{\varepsilon},x)}{( \Delta_{\min}+\varepsilon)^{2}}\ln\frac{1}{\delta}\right).\] \[\Rightarrow t=\tilde{O}\left(\frac{L_{\max}\ddot{H}^{2}(x_{\varepsilon},x )}{(\Delta_{\min}+\varepsilon)^{2}}\ln\frac{1}{\delta}\right).\] The high probability result is obtained by maximizing the above over \(x_{\varepsilon}\in\mathcal{X},x\neq x_{\varepsilon},x^{*}\).
* Step \(4\): the expected result can be derived in a similar method as in the proof of N\(\varepsilon\)BAI in Appendix F. The expected sample complexity and the high-probability sample complexity is of the same order.

**Lemma O.3**.: _With probability at least \(1-\delta\), \(\sup_{j\in[N]}|p_{j}-\ddot{p}_{t,j}|\leq\ddot{\beta}_{t}\) for all \(t\in\mathbb{N}\), where \(\ddot{\beta}_{t}=\sqrt{\frac{2}{l_{t}}\ln\frac{2}{\delta_{l_{t}}}}\) and \(\delta_{l_{t}}=\frac{\delta}{C_{3}\delta_{t}^{2}}\)._

Proof.: We may define the cumulative distribution function (CDF) and the empirical CDF for \(P_{\theta}\) as \(F_{\theta}(j)=\sum_{k=1}^{j}P_{\theta}[\theta_{j}^{*}]\) and \(\ddot{F}_{t}(j)=\sum_{l_{s}=1}^{l_{t}}\mathbbm{1}\{c_{l_{s}}=c_{j},l_{s}\leq j\}\) respectively for \(j\in[N]\). According to the DKW inequality, we have

\[\mathbb{P}\left[\sup_{j\in[N]}\left|\ddot{F}_{t}(j)-F(j)\right|\geq\epsilon \right]\leq 2\exp\left(-2l_{t}\epsilon^{2}\right).\]

By the implication

\[\epsilon \leq|p_{j}-\ddot{p}_{t,j}|=|F(j)-F(j-1)-\ddot{F}_{t}(j)+\ddot{F}_ {t}(j-1)|\] \[\leq|F(j)-\ddot{F}_{t}(j)|+|F(j-1)-\ddot{F}_{t}(j-1)|\] \[\Rightarrow |F(j)-\ddot{F}_{t}(j)|\geq\frac{\epsilon}{2}\quad\text{or}\quad|F (j-1)-\ddot{F}_{t}(j-1)|\geq\frac{\epsilon}{2},\]

we have that

\[\mathbb{P}\left[\sup_{j\in[N]}\left|p_{j}-\ddot{p}_{t,j}\right|\geq \epsilon\right] \leq\mathbb{P}\left[\sup_{j\in[N]}\left|\ddot{F}_{t}(j)-F(j) \right|\geq\frac{\epsilon}{2}\right]\leq 2\exp\left(-2l_{t}\left(\frac{\epsilon}{2} \right)^{2}\right)\] \[=2\exp\left(-\frac{l_{t}\epsilon^{2}}{2}\right).\]

This is equivalent to

\[\mathbb{P}\left[\sup_{j\in[N]}\left|p_{j}-\ddot{p}_{t,j}\right|\geq\ddot{\beta }_{t}\right]\leq\delta_{l_{t}}.\]

A union bound gives an upper bound of the failure probability \(\sum_{l_{t}=1}^{\infty}\delta_{l_{t}}=\delta\). 

**Remark O.4**.: _The use of the DKW inequality gives a union bound over the deviation of the distribution estimation all contexts. This avoid the \(N\) factor in the logarithm in \(\ddot{\beta}_{t}\) and is beneficial when the number of contexts \(N\) is large.__When there are a few contexts, it is also possible to directly bound the deviation for each context via Azuma-Hoeffding's inequality, i.e.,_

\[\mathbb{P}\left[|p_{j}-\ddot{p}_{t,j}|\leq\breve{\beta}_{t}\right]\leq\delta_{t _{t}}\]

_where \(\breve{\beta}_{t}:=\sqrt{\frac{1}{2t_{t}}\ln\frac{2C_{3}Nl_{s}^{3}}{\delta}}\). A union bound gives that with probability at least \(1-\delta\), \(|p_{j}-\ddot{p}_{t,j}|\leq\breve{\beta}_{t}\) for all \(t\in\mathbb{N},j\in[N]\). As this new confidence radius is the same as the one in Lemma O.3 up to constant and logarithmic terms, the sample complexity should be of the same order._

_We adopt this confidence radius \(\breve{\beta}_{t}:=\sqrt{\frac{1}{2t_{t}}\ln\frac{2C_{3}Nl_{s}^{3}}{\delta}}\) in the experiment._

## Appendix P Additional Discussions

In this section, we provide additional discussions on

* the related methods for BAI in the nonstationary bandits literature in subsection P.1,
* the upper on the sample complexity in Theorem 3.2 and Theorem 3.3 in subsection P.2,
* the connection between the piecewise-stationary linear bandits model to the stationary linear bandits model in subsection P.3,
* the special case where the number of context \(N=1\) in subsection P.4,

### Discussion on the Related Methods in Nonstationary Bandits

To the best of our knowledge, there is limited literature investigating the BAI in the nonstationary bandits setup (there is comparatively a much richer literature for regret minimization in non-stationary environments): [14] studies BAI in the _fixed-horizon_ setup and [15] assumes the _best arm remains unchanged_ after certain time step and explores the fixed-confidence setting. Both of the works are not directly comparable to our proposed piecewise-stationary setup.

Additionally, we provide strong baselines algorithms \(D\varepsilon BAI\) and \(D\varepsilon BAI_{\beta}\) in Section 6, which are detailed in Section O.4. These two baselines are given oracle information about the context (see Dynamics 3), while PS\(\varepsilon\)BAI\({}^{+}\) is not. As indicated by Figure 2(b), PS\(\varepsilon\)BAI\({}^{+}\) is competitive compared to these strong baselines and is much better than the naive approach.

### More Discussions on the Upper Bound

Firstly, we emphasize that the sample complexity in Theorem 3.2 and Theorem 3.3 are instance-dependent, in particular, the term \(\mathrm{H}_{\mathrm{DE}}\) characterizes the difficulty in estimating the distribution of the context. Furthermore, the presence of the gaps \(\Delta(x,x^{*})\) also underscores that our upper bounds are functions of the instance.

Secondly, our algorithm adopts the G-optimal design, which is minimax optimal for the BAI in standard linear bandits problem [1, 2]. Although we have not proved it, we believe that the sample complexity of the proposed algorithm may not be instance-dependent optimal.

Lastly, we provide some remarks on the instance-dependent optimal algorithms:

(1) The G-optimal design is the cornerstone for the more efficient and adaptive rules like \(\mathcal{X}\mathcal{Y}\)-allocation and \(\mathcal{X}\mathcal{Y}\)-Adaptive Allocation in [1]. Therefore, our algorithm provides a framework for more sophisticated algorithms in the piecewise-stationary linear bandits problem with the BAI task. Empirically, one can attempt to replace the G-optimal design by the \(\mathcal{X}\mathcal{Y}\)-allocation during implementation, which can possibly yield empirical benefits.

(2) The current lower bound is established with two simpler problems (see Section 4), which is sufficient to show our algorithm is minimax optimal. However, a tighter instance-dependent lower bound based on the original problem may be required if one wishes to show an algorithm is instance-dependent optimal. This can be challenging because the distribution of the arms, the contexts and the changepoints are unknown, and the characterization of the "alternative instance" (i.e., the \(\varepsilon\)-best arm set is changed) is difficult.

To conclude, we believe an instance-dependent optimal algorithm is appealing and can lead to future research.

### Connections to the Stationary Bandits

**Firstly**, we would like to clarify that, in the piecewise-stationary linear bandits model, the instance tends towards a stationary one when \(\max_{j\in[N]}p_{j}\to 1\), instead of the scenario in which \(L_{\max}\to\infty\).

When \(L_{\min}\) and \(L_{\max}\) are large, estimating each latent vector becomes easier since there are more observations in a single stationary segment. However, the overall reward of an arm also depends on \(P_{\theta}\), the distribution of latent context vectors, which is also assumed to be unknown in the setup. In order to estimate \(P_{\theta}\), a learning agent can get one (unobservable) sample from \(P_{\theta}\) only at the (unobservable) change points. In other words, \(L_{\max}\) charaterizes the "sparsity" of the context samples: the larger \(L_{\max}\) is, the sparser the context samples are. A larger \(L_{\max}\) indicates that samples from \(P_{\theta}\) are likely to be generated less frequently, which will result in the increase of the overall sample complexity. Consider an extreme example of Dynamics 3 where the context vector is revealed at every time step and \(L_{\min}\) and \(L_{\max}\) are very large. If at least \(l_{\tau}\) context samples from \(P_{\theta}\) are required to identify the best arm, then a sample complexity of \(l_{\tau}L_{\min}\) is unavoidable in the our setup under this extreme case.

**Secondly**, while \(\max_{j\in[N]}p_{j}\) is important in characterizing the (non)stationarity of the instance, we would like to emphasize that **both** the distribution \(P_{\theta}\) and latent context vectors are essential in characterizing the sample complexity, as shown in the term \(\bar{H}(x_{\epsilon},x)\) in Theorem 3.2. To further illustrate this, we provide a simple but illuminating instance as follows: The instance is composed by \(N=3\) contexts and \(K=2\) arms, and \(\Delta_{j}\) denotes the mean gap between arm \(1\) and arm \(2\) under context \(j\in[N]\) (to be specified below) and \(\Delta:=\sum_{j\in[N]}p_{j}\Delta_{j}\) denotes the weighted mean gap between arm \(1\) and arm \(2\). The probability of context \(1\) is \(p_{1}=\max_{j\in[N]}p_{j}=1-p_{2}-p_{3}\), and \(p_{1}\) is close to \(1\). Let \(\tilde{x}\) denote the empirical version of the statistics \(x\) in the following arguments.

In such a case, consider this question: _if an algorithm has only detected context \(1\) in the first \(t\) time steps and \(t\) is large, should it stop or not?_

As no change point has occurred, the current dynamics behaves similarly to that of a stationary bandit environment up till now. Thus the empirical probabilities of the \(3\) contexts are \(\hat{p}_{1}=1,\hat{p}_{2}=\hat{p}_{3}=0\) and the empirical mean gap under context \(1\)\(\hat{\Delta}_{1}\) is close to \(\Delta_{1}\). Consider the following two cases:

* Case 1: \(\Delta_{1}=p_{2}\) and \(\Delta_{2}=\Delta_{3}=-p_{1}\). The true weighted mean gap between arm \(1\) and arm \(2\) is \(\Delta=\sum_{j\in[N]}p_{j}\Delta_{j}=-p_{1}p_{3}<0\), and thus arm \(2\) is the best arm. This indicates that, in order to estimate \(\Delta_{2}\) and \(\Delta_{3}\), an algorithm needs to observe contexts \(2\) and \(3\) despite their small probabilities. But currently \(\hat{p}_{2}=\hat{p}_{3}=0,\hat{\Delta}=\hat{\Delta}_{1}\approx\Delta_{1}>0\), so the algorithm should not terminate.
* Case 2: \(\Delta_{1}=1\) and \(\Delta_{2},\Delta_{3}\in[-2,2]\). Thus \(\hat{\Delta}\approx\Delta\geq p_{1}-2p_{2}-2p_{3}>0\). This indicates there is no need to observe contexts \(2\) and \(3\), because arm \(1\) is the best even in the worst case (\(\Delta_{2}=\Delta_{3}=-2\)). In this case, as long as the algorithm gets a good estimate of \(\Delta_{1}\), it can confidently terminate.

As these two cases indicate, in addition to \(P_{\theta}\), the latent vectors (which determine the means of the arms) are equally important for the stopping time. Our algorithm takes both factors into account, as reflected by the summation term in equation (3.4) and \(\hat{\Delta}_{t}(x_{t}^{*},x)\) in (3.5) for the algorithm design, and by \(\bar{H}(x_{\epsilon},x)\) for the theoretical upper bound.

We **conclude** that

* The unknown distribution \(P_{\theta}\) and the latent vectors **jointly** determine the sample complexity. \(\bar{H}(x_{\epsilon},x)\) in Theorem 3.2 characterizes their roles, where the contexts with larger probabilities have commensurately greater influence on the sample complexity of the algorithm.
* When \(\max_{j\in[N]}p_{j}\to 1\) with other parameters fixed, the piecewise-stationary linear bandit instance reduces to a stationary one. \(H_{DE}(x_{\epsilon},x)\) in Theorem 3.2 becomes \(L_{\max}/4\), which implies that a **constant** number of change points need to be observed, and thus \(T_{D}(x_{\epsilon},x)\) can be regarded as a constant. The dominant term in our upper bound, the \(T_{V}(x)\) term, recovers the upper bound in the stationary bandits, that is, \(\max_{x\neq x^{*}}\frac{d}{(\Delta(x^{*},x)+\varepsilon)^{2}}\ln(1/\delta)\)[32].

### Special Case: \(N=1\)

We only consider \(N>1\) as the bandit model is only **truely** piecewise-stationary when \(N>1\). Thus, we did not specifically derive upper and lower bounds for the extreme case where \(N=1\). Nevertheless, our analysis can cover this case due to the following reasons:

* The (minimax) lower bound in Theorem 4.1 is not directly applicable since it is not derived for this extreme instance. However, if we step back to the analysis equation (M.16), the feasible set in the optimization problem is empty, and thus the lower bound on \(\mathbb{E}[l_{t}]\) (\(N_{C}\) in Theorem4.1) is \(0\). In this case, the lower bound in Theorem4.1 reduces to the lower bound in the stationary bandits.
* Regarding the upper bound in Theorem 3.2, when \(N=1\), we have \(p_{1}=1\) and \(H_{DE}=\frac{l_{\max}}{4}\). In this case, as \(H_{DE}\) does not depend on the mean gaps and the mean gaps are among the fundamental quantities to characterize the difficulty of an instance, the \(T_{D}\) term can be regarded as a constant. Therefore, the dominant term in the upper bound is \(T_{V}\). This recovers the bound in the stationary setup.
* In addition, as we assume \(N\) is an input to our algorithm, when we are aware \(N=1\), we can actually adopt the algorithms for the stationary setting, e.g., the \(G\)-allocation or \(\mathcal{XY}\)-allocation rule [1].

## Appendix Q \(\varepsilon\)-Best Arm Tuple Identification Problem

In the main paper, we consider the identification of an \(\varepsilon\)-best arm in terms of the "ensemble" quality \(\mu_{x}:=\mathbb{E}_{\theta\sim P_{\theta}}[x^{\top}\theta]=\sum_{j=1}^{N}P_{ \theta}[\theta_{j}^{*}]x^{\top}\theta_{j}^{*}\). The curious reader may wonder whether we can identify the \(\varepsilon\)_-best arm tuple_\(\mathcal{X}_{\varepsilon}^{\mathrm{tuple}}:=(x_{1}^{\varepsilon}, \ldots,x_{N}^{\varepsilon})\), where \(x_{j}^{\varepsilon}\) is an \(\varepsilon\)-best arm under context \(j\), i.e., \(x_{j}^{\varepsilon}\in\{x:x^{\top}\theta_{j}^{*}\geq\max_{x\in\mathcal{X}}x^{ \top}\theta_{j}^{*}-\varepsilon\}\). Given the tools we developed in this manuscript, we answer this problem in the affirmative.

**Intuitions:** Let \(x_{j}^{*}:=\arg\max_{x\in\mathcal{X}}x^{\top}\theta_{j}^{*}\) and \(\Delta_{j}^{*}:=\min_{x\neq x_{j}^{*}}\Delta_{j}(x_{j}^{*},x)\). We expect to have an upper bound taking the form of

\[\tilde{O}\bigg{(}\max_{j\in[N]}\frac{L_{\max}}{p_{j}}\cdot\frac{d}{\big{(} \Delta_{j}^{*}+\varepsilon\big{)}^{2}\,L_{\min}}\ln\frac{1}{\delta}\bigg{)}\]

where \(O(\frac{d}{\big{(}\Delta_{j}^{*}+\varepsilon\big{)}^{2}L_{\min}}\ln\frac{1}{ \delta})\) is an upper bound on the number of context samples \(j\) and context \(j\) will occur once among every \(\frac{1}{p_{j}}\) contexts in expectation.

**Analysis of the problem:** The change detection and context alignment subroutines are only effective within \(\tau^{*}\) time steps (Line 2 in Algorithm 1). However, if a context is with small occurrence probability \(p_{j}\), it may not appear before \(\tau^{*}\) time steps.

Regarding this scenario, we only expect to obtain a high-probability upper bound on the sample complexity, whereas the expected sample complexity requires more techniques beyond our parallel execution trick (which is used to design PS\(\varepsilon\)BAI\({}^{+}\)) and is an interesting direction left for future research.

Besides, it is more feasible to consider the identification of \(\varepsilon\)-best arms under contexts with high occurrence probability, i.e., we aim to identify

\[\mathcal{X}_{\varepsilon,\bar{p}}^{\mathrm{tuple}}:=\{x_{j}^{\varepsilon}:p_{j} >\bar{p}\}\]

where \(\bar{p}\) is a threshold on the occurrence probability of contexts. Let \(\Theta_{\bar{p}}=\{\theta_{j}^{*}:p_{j}>\bar{p}\}\) denote those context with high occurrence probability.

**Goal:** We aim to devise an algorithm with the minimum sample complexity (arm pulls) to ascertain either (1) an \(\varepsilon\)-best arm under context \(j\), or (2) \(\theta_{j}^{*}\notin\Theta_{\bar{p}}\).

With the above goal, we expect to identify an \(\varepsilon\)-best arm for all \(j\) with \(\theta_{j}^{*}\in\Theta_{\bar{p}}\); for those \(j\) with \(\theta_{j}^{*}\notin\Theta_{\bar{p}}\), either an \(\varepsilon\)-best arm is identified or \(\theta_{j}^{*}\notin\Theta_{\bar{p}}\) is ascertained.

We propose Algorithm 10 for this problem, which is quite similar to Algorithm 1, except for a few changes:* On Line 7, the algorithm stops when an \(\varepsilon\)-best arm or \(p_{j}\leq\bar{p}\) is identified for all contexts.
* On Line \(25\), it computes the confidence radii for the arms in context \(j_{t}\) as well as the confidence radii for the occurrence probabilities \[\alpha_{t,j}=\frac{d}{n}\ln\frac{2}{\delta_{v,T_{t}}}+\sqrt{\left(\frac{d}{n} \ln\frac{2}{\delta_{v,T_{t}}}\right)^{2}+\frac{4d}{n}\ln\frac{2}{\delta_{v,T_{ t}}}},\] (Q.1)\[\beta_{t,j}:=\min\left\{\frac{5}{2}\sqrt{\frac{2\phi_{t,j}L_{\max}}{T_{t}} \ln\frac{2}{\delta_{d,T_{t}}}},\,1\right\}\!,\] \[\text{where }\phi_{t,j}:=\min\left\{4\max\left\{\hat{p}_{t,j},\, \frac{25}{4}\frac{L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}\right\},\,\frac {1}{4}\right\},\]
* On Line \(26\) to \(40\), the stopping rule is changed:
* Stopping condition **(I)** on Line \(26\) \[\left(\min_{x:x\neq x_{t,j}}\hat{\Delta}_{t,j}(x_{t,j}^{*},x)- \alpha_{t,j}\geq-\varepsilon\quad\text{or}\quad\hat{p}_{j}+\beta_{t,j}<\bar{p}\right)\] (Q.2) \[\text{and}\quad T_{t}\geq(2L_{\max}/9)\ln(2/\delta_{d,T_{t}})\] where \(x_{t,j}^{*}:=\arg\max_{x\in\mathcal{X}}x^{\top}\hat{\theta}_{t,j}\).
* Lines \(27\) to \(35\): identify an \(\varepsilon\)-best arm or ascertain \(p_{j}\leq\bar{p}\) among the remaining contexts, and record these observations in \(\mathrm{Hold}\) for easy access in stopping condition **(II)**.
* Lines \(36\) to \(40\): the recommended \(\varepsilon\)-best arm is recorded, where we adopt \(\mathrm{NAN}\) to flag those contexts with small occurrence probabilities.

**Theorem Q.1**.: _Given an instance \(\Lambda\), with probability at least \(1-\delta\), Algorithm 10 can recommend an \(\varepsilon\)-best arm for all context \(j\in\Theta_{\bar{p}}\) with sample complexity_

\[\max\Bigg{\{}\tilde{O}\left(\max_{\theta_{j}^{*}\in\Theta_{\bar{p}}}\max \Bigg{\{}L_{\max},\frac{d}{\left(\Delta_{j}^{*}+\varepsilon\right)^{2}} \Bigg{\}}\cdot\frac{\ln(1/\delta)}{p_{j}}\right),\tilde{O}\left(\max_{\theta_ {j}^{*}\notin\Theta_{\bar{p}/2}}\frac{\min\left\{p_{j},\frac{1}{64}\right\}L_{ \max}\ln(1/\delta)}{(p_{j}-\bar{p})^{2}}\right),\]

\[\tilde{O}\left(\max_{\theta_{j}^{*}\in\Theta_{\bar{p}/2}\backslash\Theta_{ \bar{p}}}\min\Bigg{\{}\max\Bigg{\{}L_{\max},\frac{d}{\left(\Delta_{j}^{*}+ \varepsilon\right)^{2}}\Bigg{\}}\,\frac{\ln(1/\delta)}{p_{j}},\,\,\frac{\min \left\{p_{j},\frac{1}{64}\right\}L_{\max}\ln(1/\delta)}{(p_{j}-\bar{p})^{2}} \Bigg{\}}\right)\Bigg{\}},\]

_which can be simplified as_

\[\tilde{O}\left(\max\left\{L_{\max},\frac{d}{\varepsilon^{2}}\right\}\cdot\frac {\ln(1/\delta)}{\bar{p}}\right).\]

Proof of Theorem Q.1.: We provide a concise proof sketch for this theorem.

By adapting the stopping rule for best arm identification in stationary linear bandits to \(\varepsilon\)-best arm identification, we observe that the number of arm pulls needed for \(\varepsilon\)-best arm identification under context \(j\) is

\[T_{t,j}=\tilde{O}\bigg{(}\frac{d}{\left(\Delta_{j}^{*}+\varepsilon\right)^{2}} \ln\frac{1}{\delta}\bigg{)}.\]

The remaining problem is to determine how many context samples/changepoints are needed such that the above number of arm samples can be achieved.

Recall that \(\hat{p}_{t,j}=\frac{T_{t,j}}{T_{t}}\) (3.2) and Lemma I.2, we have

\[\mathbb{P}\left[|T_{t,j}-T_{t}p_{j}|\geq T_{t}\beta_{t,j}\big{|} \mathrm{Good}\right]\leq\delta_{d,T_{t}}.\]

In addition, we have an upper bound on \(\beta_{t,j}\) as in (J.5), so there would be sufficient arm samples for \(\varepsilon\)-best arm identification under context \(j\) if

\[T_{t}\cdot\left(p_{j}-2\cdot\frac{5}{2}\sqrt{\frac{2\min\left\{16p_{j},\frac{1 }{4}\right\}L_{\max}}{T_{t}}\ln\frac{2}{\delta_{d,T_{t}}}}\right)\geq\tilde{O} \bigg{(}\frac{d}{\left(\Delta_{j}^{*}+\varepsilon\right)^{2}}\ln\frac{1}{ \delta}\bigg{)}\]

By solving this inequality in terms of \(T_{t}\), we obtain

\[T_{t}=\tilde{O}\left(\max\left\{L_{\max},\frac{d}{\left(\Delta_{j}^{*}+ \varepsilon\right)^{2}}\right\}\cdot\frac{\ln(1/\delta)}{p_{j}}\right).\]As we aim to identify the \(\varepsilon\)-best arms under each context \(\theta_{j}^{*}\in\Theta_{\bar{p}}\), the upper bound is at least

\[T_{t}=\tilde{O}\left(\max_{\theta_{j}^{*}\in\Theta_{\bar{p}}}\max\left\{L_{\max},\frac{d}{\left(\Delta_{j}^{*}+\varepsilon\right)^{2}}\right\}\cdot\frac{\ln(1 /\delta)}{p_{j}}\right)\] (Q.3)

even if the set \(\Theta_{\bar{p}}\) is given.

Similarly, for those contexts with small occurrence probability \(\theta_{j}^{*}\notin\Theta_{\bar{p}}\), by Lemma I.2 and (J.5), we can identify them when

\[p_{j}+2\cdot\frac{5}{2}\sqrt{\frac{2\min\left\{16p_{j},\frac{1}{ 4}\right\}L_{\max}}{T_{t}}}\ln\frac{2}{\delta_{d,T_{t}}}\leq\bar{p}\] \[\Rightarrow T_{t}=\tilde{O}\left(\frac{\min\left\{p_{j},\frac{1}{64} \right\}L_{\max}\ln(1/\delta)}{(p_{j}-\bar{p})^{2}}\right).\]

Careful readers may notice that the denominator depends on a "probability gap", which can be very small. In practice, if we can actually identify the \(\varepsilon\)-best arm in those contexts, it is also acceptable. Therefore, we instead only choose not to identify the \(\varepsilon\)-best arm in those contexts \(\theta_{j}^{*}\in\Theta_{\bar{p}/2}\), which yields an upper bound

\[T_{t}=\tilde{O}\left(\max_{\theta_{j}^{*}\notin\Theta_{\bar{p}/2}}\frac{\min \left\{p_{j},\frac{1}{64}\right\}L_{\max}\ln(1/\delta)}{(p_{j}-\bar{p})^{2}} \right).\] (Q.4)

In this case, the bound is at most \(\tilde{O}\left(\frac{L_{\max}\ln(1/\delta)}{\bar{p}}\right)\). For the rest contexts \(\theta_{j}^{*}\notin\Theta_{\bar{p}/2}\setminus\Theta_{\bar{p}}\), either identifying the \(\varepsilon\)-best arm or ascertaining its small occurrence probability suffices, that is,

\[T_{t}=\tilde{O}\left(\max_{\theta_{j}^{*}\in\Theta_{\bar{p}/2} \setminus\Theta_{\bar{p}}}\min\left\{\max\left\{L_{\max},\frac{d}{\left(\Delta _{j}^{*}+\varepsilon\right)^{2}}\right\}\frac{\ln(1/\delta)}{p_{j}},\;\frac{ \min\left\{p_{j},\frac{1}{64}\right\}L_{\max}\ln(1/\delta)}{(p_{j}-\bar{p})^{ 2}}\right\}\right).\] (Q.5)

The above bound is upper bounded by \(\tilde{O}\left(\max\left\{L_{\max},\frac{d}{\varepsilon^{2}}\right\}\cdot \frac{\ln(1/\delta)}{\bar{p}}\right).\)

By taking the maximum of (Q.3), (Q.4) and (Q.5), we can obtain a high-probability problem-dependent upper bound on the sample complexity. In addition, we can get a high-probability problem-independent upper bound

\[\tilde{O}\left(\max\left\{L_{\max},\frac{d}{\varepsilon^{2}}\right\}\cdot \frac{\ln(1/\delta)}{\bar{p}}\right).\]

By setting the threshold \(\bar{p}\) carefully, the algorithm is guaranteed to terminate before \(\tau^{*}\) given the good event Good (G.1).

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The abstract and introduction accurately reflect the paper's contributions and scope. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Empirical experiments are conducted to show that Assumption \(1\) is needed for theoretical proof and the proposed algorithm is robust to mild violations of the assumptions. The limitations are discussed in Appendix B. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. 3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: The problem setting is clearly introduced in Section 2 and all theoretical results are accompanied with proofs or proof outlines. Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The procedures of the algorithms are clearly presented. All experiment details are provided in Section 6 and Appendix O. Guidelines:
* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: The code is released. Please refer to Section 6. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Please refer to Section 6 and Appendix O. Guidelines:
* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Error bars (standard deviations) are included in all experiment results. Guidelines:
* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.

* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: Please see Appendix O. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The authors conform with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: The work is mainly theoretical, thus there is no identifiable societal impact. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The work is mainly theoretical. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: The MATLAB code for the computation of G-optimal allocation used existing code, and has been mentioned and cited in Appendix O. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release new assets. Guidelines: * The answer NA means that the paper does not release new assets.

* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.