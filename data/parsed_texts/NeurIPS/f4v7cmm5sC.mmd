# Foundation Inference Models for

Markov Jump Processes

 David Berghaus1,2, Kostadin Cvejoski1,2, Patrick Seifner1,3

Cesar Ojeda4 & Ramses J. Sanchez1,2,3

Lamarr Institute1, Fraunhofer IAIS2, University of Bonn3 & University of Potsdam4

{david.berghaus, kostadin.cvejoski}@iais.fraunhofer.de

seifner@cs.uni-bonn.de, ojedamarin@uni-potsdam.de, sanchez@cs.uni-bonn.de

###### Abstract

Markov jump processes are continuous-time stochastic processes which describe dynamical systems evolving in discrete state spaces. These processes find wide application in the natural sciences and machine learning, but their inference is known to be far from trivial. In this work we introduce a methodology for _zero-shot inference_ of Markov jump processes (MJPs), on bounded state spaces, from noisy and sparse observations, which consists of two components. First, a broad probability distribution over families of MJPs, as well as over possible observation times and noise mechanisms, with which we simulate a synthetic dataset of hidden MJPs and their noisy observations. Second, a neural recognition model that processes subsets of the simulated observations, and that is trained to output the initial condition and rate matrix of the target MJP in a supervised way. We empirically demonstrate that _one and the same_ (pretrained) recognition model can infer, _in a zero-shot fashion_, hidden MJPs evolving in state spaces of different dimensionalities. Specifically, we infer MJPs which describe (i) discrete flashing ratchet systems, which are a type of Brownian motors, and the conformational dynamics in (ii) molecular simulations, (iii) experimental ion channel data and (iv) simple protein folding models. What is more, we show that our model performs on par with state-of-the-art models which are trained on the target datasets.

Our pretrained model, repository and tutorials are available online1.

Footnote 1: https://fim4science.github.io/OpenFIM/intro.html

## 1 Introduction

Very often one encounters dynamic phenomena of wildly different nature, that display features which can be reasonably described in terms of a macroscopic variable that jumps among a finite set of _long-lived_, metastable discrete states. Think, for example, of the changes in economic activity of a country, which exhibit jumps between recession and expansion states (Hamilton, 1989), or the internal motion in proteins or enzymes, which feature jumps between different conformational states (Elber and Karplus, 1987). The states in these phenomena are said to be long-lived, inasmuch as every jump event among them is rare, at least as compared to every other event (or subprocess, or fluctuation) that composes the phenomenon and that occurs, by construction, _within_ the metastable states. Such a description in terms of macroscopic variables effectively decouples the fast, intra-state events from the slow, inter-state ones, and allows for a simple probabilistic treatment of the jumping sequences as Markov stochastic processes: the _Markov Jump Processes_ (MJPs). In this work we are interested in the general problem of inferring the MJPs that best describe empirical (time series) data, recorded from dynamic phenomena of very different kinds.

To set the stage, let us assume that we want to study some \(D\)-dimensional empirical process \(\mathbf{z}(t):\mathbb{R}^{+}\rightarrow\mathbb{R}^{D}\), which features long-lived dynamic modes, trapped in some discrete set of metastable states. Let us call this set \(\mathcal{X}\). Let us also assume that we can obtain a macroscopic, coarse-grained representation from \(\mathbf{z}(t)\) -- say, with a clustering algorithm -- in which the fast, intra-state events have been integrated out (_i.e._ marginalized). Let us call this macroscopic variable \(X(t):\mathbb{R}^{+}\rightarrow\mathcal{X}\). If we now make the Markov assumption and define the quantity \(f(x|x^{\prime})\Delta t\) as the infinitesimal probability of observing one jump from state \(x^{\prime}\) (at some time \(t\)), into a different state \(x\) (at time \(t+\Delta t\)), we can immediately write down, following standard arguments (Gardiner, 2009), a differential equation that describes the probability distribution \(p_{\text{MP}}(x,t)\), over the discrete set of metastable states \(\mathcal{X}\), which encapsulates the state of the process \(X(t)\) as time evolves, that is

\[\frac{dp_{\text{MP}}(x,t)}{dt}=\sum_{x^{\prime}\neq x}\Big{(}f(x|x^{\prime})p _{\text{MP}}(x^{\prime},t)-f(x^{\prime}|x)p_{\text{MP}}(x,t)\Big{)}.\] (1)

Equation 1 is the so-called _master equation_ of the MJP whose solutions are completely characterized by an initial condition \(p_{\text{MP}}(x,t=0)\) and the transition rates \(f:\mathcal{X}\times\mathcal{X}\rightarrow\mathbb{R}^{+}\).

With these preliminaries in mind, we shall say that to infer an MJP from a set of (noisy) observations \(\mathbf{z}(\tau_{1}),\dots,\mathbf{z}(\tau_{l})\) on the process \(\mathbf{z}(t)\), recorded at some observation times \(\tau_{1},\dots,\tau_{l}\), means to infer both the transition rates and the initial condition determining the _hidden_ MJP \(X(t)\) that best explains the observations. In practice, statisticians typically assume that they directly observe the coarse-grained process \(X(t)\). That is, they assume they have access to the (possibly noisy) values \(x_{1},\dots,x_{l}\), taken by \(X(t)\) at the observation times \(\tau_{1},\dots,\tau_{l}\) (see Section 2). We shall start from the same assumptions. Statisticians then tackle the inference problem by (i) defining some (typically complex) model that encodes, in one way or the other, equation 1 above; (ii) parameterizing the model with some trainable parameter set \(\theta\); and (iii) updating \(\theta\) to fit the empirical dataset.

One issue with this approach is that it turns the inference of hidden MJPs into an instance of an _unsupervised learning problem_, which, as history shows, is far from trivial (see Section 2). Another major issue is that, if one happens to succeed in training said model, the trained parameter set \(\theta^{*}\) will usually be overly specific to the training set \(\{(x_{1},\tau_{1}),\dots,(x_{l},\tau_{l})\}\), which means it will likely struggle to handle a second empirical process, even if the latter can be described by a similar MJP. Figure 1 contains snapshots from two empirical processes of very different nature. The figure on the left shows a set of observations (blue circles) recorded from the discrete flashing ratchet process (black line). The figure on the right shows the ion flow across a cell membrane, which jumps between different activity levels (blue line). Despite the vast differences between the physical mechanisms underlying each of these processes, the coarse-grained representations of the second one (black line) is abstract enough to be strikingly similar to the first one. Now, we expect that -- at this level of representation -- one could train _a single inference model to fit each process_ (separately). Unfortunately, we also expect that an inference model trained to fit _only one_ of these (coarse-grained) processes, will have a hard time describing the second one.

In this paper we will argue that the _notion of an MJP description_ (in coarse-grained space) is simple enough, that it can be encoded into the weights of a single neural network model. Indeed, instead of training, in an unsupervised manner, a complex model (which somehow encodes the

Figure 1: Processes of very different nature (seem to) feature similar jump processes. _Left_: State values (blue circles) recorded from the discrete flashing ratchet process (black line). _Right_: Current signal (blue line) recorded from the viral potassium channel \(\text{Kcv}_{\text{MT35}}\), together with one possible coarse-grained representation (black line).

master equation) on a single empirical process; we will train, in a supervised manner, a simple neural network model on a _synthetic dataset that is composed of many different MJPs, and hence implicitly encodes the master equation_. This procedure can be understood as an _amortization_ of the probabilistic inference process through a single _recognition model_, and is therefore akin to the works of Stuhlmuller et al. (2013), Heess et al. (2013) and Paige and Wood (2016). Rather than treating, as these previous works do, our (pretrained) recognition model as auxiliary to Monte Carlo or expectation propagation methods, we employ it to directly infer hidden MJPs from various synthetic, simulation and experimental datasets, _without any parameter fine-tuning_. We thus adopt the "zero-shot" terminology introduced by Larochelle et al. (2008), by which we mean that our procedure aims to recognize objects (i.e. MJPs) whose instances (i.e. noisy and sparse series of observations on them) may have not been seen during training. We have recently shown that such an amortization can be used to train a recognition model to perform _zero-shot imputation_ of time series data (Seifner et al., 2024). Below we demonstrate that it can also be used to train a model of minimal inductive biases, to perform _zero-shot inference_ of hidden MJPs from empirical processes of very different kinds, which take values in state spaces of different sizes. We shall call this recognition model _Foundation Inference Model_2 (FIM) for Markov jump processes.

Footnote 2: We name our model foundation model because it aligns with the definition proposed by Bommasani et al. (2021). Indeed, they define foundation models as any model that is trained on broad data (generally using self-supervision at scale) that can be adapted to a wide range of downstream tasks.

In what follows, we first review both classical and recent solutions to the MJP inference problem in Section 2. We then introduce the FIM methodology in Section 3, which consists of a synthetic data generation model and a neural recognition model. In Section 4 we empirically demonstrate that our methodology is able to infer MJPs from a discrete flashing ratchet process, as well as from molecular dynamics simulations and experimental ion channel data, all in a zero-shot fashion, while performing on par with state-of-the-art models which are trained on the target datasets. Finally, Section 5 closes the paper with some concluding remarks about future work, while Section 6 comments on the main limitations of our methodology.

## 2 Related Work

The inference of MJP from noisy and sparse observations (in coarse-grained space) is by now a classical problem in machine learning. There are three main lines of research. The first (and earliest) one attempts to directly optimize the MJP transition rates, to maximize the likelihood of the discretely observed MJP via expectation maximization (Asmussen et al., 1996; Bladt and Sorensen, 2005; Metzner et al., 2007). Thus, these works encode the MJP inductive bias directly into their architecture. The second line of research leverages a Bayesian framework to infer the posterior distribution over the transition rates, through various Markov chain Monte Carlo (MCMC) algorithms (Boys et al., 2008; Fearnhead and Sherlock, 2006; Rao and Teg, 2013; Hajiaghayi et al., 2014). Accordingly, these

Figure 2: Foundation Inference Model (FIM) for MJP. _Left_: Graphical model of the FIM (synthetic) data generation mechanism. Filled (empty) circles represent observed (unobserved) random variables. The light-blue rectangle represents the continuous-time MJP trajectory, which is observed discretely in time. See main text for details regarding notation. _Right_: Inference model. The network \(\psi_{1}\) is called \(K\) times to process \(K\) different time series. Their outputs is first processed by the attention network \(\Omega_{1}\) and then by the FNNs \(\phi_{1}\), \(\phi_{2}\) and \(\phi_{3}\) to obtain the estimates \(\hat{\mathbf{F}}\), \(\log\text{Var}\,\hat{\mathbf{F}}\) and \(\hat{\boldsymbol{\pi}}_{0}\), respectively.

simulation-based approaches encode the MJP inductive bias directly into their trainable sampling distributions. The third one, also Bayesian in character, involves variational inference. Within it, one finds again MCMC (Zhang et al., 2017), as well as expectation maximization (Opper and Sanguinetti, 2007) and moment-based (Wildner and Koeppl, 2019) approaches. More recently, Seifiner and Sanchez (2023) used neural variational inference (Kingma and Welling, 2013) and neural ODEs (Chen et al., 2018) to infer an implicit distribution over the MJP transition rates. All these variational methods encode the MJP inductive bias into their training objective and, in some cases, into their architecture too.

Besides the model of Seifiner and Sanchez (2023), which automatically infers the coarse-grained representation \(X(t)\) from \(D\)-dimensional, continuous signals, all the solutions above tackle the MJP inference problem directly in coarse-grained space. Yet below, we also investigate the conformational dynamics of physical systems for which the recorded data lies in a continuous space. To approach such type of problems, we will first need to define a coarse-grained representation of the state space of interest. Fortunately for us, there is a large body of works, within the molecular simulation community, precisely dealing with different methods to obtain such representations, and we refer the reader to _e.g._Noe et al. (2020) for a review. McGibbon and Pande (2015), for example, leveraged one such method to infer the MJP transition rates describing a molecular dynamics simulation via maximum likelihood. Alternatively, researchers have also treated the conformational states in these systems as core sets, and inferred phenomenological MJP rates from them (Schutte et al., 2011), or modelled the fast intra-state events as diffusion processes, indexed by a hidden MJP, and inferred the latter either via MCMC (Kilic et al., 2021; Kohs et al., 2022) or variational (Horenko et al., 2006; Kohs et al., 2021) methods.

In this work we tackle the classical MJP inference problem _on coarse-grained space_ and present, to the best of our knowledge, its first zero-shot solution.

## 3 Foundation Inference Models

In this section we introduce a novel methodology for zero-shot inference of Markov jump processes which frames the inference task as a supervised learning problem. Our main assumption is that the space of _realizable MJPs_3, which take values on bounded state spaces that are not too large, is simple enough to be covered by a heuristically constructed synthetic distribution over noisy and discretely observed MJPs. If this assumption were to hold, a model trained to infer the hidden MJPs within a synthetic dataset sampled from this distribution _would automatically perform zero-shot inference on any unseen sequence of empirical observations_. We do not intend to formally prove this assumption. Rather, we will empirically demonstrate that a model trained in such a way can indeed perform zero-shot inference of MJPs in a variety of cases.

Footnote 3: By realizable MJPs we mean here MJPs that can be inferred from physical processes, given the typical experimental constraints, like _e.g._ temporal or spatial resolution.

Our methodology has two components. First, a data generation model that encodes our believes about the class of realizable MJPs we aim to model. Second, a neural recognition model that maps subsets of the simulated MJP observations onto the initial condition and rate matrix of their target MJPs. We will explore the details of these two components in the following sections.

### Synthetic Data Generation Model

In this subsection we define a broad distribution over possible MJPs, observation times and noise mechanisms, with which we simulate an ensemble of noisy, discretely observed MJPs. Before we start, let us remark that we will slightly abuse notation and denote both probability distributions and their densities with the same symbols. Similarly, we will also denote both random variables and their values with the same symbols.

Let us denote the size of the largest state space we include in our ensemble with \(C\), and arrange all transition rates, for every MJPs within the ensemble, into \(C\times C\) rate matrices. Let us label these matrices with \(\mathbf{F}\). We define the probability of recording the noisy sequence \(x^{\prime}_{1},\ldots,x^{\prime}_{l}\in\mathcal{X}\), at the observation times \(0<\tau_{1}<\cdots<\tau_{l}<T\), with \(T\) the observation time horizon, as follows

\[\prod_{i=1}^{l}p_{\text{noise}}(x_{i}^{\prime}|x_{i},\rho_{x})p_{\text{MP}}(x_{i} |\tau_{i},\mathbf{F},\pi_{0})p_{\text{grid}}(\tau_{1},\ldots,\tau_{l}|\rho_{\tau })p_{\text{rates}}(\mathbf{F}|\mathbf{A},\rho_{f})p(\mathbf{A},\rho_{f})p( \mathbf{\pi}_{0}|\rho_{0}).\] (2)

Next, we specify the different components of Eq. 2, starting from the right.

**Distribution over initial conditions**. The distribution \(p(\boldsymbol{\pi}_{0}|\rho_{0})\), with hyperparameter \(\rho_{0}\), is defined over the \(C\)-simplex, and encodes our beliefs about the initial state (_i.e._ the preparation) of the system. It enters the master equation as the class probabilities of the _categorical distribution_ over the states of the system, at the start of the process. That is \(p_{\text{MP}}(x,t=0)=\text{Cat}(\boldsymbol{\pi}_{0})\). We either choose \(\boldsymbol{\pi}_{0}\) to be the class probabilities of the stationary distribution of the process, or sample it from a Dirichlet distribution. Appendix B provides the specifics.

**Distribution over rate matrices**. The distribution \(p_{\text{rates}}(\mathbf{F}|\mathbf{A},\rho_{f})\) over the rate matrices encodes our beliefs about the class of MJPs we expect to find in practice. We define it to cover MJPs with state spaces whose sizes range from 2 until \(C\), because we want our FIM to be able to handle processes taking values in all those spaces. The distribution is conditioned on the adjacency matrix \(\mathbf{A}\), which encodes only connected state spaces (_i.e._ irreducible embedded Markov chains only), and a hyperparameter \(\rho_{f}\) which encodes the range of rate values within the ensemble. Specifically, we define the transition rates as \(F_{ij}=a_{ij}f_{ij}\), where \(a_{ij}\) is the corresponding entry of \(\mathbf{A}\) and \(f_{ij}\) is sampled from a set of Beta distributions, with different hyperparameters \(\rho_{f}\). Note that these choices restrict the values of the transition rates within the ensemble to the interval \((0,1)\) and hence, they restrict the number of _resolvable transitions_ within the time horizon \(T\) of the simulation. We refer the reader to Appendix B, where we specify the prior \(p(\mathbf{A},\rho_{f})=p(\mathbf{A})p(\rho_{f})\) and its consequences, as well as give details about the sampling procedure. We also discuss the main limitations of choosing a Beta prior over the transition rates in Section 6.

**Distribution over observation grids**. The distribution \(p_{\text{grid}}(\tau_{1},\ldots,\tau_{l}|\rho_{\tau})\), with hyperparameter \(\rho_{\tau}\), gives the probability of observing the MJP at the times \(\tau_{1},\ldots,\tau_{l}\), and thus encodes our uncertainty about the recording process. Given that we do not know a priori whether the data will be recorded regularly or irregularly in time, nor we know its recording frequency, we define this distribution to cover both regular and irregular cases, as well as various recording frequencies. Note that the number of observation points on the grid is variable. Please see Appendix B for details.

**Distribution over noise process**. Just as the (instantaneous) solution of the master equation \(p_{\text{MP}}(x|t,\mathbf{F},\boldsymbol{\pi}_{0})\), the noise distribution \(p_{\text{noise}}(x^{\prime}|x,\rho_{x})\), with hyperparameter \(\rho_{x}\), is defined over the set of metastable states \(\mathcal{X}\). Recall that FIM solves the MJP inference problem directly in coarse-grained space. The noise distributions then encodes both, possible measurement errors that propagate through the coarse-grained representation, or noise in the coarse-grained representation itself. We provide details of its implementation in Appendix B.

We use the generative model, Eq. 2 above, to generate \(N\) MJPs, taking values on state spaces with sizes ranging from 2 to \(C\). We then sample \(K\) paths per MJP, with probability \(p(K)\), on the interval \([0,T]\). The \(j\)th instance of the dataset thus consists of \(K\) paths and is given by

\[\mathbf{F}_{j}\sim p_{\text{rates}}(\mathbf{F}|\mathbf{A}_{j}, \rho_{fj}),\text{ and }\boldsymbol{\pi}_{0j}\sim p(\boldsymbol{\pi}_{0}|\rho_{0}),\text{ with }(\mathbf{A}_{j},\rho_{fj})\sim p(\mathbf{A},\rho_{f}),\] \[\text{so that }\left\{X_{jk}(t)\right\}_{k=1}^{K}\sim\text{ Gillespie}(\mathbf{F}_{j},\boldsymbol{\pi}_{0j}),\] (3) \[\text{and }\left\{x_{jki}^{\prime}\sim p_{\text{noise}}(x^{\prime}|X_{ jk}(\tau_{jk}))\right\}_{(k,i)=(1,1)}^{(K,l)},\text{ with }\left\{\tau_{jk1},\ldots,\tau_{jkl}\right\}_{k=1}^{K}\sim p_{\text{grid}}(\tau_{1}, \ldots,\tau_{l}|\rho_{\tau}),\]

where Gillespie denotes the Gillespie algorithm we use to sample the MJP paths (see Algorithm 1). Note that we make the number of paths (\(K\) above) per MJP random, because we do not know a priori how many realizations (_i.e._ experiments), from the empirical process of interest, will be available at the inference time. We refer the reader to Appendix B for additional details.

Figure 2 illustrates the complete data generation process.

### Supervised Recognition Model

In this subsection we introduce a neural recognition model that processes a set of \(K\) time series of the form \(\{(x_{k1}^{\prime},\tau_{k1}),\ldots,(x_{kl}^{\prime},\tau_{kl})\}_{k=1}^{K}\), as generated by the procedure in Eq. 3 above, and estimatesthe intensity rate matrix \(\mathbf{F}\) and initial distribution \(\bm{\pi}_{0}\) of the hidden MJP. Practically speaking, we would like the model to be able to infer MJPs from time series with observation times _on any scale_. To ensure this, we first normalize all observation times to lie on the unit interval, by dividing them by the maximum observation time \(\tau_{\text{max}}=\text{max}\{\tau_{k1},\dots,\tau_{kl}\}_{k=1}^{K}\), and then rescale the output of the model accordingly (see Appendix C for details).

Let us use \(\phi\), \(\psi\) and \(\Omega\) to denote feed-forward, sequence processing networks, and attention networks, respectively. Thus \(\psi\) can denote _e.g._ LSTM or Transformer networks, while \(\Omega\) can denote _e.g._ a self-attention mechanism. Let us also denote the networks' parameters with \(\theta\).

We first process each time series with a network \(\psi_{1}\) to get a set of \(K\) embeddings, which we then summarize into a global representation \(\mathbf{h}_{\theta}\) through the attention network \(\Omega_{1}\). In equations, we write

\[\mathbf{h}_{\theta}=\Omega_{1}(\mathbf{h}_{1\theta},\dots,\mathbf{h}_{K \theta},\theta)\;\;\text{with}\;\;\mathbf{h}_{k\theta}=\psi_{1}(x^{\prime}_{k 1},\tau_{k1},\dots,x^{\prime}_{kl},\tau_{kl},\theta)\;\;\text{and}\;k=1,\dots,K.\] (4)

Next we use the global representation to get an estimate of the intensity rate matrix, which we artificially model as a Gaussian variable with positive mean, and the initial distribution of the hidden MJP as follows

\[\mathbf{\hat{F}}=\exp(\phi_{1}(\mathbf{h}_{\theta},\theta)),\quad\text{Var} \,\mathbf{\hat{F}}=\exp(\phi_{2}(\mathbf{h}_{\theta},\theta))\;\;\text{and} \quad\mathbf{\hat{\pi}}_{0}=\phi_{3}(\mathbf{h}_{\theta},\theta),\] (5)

where the exponential function ensures the positivity of our estimates, and the variance is used to represent the model's _uncertainty_ in the estimation of the rates (Seifner et al., 2024). The right panel of Figure 2 summarizes the recognition model, and Appendix C provides additional information about the inputs to, outputs of and rescalings done by the model.

**Training objective**. We train the model to maximize the likelihood of its predictions, taking care of the exact zeros (_i.e._ the missing links) in the data. To wit

\[\mathcal{L} =\] (6) \[\qquad\quad-\mathop{\mathbb{E}}_{\bm{\pi}_{0}\sim p}\Bigl{\{} \sum_{i=1}^{C}\pi_{i0}\log\hat{\pi}_{i0}\Bigr{\}},\]

where the second term is nothing but the mean-squared error of the predicted rates \(\hat{f}_{ij}\) (and its standard deviation) when the corresponding link is missing, and can be understood as a regularizer with weight \(\lambda\). The latter is a hyperparameter.

**FIM context number**. During training, FIM processes a variable number \(K\) of time series, which lies on the interval \([K_{\text{min}},K_{\text{max}}]\). Similarly, each one of these time series has a variable number \(l\) of observation points, which lies on the interval \([l_{\text{min}},l_{\text{max}}]\). We shall say that FIM needs a bare minimum of \(K_{\text{min}}l_{\text{min}}\) input data points to function. Perhaps unsurprisingly, we have empirically seen that FIM perform bests when processing \(K_{\text{max}}l_{\text{max}}\) data points. Going significantly beyond this number seems nevertheless to decrease the performance of FIM. We invite the reader to check Appendix D for details.

Let us define then, for the sake of convenience, the FIM context number \(c(K,l)=Kl\) as the number of input points4 FIM makes use of to estimate \(\mathbf{F}\) and \(\bm{\pi}_{0}\).

Footnote 4: We can think about it as the context length in large language models.

## 4 Experiments

In this section we test our methodology on five datasets of varying complexity, and corrupted by noise signals of very different nature, whose hidden MJPs are known to take values in state spaces of different sizes. In what follows we use _one and the same_ (pretrained) FIM to infer hidden MJPs from all these datasets, _without any parameter fine-tuning_. Our FIM was (pre)trained on a dataset of 45K MJPs, defined over state spaces whose sizes range from 2 to 6. A maximum of (\(K=\))300 realizations (paths) _per MJP_ were observed during training, everyone of which spanned a time-horizon \(T=10\), recorded at a maximum of 100 time points, 1% of which were mislabeled. Given these specifications, FIM is expected to perform best for the context number \(c(300,100)\) during evaluation. Additionalinformation regarding model architecture, hyperparameter selection and other training details can be found in Appendix D.

**Baselines**: Depending on the dataset, we compare our findings against the NeuralMJP model of Seifner and Sanchez (2023), the switching diffusion model (SDiff) of Kohs et al. (2021), and the discrete-time Markov model (VampNets) of Mardt et al. (2017).

All these baselines are trained on the target datasets.

### The Discrete Flashing Ratchet (DFR): A Proof of Concept

In statistical physics, the ratchet effect refers to the rectification of thermal fluctuations into directed motion to produce work, and goes all the way back to Feynman (Feynman et al., 1965). Here we consider a simple example thereof, in which a Brownian particle, immersed in a thermal bath at unit temperature, moves on a one-dimensional lattice. The particle is subject to a linear, periodic and asymmetric potential of maximum height \(2V\) that is switched on and off at a constant rate \(r\). The potential has three possible values when is switched on, which correspond to three of the states of the system. The particle jumps among them with rate \(f_{ij}^{\text{on}}\). When the potential is switched off, the particle jumps freely with rate \(f_{ij}^{\text{off}}\). We can therefore think of the system as a six-state system, as illustrated in Figure 3. Similar to Roldan and Parrondo (2010), we now define the transition rates as

\[f_{ij}^{\text{on}}=\exp\left(-\frac{V}{2}(j-i)\right),\ \ \text{for}\ i,j\in(0,1,2);\ \ \ \ f_{ij}^{\text{off}}=b,\ \ \text{for}\ i,j\in(3,4,5).\] (7)

Given these specifics, we consider the parameter set \((V,r,B)=(1,1,1)\) together with the dataset simulated by Seifner and Sanchez (2023), which consists of 5000 paths (in coarse-grained space) recorded on an irregular grid of 50 time points. The task is to infer \((V,r,B)\) from these time series. NeuralMJP infers a _global_ distribution over the rate matrices and hence relies on their entire train set, which amounts to about 4500 time series. We therefore report FIM evaluations with context number \(c(300,50)\) on that same train set, averaged over 15 (non-overlapping) batches in Table 1.

The results show that FIM performs on par with (or even better than) NeuralMJP, _despite not having been trained on the data_. Note in particular that our results are sharply peaked around their mean, indicating that a context of \(c(300,50)\) points only contains enough information to describe the data well. What is more, Table 16 in the Appendix demonstrates that FIM can infer vanishing transition rates as well (see Eq. 6). Now, being able to infer the rate matrix in zero-shot mode allows us to immediately estimate a number of observables of interest _without any training_. Stationary distributions, relaxation times and mean first-passage times (see Appendix A for their definition), as well as time-dependent moments, can all be computed zero-shot via FIM. For example, we report on the left block of Figure 4 the time-dependent class probabilities (_i.e._ the master eq. solutions) computed with the FIM-inferred rate matrix (black), against the ground-truth solution (blue). The agreement is very good.

**Zero-shot estimation of entropy production**. The DFR model is interesting because the random switching combined with the asymmetry in the potential make it more likely for the particle to jump towards the right (see Figure 4). Indeed, that is the ratchet effect. As a consequence, the system features a stationary distribution with a net current -- the so-called _non-equilibrium steady state

\begin{table}
\begin{tabular}{c c c c} \hline \hline  & \(V\) & \(r\) & \(b\) \\ \hline Ground Truth & \(1.00\) & \(1.00\) & \(1.00\) \\ \hline NeuralMJP & \(\mathbf{1.06}\) & \(1.17\) & \(1.14\) \\ FIM & \(1.11(7)\) & \(\mathbf{0.99(8)}\) & \(\mathbf{0.98(5)}\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Inference of the discrete flashing ratchet process. The FIM results correspond to FIM evaluations with context number \(c(300,50)\), averaged over 15 batches.

Figure 3: Illustration of the six-state discrete flashing ratchet model. The potential \(V\) is switched on and off at rate \(r\). The transition rates \(f_{ij}^{\text{on}},f_{ij}^{\text{off}}\) allow the particle to propagate through the ring.

(Ajdari and Prost, 1992), which is characterized by a non-vanishing (stochastic) entropy production. The development of (neural) estimators of entropy production is a very active topic of current research (see _e.g._ Kim et al. (2020) and Otsubo et al. (2022)). Given that the entropy production can be written down in closed form as a function of both the rate matrix and the master eq. solution (see _e.g._ Seifert (2012)), we can readily use FIM to estimate it.

Figure 4 displays the total entropy production computed with FIM for a set of different potentials. The results are averaged over 15 FIM evaluations with \(c(300,50)\) and are again in very good agreement with the ground truth. It is noteworthy that FIM, trained on our heuristically constructed dataset, captures well _a continuous set of MJPs_. That is, we evaluate _one and the same_ FIM over different datasets, each sampled from a DFR model with a different potential value. In sharp contrast, state-of-the-art models need to be _retrained_ for every new potential value (Kim et al., 2020).

**Zero-shot simulation of the DFR process**. Inferring the rate matrix and initial condition of a MJP process entails that one can also _sample from it_. Our FIM can thus be used as a _zero-shot generative model_ for MJPs. However, to test the quality of said MJP realizations wrt. some target MJP, we need a distance between the two. Here we propose to use the Hellinger distance (Le Cam and Yang, 2000) to first estimate the divergence between a sequence of (local) histogram pairs, recorded at a given set of observation times, and then average the local estimates along time. Appendix F.1 empirically demonstrates that this pragmatically defined MJP distance is sensible.

Table 2 reports the time-averaged Hellinger distance between 1000 (ground-truth) DFR paths and 1000 paths sampled from (the MJPs inferred by) NeuralMJP and FIM. We repeat this calculation 100 times, for 1000 newly sampled paths from NeuralMJP and FIM, but the same 1000 target paths, to compute the mean values and error bars in the Table. The results show that the zero-shot DFR simulation obtained through FIM is on par with the NeuralMJP-based simulation, wrt. the ground truth.

### Switching Ion Channel (IonCh): Zero-Shot Inference of Three-State MJP

In this section we study the conformational dynamics of the viral ion channel KcvMT325, which exhibits three metastable states (Gazzarrini et al., 2006). Specifically, we analyse the ion flow across the membrane as the system jumps between its metastable configurations. This ion flow was recorded at a frequency of 5kHz over one second. Figure 1 shows one snapshot of these recordings, which were made available to us via private communication (see the Acknowledgements). Our goal is to infer physical observables -- like the stationary distribution and mean first-passage times -- of the conformational dynamics, and to compare our findings against the SDiff model of Kohs et al. (2021) and NeuralMJP.

The recordings live in real space, which means that we first need to obtain a coarse-grained representation (CGR) from them, before we can apply FIM. Here we consider two CGRs: the CGR inferred

Figure 4: Zero-shot inference of DFR process. _Left_: master eq. solution \(p_{\text{MPP}}(x,t)\) as time evolves, wrt. the (averaged) FIM-inferred rate matrix is shown in black. The ground-truth solution is shown in blue. _Right_: Total entropy production computed from FIM (over a time-horizon \(T=2.5\left[a.u.\right]\)). The model works remarkably well for a _continuous range_ of potential values.

by NeuralMJP and a naive CGR obtained with a Gaussian Mixture Model (GMM). Given that we only have 5000 observations available, we make use of a single FIM evaluation with context number \(c(50,100)\). We infer two FIM rate matrices, one per each CGR, which we label as FIM-NMJP and FIM-GMM.

Table 3 contains the inferred stationary distributions from all models and evidences that a single FIM evaluation is enough to unveil the long-time asymptotics of the process. Similarly, Table 15 in the Appendix, which contains the inferred mean-first passage times, demonstrates that FIM makes the same inference about the short-term dynamics of the process as do SDiff and NeuralMJP. See Appendix F for additional results.

**Zero-shot simulation of switching ion channel process**. Just as we did with the DFR process, we can use FIM to simulate the switching ion channel process in coarse-grained space. Since only paths on the same CG space can be compared, we evaluate NeuralMJP against FIM-NMJP. To construct the target distribution, we leverage another 30 seconds of measurements, which amount to 150K observations that have not been seen by any of the models. The results in Table 2 indicate that our zero-shot simulations is statistically closer to the ground-truth process than the NeuralMJP simulation.

### Alanine Dipeptide (ADP): Zero-Shot Inference of Six-State MJP

Alanine dipeptide is 22-atom molecule widely used as benchmark in molecular dynamics simulation studies. Its popularity stems from the fact that the heavy-atom dynamics, which jumps between six metastable states, can be fully described in terms of the dihedral (torsional) angles \(\psi\) and \(\phi\) (see _e.g._Mironov et al. (2019) for details).

We examine an all-atom ADP simulation of 1 microsecond, which was made available to us via private communication (see the Acknowledgements below), and compare against both, the VampNets model of Mardt et al. (2017) and NeuralMJP. The data consists of the values taken by the dihedral angles as time evolves and thus needs to be mapped onto some coarse-grained space. We again make use of NeuralMJP to obtain a CGR. We then use FIM with context number \(c(300,100)\) to process 32 100-point time windows of the simulation and compute an average rate matrix. Note that this is the optimal context number of our pretrained model. Table 4 (and Appendix F.2) confirms that, once again, FIM can infer the same physical properties from the ADP simulation as the baselines.

**Zero-shot simulation of the alanine dipeptide**. Simulations in coarse-grained space for molecular dynamics is a high-interest research direction (Husic et al., 2020). Here we demonstrate that FIM can be used to simulate the ADP process in zero-shot mode. Indeed, Table 2 reports the distance from both NeuralMJP and FIM to a target ADP process, computed from 200 paths with 100 observations each. Once more, FIM performs comparable to NeuralMJP.

### Zero-Shot Inference of Two-State MJPs

Finally, we consider two additional systems that feature jumps between two metastable states: a simple protein folding model and a two-mode switching system. We invite the reader to check out Appendix F.5 and F.6 for the details. That being said, Table 8 reports the distance of both NeuralMJP and FIM wrt. the empirical protein folding process (PFold). The high variance indicates that the distance cannot resolve any difference between the processes given the available number of samples.

\begin{table}
\begin{tabular}{r c c} \hline \hline Dataset & NeuralMJP & FIM \\ \hline DFR & \(0.30(0.06)\) & \(0.27(0.06)\) \\ IonCh & \(0.48(0.02)\) & \(\mathbf{0.41}(\mathbf{0.02})\) \\ ADP & \(1.38(0.52)\) & \(1.39(0.47)\) \\ PGold & \(0.015(0.015)\) & \(0.014(0.014)\) \\ \hline \hline \end{tabular}
\end{table}
Table 2: Time-averaged Hellinger distances between empirical processes and samples from either NeuralMJP or FIM [in a 1e-2 scale] (lower is better). Mean and std. are computed from a set of 100 histograms

\begin{table}
\begin{tabular}{r c c c} \hline \hline  & Bottom & Middle & Top \\ \hline SDiff & 0.17961 & 0.14987 & 0.67052 \\ NeuralMJP & 0.17672 & 0.09472 & 0.72856 \\ FIM-NMJP & 0.18224 & 0.10156 & 0.71621 \\ FIM-GMM & 0.19330 & 0.08124 & 0.72546 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Stationary distribution inferred from the switching ion channel experiment. FIM-NMJP and FIM-GMM correspond to our inference from different coarse-grained representations. The results agree well.

## 5 Conclusions

In this work we introduced a novel methodology for zero-shot inference of Markov jump processes and its Foundation Inference Model (FIM). We empirically demonstrated that _one and the same_ FIM can be used to estimate stationary distributions, relaxation times, mean first-passage times, time-dependent moments and thermodynamic quantities (_i.e._ the entropy production) from noisy and discretely observed MJPs, taking values in state spaces of different dimensionalities, _all in zero-shot mode_. To the best of our knowledge, FIM is also the first zero-shot generative model for MJPs.

_Future work_ shall involve extending our methodology to Birth and Death processes, as well as considering more complex (prior) transition rate distributions. See our discussion on Limitations in the next section, for details.

## 6 Limitations

The main limitations of our methodology clearly involve our synthetic distribution. Evaluating FIM on empirical datasets whose distribution significantly deviates from our synthetic distribution will, inevitably, yield poor estimates. Consider Figure 4 (right), for example. The performance of FIM quickly deteriorates for \(V\geq 3\), for which the ratio between the largest and smallest rates gets larger than about three orders of magnitude. These cases are unlikely under our prior Beta distributions, and hence effectively lie outside of our synthetic distribution.

More generally, the MJP dynamics underlying phenomena that feature long-lived, metastable states, ultimately depends on the shape of the energy landscape characterizing the set \(\mathcal{X}\), inasmuch as the transition rates between metastable states \(i\) and \(j\) (\(f_{ij}\) in our notation) are characterized by _the depth of the energy traps_ (that is, the height of the barrier between them).

In equations, we write

\[f_{ij}=\exp\left(\frac{-E_{j}}{T}\right),\] (8)

where \(E_{j}\) is the \(j\)th trap depth, and \(T\) is the temperature of the system. Therefore, the distribution over energy traps determines the distribution over transition rates.

Just to give an example, if we studied systems with exponentially distributed energy traps -- as _e.g._ in the classical Trap model of glassy systems of Bouchaud (1992) -- we would immediately find \(p(f)\propto Tf^{T-1}\). Transition rates sampled from such power-law distributions clearly lie outside our ensemble of Beta distributions, even if we use our rescaling trick. Future work shall explore training FIM on synthetic MJPs featuring power-law-distributed transition rates.

## Acknowledgements

This research has been funded by the Federal Ministry of Education and Research of Germany and the state of North-Rhine Westphalia as part of the Lamarr Institute for Machine Learning and Artificial Intelligence. Additionally, Cesar Ojeda was supported by Deutsche Forschungsgemeinschaft (DFG) - Project-ID 318763901 - SFB1294.

We would like to thank Lukas Kohs for sharing the experimental ion channel data with us. The actual experiment was carried out by Kerri Kukovetz and Oliver Rauh while working in the lab of Gerhard

\begin{table}
\begin{tabular}{c c c c c c c|c c c c c} \hline \hline  & \multicolumn{4}{c|}{Probability per State} & \multicolumn{4}{c}{Relaxation time scales (in \(ns\))} \\  & I & II & III & IV & V & VI & & & & & \\ \hline VAMPnets & 0.30 & 0.24 & 0.20 & 0.15 & 0.11 & 0.01 & 0.008 & 0.009 & 0.055 & 0.065 & 1.920 \\ NeuralMJP & 0.30 & 0.31 & 0.23 & 0.10 & 0.05 & 0.01 & 0.009 & 0.009 & 0.043 & 0.069 & 0.774 \\ FIM & 0.28 & 0.28 & 0.24 & 0.07 & 0.10 & 0.03 & 0.008 & 0.009 & 0.079 & 0.118 & 0.611 \\ \hline \hline \end{tabular}
\end{table}
Table 4: _Left:_ stationary distribution of the ADP process. The states are ordered in such a way that the ADP conformations associated with a given state are comparable between the VampNets and NeuralMJP CGRs. _Right_: relaxation time scales to stationarity. FIM agrees well with both baselines.

Thiel of TU Darmstadt. Similarly, we would like to thank Nick Charron and Cecilia Clementi, from the Theoretical and Computational Biophysics group of the Freie Universitat Berlin, for sharing the all-atom alanine dipeptide simulation data with us. The simulation was carried out by Christoph Wehmeyer while working in the research group of Frank Noe of the Freie Universitat Berlin.

## References

* Ajjdari and Prost [1992] Armand Ajdari and Jacques Prost. Mouvement induit par un potentiel periodique de basse symetrie: dielectrophorese pulsee. _Comptes rendus de l'Academie des sciences. Serie 2, Mecanique, Physique, Chimie, Sciences de l'univers, Sciences de la Terre_, 315(13):1635-1639, 1992.
* Asmussen et al. [1996] Soren Asmussen, Olle Nerman, and Marita Olsson. Fitting phase-type distributions via the em algorithm. _Scandinavian Journal of Statistics_, pages 419-441, 1996.
* Bladt and Sorensen [2005] Mogens Bladt and Michael Sorensen. Statistical inference for discretely observed markov jump processes. _Journal of the Royal Statistical Society: Series B (Statistical Methodology)_, 67(3):395-410, 2005.
* Bommasani et al. [2021] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the opportunities and risks of foundation models. _arXiv preprint arXiv:2108.07258_, 2021.
* Bouchaud [1992] Jean-Philippe Bouchaud. Weak ergodicity breaking and aging in disordered systems. _Journal de Physique I_, 2(9):1705-1713, 1992.
* Boys et al. [2008] Richard J Boys, Darren J Wilkinson, and Thomas BL Kirkwood. Bayesian inference for a discretely observed stochastic kinetic model. _Statistics and Computing_, 18(2):125-135, 2008.
* Chen et al. [2018] Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David Kristjanson Duvenaud. Neural ordinary differential equations. In _Neural Information Processing Systems_, 2018.
* Elber and Karplus [1987] R Elber and Martin Karplus. Multiple conformational states of proteins: a molecular dynamics analysis of myoglobin. _Science_, 235(4786):318-321, 1987.
* Erdos and Renyi [1959] P Erdos and A Renyi. On random graphs i. _Publ. math. debrecn_, 6(290-297):18, 1959.
* Fearnhead and Sherlock [2006] Paul Fearnhead and Chris Sherlock. An exact gibbs sampler for the markov-modulated poisson process. _Journal of the Royal Statistical Society: Series B (Statistical Methodology)_, 68(5):767-784, 2006.
* Feynman et al. [1965] Richard P Feynman, Robert B Leighton, Matthew Sands, and Everett M Hafner. The feynman lectures on physics; vol. i. _American Journal of Physics_, 33(9):750-752, 1965.
* Gardiner [2009] Crispin W. Gardiner. Stochastic methods: A handbook for the natural and social sciences. 2009.
* Gazzarrini et al. [2006] Sabrina Gazzarrini, Ming Kang, Svetlana Epimashko, James L Van Etten, Jack Dainty, Gerhard Thiel, and Anna Moroni. Chlorella virus mt325 encodes water and potassium channels that interact synergistically. _Proceedings of the National Academy of Sciences_, 103(14):5355-5360, 2006.
* Gillespie [1977] Daniel T. Gillespie. Exact stochastic simulation of coupled chemical reactions. _The Journal of Physical Chemistry_, 81:2340-2361, 1977.
* Hajiaghayi et al. [2014] Monir Hajiaghayi, Bonnie Kirkpatrick, Liangliang Wang, and Alexandre Bouchard-Cote. Efficient continuous-time markov chain estimation. In _International Conference on Machine Learning_, pages 638-646. PMLR, 2014.
* Hamilton [1989] James D Hamilton. A new approach to the economic analysis of nonstationary time series and the business cycle. _Econometrica: Journal of the econometric society_, pages 357-384, 1989.
* Heess et al. [2013] Nicolas Heess, Daniel Tarlow, and John Winn. Learning to pass expectation propagation messages. _Advances in Neural Information Processing Systems_, 26, 2013.
* Hochreiter and Schmidhuber [1997] Sepp Hochreiter and Jurgen Schmidhuber. Long Short-Term Memory. _Neural Computation_, 9(8):1735-1780, 1997.
* Hochreiter et al. [2014]Illia Horenko, Evelyn Dittmer, Alexander Fischer, and Christof Schutte. Automated model reduction for complex systems exhibiting metastability. _Multiscale Modeling & Simulation_, 5(3):802-827, 2006.
* Husic et al. (2020) Brooke E. Husic, Nicholas E. Charron, Dominik Lemm, Jiang Wang, Adria Perez, Maciej Majewski, Andreas Kramer, Yaoyi Chen, Simon Olsson, Gianni de Fabritiis, Frank Noe, and Cecilia Clementi. Coarse graining molecular dynamics with graph neural networks. _The Journal of Chemical Physics_, 153(19):194101, 2020.
* Kilic et al. (2021) Zeliha Kilic, Ioannis Sgouralis, and Steve Presse. Generalizing hmms to continuous time for fast kinetics: Hidden markov jump processes. _Biophysical journal_, 120(3):409-423, 2021.
* Kim et al. (2020) Dong-Kyum Kim, Youngkyoung Bae, Sangyun Lee, and Hawoong Jeong. Learning entropy production via neural networks. _Physical Review Letters_, 125(14):140604, 2020.
* Kingma and Welling (2013) Diederik P Kingma and Max Welling. Auto-encoding variational bayes. _arXiv preprint arXiv:1312.6114_, 2013.
* Kohs et al. (2021) Lukas Kohs, Bastian Alt, and Heinz Koeppl. Variational inference for continuous-time switching dynamical systems. In _Advances in Neural Information Processing Systems_, volume 34, pages 20545-20557, 2021.
* Kohs et al. (2022) Lukas Kohs, Bastian Alt, and Heinz Koeppl. Markov chain monte carlo for continuous-time switching dynamical systems. In _International Conference on Machine Learning_, pages 11430-11454. PMLR, 2022.
* Larochelle et al. (2008) Hugo Larochelle, Dumitru Erhan, and Yoshua Bengio. Zero-data learning of new tasks. In _AAAI_, volume 1, page 3, 2008.
* Le Cam and Yang (2000) Lucien Marie Le Cam and Grace Lo Yang. _Asymptotics in statistics: some basic concepts_. Springer Science & Business Media, 2000.
* Loshchilov and Hutter (2017) Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. _arXiv preprint arXiv:1711.05101_, 2017.
* Mardt et al. (2017) Andreas Mardt, Luca Pasquali, Hao Wu, and Frank Noe. Vampnets for deep learning of molecular kinetics. _Nature Communications_, 9, 2017.
* McGibbon and Pande (2015) Robert T McGibbon and Vijay S Pande. Efficient maximum likelihood parameterization of continuous-time markov processes. _The Journal of chemical physics_, 143(3):034109, 2015.
* Metzner et al. (2007) Philipp Metzner, Illia Horenko, and Christof Schutte. Generator estimation of markov jump processes based on incomplete observations nonequidistant in time. _Phys. Rev. E_, 76:066702, Dec 2007.
* Mironov et al. (2019) Vladimir Mironov, Yuri Alexeev, Vikram Khipple Mulligan, and Dmitri G. Fedorov. A systematic study of minima in alanine dipeptide. _Journal of Computational Chemistry_, 40(2):297-309, 2019.
* Noe et al. (2020) Frank Noe, Alexandre Tkatchenko, Klaus-Robert Muller, and Cecilia Clementi. Machine learning for molecular simulation. _Annual review of physical chemistry_, 71:361-390, 2020.
* Opper and Sanguinetti (2007) M. Opper and G. Sanguinetti. Variational inference for markov jump processes. In _NIPS_, 2007.
* Otsubo et al. (2022) Shun Otsubo, Sreekanth K Manikandan, Takahiro Sagawa, and Supriya Krishnamurthy. Estimating time-dependent entropy production from non-equilibrium trajectories. _Communications Physics_, 5(1):11, 2022.
* Paige and Wood (2016) Brooks Paige and Frank Wood. Inference networks for sequential monte carlo in graphical models. In _International Conference on Machine Learning_, pages 3040-3049. PMLR, 2016.
* Rao and Teg (2013) Vinayak Rao and Yee Whte Teg. Fast mcmc sampling for markov jump processes and extensions. _Journal of Machine Learning Research_, 14(11), 2013.
* Roldan and Parrondo (2010) E. Roldan and J. M. R. Parrondo. Estimating dissipation from single stationary trajectories. _Physical review letters_, 105 15:150607, 2010.
* Roldan et al. (2017)Christof Schutte, Frank Noe, Jianfeng Lu, Marco Sarich, and Eric Vanden-Eijnden. Markov state models based on milestoning. _The Journal of chemical physics_, 134(20), 2011.
* Seifert [2012] Udo Seifert. Stochastic thermodynamics, fluctuation theorems and molecular machines. _Reports on Progress in Physics_, 75(12):126001, nov 2012. doi: 10.1088/0034-4885/75/12/126001. URL https://dx.doi.org/10.1088/0034-4885/75/12/126001.
* Seifner and Sanchez [2023] Patrick Seifner and Ramses J Sanchez. Neural markov jump processes. In _International Conference on Machine Learning_, pages 30523-30552. PMLR, 2023.
* Seifner et al. [2024] Patrick Seifner, Kostadin Cvejoski, and Ramses J Sanchez. Foundational inference models for dynamical systems. _arXiv preprint arXiv:2402.07594_, 2024.
* Stuhlmuller et al. [2013] Andreas Stuhlmuller, Jacob Taylor, and Noah Goodman. Learning stochastic inverses. _Advances in neural information processing systems_, 26, 2013.
* Trendelkamp-Schroer and Noe [2014] Benjamin Trendelkamp-Schroer and Frank Noe. Efficient estimation of rare-event kinetics. _arXiv: Chemical Physics_, 2014.
* Varolgunes et al. [2019] Yasemin Bozkurt Varolgunes, T. Bereau, and Joseph F. Rudzinski. Interpretable embeddings from molecular simulations using gaussian mixture variational autoencoders. _Machine Learning: Science and Technology_, 1, 2019.
* Vaswani et al. [2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In _Advances in neural information processing systems_, pages 5998-6008, 2017.
* Wildner and Koeppl [2019] Christian Wildner and Heinz Koeppl. Moment-based variational inference for markov jump processes. In _International Conference on Machine Learning_, pages 6766-6775. PMLR, 2019.
* Zhang et al. [2017] Boqian Zhang, Jiangwei Pan, and Vinayak A Rao. Collapsed variational bayes for markov jump processes. _Advances in Neural Information Processing Systems_, 30, 2017.

Background on MJPs

In this section we provide some brief background on MJPs and describe how physical quantities such as the stationary distributions, relaxation times and mean first passage times can be computed from the intensity matrix. Additionally, we mention how trajectories for MJPs can be sampled using the Gillespie algorithm.

### Background on Markov Jump Processes in Continuous Time

Markov jump processes are stochastic models used to describe systems that transition between states at random times. These processes are characterized by the Markov property where the future state depends only on the current state, not on the sequence of events that preceded it.

A continuous-time MJP \(X(t)\) has right-continuous, piecewise-constant paths and takes values in a countable state space \(\mathcal{X}\) over a time interval \([0,T]\). The instantaneous probability rate of transitioning from state \(x^{\prime}\) to \(x\) is defined as

\[f(x|x^{\prime},t)=\lim_{\Delta t\to 0}\frac{1}{\Delta t}p_{\text{MP}}(x,t+ \Delta t|x^{\prime},t),\] (9)

where \(p_{\text{MP}}(x,t|x^{\prime},t^{\prime})\) denotes the transition probability.

The evolution of the state probabilities \(p_{\text{MP}}(x,t)\) is governed by the master equation

\[\frac{dp_{\text{MP}}(x,t)}{dt}=\sum_{x^{\prime}\neq x}\Big{(}f(x|x^{\prime})p _{\text{MP}}(x^{\prime},t)-f(x^{\prime}|x)p_{\text{MP}}(x,t)\Big{)}.\] (10)

For homogeneous MJPs with time-independent transition rates, the master equation in matrix form is

\[\frac{dp_{\text{MP}}(x,t)}{dt}(t)=\mathbf{p}_{\text{MP}}(t)\cdot\mathbf{F},\] (11)

with the solution given by the matrix exponential

\[\mathbf{p}_{\text{MP}}(t)=\mathbf{p}_{\text{MP}}(0)\cdot\exp(\mathbf{F}t).\] (12)

### Stationary Distribution

The stationary distribution \(\mathbf{p}_{\text{MP}}^{*}\) of a homogeneous MJP is a probability distribution over the state space \(\mathcal{X}\) that satisfies the condition \(\mathbf{p}_{\text{MP}}^{*}\cdot\mathbf{F}=\mathbf{0}\). This implies that the stationary distribution is a left eigenvector of the rate matrix corresponding to the eigenvalue 0.

### Relaxation Times

The relaxation time of a homogeneous MJP is determined by its non-zero eigenvalues \(\lambda_{2},\lambda_{3},\ldots,\lambda_{|\mathcal{X}|}\). These eigenvalues define the time scales of the process: \(|\text{Re}(\lambda_{2})|^{-1},|\text{Re}(\lambda_{3})|^{-1},\ldots,|\text{Re}( \lambda_{|\mathcal{X}|})|^{-1}\). These time scales are indicative of the exponential rates of decay toward the stationary distribution. The relaxation time, which is the longest of these time scales, dominates the long-term convergence behavior. If the eigenvalue corresponding to the relaxation time has a non-zero imaginary part, then this means that the system does not converge into a fixed stationary distribution but that it instead ends in a periodic oscillation.

### Mean First-Passage Times (MFPT)

For an MJP starting in a state \(i\in\mathcal{X}\), the first-passage time to another state \(j\in\mathcal{X}\) is defined as the earliest time \(t\) at which the MJP reaches state \(j\), given it started in state \(i\). The mean first-passage time (MFPT) \(\tau_{ij}\) is the expected value of this time. For a finite state, time-homogeneous MJP, the MFPTs can be determined by solving a series of linear equations for each state \(j\), distinct from \(i\), with the initial condition that \(\tau_{ii}=0\)

\[\begin{cases}\tau_{ii}=0\\ 1+\sum_{k}\mathbf{F}_{ik}\tau_{kj}=0,\end{cases}\quad j\neq i\] (13)

### The Gillespie Algorithm for Continuous-Time Markov Jump Processes

The Gillespie algorithm (Gillespie, 1977) is a stochastic simulation algorithm used to generate trajectories of Markov jump processes in continuous time. The algorithm proceeds as follows:

```
1:INPUT: The intensity matrix \(\mathbf{F}\), the initial state distribution \(\pi_{0}\), the starting time \(t_{0}\) and the end time \(t_{\text{end}}\)
2:Initialize the time \(t\) to the starting time \(t_{0}\)
3:Initialize the system's state \(s\) to an initial state \(s_{0}\sim\pi_{0}\)
4:While \(t<t_{\text{end}}\) do
5:Calculate the intensity \(\lambda=-1/\mathbf{F}_{ss}\) from state \(s\)
6:Sample the time \(\tau\) to the next event from an exponential distribution with rate \(\lambda\)
7:Update the time \(t\gets t+\tau\)
8:If \(t\geq t_{\text{end}}\) then exit loop
9:Calculate transition probabilities \(p=-\mathbf{F}_{sj}/\mathbf{F}_{ss}\) for each possible next state \(j\)
10:Set \(p_{s}\) to zero because we allow for no self jumps
11:Sample the next state \(s^{\prime}\) from the distribution defined by \(p\)
12:Update the system's state \(s\gets s^{\prime}\)
13:Record the state \(s\) and time \(t\)
14:End while
15:OUTPUT: The trajectory of states and times ```

**Algorithm 1** Gillespie Algorithm for Markov Jump Processes

## Appendix B Synthetic Dataset Generation: Statistics and other Details

This section is a continuation of section 3.1 and provides more details on the generation of our synthetic training dataset. Additionally, we provide some statistics about the dataset distribution.

### Prior Distributions and their Implementation

In this subsection we give additional details about our data generation mechanism.

**Distribution over rate matrices**. Our data generation procedure starts by sampling the entries \(f_{ij}\) of the intensity matrix from the following beta distributions

\[p(f_{ij}|\rho_{f})=\text{Beta}(\rho_{f}=(\alpha,\beta)),\text{ with }p( \alpha)=\text{Uniform}(\{1,2\})\\ \text{ and }p(\beta)=\text{Uniform}(\{1,3,5,10\}).\] (14)

Both these discrete uniform distribution define the prior \(p(\rho_{f})=p(\alpha)p(\beta)\).

The choices for \(\alpha\) and \(\beta\) were made heuristically, to obtain reasonable (varied) distributions over the number of jumps (see _e.g._ Figure 5). We remark that we fixed this set of training distributions _before evaluating the model on the evaluation sets_, in order to prevent us from introducing _unwanted_ biases into the distribution hyperparameters by optimizing on the evaluation set.

Next we define the prior over the adjacency matrix as

\[p(\mathbf{A})=\frac{1}{2}\delta(\mathbf{A}-\mathbf{J})+\frac{1}{2}p_{\text{ Erdos-Ranyi}}(\mathbf{A},p=0.5)\] (15)

where \(\delta(\cdot)\) labels the Dirac delta distribution and \(\mathbf{J}\) denotes the matrix for which all off-diagonal entries are \(1\) and the diagonal ones are \(0\). Furthermore \(p_{\text{Erdos-Ranyi}}\) labels the Erdos-Renyi model (Erdos and Renyi, 1959), for which each link is defined via an independent Bernoulli variable, with some fixed, global probability \(p\), here set to \(\frac{1}{2}\). Equation 15 indicates that (in average) 50 percent of our state networks are fully connected, whether the other 50 percent are not.

Our motivation for this prior is that it often happens in real world processes that the intensity matrices are not fully connected. Let us remark, however, that we only accept the Erdos-Renyi sample if the corresponding graph is _connected_ -- that is, if the system cannot get stuck into a single state. Both these distributions implicitly define \(p_{\text{rates}}(\mathbf{F}|\mathbf{A},\rho_{f})\), for \(F_{ij}=a_{ij}f_{ij}\).

_Remark on generalization beyond prior rate distribution_. We remark that while all entries of the intensity matrix seen during training lie on the interval \([0,1]\), the model can still predict intensities outside this interval. We empirically demonstrated that this in indeed the case on the widely different target sets of the experimental section, in the main text. The reason behind this is that we normalize the maximum time among all input paths to be 1, and rescale the predicted intensities accordingly. Ultimately, what matters is the difference among the rates (and therefore among the observation times) within the target time series. Our approach for sampling intensity matrices resulted in a vast variety of different processes.

The distribution of the number of jumps per trajectory is shown in figure 5 and that of relaxation times is shown in figure 6.

**Distribution over initial conditions**. We choose half of our initial distributions in our synthetic ensemble to be _the stationary distribution of the MJP_\(p_{\text{MP}}^{*}\). The motivation for this is that it often happens that real life experiments produce very long observations of a system in equilibrium. The second half of our initial distributions \(\bm{\pi}_{0}\) are randomly sampled from a Dirichlet distribution \(\text{Dir}(\rho_{0})\), where we heuristically choose \(\rho_{0}=50\). In equations, we write

\[p(\bm{\pi}_{0})=\frac{1}{2}p_{\text{MP}}^{*}(\mathbf{F})+\frac{1}{2}\text{Dir} (\rho_{0}=50).\] (16)

**Distribution over observation grids**. In practice, the exact jump (_i.e._ transition) times are not known. We therefore first generate observations of the state of the system on a regular grid with a maximum of \(L=100\) points. We then randomly mask out some observations from this fixed regular grid, in order to make the model grid independent. Half of our (subsampled) observation grids are chosen to be _regular_, _i.e._ they are strided with strides \(\in\{1,2,3,4\}\). The other half are chosen to be _irregular_, through a Bernoulli filter (or mask) with \(\rho_{\text{survival}}\in\{1/4,1/2\}\) applied to the base (\(L=100\)) grid.

**Distribution over noise process**. Because real world data is often noisy we also add noise to the labels. If a state observation is selected to be mislabeled, the new label is randomly chosen from a uniform distribution over all states. We investigate two different configurations in this project, one with 1% label noise (\(\rho_{x}=0.01\)) and one with 10% label noise (\(\rho_{x}=0.1\)).

**MJP simulation**. We sample the jumps between different states with an algorithm due to (Gillespie, 1977) (see A.5). We sample jumps between times 0 and 10 because almost all of our processes are in equilibrium by then (see figure 6).

Figure 5: Distributions of the number of jumps per trajectory. We used the same distributions as the training set and sampled up to time 10. The figures are based on 1000 processes with 300 paths per process.

**Training Dataset Size** The synthetic dataset on which our models were trained consists of 25k six-state processes, and 5k processes of 2-5 states, resulting in a total size of 45k processes. For each of these processes we sampled 300 paths.

**Distribution over the number of MJP paths \(p(K)\)**. While we generate the data with 300 paths per process, we want to ensure that the model is able to handle datasets with less than 300 paths. For this reason, we shuffle the training data at the beginning of every epoch and distribute it into batches with path counts \(1,11,21,\ldots,300\). We found that such a static selection of the path counts is better than a random selection, because a random selection leads to oscillating loss functions (because the model obviously gets a larger loss for samples with fewer paths), and thus training instabilities. Since we do not always select all paths per process but instead select a random subset of them, the data that the model processes changes during every epoch, which helps in reducing overfitting.

## Appendix C How to use the Model: Inputs, Outputs and Rescalings

In this section, we give details about the inputs to and outputs of our pretrained recognition model. We also comment on the internal rescalings done by the model, in order to be able to infer MJPs from time series with observation times of any scale.

### Input

The model takes as input three parameters:

1. The observation grids (shape: [num_paths \(K\), grid_size \(L\)]): The observation times \(\{\tau_{k1},\ldots,\tau_{kl}\}_{k=1}^{K}\), padded to the maximum length \(L\).
2. The observation values (shape: [num_paths \(K\), grid_size \(L\)]): The noisy observation values \(\{x^{\prime}_{k1},\ldots,x^{\prime}_{kl}\}_{k=1}^{K}\) padded to the maximum length \(L\). Note that these values are integers lying on the discrete set \(\{0,1,\ldots,C-1\}\).
3. The dimension\(c\): The (a priori known) dimension of the process as an integer between 2 and \(C\). If this dimension is unknown, the model returns a \(C\times C\) rate matrix whose rank might (approximately) be smaller than \(C\), which indicates a hidden state-space of size smaller than \(C\).

Figure 6: Distributions of the relaxation times. We also report the percentage of processes that converge into an oscillating distribution (OP) and the percentage of processes that have a relaxation time which is larger than the maximum sampling time (NCP) of our training data (given by \(t_{\text{end}}=10\)). The figures are based on 1000 processes.

We recommend users to use the model only within its training range. That is, with up to a maximum of \(K=300\) paths, and grids up to a maximum of \(L=100\) points.

### Internal Rescaling

Internally, the model does the following:

1. It computes the maximum observation time: \[\tau_{\text{max}}=\text{max}\{\tau_{k1},\dots,\tau_{kl}\}_{k=1}^{K}.\] (17)
2. It normalizes the observation times between 0 and 1: \[\{\tau_{k1},\dots,\tau_{kl}\}_{k=1}^{K}\leftarrow\{\tau_{k1},\dots,\tau_{kl}\}_ {k=1}^{K}/\tau_{\text{max}}.\] (18)
3. It computes the inter-event times \(\Delta\tau_{ki}=\tau_{k,i+1}-\tau_{ki}\), for \(k=1,\dots,K\).
4. It transforms the observation values to one-hot-encodings.
5. It predicts the (normalized) off-diagonal elements of the intensity matrix and variance matrix as well as the initial distribution (here we are working with the maximum supported dimension, that is \(C\)).
6. It rescales back the estimates to the original time scale: \[\text{intensity matrix}\,\mathbf{\hat{F}} \leftarrow\text{intensity matrix}\,\mathbf{\hat{F}}/\tau_{\text{ max}},\] (19) \[\text{Var}\,\mathbf{\hat{F}} \leftarrow\text{Var}\,\mathbf{\hat{F}}/\tau_{\text{max}}.\] (20)

Note that, as we empirically demonstrated in the paper, this rescaling procedure allows us to work with real-world MJPs of arbitrary time scales. For example, the time scales for the switching ion channel dataset were more than 500 times smaller than the time scales in our training dataset.

### Support for varying State Space Sizes

We now elaborate on how the model can deal with processes whose state spaces have sizes \(c<C\).

We arranged all the target rate matrices \(\mathbf{F}\) within our training dataset, for MJPs with state spaces of size \(c<C\), to be the leftmost block diagonal \(c\times c\) matrix within a \(C\times C\) matrix of zeros, so that the redundant matrix elements are always zero. As can be read from equation (6) of the main text, we train FIM to predict zeros for those redundant matrix elements.

In practice, however, our trained FIM does not exactly predict zeros for those redundant matrix elements. In our experiments, the user knows a priori the number of states \(c\) of the hidden process, so we explicitly set the redundant matrix elements to zero, and only then compute the corrected diagonal (i.e. the normalization) of the output rate matrix.

We afterwards select the \(c\times c\) entries of the predicted intensity matrix and variance matrix as well as the first \(c\) entries of the predicted initial distribution.

We refer the reader to our library for additional details.

### Output

The output of the model consists of three parameters:

1. The intensity matrix \(\mathbf{\hat{F}}\) (shape: [\(c\), \(c\)]).
2. The variance matrix \(\text{Var}\,\mathbf{\hat{F}}\) (shape: [\(c\),\(c\)]).
3. The initial distribution \(\pi_{0}\) (shape [\(c\)]).

Model Architecture and Experimental Setup

In this section we provide more details about the architecture of our models and the hyperparameters.

### Model Architecture

**Path encoder \(\psi_{1}\).** We evaluated two different approaches for the path encoder \(\psi_{1}\). The first approach utilizes a bidirectional LSTM (Hochreiter and Schmidhuber, 1997) as \(\psi_{1}\), while the second approach employs a transformer (Vaswani et al., 2017) for \(\psi_{1}\). The time series embeddings are denoted by \(h_{k\theta}\) (see Equation 4). The input to the encoder \(\psi_{1}\) is \((\mathbf{x}_{k1}^{\prime},\bm{\tau}_{k1},\dots,\mathbf{x}_{kl}^{\prime},\bm{ \tau}_{kl})\), where \(\bm{\tau}_{kl}=[\tau_{kl},\delta_{kl}]\), \(\delta_{kl}=\tau_{kl}-\tau_{(k-1)t}\), and \(\mathbf{x}_{kl}\in\{0,1\}^{C}\) is the one-hot encoding of the system's state.

**Path attention network \(\Omega_{1}\).** We tested two approaches. The first approach uses classical self-attention Vaswani et al. (2017) and selects the last embedding. For the second approach we used an approach we denote as _learnable query attention_ which is equivalent to classical multi-head attention with the exception that we do not compute the query based on the input, but instead make it a learnable parameter, i.e.,

\[\text{MultiHead}(Q,K,V)=\text{Concat}(\text{head}_{1},\dots, \text{head}_{h}),\] (21) \[\text{head}_{i}=\text{Attention}(Q_{i},H_{1:K}W_{i}^{K},H_{1:K}W _{i}^{V}),\] (22)

where \(H_{1:K}\in\mathbb{R}^{K\times d_{model}}\) denotes a concatenation of \(h_{1},\dots,h_{K}\), \(W_{i}^{K},W_{i}^{V}\in\mathbb{R}^{d_{model}\times d_{k}}\) and \(Q_{i}\in\mathbb{R}^{q\times d_{k}}\) is the learnable query matrix. The output dimension of the learnable query attention is therefore independent of the number of input tokens.

### Experimental Setup

**Hyperparameter tuning:** Hyperparameters were tuned using a grid search method. The optimizer utilized was AdamW (Loshchilov and Hutter, 2017), with a learning rate and weight decay both set at \(1e^{-4}\). A batch size of 128 was used. During the grid search, we experimented with the hidden size of the _path encoder_ ((64, 128, 256, 512)), the hidden size of the _path attention network_ ((128, 256)), and various MLP architectures for \(\phi_{1},\phi_{2}\), and \(\phi_{3}\) ([(32, 32, 128, 128])).

**Training procedure:** All models were trained on two A100 80Gb GPUs for approximately 500 epochs or approximately 2.5 days on average per model. Early stopping was employed as the stopping criterion. The models were trained by maximizing the likelihood.

**Final model parameters**: The final models (FIM-MJP 1% Noise and FIM-MJP 10% Noise) have the following hyperparameters: _Path encoder_ - hidden \(\text{size}(\psi_{1})=256\) (the final models used a BiLSTM); _Path attention network_ - \(\Omega_{1}\): \(q=16\), \(d_{k}=128\) (the final models used the learnable query approach); \(\phi_{1},\phi_{2},\phi_{3}=[128,128]\).

**Pretrained models**: Our pretrained models are also available online5.

Footnote 5: https://github.com/cvejoski/OpenFIM

## Appendix E Ablation Studies

In this section, we study the performance of the models with different architectures. Additionally, we study the behavior of the performance of the models with respect to varying numbers of states and varying number of paths.

### General Remarks about the Error Bars and Context Number

If the evaluation set is larger than the optimal context number \(c(K_{max},l_{max})\), we split the evaluation set into batches and give these to the model independently (because the model does not work well to give the model more paths than during training, see table 8). Afterwards, we compute the mean of the predictions among the batches and report the mean RMSE of the intensity entries (if the ground-truth is available). This makes it easier to compare our model against previous works which have also used the full dataset to make predictions. Interestingly, we find that the RMSE of this averaged prediction is often significantly better than the mean RMSE among the batches. For example for the DFR dataset the RMSE of the averaged prediction is 0.0617, while the average RMSE of the batches is 0.122. If the dataset has been split into multiple batches, we report the RMSE together with the standard deviation of the RMSE among the batches. The reported confidence is the mean predicted variance of the model (recall that we are using Gaussian log-likelihood during training).

### Performance of the Model by varying its Architecture

The ablation study presented in Table 5 evaluates the impact of different model features on the performance by comparing various combinations of architectures and attention mechanisms with varying numbers of paths, and their corresponding RMSE values. The study examines models using a BiLSTM or Transformer, with and without self-attention and learnable query attention, across 1, 100, and 300 paths. The results indicate that increasing the number of paths consistently reduces RMSE (see section E.4 for more details), demonstrating the benefit of considering more paths during training. Specifically, using a BiLSTM with learnable query attention achieves an RMSE of \(0.193\pm 0.031\) with a single path, significantly improving to \(0.048\pm 0.011\) with 100 paths, and further to \(0.0457\pm 0.0\) with 300 paths. Similarly, a Transformer with learnable query attention shows an RMSE of \(0.196\pm 0.031\) for a single path, \(0.049\pm 0.011\) for 100 paths, and \(0.0458\pm 0.0\) for 300 paths. The inclusion of self-attention in the Transformer models slightly improves performance, with the best RMSE of \(0.0459\pm 0.0\) achieved when both self-attention and learnable query attention are used with 300 paths. In this case since many of the processes contain one path it is beneficial to use the learnable query attention over the standard self-attention mechanism.

Figure 7 presents a series of line plots illustrating the impact of different hyperparameter settings on the RMSE of the model. The first subplot shows the RMSE as a function of the hidden size of the \(\psi_{1}\) path encoder, with hidden sizes 64, 128, 256, and 512. The RMSE increases as the hidden size increases, with the lowest RMSE observed at a hidden size of 256. The second subplot displays the RMSE as a function of the architecture size of \(\phi_{1}\), comparing two architectures: [2x32] and [2x128]. The RMSE decreases as the architecture size increases, indicating better performance with a larger architecture size for \(\phi_{1}\). The third subplot examines the RMSE based on the architecture size of \(\phi_{2}\), with two architectures tested: [2x32] and [2x128]. There is no significant difference in RMSE between the two sizes, suggesting that the choice of architecture size for \(\phi_{2}\) does not markedly affect model performance. The fourth subplot investigates the RMSE as a function of the hidden size of the \(\Omega_{1}\) component, with hidden sizes 128 and 256 tested, and results shown for different \(\psi_{1}\) hidden sizes (64, 128, 256, and 512). The RMSE remains relatively stable across different hidden sizes of \(\Omega_{1}\), with slight variations observed depending on the hidden size of \(\psi_{1}\). Overall, the plots highlight that some components, such as \(\psi_{1}\) and \(\phi_{1}\), are more sensitive to changes in hyperparameters, emphasizing the importance of selecting appropriate hyperparameters to optimize model performance.

\begin{table}
\begin{tabular}{c|c c|c c|c} \hline \hline \# Paths & BiLSTM & Transformer & Self Attention & Learnable Query Attention & RMSE \\ \hline
1 &  & & &  & 0.193 \(\pm\) 0.031 \\
1 &  & &  & & 0.196 \(\pm\) 0.031 \\
1 &  & &  & & 0.197 \(\pm\) 0.015 \\
100 &  & & &  & 0.048 \(\pm\) 0.011 \\
100 &  & &  & & 0.049 \(\pm\) 0.011 \\
100 &  & &  & & 0.054 \(\pm\) 0.012 \\
300 &  & &  & & 0.0457 \(\pm\) 0.0 \\
300 &  & &  & & 0.0458 \(\pm\) 0.0 \\
300 &  & &  &  & 0.0459 \(\pm\) 0.0 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Comparison of model features with different number of paths and their RMSE. This table presents an ablation study comparing the performance of models using BiLSTM and Transformer architectures, with and without self-attention and learnable query attention, across different numbers of paths (1, 100, and 300). The performance is measured by the Root Mean Square Error (RMSE), with lower values indicating better model accuracy. The study highlights that both the architectural choices and the number of paths significantly impact model performance, with the best results achieved using a combination of attention mechanisms and a higher number of paths.

Table 6 compares the performance of two models, FIM-MJP 1% and FIM-MJP 10%, on synthetic datasets with noise levels of 1% and 10%, measured in terms of RMSE. For datasets with 1% noise, the FIM-MJP 1% model achieves an RMSE of 0.046, indicating good performance, but its RMSE increases significantly to 0.199 on 10% noise data, showing decreased performance with higher noise. Conversely, the FIM-MJP 10% model, trained with 10% noise data, has an RMSE of 0.096 on 1% noise data, higher than the FIM-MJP 1% model on the same data, but achieves a lower RMSE of 0.087 on 10% noise data, demonstrating better performance under high noise conditions. This indicates that the FIM-MJP 10% model is more robust to noise, maintaining consistent performance across varying noise levels, while the FIM-MJP 1% model excels in low noise environments but struggles with higher noise. The results highlight the importance of training with appropriate noise levels to ensure robust model performance across different noise conditions.

### Performance of the Model with varying Number of States

We compare the performance of our models on processes with varying number of states. Note that our model always outputs a \(6\times 6\) dimensional intensity matrix. However, in these experiments we only use the rows and columns that correspond to the lower-dimensional process. This improves the comparability between different dimensions as lower-dimensional processes obviously have many zero-entries in their intensity matrix which would make it easier for the model to achieve a good RMSE score.

It can be seen in Table 7 that the multi-state-model performs well among all different dimensions. As expected, lower-dimensional processes seem to be easier for the model. Additionally, Table 7 shows the performance of a model which has only been trained on six-state processes. The performance of this native six-state-model for six number of states is very similar to the multi-state-model which shows that having more states during training does not reduce the single-state performance. As expected, the performance of the six-state model on processes with lower numbers of states is significantly worse, but still better than random.

### Performance of the Model with varying Number of Paths during Evaluation

One of the advantages of our model architecture is that it can handle arbitrary number of paths. We therefore use our model that was trained on at maximum 300 paths and assess its performance

\begin{table}
\begin{tabular}{c c c} \hline \hline  & 1\% Noise Data & 10\% Noise Data \\ \hline FIM-MJP 1\% & \(0.046\) & \(0.199\) \\ FIM-MJP 10\% & \(0.096\) & \(0.087\) \\ \hline \hline \end{tabular}
\end{table}
Table 6: Performance of FIM-MJP 1% and FIM-MJP 10% on synthetic datasets with different noise levels. We use a weighted average among the datasets with different numbers of states to compute a final RMSE.

Figure 7: Impact of Hyperparameters on RMSE. The figure shows four line plots illustrating the effect of hyperparameters on model RMSE. The first plot shows RMSE increases with larger \(\psi_{1}\) hidden sizes, being lowest at 256. The second plot indicates lower RMSE with a larger \(\phi_{1}\) architecture size ([2x128]). The third plot shows minimal RMSE impact from \(\phi_{2}\) architecture size. The fourth plot shows RMSE stability across different \(\Omega_{1}\) hidden sizes, with slight variations based on \(\psi_{1}\). This highlights the importance of tuning \(\psi_{1}\) and \(\phi_{1}\) for optimal performance.

with varying number of paths during evaluation. The results are presented in Table 8. When being inside the training range, the performance and the confidence of the model goes down as the model is given fewer paths per evaluation, which is to be expected. Interestingly, the performance of the learnable-query (LQ) model peaks at 500 paths instead of at 300, which was the maximum training range. One possible explanation for this might be that we are still close enough to the training range while being able to use the full data (note that the dataset contains 5000 paths which is not divisible by 300, so we have to leave some of the data out). Going too far beyond the training range does however not work well, for example processing all 5000 paths at once leads to very poor performance, although the model (falsely) become very confident. Another insight from this experiment is that the self-attention (SA) architecture behaves significantly worse when going beyond the maximum number of paths that was seen during training. This is another reason why we chose the (LQ) architecture over the (SA) architecture for the final version of our model.

## Appendix F Additional Results

This section contains more of our results which did not fit into the main text. We begin this section by providing more details on the Hellinger distance which we used as a metric to assess the performance of our models. Afterwards, we provide more results and background on the ADP, ion channel and DFR datasets. Additionally, we introduce two two-state MJPs, given by the protein folding datasets (F.5) and the two-mode switching system (F.6), which we use to evaluate our models and to compare it against previous works.

### Hellinger Distance

Real-world empirical datasets of MJPs provide no knowledge of a ground truth solution. For this reason we present a new metric that can be used to compare the performance of the inference of various models based on only the empirical data. Our metric of choice is the Hellinger distance which is a measure of the dissimilarity between two probability distributions. Given two discrete probability distributions \(P=(p_{1},\ldots,p_{k})\) and \(Q=(q_{1},\ldots,q_{k})\), the Hellinger distance is defined as

\[H(P,Q)=\frac{1}{\sqrt{2}}\sqrt{\sum_{i=1}^{k}(\sqrt{p_{i}}-\sqrt{q_{i}})^{2}}\,.\] (23)

\begin{table}
\begin{tabular}{c c c c c} \hline \hline \# States & Multi-State RMSE & Multi-State Confidence & 6-State RMSE & 6-State Confidence \\ \hline
2 & 0.026 & 0.028 & 0.129 & 0.056 \\
3 & 0.037 & 0.030 & 0.113 & 0.049 \\
4 & 0.046 & 0.037 & 0.087 & 0.046 \\
5 & 0.054 & 0.040 & 0.066 & 0.041 \\
6 & 0.059 & 0.044 & 0.059 & 0.044 \\ \hline \hline \end{tabular}
\end{table}
Table 7: Performance of the multi-state and six-state models (which has only been trained on processes with six states) on synthetic test sets with varying number of states

\begin{table}
\begin{tabular}{c c c c c} \hline \hline \#Paths during Evaluation & RMSE (LQ) & Confidence (LQ) & RMSE (SA) & Confidence (SA) \\ \hline
1 & 0.548 \(\pm\) 0.067 & 0.838 & 0.579 \(\pm\) 0.074 & 0.898 \\
30 & 0.074 \(\pm\) 0.081 & 0.263 & 0.075 \(\pm\) 0.070 & 0.264 \\
100 & 0.061 \(\pm\) 0.039 & 0.143 & 0.060 \(\pm\) 0.035 & 0.142 \\
300 & 0.056 \(\pm\) 0.023 & 0.089 & 0.059 \(\pm\) 0.024 & 0.085 \\
500 & 0.053 \(\pm\) 0.014 & 0.069 & 0.074 \(\pm\) 0.021 & 0.061 \\
1000 & 0.067 \(\pm\) 0.012 & 0.037 & 0.229 \(\pm\) 0.025 & 0.029 \\
5000 & 0.818 \(\pm\) 0.000 & 0.000 & 2.135 \(\pm\) 0.000 & 0.000 \\ \hline \hline \end{tabular}
\end{table}
Table 8: Performance of FIM-MJP 1% given varying number of paths during the evaluation on the DFR dataset with regular grid. (LQ) denotes learnable-query-attention (see section D.1), (SA) denotes self-attention.

[MISSING_PAGE_FAIL:23]

[MISSING_PAGE_FAIL:24]

### Ion Channel

We consider the 1s observation window that has been used in (Kohs et al., 2021) and (Seifner and Sanchez, 2023) and split it into 50 paths of 100 points. This dataset was provided to us via private communication. We then apply a Gaussian Mixture Model (GMM) to classify the experimental data into discrete states as shown in figure 10.

The predictions of our models and NeuralMJP are shown in table 13. Table 14 reports the stationary distributions and Table 15 reports the mean first-passage times.

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline  & \multicolumn{6}{c}{Relaxation time scales (in \(ns\))} \\ \hline VAMPnets & 0.008 & 0.009 & 0.055 & 0.065 & 1.920 \\ GMVAE & 0.003 & 0.003 & 0.033 & 0.065 & 1.430 \\ MSM & - & - & - & - & - & 1.490 \\ NeuralMJP & 0.009 & 0.009 & 0.043 & 0.069 & 0.774 \\ \hline Film-MJP 1\% Noise (NeuralMJP Labels) & 0.008 & 0.009 & 0.079 & 0.118 & 0.611 \\ Film-MJP 10\% Noise (NeuralMJP Labels) & 0.007 & 0.011 & 0.019 & 0.038 & 0.091 \\ Film-MJP 1\% Noise (KMeans Labels) & 0.001 & 0.003 & 0.046 & 0.142 & 0.455 \\ Film-MJP 10\% Noise (KMeans Labels) & 0.002 & 0.004 & 0.018 & 0.034 & 0.070 \\ \hline \hline \end{tabular}
\end{table}
Table 12: Relaxation time scales for six-state Markov models of ADP. The time scales are ordered by size and reported in nanoseconds. VAMPnet results are taken from Mardt et al. (2017), GMVAE from Varolgunes et al. (2019), MSM from Trendelkamp-Schroer and Noe (2014) and NeuralMJP from (Seifner and Sanchez, 2023).

Figure 10: Classification of the ion channel dataset into states.

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline  & \multicolumn{6}{c}{Probability per State} \\  & I & II & III & IV & V & VI \\ \hline VAMPnets & 0.30 & 0.24 & 0.20 & 0.15 & 0.11 & 0.01 \\ NeuralMJP & 0.30 & 0.31 & 0.23 & 0.10 & 0.05 & 0.01 \\ \hline FIM-MJP 1\% Noise & 0.28 & 0.28 & 0.24 & 0.07 & 0.10 & 0.03 \\ FIM-MJP 10\% Noise & 0.30 & 0.30 & 0.31 & 0.06 & 0.01 & 0.02 \\ \hline \hline \end{tabular}
\end{table}
Table 11: Comparison of the stationary distribution on the ADP dataset of FIM-MJP, VAMPnets Mardt et al. (2017) and NeuralMJP (Seifner and Snchez, 2023). The states are ordered such that the protein conformations associated to a given state are comparable in both models. We use the labels of NeuralMJP to evaluate FIM-MJP.

### Discrete Flashing Ratchet

We use the same datasets that were used in Seifner and Sanchez (2023), which contains 5000 paths on grids of size 50 that lie between times 0 and \(2.5\). This dataset was provided to us via private communication. We used 4500 paths to evaluate our model. The predicted intensity matrices for the DFR and the ground truth are shown in table 16.

\begin{table}
\begin{tabular}{c|c c c} \hline \hline \multicolumn{1}{c}{**Model**} & \multicolumn{3}{c}{**Intensity Matrix**} \\ \hline \multirow{2}{*}{NeuralMP} & \(\begin{bmatrix}-57.73&55.81&1.93\\ 102.13&-306.93&204.81\\ 0.70&26.05&-26.75\end{bmatrix}\) \\ \hline \multirow{2}{*}{FBM-MPP 19 Noise (NeuralMP Labels)} & \(\begin{bmatrix}-64.65&62.25&2.40\\ 110.55&-334.05&223.50\\ 0.78&31.53&-32.30\end{bmatrix}\) \\ \hline \multirow{2}{*}{FBM-MPP 10\% Noise (NeuralMP Labels)} & \(\begin{bmatrix}-92.63&85.83&6.79\\ 49.31&-141.72&92.40\\ 2.86&32.72&-35.58\end{bmatrix}\) \\ \hline \multirow{2}{*}{FBM-MPP 15 Noise (GMM Labels)} & \(\begin{bmatrix}-116.37&114.65&1.73\\ 271.88&-716.52&444.64\end{bmatrix}\) \\ \cline{2-3}  & \(\begin{bmatrix}0.56&49.69&-50.25\\ 10.55&-334.05&223.50\end{bmatrix}\) \\ \hline \multirow{2}{*}{FBM-MPP 10\% Noise (GMM Labels)} & \(\begin{bmatrix}-92.63&85.83&6.79\\ 49.31&-141.72&92.40\\ 2.86&32.72&-35.58\end{bmatrix}\) \\ \hline \multirow{2}{*}{FBM-MPP 15 Noise (GMM Labels)} & \(\begin{bmatrix}-116.37&114.65&1.73\\ 271.88&-716.52&444.64\end{bmatrix}\) \\ \cline{2-3}  & \(\begin{bmatrix}0.56&49.69&-50.25\\ 10.56&49.69&-50.25\end{bmatrix}\) \\ \hline \multirow{2}{*}{FBM-MPP 10\% Noise (GMM Labels)} & \(\begin{bmatrix}-104.01&97.30&6.71\\ 82.72&-215.58&132.86\\ 2.89&40.29&-43.18\end{bmatrix}\) \\ \hline \hline \end{tabular}
\end{table}
Table 13: Comparison of intensity matrices for the ion channel dataset. We cannot report error bars here because the dataset is so small that it gets processed in a single batch.

\begin{table}
\begin{tabular}{c|c c|c c c|c c c} \hline \hline  & \multicolumn{2}{c|}{Khs et al. (2021)} & \multicolumn{2}{c|}{NeuralMP} & \multicolumn{2}{c}{FIM-MJP 1\% Noise} \\ \hline \(\tau_{ij}/s\) & Bottom & Middle & Top & Bottom & Middle & Top & Bottom & Middle & Top \\ \hline Bottom & 0. & 0.068 & 0.054 & 0. & 0.019 & 0.031 & 0 & 0.017 & 0.027 \\ Middle & 0.133 & 0. & 0.033 & 0.083 & 0. & 0.014 & 0.068 & 0 & 0.012 \\ Top & 0.181 & 0.092 & 0.119 & 0.038 & 0. & 0.098 & 0.031 & 0 \\ \hline \multirow{2}{*}{
\begin{tabular}{c} \(\tau_{ij}/s\) \\ \end{tabular} } & \multicolumn{2}{c|}{FIM-MJP 10\% Noise} & \multicolumn{2}{c|}{FIM-MJP 1\% Noise} \\ \cline{2-3}  & \multicolumn{2}{c|}{(NeuralMP Labels)} & \multicolumn{2}{c|}{(GMM Labels)} & \multicolumn{2}{c}{(GMM Labels)} \\ \hline \(\tau_{ij}/s\) & Bottom & Middle & Top & Bottom & Middle & Top & Bottom & Middle & Top \\ \hline Bottom & 0 & 0.013 & 0.026 & 0 & 0.009 & 0.016 & 0 & 0.011 & 0.022 \\ Middle & 0.063 & 0 & 0.016 & 0.036 & 0 & 0.007 & 0.045 & 0 & 0.013 \\ Top & 0.086 & 0.029 & 0 & 0.055 & 0.02 & 0 & 0.065 & 0.024 & 0 \\ \hline \hline \end{tabular}
\end{table}
Table 15: Mean first-passage times of the predictions of various models on the Switching Ion Channel dataset. We compare against (Khs et al., 2021) and NeuralMPP (Seifner and Snchez, 2023). Entry \(j\) in row \(i\) is mean first-passage time of transition \(i\to j\) of the corresponding model.

### Modeling Protein Folding through Bistable Dynamics

The work of Mardt et al. (2017) introduces a simple protein folding model via a \(10^{5}\) step trajectory simulation in a \(5\)-dimensional Brownian dynamics framework, governed by:

\[dx(t)=-\nabla U(x(t))+\sqrt{2}dW(t)\quad,\]

with the potential \(U(x)\) being dependent solely on the norm \(r(x)=|x|\) as follows:

\[U(x)=\begin{cases}-2.5[r(x)-3]^{2}&\text{, if }r(x)<3\\ 0.5[r(x)-3]^{3}-[r(x)-3]^{2}&\text{, if }r(x)\geq 3\end{cases}\]

This model exhibits bistability in the norm \(r(x)\), encapsulating two states akin to the folded and unfolded conformations of a protein.

We use the dataset of Seifner and Sanchez (2023) and apply a Gaussian-Mixture-Model to classify the dataset into two states. The decision boundary of the classifier seems to be based on the absolute absolute value of the radius, namely the classifier seems to classify all states with a radius smaller than approximately 2 into the lower state (see figure 11).

Seifner and Sanchez (2023) generated \(1000\) trajectories, each with \(100\) steps after a \(1000\)-step burn-in period. We used 900 paths to evaluate our model. The results are shown in table 17. Table 18 compares the stationary distributions obtained from our models to the ones from Mardt et al. (2017) and Seifner and Sanchez (2023).

\begin{table}
\begin{tabular}{c|c c c c c c} \hline \multicolumn{2}{c}{**Model**} & \multicolumn{5}{c}{**Intensity Matrix**} \\ \hline \multirow{4}{*}{Ground Truth} & & \(\begin{bmatrix}-1.97&0.61&0.37&1&0&0\\ 1.65&-3.26&0.61&0&1&0\\ 2.72&1.65&-5.37&0&0&1\\ 1&0&0&-3&1&1\\ 0&1&0&0&1&-3&1\\ 0&0&1&1&-3&1\\ 0&0&1&1&1&-3\\ \end{bmatrix}\) \\ \hline \multirow{4}{*}{FIMMP 1% Noise} & \(\begin{bmatrix}-1.88\pm 0.09&0.52\pm 0.06&0.31\pm 0.05&0.99\pm 0.09&0.03\pm 0 0.00&0.03\pm 0.01\\ 1.62\pm 0.12&-3.34\pm 0.13&0.57\pm 0.10&0.06\pm 0.01&1.04\pm 0.14&0.05\pm 0.01\\ 2.73\pm 0.31&1.66\pm 0.19&-5.60\pm 0.05&0.12\pm 0.03&0.10\pm 0.01&1.00\pm 0.27\\ 0.97\pm 0.10&0.05\pm 0.01&0.04\pm 0.01&-3.02\pm 0.17&0.99\pm 0.10&0.97\pm 0.09\\ 0.05\pm 0.01&0.98\pm 0.12&0.05\pm 0.01&9.05\pm 0.15&-3.05\pm 0.18&1.01\pm 0.11\\ 0.07\pm 0.02&0.05\pm 0.01&0.96\pm 0.11&0.94\pm 0.10&1.03\pm 0.11&-3.05\pm 0.19 \\ \hline \multirow{4}{*}{FIM-MP 105 Noise} & \(\begin{bmatrix}-1.61\pm 0.10&0.46\pm 0.07&0.23\pm 0.05&0.88\pm 0.10&0.02\pm 0.00&0.02\pm 0.00\\ 1.42\pm 0.11&-2.78\pm 0.13&0.48\pm 0.09&0.04\pm 0.01&0.81\pm 0.12&0.04\pm 0.01 \\ 2.68\pm 0.34&1.47\pm 0.17&-4.93\pm 0.49&0.06\pm 0.01&0.06\pm 0.01&0.65\pm 0.25 \\ 0.87\pm 0.12&0.03\pm 0.01&0.03\pm 0.00&-2.53\pm 0.20&0.80\pm 0.09&0.80\pm 0.10 \\ 0.04\pm 0.01&0.84\pm 0.12&0.03\pm 0.00&0.84\pm 0.17&-2.61\pm 0.19&0.87\pm 0.10 \\ 0.05\pm 0.01&0.03\pm 0.01&0.78\pm 0.09&0.86\pm 0.09&0.93\pm 0.12&-2.65\pm 0.15 \\ \hline \end{tabular}
\end{table}
Table 16: Comparison of intensity matrices for the DFR dataset on the irregular grid.

### A Toy Two-Mode Switching System

In their study, Kohs et al. (2021) produced a time series derived from the trajectory of a switching stochastic differential equation

\[dy(t)=\alpha_{z(t)}(\beta_{z(t)}-y(t))+0.5dW(t)\,,\]

with parameters \(\alpha_{1}=\alpha_{2}=1.5\), \(\beta_{1}=-1\), and \(\beta_{2}=1\). For a concise overview of the generation process, the reader is directed to (Kohs et al., 2021) for comprehensive details. We use the same dataset that was generated in (Seifner and Sanchez, 2023) using the code of (Kohs et al., 2021) which contains 256 paths of length 67 to evaluate our model. Our results are shown in table 20.

\begin{table}
\begin{tabular}{c c c} \hline \hline  & Low STD & High STD \\ \hline NeuralMJP & \(0.028\) & \(0.085\) \\ \hline FIM-MJP \(1\%\) Noise (NeuralMJP Labels) & \(0.019\pm 0.003\) & \(0.054\pm 0.011\) \\ FIM-MJP \(10\%\) Noise (NeuralMJP Labels) & \(0.034\pm 0.005\) & \(0.055\pm 0.008\) \\ FIM-MJP \(1\%\) Noise (GMM Labels) & \(0.054\pm 0.005\) & \(0.154\pm 0.018\) \\ FIM-MJP \(10\%\) Noise (GMM Labels) & \(0.050\pm 0.006\) & \(0.093\pm 0.011\) \\ \hline \hline \end{tabular}
\end{table}
Table 17: Predicted transition rates on the protein folding dataset

Figure 11: Classification of the protein folding dataset into a Low and a High state. The GMM-Classifier has learned a decision boundary close to the radius 2.

\begin{table}
\begin{tabular}{c c c} \hline \hline  & Low STD & High STD \\ \hline Mardt et al. (2017) & \(0.73\) & \(0.27\) \\ NeuralMJP & \(0.74\) & \(0.26\) \\ \hline FIM-MJP \(1\%\) Noise (NeuralMJP Labels) & \(0.73\) & \(0.27\) \\ FIM-MJP \(10\%\) Noise (NeuralMJP Labels) & \(0.62\) & \(0.38\) \\ FIM-MJP \(1\%\) Noise (GMM Labels) & \(0.70\) & \(0.30\) \\ FIM-MJP \(10\%\) Noise (GMM Labels) & \(0.65\) & \(0.35\) \\ \hline \hline \end{tabular}
\end{table}
Table 18: Stationary distribution of the model predictions on the protein folding dataset

### Initial Distributions

For completeness, we report in this section the initial distributions predicted by FIM-MJP on various datasets as well as the heuristic initial distribution (which is computed simply by counting the number of state occurrences at the first observation). We observe that FIM-MJP typically captures the initial distribution quite well. An exception is the Two-Mode Switching System for which FIM-MJP falsely predicts a non-zero probability of the first state. This might happen because we did not capture this case in our training distribution which could be an improvement for future work.

\begin{table}
\begin{tabular}{c c c} \hline \hline Dataset & Predicted \(\pi_{0}\) & Heuristic \(\pi_{0}\) \\ \hline DFR \(V=1\) & \([0.22,0.15,0.11,0.19,0.16,0.17]\) & \([0.3,0.14,0.06,0.2,0.17,0.14]\) \\ IonCh & \([0.14,0.11,0.75]\) & \([0.24,0.08,0.68]\) \\ ADP & \([0.34,0.3,0.23,0.11,0.02,0.0]\) & \([0.33,0.29,0.25,0.11,0.02,0.0]\) \\ Two-Mode System & \([0.32,0.68]\) & \([0.0,1.0]\) \\ Protein Folding & \([0.75,0.25]\) & \([0.73,0.27]\) \\ \hline \hline \end{tabular}
\end{table}
Table 20: Comparison of the predicted initial distribution of the model versus the heuristic initial distribution of various datasets.

\begin{table}
\begin{tabular}{c c c} \hline \hline  & Bottom \(\rightarrow\) Top & Top \(\rightarrow\) Bottom \\ \hline Ground Truth & \(0.2\) & \(0.2\) \\ \hline Kohs et al. (2021) & \(0.64\) & \(0.63\) \\ NeuralMP & \(0.19\) & \(0.36\) \\ \hline FIM-MJP 1\% Noise & \(0.43\) & \(0.25\) \\ FIM-MJP 10\% Noise & \(0.23\) & \(0.15\) \\ \hline \hline \end{tabular}
\end{table}
Table 19: Two-Mode Switching System transition rates. We do not report error bars here because the dataset is so small that it runs in a single batch.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Yes, the claims of the abstract and in the introduction are shown in the contributions of sections 3 and 4. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Yes, Section 6 is devoted to the limitations of our approach. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [NA]Justification: We do not present any theoretical results in this work. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We share our code and trained models, as well as the synthetic data used to evaluate our models6. The synthetic training data is however too large to be published, but can be regenerated with our code. The relevant hyperparameters are stated in Appendix B. Lastly, we cannot share all evaluation data because we do not own it. We provide references in the Acknowledgments to the data owners. Guidelines: Footnote 6: https://github.com/cvejoski/OpenFIM

* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.

5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: Our code and models are openly available. For the availability of the data, please refer to the above point. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: All the training details are described in section D.2 in the Appendix. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Our results are reported with error bars if possible. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).

* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The resources that are used for computation are described in section D.2 of the Appendix. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Our conducted research does not clash with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: Our work is fundamental research that has no impact on society. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.

* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Our paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We have credited the owners of the evaluation data and referenced the related work on which this project has been built on. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.

* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: The new asset of this paper are the code and the models which are well documented. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper did not involve crowdsourcing or reasearch with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper did not involve crowdsourcing or reasearch with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.