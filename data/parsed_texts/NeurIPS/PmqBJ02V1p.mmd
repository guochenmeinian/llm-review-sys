# Adaptive Principal Component Regression

with Applications to Panel Data

 Anish Agarwal

Department of IEOR

Columbia University

New York, NY 10027

aa5194@columbia.edu

&Keegan Harris

School of Computer Science

Carnegie Mellon University

Pittsburgh, PA 15213

keeganh@cs.cmu.edu

&Justin Whitehouse

School of Computer Science

Carnegie Mellon University

Pittsburgh, PA 15213

jwhiteho@cs.cmu.edu

&Zhiwei Steven Wu

School of Computer Science

Carnegie Mellon University

Pittsburgh, PA 15213

zhiwei@cs.cmu.edu

For part of this work, Anish was a postdoc at Amazon, Core AI.

###### Abstract

Principal component regression (PCR) is a popular technique for fixed-design _error-in-variables_ regression, a generalization of the linear regression setting in which the observed covariates are corrupted with random noise. We provide the first time-uniform finite sample guarantees for online (regularized) PCR whenever data is collected _adaptively_. Since the proof techniques for analyzing PCR in the fixed design setting do not readily extend to the online setting, our results rely on adapting tools from modern martingale concentration to the error-in-variables setting. As an application of our bounds, we provide a framework for experiment design in panel data settings when interventions are assigned adaptively. Our framework may be thought of as a generalization of the synthetic control and synthetic interventions frameworks, where data is collected via an adaptive intervention assignment policy.

## 1 Introduction

An omnipresent task in machine learning, statistics, and econometrics is that of making predictions about outcomes of interest given an action and conditioned on observable covariates. An often overlooked aspect of the prediction task is that in many settings the learner only has access to _imperfect observations_ of the covariates, due to e.g. measurement error or inherent randomness in the problem domain. Such settings are sometimes formulated as _error-in-variables_ regression: a _learner_ is given access to a collection of data \((Z_{n},a_{n},Y_{n})_{n\geq 1}\), where \(Z_{n}\in\mathbb{R}^{d}\) are the _observed covariates_, \(a_{n}\in\{1,\ldots,A\}\) is the _action taken_, and \(Y_{n}\in\mathbb{R}\) is the _outcome_ for each observation \(n\). Typically, the outcomes are assumed to be generated by a linear model \(Y_{n}:=\langle\theta(a_{n}),X_{n}\rangle+\xi_{n}\) and \(Z_{n}:=X_{n}+\epsilon_{n}\), where \(X_{n}\in\mathbb{R}^{d}\) are the _true covariates_, \(\epsilon_{n}\in\mathbb{R}^{d}\) is the covariate noise, \(\theta(a_{n})\in\mathbb{R}^{d}\) is an _unknown slope vector_ associated with action \(a_{n}\), and \(\xi_{n}\in\mathbb{R}\) is the response noise. Note that the learner does not get to see the true covariates \(X_{n}\). Observe that when \(\epsilon_{n}=0\) we recover the traditional linear regression setting. Such an error-in-variables model can encompass many forms of data corruption including measurement error, missing values, discretization, and differential privacy--see [10, 5] for details.

Our point of departure from previous work is that we allow the sequence of data \((Z_{n},a_{n},Y_{n})_{n\geq 1}\) to be chosen _adaptively_. In other words, we provide bounds for learning in the error-in-variables regression setting when the data seen at the current round \(n\) is allowed to depend on the previously-seen data \((Z_{m},a_{m},Y_{m})_{1\leq m<n}\). Adaptive data collection occurs when the choices of future observations can depend on the inference from previous data, which is common in learning paradigms such as multi-armed bandits [58; 78], active learning [74], and time-series analysis [76; 36]. Similar to prior work on adaptive data collection that shows that valid statistical inference can be done when the true covariates are observed [34; 67; 43; 91; 92], our work provides the first time-uniform finite sample guarantees for error-in-variables regression using adaptively collected data.

Concretely, we focus on analyzing _principal component regression (PCR)_[54], a method that has been shown to be effective for learning from noisy covariates [10; 7] and a central tool for learning from panel data [8; 5; 7]. At a high level, PCR "de-noises" the sequence of observed covariates \((Z_{n})_{n\geq 1}\) as \((\widehat{Z}_{n})_{n\geq 1}\) by performing hard singular value thresholding, after which a linear model is learned using the observed outcomes \((Y_{n})_{n\geq 1}\) and the denoised covariates \((\widehat{Z}_{n})_{n\geq 1}\). See Section 3.2 for further technical background on PCR.

### Contributions

1. We derive novel time-uniform bounds for an online variant of regularized PCR when the sequence of covariates is chosen adaptively. The techniques used to derive bounds for PCR in the fixed-sample regime [7] do not extend to the setting in which data is collected adaptively; thus, we require new tools and ideas to obtain our results. Specifically, our results rely on applying recent advances in martingale concentration [50; 51], as well as more classical results on self-normalized concentration [3; 32; 33] which are commonly applied to online regression problems, to the error-in-variables setting. As an example of the bounds we obtain, consider the task of estimating the underlying relationship \(\theta(a)\) between true (i.e. noiseless) covariates and observations, given access to \(n\) adaptively-chosen noisy covariates and their corresponding actions and observations. The \(\ell_{2}\) estimation error of the adaptive PCR estimator \(\widehat{\theta}_{n}(a)\) can be bounded as \[\|\widehat{\theta}_{n}(a)-\theta(a)\|_{2}^{2}=\widetilde{O}\left(\frac{1}{{ \rm snr}_{n}(a)^{2}}\kappa({\bf X}_{n}(a))^{2}\right)\] with high probability, where \({\rm snr}_{n}(a)\) is the _signal-to-noise ratio_ associated with action \(a\) at round \(n\) (Definition 3.5), a measure of how well the true covariates stand out from the noise. \(\kappa({\bf X}_{n}(a))\) is the _condition number_ of the true covariates. Intuitively, if \({\rm snr}_{n}(a)\) is high the true covariates can be well-separated from the noise, and therefore PCR accurately estimates \(\theta(a)\) as long as the true covariates are well-conditioned. Despite the harder setting we consider, our PCR bounds for adaptively-collected data largely match the bounds currently known for the fixed-sample regime, and even improve upon them in two important ways: (1) Our bounds are _computable_, i.e. they depend on _known_ constants and quantities available to the algorithm. (2) Unlike Agarwal et al. [7], our bounds do not depend on the \(\ell_{1}\)-norm of \(\theta(a)\), i.e., we do not require approximate sparsity of \(\theta(a)\) for the bounds to imply consistency. This is important because PCR is a rotationally-invariant algorithm, and so its performance guarantees should not depend on the orientation of the basis representation of the space to be learned. The price we pay for adaptivity is that \({\rm snr}_{n}(a)\) is defined with respect to a bound on the _total_ amount of noise seen by the algorithm so far, instead of just the noise associated with the rounds that \(a\) is taken. As a result, our bound for \(\widehat{\theta}_{n}(a)\) may not be tight if \(a\) is seldomly selected.
2. We apply our PCR results to the problem of online experiment design with _panel data_. In panel data settings, the learner observes repeated, noisy measurements of _units_ (e.g. medical patients, subpopulations, geographic locations) under different _interventions_ (e.g. medical treatments, discounts, socioeconomic policies) over _time_. This is an ubiquitous method of data collection, and as a result, learning from panel data has been the subject of significant interest in the econometrics and statistics communities (see Section 2). A popular framework for learning from panel data is _synthetic control_ (SC) [1; 2], which uses historical panel data to estimate counterfactual unit measurements under control. Synthetic interventions (SI) [8] is a recent generalization of the SC framework which allows for counterfactual estimation under treatment, in addition to control. By leveraging online PCR, we can perform counterfactual estimation of unit-specific treatment effects under both treatment and control, as in the SI framework. However, unlike the traditional SI framework, we are the first to establish statistical rates for counterfactual unit outcome estimates under different interventions _while allowing for both units and interventions to be chosen adaptively_. Such adaptivity may naturally occur when treatments are prescribed to new units based on the outcomes of previous units. For example, this is the case when the intervention chosen for each unit is the one which appears to be best based on observations in the past.

## 2 Related work

Error-in-variables regressionThere is a rich literature on error-in-variables regression (e.g. [42; 57; 28; 44; 84; 47; 41]), with research focusing on topics such as high-dimensional [62; 56; 31; 72] and Bayesian settings [70; 81; 40]. Principal component regression (PCR) [54; 22; 10; 7] is a popular method for error-in-variables regression. The results of Agarwal et al. [7] are of particular relevance to us, as they provide finite sample guarantees for the fixed design (i.e. non-adaptive) version of the setting we consider.

Self-normalized concentrationThere has been a recent uptick in the application of self-normalized, martingale concentration to online learning problems. In short, self-normalized concentration aims to control the growth of processes that have been normalized by a random, or empirical, measure of accumulated variance [32; 33; 50; 51; 88]. Self-normalized concentration has led to breakthroughs in wide-ranging areas of machine learning such as differential privacy [85; 86], PAC-Bayesian learning [30], convex divergence estimation [63], and online learning [87; 29; 3]. Of particular importance for our work are the results of Abbasi-Yadkori et al. [3], which leverage self-normalized concentration results for vector-valued processes [32; 33] to construct confidence ellipsoids for online regression tasks. We take inspiration from these results when constructing our estimation error bounds for PCR in the sequel.

Learning in panel data settingsOur application to panel data builds off of the SI framework [8; 9], which itself is a generalization of the canonical SC framework for learning from panel data [1; 2; 52; 35; 17; 60; 89; 13; 14; 59; 16; 20; 23; 27; 39]. In both frameworks, a _latent factor model_ is often used to encode structure between units and time-steps [25; 61; 15; 18; 19; 68; 64; 65]. Specifically, it is assumed that unit outcomes are the product of unit- and time/intervention-specific latent factors, which capture the heterogeneity across time-steps, units, and interventions, and allows for the estimation of unit-specific counterfactuals under treatment and control. Other extensions of the SI framework include applications in biology [79], network effects [11], combinatorially-many interventions [4], and intervening under incentives [45; 66]. Finally, there is a growing line of work at the intersection of online learning and panel data. Chen [26] views the problem of SC as an instance of online linear regression, which allows them to apply the regret guarantees of the online learning algorithm _follow-the-leader_[55] to show that the predictions of SC are comparable to those of the best-in-hindsight weighted average of control unit outcomes. Farias et al. [38] build on the SC framework to estimate treatment effects in adaptive experimental design, while minimizing the regret associated with experimentation. The results of Farias et al. [38] are part of a growing line of work on counterfactual estimation and experimental design using multi-armed bandits [69; 77; 90; 24].

## 3 Setting and background

NotationWe use boldface symbols to represent matrices. For \(N\in\mathbb{N}\), we use the shorthand \([N]:=\{1,\ldots,N\}\). Unless specified otherwise, \(\|v\|\) denotes the \(\ell_{2}\)-norm of a vector \(v\), and \(\|\mathbf{A}\|_{op}\) the operator norm of matrix \(\mathbf{A}\). We use \(\operatorname{diag}(a_{1},\ldots,a_{k})\) to represent a \(k\times k\) diagonal matrix with entries \(a_{1},\ldots,a_{k}\). For two numbers \(a,b\in\mathbb{R}\), we use \(a\wedge b\) as shorthand for \(\min\{a,b\}\), and \(a\lor b\) to mean \(\max\{a,b\}\). Finally, \(\mathbb{S}^{d-1}\) denotes the \(d\)-dimensional unit sphere.

### Problem setup

We now describe our error-in-variables setting. We consider a _learner_ who interacts with an _environment_ over a sequence of rounds. At the start of each round \(n\geq 1\), the environment generates covariates \(X_{n}\in W^{*}\subset\mathbb{R}^{d}\), where \(W^{*}\) is a low-dimensional linear subspace of dimension \(\dim(W^{*})=r<d\)We assume that \(r\) (but not \(W^{*}\)) is known to the learner. Such "low rank" assumptions are reasonable whenever, e.g. data is generated according to a _latent factor model_, a popular assumption in high-dimensional statistical settings [53; 12; 48]. As we will see in Section 5, analogous assumptions are often also made in panel data settings. The learner then observes _noisy_ covariates \(Z_{n}:=X_{n}+\epsilon_{n}\), where \(\epsilon_{n}\in\mathbb{R}^{d}\) is a random noise vector. Given \(Z_{n}\), the learner selects an _action_\(a_{n}\in[A]\) and observes \(Y_{n}:=\langle\theta(a_{n}),X_{n}\rangle+\xi_{n}\), where \(\xi_{n}\) is random noise and \(\theta(a)\) for \(a\in[A]\) are unknown slope vectors in \(W^{*}\) that parameterize action choices such that \(\|\theta(a)\|_{2}\leq L\) for some \(L\in\mathbb{R}\). We require that the covariate noise is "well-behaved" according to one of the two the following assumptions:

**Assumption 3.1** (**SubGaussian Covariate Noise**).: _For any \(n\geq 1\), the noise variable \(\epsilon_{n}\) satisfies (a) \(\epsilon_{n}\) is \(\sigma\)-subGaussian, (b) \(\mathbb{E}\epsilon_{n}=0\), and (c) \(\|\mathbb{E}\epsilon_{n}\epsilon_{n}^{\top}\|_{op}\leq\gamma\), for some constant \(\gamma>0\)._

**Assumption 3.2** (**Bounded Covariate Noise**).: _For any \(n\geq 1\), the noise variable \(\epsilon_{n}\) satisfies (a) \(\|\epsilon_{n}\|\leq\sqrt{Cd}\), (b) \(\mathbb{E}\epsilon_{n}=0\), and (c) \(\mathbb{E}\epsilon_{n}\epsilon_{n}^{\top}=\sum\), for some positive-definite matrix \(\Sigma\) satisfying \(\|\Sigma\|_{op}\leq\gamma\), for some constant \(\gamma>0\)._

Note that Assumption 3.2 is a special case of Assumption 3.1, which allows us to get stronger results in some settings. We also impose the following constraint on the noise in the outcomes.

**Assumption 3.3** (**SubGaussian Outcome Noise**).: _For any \(n\geq 1\), the noise variable \(\xi_{n}\) satisfies (a) \(\mathbb{E}\xi_{n}=0\), (b) \(\xi_{n}\) is \(\eta\)-subGaussian, and (c) \(\mathbb{E}\xi_{n}^{2}\leq\alpha\), for some constant \(\alpha\)._

Under this setting, the goal of the learner is to estimate \(\theta(a)\) for \(a\in[A]\) given an (possibly adaptively-chosen) observed sequence \((Z_{n},a_{n},Y_{n})_{n\geq 1}\). For \(n\geq 1\), we define the matrix \(\mathbf{Z}_{n}\in\mathbb{R}^{n\times d}\) to be the matrix of _observed_ (i.e. noisy) covariates, with \(Z_{1},\ldots,Z_{n}\) as its rows. Similarly, \(\mathbf{X}_{n}=(X_{1},\ldots,X_{n})^{T}\in\mathbb{R}^{n\times d}\) is the matrix of _noiseless_ covariates (which are unobserved), and \(\mathcal{E}_{n}=(\epsilon_{1},\ldots,\epsilon_{n})^{T}\in R^{n\times d}, \mathbf{Y}_{n}=(Y_{1},\ldots,Y_{n})^{T}\in\mathbb{R}^{n\times 1}\), and \(\Xi_{n}=(\xi_{1},\ldots,\xi_{n})^{T}\in\mathbb{R}^{n\times 1}\) are defined analogously. For any action \(a\in[A]\), let \(N_{n}(a):=\{s\leq n:a_{s}=n\}\) be the _set of rounds_ up to and including round \(n\) on which action \(a\) was chosen. Likewise, let \(c_{n}(a):=|N_{n}(a)|\) denote the _number of rounds_ by round \(n\) on which action \(a\) was chosen. For \(a\in[A]\), we enumerate \(N_{n}(a)\) in increasing order as \(i_{1}\leq\cdots\leq i_{c_{n}(a)}\). Finally, we define \(\mathbf{Z}_{n}(a)\in\mathbb{R}^{c_{n}(a)\times d}\) to be \(\mathbf{Z}(a)=(Z_{i_{1}},\ldots,Z_{i_{c_{n}(a)}})^{T}\), and define \(\mathbf{X}_{n}(a),\mathcal{E}_{n}(a),\mathbf{Y}_{n}(a),\) and \(\Xi_{n}(a)\) analogously.

### Principal component regression

Background on singular value decompositionAny matrix \(\mathbf{A}\in\mathbb{R}^{n\times d}\) may be written in terms of its singular value decomposition \(\mathbf{A}=\mathbf{U}\Sigma\mathbf{V}^{T},\) where \(\mathbf{U}\in\mathbb{R}^{n\times d\wedge n}\) and \(\mathbf{V}\in\mathbb{R}^{d\times d\wedge n}\) are matrices with orthonormal columns, and \(\Sigma=\mathrm{diag}(\sigma_{1}(\mathbf{A}),\ldots,\sigma_{d\wedge n}(\mathbf{ A}))\in\mathbb{R}^{(d\wedge n)\times(d\wedge n)}\) is a diagonal matrix containing the singular values of \(\mathbf{A}\), where we assume \(\sigma_{1}(\mathbf{A})\geq\cdots\geq\sigma_{d\wedge n}(\mathbf{A})\geq 0\). Given a _truncation level_\(k\), we define the truncation of \(\mathbf{A}\) onto its top \(k\) principal components as \(\mathbf{A}_{k}:=\mathbf{U}_{k}\mathrm{diag}(\sigma_{1}(\mathbf{A}),\ldots, \sigma_{k\wedge d\wedge n}(\mathbf{A}))\mathbf{V}_{k}^{T}\), where \(\mathbf{U}_{k}\in\mathbb{R}^{n\times k\wedge d\wedge n}\) is the matrix with the first \(k\wedge d\wedge n\) columns of \(\mathbf{U}\), and \(\mathbf{V}_{k}\in\mathbb{R}^{n\times k\wedge d\wedge n}\) is defined analogously. Given such a singular value decomposition, we can define the projection matrix onto the subspace spanned by the top \(k\) right singular vectors as \(\mathbf{P}_{k}\in\mathbb{R}^{d\times d}\) given by \(\mathbf{P}_{k}:=\mathbf{V}_{k}\mathbf{V}_{k}^{T}\).

For \(n\geq 1\), \(a\in[A]\), and \(\mathbf{Z}_{n}(a)\) as defined above, we write the \(k\)-truncated singular value decomposition of \(\mathbf{Z}_{n}(a)\) as \(\mathbf{Z}_{n,k}(a)=\widehat{\mathbf{U}}_{n,k}(a)\mathrm{diag}(\sigma_{1}( \mathbf{Z}_{n}(a)),\ldots,\sigma_{k\wedge n\wedge d}(\mathbf{Z}_{n}(a)))\widehat {\mathbf{V}}_{n,k}^{T}(a)\), and the corresponding projection onto the top \(k\) right singular vectors of \(\mathbf{Z}_{n}(a)\) as \(\widehat{\mathbf{P}}_{n,k}(a)\). When \(k=r\), we leverage the simplified notation \(\widehat{\mathbf{P}}_{n}(a):=\widehat{\mathbf{P}}_{n,r}(a)\). (Recall \(r=\mathrm{dim}(W^{*})\).) By \(\mathbf{P}\), we denote the projection matrix onto the true, underlying subspace \(W^{*}\). While \(\mathbf{P}\) is never known, our results leverage the fact that \(\widehat{\mathbf{P}}_{n}(a)\) converges to \(\mathbf{P}\) nicely over time. We define the projected noisy covariate matrix matrix to be \(\widehat{\mathbf{Z}}_{n}(a):=\mathbf{Z}_{n}(a)\widehat{\mathbf{P}}_{n}(a)\), and define \(\widehat{\mathbf{X}}_{n}(a),\widehat{\mathcal{E}}_{n}(a)\) similarly. Any quantity with a "\(\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{ \tilde{\tilde{       \tildetildetildetilde{\tilde{\tildetilde{\tilde{\tildetilde{\tildetildetilde{\tilde                                             0}}}}}}\). Any quantity with a "\(\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tildetilde{\tilde}}}}}}}}}}\)" is defined equivalently to quantities with "\(\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\tilde{\}}{\tilde{\tilde{\tilde{\ \tilde{\tilde{\}}}}}}}}}}}\)", except with \(\mathbf{P}\) in place of \(\widehat{\mathbf{P}}_{n}(a)\). We are now ready to introduce our procedure for estimating \(\theta(a)\) for \(a\in[A]\), called _adaptive_ (or _online_) principal component regression.

**Definition 3.4** (**Adaptive Principal Component Regression**).: _Given regularization parameter \(\rho\geq 0\) and truncation level \(k\in\mathbb{N}\), for \(a\in[A]\) and \(n\geq 1\) let \(\widehat{\mathbf{Z}}_{n}(a):=\mathbf{Z}_{n}(a)\widehat{\mathbf{P}}_{n,k}(a)\) and \(\widehat{\mathcal{V}}_{n}(a):=\widehat{\mathbf{Z}}_{n}(a)^{T}\widehat{ \mathbf{Z}}_{n}(a)+\rho\widehat{\mathbf{P}}_{n,k}(a)\). Regularized principal component regression estimates \(\theta(a)\) as_

\[\widehat{\theta}_{n}(a):=\widehat{\mathcal{V}}_{n}(a)^{-1}\widehat{\mathbf{Z} }_{n}(a)\mathbf{Y}_{n}(a).\]

[MISSING_PAGE_FAIL:5]

Adaptive bounds for online (regularized) PCR

We now present the main results of this work--high-probability, time- and action-uniform bounds measuring the convergence of the PCR estimates \(\widehat{\theta}_{n}(a)\) to the true slope vectors \(\theta(a)\). Unlike existing results [6, 7, 8], our bounds are valid when the covariates \((X_{n})_{n\geq 1}\) and actions \((a_{n})_{n\geq 1}\) are determined in an online (potentially adversarial) manner.

We first point out why the analysis of Agarwal et al. [7, 8] breaks down in the setting of adaptive (or online) PCR. First, many of the concentration inequalities leveraged in Agarwal et al. [7] do not hold in the adaptive design setting. As a particular example, the authors leverage the Hanson-Wright inequality [73, 82] for quadratic forms to study how the noisy covariate matrix \(\mathbf{Z}_{n}\) concentrates around the true matrix \(\mathbf{X}_{n}\). This inequality fails to hold when the design points \((X_{n})_{n\geq 1}\) depend on the previous observations. Second, the techniques leveraged by Agarwal et al. [8] to extend the convergence guarantees of PCR to the multiple action setting fail to hold when the \(n\)-th action \(a_{n}\) is selected based on previous observations. Lastly, the bounds presented in [7] are are inherently fixed-time in nature--a simple way to convert existing fixed-time bounds to time-uniform ones would be to perform a union bound over time steps, but that introduces looseness in the bounds.

We are able to construct our bounds by exploiting connections between online PCR and self-normalized martingale concentration [50, 51, 32, 33]. In particular, we combine martingale-based results for constructing confidence ellipsoids for online regression [32, 33, 33] with methods for high-dimensional covariance estimation [80, 83] to prove our results. Exploiting this connection is what allows us to extend the results of Agarwal et al. [7] to the adaptive design, time-uniform setting. We begin with a bound which, up to constants and polylogarthmic factors, captures the rate of convergence of online PCR in terms of (a) the underlying signal to noise ratio and (b) the conditioning of the observed data.

**Theorem 4.1** (**Rate of Convergence for Online PCR**).: _Let \(\delta\in(0,1)\) be an arbitrary confidence parameter. Let \(\rho>0\) be chosen to be sufficiently small, as detailed in Appendix F. Further, assume that there is some \(n_{0}\geq 1\) such that \(\operatorname{rank}(\mathbf{X}_{n_{0}}(a))=r\) and \(\operatorname{snr}_{n}(a)\geq 2\) for all \(n\geq n_{0}\). Then, with probability at least \(1-O(A\delta)\), simultaneously for all actions \(a\in[A]\) and time steps \(n\geq n_{0}\), we have_

\[\|\widehat{\theta}_{n}(a)-\theta(a)\|_{2}^{2}=\widetilde{O}\left(\frac{1}{ \operatorname{snr}_{n}(a)^{2}}\kappa(\mathbf{X}_{n}(a))^{2}\right),\]

_where \(\kappa(\mathbf{X}_{n}(a)):=\frac{\sigma_{1}(\mathbf{X}_{n}(a))}{\sigma_{r}( \mathbf{X}_{n}(a))}\) is the condition number (ignoring zero singular values) of \(\mathbf{X}_{n}(a)\)._

Theorem 4.1 is proved in Appendix E. We begin by comparing our bounds to those of Agarwal et al. [7, 8]. At any fixed time, our bounds take on roughly the same form as those of the aforementioned authors, having an inverse quadratic dependence on the signal to noise ratio. To make their bounds non-vacuous, the authors need to make the "soft sparsity" assumption of \(\|\theta(a)\|_{1}=O(\sqrt{d})\). Our bound, on the other hand, suffers no dependence on the \(\ell_{1}\)-norm of the \(\theta(a)\)'s. This makes intuitive sense, as the specific choice of a basis should not impact the rate of convergence of PCR. However, our bounds pay a price for adaptivity--in particular, the signal to noise ratio associated with an action is defined with respect to a bound on the _total_ operator norm of the matrix \(\mathcal{E}_{n}\). If an action is selected very infrequently, the above bound may become loose.

While the above bound is stated in terms of signal to noise ratio, if we make additional assumptions, we can obtain bounds directly in terms of \(d,n,\) and \(r\). In particular, the following "well-balancing" assumptions suffice.

**Assumption 4.2** (**Well-balancing assumptions**).: _For all \(n\geq n_{0}\), the following hold: (a) \(\sigma_{i}(\mathbf{X}_{n}(a))=\Theta\left(\sqrt{\frac{c_{n}(a)d}{r}}\right)\) for all \(i\in[r]\), (b) \(c_{n}(a)=\Theta(c_{n}(a^{\prime}))\) for all \(a,a^{\prime}\in[A]\), and (c) \(A=O(r)\)._

**Corollary 4.3**.: _Assume the same setup as Theorem 4.1, and further assume Assumption 4.2 holds. Then with probability at least \(1-O(A\delta)\), simultaneously for all actions \(a\in[A]\) and time steps \(n\geq n_{0}\), we have_

\[\|\widehat{\theta}_{n}(a)-\theta(a)\|_{2}^{2}=\widetilde{O}\left(\frac{r^{2}} {d\wedge n}\right).\]Corollary 4.3 shows that Theorem 4.1 obtains the same estimation rate as Theorem 4.1 of Agarwal et al. [7] if assumption Assumption 4.2 holds. This "well-balancing" assumption says roughly that all non-zero singular values of \(\mathbf{X}_{n}\) are of the same order, each action is selected with the same frequency, and that the number of actions is, at most, proportional to dimension of the true, unknown subspace. As noted by Agarwal et al. [7], the assumption of a "well-balanced spectrum" (for \(\mathbf{X}_{n}\)) is common in many works in econometrics and robust statistics, and additionally holds with high probability if the entries of \(\mathbf{X}_{n}\) are i.i.d.[62, 21, 37]. Further, it is often the case that there only few available actions (for instance, in the synthetic control literature there are only two actions [2, 1, 38]), justifying the assumption that \(A=O(r)\). Lastly, ensuring that each action is played (very roughly) the same number of times can be viewed as a price for adaptivity.

The proof of Theorem 4.1 is immediate as a corollary from the following, more complicated bound. Theorem 4.4 below measures the convergence of \(\widehat{\theta}_{n}(a)\) to \(\theta(a)\) in terms of empirical (i.e. observed) quantities. We imagine this bound to be the most practically relevant of our results, as, unlike the results of Agarwal et al. [7], it is directly computable by the learner, involves known constants, and places minimal conditions on the signal to noise ratio.

**Theorem 4.4** (**Empirical Guarantees for Online PCR**).: _Let \(\delta\in(0,1)\) be an arbitrary confidence parameter. Let \(\rho>0\) be chosen to be sufficiently small, as detailed in Appendix F. Further, assume that there is some \(n_{0}\geq 1\) such that \(\mathrm{rank}(\mathbf{X}_{n_{0}}(a))=r\) and \(\mathrm{snr}_{n}(a)\geq 2\) for all \(n\geq n_{0}\). Then, with probability at least \(1-O(A\delta)\), simultaneously for all actions \(a\in[A]\) and time steps \(n\geq n_{0}\), we have_

\[\left\|\widehat{\theta}_{n}(a)-\theta(a)\right\|_{2}^{2}\leq\frac{L^{2}}{ \widehat{\mathrm{snr}}_{n}(a)^{2}}\left[74+216\kappa(\mathbf{Z}_{n}(a))^{2} \right]+\frac{2\mathrm{err}_{n}(a)}{\sigma_{r}(\mathbf{Z}_{n}(a))^{2}},\]

_where \(\kappa(\mathbf{Z}_{n}(a)):=\frac{\sigma_{1}(\mathbf{Z}_{n}(a))}{\sigma_{r}( \mathbf{Z}_{n}(a))}\), \(\|\theta(a)\|_{2}\leq L\), and in the above we define the "error" term \(\mathrm{err}_{n}(a)\) to be_

\[\mathrm{err}_{n}(a) :=32\rho L^{2}+64\eta^{2}\left(\log\left(\frac{A}{\delta}\right) +r\log\left(1+\frac{\sigma_{1}(\mathbf{Z}_{n}(a))^{2}}{\rho}\right)\right)\] \[+6\eta^{2}\sqrt{2c_{n}(a)\ell_{\delta}(c_{n}(a))}+10\eta^{2}\ell_ {\delta}(c_{n}(a))+6c_{n}(a)\alpha.\]

We see that the above bound, with the exception of the third term, more or less resembles the bound presented in Theorem 4.1, just written in terms of the observed covariates \(\mathbf{Z}_{n}(a)\) instead of the true covariates \(\mathbf{X}_{n}(a)\). We view the third term as a slowly growing "error" term. In particular, all terms in the quantity \(\mathrm{err}_{n}(a)\) are either constant, logarithmic in the singular values of \(\mathbf{Z}_{n}(a)\), or linear in \(c_{n}(a)\), the number of times by round \(n\) action \(a\) has been selected. This implies that \(\mathrm{err}_{n}(a)=\widetilde{O}(n+d)\), ensuring \(\mathrm{err}_{n}(a)\) is dominated by other terms in the asymptotic analysis. We now provide the proof of Theorem 4.4. The key application of self-normalized, martingale concentration comes into play in bounding the quantities that appear in the upper bounds of terms \(T_{1}\) and \(T_{2}\) (to be defined below).

Proof.: Observe the decomposition, for any \(n\geq 1\) and \(a\in[A]\)

\[\widehat{\theta}_{n}(a)-\theta(a)=\widehat{\mathbf{P}}_{n}(a)(\widehat{ \theta}_{n}(a)-\theta(a))+(\mathbf{P}^{\perp}-\widehat{\mathbf{P}}_{n}^{\perp }(a))\theta(a),\]

where \(\mathbf{P}^{\perp}\) is the projection onto the subspace orthogonal to \(W^{*}\) and \(\widehat{\mathbf{P}}_{n}^{\perp}(a)\) is the projection onto the subspace orthogonal to the learned subspace (i.e. that spanned by \(\mathbf{Z}_{n,r}(a)\)). Since \(\widehat{\mathbf{P}}_{n}(a)(\widehat{\theta}_{n}(a)-\theta(a))\) and \((\mathbf{P}^{\perp}-\widehat{\mathbf{P}}_{n}^{\perp}(a))\theta(a)\) are orthogonal vectors, we have

\[\left\|\widehat{\theta}_{n}(a)-\theta(a)\right\|_{2}^{2}=\left\|\widehat{ \mathbf{P}}_{n}(a)(\widehat{\theta}_{n}(a)-\theta(a))\right\|_{2}^{2}+\left\| (\widehat{\mathbf{P}}_{n}^{\perp}(a)-\mathbf{P}^{\perp})\theta(a)\right\|_{2}^ {2}.\]

We bound these two terms separately, beginning with the second term. Going forward, fix an action \(a\in[A]\). Observe that with probability at least \(1-\delta\), simultaneously for all \(n\geq n_{0}(a)\),

\[\left\|(\widehat{\mathbf{P}}_{n}^{\perp}(a)-\mathbf{P}^{\perp}) \theta(a)\right\|_{2}^{2} \leq\left\|\widehat{\mathbf{P}}_{n}^{\perp}(a)-\mathbf{P}^{\perp} \right\|_{op}^{2}\left\|\theta(a)\right\|_{2}^{2}\] \[\leq L^{2}\left\|\widehat{\mathbf{P}}_{n}^{\perp}(a)-\mathbf{P}^{ \perp}\right\|_{op}^{2}=L^{2}\left\|\widehat{\mathbf{P}}_{n}(a)-\mathbf{P} \right\|_{op}^{2}\] \[\leq\frac{4L^{2}U_{n}^{2}}{\sigma_{r}(\mathbf{X}_{n}(a))^{2}}\leq \frac{6L^{2}U_{n}^{2}}{\sigma_{r}(\mathbf{Z}_{n}(a))^{2}},\]where the equality in the above comes from observing \(\|\widehat{\mathbf{P}}_{n}^{\perp}(a)-\mathbf{P}^{\perp}\|_{op}=\|\widehat{\mathbf{P} }_{n}(a)-\mathbf{P}\|_{op}\), the second-to-last last inequality comes from applying Lemma B.4, and the last inequality follows from the second part of Lemma B.6.

We now bound the first term. Observe that we can write

\[\begin{split}&\left\|\widehat{\mathbf{P}}_{n}(a)\left(\widehat{ \theta}_{n}(a)-\theta(a)\right)\right\|_{2}^{2}\leq\frac{1}{\sigma_{r}( \mathbf{Z}_{n}(a))^{2}}\left\|\widehat{\mathbf{Z}}_{n}(a)\left(\widehat{\theta }_{n}(a)-\theta(a)\right)\right\|_{2}^{2}\\ &\leq\frac{2}{\sigma_{r}(\mathbf{Z}_{n}(a))^{2}}\left[\underbrace {\left\|\widehat{\mathbf{Z}}_{n}(a)\widehat{\theta}_{n}(a)-\mathbf{X}_{n}(a) \theta(a)\right\|_{2}^{2}}_{\widehat{T_{1}}}+\underbrace{\left\|\mathbf{X}_{n} (a)\theta(a)-\widehat{\mathbf{Z}}_{n}(a)\theta(a)\right\|_{2}^{2}}_{\widehat{ T_{2}}}\right],\end{split}\] (1)

where the first inequality follows from the fact that \(\widehat{\mathbf{P}}_{n}(a)\preceq\frac{1}{\sigma_{r}(\widehat{\mathbf{Z}}_{n} (a))^{2}}\widehat{\mathbf{Z}}_{n}(a)^{\top}\widehat{\mathbf{Z}}_{n}(a)\) and \(\sigma_{r}(\mathbf{Z}_{n}(a))=\sigma_{r}(\widehat{\mathbf{Z}}_{n}(a))\), and the second inequality comes from applying the parallelogram inequality. First we bound \(T_{1}\). We have, with probability at least \(1-O(\delta)\), simultaneously for all \(n\geq n_{0}(a)\)

\[\begin{split} T_{1}&\leq 8\left\|\widetilde{\mathcal{V} }_{n}(a)^{1/2}\left(\widetilde{\theta}_{n}(a)-\theta(a)\right)\right\|_{2}^{2} +6\left\|\Xi_{n}(a)\right\|_{2}^{2}+8\left\|\widehat{\mathbf{Z}}_{n}(a) \theta(a)-\mathbf{X}_{n}(a)\theta(a)\right\|_{2}^{2}\\ &\leq 32\rho L^{2}+64\eta^{2}\left(\log\left(\frac{A}{\delta} \right)+r\log\left(1+\frac{\sigma_{1}(\mathbf{Z}_{n}(a))^{2}}{\rho}\right) \right)+16L^{2}U_{n}^{2}\\ &+6\eta^{2}\sqrt{2c_{n}(a)\ell_{\delta}(c_{n}(a))}+10\eta^{2}\ell _{\delta}(c_{n}(a))+6c_{n}(a)\alpha+8T_{2},\end{split}\] (2)

where the first inequality follows from Lemma D.1, and the second inequality follows from applying Lemmas C.1 and D.3. \(\ell_{\delta}(n)=2\log\log(2n)+\log\left(\frac{d\sigma^{2}}{12\delta}\right)\), as defined in Lemma A.2. We now bound \(T_{2}\). With probability at least \(1-O(\delta)\) simultaneously for all \(n\geq n_{0}\), we have

\[\begin{split} T_{2}&\leq 2L^{2}\sigma_{1}( \mathbf{Z}_{n}(a))^{2}\left\|\mathbf{P}-\widehat{\mathbf{P}}_{n}(a)\right\|_{op }^{2}+2L^{2}\left\|\mathcal{E}_{n}\right\|_{op}^{2}\\ &\leq\frac{8L^{2}\sigma_{1}(\mathbf{Z}_{n}(a))^{2}U_{n}^{2}}{ \sigma_{r}(\mathbf{X}_{n}(a))^{2}}+2L^{2}U_{n}^{2}\\ &\leq\frac{12L^{2}\sigma_{1}(\mathbf{Z}_{n}(a))^{2}U_{n}^{2}}{ \sigma_{r}(\mathbf{Z}_{n}(a))^{2}}+2L^{2}U_{n}^{2}.\end{split}\] (3)

The first inequality follows from Lemma D.2, the second inequality follows from applying Lemmas B.4 and B.3, and the final inequality follows from Lemma B.6.

Piecing the above inequalities together yields the desired result, which can be checked via the argument at the end of Appendix D. A union bound over actions then yields that the desired inequality holds over all actions \(a\in[A]\) with probability at least \(1-O(A\delta)\). 

## 5 Application to causal inference with panel data

We now apply our bounds for adaptive PCR to online experiment design in the context of panel data. In this setting, the learner is interested in estimating _unit-specific counterfactuals_ under different _interventions_, given a sequence of unit _outcomes_ (or _measurements_) over _time_. Units can range from medical patients, to subpopulations or geographic locations. Examples of interventions include medical treatments, discounts, and socioeconomic policies. _Synthetic control (SC)_ is a popular framework used to estimate counterfactual unit outcomes in panel data settings, had they not been treated (i.e. remained under _control_) [1; 2]. In SC, there is a notion of a _pre-intervention_ time period in which all units are under control, followed by a _post-intervention_ time period, in which every unit undergoes one of several interventions (including control). At a high level, SC fits a model of a unit's pre-treatment outcomes using pre-treatment data from units who remained under control in the post-intervention time period. It then constructs a "synthetic control" by using the learned model to predict the unit's post-intervention outcomes, had they remained under control. _Synthetic interventions (SI)_ is a recent generalization of the SC framework, which allows for counterfactual estimation of unit outcomes under different interventions, in addition to control [8]. Using our bounds from Section 4, we show how to generalize the SI framework of Agarwal et al. [8] to settings where interventions are assigned via an _adaptive intervention assignment policy_.

As a motivating example, consider an online e-commerce platform (learner) which assigns discounts (interventions) to users (units) with the goal of maximizing total user engagement on the platform. For concreteness, suppose that the e-commerce platform assigns discounts _greedily_ with respect to the discount level which appears to be best at the current round (i.e. maximizes total engagement for the current user), given the sequence of previously observed (user, discount level, engagement level) tuples. Under such a setting, the intervention assigned at the current round \(n\) will be correlated with the observed engagement levels at previous rounds, thus breaking the requirement of the SI framework [8] that the intervention assignment is not adaptive to previously observed outcomes.

Formally, we consider a panel data setting in which the principal observes units over a sequence of rounds. In each round \(n\), the learner observes a unit \(n\) under _control_ for \(T_{0}\in\mathbb{N}\) time steps, followed by one of \(A\)_interventions_ (including control, which we denote by \(0\)) for the remaining \(T-T_{0}\) time steps, where \(T\in\mathbb{N}\). Overloading notation to be consistent with the literature on panel data, we denote the potential outcome of unit \(n\) at time \(t\) under intervention \(a\) by \(Y^{(a)}_{n,t}\in\mathbb{R}\), the set of unit \(n\)'s pre-treatment outcomes (under control) by \(Y_{n,pre}:=[Y^{(0)}_{n,1},\dots,Y^{(0)}_{n,T_{0}}]^{T}\in\mathbb{R}^{T_{0}}\), and their post-intervention potential outcomes under intervention \(a\) by \(Y^{(a)}_{n,post}:=[Y^{(a)}_{n,T_{0}+1},\dots,Y^{(a)}_{n,T}]^{T}\in\mathbb{R}^{T -T_{0}}\). We use \(a\) to refer to an arbitrary intervention in \(\{0,\dots,A-1\}\) and \(a_{n}\) to denote the _realized_ intervention unit \(n\) actually receives in the post-intervention time period. We posit that potential outcomes are generated by the following _latent factor model_ over units, time steps, and interventions.

**Assumption 5.1** (**Latent Factor Model)**.: _Suppose the outcome for unit \(n\) at time step \(t\) under treatment \(a\in\{0,\dots,A-1\}\) takes the form_

\[Y^{(a)}_{n,t}=\langle U^{(a)}_{t},V_{n}\rangle+\epsilon^{(a)}_{n,t},\]

_where \(U^{(a)}_{t}\in\mathbb{R}^{r}\) is a latent factor which depends only on the time step \(t\) and intervention \(a\), \(V_{n}\in\mathbb{R}^{r}\) is a latent factor which only depends on unit \(n\), and \(\epsilon^{(a)}_{n,t}\) is zero-mean SubGaussian random noise with variance at most \(\sigma^{2}\). We assume, without loss of generality, that \(|\langle U^{(a)}_{t},V_{n}\rangle|\leq 1\) for all \(n\geq 1\), \(t\in[T]\), \(a\in\{0,\dots,A-1\}\)._

Note that the learner observes \(Y^{(a)}_{n,t}\)_for only the intervention \(a_{n}\) that unit \(n\) is under at time step \(t\)_, and never observes \(U^{(a)}_{t}\), \(V_{n}\), or \(\epsilon^{(a)}_{n,t}\). Such "low rank" assumptions are ubiquitous within the panel data literature (see references in Section 2). We assume that \(r\) is known to the learner, although principled heuristics exist for estimating \(r\) in practice from data (see, e.g. Section 3.2 of Agarwal et al. [8]). Additionally, we make the following "causal transportability" assumption on the latent factors.

**Assumption 5.2** (**Linear span inclusion)**.: _For any post-intervention time step \(t\in[T_{0}+1,T]\) and intervention \(a\in\{0,\dots,A-1\}\), we assume that \(U^{(a)}_{t}\in\operatorname{span}(\{U^{(0)}_{t}:t\in[T_{0}]\})\)._

Intuitively, Assumption 5.2 allows for information to be inferred about the potential outcomes in the post-intervention time period using pre-treatment observations. The goal of the learner is to estimate unit-specific counterfactual outcomes under different interventions _when the sequence of units and interventions is chosen adaptively_. In line with previous work in SI and SC, our target causal parameter is the (counterfactual) _average expected post-intervention outcome_.

**Definition 5.3**.: _The average expected post-intervention outcome of unit \(n\) under intervention \(a\) is_

\[\mathbb{E}\bar{Y}^{(a)}_{n,post}:=\frac{1}{T-T_{0}}\sum_{t=T_{0}+1}^{T}\mathbb{ E}Y^{(a)}_{n,t},\]

_where the expectation is taken with respect to \((\epsilon^{(a)}_{n,t})_{T_{0}<t\leq T}\)._

While we consider the _average_ post-intervention outcome, our results may be readily extended to settings in which the target causal parameter is any _linear_ combination of post-intervention outcomes. Next we show that under Assumption 5.1 and Assumption 5.2, \(\mathbb{E}\bar{Y}^{(a)}_{n,post}\) may be written as a linear combination of unit \(n\)'s _pre_-intervention outcomes. We note that similar observations have previously been made in the panel data literature (e.g. [46]), but we include the following lemma for completeness' sake.

**Lemma 5.4** (**Reformulation of average expected post-intervention outcome**).: _Under Assumption 5.1 and Assumption 5.2, there exists slope vector \(\theta(a)\in\mathbb{R}^{T_{0}}\), such that the average expected post-intervention outcome of unit \(n\) under intervention \(a\) is expressible as_

\[\mathbb{E}\bar{Y}_{n,post}^{(a)}=\frac{1}{T-T_{0}}\langle\theta(a),\mathbb{E}Y_ {n,pre}\rangle.\]

\(\theta(a)\) may be interpreted as a unit-independent measure of the causal relationship between pre- and post-intervention outcomes. Using this reformulation, adaptive guarantees for the estimation of causal effects over time may now be obtained by applying our online PCR results of Section 4. Overloading the notation of Section 3, we let \(\mathbf{X}_{n}=(\mathbb{E}Y_{1,pre},\ldots,\mathbb{E}Y_{n,pre})^{T}\), \(\mathbf{Z}_{n}=(Y_{1,pre},\ldots,Y_{n,pre})^{T}\), \(\epsilon_{n,pre}=(\epsilon_{n,1}^{(0)},\ldots,\epsilon_{n,T_{0}}^{(0)})^{T}\), \(\mathcal{E}_{n}=(\epsilon_{1,pre},\ldots,\epsilon_{n,pre})^{T}\)\(\xi_{n}=\sum_{t=T_{0}+1}^{T}\epsilon_{n,t}^{(a_{n})}\), \(\Xi_{n}=(\xi_{1},\ldots,\xi_{n})^{T}\), and

\[\mathbf{Y}_{n}=\left(\frac{1}{T-T_{0}}\sum_{t=1}^{T_{0}}Y_{1,t}^{(a_{1})}, \ldots,\frac{1}{T-T_{0}}\sum_{t=1}^{T_{0}}Y_{n,t}^{(a_{n})}\right)^{T}.\]

Finally, we define quantities such as \(\mathbf{Z}_{n}(a)\), \(\mathbf{X}_{n}(a)\), \(\mathbf{Y}_{n}(a)\) analogously to Section 3. We now turn to bounding our primary quantity of interest in the panel data setting: prediction error for the average expected post-intervention outcome.

**Theorem 5.5** (**Prediction error of average expected post-intervention outcome**).: _Let \(\delta\in(0,1)\) be an arbitrary confidence parameter and \(\rho>0\) be chosen to be sufficiently small, as detailed in Appendix F. Further, assume that Assumptions 5.1 and 5.2 are satisfied, there is some \(n_{0}\geq 1\) such that \(\operatorname{rank}(\mathbf{X}_{n_{0}}(a))=r\), and \(\operatorname{snr}_{n}(a)\geq 2\) for all \(n\geq n_{0}\). If \(T_{0}\leq\frac{1}{2}T\) and \(r\leq\sqrt{T_{0}\wedge n}\), then under Assumption 4.2 with probability at least \(1-O(A\delta)\), simultaneously for all interventions \(a\in\{0,\ldots,A-1\}\)_

\[|\widehat{\mathbb{E}}\bar{Y}_{n,post}^{(a)}-\mathbb{E}\bar{Y}_{n,post}^{(a)}| =\widetilde{O}\left(\frac{L}{\sqrt{T-T_{0}}}+\frac{r}{\sqrt{T_{0} \wedge n}}+\frac{r(L\lor 1)}{\sqrt{(T-T_{0})(T_{0}\wedge n)}}\right)\]

_where \(\widehat{\mathbb{E}}\bar{Y}_{n,post}^{(a)}:=\frac{1}{T-T_{0}}\cdot\langle \widehat{\theta}_{n}(a),Y_{n,pre}\rangle\) is the estimated average post-intervention outcome for unit \(n\) under intervention \(a\)._

A more complicated expression which does not require Assumption 4.2 or \(T_{0}\leq\frac{1}{2}T\) may be found in Appendix G. Observe that \(|\widehat{\mathbb{E}}\bar{Y}_{n,post}^{(a)}-\mathbb{E}\bar{Y}_{n,post}^{(a)}|\to 0\) with high probability as \(T,T_{0},n\to\infty\).

We conclude this section by comparing our results with those of the (non-adaptive) synthetic interventions framework of Agarwal et al. [8]. Since we are regressing over _time_, our method for estimating \(\widehat{\mathbb{E}}\bar{Y}_{n,post}^{(a)}\) is known as a _horizontal_ regression method in the panel data literature. This is in contrast to _vertical_ regression methods, which regress over _units_. See Shen et al. [75] for more details on the similarities and differences between horizontal and vertical regression methods in panel data settings. While we do not exactly match the bound of Agarwal et al. [8] since their synthetic interventions framework of uses a vertical regression method, the two bounds are similar, with the notable differences being as follows: (1) The bound of [8] contains a "slow" \(\widetilde{O}(r^{1/2}T_{0}^{-1/4})\) term which does not appear in our analysis. (2) The non-adaptive SI bound also contains a term which scales as \(\widetilde{O}(\frac{\sqrt{n}}{\sqrt{T-T_{0}}})\) in the worst case, while our bound has no such dependence. However, this comes at the price of slow rate whenever \(L\) is large compared to \(\sqrt{T-T_{0}}\).

## 6 Conclusion

We obtain the first adaptive bounds for principal component regression and apply them to the problem of online experiment design in the context of panel data, where we allow for interventions to be assigned according to an adaptive policy. Exciting directions for future work include applications of our results to domains such as differential privacy, and using our bounds to obtain contextual bandit algorithms (e.g. based on LinUCB [3]) capable of regret minimization when given access to noisy contexts.

## Acknowledgements

KH is supported in part by an NDSEG Fellowship. KH, JW, and ZSW are supported in part by NSF FAI Award #1939606. The authors would like to thank the anonymous NeurIPS reviewers for valuable feedback.

## References

* Abadie and Gardeazabal [2003] Alberto Abadie and Javier Gardeazabal. The economic costs of conflict: A case study of the basque country. _American economic review_, 93(1):113-132, 2003.
* Abadie et al. [2010] Alberto Abadie, Alexis Diamond, and Jens Hainmueller. Synthetic control methods for comparative case studies: Estimating the effect of california's tobacco control program. _Journal of the American statistical Association_, 105(490):493-505, 2010.
* Abbasi-Yadkori et al. [2011] Yasin Abbasi-Yadkori, David Pal, and Csaba Szepesvari. Improved algorithms for linear stochastic bandits. _Advances in neural information processing systems_, 24, 2011.
* Agarwal et al. [2023] Abhineet Agarwal, Anish Agarwal, and Suhas Vijaykumar. Synthetic combinations: A causal inference framework for combinatorial interventions. _arXiv preprint arXiv:2303.14226_, 2023.
* Agarwal and Singh [2021] Anish Agarwal and Rahul Singh. Causal inference with corrupted data: Measurement error, missing values, discretization, and differential privacy. _arXiv preprint arXiv:2107.02780_, 2021.
* Agarwal et al. [2019] Anish Agarwal, Devavrat Shah, Dennis Shen, and Dogyoon Song. On robustness of principal component regression. _Advances in Neural Information Processing Systems_, 32, 2019.
* Agarwal et al. [2020] Anish Agarwal, Devavrat Shah, and Dennis Shen. On principal component regression in a high-dimensional error-in-variables setting. _arXiv preprint arXiv:2010.14449_, 2020.
* Agarwal et al. [2020] Anish Agarwal, Devavrat Shah, and Dennis Shen. Synthetic interventions. _arXiv preprint arXiv:2006.07691_, 2020.
* Agarwal et al. [2021] Anish Agarwal, Munther Dahleh, Devavrat Shah, and Dennis Shen. Causal matrix completion. _arXiv preprint arXiv:2109.15154_, 2021.
* Agarwal et al. [2021] Anish Agarwal, Devavrat Shah, Dennis Shen, and Dogyoon Song. On robustness of principal component regression. _Journal of the American Statistical Association_, 116(536):1731-1745, 2021. doi: 10.1080/01621459.2021.1928513.
* Agarwal et al. [2022] Anish Agarwal, Sarah Cen, Devavrat Shah, and Christina Lee Yu. Network synthetic interventions: A framework for panel data with network interference. _arXiv preprint arXiv:2210.11355_, 2022.
* Agarwal and Chen [2009] Deepak Agarwal and Bee-Chung Chen. Regression-based latent factor models. In _Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining_, pages 19-28, 2009.
* Amjad et al. [2018] Muhammad Jehangir Amjad, Devavrat Shah, and Dennis Shen. Robust synthetic control. _Journal of Machine Learning Research_, 19:1-51, 2018.
* Amjad et al. [2019] Muhammad Amjad, Vishal Mishra, Devavrat Shah, and Dennis Shen. mrsc: Multi-dimensional robust synthetic control. _Proceedings of the ACM on Measurement and Analysis of Computing Systems_, 3(2), 2019.
* Arellano and Honore [2000] Manuel Arellano and Bo Honore. Panel data models: Some recent developments. _Handbook of Econometrics_, 02 2000.
* Arkhangelsky et al. [2020] Dmitry Arkhangelsky, Susan Athey, David A. Hirshberg, Guido W. Imbens, and Stefan Wager. Synthetic difference in differences, 2020.
* Athey et al. [2021] Susan Athey, Mohsen Bayati, Nikolay Doudchenko, Guido Imbens, and Khashayar Khosravi. Matrix completion methods for causal panel data models. _Journal of the American Statistical Association_, 116(536):1716-1730, 2021.
* Bai [2003] Jushan Bai. Inferential theory for factor models of large dimensions. _Econometrica_, 71(1):135-171, 2003. ISSN 00129682, 14680262. URL http://www.jstor.org/stable/3082043.
* Bai [2009] Jushan Bai. Panel data models with interactive fixed effects. _Econometrica_, 77(4):1229-1279, 2009. ISSN 00129682, 14680262. URL http://www.jstor.org/stable/40263859.

* [20] Jushan Bai and Serena Ng. Matrix completion, counterfactuals, and factor analysis of missing data, 2020.
* [21] Jushan Bai and Serena Ng. Matrix completion, counterfactuals, and factor analysis of missing data. _Journal of the American Statistical Association_, 116(536):1746-1763, 2021.
* [22] Eric Bair, Trevor Hastie, Debashis Paul, and Robert Tibshirani. Prediction by supervised principal components. _Journal of the American Statistical Association_, 101(473):119-137, 2006.
* [23] Eli Ben-Michael, Avi Feller, and Jesse Rothstein. The augmented synthetic control method, 2020.
* [24] Aldo Gael Carranza, Sanath Kumar Krishnamurthy, and Susan Athey. Flexible and efficient contextual bandits with heterogeneous treatment effect oracles. In _International Conference on Artificial Intelligence and Statistics_, pages 7190-7212. PMLR, 2023.
* [25] Gary Chamberlain. Panel data. In Z. Griliches\(\dagger\) and M. D. Intriligator, editors, _Handbook of Econometrics_, volume 2, chapter 22, pages 1247-1318. Elsevier, 1 edition, 1984. URL https://EconPapers.repec.org/RePEc:eee:ecochp:2-22.
* [26] Jiafeng Chen. Synthetic control as online linear regression. _Econometrica_, 91(2):465-491, 2023.
* [27] Victor Chernozhukov, Kaspar Wuthrich, and Yinchu Zhu. Practical and robust \(t\)-test based inference for synthetic control and related methods, 2020.
* [28] Andrew Chesher. The effect of measurement error. _Biometrika_, 78(3):451-462, 1991.
* [29] Sayak Ray Chowdhury and Aditya Gopalan. On kernelized multi-armed bandits. In _International Conference on Machine Learning_, pages 844-853. PMLR, 2017.
* [30] Ben Chugg, Hongjian Wang, and Aaditya Ramdas. A unified recipe for deriving (time-uniform) pac-bayes bounds. _arXiv preprint arXiv:2302.03421_, 2023.
* [31] Abhirup Datta and Hui Zou. Cocolasso for high-dimensional error-in-variables regression. 2017.
* [32] Victor H de la Pena, Michael J Klass, and Tze Leung Lai. Self-normalized processes: exponential inequalities, moment bounds and iterated logarithm laws. 2004.
* [33] Victor H de la Pena, Michael J Klass, and Tze Leung Lai. Pseudo-maximization and self-normalized processes. 2007.
* [34] Yash Deshpande, Lester Mackey, Vasilis Syrgkanis, and Matt Taddy. Accurate inference for adaptive linear models. In _International Conference on Machine Learning_, pages 1194-1203. PMLR, 2018.
* [35] N. Doudchenko and G. Imbens. Balancing, regression, difference-in-differences and synthetic control methods: A synthesis. _NBER Working Paper No. 22791_, 2016.
* [36] Walter Enders. _Applied econometric time series_. John Wiley & Sons, 2008.
* [37] Jianqing Fan, Weichen Wang, and Yiqiao Zhong. An \(\ell_{\infty}\) eigenvector perturbation bound and its application to robust covariance estimation. _Journal of Machine Learning Research_, 18(207):1-42, 2018.
* [38] Vivek Farias, Cianac Moallemi, Tianyi Peng, and Andrew Zheng. Synthetically controlled bandits. _arXiv preprint arXiv:2202.07079_, 2022.
* [39] Ivan Fernandez-Val, Hugo Freeman, and Martin Weidner. Low-rank approximations of nonseparable panel models, 2020.
* [40] Jorge I Figueroa-Zuniga, Cristian L Bayes, Victor Leiva, and Shuangzhe Liu. Robust beta regression modeling with errors-in-variables: a bayesian approach and numerical applications. _Statistical Papers_, pages 1-24, 2022.

* Fuller [2009] Wayne A Fuller. _Measurement error models_. John Wiley & Sons, 2009.
* Griliches and Ringstad [1970] Zvi Griliches and Vidar Ringstad. Error-in-the-variables bias in nonlinear contexts. _Econometrica: Journal of the Econometric Society_, pages 368-370, 1970.
* Hadad et al. [2021] Vitor Hadad, David A Hirshberg, Ruohan Zhan, Stefan Wager, and Susan Athey. Confidence intervals for policy evaluation in adaptive experiments. _Proceedings of the national academy of sciences_, 118(15):e2014602118, 2021.
* Hall [2008] Daniel B Hall. Measurement error in nonlinear models: a modern perspective, 2008.
* Harris et al. [2022] Keegan Harris, Anish Agarwal, Chara Podimata, and Zhiwei Steven Wu. Strategyproof decision-making in panel data settings and beyond. _arXiv preprint arXiv:2211.14236_, 2022.
* Harris et al. [2022] Keegan Harris, Dung Daniel T Ngo, Logan Stapleton, Hoda Heidari, and Steven Wu. Strategic instrumental variable regression: Recovering causal relationships from strategic responses. In _International Conference on Machine Learning_, pages 8502-8522. PMLR, 2022.
* Hausman [2001] Jerry Hausman. Mismeasured variables in econometric analysis: problems from the right and problems from the left. _Journal of Economic perspectives_, 15(4):57-67, 2001.
* Hoff [2009] Peter D Hoff. Multiplicative latent factor models for description and prediction of social networks. _Computational and mathematical organization theory_, 15(4):261, 2009.
* Honorio and Jaakkola [2014] Jean Honorio and Tommi Jaakkola. Tight bounds for the expected risk of linear classifiers and pac-bayes finite-sample guarantees. In _Artificial Intelligence and Statistics_, pages 384-392. PMLR, 2014.
* Howard et al. [2020] Steven R Howard, Aaditya Ramdas, Jon McAuliffe, and Jasjeet Sekhon. Time-uniform chernoff bounds via nonnegative supermartingales. 2020.
* Howard et al. [2021] Steven R Howard, Aaditya Ramdas, Jon McAuliffe, and Jasjeet Sekhon. Time-uniform, nonparametric, nonasymptotic confidence sequences. 2021.
* Hsiao et al. [2012] Cheng Hsiao, H. Steve Ching, and Shui Ki Wan. A panel data approach for program evaluation: Measuring the benefits of political and economic integration of hong kong with mainland china. _Journal of Applied Econometrics_, 27(5):705-740, 2012. doi: https://doi.org/10.1002/jae.1230.
* Jenatton et al. [2012] Rodolphe Jenatton, Nicolas Roux, Antoine Bordes, and Guillaume R Obozinski. A latent factor model for highly multi-relational data. _Advances in neural information processing systems_, 25, 2012.
* Jolliffe [1982] Ian T Jolliffe. A note on the use of principal components in regression. _Journal of the Royal Statistical Society Series C: Applied Statistics_, 31(3):300-303, 1982.
* Kalai and Vempala [2005] Adam Kalai and Santosh Vempala. Efficient algorithms for online decision problems. _Journal of Computer and System Sciences_, 71(3):291-307, 2005.
* Kaul and Koul [2015] Abhishek Kaul and Hira L Koul. Weighted l1-penalized corrected quantile regression for high dimensional measurement error models. _Journal of Multivariate Analysis_, 140:72-91, 2015.
* Kim et al. [1990] In-Won Kim, Michael J Liebman, and Thomas F Edgar. Robust error-in-variables estimation using nonlinear programming techniques. _AIChE Journal_, 36(7):985-993, 1990.
* Lattimore and Szepesvari [2020] Tor Lattimore and Csaba Szepesvari. _Bandit algorithms_. Cambridge University Press, 2020.
* Li [2018] Kathleen T. Li. Inference for factor model based average treatment effects. _Available at SSRN 3112775_, 2018.
* 75, 2017. ISSN 0304-4076. doi: https://doi.org/10.1016/j.jeconom.2016.01.011.
* Liang and Zeger [1986] Kung-Yee Liang and Scott L. Zeger. Longitudinal data analysis using generalized linear models. _Biometrika_, 73(1):13-22, 04 1986. ISSN 0006-3444. doi: 10.1093/biomet/73.1.13. URL https://doi.org/10.1093/biomet/73.1.13.

* Loh and Wainwright [2011] Po-Ling Loh and Martin J Wainwright. High-dimensional regression with noisy and missing data: Provable guarantees with non-convexity. _Advances in neural information processing systems_, 24, 2011.
* Manole and Ramdas [2023] Tudor Manole and Aaditya Ramdas. Martingale methods for sequential estimation of convex functionals and divergences. _IEEE Transactions on Information Theory_, 2023.
* Moon and Weidner [2015] Hyungsik Roger Moon and Martin Weidner. Linear regression for panel with unknown number of factors as interactive fixed effects. _Econometrica_, 83(4):1543-1579, 2015. ISSN 00129682, 14680262. URL http://www.jstor.org/stable/43616977.
* Moon and Weidner [2017] Hyungsik Roger Moon and Martin Weidner. Dynamic linear panel regression models with interactive fixed effects. _Econometric Theory_, 33(1):158-195, 2017. doi: 10.1017/S0266466615000328.
* Ngo et al. [2023] Daniel Ngo, Keegan Harris, Anish Agarwal, Vasilis Syrgkanis, and Zhiwei Steven Wu. Incentive-aware synthetic control: Accurate counterfactual estimation via incentivized exploration. 2023.
* Nie et al. [2018] Xinkun Nie, Xiaoying Tian, Jonathan Taylor, and James Zou. Why adaptively collected data have negative bias and how to correct for it. In _International Conference on Artificial Intelligence and Statistics_, pages 1261-1269. PMLR, 2018.
* Pesaran [2006] M. Hashem Pesaran. Estimation and inference in large heterogeneous panels with a multifactor error structure. _Econometrica_, 74(4):967-1012, 2006. ISSN 00129682, 14680262. URL http://www.jstor.org/stable/3805914.
* Qin and Russo [2022] Chao Qin and Daniel Russo. Adaptivity and confounding in multi-armed bandit experiments. _arXiv preprint arXiv:2202.09036_, 2022.
* Reilly and Patino-Lea1 [1981] Park M Reilly and Hugo Patino-Lea1. A bayesian study of the error-in-variables model. _Technometrics_, 23(3):221-231, 1981.
* Roman et al. [2005] Steven Roman, S Axler, and FW Gehring. _Advanced linear algebra_, volume 3. Springer, 2005.
* Rosenbaum and Tsybakov [2010] Mathieu Rosenbaum and Alexandre B Tsybakov. Sparse recovery under matrix uncertainty. _The Annals of Statistics_, pages 2620-2651, 2010.
* Rudelson and Vershynin [2013] Mark Rudelson and Roman Vershynin. Hanson-wright inequality and sub-gaussian concentration. 2013.
* Settles [2009] Burr Settles. Active learning literature survey. 2009.
* Shen et al. [2022] Dennis Shen, Peng Ding, Jasjeet Sekhon, and Bin Yu. A tale of two panel data regressions. _arXiv preprint arXiv:2207.14481_, 2022.
* Shumway et al. [2000] Robert H Shumway, David S Stoffer, and David S Stoffer. _Time series analysis and its applications_, volume 3. Springer, 2000.
* Simchi-Levi and Wang [2023] David Simchi-Levi and Chonghuan Wang. Multi-armed bandit experimental design: Online decision-making and adaptive inference. In _International Conference on Artificial Intelligence and Statistics_, pages 3086-3097. PMLR, 2023.
* Slivkins et al. [2019] Aleksandrs Slivkins et al. Introduction to multi-armed bandits. _Foundations and Trends(r) in Machine Learning_, 12(1-2):1-286, 2019.
* Squires et al. [2022] Chandler Squires, Dennis Shen, Anish Agarwal, Devavrat Shah, and Caroline Uhler. Causal imputation via synthetic interventions. In _Conference on Causal Learning and Reasoning_, pages 688-711. PMLR, 2022.
* Tropp et al. [2015] Joel A Tropp et al. An introduction to matrix concentration inequalities. _Foundations and Trends(r) in Machine Learning_, 8(1-2):1-230, 2015.
* Ungarala and Bakshi [2000] Sridhar Ungarala and Bhavik R Bakshi. A multiscale, bayesian and error-in-variables approach for linear dynamic data rectification. _Computers & Chemical Engineering_, 24(2-7):445-451, 2000.

* [82] Roman Vershynin. _High-dimensional probability: An introduction with applications in data science_, volume 47. Cambridge university press, 2018.
* [83] Martin J Wainwright. _High-dimensional statistics: A non-asymptotic viewpoint_, volume 48. Cambridge university press, 2019.
* [84] Tom Wansbeek and Erik Meijer. Measurement error and latent variables. _A companion to theoretical econometrics_, pages 162-179, 2001.
* [85] Justin Whitehouse, Aaditya Ramdas, Steven Z Wu, and Ryan M Rogers. Brownian noise reduction: Maximizing privacy subject to accuracy constraints. _Advances in Neural Information Processing Systems_, 35:11217-11228, 2022.
* [86] Justin Whitehouse, Aaditya Ramdas, Ryan Rogers, and Steven Wu. Fully-adaptive composition in differential privacy. In _International Conference on Machine Learning_, pages 36990-37007. PMLR, 2023.
* [87] Justin Whitehouse, Zhiwei Steven Wu, and Aaditya Ramdas. On the sublinear regret of GP-UCB. _Advances in Neural Information Processing Systems_, 2023.
* [88] Justin Whitehouse, Zhiwei Steven Wu, and Aaditya Ramdas. Time-uniform self-normalized concentration for vector-valued processes. _arXiv preprint arXiv:2310.09100_, 2023.
* [89] Yiqing Xu. Generalized synthetic control method: Causal inference with interactive fixed effects models. _Political Analysis_, 25(1):57-76, 2017. doi: 10.1017/pan.2016.2.
* [90] Jingwen Zhang, Yifang Chen, and Amandeep Singh. Causal bandits: Online decision-making in endogenous settings. _arXiv preprint arXiv:2211.08649_, 2022.
* [91] Kelly Zhang, Lucas Janson, and Susan Murphy. Statistical inference with m-estimators on adaptively collected data. _Advances in neural information processing systems_, 34:7460-7471, 2021.
* [92] Kelly W Zhang, Lucas Janson, and Susan A Murphy. Statistical inference after adaptive sampling in non-markovian environments. _arXiv preprint arXiv:2202.07098_, 2022.