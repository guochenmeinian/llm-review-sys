[MISSING_PAGE_EMPTY:1]

recovering CT images from metal-affect measurements is a complicated _nonlinear inverse problem_. However, linear inverse problem algorithms, _e.g._, filtered back projection (FBP) [3], always lead to severe artifacts in the resulting CT images. These artifacts can greatly hamper the accuracy of clinical diagnosis and treatment planning.

Many efforts have been made for CT metal artifact reduction (MAR) task [4]. Most studies [5; 6; 7; 8; 9; 10; 11; 12] simplify this task as a linear inverse problem by designing various schemes to replace metal-affected extreme value signals (_i.e._, metal traces) in the measurements, which unfortunately results in significant degradation of the CT reconstruction due to the signal loss. Currently, supervised deep learning (DL) approaches [7; 8; 13; 14; 15; 16; 17; 6] are the mainstream MAR solutions. Supervised methods typically tend to learn mappings from metal-corrupted measurements to artifact-free CT images by training deep neural networks on a large-scale external dataset. However, related works face two main limitations. First, collecting numerous paired metal-corrupted measurements and high-quality CT images for training is resource-intensive and laborious. Second, if the metal shapes and the CT acquisition settings differ from those in the training dataset, performance may significantly decline. These challenges significantly limit the practical application of supervised MAR methods in clinical scenarios.

Implicit neural representation (INR) is a new paradigm to solve inverse problems [18]. It uses a multi-layer perception (MLP) to model an underlying signal by mapping coordinates to signal responses. The learning bias of the MLPs towards low-frequency signal components [19; 20] is considered as an implicit regularization term for the inverse problems. By approximately simulating the CT acquisition forward model as a linear integral, INR has achieved significant progress in the linear sparse-view CT reconstruction [21; 22; 23; 24; 25; 26]. However, its potential for tackling the nonlinear inverse problem, such as the MAR task, remains unexplored.

In this work, we aim to address the issue of MAR in CT scans from a nonlinear perspective. This allows us to use the complete measurement signals (_i.e._, including metal traces) and thus achieve better CT reconstruction performance. Specifically, we model the MAR as a polychromatic (_i.e._, multiple X-ray spectral energy levels) reconstruction task of CT image. This task is a highly ill-posed nonlinear inverse problem. To address this, we propose **Poly**chromatic **n**eural **r**epresentation (**Polyner**), a novel extension of INR for the nonlinear problems. In our Polymer, we make three key designs. First, we derive a forward model that accurately simulates the polychromatic nonlinear CT acquisition process. Second, we define a regularization term that effectively constrains the solution space by preserving the physical properties of the CT images across different spectral energy levels. Third, we incorporate our forward model into the INR, granting its capacity to solve the nonlinear inverse problem. Meanwhile, the continuous prior brought by INR also contributes to a more stable solution. Our Polymer is an unsupervised method and does not require any external training data, which makes it potentially applicable to a wide range of CT imaging scenarios.

We evaluate the performance of our Polymer on three datasets, including two simulation datasets and one real-world collected dataset. The experimental results demonstrate that our Polymer performs comparably to the supervised DL method on in-domain datasets, while significantly outperforming them on out-of-domain datasets. We also conduct extensive ablation studies for several key designs of our method, verifying their effectiveness. _To the best of our knowledge, our Polymer is the first unsupervised MAR method superior to its supervised counterparts_.

The main contributions of this work can be summarised as follows: (1) We propose Polymer, an unsupervised polychromatic neural representation, that can recover high-quality CT images from metal-corrupted measurements without the need for any extra data. (2) We introduce a new model perspective for the CT MAR problem, _i.e._, recovering polychromatic CT images to mitigate the nonlinear metal effect and thus achieving effective MAR. (3) We technically incorporate a polychromatic CT forward model into the INR, enabling the reconstruction of polychromatic CT images.

## 2 Preliminaries & Related Work

In this section, we first theoretically present the nonlinear metal effect during the CT acquisition process (Sec. SS2.1). Then, we provide a brief overview of the literature on the metal artifacts reduction approaches (Sec. SS2.2) and implicit neural representations for CT reconstruction (Sec. SS2.3).

### Nonlinear Metal Effect in CT Measurements

The physical interaction of X-rays passing through an object is governed by Lambert-Beer's law [27; 28], which can be expressed as follows:

\[I(\mathbf{r},E_{0})=I_{0}(E_{0})\cdot\exp\left(-\int_{\mathbf{r}}\mu_{E_{0}}( \mathbf{x})\mathrm{d}\mathbf{x}\right),\] (1)

where \(\mathbf{r}\) denotes a monochromatic X-ray, \(E_{0}\) is its energy level, \(I_{0}(E_{0})\) is the number of photons emitted by an X-ray source, \(I(\mathbf{r},E_{0})\) is the number of photons received by an X-ray detector, and \(\mu_{E_{0}}(\mathbf{x})\) is the linear attenuation coefficient (LAC) of the observed object at the position \(\mathbf{x}\). The LACs serve as a measure of the object's ability to absorb the X-rays, with higher values indicating greater absorption ability.

In practice, X-rays often are polychromatic due to limitations in the X-ray source [2; 29]. Consider a polychromatic X-ray composed of multiple monochromatic X-rays belonging to an energy level range \(\mathcal{E}\), by combining Eq. (1), the CT measurement data \(p(\mathbf{r})\) thus can be written as below:

\[\begin{split} p(\mathbf{r})&=-\ln\frac{\int_{ \mathcal{E}}I(\mathbf{r},E)\mathrm{d}E}{\int_{\mathcal{E}}I_{0}(E)\mathrm{d}E }\\ &=-\ln\int_{\mathcal{E}}\eta(E)\cdot\exp\left(-\int_{\mathbf{r}} \mu_{E}(\mathbf{x})\mathrm{d}\mathbf{x}\right)\mathrm{d}E,\ \ \text{with}\ \ \eta(E)=\frac{I_{0}(E)}{\int_{\mathcal{E}}I_{0}(E^{\prime})\mathrm{d}E^{\prime}},\end{split}\] (2)

where \(\eta(E)\) is the normalized energy spectrum that characterizes the distribution of the number of photons \(I_{0}(E)\) emitted by the X-ray source over the energy level \(E\).

CT reconstruction refers to solve the LACs \(\mu\) from the measurement data \(p\). It is widely recognized that the LACs of human body tissues exhibit slow decreases with increasing the X-ray's energy level, while those of metals undergo sharp variations as a function of energy level [2; 7; 8; 30]. Therefore, a usual assumption for the human body is that \(|\mu_{E_{a}}(\mathbf{x})-\mu_{E_{b}}(\mathbf{x})|\approx 0,\ \forall E_{a},E_{b} \in\mathcal{E}\), _i.e._, the LACs of the human body are considered as energy-independent.

Based on this assumption, we can represent the underlying LACs of a human body with metallic implants as follows:

\[\mu_{E}(\mathbf{x})=\mathcal{M}(\mathbf{x})\cdot\mu_{E}^{\star}(\mathbf{x})+ [1-\mathcal{M}(\mathbf{x})]\cdot\mu(\mathbf{x}),\] (3)

where \(\mu_{E}^{\star}(\mathbf{x})\) and \(\mu(\mathbf{x})\) denote the LACs of the metal and human body, respectively. \(\mathcal{M}\) is a metal binary mask (\(\mathcal{M}=1\) for the metal region and \(\mathcal{M}=0\) otherwise).

By combining Eq. (2), its CT measurement data can be derived as:

\[\begin{split} p(\mathbf{r})&=-\ln\int_{\mathcal{E} }\eta(E)\cdot\exp\left(-\int_{\mathbf{r}}\mathcal{M}(\mathbf{x})\cdot\mu_{E}^ {\star}(\mathbf{x})+[1-\mathcal{M}(\mathbf{x})]\cdot\mu(\mathbf{x})\mathrm{d} \mathbf{x}\right)\mathrm{d}E\\ &=\underbrace{-\ln\int_{\mathcal{E}}\eta(E)\cdot\exp\left(-\int_ {\mathbf{r}}\mathcal{M}(\mathbf{x})\cdot\mu_{E}^{\star}(\mathbf{x})\mathrm{d} \mathbf{x}\right)\mathrm{d}E}_{\text{Nonlinear Metal Effect}}+\underbrace{ \int_{\mathbf{r}}[1-\mathcal{M}(\mathbf{x})]\cdot\mu(\mathbf{x})\mathrm{d} \mathbf{x}}_{\text{Linear Integral}}.\end{split}\] (4)

This implies that the CT measurement of a human body with metallic implants can be divided into two parts: (1) a linear integral transformation for the human body and (2) a nonlinear transformation for the metallic implants. The latter is also known as the _nonlinear metal effect_ in CT measurements. Therefore, using standard reconstruction techniques, such as FBP [3], which are designed for linear inverse problems, will result in severe metal artifacts in the reconstructed CT image.

### CT Metal Artifact Reduction Approaches

Classical model-based algorithms [10; 11; 12] formulate the MAR as an image inpainting task. The metal traces in the measurements are treated as missing and completed by interpolation. However, these model-based methods often produce severe secondary artifacts since the interpolation algorithms ignore the CT physical geometry constraints. With the great success of deep neural networks in low-level vision tasks [31; 32], numerous supervised DL methods have been proposed [7; 8; 13; 14; 6; 15; 17; 16]. For example, Lin _et al_. [8] proposed a dual domain network (DuDoNet) tosimultaneously complete the measurements and enhance the CT images. Wang _et al_. [13] presented an adaptive convolutional dictionary network (ACDNet), incorporating prior knowledge of metal artifacts into a deep network. These supervised methods achieve state-of-the-art (SOTA) MAR performance due to their well-designed network architectures and data-driven priors. However, they require a large-scale training dataset for supervised learning and often suffer from out-of-domain (OOD) problems [9; 30], severely limiting their usefulness in real-world scenarios. In contrast, our Polyner is a fully unsupervised method that does not require any external training data. Moreover, both model-based and supervised DL methods often treat metal traces as missing data, which severely hinders the restoration of image details near metals. Our method decomposes the CT measurement with polychromatic LACs at different energy levels as in Eq. (2), and directly utilizes the complete measurement as input data, which avoids signal loss of the metal traces and thus achieves a better MAR performance.

### Implicit Neural Representation for CT Reconstruction

Implicit neural representation (INR) is a novel paradigm to continuously parameterize a variety of signals. INR represents an underlying signal as a continuous function that maps spatial positions to signal responses and uses an MLP network to approximate the complex function. Due to the learning bias of the MLP networks to low-frequency signals [19; 20], INR can be used for various vision inverse problems, _e.g_., view synthesis [33; 34], and surface reconstruction [35; 36]. Recently, many INR-based approaches [22; 23; 24; 25; 37; 21; 38; 39; 40; 26; 41] have been emerged for CT reconstruction. There are two key designs in these methods: (1) representing the unsolved object as a function that maps spatial coordinates to its corresponding monochromatic LACs at a single energy level, and (2) combining line integral transformation with an MLP network to approximate the function. They have shown excellent CT reconstruction performance benefiting from implicit priors by INR. However, these methods fail to handle the nonlinear CT MAR task because they strictly suppose the unsolved LACs are monochromatic, _i.e_., energy-independent, leading to the nonlinear metal effect being ignored. In contrast, our method leverages a polychromatic forward model to accurately describe the formation of the metal effect and thus enables an effective MAR.

## 3 Proposed Method

In this section, we propose our Polyner model. We first introduce our modeling for the CT MAR problem (Sec. SS3.1). Next, we present a polychromatic CT forward model for simulating the CT acquisition process (Sec. SS3.2). Moreover, we define the loss function to optimize our Polyner (Sec. SS3.3). Finally, we provide the pipeline to recover the reconstruction results (Sec. SS3.4). An overview of the proposed Polyner model is shown in Fig. 1.

### Problem Formulation

The LACs of metals to X-rays vary significantly with the spectral energy level of the X-ray, resulting in metal-affect extreme signal values in the measurement data (_i.e_., nonlinear metal effect discussed in

Figure 1: Overview of the proposed Polyner model. Firstly, we sample coordinates \(\mathbf{x}\) along an X-ray \(\mathbf{r}\). Then, we feed these coordinates into an MLP to predict the corresponding LACs \(\mathbf{v}(\mathbf{x})=\{\mu_{1}(\mathbf{x}),\cdots,\mu_{N}(\mathbf{x})\}\) at \(N\) energy levels. Thirdly, we leverage a differentiable polychromatic CT forward model to transform the predicted LACs into CT measurements \(\hat{p}(\mathbf{r})\). Finally, we optimize the MLP by minimizing the loss between the predicted and real CT measurements.

Sec. SS2.1). Recovering the underlying CT image from such measurement is a complicated nonlinear inverse problem. Existing MAR approaches [5; 6; 7; 8; 9; 10; 11; 12] mostly formulated it as a linear inverse problem by removing the metal-affected parts in the measurement.

Instead, we aim to address the MAR problem from a nonlinear perspective. We suppose that the polychromatic X-rays in the CT acquisition can be decomposed into monochromatic X-rays at \(N\) discrete energy levels. Then, we propose to reconstruct the polychromatic CT images at each of the \(N\) energy levels (_i.e._, a total number of \(N\) LAC-maps at each monochromatic X-ray for the observed object). This reconstruction task is nonlinear and is independent to the nonlinear metal effect. Hence, the MAR task is modeled as a reconstruction problem of the polychromatic CT images.

To accomplish the reconstruction, we represent the underlying object as a continuous function of spatial coordinate, which can expressed as below:

\[f:\mathbf{x}=(x,y)\in\mathbb{R}^{2}\longrightarrow\mathbf{v}(\mathbf{x})=\{ \mu_{1}(\mathbf{x}),\cdots,\mu_{i}(\mathbf{x}),\cdots,\mu_{N}(\mathbf{x})\} \in\mathbb{R}^{N},\] (5)

where \(\mathbf{x}\) denotes any spatial coordinate and \(\mathbf{v}(\mathbf{x})\) is the polychromatic CT image value at that position. Here the item \(\mu_{i}(\mathbf{x})\) is the LAC of the object to the monochromatic X-ray at energy level \(E_{i}\).

However, the function \(f\) is very complicated and intractable. Hence, we leverage an MLP network \(\mathcal{F}_{\mathbf{\Phi}}\) (here \(\mathbf{\Phi}\) denotes trainable weights) to approximate it. In other words, we learn a neural representation of the function \(f\). The artifacts-free CT images can be reconstructed by feeding all the spatial coordinates into the well-optimized MLP network \(\mathcal{F}_{\mathbf{\Phi}}\).

### Polychromatic CT Forward Model

To learn the function \(f\), we optimize the MLP network's trainable weights \(\mathbf{\Phi}\) to map any spatial coordinate \(\mathbf{x}\) in space into its corresponding polychromatic LACs \(\mathbf{v}(\mathbf{x})\). Therefore, a _differentiable_ forward model is required for transforming the LACs predicted by the MLP network \(\mathcal{F}_{\mathbf{\Phi}}\) into the CT measurements while also allowing the back-propagation of gradients from the measurement domain to the image domain.

We derive a polychromatic forward model for X-ray CT systems in Eq. (2). This forward model can accurately describe the complicated nonlinear CT acquisition process. Our Polymer employs its discrete form to transform the MLP-predicted polychromatic LACs \(\mathbf{v}(\mathbf{x})\) into the measurement data \(\hat{p}\). Fig. 1 illustrates its pipeline. For the LACs \(\mu_{i}\) at the energy level \(E_{i}\), we first generate its projection value \(\hat{p}_{i}(\mathbf{r})\) along the X-ray \(\mathbf{r}\) using a linear summation operator. We then leverage the normalized energy spectrum \(\eta(E_{i})\) to weight the sum of \(\hat{p}_{i}(\mathbf{r})\) and produce the final measurement data \(\hat{p}(\mathbf{r})\). Formally, the polychromatic CT forward model can be expressed as follows:

\[\hat{p}(\mathbf{r})=-\ln\sum_{i=1}^{N}\eta(E_{i})\cdot\exp\left\{-\hat{p}_{i} (\mathbf{r})\right\},\ \ \text{with}\ \ \hat{p}_{i}(\mathbf{r})=\sum_{\mathbf{x}\in\mathbf{r}}\mu_{i}(\mathbf{x}) \cdot\Delta\mathbf{x},\] (6)

where \(\Delta\mathbf{x}\) represents the distance between adjacent sampled coordinates along the X-ray \(\mathbf{r}\). It is set as the physical resolution (_i.e._, voxel size) of the reconstructed CT image. Here, the normalized energy spectrum \(\eta\in\mathbb{R}^{N}\) is considered as a known prior knowledge. In our experiments, we leverage SPEKTR toolkit developed by Punnoose _et al_. [42] to estimate it.

### Loss Function

**Data Consistency Loss.** We first compute a data consistency (DC) loss that measures the distance between the predicted and measured measurements. The DC loss is implemented by \(\ell_{1}\) norm, which can be written as below:

\[\mathcal{L}_{\text{DC}}=\frac{1}{|\mathcal{R}|}\sum_{\mathbf{r}\in\mathcal{R }}\|p(\mathbf{r})-\hat{p}(\mathbf{r})\|_{1},\] (7)

where \(\mathcal{R}\) denotes a set of the sampling X-rays \(\mathbf{r}\) at each training iteration.

**Energy-dependent Smooth Loss.** As discussed in Sec. SS2.1, the LACs of the human body tissues to X-rays exhibit smooth changes with increasing the energy level of the X-rays [7; 8; 30]. We thus propose an energy-dependent smooth (EDS) loss to preserve this physical property. Specifically, for the human body, the proposed EDS loss enforces a regularization that constrains the changes between the LACs at any adjacent energy levels to be smooth. We implement this regularization using the norm of the gradient along the energy spectrum. It is approximated by the sum of the absolute error between the predicted LACs at any adjacent X-ray energy levels. Mathematically, the EDS loss can be written as follows:

\[\begin{split}\mathcal{L}_{\text{EDS}}&=\frac{1}{| \mathcal{R}|\cdot|\mathbf{r}|}\sum_{\mathbf{r}\in\mathcal{R}}\sum_{\mathbf{x} \in\mathbf{r}}[1-\mathcal{M}(\mathbf{x})]\cdot\|\nabla_{E}\mathbf{v}(\mathbf{ x})\|_{1}\\ &=\frac{1}{|\mathcal{R}|\cdot|\mathbf{r}|}\sum_{\mathbf{r}\in \mathcal{R}}\sum_{\mathbf{x}\in\mathbf{r}}[1-\mathcal{M}(\mathbf{x})]\cdot \sum_{i=2}^{N}|\mu_{i-1}(\mathbf{x})-\mu_{i}(\mathbf{x})|,\end{split}\] (8)

where \(\mathcal{M}\) is a metal binary mask (\(\mathcal{M}=1\) for the metal region and \(\mathcal{M}=0\) otherwise).

In summary, our total loss function is defined as below:

\[\mathcal{L}=\mathcal{L}_{\text{DC}}+\lambda\cdot\mathcal{L}_{\text{EDS}},\] (9)

where \(\lambda\geq 0\) is a hyper-parameter that controls the contribution of the EDS regularization \(\mathcal{L}_{\text{EDS}}\).

### Reconstruction of Artifact-free CT Image

Once the optimization is completed, the MLP network \(\mathcal{F}_{\Phi}\) is able to predict the polychromatic LACs \(\mathbf{v}(\mathbf{x})=\{\mu_{1}(\mathbf{x}),\cdots,\mu_{i}(\mathbf{x}), \cdots,\mu_{N}(\mathbf{x})\}\) at \(N\) energy levels for any input spatial coordinate \(\mathbf{x}\), meaning the polychromatic CT images can be reconstructed. Given a polychromatic X-ray that consists of multiple monochromatic X-rays at \(N\) energy levels, its equivalent monochromatic X-ray's energy can be approximated by \(\bar{E}=\frac{1}{N}\sum_{i=1}^{N}E_{i}\). In this work, we aim to solve the CT MAR problem. Thus, we employ the LACs \(\mu_{\bar{E}}\) at the energy level \(\bar{E}\) as our final reconstructed image.

## 4 Experiments

In this section, we aim to answer two key questions: (1) Can our unsupervised Polymer compete with supervised DL MAR techniques for the in-domain and out-of-domain datasets? (2) What is the impact of the key components in our Polymer on the model performance? To study these questions, we conduct comprehensive experiments on three datasets. We provide additional experiment details and results in the supplementary material.

### Experimental Settings

**Datasets.** We conduct experiments on four datasets, including two simulation datasets and two real collected datasets. The first dataset is DeepLesion [43], the most commonly used dataset for the CT MAR evaluation. For this dataset, we extract 200 2D slices of 256\(\times\)256 size from the original 3D CT volumes as ground truth (GT). Then, we follow the pipeline described in [30; 7; 8] to synthesize metal-corrupted sinograms as input data. The second dataset is the XCOM dataset [44], for which we employ two cases provided by Zhang et al. [7]. The third is a real-world dataset. As shown in Fig. 3 (_Left_), we insert a metal paper clip into a walnut sample and scan it with a commercial Bruker SKYSCAN 1276 micro-CT scanner. The fourth is also a real-world dataset. We use the same micro-CT scanner to scan a mouse tight containing a metal intramedullary needle. _Note that all data solely are utilized for testing purposes since our method is fully unsupervised._

**Baselines & Metrics.** We employ nine representative CT MAR approaches from three categories as baselines: (1) four model-based algorithms (FBP [3], LI [10], NMAR [11], and ART [45]); (2) three supervised CNN-based DL methods (CNN-MAR [7], DICDNet [14], and ACDNet [13]); and (3) two unsupervised DL method (ADN [30] and Score-MAR [9]). _To ensure a fair comparison, we evaluate the five DL models using the checkpoints provided by the authors._ Among them, CNN-MAR [7] and Score-MAR [9] are respectively trained on the XCOM [44] and LIDC [46] datasets, while the other three methods are trained on the DeepLesion dataset [43]. We use peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM) to quantitatively evaluate the MAR performance.

**Implementation Details.** For our Polymer, we leverage hash encoding [47] in combination with two fully connected (FC) layers of width 128 to implement the MLP network. A ReLU activation function is then applied after the first FC layer. For the hash encoding [47], we configure its hyper-parameters as follow: \(L=16\), \(T=2^{19}\), \(F=8\), \(N_{\text{min}}=2\), and \(b=2\). To optimize the network, we randomly 

[MISSING_PAGE_EMPTY:7]

that of the model-based NMAR [11] algorithm, with -3.98 dB and -3.59 dB in PSNR, respectively. In contrast, our Polymer obtains the best performance, slightly outperforming CNN-MAR trained on the XCOM dataset [44] by +0.22 dB in PSNR. Fig. 2 shows the qualitative results. Notably, three model-based algorithms (FBP [3], LI [10], and NMAR [11]) and two unsupervised methods (ADN [30] and Score-MAR [9]) cannot yield satisfactory results, exhibiting severe artifacts on both datasets. Conversely, while DICDNet [14] and ACDNet for the DeepLesion dataset [43] yield excellent MAR performances, their results on the XCOM dataset [44] include severe artifacts. This contrasts with CNN-MAR [7], which achieves superior results for the XCOM dataset [44] but not for the DeepLesion dataset [43]. These visual inspections are consistent with the above quantitative comparisons. Remarkably, our proposed Polymer presents clean and fine-detail CT reconstructions for both datasets, indicating its robustness and superiority over existing MAR methods. _More visual results can be found in the supplementary material._

**Comparison on Real Data.** Though our Polymer model performs best on the two simulation datasets, it is important to study its performance on real collected CT data. To achieve this, we insert a metal paper clip into a walnut sample and then scan it with a commercial Bruker SKYSCAN 1276 micro-CT, as shown in Fig 3 (_Left_). We compare five baselines with our Polymer for reconstructing a 2D slice of the sample. The remaining three baselines (NMAR [11], CNN-MAR [7], and ADN [30]) are not compared because they require prior knowledge of water-bone segmentation, which is invalid for the walnut sample. Fig. 3 (_Right_) demonstrates the qualitative results. FBP [3] performs the worst, producing severe shadow artifacts. LI [10] exhibits local deformations in the reconstructed images. Score-MAR [9] almost fails due to the domain shift problem. ACDNet [13] is not effective in completely removing these shadow artifacts, it instead produces an offset in image contrast. In comparison, our Polymer recovers the best visual results in both image details and contrast. We also present the quantitative results in Fig. 3. The proposed Polymer achieves the best performance in two metrics. However, it is worth noting that the quantitative performances of all methods are relatively low (the best PSNR of 22 dB by our Polymer) since the reference CT image cannot be considered GT due to the non-negligible non-rigid deformation caused by the metal paper clip insertion. _In addition, we compare our Polymer with FDK algorithm [49] on the real mouse tight sample scanned by a 3D cone-beam CT geometry. Related results are provided in the supplementary material._

### Ablation Studies

**Influence of Polychromatic CT Forward Model.** We explore the efficiency of the polychromatic CT forward model in our Polymer. To this end, we replace it with the linear integral transformation as in [21; 22; 23; 24; 25; 26]. Other model configurations are kept the same for a fair comparison. Fig. 4 demonstrates the qualitative results. From the visualization, it is clear that without the forward model, our Polymer almost fails to handle the shadow artifacts caused by the nonlinear metal effect. In comparison, our full model with the forward model produces a clean CT image that is very close

Figure 3: (_Left_) A Bruker SKYSCAN 1276 micro-CT scanner and a walnut sample with a metal paper clip. (_Right_) Qualitative results of the compared methods on the walnut sample data. The red regions denote metals.

to the GT image. We present the quantitative results in Table 2. The results indicate that it contributes to an essential improvement of +3.92 dB in PSNR.

**Influence of Energy-dependent Smooth Loss.** We investigate the influence of the EDS loss on the model performance. To this end, we set different weights \(\lambda\in\{0,0.1,0.2,0.3,0.4\}\) for the EDS loss in Eq. (9). We show the quantitative results in Table 3. The model performance initially improves with an increasing contribution of the EDS loss but later slightly degrades if its contribution keeps increasing. The best performance is obtained at \(\lambda=0.2\). This is because the absence of the EDS loss cannot ensure the smooth changes of the LACs of the body over energy levels. However, excessive bias towards it can result in the forward model degrading as a linear integral transformation, where the polychromatic LACs across all energy levels are identical. Fig. 5 shows the qualitative results. We observe that the CT images at different energy levels randomly change when the EDS loss is not used. In contrast, the regularization can effectively ensure the changes in the LACs are smooth. Moreover, the LACs slowly decrease as the X-ray energy level increases, which is generally consistent with the experimental findings reported in previous works [50].

**Influence of Number of Energy Levels.** We investigate how the number of discrete energy levels \(N\) affects the model performance. We set the energy range to \([20,120]\) and uniformly sample the \(N=\{50,76,86,101\}\) energy levels from the range. We also resample the normalized energy spectrum \(\eta\in\mathbb{R}^{N}\) to match these levels. Table 4 shows the quantitative results, which indicate that increasing the energy resolution improves the MAR performance. We present the qualitative results in Fig. 6, which show that our Polymer with a higher energy resolution (\(N=101\)) produces better CT results in terms of both image details and contrast. Our method approximates polychromatic X-rays with discrete energy levels, introducing an approximation error. Therefore, improving the energy's resolution may help to reduce this error and improve the model performance.

## 5 Conclusion & Limitation

We present Polymer, a novel method for the nonlinear MAR problem. The proposed Polymer follows the unsupervised learning paradigm and does not require any external training data, which greatly makes it useful in clinical scenarios. Our Polymer learns a neural representation of polychromatic

\begin{table}
\begin{tabular}{c c} \hline \hline Module & PSNR \\ \hline w/o Poly. CT & 32.95\(\pm\)4.31 \\ w/ Poly. CT & **36.87\(\pm\)1.56** \\ \hline \hline \end{tabular}
\end{table}
Table 2: Quantitative results of our Polymer ablating the polychromatic CT forward model on the DeepLesion dataset [43]. The red regions denote metals.

Figure 4: Qualitative results of our Polymer ablating the polychromatic CT forward model on a sample (#6) of the DeepLesion dataset [43]. The red regions denote metals.

\begin{table}
\begin{tabular}{l c} \hline \hline Parameter & PSNR \\ \hline \(\lambda=0\) & 22.71\(\pm\)4.97 \\ \(\lambda=0.1\) & 33.75\(\pm\)2.30 \\ \(\lambda=0.2\) & **36.87\(\pm\)1.56** \\ \(\lambda=0.3\) & 36.83\(\pm\)1.52 \\ \(\lambda=0.4\) & 36.39\(\pm\)1.79 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Quantitative results of our Polymer model over the EDS loss \(\mathcal{L}_{\text{EDS}}\) on the DeepLesion [43] dataset.

Figure 5: Qualitative comparison of the CT images at different energy levels using our Polymer model without (_Top Row_) and with (_Bottom Row_) the EDS loss \(\mathcal{L}_{\text{EDS}}\) on a sample (#4) of the DeepLesion dataset [43]. The red regions denote metals.

CT images to fundamentally avoid the nonlinear metal effect causing metal artifacts. It thus can reconstruct clean CT images from metal-affect measurements. Extensive experiments on three CT datasets demonstrate that our Polymer yields comparable or even better supervised DL methods.

Though the proposed Polymer achieves excellent MAR performance, there still are some limitations. Firstly, our Polymer is case-specific, meaning an independent model has to be optimized for each sample. Technically, the optimization of the Polymer for a CT image of 256x256 size requires about 2 minutes on a single NVIDIA RTX TITAN GPU (24 GB). In addition, our current Polymer model is based on 2D fan-beam and 3D cone-beam CT, while more advanced types of beams (_e.g._, helical CT) are not implemented.

## 6 Acknowledgement

This work was supported by the National Natural Science Foundation of China under Grants No. 62071299 and MoE Key Lab of Intelligent Perception and Human-Machine Collaboration (ShanghaiTech University). Ce Wang was supported by the National Natural Science Foundation of China under Grants No. 62301532, in part by the Natural Science Foundation of Jiangsu Province under Grant No. BK20230282

## References

* [1] Ge Wang, Hengyong Yu, and Bruno De Man. An outlook on x-ray ct research and development. _Medical physics_, 35(3):1051-1064, 2008.
* [2] Jin Keun Seo and Eung Je Woo. _Nonlinear inverse problems in imaging_. John Wiley & Sons, 2012.
* [3] Avinash C Kak and Malcolm Slaney. _Principles of computerized tomographic imaging_. SIAM, 2001.
* [4] Lars Gjesteby, Bruno De Man, Yannan Jin, Harald Paganetti, Joost Verburg, Drosoula Giantsoudi, and Ge Wang. Metal artifact reduction in ct: where are we after four decades? _Ieee Access_, 4:5826-5849, 2016.
* [5] Leonid I Rudin, Stanley Osher, and Emad Fatemi. Nonlinear total variation based noise removal algorithms. _Physica D: nonlinear phenomena_, 60(1-4):259-268, 1992.
* [6] Muhammad Usman Ghani and W Clem Karl. Fast enhanced ct metal artifact reduction using data domain deep learning. _IEEE Transactions on Computational Imaging_, 6:181-193, 2019.
* [7] Yanbo Zhang and Hengyong Yu. Convolutional neural network based metal artifact reduction in x-ray computed tomography. _IEEE transactions on medical imaging_, 37(6):1370-1381, 2018.
* [8] Wei-An Lin, Haofu Liao, Cheng Peng, Xiaohang Sun, Jingdan Zhang, Jiebo Luo, Rama Chellappa, and Shaohua Kevin Zhou. Dudonet: Dual domain network for ct metal artifact reduction. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 10512-10521, 2019.

\begin{table}
\begin{tabular}{c c} \hline \(\#\)Energy Levels & PSNR \\ \hline \(N=50\) & 30.98\(\pm\)1.02 \\ \(N=76\) & 34.99\(\pm\)1.30 \\ \(N=86\) & 36.15\(\pm\)1.38 \\ \(N=101\) & **36.87\(\pm\)1.56** \\ \hline \end{tabular}
\end{table}
Table 4: Quantitative results of our Polymer ablating the discrete energy levels \(N\) on the DeepLesion [43] dataset.

Figure 6: Qualitative results of our Polymer ablating the discrete energy levels \(N\) on a sample (\(\#\)9) of the DeepLesion dataset [43]. The red regions denote metals.

* [9] Yang Song, Liyue Shen, Lei Xing, and Stefano Ermon. Solving inverse problems in medical imaging with score-based generative models. In _International Conference on Learning Representations_, 2022.
* [10] Willi A Kalender, Robert Hebel, and Johannes Ebersberger. Reduction of ct artifacts caused by metallic implants. _Radiology_, 164(2):576-577, 1987.
* [11] Esther Meyer, Rainer Raupach, Michael Lell, Bernhard Schmidt, and Marc Kachelriess. Normalized metal artifact reduction (nmar) in computed tomography. _Medical physics_, 37(10):5482-5493, 2010.
* [12] Abolfazl Mehranian, Mohammad Reza Ay, Arman Rahmim, and Habib Zaidi. X-ray ct metal artifact reduction using wavelet domain \(l\_\{0\}\) sparse regularization. _IEEE transactions on medical imaging_, 32(9):1707-1722, 2013.
* [13] Hong Wang, Yuexiang Li, Deyu Meng, and Yefeng Zheng. Adaptive convolutional dictionary network for ct metal artifact reduction. In _The 31st International Joint Conference on Artificial Intelligence_. IEEE, 2022.
* [14] Hong Wang, Yuexiang Li, Nanjun He, Kai Ma, Deyu Meng, and Yefeng Zheng. Dicdnet: Deep interpretable convolutional dictionary network for metal artifact reduction in ct images. _IEEE Transactions on Medical Imaging_, 41(4):869-880, 2021.
* [15] Lars Gjesteby, Qingsong Yang, Yan Xi, Hongming Shan, Bernhard Claus, Yannan Jin, Bruno De Man, and Ge Wang. Deep learning methods for ct image-domain metal artifact reduction. In _Developments in X-ray Tomography XI_, volume 10391, pages 147-152. SPIE, 2017.
* [16] Lequan Yu, Zhicheng Zhang, Xiaomeng Li, and Lei Xing. Deep sinogram completion with image prior for metal artifact reduction in ct images. _IEEE transactions on medical imaging_, 40(1):228-238, 2020.
* [17] Jianing Wang, Yiyuan Zhao, Jack H Noble, and Benoit M Dawant. Conditional generative adversarial networks for metal artifact reduction in ct images of the ear. In _Medical Image Computing and Computer Assisted Intervention-MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part I_, pages 3-11. Springer, 2018.
* [18] Yiheng Xie, Towaki Takikawa, Shunsuke Saito, Or Litany, Shiqin Yan, Numair Khan, Federico Tombari, James Tompkin, Vincent Sitzmann, and Srinath Sridhar. Neural fields in visual computing and beyond. In _Computer Graphics Forum_, volume 41, pages 641-676. Wiley Online Library, 2022.
* [19] Nasim Rahaman, Aristide Baratin, Devansh Arpit, Felix Draxler, Min Lin, Fred Hamprecht, Yoshua Bengio, and Aaron Courville. On the spectral bias of neural networks. In _International Conference on Machine Learning_, pages 5301-5310. PMLR, 2019.
* [20] Zhi-Qin John Xu, Yaoyu Zhang, Tao Luo, Yanyang Xiao, and Zheng Ma. Frequency principle: Fourier analysis sheds light on deep neural networks. _arXiv preprint arXiv:1901.06523_, 2019.
* [21] Darius Ruckert, Yuanhao Wang, Rui Li, Ramzi Idoughi, and Wolfgang Heidrich. Neat: Neural adaptive tomography. _ACM Transactions on Graphics (TOG)_, 41(4):1-13, 2022.
* [22] Liyue Shen, John Pauly, and Lei Xing. Nerp: implicit neural representation learning with prior embedding for sparsely sampled image reconstruction. _IEEE Transactions on Neural Networks and Learning Systems_, 2022.
* [23] Albert W Reed, Hyojin Kim, Rushil Anirudh, K Aditya Mohan, Kyle Champley, Jingu Kang, and Suren Jayasuriya. Dynamic ct reconstruction from limited views with implicit neural representations and parametric motion fields. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 2258-2268, 2021.
* [24] Yu Sun, Jiaming Liu, Mingyang Xie, Brendt Wohlberg, and Ulugbek S Kamilov. Coil: Coordinate-based internal learning for tomographic imaging. _IEEE Transactions on Computational Imaging_, 7:1400-1412, 2021.

* [25] Guangming Zang, Ramzi Idoughi, Rui Li, Peter Wonka, and Wolfgang Heidrich. Intratomo: self-supervised learning-based tomography via sinogram synthesis and prediction. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 1960-1970, 2021.
* [26] Qing Wu, Ruimin Feng, Hongjiang Wei, Jingyi Yu, and Yuyao Zhang. Self-supervised coordinate projection network for sparse-view computed tomography. _IEEE Transactions on Computational Imaging_, 9:517-529, 2023.
* [27] Johann Heinrich Lambert. _Photometria sive de mensura et gradibus luminis, colorum et umbrae_. Klett, 1760.
* [28] August Beer. Bestimmung der absorption des rothen lichts in farbigen flussigkeiten. _Ann. Physik_, 162:78-88, 1852.
* [29] Emil Y Sidky, Yu Zou, and Xiaochuan Pan. Impact of polychromatic x-ray sources on helical, cone-beam computed tomography and dual-energy methods. _Physics in Medicine & Biology_, 49(11):2293, 2004.
* [30] H. Liao, W. Lin, S. K. Zhou, and J. Luo. Adn: Artifact disentanglement network for unsupervised metal artifact reduction. _IEEE Transactions on Medical Imaging_, 2019.
* [31] Zhihao Wang, Jian Chen, and Steven CH Hoi. Deep learning for image super-resolution: A survey. _IEEE transactions on pattern analysis and machine intelligence_, 43(10):3365-3387, 2020.
* [32] Chunwei Tian, Lunke Fei, Wenxian Zheng, Yong Xu, Wangmeng Zuo, and Chia-Wen Lin. Deep learning on image denoising: An overview. _Neural Networks_, 131:251-275, 2020.
* [33] Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik, Jonathan T Barron, Ravi Ramamoorthi, and Ren Ng. Nerf: Representing scenes as neural radiance fields for view synthesis. _Communications of the ACM_, 65(1):99-106, 2021.
* [34] Jonathan T Barron, Ben Mildenhall, Matthew Tancik, Peter Hedman, Ricardo Martin-Brualla, and Pratul P Srinivasan. Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 5855-5864, 2021.
* [35] Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. Volume rendering of neural implicit surfaces. _Advances in Neural Information Processing Systems_, 34:4805-4815, 2021.
* [36] Peng Wang, Lingjie Liu, Yuan Liu, Christian Theobalt, Taku Komura, and Wenping Wang. Neus: Learning neural implicit surfaces by volume rendering for multi-view reconstruction. _Advances in Neural Information Processing Systems_, 34:27171-27183, 2021.
* [37] Ruyi Zha, Yanhao Zhang, and Hongdong Li. Naf: Neural attenuation fields for sparse-view cbct reconstruction. In _Medical Image Computing and Computer Assisted Intervention-MICCAI 2022: 25th International Conference, Singapore, September 18-22, 2022, Proceedings, Part VI_, pages 442-452. Springer, 2022.
* [38] Francisca Vasconcelos, Bobby He, Nalini Singh, and Yee Whye Teh. Uncertainr: Uncertainty quantification of end-to-end implicit neural representations for computed tomography. _arXiv preprint arXiv:2202.10847_, 2022.
* [39] Bowen Song, Liyue Shen, and Lei Xing. Piner: Prior-informed implicit neural representation learning for test-time adaptation in sparse-view ct reconstruction. In _Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision_, pages 1928-1938, 2023.
* [40] Kunal Gupta, Brendan Colvert, Zhennong Chen, and Francisco Contijoch. Difir-ct: Distance field representation to resolve motion artifacts in computed tomography. _Medical Physics_, 50(3):1349-1366, 2023.
* [41] Qing Wu, Xin Li, Hongjiang Wei, Jingyi Yu, and Yuyao Zhang. Joint rigid motion correction and sparse-view ct via self-calibrating neural field. In _2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)_, pages 1-5. IEEE, 2023.

* [42] J Punnoose, J Xu, A Sisniega, W Zbijewski, and JH Siewdersen. Technical note: spektr 3.0--a computational tool for x-ray spectrum. _Medical Physics_, 43(8):4711-4717, 2016.
* [43] Ke Yan, Xiaosong Wang, Le Lu, Ling Zhang, Adam P Harrison, Mohammad Bagheri, and Ronald M Summers. Deep lesion graphs in the wild: relationship learning and organization of significant radiology image findings in a diverse large-scale lesion database. In _Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition_, pages 9261-9270, 2018.
* [44] Martin J Berger. Xcom: Photon cross sections database, version 1.4. _http://physics. nist. gov/xcom_, 2009.
* [45] Richard Gordon, Robert Bender, and Gabor T Herman. Algebraic reconstruction techniques (art) for three-dimensional electron microscopy and x-ray photography. _Journal of theoretical Biology_, 29(3):471-481, 1970.
* [46] Samuel G Armato III, Geoffrey McLennan, Luc Bidaut, Michael F McNitt-Gray, Charles R Meyer, Anthony P Reeves, Binsheng Zhao, Denise R Aberle, Claudia I Henschke, Eric A Hoffman, et al. The lung image database consortium (lidc) and image database resource initiative (idri): a completed reference database of lung nodules on ct scans. _Medical physics_, 38(2):915-931, 2011.
* [47] Thomas Muller, Alex Evans, Christoph Schied, and Alexander Keller. Instant neural graphics primitives with a multiresolution hash encoding. _ACM Trans. Graph._, 41(4), jul 2022.
* [48] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _CoRR_, abs/1412.6980, 2015.
* [49] Lee A Feldkamp, Lloyd C Davis, and James W Kress. Practical cone-beam algorithm. _Josa a_, 1(6):612-619, 1984.
* [50] RC Chen, Renata Longo, Luigi Rigon, Fabrizio Zanconati, Alessandro De Pellegrin, Fulvia Arfelli, Diego Dreossi, RH Menk, E Vallazza, TQ Xiao, et al. Measurement of the linear attenuation coefficients of breast tissues by synchrotron radiation computed tomography. _Physics in Medicine & Biology_, 55(17):4993, 2010.

**Supplementary Material-- Unsupervised Polychromatic Neural Representation for CT Metal Artifact Reduction**

## Appendix A Additional Details of Datasets

In this work, we perform experiments on four datasets: DeepLesion [43], XCOM [44], and our Walnut Sample. DeepLesion and XCOM are simulation datasets, while Walnut Sample and Mouse Thigh are real-world datasets. _Note that our method is fully unsupervised, and thus all the data are exclusively used for testing purposes._

DeepLesion.To simulate metal-corrupted measurements in the DeepLesion dataset [43], we follow the pipelines outlined in [30; 7; 8]. For our experiments, we extract 200 2D images from the DeepLesion dataset as test GT samples [43]. As depicted in Fig. 7, we leverage ten shapes of metallic implants from [30; 7; 8] and consider them Titanium. To simulate the X-ray source, we employ a polychromatic X-ray with an energy range of [20; 120] KeV and a minimum energy unit of 1 KeV. The number of photons emitted by the X-ray source is set to 2\(\times\)10\({}^{7}\). The normalized energy spectrum \(\eta\) of the X-ray source is illustrated in Fig. 8 (_Left_). We adopt an equiangular fan-beam CT acquisition geometry, and the detailed parameters are provided in Table 5. Additionally, we incorporate Poisson noise and consider the partial volume effect in the sinogram domain during the simulation process.

Xcom.For the XCOM dataset [44], we use two samples provided by Zhang _et al._[7]. These two cases are simulated using two 2D clean CT images sourced from the XCOM [44] database. Zhang _et

Figure 8: (_Left_) The simulated spectrum within an energy range of [20; 120] for synthesizing metal-corrupted measurements of the DeepLesion [43] and XCOM [44] datasets. The spectrums estimated within the energy ranges of [0, 100] and [0, 60] estimated by the SPEKTR toolkit [42] for the real walnut sample (_Middle_) and mouse thigh (_Right_).

Figure 7: Ten shapes of metals for synthesizing metal-corrupted measurements in the DeepLesion [43] dataset. These metals are supposed as Titanium. The white regions denote metals.

al._[7] consider a polychromatic X-ray source with an energy range of [20, 120] KeV and a minimum energy unit of 1 KeV. The corresponding normalized energy spectrum \(\eta\) is depicted in Fig. 8 (_Left_). In oder to generate metal-corrupted sinograms, an equiangular fan-beam CT acquisition geometry is employed, and the geometry parameters are specified in Table 5. Similar to the DeepLesion [43] dataset, Zhang _et al._[7] also simulate Poisson noise and consider the partial volume effect in the sinogram domain during the simulation process.

Walnut Sample.To assess the performance of our proposed method on real CT data, we employ a commercial Bruker SKYSCAN 1276 micro-CT scanner to scan a walnut sample that contains a metal paper clip. Detailed parameters of the acquisition geometry can be found in Table 5. To estimate the X-ray spectrum of the micro-CT scanner, we leverage the SPEKTR toolkit [42]. The estimated spectrum is illustrated in Fig. 8 (_Middle_).

Mouse Thigh.We also scan a mouse thigh containing a metal intramedullary needle on the same micro-CT scanner. This sample is 3D cone-beam data. Detailed parameters of the acquisition geometry are shown in Table 5. We leverage the SPEKTR toolkit [42] to estimate the X-ray spectrum of the micro-CT scanner. The estimated spectrum is illustrated in Fig. 8 (_Right_).

## Appendix B Additional Details of Baselines

In our experiments, we compare our proposed method against eight baseline MAR approaches. _Notably, for the five DL-based methods, we evaluate their performance using the pre-trained models provided by the respective authors._

Fbp.The FBP [3] is a conventional approach used for reconstructing CT images. It involves re-projecting the acquired sinogram data onto the image domain using the corresponding projection angles and geometric parameters to obtain an approximate estimate of the unknown image. In our experiments, we use the in-build function ifanbem in MATLAB (https://www2.mathworks.cn/help/images/ref/ifanbeam.html?requestedDomain=cn).

Li.A simple strategy to mitigate metal artifacts in CT imaging involves the direct linear interpolation of the sinogram [10] to fill in the regions affected by metal. This approach does not require any network training but may result in imperfect sinogram completion, which in turn could introduce undesired artifacts in the reconstructed image. In our experiments, we use the implementation provided by Zhang _et al._[7] (https://github.com/yanbozhang007/CNN-MAR/blob/master/cnmar).

\begin{table}
\begin{tabular}{c c c c c} \hline \hline \multirow{2}{*}{**Parameters**} & \multicolumn{2}{c}{**Simulation Datasets**} & \multicolumn{2}{c}{**Real Datasets**} \\ \cline{2-5}  & DeepLesion [43] & XCOM [44] & Walnut & Mouse Thigh \\ \hline Type of geometry & 2D fan-beam & 2D fan-beam & 2D fan-beam & 3D cone-beam \\ \hline Source Voltage (kV) & 120 & 120 & 100 & 60 \\ \hline Source Current (uA) & - & - & 200 & 200 \\ \hline Exposure Time (ms) & - & - & 276 & 730 \\ \hline Image size & 256\(\times\)256 & 512\(\times\)512 & 650\(\times\)650 & 200\(\times\)200\(\times\)150 \\ \hline Voxel size (mm) & 1\(\times\)1 & 0.8\(\times\)0.8 & 0.05\(\times\)0.05 & 0.06\(\times\)0.06\(\times\)0.06 \\ \hline Angle range (\({}^{\circ}\)) & [0, 360) & [0, 360) & [0, 360) & [0, 360) \\ \hline The number of the angles & 360 & 984 & 720 & 900 \\ \hline Angular spacing (\({}^{\circ}\)) & 0.1 & 0.057 & - & - \\ \hline Detector spacing (mm) & - & - & 0.069 & 0.069 \\ \hline Distance from source to center (mm) & 362 & 743 & 92.602 & 92.602 \\ \hline Distance from center to detector (mm) & 362 & 743 & 65.946 & 65.946 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Detailed parameters of the acquisition geometry for the four datasets.

[MISSING_PAGE_FAIL:16]

Figure 10: Qualitative results of the compared methods on a sample (\(\#74\)) of DeepLesion [43] dataset. The white regions denote metals.

Figure 9: (_Left_) A sample among 2D projections of a mouse thigh containing a metal intramedullary needle scanned by the micro-CT scanner. (_Right_) Qualitative results of FDK [49] and our Polyner on the sample. Note that the acquisition geometry is the 3D cone beam. The reconstructed images have a size of 200\(\times\)200\(\times\)150. Our Polyner takes about 32 minutes on a single NVIDIA RTX TITAN GPU. The red regions denote the metal needle tubing. This data collection is approved ethically.

Figure 11: Qualitative results of the compared methods on a sample (\(\#162\)) of DeepLesion [43] dataset. The white regions denote metals.

Figure 12: Qualitative results of the compared methods on a sample (\(\#\)158) of DeepLesion [43] dataset. The white regions denote metals.

Figure 13: Qualitative results of the compared methods on a sample (\(\#1\)) of XCOM [44] dataset. The white regions denote metals.