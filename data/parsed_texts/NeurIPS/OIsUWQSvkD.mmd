# Identifying Causal Effects Under Functional Dependencies

 Yizuo Chen

Department of Computer Science

University of California, Los Angeles

Los Angeles, CA 90024

yizuo.chen@ucla.edu

&Adnan Darwiche

Department of Computer Science

University of California, Los Angeles

Los Angeles, CA 90024

darwiche@cs.ucla.edu

###### Abstract

We study the identification of causal effects, motivated by two improvements to identifiability which can be attained if one knows that some variables in a causal graph are functionally determined by their parents (without needing to know the specific functions). First, an unidentifiable causal effect may become identifiable when certain variables are functional. Second, certain functional variables can be excluded from being observed without affecting the identifiability of a causal effect, which may significantly reduce the number of needed variables in observational data. Our results are largely based on an elimination procedure which removes functional variables from a causal graph while preserving key properties in the resulting causal graph, including the identifiability of causal effects.

## 1 Introduction

A causal effect measures the impact of an intervention on some events of interest, and is exemplified by the question "what is the probability that a patient would recover had they taken a drug?" This type of question, also known as an interventional query, belongs to the second rung of Pearl's causal hierarchy [1] so it ultimately requires experimental studies if it is to be estimated from data. However, it is well known that such interventional queries can sometimes be answered based on observational queries (first rung of the causal hierarchy) which can be estimated from observational data. This becomes very significant when experimental studies are either not available, expensive to conduct, or would entail ethical concerns. Hence, a key question in causal inference asks when and how a causal effect can be estimated from available observational data assuming a causal graph is provided [2].

More precisely, given a set of _treatment_ variables \(\mathbf{X}\) and a set of _outcome_ variables \(\mathbf{Y}\), the causal effect of \(\mathbf{x}\) on \(\mathbf{Y}\), denoted \(\Pr(\mathbf{Y}|do(\mathbf{x}))\) or \(\Pr_{\mathbf{x}}(\mathbf{Y})\), is the marginal probability on \(\mathbf{Y}\) when an intervention sets the states of variables \(\mathbf{X}\) to \(\mathbf{x}\). The problem of identifying a causal effect studies whether \(\Pr_{\mathbf{x}}(\mathbf{Y})\) can be uniquely determined from a causal graph and a distribution \(\Pr(\mathbf{V})\) over some variables \(\mathbf{V}\) in the causal graph [2], where \(\Pr(\mathbf{V})\) is typically estimated from observational data. The causal effect is guaranteed to be identifiable if \(\mathbf{V}\) correspond to all variables in the causal graph (with some positivity assumptions); that is, if all such variables are observed. When some variables are hidden (unobserved), it is possible that different parameterizations of the causal graph will induce the same distribution \(\Pr(\mathbf{V})\) but different values for the causal effect \(\Pr_{\mathbf{x}}(\mathbf{Y})\) which leads to unidentifiability. In the past few decades, a significant amount of effort has been devoted to studying the identifiability of causal effects; see, e.g., [3; 2; 4; 5; 6; 7]. Some early works include the _back-door criterion_[8; 2] and the _front-door criterion_[3; 2]. These criteria are sound but incomplete as they may fail to identify certain causal effects that are indeed identifiable. Complete identification methods include the do-calculus [2], the identification algorithm in [9], and the ID algorithm proposed in [10]. These methods require some positivity assumptions (constraints) on the observational distribution \(\Pr(\mathbf{V})\) and can derivean identifying formula that computes the causal effect based on \(\Pr(\mathbf{V})\) when the causal effect is identifiable. Some recent works take a different approach by first estimating the parameters of a causal graph to obtain a fully-specified causal model which is then used to estimate causal effects through inference [11; 12; 13; 14]. Further works focus on the efficiency of estimating causal effects from finite data [15; 16; 17; 18], the general identifiability of causal effects from both observational and experimental data [19], and the causal effect identification with data collected from sub-populations [20].

A recent line of work studies the impact of additional information on identifiability, beyond causal graphs and observational data. For example, [21] showed that certain unidentifiable causal effects can become identifiable given information about context-specific independence. Our work in this paper follows the same direction as we consider the problem of causal effect identification in the presence of a particular type of qualitative knowledge called _functional dependencies_[22]. We say there is a functional dependency between a variable \(X\) and its parents \(\mathbf{P}\) in the causal graph if the distribution \(\Pr(X|\mathbf{P})\) is deterministic but we do not know the distribution itself (i.e., the specific values of \(\Pr(x|\mathbf{p})\)). We also say in this case that variable \(X\) is _functional_. Previous works have shown that functional dependencies can be exploited to improve the efficiency of Bayesian network inference [23; 24; 25; 13; 26]. We complement these works by showing that functional dependencies can also be exploited for identifiability. In particular, we show that some unidentifiable causal effects may become identifiable given such dependencies, propose techniques for testing identifiability in this context, and highlight other implications of such dependencies on the practice of identifiability.

Consider the following motivational example where we are interested in how the enforcement of speed limits may affect car accidents. The Driving Age (\(A\)) is functionally determined by Country (\(C\)); Driving Age and Country are causes of Speed (\(X\)); and Speed and Driving Age are causes of Accidents (\(Y\)). The DAG on the right captures the causal relations among these variables, where variable \(A\) is circled to indicate it is functional. Suppose further that variables \(C,X,Y\) are observed. According to classical causal-effect identification methods (e.g., do-calculus, ID algorithm), the causal effect of \(X\) on \(Y\) is unidentifiable in this case. However, if we take into account that variable \(A\) is a function of \(C\), which restricts the class of distributions under consideration, then the causal effect of \(X\) on \(Y\) becomes identifiable. This exemplifies the improvements to identifiability pursued in this paper.

Consider a causal graph \(G\) and a distribution \(\Pr(\mathbf{V})\) over the observed variables \(\mathbf{V}\) in \(G\). To check the identifiability of a causal effect, it is standard to first apply the _projection_ operation in [27; 28] which constructs another causal graph \(G^{\prime}\) with \(\mathbf{V}\) as its non-root variables, and follow by applying an identification algorithm to \(G^{\prime}\) like the ID algorithm [10]. This two-stage procedure, which we will call _project-ID_, is applicable only under some positivity constraints (assumptions) which preclude some events from having a zero probability. Since such positivity constraints may contradict functional dependencies, we formulate the notion of _constrained identifiability_ which takes positivity constraints as an input (in addition to the causal graph \(G\) and distribution \(\Pr(\mathbf{V})\)). We also formulate the notion of _functional identifiability_ which further takes functional dependencies as an input. This allows us to explicitly treat the interactions between positivity constraints and functional dependencies, which is needed for combining classical methods like project-ID with the results we present in this paper.

We start with some technical preliminaries in Section 2. We formally define positivity constraints and functional dependencies in Section 3 where we also introduce the problems of constrained and functional identifiability. Section 4 introduces two primitive operations, _functional elimination_ and _functional projection,_ which are needed for later treatments. Sections 5 presents our core results on functional identifiability and how they can be combined with existing identifiability algorithms. We finally close with concluding remarks in Section 6. Proofs of all results are included in the Appendix.

## 2 Technical Preliminaries

We consider discrete variables in this work. Single variables are denoted by uppercase letters (e.g., \(X\)) and their states are denoted by lowercase letters (e.g., \(x\)). Sets of variables are denoted by bold uppercase letters (e.g., \(\mathbf{X}\)) and their instantiations are denoted by bold lowercase letters (e.g., \(\mathbf{x}\)).

### Causal Bayesian Networks and Interventions

A Causal Bayesian network (CBN) is a pair \(\langle G,\mathcal{F}\rangle\) where \(G\) is a _causal graph_ in the form of a directed acyclic graph (DAG), and \(\mathcal{F}\) is a set of conditional probability tables (CPTs). We have one CPT for each variable \(X\) with parents \(\mathbf{P}\) in \(G\), which specifies the conditional probability distributions \(\Pr(X|\mathbf{P})\). This CPT will often be denoted by \(f_{X}(X,\mathbf{P})\) so \(f_{X}(x,\mathbf{p})\in[0,1]\) for all instantiations \(x,\mathbf{p}\) and \(\sum_{x}f_{X}(x,\mathbf{p})=1\) for every instantiation \(\mathbf{p}\).

A CBN induces a joint distribution over its variables \(\mathbf{V}\) which is exactly the product of its CPTs, i.e., \(\Pr(\mathbf{V})=\prod_{V\in\mathbf{V}}f_{V}\). Applying a treatment \(do(\mathbf{x})\) to the joint distribution yields a new distribution called the _interventional distribution_, denoted \(\Pr_{\mathbf{x}}(\mathbf{V})\). One way to compute the interventional distribution is to consider the _untilated CBN_\(\langle G^{\prime},\mathcal{F}^{\prime}\rangle\) that is constructed from the original CBN \(\langle G,\mathcal{F}\rangle\) as follows: remove from \(G\) all edges that point to variables in \(\mathbf{X}\), then replace the CPT in \(\mathcal{F}\) for each \(X\in\mathbf{X}\) with a CPT \(f_{X}(X)\) where \(f_{X}(x)=1\) if \(x\) is consistent with \(\mathbf{x}\) and \(f_{X}(x)=0\) otherwise. Figure 0(a) depicts a causal graph \(G\) and Figure 0(b) depicts the mutilated causal graph \(G^{\prime}\) under a treatment \(do(x_{1},x_{2})\). The interventional distribution \(\Pr_{\mathbf{x}}\) is the distribution induced by the mutilated CBN \(\langle G^{\prime},\mathcal{F}^{\prime}\rangle\), where \(\Pr_{\mathbf{x}}(\mathbf{Y})\) corresponds to the causal effect \(\Pr(\mathbf{Y}|do(\mathbf{x}))\) also notated by \(\Pr(\mathbf{Y}_{\mathbf{x}})\).

### Identifying Causal Effects

A key question in causal inference is to check whether a causal effect can be (uniquely) computed given the causal graph \(G\) and a distribution \(\Pr(\mathbf{V})\) over a subset \(\mathbf{V}\) of its variables. If the answer is yes, we say that the causal effect is _identifiable_ given \(G\) and \(\Pr(\mathbf{V})\). Otherwise, the causal effect is _unidentifiable_. Variables \(\mathbf{V}\) are said to be _observed_ and the remaining variables are said to be _hidden_, where \(\Pr(\mathbf{V})\) is usually estimated from observational data. We start with the general definition of identifiability (not necessarily for causal effects) from [2, Ch. 3.2.4] with a slight rephrasing.

**Definition 1** (Identifiability [2]).: _Let \(Q(M)\) be any computable quantity of a model \(M\). We say that \(Q\) is identifiable in a class of models if, for any pairs of models \(M_{1}\) and \(M_{2}\) from this class, \(Q(M_{1})=\overline{Q(M_{2})}\) whenever \(\Pr_{M_{1}}(\mathbf{V})=\Pr_{M_{2}}(\mathbf{V})\) where \(\mathbf{V}\) are the observed variables._

In the context of causal effects, the problem of identifiability is to check whether every pair of fully-specified CBNs (\(M_{1}\) and \(M_{2}\) in Definition 1) that induce the same distribution \(\Pr(\mathbf{V})\) will also produce the same value for the causal effect. Note that Definition 1 does not restrict the considered models \(M_{1}\) and \(M_{2}\) based on properties of the distributions \(\Pr_{M_{1}}(\mathbf{V})\) and \(\Pr_{M_{2}}(\mathbf{V})\). However, in the literature on identifying causal effects, it is quite common to only consider CBNs (models) that induce distributions which satisfy some positivity constraints, such as \(\Pr(\mathbf{V})>0\). We will examine such constraints more carefully in Section 3 as they may contradict functional dependencies.

It is well known that under some positivity constraints (e.g., \(\Pr(\mathbf{V})>0\)), the identifiability of causal effects can be efficiently tested using what we shall call the _project-ID_ algorithm. Given a causal graph \(G\), project-ID first applies the projection operation in [27; 28; 29] to yield a new causal graph \(G^{\prime}\) whose hidden variables are all roots and each has exactly two children. These properties are needed by the ID algorithm [10], which is then applied to \(G^{\prime}\) to yield an identifying formula if the causal effect is identifiable or FAIL otherwise. Consider the causal effect \(\Pr_{x_{1}x_{2}}(y)\) in Figure 0(a) where the only hidden variable is the non-root variable \(B\). We first project the causal graph \(G\) in Figure 0(a) onto its observed variables to yield the causal graph \(G^{\prime}\) in Figure 0(c) (all hidden variables in \(G^{\prime}\) are auxiliary and roots). We then run the ID algorithm on \(G^{\prime}\) which returns the following (simplified) identifying formula: \(\Pr_{x_{1}x_{2}}(y)=\sum_{acd}\Pr(c|x_{1})\Pr(d|x_{1},x_{2})\,\sum_{x_{1}^{ \prime}x_{2}^{\prime}}\Pr(y|x_{1}^{\prime},x_{2}^{\prime},a,c,d)\)\(\Pr(x_{2}^{\prime}|x_{1}^{\prime},a,c)\). Hence, the causal effect \(\Pr_{x_{1}x_{2}}(y)\) is identifiable and can be computed using the above formula. Moreover, all quantities in the formula can be obtained from the distribution \(\Pr(A,C,D,X_{1},X_{2},Y)\) over observed variables, which can be estimated from observational data. More details on the projection operation and the ID algorithm can be found in Appendix A.

## 3 Constrained and Functional Identifiability

As mentioned earlier, Definition 1 of identifiability [2, Ch. 3.2.4] does not restrict the pair of considered models \(M_{1}\) and \(M_{2}\). However, it is common in the literature on causal-effect identifiability to only consider CBNs with distributions \(\Pr(\mathbf{V})\) that satisfy some positivity constraints. Strict positivity,\(\Pr(\mathbf{V})>0\), is perhaps the mostly widely used constraint [9; 29; 2]. That is, in Definition 1, we only consider CBNs \(M_{1}\) and \(M_{2}\) which induce distributions \(\Pr_{M_{1}}\) and \(\Pr_{M_{2}}\) that satisfy \(\Pr_{M_{1}}(\mathbf{V})>0\) and \(\Pr_{M_{2}}(\mathbf{V})>0\). Weaker, and somewhat intricate, positivity constraints were employed by the ID algorithm in [10] as discussed in Appendix A, but we will apply this algorithm only under strict positivity to keep things simple. See also [31] for a recent discussion of positivity constraints.

Positivity constraints are motivated by two considerations: technical convenience, and the fact that most causal effects would be unidentifiable without some positivity constraints (more on this later). Given the multiplicity of positivity constraints considered in the literature, and given the subtle interaction between positivity constraints and functional dependencies (which are the main focus of this work), we next provide a systematic treatment of identifiability under positivity constraints.

### Positivity Constraints

We will first formalize the notion of a _positivity constraint_ and then define the notion of _constrained identifiability_ which takes a set of positivity constraints as input (in addition to the causal graph \(G\) and distribution \(\Pr(\mathbf{V})\)).1

Footnote 1: We are incorporating positivity constraints directly into the definition of identifiability. This is different from the analysis in [32] which derives positivity constraints from a particular run of the identification algorithm.

**Definition 2**.: _A positivity constraint on \(\Pr(\mathbf{V})\) is an inequality of the form \(\Pr(\mathbf{S}|\mathbf{Z})>0\) where \(\mathbf{S}\subseteq\mathbf{V}\), \(\mathbf{Z}\subseteq\mathbf{V}\) and \(\mathbf{S}\cap\mathbf{Z}=\emptyset\). That is, for all instantiations \(\mathbf{s},\mathbf{z}\), if \(\Pr(\mathbf{z})>0\) then \(\Pr(\mathbf{s},\mathbf{z})>0\)._

When \(\mathbf{Z}=\emptyset\), the positivity constraint is defined on a marginal distribution, \(\Pr(\mathbf{S})>0\). We may impose multiple positivity constraints on a set of variables \(\mathbf{V}\). We will use \(\mathcal{C}_{\mathbf{V}}\) to denote the set of positivity constraints imposed on \(\Pr(\mathbf{V})\) and use \(\mathtt{vars}(\mathcal{C}_{\mathbf{V}})\) to denote all the variables mentioned by \(\mathcal{C}_{\mathbf{V}}\). The weakest set of positivity constraints is \(\mathcal{C}_{\mathbf{V}}=\{\}\) (no positivity constraints as in Definition 1), and the strongest positivity constraint is \(\mathcal{C}_{\mathbf{V}}=\{\Pr(\mathbf{V})>0\}\).

We next provide a definition of identifiability for the causal effect of treatments \(\mathbf{X}\) on outcomes \(\mathbf{Y}\) in which positivity constraints are an input to the identifiability problem. We call it _constrained identifiability_ in contrast to the (unconstrained) identifiability of Definition 1.

**Definition 3**.: _We call \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}}\rangle\) an identifiability tuple where \(G\) is a causal graph (DAG), \(\mathbf{V}\) is its set of observed variables, and \(\mathcal{C}_{\mathbf{V}}\) is a set of positivity constraints._

**Definition 4** (Constrained Identifiability).: _Let \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}}\rangle\) be an identifiability tuple. The causal effect of \(\mathbf{X}\) on \(\mathbf{Y}\) is said to be identifiable with respect to \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}}\rangle\) if \(\Pr_{\mathbf{x}}^{1}(\mathbf{y})=\Pr_{\mathbf{x}}^{2}(\mathbf{y})\) for any pair of distributions \(\Pr^{1}\) and \(\Pr^{2}\) which are induced by \(G\) and that satisfy \(\Pr^{1}(\mathbf{V})=\Pr^{2}(\mathbf{V})\) and that also satisfy the positivity constraints \(\mathcal{C}_{\mathbf{V}}\)._

For simplicity, we say "identifiability" to mean "constrained identifiability" in the rest of paper.

We next show that without some positivity constraints, most causal effects would not be identifiable. We say that a treatment \(X\in\mathbf{X}\) is a _first ancestor_ of some outcome \(Y\in\mathbf{Y}\) if \(X\) is an ancestor of \(Y\) in causal graph \(G\), and there exists a directed path from \(X\) to \(Y\) that is not intercepted by \(\mathbf{X}\setminus\{X\}\). A first ancestor must exist if some treatment variable is an ancestor of some outcome variable.

**Proposition 5**.: _The casual effect of \(\mathbf{X}\) on \(\mathbf{Y}\) is not identifiable wrt an identifiability tuple \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}}\rangle\) if some \(X\in\mathbf{X}\) is a first ancestor of some \(Y\in\mathbf{Y}\), and \(\mathcal{C}_{\mathbf{V}}\) does not imply \(\Pr(X)>0\)._

Figure 1: Example adapted from [30]. Hidden variables are circled. A bidirected edge \(X\)\(\leftarrow\)\(\cdots\)\(\cdots\)\(\cdots\)\(Y\) is compact notation for \(X\gets H\to Y\) where \(H\) is an auxiliary hidden variable.

Hence, identifiability is not possible without some positivity constraints if at least one treatment variable is an ancestor of some outcome variable (which is common). Consider the causal graph on the right where \(U\) is the only hidden variable. By Proposition 5, the causal effect of \(\{X_{1},X_{2}\}\) on \(\{Y_{1},Y_{2}\}\) is not identifiable if the considered distributions do not satisfy \(\Pr(X_{2})>0\) as \(X_{2}\) is a first ancestor of \(Y_{2}\).

As positivity constraints become stronger, more causal effects become identifiable since the set of considered models becomes smaller. Consider the causal graph on the right in which all variables are observed, \(\mathbf{V}=\{X,Y,Z\}\). Without positivity constraints, \(\mathcal{C}_{\mathbf{V}}=\emptyset\), the causal effect of \(X\) on \(Y\) is not identifiable. However, it becomes identifiable given strict positivity, \(\mathcal{C}_{\mathbf{V}}=\{\Pr(X,Y,Z)>0\},\) leading to the identifying formula \(\Pr_{x}(y)=\sum_{z}\Pr(y|x,z)\Pr(z).\) This causal effect is also identifiable under the weaker positivity constraint \(\mathcal{C}_{\mathbf{V}}=\{\Pr(X|Z)>0\}\),2 which implies \(\Pr(X)>0,\) so strict positivity is not necessary for identifiability even though it is typically assumed for this folklore result. This is an example where strict positivity may be assumed for technical convenience only as it may facilitate the application of some identifiability techniques like the do-calculus [2].

Footnote 2: This weaker positivity constraint is sufficient to make the identifying formula well-defined since \(\Pr(y|x,z)\Pr(z)\) in the formula is equal to zero when \(\Pr(z)=0\), and is computable when \(\Pr(z)>0;\) that is, the conditional probability \(\Pr(y|x,z)\) is well-defined if \(\Pr(x|z)>0.\)

### Functional Dependencies

A variable \(X\) in a causal graph is said to _functionally depend_ on its parents \(\mathbf{P}\) if its distribution is deterministic: \(\Pr(x|\mathbf{p})\in\{0,1\}\) for every instantiation \(x,\mathbf{p}\). Variable \(X\) is also said to be _functional_ in this case. In this work, we assume _qualitative_ functional dependencies: _we do not know the distribution \(\Pr(X|\mathbf{P}),\) we only know that it is deterministic.3_

Footnote 3: We assume that root variables cannot be functional as such variables can be removed from the causal graph.

The table on the right shows two variables \(B\) and \(C\) that both have \(A\) as their parent. Variable \(C\) is functional but variable \(B\) is not. The CPT for variable \(C\) will be called a _functional CPT_ in this case. Functional CPTs are also known as (causal) mechanisms and are expressed using structural equations in structural causal models (SCMs) [33, 34, 35]. By definition, in an SCM, every non-root variable is assumed to be functional (when noise variables are represented explicitly in the causal graph).

Qualitative functional dependencies are a longstanding concept. For example, they are common in relational databases, see, e.g., [36, 37], and their relevance to probabilistic reasoning had been brought up early in [22, Ch. 3]. One example of a (qualitative) functional dependency is that different countries have different driving ages, so we know that "Driving Age" functionally depends on "Country" even though we may not know the specific driving age for each country. Another example is that a letter grade for a class is functionally dependent on the student's weighted average even though we may not know the scheme for converting a weighted average to a letter grade.

In this work, we assume that we are given a causal graph \(G\) in which some variables \(\mathbf{W}\) have been designated as functional. The presence of functional variables further restricts the set of distributions \(\Pr\) that we consider when checking identifiability. This leads to a more refined problem that we call _functional identifiability (F-identifiability)_, which depends on four elements.

**Definition 6**.: _We call \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) an F-identifiability tuple when \(G\) is a DAG, \(\mathbf{V}\) is its set of observed variables, \(\mathcal{C}_{\mathbf{V}}\) is a set of positivity constraints, and \(\mathbf{W}\) is a set of functional variables in \(G\)._

**Definition 7** (F-Identifiability).: _Let \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) be an F-identifiability tuple. The causal effect of \(\mathbf{X}\) on \(\mathbf{Y}\) is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) if \(\Pr_{\mathbf{x}}^{1}(\mathbf{y})=\Pr_{\mathbf{x}}^{2}(\mathbf{y})\) for any pair of distributions \(\Pr^{1}\) and \(\Pr^{2}\) which are induced by \(G\), and that satisfy \(\Pr^{1}(\mathbf{V})=\Pr^{2}(\mathbf{V})\) and the positivity constraints \(\mathcal{C}_{\mathbf{V}}\), and in which variables \(\mathbf{W}\) functionally depend on their parents._

Both \(\mathcal{C}_{\mathbf{V}}\) and \(\mathbf{W}\) represent constraints on the models (CBNs) we consider when checking identifiability, and these two types of constraints may contradict each other. We next define two notions that characterize some important interactions between positivity constraints and functional variables.

**Definition 8**.: _Let \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) be an F-identifiability tuple. Then \(\mathcal{C}_{\mathbf{V}}\) and \(\mathbf{W}\) are consistent if there exists a parameterization for \(G\) which induces a distribution satisfying \(\mathcal{C}_{\mathbf{V}}\) and in which \(\mathbf{W}\) functionally depend on their parents. Moreover, \(\mathcal{C}_{\mathbf{V}}\) and \(\mathbf{W}\) are separable if \(\mathbf{W}\cap\mathtt{vars}(\mathcal{C}_{\mathbf{V}})=\emptyset\)._

If \(\mathcal{C}_{\mathbf{V}}\) is inconsistent with \(\mathbf{W}\) then the set of distributions \(\Pr\) considered in Definition 7 is empty and, hence, the causal effect is not well defined (and trivially identifiable according to Definition 7). As such, one would usually want to ensure such consistency. Here are some examples of positivity constraints that are always consistent with a set of functional variables \(\mathbf{W}\): positivity on each treatment variable, i.e., \(\{\Pr(X)>0,X\in\mathbf{X}\},\) positivity on the set of non-functional treatments, i.e., \(\{\Pr(\mathbf{X}\setminus\mathbf{W})>0\},\) positivity on all non-functional variables, i.e., \(\{\Pr(\mathbf{V}\setminus\mathbf{W})>0\}.\) All these examples are special cases of the following condition. For a functional variable \(W\in\mathbf{W},\) let \(\mathbf{H}_{W}\) be variables that intercept all directed paths from non-functional variables to \(W\) (such \(\mathbf{H}_{W}\) may not be unique). If none of the positivity constraints in \(\mathcal{C}_{\mathbf{V}}\) mentions both \(W\) and \(\mathbf{H}_{W},\) then \(\mathcal{C}_{\mathbf{V}}\) and \(\mathbf{W}\) are guaranteed to be consistent (see Proposition 25 in Appendix C).

Separability is a stronger condition and it intuitively implies that the positivity constraints will not rule out any possible functions for the variables in \(\mathbf{W}.\) We need such a condition for one of the results we present later. Some examples of positivity constraints that are separable from \(\mathbf{W}\) are \(\{\Pr(\mathbf{X}\setminus\mathbf{W})>0\}\) and \(\{\Pr(\mathbf{V}\setminus\mathbf{W})>0\}.\) Studying the interactions between positivity constraints and functional variables, as we did in this section, will prove helpful later when utilizing existing identifiability algorithms (which require positivity constraints) for testing functional identifiability.

## 4 Functional Elimination and Projection

Our approach for testing identifiability under functional dependencies will be based on eliminating functional variables from the causal graph, which may be followed by invoking the project-ID algorithm on the resulting graph. This can be subtle though since the described process will not work for every functional variable as we discuss in the next section. Moreover, one needs to handle the interaction between positivity constraints and functional variables carefully. The first step though is to formalize the process of eliminating a functional variable and to study the associated guarantees.

Eliminating variables from a probabilistic model is a well studied operation, also known as marginalization; see, e.g., [38; 39; 40]. When eliminating variable \(X\) from a model that represents distribution \(\Pr(\mathbf{Z})\), the goal is to obtain a model that represents the marginal distribution \(\Pr(\mathbf{Y})=\sum_{x}\Pr(x,\mathbf{Y})\) where \(\mathbf{Y}=\mathbf{Z}\setminus\{X\}.\) Elimination can also be applied to a DAG \(G\) that represents conditional independencies \(\mathcal{I},\) leading to a new DAG \(G^{\prime}\) that represents independencies \(\mathcal{I}^{\prime}\) that are implied by \(\mathcal{I}.\) In fact, the projection operation of [27; 28] we discussed earlier can be understood in these terms. We next propose an operation that eliminates functional variables from a DAG and that comes with stronger guarantees compared to earlier elimination operations as far as preserving independencies.

**Definition 9**.: _The functional elimination of a variable \(X\) from a DAG \(G\) yields a new DAG attained by adding an edge from each parent of \(X\) to each child of \(X\) and then removing \(X\) from \(G\).4_

Footnote 4: Appendix B extends this definition to Causal Bayesian networks (i.e., updating both CPTs and causal graph).

For convenience, we sometimes say "elimination" to mean "functional elimination" when the context is clear. From the viewpoint of independence relations, functional elimination is not sound if the eliminated variable is not functional. In particular, the DAG \(G^{\prime}\) that results from this elimination process may satisfy independencies (identified by d-separation) that do not hold in the original DAG \(G\). As we show later, however, every independence implied by \(G^{\prime}\) must be implied by \(G\) if the eliminated variable is functional. In the context of SCMs, functional elimination may be interpreted as replacing the eliminated variable \(X\) by its function in all structural equations that contain \(X\). Functional elimination applies in broader contexts than SCMs though. Eliminating multiple functional variables in any order yields the same DAG (see Proposition 22 in Appendix B). For example, eliminating variables \(\{C,D\}\) from the DAG in Figure 1(a) yields the DAG in Figure 1(c) whether we use the order \(\pi_{1}=C,D\) or the order \(\pi_{2}=D,C\).

Functional elimination preserves independencies that hold in the original DAG and which are not preserved by other elimination methods including projection as defined in [27; 28]. These independencies are captured using the notion of D-separation [41; 42] which is more refined than the classical notion of d-separation [43; 44] (uppercase D- versus lowercase d-). The original definitionof D-separation can be found in [42]. We provide a simpler definition next, stated as Proposition 10, as the equivalence between the two definitions is not immediate.

**Proposition 10**.: _Let \(\mathbf{X},\mathbf{Y},\mathbf{Z}\) be disjoint variable sets and \(\mathbf{W}\) be a set of functional variables in DAG \(G\). Then \(\mathbf{X}\) and \(\mathbf{Y}\) are D-separated by \(\mathbf{Z}\) in \(\langle G,\mathbf{W}\rangle\) iff \(\mathbf{X}\) and \(\mathbf{Y}\) are d-separated by \(\mathbf{Z}^{\prime}\) in \(G\) where \(\mathbf{Z}^{\prime}\) is obtained as follows. Initially, \(\mathbf{Z}^{\prime}=\mathbf{Z}\). Repeat the next step until \(\mathbf{Z}^{\prime}\) stops changing: add to \(\mathbf{Z}^{\prime}\) every variable in \(\mathbf{W}\) whose parents are in \(\mathbf{Z}^{\prime}\)._

To illustrate the difference between d-separation and D-separation, consider again the DAG in Figure 1(a) and assume that variables \(C,D\) are functional. Variable \(G\) and \(I\) are not d-separated by \(A\) but they are D-separated by \(A\). That is, there are distributions which are induced by the DAG in Figure 1(a) and in which \(G\) and \(I\) are not independent given \(A\). However, \(G\) and \(I\) are independent given \(A\) in every induced distribution in which the variables \(C,D\) are functionally determined by their parents. Functional elimination preserves D-separation in the following sense.

**Theorem 11**.: _Consider a DAG \(G\) with functional variables \(\mathbf{W}\). Let \(G^{\prime}\) be the result of functionally eliminating variables \(\mathbf{W}^{\prime}\subseteq\mathbf{W}\) from \(G\). For any disjoint sets \(\mathbf{X}\), \(\mathbf{Y}\), \(\mathbf{Z}\) in \(G^{\prime}\), \(\mathbf{X}\) and \(\mathbf{Y}\) are D-separated by \(\mathbf{Z}\) in \(\langle G,\mathbf{W}\rangle\) iff \(\mathbf{X}\) and \(\mathbf{Y}\) are D-separated by \(\mathbf{Z}\) in \(\langle G^{\prime},\mathbf{W}\setminus\mathbf{W}^{\prime}\rangle\)._

We now define the operation of functional projection which augments the original projection operation in [27, 28] in the presence of functional dependencies.

**Definition 12**.: _Let \(G\) be a DAG, \(\mathbf{V}\) be its observed variables, and \(\mathbf{W}\) be its hidden functional variables (\(\mathbf{W}\cap\mathbf{V}=\emptyset\)). The functional projection of \(G\) on \(\mathbf{V}\) is a DAG obtained by functionally eliminating variables \(\mathbf{W}\) from \(G\) then projecting the resulting DAG on variables \(\mathbf{V}\)._

We will now contrast functional projection and classical projection using the causal graph in Figure 1(a), assuming that the observed variables are \(\mathbf{V}=\{A,B,G,H,I\}\) and the functional variables are \(\mathbf{W}=\{C,D\}\). Applying classical projection to this causal graph yields the causal graph in Figure 1(b). To apply functional projection, we first functionally eliminate \(C,D\) from Figure 1(a), which yields Figure 1(c), then project Figure 1(c) or variables \(\mathbf{V}\) which yields the causal graph in Figure 1(d). So we now need to contrast Figure 1(b) (classical projection) with Figure 1(d) (functional projection). The latter is a strict subset of the former as it is missing two bidirected edges. One implication of this is that variables \(G\) and \(I\) are not d-separated by \(A\) in Figure 1(b) because they are not d-separated in Figure 1(a). However, they are D-separated in Figure 1(a) and hence they are d-separated in Figure 1(d). So functional projection yielded a DAG that exhibits more independencies. Again, this is because \(G\) and \(I\) are D-separated by \(A\) in the original DAG, a fact that is not visible to projection but is visible to (and exploitable by) functional projection.

An important corollary of functional projection is the following. Suppose all functional variables are hidden, then two observed variables are _D-separated_ in the causal graph \(G\) iff they are _d-separated_ in the functional-projected graph \(G^{\prime}\). This shows that such D-separations in \(G\) appear as classical d-separations in \(G^{\prime}\) which allows us to feed \(G^{\prime}\) into existing identifiability algorithms as we show later. This is a key enabler of some results we shall present next on testing functional identifiability.

## 5 Causal Identification with Functional Dependencies

Consider the causal graph \(G\) in Figure 2(a) and let \(\mathbf{V}=\{A,X,Y\}\) be its observed variables. According to Definition 4 of identifiability, the causal effect of \(X\) on \(Y\) is not identifiable with respect to \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}}\rangle\) where \(\mathcal{C}_{\mathbf{V}}=\{\Pr(A,X,Y)>0\}\). We can show this by projecting the

Figure 3: \(B\) is functional.

Figure 2: Contrasting projection with functional projection. \(C,D\) are functional. Hidden variables are circled.

causal graph \(G\) on the observed variables \(\mathbf{V}\), which yields the causal graph \(G^{\prime}\) in Figure 2(b), then applying the ID algorithm to \(G^{\prime}\) which returns FAIL. Suppose now that the hidden variable \(B\) is known to be functional. According to Definition 7 of F-identifiability, this additional knowledge reduces the number of considered models so it actually renders the causal effect identifiable -- the identifying formula is \(\Pr_{x}(y)=\sum_{a}\Pr(a)\Pr(y|a,x)\) as we show later. Hence, an unidentifiable causal effect became identifiable in light of knowledge that some variable is functional even without knowing the structural equations for this variable.

The question now is: How do we algorithmically test F-identifiablity? We will propose two techniques for this purpose, the first of which is geared towards exploiting existing algorithms for classical identifiability. This technique is based on eliminating functional variables from the causal graph while preserving F-identifiability, with the goal of getting to a point where F-identifiability becomes equivalent to classical identifiability. If we reach this point, we can use existing algorithms for classical identifiability, like the ID algorithm, to test F-identifiability. This can be subtle though since hidden functional variables behave differently from observed ones. We start with the following result.

**Theorem 13**.: _Let \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) be an F-identifiability tuple. If \(G^{\prime}\) is the result of functionally eliminating the hidden functional variables \((\mathbf{W}\setminus\mathbf{V})\) from \(G\), then the causal effect of \(\mathbf{X}\) on \(\mathbf{Y}\) is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) iff it is F-identifiable wrt \(\langle G^{\prime},\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{V}\cap\mathbf{ W}\rangle\)._

An immediate corollary of this theorem is that if all functional variables are hidden, then we can reduce the question of F-identifiability to a question of identifiability since \(\mathbf{V}\cap\mathbf{W}=\emptyset\) so F-identifiability wrt \(\langle G^{\prime},\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{V}\cap\mathbf{ W}=\emptyset\rangle\) collapses into identifiability wrt \(\langle G^{\prime},\mathbf{V},\mathcal{C}_{\mathbf{V}}\rangle\).

**Corollary 14**.: _Let \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) be an F-identifiability tuple where \(\mathcal{C}_{\mathbf{V}}=\{\Pr(\mathbf{V})>0\}\) and \(\mathbf{W}\) are all hidden. If \(G^{\prime}\) is the result of functionally projecting \(G\) on variables \(\mathbf{V}\), then the causal effect of \(\mathbf{X}\) on \(\mathbf{Y}\) is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) iff it is identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}}\rangle\).5_

Footnote 5: We are requiring the positivity constraint \(\Pr(\mathbf{V})>0\) as the projection operation in [28] requires it. If the projection operation only requires a weaker positivity constraint \(\mathcal{C}_{\mathbf{V}}^{\prime}\), we can replace \(\mathcal{C}_{\mathbf{V}}\) by \(\mathcal{C}_{\mathbf{V}}^{\prime}\) in Corollary 14.

This corollary suggests a method for using the ID algorithm, which is popular for testing identifiability, to establish F-identifiability by coupling ID with functional projection instead of classical projection. Consider the causal graph \(G\) in Figure 3(a) with observed variables \(\mathbf{V}=\{A,B,C,F,X,Y\}\). The causal effect of \(X\) on \(Y\) is not identifiable under \(\Pr(\mathbf{V})>0\): projecting \(G\) on observed variables \(\mathbf{V}\) yields the causal graph \(G^{\prime}\) in Figure 3(b) and the ID algorithm produces FAIL on \(G^{\prime}\). Suppose now that the hidden variables \(\{D,E\}\) are functional. To test whether the causal effect is F-identifiable using Corollary 14, we functionally project \(G\) on the observed variables \(\mathbf{V}\) which yields the causal graph \(G^{\prime\prime}\) in Figure 3(c). Applying the ID algorithm to \(G^{\prime\prime}\) produces the following identifying formula: \(\Pr_{x}(y)=\sum_{bf}\Pr(f|b,x)\sum_{acx^{\prime}}\Pr(y|a,b,c,f,x^{\prime})\Pr (a,b,c,x^{\prime})\) so \(\Pr_{x}(y)\) is F-identifiable.

We stress again that Corollary 14 and the corresponding F-identifiability algorithm apply only when all functional variables are hidden. We now treat the case when some of the functional variables are observed. The subtlety here is that, unlike hidden functional variables, eliminating an observed functional variable does not always preserve F-identifiability. However, the following result identifies conditions that guarantees the preservation of F-identifiability in this case. If all observed functional variables satisfy these conditions, then we can again reduce F-identifiability into identifiability so we can exploit existing methods for identifiability like the ID algorithm and do-calculus.

**Theorem 15**.: _Let \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) be an F-identifiability tuple. Let \(\mathbf{Z}\) be a set of observed functional variables that are neither treatments nor outcomes, are separable from \(\mathcal{C}_{\mathbf{V}},\) and that have observed

Figure 4: Variables \(A,B,C,F,X,Y\) are observed. Variables \(D,E\) are functional (and hidden).

parents. If \(G^{\prime}\) is the result of functionally eliminating variables \(\mathbf{Z}\) from \(G\), then the causal effect of \(\mathbf{X}\) on \(\mathbf{Y}\) is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) iff it is F-identifiable wrt \(\langle G^{\prime},\mathbf{V}\setminus\mathbf{Z},\mathcal{C}_{\mathbf{V}}, \mathbf{W}\setminus\mathbf{Z}\rangle\)._

We now have the following important corollary of Theorems 13 & 15 which subsumes Corollary 14.

**Corollary 16**.: _Let \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) be an F-identifiability tuple where \(\mathcal{C}_{\mathbf{V}}=\{\Pr(\mathbf{V}\setminus\mathbf{W})>0\}\) and every variable in \(\mathbf{W}\cap\mathbf{V}\) satisfies the conditions of Theorem 15. If \(G^{\prime}\) is the result of functionally projecting \(G\) on \(\mathbf{V}\setminus\mathbf{W}\), then the causal effect of \(\mathbf{X}\) on \(\mathbf{Y}\) is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) iff it is identifiable wrt \(\langle G^{\prime},\mathbf{V}\setminus\mathbf{W},\mathcal{C}_{\mathbf{V}}\rangle\)._

Consider again the causal effect of \(X\) on \(Y\) in graph \(G\) of Figure 3(a) with observed variables \(\mathbf{V}=\{A,B,C,F,X,Y\}\). Suppose now that the observed variable \(F\) is also functional (in addition to the hidden functional variables \(D,E\)) and assume \(\Pr(A,B,C,X,Y)>0\). Using Corollary 16, we can functionally project \(G\) on \(A,B,C,X,Y\) to yield the causal graph \(G^{\prime}\) in Figure 3(d), which reduces F-identifiability on \(G\) to classical identifiability on \(G^{\prime}\). Since strict positivity holds in \(G^{\prime}\), we can apply any existing identifiability algorithm and conclude that the causal effect is not identifiable. For another scenario, suppose that the observed variable \(B\) (instead of \(F\)) is functional and we have \(\Pr(A,C,F,X,Y)>0\). Again, using Corollary 16, we functionally project \(G\) onto \(A,C,F,X,Y\) to yield the causal graph \(G^{\prime\prime}\) in Figure 3(e), which reduces F-identifiability on \(G\) to classical identifiability on \(G^{\prime\prime}\). If we apply the ID algorithm to \(G^{\prime\prime}\) we get the identifying formula (which we denote as Eq. 1): \(\Pr_{x}(y)=\sum_{af}\Pr(f|a,x)\sum_{cx^{\prime}}\Pr(y|a,c,f,x^{\prime})\Pr(a,c,x^{\prime})\). In both scenarios above, we were able to test F-identifiability using an existing algorithm for identifiability.

Corollary 16 (and Theorem 15) has yet another key application: it can help us pinpoint observations that are not essential for identifiability. To illustrate, consider the second scenario above where the observed variable \(B\) is functional in the causal graph \(G\) of Figure 3(a). The fact that Corollary 16 allowed us to eliminate variable \(B\) from \(G\) implies that observing this variable is not needed for rendering the causal effect F-identifiable and, hence, is not needed for computing the causal effect. This can be seen by examining the identifying formula (Eq. 1) which does not contain variable \(B\). This application of Corollary 16 can be quite significant in practice, especially when some variables are expensive to measure (observe), or when they may raise privacy concerns; see, e.g., [45, 46].

Theorems 13 & 15 are more far-reaching than what the above discussion may suggest. In particular, even if we cannot eliminate every (observed) functional variable using these theorems, we may still be able to reduce F-identifiability to identifiability due to the following result.

**Theorem 17**.: _Let \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) be an F-identifiability tuple. If every functional variable has at least one hidden parent, then a causal effect of \(\mathbf{X}\) on \(\mathbf{Y}\) is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) iff it is identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}}\rangle\)._

That is, if we still have functional variables in the causal graph after applying Theorems 13 & 15, and if each such variable has at least one hidden parent, then F-identifiability is equivalent to identifiability.

The method we presented thus far for testing F-identifiability is based on eliminating functional variables from the causal graph, followed by applying existing tools for causal effect identification such as the project-ID algorithm and the do-calculus. This F-identifiability method is complete if every observed functional variable either satisfies the conditions of Theorem 15 or has at least one hidden parent that is not functional. This elimination-based method not only tests identifiability but also provides an identifying formula if the causal effect turns out to be identifiable.

We next present another technique for reducing F-identifiability to identifiability. This method is more general and much more direct than the previous one, but it does not allow us to fully exploit some existing tools like the ID algorithm due to the positivity assumptions they make. The new method is based on pretending that some of the hidden functional variables are actually observed and is inspired by Proposition 10 which reduces D-separation to d-separation using a similar technique.

**Theorem 18**.: _Let \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) be an F-identifiability tuple where \(\mathcal{C}_{\mathbf{V}}=\{\Pr(X)>0,X\in\mathbf{X}\}\). A causal effect of \(\mathbf{X}\) on \(\mathbf{Y}\) is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) iff it is identifiable wrt \(\langle G,\mathcal{C}_{\mathbf{V}},\mathbf{V}^{\prime}\rangle\) where \(\mathbf{V}^{\prime}\) is obtained as follows. Initially, \(\mathbf{V}^{\prime}=\mathbf{V}\). Repeat until \(\mathbf{V}^{\prime}\) stops changing: add to \(\mathbf{V}^{\prime}\) a functional variable from \(\mathbf{W}\) if its parents are in \(\mathbf{V}^{\prime}\)._

Consider the causal effect of \(X\) on \(Y\) in graph \(G\) of Figure 3(a) and suppose the observed variables are \(\mathbf{V}=\{A,B,C,X,Y\}\), the functional variables are \(\{D,E,F\}\) and we have \(\Pr(X)>0\). By Theorem 18, the causal effect of \(X\) on \(Y\) is F-identifiable iff it is identifiable in \(G\) while pretendingthat variables \(\mathbf{V}^{\prime}=\{A,B,C,D,E,F,X,Y\}\) are all observed. In this case, the casual effect is not identifiable but we cannot obtain this answer by applying an identifiability algorithm that requires positivity constraints which are stronger than \(\Pr(X)>0\). If we have stronger positivity constraints that imply \(\Pr(X)>0,X\in\mathbf{X}\), then only the if part of Theorem 18 will hold, assuming \(\mathcal{C}_{\mathbf{V}}\) and \(\mathbf{W}\) are consistent. That is, confirming identifiability wrt \(\langle G,\mathcal{C}_{\mathbf{V}},\mathbf{V}^{\prime}\rangle\) will confirm F-identifiability wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) but if identifiability is not confirmed then F-identifiability may still hold. This suggests that, to fully exploit the power of Theorem 18, one would need a new class of identifiability algorithms that can operate under the weakest possible positivity constraints.

## 6 Conclusion

We studied the identification of causal effects in the presence of a particular type of knowledge called functional dependencies. This augments earlier works that considered other types of knowledge such as context-specific independence. Our contributions include formalizing the notion of functional identifiability; the introduction of an operation for eliminating functional variables from a causal graph that comes with stronger guarantees compared to earlier elimination methods; and the employment (under some conditions) of existing algorithms, such as the ID algorithm, for testing functional identifiability and for obtaining identifying formulas. We also provided a complete reduction of functional identifiability to classical identifiability under very weak positivity constraints, and showed how our results can be used to reduce the number of variables needed in observational data.

## Acknowledgements

We wish to thank Scott Mueller, Jin Tian, and anonymous reviewers for providing valuable feedback on earlier versions of this paper. This work has been partially supported by ONR grant N000142212501.

## References

* [1] Judea Pearl and Dana Mackenzie. _The Book of Why: The New Science of Cause and Effect_. Basic Books, 2018.
* [2] Judea Pearl. _Causality: Models, Reasoning, and Inference_. Cambridge University Press, second edition, 2009.
* [3] Judea Pearl. Causal diagrams for empirical research. _Biometrika_, 82(4):669-688, 1995. ISSN 00063444.
* [4] Peter Spirtes, Clark Glymour, and Richard Scheines. _Causation, Prediction, and Search, Second Edition_. Adaptive computation and machine learning. MIT Press, 2000. ISBN 978-0-262-19440-2.
* [5] Guido W. Imbens and Donald B. Rubin. _Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction_. Cambridge University Press, 2015.
* [6] Jonas Peters, Dominik Janzing, and Bernhard Scholkopf. _Elements of Causal Inference: Foundations and Learning Algorithms_. MIT Press, 2017.
* [7] Miguel A. Hernan and James M. Robins. _Causal Inference: What If_. Boca Raton: Chapman & Hall/CRC, 2020.
* [8] Judea Pearl. [bayesian analysis in expert systems]: Comment: Graphical models, causality and intervention. _Statistical Science_, 8(3):266-269, 1993.
* [9] Yimin Huang and Marco Valtorta. Identifiability in causal bayesian networks: A sound and complete algorithm. In _AAAI_, pages 1149-1154. AAAI Press, 2006.
* [10] Ilya Shpitser and Judea Pearl. Identification of joint interventional distributions in recursive semi-markovian causal models. In _AAAI_, pages 1219-1226. AAAI Press, 2006.

* [11] Marco Zaffalon, Alessandro Antonucci, and Rafael Cabanas. Causal Expectation-Maximisation. In _WHY Workshop, NeurIPS_, 2021. doi: 10.48550/ARXIV.2011.02912. https://arxiv.org/abs/2011.02912.
* [12] Marco Zaffalon, Alessandro Antonucci, Rafael Cabanas, and David Huber. Approximating counterfactual bounds while fusing observational, biased and randomised data sources. _International Journal of Approximate Reasoning_, 162:109023, 2023.
* [13] Adnan Darwiche. Causal inference with tractable circuits. In _WHY Workshop, NeurIPS_, 2021. https://arxiv.org/abs/2202.02891.
* [14] David Huber, Yizuo Chen, Alessandro Antonucci, Adnan Darwiche, and Marco Zaffalon. Tractable bounding of counterfactual queries by knowledge compilation. _Sixth Workshop on Tractable Probabilistic Modeling @ UAI 2023_, 2023. URL https://tractable-probabilistic-modeling.github.io/tpm2023/papers.
* [15] Yonghan Jung, Jin Tian, and Elias Bareinboim. Estimating causal effects using weighting-based estimators. In _AAAI_, pages 10186-10193. AAAI Press, 2020.
* [16] Yonghan Jung, Jin Tian, and Elias Bareinboim. Learning causal effects via weighted empirical risk minimization. In _NeurIPS_, 2020.
* [17] Yonghan Jung, Jin Tian, and Elias Bareinboim. Estimating identifiable causal effects through double machine learning. In _AAAI_, pages 12113-12122. AAAI Press, 2021.
* [18] Yonghan Jung, Jin Tian, and Elias Bareinboim. Estimating identifiable causal effects on markov equivalence class through double machine learning. In _ICML_, volume 139 of _Proceedings of Machine Learning Research_, pages 5168-5179. PMLR, 2021.
* [19] Sanghack Lee, Juan D. Correa, and Elias Bareinboim. Identifiability from a combination of observations and experiments. In _AAAI_, pages 13677-13680. AAAI Press, 2020.
* [20] Amir Mohammad Abouei, Ehsan Mokhtarian, and Negar Kiyavash. s-id: Causal effect identification in a sub-population. In _AAAI_, pages 20302-20310. AAAI Press, 2024.
* [21] Santtu Tikka, Antti Hyttinen, and Juha Karvanen. Identifying causal effects via context-specific independence relations. In _NeurIPS_, pages 2800-2810, 2019.
* [22] Judea Pearl. _Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference_. Morgan Kaufmann, 1988.
* [23] Adnan Darwiche. An advance on variable elimination with applications to tensor-based computation. In _ECAI_, volume 325 of _Frontiers in Artificial Intelligence and Applications_, pages 2559-2568. IOS Press, 2020.
* [24] Yizuo Chen, Arthur Choi, and Adnan Darwiche. Supervised learning with background knowledge. In _10th International Conference on Probabilistic Graphical Models (PGM)_, 2020.
* [25] Yizuo Chen and Adnan Darwiche. On the definition and computation of causal treewidth. In _UAI, Proceedings of the 38th Conference on Uncertainty in Artificial Intelligence_, 2022.
* [26] Yunqiu Han, Yizuo Chen, and Adnan Darwiche. On the complexity of counterfactual reasoning. In _IJCAI_, pages 5676-5684. ijcai.org, 2023.
* [27] Thomas S. Verma. Graphical aspects of causal models. _Technical Report_, R-191, 1993.
* [28] Jin Tian and Judea Pearl. On the testable implications of causal models with hidden variables. In _UAI_, pages 519-527. Morgan Kaufmann, 2002.
* [29] Jin Tian and Judea Pearl. On the identification of causal effects. _Technical Report_, R-290-L, 2003.
* [30] Manabu Kuroki and Masami Miyakawa. Identifiability criteria for causal effects of joint interventions. _Journal of the Japan Statistical Society_, 29(2):105-117, 1999.

* [31] Yaroslav Kivva, Ehsan Mokhtarian, Jalal Etesami, and Negar Kiyavash. Revisiting the general identifiability problem. In _UAI_, volume 180 of _Proceedings of Machine Learning Research_, pages 1022-1030. PMLR, 2022.
* [32] Inwoo Hwang, Yesong Choe, Yeahoon Kwon, and Sanghack Lee. On positivity condition for causal inference. In _ICML_. OpenReview.net, 2024.
* [33] Alexander Balke and Judea Pearl. Counterfactuals and policy analysis in structural models. In _UAI_, pages 11-18. Morgan Kaufmann, 1995.
* [34] David Galles and Judea Pearl. An axiomatic characterization of causal counterfactuals. _Foundations of Science_, 3(1):151-182, 1998.
* [35] Joseph Y. Halpern. Axiomatizing causal reasoning. _Journal of Artificial Intelligence Research_, 12:317-337, 2000.
* [36] Terry A. Halpin and Tony Morgan. _Information modeling and relational databases (2. ed.)_. Morgan Kaufmann, 2008.
* Normal Forms and All That Jazz_. O'Reilly, 2012.
* [38] Nevin L. Zhang and David L. Poole. Exploiting causal independence in bayesian network inference. _J. Artif. Intell. Res._, 5:301-328, 1996.
* [39] Rina Dechter. Bucket elimination: A unifying framework for probabilistic inference. In _Proceedings of the Twelfth Annual Conference on Uncertainty in Artificial Intelligence (UAI)_, pages 211-219, 1996.
* [40] Adnan Darwiche. _Modeling and Reasoning with Bayesian Networks_. Cambridge University Press, 2009.
* [41] Dan Geiger and Judea Pearl. On the logic of causal models. In _UAI_, pages 3-14. North-Holland, 1988.
* [42] Dan Geiger, Thomas Verma, and Judea Pearl. Identifying independence in bayesian networks. _Networks_, 20(5):507-534, 1990.
* [43] Judea Pearl. Fusion, propagation, and structuring in belief networks. _Artif. Intell._, 29(3):241-288, 1986.
* [44] Thomas Verma and Judea Pearl. Causal networks: semantics and expressiveness. In _UAI_, pages 69-78. North-Holland, 1988.
* [45] Santtu Tikka and Juha Karvanen. Enhancing identification of causal effects by pruning. _J. Mach. Learn. Res._, 18:194:1-194:23, 2017.
* [46] Benito van der Zander, Maciej Liskiewicz, and Johannes Textor. Separators and adjustment sets in causal graphs: Complete criteria and an algorithmic framework. _Artif. Intell._, 270:1-40, 2019.
* [47] Ilya Shpitser and Judea Pearl. Complete identification methods for the causal hierarchy. _J. Mach. Learn. Res._, 9:1941-1979, 2008.
* [48] Adnan Darwiche. An advance on variable elimination with applications to tensor-based computation. In _Proceedings of the 24th European Conference on Artificial Intelligence (ECAI)_, 2020.
* [49] Adnan Darwiche. A differential approach to inference in Bayesian networks. _J. ACM_, 50(3):280-305, 2003.

More On Projection and ID Algorithm

As mentioned in the main paper, the project-ID algorithm involves two steps: the projection operation and the ID algorithm. We will review more technical details of each step in this section.

### Projection

The projection [27, 28, 29] of \(G\) onto \(\mathbf{V}\) constructs a new DAG \(G^{\prime}\) over variables \(\mathbf{V}\) as follows. Initially, DAG \(G^{\prime}\) contains variables \(\mathbf{V}\) but no edges. Then for every pair of variables \(X,Y\in\mathbf{V}\), an edge is added from \(X\) to \(Y\) to \(G^{\prime}\) if \(X\) is a parent of \(Y\) in \(G\), or if there exists a directed path from \(X\) to \(Y\) in \(G\) such that none of the internal nodes on the path is in \(\mathbf{V}\). A bidirected edge \(X\)\(\leftarrow\)\(\cdots\)\(\rightarrow\)\(Y\) is further added between every pair of variables \(X\) and \(Y\) in \(G^{\prime}\) if there exists a divergent path6 between \(X\) and \(Y\) in \(G\) such that none of the internal nodes on the path is in \(\mathbf{V}\). For example, the projection of the DAG in Figure 0(a) onto \(A,C,D,X_{1},X_{2},Y\) yields Figure 0(c). A bidirected edge \(X\)\(\leftarrow\)\(\cdots\)\(\rightarrow\)\(Y\) is compact notation for \(X\gets H\to Y\) where \(H\) is an auxiliary hidden variable. Hence, the projected DAG in Figure 0(c) can be interpreted as a classical DAG but with additional, hidden root variables.

Footnote 6: A divergent path between \(X\) and \(Y\) is a path in the form of \(X\leftarrow\cdots\gets U\rightarrow\cdots\to Y\).

The projection operation is guaranteed to produce a DAG \(G^{\prime}\) in which hidden variables are all roots and each has exactly two children. Graphs that satisfy this property are called _semi-Markovian_ and can be fed as inputs to the ID algorithm for testing identifiability [10]. Moreover, projection preserves some properties of \(G\), such as d-separation [27] among \(\mathbf{V}\), which guarantees that identifiabilty is preserved when working with \(G^{\prime}\) instead of \(G\)[28].

### ID Algorithm

After obtaining a projected causal graph, we can apply the ID algorithm for identifying causal effects [10, 47]. The algorithm returns either an identifying formula if the causal effect is identifiable or FAIL otherwise. The algorithm is sound since each line of the algorithm can be proved with basic probability rules and do-calculus. The algorithm is also complete since a causal graph must contain a _hedge_, a graphical structure that induces the unidentifiability, if the algorithm returns FAIL. The algorithm, however, is only sound and complete under certain positivity constraints, which are weaker but more subtle than strict positivity (\(\Pr(\mathbf{V})>0\)).

The positivity constraints required by ID can be summarized as follows (\(\mathbf{X}\) are the treatment variables): (1) \(\Pr(\mathbf{X}|\mathbf{P})>0\) where \(\mathbf{P}=\text{Parents}(\mathbf{X})\setminus\mathbf{X}\), and (2) \(\Pr(\mathbf{Z})>0\) for all quantities \(\Pr(\mathbf{S}|\mathbf{Z})\) considered by the ID algorithm. The second constraint depends on a particular run of the ID algorithm and can be interpreted as follows. First, if the ID algorithm returns FAIL then the causal effect is not identifiable even under the strict positivity constraint \(\Pr(\mathbf{V})>0\). However, if the ID algorithm returns "identifiable" then the causal effect is identifiable under the above constraints which are now well defined given a particular run of the ID algorithm. We illustrate with an example next.

Consider the causal graph on the right which contains observed variables \(\{A,B,C,X,Y\}\). Suppose we are interested in the causal effect of \(X\) on \(Y\), applying the ID algorithm returns the following identifying formula: \(\Pr_{x}(y)\)\(=\)\(\sum_{abc}\Pr(c|a,b,x)\sum_{x^{\prime}}\Pr(y|a,b,c,x^{\prime})\Pr(a,b,x^{ \prime}).\) The positivity constraint extracted from this run of the algorithm is \(\Pr(a,b,c,x)>0\) for all \(a,b,c,x\). That is, we can only safely declare the causal effect identifiable based on the ID algorithm if this positivity constraint is satisfied.

## Appendix B Functional Elimination for CBNs

The functional elimination in Definition 9 removes functional variables from a DAG \(G\) and yields another DAG \(G^{\prime}\) on the remaining variables. We have shown in the main paper that the functional elimination preserves the D-separations. Here we extend the notion of functional elimination to Causal Bayesian networks (CBNs) which contain not only a causal graph (DAG) but also CPTs. We show that the (extended) functional elimination preserves the marginal distribution on the remaining variables. That is, given any CBN with the causal graph \(G\), we can construct another CBN with the causal graph \(G^{\prime}\) such that the two CBNs induce a same distribution on the variables in \(G^{\prime}\), where \(G^{\prime}\) is the result of eliminating functional variables from \(G\). Moreover, we show that the functional elimination operation further preserves the causal effects, which makes it applicable to the causal identification. This extended version of functional elimination and the corresponding results will be used for the proofs in Appendix C.

Recall that a CBN \(\langle G,\mathcal{F}\rangle\) contains a causal graph \(G\) and a set of CPTs \(\mathcal{F}\). We first extend the definition of functional elimination (Definition 9) from DAGs to CBNs.

**Definition 19**.: _The functional elimination of a functional variable \(X\) from a CBN \(\langle G,\mathcal{F}\rangle\) yields another CBN \(\langle G^{\prime},\mathcal{F}^{\prime^{\prime}}\rangle\) obtained as follows. The DAG \(G^{\prime}\) is obtained from \(G\) by Definition 9. For each child \(C\) of \(X\), its CPT in \(\mathcal{F}^{\prime}\) is \((\sum_{X}f_{X}f_{C})\) where \(f_{X}\), \(f_{C}\) are the corresponding CPTs in \(\mathcal{F}\)._

We first show that the new CPTs produced by Definition 19 are well-defined.

**Proposition 20**.: _Let \(f_{X}\) and \(f_{Y}\) be the CPTs for variables \(X\) and \(Y\) in a CBN, then \((\sum_{X}f_{X}f_{Y})\) is a valid CPT for \(Y\)._

The next proposition shows that functional elimination preserves the functional dependencies.

**Proposition 21**.: _Let \(\mathcal{M}^{\prime}\) be the CBN resulting from functionally eliminating a functional variable from a CBN \(\mathcal{M}\). Then each variable (from \(\mathcal{M}^{\prime}\)) is functional in \(\mathcal{M}^{\prime}\) if it is functional in \(\mathcal{M}\)._

The next theorem shows that the order of functional elimination does not matter.

**Proposition 22**.: _Let \(\mathcal{M}\) be a CBN and \(\pi_{1}\), \(\pi_{2}\) be two variable orders over a set of functional variables \(\mathbf{W}\). Then functionally eliminating \(\mathbf{W}\) from \(\mathcal{M}\) according to \(\pi_{1}\) and \(\pi_{2}\) yield the same CBN._

The next result shows that eliminating functional variables preserves the marginal distribution.

**Theorem 23**.: _Consider a CBN \(\mathcal{M}\) which induces \(\Pr\). Let \(\mathcal{M}^{\prime}\) be the result of functionally eliminating a set of functional variables \(\mathbf{W}\) from \(\mathcal{M}\) which induces \(\Pr^{\prime}\). Then \(\Pr^{\prime}=\sum_{\mathbf{W}}\Pr\)._

One key property of functional elimination is that it preserves the interventional distribution over the remaining variables. This property allows us to eliminate functional variables from a causal graph and estimate the causal effects in the resulting graph.

**Theorem 24**.: _Let \(\mathcal{M}^{\prime}\) be the CBN over variables \(\mathbf{V}\) resulting from functionally eliminating a set of functional variables \(\mathbf{W}\) from a CBN \(\mathcal{M}\). Then \(\mathcal{M}^{\prime}\) and \(\mathcal{M}\) attain the same \(\Pr_{\mathbf{x}}(\mathbf{V})\) for any \(\mathbf{X}\subseteq\mathbf{V}\)._

## Appendix C Proofs

The proofs of the results will be ordered slightly different from the order they appear in the main body of the paper.

#### Proof of Proposition 5

Proof.: Our goal is to construct two different parameterizations \(\mathcal{F}^{1}\) and \(\mathcal{F}^{2}\) that induce the same \(\Pr(\mathbf{V})\) but different \(\Pr_{\mathbf{x}}(\mathbf{y})\). This is done by first creating a parameterization \(\mathcal{F}\) which contains strictly positive CPTs for all variables, and then constructing \(\mathcal{F}^{1}\) and \(\mathcal{F}^{2}\) based on \(\mathcal{F}\).

Let \(\mathcal{P}\) be the directed path from \(X=X_{i}\) to \(Y\), denoted \(X\to Z\rightarrow\cdots\to Y\) which does not contain any treatment variables other than \(X\). Let \(\mathbf{P}_{X}\) be the parents of \(X\) in \(G\). For each node \(M\) on the path, let \(\mathbf{P}_{M}\) be the parents of \(M\) except for the parent that lies on \(\mathcal{P}\). Moreover, for each variable \(M\) on \(\mathcal{P}\), we will only modify the conditional probability for a single state \(m^{*}\) of \(M\), where \(x^{*}\in\mathbf{x}\) is the treated state of \(X\). Let \(\epsilon\) be an arbitrarily small constant (close to 0), we next show the modifications for the CPTs in \(\mathcal{F}^{1}\).

\[f^{1}(x|\mathbf{p}_{X})=\begin{cases}0&\text{if }x=x^{*}\\ 1/(|X|-1),&\text{otherwise}\end{cases}\]

\[f^{1}(z|x,\mathbf{p}_{Z})=\begin{cases}1-\epsilon,&\text{if }x=x^{*},z=z^{*}\\ \epsilon/(|Z|-1),&\text{if }x=x^{*},z\neq z^{*}\\ \epsilon,&\text{if }x\neq x^{*},z=z^{*}\\ (1-\epsilon)/(|Z|-1),&\text{if }x\neq x^{*},z\neq z^{*}\end{cases}\]For every variable \(T\notin\{X,Z\}\) which has parent \(Q\) on the path \(\mathcal{P}\), we assign

\[f^{1}(t|q,\mathbf{p}_{T})=\begin{cases}1-\epsilon,&\text{if }q=q^{*},t=t^{*}\\ \epsilon/(|T|-1),&\text{if }q=q^{*},t\neq t^{*}\\ \epsilon,&\text{if }q\neq q^{*},t=t^{*}\\ (1-\epsilon)/(|T|-1),&\text{if }q\neq q^{*},t\neq t^{*}\end{cases}\]

We assign the same CPTs for \(X\) and all variables \(T\notin\{X,Z\}\) but a different CPT for \(Z\) in \(\mathcal{F}^{2}\).

\[f^{2}(z|x,\mathbf{p}_{Z})=\begin{cases}\epsilon,&\text{if }x=x^{*},z=z^{*}\\ (1-\epsilon)/(|Z|-1),&\text{if }x=x^{*},z\neq z^{*}\\ \epsilon,&\text{if }x\neq x^{*},z=z^{*}\\ (1-\epsilon)/(|Z|-1),&\text{if }x\neq x^{*},z\neq z^{*}\end{cases}\]

The two parameterizations \(\mathcal{F}^{1}\) and \(\mathcal{F}^{2}\) induce the same \(\Pr(\mathbf{V})\) where \(\Pr(\mathbf{v})=0\) if \(x^{*}\in\mathbf{v}\) and \(\Pr(\mathbf{v})>0\) otherwise. We next show that the parameterization satisfies each positivity constraint \(\Pr(\mathbf{S}|\mathbf{Z})\) as long as it does not imply \(\Pr(X)>0\). We first show that \(X\in\mathbf{S}\) implies \(\Pr(X)>0\). This is because \(\Pr(\mathbf{S})=\sum_{\mathbf{z}}\Pr(\mathbf{S}|\mathbf{z})\Pr(\mathbf{z})\) and there must exist some instantiation \(\mathbf{z}\) where \(\Pr(\mathbf{z})>0\) and \(\Pr(\mathbf{S}|\mathbf{z})>0\) by constraint. This implies \(\Pr(\mathbf{S})>0\) and therefore \(\Pr(X)>0\). Hence, \(\mathcal{C}_{\mathbf{V}}\) does not contain such constraint \(\Pr(\mathbf{S}|\mathbf{Z})\) where \(X\in\mathbf{S}\). Suppose \(X\in\mathbf{Z}\), then \(\Pr(\mathbf{z})>0\) if and only if \(x^{*}\notin\mathbf{z}\). Moreover, since \(\Pr(\mathbf{v})>0\) whenever \(x^{*}\notin\mathbf{v}\), it is guaranteed that \(\Pr(\mathbf{S},\mathbf{z})>0\) when \(\Pr(\mathbf{z})>0\), which implies \(\Pr(\mathbf{S}|\mathbf{Z})>0\). Finally, suppose \(X\notin(\mathbf{S}\cup\mathbf{Z})\), then \(\Pr(\mathbf{S},\mathbf{Z})=\sum_{x}\Pr(\mathbf{S},\mathbf{Z},x)>0\). Hence, the positivity constraint is satisfied by both parameterizations. By construction, \(\Pr^{1}\) and \(\Pr^{2}\) induce different values for the causal effect \(\Pr_{\mathbf{x}}(\mathbf{y})\) since the probability of \(Y=y^{*}\) under the treatment \(do(X=x^{*})\) will be different for the two parameterizations. 

**Proposition 25**.: _Let \(G\) be a causal graph and \(\mathbf{V}\) be its observed variables. A set of functional variables \(\mathbf{W}\) is consistent with positivity constraints \(\mathcal{C}_{\mathbf{V}}\) if no single constraint in \(\mathcal{C}_{\mathbf{V}}\) mentions both \(W\in\mathbf{W}\) and a set \(\mathbf{H}_{W}\) that intercepts all directed paths from non-functional variables to \(W\)._

Proof of Proposition 25.: We construct a parameterization \(\mathcal{F}\) and show that the distribution \(\Pr\) induced by \(\mathcal{F}\) satisfies the \(\mathcal{C}_{\mathbf{V}}\), which ensures the consistency. The states of each variable \(V\) are represented in the form of \((s_{V},p_{1},\ldots,p_{m})\) where \(s_{V}\) and \(p_{i}\) (\(i\in\{1,\ldots,m\}\)) are all binary indicator (0 or 1). Specifically, each of the \(p_{i}\) corresponds to a "functional descendant paths" of \(V\) defined as follows: a functional descendant path of \(V\) is a directed path that starts with \(V\) and that all variables on the path (excluding \(V\)) are functional. Suppose \(V\) does not have any functional descendant paths, then the states of \(V\) is simply represented as \((s_{V})\).

We next show how to assign CPTs for each variable in the causal graph \(G\) based on whether the variable is functional. For each non-functional variable, we assign a uniform distribution. For each functional variable \(W\) whose parents are \(T_{1},\ldots,T_{n}\) and whose functional descendant paths are \(\mathcal{P}_{1},\ldots,\mathcal{P}_{m}\), we assign the CPT \(f_{W}\) as follows:

\[\begin{split} s_{W}&\gets p_{Ind(T_{1},W)}^{T_ {1}}\oplus\cdots\oplus p_{Ind(T_{n},W)}^{T_{n}}\\ p_{1}&\gets p_{1,1}^{T_{1}}\oplus\cdots\oplus p _{n,1}^{T_{n}}\\ &\cdots\\ p_{m}&\gets p_{1,m}^{T_{1}}\oplus\cdots\oplus p_{n,m}^{ T_{n}}\end{split}\] (1)

where \(Ind(T_{i},W)\) denotes the index assigned to the path \(\{(T_{i},W)\}\) (which contains a single edge) in the state of \(T^{i}\), and \(p_{i,j}^{T_{i}}\) denotes the indicator in the state of \(T_{i}\) for the functional descendant path \(\mathcal{P}^{\prime}\) that contains the functional descendant path \(\mathcal{P}_{j}\), i.e., \(\mathcal{P}^{\prime}=\{(T_{i},W)\}\cup\mathcal{P}_{j}\).

For simplicity, we call the set of variables \(\mathbf{H}_{W}\) that satisfies the condition in the proposition a "functional ancestor set" of \(W\). We show that \(\Pr(\mathbf{S},\mathbf{Z})>0\) for each positivity constraint in the form of \(\Pr(\mathbf{S}|\mathbf{Z})>0\). Let \(\mathbf{W}\subseteq\mathbf{S}\cup\mathbf{Z}\) be a subset of functional variables. Since \(\mathbf{S}\cup\mathbf{Z}\) does not contain any functional ancestor set of \(W\) for each \(W\in\mathbf{W}\), it follows that there exist directed paths from a set of non-functional variables \(\mathcal{A}^{\prime}_{W}\) to \(W\) that are unblocked by \(\mathbf{M}=\mathbf{S}\cup\mathbf{Z}\setminus\{W\}\) and contain only functional variables (excluding \(\mathcal{A}^{\prime}_{W}\)). We can further assume that \(\mathcal{A}^{\prime}_{W}\) is chosen such that the set \(\mathcal{A}_{W}=\mathbf{M}\cup\mathcal{A}_{W}^{\prime}\) forms a valid functional ancestor set for \(W\). We next show that for any state \(w\) of \(W\) and instantiation \(\mathbf{m}\) of \(\mathbf{M}\), there exists at least one instantiation \(\mathbf{a}\) of \(\mathcal{A}_{W}^{\prime}\) such that \(\Pr(w,\mathbf{m},\mathbf{a})>0\).

Let \(\mathbf{P}^{W}\) denote the set of all directed paths from \(\mathcal{A}_{W}\) to \(W\) that do not contain \(\mathcal{A}_{W}\) (except for the first node on the path). Let \(\mathbf{P}_{1}^{W}\subseteq\mathbf{P}^{W}\) be the paths that start with a variable in \(\mathbf{M}\), and \(\mathbf{P}_{2}^{W}\subseteq\mathbf{P}^{W}\) be other paths that start with a variable in \(\mathcal{A}_{W}^{\prime}\). Moreover, for any path \(\mathcal{P}\), let \(\mathtt{pathval}(\mathcal{P})\) be the binary indicator (e.g., \(p_{1}\)) for \(\mathcal{P}\) in the state of \(\mathcal{P}(0)\) (first variable in \(\mathcal{P}\)). Since the value assignments for \(\mathtt{pathval}(\mathcal{P})\) are independent for different \(\mathcal{P}\)'s, we can always find some instantiation \(\mathbf{a}\in\mathcal{A}_{W}^{\prime}\) such that the following equality holds given \(w\) and \(\mathbf{m}\):

\[\bigoplus_{\mathcal{P}_{2}\in\mathbf{P}_{2}^{W}}\mathtt{pathval}(\mathcal{P} _{2})=s_{W}\oplus\bigoplus_{\mathcal{P}_{1}\in\mathbf{P}_{1}^{W}}\mathtt{ pathval}(\mathcal{P}_{1})\]

We next assign values for other path indicators of a such that the indicators for the functional descendant paths in the state \(w\) are set correctly. In particular, for each functional descendant path \(\mathcal{P}\) of \(W\), let \(\mathbf{P}\) be the set of functional descendant paths of \(\mathcal{A}_{W}\) that do not contain \(\mathcal{A}_{W}\) (except for the first node on the path) and that contain \(\mathcal{P}\) as a sub-path. Let \(\mathbf{P}_{1}\subseteq\mathbf{P}\) be the paths that start with a variable in \(\mathbf{M}\), and \(\mathbf{P}_{2}\subseteq\mathbf{P}\) be other paths that start with a variable in \(\mathcal{A}_{W}^{\prime}\). Again, since all the indicators for paths in \(\mathcal{P}\) are independent, we can assign the indicators for \(\mathbf{a}\in\mathcal{A}_{W}^{\prime}\) such that

\[\bigoplus_{\mathcal{P}_{2}\in\mathbf{P}_{2}}\mathtt{pathval}(\mathcal{P}_{2}) =\mathtt{pathval}(\mathcal{P})\oplus\bigoplus_{\mathcal{P}_{1}\in\mathbf{P}_ {1}}\mathtt{pathval}(\mathcal{P}_{1})\]

Finally, we combine the cases for each individual \(W\in\mathbf{W}\) by creating the following set \(\mathcal{A}_{\mathbf{W}}=\bigcup_{W\in\mathbf{W}}\mathcal{A}_{W}\). Since all the functional descendant paths we considered for different \(W\)'s are disjoint, we can always find an assignment \(\mathbf{a}\) for \(\mathcal{A}_{\mathbf{W}}\) that is consistent with the functional dependencies (does not produce any zero probabilities). Consequently, there must exist some full instantiation \((\mathbf{u},\mathbf{v})\) compatible with \(\mathbf{s}\), \(\mathbf{z}\), a such that \(\Pr(\mathbf{u},\mathbf{v})>0\), which implies \(\Pr(\mathbf{s},\mathbf{z})>0\). 

Proof of Proposition 20

Proof.: Suppose \(Y\) is not a child of \(X\) in the CBN, then \(\sum_{X}f_{X}f_{Y}=f_{Y}(\sum_{X}f_{X})\) which is guaranteed to be a CPT for \(Y\). Suppose \(Y\) is a child of \(X\). Let \(\mathbf{P}_{X}\) denote the parents of \(X\) and \(\mathbf{P}_{Y}\) denote the parents of \(Y\) excluding \(X\). The new factor \(g=\sum_{X}f_{X}f_{Y}\) is defined over \(\mathbf{P}_{X}\cup\mathbf{P}_{Y}\cup\{Y\}\). Consider each instantiation \(\mathbf{p}_{X}\) and \(\mathbf{p}_{Y}\), then \(\sum_{y}g(\mathbf{p}_{X},\mathbf{p}_{Y},y)=\sum_{y}\sum_{x}f_{X}(x|\mathbf{p }_{x})f_{Y}(y|\mathbf{p}_{Y},x)=\sum_{x}f_{X}(x|\mathbf{p}_{X})\sum_{y}f_{Y}(y| \mathbf{p}_{Y},x)=1\). Hence, \(g\) is a CPT for \(Y\). 

Proof of Proposition 21

Proof.: Let \(X\) be the functional variables that is functionally eliminated. By definition, the elimination only affects the CPTs for the children of \(X\). Hence, any functional variable that is not a child of \(X\) remains functional. For each child \(C\) of \(X\) that is functional, the new CPT \((\sum_{X}f_{X}f_{C})\) only contains values that are either 0 or 1 since both \(f_{X}\) and \(f_{C}\) are functional. 

Proof of Proposition 22

Proof.: First note that \(\pi_{2}\) can always be obtained from \(\pi_{1}\) by a sequence of "transpositions", where each transposition swaps two adjacent variables in the first sequence. Let \(\pi\) be an elimination order and let \(\pi^{\prime}\) be the elimination order resulted from swapping \(\pi_{i}=X\) and \(\pi_{i+1}=Y\) from the \(\pi\), i.e.,

\[\pi=(\ldots,X,Y,\ldots)\ \ \ \ \pi^{\prime}=(\ldots,Y,X,\ldots)\]

We show functional elimination according to \(\pi\) and \(\pi^{\prime}\) yield a same CBN, which can be applied inductively to conclude that elimination according to \(\pi_{1}\) and \(\pi_{2}\) yield a same CBN. Since \(\pi\) and \(\pi^{\prime}\) agree on a same elimination order up to \(X\), they yield a same CBN before eliminating variables \(X,Y\). It suffices to show the CBNs resulting from eliminating \((X,Y)\) and eliminating \((Y,X)\) are the same. Let \(\langle G,\Pr\rangle\) be the CBN before eliminating variables \(X,Y\). Suppose \(X\) and \(Y\) do not belong to a same family (which contains a variable and its parents), the elimination of \(X\) and \(Y\) are independent 

[MISSING_PAGE_FAIL:17]

**Proof of Theorem 24**

**Lemma 26**.: _Consider a CBN \(\langle G,\mathcal{F}\rangle\) and its mutilated CBN \(\langle G_{\mathbf{x}},\mathcal{F}_{\mathbf{x}}\rangle\) under \(do(\mathbf{x})\). Let \(W\) be a functional variable not in \(\mathbf{X}\) and let \(\langle G^{\prime},\mathcal{F}^{\prime}\rangle\) and \(\langle G^{\prime}_{\mathbf{x}},\mathcal{F}^{\prime}_{\mathbf{x}}\rangle\) be the results of functionally eliminating \(W\) from \(\langle G,\mathcal{F}\rangle\) and \(\langle G_{\mathbf{x}},\mathcal{F}_{\mathbf{x}}\rangle\), respectively. Then \(\langle G^{\prime}_{\mathbf{x}},\mathcal{F}^{\prime}_{\mathbf{x}}\rangle\) is the mutilated CBN for \(\langle G^{\prime},\mathcal{F}^{\prime}\rangle\)._

Proof.: First observe that the children of \(W\) in \(G\) and \(G_{\mathbf{x}}\) can only differ by the variables in \(\mathbf{X}\). Let \(\mathbf{C}_{1}\) be the children of \(W\) in both \(G\) and \(G_{\mathbf{x}}\) and let \(\mathbf{C}_{2}\) be the children of \(W\) in \(G\) but not in \(G_{\mathbf{x}}\). By the definition of mutilated CBN, \(W\) has the same set of parents and CPT in \(\langle G,\mathcal{F}\rangle\) and \(\langle G_{\mathbf{x}},\mathcal{F}_{\mathbf{x}}\rangle\). Similarly, each child \(C\in\mathbf{C}_{1}\) has the same set of parents and CPT in \(\langle G,\mathcal{F}\rangle\) and \(\langle G_{\mathbf{x}},\mathcal{F}_{\mathbf{x}}\rangle\). Hence, eliminating \(W\) yields the same set of parents and CPT for each \(C\in\mathbf{C}\) in \(\langle G^{\prime},\mathcal{F}^{\prime}\rangle\) and \(\langle G^{\prime}_{\mathbf{x}},\mathcal{F}^{\prime}_{\mathbf{x}}\rangle\). We next consider the set of parents and CPT for each child \(C\in\mathbf{C}_{2}\). Since \(W\) is not a parent of \(C\) in \(\langle G_{\mathbf{x}},\mathcal{F}_{\mathbf{x}}\rangle\), variable \(C\) has the same set of parents and CPT in \(\langle G^{\prime}_{\mathbf{x}},\mathcal{F}^{\prime}_{\mathbf{x}}\rangle\), The exactly same set of parents (empty) and CPT will be assigned to \(C\) in the mutilated CBN for \(\langle G^{\prime},\mathcal{F}^{\prime}\rangle\). 

Proof.: (Theorem 24) Consider a CBN \(\langle G,\mathcal{F}\rangle\) and its mutilated CBN \(\langle G_{\mathbf{x}},\mathcal{F}_{\mathbf{x}}\rangle\). Let \(\Pr\) and \(\Pr_{\mathbf{x}}\) be the distributions induced by \(\mathcal{F}\) and \(\mathcal{F}_{\mathbf{x}}\) over variables \(\mathbf{V}\), respectively. By Lemma 26, we can eliminate each \(W\in\mathbf{W}\) inductively from \(\langle G,\mathcal{F}\rangle\) and \(\langle G_{\mathbf{x}},\mathcal{F}_{\mathbf{x}}\rangle\) and obtain \(\langle G^{\prime},\mathcal{F}^{\prime}\rangle\) and its mutilated CBN \(\langle G^{\prime}_{\mathbf{x}},\mathcal{F}^{\prime}_{\mathbf{x}}\rangle\). By Theorem 23, the distribution induced by \(\mathcal{F}^{\prime}_{\mathbf{x}}\) is exactly \(\sum_{\mathbf{W}}\Pr_{\mathbf{x}}(\mathbf{V})\). 

**Proof of Proposition 10**

Proof.: First note that the extended set \(\mathbf{Z}^{\prime}\) contains \(\mathbf{Z}\) and all variable that are functionally determined by \(\mathbf{Z}\). Consider any path \(\mathcal{P}\) between some \(X\in\mathbf{X}\) and \(Y\in\mathbf{Y}\). We show that \(\mathcal{P}\) is blocked by \(\mathbf{Z}^{\prime}\) iff it is blocked by \(\mathbf{Z}\) according to the definition in [42]. We first show the if-part. Suppose there is a convergent valve8 for variable \(W\) that is closed when conditioned on \(\mathbf{Z}\), then the valve is still closed when conditioned on \(\mathbf{Z}^{\prime}\) unless the parents of \(W\) are in \(Z^{\prime}\). However, the path \(\mathcal{P}\) will be blocked in the latter case since the parents of \(W\) must have sequential/divergent valves. Suppose there is a sequential/divergent valve that is closed when conditioned on \(\mathbf{Z}\) according to [42], then \(W\) must be in \(\mathbf{Z}^{\prime}\) since it is functionally determined by \(\mathbf{Z}\). Hence, the valve is also closed when conditioned on \(\mathbf{Z}^{\prime}\).

Footnote 8: See [40, Ch. 4] for more details on convergent, divergent and sequential valves.

We next show the only-if part. Suppose a convergent valve for variable \(W\) is closed when conditioned on \(\mathbf{Z}^{\prime}\), then none of \(\mathbf{Z}\) is a descendent of \(W\) since \(\mathbf{Z}^{\prime}\) is a superset of \(\mathbf{Z}\). Suppose a sequential/divergent valve for variable \(W\) is closed when conditioned on \(\mathbf{Z}^{\prime}\), then \(W\) is functionally determined by \(\mathbf{Z}\) by the construction of \(\mathbf{Z}^{\prime}\). Thus, the valve is closed in [42]. 

**Proof of Theorem 11**

Proof.: By induction, it suffices to show that \(\mathbf{X}\) and \(\mathbf{Y}\) are D-separated by \(\mathbf{Z}\) in \(\langle G,\mathbf{W}\rangle\) iff they are D-separated by \(\mathbf{Z}\) in \(\langle G^{\prime},\mathbf{W}^{\prime}\rangle\), where \(G^{\prime}\) is the result of functionally eliminating a single variable \(T\in\mathbf{W}\) from \(G^{\prime}\) and \(\mathbf{W}^{\prime}=\mathbf{W}\setminus\{T\}\). We first show the contrapositive of the if-part. Suppose \(\mathbf{X}\) and \(\mathbf{Y}\) are not D-separated by \(\mathbf{Z}\) in \(\langle G,\mathbf{W}\rangle\), by the completeness of D-separation, there exists a parameterization \(\mathcal{F}\) on \(G\) such that \((\mathbf{X}\not\perp\mathbf{Y}|\mathbf{Z})_{\mathcal{F}}\). If we eliminate \(T\) from the CBN \(\langle G,\mathcal{F}\rangle\), we obtain another CBN \(\langle G^{\prime},\mathcal{F}^{\prime}\rangle\) where \(\mathcal{F}^{\prime}\) is the parameterization for \(G^{\prime}\). By Theorem 23, the marginal probabilities are preserved for the variables in \(G^{\prime}\), which include \(\mathbf{X},\mathbf{Y},\mathbf{Z}\). Hence, \((\mathbf{X}\not\perp\mathbf{Y}|\mathbf{Z})_{\mathcal{F}^{\prime}}\) and \(\mathbf{X}\) and \(\mathbf{Y}\) are not D-separated by \(\mathbf{Z}\) in \(\langle G^{\prime},\mathbf{W}^{\prime}\rangle\).

Next consider the contrapositive of the only-if part. Suppose \(\mathbf{X}\) and \(\mathbf{Y}\) are not D-separated by \(\mathbf{Z}\) in \(\langle G^{\prime},\mathbf{W}^{\prime}\rangle\), then there exists a parameterization \(\mathcal{F}^{\prime}\) of \(G^{\prime}\) such that \((\mathbf{X}\not\perp\mathbf{Y}|\mathbf{Z})_{\mathcal{F}^{\prime}}\) by the completeness of D-separation. We construct a parameterization \(\mathcal{F}\) for \(G\) such that \(\mathcal{F}^{\prime}\) is the parameterization of \(G^{\prime}\) which results from eliminating \(T\) from the CBN \(\langle G,\mathcal{F}\rangle\). This is sufficient to show that \(\mathbf{X}\) and \(\mathbf{Y}\) are not D-separated by \(\mathbf{Z}\) in \(\langle G,\mathbf{W}\rangle\) since the marginals are preserved by Theorem 23.

**Construction Method** Let \(\mathbf{P}_{T}\) and \(\mathbf{C}_{T}\) denote the parents and children of \(T\) in \(G\). Our construction assumes that the cardinality of \(T\) is the number of instantiations for its parents \(\mathbf{P}_{T}\). That is, there is a one-to-one correspondence between the states of \(T\) and the instantiations of \(\mathbf{P}_{T}\), and we use \(\alpha(t)\) to denote the instantiation \(\mathbf{p}_{T}\) corresponding to state \(t\). The functional CPT for \(T\) is assigned as \(f_{T}(t|\mathbf{p}_{T})=1\) if \(\alpha(t)=\mathbf{p}_{T}\) and \(f_{T}(t|\mathbf{p}_{T})=0\) otherwise for each instantiation \(\mathbf{p}_{T}\) of \(\mathbf{P}_{T}\). Now consider each child \(C\in\mathbf{C}_{T}\) that has parents \(\mathbf{P}_{C}\) (excluding \(T\)) and \(T\) in \(G\). It immediately followsfrom Definition 9 that \(C\) has parents \(\mathbf{P}_{T}\cup\mathbf{P}_{C}\) in \(G^{\prime}\). We next construct the CPT \(f_{C}\) in \(\mathcal{F}\) based on its CPT \(f^{\prime}_{C}\) in \(\mathcal{F}^{\prime}\). Consider each parent instantiation \((t,\mathbf{p}_{C})\) where \(t\) is a state of \(T\) and \(\mathbf{p}_{C}\) is an instantiation of \(\mathbf{P}_{C}\). If \(\alpha(t)\) is consistent with \(\mathbf{p}_{C}\), assign \(f_{C}(c|t,\mathbf{p}_{C})=f^{\prime}_{C}(c|\alpha(t),\mathbf{p}_{C})\) for each state \(c\).9 Otherwise, assign any functional distribution for \(f_{C}(C|t,\mathbf{p}_{C})\). The construction ensures that the constructed CPT \(f_{T}\) for \(T\) is functional, and that the functional dependencies among other variables are preserved. In particular, for each child \(C\) of \(T\), the constructed CPT \(f_{C}\) is functional iff \(f^{\prime}_{C}\) is functional. This construction method will be reused later in other proofs.

Footnote 9: For clarity, we use the notation \(|\) to separate a variable and its parents in a CPT.

We now just need to show that CBN \(\langle G^{\prime},\mathcal{F}^{\prime}\rangle\) is the result of eliminating \(T\) from the (constructed) CBN \(\langle G,\mathcal{F}\rangle\). In particular, we need to check that the CPT for each child \(C\in\mathbf{C}_{T}\) in \(\mathcal{F}^{\prime}\) is correctly computed from the constructed CPTs in \(\mathcal{F}\). For each instantiation \((\mathbf{p}_{T},\mathbf{p}_{C})\) and state \(c\) of \(C\),

\[f^{\prime}_{C}(c|\mathbf{p}_{T},\mathbf{p}_{C}) =f_{C}(c|t^{*},\mathbf{p}_{C})=f_{T}(t^{*}|\mathbf{p}_{T})f_{C}(c| t^{*},\mathbf{p}_{C})\] \[=\sum_{t}f_{T}(t|\mathbf{p}_{T})f_{C}(c|t,\mathbf{p}_{C})\]

where \(t^{*}\) is the state of \(T\) such that \(\alpha(t^{*})=\mathbf{p}_{T}\). 

Proof of Theorem 13.: We prove the theorem by induction. It suffices to show the following statement: for each causal graph \(G\) with observed variables \(\mathbf{V}\) and functional variables \(\mathbf{W}\), the causal effect \(\Pr_{\mathbf{x}}(\mathbf{Y})\) is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) iff it is F-identifiable wrt \(\langle G^{\prime},\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}^{\prime}\rangle\) where \(G^{\prime}\) is the result of functionally eliminating some hidden functional variable \(T\in\mathbf{W}\) and \(\mathbf{W}^{\prime}=\mathbf{W}\setminus\{T\}\).

We first show the contrapositive of the if-part. Suppose \(\Pr_{\mathbf{x}}(\mathbf{Y})\) is not F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\), there exist two CBNs \(\langle G,\mathcal{F}_{1}\rangle\) and \(\langle G,\mathcal{F}_{2}\rangle\) which induce distributions \(\Pr_{1},\Pr_{2}\) such that \(\Pr_{1}(\mathbf{V})=\Pr_{2}(\mathbf{V})\) but \(\Pr_{1\mathbf{x}}(\mathbf{Y})\neq\Pr_{2\mathbf{x}}(\mathbf{Y})\). Let \(\langle G^{\prime},\mathcal{F}^{\prime}_{1}\rangle\) and \(\langle G^{\prime},\mathcal{F}^{\prime}_{2}\rangle\) be the results of eliminating \(T\notin\mathbf{V}\) from \(\langle G,\mathcal{F}_{1}\rangle\) and \(\langle G,\mathcal{F}_{2}\rangle\), the two CBNs attain the same marginal distribution on \(\mathbf{V}\) but different causal effects by Theorem 23 and Theorem 24. Hence, \(\Pr_{\mathbf{x}}(\mathbf{Y})\) is not F-identifiable wrt \(\langle G^{\prime},\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}^{\prime}\rangle\) either.

We next show the contrapositive of the only-if part. Suppose \(\Pr_{\mathbf{x}}(\mathbf{Y})\) is not F-identifiable wrt \(\langle G^{\prime},\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}^{\prime}\rangle\), there exist two CBNs \(\langle G^{\prime},\mathcal{F}^{\prime}_{1}\rangle\) and \(\langle G^{\prime},\mathcal{F}^{\prime}_{2}\rangle\) which induce distributions \(\Pr^{\prime}_{1},\Pr^{\prime}_{2}\) such that \(\Pr^{\prime}_{1}(\mathbf{V})=\Pr^{\prime}_{2}(\mathbf{V})\) but \(\Pr^{\prime}_{1\mathbf{x}}(\mathbf{Y})\neq\Pr^{\prime}_{2\mathbf{x}}(\mathbf{Y})\). We can obtain \(\langle G,\mathcal{F}_{1}\rangle\) and \(\langle G,\mathcal{F}_{2}\rangle\) by considering again the construction method in Theorem 11 where we assign a one-to-one mapping for \(T\) and adopt the CPTs from \(\mathcal{F}^{\prime}_{1}\) and \(\mathcal{F}^{\prime}_{2}\) for the children of \(T\). This way, \(\langle G^{\prime},\mathcal{F}^{\prime}_{1}\rangle\) and \(\langle G^{\prime},\mathcal{F}^{\prime}_{2}\rangle\) become the results of eliminating \(T\) from the constructed \(\langle G,\mathcal{F}_{1}\rangle\) and \(\langle G,\mathcal{F}_{2}\rangle\). Since \(T\notin\mathbf{V}\), \(\Pr_{1}(\mathbf{V})=\Pr^{\prime}_{1}(\mathbf{V})=\Pr^{\prime}_{2}(\mathbf{V})= \Pr_{2}(\mathbf{V})\) by Theorem 23, and \(\Pr_{1\mathbf{x}}(\mathbf{Y})=\Pr^{\prime}_{1\mathbf{x}}(\mathbf{Y})\neq\Pr^{ \prime}_{2\mathbf{x}}(\mathbf{Y})=\Pr_{2\mathbf{x}}(\mathbf{Y})\) by Theorem 24. Hence, \(\Pr_{\mathbf{x}}(\mathbf{Y})\) is not F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) either. 

Proof of Theorem 15.: Since we only functionally eliminate variables that have observed parents, it is guaranteed that each \(Z\in\mathbf{Z}\) has observed parents when it is eliminated. By induction, it suffices to show that \(\Pr_{\mathbf{x}}(\mathbf{Y})\) is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) iff it is F-identifiable wrt \(\langle G^{\prime},\mathbf{V}^{\prime},\mathcal{C}_{\mathbf{V}},\mathbf{W}^{ \prime}\rangle\) where \(G^{\prime}\) is the result of eliminating a single functional variable \(Z\in\mathbf{W}\) with observed parents from \(G\), \(\mathbf{V}^{\prime}=\mathbf{V}\setminus\{Z\}\), and \(\mathbf{W}^{\prime}=\mathbf{W}\setminus\{Z\}\).

We first show the contrapositive of the if-part. Suppose \(\Pr_{\mathbf{x}}(\mathbf{Y})\) is not F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\), there exist two CBNs \(\langle G,\mathcal{F}_{1}\rangle\) and \(\langle G,\mathcal{F}_{2}\rangle\) which induce distributions \(\Pr_{1},\Pr_{2}\) where \(\Pr_{1}(\mathbf{V})=\Pr_{2}(\mathbf{V})\) but \(\Pr_{1\mathbf{x}}(\mathbf{Y})\neq\Pr_{2\mathbf{x}}(\mathbf{Y})\). Let \(\langle G^{\prime},\mathcal{F}^{\prime}_{1}\rangle\) and \(\langle G^{\prime},\mathcal{F}^{\prime}_{2}\rangle\) be the results of eliminating \(Z\) from \(\langle G,\mathcal{F}_{1}\rangle\) and \(\langle G,\mathcal{F}_{2}\rangle\), the two CBNs induce the same marginal distribution \(\Pr^{\prime}_{1}(\mathbf{V}^{\prime})=\Pr^{\prime}_{2}(\mathbf{V}^{\prime})\) by Theorem 23 but different causal effects \(\Pr^{\prime}_{1\mathbf{x}}(\mathbf{Y})\neq\Pr^{\prime}_{2\mathbf{x}}(\mathbf{Y})\) by Theorem 24. Hence, \(\Pr_{\mathbf{x}}(\mathbf{Y})\) is not F-identifiable wrt \(\langle G^{\prime},\mathbf{V}^{\prime},\mathcal{C}_{\mathbf{V}},\mathbf{W}^{ \prime}\rangle\).

We now consider the contrapositive of the only-if part. Suppose \(\Pr_{\mathbf{x}}(\mathbf{Y})\) is not F-identifiable wrt \(\langle G^{\prime},\mathbf{V}^{\prime},\mathcal{C}_{\mathbf{V}},\mathbf{W}^{ \prime}\rangle\), then there exist two CBNs \(\langle G^{\prime},\mathcal{F}^{\prime}_{1}\rangle\) and \(\langle G^{\prime},\mathcal{F}^{\prime}_{2}\rangle\) which induce distributions \(\Pr^{\prime}_{1},\Pr^{\prime}_{2}\) such that \(\Pr^{\prime}_{1}(\mathbf{V}^{\prime})=\Pr^{\prime}_{2}(\mathbf{V}^{\prime})\) but \(\Pr^{\prime}_{1\mathbf{x}}(\mathbf{Y})\neq\Pr^{\prime}_{2\mathbf{x}}(\mathbf{Y})\). We again consider the construction method from the proof of Theorem 11 which produces two CBNs \(\langle G,\mathcal{F}_{1}\rangle\) and \(\langle G,\mathcal{F}_{2}\rangle\).

Moreover, \(\langle G^{\prime},\mathcal{F}^{\prime}_{1}\rangle\) and \(\langle G^{\prime},\mathcal{F}^{\prime}_{2}\rangle\) are the result of eliminating \(Z\) from \(\langle G,\mathcal{F}_{1}\rangle\) and \(\langle G,\mathcal{F}_{2}\rangle\). It is guaranteed that the two constructed CBNs produce different causal effects \(\mathrm{Pr}_{1\mathbf{x}}(\mathbf{Y})=\mathrm{Pr}^{\prime}_{1\mathbf{x}}( \mathbf{Y})\neq\mathrm{Pr}^{\prime}_{2\mathbf{x}}(\mathbf{Y})=\mathrm{Pr}_{2 \mathbf{x}}(\mathbf{Y})\) by Theorem 24. We need to show that \(\langle G,\mathcal{F}_{1}\rangle\) and \(\langle G,\mathcal{F}_{2}\rangle\) induce a same distribution over variables \(\mathbf{V}=\mathbf{V}^{\prime}\cup\{Z\}\). Consider any instantiation \((\mathbf{v}^{\prime},z)\) of \(\mathbf{V}\). Since \(\mathcal{F}_{1}\) and \(\mathcal{F}_{2}\) assign the same one-to-one mapping \(\alpha\) between \(Z\) and its parents in \(G\), it is guaranteed that the probabilities \(\mathrm{Pr}_{1}(\mathbf{v}^{\prime},z)=\mathrm{Pr}_{2}(\mathbf{v}^{\prime},z)=0\) except for the single state \(z^{\ast}\) where \(\alpha(z^{\ast})=\mathbf{p}\) where \(\mathbf{p}\) is the parent instantiation of \(Z\) consistent with \(\mathbf{v}^{\prime}\). By construction, \(\mathrm{Pr}_{1}(\mathbf{v}^{\prime},z^{\ast},\mathbf{u})=\mathrm{Pr}^{\prime} _{1}(\mathbf{v}^{\prime},\mathbf{u})\) for every instantiation \(\mathbf{u}\) of hidden variables \(\mathbf{U}\). Similarly, \(\mathrm{Pr}_{2}(\mathbf{v}^{\prime},z^{\ast},\mathbf{u})=\mathrm{Pr}^{\prime} _{2}(\mathbf{v}^{\prime},\mathbf{u})\) for every instantiation \((\mathbf{v}^{\prime},z,\mathbf{u})\). It then follows that \(\mathrm{Pr}_{1}(\mathbf{v}^{\prime},z^{\ast})=\sum_{\mathbf{u}}\mathrm{Pr}_{1 }(\mathbf{v}^{\prime},z^{\ast},\mathbf{u})=\sum_{\mathbf{u}}\mathrm{Pr}^{ \prime}_{1}(\mathbf{v}^{\prime},\mathbf{u})=\mathrm{Pr}^{\prime}_{1}(\mathbf{ v}^{\prime})\)\(=\mathrm{Pr}^{\prime}_{2}(\mathbf{v}^{\prime})=\sum_{\mathbf{u}}\mathrm{Pr}_{2}(\mathbf{v}^{ \prime},z^{\ast},\mathbf{u})=\sum_{\mathbf{u}}\mathrm{Pr}_{2}(\mathbf{v}^{ \prime},z^{\ast},\mathbf{u})=\mathrm{Pr}_{2}(\mathbf{v}^{\prime},z^{\ast})\). This means \(\mathrm{Pr}_{\mathbf{x}}(\mathbf{Y})\) is not F-identifiable wrt \(\langle G,\mathbf{V},C_{\mathbf{V}},\mathbf{W}\rangle\) either. 

#### Proof of Theorem 17

**Lemma 27**.: _Let \(G\) be a causal graph, \(\mathbf{V}\) be its observed variables and \(\mathbf{W}\) be its functional variables. Let \(Z\) be a non-descendant of \(\mathbf{W}\) that has at least one hidden parent, then a causal effect is F-identifiable wrt \(\langle G,\mathbf{V},C_{\mathbf{V}},\mathbf{W}\rangle\) iff it is F-identifiable wrt \(\langle G,\mathbf{V},C_{\mathbf{V}},\mathbf{W}\cup\{Z\}\rangle\)._

Proof.: Let \(\mathbf{W}^{\prime}\) denote the set \(\mathbf{W}\cup\{Z\}\). The only-if part holds immediately by the fact that every distribution that can be possibly induced from \(\langle G,\mathbf{W}^{\prime}\rangle\) can also be induced from \(\langle G,\mathbf{W}\rangle\). We next consider the contrapositive of the if part. Suppose a causal effect is not F-identifiable wrt \(\langle G,\mathbf{V},C_{\mathbf{V}},\mathbf{W}\rangle\), then there exist two CBNs \(\langle G,\mathcal{F}_{1}\rangle\) and \(\langle G,\mathcal{F}_{2}\rangle\) which induce distributions \(\mathrm{Pr}_{1},\mathrm{Pr}_{2}\) such that \(\mathrm{Pr}_{1}(\mathbf{V})=\mathrm{Pr}_{2}(\mathbf{V})\) but \(\mathrm{Pr}_{1\mathbf{x}}(\mathbf{Y})\neq\mathrm{Pr}_{2\mathbf{x}}(\mathbf{Y})\). We next construct \(\langle G,\mathcal{F}^{\prime\prime}_{1}\rangle\) and \(\langle G,\mathcal{F}^{\prime\prime}_{2}\rangle\) which constitute an example of unidentifiability wrt \(\langle G,\mathbf{V},C_{\mathbf{V}},\mathbf{W}^{\prime}\rangle\). In particular, the CPTs for \(Z\) need to be functional in the constructed CBNs.

WLG, we show the construction of \(\langle G,\mathcal{F}^{\prime\prime}_{1}\rangle\) from \(\langle G,\mathcal{F}_{1}\rangle\) which involves two steps (the construction of \(\langle G,\mathcal{F}^{\prime\prime}_{2}\rangle\) from \(\langle G,\mathcal{F}_{2}\rangle\) will follow a same procedure). Let \(\mathbf{P}\) be the parents of \(Z\). The first step constructs a CBN \(\langle G^{\prime},\mathcal{F}^{\prime}_{1}\rangle\) based on the known method that transforms any (non-functional) CPT into a functional CPT. This is done by adding an auxiliary hidden root parent \(U\) for \(Z\) whose states correspond to the possible functions between \(\mathbf{P}\) and \(Z\). The CPTs for \(U\) and \(Z\) are assigned accordingly such that \(f_{Z}=\sum_{U}f^{\prime}_{U}f^{\prime}_{Z}\) where \(f^{\prime}_{U}\) and \(f^{\prime}_{Z}\) are the constructed CPTs in \(\mathcal{F}^{\prime}_{1}\).10 It follows that \(\mathcal{F}_{1}\) and \(\mathcal{F}^{\prime}_{1}\) induce the same distribution over \(\mathbf{V}\) since \(\mathcal{F}_{1}=\sum_{U}\mathcal{F}^{\prime}_{1}\). The causal effect is also preserved since summing out \(U\) is independent of other CPTs in the mutilated CBN for \(\langle G^{\prime},\mathcal{F}^{\prime}_{1}\rangle\).

Footnote 10: Each state \(u\) of \(U\) corresponds to a function \(\gamma_{u}\) where \(\gamma_{u}(\mathbf{p})\) is mapped to some state of \(Z\) for each instantiation \(\mathbf{p}\). The variable \(U\) thus has \(|Z|^{|\mathbf{P}|}\) states since there are total of \(|Z|^{|\mathbf{P}|}\) possible functions from \(\mathbf{P}\) to \(Z\). For each instantiation \((z,u,\mathbf{p})\), the functional CPT for \(Z\) is defined as \(f^{\prime}_{Z}(z|u,\mathbf{p})=1\) if \(z=\gamma_{u}(\mathbf{p})\), and \(f^{\prime}_{Z}(z|u,\mathbf{p})=0\) otherwise. The CPT for \(U\) is assigned as \(f^{\prime}_{U}(u)=\prod_{\mathbf{p}\in\mathbf{P}}f_{Z}(\gamma_{u}(\mathbf{p})| \mathbf{p})\).

Our second step involves converting the CBN \(\langle G^{\prime},\mathcal{F}^{\prime}_{1}\rangle\) (constructed from the first step) into the CBN \(\langle G,\mathcal{F}^{\prime\prime}_{1}\rangle\) over the original graph \(G\). Let \(T\in\mathbf{P}\) be the hidden parent of \(W\) in \(G\). We merge the auxiliary parent \(U\) and \(T\) into a new variable \(T^{\prime}\) and substitute it for \(T\) in \(G\), i.e., \(T^{\prime}\) has the same parents and children as \(T\). \(T^{\prime}\) is constructed as the Cartesian product of \(U\) and \(T\): each state of \(T^{\prime}\) is represented as a pair \((u,t)\) where \(u\) is a state of \(U\) and \(t\) is a state of \(T\). We are ready to assign new CPTs for \(T^{\prime}\) and its children. For each parent instantiation \(\mathbf{p}\) of \(\mathbf{P}\) and each state \((u,t)\) of \(T^{\prime}\), we assign the CPT for \(T^{\prime}\) in \(\mathcal{F}^{\prime\prime}\) as \(f^{\prime\prime}_{T^{\prime}}((u,t)|\mathbf{p})=f^{\prime}_{U}(u)f^{\prime}_{T}(t| \mathbf{p})\). Next consider each child \(C\) of \(T^{\prime}\) that has parents \(\mathbf{P}_{C}\) (excluding \(T^{\prime}\)). For each instantiation \(\mathbf{p}_{C}\) of \(\mathbf{P}_{C}\) and each state \((u,t)\) of \(T^{\prime}\), we assign the CPT for \(C\) in \(\mathcal{F}^{\prime\prime}\) as \(f^{\prime\prime}_{C}(c|\mathbf{p}_{C},(u,t))=f^{\prime}_{C}(c|\mathbf{p}_{C})\) for each state \(c\). Note that \(f^{\prime\prime}_{C}\) is functional iff \(f^{\prime}_{C}\) is functional. Hence, the CPTs for \(\mathbf{W}\) are all functional in \(\mathcal{F}^{\prime\prime}\).

We need to show that \(\langle G,\mathcal{F}^{\prime\prime}_{1}\rangle\) preserves the distribution on \(\mathbf{V}\) and the causal effect from \(\langle G^{\prime},\mathcal{F}^{\prime}_{1}\rangle\). Let \(\mathbf{U}^{\prime\prime}\) be the hidden variables in \(\langle G,\mathcal{F}^{\prime\prime}_{1}\rangle\) and \(\mathbf{U}^{\prime}\) be the hidden variables in \(\langle G^{Proof of Theorem 17.: We prove the theorem by induction. We first order all the functional variables in a bottom-up order. Let \(W^{i}\) denote the \(i^{th}\) functional variable in the order and \(\mathbf{W}^{(i)}\) denote the functional variables that are ordered before \(W^{i}\) (including \(W^{i}\)). It follows that we can go over each \(W^{i}\) in the order and show that a causal effect is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}^{(i-1)}\rangle\) iff it is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}^{(i)}\rangle\) by Lemma 27. Since F-identifiability wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}^{(0)}\rangle\) is equivalent to identifiability wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}}\rangle\), we conclude that the causal effect is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) iff it is identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}}\rangle\). 

### Proof of Theorem 18

The proof of the theorem is organized as follows. We start with a lemma (Lemma 28) that allows us to modify the CPT of a variable when the marginal probability over its parents contain zero entries. We then show a main lemma (Lemma 29) that allows us to reduce F-identifiability to identifiability when all functional variables are observed or has a hidden parent. We finally prove the theorem based on the main lemma and previous theorems.

**Lemma 28**.: _Consider two CBNs that have a same causal graph and induce the distributions \(\Pr_{1}\) and \(\Pr_{2}\). Suppose the CPTs of the two CBNs only differ by \(f_{X}(X,\mathbf{P})\). Then \(\Pr_{1}(\mathbf{p})=0\) iff \(\Pr_{2}(\mathbf{p})=0\) for all instantiations \(\mathbf{p}\) of \(\mathbf{P}\)._

Proof.: Let \(f_{Y}\) and \(g_{Y}\) denote the CPT for \(Y\) in the first and second CBN. Let \(\mathcal{A}n(\mathbf{P})\) be the ancestors of variables in \(\mathbf{P}\) (including \(\mathbf{P}\)). If we eliminate all variables other than \(\mathcal{A}n(\mathbf{P})\), then we obtain the factor set \(\mathcal{F}_{1}=\prod_{Y\in\mathcal{A}n(\mathbf{P})}f_{Y}\) for the first CBN and \(\mathcal{F}_{2}=\prod_{Y\in\mathcal{A}n(\mathbf{P})}g_{Y}\) for the second CBN. Since all CPTs are the same for variables in \(\mathcal{A}n(\mathbf{P})\), it is guaranteed that \(\mathcal{F}_{1}=\mathcal{F}_{2}\). If we further eliminate variables other than \(\mathbf{P}\) from \(\mathcal{F}_{1}\) and \(\mathcal{F}_{2}\), we obtain the marginal distributions \(\Pr_{1}(\mathbf{P})=\overset{=}{\sum}_{\mathbf{P}}\mathcal{F}_{1}\) and \(\Pr_{2}(\mathbf{P})=\overset{=}{\sum}_{\mathbf{P}}\mathcal{F}_{2}\), where \(\overset{=}{\sum}_{\mathbf{P}}\) denotes the projection operation that sums out variables other than \(\mathbf{P}\) from a factor. Hence, \(\Pr_{1}(\overline{\mathbf{P}})=\Pr_{2}(\mathbf{P})\) which concludes the proof. 

**Lemma 29**.: _If a causal effect is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) but is not identifiable \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}}\rangle\), then there must exist at least one functional variable that is hidden and whose parents are all observed._

Proof.: The lemma is the same as saying that if every functional variable is observed or having a hidden parent, then F-identifiability is equivalent to identifiability. We go over each functional variable \(W_{i}\in\mathbf{W}\) in a bottom-up order \(\Pi\) and show the following inductive statement: a causal effect \(\Pr_{x}(\mathbf{Y})\) is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}^{(i)}\rangle\) iff it is F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}^{(i-1)}\rangle\), where \(\mathbf{W}^{(i)}\) is a subset of variables in \(\mathbf{W}\) that are ordered before \(W_{i}\) (and including \(W_{i}\)) in \(\Pi\). Note that \(\mathbf{W}^{(0)}=\emptyset\) and F-identifiability wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}^{(0)}\rangle\) collapses into identifiability wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}}\rangle\).

The if-part follows from the definitions of identifiability and F-identifiability. We next consider the contrapositive of the only-if part. Let \(Z\) be the functional variable in \(\mathbf{W}\) that is considered in the current inductive step. Let \(\langle G,\mathcal{F}_{1}\rangle\) and \(\langle G,\mathcal{F}_{2}\rangle\) be the two CBNs inducing distributions \(\Pr_{1}\) and \(\Pr_{2}\) that constitute the unidentifiability, i.e., \(\Pr_{1}(\mathbf{V})=\Pr_{2}(\mathbf{V})\) and \(\Pr_{1x}(\mathbf{Y})\neq\Pr_{2x}(\mathbf{Y})\). Our goal is to construct two CBNs \(\langle G,\mathcal{F}_{1}^{\prime\prime\prime}\rangle\) and \(\langle G,\mathcal{F}_{2}^{\prime\prime\prime}\rangle\), which induce distributions \(\Pr_{1}^{\prime\prime\prime}\), \(\Pr_{2}^{\prime\prime\prime}\) and contain functional CPTs for \(Z\), such that \(\Pr_{1}^{\prime\prime}(\mathbf{V})=\Pr_{2}^{\prime\prime}(\mathbf{V})\) and \(\Pr_{1x}^{\prime\prime\prime}(\mathbf{Y})\neq\Pr_{2x}^{\prime\prime\prime}( \mathbf{Y})\). Suppose \(Z\) has a hidden parent, we directly employ Lemma 27 to construct the two CBNs. We next consider the case when \(Z\) is observed and has observed parents. By default, we use \(f_{Z}\) to \(g_{Z}\) to denote the CPT for \(Z\) in \(\mathcal{F}_{1}\) and \(\mathcal{F}_{2}\).

The following three steps are considered to construct an instance of unidentifiability.

**First Step:** we construct \(\langle G,\mathcal{F}_{1}^{\prime}\rangle\) and \(\langle G,\mathcal{F}_{2}^{\prime}\rangle\) by modifying the CPTs for \(Z\). Let \(\mathbf{P}\) be the parents of \(Z\) in \(G\). For each instantiation \(\mathbf{p}\) of \(\mathbf{P}\) where \(\Pr_{1}(\mathbf{p})=\Pr_{2}(\mathbf{p})=0\), we modify the entries \(f_{Z}^{\prime}(Z|\mathbf{p})\) and \(g_{Z}^{\prime}(Z|\mathbf{p})\) for the CPTs \(f_{Z}^{\prime}\) and \(g_{Z}^{\prime}\) in \(\mathcal{F}_{1}^{\prime}\) and \(\mathcal{F}_{2}^{\prime}\) as follows. Since \(\Pr_{1x}(\mathbf{Y})\neq\Pr_{2x}(\mathbf{Y})\), there exists an instantiation \(\mathbf{y}\) such that \(\Pr_{1x}(\mathbf{y})\neq\Pr_{2x}(\mathbf{y})\). WLG, assume \(\Pr_{1x}(\mathbf{y})>\Pr_{2x}(\mathbf{y})\). Since \(\Pr_{1x}(\mathbf{y})\) is computed as the marginal probability of \(\mathbf{y}\) in the mutilated CBN for \(\langle G,\mathcal{F}_{1}\rangle\), it can be expressed in the form of _network polynomial_ as shown in [49, 40]. If we treat the CPT entries of \(f_{Z}(Z|\mathbf{p})\) as unknown, then we can write \(\Pr_{1x}(\mathbf{y})\) as follows\[\Pr_{1x}(\mathbf{y})=\alpha_{0}+\alpha_{1}f_{Z}(z_{1}|\mathbf{p})+\cdots+\alpha_{ k}f_{Z}(z_{k}|\mathbf{p})\]

where \(\alpha_{0},\alpha_{1},\ldots,\alpha_{k}\) are constants and \(z_{1},\ldots,z_{k}\) are the states of variable \(Z\). Similarly, we can write \(\Pr_{2x}(\mathbf{y})\) as follows

\[\Pr_{2x}(\mathbf{y})=\beta_{0}+\beta_{1}g_{Z}(z_{1}|\mathbf{p})+\cdots+\beta_ {k}g_{Z}(z_{k}|\mathbf{p})\]

Let \(\alpha_{i}\) be the _maximum_ value among \(\alpha_{1},\ldots,\alpha_{k}\) and \(\beta_{j}\) be the _minimum_ value among \(\beta_{1},\ldots,\beta_{k}\), our construction method assigns \(f^{\prime}_{Z}(z_{i}|\mathbf{p})=1\) and \(g^{\prime}_{Z}(z_{j}|\mathbf{p})=1\). By construction, it is guaranteed that \(\Pr^{\prime}_{1x}(\mathbf{y})-\Pr^{\prime}_{2x}(\mathbf{y})\geq\Pr_{1x}( \mathbf{y})-\Pr_{2x}(\mathbf{y})>0\) where \(\Pr^{\prime}_{1x}(\mathbf{y})\), \(\Pr^{\prime}_{2x}(\mathbf{y})\) denote the causal effects under the updated CPTs \(f^{\prime}_{Z}(Z|\mathbf{p})\) and \(g^{\prime}_{Z}(Z|\mathbf{p})\). We repeat the above procedure for all such \(\mathbf{p}\) where \(\Pr_{1}(\mathbf{p})=0\), which yields the new CBNs \(\langle G,\mathcal{F}^{\prime}_{1}\rangle\) and \(\langle G,\mathcal{F}^{\prime}_{2}\rangle\) in which \(f^{\prime}_{Z}(Z|\mathbf{p})\) and \(g^{\prime}_{Z}(Z|\mathbf{p})\) are functional whenever \(\Pr_{1}(\mathbf{p})=0\). We next show that \(\mathcal{F}^{\prime}_{1}\) and \(\mathcal{F}^{\prime}_{2}\) (with the updated \(f^{\prime}_{Z}\) and \(g^{\prime}_{Z}\)) constitute an example of unidentifiability. \(\Pr^{\prime}_{1x}(\mathbf{Y})\neq\Pr^{\prime}_{2x}(\mathbf{Y})\) since \(\Pr^{\prime}_{1x}(\mathbf{y})>\Pr^{\prime}_{2x}(\mathbf{y})\) for the particular instantiation \(\mathbf{y}\). We are left to show that the distributions \(\Pr^{\prime}_{1}\) and \(\Pr^{\prime}_{2}\) induced by \(\langle G,\mathcal{F}^{\prime}_{1}\rangle\) and \(\langle G,\mathcal{F}^{\prime}_{2}\rangle\) are the same over the observed variables \(\mathbf{V}\). Consider each instantiation \(\mathbf{v}\) of \(\mathbf{V}\) and \(\mathbf{p}\) of \(\mathbf{P}\) where \(\mathbf{p}\) is consistent with \(\mathbf{v}\). If \(\Pr_{1}(\mathbf{p})=0\), then \(\Pr^{\prime}_{1}(\mathbf{p})=\Pr^{\prime}_{2}(\mathbf{p})=0\) by Lemma 28 and thus \(\Pr^{\prime}_{1}(\mathbf{v})=\Pr^{\prime}_{2}(\mathbf{v})=0\). Otherwise, \(\Pr^{\prime}_{1}(\mathbf{v})=\Pr_{1}(\mathbf{v})=\Pr_{2}(\mathbf{v})=\Pr^{ \prime}_{2}(\mathbf{v})\) since none of the CPT entries consistent with \(\mathbf{v}\) were modified.

**Second Step:** We construct \(\langle G^{\prime\prime},\mathcal{F}^{\prime\prime}_{1}\rangle\), \(\langle G^{\prime\prime},\mathcal{F}^{\prime\prime}_{2}\rangle\) from \(\langle G,\mathcal{F}^{\prime}_{1}\rangle\), \(\langle G,\mathcal{F}^{\prime}_{2}\rangle\) by introducing an auxiliary root parent for \(Z\) and assigning a functional CPT for \(Z\). We add a root variable, denoted \(R\), to be an auxiliary parent of \(W\) which specifies all possible functions from \(\mathbf{P}^{*}\) to \(Z\) where \(\mathbf{P}^{*}\) contains all instantiations of \(\mathbf{P}^{*}\) where \(\Pr^{\prime}_{1}(\mathbf{p}^{*})=\Pr^{\prime}_{2}(\mathbf{p}^{*})>0\). Each state \(r\) of \(R\) corresponds to a function \(\varphi_{r}\) where \(\varphi_{r}(\mathbf{P}^{*})\) is mapped to some state of \(Z\) for each instantiation \(\mathbf{p}^{*}\). The variable \(R\) thus has \(|Z|^{|\mathbf{P}^{*}|}\) states since there are total of \(|Z|^{|\mathbf{P}^{*}|}\) possible functions from \(\mathbf{P}^{*}\) to \(Z\). For each instantiation \((z,r,\mathbf{p})\), if \(\mathbf{p}\in\mathbf{P}^{*}\), we define \(f^{\prime\prime}_{Z}(z|r,\mathbf{p})=1\) if \(z=\varphi_{r}(\mathbf{p})\), and \(f^{\prime\prime}_{Z}(z|r,\mathbf{p})=0\) otherwise. If \(\mathbf{p}\notin\mathbf{P}^{*}\), we define \(f^{\prime\prime\prime}_{Z}(z|r,\mathbf{p})=f^{\prime}_{Z}(z|\mathbf{p})\). The CPT for \(R\) is assigned as \(f^{\prime\prime}_{R}(r)=\prod_{\mathbf{p}\in\mathbf{P}^{*}}f^{\prime}_{Z}( \varphi_{r}(\mathbf{p})|\mathbf{p})\). Moreover, we remove all the states \(r\) of \(R\) where \(f^{\prime\prime}_{R}(r)=0\), which ensures \(f^{\prime\prime}_{R}(r)>0\) for all remaining \(r\). We assign the CPT \(g^{\prime}_{Z}\) in \(\mathcal{F}^{\prime\prime}_{2}\) in a similar way. Note that \(f^{\prime\prime}_{R}=g^{\prime\prime}_{R}\) since \(f^{\prime\prime}_{Z}(\varphi_{r}(\mathbf{p})|\mathbf{p})=\Pr^{\prime}_{1}( \varphi_{r}(\mathbf{p})|\mathbf{p})=\Pr^{\prime}_{2}(\varphi_{r}(\mathbf{p})| \mathbf{p})=g^{\prime}_{Z}(\varphi_{r}(\mathbf{p})|\mathbf{p})\) for each \(\mathbf{p}\in\mathbf{P}^{*}\) (where \(\Pr^{\prime}_{1}(\mathbf{p})=\Pr^{\prime}_{2}(\mathbf{p})>0\)).

We next show that \(\langle G^{\prime\prime},\mathcal{F}^{\prime\prime}_{1}\rangle\) and \(\langle G^{\prime\prime},\mathcal{F}^{\prime\prime}_{2}\rangle\) constitute the unidentifiability. One key observation is that \(f^{\prime\prime}_{r}(t|\mathbf{p})=\sum_{r}f^{\prime\prime}_{R}(r)f^{\prime \prime\prime}_{T}(t|\mathbf{p},r)\) and \(g^{\prime}_{T}(t|\mathbf{p})=\sum_{r}g^{\prime\prime}_{R}(r)g^{\prime\prime}_{T}( t|\mathbf{p},r)\). Consider each instantiation \((\mathbf{v},r)\) which contains the instantiation \(\mathbf{p}\) of \(\mathbf{P}\) and the state \(z\) of \(Z\). Suppose \(\Pr^{\prime}_{1}(\mathbf{p})=0\), then \(\Pr^{\prime\prime}_{1}(\mathbf{p})=0\) since the marginal over \(\mathbf{V}\) is preserved in \(\Pr^{\prime\prime}_{1x}\). Hence, \(\Pr^{\prime\prime}_{1}(\mathbf{v},r)=\Pr^{\prime\prime}_{2x}(\mathbf{v},r)=0\). Suppose \(\Pr^{\prime}_{1}(\mathbf{p})\neq 0\), then \(\Pr^{\prime\prime}_{1}(\mathbf{v},r)=(\prod_{V\in\mathbf{V}\setminus\{Z\}}f^{ \prime}_{V})\cdot f^{\prime\prime}_{R}(r)\) when \(z=\varphi_{r}(\mathbf{p})\), and \(\Pr^{\prime\prime}_{1}(\mathbf{v},r)=0\) otherwise. Similarly, \(\Pr^{\prime\prime}_{2}(\mathbf{v},r)=(\prod_{V\in\mathbf{V}\setminus\{Z\}}g^{ \prime}_{V})\cdot g^{\prime\prime}_{R}(r)\) when \(z=\varphi_{r}(\mathbf{p})\), and \(\Pr^{\prime\prime}_{2}(\mathbf{v},r)=0\) otherwise. In both cases, \(\Pr^{\prime\prime}_{1}(\mathbf{v},r)=\Pr^{\prime\prime}_{2}(\mathbf{v},r)\) since \(\mathcal{F}^{\prime\prime}_{1}\) and \(\mathcal{F}^{\prime\prime}_{2}\) assign a same function \(\varphi_{r}\) for each state \(r\) of \(R\), and \(f^{\prime}_{V}=g^{\prime}_{V}\) for all \(V\in\mathbf{V}\setminus\{Z\}\). To see \(\Pr^{\prime\prime}_{1x}(\mathbf{Y})=\Pr^{\prime}_{1x}(\mathbf{Y})\) and \(\Pr^{\prime\prime}_{2x}(\mathbf{Y})=\Pr^{\prime}_{2x}(\mathbf{Y})\), note that summing-out \(R\) from \(\Pr^{\prime\prime}_{1x}(\mathbf{V},R)\) and \(\Pr^{\prime}_{2x}(\mathbf{V},R)\) yields \(\Pr^{\prime}_{1x}(\mathbf{V})\This implies \(\Pr_{1x}^{\prime\prime\prime}(\mathbf{y}^{\prime},(r,t))\neq\Pr_{2x}^{\prime \prime}(\mathbf{y}^{\prime},(r,t))\) for the particular instantiation \(\mathbf{y}^{\prime}\) and the state \((r,t)\) of \(T^{\prime}\). Suppose \(T\) is the treatment variable \(X\), since \(\Pr_{1x}^{\prime\prime}(\mathbf{y})\neq\Pr_{2x}^{\prime\prime}(\mathbf{y})\), there exists an instantiation \((\mathbf{y},r)\) such that \(\Pr_{1x}^{\prime\prime}(\mathbf{y},r)\neq\Pr_{2x}^{\prime\prime}(\mathbf{y},r)\). Moreover, \(\Pr_{1x}^{\prime\prime}(r)=\Pr_{1x}^{\prime\prime}(r)=\Pr_{2x}^{\prime\prime}( r)=\Pr_{2x}^{\prime\prime}(r)>0\) (otherwise, \(\Pr_{1x}^{\prime\prime}(\mathbf{y},r)=\Pr_{2x}^{\prime\prime}(\mathbf{y},r)=0\)). This implies \(\Pr_{1x}^{\prime\prime}(\mathbf{y}|r)\neq\Pr_{2x}^{\prime\prime}(\mathbf{y}|r)\). Since \(R\) is a root in the multiset CBN, \(\Pr_{1(x)}^{\prime\prime}(\mathbf{y})=\Pr_{1x}^{\prime\prime}(\mathbf{y}|r) \neq\Pr_{2x}^{\prime\prime}(\mathbf{y}|r)=\Pr_{2(x)}^{\prime\prime}(\mathbf{y})\). We now consider the treatment \(do(T^{\prime}=(r,x))\) on \(G\) instead of the treatment \(do(R=r,X=x)\) on \(G^{\prime\prime}\). We have \(\Pr_{1(r,x)}^{\prime\prime\prime}(\mathbf{y})=\Pr_{1(r,x)}^{\prime\prime}( \mathbf{y})\neq\Pr_{2(r,x)}^{\prime\prime}(\mathbf{y})=\Pr_{2(r,x)}^{\prime \prime\prime}(\mathbf{y})\) for the particular state \((r,x)\) of \(T^{\prime}\). Moreover, \(\Pr_{1}^{\prime\prime\prime}((r,x))=\Pr_{1}^{\prime\prime}(r,x)=\Pr_{1}^{ \prime\prime}(r)\Pr_{1}^{\prime\prime}(x)>0\) by the positivity assumption of \(\Pr_{1}^{\prime\prime}(x)\). Thus, the positivity still holds for \(\Pr_{1}^{\prime\prime}\) and similarly for \(\Pr_{2}^{\prime\prime\prime}\). 

Proof of Theorem 18.: Let \(\mathbf{H}=\mathbf{V}^{\prime}\setminus\mathbf{V}\) be the set of hidden functional variables that are functionally determined by \(\mathbf{V}\). By Theorem 13, F-identifiable wrt \(\langle G,\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) iff F-identifiable wrt \(\langle G^{\prime},\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) where \(G^{\prime}\) is the result of functionally eliminating \(\mathbf{H}\) from \(G\). By construction, every variable in \(\mathbf{H}\) has parents in \(\mathbf{V}^{\prime}\). Hence, by Theorem 15, F-identifiable wrt \(\langle G^{\prime},\mathbf{V},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) iff F-identifiable wrt \(\langle G,\mathbf{V}^{\prime},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\). If we consider each functional variable \(W\in\mathbf{W}\), it is either in \(\mathbf{V}^{\prime}\) or having some parent that is not in \(\mathbf{V}^{\prime}\) (otherwise, \(W\) would have been added to \(\mathbf{V}^{\prime}\)). By Lemma 29, F-identifiable wrt \(\langle G,\mathbf{V}^{\prime},\mathcal{C}_{\mathbf{V}},\mathbf{W}\rangle\) iff identifiable wrt \(\langle G,\mathbf{V}^{\prime},\mathcal{C}_{\mathbf{V}}\rangle\).

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Our abstract and introduction accurately summarize our goal of studying causal-effect identifiability with functional dependencies. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The limitations have been discussed in the end of Section 5. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: Also proofs have been provided in the Appendix. 1. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? 1. Answer: [NA] Justification: This paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [NA] Justification: This paper does not include experiments. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA] Justification: This paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: This paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean.

* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: This paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We checked the code of ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: We do not see any direct societal impacts of the work. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This paper does not release any data or model. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: This paper does not use existing assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?Answer: [NA] Justification: This paper does not release new assets. Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.