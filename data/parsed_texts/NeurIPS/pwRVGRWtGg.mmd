# Apathetic or Empathetic? Evaluating LLMs'

Emotional Alignments with Humans

 Jen-tse Huang\({}^{1}\)1 & Man Ho Lam\({}^{1}\) & Eric John Li\({}^{1}\) & Shujie Ren\({}^{2}\) &Wenxuan Wang\({}^{1}\)2 & Wenxiang Jiao\({}^{3}\)3 & Zhaopeng Tu\({}^{3}\) & Michael R. Lyu\({}^{1}\)

\({}^{1}\)Department of Computer Science and Engineering, The Chinese University of Hong Kong

\({}^{2}\)Institute of Psychology, Tianjin Medical University &\({}^{3}\)Tencent AI Lab

{jthuang,wxwang,lyu}@cse.cuhk.edu.hk {mhlam,ejli}@link.cuhk.edu.hk shujieren@tmu.edu.cn {joelwxjiao,zptu}@tencent.com

Footnote 1: This work was partially done when Jen-tse Huang and Wenxuan Wang were interning at Tencent AI Lab.

Footnote 2: Wenxuan Wang and Wenxiang Jiao are corresponding authors.

###### Abstract

Evaluating Large Language Models' (LLMs) anthropomorphic capabilities has become increasingly important in contemporary discourse. Utilizing the emotion appraisal theory from psychology, we propose to evaluate the empathy ability of LLMs, _i.e._, how their feelings change when presented with specific situations. After a careful and comprehensive survey, we collect a dataset containing over 400 situations that have proven effective in eliciting the eight emotions central to our study. Categorizing the situations into 36 factors, we conduct a human evaluation involving more than 1,200 subjects worldwide. With the human evaluation results as references, our evaluation includes seven LLMs, covering both commercial and open-source models, including variations in model sizes, featuring the latest iterations, such as GPT-4, Mixtral-8x22B, and LLaMA-3.1. We find that, despite several misalignments, LLMs can generally respond appropriately to certain situations. Nevertheless, they fall short in alignment with the emotional behaviors of human beings and cannot establish connections between similar situations. Our collected dataset of situations, the human evaluation results, and the code of our testing framework, _i.e._, EmotionBench, are publicly available at https://github.com/CUHK-ARISE/EmotionBench.

## 1 Introduction

Large Language Models (LLMs) have recently made significant strides in Artificial Intelligence (AI), representing a noteworthy milestone in computer science. LLMs have showcased their capabilities across various tasks, including sentence revision (Wu et al., 2023), text translation (Jiao et al., 2023), program repair (Fan et al., 2023), and program testing (Deng et al., 2023; Kang et al., 2023). Not limited to research level, LLMs, such as ChatGPT (OpenAI, 2022), have revolutionized the way people interact with traditional software, enhancing fields such as education (Dai et al., 2023), legal advice (Deroy et al., 2023), and clinical medicine (Cascella et al., 2023). LLMs also facilitate the emergence of AI companion applications, including Yuna (https://www.yuna.io/), Pimento (https://www.pimento.design/), and Luzia (https://www.luzia.com/en). Consequently, there is a growing need for evaluating LLMs' communicative dynamics compared to human behaviors, beyond mere performance on downstream tasks.

This paper delves into an unexplored area of evaluating LLMs' **emotional alignment** with humans. Consider our daily experiences: (1) When faced with certain situations, humans often experiencesimilar emotions. For instance, walking alone at night and hearing footsteps approaching from behind often triggers feelings of anxiety or fear. (2) Individuals display varying levels of emotional response to specific situations. For example, some people may experience increased impatience and irritation when faced with repetitive questioning. It is noteworthy that we are inclined to form friendships with individuals who possess qualities such as patience and calmness. Based on these observations, we propose the following requirements for LLMs in order to achieve better alignment with human behaviors: (1) LLMs should accurately respond to specific situations regarding the emotions they exhibit. (2) LLMs should demonstrate emotional robustness when faced with negative emotions. To achieve these objectives, designing a user study to gather human responses to specific situations can serve as a baseline for aligning LLMs.

We focus on the expression of negative emotions by LLMs, which may contribute to negative user experiences. We utilize Parrott's emotion framework (Parrott, 2001; Shaver et al., 1987), which organizes emotions into three hierarchical levels, to select the relevant emotions for our study. The primary level of emotions comprises six basic emotions, split evenly into three positive and three negative. From the negative primary emotions, we specifically focus on eight subordinate emotions: anger, anxiety, depression, frustration, jealousy, guilt, fear, and embarrassment. To collect relevant situations for these emotions, we utilize emotion appraisal theory from psychology, which studies how everyday situations arouse different human emotions (Roseman and Smith, 2001). Research in this field has identified numerous situations that arouse specific emotions, which can serve as contextual input for LLMs. Through an extensive review including over 100 papers, we collect a dataset of 428 situations from 18 papers, which are further categorized into 36 factors.

Subsequently, we propose a framework for quantifying the emotional states of LLMs, consisting of the following steps: (1) Measure the default emotional values of LLMs. (2) Transform situations into contextual inputs and instruct LLMs to imagine being in the situations. (3) Measure LLMs' emotional responses again to capture the difference. Our evaluation includes state-of-the-art LLMs, namely Text-Davinci-003, GPT-3.5-Turbo (OpenAI, 2022), and GPT-4 (OpenAI, 2023). Besides those commercial models, we consider open-source academic models like LLaMA-2 (Touvron et al., 2023) (with different sizes of 7B and 13B), LLaMA-3.1-8B (Dubey et al., 2024), and Mistral-8x22B (Jiang et al., 2024a). We apply the same procedure to 1,266 human subjects from around the globe to establish a baseline from a human perspective. Finally, we analyze and compare the scores between LLMs and humans. Our key conclusions are as follows:

* Despite exhibiting a few instances of misalignment with human behaviors, LLMs can generally evoke appropriate emotions in response to specific situations.
* Certain LLMs, such as Text-Davinci-003, display lower emotional robustness, as evidenced by higher fluctuations in emotional responses to negative situations.
* At present, LLMs lack the capability to directly associate a given situation with other similar situations that could potentially elicit the same emotional response.

The contributions of this paper are:

* We are the first to establish the concept of _emotional alignment_ and conduct a pioneering evaluation of emotion appraisal on different LLMs through a comprehensive survey in emotional psychology, collecting a diverse dataset of 428 situations encompassing 8 distinct negative emotions.
* A human baseline is established through a user study involving 1,266 annotators from different ethnics, genders, regions, age groups, _etc._
* We design, implement, and release a testing framework for developers to assess the emotional alignment of AI models with human emotional expression, available at GitHub1 and HuggingFace.2

Footnote 1: https://github.com/CUHK-ARISE/EmotionBench

Footnote 2: https://huggingface.co/datasets/CUHK-ARISE/EmotionBench

## 2 Measuring Emotions

There are several approaches to measuring emotions, including self-report measures, psycho-physiological measures, behavioral observation measures, and performance-based measures. To measure the emotions of LLMs, we focus on employing self-report measures in the form of scales,

[MISSING_PAGE_FAIL:3]

people <emotion>," resulting in more than 100 papers. We apply the following rules to filter irrelevant or undesired papers: (1) We first select those providing situations that elicit the desired emotion rather than explaining how and why people evoke certain emotions. (2) We then exclude those using vague and short descriptions, such as "loss of opportunities." (3) Finally, we deprecate those applied to a specific group, such as "the anxiety doctors or nurses may encounter in their work." We finally collect 18 papers, presenting a compilation of situations that have proven to elicit the eight emotions in humans effectively. We extract 428 situations in total and then categorize them into 36 factors. For each factor, the descriptions, the numbers of situations, and the corresponding references can be found in Table 6 in the Appendix, while example Table 7 in the Appendix provides examples for all factors.

### Measuring Arousal Emotions

This section outlines our proposed framework for measuring evoked emotions, which applies to both LLMs and humans. The framework includes the following steps: (1) _Default Emotion Measure_: We begin by measuring the baseline emotional states of both LLMs and human subjects, labeled as "Default." (2) _Situation Imagination_: Next, we present textual descriptions of various situations to both LLMs and human subjects, instructing them to imagine themselves within each situation. (3) _Evoked Emotion Measure_: Following the situation imagination instruction, we reevaluate the participants' emotional states to gauge the changes resulting from imagining being in the situations. Fig. 1 briefly illustrates our framework. Below is an example prompt:

Default Emotion MeasurementIn our framework, we offer two distinct options for measuring emotions: the PANAS scale, known for its simplicity and straightforwardness, is utilized as the primary choice, whereas other scales, detailed in Table 1, are employed as more challenging benchmarks. We mitigate potential biases caused by the ordering of questions (Zhao et al., 2021) by randomizing the sequence of questions within the scales before inputting them into the LLMs. Coda-Forno et al. (2023) and Huang et al. (2024) apply paraphrasing techniques to address the data contamination problem during the training of the LLMs. However, we refrain from utilizing this method in our research since paraphrasing could lead to a loss of both validity and reliability. The working of items of a psychological scale is carefully crafted and rigorously validated through extensive research to ensure its precision in measuring the intended construct. Finally, to ensure consistency and clarity in the responses obtained from the LLMs, our prompts explicitly specify that only numerical values are allowed, accompanied by a clear definition of the meaning associated with each number (_e.g._, 1 denotes "Not at all"). We compute the average results obtained from at least ten runs to derive the final "Default" scores of the LLMs.

Figure 1: Our framework for testing both LLMs and humans.

Situation ImaginationWe have constructed a comprehensive dataset of 428 unique situations. Prior to presenting these situations to both LLMs and humans, we subject them to a series of pre-processing steps, which are as follows: (1) Personal pronouns are converted to the second person. For instance, sentences such as "I am..." are transformed to "You are..." (2) Indefinite pronouns are replaced with specific characters, thereby refining sentences like "Somebody talks back..." to "Your classmate talks back..." (3) Abstract words are rendered into tangible entities. For example, a sentence like "You cannot control the outcome." is adapted to "You cannot control the result of an interview." We leverage GPT-4 for the automatic generation of specific descriptions. Consequently, our testing situations extend beyond the initially collected dataset as we generate diverse situations involving various characters and specific contextual elements. We then provide instruction to LLMs and humans, which prompts them to imagine themselves as the protagonists within the given situation.

Evoked Emotion MeasureProvided with certain situations, LLMs and human subjects are required to re-complete the emotion measures. The procedure remains the same with the _Default Emotion Measure_ stage. After obtaining the "Evoked" scores of emotions, we conduct a comparative analysis of the means before and after exposure to the situations, thereby measuring the emotional changes caused by the situations.

### Obtaining Human Results

Goal and DesignHuman reference plays a pivotal role in the advancement of LLMs, facilitating its alignment with human behaviors (Binz & Schulz, 2024). In this paper, we propose requiring LLMs to align with human behavior, particularly concerning emotion appraisal accurately. To achieve this, we conduct a data collection process involving human subjects, following the procedure outlined in SS3.2. Specifically, the subjects are asked to complete the PANAS initially. Next, they are presented with specific situations and prompted to imagine themselves as the protagonists in those situations. Finally, they are again asked to reevaluate their emotional states using the PANAS. We use the same situation descriptions as those presented to the LLMs.

Crowd-sourcingOur questionnaire is distributed on Qualtrics (https://www.qualtrics.com/), a platform known for its capabilities in designing, sharing, and collecting questionnaires. To recruit human subjects, we utilize Prolific (https://www.prolific.com/), a platform designed explicitly for task posting and worker recruitment. To attain a medium level of effect size with Cohen's \(d=0.5\), a significance level of \(\alpha=0.05\), and a power of test of \(1-\beta=0.8\)(Faul et al., 2007), a minimum of 34 responses is deemed necessary for each factor. To ensure this threshold, we select five situations3 for each factor, and collect at least seven responses for each situation, resulting in \(5\times 7=35\) responses per factor, thereby guaranteeing the statistical validity of our survey. In order to uphold the quality and reliability of the data collected, we recruit crowd workers who met the following criteria: (1) English being their first and fluent language, and (2) being free of any ongoing mental illness. Prolific provides prescreening filters to meet these requirements. Since responses formed during subjects' first impressions are more likely to yield genuine and authentic answers, we set the estimated and recommended completion time at \(2.5\) minutes. As an incentive for their participation, each worker is rewarded with \(0.3\mathcal{L}\) (\(9\mathcal{L}\approx 11.458\) per hour, rated as "Good" on the platform) after we verify the validity of their response. In total, we successfully collect 1,266 responses from various parts of the world, contributing to the breadth and diversity of our dataset.

Footnote 3: Note that two factors in the Jealousy category have less than five situations.

## 4 Experimental Results

Leveraging the testing framework designed and implemented in SS3.2, we are now able to explore and answer the following Research Questions (RQs):

* **RQ1**: How do different LLMs respond to specific situations? Additionally, to what degree do the current LLMs align with human behaviors?
* **RQ2**: Do LLMs respond similarly towards all situations? What is the result of using positive or neutral situations?

[MISSING_PAGE_FAIL:6]

**Existing LLMs do not fully align with human emotional responses.** For the default emotions, we find that LLMs generally exhibit a stronger intensity compared to human subjects. Emotion changes in LLMs are found to be generally more pronounced compared to human subjects, especially on their changes in the positive score. However, an interesting observation is that the intensity of evoked emotions tends to be similar across both LLMs and human subjects.

**LLMs do not feel jealous towards others' benefits.** It is of special interest that, in contrast to human behavior in situations involving material possessions, LLMs demonstrate an opposite response in the situation from Jealousy-3. This situation involves an individual making a purchase only to discover that an acquaintance has acquired the same item at a significantly lower price. When confronted with such circumstances, humans typically experience increased negative emotions and decreased positive emotions. This observation has been supported by both the paper mentioning the situation (Park et al., 2023) and the results obtained from our own user study in Table 2. However, all LLMs, including the GPT and LLaMA families, consistently exhibit reduced negative emotions. The outcomes of our study indicate that LLMs do not manifest envy when they fail to attain identical benefits as others. Instead, it demonstrates a sense of pleasure upon knowing the benefits received by others.

### RQ2: Comprehending Positive Emotions

**GPT-3.5-Turbo responds differently towards positive/neutral situations.** To verify that LLMs exhibit not only negative but also positive responses to favorable circumstances, a comparative experiment is conducted by interchanging negative situations with positive (or at least neutral) counterparts. To achieve this, we select one situation for each factor and manually adapt it to create analogous yet more positive situations. For instance, the original negative situation in Guilit-3: Broken Promises and Responsibilities is as follows: "You cannot keep your promises to your children." Through modification, the positive situation is rephrased as: "You keep every promise to your children." The evaluation is performed on GPT-3.5-Turbo, and each test consists of ten iterations, as mentioned before. We present the results averaged by emotions in Table 4, and results averaged by factors in Table 12 in the Appendix. We can see a significant increase in positive scores and a considerable decrease in negative scores compared to the previous negative situations. Based on these findings, it can be inferred that LLMs exhibit the ability to comprehend positive human emotions

\begin{table}
\begin{tabular}{l c c} \hline \hline
**Factors** & **P** & **N** \\ \hline Anger & \(\uparrow\)(\(+13.0\)) & \(\downarrow\)(\(-12.0\)) \\ Anxiety & \(\uparrow\)(\(+17.5\)) & \(\downarrow\)(\(-5.8\)) \\ Depression & \(\uparrow\)(\(+18.4\)) & \(\downarrow\)(\(-11.7\)) \\ Frustration & \(\uparrow\)(\(+16.6\)) & \(-\)(\(-2.6\)) \\ Jealousy & \(\uparrow\)(\(+4.5\)) & \(\downarrow\)(\(-5.3\)) \\ Guilt & \(\uparrow\)(\(+18.3\)) & \(\downarrow\)(\(-12.7\)) \\ Fear & \(\uparrow\)(\(+11.0\)) & \(\downarrow\)(\(-17.5\)) \\ Embarrassment & \(\uparrow\)(\(+13.6\)) & \(\downarrow\)(\(-13.2\)) \\ \hline
**Overall** & \(\uparrow\)(\(+14.3\)) & \(\downarrow\)(\(-10.4\)) \\ \hline \hline \end{tabular}
\end{table}
Table 4: Results of GPT-3.5-Turbo on positive or neutral situations. The changes are compared to the original negative situations. The symbol “\(-\)” denotes no significant differences.

\begin{table}
\begin{tabular}{l c c c c c c c c} \hline \hline
**Factors** & \multicolumn{2}{c}{**LLaMA-2-7B-Chat**} & \multicolumn{2}{c}{**LLaMA-2-13B-Chat**} & \multicolumn{2}{c}{**LLaMA-3.1-8B-Instruct**} & \multicolumn{2}{c}{**Mistral-8x22B-Instruct**} \\ \cline{2-9}  & **P** & **N** & **P** & **N** & **P** & **N** & **P** & **N** \\ \hline Default & \(43.0\pm 4.2\) & \(34.2\pm 4.0\) & \(41.0\pm 3.5\) & \(22.7\pm 4.2\) & \(48.2\pm 1.4\) & \(33.0\pm 4.5\) & \(31.9\pm 1.3\) & \(10.0\pm 0.1\) \\ \hline Anger & \(\downarrow\)(\(-5.1\)) & \(\uparrow\)(\(+3.6\)) & \(\downarrow\)(\(-7.9\)) & \(\uparrow\)(\(+5.8\)) & \(\downarrow\)(\(-23.6\)) & \(\uparrow\)(\(+2.3\)) & \(\downarrow\)(\(-11.7\)) & \(\uparrow\)(\(+16.9\)) \\ Anxiety & \(\downarrow\)(\(-3.8\)) & \(\uparrow\)(\(+2.7\)) & \(\downarrow\)(\(-5.8\))triggered by positive environments. However, we believe that the systematic assessment of emotion appraisal on positive emotions holds significance as well and leave it for future investigation.

### RQ3: Challenging Benchmarks

**GPT-3.5-Turbo cannot comprehend the underlying evoked emotions to establish a link between two situations.** Aside from PANAS, we offer more complex scales to measure emotions, as listed in Table 1. While the PANAS evaluates the ability of LLMs to associate external situations with emotions, the challenging benchmarks assess its proficiency in establishing connections between disparate situations, with evoked emotions as the common nexus. For instance, an item from the Aggression Questionnaire used to measure anger is "Once in a while I can't control the urge to strike another person." When presented with situations such as "If you say 40, your classmates say 70, saying exactly the opposite" (from Anger-1: Facing Self-Opinioned People), LLMs should effectively evoke a sense of anger and yield a higher score for the statement. Utilizing the same situations in SS4.1, we conduct experiments on GPT-3.5-Turbo and present the results in averaged by emotions in Table 5, and results averaged by factors in Table 13 in the Appendix. Except for Depression, we observe no statistically significant difference between the initial scores and the scores after exposure to the situations, indicating substantial room for improvement in current LLMs.

## 5 Discussions

### Beyond Questionnaires

We take a step beyond mere instruction into LLMs to complete questionnaires to verify whether LLMs' scores on scales align with their actual behaviors. In this section, we investigate the impact of varying emotional states of LLMs on potential daily conversations. To this end, we instruct GPT-3.5-Turbo to describe specific demographic groups, aiming to discern whether they produce biased or toxic responses. Following Cheng et al. (2023), our approach utilizes prompts such as "Describe a(n) [race/ethnicity] [gender]," including a total of twenty groups, with [race/ethnicity] options being Asian, Black, Latine, Middle Eastern, and White, and [gender] options including Female, Gay, Lesbian, and Male. To have a comparative experiment, we incorporate both original negative situations and modified positive/neutral ones, detailed in SS4.2. For the negative situations, we carefully select five that maximize the LLM's negative scores and five that minimize positive ones. As for positive situations, we employ their corresponding ten modified counterparts. In each situation, we instruct GPT-3.5-Turbo to describe the twenty demographic groups.

OpenAI's GPT models incorporate a mechanism for detecting potential toxicity and bias, and it refrains from responding when its moderation system is triggered. Consequently, we propose a novel metric to assess toxicity in responses rather than detecting it directly. We count the Percentage of LLM Refusing to answer (PoR), assuming that the LLM's refusal to respond is indicative of detected toxicity. Our evaluation results indicate that the PoR is 0% when fed with no situations. However, when presented with negative situations, the PoR is 29.5%, and when presented with positive situations, it is 12.5%. Notably, this outcome suggests that while certain positive situations lead to the LLM's heightened vigilance (the 4.5% PoR stems from the Jealousy-2), negative situations trigger increased moderation, suggesting a higher likelihood of generating toxic outputs. A related

\begin{table}
\begin{tabular}{l l l l} \hline \hline
**Emotions** & **Scales** & **Default** & **Changes** \\ \hline Anger & AGQ & \(128.3\pm 8.9\) & \(-(+1.3)\) \\ Anxiety & DASS-21 & \(32.5\pm 10.0\) & \(-(-2.3)\) \\ Depression & BDI-II & \(0.2\pm 0.6\) & \(\uparrow(+6.4)\) \\ Frustration & FDS & \(91.6\pm 8.1\) & \(=\)\((-7.5)\) \\ Jealousy & MJS & \(83.7\pm 20.3\) & \(-(-0.1)\) \\ Guilt & GASP & \(81.3\pm 9.7\) & \(-(-2.6)\) \\ Fear & FSS-III & \(140.6\pm 16.9\) & \(-(-0.3)\) \\ Embarrassment & BFNE & \(39.0\pm 1.9\) & \(-(+0.2)\) \\ \hline \hline \end{tabular}
\end{table}
Table 5: Results of GPT-3.5-Turbo on challenging benchmarks. The changes are compared to the default scores. The symbol “\(-\)” denotes no significant differences.

study by Coda-Forno et al. (2023) also discovers that GPT-3.5-Turbo is more likely to exhibit biases when presented with a sad story. The likelihood is found to be highest with sad stories, followed by happy stories, and finally, neutral stories, which is consistent with our research. Additionally, our study observes that the LLM's tone becomes more aggressive when encountering negative situations. At the same time, it displays a greater willingness to describe the groups (as indicated by longer responses) when presented with positive situations. In conclusion, we can see that changing the emotional states of LLMs **extends beyond mere quantitative measures on questionnaire scores, influencing the behaviors of LLMs.**

### Limitations

This study is subject to several limitations. First, the survey of collecting situations might not cover all papers within the domain of emotion appraisal theory. Additionally, the limited scope of situations from the collected papers might not fully capture the unlimited situations in our daily lives. To address this issue, we conduct a thorough review of the existing literature as outlined in SS3.1. Moreover, the proposed framework is inherently flexible, allowing users to seamlessly integrate new situations to examine their impact on LLMs' emotions.

The second concern relates to the suitability of employing scales primarily designed for humans on LLMs, _i.e._, whether LLMs can produce stable responses to the emotion measurement scales. To address the issue, our evaluation incorporates multiple tests varying the order of questions, a methodology consistent with other research (Huang et al., 2024, 2023); Coda-Forno et al., 2023). Additionally, we assess the sensitivity of LLM to differing prompt instructions. Utilizing one template from Romero et al. (2023) and two from Serapio-Garcia et al. (2023), we run experiments on the Anger-evoking situations using GPT-3.5-Turbo. The results indicate that the employment of diverse prompts yields similar mean values with reduced variance. Furthermore, Serapio-Garcia et al. (2023) have proposed a comprehensive method to evaluate the validity of psychological scales on LLMs. Using the _Big Five Inventory_ as a case study, they demonstrate that scales originally designed for human assessment also maintain satisfactory validity when applied to LLMs.

The third potential threat is the focus on negative emotions. It is plausible for the LLMs to perform well on our benchmark by consistently responding negatively to all situations. To offset this possibility, we adopt a twofold strategy: firstly, we evaluate powerful LLMs, and secondly, we conducted a comparative experiment in SS4.2 to evaluate the LLM's capacity to accurately respond to non-negative situations. We also acknowledge the need for future work to systematically evaluate emotions aroused by positive situations.

## 6 Related Work

Researchers have dedicated significant attention to applying psychological scales to LLMs, employing various assessment tools such as the _HEXACO Personality Inventory_(Miotto et al., 2022; Bodroza et al., 2023), the _Big Five Inventory_(Romero et al., 2023; Jiang et al., 2023; Karra et al., 2022; Bodroza et al., 2023; Rutinowski et al., 2024; Serapio-Garcia et al., 2023; Jiang et al., 2024), the _Myers-Briggs Type Indicator_(Rutinowski et al., 2024; Wang et al., 2024; Rao et al., 2023), and the _Dark Triad_(Li et al., 2022; Bodroza et al., 2023). In addition to these personality tests, several studies have investigated other dimensions of LLMs. For instance, Li et al. (2022) examined _Flourishing Scale_ and _Satisfaction With Life Scale_, Bodroza et al. (2023) assessed _Self-Consciousness Scales_ and _Bidimensional Impression Management Index_, while Huang et al. (2024) built a framework consisting of thirteen widely-used scales. Another aspect explored in the literature pertains to anxiety levels exhibited by LLMs, as investigated by Coda-Forno et al. (2023) through the _State-Trait Inventory for Cognitive and Somatic Anxiety_.

Figure 2: GPT-3.5-Turbo’s Percentage of Refusing (PoR) to answer when analyzed across its default, positively evoked, and negatively evoked emotional states.

Meanwhile, researchers focus on identifying emotions in LLMs or evaluating their emotional intelligence. Rashkin et al. (2019) propose a dataset, _EmpatheticDialogues_, containing conversations annotated with specific emotions. _EmotionPrompt_(Li et al., 2023) demonstrates the enhancement of LLMs' performance in downstream tasks by utilizing emotional stimuli. Tak & Gratch (2023) focuses on varying aspects of situations that impact the emotional intensity and coping tendencies of the GPT family. _Chain-Of-Emotion_(Croissant et al., 2024) makes LLM simulate human-like emotions. _CovidET-Appraisals_(Zhan et al., 2023) evaluates how LLMs appraise Reddit posts about COVID-19 by asking 24 types of questions. Yongsatianchot et al. (2023) applies the _Stress and Coping Process Questionnaire_ to the GPT family and compares the results with human data. _Chain-of-Empathy_(Lee et al., 2023) improves LLMs' ability to understand users' emotions and to respond accordingly. LI et al. (2024) introduces _EmotionAttack_ to impair AI model performance and _EmotionDecode_ to explain the effects of emotional stimuli, both benign and malignant. He et al. (2024) prompt LLMs to generate tweets on various topics and evaluate their alignment with human emotions by measuring their proximity to human-generated tweets.

## 7 Conclusion

We set up a direction to align LLMs' emotional responses with humans in this study. Focusing on eight negative emotions, we conduct a comprehensive survey in the emotion appraisal theory of psychology. We collect 428 distinct situations which are categorized into 36 factors. We distribute questionnaires among a diverse crowd to establish human baselines for emotional responses to particular situations, ultimately garnering 1,266 valid responses. Our evaluation of five models from OpenAI and Meta AI indicates that LLMs generally demonstrate appropriate emotional responses to given situations. Also, different models show different intensities of emotion appraisals for the same situations. However, none of the models exhibit strong alignment with human references at the current stage. In conclusion, current LLMs still have considerable room for improvement. We believe our framework can provide valuable insights into the development of LLMs, ultimately enhancing its human-like emotional understanding.

## Acknowledgments

We would like to express our sincere gratitude to Xiaoyuan Liu and Pinjia He from the Chinese University of Hong Kong, Shenzhen, for their valuable assistance during the rebuttal process. The paper is supported by the Research Grants Council of the Hong Kong Special Administrative Region, China (No. CUHK 14206921 of the General Research Fund).

## References

* Arnold (1960) Magda B Arnold. Emotion and personality. _Psychological aspects_, 1, 1960.
* Arrindell et al. (1984) Willem A Arrindell, Paul MG Emmelkamp, et al. Phobic dimensions: I. reliability and generalizability across samples, gender and nations: The fear survey schedule (fss-iii) and the fear questionnaire (fq). _Advances in Behaviour Research and Therapy_, 6(4):207-253, 1984.
* Beck et al. (1996) Aaron T Beck, Robert A Steer, and Gregory Brown. Beck depression inventory-ii. _Psychological Assessment_, 1996.
* Berna et al. (2011) Chantal Berna, Tamara J Lang, Guy M Goodwin, and Emily A Holmes. Developing a measure of interpretation bias for depressed mood: An ambiguous scenarios test. _Personality and Individual Differences_, 51(3):349-354, 2011.
* Binz and Schulz (2024) Marcel Binz and Eric Schulz. Turning large language models into cognitive models. In _The Twelfth International Conference on Learning Representations_, 2024.
* Blanchard et al. (2001) D Caroline Blanchard, April L Hynd, Karl A Minke, Tiffanie Minemoto, and Robert J Blanchard. Human defensive behaviors to threat scenarios show parallels to fear-and anxiety-related defense patterns of non-human mammals. _Neuroscience & Biobehavioral Reviews_, 25(7-8):761-770, 2001.
* Blanchard et al. (2002)Bojana Bodroza, Bojana M Dinic, and Ljubisa Bojic. Personality testing of gpt-3: Limited temporal reliability, but highlighted social desirability of gpt-3's personality instruments results. _arXiv preprint arXiv:2306.04308_, 2023.
* Buss and Perry (1992) Arnold H Buss and Mark Perry. The aggression questionnaire. _Journal of personality and social psychology_, 63(3):452, 1992.
* Cascella et al. (2023) Marco Cascella, Jonathan Montomoli, Valentina Bellini, and Elena Bignami. Evaluating the feasibility of chatgpt in healthcare: an analysis of multiple clinical and research scenarios. _Journal of Medical Systems_, 47(1):33, 2023.
* Cheng et al. (2023) Myra Cheng, Esin Durmus, and Dan Jurafsky. Marked personas: Using natural language prompts to measure stereotypes in language models. In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pp. 1504-1532, 2023.
* Coda-Forno et al. (2023) Julian Coda-Forno, Kristin Witte, Akshay K Jagadish, Marcel Binz, Zeynep Akata, and Eric Schulz. Inducing anxiety in large language models increases exploration and bias. _arXiv preprint arXiv:2304.11111_, 2023.
* Cohen et al. (2011) Taya R Cohen, Scott T Wolf, Abigail T Panter, and Chester A Insko. Introducing the gasp scale: a new measure of guilt and shame proneness. _Journal of personality and social psychology_, 100(5):947, 2011.
* Croissant et al. (2024) Maximilian Croissant, Madeleine Frister, Guy Schofield, and Cade McCall. An appraisal-based chain-of-emotion architecture for affective language model game agents. _Plos one_, 19(5):e0301033, 2024.
* Cuthbert et al. (2003) Bruce N Cuthbert, Peter J Lang, Cyd Strauss, David Drobes, Christopher J Patrick, and Margaret M Bradley. The psychophysiology of anxiety disorder: Fear memory imagery. _Psychophysiology_, 40(3):407-422, 2003.
* Dai et al. (2023) Wei Dai, Jionghao Lin, Hua Jin, Tongguang Li, Yi-Shan Tsai, Dragan Gasevic, and Guanliang Chen. Can large language models provide feedback to students? a case study on chatgpt. In _2023 IEEE International Conference on Advanced Learning Technologies (ICALT)_, pp. 323-325. IEEE, 2023.
* Deng et al. (2023) Yinlin Deng, Chunqiu Steven Xia, Haoran Peng, Chenyuan Yang, and Lingming Zhang. Large language models are zero-shot fuzzers: Fuzzing deep-learning libraries via large language models. In _Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis_, pp. 423-435, 2023.
* Deroy et al. (2023) Aniket Deroy, Kripabandhu Ghosh, and Saptarshi Ghosh. How ready are pre-trained abstractive models and llms for legal case judgement summarization? _arXiv preprint arXiv:2306.01248_, 2023.
* Dubey et al. (2024) Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models. _arXiv preprint arXiv:2407.21783_, 2024.
* Fan et al. (2023) Zhiyu Fan, Xiang Gao, Martin Mirchev, Abhik Roychoudhury, and Shin Hwei Tan. Automated repair of programs from large language models. In _2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)_, pp. 1469-1481. IEEE, 2023.
* Faul et al. (2007) Franz Faul, Edgar Erdfelder, Albert-Georg Lang, and Axel Buchner. G* power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences. _Behavior research methods_, 39(2):175-191, 2007.
* Guitard et al. (2019) Tanya Guitard, Stephane Bouchard, Claude Belanger, and Maxine Berthiaume. Exposure to a standardized catastrophic scenario in virtual reality or a personalized scenario in imagination for generalized anxiety disorder. _Journal of clinical Medicine_, 8(3):309, 2019.
* Harrington (2005) Neil Harrington. The frustration discomfort scale: Development and psychometric properties. _Clinical Psychology & Psychotherapy: An International Journal of Theory & Practice_, 12(5):374-387, 2005.
* Harrington et al. (2019)Zihao He, Siyi Guo, Ashwin Rao, and Kristina Lerman. Whose emotions and moral sentiments do language models reflect? In _Findings of the Association for Computational Linguistics: ACL 2024_, pp. 611-6631, 2024.
* Henry and Crawford (2005) Julie D Henry and John R Crawford. The short-form version of the depression anxiety stress scales (dass-21): Construct validity and normative data in a large non-clinical sample. _British journal of clinical psychology_, 44(2):227-239, 2005.
* Hu et al. (2022) Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. Lora: Low-rank adaptation of large language models. In _International Conference on Learning Representations_, 2022.
* Huang et al. (2024a) Jen-tse Huang, Wenxiang Jiao, Man Ho Lam, Eric John Li, Wenxuan Wang, and Michael R Lyu. On the reliability of psychological scales on large language models. In _Proceedings of The 2024 Conference on Empirical Methods in Natural Language Processing_, 2024a.
* Huang et al. (2024b) Jen-tse Huang, Wenxuan Wang, Eric John Li, Man Ho Lam, Shujie Ren, Youliang Yuan, Wenxiang Jiao, Zhaopeng Tu, and Michael R Lyu. On the humanity of conversational ai: Evaluating the psychological portrayal of llms. In _Te Twelfth International Conference on Learning Representations_, 2024b.
* Jiang et al. (2024a) Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al. Mixtral of experts. _arXiv preprint arXiv:2401.04088_, 2024a.
* Jiang et al. (2023) Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wenjuan Han, Chi Zhang, and Yixin Zhu. Evaluating and inducing personality in pre-trained language models. _Advances in Neural Information Processing Systems_, 36, 2023.
* Jiang et al. (2024b) Hang Jiang, Xiajie Zhang, Xubo Cao, Cynthia Breazeal, Deb Roy, and Jad Kabbara. Personallm: Investigating the ability of large language models to express personality traits. In _Findings of the Association for Computational Linguistics: NAACL 2024_, 2024b.
* Jiao et al. (2023) Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Xing Wang, Shuming Shi, and Zhaopeng Tu. Is chatgpt a good translator? yes with gpt-4 as the engine. _arXiv preprint arXiv:2301.08745_, 2023.
* Kang et al. (2023) Sungmin Kang, Juyeon Yoon, and Shin Yoo. Large language models are few-shot testers: Exploring llm-based general bug reproduction. In _2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)_, pp. 2312-2323. IEEE, 2023.
* Karra et al. (2022) Saketh Reddy Karra, Son The Nguyen, and Theja Tulabandhula. Estimating the personality of white-box language models. _arXiv preprint arXiv:2204.12000_, 2022.
* Keller and Nesse (2005) Matthew C Keller and Randolph M Nesse. Is low mood an adaptation? evidence for subtypes with symptoms that match precipitants. _Journal of affective disorders_, 86(1):27-35, 2005.
* Kupfer et al. (2022) Tom R Kupfer, Morgan J Sidari, Brendan P Zietsch, Patrick Jern, Joshua M Tybur, and Laura W Wesseldijk. Why are some people more jealous than others? genetic and environmental factors. _Evolution and Human Behavior_, 43(1):26-33, 2022.
* Lazarus (1991) Richard S Lazarus. _Emotion and adaptation_. Oxford University Press, 1991.
* Leary (1983) Mark R Leary. A brief version of the fear of negative evaluation scale. _Personality and social psychology bulletin_, 9(3):371-375, 1983.
* Lee et al. (2022) Choonghyoung Lee, Jahyun Song, and Bill Ryan. When employees feel envy: The role of psychological capital. _International Journal of Hospitality Management_, 105:103251, 2022.
* Lee et al. (2023) Yoon Kyung Lee, Inju Lee, Minjung Shin, Seoyeon Bae, and Sowon Hahn. Chain of empathy: Enhancing empathetic response of large language models based on psychotherapy models. _arXiv preprint arXiv:2311.04915_, 2023.
* Li et al. (2023) Cheng Li, Jindong Wang, Yixuan Zhang, Kaijie Zhu, Wenxin Hou, Jianxun Lian, Fang Luo, Qiang Yang, and Xing Xie. Large language models understand and can be enhanced by emotional stimuli. _arXiv preprint arXiv:2307.11760_, 2023.
* Liu et al. (2020)CHENG LI, Jindong Wang, Yixuan Zhang, Kaijie Zhu, Xinyi Wang, Wenxin Hou, Jianxun Lian, Fang Luo, Qiang Yang, and Xing Xie. The good, the bad, and why: Unveiling emotions in generative ai. In _Proceedings of The Forty-first International Conference on Machine Learning_, 2024.
* Li et al. (2022) Xingxuan Li, Yutong Li, Lin Qiu, Shafiq Joty, and Lidong Bing. Evaluating psychological safety of large language models. _arXiv preprint arXiv:2212.10529_, 2022.
* Luck and Luck-Sikorski (2022) Tobias Luck and Claudia Luck-Sikorski. The wide variety of reasons for feeling guilty in adults: findings from a large cross-sectional web-based survey. _BMC psychology_, 10(1):1-20, 2022.
* Martin and Dahlen (2007) Ryan C Martin and Eric R Dahlen. The angry cognitions scale: A new inventory for assessing cognitions in anger. _Journal of Rational-Emotive & Cognitive-Behavior Therapy_, 25:155-173, 2007.
* Miotto et al. (2022) Marilu Miotto, Nicola Rossberg, and Bennett Kleinberg. Who is gpt-3? an exploration of personality, values and demographics. In _Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+ CSS)_, pp. 218-227, 2022.
* Moors et al. (2013) Agnes Moors, Phoebe C Ellsworth, Klaus R Scherer, and Nico H Frijda. Appraisal theories of emotion: State of the art and future development. _Emotion Review_, 5(2):119-124, 2013.
* Nakagawa et al. (2015) Seishu Nakagawa, Hikaru Takeuchi, Yasuyuki Taki, Rui Nouchi, Atsushi Sekiguchi, Yuka Kotozaki, Carlos Makoto Miyauchi, Kunio Iizuka, Ryoichi Yokoyama, Takamitsu Shinada, et al. Comprehensive neural networks for guilty feelings in young adults. _Neuroimage_, 105:248-256, 2015.
* OpenAI (2022) OpenAI. Introducing chatgpt. _OpenAI Blog Nov 30 2022_, 2022. URL https://openai.com/index/chatgpt/.
* OpenAI (2023) OpenAI. Gpt-4 technical report. _arXiv preprint arXiv:2303.08774_, 2023.
* Park et al. (2023) Joowon Park, Sachin Banker, Tamara Masters, and Grace Yu-Buck. Person vs. purchase comparison: how material and experiential purchases evoke consumption-related envy in others. _Journal of Business Research_, 165:114014, 2023.
* Parrott (2001) W Gerrod Parrott. _Emotions in social psychology: Essential readings_. Psychology Press, 2001.
* Pfeiffer and Wong (1989) Susan M Pfeiffer and Paul TP Wong. Multidimensional jealousy. _Journal of social and personal relationships_, 6(2):181-196, 1989.
* Rao et al. (2023) Haocong Rao, Cyril Leung, and Chunyan Miao. Can chatgpt assess human personalities? a general evaluation framework. In _Findings of the Association for Computational Linguistics: EMNLP 2023_, pp. 1184-1194, 2023.
* Rashkin et al. (2019) Hannah Rashkin, Eric Michael Smith, Margaret Li, and Y-Lan Boureau. Towards empathetic open-domain conversation models: A new benchmark and dataset. In _Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics_, pp. 5370-5381, 2019.
* Romero et al. (2023) Peter Romero, Stephen Fitz, and Teruo Nakatsuma. Do gpt language models suffer from split personality disorder? the advent of substrate-free psychometrics. _Research Square preprint_, 2023. doi: 10.21203/rs.3.rs-2717108/v1.
* Roseman and Smith (2001) Ira J Roseman and Craig A Smith. Appraisal theory. _Appraisal processes in emotion: Theory, methods, research_, pp. 3-19, 2001.
* Rutinowski et al. (2024) Jerome Rutinowski, Sven Franke, Jan Endendyk, Ina Dormuth, Moritz Roidl, and Markus Pauly. The self-perception and political biases of chatgpt. _Human Behavior and Emerging Technologies_, 2024(1):7115633, 2024.
* Sabini et al. (2000) John Sabini, Michael Siepmann, Julia Stein, and Marcia Meyerowitz. Who is embarrassed by what? _Cognition & Emotion_, 14(2):213-240, 2000.
* Sabini et al. (2001) John Sabini, Brian Garvey, and Amanda L Hall. Shame and embarrassment revisited. _Personality and Social Psychology Bulletin_, 27(1):104-117, 2001.
* Sohn et al. (2002)Klaus R Scherer. Appraisal theory. _Handbook of cognition and emotion_, pp. 637-663, 1999.
* Serapio-Garcia et al. [2023] Greg Serapio-Garcia, Mustafa Safdari, Clement Crepy, Luning Sun, Stephen Fitz, Peter Romero, Marwa Abdulhai, Aleksandra Faust, and Maja Mataric. Personality traits in large language models. _arXiv preprint arXiv:2307.00184_, 2023.
* Shaver et al. [1987] Phillip Shaver, Judith Schwartz, Donald Kirson, and Cary O'connor. Emotion knowledge: further exploration of a prototype approach. _Journal of personality and social psychology_, 52(6):1061, 1987.
* Shoji et al. [2010] Kotaro Shoji, Jinni A Harrigan, Stanley B Woll, and Steven A Miller. Interactions among situations, neuroticism, and appraisals in coping strategy choice. _Personality and Individual Differences_, 48(3):270-276, 2010.
* Simpson et al. [2021] Kate Simpson, Dawn Adams, Kathryn Ambrose, and Deb Keen. "my cheeks get red and my brain gets scared": A computer assisted interview to explore experiences of anxiety in young children on the autism spectrum. _Research in Developmental Disabilities_, 113:103940, 2021.
* Sullman [2006] Mark JM Sullman. Anger amongst new zealand drivers. _Transportation Research Part F: Traffic Psychology and Behaviour_, 9(3):173-184, 2006.
* Tak and Gratch [2023] Ala N. Tak and Jonathan Gratch. Is gpt a computational model of emotion? detailed analysis. _arXiv preprint arXiv:2307.13779_, 2023.
* Torestad [1990] Bertil Torestad. What is anger provoking? a psychophysical study of perceived causes of anger. _Aggressive Behavior_, 16(1):9-26, 1990.
* Touvron et al. [2023] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajiwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. _arXiv preprint arXiv:2307.09288_, 2023.
* Wang et al. [2024] Xintao Wang, Yunze Xiao, Jen-tse Huang, Siyu Yuan, Rui Xu, Haoran Guo, Quan Tu, Yaying Fei, Ziang Leng, Wei Wang, et al. Incharacter: Evaluating personality fidelity in role-playing agents through psychological interviews. In _Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pp. 1840-1873, 2024.
* Watson et al. [1988] David Watson, Lee Anna Clark, and Auke Tellegen. Development and validation of brief measures of positive and negative affect: the panas scales. _Journal of personality and social psychology_, 54(6):1063, 1988.
* Wu et al. [2023] Haoran Wu, Wenxuan Wang, Yuxuan Wan, Wenxiang Jiao, and Michael Lyu. Chatgpt or grammarly? evaluating chatgpt on grammatical error correction benchmark. _arXiv preprint arXiv:2303.13648_, 2023.
* Yongsatianchot et al. [2023] Nutchanon Yongsatianchot, Parisa Ghanad Torshizi, and Stacy Marsella. Investigating large language models' perception of emotion using appraisal theory. In _2023 11th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)_, pp. 1-8. IEEE, 2023.
* Zhan et al. [2023] Hongli Zhan, Desmond Ong, and Junyi Jessy Li. Evaluating subjective cognitive appraisals of emotions from large language models. In _Findings of the Association for Computational Linguistics: EMNLP 2023_, pp. 14418-14446, 2023.
* Zhao et al. [2021] Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use: Improving few-shot performance of language models. In _International Conference on Machine Learning_, pp. 12697-12706. PMLR, 2021.

###### Contents

* A More Background from Psychology
* A.1 Emotion Appraisal Theory
* A.2 Challenging Self-Report Measures
* B Details on Emotions and Factors
* B.1 Description of Each Factor
* B.2 Example Situation of Each Factor
* C Detailed Experimental Results
* C.1 Human Results
* C.2 OpenAI Model Family
* C.3 LLaMA Model Family
* C.4 Mixtral-8x22b-Instruct
* C.5 GPT-3.5-Turbo Results on Positive/Neutral Situations
* C.6 GPT-3.5-Turbo Results on the Challenging Benchmark
* D Statistics of Human Subjects
* E Prompting LLMs To Be Emotionally Stable
* F Tuning LLMs To Align with Humans
* G Ethics Statement and Broader Impacts
* G.1 Safeguards on Human Subjects
* G.2 Impacts on LLM Developers and Users
* G.3 Copyright Issues

More Background from Psychology

### Emotion Appraisal Theory

Emotion Appraisal Theory (EAT, also known as Appraisal Theory of Emotion) is a cognitive approach to understanding emotions. EAT asserts that our appraisals of stimuli determine our emotions, _i.e._, how we interpret or evaluate events, situations, or experiences will directly influence how we emotionally respond to them (Roseman & Smith, 2001). EAT was notably developed and supported since the 1960s. Arnold (1960) proposed one of the earliest forms of appraisal theories in the 1960s, while Lazarus (1991) and Scherer (1999) further expanded and refined the concept in subsequent decades.

The primary goal of EAT is to explain the variety and complexity of emotional responses to a wide range of situations. It strives to demonstrate that it is not merely the event or situation that elicits an emotional response but individual interpretations and evaluations of the event. According to this theory, the same event can elicit different emotional responses in different individuals depending on how each person interprets or "appraises" the event (Moors et al., 2013). For instance, consider a situation where you are about to give a public speech. You might feel anxious if you appraise this event as threatening or fear-inducing, perhaps due to a fear of public speaking or concerns about potential negative evaluation. Conversely, you might feel eager or motivated if you appraise it as an exciting opportunity to share your ideas.

### Challenging Self-Report Measures

* AGQ for Anger (Buss & Perry, 1992): The Aggression Questionnaire is designed to measure four major components of aggression: physical aggression, verbal aggression, anger and hostility. The AGQ consists of 29 items which are rated on a seven-point Likert scale from 1 (extremely uncharacteristic of me) to 7 (extremely characteristic of me). Respondents evaluate hypothetical actions they might undertake in various circumstances.
* DASS-21 for Anxiety (Henry & Crawford, 2005): The short-form version of the Depression Anxiety Stress Scales is designed to measure the negative emotional states of depression, anxiety, and stress. Comprising 21 items, the DASS-21 employs a four-point Likert scale ranging from 0 (never) to 3 (almost always). Respondents rate the extent to which these statements apply to them over the past week.
* BDI-II for Depression (Beck et al., 1996): The Beck Depression Inventory evaluates key symptoms of depression. The BDI-II version comprises 21 items, each of which is assessed using a five-point Likert scale ranging from 0 to 3. Respondents select the score that best corresponds to their present experience of depressive symptoms.
* FDS for Frustration (Harrington, 2005): The Frustration Discomfort Scale is designed to measure four major components: discomfort intolerance, entitlement, emotional intolerance, and achievement frustration. Comprising 28 items, the scale utilizes a four-point Likert scale, ranging from 1 (absent) to 5 (very strong), to measure respondents' perceptions of the degree of applicability of each statement to their own experiences.
* MJS for Jealousy (Pfeiffer & Wong, 1989): The Multidimensional Jealousy Scale comprises 24 items, rating on a seven-point Likert scale ranging from 1 (never) to 7 (all the time) for the cognitive and behavioral subscales, and from 1 (very pleased) to 7 (very upset) for the emotional subscale. Respondents express the frequency with which the provided statements apply to their experiences in the cognitive and behavioral subscales, as well as their moods to potential jealousy-inducing situations in the emotional subscale.
* GASP for Guitt (Cohen et al., 2011): The Guit And Shame Proneness is designed to assess an individual's inclination towards experiencing gait and shame, comprising 16 items rated on a seven-point Likert scale, ranging from 1 (very unlikely) to 7 (very likely). Respondents rate their likelihood of feeling guilty in various situations.
* FSS-III for Fear (Arindell et al., 1984): The Fear Survey Schedule assess subjects' discomfort and experienced anxiety towards each of the listed stimuli, measure five major components of fear: social fears, agoraphobia fears, injury fears, sex aggression fears, and fear of harmless animal. The FSS-III comprises 52 items, each rated on a five-point Likert scale ranging from 1 (extremely uncharacteristic of me) to 5 (extremely characteristic of me).
* BFNE for Embarrassment (Leary, 1983): The Brief Fear of Negative Evaluation scale is an abbreviated version of the original 30-item scale. Consisting of 12 items, it assesses individuals' levels of anxiety pertaining to others' humiliation, critical or hostile judgment, and disagree on a five-point Likert scale, spanning from 1 (not at all characteristic of me) to 5 (extremely characteristic of me).

Details on Emotions and Factors

### Description of Each Factor

\begin{table}
\begin{tabular}{l l l l} \hline \hline
**Emotions** & **Factors** & **Numbers** & **Descriptions** \\ \hline  & Self-Oquinioned Individuals & 13 & Anger from interactions or communication with individuals who firmly and unwersingly hold new opinions. \\
**Anger** & Blanning, Slandering, and Tatting & 11 & Anger triggered by being subjected to blame, slander, and tatting. \\ (Torreald, 1990) & Bulbing, Teasing, Insulting, and Disparaging & 15 & Experience or witnessing anger door to bullying, reasoning, insulting, and disparaging behaviors directed on street or others. \\ (Martin & Dahlen, 2007) & 
\begin{tabular}{l} Anger then functioning otherwise otherwise thoughtless behaviors and \\ impossible attitudes or experiencing misreducible consequences \\ resulting from one’s actions. \\ \end{tabular} \\
**Diffusion** & Thoughless Behaviors and Irresponsible Attitudes & 14 & Anger arising from experiencing or witnessing disrepeceful drivers \\  & Deriving Situations & 35 & The behaviors and encountering unexpected driving conditions. \\ \hline  & External Factors & 11 & Anxiety arising from factors beyond an individual’s control or influence. \\ (Shoui et al., 2016) & Self-Imposed Pressure & 16 & Anxiety stemming from self-imposed expectations or pressure. \\ (Guinard et al., 2019) & Personal Growth and Relationships & 9 & Anxiety on personal growth, relationships, and interpersonal dynamics. \\ (Simpson et al., 2021) & Uncertainty and Unknowns & 9 & Anxiety triggered by unknown outcomes, unpredictable situations, uncertainty in the future, or disproves to care routines. \\ \hline  & Failure of Important Goals & 5 & Depression due to failure in achieving goals in the past or potential future. \\  & Death of Lowed Ores & 5 & Depression connected to the loss of a family member or close \\
**Depression** & Rontantile Loss & 5 & Depression linked to the termination of a romantic relationship, breakup, or unrequested love. \\ (Keller \& Neuse, 2005) & Chronic Stress & 5 & Depression associated with an inability to cope with multiple advertisers or amacy short current or future challenges. \\  & Social Isolation & 5 & Depression correlated with a lack of sufficient social support, feelings of not belonging, or experiencing homeless. \\  & Winter & 5 & Depression attributed to seasonal affective disorder, a low mood that occurs during winter months. \\ \hline  & Disapointments and Letdowns & 6 & Frustration due to unmet expectations or hopes, leading to feel-rings of disappointment or binge at down. \\  & Unforeseen Obstacles and Accidents & 9 & Frustration involving unexpected events or circumstances creating obstacles or accidents, disrupting one’s plans or activities. \\
**Fustration** & 
\begin{tabular}{l} Unforeseen arising from interfering convey or interpretation \\ of information, resulting in confusion, disagreements, or unintended consequences due to a lack of clear communication or understanding between individuals. \\ \end{tabular} \\
**Bema et al.** (2011) & Miscommunications and Misunderstanding & 5 & Presurating some from affecting compliance or interpretation of information, resulting in confusion, disagreements, or unintended consequences due to a lack of clear communication or understanding between individuals. \\  & Rejection and Interpersonal Issues & 5 & Personal economic matters related to personal relationships and social interactions. \\ \hline  & \begin{tabular}{l} Rejectors and Recipients \\ \end{tabular} & 11 & \begin{tabular}{l} Jeaky pertaining to one’s partner’s actions or behaviors within a romantic relationship, participation without interacting with individual of the opposite gender. It involves feelings of discomfort or insecurity. \\ \end{tabular} \\ \hline  & \begin{tabular}{l} Rejectors \\ (Kipler et al., 2022) \\ (Lee et al., 2022) \\ (Park et al., 2023) \\ \end{tabular} & Rontantile (Same Gender) & 11 & 
\begin{tabular}{l} Same situations as Jeelonomy-1 but focusing specifically on interaction with individuals of the same gender. \\ \end{tabular} \\
**Jedousy** & Rontantile (Same Gender) & 11 & \begin{tabular}{l} Isolany centered around possessiveness or material goods, stemming from a sense of unfairness or every when someone discovers that another person acquired the same item or experience at a significantly lower price. \\ \end{tabular} \\ (Keppler et al., 2022) & Material Possession & 2 & \begin{tabular}{l} Isolany arising from feelings of any regarding the experiences or activities other have had. It is driven by missing out or not receiving similar benefits. \\ \end{tabular} \\ \hline  & \begin{tabular}{l} Retrayal and Deception \\ Relationship and Interpersonal \\ (Nakagawa et al., 2015) \\ \end{tabular} & 
\begin{tabular}{l} Civil arising from dishness or disloyal actions towards others. \\ \end{tabular} \\
**Gault** & \begin{tabular}{l} Rejectors and Recipients \\ \end{tabular} & 26 & Gulf pertaining to interaction between individuals and how their behavior affects their relationships. \\ (Jack \& Luck \& Slackowski, 2022) & Broken Promises and Responsbilities & 32 & Guil related to the failure to fulfill commitments, duties, or obligations. \\  & \begin{tabular}{l} Personal and Moral \\ \end{tabular} & 31 & \begin{tabular}{l} Still involving personal- choices, decisions, and ethical considerations. \\ \end{tabular} \\ \hline  & Social Fears & 16 & 
\begin{tabular}{l} Fear of being watched by others and being the center of attention within a group. \\ \end{tabular} \\
**Fear** & Agraprabobia Fears & 9 & Fear arising from feeling trapped and unable to seek help in certain situations. \\
**Cuthbert et al.** (2003) & Injury Fears & 11 & Fear of witnessing wounds, blood or experiencing personal injury. \\ (Arindell et al., 1984) & Dangerous Environments & 17 & Fear related to potential threats, harm, and inferencing experiences. \\ (Blanchard et al., 2001) & Harmless Animals & 6 & Fear towards animals perceived as crerecy or disguise, such as worms, bats, animals, or rules, despite their harmless nature. \\ \hline  & \begin{tabular}{l} Intimate \\ \end{tabular} & 13 & 
\begin{tabular}{l} Embarrassement school when witnesses or engaging in awkward behaviors of close acquaintances. \\ \end{tabular} \\
**Embarrassement** & Stranger & 13 & 
\begin{tabular}{l} Embarrassement around when witnesses or engaging in awkward behaviors of unfamiliar individuals. \\ \end{tabular} \\
**Schini et al.** (2000) & Sticky Scenarios & 10 & 
\begin{tabular}{l} Embarrassement occurring when individuals feel uncomfortable or awkward about directly asking others something. \\ \end{tabular} \\
**Schini et al.** (2001) & Centre of Attention & 16 & 
\begin{tabular}{l} Embarrassement triggered when individuals engage in awkward behaviors and find themselves under observation as the center of attention. \\ \end{tabular} \\ \hline \hline \end{tabular}
\end{table}
Table 6: Introduction to all 36 factors of the 8 emotions.

### Example Situation of Each Factor

\begin{table}
\begin{tabular}{p{56.9pt} p{113.8pt} p{113.8pt}} \hline \hline
**Emotions** & **Factors** & **Example Testing Situations** \\ \hline \multirow{6}{*}{**Anger**} & Facing Self-Opinioned People & If somebody talks back when there’s no reason. That there is no real reason to oppose. \\  & Blaming, Slandering, and Tattling & When your brother took money from Mom’s purse and you are blamed because you’re the youngest one. \\  & Bullying, Teasing, Insulting, and Disparaging & If a boy sticks a ball at you own oppose and everybody laughs. You are at a store waiting to be helped, but the clerks are talking to each other and ignoring you. \\  & Driving Situations & Someone makes an obscure gesture towards you about your driving. \\ \hline \multirow{6}{*}{**Anxiety**} & External Factors & You do not know what to do when facing a difficult financial situation. You must succeed in completing your project on time. \\  & Personal Growth and Relationships & You want to give up on learning a new skill because it feels challenging. \\  & Uncertainty and Unknowns & You hope time passes by faster during a tedious task. \\ \hline \multirow{6}{*}{**Depression**} & Failure of Important Goal & Countless hours of preparation, heart, and soul poured into pursuing your dream. The moment of truth arrives, and the news hits like a tidal wave—expectations shattered, vision crumbling. \\  & Death of Loved Ones & In the dimly lit from, a heavy silence settles. Memories of joy and a photograph of your bored grandmother remind you of her absence, creating a void in your life. \\  & Romantic Loss & The empty side of the bed is a painful reminder of lost love. The world’s colors have dulled, mirroring the void in your heart. Longing weighs heavily on your every step. \\  & & Days blend into a monotonous routine, juggling endless responsibilities and mounting pressure. Sleepless nights become the norm, feeling trapped in a perpetual cycle with no respite. \\  & & Sitting alone in a dimly lit from, your phone remains silent without any notifications. Laughter and chatter of friends echo from distant places, a curl reminder of the void surrounding you. \\  & & Gazing out the frost-covered undwaponne, the world appears monochromatic and still. The thing cold isolates you from the ubunt life outside. \\  & Winter & You miss a popular party because you fall sleep at home. \\ \hline \multirow{6}{*}{**Frustration**} & Disapointments and Ledtowns & You miss a popular party because you fall sleep at home. \\  & Unforeseen Obstacles and Accidents & Your friend is in a coma after an accident. \\  & Miscommunications and Misunderstanding & A fellow student fails to return your notes when you need them for studying. \\  & Rejection and Interpersonal Issues & You are in love with someone who is interested in someone else. \\ \hline \multirow{6}{*}{**Jealousy**} & Romantic (Opposite Gender) & Your spouse/partner shared a kiss on the lips with his/her an opposite sex. \\  & Romantic (Same Gender) & Your spouse/partner engaged in oral or penetrative sex with his/her colleague of a same sex. \\  & & You paid 51150 for a new laptop and shared about it on social media. \\  & Material Possession & You now an acquaintance approaches you and says, ”Nele laptop! just got the same one. I got a nice deal and got 5650 for mine.” \\  & Experiential & An acquaintance approaches you and says, ”I just went on a vacation to Pateqrain in South America. I got a nice deal and paid 5650 tor it.” \\ \hline \multirow{6}{*}{**Guilt**} & Betrayal and Deception & You kissed a woman other than your partner. \\  & Relationship and Interpersonal & You didn’t support friends enough. \\  & Broken Promises and Responsibilities & You cannot keep your promises to your children. \\  & Personal and Moral & You crossed the road when the traffic signal was red. \\ \hline \multirow{6}{*}{**Fear**} & Social Fears & Your paling grow columns may sowa approach the podium, with all eyes fixed upon you, ready to speak in public. \\  & Agoraphobia Fears & After jumping out of the car, you start to have a severe panic attack, you become clammy, you are in a short, and you feel less all over. \\  & Injury Fears & You glance down and notice even wounds on your hands, ocoring blood and causing a sharp, stinging pain. \\  & Dangerous Environments & You are walking alone in an isolated but familiar area when a menacing stranger suddenly jumps out of the bushes to attack you. \\  & Harmless Animals & You see a swarm of bats sweeping through the night sky, flapping omniously and casting entire shadows. \\ \hline \multirow{6}{*}{**Embarrassment**} & Intimate & You arrive home earlier than expected from your date. You’re taken abac to see your roommate and her boyfriend hastly clutching their clothes and scrambling into her bedroom. \\  & Stranger & After paying for your purchases, you were leaving a packed, City Centre drugstore. You walked through the scanner at the door, and the alarm went off as if you were a shopififier. \\  & Sticky situations & You had left your friend a large sum of money that he had not repaid. \\  & & Suddenly, you needed the money back in order to pay your rent. You knew you were going to have to ask your friend to repay the loan. \\  & & You were attending a cocktail party where you didn’t know many people. Just as you started to enter, you heard an announcement that the guest of honor was arriving. However, the spotlight followed your entrance instead of the real guest of honor who was just behind you. \\ \hline \hline \end{tabular}
\end{table}
Table 7: Example situations of all factors (some are truncated due to page limit).

[MISSING_PAGE_EMPTY:20]

[MISSING_PAGE_EMPTY:21]

[MISSING_PAGE_EMPTY:22]

[MISSING_PAGE_EMPTY:23]

[MISSING_PAGE_EMPTY:24]

### GPT-3.5-Turbo Results on the Challenging Benchmark

\begin{table}
\begin{tabular}{l l l} \hline \hline
**Emotions** & **Factors** & **Overall** \\ \hline  & Facing Self-Opinioned People & \(-(+4.1)\) \\

[MISSING_PAGE_EMPTY:26]

Figure 5: Region distribution of the human subjects.

Figure 6: Education level distribution of the human subjects.

Figure 7: Employment status distribution of the human subjects.

Prompting LLMs To Be Emotionally Stable

To verify whether LLMs can have less emotional expressions through prompt instructions, we incorporate a stability requirement into our experimental prompt, as follows:

We evaluate GPT-3.5-Turbo with this prompt and compare the results to using the default prompt on "Anger" situations. Results listed in Table 14 indicate that the emotional stability prompt does not significantly affect the model's emotional responses, having negligible impact on the model's emotional dynamics.

## Appendix F Tuning LLMs To Align with Humans

We conduct an experiment using the GPT-3.5-Turbo model and the LLaMA-3.1-8B model. Our EmotionBench (1,266 human responses) is split into 866 samples for fine-tuning and 400 for testing. The following hyperparameters are used: n_epochs\(=3\), batch_size\(=1\), and learning_rate_multiplier\(=2\) for GPT-3.5-Turbo, and learning_rate\(=5\times 10^{-5}\), per_device_train_batch_size\(=2\), and num_train_epochs\(=3\) for LLaMA-3.1-8B. For LLaMA-3.1, we apply the Low-Rank Adaptation (LoRA) (Hu et al., 2022) technique. Table 15 compares the performance of the vanilla and fine-tuned models against human baseline, specifically in terms of negative affect scores from the test set.

The results show that fine-tuned models align more closely with human emotional responses in both default and emotion-evoked states. Notably, fine-tuning the models using our dataset significantly improved emotional alignment, particularly for the LLaMA-3.1 model, which reduced its negative affect score from \(33.0\) to \(10.3\) in the default state. Our fine-tuned LLaMA-3.1 is available at https://huggingface.co/CUHK-ARISE/LLaMA-3.1-8B-EmotionBench. These findings demonstrate the effectiveness of EmotionBench in enhancing models' emotional alignment with human norms.

\begin{table}
\begin{tabular}{l c c c c c} \hline \hline
**Models** & **Human** & **GPT-3.5 (V)** & **GPT-3.5 (FT)** & **LLaMA-3.1-8B (V)** & **LLaMA-3.1-8B (FT)** \\ \hline
**Default (N)** & \(14.2_{\pm 6.4}\) & \(25.9_{\pm 0.3}\) & \(10.6_{\pm 0.5}\) & \(33.0_{\pm 4.5}\) & \(10.3_{\pm 1.1}\) \\
**Evoked (N)** & \(25.9_{\pm 9.7}\) & \(24.8_{\pm 8.5}\) & \(25.2_{\pm 9.6}\) & \(36.5_{\pm 7.7}\) & \(15.0_{\pm 6.4}\) \\ \hline \hline \end{tabular}
\end{table}
Table 15: Performance comparison of vanilla (marked as **V**) and fine-tuned (marked as **FT**) GPT-3.5 and LLaMA-3.1 models on negative affect scores.

\begin{table}
\begin{tabular}{l|c c c c c} \hline \hline
**Positive** & **Anger-1** & **Anger-2** & **Anger-3** & **Anger-4** & **Anger-5** & **Overall** \\ \hline w/ Stability & \(-15.2\) & \(-17.1\) & \(-13.9\) & \(-19.2\) & \(-17.9\) & \(-16.7\) \\ w/o Stability & \(-11.1\) & \(-15.2\) & \(-15.7\) & \(-19.0\) & \(-15.0\) & \(-15.2\) \\ \hline
**Negative** & **Anger-1** & **Anger-2** & **Anger-3** & **Anger-4** & **Anger-5** & **Overall** \\ w/ Stability & \(-2.4\) & \(-4.0\) & \(-0.6\) & \(-6.5\) & \(-4.5\) & \(-3.6\) \\ w/o Stability & \(-3.9\) & \(-2.1\) & \(+4.4\) & \(-4.7\) & \(-6.0\) & \(-2.5\) \\ \hline \hline \end{tabular}
\end{table}
Table 14: Results of GPT-3.5-Turbo on “Anger” situations, with or without the emotional stability requirement in the prompt input.

Ethics Statement and Broader Impacts

### Safeguards on Human Subjects

This study involves a survey requiring human subjects to imagine being in situations that could elicit negative emotions such as anger, anxiety, and fear. This process introduces a few ethical concerns. First, this process could hurt the mental health of human subjects. To alleviate the possibility, we take the following actions: (1) We require subjects to be free of any ongoing mental illness. (2) We inform subjects about the nature of the survey in advance, including the potential risks of emotional distress. (3) We allow all subjects to quit at any time. (4) We provide mental support and let subjects report any illness after the survey. Fortunately, no subjects reported such kind of mental illness. Another concern is related to the privacy issue during the collection of data. Our questionnaire is entirely anonymous to safeguard subjects' privacy and confidentiality. The Survey and Behavioural Research Ethics (SBRE) Committee from the Chinese University of Hong Kong has granted approval for this study, titled "Exploring Human Emotional Responses to Diverse Situations," with the reference number of SBRE-23-0696.

### Impacts on LLM Developers and Users

We would like to emphasize that the primary objective of this paper is to facilitate the scientific inquiry into understanding LLMs from a psychological standpoint. Users must exercise caution and recognize that the performance on this benchmark does not imply any applicability or certificate of automated counseling or companionship use cases.

### Copyright Issues

The PANAS and eight other scales are freely accessible online. These scales can be used in research without requiring special permission. For our released data, we distribute human responses under the GNU General Public License v3.0, which permits research use and restricts commercial applications.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The bullet items in the end of the introduction have experimental supports. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Please see SS5.2. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. 3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [NA]Justification: TThe paper does not include theoretical resultanalysis. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: Please refer to the README.md in the supplementary materials. We provide the source codes and the raw data. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: Please refer to the supplementary materials. The data and code will be made openly accessible upon publication. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Please see SS4.1. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: All the results include the STD. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors).

* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: Please see SS4.1. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We have carefully read the NeurIPS Code of Ethics and verify that our paper aligns with the requirements. We also include a section (SSG) in the appendix to discuss these issues. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: Please see SSG. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: We do not release pretrained language models, image generators, or scraped datasets. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: Please see SSG. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: Please refer to the supplementary materials which include a GNU General Public License v3.0 license. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [Yes] Justification: Please see SSG. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [Yes] Justification: We gained the approval. However, due to anonymity, we do not include the information in our paper which will reveal our affiliation. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.