# Neural Model Checking

Mirco Giacobbe

University of Birmingham, UK

&Daniel Kroening

Amazon Web Services, USA

&Abhinandan Pal

University of Birmingham, UK

&Michael Tautschnig

Amazon Web Services, USA and

Queen Mary University of London, UK

The authors are listed alphabetically.

###### Abstract

We introduce a machine learning approach to model checking temporal logic, with application to formal hardware verification. Model checking answers the question of whether every execution of a given system satisfies a desired temporal logic specification. Unlike testing, model checking provides formal guarantees. Its application is expected standard in silicon design and the EDA industry has invested decades into the development of performant symbolic model checking algorithms. Our new approach combines machine learning and symbolic reasoning by using neural networks as formal proof certificates for linear temporal logic. We train our neural certificates from randomly generated executions of the system and we then symbolically check their validity using satisfiability solving which, upon the affirmative answer, establishes that the system provably satisfies the specification. We leverage the expressive power of neural networks to represent proof certificates as well as the fact that checking a certificate is much simpler than finding one. As a result, our machine learning procedure for model checking is entirely unsupervised, formally sound, and practically effective. We experimentally demonstrate that our method outperforms the state-of-the-art academic and commercial model checkers on a set of standard hardware designs written in SystemVerilog.

## 1 Introduction

Electronic design is complex and prone to error. Hardware bugs are permanent after production and as such can irremediably affect the correctness of software--which runs on hardware--and can compromise the safety of cyber-physical systems--which embed hardware. Correctness assurance is core to the engineering of digital circuitry, with the median FPGA and IC/ASIC projects spending respectively \(40\,\mathrm{\char 37}\) and \(60\,\mathrm{\char 37}\) of time in verification [48]. Verification approaches based on directed or constrained random testing are easy to set up but are inherently non-exhaustive [89, 91]. Testing cannot show the absence of bugs which, for systems the safety of which is critical, can have serious consequences; notably, over \(40\,\mathrm{\char 37}\) of hardware development projects must satisfy at least one functional safety standard [48]. In contrast to testing, _model checking_ a design against a formal specification of correctness answers the question of whether the design satisfies the specification with mathematical certainty, for every possible execution of the system [9, 13, 35].

The EDA industry has heavily invested in software tools for symbolic model checking. Early symbolic model checking algorithms utilise fixed-point computations with binary decision diagrams (BDDs) [7], where each node specifies the Boolean assignment for a circuit's flip-flop or input bit [26, 45]. BDDs struggle to scale when applied to complex arithmetic data paths, prompting a shift towards iterative approximation of fixed points using propositional satisfiability (SAT) solving [16, 17, 33], whichis now the state-of-the-art technique. Both BDD and SAT-based model checking, despite extensive research, remain computationally demanding; even small circuit modules can require days to verify or may not complete at all. Consequently, verification engineers often limit state space exploration to a bounded time horizon through bounded model checking, sacrificing global correctness over the unbounded time domain.

We present a machine learning approach to hardware model checking that leverages neural networks to represent proof certificates for the compliance of a given hardware design with a given linear temporal logic (LTL) specification [82]. Our approach avoids fixed-point algorithms entirely, capitalises on the efficient word-level reasoning of satisfiability solvers, and delivers a formal guarantee over an unbounded time horizon. Given a hardware design and an LTL specification \(\Phi\), we train a word-level neural certificate for the compliance of the design with the specification from test executions, which we then check using a satisfiability solver. We leverage the observation that checking a proof certificate is much simpler than solving the model checking problem directly, and that neural networks are an effective representation of proof certificates for the correctness of systems [28, 50]. We ultimately obtain a machine learning procedure for hardware model checking that is entirely unsupervised, formally sound and, as our experiments show, very effective in practice.

Our learn-and-check procedure begins by generating a synthetic dataset through random executions of the system alongside a Buchi automaton that identifies counterexamples to \(\Phi\). We then train a _neural ranking function_ designed to strictly decrease whenever the automaton encounters an accepting state and remain stable on non-accepting states. After training, we formally check that the ranking function generalises to all possible executions. We frame the check as a cost-effective one-step bounded model checking problem involving the system, the automaton, and the quantised neural ranking function, which we delegate to a satisfiability solver. As the ranking function cannot decrease indefinitely, this confirms that the automaton cannot accept any system execution, effectively proving that such executions are impossible. Hence, if the solver concludes that no counterexample exists, it demonstrates that no execution satisfies \(\neg\Phi\), thereby affirming that the system satisfies \(\Phi\)[37, 95].

We have built a prototype that integrates PyTorch, the bounded model checker EBMC, the LTL-to-automata translator Spot, the SystemVerilog simulator Verilator, and the satisfiability solver Bitwuzla [44, 76, 80, 88]. We have assessed the effectiveness of our method across 194 standard hardware model checking problems written in SystemVerilog and compared our results with the state-of-the-art academic hardware model checkers ABC and nuXmv [24, 27], and two commercial counterparts. For any given time budget of less than 5 hours, our method completes on average \(60\,\%\) more tasks than ABC, \(34\,\%\) more tasks than nuXmv, and \(11\,\%\) more tasks than the leading commercial model checker. Our method is faster than the academic tools on \(67\,\%\) of the tasks, 10X faster on \(34\,\%\), and 100X faster on \(4\,\%\); when considering the leading commercial tool, our method is faster on \(75\,\%\), 10X faster on \(29\,\%\), and 100X faster on \(2\,\%\) of them. Overall, with a straightforward implementation, our method outperforms mature academic and commercial model checkers.

Our contribution is threefold. We present for the first time a hardware model checking approach based on neural certificates. We extend neural ranking functions, previously introduced for the termination analysis of software, to LTL model checking and the verification of reactive systems. We have built a prototype and experimentally demonstrated that our approach compares favourably with the leading academic and commercial hardware model checkers. Our technology delivers formal guarantees of correctness and positively contributes to the safety assurance of systems.

## 2 Automata-theoretic Linear Temporal Logic Model Checking

An LTL model checking problem consists of a model \(\mathcal{M}\) that describes a system design and an LTL formula \(\Phi\) that describes the desired temporal behaviour of the system [52, 82]. The problem is to decide whether all traces of \(\mathcal{M}\) satisfy \(\Phi\).

Our formal model \(\mathcal{M}\) of a hardware design consists of a finite set of bit-vector-typed variables \(X_{\mathcal{M}}\) with fixed bit-width and domain of assignments \(S\), partitioned into input variables \(\operatorname{inp}X_{\mathcal{M}}\subseteq X_{\mathcal{M}}\) and state-holding register variables \(\operatorname{reg}X_{\mathcal{M}}\subseteq X_{\mathcal{M}}\); we interpret primed variables \(X^{\prime}_{\mathcal{M}}\) as the value of \(X_{\mathcal{M}}\) after one clock cycle. Then, a sequential update relation \(\operatorname{Update}_{\mathcal{M}}\) relates \(X_{\mathcal{M}}\) and \(\operatorname{reg}X^{\prime}_{\mathcal{M}}\) and computes the next-state valuation of the registers from the current-state valuation of all variables; we interpret \(\operatorname{Update}_{\mathcal{M}}\) as a first-order logic formula encoding this relation. A state \(\boldsymbol{s}\in S\) is a valuation for the variables \(X_{\mathcal{M}}\). We denote as \(\operatorname{reg}\boldsymbol{s},\operatorname{inp}\boldsymbol{s},\dots\) the restriction of \(\boldsymbol{s}\) to the respective class of variables. For two states \(\bm{s}\) and \(\bm{s^{\prime}}\), the state \(\bm{s^{\prime}}\) is a successor of \(\bm{s}\), which we write as \(\bm{s}\to_{\mathcal{M}}\bm{s^{\prime}}\), if \(\mathrm{Update}_{\mathcal{M}}(\bm{s},\mathrm{reg}\,\bm{s^{\prime}})\) evaluates to true. We call \(\to_{\mathcal{M}}\) the transition relation of \(\mathcal{M}\) and say that an infinite sequence of states \(\bar{\bm{s}}_{0},\bar{\bm{s}}_{1},\bar{\bm{s}}_{2},\dots\) is an execution of \(\mathcal{M}\) if \(\bar{\bm{s}}_{i}\to_{\mathcal{M}}\bar{\bm{s}}_{i+1}\) for all \(i\geq 0\); we say that an execution is initialised in \(s_{0}\in S\) when \(\bar{\bm{s}}_{0}=s_{0}\).

We specify the intended behaviour of systems in LTL, which is the foundation of SystemVerilog Assertions. LTL extends propositional logic with temporal modalities \(\mathsf{X}\), \(\mathsf{G}\), \(\mathsf{F}\), and \(\mathsf{U}\). The modality \(\mathsf{X}\)\(\Phi_{1}\) indicates that \(\Phi_{1}\) holds immediately after one step in the future, \(\mathsf{G}\)\(\Phi_{1}\) indicates that \(\Phi_{1}\) holds at all times in the future, \(\mathsf{F}\)\(\Phi_{1}\) indicates that \(\Phi_{1}\) holds at some time in the future, and \(\Phi_{1}\)\(\Phi_{2}\) indicates that \(\Phi_{1}\) holds at all times until \(\Phi_{2}\) holds at some time in the future. We refer the reader to the literature for the formal syntax and semantics of LTL [82]. The atomic propositions of the LTL formulae we consider are Boolean variables of \(\mathcal{M}\), which we call the observables \(\mathrm{obs}\,X_{\mathcal{M}}\subseteq X_{\mathcal{M}}\) of \(\mathcal{M}\). We note that any first-order predicate over \(X_{\mathcal{M}}\) can be bound to a Boolean observable using combinational logic (cf. Figure 4, where observable \(\mathtt{ful}\) corresponds to predicate \(\mathtt{cnt}\) == \(\mathcal{T}\)).

We call a trace of \(\mathcal{M}\) a sequence \(\mathrm{obs}\,\bar{\bm{s}}_{0},\mathrm{obs}\,\bar{\bm{s}}_{1},\mathrm{obs}\, \bar{\bm{s}}_{2},\dots\) where \(\bar{\bm{s}}_{0},\bar{\bm{s}}_{1},\bar{\bm{s}}_{2},\dots\) is an execution of \(\mathcal{M}\). We define the language \(L_{\mathcal{M}}\) of \(\mathcal{M}\) as the maximal set of traces of \(\mathcal{M}\). Every LTL formula \(\Phi\) is interpreted over traces and as such defines the language \(L_{\Phi}\) of traces that satisfy \(\Phi\). The model checking problem corresponds to deciding the language inclusion question \(L_{\mathcal{M}}\subseteq L_{\Phi}\).

As is standard in automata-theoretic model checking, we rely on the result that every LTL formula admits a non-deterministic Buchi automaton that recognises the same language [95, 96]. A non-deterministic Buchi automaton \(\mathcal{A}\) consists of a finite set of states \(Q\), an initial start state \(q_{0}\in Q\), an input domain \(\Sigma\) (also called alphabet), a transition relation \(\delta\subseteq Q\times\Sigma\times Q\), and a set of fair states \(F\subseteq Q\). One can interpret an automaton \(\mathcal{A}\) as a hardware design with one register variable \(\mathrm{reg}\,X_{\mathcal{A}}=\{\mathsf{q}\}\) having domain \(Q\), input and observable variables \(\mathrm{inp}\,X_{\mathcal{A}}=\mathrm{obs}\,X_{\mathcal{A}}\) having domain \(\Sigma\), and sequential update relation \(\mathrm{Update}_{\mathcal{A}}(\bm{\sigma},\bm{q},\bm{q}^{\prime})\equiv(\bm{q},\bm{\sigma},\bm{q}^{\prime})\in\delta\) governing the automaton state transitions. We say that an execution of \(\mathcal{A}\) is _fair_ (also said to be an accepting execution) if it visits fair states infinitely often. We define the fair language \(L^{t}_{\mathcal{A}}\) of \(\mathcal{A}\) as the maximal set of traces corresponding to fair executions initialised in \(q_{0}\). Given any LTL formula \(\Phi\), there are translation algorithms and tools to construct non-deterministic Buchi automata \(\mathcal{A}_{\Phi}\) such that \(L^{t}_{\mathcal{A}_{\Phi}}=L_{\Phi}\)[44, 58].

The standard approach to answer the language inclusion question \(L_{\mathcal{M}}\subseteq L_{\Phi}\) is to answer the dual language emptiness question \(L_{\mathcal{M}}\cap L_{\neg\Phi}=\emptyset\)[13, 35]. For this purpose, we first construct a non-deterministic Buchi automaton \(\mathcal{A}_{\neg\Phi}\) for the complement specification \(\neg\Phi\) where \(\mathrm{inp}\,X_{\mathcal{A}_{\neg\Phi}}=\mathrm{obs}\,X_{\mathcal{M}}\), then we reason over the synchronous composition (over a shared clock) of \(\mathcal{M}\) and \(\mathcal{A}_{\neg\Phi}\) as illustrated in Figure 0(a). We direct the reader to the relevant literature for general definitions of system composition [10]. In this context, the synchronous composition results in the system \(\mathcal{M}\parallel\mathcal{A}_{\neg\Phi}\) with input variables \(\mathrm{inp}\,X_{\mathcal{M}\parallel\mathcal{A}_{\neg\Phi}}=\mathrm{inp}\,X_{ \mathcal{M}}\), register variables \(\mathrm{reg}\,X_{\mathcal{M}\parallel\mathcal{A}_{\neg\Phi}}=\mathrm{reg}\,X_{ \mathcal{M}}\cup\{\mathsf{q}\}\), observable variables \(\mathrm{obs}\,X_{\mathcal{M}\parallel\mathcal{A}_{\neg\Phi}}=\mathrm{obs}\,X_{ \mathcal{M}}\), and sequential update relation \(\mathrm{Update}_{\mathcal{M}\parallel\mathcal{A}_{\neg\Phi}}(s,q,r^{\prime},q^{\prime})=\mathrm{Update}_{\mathcal{M}}(s,r^{\prime})\wedge\mathrm{Update}_{ \mathcal{A}_{\neg\Phi}}(\mathrm{obs}\,s,q,q^{\prime})\). We extend the fair states of \(\mathcal{A}_{\neg\Phi}\) to \(\mathcal{M}\parallel\mathcal{A}_{\neg\Phi}\), i.e., we define them as \(\{(s,q)\mid s\in S,q\in F\}\), and as a result we have that \(L^{t}_{\mathcal{M}\parallel\mathcal{A}_{\neg\Phi}}=L_{\mathcal{M}}\cap L^{t}_{ \mathcal{A}_{\neg\Phi}}=L_{\mathcal{M}}\cap L_{\neg\Phi}\). This reduces our language emptiness question to the equivalent _fair emptiness_ problem \(L^{t}_{\mathcal{M}\parallel\mathcal{A}_{\neg\Phi}}=\emptyset\).

Figure 1: Automata-theoretic neural model checking via fair termination

The fair emptiness problem amounts to showing that all executions of \(\mathcal{M}\parallel\mathcal{A}_{\neg\Phi}\) are unfair, and we do so by presenting a ranking function that witnesses fair termination [51, 67]. A ranking function for fair termination is a map \(V:\,\mathrm{reg}\,S\times Q\to R\) where \((R,\prec)\) defines a well-founded relation and, for all system and automaton states \(\bm{s},\bm{s}^{\prime}\in S,\bm{q},\bm{q}^{\prime}\in Q\), the following two conditions hold true:

\[(\bm{s},\bm{q})\rightarrow_{\mathcal{M}\parallel\mathcal{A}_{ \neg\Phi}}(\bm{s}^{\prime},\bm{q}^{\prime})\implies V(\mathrm{reg}\,\bm{s},\bm {q})\succeq V(\mathrm{reg}\,\bm{s}^{\prime},\bm{q}^{\prime})\] (1) \[(\bm{s},\bm{q})\rightarrow_{\mathcal{M}\parallel\mathcal{A}_{ \neg\Phi}}(\bm{s}^{\prime},\bm{q}^{\prime})\wedge\bm{q}\in F\implies V(\mathrm{ reg}\,\bm{s},\bm{q})\succ V(\mathrm{reg}\,\bm{s}^{\prime},\bm{q}^{\prime})\] (2)

A ranking function \(V\) strictly decreases every time a transition from a fair state is taken, and never increases in any other case. Since every strictly decreasing sequence must be bounded from below (well-foundedness), every fair state can be visited at most finitely many times; the intuition is presented in Figure 0(b), where \(\bm{1}_{F}(q)\) denotes the indicator function of \(F\), returning 1 if \(q\in F\) and 0 otherwise. The existence of a valid ranking function represented in some form establishes that every execution of \(\mathcal{M}\parallel\mathcal{A}_{\neg\Phi}\) is necessarily unfair [95]. In this work, we represent ranking functions as neural networks, the parameters of which we train from generated sample executions.

## 3 Neural Ranking Functions for Fair Termination

We approach the problem of computing a ranking function for fair termination by training a neural network \(\bar{V}\colon\mathbb{R}^{n}\times\Theta\to\mathbb{R}\), with \(n\) input neurons where \(n=|\,\mathrm{reg}\,X_{\mathcal{M}}|\) is the number of register variables of the system, one output neuron, and with a space of learnable parameters \(\Theta\) for its weights and biases. We associate a distinct trainable parameter \(\theta_{q}\in\Theta\) to each state \(q\in Q\) of the Buchi automaton. We train these parameters on sampled executions of \(\mathcal{M}\parallel\mathcal{A}_{\neg\Phi}\) to ultimately represent a ranking function as a neural network \(V(r,q)\equiv\bar{V}(r;\theta_{q})\), which we call a neural ranking function. This scheme is illustrated in Figure 1, where we denote the set of all parameters by the unindexed \(\theta\).

We define our training objective as fulfilling conditions (1) and (2) on our synthetic dataset of sampled executions which, by analogy with reinforcement learning, can be viewed as a special case of episodes [53, 55]. Subsequently, we verify the conditions symbolically over the full state space \(S\times Q\) using satisfiability solving modulo theories (SMT) [14, 60], to confirm the validity of our neural ranking function or obtain a counterexample for re-training. Overall, our approach combines learning and SMT-based checking for both efficacy and formal soundness, as illustrated in Figure 2.

For a system \(\mathcal{M}\) and a specification \(\Phi\), we train the parameters \(\theta\) of a neural network \(\bar{V}\) from a sample dataset \(D\subset\mathrm{reg}\,S\times Q\times\mathrm{reg}\,S\times Q\) of subsequent transition pairs, which we construct from random executions of the synchronous composition \(\mathcal{M}\parallel\mathcal{A}_{\neg\Phi}\). Each execution \((\bar{\bm{s}}_{0},\bar{\bm{q}}_{0}),(\bar{\bm{s}}_{1},\bar{\bm{q}}_{1}),\dots,( \bar{\bm{s}}_{k},\bar{\bm{q}}_{k})\) initiates from a random system and automaton state pair and is then simulated over a finite number of steps; the inputs to \(\mathcal{M}\) and the non-deterministic choices in \(\mathcal{A}_{\neg\Phi}\) are resolved randomly. Our dataset \(D\) is constructed as the set of all quadruples \((\mathrm{reg}\,\bar{\bm{s}}_{i},\bar{\bm{q}}_{i},\mathrm{reg}\,\bar{\bm{s}}_{i+1 },\bar{\bm{q}}_{i+1})\) for \(i=0,\dots,k-1\) from all sampled executions, capturing consecutive state pairs along each execution; notably, the order in which quadruples are stored in \(D\) is immaterial for our purpose, as our method reasons and trains locally on each transition pair regardless of their order of appearance along any execution.

We train the parameters of our neural network \(\bar{V}\) to satisfy the ranking function conditions (1) and (2) over \(D\). For each quadruple \((\bm{r},\bm{q},\bm{r}^{\prime},\bm{q}^{\prime})\in D\), this amounts to minimising the following loss function:

\[\mathcal{L}_{\text{Rank}}(\bm{r},\bm{q},\bm{r}^{\prime},\bm{q}^{\prime};\theta) =\mathrm{ReLU}(\bar{V}(\bm{r}^{\prime};\theta_{\bm{q}^{\prime}})-\bar{V}(\bm{ r};\theta_{\bm{q}})+\epsilon\cdot\bm{1}_{F}(\bm{q})).\] (3)

where \(\epsilon>0\) is a hyper-parameter that denotes the margin for the decrease condition. When \(\mathcal{L}_{\text{Rank}}\) takes its minimum value--which is zero--then the following two cases are satisfied: if \(\bm{q}\not\in F\), then \(\bar{V}\) does not increase along the given transition, i.e., \(\bar{V}(\bm{r};\theta_{\bm{q}})\geq\bar{V}(\bm{r}^{\prime};\theta_{\bm{q}^{ \prime}})\), which corresponds to satisfy condition (1); if otherwise \(\bm{q}\in F\), then \(\bar{V}\) decreases by at least the margin \(\epsilon>0\) along the given transition, i.e., \(\bar{V}(\bm{r};\theta_{\bm{q}})\geq\bar{V}(\bm{r}^{\prime};\theta_{\bm{q}^{ \prime}})+\epsilon\), which corresponds to satisfy condition (2).

Figure 2: Learn-and-check workflow for _provably sound_ neural ranking function learning

Overall, our learning phase ensures that the total loss function \(\mathcal{L}(D;\theta)\) below takes value zero:

\[\mathcal{L}(D;\theta)=\mathbb{E}_{(\bm{r},\bm{q},\bm{r}^{\prime},\bm{q}^{\prime}) \in D}[\mathcal{L}_{\text{Rank}}(\bm{r},\bm{q},\bm{r}^{\prime},\bm{q}^{\prime}; \theta)]\] (4)

Unlike many other machine learning applications, for our purpose it is essential to attain the global minimum; if this fails, there are counterexamples to \(\bar{V}\) being a ranking function in the dataset \(D\) itself. To facilitate the optimisation process, we train the parameters associated to each automaton state independently, one after the other, as opposed to training all parameters at once. Iteratively, we select one automaton state \(q\in Q\) and optimise only \(\theta_{q}\in\Theta\) for a number of steps, while keeping all other parameters \(\theta_{q^{\prime}}\in\Theta\) fixed to their current value, for all \(q^{\prime}\neq q\). We repeat the process over each automaton state, possibly iterating over the entire set of automaton states \(Q\) multiple times, until the total loss \(\mathcal{L}(D;\theta)\) takes value zero.

Our neural network \(\bar{V}\) follows a feed-forward architecture as depicted in Figure 3: for a given automaton state \(q\in Q\) and associated parameter \(\theta_{q}\), it takes an \(n\)-dimensional input \(r\in\mathbb{R}^{n}\) where each input neuron corresponds to the value of a register variable in \(\operatorname{reg}X_{\mathcal{M}}\), and produces one output for the corresponding ranking value \(\bar{V}(r;\theta_{q})\). Our architecture consists of a normalisation layer, followed by an element-wise multiplication layer, in turn followed by a multi-layer perceptron with clamped ReLU activation functions. The first layer applies a scaling factor to each input neuron independently to ensure consistent value ranges across inputs, implemented via element-wise multiplication with a constant vector of scaling coefficients derived from the dataset \(D\) before training; this integrates data normalisation into the network, enables \(\bar{V}\) to use raw data from \(\mathcal{M}\) and simplifies the symbolic encoding of the normalisation operation during the verification phase. The second layer applies a trainable scaling factor to each individual neuron and is implemented via element-wise multiplication with a \(n\)-dimensional vector with trainable coefficients. Finally, this is followed by a fully connected multi-layer perceptron with trainable weights and biases, with the activation function defined as the element-wise application of \(\operatorname{clamp}(x;u)=\max(0,\min(x,u))\); the upper bound \(u\) and the depth and width of the hidden layers of the multi-layer perceptron component are hyper-parameters chosen to optimise training and verification performance.

Attaining zero total loss \(\mathcal{L}(D;\theta)\) guarantees that our neural ranking function candidate \(\bar{V}\) satisfies the ranking criteria for fair termination over the dataset \(D\) but not necessarily over the entire transition relation \(\to_{\mathcal{M}\|A_{-\Phi}}\), as required to fulfil conditions (1) and (2) and consequently to answer our model checking question (cf. Section 2). To formally check whether the ranking criteria are satisfied over the entire transition relation, we couple our learning procedure with a sound decision procedure that verifies their validity, as illustrated in Figure 2.

We check the validity of our candidate ranking neural network using satisfiability modulo the theory of bit-vectors. While the sequential update relation Update\({}_{\mathcal{M}\|A_{-\Phi}}\) is natively expressed over the theory of bit-vectors, the formal semantics of the neural network \(\bar{V}\) is defined on the reals. Hence, encoding \(\bar{V}\) and Update\({}_{\mathcal{M}\|A_{-\Phi}}\) within the same query would result in a combination of real and bit-vector theories, which is supported in modern SMT solvers but often leads to sub-optimal performance [60]. Therefore, to leverage the efficacy of specialised solvers for the theory of bit-vectors [80], we quantise our neural network using a standard approach for this purpose [57]; this converts all arithmetic operations within the neural networks into fixed-point arithmetic, which are implemented using integer arithmetic only. We quantise our parameters to their respective integer representation \(\tilde{\theta}\approx 2^{f}\cdot\theta\), where \(f\) is a hyper-parameter for the number of fractional digits in fixed-point representation, and we replace linear layers and activation functions by their quantised counterpart; readers may consult the relevant literature for more detailed information on neural

Figure 3: Neural ranking function architecture

network quantisation [49; 57]. This results in a quantised neural network \(\tilde{V}\colon\mathbb{Z}^{n}\times\tilde{\Theta}\to\mathbb{Z}\) that approximates our trained network \(\tilde{V}\approx 2^{f}\cdot\tilde{V}\), where \(\tilde{\Theta}\) denotes the space of integer parameters. fractional digits introduced by the linear layers [49; 57]. We consider the quantised network \(\tilde{V}\) as our candidate proof certificate for fair termination.

We reduce the validity query--whether our quantised neural network \(\tilde{V}\) satisfies the ranking criteria for fair termination (1) and (2) over the entire transition relation of \(\mathcal{M}\parallel\mathcal{A}_{\to\Phi}\)--to the dual satisfiability query for the existence of a counterexample to the criteria. Specifically, we delegate to an off-the-shelf SMT solver the task of computing a satisfying assignment \(s\in S,r^{\prime}\in\operatorname{reg}S\) for which the following quantifier-free first-order logic formula is satisfied:

\[\bigvee_{q,q^{\prime}\in Q}\operatorname{Update}_{\mathcal{M}\parallel \mathcal{A}_{\to\Phi}}(s,q,r^{\prime},q^{\prime})\wedge\tilde{V}(\operatorname {reg}s;\tilde{\bm{\theta}}_{q})-\mathbf{1}_{F}(q)<\tilde{V}(r^{\prime};\tilde{ \bm{\theta}}_{q^{\prime}})\] (5)

where \(\tilde{\bm{\theta}}\) is the (constant) parameter resulting from training and quantisation. We encode the quantised neural network \(\tilde{V}\) using a standard translation into first-order logic over the theory of bit-vectors [49], supplementing it with specialised rewriting rules to enhance the solver's performance, as detailed in Appendix A. We additionally note that \(\tilde{V}\) is guaranteed to be bounded from below as \(S\) is finite, albeit potentially very large, i.e., exponential in the combined bit-width of \(X_{\mathcal{M}}\).

If the solver finds a satisfying assignment, then the assignment represents a transition of \(\mathcal{M}\) that refutes the validity of \(\tilde{V}\); in this case, we extend it to a respective transition in \(\mathcal{M}\parallel\mathcal{A}_{\to\Phi}\), we add it to our dataset \(D\) and repeat training and verification in a loop. Conversely, if the solver determines that formula (5) is unsatisfiable, then our procedure concludes that \(\tilde{V}\) is formally a valid neural ranking function and, consequently, system \(\mathcal{M}\) satisfies specification \(\Phi\).

We note that LTL model checking of hardware designs is decidable and PSPACE-complete [9; 13; 35]. While it is theoretically possible for our approach to achieve completeness when a ranking function exists by enumerating all transitions and employing a sufficiently large neural network as a lookup table over the entire state space, this is impractical for all but toy cases. In this work, we employ tiny neural networks and incomplete but practically effective gradient descent algorithms to train neural ranking functions. We experimentally demonstrate on a large set of formal hardware verification benchmarks that this solution is very effective in practice.

## 4 Illustrative Example

Modern hardware designs frequently incorporate word-level arithmetic operations, the simplest of which being counter increments/decrements, which are a staple in hardware engineering [71; 98]. One such example is illustrated as part of the SystemVerilog module in Figure 4. This represents a simplified buffer controller that counts the number of packets stored in the buffer and indicates when the buffer is full or empty with the \(\mathtt{ful}\) and \(\mathtt{emp}\) signals, respectively. This specific controller internally coordinates read-and-write operations through the \(\mathtt{rw}\) signal: iteratively, the system signals \(\mathtt{rw}\) = 1 until the buffer is full and then \(\mathtt{rw}\) = 0 until the buffer is empty.

The design satisfies the property that both our observables \(\mathtt{ful}\) and \(\mathtt{emp}\) are true infinitely often, captured by the LTL formula \(\Phi=\mathtt{GF}\,\mathtt{ful}\wedge\mathtt{GF}\,\mathtt{emp}\). Dually, this specification says that the system

Figure 4: Illustrative hardware design, BÃ¼chi automaton, and respective ranking function

does not eventually go into a state from where \(\neg\)ful holds indefinitely nor \(\neg\)emp holds indefinitely, that is, \(\neg\Phi=\mathsf{FG}\neg\mathsf{ful}\lor\mathsf{FG}\neg\mathsf{emp}\). Equivalently, this amounts to proving that no system trace is in the fair language of the automaton \(\mathcal{A}_{\neg\Phi}\) given in Figure 4.

A neural ranking function \(\bar{V}\) for the fair termination of this system and automaton has 5 input neurons for the register variables cnt, m, ful, emp, and rw, and one hidden layer with three neurons in the multi-layer perceptron component. As illustrated in Figure 4, each automaton state is associated with a ranking function defined in terms of this architecture and their respective parameters. The sequence below gives an execution of model states alongside the respective ranking function values:

\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|} \multicolumn{12}{|c|}{\(\mathsf{emp}\)} & \multicolumn{12}{|c|}{\(\mathsf{full}\)} & \multicolumn{12}{|c|}{\(\mathsf{emp}\)} & \multicolumn{12}{|c|}{\(\mathsf{ful}\)} \\ \hline cnt & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 6 & 5 & 4 & 3 & 2 & 1 & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\ \hline m & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\ \hline rw & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 \\ \hline \(\bar{V}(\cdot;\theta_{q_{0}})\) & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 \\ \hline \(\bar{V}(\cdot;\theta_{q_{1}})\) & 8 & 7 & 6 & 5 & 4 & 3 & 2 & 1 & 14 & 13 & 12 & 11 & 10 & 9 & 8 & 7 & 6 & 5 & 4 & 3 & 2 & 1 \\ \hline \(\bar{V}(\cdot;\theta_{q_{2}})\) & 1 & 14 & 13 & 12 & 11 & 10 & 9 & 8 & 7 & 6 & 5 & 4 & 3 & 2 & 1 & 14 & 13 & 12 & 11 & 10 & 9 & 8 \\ \hline \end{tabular}

One can observe that all transitions throughout this execution satisfy conditions (1) and (2). This assessment is based on the (not explicitly presented) synchronous composition with the automaton. First, we note that every transition originating from \(q_{0}\) has a non-increasing ranking value, as \(\bar{V}(\cdot;\theta_{q_{0}})=14\) is an upper bound to all other values. Furthermore, every transition leaving \(q_{1}\)--that is, every transition whose source state satisfies \(\neg\)ful--exhibits a strictly decreasing value \(\bar{V}(\cdot;\theta_{q_{1}})\). Similarly, the same observation applies to \(q_{2}\) and the condition \(\neg\)emp. We note that the transitions that exhibit increasing values from 1 to 14 in this execution are impossible over the synchronous composition; this is because they are originating from states that satisfy both ful and \(q_{1}\), and similarly states that satisfy both emp and \(q_{2}\), and which do not have corresponding transitions in the automaton.

This neural ranking function admits no increasing transition originating from \(q_{0}\) and no non-decreasing transitions originating from \(q_{1}\) or \(q_{2}\) on the synchronous composition of the system and the automaton. Therefore, it is a valid proof certificate for every system trace to satisfy specification \(\Phi\).

## 5 Experimental Evaluation

We examine 194 verification tasks derived from ten parameterised hardware designs, detailed in Appendix B. By adjusting parameter values, we create tasks of varying complexity, resulting in different logic gate counts and state space sizes, thus offering a broad spectrum of verification complexity for tool comparison. The parameter ranges for each design are given as "all tasks" in Figure 5. These tasks serve as benchmarks to evaluate the scalability of our method relative to conventional model checking.

ImplementationWe have developed a prototype tool for neural model checking2, utilising Spot 2.11.6 [44] to generate the automaton \(\mathcal{A}_{\neg\Phi}\) from an LTL specification \(\Phi\). As depicted in Figure 1, the circuit model \(\mathcal{M}\) and the automaton \(\mathcal{A}_{\neg\Phi}\) synchronise over a shared clock to form a product machine. Using Verilator version 5.022 [88], we generate a dataset \(D\) from finite trajectories of this machine. This dataset trains a neural network using PyTorch 2.2.2, as outlined in Section 3. To ensure formal guarantees, the network is quantised and subsequently translated to SMT, following the process outlined in Appendix A. The SystemVerilog model is converted to SMT using EBMC 5.2 [76]. We check the satisfiability problem using the Bitwuzla 0.6.0 SMT solver [80].

Footnote 2: https://github.com/aiverification/neuralmc

State of the ArtWe benchmarked our neural model checking approach against two leading model checkers, nuXmv [27] and ABC [24, 25]. ABC and nuXmv were the top performers in the liveness category of the hardware model checking competition (HWMCC) [15, 19]. Our comparison employed the latest versions: nuXmv 2.0.0 and ABC's Super Prove tool suite [25], which were also used in the most recent HWMCC'20 [15]. We further consider two widely used industrial formal verification tools for SystemVerilog, anonymised as industry tool X and industry tool Y. Tool Y fails to complete any of the 194 tasks and is therefore not referenced further in this section.

Experimental SetupEvaluations were conducted on an Intel Xeon 2.5 GHz processor with eight threads and 32 GB of RAM running Ubuntu 20.04. Bitwuzla and nuXmv utilise one core each, ABC used three cores, and PyTorch leveraged all available cores. Each tool was allotted a maximum of five hours for each verification task, as detailed in Appendix C.

Hyper-parametersWe instantiate the architecture described in Section 3 and illustrated in Figure 3, employing two hidden layers containing 8 and 5 neurons. The normalisation layer scales the input values to the range [0, 100]. We train with the AdamW optimiser [70], typically setting the learning rate to 0.1 or selecting from 0.2, 0.05, 0.03, 0.01 if adjusted, with a fixed weight decay of 0.01, demonstrating minimal hyperparameter tuning for training.

Dataset GenerationIn hardware design, engineers utilise test benches to verify safety properties through directed testing or Constraint Random Verification (CRV), aiming for high coverage and capturing edge cases [89, 48]. We apply CRV to the SystemVerilog file, generating random trajectories. As outlined in Section 3, we start these trajectories by selecting the internal states of model \(\mathcal{M}\) (e.g., module BufferCtr and automaton \(A_{\neg\Phi}\); in Figure 4) using a uniform distribution. At each step, we assign random inputs to model \(\mathcal{M}\) and handle the non-determinism in automaton \(A_{\neg\Phi}\) by making choices from uniform or skewed distributions. We skew the distribution when a particular event is too predominant or too rare. In our experiments, such skewing is rare and limited to the reset and enable signals in \(\mathcal{M}\), as well as the non-determinism in the automaton \(A_{\neg\Phi}\).

Solved TasksTable 1 presents the number of completed tasks for each tool across the ten hardware designs, while Figure 5 shows the range of state-space sizes and logic gate counts each tool successfully handled. Overall, our tool performs favourably in comparison to others, with the notable exception of the VGA design, where training a ranking function failed due to local minima, preventing convergence to zero loss--a known limitation of gradient descent-based methods.

Aggregate Runtime ComparisonFigure 5(a) displays a cactus plot with a \(5\,\mathrm{h}\) limit, we consider our configuration with 8 and 5 hidden neurons as detailed in the section, along with the aggregate of the best time on individual tasks obtained from our ablation study, as detailed in Appendix D. While the default architecture performs the best across all tasks, on some tasks a smaller network is sufficient, and leads to lower verification time. At the same time, larger networks often succeed on tasks that otherwise fail, making the "our best" line strictly better than "our (5, 8)". This shows that improvement can be obtained by tuning the width of the hidden layers; note that this analysis considers three additional configurations (i.e, (3, 2), (5, 3), (15, 8)) that adhere to the architecture introduced in Section 3. For the rest of our experiments, we continue using the default architecture.

Figure 5: Solved tasks in terms of state space size and logic gate count (log scale)

\begin{table}
\begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|} \hline  & LS & LCD & Tmcp & i2cS & 7-Seg & PWM & VGA & UARTIt & Delay & Gray & Total \\ \hline Tasks & 16 & 14 & 17 & 20 & 30 & 12 & 10 & 10 & 32 & 33 & 194 \\ \hline \hline ABC & 2 & 3 & 7 & 3 & 8 & 2 & 3 & **10** & 6 & 13 & 57 \\ \hline nuXmv & 8 & 9 & 12 & 10 & 10 & 7 & 3 & **10** & 24 & 24 & 117 \\ \hline our & 15 & **14** & **17** & **18** & **30** & 11 & 0 & **10** & **32** & **33** & 180 \\ \hline \hline Ind. X & **16** & **14** & **17** & **18** & 18 & **12** & **10** & **10** & 19 & 22 & 156 \\ \hline Ind. Y & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ \hline \end{tabular}
\end{table}
Table 1: Number of verification task completed by academic and industrial tool, per design The plot further shows that our tool completes \(93\,\%\) of tasks, outperforming ABC, nuXmv, and industry tool X, which completes \(29\,\%\), \(60\,\%\), and \(80\,\%\), respectively. At any point in the time axis, we compute the difference between the percentage of tasks completed by our tool with each of the others in the figure. Then, taking the average of these differences across the time axis, showing that our method is successful in \(60\,\%\) more tasks than ABC, \(34\,\%\) more than nuXmv, and \(11\,\%\) more than the leading commercial model checker at any given time. Furthermore, the number of tasks completed by nuXmv in \(5\,\mathrm{h}\) are finished by our tool in less than \(8\,\mathrm{min}\), and those completed by ABC in \(5\,\mathrm{h}\) take just under \(3\,\mathrm{min}\) with our method.

Individual Runtime ComparisonFigure 5(b) presents a scatter plot where each point represents a verification task, with size and brightness indicating the state-space size. Points are plotted horizontally by the lesser of time taken by nuXmv or ABC and vertically by our method's time. The plot reveals that academic tools time out on \(39\,\%\) of tasks, while our method times out on \(7\,\%\). Moreover, we are faster than the academic tools on \(67\,\%\) of tasks, 10 times faster on \(34\,\%\), and 100 times faster on \(4\,\%\). These results demonstrate that we generally outperform the state of the art on this benchmark set (see Appendix 3 for individual runtimes). However, we perform relatively worse on the UARTt design. This design involves an \(N\)-bit register for data storage and a counter for transmitted bits, enabling sequential outputs. Since there is no word-level arithmetic over the \(N\)-bit register, increasing its size minimally affects the complexity of symbolic model checking. Consequently, ABC, nuXmv, and industry tool X complete all UARTt tasks in under a second, while our tool takes a few minutes due to overhead from the sampling, learning, and SMT-check steps, making us slower on trivial model-checking problems.

Learning vs. Checking TimeFigure 5(c) illustrates the time split between learning the neural network--which involves dataset generation and training--and verifying it as a valid ranking function. The lower line indicates learning time; the upper line represents total time, with the gap showing the time spent on SMT checking. Extensive sampling across a broad range of trajectories covering most edge cases led our method to learn the network directly without needing retraining due to counterexamples in the SMT-check phase, except in four tasks. The plot shows that \(93\,\%\) of tasks were trained successfully, generally within five minutes, and remarkably, the \(70\,\%\) were completed in under a minute. For tasks that did not train to zero loss, the \(5\,\mathrm{h}\) time limit was not fully utilised; the loss function stabilised at local maxima in just a few minutes. Moreover, training was faster than verification on \(97\,\%\) tasks--10 times faster on \(46\,\%\) and 100 times faster on \(6\,\%\).

LimitationsThe primary limitation of our approach arises from the extended SMT-check times and the risk of getting trapped in local minima. Despite these challenges, our method consistently outperforms traditional symbolic model checkers while relying on off-the-shelf SMT solvers and machine learning optimisers. Additionally, our neural architecture requires numerical inputs at the word level, which limits its application to bit-level netlists. This limitation is not high-impact, as modern formal verification tools predominantly utilise Verilog RTL rather than netlist representations.

Threats to ValidityThe experimental results may not generalise to other workloads. As any work that relies on benchmarks, our benchmarks may not be representative for other workloads. We mitigate this threat by selecting extremely common hardware design patterns from the standard literature. We remark that our data sets we use to train the neural nets do not suffer from the common threat of training data bias, and the common out-of-distribution problem: we train our neural net from scratch for each benchmark using randomly generated trajectories, and do not use any pretraining.

Figure 6: Runtime comparison with the state of the art (all times are in log scale)

[MISSING_PAGE_FAIL:10]

## Acknowledgements

We thank Matthew Leeke, Sonia Marin, and Mark Ryan for their feedback and the anonymous reviewers for their comments and suggestions on this manuscript. This work was supported in part by the Advanced Research + Invention Agency (ARIA) under the Safeguarded AI programme.

## References

* Abate et al. [2021] A. Abate, D. Ahmed, A. Edwards, M. Giacobbe, and A. Peruffo. FOSSIL: a software tool for the formal synthesis of Lyapunov functions and barrier certificates using neural networks. In _HSCC_, pages 24:1-24:11. ACM, 2021.
* Abate et al. [2021] A. Abate, D. Ahmed, M. Giacobbe, and A. Peruffo. Formal synthesis of Lyapunov neural networks. _IEEE Control. Syst. Lett._, 5(3):773-778, 2021.
* Abate et al. [2021] A. Abate, M. Giacobbe, and D. Roy. Learning probabilistic termination proofs. In _CAV (2)_, volume 12760 of _Lecture Notes in Computer Science_, pages 3-26. Springer, 2021.
* Leibniz-Zentrum fur Informatik, 2023.
* Abate et al. [2024] A. Abate, M. Giacobbe, and D. Roy. Stochastic omega-regular verification and control with supermartingales. In _CAV (3)_, volume 14683 of _Lecture Notes in Computer Science_, pages 395-419. Springer, 2024.
* Abate et al. [2024] A. Abate, M. Giacobbe, and Y. Schnitzer. Bisimulation learning. In _CAV (3)_, volume 14683 of _Lecture Notes in Computer Science_, pages 161-183. Springer, 2024.
* Akers [1978] S. B. Akers. Binary decision diagrams. _IEEE Trans. Computers_, 27(6):509-516, 1978.
* Alpern and Schneider [1987] B. Alpern and F. B. Schneider. Recognizing safety and liveness. _Distributed Comput._, 2(3):117-126, 1987.
* Alur [2015] R. Alur. _Principles of Cyber-Physical Systems_. MIT Press, 2015.
* Alur and Henzinger [1996] R. Alur and T. A. Henzinger. Reactive modules. In _LICS_, pages 207-218. IEEE, 1996.
* Amir et al. [2021] G. Amir, H. Wu, C. W. Barrett, and G. Katz. An SMT-based approach for verifying binarized neural networks. In _TACAS (2)_, volume 12652 of _Lecture Notes in Computer Science_, pages 203-222. Springer, 2021.
* Andraus et al. [2008] Z. S. Andraus, M. H. Liffiton, and K. A. Sakallah. Reveal: A formal verification tool for Verilog designs. In _LPAR_, volume 5330 of _Lecture Notes in Computer Science_, pages 343-352. Springer, 2008.
* Baier and Katoen [2008] C. Baier and J. Katoen. _Principles of Model Checking_. MIT Press, 2008.
* Barrett et al. [2009] C. W. Barrett, R. Sebastiani, S. A. Seshia, and C. Tinelli. Satisfiability modulo theories. In _Handbook of Satisfiability_, volume 185 of _Frontiers in Artificial Intelligence and Applications_, pages 825-885. IOS Press, 2009.
* Biere et al. [2020] A. Biere, N. Froleyks, and M. Preiner. Hardware model checking competition (HWACC) 2020. URL https://hwmcc.github.io/2020/.
* Biere et al. [1999] A. Biere, A. Cimatti, E. M. Clarke, and Y. Zhu. Symbolic model checking without BDDs. In _TACAS_, volume 1579 of _LNCS_, pages 193-207. Springer, 1999.
* Biere et al. [1999] A. Biere, E. M. Clarke, R. Raimi, and Y. Zhu. Verifiying safety properties of a Power PC microprocessor using symbolic model checking without BDDs. In _CAV_, volume 1633 of _LNCS_, pages 60-71. Springer, 1999.
* Biere et al. [2002] A. Biere, C. Artho, and V. Schuppan. Liveness checking as safety checking. In _FMICS_, volume 66 of _Electronic Notes in Theoretical Computer Science_, pages 160-177. Elsevier, 2002.

* [19] A. Biere, T. Van Dijk, and K. Heljanko. Hardware model checking competition 2017. In _Formal Methods in Computer Aided Design (FMCAD)_, pages 9-9. IEEE, 2017.
* [20] A. R. Bradley. SAT-based model checking without unrolling. In _VMCAI_, volume 6538 of _Lecture Notes in Computer Science_, pages 70-87. Springer, 2011.
* [21] A. R. Bradley, Z. Manna, and H. B. Sipma. Linear ranking with reachability. In _CAV_, volume 3576 of _Lecture Notes in Computer Science_, pages 491-504. Springer, 2005.
* [22] A. R. Bradley, Z. Manna, and H. B. Sipma. The polyranking principle. In _ICALP_, volume 3580 of _Lecture Notes in Computer Science_, pages 1349-1361. Springer, 2005.
* [23] A. R. Bradley, F. Somenzi, Z. Hassan, and Y. Zhang. An incremental approach to model checking progress properties. In _FMCAD_, pages 144-153. FMCAD Inc., 2011.
* [24] R. K. Brayton and A. Mishchenko. ABC: an academic industrial-strength verification tool. In _CAV_, volume 6174 of _LNCS_, pages 24-40. Springer, 2010.
* [25] R. K. Brayton, B. Sterin, N. Een, S. Ray, J. Long, and A. Mishchenko. Model checking system "super_prove", 2008-2017. URL https://github.com/sterin/super-prove-build.
* [26] J. R. Burch, E. M. Clarke, K. L. McMillan, D. L. Dill, and L. J. Hwang. Symbolic model checking: 10\({}^{20}\) states and beyond. _Inf. Comput._, 98(2):142-170, 1992.
* [27] R. Cavada, A. Cimatti, M. Dorigatti, A. Griggio, A. Mariotti, A. Micheli, S. Mover, M. Roveri, and S. Tonetta. The nuXmv symbolic model checker. In _CAV_, volume 8559 of _LNCS_, pages 334-342. Springer, 2014.
* [28] Y. Chang, N. Roohi, and S. Gao. Neural Lyapunov Control. In _NeurIPS_, pages 3240-3249, 2019.
* [29] H. Chen, C. David, D. Kroening, P. Schrammel, and B. Wachter. Bit-precise procedure-modular termination analysis. _ACM Trans. Program. Lang. Syst._, 40(1):1:1-1:38, 2018.
* [30] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. de Oliveira Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman, A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter, P. Tillet, F. P. Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A. Herbert-Voss, W. H. Guss, A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike, J. Achiam, V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati, K. Mayer, P. Welinder, B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, and W. Zaremba. Evaluating large language models trained on code. _CoRR_, abs/2107.03374, 2021.
* [31] K. Claessen and N. Sorensson. A liveness checking algorithm that counts. In _FMCAD_, pages 52-59. IEEE, 2012.
* [32] E. M. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith. Counterexample-guided abstraction refinement. In _CAV_, volume 1855 of _Lecture Notes in Computer Science_, pages 154-169. Springer, 2000.
* [33] E. M. Clarke, D. Kroening, and F. Lerda. A tool for checking ANSI-C programs. In _TACAS_, volume 2988 of _LNCS_, pages 168-176. Springer, 2004.
* [34] E. M. Clarke, R. P. Kurshan, and H. Veith. The localization reduction and counterexample-guided abstraction refinement. In _Essays in Memory of Amir Pnueli_, volume 6200 of _Lecture Notes in Computer Science_, pages 61-71. Springer, 2010.
* [35] E. M. Clarke, O. Grumberg, D. Kroening, D. A. Peled, and H. Veith. _Model checking, 2nd Edition_. MIT Press, 2018.
* [36] B. Cook, A. Podelski, and A. Rybalchenko. Termination proofs for systems code. In _PLDI_, pages 415-426. ACM, 2006.

* [37] B. Cook, A. Gotsman, A. Podelski, A. Rybalchenko, and M. Y. Vardi. Proving that programs eventually do something good. In _POPL_, pages 265-276. ACM, 2007.
* [38] B. Cook, A. See, and F. Zuleger. Ramsey vs. lexicographic termination proving. In _TACAS_, volume 7795 of _Lecture Notes in Computer Science_, pages 47-61. Springer, 2013.
* [39] B. Cook, H. Kllaaf, and N. Piterman. Fairness for infinite-state systems. In _TACAS_, volume 9035 of _Lecture Notes in Computer Science_, pages 384-398. Springer, 2015.
* [40] C. David, D. Kroening, and M. Lewis. Unrestricted termination and non-termination arguments for bit-vector programs. In _ESOP_, volume 9032 of _Lecture Notes in Computer Science_, pages 183-204. Springer, 2015.
* [41] C. Dawson, Z. Qin, S. Gao, and C. Fan. Safe nonlinear control using robust neural Lyapunov-barrier functions. In _CoRL_, volume 164 of _Proceedings of Machine Learning Research_, pages 1724-1735. PMLR, 2021.
* [42] D. Dietsch, M. Heizmann, V. Langenfeld, and A. Podelski. Fairness modulo theory: A new approach to LTL software model checking. In _CAV (1)_, volume 9206 of _Lecture Notes in Computer Science_, pages 49-66. Springer, 2015.
* [43] R. Dimitrova, L. M. F. Fioriti, H. Hermanns, and R. Majumdar. Probabilistic CTL": The deductive way. In _TACAS_, volume 9636 of _Lecture Notes in Computer Science_, pages 280-296. Springer, 2016.
* [44] A. Duret-Lutz, E. Renault, M. Colange, F. Renkin, A. G. Aisse, P. Schlehuber-Caissier, T. Medioni, A. Martin, J. Dubois, C. Gillard, and H. Lauko. From Spot 2.0 to Spot 2.10: What's new? In _CAV (2)_, volume 13372 of _LNCS_, pages 174-187. Springer, 2022.
* [45] E. A. Emerson and E. M. Clarke. Characterizing correctness properties of parallel programs using fixpoints. In _ICALP_, volume 85 of _LNCS_, pages 169-181. Springer, 1980.
* [46] E. A. Emerson and C. Lei. Modalities for model checking: Branching time strikes back. In _POPL_, pages 84-96. ACM Press, 1985.
* [47] R. W. Floyd. Assigning meanings to programs. In _Proceedings of Symposium in Applied lanthematics_, volume 19, pages 19-32, 1967.
* [48] H. Foster. The 2022 Wilson research group functional verification study, 2022. URL https://blogs.sw.siemens.com/verificationhorizons/2022/10/10/prologue-the-2022-wilson-research-group-functional-verification-study/.
* [49] M. Giacobbe, T. A. Henzinger, and M. Lechner. How many bits does it take to quantize your neural network? In _TACAS (2)_, volume 12079 of _LNCS_, pages 79-97. Springer, 2020.
* [50] M. Giacobbe, D. Kroening, and J. Parsert. Neural termination analysis. In _ESEC/SIGSOFT FSE_, pages 633-645. ACM, 2022.
* [51] O. Grumberg, N. Francez, J. A. Makowsky, and W. P. de Roever. A proof rule for fair termination of guarded commands. _Inf. Control._, 66(1/2):83-102, 1985.
* [52] D. Harel and A. Pnueli. On the development of reactive systems. In _Logics and Models of Concurrent Systems_, volume 13 of _NATO ASI Series_, pages 477-498. Springer, 1984.
* [53] H. Hasanbeig, D. Kroening, and A. Abate. Certified reinforcement learning with logic guidance. _Artif. Intell._, 322:103949, 2023.
* [54] D. G. Holmes and T. A. Lipo. _Pulse width modulation for power converters: principles and practice_, volume 18. John Wiley & Sons, 2003.
* [55] R. T. Icarte, T. Q. Klassen, R. A. Valenzano, and S. A. McIlraith. Reward machines: Exploiting reward function structure in reinforcement learning. _J. Artif. Intell. Res._, 73:173-208, 2022.
* [56] A. Ivrii, Z. Nevo, and J. Baumgartner. k-FAIR = k-LIVENESS + FAIR--revisiting SAT-based liveness algorithms. In _FMCAD_, pages 1-5. IEEE, 2018.

* [57] B. Jacob, S. Kligys, B. Chen, M. Zhu, M. Tang, A. G. Howard, H. Adam, and D. Kalenichenko. Quantization and training of neural networks for efficient integer-arithmetic-only inference. In _CVPR_, pages 2704-2713. Computer Vision Foundation / IEEE Computer Society, 2018.
* [58] J. Kretinsky, T. Meggendorfer, and S. Sickert. Owl: A library for \(\omega\)-words, automata, and LTL. In _ATVA_, volume 11138 of _Lecture Notes in Computer Science_, pages 543-550. Springer, 2018.
* [59] D. Kroening and O. Strichman. Efficient computation of recurrence diameters. In _VMCAI_, volume 2575 of _Lecture Notes in Computer Science_, pages 298-309. Springer, 2003.
* [60] D. Kroening and O. Strichman. _Decision Procedures--An Algorithmic Point of View, Second Edition_. Texts in Theoretical Computer Science. Springer, 2016.
* [61] D. Kroening, N. Sharygina, A. Tsitovich, and C. M. Wintersteiger. Termination analysis with compositional transition invariants. In _CAV_, volume 6174 of _Lecture Notes in Computer Science_, pages 89-103. Springer, 2010.
* [62] O. Kupferman and M. Y. Vardi. Model checking of safety properties. In _CAV_, volume 1633 of _Lecture Notes in Computer Science_, pages 172-183. Springer, 1999.
* [63] S. Kura, H. Unno, and I. Hasuo. Decision tree learning in CEGIS-based termination analysis. In _CAV (2)_, volume 12760 of _Lecture Notes in Computer Science_, pages 75-98. Springer, 2021.
* [64] L. C. Lamb, A. S. d'Avila Garcez, M. Gori, M. O. R. Prates, P. H. C. Avelar, and M. Y. Vardi. Graph neural networks meet neural-symbolic computing: A survey and perspective. In _IJCAI_, pages 4877-4884. ijcai.org, 2020.
* [65] L. Lamport. Proving the correctness of multiprocess programs. _IEEE Trans. Software Eng._, 3(2):125-143, 1977.
* [66] M. Lechner, D. Zikelic, K. Chatterjee, and T. A. Henzinger. Stability verification in stochastic control systems via neural network supermartingales. In _AAAI_, pages 7326-7336. AAAI Press, 2022.
* [67] D. Lehmann, A. Pnueli, and J. Stavi. Impartiality, justice and fairness: The ethics of concurrent termination. In _ICALP_, volume 115 of _LNCS_, pages 264-277. Springer, 1981.
* [68] J. Leike and M. Heizmann. Ranking templates for linear loops. _Log. Methods Comput. Sci._, 11(1), 2015.
* [69] M. Liu, N. R. Pinckney, B. Khailany, and H. Ren. VerilogEval: Evaluating large language models for Verilog code generation. In _ICCAD_, pages 1-8. IEEE, 2023.
* [70] I. Loshchilov and F. Hutter. Decoupled weight decay regularization. In _ICLR (Poster)_. OpenReview.net, 2019.
* [71] A. K. Maini. _Digital electronics: principles, devices and applications, Chapter 11: Counters and Registers_. John Wiley & Sons, 2007.
* [72] J. B. P. Matos, Jr., E. B. de Lima Filho, I. Bessa, E. Manino, X. Song, and L. C. Cordeiro. Counterexample guided neural network quantization refinement. _IEEE Trans. Comput. Aided Des. Integr. Circuits Syst._, 43(4):1121-1134, 2024.
* [73] K. L. McMillan. Applying SAT methods in unbounded symbolic model checking. In _CAV_, volume 2404 of _Lecture Notes in Computer Science_, pages 250-264. Springer, 2002.
* [74] A. Mirhoseini, A. Goldie, M. Yazgan, et al. A graph placement methodology for fast chip design. _Nature_, (594):207-212, 2021.
* [75] S. Mistry, I. Saha, and S. Biswas. An MILP encoding for efficient verification of quantized deep neural networks. _IEEE Trans. Comput. Aided Des. Integr. Circuits Syst._, 41(11):4445-4456, 2022.

* Mukherjee et al. [2015] R. Mukherjee, D. Kroening, and T. Melham. Hardware verification using software analyzers. In _ISVLSI_, pages 7-12. IEEE Computer Society, 2015.
* Mukherjee et al. [2016] R. Mukherjee, P. Schrammel, D. Kroening, and T. Melham. Unbounded safety verification for hardware using software analyzers. In _DATE_, pages 1152-1155. IEEE, 2016.
* Murali et al. [2024] V. Murali, A. Trivedi, and M. Zamani. Closure certificates. In _HSCC_, pages 10:1-10:11. ACM, 2024.
* Nadali et al. [2024] A. Nadali, V. Murali, A. Trivedi, and M. Zamani. Neural closure certificates. In _AAAI_, pages 21446-21453. AAAI Press, 2024.
* Niemetz and Preiner [2023] A. Niemetz and M. Preiner. Bitwuzla. In _CAV (2)_, volume 13965 of _LNCS_, pages 3-17. Springer, 2023.
* Nori and Sharma [2013] A. V. Nori and R. Sharma. Termination proofs from tests. In _ESEC/SIGSOFT FSE_, pages 246-256. ACM, 2013.
* Pnueli [1977] A. Pnueli. The temporal logic of programs. In _FOCS_, pages 46-57. IEEE, 1977.
* Podelski and Rybalchenko [2004] A. Podelski and A. Rybalchenko. Transition invariants. In _LICS_, pages 32-41. IEEE Computer Society, 2004.
* Podelski and Rybalchenko [2004] A. Podelski and A. Rybalchenko. A complete method for the synthesis of linear ranking functions. In _VMCAI_, volume 2937 of _Lecture Notes in Computer Science_, pages 239-251. Springer, 2004.
* Podelski and Rybalchenko [2007] A. Podelski and A. Rybalchenko. Transition predicate abstraction and fair termination. _ACM Trans. Program. Lang. Syst._, 29(3):15, 2007.
* Qin et al. [2021] Z. Qin, K. Zhang, Y. Chen, J. Chen, and C. Fan. Learning safe multi-agent control with decentralized neural barrier certificates. In _ICLR_. OpenReview.net, 2021.
* Seufert et al. [2023] T. Seufert, F. Winterer, C. Scholl, K. Scheibler, T. Paxian, and B. Becker. Everything you always wanted to know about generalization of proof obligations in PDR. _IEEE Trans. Comput. Aided Des. Integr. Circuits Syst._, 42(4):1351-1364, 2023.
* Snyder [2004] W. Snyder. Verilator and SystemPerl. In _North American SystemC Users' Group, Design Automation Conference_, 2004.
* Spear and Tumbush [2012] C. Spear and G. Tumbush. SystemVerilog for verification--a guide to learning the testbench language features. 2012.
* Subero and Subero [2018] A. Subero and A. Subero. USART, SPI, and I2C: serial communication protocols. _Programming PIC Microcontrollers with XC8_, pages 209-276, 2018.
* Trippel et al. [2022] T. Trippel, K. G. Shin, A. Chernyakhovsky, G. Kelly, D. Rizzo, and M. Hicks. Fuzzing hardware like software. In _USENIX Security Symposium_, pages 3237-3254. USENIX Association, 2022.
* [92] UM10204. I2C-bus specification and user manual, 2021. URL https://www.nxp.com/docs/en/user-guide/UM10204.pdf.
* Urban [2013] C. Urban. The abstract domain of segmented ranking functions. In _SAS_, volume 7935 of _Lecture Notes in Computer Science_, pages 43-62. Springer, 2013.
* Urban [2015] C. Urban. FuncTion: An abstract domain functor for termination (competition contribution). In _TACAS_, volume 9035 of _Lecture Notes in Computer Science_, pages 464-466. Springer, 2015.
* Vardi [1991] M. Y. Vardi. Verification of concurrent programs: The automata-theoretic framework. _Ann. Pure Appl. Log._, 51(1-2):79-98, 1991.
* Vardi and Wolper [1986] M. Y. Vardi and P. Wolper. An automata-theoretic approach to automatic program verification (preliminary report). In _LICS_, pages 332-344. IEEE, 1986.

* [97] E. W. Weisstein. Gray code. _https://mathworld.wolfram.com/_, 2003.
* [98] X. Zhang, S. Dwarkadas, G. Folkmanis, and K. Shen. Processor hardware counter statistics as a first-class system resource. In _HotOS_. USENIX Association, 2007.
* [99] H. Zhao, X. Zeng, T. Chen, and Z. Liu. Synthesizing barrier certificates using neural networks. In _HSCC_, pages 25:1-25:11. ACM, 2020.
* [100] D. Zhi, P. Wang, S. Liu, L. Ong, and M. Zhang. Unifying qualitative and quantitative safety verification of DNN-controlled systems. In _CAV_, Lecture Notes in Computer Science. Springer, 2024.
* [101] D. Zikelic, M. Lechner, T. A. Henzinger, and K. Chatterjee. Learning control policies for stochastic systems with reach-avoid guarantees. In _AAAI_, pages 11926-11935. AAAI Press, 2023.
* [102] D. Zikelic, M. Lechner, A. Verma, K. Chatterjee, and T. A. Henzinger. Compositional policy learning in stochastic control systems with formal guarantees. In _NeurIPS_, 2023.

Details of the SMT Encoding of Quantised Neural Networks

The \(k^{\text{th}}\) hidden layer in our network comprises a fully connected layer followed by a clamp operation that restricts outputs to the range \([0,u]\). This layer has \(h_{k}\) neurons, and the previous layer contains \(h_{k-1}\) neurons. Each neuron \(i\) in the \(k^{\text{th}}\) layer is defined by:

\[x_{i}^{(k)}=\mathrm{Clamp}(y_{i}^{(k)};u),\quad y_{i}^{(k)}=b_{i}^{(k)}+z_{i}^{ (k)},\quad z_{i}^{(k)}=\sum_{j=1}^{h_{k-1}}w_{ij}^{(k-1)}x_{j}^{(k-1)}\] (6)

To facilitate SMT-checking modulo Bit-Vector theory, we quantise the floating-point weights \(w_{ij}\) and biases \(b_{i}\) by multiplying them by \(2^{f}\) and truncating decimals, where \(f\) determines the precision. We define:

\[\tilde{w}_{ij}^{(k)}=\text{trunc}(w_{ij}^{(k)}\cdot 2^{f}),\quad\tilde{b}_{i}^{ (k)}=\text{trunc}(b_{i}^{(k)}\cdot 2^{f})\]

This transformation converts weights from floating-point values in \([0,u]\) to integers in \([0,2^{f}u]\). To ensure consistency between bit-vector and floating-point arithmetic, the output of each bit-vector encoded component should be equivalent to multiplying the floating-point output by \(2^{f}\) and truncating the decimals. To achieve this, the SMT constraints on the bit-vectors are formulated as follows:

\[\bigwedge_{i=1}^{h_{k}}\left(\tilde{x}_{i}^{(k)}=\mathrm{Clamp}(\tilde{y}_{i}^ {(k)};2^{f}u)\wedge\tilde{y}_{i}^{(k)}=\tilde{b}_{i}^{(k)}+\text{ashr}(\tilde{ z}_{i}^{(k)};f)\wedge\tilde{z}_{i}^{(k)}=\sum_{j=1}^{h_{k-1}}\tilde{w}_{ij}^{(k-1)} \tilde{x}_{j}^{(k-1)}\right)\] (7)

Here, \(\tilde{w}_{ij}^{(k-1)}\) and \(\tilde{x}_{j}^{(k-1)}\) are integers in \([0,2^{f}u]\), thus their product remains within \([0,2^{2f}u^{2}]\). The sum \(\tilde{z}_{i}^{(k)}\) aggregates \(h_{k}\) such products, resulting in \([0,2^{2f}u^{2}h_{k}]\). An arithmetic right shift by \(f\) bits scales \(\tilde{z}_{i}^{(k)}\) to \([0,2^{f}u^{2}h_{k}]\) to align with \(\tilde{b}_{i}\) in \([0,2^{f}u]\) (in floating-point arithmetic, the addition would involve values in \([0,u^{2}h_{k}]\) and \([0,u]\)). The clamp operation then restricts \(\tilde{y}_{i}^{(k)}\) to \([0,2^{f}u]\), ensuring consistency with the floating-point arithmetic, where the value would lie within \([0,u]\).

To prevent overflow in the SMT query, we set bit-vector sizes appropriately. Let \(B\) be such that \(2^{B}\geq 2^{f}u\). Each product \(\tilde{w}_{ij}^{(k)}\tilde{x}_{j}^{(k)}\) requires up to \(2B\) bits, and summing \(h_{k}\) terms necessitates additional \(\log h_{k}\) bits.

This encoding is standard in post-training quantisation of fully connected layers [49]. For element-wise multiplication layers, where each input is multiplied by a corresponding weight, we quantise \(w_{i}\cdot x_{i}\) as \(\text{ashr}(\tilde{w}_{i}\cdot\tilde{x}_{i};f)\): Again, \(\tilde{w}_{i}\tilde{x}_{i}\) lies within \([0,2^{2f}u^{2}]\), and the right shift scales it back to \([0,2^{f}u^{2}]\), ensuring consistency with the floating point encoding.

To address the significant slowdown caused by negative numbers in the Bitwuzla SMT-solver during our experiments, we restructured the dot product computation in equation 7. By decomposing the weight vector \(\tilde{w}_{ij}\) into two non-negative components--\(\tilde{w}_{ij}^{+}\) containing positive weights and \(\tilde{w}_{ij}^{-}\) containing the absolute values of negative weights--we expressed the linear layers as

\[\sum_{j=1}^{h}\tilde{w}_{ij}\tilde{x}_{j}=\sum_{j=1}^{h}\tilde{x}_{j}\tilde{w} _{ij}^{+}-\sum_{j=1}\tilde{x}_{j}\tilde{w}_{ij}^{-}\] (8)

This transformation simplified multiplications to involve only non-negative numbers and consolidated negative operations into a single subtraction, speeding up the SMT-check in our experiments.

We further rewrite the SMT encoding--originally involving several \(\tilde{a}\cdot\tilde{x}\) multiplications, where \(\tilde{x}\) is a neuron value and \(\tilde{a}\) is a quantised integer weight--by replacing these multiplications with additions and left shifts. By factorising \(\tilde{a}\) as a sum of powers of two, \(\tilde{a}=\sum_{i=0}^{d}c_{i}\cdot 2^{i}\), where \(c_{i}\in\{0,1\}\), the multiplication can be rewritten as:

\[\tilde{a}\cdot\tilde{x}=\sum_{i=0}^{d}c_{i}\cdot\text{shl}(\tilde{x};i),\]

where \(\text{shl}(\tilde{x};i)\) represents left-shifting \(x\) by \(i\) bits, effectively multiplying \(x\) by \(2^{i}\).

Details of the Case Studies

We consider ten hardware designs in our study. These serve as benchmarks to demonstrate the scalability of our method compared to conventional symbolic model checkers. They are designed to be parameterizable.

The DELAY models generates a positive signal sig after a fixed delay determined by the counter cnt, includes a reset input event that sets cnt to \(0\), and aims to ensure that sig occurs infinitely often under the assumption that the reset event rst is received finitely many times, resulting in the specification FG!rst \(\rightarrow\) GF sig. We further verify FG!rst \(\rightarrow\) GF (sig \(\wedge\) X!sig), to ensure sig doesn't remain triggered forever.

The LCD Controller (LCD) performs a display initialisation setup, then awaits the lcd_enable signal to transition from ready to send for data transmission, and returns to ready after a fixed interval, ensuring FG!cd_enable \(\rightarrow\) GF ready.

Similarly, Thermocouple (Tmcp.) transitions through stages, start, get_data and pause with suitable delay in between, processing SPI transactions and managing transitions based on bus activity, adhering to the specification FG!rst \(\rightarrow\) GF get_data.

The 7-Segment (7-Seg) model alternates between two displays, ensuring each is activated regularly unless reset, as specified by FG!rst \(\rightarrow\) (GF disp = 0 \(\wedge\) GF disp = 1), we also verify a simpler specification FG!rst \(\rightarrow\) GF disp = 1.

The i2c Stretch (i2cS) generates timing signals scl_clk and data_clk based on the ratio of input and bus clock frequencies [90; 92]. It monitors rst and detects the ena signal to manage clock stretching, ensuring FG (!rst \(\&\) ena) \(\rightarrow\) GF stretch.

The Pulse Width Modulation (PWM) system utilises an \(N\)-bit counter to adjust pulse widths dynamically based on input, verifying the low setting of pulse infinitely often as GF!pulse [54].

The VGA Controller (VGA) manages a display interface using horizontal and vertical counters for pixel coordinates, ensuring smooth rendering by adjusting sync pulses and the display enable signal disp_ena, here we confirm FG!rst \(\rightarrow\) GF disp_ena.

The UART Transmitter (UARTt) toggles between wait for preparing data and transmit for sending data, based on tx_ena requests and clk signals, validated by FG!rst \(\rightarrow\) GF wait[90].

The Load-Store (LS) toggles between load and store with a delay implemented by counter which counts from 0 up to N when load then switch to store counting back down to 0, before switching back to load, sig signals a switch from load to store, and we verify FG!rst \(\rightarrow\) GF sig.

Lastly, the Gray Counter (Gray) counts in Gray codes to minimise transition errors by ensuring single bit changes between consecutive counts, with FG!rst \(\rightarrow\) GF sig, indicating regular signalling of complete cycles [97]. Similar to the Delay module, we aim to ensure that the signal sig does not remain triggered indefinitely. We establish this with two distinct specifications FG!rst \(\rightarrow\) GF(sig \(\wedge\) X!sig) and FG!rst \(\rightarrow\) (GFsig \(\wedge\) GF!sig).

## Appendix C Details of the Experimental Results

Table 3 provides the runtimes for each tool on the 194 verification tasks considered in Section 5. These tasks involve verifying each hardware design across an increasing state space, labelled numerically. The "Train Time" column indicates the training duration for the neural network in seconds, while the other columns represent the total runtime for each tool, with the fastest tool time in bold and the rest in grey. In this table, our method uses the configuration described in Section 5, with two hidden layers containing 8 and 5 neurons, respectively. Some of our runtimes are marked with an asterisk (*), indicating that in those cases we obtained counterexamples using the SMT solver; these were used for retraining and then validating the trained network. The reported time includes all SMT checks and training. Table 1 summaries these results by showing the number of tasks successfully completed by each tool for each design. Tasks not marked as _out of time (oot.)_ or _did not train (dnt.)_ are considered successful. Table 3 serves as the basis for computing all statistical observations discussed in Section 1 and Section 5, except those related to the "our best" line in Figure 5(a). All other

components of Figure 6 are derived from this table. By aggregating the duration of each experiment in the table, including OOT instances counted as 5 hours per experiment, the total time amounts to 104 days and 11 hours.

## Appendix D Ablation Study

The network architecture described in Section 3 includes an element-wise multiplication layer and separate trainable parameters associated with each state of the automaton \(\mathcal{A}_{\neg\Phi}\). For most of our experiments in Section 5 and all experiments in Appendix C, we employ a fully connected multilayer perceptron component with two hidden layers containing 8 and 5 neurons, respectively. To experimentally justify our architecture, we perform an ablation study and report the runtimes for different configurations in Table 4. We consider three configurations for the two hidden layers: containing (3, 2) neurons, (5, 3) neurons, and (15, 8) neurons, respectively. We further replace the element-wise multiplication layer with a fully connected layer of the same size, denoted as 'ExtL' for the extra layer. Additionally, we explore providing the global trainable parameters \(\theta\) to all automaton states of the automaton \(\mathcal{A}_{\neg\Phi}\), leading to a monolithic neural ranking function \(V(r,q)\equiv\bar{V}(r,q;\theta)\), where the automaton state \(q\) is given as an additional input, which we denote as 'Mono'.

Given the large number of possible combinations of these modifications, we restrict our ablation study to switching only a single configuration at a time. In Table 4, the column labelled 'Default' contains the results for our original configuration--the runtimes in this column are the same as those under 'Our (8, 5)' in Table 3. Following that, we have one column for each of the three hidden layer configurations, followed by columns for the extra layer ('ExtL'), and the monolithic neural ranking function ('Mono'). The 'our best' line in Figure 5(a) is obtained by selecting the minimum runtime from the 'Default' and the three hidden layer configuration columns for each of the 194 tasks.

From Table 4, we observe that our default configuration succeeds in more cases than the alternative configurations, justifying our choices experimentally. Specifically, the default configuration completes \(93\,\%\) of the tasks, while the three configurations with hidden layers containing (3, 2), (5, 3), and (15, 8) neurons complete \(25\,\%\), \(63\,\%\), and \(74\,\%\) of the tasks, respectively. The extra-layer configuration and the monolithic neural ranking function complete \(24\,\%\), and \(39\,\%\), of the tasks, respectively.

Generally--but not always--when a smaller network succeeds, its runtime is lower than that of the default network. Specifically, among the tasks completed by the (3, 2) neuron configuration, it

\begin{table}
\begin{tabular}{|c|c|c|} \hline Model & LTL Specification & Key Table 3 \\ \hline \multirow{3}{*}{DELAY} & FG!rst \(\rightarrow\) GF sig & Da \\ \cline{2-3}  & FG!rst \(\rightarrow\) GF (sig \(\wedge\) X! sig) & Db \\ \hline LCD Controller & FG!cd\_enable \(\rightarrow\) GF ready & L \\ \hline Thermocouple & FG!rst \(\rightarrow\) GF get\_data & T \\ \hline \multirow{2}{*}{7-Segment} & FG!rst \(\rightarrow\) GF disp = 1 & 7a \\ \cline{2-3}  & FG!rst \(\rightarrow\) (GF disp = 0 \(\wedge\) GF disp = 1) & 7b \\ \hline i2c Stretch & FG (!rst \(\&\) ena) \(\rightarrow\) GF stretch & I \\ \hline Pulse Width Modulation & GF!pulse & P \\ \hline VGA Controller & FG!rst \(\rightarrow\) GF disp\_ena & V \\ \hline UART Transmitter & FG!rst \(\rightarrow\) GF wait & U \\ \hline Load-Store & FG!rst \(\rightarrow\) GF sig & Ls \\ \hline \multirow{3}{*}{Gray Counter} & FG!rst \(\rightarrow\) GF sig & Ga \\ \cline{2-3}  & FG!rst \(\rightarrow\) GF(sig \(\wedge\) X! sig) & Gb \\ \cline{1-1} \cline{2-3}  & FG!rst \(\rightarrow\) (GFsig \(\wedge\) GF! sig) & Gc \\ \hline \end{tabular}
\end{table}
Table 2: Model Name and LTL Specification in our Benchmarkwas faster than the default configuration in \(57\,\%\)of cases; for the (5, 3) neuron configuration, this statistic rises to 94%. Interestingly, this trend does not hold when comparing the (3, 2) and (5, 3) configurations: despite having more neurons, the (5, 3) configuration was faster than the (3, 2) configuration in \(56\,\%\) of tasks. The default configuration not only completes more tasks than the (15, 8) configuration but is also faster on \(97\,\%\) of the tasks successfully completed by the (15, 8) configuration. Notably, among the hidden layer configurations only the (15, 8) configuration succeeds on any of the tasks for the VGA design, labelled as 'V' in the table. In \(67\,\%\) of the tasks that the 'Ext. L' configuration completes, it is faster than the default configuration; this figure rises to \(86\,\%\) for the 'Mono' configuration. While the monolithic neural ranking function ('Mono') fails on 61% of tasks, it surprisingly succeeds on nine out of the ten tasks for the VGA design. Overall, only 5 of the 194 tasks fail under all configurations in the ablation study.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The primary claims of our paper are outlined in the abstract and further detailed in Section 1. Here, we briefly discuss the theoretical aspects of our claims and provide a brief summary of experiments that quantify the scalability of our method.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Our paper includes a subsection on 'Limitations' in Section 5, where we clearly outline our assumptions and justify their reasonableness alongside our theoretical limitations. In the same section, the 'Threats to Validity' subsection validates the scope of our claims by justifying the benchmarks used to compare our method against tools developed with alternative verification methods. Section 5 also presents two case studies, VGA and UART, to discuss the performance limitations of our approach, in comparison to others.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: We provide references for all theoretical results we rely on, i.e., automata-theoretical LTL model checking and fair termination, in Sec. 2
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: Subsections 'Implementation', 'Dataset Generation', and 'Network Hyperparameters' in Section 5 detail the workflow and specify the versions of our dependencies. These subsections clearly outline the hyperparameters and neural network architecture used. Specifically, Section 3 addresses theoretical aspects of the loss function, dataset generation, training procedures, neural network architecture, and the SMT-check problem. In contrast, the aforementioned subsections of Section 5 focus on practical implementation details, together providing sufficient information for implementing neural model checking. Additionally, 'Standard Model Checkers' and 'Industrial Verification Tools' discuss the tool versions we compare against. For additional specific implementation details, our code and benchmarks will be made available.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: Alongside the paper, we include a zip file in accordance with NeurIPS guidelines. This file contains benchmarks, scripts for running our experiments, and a README.md file that offers detailed instructions on how to reproduce our experiments.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyper-parameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Section 5, particularly the 'Network Hyper-parameter' subsection, outlines training details and along with other subsections in the section provides essential information for interpreting the results. Appendix C includes a table with the data used to generate the figures and tables in the main body of the paper.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer:[Yes] Justification: While error bars and confidence intervals are typically not applicable to our experiments that compare formal verification tools--which must be formally correct--we still present statistical data about our benchmarks. This data includes the range of logic gate counts and state space sizes considered for each design. Such metrics are definable for each SystemVerilog file and inherently free from errors. These details are presented in Figure 5. We further discuss potential biases of the benchmark set in the subsection 'Threats to Validity' in Section 5.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The computational resources allocated for our experiments are outlined in Section 5. The Appendix C details the computational time required for each experiment and the cumulative time to run all experiments sequentially. We included all our experiments in the experimental evaluation Section 5, and we discuss the experiments where our tool performs worse than the alternatives in the discussion of its limitations.
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We hereby affirm that all information presented in our research is disclosed with utmost academic integrity. Original works are duly cited and we ensure the reproducibility of our methodology through a detailed description of it throughout the paper, we also provide our implementation of the methodology with all our experiments in the supplementary materials accompanying this paper. Notably, our experiments utilize solely synthetic data, with no human subjects involved, thereby aligning with ethical research standards. Our method aims to enhance the reliability and safety of computer systems. The benchmarks employed are derived from standard algorithms extensively documented in academic textbooks, which are referenced appropriately. Furthermore, we have thoroughly reviewed the NeurIPS Code of Ethics and confirm our strict adherence to it.
10. **Broader Impacts**Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: As discussed in the introduction, it is conceivable that improving the correctness of hardware designs prior to production delivers safer and more reliable devices; not manufacturing buggy silicon reduces waste. We are not aware of a direct path to a negative application.
* **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA]. Justification: Our work contributes to the safety of hardware systems. The designs used in our benchmarks are standard designs, from well-known literature, which are public domain and pose no risks for misuse.
* **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We include the licences of the academic tools ABC and nuXmv. Appropriate references are used.
* **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: We include the source of code of our prototype and our benchmarks as supplementary material of this paper with MIT licence.
* **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Neither crowdsourcing nor human subjects are involved.

[MISSING_PAGE_FAIL:23]

[MISSING_PAGE_FAIL:24]