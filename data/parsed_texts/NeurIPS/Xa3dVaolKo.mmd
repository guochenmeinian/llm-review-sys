# Pure Message Passing Can Estimate

Common Neighbor for Link Prediction

 Kaiwen Dong\({}^{1,2}\) Zhichun Guo\({}^{1,2}\) Nitesh V. Chawla\({}^{1,2}\)

\({}^{1}\)Computer Science and Engineering, University of Notre Dame

\({}^{2}\)Lucy Family Institute for Data and Society, University of Notre Dame

{kdong2, zguo5, nchawla}@nd.edu

###### Abstract

Message Passing Neural Networks (MPNNs) have emerged as the _de facto_ standard in graph representation learning. However, when it comes to link prediction, they are not always superior to simple heuristics such as Common Neighbor (CN). This discrepancy stems from a fundamental limitation: while MPNNs excel in node-level representation, they stumble with encoding the joint structural features essential to link prediction, like CN. To bridge this gap, we posit that, by harnessing the orthogonality of input vectors, pure message-passing can indeed capture joint structural features. Specifically, we study the proficiency of MPNNs in approximating CN heuristics. Based on our findings, we introduce the Message Passing Link Predictor (MPLP), a novel link prediction model. MPLP taps into quasi-orthogonal vectors to estimate link-level structural features, all while preserving the node-level complexities. We conduct experiments on benchmark datasets from various domains, where our method consistently outperforms the baseline methods, establishing new state-of-the-arts.

## 1 Introduction

Link prediction is a cornerstone task in the field of graph machine learning, with broad-ranging implications across numerous industrial applications. From identifying potential new acquaintances on social networks [1] to predicting protein interactions [2], from enhancing recommendation systems [3] to completing knowledge graphs [4], the impact of link prediction is felt across diverse domains. Recently, with the advent of Graph Neural Networks (GNNs) [5] and more specifically, Message-Passing Neural Networks (MPNNs) [6], these models have become the primary tools for tackling link prediction tasks. Despite the resounding success of MPNNs in the realm of node and graph classification tasks [5, 7, 8, 9], it is intriguing to note that their performance in link prediction does not always surpass that of simpler heuristic methods [10].

Zhang et al. [11] highlights the limitations of GNNs/MPNNs for link prediction tasks arising from its intrinsic property of permutation invariance. Owing to this property, isomorphic nodes invariably receive identical representations. This poses a challenge when attempting to distinguish links whose endpoints are isomorphic nodes. As illustrated in Figure 0(a), nodes \(v_{1}\) and \(v_{3}\) share a Common Neighbor \(v_{2}\), while nodes \(v_{1}\) and \(v_{5}\) do not. Ideally, due to their disparate local structures, these two links \((v_{1},v_{3})\) and \((v_{1},v_{5})\) should receive distinct predictions. However, the permutation invariance of MPNNs results in identical representations for nodes \(v_{3}\) and \(v_{5}\), leading to identical predictions for the two links. As Zhang et al. [11] asserts, such node-level representation, even with the most expressive MPNNs, **cannot** capture structural link representation such as Common Neighbors (CN), a critical aspect of link prediction.

In this work, we posit that the pure Message Passing paradigm [6] can indeed capture structural link representation by exploiting orthogonality within the vector space. We begin by presenting amotivating example, considering a non-attributed graph as depicted in Figure 0(a). In order to fulfill the Message Passing's requirement for node vectors as input, we assign a one-hot vector to each node \(v_{i}\), such that the \(i\)-th dimension has a value of one, with the rest set to zero. These vectors, viewed as _signatures_ rather than mere permutation-invariant node representations, can illuminate pairwise relationships. Subsequently, we execute a single iteration of message passing as shown in Figure 0(b), updating each node's vector by summing the vector of its neighbors. This process enables us to compute CN for any node pair by taking the inner product of the vectors of the two target nodes.

At its core, this naive method employs an orthonormal basis as the node signatures, thereby ensuring that the inner product of distinct nodes' signatures is consistently zero. While this approach effectively computes CN, its scalability poses a significant challenge, given that its space complexity is quadratically proportional to the size of the graph. To overcome this, we draw inspiration from DotHash [12] and capitalize on the premise that the family of vectors almost orthogonal to each other swells exponentially, even with just linearly scaled dimensions [13]. Instead of relying on the orthogonal basis, we can propagate these quasi-orthogonal (QO) vectors and utilize the inner product to estimate the joint structural information of any node pair.

In sum, our paper presents several pioneering advances in the realm of GNNs for link prediction:

* We are the first, both empirically and theoretically, to delve into the proficiency of GNNs in approximating heuristic predictors like CN for link prediction. This uncovers a previously uncharted territory in GNN research.
* Drawing upon the insights gleaned from GNNs' capabilities in counting CN, we introduce **MPLP**, a novel link prediction model. Uniquely, MPLP discerns joint structures of links and their associated substructures within a graph, setting a new paradigm in the field.
* Our empirical investigations provide compelling evidence of MPLP's dominance. Benchmark tests reveal that MPLP not only holds its own but outstrips state-of-the-art models in link prediction performance.

## 2 Preliminaries and Related Work

Notations.Consider an undirected graph \(G=(V,E,\bm{X})\), where \(V\) represents the set of nodes with cardinality \(n\), indexed as \(\{1,\dots,n\}\), \(E\subseteq V\times V\) denotes the observed set of edges, and \(\bm{X}_{i,:}\in\mathbb{R}^{F_{x}}\) encapsulates the attributes associated with node \(i\). Additionally, let \(\mathcal{N}_{v}\) signify the neighborhood of a node \(v\), that is \(\mathcal{N}_{v}=\{u|\text{SPD}(u,v)=1\}\) where the function \(\text{SPD}(\cdot,\cdot)\) measures the shortest path distance between two nodes. Furthermore, the node degree of \(v\) is given by \(d_{v}=|\mathcal{N}_{v}|\). To generalize, we introduce the shortest path neighborhood \(\mathcal{N}_{v}^{s}\), representing the set of nodes that are \(s\) hops away from node \(v\), defined as \(\mathcal{N}_{v}^{s}=\{u|\text{SPD}(u,v)=s\}\).

Link predictions.Alongside the observed set of edges \(E\), there exists an unobserved set of edges, which we denote as \(E_{c}\subseteq V\times V\setminus E\). This unobserved set encompasses edges that are either absent from the original observation or are anticipated to materialize in the future within the graph \(G\)

Figure 1: (a) Isomorphic nodes result in identical MPNN node representation, making it impossible to distinguish links such as \((v_{1},v_{3})\) and \((v_{1},v_{5})\) based on these representations. (b) MPNN counts Common Neighbor through the inner product of neighboring nodesâ€™ one-hot representation.

Consequently, we can formulate the link prediction task as discerning the unobserved set of edges \(E_{c}\). Heuristics link predictors include Common Neighbor (CN) [1], Adamic-Adar index (AA) [14], and Resource Allocation (RA) [15]. CN is simply counting the cardinality of the common neighbors, while AA and RA count them weighted to reflect their relative importance as a common neighbor.

\[\text{CN}(u,v)=\sum_{k\in\mathcal{N}_{u}\bigcap\mathcal{N}_{v}}1;\ \ \text{AA}(u,v)=\sum_{k\in\mathcal{N}_{u} \bigcap\mathcal{N}_{v}}\frac{1}{\log d_{k}};\ \ \text{RA}(u,v)=\sum_{k\in\mathcal{N}_{u} \bigcap\mathcal{N}_{v}}\frac{1}{d_{k}}.\] (1)

Though heuristic link predictors are effective across various graph domains, their growing computational demands clash with the need for low latency. To mitigate this, approaches like ELPH [16] and DotHash [12] propose using estimations rather than exact calculations for these predictors. Our study, inspired by these works, seeks to further refine techniques for efficient link predictions. A detailed comparison with related works and our method is in Appendix A.

GNNs for link prediction.The advent of graphs incorporating node attributes has caused a significant shift in research focus toward methods grounded in GNNs. Most practical GNNs follow the paradigm of the Message Passing [6]. It can be formulated as:

\[\bm{m}_{v}^{(l)}=\text{AGGREGATE}\left(\{\bm{h}_{v}^{(l)},\bm{h}_{u}^{(l)}, \forall u\in\mathcal{N}_{v}\}\right),\ \ \bm{h}_{v}^{(l+1)}=\text{UPDATE}\left(\{\bm{h}_{v}^{(l)},\bm{m}_{v}^{(l)}\} \right),\] (2)

where \(\bm{h}_{v}^{(l)}\) represents the vector of node \(v\) at layer \(l\) and \(\bm{h}_{v}^{(0)}=\bm{X}_{v,:}\). For simplicity, we use \(\bm{h}_{v}\) to represent the node vector at the last layer. The specific choice of the neighborhood aggregation function, \(\text{AGGREGATE}(\cdot)\), and the updating function, \(\text{UPDATE}(\cdot)\), dictates the instantiation of the GNN model, with different choices leading to variations of model architectures. In the context of link prediction tasks, the GAE model [17] derives link representation, \(\bm{h}(i,j)\), as a Hadamard product of the target node pair representations, \(\bm{h}_{(i,j)}=\bm{h}_{i}\odot\bm{h}_{j}\). Despite its seminal approach, the SEAL model [18], which labels nodes based on proximity to target links and then performs message-passing for each target link, is hindered by computational expense, limiting its scalability. Efficient alternatives like ELPH [16] estimate node labels, while NCNC [19] directly learns edgewise features by aggregating node representations of common neighbors.

## 3 Can Message Passing count Common Neighbor?

In this section, we delve deep into the potential of MPNNs for heuristic link predictor estimation. We commence with an empirical evaluation to recognize the proficiency of MPNNs in approximating link predictors. Following this, we unravel the intrinsic characteristics of 1-layer MPNNs, shedding light on their propensity to act as biased estimators for heuristic link predictors and proposing an unbiased alternative. Ultimately, we cast light on how successive rounds of message passing can estimate the number of walks connecting a target node pair with other nodes in the graph. All proofs are provided in Appendix G.

### Estimation via Mean Squared Error Regression

To explore the capacity of MPNNs in capturing the overlap information inherent in heuristic link predictors, such as CN, AA and RA, we conduct an empirical investigation, adopting the GAE

Figure 2: GNNs estimate CN, AA and RA via MSE regression, using the mean value as a Baseline. Lower values are better.

framework [17] with GCN [5] and SAGE [7] as representative encoders. SEAL [18], known for its proven proficiency in capturing heuristic link predictors, serves as a benchmark in our comparison. Additionally, we select a non-informative baseline estimation, simply using the mean of the heuristic link predictors on the training sets. The datasets comprise eight non-attributed graphs (more details in Section 5). Given that GNN encoders require node features for initial representation, we have to generate such features for our non-attributed graphs. We achieved this by sampling from a high-dimensional Gaussian distribution with a mean of \(0\) and standard deviation of \(1\). Although one-hot encoding is frequently employed for feature initialization on non-attributed graphs, we choose to forgo this approach due to the associated time and space complexity.

To evaluate the ability of GNNs to estimate CN information, we adopt a training procedure analogous to a conventional link prediction task. However, we reframe the task as a regression problem aimed at predicting heuristic link predictors, rather than a binary classification problem predicting link existence. This shift requires changing the objective function from cross-entropy to Mean Squared Error (MSE). Such an approach allows us to directly observe GNNs' capacity to approximate heuristic link predictors.

Our experimental findings, depicted in Figure 2, reveal that GCN and SAGE both display an ability to estimate heuristic link predictors, albeit to varying degrees, in contrast to the non-informative baseline estimation. More specifically, GCN demonstrates a pronounced aptitude for estimating RA and nearly matches the performance of SEAL on datasets such as C.ele, Yeast, and PB. Nonetheless, both GCN and SAGE substantially lag behind SEAL in approximating CN and AA. In the subsequent section, we delve deeper into the elements within the GNN models that facilitate this approximation of link predictors while also identifying factors that impede their accuracy.

### Estimation capabilities of GNNs for link predictors

GNNs exhibit the capability of estimating link predictors. In this section, we aim to uncover the mechanisms behind these estimations, hoping to offer insights that could guide the development of more precise and efficient methods for link prediction. We commence with the following theorem:

**Theorem 3.1**.: _Let \(G=(V,E)\) be a non-attributed graph and consider a 1-layer GCN/SAGE. Define the input vectors \(\bm{X}\in\mathbb{R}^{N\times F}\) initialized randomly from a zero-mean distribution with standard deviation \(\sigma_{node}\). Additionally, let the weight matrix \(\bm{W}\in\mathbb{R}^{F^{\prime}\times F}\) be initialized from a zero-mean distribution with standard deviation \(\sigma_{weight}\). After performing message passing, for any pair of nodes \(\{(u,v)|(u,v)\in V\times V\setminus E\}\), the expected value of their inner product is given by:_

\[\text{GCN: }\mathbb{E}(\bm{h}_{u}\cdot\bm{h}_{v})=\frac{C}{\sqrt{\hat{d}_{u} \hat{d}_{v}}}\sum_{k\in\mathcal{N}_{u}\bigcap\mathcal{N}_{v}}\frac{1}{\hat{d} _{k}};\quad\text{SAGE: }\mathbb{E}(\bm{h}_{u}\cdot\bm{h}_{v})=\frac{C}{\sqrt{d_{u} \hat{d}_{v}}}\sum_{k\in\mathcal{N}_{u}\bigcap\mathcal{N}_{v}}1,\]

_where \(\hat{d}_{v}=d_{v}+1\) and \(C=\sigma_{node}^{2}\sigma_{weight}^{2}FF^{\prime}\)._

The theorem suggests that given proper initialization of input vectors and weight matrices, MPNN-based models, such as GCN and SAGE, can adeptly approximate heuristic link predictors. This makes them apt for encapsulating joint structural features of any node pair. Interestingly, SAGE predominantly functions as a CN estimator, whereas the aggregation function in GCN grants it the ability to weigh the count of common neighbors in a way similar to RA. This particular trait of GCN is evidenced by its enhanced approximation of RA, as depicted in Figure 2.

Quasi-orthogonal vectors.The GNN's capability to approximate heuristic link predictors is primarily grounded in the properties of their input vectors in a linear space. When vectors are sampled from a high-dimensional linear space, they tend to be quasi-orthogonal, implying that their inner product is nearly \(0\) w.h.p. With message-passing, these QO vectors propagate through the graph, yielding in a linear combination of QO vectors at each node. The inner product between pairs of QO vector sets essentially echoes the norms of shared vectors while nullifying the rest. Such a trait enables GNNs to estimate CN through message-passing. A key advantage of QO vectors, especially when compared with orthonormal basis, is their computational efficiency. For a modest linear increment in space dimensions, the number of QO vectors can grow exponentially, given an acceptable margin of error [13]. An intriguing observation is that the orthogonality of QO vectors remains intact even after GNNs undergo linear transformations post message-passing, attributed to the randomized weight matrix initialization. This mirrors the dimension reduction observed in random projection [20].

Limitations.While GNNs manifest a marked ability in estimating heuristic link predictors, they are not unbiased estimators and can be influenced by factors such as node pair degrees, thereby compromising their accuracy. Another challenge when employing such MPNNs is their limited generalization to unseen nodes. The neural networks, exposed to randomly generated vectors, may struggle to transform newly added nodes in the graph with novel random vectors. This practice also violates the permutation-invariance principle of GNNs when utilizing random vectors as node representation. It could strengthen generalizability if we regard these randomly generated vectors as signatures of the nodes, instead of their node features, and circumvent the use of MLPs for them.

Unbiased estimator.Addressing the biased element in Theorem 3.1, we propose the subsequent instantiation for the message-passing functions:

\[\bm{h}_{v}^{(l+1)}=\sum_{u\in\mathcal{N}_{v}}\bm{h}_{u}^{(l)}.\] (3)

Such an implementation aligns with the SAGE model that employs sum aggregation devoid of self-node propagation. This methodology also finds mention in DotHash [12], serving as a cornerstone for our research. With this kind of message-passing design, the inner product of any node pair signatures can estimate CN impartially:

**Theorem 3.2**.: _Let \(G=(V,E)\) be a graph, and let the vector dimension be given by \(F\in\mathbb{N}_{+}\). Define the input vectors \(\bm{X}=(X_{i,j})\), which are initialized from a random variable x having a mean of \(0\) and a standard deviation of \(\frac{1}{\sqrt{F}}\). Using the 1-layer message-passing in Equation 3, for any pair of nodes \(\{(u,v)|(u,v)\in V\times V\}\), the expected value and variance of their inner product are:_

\[\mathbb{E}(\bm{h}_{u}\cdot\bm{h}_{v}) =\text{CN}(u,v);\] \[\mathrm{Var}(\bm{h}_{u}\cdot\bm{h}_{v}) =\frac{1}{F}\left(d_{u}d_{v}+\text{CN}(u,v)^{2}-2\text{CN}(u,v) \right)+F\mathrm{Var}\big{(}\mathtt{x}^{2}\big{)}\text{CN}(u,v).\]

Though this estimator provides an unbiased estimate for CN, its accuracy can be affected by its variance. Specifically, DotHash recommends selecting a distribution for input vector sampling from vertices of a hypercube with unit length, which curtails variance given that \(\mathrm{Var}\big{(}\mathtt{x}^{2}\big{)}=0\). However, the variance influenced by the graph structure isn't adequately addressed, and this issue will be delved into in Section 4.

Orthogonal node attributes.Both Theorem 3.1 and Theorem 3.2 underscore the significance of quasi orthogonality in input vectors, enabling message-passing to efficiently count CN. Intriguingly, in most attributed graphs, node attributes, often represented as bag-of-words [21], exhibit inherent orthogonality. This brings forth a critical question: In the context of link prediction, do GNNs primarily approximate neighborhood overlap, sidelining the intrinsic value of node attributes? We earmark this pivotal question for in-depth empirical exploration in Appendix E, where we find that random vectors as input to GNNs can catch up with or even outperform node attributes.

### Multi-layer message passing

Theorem 3.2 elucidates the estimation of CN based on a single iteration of message passing. This section explores the implications of multiple message-passing iterations and the properties inherent to the iteratively updated node signatures. We begin with a theorem delineating the expected value of the inner product for two nodes' signatures derived from any iteration of message passing:

**Theorem 3.3**.: _Under the conditions defined in Theorem 3.2, let \(\bm{h}_{u}^{(l)}\) denote the vector for node \(u\) after the \(l\)-th message-passing iteration. We have:_

\[\mathbb{E}\Big{(}\bm{h}_{u}^{(p)}\cdot\bm{h}_{v}^{(q)}\Big{)}=\sum_{k\in V}| \text{walks}^{(p)}(k,u)||\text{walks}^{(q)}(k,v)|,\]

_where \(|\text{walks}^{(l)}(u,v)|\) counts the number of length-\(l\) walks between nodes \(u\) and \(v\)._

This theorem posits that the message-passing procedure computes the number of walks between the target node pair and all other nodes. In essence, each message-passing trajectory mirrors the path of the corresponding walk. As such, \(\bm{h}_{u}^{(l)}\) aggregates the initial QO vectors originating from nodes reachable by length-\(l\) walks from node \(u\). In instances where multiple length-\(l\) walks connect node \(k\) to \(u\), the associated QO vector \(\bm{X}_{k,:}\) is incorporated into the sum \(|\text{walks}^{(l)}(k,u)|\) times.

One might surmise a paradox, given that message-passing calculates the number of walks, not nodes. However, in a simple graph devoid of self-loops, where at most one edge can connect any two nodes, it is guaranteed that \(|\text{walks}^{(1)}(u,v)|=1\) iff \(\text{SPD}(u,v)=1\). Consequently, the quantity of length-\(1\) walks to a target node pair equates to CN, a first-order heuristic. It's essential to recognize, however, that \(|\text{walks}^{(l)}(u,v)|\geq 1\) only implies \(\text{SPD}(u,v)\leq l\). This understanding becomes vital when employing message-passing for estimating the local structure of a target node pair in Section 4.

## 4 Method

In this section, we introduce our novel link prediction model, denoted as **MPL**. Distinctively designed, MPLP leverages the pure essence of the message-passing mechanism to adeptly learn joint structural features of the target node pairs.

Node representation.While MPLP is specifically designed for its exceptional structural capture, it also embraces the inherent attribute associations of graphs that speak volumes about individual node characteristics. To fuse the attributes (if they exist in the graph) and structures, MPLP begins with a GNN, utilized to encode node \(u\)'s representation: \(\text{GNN}(u)\in\mathbb{R}^{F_{x}}\). This node representation will be integrated into the structural features when constructing the QO vectors. Importantly, this encoding remains flexible, permitting the choice of any node-level GNN.

### QO vectors construction

Probabilistic hypercube sampling.Though deterministic avenues for QO vector construction are documented [22; 23], our preference leans toward probabilistic techniques for their inherent simplicity. We inherit the sampling paradigm from DotHash [12], where each node \(k\) is assigned with a node signature \(\bm{h}_{k}^{(0)}\), acquired via random sampling from the vertices of an \(F\)-dimensional hypercube with unit vector norms. Consequently, the sampling space for \(\bm{h}_{k}^{(0)}\) becomes \(\{-1/\sqrt{F},1/\sqrt{F}\}^{F}\).

Harnessing One-hot hubs for variance reduction.The stochastic nature of our estimator brings along an inevitable accompaniment: variance. Theorem 3.2 elucidates that a graph's topology can augment estimator variance, irrespective of the chosen QO vector distribution. At the heart of this issue is the imperfectness of quasi-orthogonality. While a pair of vectors might approach orthogonality, the same cannot be confidently said for the subspaces spanned by larger sets of QO vectors.

Capitalizing on the empirical observation that real-world graphs predominantly obey the power-law distribution [24], we propose a strategy to control variance. Leveraging the prevalence of high-degree nodes--or _hubs_--we designate unique one-hot vectors for the foremost hubs. Consider the graph's top-\(b\) hubs; while other nodes draw their QO vectors from a hypercube \(\{-1/\sqrt{F-b},1/\sqrt{F-b}\}^{F-b}\diagdown\{0\}^{b}\), these hubs are assigned one-hot vectors from \(\{0\}^{F-b}\diagdown\{0,1\}^{b}\), reserving a distinct subspace of the linear space to safeguard orthogonality. Note that when new nodes are added, their QO vectors are sampled the same way as the non-hub nodes, which can ensure a tractable computation complexity.

Norm rescaling to facilitate weighted counts.Theorem 3.1 alludes to an intriguing proposition: the estimator's potential to encapsulate not just CN, but also RA. Essentially, RA and AA are nuanced heuristics translating to weighted enumerations of shared neighbors, based on their node degrees. In Theorem 3.2, such counts are anchored by vector norms during dot products. MPLP enhances this count methodology by rescaling node vector norms, drawing inspiration from previous works [12; 25].

Figure 3: Representation of the target link \((u,v)\) within our model (MPLP), with nodes color-coded based on their distance from the target link.

This rescaling is determined by the node's representation, \(\text{GNN}(u)\), and its degree \(d_{u}\). The rescaled vector is formally expressed as:

\[\tilde{\bm{h}}_{k}^{(0)}=f(\text{GNN}(k)||[d_{k}])\cdot\bm{h}_{k}^{(0)},\] (4)

where \(f\colon\mathbb{R}^{F_{s}+1}\to\mathbb{R}\) is an MLP mapping the node representation and degree to a scalar, enabling the flexible weighted count paradigm.

### Structural feature estimations

Node label estimation.The estimator in Theorem 3.2 can effectively quantify CN. Nonetheless, solely relying on CN fails to encompass diverse topological structures embedded within the local neighborhood. To offer a richer representation, we turn to Distance Encoding (DE) [26]. DE acts as an adept labeling tool [11], demarcating nodes based on their shortest-path distances relative to a target node pair. For a given pair \((u,v)\), a node \(k\) belongs to a node set \(\text{DE}(p,q)\) iff \(\text{SPD}(u,k)=p\) and \(\text{SPD}(v,k)=q\). Unlike its usage as node labels, we opt to enumerate these labels, producing a link feature defined by \(\#(p,q)=|\text{DE}(p,q)|\). Our model adopts a philosophy akin to ELPH [16], albeit with a distinct node-estimation mechanism.

Returning to Theorem 3.3, we recall that message-passing as in Equation 3 essentially corresponds to walks. Our ambition to enumerate nodes necessitates a single-layer message-passing alteration, reformulating Equation 3 to:

\[\bm{\eta}_{v}^{(s)}=\sum_{k\in\mathcal{N}_{v}^{s}}\tilde{\bm{h}}_{k}^{(0)}.\] (5)

Here, \(\mathcal{N}_{v}^{s}\) pinpoints \(v\)'s shortest-path neighborhoods distanced by the shortest-path \(s\). This method sidesteps the duplication dilemma highlighted in Theorem 3.3, ensuring that \(\bm{\eta}_{v}^{(s)}\) aggregates at most one QO vector per node. Similar strategies are explored in [27; 28].

For a tractable computation, we limit the largest shortest-path distance as \(r\geq max(p,q)\). Consequently, to capture the varied proximities of nodes to the target pair \((u,v)\), we can deduce:

\[\#(p,q)=\begin{cases}\mathbb{E}\Big{(}\bm{\eta}_{u}^{(p)}\cdot\bm{\eta}_{v}^{ (q)}\Big{)},&r\geq p,q\geq 1\\ |\mathcal{N}_{v}^{q}|-\sum_{1\leq s\leq r}\#(s,q),&p=0\\ |\mathcal{N}_{u}^{p}|-\sum_{1\leq s\leq r}\#(p,s),&q=0\end{cases}\] (6)

Concatenating the resulting estimates yields the expressive structural features of MPLP.

Shortcut removal.The intricately designed structural features improve the expressiveness of MPLP. However, this augmented expressiveness introduces susceptibility to distribution shifts during link prediction tasks [29]. Consider a scenario wherein the neighborhood of a target node pair contains a node \(k\). Node \(k\) resides a single hop away from one of the target nodes but requires multiple steps to connect with the other. When such a target node pair embodies a positive instance in the training data (indicative of an existing link), node \(k\) can exploit both the closer target node and the link between the target nodes as a shortcut to the farther one. This dynamic ensures that for training-set positive instances, the maximum shortest-path distance from any neighboring node to the target pair is constrained to the smaller distance increased by one. This can engender a discrepancy in distributions between training and testing phases, potentially diminishing the model's generalization capability.

To circumvent this pitfall, we adopt an approach similar to preceding works [18; 30; 19; 31]. Specifically, we exclude target links from the original graph during each training batch, as shown by the dash line in Figure 3. This maneuver ensures these links are not utilized as shortcuts, thereby preserving the fidelity of link feature construction.

Feature integration for link prediction.Having procured the structural features, we proceed to formulate the encompassing link representation for a target node pair \((u,v)\) as:

\[\bm{h}_{(u,v)}=(\text{GNN}(u)\odot\text{GNN}(v))||[\#(1,1),\dots,\#(r,r)],\]

which can be fed into a classifier for a link prediction between nodes \((u,v)\).

### More scalable estimation

MPLP estimates the cardinality of the distinct node sets with different distances relative to target node pairs in Equation 6. However, this operation requires a preprocessing step to construct the shortest-path neighborhoods \(\mathcal{N}_{v}^{s}\) for \(s\leq r\), which can cause computational overhead on large-scale graph benchmarks. To overcome this issue, we simplify the structural feature estimations as:

\[\#(p,q)=\mathbb{E}\Big{(}\tilde{\bm{h}}_{u}^{(p)}\cdot\tilde{\bm{h}}_{v}^{(q)} \Big{)},\] (7)

where \(\tilde{\bm{h}}_{v}^{(l+1)}=\sum_{u\in\mathcal{N}_{v}}\tilde{\bm{h}}_{u}^{(l)}\) follows the message-passing defined in Equation 3. Similar to common GNNs, such a message-passing only requires the one-hop neighborhood \(\mathcal{N}_{v}\), which is provided in a format of adjacency matrices/lists by most graph datasets. Therefore, we can substitute the structural features of MPLP with the estimation in Equation 7. We denote such a model with walk-level features as MPLP+.

### Triangular substructure estimation

Our method, primarily designed to encapsulate the local structure of a target node pair, unexpectedly exhibits the capacity for estimating the count of triangles linked to individual nodes. This capability, traditionally considered beyond the reach of GNNs, marks a significant advancement in the field [32]. Although triangle counting is less directly relevant in the context of link prediction, the implications of this capability are noteworthy. To maintain focus, we relegate the detailed discussion on pure message-passing for effective triangle counting to Appendix C.

\begin{table}
\begin{tabular}{l c c c c c c c c} \hline \hline  & **USAir** & **NS** & **PB** & **Yeast** & **Cele** & **Power** & **Router** & **E.coli** \\ Metric & Hits@50 & Hits@50 & Hits@50 & Hits@50 & Hits@50 & Hits@50 & Hits@50 & Hits@50 \\ \hline
**CN** & \(80.52_{\pm 4.07}\) & \(74.00_{\pm 1.98}\) & \(37.22_{\pm 3.52}\) & \(72.60_{\pm 3.85}\) & \(47.67_{\pm 10.87}\) & \(11.57_{\pm 0.55}\) & \(9.38_{\pm 1.05}\) & \(51.74_{\pm 2.70}\) \\
**AA** & \(85.51_{\pm 2.25}\) & \(74.00_{\pm 1.98}\) & \(39.48_{\pm 3.53}\) & \(73.62_{\pm 1.01}\) & \(58.34_{\pm 2.88}\) & \(11.57_{\pm 0.55}\) & \(9.38_{\pm 1.05}\) & \(68.13_{\pm 1.61}\) \\
**RA** & \(85.95_{\pm 3.83}\) & \(74.00_{\pm 1.98}\) & \(38.94_{\pm 4.54}\) & \(73.62_{\pm 1.01}\) & \(61.47_{\pm 4.59}\) & \(11.57_{\pm 0.55}\) & \(9.38_{\pm 1.05}\) & \(74.45_{\pm 0.55}\) \\ \hline
**GCN** & \(73.29_{\pm 4.70}\) & \(78.32_{\pm 2.52}\) & \(37.32_{\pm 6.69}\) & \(73.15_{\pm 2.41}\) & \(40.68_{\pm 5.45}\) & \(15.40_{\pm 2.90}\) & \(42.42_{\pm 4.59}\) & \(61.02_{\pm 21.91}\) \\
**SAGE** & \(83.81_{\pm 3.09}\) & \(56.62_{\pm 9.41}\) & \(47.26_{\pm 2.53}\) & \(71.06_{\pm 5.12}\) & \(58.97_{\pm 4.77}\) & \(6.89_{\pm 9.05}\) & \(42.25_{\pm 4.32}\) & \(75.60_{\pm 2.40}\) \\ \hline
**SEAL** & \(90.47_{\pm 3.00}\) & \(86.59_{\pm 3.03}\) & \(44.47_{\pm 2.86}\) & \(83.92_{\pm 1.17}\) & \(64.80_{\pm 2.43}\) & \(31.46_{\pm 3.25}\) & \(61.00_{\pm 10.10}\) & \(83.42_{\pm 1.01}\) \\
**No-GNN** & \(86.07_{\pm 1.96}\) & \(85.34_{\pm 3.92}\) & \(40.44_{\pm 1.89}\) & \(83.14_{\pm 0.73}\) & \(63.22_{\pm 4.32}\) & \(21.98_{\pm 4.62}\) & \(42.81_{\pm 4.13}\) & \(73.76_{\pm 1.94}\) \\
**ELPH** & \(87.04_{\pm 1.98}\) & \(88.49_{\pm 1.24}\) & \(46.91_{\pm 2.21}\) & \(82.74_{\pm 1.19}\) & \(64.45_{\pm 3.91}\) & \(26.61_{\pm 1.73}\) & \(61.07_{\pm 3.06}\) & \(75.25_{\pm 1.44}\) \\
**NCNC** & \(86.16_{\pm 1.77}\) & \(83.18_{\pm 3.17}\) & \(46.85_{\pm 3.18}\) & \(82.00_{\pm 0.97}\) & \(60.49_{\pm 5.09}\) & \(23.28_{\pm 1.55}\) & \(52.45_{\pm 8.77}\) & \(83.94_{\pm 1.57}\) \\ \hline
**MPLP** & \(\bm{92.12_{\pm 2.21}}\) & \(\bm{90.02_{\pm 2.04}}\) & \(\bm{52.55_{\pm 2.90}}\) & \(\bm{85.36_{\pm 10.72}}\) & \(\bm{74.28_{\pm 2.09}}\) & \(\bm{32.66_{\pm 3.58}}\) & \(\bm{64.68_{\pm 3.14}}\) & \(\bm{86.11_{\pm 0.83}}\) \\
**MPLP+** & \(\bm{91.24_{\pm 2.11}}\) & \(\bm{88.91_{\pm 2.04}}\) & \(\bm{51.81_{\pm 2.39}}\) & \(\bm{84.95_{\pm 0.66}}\) & \(\bm{72.73_{\pm 2.99}}\) & \(\bm{31.86_{\pm 2.59}}\) & \(60.94_{\pm 2.51}\) & \(\bm{87.07_{\pm 0.89}}\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Link prediction results on non-attributed benchmarks. The format is average score \(\pm\) standard deviation. The top three models are colored by **First**, **Second**, **Third**.

\begin{table}
\begin{tabular}{l c c c c c c c} \hline \hline  & **CS** & **Physics** & **Computers** & **Photo** & **Collab** & **PPA** & **Clation2** \\ Metric & Hits@50 & Hits@50 & Hits@50 & Hits@50 & Hits@50 & Hits@50 & Hits@100 & MRR \\ \hline
**CN** & \(51.04_{\pm 15.56}\) & \(61.46_{\pm 6.12}\) & \(21.95_{\pm 2.00}\) & \(29.33_{\pm 2.74}\) & \(61.37_{\pm 0.00}\) & \(27.65_{\pm 0.00}\) & \(51.47_{\pm 0.00}\) \\
**AA** & \(68.26_{\pm 1.28}\) & \(70.98_{\pm 1.96}\) & \(26.96_{\pm 2.08}\) & \(37.35_{\pm 2.65}\) & \(64.35_{\pm 0.00}\) & \(32.45_{\pm 0.00}\) & \(51.89_{\pm 0.00}\) \\
**RA** & \(68.25_{\pm 1.29}\) & \(72.29_{\pm 1.09}\) & \(28.05_{\pm 1.59}\) & \(40.77_{\pm 3.41}\) & \(64.00_{\pm 0.00}\) & \(49.33_{\pm 0.00}\) & \(51.98_{\pm 0.00}\) \\ \hline
**GCN** & \(66.00_{\pm 2.90}\) & \(73.71_{\pm 1.28}\) & \(22.95_{\pm 1.05}\) & \(28.14_{\pm 1.87}\) & \(35.32_{\pm 2.39}\) & \(18.67_{\pm 0.00}\) & \(84.74_{\pm 0.21}\) \\
**SAGE** & \(57.79_{\pm 1.82}\) & \(74.10_{\pm 2.51}\)

## 5 Experiments

Datasets, baselines and experimental setupWe conduct evaluations across a diverse spectrum of 15 graph benchmark datasets, which include 8 non-attributed and 7 attributed graphs 2. It also includes three datasets from OGB [10] with predefined train/test splits. In the absence of predefined splits, links are partitioned into train, validation, and test sets using a 70-10-20 percent split. Our comparison spans three categories of link prediction models: (1) heuristic-based methods encompassing CN, AA, and RA; (2) node-level models like GCN and SAGE; and (3) link-level models, including SEAL, Neo-GNN [25], ELPH [16], and NCNC [19]. Each experiment is conducted 10 times, with the average score and standard deviations reported. The evaluation metrics are aligned with the standard metrics for OGB datasets, and we utilize Hits@50 for the remaining datasets. We limit the number of hops \(r=2\), which results in a good balance of performance and efficiency. A comprehensive description of the experimental setup is available in Appendix D.

Footnote 2: Our code is publicly available at https://github.com/Barcavin/efficient-node-labelling.

ResultsPerformance metrics are shown in Tables 1 and 2. Our methods, MPLP and MPLP+, demonstrate superior performance, surpassing baseline models across all evaluated benchmarks by a significant margin. Notably, MPLP tends to outperform MPLP+ in various benchmarks, suggesting that node-level structural features (Equation 6) might be more valuable for link prediction tasks than the walk-level features (Equation 7). In large-scale graph benchmarks such as PPA and Citation2, MPLP+ sets new benchmarks, establishing state-of-the-art results. For other datasets, our methods

Figure 4: Evaluation of inference time on large-scale OGB datasets. The inference time encompasses the entire cycle within a full-batch inference.

\begin{table}
\begin{tabular}{c|c c c c c c} \hline \hline \multirow{2}{*}{Models} & \multicolumn{2}{c}{**Collab**} & \multicolumn{2}{c}{**PPA**} & \multicolumn{2}{c}{**Citation2**} \\  & MRR & Hits@20 & MRR & Hits@20 & MRR & Hits@20 \\ \hline
**CN** & 4.20 & 16.46 & 25.70 & 68.25 & 17.11 & 41.73 \\
**AA** & 5.07 & 19.59 & 26.85 & 70.22 & 17.83 & 43.12 \\
**RA** & 6.29 & 24.29 & 28.34 & 71.50 & 17.79 & 43.34 \\ \hline
**GCN** & 6.09 & 22.48 & 26.94 & 68.38 & 19.98 & 51.72 \\
**SAGE** & 5.53 & 21.26 & 27.27 & 69.49 & 22.05 & 53.13 \\
**SEAL** & 6.43 & 21.57 & 29.71 & 76.77 & 20.60 & 48.62 \\
**Neo-GNN** & 5.23 & 21.03 & 21.68 & 64.81 & 16.12 & 43.17 \\
**BUDDY** & 5.67 & 23.35 & 27.70 & 71.50 & 19.17 & 47.81 \\
**NCNC** & 4.73 & 20.49 & 33.52 & 82.24 & 19.61 & 51.69 \\ \hline
**MPLP+** & 6.79 & 25.10 & 41.40 & 84.88 & 23.11 & 55.51 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Link prediction results on OGB datasets under HeaRT [33]. The top three models are colored by **First**, **Second**, **Third**.

show a substantial performance uplift, with improvements in Hits@50 ranging from \(2\%\) to \(10\%\) compared to the closest competitors.

We extend our evaluation of MPLP+ to assess its performance on large-scale datasets under the challenging HeaRT setting proposed by Li et al. [33]. HeaRT introduces a more rigorous and realistic set of negative samples during evaluation, typically resulting in a notable decline in performance across link prediction methods. As detailed in Table 3, MPLP+ consistently outperform all other methods across three OGB graph benchmarks in this demanding context. This underscores the robustness of MPLP+, affirming its ability to maintain superior performance across a variety of graph benchmarks and evaluation settings.

Time efficiencyWe conduct an analysis of the time efficiency of our methods, MPLP and MPLP+, against established baselines using three large-scale OGB datasets. The results, illustrated in Figure 4, demonstrate that our approaches not only deliver superior performance across the graph benchmarks but also set a new benchmark for state-of-the-art time efficiency in full-batch inference. In particular, the primary component underlying our methods is the message-passing operation, which allows their inference speeds to rival that of the baseline GCN. Additionally, the structural feature estimations enhance the models' expressiveness, enabling more accurate representation of graph structures, particularly in the context of link prediction tasks. More details can be found in Appendix D.3.

Estimation accuracyWe investigate the precision of MPLP in estimating \(\#(p,q)\), which denotes the count of node labels, using the Collab dataset. The outcomes of this examination are illustrated in Figure 5. Although ELPH possesses the capability to approximate these counts utilizing techniques like MinHash and Hyperloglog, our method exhibits superior accuracy. Moreover, ELPH runs out of memory when the dimension is larger than \(3000\). Remarkably, deploying a one-hot encoding strategy for the hubs further bolsters the accuracy of MPLP, concurrently diminishing the variance introduced by inherent graph structures. An exhaustive analysis, including time efficiency considerations, is provided in Appendix F.1.

Extended ablation studiesFurther ablation studies have been carried out to understand the individual contributions within MPLP. These include: (1) an exploration of the distinct components of MPLP in Appendix F.2; (2) an analysis of the performance contributions from different structural estimations in Appendix F.3; and (3) an examination of parameter sensitivity in Appendix F.4.

## 6 Conclusion

We study the potential of message-passing GNNs to encapsulate link structural features. Based on this, we introduce a novel link prediction paradigm that consistently outperforms state-of-the-art baselines across various graph benchmarks. The inherent capability to adeptly capture structures enhances the expressivity of GNNs, all while maintaining their computational efficiency. Our findings hint at a promising avenue for elevating the expressiveness of GNNs through probabilistic approaches.

Figure 5: MSE of estimation for \(\#(1,1)\), \(\#(1,2)\) and \(\#(1,0)\) on Collab. Lower values are better.

Acknowledgements

We would like to thank the anonymous reviewers for their insightful comments and helpful discussions. This research was supported in part by the University of Notre Dame's Lucy Family Institute for Data and Society and the NSF Center for Computer-Assisted Synthesis (C-CAS), under grant number CHE-2202693.

## References

* Liben-Nowell and Kleinberg [2003] David Liben-Nowell and Jon Kleinberg. The link prediction problem for social networks. In _Proceedings of the twelfth international conference on Information and knowledge management_, CIKM '03, pages 556-559, New York, NY, USA, November 2003. Association for Computing Machinery. ISBN 978-1-58113-723-1. doi: 10.1145/956863.956972. URL http://doi.org/10.1145/956863.956972.
* Szklarczyk et al. [2019] Damian Szklarczyk, Annika L. Gable, David Lyon, Alexander Junge, Stefan Wyder, Jaime Huerta-Cepas, Milan Simonovic, Nadezhda T. Doncheva, John H. Morris, Peer Bork, Lars J. Jensen, and Christian von Mering. STRING v11: protein-protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets. _Nucleic Acids Research_, 47(D1):D607-D613, January 2019. ISSN 1362-4962. doi: 10.1093/nar/gky1131.
* Koren et al. [2009] Yehuda Koren, Robert Bell, and Chris Volinsky. Matrix factorization techniques for recommender systems. _Computer_, 42(8):30-37, 2009. Publisher: IEEE.
* Zhu et al. [2021] Zhaocheng Zhu, Zuobai Zhang, Louis-Pascal Xhonneux, and Jian Tang. Neural bellman-ford networks: A general graph neural network framework for link prediction. _Advances in Neural Information Processing Systems_, 34, 2021.
* Kipf and Welling [2017] Thomas N. Kipf and Max Welling. Semi-Supervised Classification with Graph Convolutional Networks. _arXiv:1609.02907 [cs, stat]_, February 2017. URL http://arxiv.org/abs/1609.02907. arXiv: 1609.02907.
* Gilmer et al. [2017] Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl. Neural Message Passing for Quantum Chemistry. _CoRR_, abs/1704.01212, 2017. URL http://arxiv.org/abs/1704.01212. arXiv: 1704.01212.
* Hamilton et al. [2018] William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive Representation Learning on Large Graphs. _arXiv:1706.02216 [cs, stat]_, September 2018. URL http://arxiv.org/abs/1706.02216. arXiv: 1706.02216.
* Velickovic et al. [2018] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph Attention Networks. _arXiv:1710.10903 [cs, stat]_, February 2018. URL http://arxiv.org/abs/1710.10903. arXiv: 1710.10903.
* Xu et al. [2018] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How Powerful are Graph Neural Networks? _CoRR_, abs/1810.00826, 2018. URL http://arxiv.org/abs/1810.00826. arXiv: 1810.00826.
* Hu et al. [2021] Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. Open Graph Benchmark: Datasets for Machine Learning on Graphs. _arXiv:2005.00687 [cs, stat]_, February 2021. URL http://arxiv.org/abs/2005.00687. arXiv: 2005.00687.
* Zhang et al. [2021] Muhan Zhang, Pan Li, Yinglong Xia, Kai Wang, and Long Jin. Labeling Trick: A Theory of Using Graph Neural Networks for Multi-Node Representation Learning. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P. S. Liang, and J. Wortman Vaughan, editors, _Advances in Neural Information Processing Systems_, volume 34, pages 9061-9073. Curran Associates, Inc., 2021. URL https://proceedings.neurips.cc/paper/2021/file/4be49c79f233b4f4070794825c323733-Paper.pdf.

* Nunes et al. [2023] Igor Nunes, Mike Heddes, Pere Verges, Danny Abraham, Alexander Veidenbaum, Alexandru Nicolau, and Tony Givargis. DotHash: Estimating Set Similarity Metrics for Link Prediction and Document Deduplication, May 2023. URL http://arxiv.org/abs/2305.17310. arXiv:2305.17310 [cs].
* Kainen and Kurkova [1993] Paul C. Kainen and Vera Kurkova. Quasiorthogonal dimension of euclidean spaces. _Applied Mathematics Letters_, 6(3):7-10, May 1993. ISSN 0893-9659. doi: 10.1016/0893-9659(93)90023-G. URL https://www.sciencedirect.com/science/article/pii/089396599390023G.
* Adamic and Adar [2003] Lada A. Adamic and Eytan Adar. Friends and neighbors on the Web. _Social Networks_, 25(3):211-230, 2003. ISSN 0378-8733. doi: https://doi.org/10.1016/S0378-8733(03)00009-1. URL https://www.sciencedirect.com/science/article/pii/S0378873303000091.
* Zhou et al. [2009] Tao Zhou, Linyuan Lu, and Yi-Cheng Zhang. Predicting missing links via local information. _The European Physical Journal B_, 71(4):623-630, 2009. Publisher: Springer.
* Chamberlain et al. [2022] Benjamin Paul Chamberlain, Sergey Shirobokov, Emanuele Rossi, Fabrizio Frasca, Thomas Markovich, Nils Yannick Hammerla, Michael M. Bronstein, and Max Hansmire. Graph Neural Networks for Link Prediction with Subgraph Sketching. September 2022. URL https://openreview.net/forum?id=m1oqEOAozQU.
* Kipf and Welling [2016] Thomas N. Kipf and Max Welling. Variational Graph Auto-Encoders, 2016. _eprint: 1611.07308.
* Zhang and Chen [2018] Muhan Zhang and Yixin Chen. Link Prediction Based on Graph Neural Networks. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper/2018/file/53f0d7c537d99b3824f0f99d62ea2428-Paper.pdf.
* Wang et al. [2023] Xiyuan Wang, Haotong Yang, and Muhan Zhang. Neural Common Neighbor with Completion for Link Prediction, February 2023. URL http://arxiv.org/abs/2302.00890. arXiv:2302.00890 [cs].
* Johnson and Lindenstrauss [1984] William Johnson and Joram Lindenstrauss. Extensions of Lipschitz maps into a Hilbert space. _Contemporary Mathematics_, 26:189-206, January 1984. ISSN 9780821850305. doi: 10.1090/conm/026/737400.
* Purchase et al. [2022] Skye Purchase, Yiren Zhao, and Robert D. Mullins. Revisiting Embeddings for Graph Neural Networks. November 2022. URL https://openreview.net/forum?id=Ri2dzVt_a1h.
* Kainen [1992] Paul C Kainen. Orthogonal dimension and tolerance. _Unpublished report, Washington DC: Industrial Math_, 1992.
* Kainen and Kurkova [2020] Paul C Kainen and Vera Kurkova. Quasiorthogonal dimension. In _Beyond traditional probabilistic data processing techniques: Interval, fuzzy etc. Methods and their applications_, pages 615-629. Springer, 2020.
* Barabasi and Albert [1999] Albert-Laszlo Barabasi and Reka Albert. Emergence of Scaling in Random Networks. _Science_, 286(5439):509-512, 1999. doi: 10.1126/science.286.5439.509. URL https://www.science.org/doi/abs/10.1126/science.286.5439.509. _eprint: https://www.science.org/doi/pdf/10.1126/science.286.5439.509.
* Yun et al. [2021] Seongjun Yun, Seoyoon Kim, Junhyun Lee, Jaewoo Kang, and Hyunwoo J. Kim. Neo-GNNs: Neighborhood Overlap-aware Graph Neural Networks for Link Prediction. November 2021. URL https://openreview.net/forum?id=Ic9vRN3VpZ.
* Li et al. [2020] Pan Li, Yanbang Wang, Hongwei Wang, and Jure Leskovec. Distance Encoding: Design Provably More Powerful Neural Networks for Graph Representation Learning. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, _Advances in Neural Information Processing Systems_, volume 33, pages 4465-4478. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/2f73168bf3656f697507752ec592c437-Paper.pdf.

* Abboud et al. [2022] Ralph Abboud, Radoslav Dimitrov, and Ismail Ilkan Ceylan. Shortest Path Networks for Graph Property Prediction. November 2022. URL https://openreview.net/forum?id=mwzwvWxruFg1.
* Feng et al. [2022] Jiarui Feng, Yixin Chen, Fuhai Li, Anindya Sarkar, and Muhan Zhang. How Powerful are K-hop Message Passing Graph Neural Networks. May 2022. URL https://openreview.net/forum?id=nN3aVRQsxGd.
* Dong et al. [2022] Kaiwen Dong, Yijun Tian, Zhichun Guo, Yang Yang, and Nitesh Chawla. FakeEdge: Alleviate Dataset Shift in Link Prediction. December 2022. URL https://openreview.net/forum?id=QDNojSXuvtX.
* Yin et al. [2022] Haoteng Yin, Muhan Zhang, Yanbang Wang, Jianguo Wang, and Pan Li. Algorithm and System Co-design for Efficient Subgraph-based Graph Representation Learning. _Proceedings of the VLDB Endowment_, 15(11):2788-2796, July 2022. ISSN 2150-8097. doi: 10.14778/3551793.351831. URL http://arxiv.org/abs/2202.13538. arXiv:2202.13538 [cs].
* Jin et al. [2022] Jiarui Jin, Yangkun Wang, Weinan Zhang, Quan Gan, Xiang Song, Yong Yu, Zheng Zhang, and David Wipf. Refined Edge Usage of Graph Neural Networks for Edge Prediction. December 2022. doi: 10.48550/arXiv.2212.12970. URL https://arxiv.org/abs/2212.12970v1.
* Chen et al. [2020] Zhengdao Chen, Lei Chen, Soledad Villar, and Joan Bruna. Can Graph Neural Networks Count Substructures? _arXiv:2002.04025 [cs, stat]_, October 2020. URL http://arxiv.org/abs/2002.04025. arXiv: 2002.04025.
* Li et al. [2023] Juanhui Li, Harry Shomer, Haitao Mao, Shenglai Zeng, Yao Ma, Neil Shah, Jiliang Tang, and Dawei Yin. Evaluating Graph Neural Networks for Link Prediction: Current Pitfalls and New Benchmarking, July 2023. URL http://arxiv.org/abs/2306.10453. arXiv:2306.10453 [cs].
* Katz [1953] Leo Katz. A new status index derived from sociometric analysis. _Psychometrika_, 18(1):39-43, March 1953. ISSN 1860-0980. doi: 10.1007/BF02289026. URL https://doi.org/10.1007/BF02289026.
* Salton and McGill [1986] Gerard Salton and Michael J. McGill. _Introduction to Modern Information Retrieval_. McGraw-Hill, Inc., USA, 1986. ISBN 0-07-054484-0.
* Brin and Page [1998] Sergey Brin and Lawrence Page. The Anatomy of a Large-Scale Hypertextual Web Search Engine. _Computer Networks_, 30:107-117, 1998. URL http://www-db.stanford.edu/~backrub/google.html.
* Morris et al. [2021] Christopher Morris, Martin Ritzert, Matthias Fey, William L. Hamilton, Jan Eric Lenssen, Gaurav Rattan, and Martin Grohe. Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks, November 2021. URL http://arxiv.org/abs/1810.02244. arXiv:1810.02244 [cs, stat].
* Maron et al. [2020] Haggai Maron, Heli Ben-Hamu, Hadar Serviansky, and Yaron Lipman. Provably Powerful Graph Networks. _arXiv:1905.11136 [cs, stat]_, June 2020. URL http://arxiv.org/abs/1905.11136. arXiv: 1905.11136.
* Zhang and Li [2021] Muhan Zhang and Pan Li. Nested Graph Neural Networks, 2021. URL https://arxiv.org/abs/2110.13197.
* Frasca et al. [2022] Fabrizio Frasca, Beatrice Bevilacqua, Michael M. Bronstein, and Haggai Maron. Understanding and Extending Subgraph GNNs by Rethinking Their Symmetries, June 2022. URL http://arxiv.org/abs/2206.11140. arXiv:2206.11140 [cs].
* Sato et al. [2021] Ryoma Sato, Makoto Yamada, and Hisashi Kashima. Random Features Strengthen Graph Neural Networks, 2021. _eprint: 2002.03155.
* Abboud et al. [2021] Ralph Abboud, Ismail Ilkan Ceylan, Martin Grohe, and Thomas Lukasiewicz. The Surprising Power of Graph Neural Networks with Random Node Initialization, 2021. _eprint: 2010.01179.

* [43] Pal Andras Papp, Karolis Martinkus, Lukas Faber, and Roger Wattenhofer. DropGNN: Random Dropouts Increase the Expressiveness of Graph Neural Networks, November 2021. URL http://arxiv.org/abs/2111.06283. arXiv:2111.06283 [cs].
* [44] Vladimir Batagelj and Andrej Mrvar. Pajek datasets website, 2006. URL http://vlado.fmf.uni-lj.si/pub/networks/data/.
* [45] Mark EJ Newman. Finding community structure in networks using the eigenvectors of matrices. _Physical review E_, 74(3):036104, 2006. Publisher: APS.
* [46] Robert Ackland and others. Mapping the US political blogosphere: Are conservative bloggers more prominent? In _BlogTalk Downunder 2005 Conference, Sydney_, 2005.
* [47] Christian Von Mering, Roland Krause, Berend Snel, Michael Cornell, Stephen G Oliver, Stanley Fields, and Peer Bork. Comparative assessment of large-scale data sets of protein-protein interactions. _Nature_, 417(6887):399-403, 2002. Publisher: Nature Publishing Group.
* [48] Duncan J. Watts and Steven H. Strogatz. Collective dynamics of'small-world' networks. _Nature_, 393:440-442, 1998. URL https://api.semanticscholar.org/CorpusID:3034643.
* [49] Neil Spring, Ratul Mahajan, and David Wetherall. Measuring ISP topologies with Rocketfuel. _ACM SIGCOMM Computer Communication Review_, 32(4):133-145, 2002. Publisher: ACM New York, NY, USA.
* [50] Muhan Zhang, Zhicheng Cui, Shali Jiang, and Yixin Chen. Beyond link prediction: Predicting hyperlinks in adjacency space. In _Thirty-Second AAAI Conference on Artificial Intelligence_, 2018.
* [51] Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan Gunnemann. Pitfalls of Graph Neural Network Evaluation, June 2019. URL http://arxiv.org/abs/1811.05868. arXiv:1811.05868 [cs, stat].
* [52] Matthias Fey and Jan E. Lenssen. Fast Graph Representation Learning with PyTorch Geometric. In _ICLR Workshop on Representation Learning on Graphs and Manifolds_, 2019.

## Appendix

### Table of Contents

* 1 Related work
* 2 Efficient inference at node-level complexity
* 3 Estimate triangular substructures
	* 3.1 Method
	* 3.2 Experiments
* 4 Experimental details
	* 4.1 Benchmark datasets
	* 4.2 More details in baseline methods
	* 4.3 Evaluation Details: Inference Time
	* 4.4 Software and hardware details
	* 4.5 Time Complexity
	* 4.6 Hyperparameters
* 5 Exploring Bag-Of-Words Node Attributes
	* 5.1 Node Attribute Orthogonality
	* 5.2 Role of Node Attribute Information
	* 5.3 Expanding QO Vector Dimensions
* 6 Additional experiments
	* 6.1 Node label estimation accuracy and time
	* 6.2 Model enhancement ablation
	* 6.3 Structural features ablation
	* 6.4 Parameter sensitivity
* 7 Theoretical analysis
	* 7.1 Proof for Theorem 3.1
	* 7.2 Proof for Theorem 3.2
	* 7.3 Proof for Theorem 3.3
* 8 Limitations
* 9 Broader Impact
Related work

Link predictionLink prediction, inherent to graph data analysis, has witnessed a paradigm shift from its conventional heuristic-based methods to the contemporary, more sophisticated GNNs approaches. Initial explorations in this domain primarily revolve around heuristic methods such as CN, AA, RA, alongside seminal heuristics like the Katz Index [34], Jaccard Index [35], Page Rank [36], and Preferential Attachment [24]. However, the emergence of graphs associated with node attributes has shifted the research landscape towards GNN-based methods. Specifically, these GNN-centric techniques bifurcate into node-level and link-level paradigms. Pioneers like Kipf and Welling introduce the Graph Auto-Encoder (GAE) to ascertain node pair similarity through GNN-generated node representation. On the other hand, link-level models, represented by SEAL [18], opt for subgraph extractions centered on node pairs, even though this can present scalability challenges.

Amplifying GNN Expressiveness with RandomnessThe expressiveness of GNNs, particularly those of the MPNNs, has been the subject of rigorous exploration [9]. A known limitation of MPNNs, their equivalence to the 1-Weisfeiler-Lehman test, often results in indistinguishable representation for non-isomorphic graphs. A suite of contributions has surfaced to boost GNN expressiveness, of which [37; 38; 39; 40] stand out. An elegant, yet effective paradigm involves symmetry-breaking through stochasticity injection [41; 42; 43]. Although enhancing expressiveness, such random perturbations can occasionally undermine generalizability. Diverging from these approaches, our methodology exploits probabilistic orthogonality within random vectors, culminating in a robust structural feature estimator that introduces minimal estimator variance.

Link-Level Link PredictionWhile node-level models like GAE offer enviable efficiency, they occasionally fall short in performance when compared with rudimentary heuristics [16]. Efforts to build scalable link-level alternatives have culminated in innovative methods such as Neo-GNN [25], which distills structural features from adjacency matrices for link prediction. Elsewhere, ELPH [16] harnesses hashing mechanisms for structural feature representation, while NCNC [19] adeptly aggregates common neighbors' node representation. Notably, DotHash [12], which profoundly influenced our approach, employs quasi-orthogonal random vectors for set similarity computations, applying these in link prediction tasks.

Distinctively, our proposition builds upon, yet diversifies from, the frameworks of ELPH and DotHash. While resonating with ELPH's architectural spirit, we utilize a streamlined, efficacious hashing technique over MinHash for set similarity computations. Moreover, we resolve ELPH's limitations through strategic implementations like shortcut removal and norm rescaling. When paralleled with DotHash, our approach magnifies its potential, integrating it with GNNs for link predictions and extrapolating its applicability to multi-hop scenarios. It also judiciously optimizes variance induced by the structural feature estimator in sync with graph data. We further explore the potential of achieving higher expressiveness with linear computational complexity by estimating the substructure counting [32].

## Appendix B Efficient inference at node-level complexity

In addition to its superior performance, MPLP stands out for its practical advantages in industrial applications due to its node-level inference complexity. This design is akin to employing an MLP as the predictor. Our method facilitates offline preprocessing, allowing for the caching of node signatures or representations. Consequently, during online inference in a production setting, MPLP merely requires fetching the relevant node signatures or representations and processing them through an MLP. This approach significantly streamlines the online inference process, necessitating only node-level space complexity and ensuring constant time complexity for predictions. This efficiency in both space and time makes MPLP particularly suitable for real-world applications where rapid, on-the-fly predictions are crucial.

## Appendix C Estimate triangular substructures

Not only does MPLP encapsulate the local structure of the target node pair by assessing node counts based on varying shortest-path distances, but it also pioneers in estimating the count of triangleslinked to any of the nodes-- an ability traditionally deemed unattainable for GNNs [32]. In this section, we discuss a straightforward implementation of the triangle estimation.

### Method

Constructing the structural feature with DE can provably enhance the expressiveness of the link prediction model [26; 11]. However, there are still prominent cases where labelling trick also fails to capture. Since labelling trick only considers the relationship between the neighbors and the target node pair, it can sometimes miss the subtleties of intra-neighbor relationships. For example, the nodes of DE\((1,1)\) in Figure 3 exhibit different local structures. Nevertheless, labelling trick like DE tends to treat them equally, which makes the model overlook the triangle substructure shown in the neighborhood. Chen et al. [32] discusses the challenge of counting such a substructure with a pure message-passing framework. We next give an implementation of message-passing to approximate triangle counts linked to a target node pair--equivalent in complexity to conventional MPNNs.

For a triangle to form, two nodes must connect with each other and the target node. Key to our methodology is recognizing the obligatory presence of length-\(1\) and length-\(2\) walks to the target node. Thus, according to Theorem 3.3, our estimation can formalize as:

\[\#(\mathop{\bigtriangleup}_{u})=\frac{1}{2}\mathbb{E}\Big{(}\tilde{\bm{h}}_{ u}^{(1)}\cdot\tilde{\bm{h}}_{u}^{(2)}\Big{)}.\] (8)

Augmenting the structural features with triangle estimates gives rise to a more expressive structural feature set of MPLP.

### Experiments

Following the experiment in Section 6.1 of [32], we conduct an experiment to evaluate MPLP's ability to count triangular substructures. Similarly, we generate two synthetic graphs as the benchmarks: the Erdos-Renyi graphs and the random regular graphs. We also present the performance of baseline models reported in [32]. Please refer to [32] for details about the experimental settings and baseline models. The results are shown in Table 4.

As the results show, the triangle estimation component of MPLP can estimate the number of triangles in the graph with almost negligible error, similar to other more expressive models. Moreover, MPLP achieves this with a much lower computational cost, which is comparable to 1-WL GNNs like GCN, GIN, and SAGE. It demonstrates MPLP's advantage of better efficiency over more complex GNNs like 2-IGN and PPGN.

\begin{table}
\begin{tabular}{l c c} \hline \hline
**Dataset** & **Erdos-Renyi** & **Random Regular** \\ \hline GCN & 8.27E-1 & 2.05 \\ GIN & 1.25E-1 & 4.74E-1 \\ SAGE & 1.48E-1 & 5.21E-1 \\ sGNN & 1.13E-1 & 4.43E-1 \\
2-IGN & 9.85E-1 & 5.96E-1 \\ PPGN & 2.51E-7 & 3.71E-5 \\ LRP-1-3 & 2.49E-4 & 3.83E-4 \\ Deep LRP-1-3 & 4.77E-5 & 5.16E-6 \\ \hline MPLP & 1.61E-4 & 3.70E-4 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Performance of different GNNs on learning Figure 6: Representation of the target link the counts of triangles, measured by MSE divided by \((u,v)\) of MPLP after including the triangular variance of the ground truth counts. Shown here are the estimation component.

## Appendix D Experimental details

### Benchmark datasets

The statistics of each benchmark dataset are shown in Table 5. The benchmarks without attributes are:

* **USAir**[44]: a graph of US airlines;
* **NS**[45]: a collaboration network of network science researchers;
* **PB**[46]: a graph of links between web pages on US political topics;
* **Yeast**[47]: a protein-protein interaction network in yeast;
* **C.ele**[48]: the neural network of Caenorhabditis elegans;
* **Power**[48]: the network of the western US's electric grid;
* **Router**[49]: the Internet connection at the router-level;
* **E.coli**[50]: the reaction network of metabolites in Escherichia coli.

4 out of 7 benchmarks with node attributes come from [51], while Collab, PPA and Citation2 are from Open Graph Benchmark [10]:

* **CS**: co-authorship graphs in the field of computer science, where nodes represent authors, edges represent that two authors collaborated on a paper, and node features indicate the keywords for each author's papers;
* **Physics**: co-authorship graphs in the field of physics with the same node/edge/feature definition as of **CS**;
* **Computers**: a segment of the Amazon co-purchase graph for computer-related equipment, where nodes represent goods, edges represent that two goods are frequently purchased together together, and node features represent the product reviews;
* **Physics**: a segment of the Amazon co-purchase graph for photo-related equipment with the same node/edge/feature definition as of **Computers**;
* **Collab**: a large-scale collaboration network, showcasing a wide array of interdisciplinary partnerships.
* **PPA**: a large-scale protein-protein association network, representing the biological interaction between proteins.

\begin{table}
\begin{tabular}{l c c c c c c c} \hline \hline
**Dataset** & **\#Nodes** & **\#Edges** & **Avg. node deg.** & **Std. node deg.** & **Max. node deg.** & **Density** & **Attr. Dimension** \\ \hline
**C.ele** & 297 & 4296 & 14.46 & 12.97 & 134 & 9.7734\% & - \\ \hline
**Yeast** & 2375 & 23386 & 9.85 & 15.50 & 118 & 0.8295\% & - \\ \hline
**Power** & 4941 & 13188 & 2.67 & 1.79 & 19 & 0.1081\% & - \\ \hline
**Router** & 5022 & 12516 & 2.49 & 5.29 & 106 & 0.0993\% & - \\ \hline
**USAir** & 332 & 4252 & 12.81 & 20.13 & 139 & 7.7385\% & - \\ \hline
**E.coli** & 1805 & 29320 & 16.24 & 48.38 & 1030 & 1.8009\% & - \\ \hline
**NS** & 1589 & 5484 & 3.45 & 3.47 & 34 & 0.4347\% & - \\ \hline
**PB** & 1222 & 33428 & 27.36 & 38.42 & 351 & 4.4808\% & - \\ \hline
**CS** & 18333 & 163788 & 8.93 & 9.11 & 136 & 0.0975\% & 6805 \\ \hline
**Physics** & 34493 & 495924 & 14.38 & 15.57 & 382 & 0.0834\% & 8415 \\ \hline
**Computers** & 13752 & 491722 & 35.76 & 70.31 & 2992 & 0.5201\% & 767 \\ \hline
**Photo** & 7650 & 238162 & 31.13 & 47.28 & 1434 & 0.8140\% & 745 \\ \hline
**Collab** & 235868 & 2358104 & 10.00 & 18.98 & 671 & 0.0085\% & 128 \\ \hline
**PPA** & 576289 & 30326273 & 52.62 & 99.73 & 3241 & 0.0256\% & 58 \\ \hline
**Citation2** & 2927963 & 30561187 & 10.44 & 42.81 & 10000 & 0.0014\% & 128 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Statistics of benchmark datasets.

* **Citation2**: a large-scale citation network, with papers as nodes and the citaitons as edges.

Since OGB datasets have a fixed split, no train test split is needed for it. For the other benchmarks, we randomly split the edges into 70-10-20 as train, validation, and test sets. The validation and test sets are not observed in the graph during the entire cycle of training and testing. They are only used for evaluation purposes. For Collab, it is allowed to use the validation set in the graph when evaluating on the test set.

We run the experiments 10 times on each dataset with different splits. For each run, we cache the split edges and evaluate every model on the same split to ensure a fair comparison. The average score and standard deviation are reported in Hits@100 for PPA, MMR for Citation2 and Hits@50 for the remaining datasets.

### More details in baseline methods

In our experiments, we explore advanced variants of the baseline models **ELPH** and **NCNC**. Specifically, for **ELPH**, Chamberlain et al. [2016] propose BUDDY, a link prediction method that preprocesses node representations to achieve better efficiency but compromises its expressiveness. **NCNC**[19] builds upon its predecessor, NCN, by first estimating the complete graph structure and then performing inference. In our experiments, we select the most expressiveness variant to make sure it is a fair comparison between different model architectures. Thus, we select **ELPH** over BUDDY, and **NCNC** over NCN to establish robust baselines in our study. We conduct a thorough hyperparameter tuning for **ELPH** and **NCNC** to select the best-performing models on each benchmark dataset. We follow the hyperparameter guideline of **ELPH** and **NCNC** to search for the optimal structures. For **ELPH**, we run through hyperparameters including dropout rates on different model components, learning rate, batch size, and dimension of node embedding. For **NCNC**, we experiment on dropout rates on different model components, learning rates on different model components, batch size, usage of jumping knowledge, type of encoders, and other model-specific terms like alpha. For **Neo-GNN** and **SEAL**, due to their relatively inferior efficiency, we only tune the common hyperparameters like learning rate, size of hidden dimensions.

### Evaluation Details: Inference Time

In Figure 4, we assess the inference time across different models on the OGB datasets for a single epoch of test links. Specifically, we clock the wall time taken by models to score the complete test set. This encompasses preprocessing, message-passing, and the actual prediction. For the SEAL model, we employ a dynamic subgraph generator during the preprocessing phase, which dynamically computes the subgraph. We substitute ELPH with BUDDY from [2016] in this evaluation, since BUDDY exhibits better time efficiency compared to ELPH. For both BUDDY and our proposed methods, we initially propagate the node features and signatures just once at the onset of inference. These are then cached for subsequent scoring sessions.

### Software and hardware details

We implement MPLP in Pytorch Geometric framework [18]. We run our experiments on a Linux system equipped with an NVIDIA A100 GPU with 80GB of memory.

### Time Complexity

The efficiency of MPLP stands out when it comes to link prediction inference. Let's denote \(t\) as the number of target links, \(d\) as the maximum node degree, \(r\) as the number of hops to compute, and \(F\) as the dimension count of node signatures.

For preprocessing node signatures, MPLP involves two primary steps:

1. Initially, the algorithm computes all-pairs unweighted shortest paths across the input graph to acquire the shortest-path neighborhood \(\mathcal{N}_{v}^{s}\) for each node. This can be achieved using a BFS approach for each node, with a time complexity of \(O(|V||E|)\).
2. Following this, MPLP propagates the QO vectors through the shortest-path neighborhood, which has a complexity of \(O(td^{r}F)\), and then caches these vectors in memory.

During online scoring, MPLP performs the inner product operation with a complexity of \(O(tF)\), enabling the extraction of structural feature estimations.

However, during training, the graph's structure might vary depending on the batch of target links due to the shortcut removal operation. As such, MPLP proceeds in three primary steps:

1. Firstly, the algorithm extracts the \(r\)-hop induced subgraph corresponding to these \(t\) target links. In essence, we deploy a BFS starting at each node of the target links to determine their receptive fields. This process, conceptually similar to message-passing but in a reversed message flow, has a time complexity of \(O(tdr)\). Note that, different from SEAL, we extract one \(r\)-hop subgraph induced from a batch of target links.
2. To identify the shortest-path neighborhood \(\mathcal{N}_{v}^{s}\), we simply apply sparse-sparse matrix multiplications of the adjacency matrix to get the \(s\)-power adjacency matrix, where \(s=1,2,\ldots,r\). Due to the sparsity, this takes \(O(|V|d^{r})\).
3. Finally, the algorithm engages in message-passing to propagate the QO vectors along the shortest-path neighborhoods, with a complexity of \(O(td^{r}F)\), followed by performing the inner product at \(O(tF)\).

Summing up, the overall time complexity for MPLP in the training phase stands at \(O(tdr+|V|d^{r}+td^{r}F)\).

For MPLP+, it does not require the preprocessing step for the shortest-path neighborhood. Thus, the time complexity is the same as any standard message-passing GNNs, \(O(td^{r}F)\).

### Hyperparameters

We determine the optimal hyperparameters for our model through systematic exploration. The setting with the best performance on the validation set is selected. The chosen hyperparameters are as follows:

* Number of Hops (\(r\)): We set the maximum number of hops to \(r=2\). Empirical evaluation suggests this provides an optimal trade-off between accuracy and computational efficiency.
* Node Signature Dimension (\(F\)): The dimension of node signatures, \(F\), is fixed at \(1024\), except for Citation2 with \(512\). This configuration ensures that MPLP is both efficient and accurate across all benchmark datasets.
* The minimum degree of nodes to be considered as hubs (\(b\)): This parameter indicates the minimum degree of the nodes which are considered as hubs to one-hot encode in the node signatures. We experiment with values in the set \([50,100,150]\).
* Batch Size (\(B\)): We vary the batch size depending on the graph type: For the 8 non-attributed graphs, we explore batch sizes within \([512,1024]\). For the 4 attributed graphs coming from [51], we search within \([2048,4096]\). For OGB datasets, we use \(32768\) for Collab and PPA, and \(261424\) for Citation2.

More ablation study can be found in Appendix F.4.

## Appendix E Exploring Bag-Of-Words Node Attributes

In Section 3, we delved into the capability of GNNs to discern joint structural features, particularly when presented with Quasi-Orthogonal (QO) vectors. Notably, many graph benchmarks utilize text data to construct node attributes, representing them as Bag-Of-Words (BOW). BOW is a method that counts word occurrences, assigning these counts as dimensional values. With a large dictionary, these BOW node attribute vectors often lean towards QO due to the sparse nature of word representations. Consequently, many node attributes in graph benchmarks inherently possess the QO trait. Acknowleding GNNs' proficiency with QO vector input, we propose the question: _Is it the **QO property** or the **information** embedded within these attributes that significantly impacts link prediction in benchmarks?_ This section is an empirical exploration of this inquiry.

### Node Attribute Orthogonality

Our inquiry begins with the assessment of node attribute orthogonality across three attributed graphs: CS, Photo, and Collab. CS possesses extensive BOW vocabulary, resulting in node attributes spanning over \(8000\) dimensions. Contrarily, Photo has a comparatively minimal dictionary, encompassing just \(745\) dimensions. Collab, deriving node attributes from word embeddings, limits to \(128\) dimensions.

For our analysis, we sample \(10000\) nodes (\(7650\) for Photo) and compute the inner product of their attributes. The results are visualized in Figure 7. Our findings confirm that with a larger BOW dimension, CS node attributes closely follow QO. However, this orthogonality isn't as pronounced in Photo and Collab--especially Collab, where word embeddings replace BOW. Given that increased node signature dimensions can mitigate estimation variance (as elaborated in Theorem 3.2), one could posit GNNs might offer enhanced performance on CS, due to its extensive BOW dimensions. Empirical evidence from Table 2 supports this claim.

Further, in Figure 8, we showcase the inner product of node attributes in CS and Photo, but this time, nodes are sequenced by class labels. This order reveals that nodes sharing labels tend to have diminished orthogonality compared to random pairs--a potential variance amplifier in structural feature estimation using node attributes.

### Role of Node Attribute Information

To discern the role of embedded information within node attributes, we replace the original attributes in CS, Photo, and Collab with random vectors--denoted as _random feat_. These vectors maintain the original attribute dimensions, though each dimension gets randomly assigned values from \(\{-1,1\}\). The subsequent findings are summarized in Table 6. Intriguingly, even with this "noise" as input, performance remains largely unaltered. CS attributes appear to convey valuable insights for link predictions, but the same isn't evident for the other datasets. In fact, introducing random vectors to Computers and Photo resulted in enhanced outcomes, perhaps due to their original attribute's

Figure 8: Heatmap illustrating the inner product of node attributes, arranged by node labels, across CS and Photo. The rightmost showcases the inner product of QO vectors.

Figure 7: Heatmap illustrating the inner product of node attributes across CS, Photo, and Collab datasets.

insufficient orthogonality hampering effective structural feature capture. Collab shows a performance drop with random vectors, implying that the original word embedding can contribute more to the link prediction than structural feature estimation with merely \(128\) QO vectors.

### Expanding QO Vector Dimensions

Lastly, we substitute node attributes with QO vectors of varied dimensions, utilizing GCN as the encoder. The outcomes of this experiment are cataloged in Table 6. What's striking is that GCNs, when furnished with lengthier random vectors, often amplify link prediction results across datasets, with the exception of CS. On Computers and Photo, a GCN even rivals our proposed model (Table 2), potentially attributed to the enlarged vector dimensions. This suggests that when computational resources permit, expanding our main experiment's node signature dimensions (currently set at \(1024\)) could elevate our model's performance. On Collab. the performance increases significantly compared to the experiments which are input with \(128\)-dimensional vectors, indicating that the structural features are more critical for Collab than the word embedding.

## Appendix F Additional experiments

### Node label estimation accuracy and time

In Figure 5, we assess the accuracy of node label count estimation. For ELPH, the node signature dimension corresponds to the number of MinHash permutations. We employ a default hyperparameter setting for Hyperloglog, with \(p=8\), a configuration that has demonstrated its adequacy in [16]. For time efficiency evaluation, we initially propagate and cache node signatures, followed by performing the estimation.

Furthermore, we evaluate the node label count estimation for \(\#(2,2)\) and \(\#(2,0)\). The outcomes are detailed in Figure 9. While MPLP consistently surpasses ELPH in estimation accuracy, the gains achieved via one-hot hubs diminish for #\((2,2)\) and #\((2,0)\) relative to node counts at a shortest-path distance of \(1\). This diminishing performance gain can be attributed to our selection criteria for one-hot encoding, which prioritizes nodes that function as hubs within a one-hop radius. However, one-hop hubs don't necessarily serve as two-hop hubs. While we haven't identified a performance drop for these two-hop node label counts, an intriguing avenue for future research would be to refine variance reduction strategies for both one-hop and two-hop estimations simultaneously.

\begin{table}
\begin{tabular}{l c c c c c} \hline \hline  & **CS** & **Physics** & **Computers** & **Photo** & **Collab** \\ \hline
**GCN** & \(66.00\pm_{2.90}\) & \(73.71\pm_{2.28}\) & \(22.95\pm_{10.58}\) & \(28.14\pm_{7.81}\) & \(35.53\pm_{2.39}\) \\
**GCN(random feat)** & \(51.67\pm_{2.70}\) & \(69.55\pm_{2.45}\) & \(35.86\pm_{3.17}\) & \(46.84\pm_{2.53}\) & \(17.25\pm_{1.15}\) \\ \hline
**SAGE** & \(57.79\pm_{18.23}\) & \(74.10\pm_{2.51}\) & \(1.86\pm_{2.53}\) & \(5.70\pm_{10.15}\) & \(36.82\pm_{7.41}\) \\
**SAGE(random feat)** & \(11.78\pm_{1.62}\) & \(64.71\pm_{3.65}\) & \(29.23\pm_{3.92}\) & \(39.94\pm_{3.41}\) & \(28.87\pm_{2.36}\) \\ \hline \hline  & \multicolumn{4}{c}{**Random feat**} \\ \hline
**GCN(\(F=1000\))** & \(3.73\pm_{1.44}\) & \(49.28\pm_{2.74}\) & \(36.92\pm_{3.36}\) & \(48.72\pm_{3.84}\) & \(31.93\pm_{2.10}\) \\
**GCN(\(F=2000\))** & \(24.97\pm_{2.67}\) & \(49.13\pm_{4.64}\) & \(40.24\pm_{3.04}\) & \(53.49\pm_{3.50}\) & \(40.16\pm_{1.70}\) \\
**GCN(\(F=3000\))** & \(39.51\pm_{6.47}\) & \(53.76\pm_{3.85}\) & \(42.33\pm_{3.82}\) & \(56.27\pm_{3.47}\) & \(47.22\pm_{1.60}\) \\
**GCN(\(F=4000\))** & \(43.23\pm_{3.37}\) & \(61.86\pm_{4.10}\) & \(42.85\pm_{3.60}\) & \(56.87\pm_{3.59}\) & \(50.40\pm_{1.28}\) \\
**GCN(\(F=5000\))** & \(48.25\pm_{3.28}\) & \(63.19\pm_{4.31}\) & \(44.52\pm_{2.78}\) & \(58.13\pm_{3.79}\) & \(52.13\pm_{1.02}\) \\
**GCN(\(F=6000\))** & \(51.44\pm_{1.50}\) & \(65.10\pm_{4.11}\) & \(44.90\pm_{2.74}\) & \(58.10\pm_{3.35}\) & \(53.78\pm_{0.84}\) \\
**GCN(\(F=7000\))** & \(52.00\pm_{1.74}\) & \(66.76\pm_{3.32}\) & \(45.11\pm_{3.69}\) & \(57.41\pm_{2.62}\) & \(55.04\pm_{1.06}\) \\
**GCN(\(F=8000\))** & \(54.21\pm_{3.47}\) & \(69.27\pm_{2.94}\) & \(44.47\pm_{4.11}\) & \(58.67\pm_{3.90}\) & \(55.36\pm_{1.15}\) \\
**GCN(\(F=9000\))** & \(53.16\pm_{2.80}\) & \(70.79\pm_{2.83}\) & \(45.03\pm_{3.13}\) & \(57.15\pm_{3.87}\) & OOM \\
**GCN(\(F=10000\))** & \(55.91\pm_{2.63}\) & \(71.88\pm_{3.29}\) & \(45.26\pm_{1.94}\) & \(58.12\pm_{2.54}\) & OOM \\ \hline \hline \end{tabular}
\end{table}
Table 6: Performance comparison of GNNs using node attributes versus random vectors (Hits@50). For simplicity, all GNNs are configured with two layers.

Regarding the efficiency of estimation,  IMPL consistently demonstrates superior computational efficiency in contrast to ELPH. When we increase the node signature dimension to minimize estimation variance, ELPH's time complexity grows exponentially and becomes impractical. In contrast,  IMPL displays a sublinear surge in estimation duration.

It's also worth noting that ELPH exhausts available memory when the node signature dimension surpasses \(3000\). This constraint arises as ELPH, while estimating structural features, has to cache node signatures for both MinHash and Hyperloglog. Conversely,  IMPL maintains efficiency by caching only one type of node signatures.

### Model enhancement ablation

We investigate the individual performance contributions of three primary components in  IMPL: Shortcut removal, One-hot hubs, and Norm rescaling. To ensure a fair comparison, we maintain consistent hyperparameters across benchmark datasets, modifying only the specific component under evaluation. Moreover, node attributes are excluded from the model's input for this analysis. The outcomes of this investigation are detailed in Table 7 and Table 8.

Among the three components, Shortcut removal emerges as the most pivotal for  IMPL. This highlights the essential role of ensuring the structural distribution of positive links is aligned between the training and testing datasets [29].

Regarding One-hot hubs, while they exhibited strong results in the estimation accuracy evaluations presented in Figure 5 and Figure 9, their impact on the overall performance is relatively subdued. We

\begin{table}
\begin{tabular}{l c c c c c c c c} \hline \hline  & **USAir** & **NS** & **PB** & **Yeast** & **Cele** & **Power** & **Router** & **E.coli** \\ \hline
**w/o Shortcut removal** & \(80.94_{3.49}\) & \(85.47_{2.60}\) & \(49.51_{3.57}\) & \(82.62_{0.99}\) & \(57.51_{2.00}\) & \(19.99_{2.54}\) & \(36.67_{10.03}\) & \(76.94_{11.54}\) \\
**w/o One-hot hubs** & \(84.04_{14.53}\) & \(89.45_{2.60}\) & \(51.49_{2.63}\) & \(85.11_{1.062}\) & \(68.65_{3.04}\) & \(29.54_{1.79}\) & \(50.81_{3.74}\) & \(79.07_{2.47}\) \\
**w/o Norm rescaling** & \(85.04_{14.64}\) & \(89.34_{2.79}\) & \(82.50_{2.00}\) & \(83.01_{11.03}\) & \(66.81_{3.41}\) & \(29.00_{2.00}\) & \(50.43_{2.59}\) & \(79.36_{2.18}\) \\
**MPLP** & \(\mathbf{85.19_{4.59}}\) & \(\mathbf{89.58_{2.60}}\) & \(\mathbf{52.84_{3.39}}\) & \(\mathbf{85.11_{1.062}}\) & \(\mathbf{67.97_{2.96}}\) & \(\mathbf{29.54_{1.79}}\) & \(\mathbf{51.04_{4.03}}\) & \(\mathbf{79.35_{2.35}}\) \\ \hline \hline \end{tabular}
\end{table}
Table 7: Ablation study on non-attributed benchmarks evaluated by Hits@50. The format is average score \(\pm\) standard deviation. The top three models are colored by **First**, **Second**, **Third**.

\begin{table}
\begin{tabular}{l c c c c c c} \hline \hline  & **CS** & **Physics** & **Computers** & **Photo** & **Collab** \\ \hline
**w/o Shortcut removal** & \(41.63_{7.27}\) & \(62.58_{2.40}\) & \(32.74_{3.03}\) & \(52.09_{2.52}\) & \(60.45_{1.44}\) \\
**w/o One-hot hubs** & \(\mathbf{65.49_{4.28}}\) & \(\mathbf{71.58_{2.28}}\) & \(\mathbf{36.09_{4.08}}\) & \(\mathbf{55.63_{2.48}}\) & \(\mathbf{65.07_{0.47}}\) \\
**w/o Norm rescaling** & \(65.20_{2.92}\) & \(67.73_{2.54}\) & \(35.83_{3.24}\) & \(52.59_{3.57}\) & \(63.99_{0.59}\) \\
**MPLP** & \(\mathbf{65.70_{3.86}}\) & \(\mathbf{71.03_{3.55}}\) & \(\mathbf{37.56_{3.57}}\) & \(\mathbf{55.63_{2.48}}\) & \(\mathbf{66.07_{0.47}}\) \\ \hline \hline \end{tabular}
\end{table}
Table 8: Ablation study on attributed benchmarks evaluated by Hits@50. The format is average score \(\pm\) standard deviation. The top three models are colored by **First**, **Second**, **Third**.

Figure 9: MSE of estimation for #\((2,2)\), #\((2,0)\) and estimation time on Collab. Lower values are better.

hypothesize that, in the context of these sparse benchmark graphs, the estimation variance may not be sufficiently influential on the model's outcomes.

Finally, Norm rescaling stands out as a significant enhancement in MPLP. This is particularly evident in its positive impact on datasets like Yeast, Physics, Photo, and Collab.

### Structural features ablation

We further examine the contribution of various structural features to the link prediction task. These features include: #\((1,1)\), #\((1,2)\), #\((1,0)\), #\((2,2)\), #\((2,0)\), and #\((\triangle)\). To ensure fair comparison, we utilize only the structural features for link representation, excluding the node representations derived from \(\text{GNN}(\cdot)\). Given the combinatorial nature of these features, they are grouped into four categories:

\begin{table}
\begin{tabular}{l c c c c c c c c} \hline Configurations & **USAir** & **NS** & **PB** & **Yeast** & **C.ele** & **Power** & **Router** & **E.coli** \\ \hline \(\mathbf{(1)}\) & \(76.64\pm_{26.74}\) & \(75.26\pm_{27.9}\) & \(37.48\pm_{13.30}\) & \(58.70\pm_{30.50}\) & \(46.22\pm_{24.84}\) & \(14.40\pm_{1.40}\) & \(17.29\pm_{3.96}\) & \(60.10\pm_{30.80}\) \\ \(\mathbf{(2)}\) & \(82.54\pm_{41.61}\) & \(84.76\pm_{3.63}\) & \(41.84\pm_{15.51}\) & \(80.56\pm_{0.05}\) & \(56.22\pm_{20.39}\) & \(21.38\pm_{1.46}\) & \(48.97\pm_{3.31}\) & \(67.78\pm_{3.83}\) \\ \(\mathbf{(3)}\) & \(67.76\pm_{23.65}\) & \(70.05\pm_{23.48}\) & \(44.18\pm_{2.63}\) & \(67.02\pm_{2.53}\) & \(55.63\pm_{19.86}\) & \(52.44\pm_{0.47}\) & \(21.32\pm_{2.66}\) & \(56.59\pm_{1.78}\) \\ \(\mathbf{(4)}\) & \(37.18\pm_{37.57}\) & \(25.31\pm_{39.19}\) & \(22.35\pm_{15.76}\) & \(7.42\pm_{18.0}\) & \(30.75\pm_{18.69}\) & \(5.47\pm_{13.10}\) & \(30.47\pm_{1.30}\) & \(34.90\pm_{6.63}\) \\ \(\mathbf{(5)}\) & \(86.24\pm_{27.70}\) & \(84.91\pm_{20.80}\) & \(48.35\pm_{37.86}\) & \(84.42\pm_{0.56}\) & \(66.69\pm_{36.80}\) & \(22.25\pm_{1.39}\) & \(49.68\pm_{37.80}\) & \(80.94\pm_{1.62}\) \\ \(\mathbf{(6)}\) & \(77.74\pm_{27.57}\) & \(70.09\pm_{20.92}\) & \(46.05\pm_{27.67}\) & \(74.70\pm_{1.45}\) & \(46.88\pm_{37.9}\) & \(27.74\pm_{3.23}\) & \(22.37\pm_{2.66}\) & \(71.41\pm_{1.47}\) \\ \(\mathbf{(7)}\) & \(71.11\pm_{25.51}\) & \(76.72\pm_{23.37}\) & \(35.47\pm_{37.70}\) & \(73.88\pm_{1.23}\) & \(54.99\pm_{20.14}\) & \(14.50\pm_{1.61}\) & \(31.26\pm_{2.87}\) & \(80.22\pm_{2.09}\) \\ \(\mathbf{(8)}\) & \(80.16\pm_{24.82}\) & \(88.67\pm_{27.22}\) & \(51.26\pm_{25.25}\) & \(82.52\pm_{0.85}\) & \(63.28\pm_{24.22}\) & \(28.41\pm_{2.00}\) & \(50.97\pm_{3.57}\) & \(77.26\pm_{1.31}\) \\ \(\mathbf{(9)}\) & \(75.13\pm_{26.51}\) & \(87.28\pm_{33.38}\) & \(41.80\pm_{34.34}\) & \(80.49\pm_{0.97}\) & \(60.63\pm_{34.54}\) & \(28.35\pm_{1.37}\) & \(49.78\pm_{3.56}\) & \(76.13\pm_{1.81}\) \\ \(\mathbf{(10)}\) & \(76.82\pm_{24.78}\) & \(77.43\pm_{37.40}\) & \(45.42\pm_{27.77}\) & \(67.43\pm_{34.20}\) & \(41.66\pm_{31.47}\) & \(26.65\pm_{15.47}\) & \(28.31\pm_{2.76}\) & \(70.14\pm_{104.77}\) \\ \(\mathbf{(11)}\) & \(82.82\pm_{5.52}\) & \(88.91\pm_{29.59}\) & \(52.57\pm_{30.50}\) & \(84.61\pm_{0.67}\) & \(67.11\pm_{27.52}\) & \(28.98\pm_{1.73}\) & \(50.63\pm_{37.2}\) & \(80.16\pm_{2.20}\) \\ \(\mathbf{(12)}\) & \(87.29\pm_{10.88}\) & \(88.08\pm_{25.95}\) & \(48.86\pm_{34.24}\) & \(54.99\pm_{0.60}\) & \(66.06\pm_{37.44}\) & \(23.79\pm_{1.87}\) & \(50.06\pm_{3.66}\) & \(79.57\pm_{2.46}\) \\ \(\mathbf{(13)}\) & \(78.21\pm_{24.74}\) & \(88.08\pm_{37.27}\) & \(46.00\pm_{23.1}\) & \(74.88\pm_{24.29}\) & \(34.64\pm_{4.49}\) & \(28.28\pm_{21.29}\) & \(26.24\pm_{21.8}\) & \(74.67\pm_{3.96}\) \\ \(\mathbf{(14)}\) & \(80.75\pm_{50.22}\) & \(89.14\pm_{23.88}\) & \(51.63\pm_{27.67}\) & \(82.68\pm_{0.67}\) & \(63.01\pm_{31.21}\) & \(29.41\pm_{1.44}\) & \(51.08\pm_{4.12}\) & \(76.88\pm_{1.86}\) \\ \(\mathbf{(15)}\) & \(81.06\pm_{6.62}\) & \(98.73\pm_{2.12}\) & \(53.49\pm_{2.66}\) & \(85.06\pm_{0.60}\) & \(60.41\pm_{3.02}\) & \(28.86\pm_{2.40}\) & \(50.63\pm_{3.37}\) & \(78.91\pm_{2.58}\) \\ \hline \end{tabular}
\end{table}
Table 10: Ablation analysis highlighting the impact of various structural features on link prediction. Refer to Table 9 for detailed configurations of the structural features used.

\begin{table}
\begin{tabular}{l c c c c c} \hline Configurations & \#\((1,1)\) & \#\((1,2)\) & \#\((1,0)\) & \#\((2,2)\) & \#\((2,0)\) & \#\((\triangle)\) \\ \hline \(\mathbf{(1)}\) & & & - & - & - & - & - \\ \(\mathbf{(2)}\) & & & & & - & - & - \\ \(\mathbf{(3)}\) & & - & & - & & \(\diagupup\) & & - \\ \(\mathbf{(4

[MISSING_PAGE_FAIL:25]

For GCN:

\[\mathbb{E}(\bm{h}_{u}\cdot\bm{h}_{v})=\frac{C}{\sqrt{\hat{d}_{u}\hat{d}_{v}}}\sum_{ k\in\mathcal{N}_{u}\bigcap\mathcal{N}_{v}}\frac{1}{\hat{d}_{k}},\]

For SAGE:

\[\mathbb{E}(\bm{h}_{u}\cdot\bm{h}_{v})=\frac{C}{\sqrt{d_{u}\hat{d}_{v}}}\sum_{k \in\mathcal{N}_{u}\bigcap\mathcal{N}_{v}}1,\]

where \(\hat{d}_{v}=d_{v}+1\) and the constant \(C\) is defined as \(C=\sigma_{node}^{2}\sigma_{weight}^{2}FF^{\prime}\).

Proof.: Define \(\bm{X}\) as \(\left(\bm{X}_{1}^{\top},\ldots,\bm{X}_{N}^{\top}\right)^{\top}\) and \(\bm{W}\) as \((\bm{W}_{1},\bm{W}_{2},\ldots,\bm{W}_{F})\).

Using GCN as the MPNN, the node representation is updated by:

\[\bm{h}_{u}=\bm{W}\sum_{k\in\mathcal{N}(u)\cup\{u\}}\frac{1}{\sqrt{\hat{d}_{k} \hat{d}_{u}}}\bm{X}_{k},\]

where \(\hat{d}_{v}=d_{v}+1\).

\begin{table}
\begin{tabular}{l c c c c c c} \hline \hline  & **CS** & **Physics** & **Computers** & **Photo** \\ \hline
**MPLP(\(F=256\))** & \(74.90\pm_{1.88}\) & \(73.91\pm_{1.41}\) & \(40.65\pm_{3.24}\) & \(55.13\pm_{2.98}\) \\
**MPLP(\(F=512\))** & \(74.67\pm_{2.63}\) & \(74.49\pm_{2.05}\) & \(39.36\pm_{2.28}\) & \(55.93\pm_{3.31}\) \\
**MPLP(\(F=1024\))** & \(75.02\pm_{2.68}\) & \(75.27\pm_{2.95}\) & \(42.27\pm_{3.96}\) & \(55.89\pm_{3.03}\) \\
**MPLP(\(F=2048\))** & \(75.30\pm_{2.14}\) & \(75.82\pm_{2.15}\) & \(41.98\pm_{3.21}\) & \(57.11\pm_{2.56}\) \\
**MPLP(\(F=4096\))** & \(76.04\pm_{1.57}\) & \(76.17\pm_{2.04}\) & \(43.33\pm_{2.93}\) & \(58.55\pm_{2.47}\) \\ \hline \hline \end{tabular}
\end{table}
Table 14: Ablation study of Node Signature Dimension (\(F\)) on attributed benchmarks evaluated by Hits@50. The format is average score \(\pm\) standard deviation. The top three models are colored by **First**, **Second**, **Third**.

\begin{table}
\begin{tabular}{l c c c c c} \hline \hline  & **CS** & **Physics** & **Computers** & **Photo** \\ \hline
**MPLP(\(B=256\))** & \(74.96\pm_{1.87}\) & \(76.06\pm_{1.47}\) & \(43.38\pm_{2.83}\) & \(57.58\pm_{2.92}\) \\
**MPLP(\(B=512\))** & \(75.61\pm_{2.25}\) & \(75.38\pm_{1.79}\) & \(42.95\pm_{2.56}\) & \(57.19\pm_{2.51}\) \\
**MPLP(\(B=1024\))** & \(74.89\pm_{2.00}\) & \(74.89\pm_{1.97}\) & \(42.69\pm_{2.41}\) & \(56.97\pm_{3.20}\) \\
**MPLP(\(B=2048\))** & \(75.02\pm_{2.68}\) & \(75.47\pm_{1.68}\) & \(41.39\pm_{2.87}\) & \(55.89\pm_{3.03}\) \\
**MPLP(\(B=4096\))** & \(75.46\pm_{1.78}\) & \(74.88\pm_{2.57}\) & \(40.65\pm_{2.85}\) & \(55.89\pm_{2.88}\) \\
**MPLP(\(B=8192\))** & \(75.26\pm_{1.91}\) & \(74.14\pm_{2.17}\) & \(40.00\pm_{3.40}\) & \(55.90\pm_{2.52}\) \\ \hline \hline \end{tabular}
\end{table}
Table 12: Ablation study of Batch Size (\(B\)) on attributed benchmarks evaluated by Hits@50. The format is average score \(\pm\) standard deviation. The top three models are colored by **First**, **Second**, **Third**.

\begin{table}
\begin{tabular}{l c c c c c c} \hline \hline  & **USAir** & **NS** & **PB** & **Yeast** & **Cele** & **Power** & **Router** & **E.coli** \\ \hline
**MPLP(\(F=256\))** & \(90.64\pm_{2.86}\) & \(85.22\pm_{0.07}\) & \(50.42\pm_{3.66}\) & \(80.63\pm_{0.84}\) & \(70.89\pm_{1.79}\) & \(25.74\pm_{1.09}\) & \(51.84\pm_{2.50}\) & \(84.60\pm_{0.92}\) \\
**MPLP(\(F=512\))** & \(90.49\pm_{1.98}\) & \(89.18\pm_{2.35}\) & \(51.48\pm_{2.63}\) & \(82.41\pm_{1.10}\) & \(70.91\pm_{4.68}\) & \(27.58\pm_{1.60}\) & \(51.98\pm_{4.38}\) & \(84.70\pm_{1.38}\) \\
**MPLP(\(F=1024\))** & \(90.16\pm_{0.61}\) & \(89.40\pm_{1.22}\) & \(50.60\pm_{3.40}\) & \(83.87\pm_{1.06}\) & \(70.61\pm_{4.13}\) & \(28.88\pm_{2.24}\) & \(53.92\pm_{2.88}\) & \(84.81\pm_{0.85}\) \\
**MPLP(\(F=2048\))** & \(90.14\pm_{2.24}\) & \(89.36\pm_{1.02}\) & \(51.26\pm_{1.07}\) & \(84.20\pm_{1.02}\) & \(72.44\pm_{3.81}\) & \(29.27\pm_{1.92}\) & \(54.50\pm_{4.52}\) & \(84.58\pm_{1.42}\) \\
**MPLP(\(F=4096\))** & \(89.95\pm_{1.48}\) & \(89.54\pm_{1.22}\) & \(51.07\pm_{2.87}\) & \(84.89\pm_{1.06}\) & \(71.91\pm_{3.52}\) & \(29.26\pm_{1.51}\) & \(54.71\pm_{1.57}\) & \(84.67\pm_{0.63}\) \\ \hline \hline \end{tabular}
\end{table}
Table 13: Ablation study of Node Signature Dimension (\(F\)) on non-attributed benchmarks evaluated by Hits@50. The format is average score \(\pm\) standard deviation. The top three models are colored by **First**, **Second**, **Third**.

For any two nodes \((u,v)\) from \(\{(u,v)|(u,v)\in V\times V\setminus E\}\), we compute:

\[\bm{h}_{u}\cdot\bm{h}_{v} =\bm{h}_{u}^{\top}\bm{h}_{v}\] \[=\left(\bm{W}\sum_{a\in\mathcal{N}(u)\cup\{u\}}\frac{1}{\sqrt{ \hat{d}_{a}\hat{d}_{u}}}\bm{X}_{a}\right)^{\top}\left(\bm{W}\sum_{b\in\mathcal{ N}(v)\cup\{v\}}\frac{1}{\sqrt{\hat{d}_{b}\hat{d}_{v}}}\bm{X}_{b}\right)\] \[=\sum_{a\in\mathcal{N}(u)\cup\{u\}}\frac{1}{\sqrt{\hat{d}_{a}\hat {d}_{u}}}\bm{X}_{a}^{\top}\bm{W}^{\top}\bm{W}\sum_{b\in\mathcal{N}(v)\cup\{v\}} \frac{1}{\sqrt{\hat{d}_{b}\hat{d}_{v}}}\bm{X}_{b}\] \[=\sum_{a\in\mathcal{N}(u)\cup\{u\}}\frac{1}{\sqrt{\hat{d}_{a}\hat {d}_{u}}}\bm{X}_{a}^{\top}\begin{pmatrix}\bm{W}_{1}^{\top}\bm{W}_{1}&\cdots&\bm {W}_{1}^{\top}\bm{W}_{F}\\ \vdots&\vdots&\vdots\\ \bm{W}_{F}^{\top}\bm{W}_{1}&\cdots&\bm{W}_{F}^{\top}\bm{W}_{F}\end{pmatrix}\sum _{b\in\mathcal{N}(v)\cup\{v\}}\frac{1}{\sqrt{\hat{d}_{b}\hat{d}_{v}}}\bm{X}_{b}.\]

Given that

1. \(\mathbb{E}\big{(}\bm{W}_{i}^{\top}\bm{W}_{j}\big{)}=\sigma_{weight}^{2}F^{\prime}\) when \(i=j\),
2. \(\mathbb{E}\big{(}\bm{W}_{i}^{\top}\bm{W}_{j}\big{)}=0\) when \(i\neq j\),

we obtain:

\[\mathbb{E}(\bm{h}_{u}\cdot\bm{h}_{v})=\sigma_{weight}^{2}F^{\prime}\sum_{a\in \mathcal{N}(u)\cup\{u\}}\frac{1}{\sqrt{\hat{d}_{a}\hat{d}_{u}}}\bm{X}_{a}^{ \top}\sum_{b\in\mathcal{N}(v)\cup\{v\}}\frac{1}{\sqrt{\hat{d}_{b}\hat{d}_{v}} }\bm{X}_{b}.\]

Also the orthogonal of the random vectors guarantee that \(\mathbb{E}\big{(}\bm{X}_{a}^{\top}\bm{X}_{b}\big{)}=0\) when \(a\neq b\). Then, we have:

\[\mathbb{E}(\bm{h}_{u}\cdot\bm{h}_{v})=\frac{C}{\sqrt{\hat{d}_{u}\hat{d}_{v}}} \sum_{k\in\mathcal{N}_{u}\bigcap\mathcal{N}_{v}}\frac{1}{\hat{d}_{k}}\]

where \(C=\sigma_{node}^{2}\sigma_{weight}^{2}FF^{\prime}\).

This completes the proof for the GCN variant. A similar approach, utilizing the probabilistic orthogonality of the input vectors and weight matrix, can be employed to derive the expected value for SAGE as the MPNN. 

### Proof for Theorem 3.2

We begin by restating Theorem 3.2 and then proceed with its proof:

Let \(G=(V,E)\) be a graph, and let the vector dimension be given by \(F\in\mathbb{N}_{+}\). Define the input vectors \(\bm{X}=(X_{i,j})\), which are initialized from a random variable x having a mean of \(0\) and a standard deviation of \(\frac{1}{\sqrt{F}}\). Using the message-passing as described by Equation 3, for any pair of nodes \(\{(u,v)|(u,v)\in V\times V\}\), the expected value and variance of their inner product are:

\[\mathbb{E}(\bm{h}_{u}\cdot\bm{h}_{v}) =\text{CN}(u,v),\] \[\text{Var}(\bm{h}_{u}\cdot\bm{h}_{v}) =\frac{1}{F}\left(d_{u}d_{v}+\text{CN}(u,v)^{2}-2\text{CN}(u,v) \right)+F\text{Var}\big{(}\text{x}^{2}\big{)}\text{CN}(u,v).\]

Proof.: We follow the proof of the theorem in [12]. Based on the message-passing defined in Equation 3:

\[\mathbb{E}(\bm{h}_{u}\cdot\bm{h}_{v}) =\mathbb{E}\Bigg{(}\Bigg{(}\sum_{k_{u}\in\mathcal{N}_{u}}\bm{X}_{ k_{u},:}\Bigg{)}\cdot\Bigg{(}\sum_{k_{v}\in\mathcal{N}_{v}}\bm{X}_{k_{v},:} \Bigg{)}\Bigg{)}\] \[=\mathbb{E}\Bigg{(}\sum_{k_{u}\in\mathcal{N}_{u}}\sum_{k_{v}\in \mathcal{N}_{v}}\bm{X}_{k_{u},:}\bm{X}_{k_{v},:}\Bigg{)}\] \[=\sum_{k_{u}\in\mathcal{N}_{u}}\sum_{k_{v}\in\mathcal{N}_{v}} \mathbb{E}(\bm{X}_{k_{u},:}\bm{X}_{k_{v},:}).\]

[MISSING_PAGE_EMPTY:28]

### Proof for Theorem 3.3

We begin by restating Theorem 3.3 and then proceed with its proof:

Under the conditions defined in Theorem 3.2, let \(\bm{h}_{u}^{(l)}\) denote the vector for node \(u\) after the \(l\)-th message-passing iteration. We have:

\[\mathbb{E}\Big{(}\bm{h}_{u}^{(p)}\cdot\bm{h}_{v}^{(q)}\Big{)}=\sum_{k\in V}| \text{walks}^{(p)}(k,u)||\text{walks}^{(q)}(k,v)|,\]

where \(|\text{walks}^{(l)}(u,v)|\) counts the number of length-\(l\) walks between nodes \(u\) and \(v\).

Proof.: Reinterpreting the message-passing described in Equation 3, we can equivalently express it as:

\[\text{ms}_{v}^{(l+1)}=\bigcup_{u\in\mathcal{N}_{v}}\text{ms}_{u}^{(l)},\bm{h} _{v}^{(l+1)}=\sum_{u\in\text{ms}_{v}^{(l+1)}}\bm{h}_{u}^{(0)},\] (9)

where \(\text{ms}_{v}^{(l)}\) refers to a multiset, a union of multisets from its neighbors. Initially, \(\text{ms}_{v}^{(0)}=\{\{v\}\}\). The node vector \(\bm{h}_{v}^{(l)}\) is derived by summing the initial QO vectors of the multiset's elements.

We proceed by induction: Base Case (\(l=1\)):

\[\text{ms}_{v}^{(1)}=\bigcup_{u\in\mathcal{N}_{v}}\text{ms}_{u}^{(0)}=\bigcup_ {u\in\mathcal{N}_{v}}\{\{u\}\}=\{\{k|\omega\in\text{walks}^{(1)}(k,v)\}\}\]

Inductive Step (\(l\geq 1\)): Let's assume that \(\text{ms}_{v}^{(l)}=\{\{k|\omega\in\text{walks}^{(l)}(k,v)\}\}\) holds true for an arbitrary \(l\). Utilizing Equation 9 and the inductive hypothesis, we deduce:

\[\text{ms}_{v}^{(l+1)}=\bigcup_{u\in\mathcal{N}_{v}}\{\{k|\omega\in\text{walks }^{(l)}(k,u)\}\}.\]

If \(k\) initiates the \(l\)-length walks terminating at \(v\) and if \(v\) is adjacent to \(u\), then \(k\) must similarly initiate the \(l\)-length walks terminating at \(u\). This consolidates our inductive premise.

With the induction established:

\[\mathbb{E}\Big{(}\bm{h}_{u}^{(p)}\cdot\bm{h}_{v}^{(q)}\Big{)}=\mathbb{E}\! \left(\sum_{k_{u}\in\text{ms}_{u}^{(p)}}\bm{h}_{k_{u}}^{(0)}\cdot\sum_{k_{v} \in\text{ms}_{v}^{(q)}}\bm{h}_{k_{v}}^{(0)}\right)\]

The inherent independence among node vectors concludes the proof. 

## Appendix H Limitations

Despite the promising capabilities of MPLP, there are distinct limitations that warrant attention:

1. Training cost vs. inference cost: The computational cost during training significantly outweighs that of inference. This arises from the necessity to remove shortcut edges for positive links in the training phase, causing the graph structure to change across different batches. This, in turn, mandates a repeated computation of the shortest-path neighborhood. Even though MPLP+ can avoid the computation of the shortest-path neighborhood for each batch, it shows suboptimal performance compared to MPLP. A potential remedy is to consider only a subset of links in the graph as positive instances and mask them, enabling a single round of preprocessing. Exploring this approach will be the focus of future work.
2. Estimation variance influenced by graph structure: The structure of the graph itself can magnify the variance of our estimations. Specifically, in dense graphs or those with a high concentration of hubs, the variance can become substantial, thereby compromising the accuracy of structural feature estimation.
3. Optimality of estimating structural features: Our research demonstrates the feasibility of using message-passing to derive structural features. However, its optimality remains undetermined. Message-passing, by nature, involves sparse matrix multiplication operations, which can pose challenges in terms of computational time and space, particularly for exceedingly large graphs.

Broader Impact

Our study is centered on creating a more efficient and expressive method for link prediction, with the goal of significantly advancing graph machine learning. The potential applications of our method are diverse and impactful, extending to recommendation systems, social network analysis, and biological interaction networks, among others. While we have not identified any inherent biases in our method, we acknowledge the necessity of rigorous bias assessments, particularly when integrating our method into industrial-scale applications.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The claims made in abstract and introduction clearly reflect the contribution. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The limitation is discussed in Appendix H. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. 3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: The proof is rigorously shown in the Appendix.

Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The experimental details are extensively discussed in the main body and appendix. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: The code and data are publicly available. The code is open source. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: The experimental settings are discussed in the main body and the appendix. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: The error bars are clearly reported in the experimental results. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean.

* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The compute resource is discussed in Appendix D.4. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Yes, the research conforms with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: Broader impact is discussed in Appendix I. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This study is not feasible for safeguards. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: It is all properly cited. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?Answer: [NA] Justification: No new asset is introduced. Guidelines:

* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: No crowdsourcing experiments or research with human subjects are used in this study. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: No human participants in this study. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. * We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. * For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.