# Wasserstein convergence of Cech persistence diagrams for samplings of submanifolds

Charles Arnal

Universite Paris-Saclay, Inria

&David Cohen-Steiner

Universite Cote d'Azur, Inria

&Vincent Divol

CREST, ENSAE

Equal contribution

###### Abstract

Cech Persistence diagrams (PDs) are topological descriptors routinely used to capture the geometry of complex datasets. They are commonly compared using the Wasserstein distances \(\operatorname{OT}_{p}\); however, the extent to which PDs are stable with respect to these metrics remains poorly understood. We partially close this gap by focusing on the case where datasets are sampled on an \(m\)-dimensional submanifold of \(\mathbb{R}^{d}\). Under this manifold hypothesis, we show that convergence with respect to the \(\operatorname{OT}_{p}\) metric happens exactly when \(p>m\). We also provide improvements upon the bottleneck stability theorem in this case and prove new laws of large numbers for the total \(\alpha\)-persistence of PDs. Finally, we show how these theoretical findings shed new light on the behavior of the feature maps on the space of PDs that are used in ML-oriented applications of Topological Data Analysis.

## 1 Introduction

Topological Data Analysis (TDA) is a set of tools that aims at extracting relevant topological information from complex datasets, e.g. regarding connected components, loops, cavities, or higher dimensional features. These different notions are made formal through the use of _homology theory_, and in particular the _\(i\)-th homology group_\(H_{i}(\mathsf{A})\) of a set \(\mathsf{A}\), which captures the \(i\)-dimensional topological features of \(\mathsf{A}\) for \(i\geq 0\), see e.g. [46] or Appendix B. TDA has been successfully applied in a variety of domains, including material science [51, 63, 30, 17], biology [21, 68, 8], real algebraic geometry [29, 35, 28, 44] and neuroscience [67, 61, 18], to name a few. When used in conjunction with more traditional approaches such as neural networks, TDA-based methods have outperformed state of the arts methods for tasks such as graph classifications [19, 50].

The most prominent techniques in TDA rely on multiscale approaches, in particular through the use of _persistent homology_[22]. Given a compact set \(\mathsf{A}\) in \(\mathbb{R}^{d}\), persistent homology tracks the evolution of the homology groups \(H_{i}(\mathsf{A}^{t})\) of the \(t\)-offset \(\mathsf{A}^{t}=\bigcup_{x\in\mathsf{A}}\overline{B}(x,t)\) of \(\mathsf{A}\) as \(t\) goes from \(0\) to \(+\infty\) (where \(\overline{B}(x,t)\) is the closed ball of radius \(t\) centered at \(x\)). The process is summarized by the _Cech persistence diagram (PD) of degree \(i\)_ of the set \(\mathsf{A}\): the PD \(\operatorname{dgm}_{i}(\mathsf{A})\) is a multiset2 of points in the half-plane \(\Omega:=\{(u_{1},u_{2})\in\mathbb{R}^{2}:\ u_{1}<u_{2}\}\), where each point \((u_{1},u_{2})\) in the PD corresponds to a \(i\)-dimensional topological feature that appeared in \(\mathsf{A}^{t}\) at scale \(t=u_{1}\) (its birth time) and disappeared at scale \(t=u_{2}\) (its death time), see Figure 1.3 Points close to thediagonal \(\partial\Omega=\{(u_{1},u_{2})\in\mathbb{R}^{2}:\ u_{1}=u_{2}\}\) correspond to topological features of small _persistence_\(\mathrm{pers}(u)=\frac{u_{2}-u_{1}}{2}\), which have a short lifetime in the filtration \((\mathsf{A}^{t})_{t\geq 0}\).

A key property of PDs is their robustness to small perturbation in the data, making them suitable for analyzing real-world datasets. This stability property is phrased in terms of the _bottleneck distance_ between PDs [36]. Let \(a\) and \(b\) be two PDs. A _partial matching_ between \(a\) and \(b\) is a bijection of multisets \(\gamma:a\cup\partial\Omega\to b\cup\partial\Omega\), where each point \((u,u)\) of \(\partial\Omega\) has infinite multiplicity. In other words, the points of \(a\) are either paired with a single point of \(b\), or mapped to the diagonal \(\partial\Omega\) (and similarly for the points of \(b\)). Let \(\Gamma(a,b)\) be the set of all partial matchings between \(a\) and \(b\). The bottleneck distance is defined as

\[\mathrm{OT}_{\infty}(a,b)=\inf_{\gamma\in\Gamma(a,b)}\max_{u\in\omega\cup \partial\Omega}\|u-\gamma(u)\|_{\infty}.\] (1)

The Bottleneck Stability Theorem [26, 22] states that if \(\mathsf{A}_{1}\) and \(\mathsf{A}_{2}\) are two compact sets, then for any integer \(i\geq 0\)

\[\mathrm{OT}_{\infty}(\mathrm{dgm}_{i}(\mathsf{A}_{1}),\mathrm{dgm}_{i}( \mathsf{A}_{2}))\leq\varepsilon,\] (2)

where \(\varepsilon\) is the Hausdorff distance between the sets \(\mathsf{A}_{1}\) and \(\mathsf{A}_{2}\), defined by \(d_{H}(\mathsf{A}_{1},\mathsf{A}_{2})=\sup_{x\in\mathbb{R}^{d}}|d_{\mathsf{A}_{ 1}}(x)-d_{\mathsf{A}_{2}}(x)|\) and where \(d_{\mathsf{A}}\) is the distance function to a set \(\mathsf{A}\). An important property of the bottleneck distance is that it is blind to small-persistence topological features: if \(\mathrm{OT}_{\infty}(a,b)=\varepsilon\), then one can arbitrarily modify the PDs \(a\) and \(b\) on a slab of width \(\varepsilon\) above the diagonal (for the \(\ell_{\infty}\)-metric) without changing the bottleneck distance between the two PDs.

Due to this phenomenon, the bottleneck distance turns out to be too weak in many situations of interest, where some topological features of small persistence can be as important as large-scale topological features in the PD (say, with a classification or a regression task in mind). For this reason, finer transport-like distances are often preferred to compare PDs. These distances, which we denote as \(\mathrm{OT}_{p}\), are defined for \(1\leq p<\infty\) by

\[\mathrm{OT}_{p}(a,b)=\inf_{\gamma\in\Gamma(a,b)}\left(\sum_{u\in a\cup \partial\Omega}\|u-\gamma(u)\|_{\infty}^{p}\right)^{1/p},\] (3)

with \(\mathrm{OT}_{p}\leq\mathrm{OT}_{p^{\prime}}\) for \(1\leq p^{\prime}\leq p<\infty\). They can be seen as modified versions of the Wasserstein distances used in optimal transport, with the diagonal \(\partial\Omega\) playing the role of a landfill of infinite mass, see e.g. [33].

The increased sensitivity to small perturbations of the \(\mathrm{OT}_{p}\) distances is of crucial importance in the standard TDA pipeline, which we briefly recall. Starting from a sample of sets \(\mathsf{A}_{1},\dots,\mathsf{A}_{n}\), one computes a sample of PDs \(a_{j}=\mathrm{dgm}_{i}(\mathsf{A}_{j})\), \(j=1,\dots,n\). Statistical methods to analyze this sample of PDs are typically awkward to define, due to the nonlinear geometry of the space of PDs [16, 75]. To overcome this issue, the space of PDs is mapped to a vector space through some map \(\Phi\) called a feature map. Statistical method are then applied in the feature space on the transformed sample \(\Phi(a_{1}),\dots,\Phi(a_{n})\). Various feature maps have been designed [23, 60, 25, 54, 20, 70, 53, 48], important examples including persistent images [4], PersLay [19], and PLLay [50]; in the latter two, the feature map is parametrized by a neural network. A good feature map should preserve as much as possible the geometry of the space of PDs [57]; in particular, Lipschitz (or Holder) continuity of the feature map is a basic requirement. However, due to their (often desirable) sensitivity to small scale

Figure 1: The Čech PD of a point cloud \(\mathsf{A}\) in \(\mathbb{R}^{2}\) for \(i=1\) and its \(t\)-offsets. The two points far from the diagonal \(\partial\Omega\) in \(\mathrm{dgm}_{i}(\mathsf{A})\) correspond to the two large cycles in the set \(\mathsf{A}\).

features, most common feature maps are **not** regular with respect to the \(\mathrm{OT}_{\infty}\) distance on the space of diagrams. Instead, they enjoy Lipschitz regularity with respect to either the finer \(\mathrm{OT}_{1}\) distance (see e.g. [33, Proposition 5.2]), or to the \(\mathrm{OT}_{p}\) distances (for \(p>1\)) when restricted to diagrams \(a\) whose \(\alpha\)-_total persistence_

\[\mathrm{Pers}_{\alpha}(a)=\sum_{u\in a}\mathrm{pers}(u)^{\alpha}\] (4)

is bounded for some \(\alpha>0\) large enough, see [34] and [53]. Boundedness assumptions on the \(\alpha\)-total persistence also yield a version of the Bottleneck Stability Theorem with respect to the finer \(\mathrm{OT}_{p}\) distance: if \(\mathsf{A}_{1}\) and \(\mathsf{A}_{2}\) are such that \(\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}_{k}))\leq M\) (\(k=1,2\)), then, for \(p\geq\alpha\),

\[\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{1}),\mathrm{dgm}_{i}(\mathsf{ A}_{2}))\leq M\varepsilon^{p-\alpha},\] (5)

where \(\varepsilon=d_{H}(\mathsf{A}_{1},\mathsf{A}_{2})\), see [27]. Hence, in addition to having intrinsic theoretical interest, controlling the total persistence and convergence with respect to the \(\mathrm{OT}_{p}\) distance of PDs is crucial to ensure the soundness of most methods commonly used in TDA. This is the subject of this article.

**Contributions.** We provide a deeper understanding of the structure of Cech PDs in the specific case where the underlying set \(\mathsf{A}\) is a compact subset of am \(m\)-dimensional manifold \(\mathsf{M}\) in \(\mathbb{R}^{d}\), focusing in particular on the total persistence of the PDs and their convergence to the PDs of \(\mathsf{M}\) with respect to the \(\mathrm{OT}_{p}\) distances. The importance of this case is supported by the _manifold hypothesis_, which often serves as a fundamental principle guiding the development of algorithms and models for data analysis [41, 76, 15]. Specifically, our main contributions are the following:

* **Theorem 2.2:** When \(\mathsf{A}\subset\mathsf{M}\) is a compact set satisfying \(d_{H}(\mathsf{A},\mathsf{M})\leq\varepsilon\) for \(\varepsilon\) small enough, we provide a quadratic improvement upon the standard Bottleneck Stability Theorem (2). Namely, we show that there exists an optimal bottleneck matching \(\gamma\) such that the distance between a coordinate of a point \(u\in\mathrm{dgm}_{i}(\mathsf{A})\) and the coordinate of the matched point \(\gamma(u)\in\mathrm{dgm}_{i}(\mathsf{M})\cup\partial\Omega\) is of order \(O(\varepsilon^{2})\) whenever the coordinate of \(u\) is larger than \(2\varepsilon\).
* **Theorem 3.3:** In the case where the manifold \(\mathsf{M}\) is generic and the set \(\mathsf{A}\) is a \(\delta\)-sparse point cloud (i.e. \(\min_{x\neq y\in\mathsf{A}}\|x-y\|\geq\delta\)), we provide a finer analysis by showing that the \(p\)-total persistence \(\mathrm{Pers}_{p}(\mathrm{dgm}_{i}(\mathsf{A}))\) remains bounded and the distance \(\mathrm{OT}_{p}(\mathrm{dgm}_{i}(\mathsf{A}),\mathrm{dgm}_{i}(\mathsf{M}))\) converges to \(0\) for all \(p>m\) whenever the ratio \(\varepsilon/\delta\) is upper bounded.
* **Corollary 4.3:** We then focus on a random context, by assuming that \(\mathsf{A}=\mathsf{A}_{n}\) is obtained by sampling \(n\) i.i.d. random variables with positive bounded density \(f\) on a generic manifold \(\mathsf{M}\). We prove that \(\mathrm{OT}_{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_{i}(\mathsf{M}))\) converges in expectation to \(0\) for \(p>m\). Furthermore, we obtain a law of large numbers for the \(\alpha\)-total persistence of \(\mathrm{dgm}_{i}(\mathsf{A}_{n})\): \[\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}_{n}))=\mathrm{Pers}_{ \alpha}(\mathrm{dgm}_{i}(\mathsf{M}))+C_{i}n^{1-\alpha/m}+o_{L^{1}}(n^{1-\alpha /m})+O_{L^{1}}\Big{(}\left(\frac{\log n}{n}\right)^{\frac{1}{m}}\Big{)}\] (6) for all \(\alpha>0\), where \(C_{i}\) is a constant that depends explicitly on \(\mathsf{M}\) and \(f\). In particular, for \(0\leq i<m\), \(\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}_{n}))\) stays bounded if and only if \(\alpha\geq m\).

Our contributions are to be compared to one of the only preexisting results regarding the \(\alpha\)-total persistence of a PD: in [27], the authors proved that for all \(\alpha\) strictly greater than the ambient dimension \(d\), the \(\alpha\)-total persistence of the Cech PD of a compact set \(\mathsf{A}\subset B(0,R)\subset\mathbb{R}^{d}\) satisfies

\[\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}))\leq C_{\alpha,d}R^{\alpha}\] (7)

for some constant \(C_{\alpha,d}\) depending on \(\alpha\) and \(d\). In the two scenarios we considered (either \(\delta\)-sparse or random samples), the ambient dimension \(d\) in the constraint \(\alpha>d\) for the control of the \(\alpha\)-total persistence in (7) has been replaced by the smaller intrinsic dimension \(m\) of the problem: the manifold hypothesis has been successfully exploited.

To summarize, our work sheds light on the behaviour of PDs, provides new guarantees for commonly used ML methods (see e.g. Corollary 4.4), and suggests new heuristics (see Section 5). We also perform various experiments to illustrate the validity of our results and their relevance to the classic TDA pipeline. All proofs are deferred to the Appendix.

**Related work.** This work is part of a long ongoing effort to understand simplicial complexes and PDs in a random context [10, 12, 13, 11, 49, 32, 59, 14, 45]. Closest to our work, Hiraoka, Shiraiand Trinh gave limit laws for Cech PDs for random points in the cube \([0,1]^{d}\)[47], while Goel, Trinh and Tsunoda gave similar asymptotics in the case of samples on manifolds [42]. Limit laws for the total persistence have been obtained by Divol and Polonik in the case of random samples in the cube [34]. Among other contributions, this work generalizes this result to submanifolds: unlike the cube, a manifold has a nontrivial topology; a fact which considerably complicates the situation, for we have to take into account the presence of large topological features in the Cech PDs in order to control the total persistence. Note also that tools other than persistent homology exist for studying the geometry of point clouds. For instance, the authors in [77; 52] consider complete isometric invariants for point clouds that are computable in polynomial time.

## 2 Cech persistence diagrams for subsets of submanifolds

Recall that a fundamental result in TDA, the Bottleneck Stability Theorem (2), states that Cech PDs are stable with respect to Hausdorff perturbations. Consider the particular setting where one has access to a set \(\mathsf{A}\), obtained as an approximation of an unknown shape of interest \(\mathsf{S}\) through some sampling procedure, with \(\mathsf{A}\subset\mathsf{S}\) and \(\sup_{x\in\mathsf{S}}d_{\mathsf{A}}(x)\leq\varepsilon\). The Bottleneck Stability Theorem ensures that \(\mathrm{OT}_{\infty}(\mathrm{dgm}_{i}(\mathsf{A}),\mathrm{dgm}_{i}(\mathsf{S}))\leq\varepsilon\) for any \(i\geq 0\), a bound which cannot be improved in general. However, it turns out that a finer understanding of the proximity between \(\mathrm{dgm}_{i}(\mathsf{A})\) and \(\mathrm{dgm}_{i}(\mathsf{S})\) can be obtained if more regularity is assumed on the shape of interest \(\mathsf{S}\), namely in the situation where \(\mathsf{S}=\mathsf{M}\) is a compact submanifold with positive reach.

Let us first set some notation. Let \(\mathsf{M}\) be an \(m\)-dimensional compact topological submanifold of \(\mathbb{R}^{d}\); we always assume that the boundary of \(\mathsf{M}\) is empty. The orthogonal projection \(\pi_{\mathsf{M}}\) on \(\mathsf{M}\) is defined for \(x\) close enough to \(\mathsf{M}\), and we define the _reach_\(\tau(\mathsf{M})\) as the largest \(r>0\) such that the orthogonal projection \(\pi_{\mathsf{M}}\) is well (i.e. uniquely) defined for all \(x\in\mathbb{R}^{d}\) at distance strictly less than \(r\) from \(\mathsf{M}\). The reach is a key notion to quantify the regularity of a manifold, see e.g. [39] and [24] for more information.

Let \(\mathsf{A}\subset\mathsf{M}\) be such that \(d_{H}(\mathsf{A},\mathsf{M})\leq\varepsilon\) and let \(z\in\mathbb{R}^{d}\). By definition of the Hausdorff distance, it holds that \(|d_{\mathsf{A}}(z)-d_{\mathsf{M}}(z)|\leq\varepsilon\). However, this naive bound can be quadratically improved as long as \(z\) stays far away from \(\mathsf{M}\).

**Lemma 2.1**.: _Let \(\mathsf{M}\subset\mathbb{R}^{d}\) be a compact submanifold with positive reach and let \(\mathsf{A}\subset\mathsf{M}\) be a compact set with \(d_{H}(\mathsf{A},\mathsf{M})\leq\varepsilon\) for some \(\varepsilon>0\). Let \(z\in\mathbb{R}^{d}\backslash\mathsf{M}\). Then, \(|d_{\mathsf{M}}(z)-d_{\mathsf{A}}(z)|\leq\frac{\varepsilon^{2}}{2d_{\mathsf{M }}(z)}\left(1+\frac{d_{\mathsf{M}}(z)}{\tau(\mathsf{M})}\right)\)._

We can build upon this basic remark to obtain a very precise control of the behavior of the Cech PD of the set \(\mathsf{A}\). Namely, we identify three regions in the upper halfplane \(\Omega\) (displayed in Figure 2) which contain all points in the PD \(\mathrm{dgm}_{i}(\mathsf{A})\) (for some integer \(i\geq 0\)). In the first region, corresponding to microscopic topological features disappearing at scales smaller than \(\varepsilon+\varepsilon^{2}/\tau(\mathsf{M})\), the Bottleneck Stability Theorem cannot be improved. However, there exists an optimal matching (i.e. a matching \(\gamma:\mathrm{dgm}_{i}(\mathsf{A})\cup\partial\Omega\to\mathrm{dgm}_{i}( \mathsf{M})\cup\partial\Omega\) that realizes the bottleneck distance (1)) such that at least one of the coordinates of any point in the other two regions is larger than \(\tau(\mathsf{M})-\varepsilon^{2}/\tau(\mathsf{M})\), and the proximity between a large coordinate of a point \(u\in\mathrm{dgm}_{i}(\mathsf{A})\) and the coordinate of the matched point \(\gamma(u)\in\mathrm{dgm}_{i}(\mathsf{M})\cup\partial\Omega\) is of order \(O(\varepsilon^{2})\). This yields a quadratic improvement upon the Bottleneck Stability Theorem.

**Theorem 2.2** (Improved Bottleneck Stability Theorem).: _Let \(\mathsf{M}\subset\mathbb{R}^{d}\) be a compact submanifold with positive reach and let \(\mathsf{A}\subset\mathsf{M}\) be a compact set such that \(d_{H}(\mathsf{A},\mathsf{M})\leq\varepsilon<\tau(\mathsf{M})/4\). Let \(i\geq 0\) be an integer. Then \(\mathrm{dgm}_{i}(\mathsf{A})\) is the union of three regions \(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}):=\mathrm{dgm}_{i}(\mathsf{A})\cap\{u_{1}, u_{2}\leq\varepsilon+\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\}\), \(\mathrm{dgm}_{i}^{(2)}(\mathsf{A}):=\mathrm{dgm}_{i}(\mathsf{A})\cap\{u_{1}\leq \varepsilon,u_{2}\geq\tau(\mathsf{M})-\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\}\) and \(\mathrm{dgm}_{i}^{(3)}(\mathsf{A}):=\mathrm{dgm}_{i}(\mathsf{A})\cap\{u_{1}, u_{2}\geq\tau(\mathsf{M})-\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\}\)._

Figure 2: PDs of \(\mathsf{M}\) (red) and of \(\mathsf{A}\) (black).

_Furthermore, let \(C=\frac{2}{\tau(\mathsf{M})}\left(1+\frac{R(\mathsf{M})}{\tau(\mathsf{M})}\right)\), where \(R(\mathsf{M})\) is the radius of the smallest ball that contains \(\mathsf{M}\). There exists an optimal matching \(\gamma:\operatorname{dgm}_{i}(\mathsf{A})\cup\partial\Omega\to\operatorname{dgm }_{i}(\mathsf{M})\cup\partial\Omega\) for the bottleneck distance between \(\operatorname{dgm}_{i}(\mathsf{A})\) and \(\operatorname{dgm}_{i}(\mathsf{M})\) such that_

* _Region (1): If_ \(u\in\operatorname{dgm}_{i}^{(1)}(\mathsf{A})\)_, then_ \(\gamma(u)\in\partial\Omega\) _and_ \(\|u-\gamma(u)\|_{\infty}\leq\varepsilon\)_._
* _Region (2): If_ \(u\in\operatorname{dgm}_{i}^{(2)}(\mathsf{A})\)_, then_ \(\gamma(u)\) _is of the form_ \((0,v_{2})\) _and_ \(|u_{2}-v_{2}|\leq C\varepsilon^{2}\)_. The number of such points is finite and depends only on_ \(\mathsf{M}\)_._
* _Region (3): If_ \(u\in\operatorname{dgm}_{i}^{(3)}(\mathsf{A})\)_, then_ \(\|u-\gamma(u)\|_{\infty}\leq C\varepsilon^{2}\)_._

Note that for any \(i\geq d\), the \(i\)-th PDs of \(\mathsf{M}\) and \(\mathsf{A}\) are actually trivial.

## 3 Cech persistence diagrams for subsets of generic submanifolds

The improved Bottleneck Stability Theorem (Theorem 2.2) yields information relative to the location of points in the Cech PD of \(\mathsf{A}\), but not about their numbers. However, both the \(\alpha\)-total persistence of \(\operatorname{dgm}_{i}(\mathsf{A})\) and the distance \(\operatorname{OT}_{p}(\operatorname{dgm}_{i}(\mathsf{A}),\operatorname{dgm }_{i}(\mathsf{M}))\) for \(p<\infty\) crucially depend on the number of points in \(\operatorname{dgm}_{i}(\mathsf{A})\) having small persistence.

Unfortunately, no control on, say, the total persistence, can exist without additional assumptions. Indeed, in general, even the \(\alpha\)-total persistence of the Cech PD of the submanifold \(\mathsf{M}\) can be infinite.

**Example 3.1**.: _Let \(f:x\in\mathbb{R}\mapsto 1+x^{4}\sin(1/x)^{2}\). Consider the \(C^{2}\) curve \(\mathsf{M}\) in \(\mathbb{R}^{2}\) defined as the union of the graphs of the functions \(f\) and \(-f\) on \([-2,2]\). Being \(C^{2}\), the curve has a positive reach [39]. For \(i=1\), the Cech PD of \(\mathsf{M}\) contains a sequence of points \((1,\ell_{n})\) for \(n\geq 1\), where \(\ell_{n}=1+\Theta(n^{-4})\). In particular, as \(\sum_{n\geq 1}(\ell_{n}-1)^{\alpha}=+\infty\) for \(\alpha<1/4\), the \(\alpha\)-total persistence of \(\operatorname{dgm}_{1}(\mathsf{M})\) is infinite for such a value of \(\alpha\). By considering the product \(\mathsf{M}^{m}\subset\mathbb{R}^{2m}\), one can also build an \(m\)-dimensional \(C^{2}\) compact submanifold without boundary such that \(\operatorname{dgm}_{1}(\mathsf{M})\) has an infinite \(\alpha\)-total persistence for \(\alpha<m/4\)._

The existence of such counterexamples is explained by the fact that the distance function \(d_{\mathsf{M}}\) to a set \(\mathsf{M}\) is not well-behaved in general, even when the set \(\mathsf{M}\) is smooth. In contrast to this bleak general case, Song, Yim & Monod (in the case of surfaces in \(\mathbb{R}^{3}\)) and Arnal, Cohen-Steiner & Divol (in the general case) studied the distance function \(d_{\mathsf{M}}\) to \(\mathsf{M}\) when \(\mathsf{M}\) is a _generic_ submanifold [6, 71]. Their findings indicate that, although counterexamples such as the one presented in Example 3.1 exist, they are extremely uncommon in a sense which can be made precise.

Namely, given an _abstract_ manifold \(M\), Arnal, Cohen-Steiner and Divol show that the set of \(C^{2}\) embeddings \(\mathsf{M}\) of \(M\) into \(\mathbb{R}^{d}\) such that \(d_{\mathsf{M}}\) satisfies some desirable regularity conditions (described in Appendix C) forms an open and dense set in the set of all \(C^{2}\) embeddings equipped with the \(C^{2}\)-Whitney topology [6, Theorem 1.1]. In what follows, we will simply refer to a \(C^{2}\) compact submanifold \(\mathsf{M}\) such that \(d_{\mathsf{M}}\) satisfies the regularity condition described in Appendix C as _generic_. See Figure 3 for an example.

**Proposition 3.2** (Cech PDs of generic submanifolds).: _Let \(\mathsf{M}\) be a generic submanifold of \(\mathbb{R}^{d}\). Then, for any integer \(i\geq 0\), the PD \(\operatorname{dgm}_{i}(\mathsf{M})\) contains finitely many points. In particular, \(\operatorname{Pers}_{\alpha}(\operatorname{dgm}_{i}(\mathsf{M}))<+\infty\) for all \(\alpha>0\)._

When \(\mathsf{M}\) is a generic submanifold, it becomes a reasonable task to control the number of points in \(\operatorname{dgm}_{i}(\mathsf{A})\) where \(\mathsf{A}\subset\mathsf{M}\) is an approximation of \(\mathsf{M}\) with \(d_{H}(\mathsf{A},\mathsf{M})\leq\varepsilon\). The Bottleneck Stability Theorem implies that when \(\varepsilon\) is small enough (compared to the smallest persistence of a point in \(\operatorname{dgm}_{i}(\mathsf{M})\)), every point of \(\operatorname{dgm}_{i}(\mathsf{M})\) is mapped to a point in \(\operatorname{dgm}_{i}(\mathsf{A})\) by the optimal bottleneck matching, leaving the points of \(\operatorname{dgm}_{i}(\mathsf{A})\) at \(\ell_{\infty}\)-distance to \(\partial\Omega\) less than \(\varepsilon\) unmatched; those will be mapped to the diagonal \(\partial\Omega\). The Improved Bottleneck Stability Theorem 2.2 (see Figure 2) shows that these points are of two kinds: those in Region (1), corresponding to small topological features in the set \(\mathsf{A}\) (of size of order \(O(\varepsilon)\)), and those in Region (3), corresponding to large topological features. There are many points in Region (1) (in fact, our proofs show that when \(\mathsf{A}=\mathsf{A}_{n}\) is a random

Figure 3: A generic torus.

sample of \(n\) points, the number of points in Region (1) is of order \(O(n)\)). In contrast, the genericity hypothesis allows us to show that the number of points in Region (3) is small under reasonable sampling assumptions.

We say that a point cloud \(\mathsf{A}\subset\mathsf{M}\) is _\((\delta,\varepsilon)\)-dense_ in \(\mathsf{M}\) if \(d_{H}(\mathsf{A},\mathsf{M})\leq\varepsilon\) and \(\min_{x\neq y\in\mathsf{A}}\|x-y\|\geq\delta\). Such point clouds naturally occur, e.g. as products of the farthest point sampling algorithm [2].

**Theorem 3.3**.: _Let \(\mathsf{M}\subset\mathbb{R}^{d}\) be a generic compact submanifold and \(\mathsf{A}\subset\mathsf{M}\) be a \((\delta,\varepsilon)\)-dense set in \(\mathsf{M}\) for some \(\varepsilon,\delta>0\). Let \(a\geq\varepsilon/\delta\) and let \(i\geq 0\) be an integer. There exist \(\varepsilon_{0}>0\) depending only on \(\mathsf{M}\) and \(C_{0},C_{1},C_{2},C_{3}\) depending only on \(\mathsf{M}\) and \(a\) such that if \(\varepsilon\leq\varepsilon_{0}\), then \(\mathrm{dgm}_{i}^{(3)}(\mathsf{A})\) has at most \(C_{0}\) points and for all \(p\geq 1\), \(\alpha\geq 0\),_

\[\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}),\mathrm{dgm}_{i} (\mathsf{M}))\leq C_{1}\varepsilon^{p-m}\] (8) \[\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}))\leq C_{2}(C_ {3}^{\alpha}+\varepsilon^{\alpha-m}).\]

In particular, as long as the ratio \(\varepsilon/\delta\) is larger than some constant \(a>0\), the \(\mathrm{OT}_{p}\) distance between \(\mathrm{dgm}_{i}(\mathsf{A})\) and \(\mathrm{dgm}_{i}(\mathsf{M})\) converges to \(0\) for all \(p>m\) as \(\varepsilon\to 0\), while the \(p\)-total persistence \(\mathrm{Pers}_{p}(\mathrm{dgm}_{i}(\mathsf{A}))\) stays bounded.

**Example 3.4**.: _Consider two parallel line segments \(\mathsf{M}\) in \(\mathbb{R}^{2}\), and a finite set \(\mathsf{A}\) consisting of two parallel grids of step \(2\varepsilon\): the set \(\mathsf{A}\) is \((2\varepsilon,\varepsilon)\)-dense in \(\mathsf{M}\). Then, there are \(O(\varepsilon^{-1})\) points in \(\mathrm{dgm}_{1}(\mathsf{A})\) with birth coordinates \(u_{1}\) equal to \(1/2\) and persistence of order \(O(\varepsilon^{2})\); they all belong to \(\mathrm{dgm}_{1}^{(3)}(\mathsf{A})\), whose cardinality is thus not bounded by some \(C_{0}=C_{0}(\mathsf{M})\). This example can be easily modified to make \(\mathsf{M}\) a compact \(C^{2}\)\(1\)-dimensional manifold. This shows that the first conclusion of Theorem 3.3 cannot hold without a genericity assumption on \(\mathsf{M}\)._

## 4 Random samplings of submanifolds

We now turn to the case of random samplings of (non-generic and generic) submanifolds. They tend to adopt configurations that are more regular than what can be expected from e.g. a general \(\varepsilon\)-dense sampling, yet their randomness gives rise to new technical difficulties. Let \(P\) be a probability measure having a density \(f\) (with respect to the volume measure) on a compact submanifold \(\mathsf{M}\) of dimension \(m\geq 1\). Let \(\mathsf{A}=\mathsf{A}_{n}=\{X_{1},\ldots,X_{n}\}\), where \(X_{1},\ldots,X_{n}\) is an i.i.d. sample from distribution \(P\). Let \(i\geq 0\) be an integer; we consider the three regions described in Figure 2 and in the statement of Theorem 2.2, and write again \(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n})\), \(\mathrm{dgm}_{i}^{(2)}(\mathsf{A}_{n})\) and \(\mathrm{dgm}_{i}^{(3)}(\mathsf{A}_{n})\) for the three corresponding PDs. This section is devoted to the study of the probabilistic asymptotic behaviour of these three random PDs, which can be decomposed into two almost independent questions: \(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n})\) only depends on small-scale phenomena and can essentially be reduced to the case of a cube, even if \(\mathsf{M}\) is non-generic, while \(\mathrm{dgm}_{i}^{(2)}(\mathsf{A}_{n})\) and \(\mathrm{dgm}_{i}^{(3)}(\mathsf{A}_{n})\) are tightly connected to the macroscopic geometry of the submanifold and can be further controlled using genericity assumptions on \(\mathsf{M}\).

Describing the limit behavior of the random \(\mathrm{PD}\,\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n})\) requires extending the metric \(\mathrm{OT}_{p}\) between PDs to more general Radon measures. Indeed, a PD can equivalently be seen as an integer-valued discrete Radon measure on \(\Omega\), by identifying a multiset \(a\) with the Radon measure \(\sum_{u\in a}\delta_{u}\). Let \(\mathcal{M}\) denote the space of Radon measures on \(\Omega\), that is the space of Borel measures on \(\overline{\Omega}\) which give finite mass to every compact set \(K\subset\Omega\).4 The space of Radon measures is endowed with the _vague topology_, where a sequence \((\mu_{n})_{n}\) of measures in \(\mathcal{M}\) is said to converge vaguely to \(\mu\in\mathcal{M}\) if \(\int_{\Omega}\phi\mathrm{d}\mu_{n}\to\int_{\Omega}\phi\mathrm{d}\mu\) as \(n\to\infty\) for all continuous functions \(\phi:\Omega\to\mathbb{R}\) with compact support.

Footnote 4: A compact set \(K\subset\Omega\) is at _positive distance_ from the diagonal. Hence, a measure \(\mu\in\mathcal{M}\) can have an accumulation of mass close to \(\partial\Omega\).

The \(\alpha\)-total persistence is defined for \(\mu\in\mathcal{M}\) by \(\mathrm{Pers}_{\alpha}(\mu)=\int_{\Omega}\mathrm{pers}(u)^{\alpha}\mathrm{d}\mu(u)\). For \(p\geq 1\), we let \(\mathcal{M}^{p}=\{\mu\in\mathcal{M}:\,\mathrm{Pers}_{p}(\mu)<+\infty\}\). The distance \(\mathrm{OT}_{p}\), defined between PDs in (3), can be extended to the set \(\mathcal{M}^{p}\), see [33]. The distance \(\mathrm{OT}_{p}\) between Radon measures is a variation of the Wasserstein distance, with the important difference that the standard Wasserstein distance is only defined for measures having the same mass, while the distance \(\mathrm{OT}_{p}\) is defined for measures having different (and even infinite) masses. We refer to Appendix F for the precise definition and the main properties of the \(\mathrm{OT}_{p}\) distance on the space \(\mathcal{M}_{p}\).

For \(q>0\), given a function \(f:\mathbb{N}\to\mathbb{R}\) and a sequence of (nonnecessarily measurable) real maps \((Y_{n})_{n}\) defined on some probabilisitic space, the notation \(Y_{n}=O_{L^{q}}(f(n))\) means that \(\mathbb{E}^{*}[|Y_{n}|^{q}]=O(f(n)^{q})\), where \(\mathbb{E}^{*}\) denotes the outer expectation [73, p.6] (and similarly for the little \(o\) notation).

### Region (1)

Consider the rescaled Radon measure \(\mu_{n,i}=\frac{1}{n}\sum_{u\in\operatorname{dgm}_{i}^{(1)}(\mathsf{A}_{n})} \delta_{n^{1/m}u}\), and note that \(\mu_{n,i}\) is a random measure, owing to the randomness of the set \(\mathsf{A}_{n}\). Goel, Trinh and Tsunoda studied the vague convergence of the sequence \((\mu_{n,i})_{n}\)[42, Remark 4.2]. Namely, assuming that the density \(f\) satisfies \(\int_{\mathsf{M}}f^{j}<\infty\) for all \(j\geq 0\), they show that with probability \(1\) the sequence \((\mu_{n,i})_{n}\) converges vaguely to some (non-random) Radon measure \(\mu_{f,i}\). The limit measure \(\mu_{f,i}\) has support \(\{0\}\times\mathbb{R}_{+}\) if \(i=0\) and \(\Omega\) if \(0<i<m\); it is the zero measure if \(i\geq m\). We can further describe it as follows: let \(\mu_{\infty,i,m}\) be the limit of the sequence \((\mu_{n,i})\) in the case where the sample \(\mathsf{A}_{n}\) is uniform on the unit cube \([0,1]^{m}\) (see [34]). Then, for any continuous function \(\phi:\Omega\to\mathbb{R}\) with compact support,

\[\int_{\Omega}\phi(u)\mathrm{d}\mu_{f,i}(u)=\int_{\Omega}\int_{\mathsf{M}}f(x) \phi(f(x)^{-1/m}u)\mathrm{d}x\mathrm{d}\mu_{\infty,i,m}(u).\] (9)

Note that the vague convergence of Radon measures is only defined with respect to compactly supported functions; as such, it is blind to phenomena located increasingly close to the diagonal \(\partial\Omega\) as \(n\) goes to infinity. In particular, and except in the case of the uniform distribution on the unit cube \([0,1]^{m}\) (see [34]), it was not known whether \(\mu_{n,i}\) converges to \(\mu_{f,i}\) for the \(\mathrm{OT}_{p}\) distance as well, nor whether the sequences of total persistence \((\operatorname{Pers}_{\alpha}(\mu_{n,i}))\) converge. We close this gap with the following result.

**Theorem 4.1** (Law of large numbers).: _Assume that \(P\) has a density \(f\) on \(\mathsf{M}\) bounded away from \(0\) and \(\infty\). Let \(i\geq 0\) be an integer and let \(1\leq p<\infty\). Then \(\mu_{f,i}\in\mathcal{M}_{p}\) and \(\operatorname{\mathbb{E}}[\mathrm{OT}_{p}^{p}(\mu_{n,i},\mu_{f,i})]\xrightarrow[ n\to\infty]{}0\). Furthermore, for all \(\alpha>0\), \(\operatorname{Pers}_{\alpha}(\operatorname{dgm}_{i}^{(1)}(\mathsf{A}_{n}))n^{ \frac{\alpha}{m}-1}=\operatorname{Pers}_{\alpha}(\mu_{n,i})=\operatorname{Pers }_{\alpha}(\mu_{f,i})+o_{L^{1}}(1)\)._

### Regions (2)-(3)

It is a well-known fact that the Hausdorff distance \(\varepsilon=d_{H}(\mathsf{A}_{n},\mathsf{M})\) between a random sample and \(\mathsf{M}\) is of order \((\log n/n)^{1/m}\) whenever the underlying density \(f\) is bounded away from zero and \(\infty\) on \(\mathsf{M}\), see e.g. [38]. Hence the PDs \(\operatorname{dgm}_{i}^{(2)}(\mathsf{A}_{n})\) and \(\operatorname{dgm}_{i}^{(3)}(\mathsf{A}_{n})\) can be described using Theorem 2.2. However, in the case where \(\mathsf{M}\) is a generic submanifold, one can actually obtain tighter results. We let \(\#E\) denote the cardinality of a multiset \(E\).

**Proposition 4.2**.: _Let \(\mathsf{M}\) be a generic \(m\)-dimensional submanifold. Assume that \(P\) has a density \(f\) on \(\mathsf{M}\) bounded away from \(0\) and \(\infty\). Let \(i\geq 0\) be an integer. There exists an optimal matching \(\gamma_{n}:\operatorname{dgm}_{i}(\mathsf{A}_{n})\cup\partial\Omega\to \operatorname{dgm}_{i}(\mathsf{M})\cup\partial\Omega\) for the bottleneck distance between \(\operatorname{dgm}_{i}(\mathsf{A}_{n})\) and \(\operatorname{dgm}_{i}(\mathsf{M})\) such that for any \(q\geq 1\):_

* _Region (2): It holds that_ \(\max_{u\in\operatorname{dgm}_{i}^{(2)}(\mathsf{A}_{n})}|u_{2}-\gamma_{n}(u)_{ 2}|=O_{L^{q}}(n^{-2/m})\)_._
* _Region (3): It holds that_ \(\max_{u\in\operatorname{dgm}_{i}^{(3)}(\mathsf{A}_{n})}\|u\,-\,\gamma_{n}(u)\|_ {\infty}=O_{L^{q}}(n^{-2/m})\) _and_ \(\#(\operatorname{dgm}_{i}^{(3)}(\mathsf{A}_{n}))=O_{L^{q}}(1)\)_._

We remark that the same bounds can be obtained almost surely (e.g. "a.s. there exists \(C>0\) such that \(\max_{u\in\operatorname{dgm}_{i}^{(3)}(\mathsf{A}_{n})}\|u-\gamma_{n}(u)\|_{ \infty}\leq Cn^{-2/m}\)"), rather than in expectation, using similar arguments.

Proposition 4.2 yields two distinct improvements upon direct applications of Theorem 2.2 and Theorem 3.3 to the random case. First, we obtain bounds of order \(n^{-2/m}\) instead of bounds of order \((\log n/n)^{2/m}\). Second, the random sample \(\mathsf{A}_{n}\) is in general only \(\delta\)-sparse for \(\delta\) of order \(n^{-2/m}\). Hence, \(\mathsf{A}_{n}\) is \((\delta,\varepsilon)\)-dense in \(\mathsf{M}\), but with a diverging ratio \(\varepsilon/\delta\). Therefore, Theorem 3.3 cannot be applied to control the total number of points in \(\operatorname{dgm}_{i}(\mathsf{A}_{n})\) in Region (3).

### Consequences for the Wasserstein convergence of persistence diagrams

As a simple consequence of Theorem 4.1 and Proposition 4.2, we obtain that for \(i<m\), the \(p\)-Wasserstein convergence of \((\operatorname{dgm}_{i}(\mathsf{A}_{n}))\) to \(\operatorname{dgm}_{i}(\mathsf{M})\) holds if and only if \(p>m\), as well as precise asymptotics for the total persistence of \((\operatorname{dgm}_{i}(\mathsf{A}_{n}))\).

**Corollary 4.3**.: _Let \(p\geq 1\) and let \(0\leq i<d\) be an integer. Under the same assumptions as in Proposition 4.2, the following holds:_

* _If_ \(p>m\)_, then_ \(\mathbb{E}[\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_{i }(\mathsf{M}))]\to 0\) _as_ \(n\to\infty\)_._
* _If_ \(p=m\)_,_ \(\mathbb{E}[\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_{ i}(\mathsf{M}))]\to\mathrm{Pers}_{p}(\mu_{\infty,i,m})\mathrm{Vol}(\mathsf{M})\) _as_ \(n\to\infty\)_, where_ \(\mathrm{Vol}(\mathsf{M})\) _is the volume of_ \(\mathsf{M}\)_._
* _If_ \(p<m\) _and_ \(i<m\)_, then_ \(\mathbb{E}[\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_{ i}(\mathsf{M}))]\to+\infty\) _as_ \(n\to\infty\)_._

_Furthermore, for all \(\alpha>0\), \(\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}_{n}))\) is equal to_

\[\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{M}))+n^{1-\frac{\alpha}{m}} \mathrm{Pers}_{\alpha}(\mu_{\infty,i,m})\int_{\mathsf{M}}f(x)^{1-\frac{\alpha }{m}}\mathrm{d}x+o_{L^{1}}(n^{1-\frac{\alpha}{m}})+O_{L^{1}}\Big{(}\left( \frac{\log n}{n}\right)^{\frac{1}{m}}\Big{)}.\]

As noted earlier, both \(\mathrm{dgm}_{i}(\mathsf{A}_{n})\) and \(\mathrm{dgm}_{i}(\mathsf{M})\) are trivial if \(i\geq d\).

This corollary gives a precise answer to the questions raised in the introduction. First, when \(\mathsf{A}_{n}\) is a random subset of a \(m\)-dimensional generic manifold in \(\mathbb{R}^{d}\), the \(\alpha\)-total persistence of \(\mathrm{dgm}_{i}(\mathsf{A}_{n})\) is not only bounded for \(\alpha>d\) (as was shown by Cohen-Steiner & al. [27]), but for all \(\alpha\geq m\). Moreover, the sequence \(\mathrm{dgm}_{i}(\mathsf{A}_{n})\) converges for the \(\mathrm{OT}_{p}\) distance if \(p>m\). A curious phenomenon can be observed in the case \(p=m\): the sequence does not converge to \(\mathrm{dgm}_{i}(\mathsf{M})\) as one would expect, but its distance to the power \(p\) to \(\mathrm{dgm}_{i}(\mathsf{M})\) converges to some constant-in that case, the cost to the power \(p\) of matching all the points in Region (1) to the diagonal \(\partial\Omega\) neither converges to \(0\) nor diverges, but is asymptotically equal to this constant.

Using these bounds on the total persistence, we obtain regularity guarantees for a large family of feature maps, called _linear feature maps_, which includes feature maps introduced in [23, 4, 60, 25, 54, 70, 19]. Let \((V,\|\cdot\|)\) be a normed vector space, and let \(\phi:\Omega\to V\) be a continuous bounded map. For \(\alpha\geq 0\), the linear feature map \(\Phi_{\alpha}\) associated to \(\phi\) and defined on the space \(\mathcal{D}_{f}\) of PDs having a finite number of points is defined for all \(a\in\mathcal{D}_{f}\) by \(\Phi_{\alpha}(a)=\sum_{u\in a}\mathrm{pers}(u)^{\alpha}\phi(u)\in V\).

**Corollary 4.4**.: _Let \(\alpha\geq 1\) and let \(0\leq i<d\) be an integer. Under the same assumptions as in Proposition 4.2, it holds that \(\Phi_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}_{n}))\) converges in probability to \(\Phi_{\alpha}(\mathrm{dgm}_{i}(\mathsf{M}))\) whenever \(\alpha>m\)._

Remark that other weighting schemes are possible. For instance, [53] argued for using linear feature maps of the form \(\Phi_{\alpha}(a)=\sum_{u\in a}\arctan(\mathrm{pers}(u)^{\alpha})\phi(u)\). Similar results would hold for such feature maps, as the map \(u\mapsto\arctan(\mathrm{pers}(u)^{\alpha})\phi(u)/\mathrm{pers}(u)^{\alpha}\) is continuous and bounded whenever \(\phi\) is.

## 5 Numerical experiments

We illustrate our results with synthetic experiments, full details are given in Appendix H. We create a generic submanifold of dimension \(m\) by applying a random diffeomorphism \(\Psi\) to a given \(m\)-dimensional submanifold \(\mathsf{M}_{0}\) (e.g. a torus). We then draw a sample of \(n\) i.i.d. observations sampled according to the pushforward \(P\) of the uniform distribution on \(\mathsf{M}\) by \(\Psi\).

Figure 4: Left: the Čech PD \(\mathrm{dgm}_{1}(\mathsf{A}_{n})\) of a sample of \(n=10^{4}\) points sampled on a generic torus, with points in Regions (1), (2) and (3) highlighted in different colors. Right: the persistence images of \(\mathrm{dgm}_{1}(\mathsf{A}_{n})\) with weight \(\mathrm{pers}^{p}\) for different values of \(p\).

**Continuity of feature maps.** As a first experiment, we test the continuity of a feature map, the persistence image [4]. In Figure 4, we plot the persistence image of \(\mathrm{dgm}_{1}(\mathsf{A}_{n})\) where \(\mathsf{A}_{n}\) is a sample of \(n=10^{4}\) points on a generic torus. We observe that the map is discontinuous for \(p<2\): the two points with large persistence corresponding to the PD of the underlying torus are nonapparent in the image. For \(p>2\), the two points are apparent, and the contribution of points with small persistence (close to the lower edge) has vanished. In the limit situation \(p=2\), we see the contribution of both points with large and small persistence. This phenomenon suggests the following heuristics: **when in presence of multiple datasets on \(m\)-dimensional objects whose global geometries need to be distinguished, feature maps with weights \(\mathrm{pers}^{p}\) with \(p>m\) should be used; when the relevant information is the underlying density of the datasets, the choice \(p<m\) should be preferred.**

**Convergence of total persistences.** We verify the rate of convergence of the total persistence predicted by Theorem 4.1. For values of \(n\) ranging from \(10^{2}\) to \(10^{4}\), we compute \(\mathrm{Pers}_{p}(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n}))\) in three scenarios: points sampled on a circle for \(i=0\), and points sampled on a torus for \(i=0\) and \(i=1\). The correct rates of convergence are observed on a log-log plot, see Figure 5. For \(i=1\), we remark that the asymptotic regime starts at larger values of \(n\), above \(n=10^{3}\).

**Convergence of \(\mu_{n,i}\).** We sample \(n\) points on a torus by uniformly sampling the two angles \((\theta,\phi)\) parametrizing the torus. We obtain a (nonnuniform) probability measure, having density \(f\). We then compute, for various values of \(n\), the measure \(\mu_{n,1}\). The measure is approximated by kernel density estimation (see Figure 6). We approximate in a similar manner the measure \(\mu_{\infty,1,2}\) by sampling \(n=10^{5}\) points on a square. We then apply the change of variable formula (9) to compute the theoretical limit \(\mu_{f,1}\). The distance \(\mathrm{OT}_{2}(\mu_{n,1},\mu_{f,1})\) is then computed by approximating the measures on a grid: the distance converges to \(0\) as predicted by Theorem 4.1. See also Figure 6.

Figure 5: Plot in log-log scale of \(\mathrm{Pers}_{p}(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n}))\) as a function of \(n\) for points sampled on a circle, \(i=0\) (left), points sampled on a torus, \(i=0\) (center), points sampled on a torus, \(i=1\) (right). Dashed lines have slopes equal to \(1-p/m\).

Conclusion

Under the manifold hypothesis, we have greatly refined earlier work regarding the persistent homology of subsamples of compact sets, with especially strong results when the sampling is either random or well-behaved. In particular, we have precisely described the PDs of such samplings, and provided new convergence guarantees w.r.t. the \(p\)-Wasserstein distances, as well as detailed asymptotics for their total \(\alpha\)-persistence. This results in a deeper understanding of these objects, which play an important role in ML techniques applied to TDA. The main limitations of our work were the assumptions that the data is sampled from a submanifold, and without any noise. Relaxing those assumptions, as well as establishing similar guarantees for Vietoris-Rips complexes, could be the subject of future research. We also plan on exploring the consequences of our findings regarding the persistent homology dimension [3, 66, 9, 65] of submanifolds.

## References

* [1] Eddie Aamari. _Rates of convergence for geometric inference_. PhD thesis, 2017.
* [2] Eddie Aamari and Clement Levrard. Stability and minimax optimality of tangential Delaunay complexes for manifold reconstruction. _Discrete & Computational Geometry_, 59:923-971, 2018.
* [3] Henry Adams, Manuchehr Aminian, Elin Farnell, Michael Kirby, Joshua Mirth, Rachel Neville, Chris Peterson, and Clayton Shonkwiler. A fractal dimension for measures via persistent homology. In _Topological Data Analysis: The Abel Symposium 2018_, pages 1-31. Springer, 2020.
* [4] Henry Adams, Tegan Emerson, Michael Kirby, Rachel Neville, Chris Peterson, Patrick Shipman, Sofya Chepushtanova, Eric Hanson, Francis Motta, and Lori Ziegelmeier. Persistence images: A stable vector representation of persistent homology. _Journal of Machine Learning Research_, 18(8):1-35, 2017.
* [5] Charles Arnal. The distance function to a finite set is a topological Morse function. _arXiv e-print arXiv:2407.15578_, 2024.
* [6] Charles Arnal, David Cohen-Steiner, and Vincent Divol. Critical points of the distance function to a generic submanifold. _arXiv preprint arXiv:2312.13147_, 2023.
* [7] Dominique Attali, Hana Dal Poz Kourimska, Christopher Fillmore, Ishika Ghosh, Andre Lieutier, Elizabeth Stephenson, and Mathijs Wintraecken. Tight Bounds for the Learning of Homotopy a la Niyogi, Smale, and Weinberger for Subsets of Euclidean Spaces and of Riemannian Manifolds. _https://arxiv.org/abs/2206.10485_, 2022.
* [8] Andrew Aukerman, Mathieu Carriere, Chao Chen, Kevin Gardner, Raul Rabadan, and Rami Vanguri. Persistent homology based characterization of the breast cancer immune microenvironment: A feasibility study. _Journal of Computational Geometry_, 12(2):183-206, 2022.
* [9] Tolga Birdal, Aaron Lou, Leonidas J Guibas, and Umut Simsekli. Intrinsic dimension, persistent homology and generalization in neural networks. _Advances in Neural Information Processing Systems_, 34:6776-6789, 2021.
* [10] Omer Bobrowski and Robert Adler. Distance functions, critical points, and the topology of random Cech complexes. _Homology, Homotopy & Applications_, 16(2), 2014.
* [11] Omer Bobrowski and Matthew Kahle. Topology of random geometric complexes: a survey. _Journal of applied and Computational Topology_, 1:331-364, 2018.
* [12] Omer Bobrowski, Matthew Kahle, and Primoz Skraba. Maximally persistent cycles in random geometric complexes. _The Annals of Applied Probability_, pages 2032-2060, 2017.
* [13] Omer Bobrowski and Shmuel Weinberger. On the vanishing of homology in random Cech complexes. _Random Structures & Algorithms_, 51(1):14-51, 2017.
* [14] Magnus B Botnan and Christian Hirsch. On the consistency and asymptotic normality of multiparameter persistent Betti numbers. _Journal of Applied and Computational Topology_, pages 1-38, 2022.
* [15] Bradley CA Brown, Anthony L Caterini, Brendan Leigh Ross, Jesse C Cresswell, and Gabriel Loaiza-Ganem. Verifying the union of manifolds hypothesis for image data. _arXiv preprint arXiv:2207.02862_, 2022.
* [16] Peter Bubenik and Alexander Wagner. Embeddings of persistence diagrams into Hilbert spaces. _Journal of Applied and Computational Topology_, 4(3):339-351, 2020.
* [17] Mickael Buchet, Yasuaki Hiraoka, and Ippei Obayashi. Persistent homology and materials informatics. _Nanoinformatics_, pages 75-95, 2018.
* [18] Luigi Caputi, Anna Pidnebesna, and Jaroslav Hlinka. Promises and pitfalls of topological data analysis for brain connectivity analysis. _NeuroImage_, 238:118245, 2021.

* Carriere et al. [2020] Mathieu Carriere, Frederic Chazal, Yuichi Ike, Theo Lacombe, Martin Royer, and Yuhei Umeda. Perslay: A neural network layer for persistence diagrams and new graph topological signatures. In _International Conference on Artificial Intelligence and Statistics_, pages 2786-2796. PMLR, 2020.
* Carriere et al. [2017] Mathieu Carriere, Marco Cuturi, and Steve Oudot. Sliced Wasserstein kernel for persistence diagrams. In _International conference on machine learning_, pages 664-673. PMLR, 2017.
* Carriere and Rabadan [2020] Mathieu Carriere and Raul Rabadan. Topological data analysis of single-cell hi-c contact maps. In _Topological Data Analysis: The Abel Symposium 2018_, pages 147-162. Springer, 2020.
* Chazal et al. [2016] Frederic Chazal, Vin De Silva, Marc Glisse, and Steve Oudot. _The structure and stability of persistence modules_, volume 10. Springer, 2016.
* Chazal et al. [2014] Frederic Chazal, Brittany Terese Fasy, Fabrizio Lecci, Alessandro Rinaldo, and Larry Wasserman. Stochastic convergence of persistence landscapes and silhouettes. In _Proceedings of the thirtieth annual symposium on Computational geometry_, pages 474-483, 2014.
* Chazal et al. [2006] Frederic Chazal, David Cohen-Steiner, and Andre Lieutier. A sampling theory for compact sets in Euclidean space. _Discrete & Computational Geometry_, 41:461-479, 06 2006.
* Chen et al. [2015] Yen-Chi Chen, Daren Wang, Alessandro Rinaldo, and Larry Wasserman. Statistical analysis of persistence intensity functions. _arXiv preprint arXiv:1510.02502_, 2015.
* Cohen-Steiner et al. [2005] David Cohen-Steiner, Herbert Edelsbrunner, and John Harer. Stability of persistence diagrams. In _Proceedings of the twenty-first annual symposium on Computational geometry_, pages 263-271, 2005.
* Cohen-Steiner et al. [2010] David Cohen-Steiner, Herbert Edelsbrunner, John Harer, and Yuriy Mileyko. Lipschitz functions have \(L_{p}\)-stable persistence. _Foundations of Computational Mathematics_, 10(2):127-139, Apr 2010.
* Rocco et al. [2023] Sandra Di Rocco, Parker B. Edwards, David Eklund, Oliver Gafvert, and Jonathan D. Hauenstein. Computing geometric feature sizes for algebraic manifolds. _SIAM Journal on Applied Algebra and Geometry_, 7(4):716-741, 2023.
* Rocco et al. [2020] Sandra Di Rocco, David Eklund, and Madeleine Weinstein. The bottleneck degree of algebraic varieties. _SIAM Journal on Applied Algebra and Geometry_, 4(1):227-253, 2020.
* Dijksman et al. [2018] Joshua A Dijksman, Lenka Kovalcinova, Jie Ren, Robert P Behringer, Miroslav Kramar, Konstantin Mischaikow, and Lou Kondic. Characterizing granular networks using topological metrics. _Physical Review E_, 97(4):042903, 2018.
* Divol [2021] Vincent Divol. Minimax adaptive estimation in manifold inference. _Electronic Journal of Statistics_, 15(2):5888-5932, 2021.
* Divol and Chazal [2019] Vincent Divol and Frederic Chazal. The density of expected persistence diagrams and its kernel based estimation. _Journal of Computational Geometry_, 10(2):127-153, 2019.
* Divol and Lacombe [2021] Vincent Divol and Theo Lacombe. Understanding the topology and the geometry of the space of persistence diagrams via optimal partial transport. _Journal of Applied and Computational Topology_, 5:1-53, 2021.
* Divol and Polonik [2019] Vincent Divol and Wolfgang Polonik. On the choice of weight functions for linear representations of persistence diagrams. _Journal of Applied and Computational Topology_, 3(3):249-283, 2019.
* 149, 2013.
* Edelsbrunner et al. [2002] Edelsbrunner, Letscher, and Zomorodian. Topological persistence and simplification. _Discrete & computational geometry_, 28:511-533, 2002.
* Edelsbrunner and Harer [2010] Herbert Edelsbrunner and John Harer. _Computational Topology: An Introduction_. 01 2010.

* [38] Brittany Terese Fasy, Fabrizio Lecci, Alessandro Rinaldo, Larry Wasserman, Sivaraman Balakrishnan, and Aarti Singh. Confidence sets for persistence diagrams. _The Annals of Statistics_, 42(6):2301, 2014.
* [39] Herbert Federer. Curvature measures. _Transactions of the American Mathematical Society_, 93(3):418-491, 1959.
* [40] Remi Flamary, Nicolas Courty, Alexandre Gramfort, Mokhtar Z Alaya, Aurelie Boisbunon, Stanislas Chambon, Laetitia Chapel, Adrien Corenlos, Kilian Fatras, Nemo Fournier, et al. Pot: Python optimal transport. _Journal of Machine Learning Research_, 22(78):1-8, 2021.
* [41] Christopher R Genovese, Marco Perone-Pacifico, Isabella Verdinelli, and Larry Wasserman. Manifold estimation and singular deconvolution under Hausdorff loss. _The Annals of Statistics_, 40(2):941-963, 2012.
* [42] Akshay Goel, Khanh Duy Trinh, and Kenkichi Tsunoda. Strong law of large numbers for Betti numbers in the thermodynamic regime. _Journal of Statistical Physics_, 174(4):865-892, 2019.
* [43] Karsten Grove. Critical point theory for distance functions. _Proceedings of Symposia in Pure Mathematics_, pages 357-385, 1993.
* [44] Andrea Guidolin, Antonio Lerario, Isaac Ren, and Martina Scolamiero. Morse theory of Euclidean distance functions and applications to real algebraic geometry. _arXiv e-print arXiv:2402.08639_, 2024.
* [45] Olympio Hacquard and Vadim Lebovici. Euler characteristic tools for topological data analysis. _arXiv preprint arXiv:2303.14040_, 2023.
* [46] Allen Hatcher. _Algebraic topology_. Cambridge Univ. Press, Cambridge, 2000.
* [47] Yasuaki Hiraoka, Tomoyuki Shirai, and Khanh Duy Trinh. Limit theorems for persistence diagrams. _The Annals of Applied Probability_, 28(5):2740-2780, 2018.
* [48] Christoph D Hofer, Roland Kwitt, and Marc Niethammer. Learning representations of persistence barcodes. _Journal of Machine Learning Research_, 20(126):1-45, 2019.
* [49] Matthew Kahle and Elizabeth Meckes. Limit theorems for Betti numbers of random simplicial complexes. _Homology, Homotopy and Applications_, 15(1):343-374, 2013.
* [50] Kwangho Kim, Jisu Kim, Manzil Zaheer, Joon Kim, Frederic Chazal, and Larry Wasserman. Pllay: Efficient topological layer based on persistent landscapes. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, _Advances in Neural Information Processing Systems_, volume 33, pages 15965-15977. Curran Associates, Inc., 2020.
* [51] L Kondic, M Kramar, Luis A Pugnaloni, C Manuel Carlevaro, and K Mischaikow. Structure of force networks in tapped particulate systems of disks and pentagons. ii. persistence analysis. _Physical Review E_, 93(6):062903, 2016.
* [52] Vitaliy Kurlin. Simplexwise distance distributions for finite spaces with metrics and measures, 03 2023.
* [53] Genki Kusano, Kenji Fukumizu, and Yasuaki Hiraoka. Kernel method for persistence diagrams via kernel embedding and weight factor. _Journal of Machine Learning Research_, 18(189):1-41, 2018.
* [54] Genki Kusano, Yasuaki Hiraoka, and Kenji Fukumizu. Persistence weighted gaussian kernel for topological data analysis. In _International conference on machine learning_, pages 2004-2013. PMLR, 2016.
* [55] Theo Lacombe, Marco Cuturi, and Steve Oudot. Large scale computation of means and clusters for persistence diagrams using optimal transport. _Advances in Neural Information Processing Systems_, 31, 2018.
* [56] J.W. Milnor. _Morse Theory_. Annals of mathematics studies. Princeton University Press, 1963.

* [57] Atish Mitra and Ziga Virk. The space of persistence diagrams on \(n\) points coarsely embeds into Hilbert space. _Proceedings of the American Mathematical Society_, 149(6):2693-2703, 2021.
* [58] Marston Morse. Topologically non-degenerate functions on a compact n-manifold m. _Journal d'Analyse Mathematique_, 7(1):189-208, 1959.
* [59] Takashi Owada. Convergence of persistence diagram in the sparse regime. _The Annals of Applied Probability_, 32(6):4706-4736, 2022.
* [60] Jan Reininghaus, Stefan Huber, Ulrich Bauer, and Roland Kwitt. A stable multi-scale kernel for topological machine learning. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 4741-4748, 2015.
* [61] Bastian Rieck, Tristan Yates, Christian Bock, Karsten Borgwardt, Guy Wolf, Nicholas Turk-Browne, and Smita Krishnaswamy. Uncovering the topology of time-varying fMRI data using cubical persistence. _Advances in neural information processing systems_, 33:6900-6912, 2020.
* [62] Vincent Rouvreau. Alpha complex. In _GUDHI User and Reference Manual_. GUDHI Editorial Board, 2015.
* [63] Mohammad Saadatfar, Hiroshi Takeuchi, Vanessa Robins, Nicolas Francois, and Yasuaki Hiraoka. Pore configuration landscape of granular crystallization. _Nature communications_, 8(1):15082, 2017.
* [64] Nathaniel Saul and Chris Tralie. Scikit-tda: Topological data analysis for python, 2019.
* [65] Benjamin Schweinhart. Persistent homology and the upper box dimension. _Discrete & Computational Geometry_, 65(2):331-364, 2021.
* [66] Umut Simsekli, Ozan Sener, George Deligiannidis, and Murat A Erdogdu. Hausdorff dimension, heavy tails, and generalization in neural networks. _Advances in Neural Information Processing Systems_, 33:5138-5151, 2020.
* [67] Ann E Sizemore, Jennifer E Phillips-Cremins, Robert Ghrist, and Danielle S Bassett. The importance of the whole: topological data analysis for the network neuroscientist. _Network Neuroscience_, 3(3):656-673, 2019.
* [68] Yara Skaf and Reinhard Laubenbacher. Topological data analysis in biomedicine: A review. _Journal of Biomedical Informatics_, 130:104082, 2022.
* [69] Philip Smith and Vitaliy Kurlin. Generic families of finite metric spaces with identical or trivial 1-dimensional persistence. _Journal of Applied and Computational Topology_, 8:839-855, 05 2024.
* [70] Anirudh Som, Kowshik Thopalli, Karthikeyan Natesan Ramamurthy, Vinay Venkataraman, Ankita Shukla, and Pavan Turaga. Perturbation robust representations of topological persistence diagrams. In _Proceedings of the European Conference on Computer Vision (ECCV)_, pages 617-635, 2018.
* [71] Anna Song, Ka Man Yim, and Anthea Monod. Generalized morse theory of distance functions to surfaces for persistent homology. _arXiv preprint arXiv:2306.14716_, 2023.
* [72] Guillaume Tauzin, Umberto Lupo, Lewis Tunstall, Julian Burella Perez, Matteo Caorsi, Anibal Medina-Mardones, Alberto Dassatti, and Kathryn Hess. giotto-tda: A topological data analysis toolkit for machine learning and data exploration, 2020.
* [73] Aad W Van Der Vaart and Jon A Wellner. _Weak convergence and empirical processes: with applications to statistics_. Springer New York, 1997.
* [74] Roman Vershynin. _High-dimensional probability: An introduction with applications in data science_, volume 47. Cambridge university press, 2018.
* [75] Alexander Wagner. Nonembeddability of persistence diagrams with \(p>2\) Wasserstein metric. _Proceedings of the American Mathematical Society_, 149(6):2673-2677, 2021.

* [76] Jonathan Weed and Francis Bach. Sharp asymptotic and finite-sample rates of convergence of empirical measures in Wasserstein distance. _Bernoulli_, 25(4A):2620-2648, 2019.
* [77] Daniel Widdowson and Vitaliy Kurlin. Recognizing rigid patterns of unlabeled point clouds by complete and continuous isometry invariants with no false negatives and no false positives. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 1275-1284, 2023.

## Appendix A Outline of the appendix

### Persistent homology

* Distance functions, topological Morse functions and generic submanifolds
* Proofs of Section 2
* Proof of Theorem 3.3
* The \(\mathrm{OT}_{p}\) distance between Radon measures
* Proofs of Section 4
* Details on numerical experiments

## Appendix B Persistent homology

Although this work is only concerned with PDs with respect to the Cech filtration, it is more natural to define PDs for the sublevel sets of proper continuous functions that are bounded below. We refer to [22] for a thorough introduction to persistent homology and PDs in an even more general context.

Let \(f:\mathbb{R}^{d}\to\mathbb{R}\) be a proper continuous function that is bounded below-e.g., the distance function to a compact set. For \(t\in\mathbb{R}\), let \(X_{t}=f^{-1}(-\infty,t]\) be the sublevel set of \(f\) at level \(t\). The collection \((X_{t})_{t\in\mathbb{R}}\) is called a filtration. Let \(i\geq 0\) be an integer. We let \(H_{i}(X_{t})\) be the homology group of degree \(i\) with coefficients in any fixed field \(\mathcal{F}\) (e.g. \(\mathcal{F}=\mathbb{Z}/2\mathbb{Z}\) is a popular choice) of \(X_{t}\). For \(r<s\), the inclusion between the sublevel sets at levels \(r\) and \(s\) induces a map \(\iota_{i,r,s}\) at the homology level. We define the persistent Betti number

\[\beta_{i,r,s}(f)=\mathrm{rk}(\iota_{i,r,s}:H_{i}(X_{r})\to H_{i}(X_{s})).\] (10)

As shown in [22, Corollary 3.34], this number is finite. Informally, it represents the number of \(i\)th dimensional topological features present in the sublevel set at level \(r\) that are still present at level \(s\).

Define the extended half-plane \(\Omega_{\infty}=\{u=(u_{1},u_{2})\in(\mathbb{R}\cup\{-\infty,+\infty\})^{2}: \ -\infty\leq u_{1}<u_{2}\leq+\infty\}\) and \(\Omega=\{u=(u_{1},u_{2})\in\mathbb{R}^{2}:\ u_{1}<u_{2}\}\). The collection of persistent Betti numbers \((\beta_{i,r,s}(f))_{r<s}\) defines a multiset of points in \(\Omega_{\infty}\), called the persistence diagram \(\mathrm{dgm}_{i}(f)\) of degree \(i\) of \(f\). See e.g. [22] for its precise definition.

Though persistence diagrams can have points with infinite coordinates, these will be of little interest in the cases considered in this article5. To simplify our notation and definitions, we let from now on\(\mathrm{dgm}_{i}(f)\) denote the finite part (i.e. the points whose coordinates are finite) of the diagram of degree \(i\) of \(f\), and we assume that every diagram considered henceforth has no point with infinite coordinates. In particular, they are all multisets of the half-plane \(\Omega:=\{u=(u_{1},u_{2})\in\mathbb{R}^{2}:\,u_{1}<u_{2}\}\), which leads to the following definition: the space \(\mathcal{D}\) of persistence diagrams is the set of all multisets \(a\) in \(\Omega\) that contain a finite number of points6 in every quadrant \(Q_{u}\), \(u\in\Omega\).

Footnote 6: This corresponds to the set of diagrams of \(q\)-tame persistence modules as defined in [22].

Note that while persistence diagrams capture key topological features in an interpretable fashion, they are not complete metric invariants: different sets can have equal persistence diagrams, see e.g. [69]. As such, they can be seen as a form of topology-centered dimensionality reduction technique. Other topological invariants have been proposed, some of which are complete, such as those from [77, 52].

## Appendix C Distance functions, topological Morse functions and generic submanifolds

In this section, we consider a special class of PDs -those yielded by the distance function to a compact set \(\mathsf{A}\subset\mathbb{R}^{d}\). We give a detailed description of such a PD when \(\mathsf{A}=\mathsf{M}\) is a generic submanifold.

The theory of persistent homology was historically developed for Morse functions \(f:\mathbb{R}^{d}\to\mathbb{R}\). A Morse function \(f\) is a \(C^{2}\) function whose critical points \(x\) (points for which \(d_{x}f=0\)) are non-degenerate (meaning that the Hessian of \(f\) at \(x\) is non-degenerate). The index of the critical point \(x\) is equal to the number of negative eigenvalues of the corresponding Hessian. The changes of topology of the sublevel sets of such a function are perfectly understood. First, the isotopy lemma states that two sublevel sets \(f^{-1}(-\infty,u_{1}]\) and \(f^{-1}(-\infty,u_{2}]\) are isotopic if no critical values are found in the interval \([u_{1},u_{2}]\) and if \(f^{-1}[u_{1},u_{2}]\) is compact. Second, if \(f^{-1}[u_{1},u_{2}]\) is compact and contains the critical points \(x_{1},\ldots,x_{K}\), then \(f^{-1}(-\infty,u_{2}]\) has the homotopy type of \(f^{-1}(-\infty,u_{1}]\) with cells \(e_{k}\) of dimension equal to the index of \(x_{k}\) attached along their boundaries (see e.g. [56] for a much more in-depth treatment).

In such a situation, the PD \(\mathrm{dgm}_{i}(f)\) has a clear interpretation: the coordinates \((u_{1},u_{2})\) of a point \(u\in\mathrm{dgm}_{i}(f)\) correspond to the critical value of a critical point of index \(i\) and \(i+1\) respectively. Informally, the corresponding \(i\)-dimensional topological feature appears with the attachment of a \(i\)-dimensional cell at value \(u_{1}\), and is "killed" by the attachment of a \((i+1)\)-dimensional cell at value \(u_{2}\).

The notion of Morse function extends to continuous functions with the following definition.

**Definition C.1** (Topological Morse functions [58]).: _Let \(U\subset\mathbb{R}^{d}\) be an open set and let \(f:U\to\mathbb{R}\) be a continuous function._

* _A point_ \(z\in U\) _is said to be a topological regular point of_ \(f\) _if there is a homeomorphism_ \(\phi:V_{1}\to V_{2}\) _between open neighborhoods_ \(V_{1}\) _of_ \(0\) _in_ \(\mathbb{R}^{d}\) _and_ \(V_{2}\) _of_ \(U\) _in_ \(\mathbb{R}^{d}\) _with_ \(\phi(0)=z\) _and such that for all_ \(x=(x_{1},\ldots,x_{d})\in V_{1}\)_,_ \[f\circ\phi(x)=f(z)+x_{d}.\] (11)
* _A point_ \(z\in U\) _is said to be a topological critical point of_ \(f\) _if it is not a topological regular point of_ \(f\)_._
* _A point_ \(z\in U\) _is said to be a non-degenerate topological critical point of_ \(f\) _of index_ \(i\) _if there exist an integer_ \(0\leq i\leq d\) _and a homeomorphism_ \(\phi:V_{1}\to U_{2}\) _between open neighborhoods_ \(V_{1}\) _of_ \(0\) _in_ \(\mathbb{R}^{d}\) _and_ \(V_{2}\) _of_ \(U\) _in_ \(\mathbb{R}^{d}\) _with_ \(\phi(0)=z\) _such that for all_ \(x=(x_{1},\ldots,x_{d})\in V_{1}\)_,_ \[f\circ\phi(x)=f(z)-\sum_{j=1}^{i}x_{j}^{2}+\sum_{j=i+1}^{d}x_{j}^{2}.\] (12)
* _The function_ \(f\) _is said to be a topological Morse function if all its topological critical points are non-degenerate._

For topological Morse functions, both the isotopy lemma and the handle attachment lemma stay valid:

**Lemma C.2** (Isotopy Lemma).: _Let \(f:\mathbb{R}^{d}\to\mathbb{R}\) be a proper topological Morse function. Let \(a<b\) be such that \(f^{-1}[a,b]\) contains no topological critical point. Then \(f^{-1}(-\infty,a]\) is a deformation retract of \(f^{-1}(-\infty,b]\)._

**Lemma C.3** (Handle Attachment Lemma).: _Let \(f:\mathbb{R}^{d}\to\mathbb{R}\) be a proper topological Morse function. Let \(c\in\mathbb{R}\) and \(\varepsilon>0\) be such that \(f^{-1}[c-\varepsilon,c+\varepsilon]\) contains no topological critical point except for \(z_{1},\ldots,z_{k}\in f^{-1}(c)\), with \(z_{j}\) of index \(i_{j}\). Then \(f^{-1}(-\infty,c+\varepsilon]\) is homotopically equivalent to \(f^{-1}(-\infty,c-\varepsilon]\) with cells \(B^{i_{1}},\ldots,B^{i_{k}}\) of dimension \(i_{1},\ldots,i_{k}\) attached, i.e._

\[f^{-1}(-\infty,c+\varepsilon]\simeq f^{-1}(-\infty,c-\varepsilon]\cup B^{i_{ 1}}\cup\ldots\cup B^{i_{k}}.\]

Their proofs are roughly the same as for smooth Morse functions -see [71, Theorems 4 and 5] for details. As a consequence, the description of PDs for Morse functions also stays valid for topological Morse functions.

In this paper, we are interested in the PDs of the distance function \(d_{\mathsf{A}}\) to various compact sets \(\mathsf{A}\), called the Cech persistence diagram7 of \(\mathsf{A}\) and denoted by \(\operatorname{dgm}_{i}(\mathsf{A})\). In general, such a function is not a topological Morse function. Instead, changes in the topology of its sublevels can be partially (though less completely than for a Morse function) described in terms of zeros of its generalized gradient, which is defined at \(y\in\mathbb{R}^{d}\backslash\mathsf{A}\) as

Footnote 7: The distance function \(d_{\mathsf{A}}\) is proper due to the compacity of \(\mathsf{A}\), hence its persistence module is \(q\)-tame and the associated persistence diagram is well-defined -see [22].

\[\nabla d_{\mathsf{A}}(y)=\frac{y-c(\sigma_{\mathsf{A}}(y))}{d_{\mathsf{A}}(y)},\] (13)

where \(\sigma_{\mathsf{A}}(y)=\{x\in\mathsf{A}:\;\|x-y\|=d_{\mathsf{A}}(y)\}\) is the set of projections of \(y\) on \(\mathsf{A}\) and \(c(\tau)\) represents the center of the smallest enclosing ball of a set \(\tau\). When \(y\in\mathbb{R}^{d}\backslash\mathsf{A}\) satisfies \(\nabla d_{\mathsf{A}}(y)=0\), \(y\) is called a _differential critical point_ of \(d_{\mathsf{A}}\). We let \(\operatorname{Crit}(\mathsf{A})\) denote the set of differential critical points of \(d_{\mathsf{A}}\). An adapted version of the Isotopy Lemma remains true, as shown in [43]:

**Lemma C.4** (Isotopy Lemma for Distance Functions).: _If \(0<a<b\) are such that \(d_{\mathsf{A}}^{-1}[a,b]\) contains no differential critical point of \(d_{\mathsf{A}}\), then \(d_{\mathsf{A}}^{-1}(-\infty,a]\) is a deformation retract of \(d_{\mathsf{A}}^{-1}(-\infty,b]\). Consequently, any \((u_{1},u_{2})\in\operatorname{dgm}_{i}(\mathsf{A})\) is such that \(u_{1},u_{2}\not\in[a,b]\)._

Without further assumptions, little else can be said regarding the topology of the sublevels of \(d_{\mathsf{A}}\); in particular, there is no equivalent to the Handle Attachment Lemma to control the changes occurring at critical values.

However, the distance function \(d_{\mathsf{M}}\) to a compact \(C^{2}\) submanifold \(\mathsf{M}\subset\mathbb{R}^{d}\) turns out to be a topological Morse function in a "generic" sense, as was proven by Arnal, Cohen-Steiner and Divol.

**Theorem C.5** (Genericity Theorem [6]).: _Let \(M\) be a compact \(C^{2}\) (abstract) manifold. Then the set of \(C^{2}\) embeddings \(i:M\to\mathbb{R}^{d}\) such that_

1. _the distance function_ \(d_{i(M)}:\mathbb{R}^{d}\backslash i(M)\to\mathbb{R}\) _is a topological Morse function,_
2. _for every_ \(z\in\operatorname{Crit}(\mathsf{M})\)_, the projections_ \(\sigma_{\mathsf{M}}(z)\) _are the vertices of a non-degenerate simplex of_ \(\mathbb{R}^{d}\) _and_ \(z\) _belongs to its relative interior,_
3. _the set_ \(\operatorname{Crit}(\mathsf{M})\) _is finite,_
4. _for every_ \(z\in\operatorname{Crit}(\mathsf{M})\) _and every_ \(x\in\sigma_{\mathsf{M}}(z)\)_, the sphere_ \(S(z,d_{\mathsf{M}}(z))\) _is non-osculating_ \(\mathsf{M}\) _at_ \(x\)_, in the sense that there exist_ \(\delta>0\) _and_ \(\alpha>0\) _such that for all_ \(y\in\mathsf{M}\cap B(x,\delta)\)_,_ \[\|y-z\|^{2}\geq\|x-z\|^{2}+\alpha\|y-x\|^{2},\] (14)
5. _there exist constants_ \(C>0\) _and_ \(\mu_{0}\in(0,1)\) _such that for every_ \(\mu\in[0,\mu_{0})\)_, any point_ \(x\) _such that_ \(\|\nabla d_{\mathsf{M}}(x)\|\leq\mu\) _is at distance at most_ \(C\mu\) _from_ \(\operatorname{Crit}(\mathsf{M})\)_,_

_is open and dense in the set of \(C^{2}\) embeddings \(M\to\mathbb{R}^{d}\) for the Whitney \(C^{2}\)-topology._

When \(\mathsf{M}\) is generic, the topological critical points of \(d_{\mathsf{M}}\) coincide with its differential critical points (see [6, Theorem 1.8]), and the Cech PD \(\operatorname{dgm}_{i}(\mathsf{M})\) can be related to the critical points of \(d_{\mathsf{M}}\) in the same way as for smooth Morse function. We are now in position to prove Proposition 3.2, which we restate for the reader's convenience:

**Proposition 3.2** (Cech PDs of generic submanifolds).: _Let \(\mathsf{M}\) be a generic submanifold of \(\mathbb{R}^{d}\). Then, for any integer \(i\geq 0\), the PD \(\mathrm{dgm}_{i}(\mathsf{M})\) contains finitely many points. In particular, \(\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{M}))<+\infty\) for all \(\alpha>0\)._

Proof.: The proof is similar to that used in the case of smooth Morse functions, with the Isotopy Lemma and the Handle Attachment Lemma playing the same role; we briefly summarize it for completeness nonetheless. We do not distinguish between differential and topological critical values and points, as they coincide.

The set \(\mathrm{Crit}(\mathsf{M})\) is finite: this is simply Condition 3. from the Genericity Theorem. The Isotopy Lemma shows that there is no change in homotopy type between \(\mathsf{M}^{\alpha}\) and \(\mathsf{M}^{b}\) if \(0<a<b\) and \([a,b]\) contains no critical value. Similarly, \(\mathsf{M}\) has the same homotopy type as \(\mathsf{M}^{a}\) if \(a>0\) is small enough. Hence changes in homology in the offsets can only occur at \(0\), when the entire submanifold appears in the filtration, and at critical values of \(d_{\mathsf{M}}\), and there can be no birth or death of interval between them.

Let us now consider a critical value \(c>0\) and \(0<\varepsilon<c\) such that \(d_{\mathsf{M}}^{-1}[c-\varepsilon,c+\varepsilon]\) contains no critical point except for \(z_{1},\ldots,z_{k}\in d_{\mathsf{M}}^{-1}(c)\), where \(z_{j}\) is of index \(i_{j}\). Then the Handle Attachment Lemma states that \(\mathsf{M}^{c+\varepsilon}\) is homotopically equivalent to \(\mathsf{M}^{c-\varepsilon}\) with cells \(B^{i_{1}},\ldots,B^{i_{k}}\) of dimension \(i_{1},\ldots,i_{k}\) attached, i.e.

\[\mathsf{M}^{c+\varepsilon}\simeq\mathsf{M}^{c-\varepsilon}\cup B^{i_{1}}\cup \ldots\cup B^{i_{k}}.\]

Let \(i\geq 1\), and let \(D_{i,b}\) be the dimension of the cokernel of \(H_{i}(\mathsf{M}^{c-\varepsilon})\to H_{i}(\mathsf{M}^{c+\varepsilon})\) (where the map is induced by the inclusion): it is precisely the number of births of intervals between \(c-\varepsilon\) and \(c+\varepsilon\) (hence precisely at \(c\)) in the persistence module of degree \(i\) of the filtration. Similarly, the dimension \(D_{i-1,d}\) of the kernel of \(H_{i-1}(\mathsf{M}^{c-\varepsilon})\to H_{i-1}(\mathsf{M}^{c+\varepsilon})\) is the number of deaths of intervals at \(c\) in the persistence module of degree \(i-1\) of the filtration. A straightforward application of the Mayer-Vietoris exact sequence yields that \(D_{i,b}+D_{i-1,d}\) is exactly equal to the number of \(i\)-dimensional cells among \(B^{i_{1}},\ldots,B^{i_{k}}\), meaning that each \(i\)-cell corresponds exactly either to the birth of an interval for the homology of degree \(i\), or to the death of an interval for the homology of degree \(i-1\) (in particular, an \(i-1\)-cell and an \(i\)-cell cannot "cancel each other out"). This proves that for any \(i\geq 1\), the multiset of critical values \(d_{\mathsf{M}}(z)\) of critical points \(z\) of \(\mathsf{M}\) of index \(i\) is equal to the multiset

\[\{u_{1}:\;(u_{1},u_{2})\in\mathrm{dgm}_{i}(\mathsf{M}),\;u_{1}\neq 0\}\cup\{u_{2 }:\;(u_{1},u_{2})\in\mathrm{dgm}_{i-1}(\mathsf{M})\}.\] (15)

This fact proves in turn that \(\mathrm{dgm}_{i}(\mathsf{M})\) is finite for any \(i\geq 0\), which immediately implies that \(\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{M}))<+\infty\) for all \(\alpha>0\). 

## Appendix D Proofs of Section 2

For \(\mathsf{M}\) a \(m\)-dimensional differential submanifold of \(\mathbb{R}^{d}\) and \(x\in\mathsf{M}\), we let \(T_{x}\mathsf{M}\) be the tangent space of \(\mathsf{M}\) at \(x\), which is identified with a linear subspace of \(\mathbb{R}^{d}\). We denote by \(\pi_{x}:\mathbb{R}^{d}\to T_{x}\mathsf{M}\) the orthogonal projection on this subspace and let \(\pi_{x}^{\perp}=id-\pi_{x}\) be the orthogonal projection on the normal space at \(x\). A key property, that we will repeatedly used, is that the reach of \(\mathsf{M}\) controls the deviation of the manifold \(\mathsf{M}\) from its tangent space. Namely, [39, Theorem 4.18] states that for all \(y\in\mathsf{M}\),

\[\|\pi_{x}^{\perp}(x-y)\|\leq\frac{\|x-y\|^{2}}{2\tau(\mathsf{M})}.\] (16)

We also define the _weak feature size of \(\mathsf{M}\)_, denoted by \(\mathrm{wfs}(\mathsf{M})\), as the minimal distance between a critical point of \(\mathsf{M}\) and \(\mathsf{M}\). As by definition, the projection is not unique at a critical point, we must have \(\mathrm{wfs}(\mathsf{M})\geq\tau(\mathsf{M})\).

We first prove Lemma 2.1:

**Lemma 2.1**.: _Let \(\mathsf{M}\subset\mathbb{R}^{d}\) be a compact submanifold with positive reach and let \(\mathsf{A}\subset\mathsf{M}\) be a compact set with \(d_{H}(\mathsf{A},\mathsf{M})\leq\varepsilon\) for some \(\varepsilon>0\). Let \(z\in\mathbb{R}^{d}\backslash\mathsf{M}\). Then, \(|d_{\mathsf{M}}(z)-d_{\mathsf{A}}(z)|\leq\frac{\varepsilon^{2}}{2d_{\mathsf{M} }(z)}\left(1+\frac{d_{\mathsf{M}}(z)}{\tau(\mathsf{M})}\right)\)._Proof.: As \(\mathsf{A}\subset\mathsf{M}\), we have \(d_{\mathsf{M}}(z)\leq d_{\mathsf{A}}(z)\). Let \(x\) be a projection of \(z\) onto \(\mathsf{M}\), and let \(y\in\mathsf{A}\) be a point at distance less than \(\varepsilon\) from \(x\). Then, using (16) and the fact that \(z-x\) is orthogonal to \(T_{x}\mathsf{M}\), we obtain that

\[d_{\mathsf{A}}(z)^{2} \leq\|z-y\|^{2}=\|z-x\|^{2}+\|x-y\|^{2}+2\langle z-x,x-y\rangle\] \[\leq d_{\mathsf{M}}(z)^{2}+\varepsilon^{2}+2\langle z-x,\pi_{x}^{ \perp}(x-y)\rangle\] \[\leq d_{\mathsf{M}}(z)^{2}+\varepsilon^{2}+\frac{d_{\mathsf{M}}(z )\varepsilon^{2}}{\tau(\mathsf{M})}.\]

Hence,

\[d_{\mathsf{A}}(z)-d_{\mathsf{M}}(z)=\frac{d_{\mathsf{A}}(z)^{2}-d_{\mathsf{M }}(z)^{2}}{d_{\mathsf{A}}(z)+d_{\mathsf{M}}(z)}\leq\frac{\varepsilon^{2}}{2d_ {\mathsf{M}}(z)}\left(1+\frac{d_{\mathsf{M}}(z)}{\tau(\mathsf{M})}\right).\]

We can now prove Theorem 2.2:

**Theorem 2.2** (Improved Bottleneck Stability Theorem).: _Let \(\mathsf{M}\subset\mathbb{R}^{d}\) be a compact submanifold with positive reach and let \(\mathsf{A}\subset\mathsf{M}\) be a compact set such that \(d_{H}(\mathsf{A},\mathsf{M})\leq\varepsilon<\tau(\mathsf{M})/4\). Let \(i\geq 0\) be an integer. Then \(\mathrm{dgm}_{i}(\mathsf{A})\) is the union of three regions \(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}):=\mathrm{dgm}_{i}(\mathsf{A})\cap\{u_{1},u _{2}\leq\varepsilon+\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\}\), \(\mathrm{dgm}_{i}^{(2)}(\mathsf{A}):=\mathrm{dgm}_{i}(\mathsf{A})\cap\{u_{1}\leq \varepsilon,u_{2}\geq\tau(\mathsf{M})-\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\}\) and \(\mathrm{dgm}_{i}^{(3)}(\mathsf{A}):=\mathrm{dgm}_{i}(\mathsf{A})\cap\{u_{1},u _{2}\geq\tau(\mathsf{M})-\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\}\)._

_Furthermore, let \(C=\frac{2}{\tau(\mathsf{M})}\left(1+\frac{R(\mathsf{M})}{\tau(\mathsf{M})}\right)\), where \(R(\mathsf{M})\) is the radius of the smallest ball that contains \(\mathsf{M}\). There exists an optimal matching \(\gamma:\mathrm{dgm}_{i}(\mathsf{A})\cup\partial\Omega\to\mathrm{dgm}_{i}( \mathsf{M})\cup\partial\Omega\) for the bottleneck distance between \(\mathrm{dgm}_{i}(\mathsf{A})\) and \(\mathrm{dgm}_{i}(\mathsf{M})\) such that_

* _Region (1): If_ \(u\in\mathrm{dgm}_{i}^{(1)}(\mathsf{A})\)_, then_ \(\gamma(u)\in\partial\Omega\) _and_ \(\|u-\gamma(u)\|_{\infty}\leq\varepsilon\)_._
* _Region (2): If_ \(u\in\mathrm{dgm}_{i}^{(2)}(\mathsf{A})\)_, then_ \(\gamma(u)\) _is of the form_ \((0,v_{2})\) _and_ \(|u_{2}-v_{2}|\leq C\varepsilon^{2}\)_. The number of such points is finite and depends only on_ \(\mathsf{M}\)_._
* _Region (3): If_ \(u\in\mathrm{dgm}_{i}^{(3)}(\mathsf{A})\)_, then_ \(\|u-\gamma(u)\|_{\infty}\leq C\varepsilon^{2}\)_._

Proof.: Proposition 5 from [7] states that if \(\varepsilon=d_{H}(\mathsf{A},\mathsf{M})<(\sqrt{2}-1)\tau(\mathsf{M})\), then the offset \(\mathsf{A}^{r}\) deformation-retracts onto \(\mathsf{M}\) for any

\[r\in\left[\frac{1}{2}(\tau(\mathsf{M})+\varepsilon-\sqrt{\Delta}),\frac{1}{2} (\tau(\mathsf{M})+\varepsilon+\sqrt{\Delta})\right]\]

and \(\Delta=\tau(\mathsf{M})^{2}-2\varepsilon\tau(\mathsf{M})-\varepsilon^{2}\). Under the stronger assumption that \(d_{H}(\mathsf{A},\mathsf{M})<\tau(\mathsf{M})/4\), and using elementary calculus, we find that the offset \(\mathsf{A}^{r}\) deformation-retracts onto \(\mathsf{M}\) for any

\[r\in\left[\varepsilon+\frac{\varepsilon^{2}}{\tau(\mathsf{M})},\tau(\mathsf{M })-\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\right].\]

This means in particular that the homology type, hence the homology, of \(\mathsf{A}^{r}\) does not change in that interval; as a result, there can be no birth or death of intervals in the Cech persistence diagrams of \(\mathsf{A}\) between \(\varepsilon+\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\) and \(\tau(\mathsf{M})-\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\), and all \((u_{1},u_{2})\in\mathrm{dgm}_{i}(\mathsf{A})\) must either be such that \(u_{1},u_{2}\leq\varepsilon+\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\), or \(u_{1}\leq\varepsilon+\frac{\varepsilon^{2}}{\tau(\mathsf{M})},u_{2}\geq\tau( \mathsf{M})-\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\), or \(u_{1},u_{2}\geq\tau(\mathsf{M})-\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\). This almost proves that the partition of \(\mathrm{dgm}_{i}(\mathsf{A})\) into \(\mathrm{dgm}_{i}^{(1)}(\mathsf{A})\), \(\mathrm{dgm}_{i}^{(2)}(\mathsf{A})\) and \(\mathrm{dgm}_{i}^{(3)}(\mathsf{A})\) as defined in the statement is correct, except that the definition of \(\mathrm{dgm}_{i}^{(2)}(\mathsf{A})\) requires that \(u_{1}\leq\varepsilon\), whereas we only have obtained that \(u_{1}\leq\varepsilon+\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\).

Let \(\gamma:\mathrm{dgm}_{i}(\mathsf{A})\cup\partial\Omega\to\mathrm{dgm}_{i}(\mathsf{ M})\cup\partial\Omega\) be any optimal matching for the bottleneck distance: then the Bottleneck Stability Theorem states that any point \(u=(u_{1},u_{2})\in\mathrm{dgm}_{i}(\mathsf{A})\) is such that \(\|u-\gamma(u)\|_{\infty}\leq d_{H}(\mathsf{A},\mathsf{M})\leq\varepsilon\). Suppose that \(u\) is such that \(u_{1}\leq\varepsilon+\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\) and \(u_{2}\geq\tau(\mathsf{M})-\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\).

Its distance in the infinity norm to the diagonal \(\partial\Omega\) is equal to \((u_{2}-u_{1})/2\geq(\tau(\mathsf{M})-\varepsilon-2\varepsilon^{2}/\tau(\mathsf{M }))/2\geq\frac{5}{16}\tau(\mathsf{M})>\varepsilon\), where we use the fact that \(\varepsilon<\tau(\mathsf{M})/4\). Hence \(\gamma(u)\) must belong to \(\operatorname{dgm}_{i}(\mathsf{M})\). Let \((v_{1},v_{2})\) denote \(\gamma(u)\). As in the proof of Proposition 3.2, the Isotopy Lemma shows that \(\operatorname{dgm}_{i}(\mathsf{M})\) only contains two types of points: points of the shape \((0,w_{2})\), which correspond to the homology of \(\mathsf{M}\) itself, and points of the shape \((w_{1},w_{2})\), where in both cases \(w_{1},w_{2}\) are critical values of \(d_{\mathsf{M}}\). In particular, both \(w_{1}\) and \(w_{2}\) must be greater than \(\operatorname{wfs}(\mathsf{M})\). Let \(\operatorname{dgm}_{i}^{(2)}(\mathsf{M})\) denote the multiset of all points of the first type, and \(\operatorname{dgm}_{i}^{(3)}(\mathsf{M})\) denote the multiset of all points of the second type. If \(v_{1}\) was non-zero, it would have to be greater than \(\operatorname{wfs}(\mathsf{M})\geq\tau(\mathsf{M})\), and we would have \(\|u-\gamma(u)\|_{\infty}\geq|u_{1}-v_{1}|\geq\tau(\mathsf{M})-\varepsilon- \frac{\varepsilon^{2}}{\tau(\mathsf{M})}\geq\tau(\mathsf{M})/2>\varepsilon\), which would be a contradiction (we once again use that \(\varepsilon<\tau(\mathsf{M})/4\)). Hence \(v_{1}\) must be \(0\) (i.e. \(\gamma(u)\in\operatorname{dgm}_{i}^{(2)}(\mathsf{M})\)), and \(u_{1}=|u_{1}-v_{1}|\leq\|u-\gamma(u)\|_{\infty}\leq\varepsilon\). This proves the correctness of the partition into regions from the statement.

Consider now \(u=(u_{1},u_{2})\in\operatorname{dgm}_{i}^{(1)}(\mathsf{A})\). All \(v=(v_{1},v_{2})\in\operatorname{dgm}_{i}(\mathsf{M})\) are such that

\[\|u-v\|_{\infty}\geq v_{2}-u_{2}\geq\operatorname{wfs}(\mathsf{M})- \varepsilon-\frac{\varepsilon^{2}}{\tau(\mathsf{M})}\geq\tau(\mathsf{M}) \left(1-\frac{1}{4}-\frac{1}{16}\right)>\varepsilon\geq\|u-\gamma(u)\|_{ \infty},\]

hence \(\gamma(u)\) must belong to \(\partial\Omega\). This completes the proof of the first bullet point of the statement.

We have already shown that if \(\gamma\) is an optimal matching and \(u\in\operatorname{dgm}_{i}^{(2)}(\mathsf{A})\), then \(\gamma(u)\in\operatorname{dgm}_{i}(\mathsf{M})\) is of the form \((0,v_{2})\). As \(\gamma\) maps at most a single point of \(\operatorname{dgm}_{i}^{(2)}(\mathsf{A})\) to each point of \(\operatorname{dgm}_{i}(\mathsf{M})\), the number of such points is upper bounded by the number of points of the form \((0,v_{2})\) with \(v_{2}\geq\operatorname{wfs}(\mathsf{M})\) in \(\operatorname{dgm}_{i}(\mathsf{M})\). Though \(\operatorname{dgm}_{i}(\mathsf{M})\) need not be finite (\(\mathsf{M}\) is not assumed to be generic), applying Corollary 3.34 from [22] to \(d_{\mathsf{M}}\) shows that \(\operatorname{dgm}_{i}(\mathsf{M})\) is q-tame, and in particular that it contains only a finite number \(N\) of points \((v_{1},v_{2})\) with \(v_{1}\leq\operatorname{wfs}(\mathsf{M})/4\) and \(v_{2}\geq\operatorname{wfs}(\mathsf{M})/2\). Hence the cardinality of \(\operatorname{dgm}_{i}^{(2)}(\mathsf{A})\) is bounded by \(N\).

It only remains to show that \(\gamma\) can be chosen such that if \(u=(u_{1},u_{2})\in\operatorname{dgm}_{i}^{(2)}(\mathsf{A})\), respectively \(u^{\prime}\in\operatorname{dgm}_{i}^{(3)}(\mathsf{A})\), then \(|u_{2}-\gamma(u)_{2}|\leq C\varepsilon^{2}\), respectively \(\|u^{\prime}-\gamma(u^{\prime})\|_{\infty}\leq C\varepsilon^{2}\). To that end, remember first that as shown above, our starting optimal matching \(\gamma\) must be such that points in \(\operatorname{dgm}_{i}^{(2)}(\mathsf{A})\) must be matched to points \(\operatorname{dgm}_{i}^{(2)}(\mathsf{M})\). Conversely and for the same reasons, points in \(\operatorname{dgm}_{i}^{(2)}(\mathsf{M})\) must be matched to points in \(\operatorname{dgm}_{i}^{(2)}(\mathsf{A})\). Similarly, points \(u\in\operatorname{dgm}_{i}^{(3)}(\mathsf{A})\) can only be matched to points in \(\operatorname{dgm}_{i}^{(3)}(\mathsf{M})\) or to the diagonal \(\partial\Omega\); otherwise, \(\|u-\gamma(u)\|_{\infty}\geq|u_{1}-\gamma(u)_{1}|=u_{1}\) would be too large. Likewise, points in \(\operatorname{dgm}_{i}^{(3)}(\mathsf{M})\) can only be matched to points in \(\operatorname{dgm}_{i}^{(3)}(\mathsf{A})\) or to the diagonal. Hence \(\gamma\) defines disjoint submatchings

\[\gamma^{(2)}:\operatorname{dgm}_{i}^{(2)}(\mathsf{A})\to\operatorname{dgm}_{i}^ {(2)}(\mathsf{M})\]

and

\[\gamma^{(3)}:\operatorname{dgm}_{i}^{(3)}(\mathsf{A})\cup\partial\Omega\to \operatorname{dgm}_{i}^{(3)}(\mathsf{M})\cup\partial\Omega.\]

Now let \(R(\mathsf{M})\) be the radius of the smallest ball that contains \(\mathsf{M}\), and consider the functions

\[a:\mathbb{R}^{d}\to\mathbb{R},x\mapsto\min(\max(d_{\mathsf{A}}(x),\tau(\mathsf{ M})/2),R(\mathsf{M}))\]

and

\[m:\mathbb{R}^{d}\to\mathbb{R},x\mapsto\min(\max(d_{\mathsf{M}}(x),\tau(\mathsf{ M})/2),R(\mathsf{M})).\]

Let us compare the persistence diagrams \(\operatorname{dgm}_{i}(a)\) and \(\operatorname{dgm}_{i}(m)\) of the sublevel sets filtration of \(a\) and \(m\) and the Cech persistence diagrams \(\operatorname{dgm}_{i}(\mathsf{A})\) and \(\operatorname{dgm}_{i}(\mathsf{M})\) respectively (which are by definition the persistence diagrams of the sublevel sets filtration of \(d_{\mathsf{A}}\) and \(d_{\mathsf{M}}\)).

Note first that \(d_{\mathsf{A}}\) and \(d_{\mathsf{M}}\) can have no critical values strictly greater than \(R(\mathsf{M})\), as a critical point must belong to the convex hull of its projections. Note also that for any \(t\in[\tau(\mathsf{M})/2,R(\mathsf{M})]\), the sublevel set \(a^{-1}(-\infty,t]\) is exactly equal to \(d_{\mathsf{A}}^{-1}(-\infty,t]=\mathsf{A}^{t}\). Consequently, \(\operatorname{dgm}_{i}(a)\) contains exactly two disjoint types of points. The first type are points of the form \((\tau(\mathsf{M})/2,u_{2})\), which are in bijection with the points \((u_{1},u_{2})\in\operatorname{dgm}_{i}(\mathsf{A})\) with \(u_{1}\leq\tau(\mathsf{M})/2\) (the bijection maps \((u_{1},u_{2})\mapsto(\tau(\mathsf{M})/2,u_{2})\)); those are exactly the points in \(\operatorname{dgm}_{i}^{(2)}(\mathsf{A})\). The second type are points of the form \((u_{1},u_{2})\) with \(u_{1}\geq\tau(\mathsf{M})/2\), which are in trivial bijection (the bijection is the identity) with the points in \(\operatorname{dgm}_{i}(\mathsf{A})\)that satisfy the same condition; those are exactly the points of \(\mathrm{dgm}_{i}^{(3)}(\mathsf{A})\). The points of \(\mathrm{dgm}_{i}^{(1)}(\mathsf{A})\) cannot be "seen" in \(\mathrm{dgm}_{i}(a)\). We will call \(\mathrm{dgm}_{i}^{(2)}(a)\) the subdiagram comprised of the points of the first type, and \(\mathrm{dgm}_{i}^{(3)}(a)\) the subdiagram of \(\mathrm{dgm}_{i}(a)\) comprised of the points of the second type.

Similarly, \(\mathrm{dgm}_{i}(m)\) contains two types of points: the first type are points of the form \((\tau(\mathsf{M})/2,v_{2})\), which are in bijection with the points \((0,v_{2})\in\mathrm{dgm}_{i}(\mathsf{M})\) (the bijection maps \((0,v_{2})\mapsto(\tau(\mathsf{M})/2,v_{2})\)); those are exactly the points in \(\mathrm{dgm}_{i}^{(2)}(\mathsf{M})\). The second type are points of the form \((v_{1},v_{2})\) with \(v_{1}\geq\tau(\mathsf{M})/2\), which are in trivial bijection (the bijection is the identity) with the points in \(\mathrm{dgm}_{i}(\mathsf{M})\) that satisfy the same condition; those are exactly the points of \(\mathrm{dgm}_{i}^{(3)}(\mathsf{M})\). We will call \(\mathrm{dgm}_{i}^{(2)}(m)\) the subdiagram of \(\mathrm{dgm}_{i}(m)\) comprised of the points of the first type, and \(\mathrm{dgm}_{i}^{(3)}(m)\) the subdiagram comprised of the points of the second type.

Recall that Lemma 2.1 states that \(|d_{\mathsf{M}}(z)-d_{\mathsf{A}}(z)|\leq\frac{\varepsilon^{2}}{2d_{\mathsf{M }}(z)}\left(1+\frac{d_{\mathsf{M}}(z)}{\tau(\mathsf{M})}\right)\) for any \(z\in\mathbb{R}^{d}\backslash\mathsf{M}\). If \(z\in\mathbb{R}^{d}\) is such that \(d_{\mathsf{A}}(z)\leq\tau(\mathsf{M})/2\), then \(a(z)=m(z)=\tau(\mathsf{M})/2\); if it is such that \(d_{\mathsf{M}}(z)\geq R(\mathsf{M})\), then \(a(z)=m(z)=R(\mathsf{M})\). Otherwise, \(d_{\mathsf{M}}(z)\geq d_{\mathsf{A}}(z)-d_{H}(\mathsf{A},\mathsf{M})\geq\tau( \mathsf{M})/4\) and \(d_{\mathsf{M}}(z)\leq R(\mathsf{M})\), hence

\[|d_{\mathsf{M}}(z)-d_{\mathsf{A}}(z)|\leq\frac{\varepsilon^{2}}{2d_{\mathsf{ M}}(z)}\left(1+\frac{d_{\mathsf{M}}(z)}{\tau(\mathsf{M})}\right)\leq\frac{2 \varepsilon^{2}}{\tau(\mathsf{M})}\left(1+\frac{R(\mathsf{M})}{\tau(\mathsf{M })}\right)=C\varepsilon^{2},\]

where \(C\) is as defined in the proposition. This means that

\[\|m-a\|_{\infty}\leq C\varepsilon^{2}.\]

Due to the Bottleneck Stability Theorem, the diagrams \(\mathrm{dgm}_{i}(a)\) and \(\mathrm{dgm}_{i}(m)\) must be at bottleneck distance less than \(C\varepsilon^{2}\).

Furthermore, let \(\delta\) denote \(\max_{u\in\mathrm{dgm}_{i}(\mathsf{A})\cup\partial\Omega}\|u-\gamma(u)\|_{\infty}\). The matching \(\gamma\) (and in particular the submatchings \(\gamma^{(2)}\) and \(\gamma^{(3)}\)) also induces (through the correspondence detailed above between the points of \(\mathrm{dgm}_{i}(a)\) and a subset of the points of \(\mathrm{dgm}_{i}(\mathsf{A})\)) a matching \(\gamma^{\prime}\) between \(\mathrm{dgm}_{i}(a)\) and \(\mathrm{dgm}_{i}(m)\) such that \(\max_{u\in\mathrm{dgm}_{i}(a)\cup\partial\Omega}\|u-\gamma^{\prime}(u)\|_{\infty}\leq\delta\). Hence the bottleneck distance between \(\mathrm{dgm}_{i}(a)\) and \(\mathrm{dgm}_{i}(m)\) is at most \(\min(\delta,C\varepsilon^{2})\).

Let \(\beta:\mathrm{dgm}_{i}(a)\cup\partial\Omega\to\mathrm{dgm}_{i}(m)\cup\partial\Omega\) be an optimal matching for the bottleneck distance. For similar reasons as for \(\gamma\), the matching \(\beta\) can also be decomposed into two disjoint submatchings

\[\beta^{(2)}:\mathrm{dgm}_{i}^{(2)}(a)\to\mathrm{dgm}_{i}^{(2)}(m)\]

and

\[\beta^{(3)}:\mathrm{dgm}_{i}^{(3)}(a)\cup\partial\Omega\to\mathrm{dgm}_{i}^{( 3)}(m)\cup\partial\Omega.\]

We can use the two matchings \(\beta^{(2)}\) and \(\beta^{(3)}\) to define a new optimal matching \(\tilde{\gamma}:\mathrm{dgm}_{i}(\mathsf{A})\cup\partial\Omega\to\mathrm{dgm}_ {i}(\mathsf{M})\cup\partial\Omega\) as follows:

* The points in \(\mathrm{dgm}_{i}^{(1)}(\mathsf{A})\) are matched by \(\tilde{\gamma}\) to \(\partial\Omega\) as with \(\gamma\).
* Given \(u=(u_{1},u_{2})\in\mathrm{dgm}_{i}^{(2)}(\mathsf{A})\), let \(u^{\prime}=(\tau(\mathsf{M})/2,u_{2})\) be the point of \(\mathrm{dgm}_{i}^{(2)}(a)\) with which \(u\) is in bijection. We let \(\tilde{\gamma}\) match \(u\) with the point \(v=(0,v_{2})\in\mathrm{dgm}_{i}^{(2)}(\mathsf{M})\) which is in bijection with \(\beta^{(2)}(u^{\prime})=(\tau(\mathsf{M})/2,v_{2})\in\mathrm{dgm}_{i}^{(2)}(m)\). Then \(|u_{2}-v_{2}|\leq\min\left(\delta,C\varepsilon^{2}\right)\) due to the optimality of \(\beta\), and this defines a bijective matching \(\tilde{\gamma}^{(2)}:\mathrm{dgm}_{i}^{(2)}(\mathsf{A})\to\mathrm{dgm}_{i}^{(2)}( \mathsf{M})\). Note also that \(\max_{u\in\mathrm{dgm}_{i}^{(2)}(\mathsf{A})}|u_{1}-\tilde{\gamma}^{(2)}(u)_{1}|= \max_{u\in\mathrm{dgm}_{i}^{(2)}(\mathsf{A})}u_{1}=\max_{u\in\mathrm{dgm}_{i}^{( 2)}(\mathsf{A})}|u_{1}-\gamma^{(2)}(u)_{1}|\), hence \(\max_{u\in\mathrm{dgm}_{i}^{(2)}(\mathsf{A})}\|u-\tilde{\gamma}^{(2)}(u)\|_{\infty}\leq\delta\).
* We have seen that \(\mathrm{dgm}_{i}^{(3)}(a)=\mathrm{dgm}_{i}^{(3)}(\mathsf{A})\) and \(\mathrm{dgm}_{i}^{(3)}(m)=\mathrm{dgm}_{i}^{(3)}(\mathsf{M})\). We simply define the restriction and corestrictive \(\tilde{\gamma}^{(3)}:\mathrm{dgm}_{i}^{(3)}(\mathsf{A})\cup\partial\Omega\to \mathrm{dgm}_{i}^{(3)}(\mathsf{M})\cup\partial\Omega\) of \(\tilde{\gamma}\) as being equal to \(\beta^{(3)}:\mathrm{dgm}_{i}^{(3)}(a)\cup\partial\Omega\to\mathrm{dgm}_{i}^{(3)}( m)\cup\partial\Omega\). The optimality of \(\beta\) implies that \(\max_{u\in\mathrm{dgm}_{i}^{(3)}(\mathsf{A})}\|u-\tilde{\gamma}(u)\|_{\infty}\leq\min \left(\delta,C\varepsilon^{2}\right)\).

Thus the global matching \(\tilde{\gamma}:\mathrm{dgm}_{i}(\mathsf{A})\cup\partial\Omega\to\mathrm{dgm}_ {i}(\mathsf{M})\cup\partial\Omega\) is well-defined, is optimal for the bottleneck distance, and satisfies the conditions stated in the proposition. This completes the proof.

Proof of Theorem 3.3

We prove Theorem 3.3, which we restate for the reader's convenience:

**Theorem 3.3**.: _Let \(\mathsf{M}\subset\mathbb{R}^{d}\) be a generic compact submanifold and \(\mathsf{A}\subset\mathsf{M}\) be a \((\delta,\varepsilon)\)-dense set in \(\mathsf{M}\) for some \(\varepsilon,\delta>0\). Let \(a\geq\varepsilon/\delta\) and let \(i\geq 0\) be an integer. There exist \(\varepsilon_{0}>0\) depending only on \(\mathsf{M}\) and \(C_{0},C_{1},C_{2},C_{3}\) depending only on \(\mathsf{M}\) and \(a\) such that if \(\varepsilon\leq\varepsilon_{0}\), then \(\mathrm{dgm}_{i}^{(3)}(\mathsf{A})\) has at most \(C_{0}\) points and for all \(p\geq 1\), \(\alpha\geq 0\),_

\[\begin{split}\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}), \mathrm{dgm}_{i}(\mathsf{M}))&\leq C_{1}\varepsilon^{p-m}\\ \mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}))& \leq C_{2}(C_{3}^{\alpha}+\varepsilon^{\alpha-m}).\end{split}\] (8)

Proof.: Let us first prove the bound on the cardinality of \(\mathrm{dgm}_{i}^{(3)}(\mathsf{A})\). As \(\mathsf{M}\) is generic, Theorem 1.6 from [6] states that if \(\varepsilon\) is smaller than some \(\varepsilon_{0}=\varepsilon_{0}(\mathsf{M})\), then each point in \(\mathrm{Crit}(\mathsf{A})\) at distance more than \(\tau(\mathsf{M})/2\) from \(\mathsf{A}\) must be at distance at most \(K_{1}\varepsilon\) from one of the finitely many points of \(\mathrm{Crit}(\mathsf{M})\) for some \(K_{1}=K_{1}(\mathsf{M})\). Corollary 1.7 from the same article then states that the number of points in \(\mathrm{Crit}(\mathsf{A})\) at distance less than \(K_{1}\varepsilon\) from a given point of \(\mathrm{Crit}(\mathsf{M})\) is upper bounded by some constant that depends on \(\mathsf{M}\) and the ratio \(\varepsilon/\delta\), and is decreasing in this ratio; hence it is upper bounded by some constant that depends on \(\mathsf{M}\) and \(a\). The proof of this corollary also shows that the maximum number of projections on \(\mathsf{A}\) of each of these points of \(\mathrm{Crit}(\mathsf{A})\) is also upper bounded by some constant that depends on \(\mathsf{M}\) and \(a\). Hence there exist constants \(K_{2}=K_{2}(\mathsf{M},a)\) and \(K_{3}=K_{3}(\mathsf{M},a)\) such that if \(\varepsilon\leq\varepsilon_{0}\), then there are at most \(K_{2}\) points in \(\mathrm{Crit}(\mathsf{A})\) at distance more than \(\tau(\mathsf{M})/2\) from \(\mathsf{A}\), and each has at most \(K_{3}\) projections on \(\mathsf{A}\).

Lemma E.1 below, applied to the interval \([\tau(\mathsf{M})/2,\infty)\) and the set \(\mathsf{A}\), then states that the number of points in \(\mathrm{dgm}_{i}(\mathsf{A})\) such that at least one of their coordinates is greater than \(\tau(\mathsf{M})/2\) is bounded by \(K_{2}(\binom{K_{3}}{i+1}+\binom{K_{3}}{i+2})\). Hence there are at most \(C_{0}:=K_{2}2^{K_{3}}\geq K_{2}(\binom{K_{3}}{i+1}+\binom{K_{3}}{i+2})\) points in \(\mathrm{dgm}_{i}^{(3)}(\mathsf{A})\) when \(\varepsilon\leq\varepsilon_{0}\).

Now let us prove the bounds on \(\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}),\mathrm{dgm}_{i}(\mathsf{M}))\) and \(\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}))\). As stated in Theorem 2.2, which applies as \(\varepsilon_{0}<\tau(\mathsf{M})/4\), each point \(u=(u_{1},u_{2})\in\mathrm{dgm}_{i}^{(1)}(\mathsf{A})\) is such that its coordinates satisfy \(0\leq u_{1},u_{2}\leq\varepsilon+\varepsilon^{2}/\tau(\mathsf{M})\leq 2\varepsilon\). In particular, they must correspond to the birth or the death of an interval of the \(\mathsf{C}\)ech persistence module of \(\mathsf{A}\) that occurs before filtration time \(2\varepsilon\). The homology of the offsets \(\mathsf{A}^{t}\) can be computed using the \(\mathsf{C}\)ech simplicial complex of \(\mathsf{A}\) (see e.g. [37]). In particular, each change in the homology of the offsets, hence each birth or death in the \(\mathsf{C}\)ech persistence module of \(\mathsf{A}\), is induced by the apparition of some simplex \(\sigma\) at the corresponding filtration value in the \(\mathsf{C}\)ech complex, and each such apparition causes at most a single death or birth. If a simplex \(\sigma\) appears before filtration time \(2\varepsilon\), it is by definition contained in a ball of radius \(2\varepsilon\), hence it is of diameter at most \(4\varepsilon\). Let us assume from now on that \(\varepsilon_{0}\leq\tau(\mathsf{M})/16\). Consider \(x\in\mathsf{A}\); then [2, Proposition 8.7] states that the intersection \(\overline{B}(x,4\varepsilon)\cap\mathsf{A}\) contains at most \(K_{4}(\varepsilon/\delta)^{m}\leq K_{4}a^{m}\) points for some constant \(K_{4}=K_{4}(\mathsf{M})\). Hence \(x\) belongs to at most \(2^{K_{4}a^{m}}\) simplices that appear before \(\varepsilon\), and there are at most \(\#\mathsf{A}\cdot 2^{K_{4}a^{m}}\) such simplices. As the cardinality \(\#\mathsf{A}\) can be bounded by \(K_{5}/\delta^{m}\) for some \(K_{5}=K_{5}(\mathsf{M})\), we find that \(\#(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}))\leq K_{6}/\delta^{m}\) for some \(K_{6}=K_{6}(\mathsf{M},a)\).

Furthermore, when \(\mathsf{M}\) is generic, Proposition 3.2 states that its PD \(\mathrm{dgm}_{i}(\mathsf{M})\) has a finite number of points. Let \(\gamma\) be an optimal matching between \(\mathrm{dgm}_{i}(\mathsf{A})\) and \(\mathrm{dgm}_{i}(\mathsf{M})\) for the bottleneck distance that satisfies the conclusions of Theorem 2.2. We find that any point \(u\in\mathrm{dgm}_{i}^{(1)}(\mathsf{A})\) is matched to a point of \(\partial\Omega\) at distance at most \(\varepsilon\) from \(u\). Moreover, the number of points in \(\mathrm{dgm}_{i}^{(2)}(\mathsf{A})\cup\mathrm{dgm}_{i}^{(3)}(\mathsf{A})\) is bounded by some constant \(K_{7}=K_{7}(\mathsf{M},a)\), and they are all matched to a point of \(\mathrm{dgm}_{i}(\mathsf{M})\) or \(\partial\Omega\) at distance at most \(\varepsilon\). In particular, these finitely many points are at distance at most \(K_{8}=K_{8}(\mathsf{M})\) from \(\partial\Omega\). Furthermore, this matching is surjective, in the sense that \(\gamma\) matches all points of \(\mathrm{dgm}_{i}(\mathsf{M})\) to a point of \(\mathrm{dgm}_{i}(\mathsf{A})\). As a result, for any \(p\geq 1\), we find that

\[\begin{split}\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}), \mathrm{dgm}_{i}(\mathsf{M}))&\leq\sum_{u\in\mathrm{dgm}_{i}^{(1)}( \mathsf{A})}\|u-\gamma(u)\|_{\infty}^{p}+\sum_{u\in\mathrm{dgm}_{i}^{(2)}( \mathsf{A})\cup\mathrm{dgm}_{i}^{(3)}(\mathsf{A})}\|u-\gamma(u)\|_{\infty}^{p} \\ &\leq K_{6}\delta^{-m}\varepsilon^{p}+K_{7}\varepsilon^{p}\leq K_{ 6}a^{m}\varepsilon^{p-m}+K_{7}\varepsilon^{p}\leq C_{1}\varepsilon^{p-m} \end{split}\]for some \(C_{1}=C_{1}(\mathsf{M},a)\). Likewise, for any \(\alpha\geq 0\), we have that

\[\operatorname{Pers}_{\alpha}(\operatorname{dgm}_{i}(\mathsf{A})) =\sum_{u\in\operatorname{dgm}_{i}^{(1)}(\mathsf{A})}\operatorname{ pers}(u)^{\alpha}+\sum_{u\in\operatorname{dgm}_{i}^{(2)}(\mathsf{A})\cup \operatorname{dgm}_{i}^{(3)}(\mathsf{A})}\operatorname{pers}(u)^{\alpha}\] \[\leq K_{6}\delta^{-m}\varepsilon^{\alpha}+K_{7}K_{8}^{\alpha} \leq K_{6}a^{m}\varepsilon^{\alpha-m}+K_{7}K_{8}^{\alpha}\leq C_{2}(C_{3}^{ \alpha}+\varepsilon^{\alpha-m})\]

for some \(C_{2}=C_{2}(\mathsf{M},a),C_{3}=C_{3}(\mathsf{M})\). This completes the proof. 

**Lemma E.1**.: _Let \(\mathsf{A}\subset\mathbb{R}^{d}\) be a finite set, and let \(a<b\in\mathbb{R}\cup\{-\infty,+\infty\}\) and \(i\geq 0\). Let_

\[\bigcup_{j=1}^{L}C_{j}=\operatorname{Crit}(\mathsf{A})\cap d_{\mathsf{A}}^{- 1}[a,b]\]

_be a covering of the set of critical points of \(d_{\mathsf{A}}\) whose critical value belongs to \([a,b]\),8 and let_

Footnote 8: When \(a=-\infty\), we commit a minor abuse of notation by writing \([a,b]\) rather than \((a,b]\), and similarly when \(b=+\infty\).

\[N_{j}:=\#\left(\bigcup_{z\in C_{j}}\sigma_{\mathsf{A}}(z)\right)\]

_be the cardinality of the union of the projections of the critical points of \(C_{j}\). Then the number of points in \(\operatorname{dgm}_{i}(\mathsf{A})\) such that at least one of their coordinates belongs to \([a,b]\) is upper-bounded by \(\sum_{j=1}^{L}\binom{N_{j}}{i+1}+\binom{N_{j}}{i+2}\), hence by \(\sum_{j=1}^{L}N_{j}^{i+2}\)._

Proof.: It is shown in [5] that the distance function to any finite point cloud is a topological Morse function. Hence its topological critical points are in bijection (via their critical values) with the non-zero coordinates of the points in (the union over all degrees of) the Cech persistence diagrams of \(\mathsf{A}\). The number of points in \(\operatorname{dgm}_{i}(\mathsf{A})\) such that at least one of their coordinates belongs to \([a,b]\) must then be upper bounded by the number of topological critical points \(z\) of topological Morse index \(i\) or \(i+1\) such that \(d_{\mathsf{A}}(z)\in[a,b]\). Moreover, it is also shown that the topological critical points of \(d_{\mathsf{A}}\) are a subset of \(\mathsf{A}\cup\operatorname{Crit}(\mathsf{A})\), though not all differential critical points need be topologically critical. Hence any such \(z\) belongs to \(C_{j}\) for some \(j\in\{1,\ldots,L\}\), and \(\sigma_{\mathsf{A}}(z)\subset\bigcup_{z^{\prime}\in C_{j}}\sigma_{\mathsf{A}} (z^{\prime})\).

As shown in [5], if \(z\) is of critical index \(i\), then the linear span \(\operatorname{Span}(\sigma_{\mathsf{A}}(z)-z)\) is of dimension \(i\). By Caratheodory's theorem, there exists \(i+1\) affinely independent points in \(\sigma_{\mathsf{A}}(z)\subset\bigcup_{z^{\prime}\in C_{j}}\sigma_{\mathsf{A}} (z^{\prime})\) such that \(z\) belongs to their convex hull. Those \(i+1\) points uniquely identify \(z\) among the critical points of \(\mathsf{A}\), as it is the only point equidistant to them that belongs to their convex hull. Hence there is an injection from the topological critical points of \(\mathsf{A}\) of index \(i\) that belong to \(C_{j}\) into the set of subsets of cardinality \(i+1\) of \(\bigcup_{z^{\prime}\in C_{j}}\sigma_{\mathsf{A}}(z^{\prime})\). Applying the same reasoning to the points of index \(i+1\), we find that there are at most \(\sum_{j=1}^{n}\binom{N_{j}}{i+1}+\binom{N_{j}}{i+2}\) points in \(\operatorname{dgm}_{i}(\mathsf{A})\) with at least one of their coordinates in \([a,b]\), as desired. 

## Appendix F The \(\operatorname{OT}_{p}\) distance between Radon measures

Let \(\mathcal{M}\) denote the space of Radon measures on \(\Omega\), and let us define \(\bar{\Omega}:=\{u=(u_{1},u_{2})\in\mathbb{R}^{2}:u_{1}\leq u_{2}\}\). We call \(\pi\) an admissible transport plan between \(\nu_{1},\nu_{2}\in\mathcal{M}\) if it is a Radon measure on \(\bar{\Omega}\times\bar{\Omega}\) such that for all Borel sets \(A,B\subset\Omega\),

\[\pi(A\times\bar{\Omega})=\nu_{1}(A)\quad\text{ and }\pi(\bar{\Omega}\times B)= \nu_{2}(B).\] (17)

For \(p\in[1,+\infty)\), we define

\[\operatorname{OT}_{p}^{p}(\nu_{1},\nu_{2})=\inf_{\pi\in\text{Adm}(\nu_{1},\nu _{2})}\iint\|u-v\|_{\infty}^{p}\mathrm{d}\pi(u,v)\in\mathbb{R}\cup\{+\infty\},\] (18)

where \(\|u\|_{\infty}=\max(|u_{1}|,|u_{2}|)\) and \(\text{Adm}(\nu_{1},\nu_{2})\) is the set of all admissible transport plans between \(\nu_{1}\) and \(\nu_{2}\). We also define

\[\operatorname{OT}_{\infty}(\nu_{1},\nu_{2})=\inf_{\pi\in\text{Adm}(\nu_{1},\nu _{2})}\sup\{\|u-v\|_{\infty}\,:\,(u,v)\in\text{Support}(\pi)\}\] (19)For all \(p\in[1,\infty]\), the infimum is in fact a minimum (see [33]). We call \(\operatorname{OT}_{p}(\nu_{1},\nu_{2})\) the \(p\)-Wasserstein distance between \(\nu_{1}\) and \(\nu_{2}\), though it differs from the usual Wasserstein distance, which is defined between measures with equal finite mass, while \(\operatorname{OT}_{p}\) is defined between measures that can have different (and even infinite) masses. Intuitively, \(\operatorname{OT}_{p}\) allows for some of the mass of \(\nu_{1}\) and \(\nu_{2}\) to be transported to the diagonal \(\partial\Omega:=\{(u,u)\in\mathbb{R}^{2}\}\), which acts as an infinitely deep landfill. The \(p\)-Wasserstein distance is a distance on the space \(\mathcal{M}_{p}=\{\nu\in\mathcal{M}:\ \operatorname{OT}_{p}(\nu,0)<\infty\}\), where \(0\) denotes the null measure.

As explained in Section 4, a PD \(a\) can be identified with the Radon measure \(\sum_{u\in q}\delta_{u}\). Let \(\mathcal{D}_{p}\) be the set of PDs being in \(\mathcal{M}_{p}\). Then, Divol and Lacombe show in [33] that the \(\operatorname{OT}_{p}\) distance defined in (18) coincides with the \(\operatorname{OT}_{p}\) distance defined between PDs in Equation (3), and likewise for the case \(p=\infty\).

We require the following lemma from [33]:

**Lemma F.1**.: _A sequence of measures \((\nu_{n})_{n\geq 1}\) converges with respect to \(\operatorname{OT}_{p}\) to some measure \(\nu\) if and only if the sequence \((\nu_{n})_{n\geq 1}\) converges vaguely towards \(\nu\) and \(\operatorname{Pers}_{p}(\nu_{n})\to\operatorname{Pers}_{p}(\nu)\) as \(n\to\infty\)._

## Appendix G Proofs of Section 4

We start with the proof Theorem 4.1, which is split into a series of lemmas, before proving Proposition 4.2, Corollary 4.3 and Corollary 4.4.

Let us restate Theorem 4.1 for the reader's convenience:

**Theorem 4.1** (Law of large numbers).: _Assume that \(P\) has a density \(f\) on \(\mathsf{M}\) bounded away from \(0\) and \(\infty\). Let \(i\geq 0\) be an integer and let \(1\leq p<\infty\). Then \(\mu_{f,i}\in\mathcal{M}_{p}\) and \(\mathbb{E}[\operatorname{OT}_{p}^{p}(\mu_{n,i},\mu_{f,i})]\xrightarrow[n\to\infty] {}0\). Furthermore, for all \(\alpha>0\), \(\operatorname{Pers}_{\alpha}(\operatorname{dgm}_{i}^{(1)}(\mathsf{A}_{n}))n^{ \frac{\alpha}{m}-1}=\operatorname{Pers}_{\alpha}(\mu_{n,i})=\operatorname{ Pers}_{\alpha}(\mu_{f,i})+o_{L^{1}}(1)\)._

Before proving Theorem 4.1, we state a simple lemma which allows us to control the mass of balls on \(\mathsf{M}\).

**Lemma G.1**.: _Let \(\mathsf{M}\) be a compact submanifold with positive reach. Let \(P\) be a probability measure having a density \(f\) on \(\mathsf{M}\) satisfying \(f_{\min}\leq f\leq f_{\max}\) for two strictly positive constants \(f_{\min}\), \(f_{\max}\). There exist constants \(c_{m},C_{m}\) depending only on \(m\) such that for all \(0\leq r\leq\tau(\mathsf{M})/4\)_

\[c_{m}f_{\min}r^{m}\leq P(\overline{B}(x,r))\leq C_{m}f_{\max}r^{m}.\] (20)

_Let \(\mathsf{A}_{n}\) be a sample of \(n\) i.i.d. observations of law \(P\). Then, there exists \(C=C(\mathsf{M})\) depending on \(\mathsf{M}\) such that for all \(x\in\mathsf{M}\) and all \(r>0\),_

\[\mathbb{P}(d(x,\mathsf{A}_{n})\geq r)\leq\exp(-nCf_{\min}r^{m}).\] (21)

Proof.: For the first statement, see [2, Proposition 31]. Let us prove the second one. Remark that the probability is zero for \(r>\operatorname{diam}(\mathsf{M})\). Hence, we can assume that \(r\leq\operatorname{diam}(\mathsf{M})\). When \(r\leq\tau(\mathsf{M})/4\), it holds that

\[\mathbb{P}(d(x,\mathsf{A}_{n})\geq r)=(1-P(\overline{B}(x,r)))^{n}\leq\exp(- nc_{m}f_{\min}r^{m}).\]

When \(\tau(\mathsf{M})/4\leq r\leq\operatorname{diam}(\mathsf{M})\), we write

\[\mathbb{P}(d(x,\mathsf{A}_{n})\geq r) \leq\mathbb{P}(d(x,\mathsf{A}_{n})\geq\tau(\mathsf{M})/4)\leq \exp(-nc_{m}f_{\min}(\tau(\mathsf{M})/4)^{m})\] \[\leq\exp(-nc_{m}f_{\min}\frac{(\tau(\mathsf{M})/4)^{m}}{ \operatorname{diam}(\mathsf{M})^{m}}r^{m}).\]

Hence, the result holds with \(C=c_{m}\min\left(1,\frac{(\tau(\mathsf{M})/4)^{m}}{\operatorname{diam}( \mathsf{M})^{m}}\right)\). 

Proof of Theorem 4.1.: Recall that Goel, Trinh and Tsunoda [42] have shown that almost surely, the sequence of Radon measures \((\mu_{n,i})_{n}\) vaguely converges to the Radon measure \(\mu_{f,i}\). We start by showing that, using this vague convergence and Lemma F.1, it is enough to prove the convergence of the \(p\)-total persistence.

**Lemma G.2**.: _Let \((\nu_{n})_{n\geq 1}\) be a sequence of random measures in \(\mathcal{M}_{p}\) that converges vaguely almost surely to a Radon measure \(\nu\in\mathcal{M}_{p}\), and such that \(\mathbb{E}[|\mathrm{Pers}_{p}(\nu_{n})-\mathrm{Pers}_{p}(\nu)||]\to_{n\to\infty}0\). Then, \(\mathbb{E}[\mathrm{OT}_{p}^{p}(\nu_{n},\nu)]\to_{n\to\infty}0\)._

Proof.: Let us first show that \((D_{n})_{n\geq 1}=(\mathrm{OT}_{p}^{p}(\nu_{n},\nu))_{n\geq 1}\) converges in probability to \(0\). We use the following standard result: if for every subsequence \((Z_{n_{k}})_{k\geq 1}\) of \((Z_{n})_{n\geq 1}\), one can extract a subsequence \((Z_{n_{k}})_{l\geq 1}\) that converges almost surely to \(0\), then the sequence \((Z_{n})_{n\geq 1}\) converges in probability to \(0\). Let \((D_{n_{k}})_{k\geq 1}\) be a subsequence of \((D_{n})_{n\geq 1}=(\mathrm{OT}_{p}^{p}(\nu_{n},\nu))_{n\geq 1}\). Then, as \((\mathrm{Pers}_{p}(\nu_{n}))_{n\geq 1}\) converges in \(L^{1}\) to \(\mathrm{Pers}_{p}(\nu)\), it also converges in probability. In particular, there exists a subsequence \((n_{k_{l}})_{l\geq 1}\) such that \((\mathrm{Pers}_{p}(\nu_{n_{k_{l}}}))_{n\geq 1}\) converges almost surely to \(\mathrm{Pers}_{p}(\nu)\). When restricting ourselves to this subsequence, we have both vague convergence of the measures and convergence of the \(p\)-total persistence. Hence, according to Lemma F.1, we have \(D_{n_{k_{l}}}=\mathrm{OT}_{p}^{p}(\nu_{n_{k_{l}}},\nu)\to_{l\to\infty}0\) almost surely, proving that we actually have that \((D_{n})_{n\geq 1}\) converges in probability to \(0\). To prove that \(\mathbb{E}[D_{n}]\to_{n\to\infty}0\), it remains to show that the sequence \((D_{n})_{n\geq 1}\) is uniformly integrable. By considering the trivial transport plan that sends all probability mass to \(\partial\Omega\), we have for all \(n\geq 1\)

\[D_{n}\leq\mathrm{Pers}_{p}(\nu_{n})+\mathrm{Pers}_{p}(\nu).\]

But the sequence \((\mathrm{Pers}_{p}(\nu_{n}))_{n\geq 1}\) is uniformly integrable, as it converges in \(L^{1}\). Hence, so is the sequence \((D_{n})_{n\geq 1}\), concluding the proof. 

Using Lemma G.2, Theorem 4.1 would follow from the facts that \(\mu_{f,i}\in\mathcal{M}_{p}\) and that \(\mathbb{E}[|\mathrm{Pers}_{p}(\mu_{n,i})-\mathrm{Pers}_{p}(\mu_{f,i})||]\) converges to \(0\).

Recall that \(C_{c}(\Omega)\) is the set of continuous functions \(f:\Omega\to\mathbb{R}\) with compact support (i.e. the support is bounded and at positive distance from \(\partial\Omega\)). For \(s\geq 0\), let \(T_{s}=\{(u_{1},u_{2})\in\Omega:\ u_{2}\geq s\}\).

**Lemma G.3**.: _Let \(\alpha>0\). Let \((\nu_{n})_{n\geq 1}\) be a sequence of random measures in \(\mathcal{M}_{\alpha}\) that converges vaguely almost surely to a Radon measure \(\nu\in\mathcal{M}\). Assume that the sequence of random variables \((\nu_{n}(\Omega))_{n\geq 1}\) is uniformly integrable and that_

\[\sup_{n}\mathbb{E}[\mathrm{Pers}_{\alpha}(\nu_{n})]<+\infty\text{ and }\lim_{s\to+\infty}\limsup_{n}\mathbb{E}[\int_{T_{s}}\mathrm{pers}^{\alpha}(u) \mathrm{d}\nu_{n}(u)]=0.\]

_Then, \(\nu\in\mathcal{M}_{\alpha}\) and \(\mathbb{E}[|\mathrm{Pers}_{\alpha}(\nu_{n})-\mathrm{Pers}_{\alpha}(\nu)||]\to_ {n\to\infty}0\)._

Proof.: We divide the proof into several steps.

1. Let \(\phi\in C_{c}(\Omega)\). We first show that \((\int\phi\mathrm{d}\nu_{n}))_{n\geq 1}\) converges in \(L^{1}\) to \(\int\phi\mathrm{d}\nu\). By assumption, the convergence holds almost surely. Furthermore, as \(\phi\) is bounded and as the sequence \((\nu_{n}(\Omega))_{n\geq 1}\) is uniformly integrable, so is the sequence \((\int\phi\mathrm{d}\nu_{n})_{n\geq 1}\). Hence, \(\mathbb{E}[|\int\phi\mathrm{d}(\nu_{n}-\nu)||\to_{n\to\infty}0\).
2. Let \((\phi_{k})_{k\geq 1}\) be an increasing sequence of functions in \(C_{c}(\Omega)\) that converge pointwise to the function \(\mathrm{pers}_{\alpha}\). Then, almost surely, \[\int\phi_{k}\mathrm{d}\nu\leq\liminf_{n\to\infty}\int\phi_{k}\mathrm{d}\nu_{ n}\leq\liminf_{n\to\infty}\int\mathrm{pers}_{\alpha}\mathrm{d}\nu_{n}.\] By Fatou's lemma, \(\mathbb{E}[\liminf_{n\to\infty}\int\mathrm{pers}_{\alpha}\mathrm{d}\nu_{n}] \leq\liminf_{n\to\infty}\mathbb{E}[\mathrm{Pers}_{\alpha}(\nu_{n})]=C<+\infty\) by assumption. Hence, by letting \(k\to\infty\) and applying the monotone convergence theorem, we obtain \(\mathrm{Pers}_{\alpha}(\nu)\leq C\), proving that \(\nu\in\mathcal{M}_{\alpha}\).
3. The same argument can be applied to the constant function equal to \(1\), showing that \(\nu(\Omega)<+\infty\).
4. Let \(s\geq 1\). The function \(\mathrm{pers}_{\alpha}\) can be decomposed into a sum of three positive continuous functions \(\mathrm{pers}_{\alpha}=\phi_{s}^{(1)}+\phi_{s}^{(2)}+\phi_{s}^{(3)}\), where \(\phi_{s}^{(1)}\) has compact support, the support ofis included in the band \(\{u\in\Omega:\ \mathrm{pers}(u)\leq 1/s\}\) and the support of \(\phi_{s}^{(3)}\) is included in \(T_{s}\). Hence,

\[\limsup_{n\to+\infty}\mathbb{E}[|\mathrm{Pers}_{\alpha}(\nu_{n}) -\mathrm{Pers}_{\alpha}(\nu)|]\leq\limsup_{n\to+\infty}\mathbb{E}[| \int\phi_{s}^{(1)}\mathrm{d}(\nu_{n}-\nu)|]\] \[+\limsup_{n\to+\infty}\mathbb{E}[|\int\phi_{s}^{(2)}\mathrm{d}( \nu_{n}-\nu)|]+\limsup_{n\to+\infty}\mathbb{E}[|\int\phi_{s}^{(3)}\mathrm{d}( \nu_{n}-\nu)|].\]

The first term in the above sum is equal to zero because of the first item, the second one is smaller than \(s^{-\alpha}(\sup_{n}\mathbb{E}[\nu_{n}(\Omega)]+\nu(\Omega))\), and the third one is smaller than

\[\limsup_{n}\mathbb{E}[\int_{T_{s}}\mathrm{pers}_{\alpha}(u)\mathrm{d}\nu_{n}(u )]+\int_{T_{s}}\mathrm{pers}_{\alpha}(u)\mathrm{d}\nu(u).\]

Using the hypotheses of the lemma, the second and the third term converges to \(0\) as \(s\) goes to \(\infty\). We obtain that \(\limsup_{n\to+\infty}\mathbb{E}[|\mathrm{Pers}_{\alpha}(\nu_{n})-\mathrm{Pers }_{\alpha}(\nu)|]=0\). 

Our goal is to show that the conditions of Lemma G.3 holds for the sequence \((\mu_{n,i})_{n\geq 1}\) to conclude. Remark that for any Radon measure \(\nu\in\mathcal{M}_{\alpha}\) and \(s\geq 0\)

\[\int_{T_{s}}\mathrm{pers}^{\alpha}(u)\mathrm{d}\nu(u) =\alpha\int_{0}^{\infty}t^{\alpha-1}\nu(T_{s}\cap\{u:\ \mathrm{pers}(u)\geq t\})\mathrm{d}t\] (22) \[\leq\alpha\int_{s/2}^{\infty}t^{\alpha-1}\nu(T_{2t})\mathrm{d}t+ \alpha\int_{0}^{s/2}t^{\alpha-1}\nu(T_{s})\mathrm{d}t\] \[\leq\alpha\int_{s/2}^{\infty}t^{\alpha-1}\nu(T_{2t})\mathrm{d}t+ (s/2)^{\alpha}\nu(T_{s}),\]

where we use Fubini's theorem for the first equality and the fact that \(\{u:\ \mathrm{pers}(u)\geq t\}\subset T_{2t}\) for the first inequality. We also have \(\nu(\Omega)=\nu(T_{0})\). Hence, the different conditions of Lemma G.3 can all be obtained by controlling the random variable \(\mu_{n,i}(T_{s})\) for \(s\geq 0\).

**Proposition G.4**.: _Let \(\mathsf{M}\) be a compact submanifold with positive reach. Assume that \(P\) has a density \(f\) on \(\mathsf{M}\) satisfying \(f_{\min}\leq f\leq f_{\max}\) for two positive constants \(f_{\min}\), \(f_{\max}\). Then there exist \(c,C>0\) that depend on \(\mathsf{M}\), \(i\), \(f_{\min}\) and \(f_{\max}\) such that for all integer \(n\geq 1\) and all \(s\geq 0\),_

\[\mathbb{E}[\mu_{n,i}(T_{s})^{2}]\leq C\exp(-cs^{m}).\] (23)

Before proving Proposition G.4, let us show how to use it to conclude the proof of Theorem 4.1. First, it implies that the random variables \(\mu_{n,i}(\Omega)=\mu_{n,i}(T_{0})\) for \(n\geq 1\) have a uniformly bounded second moment, and are therefore uniformly integrable. Second, we have \(\mathbb{E}[\mu_{n,i}(T_{s})]\leq\mathbb{E}[\mu_{n,i}(T_{s})^{2}]^{1/2}\) using Holder's inequality. Hence, (22) implies that for any \(\alpha>0\), we have

\[\mathbb{E}[\mathrm{Pers}_{\alpha}(\mu_{n,i})] \leq\alpha\int_{0}^{\infty}t^{\alpha-1}\mathbb{E}[\mu_{n,i}(T_{2 t})]\mathrm{d}t\] \[\leq\alpha\sqrt{C}\int_{0}^{\infty}t^{\alpha-1}e^{-c2^{m-1}t^{m} }\mathrm{d}t.\]

In particular, \(\sup_{n}\mathbb{E}[\mathrm{Pers}_{\alpha}(\mu_{n,i})]<+\infty\). Likewise,

\[\sup_{n}\mathbb{E}\left[\int_{T_{s}}\mathrm{pers}_{\alpha}(u) \mathrm{d}\mu_{n,i}(u)\right] \leq\alpha\int_{s/2}^{\infty}t^{\alpha-1}\mathbb{E}[\mu_{n,i}(T_{ 2t})]\mathrm{d}t+(s/2)^{\alpha}\mathbb{E}\left[\mu_{n,i}(T_{s})\right]\] \[\leq\alpha\sqrt{C}\int_{0}^{\infty}t^{\alpha-1}e^{-c2^{m-1}t^{m} }\mathrm{d}t+(s/2)^{\alpha}\sqrt{C}\exp(-c/2s^{m})\]

so that \(\lim_{s\to+\infty}\sup_{n}\mathbb{E}[\int_{T_{s}}\mathrm{pers}_{\alpha}(u) \mathrm{d}\mu_{n,i}(u)]=0\). We are therefore in position to apply Lemma G.3, proving the convergence of the \(\alpha\)-total persistence. Together with Lemma G.2 with \(\alpha=p\geq 1\), we also obtain the \(\mathrm{OT}_{p}\)-convergence of \(\mu_{n,i}\). It remains to prove Proposition G.4.

Proof of Proposition G.4.: Write \(\varepsilon_{n}=d_{H}(\mathsf{A}_{n},\mathsf{M})\). Let \(s\geq 0\) and let \(\varepsilon_{0}<\tau(\mathsf{M})/2\) be a small parameter, to be fixed later. Recall that we write \(\#S\) for the cardinality of a multiset \(S\). Notice that \(\mu_{n,i}(T_{s})=0\) if \(sn^{-1/m}>\varepsilon_{n}+\varepsilon_{n}^{2}/\tau(\mathsf{M})\). In particular, we may assume without loss of generality that \(s\leq n^{1/m}\mathrm{diam}(\mathsf{M})(1+\mathrm{diam}(\mathsf{M})/\tau( \mathsf{M}))=n^{1/m}\varepsilon_{\max}\), for otherwise there is nothing to prove. Consider the event \(E=\{\varepsilon_{n}+\varepsilon_{n}^{2}/\tau(\mathsf{M})<\varepsilon_{0}\}\). By definition of Region (1), if \(E\) is satisfied, then all the coordinates of points of the PD \(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n})\) are smaller than \(\varepsilon_{0}\). Notice that the cardinality of \(\mathrm{dgm}_{i}(\mathsf{A}_{n})\) is smaller than the number of \(i\)-dimensional simplices in the Cech complex of \(\mathsf{A}_{n}\), which is itself smaller than \(n^{i+1}\) (as each simplex corresponds uniquely to a choice of \(i+1\) vertices of \(\mathsf{A}_{n}\)). Hence

\[\mathbb{E}[\mu_{n,i}(T_{s})^{2}\mathbf{1}\{E^{c}\}]\leq n^{-2}n^{2i+2}\mathbb{ P}(\varepsilon_{n}+\varepsilon_{n}^{2}/\tau(\mathsf{M})\geq\varepsilon_{0}).\]

We require the following lemma, which bounds the upper tail of the random variable \(\varepsilon_{n}=d_{H}(\mathsf{A}_{n},\mathsf{M})\).

**Lemma G.5**.: _If \(r\leq\tau(\mathsf{M})/2\), then_

\[\mathbb{P}(d_{H}(\mathsf{A}_{n},\mathsf{M})>r)\leq\frac{C_{m}}{f_{\min}r^{m}} \exp(-nc_{m}f_{\min}r^{m})\] (24)

_for two positive constants \(c_{m},C_{m}\) depending only on \(m\). In particular, for any \(q\geq 1\), \(d_{H}(\mathsf{A}_{n},\mathsf{M})=O_{L^{q}}((\ln n/n)^{1/m})\)._

Proof.: The bound \(\mathbb{P}(d_{H}(\mathsf{A}_{n},\mathsf{M})>r)\) is given in [1, Lemma III.23]. Furthermore, [1, Lemma III.23] also states that for any \(q>0\), there exists \(C_{q}\) depending on \(f_{\min}\) and \(m\) such that, with probability at least \(1-n^{-q/m}\), \(d_{H}(\mathsf{A}_{n},\mathsf{M})\leq C_{q}\left(\frac{\ln n}{n}\right)^{1/m}\). In particular, we obtain that

\[\mathbb{E}[d_{H}(\mathsf{A}_{n},\mathsf{M})^{q}]\leq C_{q}^{q}\left(\frac{ \ln n}{n}\right)^{q/m}+\mathrm{diam}(\mathsf{M})^{q}n^{-q/m},\]

proving the second claim of the lemma. 

Note that \(\varepsilon_{n}\leq\mathrm{diam}(\mathsf{M})\), so \(\mathbb{P}(\varepsilon_{n}+\varepsilon_{n}^{2}/\tau(\mathsf{M})\geq \varepsilon_{0})\leq\mathbb{P}(\varepsilon_{n}\geq c_{0}\varepsilon_{0})\), with \(c_{0}=(1+\mathrm{diam}(\mathsf{M})/\tau(\mathsf{M}))^{-1}\). Apply Lemma G.5 with \(r=c_{0}\varepsilon_{0}\) to obtain that

\[\mathbb{E}[\mu_{n,i}(T_{s})^{2}\mathbf{1}\{E^{c}\}]\leq n^{2i}\frac{C_{m}}{f_{ \min}r^{m}}\exp(-nc_{m}f_{\min}r^{m})\leq C_{0}\exp(-c_{1}n)\]

for some positive constants \(c_{1}\), \(C_{0}\). Furthermore, recall that \(s\leq n^{1/m}\varepsilon_{\max}\). Hence,

\[\mathbb{E}[\mu_{n,i}(T_{s})^{2}\mathbf{1}\{E^{c}\}]\leq C_{0}\exp(-c_{1} \varepsilon_{\max}^{-m}s^{m})=C_{0}\exp(-c_{2}s^{m})\]

for some positive constant \(c_{2}\).

It remains to bound \(\mathbb{E}[\mu_{n,i}(T_{s})^{2}\mathbf{1}\{E\}]\). For each \(j=1,\ldots,n\), consider the set \(\Xi_{n,s}^{j}\) of critical points \(z\in\mathrm{Crit}(\mathsf{A}_{n})\) such that \(\sigma_{\mathsf{A}_{n}}(z)\) contains the point \(X_{i}\) and \(sn^{-1/m}\leq d_{\mathsf{A}_{n}}(z)\leq\varepsilon_{n}+\varepsilon_{n}^{2}/ \tau(\mathsf{M})\).

**Lemma G.6**.: _It holds that \(\mu_{n,i}(T_{s})\) is smaller than_

\[\frac{1}{n}\sum_{j=1}^{n}L_{j}^{i+2},\] (25)

_where \(L_{j}\) is the cardinality of the set \(\bigcup_{z\in\Xi_{n,s}^{j}}\sigma_{\mathsf{A}_{n}}(z)\)._

Proof.: Lemma E.1 applied to a realization of \(\mathsf{A}_{n}\) and the interval \([sn^{-1/m},\varepsilon_{n}+\varepsilon_{n}^{2}/\tau(\mathsf{M})]\) yields that the number of points in \(\mathrm{dgm}_{i}(\mathsf{A}_{n})\) with at least one of their coordinates in \([sn^{-1/m},\varepsilon_{n}+\varepsilon_{n}^{2}/\tau(\mathsf{M})]\) is upper bounded by \(\sum_{j=1}^{n}L_{j}^{i+2}\). By definition, this means that \(\mu_{n,i}(T_{s})\leq\frac{1}{n}\sum_{j=1}^{n}L_{j}^{i+2}\), as desired.

One can show that the set \(\Xi_{n,s}^{j}\) is localized, in the sense that it is included in a ball centered at \(X_{j}\), with a radius depending on the sample \(\mathsf{A}_{n}\), that is small with high probability. Hence, the number \(L_{j}\) is controlled by the number of points in \(\mathsf{A}_{n}\) found in a small (random) neighborhood of \(X_{j}\). Let us make this idea rigorous.

For \(r\geq 0\), define the shape

\[\mathcal{C}(r)=\{y=(y_{m},y_{d-m})\in\mathbb{R}^{m}\times\mathbb{R}^{d-m}:\; \|y\|\leq r,\;\|y_{d-m}\|\leq\frac{\|y\|^{2}}{2\tau(\mathsf{M})}\}.\] (26)

We build a partition of \(\mathcal{C}(r)\) in the following way. Consider a finite partition \(\mathcal{W}\) of the unit sphere in \(\mathbb{R}^{m}\times\{0\}^{d-m}\) into sets of diameters smaller than \(\theta=\pi/4\) (for the geodesic distance on the sphere), which we fix for a given dimension \(m\). Let \(\mathcal{W}(r)\) be the partition of \(\mathcal{C}(r)\) consisting of the sets

\[\{y=(y_{m},y_{d-m})\in\mathcal{C}(r):\;y_{m}/\|y_{m}\|\in W\},\]

where \(W\) is an element of the partition \(\mathcal{W}\).

For \(x\in\mathsf{M}\), consider an isometry \(\iota_{x}:\mathbb{R}^{d}\to\mathbb{R}^{d}\) sending \(\mathbb{R}^{m}\times\{0\}^{d-m}\) to \(T_{x}\mathsf{M}\). Let \(\mathcal{C}(x,r)=x+\iota_{x}(\mathcal{C}(r))\). Likewise, we define a partition \(\mathcal{W}(x,r)\) by applying the affine transformation \(W\mapsto x+\iota_{x}(W)\) to each \(W\in\mathcal{W}(r)\).

For \(j=1,\ldots,n\), let \(R_{jn}\) be the smallest radius \(r\leq\varepsilon_{0}\) such that every \(W\in\mathcal{W}(X_{j},r)\) contains a point of \(\mathsf{A}_{n}\) other than \(X_{j}\). By convention, we let \(R_{jn}=\varepsilon_{0}\) if such a radius does not exist. \(R_{jn}\) can be made measurable with a good choice of \(x\mapsto\iota_{x}\); we assume it to be the case henceforth.

**Lemma G.7**.: _Let \(\varepsilon_{0}\leq\tau(\mathsf{M})/\sqrt{2}\). For all \(j=1,\ldots,n\), if \(z\in\mathrm{Crit}(\mathsf{A}_{n})\) is such that \(X_{j}\in\sigma_{\mathsf{A}_{n}}(z)\) and \(d_{\mathsf{A}_{n}}(z)\leq\varepsilon_{0}\), then \(\|X_{j}-z\|\leq c_{0}R_{jn}\) for some positive absolute constant \(c_{0}\)._

Proof.: Recall that for \(x\in\mathsf{M}\), \(\pi_{x}\) is the orthogonal projection on \(T_{x}\mathsf{M}\) while \(\pi_{x}^{\perp}\) is the orthogonal projection on the normal space at \(x\). Let \(j=1,\ldots,n\) and let \(z\in\mathrm{Crit}(\mathsf{A}_{n})\) be such that \(X_{j}\in\sigma_{\mathsf{A}_{n}}(z)\). The direction \(e=\pi_{X_{j}}(z-X_{j})/\|\pi_{X_{j}}(z-X_{j})\|\) belongs to the unit sphere in \(T_{X_{j}}\mathsf{M}\); note that \(\pi_{X_{j}}(z-X_{j})\neq 0\) due to Lemma G.8 below, which applies as \(d_{\mathsf{A}_{n}}(z)\leq\varepsilon_{0}\leq\tau(\mathsf{M})/\sqrt{2}\). Hence, \(\iota_{x}^{-1}(e)\) belongs to an element \(W_{0}\) of the partition \(\mathcal{W}\). Consider the corresponding element \(W\) of the partition \(\mathcal{W}(X_{j},R_{jn})\).

If \(R_{jn}=\varepsilon_{0}\), then the conclusion of the lemma holds (for \(c_{0}=1\)): indeed we have \(\|X_{j}-z\|=d_{\mathsf{A}_{n}}(z)\leq\varepsilon_{0}\leq R_{jn}\). Otherwise, by assumption, there exists a point \(X_{k}\in W\) for some \(k\neq j\). As \(X_{j}\in\sigma_{\mathsf{A}_{n}}(z)\), it holds that \(\|X_{j}-z\|\leq\|X_{k}-z\|\). Hence,

\[\|X_{j}-z\|^{2}\leq\|X_{k}-z\|^{2}=\|X_{j}-z\|^{2}+\|X_{j}-X_{k}\|^{2}+2\langle X _{k}-X_{j},X_{j}-z\rangle\]

and

\[\langle X_{k}-X_{j},z-X_{j}\rangle\leq\frac{\|X_{j}-X_{k}\|^{2}}{2}.\] (27)

We write

\[\langle X_{k}-X_{j},z-X_{j}\rangle=\langle\pi_{X_{j}}(X_{k}-X_{j}),\pi_{X_{j} }(z-X_{j})\rangle+\langle\pi_{X_{j}}^{\perp}(X_{k}-X_{j}),\pi_{X_{j}}^{\perp} (z-X_{j})\rangle\]

By construction, as the diameter of \(W_{0}\) is less than \(\theta\), we have \(\langle\pi_{X_{j}}(X_{k}-X_{j}),\pi_{X_{j}}(z-X_{j})\rangle\geq\cos(\pi/4)\| \pi_{X_{j}}(X_{k}-X_{j})\|\|\pi_{X_{j}}(z-X_{j})\|\). On the other hand, according to [39, Theorem 4.18],

\[\|\pi_{X_{j}}^{\perp}(X_{k}-X_{j})\|\leq\frac{\|X_{k}-X_{j}\|^{2}}{2\tau( \mathsf{M})},\] (28)

which also implies that \(\|\pi_{X_{j}}(X_{k}-X_{j})\|\geq\|X_{j}-X_{k}\|\sqrt{1-\frac{\varepsilon_{0}^{ 2}}{4\tau(\mathsf{M})^{2}}}\). Similarly, Lemma G.8 below states that \(\|\pi_{X_{j}}(z-X_{j})\|\geq\|z-X_{j}\|/\sqrt{2}\) and \(\|\pi_{X_{j}}^{\perp}(z-X_{j})\|\leq\|z-X_{j}\|^{2}/\tau(\mathsf{M})\) (using our assumption that \(d_{\mathsf{A}_{n}}(z)\leq\varepsilon_{0}\leq\tau(\mathsf{M})/\sqrt{2}\)).

Hence we obtain that

\[\cos(\pi/4)\|X_{j}-X_{k}\|\|z-X_{j}\|\frac{\sqrt{1-\frac{\varepsilon_ {0}^{2}}{4\tau(\mathsf{M})^{2}}}}{\sqrt{2}} \leq\cos(\pi/4)\|\pi_{X_{j}}(X_{k}-X_{j})\|\|\pi_{X_{j}}(z-X_{j})\|\] \[\leq\frac{\|X_{k}-X_{j}\|^{2}}{2}+\frac{\|X_{k}-X_{j}\|^{2}\|z-X_ {j}\|^{2}}{2\tau(\mathsf{M})^{2}}\] \[\leq\|X_{k}-X_{j}\|^{2}\left(\frac{1}{2}+\frac{\varepsilon_{0}^{ 2}}{2\tau(\mathsf{M})^{2}}\right).\]

Dividing by \(\|X_{j}-X_{k}\|\) and using that \(\|X_{j}-X_{k}\|\leq R_{jn}\) and that \(\varepsilon_{0}\leq\tau(\mathsf{M})/\sqrt{2}\), we see that \(\|z-X_{j}\|\) is smaller than \(R_{jn}\) up to an absolute multiplicative constant. 

We now prove the lemma used above:

**Lemma G.8**.: _Let \(\mathsf{A}\subset\mathsf{M}\), \(z\in\operatorname{Crit}(\mathsf{A})\) and \(x\in\sigma_{\mathsf{A}}(z)\). Then \(\|\pi_{x}^{\perp}(z-x)\|\leq\|z-x\|^{2}/\tau(\mathsf{M})\). Furthermore, if \(d_{\mathsf{A}}(z)\leq\tau(M)/\sqrt{2}\), then \(\|\pi_{x}(z-x)\|\geq\|z-x\|/\sqrt{2}\)._

Proof.: The point \(z\) can be written as a convex combination \(z=\sum_{k}\lambda_{k}y_{k}\) where the points \(y_{k}\) are in \(\mathsf{A}\subset\mathsf{M}\). Then, using [39, Theorem 4.18],

\[\|\pi_{x}^{\perp}(z-x)\| \leq\sum_{k}\lambda_{k}\|\pi_{x}^{\perp}(y_{k}-x)\|\leq\sum_{k} \lambda_{k}\frac{\|y_{k}-x\|^{2}}{2\tau(\mathsf{M})}\] \[=\sum_{k}\lambda_{k}\frac{\|y_{k}-z\|^{2}+\|z-x\|^{2}+2\langle y_ {k}-z,z-x\rangle}{2\tau(\mathsf{M})}=\frac{\|z-x\|^{2}}{\tau(\mathsf{M})},\]

as \(\|y_{k}-z\|^{2}=\|x-z\|^{2}\) and \(\sum_{k}\lambda_{k}(y_{k}-z)=0\). The second inequality \(\|\pi_{x}(z-x)\|\geq\|z-x\|/\sqrt{2}\) from the statement follows from the first one through a direct computation. 

Let us now show that the random variable \(R_{jn}\) has controlled tails.

**Lemma G.9**.: _For all \(x\in\mathsf{M}\), \(r\geq 0\), \(B(x,r)\cap\mathsf{M}\subset\mathcal{C}(x,r)\)._

Proof.: Let \(y\in\mathsf{M}\) be such that \(\|\pi_{x}(y-x)\|\leq r\). Then, according to [39, Theorem 4.18], \(\|\pi_{x}^{\perp}(y-x)\|\leq\frac{\|y-x\|^{2}}{2\tau(\mathsf{M})}\). In particular, \(B(x,r)\cap\mathsf{M}\subset\mathcal{C}(x,r)\). 

**Lemma G.10**.: _For \(0<t\leq\tau(\mathsf{M})/4\) and \(j=1,\ldots,n\), we have \(\mathbb{P}(R_{jn}>t)\leq C_{m}e^{-c_{m}f_{\min}(n-1)t^{m}}\) for some positive constants \(c_{m}\), \(C_{m}\)._

Proof.: If \(R_{jn}\) is larger than \(t\), then there exists at least one set \(W\in\mathcal{W}(X_{j},t)\) such that its intersection with \(\mathsf{A}_{n}\) contains only \(X_{j}\). Hence,

\[\mathbb{P}(R_{jn}>t|X_{j})\leq\sum_{W\in\mathcal{W}(X_{j},t)}\mathbb{P}( \mathsf{A}_{n}\cap W=X_{j}|X_{j})=\sum_{W\in\mathcal{W}(X_{j},t)}(1-P(W))^{n-1}.\]

Let \(\pi_{0}\) be the orthogonal projection from \(\mathbb{R}^{d}\) to \(\mathbb{R}^{m}\times\{0\}^{d-m}\). The image of a set \(W\in\mathcal{W}(X_{j},t)\) by the projection \(y\mapsto\pi_{X_{j}}(y-X_{j})\) is equal to \(\iota_{X_{j}}(\pi_{0}(W_{0}))\subset T_{X_{j}}\mathsf{M}\) for some \(W_{0}\in\mathcal{W}(t)\). For \(t\leq\tau(\mathsf{M})/4\), the orthogonal projection \(y\in B(X_{j},t)\cap\mathsf{M}\mapsto\pi_{X_{j}}(y-X_{j})\in T_{X_{j}}\mathsf{M}\) is a diffeomorphism on its image, with Jacobian lower bounded by a constant \(c_{m}\) that depends only on \(m\), see e.g. [31, Lemma 2.2]. According to Lemma G.9, the preimage of \(\iota_{X_{j}}(\pi_{0}(W_{0}))\subset T_{X_{j}}\mathsf{M}\) by this diffeomorphism is equal to \(W\cap M\). Hence, by a change of variable,

\[P(W)=P(W\cap M)\geq f_{\min}c_{m}\mathrm{Vol}_{m}(W_{0})\geq f_{\min}c_{m}^{ \prime}t^{m}\]

for some \(c_{m}^{\prime}>0\). Hence,

\[\mathbb{P}(R_{jn}>t|X_{j})\leq\#\mathcal{W}e^{-f_{\min}c_{m}^{\prime}(n-1)t^{ m}}.\]

We conclude by taking the expectation.

Let us now control the number of points found in a ball \(B(X_{j},\kappa R_{jn})\) for some \(\kappa\geq 0\). Let \(\rho_{0}>0\) be small enough such that \(\int_{B(x,\rho_{0})\cap\mathsf{M}}f<1/2\) for any \(x\in\mathsf{M}\).

**Lemma G.11**.: _Let \(l\geq 0,\kappa>0\) be such that \(\kappa\varepsilon_{0}\leq\min(\rho_{0},\tau(\mathsf{M})/4)\). For \(j=1,\ldots,n\), let \(K_{jn}(\kappa)\) be the number of elements of \(\mathsf{A}_{n}\) found in \(B(X_{j},\kappa R_{jn})\). Then, \(\mathbb{E}[K_{jn}(\kappa)^{l}]\leq C_{m,l}(1+\left(\frac{f_{\max}}{f_{\min}} \right)^{l}\kappa^{lm})\) for some constant \(C_{m,l}\) which depends on \(m\) and \(l\)._

Proof.: Let us write \(\{W_{1},\ldots,W_{K}\}=\mathcal{W}(X_{j},\kappa R_{jn})\). Without loss of generality, we can assume that \(n\geq K+1\), as otherwise the bound is trivial. As in [34, Lemma 5], we remark that there is at least one sample point in every \(W_{i}\), and that there is (almost surely) one single element \(W_{i^{*}}\) of the partition with exactly one sample point on its boundary. Let \(N_{i}\) be the cardinality of \((W_{i}\cap\mathsf{A}_{n})\backslash\{X_{j}\}\), and \(N_{-1}\) be the cardinality of \(\mathsf{A}_{n}\backslash B(X_{j},\kappa R_{jn})\). Define

\[\tilde{\alpha}_{i}:=\int_{W_{i}}f\]

and \(\alpha_{i}:=\frac{\tilde{\alpha}_{i}}{1-\alpha_{i^{*}}^{2}}\) for all \(i\neq i^{*}\), as well as \(\alpha_{-1}=\frac{1-\sum_{i=1}^{K}\tilde{\alpha}_{i}}{1-\tilde{\alpha}_{i^{*}}}\). Note that as \(\kappa R_{jn}\leq\rho_{0}\), we have \(\tilde{\alpha_{i}}<1/2\) for all \(i=1,\ldots,K\). As \(\kappa R_{jn}\leq\kappa\varepsilon_{0}\leq\tau(\mathsf{M})/4\), we may use once again that the orthogonal projection \(y\in B(X_{j},\kappa R_{jn})\cap\mathsf{M}\mapsto\pi_{X_{j}}(y-X_{j})\in T_{X_ {j}}\mathsf{M}\) is a diffeomorphism on its image, with Jacobian upper and lower bounded by constants depending only on \(m\) (see [31, Lemma 2.2]) to also obtain that

\[cf_{\min}(\kappa R_{jn})^{m}\leq\tilde{\alpha_{i}}\leq Cf_{\max}(\kappa R_{jn })^{m}\]

for all \(i=1,\ldots,K\) and some constants \(c=c(m),C=C(m)\). Hence there exists \(C^{\prime}=C^{\prime}(m)>0\) such that

\[cf_{\min}(\kappa R_{jn})^{m}\leq\alpha_{i}\leq C^{\prime}f_{\max}(\kappa R_{jn })^{m}\]

for all \(i=1,\ldots,K\). Consider a multinomial random variable \(L=(L_{1},\ldots,\widehat{L_{i^{*}}},\ldots,L_{K},L_{-1})\) of parameters \(n-2\) and \((\alpha_{1},\ldots,\widehat{\alpha_{i^{*}}},\ldots,\alpha_{K},\alpha_{-1})\), and let \(E\) denote the event

\[\{L_{i}\geq 1\ \forall i\in\{1,\ldots,K\}\backslash\{i^{*}\}\}.\]

Then conditionally on \(X_{j}\), \(R_{jn}\) and \(i^{*}\), the variable \(N=(N_{1},\ldots,\widehat{N_{i^{*}}},\ldots,N_{K},N_{-1})\) follows the same distribution as \(L\mid E\). Thus, conditionally on \(X_{j}\), \(R_{jn}\) and \(W_{i^{*}}\), the variable \(K_{jn}(\kappa)=1+\sum_{i=1}^{K}N_{i}=2+\sum_{i=1,i\neq i^{*}}^{K}N_{i}\) (where the initial \(1\) comes from \(X_{j}\)) has the same distribution as

\[2+\sum_{i=1,i\neq i^{*}}^{K}L_{i}|\ E.\]

Note that as \(\kappa R_{jn}\leq\rho_{0}\), we have \(\alpha_{-1}\geq 1/2\).

As a result, Lemma G.12 below yields that

\[\mathbb{E}[K_{jn}(\kappa)^{l}|X_{j},R_{jn},W_{i^{*}}] =\mathbb{E}[(2+\sum_{i=1,i\neq i^{*}}^{K}L_{i})^{l}\mid E]\leq 2^{l}(2^ {l}+\mathbb{E}[(\sum_{i=1,i\neq i^{*}}^{K}L_{i})^{l}\mid E])\] \[\leq 2^{l}(2^{l}+C_{K,l}(1+(n-2)\sum_{i=1,i\neq i^{*}}^{K}\alpha_{ i})^{l})\] \[\leq C_{K,l}^{\prime}(1+(n\sum_{i=1,i\neq i^{*}}^{K}\alpha_{i})^{l })\leq C_{K,l}^{\prime}(1+(nKC^{\prime}f_{\max}(\kappa R_{jn})^{m})^{l})\] \[\leq C_{m,l}(1+\kappa^{ml}f_{\max}^{l}n^{l}R_{jn}^{ml})\]

where \(C_{K,l},C_{K,l}^{\prime}\) and \(C_{m,l}\) are constants whose dependencies are indicated by their indices (remember that \(K=\#\mathcal{W}\) depends only on \(m\)). We can now conclude by considering

\[\mathbb{E}[K_{jn}(\kappa)^{l}]=\mathbb{E}_{X_{j},R_{jn},W_{i^{*}}}[\mathbb{E} [K_{jn}(\kappa)^{l}|X_{j},R_{jn},W_{i^{*}}]]\leq\mathbb{E}_{R_{jn}}[C_{m,l}(1+ \kappa^{ml}f_{\max}^{l}n^{l}R_{jn}^{ml})]\]The quantity \(n^{l}\mathbb{E}[R_{jn}^{ml}]\) is bounded by a constant, which is proved by integrating the tail bound found in Lemma G.10. Indeed, Lemma G.10 implies that the random variable \(nR_{jn}^{m}\) is subexponential with a subexponential norm \(m\) independent of \(n\), of order \(O(1/f_{\min})\); the moment of order \(l\) of such a random variable is bounded by \(C_{l}m^{l}\), see [74, Section 2.7]. 

Let us now prove the technical lemma used above.

**Lemma G.12**.: _Let \(K\geq 1\) and \(L=(L_{1},\ldots,L_{K},L_{K+1})\) be a random multinomial variable of parameters \(n\) and \(\alpha_{1},\ldots,\alpha_{K},\alpha_{K+1}\). Then there exists \(C=C(K,l)\) such that_

\[\mathbb{E}[(\sum_{i=1}^{K}L_{i})^{l}|L_{i}\geq 1\;\forall i=1,\ldots,K]\leq C _{l}(1+(n\sum_{i=1}^{K}\alpha_{i})^{l}).\]

Proof.: Let \(X_{1},\ldots,X_{n}\) be i.i.d. categorical variables of parameters \(\alpha_{1},\ldots,\alpha_{K},\alpha_{K+1}\). Define \(L_{k}(p)=\sum_{r\leq p}\mathbbm{1}_{X_{r}=k}\); then \((L_{1}(n),\ldots,L_{K}(n),L_{K+1}(n))\) has the same distribution as \((L_{1},\ldots,L_{K},L_{K+1})\), and we identify the two in our notations. For a fixed \(n\), and for any injective function \(\iota:\{1,\ldots,k\}\to\{1,\ldots,n\}\), consider the event

\[E_{\iota}:=\{L_{1}(\iota(1))=1,\ldots,L_{1}(\iota(K))=1\},\]

i.e. \(\iota(i)\) is the first appearance of \(i\) among the variables \(X_{1},\ldots,X_{n}\). Note that \(E:=\{L_{1},\ldots,L_{K}\geq 1\}=\bigsqcup_{\iota}E_{\iota}\) where the sum is taken over all such injective functions. Then

\[\mathbb{E}[(\sum_{i=1}^{K}L_{i})^{l}|E]=\sum_{\iota}\mathbb{P}(E_{\iota}|E) \mathbb{E}[(\sum_{i=1}^{K}L_{i})^{l}|E_{\iota}].\]

Fix a function \(\iota\), and assume without loss of generality that \(\iota(1)<\iota(2)<\ldots<\iota(K)\). Conditioned by \(A_{\iota}\), the variable \(Y_{i}:=\sum_{r=\iota(i+1)}^{\iota(i+1)-1}\mathbbm{1}_{X_{r}\neq K+1}\) is a binomial variable of parameters \(\iota(i+1)-\iota(i)-2\leq n\) and \(\frac{\sum_{i=1}^{i}\alpha_{i}}{\alpha_{1}+\ldots+\alpha_{i}+\alpha_{K+1}} \leq\sum_{i=1}^{K}\alpha_{i}\). Hence \(\mathbb{E}[Y_{i}^{l}|E_{\iota}]\leq C_{1}(l)(n\sum_{i=1}^{K}\alpha_{i})^{l}\) using classical bounds on the \(l\)-th moment of a binomial variable, and we see that

\[\mathbb{E}[(\sum_{i=1}^{K}L_{i})^{l}|E_{\iota}] =\mathbb{E}[(\sum_{r=1}^{n}\mathbbm{1}_{X_{r}\neq K+1})^{l}|E_{ \iota}]=\mathbb{E}[(K+\sum_{i=0}^{K}\sum_{r=\iota(i)+1}^{\iota(i+1)-1} \mathbbm{1}_{X_{r}\neq K+1})^{l}|E_{\iota}]\] \[\leq C_{2}(K,l)(K^{l}+\sum_{i=0}^{K}\mathbb{E}[Y_{i}^{l}|E_{\iota} ])\leq C_{3}(K,l)(1+(n\sum_{i=1}^{K}\alpha_{i})^{l})\]

where we write \(\iota(0)=0\) and \(\iota(K+1)=n\) to simplify notations.

Let us wrap things up. Recall Lemma G.6: it holds that

\[\mu_{n,i}(T_{s})\leq\frac{1}{n}\sum_{j=1}^{n}L_{j}^{i+2},\] (29)

where \(L_{j}\) is the cardinality of the set \(\bigcup_{z\in\Xi_{n,s}^{j}}\sigma_{\mathsf{A}_{n}}(z)\). But according to Lemma G.7, if \(z\in\Xi_{n,s}^{j}\), then \(\|X_{j}-z\|\leq c_{0}R_{jn}\). In particular, \(d_{\mathsf{A}_{n}}(z)\leq c_{0}R_{jn}\), and any point \(y\in\sigma_{\mathsf{A}_{n}}(z)\) is at distance less than \(2c_{0}R_{jn}\) from \(X_{j}\). Hence, \(L_{j}\) is smaller than \(K_{jn}(\kappa)\) for \(\kappa=2c_{0}\). Choose \(\varepsilon_{0}\) so that \(\kappa\varepsilon_{0}\leq\kappa\varepsilon_{0}\leq\min(\rho_{0},\tau(\mathsf{ M})/4)\). We are in position to apply Lemma G.11. We further remark that Lemma G.7 implies that \(\Xi_{n,s}^{j}\) is empty if \(c_{0}R_{jn}<sn^{-1/m}\).

Hence, by Jensen's inequality,

\[\mathbb{E}[\mu_{n,i}(T_{s})^{2}\mathbf{1}\{E\}] \leq\mathbb{E}\left[\left(\frac{1}{n}\sum_{j=1}^{n}\mathbf{1}\{2c_ {0}R_{jn}\geq sn^{-1/m}\}K_{jn}(2c_{0})^{i+2}\right)^{2}\right]\] \[\leq\mathbb{E}\left[\mathbf{1}\{2c_{0}R_{1n}\geq sn^{-1/m}\}K_{1n }(2c_{0})^{2i+4}\right]\] \[\leq\sqrt{\mathbb{P}(2c_{0}R_{jn}\geq sn^{-1/m})\mathbb{E}[K_{1n }(2c_{0})^{4i+8}]}\] \[\leq C_{m,i}\exp(-c_{m}f_{\min}s^{m})\]

for some constants \(c_{m},C_{m,i}>0\), where we apply Lemma G.10 and Lemma G.11 at the last line. 

This completes the proof of Theorem 4.1. 

We now prove Proposition 4.2:

**Proposition 4.2**.: _Let \(\mathsf{M}\) be a generic \(m\)-dimensional submanifold. Assume that \(P\) has a density \(f\) on \(\mathsf{M}\) bounded away from \(0\) and \(\infty\). Let \(i\geq 0\) be an integer. There exists an optimal matching \(\gamma_{n}:\mathrm{dgm}_{i}(\mathsf{A}_{n})\cup\partial\Omega\to\mathrm{dgm}_{ i}(\mathsf{M})\cup\partial\Omega\) for the bottleneck distance between \(\mathrm{dgm}_{i}(\mathsf{A}_{n})\) and \(\mathrm{dgm}_{i}(\mathsf{M})\) such that for any \(q\geq 1\):_

* _Region (2): It holds that_ \(\max_{u\in\mathrm{dgm}_{i}^{(2)}(\mathsf{A}_{n})}|u_{2}-\gamma_{n}(u)_{2}|=O_ {L^{q}}(n^{-2/m})\)_._
* _Region (3): It holds that_ \(\max_{u\in\mathrm{dgm}_{i}^{(3)}(\mathsf{A}_{n})}\|u-\gamma_{n}(u)\|_{\infty} =O_{L^{q}}(n^{-2/m})\) _and_ \(\#(\mathrm{dgm}_{i}^{(3)}(\mathsf{A}_{n}))=O_{L^{q}}(1)\)_._

Proof.: Let \(\varepsilon_{n}=d_{H}(\mathsf{A}_{n},\mathsf{M})\). Let \(\Pi_{\mathsf{M}}:=\{x\in\sigma_{\mathsf{M}}(z):\ z\in\mathrm{Crit}(\mathsf{M})\}\) be the (finite) set of projections of critical points \(z\in\mathrm{Crit}(\mathsf{M})\). The proof of Theorem 3.3 relied on the use of Theorem 1.6 in [6]. This theorem states roughly that both critical points \(z\in\mathrm{Crit}(\mathsf{A}_{n})\) far from \(\mathsf{M}\) and their projections \(x\in\sigma_{\mathsf{A}_{n}}(z)\) are stable with respect to the Hausdorff distance, meaning that every such point \(z\) is at distance \(O(\varepsilon_{n})\) from a critical point \(z^{\prime}\in\mathrm{Crit}(\mathsf{M})\), with \(x\) being at distance \(O(\varepsilon_{n})\) from a point \(x^{\prime}\in\Pi_{\mathsf{M}}\). Thus, the number of critical points of \(\mathsf{A}_{n}\) located close to a given \(z^{\prime}\in\mathrm{Crit}(\mathsf{M})\) is crudely upper bounded by the number of subsets which can be formed by selecting elements in neighborhoods of size \(O(\varepsilon_{n})\) around \(x^{\prime}\in\sigma_{\mathsf{M}}(z^{\prime})\). We used the same idea to bound the cardinality of \(\mathrm{dgm}_{i}^{(3)}(\mathsf{A})\) in Theorem 3.3.

In a random setting, the distance \(\varepsilon_{n}\) is of order \((\ln n/n)^{1/m}\), as suggested by Lemma G.5, while the number of points found in a ball of radius \(r\) is typically of order \(nr^{m}\), yielding a logarithmic number of elements in a neighborhood of size \(O(\varepsilon_{n})\) around a given point \(x\in\mathsf{M}\). Hence, our earlier strategy is not tight enough to bound in expectation the cardinality of \(\mathrm{dgm}_{i}^{(3)}(\mathsf{A})\) by a constant.

We improve upon this strategy with the following intuition: the maximal distance between a point \(x\) of \(\mathsf{M}\) and the point cloud \(\mathsf{A}_{n}\) does not really matter in [6, Theorem 1.6], but only the density of the point cloud \(\mathsf{A}_{n}\)_around_ the (finitely many) projections \(x\in\Pi_{\mathsf{M}}\). Although \(\varepsilon_{n}\) is of order \((\ln n/n)^{1/m}\), the distance between a _fixed_ point \(x\in\mathsf{M}\) and \(\mathsf{A}_{n}\) is known to be of order \(n^{-1/m}\) (see (21)). This remark explains how we can intuitively replace neighborhoods of radii \((\ln n/n)^{1/m}\) by radii of size \(n^{-1/m}\) in the previous arguments.

We now make these ideas rigorous. Let \(\mathrm{Crit}_{>}(\mathsf{A}_{n})=\{z\in\mathrm{Crit}(\mathsf{A}_{n}):d_{ \mathsf{A}_{n}}(z)\geq\tau(\mathsf{M})/2\}\) denote the set of critical points of \(\mathsf{A}_{n}\) "far" from \(\mathsf{M}\) and let \(\Pi_{\mathsf{A}_{n}}:=\{x\in\sigma_{\mathsf{A}_{n}}(z):\ z\in\mathrm{Crit}_{>}( \mathsf{A}_{n})\}\) be the corresponding set of projections. We let \(\varepsilon_{0}\) be a small constant to be fixed later. Theorem 1.6 from [6] states that, thanks to the genericity of \(\mathsf{M}\), there exist \(K_{1},K_{2}>0\) such that for \(\varepsilon_{0}\) small enough, if \(\varepsilon_{n}<\varepsilon_{0}\):

* there exists a map \(\phi:\mathrm{Crit}_{>}(\mathsf{A}_{n})\to\mathrm{Crit}(\mathsf{M})\) such that \(d(z,\phi(z))\leq K_{1}\varepsilon_{n}\) for all \(z\in\mathrm{Crit}_{>}(\mathsf{A}_{n})\), and
* there exists a map \(\psi:\Pi_{\mathsf{A}_{n}}\to\Pi_{\mathsf{M}}\) such that \(d(x,\psi(x))\leq K_{2}\varepsilon_{n}\) for all \(x\in\Pi_{\mathsf{A}_{n}}\).

Furthermore, the map \(\psi\) is such that for each \(z\in\mathrm{Crit}_{>}(\mathsf{A}_{n})\) and each \(x^{\prime}\in\sigma_{\mathsf{M}}(\phi(z))\), there exists \(x\in\sigma_{\mathsf{A}_{n}}(z)\) such that \(\psi(x)=x^{\prime}\) (if \(\varepsilon_{0}\) is chosen small enough). Indeed, due to the genericity of \(\mathsf{M}\), each critical point \(z^{\prime}\in\mathrm{Crit}(\mathsf{M})\) belongs to the relative interior of \(\sigma_{\mathsf{M}}(z^{\prime})\) (as stated in Appendix C). In particular, it cannot belong to the convex hull of any strict subset of \(\sigma_{\mathsf{M}}(z^{\prime})\). By continuity of the convex hull for the Hausdorff distance, as soon as \(z\in\mathrm{Crit}_{>}(\mathsf{A}_{n})\) is close enough to \(\phi(z)\) and its projections \(x\in\sigma_{\mathsf{A}_{n}}(z)\) are close enough to \(\sigma_{\mathsf{M}}(\phi(z))\) (i.e. as soon as \(\varepsilon_{n}\) is small enough), the point \(z\) cannot belong to the convex hull of any subset \(S\subset\sigma_{\mathsf{A}_{n}}(z)\) that does not contain for each \(x^{\prime}\in\sigma_{\mathsf{M}}(\phi(z))\) at least one point \(x\) such that \(\psi(x)=x^{\prime}\). As \(z\) must belong to the convex hull of \(\sigma_{\mathsf{A}_{n}}(z)\), we conclude that each \(x^{\prime}\in\sigma_{\mathsf{M}}(\phi(z))\) has at least one preimage by \(\psi\) in \(\sigma_{\mathsf{A}_{n}}(z)\). As \(\mathrm{Crit}(\mathsf{M})\) is finite, taking the minimum distance such that this property holds for \(z^{\prime}\) over all \(z^{\prime}\in\mathrm{Crit}(\mathsf{M})\) proves the claim.

We introduce the random function defined as

\[\forall r\geq 0,\ E(r):=\min(\sup\{d_{\mathsf{A}_{n}}(y):\ y\in\mathsf{M} \cap\Pi_{\mathsf{M}}^{r}\},\varepsilon_{0})=:\min(F(r),\varepsilon_{0}),\] (30)

where \(\Pi_{\mathsf{M}}^{r}\) is as usual the \(r\)-offset of \(\Pi_{\mathsf{M}}\). This random variable measures the density of the point cloud \(\mathsf{A}_{n}\) in neighborhoods of size \(r\) of points \(x^{\prime}\in\Pi_{\mathsf{M}}\).

Let

\[\rho_{n}:=\sup\{d_{\Pi_{\mathsf{M}}}(x):x\in\Pi_{\mathsf{A}_{n}}\}\] (31)

give (when \(\varepsilon_{n}<\varepsilon_{0}\) for \(\varepsilon_{0}\) small enough) the largest distance between a projection \(x\in\Pi_{\mathsf{A}_{n}}\) and the corresponding projection \(\psi(x)\in\Pi_{\mathsf{M}}\). We also define

\[\eta_{n}:=\sup\{d_{\Pi_{\mathsf{M}}}(x):\ x=\pi_{\mathsf{M}}(z),\ z\in \mathrm{Crit}_{>}(\mathsf{A}_{n})\}.\] (32)

We require the following controls on the random variables \(\rho_{n}\) and \(\eta_{n}\).

**Lemma G.13**.: _There exist positive constants \(\varepsilon_{0}=\varepsilon_{0}(\mathsf{M})\), \(K_{3}=K_{3}(\mathsf{M})\), \(K_{4}=K_{4}(\mathsf{M})\) and \(K_{5}=K_{5}(\mathsf{M})\) such that if \(\varepsilon_{n}<\varepsilon_{0}\), it holds that for any \(z\in\mathrm{Crit}_{>}(\mathsf{A}_{n})\)_

\[|d_{\mathsf{A}_{n}}(z)-d_{\mathsf{M}}(\phi(z))|\leq K_{3}E(\eta_{ n})^{2},\] (33) \[\eta_{n}\leq K_{4}E(\eta_{n}),\] (34) \[\rho_{n}\leq K_{5}E(\eta_{n}).\] (35)

Proof.: The lemma follows from a careful read of the proof of Theorem 1.6 in [6]. First, remark that in the proof of Lemma 5.1 in [6] (applied with \(r=\tau(\mathsf{M})/2\), \(R=\mathrm{diam}(\mathsf{M})\)), the Hausdorff distance \(\varepsilon=d_{H}(\mathsf{A}_{n},\mathsf{M})\) can be replaced by \(E(\eta_{n})\). Hence, if \(z\in\mathrm{Crit}_{>}(\mathsf{A}_{n})\), there exists a \(\mu\)-critical point \(z^{\prime}\) of \(\mathsf{M}\) at distance less than \(E(\eta_{n})\), with \(\mu\leq L_{1}(\mathsf{M})E(\eta_{n})\). By genericity, for a choice of \(\varepsilon_{0}\) small enough, this point \(z^{\prime}\) is at distance \(L_{2}(\mathsf{M})\mu\) from a critical point \(z_{0}\in\mathrm{Crit}(\mathsf{M})\). For \(\varepsilon_{0}\) small enough, this point \(z_{0}\) is necessarily equal to \(\phi(z)\), with \(\|z-\phi(z)\|\leq(1+L_{2}L_{1})E(\eta_{n})\). Due to the Lipschitz property of the projection onto \(\mathsf{M}\) around \(z_{0}\) (see the arguments found at the bottom of p. 19 in [6]), any point \(x\in\pi_{\mathsf{M}}(z)\) is such that \(\|x-x^{\prime}\|\leq L_{3}(\mathsf{M})\|z-\phi(z)\|\) for some \(x^{\prime}\in\sigma_{\mathsf{M}}(\phi(z))\). By taking the supremum over all such points \(x\), we obtain that

\[\eta_{n}\leq L_{3}(1+L_{2}L_{1})E(\eta_{n}),\]

proving (34).

One can also check that \(\varepsilon_{n}\) can be replaced by \(E(\eta_{n})\) in the end of the proof of Theorem 1.6 in [6], so that (35) holds.

Let us now prove (33). Let \(z\in\mathrm{Crit}_{>}(\mathsf{A}_{n})\). Consider \(x_{\mathsf{A}_{n}}\in\sigma_{\mathsf{A}_{n}}(z)\); we know that \(\|\psi(x_{\mathsf{A}_{n}})-x_{\mathsf{A}_{n}}\|\leq K_{5}E(\eta_{n})\) using (33). As \(\phi(z)-\psi(x_{\mathsf{A}_{n}})\) is orthogonal to \(T_{\psi(x_{\mathsf{A}_{n}})}\mathsf{M}\), [39] states that \(\|\pi_{\psi(x_{\mathsf{A}_{n}})}^{\perp}(x_{\mathsf{A}_{n}}-\psi(x_{\mathsf{A}_ {n}}))\|\leq\frac{\|x_{\mathsf{A}_{n}}-\psi(x_{\mathsf{A}_{n}})\|^{2}}{2\tau( \mathsf{M})}\leq\frac{K_{5}^{2}E(\eta_{n})^{2}}{2\tau(\mathsf{M})}\), hence

\[\|\phi(z)-x_{\mathsf{A}_{n}}\|^{2} =\|\phi(z)-\psi(x_{\mathsf{A}_{n}})\|^{2}+2\langle\phi(z)-\psi(x_{ \mathsf{A}_{n}}),\psi(x_{\mathsf{A}_{n}})-x_{\mathsf{A}_{n}}\rangle+\|\psi(x_{ \mathsf{A}_{n}})-x_{\mathsf{A}_{n}}\|^{2}\] \[\leq d_{\mathsf{M}}(\phi(z))^{2}+\frac{K_{5}^{2}E(\eta_{n})^{2}}{ \tau(\mathsf{M})}d_{\mathsf{M}}(\phi(z))+K_{5}^{2}E(\eta_{n})^{2}\leq d_{ \mathsf{M}}(\phi(z))^{2}+E(\eta_{n})^{2}L_{4},\]

where \(L_{4}=K_{5}^{2}\left(\frac{R(\mathsf{M})}{\tau(\mathsf{M})}+1\right)\), \(R(\mathsf{M})\) is the radius of the smallest closed ball that contains \(\mathsf{M}\), and \(d_{\mathsf{M}}(\phi(z))\leq R(\mathsf{M})\) because a critical point must belong to the convex hull of its projections. As 

[MISSING_PAGE_FAIL:35]

Assume for a moment that Lemma G.15 holds. Then, we write (for a choice of \(\varepsilon_{0}\) small enough)

\[\max_{u\in\mathrm{dg}_{\mathrm{mi}}^{(2)}(\mathsf{A}_{n})}|u_{2}- \gamma_{n}(u)_{2}| \leq K_{3}E(\eta_{n})^{2}\mathbf{1}\{\varepsilon_{n}\leq\varepsilon_{0} \}+R(\mathsf{M})\mathbf{1}\{\varepsilon_{n}>\varepsilon_{0}\}\] \[\leq K_{3}E(\eta_{n})^{2}\mathbf{1}\{\varepsilon_{n}\leq \varepsilon_{0}\}+R(\mathsf{M})\mathbf{1}\{\varepsilon_{n}>\varepsilon_{0}\}.\] (38)

where we recall that \(R(\mathsf{M})\) is the radius of the smallest enclosing ball of \(\mathsf{M}\). Because of Lemma G.5, the random variable \(\mathbf{1}\{\varepsilon_{n}>\varepsilon_{0}\}\) is a \(O_{L^{q}}(n^{-2/m})\) for all \(q\geq 1\). But then, because of Lemma G.15, we obtain that the right-hand side in (38) is a \(O_{L^{q}}(n^{-2/m})\) for all \(q\geq 1\). Likewise, we obtain that \(\max_{u\in\mathrm{dg}_{\mathrm{mi}}^{(3)}(\mathsf{A}_{n})}\|u-\gamma_{n}(u) \|_{\infty}=O_{L^{q}}(n^{-2/m})\) for all \(q\geq 1\). At last, we have

\[\#(\mathrm{dg}_{i}^{(3)}(\mathsf{A}_{n}))\leq N(\rho_{n})^{i+2}\mathbf{1}\{ \varepsilon_{n}\leq\varepsilon_{0}\}+n^{i+2}\mathbf{1}\{\varepsilon_{n}> \varepsilon_{0}\}.\]

The first term is a \(O_{L^{q}}(1)\) for all \(q\geq 1\) because of Lemma G.15, while the second one is a \(O_{L^{q}}(1)\) for all \(q\geq 1\) because of Lemma G.5. This concludes the proof of Proposition 4.2. Let us now prove Lemma G.15. 

Proof of Lemma g.15.: Let \(t>0\). The key observation to obtain Lemma G.15 is that (34) implies that if \(\eta_{n}>t\), then there exists \(r>t\) with \(r\leq K_{4}E(r)\).

**Lemma G.16**.: _For all \(\lambda>0\), there exist positive constants \(C_{\lambda}\), \(c_{\lambda}\) (depending on \(\lambda\), \(\mathsf{M}\) and \(f_{\min}\)) such that for all \(r>0\), \(\mathbb{P}(r\leq\lambda E(r))\leq C_{\lambda}\exp(-c_{\lambda}nr^{m})\)._

Proof.: Remark that if \(r\leq\lambda E(r)\), then \(r\leq\lambda F(r)\). The set \(\mathsf{M}\cap\Pi_{\mathsf{M}}^{r}\) is the union of a finite number of balls of radius \(r\). Hence, it can be covered by \(C_{\lambda}=C_{\lambda}(\mathsf{M})\) open balls of radius \(r/(2\lambda)\), with centers \(x_{1},\ldots,x_{C_{\lambda}}\in\mathsf{M}\). Note that if all these balls intersect \(\mathsf{A}_{n}\), then for all \(y\in\mathsf{M}\cap\Pi_{\mathsf{M}}^{r}\), \(d_{\mathsf{A}_{n}}(y)<r/\lambda\). Hence, if \(\lambda F(r)\geq r\), then the intersection of one of these balls with \(\mathsf{A}_{n}\) is empty. Hence, according to Lemma G.1,

\[\mathbb{P}(r\leq\lambda F(r))\leq\sum_{k=1}^{C_{\lambda}}\mathbb{P}(d_{ \mathsf{A}_{n}}(x_{k})\geq r/(2\lambda))\leq C_{\lambda}\exp(-C(\mathsf{M})f_ {\min}n(r/\lambda)^{m}).\qed\]

Remark that the fonction \(E\) is nondecreasing and \(1\)-Lipschitz continuous: we have for \(r<s\), \(E(r)\leq E(s)\leq E(r)+(r-s)\). Fix \(t>0\) and consider the sequence \(t_{k}=a^{k}t\) for some \(a>1\) to fix. Assume that \(\eta_{n}>t\) and that \(\varepsilon_{n}\leq\varepsilon_{0}\). Then \(\eta_{n}\) is between two values \(t_{k}<t_{k+1}\). But then, according to Lemma G.14,

\[\frac{E(t_{k})}{t_{k}}\geq\frac{E(\eta_{n})-(\eta_{n}-t_{k})}{t_{ k}}\geq\frac{1}{a}\frac{E(\eta_{n})}{\eta_{n}}\frac{t_{k+1}}{t_{k}}-(a-1) \geq\frac{1}{K_{4}}-(a-1)\] \[\frac{E(t_{k+1})}{t_{k+1}}\geq\frac{1}{a}\frac{E(\eta_{n})}{t_{k} }\geq\frac{1}{a}\frac{E(\eta_{n})}{\eta_{n}}\geq\frac{1}{K_{4}a}.\]

Choose \(a>1\) such that \(\frac{1}{K_{4}}-(a-1)>0\), and let

\[\lambda=\min\Big{(}\frac{1}{K_{4}}-(a-1),\frac{1}{K_{4}a}\Big{)}>0\]

We have proven that if \(\varepsilon_{n}\leq\varepsilon_{0}\) and \(\eta_{n}>t\), then there exists \(k\geq 0\) with \(E(t_{k})\geq\lambda t_{k}\).

Hence,

\[\mathbb{P}(\eta_{n}>t,\varepsilon_{n}\leq\varepsilon_{0})\leq C_{\lambda}\sum_ {k\geq 0}\exp(-c_{\lambda}a^{km}nt^{m}).\]

A standard comparison between this sum and an integral shows that this sum is at most of order

\[K_{6}(nt^{m})^{-1}\exp(-K_{7}nt^{m}).\] (39)

for two positive constants \(K_{6}\), \(K_{7}\) depending on \(\mathsf{M}\) and \(f_{\min}\). But when \(nt^{m}\leq 1\), we can simply use the bound \(\mathbb{P}(\eta_{n}>t,\varepsilon_{n}\leq\varepsilon_{0})\leq 1\). Hence,

\[\mathbb{P}(\eta_{n}>t,\varepsilon_{n}\leq\varepsilon_{0})\leq\min(1,K_{6}(nt^{m })^{-1}\exp(-K_{7}nt^{m}))\leq K_{8}\exp(-K_{9}nt^{m}))\] (40)for two other constants \(K_{\mathsf{s}}\), \(K_{\mathsf{9}}\).

To summarize, we have shown that the random variable \(n\eta_{n}^{m}\mathbf{1}\{\varepsilon_{n}\leq\varepsilon_{0}\}\) is subexponential, with subexponential norm depending only on \(\mathsf{M}\) and \(f_{\min}\), see e.g. [74, Section 2.7]. We will now simply say that a random variable is subexponential to indicate that it is subexponential with a norm depending only on \(\mathsf{M}\) and \(f_{\min}\).

Lemma G.1 shows that the random variable \(nd_{\mathsf{A}_{n}}(x)^{m}\) for a _fixed_\(x\in\mathsf{M}\) is also subexponential. Thus, so is \(nE(0)^{m}=n\max_{x\in\Pi_{\mathsf{M}}}d_{\mathsf{A}_{n}}(x)^{m}\), as a maximum of a finite number of subexponential random variables. As \(nE(\eta_{n})^{m}\leq n(\eta_{n}+E(0))^{m}\leq 2^{m-1}(n\eta_{n}^{m}+nE(0)^{m})\), the random variable \(nE(\eta_{n})^{m}\mathbf{1}\{\varepsilon_{n}\leq\varepsilon_{0}\}\) is also subexponential. In particular, we have \(E(\eta_{n})\mathbf{1}\{\varepsilon_{n}\leq\varepsilon_{0}\}=O_{L^{q}}(n^{-1/m})\) for all \(q\geq 1\).

It remains to bound \(N(\rho_{n})\). First, because of (35), the random variable \(n\rho_{n}^{m}\mathbf{1}\{\varepsilon_{n}\leq\varepsilon_{0}\}\) is subexponential. Also, for a fixed \(t\), \(N(t)\) follows a binomial distribution of parameter \(n\) and \(P(\Pi_{\mathsf{M}}^{t})\). As long as \(t\leq\tau(\mathsf{M})/4\), a ball of radius \(t\) is of mass smaller than \(C_{m}f_{\max}t^{m}\) (see Lemma G.1). Let \(0\leq k\leq n\) be an integer. For any \(t\leq\tau(\mathsf{M})/4\), we bound

\[\mathbb{P}(N(\rho_{n})\geq k,\varepsilon_{n}\leq\varepsilon_{0}) \leq\mathbb{P}(N(t)\geq k,\rho_{n}\leq t)+\mathbb{P}(\rho_{n}>t, \varepsilon_{n}\leq\varepsilon_{0})\] \[\leq\mathbb{P}(N(t)\geq k)+2\exp(-K_{10}nt^{m}),\]

where \(K_{10}\) is proportional to the subexponential norm of \(n\rho_{n}^{m}\mathbf{1}\{\varepsilon_{n}\leq\varepsilon_{0}\}\), see [74, Section 2.7]. Let \(t=(k/n)^{1/m}\min(\tau(\mathsf{M})/4,1/(\#\Pi_{\mathsf{M}}\cdot 2C_{m}f_{\max})^{1 /m})\). This choice of \(t\) ensures that \(t\leq\tau(\mathsf{M})/4\) and that \(\mathbb{E}[N(t)]\leq n(\#\Pi_{\mathsf{M}})C_{m}f_{\max}t^{m}\leq k/2\). Then, by Bernstein's inequality [74, Theorem 2.8.4],

\[\mathbb{P}(N(t)\geq k) \leq\mathbb{P}(N(t)-\mathbb{E}[N(t)]\geq k/2)\leq\exp\left(- \frac{k^{2}/8}{n(\#\Pi_{\mathsf{M}})C_{m}f_{\max}t^{m}+k/6}\right)\] \[\leq\exp\left(-K_{11}k\right)\]

for some constant \(K_{11}\) depending on \(m\), \(\mathsf{M}\) and \(f_{\max}\). We have proven that for all \(k\geq 0\),

\[\mathbb{P}(N(\rho_{n})\geq k,\varepsilon_{n}\leq\varepsilon_{0}) \leq 2\exp\left(-K_{11}k\right)+2\exp(-K_{10}nt^{m})\] \[\leq 2\exp\left(-K_{11}k\right)+2\exp(-K_{12}k)\]

for some constant \(K_{12}\) depending on \(m\), \(\mathsf{M}\), \(f_{\min}\) and \(f_{\max}\). Hence, the random variable \(N(\rho_{n})\mathbf{1}\{\varepsilon_{n}\leq\varepsilon_{0}\}\) is subexponential, with a subexponential norm depending on \(\mathsf{M}\), \(f_{\min}\) and \(f_{\max}\). This implies in particular that \(N(\rho_{n})\mathbf{1}\{\varepsilon_{n}\leq\varepsilon_{0}\}=O_{L^{q}}(1)\) for all \(q\geq 1\). 

Corollary 4.3 is a simple consequence of Proposition 4.2:

**Corollary 4.3**.: _Let \(p\geq 1\) and let \(0\leq i<d\) be an integer. Under the same assumptions as in Proposition 4.2, the following holds:_

* _If_ \(p>m\)_, then_ \(\mathbb{E}[\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_{i }(\mathsf{M}))]\to 0\) _as_ \(n\to\infty\)_._
* _If_ \(p=m\)_,_ \(\mathbb{E}[\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_{i }(\mathsf{M}))]\to\mathrm{Pers}_{p}(\mu_{\infty,i,m})\mathrm{Vol}(\mathsf{M})\) _as_ \(n\to\infty\)_, where_ \(\mathrm{Vol}(\mathsf{M})\) _is the volume of_ \(\mathsf{M}\)_._
* _If_ \(p<m\) _and_ \(i<m\)_, then_ \(\mathbb{E}[\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_{i }(\mathsf{M}))]\to+\infty\) _as_ \(n\to\infty\)_._

_Furthermore, for all \(\alpha>0\), \(\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}_{n}))\) is equal to_

\[\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{M}))+n^{1-\frac{\alpha}{m}} \mathrm{Pers}_{\alpha}(\mu_{\infty,i,m})\int_{\mathsf{M}}f(x)^{1-\frac{\alpha}{m} }\mathrm{d}x+o_{L^{1}}(n^{1-\frac{\alpha}{m}})+O_{L^{1}}\Big{(}\left(\frac{ \log n}{n}\right)^{\frac{1}{m}}\Big{)}.\]

Proof.: Let \(\varepsilon_{n}=d_{H}(\mathsf{A}_{n},\mathsf{M})\). Consider the event \(E=\{\varepsilon_{n}<\tau(M)/2\}\). According to Theorem 2.2, on \(E\), the number of points of \(\mathrm{dgm}_{i}^{(2)}(\mathsf{A}_{n})\) is bounded by some constant \(N_{0}\) depending only on \(\mathsf{M}\).

* Consider the optimal matching \(\gamma_{n}\) given by Proposition 4.2. On the event \(E\), this optimal matching sends all the points of \(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n})\) to the diagonal \(\partial\Omega\). Thus, we have (when \(E\) is satisfied) \[\begin{split}&|\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}), \mathrm{dgm}_{i}(\mathsf{M}))-\mathrm{Pers}_{p}(\mathrm{dgm}_{i}^{(1)}(\mathsf{ A}_{n}))|\\ &\leq N_{0}\max_{u\in\mathrm{dgm}_{i}^{(2)}(\mathsf{A}_{n})}\|u- \gamma_{n}(u)\|_{\infty}^{p}+\#(\mathrm{dgm}_{i}^{(3)}(\mathsf{A}_{n}))\max_{u \in\mathrm{dgm}_{i}^{(3)}(\mathsf{A}_{n})}\|u-\gamma_{n}(u)\|_{\infty}^{p}. \end{split}\] (41) Furthermore, note that \[\begin{split}\max_{u\in\mathrm{dgm}_{i}^{(2)}(\mathsf{A}_{n})}\|u -\gamma_{n}(u)\|_{\infty}^{p}&\leq\max\left(\max_{(u_{1},u_{2}) \in\mathrm{dgm}_{i}^{(2)}(\mathsf{A}_{n})}|u_{2}-\gamma_{n}(u)_{2}|^{p}, \varepsilon_{n}^{p}\right)\\ &\leq\max_{(u_{1},u_{2})\in\mathrm{dgm}_{i}^{(2)}(\mathsf{A}_{n} )}|u_{2}-\gamma_{n}(u)_{2}|^{p}+\varepsilon_{n}^{p}.\end{split}\] We take the expectation and apply the Cauchy-Schwarz inequality to obtain (together with Theorem 4.1, Proposition 4.2 and Lemma G.5): \[\mathbb{E}[\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_ {i}(\mathsf{M}))\mathbf{1}\{E\}]\leq n^{1-p/m}\mathrm{Pers}_{p}(\mu_{f,i})+o(1).\] When \(E\) is not realized, we crudely bound \(\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_{i}(\mathsf{ M}))\) by considering the matching sending every point to the diagonal. The cost of this matching is bounded by \(C_{\mathsf{M}}(1+n^{i+1})\), where \(n^{i+1}\) is an upper bound on the number of points in \(\mathrm{dgm}_{i}(\mathsf{A}_{n})\) and \(C_{\mathsf{M}}\) is some constant depending on \(\mathsf{M}\). Hence, \[\mathbb{E}[\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_ {i}(\mathsf{M}))\mathbf{1}\{E^{c}\}]\leq C_{\mathsf{M}}(1+n^{i+1})\mathbb{P}( \varepsilon_{n}>\tau(\mathsf{M})/2)=o(1),\] according to Lemma G.5. This proves the first bullet point.
* The second bullet point is proved likewise from (41). Indeed, in that case, it holds that \[\mathbb{E}[|\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm} _{i}(\mathsf{M}))-\mathrm{Pers}_{p}(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n}))| \mathbf{1}\{E\}]=o(1).\] (42) Also, using the same crude bound, we obtain that \[\mathbb{E}[|\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm} _{i}(\mathsf{M}))-\mathrm{Pers}_{p}(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n}))| \mathbf{1}\{E^{c}\}]=o(1).\] (43) So far, we have proved that \(\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_{i}(\mathsf{ M}))=\mathrm{Pers}_{p}(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n}))+o_{L^{1}}(1)\). According to Theorem 4.1, it holds that \(\mathrm{Pers}_{p}(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n}))=\mathrm{Pers}_{p}( \mu_{f,i})+o_{L^{1}}(1)\) for \(p=m\), proving the second bullet point.
* For the third bullet point, we use that on the event \(E\), \[\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_{i}(\mathsf{ M}))\geq\mathrm{Pers}_{p}(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n})).\] (44) The latter is equal to \(n^{1-p/m}\mathrm{Pers}_{p}(\mu_{f,i})+o_{L^{1}}(n^{1-p/m})\), with \(\mathrm{Pers}_{p}(\mu_{f,i})>0\): indeed, the support of the measure \(\mu_{f,i}\) is nontrivial for \(i<m\), see [47, 42]. Hence, \[\begin{split}\mathbb{E}[\mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}( \mathsf{A}_{n}),\mathrm{dgm}_{i}(\mathsf{M}))]&\geq\mathbb{E}[ \mathrm{OT}_{p}^{p}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_{i}(\mathsf{ M}))\mathbf{1}\{E\}]\\ &\geq\mathbb{E}[\mathrm{Pers}_{p}(\mathrm{dgm}_{i}^{(1)}(\mathsf{A }_{n}))]-\mathbb{E}[\mathrm{Pers}_{p}(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n})) \mathbf{1}\{E^{c}\}].\end{split}\] The second term goes to zero (use the crude bound \(\mathrm{Pers}_{p}(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n}))\leq C_{\mathsf{M}}(1+ n^{i+1})\)), while the first one diverges. This proves the third bullet point.

At last, we prove the formula for the asymptotic expansion of

\[\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}_{n}))=\mathrm{Pers}_{\alpha} (\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n}))+\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i }^{(2)}(\mathsf{A}_{n}))+\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}^{(3)}(\mathsf{ A}_{n})).\] (45)

The first term is equal to \(n^{1-\alpha/m}\mathrm{Pers}_{\alpha}(\mu_{\infty,i,m})\int_{\mathsf{M}}f(x)^{1- \frac{\alpha}{m}}\mathrm{d}x+o_{L^{1}}(n^{1-\alpha/m})\) according to Theorem 4.1. Remark that for \(u,v\in\Omega\), \(|\mathrm{pers}_{\alpha}(u)-\mathrm{pers}_{\alpha}(v)|\leq 2\alpha(\mathrm{pers}_{ \alpha}(u)+\mathrm{pers}_{\alpha}(v))\|u-v\|_{\infty}\). Hence, on the event \(E=\{\varepsilon_{n}<\tau(\mathsf{M})/2\}\),

\[\begin{split}&|\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}^{(2)}( \mathsf{A}_{n}))+\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}^{(3)}(\mathsf{A}_{n}))- \mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{M}))|\\ &\leq 2\alpha\varepsilon_{n}(\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}^{(2)}( \mathsf{A}_{n}))+\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}^{(3)}(\mathsf{A}_{n}))+ \mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{M}))).\end{split}\]We crudely bound the persistence of a point in \(\mathrm{dgm}_{i}(\mathsf{A}_{n})\) by \(R(\mathsf{M})\), the radius of the smallest enclosing ball of \(\mathsf{M}\), to obtain that

\[|\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}^{(2)}(\mathsf{A}_{n}))+ \mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}^{(3)}(\mathsf{A}_{n}))-\mathrm{Pers}_{ \alpha}(\mathrm{dgm}_{i}(\mathsf{M}))|\] \[\leq 2\alpha\varepsilon_{n}(R(\mathsf{M})^{\alpha}+1)(\#( \mathrm{dgm}_{i}^{(2)}(\mathsf{A}_{n}))+\#(\mathrm{dgm}_{i}^{(3)}(\mathsf{A}_ {n}))+\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{M}))).\]

We have already established that \(\#(\mathrm{dgm}_{i}^{(2)}(\mathsf{A}_{n}))=O_{L^{2}}(1)\) (actually, it is larger than \(N_{0}\) with only exponentially small probability). Furthermore, Proposition 4.2 states that \(\#(\mathrm{dgm}_{i}^{(3)}(\mathsf{A}_{n}))=O_{L^{2}}(1)\). Lemma G.5 also states that \(\varepsilon_{n}=O_{L^{2}}(((\log n)/n)^{1/m})\). Hence,

\[|\mathrm{Pers}_{\alpha}(\mathrm{dgm}_{i}^{(2)}(\mathsf{A}_{n}))+\mathrm{Pers} _{\alpha}(\mathrm{dgm}_{i}^{(3)}(\mathsf{A}_{n}))-\mathrm{Pers}_{\alpha}( \mathrm{dgm}_{i}(\mathsf{M}))|=O_{L^{1}}(((\log n)/n)^{1/m}).\]

This concludes the proof. 

Finally, remember that we defined linear feature maps as follows (at the end of Section 4): we let \((V,\|\cdot\|)\) be a normed vector space and \(\phi:\Omega\to V\) be Lipschitz continuous. For \(\alpha\geq 0\), the linear feature map \(\Phi_{\alpha}\) associated to \(\phi\) and defined on the space \(\mathcal{D}_{f}\) of finite PDs is

\[\forall a\in\mathcal{D}_{f},\;\Phi_{\alpha}(a)=\sum_{u\in a}\mathrm{pers}(u)^{ \alpha}\phi(u)\in V.\] (46)

Let us prove the associated Corollary 4.4:

**Corollary 4.4**.: _Let \(\alpha\geq 1\) and let \(0\leq i<d\) be an integer. Under the same assumptions as in Proposition 4.2, it holds that \(\Phi_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}_{n}))\) converges in probability to \(\Phi_{\alpha}(\mathrm{dgm}_{i}(\mathsf{M}))\) whenever \(\alpha>m\)._

Proof.: According to [33, Proposition 5.1], the feature map \(\Phi_{\alpha}\) is continuous with respect to the \(\mathrm{OT}_{\alpha}\) distance. But we have shown in Corollary 4.3 that \(\mathbb{E}[\mathrm{OT}_{\alpha}^{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}_{n}), \mathrm{dgm}_{i}(\mathsf{M}))]\to 0\) as \(n\to\infty\). In particular, \(\mathrm{OT}_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}_{n}),\mathrm{dgm}_{i}( \mathsf{M}))\) converges in probability to \(0\). By continuity, so does \(\|\Phi_{\alpha}(\mathrm{dgm}_{i}(\mathsf{A}_{n}))-\Phi_{\alpha}(\mathrm{dgm}_{ i}(\mathsf{M}))\|\). 

## Appendix H Details on numerical experiments

We provide in this section additional details on the numerical experiments conducted in Section 5. PDs are computed using GUDHI [62]. PDs are plotted using the giotto-tda library [72] and persistence images using scikit-tda [64]. All experiments can be easily run on a standard office laptop over a few hours.

**Simulation of generic tori.** Let \(R>r\) be two positive numbers. The (standard) torus \(\mathsf{M}_{0}\) of major radius \(R\) and minor radius \(r\) is given as the image of \([0,2\pi]^{2}\) by the map

\[F:(\theta,\phi)\in[0,2\pi]^{2}\mapsto\begin{pmatrix}(R+r\cos(\theta))\cos( \phi)\\ (R+r\cos(\theta))\sin(\phi)\\ r\sin(\theta)\end{pmatrix}.\] (47)

Consider a list \(y_{1},\ldots,y_{k}\) of pairs of angles in \([0,2\pi]^{2}\), together with positive numbers \(a_{1},\ldots,a_{K}\). We let \(\mathbf{r}(y)=r+\sum_{k=1}^{K}a_{k}\psi(d(y,y_{k})/\sigma)\), where \(\psi(t)=\mathbf{1}\{t<1\}\exp(1/(t^{2}-1))\), \(0<\sigma<2\pi\) and \(d\) is the Euclidean distance on the flat torus. We then define

\[\tilde{F}:(\theta,\phi)\in[0,2\pi]^{2}\mapsto\begin{pmatrix}(R+\mathbf{r}( \theta,\phi)\cos(\theta))\cos(\phi)\\ (R+\mathbf{r}(\theta,\phi)\cos(\theta))\sin(\phi)\\ \mathbf{r}(\theta,\phi)\sin(\theta)\end{pmatrix}.\] (48)

**Lemma H.1**.: _Assume that \(\max_{(\theta,\phi)\in[0,2\pi]^{2}}\mathbf{r}(\theta,\phi)<R-r\). Then, the image of \(\tilde{F}\) is a compact smooth submanifold, homeomorphic to a torus._

Proof.: The condition on the function \(\mathbf{r}\) ensures that the function \(\tilde{F}\) is injective and \((2\pi)\)-periodic in each of its variables. Let \((\theta,\phi)\in[0,2\pi]^{2}\). We write \(\mathbf{r}\) as a shorthand for \(\mathbf{r}(\theta,\phi)\). Let \(S=R+\mathbf{r}\cos(\theta)\) and \(U=-\mathbf{r}\sin(\theta)+\partial_{\theta}\mathbf{r}\cos(\theta)\). The differential of \(\tilde{F}\) is equal to

\[d\tilde{F}(\theta,\phi)=\begin{pmatrix}U\cos(\phi)&-S\sin(\phi)+\partial_{ \phi}\mathbf{r}\cos(\theta)\cos(\phi)\\ U\sin(\phi)&S\cos(\phi)+\partial_{\phi}\mathbf{r}\cos(\theta)\sin(\phi)\\ \mathbf{r}\cos(\theta)+\partial_{\theta}\mathbf{r}\sin(\theta)&\partial_{\phi} \mathbf{r}\sin(\theta)\end{pmatrix}\] (49)The determinant of the two first rows is equal to \(SU\), and is therefore only equal to \(0\) if \(U=0\). But in that case,

\[d\tilde{F}(\theta,\phi)=\begin{pmatrix}0&-S\sin(\phi)+\partial_{\phi}\mathbf{r} \cos(\theta)\cos(\phi)\\ 0&S\cos(\phi)+\partial_{\phi}\mathbf{r}\cos(\theta)\sin(\phi)\\ \mathbf{r}\cos(\theta)+\partial_{\theta}\mathbf{r}\sin(\theta)&\partial_{ \phi}\mathbf{r}\sin(\theta)\end{pmatrix}\] (50)

is a rank \(2\) matrix. Indeed, note that \(U\) is equal to the dot product of \(e_{\theta}=(-\sin(\theta),\cos(\theta))\) with the (nonzero) vector \((\mathbf{r},\partial_{\theta}\mathbf{r})\). Hence, if \(U=0\), then the dot product of \((\mathbf{r},\partial_{\theta}\mathbf{r})\) with the vector \((\cos(\theta),\sin(\theta))\) (that is perpendicular to \(e_{\theta}\)) is nonzero. Furthermore, one of the two top entries in the second column is also nonzero. Indeed, this is clear if \(\partial_{\phi}\mathbf{r}=0\) or if \(\sin(\phi)=0\) (we have \(S>0\) by assumption). Otherwise, having the two entries equal to zero would imply that \(S^{2}=-(\partial_{\phi}\mathbf{r})\cos^{2}(\theta)\), a contradiction.

In all cases, \(d\tilde{F}(\theta,\phi)\) is of maximal rank. This implies the conclusion. 

Let \(R=2.4\), \(r=0.8\), \(\sigma=2\) and \(K=30\). We create a random torus by sampling pairs of angles \(\mathsf{Y}=\{y_{1},\ldots,y_{K}\}\) uniformly at random, conditioned on the fact that \(\max_{y\in[0,2\pi]^{2}}d\mathsf{v}(y)<\sigma\). We then draw the numbers \(a_{1},\ldots,a_{K}\) as exponential random variables of scale \(0.5\), conditioned on the fact that \(\max_{\phi\in[0,2\pi]}\mathbf{r}(\phi)<R-r\). We let \(\mathsf{M}\) be the image of \([0,2\pi]^{2}\) by \(\tilde{F}\). Although we do not rigorously prove that the manifold \(\mathsf{M}\) is almost surely generic, we conjecture that it is the case.

A probability measure on \(P\) on \(\mathsf{M}\) is obtained in the following way. Sample \((\theta,\phi)\in[0,2\pi]^{2}\) so that \(F(\theta,\phi)\) is uniform on the torus. Then, let \(x=\tilde{F}(\theta,\phi)\). To put it another way, \(P\) is the pushforward of the uniform measure on the torus by \(\tilde{F}\circ F^{-1}\).

**Continuity of feature maps** We sample \(n=10^{4}\) points according to \(P\), and compute the Cech PDs of the corresponding set \(\mathsf{A}_{n}\). For \(i=1\), we plot the persistence images with weights \(\mathrm{pers}^{p}\), \(p=0,1,2,4\), with both birth and persistence values ranging between \(0\) and \(1\), and grid step equal to \(0.002\). See Figure 4.

**Convergence of the total persistences.** We run three experiments. First, we compute the Cech PD for \(i=0\) of \(n\) uniform points on a (nongeneric) circle. Second, we compute the Cech PD for \(i=0\) of \(n\) uniform points on a (nongeneric) torus. Third, we compute the Cech PD for \(i=1\) of \(n\) uniform points on a (nongeneric) torus. Each experiment is ran for values of \(n\) ranging from \(n=10^{2}\) to \(n=10^{4}\). We observe in Figure 5 the convergence rate of the total persistence of \(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n})\) predicted by Theorem 4.1. We then repeat each experiment 10 times, with similar rates of convergence observed for each run, although with a large relative standard deviation (around \(30\%\)) for very small values of \(\mathrm{Pers}_{p}(\mathrm{dgm}_{i}^{(1)}(\mathsf{A}_{n}))\) (the relative standard deviation being defined by the ratio between the standard deviation and the mean).

**Convergence of \(\mu_{n,i}\).** Let \(i=1\). Let \(Q\) be the probability distribution obtained as the pushforward of the uniform distribution on \([0,2\pi]^{2}\) by the map \(F\) defined above. Using Equation (49), one can show that the density \(f\) of \(Q\) is given by

\[\forall x\in\mathsf{M}_{0},\;f(x)=\frac{1}{(2\pi)^{2}}\frac{1}{r(R+r\cos( \theta))},\] (51)

where \((\theta,\phi)=F^{-1}(x)\). Assume that the Radon measure \(\mu_{\infty,i,2}\) has a density \(g_{0}\) on \(\Omega\) (this fact is not proven, but conjectured and strongly supported by experiments). Then, using (9), one can make a change of variables and observe that \(\mu_{f,i}\) has a density \(g_{f}\), given by

\[\forall v\in\Omega,\;g_{f}(v)=\frac{1}{(2\pi)^{3}}\int_{0}^{2\pi}\frac{1}{r(R+ r\cos(\theta))}g_{0}\left(\frac{1}{2\pi}\frac{v}{\sqrt{r(R+r\cos(\theta))}} \right)\mathrm{d}\theta.\] (52)

We sample a set \(\mathsf{A}_{n}\) of \(n=10^{5}\) points on a square and consider the convolution of the measure \(\frac{1}{n}\sum_{u\in\mathrm{dgm}_{i}(\mathsf{A}_{n})}\delta_{n^{1/n}=u}\) with a Gaussian kernel, so that we obtain an estimation \(\hat{g}_{0}\) of the density \(g_{0}\). We then define an estimator \(\hat{g}_{f}\) of \(g_{f}\) by approximating the integral over a regular grid of \(100\) points on \([0,2\pi]\).

We then place a grid of size \(100\times 100\) over the square \([0,17]^{2}\). The measure \(\mu_{f,i}\) is approximated by the measure \(\hat{\mu}_{f,i}\) with piecewise constant density on each square of the grid, with density in the square centered at \(x\) given by \(\hat{g}_{f}(x)\). The corresponding measure is displayed in the center of Figure 6.

For a given value of \(n\), we sample a set \(\mathsf{A}_{n}\) of \(n\) points according to \(Q\), and compute the corresponding measure \(\mu_{n,i}\). The same transformations are applied to \(\mu_{n,i}\), so that we obtain a piecewise constant measure \(\hat{\mu}_{n,i}\) on the same \(100\times 100\) grid. The heatmap of this measure is shown on the left of Figure 6.

At last, we approximate the distance \(\mathrm{OT}_{2}(\mu_{n,i},\mu_{f,i})\) by computing the distance \(\mathrm{OT}_{2}(\hat{\mu}_{n,i},\hat{\mu}_{f,i})\) using the POT library, see [40, 55]. The distance is then normalized by \(\mathrm{OT}_{2}(0,\hat{\mu}_{f,i})=\sqrt{\mathrm{Pers}_{2}(\hat{\mu}_{f,i})}\). The evolution of the normalized distance with respect to \(n\) is plotted in Figure 6. As predicted by Theorem 4.1, the \(\mathrm{OT}_{2}\) distance converges to \(0\) as \(n\) gets larger. We then repeat each experiment 10 times, with a convergence to \(0\) observed each time, the relative standard deviation being always smaller than \(7\%\).

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Rigorous proofs of our main claims are provided. All statements include precise assumptions, which were clearly summarized in the introduction. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Our main results are theorems whose hypotheses are rigorously stated, as well as informally discussed. These hypotheses (such as the fact that the data is sampled on a manifold, and the lack of noise) are the main limitations of our work. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [Yes] Justification: The proofs of all the theorems appearing in the main text are given in the appendix. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: Appendix H contains all the details necessary to reproduce the numerical experiments conducted in Section 5. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [No] Justification: The numerical experiments that we ran are basic and can be easily reproduced using the GUDHI library [62]. We therefore did not feel that providing open access to the code was necessary. We are happy to share it on demand. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: All the hyperparameters needed to produce the figures in Section 5 are given in Appendix H. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: The two numerical experiments exhibiting rates of convergence (Figure 5 and Figure 6) were conducted over multiple runs, with orders of magnitude of the fluctuations presented in Appendix H. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.

* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: As stated in the appendix, we only ran small to medium-scale experiments, which each took no more than an hour on a standard office laptop. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research conducted in the paper conforms, in every respect, with the NeurIPS Code of Ethics. Note that due to the theoretical nature of our work, many (though not all) points raised in the Code of Ethics are moot. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: There is no societal impact of the work performed, as it is foundational. Guidelines:* The answer NA means that there is no societal impact of the work performed.
* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: All the libraries used in the experiments are free of use and properly credited. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.

* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with Human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.