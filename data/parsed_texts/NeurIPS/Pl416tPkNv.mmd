**Taking the neural sampling code very seriously: A data-driven approach for evaluating generative models of the visual system**

**Suhas Shrinivasan1,\({}^{\dagger}\), Konstantin-Klemens Lurz1, Kelli Restivo2, George H. Denfield3, Andreas S. Tolias2,5, Edgar Y. Walker4,*, Fabian H. Sinz1,2* \({}^{1}\) Institute for Computer Science and Campus Institute for Data Science, University of Gottingen, Gottingen, Germany \({}^{2}\) Center for Neuroscience and Artificial Intelligence, Department of Neuroscience, Baylor College of Medicine, Houston, USA \({}^{3}\) Department of Psychiatry, Columbia University, New York City, USA \({}^{4}\) Department of Physiology and Biophysics, and Computational Neuroscience Center, University of Washington, Seattle, USA \({}^{5}\) Department of Electrical and Computer Engineering, Rice University, Houston, USA \({}^{\dagger}\)Correspondence: suhas.shrinivasan@uni-goettingen.de, \({}^{*}\) Equal contribution**

[MISSING_PAGE_POST]

Footnote 64perception and behavior have thus grown in prominence, successfully accounting for an extensive array of tasks across perception [1, 2], cognition [3], sensory-motor learning [4] and decision making [5, 6, 7, 8]. These models posit that the brain maintains a statistical generative model of the world, where sensory observations \(\mathbf{x}\) are generated from unknown, world-state variable \(\mathbf{z}\). Upon encountering a stimulus \(\mathbf{x}\), perception in the brain is conceptualized as _probabilistically inferring_ the world-state variable \(\mathbf{z}\) that caused \(\mathbf{x}\). In other words, to perceive \(\mathbf{x}\), the brain would invert the generative model to compute the posterior distribution over \(\mathbf{z}\): \(p\left(\mathbf{z}|\mathbf{x}\right)\). One can express the posterior via Bayes' rule as: \(p\left(\mathbf{z}|\mathbf{x}\right)\propto p\left(\mathbf{x}|\mathbf{z}\right)p \left(\mathbf{z}\right)\), where \(p\left(\mathbf{z}\right)\) is the prior distribution of \(\mathbf{z}\) and \(p\left(\mathbf{x}|\mathbf{z}\right)\) is the conditional distribution characterizing how well a given \(\mathbf{z}\) describes \(\mathbf{x}\). While this has been an influential framework, the neuronal underpinnings of probabilistic inference remain challenging to conceptualize and test experimentally. To this end, the Neural Sampling Code (NSC) [9, 10, 11, 12, 13, 14, 15, 16] is a prominent theory that offers a unique link between neuronal responses and probabilistic inference. Specifically, NSC posits that neuronal responses, \(\mathbf{r}\), to a given stimulus, \(\mathbf{x}\), can be thought of as samples drawn from the posterior distribution: \(\mathbf{r}\sim p\left(\mathbf{z}|\mathbf{x}\right)\) (Figure 1).

Background and related workPrevailing literature on NSC uses simple and restrictive generative models and performs qualitative comparisons of model predictions with neurophysiological data to test the theory. Notably, existing NSC works use simple prior- and conditional distributions with pre-specified parameters. For example, a popular choice for the conditional distribution of images (stimuli) has been Gaussian with a likelihood function that linearly combines pre-specified filters. Hoyer and Hyvarinen [9] learn these filters via independent component analysis on natural images, whereas Haefner, Berkes, and Fiser [12] use oriented Gabor filters instead. Similarly, a popular choice for the prior is the exponential distribution with a pre-specified rate parameter [9]. These choices are inspired by (a) what is already known about sensory neurons, especially in the primary visual cortex (V1), and (b) the fact that it renders posterior computation mathematically simpler. In the examples above, the choice of filters reflects well-known findings that the receptive fields of V1 neurons resemble (Gabor-like) orientation filters [17, 18, 19, 20], and the exponential prior is motivated by the principle of sparse coding [9, 20]. Importantly, these parameters and distributions -- and thereby, the generative models -- are not informed or learned _explicitly_ from neurophysiological data. Rather, these works typically sample from the posterior of the assumed generative model in response to strongly parameterized stimuli (e.g., noisy oriented gratings). The models -- and thereby the theory -- are then evaluated based on how well the samples _qualitatively_ capture specific neurophysiological phenomena such as the mean-variance relationship [9, 21, 22], task-induced noise correlation structures [12], and contextual modulation in V1 neurons [16].

In contrast, recent advances in deep learning-based neural system identification models have set new standards in providing expressive models that can faithfully predict neural population responses to natural stimuli [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], and offer experimentally verifiable insights at the single-neuron level [40, 41, 42]. Additionally, advances in generative modeling, especially of images, have clearly demonstrated the effectiveness of deep, highly nonlinear, generative models such as auto-regressive models [43, 44], variational autoencoders [45, 46, 47], normalizing flows [48, 49, 50, 51], and diffusion models [52, 53, 54]. Given the complexity of high-dimensional natural stimuli and real-world tasks, it is paramount that NSC be considered under a generative model that can match such complexity.

Our objective and contributionsHere we ask: what exactly is the brain's generative model? More specifically, can we identify the brain's generative model from NSC population responses to natural stimuli? Although simple generative models and qualitative evaluations in the NSC literature have offered us great insight into the potential generative models of the brain and engendered support for the theory, there remains a conspicuous gap in the quantitative evaluation of NSC, particularly in response to natural stimuli. In this work, we bridge this gap by proposing a formalization of NSC that 1 allows us to directly fit NSC generative models to recorded neuronal activity in response to natural images, 2 formulate richer and more flexible generative models, and 3 employ standard metrics such as log-likelihood and single trial correlation to quantitatively evaluate different generative models under NSC. As opposed to specifying a generative model that ought to be maintained by the brain, our framework allows us to _learn_ the generative model directly from neurophysiological data. Learning expressive generative models in a data-driven fashion additionally lets us take advantage of population recordings of large and ever-increasing scale in the field [55, 56, 57]. Furthermore, our formalization 1 lets us derive a stimulus-conditioned predictive model of neuronal responses from the trained generative model, which can be directly compared to state-of-the-art system identification models. The predictive model has the ability to provide experimentally-verifiable, neuron-specific predictions from the normative theory.

We demonstrate our approach by fitting classical generative models from NSC literature and flexible deep learning-based generative models on macaque primary visual cortex (V1) population responses to natural images. We show that the flexible models outperform classical models in both their generative- and predictive-model performance. Overall, this work presents an important step towards a quantitative evaluation of NSC, paving the way for a data-driven approach in _learning_ the generative model of the brain.

## 2 Fitting the Neural Sampling Code

### Theory

An explicit formalization of NSCWe begin by formalizing NSC as a latent variable probabilistic model \(\mathbf{z}\longrightarrow\mathbf{x}\longrightarrow\mathbf{r}\), where \(\mathbf{z}\) represents the world state variable that underlies the observable stimulus \(\mathbf{x}\) (Figure 1**A**). Subsequently, the stimulus \(\mathbf{x}\) gives rise to the neuronal responses \(\mathbf{r}\) via the posterior \(p\left(\mathbf{z}|\mathbf{x}\right)\) (Figure 1**B**). NSC posits that the neuronal responses \(\mathbf{r}\) elicited by stimulus \(\mathbf{x}\) can be interpreted as stochastic samples from the posterior distribution \(p\left(\mathbf{z}|\mathbf{x}\right)\) (Figure 1**B, C**). However, the exact relation between \(\mathbf{z}\) and \(\mathbf{r}\) is often left unspecified. For instance, it is not clear what aspect of the neuronal response (e.g., firing rate, presence or absence of spikes, or membrane potential) should be treated as a sample. In fact, most previous works do not make a distinction between \(\mathbf{r}\) and \(\mathbf{z}\), and simply equate an aspect of the neuronal response such as firing rate with the latent sample. Here, we make this assumption explicit and treat the neural response \(\mathbf{r}\) as a random variable that matches the latent random variable \(\mathbf{z}\) in stimulus-conditioned distributions:

\[\mathbf{z}_{\text{sample}} \sim p\left(\mathbf{z}|\mathbf{x}\right)\] (1) \[\mathbf{r} =\mathbf{z}_{\text{sample}},\] (2)

Equation 2 is a slight abuse of notation to state the equivalence in the stimulus-conditioned distributions of \(\mathbf{r}\) and \(\mathbf{z}\), more formally stated as:

\[p\left(\mathbf{r}|\mathbf{x}\right)\overset{\mathrm{d}}{=}p\left(\mathbf{z}| \mathbf{x}\right),\] (3)

where \(\overset{\mathrm{d}}{=}\) denotes equality in distribution or density function. By marginalizing the stimulus, we find that the marginal distribution of \(\mathbf{r}\) must also match that of \(\mathbf{z}\):

\[p\left(\mathbf{r}\right)=\int p\left(\mathbf{r}|\mathbf{x}\right)p\left( \mathbf{x}\right)\mathrm{d}\mathbf{x}\ \overset{\mathrm{d}}{=}\int p\left(\mathbf{z}|\mathbf{x}\right)p\left( \mathbf{x}\right)\mathrm{d}\mathbf{x}=p\left(\mathbf{z}\right).\] (4)

Figure 1: Conceptualizing NSC. **A.** Latent variable model of the world (stimulus): \(\mathbf{z}\) is the world state variable (intensity of oriented Gabor filter here; figure inspired from Orbán et al. [13]) and \(\mathbf{x}\) is the observed sensory stimulus (e.g., an image of a tiger). **B.** Responses \(\mathbf{r}\) under NSC: As the brain encounters a stimulus \(\mathbf{x}\), it inverts its generative model, combining the likelihood \(p\left(\mathbf{x}|\mathbf{z}\right)\) and prior \(p\left(\mathbf{z}\right)\), to obtain the posterior \(p\left(\mathbf{z}|\mathbf{x}\right)\), and \(\mathbf{r}\) are samples from the posterior. **C.** Neural response distribution under NSC: Each point corresponds to a single response pair of two NSC neurons under three distinct stimuli depicted by distinct colors. The distribution of neurons matches the distribution over the corresponding latent variables \(\mathbf{z}\).

Explicitly formalizing NSC with distinct \(\mathbf{r}\) and \(\mathbf{z}\) has two advantages. Firstly, the resulting formulation provides the crucial link between the generative model \(\mathbf{z}\rightarrow\mathbf{x}\) and observed responses \(\mathbf{r}\), serving as the basis for learning the generative model from the responses. This also provides the basis for a neuron-specific model comparison between different NSC models as well as the possibility to make predictions for specific neurons that can be experimentally tested. Secondly, the explicit link highlights the possibility to explore more flexible mappings between \(\mathbf{z}\) and \(\mathbf{r}\). For instance, one could assume that the latent variable \(\mathbf{z}\) is encoded in the membrane potential, but what we observe are spike counts, i.e. \(\mathbf{r}=f(\mathbf{z})\) for some stochastic mapping \(f\). This relation can, in turn, become part of the model, which can then be fitted to real data and compared to alternative versions of the model. In this work, we choose to learn the generative models from the data under the simplest mapping of \(\mathbf{r}\equiv\mathbf{z}\) (Section 3.2). Please see Section 4 for a discussion on alternative mappings between \(\mathbf{r}\) and \(\mathbf{z}\).

In NSC, we note that the latent variables are what underlie the stimulus (such as the intensity of an oriented filter in 1\(\mathbf{A}\)) and are not necessarily any task-relevant experimenter-defined variables (such as orientation in an orientation-discrimination task). This is in contrast to the alternative theory of probabilistic population codes [58; 59], where typically, the latent variable is explicitly defined to be the task-relevant experimenter-defined variables.

Learning the generative model under NSCOne way to quantitatively test an NSC generative model \(p\left(\mathbf{z},\mathbf{x}\right)\) is testing how well the response distribution \(p(\mathbf{r}|\mathbf{x})\) approximates the posterior \(p\left(\mathbf{z}|\mathbf{x}\right)\) of the generative model, i.e., testing equation 3. However in reality \(p\left(\mathbf{z},\mathbf{x}\right)\), and consequently \(p\left(\mathbf{z}|\mathbf{x}\right)\), is unknown to us. However, our formalization allows us to learn the generative model \(p\left(\mathbf{z},\mathbf{x}\right)\) via learning the joint distribution \(p\left(\mathbf{r},\mathbf{x}\right)\). The equivalence between \(p\left(\mathbf{z},\mathbf{x}\right)\) and \(p\left(\mathbf{r},\mathbf{x}\right)\) follows from equations 2, 3 and 4:

\[p\left(\mathbf{z},\mathbf{x}\right) =p\left(\mathbf{z}|\mathbf{x}\right)p\left(\mathbf{x}\right) \overset{\mathrm{d}}{=}p\left(\mathbf{r}|\mathbf{x}\right)p\left(\mathbf{x} \right)=p\left(\mathbf{r},\mathbf{x}\right)\] (5) \[=p\left(\mathbf{x}|\mathbf{z}\right)p\left(\mathbf{z}\right) \overset{\mathrm{d}}{=}p\left(\mathbf{x}|\mathbf{r}\right)p\left(\mathbf{r} \right)=p\left(\mathbf{r},\mathbf{x}\right)\] (6)

The joint distribution can then simply be fitted to recorded stimulus-response pairs \(\{\mathbf{x}^{(i)},\mathbf{r}^{(i)}\}_{i=1}^{N}\) by maximizing the likelihood:

\[\theta^{*}=\operatorname*{arg\,max}_{\theta}\sum_{i=1}^{N}\log \underbrace{p\left(\mathbf{x}^{(i)},\mathbf{r}^{(i)};\theta\right)}_{\text{ Joint}}=\operatorname*{arg\,max}_{\theta_{L},\theta_{P}}\;\sum_{i=1}^{N}\log \underbrace{p\left(\mathbf{x}^{(i)}|\mathbf{r}^{(i)};\theta_{L}\right)}_{ \text{Likelihood}}+\log\underbrace{p\left(\mathbf{r}^{(i)};\theta_{P} \right)}_{\text{Prior}}\] (7)

where \(\theta\) are the parameters of the generative model, that we split into \(\theta_{L}\) and \(\theta_{P}\) for parameters relevant to the likelihood and prior, respectively. Provided that \(\theta_{L}\) and \(\theta_{P}\) do not overlap, the generative models can be learned by learning the likelihood and prior separately.

Evaluating NSC on dataFitting generative models under NSC on recorded data allows us to compare the generative models quantitatively by evaluating their performances as log-likelihood on a held-out test set. Furthermore, once we have learned the generative model \(p\left(\mathbf{r},\mathbf{x};\theta^{*}\right)\), we can invert it to arrive at the posterior \(p\left(\mathbf{r}|\mathbf{x};\theta^{*}\right)\). This provides a neuronal encoding model \(p\left(\mathbf{r}|\mathbf{x}\right)\) under specific assumptions of the NSC model, allowing us to predict neural responses to arbitrary new stimuli. The performance of this predictive model can serve as yet another metric for quantitative model comparison under NSC. Additionally, the posterior allows us to compare the generative models to the normative-theory-free system identification models. It is important to note that our quantification does not make any assumption about the kind of stimuli \(\mathbf{x}\). Existing works on NSC use parametric stimuli from classical neuroscience experiments and perform a qualitative comparison between model- and real-neuronal responses to the same stimuli. Our formulation, on the other hand, allows us to compare different NSC models on _natural images_, the type of stimuli the visual system has evolved to process.

### Models

Following previous work in NSC [9; 10; 11; 12; 13; 14; 15; 16], here we focus on vision and develop generative models under NSC for natural image stimuli \(\mathbf{x}\) and spike counts \(\mathbf{r}\) recorded from the visual cortex (Figure 2**A**). Developing generative models entails developing models for the prior \(p\left(\mathbf{r}\right)\) and the likelihood \(p\left(\mathbf{x}|\mathbf{r}\right)\) (Figure 2**B**). Additionally, we also fit an approximate posterior \(q\left(\mathbf{r}|\mathbf{x}\right)\). We summarize our fitting methodology in an algorithm towards the end of the section (Algorithm 1).

PriorSpike counts \(\mathbf{r}\) are discrete. Hence, we can neither directly fit standard literature models, such as an exponential [9] or a Laplace distribution [20] to the discrete variable \(\mathbf{r}\), nor can we straightforwardly fit more common flexible density models such as normalizing flows [49; 60], as they are all continuous density models. A common approach to remedy this is to employ uniform dequantization, where the discrete quantity is converted into a continuous signal by adding uniform random noise [43; 61; 62]. We adopt the more general approach of variational dequantization where the noise distribution is learned instead of being fixed to be uniform [63; 64; 65; 66]. In this method, prior distribution over discrete \(\mathbf{r}\) is captured by positing a generative model involving a continuous latent variable \(\boldsymbol{\zeta}\) linked to the discrete response \(\mathbf{r}\) via a deterministic quantizer function: \(P\left(\mathbf{r}\right)=\int P(\mathbf{r}|\boldsymbol{\zeta})p(\boldsymbol{ \zeta})d\boldsymbol{\zeta}\), where \(P(\mathbf{r}|\boldsymbol{\zeta})\) is the _quantizer_ and \(p(\boldsymbol{\zeta})\) is the _continuous prior_.

Since the integral is usually intractable, the whole model is fit by optimizing the evidence lower bound (ELBO):

\[\log P\left(\mathbf{r}\right)\geq\mathbb{E}_{\boldsymbol{\zeta}\sim q( \boldsymbol{\zeta}|\mathbf{r};\nu)}\left[\log\overbrace{p\left(\boldsymbol{ \zeta};\omega\right)}^{\text{Continuous prior}}\right]+\mathbb{H}\left( \overbrace{q\left(\boldsymbol{\zeta}|\mathbf{r};\nu\right)}^{\text{Dequantizer}}\right)\] (8)

where \(q\left(\boldsymbol{\zeta}|\mathbf{r};\nu\right)\) is the approximate posterior distribution with parameters \(\nu\), \(p\left(\boldsymbol{\zeta};\omega\right)\) is the continuous prior with parameters \(\omega\), and \(\mathbb{H}\left(q\left(\boldsymbol{\zeta}|\mathbf{r};\nu\right)\right)=- \mathbb{E}_{\boldsymbol{\zeta}\sim q(\boldsymbol{\zeta}|\mathbf{r};\nu)} \left[\log q\left(\boldsymbol{\zeta}|\mathbf{r};\nu\right)\right]\) is the conditional entropy of the dequantizing distribution. Note that Equation (8) only provides a lower-bound to \(\log P\left(\mathbf{r}\right)\), and a tighter bound via importance-weighted sampling [66; 67; 68] (Appendix A).

In our work, we only consider factorized prior distributions, i.e., we treat neurons to be _a priori_ independent \(\log P\left(\mathbf{r}\right)=\sum_{i}\log P\left(\mathbf{r}_{i}\right)\). This choice is informed by both the nature of the V1 neural data that showed limited correlation across all stimuli and the simplicity of the fit it provides. The same independence assumption was applied for the continuous prior distribution over the dequantized responses \(\boldsymbol{\zeta}\). Given this dequantizer framework, we explore three different NSC priors by varying the distribution over the continuous latent \(p\left(\boldsymbol{\zeta};\nu\right)\):

1. Exponential (**Exp**), \(\frac{1}{\lambda}\exp\frac{-\boldsymbol{\zeta}}{\lambda}H\left(\boldsymbol{ \zeta}\right)\), as found in the original NSC model by Hoyer & Hyvarinen [9].
2. Half-normal (**HN**), \(\frac{\sqrt{2}}{\sigma\sqrt{\pi}}\exp\left(-\frac{\xi^{2}}{2\sigma^{2}} \right)H\left(\boldsymbol{\zeta}\right)\), where \(H\left(\boldsymbol{\zeta}\right)\) is the heavyside function.
3. Normalizing flow (**Flow**): \(p(\boldsymbol{\zeta};\omega)=p_{\text{base}}(T^{-1}(\boldsymbol{\zeta};\omega) )\cdot|\frac{\partial\,T^{-1}(\boldsymbol{\zeta};\omega)}{\partial\boldsymbol {\zeta}}|\), where we choose \(p_{\text{base}}\) to be a standard normal, and \(T^{-1}\) represents the following series of invertible mappings with learnable parameters \(\omega\): [affine, \(\tanh\), affine, \(\tanh\), affine, \(\tanh\), affine, \(\text{softplus}^{-1}]\), where \(\text{softplus}^{-1}(y)=\log(e^{y}-1)\), affine\((y)=ay+b\) with learnable parameters \(a\) and \(b\). \(\text{softplus}^{-1}\) ensures that the support of \(\boldsymbol{\zeta}\) is non-negative, since we are ultimately interested in modeling the distribution of (non-negative) spike counts (Figure 2**C**, "Prior" sub-panel).

Figure 2: **A. Overview of the experimental setup for neuronal recordings (see Section 3.2 for a summary of the data description and Cadena et al. [29] for the complete details). B. Parameterized generative model for NSC: \(\theta_{P}\): parameter of the prior \(p\left(\mathbf{r};\theta_{P}\right)\); \(\theta_{L}\): parameter of the likelihood \(p\left(\mathbf{x}|\mathbf{z};\theta_{L}\right)\); \(\phi\): parameters of the (approximate) posterior \(q\left(\mathbf{r}|\mathbf{x};\phi\right)\). C. Flexible prior, likelihood, and posterior models. The prior follows our dequantization framework consisting of 3 components: (1) continuous prior \(p(\boldsymbol{\zeta};\omega)\) (normalizing flow with Gaussian base distribution), (2) quantizer \(P(\mathbf{r}|\boldsymbol{\zeta})\) (floor function), and (3) variational dequantizer \(q\left(\boldsymbol{\zeta}|\mathbf{r};\nu\right)\) (a conditional normalizing flow, Appendix B). The likelihood is an isotropic Gaussian distribution over \(\mathbf{x}\), where the parameters are functions (MLP) of \(\mathbf{r}\). The posterior is a Gamma distribution over \(\mathbf{r}\) whose parameters are functions of \(\mathbf{x}\), modeled as a system identification-based convolutional neural-network model (Appendix C).**

For the dequantizer distribution, \(q\left(\bm{\zeta}|\mathbf{r};\nu\right)\), we utilize a conditional normalizing flow-based flexible distribution, as in [66] (Appendix B).

LikelihoodWe model the likelihood as an isotropic Gaussian distribution:

\[p\left(\mathbf{x}|\mathbf{r}^{(i)}\right)=\mathcal{N}\left(\mathbf{x}|\bm{\mu}^ {(i)},\bm{\sigma}^{2(i)}\cdot\mathbf{I}\right),\] (9)

where the parameters mean, \(\bm{\mu}^{(i)}\in\mathbb{R}^{\left|\mathbf{x}\right|}\) and variance, \(\bm{\sigma}^{(i)}\in\mathbb{R}_{>0}^{\left|\mathbf{x}\right|}\) are functions of response, \(\mathbf{r}^{(i)}\), and \(\left|\mathbf{x}\right|\) is the number of dimensions of \(\mathbf{x}\). We consider (1) a linear function where \(\bm{\mu}=w_{\bm{\mu}}\mathbf{r}^{(i)}+b_{\bm{\mu}}\) and \(\bm{\sigma}=\exp^{w_{\bm{\sigma}}\mathbf{r}^{(i)}+b_{\bm{\sigma}}}\) (**Lin**) and (2) a nonlinear function \(\bm{\mu}=w_{\bm{\mu}}\text{MLP}(\mathbf{r}^{(i)})+b_{\bm{\mu}}\) and \(\bm{\sigma}=\exp^{w_{\bm{\sigma}}\text{MLP}(\mathbf{r}^{(i)})+b_{\bm{\sigma}}}\), where \(\text{MLP}(\cdot)\) is a neural network (**MLP**) (Figure 2**C** "Likelihood" sub-panel).

PosteriorIn many cases, the posterior distribution for a desired generative model is not analytically tractable and must be approximated, commonly using variational inference or Markov Chain Monte Carlo sampling [69; 70; 71]. Here, since we learn the generative model \(p\left(\mathbf{x},\mathbf{r};\theta^{*}\right)\), we can approximate the true posterior \(p\left(\mathbf{r}|\mathbf{x};\theta^{*}\right)\) by fitting a model posterior \(q\left(\mathbf{r}|\mathbf{x};\phi\right)\) to samples from \(p\left(\mathbf{x},\mathbf{r};\theta^{*}\right)\) directly via maximum log-likelihood:

\[\phi^{*}=\arg\max_{\phi}\sum_{\mathbf{x}^{\prime},\mathbf{r}^{\prime}}\log q \left(\mathbf{r}^{\prime}|\mathbf{x}^{\prime};\phi\right),\] (10)

where \(\mathbf{x}^{\prime},\mathbf{r}^{\prime}\sim p\left(\mathbf{x},\mathbf{r}; \theta^{*}\right)\), are samples from the trained generative model. We model the posterior distribution of responses conditioned on images as a factorized Gamma distribution, following state-of-the-art (SOTA) work in system identification [72]: \(p\left(\mathbf{r}|\mathbf{x}^{(i)}\right)=\prod_{j=1}^{S}p_{\Gamma}\left( \mathbf{r}_{j}|\bm{\alpha}^{(i)},\bm{\beta}^{(i)}\right)\), where \(\mathbf{x}^{(i)}\) is the \(i\)th image, \(\mathbf{r}_{j}\) is the \(j\)th neuron out of \(|\mathbf{r}|=S\) total neurons, and the parameters concentration, \(\bm{\alpha}^{(i)}\) and rate, \(\bm{\beta}^{(i)}\) are functions of the image, \(\mathbf{x}^{(i)}\). Since these functions map an image to response distribution parameters, we model them using a convolutional neural network model (Figure 2**C** "Posterior" sub-panel), following SOTA system identification work [25; 27; 73] (Appendix C).

## 3 Experiments

### Synthetic data

We simulated 10,000 pairs of images and neuronal responses from the following three classical NSC models: \(\left.\vbox{\hbox{\hbox to 0.0pt{\hbox to 0.0pt{\hbox to 0.0pt{\hbox to 0.0pt{\hss \char 30}}}\hbox{$\bf{1}$}}}}\right.\) a Hoyer & Hyvarinen model (HNH) with an exponential prior [9], \(\left.\vbox{\hbox{\hbox to 0.0pt{\hbox to 0.0pt{\hbox to 0.0pt{\hbox to 0.0pt{\hss \char 30}}}\hbox{$\bf{1}$}}}}\right.\) an Olshausen & Field (ONF) model where the prior is a Laplace distribution [20], and \(\left.\vbox{\hbox{\hbox to 0.0pt{\hbox to 0.0pt{\hbox to 0.0pt{\hbox to 0.0pt{\hss \char 30}}}\hbox{$\bf{1}$}}}}\right.\) a full Gaussian model (Gauss) where the prior is an isotropic Gaussian with mean 0 and variance \(\sigma_{2}^{2}\). All the three models share a common linear, isotropic Gaussian likelihood \(p\left(\mathbf{x}|\mathbf{r}\right)=\mathcal{N}\left(\mathbf{x}|Ar,\sigma^{2} \mathbf{I}\right)\), where \(A\) is the factor loading matrix learned via standard independent component analysis model (ICA) with a complete basis on natural image patches [9; 74]. Additionally, we sampled image-response pairs from \(\left.\vbox{\hbox{\hbox to 0.0pt{\hbox to 0.0pt{\hbox to 0.0pt{\hbox to 0.0pt{\hbox to 0.0pt{\hss \char 30}}}\hbox{$\bf{1}$}}}}}\right.\) our flexible model with **Flow** prior (described in Section 2.2) and MLP-based likelihood (Section 2.2), where all parameters were randomly initialized. For any given generative model, we first sample neuronal responses from the prior via \(\mathbf{r}^{(i)}\sim p\left(\mathbf{r}\right)\), and then sample corresponding images via

\begin{table}
\begin{tabular}{c c c} \hline \hline
**Prior** & **Likelihood** & **Name** \\ \hline Exponential (\(\lambda=1\)) & Linear & Exp1-Lin \\ Exponential & Linear & Exp-Lin \\ Half-Normal & Linear & HN-Lin \\ Normalizing Flow & Linear & Flow-Lin \\ Exponential & MLP & Exp-MLP \\ Half-Normal & MLP & HN-MLP \\ Normalizing Flow & MLP & Flow-MLP \\ \hline \hline \end{tabular}
\end{table}
Table 1: Generative models that we fit as being composed of priors and likelihoods.

\(\mathbf{x}^{(i)}\sim p\left(\mathbf{x}|\mathbf{r}^{(i)}\right)\), where \(i\in{1,\ldots,10,000}\). We hold out a set of 1,000 pairs as the test set. We fitted all models on the datasets simulated from the classical as well as the flexible models via Equation (7) and computed joint log-likelihoods of the trained models on the held-out test set as \(\log p\left(\mathbf{x}^{(i)},\mathbf{r}^{(i)}\right)=\log p\left(\mathbf{x}^{(i )}|\mathbf{r}^{(i)}\right)+\log p\left(\mathbf{r}^{(i)}\right)\). For the classical models, maximum likelihood estimates of the parameters were obtained analytically (Appendix F). We trained the flexible model using gradient descent.

We find that (1) the flexible model fits responses and images simulated under other NSC models well, i.e., learns \(p\left(\mathbf{r}\right)\) and \(p\left(\mathbf{x}|\mathbf{r}\right)\) and closely approximates the log-likelihood of the true models. Importantly, it outperforms the fit of other NSC models with mismatched generative distributions, consistently being the best model after the ground-truth model (first 3 columns in Figure 3). Furthermore, the flexible model is capable of generating complex image and response distributions that could not be easily captured by the classical generative models (column 4 in Figure 3). This demonstrates that our framework allows for NSC model fitting and that the flexible model has the ability to flexibly capture the data distribution across a wide range of generative models. Critically, a flexible model could fit complex generative models that cannot be modeled well by other classical models.

### Neurophysiological data

Data descriptionNext, we demonstrate applying our approach to real neuronal data. We used 32-channel laminar NeuroNexus arrays (Figure 2**A**) to record population activity from the primary visual cortex (V1) of two awake male rhesus macaque monkeys (_Macaca muldata_) [29] as they fixated on grayscale natural images sampled from the ImageNet dataset [75]. All the experiments concerned with the recordings adhered to the National Institutes of Health, United States guidelines, and received approval from the Institutional Animal Care and Use Committee. Each image was presented for 120 ms, and spike counts between 40 ms and 160 ms after the image onset were computed and used as the neuronal response \(\mathbf{r}\). The image stimulus \(\mathbf{x}\) used for modeling is 41 \(\times\) 41 px. For more details on the experiments and data collection, refer to Cadena et al. [29]. We collected data across 12 recording sessions, each having approximately 16,000 image-response pairs and at least 16 well-isolated single units. We split the dataset into approximately 10,000 pairs for training, 3,000 pairs for validation, and 3,000 for testing (for exact details on all sessions, see Appendix D). We do not aggregate data across sessions and fit models separately for each session since the images can differ from session to session, and not all neurons have seen every image.

Fitting the generative modelGiven a dataset of images and responses, \(\{\mathbf{x},\mathbf{r}\}_{i=0}^{N}\), we fit the likelihood \(p\left(\mathbf{x}|\mathbf{r};\theta_{L}\right)\) on the image-response pairs and the prior \(p\left(\mathbf{r};\theta_{P}\right)\) on the responses, \(\mathbf{r}\) as in Equation (7). We fit all of the generative models on each recording session as following procedure described in Table 1. Below, we describe our results for the session with the largest number of neurons (29 well-isolated single units) in detail and report summary results on all sessions.

For the prior models (Figure 4**A**), we report the test-set log-likelihood performance of all models (Exp, HN, Flow) relative to the Exp1-model as the baseline. We find that our flexible normalizing flow model (Flow) achieves the best performance, improving the score from the exponential distribution (Exp) by 0.095 bits per neuron per trial, amounting to 2.755 bits across 29 neurons per trial. For the likelihood models (Figure 4**B**), we find that using an MLP likelihood function, the model improved by 0.052 bits per pixel per trial, amounting to 87.19 bits of improvement across all 41\(\times\)41 pixels per trial, relative to the model with linear likelihood function. For the joint distribution (Figure 4**C**), we find that the flexible model (Flow-MLP) achieves the highest log-likelihood score, offering an improvement of 1.8452e-3 bits per pixel per neuron per trial, amounting to 89.951 bits across all 41\(\times\)41 pixels and 29 neurons per trial. We observed that in each of the cases, flexible models (Flow prior, MLP likelihood) offer much higher log-likelihood performance, with the same trend found across all sessions (Appendix D).

Figure 3: \(\log p\left(\mathbf{x},\mathbf{r}\right)\) of models on simulated data (trial averaged, in bits). Column denotes the model generating the samples (data) and rows the trained NSC model. Since the exponential prior in HN has a non-negative support and does not match that of ONF and Gauss, the scores for HN under ONF and Gauss data are unavailable.

**Learning the posterior distribution** For each of the trained generative models, \(p\left(\mathbf{x},\mathbf{r};\theta^{*}\right)\), we approximated the model's posterior distribution \(p\left(\mathbf{r}|\mathbf{x};\theta^{*}\right)\) using an approximate posterior \(q\left(\mathbf{r}|\mathbf{x};\phi\right)\) trained on samples drawn from the trained generative model (Equation (10), Algorithm 1). We evaluated the posterior distribution for each generative model by computing their mean log-likelihood on real neuronal responses conditioned on real images from the test set (Figure 5**A, B**). We also computed a single-trial correlation between the mean of the learned posterior distributions and neuronal responses (Figure 5**C, D**). Finally, we compared the posterior distribution to a deep system identification model.

We find that, in general, a more flexible trained generative model tends to yield a higher posterior predictive performance. Based on the log-likelihood evaluation, our flexible generative model (Flex-MLP) gained as much as 1.39 bits per neuron per trial compared to the baseline Exp1-Lin model and 0.61 bits per neuron per trial compared to Exp-Lin model (the Hoyer & Hyvarinen model [9]). In terms of single-trial correlation performance, our flexible generative model (Flex-MLP) achieved 10% higher correlation compared to the Exp1-Lin baseline and 8% higher correlation compared to Exp-Lin. When averaged across all sessions, we find that Flow-Lin performs best, almost on

Figure 4: Log-likelihood scores (in bits) of generative models on population recordings (test set) as fit on recording session with the highest number of neurons (\(n=29\)). Error-bars denote the standard error of mean across trials. **A**. Prior models, \(p\left(\mathbf{r}\right)\): log-likelihood (lower bound) relative to the baseline Exp1 prior model. The score is averaged across neurons and trials. Note that for the prior models on discrete spike counts, \(\mathbf{r}\), we can only obtain a lower bound on \(p\left(\mathbf{r}\right)\). Here we show the importance-sampling bound (Equation (11)) with 1000 samples. **B**. Likelihood models \(p\left(\mathbf{x}|\mathbf{r}\right)\): absolute log-likelihood of likelihood functions, averaged across image pixels and trials. **C**. Joint models \(p\left(\mathbf{x},\mathbf{r}\right)\): log-likelihoods relative to the baseline Exp1-Lin generative model. The score is averaged across pixels, neurons and trials.

Figure 5: Posterior performance of NSC models, along with system identification model (“Sysident”). Error bars represent the standard error of mean over neuronal responses. All metrics are averaged over number of neurons and trials. **A**. The lower bound of log-likelihood in bits, for session with 29 neurons. We compute the lower-bound since we are evaluating the Gamma-posterior on (discrete) spike counts, and full-likelihood is intractable (Appendix G). **B**. Same as A but across all 12 sessions (purple: average, gray: single session). **C**. Single-trial correlation, for session with 29 neurons. **D**. Same as C across all 12 sessionspar with the Flow-MLP, which achieves 0.019 bits per neuron per trial less. Furthermore, a system identification model trained on the dataset of real neuronal responses performed better than the best NSC generative model, gaining 0.17 bits per neuron per trial and 17% higher correlation per neuron per trial compared to Flex-MLP.

All model training was performed using backpropagation and gradient descent and we provide training, compute and infrastructure details in Appendix E.

## 4 Discussion

The main focus of this work was to develop a way to answer the question, "How well does NSC explain neurophysiological data _quantitatively_?". While NSC is a prominent normative theory for probabilistic computation in the brain, and the literature has provided much qualitative insight, our work is the first to offer a quantitative paradigm for empirically testing it using brain responses to ecological, natural stimuli. Our framework additionally lets us formulate more flexible generative models -- which can be better informed by the data -- and employ standard metrics such as log-likelihood to quantitatively evaluate alternative generative models under NSC. Furthermore, inverting the learned generative model has allowed us to obtain the posterior distribution, which is equivalently a neuronal response predictive model. Importantly, this let us compare NSC models to models outside of NSC's theoretical framework, such as system identification models, allowing us to benchmark the predictive performance of NSC models. Our results demonstrated that the flexible generative models outperformed classical models in terms of both generative and predictive model performance, yet system identification models achieve superior response-predictive performance compared to even our best generative models. We now discuss some limitations of our current study and discuss a number of open questions and implement future directions.

**Limitations I: Assumption of strict 1:1 neuron-latent mapping**: One limitation in our current study is that we only use a 1:1 identity mapping between the activity of neurons and latent variables in our formulation of NSC. Abiding by this restriction could limit the capacity of the NSC models, especially considering some existing work in NSC that have qualitatively explored more flexible mappings. For example, Orban et al. [13] model membrane potential values (responses) as a nonlinear function of posterior samples. Furthermore, Savin and Deneve [76] map responses of \(N\) neurons to \(D\) latent variables where \(N>D\). Many more ways of how \(\mathbf{r}\) and \(\mathbf{z}\) relate are conceivable. However, our formulation with a separate \(\mathbf{r}\) and \(\mathbf{z}\) allows us to, in principle, incorporate different mappings and learn the corresponding generative models. Since the focus of this study was on the aspect of fitting NSC models to data, we chose the simplest (original) interpretation of NSC where \(\mathbf{r}\equiv\mathbf{z}\).

**Limitations II: Definition of a "sample" as total spike counts**: We defined a "sample" as the total spike count of neuronal activity within a specific time window following the stimulus, which is not necessarily what literature works do. However, to our knowledge, there is no generally agreed upon or rigorous definition of a "sample" in NSC. While NSC was originally motivated with firing rate/spike counts over a 500ms window as the sample [9; 21], many alternative definitions such as membrane potential over 10ms [13] have been employed. It is unclear on what generally applicable metric -- other than goodness of fit to data -- such a definition could be evaluated. This in fact served to us as another motivating factor for striving towards a data-driven evaluation of sampling models that would allow one to compare such choices in an informed manner. In this work, we chose the total spike count as the working definition.

**Limitations III: Better generative models are needed:** Advances in deep learning architectures, latent variable models, and transfer learning have greatly enhanced the capabilities of generative models in machine learning. We believe the models we chose, although more expressive than classical models, are still limiting, especially considering that our likelihood \(p\left(\mathbf{x}|\mathbf{r}\right)\) uses linear or MLP decoding from neurons to images, with a simple Gaussian noise model. To capture the rich and complex nature of neuronal representations of natural images, we believe it is necessary to consider more sophisticated generative models, that even incorporate a natural image prior, that would eventually close the gap in predictive performance between system identification performance and NSC generative models. Furthermore, an important avenue of research is identifying biological mechanisms that underlie NSC (i.e. sampling from the posterior) [14; 77; 78; 79; 80; 81; 82]. It is worth noting that our deep learning-based generative models are not meant to be mechanistic models of NSC neurons.

Rather, we believe that our approach lays the foundation for alternative biologically plausible models to be quantitatively evaluated and compared.

**Why do system identification models perform better than NSC generative models?** System identification models are directly trained discriminatively, i.e., \(\min_{\theta}\mathbb{E}_{\mathbf{x}}\left[D_{\text{KL}}\left(p_{\text{true}}\left( \mathbf{r}|\mathbf{x}\right)||p_{\text{model}}\left(\mathbf{r}|\mathbf{x}; \theta\right)\right)\right]\), to predict neuronal responses to natural images and deep-learning based ones are currently SOTA. There is still much room to build better generative models that would better explain the data (see Limitations III). However, for a given dataset of responses to stimuli from a _fixed stimulus distribution_, we do not expect the posterior of even the ideal generative model to surpass the performance of the ideal system identification model because the generative model training, i.e., \(\min_{\theta}\left\{\mathbb{E}_{\mathbf{x}}\left[D_{\text{KL}}\left(p_{\text{ true}}\left(\mathbf{r}|\mathbf{x}\right)||p_{\text{model}}\left(\mathbf{r}| \mathbf{x};\theta\right)\right)\right]+D_{\text{KL}}\left(p_{\text{true}}\left( \mathbf{x}\right)||p_{\text{model}}\left(\mathbf{x};\theta\right)\right)\right\}\), does not provide any advantage over system identification in response prediction unless some specific inductive biases are introduced in the generative model.

**Why bother fitting NSC models if they fail to quantitatively compete with system identification?** If we change the stimulus distribution \(p\left(\mathbf{x}\right)\) to \(p_{\text{new}}\left(\mathbf{x}\right)\) with markedly different stimulus statistics and let the sensory neurons adapt to \(p_{\text{new}}\left(\mathbf{x}\right)\), we would expect the system identification model's performance to drop on \(p_{\text{new}}\left(\mathbf{x}\right)\). The system identification model might have to be retrained on a new dataset of responses under \(p_{\text{new}}\left(\mathbf{x}\right)\). This is the case where we would expect the NSC's learned generative model to be beneficial. Specifically, change in \(p\left(\mathbf{x}\right)\) to \(p_{\text{new}}\left(\mathbf{x}\right)\) may entirely derive from the change in prior \(p\left(\mathbf{z}\right)\) to \(p_{\text{new}}\left(\mathbf{z}\right)\), while \(p\left(\mathbf{x}|\mathbf{z}\right)\) remains fixed. Hypothetically, this is since \(p\left(\mathbf{x}|\mathbf{z}\right)\) represents the invariant "physical" process by which the latents (e.g., the identity of an animal) give rise to observations (e.g., the appearance of the animal). Consequently, if NSC accurately describes a neural population, i.e, \(\mathbf{r}\sim p\left(\mathbf{z}|\mathbf{x}\right)\propto p\left(\mathbf{x}| \mathbf{z}\right)p\left(\mathbf{z}\right)\), the neuronal adaptation can be accounted for by simply learning \(p_{\text{new}}\left(\mathbf{z}\right)\), i.e., \(\mathbf{r}_{\text{new}}\sim p_{\text{new}}\left(\mathbf{z}|\mathbf{x}\right) \propto p\left(\mathbf{x}|\mathbf{z}\right)p_{\text{new}}\left(\mathbf{z}\right)\), keeping \(p\left(\mathbf{x}|\mathbf{z}\right)\) fixed. We believe such out-of-context generalization is a theoretical strength of NSC, and is a consequence of its normative nature (responses being "samples" from the _posterior distribution_). Such normative hypotheses are neither present in the purely phenomenological system identification models and nor is it straightforward to equip them with normative assumptions.

The above insight thus helps us identify potential future experiments to test NSC models utilizing our framework since it lets us learn the generative model \(p\left(\mathbf{x}|\mathbf{z}\right)p\left(\mathbf{z}\right)\) via \(p\left(\mathbf{x}|\mathbf{r}\right)p\left(\mathbf{r}\right)\) (NSC assumption). Namely, one could perform experiments in which we let the neural population adapt to different sensory contexts with expected shifts in \(p\left(\mathbf{z}\right)\). Using our NSC framework, we would expect to be able to predict how neuronal responses should change (as reflected in updated \(\mathbf{r}_{\text{new}}\sim p_{\text{new}}\left(\mathbf{z}|\mathbf{x}\right)\)) under new contexts.

**Why have previous works not fit NSC models to data?** We attribute the lack of such attempts to (1) limitations in data availability, (2) complexities involved in training flexible machine learning and inference algorithms on recorded data, and (3) the philosophical approach behind normative theories. Normative theories describe how a biological system _ought_ to function in order to tackle fundamental tasks. They propose models with parameters that are optimized for those tasks, without relying on actual experimental data [83, 84]. Typically normative theories are evaluated using qualitative agreements between the proposed models and data. NSC is itself a normative theory. In contrast, phenomenological approaches such as system identification propose models whose parameters are directly learned from experimental data. Normative and phenomenological approaches have historically been developed independently of each other. Similar to Mlynarski et al. [83], who interpolate between phenomenological and normative models via maximum entropy priors, our approach allows us to get the best of both worlds: state-of-the-art deep learning-based system identification models from phenomological approaches and the theoretical underpinnings of the normative NSC. System identification provides us with expressive models that faithfully model and predict the activity of thousands of neurons to rich natural stimuli. NSC, on the other hand, goes beyond what experimental data alone could offer by letting us hypothesize how neurons encode uncertainty about the stimulus, reflecting the posterior distribution over latent variables in a generative model of the world, thus allowing us make novel predictions such as about generalizability across stimulus contexts and design relevant experiments.

## Acknowledgements

We thank all the reviewers for their valuable and constructive feedback. We additionally thank Jakob Macke, Xaq Pitkow, Ralf Haefner, GregO Orban, members of Sinz-, Walker-, Tolias-lab for helpful and stimulating discussions. SS and FHS are supported by the German Research Foundation (DFG): SFB 1233, Robust Vision: Inference Principles and Neural Mechanisms, TP 06, project number: 276693517. KKL is supported by German Federal Ministry of Education and Research through the Tubingen AI Center (FKZ: 01IS18039A). KR and AST are supported by the National Eye Institute, National Institutes of Health (NIH), USA with award numbers R01 EY026927, and Core Grant for Vision Research with grant number T32-EY-002520-37. AST, KR and FHS are supported by the National Science Foundation Collaborative Research in Computational Neuroscience, USA with grant number IIS-2113173, Germany with FKZ: 01GQ2107. GHD is supported by The National Institute of Mental Health, NIH, USA with grant number T32MH015144. EYW is supported by the National Institute of Neurological Disorders and Stroke, NIH, USA with grant number 1U19NS107609-01.

## References

* [1] Yair Weiss, Eero P Simoncelli, and Edward H Adelson. "Motion illusions as optimal percepts". In: _Nature neuroscience_ 5.6 (2002), pp. 598-604.
* [2] David C Knill and Whitman Richards. _Perception as Bayesian inference_. Cambridge University Press, 1996.
* [3] Charles Kemp et al. "A probabilistic model of theory formation". In: _Cognition_ 114.2 (2010), pp. 165-196.
* [4] Konrad P Kording and Daniel M Wolpert. "Bayesian integration in sensorimotor learning". In: _Nature_ 427.6971 (2004), pp. 244-247.
* [5] Marc O Ernst and Martin S Banks. "Humans integrate visual and haptic information in a statistically optimal fashion". In: _Nature_ 415.6870 (2002), pp. 429-433.
* [6] Aaron C Courville, Nathaniel D Daw, and David S Touretzky. "Bayesian theories of conditioning in a changing world". In: _Trends in cognitive sciences_ 10.7 (2006), pp. 294-300.
* [7] Konrad Kording. "Decision theory: what" should" the nervous system do?" In: _Science_ 318.5850 (2007), pp. 606-610.
* [8] Nathaniel D Daw et al. "Cortical substrates for exploratory decisions in humans". In: _Nature_ 441.7095 (2006), pp. 876-879.
* [9] Patrik Hoyer and Aapo Hyvarinen. "Interpreting neural response variability as Monte Carlo sampling of the posterior". In: _Advances in neural information processing systems_ 15 (2002).
* [10] Jozsef Fiser et al. "Statistically optimal perception and learning: from behavior to neural representations". In: _Trends in cognitive sciences_ 14.3 (2010), pp. 119-130.
* [11] Pietro Berkes et al. "Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment". In: _Science_ 331.6013 (2011), pp. 83-87.
* [12] Ralf M Haefner, Pietro Berkes, and Jozsef Fiser. "Perceptual decision-making as probabilistic inference by neural sampling". In: _Neuron_ 90.3 (2016), pp. 649-660.
* [13] Gergo Orban et al. "Neural variability and sampling-based probabilistic representations in the visual cortex". In: _Neuron_ 92.2 (2016), pp. 530-543.
* [14] Rodrigo Echeveste et al. "Cortical-like dynamics in recurrent circuits optimized for sampling-based probabilistic inference". In: _Nature neuroscience_ 23.9 (2020), pp. 1138-1149.
* [15] Camille Rullan Buxo and Cristina Savin. "A sampling-based circuit for optimal decision making". In: _Advances in Neural Information Processing Systems_ 34 (2021), pp. 14163-14175.
* [16] Dylan Festa et al. "Neuronal variability reflects probabilistic inference tuned to natural image statistics". In: _Nature communications_ 12.1 (2021), p. 3635.
* [17] David H Hubel and Torsten N Wiesel. "Receptive fields of single neurones in the cat's striate cortex". In: _The Journal of physiology_ 148.3 (1959), p. 574.

* [18] S Marcelja. "Mathematical description of the responses of simple cortical cells". In: _JOSA_ 70.11 (1980), pp. 1297-1300.
* [19] John G Daugman. "Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensional visual cortical filters". In: _JOSA A_ 2.7 (1985), pp. 1160-1169.
* [20] Bruno A Olshausen and David J Field. "Emergence of simple-cell receptive field properties by learning a sparse code for natural images". In: _Nature_ 381.6583 (1996), pp. 607-609.
* [21] AF Dean. "The variability of discharge of simple cells in the cat striate cortex". In: _Experimental Brain Research_ 44.4 (1981), pp. 437-440.
* [22] David J Tolhurst, J Anthony Movshon, and Andrew F Dean. "The statistical reliability of signals in single neurons in cat and monkey visual cortex". In: _Vision research_ 23.8 (1983), pp. 775-785.
* [23] Daniel LK Yamins et al. "Performance-optimized hierarchical models predict neural responses in higher visual cortex". In: _Proceedings of the national academy of sciences_ 111.23 (2014), pp. 8619-8624.
* [24] Alexander S Ecker et al. "A rotation-equivariant convolutional neural network model of primary visual cortex". In: _arXiv preprint arXiv:1809.10504_ (2018).
* [25] Santiago A Cadena et al. "Deep convolutional models improve predictions of macaque V1 responses to natural images". In: _PLoS computational biology_ 15.4 (2019), e1006897.
* [26] Benjamin Cowley and Jonathan W Pillow. "High-contrast "gaudy" images improve the training of deep neural network models of visual cortex". In: _Advances in Neural Information Processing Systems_ 33 (2020), pp. 21591-21603.
* [27] Konstantin-Klemens Lurz et al. "Generalization in data-driven models of primary visual cortex". In: _BioRxiv_ (2020), pp. 2020-10.
* [28] Mohammad Bashiri et al. "A flow-based latent state generative model of neural population responses to natural images". In: _Advances in Neural Information Processing Systems_ 34 (2021), pp. 15801-15815.
* [29] Santiago A Cadena et al. "Diverse task-driven modeling of macaque V4 reveals functional specialization towards semantic tasks". In: _bioRxiv_ (2022), pp. 2022-05.
* [30] Konstantin F Willeke et al. "Deep learning-driven characterization of single cell tuning in primate visual area V4 unveils topological organization". In: _bioRxiv_ (2023), pp. 2023-05.
* [31] Pawel A Pierzchlewicz et al. "Energy Guided Diffusion for Generating Neurally Exciting Images". In: _bioRxiv_ (2023), pp. 2023-05.
* [32] Charles F Cadieu et al. "Deep neural networks rival the representation of primate IT cortex for core visual object recognition". In: _PLoS computational biology_ 10.12 (2014), e1003963.
* [33] Eleanor Batty et al. "Multilayer recurrent network models of primate retinal ganglion cell responses". In: _International Conference on Learning Representations_. 2016.
* [34] Jan Antolik et al. "Model constrained by visual hierarchy improves prediction of neural responses to natural scenes". In: _PLoS computational biology_ 12.6 (2016), e1004927.
* [35] Lane McIntosh et al. "Deep learning models of the retinal response to natural scenes". In: _Advances in neural information processing systems_ 29 (2016).
* [36] William F Kindel, Elijah D Christensen, and Joel Zylberberg. "Using deep learning to reveal the neural code for images in primary visual cortex". In: _arXiv preprint arXiv:1706.06208_ (2017).
* [37] David Klindt et al. "Neural system identification for large populations separating "what" and "where"": In: _Advances in Neural Information Processing Systems_ 30 (2017).
* [38] Martin Schrimpf et al. "Brain-score: Which artificial neural network for object recognition is most brain-like?" In: _BioRxiv_ (2018), p. 407007.
* [39] Fabian Sinz et al. "Stimulus domain transfer in recurrent models for large scale cortical population prediction on video". In: _Advances in neural information processing systems_ 31 (2018).

* [40] Pouya Bashivan, Kohitij Kar, and James J DiCarlo. "Neural population control via deep image synthesis". In: _Science_ 364.6439 (2019), eaav9436.
* [41] Carlos R Ponce et al. "Evolving images for visual neurons using a deep generative network reveals coding principles and neuronal preferences". In: _Cell_ 177.4 (2019), pp. 999-1009.
* [42] Edgar Y Walker et al. "Inception loops discover what excites neurons most using deep predictive models". In: _Nature neuroscience_ 22.12 (2019), pp. 2060-2065.
* [43] Benigno Uria, Iain Murray, and Hugo Larochelle. "RNADE: The real-valued neural autoregressive density-estimator". In: _Advances in Neural Information Processing Systems_ 26 (2013).
* [44] Aaron Van den Oord et al. "Conditional image generation with pixelcnn decoders". In: _Advances in neural information processing systems_ 29 (2016).
* [45] Diederik P Kingma and Max Welling. "Auto-encoding variational bayes". In: _arXiv preprint arXiv:1312.6114_ (2013).
* [46] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. "Stochastic backpropagation and approximate inference in deep generative models". In: _International conference on machine learning_. PMLR. 2014, pp. 1278-1286.
* [47] Rewon Child. "Very deep vaes generalize autoregressive models and can outperform them on images". In: _arXiv preprint arXiv:2011.10650_ (2020).
* [48] Laurent Dinh, David Krueger, and Yoshua Bengio. "Nice: Non-linear independent components estimation". In: _arXiv preprint arXiv:1410.8516_ (2014).
* [49] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. "Density estimation using real nvp". In: _arXiv preprint arXiv:1605.08803_ (2016).
* [50] Mathieu Germain et al. "Made: Masked autoencoder for distribution estimation". In: _International conference on machine learning_. PMLR. 2015, pp. 881-889.
* [51] Durk P Kingma and Prafulla Dhariwal. "Glow: Generative flow with invertible 1x1 convolutions". In: _Advances in neural information processing systems_ 31 (2018).
* [52] Jonathan Ho, Ajay Jain, and Pieter Abbeel. "Denoising diffusion probabilistic models". In: _Advances in neural information processing systems_ 33 (2020), pp. 6840-6851.
* [53] Jiaming Song, Chenlin Meng, and Stefano Ermon. "Denoising diffusion implicit models". In: _arXiv preprint arXiv:2010.02502_ (2020).
* [54] Robin Rombach et al. "High-resolution image synthesis with latent diffusion models". In: _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_. 2022, pp. 10684-10695.
* [55] Ian H Stevenson and Konrad P Kording. "How advances in neural recording affect data analysis". In: _Nature neuroscience_ 14.2 (2011), pp. 139-142.
* [56] Peiran Gao and Surya Ganguli. "On simplicity and complexity in the brave new world of large-scale neuroscience". In: _Current opinion in neurobiology_ 32 (2015), pp. 148-155.
* [57] Cole Hurwitz et al. "Building population models for large-scale neural recordings: Opportunities and pitfalls". In: _Current opinion in neurobiology_ 70 (2021), pp. 64-73.
* [58] Wei Ji Ma et al. "Bayesian inference with probabilistic population codes". In: _Nature neuroscience_ 9.11 (2006), pp. 1432-1438.
* [59] Jeffrey M Beck et al. "Probabilistic population codes for Bayesian decision making". In: _Neuron_ 60.6 (2008), pp. 1142-1152.
* [60] Danilo Rezende and Shakir Mohamed. "Variational inference with normalizing flows". In: _International conference on machine learning_. PMLR. 2015, pp. 1530-1538.
* [61] L Theis, A van den Oord, and M Bethge. "A note on the evaluation of generative models". In: _International Conference on Learning Representations (ICLR 2016)_. 2016, pp. 1-10.
* [62] Aaron Van den Oord and Benjamin Schrauwen. "Factoring variations in natural images with deep gaussian mixture models". In: _Advances in neural information processing systems_ 27 (2014).

* [63] Jonathan Ho et al. "Flow++: Improving flow-based generative models with variational dequantization and architecture design". In: _International Conference on Machine Learning_. PMLR. 2019, pp. 2722-2730.
* [64] Christina Winkler et al. "Learning likelihoods with conditional normalizing flows". In: _arXiv preprint arXiv:1912.00042_ (2019).
* [65] Emiel Hoogeboom et al. "Integer discrete flows and lossless compression". In: _Advances in Neural Information Processing Systems_ 32 (2019).
* [66] Emiel Hoogeboom, Taco S Cohen, and Jakub M Tomczak. "Learning discrete distributions by dequantization". In: _arXiv preprint arXiv:2001.11235_ (2020).
* [67] Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. "Importance weighted autoencoders". In: _arXiv preprint arXiv:1509.00519_ (2015).
* [68] Justin Domke and Daniel R Sheldon. "Importance weighting and variational inference". In: _Advances in neural information processing systems_ 31 (2018).
* [69] David M Blei, Alp Kucukelbir, and Jon D McAuliffe. "Variational inference: A review for statisticians". In: _Journal of the American statistical Association_ 112.518 (2017), pp. 859-877.
* [70] Christopher M Bishop and Nasser M Nasrabadi. _Pattern recognition and machine learning_. Vol. 4. 4. Springer, 2006.
* [71] David JC MacKay. _Information theory, inference and learning algorithms_. Cambridge university press, 2003.
* [72] Konstantin-Klemens Lurz et al. "Bayesian Oracle for bounding information gain in neural encoding models". In: _The Eleventh International Conference on Learning Representations_. 2023. url: https://openreview.net/forum?id=iYCSh0MqUg.
* [73] Luca Baroni et al. "Learning invariance manifolds of visual sensory neurons". In: _NeurIPS Workshop on Symmetry and Geometry in Neural Representations_. PMLR. 2023, pp. 301-326.
* [74] Aapo Hyvarinen. "Independent component analysis: recent advances". In: _Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences_ 371.1984 (2013), p. 20110534.
* [75] Jia Deng et al. "Imagenet: A large-scale hierarchical image database". In: _2009 IEEE conference on computer vision and pattern recognition_. Ieee. 2009, pp. 248-255.
* [76] Cristina Savin and Sophie Deneve. "Spatio-temporal Representations of Uncertainty in Spiking Neural Networks". In: _Advances in Neural Information Processing Systems_. Ed. by Z Ghahramani et al. Vol. 27. Curran Associates, Inc., 2014, pp. 2024-2032.
* [77] Lars Buesing et al. "Neural dynamics as sampling: a model for stochastic computation in recurrent networks of spiking neurons". In: _PLoS computational biology_ 7.11 (2011), e1002211.
* [78] Yanping Huang and Rajesh P Rao. "Neurons as Monte Carlo Samplers: Bayesian Inference and Learning in Spiking Networks". In: _Advances in neural information processing systems_ 27 (2014).
* [79] Guillaume Hennequin, Laurence Aitchison, and Mate Lengyel. "Fast sampling-based inference in balanced neuronal networks". In: _Advances in neural information processing systems 27_ (2014).
* [80] Xingsi Dong et al. "Adaptation Accelerating Sampling-based Bayesian Inference in Attractor Neural Networks". In: _Advances in Neural Information Processing Systems_ 35 (2022), pp. 21534-21547.
* [81] Paul Masset et al. "Natural gradient enables fast sampling in spiking neural networks". In: _Advances in Neural Information Processing Systems_ 35 (2022), pp. 22018-22034.
* [82] Shirui Chen et al. "Expressive probabilistic sampling in recurrent neural networks". In: _arXiv preprint arXiv:2308.11809_ (2023).
* [83] Wiktor Mlynarski et al. "Statistical analysis and optimality of neural systems". en. In: _Neuron_ 109.7 (Apr. 2021), 1227-1241.e5.
* [84] Daniel Levenstein et al. "On the role of theory and modeling in neuroscience". In: _Journal of Neuroscience_ 43.7 (2023), pp. 1074-1088.

* [85] Adam Paszke et al. "Pytorch: An imperative style, high-performance deep learning library". In: _Advances in neural information processing systems_ 32 (2019).
* [86] Diederik P Kingma and Jimmy Ba. "Adam: A method for stochastic optimization". In: _arXiv preprint arXiv:1412.6980_ (2014).