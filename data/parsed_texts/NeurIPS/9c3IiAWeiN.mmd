# IPM-LSTM: A Learning-Based Interior Point Method for Solving Nonlinear Programs

Xi Gao

School of Mathematics and Statistics, Xi'an Jiaotong University, Xi'an, China

Jinxin Xiong

Akang Wang

Qihong Duan

School of Mathematics and Statistics, Xi'an Jiaotong University, Xi'an, China

Jiang Xue

Qingjiang Shi

###### Abstract

Solving constrained nonlinear programs (NLPs) is of great importance in various domains such as power systems, robotics, and wireless communication networks. One widely used approach for addressing NLPs is the interior point method (IPM). The most computationally expensive procedure in IPMs is to solve systems of linear equations via matrix factorization. Recently, machine learning techniques have been adopted to expedite classic optimization algorithms. In this work, we propose using Long Short-Term Memory (LSTM) neural networks to approximate the solution of linear systems and integrate this approximating step into an IPM. The resulting approximate NLP solution is then utilized to warm-start an interior point solver. Experiments on various types of NLPs, including Quadratic Programs and Quadratically Constrained Quadratic Programs, show that our approach can significantly accelerate NLP solving, reducing iterations by up to \(60\%\) and solution time by up to \(70\%\) compared to the default solver.

## 1 Introduction

Constrained _Nonlinear Programs_ (NLPs) represent a category of mathematical optimization problems in which the objective function, constraints, or both, exhibit nonlinearity. Popular NLP variants encompass _Quadratic Programs_ (QPs), _Quadratically Constrained Quadratic Programs_ (QCQPs), semi-definite programs, among others. These programs are commonly classified as convex or non-convex, contingent upon the characteristics of their objective function and constraints. The versatility of NLPs allows for their application across a wide array of domains, including power systems (Conejo and Baringo, 2018), robotics (Schaal and Atkeson, 2010), and wireless communication networks (Chiang, 2009).

The primal-dual _Interior Point Method_ (IPM) stands as a preeminent algorithm for addressing NLPs (Nesterov and Nemirovskii, 1994; Nocedal and Wright, 1999). It initiates with an infeasible solution positioned sufficiently far from the boundary. Subsequently, at each iteration, the method refines the solution by solving a system of linear equations, thereby directing it towards the optimal solution. Throughout this iterative process, the algorithm progresses towards feasibility and optimality while keeping the iterate well-centered, ultimately converging to the optimal solution. However, a notable computational bottleneck arises during the process of solving linear systems, necessitating matrix decomposition with a runtime complexity of \(\mathcal{O}(n^{3})\).

Recently, the _Learning to Optimize_ (L2O) (Bengio et al., 2021; Chen et al., 2024; Gasse et al., 2022) paradigm has emerged as a promising methodology for tackling various optimization problems,spanning unconstrained optimization (Chen et al., 2022a), linear optimization (Chen et al., 2022b; Li et al., 2024), and combinatorial optimization (Baker, 2019; Gasse et al., 2022; Han et al., 2023). Its ability to encapsulate common optimization patterns renders it particularly appealing. Noteworthy is the application of learning techniques to augment traditional algorithms such as the gradient descent method (Andrychowicz et al., 2016), simplex method (Liu et al., 2024), and IPM (Qian et al., 2024).

We observe that existing works on learning-based IPMs primarily concentrate on solving LPs (Qian et al., 2024). Motivated by the robustness and efficiency of IPMs for general NLPs, we pose the following question:

_Can we leverage L2O techniques to expedite IPMs for NLPs?_

In this study, we propose the integration of _Long Short-Term Memory_ (LSTM) neural networks to address the crucial task of solving systems of linear equations within IPMs, introducing a novel approach named IPM-LSTM. An illustration of the IPM-LSTM approach is depicted in Figure 1. Specifically, we substitute the conventional method of solving linear systems with an unconstrained optimization problem, leveraging LSTM networks to identify near-optimal solutions for the latter. We integrate a fixed number of IPM iterations into the LSTM loss function and train these networks within the self-supervised learning framework. The substitution is embedded within a classic IPM to generate search directions. Ideally, the primal-dual solution provided by IPM-LSTM should be well-centered with respect to the boundary and associated with a small duality gap. Finally, we utilize such approximate primal-dual solution pairs to warm-start an interior point solver. IPM-LSTM has several attractive features: (_i_) it can be applied to _general NLPs_; (_ii_) it strikes a _good balance between feasibility and optimality_ in the returned solutions; (_iii_) it can _warm-start_ and thereby accelerate interior point solvers.

The distinct contributions of our work can be summarized as follows:

* **Approximating Solutions to Linear Systems via LSTM:** This study marks the first attempt to employ learning techniques for approximating solutions of linear systems in IPMs, achieving significant speedup compared to traditional linear algebra approaches.
* **Two-Stage Framework:** We introduce a two-stage L2O framework. In the first stage, IPM-LSTM generates high-quality primal-dual solutions. In the second stage, these solutions are used to warm-start an interior point solver. This framework effectively accelerates the solving process of IPMs while yielding optimal solutions.
* **Empirical Results:** Compared with existing L2O algorithms, IPM-LSTM demonstrates favorable performance in terms of solution feasibility and optimality across various NLP types, including QPs and QCQPs. Utilizing these solutions as initial points in the state-of-the-art NLP solver IPOPT (Wachter and Biegler, 2006) reduces iterations by up to \(60\%\) and solution time by up to \(70\%\).

Figure 1: An illustration of the IPM-LSTM approach.

Related Works

**Constrained L2O.** Approaches utilizing L2O for constrained optimization can be broadly categorized into two directions: (i) direct learning of the mapping from optimization inputs to full solutions, and (ii) integration of learning techniques alongside or within optimization algorithms (Bengio et al., 2021; Donti et al., 2021). Previous works (Fioretto et al., 2020; Huang et al., 2021; Pan et al., 2023) adopted the former approach, employing a supervised learning scheme to train the mapping. However, this method necessitates a large number of (near-)optimal solutions as training samples, making it resource-intensive. From a self-supervised learning perspective, an intuitive approach is to incorporate the objective and penalization for constraint violation directly into the loss function (Kim et al., 2023; Park and Van Hentenryck, 2023). Nevertheless, such an approach may not guarantee the feasibility of the returned solutions. To address the feasibility issue, notable works such as Donti et al. (2021) first predict a partial solution via neural networks and then complete the full solution by utilizing equality constraints, iteratively correcting the solution towards the satisfaction of inequalities by applying gradient-based methods. However, for general nonlinear inequalities, this correction step may not ensure feasibility (Liang et al., 2023). Other approaches like Li et al. (2023) utilized gauge mappings to enforce feasibility for linear inequalities, while Liang et al. (2023) proposed the homeomorphic projection scheme to guarantee feasibility. However, these methods have limitations; the former is only applicable to linearly constrained problems, and the latter works for problems with feasibility regions homeomorphic to a unit ball. Another critical issue with the approach in Donti et al. (2021) is that the completion step may fail during training when the equality system with some fixed variables becomes infeasible, as highlighted in Han et al. (2024) and Zeng et al. (2024). Consequently, such an approach will not succeed during the training stage. To mitigate this issue, Han et al. (2024) proposed solving a projection problem if the completion step fails. However, the computationally expensive projection step may still be necessary during inference, which hinders its practical value.

**Learning-Based IPMs.** Primal-dual IPMs are polynomial-time algorithms used for solving constrained optimization problems such as LPs and NLPs. The work of Qian et al. (2024) demonstrated that properly designed _Graph Neural Networks_ (GNNs) can theoretically align with IPMs for LPs, enabling GNNs to function as lightweight proxies for solving LPs. However, extending this alignment to NLPs is challenging as representation learning for general NLPs remains unknown. Another avenue of research in learning-based IPMs involves warm-starting implementation. Previous works like Baker (2019), Diehl (2019) and Zhang and Zhang (2022) addressed alternative current optimal power flow (ACOPF) applications and proposed using learning models, such as GNNs, to learn the mapping between ACOPF and its optimal solutions. These predicted solutions are then utilized as initial points to warm-start an interior point optimizer. However, even if these solutions are close to the optimal ones, they may not be well-centered with respect to the trajectory in IPMs, causing the optimizer to struggle in progressing towards feasibility and optimality (Forsgren, 2006).

## 3 Approach

### The Classic IPM

We focus on solving the following NLP (1):

\[\begin{split}\underset{x\in\mathbb{R}^{n}}{\text{min}}& f(x)\\ \text{s.t.}& h(x)=0\\ & x\geq 0\end{split}\] (1)

where the functions \(f:\mathbb{R}^{n}\rightarrow\mathbb{R}\) and \(h:\mathbb{R}^{n}\rightarrow\mathbb{R}^{m}\) are all assumed to be twice continuously differentiable. Problems with general nonlinear inequality constraints can be reformulated in the above form by introducing slack variables. We note that for simplicity, we assume all variables in (1) are non-negative, though NLPs with arbitrary variable bounds can also be handled effectively. Readers are referred to Appendix A for details.

The primal-dual IPM stands as one of the most widely utilized approaches for addressing NLPs. It entails iteratively solving the perturbed _Karush-Kuhn-Tucker_ (KKT) conditions (2) for a decreasing sequence of parameters \(\mu\) converging to zero.

\[\begin{array}{ll}\nabla f(x)+\lambda^{\top}\nabla h(x)-z=0&\quad h(x)=0\\ \text{diag}(z)\text{diag}(x)e=\mu e&\quad x,z\geq 0\end{array}\] (2)

where \(\lambda\in\mathbb{R}^{m}\) and \(z\in\mathbb{R}_{+}^{n}\) denote the corresponding dual variables, \(\text{diag}(\cdot)\) represents a diagonal matrix, and \(e\) is a vector of ones. Let \(F(x,\lambda,z)=0\) denote the system of nonlinear equations in (2). We then employ a one-step _Newton's method_ to solve such a system, aiming to solve systems of linear equations (3).

\[\underbrace{\begin{bmatrix}\nabla^{2}f(x)+\lambda^{\top}\nabla^{2}h(x)&\nabla h ^{\top}(x)&-I\\ \nabla h(x)&&\\ \text{diag}(z)&&\text{diag}(x)\end{bmatrix}}_{\mathcal{J}}\begin{bmatrix} \Delta x\\ \Delta\lambda\\ \Delta z\end{bmatrix}=-F(x,\lambda,z)\] (3)

The IPM commences with an initial solution \((x^{0},\lambda^{0},z^{0})\) such that \(x^{0},z^{0}>0\). At iteration \(k\), the linear system (3) defined by the current iterate \((x^{k},\lambda^{k},z^{k})\) is solved, with \(\mu:=\sigma\left[(z^{k})^{\top}x^{k}\right]/n\) being the perturbation parameter and constant \(\sigma\in(0,1)\). A line-search filter step along the direction \((\Delta x^{k},\Delta\lambda^{k},\Delta z^{k})\) is then performed to ensure boundary condition satisfaction as well as sufficient progress towards objective value improvement or constraint violation reduction. This process iterates until convergence criteria, such as achieving optimality and feasibility within specified tolerances, are met. The IPM is guaranteed to converge to a KKT point with a superlinear rate. A pseudocode of the IPM is presented as Algorithm 1.

```
0: An initial solution \((x^{0},\lambda^{0},z^{0})\), \(\sigma\in(0,1)\), \(k\gets 0\)
0: The optimal solution \((x^{*},\lambda^{*},z^{*})\)
1:while not converged do
2: Update \(\mu^{k}\)
3: Solve the system \(J^{k}\left[(\Delta x^{k})^{\top},(\Delta\lambda^{k})^{\top},(\Delta z^{k})^{ \top}\right]^{\top}=-F^{k}\)
4: Choose \(\alpha^{k}\) via a line-search filter method
5:\((x^{k+1},\lambda^{k+1},z^{k+1})\leftarrow(x^{k},\lambda^{k},z^{k})+\alpha^{k }(\Delta x^{k},\Delta\lambda^{k},\Delta z^{k})\)
6:\(k\gets k+1\)
7:endwhile ```

**Algorithm 1** The classic IPM

We note that, in classic IPMs, one typically reformulates the system (3) and then solves a reduced system of equations (i.e., augmented system) for greater efficiency. However, in this work, we are interested in the full systems since they are associated with smaller condition numbers (Greif et al., 2014) that are critical to the performance of our proposed approach. Additionally, various techniques have been proposed to enhance the robustness and efficiency of IPMs, including second-order correction, inertial correction, and feasibility restoration. Interested readers are referred to Wachter and Biegler (2006) for further details about IPMs.

### Approximating Solutions to Linear Systems

The small number of iterations in IPMs does not always guarantee efficiency because, at times, IPMs encounter a high per-iteration cost of linear algebra operations. In the worst-case scenario, the cost of solving a dense optimization problem using a direct linear algebra method to solve the Newton equation system (3) may reach \(\mathcal{O}(n^{3})\) flops per iteration. This motivates us to avoid computing exact solutions to linear systems and instead focus on their approximations. Toward this goal, we consider the following _least squares problem_ (4):

\[\min_{y}\frac{1}{2}\left\|J^{k}y+F^{k}\right\|^{2},\] (4)

where \(\left\|\cdot\right\|\) denotes the Euclidean norm. If (3) is solvable, then an optimal solution to problem (4) is also the exact solution \(\left[(\Delta x^{k})^{\top},(\Delta\lambda^{k})^{\top},(\Delta z^{k})^{\top} \right]^{\top}\) to system (3). Otherwise, we resort to an approximation of the latter. This perspective is similar to the _inexact IPM_(Bellavia, 1998; Dexter et al., 2022).

**Assumption 1**.: _At iteration \(k\), we could identify some \(y^{k}\) such that_

\[\left\|J^{k}y^{k}+F^{k}\right\|\leq\eta\left[(z^{k})^{\top}x^{k} \right]/n\] (5) \[\|y^{k}\|\leq(1+\sigma+\eta)\|F_{0}(x^{k},\lambda^{k},z^{k})\|.\] (6)

_where \(\eta\in(0,1)\) and \(F_{0}(x^{k},\lambda^{k},z^{k})\) denotes \(F(x^{k},\lambda^{k},z^{k})\) with \(\mu=0\)._

To satisfy Assumption 1, the approximate solution \(y^{k}\) has to be bounded and accurate enough, regardless of whether \(J^{k}\) is invertible.

**Proposition 1** (Bellavia (1998)).: _If \((x^{k},\lambda^{k},z^{k})\) is generated such that Assumption 1 is satisfied, let \((x^{*},\lambda^{*},z^{*})\) denote a limit point of the sequence \(\{(x^{k},\lambda^{k},z^{k})\}\), then \(\{(x^{k},\lambda^{k},z^{k})\}\) converges to \((x^{*},\lambda^{*},z^{*})\) and \(F_{0}(x^{*},\lambda^{*},z^{*})=0\)._

Proposition 1 implies that if solutions with specified accuracy for linear systems in Step 3 are found, the IPM would converge.

### The IPM-LSTM Approach

The problem (4) is an unconstrained convex optimization problem. Various L2O methods have been proposed to solve such problems (Chen et al., 2022; Gregor and LeCun, 2010; Liu et al., 2023). We will employ the LSTM networks in our L2O method for addressing problem (4), hence our approach is called "IPM-LSTM".

**Model Architecture.** LSTM is a type of _recurrent neural network_ designed to effectively capture and maintain long-term dependencies in sequential data (Yu et al., 2019). LSTM networks are commonly considered suitable for solving unconstrained optimization problems due to the resemblance between LSTM recurrent calculations and iterative algorithms (Andrychowicz et al., 2016; Liu et al., 2023; Lv et al., 2017).

The LSTM network consists of \(T\) cells parameterized by the same learnable parameters \(\theta\). Each cell can be viewed as one iteration of a traditional iterative method, as illustrated in Figure 2. Let \(\phi(y):=\frac{1}{2}\left\|J^{k}y+F^{k}\right\|^{2}\) for convenience. The \(t\)-th cell takes the previous estimate \(y_{t-1}\) and the gradient \((J^{k})^{\top}(J^{k}y_{t-1}+F^{k})\) as the input and outputs the current estimate \(y_{t}\):

\[y_{t}:=\text{LSTM}_{\theta}\left(\left[y_{t-1},(J^{k})^{\top}(J^{k}y_{t-1}+F^{ k})\right]\right).\] (7)

The \(T\)-th cell yields \(y_{T}\) as an approximate solution to problem (4). As suggested by Andrychowicz et al. (2016) and Liu et al. (2023), we utilize a coordinate-wise LSTM that shares parameters not only across different LSTM cells but also for all coordinates of \(y\).

**Model Training.** We train the proposed optimizer by finding the optimal \(\theta\) in (7) on a dataset \(\mathcal{M}\) of NLPs. Each sample in \(\mathcal{M}\) is an instance of the optimization problem. During training, we apply the optimizer to each instance \(M\in\mathcal{M}\), performing \(K\) IPM iterations in the outer loop and \(T\) LSTM

Figure 2: The LSTM architecture for solving \(\underset{y}{\text{min}}\)\(\phi(y)\).

time steps in the inner loop, generating a sequence of iterates \(\{(y_{1}^{1},...,y_{T}^{1}),...,(y_{1}^{K},...,y_{T}^{K})\}\) where the superscript \(k\) denotes the IPM iteration number. We then optimize \(\theta\) by minimizing the following loss function:

\[\min_{\theta}\frac{1}{|\mathcal{M}|}\sum_{M\in\mathcal{M}}\left(\frac{1}{K} \sum_{k=1}^{K}\frac{1}{T}\sum_{t=1}^{T}\frac{1}{2}\left\|J^{k}y_{t}^{k}(\theta )+F^{k}\right\|^{2}\right)_{M},\]

where the subscript \(M\) indicates that the corresponding term is associated with instance \(M\). Clearly, our model training falls into the category of _self-supervised learning_. To mitigate memory issues caused by excessively large computational graphs, we employ _truncated backpropagation through time_ after each IPM iteration during training, as done in Chen et al. (2022) and Liu et al. (2023).

**Preconditioning.** The Hessian matrix of \(\phi(y)\) is \((J^{k})^{\top}J^{k}\), whose condition number, \(\kappa((J^{k})^{\top}J^{k})\), is the square of that of \(J^{k}\). Consequently, \(\kappa((J^{k})^{\top}J^{k})\) can easily become very large. Since solving system (4) via LSTM networks emulates iterative first-order methods, the value of \(\kappa((J^{k})^{\top}J^{k})\) strongly affects the performance of LSTM networks. To address this issue, we employ a simple diagonal preconditioning technique that rescales the Hessian matrix \((J^{k})^{\top}J^{k}\) using the Ruiz scaling method Ruiz (2001) to decrease its condition number.

### Two-Stage Framework

To further enhance the solution quality, we propose a two-stage framework that initially obtains a near-optimal and well-centered primal-dual solution via IPM-LSTM and then utilizes this approximate solution to warm-start an interior point solver. In this study, we select IPOPT Wachter and Biegler (2006), an IPM-based solver renowned for its robustness and efficiency in optimizing NLPs.

Our two-stage framework works as follows: Given an NLP (1), we generate an initial point \((x^{0},\lambda^{0},z^{0})\) and formulate the least squares problem (4). Subsequently, the trained LSTM network with \(T\) cells solves this problem and returns a search direction. We then employ the simple fractional-to-boundary method Wachter and Biegler (2006) to determine the step size and reach the new iterate. This procedure is iterated \(K\) times, resulting in a primal-dual solution \((x^{K},\lambda^{K},z^{K})\). Finally, the obtained solution serves as the warm-start solution for IPOPT, leading to the optimal solution \(x^{*}\) upon IPOPT convergence.

## 4 Experiments

### Experimental Settings

We evaluate our approach and compare its performance against traditional methods as well as L2O algorithms for solving various types of NLPs. Furthermore, we also quantify the warm-starting effect of our proposed two-stage approach. Our code is available at https://github.com/NetSysOpt/IPM-LSTM.

**Baseline Algorithms.** In our experiments, we denote our algorithm by IPM-LSTM and compare it against both traditional optimizers and L2O algorithms. The traditional optimizers considered are: (i) OSQP Stellato et al. (2020): an ADMM-based solver designed for convex QPs. (ii) IPOPT 3.14.8 Wachter and Biegler (2006): a state-of-the-art IPM-based solver for NLPs with the default linear solver MUMPS Amestoy et al. (2000) and a convergence tolerance of \(10^{-4}\). We also assess several L2O algorithms, including: (i) NN Donti et al. (2021): a straightforward deep learning approach that integrates the objective function and penalty for constraint violations into the loss function. (ii) DC3 Donti et al. (2021): an end-to-end method that uses "completion" steps to maintain equality constraints and "correction" steps for inequality feasibility. (iii) DeepLDE Kim et al. (2023): an algorithm that trains neural networks using a primal-dual approach to impose inequality constraints and employs "completion" for equality constraints. (iv) PDL Park and Van Hentenryck (2023): a self-supervised learning method that jointly trains two networks to approximate primal and dual solutions. (v) LOOP-LC Li et al. (2023): a neural approximator that maps inputs of linearly constrained models to high-quality feasible solutions using gauge maps. (vi) H-Proj Liang et al. (2023): a method that applies a homeomorphic projection scheme to post-process solutions resulting from the completion step in DC3.

**Datasets.** The dataset used in this paper includes randomly generated benchmarks obtained from Chen and Burer (2012), Donti et al. (2021) and Liang et al. (2023), as well as real-world instancesfrom Globallib (see http://www.minlplib.org). These benchmarks encompass QPs, QCQPs, and simplex non-convex programs. For each case, we generate \(10,000\) samples and divide them into a \(10:1:1\) ratio for training, validation, and testing, respectively. All numerical results are reported for the test set.

**Model Settings.** All LSTM networks have a single layer and are trained using the Adam optimizer (Kingma, 2014). During IPM-LSTM training, an early stopping strategy with a patience of \(50\) is employed, halting training if no improvement is observed for \(50\) iterations, while satisfying inequality and equality constraints violation less than 0.005 and 0.01. The learning rate is 0.0001, and the batch size is 128 for each task. Additional IPM-LSTM parameters for each task are provided in Appendix C.

**Evaluation Configuration.** All our experiments were conducted on an NVIDIA RTX A6000 GPU, an Intel Xeon 2.10GHz CPU, using Python 3.10.0 and PyTorch 1.13.1.

### Computational Results

**Convex QPs.** We consider convex QPs with both equality and inequality constraints:

\[\begin{split}\underset{x\in\mathbb{R}^{n}}{\text{min}}& \frac{1}{2}x^{\top}Q_{0}x+p_{0}^{\top}x\\ \text{s.t.}& p_{j}^{\top}x\leq q_{j}& j=1,\cdots,l\\ & p_{j}^{\top}x=q_{j}& j=l+1,\cdots,m\\ & x_{i}^{L}\leq x_{i}\leq x_{i}^{U}& i=1,\cdots,n\end{split}\] (8)

where \(Q_{0}\in\mathbb{S}_{+}^{n}\), \(p_{j}\in\mathbb{R}^{n}\), \(q_{j}\in\mathbb{R}\), \(x_{i}^{L}\in\mathbb{R}\cup\{-\infty\}\) and \(x_{i}^{U}\in\mathbb{R}\cup\{+\infty\}\). We conduct experiments on two groups of QPs, each instance with \(200\) variables, \(100\) inequalities and \(100\) equalities. The first group is generated in the same way as Donti et al. (2021), where only the right hand sides of equality constraints are perturbed while the second one considers perturbation for all model parameters. Let "Convex QP (RHS)" denote the former and "Convex QPs (ALL)" denote the latter. It is noteworthy that, in line with Donti et al. (2021), we also investigate the performance of IPM-LSTM and baseline algorithms on smaller-scale convex QPs. Interested readers are directed to Appendix D for details.

We ran IPM-LSTM and all baseline algorithms on the test set "Convex QPs (RHS)", and we reported their computational results, which were averaged across \(833\) instances. The results are presented in Table 1. We denote this experiment by "End-to-End" for convenience. The columns labeled "Max Ineq.", "Mean Ineq.", "Max Eq.", and "Mean Eq." denote the maximum and mean violations for inequalities and equalities, respectively. The columns "Obj." and "Time (s)" represent the final primal objective and the runtime in seconds. Both OSQP and IPOPT solved these instances to guaranteed optimality, with OSQP being significantly more efficient due to its specialization as a QP-specific solver. All L2O baseline algorithms returned solutions very quickly. However, solutions generated by NN and PDL exhibited significant constraint violations. While the solutions from DC3 and DeepLDE were nearly feasible, they corresponded to inferior objective values. On the other hand, LOOP-LC produced feasible and near-optimal solutions, whereas H-Proj generated feasible solutions but with

\begin{table}
\begin{tabular}{c c c c c c c c c c c} \hline \hline \multirow{2}{*}{Method} & \multicolumn{5}{c}{End-to-End} & \multicolumn{5}{c}{IPOPT (warm start)} & \multirow{2}{*}{Total} & \multirow{2}{*}{Gain} \\  & Obj. \(\downarrow\) & Max ineq. \(\downarrow\) & Mean ineq. \(\downarrow\) & Max eq. \(\downarrow\) & Mean eq. \(\downarrow\) & Time (s) \(\downarrow\) & Ine. \(\downarrow\) & Time (s) \(\downarrow\) & Time (s) \(\downarrow\) \\ \hline \multicolumn{10}{c}{**Convex QPs (RHS)**} \\ \hline OSQP & -29.176 & 0.000 & 0.000 & 0.000 & 0.000 & 0.009 & - & - & - & - \\ IPOPT & -29.176 & 0.000 & 0.000 & 0.000 & 0.000 & 0.642 & 12.5 & - & - & - \\ HN & -26.787 & 0.000 & 0.000 & 0.631 & 0.235 & 0.001 & 10.5 & 0.560 & 0.560 & 16.051 \\ DC3 & -26.720 & 0.002 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 10.2 & 0.535 & 0.535 & 18.436 /16.7\% \\ DeepLDE & -3.697 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 12.5 & 0.648 & 0.648 & 0.005 /0.9\% \\ PDL & -28.559 & 0.421 & 0.122 & 0.024 & 0.000 & \(<\)0.001 & 9.7 & 0.514 & 0.514 & 22.43 /**19.9\%** \\ LOOP-LC & -28.512 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 10.8 & 0.565 & 0.565 & 13.651 /21.0\% \\ IPM-Prej & -23.257 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 11.2 & 0.605 & 0.605 & 10.49\% /5.8\% \\ IPM-LSTM & -29.050 & 0.000 & 0.000 & 0.000 & 0.001 & 0.175 & 7.2 & 0.370 & 0.545 & **42.45**/15.1\% \\ \hline \multicolumn{10}{c}{**Convex QPs (ALL)**} \\ \hline OSQP & -33.183 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & - & - & - & - \\ IPOPT & -33.183 & 0.000 & 0.000 & 0.000 & 0.000 & 0.671 & 12.9 & - & - \\ IPM-LSTM & -32.600 & 0.000 & 0.000 & 0.003 & 0.001 & 0.195 & 8.3 & 0.426 & 0.621 & **35.7\%/7.5\%** \\ \hline \hline \end{tabular}
\end{table}
Table 1: Computational results on convex QPs.

larger objective values. Solutions identified by IPM-LSTM showed mild constraint violations but yielded superior objective values very close to the optimal values. Clearly, IPM-LSTM effectively balances feasibility and optimality in the returned solutions. This comes at the cost of longer runtime compared to the L2O baseline algorithms, as the baselines typically employ simple multi-layer perceptrons, whereas IPM-LSTM utilizes a neural network with several dozen LSTM cells.

Since IPM-LSTM is designed to provide interior point optimizers with high-quality initial points, we fed the returned primal-dual solution pair to IPOPT and reported the performance in Table 1. For comparison, we also provided IPOPT with initial points generated from other L2O algorithms. The columns labeled "Ite." and "Time (s)" under "IPOPT (warm-start)" indicate the number of iterations and solver time, respectively, while the column "Total Time (s)" represents the cumulative time for running both the L2O algorithms and IPOPT. The final column, "Gain (Ite/Time)", shows the reduction in iteration number and solution time, with the default IPOPT iteration number listed in the "Ite." column for reference. When initial solutions from IPM-LSTM and most L2O baseline algorithms (except DeepLDE) were used, IPOPT converged with fewer iterations and reduced solution time. Notably, IPM-LSTM achieved the most significant reduction in iterations, from \(12.5\) to \(7.2\), and decreased the average solver time from \(0.642\) seconds to \(0.37\) seconds. Including the computational time for IPM-LSTM, the total runtime was \(0.545\) seconds, reflecting a 15.1% reduction in time. It is worth noting that while IPM-LSTM did not yield the maximum solution time reduction, this was due to its relatively high computational expense.

To our knowledge, there is no existing representation learning approach for general convex QPs. Since the aforementioned L2O baseline algorithms depend on specific representations of QPs, they are not applicable to "Convex QPs (ALL)". Therefore, we only provide results for OSQP, IPOPT, and IPM-LSTM. We also report computational results averaged across \(833\) instances in the test set "Convex QPs (ALL)", presented in Table 1. The results demonstrate that IPM-LSTM can identify high-quality solutions for general convex QPs, and using these solutions as initial points can reduce iterations by \(35.7\%\) and solution time by \(7.5\%\).

**Convex QCQPs.** We now turn to convex QCQPs with both equaltity and inequality constraints:

\[\underset{x\in\mathbb{R}^{n}}{\text{min}} \frac{1}{2}x^{\top}Q_{0}x+p_{0}^{\top}x\] s.t. \[x^{\top}Q_{j}x+p_{j}^{\top}x\leq q_{j} j=1,\cdots,l\] \[p_{j}^{\top}x=q_{j} j=l+1,\cdots,m\] \[x_{i}^{L}\leq x_{i}\leq x_{i}^{U} i=1,\cdots,n\]

where \(Q_{j}\in\mathbb{S}_{+}^{n},p_{j}\in\mathbb{R}^{n}\), \(q_{j}\in\mathbb{R}\), \(x_{i}^{L}\in\mathbb{R}\cup\{-\infty\}\) and \(x_{i}^{U}\in\mathbb{R}\cup\{\infty\}\). Similar to our experiments on convex QPs, we also consider two groups of convex QCQPs, each with \(200\) variables, \(100\) inequality constraints, and \(100\) equality constraints. The first group (denoted as "Convex QCQPs (RHS)") is generated as described in Liang et al. (2023), with perturbations only to the right-hand sides of the equality constraints. The second group (denoted as "Convex QCQPs (ALL)") considers perturbations to all parameters. We also refer readers to Appendix D for computational experiments on smaller-sized convex QCQPs.

We omit OSQP and LOOP-LC since the former cannot handle QCQPs, while the latter is only applicable to linearly constrained problems. We evaluate IPM-LSTM and compare it against the remaining baseline algorithms. The computational results are reported in Table 2. Again, solutions produced by NN and PDL exhibit significant constraint violations, while those from DC3 and H-Proj are of high quality in terms of feasibility and optimality. Once more, the solutions produced by DeepLDE were deemed feasible but exhibited inferior objective values. Conversely, our approach, IPM-LSTM, produced solutions with superior objective values albeit with minor infeasibility. Compared to the baseline algorithms, utilizing solutions from IPM-LSTM to warm-start IPOPT resulted in the most substantial reduction in iterations.

As the aforementioned L2O baseline algorithms are not applicable to "Convex QCQPs (ALL)", we only report computational results for IPOPT and IPM-LSTM in Table 2. The IPM-LSTM approach produced high-quality approximate solutions to convex QCQPs, and warm-starting IPOPT with these solutions accelerated IPOPT by \(11.4\%\), with a \(33.1\%\) reduction in iterations.

**Non-convex QPs.** We now consider non-convex QPs of exactly the same form as (8) but with \(Q_{0}\) being indefinite. We take \(8\) representative non-convex QPs from the datasets Globallib and RandQP (Chen and Burer, 2012), each with up to \(50\) variables and \(20\) constraints, and perturb the relevant parameters for instance generation. Details can be found in Appendix D.2.

Among all the baselines, only IPOPT is applicable to these general non-convex QPs. Hence, we report computational results for IPOPT and IPM-LSTM in Table 3. IPOPT solved these instances to local optimality, while IPM-LSTM identified high-quality approximate solutions very efficiently. Using these primal-dual approximations to warm-start IPOPT resulted in an iteration reduction of up to \(63.9\%\) and a solution time reduction of up to \(70.5\%\).

**Simple non-convex programs.** Following the approach outlined in Donti et al. (2021), we consider a set of simple non-convex programs where the linear objective term in (8) is substituted with \(p_{0}^{\top}\sin(x)\). These instances were generated using the same methodology as Donti et al. (2021). We subject these problems to evaluation using both IPM-LSTM and baseline algorithms. Once again, the computational results underscore the high-quality solutions obtained by IPM-LSTM and its superior warm-starting capability. Detailed results are provided in Appendix D.4.

### Performance Analysis of IPM-LSTM

In Assumption 1, we posit that the linear systems (3) can be solved with an acceptable residual (Condition (5)) and that the solutions are properly bounded (Condition (6)). Although the LSTM network cannot guarantee the satisfaction of these conditions, we empirically assess the validity of Assumption 1 in IPM-LSTM. We plot the progress of \(\left\|J^{k}y^{k}+F^{k}\right\|\), \(\eta\left[(z^{k})^{\top}x^{k}\right]/n\), \(\left\|y^{k}\right\|\), and \(\left\|F_{0}(x^{k},\lambda^{k},z^{k})\right\|\) as the IPM iterations increase in Figure 3(a) and 3(b). Condition (5) is mostly satisfied except during the first few iterations, while Condition (6) is strictly satisfied across all IPM iterations. To assess the precision of the approximate solutions as the LSTM time steps increase, we plot the progress of the residual for linear systems (3) in Figure 3(c). At IPM iteration \(k\), the residual decreases monotonically towards \(0\) as the LSTM time steps increase, indicating that LSTM networks can produce high-quality approximate solutions to system (3). The approximation quality improves with the number of IPM iterations. As shown in Figure 3(d), the primal objective decreases monotonically towards the optimal value with increasing IPM iterations, empirically demonstrating the convergence of IPM-LSTM. Note that the condition number \(\kappa((J^{k})^{\top}J^{k})\) becomes quite large in the later IPM iterations, which can adversely affect the performance of LSTM networks in obtaining approximations to systems (3). Consequently, we terminate IPM-LSTM after a finite number of iterations. Further analysis regarding the number of IPM iterations and LSTM time steps is

\begin{table}
\begin{tabular}{c c c c c c c c c c c c} \hline \hline \multirow{2}{*}{Method} & \multicolumn{5}{c}{End-to-End} & \multicolumn{5}{c}{IPOPT (warm start)} & \multirow{2}{*}{Total} & \multirow{2}{*}{Gain} \\  & Obj. \(\downarrow\) & Max incq. \(\downarrow\) & Mean incq. \(\downarrow\) & Max eq. \(\downarrow\) & Mean eq. \(\downarrow\) & Time (s) \(\downarrow\) & Ihe. \(\downarrow\) & Time (s) \(\downarrow\) & Time (s) \\ \hline \multicolumn{11}{c}{**Convex QCQPs (RHS)**} \\ \hline IPOPT & -39.162 & 0.000 & 0.000 & 0.000 & 0.000 & 1.098 & 12.5 & - & - & - \\  & NM & -2.105 & 0.000 & 0.000 & 0.552 & 0.169 & +0.001 & 12.1 & 1.311 & 1.311 & 3.25/-19.4\% \\  & DC3 & -35.741 & 0.000 & 0.000 & 0.000 & 0.000 & 0.005 & 9.6 & 1.051 & 1.051 & 20.75/4.8\% \\  & DeepID & -15.132 & 0.000 & 0.000 & 0.000 & 0.000 & 0.000 & 11.5 & 1.222 & 1.22 & 8.90/-11.3\% \\  & PPL & -39.089 & 0.005 & 0.000 & 0.015 & 0.005 & +0.001 & 8.9 & 1.013 & 1.013 & 2.88 /-**9.75** \\  & H-Proj & -36.062 & 0.000 & 0.000 & 0.000 & 0.000 & +0.001 & 9.8 & 1.070 & 1.070 & 21.65/2.6\% \\  & IPM-LSTM & -38.540 & 0.000 & 0.000 & 0.004 & 0.001 & 0.205 & 8.0 & 0.825 & 1.030 & **36.05**/6.2\% \\ \hline \multicolumn{11}{c}{**Convex QCQPs (ALL)**} \\ \hline IPOPT & -39.868 & 0.000 & 0.000 & 0.000 & 0.000 & 0.801 & 12.4 & - & - & - \\  & IPM-LSTM & -38.405 & 0.004 & 0.000 & 0.001 & 0.000 & 0.203 & 8.3 & 0.507 & 0.710 & **33.15**/**11.4\%** \\ \hline \hline \end{tabular}
\end{table}
Table 2: Computational results on convex QCQPs.

\begin{table}
\begin{tabular}{c c c c|c c c c c c c} \hline \hline \multirow{2}{*}{Instance} & \multicolumn{2}{c}{IPOPT} & \multicolumn{2}{c}{IPM-LSTM} & \multicolumn{2}{c}{IPOPT (warm start)} & \multirow{2}{*}{Total} & \multirow{2}{*}{Gain} \\  & Obj. & Ihe. & Time (s) & Obj. & Max Vo. & Time (s) & Obj. & Ihe. & Time (s) & Time (s) & (Ihe./ Time) \\ \hline q1 & 0.001 & 52.0 & 0.707 & 0.045 & 0.008 & 0.017 & 0.001 & 42.0 & 0.559 & 0.576 & 19 27/18.5\% \\ qp2 & 0.001 & 69.0 & 0.674 & 0.034 & 0.008 & 0.029 & 0.001 & 40.0 & 0.347 & 0.376 & 42.05/4.2\% \\  & sJ\_v1 & -58.430 & 215.0 & 0.955 & -34.563 & 0.000 & 0.009 & -58.867 & 16.0 & 6.266 & 0.635 & 21.99/33.5\% \\  & sJ\_v2 & -67.083 & 190.8 & 0.956 & -30.955 & 0.000 & 0.011 & -67.083 & 120.5 & 0.482 & 0.494 & 36.86/38.1\% \\  & sJ\_v3 & 0.000 & 55.0 & 0.781 & 0.818 & 0.000 & 0.017 & 0.000 & 47.0 & 0.616 & 0.634 & 14.59/18.8\% \\  & sJ\_v7 & -132.019 & 449.0 & 2.445 & -61.428 & 0.000 & 0.016 & -131.756 & 162.0 & 0.705 & 0.721 & 63.99/70.5\% \\  & sJ\_v9 & -126.945 & 655.0 & 3.457 & -58.415 & 0.000 & 0.026 & -127.652 & 400.8 & 1.830 & 1.856 & 37.74/64.3\% \\  & qp30\_15\_1\_1 & 37.767 & 16.0 & 0.198 & 37.787 & 0.002 & 0.021 & 37.767 & 9.0 & 0.083 & 0.104 & 33.75/47.5\% \\ \hline \hline \end{tabular} Max Vo. denotes the maximum constraint violation.

\end{table}
Table 3: Computational results on non-convex QPs.

presented in Appendix D.5. Additionally, we include the performance of IPM-LSTM under various hyperparameter settings in Appendix D.5.

## 5 Limitations and Conclusions

In this paper, we present a learning-based IPM called IPM-LSTM. Specifically, we propose approximating solutions of linear systems in IPMs by solving least square problems using trained LSTM networks. We demonstrate that IPMs with this approximation procedure still converge. The solutions returned by IPM-LSTM are used to warm-start interior point optimizers. Our computational experiments on various types of NLPs, including general QPs and QCQPs, showcase the effectiveness of IPM-LSTM and its ability to accelerate IPOPT. Although IPM-LSTM generates high-quality primal-dual solutions, it is relatively computationally expensive due to the utilization of multi-cell LSTM networks. In future endeavors, we aim to investigate the efficacy of employing low-complexity neural networks to approximate solutions of linear systems within IPMs.

## Acknowledgments

This work was supported by the National Key R&D Program of China under grant 2022YFA1003900. Jinxin Xiong and Akang Wang also gratefully acknowledge support from the National Natural Science Foundation of China (Grant No. 12301416), the Shenzhen Science and Technology Program (Grant No. RCBS20221008093309021), the Guangdong Basic and Applied Basic Research Foundation (Grant No. 2024A1515010306) and Longgang District Special Funds for Science and Technology Innovation (LGKCDPT2023002).

## References

* Amestoy et al. (2000) Patrick R Amestoy, Iain S Duff, Jean-Yves L'Excellent, and Jacko Koster. Mumps: a general purpose distributed memory sparse solver. In _International Workshop on Applied Parallel Computing_, pages 121-130. Springer, 2000.
* Andrychowicz et al. (2016) Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, and Nando De Freitas. Learning to learn by gradient descent by gradient descent. _Advances in neural information processing systems_, 29, 2016.
* Baker (2019) Kyri Baker. Learning warm-start points for ac optimal power flow. In _2019 IEEE 29th International Workshop on Machine Learning for Signal Processing (MLSP)_, pages 1-6. IEEE, 2019.
* Bellavia (1998) Stefania Bellavia. Inexact interior-point method. _Journal of Optimization Theory and Applications_, 96:109-121, 1998.
* Bengio et al. (2021) Yoshua Bengio, Andrea Lodi, and Antoine Prouvost. Machine learning for combinatorial optimization: a methodological tour d'horizon. _European Journal of Operational Research_, 290(2):405-421, 2021.
* Chen and Burer (2012) Jieqiu Chen and Samuel Burer. Globally solving nonconvex quadratic programming problems via completely positive programming. _Mathematical Programming Computation_, 4(1):33-52, 2012.
* Chen et al. (2022a) Tianlong Chen, Xiaohan Chen, Wuyang Chen, Howard Heaton, Jialin Liu, Zhangyang Wang, and Wotao Yin. Learning to optimize: A primer and a benchmark. _Journal of Machine Learning Research_, 23(189):1-59, 2022a.

Figure 3: The performance analysis of IPM-LSTM on a convex QP (RHS).

Xiaohan Chen, Jialin Liu, and Wotao Yin. Learning to optimize: A tutorial for continuous and mixed-integer optimization. _Science China Mathematics_, pages 1-72, 2024.
* Chen et al. (2022b) Ziang Chen, Jialin Liu, Xinshang Wang, and Wotao Yin. On representing linear programs by graph neural networks. In _The Eleventh International Conference on Learning Representations_, 2022b.
* Chiang (2009) Mung Chiang. Nonconvex optimization for communication networks. _Advances in Applied Mathematics and Global Optimization: In Honor of Gilbert Strang_, pages 137-196, 2009.
* Conejo and Baringo (2018) Antonio J Conejo and Luis Baringo. _Power system operations_, volume 14. Springer, 2018.
* Dexter et al. (2022) Gregory Dexter, Agniva Chowdhury, Haim Avron, and Petros Drineas. On the convergence of inexact predictor-corrector methods for linear programming. In _International Conference on Machine Learning_, pages 5007-5038. PMLR, 2022.
* Diehl (2019) Frederik Diehl. Warm-starting ac optimal power flow with graph neural networks. In _33rd Conference on Neural Information Processing Systems (NeurIPS 2019)_, pages 1-6, 2019.
* Donti et al. (2021) Priya L Donti, David Rolnick, and J Zico Kolter. Dc3: A learning method for optimization with hard constraints. In _International Conference on Learning Representations_, 2021.
* Eisenstat and Walker (1994) Stanley C Eisenstat and Homer F Walker. Globally convergent inexact newton methods. _SIAM Journal on Optimization_, 4(2):393-422, 1994.
* Fioretto et al. (2020) Ferdinando Fioretto, Terrence WK Mak, and Pascal Van Hentenryck. Predicting ac optimal power flows: Combining deep learning and lagrangian dual methods. In _Proceedings of the AAAI conference on artificial intelligence_, volume 34, pages 630-637, 2020.
* Forsgren (2006) Anders Forsgren. On warm starts for interior methods. In _System Modeling and Optimization: Proceedings of the 22nd IFIP TC7 Conference held from July 18-22, 2005, in Turin, Italy 22_, pages 51-66. Springer, 2006.
* Gasse et al. (2022) Maxime Gasse, Simon Bowly, Quentin Cappart, Jonas Chaffreitag, Laurent Charlin, Didier Chetelat, Antonia Chmiela, Justin Dumouchelle, Ambros Gleixner, Aleksandr M Kazachkov, et al. The machine learning for combinatorial optimization competition (ml4co): Results and insights. In _NeurIPS 2021 competitions and demonstrations track_, pages 220-231. PMLR, 2022.
* Gregor and LeCun (2010) Karol Gregor and Yann LeCun. Learning fast approximations of sparse coding. In _Proceedings of the 27th international conference on international conference on machine learning_, pages 399-406, 2010.
* Greif et al. (2014) Chen Greif, Erin Moulding, and Dominique Orban. Bounds on eigenvalues of matrices arising from interior-point methods. _SIAM Journal on Optimization_, 24(1):49-83, 2014.
* Han et al. (2024) Jiayu Han, Wei Wang, Chao Yang, Mengyang Niu, Cheng Yang, Lei Yan, and Zuyi Li. FRMNet: A Feasibility Restoration Mapping Deep Neural Network for AC Optimal Power Flow. _IEEE Transactions on Power Systems_, pages 1-11, 2024. ISSN 0885-8950, 1558-0679. doi: 10.1109/TPWRS.2024.3354733. URL https://ieeexplore.ieee.org/document/10411984/.
* Han et al. (2023) Qingyu Han, Linxin Yang, Qian Chen, Xiang Zhou, Dong Zhang, Akang Wang, Ruoyu Sun, and Xiaodong Luo. A gnn-guided predict-and-search framework for mixed-integer linear programming. In _The Eleventh International Conference on Learning Representations_, 2023.
* Huang et al. (2021) Wanjun Huang, Xiang Pan, Minghua Chen, and Steven H Low. Deepopf-v: Solving ac-opf problems efficiently. _IEEE Transactions on Power Systems_, 37(1):800-803, 2021.
* Kim et al. (2023) Hongseok Kim et al. Self-supervised equality embedded deep lagrange dual for approximate constrained optimization. _arXiv preprint arXiv:2306.06674_, 2023.
* Kingma (2014) DP Kingma. Adam: a method for stochastic optimization. In _Int Conf Learn Represent_, 2014.
* Li et al. (2024) Bingheng Li, Linxin Yang, Yupeng Chen, Semmiao Wang, Qian Chen, Haitao Mao, Yao Ma, Akang Wang, Tian Ding, Jiliang Tang, et al. Pdhg-unrolled learning-to-optimize method for large-scale linear programming. In _Forty-first International Conference on Machine Learning_, 2024.
* Li et al. (2023) Meiyi Li, Soheil Kolouri, and Javad Mohammadi. Learning to solve optimization problems with hard linear constraints. _IEEE Access_, 2023.
* Liang et al. (2023) Enming Liang, Minghua Chen, and Steven Low. Low complexity homeomorphic projection to ensure neural-network solution feasibility for optimization over (non-) convex set. In _Conference on Parsimony and Learning (Recent Spotlight Track)_, 2023.
* Liu et al. (2020)Jialin Liu, Xiaohan Chen, Zhangyang Wang, Wotao Yin, and HanQin Cai. Towards constituting mathematical structures for learning to optimize. In _International Conference on Machine Learning_, pages 21426-21449. PMLR, 2023.
* Liu et al. (2024) Tianhao Liu, Shanwen Pu, Dongdong Ge, and Yinyu Ye. Learning to pivot as a smart expert. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 38, pages 8073-8081, 2024.
* Lv et al. (2017) Kaifeng Lv, Shunhua Jiang, and Jian Li. Learning gradient descent: Better generalization and longer horizons. In _International Conference on Machine Learning_, pages 2247-2255. PMLR, 2017.
* Nesterov and Nemirovskii (1994) Yurii Nesterov and Arkadii Nemirovskii. _Interior-point polynomial algorithms in convex programming_. SIAM, 1994.
* Nocedal and Wright (1999) Jorge Nocedal and Stephen J Wright. _Numerical optimization_. Springer, 1999.
* Pan et al. (2023) Xiang Pan, Minghua Chen, Tianyu Zhao, and Steven H. Low. Deepopf: A feasibility-optimized deep neural network approach for ac optimal power flow problems. _IEEE Systems Journal_, 17(1):673-683, 2023. doi: 10.1109/JSYST.2022.3201041.
* Park and Van Hentenryck (2023) Seonho Park and Pascal Van Hentenryck. Self-supervised primal-dual learning for constrained optimization. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 37, pages 4052-4060, 2023.
* Qian et al. (2024) Chendi Qian, Didier Chetelat, and Christopher Morris. Exploring the power of graph neural networks in solving linear optimization problems. In _International Conference on Artificial Intelligence and Statistics_, pages 1432-1440. PMLR, 2024.
* Ruiz (2001) Daniel Ruiz. A scaling algorithm to equilibrate both rows and columns norms in matrices. Technical report, CM-P0004015, 2001.
* Schaal and Atkeson (2010) Stefan Schaal and Christopher G Atkeson. Learning control in robotics. _IEEE Robotics & Automation Magazine_, 17(2):20-29, 2010.
* Stellato et al. (2020) B. Stellato, G. Banjac, P. Goulart, A. Bemporad, and S. Boyd. OSQP: an operator splitting solver for quadratic programs. _Mathematical Programming Computation_, 12(4):637-672, 2020. doi: 10.1007/s12532-020-00179-2. URL https://doi.org/10.1007/s12532-020-00179-2.
* Wachter and Biegler (2006) Andreas Wachter and Lorenz T Biegler. On the implementation of an interior-point filter line-search algorithm for large-scale nonlinear programming. _Mathematical programming_, 106:25-57, 2006.
* Yu et al. (2019) Yong Yu, Xiaosheng Si, Changhua Hu, and Jianxun Zhang. A review of recurrent neural networks: Lstm cells and network architectures. _Neural computation_, 31(7):1235-1270, 2019.
* Zeng et al. (2024) Sihan Zeng, Youngdae Kim, Yuxuan Ren, and Kibaek Kim. QCQP-Net: Reliably Learning Feasible Alternating Current Optimal Power Flow Solutions Under Constraints, January 2024. URL http://arxiv.org/abs/2401.06820. arXiv:2401.06820 [cs, math] version: 1.
* Zhang and Zhang (2022) Ling Zhang and Baosen Zhang. Learning to solve the ac optimal power flow via a lagrangian approach. In _2022 North American Power Symposium (NAPS)_, pages 1-6, 2022. doi: 10.1109/NAPS56150.2022.10012237.

## Appendix A Implementation Details

The general NLP considered in this paper can be formulated as:

\[\begin{array}{ll}\min_{x\in\mathbb{R}^{n}}&f(x),\\ \text{s.t.}&g(x)+s=0\\ h(x)=0\\ &s\geq 0\\ &x_{i}\geq x_{i}^{L},\hskip 28.452756pti\in I^{L}\\ &x_{i}\leq x_{i}^{L},\hskip 28.452756pti\in I^{U}\end{array}\] (9)

where \(f:\mathbb{R}^{n}\rightarrow\mathbb{R}\), \(g:\mathbb{R}^{n}\rightarrow\mathbb{R}^{m_{\text{\tiny{inst}}}}\), and \(h:\mathbb{R}^{n}\rightarrow\mathbb{R}^{m_{\text{\tiny{sq}}}}\) are twice continuously differentiable functions; \(s\in\mathbb{R}^{m_{\text{\tiny{inst}}}}\) is the slack variable corresponding to the inequality constraints; \(I^{L}=\{i:x_{i}^{L}\neq-\infty\}\) and \(I^{U}=\{i:x_{i}^{U}\neq\infty\}\). The Lagrangian function is defined as:

\[L\left(x,\eta,\lambda,s,z^{L},z^{U}\right):=f(x)+\eta^{\top}g(x)+\lambda^{\top }h(x)-\sum_{i\in I^{U}}z_{i}^{L}\left(x_{i}-x_{i}^{L}\right)-\sum_{i\in I^{U} }z_{i}^{U}\left(x_{i}^{U}-x_{i}\right)\] (10)

where \(\eta\in\mathbb{R}^{m_{\text{\tiny{inst}}}}\) and \(\lambda\in\mathbb{R}^{m_{\text{\tiny{sq}}}}\) are the corresponding dual variables. The perturbed KKT conditions are given by:

\[\left\{\begin{array}{l}\nabla f(x)+\eta^{\top}\nabla g(x)+\lambda^{\top} \nabla h(x)-z^{L}+z^{U}=0\\ g(x)+s=0\\ \text{diag}(\eta)\text{diag}(s)e=\mu e\\ \eta\geq 0,s\geq 0,h(x)=0\\ z_{i}^{L}(x_{i}-x_{i}^{L})=\mu,i\in I^{L}\\ z_{i}^{U}(x_{i}^{U}-x_{i})=\mu,i\in I^{U}\\ z_{i}^{L}\geq 0,i\in I^{L},z_{i}^{U}\geq 0,i\in I^{U}\\ x_{i}\geq x_{i}^{L},i\in I^{L},x_{j}\leq x_{j}^{U},j\in I^{U}\end{array}\right.\] (11)

The nonlinear system extracted from the KKT conditions is represented as:

\[F(x,\eta,\lambda,s,z^{L},z^{U})=0\] (12)

where

\[F(x,\eta,\lambda,s,z^{L},z^{U})=\left(\begin{array}{cccc}\nabla f(x)+\eta^ {\top}\nabla g(x)+\lambda^{\top}\nabla h(x)-z^{L}+z^{U}\\ g(x)+s\\ \text{diag}(\eta)\text{diag}(s)e-\mu e\\ h(x)\text{diag}(z^{L})\text{diag}(x-x^{L})e-\mu e\\ \text{diag}(z^{U})\text{diag}(x^{U}-x)e-\mu e\end{array}\right)=0\]

The Jacobian matrix of \(F(x,\eta,\lambda,s,z^{L},z^{U})\) is:

\[J(x,\eta,\lambda,s,z^{L},z^{U}):=\left(\begin{array}{cccccc}\nabla^{2L}(x, \eta,\lambda,s,z^{L},z^{U}),&\nabla g(x)^{\top},&\nabla h(x)^{\top},&0,&-I,&I\\ \nabla g(x),&0,&0,&I,&0,&0\\ 0,&\text{diag}(s),&0,&\text{diag}(\eta),&0,&0\\ \text{diag}(z^{L}),&0,&0,&0,&\text{diag}(x-x^{L}),&0\\ -\text{diag}(z^{U}),&0,&0,&0,&\text{diag}(x^{U}-x)\end{array}\right)\]

where

\[\nabla^{2}L\left(x,\eta,\lambda,s,z^{L},z^{U}\right)=\nabla^{2}f(x)+\sum_{i=1 }^{m_{\text{\tiny{inst}}}}\eta_{i}\nabla^{2}g_{i}(x)+\sum_{j=1}^{m_{\text{ \tiny{eq}}}}\lambda_{j}\nabla^{2}h_{j}(x)\] (13)

For convenience, we define the updates of primal and dual variables as:

\[y:=\left(\begin{array}{c}\Delta x\\ \Delta\eta\\ \Delta\lambda\\ \Delta s\\ \Delta z^{L}\\ \Delta z^{U}\end{array}\right).\] (14)Then the linear system obtained from one-step Newton's method is shown as:

\[J\left(x,\eta,\lambda,s,z^{L},z^{U}\right)y=-F\left(x,\eta,\lambda,s,z^{L},z^{U}\right)\] (15)

**Initial points.** If dual variables \(\eta\), \(s\), \(z^{L}\), and \(z^{U}\) exist, their initial values are set to 1. If the dual variable \(\lambda\) exists, its initial value is set to 0. The initial value of the primal variable \(x\) can be formulated as:

\[x_{i}=\left\{\begin{array}{ll}z_{i}^{L}+1,&i\in I^{L}\backslash I^{U}\\ z_{i}^{U}-1,&i\in I^{U}\backslash I^{L}\\ (z_{i}^{L}+z_{i}^{U})/2,&i\in I^{L}\cap I^{U}\\ 0,&\text{otherwise.}\end{array}\right..\] (16)

**The step length.** If the dual variables \(\eta\), \(s\), \(z^{L}\) and \(z^{U}\) exist, their step lengths are chosen as follows:

\[\alpha^{\eta}:=\sup\left\{\alpha\in(0,1]\mid\eta_{i}+\alpha\Delta\eta_{i}\geq 0,i=1,\cdots,m_{\text{ineq}}\right\}\] (17)

\[\alpha^{s}:=\sup\left\{\alpha\in(0,1]\mid s_{i}+\alpha\Delta s_{i}\geq 0,i=1,\cdots,m_{\text{ineq}}\right\}\] (18)

\[\alpha^{z^{L}}:=\sup\left\{\alpha\in(0,1]\mid z_{i}^{L}+\alpha\Delta z_{i}^{L} \geq 0,i\in I^{L}\right\}\] (19)

\[\alpha^{z^{U}}:=\sup\left\{\alpha\in(0,1]\mid z_{i}^{U}+\alpha\Delta z_{i}^{U }\geq 0,i\in I^{U}\right\}\] (20)

If \(x\) is bounded, the step sizes for \(x\) and \(\lambda\) are chosen to be equal as:

\[\alpha^{\lambda},\alpha^{x}:=\sup\left\{\alpha\in(0,1]\mid x_{i}+\alpha\Delta x _{i}\geq x_{i}^{L},i\in I^{L};x_{i}+\alpha\Delta x_{i}\leq x_{i}^{U},i\in I^{U}\right\}\] (21)

If \(x\) is unbounded but inequality constraints exist, the step lengths for \(x\) and \(\lambda\) are chosen the same as the step length for \(s\). If \(x\) is unbounded and there are no inequality constraints, the step lengths for \(x\) and \(\lambda\) are chosen to be 1. In our experiments, additional line search procedures for step lengths, as described in Bellavia (1998), were not implemented in order to save computational time.

## Appendix B Proof of Proposition 1

Proof.: **Step 1.** Let \(\delta>0\), suppose that \((x^{k},\lambda^{k},z^{k})\in N_{\delta}(x^{*},\lambda^{*},z^{*}):=\{(x, \lambda,z)\mid\|(x,\lambda,z)-(x^{*},\lambda^{*},z^{*})\|<\delta\}\). Define \(\sigma:=\min\{\sigma^{k}\}\) and \(\eta:=\min\{\eta^{k}\}\), where \(\sigma^{k}\) and \(\eta^{k}\) are chosen to satisfy the update rule (11) in Bellavia (1998). Then from the Assumption 1:

\[\|y^{k}\|\leq(1+\sigma^{k}+\eta^{k})\|F_{0}(x^{k},\lambda^{k},z^{k})\|.\] (22)

By using the steplength \(\alpha^{k}\) obtained from the line search method of Bellavia (1998) and defining:

\[\hat{\eta}^{k}=1-\alpha^{k}\left(1-\sigma^{k}-\eta^{k}\right)\] (23)

we obtain:

\[\begin{array}{lll}\|p^{k}\|&=&\|\alpha^{k}y^{k}\|\\ &=&\|\frac{(1-\hat{\eta}^{k})\alpha^{k}y^{k}}{1-\alpha^{k}(1-\sigma^{k}-\eta^ {k}))}\|\\ &=&\frac{1-\hat{\eta}^{k}}{1-\sigma^{k}-\eta^{k}}\|y^{k}\|\\ &\leq&(1-\hat{\eta}^{k})\frac{1+\sigma^{k}+\eta^{k}}{1-\sigma^{k}-\eta^{k}}\| F_{0}(x^{k},\lambda^{k},z^{k})\|\\ &\leq&(1-\hat{\eta}^{k})\Gamma\|F_{0}(x^{k},\lambda^{k},z^{k})\|\end{array}\] (24)

where \(\Gamma=\frac{1+\eta_{\text{max}}}{1-\eta_{\text{max}}}\), \((\sigma^{k}+\eta^{k})\in(0,\eta_{\text{max}})\) and \(\eta_{\text{max}}\in(0,1)\). Then, there exists a constant \(\Gamma\) independent of \(k\) such that (24) holds, whenever \(y^{k}\) is bounded by \((1+\sigma^{k}+\eta^{k})\|F_{0}(x^{k},\lambda^{k},z^{k})\|\). Hence, from Theorem 3.5 of Eisenstat and Walker (1994), it follows that \((x^{k},\lambda^{k},z^{k})\rightarrow(x^{*},\lambda^{*},z^{*})\).

**Step 2.** In this step, we aim to prove that the step size \(\alpha^{k}\) of the inexact IPM is bounded away from 0. Given that Assumption 1 is satisfied, it follows that \(\|J^{k}y^{k}+F^{k}\|\) and \(\|y^{k}\|\) are both bounded. Then we assume the first two equations of \(F_{0}(x,\lambda,z)\) are Lipschitz continuous gradient with constant \(L\). The remaining proofs are consistent with Theorem 3.2 in Bellavia (1998).

**Step 3.** The line search method of Bellavia (1998) enables \(\alpha^{k}\) to satisfy:

\[\|F_{0}(x^{k+1},\lambda^{k+1},z^{k+1})\|\leq(1-\beta(1-\hat{\eta}^{k}))\|F_{0} (x^{k},\lambda^{k},z^{k})\|\] (25)where \(\beta\in(0,1)\). Therefore \(\{\|F_{0}(x^{k},\lambda^{k},z^{k})\|\}\) is decreasing and bounded, hence, it is convergent. Based on Assumption 1, (24) holds. Furthermore, we assume \(\|F_{0}(x^{k},\lambda^{k},z^{k})\|\neq 0\) and \(\delta\) is chosen sufficiently small so that

\[\begin{split}\|F_{0}(x_{2},\lambda_{2},z_{2})&-F_{0 }(x_{1},\lambda_{1},z_{1})-J(x_{1},\lambda_{1},z_{1})[(x_{2}-x_{1})^{\top},( \lambda_{2}-\lambda_{1})^{\top},(z_{2}-z_{1})^{\top}]^{\top}\|\\ &\leq((1-\beta)/\Gamma)\|[(x_{2}-x_{1})^{\top},(\lambda_{2}- \lambda_{1})^{\top},(z_{2}-z_{1})^{\top}]^{\top}\|\end{split}\] (26)

is satisfied, whenever \((x_{1},\lambda_{1},z_{1}),(x_{2},\lambda_{2},z_{2})\in N_{2\delta}(x^{*}, \lambda^{*},z^{*})\). Define

\[S:=\sup_{(x,\lambda,z)\in N_{\delta}(x^{*},\lambda^{*},z^{*})}\|F_{0}(x, \lambda,z)\|,\] (27)

then based on Lemma 5.1 of Eisenstat and Walker (1994), the loop of backtracking line search of Bellavia (1998) will terminate with

\[1-\hat{\eta}^{k}\geq\text{min}(\alpha^{k}(1-\sigma^{k}-\eta^{k}),\theta\delta/ (\Gamma S))\] (28)

where \(\theta\in(0,1)\) is a control parameter. This implies that the series \(\sum\limits_{k=0}^{\infty}(1-\hat{\eta}^{k})\) is divergent. By applying (25) iteratively, we have

\[\begin{split}\|F_{0}(x^{k},\lambda^{k},z^{k})\|& \leq(1-\beta(1-\hat{\eta}^{k-1}))\|F_{0}(x^{k-1},\lambda^{k-1},z^{ k-1})\|\\ &\leq\|F_{0}(x^{0},\lambda^{0},z^{0})\|\prod_{0\leq j<k}(1-\beta (1-\hat{\eta}^{j}))\\ &\leq\|F_{0}(x^{0},\lambda^{0},z^{0})\|\text{exp}(-\beta\sum \limits_{0\leq j<k}(1-\hat{\eta}^{j})).\end{split}\] (29)

Since \(\beta>0\) and \(1-\hat{\eta}^{j}\geq 0\), the divergence of series \(\sum\limits_{j=0}^{\infty}(1-\hat{\eta}^{j})\) implies \(\|F_{0}(x^{k},\lambda^{k},z^{k})\|\to 0\). 

## Appendix C Datasets and Parameter setting

The key hyperparameters for each task, including \(K\), \(T\), and the hidden dimension of LSTM networks, are listed in Table 4. Generally, IPM-LSTM demonstrates improved performance with larger values of \(K\) and \(T\), although this comes at the cost of increased computational time. Increasing \(T\) could enhance the quality of solutions to the linear system. In this study, \(K\) is maintained at the same value for both training and testing. Further analysis can be found in Appendix D.5.

\begin{table}
\begin{tabular}{c c c c c c|c c c} \hline \hline \multirow{2}{*}{Instance} & \multicolumn{4}{c}{Information} & \multicolumn{4}{c}{Hyperparameters} \\ \cline{2-9}  & Source & \(n\) & \(m_{\text{inteq}}\) & \(m_{\text{zq}}\) & \(|I^{L}|\) & \(|I^{U}|\) & \(K\) & \(T\) & Hidden dimension \\ \hline \multirow{3}{*}{Convex QPs (RHS)} & & 100 & 50 & 50 & 0 & 0 & 100 & 50 & 50 \\  & & 200 & 100 & 100 & 0 & 0 & 100 & 50 & 75 \\  & & 100 & 50 & 50 & 0 & 0 & 100 & 50 & 50 \\  & & 200 & 100 & 100 & 0 & 0 & 100 & 50 & 100 \\ \multirow{3}{*}{Convex QCQPs (RHS)} & & 100 & 50 & 50 & 0 & 0 & 100 & 50 & 50 \\  & & 200 & 100 & 100 & 0 & 0 & 100 & 50 & 100 \\ \multirow{3}{*}{Convex QCQPs (ALL)} & & 100 & 50 & 50 & 0 & 0 & 100 & 50 & 50 \\  & & 200 & 100 & 100 & 0 & 0 & 100 & 50 & 100 \\ \multirow{3}{*}{Non-convex Programs (RHS)} & & 100 & 50 & 50 & 0 & 0 & 100 & 50 & 50 \\  & & 200 & 100 & 100 & 0 & 0 & 100 & 50 & 75 \\ \multirow{3}{*}{Non-convex Programs (ALL)} & & 100 & 50 & 50 & 0 & 0 & 100 & 50 & 50 \\  & & 200 & 100 & 100 & 0 & 0 & 100 & 50 & 100 \\ \hline \multirow{3}{*}{qp1} & & 50 & 1 & 1 & 50 & 0 & 100 & 50 & 30 \\  & & 50 & 1 & 1 & 50 & 0 & 100 & 50 & 30 \\ \multirow{3}{*}{st\_rv1} & & 10 & 5 & 0 & 10 & 0 & 100 & 50 & 50 \\  & & 20 & 10 & 0 & 20 & 0 & 100 & 50 & 50 \\ \multirow{3}{*}{st\_rv3} & & 50 & 1 & 0 & 50 & 0 & 100 & 50 & 50 \\  & & 30 & 20 & 0 & 30 & 0 & 100 & 50 & 50 \\ \multirow{3}{*}{st\_rv7} & & 50 & 20 & 0 & 50 & 0 & 100 & 50 & 50 \\ \cline{1-1} \cline{2-9}  & & 50 & 20 & 0 & 50 & 0 & 100 & 50 & 50 \\ \hline \multirow{3}{*}{qp30\_15\_1} & \multirow{3}{*}{Rand\_QP} & 30 & 15 & 6 & 30 & 30 & 100 & 50 & 50 \\ \cline{1-1} \cline{2-9}  & & & & & & & & & \\ \hline \hline \end{tabular}
\end{table}
Table 4: Instance information and hyperparameter settings.

Experimental Results

### Convex QPs

The performance on convex QPs, including "Convex QPs (RHS)" and "Convex QPs (ALL)", each instance with 100 variables, 50 inequality constraints, and 50 equality constraints, is shown in Table 5. From Table 5, IPM-LSTM provided the best objective value with acceptable constraint violations.

Also, IPM-LSTM achieved the most significant reduction in iterations when the returned primal-dual solution pair is utilized for warm-starting IPOPT.

### Non-convex QPs

For non-convex QPs (8), all the non-zero elements without any special physical meaning, such as all zeros or all ones, are multiplied by a value generated from a uniform distribution in the range \([0.8,1.2]\). If the original elements are integers, we will perform an additional rounding operation. We use "p" and "r" to represent these operations, respectively, and use "c" to denote the case without perturbation. The detailed perturbation rules for each instance are shown as:

### Convex QCQPs

The performance on convex QPs, including "Convex QCQPs (RHS)" and "Convex QCQPs (ALL)", each instance with 100 variables, 50 inequality constraints, and 50 equality constraints, is shown in Table 7. From Table 7, IPM-LSTM provided the best objective value with acceptable constraint violations. Also, IPM-LSTM achieved the most significant reduction in iterations when the returned primal-dual solution pair is utilized for warm-starting IPOPT.

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \hline Instance & \(Q_{0}\) & \(p_{0}\) & \(p_{\text{ineq}}\) & \(q_{\text{ineq}}\) & \(p_{\text{eq}}\) & \(q_{\text{eq}}\) & \(x^{L}\) & \(x^{U}\) \\ \hline qp1 & p & c & p & p & c & c & c & - \\ qp2 & p & c & p & p & c & c & c & - \\ st\_rv1 & p & p & r & r & - & - & c & - \\ st\_rv2 & p & p & r & r & - & - & c & - \\ st\_rv3 & p & p & r & r & - & - & c & - \\ st\_rv7 & p & p & r & r & - & - & c & - \\ st\_rv9 & p & p & r & r & - & - & c & - \\ qp30\_15\_1\_1 & p & p & p & p & p & p & c & c \\ \hline \hline \end{tabular}
\end{table}
Table 6: Perturbation rules.

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline \hline \multirow{2}{*}{Method} & \multicolumn{5}{c}{End-to-End} & \multicolumn{5}{c}{IPOPT (warm start)} & \multirow{2}{*}{Total} & \multirow{2}{*}{Cain} \\ \cline{2-2} \cline{6-10}  & Obj \(\downarrow\) & Max ineq. \(\downarrow\) & Mean ineq. \(\downarrow\) & Max eq. \(\downarrow\) & Mean eq. \(\downarrow\) & Time (s) \(\downarrow\) & \multicolumn{1}{c}{Ie. \(\downarrow\)} & Time (s) \(\downarrow\) & Time (s) \(\downarrow\) & \multicolumn{1}{c}{Time (s) \(\uparrow\)} \\ \hline \multicolumn{10}{c}{**Convex QPs (RHS)**} \\ \hline OSOP & -15.047 & 0.000 & 0.000 & 0.000 & 0.000 & 0.002 & - & - & - & - \\ IPOPT & -15.047 & 0.000 & 0.000 & 0.000 & 0.000 & 0.269 & 12.2 & - & - \\ DGS & -13.460 & 0.000 & 0.000 & 0.000 & 0.000 & -0.001 & 10.5 & 0.227 & 0.227 & 13.96/15.6\% \\ NN & -12.570 & 0.000 & 0.000 & 0.350 & 0.130 & 0.001 & 10.7 & 0.234 & 0.234 & 12.38/13.0\% \\ DeepLL & 46.316 & 0.000 & 0.000 & 0.007 & 0.000 & -0.001 & 12.9 & 0.294 & 0.294 & 5.75/9.9\% \\ PPL & -14.969 & 0.011 & 0.003 & 0.002 & 0.000 & -0.001 & 9.5 & 0.199 & 0.199 & 21.91/26.0\% \\ LOOP-LC & -13.628 & 0.000 & 0.000 & 0.000 & 0.000 & -0.001 & 11.2 & 0.246 & 0.246 & 8.25/8.6\% \\ IPM-LSTM & -11.788 & 0.000 & 0.000 & 0.000 & 0.000 & -0.001 & 10.7 & 0.233 & 0.233 & 12.36/13.4\% \\ IPM-LSTM & -14.985 & 0.000 & 0.000 & 0.001 & 0.000 & 0.045 & 6.5 & 0.115 & 0.160 & **46.7***0.5*** \\ \hline \multicolumn{10}{c}{**Convex QPs (ALL)**} \\ \hline OSOP & -16.670 & 0.000 & 0.000 & 0.000 & 0.000 & 0.002 & - & - & - & - \\ IPOPT & -16.670 & 0.000 & 0.000 & 0.000 & 0.029 & 12.4 & 0.000 & 0.279 & - \\ IPM-LSTM & -16.116 & 0.000 & 0.000 & 0.003 & 0.001 & 0.044 & 8.5 & 0.157 & 0.201 & **31.25***28.0*** \\ \hline \hline \end{tabular}
\end{table}
Table 5: Computational results on convex QPs

### A Simple Non-convex Program

\[\begin{split}\underset{x\in\mathbb{R}^{n}}{\text{min}}& \frac{1}{2}x^{\top}Q_{0}x+p_{0}^{\top}\sin(x)\\ \text{s.t.}& p_{j}^{\top}x\leq q_{j}& j=1,\cdots,l\\ & p_{j}^{\top}x=q_{j}& j=l+1,\cdots,m\\ & x_{i}^{L}\leq x_{i}\leq x_{i}^{U}& i=1,\cdots,n\end{split}\] (30)

The performance on simple non-convex programs (30), including "Non-convex Programs (RHS)" and "Non-convex Programs (ALL)", each instance with 100/200 variables, 50/100 inequality constraints, and 50/100 equality constraints, is shown in Table 8. From this table, IPM-LSTM provided the best objective value with acceptable constraint violations. Also, IPM-LSTM achieved the most significant reduction in iterations when the returned primal-dual solution pair is utilized for warm-starting IPOPT.

### Performance Analysis

#### d.5.1 The Number of LSTM Time Steps

The number of LSTM time steps \(T\) is a key hyperparameter which decides the performance-efficiency trade-off of IPM-LSTM. To illustrate this, we conduct experiments on a convex QP (RHS) problem

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline \hline \multirow{2}{*}{Method} & \multicolumn{5}{c}{End-to-End} & \multicolumn{3}{c}{IPOPT (warm start)} & Total & Gain \\ \cline{2-10}  & Obj \(\downarrow\) & Max ineq. \(\downarrow\) & Mean ineq. \(\downarrow\) & Max eq. \(\downarrow\) & Mean eq. \(\downarrow\) & Time (s) \(\downarrow\) & Ie. \(\downarrow\) & Time (s) \(\downarrow\) & Time (s) \(\downarrow\) \\ \hline \multicolumn{10}{c}{**convex QCQPs (RHS)**} \\ \hline IPOPT & -18.761 & 0.000 & 0.000 & 0.000 & 0.000 & 0.287 & 12.3 & - & - & - \\ NN & -1.931 & 0.000 & 0.000 & 0.439 & 0.141 & \(<\)0.001 & 12.2 & 0.285 & 0.285 & 0.98\%/0.7\% \\ DC3 & -14.111 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 10.6 & 0.244 & 0.244 & 13.8\%/15.8\% \\ Deep1e & -10.331 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 11.2 & 0.282 & 0.282 & 8.9\%/1.7\% \\ PPL & -15.311 & 0.006 & 0.000 & 0.000 & 0.002 & \(<\)0.001 & 10.1 & 0.227 & 0.227 & 17.9\%/0.2\% \\ H-Proj & -15.450 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 10.8 & 0.247 & 0.247 & 12.2\%/13.9\% \\ IPM-LSTM & -18.654 & 0.000 & 0.000 & 0.000 & 0.000 & 0.051 & 7.6 & 0.163 & 0.213 & **38.2\%/25.8\%** \\ \hline \multicolumn{10}{c}{**convex QCQPs (ALL)**} \\ \hline IPOPT & -21.849 & 0.000 & 0.000 & 0.000 & 0.000 & 0.253 & 11.8 & - & - & - \\ IPM-LSTM & -21.200 & 0.000 & 0.000 & 0.001 & 0.001 & 0.049 & 7.4 & 0.124 & 0.173 & **37.3\%/31.6\%** \\ \hline \hline \end{tabular}
\end{table}
Table 7: Computational results on convex QCQPs

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline \hline \multirow{2}{*}{Method} & \multicolumn{5}{c}{End-to-End} & \multicolumn{5}{c}{IPOPT (warm start)} & Total & Gain \\ \cline{2-10}  & Obj \(\downarrow\) & Max ineq. \(\downarrow\) & Mean ineq. \(\downarrow\) & Max eq. \(\downarrow\) & Mean eq. \(\downarrow\) & Time (s) \(\downarrow\) & Ie. \(\downarrow\) & Time (s) \(\downarrow\) & Time (s)\(\downarrow\) & Time (s)\(\downarrow\) \\ \hline \multicolumn{10}{c}{**Non-convex Programs (RHS)**: \(n=200,m_{\text{max}}=100,m_{\text{max}}=100\)} \\ \hline IPOPT & -22.375 & 0.000 & 0.000 & 0.000 & 0.000 & 0.717 & 13.1 & - & - & - \\ DC3 & -20.671 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 10.9 & 0.603 & 0.603 & 16.8\%/15.9\% \\ NN & -20.736 & 0.000 & 0.000 & 0.032 & 0.235 & \(<\)0.001 & 11.0 & 0.607 & 0.607 & 16.0\%/20.7\% \\ Deep1e & -20.074 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 10.5 & 0.576 & 0.576 & 19.8\%/19.7\% \\ PPL & -21.859 & 0.589 & 0.167 & 0.026 & 0.000 & \(<\)0.001 & 10.9 & 0.600 & 0.600 & 16.8\%/16.3\% \\ LOOP-LC & -21.932 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 10.2 & 0.558 & 0.558 & 22.1\%/22.2\% \\ IPM-Proj & -19.097 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 11.5 & 0.634 & 0.634 & 12.2\%/11.6\% \\ IPM-LSTM & -22.213 & 0.000 & 0.000 & 0.002 & 0.001 & 0.175 & 9.5 & 0.533 & 0.708 & **27.5\%/1.3\%** \\ \hline \multicolumn{10}{c}{**Non-convex Programs (ALL)**: \(n=200,m_{\text{max}}=100,m_{\text{max}}=100\)} \\ \hline IPOPT & -25.1043 & 0.000 & 0.000 & 0.000 & 0.000 & 0.768 & 14.3 & - & - & - \\ IPM-LSTM & -20.288 & 0.000 & 0.000 & 0.000 & 0.002 & 0.195 & 12.1 & 0.639 & 0.834 & **15.4\%/8.6\%** \\ \hline \multicolumn{10}{c}{**Non-convex Programs (HHS)**: \(n=100,m_{\text{max}}=50,m_{\text{max}}=50\)} \\ \hline IPOPT & -11.590 & 0.000 & 0.000 & 0.000 & 0.000 & 0.289 & 12.9 & - & - & - \\ DC3 & -10.660 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 11.6 & 0.259 & 0.259 & 11.6\%/10.4\% \\ NN & -10.020 & 0.000 & 0.000 & 0.350 & 0.130 & \(<\)0.001 & 11.4 & 0.253 & 0.253 & 11.6\%/12.5\% \\ Deeplle & -4.870 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 13.1 & 0.24 & 0.294 & 0.294 & -1.6\%/1.7\% \\ PPL & -11.138 & 0.006 & 0.002 & 0.001 & 0.000 & \(<\)0.001 & 9.6 & 0.207 & 0.207 & 25.6\%/**28.4\%** \\ LOOP-LC & -11.296 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 10.1 & 0.217 & 0.217 & 21.7\%/24.9\% \\ H-Proj & -9.616 & 0.000 & 0.000 & 0.000 & 0.000 & \(<\)0.001 & 11.3 & 0.252 & 0.

with 100 variables, 50 inequality constraints, and 50 equality constraints, investigating the quality of approximate solutions under different LSTM time step settings. As shown in Table 9, the IPM-LSTM with deeper LSTM architectures generally yields better approximate solutions (with lower objective values, smaller constraint violation and better warm-start performance) but with longer computational time. Specifically, the IPM-LSTM with 60 and 70 time steps achieves most significant reductions in warm-starting iteration count and total runtime, respectively. However, taking into account the end-to-end solution time, we have opted to set \(T\) to 50 in our experiments. At each IPM iteration, as the LSTM network depth increases, \(\|J^{k}y^{k}+F^{k}\|\) decreases (see Figure 5(a)). This indicates an improvement in the quality of solutions to the linear systems. Furthermore, the corresponding IPM-LSTM converges faster (e.g., fewer IPM iterations) when the LSTM network becomes deeper (see Figure 4).

#### d.5.2 Linear System Solutions

In order to provide an more specific presentation of how accurately the LSTM performs, we report the detailed values of Figure 3(a) in Table 10. We can conclude that, \(\|J^{k}y^{k}+F^{k}\|\) is roughly in the same order of magnitude as \(\eta[(z^{k})^{\top}x^{k}]/n\) at each IPM iteration. To reveal the relationship between the error of the linear system solution \(\|J^{k}y^{k}+F^{k}\|\) and the LSTM time steps, hidden dimensions, training sizes and test sizes, we conduct experiments on representative convex QP (RHS) problems with 100 variables, 50 inequality constraints, and 50 equality constraints, and the results are included in Figure 5.

* In Figure 5(a), with the number of LSTM time steps increasing, \(\|J^{k}y^{k}+F^{k}\|\) decreases.
* In Figure 5(b), we consider LSTMs with 25, 50, 75, and 100 hidden dimensions and find that an LSTM with a hidden dimension of 50, as used in our manuscript, generally performs the best (e.g., the smallest \(\|J^{k}y^{k}+F^{k}\|\)).
* In Figure 5(c), a larger training set is more beneficial for model training. The training set size in our experiment is 8,334, and the error in solving the linear system \(\|J^{k}y^{k}+F^{k}\|\) is smaller compared with the case of 4,000 or 6,000 training samples.

Figure 4: The objective values returned by IPM-LSTM at each IPM iteration on a convex QP (RHS).

\begin{table}
\begin{tabular}{c c c c c c c|c c c} \hline \hline \(T\) & \multicolumn{6}{c}{End-to-End} & \multicolumn{3}{c}{IPOPT (warm start)} & \multicolumn{1}{c}{Total} & Gain \\ \cline{2-10}  & Obj. \(\downarrow\) & Max ineq. \(\downarrow\) & Mean ineq. \(\downarrow\) & Max eq. \(\downarrow\) & Mean eq. \(\downarrow\) & Time (s) \(\downarrow\) & Ike. \(\downarrow\) & Time (s) \(\downarrow\) & Time (s)\(\downarrow\) & (Ike./ Time) \(\uparrow\) \\ \hline
10 & -12.740 & 0.000 & 0.000 & 0.006 & 0.002 & 0.014 & 9.7 & 0.203 & 0.217 & 20.55/19.3\% \\
20 & -14.615 & 0.000 & 0.000 & 0.003 & 0.001 & 0.021 & 8.5 & 0.171 & 0.192 & 30.37/82.6\% \\
30 & -14.753 & 0.000 & 0.000 & 0.002 & 0.001 & 0.029 & 8.0 & 0.155 & 0.184 & 34.45/31.6\% \\
40 & -14.897 & 0.000 & 0.000 & 0.003 & 0.001 & 0.037 & 7.1 & 0.130 & 0.167 & 41.85/37.9\% \\
50 & -14.985 & 0.000 & 0.000 & 0.001 & 0.000 & 0.045 & 6.5 & 0.115 & 0.160 & 46.74/0.5\% \\
60 & -15.021 & 0.000 & 0.000 & 0.001 & 0.000 & 0.055 & 6.1 & 0.099 & 0.154 & 50.05/**42.7\%** \\
70 & -15.026 & 0.000 & 0.000 & 0.000 & 0.000 & 0.064 & 6.0 & 0.100 & 0.164 & **50.85**/39.0\% \\
80 & -15.012 & 0.000 & 0.000 & 0.000 & 0.000 & 0.073 & 6.2 & 0.106 & 0.179 & 49.25/33.4\% \\
90 & -14.960 & 0.000 & 0.000 & 0.000 & 0.000 & 0.081 & 6.6 & 0.117 & 0.198 & 45.99/26.4\% \\ \hline \hline \end{tabular}
\end{table}
Table 9: Computational results on convex QPs (RHS) under different LSTM time steps.

* As shown by Figure 5(d), the number of samples in the test set does not affect the performance of LSTM for solving linear systems.

We take the log of the y-axis in Figure 3(a) and plot it in Figure 6(a). Roughly speaking, \(\|J^{k}y^{k}+F^{k}\|\) is smaller than \(\eta[(z^{k})^{\top}x^{k}]/n\) in the first 40 IPM iterations, while \(\|J^{k}y^{k}+F^{k}\|\) surpasses \(\eta[(z^{k})^{\top}x^{k}]/n\) in the later IPM iterations. We increase the number of LSTM time steps and report the computational results in Figure 6(b). From Figure 6, we can claim that with the number of LSTM time steps increasing, \(\|J^{k}y^{k}+F^{k}\|\) becomes smaller.

#### d.5.3 Condition Numbers

The LSTM approach for solving linear systems is negatively affected by their large condition numbers. To demonstrate this, we consider the least squares problem

\[\min_{y\in\mathbb{R}^{l}}\phi(y):=\frac{1}{2}\left\|J^{k}y+F^{k}\right\|^{2}\] (31)

\begin{table}
\begin{tabular}{c c c} \hline \hline IPM Ite. & \(\|J^{k}y^{k}+F^{k}\|\) & \(\eta[(z^{k})^{\top}x^{k}]/n\) \\ \hline
1 & 2.396 & 0.900 \\
10 & 0.154 & 0.255 \\
20 & 0.104 & 0.124 \\
30 & 0.073 & 0.073 \\
40 & 0.052 & 0.047 \\
50 & 0.040 & 0.031 \\
60 & 0.032 & 0.021 \\
70 & 0.027 & 0.013 \\
80 & 0.024 & 0.008 \\
90 & 0.022 & 0.006 \\
100 & 0.020 & 0.005 \\ \hline \hline \end{tabular}
\end{table}
Table 10: The detailed values of Figure 3(a).

Figure 5: The relationship between the error of the linear system solution with different parameter settings of LSTM.

Figure 6: Equation (5) under different LSTM time steps. The first number in the parentheses denotes the number of IPM iterations, while the second one represents the number of LSTM time steps.

We utilize a first-order method (e.g., steepest descent method) to minimize \(\phi(y)\) and achieve a linear convergence rate (Nocedal and Wright, 1999), i.e.,

\[\phi\left(y^{t+1}\right)-\phi\left(y^{\star}\right)\leq\left(1-\frac{2}{\left( \kappa\left(J^{k}\right)\right)^{2}+1}\right)^{2}\left(\phi\left(y^{t}\right)- \phi\left(y^{\star}\right)\right)\] (32)

As we discussed in Section 3.3, since solving linear systems via LSTM networks emulates iterative first-order methods, thus the value of \(\kappa\left(J^{k}\right)\) affects the performance of LSTM networks. However, LSTM networks can empirically achieve a faster convergence rate than traditional first-order algorithms when solving the same least squares problems as shown in the computational studies (Section 3.1) of Andrychowicz et al. (2016). In order to alleviate the effect of large condition numbers, as discussed in Section 3.3, we have employed preconditioning techniques. To illustrate its effect, we conduct experiments on the simple non-convex programs, and report \(\kappa\left(J^{k}\right)\) and their values after preconditioning (in parantheses) across several IPM iterations (e.g., \(1^{st}\), \(10^{th}\), \(20^{th}\), \(50^{th}\), \(100^{th}\)) in Table 11. We can conclude that the condition numbers \(\kappa\left(J^{k}\right)\) remain within reasonable magnitudes even during the later IPM iterations, and are significantly reduced after applying the preconditioning technique.

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline Instance & \(1^{st}\) & \(10^{th}\) & \(20^{th}\) & \(50^{th}\) & \(100^{th}\) \\ \hline Non-convex Programs (RHS) (100, 50, 50) & 53.8 (59.8) & 126.2 (580.7) & 153.1 (711.2) & 208.7 (1004.8) & 348.4 (1860.1) \\ Non-convex Programs (ALL) (100, 50, 50) & 55.4 (59.8) & 113.6 (5170) & 139.8 (658.5) & 214.0 (1190.9) & 329.2 (1859.9) \\ Non-convex Programs (RHS) (200, 100, 100) & 91.5 (99.8) & 157.1 (1114.0) & 205.8 (1441.1) & 326.2 (2398.3) & 488.3 (3667.8) \\ Non-convex Programs (ALL) (200, 100, 100) & 72.1(75.7) & 175.4 (1143.4) & 184.5 (1352.7) & 249.5 (2016.6) & 368.4 (3015.3) \\ \hline \hline \end{tabular}
\end{table}
Table 11: The condition numbers of simple non-convex programs in IPM iteration process.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Please refer to Abstract and Section 1. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Please refer to Section 5. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: Please refer to Section 3.2 and Appendix B. 1. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? 1. Answer: [Yes] Justification: Please refer to Section 3. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: Please refer to Section 4.1 for data. Our code will be available to public once our work is accepted, as mentioned in Section 1. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Please refer to Section 4.1 and Appendix C. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Please refer to Section 4.2. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors).

* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: Please refer to Section 4.1. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research presented in this paper adheres to the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Our paper does not present any such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: Please refer to Section 4.1. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: Our paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: Our paper does not involve any crowdsourcing or research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Our paper does not involve any crowdsourcing or research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.