# Putnam-AXIOM: A Functional and Static Benchmark for Measuring Higher Level Mathematical Reasoning

 Aryan Gulati

Department of Computer Science

Stanford University

aryangul@stanford.edu &Brando Miranda

Department of Computer Science

Stanford University

brando9@stanford.edu Eric Chen

Department of Mathematics

Stanford University

ericcc97@stanford.edu &Emily Xia

Department of Mathematics

Stanford University

emxia18@stanford.edu &Kai Fronsdal

Department of Computer Science

Stanford University

kaif@stanford.edu &Bruno de Moraes Dumont

Department of Mathematics

Stanford University

bdumont@stanford.edu &Sanmi Koyejo

Department of Computer Science

Stanford University

sanmi@stanford.edu

###### Abstract

As large language models (LLMs) continue to advance, many existing benchmarks designed to evaluate their reasoning capabilities are becoming saturated. Therefore, we present the Putnam-AXIOM Original benchmark consisting of 236 mathematical problems from the William Lowell Putnam Mathematical Competition, along with detailed step-by-step solutions. To preserve the Putnam-AXIOM benchmark's validity and mitigate potential data contamination, we created the Putnam-AXIOM Variation benchmark with functional variations of 52 problems. By programmatically altering problem elements like variables and constants, we can generate unlimited novel, equally challenging problems not found online. We see that almost all models have significantly lower accuracy in the variations than the original problems. Our results reveal that OpenAI's 01-preview, the best performing model, achieves merely 41.95% accuracy on the Putnam-AXIOM Original but experiences around a 30% reduction in accuracy on the variations' dataset when compared to corresponding original problems. The data and the evaluation code are available at https://anonymous.4open.science/r/putnam-axiom-B57C/.

## 1 Introduction

The ability for Large Language Models (LLMs) to reason about complex problems has a plethora of applications in many fields such as economics (Zhang et al., 2024), drug discovery (Bran et al., 2023), and even simulations of human behavior and society (Park et al., 2023). The prominence of this ability has led to significant development in the performance of LLMs on many reasoning benchmarks.

**Outpacing Current Evaluations.** Indeed, advanced models like GPT-4 (OpenAI, 2023) and Gemini Ultra (Team, 2023) have even surpassed human-level performance on many benchmarks like MMLU (Hendrycks et al., 2020) and MMMU (Yue et al., 2023). Similarly, LLMs have seen astonishing

[MISSING_PAGE_FAIL:2]

simply parsing the LLM generated string solution for the value within the box, thereby enhancing reliability and consistency of the evaluation process while being quick and cost-effective. To further ensure fair evaluation, we implemented an equivalence function that homogenizes similar answers, addressing both simple string inconsistencies and complex mathematical equivalences like \((x+1)^{2}\) and \(x^{2}+2x+1\) or numerical expressions such as \(\langle\texttt{frac}\texttt{1}\rangle\texttt{2}\), \(\texttt{1}\texttt{/2}\), and \(\texttt{0}\texttt{.5}\) and equating them.

**Modified Boxing.** Given the complex nature of certain Putnam questions, some problems do not lend themselves to simple, singular boxed answers. Instead, they often include conditions, multiple possible answers, varied answer formats and elaborate proofs. These original questions would have necessitated costly and difficult human evaluations which we seek to avoid. To address this, we modified these questions by adding a trivial next step to the original questions, changing the solution accordingly. This additional step was designed so as to ensure that solvers reached the same conclusions and insights necessary to solve the problem, but then needed to perform a simpler computation to get a simplified, boxable answer. We provide an example of such a change in Figure 3. By incorporating this minor modification, we preserved the inherent difficulty and complexity of the original problems while making the answers suitable for our boxed answer evaluation criteria.

### Putnam-AXIOM Variation Dataset

Models trained on snapshots of the internet have likely encountered Putnam questions, potentially inflating their performance on the Putnam-AXIOM Original dataset. Therefore, drawing inspiration from Srivastava et al. (2024), we introduce functional variations of select problems from Putnam-AXIOM Original providing an effective way of evaluating models that have been trained on the entire internet by taking advantage of weaknesses in model memorization. These variations are classified into two types.

1. **Variable Change.** The simplest variation is a variable change, where variable names are altered and the final answer is unvaried. Variable changes slightly modify the problem from its original statement, which models could have trained on.
2. **Constant Change.** Constant changes modify numeric properties of the question, altering constants within the step-by-step solution and the final answer. Constant changes significantly transform the problem from its original statement, challenging models to perform complex reasoning on how the changes affect the solution and final answer, as in the example from Figure 4.

**Variational Dataset Description.** We created functional variations for 52 Putnam-AXIOM questions, considering limitations such as problem-specific constants, non-generalizable solutions, and questions lacking constants or boxable answers. The dataset includes 26 constant+variable and 26 variable-only changes. We rephrased problem statements while maintaining the core task to prevent pattern recognition by LLMs. Each variation can generate infinite unique, equally difficult snapshots, offering a sustainable evaluation method. To evaluate various SOTA models, evaluators are expected to generate snapshots (instances of the infinite potential variations) of the variation dataset by running the generation code.

### Model Evaluations

Using the LM Harness Evaluation framework (Gao et al., 2024), we evaluated several open-source and proprietary SOTA LLMs. Models were prompted to provide answers in \(\backslash\)boxed format, which were then compared to Putnam ground truths with an exact final answer match. We evaluated the 236-question Putnam-AXIOM Original dataset once. For the variation dataset, we conducted five trials, each using a randomly selected variation snapshot and its corresponding 52 original questions. We then calculated mean accuracy and 95% confidence intervals.

## 3 Results and Analysis

### Putnam-AXIOM Model Performance

Table 1 presents Putnam-AXIOM Original dataset accuracies. Most models score below 10%, with even NuminaMath, the AI Mathematics Olympiad winner (Investments, 2024), achieving only 4.66%.

[MISSING_PAGE_FAIL:4]

### LLM Error Analysis

Though we used automated evaluations for efficiency, a manual review of model responses on Putnam-AXIOM Original provides deeper insights into models' reasoning and errors. We selected the two best-performing models, GPT-4o and OpenAI o1-preview, as they likely exhibit the strongest reasoning abilities. Our goal is to analyze this reasoning in greater depth.

**OpenAI o1-preview Performance:** Out of all models, we see that OpenAI o1-preview performed the best on Putnam-AXIOM Original, receiving \(41.9\%\) boxed accuracy (\(99/236\)) while other models received less than \(20\%\). Analyzing the answers, we see that most of the OpenAI o1-preview responses followed generally the same logical path as the ground truth solution. However, several of these questions contained logical mistakes and inconsistencies. The biggest discrepancy between model responses and the ground-truth solution was a general lack of mathematical rigor. Whereas the ground truth solution will make claims to advance its solution then prove those claims step-by-step, o1-preview will often make and use claims without justification. While this does succeed in getting to the correct boxed final answer, these unjustified claims would receive little credit when marked by a human grader. A large part of the difficulty of mathematical reasoning is being logically airtight throughout the entire solution; thus, though o1-preview shows promise, there are still evident flaws in its mathematical reasoning abilities. In several solutions like Figure 7, for instance, o1-preview correctly identified the maximal or minimal value of a variable, but failed to provide sufficient proof that the value it provided was indeed the maximum or minimum.

**GPT-4o Performance:** Like the o1-preview, GPT-4o mostly followed correct logical reasoning for most of its solutions. For GPT-4o, the biggest discrepancy between model responses and the ground-truth solution is the same general lack of mathematical rigor throughout most of the solutions. An example of this lack of rigor is shown in Figure 8, where GPT-4o makes the claim that a rectangle gives the minimal area subject to a set of constraints without any justification. In addition to issues with rigor, GPT-4o also displayed logical leaps and incoherent reasoning, as displayed in Figure 9 where the model simply assumes that an answer is correct. These logical leaps are symptomatic of an issue in the GPT-4o's CoT reasoning, as the model prioritizes reaching the final answer rather providing a rigorous logical output.

**General Analysis:** Beyond GPT-4o and the o1-preview, we wanted a general overview of the reasoning behaviors of models. To do so, we chose the best-performing open-source models, DeepSeek-Math-7B-RL, Qwen2-Math-7B, and NuminaMath-7B. We tend to see that open-source models are much more error-prone than the proprietary models we evaluated earlier. In general, we notice that open-source models are subject to the same lack of mathematical rigor. However, this rigor issue is overshadowed by major calculation errors, hallucinated/irrelevant information, misunderstandings of the problem, and logical jumps. For instance, in Figure 10, NuminaMath simultaneously makes a calculation, irrelevancy, and misunderstanding error when writing the last step of its solution; in Figure 11, the model makes false assumptions about functions defined in the problem; in Figure 12, the model completely removes a crucial part of the problem and proceeds to an incorrect final solution.

## 4 Conclusion

In this paper, we present Putnam-AXIOM, a novel challenging benchmark of \(236\) problems from the Putnam examination for evaluating reasoning capabilities of large language models. Our dataset allows for automated evaluations with an equivalence function. While SOTA LLMs already have saturated performance on benchmarks like MATH, they still struggle with successfully answering questions in Putnam-AXIOM. To address potential data contamination issues, we introduce Putnam-AXIOM Variations, altering the variable names, constant values, or the phrasing of the question to create a potentially infinite number of problems not found anywhere on the internet. We notice that for most problems, models get significantly worse on the variations than they do the corresponding original questions. Our dataset fills the void opened by rapid progress in model reasoning capabilities. We hope that our benchmark will accelerate future research into artificial reasoning.

## References

* Zhang et al. [2024] Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Adrian de Wynter, Yan Xia, Wenshan Wu, Ting Song, Man Lan, and Furu Wei. Llm as a mastermind: A survey of strategic reasoning with large language models, 2024. URL https://arxiv.org/abs/2404.01230.
* Bran et al. [2023] Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, and Philippe Schwaller. Chemcrow: Augmenting large-language models with chemistry tools, 2023. URL https://arxiv.org/abs/2304.05376.
* Park et al. [2023] Joon Sung Park, Joseph C. O'Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. Generative agents: Interactive simulacra of human behavior, 2023. URL https://arxiv.org/abs/2304.03442.
* OpenAI [2023] OpenAI. Gpt-4 technical report. _Preprint_, 2023.
* Team [2023] Gemini Team. Gemini: A family of highly capable multimodal models. _arXiv preprint arXiv: 2312.11805_, 2023.
* Hendrycks et al. [2020] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, D. Song, and J. Steinhardt. Measuring massive multitask language understanding. _International Conference on Learning Representations_, 2020.
* Yue et al. [2022] Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. Mmmu: A massive multi-discipline multimodal understanding and reasoning benchmark for expert agi. _arXiv preprint arXiv: 2311.16502_, 2023.
* Chen et al. [2022] Zhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang Ma, Sameena Shah, and William Yang Wang. Convfinqa: Exploring the chain of numerical reasoning in conversational finance question answering. _arXiv preprint arXiv: 2210.03849_, 2022.
* Hendrycks et al. [2021] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. In J. Vanschoren and S. Yeung, editors, _Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks_, volume 1. Curran, 2021. URL https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/be83ab3ecd0db773eb2dc1b0a17836a1-Paper-round2.pdf.
* Lei [2024] Bin Lei. Macm: Utilizing a multi-agent system for condition mining in solving complex mathematical problems, 2024. URL https://arxiv.org/abs/2404.04735.
* Zhong et al. [2021] Qihuang Zhong, Kang Wang, Ziyang Xu, Juhua Liu, Liang Ding, Bo Du, and Dacheng Tao. Achieving >97 URL https://arxiv.org/abs/2404.14963.
* Srivastava et al. [2024] Saurabh Srivastava, Annarose M B, Anto P V, Shashank Menon, Ajay Sukumar, Adwaith Samod T, Alan Philipose, Stevin Prince, and Sooraj Thomas. Functional benchmarks for robust evaluation of reasoning performance, and the reasoning gap. _arXiv preprint arXiv: 2402.19450_, 2024.
* Gao et al. [2024] Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le Noac'h, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou. A framework for few-shot language model evaluation, 07 2024. URL https://zenodo.org/records/12608602.
* progress prize 1, 2024. URL https://kaggle.com/competitions/ai-mathematical-olympiad-prize.
* United states copyright act. _U.S. Code Title 17_, 1976. Available at https://www.copyright.gov/title17/.

Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems. _arXiv preprint arXiv: 2110.14168_, 2021.
* Sawada et al. [2023] Tomohiro Sawada, Daniel Paleka, Alexander Havrilla, Pranav Tadepalli, Paula Vidas, Alexander Kranias, John J. Nay, Kshitij Gupta, and Aran Komatsuzaki. Arb: Advanced reasoning benchmark for large language models, 2023. URL https://arxiv.org/abs/2307.13692.
* He et al. [2024] Chaoqun He, Renjie Luo, Yuzhuo Bai, Shengding Hu, Zhen Leng Thai, Junhao Shen, Jinyi Hu, Xu Han, Yujie Huang, Yuxiang Zhang, Jie Liu, Lei Qi, Zhiyuan Liu, and Maosong Sun. Olympiad-bench: A challenging benchmark for promoting agi with olympiad-level bilingual multimodal scientific problems. _arXiv preprint arXiv: 2402.14008_, 2024.
* Wang et al. [2023] Xiaoxuan Wang, Ziniu Hu, Pan Lu, Yanqiao Zhu, Jieyu Zhang, Satyen Subramaniam, Arjun R. Loomba, Shichang Zhang, Yizhou Sun, and Wei Wang. Scibench: Evaluating college-level scientific problem-solving abilities of large language models. _arXiv preprint arXiv: 2307.10635_, 2023.
* Tsoukalas et al. [2024] George Tsoukalas, Jasper Lee, John Jennings, Jimmy Xin, Michelle Ding, Michael Jennings, Amitayush Thakur, and Swarat Chaudhuri. Putnambench: Evaluating neural theorem-provers on the putnam mathematical competition, 2024. URL https://arxiv.org/abs/2407.11214.
* Schaeffer [2023] Rylan Schaeffer. Pretraining on the test set is all you need, 2023. URL https://arxiv.org/abs/2309.08632.
* Sainz et al. [2023] Oscar Sainz, Jon Ander Campos, Iker Garcia-Ferrero, Julen Etxaniz, Oier Lopez de Lacalle, and Eneko Agirre. Nlp evaluation in trouble: On the need to measure llm data contamination for each benchmark, 2023. URL https://arxiv.org/abs/2310.18018.
* Zhong et al. [2023] Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, and Nan Duan. Agieval: A human-centric benchmark for evaluating foundation models, 2023. URL https://arxiv.org/abs/2304.06364.
* Magar and Schwartz [2022] Inbal Magar and Roy Schwartz. Data contamination: From memorization to exploitation. _Annual Meeting of the Association for Computational Linguistics_, 2022. doi: 10.48550/arXiv.2203.08242.
* Ranaldi et al. [2023] Leonardo Ranaldi, Elena Sofia Ruzzetti, and Fabio Massimo Zanzotto. PreCog: Exploring the relation between memorization and performance in pre-trained language models. In Ruslan Mitkov and Galia Angelova, editors, _Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing_, pages 961-967, Varna, Bulgaria, September 2023. INCOMA Ltd., Shoumen, Bulgaria. URL https://aclanthology.org/2023.ranlp-1.103.

## Appendix A Appendix / supplemental material

### Legal Compliance

We collect and modify various problems from the William Lowell Putnam Competition to create the original and variation datasets of Putnam-AXIOM. Putnam problems are created by the Mathematical Association of America (MAA), which is also the source of the AMC and AIME problems used in the MATH dataset (Hendrycks et al., 2021). Like Hendrycks et al. (2021), we do not in any form seek to monetize or commercialize Putnam problems--only to utilize them for academic purposes.

Our use of the Putnam problems to create an evaluation dataset completely falls under the "research" section of Fair Use. Indeed, according to Section 107, of the U.S. Copyright Act (USC, 1976), our work certainly qualifies as Fair Use for the following reasons:

1. Our use of MAA problems is _only_ for academic research purposes. We do not monetize or commercialize the problems.
2. Our use of Putnam problems as a reasoning evaluation benchmark for large language models is significantly different from their original use as competition problems.

3. Our use of Putnam problems is transformative. As detailed in Section 2 above, we have transformed the questions to be answered with a single numerical or algebraic "boxed answer" We have altered all of the solutions so that the final boxed answer lies at the end of the solution (so as to encourage models to explain their rationale before outputting a solution). We have also standardized the solutions: If there are many solutions given, we only use the first; if there are any references irrelevant to mathematics necessary to understand and solve the problem (such as comments like "Communicated by..."), we have removed those.
4. Our use of Putnam problems to construct a benchmark has no effect on the demand for or supply of Putnam problems in the William Lowell Putnam Competition. The existence of our dataset does not alter the value of the original problems--as those are already freely available online--nor does it influence the market of future competitors/problem writers.

**Problem:** Let \(F_{m}\) be the \(m\)th Fibonacci number, defined by \(F_{1}=F_{2}=1\) and \(F_{m}=F_{m-1}+F_{m-2}\) for all \(m\geq 3\). Let \(p(x)\) be the polynomial of degree \(1008\) such that \(p(2n+1)=F_{2n+1}\) for \(n=0,1,2,\ldots,1008\). Find integers \(j\) and \(k\) such that \(p(2019)=F_{j}-F_{k}\) and give the answer in the form \(j/k\).

**Solution:** More generally, let \(p(x)\) be the polynomial of degree \(N\) such that \(p(2n+1)=F_{2n+1}\) for \(0\leq n\leq N\). We will show that \(p(2N+3)=F_{2N+3}-F_{N+2}\).

Define a sequence of polynomials \(p_{0}(x),\ldots,p_{N}(x)\) by \(p_{0}(x)=p(x)\) and \(p_{k}(x)=p_{k-1}(x)-p_{k-1}(x+2)\) for \(k\geq 1\). Then by induction on \(k\), it is the case that \(p_{k}(2n+1)=F_{2n+1+k}\) for \(0\leq n\leq N-k\), and also that \(p_{k}\) has degree (at most) \(N-k\) for \(k\geq 1\). Thus \(p_{N}(x)=F_{N+1}\) since \(p_{N}(1)=F_{N+1}\) and \(p_{N}\) is constant.

We now claim that for \(0\leq k\leq N\), \(p_{N-k}(2k+3)=\sum_{j=0}^{k}F_{N+1+j}\). We prove this again by induction on \(k\): for the induction step, we have

\[p_{N-k}(2k+3) =p_{N-k}(2k+1)+p_{N-k+1}(2k+1)\] \[=F_{N+1+k}+\sum_{j=0}^{k-1}F_{N+1+j}.\]

Thus we have

\[p(2N+3)=p_{0}(2N+3)=\sum_{j=0}^{N}F_{N+1+j}.\]

Now one final induction shows that \(\sum_{j=1}^{m}F_{j}=F_{m+2}-1\), and so \(p(2N+3)=F_{2N+3}-F_{N+2}\), as claimed. In the case \(N=1008\), we thus have \(p(2019)=F_{2019}-F_{1010}\). We thus prove that \((j,k)=(2019,1010)\) is a valid solution with the final answer thus being \(\boxed{2019/1010}\).

**Year: 2017 ID: A6 Final Answer: \(2019/1010\)**

Figure 2: An example problem in Putnam-AXIOM. Solving this problem requires non-trivial constructions and multiple advanced reasoning chains. The format of the final answer is specified in the problem statement to make comparison simpler.

**Problem:** Determine which positive integers \(n\) have the following property: For all integers \(m\) that are relatively prime to \(n\), there exists a permutation \(\pi\colon\{1,2,\ldots,n\}\to\{1,2,\ldots,n\}\) such that \(\pi(\pi(k))\equiv mk\pmod{n}\) for all \(k\in\{1,2,\ldots,n\}\).

**Solution:** The desired property holds if and only if \(n=1\text{ or }n\equiv 2\pmod{4}\). Let \(\sigma_{n,m}\) be the permutation of \(\mathbb{Z}/n\mathbb{Z}\) induced by multiplication by \(m\); the original problem asks for which \(n\) does \(\sigma_{n,m}\) always have a square root.

\(\ldots\)

By Lemma 1, \(\sigma_{n,m}\) does not have a square root.

**Problem:** Determine the sum of the first \(k\) positive integers \(n\) (in terms of \(k\)) which have the following property: For all integers \(m\) that are relatively prime to \(n\), there exists a permutation \(\pi\colon\{1,2,\ldots,n\}\to\{1,2,\ldots,n\}\) such that \(\pi(\pi(k))\equiv mk\pmod{n}\) for all \(k\in\{1,2,\ldots,n\}\).

**Solution:** Let \(\sigma_{n,m}\) be the permutation of \(\mathbb{Z}/n\mathbb{Z}\) induced by multiplication by \(m\); the original problem asks for which \(n\) does \(\sigma_{n,m}\) always have a square root.

\(\ldots\)

The desired property holds if and only if \(n=1\text{ or }n\equiv 2\pmod{4}\), hence making the required sum \(\left\lceil\frac{2k^{2}-4k+3}{2k^{2}-4k+3}\right\rceil\).

**Year:** 2016 **ID:** A1 **Final Answer: \(2k^{2}-4k+3\)**

**Problem:** Define a _growing spiral_ in the plane to be a sequence of points with integer coordinates \(P_{0}=(0,0),P_{1},\ldots,P_{n}\) such that \(n\geq 2\) and: \(\ldots\)

How many of the points \((x,y)\) with integer coordinates \(0\leq x\leq 2011,0\leq y\leq 2011\)_cannot_ be the last point, \(P_{n}\) of any growing spiral?

**Solution:** We claim that the set of points with \(0\leq x\leq 2011\) and \(0\leq y\leq 2011\) that cannot be the last point of a growing spiral are as follows: \((0,y)\) for \(0\leq y\leq 2011\); \((x,0)\) and \((x,1)\) for \(1\leq x\leq 2011\); \((x,2)\) for \(2\leq x\leq 2011\); and \((x,3)\) for \(3\leq x\leq 2011\).

\(\ldots\)

This gives a total of

\[2012+2011+2011\] \[+2010+2009=\boxed{10053}\]

excluded points.

**Year: 2011 ID: A1 Final Answer: \(10053\) Year: 2011 ID: A1 Final Answer: \(23398\)**

**Problem:** Define the greatest possible value of \(\sum_{i=1}^{10}\cos(3x_{i})\) for real numbers \(x_{1},x_{2},\ldots,x_{10}\) satisfying \(\sum_{i=1}^{10}\cos(x_{i})=0\).

**Solution:** Since \(\cos(3x_{i})=4\cos(x_{i})^{3}-3\cos(x_{i})\), it is equivalent to maximize \(4\sum_{i=1}^{10}y_{i}^{3}\) for \(y_{1},\ldots,y_{10}\in[-1,1]\) with \(\sum_{i=1}^{10}y_{i}=0\); note that this domain is compact, so the maximum value is guaranteed to exist.

\(\ldots\)

The maximum value is \(\boxed{480/49}\)

**Year: 2018 ID: A3 Final Answer: \(480/49\)**

**Problem:** Define a _growing spiral_ in the plane to be a sequence of points with integer coordinates \(L_{0}=(0,0),L_{1},\ldots,L_{n}\) such that \(n\geq 2\) and: \(\ldots\)

How many of the points \((w,v)\) with integer coordinates \(0\leq w\leq 4680,0\leq v\leq 4680\)_cannot_ be the last point, \(L_{n}\) of any growing spiral?

**Solution:** We claim that the set of points with \(0\leq w\leq 4680\) and \(0\leq v\leq 4680\) that cannot be the last point of a growing spiral are as follows: \((0,v)\) for \(0\leq v\leq 4680\); \((w,0)\) and \((w,1)\) for \(1\leq w\leq 4680\); \((w,2)\) for \(2\leq w\leq 4680\); and \((w,3)\) for \(3\leq w\leq 4680\).

\(\ldots\)

This gives a total of

\[4681+4680+4680\] \[+4679+4678=\boxed{23398}\]

excluded points.

**Year: 2011 ID: A1 Final Answer: \(10053\) Year: 2011 ID: A1 Final Answer: \(23398\)**

**Problem:** Determine the greatest possible value of \(\sum_{i=1}^{10}\cos(3x_{i})\) for real numbers \(x_{1},x_{2},\ldots,x_{10}\) satisfying \(\sum_{i=1}^{10}\cos(x_{i})=0\).

**Solution:** Since \(\sin(3c_{i})=3\sin(c_{i})-4\sin(c_{i})^{3}\), it is equivalent to minimize \(4\sum_{i=1}^{10}y_{i}^{3}\) for \(y_{1},\ldots,y_{10}\in[-1,1]\) with \(\sum

### Binary and Complex Questions

Several questions in Putnam-AXIOM are binary, meaning that the question inherently has two possible answers. These include true/false questions, questions about divergence or convergence, or questions about the winner of a two-player game. These questions make up \(26\) of the \(262\) question in Putnam-AXIOM Original; of the \(59\) questions of Putnam-AXIOM Variations, binary questions make up \(7\). We refer to all questions that are not binary as "complex" questions.

Given the guessable nature of these questions and our answer-matching evaluation method, models have a much higher chance of randomly guessing the right answer on these questions.

To discern whether the inclusion of these guessable questions significantly affects the overall difficulty of Putnam-AXIOM, we conducted an analysis of the accuracy of various models with and without the binary questions, with the overall accuracies in Figure 6.

We see that, with the exception of Qwen2 Math 7B, almost all models have a higher accuracy on Putnam-AXIOM with its binary questions than without, meaning that guessing is contributing to their success to some extent. However, we see that on the more advanced models--Qwen2 Math 7B, GPT 4, and Claude Sonnet 3.5--the gap between the accuracies on the entire dataset and the accuracies on only complex questions is much smaller. This is likely because these models are capable enough that they successfully answer a similar percentage of complex questions and binary questions; less advanced models get significantly fewer complex questions correct than binary questions, so we see a large accuracy gap.

Based on the results of this experiment, we've decided to use only the complex questions for most of our evaluations such as in Table 1 and Figure 1.

Figure 6: Putnam-AXIOM v.s. Putnam-AXIOM with only complex questions

[MISSING_PAGE_EMPTY:12]

### Model Analysis Examples

**Problem:** Let \(n\) be a positive integer. Determine, in terms of \(n\), the largest integer \(m\) with the following property: There exist real numbers \(x_{1},\ldots,x_{2n}\) with \(-1<x_{1}<x_{2}<\cdots<x_{2n}<1\) such that the sum of the lengths of the \(n\) intervals

\[[x_{1}^{2k-1},x_{2}^{2k-1}],[x_{3}^{2k-1},x_{4}^{2k-1}],\ldots,[x_{2n-1}^{2k-1},x_{2n}^{2k-1}]\]

is equal to 1 for all integers \(k\) with \(1\leq k\leq m\).

**Model's Response:** We are given \(n\) positive integers and need to determine the largest integer \(m\), in terms of \(n\), such that there exist real numbers \(x_{1},x_{2},\ldots,x_{2n}\) satisfying:

1. The \(x_{i}\) are strictly increasing between \(-1\) and 1:

\[-1<x_{1}<x_{2}<\cdots<x_{2n}<1\]

2. For each integer \(k\) with \(1\leq k\leq m\), the sum of the lengths of \(n\) intervals is equal to 1:

\[\sum_{i=1}^{n}\left(x_{2i}^{2k-1}-x_{2i-1}^{2k-1}\right)=1\]

Our goal is to find the largest integer \(m\) (in terms of \(n\)) satisfying these conditions.

\(\ldots\)

**General Case:** We have \(2n\) variables and \(m\) equations.

- Each equation is independent due to the distinct exponents.

- To have a solution, we must have at least as many variables as equations.

- **Therefore, the maximum number \(m\) is bounded by \(2n\).**

- However, since we have \(2n\) variables but they are constrained by the ordering and the interval \((-1,1)\), the effective degrees of freedom are less than \(2n\).

*Conclusion:**

Given the constraints and the increasing number of equations with \(m\), the largest integer \(m\) for which the conditions can be satisfied is:

\[m=n\]

**Final Answer:**

The final answer is \(\boxed{m}\) I hope it is correct.

**Year: 2022 ID: A6 Final Answer: \(n\)**

Figure 7: **An example response where OpenAI o1-preview gets the final answer correct, but made an unjustified claim.** OpenAI o1-preview claims that the largest possible value for \(m\) is \(n\). However, its only justification for this claim is that \(m\) is bounded by \(2n\). OpenAI o1-preview does not justify why a value of \(m\) between \(n\) and \(2n\) cannot work.

Problem:Find the least possible area of a convex set in the plane that intersects both branches of the hyperbola \(xy=1\) and both branches of the hyperbola \(xy=-1\). (A set \(S\) in the plane is called _convex_ if for any two points in \(S\) the line segment connecting them is contained in \(S\).)

Model's Response:To find the least possible area of a convex set in the plane that intersects both branches of the hyperbolas \(xy=1\) and \(xy=-1\), we need to consider the geometric constraints. Let's start by visualizing these hyperbolas:

The hyperbola \(xy=1\) consists of two branches in the first and third quadrants:

\[y=\frac{1}{x}.\]

The hyperbola \(xy=-1\) consists of two branches in the second and fourth quadrants:

\[y=-\frac{1}{x}.\]

We aim to place a convex set that intersects both branches of each hyperbola. One useful geometric figure for this is a rectangle aligned along the hyperbolic axes. We can guarantee that the rectangle will intersect both branches of \(xy=1\) and \(xy=-1\) by making its sides tangent to the hyperbolas.

\[\ldots\]

The geometric configuration simplifies the calculation:

The minimum enclosing convex area tangency ideally is of square structure, yielding the unit hyperbola intersection:

\[\text{area}=4\text{ (Since side }2\cdot 2=4\text{formation in closed square)}.\]

This geometric construction ensures least, minimum convex interaction:

Final Answer: The final answer is 4. I hope it is correct.

Figure 8: **An example response where GPT-4o gets the final answer correct, but made an unjustified logical step, resulting in a non-rigorous solution.** OpenAI o1-preview logically jumps to the idea that the geometric shape that minimizes the area is a rectangle. However, it does not attempt to justify this claim in any way, and proceeds as though this is obvious.

**Problem:** Given

\[11z^{10}+10iz^{9}+10iz-11=0,\]

find the value of \(|z|\). (Here \(z\) is a complex number and \(i^{2}=-1\).)

**Model's Response:** To solve the equation

\[11z^{10}+10iz^{9}+10iz-11=0\]

and find the value of \(|z|\), where \(z\) is a complex number, we'll proceed step by step.

**Step 2:** Assume \(|z|=1\)**

Let's assume that \(|z|=1\), which means \(z=e^{i\theta}\) for some real number \(\theta\).

**Step 3:** Substitute \(z=e^{i\theta}\) into the Equation**

Substituting \(z=e^{i\theta}\) into the equation, we get:

\[11(e^{i\theta})^{10}+10i(e^{i\theta})^{9}+10ie^{i\theta}-11=0\]

Simplify each term:

- \((e^{i\theta})^{10}=e^{10i\theta}\)

- \((e^{i\theta})^{9}=e^{9i\theta}\)

So the equation becomes:

\[11e^{10i\theta}+10ie^{9i\theta}+10ie^{i\theta}-11=0\]

\[\ldots\]

**Step 6:** Analyze the Equations**

The trigonometric equations are complex and difficult to solve directly. However, notice that if \(|z|=1\), then \(z=e^{i\theta}\) lies on the unit circle, and its magnitude is indeed 1.

Moreover, since we couldn't find any specific \(\theta\) that satisfies both equations simultaneously (as shown by trying several angles), this suggests that no specific angle \(\theta\) other than those corresponding to \(|z|=1\) satisfy the equation.

**Conclusion:**

Since our manipulations suggest that \(|z|=1\) is necessary (and given the nature of complex numbers and the unit circle), we conclude that:

*Final Answer:** The final answer is 1. I hope it is correct.

**Year:** 1989 **ID:** A3 **Final Answer:** 1

Figure 9: **An example response where GPT-40 make a logical leap and is completely incoherent**. In this solution, the model jumps to assume that \(|z|=1\) and performs a series of calculations. Then, it concludes that the final answer is \(1\) simply because the equations it made were too “complex and difficult” to solve.

Problem:Let \(k\) be the smallest positive integer for which there exist distinct integers \(m_{1},m_{2},m_{3},m_{4},m_{5}\) such that the polynomial \[p(x)=(x-m_{1})(x-m_{2})(x-m_{3})(x-m_{4})(x-m_{5})\] has exactly \(k\) nonzero coefficients. Find a set of integers \(m_{1},m_{2},m_{3},m_{4},m_{5}\) for which this minimum \(k\) is achieved and given the sum \(k+m_{1}+m_{2}+m_{3}+m_{4}+m_{5}\) as the final answer.

Model's Response:The polynomial \(p(x)=(x-m_{1})(x-m_{2})(x-m_{3})(x-m_{4})(x-m_{5})\) has exactly \(k\) nonzero coefficients when the values of \(m_{i}\) are distinct integers. We want to minimize \(k\) and find a set of values for \(m_{i}\) that achieves this minimum.

The expansion of \(p(x)\) will include all possible products of the differences \((x-m_{i})\). For each term of the form \((x-a)\), this generates a coefficient for that term, and this will happen for each combination of \(i\) and \(j\), including when \(i=j\).

The minimum possible value for \(k\) can be calculated by considering the sparsity of nonzero coefficients in the polynomial's expansion. This is achieved when the polynomial is written in the form that it eliminates as many terms as possible, leading to a minimal number of nonzero coefficients.

For \((x-m_{1})(x-m_{2})(x-m_{3})(x-m_{4})(x-m_{5})\), it can be achieved if the differences \((x-m_{i})\) produce terms that include maximal cancellation. The problem becomes one of determining the minimal degree of the polynomial that includes maximal cancellation.

The key observation here is that the minimal nonzero coefficients are achieved when the polynomial is arranged in such a way that most coefficients are zero due to symmetry and cancellation properties.

The smallest positive integer \(k\) for such polynomials happens at \(k=2\), for instance, \((x-1)(x-2)(x-3)(x-4)(x-5)\) results in a polynomial with precisely coefficients as follows:

\[p(x)=x^{5}-(1+2+3+4+5)x^{4}\] \[+(\text{sum of products of each combination of 2 distinct elements})x^{3}\text{ etc...}\]

Since the polynomial in this problem demands exactly \(k\) nonzero coefficients, the product of differences can lead to cancellations resulting in minimal terms.

Let's consider the initial observation:

\[m_{1}=1,m_{2}=2,m_{3}=3,m_{4}=4,m_{5}=5\]

The resulting polynomial, \((x-1)(x-2)(x-3)(x-4)(x-5)\)

Final answer: \(\framebox{$15$}\)

Figure 10: **An example response where NuminaMath makes a calculation error, includes irrelevant information, and misunderstands the problem.** In this solution, we see that the final answer is obtained by adding \(k+m_{1}+m_{2}+m_{3}+m_{4}+m_{5}\). In the model’s final solution, its value of \(k\) is \(2\), so its final answer should be \(2+1+2+3+4+5=17\), not \(15\); this is due a misunderstanding of the problem and/or a calculation error. Furthermore, the model includes the expression of the “resulting polynomial,” which is completely irrelevant to the problem it’s attempting to solve.

**Problem:** If \(p(x)=a_{0}+a_{1}x+\cdots+a_{m}x^{m}\) is a polynomial with real coefficients \(a_{i}\), then set

\[\Gamma(p(x))=a_{0}^{2}+a_{1}^{2}+\cdots+a_{m}^{2}.\]

Let \(f(x)=3x^{2}+7x+2\). Find, with proof, a polynomial \(g(x)\) with real coefficients such that

1. \(g(0)=1\), and
2. \(\Gamma(f(x)^{n})=\Gamma(g(x)^{n})\)

for every integer \(n\geq 1\).

**Model's Response:** We have that \(F(x)=3x^{2}+7x+2\) and thus \(\Gamma(F(x))=3^{2}+7^{2}+2^{2}=9+49+4=62\). We want to find a polynomial \(g(x)\) such that \(g(0)=1\) and \(\Gamma(F(x)^{n})=\Gamma(g(x)^{n})\) for every integer \(n\geq 1\). Suppose \(g(x)=x^{2}+bx+1\). Then \(\Gamma(g(x))=1+b^{2}+1=b^{2}+2\). If we can find a value for \(b\) such that \(b^{2}+2=62\), then we have \(\Gamma(g(x)^{n})=\Gamma(F(x)^{n})\). Solving \(b^{2}+2=62\) gives \(b^{2}=60\), so \(b=\sqrt{60}=2\sqrt{15}\). Therefore, we can take \(g(x)=x^{2}+2\sqrt{15}x+1\). Since \(g(0)=1\), \(g(x)\) satisfies both conditions.

Final Answer: The final answer is \(x^{2}+2\sqrt{15}x+1\). I hope it is correct.

Figure 11: **An example response where Qwen2-Math-7B hallucinates and misunderstands the problem.** First, Qwen misunderstands that the polynomial is quadratic—which is not stated anywhere in the problem statement. Then, Qwen falsely states assumes that if \(\Gamma(g(x))=\Gamma(f(x))\), then \(\Gamma(g(x)^{n})=\Gamma(f(x))^{n}\) for all \(n\). These mistakes lead Qwen to the wrong solution.

**Problem:** Let \(x_{0}=1\) and for \(n\geq 0\), let \(x_{n+1}=3x_{n}+\lfloor x_{n}\sqrt{5}\rfloor\). In particular, \(x_{1}=5\), \(x_{2}=26\), \(x_{3}=136\), \(x_{4}=712\). Find a closed-form expression for \(x_{2007}\). (\(\lfloor a\rfloor\) means the largest integer \(\leq a\).)

Figure 12: **An example response where DeepSeek-Math-7B-RL makes an incorrect logical jump. In the series of equalities in the beginning, DeepSeek simply removes the floor function and proceeds. However, the floor function is an integral part of the problem, and without it, DeepSeek is unable to come to the right solution.**Related Work

### Mathematics benchmarks

Numerous benchmarks exist to assess the mathematical capabilities of models, each typically focusing on a specific task. Two notable examples are MATH [Hendrycks et al., 2021] and GSM8K [Cobbe et al., 2021]. The MATH dataset contains questions sourced from American high school mathematics competitions such as the AMC 10, AMC 12, and AIME [Hendrycks et al., 2021], while the GSM8K dataset contains 8.5K handwritten elementary school level questions Cobbe et al. [2021]. Both contain questions and answers with detailed rationale explanations.

As models have become larger and more powerful, even the most difficult existing benchmarks have become less challenging. For instance, while the MATH dataset saw \(6.9\%\) accuracy on its release, it now sees \(87.92\%\) accuracy with GPT-4 MACM [Lei, 2024]. Similarly, GPT4 has attained \(97.1\%\) accuracy on the GSM8K [Zhong et al., 2024]. This saturation necessitates the development of more challenging benchmarks.

Many contemporary data sets have been created to combat the saturation of existing benchmarks. For instance, the ARB dataset includes hundreds of challenging problems in high school and college-level math, physics, and chemistry Sawada et al. [2023]. Similarly OlympiadBench contains nearly 9,000 problems from the International Mathematics Olympiad (IMO), the Chinese GaoKao, and more He et al. [2024]. Finally, SciBench is a similar reasoning benchmark that includes hundreds of college-level scientific reasoning questions from instructional textbooks Wang et al. [2023].

Although these datasets alleviate the saturation problem, they come with many limitations. For instance, ARB Sawada et al. [2023] and OlympiadBench He et al. [2024] both contain several symbolic and proof-based questions which cannot be graded automatically and require a costly and lengthy human evaluation process. Though ARB attempts to utilize LLMs to grade their own responses with a rubric, this process is often unreliable and self-referential. Our Putnam-AXIOM dataset addresses these limitations by offering challenging Putnam problems with fully-written solutions and easily evaluable answers. It enables efficient automated assessment via frameworks like LM Harness [Gao et al., 2024], avoiding costly human evaluation or unreliable self-grading.

PutnamBench [Tsoukalas et al., 2024] is a related benchmark that primarily focuses on formal theorem proving. Its main objective is to derive formalized proofs of mathematical statements and it provides formalizations in systems such as Lean, Isabelle, and Coq, all sourced from the prestigious Putnam competition. PutnamBench also includes 640 natural language statements and their corresponding answers where applicable. While both benchmarks draw from the same competition, Putnam-AXIOM focuses on the curation of natural language problems for final answer verification and introduces automatic functional variations to generate additional benchmarks addressing potential data contamination. Further we focus on assessing true mathematical reasoning ability and hence take measures to remove easily guessable answers.

### Functional Benchmarks

Data contamination is a significant problem in creating evaluation benchmarks, as many of these problems are openly available on the Internet and are likely included in the training data for large models [Schaeffer, 2023, Sainz et al., 2023]. Thus, the MATH [Hendrycks et al., 2021], AGIEval [Zhong et al., 2023], OlympiadBench [He et al., 2024], and ARB [Sawada et al., 2023] benchmarks (which are all sourced from problems on the Internet) could potentially be contaminated. Therefore, models may achieve artificially high performance on an evaluation benchmark by memorizing the answers to the problems Magar and Schwartz [2022], Ranaldi et al. [2023].

A straightforward way of avoiding data contamination issues is to utilize problems unavailable on the Internet. However, even if problems are not currently part of model training data, it is unrealistic to expect them to remain inaccessible. At the same time, it is costly to rely on the continuous human development of new datasets.

Srivastava et al. [2024] attempts to alleviate this data contamination issue by creating _functional_ variations of the MATH dataset, where new problems can be generated simply by changing numeric parameters, yielding different solutions. They observe a significant discrepancy in models' performance between standard benchmarks and these new variations. We recognize the potential of this idea and have adapted it to our more challenging dataset. We have altered the variables, constants, and phrasing of many Putnam questions while preserving their overall difficulty and requirements for logical and mathematical reasoning.