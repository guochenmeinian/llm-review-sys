# On the Computational Complexity of Private High-dimensional Model Selection

Saptarshi Roy Zehua Wang Ambuj Tewari

Department of Statistics

University of Michigan, Ann Arbor

{roysapta, wangzeh, tewaria}@umich.edu

###### Abstract

We consider the problem of model selection in a high-dimensional sparse linear regression model under privacy constraints. We propose a differentially private (DP) best subset selection method with strong statistical utility properties by adopting the well-known exponential mechanism for selecting the best model. To achieve computational expediency, we propose an efficient Metropolis-Hastings algorithm and under certain regularity conditions, we establish that it enjoys polynomial mixing time to its stationary distribution. As a result, we also establish both approximate differential privacy and statistical utility for the estimates of the mixed Metropolis-Hastings chain. Finally, we perform some illustrative experiments on simulated data showing that our algorithm can quickly identify active features under reasonable privacy budget constraints.

## 1 Introduction

In this paper, we consider the problem of _private model selection_ in high-dimensional sparse regression which has been one of the central topics in statistical research over the past decade. Consider observations \(\{(\mathbf{x}_{i},y_{i})\}_{i=1}^{n}\subseteq\mathcal{X}\times\mathcal{Y}\) following the linear model:

\[y_{i}=\mathbf{x}_{i}^{\top}\boldsymbol{\beta}+w_{i},\quad i\in\{1,\ldots,n\},\] (1)

where \(\{\mathbf{x}_{i}\}_{i\in[n]}\) are _fixed_\(p\)-dimensional feature vectors, \(\{w_{i}\}_{i\in[n]}\) are i.i.d. _mean-zero_\(\sigma\)-sub-Gaussian noise, i.e., \(\mathbb{E}\exp(\lambda w_{i})\leq\exp(\lambda^{2}\sigma^{2}/2)\) for all \(\lambda\in\mathbb{R}\) and \(i\in[n]\), and the signal vector \(\boldsymbol{\beta}\in\mathbb{R}^{p}\) is unknown but is assumed to have a sparse support. In matrix notation, the observations can be represented as

\[\mathbf{y}=\mathbf{X}\boldsymbol{\beta}+\mathbf{w},\]

where \(\mathbf{y}=(y_{1},\ldots,y_{n})^{\top}\), \(\mathbf{X}=(\mathbf{x}_{1},\ldots,\mathbf{x}_{n})^{\top}\), and \(\mathbf{w}=(w_{1},\ldots,w_{n})^{\top}\). We consider the standard _high-dimensional sparse_ setup where \(n<p\), and possibly \(n\ll p\), and the vector \(\boldsymbol{\beta}\) is sparse in the sense that \(\left\|\boldsymbol{\beta}\right\|_{0}:=\sum_{j=1}^{p}\mathbbm{1}(\beta_{j}\neq 0 )=s\), which is much smaller than \(p\). The main goal of variable selection is to identify the active set \(\gamma^{*}:=\{j:\beta_{j}\neq 0\}\).

For the past two decades, there has been ample work on model selection problem in the non-private setting for \(\ell_{1}\)-penalized methods[57, 54, 46, 23], concave regularized methods [55, 53, 12, 16], \(\ell_{0}\)-penalized/constrained methods [13, 1, 37, 39] in high-dimensional setting. On the computational side, recent advancements related to mixed integer optimization (MIO) in [4, 5] and [20] have pushed the computational barrier of best subset selection (BSS) in terms of solving problems of large dimensions (large \(p\)), and consequently, simulation studies in [19] have revealed the improved performance of BSS over its computational surrogates like LASSO, SCAD, and MCP.

Despite these theoretical and computational advancements related to BSS, to the best of our knowledge, there is no computationally efficient private algorithmic framework for BSS for high-dimensional sparse regression setup (1). This is especially surprising as private model selectionis important in many contemporary applications involving sensitive data including genetics [21], neuroimaging [33], and computer vision [56]. One major reason for this could be the lack of DP mechanisms for MIO problems which restricts us from exploiting the MIO formulation of BSS introduced in [4]. Secondly, the apparent computational burden stemming from the requirement of exponentially large numbers of search queries in private BSS has eluded the majority of the machine learning and statistics community. In this paper, we address the latter issue by mainly focusing on the utility and computational complexity of BSS under privacy constraints. To be specific, we make the following contributions listed below:

1. We adopt the exponential mechanism [31] to design a DP BSS algorithm, and we establish its good statistical or utility guarantee under high-privacy regime whenever \(\beta_{min}:=\min_{j\in\gamma^{*}}|\beta_{j}|\gtrsim\sigma\{(s\log p)/n\}^{1/2}\).
2. Under the low-privacy regime, we show that accurate model recovery is possible whenever \(\beta_{min}\gtrsim\sigma\{(\log p)/n\}^{1/2}\), which is the minimax optimal \(\beta_{min}\) requirement for model recovery under non-private setting. Therefore, this paper points out an inflection phenomenon in the signal strength requirement for the model consistency across different privacy regimes.
3. In addition, we design an MCMC chain that converges to its stationary distribution that matches the sampling distribution in the exponential mechanism. As a consequence, the model estimator generated by the MCMC also enjoys (approximate) DP. Furthermore, under certain regularity conditions on the design, we show that the MCMC chain enjoys a polynomial mixing time in \((n,p,s)\) to the stationary distribution with good utility guarantee.

In summary, this paper proposes a DP version of BSS that generates a private model estimator of \(\gamma^{*}\) with strong model recovery property within polynomial time in the problem parameters \(n,p,s\). In the next section, we will discuss some prior related works on DP model selection and discuss some of their limitations.

### Comparison with Prior Related Works

In the past decades, there has been a considerable amount of work studying DP sparse regression problems. However, most of these works focus either on empirical risk minimization [25; 44; 26; 48] or establishing \(\ell_{2}\)-consistency rate [47; 6] which are not directly related to the task of model selection. To the best of our knowledge, there are only three works considering the problem of variable selection in sparse regression problems under the DP framework, [27; 45], and [29]. Table 1 shows a clear comparison between those methods and our method. [27] proposed two algorithms under sparse regression setting. One of them is based on the exponential mechanism, which is known to be computationally inefficient due to exponentially large numbers of search queries. However, they do not analyze the algorithm under the model selection framework. Moreover, for the privacy analysis, they assume that the loss functions are bounded over the space of sparse vectors, which is rather restrictive in the linear regression setting. In comparison, our paper provides a solid model recovery guarantee (Theorem 3.5) for a similar exponential mechanism without using the bounded loss assumption. Furthermore, under a slightly stronger assumption, we design a computationally efficient MCMC algorithm that also enjoys desirable utility similar to the exponential mechanism (Theorem 4.3) under DP framework. The other algorithm in [27] is based on the resample-and-aggregate framework [36; 42]. Although computationally efficient, this method requires sub-optimal \(\beta_{min}\) condition compared to Theorem 3.5. In [45], the authors introduced two concepts of stability for LASSO and proposed two PTR-based (propose-test-release) algorithms for variable selection. However, these methods have nontrivial probabilities of outputting the null (no result), which is undesirable in practice. Also, the support recovery probabilities for these methods do not approach 1 with a growing sample size even under the _strong irrepresentability condition_[57] on the design matrix. In [29], the authors proposed to use the Akaike information criterion or Bayesian information criterion coupled with the exponential mechanism to choose the proper model. However, the runtime of this algorithm is exponential and also requires stronger \(\beta_{min}\) condition. As mentioned earlier, in this paper, we show that our proposed MCMC algorithm is both computationally efficient and produces approximate DP estimates of \(\gamma^{*}\) with a strong utility guarantee under a better \(\beta_{min}\) condition. One may also apply sparse vector techniques (SVT) to choose important features [43]. In this case, each feature can be associated with an appropriate choice of score function, and then apply SVT to choose the relevant features. However, the choice of the score function in high-dimensional sparse regression cases remains unclear, and moreover, it is also known that the exponential mechanism enjoys better accuracy compared to SVT [30] under such an offline setting.

## 2 Differential Privacy

Differential privacy requires the output of a randomized procedure to be robust with respect to a small perturbation in the input dataset, i.e., an attacker can hardly recover the presence or absence of a particular individual in the dataset based on the output only. It is important to note that differential privacy is a property of the randomized procedure, rather than the output obtained.

### Preliminaries

In this section, we will formalize the notion of differential privacy. Consider a dataset \(D:=\{z_{1},\ldots,z_{n}\}\in\mathcal{Z}^{n}\) consisting of \(n\) datapoints in the sample space \(\mathcal{Z}\). A _randomized_ algorithm \(\mathcal{A}\) maps the dataset \(D\) to \(\mathcal{A}(D)\in\mathcal{O}\), an output space. Thus, \(\mathcal{A}(D)\) is a random variable on the output space \(\mathcal{O}\).

For any two datasets \(D\) and \(D^{\prime}\), we say they are _neighbors_ if \(|D\Delta D^{\prime}|=1\). We can now formally introduce the definition of differential privacy.

**Definition 2.1** (\((\varepsilon,\delta)\)-DP, [9]).: _Given the privacy parameters \((\varepsilon,\delta)\in\mathbb{R}^{+}\times\mathbb{R}^{+}\), a randomized algorithm \(\mathcal{A}(\cdot)\) is said to satisfy the \((\varepsilon,\delta)\)-DP property if_

\[\mathbb{P}(\mathcal{A}(D)\in\mathcal{K})\leq e^{\varepsilon}\mathbb{P}( \mathcal{A}(D^{\prime})\in\mathcal{K})+\delta\] (2)

_for any measurable event \(\mathcal{K}\in\text{range}(\mathcal{A})\) and for any pair of neighboring datasets \(D\) and \(D^{\prime}\)._

In the above definition, the probability is only with respect to the randomness of the algorithm \(\mathcal{A}(\cdot)\), and it does not impose any condition on the distribution of \(D\) or \(D^{\prime}\). If both \(\varepsilon\) and \(\delta\) are small, then Definition 2.1 essentially entails that distribution of \(\mathcal{A}(D)\) and \(\mathcal{A}(D^{\prime})\) are almost indistinguishable from each other for any choices of neighboring datasets \(D\) and \(D^{\prime}\). This guarantees strong privacy against an attacker by masking the presence or absence of a particular individual in the dataset. As a special case, when \(\delta=0\), the notion of DP in Definition 2.1 is known as the _pure differential privacy_.

### Privacy Mechanisms

For any DP procedure, a specific randomized procedure \(\mathcal{A}\) must be designed that takes a database \(D\in\mathcal{Z}^{n}\) as input and returns an element of the output space \(\mathcal{O}\) while satisfying the condition in (2). Several approaches exist that are generic enough to be adaptable to different tasks, and which often serve as building blocks for more complex ones. A few popular examples include the Laplace mechanism [11], Gaussian mechanism [10], and Exponential mechanism [31]. We only provide the details of the last technique, since the other two techniques are out-of-scope for the methods and experiments in this paper.

Exponential mechanism:The exponential mechanism is designed for discrete output space, Suppose \(\mathscr{S}=\{\alpha_{i}:i\in\mathcal{I}\}\) for some index set \(\mathcal{I}\), and let \(u:\mathscr{S}\times\mathcal{Z}^{n}\rightarrow\mathbb{R}\) be score function that measures the quality of \(\alpha\in\mathscr{S}\). Denote by \(\Delta u_{K}\) the global sensitivity of the score function \(u\), i.e.

\[\Delta u_{K}:=\max_{\alpha\in\mathscr{S}}\max_{D,\,D^{\prime}\text{ are neighbors}}\left|u(\alpha,D)-u(\alpha,D^{\prime})\right|.\]

\begin{table}
\begin{tabular}{|c|c|c|c|c|} \hline Paper & Method & \(\beta_{min}\) cond. & failure prob. \(\rightarrow\) 0 & runtime \\ \hline \hline
[27] & Exp-Mech & NA & NA & exp \\  & Lasso + Samp-Agg & \(\Omega(\sqrt{\frac{s\log p}{n^{1/2}}})\) & yes & poly \\ \hline
[45] & Lasso + Sub-samp. stability & \(\Omega(\sqrt{\frac{s\log p}{n}})\) & no & poly \\  & Lasso + Pert. stability & \(\Omega(\max\{\sqrt{\frac{s\log p}{n}},\frac{s^{3/2}}{\varepsilon n}\})\) & no & poly \\ \hline
[29] & Exp-Mech & \(\Omega(\sqrt{\max\{1,\frac{s}{\varepsilon}\}\frac{s\log n}{n}})\) & yes & exp \\ \hline
**This paper** & Exp-Mech & \(\Omega(\sqrt{\max\{1,\frac{s}{\varepsilon}\}\frac{\log p}{n}})\) & yes & exp \\  & Approx. Exp-Mech via MCMC & \(\Omega(\sqrt{\max\{1,\frac{s}{\varepsilon}\}\frac{\log p}{n}})\) & yes & poly \\ \hline \end{tabular}
\end{table}
Table 1: Comparison of DP model selection methods.

Intuitively, sensitivity quantifies the effect of any individual in the dataset on the outcome of the analysis. The score function \(u(\cdot,\cdot)\) is called _data monotone_ if the addition of a data record can either increase (decrease) or remain the same with any outcome, e.g., \(u(\alpha,D)\leq u(\alpha,D\cup\{z\})\). Next, we have the following result.

**Lemma 2.2** ([8; 31]).: _Exponential mechanism \(\mathcal{A}_{E}(D)\) that outputs samples from the probability distribution_

\[\mathbb{P}(\mathcal{A}_{E}(D)=\alpha)\propto\exp\left\{\frac{\varepsilon u( \alpha,D)}{\Delta u}\right\}\] (3)

_preserves \((2\varepsilon,0)\)-differential privacy. If \(u(\cdot,\cdot)\) is data monotone, then we have \((\varepsilon,0)\)-differential privacy._

In general, if the \(\mathscr{S}\) is too large, the sampling from the distribution could be computationally inefficient. However, we show below that the special structure of the linear model (1) allows us to design an MCMC chain that can generate approximate samples _efficiently_ from the distribution (3) for privately solving BSS under an appropriately chosen score function.

## 3 Best Subset Selection

We briefly review the preliminaries of BSS, one of the most classical variable selection approaches. For a given sparsity level \(\widehat{s}\), BSS solves for \(\widehat{\boldsymbol{\beta}}_{\mathrm{best}}(\widehat{s}):=\arg\min_{ \boldsymbol{\theta}\in\mathbb{R}^{p},\|\boldsymbol{\theta}\|_{0}\leq\widehat {s}}\left\|\mathbf{y}-\mathbf{X}\boldsymbol{\theta}\right\|_{2}^{2}.\) For model selection purposes, we can choose the best fitting model to be \(\widehat{\gamma}_{\mathrm{best}}(\widehat{s}):=\{j:[\widehat{\boldsymbol{ \beta}}_{\mathrm{best}}(\widehat{s})]_{j}\neq 0\}\). For a subset \(\gamma\subseteq[p]\), define the matrix \(\mathbf{X}_{\gamma}:=(\mathbf{X}_{j};j\in\gamma)\). Let \(\boldsymbol{\Phi}_{\gamma}:=\mathbf{X}_{\gamma}(\mathbf{X}_{\gamma}^{\top} \mathbf{X}_{\gamma})^{-1}\mathbf{X}_{\gamma}^{\top}\) be orthogonal projection operator onto the column space of \(\mathbf{X}_{\gamma}\). Also, define the corresponding residual sum of squares (RSS) for model \(\gamma\) as \(L_{\gamma}(\mathbf{y},\mathbf{X}):=\mathbf{y}^{\top}(\mathbb{I}_{n}- \boldsymbol{\Phi}_{\gamma})\mathbf{y}\). With this notation, the \(\widehat{\gamma}_{\mathrm{best}}(\widehat{s})\) can be alternatively written as

\[\widehat{\gamma}_{\mathrm{best}}(\widehat{s}):=\arg\min_{\gamma\subseteq[p]: \gamma|\leq\widehat{s}}L_{\gamma}(\mathbf{y},\mathbf{X}).\] (4)

Let \(\mathbf{X}_{\gamma}\) be the matrix comprised of only the columns of \(\mathbf{X}\) with indices in \(\gamma\), and \(\boldsymbol{\Phi}_{\gamma}\) denotes the orthogonal projection matrix onto the column space of \(\mathbf{X}_{\gamma}\). In addition, let \(\widehat{\mathbf{\Sigma}}:=n^{-1}\mathbf{X}^{\top}\mathbf{X}\) be the sample covariance matrix and for any two sets \(\gamma_{1},\gamma_{2}\subset[p]\), \(\widehat{\mathbf{\Sigma}}_{\gamma_{1},\gamma_{2}}\) denotes the submatrix of \(\mathbf{\Sigma}\) with row indices in \(\gamma_{1}\) and column indices in \(\gamma_{2}\). Finally, define the collection \(\mathscr{H}_{z}:=\{\gamma\subset[p]:\gamma\neq\gamma^{*},|\gamma|=\widehat{s}\}\), and for \(\gamma\in\mathscr{A}_{\widehat{s}}\) write \(\Gamma(\gamma)=\widehat{\mathbf{\Sigma}}_{\gamma^{*}\setminus\gamma,\gamma^ {*}\setminus\gamma}-\widehat{\mathbf{\Sigma}}_{\gamma^{*}\setminus\gamma, \gamma}\widehat{\mathbf{\Sigma}}_{\gamma,\gamma^{*}\setminus\gamma}^{-1} \widehat{\mathbf{\Sigma}}_{\gamma,\gamma^{*}\setminus\gamma}\). Then, it follows that \(\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}^{\top}\Gamma(\gamma) \boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}\) is equal to the _residualized_ signal strength \(n^{-1}\|(\mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma})\mathbf{X}_{\gamma^{*} \setminus\gamma}\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}\|_{2}^{2}\). Therefore, \(\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}^{\top}\Gamma(\gamma) \boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}\) quantifies the separation between \(\gamma\) and the true model \(\gamma^{*}\). Ideally, a larger value of the quantity will help BSS to discriminate between \(\gamma^{*}\) and any other candidate model \(\gamma\). More details on this can be found in [40]. Now we are ready to introduce the identifiability margin that characterizes the _model discriminative power_ of BSS.

### Identifiability Margin

The discussion in Section 3 motivates us to define the following _identifiablity margin_:

\[\mathfrak{m}_{*}(\widehat{s}):=\min_{\gamma\in\mathscr{A}_{\widehat{s}}}\frac {\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}^{\top}\Gamma(\gamma) \boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}}{|\gamma\setminus\gamma^{*}|}.\] (5)

As mentioned earlier, the quantity \(\mathfrak{m}_{*}(\widehat{s})\) captures the model discriminative power of BSS. To add more perspective, note that if the features are highly correlated among themselves then it is expected that \(\mathfrak{m}_{*}(\widehat{s})\) is very close to \(0\). Hence, any candidate model \(\gamma\) is practically indistinguishable from the true model \(\gamma^{*}\) which in turn makes the problem of exact model recovery harder. On the contrary, if the features are uncorrelated then \(\mathfrak{m}_{*}(\widehat{s})\) becomes bounded away from 0 making the true model \(\gamma^{*}\) easily recoverable. For example, [17] showed that under the knowledge of true sparsity, i.e., when \(\widehat{s}=s\), the condition

\[\mathfrak{m}_{*}(s)\gtrsim\sigma^{2}\frac{\log p}{n},\] (6)

is sufficient for BSS to achieve model consistency. One can also view \(\mathfrak{m}_{*}(s)\) as a quantifier of the coupled effect of model correlation and signal strength. If we define the minimum and maximum eigenvalues over all models to be \(\lambda_{*}=\min_{\gamma\in\mathscr{A}_{s}}\lambda_{min}(\Gamma(\gamma))\) and \(\lambda^{*}=\max_{\gamma\in\mathscr{A}_{s}}\lambda_{max}(\Gamma(\gamma))\) respectively, then it follows that

\[\lambda_{*}\beta_{min}^{2}\leq\mathfrak{m}_{*}(s)\leq\lambda^{*}\beta_{min}^{2}.\]

Therefore, it suffices to have \(\beta_{min}\gtrsim\sigma\{(\log p)/(n\lambda_{*})\}^{1/2}\) in order to satisfy condition (6). In this case, \(\lambda_{*}\) captures the degree of model correlation, and \(\beta_{min}\) is the minimum signal strength. Similar to our previous discussion, if there is high collinearity in the model, \(\lambda_{*}\) will be typically small, and BSS needs a large value of \(\beta_{min}\) to identify the true model \(\gamma^{*}\). On the other hand, if \(\beta_{min}\) is too small for a given level of model correlation, i.e, if \(\beta_{min}\ll\sigma\{(\log p)/(n\lambda^{*})\}^{1/2}\), then also BSS fails to achieve model consistency as it is hard to identify active features under the presence of weak signals [17, Theorem 2.1]. As we will see in the next section, the DP BSS algorithm also requires a margin condition similar to (6) to ensure model recovery, and this is indeed an indispensable condition as it is needed even in non-private case.

### Differentially Private BSS and Utility Analysis

In order to privatize the optimization problem in (4), we will adopt the exponential mechanism discussed in Section 2.2. In particular, for a tuning parameter \(K>0\), we consider the score function

\[u_{K}(\gamma;\mathbf{X},\mathbf{y}):=-\min_{\boldsymbol{\theta}\in\mathbb{R}^{ 2}:\left\|\boldsymbol{\theta}\right\|_{1}\leq K}\left\|\mathbf{y}-\mathbf{X}_ {\gamma}\boldsymbol{\theta}\right\|_{2}^{2}\,\]

and for a given privacy budget \(\varepsilon>0\), we sample \(\gamma\in\mathscr{A}_{s}\) from the distribution

\[\pi(\gamma)\propto\exp\left\{\frac{\varepsilon u_{K}(\gamma;\mathbf{X}, \mathbf{y})}{\Delta u_{K}}\right\}\mathbbm{1}(\gamma\in\mathscr{A}_{s}\cup\{ \gamma^{*}\}).\] (7)

As we are concerned with the exact recovery \(\gamma^{*}\), from here on we assume \(\widehat{s}=s\). The above algorithm is essentially the same as Algorithm 4 in [27]; however, they do not introduce the extra \(\ell_{1}\)-constraint on the parameter space. Instead, their algorithm needs the loss-term \((y-\mathbf{x}_{\gamma}^{\top}\boldsymbol{\theta})^{2}\) to be bounded by a constant for every possible choice of \(\mathbf{x},y,\gamma\) and \(\boldsymbol{\theta}\). This assumption is not true in general for the squared error loss, and to remedy this issue, we introduce the extra \(\ell_{1}\)-constraint in the score function. This is a common strategy that is used to guarantee worst-case sensitivity bound and similar methods also have been adopted in [29, 6] to construct private estimators. Next, we present the following lemma that shows the data-monotonicity of the proposed score function.

**Lemma 3.1**.: _The score function \(u_{K}(\gamma;\cdot)\) in (7) is data monotone._

Therefore, Lemma 2.2 automatically guarantees that the above procedure is \((\varepsilon,0)\)-DP. However, in practice, we need an explicit form for \(\Delta u_{K}\) to carry out the sampling method, and it is also needed to analyze the utility guarantee of the exponential mechanism. To provide a concrete upper bound on the global sensitivity of \(u_{K}(\cdot;\cdot)\), we make the following boundedness assumption on the database:

**Assumption 3.2**.: _There exists positive constants \(r,x_{\mathsf{max}}\) such that \(\sup_{y\in\mathcal{Y}}\left|y\right|\leq r,\sup_{\mathbf{x}\in\mathcal{X}} \left\|\mathbf{x}\right\|_{\infty}\leq x_{\mathsf{max}}\)._

Under this assumption, the following lemma provides an upper bound on the global sensitivity of the score function along with the DP guarantee.

**Lemma 3.3** (Sensitivity bound and DP).: _Under Assumption 3.2, the global sensitivity \(\Delta u_{K}\) is bounded by \(\Delta_{K}:=(r+x_{\mathsf{max}}K)^{2}\). Therefore, the exponential mechanism (7) with \(\Delta u_{K}\) replaced by \(\Delta_{K}\) satisfies \((\varepsilon,0)\)-DP._

The above lemma provides an upper bound on the global sensitivity of the score function rather than finding the exact value of it. However, to guarantee \((\varepsilon,0)\)-DP property of exponential mechanism, it suffices to use the upper bound of \(\Delta u_{K}\) in (7). Now we will shift towards the utility analysis of the proposed exponential mechanism. First, we require some technical assumptions.

**Assumption 3.4**.: _We assume the following hold:_

* _There exists positive constants_ \(b_{\mathsf{max}}\) _such that_ \(\left\|\boldsymbol{\beta}\right\|_{1}\leq b_{\mathsf{max}}\)_._
* _There exists positive constants_ \(\kappa_{-},\kappa_{+}\) _such that_ \[\kappa_{-}\leq\lambda_{\min}\left(\mathbf{X}_{\gamma}^{\top}\mathbf{X}_{ \gamma}/n\right)\leq\lambda_{\max}\left(\mathbf{X}_{\gamma}^{\top}\mathbf{X}_ {\gamma}/n\right)\leq\kappa_{+},\] (8) _for all_ \(\gamma\in\mathscr{A}_{s}\cup\{\gamma^{*}\}\)_.__._
3. _The true sparsity level_ \(s\) _follows the inequality_ \(s\leq n/(\log p)\)_._

Assumption 3.4(a) tells that the true parameter \(\bm{\beta}\) lies inside a \(\ell_{1}\)-ball. Similar boundedness assumptions are fairly standard in privacy literature [49; 29; 6]. Assumption 3.4(b) is a well-known assumption in the high-dimensional literature [54; 22; 32] which is known as the Sparse Riesz Condition (SRC). Finally, Assumption 3.4(c) essentially assumes that the \(s=o(n)\), i.e., sparsity grows with a sufficiently small rate compared to the sample size \(n\).

**Theorem 3.5** (Utility guarantee).: _Let the conditions in Assumption 3.2 and Assumption 3.4 hold. Set \(K\geq\{(\kappa_{+}/\kappa_{-})b_{\mathsf{max}}+(8x_{\mathsf{max}}/\kappa_{-}) \sigma\}\sqrt{s}\). Then, under the data generative model (1), there exist universal positive constants \(c_{1},C_{1}\) such that whenever_

\[\mathfrak{m}_{*}(s)\geq C_{1}\sigma^{2}\max\left\{1,\frac{\Delta_{K}}{\varepsilon \sigma^{2}}\right\}\frac{\log p}{n},\] (9)

_with probability at least \(1-c_{1}p^{-2}\) we have \(\pi(\gamma^{*})\geq 1-p^{-2}\)._

Cost of privacy.Theorem 3.5 essentially says that whenever the identifiability margin is large enough, the exponential mechanism outputs the true model \(\gamma^{*}\) with high probability. Note that \(\Delta_{K}/\sigma^{2}=\Omega(s)\). In the low privacy regime, i.e., for \(\varepsilon>\Delta_{K}/\sigma^{2}\) we only require \(\mathfrak{m}_{*}(s)\gtrsim\sigma^{2}(\log p)/n\) to achieve model consistency and this matches with the optimal rate for model consistency of non-private BSS. Note that, the margin condition does not depend at all on \(\varepsilon\) in this regime. In contrast, in a high privacy regime, i.e., for \(\varepsilon<\Delta_{K}/\sigma^{2}\), Condition (9) essentially demands \(\mathfrak{m}_{*}(s)\gtrsim\sigma^{2}(s\log p)/(n\varepsilon)\) to achieve model consistency. Thus, in a high privacy regime, we pay an extra factor of \((s/\varepsilon)\) in the margin requirement.

**Remark 3.6**.: _The failure probability in Theorem 3.5 can be improved to \(O(p^{-M})\) for any arbitrary integer \(M>2\). However, we have to pay a cost in the universal constant \(C_{1}\) in terms of a multiplicative constant larger than 1._

**Remark 3.7**.: _Under Assumption 3.4(b), it follows that \(\lambda_{*}\geq\kappa_{-}\). Therefore, it suffices to have \(\min_{j\in\gamma^{*}}\beta_{j}^{2}\geq\left(\frac{C_{1}\sigma^{2}}{\kappa_{-} }\right)\max\left\{1,\Delta_{K}/(\varepsilon\sigma^{2})\right\}\frac{\log p}{n}\) in order to hold condition (9). Therefore, in high-privacy regime, our method requires \(\min_{j\in\gamma^{*}}|\beta_{j}|\gtrsim\sigma\{(s\log p)/(n\varepsilon\kappa_{ -})\}^{1/2}\). In contrast, under the low-privacy regime, we retrieve the optimal requirement \(\min_{j\in\gamma^{*}}|\beta_{j}|\gtrsim\sigma\{(\log p)/(n\kappa_{-})\}^{1/2}\)._

## 4 Efficient Sampling through MCMC

In this section, we will propose an efficient sampling method to generate approximate samples from the distribution (7). One of the challenges of sampling methods in high-dimension is their high computational complexity. For example, the distribution in (7) places mass on all \(\binom{p}{s}\) subsets of \([p]\), and it is practically infeasible to sample \(\gamma\) from the distribution as we have to essentially explore over an exponentially large space. This motivates us to resort to sampling techniques based on MCMC, through which we aim to obtain approximate samples from the distribution in (7). Past works on MCMC algorithms for Bayesian variable selection can be divided into two main classes - Gibbs sampler [15; 24; 34] and Metropolis-Hastings [18; 28]. In this paper, we focus on a particular form of Metropolis-Hastings updates.

In general terms, Metropolis-Hastings (MH) random walk is an iterative and local-move based method involving three steps:

1. Given the current state \(\gamma\), construct a neighborhood \(\mathcal{N}(\gamma)\) of proposal states.
2. Choose a new state \(\gamma^{\prime}\in\mathcal{N}(\gamma)\) according to some proposal distribution \(\mathbf{F}(\gamma,\cdot)\) over the neighborhood \(\mathcal{N}(\gamma)\).
3. Move to the new state \(\gamma^{\prime}\) with probability \(\mathbf{R}(\gamma,\gamma^{\prime})\), and stay in the original state \(\gamma\) with probability \(1-\mathbf{R}(\gamma,\gamma^{\prime})\), where the acceptance probability is given by \[\mathbf{R}(\gamma,\gamma^{\prime})=\min\left\{1,\frac{\pi(\gamma^{\prime}) \mathbf{F}(\gamma^{\prime},\gamma)}{\pi(\gamma)\mathbf{F}(\gamma,\gamma^{ \prime})}\right\},\] where \(\pi(\cdot)\) is same as in Equation (7).

This procedure generates a Markov chain for any choice of the neighborhood structure \(\mathcal{N}(\gamma)\) with the following transition probability:

\[\mathbf{P}_{\text{MH}}(\gamma,\gamma^{\prime})=\begin{cases}\mathbf{F}(\gamma, \gamma^{\prime})\mathbf{R}(\gamma,\gamma^{\prime}),&\text{if }\gamma^{\prime} \in\mathcal{N}(\gamma),\\ 1-\sum_{\gamma^{\prime}\neq\gamma}\mathbf{P}_{\text{MH}}(\gamma,\gamma^{ \prime}),&\text{if }\gamma^{\prime}=\gamma,\\ 0,&\text{otherwise}.\end{cases}\]

The specific form of Metropolis-Hastings update analyzed in this paper is obtained by following the _double swap update_ scheme to update \(\gamma\).

Double swap update:Let \(\gamma\in\mathscr{A}_{\text{s}}\cup\{\gamma^{*}\}\) be the initial state. Choose an index pair \((k,\ell)\in\gamma\times\gamma^{c}\)_uniformly_ at random. Construct the new state \(\gamma^{\prime}\) by setting \(\gamma^{\prime}=\gamma\cup\{\ell\}\setminus\{k\}\).

The above scheme can be viewed as a general MH update scheme when \(\mathcal{N}(\gamma)\) is the collection of all models \(\gamma^{\prime}\) which can be obtained by swapping two distinct coordinates of \(\gamma\) and \(\gamma^{c}\) respectively. Thus, letting \(d_{H}(\gamma,\gamma^{\prime})=|\gamma\setminus\gamma^{\prime}|+|\gamma^{ \prime}\setminus\gamma|\) denote the Hamming distance between \(\gamma\) and \(\gamma^{\prime}\), the neighborhood is given by \(\mathcal{N}(\gamma)=\{\gamma^{\prime}\mid d_{H}(\gamma,\gamma^{\prime})=2, \exists\;\;(k,\ell)\in\gamma\times\gamma^{c}\;\text{such that}\;\gamma^{ \prime}=\gamma\cup\{\ell\}\setminus\{k\}\}\). With this definition, the transition matrix of the previously described Metropolis-Hastings scheme can be written as follows:

\[\mathbf{P}_{\text{MH}}(\gamma,\gamma^{\prime})=\begin{cases}\frac{1}{|\gamma |\mid|\gamma^{c}|}\min\{1,\frac{\pi(\gamma^{\prime})}{\pi(\gamma)}\},&\text{ if }\gamma^{\prime}\in\mathcal{N}(\gamma),\\ 1-\sum_{\gamma^{\prime}\neq\gamma}\mathbf{P}_{\text{MH}}(\gamma,\gamma^{\prime }),&\text{if }\gamma^{\prime}=\gamma,\\ 0,&\text{otherwise}.\end{cases}\] (10)

### Mixing Time and Approximate DP

Let \(\mathcal{C}\) be a Markov chain on the discrete space \(\mathscr{S}\) with a transition probability matrix \(\mathbf{P}\in\mathbb{R}^{|\mathscr{S}|\times|\mathscr{S}|}\) with stationary distribution \(\nu\). Throughout our discussion, we assume that \(\mathcal{C}\) is reversible, i.e., it satisfies the balanced condition \(\nu(\gamma)\mathbf{P}(\gamma,\gamma^{\prime})=\nu(\gamma^{\prime})\mathbf{P}( \gamma^{\prime},\gamma)\) for all \(\gamma,\gamma^{\prime}\in\mathscr{S}\). Note that the previously described transition matrix \(\mathbf{P}_{\text{MH}}\) in (10) satisfies the reversibility condition. It is convenient to identify a reversible chain with a weighted undirected graph \(G\) on the vertex set \(\mathscr{S}\), where two vertices \(\gamma\) and \(\gamma^{\prime}\) are connected if and only if the edge weight \(\mathbf{Q}(\gamma,\gamma^{\prime}):=\nu(\gamma)\mathbf{P}(\gamma,\gamma^{ \prime})\) is strictly positive. For \(\gamma\in\mathscr{S}\) and any subset \(S\subseteq\mathscr{S}\), we write \(\mathbf{P}(\gamma,S)=\sum_{\gamma^{\prime}\in S}\mathbf{P}(\gamma,\gamma^{ \prime})\). If \(\gamma\) is the initial state of the chain, then the total variation distance to the stationary distribution after \(t\) iterations is

\[\Delta_{\gamma}(t)=\left\|\mathbf{P}^{t}(\gamma,\cdot)-\nu(\cdot)\right\|_{ \text{TV}}:=\max_{S\in\mathscr{S}}\left|\mathbf{P}^{t}(\gamma,S)-\nu(S) \right|.\]

The \(\eta\)-mixing time is given by

\[\tau_{\eta}:=\max_{\gamma\in\mathscr{S}}\min\{t\in\mathbb{N}\mid\Delta_{ \gamma}(t^{\prime})\leq\eta\text{ for all }t^{\prime}\geq t\},\] (11)

which measures the number of iterations needed for the chain to be within distance \(\eta\in(0,1)\) of the stationary distribution.

Privacy of MCMC estimator:Now, we will show that once the MH chain in (10) has mixed with its stationary distribution \(\pi(\cdot)\) defined in (7), the model estimators at each iteration will enjoy approximate DP. To fix the notation, let \(\gamma_{t}\) be the \(t\)th iteration of the MH chain in (10). Then, we have the following useful lemma:

**Lemma 4.1**.: _The model estimator \(\gamma_{\tau_{\eta}}\) is \((\varepsilon,\delta)\)-DP with \(\delta=\eta(1+e^{\varepsilon})\)._

The above lemma shows that smaller \(\eta\) entails a better privacy guarantee for a fixed level \(\varepsilon\) as \(\delta\) decreases with \(\eta\). Therefore, allowing more mixing of the chain will provide better privacy protection. However, this raises a concern about how long a practitioner must wait until the chain archives \(\eta\)-mixing. In particular, it is important to understand how \(\tau_{\eta}\) scales in the difficulty parameters of the problem, for example, the dimension of the parameter space and sample size. In our case, we are interested in the covariate dimension \(p\), sample size \(n\), sparsity \(s\), and the privacy parameter \(\varepsilon\). In the next section, we will show that the chain with transition matrix (10) enjoys rapid mixing, meaning that the mixing time \(\tau_{\eta}\) grows at most at a polynomial rate in \(p,s\) and the sample size \(n\).

### Rapid Mixing of MCMC

We now turn to develop sufficient conditions for MH scheme (10) to be rapidly mixing. To this end, we make a technical assumption on the design matrix. Essentially, the following assumption controls the amount of correlation between active features and spurious features.

**Assumption 4.2**.: _For every \(\gamma^{\prime}\in\mathscr{A}_{s}\setminus\{\gamma^{*}\}\), there exists \(k\notin\gamma^{*}\cup\gamma^{\prime}\) such that_

\[\max_{j\in\gamma^{*}\setminus\gamma^{\prime}}\frac{\left|\mathbf{X}_{j}^{ \top}(\mathbb{I}_{n}-\mathbf{\Phi}_{\gamma^{\prime}})\mathbf{X}_{k}\right|}{ \left\|(\mathbb{I}_{n}-\mathbf{\Phi}_{\gamma^{\prime}})\mathbf{X}_{k}\right\|_ {2}}\leq b_{\text{max}}^{-1}\sqrt{(\kappa_{-}C_{1}\sigma^{2}/2)\log p},\]

_where \(C_{1}\) is the same universal positive constant as in Theorem 3.5._

First, note that Assumption 4.2 basically controls the length of the projection of the feature \(\mathbf{X}_{j}\) on the unit vector \(\mathbf{u}_{k}:=(\mathbb{I}_{n}-\mathbf{\Phi}_{\gamma^{\prime}})\mathbf{X}_{k }/\left\|(\mathbb{I}_{n}-\mathbf{\Phi}_{\gamma^{\prime}})\mathbf{X}_{k}\right\| _{2}\). Therefore, the above inequality restricts the correlation between an active feature \(\mathbf{X}_{j}\) and the spurious scaled feature \(\mathbf{u}_{k}\) from being too large. To this end, we emphasize that stronger assumptions on model correlation (on top of the SRC condition) are common in literature for establishing the computational efficiency of Bayesian variable selection methods involving MH algorithm. For example, to show the computational efficiency MH algorithm under Zellner's \(g\)-prior, [51] assumes

\[\max_{\gamma:|\gamma|\leq s_{0}}\left\|(\mathbf{X}_{\gamma}^{\top}\mathbf{X}_ {\gamma})^{-1}\mathbf{X}_{\gamma}^{\top}\mathbf{X}_{\gamma^{*}\setminus\gamma }\right\|_{\text{op}}^{2}=O\left(\frac{n}{s\log p}\right),\] (12)

where \(s_{0}\) (larger than \(s\)) is a specific tuning parameter of their algorithm that controls the model size. The assumption in the above display is akin to the well-known irrepresentability condition [57] which is a very strong assumption on the design. On a high level, at any given current state \(\gamma\), Assumption 4.2 or Condition (12) helps to identify a good local move towards the true model \(\gamma^{*}\) in the MH algorithm via deletion of the least influential covariate in \(\gamma\). Now, we present our main result for the mixing time of MCMC.

**Theorem 4.3** (Rapid mixing time).: _Let the conditions in Assumption 3.2, Assumption 3.4 and Assumption 4.2 hold. Then, under the data generative model (1), there exists a universal constant \(C_{1}^{\prime}>0\) such that under the margin condition_

\[\mathfrak{m}_{*}(s)\geq C_{1}^{\prime}\sigma^{2}\max\left\{1,\frac{\Delta_{K }}{(\kappa_{-}\wedge 1)\varepsilon\sigma^{2}}\right\}\frac{\log p}{n},\] (13)

_there exist universal positive constants \(c_{2},C_{2}\) such that the mixing time \(\tau_{\eta}\) of the MCMC chain (10) enjoys the following with probability at least \(1-c_{2}p^{-2}\):_

\[\tau_{\eta}\leq C_{2}p^{8}\left\{n\epsilon\Psi^{-1}\kappa_{+}b_{\text{max}}^{ 2}+\log(1/\eta)\right\},\] (14)

_where \(\Psi=\left\{r+(\kappa_{+}/\kappa_{-})b_{\text{max}}x_{\text{max}}+(\sigma/ \kappa_{-})x_{\text{max}}^{2}\right\}^{2}\)._

The main technical innovation in the theorem is the double swap updating scheme in the MCMC that allows us to leverage the _canonical path ensemble_ construction argument [41] to prove the bound (14) on the mixing time. Essentially, we show that under Assumption 4.2, there exists a canonical path in a specially weighted graph corresponding to the MCMC random walk with low path congestion. The complete proof can be found in Appendix A.5.

Regarding the statement of the theorem, note that the margin condition (13) is slightly stronger than the margin condition in Theorem 3.5. Under that condition, the above theorem shows that the \(\eta\)-mixing time of the MCMC algorithm designed for approximate sampling from the distribution (7) grows at a polynomial rate in \((n,p,s)\). Recall that according to the previous definition (11) of the mixing time, Theorem 4.3 characterizes the _worst-case_ mixing time, meaning the number of iterations when starting from the worst possible initialization. If we start with a good initial state -- for example, the true model \(\gamma^{*}\) would be an ideal though impractical choice - then we can remove the \(n\) term in the upper bound in (14). Therefore, the bound in (14) can be thought of as the worst-case number of iterations required in the burn-in period of the MCMC algorithm. Furthermore, it is important to point out that Assumption 4.2 is only needed to ensure the "quick" mixing time of the MCMC chain. It is possible to relax this assumption, however, in that case, the MCMC chain is not guaranteed to mix under polynomial time. Nonetheless, given enough iterations, the chain will indeedconverge to the distribution (7) as MH algorithm always generates an ergodic chain that eventually mixes to its stationary distribution.

It is interesting to note that Theorem 4.3 suggests that in a large \(\varepsilon\) regime, the chain mixes slower compared to the small \(\varepsilon\) regime. The main reason for this is that Theorem 4.3 only relies on worst-case analysis. The intuition is the following: When \(\varepsilon\) is very large, then the target distribution is essentially fully concentrated on \(\gamma^{*}\) (assuming the score for \(\gamma^{*}\) is highest). Now, the current analysis of Theorem 4.3 does not assume any condition on the initial state of the MCMC chain. It treats the initial state \(\gamma_{0}\) as if it is chosen in a completely random manner, i.e., it is the worst case. From this point of view, it is hard for a completely uninformative distribution to converge to a target distribution that is concentrated on a single subset (very informative), and resulting in a longer mixing time. Finally, Theorem 4.3 leads to the following corollary:

**Corollary 4.4**.: _Let \(\pi_{t}\) denote the distribution of the \(t\)th iterate \(\gamma_{t}\) of the MCMC scheme (10). Then, under the conditions of Theorem 3.5 and Theorem 4.3, there exists a universal constant \(c_{3}>0\) such that for any fixed iteration \(t\) such that \(t\geq C_{2}p\mathrm{s}^{2}\left\{n\varepsilon\Psi^{-1}\kappa_{+}b_{\mathsf{ max}}^{2}+\log(1/\eta)\right\},\) we have \(\pi_{t}(\gamma^{*})\geq 1-\eta-p^{-2}\) with probability at least \(1-c_{3}p^{-2}\)._

The above corollary is useful in the sense that it provides a quantitative choice of \(\eta\) that yields high utility of the estimator \(\gamma_{t}\). For example, if we set \(\eta=p^{-2}\) and \(\varepsilon=O(1)\), then for any \(t\gtrsim ps^{2}(n\varepsilon+\log p)\) the resulting sample \(\gamma_{t}\) will match \(\gamma^{*}\) with probability \(1-c_{3}p^{-2}\).

**Remark 4.5**.: _Similar to Remark 3.6, the failure probability in Theorem 4.3 and Corollary 4.4 can be improved to \(O(p^{-M})\) for arbitrary large \(M>2\), but at the cost of paying higher values for the absolute constants \(C_{1}^{\prime}\) and \(C_{2}\)._

## 5 Numerical experiments

In this section, we will conduct some illustrative simulations. To compare the quality of the DP model estimator, we compare F-score[19] of the estimated model with that of the true model \(\gamma^{*}\) and the BSS estimator. As the actual BSS is computationally infeasible, we use the adaptive best subset selection (ABESS) algorithm [58] as a computational surrogate to BSS. Throughout this section, we assume that the true sparsity \(s\) is known, i.e., we provide the knowledge of \(s\) to the algorithm. All codes are available at https://github.com/roysaptaumich/DP-BSS.

Uniform design.We consider a random design matrix, formed by choosing each entry from the distribution \(\mathrm{Uniform}(-1,1)\) in i.i.d. fashion. In detail, we set \(n=900,p=2000\), and the sparsity level \(s=4\). We generate the entries of the noise \(\mathbf{w}\) independently from \(\mathrm{Uniform}(-0.1,0.1)\), and consider the linear model (1). We choose the design vector \(\boldsymbol{\beta}\) with true sparsity \(s=4\) and the support set \(\gamma^{*}=\{j:1\leq j\leq 4\}\). We set all the signal strength to be equal, taking the following two forms: (i) **Strong signal:**\(\beta_{j}=2\{(s\log p)/n\}^{1/2}\), and (ii) **Weak signal:**\(\beta_{j}=2\{(\log p)/n\}^{1/2}\) for all \(j\in\gamma^{*}\).

Under these setups, we consider the privacy parameter \(\varepsilon\in\{0.5,1,3,5,10\}\) which are acceptable choices of \(\varepsilon\)[35]. Moreover, similar (or larger) choices of \(\varepsilon\) are common in various applications including US census study [14], socio-economic study [38], and industrial applications [3, 52]. For the Metropolis-Hastings random walk, we vary \(K\in\{0.5,2,3,3.5\}\) and initialize 10 independent Markov chains from random initializations and record the F-score of the last iteration. We use the CVXPY package [7, 2] for solving the \(\ell_{1}\)-constrained optimization problem in the updating step of MCMC. We also track the qualities of the model through its explanatory power for convergence diagnostics. In particular, we calculate the scale factor \(R_{\gamma}:=\mathsf{y}^{\top}\boldsymbol{\Phi}_{\gamma}\mathbf{y}/\left\| \mathbf{y}\right\|_{2}^{2}\) for each model update along the random walk and compare those with \(R_{\widehat{\mathrm{s}}_{\mathrm{books}}}\) to heuristically gauge the quality of mixing. More details and a set of comprehensive plots can be found in Appendix D.1 where we also discuss more about the effect of \(\varepsilon\) and \(K\) on the utility. For \(K=2\), Table 2 shows that F-score increases as \(\varepsilon\) increases both in the cases of strong and weak signals. In fact, for \(\varepsilon\geq 3\), the performance of the algorithm is on par with the non-private BSS. This is consistent with the inflection phenomenon pointed out in Theorem 3.5 and Corollary 4.4. Furthermore, as expected, we see that for a fixed \(\varepsilon\), the F-score is generally higher in the strong signal case.

We also carry out experiments under independent Gaussian design. The details and more comprehensive discussion of the findings are deferred to Appendix D.2. In summary, in this case also, our algorithm enjoys greater utility under the strong signal case as shown in Table 2.

Computational resources and license information :All the experiments were performed in the Great Lakes cluster with 16 cores and 10 GB RAM. ABESS package is distributed under GNU General Public License, Version 3. CVXPY package is distributed under Apache License, Version 2.

## 6 Conclusion

In this paper, we study the variable selection performance of BSS under the differential privacy constraint. In order to achieve (pure) differential privacy, we adopt the exponential mechanism and establish its high statistical utility guarantee in terms of exact model recovery. Furthermore, for computational efficiency, we design a MH random walk that provably mixes with the stationary distribution within a mixing time of the polynomial order in \((n,p,s)\). We also show that the samples from the MH random walk enjoy approximate DP while retaining a high utility guarantee with experimental underpinnings. In summary, as discussed in Section 1.1, we establish both high utility and efficient computational guarantee for our model selection algorithm under privacy constraints, which is in sharp contrast with the previous works in DP model selection literature. Moreover, the proposed MCMC method is generic enough to adopt in other models beyond linear structures. For example, one can use this technique under the setup of generalized linear models with likelihood loss as the utility function. Therefore, our method can be used in diverse domains including medical studies to fast-track scientific discoveries and promote the practice of responsible AI.

To this end, we also point out some of the open problems and future directions. One limitation, of our main result Theorem 3.5 is that it requires the condition \(\min_{j\in\gamma^{*}}|\beta_{j}|=\Omega(\sqrt{(s\log p)/n})\) in high-privacy regime. It is still an open question whether the extra \(\sqrt{s}\) factor is necessary for model selection. Future research along this line could focus on solving BSS through DP mixed integer optimization (MIO). This would mean an important contribution in this field as commercial solvers like GUROBI or MOSEK would be capable of solving the BSS problems at an industrial scale with high computational efficiency using a general DP framework.

## References

* [1] Shuchin Aeron, Venkatesh Saligrama, and Manqi Zhao. Information theoretic bounds for compressed sensing. _IEEE Transactions on Information Theory_, 56(10):5111-5130, 2010.
* [2] Akshay Agrawal, Robin Verschueren, Steven Diamond, and Stephen Boyd. A rewriting system for convex optimization problems. _Journal of Control and Decision_, 5(1):42-60, 2018.
* [3] Apple. Learning with privacy at scale. https://docs-assets.developer.apple.com/ml-research/papers/learning-with-privacy-at-scale.pdf, 2017.
* [4] Dimitris Bertsimas, Angela King, and Rahul Mazumder. Best subset selection via a modern optimization lens. _The Annals of Statistics_, 44(2):813-852, 2016.

\begin{table}
\begin{tabular}{|c|c|c||c|c|} \hline \multirow{2}{*}{Privacy Level} & \multicolumn{2}{c||}{Uniform Design} & \multicolumn{2}{c|}{Gaussian Design} \\ \cline{2-5}  & Strong Signal & Weak Signal & Strong Signal & Weak Signal \\ \hline \hline \(\varepsilon=0.5\) & **0.025** & 0.00 & 0.00 & 0.00 \\ \(\varepsilon=1\) & **0.15** & 0.05 & 0.00 & 0.00 \\ \(\varepsilon=3\) & **1.00*** & 0.15 & **0.025** & 0.00 \\ \(\varepsilon=5\) & **1.00*** & 0.40 & **0.375** & 0.075 \\ \(\varepsilon=10\) & **1.00*** & **1.00*** & **0.925*** & 0.025 \\ \hline Non-private & **1.00** & **1.00** & **1.00** & **1.00** \\ \hline \end{tabular}
\end{table}
Table 2: Comparison of mean F-score across chains for \(K=2\) under independent Uniform and Gaussian design. \((*)\) denotes that the chain has mixed reasonably well.

- 323, 2020.
* [6] T Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates of convergence for parameter estimation with differential privacy. _The Annals of Statistics_, 49(5):2825-2850, 2021.
* [7] Steven Diamond and Stephen Boyd. CVXPY: A Python-embedded modeling language for convex optimization. _Journal of Machine Learning Research_, 17(83):1-5, 2016.
* [8] David Durfee and Ryan M Rogers. Practical differentially private top-k selection with pay-what-you-get composition. _Advances in Neural Information Processing Systems_, 32, 2019.
* [9] Cynthia Dwork. Differential privacy. In _International colloquium on automata, languages, and programming_, pages 1-12. Springer, 2006.
* [10] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni Naor. Our data, ourselves: Privacy via distributed noise generation. In _Advances in Cryptology-EUROCRYPT 2006: 24th Annual International Conference on the Theory and Applications of Cryptographic Techniques, St. Petersburg, Russia, May 28-June 1, 2006. Proceedings 25_, pages 486-503. Springer, 2006.
* [11] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In _Theory of Cryptography: Third Theory of Cryptography Conference, TCC 2006, New York, NY, USA, March 4-7, 2006. Proceedings 3_, pages 265-284. Springer, 2006.
* [12] Jianqing Fan and Runze Li. Variable selection via nonconcave penalized likelihood and its oracle properties. _Journal of the American Statistical Association_, 96(456):1348-1360, 2001.
* [13] Alyson K. Fletcher, Sundeep Rangan, and Vivek K Goyal. Necessary and sufficient conditions for sparsity pattern recovery. _IEEE Transactions on Information Theory_, 55(12):5758-5772, 2009.
* [14] Simson Garfinkel. Differential privacy and the 2020 us census. https://mit-serc.pubpub.org/pub/differential-privacy-2020-us-census/release/1, 2022.
* [15] Edward I George and Robert E McCulloch. Variable selection via gibbs sampling. _Journal of the American Statistical Association_, 88(423):881-889, 1993.
* [16] Xiao Guo, Hai Zhang, Yao Wang, and Jiang-Lun Wu. Model selection and estimation in high dimensional regression models with group SCAD. _Statistics & Probability Letters_, 103:86-92, 2015.
* [17] Yongyi Guo, Ziwei Zhu, and Jianqing Fan. Best subset selection is robust against design dependence. _arXiv preprint arXiv:2007.01478_, 2020.
* [18] Chris Hans, Adrian Dobra, and Mike West. Shotgun stochastic search for "large p" regression. _Journal of the American Statistical Association_, 102(478):507-516, 2007.
* [19] Trevor Hastie, Robert Tibshirani, and Ryan Tibshirani. Best subset, forward stepwise or lasso? analysis and recommendations based on extensive comparisons. _Statistical Science_, 35(4):579-592, 2020.
* [20] Hussein Hazimeh, Rahul Mazumder, and Ali Saab. Sparse regression at scale: Branch-and-bound rooted in first-order optimization. _Mathematical Programming_, 196(1-2):347-388, 2022.
* [21] Qianchuan He and Dan-Yu Lin. A variable selection method for genome-wide association studies. _Bioinformatics_, 27(1):1-8, 2011.
* [22] Jian Huang, Yuling Jiao, Yanyan Liu, and Xiliang Lu. A constructive approach to l0 penalized regression. _The Journal of Machine Learning Research_, 19(1):403-439, 2018.

* Huang et al. [2008] Jian Huang, Shuangge Ma, and Cun-Hui Zhang. Adaptive lasso for sparse high-dimensional regression models. _Statistica Sinica_, pages 1603-1618, 2008.
* 773, 2005.
* Jain and Thakurta [2014] Prateek Jain and Abhradeep Guha Thakurta. (near) dimension independent risk bounds for differentially private learning. In _International Conference on Machine Learning_, pages 476-484. PMLR, 2014.
* Kasiviswanathan and Jin [2016] Shiva Prasad Kasiviswanathan and Hongxia Jin. Efficient private empirical risk minimization for high-dimensional learning. In _International Conference on Machine Learning_, pages 488-497. PMLR, 2016.
* Kifer et al. [2012] Daniel Kifer, Adam Smith, and Abhradeep Thakurta. Private convex empirical risk minimization and high-dimensional regression. In _Conference on Learning Theory_, pages 25-1. JMLR Workshop and Conference Proceedings, 2012.
* Lamnisos et al. [2013] Demetris Lamnisos, Jim E Griffin, and Mark FJ Steel. Adaptive monte carlo for bayesian variable selection in regression models. _Journal of Computational and Graphical Statistics_, 22(3):729-748, 2013.
* Lei et al. [2018] Jing Lei, Anne-Sophie Charest, Aleksandra Slavkovic, Adam Smith, and Stephen Fienberg. Differentially private model selection with penalized and constrained likelihood. _Journal of the Royal Statistical Society Series A: Statistics in Society_, 181(3):609-633, 2018.
* Lyu et al. [2017] Min Lyu, Dong Su, and Ninghui Li. Understanding the sparse vector technique for differential privacy. _Proceedings of the VLDB Endowment_, 10(6):637-648, 2017.
* McSherry and Talwar [2007] Frank McSherry and Kunal Talwar. Mechanism design via differential privacy. In _48th Annual IEEE Symposium on Foundations of Computer Science (FOCS'07)_, pages 94-103. IEEE, 2007.
* 270, 2009.
* Mwangi et al. [2014] Benson Mwangi, Tian Siva Tian, and Jair C Soares. A review of feature reduction techniques in neuroimaging. _Neuroinformatics_, 12:229-244, 2014.
* Narisetty et al. [2018] Naveen N Narisetty, Juan Shen, and Xuming He. Skinny gibbs: A consistent and scalable gibbs sampler for model selection. _Journal of the American Statistical Association_, 2018.
* Near and Darais [2022] Joseph Near and David Darais. Differential privacy: Future work & open challenges. https://www.nist.gov/blogs/cybersecurity-insights/differential-privacy-future-work-open-challenges, 2022.
* Nissim et al. [2007] Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private data analysis. In _Proceedings of the thirty-ninth annual ACM symposium on Theory of computing_, pages 75-84, 2007.
* Rad [2011] Kamiar Rahnama Rad. Nearly sharp sufficient conditions on exact sparsity pattern recovery. _IEEE Transactions on Information Theory_, 57(7):4672-4679, 2011.
* Rogers et al. [2020] Ryan Rogers, Adrian Rivera Cardoso, Koray Mancuhan, Akash Kaura, Nikhil Gahlawat, Neha Jain, Paul Ko, and Parvez Ahammad. A members first approach to enabling linkedin's labor market insights at scale. _arXiv preprint arXiv:2010.13981_, 2020.
* Roy et al. [2022] Saptarshi Roy, Ambuj Tewari, and Ziwei Zhu. High-dimensional variable selection with heterogeneous signals: A precise asymptotic perspective. _arXiv preprint arXiv:2201.01508_, 2022.
* Roy et al. [2023] Saptarshi Roy, Ambuj Tewari, and Ziwei Zhu. Tale of two c (omplex) titles. _arXiv preprint arXiv:2301.06259_, 2023.
* Sinclair [1992] Alistair Sinclair. Improved bounds for mixing rates of markov chains and multicommodity flow. _Combinatorics, probability and Computing_, 1(4):351-370, 1992.

* [42] Adam Smith. Privacy-preserving statistical estimation with optimal convergence rates. In _Proceedings of the forty-third annual ACM symposium on Theory of computing_, pages 813-822, 2011.
* [43] Ben Stoddard, Yan Chen, and Ashwin Machanavajjhala. Differentially private algorithms for empirical machine learning. _arXiv preprint arXiv:1411.5428_, 2014.
* [44] Kunal Talwar, Abhradeep Guha Thakurta, and Li Zhang. Nearly optimal private lasso. _Advances in Neural Information Processing Systems_, 28, 2015.
* [45] Abhradeep Guha Thakurta and Adam Smith. Differentially private feature selection via stability arguments, and the robustness of the lasso. In Shai Shalev-Shwartz and Ingo Steinwart, editors, _Proceedings of the 26th Annual Conference on Learning Theory_, volume 30 of _Proceedings of Machine Learning Research_, pages 819-850, Princeton, NJ, USA, 12-14 Jun 2013. PMLR.
* [46] Martin J. Wainwright. Sharp thresholds for high-dimensional and noisy sparsity recovery using \(\ell_{1}\) -constrained quadratic programming (lasso). _IEEE Transactions on Information Theory_, 55(5):2183-2202, 2009.
* [47] Di Wang and Jinhui Xu. On sparse linear regression in the local differential privacy model. In _International Conference on Machine Learning_, pages 6628-6637. PMLR, 2019.
* [48] Di Wang, Minwei Ye, and Jinhui Xu. Differentially private empirical risk minimization revisited: Faster and more general. _Advances in Neural Information Processing Systems_, 30, 2017.
* [49] Yu-Xiang Wang. Revisiting differentially private linear regression: optimal and adaptive prediction & estimation in unbounded domain. _arXiv preprint arXiv:1803.02596_, 2018.
* 124, 2013.
* 2532, 2016.
* [52] McGee Young, Marc-Antoine Pare, Harry Bergmann, et al. Differential privacy for expanding access to building energy data. In _ACEEE Summer Study on Energy Efficiency in Buildings Proceedings_, 2020.
* [53] Cun-Hui Zhang. Nearly unbiased variable selection under minimax concave penalty. _The Annals of Statistics_, 38(2):894-942, 2010.
* [54] Cun-Hui Zhang and Jian Huang. The sparsity and bias of the lasso selection in high-dimensional linear regression. _The Annals of Statistics_, 36(4):1567-1594, 2008.
* [55] Cun-Hui Zhang and Tong Zhang. A general theory of concave regularization for high-dimensional sparse estimation problems. _Statistical Science_, 27(4):576-593, 2012.
* [56] Fan Zhang, Wei Li, Yifan Zhang, and Zhiyong Feng. Data driven feature selection for machine learning algorithms in computer vision. _IEEE Internet of Things Journal_, 5(6):4262-4272, 2018.
* [57] Peng Zhao and Bin Yu. On model selection consistency of lasso. _The Journal of Machine Learning Research_, 7:2541-2563, 2006.
* [58] Jin Zhu, Xueqin Wang, Liyuan Hu, Junhao Huang, Kangkang Jiang, Yanhang Zhang, Shiyun Lin, and Junxian Zhu. abess: A fast best-subset selection library in python and r. _Journal of Machine Learning Research_, 23(202):1-7, 2022.

Proof of Main results

### Proof of Lemma 3.1

Recall that \(u_{K}(\gamma;\mathbf{X},\mathbf{y})=-L_{\gamma,K}(\mathbf{X},\mathbf{y})\) where \(L_{\gamma,K}(\mathbf{X},\mathbf{y}):=\sum_{i=1}^{n}(y_{i}-\mathbf{x}_{i,\gamma}^ {\top}\boldsymbol{\beta})^{2}\). Therefore, it suffices to show that \(L_{\gamma,K}(\cdot,\cdot)\) is data monotone. Let \(D=\{(\mathbf{x}_{i},y_{i})\}_{i=1}^{n}\) and \(D^{\prime}=D\cup\{\mathbf{x}_{n+1},y_{n+1}\}\). We define

\[\widehat{\boldsymbol{\beta}}_{n,\gamma}:=\arg\min_{\boldsymbol{\beta}:\| \boldsymbol{\beta}\|_{1}\leq K}\sum_{i=1}^{n}(y_{i}-\mathbf{x}_{i,\gamma}^{ \top}\boldsymbol{\beta})^{2},\]

\[\widehat{\boldsymbol{\beta}}_{n+1,\gamma}:=\arg\min_{\boldsymbol{\beta}:\| \boldsymbol{\beta}\|_{1}\leq K}\sum_{i=1}^{n+1}(y_{i}-\mathbf{x}_{i,\gamma}^{ \top}\boldsymbol{\beta})^{2}.\]

Therefore, we have the following inequalities:

\[L_{\gamma,K}(D^{\prime})=\sum_{i=1}^{n+1}(y_{i}-\mathbf{x}_{i,\gamma}^{\top} \widehat{\boldsymbol{\beta}}_{n+1,\gamma})^{2}\geq\sum_{i=1}^{n}(y_{i}- \mathbf{x}_{i,\gamma}^{\top}\widehat{\boldsymbol{\beta}}_{n+1,\gamma})^{2} \geq\sum_{i=1}^{n}(y_{i}-\mathbf{x}_{i,\gamma}^{\top}\widehat{\boldsymbol{ \beta}}_{n,\gamma})^{2}=L_{\gamma,K}(D).\]

The above inequalities conclude the proof.

### Proof of Sensitivity Bound (Lemma 3.3)

Let \((\mathbf{X},\mathbf{y})\) and \((\tilde{\mathbf{X}},\tilde{\mathbf{y}})\) be two neighboring datasets with \(n\) and \(n+1\) observation respectively. For a subset \(\gamma\in\mathcal{A}_{s}\cup\{\gamma^{*}\}\), consider the OLS estimators as follows:

\[\boldsymbol{\beta}_{\gamma,K}:=\arg\min_{\boldsymbol{\theta}:\| \boldsymbol{\theta}\|_{1}\leq K}\left\|\mathbf{y}-\mathbf{X}_{\gamma} \boldsymbol{\theta}\right\|_{2}^{2},\quad\text{and}\quad\widehat{\boldsymbol{ \beta}}_{\gamma,K}:=\arg\min_{\boldsymbol{\theta}:\|\boldsymbol{\theta}\|_{1} \leq K}\left\|\tilde{\mathbf{y}}-\tilde{\mathbf{X}}_{\gamma}\boldsymbol{ \theta}\right\|_{2}^{2}.\]

From the definition of the score function \(u(\gamma;\mathbf{X},\mathbf{y})\), we have

\[u(\gamma;\mathbf{X},\mathbf{y}) =-\sum_{i=1}^{n}(y_{i}-\mathbf{x}_{i,\gamma}^{\top}\boldsymbol{ \beta}_{\gamma,K})^{2}\] \[u(\gamma;\tilde{\mathbf{X}},\tilde{\mathbf{y}}) =-\sum_{i=1}^{n}(y_{i}-\mathbf{x}_{i,\gamma}^{\top}\tilde{ \boldsymbol{\beta}}_{\gamma,K})^{2}-(\tilde{\mathbf{y}}_{n+1}-\tilde{\mathbf{ x}}_{n+1,\gamma}^{\top}\tilde{\boldsymbol{\beta}}_{\gamma,K})^{2}.\]

By the property of the OLS estimators, we have

\[u(\gamma;\mathbf{X},\mathbf{y})-u(\gamma;\tilde{\mathbf{X}}, \tilde{\mathbf{y}})\] \[=\sum_{i=1}^{n}(y_{i}-\mathbf{x}_{i,\gamma}^{\top}\tilde{ \boldsymbol{\beta}}_{\gamma,K})^{2}+(\tilde{y}_{n+1}-\tilde{\mathbf{x}}_{n+1, \gamma}^{\top}\tilde{\boldsymbol{\beta}}_{\gamma,K})^{2}-\sum_{i=1}^{n}(y_{i}- \mathbf{x}_{i,\gamma}^{\top}\boldsymbol{\beta}_{\gamma,K})^{2}\] \[\leq\sum_{i=1}^{n}(y_{i}-\mathbf{x}_{i,\gamma}^{\top}\boldsymbol{ \beta}_{\gamma,K})^{2}+(\tilde{y}_{n+1}-\tilde{\mathbf{x}}_{n+1,\gamma}^{\top} \boldsymbol{\beta}_{\gamma,K})^{2}-\sum_{i=1}^{n}(y_{i}-\mathbf{x}_{i,\gamma}^ {\top}\boldsymbol{\beta}_{\gamma,K})^{2}\] \[=(\tilde{y}_{n+1}-\tilde{\mathbf{x}}_{n+1,\gamma}^{\top}\boldsymbol {\beta}_{\gamma,K})^{2}\] \[\leq(r+x_{\text{max}}K)^{2}.\]

Similarly, we have \(u(\gamma;\tilde{\mathbf{X}},\tilde{\mathbf{y}})-u(\gamma;\mathbf{X},\mathbf{y })\leq(r+x_{\text{max}}K)^{2}\). Next, the \((\varepsilon,0)\)-DP follows from Lemma 2.2. This finishes the proof.

### Proof of Utility Guarantee (Theorem 3.5)

Consider the notation in Section B.1 and recall the event \(\mathcal{E}_{K}:=\cap_{\gamma:\gamma\in\mathcal{A}_{s}}\{\boldsymbol{\beta}_{ \gamma,K}=\boldsymbol{\beta}_{\gamma,ols}\}\). We will For notational brevity, we use \(L_{\gamma}\) to denote \(L_{\gamma}(\mathbf{X},\mathbf{y})\). Now, we restrict ourselves to the event \(\mathcal{E}_{K}\). therefore we have \(L_{\gamma,K}=L_{\gamma}\) for all \(\gamma\). To establish a lower bound \(\pi(\gamma^{*})\), we make use of its specific form, thereby obtaining the following inequality:\[\pi(\gamma^{*})=\frac{1}{1+\sum_{\gamma^{\prime}\in\mathscr{A}_{s}}\exp\left\{- \frac{\varepsilon(L_{\gamma^{\prime}}-L_{\gamma^{*}})}{\Delta u}\right\}}.\]

Now we fix \(k\in[s]\), and consider any \(\gamma\in\mathscr{A}_{s,k}\). For any \(\eta\in[0,1]\), note that

\[n^{-1}(L_{\gamma}-L_{\gamma^{*}})=n^{-1}\{\mathbf{y}^{\top}( \mathbb{I}_{n}-\mathbf{\Phi}_{\gamma})\mathbf{y}-\mathbf{y}^{\top}(\mathbb{I}_ {n}-\mathbf{\Phi}_{\gamma^{*}})\mathbf{y}\}\] \[=n^{-1}\left\{(\mathbf{X}_{\gamma^{*}\backslash\gamma}\boldsymbol {\beta}_{\gamma^{*}\backslash\gamma}+\mathbf{w})^{\top}(\mathbb{I}_{n}- \mathbf{\Phi}_{\gamma})(\mathbf{X}_{\gamma^{*}\backslash\gamma}\boldsymbol{ \beta}_{\gamma^{*}\backslash\gamma}+\mathbf{w})-\mathbf{w}^{\top}(\mathbb{I}_ {n}-\mathbf{\Phi}_{\gamma^{*}})\mathbf{w}\right\}\] \[=\eta\boldsymbol{\beta}_{\gamma^{*}\backslash\gamma}^{\top} \Gamma(\gamma)\boldsymbol{\beta}_{\gamma^{*}\backslash\gamma}+2^{-1}(1-\eta) \boldsymbol{\beta}_{\gamma^{*}\backslash\gamma}^{\top}\Gamma(\gamma) \boldsymbol{\beta}_{\gamma^{*}\backslash\gamma}-2\left\{n^{-1}(\mathbb{I}_{n} -\mathbf{\Phi}_{\gamma})\mathbf{X}_{\gamma^{*}\backslash\gamma}\boldsymbol{ \beta}_{\gamma^{*}\backslash\gamma}\right\}^{\top}(-\mathbf{w})\] \[\quad+2^{-1}(1-\eta)\boldsymbol{\beta}_{\gamma^{*}\backslash \gamma}^{\top}\Gamma(\gamma)\boldsymbol{\beta}_{\gamma^{*}\backslash\gamma}-n ^{-1}\mathbf{w}^{\top}(\mathbf{\Phi}_{\gamma}-\mathbf{\Phi}_{\gamma^{*}}) \mathbf{w}.\]

Consider the random variable Following the analysis of Theorem 2.1 in [17], we have

\[\mathbb{P}\left[\max_{\gamma\in\mathscr{A}_{s,k}}\left|2n^{-1}\{(\mathbb{I}_ {n}-\mathbf{\Phi}_{\gamma})\mathbf{X}_{\gamma^{*}\backslash\gamma}\boldsymbol{ \beta}_{\gamma^{*}\backslash\gamma}\}^{\top}\mathbf{w}\right|\geq 2^{-1}(1-\eta) \boldsymbol{\beta}_{\gamma^{*}\backslash\gamma}^{\top}\Gamma(\gamma) \boldsymbol{\beta}_{\gamma^{*}\backslash\gamma}\right]\leq 2e^{-6k\log p},\]

and,

\[\mathbb{P}\left[\max_{\gamma\in\mathscr{A}_{s,k}}n^{-1}\left|\mathbf{w}^{ \top}(\mathbf{\Phi}_{\gamma}-\mathbf{\Phi}_{\gamma^{*}})\mathbf{w}\right| \geq 2^{-1}(1-\eta)\boldsymbol{\beta}_{\gamma^{*}\backslash\gamma}^{\top} \Gamma(\gamma)\boldsymbol{\beta}_{\gamma^{*}\backslash\gamma}\right]\leq 4e^{-2k\log p},\]

whenever

\[\frac{\min_{\gamma\in\mathscr{A}_{s,k}}\boldsymbol{\beta}_{\gamma^{*} \backslash\gamma}^{\top}\Gamma(\gamma)\boldsymbol{\beta}_{\gamma^{*} \backslash\gamma}}{k}\geq C\sigma^{2}\left\{\frac{\log p}{n(1-\eta)}\right\}\]

for large enough universal constant \(C>0\). Setting \(\eta=1/2\), we note that whenever \(\mathfrak{m}_{*}(s)\geq 2C\sigma^{2}\{(\log p)/n\}\), we get

\[n^{-1}(L_{\gamma}-L_{\gamma^{*}})\geq\frac{1}{2}\boldsymbol{\beta}_{\gamma^{ *}\backslash\gamma}^{\top}\Gamma(\gamma)\boldsymbol{\beta}_{\gamma^{*} \backslash\gamma}\geq\frac{k\mathfrak{m}_{*}(s)}{2}\quad\text{for all $\gamma\in\mathscr{A}_{s}$,}\]

with probability at least \(1-2p^{-6}-4p^{-2}\). Also, note that \(\boldsymbol{\beta}_{\gamma^{*}\backslash\gamma}^{\top}\Gamma(\gamma) \boldsymbol{\beta}_{\gamma^{*}\backslash\gamma}\leq\kappa_{+}sb_{\text{max}}^ {2}\). Hence, if we have

\[\mathfrak{m}_{*}(s)\geq\max\left\{2C,\frac{16\Delta u}{\varepsilon\sigma^{2}} \right\}\frac{\sigma^{2}\log p}{n},\]

the following are true:

\[\sum_{\gamma^{\prime}\in\mathscr{A}_{s}}\exp\left\{-\frac{ \varepsilon(L_{\gamma^{\prime}}-L_{\gamma^{*}})}{\Delta u}\right\}\] \[\leq\sum_{\gamma^{\prime}\in\mathscr{A}_{s}}\exp\left\{-\frac{nk \varepsilon\mathfrak{m}_{*}(s)}{2\Delta u}\right\}\] \[\leq\sum_{k=1}^{s}\binom{p-s}{k}\binom{s}{k}\exp\left\{-\frac{nk \varepsilon\mathfrak{m}_{*}(s)}{2\Delta u}\right\}\] \[\leq\sum_{k=1}^{s}p^{2k}.p^{-4k}\leq p^{-2}.\]

Therefore, we have

\[\min_{\gamma\in\mathscr{A}_{s}\cup\{\gamma^{*}\}}\pi(\gamma)\geq\frac{1}{1+p^ {-2}}\geq 1-p^{-2}\]

with probability \(1-2p^{-6}-4p^{-2}\). Now by the discussion in Section B.1, we have \(\mathbb{P}(\mathcal{E}_{K})\geq 1-2p^{-2}\) for \(K\geq\sqrt{s}\left\{(\frac{\kappa_{+}}{\kappa_{-}})b_{\text{max}}+(\frac{8}{ \kappa_{-}})\sigma x_{\text{max}}\right\}\). This finishes the proof.

### Proof of Lemma 4.1

For clarity, we first specify some notations. Let \(\gamma_{t}^{D}\) denote the model update of MH chain run over dataset \(D\). Let \(\tau_{\eta}^{D}\) be the corresponding \(\eta\)-mixing time. Let \(D\) and \(D^{\prime}\) be two neighboring datasets, and \(\pi^{D}\) and \(\pi^{D^{\prime}}\) be the corresponding probability mass functions for the exponential mechanism. Then, we have the following:

\[\mathbb{P}(\gamma_{\tau_{\eta}^{D}}^{D}=\gamma) \leq\pi^{D}(\gamma)+\eta\] \[\leq e^{\varepsilon}\pi^{D^{\prime}}(\gamma)+\eta\] \[\leq e^{\varepsilon}\mathbb{P}(\gamma_{\tau_{\eta}^{D^{\prime}}}^ {D^{\prime}}=\gamma)+\eta(1+e^{\varepsilon}).\]

This finishes the proof.

### Proof of Mixing Time (Theorem 4.3)

We again restrict ourselves to the event \(\mathcal{E}_{K}\) with \(K\geq\sqrt{s}\left\{(\frac{\kappa_{+}}{\kappa_{-}})b_{\mathsf{max}}+(\frac{8 }{\kappa_{-}})\sigma x_{\mathsf{max}}\right\}\). For the proof, let \(\widetilde{\mathbf{P}}\) denote the transition matrix of the original Metropolis-Hastings sampler (10). In this case, the state space is \(\mathscr{S}=\mathscr{A}_{s}\cup\{\gamma^{*}\}\). Now consider the transition matrix \(\mathbf{P}=\widetilde{\mathbf{P}}/2+\mathbb{I}_{n}/2\), corresponding to the lazy version of the random walk that stays in its current position with a probability of at least 1/2. Due to the construction, the smallest eigenvalue of \(\mathbf{P}\) is always non-negative, and the mixing time of the chain is completely determined by the second largest eigenvalue \(\lambda_{2}\) of \(\mathbf{P}\). To this end, we define the spectral gap \(\mathsf{Gap}(\mathbf{P})=1-\lambda_{2}\), and for any lazy Markov chain, we have the following sandwich relation [41, 50]

\[\frac{1}{2}\frac{(1-\mathsf{Gap}(\mathbf{P}))}{\mathsf{Gap}(\mathbf{P})}\log( 1/(2\eta))\leq\tau_{\eta}\leq\frac{\log[1/\min_{\gamma\in\mathscr{S}}\pi( \gamma)]+\log(1/\eta)}{\mathsf{Gap}(\mathbf{P})}.\] (15)

**Lower Bound on \(\pi(\cdot)\)** :

To establish a lower bound on the target distribution in (7), we make use of its specific form, thereby obtaining the following inequality:

\[\pi(\gamma) =\pi(\gamma^{*}).\frac{\pi(\gamma)}{\pi(\gamma^{*})}\] \[=\frac{1}{1+\sum_{\gamma^{\prime}\in\mathscr{A}_{s}}\exp\left\{- \frac{\varepsilon(L_{\gamma^{\prime}}-L_{\gamma^{*}})}{\Delta u}\right\}}. \exp\left\{-\frac{\varepsilon(L_{\gamma}-L_{\gamma^{*}})}{\Delta u}\right\}.\]

Now we fix \(k\in[s]\), and and consider any \(\gamma\in\mathscr{A}_{s,k}\).

Similar to the proof of Section A.3, we note that whenever \(\mathfrak{m}_{*}(s)\geq 2C\sigma^{2}\{(\log p)/n\}\) for a large enough universal constant \(C>0\), we get

\[\frac{3}{2}\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}^{\top}\Gamma( \gamma)\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}\geq n^{-1}(L_{\gamma}-L_ {\gamma^{*}})\geq\frac{1}{2}\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}^{ \top}\Gamma(\gamma)\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}\geq\frac{k \mathfrak{m}_{*}(s)}{2}\quad\text{for all }\gamma\in\mathscr{A}_{s},\]

with probability at least \(1-2p^{-6}-4p^{-2}\). Also, note that \(\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}^{\top}\Gamma(\gamma) \boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}\leq\kappa_{+}sb_{\mathsf{max}}^ {2}\). Hence, if we have

\[\mathfrak{m}_{*}(s)\geq\max\left\{2C,\frac{16\Delta u}{\varepsilon\sigma^{2}} \right\}\frac{\sigma^{2}\log p}{n},\]the following are true:

\[\sum_{\gamma^{\prime}\in\mathscr{A}_{s}}\exp\left\{-\frac{\varepsilon (L_{\gamma^{\prime}}-L_{\gamma^{*}})}{\Delta u}\right\}\] \[\leq\sum_{\gamma^{\prime}\in\mathscr{A}_{s}}\exp\left\{-\frac{nk \varepsilon\mathfrak{m}_{*}(s)}{2\Delta u}\right\}\] \[\leq\sum_{k=1}^{s}\binom{p-s}{k}\binom{s}{k}\exp\left\{-\frac{nk \varepsilon\mathfrak{m}_{*}(s)}{2\Delta u}\right\}\] \[\leq\sum_{k=1}^{s}p^{2k}.p^{-4k}\leq p^{-2},\]

and,

\[\exp\left\{-\frac{\varepsilon(L_{\gamma}-L_{\gamma^{*}})}{\Delta u}\right\} \geq\exp\left\{-\frac{3n\varepsilon\boldsymbol{\beta}_{\gamma^{ \prime}\setminus\gamma}^{\top}\Gamma(\gamma)\boldsymbol{\beta}_{\gamma^{ \prime}\setminus\gamma}}{2\Delta u}\right\}\] \[\geq\exp\left\{-\frac{3ns\varepsilon\kappa_{+}b_{\text{max}}^{2} }{2\Delta u}\right\}\]

Combining these two facts we have

\[\min_{\gamma\in\mathscr{A}_{s}\cup\{\gamma^{*}\}}\pi(\gamma)\geq\frac{1}{1+p^ {-2}}\exp\left\{-\frac{3ns\varepsilon\kappa_{+}b_{\text{max}}^{2}}{2\Delta u} \right\}\geq\frac{1}{2}\exp\left\{-\frac{3ns\varepsilon\kappa_{+}b_{\text{max }}^{2}}{2\Delta u}\right\}\] (16)

with probability \(1-2p^{-6}-4p^{-2}\).

**Lower Bound on Spectral Gap:**

Now it remains to prove a lower bound on the spectral gap \(\mathsf{Gap}(\mathbf{P})\), and we do so via the canonical path argument [41]. We begin by describing the idea of a canonical path ensemble associated with a Markov chain. Given a Markov chain \(\mathcal{C}\) with state space \(\mathscr{S}\), consider the weighted directed graph \(G(\mathcal{C})=(V,E)\) with vertex set \(V=\mathscr{S}\) and the edge set \(E\) in which a ordered pair \(e=(\gamma,\gamma^{\prime})\) is included as an edge with weight \(\mathbf{Q}(e)=\mathbf{Q}(\gamma,\gamma^{\prime})=\pi(\gamma)\mathbf{P}(\gamma, \gamma^{\prime})\) iff \(\mathbf{P}(\gamma,\gamma^{\prime})>0\). A _canonical path ensemble_\(\mathcal{T}\) corresponding to \(\mathcal{C}\) is a collection of paths that contains, for each ordered pair \((\gamma,\gamma^{\prime})\) of distinct vertices, a unique simple path \(T_{\gamma,\gamma^{\prime}}\) connecting \(\gamma\) and \(\gamma^{\prime}\). We refer to any path in the ensemble \(\mathcal{T}\) as a canonical path.

[41] shows that for any reversible Markov chain and nay choice of a canonical path ensemble \(\mathcal{T}\), the spectral gap of \(\mathbf{P}\) is lower bounded as

\[\mathsf{Gap}(\mathbf{P})\geq\frac{1}{\rho(\mathcal{T})\ell(\mathcal{T})},\] (17)

where \(\ell(\mathcal{T})\) corresponds to the length of the longest path in the ensemble \(\mathcal{T}\), and the quantity \(\rho(\mathcal{T}):=\max_{e\in E}\frac{1}{Q(e)}\sum_{(\gamma,\gamma^{\prime}): e\in T_{\gamma,\gamma^{\prime}}}\pi(\gamma)\pi(\gamma^{\prime})\) is known as the _path congestion parameter_.

Thus, it boils down to the construction of a suitable canonical path ensemble \(\mathcal{T}\). Before going into further details, we introduce some working notations. For any two given paths \(T_{1}\) and \(T_{2}\):

* Their intersection \(T_{1}\cap T_{2}\) denotes the collection of overlapping edges.
* If \(T_{2}\subset T_{1}\), then \(T_{1}\setminus T_{2}\) denotes the path obtained by removing all the edges of \(T_{2}\) from \(T_{1}\).
* We use \(\bar{T}_{1}\) to denote the reverse of \(T_{1}\).
* If the endpoint of \(T_{1}\) is same as the starting point of \(T_{2}\), then \(T_{1}\cup T_{2}\) denotes the path obtained by joining \(T_{1}\) and \(T_{2}\) at that point.

We will now shift focus toward the construction of the canonical path ensemble. At a high level, our construction follows the same scheme as in [51].

### Canonical path ensemble construction:

First, we need to construct the canonical path \(T_{\gamma,\gamma^{*}}\) from any \(\gamma\in\mathscr{S}\) to the true model \(\gamma^{*}\). To this end, we introduce the concept of _memoryless_ paths. We call a set \(\mathcal{T}_{M}\) of canonical paths memoryless with respect to the central state \(\gamma^{*}\) if

1. for any state \(\gamma\in\mathscr{S}\) satisfying \(\gamma\neq\gamma^{*}\), there exists a unique simple path \(T_{\gamma,\gamma^{*}}\) in \(\mathcal{T}_{M}\) connecting \(\gamma\) and \(\gamma^{*}\);
2. for any intermediate state \(\tilde{\gamma}\in\mathscr{S}\) on any path \(T_{\gamma,\gamma^{*}}\in\mathcal{T}_{M}\), the unique path connecting \(\tilde{\gamma}\) and \(\gamma^{*}\) is the sub-path of \(T_{\gamma,\gamma^{*}}\) starting from \(\tilde{\gamma}\) and ending at \(\gamma^{*}\).

Intuitively, this memoryless property tells that for any intermediate step in any canonical path, the next step towards the central state does not depend on history. Specifically, the memoryless canonical path ensemble has the property that in order to specify the canonical path connecting any state \(\gamma\in\mathscr{S}\) and the central state \(\gamma^{*}\), we only need to specify the next state from \(\gamma\in\mathscr{S}\setminus\{\gamma^{*}\}\), i.e., we need a transition function \(\mathcal{G}:\mathscr{S}\setminus\{\gamma^{*}\}\to\mathscr{S}\) that maps the current state \(\gamma\) to the next state. For simplicity, we define \(\mathcal{G}(\gamma^{*})=\gamma^{*}\) to make \(\mathscr{S}\) as the domain of \(\mathcal{G}\). For a more detailed discussion, we point the readers to Section 4 of [51]. We now state a useful lemma that is pivotal to the construction of the canonical path ensemble.

**Lemma A.1** ([51]).: _If a function \(\mathcal{G}:\mathscr{S}\setminus\{\gamma^{*}\}\to\mathscr{S}\) satisfies the condition \(d_{H}(\mathcal{G}(\gamma),\gamma^{*})<d_{H}(\gamma,\gamma^{*})\) for any state \(\gamma\in\mathscr{S}\setminus\{\gamma^{*}\}\), then \(\mathcal{G}\) is a valid transition map._

Using the above lemma, we will now construct the memoryless set of canonical paths from any state \(\gamma\in\mathscr{S}\) to \(\gamma^{*}\) by explicitly specifying a transition map \(\mathcal{G}\). In particular, we consider the following transition function:

* If \(\gamma\neq\gamma^{*}\), we define \(\mathcal{G}(\gamma)\) to be \(\gamma^{\prime}\), whch is formed by replacing the least influential covariate in \(\gamma\) with most influential covariate in \(\gamma^{*}\setminus\gamma\). In notations, we have \(\gamma_{j}^{\prime}=\gamma_{j}\) for all \(j\notin\{j_{\gamma},k_{\gamma}\}\), \(\gamma_{j_{\gamma}}^{\prime}=1\) and \(\gamma_{k_{\gamma}}^{\prime}=0\), where \(j_{\gamma}:=\operatorname*{arg\,max}_{j\in\gamma^{*}\setminus\gamma}\left\| \mathbf{\Phi}_{\gamma\cup\{j\}}\mathbf{X}_{\gamma^{*}}\mathbf{\beta}_{\gamma^ {*}}\right\|_{2}^{2}\) and \(k_{\gamma}:=\operatorname*{arg\,min}_{k\in\gamma\setminus\gamma^{*}}\left\| \mathbf{\Phi}_{\gamma\cup\{j\}}\mathbf{X}_{\gamma^{*}}\mathbf{\beta}_{\gamma^ {*}}\right\|_{2}^{2}-\left\|\mathbf{\Phi}_{\gamma\cup\{j\}\setminus\{k\}} \mathbf{X}_{\gamma^{*}}\mathbf{\beta}_{\gamma^{*}}\right\|_{2}^{2}\). Thus, the transition step involves a double flip which entails that \(d_{H}(\mathcal{G}(\gamma),\gamma^{*})=d_{H}(\gamma,\gamma^{*})-2\).

Due to Lemma A.1, it follows that the above transition map \(\mathcal{G}\) is valid and gives rise to a unique memoryless set \(\mathcal{T}_{M}\) of canonical paths connecting any \(\gamma\in\mathscr{S}\) and \(\gamma^{*}\).

Based on this, we are now ready to construct the canonical path ensemble \(\mathcal{T}\). Specifically, due to memoryless property, two simple paths \(T_{\gamma,\gamma^{*}}\) and \(T_{\gamma^{\prime},\gamma^{*}}\) share an identical subpath to \(\gamma^{*}\) starting from their first common intermediate state. Let \(T_{\gamma\cap\gamma^{*}}\) denote the common sub-path \(T_{\gamma\cap\gamma^{*}}\cap T_{\gamma^{\prime}\cap\gamma*}\), and \(T_{\gamma\setminus\gamma^{\prime}}:=T_{\gamma,\gamma^{*}}\setminus T_{\gamma \cap\gamma^{\prime}}\) denotes the remaining path of \(T_{\gamma,\gamma^{*}}\) after removing the segment \(T_{\gamma\cap\gamma^{\prime}}\). The path \(T_{\gamma^{\prime}\setminus\gamma}\) is defined in a similar way. Then it follows that \(T_{\gamma\setminus\gamma^{\prime}}\) and \(T_{\gamma^{\prime}\setminus\gamma}\) have the same endpoint. Therefore, it is allowed to consider the path \(T_{\gamma\setminus\gamma^{\prime}}\cup\bar{T}_{\gamma^{\prime}\setminus\gamma}\).

We call \(\gamma\) a _precedent_ of \(\gamma^{\prime}\) if \(\gamma^{\prime}\) is on the canonical path \(T_{\gamma,\gamma^{*}}\in\mathcal{T}\), and a pair of states \(\gamma,\gamma^{\prime}\) are _adjacent_ if the canonical path \(T_{\gamma,\gamma^{\prime}}\) is \(e_{\gamma,\gamma^{\prime}}\), the edge connecting \(\gamma\) and \(\gamma^{\prime}\). Next, for \(\gamma\in\mathscr{S}\), define

\[\Lambda(\gamma):=\{\tilde{\gamma}\mid\gamma\in T_{\tilde{\gamma},\gamma^{*}}\}\] (18)

denote the set of all precedents. We denote by \(|T|\) the length of the path \(T\). The following lemma provides some important properties of the previously constructed canonical path ensemble.

**Lemma A.2**.: _For any distinct pair \((\gamma,\gamma^{\prime})\in\mathscr{S}\times\mathscr{S}\):_

1. _We have_ \[|T_{\gamma,\gamma^{*}}|\leq d_{H}(\gamma,\gamma^{*})/2\leq s,\quad\text{and}\] \[|T_{\gamma,\gamma^{\prime}}|\leq\frac{1}{2}\{d_{H}(\gamma,\gamma^{*})+d_{H}( \gamma^{\prime},\gamma^{*})\}\leq 2s.\]
2. _If_ \(\gamma\) _and_ \(\gamma^{\prime}\) _are adjacent and_ \(\gamma\) _is precedent of of_ \(\gamma^{\prime}\)_, then_ \[\{(\tilde{\gamma},\tilde{\gamma}^{\prime})\mid e_{\gamma,\gamma^{\prime}}\in T _{\tilde{\gamma},\tilde{\gamma}^{\prime}}\}\subset\Lambda(\gamma)\times\mathscr{ S}.\]Proof.: For the first claim, let us first assume that \(|T_{\gamma,\gamma^{*}}|=k\), i.e., \(\mathcal{G}^{k}(\gamma)=\gamma^{*}\) for the appropriate transition map \(\mathcal{G}\). Also, recall that \(|\gamma|=|\gamma^{*}|=s\). Hence, due to an elementary iterative argument, it follows that

\[2s\geq d_{H}(\gamma,\gamma^{*}) =d_{H}(\mathcal{G}(\gamma),\gamma^{*})+2\] \[=d_{H}(\mathcal{G}^{2}(\gamma),\gamma^{*})+4\] \[\quad\vdots\] \[=2k.\]

Also, note that \(|T_{\gamma,\gamma^{\prime}}|\leq|T_{\gamma,\gamma^{*}}|+|T_{\gamma^{\prime}, \gamma^{*}}|\). Hence, the claim follows using the previous inequality.

For the second claim, note that for any pair \((\bar{\gamma},\bar{\gamma}^{\prime})\) such that \(T_{\bar{\gamma},\bar{\gamma}^{\prime}}\ni e_{\gamma,\gamma^{\prime}}\), we have two possible options : (i) \(e_{\gamma,\gamma^{\prime}}\in T_{\bar{\gamma}\setminus\bar{\gamma}^{\prime}}\), or (ii) \(e_{\gamma,\gamma^{\prime}}\in T_{\bar{\gamma}^{\prime}\setminus\bar{\gamma}}\). As \(\gamma\) is precedent of \(\gamma^{\prime}\), the only possibility that we have is \(e_{\gamma,\gamma^{\prime}}\in T_{\gamma\setminus\gamma^{\prime}}\). This shows that \(\gamma\) belongs to the path \(T_{\bar{\gamma},\gamma^{*}}\) and \(\bar{\gamma}\in\Lambda(\gamma)\). 

According to Lemma A.2(b), the path congestion parameter \(\rho(T)\) satisfies

\[\rho(T)\leq\max_{(\gamma,\gamma^{\prime})\in\Gamma}\frac{1}{\mathbf{Q}(\gamma, \gamma^{\prime})}\sum_{\bar{\gamma}\in\Lambda(\gamma),\bar{\gamma}^{\prime}\in \mathscr{S}}\pi(\bar{\gamma})\pi(\bar{\gamma}^{\prime})=\max_{(\gamma,\gamma^ {\prime})\in\Gamma_{*}}\frac{\pi[\Lambda(\gamma)]}{\mathbf{Q}(\gamma,\gamma^{ \prime})},\] (19)

where the set \(\Gamma_{*}:=\{(\gamma,\gamma^{\prime})\in\mathscr{S}\times\mathscr{S}\mid T_{ \gamma,\gamma^{\prime}}=e_{\gamma,\gamma^{\prime}},\gamma\in\Lambda(\gamma^{ \prime})\}\). Here we used the fact that the weight function \(\mathbf{Q}\) satisfies the reversibility condition \(\mathbf{Q}(\gamma,\gamma^{\prime})=\mathbf{Q}(\gamma^{\prime},\gamma)\) in order to restrict the range of the maximum to pairs \((\gamma,\gamma^{\prime})\) where \(\gamma\in\Lambda(\gamma^{\prime})\).

For the lazy form of the Metropolis-Hastings walk (10), we have

\[\mathbf{Q}(\gamma,\gamma^{\prime}) =\pi(\gamma)\mathbf{P}(\gamma,\gamma^{\prime})\] \[\geq\frac{1}{ps}\pi(\gamma)\min\left\{1,\frac{\pi(\gamma^{\prime })}{\pi(\gamma)}\right\}\geq\frac{1}{ps}\min\left\{\pi(\gamma),\pi(\gamma^{ \prime})\right\}.\]

Substituting this bound in (19), we get

\[\rho(T) \leq ps\max_{(\gamma,\gamma^{\prime})\in\Gamma_{*}}\frac{\pi( \Lambda(\gamma))}{\min\{\pi(\gamma),\pi(\gamma^{\prime})\}}\] (20) \[=ps\max_{(\gamma,\gamma^{\prime})\in\Gamma_{*}}\left\{\max\left\{ 1,\frac{\pi(\gamma)}{\pi(\gamma^{\prime})}\right\}\cdot\frac{\pi(\Lambda( \gamma))}{\pi(\gamma)}\right\}.\]

In order to prove that \(\rho(T)=O(ps)\) with high probability, it is sufficient to prove that the two terms inside the maximum are \(O(1)\). To this end, we introduce two useful lemmas.

**Lemma A.3**.: _Consider the event_

\[\mathcal{A}_{n}=\left\{\max_{\gamma\in\mathscr{S},\ell\notin\gamma}\mathbf{w }^{\top}(\mathbf{\Phi}_{\gamma\cup\{\ell\}}-\mathbf{\Phi}_{\gamma})\mathbf{w} \leq 12\sigma^{2}s\log p\right\}\]

_Then we have \(\mathbb{P}(\mathcal{A}_{n})\geq 1-p^{-2}\)._

Proof.: First note that \(\mathbf{w}^{\top}(\mathbf{\Phi}_{\gamma\cup\{\ell\}}-\mathbf{\Phi}_{\gamma}) \mathbf{w}=(\mathbf{h}_{\gamma,\ell}^{\top}\mathbf{w})^{2}\) for an appropriate unit vector \(\mathbf{h}_{\gamma,\ell}\) depending only upon \(\mathbf{X}_{\gamma}\) and \(\mathbf{X}_{\ell}\). By Sub-gaussian tail inequality, we have

\[\mathbb{P}\left\{(\mathbf{h}_{\gamma,\ell}^{\top}\mathbf{w})^{2}\geq t\right\} \leq 2e^{-\frac{t}{2\sigma^{2}}}.\]

Setting \(t=12\sigma^{2}s\log p\) and applying an union bound we get

\[\mathbb{P}\left\{\max_{\gamma\in\mathscr{S},\ell\notin\gamma}( \mathbf{h}_{\gamma,\ell}^{\top}\mathbf{w})^{2}\geq 12\sigma^{2}s\log p\right\} \leq 2\binom{p}{s}(p-s)p^{-6s}\] \[\leq 2p^{-3s}\] \[\leq p^{-2}.\]

**Lemma A.4**.: _Suppose that, in addition to the conditions in Theorem 4.3, the event \(\mathcal{A}_{n}\) holds. Then for all \(\gamma\neq\gamma^{*}\), we have_

\[\frac{\pi(\gamma)}{\pi(\mathcal{G}(\gamma))}\leq p^{-3}.\]

_Moreover, for all \(\gamma\),_

\[\frac{\pi[\Lambda(\gamma)]}{\pi(\gamma)}\leq 2.\]

Therefore, both Lemma A.3 and Lemma A.4 give \(\rho(T)\leq 2ps\) with probability \(1-p^{-2}\). Lemma A.2(a) suggests that \(\ell(T)\leq 2s\). Therefore, Equation (17) shows that \(\mathsf{Gap}(\mathbf{P})\geq\frac{1}{4ps^{2}}\) with probability \(1-p^{-2}\). Finally, combining (16) and (15), we get the following with \(1-8p^{-2}\)

\[\tau_{\eta}\leq C_{2}ps^{2}\left(\frac{n\varepsilon\kappa_{+}b_{\mathsf{max}} ^{2}}{\left\{r+(\frac{\kappa_{+}}{\kappa_{-}})b_{\mathsf{max}};r_{\mathsf{max }}+(\frac{\sigma}{\kappa_{-}})x_{\mathsf{max}}^{2}\right\}^{2}}+\log(1/\eta) \right),\]

where \(C_{2}>0\) is a universal constant. Finally, the proof is concluded by arguing that \(\mathbb{P}(\mathcal{E}_{K}^{c})\leq 2p^{-2}\).

## Appendix B Proof of Auxiliary Results

### Constrained problem to unconstrained OLS problem

Now we are ready to bound \(\left\|\bm{\beta}_{\gamma,K}\right\|_{1}\). Define the OLS estimator corresponding to the model \(\gamma\) as

\[\bm{\beta}_{\gamma,ols}=(\underbrace{\frac{\mathbf{X}_{\gamma}^{\top}\mathbf{ X}_{\gamma}}{n})^{-1}\underbrace{\mathbf{X}_{\gamma}^{\top}\mathbf{X}_{\gamma^{*}} \bm{\beta}_{\gamma^{*}}}_{:=\mathbf{u}_{1}}}_{:=\mathbf{u}_{1}}+(\underbrace{ \mathbf{X}_{\gamma}^{\top}\mathbf{X}_{\gamma}}_{:})^{-1}\underbrace{\mathbf{X }_{\gamma}^{\top}\mathbf{w}}_{:=\mathbf{u}_{2}}.\]

In this section, we will show that there exists a choice for \(K\) such that the event \(\mathcal{E}_{K}:=\cap_{\gamma:|\gamma|=s}\{\bm{\beta}_{\gamma,ols}=\bm{\beta}_ {\gamma,K}\}\) holds with high probability. By Holder's inequality we have \(\left\|\mathbf{u}_{1}\right\|_{2}\leq\left\|(\mathbf{X}_{\gamma}^{\top} \mathbf{X}_{\gamma}/n)^{-1}\right\|_{\mathrm{op}}\left\|\mathbf{X}_{\gamma}^ {\top}\mathbf{X}_{\gamma^{*}}/n\right\|_{\mathrm{op}}\left\|\bm{\beta}_{ \gamma^{*}}\right\|_{2}\leq(\frac{\kappa_{+}}{\kappa_{-}})b_{\mathsf{max}}\). Hence, an application of Cauchy-Schwarz inequality directly yields that \(\left\|\mathbf{u}_{1}\right\|_{1}\leq 2(\frac{\kappa_{+}}{\kappa_{-}})\sqrt{s}b_{ \mathsf{max}}\). Next, note that

\[\left\|\mathbf{u}_{2}\right\|_{2}\leq\left\|(\frac{\mathbf{X}_{\gamma}^{\top} \mathbf{X}_{\gamma}}{n})^{-1}\right\|_{2}\left\|\frac{\mathbf{X}_{\gamma}^{ \top}\mathbf{w}}{n}\right\|_{2}\leq\sqrt{s}\left\|(\frac{\mathbf{X}_{\gamma}^ {\top}\mathbf{X}_{\gamma}}{n})^{-1}\right\|_{2}\left\|\frac{\mathbf{X}_{\gamma }^{\top}\mathbf{w}}{n}\right\|_{\infty}\leq\sqrt{s}\left\|(\frac{\mathbf{X}_{ \gamma}^{\top}\mathbf{X}_{\gamma}}{n})^{-1}\right\|_{2}\left\|\frac{\mathbf{X }_{\gamma}^{\top}\mathbf{w}}{n}\right\|_{\infty}.\]

Therefore, we get \(\left\|\mathbf{u}_{2}\right\|_{1}\leq\frac{s}{\kappa_{-}}\left\|\mathbf{X}^{ \top}\mathbf{w}/n\right\|_{\infty}\). In order to upper bound the last term in the previous inequality, we define \(D_{i,j}=\mathbf{X}[i,j]w_{j}\) for all \((i,j)\in[s]\times[n]\). Using the sub-Gaussian property of \(w_{j}\), we have \(\mathbb{E}(e^{\lambda w_{j}})\leq e^{\lambda x_{\mathsf{max}}^{2}\sigma^{2}/2}\). Therefore, due to Hoeffding's inequality, we have

\[\mathbb{P}\left(\frac{1}{n}\big{|}\sum_{j\in[n]}D_{i,j}\big{|}\geq 8\sigma x_{ \mathsf{max}}\sqrt{\frac{\log p}{n}}\right)\leq 2p^{-4}.\]

Note that \(\left\|\mathbf{X}^{\top}\mathbf{w}/n\right\|_{\infty}=\max_{i\in[s]}n^{-1} \big{|}\sum_{j\in[n]}D_{i,j}\big{|}\). Hence, by simple union-bound argument, it follows that

\[\mathbb{P}\left(\max_{\gamma:|\gamma|=s}\left\|\frac{\mathbf{X}_{\gamma}^{\top} \mathbf{w}}{n}\right\|_{\infty}\geq 8\sigma x_{\mathsf{max}}\sqrt{\frac{\log p}{n}} \right)\leq 2p^{-4}\leq 2p^{-2}.\]

Thus, Assumption 3.4(c) yields that \(\left\|\bm{\beta}_{\gamma,K}\right\|_{1}^{2}\leq s\left\{(\frac{\kappa_{+}}{ \kappa_{-}})b_{\mathsf{max}}+(\frac{8}{\kappa_{-}})\sigma x_{\mathsf{max}} \right\}^{2}\). Therefore, if \(K\geq\sqrt{s}\left\{(\frac{\kappa_{+}}{\kappa_{-}})b_{\mathsf{max}}+(\frac{8} {\kappa_{-}})\sigma x_{\mathsf{max}}\right\}\) then \(\mathbb{P}(\mathcal{E}_{K})\geq 1-2p^{-2}\).

### Proof of Corollary 4.4

Based on Theorem 4.3, we have \(\left\|\pi_{t}-\pi\right\|_{\mathsf{TV}}\leq eta\) with probability at least \(1-c_{2}p^{-2}\) whenever \(t\) is sufficiently large. Also, by Theorem 3.5, we know \(\pi(\gamma^{*})\geq 1-p^{-2}\) with probability \(1-c_{1}p^{-2}\). Therefore, we have \(\pi_{t}(\gamma^{*})\geq 1-\eta-p^{-2}\) with probability at least \(1-(c_{1}+c_{2})p^{-2}\). This finishes the proof.

Proof of Lemma A.4

**part (a):**

Let \(j_{\gamma},k_{\gamma}\) be the indices defined in the construction of \(\mathcal{G}(\gamma)\). The we have \(\gamma^{\prime}=\gamma\cup\{j_{\gamma}\}\setminus\{k_{\gamma}\}\). Let \(\mathbf{v}_{1}=(\mathbf{\Phi}_{\gamma\cup\{j_{\gamma}\}}-\mathbf{\Phi}_{\gamma })\mathbf{X}_{\gamma^{*}}\mathbf{\beta}_{\gamma^{*}}\) and \(\mathbf{v}_{2}=(\mathbf{\Phi}_{\gamma\cup\{j_{\gamma}\}}-\mathbf{\Phi}_{\gamma ^{\prime}})\mathbf{X}_{\gamma^{*}}\mathbf{\beta}_{\gamma^{*}}\). Then Lemma C.1 guarantees that

\[\left\|\mathbf{v}_{1}\right\|_{2}^{2}\geq n\kappa_{-}\mathfrak{m}_{*}(s), \quad\text{and}\quad\left\|\mathbf{v}_{2}\right\|_{2}^{2}\leq n\kappa_{-} \mathfrak{m}_{*}(s)/2.\] (21)

By the form in (7), we have

\[\frac{\pi(\gamma)}{\pi(\gamma^{\prime})}=\exp\left\{-\frac{\mathbf{y}^{\top} (\mathbf{\Phi}_{\gamma^{\prime}}-\mathbf{\Phi}_{\gamma})\mathbf{y}}{(\Delta u /\varepsilon)}\right\}.\]

To show that the above ration is \(O(1)\), it suffices to show that \(\mathbf{y}^{\top}(\mathbf{\Phi}_{\gamma^{\prime}}-\mathbf{\Phi}_{\gamma}) \mathbf{y}\) is large. By simple algebra, it follows that

\[\mathbf{y}^{\top}(\mathbf{\Phi}_{\gamma^{\prime}}-\mathbf{\Phi}_ {\gamma})\mathbf{y}=\mathbf{y}^{\top}(\mathbf{\Phi}_{\gamma\cup\{j_{\gamma}\}} -\mathbf{\Phi}_{\gamma})\mathbf{y}-\mathbf{y}^{\top}(\mathbf{\Phi}_{\gamma \cup\{j_{\gamma}\}}-\mathbf{\Phi}_{\gamma^{\prime}})\mathbf{y}\] \[=\left\|\mathbf{v}_{1}\right\|_{2}^{2}+2\mathbf{v}_{1}^{\top} \mathbf{w}+\mathbf{w}^{\top}(\mathbf{\Phi}_{\gamma\cup\{j_{\gamma}\}}- \mathbf{\Phi}_{\gamma})\mathbf{w}-\left\{\left\|\mathbf{v}_{2}\right\|_{2}^{2 }+2\mathbf{v}_{2}^{\top}\mathbf{w}+\mathbf{w}^{\top}(\mathbf{\Phi}_{\gamma \cup\{j_{\gamma}\}}-\mathbf{\Phi}_{\gamma^{\prime}})\mathbf{w}\right\}\] \[=\left\|\mathbf{v}_{1}\right\|_{2}^{2}+2\mathbf{v}_{1}^{\top}( \mathbf{\Phi}_{\gamma\cup\{j_{\gamma}\}}-\mathbf{\Phi}_{\gamma})\mathbf{w}+ \mathbf{w}^{\top}(\mathbf{\Phi}_{\gamma\cup\{j_{\gamma}\}}-\mathbf{\Phi}_{ \gamma})\mathbf{w}\] \[\geq\left\|\mathbf{v}_{1}\right\|_{2}\left(\left\|\mathbf{v}_{1} \right\|_{2}-2\left\|(\mathbf{\Phi}_{\gamma\cup\{j_{\gamma}\}}-\mathbf{\Phi}_{ \gamma})\mathbf{w}\right\|_{2}\right)-\left\|\mathbf{v}_{2}\right\|_{2}( \left\|\mathbf{v}_{2}\right\|_{2}+2\left\|(\mathbf{\Phi}_{\gamma\cup\{j_{ \gamma}\}}-\mathbf{\Phi}_{\gamma^{\prime}})\mathbf{w}\right\|_{2})\] \[\quad-\left\|(\mathbf{\Phi}_{\gamma\cup\{j_{\gamma}\}}-\mathbf{ \Phi}_{\gamma^{\prime}})\mathbf{w}\right\|_{2}^{2}.\] (22)

Now, we recall the event

\[\mathcal{A}_{n}=\left\{\max_{\gamma\in\mathscr{S},\ell\notin\gamma}\mathbf{w} ^{\top}(\mathbf{\Phi}_{\gamma\cup\{\ell\}}-\mathbf{\Phi}_{\gamma})\mathbf{w} \leq 12\sigma^{2}s\log p\right\}.\]

Let \(A^{2}:=n\kappa_{-}\mathfrak{m}_{*}(s)\geq\kappa_{-}C_{0}\sigma^{2}\log p\). Then for \(C_{0}\) large enough so that \(\kappa_{-}C_{0}\geq(128\times 12)s\), Equation (22) leads to the following inequality under event \(\mathcal{A}_{n}\):

\[\mathbf{y}^{\top}(\mathbf{\Phi}_{\gamma^{\prime}}-\mathbf{\Phi}_{\gamma}) \mathbf{y}\geq A(A-A/4)-(A/\sqrt{2})(A/\sqrt{2}+A/4)-A^{2}/16\geq A/8.\]

This readily yields that

\[\frac{\pi(\gamma)}{\pi(\gamma^{\prime})}\leq\exp\left\{-\frac{n\kappa_{-} \mathfrak{m}_{*}(s)}{(16\Delta u/\varepsilon)}\right\}\leq p^{-3}\] (23)

under the margin condition of Theorem 4.3.

**Part (b):**

From the previous part, the bound (23) implies that \(\pi(\gamma)/\pi(\mathcal{G}(\gamma))\leq p^{-3}\). For each \(\bar{\gamma}\in\Lambda(\gamma)\), we have that \(\gamma\in T_{\bar{\gamma},\gamma}\subset T_{\bar{\gamma},\gamma^{*}}\). Let the path \(T_{\bar{\gamma},\gamma}\) be \(\gamma_{0}\to\gamma_{1}\to\ldots\to\gamma_{k}\), where \(k=|T_{\bar{\gamma},\gamma}|\) is the length of the path, and \(\gamma_{0}=\bar{\gamma}\) and \(\gamma_{k}=\gamma\) are the two endpoints. Now note that \(\{\gamma_{\ell}\}_{\ell\leq k-1}\subset\mathscr{S}\), and (23) ensures that

\[\frac{\pi(\bar{\gamma})}{\pi(\gamma)}=\prod_{\ell=1}^{k}\frac{\pi(\gamma_{\ell-1 })}{\pi(\gamma_{\ell})}\leq p^{-3k}.\]

Also, by Lemma A.2(a) we have \(k\in[s]\). Now, we count the total number of sets in \(\Lambda(\gamma)\) for each \(k\in[s]\). Recall that by the construction of the canonical path, we update the current state by adding a new influential covariate and deleting one unimportant one. Hence any state in \(\mathscr{S}\) has at most \(sp\) adjacent precedents, implying that there could be at most \(s^{k}p^{k}\) distinct paths of length \(k\). This entails that

\[\frac{\pi(\Lambda(\gamma))}{\pi(\gamma)}\leq\sum_{\bar{\gamma}\in\Lambda( \gamma)}\frac{\pi(\bar{\gamma})}{\pi(\gamma)}\leq\sum_{k=1}^{s}(ps)^{k}p^{-3k} \leq\sum_{k=1}^{s}p^{-k}\leq\frac{1}{1-1/p}\leq 2.\]

### Supporting lemmas

Recall the definition of \(j_{\gamma}\) and \(k_{\gamma}\). The first result in the following lemma shows that the gain in adding \(j_{\gamma}\) to the current model \(\gamma\) is at least \(n\kappa\_\_\mathfrak{m}_{*}(s)\). The second result shows that the loss incurred by removing \(k_{\gamma}\) from the model \(\gamma\cup\{j_{\gamma}\}\) is at most \(n\kappa\_\_\mathfrak{m}_{*}(s)/2\). As a result, it follows that it is favorable to replace \(\mathbf{X}_{k_{\gamma}}\) with the more influential feature \(\mathbf{X}_{j_{\gamma}}\) in the current model \(\gamma\).

**Lemma C.1**.: _Under Assumption 3.4(b) and Assumption 4.2, the following hold for all \(\gamma\in\mathscr{A}_{s}\):_

1. \(\left\|\boldsymbol{\Phi}_{\gamma\cup\{j_{\gamma}\}}\mathbf{X}_{\gamma^{*}} \boldsymbol{\beta}_{\gamma^{*}}\right\|_{2}^{2}-\left\|\boldsymbol{\Phi}_{ \gamma}\mathbf{X}_{\gamma^{*}}\boldsymbol{\beta}_{\gamma^{*}}\right\|_{2}^{2} \geq n\kappa\_\_\mathfrak{m}_{*}(s)\)_, and_
2. \(\left\|\boldsymbol{\Phi}_{\gamma\cup\{j_{\gamma}\}}\mathbf{X}_{\gamma^{*}} \boldsymbol{\beta}_{\gamma^{*}}\right\|_{2}^{2}-\left\|\boldsymbol{\Phi}_{ \gamma\cup\{j_{\gamma}\}\setminus\{k\}}\mathbf{X}_{\gamma^{*}}\boldsymbol{ \beta}_{\gamma^{*}}\right\|_{2}^{2}\leq n\kappa\_\_\mathfrak{m}_{*}(s)/2\)_._

Proof.: For each \(\ell\in\gamma^{*}\setminus\gamma\), we have

\[\left\|\boldsymbol{\Phi}_{\gamma\cup\{\ell\}}\mathbf{X}_{\gamma^ {*}}\boldsymbol{\beta}_{\gamma^{*}}\right\|_{2}^{2}-\left\|\boldsymbol{\Phi}_ {\gamma}\mathbf{X}_{\gamma^{*}}\boldsymbol{\beta}_{\gamma^{*}}\right\|_{2}^{2} =\boldsymbol{\beta}_{\gamma^{*}}^{\top}\mathbf{X}_{\gamma^{*}} ^{\top}(\boldsymbol{\Phi}_{\gamma\cup\{\ell\}}-\boldsymbol{\Phi}_{\gamma}) \mathbf{X}_{\gamma^{*}}\boldsymbol{\beta}_{\gamma^{*}}\] \[=\frac{\boldsymbol{\beta}_{\gamma^{*}}^{\top}\mathbf{X}_{\gamma^ {*}}^{\top}(\mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma})\mathbf{X}_{\ell} \mathbf{X}_{\ell}^{\top}(\mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma})\mathbf{X}_ {\gamma^{*}}\boldsymbol{\beta}_{\gamma^{*}}}{\mathbf{X}_{\ell}^{\top}( \mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma})\mathbf{X}_{\ell}}\] \[\geq\frac{\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}^{\top} \mathbf{X}_{\gamma^{*}\setminus\gamma}^{\top}(\mathbb{I}_{n}-\boldsymbol{ \Phi}_{\gamma})\mathbf{X}_{\ell}\mathbf{X}_{\ell}^{\top}(\mathbb{I}_{n}- \boldsymbol{\Phi}_{\gamma})\mathbf{X}_{\gamma^{*}\setminus\gamma} \boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}}{n},\]

where the second equality simply follows from Gram-Schmidt orthogonal decomposition. By summing the preceding inequality over \(\ell\in\gamma^{*}\setminus\gamma\), we get

\[\sum_{\ell\in\gamma^{*}\setminus\gamma}\left\|\boldsymbol{\Phi}_ {\gamma\cup\{\ell\}}\mathbf{X}_{\gamma^{*}}\boldsymbol{\beta}_{\gamma^{*}} \right\|_{2}^{2}-\left\|\boldsymbol{\Phi}_{\gamma}\mathbf{X}_{\gamma^{*}} \boldsymbol{\beta}_{\gamma^{*}}\right\|_{2}^{2} \geq\frac{\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}^{\top} \mathbf{X}_{\gamma^{*}\setminus\gamma}^{\top}(\mathbb{I}_{n}-\boldsymbol{\Phi} _{\gamma})\mathbf{X}_{\gamma^{*}\setminus\gamma}\mathbf{X}_{\gamma^{*} \setminus\gamma}^{\top}(\mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma})\mathbf{X}_{ \gamma^{*}\setminus\gamma}\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}}{n}\] \[\geq\kappa_{-}\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma}^{ \top}\mathbf{X}_{\gamma^{*}\setminus\gamma}^{\top}(\mathbb{I}_{n}-\boldsymbol{ \Phi}_{\gamma})\mathbf{X}_{\gamma^{*}\setminus\gamma}\boldsymbol{\beta}_{\gamma^ {*}\setminus\gamma}\] \[\geq n\kappa_{-}\left|\gamma\setminus\gamma^{*}\right| \mathfrak{m}_{*}(s)\] \[=n\kappa_{-}\left|\gamma^{*}\setminus\gamma\right|\mathfrak{m}_{*} (s).\]

The last inequality follows from the fact that \(\left|\gamma\right|=\left|\gamma^{*}\right|=s\). Since \(j_{\gamma}\) maximizes \(\left\|\boldsymbol{\Phi}_{\gamma\cup\{\ell\}}\mathbf{X}_{\gamma^{*}} \boldsymbol{\beta}_{\gamma^{*}}\right\|_{2}^{2}\) over all \(\ell\in\gamma^{*}\setminus\gamma\), the preceding inequality implies that

\[\left\|\boldsymbol{\Phi}_{\gamma\cup\{j_{\gamma}\}}\mathbf{X}_{\gamma^{*}} \boldsymbol{\beta}_{\gamma^{*}}\right\|_{2}^{2}-\left\|\boldsymbol{\Phi}_{ \gamma}\mathbf{X}_{\gamma^{*}}\boldsymbol{\beta}_{\gamma^{*}}\right\|_{2}^{2} \geq n\kappa\_\mathfrak{m}_{*}(s).\]

Similarly, to prove the second claim, first note that for any \(k\in\gamma\setminus\gamma^{*}\), we have

\[\left\|\boldsymbol{\Phi}_{\gamma^{\prime}\cup\{k\}}\mathbf{X}_{ \gamma^{*}}\boldsymbol{\beta}_{\gamma^{*}}\right\|_{2}^{2}-\left\|\boldsymbol{ \Phi}_{\gamma^{\prime}}\mathbf{X}_{\gamma^{*}}\boldsymbol{\beta}_{\gamma^{*}} \right\|_{2}^{2} =\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma^{*}}^{\top}\mathbf{X }_{\gamma^{*}\setminus\gamma^{\prime}}^{\top}(\boldsymbol{\Phi}_{\gamma^{*} \cup\{k\}}-\boldsymbol{\Phi}_{\gamma^{\prime}})\mathbf{X}_{\gamma^{*} \setminus\gamma^{\prime}}\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma^{\prime}}\] \[=\frac{\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma^{*}}^{\top} \mathbf{X}_{\gamma^{*}\setminus\gamma^{\prime}}^{\top}(\mathbb{I}_{n}- \boldsymbol{\Phi}_{\gamma^{\prime}})\mathbf{X}_{k}\mathbf{X}_{k}^{\top}( \mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma^{\prime}})\mathbf{X}_{\gamma^{*} \setminus\gamma^{\prime}}\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma^{\prime}}}{ \mathbf{X}_{k}^{\top}(\mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma})\mathbf{X}_{k}}\] \[=\left\langle(\mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma^{\prime}}) \mathbf{X}_{\gamma^{*}\setminus\gamma^{\prime}}\boldsymbol{\beta}_{\gamma^{*} \setminus\gamma^{\prime}}\frac{(\mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma^{\prime}}) \mathbf{X}_{k}}{\left\|(\mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma^{\prime}}) \mathbf{X}_{k}\right\|_{2}}\right\rangle^{2}\] \[\leq\left\|\boldsymbol{\beta}_{\gamma^{*}\setminus\gamma} \right\|_{1}^{2}\left\|\frac{\mathbf{X}_{\gamma^{*}\setminus\gamma^{\prime}}^{\top}( \mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma^{\prime}})\mathbf{X}_{k}}{\left\|( \mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma^{\prime}})\mathbf{X}_{k}\right\|_{2}} \right\|_{\infty}^{2}\] \[\leq b_{\text{max}}^{2}\left\|\frac{\mathbf{X}_{\gamma^{*} \setminus\gamma^{*}}^{\top}(\mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma^{\prime}}) \mathbf{X}_{k}}{\left\|(\mathbb{I}_{n}-\boldsymbol{\Phi}_{\gamma^{\prime}}) \mathbf{X}_{k}\right\|_{2}}\right\|_{\infty}^{2}.\]

Since \(k_{\gamma}\) minimizes \(\left\|\boldsymbol{\Phi}_{\gamma^{\prime}\cup\{k\}}\mathbf{X}_{\gamma^{*}} \boldsymbol{\beta}_{\gamma^{*}}\right\|_{2}^{2}-\left\|\boldsymbol{\Phi}_{ \gamma^{\prime}}\mathbf{X}_{\gamma^{*}}\boldsymbol{\beta}_{\gamma^{*}}\right\|_{2 }^{2}\) over all possible \(k\in\gamma\setminus\gamma^{*}\), by Assumption 4.2 we have

\[\left\|\boldsymbol{\Phi}_{\gamma\cup\{j_{\gamma}\}}\mathbf{X}_{\gamma^{*}} \boldsymbol{\beta}_{\gamma^{*}}\right\|_{2}^{2}-\left\|\boldsymbol{\Phi}_{ \gamma\cup\{j_{\gamma}\}\setminus\{k\}}\mathbf{X}_{\gamma^{*}}\boldsymbol{\beta}_{ \gamma^More simulation details

### Independent Uniform design

Under the setup of Section 5, we consider the privacy parameter \(\varepsilon\in\{0.5,1,3,5,10\}\). For the Metropolis-Hastings random walk, we vary \(K\in\{0.5,2,3,3.5\}\) and initialize 10 independent Markov chains from random initializations and record the F-score of the last iteration. We also track the qualities of the model through its explanatory power. In particular, we calculate the scale factor \(R_{\gamma}:=\mathbf{y}^{\top}\boldsymbol{\Phi}_{\gamma}\mathbf{y}/\left\| \mathbf{y}\right\|_{2}^{2}\) for each model \(\gamma\in\{\gamma_{t}\}_{t\geq 1}\) along the random walks. Typically, a high value of \(R_{\gamma}\) will indicate the superior quality of the model \(\gamma\). Note that \(-\left\|\mathbf{y}\right\|_{2}^{2}(1-R_{\gamma})\) is proportional to the log of the probability mass function function of \(\gamma\). Thus, tracking \(R_{\gamma}\) is equivalent to tracking the log-likelihood of \(\gamma\) along the random walks.

Strong signal:Under this setup, note that the model estimate of ABESS exactly matches the true model. For \(\varepsilon\geq 3\) and \(K\geq 2\), Figure 1 shows that all the chains have identified a reasonably good estimate of the true model \(\gamma^{*}\) within \(50p\) iterations. This empirical phenomenon validates theoretical findings in Theorem 4.3. However, for larger values of \(K\) the performance is worse as the noise level is also large. On the other hand, for the case of \(K=0.5\), the performance is also worse due to too much shrinkage that results in a bad estimate of \(\boldsymbol{\beta}\). The mean F-score's also suggest the same phenomenon. For smaller values of \(\varepsilon\), the performance is generally bad due to increased noise level. This is expected as higher privacy usually entails a worse performance in terms of utility.

Weak signal:We perform the same experiments under a weak signal regime. As expected, both Figure 2 and Table 1 show that the performance of the proposed algorithm is generally inferior to that in the strong signal regime for \(K\geq 2\). However, note that our algorithm enjoys a better utility for \(K=0.5\). In fact, performance is as good as the non-private BSS for \(\varepsilon\geq 3\). This is not surprising as \(K=0.5\) closer to \(\left\|\boldsymbol{\beta}\right\|_{1}\approx 0.7\) in the weak signal case and results in better estimation for \(\boldsymbol{\beta}\). On the contrary, larger values of \(K\) inject more noise into the algorithm and the utility deteriorates.

### Independent Gaussian Design

We consider an independent Gaussian design matrix, formed by sampling entries from identical independent standard normal distributions and normalized by the \(\ell_{\infty}\) norm. Specifically, we set \(n=900,p=2000\) with the sparsity level \(s=4\). Similar to the setup in Section 5, we generate entries with independent \(\mathrm{Uniform}(-0.1,0.1)\) noise \(\mathbf{w}\) following the linear model (1). We choose the design vector \(\boldsymbol{\beta}\) with true sparsity \(s=4\) and the support set \(\gamma^{*}=\{j:1\leq j\leq 4\}\). All the signal strengths are set to be equal, taking the following two forms: (i) **Strong signal:**\(\beta_{j}=2\{(s\log p)/n\}^{1/2}\), and (ii) **Weak signal:**\(\beta_{j}=2\{(\log p)/n\}^{1/2}\) for all \(j\in\gamma^{*}\). We consider the privacy parameter \(\varepsilon\in\{0.5,1,3,5,10\}\). For the Metropolis-Hastings random walk, we vary \(K\in\{0.5,2,3,3.5\}\) and initialize 10 independent Markov chains from random initialization and record the F-score of the last iteration.

Strong signal:Under this setup, note that the model estimate of ABESS exactly matches the true model with \(\texttt{F-score}=1\). For the case of \(K=0.5\), Figure 3 shows the performance is better compared with settings \(K\geq 2\) when \(\varepsilon\leq 5\). However, when \(\varepsilon=10\), the performance is worse due to shrinkage of the estimate of \(\boldsymbol{\beta}\) while the estimations in other settings are easier due to lower privacy requirements. For higher values of \(\varepsilon\), the performance is generally strong because of the reduced noise level. This is expected since lower privacy typically leads to better utility performance. Notice that for \(\varepsilon=10\) and \(K=2\), we have a fairly accurate estimate of the true model \(\gamma^{*}\) within \(50p\) iterations.

Weak signal:We conduct the same experiments under a weak signal regime. As expected, Figure 4 shows that the performance of the proposed algorithm is generally inferior to that in the strong signal regime for \(K\geq 2\). However, note that our algorithm enjoys a better utility for \(K=0.5\) when \(\varepsilon\geq 3\). In fact, performance is as good as the non-private BSS for \(\varepsilon=10\). This is not surprising as \(K=0.5\) closer to \(\left\|\boldsymbol{\beta}\right\|_{1}\approx 0.7\) in the weak signal case, leading to better estimation for \(\boldsymbol{\beta}\). In contrast, larger values of \(K\) introduce more noise into the algorithm and weaken the utility.

Figure 1: Metropolis-Hastings random walk under different privacy budgets and \(\ell_{1}\) regularization. (Strong signal)

Figure 2: Metropolis-Hastings random walk under different privacy budgets and \(\ell_{1}\) regularization. (Weak signal)

Figure 3: Gaussian setting Metropolis-Hastings random walk under different privacy budgets and \(\ell_{1}\) regularization. (Strong signal)

Figure 4: Gaussian setting Metropolis-Hastings random walk under different privacy budgets and \(\ell_{1}\) regularization. (Weak signal)

### NeurIPS Paper Checklist

The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: **The papers not including the checklist will be desk rejected.** The checklist should follow the references and precede the (optional) supplemental material. The checklist does NOT count towards the page limit.

Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist:

* You should answer [Yes], [No], or [NA].
* [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.
* Please provide a short (1-2 sentence) justification right after your answer (even for NA).

**The checklist answers are an integral part of your paper submission.** They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper.

The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a proper justification is given (e.g., "error bars are not reported because it would be too computationally expensive" or "we were unable to find the license for the dataset we used"). In general, answering "[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found.

IMPORTANT, please:

* **Delete this instruction block, but keep the section heading "NeurIPS paper checklist"**,
* **Keep the checklist subsection headings, questions/answers and guidelines below.**
* **Do not modify the questions and only use the provided macros for your answers**.

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: In the abstract and introduction we claim that our our method provides a DP model estimator while enjoying computational efficiency. This matches with the theoretical and experimental demonstrations in the paper. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes]Justification: We point out some of the limitations of the work and possible future directions in the Conclusion section. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: We explicitly mention all the assumptions in the statement of the theorems and lemmas. The proofs of these results can be found in the appendix sections. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.x * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We clearly state all of the key parameters of the simulation experiments in the simulation section.

Guidelines:

* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: The Github Link is provided in the footnote of Page 9. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.

* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We do the experiments on simulated data. Therefore, technically, we just have the testing step. We do specify clearly about this step in the simulation section. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [No] Justification: We do not include the error bar for the F-scores as the results are pretty robust across different repetitions. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We have added the information about the computational resources in SectionGuidelines:

* The answer NA means that the paper does not include experiments.
* The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.
* The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.
* The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: This research work does not violate any NeurIPS Code of ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: We point toward the potential positive impacts of our work in the conclusion sections. To the best of our knowledge, we could not think of any negative societal impact of our work. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards**Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **License for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We clearly cite the main webpage information and relevant papers regarding the used packages in the paper along with the license information. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: The Github Link to our code is provided in the footnote of Page 9. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used.

* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. * We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. * For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.