# GADBench: Revisiting and Benchmarking Supervised Graph Anomaly Detection

 Jianheng Tang\({}^{1,2}\), Fengrui Hua\({}^{1}\), Ziqi Gao\({}^{1,2}\), Peilin Zhao\({}^{3}\), Jia Li\({}^{1,2}\)

\({}^{1}\)Hong Kong University of Science and Technology (Guangzhou)

\({}^{2}\)Hong Kong University of Science and Technology, \({}^{3}\)Tencent AI Lab

{jtangbf,zgaoat}@connect.ust.hk, huafengrui@outlook.com,

masonzhao@tencent.com, jialee@ust.hk

Work done during an internship at Tencent AI Lab.Corresponding Author.

###### Abstract

With a long history of traditional Graph Anomaly Detection (GAD) algorithms and recently popular Graph Neural Networks (GNNs), it is still not clear (1) how they perform under a standard comprehensive setting, (2) whether GNNs can outperform traditional algorithms such as tree ensembles, and (3) how about their efficiency on large-scale graphs. In response, we introduce GADBench--a benchmark tool dedicated to supervised anomalous node detection in static graphs. GADBench facilitates a detailed comparison across 29 distinct models on ten real-world GAD datasets, encompassing thousands to millions (\(\sim\)6M) nodes. Our main finding is that tree ensembles with simple neighborhood aggregation can outperform the latest GNNs tailored for the GAD task. We shed light on the current progress of GAD, setting a robust groundwork for subsequent investigations in this domain. GADBench is open-sourced at https://github.com/squareRoot3/GADBench.

## 1 Introduction

Graph Anomaly Detection (GAD) is the process of identifying uncommon graph objects, such as nodes, edges, or substructures, that significantly deviate from the majority of reference objects within a graph database [4, 55]. With a notable history spanning over two decades, GAD has proven its effectiveness across a variety of applications. These include, but are not limited to, the prevention of financial fraud [36] and money-laundering [83], the prediction of network intrusions [57, 64] and device failures [46], the identification of spam reviews [56] and fake news [8]. Unlike outlier detection in tabular data, GAD considers the inter-dependencies among a group of objects, which can often yield additional insights for identifying fraudulent patterns. Meanwhile, GAD also presents unique challenges in terms of modeling efficiency and necessitates strategies to address issues such as label imbalance [50], feature heterophily [26], and relation camouflage [22].

The definitions of GAD can be multifaceted, depending on the specific objectives and applications. In this paper, we focus on the most prevalent GAD scenario--**the detection of anomalous nodes within a static attributed graph**. Despite the plenty of methods proposed for this task, including traditional structural pattern mining algorithms [57, 4] and advanced deep learning techniques [21, 55], several limitations exist in the current model development and evaluation scheme:

* **Absence of a comprehensive supervised GAD benchmark.** We summarize the exiting GAD benchmarks and toolboxes in Table 1. The latest benchmark available for GAD, BOND [49], exclusively evaluates unsupervised methods. This overlooks the fact that many GAD models rely on labeled data to boost their performance. In comparison, there have been a variety of supervisedanomaly detection benchmarks for time series [59; 61], images [68], videos [1], and tabular data [31; 77]. Semi-supervised approach is another setting that calls for attention because it can strike a balance between label annotation budgets and model performance.
* **Insufficient comparative studies between tree ensembles and GNNs.** Tree ensemble methods, including Random Forest [12], XGBoost [16], and Isolation Forest [48], have long been favored in the industry. They also showcase impressive results in a recent benchmark for anomaly detection within tabular datasets [31]. These models are also applicable to GAD datasets [83] with appropriate feature engineering. However, a systematic comparison between tree ensembles and GNNs in the context of GAD is still absent.
* **Limited exploration on large-scale graphs.** While many GNN models tailored for GAD have shown promising results on small-scale datasets, their efficacy on large graphs remains unexplored. On the other hand, although several large-scale GAD datasets have been proposed [36; 83; 74], they mainly focus on the comparisons of GNN variants, making it unclear how they perform compared with traditional GAD algorithms.

To redress these gaps and foster academia-industry synergy in GAD evaluation, we propose GADBench, which serves as the first comprehensive benchmark for supervised GAD. Our evaluation encompasses 7 non-graph models, 10 standard GNNs, and 10 state-of-the-art GNNs specifically designed for GAD. Recognizing the proven success of tree ensembles in the anomaly detection of tabular data, we additionally employ two tree ensemble models with simple neighborhood aggregations. All models are evaluated on 10 real-world GAD datasets ranging from thousands to millions of nodes. They are tested in both semi-supervised and fully-supervised settings, with and without hyperparameter tuning.

Through extensive experiments, we discover that (1) surprisingly, tree ensembles with neighbor aggregation have the superior performance among all models; (2) most standard GNNs are not suitable for the GAD task; (3) GNNs specifically designed for GAD require hyperparameter tuning to achieve satisfactory performance. We highlight that our findings can offer the research community a clearer insight into the current progress in GAD. In summary, our contributions can be organized into three main aspects:

* We introduce GADBench, the first comprehensive benchmark for supervised anomalous node detection on static attributed graphs. This includes a comparison of 29 well-known GAD methods across a collection of 10 real-world datasets in both semi-supervised and fully-supervised settings.
* To ensure a rigorous and fair comparison, we identify the limitations inherent in the existing evaluation scheme for GAD, instituting enhancements from dataset selection, metric utilization, model training, and hyperparameter tuning.
* We integrate all models, datasets, and evaluation protocols mentioned in this paper into an open-source repository. Users can reproduce the results and evaluate their own datasets/models with minimal effort.

## 2 Preliminaries and Related Work

Task definition.We focus on the detection of anomalous nodes within a static attributed graph. Formally, consider a graph \(\mathcal{G}=\{\mathcal{V},\bm{A},\bm{X}\}\), where \(\mathcal{V}=\{v_{1},v_{2},\cdots,v_{N}\}\) denotes a set of \(N\) nodes. The non-negative adjacency matrix \(\bm{A}\in\mathbb{R}^{N\times N}\) is defined such that \(\bm{A}_{ij}>0\) if and only if there is an edge between \(v_{i}\) and \(v_{j}\). \(\bm{X}\in\mathbb{R}^{N\times d}\) is a feature matrix, of which the \(i\)-th row vector \(\mathbf{x}_{i}=\bm{X}(i,:)\) is the \(d\)-dimensional feature vector of node \(v_{i}\). Given a subset of labeled nodes \(\mathcal{V}^{*}\subset\mathcal{V}\), the task is to classify the remaining nodes into either normal or anomalous categories. In the context of

\begin{table}
\begin{tabular}{l l l l l l} \hline \hline Benchmark & \#Datasets & Max. Nodes & \#Models & Model Type & Supervision Scenario \\ \& Toolbox & (Organic) & /Edges & \#Models & Model Type & Supervision Scenario \\ \hline UGFraud [23] & 1 (1) & 45K/3M & 6 & GNN & Unsupervised \\ DGFraud [22] & 3 (1) & 45K/3M & 9 & GNN & Supervised \\ BOND [49] & 9 (6) & 3M/4M & 14 & GNN, Classic & Unsupervised \\ \hline GADBench & 10 (10) & 5M/73M & 29 & GNN, Classic, Trees & Fully- and Semi-Supervised \\ \hline \hline \end{tabular}
\end{table}
Table 1: Comparison of existing GAD benchmarks in terms of datasets, models, and scenarios.

a heterogeneous graph, multiple adjacency matrices \(\{\bm{A}_{1},\bm{A}_{2},\cdots\}\) might exist, each representing different types of relationships among nodes.

Although the GAD task can be regarded as a binary node classification problem, it introduces several additional challenges. Firstly, anomalous nodes typically constitute a small portion of the total nodes, resulting in a significant data **imbalance**[50; 74]. Secondly, graphs with anomalies often exhibit strong **heterophily**, where connected nodes possess varying features and labels [27; 26]. This necessitates strategies to handle neighborhood feature disparities during message passing. Lastly, anomalous nodes have a tendency to **camouflage** their features and connections, blending seamlessly by mimicking the normal patterns in the graph [22; 51]. This demands attention to intentionally manipulated edges and node features. Before presenting our benchmark, we provide a brief overview of both classic methods and deep learning based GAD models. For a more thorough review of GAD models, please refer to these relevant surveys [55; 4; 38].

**Classical methods.** Classical methods primarily detect graph anomalies by leveraging graph statistical patterns [57; 34], community and clustering structures [14; 43; 86], egonet information [3], spectral analysis [25], random walk-based techniques [81; 29], etc. Other than these heuristic approaches and handcraft feature engineering, another research line leverages learning methods for a more flexible encoding of graph information to identify anomalies. Examples include residual learning [45; 63], relational learning [40; 66], and Bayesian models [33]. Despite their advantages, most methods are primarily designed for plain graphs and struggle to handle attributed graphs. Additionally, they predominantly emphasize unsupervised settings and are generally inefficient in utilizing node labels.

**GNNs for GAD.** With superb ability to encode both structure and attribute information simultaneously, GNNs have recently gained popularity in mining graph data [76; 39; 85; 30]. To tackle the unique challenges of graph anomalies, such as imbalance, heterophily, and camouflage, several adaptations of standard GNNs have been proposed [20; 96; 24; 53; 52; 21; 79; 54; 90]. On one hand, **spatial** GNNs have primarily been redesigned at the level of their inherent mechanisms, such as message passing and aggregation [99]. For instance, GAS [44] employs a structure-enhanced pre-processing strategy to establish implicit connections between anomalies. CARE-GNN [22] and GraphConsis [51] combat the camouflage behavior by designing camouflage-resistant message passing and aggregation processes. H2-FDetector [72] introduces a novel information aggregation strategy that enables homophilic connections to propagate similar information, while heterophilic connections disseminate differing information. With the consideration of label imbalance, solutions like PC-GNN [50] and DAGAD [47] use imbalance-aware data sampling and graph augmentation to highlight the importance of anomalies during training. On the other hand, **spectral** GNNs provide a fresh viewpoint that associates graph anomalies with high frequency spectral distributions [26]. For example, BWGNN [74] applies Beta kernel to manage higher frequency anomalies via flexible and localized band-pass filters. AMNet [13] captures both low-frequency and high-frequency signals, adaptively integrating signals of varying frequencies.

**Ensemble models.** Tree ensembles, such as Random Forest [12; 9; 6; 5] and XGBoost [16; 78; 97; 58], have shown superior performance in anomaly detection tasks related to tabular data [93; 10; 2; 100]. For example, XGBOD [93], an extension of the XGBoost algorithm specifically designed for anomaly detection, incorporates scores from other models such as Isolation Forest [48] as additional feature and achieves superior performance. Despite their potential, few research has explored the application of tree ensembles in leveraging both structural and feature information simultaneously for GAD. Beyond trees, various base models can be integrated into ensembles for anomaly detection, as suggested by [89]. The use of neighborhood aggregation has been demonstrated to enhance anomaly detection performance, which can be utilized during various stages such as pre-processing [87], model-training [17], and post-processing [88] phases. In this work, we revisit tree ensemble models and demonstrate their potential to outperform GNNs after combining a straightforward structural neighborhood aggregation.

## 3 The Setup of GADBench

In this section, we present a comprehensive overview of the setup for GADBench. We provide the general selection criteria and considerations for models (Section 3.1), datasets (Section 3.2), and other details (Section 3.3).

### Benchmark Models

Table 2 provides an overview of the 29 models assessed in GADBench. We briefly introduce each model in the following, and provide a more detailed description in Appendix A.

**Classical methods.** We select three basic algorithms for supervised classification: Multi-Layer Perceptron (MLP), \(k\)-Nearest Neighbors (KNN), and Support Vector Machine (SVM). Additionally, we incorporate three representative decision tree ensembles, including a bagging-based model, Random Forest (RF); a boosting-based model, Extreme Gradient Boosting Tree (XGBoost); and an advanced XGBoost model named Extreme Boosting Based Outlier Detection (XGBOD). We also assess a recent anomaly detection technique, Neighborhood Averaging (NA), which enhances the outlier scores of existing anomaly detectors by averaging them with the scores of neighboring objects.

**Standard GNNs.** We evaluate several standard GNNs that have proven to be effective across diverse graph learning tasks, including Graph Convolutional Network (GCN), Chebyshev Spectral Convolution Network (ChebNet), Graph Isomorphism Network (GIN), Graph Sample and Aggregate (GraphSAGE), Graph Attentional Network (GAT), Graph Transformer (GT), Principle Neighbor Aggregation (PNA), Boosted Graph Neural Network (BGNN). We also consider two widely used heterogeneous GNNs, including Relational Graph Convolution Network (RGCN) and Heterogeneous Graph Transformer (HGT).

**Specialized GNNs.** This group contains GNNs specifically designed for anomaly detection. We evaluate five spatial GNNs including the Graph-based Anti-Spam Model (GAS), Deep Cluster Infomax (DCI), Pick and Choose GNN (PC-GNN), and the GAT with ego- and neighbor-embedding separation (GAT-sep). For spectral GNNs, we evaluate the graph spectral filter via Bernstein Approximation (BernNet), Adaptive Multi-frequency GNN (AMNet), Beta Wavelet GNN (BWGNN), and the Graph Heterophily Reduction Network (GHRN). Additionally, we assess two GNNs optimized for heterogeneous graphs: the CAmouflage-REsistant GNN (CARE-GNN) and the Fraud Detector with Homophilic and Heterophilic Interactions (H2-FDetector).

**Tree ensembles with neighbor aggregation.** Decision tree ensembles have shown their effectiveness in anomaly detection with tabular data [31], prompting us to adapt them for GAD. To incorporate graph structure information, we follow the idea from a subclass of GNNs that independently manage message passing and node feature transformation [84; 98; 91]. Consequently, we devise tree ensembles with Neighbor aggregation that adhere to the following computational paradigm:

\[\bm{h}_{v_{i}}^{(l)} =\text{Aggregate}\{\bm{h}_{v_{j}}^{(l-1)}|v_{i}\in\text{Neighbor} (v_{j})\}\] \[\text{Score}(v_{i}) =\text{TreeEnsemble}([\bm{h}_{v_{i}}^{0}||\bm{h}_{v_{i}}^{1}|| \cdots||\bm{h}_{v_{i}}^{L}]).\]

In this scheme, \(\bm{h}_{v_{i}}^{(0)}=\bm{x}_{i}\) denotes the initial node attributes, and \(\bm{h}_{v_{i}}^{(l)}\) represents the feature of node \(v_{i}\) after \(l\)-layers of neighbor aggregation. Aggregate\((\cdot)\) can take on any aggregation function such as mean, max, or sum pooling. Same as [84; 98; 91], the aggregation process is parameter-free. TreeEnsemble\((\cdot)\) can be any tree ensembles that takes the aggregated features as input to predict the anomaly score of node \(v_{i}\). In GADBench, we utilize Random Forest and XGBoost to instantiate two new tree ensemble baselines with neighbor aggregation, referred to as RF-Graph and XGB-Graph.

### Benchmark Datasets

In GADBench, we have gathered 10 diverse and representative datasets, as detailed in table 3, which are chosen based on the following criteria:

\begin{table}
\begin{tabular}{l l} \hline \hline Classic Methods & MLP [67], KNN [18], SVM [15], RF [12], XGBoost [16], XGBOD [93], NA [88] \\ \hline \multirow{2}{*}{Standard GNNs} & GCN [39], SGC [84], GIN [85], GraphSAGE [30], GAT [76], GT [73], PNA [17] \\  & BGNN [37], RGCN [70], HGT [35] \\ \hline \multirow{2}{*}{Specialized GNNs} & GAS [44], DCI [82], PC-GNN [50], GAT-sep [99], BernNet [32], AMNet [13], \\  & BWGNN [74], GHRN [26], CARE-GNN [22], H2-FDetector [72] \\ \hline Tree Ensembles with Neighbor Aggregate & RF-Graph, XGB-Graph \\ \hline \hline \end{tabular}
\end{table}
Table 2: Categorization of all models used in our evaluation.

* **Organic anomalies.** Datasets in GADBench exclusively contain anomalies that naturally emerge in real-world scenarios, a distinction from previous studies that employ synthetic anomalies for GAD evaluations [21; 49]. These earlier works typically inject artificial node attributes and structures into normal graphs like Cora [71], resulting in anomalies that are relatively straightforward to be identified and obviously different from real-world anomalies.
* **Various domains.** Datasets in GADBench span multiple domains, including social media, e-commerce, e-finance, and crowd-sourcing. As presented in Table 3, the graph edge in each dataset embodies unique relation concepts, which shows a diverse distribution of applications.
* **Diverse scale.** GADBench datasets cover a wide scale, from thousands to millions of nodes. We have consciously excluded datasets with fewer than 5,000 nodes, such as Bitcoin-Alpha [41], Disney, and Books [69].
* **Imbalance ratio.** We have ensured that the number and ratio of anomalies within the datasets meet a specific criteria: each dataset contains more than 100 anomalies, to ensure stable experimental results, and no more than a 25% anomaly ratio, preserving the inherent imbalance nature of GAD. This criterion leads to the exclusion of the Enron dataset [69].

Among the datasets in GADBench, Weibo, Reddit, Questions, and T-Social are designed to identify anomalous accounts on social media platforms. Tolokers, Amazon and YelpChi datasets aim to detect fraudulent workers, reviews and reviewers on crowd-sourcing or e-commerce platforms. T-Finance, Elliptic, and DGraph-Fin concentrate on identifying fraudulent users, illicit entities and overdue loans in financial networks, respectively. For a more comprehensive description of each dataset, please refer to Appendix B.

### Other Details

**Data split.** We employ both fully-supervised and semi-supervised settings for model evaluation. In a fully-supervised setting, we preserve pre-existing data splits when available. If such divisions are not provided, we follow the approach suggested by [74], randomly partitioning nodes into three subsets: 40% for training, 20% for validation, and the remaining 40% for testing. For each dataset, the specific training ratio is reported in table 3. The semi-supervised setting typically involves a smaller training ratio, e.g., 1% or 5% in previous studies [74; 22]. However, due to the variance in graph sizes present in GADBench, a fixed training ratio might lead to substantial discrepancies in the scale of training sets. To more accurately mimic real-world semi-supervised scenarios, we standardize the training set across all datasets to include a total of 100 labels--20 positive labels (anomalous nodes) and 80 negative labels (normal nodes). To ensure robustness in our findings, we execute **ten** random splits on each dataset and analyze the average performance of the model.

**Metrics.** According to existing anomaly detection benchmarks [49; 31], we select Area Under the Receiver Operating Characteristic Curve (**AUROC**), Area Under the Prevision Recall Curve (**AUPRC**) calculated by average precision, and the Recall score within top-\(k\) predictions (**Rec@K**) as performance metrics for the GAD task. We set \(k\) as the number of anomalies within the test set. For all metrics, anomalies are considered as the positive class, and higher scores indicate better model

\begin{table}
\begin{tabular}{l r r r r r l l} \hline \hline  & \#Nodes & \#Edges & \#Feat. & Anomaly & Train & Relation Concept & Feature Type \\ \hline
**Reddit[42; 49]** & 10,984 & 168,016 & 64 & 3.3\% & 40\% & Under Same Post & Text Embedding \\
**Weibo[92; 49]** & 8,405 & 407,963 & 400 & 10.3\% & 40\% & Under Same Hashtag & Text Embedding \\
**Amazon[56; 22]** & 11,944 & 4,398,392 & 25 & 9.5\% & 70\% & Review Correlation & Misc. Information \\ YelpChi[66; 22] & 45,954 & 3,846,979 & 32 & 14.5\% & 70\% & Reviewer Interaction & Misc. Information \\
**Tolokers[65]** & 11,758 & 519,000 & 10 & 21.8\% & 40\% & Work Collaboration & Misc. Information \\
**Questions[65]** & 48,921 & 153,540 & 301 & 3.0\% & 52\% & Question Answering & Text Embedding \\
**T-Finance[74]** & 39,357 & 21,222,543 & 10 & 4.6\% & 50\% & Transaction Record & Misc. Information \\
**Elliptic[83]** & 203,769 & 234,355 & 166 & 9.8\% & 50\% & Payment Flow & Misc. Information \\
**DGraph-Fin[36]** & 3,700,550 & 4,300,999 & 17 & 1.3\% & 70\% & Loan Guarantor & Misc. Information \\
**T-Social[74]** & 5,781,065 & 73,105,508 & 10 & 3.0\% & 40\% & Social Friendship & Misc. Information \\ \hline \hline \end{tabular}
\end{table}
Table 3: Statistics of all datasets in GADBench including the number of nodes and edges, the node feature dimension, the ratio of anomalous labels, the training ratio in the fully-supervised setting, the concept of relations, and the type of node features. Misc. indicates the node features are a combination of heterogeneous attributes, possibly including categorical, numerical, and temporal information, More details are shown in Appendix B.

performance. Among these metrics, AUROC primarily focuses on overall performance and is not sensitive to top-\(k\) predictions, Rec@K only cares top-\(k\) performance, and AUPRC strikes a balance between the two. Suppose the test set includes 10 anomalies within 1000 data points and a model ranks them from positions 11\(th\) to 20\(th\), it would attain an AUROC of 0.99, an AUPRC of 0.33, and a Rec@10 of 0. We also document the **running time** and **memory consumption** of each model.

**Hyperparameter Optimization.** To control the effect of hyperparameter selection and ensure fairness [11], we standardize the evaluation process with and without hyperparameter tuning. Initially, we employ default hyperparameters as stated in the original papers. To ensure fairness in hyperparameter tuning, we then utilize **random search**[7] to optimize hyperparameters. During one trial on each dataset, we randomly select a set of hyperparameters from the predefined search space for each model. For more information about metrics, default hyperparameters, search spaces, and other implementation details, please refer to Appendix C.

## 4 Experimental Results

In this section, we study the experimental results of all the benchmarked models. We first provide a comprehensive comparison of all models, taking into account both default and optimally tuned hyperparameters. Following that, we aim to conduct an in-depth comparison between tree ensembles with neighbor aggregation and GNN-based methods.

### Overall Comparison

In Figure 1, we present an overview of model performance across 10 datasets for all metrics, excluding four GNNs that are specific to heterogeneous graphs. In Table 4, we take a close look at the model performance regarding the AUPRC score after hyper-parameter tuning on each dataset. For comprehensive experimental results, please refer to Appendix D. Our key findings include:

**Ensemble trees with neighbor aggregation have superior performance.** As highlighted in Figure 1, XGB-Graph and RF-Graph consistently surpass other compared models across all metrics using default hyperparameters. The performance gap becomes particularly significant in the fully-supervised setting, i.e., XGB-Graph surpasses BWGNN--the best GNN model in this setting--by an absolute average improvement of 2.0% on AUROC, 12.9% on AUPRC, and 9.8% on Rec@K. In the semi-supervised context, RF-Graph presents an absolute average improvement of 2.8% on AUROC, 8.0% on AUPRC, and 3.1% on Rec@K, as compared to GHRN, the best GNN model in this setting. It is important to highlight that the improvement in AUPRC and Rec@K is more pronounced than that in AUROC due to the imbalanced issue, suggesting that RF-Graph and XGB-Graph are more proficient in predicting top-\(k\) high-confidence anomalies. Further, as shown in the bottom of Figure 1, tree ensembles with neighbor aggregation not only outperform GNNs in terms of efficiency but also exhibit lower memory consumption. Although the performance gap of different models narrow after hyperparameter tuning as in Table 4, RF-Graph and XGB-Graph still prevail among 6 out of 10 datasets. Accordingly, our observations show the superior effectiveness and efficiency of RF-Graph and XGB-Graph across diverse GAD datasets and scenarios.

**Most standard GNNs prove unsuitable for GAD.** As shown in Figure 1, it becomes clear that the majority of standard GNNs encounter difficulties when dealing with GAD tasks. To illustrate, the performance of GCN and GIN is on par with that of MLP--a method that does not take graph structure information into account. This indicates that standard GNNs often struggle to effectively handle structure camouflage or feature heterophily problems induced by anomalies. In Table 4, while hyperparameter tuning does improve the results of all standard GNNs, they remain subpar compared to methods in other categories. An exception is GraphSAGE, which displays an average absolute improvement of 10.4% on average AUPRC when optimal hyperparameters are used, making it competitive with specialized GNNs. BGNN, while impressive on specific datasets such as T-Social, exhibits poor performance on other datasets. This inconsistency may result from the inherent instability of its joint training scheme, especially when compared to the more stable two-step approach in XGB-Graph and RF-Graph.

**Specialized GNNs require hyperparameter tuning to achieve satisfactory performance.** Generally, specialized GNNs outperform standard GNNs in Figure 1, indicating that GNNs tailored for GAD can indeed enhance anomaly detection capabilities. However, the performance of these specialized GNNs strongly depends on hyperparameter tuning. As indicated in the last column of Table 4, all these methods witness a performance improvement after a hyperparameter search. For instance, when optimized hyperparameters are employed, BWGNN can surpass RF-Graph and XGB-Graph on the Reddit dataset. This demonstrates that under certain conditions, some specialized GNNs can deliver commendable performance. However, as illustrated at the bottom of Figure 1, these GNNs often demand more training time and memory. The inherent limitations of hyperparameter tuning are the same as the ones in the previous section.

Figure 1: Comparison of the anomaly detection performance, wall-clock time (on all datasets), and peak CPU/GPU memory utilization (on DGraph-Fin) among all models with default hyperparameters. Top three lines are in semi-supervised settings and the others are in fully-supervised settings. The color of the box plot represents the average score for each metric, while the central line within the box indicates the median score.

search also pose significant challenges, especially in real-world applications where there might be a scarcity of annotated labels or computational resources. Given these constraints, tree ensembles with neighborhood aggregation might still be the preferred choice.

NA is a versatile technique adaptable to any model in GADBench. We apply it to XGBoost and observe a remarkable enhancement in the semi-supervised setting, where the average AUPRC across 10 datasets increases from 37.5% to 38.9%. However, the boost is not significant in the fully-supervised setting. These findings highlight NA's potential as an effective strategy to address challenges associated with label scarcity. For additional results related to the application of NA on other models, please refer to Appendix D.

Finally, we observe that all methods perform poorly on the DGraph-Fin dataset. This can be attributed to the highly imbalanced and sparse graph structure, with an average degree of 1.16. Furthermore, we find that node features in this dataset are highly indistinguishable, as nearly all anomalous nodes share identical features with normal nodes. Indeed, the AUROC scores of all models on this dataset align with those reported in the original paper, as demonstrated in Appendix D.

### Specialized Experiments in Heterogeneous and Inductive Settings

\begin{table}
\begin{tabular}{l|c c c c c c c c c c|c c c} \hline \hline \multirow{2}{*}{**Model**} & \multirow{2}{*}{Reddit} & \multirow{2}{*}{Weibo} & \multirow{2}{*}{Amazon} & \multirow{2}{*}{Felp.} & \multirow{2}{*}{T-Fin.} & \multicolumn{2}{c|}{Ellip.} & \multirow{2}{*}{Tolo.} & \multirow{2}{*}{Quest} & \multirow{2}{*}{DGraph.} & \multirow{2}{*}{T-Social} & \multirow{2}{*}{**Ave.**} & \multirow{2}{*}{**Imp.**} \\ \hline MLP & 5.91 & 84.88 & 87.34 & 47.68 & 74.21 & 43.77 & 38.29 & 15.34 & 2.69 & 9.69 & 44.46 & 2.67 \\ KNN & 6.12 & 81.12 & 84.41 & 54.39 & 74.97 & 60.98 & 35.30 & 15.37 & 1.67 & 36.32 & 46.04 & 9.13 \\ SVM & 6.88 & 84.91 & 85.80 & 41.01 & 78.10 & 20.98 & 37.90 & 15.37 & 2.65 & OSOT & 41.51 & 4.53 \\ RF & 4.63 & 93.52 & 91.18 & 77.77 & 81.99 & 78.42 & 38.64 & 14.37 & 2.57 & 41.56 & 53.68 & 0.81 \\ XGBoost & 5.56 & 94.49 & 91.88 & 84.00 & 82.64 & 76.93 & 40.05 & 16.24 & 2.75 & 16.60 & 54.95 & 0.73 \\ XGBoD & 8.27 & 95.70 & 92.15 & 79.46 & 82.32 & 74.86 & 40.65 & 16.08 & 1.95 & OSOT & 54.61 & 1.62 \\ NA & **9.70** & 94.09 & 91.56 & 63.93 & 88.78 & 29.14 & 51.06 & 14.32 & 4.13 & 79.21 & 49.64 & 3.38 \\ \hline GCN & 4.63 & 94.64 & 45.65 & 20.88 & 78.22 & 25.37 & 40.57 & 14.06 & 3.80 & 76.35 & 36.42 & 1.54 \\ SGC & 6.04 & 91.16 & 42.69 & 19.87 & 68.68 & 17.82 & 39.59 & 10.53 & 2.49 & 16.28 & 33.21 & 5.66 \\ GIN & 6.41 & 91.67 & 84.61 & 33.63 & 78.35 & 26.21 & 40.36 & 13.68 & 3.47 & 60.79 & 42.04 & 2.57 \\ GraphSAGE & 5.56 & 94.02 & 82.45 & 46.64 & 84.71 & 57.82 & 51.41 & 17.50 & 3.77 & 75.32 & 49.32 & 10.44 \\ GAT & 7.20 & 92.91 & 87.94 & 43.62 & 82.72 & 27.53 & 45.25 & 15.51 & 3.85 & 32.07 & 45.17 & 2.80 \\ GT & 7.68 & 89.85 & 84.90 & 44.60 & 83.14 & 25.90 & 45.71 & 17.08 & 3.83 & 36.14 & 44.74 & 5.42 \\ PNA & 7.75 & 96.04 & 35.24 & 29.95 & 76.67 & 27.81 & 47.14 & 13.13 & 3.22 & 21.24 & 36.64 & 4.93 \\ BGNN & 6.87 & 95.99 & 67.92 & 97.13 & 87.32 & 62.03 & 45.35 & 9.43 & **4.24** & **99.09** & 45.03 & 0.95 \\ \hline GAS & 4.43 & 96.76 & 81.43 & 35.11 & 85.95 & 29.80 & 47.21 & 15.48 & 3.65 & 62.36 & 44.42 & 6.62 \\ DCI & 7.74 & 91.77 & 85.17 & 39.88 & 63.68 & 27.39 & 37.73 & 14.59 & 3.31 & 12.97 & 41.25 & 1.01 \\ PCGNN & 7.73 & 89.07 & 89.33 & 44.51 & 83.31 & 42.66 & 44.85 & 15.59 & 3.42 & 80.29 & 46.72 & 4.69 \\ BernNet & 7.82 & 92.38 & 84.89 & 51.92 & 89.17 & 38.25 & 43.69 & 17.25 & 3.27 & 44.30 & 47.63 & 2.90 \\ AMNet & 7.87 & 94.99 & 88.36 & 46.86 & 88.87 & 25.18 & 40.74 & 15.63 & 2.81 & 37.70 & 45.70 & 2.49 \\ GAT-sep & 7.19 & 93.40 & 84.72 & 45.59 & 84.01 & 26.35 & 46.66 & 17.90 & 3.84 & 33.39 & 45.50 & 2.98 \\ BWGNN & 8.32 & 94.01 & 91.48 & 61.53 & 89.38 & 29.31 & 49.58 & **18.57** & 3.97 & 78.93 & 49.57 & 2.12 \\ GHRN & 4.66 & 95.27 & 89.52 & 55.42 & 87.60 & 43.90 & 47.45 & 18.31 & 3.80 & 86.78 & 49.55 & 1.77 \\ \hline RF-Graph & 5.13 & 96.95 & 90.53 & 83.92 & 89.23 & **78.86** & 52.34 & 14.44 & 2.15 & 97.63 & 57.06 & 1.21 \\ XGB-Graph & 5.29 & **97.06** & **93.33** & **91.11** & **90.12** & 77.78 & **53.92** & 18.19 & 3.79 & 97.34 & **58.95** & 1.34 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Comparison of the AUPRC score of each model with optimal hyperparameters through random search. Best results are highlighted in **bold**. In the last two columns, **Ave.** signifies the average score across the first 9 datasets without T-Social, while **Imp.** denotes the absolute increase in this average score when compared to the default hyperparameters. OOT means the model could not complete training within a day. Results for other metrics can be found in Appendix D and Table 13.

\begin{table}
\begin{tabular}{l|c c|c c|c c c|c c c c} \hline \hline  & \multicolumn{2}{c|}{Amazon (Semi-Supervised)} & \multicolumn{2}{c|}{Amazon (Fully-Supervised)} & \multicolumn{2}{c|}{Velp (Semi-Supervised)} & \multicolumn{2}{c|}{Yelp (Fully-Supervised)} \\ \cline{2-11} Model & AUROC & AUPRC & Rec@K & AUROC & AUPRC & Rec@K & AUROC & AUPRC & Rec@K & AUROC & AUPRC & Rec@K \\ \hline GAT & 92.44 & 81.57 & 77.07 & 96.66 & 86.67 & 83.10 & 65.56 & 25.03 & 28.08 & 79.50 & 43.41 & 43.65 \\ BWGNN & 91.83 & 81.68 & 77.01 & 97.95 & 89.09 & 85.00 & 64.30 & 23.66 & 26.44 & 84.89 & 55.06 & 52.18 \\ \hline RGCN & 84.17 & 41.07 & 45.57 & 92.03 & 67.97 & 65.49 &

**Dealing with heterogeneous graphs.** We evaluated the performance of four GAD methods that consider heterogeneity--RGCN, HGT, CARE-GNN, and H2-FDetector--using the Amazon and Yelp datasets, each comprising three different types of edges as detailed in Appendix B. For comparison, we also tested three other methods--GAT, BWGNN, and XGB-Graph--that treat all edge types equivalently. As shown in table 5, considering heterogeneity does not enhance performance on the Amazon dataset, but it leads to improvements on the Yelp dataset. Specifically, CARE-GNN outperforms all other methods under label-scarce conditions.

**Performance in the inductive setting.** Our primary experiments focus on the transductive setting, characterized by the assumption that all nodes are visible in the training process. To offer a holistic evaluation, we also conduct experiments in the inductive setting using DGraph-Fin and Elliptic datasets which have temporal features. In this setting, features and structures associated with test nodes are not accessible during the training phase. As presented in table 6, the model performance is generally impacted in the inductive setting of two datasets. Specifically, XGB-Graph outperforms other models across all metrics on Elliptic, while GHRN stands out as the most robust model on DGraph-Fin.

**The impact of different number of neighbor aggregation layers.** Figure 2 illustrates the performance change in XGB-Graph and RF-Graph with varying numbers of neighbor aggregation layers. Observably, the performance on most datasets improves when the number of neighbor aggregation layers increases from 0 to 2, confirming the effectiveness of the neighbor aggregation process. However, further increments in the number of layers do not contribute to any significant improvement in the model performance. Consequently, in most instances, two layers are adequate for XGB-Graph and RF-Graph, and utilizing more layers could lead to unnecessary computational overhead and memory usage.

### Why and When Do Tree Ensembles with Neighbor Aggregation Outperform GNNs?

**An initial study on decision boundaries.** Inspired by a recent benchmark about ensemble trees and neural networks on the tabular data [28], we explore the possible reasons for the superior performance of ensemble trees with neighborhood aggregation. Specifically, our primary investigation focuses on the models' decision boundaries.

In the left panel of Figure 3, we visualize the decision boundaries of GIN and RF-Graph on Amazon dataset. For detailed implementations, please see Appendix E. It is observed that the normal and anomalous nodes are closely intertwined, making them hard to separate. Unfortunately, GIN tends to produce simple and smooth decision boundaries, leading to frequent misclassification of normal nodes in the right bottom corners. Differently, RF-Graph can produce more intricate decision boundaries, demonstrating greater proficiency in distinguishing anomalous data. In the right panel of Figure 3, we visualize the decision boundaries of BWGNN and XGB-Graph on Weibo dataset. As can be seen, the anomalous nodes are grouped into several dispersed clusters. With this dispersed distributions, BWGNN is hard to achieve accurate classification due to simple and continuous decision boundaries. In contrast, XGB-Graph successfully classifies anomalies within each cluster.

\begin{table}
\begin{tabular}{l|c c c|c c c|c c c|c c c} \hline \hline  & \multicolumn{3}{c|}{Elliptic (Inductive)} & \multicolumn{3}{c|}{Elliptic (Transductive)} & \multicolumn{3}{c|}{DGraph-Fin (Inductive)} & \multicolumn{3}{c}{DGraph-Fin (Transductive)} \\ \cline{2-13} Model & AUROC & AUPRC & Rec@K & AUROC & AUPRC & Rec@K & AUROC & AUPRC & Rec@K & AUROC & AUPRC & Rec@K \\ \hline GCN & 75.79 & 14.97 & 16.73 & 92.40 & 73.87 & 69.99 & 73.93 & 3.35 & 5.61 & 75.85 & 3.99 & 7.05 \\ GraphsSAGE & 79.51 & 19.64 & 20.59 & 82.85 & 34.76 & 45.95 & 72.66 & 3.06 & 5.43 & 75.63 & 3.76 & 6.97 \\ BWGNN & 82.29 & 22.49 & 28.26 & 96.12 & 86.58 & 81.14 & 73.85 & 3.24 & 5.83 & **76.26** & **4.01** & 7.52 \\ GHRN & 84.74 & 25.42 & 28.54 & 96.05 & 86.57 & 81.11 & **76.20** & **4.03** & **7.48** & 76.14 & 3.99 & **7.54** \\ \hline XGB-Graph & **90.36** & **76.20** & **70.64** & **96.80** & **89.58** & **84.59** & 71.25 & 2.81 & 5.33 & 74.64 & 3.66 & 6.75 \\ \hline \hline \end{tabular}
\end{table}
Table 6: Performance comparison on the Elliptic and DGraph-Fin datasets under inductive and transductive settings, with all results being averaged over 10 runs.

Figure 2: The impact of different number of neighbor aggregation layers on the performance of XGB-Graph and RF-Graph.

In summary, anomaly instances tend to form multiple dispersed clusters and are coupled with normal instances, which fall in the categories of the inductive bias of RF-Graph and XGB-Graph that favor complex and disjoint decision boundaries. In contrast, as GNNs typically employ MLP as the final layer, they tend to generate simple and continuous decision boundaries, which makes GNNs sub-optimal on some challenging GAD datasets.

**The impact of dataset feature types on model performance.** As indicated in Table 3, out of the 10 datasets in GADBench, 3 datasets purely use text embeddings as node features, while in the remaining 7 datasets, node features contain miscellaneous information such as the combination of numerical, categorical, and temporal features. Notably, for datasets that rely on text-based features--namely Reddit, Weibo, and Questions--GNNs showcase competitive performance in comparison to other methods including tree ensembles. This could be attributed to the nature of text embeddings: they often represent low-dimensional manifolds in a high-dimensional feature space, where dimensions tend to be highly correlated. A GNN can process all these dimensions simultaneously, whereas an individual decision tree might only consider a limited subset of feature columns. Conversely, in the other 7 datasets with diverse feature types that have low correlation (for instance, gender and age information), tree ensembles with neighbor aggregation typically exhibit superior performance.

In conclusion, in common GAD scenarios such as fraud detection, node features mainly originate from user profiles, which may encompass varied feature types. Thus, tree ensembles with neighbor aggregation often emerge as the preferred choice. However, for specific tasks like fake news and rumor detection, where text data is pivotal, GNNs still present a compelling option.

## 5 Conclusion and Future Plan

In this paper, we introduce GADBench, the first comprehensive benchmark for supervised anomalous node detection on static attributed graphs. Our evaluation of 29 models on 10 real-world datasets shows that tree ensembles with simple neighborhood aggregation generally outperform other models, including GNNs specifically designed for the GAD task. The rationale behind this finding is initially examined from the standpoints of decision boundary and node feature type. Our results challenge the prevailing belief about the superiority of GNNs in GAD and underline the importance of a fair and comprehensive comparison in accurately understanding the capabilities of various models. By making GADBench open-source, we aim to foster further research and refinement of GAD algorithms, as well as their more informed evaluations and comparisons.

We regard GADBench as a long-term evolving project and are dedicated to its continuous development. Our roadmap for the future includes expanding its scope to include a broader spectrum of GAD scenarios, incorporating more cutting-edge models, and integrating newer datasets. At present, we primarily focus on treating datasets as static graphs to ensure compatibility with most baselines. We have only embarked on preliminary studies concerning heterogeneous and inductive settings. Looking ahead, we envision extending our evaluations to more complex types of graphs and anomalies. Our ultimate goal is to transform GADBench into a more robust, scalable GAD toolbox, with advanced features like automated model selection [95].

**Acknowledgement** This research was supported by NSFC Grant No. 62206067, Tencent AI Lab Rhino-Bird Focused Research Program and Guangzhou-HKUST(GZ) Joint Funding Scheme 2023A03J0673.

Figure 3: Decision boundaries comparison of different approaches. Blue points represent anomalies while red points are normal nodes. Similarly, the blue/red regions correspond to model predictions for anomalous/normal classes.

## References

* [1] Andra Acsimtoae, Andrei Florescu, Mariana-Iuliana Georgescu, Tudor Mare, Paul Sumedrea, Radu Tudor Ionescu, Fahad Shahbaz Khan, and Mubarak Shah. Ubnormal: New benchmark for supervised open-set video anomaly detection. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 20143-20153, June 2022.
* [2] Charu C Aggarwal. Outlier ensembles: position paper. _ACM SIGKDD Explorations Newsletter_, 14(2):49-58, 2013.
* [3] Leman Akoglu, Mary McGlohon, and Christos Faloutsos. Oddball: Spotting anomalies in weighted graphs. In _Advances in Knowledge Discovery and Data Mining: 14th Pacific-Asia Conference, PAKDD 2010, Hyderabad, India, June 21-24, 2010. Proceedings. Part II 14_, pages 410-421. Springer, 2010.
* [4] Leman Akoglu, Hanghang Tong, and Danai Koutra. Graph based anomaly detection and description: a survey. _Data mining and knowledge discovery_, 29(3):626-688, 2015.
* [5] Susan Athey, Julie Tibshirani, and Stefan Wager. Generalized random forests. _The Annals of Statistics_, 47(2):1148-1178, 2019.
* [6] Mariana Belgiu and Lucian Dragut. Random forest in remote sensing: A review of applications and future directions. _ISPRS journal of photogrammetry and remote sensing_, 114:24-31, 2016.
* [7] James Bergstra, Daniel Yamins, and David Cox. Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures. In _International conference on machine learning_, pages 115-123. PMLR, 2013.
* [8] Tian Bian, Xi Xiao, Tingyang Xu, Peilin Zhao, Wenbing Huang, Yu Rong, and Junzhou Huang. Rumor detection on social media with bi-directional graph convolutional networks. In _Proceedings of the AAAI Conference on Artificial Intelligence_, 2020.
* [9] Gerard Biau. Analysis of a random forests model. _The Journal of Machine Learning Research_, 13(1):1063-1095, 2012.
* [10] Azzedine Boukerche, Lining Zheng, and Omar Alfandi. Outlier detection: Methods, models, and classification. _ACM Computing Surveys (CSUR)_, 53(3):1-37, 2020.
* [11] Xavier Bouthillier, Pierre Delaunay, Mirko Bronzi, Assya Trofimov, Brennan Nichyporuk, Justin Szeto, Nazanin Mohammadi Sepahvand, Edward Raff, Kanika Madan, Vikram Voleti, et al. Accounting for variance in machine learning benchmarks. _Proceedings of Machine Learning and Systems_, 3:747-769, 2021.
* [12] Leo Breiman. Random forests. _Machine learning_, 45:5-32, 2001.
* [13] Ziwei Chai, Siqi You, Yang Yang, Shiliang Pu, Jiarong Xu, Haoyang Cai, and Weihao Jiang. Can abnormality be detected by graph neural networks? In _IJCAI_, 2022.
* [14] Deepayan Chakrabarti. Autopart: Parameter-free graph partitioning and outlier detection. In _European conference on principles of data mining and knowledge discovery_, pages 112-124. Springer, 2004.
* [15] Chih-Chung Chang and Chih-Jen Lin. Libsvm: a library for support vector machines. _ACM transactions on intelligent systems and technology (TIST)_, 2(3):1-27, 2011.
* [16] Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In _Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining_, pages 785-794, 2016.
* [17] Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Lio, and Petar Velickovic. Principal neighbourhood aggregation for graph nets. _Advances in Neural Information Processing Systems_, 33:13260-13271, 2020.
* [18] Thomas Cover and Peter Hart. Nearest neighbor pattern classification. _IEEE transactions on information theory_, 13(1):21-27, 1967.
* [19] Michael Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. _NeurIPS_, pages 3844-3852, 2016.
* [20] Ailin Deng and Bryan Hooi. Graph neural network-based anomaly detection in multivariate time series. In _Proceedings of the AAAI conference on artificial intelligence_, pages 4027-4035, 2021.

* [21] Kaize Ding, Jundong Li, Rohit Bhanushali, and Huan Liu. Deep anomaly detection on attributed networks. In _Proceedings of the SDM_, pages 594-602. SIAM, 2019.
* [22] Yingtong Dou, Zhiwei Liu, Li Sun, Yutong Deng, Hao Peng, and Philip S Yu. Enhancing graph neural network-based fraud detectors against camouflaged fraudsters. In _CIKM_, pages 315-324, 2020.
* [23] Yingtong Dou, Guixiang Ma, Philip S Yu, and Sihong Xie. Robust spammer detection by nash reinforcement learning. In _Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_, 2020.
* [24] Jingcan Duan, Siwei Wang, Pei Zhang, En Zhu, Jingtao Hu, Hu Jin, Yue Liu, and Zhibin Dong. Graph anomaly detection via multi-scale contrastive learning networks with augmented view. _arXiv preprint arXiv:2212.00535_, 2022.
* [25] Zhouyu Fu, Weiming Hu, and Tieniu Tan. Similarity based vehicle trajectory clustering and anomaly detection. In _IEEE International Conference on Image Processing 2005_, volume 2, pages II-602. Ieee, 2005.
* [26] Yuan Gao, Xiang Wang, Xiangnan He, Zhenguang Liu, Huamin Feng, and Yongdong Zhang. Addressing heterophily in graph anomaly detection: A perspective of graph spectrum. In _Proceedings of the ACM Web Conference_, 2023.
* [27] Yuan Gao, Xiang Wang, Xiangnan He, Zhenguang Liu, Huamin Feng, and Yongdong Zhang. Alleviating structural distribution shift in graph anomaly detection. In _Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining_, pages 357-365, 2023.
* [28] Leo Grinsztajn, Edouard Oyallon, and Gael Varoquaux. Why do tree-based models still outperform deep learning on typical tabular data? In _Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track_, 2022.
* [29] Zoltan Gyongyi, Hector Garcia-Molina, and Jan O. Pedersen. Combating web spam with trustrank. In _(e)Proceedings of the Thirtieth International Conference on Very Large Data Bases, VLDB_, 2004.
* [30] William L Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. In _NeurIPS_, 2017.
* [31] Songqiao Han, Xiyang Hu, Hailiang Huang, Mingqi Jiang, and Yue Zhao. ADBench: Anomaly detection benchmark. In _Advances in Neural Information Processing Systems (NeurIPS)_, 2022.
* [32] Mingguo He, Zhewei Wei, Hongtenge Xu, et al. Bernnet: Learning arbitrary graph spectral filters via bernstein approximation. _Advances in Neural Information Processing Systems_, 34:14239-14251, 2021.
* [33] NA Heard, David J Weston, K Platanioti, and DJ Hand. Bayesian anomaly detection methods for social networks. _The Annals of Applied Statistics_, 4(2):645-662, 2010.
* [34] Keith Henderson, Tina Eliassi-Rad, Christos Faloutsos, Leman Akoglu, Lei Li, Koji Maruhashi, B Aditya Prakash, and Hanghang Tong. Metric forensics: a multi-level approach for mining volatile graphs. In _Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining_, pages 163-172, 2010.
* [35] Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. Heterogeneous graph transformer. In _Proceedings of the web conference 2020_, pages 2704-2710, 2020.
* [36] Xuanwen Huang, Yang Yang, Yang Wang, Chunping Wang, Zhisheng Zhang, Jiaroug Xu, Lei Chen, and Michalis Vazirgiannis. Dgraph: A large-scale financial dataset for graph anomaly detection. In _Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track_, 2022.
* [37] Sergei Ivanov and Liudmila Prokhorenkova. Boost then convolve: Gradient boosting meets graph neural networks. In _ICLR_, 2021.
* [38] Minqi Jiang, Chaochuan Hou, Ao Zheng, Xiyang Hu, Songqiao Han, Hailiang Huang, Xiangnan He, Philip S Yu, and Yue Zhao. Weakly supervised anomaly detection: A survey. _arXiv preprint arXiv:2302.04549_, 2023.
* [39] Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In _ICLR_, 2017.

* [40] Danai Koutra, Tai-You Ke, U Kang, Duen Horng Polo Chau, Hsing-Kuo Kenneth Pao, and Christos Faloutsos. Unifying guilt-by-association approaches: Theorems and fast algorithms. In _Joint European Conference on Machine Learning and Knowledge Discovery in Databases_, pages 245-260. Springer, 2011.
* [41] Srijan Kumar, Bryan Hooi, Disha Makhija, Mohit Kumar, Christos Faloutsos, and VS Subrahmanian. Rev2: Fraudulent user prediction in rating platforms. In _Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining_, pages 333-341, 2018.
* [42] Srijan Kumar, Kikun Zhang, and Jure Leskovec. Predicting dynamic embedding trajectory in temporal interaction networks. In _Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining_, pages 1269-1278, 2019.
* [43] Kingsly Leung and Christopher Leckie. Unsupervised anomaly detection in network intrusion detection using clusters. In _Proceedings of the Twenty-eighth Australasian conference on Computer Science-Volume 38_, pages 333-342, 2005.
* [44] Ao Li, Zhou Qin, Runshi Liu, Yiqun Yang, and Dong Li. Spam review detection with graph convolutional networks. In _Proceedings of the 28th ACM International Conference on Information and Knowledge Management_, pages 2703-2711, 2019.
* [45] Jundong Li, Harsh Dani, Xia Hu, and Huan Liu. Radar: Residual analysis for anomaly detection in attributed networks. In _IJCAI_, pages 2152-2158, 2017.
* [46] Tianfu Li, Zheng Zhou, Sinan Li, Chuang Sun, Ruqiang Yan, and Xuefeng Chen. The emerging graph neural networks for intelligent fault diagnostics and prognostics: A guideline and a benchmark study. _Mechanical Systems and Signal Processing_, 168:108653, 2022.
* [47] Fanzhen Liu, Xiaoxiao Ma, Jia Wu, Jian Yang, Shan Xue, Amin Beheshti, Chuan Zhou, Hao Peng, Quan Z Sheng, and Charu C Aggarwal. Dagad: Data augmentation for graph anomaly detection. _arXiv preprint arXiv:2210.09766_, 2022.
* [48] Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. Isolation-based anomaly detection. _ACM Transactions on Knowledge Discovery from Data (TKDD)_, 6(1):1-39, 2012.
* [49] Kay Liu, Yingtong Dou, Yue Zhao, Xueying Ding, Xiyang Hu, Ruitong Zhang, Kaize Ding, Canyu Chen, Hao Peng, Kai Shu, Lichao Sun, Jundong Li, George H Chen, Zhihao Jia, and Philip S Yu. Bond: Benchmarking unsupervised outlier node detection on static attributed graphs. In _Advances in Neural Information Processing Systems_, volume 35, 2022.
* [50] Yang Liu, Xiang Ao, Zidi Qin, Jianfeng Chi, Jinghua Feng, Hao Yang, and Qing He. Pick and choose: A gnn-based imbalanced learning approach for fraud detection. In _Proceedings of the Web Conference 2021_, 2021.
* [51] Zhiwei Liu, Yingtong Dou, Philip S Yu, Yutong Deng, and Hao Peng. Alleviating the inconsistency problem of applying graph neural network to fraud detection. In _SIGIR_, pages 1569-1572, 2020.
* [52] Zhiyuan Liu, Chunjie Cao, and Jingzhang Sun. Mul-gad: a semi-supervised graph anomaly detection framework via aggregating multi-view information. _arXiv preprint arXiv:2212.05478_, 2022.
* [53] Zhiyuan Liu, Chunjie Cao, Fangjian Tao, and Jingzhang Sun. Revisiting graph contrastive learning for anomaly detection. _arXiv preprint arXiv:2305.02496_, 2023.
* [54] Ziqi Liu, Chaochao Chen, Longfei Li, Jun Zhou, Xiaolong Li, Le Song, and Yuan Qi. Geniepath: Graph neural networks with adaptive receptive paths. In _Proceedings of the AAAI Conference on Artificial Intelligence_, pages 4424-4431, 2019.
* [55] Xiaoxiao Ma, Jia Wu, Shan Xue, Jian Yang, Chuan Zhou, Quan Z Sheng, Hui Xiong, and Leman Akoglu. A comprehensive survey on graph anomaly detection with deep learning. _IEEE Transactions on Knowledge and Data Engineering_, 2021.
* [56] Julian John McAuley and Jure Leskovec. From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews. In _WWW_, 2013.
* [57] Caleb C Noble and Diane J Cook. Graph-based anomaly detection. In _KDD_, 2003.
* [58] Adeola Ogunleye and Qing-Guo Wang. Xgboost model for chronic kidney disease diagnosis. _IEEE/ACM transactions on computational biology and bioinformatics_, 17(6):2131-2140, 2019.

* [59] John Paparrizos, Yuhao Kang, Paul Boniol, Ruey S Tsay, Themis Palpanas, and Michael J Franklin. Tsb-uad: an end-to-end benchmark suite for univariate time-series anomaly detection. _Proceedings of the VLDB Endowment_, 2022.
* [60] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. _NeurIPS_, 32:8026-8037, 2019.
* [61] Dhaval Patel, Giridhar Ganapavarapu, Srideepika Jayaraman, Shuxin Lin, Anuradha Bhamidipaty, and Jayant Kalagnanam. Anomalykits: Anomaly detection toolkit for time series. In _Proceedings of the AAAI Conference on Artificial Intelligence_, pages 13209-13211, 2022.
* [62] Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. Scikit-learn: Machine learning in python. _the Journal of machine Learning research_, 12:2825-2830, 2011.
* [63] Zhen Peng, Minnan Luo, Jundong Li, Huan Liu, and Qinghua Zheng. Anomalous: A joint modeling approach for anomaly detection on attributed networks. In _IJCAI_, pages 3513-3519, 2018.
* [64] Muhammad Shakil Pervez and Dewan Md Farid. Feature selection and intrusion classification in nslkdd cup 99 dataset employing svms. In _The 8th International Conference on Software, Knowledge, Information Management and Applications (SKIMA 2014)_, pages 1-6. IEEE, 2014.
* [65] Oleg Platonov, Denis Kuznedelev, Michael Diskin, Artem Babenko, and Liudmila Prokhorenkova. A critical look at the evaluation of gnns under heterophily: are we really making progress? In _ICLR_, 2023.
* [66] Shebuti Rayana and Leman Akoglu. Collective opinion spam detection: Bridging review networks and metadata. In _KDD_, pages 985-994, 2015.
* [67] Frank Rosenblatt. The perceptron: a probabilistic model for information storage and organization in the brain. _Psychological review_, 65(6):386, 1958.
* [68] Lukas Ruff, Robert A Vandermeulen, Billy Joe Franks, Klaus-Robert Muller, and Marius Kloft. Rethinking assumptions in deep anomaly detection. _arXiv preprint arXiv:2006.00339_, 2020.
* [69] Patricia Iglesias Sanchez, Emmanuel Muller, Fabian Loforet, Fabian Keller, and Klemens Bohm. Statistical selection of congruent subspaces for mining attributed graphs. In _2013 IEEE 13th international conference on data mining_, pages 647-656. IEEE, 2013.
* [70] Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. Modeling relational data with graph convolutional networks. In _The Semantic Web: 15th International Conference_, pages 593-607, 2018.
* [71] Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. Collective classification in network data. _AI magazine_, 29(3):93-93, 2008.
* [72] Fengzhao Shi, Yanan Cao, Yanmin Shang, Yuchen Zhou, Chuan Zhou, and Jia Wu. H2-fdetector: A gnn-based fraud detector with homophilic and heterophilic connections. In _Proceedings of the ACM Web Conference 2022_, pages 1486-1494, 2022.
* [73] Yunsheng Shi, Zhengjie Huang, Shikun Feng, Hui Zhong, Wenjing Wang, and Yu Sun. Masked label prediction: Unified message passing model for semi-supervised classification. In _IJCAI_, 2021.
* [74] Jianheng Tang, Jiajin Li, Ziqi Gao, and Jia Li. Rethinking graph neural networks for anomaly detection. In _International Conference on Machine Learning_, 2022.
* [75] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. _Journal of machine learning research_, 9(11), 2008.
* [76] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. In _ICLR_, 2017.
* [77] Miryam Elizabeth Villa-Perez, Miguel A Alvarez-Carmona, Octavio Loyola-Gonzalez, Miguel Angel Medina-Perez, Juan Carlos Velazco-Rossell, and Kim-Kwang Raymond Choo. Semi-supervised anomaly detection algorithms: A comparative summary and future research directions. _Knowledge-Based Systems_, 218:106878, 2021.
* [78] Chen Wang, Chengyuan Deng, and Suzhen Wang. Imbalance-xgboost: leveraging weighted and focal losses for binary label-imbalanced classification with xgboost. _Pattern Recognition Letters_, 136:190-197, 2020.

* [79] Daixin Wang, Jianbin Lin, Peng Cui, Quanhui Jia, Zhen Wang, Yanming Fang, Quan Yu, Jun Zhou, Shuang Yang, and Yuan Qi. A semi-supervised graph attentive network for financial fraud detection. In _ICDM_, pages 598-607. IEEE, 2019.
* [80] Minjie Wang, Da Zheng, Zihao Ye, Quan Gan, Mufei Li, Xiang Song, Jinjing Zhou, Chao Ma, Lingfan Yu, Yu Gai, Tianjun Xiao, Tong He, George Karypis, Jinyang Li, and Zheng Zhang. Deep graph library: A graph-centric, highly-performant package for graph neural networks. _arXiv:1909.01315_, 2019.
* [81] Xiang Wang and Ian Davidson. Discovering contexts and contextual outliers using random walks in graphs. In _2009 Ninth IEEE International Conference on Data Mining_, pages 1034-1039. IEEE, 2009.
* [82] Yanling Wang, Jing Zhang, Shasha Guo, Hongzhi Yin, Cuiping Li, and Hong Chen. Decoupling representation learning and classification for gnn-based anomaly detection. In _Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval_, pages 1239-1248, 2021.
* [83] Mark Weber, Giacomo Domeniconi, Jie Chen, Daniel Karl I Weidele, Claudio Bellei, Tom Robinson, and Charles E Leiserson. Anti-money laundering in bitcoin: Experimenting with graph convolutional networks for financial forensics. _arXiv preprint arXiv:1908.02591_, 2019.
* [84] Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian Weinberger. Simplifying graph convolutional networks. In _ICML_, pages 6861-6871, 2019.
* [85] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? _ICLR_, 2019.
* [86] Xiaowei Xu, Nurcan Yuruk, Zhidan Feng, and Thomas AJ Schweiger. Scan: a structural clustering algorithm for networks. In _Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining_, pages 824-833, 2007.
* [87] Jiawei Yang, Yu Chen, and Sylwan Rahardja. Neighborhood representative for improving outlier detectors. _Information Sciences_, 625:192-205, 2023.
* [88] Jiawei Yang, Susanto Rahardja, and Pasi Franti. Neighborhood averaging for improving outlier detectors. _arXiv preprint arXiv:2303.09972_, 2023.
* [89] Jiawei Yang, Sylwan Rahardja, and Susanto Rahardja. Foor: Be careful for outlier-score outliers when using unsupervised outlier ensembles. _IEEE Transactions on Computational Social Systems_, 2023.
* [90] Ge Zhang, Jia Wu, Jian Yang, Amin Beheshti, Shan Xue, Chuan Zhou, and Quan Z Sheng. Fraudre: Fraud detection dual-resistant to graph inconsistency and imbalance. In _2021 IEEE International Conference on Data Mining (ICDM)_, pages 867-876. IEEE, 2021.
* [91] Wentao Zhang, Ziqi Yin, Zeang Sheng, Yang Li, Wen Ouyang, Xiaosen Li, Yangyu Tao, Zhi Yang, and Bin Cui. Graph attention multi-layer perceptron. In _Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, pages 4560-4570, 2022.
* [92] Tong Zhao, Chuchen Deng, Kaifeng Yu, Tianwen Jiang, Daheng Wang, and Meng Jiang. Error-bounded graph anomaly loss for gnns. In _CIKM_, 2020.
* [93] Yue Zhao and Maciej K Hyniewicki. Xgbd: improving supervised outlier detection with unsupervised representation learning. In _2018 International Joint Conference on Neural Networks (IJCNN)_, pages 1-8. IEEE, 2018.
* [94] Yue Zhao, Zain Nasrullah, and Zheng Li. PyOD: A python toolbox for scalable outlier detection. _Journal of Machine Learning Research_, 20(96):1-7, 2019.
* [95] Yue Zhao, Ryan Rossi, and Leman Akoglu. Automatic unsupervised outlier model selection. _Proceedings of the NeurIPS_, 34:4489-4502, 2021.
* [96] Li Zheng, Zhenpeng Li, Jian Li, Zhao Li, and Jun Gao. Addgraph: Anomaly detection in dynamic graph using attention-based temporal gcn. In _IJCAI_, pages 4419-4425, 2019.
* [97] Jiancheng Zhong, Yusui Sun, Wei Peng, Minzhu Xie, Jiahong Yang, and Xiwei Tang. Xgbfemf: an xgboost-based framework for essential protein prediction. _IEEE transactions on nanobioscience_, 17(3):243-250, 2018.
* [98] Hao Zhu and Piotr Koniusz. Simple spectral graph convolution. In _International conference on learning representations_, 2021.

* [99] Jiong Zhu, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, and Danai Koutra. Beyond homophily in graph neural networks: Current limitations and effective designs. _Advances in Neural Information Processing Systems_, 33, 2020.
* [100] Arthur Zimek, Ricardo JGB Campello, and Jorg Sander. Ensembles for unsupervised outlier detection: challenges and research questions a position paper. _Acm Sigkdd Explorations Newsletter_, 15(1):11-22, 2014.

Detailed Description of Models in GADBench

**Classic Methods**

* **MLP (Multi-Layer Perceptron [67]:** A type of feedforward neural network composed of multiple layers of interconnected artificial neurons that can learn and make predictions by adjusting the weights and biases of the connections between the neurons.
* **KNN (\(k\)-Nearest Neighbors [18]):** A non-parametric classification algorithm that assigns labels to data points based on the labels of their \(k\) nearest neighbors within the feature space.
* **SVM (Support Vector Machine [15]):** A supervised learning algorithm that classifies data by identifying an optimal hyperplane that maximally separates different classes in a high-dimensional feature space.
* **RF (Random Forest [12]):** An ensemble learning algorithm that utilizes bagging to train a collection of individual decision tree models on subsets of the original dataset. The predictions from these individual models are then combined through averaging or voting, resulting in a robust and accurate prediction model.
* **XGBoost (eXtreme Gradient Boosting [16]):** A gradient boosting decision tree framework that uses a gradient descent algorithm to minimize the loss function and iteratively adds new trees into the model to correct the errors made by the previous trees.
* **XGBOD (Extreme Boosting Based Outlier Detection [93]):** An enhanced XGBoost model that integrates unsupervised outlier detectors to generate abnormality scores as additional features for the original data. These generated features are concatenated to the original feature set and used in an XGBoost classifier for outlier detection.
* **Neighborhood Averaging [88]:** A method that post-processes the outlier scores provided by any existing outlier detector by averaging it with the scores of its neighbors in the feature space. In GADBench, we integrated this technique into BWGNN as a case study for in-depth analysis.

**Standard GNN Architectures**

* **GCN (Graph Convolutional Network [39]):** A method that utilizes convolution operation on the graph to propagate information from a node to its neighboring nodes, enabling the network to learn a representation for each node based on its local neighborhood.
* **ChebNet ( Chebyshev Spectral Convolution Network [19]):** A variant of GCN that applies Chebyshev polynomials to approximate the spectral graph convolution operator. This approach allows the model to capture both local and global graph structures, making it scalable for larger graphs.
* **GIN (Graph Isomorphism Network [85]):** A type of GNN that learns to capture the structure of a graph while respecting graph isomorphism. This means it generates identical embeddings for graphs that are structurally identical, regardless of permutations in their node labels.
* **GraphSAGE (Graph Sample and Aggregate [30]:)** A general inductive learning framework that generates node embeddings by sampling and aggregating features from a node's local neighborhood.
* **GAT (Graph Attention Networks [76]):** A GNN framework that incorporates the attention mechanism. It assigns varying levels of importance to different nodes during the neighborhood information aggregation process, allowing the model to focus on the most informative parts.
* **GT (Graph Transformer [73]):** An adaptation of the neural network architecture that applies the principles of the Transformer model to graph-structured data. It uses masks in the self-attention process to leverage the graph structure and enhance model efficiency
* **PNA (Principle Neighbor Aggregation)[17]:** A novel graph neural network architecture combining multiple aggregators with degree-scalers in the neighborhood aggregation process.
* **BGNN (Gradient Boosting Meets Graph Neural Networks) [37]:** An end-to-end framework that trains GBDT and GNN jointly by allowing new trees to fit the gradient updates of GNN.
* **RGCN (Relational Graph Convolution Network) [70]:** A specialized framework derived from Graph Convolutional Networks, tailored for handling relational data.
* **HGT (Heterogeneous Graph Transformer) [35]:** A GNN framework to model Web-scale heterogeneous graphs by designing node- and edge-type dependent parameters for characterizing heterogeneous attention over each edge, thus facilitating the maintenance of dedicated representations for different types of nodes and edges.

**GNNs Specialized for Graph Anomaly Detection**

* **GAS (GCN-based Anti-Spam [44]):** A highly scalable method for detecting spam reviews. It extends GCN to handle heterogeneous and heterophilic graphs and adapts to the graph structure of specific GAD applications using the KNN algorithm.
* **DCI (Deep Cluster Infomax[82]):** A self-supervised learning scheme that decouples node representation learning from classification for anomaly detection. It mitigates inconsistencies between node behavior patterns and label semantics, and captures intrinsic graph properties in concentrated feature spaces by clustering the entire graph into multiple parts.
* **PC-GNN (Pick and Choose Graph Neural Network [50]):** A framework designed for imbalanced GNN learning in fraud detection. It uses a label-balanced sampler to select nodes and edges for training, resulting in a balanced label distribution in the induced sub-graph. Furthermore, it employs a learnable parameterized distance function to select neighbors, filtering out redundant links and adding beneficial ones for fraud prediction.
* **BernNet [32]:** A GNN variant that offers a robust scheme for designing and learning arbitrary graph spectral filters. It uses an order-K Bernstein polynomial approximation to estimate any filter over the normalized Laplacian spectrum of a graph.
* **GAT-sep [99]:** A GNN designed to enhance learning from graph structures under high heterophily. It combines key designs such as ego- and neighbor-embedding separation, higher-order neighborhoods, and intermediate representation combinations.
* **AMNet (Adaptive Multi-frequency Graph Neural Network [13]):** A method designed to capture both low-frequency and high-frequency signals through stacking multiple BernNets, and adaptively combine signals of different frequencies.
* **BWGNN (Beta Wavelet Graph Neural Network [74]):** A method proposed to tackle the 'right-shift' phenomenon of graph anomalies, i.e., the spectral energy distribution concentrates less on low frequencies and more on high frequencies. It employs the Beta kernel to address higher frequency anomalies through multiple flexible, spatial/spectral-localized, and band-pass filters
* **GHRN (Graph Heterophily Reduction Network [26]):** A method that addresses the heterophily issue in the spectral domain of graph anomaly detection. The approach prune inter-class edges to emphasize and delineate the graph's high-frequency components.
* **CARE-GNN (CAmouflage-REsistant GNN) [22]:** A GNN-based fraud detector designed for multi-relation graphs, which is equipped with three modules that enhance its performance against camouflaged fraudsters.
* **H2-FDetector (Fraud Detector with Homophilic and Heterophilic Interactions) [72]** A heterogeneous GNN framework for fraud detection that facilitates the propagation of analogous information through homophilic connections and varied information via heterophilic connection.

## Appendix B Detailed Description of Datasets in GADBench

**Reddit [42]**: This dataset contains a user-subreddit graph, capturing one month's worth of posts shared across various subreddits. Verified labels of banned users are included. The dataset focuses on the 1,000 most active subreddits and the 10,000 most engaged users, leading to a total of 672,447 interactions. Posts were transformed into feature vectors, each representing the Linguistic Inquiry and Word Count (LIWC) categories of the text.

**Weibo [42]**: This dataset features a graph of users and their associated hashtags from the Tencent-Weibo platform, consisting of 8,405 users and 61,964 hashtags. Suspicious activities are defined as two posts made within specific timeframes, such as 60 seconds. Users that engaged in at least five such activities are labeled as "suspicious", while the rest are categorized as "benign". This process yielded 868 suspicious and 7,537 benign users. The raw feature vector is composed of the location of a micro-blog post and bag-of-words features.

**YelpChi [66]**: This dataset is designed to identify anomalous reviews that unfairly promote or demote products or businesses on Yelp.com. The graph includes three types of edges: R-U-R (reviews posted by the same user), R-S-R (reviews for the same product with the same star rating), and R-T-R (reviews for the same product posted in the same month).

**Amazon [56]**: The goal of this dataset is to identify users paid to write fake reviews for products in the Musical Instrument category on Amazon.com. The graph includes three types of relations:U-P-U (users reviewing at least one same product), U-S-U (users giving at least one same star rating within one week), and U-V-U (users with top-5% mutual review similarities).

**T-Finance**[74]: This dataset aims to find the anomaly accounts in transaction networks. The nodes are unique anonymized accounts with 10-dimension features related to registration days, logging activities and interaction frequency. The edges in the graph represent two accounts that have transaction records. Human experts annotate nodes as anomalies if they fall into categories like fraud, money laundering and online gambling.

**Tolokers**[65]: This dataset is derived from the Toloka crowd-sourcing platform. Nodes represent workers who have participated in at least one of 13 selected projects, and an edge connects two workers if they worked on the same task. The task is to predict which worker has been banned in one of the projects. Node features are based on worker's profile and task performance statistics.

**Questions**[65]: This dataset is collected from the question-answering website Yandex Q. Nodes are users, and an edge connects two users if one user answered the other user's question during a one-year period (September 2021 to August 2022). The dataset focuses on users interested in the topic "medicine". The task is to predict which users remained active on the website at the end of the period. Node features are the mean of FastText embeddings for words in the user description, with an additional binary feature indicating users without descriptions.

**Elliptic**[83]: This dataset includes a graph of over 200,000 Bitcoin transactions (nodes), 234,000 directed payment flows (edges), and 166 node features. The dataset maps Bitcoin transactions to real-world entities associated with licit categories, such as exchanges, wallet providers, miners, and legal services, as well as illicit categories like scams, malware, terrorist organizations, ransomware, and Ponzi schemes.

**DGraph-Fin**[36]: This dataset is a real-world, large-scale dynamic graph provided by the Finvolution Group, representing a social network within the financial industry. In DGraph-Fin, a node represents a Finvolution user, and an edge between two users indicates that one user lists the other as their emergency contact. Anomalous nodes in DGraph-Fin represent users who exhibit overdue behaviors. The dataset comprises over 3 million nodes, 4 million dynamic edges, and more than 1 million extremely unbalanced ground-truth nodes.

**T-Social**[74]: This dataset aims to find the anomaly accounts in social networks. It has the same node annotations and features as T-Finance, while two nodes are connected if they maintain the friend relationship for more than three months. Same as T-Finance, human experts annotate nodes as anomalies if they fall into categories like fraud, money laundering and online gambling.

## Appendix C Other Information in GADBench

### Metrics

**AUPRC (Area Under the Precision-Recall Curve).** AUPRC is a metric that evaluates the performance of classification models by computing the area beneath the Precision-Recall curve. This curve

\begin{table}
\begin{tabular}{l|c c c} \hline \hline Dataset & Node Feature Type & \#Dim. & Detailed Feature Description \\ \hline Reddit & Text Embedding & 64 & LIWC text embedding for posts \\ Weibo & Text Embedding & 400 & Bag-of-words features from posts \\ Amazon & Misc. Information & 25 & Hand-crafted user features and statistics \\ YelpChi & Misc. Information & 32 & Hand-crafted review features and statistics \\ Tolokers & Misc. Information & 10 & User profile with task performance statistics \\ Questions & Text Embedding & 301 & FastText embeddings for user descriptions \\ T-Finance & Misc. Information & 10 & User profile details such as registration days \\ Elliptic & Misc. Information & 166 & Timestamps and transaction information \\ DGraph-Fin & Misc. Information & 17 & Timestamps and user profiles details \\ T-Social & Misc. Information & 10 & User profile details such as logging activities \\ \hline \hline \end{tabular}
\end{table}
Table 7: Overview of datasets in GADBench with their corresponding node feature types, feature dimension, and detailed descriptions.

[MISSING_PAGE_FAIL:20]

[MISSING_PAGE_FAIL:21]

\begin{table}
\begin{tabular}{l l l l} \hline \hline
**Model** & **Hyperparameter** & **Default value** & **Distribution / Search Space** \\ \hline \multicolumn{3}{l}{_Shared hyperparameters for all neural networks_} \\ \hline Common & learning rate & 0.01 & \(10^{Uniform(-3,-1)}\) \\  & dropout rate & 0 & [0.0.1,0.2,0.3] \\  & hidden dimension & 32 & [16,32,64] \\  & epochs & 100 & - \\ \hline \multicolumn{3}{l}{_Specific hyperparameters for each model_} \\ \hline MLP & layers & 2 & [1,2,3,4] \\  & activation & ReLU & [ReLU, LeakyReLU, Tanh] \\ \hline GCN & layers & 2 & [1,2,3] \\  & activation & ReLU & [ReLU, LeakyReLU, Tanh] \\ \hline SGC & number of hops & 2 & [1,2,3,4] \\  & activation & ReLU & [ReLU, LeakyReLU, Tanh] \\  & MLP layers & 1 & [1,2] \\ \hline GIN & layers & 2 & [1,2,3] \\  & aggregation & mean & [sum, mean, max] \\  & activation & ReLU & [ReLU, LeakyReLU, Tanh] \\ \hline GraphSAGE & layers & 2 & [1,2,3] \\  & aggregation & mean & [mean, GCN, pool] \\  & activation & ReLU & [ReLU, LeakyReLU, Tanh] \\ \hline GAT & layers & 2 & [1,2,3] \\  & attention heads & 4 & [1,2,4,8] \\ \hline GT & layers & 2 & [1,2,3] \\  & attention heads & 4 & [1,2,4,8] \\ \hline PNA & layers & 2 & [1,2,3,4] \\  & activation & ReLU & [ReLU, LeakyReLU, Tanh] \\ \hline BGNN & depth & 6 & [4,5,6,7] \\  & iteration per epoch & 10 & [2,5,10,20] \\  & GBDT learning rate & 0.1 & \(10^{Uniform(-2,-0.5)}\) \\  & normalize features & False & [True, False] \\  & activation & ReLU & [ReLU, LeakyReLU, Tanh] \\ \hline \hline GAS & layers & 2 & [1,2,3,4] \\  & number of neighbors & 5 & RandInt(3,50) \\  & distance function & cosine & [euclidean, cosine] \\ \hline DCI & layers & 2 & [1,2,3,4] \\  & pretain epochs & 100 & [20,50,100] \\  & number of clusters & 2 & RandInt(2,30) \\ \hline PC-GNN & layers & 2 & [1,2,3] \\  & under-sample ratio & 0.7 & Uniform(0.01,0.8) \\  & over-sample ratio & 0.3 & Uniform(0.01,0.8) \\  & distance function & cosine & [euclidean, cosine] \\ \hline GAT-sep & layers & 2 & [1,2,3] \\  & attention heads & 4 & [1,2,4,8] \\ \hline BernNet & MLP layers & 2 & [1,2] \\  & orders & 2 & [2,3,4,5] \\ \hline AMNet & layers & 3 & [1,2,3] \\  & orders & 2 & [2,3] \\  & activation & ReLU & [ReLU, LeakyReLU, Tanh] \\ \hline BWGNN & layers & 2 & [1,2,3,4] \\  & MLP layers & 2 & [1,2] \\  & activation & ReLU & [ReLU, LeakyReLU, Tanh] \\ \hline GHRN & layers & 2 & [1,2,3,4] \\  & MLP layers & 2 & [1,2] \\  & deletion ratio & 0.015 & \(10^{Uniform(-2,-1)}\) \\ \hline \hline \end{tabular}
\end{table}
Table 8: Default hyperparameters and random search space for MLP and GNN models. Elements in [,] is randomly selected with equal probability during each trial. RandInt(\(a\),\(b\)) returns an random integer between \(a\) and \(b\) (both included).

\begin{table}
\begin{tabular}{l|c c c|c c c} \hline \hline  & \multicolumn{3}{c|}{Semi-Supervised} & \multicolumn{3}{c}{Fully-Supervised} \\ Model & AUROC & AUPRC & Rec@K & AUROC & AUPRC & Rec@K \\ \hline GIN & 73.61 & 30.26 & 32.14 & 79.97 & 36.54 & 37.52 \\ with NA & **74.78** & **33.91** & **34.18** & **80.43** & **39.03** & **40.01** \\ \hline BWGNN & 76.00 & 35.42 & **37.36** & **84.73** & **48.19** & 48.01 \\ with NA & **76.95** & **36.96** & 37.34 & 84.70 & 47.93 & **48.08** \\ \hline XGB-Graph & 77.74 & 42.91 & 41.29 & **86.71** & **61.09** & **57.82** \\ with NA & **78.41** & **44.30** & **42.07** & 86.05 & 59.58 & 57.41 \\ \hline RF-Graph & 78.94 & 43.37 & 40.83 & **85.35** & **59.65** & **56.90** \\ with NA & **79.56** & **45.14** & **42.28** & 85.17 & 58.54 & 55.33 \\ \hline \hline \end{tabular}
\end{table}
Table 10: The impact of introducing neighborhood averaging (NA) on the performance of four representative methods in GADBench.

\begin{table}
\begin{tabular}{l l l l} \hline \hline
**Model** & **Hyperparameter** & **Default value** & **Distribution / Search Space** \\ \hline SVM & weights & uniform & [uniform, distance] \\  & L2 regularization \(C\) & 1 & \(10^{\text{Uniform}(-1,1)}\) \\ \hline RF & number of estimators & 100 & RandInt(10,200) \\  & split criterion & gini & [gini, entropy] \\  & max samples & 1 & Uniform(0.1,1) \\ \hline XGBoost & number of estimators & 100 & RandInt(10,200) \\  & learning rate \(\eta\) & 0.3 & \(0.5*10^{\text{Uniform}(-1,0)}\) \\  & L2 regularization \(\lambda\) & 1 & [0,1,10] \\  & subsample rate & 1 & [0.5,0.75,1] \\  & booster & gbtree & [gbtree, dart] \\ \hline XGBOD & Same as XGBoost & & & \\ \hline NA & Same as XGBoost, with 1 additional hyperparameter: & & & \\  & number of neighbors & 5 & RandInt(0,50) \\ \hline RF-Graph & Same as RF, with 2 additional hyperparameters: & & & \\  & aggregation layers \(L\) & 2 & [1,2,3,4] \\  & aggregation function & mean & [sum, mean, max] \\ \hline XGB-Graph & Same as XGBoost, with 2 additional hyperparameters: & & & \\  & aggregation layers \(L\) & 2 & [1,2,3,4] \\  & aggregation function & mean & [sum, mean, max] \\ \hline \hline \end{tabular}
\end{table}
Table 9: Default hyperparameters and random search space for non-deep learning models. Elements in [,] is randomly selected with equal probability during each trial. RandInt(_a,b_) returns an random integer between \(a\) and \(b\) (both included).

[MISSING_PAGE_EMPTY:24]

[MISSING_PAGE_EMPTY:25]

[MISSING_PAGE_EMPTY:26]