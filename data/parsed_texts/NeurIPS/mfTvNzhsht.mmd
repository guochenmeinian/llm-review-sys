## Dueling Over Dessert, Mastering the Art of Repeated Cake Cutting

**Simina Branzei**

Purdue University

simina.branzei@gmail.com

**MohammadTaghi Hajiaghayi**

University of Maryland

hajiaghayi@gmail.com

**Reed Phillips**

Purdue University

phill289@purdue.edu

**Suho Shin**

University of Maryland

suhoshin@umd.edu

**Kun Wang**

Purdue University

wang5675@purdue.edu

## Abstract

We consider the setting of repeated fair division between two players, denoted Alice and Bob, with private valuations over a cake. In each round, a new cake arrives, which is identical to the ones in previous rounds. Alice cuts the cake at a point of her choice, while Bob chooses the left piece or the right piece, leaving the remainder for Alice. We consider two versions: _sequential_, where Bob observes Alice's cut point before choosing left/right, and _simultaneous_, where he only observes her cut point after making his choice. The simultaneous version was first considered in Aumann and Maschler (1995).

We observe that if Bob is almost myopic and chooses his favorite piece too often, then he can be systematically exploited by Alice through a strategy akin to a binary search. This strategy allows Alice to approximate Bob's preferences with increasing precision, thereby securing a disproportionate share of the resource over time.

We analyze the limits of how much a player can exploit the other one and show that fair utility profiles are in fact achievable. Specifically, the players can enforce the equitable utility profile of \((1/2,1/2)\) in the limit on every trajectory of play, by keeping the other player's utility to approximately \(1/2\) on average while guaranteeing they themselves get at least approximately \(1/2\) on average. We show this theorem using a connection with Blackwell approachability.

Finally, we analyze a natural dynamic known as fictitious play, where players best respond to the empirical distribution of the other player. We show that fictitious play converges to the equitable utility profile of \((1/2,1/2)\) at a rate of \(O(1/\sqrt{T})\).

Introduction

Cake cutting is a model of fair division Steinhaus (1948), where the cake is a metaphor for a heterogeneous divisible resource such as land, time, memory in shared computing systems, clean water, greenhouse gas emissions, fossil fuels, or other natural deposits (Procaccia (2013)). The problem is to divide the resource among multiple participants so that everyone believes the allocation is fair. There is an extensive literature on cake cutting in mathematics, political science, economics (Robertson and Webb (1998); Brams and Taylor (1996); Moulin (2003)) and computer science (Brandt et al. (2016)), with a number of protocols implemented (Goldman and Procaccia (2014)).

Traditional approaches to cake cutting often consider single instances of division. However, many real-world scenarios require a repeated division of resources. For instance, consider the recurring task of allocating classroom space in educational institutions each quarter or that of repeatedly dividing computational resources (such as CPU and memory) among the members of an organization. These settings reflect the reality of many social and economic interactions, necessitating a model that not only addresses the fairness of a single division, but also the dynamics and strategies that emerge among participants over repeated interactions.

Repeated fair division is a classic problem first considered by Aumann and Maschler (1995), where two players--denoted Alice and Bob--have private valuations over the cake and interact in the following environment. Every day a new cake arrives, which is the same as the ones in previous days. Alice cuts the cake at a point of her choosing, while Bob chooses either the left piece or the right piece, leaving the remainder to Alice. Aumann and Maschler (1995) considered the simultaneous setting, where both players take their actions at the same time each day, and analyzed the payoffs achievable by Bob when he can have one of two types of valuations.

In this paper, we provide the first substantial progress in this classic setting. We further analyze the simultaneous version from Aumann and Maschler (1995) and also go beyond it, by considering the sequential version where Bob has the advantage of observing Alice's chosen cut point before making his selection. Tactical considerations remain pivotal in the sequential version, which is none other than the repeated _Cut-and-choose_ protocol with strategic players.

A key observation in our study is the strategic vulnerability inherent in repeated Cut-and-choose. At a high level, if Bob consistently chooses his preferred piece, then he can be systematically exploited by Alice through a strategy akin to a binary search. This strategy allows Alice to approximate Bob's preferences with increasing precision, thereby securing a disproportionate share of the resource over time. To fight back Alice's attempt to exploit him, Bob could deceive her by being unpredictable, thus hiding his preferences. While this behavior has the potential to reduce Alice's share of the cake, it could also come at the price of affecting Bob's own payoff guarantees in the long term.

Our analysis of the repeated cake cutting game formalizes the intuition that Alice can exploit a (nearly) myopic Bob that often chooses his favorite piece. This outcome, where Alice gains more value, is not entirely fair, as it leaves her happier than Bob. The fairness notion of _equitability_ addresses this imbalance, embodying the idea that players should be equally happy. Formally, it requires that Alice's value for her allocation should equal Bob's value for his allocation. Achieving equatiability is particularly important in scenarios with potential for conflict, such as splitting an inheritance.

We show that achieving equitable outcomes in the repeated interaction is in fact possible. Specifically, each player has a strategy that guarantees the other player receives no more than approximately \(1/2\) on average, while securing at least approximately \(1/2\) for themselves. This approaches the equitable utility profile of \((1/2,1/2)\) in the limit. We obtain this result by using a connection with Blackwell approachability (1956). Moreover, we consider a natural dynamic known as fictitious play (Brown (1951)), where players best respond to the empirical frequency of the other player's past actions. We show that fictitious play converges to the equitable utility profile of \((1/2,1/2)\) at a rate of \(O(1/\sqrt{T})\).

### Model

Cake cutting model for two players.The cake is modelled as the interval \([0,1]\). There are players \(N=\{A,B\}\), where \(A\) stands for Alice and \(B\) for Bob. Each player \(i\) has a private value density function \(v_{i}:[0,1]\rightarrow\mathbb{R}_{+}\). A _piece_ of cake is a measurable set \(S\subseteq[0,1]\). The value of player \(i\) for \(S\) is \(V_{i}(S)=\int_{x\in S}v_{i}(x)\ dx\). Atoms are worth zero and the valuations are normalized so that \(V_{i}([0,1])=1\ \forall i\in[n]\). We require bounded densities, i.e. there exist fixed arbitrary \(\delta,\Delta>0\) such that \(\delta\leq v_{i}(x)\leq\Delta\) for all \(x\in[0,1]\).

An allocation \(Z=(Z_{A},Z_{B})\) is a partition of the cake among the players such that each player \(i\) receives piece \(Z_{i}\), the pieces are disjoint, and \(\bigcup_{i\in N}Z_{i}=[0,1]\). The valuation (aka utility or payoff) of player \(i\) at an allocation \(Z\) is \(V_{i}(Z_{i})\). An allocation \(Z\) is _equitable_ if the players are equally happy with their pieces, meaning \(V_{A}(Z_{A})=V_{B}(Z_{B})\).

Let \(m_{A}\) be Alice's midpoint of the cake and \(m_{B}\) Bob's midpoint. Alice's _Stackelberg value_, denoted \(u^{*}_{A}\), is the utility she receives when she cuts the cake at \(m_{B}\) and Bob chooses his favorite piece, breaking ties in Alice's favor. The midpoints and Alice's Stackelberg value are depicted in Figure 1.

Repeated cake cutting.Each round \(t=1,2,\ldots,T\), the next steps take place:

* A new cake arrives, which is identical to the ones in previous rounds.
* Alice cuts the cake at a point \(a_{t}\in[0,1]\) of her choice. Bob chooses either the left piece or the right piece, then Alice takes the remainder.

We consider two versions: _sequential_, where Bob observes Alice's cut point \(a_{t}\) before choosing left/right, and _simultaneous_, where he only observes her cut point after making his choice.

A pure strategy is a map from the history observed by a player to the next action to play. A mixed strategy is a probability distribution over pure strategies.

### Our Results

Our results will examine how players fare in the repeated game over \(T\) rounds. Given a history \(H\), Alice's Stackelberg regret is \(\text{Reg}_{A}(H)=\sum_{t=1}^{T}\left[u^{*}_{A}-u^{t}_{A}(H)\right]\), where \(u^{*}_{A}\) is Alice's Stackelberg value and \(u^{t}_{A}(H)\) is Alice's utility in round \(t\) under history \(H\).

Suppose Alice uses a mixed strategy \(S_{A}\) and Bob uses a mixed strategy \(S_{B}\). Then \(S_{A}\) ensures Alice's Stackelberg regret is at most \(\gamma\) against \(S_{B}\) if \(\text{Reg}_{A}(H)\leq\gamma\) for all \(T\)-round histories \(H\) that could have arisen under the strategies \((S_{A},S_{B})\). Precise definitions for strategies/regret and the remaining notation needed for the full proofs can be found in Section 3.

#### Alice exploiting Bob

We start with an observation about the sequential setting. If Bob chooses his favorite piece in each round, then Alice can exploit him by running binary search until identifying his midpoint within a small error and then cutting near it for the rest of time. This will lead to Alice getting essentially her Stackelberg value in all but \(O(\log T)\) rounds, while Bob will get \(1/2\) in all but \(O(\log T)\) rounds.

**Proposition 1**.: _If Bob plays myopically in the sequential setting, then Alice has a strategy that ensures her Stackelberg regret is \(O(\log T)\)._

This exploitation phenomenon holds more generally: if Bob's strategy has bounded regret with respect to the standard of selecting his preferred piece in every round in hindsight, then Alice can almost get her Stackelberg value in each round. Her Stackelberg regret is a function of Bob's regret guarantee, as quantified in the next theorem.

Figure 1: Densities for Alice (blue) and Bob (red). Figure (a) shows Alice’s midpoint \(m_{A}\) and Bob’s midpoint \(m_{B}\). The shaded area in Figure (b) is Alice’s Stackelberg value.

**Theorem 1** (Exploiting a nearly myopic Bob).: _Let \(\alpha\in[0,1)\). Suppose Bob plays a strategy that ensures his regret is \(O(T^{\alpha})\) in the sequential setting. Let \(\mathcal{B}^{\alpha}\) denote the set of all such Bob strategies._

\(\bullet\) _If Alice knows \(\alpha\), she has a strategy \(S_{A}=S_{A}(\alpha)\) that ensures her Stackelberg regret is \(O(T^{\frac{\alpha+1}{2}}\log T)\). The exponent is sharp: Alice's Stackelberg regret is \(\Omega(T^{\frac{\alpha+1}{2}})\) for some Bob strategy in \(\mathcal{B}^{\alpha}\)._

\(\bullet\) _If Alice does not know_ \(\alpha\)_, she has a strategy_ \(S_{A}\) _that ensures her Stackelberg regret is_ \(O\big{(}\frac{T}{\log T}\big{)}\)_. The exponent is sharp: if_ \(S_{A}\) _guarantees Alice Stackelberg regret_ \(O(T^{\beta})\) _against all Bob strategies in_ \(\mathcal{B}^{\alpha}\) _for some_ \(\beta\in[0,1)\)_, then_ \(S_{A}\) _has Stackelberg regret_ \(\Omega(T)\) _for some Bob strategy in_ \(\mathcal{B}^{\beta}\)_._

In contrast, in the simultaneous setting, Alice may not approach her Stackelberg value on _every_ trajectory of play. In order to get her Stackelberg value in any given round, Alice needs to cut near Bob's midpoint and Bob needs to pick the piece he prefers, say \(R\). However, if Bob deterministically commits to picking \(R\), he will be completely exploited by an Alice who cuts at \(1\), breaking any reasonable regret guarantee he might have. Indeed, any Bob with a deterministic strategy (possibly using different actions over the rounds) has a corresponding Alice who can completely exploit him. Therefore, any Bob strategy with a good regret guarantee would behave randomly, making it impossible for Alice to reliably get her Stackelberg value on every trajectory. For this reason, we focus on the sequential setting when studying how Alice can exploit Bob.1

Footnote 1: One may explore a weaker regret benchmark for Bob of always picking the better of left or right in hindsight, which we believe would be an interesting direction for future work.

#### Equitable payoffs.

Motivated by Theorem 1, we examine the general limits of how much each player can exploit the other and whether fair outcomes are achievable, in both the sequential and simultaneous settings.

Given a history \(H\), player \(i\) is said to get an average payoff of \(\gamma\) if \(\big{(}\frac{1}{T}\big{)}\sum_{t=1}^{T}u_{i}^{t}(H)=\gamma\), where the left hand side is not expected utility, but rather the observed total utility averaged over \(T\) rounds.

We say a utility profile \((u_{A},u_{B})\) is _equitable_ if \(u_{A}=u_{B}\). In the single round setting, \(u_{A}\) and \(u_{B}\) will naturally represent the utilities of the players at an allocation. In the repeated setting, \(u_{A}\) and \(u_{B}\) will represent the time-average utilities of the players.

The next theorems show that each player can keep the other player at \(1/2\) while guaranteeing \(1/2\) for themselves. This type of behavior is reminiscent of spiteful bidding in auctions (Tang and Sandholm (2012)), where a buyer's utility diminishes if other bidders are too satisfied.

**Theorem 2** (Alice enforcing equitable payoffs; informal).: _In both the sequential and simultaneous settings, Alice has a pure strategy \(S_{A}\), such that for every Bob strategy \(S_{B}\):_

\(\bullet\) _on every trajectory of play, Alice's average payoff is at least \(1/2-o(1)\), while Bob's average payoff is at most \(1/2+o(1)\). More precisely, \(\frac{u_{B}}{T}\geq\frac{1}{2}-\Theta\left(\frac{1}{\sqrt{T}}\right)\) and \(\frac{u_{B}}{T}\leq\frac{1}{2}+\Theta\left(\frac{1}{\ln T}\right)\), where \(u_{i}\) is the cumulative payoff of player \(i\) over the time horizon \(T\)._

A key ingredient in the proof of Theorem 2 is a connection with Blackwell's approachability theorem Blackwell (1956). Generally speaking, Blackwell approachability can be used by a player to limit the payoff of the other player in a certain region of the utility profile. However, the main challenge is that there are uncountably many types of Bob and so Alice cannot apply the strategy from Blackwell directly. Instead, Alice's strategy constructs a countably infinite set of representatives, which allows us to adapt Blackwell's argument to this setting.

We show a symmetric theorem for Bob in the sequential setting, while in the simultaneous setting Bob's guarantee only holds in expectation.

**Theorem 3** (Bob enforcing equitable payoffs; informal).:

\(\bullet\) In the sequential setting: _Bob has a pure strategy \(S_{B}\), such that for every Alice strategy \(S_{A}\), on every trajectory of play, Bob's average payoff is at least \(1/2-o(1)\), while Alice's average payoff is at most \(1/2+o(1)\). More precisely, \(\frac{u_{B}}{T}\geq\frac{1}{2}-\frac{1}{\sqrt{T}}\) and \(\frac{u_{A}}{T}\leq\frac{1}{2}+\Theta\left(\frac{1}{\sqrt{T}}\right)\)._* In the simultaneous setting: _Bob has a mixed strategy \(S_{B}\), such that for every Alice strategy \(S_{A}\), both players have average payoff \(1/2\) in expectation._

When Alice and Bob play such strategies against each other, they approach an equitable utility profile of \((1/2,1/2)\). If just one player follows such a strategy, then the best the other player can do is to ensure the safety value of \(1/2\) for themselves, thus achieving the utility profile \((1/2,1/2)\).

#### Fictitious play

Fictitious play is a classic learning rule where at each round, each player best responds to the empirical frequency of play of the other player. Fictitious play was introduced in Brown (1951). Convergence to Nash equilibria has been shown for zero-sum games (Robinson (1951)) and special cases of general-sum games (Nachbar (1990); Monderer and Shapley (1996b, a)).

In the cake cutting model, learning rules such as fictitious play are more meaningful in the simultaneous setting, where there is uncertainty for both players due to the simultaneous actions. The precise definition of the fictitious play dynamic is in Section 6, while an example of trajectories for an instance with random valuations and uniform random tie-breaking can be found in Figure 2.

The convergence properties of fictitious play can be characterized as follows.

**Theorem 4** (Fictitious Play; informal).: _When both Alice and Bob run fictitious play, the average payoff of each player converges to \(1/2\) at a rate of \(O(1/\sqrt{T})\)._

Roadmap to the paper.Related work is in Section 2. Formal notation and preliminaries can be found in Section 3. An overview of how Alice can exploit a nearly myopic Bob can be found in Section 4, with formal proofs in Appendix A. An overview of how players can enforce equitable payoffs can be found in Section 5, with formal proofs in Appendix B. Fictitious play can be found in Section 6, with formal proofs in Appendix C. Concluding remarks can be found in Section 7.

## 2 Related Work

**Cake cutting and fairness notions.** The cake cutting model is due to Steinhaus (1948). Standard fairness notions include proportionality, equitability, envy-freeness (Even and Paz (1984); Dubins and Spanier (1961); Edward Su (1999); Stromquist (1980); Alon (1987)). For surveys, see Robertson and Webb (1998); Brams and Taylor (1996); Moulin (2003); Brandt et al. (2016); Procaccia (2013).

In the Robertson-Webb (RW) query model for cake cutting (Woeginger and Sgall (2007)), a mediator asks the players enough queries about their preferences until it can output a fair allocation. For studies on the query complexity of cake cutting, see Even and Paz (1984); Woeginger and Sgall (2007); Edmonds and Pruhs (2006); Procaccia (2009); Aziz and Mackenzie (2016); Amanatidis et al. (2018); Cheze (2020); Stromquist (2008); Deng et al. (2012); Goldberg et al. (2020a); Filos-Ratsikas et al. (2022); Segal-Halevi (2018); Deligkas et al. (2021); Goldberg et al. (2020b); Branzei and Nisan (2022, 2019); Filos-Ratsikas et al. (2020); Alon and Graur (2020); Filos-Ratsikas et al. (2021).

Figure 2: Illustration of Alice’s and Bob’s average payoff in a randomly generated instance of valuations. The X axis shows the time and the Y axis shows the average payoff up to that round.

Mossel and Tamuz (2010); Branzei and Miltersen (2015) studied truthful cake cutting in the RW query model, and Chen et al. (2013); Bu et al. (2023); Bei et al. (2022); Tao (2022) in the direct revelation model. The equilibria of cake cutting protocols were considered in Nicolo and Yu (2008); Branzei and Miltersen (2013); Branzei et al. (2016); Goldberg and Iaru (2021).

Multiple divisible/indivisible goods and chores.The algorithms and complexity of finding fair allocations in settings with multiple divisible/indivisible goods/bads were considered in Oh et al. (2021); Plaut and Roughgarden (2020, 2019); Manurangsi and Suksompong (2021); Chaudhury et al. (2021c); Bilo et al. (2019); Amanatidis et al. (2022); Procaccia (2020); Chaudhury et al. (2020, 2021b); Procaccia and Wang (2014); Kulkarni et al. (2021); Chaudhury et al. (2021a). Tucker-Foltz and Zeckhauser (2023) analyze how the cutter should act in a single-round cut-and-choose on multiple goods where the players' valuations of the goods are drawn from a publicly known distribution.

Ghodsi et al. (2011) studied fairness in cloud computing settings, where there are multiple divisible goods (e.g. CPU and memory) and the users have to run jobs with different resource requirements. Kandasamy et al. (2020) studied players who do not know their own resource requirements.

Dynamic fair division.Closest to our setting is the analysis in the book of Aumann and Maschler (1995) (page 243), where two players are dividing a cake with a cherry. Alice (the cutter) has a uniform density and so she does not care for the cherry, while Bob (the chooser) may or may not like the cherry. Alice and Bob declare their actions simultaneously and Alice is only allowed to cut in one of two locations. Additionally, Alice has a prior over the type of Bob she is facing. Aumann and Maschler (1995) analyzes the set of payoffs approachable for Bob using Blackwell approachability. In contrast, we allow arbitrary value densities for the players and do not assume priors and also consider the sequential version of the game.

Tamuz et al. (2018) introduced exploitability in repeated cut-and-choose protocols, with some cuts made by a mediator, designing non-exploitable protocols. Online cake cutting was studied by Walsh (2011), where agents can arrive/depart over time. For dynamic fair division where goods are allocated irrevocably upon arrival, see Kash et al. (2014); Friedman et al. (2015); Benade et al. (2022).

Learning in repeated Stackelberg games.The Stackelberg game was introduced by Stackelberg (1934) to understand the first mover advantage of firms when entering a market. The Stackelberg equilibrium concept has important applications such as security games Tambe (2011); Balcan et al. (2015), online strategic classification Dong et al. (2018), and online principal agent problems Hajiaghayi et al. (2023). Our model can be seen as each player facing an online learning version of a repeated Stackelberg game.

Kleinberg and Leighton (2003) considered a seller's problem of designing an efficient repeated posted price mechanism to buy identical goods when it interacts with a sequence of myopic buyers. Gan et al. (2019); Birmpas et al. (2020); Zhao et al. (2023) considered a repeated Stackelberg game to study how the follower or leader can exploit the opponent in a general game with arbitrary payoffs. Their techniques, however, do not apply to our model as they typically consider the setting of one player knowing the entire payoff matrix trying to deceive the other player given behavioral assumptions.

Exploiting no-regret agents.Several works considered the extent to which one player can exploit the knowledge that the other player has a strategy with sublinear regret. The goal is often to approach the Stackelberg value, the maximum payoff that the exploiter could get by selecting an action first and allowing the opponent to best-respond. In simultaneous games, Deng et al. (2019) showed the exploiter can approach their Stackelberg value, assuming knowledge of the other player's payoff function. Haghtalab et al. (2022) showed that, for certain types of sequential games, an exploiting leader can approach their Stackelberg value in the limit. Theorem 1 is a similar statement in our setting, but we bound the exploited agent's behavior with an explicit regret guarantee rather than using discounted future payoffs; also, our setting is not captured by the types of games they consider.

Fictitious play.Fictitious play was introduced in Brown (1951). Convergence to Nash equilibria has been shown for zero-sum games (Robinson (1951)) and special cases of general-sum games (Nachbar (1990); Monderer and Shapley (1996b, a)). None of these results directly apply to our setting, but the most relevant is Berger (2005), which covered non-degenerate \(2\times n\) games (i.e. where every action has a unique best response). Our "\(2\times\infty\)" game is degenerate, as Bob does not have a unique best response to Alice cutting at \(m_{B}\). Few existing works apply fictitious play to games with continuous action spaces. An example is Perkins and Leslie (2014), which showed that stochastic fictitious play does converge in two-player zero-sum games with continuous action spaces.

Karlin (1959) conjectured that fictitious play converges at a rate of \(O(T^{-1/2})\). Brandt et al. (2013) found small games where the convergence rate is \(O(T^{-1/2})\), but with very large constants in the \(O()\). Daskalakis and Pan (2014) disproved Karlin's conjecture, showing there exist games with \(n\times n\) payoff matrices in which convergence takes place at a rate of \(\Omega(T^{-1/n})\) using adversarial tie-breaking rules. Panageas et al. (2023) found examples of even slower convergence.

Harris (1998) showed that fictitious play converges at a rate of \(O(T^{-1})\) in \(2\times 2\) zero-sum games. Abernethy et al. (2021) considered diagonal payoff matrices with non-adversarial tie-breaking rules, showing convergence rates of \(O(T^{-1/2})\). Abernethy et al. (2021) does not give a rate of convergence in our setting because requiring the payoff matrix to be diagonal would correspond to Alice only being allowed to cut at \(0\) or \(1\). This assumption is not as natural in our setting. In fact, if Alice can only cut at \(0\) or \(1\) the game becomes zero-sum. Furthermore, we allow arbitrary tie-breaking rules.

## 3 Preliminaries

In this section we formally define the notation used in our proofs. All our notation applies to both the sequential and simultaneous settings, unless otherwise stated.

**History.** Recall \(T\) is the number of rounds. For each round \(t\in[T]\),

* let \(a_{t}\in[0,1]\) be Alice's cut at time \(t\) and \(b_{t}\in\{L,R\}\) be Bob's choice at time \(t\), where \(L\) stands for the left piece \([0,a_{t}]\) and \(R\) for the right piece \([a_{t},1]\).
* let \(A_{t}=(a_{1},\ldots,a_{t})\) be the history of cuts until the end of round \(t\) and \(B_{t}=(b_{1},\ldots,b_{t})\) the history of choices made by Bob until the end of round \(t\).

A history \(H=(A_{T},B_{T})\) denotes an entire trajectory of play.

**Strategies.** Let \(\mathcal{P}\) be the space of integrable value densities over \([0,1]\). A pure strategy for Alice at time \(t\) is a function \(S_{A}^{t}:[0,1]^{t-1}\times\{L,R\}^{t-1}\times\mathcal{P}\times\mathbb{N} \rightarrow[0,1]\), such that \(S_{A}^{t}(A_{t-1},B_{t-1},v_{A},T)\) is the next cut point made by Alice as a function of the history \(A_{t-1}\) of Alice's cuts, the history \(B_{t-1}\) of Bob's choices, Alice's valuation \(v_{A}\), and the horizon \(T\).

For Bob, we define pure strategies separately for the sequential and simultaneous settings due to the different feedback that he gets:

_Sequential:_ A pure Bob strategy at time \(t\) is a map \(S_{B}^{t}:[0,1]^{t}\times\{L,R\}^{t-1}\times\mathcal{P}\times\mathbb{N} \rightarrow\{L,R\}\). That is, Bob observes Alice's cut point and then responds.

_Simultaneous:_ A pure Bob strategy at time \(t\) is a map \(S_{B}^{t}:[0,1]^{t-1}\times\{L,R\}^{t-1}\times\mathcal{P}\times\mathbb{N} \rightarrow\{L,R\}\). Thus here Bob chooses \(L\!/R\) before observing Alice's cut point at time \(t\).

A pure strategy for Alice over the entire time horizon \(T\) is denoted \(S_{A}=(S_{A}^{1},\ldots,S_{A}^{T})\) and tells Alice what cut to make at each time \(t\). A pure strategy for Bob over the entire time horizon \(T\) is denoted \(S_{B}=(S_{B}^{1},\ldots,S_{B}^{T})\) and tells Bob whether to play \(L\!/R\) at each time \(t\).

A mixed strategy is a probability distribution over the set of pure strategies. 2

Footnote 2: In fact, this is equivalent to the behavior strategy in which the player assigns a probability distribution given a history, thanks to Kuhn’s theorem Kuhn (1950); Kuhn (1953). The original version of Kuhn’s theorem is restricted to games with finite action space, but can be extended to any action space that is isomorphic to unit interval by Aumann (1961); Dresher et al. (2016), which contains our setting.

**Rewards and utilities.** Suppose Alice has mixed strategy \(S_{A}\) and Bob has mixed strategy \(S_{B}\). Let \(u_{A}^{t}\) and \(u_{B}^{t}\) be the random variables for the utility (payoff) experienced by Alice and Bob, respectively, at round \(t\). The utility of player \(i\in\{A,B\}\) is denoted \(u_{i}=u_{i}(S_{A},S_{B})=\sum_{t=1}^{T}u_{i}^{t}\). The utility of player \(i\) from round \(t_{1}\) to \(t_{2}\) is \(u_{i}(t_{1},t_{2})=\sum_{t=t_{1}}^{t_{2}}u_{i}^{t}\).

The expected utility of player \(i\) is \(\mathbb{E}[u_{i}]=\sum_{t=1}^{T}\mathbb{E}[u_{i}^{t}],\) where the expectation is taken over the randomness of the strategies \(S_{A}\) and \(S_{B}\).

Given a history \(H\), let \(u_{i}^{t}(H)\) be player \(i\)'s utility in round \(t\) under \(H\) and let \(u_{i}(H)=\sum_{t=1}^{T}u_{i}^{t}(H)\) be player \(i\)'s cumulative utility under \(H\).

**Midpoints and Stackelberg value.** Let \(m_{A}\in[0,1]\) be Alice's midpoint of the cake, with \(V_{A}([0,m_{A}])=1/2\), and \(m_{B}\in[0,1]\) be Bob's midpoint, with \(V_{B}([0,m_{B}])=1/2\). Since the densities are bounded from below, the midpoint of each player is uniquely defined. Alice's _Stackelberg value_, denoted \(u^{*}_{A}\), is the utility Alice gets when she cuts at \(m_{B}\) and Bob chooses his favorite piece breaking ties in favor of Alice (i.e. taking the piece she prefers less).

## 4 Alice exploiting Bob

In this section we give an overview of Theorem 1, which considers the sequential setting and quantifies the extent to which Alice can exploit a Bob that has sub-linear regret with respect to the benchmark of choosing the best piece in each round. Formal proofs for this section are in Appendix A.

We start by defining the notion of Stackelberg regret (Dong et al. (2018); Haghtalab et al. (2022)).

**Definition 1** (Stackelberg regret).: _Given a history \(H\) of the places Alice cut and the pieces Bob chose in each round, Alice's Stackelberg regret is \(\text{Reg}_{A}(H)=\sum_{t=1}^{T}\big{[}u^{*}_{A}-u^{t}_{A}(H)\big{]}\), where \(u^{*}_{A}\) is Alice's Stackelberg value and \(u^{t}_{A}(H)\) is Alice's utility in round \(t\) under history \(H\)._

For Bob, we consider the basic notion of static regret, where Bob compares his payoff to what would have happened if Alice's actions remained the same but he chose the best piece in each round.

**Definition 2** (Regret).: _Given a history \(H\), Bob's regret is_

\[\text{Reg}_{B}(H)=\sum_{t=1}^{T}\Bigl{[}\max\Bigl{\{}V_{B}([0,a_{t}]),V_{B}([a _{t},1])\Bigr{\}}-u^{t}_{B}(H)\Bigr{]},\]

_recalling that \(u^{t}_{B}(H)\) is Bob's utility in round \(t\) under history \(H\)._

Next we provide a proof sketch for Theorem 1, which is divided in the next two propositions, corresponding to the cases where Alice knows \(\alpha\) and does not know \(\alpha\).

**Proposition 2**.: _Let \(\alpha\in[0,1)\). Suppose Bob plays a strategy that ensures his regret is \(O(T^{\alpha})\) and let \(\mathcal{B}^{\alpha}\) denote the set of all such Bob strategies. Assume Alice knows \(\alpha\). Then she has a strategy \(S_{A}=S_{A}(\alpha)\) that ensures her Stackelberg regret is \(O\bigl{(}T^{\frac{\alpha+1}{2}}\log T\bigr{)}\). The exponent is sharp: Alice's Stackelberg regret is \(\Omega\bigl{(}T^{\frac{\alpha+1}{2}}\bigr{)}\) for some Bob strategy in \(\mathcal{B}^{\alpha}\)._

Proof sketch.: We sketch both the upper and lower bounds.

**Sketch for the upper bound.** Let \(S_{B}\) denote Bob's strategy, which guarantees his regret is \(O(T^{\alpha})\). Suppose Alice knows \(\alpha\). Then Alice initializes an interval \(I=[0,1]\) and uses the following strategy.

Iteratively, for \(i=0,1,\ldots\);

**(1)**: Alice discretizes the interval \(I=[u,w]\) in a constant number of sub-intervals (set to \(6\)) of equal value to her, by cutting at points \(a_{i,j}\) for \(j\in[5]\) such that \(u<a_{i,1}<a_{i,2}<\ldots<a_{i,5}<w\). Denote \(a_{i,0}=u\) and \(a_{i,6}=w\). An illustration is in Figure 3.

**(2)**: Alice selects a number \(\eta\), which will be set "large enough" as a function of \(T\) and \(\alpha\). In the next \(5\eta\) rounds, Alice cuts an equal number of times at each point \(a_{i,j}\) for \(j\in[5]\). That is:

* In each of the next \(\eta\) rounds, Alice cuts at \(a_{i,1}\) and observes Bob's choices there, computing the majority answer as \(c_{i,1}=L\) if Bob picked the left piece more times than the right piece, and \(c_{i,1}=R\) otherwise. The next \(\eta\) rounds after that Alice switches to cutting at \(a_{i,2}\), and so on.

In this fashion, Alice computes \(c_{i,j}\) as Bob's majority answer corresponding to cut point \(a_{i,j}\) for all \(j\in[5]\). Also, by default \(c_{i,0}=R\) and \(c_{i,6}=L\). An illustration is in Figure 4.

Figure 3: Illustration of step \((1)\) for \(i=0\). Alice divides the interval \([0,1]\) in \(6\) disjoint intervals of equal value to her, demarcated by points \(a_{0,0}=0<a_{0,1}<a_{0,2}<a_{0,3}<a_{0,4}<a_{0,5}<1=a_{0,6}\).

**(3)**: The points \(a_{i,j}\) for \(j\in\{0,\ldots,6\}\) are arranged on a line and each is labelled \(L\) or \(R\), with the leftmost point \(a_{i,0}=0\) labelled \(R\) and the rightmost point \(a_{i,6}=1\) labelled \(L\). Then there is an index \(j\in\{0,\ldots,5\}\) such that \(c_{i,j}=R\) and \(c_{i,j+1}=L\).

Alice computes a smaller interval \(I_{i+1}\), essentially consisting of \([a_{i,j},a_{i,j+1}]\) and some extra space around it to make sure that \(I_{i+1}\) contains Bob's midpoint as follows. If \(j\in\{1,\ldots,4\}\), set \(I_{i+1}=[a_{i,j-1},a_{i,j+2}]\). If \(j=0\), set \(I_{i+1}=[a_{i,0},a_{i,3}]\). If \(j=5\), set \(I_{i+1}=[a_{i,3},a_{i,6}]\). Then Alice iterates steps \((1-3)\) on the interval \(I_{1}\). An illustration is in Figure 5.

The full proof explains why the index \(j\) from step \(3\) is unique and why it is in fact necessary to include a slightly larger interval than \([a_{i,j},a_{i,j+1}]\) in the recursion step, due to Bob potentially having lied if his midpoint was very close to a boundary of \([a_{i,j},a_{i,j+1}]\) but on the other side.

Sketch for the lower bound.The lower bound of \(\Omega\big{(}T^{\frac{\alpha+1}{2}}\big{)}\) relies on the observation that rounds where Alice cuts near \(m_{B}\) and Bob picks his less-preferred piece cost Bob very little but cost Alice a lot. More precisely, suppose \(m_{A}<m_{B}\) and Alice cuts at \(m_{B}-\varepsilon\). Then compared to his regret bound, Bob loses \(\Theta(\varepsilon)\) if he picks the wrong piece. On the other hand, Alice loses \(\Theta(m_{B}-m_{A})=\Theta(1)\) compared to her Stackelberg value.

Bob can use this asymmetry by acting as if his midpoint were \(\Theta\big{(}T^{\frac{\alpha-1}{2}}\big{)}\) closer to \(m_{A}\) than it really is. Living \(\Theta\big{(}T^{\frac{\alpha+1}{2}}\big{)}\) times costs Bob only \(\Theta(T^{\alpha})\) regret, but costs Alice \(\Theta\big{(}T^{\frac{\alpha+1}{2}}\big{)}\) regret. To avoid accumulating more regret than this, Bob can afterwards revert to picking his truly preferred piece; the damage to Alice's payoff has already been done. 

**Proposition 3**.: _Let \(\alpha\in[0,1)\). Suppose Bob plays a strategy that ensures his regret is \(O(T^{\alpha})\). Let \(\mathcal{B}^{\alpha}\) denote the set of all such Bob strategies. If Alice does not know \(\alpha\), she has a strategy \(S_{A}\) that ensures her Stackelberg regret is \(O\big{(}\frac{T}{\log T}\big{)}\)._

_The exponent is sharp: if \(S_{A}\) guarantees Alice Stackelberg regret \(O(T^{\beta})\) against all Bob strategies in \(\mathcal{B}^{\alpha}\) for some \(\beta\in[0,1)\), then \(S_{A}\) has Stackelberg regret \(\Omega(T)\) for some Bob strategy in \(\mathcal{B}^{3}\)._

Proof sketch.: Alice's strategy that achieves \(O(T/\log T)\) regret follows the same template as her strategy from Proposition 2. The only difference is that she sets \(\eta\) differently (and much larger) to cover any possible regret bound Bob could have.

The idea of the lower bound is that, if Alice does not know the value of \(\alpha\) in Bob's regret bound, she cannot know when she has true information about Bob's preferences. We use this by having a Bob with \(O(T^{\beta})\) regret behave exactly like one with \(O(T^{\alpha})\) regret but a different midpoint. Then Bob can hide his deception from an Alice with \(O(T^{\beta})\) regret since he can tolerate more regret than her. 

Theorem 1 is implied by Propositions 2 and 3. The players' value densities must be bounded for Theorem 1 to hold; see Remark 1 in Appendix A.2 for a counterexample with unbounded densities.

Figure 4: Illustration of step \((2)\) for \(i=0\). Suppose \(\eta=3\). Alice cuts \(3\) times at each of the points \(a_{0,j}\) and observes Bob’s choices, which are marked near each such cut point. By default, Alice knows what the answer would be if she cut at \(0\) or \(1\), so those are set to \(R\) and \(L\), respectively. The truthful answers (reflecting Bob’s favorite piece according to his actual valuation) are marked with green, while the lying answers are marked with orange.

Figure 5: Illustration of step \((3)\) for \(i=0\). Alice labels each point \(a_{0,j}\) with the majority answer there. Then she identifies the index \(j\) such that the point \(a_{0,j}\) is labelled \(R\) and the point \(a_{0,j+1}\) is labelled \(L\). At this stage she is assured that either the interval \([a_{0,j},a_{0,j+1}]\) or one of the adjacent ones contains Bob’s midpoint. Alice sets \(I_{1}=[a_{0,3},a_{0,6}]\) and recurses on it.

Equitable payoffs

Here we sketch the proofs of Theorems 2 and 3. The formal proofs can be found in Appendix B.

Theorem 2 shows how Alice can get at least \(1/2\) per round while keeping Bob at \(1/2\) per round.

Proof sketch of Theorem 2.: Alice's strategy uses Blackwell approachability (1956). A challenge is that Blackwell's original version required the number of player types to be finite, but Alice has to be prepared for an uncountably infinite variety of Bob's valuation functions. Another difference is that Alice's action space is also infinite, which turns out to be necessary.

We get around the infinite-Bob issue in two steps. First, Alice defines a countably infinite set \(\overline{\mathcal{V}}\) as a stand-in for the full variety of Bobs; \(\overline{\mathcal{V}}\) includes arbitrarily good approximations to any valuation.

Second, we replace Blackwell's original finite-dimensional space with a countably-infinite-dimensional one, where the elements of \(\overline{\mathcal{V}}\) are the axes. We define an inner product on this space and adapt Blackwell's argument for it. Briefly, Alice's strategy tracks the average payoff to each type of Bob in \(\overline{\mathcal{V}}\) and defines \(\mathcal{S}\) to be the region of the space where all of them have payoffs at most \(1/2\). In each round, she constructs a cut point which moves the Bobs' average payoff closer to \(\mathcal{S}\), and in the limit traps them in \(\mathcal{S}\).

Under this strategy, Alice's payoff guarantee is mostly a byproduct of Bob's. If Bob and Alice have the same value density, then their payoffs sum to \(1\), so bounding Bob's payoff to \(1/2\) also bounds Alice's to \(1/2\). We achieve the substantially better bound on Alice's payoff by explicitly including her value density \(v_{A}\) in the set \(\overline{\mathcal{V}}\) of Bobs, thus eliminating any approximation error. 

Theorem 3 shows how Bob can do the same, albeit only in expectation in the simultaneous setting.

Proof sketch of Theorem 3.: We cover the simultaneous setting first because it informs the sequential setting. In the simultaneous setting, Bob's algorithm is extremely simple: in each round, randomly select \(L\) or \(R\) with equal probability. The expected payoffs to each player follow immediately.

Bob's strategy for the sequential setting can be seen as a derandomized version of the simultaneous strategy. The simplest way to derandomize it would be to strictly alternate between \(L\) and \(R\), but if Bob runs that strategy Alice can easily exploit it. Instead, Bob mentally partitions the cake into \(\sqrt{T}\) intervals \(I_{1},\ldots,I_{\sqrt{T}}\) of equal value to him. He then treats each interval \(I_{i}\) as a separate cake, alternating between \(L\) and \(R\) for the rounds Alice cuts in \(I_{i}\). Alice can still exploit this strategy on a single interval \(I_{i}\), but doing so can only give her an average payoff of \(1/2+O(V_{A}(I_{i}))\in 1/2+O(1/\sqrt{T})\). The full proof shows this bound applies for any Alice strategy. 

## 6 Fictitious play

In this section we include a proof sketch of Theorem 4, which analyzes the fictitious play dynamic. The formal proof can be found in Appendix C.

Proof sketch of Theorem 4.: To analyze the fictitious play dynamic, we define for each \(t=0,\ldots,T\) two quantities called \(\alpha_{t}\) and \(\beta_{t}\). Let \(\alpha_{t}=r_{t}-\ell_{t}\), where \(r_{t}\) is the number of times Bob picked \(R\) up to round \(t\) and \(\ell_{t}\) is the number of times he picked \(L\). Let \(\beta_{t}=\sum_{\tau=1}^{t}(2V_{B}([0,a_{\tau}])-1)\).

The quantities \(\alpha_{t}\) and \(\beta_{t}\) control what happens under fictitious play: Alice's decision in round \(t+1\) is based on \(\alpha_{t}\) and Bob's decision in round \(t+1\) is based on \(\beta_{t}\). These decisions in turn affect \(\alpha_{t+1}\) and \(\beta_{t+1}\), forming a dynamical system that results in a counterclockwise spiral through \(\alpha\)-\(\beta\) space. Figure 6 illustrates the sequences \(\alpha_{t}\) and \(\beta_{t}\) for the instance in Figure 2.

We define \(\rho_{t}=|\alpha_{t}|+|\beta_{t}|\) and formalize this spiral, by showing that the sequence \(\{\rho\}_{t=0}^{T}\) is non-decreasing and analyzing the change in \((\alpha_{t},\beta_{t})\) from round to round. Figure 6 illustrates the parameter \(\rho_{t}\) over time, while Figure 7 illustrates the spiral (associated with the same trajectory as in Figure 2 and 6), where the spiral is visualized as a scatter plot of the sequence \((\alpha_{t},\beta_{t})_{t\geq 1}\).

We first use these dynamics to bound Bob's payoff. Bob's payoff can be almost directly read off due to changes in \(\beta_{t}\) closely matching changes in Bob's payoff. Bob's total payoff to round \(t\) turns out to be of the order \(t/2\pm\rho_{t}\), so bounding the rate at which the spiral expands also bounds Bob's payoff.

We then use the dynamics to bound the total payoff to Alice and Bob. Alice can only cut in the interior of the cake when \(\alpha_{t}=0\), which happens less and less often as the spiral expands. The players' total payoff when Alice cuts at one end of the cake is \(1\), so across \(T\) rounds we show the sum of cumulative payoffs of the players is of the order \(T\pm\Theta(\sqrt{T})\). Combining the bound on the total payoff with the bound on Bob's payoff gives a bound for Alice's payoff. 

## 7 Concluding remarks

There are several directions for future work. One direction is to consider a wider class of regret benchmarks and understand how the choice of benchmark influences the outcomes reached. Moreover, what payoff profiles are attained when the players use randomized algorithms such as exponential weights to update their strategies? It would also make sense to consider settings where the cake has both good and bad parts. Finally, studying richer feedback models, _e.g.,_ when Alice and Bob takes turns cutting and choosing, or allowing Alice to divide the cake into any multiple measurable sets would be intriguing directions.

Figure 6: Illustration of the sequences \(\{\alpha_{t}\}_{t=1}^{\infty}\), \(\{\beta_{t}\}_{t=1}^{\infty}\), and \(\{\rho_{t}\}_{t=1}^{\infty}\) for the instance with trajectories shown in Figure 2. The X axis shows the round number \(t\) and the Y axis the variable plotted.

Figure 7: Scatter plot of the sequence \((\alpha_{t},\beta_{t})_{t\geq 1}\), illustrating the spiral for the instance with trajectories shown in Figure 2, where the sequences \(\alpha_{t}\) and \(\beta_{t}\) are illustrated separately in Figure 6.

## Acknowledgements

We would like to thank the reviewers for useful feedback that helped improve the paper. This work was supported by US National Science Foundation CAREER grant CCF-2238372, DARPA QuICC, NSF AF:Small #2218678, NSF AF:Small #2114269, Army-Research Laboratory (ARL) #W911NF2410052, and MURI on Algorithms, Learning and Game Theory.

## References

* Abernethy et al. (2021) Jacob Abernethy, Kevin A. Lai, and Andre Wibisono. 2021. _Fast Convergence of Fictitious Play for Diagonal Payoff Matrices_. 1387-1404. https://doi.org/10.1137/1.9781611976465.84 arXiv:https://epubs.siam.org/doi/pdf/10.1137/1.9781611976465.84
* Alon (1987) N. Alon. 1987. Splitting necklaces. _Advances in Mathematics_ 63, 3 (1987), 247-253.
* Alon and Graur (2020) Noga Alon and Andrei Graur. 2020. Efficient Splitting of Measures and Necklaces. https://doi.org/10.48550/ARKIV.2006.16613
* Amanatidis et al. (2022) Georgios Amanatidis, Georgios Birmpas, Aris Filos-Ratsikas, and Alexandros A. Voudouris. 2022. Fair Division of Indivisible Goods: A Survey. In _Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022_, Luc De Raedt (Ed.). ijcai.org, 5385-5393. https://doi.org/10.24963/IJCAI.2022/756
* Amanatidis et al. (2018) G. Amanatidis, G. Christodoulou, J. Fearnley, E. Markakis, C.-Alexandros Psomas, and E. Vakaliou. 2018. An Improved Envy-Free Cake Cutting Protocol for Four Agents. In _Proceedings of the 11th International Symposium on Algorithmic Game Theory SAGT_. 87-99.
* Aumann and Maschler (1995) Robert Aumann and Michael Maschler. 1995. _Repeated Games with Incomplete Information_. MIT Press.
* Aumann (1961) Robert J Aumann. 1961. _Mixed and behavior strategies in infinite extensive games_. Princeton University Princeton.
* Aziz and Mackenzie (2016) H. Aziz and S. Mackenzie. 2016. A Discrete and Bounded Envy-Free Cake Cutting Protocol for Any Number of Agents. In _FOCS_. 416-427.
* Balcan et al. (2015) Maria-Florina Balcan, Avrim Blum, Nika Haghtalab, and Ariel D Procaccia. 2015. Commitment without regrets: Online learning in stackelberg security games. In _Proceedings of the sixteenth ACM conference on economics and computation_. 61-78.
* Bei et al. (2022) Xiaohui Bei, Xinhang Lu, and Warut Suksompong. 2022. Truthful cake sharing. In _Proceedings of the AAAI Conference on Artificial Intelligence_, Vol. 36. 4809-4817.
* Benade et al. (2022) Gerdus Benade, Daniel Halpern, and Alexandros Psomas. 2022. Dynamic fair division with partial information. _Advances in neural information processing systems_ 35 (2022), 3703-3715.
* Berger (2005) U. Berger. 2005. Fictitious Play in 2xN Games. _Journal of Economic Theory_ 120 (2005), 139-154.
* Leibniz-Zentrum fur Informatik, 14:1-14:21. https://doi.org/10.4230/LIPIcs.ITCS.2019.14
* Birmpas et al. (2020) Georgios Birmpas, Jiarui Gan, Alexandros Hollender, Francisco Marmolejo, Ninad Rajgopal, and Alexandros Voudouris. 2020. Optimally deceiving a learning leader in stackelberg games. _Advances in Neural Information Processing Systems_ 33 (2020), 20624-20635.

* Brams and Taylor (1996) S. Brams and A. Taylor. 1996. _Fair Division: from cake cutting to dispute resolution_. Cambridge University Press.
* Brams et al. (2018)F. Brandt, V. Conitzer, U. Endriss, J. Lang, and A. D. Procaccia (Eds.). 2016. _Handbook of Computational Social Choice_ (1 ed.). Cambridge University Press.
* Brandt et al. (2013) Felix Brandt, Felix Fischer, and Paul Harrenstein. 2013. On the rate of convergence of fictitious play. _Theory of Computing Systems_ 53 (2013), 41-52.
* Branzei et al. (2016) Simina Branzei, Ioannis Caragiannis, David Kurokawa, and Ariel D. Procaccia. 2016. An Algorithmic Framework for Strategic Fair Division. In _Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17, 2016, Phoenix, Arizona, USA_, Dale Schuurmans and Michael P. Wellman (Eds.). AAAI Press, 418-424. http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12294
* Branzei and Miltersen (2013) Simina Branzei and Peter Bro Miltersen. 2013. Equilibrium analysis in cake cutting.. In _AAMAS_. Citeseer, 327-334.
* Branzei and Miltersen (2015) S. Branzei and P. B. Miltersen. 2015. A Dictatorship Theorem for Cake Cutting. In _IJCAI_. 482-488.
* Branzei and Nisan (2019) Simina Branzei and Noam Nisan. 2019. Communication Complexity of Cake Cutting. In _Proceedings of the 2019 ACM Conference on Economics and Computation (EC)_. 525.
* Branzei and Nisan (2022) Simina Branzei and Noam Nisan. 2022. The Query Complexity of Cake Cutting. In _NeurIPS_. 37905-37919. http://papers.nips.cc/paper_files/paper/2022/hash/f7a7bb369e48f10e85fce85b67d8c516-Abstract-Conference.html
* Brown (1951) G.W. Brown. 1951. Iterative Solutions of Games by Fictitious Play. _Activity Analysis of Production and Allocation_ (1951).
* Bu et al. (2023) Xiaolin Bu, Jiaxin Song, and Biaoshuai Tao. 2023. On existence of truthful fair cake cutting mechanisms. _Artificial Intelligence_ 319 (2023), 103904. https://doi.org/10.1016/j.artint.2023.103904
* Chaudhury et al. (2021a) Bhaskar Ray Chaudhury, Jugal Garg, Peter McGlaughlin, and Ruta Mehta. 2021a. Competitive allocation of a mixed manna. In _Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms (SODA)_. SIAM, 1405-1424.
* Chaudhury et al. (2020) Bhaskar Ray Chaudhury, Jugal Garg, and Kurt Mehlhorn. 2020. EFX exists for three agents. In _Proceedings of the 21st ACM Conference on Economics and Computation_. 1-19.
* Chaudhury et al. (2021b) Bhaskar Ray Chaudhury, Jugal Garg, Kurt Mehlhorn, Ruta Mehta, and Pranabendu Misra. 2021b. Improving EFX guarantees through rainbow cycle number. In _Proceedings of the 22nd ACM Conference on Economics and Computation_. 310-311.
* Chaudhury et al. (2021c) Bhaskar Ray Chaudhury, Telikepalli Kavitha, Kurt Mehlhorn, and Alkmini Sgouritsa. 2021c. A Little Charity Guarantees Almost Envy-Freeness. _SIAM J. Comput._ 50, 4 (2021), 1336-1358. https://doi.org/10.1137/20M1359134
* Chen et al. (2013) Yiling Chen, John K. Lai, David C. Parkes, and Ariel D. Procaccia. 2013. Truth, justice, and cake cutting. _Games and Economic Behavior_ 77, 1 (2013), 284-297. https://EconPapers.repec.org/RePEc:eee:gamebe:v77:y:2013:i:1:p:284-297
* Cheze (2020) Guillaume Cheze. 2020. Envy-free cake cutting: A polynomial number of queries with high probability.
* Daskalakis and Pan (2014) Constantinos Daskalakis and Qinxuan Pan. 2014. A Counter-example to Karlin's Strong Conjecture for Fictitious Play. In _2014 IEEE 55th Annual Symposium on Foundations of Computer Science_. 11-20. https://doi.org/10.1109/FOCS.2014.10
* Deligkas et al. (2021) Argyrios Deligkas, Aris Filos-Ratsikas, and Alexandros Hollender. 2021. Two's Company, Three's a Crowd: Consensus-Halving for a Constant Number of Agents. In _EC '21: The 22nd ACM Conference on Economics and Computation, Budapest, Hungary, July 18-23, 2021_, Peter Biro, Shuchi Chawla, and Federico Echenique (Eds.). ACM, 347-368. https://doi.org/10.1145/3465456.3467625
* Deng et al. (2012) X. Deng, Q. Qi, and A. Saberi. 2012. Algorithmic Solutions for Envy-Free Cake Cutting. _Oper. Res_ 60, 6 (2012), 1461-1476.

Yuan Deng, Jon Schneider, and Balasubramanian Sivan. 2019. Strategizing against no-regret learners. _Advances in neural information processing systems_ 32 (2019).
* Dong et al. (2018) Jinshuo Dong, Aaron Roth, Zachary Schutzman, Bo Waggoner, and Zhiwei Steven Wu. 2018. Strategic classification from revealed preferences. In _Proceedings of the 2018 ACM Conference on Economics and Computation_. 55-70.
* Dresher et al. (2016) Melvin Dresher, Lloyd S Shapley, and Albert William Tucker. 2016. _Advances in Game Theory.(AM-52), Volume 52_. Vol. 52. Princeton University Press.
* Dubins and Spanier (1961) L. E. Dubins and E. H. Spanier. 1961. How to Cut A Cake Fairly. _Am. Math. Mon_ 68, 1 (1961), 1-17.
* Edmonds and Pruhs (2006) J. Edmonds and K. Pruhs. 2006. Cake Cutting Really Is Not a Piece of Cake. In _SODA_. 271-278.
* Su (1999) Francis Edward Su. 1999. Rental harmony: Sperner's lemma in fair division. _The American mathematical monthly_ 106, 10 (1999), 930-942.

* Filos-Ratsikas et al. (2022) Aris Filos-Ratsikas, Kristoffer Arnsfelt Hansen, Kasper Hogh, and Alexandros Hollender. 2022. FIXP-membership via Convex Optimization: Games, Cakes, and Markets. In _2021 IEEE 62nd Annual Symposium on Foundations of Computer Science (FOCS)_. 827-838. https://doi.org/10.1109/FOCS52979.2021.00085
* Filos-Ratsikas et al. (2020) Aris Filos-Ratsikas, Alexandros Hollender, Katerina Sotiraki, and Manolis Zampetakis. 2020. Consensus-Halving: Does It Ever Get Easier?. In _Proceedings of the 21st ACM Conference on Economics and Computation_ (Virtual Event, Hungary) _(EC '20)_. Association for Computing Machinery, New York, NY, USA, 381-399. https://doi.org/10.1145/3391403.3399527
* Filos-Ratsikas et al. (2021) Aris Filos-Ratsikas, Alexandros Hollender, Katerina Sotiraki, and Manolis Zampetakis. 2021. A topological characterization of modulo-p arguments and implications for necklace splitting. In _Proceedings of the 2021 ACM-SIAM Symposium on Discrete Algorithms (SODA)_. SIAM, 2615-2634.
* Friedman et al. (2015) Eric Friedman, Christos-Alexandros Psomas, and Shai Vardi. 2015. Dynamic fair division with minimal disruptions. In _Proceedings of the sixteenth ACM conference on Economics and Computation_. 697-713.
* Gan et al. (2019) Jiarui Gan, Haifeng Xu, Qingyu Guo, Long Tran-Thanh, Zinovi Rabinovich, and Michael Wooldridge. 2019. Imitative follower deception in stackelberg games. In _Proceedings of the 2019 ACM Conference on Economics and Computation_. 639-657.
* Ghodsi et al. (2011) Ali Ghodsi, Matei Zaharia, Benjamin Hindman, Andy Konwinski, Scott Shenker, and Ion Stoica. 2011. Dominant resource fairness: Fair allocation of multiple resource types. In _8th USENIX symposium on networked systems design and implementation (NSDI 11)_.
* Goldberg et al. (2020a) Paul Goldberg, Alexandros Hollender, and Warut Suksompong. 2020a. Contiguous Cake Cutting: Hardness Results and Approximation Algorithms. _J. Artif. Intell. Res._ 69 (2020), 109-141. https://doi.org/10.1613/jair.1.12222
* 16th International Conference, WINE 2020, Beijing, China, December 7-11, 2020, Proceedings (Lecture Notes in Computer Science, Vol. 12495)_, Xujin Chen, Nikolai Gravin, Martin Hoefer, and Ruta Mehta (Eds.). Springer, 384-397. https://doi.org/10.1007/978-3-030-64946-3_27
* Goldberg and Jaru (2021) Paul W. Goldberg and Ioana Jaru. 2021. Equivalence of Models of Cake-Cutting Protocols. https://doi.org/10.48550/ARXIV.2108.03641
* Goldman and Procaccia (2014) J. Goldman and A. D. Procaccia. 2014. Spliddit: Unleashing fair division algorithms. _ACM SIG. Exch_ 13, 2 (2014), 41-46.
* Ghodsi et al. (2016)Nika Haghtalab, Thodoris Lykouris, Sloan Nietert, and Alexander Wei. 2022. Learning in stackelberg games with non-myopic agents. In _Proceedings of the 23rd ACM Conference on Economics and Computation_. 917-918.
* Hajiaghayi et al. (2023) MohammadTaghi Hajiaghayi, Mohammad Mahdavi, Keivan Rezaei, and Suho Shin. 2023. Regret Analysis of Repeated Delegated Choice. _arXiv preprint arXiv:2310.04884_ (2023).
* Harris (1998) Christopher Harris. 1998. On the Rate of Convergence of Continuous-Time Fictitious Play. _Games and Economic Behavior_ 22, 2 (1998), 238-259. https://doi.org/10.1006/game.1997.0582
* Kandasamy et al. (2020) Kirthevasan Kandasamy, Gur-Eyal Sela, Joseph E Gonzalez, Michael I Jordan, and Ion Stoica. 2020. Online Learning Demands in Max-min Fairness. arXiv:2012.08648 [stat.ML]
* Karlin (1959) Samuel Karlin. 1959. _Mathematical Methods and Theoryin Games, Programming, and Economics_. Addison Wesley.
* Kash et al. (2014) Ian Kash, Ariel D Procaccia, and Nisarg Shah. 2014. No agent left behind: Dynamic fair division of multiple resources. _Journal of Artificial Intelligence Research_ 51 (2014), 579-603.
* Kleinberg and Leighton (2003) Robert Kleinberg and Tom Leighton. 2003. The value of knowing a demand curve: Bounds on regret for online posted-price auctions. In _44th Annual IEEE Symposium on Foundations of Computer Science, 2003. Proceedings._ IEEE, 594-605.
* Kuhn (1950) Harold W Kuhn. 1950. Extensive games. _Proceedings of the National Academy of Sciences_ 36, 10 (1950), 570-576.
* Kuhn (1953) HW Kuhn. 1953. Extensive games and the problem of information. _Contributions to the Theory of Games_ 24 (1953), 193.
* Kulkarni et al. (2021) Rucha Kulkarni, Ruta Mehta, and Setareh Taki. 2021. Indivisible mixed manna: On the computability of MMS+ PO allocations. In _Proceedings of the 22nd ACM Conference on Economics and Computation_. 683-684.
* Manurangsi and Suksompong (2021) Pasin Manurangsi and Warut Suksompong. 2021. Closing Gaps in Asymptotic Fair Division. _SIAM Journal on Discrete Mathematics_ 35, 2 (2021), 668-706. https://doi.org/10.1137/20M1353381 arXiv:https://doi.org/10.1137/20M1353381
* Monderer and Shapley (1996a) D. Monderer and L.S. Shapley. 1996a. Fictitious Play Property for Games with Identical Interests. _Journal of Economic Theory_ 68 (1996), 258-265.
* Monderer and Shapley (1996b) D. Monderer and L.S. Shapley. 1996b. Potential Games. _Games and Economic Behavior_ 14 (1996), 124-143.
* Mossel and Tamuz (2010) Elchanan Mossel and Omer Tamuz. 2010. Truthful Fair Division. In _Algorithmic Game Theory_, Spyros Kontogiannis, Elias Koutsoupias, and Paul G. Spirakis (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 288-299.
* Moulin (2003) H. Moulin. 2003. _Fair Division and Collective Welfare_. The MIT Press.
* Nachbar (1990) J. Nachbar. 1990. Evolutionary Selection Dynamics in Games: Convergence and Limit Properties. _International Journal of Game Theory_ 19 (1990), 59-89.
* Nicolo and Yu (2008) Antonio Nicolo and Yan Yu. 2008. Strategic divide and choose. _Games and Economic Behavior_ 64, 1 (2008), 268-289. https://doi.org/10.1016/j.geb.2008.01.006
* Oh et al. (2021) Hoon Oh, Ariel D. Procaccia, and Warut Suksompong. 2021. Fairly Allocating Many Goods with Few Queries. _SIAM Journal on Discrete Mathematics_ 35, 2 (2021), 788-813. https://doi.org/10.1137/20M1313349 arXiv:https://doi.org/10.1137/20M1313349
* Panageas et al. (2023) Ioannis Panageas, Nikolas Patris, Stratis Skoulakis, and Volkan Cevher. 2023. Exponential Lower Bounds for Fictitious Play in Potential Games. arXiv:2310.02387 [cs.GT]
* Perkins and Leslie (2014) S. Perkins and D.S. Leslie. 2014. Stochastic fictitious play with continuous action sets. _Journal of Economic Theory_ 152 (2014), 179-213. https://doi.org/10.1016/j.jet.2014.04.008Benjamin Plaut and Tim Roughgarden. 2019. Communication Complexity of Discrete Fair Division. In _Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2019, San Diego, California, USA, January 6-9, 2019_, Timothy M. Chan (Ed.). SIAM, 2014-2033. https://doi.org/10.1137/1.9781611975482.122
* Plaut and Roughgarden (2020) Benjamin Plaut and Tim Roughgarden. 2020. Almost envy-freeness with general valuations. _SIAM Journal on Discrete Mathematics_ 34, 2 (2020), 1039-1068.
* Procaccia (2009) A. D. Procaccia. 2009. Thou Shalt Covet Thy Neighbor's Cake. In _IJCAI_. 239-244.
* Procaccia (2013) A. D. Procaccia. 2013. Cake Cutting: Not Just Child's Play. _Commun. ACM_ 56, 7 (2013), 78-87.
* Procaccia (2020) Ariel D. Procaccia. 2020. Technical perspective: An answer to fair division's most enigmatic question. _Commun. ACM_ 63, 4 (mar 2020), 118. https://doi.org/10.1145/3382131
* Procaccia and Wang (2014) Ariel D Procaccia and Junzing Wang. 2014. Fair enough: Guaranteeing approximate maximin shares. In _Proceedings of the fifteenth ACM conference on Economics and computation_. 675-692.
* Robertson and Webb (1998) J. M. Robertson and W. A. Webb. 1998. _Cake Cutting Algorithms: Be Fair If You Can_. A. K. Peters.
* Robinson (1951) J. Robinson. 1951. An Iterative Method of Solving a Game. _Annals of Mathematics_ 54 (1951), 296-301.
* Segal-Halevi (2018) Erel Segal-Halevi. 2018. Cake-Cutting with Different Entitlements: How Many Cuts are Needed? _CoRR_ abs/1803.05470 (2018). arXiv:1803.05470 http://arxiv.org/abs/1803.05470
* von Stackelberg (1934) Heinrich von Stackelberg. 1934. Marktform und gleichgewicht. _(No Title)_ (1934).
* Steinhaus (1948) H. Steinhaus. 1948. The Problem of Fair Division. _Econometrica_ 16 (1948), 101-104.
* Stromquist (1980) W. Stromquist. 1980. How to cut a cake fairly. _Am. Math. Mon_ 8 (1980), 640-644. Addendum, vol. 88, no. 8 (1981). 613-614.
* Stromquist (2008) W. Stromquist. 2008. Envy-free cake divisions cannot be found by finite protocols. _Electron. J. Combin._ 15 (2008).
* Tambe (2011) Milind Tambe. 2011. _Security and game theory: algorithms, deployed systems, lessons learned_. Cambridge university press.
* Tamuz et al. (2018) Omer Tamuz, Shai Vardi, and Juba Ziani. 2018. Non-Exploitable Protocols for Repeated Cake Cutting. In _Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018_, Sheila A. McIlraith and Kilian Q. Weinberger (Eds.). AAAI Press, 1226-1233. https://doi.org/10.1609/AAAI.V3211.11472
* Tang and Sandholm (2012) Pingzhong Tang and Tuomas Sandholm. 2012. Optimal Auctions for Spiteful Bidders. In _Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence, July 22-26, 2012, Toronto, Ontario, Canada_, Jorg Hoffmann and Bart Selman (Eds.). AAAI Press, 1457-1463. https://doi.org/10.1609/AAAI.V26I1.8235
* Tao (2022) Biaoshuai Tao. 2022. On Existence of Truthful Fair Cake Cutting Mechanisms. In _Proceedings of the 23rd ACM Conference on Economics and Computation_ (Boulder, CO, USA) _(EC '22)_. Association for Computing Machinery, New York, NY, USA, 404-434. https://doi.org/10.1145/3490486.3538321
* Tucker-Foltz and Zeckhauser (2023) Jamie Tucker-Foltz and Richard J. Zeckhauser. 2023. Playing Divide-and-Choose Given Uncertain Preferences. In _Proceedings of the 24th ACM Conference on Economics and Computation_ (London, United Kingdom) _(EC '23)_. Association for Computing Machinery, New York, NY, USA, 1127. https://doi.org/10.1145/3580507.3597811
* Walsh (2011) Toby Walsh. 2011. Online cake cutting. In _Algorithmic Decision Theory: Second International Conference, ADT 2011, Piscataway, NJ, USA, October 26-28, 2011. Proceedings 2_. Springer, 292-305.
* Wainwright and Zee (2012)Gerhard J Woeginger and Jiri Sgall. 2007. On the complexity of cake cutting. _Discrete Optimization_ 4, 2 (2007), 213-220.
* Zhao et al. (2023) Geng Zhao, Banghua Zhu, Jiantao Jiao, and Michael Jordan. 2023. Online learning in stackelberg games with an omniscient follower. In _International Conference on Machine Learning_. PMLR, 42304-42316.

Appendix: Alice exploiting Bob

In this section we present the proofs for Proposition 1, showing how Alice can exploit a myopic Bob that chooses his favorite piece in each round, and for Theorem 1, where Bob is nearly myopic.

Before giving the proofs, we formally define what we mean for Alice or Bob to ensure themselves a certain amount of regret.

**Definition 3** (Ensuring Alice's regret).: _Suppose Bob plays a strategy \(S_{B}\). A mixed strategy \(S_{A}\) for Alice ensures her Stackelberg regret is at most \(\gamma\) against \(S_{B}\) if \(\text{Reg}_{A}(H)\leq\gamma\) for all \(T\)-round histories \(H\) that could have arisen under the strategy pair \((S_{A},S_{B})\)._

_If instead Alice only knows that Bob plays some strategy from a set \(\mathcal{B}\) of strategies, then a mixed strategy \(S_{A}\) for Alice ensures her Stackelberg regret is at most \(\gamma\) if it ensures her Stackelberg regret is at most \(\gamma\) against all \(S_{B}\in\mathcal{B}\)._

**Definition 4** (Ensuring Bob's regret).: _Suppose Alice plays a strategy \(S_{A}\). A mixed strategy \(S_{B}\) for Bob ensures his regret is at most \(\gamma\) against \(S_{A}\) if \(\text{Reg}_{B}(H)\leq\gamma\) for all \(T\)-round histories \(H\) that could have arisen under the strategy pair \((S_{A},S_{B})\)._

_In general, a mixed strategy \(S_{B}\) for Bob ensures his regret is at most \(\gamma\) if it ensures his regret is at most \(\gamma\) against all Alice strategies._

### Appendix: Exploiting a Myopic Bob

**Restatement of Proposition 1**.: _If Bob plays myopically in the sequential setting, then Alice has a strategy that ensures her Stackelberg regret is \(O(\log T)\)._

Proof.: We consider an explore-then-commit type of algorithm for Alice. In the exploration phase, Alice does binary search to find Bob's midpoint (within accuracy of \(1/T\)). In the commitment (exploitation) phase, Alice repeatedly cuts at Bob's approximate midpoint. This leads to Alice getting nearly her Stackelberg value in nearly every round. Figure 8 shows a visualization of a cake instance with Alice and Bob's midpoints, respectively, with Alice's search process.

Alice's algorithm is described precisely in Figure 9.

Figure 8: Alice’s algorithm against myopic Bob in the exploration phase. Alice’s density is shown with blue and her midpoint is \(m_{A}\), while Bob’s density is shown with red and his midpoint is \(m_{B}\). The algorithm initialized \(\ell_{1}=0\) and \(r_{1}=1\) and then re-computes them iteratively depending on Bob’s answers. The constructed interval \([\ell_{t},r_{t}]\) shrinks exponentially and becomes closer to \(m_{B}\) as the time \(t\) increases.

Alice's algorithm when Bob is myopic: InitializationSet \(\ell_{1}=0,r_{1}=1\) and \(\tau=\ln(T)\). ExplorationFor \(t=1,2,\ldots,\tau:\) * Cut at a point \(x_{t}\in[\ell_{t},r_{t}]\) such that \(V_{A}([\ell_{t},x_{t}])=V_{A}([x_{t},r_{t}])\). Then observe Bob's action \(b_{t}\). * If \(b_{t}=L\), then set \((\ell_{t+1},r_{t+1})=(\ell_{t},x_{t})\). * Else if \(b_{t}=R\), then set \((\ell_{t+1},r_{t+1})=(x_{t},r_{t})\). ExploitationFor \(t=\tau+1,\ldots,T\): * If \(m_{A}\leq\ell_{\tau}\), then cut at \(\ell_{\tau}-1/T\). * If \(m_{A}\geq r_{\tau}\), then cut at \(r_{\tau}+1/T\).

We show that Algorithm A.1 in Figure 9 with \(\tau=\Theta(\ln T)\) gives the desired regret bound in several steps.

Bob's midpoint lies in the interval \([r_{t},\ell_{t}]\) for all \(t\)To this end, we first claim that Bob's midpoint lies in \([\ell_{t},r_{t}]\) at each round \(t\). We proceed by induction on \(t\). The base case is \(t=1\) clearly holds since \(\ell_{1}=0\) and \(r_{1}=1\), so \(m_{B}\in[\ell_{1},r_{t}]\). Suppose that \(m_{B}\in[\ell_{t},r_{t}]\) for some \(t\geq 1\). Given that Alice cuts at \(x_{t}\in(\ell_{t},r_{t})\), if \(b_{t}=L\), this implies that \(m_{B}\in[\ell_{t},x_{t}]\). Hence \(m_{B}\in[\ell_{t},x_{t}]=[\ell_{t+1},r_{t+1}]\). This argument also holds when Bob chooses \(R\). Thus by induction, we conclude that \(m_{B}\in[\ell_{t},r_{t}]\) for every \(t\in[T]\).

Alice's midpoint satisfies \(m_{A}\notin(\ell_{t},r_{t})\) for every \(t\geq 2\)Now, during the execution of the algorithm, we will next show that Alice's midpoint \(m_{A}\) satisfies either of \(m_{A}\leq\ell_{t}\) and \(m_{A}\geq r_{t}\), _i.e.,_\(m_{A}\notin(\ell_{t},r_{t})\) for every \(t\geq 2\). To see this, recall that in the first round, Alice cuts \(x_{1}=m_{A}\). If \(b_{1}=L\), then \(\ell_{2}=0\) and \(r_{2}=m_{A}\). In this case, \([\ell_{2},r_{2}]=[0,m_{A}]\), so \(m_{A}\notin(\ell_{2},r_{2})\). Afterwards, it still holds since the intervals only shrink, _i.e.,_\((\ell_{t+1},r_{t+1})\subset(\ell_{t},r_{t})\). Similarly, consider the case that \(b_{1}=R\). Then, we have \(\ell_{2}=m_{A}\) and \(r_{2}=1\). Thus \([\ell_{2},r_{2}]=[m_{A},1]\), which implies that \(m_{A}\notin(\ell_{2},r_{2})\). Again since the intervals \((\ell_{t},r_{t})\) only shrink, we conclude that \(m_{A}\notin(\ell_{t},r_{t})\) for every \(t\geq 2\).

Interval exponentially shrinksWe have \(V_{A}([\ell_{t},r_{t}])=V_{A}([\ell_{t-1},r_{t-1}])/2\) for every \(t\in[T]\), as we shrink the interval by cutting a point that equalizes Alice's value for both parts within the interval. This implies that \(V_{A}([\ell_{\tau},r_{\tau}])=2^{-\tau+1}\).

Bounding exploitation phase regretIn the exploitation phase, due to the observation above, we have two cases: (i) \(m_{A}\leq\ell_{\tau}\) and (ii) \(m_{A}\geq r_{\tau}\). We will prove that in either case, Alice's single-round regret in the exploitation phase is at most \(2^{-\tau+1}+\Delta/T\).

* For the first case of \(m_{A}\leq\ell_{\tau}\), Alice keeps cutting at \(\ell_{\tau}-1/T\) for the rest of rounds as per the algorithm's description. Then, Bob will myopically choose \(R\) and Alice will obtain \(V_{A}([0,\ell_{\tau}-1/T])\). In this case, we have that \(m_{A}\leq m_{B}\) since \(m_{B}\in[\ell_{\tau},r_{\tau}]\). Then, Alice's single-round regret in the exploitation phase is bounded by \[V_{A}([0,m_{B}])-V_{A}([0,\ell_{\tau}-1/T]) =V_{A}([\ell_{\tau},m_{B}])+V_{A}([\ell_{\tau}-1/T,\ell_{\tau}])\] \[\leq V_{A}([\ell_{\tau},r_{\tau}])+\frac{\Delta}{T}\] \[=2^{-\tau+1}+\frac{\Delta}{T}.\]
* Otherwise suppose \(m_{A}\geq r_{\tau}\). According to the algorithm, Alice keeps cutting \(r_{\tau}+1/T\) for all the rest of the rounds, and Bob will respond with \(L\). In this case we have

Figure 9: Algorithm A.1

since \(m_{B}\in[\ell_{r},r_{\tau}]\). Similarly, Alice's single-round regret can be upper-bounded by

\[V_{A}([m_{B},1])-V_{A}([r_{\tau}+1/T,1]) =V_{A}([m_{B},r_{\tau}])+V_{A}([r_{\tau},r_{\tau}+1/T])\] \[\leq V_{A}([\ell_{\tau},r_{\tau}])+\frac{\Delta}{T}\] \[=2^{-\tau+1}+\frac{\Delta}{T}.\]

Hence in both cases, Alice's single-round regret in the exploitation phase is at most \(2^{-\tau+1}+\Delta/T\).

Final regret boundOverall, by simply upper-bounding Alice's single-round regret in the exploration phase by \(1\), we obtain the following upper bound for the total regret:

\[\tau\cdot 1+(T-\tau)\cdot\left(2^{-\tau+1}+\frac{\Delta}{T}\right).\]

Plugging \(\tau=\ln(T)\), we obtain the regret bound of \(O(\ln T)\), which completes the proof.3 

Footnote 3: We do not optimize over \(\tau\).

### Appendix: Exploiting a Nearly Myopic Bob

In this section we prove Theorem 1, which explains the payoffs achievable by Alice when Bob has a strategy with sub-linear regret. We restate it here for reference.

**Restatement of Theorem 1** (Exploiting a nearly myopic Bob).: _Let \(\alpha\in[0,1)\). Suppose Bob plays a strategy that ensures his regret is \(O(T^{\alpha})\). Let \(\mathcal{B}^{\alpha}\) denote the set of all such Bob strategies._

\(\bullet\) _If Alice knows \(\alpha\), she has a strategy \(S_{A}=S_{A}(\alpha)\) that ensures her Stackelberg regret is \(O\big{(}T^{\frac{\alpha+1}{2}}\log T\big{)}\). The exponent is sharp: Alice's Stackelberg regret is \(\Omega\big{(}T^{\frac{\alpha+1}{2}}\big{)}\) for some Bob strategy in \(\mathcal{B}^{\alpha}\)._

\(\bullet\) _If Alice does not know \(\alpha\), she has a strategy \(S_{A}\) that ensures her Stackelberg regret is \(O\big{(}\frac{T}{\log T}\big{)}\). The exponent is sharp: if \(S_{A}\) guarantees Alice Stackelberg regret \(O(T^{\beta})\) against all Bob strategies in \(\mathcal{B}^{\alpha}\) for some \(\beta\in[0,1)\), then \(S_{A}\) has Stackelberg regret \(\Omega(T)\) for some Bob strategy in \(\mathcal{B}^{\beta}\)._

Proof of Theorem 1.: The known-\(\alpha\) upper bound of \(O\big{(}T^{\frac{\alpha+1}{2}}\log T\big{)}\) follows from invoking Proposition 4 with \(f(T)=T^{\alpha}\). The \(\Omega\big{(}T^{\frac{\alpha+1}{2}}\big{)}\) lower bound is Proposition 5.

The lower bound for the case where \(\alpha\) is unknown follows from Lemma 3. The upper bound follows from invoking Proposition 4 with \(f(T)=\frac{T}{(\log T)^{4}}\). 

Both upper bounds follow the same template, which is captured by the following proposition.

**Proposition 4**.: _Suppose Bob's strategy has regret \(O(f(T))\), for \(f(T)\in o\big{(}\frac{T}{(\log T)^{2}}\big{)}\) and \(f(T)\geq 1\). If Alice knows \(f\), then she has a strategy that guarantees her Stackelberg regret is \(O(\sqrt{T\cdot f(T)}\log T)\). In particular, if_

* _Bob's strategy has regret at most_ \(rf(T)\)_, for some_ \(r>0\)_; and_
* \(T\) _is large enough so that_ \(T>\exp\big{(}\frac{4r\Delta}{\delta}\big{)}\) _and_ \(f(T)<\frac{T}{(\ln T)^{2}}\)_;_

_then Alice's payoff satisfies:_

\[u_{A}\geq T\cdot u_{A}^{*}-\left(\frac{5}{\ln 2}+6\right)\sqrt{f(T)\cdot T}\ln T\,.\]

Before proving the proposition, we present the algorithm that Alice will run to beat a Bob with a regret guarantee of \(O(f(T))\).

_Alice's strategy when Bob's regret is at most \(r\cdot f(T)\), for some constant \(r>0\):_

_Informational assumption: Alice needs to know \(f\) and \(T,\) but not \(r\)._

**Initialization**: Define

\[x_{0}=0;\ \ y_{0}=1;\ \ \eta=\lceil\sqrt{f(T)\cdot T}\rceil;\ \ n=\lfloor-\log_{2} \bigl{(}3\sqrt{f(T)/T}\ln T\bigr{)}\rfloor\,.\]
**Exploration**: For \(i=0,1,\ldots,n-1\):

* **Step 1:** Set \(a_{i,0}=x_{i}\) and \(a_{i,6}=y_{i}\). For \(j\in[5]\), let \(a_{i,j}\) be the point with \[V_{A}([x_{i},a_{i,j}])=\frac{j}{6}V_{A}([x_{i},y_{i}])\,.\]
* **Step 2:*
* For \(j\in[5]\):
* Cut at \(a_{i,j}\) for \(\eta\) rounds. Define \(c_{i,j}=L\) if the majority of Bob's answers were left when the cut point was \(a_{i,j}\), and \(c_{i,j}=R\) otherwise.
* **Step 3:*
* If \(c_{i,j}=L\)\(\forall j\in[5]\), then set \(x_{i+1}=x_{i}\) and \(y_{i+1}=a_{i,3}\).
* If \(c_{i,j}=R\)\(\forall j\in[5]\), then set \(x_{i+1}=a_{i,3}\) and \(y_{i+1}=y_{i}\).
* Else, there exists a unique \(k\in[4]\) such that \(c_{i,j}=R\) for all \(j\leq k\) and \(c_{i,j}=L\) for all \(j>k\). Set \(x_{i+1}=a_{i,k-1}\) and \(y_{i+1}=a_{i,k+2}\).
**Exploitation**: For the rest of the rounds, Alice cuts at \(\chi\) based on the following cases:

\[\chi=\begin{cases}x_{n}&m_{A}<x_{n}\\ y_{n}&m_{A}>y_{n}\\ m_{A}&m_{A}\in[x_{n},y_{n}].\end{cases}\]

Proof of Proposition 4.: Overall, Alice will use an explore-then-commit style of algorithm:

* In the exploration phase, Alice conducts a variant of binary search to locate Bob's midpoint \(m_{B}\) within an accuracy of \(O\bigl{(}\sqrt{f(T)/T}\log T\bigr{)}\).
* In the exploitation phase, Alice cuts near the estimated midpoint for the rest of the rounds.

The main difficulty that Alice encounters is to precisely locate Bob's midpoint in the exploration phase, since Bob can fool Alice if she cuts sufficiently close to his midpoint. We overcome this challenge by having Alice's algorithm stay far enough from \(m_{B}\) so that Bob is forced to answer truthfully most of the time.

Notation.Let \(w=\sqrt{f(T)/T}\ln T\). Then \(n=\lfloor-\log_{2}(3w)\rfloor\). Since \(f(T)<\frac{T}{(\ln T)^{2}}\) by the assumption in the proposition statement, we have \(w<1\) and thereby \(n\geq 0\). Also recall the proposition statement assumes that Bob's strategy guarantees him a regret of at most \(rf(T)\) for some \(r>0\). Moreover, \(T\) was chosen such that \(T>\exp\left(\frac{4r\Delta}{\delta}\right)\).

Consider the Alice strategy described in Algorithm A.2 (Fig. 10). By Lemma 1, the exploration phase in Alice's strategy is well-defined.

Next we derive some useful observations and then combine them to upper-bound Alice's regret.

Useful observations.By Lemma 2, we have \(m_{B}\in[x_{n},y_{n}]\). Consider the cut point \(\chi\) in the exploitation phase. We write \(\textsc{Intv}[x,y]\) to denote the interval \([x,y]\) if \(y\geq x\) and \([y,x]\) if \(x>y\)

Figure 10: Algorithm A.2

Then, we obtain

\[V_{A}(\textsc{Intv}[\chi,m_{B}]) \leq V_{A}([x_{n},y_{n}])\] (By definition of \[\chi\] ) \[=2^{-n}\] (By property 2 of Lemma 2 ) \[\leq 2^{\log_{2}(3w)+1}\] (Plugging in \[n\] and using \[-\lfloor-x\rfloor\leq x+1\] ) \[=6\sqrt{\frac{f(T)}{T}}\ln T,\] (1)

where the last identity in (1) holds by definition of \(w\).

To upper-bound the number of times that Bob chooses the piece he likes less in the exploitation phase, we consider the following three cases with respect to \(\chi\):

* If \(\chi=x_{n}\) then \(m_{A}<x_{n}\). Thus \(x_{n}\neq 0\), so \(V_{B}([\chi,m_{B}])>r\sqrt{f(T)/T}\) by Lemma 2. Since Bob's regret is at most \(rf(T)\), it follows that Bob takes the wrong piece at most \(\frac{1}{2}\sqrt{f(T)\cdot T}\) times.
* If \(\chi=y_{n}\) then \(m_{A}>y_{n}\). Thus \(y_{n}\neq 1\), so \(V_{B}([m_{B},\chi])>r\sqrt{f(T)/T}\) by Lemma 2. Since Bob's regret is at most \(rf(T)\), it follows that Bob takes the wrong piece at most \(\frac{1}{2}\sqrt{f(T)\cdot T}\) times.
* If \(\chi=m_{A}\), then there is no wrong piece because Alice values both equally. Thus this case does not increase the count of incorrect decisions.

Putting it all together.In the exploration phase, Alice accumulates regret at most \(n\cdot 5\left\lceil\sqrt{f(T)\cdot T}\right\rceil\), since that is the length of the exploration phase. In the exploitation phase, the regret comes from two sources:

* The gap between \(\chi\) and \(m_{B}\), which is bounded in equation (1).
* The rounds in the exploitation phase in which Bob chooses his least favorite piece. There are at most \(\frac{1}{2}\sqrt{f(T)\cdot T}\) such rounds by cases (a-c). Thus Alice's cumulative regret due to these rounds is also at most \(\frac{1}{2}\sqrt{f(T)\cdot T}\).

Then Alice's overall regret is at most:

\[n\cdot 5\left\lceil\sqrt{f(T)\cdot T}\right\rceil+T \cdot 6\sqrt{f(T)/T}\ln T+\frac{1}{2}\sqrt{f(T)\cdot T}\] \[\leq n\cdot 10\sqrt{f(T)\cdot T}+T\cdot 6\sqrt{f(T)/T}\ln T+\frac{1}{2} \sqrt{f(T)\cdot T}\] (Since \[\lceil x\rceil\leq 2x\enspace\forall x\geq 1\] ) \[\leq \left(\frac{5}{\ln 2}+6\right)\sqrt{f(T)\cdot T}\ln T,\] (Plugging in \[n\] and rearranging )

which is \(O\left(\sqrt{f(T)\cdot T}\ln T\right)\). This completes the proof. 

The following lemma shows that the exploration phase is well-defined.

**Lemma 1**.: _Alice's strategy from Algorithm A.2 (Fig. 10) has the following properties:_

* _If step_ \((3.c)\) _is executed in Alice's exploration phase, then there is a unique index_ \(k\in[4]\) _such that_ \(c_{i,j}=R\ \forall j\leq k\) _and_ \(c_{i,j}=L\ \forall j>k\)_._
* _For each_ \(j\in[5]\)_, define_ \(\tilde{c}_{i,j}=L\) _if Bob prefers_ \([0,a_{i,j}]\) _to_ \([a_{i,j},1]\) _and_ \(\tilde{c}_{i,j}=R\) _otherwise. If there exists_ \(j\in[5]\) _such that_ \(\tilde{c}_{i,j}\neq c_{i,j}\)_, then_ \(m_{B}\in(a_{i,j-1},a_{i,j+1})\)_._
* _For all_ \(i\in\{0,\dots,n-1\}\) _and_ \(j\in\{0,1,\dots,5\}\)_, we have_ \(V_{B}([a_{i,j},a_{i,j+1}])>2r\sqrt{f(T)/T}\)_._

Proof.: We prove each of the parts \((i-iii)\) required by the lemma.

Proof of part \((iii)\).Let \(j\in\{0,\ldots,5\}\). Bob's valuation for the interval \([a_{i,j},a_{i,j+1}]\) can be lower bounded as follows:

\[V_{B}([a_{i,j},a_{i,j+1}]) \geq\delta\cdot(a_{i,j+1}-a_{i,j}) (\text{Since }v_{B}(x)\geq\delta\ \forall x\in[0,1])\] \[\geq\frac{\delta}{\Delta}V_{A}([a_{i,j},a_{i,j+1}]) (\text{Since }v_{A}(x)\leq\Delta\ \forall x\in[0,1])\] \[=\frac{\delta}{\Delta}\cdot\frac{1}{6}V_{A}([x_{i},y_{i}])\,.\] (2)

By definition, Alice's strategy halves the cake interval considered with each iteration

\(i\in\{0,\ldots,n-1\}\), that is: \(V_{A}([x_{i},y_{i}])=1/2\cdot V_{A}([x_{i-1},y_{i-1}])\). Thus \(V_{A}([x_{i},y_{i}])=2^{-i}\) and \(2^{-i}\geq 2^{-n}\) for all \(i\in\{0,\ldots,n\}\). Combining these observations with inequality (2), we obtain

\[V_{B}([a_{i,j},a_{i,j+1}])\geq 2\cdot\frac{\delta}{12\Delta}2^{-n}\,.\] (3)

Let \(w=\sqrt{f(T)/T}\ln T\). Then \(n=\lfloor-\log_{2}(3w)\rfloor\). We have

\[\frac{\delta}{12\Delta}2^{-n} =\frac{\delta}{12\Delta}2^{-\lfloor-\log_{2}(3w)\rfloor} \text{(By definition of }n\text{)}\] \[\geq\frac{\delta}{12\Delta}2^{\log_{2}(3w)} \text{(Since }-\lfloor-x\rfloor\geq x\text{)}\] \[>\frac{\delta}{4\Delta}\cdot\sqrt{\frac{f(T)}{T}}\cdot\frac{4r \Delta}{\delta} \text{(By definition of }w\text{ and since }T>\exp\left(\frac{4r\Delta}{\delta}\right)\right)\] \[=r\sqrt{f(T)/T}\,.\] (4)

Combining inequalities (3) and (4), we conclude that

\[V_{B}([a_{i,j},a_{i,j+1}])>2r\sqrt{\frac{f(T)}{T}}.\] (5)

This concludes the proof of part \((iii)\).

Proof of parts \((i)\) and \((ii)\).For each \(i=0,\ldots,n-1\), we will show that at most one of the majority answers \(c_{i,j}\), for \(j\in[5]\), is different from Bob's truthful response.

To be precise, recall from the lemma statement that \(\tilde{c}_{i,j}\in\{L,R\}\) is Bob's truthful response that maximizes his value when Alice cut at \(a_{i,j}\).

Define

\[S_{i}=\left\{j\in[5]:c_{i,j}\neq\tilde{c}_{i,j}\right\}.\] (6)

Let \(\textsc{Intv}[x,y]\) denote the interval \([x,y]\) if \(y\geq x\) and \([y,x]\) if \(x>y\). If \(j\in S_{i}\), it must be the case that Bob picked the wrong piece in at least \(\frac{1}{2}\sqrt{f(T)\cdot T}\) rounds in which the cut was \(a_{i,j}\). Then Bob accumulated at least \(V_{B}(\textsc{Intv}[m_{B},a_{i,j}])\) regret in each such round. Let \(\ell\in[4]\). We have

\[\frac{1}{2}\sqrt{f(T)\cdot T}\sum_{j\in S_{i}}V_{B}(\textsc{Intv }[m_{B},a_{i,j}]) \leq r\cdot f(T)\quad\text{(Since Bob's total regret is at most }r\cdot f(T)\text{)}\] \[<\frac{1}{2}V_{B}([a_{i,\ell},a_{i,\ell+1}])\sqrt{f(T)\cdot T}\,.\] (By (5))

Dividing both sides by \(\frac{1}{2}\sqrt{f(T)\cdot T}\) gives:

\[\sum_{j\in S_{i}}V_{B}(\textsc{Intv}[m_{B},a_{i,j}])<V_{B}([a_{i,\ell},a_{i, \ell+1}])\quad\forall\ell\in[4]\,.\] (7)

We show that \(|S_{i}|\leq 1\). Suppose towards a contradiction that \(|S_{i}|>1\), meaning there exist indices \(j,\ell\in S_{i}\) with \(j\neq\ell\). Then

\[\textsc{Intv}[a_{i,j},a_{i,\ell}]\subseteq(\textsc{Intv}[m_{B},a_{i,j}]\cup \textsc{Intv}[m_{B},a_{i,\ell}])\,.\]This implies that

\[V_{B}(\textsc{Intv}[a_{i,j},a_{i,\ell}])\leq V_{B}(\textsc{Intv}[m_{B},a_{i,j}])+V _{B}(\textsc{Intv}[m_{B},a_{i,\ell}])\leq\sum_{j\in S_{i}}V_{B}(\textsc{Intv}[m_{ B},a_{i,j}]),\] (8)

which contradicts (7). Thus the assumption was false and \(|S_{i}|\leq 1\).

For any \(j\in S_{i}\), we must have either \(m_{B}\in(a_{i,j-1},a_{i,j}]\) or \(m_{B}\in[a_{i,j},a_{i,j+1})\), as otherwise (7) would be violated. Therefore, if \(\tilde{c}_{i,j}\neq c_{i,j}\) for some \(j\in[5]\), then \(m_{B}\in(a_{i,j-1},a_{i,j+1})\). This is part \((ii)\) required by the lemma.

Finally, we prove part \((i)\). We will show there exists a unique \(k\in[4]\) such that \(c_{i,j}=R\;\forall j\leq k\) and \(c_{i,j}=L\;\forall j>k\). The proof considers two cases:

* Case \(|S_{i}|=0\). Then every \(c_{i,j}\) truthfully reflects Bob's preferences: \(c_{i,j}=R\) if \(a_{i,j}<m_{B}\), and \(c_{i,j}=L\) if \(a_{i,j}>m_{B}\); \(c_{i,j}\in\{L,R\}\) if \(a_{i,j}=m_{B}\). An illustration can be seen in Figure 11. In all cases, there is a single switch from \(R\) to \(L\), and so the index \(k\) is unique. 
* Case \(|S_{i}|=1\). Then all but one of the \(c_{i,j}\)'s truthfully reflect Bob's preferences. An illustration can be seen in Figure 12. 

By part \((ii)\) of the lemma, the only exception occurs at an index \(j\) with the property \(m_{B}\in(a_{i,j-1},a_{i,j+1})\). But then \(c_{i,\ell}=\tilde{c}_{i,\ell}=R\) for \(\ell\leq j-1\) and \(c_{i,\ell}=\tilde{c}_{i,\ell}=L\) for \(\ell\geq j+1\), so regardless of \(c_{i,j}\) there will be a single switch from \(R\) to \(L\).

This concludes that the conditions for \(c_{i,j}\) in Step 3.c hold if the conditions in steps 3.a and 3.b do not. This concludes the proof of part \((i)\).

Figure 11: Illustration of Alice’s initial cuts for \(i=0\). In this example, she cuts \(3\) times at each of the points \(a_{0,j}\) and observes Bob’s choices, which are marked with \(L\)/\(R\) near each such cut point. By default, Alice knows what the answer would be if she cut at \(0\) or \(1\), so those are set to \(R\) and \(L\), respectively. In Figure (a), the truthful answers (reflecting Bob’s favorite piece according to his actual valuation) are marked with green, while the lying answers are marked with orange. The majority answer at each cut point \(a_{0,j}\), denoted \(c_{0,j}\), is illustrated in Figure (b). In this example, the majority answer at each cut point is consistent with Bob’s true preference.

Figure 12: Illustration of Alice’s initial cuts for \(i=0\). In this example, she cuts \(3\) times at each of the points \(a_{0,j}\) and observes Bob’s choices, which are marked with \(L\)/\(R\) near each such cut point. By default, Alice knows what the answer would be if she cut at \(0\) or \(1\), so those are set to \(R\) and \(L\), respectively. In Figure (a), the truthful answers (reflecting Bob’s favorite piece according to his actual valuation) are marked with green, while the lying answers are marked with orange. The majority answer at each cut point \(a_{0,j}\), denoted \(c_{0,j}\), is illustrated in Figure (b). In this example, the majority answer at each cut point is consistent with Bob’s true preference _except_ for cut point \(a_{0,4}\) where Bob lied every time and so the majority is incorrect as well.

The following lemma further reveals several properties of the constructed intervals during the execution of the algorithm.

**Lemma 2**.: _In the exploration phase of Algorithm A.2 (Fig. 10), Alice constructs a sequence of intervals_

\[[x_{0},y_{0}],[x_{1},y_{1}],\ldots,[x_{n},y_{n}]\]

_such that the following properties hold:_

* Property 1: \(x_{0}=0\) _and_ \(y_{0}=1\)_,_
* Property 2: \(V_{A}([x_{i+1},y_{i+1}])=\frac{1}{2}V_{A}([x_{i},y_{i}])\) _for_ \(i=0,\ldots,n-1\)_,_
* Property 3: \(m_{B}\in[x_{i},y_{i}]\)_, for all_ \(i\)_,_
* Property 4: _If_ \(x_{i}\neq 0\)_, then_ \(V_{B}([x_{i},m_{B}])>r\sqrt{f(T)/T}\)_._
* Property 5: _If_ \(y_{i}\neq 1\)_, then_ \(V_{B}([m_{B},y_{i}])>r\sqrt{f(T)/T}\)_._

Proof.: Property \(1\) holds since \([x_{0},y_{0}]=[0,1]\) by definition of the algorithm.

Property 2 follows from our choice of \(x_{i+1}\) and \(y_{i+1}\) always ensuring that \([x_{i+1},y_{i+1}]\) contains \(3\) of the \(6\) intervals of equal value the \(a_{i,j}\) divide \([x_{i},y_{i}]\) into.

We will show Properties 3-5 by induction. The base case is \(i=0\). Then \([x_{0},y_{0}]=[0,1]\). Properties 3-5 are vacuously true for this interval.

Assume that Properties 3-5 hold for \(i\in\{0,1,\ldots,n-1\}\). For each \(j\in[5]\), let \(\tilde{c}_{i,j}\) represent Bob's truthful answer when the cut point is \(a_{i,j}\). Formally, we have \(\tilde{c}_{i,j}=L\) if Bob prefers \([0,a_{i,j}]\) to \([a_{i,j},1]\) and \(\tilde{c}_{i,j}=R\) otherwise.

We show Properties 3-5 also hold for \(i+1\) by considering the next three cases:

**Case \(c_{i,j}=L\) for all \(j\).** In this case, the majority of Bob's answers is \(L\) at each cut point used by Alice. An illustration can be seen in Figure 13.

Then the algorithm recurses in the interval \([x_{i+1},y_{i+1}]\) given by \(x_{i+1}=x_{i}\) and \(y_{i+1}=a_{i,3}\). By Lemma 1, we have \(\tilde{c}_{i,j}=c_{i,j}\) for each of \(j\in\{2,3,4,5\}\), as otherwise Bob's "true" preferences would alternate between \(R\) and \(L\) more than once.

We claim that \(m_{B}\in[x_{i},a_{i,2})\). To see this, consider two cases:

* Case \(\tilde{c}_{i,1}=c_{i,1}\): then \(m_{B}\in[x_{i},a_{i,1}]\) since the majority answers are consistent with Bob's true preference.
* Case \(\tilde{c}_{i,1}\neq c_{i,1}\): then \(m_{B}\in(x_{i},a_{i,2})\) by Lemma 1.

Then \(m_{B}\in[x_{i},a_{i,2})\subset[x_{i+1},y_{i+1}]\), which proves Property 3 for \(i+1\).

If \(x_{i+1}=0\), then Property 4 vacuously follows. Otherwise, we have \(x_{i+1}=x_{i}\). Then by the inductive hypothesis we obtain \(V_{B}([x_{i+1},m_{B}])=V_{B}([x_{i},m_{B}])>r\sqrt{f(T)/T}\). Thus Property 4 holds for \(i+1\) as well.

Figure 13: Illustration of Alice’s initial cuts for \(i=0\). At each cut point \(a_{0,j}\), the majority of Bob’s answers is \(L\) (i.e. \(c_{0,j}=L\)). Then the algorithm recurses in the interval \([0,a_{0,3}]\).

Since \(m_{B}\in[x_{i},a_{i,2})\), we have \[V_{B}([m_{B},y_{i+1}])\geq V_{B}([a_{i,2},a_{i,3}])>2r\sqrt{f(T)/T},\] and so Property 5 holds for \(i+1\).

**Case \(c_{i,j}=R\) for all \(j\).**: In this case, the majority of Bob's answers is \(R\) at each cut point used by Alice. An illustration can be seen in Figure 14.

Then the algorithm recurses in the interval \([x_{i+1},y_{i+1}]\) given by \(x_{i+1}=a_{i,3}\) and \(y_{i+1}=y_{i}\). By Lemma 1, we have \(\tilde{c}_{i,j}=c_{i,j}\) for each of \(j\in\{1,2,3,4\}\).

We claim that \(m_{B}\in(a_{i,4},y_{i}]\). To see this, consider two cases:

* Case \(\tilde{c}_{i,5}=c_{i,5}\): then \(m_{B}\in[a_{i,5},y_{i}]\) since the majority answers are consistent with Bob's true preference.
* Case \(\tilde{c}_{i,5}\neq c_{i,5}\): then \(m_{B}\in(a_{i,4},y_{i})\) by Lemma 1.

Then \(m_{B}\in(a_{i,4},y_{i}]\subset[x_{i+1},y_{i+1}]\), which proves Property 3 for \(i+1\).

Since \(m_{B}\in(a_{i,4},y_{i}]\), we have

\[V_{B}([x_{i+1},m_{B}])\geq V_{B}([a_{i,3},a_{i,4}])>2r\sqrt{f(T)/T},\]

and so Property 4 holds for \(i+1\).

If \(y_{i+1}=1\), then Property 5 vacuously follows. Otherwise, we have \(y_{i+1}=y_{i}\). Then by the inductive hypothesis we obtain \(V_{B}([m_{B},y_{i+1}])=V_{B}([m_{B},y_{i}])>r\sqrt{f(T)/T}\). Thus Property 5 holds for \(i+1\) as well.
**Case where there is a transition from \(R\) to \(L\) and the last \(R\) is \(c_{i,k}\) for some \(k\in\{1,\ldots,4\}\).**: An illustration can be seen in Figure 15.

In this case, Alice recurses on the interval \([x_{i+1},y_{i+1}]\) given by

\[x_{i+1}=a_{i,k-1}\;\;\text{and}\;\;y_{i+1}=a_{i,k+2}\,.\]

If any of the \(c_{i,j}\) differ from the \(\tilde{c}_{i,j}\), it must be \(c_{i,k}\) or \(c_{i,k+1}\) because otherwise Bob's true preferences would alternate between \(R\) and \(L\) more than once, which is impossible. We consider three sub-cases:

Figure 14: Illustration of Alice’s initial cuts for \(i=0\). At each cut point \(a_{0,j}\), the majority of Bob’s answers is \(R\) (i.e. \(c_{0,j}=R\)). Then the algorithm recurses in the interval \([a_{0,3},1]\).

Figure 15: Illustration of Alice’s initial cuts for \(i=0\). In this example, there is a transition from \(R\) to \(L\) in the interval \([a_{0,2},a_{0,3}]\). Then the algorithm recurses in the interval \([a_{0,1},a_{0,4}]\), which is guaranteed to contain Bob’s midpoint.

1. **Case \(\tilde{c}_{i,k}\neq c_{i,k}\).** Each time Bob picked his less-preferred piece when Alice cut at \(a_{i,k}\), he lost \(2V_{B}(\textsc{Intv}[a_{i,k},m_{B}])\) in value compared to his regret benchmark. Since \(\tilde{c}_{i,k}\neq c_{i,k}\), he did so at least \(\frac{1}{2}\sqrt{f(T)\cdot T}\) times. In order to have regret at most \(rf(T)\), he must have \[V_{B}(\textsc{Intv}[a_{i,k},m_{B}])\leq r\sqrt{\frac{f(T)}{T}}.\] (9) By Lemma 1, we have \[m_{B}\in(a_{i,k-1},a_{i,k+1})\] (10) and \[V_{B}([a_{i,k-1},a_{i,k}])>2r\sqrt{\frac{f(T)}{T}}\,.\] (11) Combining equations (9), (10), and (11) we obtain \[V_{B}([x_{i+1},m_{B}]) =V_{B}([a_{i,k-1},m_{B}])\] (Since \[x_{i+1}=a_{i,k-1}\] ) \[\geq V_{B}([a_{i,k-1},a_{i,k}])-V_{B}(\textsc{Intv}[a_{i,k},m_{B}])\] (Since \[m_{B}>a_{i,k-1}\] by ( 10 )) \[>r\sqrt{f(T)/T}\,.\] (By ( 9 ) and ( 11 )) Thus \(V_{B}([x_{i+1},m_{B}])>r\sqrt{f(T)/T}\), so Property 4 holds for \(i+1\). Since \(m_{B}\in(a_{i,k-1},a_{i,k+1})\), we have \[V_{B}([m_{B},y_{i+1}])\geq V_{B}([a_{i,k+1},a_{i,k+2}])>2r\sqrt{f(T)/T},\] proving Property 5 for \(i+1\).
2. **Case \(\tilde{c}_{i,k+1}\neq c_{i,k+1}\).** Each time Bob picked his less-preferred piece when Alice cut at \(a_{i,k+1}\), he lost \(2V_{B}(\textsc{Intv}[a_{i,k+1},m_{B}])\) in value compared to his regret benchmark. Since \(\tilde{c}_{i,k+1}\neq c_{i,k+1}\), he did so at least \(\frac{1}{2}\sqrt{f(T)}\cdot T\) times. In order to have regret at most \(rf(T)\), he must have \[V_{B}(\textsc{Intv}[a_{i,k+1},m_{B}])\leq r\sqrt{\frac{f(T)}{T}}.\] (12) By Lemma 1, we have \[m_{B}\in(a_{i,k},a_{i,k+2})\] (13) and \[V_{B}([a_{i,k},a_{i,k+1}])>2r\sqrt{\frac{f(T)}{T}}\,.\] (14) Combining equations (12), (13), and (14) we obtain \[V_{B}([m_{B},y_{i+1}]) =V_{B}([m_{B},a_{i,k+2}])\] (Since \[y_{i+1}=a_{i,k+2}\] ) \[\geq V_{B}([a_{i,k+1},a_{i,k+2}])-V_{B}(\textsc{Intv}[a_{i,k+1},m_{B}])\] (Since \[m_{B}<a_{i,k+2}\] by ( 13 )) \[>r\sqrt{f(T)/T}\,.\] (By ( 12 ) and ( 14 )) Thus \(V_{B}([m_{B},y_{i+1}])>r\sqrt{f(T)/T}\), so Property 5 holds for \(i+1\). Since \(m_{B}\in(a_{i,k},a_{i,k+2})\), we have \[V_{B}([x_{i+1},m_{B}])\geq V_{B}([a_{i,k-1},a_{i,k}])>2r\sqrt{f(T)/T},\] which proves Property 4 for \(i+1\).

3. **Case**\(\tilde{c}_{i,j}=c_{i,j}\) **for all**\(j\in[5]\)**.** Then \(m_{B}\in[a_{i,k},a_{i,k+1}]\). By Lemma 1, we have \[V_{B}([x_{i},m_{B}])\geq V_{B}([x_{i},a_{i,k}])=V_{B}([a_{i,k-1},a_{i,k}])>2r \sqrt{f(T)/T}\] (15) and \[V_{B}([m_{B},y_{i}])\geq V_{B}([a_{i,k+1},y_{i}])=V_{B}([a_{i,k+1},a_{i,k+2}])>2r \sqrt{f(T)/T}\,.\] (16) Inequality (15) implies Property 4 for \(i+1\), while inequality (16) implies Property 5 for \(i+1\). In all three cases, \(m_{B}\in[a_{i,k-1},a_{i,k+2}]=[x_{i+1},y_{i+1}]\), showing Property 3 for \(i+1\).

Thus, in all three cases, Properties 3-5 hold for \(i+1\). By induction, they hold for all \(i\in\{0,1,\ldots,n\}\). This completes the proof. 

**Proposition 5**.: _Let \(v_{A}\) be an arbitrary Alice density and \(\alpha\in[0,1)\). Then there exists a value density function \(\tilde{v}_{B}=\tilde{v}_{B}(v_{A})\) and strategy \(\tilde{S}_{B}=\tilde{S}_{B}(v_{A},\alpha)\) that ensures Bob's regret is \(O(T^{\alpha})\) while Alice's Stackelberg regret is \(\Omega\left(T^{\frac{\alpha+1}{2}}\right)\)._

Proof.: At a high level, the Bob we construct will behave as if his midpoint were at \(m_{B}-T^{\frac{\alpha-1}{2}}\). If Alice calls his bluff, i.e. cuts close to \(m_{B}\) "enough" times, then Bob reverts to being honest by actually selecting his preferred piece.

Formally, let \(y\) be an arbitrary point such that \(y>m_{A}\). Define the Bob value density \(\tilde{v}_{B}\) as follows:

\[\tilde{v}_{B}(x)=\begin{cases}\frac{1}{2y}&\forall x\in[0,y]\\ \frac{1}{2(1-y)}&\forall x\in(y,1]\,.\end{cases}\] (17)

Bob's value density \(\tilde{v}_{B}\) is bounded since \(y\) is a fixed constant. Moreover, Bob's midpoint \(m_{B}\) is exactly at \(y\). Let \(\tilde{S}_{B}\) be Bob's strategy as defined in Figure 16.

Strategy \(\tilde{S}_{B}\) ensures that Bob takes his less-favorite piece at most \(T^{\frac{\alpha+1}{2}}\) times, and this only happens when Alice cuts in the interval

\[P=\left[m_{B}-T^{\frac{\alpha-1}{2}},m_{B}\right].\] (18)

Since the density \(\tilde{v}_{B}\) is bounded from above by a constant, Bob gives up a value of at most \(O(T^{\frac{\alpha-1}{2}})\) in each such round. Thus Bob's regret is \(O(T^{\alpha})\).

Now let us compute Alice's regret with respect to her Stackelberg value. Suppose that \(T\) is sufficiently large, so that \(m_{B}-T^{\frac{\alpha-1}{2}}>m_{A}\). There are two cases depending on whether Alice triggers the switch in Bob's strategy or not.

Figure 16: Algorithm A.3

* _Alice cuts in \(P\) at least \(T^{\frac{\alpha+1}{2}}\) times._ Consider the first \(T^{\frac{\alpha+1}{2}}\) times Alice cuts in \(P\). Whenever Alice cuts at some point \(x\in P\), her utility will be \(V_{A}([x,1])\) since Bob plays \(L\). Therefore, her payoff in that round is maximized when \(x\) is minimized, which occurs at the left-hand endpoint \(x=m_{B}-T^{\frac{\alpha-1}{2}}\). However, \[m_{B}-T^{\frac{\alpha-1}{2}}>m_{A},\] and so \[V_{A}\left(\left[m_{B}-T^{\frac{\alpha-1}{2}},1\right]\right)<1/2\,.\] (19) Then her Stackelberg regret over all the rounds in which she cuts in \(P\) is at least \[T^{\frac{\alpha+1}{2}}\cdot\left(V_{A}([0,m_{B}])-V_{A}\left( \left[m_{B}-T^{\frac{\alpha-1}{2}},1\right]\right)\right)\] \[\qquad>T^{\frac{\alpha+1}{2}}\cdot\left(V_{A}([0,m_{A}])+V_{A}([m_ {A},m_{B}])-\frac{1}{2}\right)\] \[\qquad=T^{\frac{\alpha+1}{2}}V_{A}([m_{A},m_{B}])\in\Omega\left(T^{ \frac{\alpha+1}{2}}\right)\,.\]
* _Alice cuts in_ \(P\) _fewer than_ \(T^{\frac{\alpha+1}{2}}\) _times_. In this case, we will show that Alice's payoff per round cannot be more than_ \(V_{A}\left(\left[0,m_{B}-T^{\frac{\alpha-1}{2}}\right]\right)\)_. To see this, we consider two sub-cases. If Alice cuts at a point_ \(x<m_{B}-T^{\frac{\alpha-1}{2}}\)_, then Bob picks R and Alice's utility in that round is_ \[V_{A}([0,x])<V_{A}\left(\left[0,m_{B}-T^{\frac{\alpha-1}{2}}\right]\right)\,.\] (20) If Alice cuts at a point_ \(x\geq m_{B}-T^{\frac{\alpha-1}{2}}\)_, then Bob picks L and Alice's utility in that round is_ \[V_{A}([x,1])<\frac{1}{2}<V_{A}\left(\left[0,m_{B}-T^{\frac{\alpha-1}{2}}\right] \right)\,.\] (21) Combining (20) and (21), we obtain that in each round_ \(t\in[T]\)_, Alice's utility is \[u_{A}^{t}\leq V_{A}\left(\left[0,m_{B}-T^{\frac{\alpha-1}{2}}\right]\right)\,.\] (22) Summing over all rounds_ \(t\in[T]\)_, we obtain that Alice's Stackelberg regret is_ \[\sum_{t=1}^{T}\left(u_{A}^{*}-u_{A}^{t}\right) \geq\sum_{t=1}^{T}\left(V_{A}([0,m_{B}])-V_{A}\left(\left[0,m_{B}- T^{\frac{\alpha-1}{2}}\right]\right)\right)\] (23) \[=\sum_{t=1}^{T}V_{A}\left(\left[m_{B}-T^{\frac{\alpha-1}{2}},m_{B} \right]\right)\] (24) \[\geq\sum_{t=1}^{T}\delta\cdot T^{\frac{\alpha-1}{2}}\in\Omega \left(T^{\frac{\alpha+1}{2}}\right)\,.\] (25)

_Thus in both cases, Alice's Stackelberg regret is at least_ \(\Omega\left(T^{\frac{\alpha+1}{2}}\right)\)_, which concludes the proof._

**Lemma 3**.: _Let \(\alpha,\beta\in[0,1)\). Suppose Alice's density is \(v_{A}\) and her strategy is \(S_{A}\). There exists a Bob \(\texttt{Bob}_{1}=(v_{B,1},S_{B,1})\) that depends on \(v_{A}\) and a Bob \(\texttt{Bob}_{2}=(v_{B,2},S_{B,2})\) that depends on \(v_{A}\) and \(S_{A}\), such that_

* \(\texttt{Bob}_{1}\) _has regret_ \(O(T^{\alpha})\) _(i.e. strategy_ \(S_{B,1}\) _ensures that a player with density_ \(v_{B,1}\) _has regret_ \(O(T^{\alpha})\)_)_
* \(\texttt{Bob}_{2}\) _has regret_ \(O(T^{\beta})\)_; and_* _if_ \(S_{A}\) _ensures Alice Stackelberg regret of_ \(O(T^{\beta})\) _against_ \(\texttt{Bob}_{1}\)_, then_ \(S_{A}\) _has regret at least_ \(T/6\) _against_ \(\texttt{Bob}_{2}\)_._

Proof.: Let \(x\) be the cake position such that \(V_{A}([0,x])=2/3\), and let \(y\) be the cake position such that \(V_{A}([0,y])=5/6\). The first \(\texttt{Bob}\), \(\texttt{Bob}_{1}\), will have a valuation function \(v_{B,1}\) that has midpoint \(x\). We define \(\texttt{Bob}_{1}\)'s strategy \(S_{B,1}\) so that it truthfully picks his preferred piece, _i.e.,_

\[S_{B,1}(A_{t},B_{t-1})=\begin{cases}L&\text{if }a_{t}\in(x,1]\\ R&\text{if }a_{t}\in[0,x]\,.\end{cases}\] (26)

Against \(\texttt{Bob}_{1}\), Alice's Stackelberg value is \(2/3\). Suppose \(S_{A}\) ensures Alice Stackelberg regret at most \(rT^{\beta}\) against \(\texttt{Bob}_{1}\) for some \(r>0\).

Then we define our second Bob, denoted \(\texttt{Bob}_{2}\), having a valuation function \(v_{B,2}\) which has a midpoint at \(y\). Let \(k(t)\) be the number of times Alice cuts in the interval \((x,y]\) in rounds \(\{1,\ldots,t\}\). Then \(\texttt{Bob}_{2}\)'s strategy will be defined as follows:

\[S_{B,2}(A_{t},B_{t-1})=\begin{cases}S_{B,1}(A_{t},B_{t-1})&\text{if }k(t)\leq 3rT^{\beta} \\ L&\text{if }k(t)>3rT^{\beta}\text{ and }a_{t}\in(y,1]\\ R&\text{if }k(t)>3rT^{\beta}\text{ and }a_{t}\in[0,y]\,.\end{cases}\] (27)

Intuitively, \(S_{B,2}\) switches to being honest after Alice cuts in \((x,y]\) sufficiently many times. This transition gives \(\texttt{Bob}_{2}\) a regret guarantee of \(O(T^{\beta})\).

When Alice plays \(S_{A}\) against \(\texttt{Bob}_{1}\), her total payoff is

\[u_{A}(S_{A},S_{B,1})\geq 2T/3-rT^{\beta}\,.\] (28)

However, every round she cuts in \((x,y]\), her payoff is less than \(1/3\). Therefore, against \(\texttt{Bob}_{1}\), her total payoff can also be bounded by

\[u_{A}(S_{A},S_{B,1})\leq 2T/3-k(T)/3\,.\] (29)

Combining inequalities (28) and (29), we obtain

\[k(T)\leq 3rT^{\beta}.\] (30)

By definition, strategy \(S_{B,2}\) behaves the same as strategy \(S_{B,1}\) when \(k(T)\leq 3rT^{\beta}\). By (30), we have \(k(T)\leq 3rT^{\beta}\) when Alice uses strategy \(S_{A}\). Thus, if Alice uses strategy \(S_{A}\), then \(\texttt{Bob}_{1}\) and \(\texttt{Bob}_{2}\) behave exactly the same way. Therefore, Alice receives no more than \(2/3\) per round against \(\texttt{Bob}_{2}\), so her regret is at least \(T/6\in\Omega(T)\). 

If Bob's density is not lower bounded by any constant, then Theorem 1 fails as shown in the next remark.

**Remark 1**.: _Let \(\alpha\in(0,1)\). There exist value densities \(v_{A}\) and \(v_{B}\), where \(v_{A}(x)\in[\delta,\Delta]\;\forall x\in[0,1]\) and \(v_{B}(x)\in(0,\Delta]\;\forall x\in[0,1]\) such that Bob has a strategy \(S_{B}\) which guarantees his regret is at most \(T^{\alpha}\) and Alice's Stackelberg regret is at least \(\Omega(T/\log T)\), no matter what strategy she uses._

Proof.: The specific valuations will be defined in terms of cumulative valuations. Let Alice's valuation be:

\[V_{A}([0,x])=\begin{cases}\frac{1}{2}x&\text{if }x\in[0,1/2]\\ \frac{3}{2}x-\frac{1}{2}&\text{if }x\in(1/2,1]\end{cases}\]

Let Bob's valuation be:

\[V_{B}([0,x])=\begin{cases}x&\text{if }x\in[0,1/2]\\ \frac{1}{2}+2^{-\frac{1}{2x-1}}&\text{if }x\in(1/2,1]\end{cases}\] (31)

Intuitively, Alice has a well-behaved piecewise uniform density with midpoint \(m_{A}=2/3\). Bob's density is well-behaved for \(x\leq 1/2\), but the density rapidly approaches zero just to the right of \(x=1/2\).

Fix an arbitrary \(\alpha\in(0,1)\). There exists a point \(y\) on the cake such that \(V_{B}([1/2,y])=\frac{1}{2}T^{\alpha-1}\). Define Bob's strategy \(S_{B}\) as follows:

\[S_{B}(A_{t},B_{t-1},v_{B},T)=\begin{cases}R&\text{if }a_{t}<y\\ L&\text{if }a_{t}\geq y\,.\end{cases}\]

This strategy would be honest if Bob's midpoint were at \(y\) rather than \(1/2\). That means it only differs from his preferred piece when \(a_{t}\in(1/2,y]\). The worst outcome for Bob occurs when \(a_{t}=y\). But by construction, even in a round where Alice cuts at \(y\), Bob only loses \(T^{\alpha-1}\) utility compared to picking his preferred piece. Since there are \(T\) rounds, his overall regret is at most \(T^{\alpha}\).

Alice, on the other hand, cannot do very well compared to her Stackelberg value. Her Stackelberg value is \(3/4\), achieved by cutting at Bob's midpoint of \(1/2\) and receiving her preferred piece. But Bob prevents this payoff by pretending his midpoint is at \(y\). To obtain the exact location of \(y\), note that

\[V_{B}([1/2,y])=\frac{1}{2}T^{\alpha-1}.\]

Plugging (31), this is equivalent to

\[2^{-\frac{1}{2y-1}}=\frac{1}{2}T^{\alpha-1}.\]

Solving for \(y\), we have

\[y=\frac{1}{2}+\frac{1}{(2-2\alpha)\log_{2}T+2}\,.\]

For sufficiently large \(T\), we have \(y\in(m_{B},m_{A})\). Alice's best cut location in each round is then at \(y\) itself, which gives her a per-round payoff of

\[V_{A}([y,1])=\frac{3}{4}-\frac{3}{(4-4\alpha)\log_{2}T+4}\,.\]

Adding this up over all \(T\) rounds gives a total regret of at least, we obtain

\[\frac{3T}{(4-4\alpha)\log_{2}T+4},\]

which is \(\Omega(T/\log T)\) as required. This completes the proof.

Appendix: Equitable payoffs

This appendix has two parts. In Appendix B.1, we prove Theorem 2, which shows that Alice can enforce equitable payoffs. In Appendix B.2, we prove Theorem 3, which shows that Bob can enforce equitable payoffs.

### Appendix: Alice enforcing equitable payoffs

In this section we prove Theorem 2, the statement of which is included next.

**Restatement of Theorem 2** (Alice enforcing equitable payoffs; formal).: _In both the sequential and simultaneous settings, Alice has a pure strategy \(S_{A}\), such that for every Bob strategy \(S_{B}\):_

* _on every trajectory of play, Alice's average payoff is at least_ \(1/2-o(1)\)_, while Bob's average payoff is at most_ \(1/2+o(1)\)_. More precisely, for all_ \(t\in\{3,\ldots,T\}\)_:_ \[\frac{u_{B}(1,t)}{t} \leq\frac{1}{2}+\frac{5\Delta+11}{\ln(2t/5)}\] (32) \[\frac{u_{A}(1,t)}{t} \geq\frac{1}{2}-\frac{4}{\sqrt{t-1}},\] (33) _recalling that_ \(\Delta\) _is the upper bound on the players' value densities._

_Moreover, even if Bob's value density is unbounded, his average payoff will still converge to \(1/2\)._

The proof of the theorem is deferred until additional definitions have been stated and helpful lemmas have been proved. We first define some notations.

**Definition 5** (Set of valuations \(\mathcal{W}_{n}\)).: _For each \(n\in\mathbb{N}^{*}\), we define the following set of non-decreasing piecewise linear functions with \(n\) pieces:_

\[\mathcal{W}_{n} =\begin{cases}f:[0,1]\to[0,1]\mid f\text{ is non-decreasing with }f(0)=0,f(1)=1,f(i/n)\cdot n\in\mathbb{Z}_{\geq 0},\text{ and}\] \[f(x) =f\Big{(}\frac{i}{n}\Big{)}+\Big{(}x-\frac{i}{n}\Big{)}\Big{(}f \left(\frac{i+1}{n}\right)-f\left(\frac{i}{n}\right)\Big{)}\forall i\in\{0, \ldots,n-1\}\,\forall x\in\left[\frac{i}{n},\frac{i+1}{n}\right]\end{cases}.\]

**Definition 6** (Set of functions \(\mathcal{V}_{n}\)).: _For each \(n\in\mathbb{N}^{*}\), recall \(\mathcal{W}_{n}\) was given in Definition 5 and define \(\mathcal{V}_{n}\) as the following set of functions:_

\[\mathcal{V}_{n} =\begin{cases}\mathcal{W}_{n}&\text{if }n\neq 2\\ \mathcal{W}_{2}\cup\{f_{A}\}&\text{if }n=2,\text{ where }f_{A}:[0,1]\to[0,1]\text{ is the function }f_{A}(x)=V_{A}([0,x]).\end{cases}\]

**Definition 7** (The set \(\overline{\mathcal{V}}\)).: _Let \(\overline{\mathcal{V}}=\bigcup_{n=1}^{\infty}\left\{(n,V):V\in\mathcal{V}_{n} \right\},\) where \(\mathcal{V}_{n}\) is given by Definition 6._

**Remark 2**.: _By construction, for each \(n\in\mathbb{N}^{*}\), every function \(f\in\mathcal{V}_{n}\) is non-decreasing._

For each \(n\in\mathbb{N}^{*}\), \(\mathcal{W}_{n}\) contains the nondecreasing piecewise linear functions through a grid with spacing \(1/n\). For large \(n\), then, \(\mathcal{W}_{n}\) should contain approximations to any given function accurate to roughly \(O(1/n)\).

If Alice bases her strategy on limiting the payoff of the Bobs in each \(\mathcal{W}_{n}\), then she will limit Bob's payoff but not necessarily guarantee herself a very good payoff. The inclusion of Alice's valuation function in \(\overline{\mathcal{V}}\) rectifies this, allowing us to show a much tighter bound on Alice's payoff.

To formalize the ability of the elements of the \(\mathcal{V}_{n}\) to approximate arbitrary valuation functions, we prove the following three lemmas. The first of them (Lemma 4) is somewhat technical, but most directly shows the richness of the \(\mathcal{V}_{n}\). It will be used to prove Lemmas 5 and 6, which will be used directly to bound the payoff of an unbounded-density and bounded-density Bob, respectively.

**Lemma 4**.: _Let \(f:[0,1]\to[0,1]\) be continuous and increasing with \(f(0)=0\) and \(f(1)=1\). Suppose there exist \(n\in\mathbb{N}^{*}\) and \(\varepsilon\in(0,\infty)\) such that_

\[|f(x)-f(y)|\leq\varepsilon\qquad\forall x,y\in[0,1]\text{ with }|x-y|\leq 1/n\,.\] (34)

_Then there exists \(V_{n}\in\mathcal{V}_{n}\), where \(\mathcal{V}_{n}\) is the set of functions from Definition 6, such that \(|f(x)-V_{n}(x)|\leq\varepsilon+2/n\;\;\forall x\in[0,1]\)._Proof.: For \(x\in\mathbb{R}\), let \(\lfloor x\rceil\) denote the nearest integer to \(x\), breaking ties in favor of \(\lceil x\rceil\) when \(x=\lfloor x\rfloor+1/2\).

Recall the set of functions \(\mathcal{W}_{n}\) from Definition 5. Let \(V_{n}\) be the function in \(\mathcal{W}_{n}\) such that:

\[V_{n}(i/n)=\frac{\lfloor n\cdot f(i/n)\rceil}{n}\qquad\forall i\in[n-1]\,.\] (35)

Then we claim the function \(V_{n}\) approximates well the function \(f\) at the points \(i/n\), that is:

\[\left|V_{n}(i/n)-f(i/n)\right|=\left|\frac{\lfloor n\cdot f(i/n)\rceil}{n}-f(i /n)\right|\leq\frac{1}{2n}\qquad\forall i\in\{0,\ldots,n\},\] (36)

where

* for \(i\in[n-1]\) the inequality in (36) follows from (35);
* for \(i=0\) it follows from \(V_{n}(0)=0=f(0)\), and
* for \(i=n\) it follows from \(V_{n}(1)=1=f(1)\).

Let \(x\in[0,1]\). We show three inequalities next:

1. By inequality (34) from the lemma statement with parameters \(\lfloor xn\rfloor/n\) and \(\lceil xn\rceil/n\), we get \[f\left(\frac{\lceil xn\rceil}{n}\right)-f\left(\frac{\lfloor xn\rfloor}{n} \right)\leq\varepsilon\,.\] (37)
2. By inequality (36) with \(i=\lceil xn\rceil\), we have \[\left|V_{n}\left(\frac{\lceil xn\rceil}{n}\right)-f\left(\frac{\lceil xn \rceil}{n}\right)\right|\leq\frac{1}{2n}\,.\] (38)
3. By inequality (36) with \(i=\lfloor xn\rfloor\), we have \[\left|f\left(\frac{\lfloor xn\rfloor}{n}\right)-V_{n}\left(\frac{\lfloor xn \rfloor}{n}\right)\right|\leq\frac{1}{2n}\,.\] (39)

Summing up inequalities (37), (38), (39) and applying the triangle inequality, we obtain

\[\left|V_{n}\left(\frac{\lceil xn\rceil}{n}\right)-V_{n}\left(\frac{\lfloor xn \rfloor}{n}\right)\right|\leq\varepsilon+\frac{1}{n}\,.\] (40)

We obtain

\[V_{n}\left(\frac{\lfloor xn\rfloor}{n}\right)-\frac{1}{2n} \leq f\left(\frac{\lfloor xn\rfloor}{n}\right)\] (By ( 36 ) with

\[i=\lfloor xn\rfloor\] ) \[\leq f(x)\] (Since

\[f\]

 is non-decreasing) \[\leq f\left(\frac{\lceil xn\rceil}{n}\right)\] (Since

\[f\]

 is non-decreasing) \[\leq V_{n}\left(\frac{\lceil xn\rceil}{n}\right)+\frac{1}{2n}\,.\] (By ( 36 ) with

\[i=\lceil xn\rceil\]

)

Denoting \(J=\left[V_{n}\big{(}\frac{\lfloor xn\rfloor}{n}\big{)}-1/(2n),V_{n}\big{(} \frac{\lceil xn\rceil}{n}\big{)}+1/(2n)\right]\), we conclude that \(f(x)\in J\). Since the function \(V_{n}\) is non-decreasing by Remark 2, we have

\[V_{n}\left(\frac{\lfloor xn\rfloor}{n}\right)-\frac{1}{2n}\leq V_{n}\left(x \right)-\frac{1}{2n}<V_{n}(x)<V_{n}(x)+\frac{1}{2n}\leq V_{n}\left(\frac{ \lceil xn\rceil}{n}\right)+\frac{1}{2n}\,.\] (41)Thus \(V_{n}(x)\in J\). Since both \(f(x)\in J\) and \(V_{n}(x)\in J\), we can bound \(|f(x)-V_{n}(x)|\) as follows:

\[|f(x)-V_{n}(x)| \leq|J|\] \[=\left(V_{n}\left(\frac{\lceil xn\rceil}{n}\right)+\frac{1}{2n} \right)-\left(V_{n}\left(\frac{\lfloor xn\rfloor}{n}\right)-\frac{1}{2n}\right)\] \[\leq\varepsilon+\frac{2}{n}\,.\qquad\qquad\text{ (Since $V_{n}\left(\frac{\lfloor xn\rfloor}{n}\right)-V_{n}\left(\frac{\lfloor xn \rfloor}{n}\right)\leq\varepsilon+1/n$ by \eqref{eq:Vn})}\]

Since this holds for all \(x\in[0,1]\), the function \(V_{n}\) required by the lemma exists. 

**Lemma 5**.: _Let \(f:[0,1]\to[0,1]\) be continuous and increasing with \(f(0)=0\) and \(f(1)=1\). For each \(\varepsilon>0\), there exists \(n\in\mathbb{N}^{*}\) and a function \(V_{n}\in\mathcal{V}_{n}\) such that_

\[|V_{n}(x)-f(x)|\leq\varepsilon\,\,\,\forall x\in[0,1],\] (42)

_recalling that the set of functions \(\mathcal{V}_{n}\) is given by Definition 6._

Proof.: Let \(\epsilon>0\). Since \(f\) is continuous and increasing, its inverse \(f^{-1}\) is also continuous and increasing. Since \(f(0)=0\) and \(f(1)=1\), we have \(f^{-1}(0)=0\) and \(f^{-1}(1)=1\). Consider a function \(g:[0,1-\varepsilon/4]\to[0,1]\) defined as

\[g(x)=f^{-1}\left(x+\varepsilon/4\right)-f^{-1}(x)\,.\] (43)

Since \(f^{-1}\) is continuous and bounded over a closed interval, so is the function \(g\). Therefore, by the extreme value theorem, \(g\) attains a global minimum value \(\delta^{*}\). Since \(f^{-1}\) is strictly increasing, \(g\) is never zero, so

\[\delta^{*}>0\,.\] (44)

Since we will analyze \(g(f(x))\), it will be useful to define the set of values \(x\) for which \(g(f(x))\) is well defined, that is:

\[S_{\varepsilon}=\{x\in[0,1]\mid f(x)\in[0,1-\varepsilon/4]\}\,\,.\] (45)

Since \(\delta^{*}\) is a global minimum of \(g\), we have

\[g(f(x))\geq\delta^{*}\qquad\forall x\in S_{\varepsilon}\,.\] (46)

Using the definition of \(g\) (equation (43)) in (46) yields

\[g(f(x))=f^{-1}\left(f(x)+\varepsilon/4\right)-f^{-1}(f(x))\geq\delta^{*} \qquad\forall x\in S_{\varepsilon}\,.\] (47)

Since \(f^{-1}(f(x))=x\), inequality (47) yields \(f^{-1}\left(f(x)+\varepsilon/4\right)-x\geq\delta^{*}\), or equivalently,

\[f^{-1}\left(f(x)+\varepsilon/4\right)\geq x+\delta^{*}\qquad\forall x\in S_{ \varepsilon}\,.\] (48)

Applying \(f\) to both sides of (48) and using monotonicity of \(f\), we obtain \(f(x)+\varepsilon/4\geq f(x+\delta^{*})\) for all \(x\in S_{\varepsilon}\), or equivalently

\[f\left(x+\delta^{*}\right)-f(x)\leq\varepsilon/4\qquad\forall x\in S_{ \varepsilon}\,.\] (49)

Since \(\varepsilon>0\) and \(\delta^{*}>0\) by (44), there exists \(n\in\mathbb{N}\) such that

\[n>1/\delta^{*}\,\,\,\text{and}\,\,\,n>4/\varepsilon\,.\] (50)

Note that because the range of \(f^{-1}\) is \([0,1]\), the left side of (48) is at most \(1\). Therefore, from (48) and the fact that \(\delta^{*}>1/n\) by (50):

\[1\geq x+\delta^{*}>x+1/n\qquad\forall x\in S_{\varepsilon}\] (51)

Consider an arbitrary \(x,y\in[0,1]\) with \(x\leq y\leq x+1/n\). We consider two cases:

* Case \(x\in S_{\varepsilon}\): Since \(f\) is strictly increasing and \(x+\delta^{*}\leq 1\) by (51), we have: \[f(y)\leq f(x+1/n)<f(x+\delta^{*})\] (52) Subtracting \(f(x)\) from both sides of (52) and applying (49), we obtain \[f(y)-f(x)<\varepsilon/4\] (53)* Case \(x\not\in S_{\varepsilon}\): Then \(f(x)>1-\varepsilon/4\). Since \(f(y)\leq 1\), we have: \[f(y)-f(x)<1-(1-\varepsilon/4)=\varepsilon/4\,.\] (54)

Combining cases \(x\in S_{\varepsilon}\) and \(x\not\in S_{\varepsilon}\) gives \(f(y)-f(x)<\varepsilon/4\;\forall x,y\in[0,1]\) with \(x\leq y\leq x+1/n\,.\) Since \(f\) is strictly increasing, we have \(f(x)\leq f(y)\) when \(x\leq y\), and so \[|f(x)-f(y)|<\varepsilon/4\qquad\forall x,y\in[0,1]\text{ with }|x-y|\leq 1/n\,.\] (55)

By Lemma 4, there exists a function \(V_{n}\in\mathcal{V}_{n}\) such that:

\[|f(x)-V_{n}(x)|\leq\varepsilon/4+2/n\qquad\forall x\in[0,1]\,.\] (56)

Since \(n>4/\varepsilon\) by (50), inequality (56) gives

\[|f(x)-V_{n}(x)|\leq\varepsilon/4+2/n<\varepsilon/4+\varepsilon/2<\varepsilon \qquad\forall x\in[0,1]\,.\] (57)

This completes the proof.

**Lemma 6**.: _Suppose \(v_{B}\) is a value density function for Bob with \(v_{B}(x)\leq\Delta\) for some \(\Delta>0\) and all \(x\in[0,1]\). Then for all \(n\in\mathbb{N}^{*}\), there exists a function \(V_{n}\in\mathcal{V}_{n}\) such that_

\[\Big{|}V_{n}(x)-V_{B}([0,x])\Big{|}\leq\frac{\Delta+2}{n}\qquad\forall x\in[0, 1]\,.\]

Proof.: Let \(n\in\mathbb{N}^{*}\). Since Bob's density is upper bounded by \(\Delta\), we have

\[|V_{B}([0,x])-V_{B}([0,y])|\leq\Delta|x-y|\qquad\forall x,y\in[0,1]\,.\] (58)

When \(|x-y|\leq 1/n\), we get \(|V_{B}([0,x])-V_{B}([0,y])|\leq\Delta|x-y|\leq D/n\).

By Lemma 4 applied to the function \(f:[0,1]\to[0,1]\) given by \(f(x)=V_{B}([0,x])\), there exists \(V_{n}\in\mathcal{V}_{n}\) with \(|V_{n}(x)-V_{B}([0,x])|\leq\Delta/n+2/n\) for all \(x\in[0,1]\,.\) This completes the proof. 

The set of functions \(\mathcal{V}_{n}\) will be used to construct a strategy for Alice. Next we bound the size of \(\mathcal{V}_{n}\) as a function of \(n\), as this rate of growth will influence the error bounds on the players' utilities.

**Lemma 7**.: \(|\mathcal{V}_{n}|\leq 4^{n-1}\;\;\forall n\in\mathbb{N}^{*}\)_._

Proof.: We first estimate the size of each set \(\mathcal{W}_{n}\), and then will infer the bound for the size of \(\mathcal{V}_{n}\). Consider the density function corresponding to any particular \(V\in\mathcal{W}_{n}\). Because \(V\) is piecewise linear, its density is piecewise constant. Each \(V\) is then uniquely determined by a sequence \(d_{1},d_{2},\ldots,d_{n}\), where \(d_{i}\) is the value density between \(\frac{i-1}{n}\) and \(\frac{i}{n}\). Each \(d_{i}\) must be a non-negative integer, because each of these intervals has width \(1/n\) and sees \(V\) rise by an integer multiple of \(1/n\). More strongly, because \(V(0)=0\) and \(V(1)=1\), we must have the next relation between the \(d_{i}\)'s:

\[\sum_{i=1}^{n}\frac{d_{i}}{n}=1\iff\sum_{i=1}^{n}d_{i}=n\,.\] (59)

Thus, the size \(|\mathcal{W}_{n}|\) is the number of possible partitions of \(n\) into \(n\) parts with nonnegative integer sizes. The size of \(\mathcal{W}_{n}\) can then be counted by a standard combinatorics technique. Represent each choice of \(d_{1},d_{2},\ldots,d_{n}\) with a sequence of \(n\) "stars" and \(n-1\) "bars": \(d_{1}\) stars, then a bar, then \(d_{2}\) stars, then another bar, and so on. Each choice of \(d_{1},\ldots,d_{n}\) corresponds to a unique arrangement of stars and bars. The opposite is also true: given an arrangement, the number of stars between each pair of bars can be read off as \(d_{1},\ldots,d_{n}\). The size of \(\mathcal{V}_{n}\) is then the number of arrangements, which is \(\binom{2n-1}{n}\).

The upper bound can then be shown by induction. As a base case, \(\binom{2\cdot 1-1}{1}=\binom{1}{1}=1\leq 4^{1-1}\).

Now assume \(\binom{2n-1}{n}\leq 4^{n-1}\) for an arbitrary \(n\geq 1\). We have

\[\binom{2(n+1)-1}{n+1} =\frac{(2n+1)!}{(n+1)!\cdot n!}=\frac{(2n-1)!\cdot 2n\cdot(2n+1)}{n! \cdot(n-1)!\cdot n(n+1)}=\binom{2n-1}{n}\cdot\frac{2n(2n+1)}{n(n+1)}\] \[\leq 4^{n-1}\cdot 4\frac{n+\frac{1}{2}}{n+1}\] (By the inductive hypothesis) \[\leq 4^{n-1}\cdot 4=4^{(n+1)-1}\]

So by induction, the bound holds for all \(n\geq 1\).

Because \(\mathcal{V}_{n}=\mathcal{W}_{n}\) for all \(n\neq 2\), the only case left to verify is \(n=2\). By calculation, \(|\mathcal{W}_{2}|=\binom{3}{2}=3\), so including the extra function makes \(|\mathcal{V}_{2}|=4=4^{2-1}\). 

Some other technical lemmas are necessary. The first two relate to the following function, which acts like an infinite-dimensional inner product.

**Definition 8**.: _Let \(\mathcal{X}\) be the collection of all functions \(X:\overline{\mathcal{V}}\to[-1,1]\). For each pair of functions \(X,Y:\overline{\mathcal{V}}\to[-1,1]\,,\) define \(P:\mathcal{X}\times\mathcal{X}\to\mathsf{R}\) as follows:_

\[P(X,Y)=\sum_{n=1}^{\infty}\frac{1}{2^{n}\,|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}X(n,V)Y(n,V)\,.\]

**Lemma 8**.: _The function \(P\) has the properties of an inner product. In particular, for all functions \(X,Y,Z:\overline{\mathcal{V}}\to[-1,1]\) and all constants \(c\in[-1,1]\), the following holds:_

1. \(P(X,Y)\) _exists, and the infinite sum converges absolutely_
2. \(P(X,Y)=P(Y,X)\)__
3. \(|P(X,Y)|\leq 1\)__
4. \(P(cX,Y)=cP(X,Y)\)__
5. \(P(X+Z,Y)=P(X,Y)+P(Z,Y)\)_, assuming_ \(X+Z\) _is in the domain of_ \(P\)__
6. \(P(X,X)=0\) _if_ \(X(n,V)=0\) _for all_ \(n\) _and all_ \(V\)_, and_ \(P(X,X)>0\) _otherwise_

Proof.: We separately prove each of the properties.

For the first property, note that the individual terms go to zero

\[\lim_{n\to\infty}\left|\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}X(n,V)Y(n,V)\right| \leq\lim_{n\to\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}|X(n,V)Y(n,V)|\] \[\leq\lim_{n\to\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}1\quad\text{ (By the bounds on $X$ and $Y$)}\] \[=\lim_{n\to\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}|\mathcal{V}_{n} |=\lim_{n\to\infty}\frac{1}{2^{n}}\] \[=0\,.\]

Using the above upper bound for individual terms, the sum of the absolute values does not diverge as follows

\[\sum_{n=1}^{\infty}\left|\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}X(n,V)Y(n,V)\right|\leq\sum_{n=1}^{\infty}\frac{1}{2^{n}}=1\,.\]

So \(P(X,Y)\) exists and the infinite sum converges absolutely.

The existence is enough for property (2), which follows directly from the product \(X(n,V)Y(n,V)\) being commutative. This calculation directly verifies property (3).

The absolute convergence allows for the linear operations in properties (4) and (5) to factor through the sum.

First, for property (4) we obtain

\[P(cX,Y) =\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}cX(n,V)Y(n,V)\] \[=c\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}X(n,V)Y(n,V)\] \[=cP(A,B)\,.\]

For property (5) observe that:

\[P(X+Z,Y) =\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}(X(n,V)+Z(n,V))Y(n,V)\] \[=\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}X(n,V)Y(n,V)+Z(n,V)Y(n,V)\] \[=\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}X(n,V)Y(n,V)+\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n }|}\sum_{V\in\mathcal{V}_{n}}Z(n,V)Y(n,V)\] \[=P(X,Y)+P(Z,Y)\,.\]

For property (6), observe that the expression can be rewritten as:

\[P(X,X)=\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in\mathcal{V }_{n}}X(n,V)^{2}\,.\]

This is a sum of squares, which will be zero if all the included \(X(n,V)\) are zero and positive otherwise. 

**Lemma 9**.: _For each \(x\in[0,1]\), let \(G_{x}:\overline{\mathcal{V}}\to[-1/2,-1/2]\) be given by \(G_{x}(n,V)=V(x)-\frac{1}{2}\). Then, for all \(Z:\overline{\mathcal{V}}\to[-1,1]\), the following function is continuous in \(x\):_

\[P(G_{x},Z)=\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}\left(V(x)-\frac{1}{2}\right)Z(n,V).\]

Proof.: Alice's valuation function in \(\mathcal{V}_{2}\) needs to be handled separately. Accordingly, write:

\[P(G_{x},Z) =\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in V _{n}}\left(V(x)-\frac{1}{2}\right)Z(n,V)\] \[=\frac{1}{2^{2}|\mathcal{V}_{2}|}\left(V_{A}([0,x])-\frac{1}{2} \right)Z(n,V_{A})+\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V \in\mathcal{V}_{n}}\left(V(x)-\frac{1}{2}\right)Z(n,V)\,.\]

As long as each of these two parts is continuous, the sum will be too. The first part is continuous because \(V_{A}([0,x])\) is continuous. To prove the second part, for notational simplicity, define

\[P^{\prime}(G_{x},Z)=\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V \in\mathcal{W}_{n}}\left(V(x)-\frac{1}{2}\right)Z(n,V)\]

The continuity of \(P^{\prime}\) will be shown by directly appealing to the definition of a limit. First, note that each \(V\in\mathcal{W}_{n}\) is made of \(n\) linear segments, each of width \(\frac{1}{n}\) and height at most \(1\). Therefore, if \(V\in\mathcal{W}_{n}\), for all \(x,y\in[0,1]\):

\[|V(y)-V(x)|\leq|y-x|n\] (60)Fix an arbitrary \(\varepsilon>0\) and \(x\in[0,1]\). Choose \(\delta=\varepsilon/2\). For any \(y\) such that \(|y-x|<\delta\):

\[|P^{\prime}(G_{y},Z)-P^{\prime}(G_{x},Z)| =|P^{\prime}(G_{y}-G_{x},Z)|\] (By property (5)) \[=\left|\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V \in\mathcal{W}_{n}}(V(y)-V(x))Z(n,V)\right|\] \[\leq\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V \in\mathcal{W}_{n}}|V(y)-V(x)|\cdot|Z(n,V)|\] (Triangle inequality) \[\leq\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V \in\mathcal{W}_{n}}n|y-x|\cdot 1\] (By ineq ( 60 ) and \[Z\leq 1\] ) \[\leq|y-x|\sum_{n=1}^{\infty}\frac{n}{2^{n}}\] (Since \[|\mathcal{W}_{n}|\leq|\mathcal{V}_{n}|\] ) \[=|y-x|\cdot 2\] \[<2\delta\] (By choice of \[\delta\] ) \[=\varepsilon\,.\]

Therefore, for all \(x\in[0,1]\):

\[\lim_{y\to x}P^{\prime}(G_{y},Z)=P^{\prime}(G_{x},Z),\]

which is the definition of \(P^{\prime}(G_{x},Z)\) being continuous in \(x\). This concludes that \(P(G_{x},Z)\) is continuous in \(x\). 

Finally, the last one is a strengthening of Lemma 1 from Blackwell (1956), under stronger hypotheses.

**Lemma 10**.: _Suppose a sequence of nonnegative values \(\delta_{1},\delta_{2},\dots\) satisfies, for all \(t\geq 1\):_

\[\delta_{t+1}\leq\frac{1}{(t+1)^{2}}+\left(\frac{t-1}{t+1}\right)\delta_{t}\,.\]

_Then \(\lim_{t\to\infty}\delta_{t}=0\). In particular, for all \(t\geq 2\):_

\[\delta_{t}\leq\frac{1}{t(t-1)}\sum_{i=2}^{t}\frac{i-1}{i}\leq\frac{1}{t}\,.\]

Proof.: The latter bound will be shown by induction. As a base case, consider \(t=2\). The condition for \(t=1\) gives:

\[\delta_{2}\leq\frac{1}{(1+1)^{2}}+\left(\frac{1-1}{1+1}\right)\delta_{1}= \frac{1}{4}=\frac{1}{2(2-1)}\sum_{i=2}^{2}\frac{i-1}{i}\,.\] (61)

So the base case holds. Now suppose the conclusion holds for some \(t\geq 2\). Assume that the claim holds for \(\delta_{t}\). We can expand the upper bound of \(\delta_{t+1}\) as follows.

\[\delta_{t+1} \leq\frac{1}{(t+1)^{2}}+\left(\frac{t-1}{t+1}\right)\delta_{t}\] (62) \[\leq\frac{1}{(t+1)^{2}}+\left(\frac{t-1}{t+1}\right)\frac{1}{t(t- 1)}\sum_{i=2}^{t}\frac{i-1}{i}\] (By the induction hypothesis) \[=\frac{1}{(t+1)^{2}}+\frac{1}{t(t+1)}\sum_{i=2}^{t}\frac{i-1}{i}\] (63) \[=\frac{1}{(t+1)t}\sum_{i=2}^{t+1}\frac{i-1}{i}\,.\] (64)Now it suffices to show that the last term in (64) is upper bounded by \(1/t\), which follows from the following inequality:

\[\frac{1}{t(t-1)}\sum_{i=2}^{t}\frac{i-1}{i}\leq\frac{1}{t(t-1)}\sum_{i=2}^{t}1= \frac{1}{t(t-1)}\cdot(t-1)=\frac{1}{t}\,.\] (65)

Thus \(\delta_{t+1}\leq 1/t\), which completes the proof. 

Now the groundwork is laid to prove Theorem 2. The idea is to limit every strategy and every valuation in every \(\mathcal{V}_{n}\) to an average payoff of \(1/2\), which is sufficient to limit Bob equipped with arbitrary valuation as well.

Proof of Theorem 2.: We first define the Alice's strategy in an analytical manner, and then prove that it is well-defined. Then we will show that this strategy will force Bob's payoff to be at most \(1/2\) on average, by showing both that Bob's valuation can be well-approximated by functions in \(\overline{\mathcal{V}}\) and that such valuation functions are limited to a payoff of \(1/2\) on average. Finally, we establish explicit convergence rates for Bob's payoff if his valuation is bounded, as well as the convergence of Alice's payoff to \(1/2\).

Defining Alice's strategy \(S_{A}\)Consider Alice's decision in round \(T\). In each round \(t<T\), let the payoff to Bob whose cumulative valuation function is \(V\) be \(u_{t,V}\). For each \(x\in[0,1]\), let \(G_{x}:\overline{\mathcal{V}}\to[-1,1]\) be a function defined as \(G_{x}(n,V)=V(x)-1/2\). Let \(U_{t}(n,V)=u_{t,V}-1/2\) for \(t=1,\dots,T-1\), and let \(\overline{U}_{t}(n,V)=\sum_{i=1}^{t}U_{i}(n,V)/t\). Let \(W_{i}(n,V)=\max\{0,\overline{U}_{t}(n,V)\}\) for \(t=1,\dots,T-1\). In round \(T\), Alice's strategy \(S_{A}\) is to cut at a point \(x\) such that \(P(G_{x},W_{T-1})=0\).

We then show that \(S_{A}\) is well-defined. It suffices to prove that such an \(x\) always exists. To this end, observe that

\[P(G_{0},W_{T-1}) =\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}\left(V(0)-\frac{1}{2}\right)W_{T-1}(n,V)\] \[=\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}-\frac{1}{2}W_{T-1}(n,V)\] \[\leq\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V \in\mathcal{V}_{n}}0\qquad\qquad\qquad\text{(Since $W_{T-1}(\cdot)$ is nonnegative)}\] \[=0\,.\]

Using similar algebra for \(P(G_{1},W_{T-1})\), we obtain

\[P(G_{1},W_{T-1}) =\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}\left(V(1)-\frac{1}{2}\right)W_{T-1}(n,V)\] \[=\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}\frac{1}{2}W_{T-1}(n,V)\] \[\geq\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}0\qquad\qquad\qquad\text{(Since $W_{T-1}(\cdot)$ is nonnegative)}\] \[=0\]

By Lemma 9, \(P(G_{x},W_{T-1})\) is continuous in \(x\), so by the Intermediate Value Theorem there exists \(x\) such that \(P(G_{x},W_{T-1})=0\).

Bounding Bob's payoffDefine

\[\mathcal{S}=\left\{X:-\frac{1}{2}\leq X(n,V)\leq 0\text{ for all }(n,V)\in\overline{\mathcal{V}}\right\}.\]For each round \(t\), let \(\delta_{t}\) be the distance from \(\mathcal{S}\) to \(\overline{U}_{t}\), defined as:

\[\delta_{t}=\inf_{X\in\mathcal{S}}P(\overline{U}_{t}-X,\overline{U}_{t}-X).\] (66)

For \(t<T\), let \(Y_{t}:\overline{\mathcal{V}}\to[-1/2,1/2]\) be the function defined by:

\[Y_{t}(n,V)=\min\{0,\overline{U}_{t}(n,V)\}\]

By Claim 3, we have \(\delta_{t}\leq 1/t\) for all \(t\geq 2\).

Now we will show that this strategy guarantees that, for any Bob's valuation function \(v_{B}\) and any strategy \(S_{B}\) Bob employs, his average payoff is at most \(1/2\). Consider an arbitrary \(\varepsilon>0\). It will be shown that, for some sufficiently large \(T\), Bob's average payoff up to any point after round \(T\) is at most \(1/2+\varepsilon\).

In the general case, this convergence can be established from Lemma 5. Consider \(N,T\in\mathbb{N}^{*}\) such that

* \(N\) is such that there exists \(V^{\prime}\in\mathcal{V}_{N}\) with \(|V^{\prime}(x)-V_{B}([0,x])|<\varepsilon/2\) for all \(x\in[0,1]\).
* \(T\) is sufficiently large so that \[\delta_{t}<\frac{\varepsilon^{2}}{4\cdot 2^{N}|\mathcal{V}_{N}|}\qquad \forall t\geq T\,.\] (67) For example, taking \(T=\left\lceil\frac{4\cdot 2^{N}|\mathcal{V}_{N}|}{\varepsilon^{2}}\right\rceil\) would suffice.

We will show that for each \(t\geq T\), we have \(\overline{U}_{t}(N,V^{\prime})<\varepsilon/2\). This trivially holds if \(\overline{U}_{t}(N,V^{\prime})\leq 0\), so assume \(\overline{U}_{t}(N,V^{\prime})>0\). We then obtain

\[\overline{U}_{t}(N,V^{\prime}) =\sqrt{2^{N}|\mathcal{V}_{N}|\cdot\frac{1}{2^{N}|\mathcal{V}_{N}| }\overline{U}_{t}(N,V^{\prime})^{2}}\] \[=\sqrt{2^{N}|\mathcal{V}_{N}|\cdot\frac{1}{2^{N}|\mathcal{V}_{N}| }\left(\overline{U}_{t}(N,V^{\prime})-Y_{t}(N,V^{\prime})\right)^{2}},\] (68)

where (68) follows from the fact that \(Y_{t}(N,V^{\prime})=\min\{0,\overline{U}_{t}(N,V^{\prime})\}=0\). Using (68), we can upper bound \(\overline{U}_{t}(N,V^{\prime})\) as follows:

\[\overline{U}_{t}(N,V^{\prime}) \leq\sqrt{2^{N}|\mathcal{V}_{N}|\sum_{n=1}^{\infty}\frac{1}{2^{n} |\mathcal{V}_{n}|}\sum_{V\in\mathcal{V}_{n}}\left(\overline{U}_{t}(n,V)-Y_{t} (n,V)\right)^{2}}\] \[=\sqrt{2^{N}|\mathcal{V}_{N}|P(\overline{U}_{t}-Y_{t},\overline{U }_{t}-Y_{t})}\] \[=\sqrt{2^{N}|\mathcal{V}_{N}|\delta_{t}}\] (69) \[<\sqrt{2^{N}|\mathcal{V}_{N}|\cdot\frac{\varepsilon^{2}}{4\cdot 2 ^{N}|\mathcal{V}_{N}|}}=\frac{\varepsilon}{2}\,.\] (By ( 67 ) )

Therefore, we have \(\overline{U}_{t}(N,V^{\prime})<\varepsilon/2\) for all \(t\geq T\). Translating back into payoffs, this gives a Bob whose cumulative valuation function is \(V^{\prime}\) an average payoff of less than \(1/2+\varepsilon/2\). By the choice of \(V^{\prime}\), we have

\[|V^{\prime}(x)-V_{B}([0,x])|<\varepsilon/2\qquad\text{for all }x\in[0,1]\,.\] (70)

so the average payoff to a Bob whose valuation function is \(v_{B}\) is less than \(1/2+\varepsilon\). Since this construction works for all \(\varepsilon>0\), Bob's average payoff satisfies the following inequality as required:

\[\frac{u_{B}(1,t)}{t}\leq\frac{1}{2}+o(1)\,.\]Explicit boundsIt remains to prove inequality (32) when Bob's density is upper bounded by \(\Delta\), and prove Alice's explicit payoff in inequality (33). Choose an integer \(N\) large enough that

\[\frac{\Delta+2}{N}<\frac{\varepsilon}{2}\,.\]

For instance, taking \(N=\lceil 2(\Delta+2)/\varepsilon\rceil\) is sufficient. By Lemma 6, there exists \(V^{\prime}\in\mathcal{V}_{N}\) such that

\[|V^{\prime}(x)-V_{B}([0,x])|<(\Delta+2)/N\ \ \text{for all }x\in[0,1]\,.\]

Choose \(T\) in exactly the same way as the general case, i.e. \(T=\lceil 4\cdot 2^{N}|\mathcal{V}_{N}|/\varepsilon^{2}\rceil\). By exactly the same algebra as the general case, we can conclude that \(\overline{U}_{t}(N,V^{\prime})<\varepsilon/2\) for all \(t\geq T\). By the choice of \(V^{\prime}\), we have

\[|V^{\prime}(x)-V_{B}([0,x])|<\varepsilon/2\qquad\text{for all }x\in[0,1]\,,\] (71)

so the average payoff to Bob is at most \(\frac{1}{2}+\varepsilon\).

In this case, Bob's average payoff will be within \(\varepsilon\) of \(1/2\) by time

\[T_{\varepsilon}=\left\lceil\frac{4\cdot 2^{N}|\mathcal{V}_{N}|}{ \varepsilon^{2}}\right\rceil\,,\qquad\text{where}\quad N=\lceil 2(\Delta+2)/ \varepsilon\rceil\,.\] (72)

Hence, for such \(T_{\varepsilon}\), we have

\[T_{\varepsilon}\leq\left\lceil\frac{4\cdot 2^{N}\cdot 4^{N-1}}{ \varepsilon^{2}}\right\rceil.\]

Since \(\lceil x\rceil\leq 2x\) for \(x\geq 1/2\), this implies

\[T_{\varepsilon}\leq 2\frac{8^{N}}{\varepsilon^{2}}.\]

Due to our choice of \(N\), we can further obtain

\[T_{\varepsilon}\leq 2\cdot\frac{8^{\frac{2(\Delta+2)}{ \varepsilon}+1}+1}{\varepsilon^{2}}.\] (73)

Taking the natural logarithm of both sides in (73), we have

\[\ln(T_{\varepsilon})\leq\ln(16)+\frac{2(\Delta+2)}{\varepsilon} \ln(8)+2\ln\left(\frac{1}{\varepsilon}\right).\]

Using the fact that \(\ln(x)\leq x-1\) for every \(x>0\), it follows that

\[\ln(T_{\varepsilon})\leq\ln(16)+\frac{2(\Delta+2)}{\varepsilon} \ln(8)+2\left(\frac{1}{\varepsilon}-1\right).\] (74)

Rearranging (74), we finally obtain

\[\varepsilon\leq\frac{2\ln(8)(\Delta+2)+2}{\ln(T_{\varepsilon})- \ln(16)+2}.\]

Note that this requires the step of dividing by \(\ln(T_{\varepsilon})-\ln(16)+2\) and it needs this quantity to be positive, which is indeed positive for \(T\geq 3\). Rounding the terms gives the desired regret bound for Bob.

To provide Alice's payoff bound in inequality (33), consider a hypothetical Bob whose valuation function \(\tilde{v}_{B}\) is exactly the same as Alice's valuation function \(v_{A}\). For all rounds \(\tau\), the payoff \(\tilde{u}_{B}^{\tau}\) to this Bob then satisfies:

\[u_{A}^{\tau}+\tilde{u}_{B}^{\tau} =V_{A}([0,a_{\tau}])+V_{A}([a_{\tau},1])\] (75) \[\text{(One player gets }V_{A}([0,a_{\tau}])\text{ and the other gets }V_{A}([a_{\tau},1]))\] \[=1\]

For any \(t\), summing \(u_{A}^{\tau}+\tilde{u}_{B}^{\tau}\) over \(\tau\in[t]\) and dividing by \(t\) then gives:

\[\frac{u_{A}(1,t)}{t}+\frac{\tilde{u}_{B}(1,t)}{t}=1\] (76)So it suffices to upper-bound this particular Bob's payoff to lower-bound Alice's payoff.

Choose an arbitrary \(\varepsilon>0\). Let \(T_{\varepsilon}=\left\lceil\frac{2^{2}|\mathcal{V}_{2}|}{\varepsilon^{2}}\right\rceil\), ensuring \(\delta_{t}<\frac{\varepsilon^{2}}{2^{2}|\mathcal{V}_{2}|}\) for all \(t\geq T_{\varepsilon}\). By construction, Alice's valuation function \(V_{A}([0,x])\in\mathcal{V}_{2}\). Taking \(N=2\) and \(V^{\prime}=V_{A}\), we can then use identical algebra as the general-Bob case up to (69) to conclude that, for \(t\geq T_{\varepsilon}\):

\[\overline{U}_{t}(2,V_{A}) \leq\sqrt{2^{2}|\mathcal{V}_{2}|\delta_{t}}\] (Copying over ( 69 )) \[<\sqrt{2^{2}|\mathcal{V}_{2}|\cdot\frac{\varepsilon^{2}}{2^{2}| \mathcal{V}_{2}|}}=\varepsilon\] (77)

So this Bob's payoff is upper-bounded by \(1/2+\varepsilon\), and so by (76) Alice's payoff is lower-bounded by \(1/2-\varepsilon\). To solve for \(\varepsilon\), observe that \(T_{\varepsilon}\leq 16/\varepsilon^{2}+1\). Solving this bound on \(T_{\varepsilon}\) for \(\varepsilon\) gives

\[\varepsilon\leq\frac{4}{\sqrt{T_{\varepsilon}-1}}\,,\]

and it finishes the proof. 

We finally provide the claims and their proofs used throughout the main proof.

**Claim 1**.: _In the setting of Theorem 2, if \(\overline{U}_{t}\notin\mathcal{S}\), then \(\operatorname*{argmin}_{X\in\mathcal{S}}P(\overline{U}_{t}-X,\overline{U}_{t}-X)\) exists. Furthermore:_

\[\operatorname*{argmin}_{X\in\mathcal{S}}P(\overline{U}_{t}-X,\overline{U}_{t}- X)=Y_{t}=\min\{0,\overline{U}_{t}(n,V)\}\]

Proof of the claim.: Let \(Y_{t}=\min\{0,\overline{U}_{t}(n,V)\}\in\mathcal{S}\). For any \(X\in\mathcal{S}\),

\[P(\overline{U}_{t}-X,\overline{U}_{t}-X) =\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in V _{n}}\left(\overline{U}_{t}(n,V)-X(n,V)\right)^{2}\] \[=\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\left(\sum_{ \begin{subarray}{c}V\in V_{n}\\ \overline{U}_{t}(n,V)>0\end{subarray}}\left(\overline{U}_{t}(n,V)-X(n,V) \right)^{2}+\sum_{\begin{subarray}{c}V\in V_{n}\\ \overline{U}_{t}(n,V)\leq 0\end{subarray}}\left(\overline{U}_{t}(n,V)-X(n,V) \right)^{2}\right)\] (78)

Since \(X\in\mathcal{S}\), we have that \(X(n,V)\leq 0\) for every \(n\) and \(V\), due to our construction of \(\mathsf{S}\).

Therefore, replacing them with \(0\) brings them closer to any positive value and so decreases the first sum of squares. The second sum of squares is nonnegative, so it can be reduced by replacing it with \(0\). Applying these simplifications, we obtain

\[\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\left(\sum_{ \begin{subarray}{c}V\in V_{n}\\ \overline{U}_{t}(n,V)>0\end{subarray}}\left(\overline{U}_{t}(n,V)-X(n,V) \right)^{2}+\sum_{\begin{subarray}{c}V\in V_{n}\\ \overline{U}_{t}(n,V)\leq 0\end{subarray}}\left(\overline{U}_{t}(n,V)-X(n,V) \right)^{2}\right)\] \[\geq \sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\left(\sum_{ \begin{subarray}{c}V\in V_{n}\\ \overline{U}_{t}(n,V)>0\end{subarray}}\left(\overline{U}_{t}(n,V)-0\right)^{2 }+0\right)\] \[= D(\overline{U}_{t}-Y_{t},\overline{U}_{t}-Y_{t}),\] (Only the

\[\overline{U}(n,V)>0\]

terms remain)

and it proves the claim. 

**Claim 2**.: _In the setting of Theorem 2, the following properties hold when \(\overline{U}_{t}\notin\mathcal{S}\)._

1. \(P(Y_{t},W_{t})=0\)__
2. \(P(U_{t+1},W_{t})=0\)__3. \(P(\overline{U}_{t},W_{t})>0\)__
4. \(P(X,W_{t})\leq 0\) _for all_ \(X\in\mathcal{S}\)__

Proof of the claim.: All of these properties can be explained by expanding the dot product \(P\) and referring to the strategy \(S_{A}\). The first one is the most straightforward: \(Y_{t}\) and \(W_{t}\) are never nonzero in the same coordinate, so \(P(Y_{t},W_{t})=0\). For the second one, by definition, in round \(t+1\) Alice cuts at a point \(x\) such that \(P(G_{x},W_{t})=0\). If Bob selects the left piece, \(U_{t+1}=G_{x}\). If Bob instead selects the right piece:

\[U_{t+1}(n,V) =(1-V(x))-\frac{1}{2}\] \[=\frac{1}{2}-V(x)\] \[=-G_{x}(n,V)\,.\]

So by property 4 of Lemma 8, we have \(P(U_{t+1},W_{t})=-P(G_{x},W_{t})=0\). Because \(P\) is linear as per property 5 in Lemma 8, any mixed strategy over these outcomes must also satisfy \(P(U_{t+1},W_{t})=0\).

For part (3) of the lemma, expanding the dot product gives:

\[P(X,W_{t}) =\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n}}X(n,V)\cdot\max\{0,\overline{U}_{t}(n,V)\}\] \[=\sum_{n=1}^{\infty}\frac{1}{2^{n}|\mathcal{V}_{n}|}\sum_{V\in \mathcal{V}_{n},\overline{U}_{t}(n,V)>0}X(n,V)\overline{U}_{t}(n,V)\,.\]

As there exists \((n,V)\) such that \(\overline{U}_{t}(n,V)>0\), this sum is strictly positive when \(X=\overline{U}_{t}(n,V)\), and so \(P(\overline{U}_{t},W_{t})>0\). Similarly, for \(X\in\mathcal{S}\), we have \(X(n,V)\leq 0\) for all \((n,V)\), so \(P(X,W_{t})\leq 0\). 

**Claim 3**.: _In the setting of Theorem 2, the sequence \(\{\delta_{t}\}_{t=1}^{\infty}\) defined in (66) satisfies the inequality \(\delta_{t}\leq 1/t\) for all \(t\geq 2\)._

Proof.: We will show that our construction of \(\delta_{t}\) satisfies the recursion formula defined in Lemma 10. We first focus on the case such that \(\delta_{t}>0\), which is equivalent to \(\overline{U}_{t}\notin\mathcal{S}\), and then prove that it also holds for \(\delta_{t}=0\). Given that \(\delta_{t}>0\), we observe that

\[\delta_{t+1}=\inf_{X\in\mathcal{S}}P(\overline{U}_{t+1}-X,\overline{U}_{t+1}- X)\leq P(\overline{U}_{t+1}-Y_{t},\overline{U}_{t+1}-Y_{t})\,.\] (79)

By rewriting the right hand side of (79), we obtain

\[\delta_{t+1}\leq P((\overline{U}_{t+1}-\overline{U}_{t})+(\overline{U}_{t}-Y_ {t}),(\overline{U}_{t+1}-\overline{U}_{t})+(\overline{U}_{t}-Y_{t}))\] (80)

Distributing over \(P\) in the expression on the right hand side of (80), we get that (80) is equivalent to

\[\delta_{t+1} \leq P(\overline{U}_{t+1}-\overline{U}_{t},\overline{U}_{t+1}- \overline{U}_{t})+2P(\overline{U}_{t+1}-\overline{U}_{t},\overline{U}_{t}-Y_ {t})+P(\overline{U}_{t}-Y_{t},\overline{U}_{t}-Y_{t})\] \[=P(\overline{U}_{t+1}-\overline{U}_{t},\overline{U}_{t+1}- \overline{U}_{t})+2P(\overline{U}_{t+1}-\overline{U}_{t},\overline{U}_{t}-Y_ {t})+\delta_{t},\] (81)

where the inequality follows from Claim 1.

Noting that \(\overline{U}_{t+1}-\overline{U}_{t}=(U_{t+1}-\overline{U}_{t})/(t+1)\), we have

\[P(\overline{U}_{t+1}-\overline{U}_{t},\overline{U}_{t}-Y_{t}) =\frac{1}{t+1}P(U_{t+1}-\overline{U}_{t},\overline{U}_{t}-Y_{t})\] \[=\frac{1}{t+1}P((U_{t+1}-Y_{t})+(Y_{t}-\overline{U}_{t}), \overline{U}_{t}-Y_{t})\] \[=\frac{1}{t+1}\left(P(U_{t+1}-Y_{t},\overline{U}_{t}-Y_{t})+P(Y_{ t}-\overline{U}_{t},\overline{U}_{t}-Y_{t})\right).\]By using \(\overline{U}_{t}=W_{t}+Y_{t}\), we can expand it by

\[P(\overline{U}_{t+1}-\overline{U}_{t},\overline{U}_{t}-Y_{t}) =\frac{1}{t+1}\left(P(U_{t+1},W_{t})-P(Y_{t},W_{t})-P(Y_{t}- \overline{U}_{t},\overline{U}_{t}-Y_{t})\right).\] \[=\frac{1}{t+1}\left(P(U_{t+1},W_{t})-P(Y_{t},W_{t})-\delta_{t}\right) \text{(By Claim \ref{eq:P_t})}\] \[=\frac{1}{t+1}\left(0-0-\delta_{t}\right) \text{(By Claim \ref{eq:P_t})}\] \[=-\frac{1}{t+1}\cdot\delta_{t}.\] (82)

Further, observe that

\[P(\overline{U}_{t+1}-\overline{U}_{t},\overline{U}_{t+1}- \overline{U}_{t}) =\frac{1}{(t+1)^{2}}P(U_{t+1}-\overline{U}_{t},U_{t+1}-\overline {U}_{t})\] \[\leq\frac{1}{(t+1)^{2}},\] (83)

where the inequality follows from Property (3) in Lemma 8.

Putting (81), (82) and (83) together, we obtain the following inequality for \(\delta_{t}>0\):

\[\delta_{t+1} \leq P(\overline{U}_{t+1}-\overline{U}_{t},\overline{U}_{t+1}- \overline{U}_{t})+2P(\overline{U}_{t+1}-\overline{U}_{t},\overline{U}_{t}-Y_{ t})+\delta_{t}\] \[\leq\frac{1}{(t+1)^{2}}-\frac{2}{t+1}\delta_{t}+\delta_{t}\] \[=\frac{1}{(t+1)^{2}}+\left(1-\frac{2}{t+1}\right)\delta_{t}\,.\]

Now, we show that the same inequality holds for the case such that \(\delta_{t}=0\) too. Since \(\overline{U}_{t}\in\mathcal{S}\), we obtain

\[\delta_{t+1} =\inf_{X\in\mathcal{S}}P(\overline{U}_{t+1}-X,\overline{U}_{t+1}-X)\] \[\leq P(\overline{U}_{t+1}-\overline{U}_{t},\overline{U}_{t+1}- \overline{U}_{t})\] \[\leq\frac{1}{(t+1)^{2}}\] (By ( 83 )) \[=\frac{1}{(t+1)^{2}}+\left(1-\frac{2}{t+1}\right)\delta_{t}.\]

By Lemma 10, we therefore have that \(\delta_{t}\leq 1/t\) for \(t\geq 2\). 

### Appendix: Bob enforcing equitable payoffs

In this section, we prove Theorem 3, which shows how Bob can enforce equitable payoffs.

**Restatement of Theorem 3** (Bob enforcing equitable payoffs; formal).:
* In the sequential setting: _Bob has a pure strategy_ \(S_{B}\)_, such that for every Alice strategy_ \(S_{A}\)_, on every trajectory of play, Bob's average payoff is at least_ \(1/2-o(1)\)_, while Alice's average payoff is at most_ \(1/2+o(1)\)_. More precisely,_ \[\frac{u_{B}}{T}\geq\frac{1}{2}-\frac{1}{\sqrt{T}}\qquad\text{and}\qquad\frac{u _{B}}{T}\leq\frac{1}{2}+\left(\frac{\Delta}{2\delta}+2\right)\frac{1}{\sqrt{T }},\] _recalling that_ \(\delta\) _and_ \(\Delta\) _are, respectively, the lower and upper bounds on the players' value densities._
* In the simultaneous setting: _Bob has a mixed strategy_ \(S_{B}\)_, such that for every Alice strategy_ \(S_{A}\)_, both players have average payoff_ \(1/2\) _in expectation._Proof of Theorem 3.: Bob's strategy for the simultaneous setting follows from Proposition 6. His strategy for the sequential setting follows from Proposition 7. 

**Proposition 6**.: _In the simultaneous setting, Bob has a mixed strategy \(S_{B}\) such that, for every Alice strategy \(S_{A}\):_

\[\frac{\mathbb{E}[u_{A}]}{T}=\frac{\mathbb{E}[u_{B}]}{T}=\frac{1}{2}\,.\]

Proof.: Bob's strategy is very simple: in each round, randomly pick \(L\) or \(R\) with equal probability.

To analyze the expected payoffs, consider an arbitrary player \(i\in\{A,B\}\) and arbitrary round \(t\). Bob is equally likely to pick \(L\) or \(R\) in round \(t\), so each player is equally likely to receive \([0,a_{t}]\) or \([a_{t},1]\) in round \(t\). Therefore, their expected payoff is:

\[\mathbb{E}[u_{i}^{t}] =\frac{1}{2}V_{i}([0,a_{t}])+\frac{1}{2}V_{i}([a_{t},1])\] \[=\frac{1}{2}V_{i}([0,1])\] (Since valuations are additive) \[=\frac{1}{2}\,.\] (84)

Summing (84) over the \(T\) rounds gives the desired expected payoffs for each player. 

**Proposition 7**.: _Bob has a pure strategy \(S_{B}\), such that for every Alice strategy \(S_{A}\), the cumulative utilities in the sequential game are bounded by:_

\[u_{A}(S_{A},S_{B})\leq T/2+\left(\frac{\Delta}{2\delta}+2\right)\cdot\sqrt{T} \qquad\text{and}\qquad u_{B}(S_{A},S_{B})\geq T/2-\sqrt{T}\,.\]

Proof.: Bob devises his strategy \(S_{B}\) by considering a division of the cake into \(P=\lceil\sqrt{T}\rceil\) consecutive intervals \(I_{1},\ldots,I_{P}\) of equal value to him. That is, Bob chooses points \(0=z_{0}\leq z_{1}\ldots\leq z_{P}=1\) such that

\[I_{j}=\begin{cases}[z_{j-1},z_{j})&\text{if }1\leq j\leq P-1;\\ [z_{P-1},z_{P}]&\text{if }j=P;\end{cases}\qquad\text{and}\qquad V_{B}(I_{j})=1/P \ \ \forall j\in[P]\,.\] (85)

An illustration of the division into intervals used by Bob can be seen in Figure 17.

Bob's strategy \(S_{B}\) is defined as follows. Bob keeps a counter \(j\) associated with each interval \(I_{j}\), such that the value of the counter at time \(t\), denoted \(c_{j,t}\), represents how many times Alice has cut inside the interval \(I_{j}\) in the first \(t\) rounds (including round \(t\)). For each time \(t\in[T]\):

Figure 17: Example of a Bob density and the discretization used by Bob when \(T=10\). The number of intervals is \(P=\lceil\sqrt{T}\rceil=4\). The intervals are \(I_{j}=[z_{j-1},z_{j})\) for \(j\in[3]\) and \(I_{4}=[z_{3},z_{4}]\), with \(V_{B}(I_{j})=1/4\ \forall j\in[4]\).

* Let \(I_{j}\) be the interval that contains Alice's cut at time \(t\) (that is, \(a_{t}\in I_{j}\)), for \(j\in[P]\).
* If \(c_{j,t}\) is even then Bob plays L; if \(c_{j,t}\) is odd, then Bob plays R.

Informally, Bob alternates between L and R inside each interval \(I_{j}\). We argue that this Bob strategy ensures his payoff is at least \(1/2-o(1)\) per round, while Alice cannot get more than \(1/2+o(1)\) per round.

For each \(i\in[P]\) and \(j\in[c_{i,T}]\), let \(r_{i,j}\) be the first time when the number of cuts in \(I_{i}\) reached \(j\). That is,

\[r_{i,j}=\min\{t\in\mathbb{N}\mid c_{i,t}=j\text{ and }a_{t}\in I_{i}\}\,.\]

By definition of the sequence \(\{r_{i,\ell}\}\), for each \(i,j\in\mathbb{N}\) with \(2j\leq c_{i,T}\):

* Alice cut in the interval \(I_{i}\) in both rounds \(r_{i,2j-1}\) and \(r_{i,2j}\) (meaning \(a_{r_{i,2j-1}},a_{r_{i,2j}}\in I_{i}\));
* Bob played different actions in the rounds \(r_{i,2j-1}\) and \(r_{i,2j}\).

We view rounds \(r_{i,2j-1}\) and \(r_{i,2j}\) as a pair. For each \(i\in[P]\), there is at most one round \(r_{i,j}\) that does not have a pair, namely round \(r_{i,c_{i,T}}\): the last round Alice cut in \(I_{i}\). However, this loss only represents at most \(P\) rounds in total, which will translate to a sub-linear loss for either Alice's or Bob's utility estimates.

Now we can bound the cumulative utility of each player.

**Bob's payoff.**: For each \(i,j\in\mathbb{N}\) with \(2j\leq c_{i,T}\), Bob's payoff across the two rounds \(r_{i,2j-1}\) and \(r_{i,2j}\) is bounded by

\[u_{B}^{r_{i,2j-1}}+u_{B}^{r_{i,2j}}\geq 1-V_{B}(I_{i})=1-\frac{1}{P}\,.\] (86)

Since the rounds \(r_{i,j}\) with \(i\in[P]\) and \(2j\leq c_{i,T}\) represent a subset of the total set of rounds \([T]\), Bob's cumulative payoff is at least

\[\sum_{t=1}^{T}u_{B}^{t} \geq\sum_{i=1}^{P}\left(\sum_{j\in\mathbb{N}:2j\leq c_{i,T}}u_{B} ^{r_{i,2j-1}}+u_{B}^{r_{i,2j}}\right)\] \[\geq\sum_{i=1}^{P}\left(\sum_{j\in\mathbb{N}:2j\leq c_{i,T}} \left(1-\frac{1}{P}\right)\right)\] (By ( 86 )) \[\geq\left(1-\frac{1}{P}\right)\frac{T-P}{2}\qquad\text{(Since the sum is over at least $\frac{T-P}{2}$ pairs of rounds)}\]

Since \(P=\lceil\sqrt{T}\rceil\geq\sqrt{T}\), we get

\[u_{B}=\sum_{t=1}^{T}u_{B}^{t} \geq\left(1-\frac{1}{P}\right)\frac{T-P}{2}=\frac{T}{2}-\frac{ \lceil\sqrt{T}\rceil}{2}-\frac{T}{2\lceil\sqrt{T}\rceil}+\frac{1}{2}\] \[\geq\frac{T}{2}-\frac{\sqrt{T}+1}{2}-\frac{\sqrt{T}}{2}+\frac{1}{2}\] \[=\frac{T}{2}-\sqrt{T}\,.\] (87)

**Alice's payoff.**: For each \(i,j\in\mathbb{N}\) with \(2j\leq c_{i,T}\), Alice's payoff across rounds \(r_{i,2j-1}\) and \(r_{i,2j}\) is

\[u_{A}^{r_{i,2j-1}}+u_{A}^{r_{i,2j}}\leq 1+V_{A}(I_{i})\leq 1+\frac{\Delta}{ \delta}V_{B}(I_{i})=1+\frac{\Delta}{\delta}\cdot\frac{1}{P}\,.\] (88)There is at most one round without a pair for each interval \(I_{i}\), namely round \(r_{i,c_{i,T}}\): the last time Alice cut in \(I_{i}\). For each such round without a pair, we upper bound Alice's payoff by \(1\). Then we can upper bound Alice's cumulative utility by

\[\sum_{t=1}^{T}u_{A}^{t} \leq P+\sum_{i=1}^{P}\left(\sum_{j\in\mathbb{N}:2j\leq c_{i,T}}u_{A }^{r_{i,2j-1}}+u_{A}^{r_{i,2j}}\right)\] \[\leq P+\sum_{i=1}^{P}\left(\sum_{j\in\mathbb{N}:2j\leq c_{i,T}} \left(1+\frac{\Delta}{\delta}\cdot\frac{1}{P}\right)\right)\] (By ( **88** )) \[\leq P+\frac{T}{2}\left(1+\frac{\Delta}{P\delta}\right)\] (Since the sum is over at most \[T/2\] pairs) \[=\frac{T}{2}+\frac{T}{P}\cdot\frac{\Delta}{2\delta}+P\] \[\leq\frac{T}{2}+\sqrt{T}\left(\frac{\Delta}{2\delta}+2\right)\] ( \[P=\lceil\sqrt{T}\rceil\leq 2\sqrt{T}\] )

This completes the proof.

Appendix: Fictitious play

In this section, we analyze the fictitious play dynamics. We first formally define fictitious play in terms of the _empirical frequency_ and _empirical distribution_:

* The empirical frequency of Alice's play up to (but not including) time \(t\) is: \[\phi_{A}^{t}(x)=\sum_{\tau=1}^{t-1}\mathbbm{1}_{\{a_{\tau}=x\}}\ \ \forall x\in[0,1]\,.\]
* The empirical frequency of Bob's play up to (but not including) time \(t\) is: \[\phi_{B}^{t}(x)=\sum_{\tau=1}^{t-1}\mathbbm{1}_{\{b_{\tau}=x\}}\ \ \forall x\in\{L,R\}\,.\]
* The _empirical distribution_ of player \(i\)'s play up to (but not including) time \(t\) is: \[\mathfrak{p}_{i}^{t}(x)=\frac{\phi_{i}^{t}(x)}{(t-1)},\] Where \(x\in[0,1]\) for Alice and \(x\in\{L,R\}\) for Bob.

**Definition 9**.: _(Fictitious play) In round \(t=1\), each player simultaneously selects an arbitrary action. In every round \(t=2,\dots,T\), each player simultaneously best responds to the empirical distribution of the other player up to time \(t\). If there are multiple best responses, the player chooses one arbitrarily._

We now give the proof of Theorem 4 using lemmas that will be presented later, and then prove the required lemmas.

**Restatement of Theorem 4**.: _When both Alice and Bob run fictitious play, regardless of tie-breaking rules, their average payoff will converge to \(1/2\) at a rate of \(O(1/\sqrt{T})\). Formally:_

\[\left|\frac{u_{A}}{T}-\frac{1}{2}\right|\leq\frac{2\sqrt{10}}{ \sqrt{T}}\qquad\text{and}\qquad\left|\frac{u_{B}}{T}-\frac{1}{2}\right|\leq \frac{\sqrt{10}}{\sqrt{T}}\qquad\forall T\geq 5\,.\] (89)

Proof.: The bounds on Bob's payoff follow immediately from Lemma 21, which states that

\[\frac{T}{2}-\sqrt{10T}\leq\sum_{t=1}^{T}u_{B}^{t}\leq\frac{T}{2}+ \sqrt{10T}\,.\] (90)

By Lemma 22,

\[T-\sqrt{10T}\leq\sum_{t=1}^{T}\left(u_{A}^{t}+u_{B}^{t}\right) \leq T+\sqrt{10T}.\] (91)

Subtracting equation (90) from (91) gives

\[\frac{T}{2}-2\sqrt{10T}\leq\sum_{t=1}^{T}u_{A}^{t}\leq\frac{T}{2} +2\sqrt{10T}\,.\] (92)

Since \(u_{A}=\sum_{t=1}^{T}u_{A}^{t}\) and \(u_{B}=\sum_{t=1}^{T}u_{B}^{t}\), both players' utilities are bounded as required, which completes the proof. 

To prove the required lemmas, we first introduce several notations. For ease of exposition, we often use round \(t=0\) as a fake round in which nothing actually happens and all the defined quantities are zero.

**Definition 10**.: _For \(t\in\{0,1,\dots,T\}\):_

* _Let_ \(r_{t}\) _be the number of rounds in which Bob has picked_ \(R\)_, up to and including round_ \(t\)* _Let_ \(\ell_{t}\) _be the number of rounds in which Bob has picked_ \(L\) _up to and including round_ \(t\)_._
* _Let_ \(\alpha_{t}=r_{t}-\ell_{t}\)_._
* _Let_ \(\beta_{t}=\sum_{i=1}^{t}(2V_{B}([0,a_{i}])-1)\)_._
* _Let_ \(\rho_{t}=|\alpha_{t}|+|\beta_{t}|\)_, which we call the_ _radius__._

We remark that in the fake round of \(t=0\), all these variables have the value zero. Alice's action under fictitious play entirely depends on the variable \(\alpha_{t}\) while Bob's action entirely depends on \(\beta_{t}\). Overall, we will bound the payoffs using the growth of the radius \(\rho_{t}\) over \(t=0,1,\dots,T\). To this end, we introduce two lemmas that will play an essential role throughout the proof.

First, the following lemma formally argues that the action taken by each player is guided by their corresponding variable \(\alpha\) and \(\beta_{t}\), respectively.

**Lemma 11**.: _Let \(t\in\{0,1,\dots,T-1\}\). Then the following hold for round \(t+1\):_

* _Alice's action with respect to_ \(\alpha_{t}\)_:_
* _If_ \(\alpha_{t}>0\)_, Alice will cut at 1._
* _If_ \(\alpha_{t}<0\)_, Alice will cut at 0._
* _If_ \(\alpha_{t}=0\)_, any action would incur the same payoff, so she could cut anywhere._
* _Bob's action with respect to_ \(\beta_{t}\)_:_
* _If_ \(\beta_{t}>0\)_, Bob will pick_ \(L\)_._
* _If_ \(\beta_{t}<0\)_, Bob will pick_ \(R\)_._
* _If_ \(\beta_{t}=0\)_, any action would incur the same payoff, so he could pick either_ \(L\) _or_ \(R\)_._

Proof.: First, consider Alice's choice. For \(t=0\), there is no history, so any choice has the same value to her; accordingly, \(\alpha_{0}=0\). For \(t\geq 1\), the expected value she assigns to any particular cut location \(x\) is:

\[\frac{1}{t}\left(r_{t}V_{A}([0,x])+\ell_{t}V_{A}([x,1])\right) =\frac{1}{t}\left(r_{t}V_{A}([0,x])+\ell_{t}(1-V_{A}([0,x]))\right.\] \[=\frac{r_{t}-\ell_{t}}{t}V_{A}([0,x])+\frac{\ell_{t}}{t}\] \[=\frac{\alpha_{t}}{t}V_{A}([0,x])+\frac{\ell_{t}}{t}\,.\] (93)

From (93), we get that Alice's cut decision is entirely based on \(\alpha_{t}\). If \(\alpha_{t}<0\), she will minimize \(V_{A}([0,x])\), which means she cuts at 0. If \(\alpha_{t}>0\), she will maximize \(V_{A}([0,x])\), which means she cuts at 1. If \(\alpha_{t}=0\), then her choice of \(x\) doesn't affect her expected value.

Now consider Bob's choice. For \(t=0\), there is no history, so Bob is indifferent between \(L\) and \(R\); accordingly, \(\beta_{0}=0\). For \(t\geq 1\), the expected value he assigns to choosing \(L\) is:

\[E_{L}=\frac{1}{t}\sum_{i=1}^{t}V_{B}([0,a_{i}])\,.\] (94)

The expected value he assigns to choosing \(R\) is:

\[E_{R}=\frac{1}{t}\sum_{i=1}^{t}V_{B}([a_{i},1])\,.\] (95)

Combining (94) and (95), the difference between his expected value for choosing \(L\) and \(R\) is:

\[E_{L}-E_{R}=\left(\frac{1}{t}\sum_{i=1}^{t}V_{B}([0,a_{i}])\right)-\left(\frac {1}{t}\sum_{i=1}^{t}V_{B}([a_{i},1])\right)=\frac{1}{t}\sum_{i=1}^{t}(2V_{B}( [0,a_{i}])-1)=\frac{\beta_{t}}{t}\,.\] (96)

From (96), we get that Bob's decision is entirely based on \(\beta_{t}\). If \(\beta_{t}<0\), he values \(R\) more than \(L\), so he picks \(R\). If \(\beta_{t}>0\), he values \(L\) more than \(R\), so he picks \(L\). If \(\beta_{t}=0\), he values each equally.

The following lemma further describes the evolution of \(\alpha_{t}\) and \(\beta_{t}\) given the actions taken by the players.

**Lemma 12**.: _For each round \(t\in[T]\):_

* _Alice's action affects_ \(\beta_{t}\) _as follows:_
* _If Alice cuts at_ \(0\) _in round_ \(t\)_, then_ \(\beta_{t}=\beta_{t-1}-1\)_._
* _If Alice cuts at_ \(1\) _in round_ \(t\)_, then_ \(\beta_{t}=\beta_{t-1}+1\)_._
* _If she cuts at_ \(x\in(0,1)\)_, then_ \(|\beta_{t}-\beta_{t-1}|<1\)_._
* _Bob's action affects_ \(\alpha_{t}\) _as follows:_
* _If Bob picks_ \(L\) _in round_ \(t\)_, then_ \(\alpha_{t}=\alpha_{t-1}-1\)_._
* _If Bob picks_ \(R\) _in round_ \(t\)_, then_ \(\alpha_{t}=\alpha_{t-1}+1\)_._

Proof.: First, we consider the impact of Alice's cut point \(a_{t}\) on \(\beta_{t}\). Explicitly writing out the difference \(\beta_{t}-\beta_{t-1}\) gives:

\[\beta_{t}-\beta_{t-1}=\sum_{i=1}^{t}(2V_{B}([0,a_{i}])-1)-\sum_{i=1}^{t-1}(2V_ {B}([0,a_{i}])-1)=2V_{B}([0,a_{t}])-1\,.\] (97)

If \(a_{t}=0\), then \(V_{B}([0,a_{t}])=V_{B}([0,0])=0\), so by (97) we have \(\beta_{t}-\beta_{t-1}=-1\) as desired.

If \(a_{t}=1\), then \(V_{B}([0,a_{t}])=V_{B}([0,1])=1\), so by (97) we have \(\beta_{t}-\beta_{t-1}=1\).

If \(a_{t}\in(0,1)\), then there is at least some cake on each side of \(a_{t}\), so we have \(V_{B}([0,a_{t}])\in(0,1)\). By (97), we have \(\beta_{t}-\beta_{t-1}\in(-1,1)\), so \(|\beta_{t}-\beta_{t-1}|<1\) as stated by the lemma.

Second, we consider the impact of Bob's choice on \(\alpha_{t}\). Explicitly writing out the difference \(\alpha_{t}-\alpha_{t-1}\), we obtain the following:

\[\alpha_{t}-\alpha_{t-1}=(r_{t}-\ell_{t})-(r_{t-1}-\ell_{t-1})=(r_{t}-r_{t-1}) -(\ell_{t}-\ell_{t-1})=\begin{cases}1&b_{t}=R\\ -1&b_{t}=L\end{cases}\] (98)

This completes the proof. 

Let us elaborate more the dynamics of each player based on Lemma 11 and 12. If either of \(\alpha_{t}\) or \(\beta_{t}\) is exactly 0, the corresponding player will use their tie-breaking rules. Ignoring these cases, these choices lead to movement through \((\alpha_{t},\beta_{t})\) space that spirals counter-clockwise around the origin at exactly \(45\) degree angles. Figure 18-(a) describes the overall dynamics of the variables \((\alpha_{t},\beta_{t})\).

The following lemma shows a symmetry that will help reduce the number of cases in the subsequent analysis. Figure 18-(b) depicts the rotational symmetry of fictitious play dynamics in the \(\alpha\)-\(\beta\)-plane shown by the lemma. Specifically, the symmetry will allow us to assume \(\alpha_{t}\geq 0\) without loss of generality when analyzing \(\rho_{t}\) and \(u_{B}^{t}\).

**Lemma 13**.: _Consider an arbitrary pair of tie-breaking rules for both players. Consider the resulting sequence for the variables \(\alpha_{t},\beta_{t}\) and \(u_{B}^{t}\) for \(t=0,\dots,T\). Then, there exists another choice of tie-breaking rules that would result in the sequence of variables \(\tilde{\alpha}_{t}\), \(\tilde{\beta}_{t}\), and \(\tilde{u}_{B}^{t}\) for \(t=0,\dots,T\) such that_

\[\tilde{\alpha}_{t}=-\alpha_{t};\ \ \tilde{\beta}_{t}=-\beta_{t};\ \ \tilde{u}_{B}^{t}=u_{B}^{t}\,.\] (99)

Proof.: The proof will proceed by induction.

Base caseAll of \(\alpha_{0}\), \(\tilde{\alpha}_{0}\), \(\beta_{0}\), \(\tilde{\beta}_{0}\), \(u_{B}^{0}\), and \(\tilde{u}_{B}^{0}\) are zero, so (99) trivially holds.

Inductive hypothesisAssume that (99) holds for some \(t\geq 0\).

Inductive stepWe show that (99) holds for \(t+1\). Suppose that, under the original tie-breaking rules, Alice cut at \(a_{t+1}\) and Bob picked \(b_{t+1}\in\{L,R\}\) in round \(t+1\). First, we analyze for Alice. Let \(a^{\prime}_{t+1}\in[0,1]\) be the unique point for which

\[V_{B}([0,a_{t+1}])=V_{B}([a^{\prime}_{t+1},1])\,.\] (100)

The point \(a^{\prime}_{t+1}\) is uniquely defined since Bob's density is strictly positive.

We show that there exists another choice of tie-breaking rules under which, starting from \(\tilde{\alpha}_{t}\) and \(\tilde{\beta}_{t}\), Alice cuts at \(a^{\prime}_{t+1}\) in round \(t+1\). We split into cases based on \(\alpha_{t}\):

* Then \(a_{t+1}=1\) by Lemma 11. Since \(V_{B}([0,a_{t+1}])=V_{B}([0,1])\), we have \(a^{\prime}_{t+1}=0\) by definition. By the inductive hypothesis, we have \(\tilde{\alpha}_{t}=-\alpha_{t}\), and so \(\tilde{\alpha}_{t}<0\). Then, regardless of tie-breaking rules, Alice cuts at \(0=a^{\prime}_{t+1}\).
* Then \(a_{t+1}=0\) by Lemma 11. Since \(V_{B}([0,a_{t+1}]=0=V_{B}([1,1])\), we have \(a^{\prime}_{t+1}=1\) by definition. By the inductive hypothesis, \(\tilde{\alpha}_{t}=-\alpha_{t}\), and so \(\tilde{\alpha}_{t}>0\). Then, regardless of tie-breaking rules, Alice cuts at \(1=a^{\prime}_{t+1}\).
* Then Alice can break ties any way she likes by Lemma 11. However, \(\tilde{\alpha}_{t}=-\alpha_{t}=0\), so any cut point is a valid choice for her new tie-breaking rule. In particular, she can cut at \(a^{\prime}_{t+1}\).

Second, we analyze for Bob. Let \(b^{\prime}_{t+1}\in\{L,R\}\) be such that \(b^{\prime}_{t+1}\neq b_{t+1}\). We show that there exist tie-breaking rules under which, starting from \(\tilde{\alpha}_{t}\) and \(\tilde{\beta}_{t}\), Bob chooses \(b^{\prime}_{t+1}\). We split into cases based on \(\beta_{t}\):

* Then \(b_{t+1}=L\) by Lemma 11; therefore, \(b^{\prime}_{t+1}=R\). By the inductive hypothesis, \(\tilde{\beta}_{t}=-\beta_{t}\), so \(\tilde{\beta}_{t}<0\). Then, regardless of tie-breaking rules, Bob picks \(R=b^{\prime}_{t+1}\).
* Then \(b_{t+1}=R\) by Lemma 11; therefore, \(b^{\prime}_{t+1}=L\). By the inductive hypothesis, \(\tilde{\beta}_{t}=-\beta_{t}\), so \(\tilde{\beta}_{t}>0\). Then, regardless of tie-breaking rules, Bob picks \(L=b^{\prime}_{t+1}\).

Figure 18: Figure (a) represents the overall illustration of the dynamics of the action quantities \(\alpha_{t}\) and \(\beta_{t}\) for \(t=0,1,\ldots,T\). The \(x\)-axis denotes the quantity of \(\alpha_{t}\) and the \(y\)-axis denotes that of \(\beta_{t}\). Blue circles represent the sequence of points in the plane, where the number inside the circle denotes the index \(t\). Note that \(\alpha_{t}\) only takes integer values, while \(\beta_{t}\) possibly takes noninteger values at some rounds. Figure (b) also depicts an overall dynamics implemented by another pair of tiebreaking rules guaranteed by Lemma 13. Note that each point is reflected with respect to the origin point. Importantly, Lemma 13 guarantees that \(\rho_{t}\) and \(u^{t}_{B}\) for \(t=0,1,\ldots,T\) remain exactly the same for both dynamics.

\((\beta_{t}=0)\)**:**: Then Bob can break ties any way he likes by Lemma 11. However, \(\tilde{\beta}_{t}=-\beta_{t}=0\), so either \(L\) or \(R\) is a valid choice for his new tie-breaking rule. In particular, he can choose \(b^{\prime}_{t+1}\).

Finally, we show that these opposite choices have exactly the desired effect on \(\tilde{\alpha}_{t+1}\), \(\tilde{\beta}_{t+1}\), and \(\tilde{u}_{B}^{t+1}\). Covering each in turn:

* Since Bob picks the opposite side under the trajectory associated with \(\tilde{\alpha}\) and \(\tilde{\beta}\), the change from \(\alpha_{t}\) to \(\alpha_{t+1}\) is in the opposite direction as the change from \(\tilde{\alpha}_{t}\) to \(\tilde{\alpha}_{t+1}\) by Lemma 12. By the inductive hypothesis, we have \(\tilde{\alpha}_{t}=-\alpha_{t}\), and so \(\tilde{\alpha}_{t+1}=-\alpha_{t+1}\).
* Since Alice picks the mirror image of her cut point under the trajectory associated with \(\tilde{\alpha}\) and \(\tilde{\beta}\), the change from \(\beta_{t}\) to \(\beta_{t+1}\) is exactly opposite to the change from \(\tilde{\beta}_{t}\) to \(\tilde{\beta}_{t+1}\). Specifically, \[\beta_{t+1}=\beta_{t}+\Big{(}2V_{B}([0,a_{t+1}])-1\Big{)},\] (101) while \[\tilde{\beta}_{t+1} =\tilde{\beta}_{t}+\Big{(}2V_{B}([0,a^{\prime}_{t+1}])-1\Big{)}\] \[=\tilde{\beta}_{t}+2(1-V_{B}([a^{\prime}_{t+1},1]))-1\] \[=\tilde{\beta}_{t}+2(1-V_{B}([0,a_{t+1}]))-1\] \[=\tilde{\beta}_{t}-\Big{(}2V_{B}([0,a_{t+1}])-1\Big{)}\,.\] (102) By the inductive hypothesis, we have \(\tilde{\beta}_{t}=-\beta_{t}\). Using equations (101) and (102), we obtain \(\tilde{\beta}_{t+1}=-\beta_{t+1}\).
* Under Alice's new cut point \(a^{\prime}_{t+1}\), Bob's valuation of the left and right sides of the cake swap, _i.e.,_\(V_{B}([0,a^{\prime}_{t+1}])=V_{B}([a_{t+1},1])\). But he also chooses the opposite side, so he gets exactly the same payoff as under the original tie-breaking rules in round \(t+1\). Therefore, \(\tilde{u}_{B}^{t+1}=u_{B}^{t+1}\).

By induction, the claim holds for all \(t\), which completes the proof. 

In addition, it is helpful to distinguish between the rounds that cross an axis in the \(\alpha\)-\(\beta\) plane and those that do not. The following formalizes the definition of such rounds, which are depicted in Figure 19-(a).

**Definition 11**.: _An axis-crossing round is a round \(t\) where at least one of the following occurs:_

* \(\alpha_{t}=0\)__
* \(\beta_{t+1}>0\)_, but_ \(\beta_{t}\leq 0\)__
* \(\beta_{t+1}<0\)_, but_ \(\beta_{t}\geq 0\)_._

Importantly, we will show that \(\rho_{t}\) can strictly increase only if the current round is axis-crossing, while it is non-decreasing over the entire game. The following lemma formalizes this observation. We provide an example in Figure 19-(b).

**Lemma 14**.: _Let \(t\in\{0,1,\ldots,T\}\). The radius \(\rho_{t}\) satisfies the following properties:_

* \(\rho_{t}=\rho_{t+1}\) _if_ \(t\) _is not axis-crossing_
* \(\rho_{t}\leq\rho_{t+1}\leq 2+\rho_{t}\) _if_ \(t\) _is axis-crossing_
* \(\rho_{0}=0\)__
* \(\rho_{t}\geq 1\) _for_ \(t\geq 1\)_.__In particular, the radius \(\rho_{t}\) is non-decreasing in \(t\)._

Proof.: First, we will show (a) and (b). Consider an arbitrary round \(t\in\{0,\ldots,T\}\). By Lemma 12, we have \(|\alpha_{t+1}-\alpha_{t}|\leq 1\) and \(|\beta_{t+1}-\beta_{t}|\leq 1\), so by the triangle inequality

\[\left|\rho_{t+1}-\rho_{t}\right|=\left|\left|\alpha_{t+1}\right|+ \left|\beta_{t+1}\right|-\left|\alpha_{t}\right|-\left|\beta_{t}\right|\right| \leq 2\,.\] (103)

Therefore, \(\rho_{t+1}\leq 2+\rho_{t}\), as required by (b). Thus for (a) and (b) it remains to show that \(\rho_{t+1}\geq\rho_{t}\)\(\forall t\in\{0,\ldots,T\}\) and that \(\rho_{t+1}=\rho_{t}\) if \(t\) is not axis-crossing.

By Lemma 13, it suffices to consider \(\alpha_{t}\geq 0\). More precisely, this is because if \(\alpha_{t}\leq 0\), then there exists a tie-breaking rule with associated \(\tilde{\alpha}_{t}\) satisfying \(\tilde{\alpha}_{t}=-\alpha_{t}\) for every \(t=0,1,\ldots,T\), so \(\tilde{\alpha}_{t}\geq 0\). Crucially, the lemma ensures the sequences \(\tilde{\alpha}_{t}\) and \(\alpha_{t}\) have the same radius \(\rho_{t}\).

We consider a few cases based on \(\alpha_{t}\) and \(\beta_{t}\), considering only \(\alpha_{t}\geq 0\). Since \(\alpha_{t}\) is an integer, also divide into \(\alpha_{t}\geq 1\) and \(\alpha_{t}=0\):

\[(\alpha_{t}\geq 1\ \textbf{and}\ \beta_{t}>0)\textbf{:}\]

By Lemma 11 Alice will cut at 1 and Bob will pick L. Then by Lemma 12, we have \(\alpha_{t+1}=\alpha_{t}-1\) and \(\beta_{t+1}=\beta_{t}+1\). Therefore:

\[\rho_{t+1}=|\alpha_{t+1}|+|\beta_{t+1}| =\alpha_{t}-1+\beta_{t}+1\] (Since

\[\alpha_{t+1}\geq 0\]

) \[=|\alpha_{t}|+|\beta_{t}|\] (Because

\[\alpha_{t},\beta_{t}\geq 0\]

) \[=\rho_{t}\,.\] (104)

\((\alpha_{t}\geq 1\ \textbf{and}\ \beta_{t}=0)\textbf{:}\) Then Alice will cut at 1 and Bob will pick whichever piece he likes. Therefore \(\alpha_{t+1}=\alpha_{t}\pm 1\) and \(\beta_{t+1}=\beta_{t}+1=1\). Since \(\beta_{t}\leq 0\) but \(\beta_{t+1}>0\), round \(t\) is axis-crossing. What remains is to show that \(\rho_{t+1}\geq\rho_{t}\) in this case:

\[\rho_{t+1}=|\alpha_{t+1}|+|\beta_{t+1}| \geq|\alpha_{t}|-1+1\] (Because

\[|x\pm y|\geq|x|-|y|\]

 for all

\[x,y\]

) \[=|\alpha_{t}|+|\beta_{t}|\] (Since

\[\beta_{t}=0\]

) \[=\rho_{t}\,.\] (105)

\((\alpha_{t}\geq 1\ \textbf{and}\ -1<\beta_{t}<0)\textbf{:}\) Then Alice will cut at 1 and Bob will pick R. Therefore, \(\alpha_{t+1}=\alpha_{t}+1\) and \(\beta_{t+1}=\beta_{t}+1\). Since \(\beta_{t}<0\) but \(\beta_{t+1}>0\), round \(t\) is axis-crossing. What

Figure 19: Overall dynamics of \(\alpha_{t}\) and \(\beta_{t}\) with non axis-crossing rounds (blue circles) and axis-crossing rounds (red circles). Figure (b) shows that the radius \(\rho_{t}=|\alpha_{t}|+|\beta_{t}|\) is nondecreasing in \(t\) as shown by Lemma 14. In particular, \(\rho_{t}\) remains the same for non axis-crossing rounds but possibly increases for axis-crossing rounds.

remains is to show that \(\rho_{t+1}\geq\rho_{t}\):

\[\rho_{t+1}=|\alpha_{t+1}|+|\beta_{t+1}| =\alpha_{t}+1+|\beta_{t}+1|\] \[\geq\alpha_{t}+1+|\beta_{t}|-1\quad\quad(\text{Since }|x+y|\geq|x|-|y| \text{ for all }x,y)\] \[=\rho_{t}\,.\] (106)

\((\alpha_{t}\geq 1\) **and \(\beta_{t}\leq-1)\):**: Then Alice will cut at 1 and Bob will pick R. Therefore, \(\boldsymbol{\alpha_{t+1}=\alpha_{t}+1}\) and \(\beta_{t+1}=\beta_{t}+1\). In this case, \(\rho_{t+1}=\rho_{t}\):

\[\rho_{t+1}=|\alpha_{t+1}|+|\beta_{t+1}| =\alpha_{t}+1-(\beta_{t}+1)\] (Because

\[\beta_{t}+1\leq 0\]

) \[=|\alpha_{t}|+|\beta_{t}|\] (Since

\[\beta_{t}\leq 0\]

) \[=\rho_{t}\,.\] (107)

\((\alpha_{t}=0\) **and \(\beta_{t}\geq 0)\):**: Then \(t\) is an axis-crossing round. Bob could pick either L or R, but either way \(|\alpha_{t+1}|=1\). Alice could cut anywhere, but since \(|\beta_{t+1}-\beta_{t}|\leq 1\) we can still conclude \(|\beta_{t}|-|\beta_{t+1}|\leq 1\). Therefore:

\[\rho_{t+1}=|\alpha_{t+1}|+|\beta_{t+1}| \geq 1+|\beta_{t}|-1\] \[=|\alpha_{t}|+|\beta_{t}|\] (Since

\[\alpha_{t}=0\]

) \[=\rho_{t}\,.\] (108)

\((\alpha_{t}=0\) **and \(\beta_{t}<0)\):**: Then we can use the symmetry of Lemma 13 to consider \(\beta_{t}>0\) instead, which has already been covered.

In all cases, properties (a) and (b) must hold.

Now we show that the properties (c) and (d) hold. Property (c) follows from \(\alpha_{0}=\beta_{0}=0\). Because \(\rho_{t+1}\geq\rho_{t}\) for all \(t\), property (d) would follow from showing \(\rho_{1}\geq 1\), which can be seen true from the following inequality:

\[\rho_{1}=|\alpha_{1}|+|\beta_{1}| =1+|\beta_{1}|\] (Since

\[\alpha_{0}=0\]

, so

\[\alpha_{1}=\pm 1\]

) \[\geq 1\,.\] (109)

This finishes the proof. 

**Lemma 15**.: _Suppose \(t-1\) is an axis-crossing round and \(\tau>t-1\) is the next axis-crossing round after \(t-1\). Then, there exists at least \(\rho_{t}-2\) and at most \(\rho_{t}\) rounds between them, i.e.,_

\[\rho_{t}-2\leq\tau-t\leq\rho_{t}\,.\] (110)

Proof.: By Lemma 13, we can assume \(\alpha_{t-1}\geq 0\). Then it suffices to consider only four types that the axis-crossing round \(t-1\) could have:

1. \(\alpha_{t-1}\geq 1\), \(\beta_{t-1}\leq 0\), and \(\beta_{t}>0\);
2. \(\alpha_{t-1}\geq 1\), \(\beta_{t-1}\geq 0\), and \(\beta_{t}<0\);
3. \(\alpha_{t-1}=0\) and \(\beta_{t-1}\geq 1\);
4. \(\alpha_{t-1}=0\) and \(0\leq\beta_{t-1}<1\).

We show separately for each of the types **(i)-(iv)**.

**(i) \(\alpha_{t-1}\geq 1\), \(\beta_{t-1}\leq 0\), and \(\beta_{t}>0\).**: Because \(\alpha_{t-1}>0\), Alice will cut at 1 in round \(t\) by Lemma 11, so \(\beta_{t}=\beta_{t-1}+1\). Since \(\beta_{t-1}\) and \(\beta_{t}\) have different signs, it must be that \(-1<\beta_{t-1}\leq 0\) and \(0<\beta_{t}\leq 1\). As long as \(\alpha\) remains positive, Alice will keep cutting at 1 and increasing \(\beta\) by Lemma 11 and Lemma 12, so the next axis-crossing round \(\tau\) cannot be one where \(\beta\) changes sign. Thus, it must be the one satisfying \(\alpha_{\tau}=0\). Until then, Bob will keep picking L, so \(\alpha\) will decrease by 1 every round. Therefore, this implies that \(\tau=t+\alpha_{t}\). To show \(\tau-t\leq\rho_{t}\) as required by (110), we have

\[\tau-t=\alpha_{t}\leq|\alpha_{t}|+|\beta_{t}|\leq\rho_{t}.\]To prove \(\rho_{t}-2\leq\tau-t\), observe that \(\alpha_{t}\geq\alpha_{t-1}-1\). Since \(\alpha_{t-1}\geq 1\), we have \(\alpha_{t}\geq 0\). Thus \[\tau-t =\alpha_{t}\] \[\geq|\alpha_{t}|+|\beta_{t}|-1\] (Since \[0<\beta_{t}\leq 1\] and \[\alpha_{t}\geq 0\] ) \[=\rho_{t}-1>\rho_{t}-2\,.\] (111)

**(ii)**\(\alpha_{t-1}\geq 1\)**, \(\beta_{t-1}\geq 0\), and \(\beta_{t}<0\). Because \(\alpha_{t-1}>0\), Alice will cut at \(1\) in round \(t\), so \(\beta_{t}=\beta_{t-1}+1\). But then \(\beta_{t}>\beta_{t-1}\geq 0\), contradicting \(\beta_{t}<0\). Therefore, this case cannot happen.

**(iii)**\(\alpha_{t-1}=0\) and \(\beta_{t-1}\geq 1\).: By Lemma 11, Alice can cut wherever she likes, but Bob will pick L. Wherever Alice cuts, we will have \(\alpha_{t}=-1\) and \(\beta_{t}\geq 0\). In order to return to \(\alpha=0\), Bob must start picking R, but he cannot do so until \(\beta\leq 0\) by Lemma 11. Therefore, the next axis-crossing round \(\tau\) will be the one where \(\beta_{\tau+1}<0\) and \(\beta_{\tau}\geq 0\). Until then, Alice will keep cutting at 0, so \(\beta\) will decrease by 1 every round. Therefore, \(\tau=t+\lfloor\beta_{t}\rfloor\), and this implies that

\[\tau-t=\lfloor\beta_{t}\rfloor\leq|\alpha_{t}|+|\beta_{t}|=\rho_{t}\,.\]

Again to show \(\rho_{t}-2\leq\tau-t\), observe that

\[\tau-t =\lfloor\beta_{t}\rfloor\] \[\geq|\alpha_{t}|-1+|\beta_{t}|-1\] (Since \[\alpha_{t}=-1\] and \[\beta_{t}\geq 0\] ) \[=\rho_{t}-2\,.\]

**(iv)**\(\alpha_{t-1}=0\) and \(0\leq\beta_{t-1}<1\).: Under these constraints, we have \(\rho_{t-1}=|\alpha_{t-1}|+|\beta_{t-1}|<1\), so part (d) of Lemma 14 implies that \(t-1=0\). Therefore, we have \(\alpha_{t-1}=\beta_{t-1}=0\). Accounting for all possible choices Alice and Bob can make, it must be the case that \(\alpha_{t}=\pm 1\) and \(-1\leq\beta_{t}\leq 1\), which implies that \(1\leq\rho_{t}\leq 2\). Thus it suffices to show that \(\tau-t\leq 1\). We have a few cases:

* If \(\alpha_{t}=1\) and \(\beta_{t}>0\), then Bob will pick L in round \(t+1\) by Lemma 11. Therefore, \(\alpha_{t+1}=0\), so \(\tau=t+1\).
* If \(\alpha_{t}=1\) and \(-1<\beta_{t}\leq 0\), then Alice will cut at 1 in round \(t+1\) by Lemma 11. Therefore, \(\beta_{t+1}>0\), so round \(t\) is axis-crossing and \(\tau-t=0\).
* If \(\alpha_{t}=1\) and \(\beta_{t}=-1\), then Alice will cut at 1 and Bob will pick R in round \(t+1\) by Lemma 11. That will lead to \(\alpha_{t+1}=2\) and \(\beta_{t+1}=0\), so round \(t+1\) is axis-crossing. Therefore, \(\tau-t=1\).
* If \(\alpha_{t}=-1\), we can reduce to the \(\alpha_{t}=1\) case by Lemma 13.

Thus for all types **(i)-(iv)**, it follows that \(\rho_{t}-2\leq\tau-t\leq\rho_{t}\) as desired. 

The next two lemmas show different conditions under which \(\rho\) must increase. The first (Lemma 16) is more technical in nature, while the second (Lemma 17) is key to bounding the players' total payoff.

**Lemma 16**.: _Suppose there exists a round \(t\) such that \(\beta_{t}\not\in\mathbb{Z}\). Let \(\tau>t\) be the first round after \(t\) such that \(\beta_{t}\beta_{\tau}\leq 0\), i.e., \(\beta_{\tau}\) is zero or has the opposite sign of \(\beta_{t}\). Then the following inequality holds:_

\[\rho_{\tau}\geq\lfloor\rho_{t}\rfloor+1.\]

Proof.: Again by Lemma 13, we can assume without loss of generality that \(\beta_{t}\geq 0\). Since \(\beta_{t}\not\in\mathbb{Z}\), we can further assume \(\beta_{t}>0\).

Suppose that \(\beta_{\tau}\not\in\mathbb{Z}\). Because \(\tau>t\) is the first round after \(t\) with \(\beta_{\tau}\leq 0\), we must have \(\beta_{\tau-1}>0\). Since \(\beta_{\tau}\not\in\mathbb{Z}\), we also have \(\beta_{\tau}<0\). Combining \(|\beta_{\tau}-\beta_{\tau-1}|\leq 1\) and \(\beta_{\tau}<0\) yields \(0<\beta_{\tau-1}<1\). Since \(\beta_{\tau-1}>0\), Bob picked L in round \(\tau\) by Lemma 11, so we have \(\alpha_{\tau}=\alpha_{\tau-1}-1\). As \(\beta_{\tau}<\beta_{\tau-1}\)Alice must have not cut at 1 in round \(\tau\) by Lemma 12. This implies that \(\alpha_{\tau-1}\leq 0\). Finally, we obtain

\[\rho_{\tau}=\left|\alpha_{\tau}\right|+\left|\beta_{\tau}\right| \geq\left|\alpha_{\tau-1}-1\right|+0\] (Since \[\alpha_{\tau}=\alpha_{\tau-1}-1\] ) \[=1-\alpha_{\tau-1}\] (Since \[\alpha_{\tau-1}\leq 0\] ) \[=1+\left|\alpha_{\tau-1}\right|+\left\lfloor\left|\beta_{\tau-1} \right|\right\rfloor\] (Since \[\alpha_{\tau-1}\leq 0\] and \[0<\beta_{\tau-1}<1\] ) \[=1+\left\lfloor\rho_{\tau-1}\right\rfloor\] (Since \[\alpha_{\tau-1}\in\mathbb{Z}\] ) \[\geq 1+\left\lfloor\rho_{t}\right\rfloor.\] (By Lemma 14)

On the other hand, suppose \(\beta_{\tau}\in\mathbb{Z}\). By Lemma 14, we have \(\rho_{\tau}\geq\rho_{t}\). Since \(\beta_{t}\not\in\mathbb{Z}\) but \(\alpha_{t}\in\mathbb{Z}\) and \(\alpha_{\tau}\in\mathbb{Z}\), we have \(\rho_{\tau}\in\mathbb{Z}\) but \(\rho_{t}\not\in\mathbb{Z}\). Therefore, \(\left\lfloor\rho_{t}\right\rfloor<\rho_{t}\leq\rho_{\tau}\). Since both \(\left\lfloor\rho_{t}\right\rfloor\in\mathbb{Z}\) and \(\rho_{\tau}\in\mathbb{Z}\), we have \(\rho_{\tau}\geq\left\lfloor\rho_{t}\right\rfloor+1\). 

**Lemma 17**.: _Let \(t\) be a round in which Alice cuts at \(a_{t}\in(0,1)\). Let \(\tau-1\) be the first axis-crossing round strictly after \(t-1\). Then \(\rho_{\tau}\geq\left\lfloor\rho_{t-1}\right\rfloor+1\)._

Proof.: By Lemma 11, Alice will cut at 0 or 1 if \(\alpha_{t-1}\neq 0\). As Alice does not cut at \(0\) or \(1\) in round \(t\), this implies that \(\alpha_{t-1}=0\). First, if \(\beta_{t-1}=0\), then Lemma 14 implies \(t-1=0\), so \(\rho_{\tau}\geq 1=\left\lfloor\rho_{t-1}\right\rfloor+1\) as required.

Otherwise, by Lemma 13, we can assume without loss of generality that \(\beta_{t-1}>0\). Because \(\rho_{t-1}\geq\left|\beta_{t-1}\right|>0\), Lemma 14 implies \(t-1\geq 1\). By part (d) of Lemma 14, we further have

\[1\leq\rho_{t-1}=\left|\alpha_{t-1}\right|+\left|\beta_{t-1}\right|=\beta_{t-1 }\,.\]

Since Alice does not cut at 0 in round \(t\), we have \(\beta_{t}>\beta_{t-1}-1\) by Lemma 11, which implies that \(\beta_{t}>0\). As \(\beta_{t-1}>0\), Bob picked L in round \(t\) by Lemma 11, so we have \(\alpha_{t}<0\). Again by Lemma 11, for \(\alpha\) to return to \(0\), Bob would have to start picking R, but he won't until \(\beta\) stops being positive. Therefore, the next axis-crossing round after \(t\) will be one where \(\beta\) crosses into being non-positive from positive, so \(\beta_{\tau}<0\).

Let \(s>t-1\) be the first round after \(t-1\) such that \(\beta_{s}\leq 0\). Because \(\beta_{\tau}<0\), we have \(s\leq\tau\). Because \(\beta_{t}>0\), we have \(s>t\).

If \(\beta_{t-1}\not\in\mathbb{Z}\), then applying Lemma 16 to \(t-1\) yields \(\rho_{s}\geq\left\lfloor\rho_{t-1}\right\rfloor+1\). By Lemma 14, we have \(\rho_{\tau}\geq\rho_{s}\), and so \(\rho_{\tau}\geq\rho_{s}\geq\left\lfloor\rho_{t-1}\right\rfloor+1\) as required.

If \(\beta_{t}\not\in\mathbb{Z}\), then applying Lemma 16 to \(t\) yields \(\rho_{s}\geq\left\lfloor\rho_{t}\right\rfloor+1\). By Lemma 14, we have \(\rho_{\tau}\geq\rho_{s}\) and \(\rho_{t}\geq\rho_{t-1}\), and so \(\rho_{\tau}\geq\rho_{s}\geq\left\lfloor\rho_{t}\right\rfloor+1\geq\left\lfloor \rho_{t-1}\right\rfloor+1\) as required.

Else, we have \(\beta_{t-1},\beta_{t}\in\mathbb{Z}\). Since Alice did not cut at 0 or 1 in round \(t\), by Lemma 12 we have \(\left|\beta_{t}-\beta_{t-1}\right|<1\). Since \(\beta_{t},\beta_{t-1}\in\mathbb{Z}\), we get \(\beta_{t-1}=\beta_{t}\). Moreover, since \(\alpha_{t-1}=0\), we have \(\left|\alpha_{t}\right|=\left|\alpha_{t-1}\pm 1\right|=1\). This implies that

\[\rho_{\tau} \geq\rho_{t}\] (By Lemma 14) \[=\rho_{t-1}+1\] (Since \[\beta_{t}=\beta_{t-1}\] and \[\left|\alpha_{t}\right|=\left|\alpha_{t-1}\right|+1\] ) \[\geq\left\lfloor\rho_{t-1}\right\rfloor+1\,.\]

This completes the proof. 

The following lemma bounds Bob's total payoff using the radius \(\rho_{t}\).

**Lemma 18**.: _For every round \(t\geq 0\), the following inequalities hold:_

\[-\rho_{t}\leq\sum_{i=1}^{t}(2u_{B}^{i}-1)\leq\rho_{t}.\] (112)

Proof.: We will first show the following stronger set of inequalities by induction on \(t\):

\[0\leq\left|\alpha_{t}\right|+\sum_{i=1}^{t}(2u_{B}^{i}-1)\leq\rho_{t}.\] (113)

As a base case, consider \(t=0\). Before anything has happened, all three sides of (113) are zero, so the inequalities trivially hold.

Now assume that (113) holds for some \(t\geq 0\), and we will prove that it still holds for round \(t+1\). We consider three cases separately in what follows, depending on the values of \(\alpha_{t}\) and \(\beta_{t}\). Note that again by Lemma 13, it suffices to only consider cases where \(\alpha_{t}\geq 0\).

* If \(\alpha_{t}>0\), Alice will cut at 1 in round \(t+1\) by Lemma 11. If Bob picks \(L\), then he will receive a payoff of 1 and \(\alpha_{t}\) will decrease by 1 due to Lemma 12. If Bob picks \(R\), then he will receive a payoff of 0 and \(\alpha_{t}\) will increase by 1 due to Lemma 12. In either case, the changes to \(|\alpha_{t}|+\sum_{i=1}^{t}(2u_{B}(i)-1)\) cancel out, which implies that \[|\alpha_{t}|+\sum_{i=1}^{t}(2u_{B}^{i}-1)=|\alpha_{t+1}|+\sum_{i=1}^{t+1}(2u_{ B}^{i}-1).\] (114) Further, by Lemma 14 we have \(\rho_{t+1}\geq\rho_{t}\). Together with the induction hypothesis (113), this concludes \[0\leq|\alpha_{t+1}|+\sum_{i=1}^{t+1}(2u_{B}^{i}-1)\leq\rho_{t+1},\] and thus the induction holds for the first case.
* If \(\alpha_{t}=0\) and \(\beta_{t}\geq 0\), then regardless of whether Bob picks L or R in round \(t+1\) we have \(|\alpha_{t+1}|=|0\pm 1|=1\) as \(\alpha\) necessarily changes by \(1\). Therefore, we have \[\left(|\alpha_{t+1}|+\sum_{i=1}^{t+1}(2u_{B}^{i}-1)\right)-\left(| \alpha_{t}|+\sum_{i=1}^{t}(2u_{B}^{i}-1)\right) =1+2u_{B}^{t+1}-1\] \[=2u_{B}^{t+1}\] (115) Also, the change in \(\rho\) can be bounded as follows: \[\rho_{t+1}-\rho_{t} =|\alpha_{t+1}|+|\beta_{t+1}|-|\alpha_{t}|-|\beta_{t}|\] \[=1+\left|\sum_{i=1}^{t+1}(2V_{B}([0,a_{t}])-1)\right|-0-\beta_{t}\] ( \[\beta_{t}\geq 0\] ) \[=1+|(2V_{B}([0,a_{t+1}])-1)+\beta_{t}|-\beta_{t}\] \[\geq 1+2V_{B}([0,a_{t+1}])-1\] (Removing the absolute value) \[=2V_{B}([0,a_{t+1}])\] (116) If Bob picked \[L\] in round \[t+1\], this is exactly the same as ( 115 ). If Bob picked \[R\], then by Lemma 11  and the assumption that \[\beta_{t}\geq 0\] we must have \[\beta_{t}=0\]. The change in the radius can be bounded as follows: \[\rho_{t+1}-\rho_{t} =|\alpha_{t+1}|+|\beta_{t+1}|-|\alpha_{t}|-|\beta_{t}|\] \[=1+|2V_{B}([0,a_{t+1}])-1|-0-0\] ( \[\beta_{t}=0\] ) \[=1+|1-2V_{B}([a_{t+1},1])|\] ( \[V_{B}([0,a_{t+1}])+V_{B}([a_{t+1},1])=1\] ) \[=1+|-(1-2V_{B}([a_{t+1},1]))|\] \[\geq 1-1+2V_{B}([a_{t+1},1])\] (Removing the absolute value) \[=2u_{B}^{t+1}\] (Since Bob picked \[R\] ) In either case, the radius increased by at least as much as the middle of ( 113 ). More precisely, by the induction hypothesis ( 113 ), we obtain \[|\alpha_{t+1}|+\sum_{i=1}^{t}(2u_{B}^{i}-1) =|\alpha_{t}|+\sum_{i=1}^{t}(2u_{B}^{i}-1)+2u_{B}^{t+1}-1+| \alpha_{t+1}|-|\alpha_{t}|\] \[\geq 0+2u_{B}^{t+1}\] ( \[\alpha_{t}=0\] and \[|\alpha_{t+1}|=1\] ) \[\geq 0.\] ( \[u_{B}^{t+1}\geq 0\] )Note further that \[|\alpha_{t+1}|+\sum_{i=1}^{t}(2u_{B}^{i}-1) =|\alpha_{t}|+\sum_{i=1}^{t}(2u_{B}^{i}-1)+2u_{B}^{t+1}-1+|\alpha_{t +1}|-|\alpha_{t}|\] \[\leq\rho_{t}+2u_{B}^{t+1}\] (By the induction hypothesis) \[=\rho_{t+1}.\] ( \[\rho_{t+1}-\rho_{t}=2u_{B}^{t+1}\] ) This finishes the proof of the induction for the second case.
* If \(\alpha_{t}=0\) and \(\beta_{t}<0\), then by Lemma 13 we can consider \(\alpha_{t}=0\) and \(\beta_{t}>0\) instead, which has already been shown above.

In all cases, the inductive step holds. Therefore, by induction principle, (113) holds for all \(t\). Subtracting \(|\alpha_{t}|\) from all three sides of it, we obtain

\[-|\alpha_{t}|\leq\sum_{i=1}^{t}(2u_{B}^{i}-1)\leq|\beta_{t}|.\]

Since \(\rho_{t}=|\alpha_{t}|+|\beta_{t}|\), this immediately implies the desired bounds. 

Now that we have bounds on the relevant events in terms of \(\alpha\), \(\beta\), and \(\rho\), we can bound them as functions of \(T\) to obtain our final result.

**Lemma 19**.: _Let \(n\geq 7\). Let \(t_{1},t_{2},\ldots,t_{n}\) be a sequence of rounds such that for all \(i\in[n-1]\) the following inequality holds:_

\[\rho_{t_{i+1}}\geq\lfloor\rho_{t_{i}}\rfloor+1.\] (117)

_Then \(t_{n}-t_{1}>\frac{1}{10}n^{2}\)._

Proof.: First, we will show by induction that, for \(i\in[n]\), we have \(\rho_{t_{i}}\geq i-1\). For the base case, \(\rho_{t_{1}}\geq\rho_{0}=0\), so the inequality trivially holds.

Now assume \(\rho_{t_{i}}\geq i-1\) for some \(i\in[n-1]\) and we will prove that the induction step holds for the case \(i+1\). By (117), observe that

\[\rho_{t_{i+1}} \geq\lfloor\rho_{t_{i}}\rfloor+1\] \[\geq\lfloor i-1\rfloor+1\] \[=(i+1)-1.\]

Thus, by the induction principle we have

\[\rho_{t_{i}}\geq i-1\text{ for }i=1,\ldots,n\] (118)

Now consider an arbitrary \(i\in[n-1]\). Note that \(\rho_{t_{i+1}}\geq\lfloor\rho_{t_{i}}\rfloor+1\) implies \(\rho_{t_{i+1}}>\rho_{t_{i}}\). Therefore, by Lemma 14, there must be an axis-crossing round \(c_{i}\) among the interval \([t_{i},t_{i+1})\). This is because if this is not true, we have \(\rho_{t_{i+1}}=\rho_{t_{i}}\) which contradicts \(\rho_{t_{i+1}}>\rho_{t_{i}}\). Repeating the same argument for each \(i\), we conclude that there exists a sequence of rounds \(c_{1},c_{2},\ldots,c_{n-1}\) each of which is axis-crossing, and satisfies the following inequality for every \(i\in[n-1]\):

\[t_{i}\leq c_{i}<t_{i+1}\] (119)

In addition, for any \(i\in[n-1]\), we observe that

\[c_{i+1}-(c_{i}+1) \geq\rho_{c_{i}+1}-2\] (By Lemma 15, with

\[\tau=c_{i+1}\]

 and

\[t=c_{i}+1\]

) \[\geq\rho_{t_{i}}-2\] (By (119)) \[\geq i-3\] (By (118))

Slightly rearranging, we obtain

\[c_{i+1}-c_{i}\geq i-2\ \ \forall i\in[n-1]\,.\] (120)Combining (119) and (120), we finally obtain

\[t_{n}-t_{1} >c_{n-1}-c_{1}\] (By (119)) \[=\sum_{i=1}^{n-2}(c_{i+1}-c_{i})\] \[\geq\sum_{i=1}^{n-2}(i-2)\] (By (120)) \[=\frac{1}{2}n^{2}-\frac{7}{2}n+5.\]

For \(n\geq 7\), we have \(\frac{1}{2}n^{2}-\frac{7}{2}n+5\geq\frac{1}{10}n^{2}\),4 and so \(t_{n}-t_{1}>n^{2}/10\), as required. 

Footnote 4: We omit the elementary calculus.

The following lemma will finally be combined with Lemma 18 to obtain the desired bound for Bob's payoff.

**Lemma 20**.: _For \(T\geq 5\), the final radius \(\rho_{T}\) satisfies the following:_

\[\rho_{T}\leq 2\sqrt{10T}.\]

Proof.: Let \(t_{1}=0\), and for \(i\geq 2\) recursively define \(t_{i}\) be the first round after \(t_{i-1}\) satisfying \(\rho_{t_{i}}\geq\lfloor\rho_{t_{i-1}}\rfloor+1\). Let \(n\) be the last index of such \(t_{i}\) given the time horizon \(T\).

As an immediate corollary of Lemma 19, we have

\[n\leq\max\{7,\sqrt{10T}\}.\]

For \(T\geq 5\), this implies that

\[n\leq\sqrt{10T}\] (121)

By Lemma 14, we also know that \(\rho\) can increase by at most \(2\) per round. Furthermore, since \(t_{n}\) is the last element in the sequence \(\{t_{i}\}_{i\in[n]}\), we have \(\rho_{T}<\lfloor\rho_{t_{n}}\rfloor+1\). Relaxing this slightly, we have

\[\rho_{T}\leq\rho_{t_{n}}+2\] (122)

Therefore, we obtain the following inequalities:

\[\rho_{T} \leq 2+\rho_{t_{n}}\] (By (122)) \[=2+\sum_{i=1}^{n-1}(\rho_{i+1}-\rho_{i})\] \[\leq 2+2(n-1)\] (By Lemma 14) \[=2n\] (123)

Putting (121) and (123) together, we obtain

\[\rho_{T}\leq 2\sqrt{10T},\]

which finishes the proof of the lemma. 

Using the above bound on the radius together with Lemma 18, Bob's payoff can now be bounded as follows.

**Lemma 21**.: _For \(T\geq 5\), Bob's total payoff satisfies:_

\[\frac{T}{2}-\sqrt{10T}\leq\sum_{t=1}^{T}u_{B}^{t}\leq\frac{T}{2}+\sqrt{10T}\,.\]Proof.: We start from the inequality (112). Halving all three sides of (112) for \(t=T\) and adding \(T/2\), we obtain

\[\frac{T}{2}-\frac{1}{2}\rho_{T}\leq\sum_{t=1}^{T}u_{B}^{t}\leq\frac{T}{2}+\frac{ 1}{2}\rho_{T}.\]

Using the upper bound \(\rho_{T}\leq 2\sqrt{10T}\) from Lemma 20 gives the desired bounds. 

Combined with Lemma 21, Alice's payoff can eventually be bounded using the following lemma, which effectively bounds the summation of Alice and Bob's total payoff.

**Lemma 22**.: _For \(T\geq 5\), the summation of total payoff to Alice and Bob satisfies the following:_

\[T-\sqrt{10T}\leq\sum_{t=1}^{T}\left(u_{A}^{t}+u_{B}^{t}\right)\leq T+\sqrt{10T }\,.\]

Proof.: Given the time horizon \(T\), let \(s_{1},s_{2},\ldots,s_{k}\) be the rounds in which Alice cuts at a point other than \(0\) or \(1\), where \(k\) denotes the number of such rounds. These are the only rounds in which the total payoff \(u_{A}^{t}+u_{B}^{t}\) is not necessarily \(1\). The total payoff in these rounds can be bounded as

\[0\leq u_{A}^{s_{i}}+u_{B}^{s_{i}}\leq 2,\]

for any \(i\in[k]\). Thus, we obtain

\[T-k\leq\sum_{t=1}^{T}u_{A}^{t}+u_{B}^{t}\leq T+k.\]

Therefore, it suffices to prove that \(k\leq\sqrt{10T}\).

If \(k<7\), the proof follows as \(k<7\leq\sqrt{10T}\).

Otherwise, we have \(k\geq 7\). For each \(s_{i}\), let \(\tau_{i}\) be the round after the next axis-crossing round after \(s_{i}-1\). Consider \(s_{i}\) for an arbitrary \(i\in[k]\). Due to Lemma 11, if \(\alpha_{s_{i}-1}\neq 0\) then Alice cuts at \(0\) or \(1\) in round \(s_{i}\), which contradicts our definition of round \(s_{i}\). Thus we have \(\alpha_{s_{i}-1}=0\). This argument holds for arbitrary \(i\in[k]\), so both \(s_{i}-1\) and \(s_{i+1}-1\) are axis-crossing rounds. Moreover, since both \(\alpha_{s_{i}-1}=0\) and \(\alpha_{s_{i+1}-1}=0\), there must have been some rounds between \(s_{i}-1\) and \(s_{i+1}-1\) where Bob picked \(L\) and some where he picked \(R\). Therefore, \(\beta\) must have changed sign at least once, so there is another axis-crossing round in between \(s_{i}-1\) and \(s_{i+1}-1\) where \(\beta\) changed sign. This implies that for every \(i=1,\ldots,k-1\), the next axis crossing round \(\tau_{i}\) after \(s_{i}-1\) should exist at least before \(s_{i+1}-1\), _i.e.,_

\[\tau_{i}\leq s_{i+1}-1\,.\] (124)

Due to the monotonicity of \(\rho\) by Lemma 14, for any \(i\in\{1,\ldots,k-1\}\) we have

\[\rho_{s_{i+1}-1} \geq\rho_{\tau_{i}}\] (By (124)) \[\geq\lfloor\rho_{s_{i}-1}\rfloor+1\,.\] (By Lemma 17)

By Lemma 19, we have:

\[(s_{k}-1)-(s_{1}-1)>\frac{1}{10}k^{2}\,.\] (125)

Re-arranging (125) and using the fact that \(s_{k}-s_{1}\leq T\), we obtain \(k<\sqrt{10T}\). This finishes the proof of the case \(k\geq 7\), which completes the lemma.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes]. Justification: We prove all the theorems and propositions that are summarized in the abstract. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes]. Justification: The paper clearly states the modelling assumptions under which the theorems and propositions hold. We also suggest a few directions for future work in Concluding Remarks. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [Yes] Justification: The main body of the paper has our model, theorem statements, and proof sketches. The formal proofs are in the appendix. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We included a few example trajectories from the fictitious play dynamic. The code is included with the submission. All our results are proved mathematically and the experimental data is purely illustrative. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.

5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes]. Justification: This is a theoretical paper, so the paper provides all the proofs for the stated theorems. We also include the code for the fictitious play dynamic, which we illustrate an example trajectory of in the main file. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA]. Justification: As mentioned above, we just included one example trajectory for visualization purposes. Code which generates similar trajectories is included. Our results are not based on experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA]. Justification: This is not relevant to our paper. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.

* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA]. Justification: The code we included is a very simple dynamical system that can be run on any laptop in a minute or two. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We do not propose a model, use a dataset, or involve human participants. Our theoretical results do not have immediate possibilities for misuse. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: We do not propose a concrete technology. Our idealized setting does not have any immediate societal applications. Guidelines:* The answer NA means that there is no societal impact of the work performed.
* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA]. Justification: We wrote the paper and the simulation of fictitious play, which is a very standard type of dynamic. There is no license or asset used from other sources. We cite all the related papers in the literature that we are aware of. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset.

* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.

13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA]. Justification: Not applicable. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.

14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.

15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.

* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.