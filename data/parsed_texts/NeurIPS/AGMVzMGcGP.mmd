# Active Bipartite Ranking

 James Cheshire Stephan Clemencon

Telecom ParisTech

first.last@telecom-paris.fr

Vincent Laurent

ENS Paris Saclay

first.last@ens-paris-saclay.fr

###### Abstract

In this paper, we develop an active learning framework for the bipartite ranking problem. Motivated by numerous applications, ranging from supervised anomaly detection to credit-scoring through the design of medical diagnosis support systems, and usually formulated as the problem of optimizing (a scalar summary of) the \(\mathrm{ROC}\) curve, bipartite ranking has been the subject of much attention in the passive context. Various dedicated algorithms have been recently proposed and studied by the machine-learning community. In contrast, active bipartite ranking rule is poorly documented in the literature. Due to its global nature, a strategy for labeling sequentially data points that are difficult to rank w.r.t. to the others is required. This learning task is much more complex than binary classification, for which many active algorithms have been designed. It is the goal of this article to provide a rigorous formulation of such a selective sampling approach. We propose a dedicated algorithm, referred to as active-rank, which aims to minimise the distance between the ROC curve of the ranking function built and the optimal one, w.r.t. the \(\mathrm{sup}\) norm. We show that, for a fixed confidence level \(\varepsilon\) and probability \(\delta\), active-rank is \(\mathrm{PAC}(\varepsilon,\delta)\). In addition, we provide a problem dependent upper bound on the expected sampling time of active-rank and also demonstrate a problem dependent lower bound on the expected sampling time of any \(\mathrm{PAC}(\varepsilon,\delta)\) algorithm. Beyond the theoretical analysis carried out, numerical results are presented, providing strong empirical evidence of the performance of the algorithm proposed, which compares favorably with more naive approaches.

## 1 Introduction

In bipartite ranking, the statistical framework is exactly the same as that in standard binary classification, the flagship problem in statistical learning theory. One observes \(n\geq 1\) independent copies \(\mathcal{D}_{n}=\{(X_{1},Y_{1}),\ \dots,\ (X_{n},Y_{n})\}\) of a generic random pair \((X,Y)\) with (unknown) distribution \(P\), where \(Y\) is a binary random label, valued in \(\{-1,\ +1\}\) say, and \(X\) is a high dimensional random vector, taking its values in \(\mathcal{X}\subset\mathbb{R}^{d}\) with \(d\geq 1\), that models some information hopefully useful to predict \(Y\). In contrast to binary classification, the goal pursued is of global (and not local) nature. It is not to assign a label, positive or negative, to any new input observation \(X\) but to rank any new set of (temporarily unlabeled) observations \(X^{\prime}_{1},\ \dots,\ X^{\prime}_{n^{\prime}}\) by means of a (measurable) scoring function \(s:\mathcal{X}\rightarrow\mathbb{R}\), so that those with positive label appear on top of the list (_i.e._ are those with the highest scores) with high probability. More formally, the accuracy of any scoring rule can be evaluated through the \(\mathrm{ROC}\) curve criterion or its popular scalar summary, the \(\mathrm{AUC}\) (standing for the Area Under the \(\mathrm{ROC}\) Curve), and, as expected, optimal scoring functions w.r.t. these performance measures can be shown to be increasing transforms of the posterior probability \(\eta(x)=\mathbb{P}\{Y=+1\mid X=x\}\)\(x\in\mathcal{X}\). Though easy to formulate, this problem encompasses many applications, ranging from credit risk screening to the design of decision support tools for medical diagnosis through (supervised) anomaly detection. Hence, motivated by a wide variety of applications, bipartite ranking has received much attention these last few years. Many approaches to this global learning problem (_i.e._ the problem of learning a preorder on the input space \(\mathcal{X}\) based on a binary feedback) have been proposed and investigated. In Clemencon and Vayatis (2009), optimization of the (empirical) \(\mathrm{ROC}\) curve in \(\sup\) norm is considered via nonlinear approximation techniques, while this functional optimization problem is viewed as a superposition of cost-sensitive binary classification problems in Clemencon and Vayatis (2008) so as to propose an alternative method. In Clemencon et al. (2008) (see also Agarwal et al. (2005)), empirical maximization of the empirical \(\mathrm{AUC}\) criterion is considered, bipartite ranking being viewed as a pairwise classification problem, a _plug-in_ approach to bipartite ranking is developed in Clemencon and Robbiano (2011) and scalar performance criteria other than the \(\mathrm{AUC}\) have been recently reviewed in Menon and Williamsson (2016). Whereas the vast majority of dedicated articles consider the _batch_ situation solely, where the learning procedure fully relies on a set \(\mathcal{D}_{n}\) of training examples given in advance, the goal of this paper is to develop an _active learning_ framework for bipartite ranking, in other words to investigate this problem in an iterative context, where the learning procedure can formulate queries in a sequential manner, so as to observe the labels at new data points in order to refine progressively the scoring/ranking model. Precisely, the challenge consists in determining an incremental experimental design to label the data points in \(\mathcal{X}\) that would permit to improve the \(\mathrm{ROC}\) curve progressively, with statistical guarantees.

Our contributionsWe describe an algorithm, active-rank, which sequentially queries points of the feature space \(\mathcal{X}\). Given a confidence level \(\varepsilon>0\) and probability \(\delta>0\), the goal of active-rank is, in a few queries as possible, to output a ranking of \(\mathcal{X}\), such that the induced ROC curve of said ranking is within \(\varepsilon\) of the optimal ROC curve, in terms of the sup norm, with probability greater than \(1-\delta\). We restrict our selves to dimension 1, i.e. \(\mathcal{X}=[0,1]\) and make a single key assumption that the posterior \(\eta\) is piecewise constant on a grid of size \(K\). Theorem 3.2 then shows that active-rank satisfies the above statistical guarantee and furthermore, provides an upper bound on it's expected total number of queries. In Theorem 3.3 we provide a lower bound on the expected number of queries for any possible policy, which satisfies a confidence level \(\varepsilon\) with probability greater than \(1-\delta\). The aforementioned bounds are _problem dependent_, in the sense that they depend on features of the posterior \(\eta\). Finally we conduct a practical analysis of active-rank on synthetic data, comparing it to several naive approaches.

The article is structured as follows. In Section 2 we formally define our setting as well recalling some key notions related to bipartite ranking and \(\mathrm{ROC}\) analysis. In Section 2 we also cover some of the existing literature in active learning, of relevance to bipartite ranking. We then describe the active-rank algorithm in Section 3.1. Following this our theoretical results are presented in Section 3.2. Lastly, the experiments are displayed in Section 4. We then conclude and discuss some perspectives for future research in Section 5. Technical details and proofs are deferred to the Supplementary Material.

## 2 Background and preliminaries

### Notation

Here we introduce several dedicated notions that will be extensively used in the subsequent analysis. For any integer \(n\geq 1\), we set \([n]:=\{1,\ \ldots,\ n\}\), denote by \(\mathfrak{S}_{n}\) the symmetric group of permutations on \(\{1,\ \ldots,\ n\}\), by \(\mathbf{I}_{n}\) the identity map of \(\mathfrak{S}_{n}\). By \(\lambda\) is meant the Lebesgue measure on \([0,1]\). Given two probability distributions \(P\) and \(Q\) on a measurable space \((\Omega,\mathcal{F})\), we write \(P\ll Q\) when \(P\) is absolutely continuous w.r.t. \(Q\). For any \(a,\ b\) in \([0,1]\), \(\mathcal{B}\mathrm{er}(a)\) refers to the Bernoulli distribution with mean \(a\) and \(\mathrm{kl}(a,b)\) to the Kullback Leibler divergence between the Bernoulli distributions \(\mathcal{B}\mathrm{er}(a)\) and \(\mathcal{B}\mathrm{er}(b)\). For any \(a,b\in[0,1]\), the Chernoff Information between the distributions \(\mathcal{B}\mathrm{er}(a)\) and \(\mathcal{B}\mathrm{er}(b)\) is defined as, \(\mathrm{kl}^{*}(a,b)=\mathrm{kl}(x^{*},a)=\mathrm{kl}(x^{*},b)\), where \(x^{*}\) is the unique \(x\in[0,1]\) such that \(\mathrm{kl}(x,a)=\mathrm{kl}(x,b)\). The indicator function of any event \(\mathcal{E}\) is denoted by \(\mathbb{I}\{\mathcal{E}\}\), the Dirac mass at any point \(x\) by \(\delta_{x}\), and the pseudo-inverse of any cdf \(\kappa(u)\) on \(\mathbb{R}\) by \(\kappa^{-1}(t)=\inf\{v\in\mathbb{R}:\ \kappa(v)\geq t\}\).

### Setting

The bipartite ranking problemA rigorous formulation of bipartite ranking involves functional performance measures. Let \(\mathcal{S}\) be the set of all scoring functions, any \(s\in\mathcal{S}\) defines a preorder \(\preceq_{s}\) on \(\mathcal{X}\): for all \((x,x^{\prime})\in\mathcal{X}^{2}\), \(x\preceq_{s}x^{\prime}\Leftrightarrow s(x)\leq s(x^{\prime})\). From a quantitative perspective, the accuracy of any scoring rule can be evaluated through the \(\mathrm{ROC}\) curve criterion, namely the PP-plot \(t\in\mathbb{R}\mapsto(1-H_{s}(t),\ 1-G_{s}(t))\), where \(H_{s}(t)=\mathbb{P}\{s(X)\leq t\mid Y=-1\}\) and \(G_{s}(t)=\mathbb{P}\{s(X)\leq t\mid Y=+1\}\), for all \(t\in\mathbb{R}\). The curve can also be viewed as the graph of the cad-lag function \(\alpha\in(0,1)\mapsto\mathrm{ROC}(s,\alpha)=1-G_{s}\circ H_{s}^{-1}(-1-\alpha)\). The notion of \(\mathrm{ROC}\) curve defines a partial order on the set of all scoring functions (respectively, the set of all preorders on \(\mathcal{X}\)): \(s_{1}\) is more accurate than \(s_{2}\) when \(\mathrm{ROC}(s_{2},\alpha)\leq\mathrm{ROC}(s_{1},\alpha)\) for all \(\alpha\in(0,1)\). As can be proved by a straightforward Neyman-Pearson argument, the set \(\mathcal{S}^{*}\) of optimal scoring functions is composed of increasing transforms of the posterior probability \(\eta(x)=\mathbb{P}\{Y=+1\mid X=x\}\), \(x\in\mathcal{X}\). We have \(\mathcal{S}^{*}=\{s\in\mathcal{S}:\ \forall(x,\ x^{\prime})\in\mathcal{X}^{2},\ \ \eta(x)< \eta(x^{\prime})\Rightarrow s^{*}(x)<s^{*}(x^{\prime})\}\) and

\[\forall(s,s^{*})\in\mathcal{S}\times\mathcal{S}^{*},\ \forall\alpha\in(0,1),\ \ \mathrm{ROC}(s,\alpha)\leq\mathrm{ROC}^{*}(\alpha):=\mathrm{ROC}(s^{*},\alpha).\]

The ranking performance of a candidate \(s\in\mathcal{S}\) can be thus measured by the distance in \(\mathrm{sup}\)-norm between its \(\mathrm{ROC}\) curve and \(\mathrm{ROC}^{*}\), namely \(d_{\infty}(s,s^{*}):=\sup_{\alpha\in(0,1)}\{\mathrm{ROC}^{*}(\alpha)-\mathrm{ ROC}(s,\alpha)\}\). An alternative convention to represent the ROC of a scoring function \(s\), which we will use for the remainder of this paper, is to consider the broken line \(\widetilde{\mathrm{ROC}}(s,.)\), which arises from connecting the PP-plot by line segments at each possible jump of the cdf \(H_{s}\). **From here on out when referring to the \(\mathrm{ROC}\) of a scoring function \(s\), we refer to the broken line \(\widetilde{\mathrm{ROC}}(s,.)\).**

The active learning settingWhereas in the batch mode, the construction of a nearly optimal scoring function (_i.e._ a function \(s\in\mathcal{S}\) such that \(d_{\infty}(s,s^{*})\) is'small' with high probability) is based on a collection of independent training examples given in advance, the objective of an _active learner_ is to formulate queries in order to recover sequentially the optimal preorder on the feature space \(\mathcal{X}\) defined by the supposedly unknown function \(\eta\). That is, the active learner plays a game with multiple time steps, where, at time each step \(n\), they must choose a point \(a_{n}\in\mathcal{X}\) to query, so as to observe the random label \(Y_{n}\sim\mathcal{B}\mathrm{er}(\eta(a_{n}))\) and refine the scoring model incrementally. After a sufficient number of rounds has elapsed, chosen at the learner's discretion, a final scoring function \(\hat{s}\), is output.

Piecewise constant scoring functionsHere we consider the simplest scoring functions, measurable functions that are constant on pieces of the input space \(\mathcal{X}\) forming a partition. As shown in Clemencon and Vayatis (2009) (see subsection 2.3 therein), when smooth enough, \(\mathrm{ROC}^{*}\) can be accurately approximated by the (stepwise) \(\mathrm{ROC}\) curve of a piecewise constant scoring function. Because the goal of this paper is to highlight the nature of active bipartite ranking rather than treating the problem in full generality, various simplifying assumptions are made in the subsequent analysis. For simplicity we suppose that \(\mathcal{X}=[0,1)\) and introduce the grid points \(\{G_{1},...,G_{K}\}=\{i/K:\ \ i=1,\ \ldots,\ K-1\}\), where \(K\geq 1\). A preorder on \(\mathcal{X}\) can be then naturally defined by means of a permutation \(\sigma\in\mathfrak{S}_{K}\). Consider indeed the scoring function

\[s_{\sigma}(x):=\sum_{i=1}^{K}i\cdot\mathbb{I}\{x\in[G_{\sigma(i)},\ G_{\sigma( i+1)})\}.\] (1)

We denote by \(\mathcal{S}_{K}\) the set of all functions of type (1). To avoid dealing with model bias here, we assume that the optimal preorder, that induced by \(\eta(x)\) namely, can be defined by a scoring function in \(\mathcal{S}_{K}\).

**Assumption 2.1**.: There exist a permutation \(\sigma\in\mathfrak{S}_{K}\) and distinct constants \(\mu_{1},\ \ldots,\ \mu_{K}\) in \((0,1)\) such that

\[\eta(x)=\sum_{i=1}^{K}\mu_{i}\cdot\mathbb{I}\{x\in[G_{\sigma(i)},\ G_{\sigma(i+ 1)})\}\ \text{for all}\ x\in[0,1)\.\]

We write \(p=\frac{1}{K}\sum_{i\in[K]}\mu_{i}\). We point out that, as \(\eta\) may remain constant over multiple sections of the grid, the permutation \(\sigma\) satisfying assumption 2.1, is not necessarily unique. In the subsequent analysis, the parameter \(K\) is supposed to be known, in contrast with the \(\mu_{i}\)'s, which have to be learned by means of an active strategy. As we assume no structure between the grid points, one can easily consider Assumption 2.1 in higher dimensions, simply consider the \(d\) dimensional grid of size \(K^{d}\). As such, all results presented in this paper **extend trivially to higher dimensions**.

**Policies and fixed confidence regime.** We denote the outputted scoring function of the learner \(\hat{s}\in S_{K}\). The way the learner interacts with the environment - i.e. their choice of points to query, how many samples to draw in total and their choice of \(\hat{s}\in S_{K}\), we term the _policy_ of the learner. We write \(\mathcal{C}\) for the set of all possible policies of the learner. For a policy \(\pi\in\mathcal{C}\) and problem \(\nu\in\mathcal{B}\) we denote random variable \(\tau^{\pi}_{\nu}\) as the stopping time of policy \(\pi\). We write \(\tilde{s}^{\pi}_{\nu}\) for the scoring function outputted by policy \(\pi\) on problem \(\nu\). Where obvious we may drop the dependency on \(\pi,\nu\) in the notation, referring to the scoring function outputted by the learner as simply \(\hat{s}\). We write \(\mathbb{P}_{\nu,\pi}\) as the distribution on all samples gathered by a policy \(\pi\) on problem \(\nu\). We similarly define \(\mathbb{E}_{\nu,\pi}\).

For the duration of this paper we will work in the _fixed confidence regime_. For a confidence level \(\varepsilon\), define, \(S^{\varepsilon}_{K}:=\{s\in S_{K}:d_{\infty}(s,\eta)\leq\varepsilon\}\). A policy \(\pi\) is said to be \(\text{PAC}(\delta,\varepsilon)\) (probably approximately correct), on the class of problems \(\mathcal{B}\), if, \(\forall\nu\in\mathcal{B},\mathbb{P}_{\nu,\pi}[\hat{s}\in S^{\varepsilon}_{K}] \geq 1-\delta\). The goal of the learner is to then obtain a \(\text{PAC}(\delta,\varepsilon)\) policy \(\pi\), such that the expected stopping time in the worst case, \(\sup_{\nu\in\mathcal{B}}\mathbb{E}_{\nu,\pi}[\tau^{\pi}_{\nu}]\), is minimised.

**Defining problem complexity** The expected minimum number of samples a policy must draw on a certain problem, \(\nu\in\mathcal{B}\), to be \(\text{PAC}(\delta,\varepsilon)\) is a quantity which depends upon the features of \(\nu\), specifically, the shape of the posterior \(\eta\). When defining our measure of problem complexity we must capture this dependence as succinctly as possible. To build intuition for our definition we first explore a naive strategy and introduce some informative Lemmas. A naive approach to the active bipartite ranking problem, is to treat each pair of points on the grid, \(i,j\in[K]\) as a separate classification problem. To correctly distinguish the situations, \(\mathcal{H}^{i,j}_{0}:=\mu_{i}>\mu_{j}\), \(\mathcal{H}^{i,j}_{1}:=\mu_{i}<\mu_{j}\), with probability greater than \(1-\delta\), it is well known, see e.g. Kaufmann et al. (2014), that for small \(\delta\), the minimum number of samples required is of the order \(\frac{\log(1/\delta)}{\mathrm{kl}^{*}(\mu_{j},\mu_{i})}\), where we remind the reader \(\mathrm{kl}^{*}\) is the the Chernoff Information, closely related to the \(\mathrm{kl}\) divergence, see Section 2.1. Thus, if the learner wished to output a scoring function in \(S^{*}\), the sample complexity would be of the order, \(\sum_{i\in[K]}\frac{\log(1/\delta)}{\min_{j\in[K]}(\mathrm{kl}^{*}(\mu_{j}, \mu_{i}))}\). Of course, distinguishing between \(\mathcal{H}^{i,j}_{0}\) and \(\mathcal{H}^{i,j}_{1}\) is impractical when \(\mu_{i}\) and \(\mu_{j}\) are very close, or even equal. However, in our regime, the learner is not required to correctly rank every pair of points \(i,j\in[K]\), only to output a scoring function existing in \(S^{\varepsilon}_{K}\). Intuition indicates that the learner may be irreventent to the ranking within certain groups of points on the gird, as long as there posterior values are sufficiently close. For instance, consider a partition of \([0,1]\), \(\mathcal{P}=\{C_{1},C_{2},C_{3}\}\), and increasing sequence \((\beta_{1},\beta_{2},\beta_{3})\in[0,1]^{3}\) with

\[\eta(x)=\sum_{i=1}^{3}\mathbb{I}(x\in C_{i})\beta_{i},\qquad\tilde{s}(x)= \mathbb{I}(x\in C_{1})+2\mathbb{I}(x\in\{C_{2}\cup C_{3}\})\;,\] (2)

Where the scoring function function \(\tilde{s}\) essentially, treats all points of \(C_{2},C_{3}\) of the same rank. See Figure 1 for the ROC curves of \(\eta\) and \(\tilde{s}\). Via simple calculation, we have the following, \(d_{\infty}(\eta,\tilde{s})=\frac{\lambda(C_{3})}{p}\frac{(\beta_{3}-\beta_{2}) /2}{1-(\beta_{3}+\beta_{2})/2}\), which suggests that, whether or not there exists a scoring function in \(S^{\varepsilon}_{K}\), which treats the groups \(C_{2},C_{3}\) of the same rank, depends upon two things, the size of the groups and also their position on the ROC curve. Specifically, if \(\beta_{3}-\beta_{2}\geq\frac{2\varepsilon p(1-(\beta_{3}+\beta_{2})/2)}{ \lambda(C_{3})}\), then \(\tilde{s}\notin S^{\varepsilon}_{K}\). The following lemma formalises this intuition, the proof follows via a direct generalisation of the above example.

**Lemma 2.2**.: _Let \(\Delta>0\), \(i\in[K]\) and define \(S^{(i,\Delta)}_{K}\) as the set of scoring functions such that, for all \(s\in S^{(i,\Delta)}_{K}\), one has that \(\forall j:|\mu_{j}-\mu_{i}|\geq\Delta,\ \mathrm{sign}(s(i)-s(j))=\mathrm{sign}(\mu_{i}-\mu_{j})\). There exist a \(\tilde{s}\in S^{(i,\Delta)}_{K}\), \(\nu\in\mathcal{B}\), such that on problem \(\nu\), \(d_{\infty}(\eta,\tilde{s})\geq\frac{\Delta|(j:|\mu_{i}-\mu_{j}|\leq\Delta)|}{p( 1-\mu_{i})}\)._

Lemma 2.2 suggests that the for \(i\in[K]\) the learner must be _at least_ able to distinguish \(\mathcal{H}^{i,j}_{0}\) vs \(\mathcal{H}^{i,j}_{1}\), for all \(j:|\mu_{i}-\mu_{k}|\leq\tilde{\Delta}_{i}\), where, \(\tilde{\Delta}_{i}:=\max\left\{x>0:\sum_{i\neq j}x\mathbb{I}\big{(}|\mu_{i}- \mu_{j}|\leq x\big{)}<K\varepsilon p(1-\mu_{i})\right\}\).

The following Lemma shows that \(\tilde{\Delta}_{i}\) is not only an upper bound on the necessary order of the confidence level around \(\mu_{i}\) but also a lower bound, the proof of which can be found in the proof of Theorem 3.2.

**Lemma 2.3**.: _For a problem \(\nu\in\mathcal{B}\), let \(s\in S_{K}\) be a scoring function such that the following holds, \(\forall i\in[K]\),_

\[\forall j:|\mu_{j}-\mu_{i}|\geq\tilde{\Delta}_{i}/4,\ \mathrm{sign}(s(i)-s(j))= \mathrm{sign}(\mu_{i}-\mu_{j})\]_then \(s\in S_{K}^{e}\)._

Under the conditions where \(K\varepsilon p>1\) and for a grid point \(i\in[K]\), \(\mu_{i}\) is close to one, a certain phenomenon occurs. Specifically, when \(\tilde{\Delta}_{i}\geq 1-\mu_{i}\), for the learner to know the value of \(\mu_{i}\) up to an error of \(\tilde{\Delta}_{i}\) is no longer sufficient, as in such a case, to the best of the learners knowledge, the value of \(\mu_{i}\) may be arbitrarily close to 1, and thus have an arbitrarily large effect on the regret. With this in mind, we define \(\Delta_{i}\) as follows,

\[\Delta_{i}:=\max\left\{x>0:\sum_{i\neq j}x\mathbb{I}\big{(}|\mu_{i}-\mu_{j}|\leq x \big{)}<K\varepsilon p(1-\mu_{i})\right\}\wedge(1-\mu_{i})\]

Note that in the case where \(K\varepsilon p<1\), we have \(\Delta_{i}=\tilde{\Delta}_{i}\). In the case where \(\mu_{i}\geq\Delta_{i}\), we thus define the complexity at a point \(i\in[K]\) as \(H_{i}^{(1)}=\frac{1}{\mathrm{kl}(\mu_{i},\mu_{i}+\Delta_{i})\wedge\mathrm{kl} (\mu_{i},\mu_{i}-\Delta_{i})}.\) If \(\mu_{i}\leq\Delta_{i}\), \(H_{i}^{(1)}=\frac{1}{\mathrm{kl}(\mu_{i},\mu_{i}+\Delta_{i})}\). For a problem \(\nu\in\mathcal{B}\), the total problem complexity is then given as \(\sum_{i\in[K]}H_{i}^{(1)}\). As an illustrative example, see Figure 2 for the complexity of \(i\in[K]\) with \(\eta\) defined as in Scenario 1 of the experiments, see section 4.

There is a natural comparison to multi armed bandits, where the problem complexity is typically given as the summation across the individual complexity of each arm. However, in most multi armed settings the complexity of a single arm is dependent upon its distance to a single other arm, e.g. the optimal arm, whereas in our setting the complexity of a single grid point \(i\in[K]\) has a more complex dependency on the shape of the posterior around \(G_{i}\).

### Performance of the passive approach

At this point we can consider how a uniform sampling strategy would perform, that is, the learner simply draws a sample from each section of the grid in turn. This would be essentially a _passive approach_, in line with the classical batch setting. For a uniform/passive sampling strategy to be PAC\((\varepsilon,\delta)\) one would have to draw samples until the width of the confidence interval at all points \(i\) is less than \(\Delta_{i}\). Therefore, a uniform sampling strategy, with an appropriate stopping rule, would have the following tight upper bound on its expected sampling time, up to log terms, \(cK\max_{i\in[K]}\frac{1}{\mathrm{kl}(\mu_{i},\mu_{i}+\varepsilon\Delta_{i})},\) for some absolute constants \(c,c^{\prime}>0\). The improvement we hope to gain in the active setting is to replace the \(\max\) with a weighted summation across the grid. Thus, in settings where the \(\Delta_{i}\) are relatively constant across large sections of the grid, then the theoretical performance of a passive approach can be close to optimal. In contrast, in cases where a very small section of the interval is hard to rank and the rest is easy - i.e. \(K\max_{i\in[K]}\frac{1}{\mathrm{kl}(\mu_{i},\mu_{i}+\Delta_{i})}\) is much greater than \(\sum_{i\in[K]}\frac{1}{\mathrm{kl}(\mu_{i},\mu_{i}+\Delta_{i})}\), a passive approach will fail. Such settings involve large \(K\) where the gaps \(\Delta_{i}\) on the majority of cells are large, with a relatively small number of cells with small gaps \(\Delta_{i}\). Incidentally, we point out that this corresponds to many situations of interest in practice (ininformation retrieval, for a specific request, the vast majority of the documents are equally irrelevant, while the ranking of a very small fraction of relevant documents is challenging; the same phenomenon is also observed in credit-risk screening). In these cases the benefit to the practitioner, will be that they quickly focus on the interesting sections of the feature space.

### Related literature in active learning

While, to the best of our knowledge, Bipartite Ranking has not yet been considered under active learning, there are several related settings. Firstly, it is important to note, that as we assume the posterior \(\eta\) is piecewise constant on the grid of size \(K\), we can view our problems as a \(K\) armed bandit. In the case where \(K=2\) the bipartite ranking problem becomes akin to best arm identification (BAI) for the two armed bandit, also known as A/B-Testing. In BAI for the two armed bandit, the learner sequentially draws samples from two distributions \(\nu_{A},\nu_{B}\) with respective means \(\mu_{A},\mu_{B}\). Their objective is then carry out the hypothesis test, \(\mathcal{H}_{0}:=(\mu_{A}\leq\mu_{B})\), \(\mathcal{H}_{1}:=(\mu_{a}>\mu_{B})\) in as few samples as possible. A/B Testing is considered in an active, fix confidence regime, in Kaufmann and Kalyanakrishnan (2013), wherein they prove a lower bound on the expected sampling time of any PAC\((\varepsilon,\delta)\) as of the order \(\frac{\log(1/\delta)}{\operatorname{\mathrm{I}}[\operatorname{\mathrm{I}}(\mu_ {A},\mu_{B})}\). Note that, in the case where \(K=2\) active-rank matches said lower bound up to logarithmic terms. In the fixed confidence regime, the BAI problem has also been generalised for larger \(K>2\) - see Garivier and Kaufmann (2016),Jamieson and Talwalkar (2016) along with the TopM problem, where the learner must output the \(M\) best arms - see Kaufmann et al. (2014), Kalyanakrishnan et al. (2012), however, for \(K>2\) both BAI and TopM problems are no longer comparable to our setting.

Aside from BAI and the TopM problem, there are several other settings in active learning that, while not directly comparable to our own, are worth mentioning. The first is active clustering. Several works have considered clustering in an online framework, see Choromanska and Monteleoni (2012), Liberty et al. (2016), Cohen-Addad et al. (2021) and Khaleghi et al. (2012). In the above works new observations from certain arms become available to the learner at each time step, however the learner does not actively choose which arms to pull and therefore the flavour of the above literature is very different to our setting. Much closer is the work of Yang et al. (2022) in which the authors consider a active clustering problem, represented as \(K\) armed \(d\) dimensional bandit, where the arms are split into \(M\) clusters. They work in a PAC\((\delta)\) setup where their goal is to recover the entire clustering of the arms, with probability greater than \(1-\delta\) in as few samples as possible. Comparing to our setting, if one is to view a section of the grid on which \(\eta\) is constant as a single cluster, by retrieving the clustering of the arms one can then easily do ranking. Their results differ to our own in several key ways though. Firstly their algorithm takes the number of clusters \(M\) as a parameter, this highlights the main difference between their setting and our own. In the Bipartite ranking problem, assuming \(\varepsilon\) is not very small, one does not have to recover exactly all the clusters to ensure regret under the \(d_{\infty}\) norm is less than \(\varepsilon\). Therefore we do not need to know the number of clusters and our algorithm must be able to exploit larger \(\varepsilon\) to achieve smaller stopping times. The second key difference is that the results of Yang et al. (2022) are hold only in the asymptotics, that is as \(\delta\to 0\). Their algorithm employs a forced exploration phase, which ensures each arm is pulled at at least a sub linear rate. Essentially, this means that in such an asymptotic setting, _the means of the arms are known to the learner_, which naturally drastically changes the nature of their results. Extension to bounds for fixed \(\delta>0\) would be none trivial, noted as potential future work in Yang et al. (2022), and essential if one were to compare to our confidence setting.

Also of note is active multi class classification. In Krishnamurthy et al. (2017) they consider a cost sensitive classification problem, where the learner receives input examples \(x\in\mathcal{X}\) and cost vectors \(c\in\mathbb{R}^{K}\), where \(c(y)\) is the cost of predicting label \(y\) on \(x\). For each input example received the learner is able to query a subset of labels. The objective is to then train a classifier with minimal expected loss in as few queries as possible. The results of Krishnamurthy et al. (2017) cannot be directly compared to our own, as in our setting there is no such thing as the cost of a classifier at a given point \(x\in\mathcal{X}\), as the cost miss ranking a section of \([0,1]\) is dependent on our ranking of the entire feature space.

## 3 Our results

### The active-rank Algorithm

Our algorithm active-rank maintains an active set of grid points across several rounds. At the beginning of each round active-rank draws a sample, uniformly, from all points of the grid in the active set and at the end of each round, eliminates points from the active set based on a specific criterion. We track the empirical mean of all samples drawn from the \(i\)th point of the grid, \([G_{i},G_{i+1})\) up to round \(t\) as \(\hat{\mu}_{i}^{t}\). At the beginning of each round \(t\), for each grid point \(i\in[K]\), we will maintain an upper and lower confidence bound, on \(\mu_{i}\), which we term the UCB and LCB index respectively. At time \(t\), for each grid point \(i\in[K]\) and exploration parameter \(\beta(t,\delta):\mathbb{N}\times[0,1]\rightarrow\mathbb{R}_{+}\), remaining in the active set, we then define the LCB index,

\[\mathrm{LCB}(t,i):=\min\biggl{\{}q\in\bigl{[}0,\hat{\mu}_{i}^{t} \bigr{]}:\mathrm{kl}\bigl{(}\hat{\mu}_{i}^{t},q\bigr{)}\leq\frac{\beta(t, \delta)}{t}\biggr{\}}\;,\] (3)

and the UCB index,

\[\mathrm{UCB}(t,i):=\max\biggl{\{}q\in\bigl{[}\hat{\mu}_{i}^{t},1 \bigr{]}:\mathrm{kl}\bigl{(}\hat{\mu}_{i}^{t},q\bigr{)}\leq\frac{\beta(t, \delta)}{t}\biggr{\}}\;.\] (4)

Let \(S_{t}\) denote the active set at the beginning of round \(t\), via careful choice of exploration parameter the following Lemma holds, the proof of which can be found in Section A of the supplementary material.

**Lemma 3.1**.: _We have that, the event_

\[\mathcal{E}=\bigcap_{t\in\mathbb{N}}\bigcap_{i\in[S_{t}]}\{\mu_{k} \in[\mathrm{LCB}(t,i),\mathrm{UCB}(t,i)]\}\;,\]

_occurs with probability greater than \(1-\delta\)._

For \(i\in[K]\), time \(t\) and \(z\in\mathbb{R}\) define, \(U_{i,t}(z):=\bigl{\{}j\in S_{t}:j\neq i,|\widehat{\mu}_{i}^{t}-\widehat{\mu}_ {j}^{t}|\leq z\bigr{\}}\). Following Lemma 2.2, our intuition would be to then remove a point \(i\) from the active set if, \(\bigl{|}U_{i,t}\bigl{(}\mathrm{UCB}(i,t)-\mathrm{LCB}(i,t)\bigr{)}\bigr{|} \leq\frac{c\mathcal{E}\varepsilon p(1-\widehat{\mu}_{i,t})}{\|\mathrm{CBB}(i,t)-\mathrm{LCB}(i,t)\|}\), for some well chosen constant \(c>0\). However, due to the technical difficulty of the proof, we make the following concession. For \(t>0\), let \(S_{t}\) be the list \(S\) at time \(t\). At time \(t\) let \(\Delta_{(t)}=\max_{i\in S_{t}}(\mathrm{UCB}(t,i)-\mathrm{LCB}(t,i))\). Furthermore, at time \(t\) define the set of grid points,

\[\mathcal{Q}_{t}:=\biggl{\{}i\in[K]:\Delta_{(t)}\leq\frac{1}{24} \biggl{(}\frac{K\varepsilon\widehat{p}_{t}}{|U_{i,t}(6\Delta_{(t)})|}\wedge 1 \biggr{)}(1-\widehat{\mu}_{i}^{t})\biggr{\}}\;.\] (5)

If a point exists in \(\mathcal{Q}_{t}\), we remove it from the active set. Note that active-rank does not take the average of the posterior \(p\) as a parameter. Instead we show it is possible to use an estimate \(\widehat{p}_{t}\) which updates round by round.

Elimination algorithms such as active-rank have seen wide usage in the literature for BAI, see In Paulson (1964),Mannor and Tsitsiklis (2004), Even-Dar et al. (2002) and Even-Dar et al. (2006). However, closer to our work is the Racing algorithm Kaufmann and Kalyanakrishnan (2013), designed for the TopM problem, where, as in our approach, the confidence bounds used are based on the kl divergence as opposed to Hoeffdings. Their elimination criterion, however, differs considerably to our own. For simplicity let us consider the Top1 problem, that is BAI - the following arguments can be extended in the case of TopM. The racing algorithm of Kaufmann and Kalyanakrishnan (2013) eliminates an arm \(i\in[K]\) from the active set, at time \(t\), when, the positive gap the lower confidence bound around the highest empirical mean and the upper confidence bound at point \(i\) is greater than \(\varepsilon\). However, due to the global nature of the ranking problem, in our setting, the decision to remove a point from the active set is not made based on the distance to another single point. We rather consider a condition on the local smoothness of the posterior around the point \(i\). An additional difficulty that arises here is that the local smoothness around a point can potentially depend upon points no longer in the active set and once a point is no longer in the active set, we essentially have no control of the width of its confidence interval.

**Proving** active-rank **is PAC\((\varepsilon,\delta)\) and upper bounding the expected sampling time** Theorem 3.2 demonstrates that our algorithm active-rank is PAC\((\varepsilon,\delta)\) and provides a problem dependent upper bound on it's expected sampling time. The proof can be found in Section A of the supplementary material. Theorem 3.2 makes no assumption on the posterior \(\eta\), aside from it being piecewise constant on the grid of size \(K\), i.e. Assumption 2.1. For \(i\in[K]\), set \(H_{i}^{(2)}=\max_{j\in[K]}\Bigl{(}\frac{1}{\operatorname{\mathbb{R}}(\mu_{j}, \mu_{j}+\Delta_{i}/8)}\vee\frac{1}{\operatorname{\mathbb{R}}(\mu_{j},\mu_{j} -\Delta_{i}/8)}\Bigr{)}\).

**Theorem 3.2**.: _For \(\varepsilon,\delta>0,\gamma>480/\log(K)\), with \(\beta(t,\delta)=c_{\gamma}\log(t^{2}K^{2}/\delta)\) where \(c_{\gamma}\) is a constant depending only on \(\gamma\), on all problems \(\nu\in\mathcal{B}\), on execution of active-rank, with output \(\hat{s}\), we have that,_

\[d_{\infty}(\hat{s},\eta)\leq\varepsilon\,\]

_with probability greater than \(1-\delta\). Furthermore, the expected stopping time of active-rank is upper bounded by the following,_

\[c_{\gamma}^{\prime}\sum_{i\in[K]}H_{i}^{(2)}\log\Bigl{(}c_{\gamma}^{\prime \prime}H_{i}^{(2)}K/\delta\Bigr{)}\,\]

_where \(c_{\gamma}^{\prime}\), \(c_{\gamma}^{\prime\prime}\), are constants depending only on \(\gamma\)._

Lower boundTheorem 3.3 provides a problem dependent lower bound on the expected sampling time of any PAC\((\varepsilon,\delta)\) policy. The proof of Theorem 3.3 can be found in Section B of the supplementary material.

**Theorem 3.3**.: _Let \(\varepsilon\in[0,1/4),0<\delta<1-\exp(-1/8)\) and \(\nu\in\mathcal{B}\) such that \(K\varepsilon p<1/8\). For any PAC\((\varepsilon,\delta)\) policy \(\pi\), there exists a problem \(\bar{\nu}\in\mathcal{B}\) such that, for all \(i\in[K]\), \(\bar{\Delta}_{i}\geq\Delta_{i}/2\) where \(\bar{\Delta}_{i}\) is the gap of the \(i\)th grid point on problem \(\bar{\nu}\), where the expected stopping time of policy \(\pi\) on problem \(\bar{\nu}\) is bounded as follows,_

\[\mathbb{E}_{\bar{\nu},\pi}\bigl{[}\tau_{\pi}^{\bar{\nu}}\bigr{]}\geq c^{\prime }\sum_{i\in[K]}\bar{H}_{i}^{(1)}\,\]

_where \(c^{\prime}>0\) is an absolute constant and \(\bar{H}_{i}^{(1)}\) is the complexity of point \(i\) on problem \(\bar{\nu}\). Furthermore we have that,_

\[\sum_{i\in[K]}\bar{H}_{i}^{(1)}\geq c\sum_{i\in[K]}H_{i}^{(1)}\,\]

_where \(c>0\) is an absolute constant._

The proof of Theorem 3.3 follows from a novel application of a Fano type inequality on a well chosen set of problems.

Gap between upper and lower boundThere are essentially two components in the gap between the bounds of Theorems, 3.3 and 3.2. The first is the additional logarithmic dependency upon \(K\) present in our upper bound. Despite being logarithmic this dependence is potentially significant, as in practical situations, the size of grid needed, for the assumption that the posterior \(\eta\) is piecewise constant, may be very large. The second component, in the gap between upper and lower bounds is the difference in the \(H_{i}^{(1)}\) and \(H_{i}^{(2)}\) terms. The reason \(H_{i}^{(2)}\) appears in Theorem 3.2 is that, the decision to remove a point \(i\in[K]\) from our active set is made based on the minimum width of confidence interval across the entire grid, \(\Delta_{(t)}\) as opposed to the local width at \(i\), \(\operatorname{UCB}(i,t)-\operatorname{LCB}(i,t)\), see Equation (5). As we are dealing with Bernoulli distributions and kl divergence based confidence bounds, for a fixed number of samples, points close to zero or one will have tighter confidence boundsand thus may be sampled more than is necessary. If one were to assume that the posterior \(\eta\) exists solely in the interval \([\gamma,1-\gamma]\) for some \(\gamma>0\), then for all \(i\in[K]\), \(H_{i}^{(2)}\) and \(H_{i}^{(1)}\) will be with a constant factor of each other, with that constant depending on \(\gamma\).

In authors opinion, both the logarithmic dependency on \(K\) and usage of \(\Delta_{(t)}\) may be removed. However, this would require several non trivial modifications to the proof of Theorem 3.2, see the discussion in Section A of the supplementary material for details. As, to the best of our knowledge, this is the first work to consider the bipartite ranking problem in an active learning setting, we present Theorem 3.2 as it stands and leave the aforementioned improvements for future works.

## 4 Experiments

In this section we discuss practical cases based on synthetic data. For all experiments \(\delta\) is fixed at \(0.01\) and the constants used are smaller than their theoretical counterparts, which are typically overestimated, furthermore \(\widehat{p}\) is calculated with all previous samples. As represented in Figure 3, each cell \(i\) is assigned a level value \(\mu_{i}\) so that \(\eta\) follows the Assumption 2.1. Without loss of generality, we assume that \(\eta\) can be described as an increasing family \((\mu_{i})_{i\in[K]}\). Our study scenarios are then as follows:

* Scenario 1: \((\mu_{i})_{i\in[K]}=(0,0.28,0.3,0.38)\) and \(K=16\);
* Scenario 2: \((\mu_{i})_{i\in[K]}=(0.8((i-1)/K)^{4}+0.1)_{i\in[K]}\) and \(K=64\);
* Scenario 3: \((\mu_{i})_{i\in[K]}\) is sub-sampled (with replacement) of \(((i-1)/K)^{4})_{i\in[100]}\) and \(K=64\)
* Scenario 4: \(\mu_{i}=0.8((i-1)/K)+0.1\,\forall i\in[K]\backslash\{7,8\}\) with \(\mu_{7}=0.8(6/K)+0.3\), \(\mu_{8}=0.8(7/K)-0.1\) and \(K=16\)

The objective of these scenarios is to evaluate the capacity of the algorithm on different cases. As shown in Figure 3, scenarios 1 and 3 will have variable jumps and cell sizes.

Competing algorithmsTo our knowledge there is no algorithm dealing with the active learning for bipartite ranking problem, we thus compare to the following naive approaches. **Passive rank**: each new point \(a_{t}\) is drawn uniformly on \([0,1]\). **Naive rank**: each new point \(a_{t}\) is sampled in \(P_{i_{t}}\) s.t. \(i_{t}:=\operatorname*{arg\,max}_{i\in[K]}\operatorname{UCB}(t,i)- \operatorname{LCB}(t,i)\), this algorithm reduces the bias in an undifferentiated way without considering the problem as global (requiring peer-to-peer comparison). **Active classification**: for this algorithm we consider binary classification with threshold \(0.5\). The set of active cells \(S\), as defined in Algorithm 1 is then \(S_{t}=\{i\in[K];0.5\in[\hat{\mu}_{i}^{t}-\operatorname{LCB}(t,i);\hat{\mu}_{i }^{t}+\operatorname{UCB}(t,i)]\}\cup\left\{i;\underset{i\in[K]}{\text{argmin}}( |0.5-\hat{\mu}_{i}^{t}|)\right\}\). As the competing algorithms do not output a stopping time, for a single \(\eta\), algorithm active-rank is run across several values of \(\varepsilon\), following a geometric sequence of common ratio \(0.99\) and initial value \(1\). The values of \(\varepsilon\) then plotted against the respective stopping times of active-rank.

Interpretation of resultsOn scenario 1, the simplest case, and to an extent scenario 2, active-rank and passive suffer near identical regret for larger sample sizes. On all other scenarios active-rank outperforms all competitors. The fact that active-rank does not reach extremely small values of regret suggests that analysis for much higher sample size may be interesting, however this creates issues in computation time, the same goes for larger \(K\). Also, the uniform

Figure 3: Different scenarios chosen for the experiments

approach still performs relatively well, and appears difficult to fool. Some more work may be needed to find a setting in which uniform sampling suffers considerably.

## 5 Conclusion

To the best of our knowledge we have developed the first rigorous framework for the active bipartite ranking problem and our algorithm, active-rank, is the first to tackle said problem. Our upper bound on performance of active-rank matches our lower bound up to logarithmic terms, in the case where the posterior \(\eta\) is not very close to 0 or 1 at any point. As well as theoretical guarantees we have demonstrated good practical performance of active-rank, on synthetic data, in various settings. We conclude with some perspectives for future research.

An obvious path for future research, is to replace the Assumption 2.1 with a smoothness assumption on the posterior \(\eta\), e.g. a Holder condition. The setting would then be equivalent to a continuous armed bandit as opposed to a finite armed bandit. Assuming the learner has knowledge of the Holder coefficient, a standard approach in continuous armed bandits is to first discretise and then apply classic techniques from finite armed bandits, carefully choosing the discretisation level to balance the discretisation error and classical regret. It is of our opinion that such an approach would not be sufficient in our case. We conjecture that to achieve optimal or near optimal performance the learner must vary the level of discretisation across the feature space, based on the flatness of the posterior function \(\eta\) and placement on the ROC curve. Also, under such a Holder condition, the extension to higher dimensions would no longer be immediate.

## References

* Agarwal et al. (2005) Agarwal, S., Graepel, T., Herbrich, R., Har-Peled, S., and Roth, D. (2005). Generalization bounds for the area under the ROC curve. _J. Mach. Learn. Res._, 6:393-425.
* Choromanska and Monteleoni (2012) Choromanska, A. and Monteleoni, C. (2012). Online clustering with experts. In _Artificial Intelligence and Statistics_, pages 227-235. PMLR.
* Clemencon and Robbiano (2011) Clemencon, S. and Robbiano, S. (2011). Minimax learning rates for bipartite ranking and plug-in rules. In _Proceedings of ICML_, number 1.
* Clemencon and Vayatis (2008) Clemencon, S. and Vayatis, N. (2008). Overlaying classifiers: a practical approach for optimal scoring. _Constructive Approximation_,..
* Clemencon and Vayatis (2009) Clemencon, S. and Vayatis, N. (2009). Tree-based ranking methods. _IEEE Transactions on Information Theory_, 55(9):4316-4336.
* Clemencon et al. (2008) Clemencon, S., Lugosi, G., and Vayatis, N. (2008). Ranking and Empirical Minimization of U-Statistics. _The Annals of Statistics_, 36(2):844-874.
* Clemencon et al. (2012)

Figure 4: Regret estimated by Monte Carlo for 100 realizations of each algorithm, corresponding to the scenarios of the figure 3 respectively.

Clemencon, S. and Vayatis, N. (2009). On partitioning rules for bipartite ranking. In van Dyk, D. and Welling, M., editors, _Proceedings of the Twelfth International Conference on Artificial Intelligence and Statistics_, volume 5 of _Proceedings of Machine Learning Research_, pages 97-104, Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA. PMLR.
* Cohen-Addad et al. (2021) Cohen-Addad, V., Guedj, B., Kanade, V., and Rom, G. (2021). Online k-means clustering. In _International Conference on Artificial Intelligence and Statistics_, pages 1126-1134. PMLR.
* Even-Dar et al. (2002) Even-Dar, E., Mannor, S., and Mansour, Y. (2002). Pac bounds for multi-armed bandit and markov decision processes. In _International Conference on Computational Learning Theory_, pages 255-270. Springer.
* Even-Dar et al. (2006) Even-Dar, E., Mannor, S., and Mansour, Y. (2006). Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems. _Journal of machine learning research_, 7(Jun):1079-1105.
* Garivier and Kaufmann (2016) Garivier, A. and Kaufmann, E. (2016). Optimal best arm identification with fixed confidence. In _Conference on Learning Theory_, pages 998-1027. PMLR.
* Jamieson and Talwalkar (2016) Jamieson, K. and Talwalkar, A. (2016). Non-stochastic best arm identification and hyperparameter optimization. In _Artificial intelligence and statistics_, pages 240-248. PMLR.
* Kalyanakrishnan et al. (2012) Kalyanakrishnan, S., Tewari, A., Auer, P., and Stone, P. (2012). Pac subset selection in stochastic multi-armed bandits. In _ICML_, volume 12, pages 655-662.
* Kaufmann et al. (2014) Kaufmann, E., Cappe, O., and Garivier, A. (2014). On the complexity of a/b testing. In _Conference on Learning Theory_, pages 461-481. PMLR.
* Kaufmann and Kalyanakrishnan (2013) Kaufmann, E. and Kalyanakrishnan, S. (2013). Information complexity in bandit subset selection. In _Conference on Learning Theory_, pages 228-251. PMLR.
* Khaleghi et al. (2012) Khaleghi, A., Ryabko, D., Mary, J., and Preux, P. (2012). Online clustering of processes. In _Artificial Intelligence and Statistics_, pages 601-609. PMLR.
* Krishnamurthy et al. (2017) Krishnamurthy, A., Agarwal, A., Huang, T., III, H. D., and Langford, J. (2017). Active learning for cost-sensitive classification. _CoRR_, abs/1703.01014.
* Liberty et al. (2016) Liberty, E., Sriharsha, R., and Sviridenko, M. (2016). An algorithm for online k-means clustering. In _2016 Proceedings of the eighteenth workshop on algorithm engineering and experiments (ALENEX)_, pages 81-89. SIAM.
* Mannor and Tsitsiklis (2004) Mannor, S. and Tsitsiklis, J. N. (2004). The sample complexity of exploration in the multi-armed bandit problem. _Journal of Machine Learning Research_, 5(Jun):623-648.
* Menon and Williamsson (2016) Menon, A. and Williamsson, R. (2016). Bipartite ranking: A risk theoretic perspective. _Journal of Machine Learning Research_, 7:1-102.
* Paulson (1964) Paulson, E. (1964). A sequential procedure for selecting the population with the largest mean from k normal populations. _The Annals of Mathematical Statistics_, 35(1):174-180.
* Yang et al. (2022) Yang, J., Zhong, Z., and Tan, V. Y. (2022). Optimal clustering with bandit feedback. _arXiv preprint arXiv:2202.04294_.

Proof of theorem 3.2

Before the proof of Theorem 3.2 we prove some initial lemmas, the first of which is Lemma 3.1, which lower bounds the probability of our favourable event \(\mathcal{E}\) by \(1-\delta\). We prove a slightly extended version of Lemma 3.1. At time \(t\), define the LCB index of \(\widehat{p}\) as,

\[\mathrm{LCB}(t,0):=\min\biggl{\{}q\in[0,\widehat{p}_{t}]:\mathrm{kl}(\widehat{ p}_{t},q)\leq\frac{\beta(t,\delta)}{t}\biggr{\}}\;,\] (6)

and the UCB index,

\[\mathrm{UCB}(t,0):=\max\biggl{\{}q\in[\widehat{p}_{t},1]:\mathrm{kl}(\widehat{ p}_{t},q)\leq\frac{\beta(t,\delta)}{t}\biggr{\}}\;.\] (7)

Note that as \(\widehat{p}_{t}\in[\min(\mu_{i}^{t}),\max(\mu_{i}^{t})]\), we have that,

\[\mathrm{UCB}(0,t)-\mathrm{LCB}(0,t)\leq\Delta_{(t)}\;.\]

The extended version of Lemma 3.1 is then as follows,

**Lemma A.1**.: _We have that, the event_

\[\mathcal{E}=\bigcap_{t\in\mathbb{N}}\bigcap_{i\in[S_{t}]\cup\{0\}}\{\mu_{k} \in[\mathrm{LCB}(t,i),\mathrm{UCB}(t,i)]\}\;,\]

_occurs with probability greater than \(1-\delta\)._

Proof.: Via Chernoff's inequality, for \(i\in[K]\cup\{0\}\), at time \(t\) we have that,

\[\mathbb{P}(\mathrm{LCB}(t,k)\geq\mu_{k})\leq\exp(-\beta(t,\delta))\;,\]

and,

\[\mathbb{P}(\mathrm{UCB}(t,k)\leq\mu_{k})\leq\exp(-\beta(t,\delta))\;.\]

It then remains to note that via our choice of exploration parameter and a union bound,

\[2\sum_{t\in\mathbb{N}}\sum_{k\in[K]\cup\{0\}}\exp(-\beta(t,\delta))\leq\delta\;,\]

and the result follows. 

The following Lemma shows that, on rounds in which a point is removed from the active set, our estimate \(\widehat{p}\) remains within a constant factor of the true \(p\).

**Proposition A.2**.: _On event \(\mathcal{E}\) we have that, for all rounds \(t\) such that a point is removed from the active set, \(2p/3\leq\hat{p}_{t}\leq 4p/3\)._

Proof.: Let \(t\) be a round in which a point is removed from the active set. On event \(\mathcal{E}\), for all \(i\in[K]\),

\[|\mu_{i}-\hat{\mu}_{i}^{t}|\leq\Delta_{(t)}\;,\]

we thus have \(|p-\hat{p}|\leq\Delta_{(t)}\) which, in combination with the fact \(\Delta_{(t)}\leq\hat{p}/4\), implies \(\Delta_{(t)}\leq(\widehat{p}+\Delta_{(t)})/3\) and thus \(\Delta_{(t)}\leq p/3\).

For the purposes of the proof we split Theorem 3.2 into two parts. The first part is covered by the following lemma, which states that active-rank is PAC\((\varepsilon,\delta)\).

**Lemma A.3**.: _For \(\varepsilon,\delta>0\), \(1/K\geq\varepsilon p\) on all problems \(\nu\in\mathcal{B}\), on execution of active-rank, with output \(\hat{s}\), we have that,_

\[d_{\infty}(\hat{s},\eta)\leq\varepsilon\;,\]

_with probability greater than \(1-\delta\)._

[MISSING_PAGE_EMPTY:13]

For the first statement, assume \(j\in S_{t-1}\) and that \(\{k:|\mu_{j}-\mu_{k}|\}\subset S_{t-1}\), as otherwise we are done, via the inductive assumption. The point \(j\) is then removed from the active set at the end of round \(t+1\) and the statement thus follows via Proposition A.4.

For the second statement, for \(j\in S_{t-1}\) assume \(\{k:|\mu_{j}-\mu_{k}|\}\subset S_{t-1}\), as otherwise we are done via the inductive assumption. Therefore, there must exist such an \(k\), removed from the active set at the end of round \(t-1\), such that \(|\mu_{k}-\mu_{j}|\leq\Delta_{j}\). The result then follows via Proposition A.4. 

For a set \(C\subset[0,1]\), define,

\[\kappa(C):=\frac{1}{\lambda(C)}\int_{C}\eta(x)\,dx\.\]

Let \(\alpha\in[0,1]\), define the subset \(Z_{\alpha}\subset[0,1]\) such that, \(\mathbb{P}(X\in Z_{\alpha}|Y=-1)=\alpha\), that is,

\[\frac{\lambda(Z_{\alpha})(1-\kappa(Z_{\alpha}))}{1-p}=\alpha\,\]

and such that, for some \(i_{\alpha}\in[K]\),

\[\forall j:\mu_{j}>\mu_{i_{\alpha}},P_{j}\subset Z_{\alpha}\,\qquad\forall j:\mu_{j} <\mu_{i_{\alpha}},P_{j}\cap Z_{\alpha}=\emptyset\.\] (9)

We then have \(\mathrm{ROC}^{*}(\alpha)=\mathbb{P}(X\in Z_{\alpha}|Y=+1)=\frac{\lambda(Z_{ \alpha})(\kappa(Z_{\alpha}))}{p}\). The choice of \(Z_{\alpha}\) is not necessarily unique, and as \(\eta\) me be constant across multiple sections of the grid \(i_{\alpha}\) is also not necessarily unique, in this case we take arbitrary \(Z_{\alpha}\), \(i_{\alpha}\). Now define the subset \(\hat{Z}_{\alpha}\in[0,1]\) such that,

\[\frac{\lambda(\hat{Z}_{\alpha})(1-\kappa(\hat{Z}_{\alpha}))}{1-p}=\alpha\,\]

and,

\[\forall x\in\hat{Z}_{\alpha},y\notin\hat{Z}_{\alpha},s_{\hat{\mathcal{P}}}(x) \geq s_{\hat{\mathcal{P}}}(y)\,\]

so \(\mathrm{ROC}(s,\alpha)=\frac{\lambda(\hat{Z}_{\alpha})(\kappa(\hat{Z}_{\alpha} ))}{p}\). Again \(\hat{Z}_{\alpha}\) is not necessarily unique, in which case we choose arbitrarily. Via Propositions A.4 and A.5, we have that, \(\forall j\in[K]:|\mu_{j}-\mu_{i_{\alpha}}|\leq\Delta_{i_{\alpha}}\),

\[\mathrm{sign}(\widehat{\mu}_{j}^{\tau}-\widehat{\mu}_{i_{\alpha}}^{\tau})= \mathrm{sign}(\mu_{j}-\mu_{i_{\alpha}})\.\] (10)

Let

\[Z_{\alpha}^{\prime}=\{x\in Z_{\alpha}:|\eta(x)-\mu_{i_{\alpha}}|\leq\Delta_{i_ {\alpha}}\}\,\qquad\hat{Z}_{\alpha}^{\prime}=\{x\in\hat{Z}_{\alpha}:|\eta(x)-\mu_{i_{ \alpha}}|\leq\Delta_{i_{\alpha}}\}\.\]

Via Equation 10, we have that,

\[\mathrm{ROC}(\alpha,\eta)-\mathrm{ROC}(\alpha,s_{\hat{\mathcal{P}}})=\frac{ \lambda(Z_{\alpha}^{\prime})\kappa(Z_{\alpha}^{\prime})}{p}-\frac{\lambda( \hat{Z}_{\alpha}^{\prime})\kappa(\hat{Z}_{\alpha}^{\prime})}{p}\.\]

Before finalising the proof we must lower bound \(\lambda(\hat{Z}_{\alpha}^{\prime})\) and \(\kappa(\hat{Z}_{\alpha}^{\prime})\). We first lower bound \(\kappa(\hat{Z}_{\alpha}^{\prime})\).

\[\kappa(\hat{Z}_{\alpha}^{\prime})\geq\mu_{i_{\alpha}}-\Delta_{i_{\alpha}}\, \qquad\kappa(Z_{\alpha}^{\prime}),\leq\mu_{i_{\alpha}}+\Delta_{i_{\alpha}}\.\] (11)

We will now lower bound \(\lambda(\hat{Z}_{\alpha}^{\prime})\)

\[\frac{\lambda(\hat{Z}_{\alpha}^{\prime})}{\lambda(Z_{\alpha}^{\prime})}=\frac {1-\kappa(Z_{\alpha}^{\prime})}{1-\kappa(\hat{Z}_{\alpha}^{\prime})}\leq\frac {1-\mu_{i_{\alpha}}+\Delta_{i_{\alpha}}}{1-\mu_{i_{\alpha}}-\Delta_{i_{\alpha}} }\.\] (12)

Via combinations of Equations (11) and (12), we have,

\[\frac{\lambda(Z_{\alpha}^{\prime})\kappa(Z_{\alpha}^{\prime})}{p }-\frac{\lambda(\hat{Z}_{\alpha}^{\prime})\kappa(\hat{Z}_{\alpha}^{\prime})}{p} \leq\frac{1}{p}\Big{(}\lambda(Z_{\alpha}^{\prime})(\mu_{i_{\alpha}}+ \Delta_{i_{\alpha}})-\lambda(\hat{Z}_{\alpha}^{\prime})(\mu_{i_{\alpha}}- \Delta_{i_{\alpha}})\Big{)}\] (13) \[\leq\frac{1}{p}\bigg{(}\lambda(Z_{\alpha}^{\prime})(\mu_{i_{ \alpha}}+\Delta_{i_{\alpha}})-\lambda(Z_{\alpha}^{\prime})\frac{(\mu_{i_{ \alpha}}-\Delta_{i_{\alpha}})(1-\mu_{i_{\alpha}}+\Delta_{i_{\alpha}}))}{1-\mu_ {i_{\alpha}}-\Delta_{i_{\alpha}}}\bigg{)}\] (14) \[\leq\frac{2\lambda(Z_{\alpha}^{\prime})\Delta_{i_{\alpha}}}{p(1- \mu_{i_{\alpha}}-\Delta_{i_{\alpha}})}\leq\frac{2\lambda(Z_{\alpha}^{\prime}) \Delta_{i_{\alpha}}}{p(1-\mu_{i_{\alpha}})}\] (15)It remains to remark that, \(\Delta_{i_{\alpha}}\leq\frac{ep}{\lambda(Z_{\alpha}^{\prime})}\), by definition, and thus,

\[\mathrm{ROC}(\alpha,\eta)-\mathrm{ROC}\big{(}\alpha,s_{\hat{\mathcal{P}}}\big{)} \leq\varepsilon\.\]

As we chose \(\alpha\) w.l.o.g the proof then follows.

### Proof of stopping time for active-rank

We will now prove the second part of Theorem 3.2, the upper bound on the expected sampling time of active-rank.

**Lemma A.6**.: _For \(\varepsilon,\delta>0,\gamma>480/\log(K)\), \(1/K\geq p\varepsilon\), with \(\beta(t,\delta)=c_{\gamma}\log(t^{2}K^{2}/\delta)\) where \(c_{\gamma}\) is a constant depending only on \(\gamma\), on all problems \(\nu\in\mathcal{B}\) such that \(\forall i\in[K],\Delta_{i}\leq 1-\mu_{i}\), we have that, for \(\gamma>1\), the expected stopping time of active-rank is upper bounded by the following,_

\[c_{\gamma}^{\prime}\sum_{i\in[K]}H_{i}^{(2)}\log\Big{(}c_{\gamma}^{\prime \prime}H_{i}^{(2)}K^{2}/\delta\Big{)}\,\]

_where \(c_{\gamma}^{\prime}\), \(c_{\gamma}^{\prime\prime}\) are constants depending only on \(\gamma\)._

Proof.: We upper bound \(\mathbb{E}[\tau]\) as follows. We denote the number of times a section of the grid \([G_{i},G_{i+1})\) has been sampled by the learner, up to and including time \(t\) as, \(N_{i}(t)\). Let \(\tau_{i}=N_{i}(\tau)\).

\[\mathbb{E}[\tau_{i}] \leq\sum_{t=1}^{\infty}\mathbb{P}(\tau_{i}\geq t)\] (16) \[\leq\sum_{t=1}^{\infty}\mathbb{P}(i\notin\mathcal{Q}_{t})\.\] (17)

Define the event,

\[\xi_{i,t}:=\{\forall j\in S_{t},(\mathrm{UCB}(t,j)\leq\mu_{j}+ \Delta_{i}/96\}\cup\{\forall j\in S_{t},\mathrm{LCB}(t,j)\geq\mu_{j}-\Delta_{ i}/96)\}\] \[\cup\{p-\Delta_{(t)}\leq\widehat{p}_{t}\leq p+\Delta_{(t)}\}\.\]

**Proposition A.7**.: _For \(i\in[K]\) such that \(\Delta_{i}\leq 2p\), \(t>0\), we have that, on \(\xi_{i,t}\), \(i\in\mathcal{Q}_{t}\)._

Proof.: First note that, under event \(\xi_{i,t}\), \(\Delta_{(t)}\leq\Delta_{i}/96\) and thus for a \(j\in U_{i,t}(6\Delta_{(t)})\), we have,

\[|\mu_{i}-\mu_{j}|\leq\Delta_{i}/96+\Delta_{i}/96+6\Delta_{i}/96\leq\Delta_{i}\,\]

thus,

\[|U_{i,t}(6\Delta_{(t)})|\leq|\{j:|\mu_{i}-\mu_{j}|\leq\Delta_{i}\}|\] (18)

and furthermore, \(\Delta_{(t)}\leq p/4\) which implies \(\widehat{p}\leq 2p\). Now, via definition of \(\Delta_{i}\),

\[\Delta_{i}\leq\bigg{(}\frac{Kp\varepsilon}{|\{j:|\mu_{i}-\mu_{j}|\leq\Delta_ {i}\}|}\wedge 1\bigg{)}(1-\mu_{i})\,\] (19)

In the case, \(\frac{Kp\varepsilon}{|\{j:|\mu_{i}-\mu_{j}|\leq\Delta_{i}\}|}\geq 1\),

\[\Delta_{(t)}\leq\frac{(1-\widehat{\mu}_{i})+\Delta_{(t)}}{96}\leq(1-\widehat{ \mu}_{i})/48\]

and we have that

\[\frac{Kp\varepsilon}{|\{j:|\mu_{i}-\mu_{j}|\geq\Delta_{i}\}|}\leq(1+\Delta_{( t)})\frac{K\widehat{p}\varepsilon}{|U_{i,t}(6\Delta_{(t)})|}\leq\frac{3K \widehat{p}\varepsilon}{2|U_{i,t}(6\Delta_{(t)})|}\]

thus

\[\frac{K\widehat{p}\varepsilon}{|U_{i,t}(6\Delta_{(t)})|}\geq\frac{2}{3}\]finally leading to,

\[\Delta_{(t)}\leq\frac{K\varepsilon\hat{p}_{t}(1-\widehat{\mu}_{i}^{t})}{24|U_{i,t }(6\Delta_{(t)})|}\.\]

Then let us assume \(\frac{Kpe}{|(j:|\mu_{i}-\mu_{j}|\leq\Delta_{i}|)|}\leq 1\). In this case,

\[\Delta_{(t)}\leq\Delta_{i}/96\leq\frac{K\varepsilon p(1-\mu_{i})}{96|U_{i,t}( 6\Delta_{(t)})|}\leq\frac{K\varepsilon\widehat{p}((1-\widehat{\mu}_{i}^{t})+ \Delta_{(t)})}{48|U_{i,t}(6\Delta_{(t)})|}\leq\frac{K\varepsilon\widehat{p}(1- \widehat{\mu}_{i}^{t})}{24|U_{i,t}(6\Delta_{(t)})|}\,\]

where the third inequality comes from the fact that \(\Delta_{(t)}\leq p/4\) which implies \(\widehat{p}\leq 2p\).

In what follows, assume \(i\) is such that \(\Delta_{i}\leq 2p\). Via combination Proposition A.7 and Equation (17), we have that,

\[\mathbb{E}[\tau_{i}]\leq\sum_{t=1}^{\infty}\mathbb{P}\big{(}\xi_{i,t}^{c} \big{)}\.\]

We will now upper bound \(\sum_{t=1}^{\infty}\mathbb{P}(\xi_{i,t})\). For \(\gamma>1\) let,

\[T_{0}^{i}=\min\!\bigg{(}t:\frac{\beta(t,\delta)}{t}\leq\min_{i\in[K]}\!\bigg{(} \frac{\mathrm{kl}(\mu_{i},\mu_{i}+\Delta_{i}/96)}{\log(K)\gamma}\wedge\frac{ \mathrm{kl}(\mu_{i},\mu_{i}-\Delta_{i}/96)}{\log(K)\gamma}\bigg{)}\bigg{)}\.\]

We have that, for all \(t>T_{0}^{i}\), \(j\in S_{t}\),

\[\mathbb{P}(\mathrm{UCB}(t,j)\geq\mu_{j}+\Delta_{i}/96)\leq\mathbb{P}\bigg{(} \mathrm{kl}(\hat{\mu}_{j}^{t},\mu_{j}+\Delta_{i}/96)\leq\frac{\mathrm{kl}(\mu _{j},\mu_{j}+\Delta_{i}/96)}{\log(K)\gamma}\bigg{)}\.\] (20)

Let,

\[r(\gamma)=\{x\in(\mu_{j},\mu_{j}+\Delta_{i}/96):\mathrm{kl}(x,\mu_{j}+\Delta_ {i}/96)=\mathrm{kl}(\mu_{j},\mu_{j}+\Delta_{i}/96)/(\log(K)\gamma)\}\.\]

Consider the function \(\phi(x)=\mathrm{kl}(\mu_{j}+x,\mu_{j}+\Delta_{i}/96)\), on the interval \([0,\Delta_{i}/96]\). Via the properties of the KL divergence, \(\phi\) is convex and \(\phi(\Delta_{i}/96)=0\). As a result, \(\phi(x)\leq(1-x)\,\mathrm{kl}(\mu_{j},\mu_{j}+\Delta_{i}/96)/(2\Delta_{i})\), which implies,

\[r(\gamma)\geq\mu_{j}+\Delta_{i}\bigg{(}\frac{1}{96}-\frac{2}{\log(K)\gamma} \bigg{)}\geq\mu_{j}+\frac{\Delta_{i}}{192}\,\]

for \(\log(K)\gamma>384\). We now have, for all \(t>T_{0}^{i}\),

\[\mathbb{P}\bigg{(}\mathrm{kl}(\hat{\mu}_{j}^{t},\mu_{j}+\Delta_ {i}/96)\leq\frac{\mathrm{kl}(\mu_{j},\mu_{j}+\Delta_{i}/96)}{\log(K)\gamma} \bigg{)} =\mathbb{P}\big{(}\mathrm{kl}(\hat{\mu}_{j}^{t},\mu_{j}+\Delta_{i }/96)\leq\mathrm{kl}(r(\gamma),\mu_{j}+\Delta_{i}/96)\big{)}\] \[=\mathbb{P}(\hat{\mu}_{j}^{t}\geq r(\gamma))\] \[\leq\exp(-t\,\mathrm{kl}(\mu_{j},r(\gamma)))\] \[\leq\exp\!\bigg{(}-\frac{\log(K)\gamma\,\mathrm{kl}(\mu_{j},r( \gamma))}{\mathrm{kl}(\mu_{j},\mu_{j}+\Delta_{i}/96)}\beta(t,\delta)\bigg{)}\] \[\leq\exp\!\bigg{(}-\frac{\gamma\,\mathrm{kl}(\mu_{j},\mu_{j}+ \frac{\Delta_{i}}{192})}{\mathrm{kl}(\mu_{j},\mu_{j}+\Delta_{i}/96)}\beta(t, \delta)\bigg{)}\] \[\leq\exp(-\log(K)\beta(t,\delta)c_{\gamma})\]

where \(c_{\gamma}\) is a constant depending only on \(\gamma\). Thus, via Equation (20), for \(t\geq T_{0}^{i}\)

\[\mathbb{P}(\mathrm{UCB}(t,j)\geq\mu_{j}+\Delta_{i}/2)\leq\exp(-\log(K)\beta(t, \delta)c_{\gamma})\,\]

via similar reasoning we have also that,

\[\mathbb{P}(\mathrm{LCB}(t,j)\leq\mu_{j}-\Delta_{i}/2)\leq\exp(-\log(K)\beta(t, \delta)c_{\gamma})\,\]

and furthermore, \(\mathbb{P}(\widehat{p}_{t}\notin[p-\Delta_{(t)},p+\Delta_{(t)}])\leq\exp(- \beta(t,\delta)),\) and now via a union bound,\[\sum_{t=T_{0}^{i}+1}^{\infty}\mathbb{P}(\xi_{t,i}^{c})\leq c\exp(-c_{\gamma})\.\] (21)

where \(c>0\) is an absolute constant. Thus we have shown that for a point \(i:\Delta_{i}\leq 2p\),

\[\mathbb{E}[\tau_{i}]\leq T_{0}^{i}+cK\exp(-c_{\gamma})\.\]

It is then straight forward to note that for any point \(i:\Delta_{i}\geq 2p\),

\[\mathbb{E}[\tau_{i}]\leq T_{0}^{i^{\prime}}+cK\exp(-c_{\gamma})\,\]

where \(i^{\prime}\) is any point \(i^{\prime}\) such that \(\Delta_{i^{\prime}}\leq 2p\). It remains to upper bound \(T_{0}^{i}\). Via definition of the exploration parameter, we have that,

\[T_{0}^{i}\leq H_{i}^{(2)}\log\Bigl{(}\tilde{c}_{\gamma}H_{i}^{(2)}K/\delta \Bigr{)}\,\]

where \(\tilde{c}_{\gamma}>0\) is an absolute constant depending only on \(\gamma\). Before continuing, we demonstrate the following Lemma-

**Lemma A.8**.: _On all problems \(\nu\in\mathcal{B}\), we have that,_

\[|\{i:\Delta_{i}<2p\}|\geq K/4.\]

Proof.: Firstly assume that,

\[|\{i:\Delta_{i}\geq\mu_{i}\}|\geq K/4\]

and define \(i^{*}=\max\{i:\Delta_{i}\geq\mu\}\). We then have that,

\[\forall j:\Delta_{j}\geq\mu_{j},|\mu_{i^{*}}-\mu_{j}|\leq\Delta_{i^{*}}\,\]

and thus,

\[\Delta_{i^{*}}\leq\frac{K\varepsilon p}{|\{j:|\mu_{i^{*}}-\mu_{j}|\leq\Delta_ {i^{*}}\}|}\leq\varepsilon p/4\leq p\.\]

Thus we have \(|\{i:\Delta_{i}<p\}|\geq K/4\). Now assume,

\[|\{i:\Delta_{i}\geq\mu_{i}\}|\leq K/4\.\]

As we must have \(|\{i:\mu_{i}>2p\}|\leq K/2\), we thus have, \(|\{i:\Delta_{i}<2p\}|\geq K/4\) 

With Lemma A.8, we can then upper bound \(\mathbb{E}[\tau]\) as follows,

\[\mathbb{E}[\tau]\leq 4\sum_{i:\Delta_{i}\leq 2p}\mathbb{E}[\tau_{i}]\leq 4 \sum_{i\in[K]}H_{i}^{(2)}\log(\tilde{c}_{\gamma}H_{i}^{(2)}K/\delta)+c_{ \gamma}^{\prime}K\exp(-c_{\gamma})\,\]

and the result follows.

## Appendix B Proof of Theorem 3.3

Proof.: The proof will follow by application of a Fano type inequality on a well chosen set of problems.

Step 1: Constructing our well chosen set of problemsWe define a set of grid points \(U_{0},U_{1},...\) recursively as follows, \(U_{0}=\arg\min(\Delta_{i})\), for \(m\geq 0\) we then define

\[U_{m+1}=\arg\min\{\Delta_{i}:\forall j\leq m,|\mu_{U_{j}}-\mu_{i}|\geq 3 \Delta_{i}+3\Delta_{U_{j}}\}\.\]

Let \(M\) be the largest integer for which \(U_{M}\) exists. Note that the sequence \(\left(\Delta_{U_{m}}\right)_{m>M}\) is monotonically increasing and furthermore, for all \(i\in[K]\),

\[|\{m\in[M]:|3\mu_{U_{m}}-3\mu_{i}|\geq\Delta_{U_{m}}+\Delta_{i}\}|\leq 2\.\] (22)

We then define the corresponding set of groups, \(D_{0},D_{1},...,D_{M}\) as follows. For \(i\in[K]\) let \(m,n\in[M]\) be such that, \(\mu_{U_{m}}\leq\mu_{i}\leq\mu_{U_{n}}\) then set \(i^{+}=m\lor n\) and \(i^{-}=m\wedge n\). If \(|\mu_{i}-\mu_{i^{*}}|\leq\Delta_{i}+\Delta_{i^{+}}\) then \(i\in D_{i^{+}}\), otherwise \(i\in D_{i^{-}}\).

**Proposition B.1**.: _For all \(m\in[M]\) we have that, \(\forall i\in D_{m},\Delta_{U_{m}}\leq\Delta_{i}\)._

Proof.: W.l.o.g assume \(\mu_{i}\geq\mu_{U_{m}}\). Let \(j\) be such that \(|\mu_{U_{j}}-\mu_{i}|\leq 3\Delta_{i}+3\Delta_{U_{j}}\). Via Equation (22) we have that \(\mu_{U_{m}}\leq\mu_{i}\leq\mu_{U_{j}}\) and by definition of \(D_{m},D_{j}\), \(m>j\). Thus \(\nexists j<m:|\mu_{i}-\mu_{U_{j}}|\leq 3\Delta_{U_{j}}+3\Delta_{i}\) and therefore, if \(\Delta_{i}<\Delta_{U_{m}}\), then

\[\arg\min\{\Delta_{i}:\forall j\leq m-1,|\mu_{U_{j}}-\mu_{i}|\geq 3\Delta_{m}+3 \Delta_{j}\}\neq U_{m}\]

which is a contradiction via the definition of \(U_{m}\).

For \(m\in[M]\), set \(W_{m}=\{i:|\mu_{i}-\mu_{U_{m}}|\leq 3\Delta_{U_{m}}\}\).

**Proposition B.2**.: _For all \(m\in[M]\),_

\[|\{i\in D_{m}:|\mu_{i}-\mu_{U_{m}}|\geq 3\Delta_{U_{m}}\}|\leq 36|W_{m}|\]

Proof.: Firstly, by definition we have that,

\[\Delta_{U_{m}}\geq\frac{K\varepsilon p(1-\mu_{U_{m}})}{|W_{m}|}\.\] (23)

Now, let \(i^{*}=\arg\max_{i\in D_{m}\setminus W_{m}}(\Delta_{i})\). As we have that \(\forall i\in D_{m},|\mu_{i}-\mu_{U_{m}}|\leq 3\Delta_{i}+3\Delta_{U_{m}}\), the following holds,

\[\forall i\in D_{m}\setminus W_{m},|\mu_{i}-\mu_{i^{*}}|\leq 3\Delta_{i^{*}}+3 \Delta_{U_{m}}\.\]

Now consider the set of adjacent grid points \(L\subset D_{m}\setminus W_{m}\) such that \(\lambda\big{(}\bigcup_{i\in L}[G_{i},G_{i+1})\big{)}\leq\Delta_{i^{*}}\), for \(j\in L\),

\[\Delta_{j} \leq\frac{K\varepsilon p(1-\mu_{j})}{|L|}\] (24) \[\leq\frac{K\varepsilon p((1-\mu_{U_{m}})+3\Delta_{j}+3\Delta_{U_ {m}})}{|L|}\] (25) \[\leq\frac{K\varepsilon p(1-\mu_{U_{m}})}{|L|}+\frac{6\Delta_{j}}{ |L|}\] (26)

Where the final inequality comes from the fact we assume \(K\varepsilon p<1\). Thus if we assume \(|L|\geq 12|W_{m}|\), we have that, \(\Delta_{j}\leq\frac{K\varepsilon p(1-\mu_{U_{m}})}{2|C_{k}|}\), a contradiction via proposition B.1 and Equation (23)

The proof of the following proposition follows via the same argument as in the proof of Proposition B.2.

**Proposition B.3**.: _For all \(m\in[M]\),_

\[|W_{m}|\leq 3|\{i\in W_{m}:|\mu_{i}-\mu_{U_{m}}|\leq\Delta_{U_{m}}\}|\]

We are now ready to construct our set of problems. Consider a family of problems \(\nu^{Q}\) indexed by \(Q\in\{0,1\}^{K}\), where the target function \(\eta_{Q}\) corresponding to \(\nu^{Q}\) is defined as follows. Set the coefficients,

\[(\beta_{m}^{1},\beta_{m}^{2})_{m\in[M]}\]

and for \(m\in[M]\), set \(\beta_{1}^{m}=\mu_{U_{m}}+4/3\Delta_{U_{m}},\beta_{2}=\mu_{U_{m}}-4/3\Delta_{U _{m}}\), also define the sets

\[C_{m,1}^{Q}=\bigcup_{i\in W_{m}:Q_{i}=1}[G_{i},G_{i+1})\qquad C_{m,2}^{Q}= \bigcup_{i\in W_{m}:Q_{i}=-1}[G_{i},G_{i+1})\.\]

and \(C_{m}=\bigcup_{i\in W_{m}}[G_{i},G_{i+1})\) we then have

\[\eta_{Q}(x)=\sum_{m\in[M]}\mathbf{1}(x\in C_{m,1}^{Q})\beta_{m}^{1}+\mathbf{1 }(x\in C_{m,2}^{Q})\beta_{m}^{2}\.\]Finally let \(C_{0}^{Q}=[0,1]\setminus\{C_{m,1}^{Q},C_{m,2}^{Q}:m\in[M]\}\) and note that for all \(x\in C_{0}^{Q}\), \(\eta(x)=0\). The following Lemma shows that, for a problem \(\nu\in\mathcal{B}\), the gaps and complexity across our family problems, \(\nu^{Q}\) indexed by \(Q\), does not differ too much from \(\nu\).

**Lemma B.4**.: _Let \(Q\in\{0,1\}^{K}\), for all \(m\in[M],i:[G_{i},G_{i+1})\in C_{m}\), we have that \(\Delta_{U_{m}}/4<\Delta_{i}^{(Q)}<3\Delta_{U_{m}}\), where \(\Delta_{i}^{(Q)}\) is the gap of point \(i\) on problem \(\nu^{Q}\)_

Proof.: We have immediately that \(3\Delta_{U_{m}}\leq 3\Delta_{U_{m}}\), definition of \(\Delta_{U_{m}}\) Then, by proposition B.3,

\[\Delta_{U_{m}}/3\leq\frac{K\varepsilon p(1-\mu_{U_{m}})}{3|\{i:|\mu_{i}-\mu_{ U_{m}}|\leq\Delta_{j}\}|}\leq\frac{K\varepsilon p(1-\mu_{U_{m}})}{|W_{m}|}\leq \frac{K\varepsilon p(1-\mu_{U_{m}}\rightsquigarrow^{4}\Delta_{U_{m}}/3)}{|W_{m} |}+\frac{4K\varepsilon p\Delta_{U_{m}}}{3|W_{m}|}\,\]

which implies, in combination with our assumption \(K\varepsilon p\leq 1/8\) that,

\[\Delta_{U_{m}}/6\leq\frac{K\varepsilon p(1-\mu_{U_{m}}\rightsquigarrow^{4} \Delta_{U_{m}}/3)}{|W_{m}|}\]

and thus that for all \(i\in W_{m}\), \(\Delta_{i}^{(Q)}\geq\Delta_{U_{m}}/6\). 

**Lemma B.5**.: _Given, \(\nu\in\mathcal{B}\), we have that for all \(\nu^{Q}\), \(i\in[K],\Delta_{i}^{(Q)}\geq\Delta_{i}/2\), where \(\Delta_{i}^{(Q)}\) is the gap of point \(i\) on problem \(\nu^{Q}\). Furthermore, \(\sum H_{i,Q}^{(1)}\geq c\sum H_{i}^{(1)}\) where \(H_{i,Q}^{(1)}\) is the complexity of point \(i\) on problem \(\nu^{Q}\), for some absolute constant \(c>0\)._

Proof.: We prove the first statement. For all \(i:[G_{i},G_{i+1})\in C_{0}\) we have that \(\Delta_{i}^{(Q)}=1\) and otherwise the statement follows from Lemma B.5. The second statement then follows by combination of Lemma B.5 and Propositions B.2 and B.1.

Step 2: showing that one suffers \(\varepsilon\) regret on a well chosen eventLet \(Q^{i}\) be the transformation of \(Q\) that flips the \(i\)th coordinate,

\[Q_{a}^{k}=\begin{cases}Q_{a}\text{ If }a\neq k,\\ 1-Q_{a}\text{ If }a=k\,.\end{cases}\]

We remind the reader that we denote the scoring function outputted by the learner as \(\hat{s}\). Now define,

\[z_{m}:=\min\!\left(z:H_{s_{i}}(z)\geq\frac{\lambda\!\left(\bigcup_{n=1}^{m-1}C _{n}\cup C_{m,1}^{Q}\right)\!(1-\kappa\!\left(\bigcup_{n=1}^{m-1}C_{n}\cup C_ {m,1}^{Q}\right)}{(1-p)}\right)\,,\]

define the event,

\[\xi_{i,m}:=\left\{\{x\in[G_{i},G_{i+1}):\hat{s}(x)>z_{m}\}\leq\frac{1}{2K} \right\}\,.\]

and then the events,

\[\mathcal{E}_{1}^{m}:=\left\{\sum_{i:[G_{i},G_{i+1})\in C_{m},Q_{i}=1}\mathbf{ 1}(\xi_{i,m})\leq\frac{3K\lambda(C_{m})}{4}\right\},\ \ \ \ \ \mathcal{E}_{0}^{m}:=\left\{\sum_{i:[G_{i},G_{i+1})\in C_{m},Q_{i}=0}\mathbf{1} (\xi_{i,m})\geq\frac{K\lambda(C_{m})}{4}\right\}\,.\]

For a set \(C\subset[0,1]\), define,

\[\kappa(C):=\frac{1}{\lambda(C)}\int_{C}\eta(x)\,dx\.\]

Let \(\hat{Z}_{m}\subset[0,1]\) be the largest set such that, \(\forall x\in\hat{Z}_{m},y\notin\hat{Z}_{m},\hat{s}(x)\leq\hat{s}(y)\), and,

\[\lambda(\hat{Z}_{m})(1-\kappa(\hat{Z}_{m}))\leq\lambda\!\left(\bigcup_{n=1}^ {m-1}C_{n}\cup C_{m,1}\right)\!\left(1-\kappa\!\left(\bigcup_{n=1}^{m-1}C_{n} \cup C_{m,1}\right)\right)\,.\]Note that \(\hat{Z}_{m}\) is not necessarily unique, in this case we choose an arbitrary such \(\hat{Z}_{m}\). Furthermore define,

\[\hat{Z}_{m}^{0}=\left\{x\in\hat{Z}_{m}:x\in\bigcup_{n=1}^{m-1}C_{n}\right\}, \qquad\hat{Z}_{m}^{1}=\left\{x\in\hat{Z}_{m}:x\in C_{m,1}\right\}\,,\]

and

\[\hat{Z}_{m}^{2}=\left\{x\in\hat{Z}_{m}:x\in C_{m,2}\cup\bigcup_{n=m+1}^{M}C_{n} \right\}\,.\]

And let \(\hat{G}_{m}=\bigcup_{n=1}^{m-1}C_{n}\setminus\hat{Z}_{m}^{0}\). Note that under event \(\mathcal{E}_{1}^{m}\), we have

\[\lambda\big{(}Z_{m}^{1}\big{)}\leq K\lambda(C_{m})/4\.\] (27)

Now, via definition of \(\hat{Z}_{m}\), we have the following,

\[\lambda(\hat{Z}_{m}^{1})(1-\kappa(C_{m,1}))+\lambda(\hat{Z}_{m}^{2})(1-\kappa (C_{m,2}))\leq\lambda(C_{m,1})(1-\kappa(C_{m,1}))+\lambda(\hat{G}_{m})(1- \kappa(\hat{G}_{m}))\,\] (28)

Thus, for a problem \(\nu^{Q}:\sum_{i:[G_{i},G_{i+1})\in C_{m}}Q_{i}\geq K\lambda(C_{m})/2\), on event \(\mathcal{E}_{1}^{m}\), via combination of Equations (27) and (28),

\[\lambda(\hat{Z}_{m}^{2})(1-\kappa(C_{m,2})) \leq 3\lambda(C_{m,1})(1-\kappa(C_{m,1}))/4+\lambda(\hat{G}_{m})( 1-\kappa(\hat{G}_{m}))\] (29) \[\leq(3\lambda(C_{m,1})/4+\lambda(\hat{G}_{m}))(1-\kappa(C_{m,1}))\,\] (30)

where the final inequality comes from the fact \(\kappa(C_{m,1})\geq\kappa(\hat{G}_{m})\). To complete Step: 2 we now lower bound \(d_{\infty}(\hat{s},\eta)\) on event \(\mathcal{E}_{1}^{m}\). Firstly note that,

\[\mathrm{ROC}\Bigg{(}\frac{(1-\hat{Z}_{m})\lambda(\hat{Z}_{m})}{1-p },\eta\Bigg{)} =\frac{\lambda\Big{(}\bigcup_{n=1}^{m-1}C_{n}\cup C_{m,1}\Big{)} \kappa\Big{(}\bigcup_{n=1}^{m-1}C_{n}\cup C_{m,1}\Big{)}}{p}\] \[=\frac{\lambda\Big{(}\bigcup_{n=1}^{m-1}C_{n}\Big{)}\kappa\Big{(} \bigcup_{n=1}^{m-1}C_{n}\Big{)}}{p}+\frac{\lambda(C_{m,1})\kappa(C_{m,1})}{p}\]

therefore, for a problem \(\nu^{Q}:\sum_{i:P_{i}\in C_{m}}Q_{i}\geq K\lambda(C_{m})/2\), on event \(\mathcal{E}_{1}^{m}\),

\[d_{\infty}(\hat{s},\eta) \geq\frac{\lambda(\hat{G}_{m})\kappa(\hat{G}_{m})}{p}+\frac{ \lambda(C_{m,1})\kappa(C_{m,1})}{p}-\frac{\kappa(C_{m,1})\lambda(\hat{Z}_{m}^ {1})}{p}-\frac{\kappa(C_{m,2})\lambda(\hat{Z}_{m}^{2})}{p}\] \[\geq\frac{\lambda(\hat{G}_{m})\kappa(\hat{G}_{m})}{p}+\frac{3 \lambda(C_{m,1})\kappa(C_{m,1})}{4p}-\frac{\kappa(C_{m,2})\lambda(\hat{Z}_{m} ^{2})}{p}\] \[\geq\frac{\lambda(\hat{G}_{m})\kappa(\hat{G}_{m})}{p}+\frac{3 \lambda(C_{m,1})\kappa(C_{m,1})}{4p}-\frac{\kappa(C_{m,2})(3\lambda(C_{m,1}/4 +\lambda(\hat{G}_{m}))}{p}\frac{1-\kappa(C_{m,1})}{1-\kappa(C_{m,2})}\] \[\geq\frac{3\lambda(C_{m,1})}{4p}\bigg{(}\kappa(C_{m,1})-\kappa(C _{m,1})\frac{1-\kappa(C_{m,1})}{1-\kappa(C_{m,2})}\bigg{)}\] \[=\frac{3\lambda(C_{m,1})}{4p}\bigg{(}\frac{\kappa(C_{m,1})-\kappa( C_{m,2})}{1-\kappa(C_{m,2})}\bigg{)}\] \[=\frac{3\lambda(C_{m,1})}{4p}\bigg{(}\frac{8/3\Delta_{U_{m}}}{1- \kappa(C_{m,2})}\bigg{)}\geq\frac{3\lambda(C_{m,1}\cup C_{m,2})}{8p}\bigg{(} \frac{8/3\Delta_{U_{m}}}{1-\kappa(C_{m,2})}\bigg{)}\geq\varepsilon\]

where the first inequality follows from Equation (27) and the second from (29).

Thus, as we assume policy \(\pi\) is PAC\((\delta,\varepsilon)\), on all problems \(\nu^{Q}\), we must have that, on all problems \(\nu^{Q}:\sum_{i:[G_{i},G_{i+1})\in C_{m}}Q_{i}\geq K\lambda(C_{m})/2\),

\[\mathbb{P}_{\nu^{Q},\pi}(\mathcal{E}_{1}^{m})\leq\delta\,\] (31)

Via similar reasoning we can show that on all problems \(\nu^{Q}:\sum_{i:[G_{i},G_{i+1})\in C_{m}}Q_{i}\leq K\lambda(C_{m})/2\), we must have that,

\[\mathbb{P}_{\nu^{Q},\pi}(\mathcal{E}_{0}^{m})\leq\delta\.\]Step 4: bounding the probability of the sum of \(\xi_{i}^{m}\)Now, for \(m\in[M]\), via the Azuma hoeffding inequality applied to the martingale,

\[\sum_{i:[G_{i},G_{i+1})\in C_{m},Q_{i}=0}[\mathbf{1}(\xi_{i,m})-\mathbb{P}_{Q}( \xi_{i,m})]\,\]

we have that,

\[\mathbb{P}_{Q}\left(\sum_{i:[G_{i},G_{i+1})\in C_{m},Q_{i}=0}[\mathbf{1}(\xi_{ i,m})-\mathbb{P}_{Q}(\xi_{i,m})]\geq K\lambda(C_{m})\log\!\left(\frac{1}{1- \delta}\right)\right)\leq 1-\delta\.\] (33)

Thus via combination of Equations (32) and (33) we must have that, \(\forall Q:\sum_{i:[G_{i},G_{i+1})\in C_{m}}^{K}Q_{i}\leq K\lambda(C_{m})/2\),

\[\sum_{i:[G_{i},G_{i+1})\in C_{m},Q_{i}=0}\mathbb{P}_{Q}(\xi_{i,m})\leq\lambda( C_{m})\!\left(\frac{K}{4}+K\log\!\left(\frac{1}{1-\delta}\right)\right)\leq \frac{3K\lambda(C_{m})}{8}\,\] (34)

where the second inequality comes from our assumption \(\delta\leq 1-\exp(-1/8)\). Via similar reasoning we also have that, \(\forall Q:\sum_{i:[G_{i},G_{i+1})\in C_{m}}Q_{a}\geq K\lambda(C_{m})/2\)

\[\sum_{i:[G_{i},G_{i+1})\in C_{m},Q_{i}=1}\mathbb{P}_{Q}(\xi_{i,m})\geq\lambda( C_{m})\!\left(\frac{K}{2}-K\log\!\left(\frac{1}{1-\delta}\right)\right)\geq \frac{5K\lambda(C_{m})}{8}\.\] (35)

Step 5: applying a Fano type inequalityWe first define the class of problems upon which we will apply Fano.

\[\mathfrak{Q}=\left\{Q:\forall m\in[M],\sum_{i:[G_{i},G_{i+1})\in C _{m}}Q_{i}=\frac{K\lambda(C_{m})}{2}\right\}\] \[\mathfrak{Q}_{0}=\left\{Q:\forall m\in[M],\sum_{i:[G_{i},G_{i+1}) \in C_{m}}Q_{i}=\frac{K\lambda(C_{m})}{2}-1\right\}\]

We remind the reader that for \(i\in[K]\), we write \(\tau_{i}=\sum_{t=1}^{\tau}\mathbf{1}(a_{t}\in[G_{i},G_{i+1}))\) and for \(m\in[M]\), \(\tau_{(m)}=\sum_{i:[G_{i},G_{i+1})\in C_{m}}T_{i}\). We see that, for all \(Q\in\mathfrak{Q}_{0},i:Q_{i}=0\), there exists a unique \(\tilde{Q}\in\mathfrak{Q}\) such that \(\tilde{Q}^{i}=Q\), therefore,

\[\sum_{Q\in\mathfrak{Q}}\sum_{m\in[M]}\ \sum_{i:[G_{i},G_{i+1})\in C_{m},Q_{i}=1} \mathbb{P}_{Q^{\prime}}(\xi_{i,m})=\sum_{Q\in\mathfrak{Q}_{0}}\sum_{m\in[M]} \ \sum_{i:[G_{i},G_{i+1})\in C_{m},Q_{i}=0}\mathbb{P}_{Q}(\xi_{i,m})\,\]

and thus, using the data processing inequality and the convexity of the relative entropy we have,

\[\text{kl}\left(\underbrace{\frac{1}{|\mathfrak{Q}|}\sum_{Q\in \mathfrak{Q}}\sum_{m\in[M]}\frac{2}{K\lambda(C_{m})}\sum_{i:P_{i}\in C_{m},Q_{ i}=1}\mathbb{P}_{Q^{\prime}}(\xi_{i,m})}_{\leq 6/8},\underbrace{\frac{1}{| \mathfrak{Q}|}\sum_{Q\in\mathfrak{Q}}\sum_{m\in[M]}\frac{2}{K\lambda(C_{m})} \sum_{i:P_{i}\in C_{m},Q_{i}=1}\mathbb{P}_{Q}(\xi_{i,m})}_{\geq 10/8}\right)\] \[\leq\frac{1}{|\mathfrak{Q}|}\sum_{Q\in\mathfrak{Q}}\sum_{m\in[M]} \ \frac{2}{K\lambda(C_{m})}\sum_{i:P_{i}\in C_{m},Q_{i}=1}\mathbb{E}_{Q}[\tau_{m} ]\frac{\text{kl}(\mu_{U_{m}}-4/3\Delta_{U_{m}},\mu_{U_{m}}+4/3\Delta_{U_{m}}) }{2}\] \[\leq\frac{1}{|\mathfrak{Q}|}\sum_{Q\in\mathfrak{Q}}\sum_{m\in[M] }\frac{\mathbb{E}_{Q}[\tau_{(m)}]\,\text{kl}(\mu_{U_{m}}-4/3\Delta_{U_{m}}, \mu_{U_{m}}+4/3\Delta_{U_{m}})}{K\lambda(C_{m})}\] \[\leq\max_{Q\in\mathfrak{Q}}\sum_{m\in[M]}\frac{\mathbb{E}_{Q}[ \tau_{(m)}]\,\text{kl}(\mu_{U_{m}}-4/3\Delta_{U_{m}},\mu_{U_{m}}+4/3\Delta_{U_{ m}})}{K\lambda(C_{m})}\.\]Then using the Pinsker inequality \(\operatorname{kl}(x,y)\geq 2(x-y)^{2}\), we obtain

\[\frac{1}{|\mathfrak{L}_{m}|}\sum_{Q\in\mathfrak{L}_{m}}\sum_{m\in[M]}\frac{2}{K \lambda(C_{m})}\ \sum_{i:P_{i}\in C_{m};Q_{i}=1}\mathbb{P}_{Q}(\xi_{i,m})\leq\frac{3}{8}+ \sqrt{\max_{Q\in\mathfrak{L}}\sum_{m\in[M]}\frac{\mathbb{E}_{Q}[\tau_{(m)}] \operatorname{kl}(\mu_{U_{m}}-4/3\Delta_{U_{m}},\mu_{U_{m}}+4/3\Delta_{U_{m}}) }{K\lambda(C_{m})}}\]

and therefore,

\[\max_{Q\in\mathfrak{L}}\sum_{m\in[M]}\ \frac{\mathbb{E}_{Q}[\tau_{(m)}] \operatorname{kl}(\mu_{U_{m}}-\Delta_{m},\mu_{U_{m}}+\Delta_{m})}{K\lambda(C _{m})}\geq\frac{9}{64}\]

thus

\[\max_{Q\in\mathfrak{L}}\sum_{m\in[M]}\mathbb{E}_{Q}[\tau_{(m)}]\geq\ c^{ \prime}\sum_{m\in[M]}\frac{K\lambda(C_{m})}{\operatorname{kl}(\mu_{U_{m}}-4/ 3\Delta_{U_{m}},\mu_{U_{m}}+4/3\Delta_{U_{m}})}\]

where \(c^{\prime}>0\) is an absolute constant. The proof now follows, as \(\forall m\in[M],i:[G_{i},G_{i+1})\subset C_{m}\), \(H_{i}\geq\frac{1}{\operatorname{kl}(\mu_{U_{m}}-4/3\Delta_{U_{m}},\mu_{U_{m}} +4/3\Delta_{U_{m}})}\).