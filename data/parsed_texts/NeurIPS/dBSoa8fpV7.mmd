PEACE: A Dataset of Pharmaceutical Care for Cancer Pain Analgesia Evaluation and Medication Decision

Yutao Dou\({}^{1,2}\), Huimin Yu\({}^{2}\), Wei Li\({}^{3}\), Jingyang Li\({}^{2}\), Fei Xia\({}^{1}\), Jian Xiao\({}^{2}\)

\({}^{1}\) College of Computer Science and Electronic Engineering, Hunan University, Changsha 410082, China.

\({}^{2}\) Department of Pharmacy, Xiangya Hospital, Central South University, Changsha 410008, China.

\({}^{3}\) School of Computer Science, The University of Sydney, Darlington, NSW, 2008, Australia.

ytdou@hnu.edu.cn, 228112395@csu.edu.cn, weiwilson.li@sydney.edu.au,

228112396@csu.edu.cn, xcyphoenix@hnu.edu.cn, admanoas@163.com

Equal contributionCorresponding author

###### Abstract

Over half of cancer patients experience long-term pain management challenges. Recently, interest has grown in systems for cancer pain treatment effectiveness assessment (TEA) and medication recommendation (MR) to optimize pharmacological care. These systems aim to improve treatment effectiveness by recommending personalized medication plans based on comprehensive patient information. Despite progress, current systems lack multidisciplinary treatment (MDT) team assessments of treatment and the patient's perception of medication, crucial for effective cancer pain management. Moreover, managing cancer pain medication requires multiple adjustments to the treatment plan based on the patient's evolving condition, a detail often missing in existing datasets. To tackle these issues, we designed the PEACE dataset specifically for cancer pain medication research. It includes detailed pharmacological care records for over 38,000 patients, covering demographics, clinical examination, treatment outcomes, medication plans, and patient self-perceptions. Unlike existing datasets, PEACE records not only long-term and multiple follow-ups both inside and outside hospitals but also includes patients' self-assessments of medication effects and the impact on their lives. We conducted a proof-of-concept study with 13 machine learning algorithms on the PEACE dataset for the TEA (classification task) and MR (regression task). These experiments provide valuable insights into the potential of the PEACE dataset for advancing personalized cancer pain management. The dataset is accessible at: [https://github.com/YTYTYTYD/PEACE].

## 1 Introduction

Cancer pain is a common symptom among cancer patients, with an incidence rate of up to 53%. This greatly affects patients' quality of life and may impede effective cancer treatment. Pharmacotherapy, the mainstay of cancer pain management, often involves long-term medication use. Physicians must continually assess the efficacy of the current analgesic regimen by considering factors such as the patient's physical condition, pain intensity, type of pain, and prior medications. This enables targeted adjustments to the treatment plan to improve therapeutic outcomes.

Recently, machine learning and deep neural network technologies have significantly advanced automated treatment effect assessment (TEA) and medication recommendation (MR) systems for cancer pain management. These systems use patient data to make accurate assessments and provide medication recommendations. However, most existing systems focus on single treatments and rarely include long-term follow-up. In practice, medication assessment and decision-making often rely on multidisciplinary treatment (MDT) collaboration. Including a pharmacist can significantly enhance cancer pain management efficiency and improve patient pain control and medication adherence. Notably, widely used public datasets like MIMIC [11; 10] and FAERS [28] lack ongoing MDT assessments of patients' medication rationality.

We developed the PEACE (Pharmaceuticals for Easing cAncer pain with CarE) dataset, a comprehensive resource specifically designed for the construction of TEA and MR systems for cancer pain. Compared to other cancer pain related datasets, PEACE offers significant improvements in both the size of patient records and the duration of observations. To our knowledge, it is the first cancer pain medication dataset that provides long-term patient observations and comprehensively contains the information required for MDT decision-making. This dataset includes in-hospital features (patient information, laboratory indicators, physician diagnoses) and out-of-hospital features (patient comments, medication feedback, impact on life). Additionally, it details the MDT's evaluation of the patient's medication use and treatment planning rationale.

Our main contributions are as follows:

1. We release the PEACE dataset1, the first known resource specifically designed for pharmaceutical care in cancer pain management. This dataset contains over 38,000 patient records, encompassing 103 features related to diverse pathologies, symptoms, and etiologies. It includes multi-visit, long-term observations for 2,600 patients, providing valuable insights into patient care trajectories. Footnote 1: Dataset available at https://github.com/YTYTYD/PEACE
2. PEACE incorporates medical professionals' assessments of the current health state and the rationale behind medication plans, which are not present in existing datasets.
3. We conducted extensive experiments with this dataset, validating the efficacy of 13 machine learning and deep learning approaches in enhancing treatment effect evaluations and medication decision-making.

## 2 Related work

To build reliable TEA and MR systems, it is crucial to gather comprehensive data on both inpatients and outpatients. This includes medication details, treatment outcomes, adverse events and their etiologies, treatment adjustments, and impact on patients' quality of life. However, no public dataset currently meets all these requirements comprehensively. Widely used datasets such as MIMIC-III [11] and MIMIC-IV [10], while detailed in recording medication specifics, lack pharmacist assessments of treatment outcomes. These datasets primarily focus on single hospitalization events rather than the long-term health status of patients, which is particularly disadvantageous for managing chronic conditions like cancer pain. Similarly, the eICU Collaborative Research Database [20] documents essential medication usage information but fails to provide clear explanations of medication effects and lacks long-term patient follow-up. Additionally, these datasets lack patient feedback on their treatment plans. SEER [26] is a representative large-scale cancer registry databases in the United States, compiling extensive retrospective clinical data. It primarily focuses on the treatment processes of cancer patients but does not include assessments of medication plans following hospital discharge. For medication effect assessment, the SIDER [13] database lists adverse reactions for marketed drugs, while the FAERS [28] and TwoSIDES [27] datasets record potential drug interactions. Although these datasets are useful in some aspects, they generally lack detailed records of patients' conditions and necessary clinical features, limiting their practical utility. ISS[19] is a cancer pain assessment dataset that includes videos of 29 patients, along with their self-reported pain scale scores, used to predict the patients' pain levels. A common shortfall of these datasets is their inability to continuously observe and assess patient conditions. They often describe data from a single perspective and fail to integrate the diverse characteristics needed for making MDT decisions. The following section details the PEACE dataset and the steps taken to construct it, aiming to address the deficiencies of existing datasets.

## 3 Dataset Construction

As illustrated in Figure 1, the PEACE dataset construction process begins with clinical data manually collected from hospital, along with follow-up web interactions for patient-reported symptoms. Patient identifiers are anonymized, and dates are shifted to ensure privacy. Feature selection is conducted by experts using the Delphi consensus method [9], a structured communication technique that relies on a panel of experts answering questionnaires in multiple rounds to reach a consensus on key attributes. Data preprocessing involves standardization, imputation, and simplification. Finally, features are categorized, and the processed data is structured into a consistent format, ready for analysis, ensuring both data integrity and privacy protection.

### Data Sources

The data used in this study was collected from two main sources. The first part originated from the Xiangya hospital, encompassing a broad range of patient information, including patient demographics, clinical signs, medication details, physiological parameters, and treatment outcomes. The second part of the data source is our cancer pain online follow-up platform. This platform allows continuous follow-up of cancer pain patients after hospital discharge through patient-initiated reports. It includes patient basic information, pain levels, adverse reactions from medication, dynamic adjustments to medication, treatment of adverse reactions, and other related data. Further details regarding the online follow-up platform can be found in Appendix A.

The inclusion criteria for this research required subjects to have a definitive diagnosis of cancer with associated pain, confirmed via histopathological or cytological methods, with cancer being the primary diagnosis in their medical records. Exclusion criteria included cases with severely incomplete key medical records or significant medical complications. Our work is approved by the Institutional Review Board of the Xiangya Hospital (Ethics Approval ID: 202109422). This work does not interfere with clinical care and treatment procedures. Informed consent is obtained from the patients, and all protected health information is de-identified.

Figure 1: Overview of the data construction process for the PEACE dataset

### De-identification and Privacy Protection

In the collected data, patient identifiers were removed, and each patient was assigned a unique randomized code ID. Date and time values were shifted 30 to 80 years into the future using a personalized random offset measured in years. Each patient received an independent date transformation, ensuring that the temporal sequence within their data remained consistent. For instance, if the interval between two measurements in the original data was 15 days, the same interval was maintained in the PEACE dataset. However, temporal data for different patients are not comparable. This means that two patients treated in the year 2100 in the dataset are not necessarily treated in the same year in reality. Patients older than 89 years were uniformly labeled as 89 years old to protect their privacy, and patients younger than 18 years were excluded from the dataset. Finally, patient-specific diagnostic reports were reorganized, classified into different categories, and clearly labeled to facilitate data analysis and model training while ensuring privacy protection.

### Features Selection

Inspired by [30], this section identifies key features in cancer pain management through the Delphi consensus process, integrating insights from clinical practice and MDT pharmaceutical care. In clinical pharmacy, the Delphi technique is primarily used to develop guidelines or pathways. This is achieved through several rounds of anonymous surveys, repeated consultations, multiple revisions, and generalizations, ultimately leading to the convergence of final opinions [18]. The detailed screening process is outlined in Appendix B.

#### 3.3.1 Expert Panel Recruitment

We employed judgmental sampling [2], a targeted recruitment strategy, to identify and invite experts in cancer pain management. Detailed descriptions of the study design and objectives were provided to ensure informed participation. This transparency allowed potential candidates to understand the research goals, methods, and their role in contributing expertise. A multidisciplinary team of experts was assembled to create an effective feature list. This team included clinical pharmacists, anesthetists, oncologists, and nurses. All experts met the following criteria: employment at a tertiary hospital, a minimum of five years of experience in cancer pain management, holding an academic role within a provincial cancer pain association, and willingness to participate in two questionnaire rounds. To ensure balanced representation among professionals, we aimed to maintain equal numbers of doctors and nurses as suggested in [21], with pharmacists serving as additional specialists. We finally recruited 32 experts, including 16 pharmacists, 4 anesthetists, 4 oncologists, and 8 nurses, all based in tertiary hospitals across nine provinces. Their demographics are provided in Appendix B.2.

Experts were required to self-assess their authority (Cr) for each round, based on criteria (Ca) and their familiarity with clinical issues (Cs). The criteria (Ca) encompassed four dimensions: work experience, theoretical analysis, knowledge of domestic and international peers, and insights. Familiarity (Cs) was categorized into five levels: very familiar, familiar, somewhat familiar, unfamiliar, and very unfamiliar, quantified as 1.0, 0.8, 0.6, 0.4, and 0.2, respectively. The questionnaires in both rounds calculated the experts' opinion coordination coefficient (W) and response rate, with a response rate of 75% or higher considered satisfactory. Detailed calculations are provided in Appendix B.1.

#### 3.3.2 Delphi Consensus

**The First Round:** In this round, we initiated the Delphi process by inviting experts to participate via email. We informed participants of all study details. The survey began with an introduction and participant demographics section, collecting information like age, gender, education, profession, title, and years of experience. The core of the survey focused on six key themes relevant to cancer pain management pharmaceutical services: patient basic information, comprehensive pain assessment, previous analgesic treatment, evaluation of previous analgesic treatment, cancer pain medication decision, and follow-up. For each theme, experts rated features using a 5-point Likert scale (agreement scale). Additionally, open-ended sections allowed for written feedback.

Following the first round, we calculated average scores and coefficients of variation for each feature. Consensus for an item was defined by meeting the following criteria: 1) average score \(\geq 4.0\); 2) coefficient of variation \(<0.15\); and 3) no dissenting opinions. However, if an item received "Agree" or "Strongly Agree" from over 25% of experts but an average score below 3.0, it was carried forward to the second round for further discussion. The first round also encouraged the experts to raise relevant clinical questions. This feedback was collated and shared with all participants as reference material for the second round. Finally, the survey concluded with a self-assessment section where experts rated their own level of expertise and agreement with the overall process. Appendix B.3 provides a more in-depth look at the first round of the Delphi process.

**The Second Round:** This round focused exclusively on features that lacked clear consensus in the first round [1]. Experts received their individual scores alongside the overall distribution and percentages of scores from their peers [24; 25]. This facilitated informed reflection and potential adjustments to their initial ratings. We also considered expert suggestions for modifying existing questions or introducing new ones from the first round. These were incorporated into personalized questionnaires for the second round. Stringent inclusion criteria remained for the second round. Features required an average rating of at least 4.0 (strongly agree), and a coefficient of variation less than 0.15 (low variability) to be considered for the final list. Please see Appendix B.4 for a detailed breakdown of the second-round process.

### Data Preprocessing

**Data Standardization:** The raw medication data presented significant challenges for direct modeling due to noise, complex attribute relationships, and high dimensionality. Common issues included disorganization, duplicate records, and missing information, which complicate model training. To mitigate these challenges, we implemented a comprehensive data preprocessing pipeline. For example, we standardized synonym variations within pain intensity labels. Terms like "burning pain," "scaling pain," and "burn-like pain" were standardized to "burning-type pain" to ensure consistent representation. Redundancies were addressed by merging useful fields from duplicate records to enhance data quality. For data inconsistencies and anomalies potentially arising from human errors, we employed a two-pronged approach. When sample sizes permitted, we opted for data correction through expert consultation to preserve valuable information. In cases where data accuracy could not be confirmed, or sample sizes were inadequate, data points were removed to prevent model bias and improve training robustness.

**Feature Categorization:** The original data included numerous multiple-choice features, such as various analgesics with similar effects but different brands or specifications. Patients might also take several similar drugs simultaneously due to complementary effects. Given the large number of possible combinations, directly including these features in the model may lead to suboptimal performance. To mitigate this, we categorized these features to structure them for better usability in machine learning tasks. For instance, combinations of dozens of drugs in the raw data were grouped into seven categories based on their actions and specifications: "Extended Release Strong Opiates (ERSO)," "Immediate Release Strong Opiates (IRSO)," "Extended Release Weak Opiates (ERWO)," "Immediate Release Weak Opiates (IRWO)," "Nonsteroidal Anti-Inflammatory Drugs (NSAID)," "Anticonvulsants/Antidepressants (A/A)," and "Others," with numerical representation of the quantity of medication used per category. Similarly, we classified patients' pain types into four categories by integrating specific pain locations, pain intensity, and the nature of the pain, providing the model with a comprehensive representation of pain characteristics. Additionally, we addressed the high dimensionality of the pain intensity score. The original specific number of times or persistent pain was simplified into a more practical multiclassification (0: none, 1: \(<\)3 times, 2: \(\geq\)3 times, and 3: persistent pain) to improve model efficiency without compromising essential information.

### Dataset Features

Our data construction process resulted in a comprehensive dataset encompassing 103 features, broadly categorized into six groups. The Patient Baseline Information group (50 features) captures demographic and clinical characteristics of the patients, potentially including age, gender, co-morbidities, and disease stage. The Comprehensive Pain Assessment group (15 features) details the extent and characteristics of the patients' pain experience, potentially including pain intensity scores, pain quality descriptors (e.g., visceral pain, somatic pain), and functional limitations. The Previous Analgesic Treatment group (23 features) details the medications and interventions previously used to manage the patients' pain, potentially including medication names, dosages, durations, and routes of administration. The Evaluation of Previous Analgesic Treatment group (5 features) captures the effectiveness and tolerability of prior pain management strategies, potentially including patient-reported outcomes or physician assessments. The Cancer Pain Medication Decision group (9 features) details the rationale behind the selection of specific pain medications for the study participants, potentially including factors like pain type, treatment history, and co-morbidities. The Follow-Up group (1 feature) captures information on patient outcomes after the intervention of interest, potentially including pain response or adverse events. A detailed description of each feature is provided in Appendix B.5.

### Dataset Descriptive Analysis

**Feature distribution:** Table 1 categorizes the 103 features in the PEACE dataset, with numeric features comprising the majority at 75%.

**Demographics:** The socio-demographic statistics of our patients are presented in Figure 2 (a), showing that the 45-74 age group has the highest cancer incidence. Figure 2 (b) illustrates the gender distribution, which is nearly balanced with a male-to-female ratio of 51.4:48.6. See Appendix C for more detailed demographics.

**Visit Statistics:** Table 2 summarizes patient visit statistics. Notably, 7% of patients have multiple visits recorded, with a maximum of 33 visits.

**Patient Sample:** We present a sample patient with selected features from the PEACE dataset in Table 3. The table illustrates how medical staff adjust the patient's medication based on the effectiveness of each treatment and the drug reactions experienced during the medication process. This approach

\begin{table}
\begin{tabular}{l|c c c c c c c c c} \hline \hline \multicolumn{5}{c}{**Patient Basic Information**} & \multicolumn{5}{c}{**Comprehensive Pain Assessment**} & \multicolumn{5}{c}{**Previous Analgesic Treatment**} \\ \cline{2-10} Total & Binary & Multiclass & Numerical & Total & Binary & Multiclass & Numerical & Total & Binary & Multiclass & Numerical \\ \hline
50 & 6 & 2 & 42 & 15 & 0 & 4 & 11 & 23 & 5 & 0 & 18 \\ \hline \multicolumn{5}{c}{**Evaluation of Previous Analgesic Treatment**} & \multicolumn{5}{c}{**Cancer Pain Medication Decision**} & \multicolumn{5}{c}{**Follow-up**} \\ \cline{2-10} Total & Binary & Multiclass & Numerical & Total & Binary & Multiclass & Numerical & Total & Binary & Multiclass & Numerical \\ \hline
5 & 0 & 5 & 0 & 9 & 2 & 0 & 7 & 1 & 0 & 1 & 0 \\ \hline \hline \end{tabular}
\end{table}
Table 1: Summary of dataset features distribution.

Figure 2: Patient demographics: Age and gender distributionaims to mitigate adverse reactions and achieve better outcomes. The complete data for this patient and additional patient samples are provided in Appendix F.

### Dataset Usage

The PEACE dataset is designated for research purposes exclusively. The dataset access process involves three steps: 1) Completing relevant training (such as the CITI or GCP training), 2) Signing and adhering to a data use agreement, and 3) Obtaining approval from Xiangya Hospital. The agreement outlines responsible data handling practices and emphasizes the importance of following established collaborative research ethics. Models trained on this dataset should undergo rigorous evaluation before real-world deployment. This evaluation should assess the model's performance, generalizability, and representativeness for the target real-world application. A detailed description of the PEACE dataset usage is provided in Appendix E.

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \hline  & Number of patients & Avg & Std dev & Min & 1st quartile & Median & 3rd quartile & Max \\ \hline All patients & 38,766 & 1.09 & 0.58 & 1 & 1 & 1 & 1 & 33 \\ Patients with records \(\geq\) 2 & 2,601 & 2.48 & 1.74 & 2 & 2 & 2 & 2 & 33 \\ Patients with records \(\geq\) 3 & 514 & 4.44 & 3.27 & 3 & 3 & 3 & 4 & 33 \\ Patients with records \(\geq\) 5 & 116 & 8.69 & 4.86 & 5 & 6 & 7 & 9.25 & 33 \\ Patients with records \(\geq\) 10 & 29 & 14.82 & 6.25 & 10 & 11 & 13 & 16 & 33 \\ \hline \hline \end{tabular}
\end{table}
Table 2: Statistics on the patient records

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline
**ID: SJ-289031** & \multicolumn{6}{c}{Patient Basic Information} \\ \hline Gender & Age & \begin{tabular}{c} Length of \\ Hospital Star \\ \end{tabular} & \begin{tabular}{c} Discharge \\ Diagnosis \\ \end{tabular} & \begin{tabular}{c} Smoking \\ History \\ \end{tabular} & \begin{tabular}{c} Treatment \\ Method \\ \end{tabular} & 
\begin{tabular}{c} White Blood \\ Cell Count \\ \end{tabular} & Total 50 Features \\ \hline

[MISSING_PAGE_POST]

 \hline \hline \end{tabular}
\end{table}
Table 3: A sample patient from the PEACE dataset (Pain Relief and Post-medication Pain Score: 1. Complete Relief, 2. Partial Relief, 3. Mild Relief, 4. Ineffective)Experiment

### Experimental Setup

#### 4.1.1 Tasks

To establish the TEA/MR system, this study quantitatively assess patient treatment outcomes and guide future treatment strategies. Our PEACE dataset supports two types of prediction tasks: (1) TEA, which is a multi-label classification (levels 1-4) using patient characteristics with time series data to quantify levels of treatment efficacy; and (2) MR, which involves regression analyses utilizing time series data to predict the quantity of various analgesics required by patients following adjustments in their treatment plans based on their medication history.

#### 4.1.2 Baselines

We present the results for 13 algorithms, which cover machine learning and deep learning algorithms, on the PEACE dataset for both tasks. These algorithms include 5 basic machine learning and neural network models: Decision Trees [22], Logistic Regression [5], Random Forests [14], SVM [4] and MLP [23]; 3 popular gradient boosting decision tree methods: LightGBM [12], XGBoost [3], and AdaBoost [6]; 3 advanced neural network models designed for time-series data: iTransformer [15], TransTab [29], and Mampa [8]; and 2 neural network models specifically tailored for electronic health records (EHR): Stagenet[7] and Adacare[16]. Details of the baselines are provided in Appendix D.1.

#### 4.1.3 Experiment Environment

In our experiments, 80% of the dataset was used for model building with 5-fold cross-validation, while the remaining 20% served as an independent test set. For detailed information on data partitioning, please refer to Appendix D.2. A random state of 42 was used in all our experiments. The models were trained on a computing platform platform equipped with an Intel i7-13700KF CPU, 128GB of memory, and an NVIDIA RTX4090 24GB GPU.

#### 4.1.4 Evaluation Metrics

In our experiments, we used the following metrics to evaluate the performance. For TEA (classification tasks), we used the metrics of accuracy (ACC), area under the receiver operating characteristic curve (AUROC), F1 score, recall, and precision. For MR (regression tasks), we used mean squared error (MSE) and mean absolute error (MAE). The details of the metrics are given in Appendix D.3.

### Results

For the TEA task, as shown in Table 4, the GBDT algorithm LightGBM achieved the highest ACC and Recall. This success is due to its ability to handle large-scale, high-dimensional data, robust feature selection, and effective regularization to prevent overfitting. XGBoost also performed well, closely following LightGBM. Basic models like Decision Trees and Logistic Regression, although simple and efficient, struggled with complex data patterns and multidimensional features. General neural network models required more precise tuning and did not perform as well on the tabular format of the PEACE dataset. In contrast, EHR-specific models were better at identifying task-relevant features, leading to improved performance. Detailed results for the K-fold and independent test set experiments for the TEA task are given in Table 14 of Appendix D.4.

For the MR task, as shown in Table 5, tree-based models, including decision trees, random forests, and GBDT, demonstrated good performance and stability, achieving the top results in most metrics. Advanced neural network models like iTransformer, while excelling in specific categories, were prone to overfitting and lacked the robustness of tree-based models. Similar to their performance in the TEA task, neural network models optimized for the EHR scenario show potential for significant improvement. Detailed results on the K-fold and independent test set experiments for the MR task are given in Table 15 of Appendix D.4.

[MISSING_PAGE_FAIL:9]

Conclusion and Future Work

In this work, we introduce PEACE, a comprehensive dataset for cancer pain medication therapy, which comprises over 38,000 patients experiencing cancer-related pain, including more than 2,600 patients with multiple long-term follow-up records. The dataset integrates features from hospital and online follow-up platform through an expert Delphi consensus process. These features encompass demographics, laboratory tests, pain assessments, medication treatments, and variables related to outcome evaluation and medication recommendations. Using this dataset, we evaluated the performance of 13 models on the classification and regression tasks. Our results indicate that existing models are unable to fully harness the dataset's potential. Constructed from a multidisciplinary therapeutic research perspective, PEACE thoroughly incorporates the specifics of the medical field, making it a valuable resource for researchers seeking to extract meaningful medical information. This dataset could be utilized in many studies concerning cancer pain.

In the next phase of our work, we will continue to incorporate more patient information into our dataset to enhance its generalizability and representativeness. We also plan to expand our selected features, particularly with more detailed laboratory indicators such as blood drug concentrations, based on further expert advice. Additionally, we intend to explore potential correlations between human genes, drug molecules, and cancer pain from the perspectives of biogenetics, bioinformatics, and medicinal chemistry to enhance medication safety for patients and reduce adverse effects. This approach will help enhance medication safety and reduce adverse effects. Finally, we will validate our models in clinical settings to assess their practical efficacy and reliability.

## Acknowledgment

This work was supported by the Natural Science Foundation of Hunan Province (No. 2022JJ80114); The Fundamental Research Funds for the Central South University (2024ZZTS0287); Graduate Research Innovation Project of Hunan Province (CX20240417).

## References

* [1] P. E. Beeler, D. W. Bates, and B. L. Hug. Clinical decision support systems. _Swiss medical weekly_, 144(5152):w14073-w14073, 2014.
* [2] P. Bhardwaj. Types of sampling in research. _Journal of Primary Care Specialities_, 5(3):157-163, 2019.
* [3] T. Chen and C. Guestrin. Xgboost: A scalable tree boosting system. In _Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining_, pages 785-794, 2016.
* [4] C. Cortes and V. Vapnik. Support-vector networks. _Machine learning_, 20:273-297, 1995.
* [5] D. R. Cox. The regression analysis of binary sequences. _Journal of the Royal Statistical Society Series B: Statistical Methodology_, 20(2):215-232, 1958.
* [6] Y. Freund and R. E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. _Journal of computer and system sciences_, 55(1):119-139, 1997.
* [7] J. Gao, C. Xiao, Y. Wang, W. Tang, L. M. Glass, and J. Sun. Stagenet: Stage-aware neural networks for health risk prediction. In _Proceedings of The Web Conference 2020_, pages 530-540, 2020.
* [8] A. Gu and T. Dao. Mamba: Linear-time sequence modeling with selective state spaces, 2023.
* [9] C.-C. Hsu and B. A. Sandford. The delphi technique: making sense of consensus. _Practical assessment, research, and evaluation_, 12(1), 2007.
* [10] A. E. Johnson, L. Bulgarelli, L. Shen, A. Gayles, A. Shammout, S. Horng, T. J. Pollard, S. Hao, B. Moody, B. Gow, et al. Mimic-iv, a freely accessible electronic health record dataset. _Scientific data_, 10(1):1, 2023.
* [11] A. E. Johnson, T. J. Pollard, L. Shen, L.-w. H. Lehman, M. Feng, M. Ghassemi, B. Moody, P. Szolovits, L. Anthony Celi, and R. G. Mark. Mimic-iii, a freely accessible critical care database. _Scientific data_, 3(1):1-9, 2016.

* [12] G. Ke, Q. Meng, T. Finley, T. Wang, W. Chen, W. Ma, Q. Ye, and T.-Y. Liu. Lightgbm: A highly efficient gradient boosting decision tree. _Advances in neural information processing systems_, 30, 2017.
* [13] M. Kuhn, I. Letunic, L. J. Jensen, and P. Bork. The sider database of drugs and side effects. _Nucleic acids research_, 44(D1):D1075-D1079, 2016.
* [14] A. Liaw, M. Wiener, et al. Classification and regression by randomforest. _R news_, 2(3):18-22, 2002.
* [15] Y. Liu, T. Hu, H. Zhang, H. Wu, S. Wang, L. Ma, and M. Long. itransformer: Inverted transformers are effective for time series forecasting. _arXiv preprint arXiv:2310.06625_, 2023.
* [16] L. Ma, J. Gao, Y. Wang, C. Zhang, J. Wang, W. Ruan, W. Tang, X. Gao, and X. Ma. Adacare: Explainable clinical health status representation learning via scale-adaptive feature extraction and recalibration. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 34, pages 825-832, 2020.
* [17] D. McElfresh, S. Khandagale, J. Valverde, V. Prasad C, G. Ramakrishnan, M. Goldblum, and C. White. When do neural nets outperform boosted trees on tabular data? _Advances in Neural Information Processing Systems_, 36, 2024.
* [18] C. Okoli and S. D. Pawlowski. The delphi method as a research tool: an example, design considerations and applications. _Information & management_, 42(1):15-29, 2004.
* [19] C. Ordun. Intelligent sight and sound: A chronic cancer facial pain dataset. In _Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track_, 2021.
* [20] T. J. Pollard, A. E. Johnson, J. D. Raffa, L. A. Celi, R. G. Mark, and O. Badawi. The eicu collaborative research database, a freely available multi-center database for critical care research. _Scientific data_, 5(1):1-13, 2018.
* [21] J. Price, A. Rushton, V. Tyros, and N. R. Heneghan. Consensus on the exercise and dosage variables of an exercise training programme for chronic non-specific neck pain: protocol for an international e-delphi study. _BMJ open_, 10(5):e037656, 2020.
* [22] J. R. Quinlan. Induction of decision trees. _Machine learning_, 1:81-106, 1986.
* [23] D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Learning representations by back-propagating errors. _nature_, 323(6088):533-536, 1986.
* [24] R. Shawahna et al. Development of key performance indicators for capturing impact of pharmaceutical care in palestinian integrative healthcare facilities: a delphi consensus study. _Evidence-Based Complementary and Alternative Medicine_, 2020, 2020.
* [25] R. Shawahna, S. Khalaily, and D. A. Saleh. Promoters of therapeutic inertia in managing hypertension: a consensus-based study. _American Journal of Managed Care_, 27(11), 2021.
* seer 18 regs research data, nov 2021 sub (1975-2019)
- linked to county attributes
- time dependent (1990-2019) income/rurality, 1969-2019 counties, 2022. National Cancer Institute, DCCPS, Surveillance Research Program, released April 2022, based on the November 2021 submission. Available at: https://seer.cancer.gov/.
* [27] N. P. Tatonetti, P. P. Ye, R. Daneshjou, and R. B. Altman. Data-driven prediction of drug effects and interactions. _Science translational medicine_, 4(125):125ra31-125ra31, 2012.
* [28] U.S. Food and Drug Administration. Fda adverse event reporting system (faers) public dashboard. https://fis.fda.gov/extensions/FPD-QDE-FAERS/FPD-QDE-FAERS.html, 2024. Accessed on 2024-05-09.
* [29] Z. Wang and J. Sun. Transtab: Learning transferable tabular transformers across tables. _Advances in Neural Information Processing Systems_, 35:2902-2915, 2022.
* [30] L. Zhang, X.-Y. Ren, H.-X. Huang, Y.-M. Huang, L. Huang, X.-P. Chen, Y. Chen, C. Wang, and J. Xiao. Development of the practice of pharmaceutical care for cancer pain management in outpatient clinics using the delphi method. _Frontiers in Pharmacology_, 13:840560, 2022.

## Checklist

1. For all authors... 1. Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes] See Section 3 and Section 4. 2. Did you describe the limitations of your work? [Yes] See Section 5. 3. Did you discuss any potential negative societal impacts of your work? [Yes] See Section 3.7 and Section 6. 4. Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes] See Section 3 and Section 6
2. If you are including theoretical results... 1. Did you state the full set of assumptions of all theoretical results? [N/A] 2. Did you include complete proofs of all theoretical results? [N/A]
3. If you ran experiments (e.g. for benchmarks)... 1. Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes] See the abstract for links to the dataset, and the code and data are available. The code includes a README file with the instructions needed to reproduce the main experimental results. 2. Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes] See Section 4.1.3 and Appendix D.2 3. Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [Yes] Refer to Table 4 and Table 5 in Section 4.2, and Table 14 and Table 15 in Appendix D.4. 4. Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes] See Section 4.1.3
4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets... 1. If your work uses existing assets, did you cite the creators? [Yes] See Section 4.1 2. Did you mention the license of the assets? [Yes] See Section 3.7 and The license is in Appendix E 3. Did you include any new assets either in the supplemental material or as a URL? [Yes] See Abstract, Section 1of footnotes and Appendix E 4. Did you discuss whether and how consent was obtained from people whose data you're using/curating? [Yes] See Section 3.7 and Appendix E 5. Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [Yes] See Section 3.2
5. If you used crowdsourcing or conducted research with human subjects... 1. Did you include the full text of instructions given to participants and screenshots, if applicable? [Yes] See Section 3.1 2. Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [Yes] See Section 3.1, IRB Ethics Approval ID: 202109422 3. Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A]Online Follow-up Platform

As illustrated in Figure 3, the cancer pain online follow-up platform allows patients to proactively report their condition after hospital discharge. Given that our system operates in a non-English environment, we have translated its pages into English to ensure readability and comprehension.

## Appendix B Delphi Process Design

### Process Design

In each round of the Delphi survey, experts were asked to rate each item using a five-point Likert scale (ranging from strongly agree, agree, neutral, disagree, to strongly disagree). Consensus was defined as: 1) an average score of \(\geq\) 4.0; 2) a coefficient of variation <0.15; and 3) no dissenting opinions. Additionally, experts were required to self-assess their authority (Cr) for each round, determined by the judgement criteria (Ca) and their familiarity with the clinical issues (Cs). The Ca encompassed four dimensions: work experience, theoretical analysis, understanding from domestic and international peers, and insights. The Cs included five levels: very familiar, familiar, somewhat familiar, unfamiliar, and very unfamiliar, quantified as 1.0, 0.8, 0.6, 0.4, and 0.2, respectively. Both rounds of questionnaires will calculate the experts' coordination coefficient (W) and response rate, with a response rate of 75% or above considered satisfactory. The questionnaires were distributed to experts via email. To ensure a high response rate, each Delphi round was open for two weeks, with email reminders sent at the start and end of each round.

Figure 3: Functions of the cancer pain online follow-up platform (English translation version)

The expert response rate was calculated as follows:

\[\text{Expert Coefficient}=\left(\frac{\text{Number of returned questionnaires}}{\text{ Number of distributed questionnaires}}\right)\times 100\%\] (1)

The coordination ratio \(Cr\) was calculated using:

\[Cr=\frac{Ca+Cs}{2}\] (2)

The experts' opinion coordination coefficient (W) was represented by Kendall's \(W\), with differences assessed using the Chi-square (\(\chi^{2}\)) test. A \(p\)-value of less than 0.05 was considered statistically significant.

### Expert Invitation

A total of 32 experts from nine provinces in China were invited to participate in this study, including 16 pharmacists, 4 anesthetists, 4 oncologists, and 8 nurses. All experts are employed at top-tier hospitals in China. Detailed demographic information of the experts is provided in Table 6.

### First Round Delphi

In the first round of the Delphi survey, experts were invited to rate 21 items across 6 themes, as shown in Table 7(Clinical features of the first round). All items were rated as "Agree" or "Strongly Agree," with an average score of \(\geq\)4.0. In this round, consensus was reached for 17 items (80.9%) submitted to the expert panel. Specifically, 5 items from Theme A, 5 items from Theme B, 4 items from Theme C, and all items from Themes D, E, and F achieved consensus. Items A3 (Smoking history, alcohol consumption history, allergic history), B6-1 (Worsening factors, including activities,

\begin{table}
\begin{tabular}{l r r} \hline \hline
**Characteristic** & **N** & **\%** \\ \hline
**Gender** & & \\ Male & 6 & 18.6 \\ Female & 26 & 81.4 \\ \hline
**Age** & & \\
30-39 & & 10 & 31.3 \\
40-49 & & 16 & 50.0 \\ \(\geq\)50 & & 6 & 18.7 \\ \hline
**Profession** & & \\ Pharmacist & 16 & 50.0 \\ Anaesthetists & 4 & 12.5 \\ Oncologists & 4 & 12.5 \\ Nurse & 8 & 25.0 \\ \hline
**Professional title** & & \\ Director & 9 & 28.1 \\ Associate director & 23 & 71.9 \\ \hline
**Highest level of education** & & \\ Bachelor degree & 9 & 28.1 \\ Master degree & 12 & 37.5 \\ Doctoral degree & 11 & 34.4 \\ \hline
**Experience in cancer pain management (years)** & & \\
5-9 & 13 & 40.6 \\
10-19 & 14 & 43.8 \\
20-29 & 3 & 9.4 \\ \(\geq\)30 & 2 & 6.2 \\ \hline \hline \end{tabular}
\end{table}
Table 6: Baseline characteristics of the expertsweather, and mental factors), B6-2 (Alleviating factors, including rest, suitable environment, and taking analgesics), and C2 (Duration of analgesics use) did not meet the inclusion criteria for the coefficient of variation and will thus proceed to the second round.

Additionally, three supplementary items submitted by the experts will be included in the second round: O1 (Monitoring and management of analgesic-related adverse reactions), O2 (Patient lifestyle), and O3 (Drug accessibility).

### Second Round Delphi

Based on the results of the first round of evaluations, the new questionnaire includes 7 items. In this round, consensus was achieved for 3 items (42.8%) submitted to the expert panel. Items A3, C2, and the newly introduced item O1 were included, while the other items were excluded. The results of the second round are shown in Table 7(Clinical features of the second round).

Figure 4: Overview of the Delphi rounds

[MISSING_PAGE_EMPTY:16]

The response rate for both rounds was 100% (32/32). In both rounds of the Delphi survey, the mean familiarity score (Cs), the mean judgment criteria score (Ca), and the mean authority coefficient (Cr) of the experts were all greater than 0.70 (Tables 8 and 9). The coordination coefficient (W) of the experts' opinions was 0.195 in the first round and 0.250 in the second round. The \(\chi^{2}\) test indicated that the coordination of expert opinions was significant (p < 0.05), suggesting that the experts' opinions were well-coordinated and the results are reliable (Table 10).

As shown in Figure 4, consensus was reached on 20 feature items over two rounds of the Delphi process. From these 20 items, a total of 103 sub-items were included as features, covering six areas: basic patient information, comprehensive pain assessment, previous analgesic treatment and evaluation, cancer pain medication decision-making, monitoring and management of adverse reactions, and pain relief assessment.

### Feature Description

Patients in the PEACE dataset have the following features (for data type, B: Binary, N: Numeric, M: Multiclass, *: Label):

**Patient Basic Information(50)**

1. **Demographics** * **ID (N)**: A unique random identification number assigned to each patient.
2. **Gender (B)**: The gender of the patient.
3. **Age (N)**: The age of the patient.
4. **Height (N)**: The height of the patient.
5. **Weight (N)**: The weight of the patient.
6. **BMI (N)**: A common indicator for assessing body fat, calculated using weight and height.

\begin{table}
\begin{tabular}{l c c c} \hline \hline
**Delphi round** & **Items** & **W** & \(\chi^{2}\) & **P** \\ \hline Round 1 & 21 & 0.195 & 126.779 & \textless{}0.001 \\ Round 2 & 7 & 0.250 & 54.163 & 0.006 \\ \hline \hline \end{tabular}
\end{table}
Table 10: Coefficient of concordance (W) of experts in each round

\begin{table}
\begin{tabular}{l c c} \hline \hline
**Themes** & **Cs** & **Ca** & **Cr** \\ \hline Patient Basic Information & 0.79 & 0.86 & 0.82 \\ Comprehensive Pain Assessment & 0.87 & 0.87 & 0.87 \\ Previous Analgesic Treatment & 0.83 & 0.80 & 0.81 \\ Evaluation of Previous Analgesic Treatment & 0.76 & 0.83 & 0.79 \\ Cancer Pain Medication Decision & 0.76 & 0.85 & 0.80 \\ Follow-up & 0.88 & 0.93 & 0.90 \\ \hline \hline \end{tabular}
\end{table}
Table 8: Expert authority coefficient (Cr) in the first round

\begin{table}
\begin{tabular}{l c c c} \hline \hline
**Themes** & **Cs** & **Ca** & **Cr** \\ \hline Patient Basic Information & 0.83 & 0.88 & 0.85 \\ Comprehensive pain assessment & 0.87 & 0.86 & 0.86 \\ Previous analgesic treatment & 0.81 & 0.78 & 0.79 \\ Monitoring and management of analgesic-related adverse reactions & 0.87 & 0.90 & 0.88 \\ Drug accessibility & & 0.77 & 0.82 & 0.79 \\ Lifestyle of patients & & 0.91 & 0.80 & 0.85 \\ \hline \hline \end{tabular}
\end{table}
Table 9: Expert authority coefficient (Cr) in the second round * **Body Surface Area (BSA) (N)**: The total surface area of the human body.
* **Medical Record Date (N)**: The date on which the doctor makes a decision regarding cancer pain medication treatment based on a comprehensive pain assessment.
* **Length of Hospital Stay (N)**: The duration of the patient's stay during the current hospital visit, measured in days.
* **Number of Hospital Admissions (N)**: The total number of times the patient has been hospitalized due to tumour diseases.
* **Diagnosis (M)**: The diagnosis provided by the doctor at the time of discharge, only including tumour-related diseases.
* **Smoking History (B)**: Whether the patient has a history of smoking continuously for 6 months or more.
* **Drinking History (B)**: Whether the patient has a history of drinking alcohol at least once a week for 6 months or more.
* **Allergy History (B)**: Whether the patient has experienced allergic reactions.
* **Tumour Treatment Methods (M)**: The methods of tumour treatment, including surgery, chemotherapy, radiotherapy, targeted therapy, and immunotherapy.
* **Gastrointestinal Risk (B)**: The likelihood of the patient developing gastrointestinal diseases (such as gastric ulcers, gastritis, enteritis) or related adverse reactions (such as gastrointestinal bleeding, indigestion) after taking pain medication.
* **Cardiovascular Risk (B)**: The likelihood of the patient developing cardiovascular diseases (such as hypertension, coronary heart disease, myocardial infarction) or related adverse reactions (such as arrhythmia, heart failure) after taking pain medication.
* **PS Score (N)**: The performance status score.
2. **Laboratory Examination Variables** 1. **Complete Blood Count:** * **White Blood Cell Count (N)**: The number of white blood cells in a unit volume of blood. * **Red Blood Cell Count (N)**: The number of red blood cells in a unit volume of blood. * **Hemoglobin (N)**: The amount of hemoglobin in a unit volume of blood. * **Platelet Count (N)**: The number of platelets in a unit volume of blood. * **Hematoricit (N)**: The volume percentage of red blood cells in blood. * **Neutrophil Count (N)**: The number of neutrophils in a unit volume of blood. * **Lymphocyte Count (N)**: The number of lymphocytes in a unit volume of blood. * **Eosinophil Count (N)**: The number of eosinophils in a unit volume of blood. * **Basophil Count (N)**: The number of basophils in a unit volume of blood. * **Monocyte Percentage (N)**: The proportion of monocytes in the total white blood cell count. * **Neutrophil Percentage (N)**: The proportion of neutrophils in the total white blood cell count. * **Lymphocyte Percentage (N)**: The proportion of lymphocytes in the total white blood cell count. * **Basophil Percentage (N)**: The proportion of basophils in the total white blood cell count. * **Eosinophil Percentage (N)**: The proportion of eosinophils in the total white blood cell count. * **Mean Corpuscular Volume (N)**: The average volume of a single red blood cell. * **Mean Corpuscular Hemoglobin (N)**: The average amount of hemoglobin in a single red blood cell. * **Mean Corpuscular Hemoglobin Concentration (N)**: The average concentration of hemoglobin in a single red blood cell.

* **Red Cell Distribution Width (N)**: The variation in the size of red blood cells.
* **Plateletcrit (N)**: The volume percentage of platelets in blood.
* **Mean Platelet Volume (N)**: The average volume of a single platelet.
* **Liver Function:*
* **Total Protein (N)**: The total amount of proteins in a unit volume of blood.
* **Albumin (N)**: The amount of albumin in a unit volume of blood.
* **Globulin (N)**: The amount of globulin in a unit volume of blood.
* **Albumin/Globulin Ratio (N)**: The ratio of albumin to globulin in blood.
* **Total Bilirubin (N)**: The total amount of bilirubin in a unit volume of blood.
* **Direct Bilirubin (N)**: The amount of direct (conjugated) bilirubin in a unit volume of blood.
* **Total Bile Acids (N)**: The total amount of bile acids in a unit volume of blood.
* **Alanine Aminotransferase (N)**: The amount of alanine aminotransferase (ALT) in a unit volume of blood.
* **Aspartate Aminotransferase (N)**: The amount of aspartate aminotransferase (AST) in a unit volume of blood.
* **Kidney Function:*
* **Urea (N)**: The amount of urea in a unit volume of blood, reflecting kidney excretory function.
* **Creatinine (N)**: The amount of creatinine in a unit volume of blood, reflecting kidney filtration function.
* **Uric Acid (N)**: The amount of uric acid in a unit volume of blood, reflecting kidney excretory function and purine metabolism status.

**Comprehensive Pain Assessment (15):**

* **Pain Type (M)**: Classification of pain based on the pathological mechanism.
* **Worst Pain (N)**: The highest level of pain experienced in the last 24 hours, assessed using the Numerical Rating Scale (NRS).
* **Mildest Pain (N)**: The lowest level of pain experienced in the last 24 hours, assessed using NRS.
* **Average Pain (N)**: The average level of pain experienced in the last 24 hours, assessed using NRS.
* **Current Pain (N)**: The current level of pain, assessed using NRS.
* **Impact of Pain on Daily Life (N)**: The degree to which daily life was affected by pain in the past week.
* **Impact of Pain on Mood (N)**: The degree to which mood was affected by pain in the past week.
* **Impact of Pain on Walking Ability (N)**: The degree to which walking ability was affected by pain in the past week.
* **Impact of Pain on Daily Work (N)**: The degree to which daily work was affected by pain in the past week.
* **Impact of Pain on Relationships with Others (N)**: The degree to which relationships with others were affected by pain in the past week.
* **Impact of Pain on Sleep (N)**: The degree to which sleep was affected by pain in the past week.
* **Impact of Pain on Interest in Life (N)**: The degree to which interest in life was affected by pain in the past week.
* **Pain Frequency (M)**: The number of times pain occurred in a day for cancer pain patients.

* **Type of Breakthrough Pain (M)**: Classification of breakthrough pain according to the National Comprehensive Cancer Network (NCCN).
* **Frequency of Breakthrough Pain (M)**: The number of times breakthrough pain occurred in a day for cancer pain patients.

**Previous Analgesic Treatment(23):**

* **Prev_Extended Release Strong Opiates (ERSO) (N)**: The number of types of extended-release strong opiates used by the patient in the past week.
* **Prev_Immediate Release Strong Opiates (IRSO) (N)**: The number of types of immediate-release strong opiates used by the patient in the past week.
* **Prev_Extended Release Weak Opiates (ERWO) (N)**: The number of types of extended-release weak opiates used by the patient in the past week.
* **Prev_Immediate Release Weak Opiates (IRWO) (N)**: The number of types of immediate-release weak opiates used by the patient in the past week.
* **Prev_Nonsteroidal Anti-inflammatory Drugs (NSAID) (N)**: The number of types of nonsteroidal anti-inflammatory drugs used by the patient in the past week.
* **Prev_Anticonvulsants/Antidepressants (A/A) (N)**: The number of types of anticonvulsants/antidepressants used by the patient in the past week.
* **Prev_Others (N)**: The number of other analgesics used by the patient in the past week, excluding ERSO, IRSO, ERWO, IRWO, NSAIDs, and A/A.
* **Opiate Tolerance (B)**: Whether the patient has developed a decreased effect or reduced duration of action when using opiates for pain treatment.
* **Days of Medication Use (N)**: The number of days the patient used opiates (calculated based on the highest level of opiates used if multiple types were used simultaneously).
* The following 9 items are from the Morisky Medication Adherence Scale (MMAS-8), including 8 questions and a total score:
* **M1 (N)**: Do you sometimes forget to take your medications?
* **M2 (N)**: People sometimes miss taking their medications for reasons other than forgetting. Thinking over the past two weeks, were there any days when you did not take your medications?
* **M3 (N)**: Have you ever cut back or stopped taking your medications without telling your doctor because you felt worse when you took them?
* **M4 (N)**: When you travel or leave home, do you sometimes forget to bring along your medications?
* **M5 (N)**: Did you take all your medications yesterday?
* **M6 (N)**: When you feel like your symptoms are under control, do you sometimes stop taking your medications?
* **M7 (N)**: Taking medication every day is a real inconvenience for some people. Do you ever feel hasled about sticking to your treatment plan?
* **M8 (N)**: Do you have difficulty remembering to take all your medications?
* **MMAS-8 Total Score (N)**: The total score ranges from M1 to M8, with higher scores indicating better adherence to medication.
* **Duration of Analgesic Control (N)**: The duration of pain control after taking analgesics.
* **Constipation (B)**: Whether the patient experienced constipation as an adverse reaction after taking analgesics.
* **Nausea/Vomiting (B)**: Whether the patient experienced nausea or vomiting as an adverse reaction after taking analgesics.

* **Other Adverse Reactions (B)**: Whether the patient experienced other adverse reactions besides constipation and nausea/vomiting after taking analgesics.
* **Medication for Adverse Reactions (B)**: Whether the patient used medications to manage adverse reactions.

Evaluation of Previous Analgesic Treatment(5):

1. The following 5 features are classified according to the Pharmaceutical Care Network Europe (PCNE) V8.0 classification of drug-related problems (DRPs): * **Drug-Related Problems (DRPs) (M)**: Any undesirable outcome or potential issue arising during the patient's drug therapy. This includes aspects of treatment effectiveness and safety.
* **Causes (M)**: The underlying causes or factors leading to drug therapy problems.
* **Interventions (M)**: Specific actions or measures taken to address drug therapy problems. These interventions can be implemented by pharmacists, doctors, or other healthcare professionals.
* **Acceptance of Interventions (M)**: The patient's acceptance of the intervention plans proposed by healthcare professionals.
* **Status of DRPs (M)**: The resolution status of DRPs after healthcare professionals' intervention.

Cancer Pain Medication Decision(9):

* **ERSO_Recommended (N*)**: The number of extended-release strong opiates recommended by the doctor.
* **IRSO_Recommended (N*)**: The number of immediate-release strong opiates recommended by the doctor.
* **ERWO_Recommended (N*)**: The number of extended-release weak opiates recommended by the doctor.
* **IRWO_Recommended (N*)**: The number of immediate-release weak opiates recommended by the doctor.
* **NSAIDs_Recommended (N*)**: The number of nonsteroidal anti-inflammatory drugs recommended by the doctor.
* **A/A_Recommended (N*)**: The number of anticonvulsants/antidepressants recommended by the doctor.
* **Others (N*)**: The number of other analgesics recommended by the doctor, excluding ERSO, IRSO, ERWO, INAIDs, and A/A.
* **Constipation Medication Recommended (M)**: The types of medication recommended by the doctor for managing constipation.
* **Nausea/Vomiting Medication Recommended (M)**: The types of medication recommended by the doctor for managing nausea and vomiting.

Follow-up(1):

* **Pain Relief Status (M*)**: The degree of pain relief experienced by the patient after using the analgesic regimen recommended by the doctor.

## Appendix C Demographics

This section examines the age distribution within the PEACE dataset. We analyze the population breakdown across different age groups, as detailed in Table 11. The table categorizes the number of individuals in each age group by gender.

## Appendix D Training Details

### Baseline Models

The source code of the models used in our experiments is available at https://github.com/YTYTYTYD/PEACE/tree/main/Code.

**Basic machine learning and neural network models:**

1. Decision Trees[22]: A machine learning algorithm that predicts outcomes by recursively splitting data into subsets based on feature values, forming a tree structure of decisions.
2. Logistic Regression[5]: A machine learning algorithm used for both classification and regression tasks that models the probability of outcomes using a logistic function.
3. Random Forests[14]: A machine learning algorithm that employs an ensemble of decision trees to improve prediction accuracy and control overfitting by aggregating the predictions of multiple trees.
4. Support Vector Machines (SVM)[4]: A machine learning algorithm for classification and regression that identifies the optimal hyperplane to separate different classes in a high-dimensional space.
5. Multilayer Perceptrons (MLP)[23]: A neural network algorithm composed of multiple layers of neurons, capable of performing various tasks including classification and regression.

**Gradient boosting decision tree models:**

1. LightGBM[12]: is an advanced machine learning algorithm that implements gradient boosting on decision trees using a leaf-wise growth strategy, offering superior performance and computational efficiency for large-scale and high-dimensional datasets.
2. XGBoost[3]: is a highly optimised and scalable machine learning algorithm that applies gradient boosting techniques with features like regularisation, parallel processing, and tree pruning, achieving exceptional performance and accuracy in various predictive modelling tasks.
3. AdaBoost[6]: is a machine learning algorithm that enhances classification and regression accuracy by iteratively combining multiple weak classifiers into a strong classifier, focusing on misclassified instances to improve overall model performance.

**Advanced neural network models:**

1. iTransformer[15]: is a neural network algorithm specifically designed for time series forecasting. It inverts the traditional transformer architecture to better capture temporal dependencies and sequence patterns in time series data. By reversing the order of attention mechanisms, iTransformer focuses on leveraging past data more effectively to predict future values. The algorithm employs a novel architecture that integrates both local and global temporal information, leading to significant improvements in forecasting accuracy.

\begin{table}
\begin{tabular}{l c c c} \hline \hline
**Age Group** & **Number** & **Male** & **Female** \\ \hline
18-29 & 2,681 & 1,931 & 750 \\
30-44 & 7,675 & 5,045 & 2,630 \\
45-59 & 14,737 & 7,663 & 7,074 \\
60-74 & 11,054 & 4,316 & 6,738 \\ \(\geq\)75 & 2,619 & 969 & 1,650 \\ \hline Total & 38,766 & 18,842 & 19,924 \\ \hline \hline \end{tabular}
\end{table}
Table 11: Population Distribution2. Transtab[29]: is a neural network algorithm based on transformer architecture, designed to handle tabular data with varying structures by converting each row into a generalisable embedding vector and using stacked transformers for feature encoding. It combines column descriptions and table cells as input to a gated transformer model and leverages supervised and self-supervised pretraining to enhance performance. Transtab excels in learning from multiple tables with partially overlapping columns and updating models incrementally, achieving top rankings in supervised, incremental, and transfer learning tasks across diverse datasets.
3. Mamba[8]: is a neural network algorithm that addresses the inefficiencies of transformer models in sequence modeling. By using selective state space models (SSMs) where parameters depend on the input, Mamba can selectively retain or discard information, achieving linear scaling in sequence length without attention or MLP blocks. This design enables faster inference and high throughput, demonstrating state-of-the-art performance across various domains, including language, audio, and genomics, and outperforming similarly sized transformers.

**EHR-specific models:**

1. Stagenet[7]: is a neural network model designed for health risk prediction, leveraging the identification of different stages in a patient's disease progression to improve prediction accuracy. The model consists of two key modules: the stage-aware LSTM module, which automatically and unsupervisedly extracts stage variations in a patient's health condition, and the stage-adaptive convolutional module, which uses convolution operations to capture health progression patterns from these stages, focusing on stage-specific features and recalibrating them to enhance prediction outcomes.
2. Adacare[16]: is a health status representation learning model focused on EHR, capable of capturing the variation trends of biomarkers in both long-term and short-term scales. It uses dilated convolutions to capture features across different time scales. Additionally, it incorporates a scale-adaptive feature recalibration module, which adaptively enhances important features based on the patient's health condition while suppressing irrelevant features.

### Data splitting

Data splitting for model training. see Figure 5. For the TEA task, we removed some records with missing labels.

### Evaluation Metrics

This section describes the metrics used to evaluate the performance of the trained model. For classification tasks, TP (True Positive) is a true positive, TN (True Negative) is a true negative, FP (False Positive) is a false positive, and FN (False Negative) is a false negative. Our evaluation metrics

Figure 5: Data splitting for PEACE dataset

and calculation methods are shown in Table 12. For regression tasks, \(y_{i}\) is the actual value, \(\hat{y}_{i}\) is the predicted value, and \(n\) is the number of observations. Our evaluation metrics and calculation methods are shown in Table 13.

### Detailed Experimental Results

Tables 14 and 15 respectively present the performance evaluation details of TEA and MR tasks, including the detailed evaluation metrics for each fold, the mean and error of the 5-folds, and the values for the independent test set. The statistical and analytical processing of experimental results retains four decimal places to minimise rounding errors. We acknowledge that data processing and visualisation tasks, including calculations of means and errors, are supported by large language models (LLMs).

## Appendix E Release and Usage of Dataset

We release the PEACE dataset under a CC-BY license. The dataset access involves three steps:

1. Complete some training and provide certification (such as the CITI or GCP certification).
2. Carefully read the terms of the Data Use Agreement and if you agree and wish to proceed, send your application to the manager. Please use an official email address (such as.edu).
3. Final approval of data access is required by Xiangya Hospital

Once an application is approved, the researcher will receive an email with instructions for downloading the dataset. We estimate a response time of 20 business days for processing requests. This duration may vary depending on the completeness of the provided information and can take up to three months. Any model trained on this dataset should not be deployed in real-world systems

\begin{table}
\begin{tabular}{l l} \hline
**Metric** & **Explanation and Formula** \\ \hline \multirow{2}{*}{\begin{tabular}{l} Mean Squared Error \\ (MSE) \\ \end{tabular} } & **Explanation:** MSE measures the average squared difference between the predicted values and the actual values. It gives a higher weight to larger errors, making it sensitive to outliers. \\  & **Formula:** MSE \(=\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}\) \\ \hline \multirow{2}{*}{
\begin{tabular}{l} Mean Absolute Error \\ (MAE) \\ \end{tabular} } & **Explanation:** MAE measures the average absolute difference between the predicted values and the actual values. It gives equal weight to all errors, making it less sensitive to outliers. \\  & **Formula:** MAE \(=\frac{1}{n}\sum_{i=1}^{n}|y_{i}-\hat{y}_{i}|\) \\ \hline \end{tabular}
\end{table}
Table 12: Classification evaluation metrics

\begin{table}
\begin{tabular}{l l} \hline
**Metric** & **Explanation and Formula** \\ \hline \multirow{2}{*}{\begin{tabular}{l} Accuracy (ACC) \\ \end{tabular} } & **Explanation:** Accuracy is the proportion of correctly predicted samples out of the total samples. \\  & **Formula:** Accuracy \(=\frac{TP+TN}{TP+TN+FP+FN}\) \\ \hline \multirow{2}{*}{\begin{tabular}{l} Area Under the Receiver Operating Characteristic Curve \\ (AUROC) \\ \end{tabular} } & **Explanation:** AUROC is the area under the ROC curve, which evaluates the performance of a classification model. The ROC curve shows the trade-off between the true positive rate (TPR) and false positive rate (FPR) at various threshold settings. \\ \hline \multirow{2}{*}{
\begin{tabular}{l} Recall \\ \end{tabular} } & **Explanation:** Recall is the proportion of true positives correctly identified by the model out of all actual positives. \\  & **Formula:** Recall \(=\frac{TP}{TP+FN}\) \\ \hline \multirow{2}{*}{Precision} & **Explanation:** Precision is the proportion of true positives correctly identified by the model out of all predicted positives. \\  & **Formula:** Precision \(=\frac{TP}{TP+FP}\) \\ \hline \multirow{2}{*}{F1 Score} & **Explanation:** The F1 score is the harmonic mean of precision and recall, providing a balance between the two. \\  & **Formula:**\(F1=2\times\frac{\text{Precision}\times\text{Recall}}{\text{Discussion+Recall}}\) \\ \hline \end{tabular}
\end{table}
Table 13: Regression evaluation metrics 

[MISSING_PAGE_FAIL:25]

[MISSING_PAGE_FAIL:26]

until its performance has been rigorously evaluated and the system's scope and representative-ness in relation to real-world applications have been validated. Data usage must strictly adhere to applicable regulations in China. Access to the PEACE dataset can be found at the following address:[https://github.com/YTYTYD/PEACE].

### Dataset Documentation

**Main Data:**

1. All_Data.csv: a.CSV file containing all patients in the dataset, with patient ID.
2. All_data.json: a.JSON file describing all the data in the dataset.

**Dictionaries:**

1. D_Numerical.csv: A.csv file containing the units of the numerical features.
2. D_Multiclass.csv: A.csv file containing the meaning of multiclass features.
3. D_Diagnosis.csv: A.csv file containing the meaning of diagnosis.

**Model Training:**

1. Train data: a.CSV file containing the training set of patients.
2. Test data: a.CSV file containing the test set of patients.

### Responsibility Statement

The corresponding author(s) acknowledge and accept full responsibility for any potential infringement of rights associated with this dataset.

### Ethical Considerations

All data are de-identified to the greatest extent possible and stored in a database controlled internally by Xiangya Hospital. This work has been approved by the Xiangya Hospital Institutional Review Board (Ethics Approval No.: 202109422). The data are available for future research by other Xiangya Hospital researchers. Access for external researchers will be provided under restricted conditions, with permissions ultimately reviewed by the Xiangya Hospital.

## Appendix F Samples and Case Studies

**Sample 1:**

As shown in Table 16, the patient in Sample 1 was diagnosed with a malignant tumor of the right kidney with multiple metastases. The patient denies any history of allergies, smoking, or alcohol consumption. Chemotherapy was chosen as the treatment method for the tumor. After evaluation, no cardiovascular or gastrointestinal risks were identified. The results of the complete blood count, liver function, and kidney function tests were all within normal ranges. The type of pain experienced is somatic, with a Numerical Rating Scale (NRS) score of 8 at its most severe, 6 at its least severe, an average of 8, and currently 6. This indicates severe pain that significantly affects the patient's daily life and emotions. The pain occurs three or more times per day. Breakthrough pain is of the end-of-dose type, occurring three or more times per day. The tumor symptoms are severe. The patient has been using sustained-release strong opioids for three days, with a compliance score of 5.75, and has not tolerated opioids well. Pain control lasts for six hours post-medication, with side effects of constipation, nausea, and vomiting, which have been managed with additional medications. The patient's pain control is poor, possibly due to inappropriate medication selection. The doctor and pharmacist recommended continuing the use of sustained-release strong opioids and adding NSAIDs, along with medications for constipation and nausea. The patient fully complied with and followed the advice. One week later, during follow-up, the pain was mildly relieved and evaluated as moderate pain. It was recommended to increase the dose of sustained-release strong opioids, continue using NSAIDs, and medications for adverse effects. After adjusting the dose, the pain was partially relieved, but breakthrough pain persisted. It was recommended to use sustained-release strong opioids, immediate-release strong opioids, and NSAIDs. Following this adjustment, the patient's pain was completely relieved, and it was recommended to continue the treatment as per the original plan.

**Sample 2:**

As shown in Table 17, the patient in Sample 2 was diagnosed with a malignant tumor of the jejunum. The patient denies any history of allergies, smoking, or alcohol consumption. The treatment for the tumor involved surgery. After evaluation, there were no cardiovascular or gastrointestinal risks. The results of the complete blood count, liver function, and kidney function tests were all normal. The type of pain experienced is visceral pain, with an NRS (Numerical Rating Scale) of 6 at its most severe, 3 at its least severe, an average of 5, and currently 2. The pain affects daily life and emotions. The frequency of pain is less than three times per day, with activity-induced breakthrough pain occurring less than three times per day. The tumor symptoms are mild. The patient has been using immediate-release weak opioids for 10 days, with a compliance score of 3.25. Nausea and vomiting were observed after medication administration. Poor pain control might be due to an insufficient dose. The pharmacist and doctor recommended continuing the use of immediate-release weak opioids and increasing the dose, along with antielectic medication. After administration, the pain was partially relieved. Five days later, the patient's NRS was 7 at its most severe, 4 at its least severe, with an average of 6, and currently 6. No breakthrough pain was reported. The patient had been using immediate-release weak opioids for 15 days, with a compliance score of 7. The analgesic effect was poor, possibly due to inappropriate medication selection. After discussion with the pharmacist, the doctor adjusted the medication to sustained-release strong opioids. The patient fully complied and followed the advice. One week later, during follow-up, the pain was partially relieved after taking sustained-release strong opioids.

**Sample 3:**

As shown in Table 18, the patient in Sample 3 was diagnosed with a malignant tumor of the ascending colon. The patient denies any history of allergies or smoking but has a history of alcohol consumption. After evaluation, there were no cardiovascular or gastrointestinal risks. The results of the complete blood count, liver function, and kidney function tests were all normal. The type of pain is mixed, with an NRS (Numerical Rating Scale) of 10 at its most severe, 2 at its least severe, an average of 6, and currently 8. The pain affects daily life and emotions. The pain frequency is less than three times per day, with breakthrough pain of the end-of-dose type occurring three or more times per day. The tumor symptoms are severe. Currently, the patient is not using any analgesic medication. The pharmacist and doctor recommended immediate-release weak opioids, which partially relieved the pain after administration. One week later, the patient's NRS was 4 at its most severe, 2 at its least severe, with an average of 3, and currently 2. The pain has a slight impact on daily life and emotions, with no breakthrough pain. The patient has been using immediate-release weak opioids for 7 days, with a compliance score of 6.5. After medication, pain control lasts for 5 hours, with no adverse reactions observed. The analgesic effect is poor, possibly due to inappropriate medication selection. After discussion with the pharmacist, the doctor adjusted the medication to sustained-release strong opioids. The patient fully complied and followed the advice. One week later, during follow-up, the patient's pain was completely relieved after taking sustained-release strong opioids.

**Sample 4:**

As shown in Table 19, the patient in Sample 4 was diagnosed with a malignant neck tumor. The patient denies any history of smoking, allergies, or alcohol consumption. Upon evaluation, there were no cardiovascular or gastrointestinal risks identified. Results from the complete blood count, liver function, and kidney function tests were all within normal ranges. The patient's pain is characterized as somatic, with a Numerical Rating Scale (NRS) score of 10 at its most severe, 6 at its least severe, an average of 7, and currently 5. The pain significantly impacts daily life and emotional well-being and is persistent. The patient experiences breakthrough pain less than three times per day, primarily activity 

\begin{table}
\begin{tabular}{c c c c c} \hline
**J20** & **Complete** & **Product Back Information** & **Weight** \\ \hline
82-20017 & 1 & 59 & 110 & 275 \\
82-20011 & 1 & 59 & 110 & 275 \\
82-20011 & 1 & 59 & 110 & 275 \\
82-20011 & 1 & 59 & 110 & 275 \\ \hline
**B90** & **Body Surface Area (BRA)** & **Model Based Data** & Length-of-Handed Star & Number of Liquids Adduction \\ \hline
21,796 & 18411 & 2037017 & 10 & 2 \\
21,909 & 18441 & 2036279 & 10 & 2 \\
21,909 & 18441 & 2036278 & 17 & 4 \\ \hline
**Demograph** & **Stacking History** & **Dictionary History** & **Allow History** & **Traver Temporal Methods** \\ \hline
112 & 0 & 0 & 0 & 2 \\
112 & 0 & 0 & 0 & 2 \\
112 & 0 & 0 & 0 & 2 \\ \hline
**Cardiovascular Risk** & **G**unctional Risk & **PS** Count & **White Blood Cell Count** & **Real Based Cell Count** \\ \hline
0 & 0 & 2 & 7.5 & 3.3 \\
0 & 0 & 2 & 4.2 & 3.4 \\
0 & 0 & 2 & 4.7 & 3.17 \\ \hline
**Mong/slake** & **R**eight-Count & **B**ursection & **Non-Feed Count** & **T**otype-Count \\ \hline
140 & 114 & 42.1 & 2.5 & 1.5 \\
150 & 146 & 31.4 & 2.5 & 1 \\
150 & 171 & 48.8 & 2.2 & 1.9 \\ \hline
**E**ense/Central-Count & **B**earch-Count & **M**over-Promoter & **A**entral-Promoter & **L**emephone \\ \hline
0 & 0 & 120 & 59 & 24 \\
0 & 0 & 5.2 & 54.3 & 75.4 \\
0.08 & 0.02 & 17.8 & 66.4 & 97.7 \\ \hline
**E**ength Processing** & **E**ensurgical Processing & **M**an Copyright Culture & Mean Corresponding Hennigala & **M**an Copyright Recognition & **C**over-Promoter \\ \hline
0.7 & 1.8 & 91 & 50.3 & 323.5 \\
0.1 & 0.0 & 89.2 & 31.3 & 348.8 \\
0.4 & 1.7 & 88.6 & 29 & 25.8 \\ \hline
**End Cell Deforming With** & **P**urbulent & **M**an-Product & **T**orbata & **A**ubama \\ \hline
152 & 0.32 & 20.1 & 67.6 & 92.8 \\
153 & 0.35 & 6.35 & 61.5 & 40.5 \\
154 & 0.35 & 11.4 & 54.4 & 80.9 \\ \hline
**G** Optimality & **A**entral-Graph & **T**aint-Hash & **D**ence & **T**ark-Acids \\ \hline
21 & 1.8 & 7.3 & 3.3 & 3.4 \\
20 & 2.1 & 4.8 & 1.3 & 3.2 \\
17.5 & 2.1 & 17.7 & 6.3 & 8.1 \\ \hline
**A**tive Augmentation & **A**epative Augmentation & **U**obs & **C**ordinate & **U**obs Acid \\ \hline
274 & 175 & 5.88 & **88** & 421.5 \\
278 & 175 & 5.88 & 27.1 & 341.5 \\
12.8 & 11.4 & 7.5 & 88.4 & 341.4 \\ \hline
**C**omprehensive Path Assessment & **C**omprehensive Path Assessment & **C**umor & **P**urbulent \\ \hline
**P**ax Type & **W**ixed State & **M**ixed State & **M**ixed State & **C**umor \\ \hline
2 & 6 & 4 & 6 & 7 \\
2 & 4 & 2 & 2 & 0 \\ \hline
**J** & 1 & 0 & 2 & 0 \\ \hline
**J** & 1 & 0 & 2 & 0 \\ \hline

[MISSING_PAGE_FAIL:30]

[MISSING_PAGE_EMPTY:31]

[MISSING_PAGE_FAIL:32]

[MISSING_PAGE_FAIL:33]