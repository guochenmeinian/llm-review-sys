# Compositional Generative Inverse Design

 Tailin Wu 1

Westlake University

wutailin@westlake.edu.cn

&Takashi Maruyama 1

NEC Laboratories Europe

Takashi.Maruyama@neclab.eu

&Long Wei 1

Westlake University

weilong@westlake.edu.cn

&Tao Zhang 1

Westlake University

zhangtao@westlake.edu.cn

&Yilun Du 1

Massachusetts Institute of Technology

yilundu@mit.edu

&Gianluca Iaccarino

Stanford University

jops@stanford.edu

&Jure Leskovec

Stanford University

jure@cs.standford.edu

Footnote 1: These authors contributed equally to this work

###### Abstract

Inverse design, where we seek to design input variables in order to optimize an underlying objective function, is an important problem that arises across fields such as mechanical engineering to aerospace engineering. Inverse design is typically formulated as an optimization problem, with recent works leveraging optimization across learned dynamics models. However, as models are optimized they tend to fall into adversarial modes, preventing effective sampling. We illustrate that by instead optimizing over the learned energy function captured by the diffusion model, we can avoid such adversarial examples and significantly improve design performance. We further illustrate how such a design system is compositional, enabling us to combine multiple different diffusion models representing subcomponents of our desired system to design systems with every specified component. In an N-body interaction task and a challenging 2D multi-airfoil design task, we demonstrate that our method allows us to design initial states and boundary shapes that are more complex than those in the training data. Our method outperforms state-of-the-art neural inverse design method for the N-body dataset and discovers formation flying to minimize drag in the multi-airfoil design task.

## 1 Introduction

The problem of inverse design - finding a set of high-dimensional design parameters (e.g., boundary and initial conditions) for a system to optimize a set of specified objectives and constraints, occurs across many engineering domains such as mechanical, materials, and aerospace engineering, with important applications such as jet engine design (Athanasopoulos et al., 2009), nanophotonic design (Molesky et al., 2018), shape design for underwater robots (Saghaf & Lavimi, 2020), and battery design (Bhowmik et al., 2019). Such inverse design problems are extremely challenging since they typically involve simulating the full trajectory of complicated physical dynamics as an inner loop, have high-dimensional design space, (e.g. complex shape for airplane surface design) and require out-of-distribution test-time generalization (to design more complex parts and shapes than seen in training).

Recent deep learning has made promising progress for inverse design. A notable work is by Allen et al. (2022), which addresses inverse design by first learning a neural surrogate model to approximatethe forward physical dynamics, and then performing backpropagation through the full simulation trajectory to optimize the design parameters such as the boundary shape. Compared with standard sampling-based optimization methods with classical simulators, it shows comparable and sometimes better performance, establishing deep learning as a viable technique for inverse design.

However, an underlying issue with backpropagation with surrogate models is over-optimization - as learned models have adversarial minima, excessive optimization with respect to a learned forward model leads to adversarial design parameters which lead to poor performance (Zhao et al., 2022). A root cause of this is that the forward model does not have a measure of _data likelihood_ and does not know which design parameters are in or out of the training distribution it has seen, allowing optimization to easily fall out-of-distribution of the design parameters seen during training.

To address this issue, we view the inverse design problem from an energy optimization perspective, where constraints of the simulation model are implicitly captured through the generative energy function of a diffusion model trained with design parameters and simulator outputs. Designing parameters subject to constraints corresponds to optimizing for design parameters that minimize the energy of both the generative energy function and associated design objective functions. The generative energy function prevents design parameters from deviating and falling out of distribution.

An essential aspect of inverse design is the ability to further construct _new structures_ subjects to different constraints at test-time. By formulating inverse design as optimizing generative energy function trained on existing designs, a naive issue is that it constrains design parameters to be roughly those seen in the training data. We circumvent this issue by using a set of generative energy functions, where each generative model captures a subset of design parameters governing the system. Each individual generative energy function ensures that designs do not locally fall out of distribution, with their composition ensuring that inferred design parameters are roughly "locally" in distribution. Simultaneously, designs from this compositional set of generative energy functions may be significantly different from the training data, as designs are not constrained to globally follow the observed data (Liu et al., 2022; Du et al., 2023), achieving compositional generalization in design.

We illustrate the promise of using such compositional energy functions across a variety of different settings. We illustrate that temporally composing multiple compositional energy functions, we may design sequences of outputs that are significantly longer than the ones seen in training. Similarly, we can design systems with many more objects and more complex shapes than those seen in training.

Concretely, we contribute the following: **(1)** We propose a novel formulation for inverse design as an energy optimization problem. **(2)** We introduce Compositional Inverse Design with Diffusion Models (CinDM) method, which enables us to generalize to out-of-distribution and more complex design inputs than seen in training. **(3)** We present a set of benchmarks for inverse design in 1D and 2D. Our method outperforms prior state-of-the-art models by an average of 41.5% in prediction MAE and 14.3% in design objective for the N-body dataset and discovers formation flying to minimize drag in the multi-airfoil design task.

Figure 1: **CinDM schematic.** By composing generative models specified over subsets of inputs, we present an approach which design materials significantly more complex than those seen at training.

Related Work

**Inverse Design.** Inverse design plays a key role across science and engineering, including mechanical engineering (Coros et al., 2013), materials science (Dijkstra and Luijten, 2021), nanophotonics (Molesky et al., 2018), robotics (Saghafi and Lavimi, 2020), chemical engineering (Bhowmik et al., 2019), and aerospace engineering (Athanasopoulos et al., 2009; Anderson and Venkatakrishnan, 1999). Classical methods to address inverse design rely on slow classical solvers. They are accurate but are prohibitively inefficient (e.g., sampling-based methods like CEM (Rubinstein and Kroese, 2004)). Recently, deep learning-based inverse design has made promising progress. Allen et al. (2022) introduced backpropagation through the full trajectory with surrogate models. Wu et al. (2022) introduced backpropagation through latent dynamics to improve efficiency and accuracy. For Stokes systems, Du et al. (2020) introduced an inverse design method under different types of boundary conditions. While the above methods typically rely on learning a surrogate model for the dynamics and use it as an inner loop during inverse design, we introduce a novel generative perspective that brings the important benefit of out-of-distribution generalization and compositionality. Ren et al. (2020); Trabucco et al. (2021); Ansari et al. (2022); Chen et al. (2023) benchmarked varieties of deep learning-based methods in a wide range of inverse design tasks.

**Compositional Models.** A large body of recent work has explored how multiple different instances of generative models can be compositionally combined for applications such as 2D images synthesis (Du et al., 2020; Liu et al., 2021; Nie et al., 2021; Liu et al., 2022; Wu et al., 2022; Wu et al., 2022; Du et al., 2023; Wang et al., 2023), 3D synthesis (Po and Wetzstein, 2023), video synthesis (Yang et al., 2023), trajectory planning (Du et al., 2019; Urain et al., 2021; Gkanatsios et al., 2023; Yang et al., 2023b) and multimodal perception (Li et al., 2022) and hierarchical decision making (Ajay et al., 2023). To the best of our knowledge, we are the first to introduce a compositional generative perspective and method to inverse design, and show how compositional models can enable us to generalize to design spaces that are much more complex than seen at training time.

## 3 Method

In this section, we detail our method of Compositional INverse design with Diffusion Models (CinDM). We first introduce the problem setup in Section 3.1. In Section 3.2, we introduce generative inverse design, a novel generative paradigm for solving the inverse design problem. In Section 3.3, we detail how our method allows for test-time composition of the design variables.

### Problem setup

We formalize the inverse design problem using a similar setup as in Zhang et al. (2023). Concretely, let \(u(x,t;\gamma)\) be the state of a dynamical system at time \(t\) and location \(x\) where the dynamics are described by a partial differential equation (PDE) or an ordinary differential equation (ODE). Here \(\gamma=(u_{0},\mathcal{B})\in\Gamma\) consists of the initial state \(u_{0}\) and boundary condition \(\mathcal{B}\), \(\Gamma\) is the design space, and we will call \(\gamma\) "boundary" for simplicity. Given a PDE or ODE, a specific \(\gamma\) can uniquely determine a specific trajectory \(u_{[0,T]}(\gamma):=\{u(x,t;\gamma)|t\in[0,T]\}\), where we have written the dependence of \(u_{[0,T]}\) on \(\gamma\) explicitely. Let \(\mathcal{J}\) be the design objective which evaluates the quality of the design. Typically \(\mathcal{J}\) is a function of a subset of the trajectory \(u_{[0,T]}\) and \(\gamma\) (esp. the boundary shape). The inverse design problem is to find an optimized design \(\hat{\gamma}\) which minimizes the design objective \(\mathcal{J}\):

\[\hat{\gamma}=\operatorname*{arg\,min}_{\gamma}\mathcal{J}(u_{[0,T]}(\gamma),\gamma)\] (1)

We see that \(\mathcal{J}\) depends on \(\gamma\) through two routes. On the one hand, \(\gamma\) influences the future trajectory of the dynamical system, which \(\mathcal{J}\) evaluates on. On the other hand, \(\gamma\) can directly influence \(\mathcal{J}\) at future times, since the design objective may be directly dependent on the boundary shape.

Typically, we don't have access to the ground-truth model for the dynamical system, but instead only observe the trajectories \(u_{[0,T]}(\gamma)\) at discrete time steps and locations and a limited diversity of boundaries \(\gamma\in\Gamma\). We denote the above discrete version of the trajectory as \(U_{[0,T]}(\gamma)=(U_{0},U_{1},...,U_{T})\) across time steps \(t=0,1,...T\). Given the observed trajectories \(U_{[0,T]}(\gamma),\gamma\in\Gamma\), a straightforward method for inverse design is to use such observed trajectories to train a neural surrogate model \(f_{\theta}\) for forward modeling, so the trajectory can be autoregressively simulated by \(f_{\theta}\):

\[\hat{U}_{t}(\gamma)=f_{\theta}(\hat{U}_{t-1}(\gamma),\gamma),\quad\hat{U}_{0}: =U_{0},\;\gamma=(U_{0},\mathcal{B}),\] (2)```
1:Require Compositional set of diffusion models \(\epsilon_{\theta}^{i}(z_{s},s),i=1,2,...N\), design objective \(\mathcal{J}(\cdot)\), covariance matrix \(\sigma_{t}^{2}I\), hyperparameters \(\lambda,S,K\)
2:Initialize optimization variables \(z_{S}\sim\mathcal{N}(\mathbf{0},\boldsymbol{I})\)
3:for\(s=S,\ldots,1\)do
4:for\(k=1,\ldots,K\)do
5:\(\xi\sim\mathcal{N}\big{(}0,\sigma_{s}^{2}I\big{)}\)
6:\(z_{s}\gets z_{s}-\eta\frac{1}{N}\sum_{i=1}^{N}\big{(}\epsilon_{\theta}^{i} (z_{s}^{i},s)+\lambda\nabla_{z}\mathcal{J}(z_{s})\big{)}+\xi\)
7:endfor
8:\(\xi\sim\mathcal{N}\big{(}0,\sigma_{s}^{2}I\big{)}\)
9:\(z_{s-1}\gets z_{s}-\eta\frac{1}{N}\sum_{i=1}^{N}\big{(}\epsilon_{\theta}^{ i}(z_{s}^{i},s)+\lambda\nabla_{z}\mathcal{J}(z_{s})\big{)}+\xi\)
10:endfor
11:\(\gamma,U_{[0,T]}=z_{0}\)
12:return\(\gamma\) ```

**Algorithm 1** Algorithm for Compositional Inverse Design with Diffusion Models (CinDM)

Here we use \(\hat{U}_{t}\) to represent the prediction by \(f_{\theta}\), to differentiate from the actual observed state \(U_{t}\). In the test time, the goal is to optimize \(\mathcal{J}(\hat{U}_{[0,T]}(\gamma),\gamma)\) w.r.t. \(\gamma\), which includes the autoregressive rollout with \(f_{\theta}\) as an inner loop, as introduced in Allen et al. (2022). In general inverse design, the trajectory length \(T\), state dimension \(\text{dim}(U_{[0,T]}(\gamma))\), and complexity of \(\gamma\) may be much larger than in training, requiring significant out-of-distribution generalization.

### Generative Inverse Design

Directly optimizing equation 1 with respect to \(\gamma\) using a learned surrogate model \(f_{\theta}\) is often problematic as the optimization procedure on \(\gamma\) often leads a set of \(U_{[0,T]}\) that is out-of-distribution or adversarial to the surrogate model \(f_{\theta}\), leading to poor performance, as observed in Zhao et al. (2022). A major cause of this is that \(f_{\theta}\) does not have an inherent measure of uncertainty, and cannot prevent optimization from entering design spaces \(\gamma\) that the model cannot guarantee its performance in.

To circumvent this issue, we propose a generative perspective to inverse design: during the inverse design process, we jointly optimize for both the design objective \(\mathcal{J}\) and a generative objective \(E_{\theta}\),

\[\hat{\gamma}=\operatorname*{arg\,min}_{\gamma,U_{[0,T]}}\big{[}E_{\theta}(U_{[ 0,T]},\gamma)+\lambda\cdot\mathcal{J}(U_{[0,T]},\gamma)\big{]}\,,\] (3)

where \(E_{\theta}\) is an energy-based model (EBM) \(p(U_{[0,T]},\gamma)\propto e^{-E_{\theta}(U_{[0,T]},\gamma)}\)(LeCun et al., 2006; Du and Mordatch, 2019) trained over the joint distribution of trajectories \(U_{[0,T]}\) and boundaries \(\gamma\), and \(\lambda\) is a hyperparameter. Both \(U_{[0,T]}\) and \(\gamma\) are _jointly optimized_ and the energy function \(E_{\theta}\) is minimized when both \(U_{[0,T]}\) and \(\gamma\) are _consistent_ with each other and serves the purpose of a surrogate model \(f_{\theta}\) in approximating simulator dynamics. The joint optimization optimizes all the steps of the trajectory \(U_{[0,T]}\) and the boundary \(\gamma\) simultaneously.

To train \(E_{\theta}\), we use a diffusion objective, where we learn a denoising network \(\epsilon_{\theta}\) that learns to denoise all variables in design optimization \(z=U_{[0,T]}\bigoplus\gamma\) supervised with the training loss

\[\mathcal{L}_{\text{MSE}}=\|\epsilon-\epsilon_{\theta}(\sqrt{1-\beta_{s}}z+ \sqrt{\beta_{s}}\epsilon,s)\|_{2}^{2},\;\;\;\epsilon\sim\mathcal{N}(0,I).\] (4)

As discussed in Liu et al. (2022), the denoising network \(\epsilon_{\theta}\) corresponds to the gradient of an EBM \(\nabla_{z}E_{\theta}(z)\). To optimize equation 3 using a Langevin sampling procedure, we can initialize an optimization variable \(z_{S}\) from Gaussian noise \(\mathcal{N}(0,I)\), and iteratively run

\[z_{s-1}=z_{s}-\eta\left(\nabla_{z}(E_{\theta}(z_{s})+\lambda\,\mathcal{J}(z_{s }))\right)+\xi,\quad\xi\sim\mathcal{N}\big{(}0,\sigma_{s}^{2}I\big{)},\] (5)

for \(s=S,S-1,...,1\). This sampling procedure is implemented with diffusion models by optimizing

\[z_{s-1}=z_{s}-\eta\left(\epsilon_{\theta}(z_{s},s)+\lambda\nabla_{z}\mathcal{J }(z_{s})\right)+\xi,\quad\xi\sim\mathcal{N}\big{(}0,\sigma_{s}^{2}I\big{)},\] (6)

where \(\sigma_{s}^{2}\) and \(\eta\) correspond to a set of different noise schedules and scaling factors used in the diffusion process. To further improve the performance, we run additional steps of Langevin dynamics optimization at a given noise level following Du et al. (2023).

### Compositional Generative Inverse Design

A key challenge in inverse design is that the boundary \(\gamma\) or the trajectory \(U_{[0,T]}\) can be substantially different than seen during training. To enable generalization across such design variables, we propose to compositionally represent the design variable \(z=U_{[0,T]}\bigoplus\gamma\), using a composition of different energy functions \(E_{\theta}\) (Du et al., 2020b) on subsets of the design variable \(z_{i}\subset z\). Each of the above \(E_{\theta}\) on the subset of design variable \(z_{i}\) provides a physical consistency constraint on \(z_{i}\), encouraging each \(z_{i}\) to be physically consistent _internally_. Also, we make sure that different \(z_{i},i=1,2,...N\) overlap with each other, and overall cover \(z\) (See Fig. 1), so that the full \(z\) is physically consistent. Thus, test-time compositions of energy functions defined over subsets of the design variable \(z_{i}\subset z\) can then be composed together to generalize to new design variable \(z\) values that are substantially different than those seen during training, but exploiting shared local structure in \(z\).

Below, we illustrate three different ways compositional inverse design can enable to generalize to design variables \(z\) that are much more complex than the ones seen during training.

**I. Generalization to more time steps.** In the test time, the trajectory length \(T\) may be much longer than the trajectory length \(T^{\text{tr}}\) seen in training. In this case, the energy function can be written in terms of a composition of \(N\) energy functions over subsets of trajectories with overlapping states:

\[E_{\theta}(U_{[0,T]},\gamma)=\sum_{i=1}^{N}E_{\theta}(U_{[(i-1)\cdot t_{q},i \cdot t_{q}+T^{\text{tr}}]},\gamma).\] (7)

Here \(z_{i}:=U_{[(i-1)\cdot t_{q},i\cdot t_{q}+T^{\text{tr}}]}\bigoplus\gamma\) is a subset of the design variable \(z:=U_{[0,T]}\bigoplus\gamma\). \(t_{q}\in\{1,2,...T-1\}\) is the stride for consecutive time intervals, and we let \(T=N\cdot t_{q}+T^{\text{tr}}\).

**II. Generalization to more interacting bodies.** Our method allows generalizing the trained model to more interacting bodies for a dynamical system. Now we illustrate it with a 2-body to N-body generalization. Suppose that only the trajectory of a 2-body interaction is given, where we have the trajectory of \(U_{[0,T]}^{(i)}=(U_{0}^{(i)},U_{1}^{(i)},...,U_{T}^{(i)})\) for body \(i\in\{1,2\}\) at time steps \(t=0,1,...T\). We can learn an energy function \(E_{\theta}((U_{[0,T]}^{(1)},U_{[0,T]}^{(2)}),\gamma)\) from this trajectory. In the test time, suppose that we have \(N>2\) interacting bodies subjecting to the same pairwise interactions. The energy function for the combined trajectory \(U_{[0,T]}=(U_{[0,T]}^{(1)},...,U_{[0,T]}^{(N)})\) for the \(N\) bodies is then be given by:

\[E_{\theta}(U_{[0,T]},\gamma)=\sum_{i<j}E_{\theta}\left((U_{[0,T]}^{(i)},U_{[0,T]}^{(j)}),\gamma\right)\] (8)

**III. Generalization from part to whole for boundaries.** Real-life inverse design typically involves designing shapes consisting of multiple _parts_ that constitute an integral _whole_. In this case, we can again compose the energy function over subsets of the design variable \(z\). Concretely, suppose that we have trajectories \(U_{[0,T]}^{(i)}\) corresponding to the part \(\gamma^{i}\), \(i=1,2,...N\), we can learn energy functions corresponding to the dynamics of each part \(E_{\theta_{i}}(U_{[0,T]}^{(i)},\gamma^{i})\). In the test time, when requiring to generalize over a whole boundary \(\gamma\) that consisting of these \(N\) parts \(\gamma^{i},i=1,2...N\), we have

\[E_{\theta}(U_{[0,T]},\gamma)=\sum_{i=1}^{N}E_{\theta_{i}}(U_{[0,T]},\gamma^{i})\] (9)

Note that here in the composition, all the parts \(\gamma^{i}\) share the same trajectory \(U_{[0,T]}\), which can be intuitively understood in the example of the plane where all the parts of the plane influence the same full state of fluid around the plane. The composition of energy functions in equation 9 means that the full energy \(E_{\theta}(U_{[0,T]},\gamma)\) will be low if the trajectory \(U_{[0,T]}\) is consistent with all the parts \(\gamma^{i}\).

**Compositional Generative Inverse Design.** Given the above composition of energy functions, we can correspondingly learn each energy function over the design variable \(z=U_{[0,T]}\bigoplus\gamma\) by training a corresponding diffusion model over the subset of design variables \(z^{i}\subset z\). Our overall sampling objective given the set of energy functions \(\{E_{i}(z^{i})\}_{i=1:N}\) is then given by

\[z_{s-1}=z_{s}-\eta\frac{1}{N}\sum_{i=1}^{N}\big{(}\dot{\epsilon}_{\theta}^{i}(z _{s}^{i},s)+\lambda\nabla_{z}\mathcal{J}(z_{s})\big{)}+\xi,\quad\xi\sim \mathcal{N}\big{(}0,\sigma_{s}^{2}I\big{)},\] (10)for \(s=S,S-1,...1\). Similarly to before, we can further run multiple steps of Langevin dynamics optimization at a given noise level following Du et al. (2023) to further improve performance. We provide the overall pseudo-code of our method in the compositional setting in Algorithm 1.

## 4 Experiments

In the experiments, we aim to answer the following questions: (1) Can CinDM generalize to more complex designs in the test time using its composition capability? (2) Comparing backpropagation with surrogate models and other strong baselines, can CinDM improve on the design objective? (3) Can CinDM address high-dimensional design space? To answer these questions, we perform our experiments in three different scenarios: compositional inverse design in time dimension (Sec. 4.1), compositional inverse design generalizing to more objects (Sec. 4.2), and 2D compositional design for multiple airfoils with Navier-Stokes flow (Sec. 4.3). Each of the above experiments represents an important scenario in inverse design and has important implications in science and engineering. In each experiment, we compare CinDM with the state-of-the-art deep learning-based inverse design method proposed by Allen et al. (2022), which we term Backprop, and cross-entropy method (CEM) (Rubinstein and Kroese, 2004) which is a standard sampling-based optimization method typically used in classical inverse design. To evaluate the performance of each inverse design method fairly, all the baselines and our model contain similar numbers of parameters in each comparison. We feed the output of the inverse design method to the ground-truth solver, perform rollout by the solver and feed the rollout trajectory to the design objective in evaluation.

### Compositional inverse design in time

In this experiment, we aim to test each method's ability to generalize to _more_ forward time steps than during training. This is important since in test time, the inverse design methods are typically used over longer prediction horizons than in training. We use an N-body interaction environment where each ball with a radius of 0.1 is bouncing in a \(1\times 1\) box. The balls will exchange momentum (resulting in a velocity change) when elastically colliding with each other or with the wall. The design task is to identify the initial state (position and velocity of the balls) of the system such that the _end_ state optimizes a certain objective (e.g., as close to a certain target as possible). This setting represents a simplified version of many real-life scenarios such as billiard, bowling, and ice hockey. Details for this experiment are provided in Appendix A.

From Table 1, we see that our method generally outperforms the baselines by a wide margin. In the "2-body 24 steps" scenario which is the same setting as in training and without composition, our model performs similarly to "Backprop with U-Net" that shares the same backbone architecture. However, with more prediction steps, the design objective and MAE for all the baseline methods worsen quickly. In contrast, our method's metrics remain much lower than the baselines, with wider gaps for longer prediction steps. This shows the two-fold advantage of our method. Firstly, even with the same backbone architecture, our diffusion method can roll out stably and accurately for much longer than the baseline, since the forward surrogate models in the baselines during design may encounter out-of-distribution and adversarial inputs which it does not know how to evolve properly. On the other hand, our diffusion-based method is trained to denoise and has a sense of how likely

\begin{table}
\begin{tabular}{l c c c c c c c c} \hline \hline \multirow{2}{*}{Method} & \multicolumn{2}{c}{**2-body 24 steps**} & \multicolumn{2}{c}{**2-body 34 steps**} & \multicolumn{2}{c}{**2-body 44 steps**} & \multicolumn{2}{c}{**2-body 54 steps**} \\  & design obj & MAE & design obj & MAE & design obj & MAE & design obj & MAE \\ \hline CEM, GNS (1-step) & 0.3021 & 0.14941 & 0.2531 & 0.13296 & 0.2781 & 0.20109 & 0.2845 & 0.19811 \\ CEM, GNS & 0.3144 & 0.12741 & 0.3178 & 0.16538 & 0.3102 & 0.24884 & 0.3059 & 0.24863 \\ CEM, U-Net (1-step) & 0.2733 & 0.08013 & 0.2680 & 0.13183 & 0.2910 & 0.14783 & 0.2919 & 0.13348 \\ CEM, U-Net & 0.2731 & 0.02995 & 0.2424 & 0.02937 & 0.2616 & 0.04460 & 0.2804 & 0.06520 \\ \hline Backprop, GNS (1-step) & 0.1216 & 0.03678 & 0.1643 & 0.02976 & 0.1966 & 0.03645 & 0.2657 & 0.10331 \\ Backprop, GNS & 0.2453 & 0.13024 & 0.2822 & 0.11200 & 0.2959 & 0.12867 & 0.2877 & 0.14241 \\ Backprop, U-Net (1-step) & 0.2020 & 0.06338 & 0.2193 & 0.07705 & 0.2187 & 0.05668 & 0.2851 & 0.07716 \\ Backprop, U-Net & 0.1168 & **0.01137** & 0.1294 & 0.01303 & 0.1481 & 0.00804 & 0.3140 & 0.01675 \\ \hline
**CinDM (ours)** & **0.1143** & 0.01202 & **0.1251** & **0.00763** & **0.1326** & **0.00695** & **0.1533** & **0.00870** \\ \hline \hline \end{tabular}
\end{table}
Table 1: **Compositional Generalization Across Time. Experiment on compositional inverse design in time. The confidence interval information is deligated to Table 6 in Appendix B for page constraints. Bold font denotes the best model.**an input is consistent with the underlying physics. Secondly, our compositional method allows our model to generalize to longer time steps and allows for stable rollout. An example trajectory designed by our CinDM is shown in Fig. 2 (a). We see that it matches with the ground-truth simulation nicely, captures the bouncing with walls and with other balls, and the end position of the bodies tends towards the center, showing the effectiveness of our method. We also see that Backprop's performance is superior to the sampling-based CEM, consistent with Allen et al. (2022).

### Compositional inverse design generalizing to more objects

In this experiment, we test each method's capability to perform inverse design on larger state dimensions than in training. We utilize the N-body simulation environment as in Sec. 4.1, but instead of considering longer trajectories, we test on more bodies than in training, resulting in larger state dimensions. This setting is also inspired by real-life scenarios where the dynamics in test time have more interacting objects than in training (e.g., in astronomical simulation and biophysics). Specifically, all methods are trained with only 2-body interactions with 24 time steps, and in test time, we directly test them with 4-body and 8-body interactions for 24 and 44 time steps using Eq. 8. For the base network architecture, the U-Net in Backprop cannot generalize to more bodies due to U- Net's fixed feature dimension. Thus we only use GNS as the backbone architecture in the baselines. The results are reported in Table 2.

From Table 2, we see that our CinDM method outperforms all baselines by a wide margin in both the design objective and MAE. On average, our method achieves an improvement of 14.1% in design objective, and an improvement of 58.8% in MAE than the best baseline. In Fig. 2 (b), we see that our method captures the interaction of the 4 bodies with the wall and each other nicely and all bodies tend towards the center at the end. The above results again demonstrate the strong compositional capability of our method: it can generalize to much larger state space than seen in training.

### 2D compositional design for multiple airfoils

In this experiment, we test the methods' ability to perform inverse design in high-dimensional space, for multiple 2D airfoils. We train the methods using flow around a single randomly-sampled shape, and in the test time, ask it to perform inverse design for one or more airfoils. The standard goal for airfoil design is to maximize the ratio between the total lift force and total drag force, thus improving aerodynamic performance (range) and reducing cost (fuel consumption). The multi-airfoil case represents an important scenario in real-life engineering where the boundary shape

\begin{table}
\begin{tabular}{l c c c c c c c c} \hline \hline  & **4-body 24 steps** & \multicolumn{2}{c}{**4-body 44 steps**} & \multicolumn{2}{c}{**8-body 24 steps**} & \multicolumn{2}{c}{**8-body 44 steps**} \\ Method & design obj & MAE & design obj & MAE & design obj & MAE & design obj & MAE \\ \hline CEM, GNS (1-step) & 0.3029 & 0.20027 & 0.3215 & 0.26518 & 0.3312 & 0.36865 & 0.3292 & 0.37430 \\ CEM, GNS & 0.3139 & 0.21253 & 0.3110 & 0.26924 & 0.3221 & 0.26708 & 0.3319 & 0.32678 \\ \hline Backprop, GNS (1-step) & 0.2872 & 0.08023 & 0.2900 & 0.11331 & 0.3312 & 0.27988 & 0.3227 & 0.74314 \\ Backprop, GNS & 0.3118 & 0.10249 & 0.3423 & 0.15277 & 0.3302 & 0.19039 & 0.3233 & 0.24718 \\ \hline
**CinDM (ours)** & **0.2066** & **0.04152** & **0.2281** & **0.03195** & **0.3056** & **0.08821** & **0.3169** & **0.09566** \\ \hline \hline \end{tabular}
\end{table}
Table 2: **Compositional Generalization Across Objects. Experiment on compositional inverse design generalizing to more objects. The confidence interval information is deligated to Table 7 in Appendix B for page constraints.**

Figure 2: **Example trajectories for N-body dataset with compositional inverse design in time (a) and bodies (b). The circles indicate CinDM-designed trajectory for the balls, drawn every 2 steps, and darker color indicating later states. The central star indicates the design target that the end state should be as close to as possible. “+” indicates ground-truth trajectory simulated by the solver.**

that needs to be designed is more complicated and out-of-distribution than in training but can be constructed by composing multiple parts. Moreover, when there are multiple flying agents, they may use formation flying to minimize drag, as has been observed in nature for migrating birds (Lissaman and Shollenberger, 1970; Hummel, 1995) and adopted by humans in aerodynamics (Venkataraman et al., 2003). For the ground-truth solver that generates a training set and performs evaluation, we use Lily-Pad (Weymouth, 2015) which is adept at modeling fluid-boundary interactions. Detailed simulation and evaluation settings are given in Appendix D.

For our CinDM method, we use U-Net as the backbone architecture and train it to denoise the joint variable of the trajectory and the boundary. In the test time, we utilize Eq. 9 to compose multiple airfidis into a formation. For both CEM and Backprob, we use the state-of-the-art architecture of FNO (Li et al., 2021) and LE-PDE (Wu et al., 2022). For all methods, to improve design stability, we use the design objective of \(\mathcal{J}=-\text{lift}+\text{drag}\) and evaluate both this design objective and the lift-to-drag ratio. The results are in Table 3. Details for the experiment are provided in Appendix D.

From the table, we see that although CinDM has a similar design objective as baseline methods, it achieves a much higher lift-to-drag ratio than the baselines, especially in the compositional case of 2 airfolis. Fig. 9 and Fig. 10 show examples of the designed initial state and boundary for the 2-airfoil scenario, for our model and "CEM, FNO" baseline respectively. We see that while our CinDM can design a smooth initial state and reasonable boundaries, the baseline falls into adversarial modes. A surprising finding is that our model discovers formation flying (Fig. 3) that reduces the drag by 53.6% and increases the lift-to-drag ratio by 66.1% compared to each airfoil flying separately. The above demonstrates the capability of CinDM to effectively design boundaries that are more complex than in training, avoiding the adversarial mode issue through its generative modeling, and achieving much better design performance.

## 5 Conclusion

In this work, we have introduced Compositional Inverse Design with Diffusion Models (CinDM), a novel paradigm and method to perform compositional generative inverse design. By composing the trained diffusion models on subsets of the design variables and jointly optimizing the trajectory and the boundary, CinDM can generalize to design systems much more complex than the ones seen in training. We've demonstrated our model's compositional inverse design capability in N-body and 2D multi-airfoil tasks, and believe that the techniques presented in this paper are general (Appendix J), and may further be applied across other settings such as material, drug, and molecule design.

\begin{table}
\begin{tabular}{l c c c c} \hline \hline  & \multicolumn{2}{c}{**1 airfoil**} & \multicolumn{2}{c}{**2 airfolis**} \\ Method & design obj \(\downarrow\) & lift-to-drag ratio \(\uparrow\) & design obj \(\downarrow\) & lift-to-drag ratio \(\uparrow\) \\ \hline CEM, FNO & 0.0932 & 1.4005 & 0.3890 & 1.0914 \\ CEM, LE-PDE & 0.0794 & 1.4340 & 0.1691 & 1.0568 \\ \hline Backprop, FNO & **0.0281** & 1.3300 & 0.1837 & 0.9722 \\ Backprop, LE-PDE & 0.1072 & 1.3203 & **0.0891** & 0.9866 \\ \hline
**CinDM (ours)** & 0.0797 & **2.177** & 0.1986 & **1.4216** \\ \hline \hline \end{tabular}
\end{table}
Table 3: **Generalization Across Airfolis. Experiment results for multi-airfoil compositional design.**

Figure 3: **Discovered formation flying. In the 2-airfoil case, our model’s designed boundary forms a “leader” and “follower” formation (a), reducing the drag by 53.6% and increasing the lift-to-drag ratio by 66.1% compared to each airfoil flying separately (b)(c). Colors represent fluid vorticity.**

## References

* Ajay et al. (2023) Anurag Ajay, Seungwook Han, Yilun Du, Shaung Li, Abhi Gupta, Tommi Jaakkola, Josh Tenenbaum, Leslie Kaelbling, Akash Srivastava, and Pulkit Agrawal. Compositional foundation models for hierarchical planning. _arXiv preprint arXiv:2309.08587_, 2023.
* Allen et al. (2022) Kelsey Allen, Tatiana Lopez-Guevara, Kimberly L Stachenfeld, Alvaro Sanchez Gonzalez, Peter Battaglia, Jessica B Hamrick, and Tobias Pfaff. Inverse design for fluid-structure interactions using graph network simulators. In _Advances in Neural Information Processing Systems_, volume 35, pp. 13759-13774. Curran Associates, Inc., 2022.
* Anderson and Venkatakrishnan (1999) W Kyle Anderson and V Venkatakrishnan. Aerodynamic design optimization on unstructured grids with a continuous adjoint formulation. _Computers & Fluids_, 28(4-5):443-480, 1999.
* Ansari et al. (2022) Navid Ansari, Hans peter Seidel, Nima Vahidi Ferdowsi, and Vahid Babaei. Autoinverse: Uncertainty aware inversion of neural networks. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), _Advances in Neural Information Processing Systems_, 2022. URL https://openreview.net/forum?id=dNyCj1Ab0b.
* Athanasopoulos et al. (2009) Michael Athanasopoulos, Hassan Ugail, and Gabriela Gonzalez Castro. Parametric design of aircraft geometry using partial differential equations. _Advances in Engineering Software_, 40(7):479-486, 2009.
* Bhowmik et al. (2019) Arghya Bhowmik, Ivano E Castelli, Juan Maria Garcia-Lastra, Peter Bjorn Jorgensen, Ole Winther, and Tejs Vegge. A perspective on inverse design of battery interphases using multi-scale modelling, experiments and generative deep learning. _Energy Storage Materials_, 21:446-456, 2019.
* Blamqvist (2007) Victor Blamqvist. _Pymunk tutorials_, 2007. URL http://www.pymunk.org/en/latest/tutorials.html.
* Chen et al. (2023) Can Chen, Yingxue Zhang, Xue Liu, and Mark Coates. Bidirectional learning for offline model-based biological sequence design, 2023. URL https://openreview.net/forum?id=luEG3j9LW5-.
* Coros et al. (2013) Stelian Coros, Bernhard Thomaszewski, Gioacchino Noris, Shinjirio Sueda, Moira Forberg, Robert W Sumner, Wojciech Matusik, and Bernd Bickel. Computational design of mechanical characters. _ACM Transactions on Graphics (TOG)_, 32(4):1-12, 2013.
* Dijkstra and Luijten (2021) Marjolein Dijkstra and Erik Luijten. From predictive modelling to machine learning and reverse engineering of colloidal self-assembly. _Nature materials_, 20(6):762-773, 2021.
* Du et al. (2020a) Tao Du, Kui Wu, Andrew Spielberg, Wojciech Matusik, Bo Zhu, and Eftychios Sifakis. Functional optimization of fluidic devices with differentiable stokes flow. _ACM Transactions on Graphics (TOG)_, 39(6):1-15, 2020a.
* Du and Mordatch (2019) Yilun Du and Igor Mordatch. Implicit generation and generalization in energy-based models. _arXiv preprint arXiv:1903.08689_, 2019.
* Du et al. (2019) Yilun Du, Toru Lin, and Igor Mordatch. Model based planning with energy based models. _CORL_, 2019.
* Du et al. (2020b) Yilun Du, Shuang Li, and Igor Mordatch. Compositional visual generation with energy based models. In _Advances in Neural Information Processing Systems_, 2020b.
* Du et al. (2023) Yilun Du, Conor Durkan, Robin Strudel, Joshua B Tenenbaum, Sander Dieleman, Rob Fergus, Jascha Sohl-Dickstein, Arnaud Doucet, and Will Grathwohl. Reduce, reuse, recycle: Compositional generation with energy-based diffusion models and mcmc. _arXiv preprint arXiv:2302.11552_, 2023.
* Gkanatsios et al. (2023) Nikolaos Gkanatsios, Ayush Jain, Zhou Xian, Yunchu Zhang, Christopher Atkeson, and Katerina Fragkiadaki. Energy-based models as zero-shot planners for compositional scene rearrangement. _arXiv preprint arXiv:2304.14391_, 2023.
* Hummel (1995) Dietrich Hummel. Formation flight as an energy-saving mechanism. _Israel Journal of Ecology and Evolution_, 41(3):261-278, 1995.
* Hummel (1996)Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_, 2014.
* LeCun et al. (2006) Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, and F Huang. A tutorial on energy-based learning. _Predicting structured data_, 1(0), 2006.
* Li et al. (2022) Shuang Li, Xavier Puig, Chris Paxton, Yilun Du, Clinton Wang, Linxi Fan, Tao Chen, De-An Huang, Ekin Akyurek, Anima Anandkumar, et al. Pre-trained language models for interactive decision-making. _Advances in Neural Information Processing Systems_, 35:31199-31212, 2022.
* Li et al. (2021) Zongyi Li, Nikola Borislavov Kovachki, Kamyar Azizzadenesheli, Burigede liu, Kaushik Bhattacharya, Andrew Stuart, and Anima Anandkumar. Fourier neural operator for parametric partial differential equations. In _International Conference on Learning Representations_, 2021. URL https://openreview.net/forum?id=c8P9NQVtmn0.
* Lissaman and Shollenberger (1970) Peter BS Lissaman and Carl A Shollenberger. Formation flight of birds. _Science_, 168(3934):1003-1005, 1970.
* Liu et al. (2021) Nan Liu, Shuang Li, Yilun Du, Josh Tenenbaum, and Antonio Torralba. Learning to compose visual relations. _Advances in Neural Information Processing Systems_, 34:23166-23178, 2021.
* Liu et al. (2022) Nan Liu, Shuang Li, Yilun Du, Antonio Torralba, and Joshua B Tenenbaum. Compositional visual generation with composable diffusion models. _arXiv preprint arXiv:2206.01714_, 2022.
* Molesky et al. (2018) Sean Molesky, Zin Lin, Alexander Y Piggott, Weiliang Jin, Jelena Vuckovic, and Alejandro W Rodriguez. Inverse design in nanophotonics. _Nature Photonics_, 12(11):659-670, 2018.
* Nie et al. (2021) Weili Nie, Arash Vahdat, and Anima Anandkumar. Controllable and compositional generation with latent-space energy-based models. _Advances in Neural Information Processing Systems_, 34, 2021.
* Po and Wetzstein (2023) Ryan Po and Gordon Wetzstein. Compositional 3d scene generation using locally conditioned diffusion. _arXiv preprint arXiv:2303.12218_, 2023.
* Ren et al. (2020) Simiao Ren, Willie Padilla, and Jordan Malof. Benchmarking deep inverse models over time, and the neural-adjoint method. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), _Advances in Neural Information Processing Systems_, volume 33, pp. 38-48. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper_files/paper/2020/file/007ff380ee5ac49ffc3442f5c2a2b86-Paper.pdf.
* Ronneberger et al. (2015) Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In _Medical Image Computing and Computer-Assisted Intervention-MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18_, pp. 234-241. Springer, 2015.
* Rubinstein and Kroese (2004) Reuven Y Rubinstein and Dirk P Kroese. _The cross-entropy method: a unified approach to combinatorial optimization, Monte-Carlo simulation, and machine learning_, volume 133. Springer, 2004.
* Saghafi and Lavimi (2020) Mohammad Saghafi and Roham Lavimi. Optimal design of nose and tail of an autonomous underwater vehicle hull to reduce drag force using numerical simulation. _Proceedings of the Institution of Mechanical Engineers, Part M: Journal of Engineering for the Maritime Environment_, 234(1):76-88, 2020.
* Sanchez-Gonzalez et al. (2020) Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, and Peter Battaglia. Learning to simulate complex physics with graph networks. In _International Conference on Machine Learning_, pp. 8459-8468. PMLR, 2020.
* Shinners (2000) Pete Shinners. _Pygame: A set of Python modules designed for writing video games_, 2000. URL https://www.pygame.org/.
* Trabucco et al. (2021) Brandon Trabucco, Aviral Kumar, Xinyang Geng, and Sergey Levine. Design-bench: Benchmarks for data-driven offline model-based optimization, 2021. URL https://openreview.net/forum?id=cQzf26aA3vM.

Julen Urain, Anqi Li, Puze Liu, Carlo D'Eramo, and Jan Peters. Composable energy policies for reactive motion generation and reinforcement learning. _arXiv preprint arXiv:2105.04962_, 2021.
* Venkataraman et al. (2003) Sriram Venkataraman, Atilla Dogan, and William Blake. Vortex effect modelling in aircraft formation flight. In _AIAA atmospheric flight mechanics conference and exhibit_, pp. 5385, 2003.
* Wang et al. (2023) Zihao Wang, Lin Gui, Jeffrey Negrea, and Victor Veitch. Concept algebra for text-controlled vision models. _arXiv preprint arXiv:2302.03693_, 2023.
* Weymouth (2015) Gabriel D Weymouth. Lily pad: Towards real-time interactive computational fluid dynamics. _arXiv preprint arXiv:1510.06886_, 2015.
* Wu et al. (2022a) Tailin Wu, Takashi Maruyama, and Jure Leskovec. Learning to accelerate partial differential equations via latent global evolution. _Advances in Neural Information Processing Systems_, 35:2240-2253, 2022a.
* Wu et al. (2022b) Tailin Wu, Megan Tjandrasuwita, Zhengxuan Wu, Xuelin Yang, Kevin Liu, Rok Sosic, and Jure Leskovec. Zeroc: A neuro-symbolic model for zero-shot concept recognition and acquisition at inference time. _Advances in Neural Information Processing Systems_, 35:9828-9840, 2022b.
* Yang et al. (2023a) Mengjiao Yang, Yilun Du, Bo Dai, Dale Schuurmans, Joshua B Tenenbaum, and Pieter Abbeel. Probabilistic adaptation of text-to-video models. _arXiv preprint arXiv:2306.01872_, 2023a.
* Yang et al. (2023b) Zhutian Yang, Jiayuan Mao, Yilun Du, Jiajun Wu, Joshua B Tenenbaum, Tomas Lozano-Perez, and Leslie Pack Kaelbling. Compositional diffusion-based continuous constraint solvers. _arXiv preprint arXiv:2309.00966_, 2023b.
* Zhang et al. (2023) Xuan Zhang, Limei Wang, Jacob Helwig, Youzhi Luo, Cong Fu, Yaochen Xie, Meng Liu, Yuchao Lin, Zhao Xu, Keqiang Yan, et al. Artificial intelligence for science in quantum, atomistic, and continuum systems. _arXiv preprint arXiv:2307.08423_, 2023.
* Zhao et al. (2022) Qingqing Zhao, David B. Lindell, and Gordon Wetzstein. Learning to solve PDE-constrained inverse problems with graph networks. In _ICML_, 2022.

Additional details for compositional inverse design in time

This section provides additional details for Section 4.1 and Section 4.2. In both sections, we use the same dataset for training, and the model architecture and training specifics are the same for both sections.

**Setup of experiment in Section 4.1.** This experiment represents a non-trivial inverse design problem with abrupt changes in the design space (i.e. small changes in the initial state leads to large differences in the outcomes) since the collisions preserve kinetic energy but modify speed and direction of each ball and multiple collisions can happen over a long time. During training time, we provide each method with training trajectory consisting of 24 steps, and in test time, let it roll out for a total of 24, 34, 44, and 54 steps. The design objective is to minimize the last step's Euclidean distance to the center \((x,y)=(0.5,0.5)\). For baselines, we compare with CEM (Rubinstein and Kroese, 2004) and Backprop (Allen et al., 2022). Each method uses either Graph Network Simulator (GNS, Sanchez-Gonzalez et al. (2020), a state-of-the-art method for modeling N-body interactions) or U-Net (Ronneberger et al., 2015) as backbone architecture that either predicts 1 step or 23 steps in a single forward pass. For our method, we use the same U-Net backbone architecture for diffusion. To perform time composition, we superimpose \(N\) EBMs \(E_{\theta}(U_{[0,T]},\gamma)\) on states with overlapping time ranges: \(U_{[0,23]}\), \(U_{[10,33]}\), \(U_{[20,43]}\),...\(U_{[10(N-1),10(N-1)+23]}\) as in Eq. 7, and use Eq. 10 to perform denoising diffusion. Besides evaluating with the design objective (\(\mathcal{J}\)), we also use the metric of mean absolute error (MAE) between the predicted trajectory and the trajectory generated by the ground-truth solver to evaluate how faithful each method's prediction is. Each design scenario is run 50 times and the average performance is reported in Table 1. We show example trajectories of our method in Fig. 2.

**Dataset.** We use two Python packages Pymunk (Blomqvist, 2007) and Pygame (Shinners, 2000) to generate the trajectories for this N-body dataset. We use 4 walls and several bodies to define the simulation environment. The walls are shaped as a \(200\times 200\) rectangle, setting elasticity to 1.0 and friction to 0.0. A body is described as a ball (circle) with a radius of 20, which shares the same elasticity and friction coefficient as the wall it interacts with. The body is placed randomly within the boundaries and its initial velocity is determined using a uniform distribution \(v\sim U(-100,100)\). We performed 2000 simulations, for 2 balls, 4 balls, and 8 balls in each simulation. Each simulation has a time step of 1/60 seconds, consisting of 1000 steps in total. During these simulations, we record the positions and velocities of each particle in two dimensions at each time step to generate 3 datasets with a shape of \([N_{s},N_{t},N_{b},N_{f}]\). \(N_{s}\) means number of simulations, \(N_{t}\) means number of time steps, \(N_{b}\) is number of bodies, \(N_{f}\) means number of features. The input of one piece of data shaped as \([B,1,N_{b}\times N_{f}]\), \(B\) is batch size, for example, \([32,1,8]\) for 2 bodies conditioning on only one step. Before training the model, the final data will be normalized by dividing it by 200 and setting the time resolution to four simulation time steps.

**Model structure.** The U-Net (Ronneberger et al., 2015) consists of three modules: the downsampling encoder, the middle module, and the upsampling decoder. The downsampling encoder comprises 4 layers, each including three residual modules and downsampling convolutions. The middle module contains 3 residual modules, while the upsampling decoder includes four layers, each with 3 residual modules and upsampling. We mainly utilize one-dimensional convolutions in each residual module and incorporate attention mechanisms. The input shape of our model is defined as \([batch\_size,n\_steps,n\_features]\), and the output shape follows the same structure. The GNS (Sanchez-Gonzalez et al., 2020) model consists of three main components. First, it builds an undirected graph based on the current state. Then, it encodes nodes and edges on the constructed graph, using message passing to propagate information. Finally, it decodes the predicted acceleration and utilizes semi-implicit Euler integration to update the next state. In our implementation of GNS, each body represents a node with three main attributes: current speed, distance from the wall, and particle type. We employ the standard k-d tree search algorithm to locate adjacent bodies within a connection radius, which is set as 0.2 twice the body radius. The attribute of an edge is the vector distance between the two connected bodies. More details are in Table 4.

**Training.** We utilize the MSE (mean squared error) as the loss function in our training process. Our model is trained for approximately 60 hours on a single Tesla V100 GPU, with a batch size of 32, employing the Adam optimizer for 1 million iterations. For the first 600,000 steps, the learning rate is set to 1e-4. After that, the learning rate is decayed by 0.5 every 40,000 steps for the remaining 400,000 iterations. More details are provided in Table 5.

To perform inverse design, we mainly trained the following models: U-Net, conditioned on 1 step and capable of rolling out 23 steps; U-Net (single step), conditioned on 1 step and limited to rolling out only 1 step; GNS, conditioned on 1 step and able to roll out 23 steps; GNS (single step), conditioned on 1 step and restricted to rolling out only 1 step; and the diffusion model. Simultaneously, we conducted a comparison to assess the efficacy of time compose by training a diffusion model with 44 steps directly for inverse design, eliminating the requirement for time compose. The results and analysis are shown in Appendix C. Throughout the training process, we maintained consistency in the selection of optimizers, datasets, and training steps for these models.

**Inverse design.** The center point is defined as the target point, and our objective is to minimize the mean squared error (MSE) between the position of the trajectory's last step and the target point. To compare our CinDM method, we utilize U-Net and GNS as forward models separately. We then use CEM (Rubinstein and Kroese, 2004) and Backprop (Allen et al., 2022) for inverse design with conditioned state \((x_{0},y_{0},v_{x0},v_{y0})\) used as input, and multiple trajectories of different bodies as rolled out. While the CEM algorithm does not require gradient information, we define a parameterized Gaussian distribution and sample several conditions from it to input into the forward model for prediction. After the calculation of loss between the prediction and target, the best-performing samples are selected to update the parameterized Gaussian distribution. Through multiple iterations, we can sample favorable conditions from the optimized distribution to predict trajectories with low loss values. Backpropagation heavily relies on gradient information. It calculates the gradient of the loss concerning the conditions and updates the conditions using gradient descent, ultimately designing conditions that result in promising output.

\begin{table}
\begin{tabular}{l l l} \hline Hyperparameter name & 23-steps & 1-step \\ \hline Hyperparameters for U-Net architecture: & & \\ \hline Channel Expansion Factor & \((1,2,4,8)\) & \((1,2,1,1)\) \\ Number of downsampling layers & 4 & 4 \\ Number of upsampling layers & 4 & 4 \\ Input channels & 8 & 8 \\ Number of residual blocks for each layer & 3 & 3 \\ Batch size & 32 & 32 \\ Input shape & \([32,24,8]\) & \([32,2,8]\) \\ Output shape & \([32,24,8]\) & \([32,2,8]\) \\ \hline Hyperparameters for GNS architecture: & & \\ \hline Input steps & 1 & 1 \\ Prediction steps & 23 & 1 \\ Number of particle types & 1 & 1 \\ Connection radius & 0.2 & 0.2 \\ Maximum number of edges per node & 6 & 6 \\ Number of node features & 8 & 8 \\ Number of edge features & 3 & 3 \\ Message propagation layers & 5 & 5 \\ Latent size & 64 & 64 \\ Output size & 46 & 2 \\ \hline Hyperparameters for the U-Net in our CinDM: & & \\ \hline Diffusion Noise Schedule & cosine & cosine \\ Diffusion Step & 1000 & 1000 \\ Channel Expansion Factor & \((1,2,4,8)\) & \((1,2,1,1)\) \\ Number of downsampling layers & 4 & 4 \\ Number of upsampling layers & 4 & 4 \\ Input channels & 8 & 8 \\ Number of residual blocks for each layer & 3 & 3 \\ Batch size & 32 & 32 \\ Input shape & \([32,24,8]\) & \([32,2,8]\) \\ Output shape & \([32,24,8]\) & \([32,2,8]\) \\ \hline \end{tabular}
\end{table}
Table 4: **Hyperparameters of model architecture for N-body task**.

During training, we can only predict a finite number of time steps based on conditional states, but the system evolves over an infinite number of time steps starting from an initial state in real-world physical processes. To address this, we need to combine time intervals while training a single model capable of predicting longer trajectories despite having a limited number of training steps. For the forward model, whether using U-Net or GNS, we rely on an intermediate time step derived from the last prediction as the condition for the subsequent prediction. We iteratively forecast additional time steps based on a single initial condition in this manner. As for the forward model (single step), we employ an autoregressive approach using the last step of the previous prediction to predict more steps.

## Appendix B Full table for compositional inverse design in time and number of bodies

Here we provide the full table including the 95% confidence interval (for 50 instances) for Table 1 in Section 4.1, as in Table 6. In addition, we provide the full table including the 95% confidence interval for Table 2 in Section 4.2, as in Table 7.

\begin{table}
\begin{tabular}{l l l} \hline Hyperparameter name & 23-steps & 1-step \\ \hline Hyperparameters for U-Net training: & & MSE \\ \hline Loss function & MSE & MSE \\ Number of examples for traing dataset & \(3\times 10^{5}\) & \(3\times 10^{5}\) \\ Total number of training steps & \(1\times 10^{6}\) & \(1\times 10^{6}\) \\ Batch size & 32 & 32 \\ Initial learning rate & \(1\times 10^{-4}\) & \(1\times 10^{-4}\) \\ Number of training steps with a fixed learning rate & \(6\times 10^{5}\) & \(6\times 10^{5}\) \\ Learning rate adjustment strategy & StepLR & StepLR \\ Optimizer & Adam & Adam \\ Number of steps for saving checkpoint & \(1\times 10^{4}\) & \(1\times 10^{4}\) \\ Exponential Moving Average decay rate & 0.95 & 0.95 \\ \hline Hyperparameters for GNS training: & & \\ \hline Loss function & MSE & MSE \\ Number of examples for traing dataset & \(3\times 10^{5}\) & \(3\times 10^{5}\) \\ Total number of training steps & \(1\times 10^{6}\) & \(1\times 10^{6}\) \\ Batch size & 32 & 32 \\ Initial learning rate & \(1\times 10^{-4}\) & \(1\times 10^{-4}\) \\ Number of training steps with a fixed learning rate & \(6\times 10^{5}\) & \(6\times 10^{5}\) \\ Learning rate adjustment strategy & StepLR & StepLR \\ Optimizer & Adam & Adam \\ Number of steps for saving checkpoint & \(1\times 10^{4}\) & \(1\times 10^{4}\) \\ Exponential Moving Average decay rate & 0.95 & 0.95 \\ \hline \end{tabular}
\end{table}
Table 5: **Hyperparameters of training for N-body task**.

[MISSING_PAGE_FAIL:15]

**Model architecture.** We use U-Net (Ronneberger et al., 2015) as our backbone for denoising from a random state sampled from a prior distribution. Without considering the mini-batch size dimension, the input includes a tensor of shape \((3T+3)\times 64\times 64\), which concatenates flow states (pressure, velocity of horizontal and vertical directions) of \(T\) time steps and the boundary mask and offsets of horizontal and vertical directions along the channel dimension, and additionally the current diffusion step \(s\). The output tensor shares the same shape with the input except \(s\). The model architecture is illustrated in Fig. 4. The hyperparameters in our model architecture is shown in Table 9.

**Training.** We utilize the MSE (mean squared error) between prediction and a Gaussian noise as the loss function during training. We take batch size of 48 and run for 700,000 iterations. The learning rate is initialized as \(1\times 10^{-4}\). Training details are provided in Table 10.

**Evaluation of design results.** In inference, we set \(\lambda\) in Eq. 3 as 0.0002. We find that this \(\lambda\) could get the best design result. More discussion on the selection of \(\lambda\) is presented in Appendix I. For each method and each airfoil design task (one airfoil or two airfolis), we conduct 10 batches of design and each batch contains 20 examples. After we get the designed boundaries, we input them into Lily-Pad and run simulation. To make the simulation more accurate and convincing, we use a 128\(\times\)128 resolution of the flow field, instead of 64 \(\times\) 64 as in the generation of training data. Then we use the calculated horizontal and vertical flow force to compute our two metrics: \(-\)lift \(+\) drag and lift-to-drag ratio. In each batch, we choose the best designed boundary (or pair of boundaries in two airfoils scenario) and then we report average values regarding the two metrics over 10 batches.

### Surrogate Model for Force Prediction

**Model architecture.** In the 2D compositional inverse design of multiple airfoils, we propose a neural surrogate model \(g_{\varphi}\) to approximate the mapping from the state \(U_{t}\) and boundary \(\gamma\) to the lift and

Figure 4: **Diffusion model architecture of 2D inverse design.**

Figure 5: **Example of Lily-Pad simulation.**

[MISSING_PAGE_FAIL:17]

Figure 6: **54 time steps trajectories of 2 bodies after performing inverse design using the backpropagation algorithm**. Figures (a), (b), (c), and (d) represent the trajectory graphs obtained using GNS, GNS (single step), U-Net, and U-Net (single step) as the forward models, respectively. And (e) is the result of CinDM. The legend of this figure is consistent with Figure 2.

Figure 7: **54-step trajectories of 2 bodies after performing inverse design using the backpropagation algorithm**. Figures (a), (b), (c), and (d) represent the trajectory graphs obtained using GNS, GNS (single step), U-Net, and U-Net (single step) as the forward models, respectively. And (e) is the result of CinDM. The legend of this figure is consistent with Figure 2.

Figure 8: **44-time steps trajectories of 4 bodies after performing inverse design using CEM. Figures (a), (b), (c), and (d) represent the trajectory graphs obtained using GNS, GNS (single step), U-Net, and U-Net (single step) as the forward models, respectively. And (e) is the result of CinDM. The legend of this figure is consistent with Figure 2.**

## 6 Conclusion

Figure 9: **Compositional design results of our method in 2D airfoil generation**. Each row represents an example. We show the heatmap of velocity in horizontal and vertical direction and pressure in the initial time step, inside which we plot the generated airfoil boundaries.

## Appendix F Visualization results of 2D inverse design by our CinDM

We show compositional design results of our method in 2D airfoils generation in Figure 9.

## Appendix G Some visualization results of 2d inverse design baseline.

We show some 2D design results of our baseline model in Fig. 10.

## Appendix H Comparison to additional works

Besides comparison results of baselines shown in the main text, we further evaluated additional two baselines: neural adjoint method with boundary loss function (NABL) and conditional invertible neural network (cINN) method (Ren et al., 2020; Ansari et al., 2022) for both N-body and airfoils design experiments.

We implement NABL on top of baselines FNO and LE-PDE in the airfoil design task and U-net in tcompositionalostional taskamed as "NABL, FNO", "NABL, LE-PDE" and "NABL, U-net" respectively. These new NABL baselines additionally use the boundary loss defined by the mean value and 95% significance radius of the training dataset. cINN does not apply to compositional design because the input scale for the invertible neural network function is fixed. Therefore, for the time composition task, we trained 4 cINN models, each for one of the time steps: 24, 34, 44, and 54. These models differ only in the input size. The input \(x\) to cINN is a vector of size \(2\times 4\times T\), where 2 is the number of objects, 4 is the number of features and \(T\) is the number of time steps. The condition \(y\) is set to 0, the minimal distance to the target point. For cINN for 2D airfoil design, we adopt 2D coordinates of 40 boundary points--arsewhich is spanned 80--dimensionalised vector, as the input, since the invertible constraint on the cINN model hardly accepts image-like inputs adopted in the main experiments. Therefore we evaluate cINN only in the single airfoil design task. The condition \(y\) is set as the minimal value of drag - lift drag in the training trajectories. In both tasks, the random variable \(z\) has a dimension of dim(\(x\)) - dim(\(y\)). It is drawn from a Gaussian distribution and then input to the INN for inference. We also adjust the hyperparameters, such as hidden size and a number of reversible blocks, to make the number of parameters in cINN close to ours for fair comparison.

The results of NABL and cINN are shown in Table 11 and Table 12. We can see that CinDM significantly outperforms the new baselines in both experiments. Even compared to the original baselines (whocontains contain "Backprop-") without the boundary loss function, as shown in Table 1 and Table 3, the NABL baselines in both tasks do not show the improvement in the objective for out-of-distribution data. These results show that our method generalizes to out-of-distribution while the original and new baselines struggle to generalize the out-of-distribution. CinDM also outperforms cINN by a large margin in both the time composition and airfoil design tasks. Despite the quantities, we also find that airfoil boundaries generated by cINN have little variation in shape, and the orientation is not as desired, which could incur high drag force in simulation. These results may be caused by the limitation of the model architecture of cINN, which utilizes fully connected layers as building blocks, and thus has an obvious disadvantage in capturing inductive bias of spatial-temporal features. We think it is necessary to extend cINN to convolutional networks when cINN is applied to such high-resolution design problems. However, this appears challenging when the invertible requirement is imposed. In summary, our method outperforms both NABL and cINN in both tasks. Furthermore, our method could be used for flexible compositional design. We use only one trained model to generate samples lying in a much larger state space than in training during inference, which is a unique advantage of our method beyond these baselines.

\begin{table}
\begin{tabular}{l|c c|c c|c c|c c} \hline \hline  & \multicolumn{2}{c}{**2-body 24 steps**} & \multicolumn{2}{c}{**2-body 34 steps**} & \multicolumn{2}{c}{**2-body 44 steps**} & \multicolumn{2}{c}{**2-body 54 steps**} \\ Method & design obj & MAE & design obj & MAE & design obj & MAE & design obj & MAE \\ \hline NABL, U-Net (1-step) & 0.1174 & 0.01650 & 0.1425 & 0.01511 & 0.1788 & 0.01185 & 0.2606 & 0.02042 \\ cINN & 0.3235 & 0.11704 & 0.3085 & 0.18015 & 0.3478 & 0.18322 & 0.3372 & 0.19296 \\ \hline
**CinDM (ours)** & **0.1143** & **0.01202** & **0.1251** & **0.00763** & **0.1326** & **0.00695** & **0.1533** & **0.00870** \\ \hline \hline \end{tabular}
\end{table}
Table 11: **Comparison to NABL and cINN for N-body time composition inverse design task.**Figure 10: **Design results of FNO with CEM in 2D airfoil generation**. Each row is the heatmap of optimized velocities in horizontal and vertical direction and optimized pressure in the initial time step, inside which we plot the generated airfoil boundaries.

[MISSING_PAGE_FAIL:24]

the simulator to obtain the output \(\hat{y}\) for each design \(x\) from the \(T\) design results given the target \(y\) and compute the "re-simulation" error \(L(\hat{y},y)\). We then calculate the least error among a batch of \(T\) design results. This process is repeated for several batches, and the mean least error \(r_{T}\) is obtained by averaging over these batches.

Table 15 and Fig 14 present the results for the N-body inverse design task. We consider values of \(T\) ranging from 10 to 100, with \(N=10\) batches. The target \(y\) is set to be 0, which represents the distance to a fixed target point. The results show that \(r_{T}\) gradually decreases as \(T\) increases in the 24-step design, indicating that the design space is well explored and most solutions can be retrieved even with a small number of samplings. This demonstrates the efficiency of our method in generating designs. Moreover, similar observations can be made when time composition is performed in 34, 44, and 54 steps, indicating the effectiveness of our time composition approach in capturing long-time range physical dependencies and enabling efficient generation in a larger design space.

In the 2D inverse design task, the target \(y\) is slightly different. Here, we aim to minimize the model output (drag - lift force). Hence, we adopt the "re-simulation" performance metric, which is the lift/drag ratio, as opposed to the "re-simulation" error used in the N-body task, to evaluate sensitivity to initialization. For each \(T\), the lift/drag ratio is chosen as the highest value among the simulation results of a batch of \(T\) designed boundaries (or boundary pairs for the 2 airfoils design). Any invalid

Figure 11: **Design objective of different \(\lambda\) in N-body time composition inverse design.**

Figure 12: **MAE of different \(\lambda\) in N-body time composition inverse design.**

design results, such as overlapping airfoil pairs in the 2- airfoil design, are removed from the \(T\) results before computing the maximal lift/drag ratio. The reported numbers are obtained by averaging over \(N\) batches for each \(T\).

Table 16 and Fig 15 present the results for the 2D airfoils design task. In the 1 airfoil design column, we observe that the lift/drag performance remains relatively steady for \(T\geq 20\). For \(T=10\), the lift/drag ratio is relatively low, indicating that the design space is not sufficiently explored due to its high dimensionality (64x64x3 in our boundary mask and offsets representation). In the 2 airfoils design column, the lift/drag ratio increases with \(T\). This is attributed to the higher dimensional and more complex design space compared to the single airfoil design task. The stringent constraints on boundary pairs, such as non-overlapping, lead to the presence of complex infeasible regions in the design space. Random initialization may lead to these infeasible regions, resulting in invalid design results. The rate of increase in lift/drag ratio becomes slower when \(T\geq 30\), indicating that a majority of solutions have been explored. Despite the training data only containing a single airfoil boundary, which lies in a relatively lower dimensional and simpler design space, our model demonstrates a strong ability to generalize and efficiently generate designs for this challenging 2 body compositional design problem.

Figure 14: **“Re-simulation” error \(r_{T}\) of different \(T\) in N-body inverse design.**

Figure 13: **Performance of different \(\lambda\) in 2D airfoil inverse design.**

### Influence of the number of sampling steps in inference

Figure 16: **Design objective of different sampling steps in N-body inverse design.**

Fig 16 and Fig 17 illustrate the outcomes of inverse design carried out by CinDM. It is apparent that with an increase in the number of sampling time steps, the design objective gradually decreases. In contrast, the MAE fluctuates within a small range, occasionally rising. This phenomenon can be examined as follows: as the number of sampling steps increases, the participation of the design objective in the diffusion process intensifies. As a result, the designs improve and align more closely

\begin{table}
\begin{tabular}{l|l l l l} \hline
**T** & **2-body 24 steps** & **2-body 34 steps** & **2-body 44 steps** & **2-body 54 steps** \\ \hline
**10** & 0.10122654 & 0.1022556 & 0.10542078 & 0.11227837 \\
**20** & 0.10051114 & 0.10122902 & 0.10261874 & 0.10554917 \\
**30** & 0.09950846 & 0.10106587 & 0.10220513 & 0.10408381 \\
**40** & 0.09928784 & 0.10066015 & 0.10173534 & 0.10409425 \\
**50** & 0.09794939 & 0.10023642 & 0.10168899 & 0.10462530 \\
**60** & 0.09876589 & 0.0997466 & 0.10105932 & 0.10257294 \\
**70** & 0.09858151 & 0.09979441 & 0.10124100 & 0.10179855 \\
**80** & 0.09809845 & 0.09972977 & 0.10060663 & 0.10203485 \\
**90** & 0.09808731 & 0.09941968 & 0.10108861 & 0.10120515 \\
**100** & 0.09734109 & 0.09912691 & 0.10056177 & 0.10135190 \\ \hline \end{tabular}
\end{table}
Table 15: **Influence of initialization. \(r_{T}\) with respect to \(T\) for N-body inverse design task. Each number is an of average over 10 batches.**

[MISSING_PAGE_POST]

Fig 25: **Design performance (left-to-drag) of different \(T\) in 2D airfoil inverse design.**with the design objective, ultimately leading to a decrease in the design objective. However, when the number of sampling steps increases, the MAE also increases. This is because, with a small number of sampling steps, the initial velocities of some designed samples are very small, causing the diffusion of trajectories to be concentrated within a narrow range. Consequently, both the true trajectory and the diffused trajectory are highly concentrated, resulting in a small calculated MAE. By analyzing the sensitivity of the design objective and MAE to different sampling steps, we can conclude that ClinDM can achieve desired design results that align with design objectives and physical constraints by appropriately selecting a sampling step size during the inverse design process.

## Appendix J Broader impacts and limitations

Our method, CinDM, extends the scope of design exploration and enables efficient design and control of complex systems. Its application across various scientific and engineering fields has profound implications. In materials science, utilizing the diffusion model for inverse design facilitates the customization of material microstructures and properties. In biomedicine, it enables the structural design of drug molecular systems and optimizes production processes. Furthermore, in the aerospace sector, integrating the diffusion model with inverse design can lead to the development of more diverse shapes and structures, thereby significantly enhancing design efficiency and quality.

CinDM combines the advantages of diffusion models, allowing us to generate more diverse and sophisticated design samples. However, some limitations need to be addressed at present. In terms of design quality and exploration space, we need to strike a balance between different objectives to avoid getting stuck in local optima, especially when dealing with complex, nonlinear systems in the real world. We also need to ensure that the designed samples adhere to complex multi-scale physical constraints. Furthermore, achieving interpretability in the samples designed by deep learning models is challenging for inverse design applications. From a cost perspective, training diffusion models requires large datasets and intensive computational resources. The complexity of calculations also hinders the speed of our model design.

Moving forward, we intend to incorporate more physical prior knowledge into the model, leverage multi-modal data for training, employ more efficient sampling methods to enhance training efficiency, improve interpretability, and generalize the model to multiple scales.

\begin{table}
\begin{tabular}{c|c c} \hline
**T** & **1 airfoil** & **2 airfoils** \\ \hline
**10** & 1.4505 & 0.8246 \\
**20** & 2.2725 & 0.7178 \\
**30** & 2.2049 & 1.3862 \\
**40** & 2.6506 & 1.5781 \\
**50** & 2.1355 & 1.6055 \\ \hline \end{tabular}
\end{table}
Table 16: **Influence of initialization**. Design performance (lift-tconcerningspect to \(T\) for 2D inverse design task. Each number is an of average over 10 batches.

Figure 17: **MAE of different sampling steps in N-body inverse design.**