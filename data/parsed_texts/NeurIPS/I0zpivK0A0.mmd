# Terra: A Multimodal Spatio-Temporal

Dataset Spanning the Earth

 Wei Chen\({}^{1}\) **Xixuan Hao\({}^{1}\)****Yuankai Wu\({}^{2}\)****Yuxuan Liang\({}^{1}\)**

\({}^{1}\)The Hong Kong University of Science and Technology (Guangzhou) \({}^{2}\)Sichuan University

onedeanxxx@gmail.com, yuxliang@outlook.com

Y. Liang is the corresponding author.

###### Abstract

Since the inception of our planet, the meteorological environment, as reflected through spatio-temporal data, has always been a fundamental factor influencing human life, socio-economic progress, and ecological conservation. A comprehensive exploration of this data is thus imperative to gain a deeper understanding and more accurate forecasting of these environmental shifts. Despite the success of deep learning techniques within the realm of spatio-temporal data and earth science, existing public datasets are best with limitations in terms of spatial scale, temporal coverage, and reliance on limited time series data. These constraints hinder their optimal utilization in practical applications. To address these issues, we introduce Terra, a multimodal spatio-temporal dataset spanning the earth. This dataset encompasses hourly time series data from 6,480,000 grid areas worldwide over the past 45 years, while also incorporating multimodal spatial supplementary information including geo-images and explanatory text. Through a detailed data analysis and evaluation of existing deep learning models within earth sciences, utilizing our constructed dataset. we aim to provide valuable opportunities for enhancing future research in spatio-temporal data mining, thereby advancing towards more spatio-temporal general intelligence. Our source code and data can be accessed at https://github.com/CityMind-Lab/NeurIPS24-Terra.

## 1 Introduction

With the rapid development of remote sensing satellite systems [32, 27], radar monitoring devices [77, 65], and various advanced geographical observation technologies, spatio-temporal data [16, 79], particularly those pertaining to the Earth's environment and climate, are becoming increasingly available. Analyzing and mining valuable knowledge from such spatio-temporal data is crucial for many real-world applications, including environmental monitoring [37], disaster management [75], urban planning [40], and climate change assessment [76]. In the era of sensory artificial intelligence, an array of methods has been devised, ranging from conventional time series and spatial statistical analysis tools [80] to cutting-edge spatio-temporal deep learning models [30], for the analysis and utilization of domain-specific data. Despite remarkable achievements, there remains a huge gap between mainstream spatio-temporal data mining research [94] and the recent shift towards artificial general intelligence research [21], where the latter aims to address various challenges in a unified manner, while the generalizability and scalability challenge still lies in the former.

What causes this gap, or in other words, what measures can be taken to further advance research in spatio-temporal general intelligence? From historical experience, comprehensive, large-scale, high-quality datasets are crucial for the progress of any research community in any field. For instance, the ImageNet dataset [26], which has historically driven the development of the Computer Vision community, and the Common Crawl dataset [64], which is currently fostering growth in themodel with billions parameters has led to remarkable breakthroughs in the generalization ability of vision and language models across various tasks [20; 63]. However, most of the work on spatio-temporal data mining focuses on developing advanced models [79], while neglecting the urgent need for comprehensive datasets themselves. Thus, there is an immediate necessity for a high-quality spatio-temporal dataset with sufficient breadth, granularity, capacity, and multimodal integration, allowing researchers to explore different methods at various scales and to move towards more general spatio-temporal intelligence.

To address these challenges, we introduce Terra, a public, large-scale, fine-grained, and multimodal dataset across spatio-temporal domains. The name is derived from the earth goddess in ancient Roman mythology. As shown in Figure 1, Terra rasterizes the Earth, integrates various data sources, and includes over 6820 billion hourly Earth meteorological observation time series data collected globally within raster grids from 1979 to 2024, as well as spatial multimodal geographic information supplements for all regions within global raster grids, including text descriptions and geographic images, aiming to advance spatio-temporal data analysis and spatial intelligence research. Specifically, Terra distinguishes itself significantly from previous spatio-temporal datasets with its comprehensive spatio-temporal coverage, outstanding quality, and diverse data modalities.

In summary, we condense its outstanding characteristics into three contributions: _(1) Large scale_, encompassing over 45 years of sequential observational information in terms of temporal range and global-level geographic information in terms of spatial range, ensuring the robustness, generalization, and reliability of models through large-scale data properties. _(2) Fine granularity_, supporting up to 3 hourly time granularity and up to 0.1\({}^{\circ}\) resolution spatial grid records, ensuring the practical feasibility of real-world application scenarios through fine-grained data properties. _(3) Multi Modality_, unlike previous datasets that only consisted solely of spatio-temporal observation records without exogenous data, we further provide a variety of multimodal supplementary data, including rich text and image data, enabling the exploration of large language and vision models in this field, thereby enhancing the interpretability of models.

## 2 Background

In this section, we review relevant works in spatio-temporal data mining, focusing on its challenges, various applications, and the limitations of existing datasets that support research in this field. It is worth noting that we particularly emphasize data types related to earth sciences. Other types of spatio-temporal data, such as vision-based video data [62], are beyond the scope of this paper.

### Challenges and Applications of Spatio-Temporal Data Mining

Spatio-temporal data mining represents an interdisciplinary fusion of various fields such as spatio-temporal databases, machine learning, statistics, geography, meteorology, and information theory [31]. Specifically, spatio-temporal data refer to types of geographic entity data that exist at different scales

Figure 1: Overview of Terra and its application in spatio-temporal data intelligence.

with spatio-temporal associations. These include spatial relationships, both metric (_e.g._, distance) and non-metric (_e.g._, topology, flow, and shape), temporal relationships (_e.g._, before or after), and spatio-temporal relationships (_e.g._, correlation and heterogeneity) that are explicitly or implicitly present in the data. In recent years, deep learning models such as recurrent neural networks [71], convolutional neural networks [93], and graph neural networks [40] achieve remarkable success in capturing the temporal and spatial dependencies in spatio-temporal data. These efforts lead to significant advances in various fields. For example, they have broad applications in environmental and climate areas (_e.g._, precipitation forecasting [71] and air quality inference [53]), urban planning (_e.g._, traffic flow prediction [40] and anomaly detection [36]), and human mobility (_e.g._, travel recommendations [55] and personalized marketing [23]). However, applying deep models to spatio-temporal data is often more challenging. Firstly, spatio-temporal data are usually embedded in continuous space, different from the discrete space common in vision and language data. Secondly, spatio-temporal data often have high auto-correlation, contrasting with the traditional i.i.d. assumption of data samples. Lastly, spatio-temporal data have different scales of spatial and temporal resolution, and models trained on limited data often lack generalizability. Recently, with the success of foundational models [52; 18] (_e.g._, large language models [11; 42] and diffusion models [67; 87]), researchers are exploring the construction of spatio-temporal foundational models to revolutionize this field. The aim is to achieve zero-shot inference and robust generalizability across different spatio-temporal tasks. For instance, in meteorological forecasting, Pangu [17] and GraphCast [48] provide unprecedented forecasting capabilities through pre-training on massive climate data. In urban computing [100], some studies [50; 51] combine the capabilities of large models to pioneer the development of foundational models for traffic. All these advancements enable researchers to uncover valuable insights into spatio-temporal patterns, continuously optimize the Earth's environmental systems, promote human economic and social development, and contribute to extensive interdisciplinary research.

### Limitations of Existing Spatio-Temporal Datasets

Table 1 presents a comparison between the proposed Terra and other popular or latest spatio-temporal datasets. We next detail the improvements of Terra over others from five aspects.

* **Incomplete Analytical Perspectives:** Widely adopted datasets such as GeoLife [97], and more recent ones like GEO-Bench [47] and CityScape [34], have significantly contributed to spatial analysis research, including location recommendation and urban region analysis. At the same time, researchers have also performed various temporal analyses on time-series data like GluonTS [12], including tasks like prediction, imputation, and anomaly detection. However, these datasets are often only able to focus on singular spatial or temporal analyses. _In contrast, Terra offers comprehensive possibilities for spatio-temporal analysis from both perspectives._

\begin{table}
\begin{tabular}{c|c|c|c|c|c|c|c|c} \hline \hline \multirow{2}{*}{**Dataset**} & \multirow{2}{*}{**Year**} & \multirow{2}{*}{**Accessibility**} & \multirow{2}{*}{**Volume**} & \multicolumn{2}{c|}{**Large-Scale**} & \multicolumn{2}{c|}{**Fine-Granularity**} & \multicolumn{2}{c}{**Multi-Modality**} \\ \cline{6-9}  & & & & Spatial & Temporal & & Time Series & Text & Image \\ \hline Geolife [97] & 2010 & ✓ & 24M+ & ✗ & ✗ & ✓ & ✓ & ✗ & ✗ \\ \hline GluonTS [12] & 2020 & ✓ & 16M & ✗ & ✗ & ✓ & ✓ & ✗ & ✗ \\ \hline NYC [88] & 2019 & ✓ & 22M+ & ✗ & ✓ & ✓ & ✓ & ✓ & ✗ \\ \hline PEMS [72] & 2020 & ✓ & 42M+ & ✗ & ✗ & ✓ & ✓ & ✓ & ✗ \\ \hline SEVIR [77] & 2020 & ✓ & \(\diamondsuit\) & ✗ & ✓ & ✓ & ✗ & ✓ \\ \hline ML4Road [61] & 2024 & ✓ & 9M+ & \(\sim\) & \(\sim\) & ✓ & ✓ & ✓ & ✗ \\ \hline BioMassters [59] & 2024 & ✓ & 79M+ & ✗ & \(\sim\) & ✓ & ✗ & ✓ & ✗ \\ \hline ClimateSet [43] & 2024 & ✓ & ✓ & ✓ & ✓ & \(\sim\) & ✓ & ✓ & ✗ \\ \hline ClinSim [90] & 2024 & ✓ & 5.7B+ & ✓ & ✓ & \(\sim\) & ✓ & ✓ & ✗ \\ \hline Digital Typhoon [44] & 2024 & ✓ & 49B+ & \(\sim\) & ✓ & ✓ & ✓ & \(\sim\) & ✗ \\ \hline Mesogeos [46] & 2024 & ✓ & 1344B+ & ✗ & ✓ & ✓ & ✓ & ✓ & \(\sim\) & \(\sim\) \\ \hline GEO-Bench [47] & 2024 & ✓ & \(\diamondsuit\) & ✓� & ✗ & ✓ & ✗ & ✗ & ✓ \\ \hline CityScape [34] & 2024 & ✗ & 65K+ & ✗ & ✓ & ✗ & ✗ & ✓ & ✓ \\ \hline ChatEarthNet [91] & 2024 & ✓ & \(\diamondsuit\) & ✓� & ✓� & ✗ & ✗ & ✓ & ✓ \\ \hline Terra (ours) & 2024 & ✓ & 6820B+ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ \\ \hline \hline \end{tabular}
\end{table}
Table 1: Comparisons between Terra and other spatio-temporal datasets. Here, ✓ represents meeting a better standard, � represents not meeting it, and \(\sim\) represents partially meeting or being convertible to meet it. Due to the difficulty of counting sizes from multiple data sources, we mark it with \(\diamondsuit\).

* **Restricted Access Opportunities:** Early spatial-temporal datasets often focused on human mobility (_e.g._, Geolife [97] and NYC [88]) and intelligent transportation (_e.g._, PEMS [72] and ML4Road [61]). However, these datasets typically involve privacy concerns and are held by a few companies or organizations with proprietary or restrictive access policies, resulting in restricted access to small datasets. Therefore, recent benchmarks has shifted towards spatio-temporal data in freely accessible fields such as Earth Sciences, leading to the emergence of numerous datasets such as BioMasters [59], ChatEarthNet [91], _etc. Similarly, Terra also benefits from this shift, allowing free access to these massive spatio-temporal data._
* **Limited Spatio-Temporal Coverage:** Due to the labor and financial costs associated with data collection, existing datasets are often confined to specific cities or regions. Early examples, including NYC [88] and PEMS [72], generally cover only a few months of data for a single city or region. Recent earth science datasets, like SEVIR [77], Mesogeos [46] and Digital Typhoon [44], have significantly increased in scale but still struggle to achieve global coverage over several decades. This limitation results in insufficient geographic representation, impeding generalizability to other regions, and inadequate temporal representation, failing to capture seasonal or annual trends. _In contrast, Terra offers global spatial coverage and over 45 years of temporal coverage._
* **Limited Spatio-Temporal Resolution:** Although some recent spatial-temporal datasets have reached considerable scales, they still fail to provide sufficiently granular spatial-temporal resolution. For instance, ClimateSet [43] only offers monthly climate records. These low sampling rates and resolutions further diminish their practical utility. _In contrast, Terra provides resolutions up to 0.1\({}^{\circ}\) spatially and 3-hour intervals temporally._
* **Limited Multimodal Supplement:** Existing datasets often provide only basic spatial-temporal sequences, such as ClimSim [90], lacking rich multimodal supplementary information like text or images. This deficiency hinders comprehensive analysis and fails to meet the requirements for multimodal or advanced model design. _In contrast, Terra provides global-scale visual and textual information, serving as potential components for building foundational spatial-temporal models.

## 3 Dataset Details

In this section, we formally introduce our proposed Terra dataset. As shown in Figure 2, our dataset consists of three modalities, each containing different types of data. We describe in detail the collection and processing methods of different modality data below to deepen the understanding of Terra. For more data introduction, analysis, statistics, visualization, and statement, see Appendix A.

Figure 2: Different modality components of Terra. We provide the data with three temporal scales (3 hourly / daily / monthly), and three spatial scale (0.1\({}^{\circ}\) / 0.5\({}^{\circ}\) / 1\({}^{\circ}\)).

**Time Series Modality.** We obtain the time-series modality data for Terra from the _Global Water (GloH2O) Measurement Project_[5]. Specifically, we combine the past observation records from two products: Multi-Source Weather (MSWX) and Multi-Source Weighted-Ensemble Precipitation (MSWEP). MSWX is an operational high-resolution (3 hours, 0.1\({}^{\circ}\)), bias-corrected meteorological product, covering the global range from 1979 to 5 days before real-time. This product includes 10 meteorological variables: precipitation (mm/3h), air temperature (\({}^{\circ}\)C), daily minimum and maximum temperatures (\({}^{\circ}\)C), surface pressure (Pa), relative and specific humidity (% and g/g), wind speed (m/s), and downward shortwave and longwave radiation (W/m\({}^{2}\)). As shown on the left side of Figure 2, we exclude the daily minimum and maximum temperatures due to their limited resolution. MSWEP, a global precipitation product, spans from 1979 to 3 hours before real-time with a resolution of 3 hours and 0.1\({}^{\circ}\). Unlike MSWX, MSWEP uniquely combines gauge, satellite, and reanalysis data to provide the highest quality precipitation estimates at each location. Since MSWEP includes satellite data, its precipitation estimates may be more accurate than those of MSWX in regions with dense measurements and convection-dominated areas. Therefore, we replace MSWX precipitation records with MSWEP values. We select a time span covering 45 years from [01/01/1979 to 01/01/2024), equivalent to 540 months or 16,436 days. As a result, we obtain the largest dataset with a resolution of 0.1\({}^{\circ}\), 3 hours, and a total of 6.82e+12 numerical records. Based on this, we further resample and combine the data at spatial resolutions of 0.5\({}^{\circ}\) and 1\({}^{\circ}\) and temporal resolutions of daily and monthly. This process yields a total of 9 variant, with the number of records for each dataset shown in Figure 3.

**Text Modality.** We first obtain the geographic text data within each raster region, mainly including climate, mean elevation, land vegetation, and the countries included. Specifically, We crawl the climate metadata from _Koppen climate classification project_[6], which reveal variations and changes of climate over the period 1901-2010. Given the slow pace of climate change, we utilize this data to represent current climate values. Climate types are represented by a two or three-letter combination, where the first letter denotes the major type (_e_.\(g\)., tropical, dry, snow), and the second letter or third letter specifies subcategories (_e_.\(g\)., fully humid, desert). Global elevation values are queried from _ETOPO2v2_[3], which combines topography, bathymetry, and shoreline data from both regional and global sources, enabling detailed, high-resolution renderings of the Earth's geophysical characteristics. We take the average of all data points within the indexed region, referred to as the mean elevation of the current indexed region. We also crawl Land Cover data from the _C3S Global Land Cover Product_[2], which classifies land cover into 38 categories (_e_.\(g\)., cropland_raifield and tree_broadleaved_deciduous_closed). we use data for 2022 year. For the land cover and climate type, we calculate the proportion within each region and provide it in percentage form. Regarding the country's affiliation, we referred to data from the world-geo-json repository [4]. Although these meta texts partially reflect the region's geographical characteristics, they lack comprehensive analysis and inference of potential spatial features (_e_.\(g\)., how land cover types influence the area's climate and rainfall patterns). Recently, large language models (LLMs) have become essential for enhancing spatio-temporal data due to their integrated geographical knowledge, compressed through pre-training on extensive corpora [14, 42]. Consequently, we employ the state-of-the-art open-source language

Figure 4: A example of spatial prompt engineering.

Figure 3: Dataset volume comparison.

model LLaMA3 [58] to generate supplementary textual information. Given the open challenge of hallucinations in LLMs [38], resulting inaccuracies can introduce noise into downstream tasks. To mitigate this problem, we designed a spatial prompt engineering, as shown in Figure 4. This technique suggests querying factual meta text-related to country, climate, land vegetation, and mean elevation characteristics as auxiliary prompts. This approach aims to provide LLMs with comprehensive information, facilitating more accurate extraction of surface environmental data. Figure 5 presents statistics and visual insights of the selected LLM text modality data. We also discuss the necessity of our prompting technique and compare different LLM choices in Appendix A.3.

**Image Modality.** We further adopt the Mercator projection [10] to map the Earth into grids at different spatial resolutions and crawl relevant geographic image information for each grid cell. Specifically, we first access geographic datasets provided by remote machines of GMT [9] and utilize the PyGMT [7] toolkit to draw geo-images according to specified longitude and latitude regions. In particular, we select common geographic images including Earth Geoid (coinciding with the mean sea level and extending into the interior of continents), Earth Free-Air Anomaly Errors (normalizing observed values and height correction, converting gravity values to gravity anomalies referenced to the same latitude geoid), Earth Magnetic Anomaly (obtained by subtracting the global magnetic field from the Earth's core main magnetic field and its induced magnetic field after subtracting the variable magnetic field, resulting in lithospheric magnetic field), Earth Mask (referring to surface water-land geographical features), Earth Relief (containing observed topography and terrain inferred through height gravity), Earth Vertical Gravity Gradient (referring to the vertical derivative of gravity for detecting geological structures and positions of small geological bodies). All these converted geo-images are commonly used for exploring Earth sciences and summarizing regional geographic information. Additionally, satellite remote sensing images are usually another excellent visual descriptive imagery of geographic information, apart from the aforementioned types, and can also be obtained for each grid under corresponding image information using ArcGIS [1].

**Discussion.** Despite our best efforts to obtain rich spatio-temporal data from multiple sources, several unavoidable issues still persist: Firstly, our image and text modalities still do not support a spatial resolution of 0.1\({}^{\circ}\) due to the enormous time and monetary costs associated with this scale. Secondly, as we utilize LLM models to generate text data, the inevitable obsolescence of the latest LLM capabilities exists. Finally, the acquired satellite remote sensing images may have outdated and unstable redistribution restrictions. For the first issue, we hope to continually invest time and monetary resources to highlight higher-resolution text and image modal data in future versions. Regarding the second issue, we first empirically studied the suitability of existing generated text (see Appendix A.3) and look forward to regularly update and utilize the latest and best open-source LLM to generate new text data, selectively replacing existing text. For the third issue, we also suggest exploring alternative satellite image products from other open-source communities, such as Sentinel-2 [8], for updates.

**Potential Applications Summary.** We summarize a range of potential application scenarios for our proposed Terra dataset, encompassing but not limited to those enumerated in the Table 2. Spanning remote sensing, urban indicator prediction, time series forecasting, and beyond, the diverse modalities and extensive volume of the Terra dataset present limitless application possibilities. We aspire for the community to leverage Terra to foster significant advancements in spatial-temporal data mining.

**Data License.** The Terra dataset is made available under the CC BY-NC 4.0 International License: https://creativecommons.org/licenses/by-nc/4.0. Our code and dataset are released under the MIT License: https://opensource.org/licenses/MIT. The license of any baselines and subdata sources used in this paper should also be verified on their official repositories.

Figure 5: Statistical and visual insights of text modality data.

## 4 Use Cases

To further demonstrate the practicality and versatility of our dataset, we have selected its use in two key tasks: spatio-temporal analysis and spatial analysis. These tasks are classical examples in spatio-temporal data mining, with the former providing insights into joint modeling of spatial and temporal, and the latter supporting common applications in spatial modeling. Through these simple application cases, our goal is to illustrate the versatility and usability of Terra.

### Spatio-Temporal Analysis Task

**Problem Definition.** Each record in a grid is a multivariate time series \(x\in\mathbb{R}^{T\times C}\), capturing dynamic observations of \(C\) measurement features over \(T\) time steps. Here, \(N\) regions with spatially correlated locations constitute a spatial-otemporal tensor \(X\in\mathbb{R}^{N\times T\times C}\). Spatio-temporal forecasting predicts signals \(X\in\mathbb{R}^{N\times T^{f}\times C}\) for \(T^{f}\) future time steps across \(N\) variables, utilizing \(T^{h}\) steps historical time series \(X\in\mathbb{R}^{N\times T^{h}\times C}\) (and an optional spatial correlation graph \(\mathcal{G}\) among recorded regions).

**Setup.** Here, we choose precipitation prediction as a representative example. We extract spatio-temporal precipitation sequences from time-series modality data with a temporal resolution of 1 day and spatial resolution of 1\({}^{\circ}\), covering a temporal span of 26 years and global spatial extent, forming the _Global_ dataset. Subsequently, we construct five smaller country datasets representing five continents by selecting representative countries: the United Kingdom (_UK_), the United States (_USA_), China (_CN_), South Africa (_SA_), and Australia (_AUS_). For all datasets, we partition the dataset into training, validation and test sets as 6:2:2. Then, we select four categories of popular methods as baselines, including time-series models (**TimesNet**[82], **FEDformer**[99], **PatchTST**[60], **DLinear**[92]), spatio-temporal prediction models (**STAEformer**[54], **STID**[70], **GWNet**[83], **STGCN**[89]), precipitation-specific prediction model **ConvLSTM**[71], and historical mean method **HI**[24]. For different methods, in order to adapt to the task, we make appropriate feature, structure and hyperparameter adjustments to achieve the best results. We conduct three prediction scenarios: predicting precipitation for the next 7, 15, and 30 days based on the historical 30-day precipitation sequences, using mean absolute error (MAE) and root mean square error (RMSE) to evaluate prediction performance. All experiments are conducted three times, and the mean values are reported. For more detailed information about the experimental setup, please refer to Appendix A.

**Result Analysis.** Table 3 presents the MAE and RMSE test results for specific horizons of 7, 15, and 30 days, along with the average performance across all prediction horizons. The simple method **HI** performs the worst as it completely ignores temporal dependency and spatial correlation, relying solely on the last lagged value from historical records. Additionally, the state-of-the-art **TimesNet** model in time-series prediction and advanced spatio-temporal prediction model **STID** achieve the best and second-best performance, respectively. This could be attributed to their incorporation of embedding information of time and

\begin{table}
\begin{tabular}{c|c|c|c} \hline \multirow{2}{*}{**Single Modality**} & **Modality** & **Application Examples** & **Method Examples** \\ \hline \multirow{4}{*}{**Single Modality**} & (Spatial)-Time Series & Time Series Forecasting, Imputation, Classification\({}^{\dagger}\), & Motrai\({}^{\dagger}\)[81], TimesNet\({}^{\dagger}\)[82], UrbanDT\({}^{\ddagger}\)[15] \\  & Spatio-Temporal Forecasting, Interpolation\({}^{\circ}\), & & \\ \cline{2-4}  & Remote Sensing Representation Learning\({}^{\dagger}\), & Cross-Scale MAE\({}^{\dagger}\)[74], Scale-MAE\({}^{\ddagger}\)[66], G\({}^{\ddagger}\)[39], \\  & Image & Location Embedding\({}^{\ddagger}\), Geo-Localization\({}^{\ddagger}\), & SuCLIP\({}^{\ddagger}\)[45], GeoCLIP\({}^{\ddagger}\)[78], CSF\({}^{\ddagger}\)[56] \\  & & Supr-Resolution for Remote Sensing, & \\ \cline{2-4}  & Text & Geo-Language Model\({}^{\dagger}\), Geo-Text Mining\({}^{\ddagger}\), & GeoLLM\({}^{\ddagger}\)[57], K\({}^{\ddagger}\)[25], \({}^{\ddagger}\)[23], \({}^{\ddagger}\)[88, 13] \\ \hline \multirow{4}{*}{**Multi Modality**} & (Spatial)-Time Series + Image & Image-enhanced Spatial\({}^{\dagger}\) / Temporal\({}^{\ddagger}\) Prediction,... & VisionTST\({}^{\ddagger}\)[22], \({}^{\ddagger}\)[73, 49, 19] \\ \cline{2-4}  & (Spatial)-Time Series + Text & LLM-enhanced Spatio-Temporal Forecasting,... & UrbanGPT [50], Time-LLM [41], Promporcast [85] \\ \cline{2-4}  & Image + Text & Urban Region Profiling, Remote Sensing LDMF\({}^{\ddagger}\), & UrbanGPT [56], UrbanGPT\({}^{\ddagger}\)[34], \\ \cline{2-4}  & (Spatial)-Time Series & Weighted Image-Text Retrieval\({}^{\dagger}\), Urban Urban \({}^{\ddagger}\), & EarthGP\({}^{\ddagger}\)[95], UrbanCross\({}^{\ddagger}\)[98] \\ \cline{2-4}  & + Image + Text & Urban Foundation Model\({}^{\ddagger}\),... & UGI\({}^{\ddagger}\)[84], CityGPT\({}^{\ddagger}\)[29], UFM\({}^{\ddagger}\)[96] \\ \hline \end{tabular}
\end{table}
Table 2: Potential application scenarios for Terra dataset. All single modalities can be associated with geo-coordinates.

Figure 6: Global performance comparison.

[MISSING_PAGE_FAIL:8]

**SatCLIP** could be offered more pertinent semantic information for downstream environment-related tasks. Conversely, **CSP** focuses on pretraining location encoders for specific applications, which diminishes its adaptability to new downstream tasks. Overall, these results corroborate the suitability and practical utility of our Terra dataset for environment-related spatial variable prediction, thereby reinforcing its potential for advancing research in spatial-temporal data mining.

#### 4.2.2 Vision-Language based Spatial Variable Prediction

**Problem Definition.** To demonstrate the multimodal nature of the Terra, we follow the recent paradigm of spatial variable prediction based on vision-language pre-training [34, 86], which provides a comprehensive geographic vision of a region through satellite images, and provides an overview of the region's inherent knowledge through text descriptions, thereby enhancing spatial variable prediction. Formally, vision-language based spatial prediction aims to predict \(L\) spatial indicators of \(N\) locations, denoted as \(Y\in\mathbb{R}^{N\times L}\), given visual and textual pairs \(X\in\mathbb{R}^{N\times(I,T)}\) of \(N\) locations.

**Setup.** We follow the same experimental setup as in Sec. 4.2.1. However, in the context of vision-language pre-training, making predictions on a global scale poses significant challenges in terms of computational resources. Thus, similar to Sec. 4.1, we select three representative countries(_USA_, _CN_, _AUS_) for experiments. We select two representative VLP models in the spatio-temporal domain, **UrbanVLP**[34] and **UrbanCLIP**[86], as well as the classic general baseline **CLIP**[63]. Similarly, the dataset is split into training, validation, and test sets in a 7:1:2 ratio, and the performance metrics used for comparison are: coefficient of determination (\(R^{2}\)) and mean squared error (MSE).

**Result Analysis:** Table 5 illustrates the performance of three spatial variable predictions on three countries. Overall, these models demonstrated similar performance to those presented in [34]. The distinct performance of different models effectively highlights the consistency of our dataset. Specifically, the performance trends for each metric vary across the three countries. For example, the USA exhibits relatively poor performance in precipitation prediction, possibly due to its status as the country with the most diverse climate types in the world, which affects precipitation patterns. Conversely, Australia's suboptimal performance in temperature prediction may be attributed to its unusual geographic situation, being surrounded by oceans while having an inland desert climate. Additionally, due to being trained on data from a limited number of countries, the performance is slightly inferior to location-based models, which use pretrained encoders on global-scale datasets.

## 5 Conclusions

This work introduces the Terra, a multimodal spatio-temporal dataset. Terra is a comprehensive dataset encompassing various meteorological data spanning the earth, covering 6,480,000 grid regions over the past 45 years. It includes spatio-temporal observations along with multimodal spatial information such as geo-images and explanatory texts. Based on a thorough introduction of the data and analysis of experimental results, we highlight the significant impact of the Terra dataset on advancing spatio-temporal data mining research and its potential for progressing towards spatio-temporal general intelligence.

\begin{table}
\begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c|c} \hline \multirow{2}{*}{MethodsDatasets} & \multicolumn{3}{c|}{Precipitation} & \multicolumn{3}{c|}{Wind Speed} & \multicolumn{3}{c}{Temperature} \\ \cline{2-13}  & CN & USA & \multicolumn{3}{c|}{USA} & \multicolumn{3}{c|}{CN} & \multicolumn{3}{c|}{USA} & \multicolumn{3}{c|}{SUS} & \multicolumn{3}{c|}{CN} & \multicolumn{3}{c|}{USA} & \multicolumn{3}{c}{AUSU} \\ \hline Metric & \(R^{2}\) & MSE & \(R^{2}\) & MSE & \(R^{2}\) & MSE & \(R^{2}\) & MSE & \(R^{2}\) & MSE & \(R^{2}\) & MSE & \(R^{2}\) & MSE & \(R^{2}\) & MSE & \(R^{2}\) & MSE & \(R^{2}\) & MSE \\ \hline
**CLIP** & 0.483 & 0.537 & 0.359 & 0.631 & 0.321 & 0.683 & 0.587 & 0.429 & 0.519 & 0.483 & 0.266 & 0.731 & 0.454 & 0.575 & 0.422 & 0.178 & 0.992 \\ \hline
**UrbanCLIP** & 0.617 & 0.418 & 0.409 & 0.577 & 0.383 & 0.623 & 0.674 & 0.352 & 0.579 & 0.425 & 0.340 & 0.657 & 0.685 & 0.344 & 0.650 & 0.344 & 0.210 & 0.981 \\ \hline
**UrbanVLP\({}^{*}\)** & **0.745** & **0.279** & **0.589** & **0.402** & **0.680** & **0.323** & **0.747** & **0.244** & **0.750** & **0.252** & **0.591** & **0.407** & **0.791** & **0.228** & **0.802** & **0.195** & **0.352** & **0.804** \\ \hline \end{tabular}
\end{table}
Table 5: Results of Vision-Language based Spatial Variable Prediction. UrbanVLP\({}^{*}\) denotes that we leverage UrbanVLP without its street-view branch. **Red**: the best, **Blue**: the second best.

Figure 7: SatCLIP predicted global-scale precipitation.

## Acknowledgments and Disclosure of Funding

The authors would like to thank the anonymous reviewers for their valuable comments. This work is mainly supported by the National Natural Science Foundation of China (No. 62402414). This work is also supported by the Guangzhou-HKUST(GZ) Joint Funding Program (No. 2024A03J0620), Guangzhou Municipal Science and Technology Project (No. 2023A03J0011), the Guangzhou Industrial Information and Intelligent Key Laboratory Project (No. 2024A03J0628), and a grant from State Key Laboratory of Resources and Environmental Information System, and Guangdong Provincial Key Lab of Integrated Communication, Sensing and Computation for Ubiquitous Internet of Things (No. 2023B1212010007).

## References

* [1] arcegis.com. https://www.arcgis.com/.
* [2] Copernicus Climate Data Store | Copernicus Climate Data Store -- cds.climate.copernicus.eu. https://cds.climate.copernicus.eu.
* [3] ETOPO Global Relief Model -- ncei.noaa.gov. https://www.ncei.noaa.gov/products/etopo-global-relief-model.
* Surbowl/world-geo-json-zh:A simplified world map in GeoJSON format -
- github.com. https://github.com/Surbowl/world-geo-json-zh.
* GloH2O -
- gloh2o.org. https://www.gloh2o.org/.
* [6] Koppen climate classification -- hanschen.org. https://hanschen.org/koppen.
* [7] PyGMT -- pygmt.org. https://www.pygmt.org/latest/index.html.
* [8] Sentinel-2 -- esa.int. https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-2.
* [9] The Generic Mapping Tools -- generic-mapping-tools.org. https://www.generic-mapping-tools.org.
* Wikipedia -
- en.wikipedia.org. https://en.wikipedia.org/wiki/Web_Mercator_projection.
* [11] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat, et al. Gpt-4 technical report. _arXiv preprint arXiv:2303.08774_, 2023.
* [12] A. Alexandrov, K. Benidis, M. Bohlke-Schneider, V. Flunkert, J. Gasthaus, T. Januschowski, D. C. Maddix, S. Rangapuram, D. Salinas, J. Schulz, et al. Gluonts: Probabilistic and neural time series modeling in python. _Journal of Machine Learning Research_, 21(116):1-6, 2020.
* [13] M. Alkathiri, J. Abdul, and M. Potdar. Geo-spatial big data mining techniques. _International Journal of Computer Applications_, 135(11):28-36, 2016.
* [14] B. Alkhamissi, M. Li, A. Celikyilmaz, M. Diab, and M. Ghazvininejad. A review on language models as knowledge bases. _arXiv preprint arXiv:2204.06031_, 2022.
* [15] Anonymous. Urbandit: A foundation model for open-world urban spatio-temporal learning. In _The Thirteenth International Conference on Learning Representations_, 2025.
* [16] G. Atluri, A. Karpatne, and V. Kumar. Spatio-temporal data mining: A survey of problems and methods. _ACM Computing Surveys (CSUR)_, 51(4):1-41, 2018.
* [17] K. Bi, L. Xie, H. Zhang, X. Chen, X. Gu, and Q. Tian. Accurate medium-range global weather forecasting with 3d neural networks. _Nature_, 619(7970):533-538, 2023.
* [18] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von Arx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill, et al. On the opportunities and risks of foundation models. _arXiv preprint arXiv:2108.07258_, 2021.

* [19] M. A. Bourassa, T. Meissner, I. Cerovecki, P. S. Chang, X. Dong, G. De Chiara, C. Donlon, D. S. Dukhovskoy, J. Elya, A. Fore, et al. Remotely sensed winds and wind stresses for marine forecasting and ocean modeling. _Frontiers in Marine Science_, 6:437064, 2019.
* [20] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners. _Advances in neural information processing systems_, 33:1877-1901, 2020.
* [21] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg, et al. Sparks of artificial general intelligence: Early experiments with gpt-4. _arXiv preprint arXiv:2303.12712_, 2023.
* [22] M. Chen, L. Shen, Z. Li, X. J. Wang, J. Sun, and C. Liu. Visionts: Visual masked autoencoders are free-lunch zero-shot time series forecasters. _arXiv preprint arXiv:2408.17253_, 2024.
* [23] W. Chen, S. Li, C. Huang, Y. Yu, Y. Jiang, and Y. Dong. Mutual distillation learning network for trajectory-user linking. In _Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence_, 2022.
* [24] Y. Cui, J. Xie, and K. Zheng. Historical inertia: A neglected but powerful baseline for long sequence time-series forecasting. In _Proceedings of the 30th ACM international conference on information & knowledge management_, pages 2965-2969, 2021.
* [25] C. Deng, T. Zhang, Z. He, Q. Chen, Y. Shi, Y. Xu, L. Fu, W. Zhang, X. Wang, C. Zhou, et al. K2: A foundation language model for geoscience knowledge understanding and utilization. In _Proceedings of the 17th ACM International Conference on Web Search and Data Mining_, pages 161-170, 2024.
* [26] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In _2009 IEEE conference on computer vision and pattern recognition_, pages 248-255. Ieee, 2009.
* [27] M. Drusch, U. Del Bello, S. Carlier, O. Colin, V. Fernandez, F. Gascon, B. Hoersch, C. Isola, P. Laberini, P. Martimort, et al. Sentinel-2: Esa's optical high-resolution mission for gmes operational services. _Remote sensing of Environment_, 120:25-36, 2012.
* [28] P. Emami, Z. Li, S. Sinha, and T. Nguyen. Syscaps: Language interfaces for simulation surrogates of complex systems. _arXiv preprint arXiv:2405.19653_, 2024.
* [29] J. Feng, Y. Du, T. Liu, S. Guo, Y. Lin, and Y. Li. Citygpt: Empowering urban spatial cognition of large language models. _arXiv preprint arXiv:2406.13948_, 2024.
* [30] N. Gao, H. Xue, W. Shao, S. Zhao, K. K. Qin, A. Prabowo, M. S. Rahaman, and F. D. Salim. Generative adversarial networks for spatio-temporal data: A survey. _ACM Transactions on Intelligent Systems and Technology (TIST)_, 13(2):1-25, 2022.
* [31] R. Geetha, N. Sumathi, S. Sathiyabama, and T. T. Tiruchengode. A survey of spatial, temporal and spatio-temporal data mining. _journal of computer applications_, 1(4):31-33, 2008.
* [32] N. Gorelick, M. Hancher, M. Dixon, S. Ilyushchenko, D. Thau, and R. Moore. Google earth engine: Planetary-scale geospatial analysis for everyone. _Remote sensing of Environment_, 202:18-27, 2017.
* [33] M. Haberle, M. Werner, and X. X. Zhu. Geo-spatial text-mining from twitter-a feature space analysis with a view toward building classification in urban regions. _European journal of remote sensing_, 52(sup2):2-11, 2019.
* [34] X. Hao, W. Chen, Y. Yan, S. Zhong, K. Wang, Q. Wen, and Y. Liang. Urbanvlp: A multi-granularity vision-language pre-trained foundation model for urban indicator prediction. _arXiv preprint arXiv:2403.16831_, 2024.
* [35] K. He, X. Chen, S. Xie, Y. Li, P. Dollar, and R. Girshick. Masked autoencoders are scalable vision learners. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 16000-16009, 2022.

* [36] T. He, J. Bao, R. Li, S. Ruan, Y. Li, C. Tian, and Y. Zheng. Detecting vehicle illegal parking events using sharing bikes' trajectories. In _Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_, pages 340-349, 2018.
* [37] M. Hino, E. Benami, and N. Brooks. Machine learning for environmental monitoring. _Nature Sustainability_, 1(10):583-588, 2018.
* [38] L. Huang, W. Yu, W. Ma, W. Zhong, Z. Feng, H. Wang, Q. Chen, W. Peng, X. Feng, B. Qin, et al. A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. _arXiv preprint arXiv:2311.05232_, 2023.
* [39] P. Jia, Y. Liu, X. Li, X. Zhao, Y. Wang, Y. Du, X. Han, X. Wei, S. Wang, and D. Yin. G3: An effective and adaptive framework for worldwide geolocalization using large multi-modality models. _arXiv preprint arXiv:2405.14702_, 2024.
* [40] G. Jin, Y. Liang, Y. Fang, Z. Shao, J. Huang, J. Zhang, and Y. Zheng. Spatio-temporal graph neural networks for predictive learning in urban computing: A survey. _IEEE Transactions on Knowledge and Data Engineering_, 2023.
* [41] M. Jin, S. Wang, L. Ma, Z. Chu, J. Y. Zhang, X. Shi, P.-Y. Chen, Y. Liang, Y.-F. Li, S. Pan, et al. Time-llm: Time series forecasting by reprogramming large language models. _arXiv preprint arXiv:2310.01728_, 2023.
* [42] M. Jin, Y. Zhang, W. Chen, K. Zhang, Y. Liang, B. Yang, J. Wang, S. Pan, and Q. Wen. Position paper: What can large language models tell us about time series analysis. _arXiv preprint arXiv:2402.02713_, 2024.
* [43] J. Kaltenborn, C. Lange, V. Ramesh, P. Brouillard, Y. Gurwicz, C. Nagda, J. Runge, P. Nowack, and D. Rolnick. Climateset: A large-scale climate model dataset for machine learning. _Advances in Neural Information Processing Systems_, 36:21757-21792, 2023.
* [44] A. Kitamoto, J. Hwang, B. Vuillod, L. Gautier, Y. Tian, and T. Clanuwat. Digital typhoon: Long-term satellite image dataset for the spatio-temporal modeling of tropical cyclones. _Advances in Neural Information Processing Systems_, 36, 2024.
* [45] K. Klemmer, E. Rolf, C. Robinson, L. Mackey, and M. Russwurm. Satchip: Global, general-purpose location embeddings with satellite imagery. _arXiv preprint arXiv:2311.17179_, 2023.
* [46] S. Kondylatos, I. Prapas, G. Camps-Valls, and I. Papoutsis. Mesogeos: A multi-purpose dataset for data-driven wildfire modeling in the mediterranean. _Advances in Neural Information Processing Systems_, 36, 2024.
* [47] A. Lacoste, N. Lehmann, P. Rodriguez, E. Sherwin, H. Kerner, B. Lutjens, J. Irvin, D. Dao, H. Alemohammad, A. Drouin, et al. Geo-bench: Toward foundation models for earth monitoring. _Advances in Neural Information Processing Systems_, 36, 2023.
* [48] R. Lam, A. Sanchez-Gonzalez, M. Willson, P. Wirnsberger, M. Fortunato, F. Alet, S. Ravuri, T. Ewalds, Z. Eaton-Rosen, W. Hu, et al. Learning skillful medium-range global weather forecasting. _Science_, 382(6677):1416-1421, 2023.
* [49] L. Li and Y. Zha. Estimating monthly average temperature by remote sensing in china. _Advances in Space Research_, 63(8):2345-2357, 2019.
* [50] Z. Li, L. Xia, J. Tang, Y. Xu, L. Shi, L. Xia, D. Yin, and C. Huang. Urbangpt: Spatio-temporal large language models. In _Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, pages 5351-5362, 2024.
* [51] Z. Li, L. Xia, Y. Xu, and C. Huang. Gpt-st: Generative pre-training of spatio-temporal graph neural networks. _Advances in Neural Information Processing Systems_, 36, 2024.
* [52] Y. Liang, H. Wen, Y. Nie, Y. Jiang, M. Jin, D. Song, S. Pan, and Q. Wen. Foundation models for time series analysis: A tutorial and survey. _arXiv preprint arXiv:2403.14735_, 2024.

* [53] Y. Liang, Y. Xia, S. Ke, Y. Wang, Q. Wen, J. Zhang, Y. Zheng, and R. Zimmermann. Airformer: Predicting nationwide air quality in china with transformers. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 37, pages 14329-14337, 2023.
* [54] H. Liu, Z. Dong, R. Jiang, J. Deng, J. Deng, Q. Chen, and X. Song. Spatio-temporal adaptive embedding makes vanilla transformer sota for traffic forecasting. In _Proceedings of the 32nd ACM international conference on information and knowledge management_, pages 4125-4129, 2023.
* [55] Y. Luo, Q. Liu, and Z. Liu. Stan: Spatio-temporal attention network for next location recommendation. In _Proceedings of the web conference 2021_, pages 2177-2185, 2021.
* [56] G. Mai, N. Lao, Y. He, J. Song, and S. Ermon. Csp: Self-supervised contrastive spatial pre-training for geospatial-visual representations. In _International Conference on Machine Learning_, pages 23498-23515. PMLR, 2023.
* [57] R. Manvi, S. Khanna, G. Mai, M. Burke, D. Lobell, and S. Ermon. Geollm: Extracting geospatial knowledge from large language models. _arXiv preprint arXiv:2310.06213_, 2023.
* [58] A. Meta. Introducing meta llama 3: The most capable openly available llm to date. _Meta AI._, 2024.
* [59] A. Nascetti, R. Yadav, K. Brodt, Q. Qu, H. Fan, Y. Shendryk, I. Shah, and C. Chung. Biomassters: A benchmark dataset for forest biomass estimation using multi-modal satellite time-series. _Advances in Neural Information Processing Systems_, 36, 2024.
* [60] Y. Nie, N. H. Nguyen, P. Sinthong, and J. Kalagnanam. A time series is worth 64 words: Long-term forecasting with transformers. In _The Eleventh International Conference on Learning Representations_, 2022.
* [61] A. Nippani, D. Li, H. Ju, H. Koutsopoulos, and H. Zhang. Graph neural networks for road safety modeling: Datasets and evaluations for accident analysis. _Advances in Neural Information Processing Systems_, 36, 2024.
* [62] S. Oprea, P. Martinez-Gonzalez, A. Garcia-Garcia, J. A. Castro-Vargas, S. Orts-Escolano, J. Garcia-Rodriguez, and A. Argyros. A review on deep learning techniques for video prediction. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 44(6):2806-2826, 2020.
* [63] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, et al. Learning transferable visual models from natural language supervision. In _International conference on machine learning_, pages 8748-8763. PMLR, 2021.
* [64] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. _Journal of machine learning research_, 21(140):1-67, 2020.
* [65] S. Ravuri, K. Lenc, M. Willson, D. Kangin, R. Lam, P. Mirowski, M. Fitzsimons, M. Athanasiadou, S. Kashem, S. Madge, et al. Skifful precipitation nowcasting using deep generative models of radar. _Nature_, 597(7878):672-677, 2021.
* [66] C. J. Reed, R. Gupta, S. Li, S. Brockman, C. Funk, B. Clipp, K. Keutzer, S. Candido, M. Uyttendaele, and T. Darrell. Scale-mae: A scale-aware masked autoencoder for multiscale geospatial representation learning. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 4088-4099, 2023.
* [67] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer. High-resolution image synthesis with latent diffusion models. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 10684-10695, 2022.
* [68] C. Scheele, M. Yu, and Q. Huang. Geographic context-aware text mining: Enhance social media message classification for situational awareness by integrating spatial and temporal features. _International Journal of Digital Earth_, 14(11):1721-1743, 2021.

* [69] Z. Shao, F. Wang, Y. Xu, W. Wei, C. Yu, Z. Zhang, D. Yao, G. Jin, X. Cao, G. Cong, et al. Exploring progress in multivariate time series forecasting: Comprehensive benchmarking and heterogeneity analysis. _arXiv preprint arXiv:2310.06119_, 2023.
* [70] Z. Shao, Z. Zhang, F. Wang, W. Wei, and Y. Xu. Spatial-temporal identity: A simple yet effective baseline for multivariate time series forecasting. In _Proceedings of the 31st ACM International Conference on Information & Knowledge Management_, pages 4454-4458, 2022.
* [71] X. Shi, Z. Chen, H. Wang, D.-Y. Yeung, W.-K. Wong, and W.-c. Woo. Convolutional lstm network: A machine learning approach for precipitation nowcasting. _Advances in neural information processing systems_, 28, 2015.
* [72] C. Song, Y. Lin, S. Guo, and H. Wan. Spatial-temporal synchronous graph convolutional networks: A new framework for spatial-temporal network data forecasting. In _Proceedings of the AAAI conference on artificial intelligence_, volume 34, pages 914-921, 2020.
* [73] D. Stampoulis, H. Damavandi, D. Boscovic, and J. Sabo. Using satellite remote sensing and machine learning techniques towards precipitation prediction and vegetation classification. _Journal of Environmental Informatics_, 37(1):1-15, 2021.
* [74] M. Tang, A. Cozma, K. Georgiou, and H. Qi. Cross-scale mae: A tale of multiscale exploitation in remote sensing. _Advances in Neural Information Processing Systems_, 36, 2024.
* [75] A. Telenti, A. Arvin, L. Corey, D. Corti, M. S. Diamond, A. Garcia-Sastre, R. F. Garry, E. C. Holmes, P. S. Pang, and H. W. Virgin. After the pandemic: perspectives on the future trajectory of covid-19. _Nature_, 596(7873):495-504, 2021.
* [76] W. Thiery, S. Lange, J. Rogelj, C.-F. Schleussner, L. Gudmundsson, S. I. Seneviratne, M. Andrijevic, K. Frieler, K. Emanuel, T. Geiger, et al. Intergenerational inequities in exposure to climate extremes. _Science_, 374(6564):158-160, 2021.
* [77] M. Veillette, S. Samsi, and C. Mattioli. Sevir: A storm event imagery dataset for deep learning applications in radar and satellite meteorology. _Advances in Neural Information Processing Systems_, 33:22009-22019, 2020.
* [78] V. Vivanco Cepeda, G. K. Nayak, and M. Shah. Geoclip: Clip-inspired alignment between locations and images for effective worldwide geo-localization. In _Advances in Neural Information Processing Systems_, volume 36, pages 8690-8701, 2023.
* [79] S. Wang, J. Cao, and S. Y. Philip. Deep learning for spatio-temporal data mining: A survey. _IEEE transactions on knowledge and data engineering_, 34(8):3681-3700, 2020.
* [80] C. K. Wikle, A. Zammit-Mangion, and N. Cressie. _Spatio-temporal statistics with R_. Chapman and Hall/CRC, 2019.
* [81] G. Woo, C. Liu, A. Kumar, C. Xiong, S. Savarese, and D. Sahoo. Unified training of universal time series forecasting transformers. _arXiv preprint arXiv:2402.02592_, 2024.
* [82] H. Wu, T. Hu, Y. Liu, H. Zhou, J. Wang, and M. Long. Timesnet: Temporal 2d-variation modeling for general time series analysis. In _The eleventh international conference on learning representations_, 2022.
* [83] Z. Wu, S. Pan, G. Long, J. Jiang, and C. Zhang. Graph wavenet for deep spatial-temporal graph modeling. In _Proceedings of the 28th International Joint Conference on Artificial Intelligence_, pages 1907-1913, 2019.
* [84] F. Xu, J. Zhang, C. Gao, J. Feng, and Y. Li. Urban generative intelligence (ugi): A foundational platform for agents in embodied city environment. _arXiv preprint arXiv:2312.11813_, 2023.
* [85] H. Xue and F. D. Salim. Promptcast: A new prompt-based learning paradigm for time series forecasting. _IEEE Transactions on Knowledge and Data Engineering_, 2023.

* [86] Y. Yan, H. Wen, S. Zhong, W. Chen, H. Chen, Q. Wen, R. Zimmermann, and Y. Liang. Urbanclip: Learning text-enhanced urban region profiling with contrastive language-image pretraining from the web. In _Proceedings of the ACM on Web Conference 2024_, pages 4006-4017, 2024.
* [87] Y. Yang, M. Jin, H. Wen, C. Zhang, Y. Liang, L. Ma, Y. Wang, C. Liu, B. Yang, Z. Xu, et al. A survey on diffusion models for time series and spatio-temporal data. _arXiv preprint arXiv:2404.18886_, 2024.
* [88] H. Yao, X. Tang, H. Wei, G. Zheng, and Z. Li. Revisiting spatial-temporal similarity: A deep learning framework for traffic prediction. In _Proceedings of the AAAI conference on artificial intelligence_, volume 33, pages 5668-5675, 2019.
* [89] B. Yu, H. Yin, and Z. Zhu. Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting. In _Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence_. International Joint Conferences on Artificial Intelligence Organization, 2018.
* [90] S. Yu, W. Hannah, L. Peng, J. Lin, M. A. Bhouri, R. Gupta, B. Lutjens, J. C. Will, G. Behrens, J. Busecke, et al. Climsim: A large multi-scale dataset for hybrid physics-ml climate emulation. _Advances in Neural Information Processing Systems_, 36, 2024.
* [91] Z. Yuan, Z. Xiong, L. Mou, and X. X. Zhu. Chatearthnet: A global-scale, high-quality image-text dataset for remote sensing. _arXiv preprint arXiv:2402.11325_, 2024.
* [92] A. Zeng, M. Chen, L. Zhang, and Q. Xu. Are transformers effective for time series forecasting? In _Proceedings of the AAAI conference on artificial intelligence_, volume 37, pages 11121-11128, 2023.
* [93] J. Zhang, Y. Zheng, and D. Qi. Deep spatio-temporal residual networks for citywide crowd flows prediction. In _Proceedings of the AAAI conference on artificial intelligence_, volume 31, 2017.
* [94] Q. Zhang, H. Wang, C. Long, L. Su, X. He, J. Chang, T. Wu, H. Yin, S.-M. Yiu, Q. Tian, et al. A survey of generative techniques for spatial-temporal data mining. _arXiv preprint arXiv:2405.09592_, 2024.
* [95] W. Zhang, M. Cai, T. Zhang, Y. Zhuang, and X. Mao. Earthgpt: A universal multi-modal large language model for multi-sensor image comprehension in remote sensing domain. _arXiv preprint arXiv:2401.16822_, 2024.
* [96] W. Zhang, J. Han, Z. Xu, H. Ni, H. Liu, and H. Xiong. Towards urban general intelligence: A review and outlook of urban foundation models. _arXiv preprint arXiv:2402.01749_, 2024.
* [97] Y. Zheng, X. Xie, W.-Y. Ma, et al. Geolife: A collaborative social networking service among user, location and trajectory. _IEEE Data Eng. Bull._, 33(2):32-39, 2010.
* [98] S. Zhong, X. Hao, Y. Yan, Y. Zhang, Y. Song, and Y. Liang. Urbancross: Enhancing satellite image-text retrieval with cross-domain adaptation. _arXiv preprint arXiv:2404.14241_, 2024.
* [99] T. Zhou, Z. Ma, Q. Wen, X. Wang, L. Sun, and R. Jin. Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting. In _International conference on machine learning_, pages 27268-27286. PMLR, 2022.
* [100] X. Zou, Y. Yan, X. Hao, Y. Hu, H. Wen, E. Liu, J. Zhang, Y. Li, T. Li, Y. Zheng, et al. Deep learning for cross-domain data fusion in urban computing: Taxonomy, advances, and outlook. _arXiv preprint arXiv:2402.19348_, 2024.

## Supplementary Material

Terra: A Multimodal Spatio-Temporal Dataset

Spanning the Earth

## Appendix A More Dataset Details

### Data Composition and Statistics

### Data Visualization and Analysis

### Discussion of LLM-Derived Text Description

### Data Statements and Accountability

### More Experimental Details

### Training Resources & Code Implementation

### Spatio-Temporal Analysis Experiment

### Spatial Analysis Experiment

### More Discussion
More Dataset Details

We provide a comprehensive supplementary introduction to the Terra dataset in this section, covering data composition, statistics, visualization and analysis. Moreover, We also discuss the risks existing in the text descriptions derived from LLM and the rationality of our solutions. Lastly, We conclude by presenting statements on data availability and access links.

### Data Composition and Statistics

After completing the entire process of acquiring and cleaning time series data from different sources, we further resample the data to obtain time series data of different temporal and spatial resolutions. For each spatial unit area at different spatial resolutions, we also supplement them with other meta text elements, generated text knowledge, geo-images, and remote sensing images in a multimodal context. This section provides a detailed description of the various data types contained in each spatial unit of the dataset, their structure, and key attributes, ensuring a comprehensive understanding of the content of the dataset and its potential applications.

**Time Series.** Our dataset is structured based on spatial resolution, with initial directories containing data at 1\({}^{\circ}\) / 0.5\({}^{\circ}\) / 0.1\({}^{\circ}\) resolutions. The 1\({}^{\circ}\) and 0.5\({}^{\circ}\) resolutions are obtained by downsampling 0.1\({}^{\circ}\) data by a factor of 10 and 5, respectively. For the time series data within each spatial resolution directory, we further categorize them into subdirectories based on temporal resolution, including monthly / daily / 3 hourly data. The monthly and daily data are obtained by downsampling the 3 hourly data by a factor of 8 and 8 times the number of days in a month (28-31 days). Specifically, under each temporal resolution, there are usually 8 sub-files, each recording climate index values from 00:00 on January 1, 1979, to 00:00 on January 1, 2024 (inclusive start, exclusive end), spanning 45 years. These files contain data on precipitation, air temperature, surface pressure, relative and specific humidity, wind speed, and downward shortwave and longwave radiation. Note that for individual sub-files that take up a large amount of storage, we will split them into multiple files based on the year. The complete folder directory and the contents of a single file are shown in Figure 8, where each file under the subdirectory is stored in.csv format, and the shape is summarized in Table 6.

\begin{table}
\begin{tabular}{c|c|c|c} \hline \multirow{2}{*}{**Temporal**} & \multirow{2}{*}{**Spatial**} & \multicolumn{2}{c}{**Spatial Resolution**} \\ \cline{3-4}  & & 0.1\({}^{\circ}\) & 0.5\({}^{\circ}\) & 1\({}^{\circ}\) \\ \hline \multirow{3}{*}{**Temporal**} & 3 Hourly & [131488, 6480000] & [131488, 259200] & [131488, 64800] \\ \cline{2-4}  & Daily & [16436, 6480000] & [16436, 259200] & [16436, 64800] \\ \cline{1-1} \cline{2-4}  & Monthly & [540, 6480000] & [540, 259200] & [540, 64800] \\ \hline \end{tabular}
\end{table}
Table 6: Shape of a single file at different spatial and temporal resolutions.

Figure 8: Example of folder structure and file contents for time series modality.

**Text.** As mentioned in the previous section, our text dataset also includes initial directories at different spatial resolutions. Due to the significant time and cost involved, we currently only provide text modal information at 1\({}^{\circ}\) and 0.5\({}^{\circ}\) spatial resolutions. For the text data at each spatial resolution, we provide two types of text description files. The first type of description file is meta-text data. We crawl the corresponding spatial unit area metadata for the project as introduced in the main body, including latitude and longitude ranges, countries, land types, climate conditions, and average elevation, organized and stored together in a _txt_ file. The file name is named after the upper left

\begin{table}
\begin{tabular}{c|c|c|c} \hline \hline
**Meta Name** & **Processing** & **Raw Information** & **Area** \\ \hline Range & Split Segment & \([-90\sim+90]\,\mathrm{S}\,\mathrm{/}\,\mathrm{N}\), & Global \\ \cline{3-4}  & & \begin{tabular}{c} Afghanistan, Antarctica, Andorra \\ \(-[180\sim+180]\,\mathrm{W}\,\mathrm{/}\,\mathrm{E}\) \\ \end{tabular} & \begin{tabular}{c} Global \\ \end{tabular} \\ \hline Country & Index Search & \begin{tabular}{c} Afghanistan, Antarctica, Andorra \\ \(-[8775.47\sim+5371.13]\,\mathrm{m}\mathrm{m}\mathrm{m}\mathrm{m}\mathrm{m}\mathrm{m}\mathrm{m}\mathrm{m}\mathrm{m}\mathrm{m}\mathrm{m}\mathrm{m}\mathrm{m}\mathrm{m}\) \\ \end{tabular} & Global \\ \hline Mean Elevation & Calculate Average & \begin{tabular}{c} \(\sim\) \\ \end{tabular} & Global \\ \hline Land Vegetation & Proportional Allocation & \begin{tabular}{c} no\_data, cropland\_rainted, cropland\_rainted, herbaceous\_cover, \\ cropland\_rainted\_tree,\_dr\_whub\_cover, cropland\_irigated, \\ mosaic\_cropland, mosaic\_natural\_vegetation, \\ tree\_broadleaved\_covergreen\_closed\_to\_open, \\ tree\_broadleaved\_deciduous\_closed, \\ tree\_broadleaved\_deciduous\_closed, \\ tree\_broadleaved\_deciduous\_open, \\ tree\_needleaved\_evergreen\_closed, \\ tree\_needleaved\_evergreen\_open, \\ tree\_needleaved\_evergreen\_open, \\ tree\_needleaved\_deciduous\_closed, \\ tree\_needleaved\_deciduous\_open, \\ tree\_needleaved\_deciduous\_open, \\ tree\_mixed\_mosaic\_rebaceous\_strubal\_strubal\_vergreen, \\ tree\_broalleaved\_deciduous\_open, \\ tree\_broalleaved\_deciduous\_open, \\ tree\_mixed\_mosaic\_tree\_and\_shrub\_ch\_ch\_ \\ mosaic\_herbaceous\_strubal, shrubland\_evergreen, \\ shrubland\_dediculous\_grass\_tree, \_sparse\_shrub\_s, \\ sparse\_herbaceous\_tree\_cover\_flood\_fresh\_or\_b\_drashish\_water, \\ tree\_cover\_flood\_saline\_water, \\ shrub\_or\_herbaceous\_cover\_flooded\_urban\_bare\_areas, bare\_areas\_consolidated, \\ bare\_areas\_unconsolidated\_water, snow\_and\_ice \\ \hline Climate & Proportional Allocation & \begin{tabular}{c} Tropical rain forest, Tropical monososons, \\ Tropical savanna with dry summer, \\ Deepstral (arid), \\ Mild temperate with dry summer, \\ Mild temperate with dry winter, \\ Mild temperate, fully humid, \\ Snow with dry summer, \\ Snow, fully humid, \\ \end{tabular} & 
\begin{tabular}{c} Mainland \\ \end{tabular} \\ \hline \hline \end{tabular}
\end{table}
Table 7: Processing methods and raw information of the meta text.

Figure 9: Example of folder structure and file contents for text modality.

corner latitude and longitude of the unit area (for example, the file for the 22-23N, 112-113E grid area is named _meta_23N_112E.txt_). The specific processing methods and original information for all categories in the meta text are shown in Table 7. The second type of description file is LLM-derived text description. Similarly, for each unit spatial area, we use the spatial cue engineering technology introduced in the text and generate climate description information for each grid area using the latest open-source LLM model LLama3, storing the content in a _.txt_ file (the file for the same area grid is named _llm_23N_112E.txt_). The complete folder directory and the contents of a single text modality file are shown in Figure 9.

**Image.** Similarly, our image dataset is also contained in initial directories with different spatial resolutions. Due to significant time and cost constraints, we currently provide modal information images at 1\({}^{\circ}\) and 0.5\({}^{\circ}\) spatial resolutions. The image data provides descriptions of both overall and detailed aspects of all spatial regions. For each spatial resolution, we offer various types of image information. Specifically, as described in the text, there are seven main categories of images, namely the geoid area map, spatial error area map, lithosphere magnetic field area map, hydrological area map, topography area map, and gravity geological area map, along with the satellite remote sensing area map. The first six can be considered as geo-image categories, primarily describing inherent properties of the Earth's terrain, topography, land, and sea. The last one is classified as a remote sensing image category, mainly used to describe overall regional geographical information. Different types of image folders are named sequentially as (_img_geoid_, _img_faa_, _img_ma_, _img_mask_, _img_relief_, _img_vgg_, _img_satellite_), and for each type, individual spatial region images are named based on the upper left corner's longitude and latitude (for example, the relief map for the 19-20N, 109-110E grid is named _relief_20N_109E.png_). The complete folder directory and the contents of a single image modality file are shown in Figure 10. Due to the adoption of the Mercator projection, distortions are unavoidable for images in the polar regions; therefore, we disregard high latitude areas in the Arctic and Antarctic circles. Additionally, for the _img_mask_ files, completely oceanic and completely terrestrial regions cannot be projected as image types, so they are omitted. The summary of all file types, areas, and levels is presented in Table 8.

\begin{table}
\begin{tabular}{c|c|c|c|c} \hline \hline
**Image Name** & **Type** & **Area** & **Level** & **Source time** \\ \hline img\_geoid & geo-image & \([-80\sim+80\) S/ N, \([-180\sim+180]\) W/ E & Code: 01m & 2008 \\ \hline img\_faa & geo-image & \([-80\sim+80\) S/ N, \([-180\sim+180]\) W/ E & Code: 01m & 2019 \\ \hline img\_ma & geo-image & \([-80\sim+80\) S/ N, \([-180\sim+180]\) W/ E & Code: 02m & 1946-2014 \\ \hline img\_mask & geo-image & \([-80\sim+80\) S/ N, \([-180\sim+180]\) W/ E & Code: 15s & - \\ \hline img\_relief & geo-image & \([-80\sim+80\) S/ N, \([-180\sim+180]\) W/ E & Code: 01s & 2019 \\ \hline img\_vgg & geo-image & \([-80\sim+80\) S/ N, \([-180\sim+180]\) W/ E & Code: 01m & 2019 \\ \hline img\_satellite & satellite-image & \([-85\sim+85]\) S/ N, \([-180\sim+180]\) W/ E & Zoom: 10 / 11 & 2023-2024 \\ \hline \hline \end{tabular}
\end{table}
Table 8: Basic information about different image.

Figure 10: Example of folder structure and file contents for image modality.

### Data Visualization and Analysis

We further selected representative regions used in the experiment and visualized some modal data metadata corresponding to them, aiming to provide local intuitive insights.

**Time Series.** As shown in Figure 11, we randomly selected precipitation time series data from three spatial regions and aligned them for visualization. The first column displays the precipitation variations in these three spatial regions over more than 20 years. Among them, Grid 98 and Grid 99 are geographically adjacent, while Grid 3 is geographically distant from the other two grids. It can be observed that the precipitation amounts in Grids 98 and 99 exhibit similar patterns of change, reflecting spatial correlation. In contrast, Grid 3 shows a distinctly different precipitation pattern compared to the other two grids, indicating spatial heterogeneity. Further Seasonal and Trend decomposition using Loess (STL) of the precipitation time series data for each spatial region reveals similar observations in terms of trend, seasonality, and residuals.

**Text.** Figure 5 presents statistics and visual insights of the selected LLM text modality data. As we can observe, the text length predominantly centers around 200, which is longer than that found in current state-of-the-art datasets such as ChatEarthNet dataset [91], whose highest frequency distribution occurs at 155 (for texts generated by GPT-3.5). Our most common content words are primarily related to geography, environment, and climate, reflecting the consistency between the text content and the thematic focus of the Terra dataset.

Figure 11: Statistical and visual insights of time series modality data.

Figure 12: Land type frequency diagram.

**Image.** Due to the difficulty of direct image visualization, we use metadata on land types and climate types as proxy labels for spatial area images. Specifically, we select the predominant land or climate type in the current spatial area as the true label. As shown in Figure 12, we first visualize global surface types. It is well known that oceans cover approximately 71% of the Earth's surface area, which aligns with our visualization finding that water has the highest frequency. As illustrated in Figure 13, we further visualize the climate type proportions for all regions. It is evident that polar frost and snow climates, as well as snow, fully humid and cool summer have the highest proportions. In contrast, temperate climates with dry summers and cool summers, and temperate climates with dry winters and cool summers, have the lowest proportions.

### Discussion of LLM-Derived Text Description

In this section, we further discuss the technology of LLM-derived text description. Specifically, we first analyze the spatial prompt engineering strategy and rationality we designed, and then compare the impact of different open source LLMs on the quality of text descriptions.

**The Suitability of Current Text Data.** The text generation methods of LLMs are promising; however, it remains unclear to what extent the text generated by LLMs is reliable, even with the use of metadata. One suggested approach for quantification is to extract text embeddings from the generated text, using either the LLM itself or BERT, and then train a multi-class classifier or regressor on these embeddings to predict each metadata attribute present in the txt metadata file. The accuracy of the classifier serves as a rough proxy for the illusion rate of each attribute (the frequency at which the LLM omits or incorrectly alters attributes). We refer to paper [28] to calculate the illusion rate of the generated text. Due to the diversity of metadata, we simultaneously train both a regressor and a classifier. For the regression task, we predict the elevation and latitude/longitude coordinates of the current area. For the classification task, we identify the dominant land vegetation type in the region. Additionally, we choose BERT as the backbone encoder. The dataset is split in a 7:1:2 ratio. Table 9 presents the NRMSE and accuracy metrics for several text regions used in this study. The experimental results indicate that our spatial prompting engineering approach achieves approximately 70% retention and success rates, effectively mitigating the illusion problem to some extent.

\begin{table}
\begin{tabular}{c|c|c} \hline \hline Country & NRMSE & Accuracy \\ \hline USA & 0.0519 & 0.764 \\ \hline AUS & 0.056 & 0.724 \\ \hline SA & 0.0705 & 0.696 \\ \hline \hline \end{tabular}
\end{table}
Table 9: The Suitability study of experimental text data

Figure 13: Climate type proportion diagram.

The necessity of Spatial Prompt Engineering.As shown in Figure 14, here we provide an illustration example of comparison of generated text with prompt with meta data and without meta data. As observed, the absence of metadata can cause large language models (LLMs) to experience hallucinations, resulting in factual inaccuracies, generalized climate descriptions, erroneous terrain depictions, and incomplete vegetation information. Conversely, the provision of precise metadata can effectively steer LLMs towards generating accurate and detailed descriptions.

**The impact of different LLM choices.** We compare four common popular large language models, including the open-source language models LLaMA3-8B, Vicuna-13b, Gemini-1.5 Pro, and the closed-source language model GPT3.5, as shown in a simple comparison example in Figure 15. Among them, LLaMA3-8B and GPT3.5 have achieved similarly excellent results. Compared to other open-source large language models, LLaMA3-8B can generate more accurate descriptions of climate types and provide more detailed subdivisions of various components, which has been confirmed by numerical data. In addition, the acceptable performance of other models also proves the effectiveness of our prompts, highlighting the potential of using LLM to extract and elucidate compressed geographical spatial knowledge.

Figure 14: Comparison of generated text with prompt with meta data and without meta data.

Figure 15: Comparison of generated text with different LLMs.

### Data Statements and Accountability.

The code and data used for the experiment can be accessed in the repository https://github.com/CityMind-Lab/NeurIPS24-Terra. The official dataset will be hosted on the Hugging Face repository https://huggingface.co/datasets/onedean/Terra. Our code and dataset follow the CC BY-NC 4.0 International License. All authors confirm the data license and commit that the dataset will only be used for academic research.

## Appendix B More Experimental Details

### Training Resources & Code Implementation.

Our running environment consists of a Linux server equipped with a \(2\times\) AMD EPYC 7763 128-Core Processor CPU (512GB memory) and \(8\times\) NVIDIA RTX A6000 (48GB memory) GPUs. To carry out benchmark testing experiments, all baselines are set to run for a duration of 24 hours by default, with specific timings contingent upon the method.

### Spatio-Temporal Analysis Experiment

**Detail Datasets.** As shown in Table 10, we provide the statistical information of the datasets used in this experiment. Five representative countries were selected from the five continents around the world. However, since we directly used rectangles to cover the selected countries, the area covered may exceed the actual country area, or miss areas outside the main continent (such as Alaska State in the USA). Below are the specific ranges of different countries and basic geographical information introductions. To further illustrate, we give an intuitive visualization as shown in Figure 16.

**Detail Baselines.** The essence of spatio-temporal forecasting lies in predicting the time series of multiple spatial regions, thus the available method choices include time series forecasting and spatio-temporal forecasting methods. In addition, we also include models specifically designed for precipitation prediction and the traditional HI method. Below is a brief introduction to each method:

* TimesNet [82]: This paper presents a novel time series forecasting model that consistently achieves state-of-the-art performance in various time series analysis tasks by capturing the multi-periodicity and complex variations of time series through the transformation of one-dimensional time series into two-dimensional tensors.
* FEDformer [99]: The paper introduces a Transformer model that combines seasonal trend decomposition and frequency enhancement for long-term time series forecasting, improving the efficiency and accuracy of predictions by applying the Transformer in the frequency domain.

Figure 16: Visualization of dataset regions.

* PatchTST [60]: A highly efficient Transformer-based model for multivariate time series forecasting and self-supervised representation learning is proposed. This model significantly enhances the accuracy of long-term predictions by segmenting the time series into small pieces and processing each channel independently.
* DLinear [92]: The paper introduces a simple linear model called DLinear, which decomposes the time series into trend and remainder sequences and uses a two-layer linear network for direct multi-step forecasting, often outperforming existing complex Transformer models.
* STAEformer [54]: A new type of spatio-temporal Transformer model is introduced, which significantly enhances the accuracy of spatio-temporal forecasting by incorporating spatio-temporal adaptive embeddings. The STAEformer achieves state-of-the-art performance on six real-world datasets.
* STID [70]: This paper presents a simple and effective baseline model for multivariate spatio-temporal forecasting, which addresses the indistinguishability of samples in spatial and temporal dimensions by adding spatial and temporal identity information. Based on a simple multi-layer perceptron (MLP), it achieves optimal performance and efficiency.
* GWNet [83]: This paper introduces a novel graph neural network architecture called Graph WaveNet for spatial-temporal graph modeling. It effectively captures hidden spatial dependencies and long sequence time trends in the data through adaptive dependency matrices and stacked dilated one-dimensional convolutional components.
* STGCN [89]: A new deep learning framework for spatio-temporal forecasting, STGCN, is introduced. It combines graph convolution and gated temporal convolution to capture spatio-temporal correlations in the network, achieving excellent performance on multiple real-world traffic datasets.
* ConvLSTM [71]: This paper proposes a new convolutional LSTM network for precipitation forecasting. By extending the traditional fully connected LSTM to include convolutional structures for input-to-state and state-to-state transitions, ConvLSTM is better equipped to capture correlations in spatio-temporal sequences. https://github.com/jhhuang96/ConvLSTM-PyTorch
* HI [24]: This paper introduces historical inertia (HI) as a new baseline for long-term time series forecasting. Research indicates that even when HI is used directly as the output, it can achieve improvements on four public real-world datasets.

We have chosen the benchmark toolbox BasicTS+ https://github.com/zezhishao/BasicTS/tree/master designed specifically for spatio-temporal and time series forecasting as our code framework. However, it should be noted that TimesNet, STAEformer, and STID require date embeddings. Since we are predicting the future 30 days based on the past 30 days, we use "day of month" and "month of year" as substitutes for the original more fine-grained time embeddings to capture trends on a daily and monthly basis. Additionally, for GWNet and STGCN, spatial graphs are constructed by connecting each region with its neighboring regions. Finally, following the original paper on ConvLSTM, we implement it in the code framework for ease of comparison. For all methods, we adhere to the original default parameter settings and make appropriate adjustments for optimal performance.

**Detail Metrics.** Our evaluation is conducted on re-normalized data, employing metrics such as MAE, MSE. Formally, assuming \(n\) represents the indices of all observed samples, \(y_{i}\) denotes the \(i\)-th actual sample, and \(\dot{y}_{i}\) is the corresponding prediction, these metrics are formulated as following:

\begin{table}
\begin{tabular}{c|c|c|c|c|c|c|c} \hline \multirow{2}{*}{**Dataset**} & \multicolumn{2}{c|}{**Spatial Coverage**} & \multicolumn{2}{c|}{**Temporal**} & \multicolumn{2}{c|}{**Resolution**} & \multirow{2}{*}{**Variable**} \\ \cline{2-2} \cline{4-7}  & **Bottom-left** & **Top-right** & & **Coverage** & **Spatial** & **Temporal** \\ \hline Global & -90\({}^{\circ}\)S, -180\({}^{\circ}\)W & 90\({}^{\circ}\)N, 180\({}^{\circ}\)E & 1996/10/1-2022/6/30 & 1\({}^{\circ}\) & Daily & Precipitation \\ \hline UK & 50\({}^{\circ}\)N, 8\({}^{\circ}\)W & 60\({}^{\circ}\)N, 2\({}^{\circ}\)E & 1996/10/1-2022/6/30 & 1\({}^{\circ}\) & Daily & Precipitation \\ \hline USA & 25\({}^{\circ}\)N, -125\({}^{\circ}\)W & 49\({}^{\circ}\)N, -67\({}^{\circ}\)W & 1996/10-2022/6/30 & 1\({}^{\circ}\) & Daily & Precipitation \\ \hline CN & 20\({}^{\circ}\)N, 75\({}^{\circ}\)E & 50\({}^{\circ}\)N, 135\({}^{\circ}\)E & 1996/10/1-2022/6/30 & 1\({}^{\circ}\) & Daily & Precipitation \\ \hline SA & -35\({}^{\circ}\)S, 16\({}^{\circ}\)E & -22\({}^{\circ}\)S, 33\({}^{\circ}\)E & 1996/10/1-2022/6/30 & 1\({}^{\circ}\) & Daily & Precipitation \\ \hline AUS & -40\({}^{\circ}\)S, 113\({}^{\circ}\)E & -10\({}^{\circ}\)S, 154\({}^{\circ}\)E & 1996/10/1-2022/6/30 & 1\({}^{\circ}\) & Daily & Precipitation \\ \hline \end{tabular}
\end{table}
Table 10: Spatio-temporal analysis dataset statistics. _Please note that due to the use of rectangular selection, the current latitude and longitude coverage only includes parts of the country’s territory, and may also include some territories and oceans of other countries. The dataset name is used for identification purposes only and does not represent actual national territories._\[\text{MAE}=\frac{1}{n}\sum_{i=1}^{n}\lvert y_{i}-\hat{y}_{i}\rvert,\quad\text{ RMSE}=\sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}}\]

### Spatial Analysis Experiment

**Detail Datasets.** As shown in Table 11, we summarize the statistical information of the datasets used for spatial analysis tasks. In contrast to spatio-temporal analysis tasks, we utilize daily averages with a finer spatial resolution of 0.1\({}^{\circ}\) from 2020 to 2022 to represent spatial indicators. Specifically, we selected three indicator variables: precipitation, wind speed, and air temperature.

**Detail Baselines.** For spatial analysis tasks, we have chosen two types of spatial variable prediction methods based on location and visual-language. A brief overview of all methods is as follows:

* CSP [56], also known as Contrastive Spatial Pre-Training, is a robust and innovative multi-modal, self-supervised pre-training methodology, capitalizing on extensive collections of unlabeled geo-tagged imagery. This approach significantly advances the acquisition of location-specific representations, thereby facilitating their application in few-shot learning scenarios. https://github.com/gengchenmai/csp
* GeoCLIP [78] pioneers the worldwide geo-localization task through an image-to-GPS retrieval methodology, explicitly aligning image features with their corresponding GPS locations. By integrating positional encoding with random Fourier features, its location encoder effectively encodes GPS coordinates, thus reducing spectral bias in multi-layer perceptrons (MLPs). https://github.com/VicenteVivan/geo-clip
* SatCLIP [45] introduces the first global-coverage, general-purpose pretrained geographic location encoder, utilizing Satellite Contrastive Location Image Pretraining. SatCLIP distills spatially varying visual patterns from globally distributed satellite data into an implicit neural representation within a compact and efficient neural network, achieving excellent performance across a wide range of downstream tasks. https://github.com/microsoft/satclip
* CLIP [63], as a milestone in the field of Vision-Language Pretraining (VLP), it has demonstrated that cross-modal learning with web-scale data can exhibit outstanding performance. CLIP excels in various domains such as image-text retrieval, image-text generation, and possesses zero-shot capabilities. https://github.com/openai/CLIP
* UrbanCLIP [86] is the pioneering framework that integrates textual modality knowledge into urban region analysis. It demonstrates that the comprehensive textual data generated from Large Multimodal Models is an siginificant supervision signal to urban area representations. Through a contrastive learning-based encoder-decoder architecture, UrbanCLIP injects textual knowledge into visual representations by incorporating contrastive loss as well as language modeling loss, making it a versatile and robust approach for urban region profiling. https://github.com/StupidBuluchacha/UrbanCLIP

\begin{table}
\begin{tabular}{c|c|c|c|c|c|c|c|c} \hline \multirow{2}{*}{**Dataset**} & \multicolumn{2}{c|}{**Spatial Coverage**} & \multicolumn{1}{c|}{**Temporal**} & \multicolumn{2}{c|}{**Resolution**} & \#LLM & \#Satellite & \multirow{2}{*}{**Variable**} \\ \cline{2-2} \cline{6-9}  & **Bottom-left** & **Top-right** & **Coverage** & **Spatial** & **Temporal** & **Text** & **Image** & \\ \hline Global & -90\({}^{\circ}\)S, -180\({}^{\circ}\)W & 90\({}^{\circ}\)N, 180\({}^{\circ}\)E & 2020/1/1-2022/12/31 & 0.1\({}^{\circ}\)\(\rightarrow\) 1\({}^{\circ}\) & Daily-Mean & / & Precipitation, \\  & & & & & & Air Temperature \\ \hline USA & 25\({}^{\circ}\)N, -125\({}^{\circ}\)W & 49\({}^{\circ}\)N, -67\({}^{\circ}\)W & 2020/1/1-2022/12/31 & 1\({}^{\circ}\) & Daily-Mean & 1,392 & Precipitation, \\  & & & & & & Air Temperature \\ \hline CN & 20\({}^{\circ}\)N, 75\({}^{\circ}\)E & 50\({}^{\circ}\)N, 135\({}^{\circ}\)E & 2020/1/1-2022/12/31 & 1\({}^{\circ}\) & Daily-Mean & 1,800 & 1,800 & Precipitation, \\  & & & & & & Air Temperature \\ \hline AUS & -40\({}^{\circ}\)S, 113\({}^{\circ}\)E & -10\({}^{\circ}\)S, 154\({}^{\circ}\)E & 2020/1/1-2022/12/31 & 1\({}^{\circ}\) & Daily-Mean & 1,230 & 1,230 & Precipitation, \\  & & & & & & Air Temperature \\ \hline \end{tabular}
\end{table}
Table 11: Spatial analysis dataset statistics. _Please note that due to the use of rectangular selection, the current latitude and longitude coverage only includes parts of the country’s territory, and may also include some territories and oceans of other countries. The dataset name is used for identification purposes only and does not represent actual national territories._* UrbanVLP [34] introduces a pioneering framework for urban region representation learning that comprehensively explores multi-granularity cross-modal alignment. This framework also facilitates automatic text generation and calibration through the application of PerceptionScores, thereby ensuring the high quality of generated texts. This innovative approach has exhibited exceptional performance across six downstream tasks, spanning environmental, social, and economic domains.

For all methods, we followed the default parameters and architectural designs as stated in the original papers, and conducted experiments using their official codes. The only modification made was to UrbanVLP, as this method requires street view images which were not effectively obtainable in our dataset. Therefore, the encoder branch used for street view images was removed while the rest remained unchanged.

**Detail Metrics.** To assess the spaitd prediction performance, we also adopt three commonly used evaluation metrics: mean squared error (MSE), mean absolute error (MAE) and coefficient of determination (\(R^{2}\)). MAE and MSE are calculated in a similar way as in the previous section, and both of these metrics are better when they are smaller. The \(R^{2}\) is a statistical measure that indicates how well a regression model fits the data. It represents the proportion of the variance in the dependent variable that is predictable from the independent variables. The formulation for \(R^{2}\) is:

\[R^{2}=1-\frac{\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}}{\sum_{i=1}^{n}(y_{i}-\bar{ y})^{2}}\]

where \(\bar{y}\) is the mean of the actual values. An \(R^{2}\) value closer to 1 indicates that the model explains a large proportion of the variance in the data, meaning the model has a good fit. The advantage of \(R^{2}\) is that it provides a measure of how well the model explains the variability of the data. However, it can be less useful for non-linear relationships and is sensitive to outliers. In summary, MSE, MAE, and \(R^{2}\) have their respective strengths and weaknesses. MSE and MAE primarily measure the magnitude of prediction errors, while \(R^{2}\) evaluates the explanatory power of the model.

## Appendix C More Discussion

**Potential for Higher Resolution.** Currently, the time series modality in our dataset has achieved a spatial resolution of 0.1\({}^{\circ}\), while the corresponding text and image modalities have not reached this level. Specifically, the main challenge in achieving higher spatial resolution for text lies in the reliability and redundancy of the Large Language Model generating the text, as text descriptions are mainly related to the climate, terrain, and environment of the current area. Fine-grained spatially adjacent regions may have a large amount of redundant text descriptions, posing greater challenges for noise removal. On the other hand, the main adjustment in achieving higher spatial resolution for images lies in the significant time and monetary costs required to handle and manage such fine-grained data. However, increasing the resolution to a spatial scale of 0.1\({}^{\circ}\) will exponentially increase the amount of data, necessitating advanced storage solutions, more powerful computing resources, and substantial financial investment. To address this issue, we are committed to continuously investing time and resources in gradually improving the resolution of various modalities in our dataset. This includes leveraging advancements in data storage technologies, optimizing data processing algorithms, and exploring cloud platforms that can support scalable storage.

**Risk of LLM Obsolescence.** The use of LLMs to generate explanatory text data is a double-edged sword. While LLMs provide a powerful tool for creating comprehensive and detailed textual data, they are also prone to rapid obsolescence due to the fast-paced advancements in AI research and technology. As newer, more advanced LLMs emerge, the text generated by older models may become outdated or less accurate, potentially compromising the quality of the dataset. Moreover, keeping the text data relevant and accurate necessitates regular updates and replacements, which can be resource-intensive. To mitigate these risks, we hope to regularly update our dataset with the latest and best open-source LLMs. This involves a systematic review process to identify advancements in LLM capabilities, followed by the selective replacement of existing text data. By doing so, we ensure that our dataset remains at the forefront of technological innovation and continues to provide high-quality, reliable data for research and practical applications.

**Instability of Satellite Distribution.** Due to potential redistribution constraints, the reliance on commercial satellite remote sensing imagery introduces a certain degree of instability in data acquisition. These constraints may stem from changes in commercial policies, geopolitical factors,or fluctuations in the satellite data market dynamics. For example, Esri grants recipients of Esri information contained in the esri.com website the right to freely copy, redistribute, rebroadcast, and/or retransmit this information for personal non-commercial purposes (including educational, classroom use, academic and/or research purposes) 2; however, these permissions may expire or encounter issues over time. Therefore, in future iterations, we will explore alternative satellite image products from the open-source community, such as Sentinel-2 provided by the European Space Agency (ESA). Open-source satellite data offers a more stable, cost-effective solution, ensuring continued access to high-quality imagery reliably. Furthermore, establishing partnerships with academic and governmental institutions that provide open access to satellite data can further enhance the robustness and stability of our dataset.

Footnote 2: https://www.esri.com/en-us/legal/copyright-proprietary-rights

**Timeliness of Spatial Text and Images.** One potential assumption of our dataset is that spatial information is stable and not time-dependent. However, despite spatial information typically being static or slowly changing, it can undergo significant changes over time. For instance, rapid urbanization can lead to substantial changes in land use, infrastructure, and population density. Areas that were once rural may urbanize, altering the spatial features captured in early images. Furthermore, natural disasters such as earthquakes, floods, and hurricanes can completely transform landscapes, necessitating image updates to accurately reflect these changes. These examples underscore the importance of ensuring the timeliness of spatial images and related textual data in a dataset. Nevertheless, obtaining dynamic temporal text and images is currently impractical, not only due to the challenge of accessing valid sources but also because of the massive storage and crawling costs involved. As a future research direction, we look forward to developing automated systems for detecting changes in spatial data and triggering updates of images and text. Machine learning algorithms can be utilized to identify areas undergoing significant changes, prompting a review and update of the corresponding data.

## Appendix D Broader Impact

The introduction of this Terra dataset will undoubtedly have a profound impact in the fields of earth science and deep learning, and these impacts will be reflected in many aspects.

**Positive Impact**

* **More Accurate Weather Forecasting and Environmental Monitoring:** The Terra dataset provides hourly time series data spanning 45 years globally, enabling meteorologists and environmental scientists to predict weather patterns, climate trends, and the likelihood of natural disasters more accurately. This is crucial for preparedness, ecological protection, and ensuring human safety.
* **Enhanced Training and Application of Deep Learning Models:** The scale and multimodal nature of this dataset will provide rich data resources for the development of deep learning models. Training and evaluating on spatio-temporal data can improve existing models and lay a solid foundation for future spatio-temporal general intelligence.
* **Promotion of Scientific Research and Interdisciplinary Collaboration:** The open sharing of the Terra dataset will facilitate collaboration between fields such as Earth science, computer science, and data science. Researchers can jointly utilize this dataset to explore the complexity of the Earth system, advancing interdisciplinary research.

**Negative Impact**

* **Data Bias and Misinterpretation:** In constructing and utilizing the Terra dataset, there may be issues of data bias and misinterpretation. For example, uneven distribution of observation stations or sensor malfunctions may result in inaccurate or incomplete data for certain regions, leading to misinterpretation of environmental characteristics.
* **Technological Dependency and Data Dominance:** Over-reliance on the Terra dataset may lead to neglect of other data sources, weakening diversity and reliability. When using this dataset, it is important not to overly rely on it but to complement it with other data resources for comprehensive analysis and validation.

## Checklist

1. For all authors... 1. Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes] we summarize the contributions of this paper into three main points in Section 1 2. Did you describe the limitations of your work? [Yes] We discuss three potential issues with our dataset in detail in Section 3 and provide further discussion in Appendix C. 3. Did you discuss any potential negative societal impacts of your work? We discuss potential impacts in Appendix D. 4. Have you read the ethics review guidelines and ensured that your paper conforms to them? We have read the ethical review guidelines and ensured that the paper complies with these guidelines.
2. If you are including theoretical results... 1. Did you state the full set of assumptions of all theoretical results? Our work does not involve theoretical analysis. 2. Did you include complete proofs of all theoretical results? Our work does not involve theoretical analysis.
3. If you ran experiments (e.g. for benchmarks)... 1. Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? 2. Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? We describe the method, experimental setup, and reproduction parameters in detail in Appendix B, and we also provide a code repository to support it. 3. Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? In fact, we conducted 3 experiments and showed the mean results. Due to limited display space and most of the variance errors are very small (3 decimal places), we ignore the error results. 4. Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? We describe in detail the training resources needed to reproduce the experiment in Appendix B.
4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets... 1. If your work uses existing assets, did you cite the creators? We thoroughly review the assets used and give correct citations for all of them. 2. Did you mention the license of the assets? We provide guidelines for licensing and access to assets in Section 3. 3. Did you include any new assets either in the supplemental material or as a URL? We fully describe the assets we used in the main text, and the appendix is only used to further analyze and illustrate. 4. Did you discuss whether and how consent was obtained from people whose data you're using/curating? We have reviewed all asset permissions and summarized them in section 3. 5. Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? Since our datasets are earth science and climate related datasets, concerns such as personal privacy do not apply.
5. If you used crowdsourcing or conducted research with human subjects... 1. Did you include the full text of instructions given to participants and screenshots, if applicable? Our dataset does not involve any human experiments. 2. Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? Our dataset does not involve any human experiments. 3. Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? Our dataset does not involve any human experiments.