# Add and Thin: Diffusion for Temporal Point Processes

David Ludke\({}^{1,\,2}\)   Marin Bilos\({}^{1,\,3}\)   Oleksandr Shchur\({}^{1,\,4}\)

**Marten Lienen\({}^{1,\,2}\)   Stephan Gunnemann\({}^{1,\,2}\)**

\({}^{1}\)School of Computation, Information and Technology, Technical University of Munich, Germany

\({}^{2}\)Munich Data Science Institute, Technical University of Munich, Germany

\({}^{3}\)Machine Learning Research, Morgan Stanley, United States

\({}^{4}\)Amazon Web Services, Germany

{d.luedke,m.bilos,o.shchur,m.lienen,s.guennemann}@tum.de

###### Abstract

Autoregressive neural networks within the temporal point process (TPP) framework have become the standard for modeling continuous-time event data. Even though these models can expressively capture event sequences in a one-step-ahead fashion, they are inherently limited for long-term forecasting applications due to the accumulation of errors caused by their sequential nature. To overcome these limitations, we derive Add-Thin, a principled probabilistic denoising diffusion model for TPPs that operates on entire event sequences. Unlike existing diffusion approaches, Add-Thin naturally handles data with discrete and continuous components. In experiments on synthetic and real-world datasets, our model matches the state-of-the-art TPP models in density estimation and strongly outperforms them in forecasting.

## 1 Introduction

Many machine learning applications involve the analysis of continuous-time data, where the number of events and their times are random variables. This data type arises in various domains, including healthcare, neuroscience, finance, social media, and seismology. Temporal point processes (TPPs) provide a sound mathematical framework to model such event sequences, where the main problem is finding a parametrization that can capture the seasonality and complex interactions (e.g., excitation and inhibition) within point processes.

Traditional TPP models [17; 20] employ simple parametric forms, limiting their flexibility to capture the intricacies of arbitrary TPPs. In recent years, various neural TPPs have been proposed (see [43] for an overview) that capture complex event interactions in an autoregressive manner,

Figure 1: Proposed noising and denoising process for Add-Thin. _(Left)_ Going from step \(n-1\) to step \(n\), we add and remove some points at random. _(Right)_ Given \(\bm{t}^{(n)}\) and \(\bm{t}^{(0)}\) we know the intensity of points at step \(n-1\). We approximate this intensity with our model, which enables sampling new sequences.

often using recurrent neural networks (RNN) or transformer architectures. While autoregressive models are expressive and have shown good performance for _one-step-ahead_ prediction, their suitability for forecasting remains limited due to the accumulation of errors in sequential sampling.

We propose to take a completely different approach: instead of autoregressive modeling, we apply a generative diffusion model, which iteratively refines entire event sequences from noise. Diffusion models [18; 45] have recently shown impressive results for different data domains, such as images [15; 18; 25], point clouds [31; 32], text [27] and time-series [1; 3; 24; 46]. But how can we apply diffusion models to TPPs? We cannot straightforwardly apply existing Gaussian diffusion models to learn the mapping between TPPs due to the particular requirements that must be met, namely, the randomness in the number of events and the strictly positive arrival times.

We present a novel diffusion-inspired model for TPPs that allows sampling entire event sequences at once without relying on a specific choice of a parametric distribution. Instead, our model learns the probabilistic mapping from complete noise, i.e., a homogeneous Poisson process (HPP), to data. More specifically, we learn a model to reverse our noising process of adding (superposition) and removing (thinning) points from the event sequence by matching the conditional inhomogeneous denoising intensity \(\lambda_{n-1}(t\mid\bm{t}^{(0)},\bm{t}^{(n)})\) as presented in Figure 1. Thereby, we achieve a natural way to generate sequences with varying numbers of events and expressively model arbitrary TPPs. In short, our contributions are as follows:

* We connect diffusion models with TPPs by introducing a novel model that naturally handles the discrete and continuous nature of point processes.
* We propose a model that is flexible and permits parallel and closed-form sampling of entire event sequences, overcoming common limitations of autoregressive models.
* We show that our model matches the performance of state-of-the-art TPP models in density estimation and outperforms them in forecasting.

## 2 Background

### Temporal point processes (TPPs)

Temporal point processes (TPPs) [8; 9] are stochastic processes that define a probability distribution over event sequences whose number of points (events) \(K\) and their locations (arrival times) \(t_{i}\) are random. A realization of a TPP can be represented as a sequence of strictly increasing arrival times: \(\bm{t}=(t_{1},\dots,t_{K})\), \(0<t_{1}<\dots<t_{K}\leq T\). Viewing a TPP as a counting process, we can equivalently represent a TPP realization by a counting measure \(N(t)=\sum_{i}^{K}\mathbbm{1}(t_{i}\leq t)\), for \(t\in[0,T]\). The intensity characterizing a TPP can be interpreted as the expected number of events per unit of time and is defined as:

\[\lambda(t\mid\mathcal{H}_{t})=\lim_{\Delta t\downarrow 0}\frac{\mathbb{E}[N(t+ \Delta t)-N(t)\mid\mathcal{H}_{t}]}{\Delta t},\] (1)

where \(\mathcal{H}_{t}=\{t_{i}:t_{i}<t\}\) is the event history until time \(t\), which acts as a filtration to the process.

TPPs have a number of convenient theoretical properties, two of which will be central to our derivation of a noising process for TPPs later in the paper. The first property is _superposition_: If we combine events generated by TPPs with intensities \(\lambda_{1}(t)\) and \(\lambda_{2}(t)\), the resulting event sequence will again follow a TPP, but now with intensity \(\lambda_{1}(t)+\lambda_{2}(t)\). Conversely, randomly removing each event generated by a TPP process with intensity \(\lambda(t)\) with probability \(p\) is known as independent _thinning_. This is equivalent to sampling from a TPP with intensity \((1-p)\lambda(t)\)[9].

Poisson process.A _(in)homogeneous_ Poisson process is the simplest class of TPPs, where the rate of event occurrence is independent of the history. Then the number of points on \([0,T]\) follows a Poisson distribution with rate \(\Lambda(T)=\int_{0}^{t}\,\lambda(t)\,\mathrm{d}t\). In the context of our model, the Poisson process with a constant intensity on \([0,T]\), called _homogeneous_ Poisson Process (HPP), represents the noise distribution. Even though Poisson processes can model seasonality, i.e., time-varying rates of event occurrence, they assume the events to be independent and do not capture the exciting or inhibiting behavior present in the real world, e.g., a large earthquake increasing the likelihood of observing other earthquakes soon after.

Conditional intensity.Most TPP models leverage the _conditional intensity_ function \(\lambda(t\mid\mathcal{H}_{t})\) or equivalently the conditional density \(p(t\mid\mathcal{H}_{t})\) to overcome the independence of points limitation of an _inhomogeneous_ Poisson process. Historically, these intensity models were parameterized using hand-crafted functions [17; 20], whereas now, it is more common to use neural networks for learning intensities from data [12; 33; 41]. While the conditional intensity provides a general framework to model TPPs, sampling from these models is inherently autoregressive.

### Denoising diffusion probabilistic models

Diffusion models [18; 45] are a class of latent variable models that learn a generative model to reverse a fixed probabilistic noising process \(\bm{x}_{0}\rightarrow\bm{x}_{1}\rightarrow\cdots\rightarrow\bm{x}_{N}\), which gradually adds noise to clean data \(\bm{x}_{0}\) until no information remains, i.e., \(\bm{x}_{N}\sim p(\bm{x}_{N})\). For continuous data, the forward (noising) process is usually defined as a fixed Markov chain \(q(\bm{x}_{n}\mid\bm{x}_{n-1})\) with Gaussian transitions. Then the Markov chain of the reverse process is captured by approximating the true posterior \(q(\bm{x}_{n-1}\mid\bm{x}_{0},\bm{x}_{n})\) with a model \(p_{\theta}(\bm{x}_{n-1}\mid\bm{x}_{n})\). Ultimately, sampling new realizations \(\bm{x}_{0}\) from the modeled data distribution \(p_{\theta}(\bm{x}_{0})=\int p(\bm{x}_{N})\prod_{n=1}^{N}p_{\theta}(\bm{x}_{n-1 }\mid\bm{x}_{n})\,\mathrm{d}\bm{x}_{1}\ldots\bm{x}_{N}\) is performed by starting with a sample from pure noise \(\bm{x}_{N}\sim p(\bm{x}_{N})\) and gradually denoising it with the learned model over \(N\) steps \(\bm{x}_{N}\rightarrow\bm{x}_{N-1}\rightarrow\cdots\rightarrow\bm{x}_{0}\).

## 3 Add-Thin

In the following, we derive a diffusion-like model for TPPs--Add-Thin. The two main components of this model are the forward process, which converts data to noise (noising), and the reverse process, which converts noise to data (denoising). We want to emphasize again that existing Gaussian diffusion models [18; 45] are not suited to model entire event sequences, given that the number of events is random and the arrival times are strictly positive. For this reason, we will derive a new noising and denoising process (Sections 3.1 & 3.2), present a learnable parametrization and appropriate loss to approximate the posterior (Section 3.3) and introduce a sampling procedure (Sections 3.4 & 3.5).

### Forward process - Noising

Let \(\bm{t}^{(0)}=(t_{1},\ldots,t_{K})\) denote an i.i.d. sample from a TPP (data process) with \(T=1\) specified by the unknown (conditional) intensity \(\lambda_{0}\). We define a _forward_ noising process as a sequence of TPPs that start with the true intensity \(\lambda_{0}\) and converge to a standard HPP, i.e., \(\lambda_{0}\rightarrow\lambda_{1}\rightarrow\cdots\rightarrow\lambda_{N}\):

\[\lambda_{n}(t)=\underbrace{\alpha_{n}\lambda_{n-1}(t)}_{\text{(i) Thin}}+ \underbrace{(1-\alpha_{n})\lambda_{\text{HPP}}}_{\text{(ii) Add}},\] (2)

where \(1>\alpha_{1}>\alpha_{2}>\cdots>\alpha_{N}>0\) and \(\lambda_{\text{HPP}}\) denotes the constant intensity of an HPP. Equation 2 corresponds to a superposition of (i) a process \(\lambda_{n-1}\) thinned with probability \(1-\alpha_{n}\) (removing old points), and (ii) an HPP with intensity \((1-\alpha_{n})\lambda_{\text{HPP}}\) (adding new points).

**Property** (Stationary intensity).: _For any starting intensity \(\lambda_{0}\), the intensity function \(\lambda_{N}\) given by Equation 2 converges towards \(\lambda_{\text{HPP}}\). That is, the noised TPP will be an HPP with \(\lambda_{\text{HPP}}\)._

Proof.: In Appendix B.1 we show that, given \(\lambda_{0}\) and Equation 2, \(\lambda_{n}\) is given by:

\[\lambda_{n}(t)=\bar{\alpha}_{n}\lambda_{0}(t)+(1-\bar{\alpha}_{n})\lambda_{ \text{HPP}},\] (3)

where \(\bar{\alpha}_{n}=\prod_{j}^{n}\alpha_{j}\). Since \(\prod_{j}^{N}\alpha_{j}\to 0\) as \(N\rightarrow\infty\), thus \(\lambda_{N}(t)\rightarrow\lambda_{\text{HPP}}\). 

If all \(\alpha_{n}\) are close to \(1\), each consecutive realization will be close to the one before because we do not remove a lot of original points, nor do we add many new points. And if we have enough steps, we will almost surely converge to the HPP. Both of these properties will be very useful in training a generative model that iteratively reverses the forward noising process.

But how can we sample points from \(\lambda_{n}\) if we do not have access to \(\lambda_{0}\)? Since we know the event sequence \(\bm{t}^{(0)}\) comes from a true process which is specified with \(\lambda_{0}\), we can sample from a thinned process \(\bar{\alpha}_{n}\lambda_{0}(t)\), by thinning the points \(\bm{t}^{(0)}\) independently with probability \(1-\bar{\alpha}_{n}\). This shows that even though we cannot access \(\lambda_{0}\), we can sample from \(\lambda_{n}\) by simply thinning \(\bm{t}^{(0)}\) and adding new points from an HPP.

To recap, given a clean sequence \(\bm{t}^{(0)}\), we obtain progressively noisier samples \(\bm{t}^{(n)}\) by both removing original points from \(\bm{t}^{(0)}\) and adding new points at random locations. After \(N\) steps, we reach a sample corresponding to an HPP--containing no information about the original data.

### Reverse process - Denoising

To sample realizations \(\bm{t}\sim\lambda_{0}\) starting from \(\bm{t}^{(N)}\sim\lambda_{HPP}\), we need to learn to reverse the Markov chain of the forward process, i.e., \(\lambda_{N}\rightarrow\cdots\rightarrow\lambda_{0}\), or equivalently \(\bm{t}^{(N)}\rightarrow\cdots\rightarrow\bm{t}^{(0)}\). Conditioned on \(\bm{t}^{(0)}\), the reverse process at step \(n\) is given by the posterior \(q(\bm{t}^{(n-1)}\mid\bm{t}^{(0)},\bm{t}^{(n)})\), which is an inhomogeneous Poisson process for the chosen forward process (Section 3.1). Therefore, the posterior can be represented by a history-independent intensity function \(\lambda_{n-1}(t\mid\bm{t}^{(0)},\bm{t}^{(n)})\).

As the forward process is defined by adding and thinning event sequences, the points in the random sequence \(\bm{t}^{(n-1)}\) can be decomposed into disjoint sets of points based on whether they are also in \(\bm{t}^{(0)}\) or \(\bm{t}^{(n)}\). We distinguish the following cases: points in \(\bm{t}^{(n-1)}\) that were kept from \(0\) to \(n\) (**B**), points in \(\bm{t}^{(n-1)}\), that were kept from \(0\) to \(n-1\) but thinned at the \(n\)-th step (**C**), added points in \(\bm{t}^{(n-1)}\) that are thinned in the \(n\)-th step (**D**) and added points in \(\bm{t}^{(n-1)}\) that are kept in the \(n\)-th step (**E**). Since the sets **B**-**E** are disjoint, the posterior intensity is a superposition of the intensities of each subsets of \(\bm{t}^{(n-1)}\): \(\lambda_{n-1}(t\mid\bm{t}^{(0)},\bm{t}^{(n)})=\lambda^{(B)}(t)+\lambda^{(C)}( t)+\lambda^{(D)}(t)+\lambda^{(E)}(t)\).

To derive the intensity functions for cases **B**-**E**, we additionally define the following helper sets: **A** the points \(\bm{t}^{(0)}\setminus\bm{t}^{(n-1)}\) that were thinned until \(n-1\) and **F** the points \(\bm{t}^{(n)}\setminus\bm{t}^{(n-1)}\) that have been added at step \(n\). The full case distinction and derived intensities are further illustrated in Figure 2. In the following paragraphs, we derive the intensity functions for cases **B**-**E**:

**Case B:** The set \(\bm{t}^{(B)}\) can be formally defined as \(\bm{t}^{(0)}\cap\bm{t}^{(n)}\) since \((\bm{t}^{(0)}\cap\bm{t}^{(n)})\setminus\bm{t}^{(n-1)}=\emptyset\) almost surely. This is because adding points at any of the locations \(t\in\bm{t}^{(0)}\cap\bm{t}^{(n)}\) carries zero measure at every noisy step. Hence, given \(\bm{t}^{(0)}\cap\bm{t}^{(n)}\) the intensity can be written as a sum of Dirac measures: \(\lambda^{(B)}(t)=\sum_{t_{i}\in\bm{t}^{(0)}\cap\bm{t}^{(n)}}\delta_{t_{i}}(t)\). Similar to how the forward process generated \(\bm{t}^{(B)}\) by preserving some points from \(\bm{t}^{(0)}\), sampling from the reverse process preserves points from \(\bm{t}^{(n)}\).

**Case C:** Given \(\bm{t}^{(A\cup C)}=\bm{t}^{(0)}\setminus\bm{t}^{(n)}\), \(\bm{t}^{(C)}\) can be found by thinning and consists of points that were kept by step \(n-1\) and removed at step \(n\). Using the thinning of Equations 2 and 3, we know the probability of a point from \(\bm{t}^{(0)}\) being in \(\bm{t}^{(C)}\) and \(\bm{t}^{(A\cup C)}\) is \(\bar{\alpha}_{n-1}(1-\alpha_{n})\) and \(1-\bar{\alpha}_{n}\), respectively. Since we already know \(\bm{t}^{(B)}\) we can consider the probability of finding a point in \(\bm{t}^{(C)}\), given \(\bm{t}^{(A\cup C)}\), which is equal to \(\frac{\bar{\alpha}_{n-1}-\bar{\alpha}_{n}}{1-\bar{\alpha}_{n}}\). Consequently, \(\lambda^{(C)}(t)\) is given as a thinned sum of Dirac measures over \(\bm{t}^{(A\cup C)}\) (cf., Figure 2).

**Case D:** The set \(\bm{t}^{(D)}\) contains all points \(t\notin(\bm{t}^{(0)}\cup\bm{t}^{(n)})\) that were added until step \(n-1\) and thinned at step \(n\). Again using Equations 2 and 3, we can see that these points were added with intensity \((1-\bar{\alpha}_{n-1})\lambda_{HPP}\) and then removed with probability \(\alpha_{n}\) at the next step. Equivalently, we can write down the intensity that governs this process as \(\lambda^{(D)}(t)=(1-\bar{\alpha}_{n-1})(1-\alpha_{n})\lambda_{HPP}\), i.e., sample points from an HPP and thin them to generate a sample \(\bm{t}^{(D)}\).

Figure 2: _(Left) Illustration of all possible disjoint sets that we can reach in our forward process going from \(\bm{t}^{(0)}\) to \(\bm{t}^{(n)}\) through \(\bm{t}^{(n-1)}\). (Right) Posterior intensity describing the distribution of \(\bm{t}^{(n-1)}\mid\bm{t}^{(0)},\bm{t}^{(n)}\), where each subset **B**-**E** can be generated by sampling from the intensity functions.

**Case E:** The set \(\bm{t}^{(E)}\) can be found by thinning \(\bm{t}^{(E\cup F)}=\bm{t}^{(n)}\setminus\bm{t}^{(0)}\) and contains the points that were added by step \(n-1\) and then kept at step \(n\). The processes that generated \(\bm{t}^{(E)}\) and \(\bm{t}^{(F)}\) are two independent HPPs with intensities \(\lambda^{(E)}=(1-\bar{\alpha}_{n-1})\alpha_{n}\lambda_{HPP}\) and \(\lambda^{(F)}=(1-\alpha_{n})\lambda_{HPP}\), respectively, where \(\lambda^{(E)}(t)\) is derived in a similar way to \(\lambda^{(D)}(t)\). Since \(\bm{t}^{(E)}\) and \(\bm{t}^{(F)}\) are independent HPPs and we know \(\underline{\bm{t}}^{(E\cup F)}\), the number of points in \(\bm{t}^{(E)}\) follows a Binomial distribution with probability \(p=\frac{\lambda^{(A)}}{\lambda^{(E)}+\lambda^{(F)}}\) (see Appendix B.2 for details). That means we can sample \(\bm{t}^{(E)}\) given \(\bm{t}^{(n)}\) and \(\bm{t}^{(0)}\) by simply thinning \(\bm{t}^{(E\cup F)}\) with probability \(1-p\) and express the intensity as a thinned sum of Dirac functions (cf., Figure 2).

For sequences of the training set, where \(\bm{t}^{(0)}\) is known, we can compute these intensities for all samples \(\bm{t}^{(n)}\) and reverse the forward process. However, \(\bm{t}^{(0)}\) is unknown when sampling new sequences. Therefore, similarly to the denoising diffusion approaches [18], in the next section, we show how to approximate the posterior intensity, given only \(\bm{t}^{(n)}\). Further, in Section 3.4, we demonstrate how the trained neural network can be leveraged to sample new sequences \(\bm{t}\sim\lambda_{0}\).

### Parametrization and training

In the previous section we have derived the intensity \(\lambda_{n-1}(t\mid\bm{t}^{(0)},\bm{t}^{(n)})\) of the posterior \(q(\bm{t}^{(n-1)}\mid\bm{t}^{(0)},\bm{t}^{(n)})\) for the reverse process, i.e., the intensity of points at step \(n-1\) given \(\bm{t}^{(n)}\) and \(\bm{t}^{(0)}\). Now we want to approximate this posterior using a model \(p_{\bm{\theta}}(\bm{t}^{(n-1)}\mid\bm{t}^{(n)},n)\) to learn to sample points \(\bm{t}^{(n-1)}\) given only \(\bm{t}^{(n)}\). As we are only missing information about \(\bm{t}^{(0)}\) we will learn to model \(\lambda^{(B)}(t)\) and \(\lambda^{(A\cup C)}(t)\) to approximate \(\hat{\bm{t}}^{(0)}\approx\bm{t}^{(0)}\) (cf., Figure 3) for each \(n\) and then have access to the full posterior intensity from Section 3.2 to reverse the noising process.

Sequence embedding.To condition our model on \(\bm{t}^{(n)}\) and \(n\) we propose the following embeddings. We use a sinusoidal embedding [47] to embed the diffusion time \(n\). Further, we encode each arrival time \(t_{i}\in\bm{t}^{(n)}\) and inter-event time \(\tau_{i}=t_{i}-t_{i-1}\), with \(t_{0}=0\), to produce a temporal event embedding \(\bm{e}_{i}\in\mathbb{R}^{d}\) by applying a sinusoidal embedding [47]. Then we leverage a three-layered 1D-Convolutional Neural Network (CNN) with circular padding, dilation, and residual connections to compute a context embedding \(\bm{c}_{i}\in\mathbb{R}^{d}\). Compared to attention and RNN-based encoders, the CNN is computationally more efficient and scales better with the length of event sequences while allowing us to capture long-range dependencies between the events. Finally, a global sequence embedding \(\overline{\bm{c}}\) is generated by a mean aggregation of the context embeddings.

Posterior approximation.The posterior defining \(\bm{t}^{(D)}\) is independent of \(\bm{t}^{(0)}\) and \(\bm{t}^{(n)}\) and can be sampled from directly. The set \(\bm{t}^{(B)}\) corresponds to those points that were kept from \(\bm{t}^{(0)}\) until the \(n\)-th step. Since all of these points are also included in \(\bm{t}^{(n)}\) we specify a classifier \(g_{\theta}(\bm{e}_{i},\bm{c}_{i},n)\) with an MLP that predicts which points from \(\bm{t}^{(n)}\) belong to \(\bm{t}^{(0)}\). As \(\bm{t}^{(0)}\) is known during training, this is a standard classification setting. We use the binary cross entropy (BCE) loss \(\mathcal{L}_{\mathrm{BCE}}\) to train \(g_{\theta}\). Note that classifying \(\bm{t}^{(B)}\) from \(\bm{t}^{(n)}\) simultaneously predicts \(\bm{t}^{(n)}\setminus\bm{t}^{(0)}=\bm{t}^{(E\cup F)}\). Therefore we can subsequently attain \(\bm{t}^{(E)}\) by thinning \(\bm{t}^{(E\cup F)}\) as explained in Section 3.2.

To sample points \(\bm{t}^{(C)}\) we have to specify the intensity function \(\lambda^{(A\cup C)}(t)\) that will be thinned to attain \(\bm{t}^{(C)}\) (cf., Section 3.2). As \(\lambda^{(A\cup C)}(t)\) is a mixture of Dirac functions we use an _unnormalized_ mixture of \(H\) weighted and truncated Gaussian density functions \(f\) on \([0,T]\) to parameterize the

Figure 3: Architecture of our model predicting \(\bm{t}_{0}\) from \(\bm{t}_{n}\).

inhomogeneous intensity:

\[\lambda_{\theta}^{(A\cup C)}(t)=K\sum\limits_{j=1}^{H}w_{j}f\left(t;\mu_{j}, \sigma_{j}\right),\] (4)

where \(w_{j}=\mathrm{Softplus}(\mathrm{MLP}_{w}([n,\overline{\mathbf{c}}]))\), \(\mu_{j}=\mathrm{Sigmoid}(\mathrm{MLP}_{\mu}([n,\overline{\mathbf{c}}]))\) and \(\sigma_{j}=\exp(-|\mathrm{MLP}_{\sigma}([n,\overline{\mathbf{c}}])|)\) are parameterized by MLPs with two layers, a hidden dimension of \(d\) and a ReLU activation. Note that the Gaussian function is the standard approximation of the Dirac delta function and can, in the limit \(\sigma\to 0\), perfectly approximate it. We include \(K\), the number of points in \(\bm{t}^{(n)}\), in the intensity to more directly model the number of events. Then \(\lambda_{\theta}^{(A\cup C)}(t)\) is trained to match samples \(\bm{t}^{(A\cup C)}\sim\lambda^{(A\cup C)}\) by minimizing the negative log-likelihood (NLL):

\[\mathcal{L}_{\mathrm{NLL}}=-\log p(\bm{t}^{(A\cup C)})=-\sum\limits_{t_{i}\in \bm{t}^{(A\cup C)}}\log\lambda_{\theta}^{(A\cup C)}(t_{i})+\int_{0}^{T}\lambda _{\theta}^{(A\cup C)}(t)\,\mathrm{d}t.\] (5)

Thanks to the chosen parametrization, the integral term in \(\mathcal{L}_{\mathrm{NLL}}\) can be efficiently computed in any deep-learning framework using the 'erf' function, without relying on Monte Carlo approximation. We present an overview of our model architecture to predict \(\bm{t}^{(0)}\) from \(\bm{t}^{(n)}\) in Figure 3.

Training objective.The full model is trained to minimize \(\mathcal{L}=\mathcal{L}_{\mathrm{NLL}}+\mathcal{L}_{\mathrm{BCE}}\). During training, we do not have to evaluate the true posterior or sample events from any of the posterior distributions. Instead, we can simply sample \(n\) and subsequently \(\bm{t}^{(n)}\) and minimize \(\mathcal{L}\) for \(\bm{t}^{(n)}\). Interestingly, in Appendix A, we show that \(\mathcal{L}\) is equivalent to the Kullback-Leibler (KL) divergence between the approximate posterior \(p_{\theta}(\bm{t}^{(n-1)}\mid\bm{t}^{(n)},n)\) and the true posterior \(q(\bm{t}^{(n-1)}\mid\bm{t}^{(0)},\bm{t}^{(n)})\). Ultimately, this shows that optimizing the evidence lower bound (ELBO) of the proposed model boils down to simply learning a binary classification and fitting an inhomogeneous intensity.

### Sampling

To sample an event sequence from our model, we start by sampling \(\bm{t}^{(N)}\) from an HPP with \(\lambda_{\mathrm{HPPP}}\). Subsequently, for each \(n\in[N,\cdots,1]\), \(\hat{\bm{t}}^{(0)}\) is predicted by classifying \(\hat{\bm{t}}^{(R)}\) and sampling \(\hat{\bm{t}}^{(A\cup C)}\) from \(\lambda_{\theta}^{(A\cup C)}(t)\). Note that the Poisson distribution with intensity \(\Lambda^{(A\cup C)}(T)=\int_{0}^{T}\lambda_{\theta}^{(A\cup C)}(t)\,\mathrm{d}t\) parameterizes the number of points in \(A\cup C\). Therefore, \(\hat{\bm{t}}^{(A\cup C)}\) can be sampled by first sampling the number of events and then sampling the event times from the normalized intensity \(\lambda_{\theta}^{(A\cup C)}(t)/\Lambda^{(A\cup C)}(T)\). Given our predicted \(\hat{\bm{t}}^{(0)}\) we can sample \(\hat{\bm{t}}^{(n-1)}\) from the posterior intensity defined in Section 3.2. By repeating this process, we produce a sequence of \(\bm{t}^{(n-1)}\)s. Finally, we obtain a denoised sample \(\bm{t}^{(0)}\) by predicting it from \(\hat{\bm{t}}^{(1)}\). We provide an overview of the sampling procedure as pseudo-code in Algorithm 1.

``` \(\bm{t}^{(n=N)}\sim\lambda_{\mathrm{HPPP}}\); for\(n\in\{N,\dots,1\}\)do  sample \(\hat{\bm{t}}^{(B)}\sim\sum\limits_{t_{i}\in\bm{t}^{(n)}}g_{\theta}(t_{i}\mid\bm{ e}_{i},\bm{c}_{i},n)\delta_{t_{i}}(t)\);  sample \(\hat{\bm{t}}^{(C)}\sim\frac{\hat{a}_{n-1}-\hat{a}_{n}}{1-\hat{a}_{n}}\lambda_ {\theta}^{(A\cup C)}(t\mid\bm{t}^{(n)},n)\);  sample \(\hat{\bm{t}}^{(D)}\sim(1-\bar{\alpha}_{n-1})(1-\alpha_{n})_{\mathrm{HPPP}}\);  sample \(\hat{\bm{t}}^{(E)}\sim\sum\limits_{t_{i}\in\bm{t}^{(n)}\hat{\bm{t}}^{(E)}} \frac{\alpha_{n}-\bar{a}_{n}}{1-\hat{a}_{n}}\delta_{t_{i}}(t)\); \(\bm{t}^{(n-1)}\leftarrow\hat{\bm{t}}^{(B)}\cup\hat{\bm{t}}^{(C)}\cup\hat{\bm{t }}^{(D)}\cup\hat{\bm{t}}^{(E)}\);  end for  sample \(\hat{\bm{t}}^{(A\cup C)}\sim\lambda_{\theta}^{(A\cup C)}(t\mid\bm{t}^{(1)},1)\);  sample \(\hat{\bm{t}}^{(B)}\sim\sum\limits_{t_{i}\in\bm{t}^{(1)}}g_{\theta}(t_{i}\mid \bm{e}_{i},\bm{c}_{i},1)\delta_{t_{i}}(t)\); \(\bm{t}\leftarrow\hat{\bm{t}}^{(B)}\cup\hat{\bm{t}}^{(A\cup C)}\); return\(\bm{t}\) ```

**Algorithm 1**Sampling

### Conditional sampling

The above-described process defines an _unconditional_ generative model for event sequences on an interval \([0,T]\). For many (multi-step) forecasting applications, such as earthquake forecasting [10], we need to condition our samples on previous event sequences and turn our model into a conditional one that can generate future event sequences in \([H,H+T]\) given the past observed events in \([0,H]\). To condition our generative model on a history, we apply a simple GRU encoder to encode the history into a \(d\)-dimensional history embedding \(\bm{h}\), which subsequently conditions the classifier and intensity model by being added to the diffusion time embedding.

Related work

Autoregressive neural TPPs.Most neural TPPs model the intensity or density of each event conditional on a history and consequently consist of two parts: a history encoder and an intensity/density decoder. As history encoders, RNNs [12; 41] and attention-based set encoders [50; 52] have been proposed. Attention-based encoders are postulated to better model long-range dependencies in the event sequences, but at the cost of a more complex encoder structure [43]. To decode the intensity \(\lambda(t|\mathcal{H})\), density \(p(t|\mathcal{H})\) or the cumulative hazard function from the history, uni-modal distributions [12], mixture-distributions [41], a mixture of kernels [36; 44; 51], neural networks [37] and Gaussian diffusion [29] have been proposed. Another branch of neural TPPs models the event times conditional on a latent variable that follows a continuous-time evolution [5; 13; 16; 21], where, e.g., Hasan et al. [16] relate inter-event times of a TPP to the excursion of a stochastic process. In general, most neural TPPs are trained by maximizing the log-likelihood, but other training approaches have been proposed [26; 29; 49]. We want to highlight the difference of our model to two related works. TriTPP [42] learns a deterministic mapping between a latent HPP and a TPP using normalizing flows, which allows for parallel sampling. However, it models the conditional hazard function, which forces a conditional dependency of later arrival times and can still produce error accumulation. Lin et al. [29] proposed an autoregressive TPP model leveraging Gaussian diffusion to approximate the conditional density. Besides being autoregressive, the model does not directly model the number of points in the TPP but instead is trained to maximize the ELBO of the next inter-event time.

Non-autoregressive neural TPPs.An alternative to the conditional (autoregressive) modeling of TPPs is to apply a latent variable model that learns to relate entire point processes to latent variables. The class of Cox processes [7; 11; 19] models point processes through a hierarchy of latent processes under the assumption that higher-level latent variables trigger lower-level realizations. Add-Thin can be considered to be a non-autoregressive latent variable model.

Denoising diffusion models.Recently, denoising diffusion models on continuous state spaces [18; 45] established the new state-of-the-art for many image applications [15; 18; 25]. Subsequently, diffusion models for other application domains such as point clouds [31; 32], physical simulations [23; 28; 30] and time-series [1; 3; 24; 46] emerged. While the majority of denoising diffusion models are based on Gaussian transition kernels in continuous state spaces proposed in [18; 45], a variety of diffusion models for discrete state spaces such as graphs [48], text [2; 27] and images [2; 6] have been presented. Here, we highlight the similarity of our work to the concurrent work of Chen and Zhou [6], who derived a diffusion process that models pixel values as a count distribution and thins them to noise images. In contrast to the related work on continuous and discrete state space diffusion models, Add-Thin constitutes a novel diffusion model defined on a state space that captures both the discrete and continuous components of point processes.

## 5 Experiments

We evaluate the proposed model in two settings: density estimation and forecasting. In density estimation, the goal is to learn an unconditional model for event sequences. As for forecasting, the objective is to accurately predict the entire future event sequence given the observed past events.

Data.Add-Thin is evaluated on 7 real-world datasets proposed by Shchur et al. [42] and 6 synthethic datasets from Omi et al. [37]. The synthetic datasets consist of Hawkes1 and Hawkes2 [17], a self-correcting (SC) [20], inhomogeneous Poisson process (IPP) and a stationary and a non-stationary renewal process (MRP, RP) [39; 11]. For the real-world datasets, we consider PUBG, Reddit-Comments, Reddit-Submissions, Taxi, Twitter, and restaurant check-ins in Yelp1 and Yelp2. We split each dataset into train, validation, and test set containing 60%, 20%, and 20% of the event sequences, respectively. Further dataset details and statistics are reported in Appendix C.

Baselines.We apply the _RNN_-based intensity-free TPP model from Shchur et al. [41]. Similar to Sharma et al. [40], we further combine the intensity-free model with an attention-based encoder from Zuo et al. [52] as a _Transformer_ baseline. Additionally, we compare our model to an autoregressive TPP model with a continuous state Gaussian-diffusion [18] from Lin et al. [29], which we abbreviate as _GD_. Lastly, _TriTPP_[42] is used as a model that provides parallel but autoregressive sampling.

Training and model selection.We train each model by its proposed training loss using Adam [22]. For our model, we set the number of diffusion steps to \(N=100\), apply the cosine beta-schedule proposed in Glide [34], and set \(\lambda_{\mathrm{HPP}}=1\) for the noising process. We apply early stopping, hyperparameter tuning, and model selection on the validation set for each model. Further hyperparameter and training details are reported in Appendix D.

### Sampling - Density estimation

A good TPP model should be flexible enough to fit event sequences from various processes. We evaluate the generative quality of the TPP models on 13 synthetic and real-world datasets by drawing 4000 TPP sequences from each model and computing distance metrics between the samples and event sequences from a hold-out test set. In short, the goal of this experiment is to show that our proposed model is a flexible TPP model that can generate event sequences that are 'close' to the samples from the data-generating distribution.

Metrics.In general, diffusion models cannot evaluate the exact likelihood. Instead, we evaluate the quality of samples by comparing the distributions of samples from each model and the test set with the maximum mean discrepancy measure (MMD) [14] as proposed by Shchur et al. [42]. Furthermore, we compute the Wasserstein distance [38] between the distribution of sequence lengths of the sampled sequences and the test set. We report the results on the test set averaged over five runs with different seeds.

Results.Table 1 presents the MMD results for all models and datasets. Among them, the RNN baseline demonstrates a strong performance across all datasets and outperforms both _Transformer_ and _GD_. Notably, Add-Thin exhibits competitive results with the autoregressive baseline, surpassing or matching (\(\pm 0.01\)) it on 11/13 datasets. Additionally, Add-Thin consistently outperforms the _Transformer_ and _GD_ model on all datasets except SC and RP. Lastly, _TriTPP_ performs well on most datasets but is outperformed or matched by our model on all but two datasets.

Table 2 shows the result for comparing the count distributions. Overall, the Wasserstein distance results align closely with the MMD results. However, the _GD_ model is an exception, displaying considerably worse performance when focusing on the count distribution. This outcome is expected since the training of the _GD_ model only indirectly models the number of events by maximizing the ELBO of each diffusion step to approximate the conditional density of the next event and not the likelihood of whole event sequences. Again, Add-Thin shows a very strong performance, further emphasizing its expressiveness.

In summary, these results demonstrate the flexibility of our model, which can effectively capture various complex TPP distributions and matches the state-of-the-art performance in density estimation.

\begin{table}
\begin{tabular}{l|c c c c c c c c c c c c c}  & Hawkes1 & Hawkes2 & SC & IPP & RP & MRP & PUBG & Reddit-C & Reddit-S & Taxi & Twitter & Yelp1 & Yelp2 \\ \hline RNN & **0.02** & **0.01** & **0.08** & 0.05 & **0.01** & **0.03** & 0.04 & **0.01** & **0.02** & **0.04** & **0.03** & 0.07 & **0.03** \\ Transformer & 0.03 & 0.04 & 0.19 & 0.10 & 0.02 & 0.19 & 0.06 & 0.05 & 0.09 & 0.09 & 0.08 & 0.12 & 0.14 \\ GD & 0.06 & 0.06 & 0.13 & 0.08 & 0.05 & 0.14 & 0.11 & 0.03 & 0.03 & 0.10 & 0.15 & 0.12 & 0.10 \\ TriTPP & 0.03 & 0.04 & 0.23 & 0.04 & 0.02 & 0.05 & 0.06 & 0.09 & 0.12 & 0.07 & 0.04 & **0.06** & 0.06 \\ Add-Thin & **0.02** & 0.02 & 0.19 & **0.03** & 0.02 & 0.10 & **0.03** & **0.01** & **0.02** & **0.04** & 0.04 & 0.08 & 0.04 \\ \end{tabular}
\end{table}
Table 1: MMD (\(\downarrow\)) between the TPP distribution of sampled sequences and hold-out test set (**bold** best, underline second best). The results with standard deviation are reported in Appendix E.

\begin{table}
\begin{tabular}{l|c c c c c c c c c c c c c}  & Hawkes1 & Hawkes2 & SC & IPP & RP & MRP & PUBG & Reddit-C & Reddit-S & Taxi & Twitter & Yelp1 & Yelp2 \\ \hline RNN & **0.03** & **0.01** & **0.00** & 0.02 & **0.02** & **0.01** & **0.02** & **0.01** & 0.05 & **0.02** & **0.01** & 0.04 & **0.02** \\ Transformer & 0.06 & 0.04 & 0.06 & 0.07 & 0.04 & 0.11 & 0.04 & 0.08 & 0.11 & 0.13 & 0.05 & 0.11 & 0.21 \\ GD & 0.16 & 0.13 & 0.50 & 0.42 & 0.28 & 0.50 & 0.54 & 0.02 & 0.16 & 0.33 & 0.07 & 0.26 & 0.25 \\ TriTPP & **0.03** & 0.03 & 0.01 & **0.01** & **0.02** & 0.03 & 0.03 & 0.09 & 0.09 & 0.04 & **0.01** & **0.03** & 0.04 \\ Add-Thin & 0.04 & 0.02 & 0.08 & **0.01** & **0.02** & 0.04 & **0.02** & 0.03 & **0.04** & 0.03 & **0.01** & 0.04 & **0.02** \\ \end{tabular}
\end{table}
Table 2: Wasserstein distance (\(\downarrow\)) between the distribution of the number of events of sampled sequences and hold-out test set (**bold** best, underline second best). The results with standard deviation are reported in Appendix E.

### Conditional sampling - Forecasting

Forecasting event sequences from history is an important real-world application of TPP models. In this experiment, we evaluate the forecasting capability of our model on all real-world datasets. We evaluate each model's performance in forecasting the events in a forecasting window \(\Delta T\), by randomly drawing a starting point \(T_{s}\in[\Delta T,T-\Delta T]\). Then, the events in \([0,T_{s}]\) are considered the history, and \([T_{s},T_{s}+\Delta T]\) is the forecasting time horizon.

In the experiment, we randomly sample 50 forecasting windows for each sequence from the test set, compute history embedding with each model's encoder, and then conditionally sample the forecast from each model. Note that _TriTPP_ does not allow for conditional sampling and is therefore not part of the forecasting experiment.

Metrics.To evaluate the forecasting experiment, we will not compare distributions of TPPs but rather TPP instances. We measure the distance between two event sequences, i.e., forecast and ground truth data, by computing the distance between the count measures with the Wasserstein distance between two TPPs, as introduced by Xiao et al. [49]. Additionally, we report the mean absolute relative error (MAPE) between the predicted sequence length and ground truth sequence length in the forecasting horizon. We report the results on the test set averaged over five runs with different seeds.

Results.Table 3 presents the average Wasserstein distance between the predicted and ground truth forecast sequences. The results unequivocally demonstrate the superior performance of our model by forecasting entire event sequences, surpassing all autoregressive baselines on all datasets. Notably, the disparity between Add-Thin and the baselines is more pronounced for datasets with a higher number of events per sequence, indicating the accumulation of prediction errors in the autoregressive models. Further, the transformer baseline achieves better forecasting results than the RNN baseline for some datasets with more events. This suggests that long-range attention can improve autoregressive forecasting and mitigate some error accumulation.

Table 4 reports the MAPE between the forecasted and ground truth sequence length. The MAPE results align consistently with the Wasserstein distance across all models and datasets. Figure 4

\begin{table}
\begin{tabular}{l|c c c c c c c}  & PUBG & Reddit-C & Reddit-S & Taxi & Twitter & Yelp1 & Yelp2 \\ \hline Average Seq. Length & 76.5 & 295.7 & 1129.0 & 98.4 & 14.9 & 30.5 & 55.2 \\ \hline RNN & 1.72 & 5.47 & 0.68 & 0.54 & 0.95 & 0.59 & 0.72 \\ Transformer & 0.65 & 7.38 & 0.55 & 0.46 & 1.18 & 0.63 & 0.99 \\ GD & 1.66 & 10.49 & 1.33 & 0.71 & 1.43 & 0.78 & 1.65 \\ Add-Thin (Ours) & **0.45** & **1.07** & **0.38** & **0.37** & **0.69** & **0.45** & **0.50** \\ \end{tabular}
\end{table}
Table 4: Count MAPE \(\times 100\%\) between forecasted event sequences and ground truth reported for 50 random forecast windows on the test set (lower is better). The results with standard deviation are reported in Appendix E.

Figure 4: \(5\%\), \(25\%\), \(50\%\), \(75\%\), and \(95\%\) quantile of forecasts generated by Add-Thin for a Taxi event sequence (_blue_: history, _black_ ground truth future).

\begin{table}
\begin{tabular}{l|c c c c c c c}  & PUBG & Reddit-C & Reddit-S & Taxi & Twitter & Yelp1 & Yelp2 \\ \hline Average Seq. Length & 76.5 & 295.7 & 1129.0 & 98.4 & 14.9 & 30.5 & 55.2 \\ \hline RNN & 6.15 & 35.22 & 39.23 & 4.14 & 2.04 & 1.28 & 2.21 \\ Transformer & 2.45 & 38.77 & 27.52 & 3.12 & 2.09 & 1.29 & 2.64 \\ GD & 5.44 & 44.72 & 64.25 & 4.32 & 2.16 & 1.52 & 4.25 \\ Add-Thin (Ours) & **2.03** & **17.18** & **21.32** & **2.42** & **1.48** & **1.00** & **1.54** \\ \end{tabular}
\end{table}
Table 3: Wasserstein distance between forecasted event sequence and ground truth reported for 50 random forecast windows on the test set (lower is better). The results with standard deviation are reported in Appendix E.

depicts the quantiles for 1000 forecasts generated by Add-Thin for one Taxi event sequence and highlights the predictive capacity of our model. Overall, our model outperforms state-of-the-art TPP models in forecasting real-world event sequences.

## 6 Discussion

Add-Thin vs. autoregressive TPP models.On a conceptual level, Add-Thin presents a different trade-off compared to other TPP models: Instead of being autoregressive in event time, our model gradually refines the entire event sequence in parallel at every diffusion step to produce a sample from the learned data distribution. Thereby, we have found that our model is better suited for forecasting and modeling very long event sequences than autoregressive TPP models. Furthermore, the iterative refinement of the entire sequence allows us to leverage simple and shared layers to accurately model the long-range interaction between events and results in nearly constant sampling times across different sequence lengths (cf., Appendix E.3).

Limitations and future work.With Add-Thin, we have derived a novel diffusion-inspired model for TPPs. Thereby, we focused on modeling the arrival times of the events and did not model continuous and discrete marks. However, we see this as an exciting extension to our framework, which might incorporate Gaussian diffusion [18] for continuous marks and discrete diffusion [2] for discrete marks. Further, while generative diffusion is known to produce high-quality samples, it also can be expensive. Besides tuning the number of diffusion steps, future work could focus on alternative and faster sampling routines [35]. Ultimately, we hope that by having connected diffusion models with TPPs, we have opened a new direction to modeling TPPs and broadened the field of diffusion-based models. Here, it would be especially interesting for us to see whether our framework could benefit other application domains in machine learning that involve sets of varying sizes, such as graph generation (molecules), point clouds, and spatial point processes.

## 7 Conclusion

By introducing Add-Thin, we have connected the fields of diffusion models and TPPs and derived a novel model that naturally handles the discrete and continuous nature of point processes. Our model permits parallel and closed-form sampling of entire event sequences, overcoming common limitations of autoregressive TPP models. In our experimental evaluation, we demonstrated the flexibility of Add-Thin, which can effectively capture complex TPP distributions and matches the state-of-the-art performance in density estimation. Additionally, in a long-term forecasting task on real-world data, our model distinctly outperforms the state-of-the-art TPP models by predicting entire forecasting windows non-autoregressively.

## Broader impact

We see the proposed model as a general framework to model continuous-time event data. As such, our method can be applied to many fields, where common application domains include traffic, social networks, and electronic health records. We do not find any use cases mentioned above raise ethical concerns; however, it is essential to exercise caution when dealing with sensitive personal data.

## Acknowledgements

This research was supported by the German Research Foundation, grant GU 1409/3-1.

## References

* [1] J. M. L. Alcaraz and N. Strodthoff. Diffusion-based time series imputation and forecasting with structured state space models. _arXiv preprint arXiv:2208.09399_, 2022.
* [2] J. Austin, D. D. Johnson, J. Ho, D. Tarlow, and R. Van Den Berg. Structured denoising diffusion models in discrete state-spaces. _Advances in Neural Information Processing Systems_, 34:17981-17993, 2021.
* [3] M. Bilos, K. Rasul, A. Schneider, Y. Nevmyvaka, and S. Gunnemann. Modeling temporal data as continuous functions with stochastic process diffusion. In _International Conference on Machine Learning (ICML)_, 2023.
* [4] T. Bosser and S. B. Taieb. On the predictive accuracy of neural temporal point process models for continuous-time event data. _Transactions on Machine Learning Research_, 2023.
* [5] R. T. Chen, B. Amos, and M. Nickel. Neural spatio-temporal point processes. _arXiv preprint arXiv:2011.04583_, 2020.
* [6] T. Chen and M. Zhou. Learning to jump: Thinning and thickening latent counts for generative modeling. _arXiv preprint arXiv:2305.18375_, 2023.
* [7] D. R. Cox. Some statistical methods connected with series of events. _Journal of the Royal Statistical Society: Series B (Methodological)_, 17(2):129-157, 1955.
* [8] D. Daley and D. Vere-Jones. _An Introduction to the Theory of Point Processes: Volume I: Elementary Theory and Methods_. Probability and Its Applications. Springer New York, 2006.
* [9] D. J. Daley and D. Vere-Jones. _An introduction to the theory of point processes: volume II: general theory and structure_. Springer Science & Business Media, 2007.
* [10] K. Dascher-Cousineau, O. Shchur, E. E. Brodsky, and S. Gunnemann. Using deep learning for flexible and scalable earthquake forecasting. _Geophysical Research Letters_, 50(17), 2023.
* [11] C. DR and I. COLL. The statistical analysis of dependencies in point processes. _Stochastic Point Processes. Wiley: New York_, pages 55-66, 1972.
* [12] N. Du, H. Dai, R. Trivedi, U. Upadhyay, M. Gomez-Rodriguez, and L. Song. Recurrent marked temporal point processes: Embedding event history to vector. In _Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining_, pages 1555-1564, 2016.
* [13] J. Enguehard, D. Busbridge, A. Bozson, C. Woodcock, and N. Hammerla. Neural temporal point processes for modelling electronic health records. In _Machine Learning for Health_, pages 85-113. PMLR, 2020.
* [14] A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Scholkopf, and A. Smola. A kernel two-sample test. _The Journal of Machine Learning Research_, 13(1):723-773, 2012.
* [15] X. Han, H. Zheng, and M. Zhou. Card: Classification and regression diffusion models. _arXiv preprint arXiv:2206.07275_, 2022.
* [16] A. Hasan, Y. Chen, Y. Ng, M. Abdelghani, A. Schneider, and V. Tarokh. Inference and sampling of point processes from diffusion excursions. In _The 39th Conference on Uncertainty in Artificial Intelligence_, 2023.
* [17] A. G. Hawkes. Spectra of some self-exciting and mutually exciting point processes. _Biometrika_, 58(1):83-90, 1971.
* [18] J. Ho, A. Jain, and P. Abbeel. Denoising diffusion probabilistic models. _Neural Information Processing Systems (NeurIPS)_, 2020.
* [19] C. Hong and C. Shelton. Deep neyman-scott processes. In _Proceedings of the 25th International Conference on Artificial Intelligence and Statistics_, volume 151, pages 3627-3646. PMLR, 2022.

* [20] V. Isham and M. Westcott. A self-correcting point process. _Stochastic processes and their applications_, 8(3):335-347, 1979.
* [21] J. Jia and A. R. Benson. Neural jump stochastic differential equations. _Advances in Neural Information Processing Systems_, 32, 2019.
* [22] D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_, 2014.
* [23] G. Kohl, L.-W. Chen, and N. Thuerey. Turbulent flow simulation using autoregressive conditional diffusion models, 2023.
* [24] M. Kollovieh, A. F. Ansari, M. Bohlke-Schneider, J. Zschiegner, H. Wang, and Y. Wang. Predict, refine, synthesize: Self-guiding diffusion models for probabilistic time series forecasting. _arXiv preprint arXiv:2307.11494_, 2023.
* [25] H. Li, Y. Yang, M. Chang, S. Chen, H. Feng, Z. Xu, Q. Li, and Y. Chen. Sridff: Single image super-resolution with diffusion probabilistic models. _Neurocomputing_, 479:47-59, 2022.
* [26] S. Li, S. Xiao, S. Zhu, N. Du, Y. Xie, and L. Song. Learning temporal point processes via reinforcement learning. _Advances in neural information processing systems_, 31, 2018.
* [27] X. Li, J. Thickstun, I. Gulrajani, P. S. Liang, and T. B. Hashimoto. Diffusion-lm improves controllable text generation. _Advances in Neural Information Processing Systems_, 35:4328-4343, 2022.
* [28] M. Lienen, D. Ludke, J. Hansen-Palmus, and S. Gunnemann. From zero to turbulence: Generative modeling for 3d flow simulation, 2023.
* [29] H. Lin, L. Wu, G. Zhao, L. Pai, and S. Z. Li. Exploring generative neural temporal point process. _Transactions on Machine Learning Research_, 2022.
* [30] P. Lippe, B. S. Veeling, P. Perdikaris, R. E. Turner, and J. Brandstetter. Pde-refiner: Achieving accurate long rollouts with neural pde solvers. _arXiv preprint arXiv:2308.05732_, 2023.
* [31] S. Luo and W. Hu. Diffusion probabilistic models for 3d point cloud generation. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 2837-2845, 2021.
* [32] Z. Lyu, Z. Kong, X. Xu, L. Pan, and D. Lin. A conditional point diffusion-refinement paradigm for 3d point cloud completion. _arXiv preprint arXiv:2112.03530_, 2021.
* [33] H. Mei and J. M. Eisner. The neural hawkes process: A neurally self-modulating multivariate point process. In _Neural Information Processing Systems (NeurIPS)_, 2017.
* [34] A. Nichol, P. Dhariwal, A. Ramesh, P. Shyam, P. Mishkin, B. McGrew, I. Sutskever, and M. Chen. Glide: Towards photorealistic image generation and editing with text-guided diffusion models. _arXiv preprint arXiv:2112.10741_, 2021.
* [35] A. Q. Nichol and P. Dhariwal. Improved denoising diffusion probabilistic models. In _International Conference on Machine Learning_, pages 8162-8171. PMLR, 2021.
* [36] M. Okawa, T. Iwata, T. Kurashima, Y. Tanaka, H. Toda, and N. Ueda. Deep mixture point processes: Spatio-temporal event prediction with rich contextual information. In _Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_, pages 373-383, 2019.
* [37] T. Omi, K. Aihara, et al. Fully neural network based model for general temporal point processes. _Advances in neural information processing systems_, 32, 2019.
* [38] A. Ramdas, N. Garcia Trillos, and M. Cuturi. On wasserstein two-sample testing and related families of nonparametric tests. _Entropy_, 19(2):47, 2017.
* [39] B. Sevast'yanov. Renewal theory. _Journal of Soviet Mathematics_, 4(3):281-302, 1975.

* [40] K. Sharma, Y. Zhang, E. Ferrara, and Y. Liu. Identifying coordinated accounts on social media through hidden influence and group behaviours. In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_, pages 1441-1451, 2021.
* [41] O. Shchur, M. Bilos, and S. Gunnemann. Intensity-free learning of temporal point processes. In _International Conference on Learning Representations (ICLR)_, 2020.
* [42] O. Shchur, N. Gao, M. Bilos, and S. Gunnemann. Fast and flexible temporal point processes with triangular maps. In _Advances in Neural Information Processing Systems (NeurIPS)_, 2020.
* [43] O. Shchur, A. C. Turkmen, T. Januschowski, and S. Gunnemann. Neural temporal point processes: A review. _arXiv preprint arXiv:2104.03528_, 2021.
* [44] A. Soen, A. Mathews, D. Grixti-Cheng, and L. Xie. Unipoint: Universally approximating point processes intensities. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 35, pages 9685-9694, 2021.
* [45] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In _International Conference on Machine Learning (ICML)_, pages 2256-2265, 2015.
* [46] Y. Tashiro, J. Song, Y. Song, and S. Ermon. Csdi: Conditional score-based diffusion models for probabilistic time series imputation. _Advances in Neural Information Processing Systems_, 34:24804-24816, 2021.
* [47] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. Attention is all you need. _Advances in neural information processing systems_, 30, 2017.
* [48] C. Vignac, I. Krawczuk, A. Siraudin, B. Wang, V. Cevher, and P. Frossard. Digress: Discrete denoising diffusion for graph generation. _arXiv preprint arXiv:2209.14734_, 2022.
* [49] S. Xiao, M. Farajtabar, X. Ye, J. Yan, L. Song, and H. Zha. Wasserstein learning of deep generative point process models. _Advances in neural information processing systems_, 30, 2017.
* [50] Q. Zhang, A. Lipani, O. Kirnap, and E. Yilmaz. Self-attentive hawkes process. In _International conference on machine learning_, pages 11183-11193. PMLR, 2020.
* [51] W. Zhang, T. Panum, S. Jha, P. Chalasani, and D. Page. Cause: Learning granger causality from event sequences using attribution methods. In _International Conference on Machine Learning_, pages 11235-11245. PMLR, 2020.
* [52] S. Zuo, H. Jiang, Z. Li, T. Zhao, and H. Zha. Transformer hawkes process. _arXiv preprint arXiv:2002.09291_, 2020.

On the relationship between the applied loss and the ELBO

In the following section, we investigate the relationship between our applied loss function and the ELBO to the unknown data distribution derived for diffusion models. The ELBO of diffusion models [18] is given as follows:

\[\begin{split}\mathcal{L}_{ELBO}=\mathbb{E}_{q}\bigg{[}& \underbrace{D_{KL}\left(q(\boldsymbol{t}^{(N)}\mid\boldsymbol{t}^{(0)}) \parallel p(\boldsymbol{t}^{(N)})\right)}_{\mathcal{L}_{N}}-\underbrace{ \log p_{\theta}(\boldsymbol{t}^{(0)}\mid\boldsymbol{t}^{(1)})}_{\mathcal{L} _{0}}+\\ &\sum_{n=2}^{N}\underbrace{D_{KL}\left(q(\boldsymbol{t}^{(n-1)} \mid\boldsymbol{t}^{(0)},\boldsymbol{t}^{(n)})\parallel p_{\theta}( \boldsymbol{t}^{(n-1)}\mid\boldsymbol{t}^{(n)})\right)}_{\mathcal{L}_{n}} \bigg{]}.\end{split}\] (6)

Additionally, the Janossi density [8] of an event sequence \(\boldsymbol{t}\) on \([0,T]\) allows us to represent each element of the ELBO in terms of our derived inhomogeneous (approximate) posterior intensities (Section 3.2 and Figure 2) as follows:

\[p(\boldsymbol{t})=\exp\left(-\int_{0}^{T}\lambda(t)\,\mathrm{d}t\right)\prod _{t_{i}\in\boldsymbol{t}}\lambda(t_{i}).\] (7)

\(\boldsymbol{\mathcal{L}_{N}}\): \(\mathcal{L}_{N}\) is constant as the intensity \(\lambda_{\mathrm{HPP}}\) defining \(q(\boldsymbol{t}^{(N)}\mid\boldsymbol{t}^{(0)})\) and \(p(\boldsymbol{t}^{(N)})\) has no learnable parameters.

\(\boldsymbol{\mathcal{L}_{0}}\): We directly train our model to optimize this likelihood term as described in Section 3.3.

\(\boldsymbol{\mathcal{L}_{n}}\): The KL divergence between two densities is defined as:

\[D_{KL}(q\parallel p_{\theta})=\mathbb{E}_{q}\left[\log(q(\boldsymbol{t}^{(n-1 )}\mid\boldsymbol{t}^{(0)},\boldsymbol{t}^{(n)}))-\log(p_{\theta}(\boldsymbol {t}^{(n-1)}\mid\boldsymbol{t}^{(n)}))\right],\] (8)

where only the right-hand side relies on \(\theta\), letting us minimize the KL divergence by maximizing the expectation over the log-likelihood \(\log(p_{\theta}(\boldsymbol{t}^{(n-1)}\mid\boldsymbol{t}^{(n)}))\).

To add some additional context to the KL divergence in \(\mathcal{L}_{n}\) and similar to the derivation of the posterior in Section 3.2, we will further distinguish three cases:

1. **Case B & E:**\(q(\boldsymbol{t}^{(n-1)}\mid\boldsymbol{t}^{(0)},\boldsymbol{t}^{(n)})\) and \(p_{\theta}(\boldsymbol{t}^{(n-1)}\mid\boldsymbol{t}^{(n)})\) are defined by Bernoulli distributions over each element of \(\boldsymbol{t}^{(n)}\). By definition the cross-entropy \(H(q,p)\) of the distribution \(p\) relative to \(q\) is given by \(H(q,p)=H(q)+D_{KL}(q\parallel p)\), where \(H(q)\) is the entropy and \(D_{KL}\) the KL divergence. We can see that minimizing the (binary) cross-entropy is equivalent to minimizing the KL divergence, as the entropy \(H(q)\) is constant for the data distribution.
2. **Case C:** Minimizing this KL divergence by maximizing the \(\mathbb{E}_{q}\left[\log(p_{\theta}(\boldsymbol{t}^{(n-1)}\mid\boldsymbol{t}^ {(n)}))\right]\) is proposed in Section 3.2 to learn \(\lambda_{\theta}^{(A\cup C)}(t)\). Note that \(q(\boldsymbol{t}^{(n-1)}\mid\boldsymbol{t}^{(0)},\boldsymbol{t}^{(n)})\) is sampled from by independently thinning \(\boldsymbol{t}^{(0)}\setminus\boldsymbol{t}^{(n)}\). Consequently, by minimizing the NLL of our intensity \(\lambda_{\theta}^{(A\cup C)}(t)\) with regards to \(\boldsymbol{t}^{(0)}\setminus\boldsymbol{t}^{(n)}\), we optimize the expectation in closed form.
3. **Case D:** Our parametrization uses the same intensity function for \(q(\boldsymbol{t}^{(n-1)}\mid\boldsymbol{t}^{(0)},\boldsymbol{t}^{(n)})\) and \(p_{\theta}(\boldsymbol{t}^{(n-1)}\mid\boldsymbol{t}^{(n)})\), which does not rely on any learned parameters.

## Appendix B Derivations

### Direct forward sampling

Proof.: We first repeat Equation 2:

\[\lambda_{n}(t)=\alpha_{n}\lambda_{n-1}(t)+(1-\alpha_{n})\lambda_{\text{HPP}}.\] (2)

Then for the first step we can write:

\[\lambda_{1}(t) =\alpha_{1}\lambda_{0}(t)+(1-\alpha_{1})\lambda_{\text{HPP}}\] \[=\left(\prod_{j=1}^{n=1}\alpha_{j}\right)\lambda_{0}+\left(1- \prod_{j=1}^{n=1}\alpha_{j}\right)\lambda_{\text{HPP}}.\]Assuming Equation 3 holds for step \(n-1\):

\[\lambda_{n-1}(t)=\left(\prod_{j=1}^{n-1}\alpha_{j}\right)\lambda_{0}(t)+\left(1- \prod_{j=1}^{n-1}\alpha_{j}\right)\lambda_{\text{HPP}},\]

we can write for step \(n\):

\[\lambda_{n}(t) =\alpha_{n}\lambda_{n-1}(t)+(1-\alpha_{n})\lambda_{\text{HPP}}\] \[=\alpha_{n}\left(\left(\prod_{j=1}^{n-1}\alpha_{j}\right)\lambda_ {0}(t)+\left(1-\prod_{j=1}^{n-1}\alpha_{j}\right)\lambda_{\text{HPP}}\right)+( 1-\alpha_{n})\lambda_{\text{HPP}}\] \[=\left(\prod_{j=1}^{n}\alpha_{j}\right)\lambda_{0}(t)+\left( \alpha_{n}-\prod_{j=1}^{n}\alpha_{j}\right)\lambda_{\text{HPP}}+(1-\alpha_{n} )\lambda_{\text{HPP}}\] \[=\left(\prod_{j=1}^{n}\alpha_{j}\right)\lambda_{0}(t)+\left(1- \prod_{j=1}^{n}\alpha_{j}\right)\lambda_{\text{HPP}}\] \[=\bar{\alpha}_{n}\lambda_{0}(t)+(1-\bar{\alpha}_{n})\lambda_{ \text{HPP}},\]

which completes the proof by induction. 

### Conditional distribution of Poisson variables

**Proposition**.: _Given two independent random variables \(X_{1}\sim Poisson(\lambda_{1})\), \(X_{2}\sim Poisson(\lambda_{2})\), \(X_{1}\mid X_{1}+X_{2}=k\) is Binomial distributed, i.e., \(X_{1}\mid X_{1}+X_{2}=k\sim Binomial(x_{1};k,\frac{\lambda_{1}}{\lambda_{1}+ \lambda_{1}})\)._

Proof.: The Poisson distributed random variables \(X_{1}\) and \(X_{2}\) have the following joint probability mass function:

\[P(X_{1}=x_{1},X_{2}=x_{2})=e^{-(\lambda_{1})}\frac{\lambda_{1}^{x_{1}}}{x_{1}! }e^{-\lambda_{2}}\frac{\lambda_{2}^{x_{2}}}{x_{2}!},\] (9)

which further defines the joint probability mass function of \(P(X_{1}=x_{1},X_{2}=x_{2},Y=k)\) if \(x_{1}+x_{2}=k\). Additionally, it is well know that \(Y=X_{1}+X_{2}\) is a Poisson random variable with intensity \(\lambda_{1}+\lambda_{2}\) and therefore \(P(Y=k)=e^{-(\lambda_{1}+\lambda_{2})}\frac{(\lambda_{1}+\lambda_{2})^{k}}{k!}\). Then \(P(X_{1}=x_{1}\mid Y=k)\) is given by the following:

\[P(X_{1}=x_{1}\mid Y=k) =\frac{P(X_{1}=x_{1},X_{2}=x_{2},Y=k)}{P(Y=k)}\text{ if }x_{1}+x_{2}=k,\] (10) \[=\frac{e^{-\lambda_{1}}\frac{\lambda_{1}^{x_{1}}}{x_{1}!}e^{- \lambda_{2}}\frac{\lambda_{2}^{x_{2}}}{x_{2}!}}{e^{-(\lambda_{1}+\lambda_{2})} \frac{(\lambda_{1}+\lambda_{2})^{k}}{k!}}\text{ if }x_{1}+x_{2}=k,\] (11) \[=\frac{k!}{x_{1}!x_{2}!}\frac{\lambda_{1}^{x_{1}}\lambda_{2}^{x_{2 }}}{(\lambda_{1}+\lambda_{2})^{x_{1}}}\text{ if }x_{1}+x_{2}=k,\] (12) \[=\frac{k!}{x_{1}!(k-x_{1})!}\frac{\lambda_{1}^{x_{1}}}{(\lambda_ {1}+\lambda_{2})^{x_{1}}}\frac{\lambda_{2}^{k-x_{1}}}{(\lambda_{1}+\lambda_{2 })^{k-x_{1}}}\text{ if }x_{1}+x_{2}=k,\] (13) \[=\frac{k!}{x_{1}!(k-x_{1})!}\left(\frac{\lambda_{1}}{(\lambda_{1 }+\lambda_{2})}\right)^{x_{1}}\left(1-\frac{\lambda_{1}}{(\lambda_{1}+\lambda _{2})}\right)^{(k-x_{1})}\text{ if }x_{1}+x_{2}=k,\] (14)

where we have leveraged \(x_{2}=k-x_{1}\) and \(\frac{\lambda_{2}}{(\lambda_{1}+\lambda_{2})}=1-\frac{\lambda_{1}}{(\lambda_{1 }+\lambda_{2})}\). As we have shown \(P(X_{1}=x_{1}\mid Y=k)\) follows the Binomial distribution with \(p=\frac{\lambda_{1}}{(\lambda_{1}+\lambda_{2})}\).

## Appendix C Datasets

Synthetic datasets.The six synthethic dataset were sampled by Shchur et al. [42] following the procedure in Section 4.1 of Omi et al. [37] and consist of 1000 sequences on the interval \([0,100]\).

Real-world datasets.The seven real-world datasets were proposed by Shchur et al. [42] and consist of PUBG, Reddit-Comments, Reddit-Submissions, Taxi, Twitter, Yelp1, and Yelp2. The event sequences of **PUBG** represent the death of players in a game of Player Unknown's Battleground (PUBG). The event sequences of **Reddit-Comments** represent the comments on the askscience subreddit within 24 hours after opening the discussion in the period from 01.01.2018 until 31.12.2019. The event sequences of **Reddit-Submissions** represent the discussion submissions on the politics subreddit within a day in the period from 01.01.2017 until 31.12.2019. The event sequences of **Taxi** represent taxi pick-ups in the south of Manhattan, New York. The event sequences of **Twitter** represent tweets by user 2507387. The event sequences of **Yelp1** represent check-ins for the McCarran International Airport recorded for 27 users in 2018. The event sequences of **Yelp2** represent check-ins for all businesses in the city of Mississauga recorded for 27 users in 2018.

We report summary statistics on the datasets in Table 5 and 6. Lately, the validity of some of the widely used real-world benchmark datasets was criticized [4]. In one-step-ahead prediction tasks with teacher forcing, very simple architectures achieved similar results to some of the more advanced ones. However, this seems to be more of a problem of the task than the datasets. In our work, we consider different tasks (density estimation and long-term forecasting) and metrics and have found significant empirical differences between the baselines on these datasets.

## Appendix D Experimental set-up

All models but the transformer baseline were trained on an Intel Xeon E5-2630 v4 @ 2.20 GHz CPU with 256GB RAM and an NVIDIA GeForce GTX 1080 Ti. Given its RAM requirement, the transformer baseline had to be trained with batch size 32 on an NVIDIA A100-PCIE-40GB for the Reddit-C and Reddit-S datasets.

Hyperparameter tuning.has been applied to all models. The hyperparameter tuning was done on the MMD loss between 1000 samples from the model and the validation set. We use a hidden dimension of 32 for all models. Further, we have tuned the learning rate in \(\{0.01,0.001\}\) for all models, the number of mixture components in \(\{8,16\}\) for Add-Thin, _RNN_ and _Transformer_, the number of knots in \(\{10,20\}\) for _TriTPP_ and the number of attention layers in \(\{2,3\}\) for the transformer baseline. The values of all other baseline hyperparameters were set to the recommended

\begin{table}
\begin{tabular}{l|c c c c c}  & \# Sequences & \(T\) & Unit of time & Average sequence length & \(\tau\) & \(\Delta T\) \\ \hline PUBG & 3001 & 30 & minutes & 76.5 & \(0.41\pm 0.56\) & 5 \\ Reddit-C & 1356 & 24 & hours & 295.7 & \(0.07\pm 0.28\) & 4 \\ Reddit-S & 1094 & 24 & hours & 1129.0 & \(0.02\pm 0.03\) & 4 \\ Taxi & 182 & 24 & hours & 98.4 & \(0.24\pm 0.40\) & 4 \\ Twitter & 2019 & 24 & hours & 14.9 & \(1.26\pm 2.80\) & 4 \\ Yelp1 & 319 & 24 & hours & 30.5 & \(0.77\pm 1.10\) & 4 \\ Yelp2 & 319 & 24 & hours & 55.2 & \(0.43\pm 0.96\) & 4 \\ \end{tabular}
\end{table}
Table 6: Statistics for the real-world datasets.

\begin{table}
\begin{tabular}{l|c c c c}  & \# Sequences & \(T\) & Average sequence length & \(\tau\) \\ \hline Hawkes1 & 1000 & 100 & 95.4 & \(1.01\pm 2.38\) \\ Hawkes2 & 1000 & 100 & 97.2 & \(0.98\pm 2.56\) \\ SC & 1000 & 100 & 100.2 & \(0.99\pm 0.71\) \\ IPP & 1000 & 100 & 100.3 & \(0.99\pm 2.22\) \\ RP & 1000 & 100 & 109.2 & \(0.83\pm 2.76\) \\ MRP & 1000 & 100 & 98.0 & \(0.98\pm 1.83\) \\ \end{tabular}
\end{table}
Table 5: Statistics for the synthetic datasets.

[MISSING_PAGE_EMPTY:17]

### Forecasting results with standard deviations

### Sampling runtimes

We compare sampling runtimes on an NVIDIA GTX 1080 Ti across the different models in Figure 5. Add-Thin maintains near-constant runtimes by refining the entire sequence in parallel. The autoregressive baselines _RNN_ and _Transformer_ show increasing runtimes, with longer sequences surpassing Add-Thin's runtime. _TriTPP_ is a highly optimized baseline computing the autoregressive interactions between event times in parallel by leveraging triangular maps, resulting in the fastest runtimes. Lastly, _GD_ is autoregressive in event time and gradually refines each event time over 100 diffusion steps, leading to the worst runtimes.

\begin{table}
\begin{tabular}{l|c c c c c c c}  & PUBG & Reddit-C & Reddit-S & Taxi & Twitter & Yelp1 & Yelp2 \\ \hline Average Seq. Length & 76.5 & 295.7 & 1129.0 & 98.4 & 14.9 & 30.5 & 55.2 \\ \hline RNN & 6.15\(\pm\)2.53 & 35.22\(\pm\)4.02 & 39.23\(\pm\)2.06 & 4.14\(\pm\)0.25 & 2.04\(\pm\)0.08 & 1.28\(\pm\)0.03 & 2.21\(\pm\)0.06 \\ Transformer & 2.45\(\pm\)0.21 & 38.77\(\pm\)10.68 & 27.52\(\pm\)5.24 & 3.12\(\pm\)0.1 & 2.09\(\pm\)0.07 & 1.29\(\pm\)0.1 & 2.64\(\pm\)0.24 \\ GD & 5.44\(\pm\)0.2 & 44.72\(\pm\)1.77 & 64.25\(\pm\)4.45 & 4.32\(\pm\)0.3 & 2.16\(\pm\)0.23 & 1.52\(\pm\)0.15 & 4.25\(\pm\)0.46 \\ Add-Thin (Ours) & 2.03\(\pm\)0.01 & 17.18\(\pm\)1.18 & 21.32\(\pm\)0.42 & 2.42\(\pm\)0.03 & 1.48\(\pm\)0.03 & 1.0\(\pm\)0.02 & 1.54\(\pm\)0.04 \\ \end{tabular}
\end{table}
Table 11: Wasserstein distance \((\downarrow)\) between forecasted event sequence and ground truth reported for 50 random forecast windows on the test set.

Figure 5: Sampling runtime for a batch of 100 event sequences averaged over 100 runs. We report the trained model’s sampling times for the real-world datasets with different sequence lengths (from left to right: Twitter, Yelp 1, Yelp 2, PUBG, Taxi, Reddit-C, Reddit-A).

\begin{table}
\begin{tabular}{l|c c c c c c c}  & PUBG & Reddit-C & Reddit-S & Taxi & Twitter & Yelp1 & Yelp2 \\ \hline Average Seq. Length & 76.5 & 295.7 & 1129.0 & 98.4 & 14.9 & 30.5 & 55.2 \\ \hline RNN & 1.72\(\pm\)0.65 & 5.47\(\pm\)0.92 & 0.68\(\pm\)0.07 & 0.54\(\pm\)0.02 & 0.95\(\pm\)0.08 & 0.59\(\pm\)0.02 & 0.72\(\pm\)0.03 \\ Transformer & 0.65\(\pm\)0.11 & 7.38\(\pm\)2.51 & 0.55\(\pm\)0.14 & 0.46\(\pm\)0.04 & 1.18\(\pm\)0.09 & 0.63\(\pm\)0.08 & 0.99\(\pm\)0.11 \\ GD & 1.66\(\pm\)0.06 & 10.49\(\pm\)0.42 & 1.33\(\pm\)0.12 & 0.71\(\pm\)0.05 & 1.43\(\pm\)0.2 & 0.78\(\pm\)0.1 & 1.65\(\pm\)0.2 \\ Add-Thin (Ours) & 0.45\(\pm\)0.005 & 1.07\(\pm\)0.19 & 0.38\(\pm\)0.02 & 0.37\(\pm\)0.02 & 0.69\(\pm\)0.03 & 0.45\(\pm\)0.02 & 0.5\(\pm\)0.03 \\ \end{tabular}
\end{table}
Table 12: Count MAPE \(\times 100\%\)\((\downarrow)\) between forecasted event sequences and ground truth reported for 50 random forecast windows on the test set.