# A Primal-Dual-Assisted Penalty Approach to Bilevel Optimization with Coupled Constraints

 Liuyuan Jiang\({}^{\dagger}\), Quan Xiao\({}^{\dagger}\), Victor M. Tenorio\({}^{*}\), Fernando Real-Rojas\({}^{*}\)

Antonio G. Marques\({}^{*}\), Tianyi Chen\({}^{\dagger}\)

\({}^{\dagger}\)Rensselaer Polytechnic Institute, Troy, NY, United States

\({}^{*}\)King Juan Carlos University, Madrid, Spain

{jiang17, xiaoq5, chen18}@rpi.edu

{victor.tenorio, antonio.garcia.marques}@urjc.es; f.real.2018@alumnos.urjc.es

###### Abstract

Interest in bilevel optimization has grown in recent years, partially due to its applications to tackle challenging machine-learning problems. Several exciting recent works have been centered around developing efficient gradient-based algorithms that can solve bilevel optimization problems with provable guarantees. However, the existing literature mainly focuses on bilevel problems either without constraints, or featuring only simple constraints that do not couple variables across the upper and lower-levels, excluding a range of complex applications. Our paper studies this challenging but less explored scenario and develops a (fully) first-order algorithm, which we term **BLOCC**, to tackle **Bi**Level **O**ptimization problems with **C**oupled **C**onstraints. We establish rigorous convergence theory for the proposed algorithm and demonstrate its effectiveness on two well-known real-world applications - hyperparameter selection in support vector machine (SVM) and infrastructure planning in transportation networks using the real data from the city of Seville.

## 1 Introduction

Bilevel optimization (BLO) approaches are pertinent in various machine learning problems, including hyperparameter optimization [49, 24], meta-learning [22], and reinforcement learning [67, 63]. Moreover, the ability to handle BLO with constraints is particularly important, as these constraints appear in applications such as pricing [15], transportation [50, 1], and kernelized SVM [30]. Although there is extensive research on BLO problems without constraints or with uncoupled constraints [31, 12, 39, 42, 62], solutions for BLO problems with coupled constraints (CCs) remain limited; see details in Table 1. However, it is of particular interest to investigate BLO with lower-level CCs. Taking infrastructure planning in a transportation network as an example, the lower-level seeks to optimize a utility constrained by the upper-level parameter, network configuration.

Motivated by this, we consider the coupled-constrained BLO problem in the following form

\[\min_{x\in\mathcal{X}}f(x,y_{g}^{*}(x))\] (1a) \[\text{s.t.}\quad y_{g}^{*}(x):=\arg\min_{y\in\mathcal{Y}(x)}g(x,y) \quad\text{with}\quad\mathcal{Y}(x):=\{y\in\mathcal{Y}:g^{c}(x,y)\leq 0\}\] (1b)

where \(f:\mathbb{R}^{d_{x}}\times\mathbb{R}^{d_{y}}\to\mathbb{R}\) is the upper-level objective, \(g:\mathbb{R}^{d_{x}}\times\mathbb{R}^{d_{y}}\to\mathbb{R}\) is the lower-levelobjective which is strongly convex, \(g^{c}(x,y):\mathbb{R}^{d_{x}}\times\mathbb{R}^{d_{y}}\rightarrow\mathbb{R}^{d_{c}}\) defines the lower-level CCs, and \(\mathcal{X}\subseteq\mathbb{R}^{d_{x}},\mathcal{Y}\subseteq\mathbb{R}^{d_{y}}\) are the domain of \(x\) and \(y\) that are easy to project, such as the Euclidean ball.

The challenge in solving (1) arises from the coupling of the upper and lower-level problems. Prior work addressed this by starting with the unconstrained BLO problem, using implicit gradient descent (IGD) methods [27, 31, 34, 12, 13, 40, 61, 43, 66] and penalty-based methods [45, 44, 61, 41, 42]. To solve BLO with CCs, AiPOD [71] and GAM [72] investigated the IGD method under different constraint settings. However, AiPOD only considered equality constraints, and GAM lacked finite-time convergence guarantees. Leveraging a penalty reformulation, [75] developed a Hessian-free method with finite-time convergence. However, a key algorithm step in [75] is a joint projection of the current iterate \((x,y)\) onto the coupled constraint set. This projection, required at each iteration, becomes particularly challenging when \(g^{c}(x,y)\) is not jointly convex and can be computationally expensive for large-scale problems with a high number of variables (\(d_{x},d_{y}\)) or constraints (\(d_{c}\)).

To this end, this paper aims to address the following question

_Can we develop an efficient algorithm that bypasses joint projections on \(g^{c}(x,y)\) and quickly solves the BLO problem with coupled inequality constraints in (1)?_

We address this question affirmatively, focusing on the setting where the lower-level objective, \(g(x,y)\), is strongly convex in \(y\), and the constraints \(g^{c}(x,y)\) are convex in \(y\). To avoid implementing a joint projection, we put forth a novel single-level primal-dual-assisted penalty reformulation that decouples \(x\) and \(y\). Specifically, with \(\mu\in\mathbb{R}^{d_{c}}\) denoting the Lagrange multiplier of (1b), we propose solving

\[\min_{x\in\mathcal{X}}\ \ F_{\gamma}(x):=\max_{\mu\in\mathbb{R}^{d_{x}}_{+}} \min_{y\in\mathcal{Y}}f(x,y)+\underbrace{\gamma(g(x,y)-v(x))}_{\text{penalty term}}+ \underbrace{\langle\mu,g^{c}(x,y)\rangle}_{\text{Lagrangian term}}\] (2a) \[\text{where}\quad v(x):=\min_{y\in\mathcal{Y}(x)}g(x,y)\] (2b)

where the penalty constant \(\gamma\) controls the distance between \(y\) and \(y^{*}_{g}(x)\) by penalizing \(g(x,y)\) to its value function \(v(x)\), and the Lagrangian term penalizes the constraint violation of \(g^{c}(x,y)\).

However, recognizing the max-min subproblems involved in (2a), it becomes computationally costly to evaluate the penalty function \(F_{\gamma}(x)\) and its gradient. To this end, we pose the following question

_Can we develop efficient algorithms to solve the max-min subproblem and evaluate \(\nabla F_{\gamma}(x)\)?_

We answer this question by proving that this reformulation exhibits several favorable properties, including smoothness. These properties are critical for designing gradient-based algorithms and characterizing their performance. However, the presence of the CCs renders the calculation of the gradient \(\nabla F_{\gamma}(x)\) more challenging than for its unconstrained counterpart [62]. Building upon this, we design a primal-dual gradient method with rigorous convergence guarantees for the BLO with general inequality CCs, and provide an improved result for the case of \(g^{c}\) being affine in \(y\).

### Main contributions

In a nutshell, our main contributions are outlined below.

* In Section 2, leveraging the Lagrangian duality theorem, we introduce the function \(F_{\gamma}(x)\) in (2a) as a penalty-based reformulation of (1), establish the continuity and smoothness of \(F_{\gamma}(x)\), and develop a novel way to compute its gradient.
* In Section 3, we develop BLOCC, a fully first-order algorithm to tackle BLO problems with CCs. With \(\epsilon\) being the target error for the generalized gradient norm square of \(F_{\gamma}(x)\), we establish that the iteration complexity under the generic constraint \(g^{c}(x,y)\) in (1b) is \(\tilde{\mathcal{O}}(\epsilon^{-2.5})\). We establish, for the first time, the linear convergence of a strongly convex-concave max-min problem with linear interaction and a constrained maximization parameter, reducing BLOCC's complexity to \(\tilde{\mathcal{O}}(\epsilon^{-1.5})\) when the constraint \(g^{c}(x,y)\) is affine in \(y\).
* In Section 4, we apply our BLOCC algorithm to two real-world applications: SVM model training and transportation network planning. By comparison with LV-HBA [75] and GAM [72], we demonstrate the algorithm's effectiveness and its robustness to large-scale problems.

### Related works

BLO has a long history, dating back to the seminal work of [8]. It has inspired a rich body of literature, e.g., [76; 68; 14; 65]. The recent focus on BLO is centered on developing efficient gradient-based approaches with provable finite-time guarantees.

**Methods for BLO without constraints.** A cluster of BLO gradient-based approaches gravitates around the implicit gradient descent (IGD) method [55], where the key idea is to approximate the hypergradient by the implicit function theorem. The finite-time convergence of IGD was first established in [27] for unconstrained strongly-convex lower-level problems. Subsequent works improved the convergence rates and/or relaxed the assumptions under various settings; see [31; 34; 12; 13; 40; 61; 43; 66; 73; 35; 70]. Another cluster of works is based on iterative differentiation (ITD) [49; 23; 53; 60], which estimates the hypergradient by differentiating the entire iterative algorithm used to solve the lower-level problem with respect to the upper-level variables. The finite-time guarantee was first established in [28; 47; 33; 6]. Viewing the lower-level problem as a constraint such as in [64], penalty-based methods have also emerged as a promising approach for BLO. Dated back to [77], this line of works [45; 51; 44; 41; 62; 25; 48] reformulated the original BLO as the single-level problems with various penalty terms and leveraged first-order methods to solve them.

**BLO with constraints.** While substantial progress has been made for unconstrained BLO, the analysis for constrained BLO is more limited. Upper-level constraints of the form \(x\in\mathcal{X}\) were considered in [31; 12]. For the lower-level uncoupled constraint, SIGD [39] considered the uncoupled constraint \(Ay\leq b\) and achieved asymptotic convergence, [42; 62] employed penalty reformulation and considered both upper and lower uncoupled constraints. However, the literature on **BLO with CCs** is scarce. BVFSM [46] conducted a penalty-based method to avoid the calculation of the Hessian, as IGD methods do. However, only asymptotic convergence was achieved. GAM [72] investigated the IGD method under inequality constraints while failing to provide finite-time convergence results as well. AiPOD [71] also applied IGD and successfully achieved finite-time convergence, but it only considered equality constraints. LV-HBA [75] considered inequality constraints and constructed a penalty-based reformulation. However, it employed a joint projection of \((x,y)\) onto \(\{\mathcal{X}\times\mathcal{Y}:g^{c}(x,y)\leq 0\}\) which is computationally inefficient when there are many constraints or when \(g^{c}(x,y)\) is not jointly convex. After our initial submission, we found a concurrent work [74] posted on ArXiv, which used Lagrange duality theory differently from ours, applying it to construct a new smoothed penalty term. However, it does not quantify the relationship between the relaxation of this penalty and the relaxation of lower-level optimality, and it does not guarantee lower-level feasibility. We summarized prior works on BLO with lower-level CCs in Table 1.

## 2 Primal-dual Penalty-based Reformulation

In this section, our goal is to construct a primal-dual-assisted penalty reformulation for our BLOCC problem. The technical challenge comes from finding a suitable penalty function for BLO with CCs.

### The challenges in BLO with coupled constraints

Here, we will elaborate on the two technical challenges of BLO with CCs.

The _first challenge_ associated with the presence of CCs is the difficulty to find the descent direction for \(x\), which involves finding the closed-form expression of the gradient \(\nabla v(x)\). The expression without CCs, \(\nabla v(x)=\nabla_{x}g(x,y_{g}^{*}(x))\) provided in [62; 42; 41; 44], is not applicable.

\begin{table}
\begin{tabular}{l|c|c|c} \hline \hline  & LL constraint & First Order & Complexity \\ \hline
**BLOCC** & \(g^{c}(x,y)\leq 0\) convex in \(y\) and LICQ holds; & ✓ & \(\mathcal{O}(\epsilon^{-2.5})\); \\  & Special case: \(g^{c}(x,y)\) affine in \(y\) & & \(\mathcal{O}(\epsilon^{-1.5})\) \\ \hline LV-HBA & \(g^{c}(x,y)\leq 0\) convex in \(x\times y\) & ✓ & \(\mathcal{O}(\epsilon^{-3})\) \\ \hline GAM & \(g^{c}(x,y)\leq 0\) convex in \(x\times y\) and LICQ holds & ✗ & ✗ \\ \hline BVFSM & \(g^{c}(x,y)\leq 0\) satisfying other requirements & ✓ & ✗ \\ \hline AiPOD & \(g^{c}(x,y)=Ay-b(x)=0\) & ✗ & \(\mathcal{O}(\epsilon^{-1.5})\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Comparison of our work with LV-HBA [75], BVFSM [46], AiPOD [71], and Gradient Approximation method (GAM) [72]. LL convergence is on metric the squared distance of \(y_{t}\) to its optimal solution, and UL convergence is on squared (generalized) gradient norm.

For example, when \(g(x,y)=(y-2x)^{2}\) and \(g^{c}(x,y)=3x-y\), the optimal lower-level solution is \(y_{g}^{*}(x)=3x\) and thus, \(v(x)=x^{2}\) with \(\nabla v(x)=2x\). However, \(\nabla_{x}g(x,y_{g}^{*}(x))=-4x\neq\nabla v(x)\). The closed form gradient for BLO with CCs should be (8), which considers a Lagrange term that will be illustrated later in this paper. In Figure 1, we present the gradient \(\nabla v(x)\) without the Lagrange multiplier in [62, 42, 41, 44] and ours with the Lagrange term. In this example, the gradient without the Lagrange term leads to the opposite direction to the true gradient.

The _second challenge_ associated with the presence of CCs is the difficulty of performing the joint projection. If we directly extend the penalty reformulation in [62, 41], we could treat the coupling constraint set \(\mathcal{Y}(x)\) as a joint constraint \(\{(x,y):g^{c}(x,y)\leq 0\}\), and employ a joint projection of \((x,y)\) to ensure the feasibility. However, this can be computationally inefficient when the problem is large-scale, i.e. the number of variables or constraints is large. The detailed analysis of computational cost can be seen in Appendix H. Moreover, when \(g^{c}(x,y)\) is complex, the projection may not have a closed form and may not even be well-defined if \(g^{c}(x,y)\) is not jointly convex.

### The Lagrangian duality-based penalty reformulation

Before proceeding, we summarize the assumptions considered as follows.

**Assumption 1** (Lipschitz Continuity).: _Assume that \(f\), \(\nabla f\), \(\nabla g\), \(g^{c}\) and \(\nabla g^{c}\), and are respectively \(l_{f,0}\), \(l_{f,1}\), \(l_{g,1}\), \(l_{g^{c},0}\), and \(l_{g^{c},1}\)-Lipschitz jointly over \((x,y)\in\mathcal{X}\times\mathcal{Y}\), and \(g\) is \(l_{g_{x},0}\)-Lipschitz in \(x\in\mathcal{X}\)._

**Assumption 2** (Convexity in \(y\)).: _For any given \(x\in\mathcal{X}\), \(g(x,y)\) and \(g^{c}(x,y)\) are \(\alpha_{g}\)-strongly convex and convex in \(y\in\mathcal{Y}\), respectively._

**Assumption 3** (Domain Feasibility).: _Domain \(\mathcal{X}\subseteq\mathbb{R}^{d_{x}}\) and \(\mathcal{Y}\subseteq\mathbb{R}^{d_{y}}\) are non-empty, closed, and convex. For any given \(x\in\mathcal{X}\), \(\mathcal{Y}(x):=\{y\in\mathcal{Y}:g^{c}(x,y)\leq 0\}\) is non-empty._

**Assumption 4** (Constraint Qualification).: _For any given \(x\in\mathcal{X}\), \(g^{c}\) satisfies the Linear Independence Constraint Qualification (LICQ) condition for every \(y\mathcal{Y}\) in a neighborhood of \(y_{g}^{*}(x)\)._

The Lipschitz continuity in Assumption 1 and the strong convexity of \(g\) over \(y\) in Assumption 2 are conventional [27, 31, 41, 71, 35, 13]. Moreover, we only require \(g^{c}(x,y)\) to be convex in \(y\) rather than: i) jointly convex in \((x,y)\) as in [75], or ii) linear as in [39, 71]. Assumption 3 pertains to the convexity and closeness of the domain, which is also conventional, and Assumption 4 is a standard constraint qualification condition.

To build a penalty reformulation for BLO with lower-level CCs, the first challenge is to find a penalty that regulates \(\|y-y_{g}^{*}(x)\|\). In the following lemma, we show that \(g(x,y)-v(x)\) is a good choice.

**Lemma 1**.: _Suppose that Assumptions 2-4 hold and \(v(x)\) is defined as in (2b). Then, it holds that_

* \(g(x,y)-v(x)\geq\frac{\alpha_{g}^{{}^{\prime}}}{2}\|y-y_{g}^{*}(x)\|^{2}\)_, for some_ \(\alpha_{g}^{\prime}>0\)_, for all_ \(y\in\mathcal{Y}(x)\)_; and_
* \(g(x,y)=v(x)\) _if and only if_ \(y=y_{g}^{*}(x)\)_, for all_ \(y\in\mathcal{Y}(x)\)_._

The technical challenge of proving this lemma lies in showing the quadratic growth property as in c1) of Lemma 1. For BLO without the CCs, this naturally holds as the lower-level objective \(g(x,y)\) is strongly convex in \(y\). For BLO with CCs, one needs to use the Lagrangian duality theorem. The full proof of Lemma 1 is given in Appendix B.1, where the key challenge is to show the invariance of the modulus of strong convexity in the Lagrangian reformulated lower-level objective.

With \(\gamma\) denoting a penalty constant, we consider the following penalty reformulation:

\[\min_{(x,y)\in\{\mathcal{X}\times\mathcal{Y}:g^{c}(x,y)\leq 0\}}f(x,y)+ \gamma(g(x,y)-v(x))\] (3)

where the penalty term confines the squared Euclidean distance from \(y\) to \(y_{g}^{*}(x)\). Furthermore, to avoid projecting \((x,y)\) onto the \(\{\mathcal{X}\times\mathcal{Y}:g^{c}(x,y)\leq 0\}\), we propose the primal-dual-assisted penalty

Figure 1: Calculation of \(\nabla v(x)\). The blue line is \(v(x)\), the the yellow dashed line is calculated by the formulation given in [62, 41], while red dashed line is derived by our BLOCC. It can be seen that \(\nabla v(x)\) without the Lagrange multiplier is very biased from the true gradient.

reformulation, which was defined in (2). The approximate equivalence of the reformulation (2) to the original BLO problem (1) is established in the following theorem.

**Theorem 1** (Equivalence).: _Suppose that \(f\) is Lipschitz in \(y\) and \(\nabla f\) is \(l_{f,1}\)-Lipschitz in \((x,y)\) in Assumption 1 hold, and Assumptions 2-4 hold. Then, solving the \(\epsilon\)-approximation problem of (1):_

\[\min_{(x,y)\in\{\mathcal{X}\times\mathcal{Y}:g^{c}(x,y)\leq 0\}}f(x,y)\quad \text{s.t.}\quad\|y-y_{g}^{*}(x)\|^{2}\leq\epsilon,\] (4)

_is equivalent to solve the primal-dual penalty reformulation in (2) with \(\gamma=\mathcal{O}(\epsilon^{-0.5})\) and \(\gamma>\frac{l_{f,1}}{\alpha_{g}}\)._

The detailed proof is provided in Appendix B.2. By setting \(\gamma=\mathcal{O}(\epsilon^{-0.5})\), we effectively state the equivalence between the penalty reformulation in (3) and the approximated original problem (4). We can then decouple the joint minimization on \((x,y)\) to a min-min problem on \(x\) and \(g^{c}\) constrained \(y\). For the inner minimization problem in \(y\), we choose \(\gamma\) in a way that \(\gamma\alpha_{g}-l_{f,1}>0\) holds. This ensures the objective in (2a) being strongly convex in \(y\), as \(l_{f,1}\)-smoothness ensures a lower bound for negative curvature of \(f(x,y)\). Furthermore, the convexity of \(g^{c}(x,y)\) in \(y\) validates the strong duality theorem in [59, 32], thereby enabling the max-min primal-dual reformulation in (2).

### Smoothness of the penalty reformulation

To evaluate \(F_{\gamma}(x)\) defined in (2a), we can find the solution to the inner max-min problem:

\[(\mu_{F}^{*}(x),y_{F}^{*}(x)):=\arg\max_{\mu\in\mathbb{R}_{+}^{dx}}\min_{y\in \mathcal{Y}}\underbrace{f(x,y)+\gamma(g(x,y)-v(x))+\langle\mu,g^{c}(x,y) \rangle}_{=:L_{F}(\mu,y;x)}.\] (5)

The uniqueness of \(y_{F}^{*}(x)\) and \(\mu_{F}^{*}(x)\) is guaranteed under Assumptions 2 and 4 (see Lemma 5 in Appendix A). Therefore, \(F_{\gamma}(x)\) in (2a) can be evaluated using the unique optimal solutions by

\[F_{\gamma}(x)=L_{F}(\mu_{F}^{*}(x),y_{F}^{*}(x);x).\] (6)

Similarly, we can evaluate \(v(x)=L_{g}(\mu_{g}^{*}(x),y_{g}^{*}(x);x)\), where

\[(\mu_{g}^{*}(x),y_{g}^{*}(x)):=\arg\max_{\mu\in\mathbb{R}_{+}^{dx}}\min_{y\in \mathcal{Y}}\underbrace{g(x,y)+\langle\mu,g^{c}(x,y)\rangle}_{=:L_{g}(\mu,y;x )}.\] (7)

The penalty reformulation \(F_{\gamma}(x)\) can hardly be convex, as \(-v(x)\) may be concave, even when \(g(x,y)=g(y)\) and \(g^{c}(x,y)=A^{\top}y-x\); see Lemma 4.24 in [59]. Instead, in the subsequent lemma, we not only show that \(v(x)\) is differentiable, but also provide a closed-form expression of \(\nabla v(x)\).

**Lemma 2** (Danskin-like theorem for \(v(x)\)).: _Suppose that Assumptions 1-4 hold, and let \(B_{g}<\infty\) be a constant such that \(\|\mu_{g}^{*}(x)\|<B_{g}\) for all \(x\in\mathcal{X}\). Then, it holds that_

_1. \(y_{g}^{*}(x)\) and \(\mu_{g}^{*}(x)\) defined in (7) are \(L_{g}\)-Lipschitz for some finite constant \(L_{g}\geq 0\)._

_2. \(v(x)\) defined in (2b) is \(l_{v,1}\)-smooth where \(l_{v,1}\leq(l_{g,1}+B_{g}l_{g^{c},1})(1+L_{g})+l_{g^{c},0}L_{g}\) and_

\[\nabla v(x)=\nabla_{x}g(x,y_{g}^{*}(x))+\langle\mu_{g}^{*}(x),\nabla_{x}g^{c} (x,y_{g}^{*}(x))\rangle.\] (8)

The assumption of the existence of the upper bound for the Lagrange multiplier is a consequence of the LICQ condition [69, Theorem 1]. This assumption is mild and traditional [75]. Finding \(\nabla v(x)\) is crucial for the design of a gradient-based method to solve \(\min_{x\in\mathcal{X}}F_{\gamma}(x)\). Leveraging Lemma 2, the gradient \(\nabla F_{\gamma}(x)\) can be obtained by the next lemma.

**Lemma 3** (Danskin-like theorem for \(F_{\gamma}(x)\)).: _Suppose that the conditions in Lemma 2 hold. Moreover, assume that \(\gamma>\frac{l_{f,1}}{\alpha_{g}}\), and there exist \(B_{F}\!<\!\infty\) such that \(\|\mu_{F}^{*}(x)\|\!<\!B_{F},\,\forall x\in\mathcal{X}\). Then, it holds that_

_1. \(y_{F}^{*}(x)\) and \(\mu_{F}^{*}(x)\) defined in (5) are \(L_{F}\)-Lipschitz for some constant \(L_{F}\geq 0\)._

_2. \(F_{\gamma}(x)\) is \(l_{F,1}\)-smooth with \(l_{F,1}\leq(l_{f,1}+\gamma l_{g,1}+B_{F}l_{g^{c},1})(1+L_{F})+\gamma l_{v,1}+l_{f ^{c},0}L_{F}\), and_

\[\nabla F_{\gamma}(x)=\nabla_{x}f(x,y_{F}^{*}(x))+\gamma\left(\nabla_{x}g(x,y_{F }^{*}(x))-\nabla v(x)\right)+\langle\mu_{F}^{*}(x),\nabla_{x}g^{c}(x,y_{F}^{*} (x))\rangle.\] (9)

The proof of Lemmas 2 and 3 is provided in Appendix C. Similar to [62], the Danskin-like theorems in Lemmas 2 and 3 rely on the Lipschitzness of the solutions in (5) and (7). Different from BLO without CCs [62], the results here also hinge on the Lagrange multipliers \(\mu_{g}^{*}(x)\) and \(\mu_{F}^{*}(x)\).

Main Results

We will first introduce an algorithm tailored for **BiL**evel **O**ptimization problems with inequality **C**oupled **C**onstraints, and present its convergence analysis. In Section 3.2, we will propose a primal-dual solver for the inner max-min problems and characterize the overall convergence.

### BLOCC algorithm

As \(F_{\gamma}(x)\) features differentiability and smoothness, we can apply a projected gradient descent (PGD)-based method to solve \(\min_{x\in\mathcal{X}}F_{\gamma}(x)\). At iteration \(t\), update

\[x_{t+1}=\operatorname{Proj}_{\mathcal{X}}(x_{t}-\eta g_{F,t})\] (10)

with stepsize \(\eta\) and \(g_{F,t}\) as an estimate of \(\nabla F_{\gamma}(x_{t})\).

In the previous section, we have obtained the closed-form expressions of \(\nabla v(x)\) in (8) and \(\nabla F_{\gamma}(x)\) in (9). Evaluating the closed-form expression requires finding \((y^{*}_{g}(x_{t}),\mu^{*}_{g}(x_{t}))\) and \((y^{*}_{F}(x_{t}),\mu^{*}_{F}(x_{t}))\), the solutions to the max-min problem \(L_{g}(\mu,y;x)\) in (7) and \(L_{F}(\mu,y;x)\) in (5) respectively.

Given \(x_{t}\in\mathcal{X}\), we can use some minmax optimization solvers with \(T_{g}\) iterations on (7) and \(T_{F}\) iterations on (5) to find an \(\epsilon_{g}\)-solution \((y^{T_{g}}_{g,t},\mu^{T_{g}}_{g,t})\) and an \(\epsilon_{F}\)-solution \((y^{T_{F}}_{F,t},\mu^{T_{F}}_{F,t})\) satisfying

\[\|(y^{T_{g}}_{g,t},\mu^{T_{g}}_{g,t})-(y^{*}_{g}(x_{t}),\mu^{*}_{g}(x_{t}))\|^ {2}=\mathcal{O}(\epsilon_{g});\quad\|(y^{T_{F}}_{F,t},\mu^{T_{F}}_{F,t})-(y^{* }_{F}(x_{t}),\mu^{*}_{F}(x_{t}))\|^{2}=\mathcal{O}(\epsilon_{F})\] (11)

for target estimation accuracy \(\epsilon_{g},\epsilon_{F}>0\). Such an effective minmax optimization solver will be introduced in the following Section 3.2. In this way, \(\nabla v(x_{t})\) in (9) can be estimated as

\[g_{v,t}=\nabla_{x}g(x_{t},y^{T_{g}}_{g,t})+\langle\mu^{T_{g}}_{g,t},\nabla_{x} g^{c}(x_{t},y^{T_{g}}_{g,t})\rangle.\] (12)

Leveraging \(g_{v,t}\), the gradient \(\nabla F_{\gamma}(x)\) can be estimated via (8) as

\[g_{F,t}=\nabla_{x}f(x_{t},y^{T_{F}}_{F,t})+\gamma\left(\nabla_{x}g(x_{t},y^{T_ {F}}_{F,t})-g_{v,t}\right)+\langle\mu^{T_{F}}_{F},\nabla_{x}g^{c}(x,y^{T_{F}}_ {F,t})\rangle.\] (13)

We summarize the oracle for finding \(\min F_{\gamma}(x)\) as in Algorithm 1, which we term BLOCC, an algorithm designed for BiLevel Optimization with Coupled Constraints. Notably, our BLOCC algorithm can be seamlessly integrated with any MaxMin Solver (or min-max solver) that converges to the optimal solutions of the max-min subproblems by achieving (11). In the following, we present the convergence result of it allowing estimation error \(\epsilon_{g},\epsilon_{F}>0\) from the MaxMin Solver.

```
1:inputs: initial points \(x_{0},y_{g,0},\mu_{g,0},y_{F,0}\), \(\mu_{F,0}\); stepsize \(\eta\), \(\eta_{g}\), \(\eta_{F}\); counters \(T_{g}\), \(T_{F}\).
2:for\(t=0,1,\ldots,T\)do
3:\((y^{T_{g}}_{g,t},\mu^{T_{g}}_{g,t})=\textsf{MaxMin}(T_{g},T^{g}_{g})\)
4:\((y^{T_{F}}_{F,t},\mu^{T_{F}}_{F,t})=\textsf{MaxMin}(T_{F},T^{F}_{g})\)
5: update \(x_{t+1}\) via (10) \(\triangleright\) with \(g_{F,t}\) in (13)
6:endfor
7:outputs:\((x_{T},y^{T_{F}}_{F,T})\) ```

**Algorithm 1** Meta algorithm: BLOCC

**Theorem 2**.: _Suppose that the assumptions in Lemma 3 hold. Run Algorithm 1 with some effective inner MaxMin solver to find \((y^{T_{g}}_{g,t},\mu^{T_{g}}_{g,t})\) and \((y^{T_{F}}_{F,t},\mu^{T_{F}}_{F,t})\) respectively \(\mathcal{O}(\epsilon_{g})\) and \(\mathcal{O}(\epsilon_{F})\)-optimal in squared distance as in (11). Set \(\eta\leq\frac{1}{T_{F,1}}\) with some \(l_{F,1}\) defined in Lemma 3. It then holds that_

\[\frac{1}{T}\sum_{t=0}^{T-1}\|G_{\eta}(x_{t})\|^{2}:=\frac{1}{T\eta^{2}}\sum_{t= 0}^{T-1}\|(x_{t+1}-x_{t})\|^{2}= \mathcal{O}(\gamma T^{-1}+\gamma^{2}\epsilon_{F}+\gamma^{2}\epsilon_{g}).\] (14)

The proof is available in Appendix D.1. Using the projected gradient \(G_{\eta}=\eta^{-1}(x_{t+1}-x_{t})\) as the convergence metric for constrained optimization problems is standard [26]. The term \(\mathcal{O}(\gamma^{2}\epsilon_{F}+\gamma^{2}\epsilon_{g})\) arises from estimation errors using specific MaxMin Solver. Although the inner oracle can be any one that achieves (11), we value the computational effectiveness and therefore present a particular efficient solver Algorithm 2 in the following section.

### MaxMin Solver for the BLO with inequality CCs

In this section, we specify the MaxMin solver in Algorithm 1. By viewing \(L_{g}(\mu,y;x)\) in (7) and \(L_{F}(\mu,y;x)\) in (5) as \(L(\mu,y)\) for fixed given \(x\in\mathcal{X}\), we consider the following max-min problem

\[\max_{\mu\in\mathbb{R}^{d_{c}}_{+}}\min_{y\in\mathcal{Y}}L(\mu,y)\] (15)which is concave (linear) in \(\mu\) and strongly convex in \(y\). We can evaluate the dual function of \(L(\mu,y)\) defined below by finding \(y_{\mu}^{*}(\mu)\).

\[D(\mu):= \min_{y\in\mathcal{Y}}L(\mu,y)=L(\mu,y_{\mu}^{*}(\mu))\] (16) \[\text{where}\quad y_{\mu}^{*}(\mu):=\arg\min_{y\in\mathcal{Y}}L( \mu,y).\]

According to Danskin's theorem, we have \(\nabla D(\mu)=\nabla_{\mu}L(\mu,y_{\mu}^{*}(\mu))\). Taking either \(L_{g}(\mu,y;x)\) or \(L_{F}(\mu,y;x)\) as \(L(\mu,y)\) for given \(x\in\mathcal{X}\), \(D(\mu)\) defined as (16) exhibits favorable properties namely smoothness and concavity, with details illustrated in Lemma 10 in Appendix D.2. We can, therefore, apply accelerated gradient methods designed for smooth and convex functions such as [52, 4].

At each iteration \(t\), we first perform a momentum-based update step to update \(\mu_{t+\frac{1}{2}}\) as

\[\mu_{t+\frac{1}{2}}=\mu_{t}+\frac{t-1}{t+2}(\mu_{t}-\mu_{t-1}), \quad\text{with }\mu_{-1}=\mu_{0}.\] (17)

To evaluate \(\nabla D(\mu_{t+\frac{1}{2}})=\nabla_{\mu}L(\mu_{t+\frac{1}{2}},y_{\mu}^{*}( \mu_{t+\frac{1}{2}})\), with an arbitrary small target accuracy \(\epsilon>0\), we can run \(T_{y}=\mathcal{O}(\ln(\epsilon^{-1}))\) PGD steps on \(L(\mu_{t+\frac{1}{2}},y)\) in \(y\) via

\[y_{t,t_{y}+1}=\operatorname{Proj}_{\mathcal{Y}}\left(y_{t,t_{y}}- \eta_{1}\nabla_{y}L(\mu_{t+\frac{1}{2}},y_{t,t_{y}})\right).\] (18)

Defining the output after \(T_{y}\) iterations as \(y_{t+1}\), since strongly convexity of \(L(\mu,\cdot)\) ensures that PGD converges linearly [9, Theorem 3.10], it implies that \(\|y_{t+1}-y_{\mu}^{*}(\mu_{t+\frac{1}{2}})\|=\mathcal{O}(\epsilon)\). We can conduct

\[\mu_{t+1}=\operatorname{Proj}_{\mathbb{R}_{+}^{d_{c}}}(\mu_{t+ \frac{1}{2}}+\eta_{2}\nabla_{\mu}L(\mu_{t+\frac{1}{2}},y_{t+1})).\] (19)

We summarize this oracle in Algorithm 2 based on an accelerated method [52]. When we skip the momentum update, i.e. setting \(\mu_{t+\frac{1}{2}}=\mu_{t}\), it is a simple PGD method on \(D(\mu)\).

```
1:inputs: initial points \(y_{0}\), \(\mu_{0}\); stepsizes \(\eta_{1},\eta_{2}\); counters \(T,T_{y}\). Blue part is the version with acceleration; and red part is without.
2:for\(t=0,\dots,T-1\)do
3: update \(\mu_{t+\frac{1}{2}}\) via (17) or \(\mu_{t+\frac{1}{2}}=\mu_{t}\)
4:for\(t_{y}=0,\dots,T_{y}-1\)do
5: update \(y_{t,t_{y}+1}\) via (18) \(\triangleright\) set \(y_{t,0}=y_{t}\)
6:endfor
7: update \(\mu_{t+1}\) via (19) \(\triangleright\) set \(y_{t+1}=y_{t,T_{y}}\)
8:endfor
9:outputs:\((y_{T},\mu_{T})\) ```

**Algorithm 2** Subroutine on \(\mathsf{MaxMin}(T,T_{y})\)

However, for a convex function \(-D(\mu)\), the standard results only provide convergence of the function value, i.e. \(\max_{\mu\in\mathbb{R}_{+}^{d_{c}}}D(\mu)-D(\mu_{t})\stackrel{{ t \rightarrow\infty}}{{\longrightarrow}}0\). To establish the convergence of \(\|\mu_{g,t}^{T_{g}}-\mu_{g}^{*}(x_{t})\|\) and \(\|\mu_{F,t}^{T_{F}}-\mu_{F}^{*}(x_{t})\|\), we define the dual functions associated with inner problems (7) and (5) as

\[D_{g}(\mu)=\min_{y\in\mathcal{Y}}L_{g}(\mu,y;x)\quad\text{ and }\quad D_{F}(\mu)=\min_{y\in\mathcal{Y}}L_{F}(\mu,y;x)\] (20)

and make the following curvature assumption near the optimum.

**Assumption 5**.: _There exist \(\delta_{g},\delta_{F}>0\) and \(C_{\delta_{g}},C_{\delta_{F}}>0\) such that_

\[\langle-\nabla D_{g}(\mu)+\nabla D_{g}(\mu_{g}^{*}(x)),\mu-\mu_{g }^{*}(x)\rangle\geq C_{\delta_{g}}\|\mu-\mu_{g}^{*}(x)\|^{2},\quad\forall\mu \in\mathcal{B}(\mu_{g}^{*}(x);\delta_{g}),\] (21a) \[\langle-\nabla D_{F}(\mu)+\nabla D_{F}(\mu_{F}^{*}(x)),\mu-\mu_{F }^{*}(x)\rangle\geq C_{\delta_{F}}\|\mu-\mu_{F}^{*}(x)\|^{2},\quad\forall\mu \in\mathcal{B}(\mu_{F}^{*}(x);\delta_{F}).\] (21b)

It is worth noting that \(\langle-\nabla D_{g}(\mu)+\nabla D_{g}(\mu_{g}^{*}(x)),\mu-\mu_{g}^{*}(x)\rangle\geq\) 0 holds for all \(\mu\) due to concavity and in a neighborhood of the optimal, the equality only happens at the optimal due to the uniqueness of \(\mu_{g}^{*}(x)\). The same argument applies to \(D_{F}\) due to the concavity of the dual functions. Therefore, Assumption 5 essentially asserts a positive lower bound on the curvature of the left-hand side term, which is mild as it only applies to the neighborhood of the optima \(\mu_{g}^{*}(x)\) and \(\mu_{F}^{*}(x)\). It is also weaker than the local strong concavity or global restricted secant inequality (RSI) conditions.

By choosing Algorithm 2 with acceleration as the \(\mathsf{MaxMin}\) solver, we provide the convergence analysis of Algorithm 1 next, the proof of which can be found in Appendix D.2.

**Theorem 3**.: _Suppose that Assumptions 1-5 and the conditions in Theorem 2 hold. Let \(\gamma>\frac{l_{f,1}}{\alpha_{g}}\), \(\epsilon_{g}\leq\frac{C_{\delta_{g}}}{2}\delta_{g}\) and \(\epsilon_{F}\leq\frac{C_{\delta_{F}}}{2}\delta_{F}\). If we choose Algorithm 2 with acceleration as the inner loop and input \(T_{g}=\mathcal{O}(\epsilon_{g}^{-0.5}),T_{F}=\mathcal{O}(\epsilon_{F}^{-0.5})\), and \(T_{y}^{g}=\mathcal{O}(\ln(\epsilon_{g}^{-1})),T_{y}^{F}=\mathcal{O}(\ln(\epsilon_{ F}^{-1}))\) with proper constant stepsizes in Remark 3, then the iterates generated by the Algorithm 1 satisfy (11):_

\[\|(y_{g,t}^{T_{g}},\mu_{g,t}^{T_{g}})-(y_{g}^{*}(x_{t}),\mu_{g}^{*}(x_{t}))\|^{2} =\mathcal{O}(\epsilon_{g});\ \ \|(y_{F,t}^{T_{p}},\mu_{F,t}^{T_{F}})-(y_{F}^{*}(x_{t}),\mu_{F}^{*}(x_{t}))\|^{2}= \mathcal{O}(\epsilon_{F}).\]Theorem 3 concludes the \(\mathcal{O}(\epsilon_{g}^{-0.5})\) complexity for achieving \(\epsilon_{g}\)-optimal solutions for the constrained concave-strongly-convex problem \(\max_{\mu\in\mathbb{R}_{+}^{d_{x}}}\min_{y\in\mathcal{Y}}L(\mu,y)\), and so as for \(\epsilon_{F}\). For solving an \(\epsilon\)-approximation problem of BLO defined in (4), we solve \(\min_{x\in\mathcal{X}}F_{\gamma}(x)\) with \(\gamma=\mathcal{O}(\epsilon^{-0.5})\) according to Theorem 1. In this way, to achieve \(\frac{1}{T}\sum_{t=0}^{T-1}\|G_{\eta}(x_{t})\|^{2}=\mathcal{O}(\gamma T^{-1}+ \gamma^{2}\epsilon_{F}+\gamma^{2}\epsilon_{g})\leq\epsilon\) by (14), we need \(\epsilon_{g},\epsilon_{F}=\mathcal{O}(\epsilon^{2})\), i.e. complexity \(\tilde{\mathcal{O}}(\epsilon^{-1})\) for the MaxMin solver in Algorithm 2, and \(T=\mathcal{O}(\gamma\epsilon^{-1})=\mathcal{O}(\epsilon^{-1.5})\) for the number of iteration in BLOCC (Algorithm 1). Therefore, the overall complexity is \(\tilde{\mathcal{O}}(\epsilon^{-2.5})\), where \(\tilde{\mathcal{O}}\) omits the \(\ln\) terms.

Special case of the MaxMin Solver: \(g^{c}(x,y)\) being affine in \(y\) and \(\mathcal{Y}=\mathbb{R}^{d_{y}}\)

In this section, we investigate a special case of BLO with CCs where Assumption 5 automatically holds. Specifically, we focus on the case where \(g^{c}\) is affine in \(y\) and \(\mathcal{Y}=\mathbb{R}^{d_{y}}\), i.e.

\[g^{c}(x,y)=g_{1}^{c}(x)^{\top}y-g_{2}^{c}(x).\] (22)

In this case, fixing \(x\), taking \(L_{g}(\mu,y;x)\) in (7) and \(L_{F}(\mu,y;x)\) as \(L(\mu,y)\), (16) gives

\[D_{g}(\mu)= \min_{y\in\mathbb{R}^{d_{y}}}-\langle g_{2}^{c}(x),\mu\rangle+ \langle y,g_{1}^{c}(x)\mu\rangle+g(x,y)\quad\text{and}\] (23a) \[D_{F}(\mu)= \min_{y\in\mathbb{R}^{d_{y}}}-\langle g_{2}^{c}(x),\mu\rangle+ \langle y,g_{1}^{c}(x)\mu\rangle+f(x,y)+\gamma(g(x,y)-v(x)).\] (23b)

When \(g_{1}^{c}(x)\) is of full column rank, both \(D_{g}(\mu)\) and \(D_{F}(\mu)\) are strongly concave according to Lemma 13 in Appendix so that Assumption 5 holds globally. Moreover, when applying PGD on \(-D_{g}(\mu)\) and \(-D_{F}(\mu)\), strongly convexity guarantees linear convergence (Theorem 3.10 in [9]). Therefore, even without acceleration, Algorithm 2 with \(T_{y}\) sufficiently large performs PGD on \(-D(\mu)\) and it converges linearly up to inner loop accuracy. Moreover, PGD on \(L(\mu,y)\) in \(y\) also converges linearly. This motivates us to implement a single-loop version (\(T_{y}=1\)) of Algorithm 2.

When both \(y\) and \(\mu\) are unconstrained, the analysis has been established in [19]. However, as \(\mu\) is constrained to \(\mathbb{R}_{+}^{d_{e}}\) in the Lagrangian formulation for inequality constraints, the convergence analysis in [19] is not applicable, and the extension is nontrivial due to the non-differentiability of the projection. We address this technical challenge by treating \(\mathbb{R}_{+}^{d_{e}}\) as an inequality constraint and reformulating it as an unconstrained problem using Lagrange duality theory. This approach demonstrates that a single-loop \(T_{y}=1\) update in Algorithm 2, without acceleration, achieves linear convergence for the max-min problem (15). The detailed proof is provided in Appendix D.3.

Thus, by selecting the single-loop version (\(T_{y}=1\)) of Algorithm 2 without acceleration as the MaxMin solver in Algorithm 1, we establish the following theorem with proof available in Appendix D.3.

**Theorem 4** (Inner linear convergence).: _Consider BLO with \(\mathcal{Y}=\mathbb{R}^{d_{y}}\) and \(g^{c}(x,y)\) defined in (22). Suppose Assumptions 1-4 and the conditions in Theorem 2 hold. Suppose for any \(x\in\mathcal{X}\), there exist constants \(s_{\min}\) and \(s_{\max}\) such that \(0<s_{\min}\leq\sigma_{\min}(g_{1}^{c}(x))\leq\sigma_{\max}(g_{1}^{c}(x))\leq s _{\max}<\infty\). Let \(\gamma>\frac{l_{f,1}}{\alpha_{g}}\). If we choose Algorithm 2 without acceleration as the inner loop and input \(T_{g}=\mathcal{O}(\ln\bigl{(}\epsilon_{g}^{-1}\bigr{)}),T_{F}=\mathcal{O}(\ln \bigl{(}\epsilon_{F}^{-1}\bigr{)})\), and \(T_{y}^{g}=T_{y}^{F}=1\) with proper constant stepsizes in Remark 4, then the iterates generated by Algorithm 1 satisfy (11):_

\[\|(y_{g,t}^{T_{g}},\mu_{g,t}^{T_{g}})-(y_{g}^{*}(x_{t}),\mu_{g}^{*}(x_{t}))\|^{ 2}=\mathcal{O}(\epsilon_{g});\quad\|(y_{F,t}^{T_{g}},\mu_{F,t}^{T_{F}})-(y_{F} ^{*}(x_{t}),\mu_{F}^{*}(x_{t}))\|^{2}=\mathcal{O}(\epsilon_{F}).\]

Theorem 4 establishes, for the first time, the linear convergence of a strongly convex-concave maxim problem with a constrained maximization parameter. Similar to the previous analysis, we choose \(\gamma=\mathcal{O}(\epsilon^{-0.5})\) to solve the equivalent (2a) to \(\epsilon\)-approximation problem of BLO (4). To achieve \(\frac{1}{T}\sum_{t=0}^{T-1}\|G_{\eta}(x_{t})\|^{2}\leq\epsilon\), the number of iteration in BLOCC \(T=\mathcal{O}(\gamma\epsilon^{-1})=\mathcal{O}(\epsilon^{-1.5})\) by (14). As the inner MaxMin solver convergences linearly, the overall complexity is \(\tilde{\mathcal{O}}(\epsilon^{-1.5})\) where \(\tilde{\mathcal{O}}\) omits the \(\ln\) terms. We summarized the overall iteration complexity of our BLOCC algorithm in different settings in Table 1.

## 4 Numerical Experiments

This section reports the results of numerical experiments for three different problems: a toy example used to validate our method, an SVM training application, and a network design problem in both synthetic and real-world transportation scenarios. We provide sensitivity analysis and insights for hyper-parameter choices in Appendix G.1. In the two real-world experiments, we compare the proposed algorithm with two baselines, LV-HBA [75] and GAM [72]. The code is available at https://github.com/Liuyuan999/Penalty_Based_Lagrangian_Bilevel.

### Toy example

Consider the BLO problem with an inequality coupled constraint \(\mathcal{Y}(x):=\{y\in\mathcal{Y}:y-x\leq 0\}\), given by

\[\min_{x\in[0,3]} f(x,y_{g}^{*}(x))=\frac{e^{-y_{g}^{*}(x)+2}}{2+\cos(6x)}+\frac{1}{2} \ln\bigl{(}(4x-2)^{2}+1\bigr{)}\] \[\text{with} y_{g}^{*}(x)\in\text{arg}\min_{y\in\mathcal{Y}(x)}\ g(x,y)=(y-2x)^{2}.\] (24)

Problem (24) satisfies all assumptions for Theorem 2 and Theorem 4. The lower-level problem is strongly convex and \(y_{g}^{*}(x)=x\). Therefore, the BLO problem with inequality constraint in (24) reduces to \(\min_{x\in[0,3]}f(x,y)|_{y=x}\). In Figure 2, we plot the dashed line as the intersected line of the surface \(f(x,y)\) and the plane \(f(x,y_{g}^{*}(x))\), and the red points as the converged points by running BLOCC with \(\gamma=5\) and with 200 different initialization values. It can be seen that BLOCC consistently finds the local minima, verifying the effectiveness.

### Hyperparameter optimization for SVM

We test the performance of our algorithm BLOCC with \(\gamma=12\) when training a linear SVM model on the diabetes [20] and four-class datasets [29]. The model is trained via the BLO formulation (1) with inequality CCs; see the details in Appendix E. We compared performance with two baselines, LV-HBA [75] and GAM [72], as they are the only existing algorithms addressing coupled constraints and experimentally evaluated on SVM problems in their respective papers.

Table 2 shows that the model trained by our BLOCC algorithm outperforms that of GAM [72] significantly and is of a similar level as that of LV-HBA [75]. We present some of the performance plots for the diabetes dataset as in Figure 3. Looking into the test accuracy (left), our algorithm achieves more than 0.76 accuracy in the first 2 iterations, which is significantly better than the other ones. For the upper-level objective (middle), in the first few iterations, the loss decreases significantly under all algorithms, in which our BLOCC achieves the lowest results. Moreover, in Figure 3 (right), the lower-level optimum for LV-HBA was not attained until the very end. This indicates that the decrease of upper loss between 0-40 iterations in the middle figure may be due to the suboptimality of lower-level variables. For our BLOCC and GAM, the lower-level minimum is attained as lower-level objective \(g\geq 0\) in this case.

### Transportation network design problem

BLO is particularly relevant in transportation, where network planning must consider different time horizons and actors. Those problems are large-scale with a large number of upper- and lower-level variables and CCs, challenging the use of traditional BLO techniques, which involve expensive calculations of second order information. As a result, our final experiment considers a network design problem, where we act as an operator whose profit is modeled as the upper-level objective that is determined by the passengers' behavior, modeled in the lower-level. We considered three networks:

\begin{table}
\begin{tabular}{c||c|c} \hline Methods & diabetes & fourclass \\ \hline \hline
**BLOCC** & \(\mathbf{0.767\pm 0.039}\) & \(\mathbf{0.761\pm 0.014}\) \\ (**Ours**) & \(\mathbf{(1.729\pm 0.529)}\) & \(\mathbf{(1.922\pm 0.108)}\) \\ \hline \multirow{2}{*}{LV-HBA} & \(0.765\pm 0.039\) & \(0.748\pm 0.060\) \\  & \((2.899\pm 1.378)\) & \((2.404\pm 0.795)\) \\ \hline \multirow{2}{*}{GAM} & \(0.721\pm 0.047\) & \(0.715\pm 0.056\) \\  & \((8.752\pm 4.736)\) & \((13.481\pm 0.970)\) \\ \hline \hline \end{tabular}
\end{table}
Table 2: Numerical results on the training outcome of our BLOCC in comparison with LV-HBA [75] and GAM [72]. The first row represents accuracy mean \(\pm\) standard deviation, and the second row between brackets represents the running time until the upper-level objective’s update is smaller than 1e\({}^{-5}\).

Figure 2: 3-D plot of the upper-level objective \(f(x,y)\) of the toy example, with the line \(f(x,y)|_{y=x}\) shown in dashed red and the convergence points marked as red dots.

two synthetic networks of 3 and 9 nodes, respectively, and a real-world network of 26 nodes in the city of Seville, Spain. Further details about the formulation and the experiment can be found in Appendix F.

In this experiment, we only compare our BLOCC with LV-HBA [75] as the sole baseline, which is the only existing algorithm that addresses both coupled inequality \(g^{c}(x,y)\leq 0\) and domain constraints \(\mathcal{Y}\). GAM [72] and BVFSM [46] cannot handle lower-level domain constraints as they rely on the hypergradient of lower-level and require LL stationarity in an unconstrained space. From Table 3, we can see that LV-HBA failed to work efficiently, especially for large networks. This is mainly because the increased constraints render the projection step impracticable. Our BLOCC, in contrast, is much faster, and it successfully converges even with large real-world networks. We provided computational complexity analysis in Appendix H and we can conclude that our BLOCC is robust to large-scale problems.

## 5 Conclusions and Future Work

This paper proposed a novel primal-dual-assisted penalty reformulation for BLO problems with coupled lower-level constraints, and developed a new first-order method BLOCC to solve the resultant problem. The non-asymptotic convergence rate of our algorithm is \(\widetilde{\mathcal{O}}(\epsilon^{-2.5})\), tightening to \(\widetilde{\mathcal{O}}(\epsilon^{-1.5})\) when the lower-level constraints are affine in \(y\) without any other constraints. Our method achieves the best-known convergence rate and is projection-free, making it more favorable for large-scale, high-dimensional, constrained BLO problems. Experiments on SVM model training and transportation network planning showcased the effectiveness of our algorithm.

\begin{table}
\begin{tabular}{c||c|c|c|c|c} \hline \hline  & \multicolumn{2}{c|}{NN = 3, NV = 48} & \multicolumn{2}{c|}{NN = 9, NV = 2,262} & \multicolumn{2}{c}{NN = 26, NV = 49,216} \\  & NC = 24, NZ = 126 & NC = 678, NZ = 6,222 & NC = 13,336, NZ = 129,256 \\ Methods & Runtime (s) & UL utility & Runtime (s) & UL utility & Runtime (s) & UL utility \\ \hline \hline LV-HBA & \(3.51e2\) & 1.53 & 7 & / & / & / \\ BLOCC (Ours)-\(\gamma=2\) & \(2.02e1\) & 1.07 & \(7.27e2\) & 8.09 & \(6.82e4\) & 98.40 \\ BLOCC (Ours)-\(\gamma=3\) & \(2.00e1\) & 1.69 & \(8.50e2\) & 10.37 & \(6.42e4\) & 111.39 \\ BLOCC (Ours)-\(\gamma=4\) & \(2.01e1\) & 1.71 & \(8.68e2\) & 11.04 & \(6.70e4\) & 138.78 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Results of the transportation experiment, both in terms of running time (Runtime) and convergenced upper-level objective value (UL utility, larger there better), with stepsize \(\eta=1.6e-4\). We use ”/” for algorithms that cannot converge within 24 hours of execution. NN (Number of Nodes) is the number of stations in the network. Analogously, NV (Number of Variables), NC (Number of Constraints), and NNZ (Number of non-zero elements) are the number of optimization variables, constraints, and non-zero elements of the constraints matrix, respectively.

Figure 3: Test accuracy (left), upper loss \(f(x,y)\) (middle), and lower loss \(g(x,y)\) (right) for the SVM on the diabetes dataset. The experiments are executed for 50 different random train-validation-test splits, with the bold line representing the mean, and the shaded regions being the standard deviation.

## References

* [1] Seyed Mehdi Alizadeh, Patrice Marcotte, and Gilles Savard. Two-stage stochastic bilevel programming over a transportation network. _Transportation Research Part B: Methodological_, 58:92-105, 2013.
* [2] Aram V Arutyunov, Evgeniy R Avakov, and Alexey F Izmailov. Directional regularity and metric regularity. _SIAM Journal on Optimization_, 18(3):810-833, 2007.
* [3] Dominique Aze and Jean-Paul Penot. Uniformly convex and uniformly smooth convex functions. In _Annales de la Faculte des sciences de Toulouse: Mathematiques_, 1995.
* [4] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. _SIAM journal on imaging sciences_, 2(1):183-202, 2009.
* [5] Moshe E Ben-Akiva and Steven R Lerman. _Discrete choice analysis: theory and application to travel demand_, volume 9. MIT press, 1985.
* [6] J. Bolte, E. Pauwels, and S. Vaiter. Automatic differentiation of nonsmooth iterative algorithms. In _Advances in Neural Information Processing Systems_, 2022.
* [7] J Frederic Bonnnans and Alexander Shapiro. _Perturbation analysis of optimization problems_. Springer Science & Business Media, 2013.
* [8] Jerome Bracken and James T McGill. Mathematical programs with optimization problems in the constraints. _Operations Research_, 21(1):37-44, 1973.
* [9] Sebastien Bubeck. _Convex Optimization: Algorithms and Complexity_. Foundations and Trends(r) in Machine Learning, 2015.
* [10] Luis Cadarso and Angel Marin. Combining robustness and recovery in rapid transit network design. _Transportmetrica A: Transport Science_, 12:1-26, 11 2015.
* [11] Ennio Cascetta. _Transportation systems analysis: models and applications_, volume 29. Springer Science & Business Media, 2009.
* [12] Tianyi Chen, Yuejiao Sun, Quan Xiao, and Wotao Yin. A single-timescale method for stochastic bilevel optimization. In _International Conference on Artificial Intelligence and Statistics_, virtual, 2022.
* [13] Tianyi Chen, Yuejiao Sun, and Wotao Yin. Closing the gap: Tighter analysis of alternating stochastic gradient methods for bilevel problems. In _Advances in Neural Information Processing Systems_, Virtual, 2021.
* [14] Benoit Colson, Patrice Marcotte, and Gilles Savard. An overview of bilevel optimization. _Annals of operations research_, 153(1):235-256, 2007.
* [15] Jean-Philippe Cote, Patrice Marcotte, and Gilles Savard. A bilevel modelling approach to pricing and fare optimisation in the airline industry. _Journal of Revenue and Pricing Management_, 2:23-36, 2003.
* [16] Olivier Devolder, Francois Glineur, and Yurii Nesterov. First-order methods of smooth convex optimization with inexact oracle. _Mathematical Programming_, 146:37-75, 2014.
* [17] Asen L Dontchev and R Tyrrell Rockafellar. _Implicit functions and solution mappings_, volume 543. Springer, 2009.
* [18] Dmitriy Drusvyatskiy and Adrian S Lewis. Error bounds, quadratic growth, and linear convergence of proximal methods. _Mathematics of Operations Research_, 43(3):919-948, 2018.
* [19] Simon S Du and Wei Hu. Linear convergence of the primal-dual gradient method for convex-concave saddle point problems without strong convexity. In _The 22nd International Conference on Artificial Intelligence and Statistics_, pages 196-205, 2019.
* [20] Dheeru Dua and Casey Graff. Uci machine learning repository, 2017. Accessed: 2024-05-21.

* [21] Laureano Escudero and Susana Munoz. An approach for solving a modification of the extended rapid transit network design problem. _Top_, 17:320-334, 12 2009.
* [22] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. In _International Conference on Machine Learning_, pages 1126-1135, Sydney, Australia, 2017.
* [23] Luca Franceschi, Michele Donini, Paolo Frasconi, and Massimiliano Pontil. Forward and reverse gradient-based hyperparameter optimization. In _International Conference on Machine Learning_, pages 1165-1173, 2017.
* [24] Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimiliano Pontil. Bilevel programming for hyperparameter optimization and meta-learning. In _International Conference on Machine Learning_, Stockholm, Sweden, 2018.
* [25] Lucy L Gao, Jane Ye, Haian Yin, Shangzhi Zeng, and Jin Zhang. Value function based difference-of-convex algorithm for bilevel hyperparameter selection problems. In _International Conference on Machine Learning_, pages 7164-7182, Baltimore, MD, 2022.
* [26] Saeed Ghadimi, Guanghui Lan, and Hongchao Zhang. Mini-batch stochastic approximation methods for nonconvex stochastic composite optimization. _Mathematical Programming_, 155(1):267-305, 2016.
* [27] Saeed Ghadimi and Mengdi Wang. Approximation methods for bilevel programming. _arXiv preprint arXiv:1802.02246_, 2018.
* [28] Riccardo Grazzi, Luca Franceschi, Massimiliano Pontil, and Saverio Salzo. On the iteration complexity of hypergradient computation. In _International Conference on Machine Learning_, pages 3748-3758, virtual, 2020.
* [29] Tin Kam Ho and Eugene M Kleinberg. Building projectable classifiers of arbitrary complexity. In _Proceedings of 13th International Conference on Pattern Recognition_, volume 2, pages 880-885, 1996.
* [30] Thomas Hofmann, Bernhard Scholkopf, and Alexander J Smola. Kernel methods in machine learning. 2008.
* [31] Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. A two-timescale framework for bilevel optimization: Complexity analysis and application to actor-critic. _SIAM Journal on Optimization_, 33(1), 2023.
* [32] Kazufumi Ito and Karl Kunisch. _Lagrange Multiplier Approach to Variational Problems and Applications_, volume 15 of _Advances in Design and Control_. Not specified in the provided information, 2008. Includes bibliographical references and index.
* [33] Kaiyi Ji, Mingrui Liu, Yingbin Liang, and Lei Ying. Will bilevel optimizers benefit from loops. _arXiv preprint arXiv:2205.14224_, 2022.
* [34] Kaiyi Ji, Junjie Yang, and Yingbin Liang. Provably faster algorithms for bilevel optimization and applications to meta-learning. In _Advances in Neural Information Processing Systems_, 2020.
* [35] Kaiyi Ji, Junjie Yang, and Yingbin Liang. Bilevel optimization: Convergence analysis and enhanced design. In _International Conference on Machine Learning_, virtual, 2021.
* [36] Sham Kakade, Shai Shalev-Shwartz, Ambuj Tewari, et al. On the duality of strong convexity and strong smoothness: Learning applications and matrix regularization. _Unpublished Manuscript, http://ttic.uchicago. edu/shai/papers/KakadeShalevTewari09. pdf_, 2(1):35, 2009.
* [37] Hamed Karimi, Julie Nutini, and Mark Schmidt. Linear convergence of gradient and proximal-gradient methods under the polyak-lojasiewicz condition. In _Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2016, Riva del Garda, Italy, September 19-23, 2016, Proceedings, Part I 16_, pages 795-811, 2016.

* [38] Narendra Karmarkar. A new polynomial-time algorithm for linear programming. In _Proceedings of the sixteenth annual ACM symposium on Theory of computing_, pages 302-311, 1984.
* [39] Prashant Khanduri, Ioannis Tsaknakis, Yihua Zhang, Jia Liu, Sijia Liu, Jiawei Zhang, and Mingyi Hong. Linearly constrained bilevel optimization: A smoothed implicit gradient approach. In _International Conference on Machine Learning_, pages 16291-16325, 2023.
* [40] Prashant Khanduri, Siliang Zeng, Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. A near-optimal algorithm for stochastic bilevel optimization via double-momentum. In _Advances in Neural Information Processing Systems_, Virtual, 2021.
* [41] Jeongyeol Kwon, Dohyun Kwon, Stephen Wright, and Robert D Nowak. A fully first-order method for stochastic bilevel optimization. In _International Conference on Machine Learning_, pages 18083-18113, 2023.
* [42] Jeongyeol Kwon, Dohyun Kwon, Steve Wright, and Robert Nowak. On penalty methods for nonconvex bilevel optimization and first-order stochastic approximation. In _International Conference on Learning Representations_, Vienna, Austria, 2024.
* [43] Junyi Li, Bin Gu, and Heng Huang. A fully single loop algorithm for bilevel optimization without hessian inverse. In _Association for the Advancement of Artificial Intelligence_, pages 7426-7434, virtual, 2022.
* [44] Bo Liu, Mao Ye, Stephen Wright, Peter Stone, and Qiang Liu. Bome! bilevel optimization made easy: A simple first-order approach. _Advances in neural information processing systems_, 35:17248-17262, 2022.
* [45] Risheng Liu, Xuan Liu, Xiaoming Yuan, Shangzhi Zeng, and Jin Zhang. A value-function-based interior-point method for non-convex bi-level optimization. In _International conference on machine learning_, pages 6882-6892, 2021.
* [46] Risheng Liu, Xuan Liu, Shangzhi Zeng, Jin Zhang, and Yixuan Zhang. Value-function-based sequential minimization for bi-level optimization. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, 2023.
* [47] Risheng Liu, Yaohua Liu, Shangzhi Zeng, and Jin Zhang. Towards gradient-based bilevel optimization with non-convex followers and beyond. In _Advances in Neural Information Processing Systems_, volume 34, pages 8662-8675, 2021.
* [48] Songtao Lu. SIm: A smoothed first-order lagrangian method for structured constrained nonconvex optimization. _Advances in Neural Information Processing Systems_, 36, 2023.
* [49] Dougal Maclaurin, David Duvenaud, and Ryan Adams. Gradient-based hyperparameter optimization through reversible learning. In _International Conference on Machine Learning_, pages 2113-2122, Lille, France, 2015.
* [50] Patrice Marcotte. Network design problem with congestion effects: A case of bilevel programming. _Mathematical programming_, 34(2):142-162, 1986.
* [51] Akshay Mehra and Jihun Hamm. Penalty method for inversion-free deep bilevel optimization. In _Asian conference on machine learning_, pages 347-362, 2021.
* [52] Yu Nesterov. Smooth minimization of non-smooth functions. _Mathematical programming_, 103:127-152, 2005.
* [53] Alex Nichol, Joshua Achiam, and John Schulman. On first-order meta-learning algorithms. _arXiv preprint arXiv:1803.02999_, 2018.
* [54] Norbert Oppenheim. Equilibrium trip distribution/assignment with variable destination costs. _Transportation Research Part B: Methodological_, 27(3):207-217, 1993.
* [55] Fabian Pedregosa. Hyperparameter optimization with approximate gradient. In _International conference on machine learning_, pages 737-746, 2016.

* [56] Fernando Real-Rojas. Diseno de redes de transporte: integrando la competencia modal con tecnicas de optimizacion convexa, BSc Thesis, King Juan Carlos University. June 2024.
* [57] Fernando Real-Rojas, Victor M. Tenorio, and Antonio G. Marques. A sparse nonlinear approach for designing hub-and-spoke air transportation networks. In _Asilomar Conference on Signals, Systems, and Computers_, Pacific Grove, CA, 2024.
* [58] R. Tyrrell Rockafellar. _Convex Analysis_. Princeton University Press, Princeton, NJ, USA, 1970s.
* [59] Andrzej Ruszczynski. _Nonlinear Optimization_. Princeton University Press, 2006.
* [60] Amirreza Shaban, Ching-An Cheng, Nathan Hatch, and Byron Boots. Truncated backpropagation for bilevel optimization. In _The 22nd International Conference on Artificial Intelligence and Statistics_, pages 1723-1732, 2019.
* [61] Han Shen and Tianyi Chen. A single-timescale analysis for stochastic approximation with multiple coupled sequences. _Advances in Neural Information Processing Systems_, 35:17415-17429, 2022.
* [62] Han Shen, Quan Xiao, and Tianyi Chen. On penalty-based bilevel gradient descent method. In _International Conference on Machine Learning_, Honolulu, HI, 2023.
* [63] Han Shen, Zhuoran Yang, and Tianyi Chen. Principled penalty-based methods for bilevel reinforcement learning and RLHF. In _International Conference on Machine Learning_, Vienna, Austria, 2024.
* [64] Ankur Sinha, Samish Bedi, and Kalyanmoy Deb. Bilevel optimization based on kriging approximations of lower level optimal value function. In _2018 IEEE congress on evolutionary computation (CEC)_, pages 1-8. IEEE, 2018.
* [65] Ankur Sinha, Pekka Malo, and Kalyanmoy Deb. A review on bilevel optimization: from classical to evolutionary approaches and applications. _IEEE Transactions on Evolutionary Computation_, 22(2):276-295, 2017.
* [66] Daouda Sow, Kaiyi Ji, and Yingbin Liang. On the convergence theory for hessian-free bilevel algorithms. volume 35, pages 4136-4149, 2022.
* [67] Bradly Stadie, Lunjun Zhang, and Jimmy Ba. Learning intrinsic rewards as a bi-level optimization problem. In _Conference on Uncertainty in Artificial Intelligence_, virtual, 2020.
* [68] Luis N Vicente and Paul H Calamai. Bilevel and multilevel programming: A bibliography review. _Journal of Global optimization_, 5(3):291-306, 1994.
* [69] Gerd Wachsmuth. On licq and the uniqueness of lagrange multipliers. _Operations Research Letters_, 41(1):78-80, 2013.
* [70] Quan Xiao, Songtao Lu, and Tianyi Chen. A generalized alternating method for bilevel learning under the polyak-lojasiewicz condition. In _Advances in Neural Information Processing Systems_, 2023.
* [71] Quan Xiao, Han Shen, Wotao Yin, and Tianyi Chen. Alternating implicit projected sgd and its efficient variants for equality-constrained bilevel optimization. In _International Conference on Artificial Intelligence and Statistics_, 2023.
* [72] Siyuan Xu and Minghui Zhu. Efficient gradient approximation method for constrained bilevel optimization. In _Proceedings of the AAAI Conference on Artificial Intelligence_, 2023.
* [73] Haikuo Yang, Luo Luo, Chris Junchi Li, Michael Jordan, and Maryam Fazel. Accelerating inexact hypergradient descent for bilevel optimization. In _OPT 2023: Optimization for Machine Learning_, 2023.
* [74] Wei Yao, Haian Yin, Shangzhi Zeng, and Jin Zhang. Overcoming lower-level constraints in bilevel optimization: A novel approach with regularized gap functions. _arXiv preprint arXiv:2406.01992_, 2024.

* [75] Wei Yao, Chengming Yu, Shangzhi Zeng, and Jin Zhang. Constrained bi-level optimization: Proximal lagrangian value function approach and hessian-free algorithm. _arXiv preprint arXiv:2401.16164_, 2024.
* [76] Jane J Ye and Daoli Zhu. Optimality conditions for bilevel programming problems. _Optimization_, 33(1):9-27, 1995.
* [77] Jane J Ye, Daoli Zhu, and Qiji Jim Zhu. Exact penalization and necessary optimality conditions for generalized bilevel programming problems. _SIAM Journal on optimization_, 7(2):481-507, 1997.

**Supplementary Material for "A Primal-Dual-Assisted Penalty Approach to**

**Bilevel Optimization with Coupled Constraints"**

## Table of Contents

* A Preliminaries
* B Analysis of the Penalty-Based Lagrangian Reformulation
* B.1 Proof of Lemma 1
* B.2 Proof of Theorem 1
* C Analysis of the Differentiability of Value Functions
* C.1 Proof of Lemma 2
* C.2 Proof of Lemma 3
* D Convergence Analysis of the Main Result
* D.1 Proof of Theorem 2
* D.2 Proof of Theorem 3
* D.3 Proof of Theorem 4
* E Applications to Hyperparameter Optimization for SVM
* E.1 Problem formulation
* E.2 Experiment details
* F Applications to Transportation Network Planning
* F.1 Problem formulation
* F.2 Numerical results for the 3-node network
* F.3 Numerical results for the 9-node network
* F.4 Numerical results for the Seville network
* G Sensitivity Analysis
* G.1 Sensitivity analysis for the toy example
* G.2 Sensitivity Analysis for the 3-node network
* H Analysis of the Computational Complexity
* H.1 Complexity comparison
* H.2 Complexity analysis of BLOCC

## Appendix A Preliminaries

This section will provide some preliminaries for our subsequent analysis.

**Definition 5**.: _For a convex function \(h:\mathbb{R}^{d_{q}}\to\mathbb{R}\) whose domain is \(\mathcal{Q}\subseteq\mathbb{R}^{d_{q}}\), the Legendre conjugate of \(h^{*}:\mathcal{Q}^{*}\to\mathbb{R}\) is defined as:_

\[h^{*}(q):=\sup_{q^{\prime}\in\mathcal{Q}}\{\langle q^{\prime},q \rangle-h(q^{\prime})\}=-\inf_{q^{\prime}\in\mathcal{Q}}\{-\langle q^{\prime}, q\rangle+h(q^{\prime})\},\] \[\forall q\in\mathcal{Q}^{*}:=\{q\in\mathbb{R}^{d_{q}}\,:\sup_{q^{ \prime}\in\mathcal{Q}}\{\langle q^{\prime},q\rangle-h(q^{\prime})\}<\infty\}.\]

**Remark 1**.: _When \(h\) is strongly convex in \(\mathbb{R}^{d_{q}}\), it is lower bounded and therefore \(\mathcal{Q}^{*}=\mathbb{R}^{d_{q}}\)._

**Lemma 4**.: _Suppose \(h:\mathbb{R}^{d_{q}}\to\mathbb{R}\) is \(l_{h,1}\)-smooth and \(\alpha_{h}\)-strongly convex and its domain \(\mathcal{Q}\subseteq\mathbb{R}^{d_{q}}\) is convex, closed and non-empty._

1. _If_ \(\mathcal{Q}=\mathbb{R}^{d_{q}}\)_, the gradient mappings_ \(\nabla h\) _and_ \(\nabla h^{*}\) _are inverse of each other (_[_58_]__); and_ \(h^{*}:\mathbb{R}^{d_{q}}\to\mathbb{R}\) _is_ \(\frac{1}{\alpha_{h}}\)_-smooth and_ \(\frac{1}{l_{h,1}}\)_-strongly convex (Proposition_ 2.6 _[_3_]__)._2. If \(\mathcal{Q}\subset\mathbb{R}^{d_{q}}\), \(h^{*}\) is \(\frac{1}{\alpha_{n}}\)-smooth ([36]) and and convex (Theorem 4.43 [32]).

**Lemma 5**.: _Suppose \(\mathcal{Q}\subseteq\mathbb{R}^{d_{q}}\) is convex, closed and non-empty, \(h:\mathbb{R}^{d_{q}}\to\mathbb{R}\) is strongly convex on \(\mathcal{Q}\), \(h^{c}:\mathbb{R}^{d_{q}}\to\mathbb{R}^{d_{c}}\) is convex on \(\mathcal{Q}\) and \(d_{c}\) is finite, and \(\{q\in\mathcal{Q}:h^{c}(q)\leq 0\}\) is non-empty._

1. _The problem_ \(\min_{q\in\{\mathcal{Q}:h^{c}(q)\leq 0\}}h(q)\) _has a unique feasible solution._
2. _When linear independence constraint qualification (LICQ) condition holds for_ \(h^{c}(q)\)_, the Lagrange multiplier for the problem_ \(\min_{q\in\{q\in\mathcal{Q}:h^{c}(q)\leq 0\}}h(q)\)_, i.e. solution to the problem_ \(\max_{\mu\in\mathbb{R}^{d_{c}}_{+}}\min_{q\in\mathcal{Q}}h(q)+\langle\mu,h^{c }(q)\rangle\) _is unique_ _[_69_]__._

**Lemma 6** (Lemma 3.1 in [9]).: _Suppose \(\mathcal{Q}\subseteq\mathbb{R}^{d_{q}}\) is convex, closed, and nonempty. For any \(q_{1}\in\mathbb{R}^{d_{q}}\) and any \(q_{2}\in\mathcal{Q}\), it follows that_

\[\langle\operatorname{Proj}_{\mathcal{Q}}(q_{1})-q_{2},\operatorname{Proj}_{ \mathcal{Q}}(q_{1})-q_{1}\rangle\leq 0.\] (25)

_In this way, take \(q_{1}=q_{3}-\eta g\) for any \(q_{3}\in\mathcal{Q}\), and denote \(q_{3}^{\eta,g}=\operatorname{Proj}_{\mathcal{Q}}(q_{3}-\eta g)\) as a projected gradient update in direction \(g\) with stepsize \(\eta\), we have,_

\[\langle g,q_{3}^{\eta,g}-q_{2}\rangle\leq-\frac{1}{\eta}\langle q_{3}^{\eta,g} -q_{2},q_{3}^{\eta,g}-q_{3}\rangle,\quad\forall q_{2},q_{3}\in\mathcal{Q}.\] (26)

**Lemma 7** (Theorem 3.10 [9]).: _Suppose a differentiable function \(h\) is \(l_{h,1}\)-smooth and \(\alpha_{h_{2}}\)-strongly convex. Consider the constrained problem \(\min_{q\in\mathcal{Q}}h(q)\) where \(\mathcal{Q}\) is non-empty, closed and convex. Projected Gradient Descent with \(\eta\leq\frac{1}{l_{h,1}}\) converges linearly to the unique \(q^{*}=\arg\min_{q\in\mathcal{Q}}h(q)\):_

\[\|\operatorname{Proj}_{\mathcal{Q}}(q-\eta\nabla h(q))-q^{*}\|\leq(1-\alpha \eta)^{1/2}\|q-q^{*}\|\leq(1-\alpha\eta/2)\|q-q^{*}\|,\quad\forall q\in \mathcal{Q}.\] (27)

## Appendix B Analysis of the Penalty-Based Lagrangian Reformulation

### Proof of Lemma 1

According to Lemma 5, for any fixed \(x\), there exists a unique \(\mu_{g}^{*}(x)\). Therefore, according to Lagrange duality theorem, for any fixed \(x\), the primal problem

\[\min_{y\in\mathcal{Y}}g(x,y)\quad\text{s.t.}\quad g^{c}(x,y)\leq 0\quad \Leftrightarrow\quad\min_{y\in\mathcal{Y}}g(x,y)+\langle\mu_{g}^{*}(x),g^{c}( x,y)\rangle.\]

As \(g(x,y)\) is \(\alpha_{g}\)-strongly convex in \(y\) and \(g^{c}(x,y)\) is convex in \(y\), we know \(g(x,y)+\langle\mu_{g}^{*}(x),g^{c}(x,y)\rangle\) is \(\alpha_{g}\)-strongly convex in \(y\), where the modulus \(\alpha_{g}\) is independent of \(x\). Therefore, according to Appendix F and G in [37], and Theorem 3.3 in [18], the quadratic growth in statement 1 can be concluded.

As \(g(x,y)\) is strongly convex in \(y\), and \(\mathcal{Y}(x)\) is a non-empty, closed and convex set under assumption 3, there exists a unique solution \(y_{g}^{*}(x)\) such that \(g(x,y_{g}^{*}(x))=v(x)\) by Lemma 5. In this way, if \(y\neq y_{g}^{*}(x)\) and \(y\in\mathcal{Y}(x)\), we have \(g(x,y)>v(x)\). This completes the proof of statement 2.

### Proof of Theorem 1

We know from Lemma 1 that \(g(x,y)-v(x)\geq\frac{\alpha_{g}}{2}\|y-y_{g}^{*}(x)\|^{2}\) and \(g(x,y)=v(x)\) if and only if \(y=y_{g}^{*}(x)\). This is squared-distance bound follows Definition 1 in [62]. Under Lipschitzness of \(f(x,y)\) with respect to \(y\), finding the solutions to the \(\epsilon\)-approximate problem in (4) is equivalent to finding the solutions to its penalty reformulation

\[\min_{(x,y)\in\{\langle x\times\mathcal{Y}:g^{c}(x,y)\leq 0\}}f(x,y)+\gamma(g(x,y)-v( x))\] (28)

with \(\gamma=\mathcal{O}(\epsilon^{-0.5})\) following Theorems 1 and 2 in [62].

Moreover, jointly finding solution for \((x,y)\) in (28) is in equivalence to finding solutions in

\[\min_{x\in\mathcal{X}}\min_{y\in\mathcal{Y}(x)}f(x,y)+\gamma(g(x,y)-v(x)).\] (29)The proof of this equivalence is as follows. Suppose \((x_{0},y_{0})\in\{\mathcal{X}\times\mathcal{Y}:g^{c}(x,y)\leq 0\}\) being a solution to (28). Suppose for any \(x\in\mathcal{X}\), \(y_{F}^{*}(x)\in\arg\min_{y\in\mathcal{Y}(x)}f(x,y)+\gamma(g(x,y)-v(x))\). We know that for any \(x\in\mathcal{X}\), \(y\in\mathcal{Y}(x)\), it follows that

\[f(x_{0},y_{0})+\gamma(g(x_{0},y_{0})-v(x_{0}))\leq f(x,y_{F}^{*}(x))+\gamma(g(x,y_{F}^{*}(x))-v(x))\] \[\leq f(x,y)+\gamma(g(x,y)-v(x)).\]

This means any solution to (28) is a solution to (29). On the other hand, suppose \(x_{0}\in\mathcal{X}\), \(y_{F}^{*}(x_{0})\in\mathcal{Y}(x_{0})\) is a solution to (29). We know that for any \((x,y)\in\{\mathcal{X}\times\mathcal{Y}:g^{c}(x,y)\leq 0\}\),

\[f(x_{0},y_{F}^{*}(x_{0}))+\gamma(g(x_{0},y_{F}^{*}(x_{0}))-v(x_{0 }))\leq f(x,y_{F}^{*}(x))+\gamma(g(x,y_{F}^{*}(x))-v(x))\] \[\leq f(x,y)+\gamma(g(x,y)-v(x)).\]

This means any solution to (29) is a solution to (28).

Besides, we know \(f(x,y)\) is \(l_{f,1}\)-smooth, \(g(x,y)\) is \(\alpha_{g}\)-strongly convex in \(y\). By the definitions of strongly convexity and smoothness, we know for fixed \(x\), for any \(y_{1},y_{2}\in\mathcal{Y}\),

\[f(x,y_{1})+\gamma(g(x,y_{1})-v(x))-f(x,y_{2})+\gamma(g(x,y_{2})-v (x))\] \[= f(x,y_{1})-f(x,y_{2})+\gamma(g(x,y_{1})-g(x,y_{2}))\] \[\geq \langle\nabla_{y}f(x,y_{2}),y_{1}-y_{2}\rangle-\frac{l_{f,1}}{2} \|y_{1}-y_{2}\|^{2}+\gamma\langle\nabla_{y}g(x,y_{2}),y_{1}-y_{2}\rangle+ \gamma\frac{\alpha_{g}}{2}\|y_{1}-y_{2}\|^{2}\] \[= \langle\nabla_{y}f(x,y_{2})+\gamma\nabla_{y}g(x,y_{2}),y_{1}-y_{2 }\rangle+\frac{\gamma\alpha_{g}-l_{f,1}}{2}\|y_{1}-y_{2}\|^{2}.\] (30)

This proves that \(f(x,y)+\gamma(g(x,y)-v(x))\) is \((\gamma\alpha_{g}-l_{f,1})\)-strongly convex in \(y\). Moreover, according to Assumption 2, the constraint \(g^{c}(x,y)\) is convex in \(y\), and \(\min_{y\in\mathcal{Y}(x)}f(x,y)+\gamma(g(x,y)-v(x))\) is equivalent to its equivalent _Lagrangian Dual Form_[59]

\[\max_{\mu\in\mathbb{R}_{+}^{d_{e}}}\min_{y\in\mathcal{Y}}f(x,y)+\gamma(g(x,y)- v(x))+\langle\mu,g^{c}(x,y)\rangle.\] (31)

Therefore, (28) can be recovered to (2a) and this completes the proof.

## Appendix C Analysis of the Differentiability of Value Functions

**Lemma 8** (Theorem 2.16 in [32]).: _Suppose \(h(x,y)\) is strongly convex in \(y\in\mathcal{Y}\) and is Lipschitz with respect to \(x\in\mathcal{X}\), \(h^{c}(x,y)\) is convex in \(y\) and is Lipschitz with respect to \(x\), and both \(\mathcal{Y}\) and \(\{y\in\mathcal{Y}:h^{c}(x,y)\leq 0\}\) are non-empty, closed, and convex. For the problem \(\min_{y\in\{y\in\mathcal{Y}:h^{c}(x,y)\leq 0\}}h(x,y)\), the unique solution \(y_{h}^{*}(x)\) and unique Lagrange multiplier \(\mu_{h}^{*}(x)\), defined as_

\[(y_{h}^{*}(x),\mu_{h}^{*}(x)):=\arg\max_{\mu\in\mathbb{R}_{+}^{d_{x}}}\min_{y \in\mathcal{Y}}h(x,y)+\langle\mu,h^{c}(x,y)\rangle,\] (32)

_is Lipschitz in \(x\). In other words, there exist \(L_{h}\geq 0\) that, for all \(x_{1},x_{2}\in\mathcal{X}\),_

\[\|(y_{h}^{*}(x_{1});\mu_{h}^{*}(x_{1}))-(y_{h}^{*}(x_{2});\mu_{h}^{*}(x_{2})) \|\leq L_{h}\|x_{1}-x_{2}\|.\]

Before proving Lemmas 2 and 3, we would like to introduce a more general form.

**Lemma 9**.: _Suppose \(\mathcal{Y}\) and \(\{y\in\mathcal{Y}:h^{c}(x,y)\leq 0\}\) are both non-empty, closed and convex, \(h(x,y)\) is jointly smooth in \((x,y)\) and is strongly convex in \(y\), \(h^{c}(x,y)\) is convex in \(y\), and both \(h(x,y)\) and \(h^{c}(x,y)\) are Lipschitz with respect to \(x\). Then we have_

\[v_{h}(x)=\min_{y\in\mathcal{Y}}h(x,y)\quad\text{s.t.}\quad h^{c}(x,y)\leq 0\]

_is differentiable with its gradient as_

\[\nabla v_{h}(x)=\nabla_{x}h(x,y_{h}^{*}(x))+\langle\mu_{h}^{*}(x),h^{c}(x,y_{h} ^{*}(x))\rangle,\] (33)

_where \((y_{h}^{*}(x),\mu_{h}^{*}(x))\) defined in (32) are unique._Proof.: We prove this using Theorem 4.24 in [7].

i) As \(h(x,y)\) being strongly convex in \(y\), Condition 1 in Theorem 4.24 in [7] is satisfied and the solution sets are of singleton value \((y_{h}^{*}(x),\mu_{h}^{*}(x))\) according to Lemma 5.

ii) Moreover, the smoothness of \(h(x,y)\) guarantees Robinson's constraint qualification [2], which implies the directional regularity condition (Definition 4.8 in [7]) for any direction \(d\) (Theorem 4.9. (ii) in [7]). This guarantees Condition 2 in Theorem 4.24 in [7] can be satisfied for all directions \(d\).

iii) Additionally, under the Lipschitzness of \(h(x,y)\) and \(h^{c}(x,y)\) with respect to \(x,y_{h}^{*}(x),\mu_{h}^{*}(x)\) are Lipschitz according to Lemma 8. This implies condition 3 in Theorem 4.24 in [7] holds.

In this way, all conditions in Theorem 4.24 in [7] hold and it gives the gradient as in (33) for unique \((y_{h}^{*}(x),\mu_{h}^{*}(x))\). This completes the proof. 

### Proof of Lemma 2

Proof.: The problem \(\min_{y\in\mathcal{Y}}g(x,y)\) s.t. \(g^{c}(x,y)\leq 0\) fits in the setting of Lemma 9 by taking \(h(x,y)=g(x,y)\) and \(h^{c}(x,y)=g^{c}(x,y)\). Therefore the derivative (8) can be obtained accordingly. Moreover, for any \(x_{1},x_{2}\in\mathcal{X}\),

\[\|\nabla v(x_{1})-\nabla v(x_{2})\|\] \[= \|\nabla_{x}g(x_{1},y_{g}^{*}(x_{1}))+\langle\mu_{g}^{*}(x_{1}), \nabla_{x}g^{c}(x_{1},y_{g}^{*}(x_{1}))\rangle-\nabla_{x}g(x_{2},y_{g}^{*}(x_ {2}))\] \[-\langle\mu_{g}^{*}(x_{2}),\nabla_{x}g^{c}(x_{2},y_{g}^{*}(x_{2} ))\rangle\|\] \[\overset{(a)}{\leq} \|\nabla_{x}g(x_{1},y_{g}^{*}(x_{1}))-\nabla_{x}g(x_{2},y_{g}^{*} (x_{2}))\|\] \[+\|\langle\mu_{g}^{*}(x_{1}),\nabla_{x}g^{c}(x_{1},y_{g}^{*}(x_{1 }))\rangle-\langle\mu_{g}^{*}(x_{1}),\nabla_{x}g^{c}(x_{2},y_{g}^{*}(x_{2})) \rangle\|\] \[+\|\langle\mu_{g}^{*}(x_{1}),\nabla_{x}g^{c}(x_{2},y_{g}^{*}(x_{2 }))\rangle-\langle\mu_{g}^{*}(x_{2}),\nabla_{x}g^{c}(x_{2},y_{g}^{*}(x_{2})) \rangle\|\] \[\overset{(b)}{\leq} (l_{g,1}+B_{g}l_{g^{c},1})(\|x_{1}-x_{2}\|+\|y_{g}^{*}(x_{1})-y_{ g}^{*}(x_{2})\|)+l_{g^{c},0}\|\mu_{g}^{*}(x_{1})-\mu_{g}^{*}(x_{2})\|\] \[\overset{(c)}{\leq} ((l_{g,1}+B_{g}l_{g^{c},1})(1+L_{g})+l_{g^{c},0}L_{g})\|x_{1}-x_{2}\|,\]

where \((a)\) follows triangle inequality; \((b)\) leverage on the Lipschitzness of \(\nabla g\), \(g^{c}\) and \(\nabla g^{c}\) in \(x\), and the upper bound for \(\|\mu_{g}^{*}(x)\|\); and \((c)\) uses the Lipschitzness of \(y_{g}^{*}(x)\) and \(\mu_{g}^{*}(x)\) from Lemma 8. As the bound is loose due to the use of triangle inequality, we can conclude that \(v(x)\) is \(l_{v,1}\)-smooth where \(l_{v,1}\leq((1+B_{g})(1+L_{g})l_{g^{c},1}+l_{g^{c},0}L_{g})\). 

### Proof of Lemma 3

By assumption, \(f(x,y)\) is \(l_{f,1}\)-smooth and \(g(x,y)\) is \(\alpha_{g}\)-strongly convex in \(y\). We know \(f(x,y)+\gamma(g(x,y)-v(x))\) is \((\gamma\alpha_{g}-l_{f,1})\)-strongly convex when \(\gamma>\frac{l_{f,1}}{\alpha_{g}}\) as discussed in (30). Moreover, constraint \(g^{c}(x,y)\) is convex in \(y\) by Assumption 2. In this way, the problem

\[\min_{y\in\mathcal{Y}}\:f(x,y)+\gamma(g(x,y)-v(x))\quad\text{ s.t. }g^{c}(x,y)\leq 0\]

features strong convexity according to Chapter 4 in [59] and it equals to

\[F_{\gamma}(x)=\max_{\mu\in\mathbb{R}_{+}^{d}}\min_{y\in\mathcal{Y}}f(x,y)+ \gamma(g(x,y)-v(x))+\langle\mu,g^{c}(x,y)\rangle.\]

Considering the smoothness of \(v(x)\) as presented in Lemma 2, all assumptions in Lemma 9 are satisfied. Therefore the derivative (9) can be obtained. In addition, for any \(x_{1},x_{2}\in\mathcal{X}\),

\[\|\nabla F(x_{1})-\nabla F(x_{2})\|\] \[= \|\nabla_{x}f(x_{1},y_{F}^{*}(x_{1}))+\gamma\left(\nabla_{x}g(x_{ 1},y_{F}^{*}(x_{1}))-\nabla v(x_{1})\right)+\langle\mu_{F}^{*}(x_{1}),\nabla_{ x}g^{c}(x_{1},y_{F}^{*}(x_{1}))\rangle\] \[-\nabla_{x}f(x_{2},y_{F}^{*}(x_{2}))-\gamma\left(\nabla_{x}g(x_{ 2},y_{F}^{*}(x_{2}))-\nabla v(x_{2})\right)-\langle\mu_{F}^{*}(x_{2}),\nabla_{ x}g^{c}(x_{2},y_{F}^{*}(x_{2}))\rangle\|\] \[\overset{(a)}{\leq} \|\nabla_{x}f(x_{1},y_{F}^{*}(x_{1}))-\nabla_{x}f(x_{2},y_{F}^{*}( x_{2}))\|+\gamma\|\nabla_{x}g(x_{1},y_{F}^{*}(x_{1}))-\nabla_{x}g(x_{2},y_{F}^{*}(x_{2}))\|\] \[+\gamma\|\nabla v(x_{1})-\nabla v(x_{2})\|+\|\langle\mu_{F}^{*}(x _{1}),\nabla_{x}g^{c}(x_{1},y_{F}^{*}(x_{1}))\rangle-\langle\mu_{F}^{*}(x_{1}), \nabla_{x}g^{c}(x_{2},y_{F}^{*}(x_{2}))\rangle\|\]\[\begin{split}&\quad+\|\langle\mu_{F}^{*}(x_{1}),\nabla_{x}g^{c}(x_{2},y_ {F}^{*}(x_{2}))\rangle-\langle\mu_{F}^{*}(x_{2}),\nabla_{x}g^{c}(x_{2},y_{F}^{ *}(x_{2}))\rangle\|\\ &\stackrel{{(b)}}{{\leq}}(l_{f,1}+\gamma l_{g,1}+B_ {F}l_{g^{c},1})(\|x_{1}-x_{2}\|+\|y_{F}^{*}(x_{1})-y_{F}^{*}(x_{2})\|)+\gamma l _{v,1}\|x_{1}-x_{2}\|\\ &\quad+l_{g^{c},0}\|\mu_{F}^{*}(x_{1})-\mu_{F}^{*}(x_{2})\|\\ &\stackrel{{(c)}}{{\leq}}((l_{f,1}+\gamma l_{g,1}+B_ {F}l_{g^{c},1})(1+L_{F})+\gamma l_{v,1}+l_{f^{c},0}L_{F})\|x_{1}-x_{2}\|,\end{split}\]

where \((a)\) follows triangle inequality; \((b)\) leverage on the Lipschitzness of \(\nabla f\), \(\nabla g\), \(g^{c}\) and \(\nabla g^{c}\) in \(x\), and the upper bound for \(\|\mu_{F}^{*}(x)\|\); and \((c)\) uses the Lipschitzness of \(y_{F}^{*}(x)\) and \(\mu_{F}^{*}(x)\) from Lemma 8. As the bound is loose due to the use of triangle equality, we can conclude that \(F(x)\) is \(l_{F,1}\)-smooth where \(l_{F,1}\leq(l_{f,1}+\gamma l_{g,1}+B_{F}l_{g^{c},1})(1+L_{F})+\gamma l_{v,1}+l _{f^{c},0}L_{F}\).

## Appendix D Convergence Analysis of the Main Result

### Proof of Theorem 2

Define the bias term \(b(x_{t})\) of the gradient \(\nabla F_{\gamma}(x_{t})\) as

\[b(x_{t}):= \nabla F_{\gamma}(x_{t})-g_{F,t}\] \[= \bigg{(}\nabla_{x}f(x_{t},y_{F}^{*}(x_{t}))+\gamma\big{(}\nabla_{ x}g(x,y_{F}^{*}(x_{t}))-\big{(}\nabla_{x}g(x_{t},y_{g}^{*}(x_{t}))+\big{\langle} \mu_{g}^{*}(x_{t}),\nabla_{x}g^{c}(x_{t},y_{g}^{*}(x_{t}))\big{\rangle}\, \big{)}\big{)}\] \[\quad+\langle\mu_{F}^{*}(x_{t}),\nabla_{x}g^{c}(x_{t},y_{F}^{*}(x _{t}))\rangle\,\bigg{)}\] \[-\bigg{(}\nabla_{x}f(x_{t},y_{F,t}^{T_{F}})+\gamma\,\Big{(}\nabla_ {x}g(x_{t},y_{F,t}^{T_{F}})-\Big{(}\nabla_{x}g(x_{t},y_{g,t}^{T_{g}})+\Big{ \langle}\mu_{g,t}^{T_{g}},\nabla_{x}g^{c}(x_{t},y_{g,t}^{T_{g}})\Big{\rangle} \Big{)}\Big{)}\] \[\quad+\langle\mu_{F}^{T_{F}},\nabla_{x}g^{c}(x_{t},y_{F,t}^{T_{F }})\rangle\bigg{)}.\]

In this way, we have

\[\|b(x_{t})\|\stackrel{{(a)}}{{\leq}} \|\nabla_{x}f(x_{t},y_{F,t}^{T_{F}})-\nabla_{x}f(x_{t},y_{F}^{*}( x_{t}))\|\] \[\quad+\gamma\Big{(}\|\nabla_{x}g(x_{t},y_{F,t}^{T_{F}})-\nabla_{ x}g(x_{t},y_{F}^{*}(x_{t}))\|+\|\nabla_{x}g(x_{t},y_{g,t}^{T_{g}})-\nabla_{x}g(x_{t},y_{ g}^{*}(x_{t}))\|\] \[\qquad\qquad+\Big{\|}\big{\langle}\mu_{g}^{*}(x_{t}),\nabla_{x}g^ {c}(x_{t},y_{g}^{*}(x_{t}))\big{\rangle}-\Big{\langle}\mu_{g}^{*}(x_{t}), \nabla_{x}g^{c}(x_{t},y_{g,t}^{T_{g}})\big{\rangle}\Big{\|}\] \[\qquad\qquad+\|\big{\langle}\mu_{g}^{*}(x_{t}),\nabla_{x}g^{c}(x_ {t},y_{g,t}^{T_{g}})\big{\rangle}-\Big{\langle}\mu_{g,t}^{T_{g}},\nabla_{x}g^{ c}(x_{t},y_{g,t}^{T_{g}})\big{\rangle}\Big{\|}\bigg{)}\] \[\quad+\|\langle\mu_{F}^{T_{F}},\nabla_{x}g^{c}(x_{t},y_{F,t}^{T_ {F}})\rangle-\langle\mu_{F}^{*}(x_{t}),\nabla_{x}g^{c}(x_{t},y_{F,t}^{T_{F}})\rangle\|\] \[\quad+\|\langle\mu_{F}^{*}(x_{t}),\nabla_{x}g^{c}(x_{t},y_{F,t}^{ T_{F}})\rangle-\langle\mu_{F}^{*}(x_{t}),\nabla_{x}g^{c}(x_{t},y_{F,t}^{*}(x_{t}))\rangle\|\] \[\stackrel{{(b)}}{{\leq}} l_{f,1}\|y_{F,t}^{T_{F}}-y_{F}^{*}(x_{t})\|+\gamma\bigg{(}l_{g,1}\| y_{F,t}^{T_{F}}-y_{F}^{*}(x_{t})\|+l_{g,1}\|y_{g,t}^{T_{g}}-y_{g}^{*}(x_{t})\|\] \[\qquad\qquad+l_{g^{c},0}\|\mu_{g,t}^{T_{g}}-\mu_{g}^{*}(x_{t}) \|+B_{g}l_{g^{c},1}\|y_{g,t}^{T_{g}}-y_{g}^{*}(x_{t})\|\bigg{)}\] \[\quad+l_{g^{c},0}\|\mu_{F,t}^{T_{F}}-\mu_{F}^{*}(x_{t})\|+B_{F}l_ {g^{c},1}\|y_{F,t}^{T_{g}}-y_{F}^{*}(x_{t})\|\] \[\stackrel{{(c)}}{{=}} (l_{f,1}+\gamma l_{g,1}+B_{F}l_{g^{c},0})\|y_{F,t}^{T_{F}}-y_{F}^{*} (x_{t})\|+l_{g^{c},0}\|\mu_{F,t}^{T_{F}}-\mu_{F}^{*}(x_{t})\|\] \[\quad+\gamma\left((l_{g,1}+B_{g}l_{g^{c},1})\|y_{g,t}^{T_{g}}-y_{g}^ {*}(x_{t})\|+l_{g^{c},0}\|\mu_{g,t}^{T_{g}}-\mu_{g}^{*}(x_{t})\|\right),\]

where \((a)\) uses triangle inequality, \((b)\) relies on the Lipschitzness of \(\nabla f\), \(\nabla g\), \(g^{c}\), and \(\nabla g^{c}\) in \(x\), the upper bounds for \(\|\mu_{F}^{*}(x)\|\) and \(\|\mu_{g}^{*}(x)\|\), and Cauchy-Schwartz inequality, and \((c)\) is by rearrangement.

Furthermore, according to Young's inequality, it follows that

\[\|b(x_{t})\|^{2}\leq 2\left((l_{f,1}+\gamma l_{g,1}+B_{F}l_{g^{c},0})\|y_{F,t}^{T_{g}}-y_ {F,t}^{*}\|+l_{g^{c},0}\|\mu_{F,t}^{T_{F}}-\mu_{F,t}^{*}\|\right)^{2}\] \[+2\gamma^{2}\left((l_{g,1}+B_{g}l_{g^{c},1})\|y_{g,t}^{T_{g}}-y_{g }^{*}(x_{t})\|+l_{g^{c},0}\|\mu_{g,t}^{T_{g}}-\mu_{g}^{*}(x_{t})\|\right)^{2}\] \[= \mathcal{O}(\gamma^{2}\epsilon_{F}+\gamma^{2}\epsilon_{g}).\]

According to Lemma 3, \(F_{\gamma}(x)\) is \(l_{F,1}\)-smooth in \(\mathcal{X}\). In this way, by the smoothness, we have

\[F(x_{t+1})\leq F(x_{t})+\langle\nabla F(x_{t}),x_{t+1}-x_{t}\rangle+\frac{l_{F, 1}}{2}\|x_{t+1}-x_{t}\|^{2}\] \[\leq F(x_{t})+\langle g_{F,t},x_{t+1}-x_{t}\rangle+\frac{1}{2\eta}\| x_{t+1}-x_{t}\|^{2}+\langle b(x_{t}),x_{t+1}-x_{t}\rangle,\] (34)

where the second inequality is by \(\eta\leq\frac{1}{l_{F,1}}\) and \(\nabla F(x_{t})=g_{F_{t}}+b(x_{t})\).

The projection guarantees that \(x_{t+1}\) and \(x_{t}\) are in \(\mathcal{X}\). Following Lemma 6, we know that

\[\langle g_{F,t},x_{t+1}-x_{t}\rangle\leq-\frac{1}{\eta}\|x_{t+1}-x_{t}\|^{2}.\]

Plugging this back to (34), it follows

\[F(x_{t+1})\leq F(x_{t})-\frac{1}{2\eta}\|x_{t+1}-x_{t}\|^{2}+\langle b(x_{t}),x_ {t+1}-x_{t}\rangle\] \[\leq F(x_{t})-\frac{1}{2\eta}\|x_{t+1}-x_{t}\|^{2}+\eta\|b(x_{t})\|^ {2}+\frac{1}{4\eta}\|x_{t+1}-x_{t}\|^{2}\] \[= F(x_{t})-\frac{1}{4\eta}\|x_{t+1}-x_{t}\|^{2}+\eta\|b(x_{t})\|^ {2},\]

where the second inequality is from Young's inequality. Telescoping therefore gives

\[\frac{1}{T}\sum_{t=0}^{T-1}\|G_{\eta}(x_{t})\|^{2}\leq \frac{4}{\eta T}(F(x_{0})-F(x_{T}))+\frac{4}{T}\sum_{t=0}^{T-1}\| b(x_{t})\|^{2}\] \[= \mathcal{O}(\eta^{-1}T^{-1})+O(\gamma^{2}\epsilon_{F}+\gamma^{2} \epsilon_{g})\] \[= \mathcal{O}(\gamma T^{-1}+\gamma^{2}\epsilon_{F}+\gamma^{2} \epsilon_{g})\]

where last equality comes from \(\eta=\mathcal{O}(\gamma^{-1})\) as \(\eta\leq\frac{1}{l_{F,1}}\) and \(l_{F,1}\leq(l_{f,1}+\gamma l_{g,1}+B_{F}l_{g^{c},1})(1+L_{F})+\gamma l_{v,1}+ l_{f^{c},0}L_{F}=\mathcal{O}(\gamma)\). This completes the proof.

### Proof of Theorem 3

To restate, we are viewing \(L_{g}(\mu,y;x)\) in (7) and \(L_{F}(\mu,y;x)\) in (5) respectively as \(L(\mu,y)\) and considering the following max-min problem

\[\max_{\mu\in\mathbb{R}^{d_{c}^{c}}_{\eta}}\min_{y\in\mathcal{Y}}L(\mu,y).\]

In (16), we defined the minimization part as

\[D(\mu):=\min_{y\in\mathcal{Y}}L(\mu,y)=L(\mu,y_{\mu}^{*}(\mu))\quad\text{where} \quad y_{\mu}^{*}(\mu):=\arg\min_{y\in\mathcal{Y}}L(\mu,y).\]

To evaluate \(D(\mu)\) for \(L_{g}(\mu,y;x)\) in (7) and \(L_{F}(\mu,y;x)\) in (5) as \(L(\mu,y)\), we define the following mappings for fixed \(x\in\mathcal{X}\):

\[y_{\mu,g}^{*}(\mu):= \arg\min_{y\in\mathcal{Y}}L_{g}(\mu,y;x),\] (35) \[y_{\mu,F}^{*}(\mu):= \arg\min_{y\in\mathcal{Y}}L_{F}(\mu,y;x).\] (36)In this way, for \(L_{g}(\mu,y;x)\) in (7) and \(L_{F}(\mu,y;x)\) in (5) respectively as \(L(\mu,y)\), \(D(\mu)\) defined in (16) equals to \(D_{g}(\mu)\) and \(D_{F}(\mu)\) respectively, where

\[D_{g}(\mu)= \min_{y\in\mathcal{Y}}L_{g}(\mu,y;x)=L_{g}(\mu,y^{*}_{\mu,g}(\mu); x),\] (37) \[D_{F}(\mu)= \min_{y\in\mathcal{Y}}L_{F}(\mu,y;x)=L_{F}(\mu,y^{*}_{\mu,F}(\mu) ;x).\] (38)

In the following lemma, we show that \(D(\mu)\) exhibits concavity and smoothness, which are favorable properties for conducting gradient-based algorithm.

**Lemma 10** (Smoothness and Concavity of \(D(\mu)\)).: _Suppose all the assumptions in Theorem 3 hold. For fixed \(x\in\mathcal{X}\), the following holds_

1. \(y^{*}_{\mu,g}(\mu)\) _in (_35_) and_ \(y^{*}_{\mu,F}(\mu)\) _in (_36_) are respectively_ \(\frac{1}{\alpha_{g}}\) _and_ \(\frac{1}{\gamma\alpha_{g}-l_{f,1}}\)_-Lipschitz to_ \(\mu\)_._
2. \(D_{g}(\mu)\) _in (_37_) is concave and_ \(\frac{l_{g^{c},0}}{\alpha_{g}}\)_-smooth, and_ \(D_{F}(\mu)\) _in (_38_) is concave and_ \(\frac{l_{g^{c},0}}{\gamma\alpha_{g}-l_{f,1}}\)_-smooth._

Proof.: To restate,

\[L_{g}(\mu,y;x)= g(x,y)+\langle\mu,g^{c}(x,y)\rangle,\] \[L_{F}(\mu,y;x)= f(x,y)+\gamma(g(x,y)-v(x))+\langle\mu,g^{c}(x,y)\rangle.\]

Under Assumption 1 and 2, for fixed \(x\) and given \(\mu\), \(L_{g}(\mu,y;x)\) is \(\alpha_{g}\)-strongly convex and \((l_{g,1}+\|\mu\|l_{g^{c},1})\)-smooth in \(y\), and \(L_{F}(\mu,y;x)\) is \((\gamma\alpha_{g}-l_{f,1})\)-strongly convex and \((l_{f,1}+\gamma l_{g,1}+\|\mu\|l_{g^{c},1})\)-smooth in \(y\). Therefore, we know \(y^{*}_{\mu,g}(\mu)\) in (35) and \(y^{*}_{\mu,F}(\mu)\) in (36) are respectively \(\frac{1}{\alpha_{g}}\) and \(\frac{1}{\gamma\alpha_{g}-l_{f,1}}\)-Lipschitz to \(\mu\) by directly quoting Theorem F.10 in [17] or Theorem 4.47 in [32]. This proves the first part of the Lemma.

For the second part, the concavity of \(D_{g}(\mu)\) and \(D_{F}(\mu)\) can be directly obtained by Lemma 2.58 in [59] as \(L_{g}(\mu,y;x)\) and \(L_{g}(\mu,y;x)\) are both convex in \(y\).

Moreover, following Theorem 4.24 in [7], we have

\[\nabla D_{g}(\mu)= \nabla_{\mu}L_{g}(\mu,y^{*}_{\mu,g}(\mu))=g^{c}(x,y^{*}_{\mu,g}( \mu)),\] \[\nabla D_{F}(\mu)= \nabla_{\mu}L_{F}(\mu,y^{*}_{\mu,F}(\mu))=g^{c}(x,y^{*}_{\mu,F}( \mu)).\]

As \(g^{c}(x,y)\) is \(l_{g^{c},0}\)-Lipschitz by Assumption 1, for any \(\mu_{1},\mu_{2}\in\mathbb{R}^{d_{c}}_{+}\):

\[\|\nabla D_{g}(\mu_{1})-\nabla D_{g}(\mu_{2})\|= \|g^{c}(x,y^{*}_{\mu,g}(\mu_{1}))-g^{c}(x,y^{*}_{\mu,g}(\mu_{2}))\|\] \[\leq l_{g^{c},0}\|y^{*}_{\mu,g}(\mu_{1})-y^{*}_{\mu,g}(\mu_{2})\|\leq \frac{l_{g^{c},0}}{\alpha_{g}}\|\mu_{1}-\mu_{2}\|,\] (39)

and similarly,

\[\|\nabla D_{F}(\mu_{1})-\nabla D_{F}(\mu_{2})\|= \|g^{c}(x,y^{*}_{\mu,F}(\mu_{1}))-g^{c}(x,y^{*}_{\mu,F}(\mu_{2}))\|\] \[\leq l_{g^{c},0}\|y^{*}_{\mu,F}(\mu_{1})-y^{*}_{\mu,F}(\mu_{2})\|\leq \frac{l_{g^{c},0}}{\gamma\alpha_{g}-l_{f,1}}\|\mu_{1}-\mu_{2}\|.\] (40)

We can conclude that \(D_{g}(\mu)\) and \(D_{F}(\mu)\) are respectively \(\frac{l_{g^{c},0}}{\alpha_{g}}\) and \(\frac{l_{g^{c},0}}{\gamma\alpha_{g}-l_{f,1}}\)-smooth. 

In Algorithm 2, we are implementing an accelerated projected gradient descent on \(-D(\mu)\) where the gradient bias is controlled by \(T_{y}\). Following [16], the following lemma presents the convergence analysis of the accelerated method on smooth and convex functions.

**Lemma 11** (Section 5 and 6 in [16]).: _Suppose \(D(\mu)\) is concave and \(l_{D,1}\)-smooth. Consider the constrained problem \(\max_{\mu\in\mathbb{R}^{d_{c}}_{+}}D(\mu)\). At iteration \(t=0,\ldots,T-1\), perform accelerated projected gradient update with stepsize \(\eta\leq\frac{1}{l_{D,1}}\) and initial value \(\mu_{0}=\mu_{-1}\):_

\[\mu_{t+\frac{1}{2}}= \mu_{t}+\frac{t-1}{t+2}(\mu_{t}-\mu_{t-1})\] (41a)\[\mu_{t+1}= \operatorname{Proj}_{\mathbb{R}^{d_{c}}_{+}}(\mu_{t+\frac{1}{2}}+\eta g _{t+\frac{1}{2}})\] (41b)

_where \(g_{t+\frac{1}{2}}\) is an \(\epsilon^{1.5}\)-approximate to \(\nabla D(\mu_{t+\frac{1}{2}})\) satisfying \(\|g_{t+\frac{1}{2}}\,-\nabla D(\mu_{t+\frac{1}{2}})\|=\mathcal{O}(\epsilon^{1.5})\). for a given accuracy \(\epsilon>0\). Denote \(D^{*}=\max_{\mu\in\mathbb{R}^{d_{c}}_{+}}D(\mu)\), performing \(T=\mathcal{O}(\epsilon^{-0.5})\) iterations leads to_

\[D^{*}-D(\mu_{T})=\mathcal{O}(\epsilon).\]

**Remark 2**.: _The domain for \(\mu\in\mathbb{R}^{d_{c}}_{+}\) can be replaced by any closed, convex, non-empty domain._

In this way, we are ready to proceed to the **proof of Theorem 3**.

proof of Theorem 3.: Algorithm 2 solves (7) and (5) by taking \(L_{g}(\mu,y;x)\) and \(L_{F}(\mu,y;x)\) respectively as \(L(\mu,y)\) and run respectively iterations \(T\) equals \(T_{g}\) and \(T_{F}\)

We begin our proof with analysis on (7). The accelerated version of Algorithm 2 solves this by taking \(L_{g}(\mu,y;x)\) in (7) with fixed \(x\in\mathcal{X}\) as \(L(\mu,y)\).

Fixing \(\mu_{t+\frac{1}{2}}\), steps 4-6 are \(T_{y}\)-step projected gradient descent in \(y\). As \(L_{g}(\mu,y;x)\) is \((l_{g,1}+l_{g^{c},1})\)-smooth and \(\alpha_{g}\)-strongly convex in \(y\), taking the inner loop stepsize \(\eta_{1}\) as \(\eta_{g,1}\leq\frac{1}{l_{g,1}+l_{g^{c},1}}\) ensures linear convergence according to Lemma 7. Choosing \(T_{y}=\mathcal{O}(\ln((\epsilon^{1.5})^{-1}))=\mathcal{O}(\ln(\epsilon_{g}^{- 1}))\) leads to

\[\|y_{t+1}-y^{*}_{\mu,g}(\mu_{t+\frac{1}{2}})\|=\mathcal{O}(\epsilon_{g}^{1.5})\]

for target accuracy \(\epsilon_{g}>0\) where \(y^{*}_{\mu,g}(\mu)\) is defined in (35).

In step 7, we update \(\mu\) with a projected gradient descent step which takes \(\nabla_{\mu}L(\mu_{t+\frac{1}{2}},y_{t+1})=g^{c}(x,y_{t+1})\) as an estimate of \(\nabla D_{g}(\mu_{t+\frac{1}{2}})=g^{c}(x,y_{\mu,g}^{*})\). The estimation bias is bounded by

\[\|\nabla_{\mu}L(\mu_{t+\frac{1}{2}},y_{t+1})-\nabla D_{g}(\mu_{t +\frac{1}{2}})\|= \|g^{c}(x,y_{t+1})-g^{c}(x,y_{\mu,g}^{*}(\mu_{t+\frac{1}{2}}))\|\] \[\leq l_{g^{c},0}\|y_{t+1}-y_{\mu,g}^{*}(\mu_{t+\frac{1}{2}})\|= \mathcal{O}(\epsilon_{g}^{1.5}).\]

By Lemma 11, we can conclude the complexity is \(\tilde{\mathcal{O}}(\epsilon_{g}^{-0.5})\) for conducting the accelerated version of Algorithm 2 on \(L_{g}(\mu,y;x)\) in (7) as \(L(\mu,y)\) to achieve

\[D_{g}(\mu_{g}^{*}(x))-D_{g}(\mu_{T_{g}})=\mathcal{O}(\epsilon_{g}).\] (42)

Similarly, the complexity of the accelerated version of Algorithm 2 for (5) is \(\tilde{\mathcal{O}}(\epsilon_{F}^{-0.5})\), i.e.,

\[D_{F}(\mu_{F}^{*}(x))-D_{F}(\mu_{T_{F}})=\mathcal{O}(\epsilon_{F}).\] (43)

In the following, we are going to show that (42) and (43) and respectively sufficient to bound \(\|\mu_{T_{g}}-\mu_{g}^{*}(x)\|\) and \(\|\mu_{T_{F}}-\mu_{F}^{*}(x)\|\) considering Assumption 5 is satisfied.

As \(D_{g}(\mu)\) and \(D_{F}(\mu)\) are both concave in \(\mu\) and \(\mu\in\mathbb{R}^{d_{c}}_{+}\) is equivalent to \(\mu\geq 0\), the problems

\[\max_{\mu\in\mathbb{R}^{d_{c}}_{+}}D_{g}(\mu)\quad\text{and}\quad\max_{\mu\in \mathbb{R}^{d_{c}}_{+}}D_{F}(\mu)\]

are respectively equivalent to the unconstrained problems

\[\max_{\mu\in\mathbb{R}^{d_{c}}}\tilde{D}_{g}(\mu):=D_{g}(\mu)+\lambda_{g}^{ \top}\mu\quad\text{and}\quad\max_{\mu\in\mathbb{R}^{d_{c}}}\tilde{D}_{F}(\mu):= D_{F}(\mu)+\lambda_{F}^{\top}\mu\]

with the Lagrange multipliers \(\lambda_{g},\lambda_{F}\) being non-negative and finite in all dimension, i.e. \(0\leq\lambda_{g}<\infty\), \(0\leq\lambda_{F}<\infty\) according to Lagrange duality Theorem. Moreover, it is well known (Chapter 4 in [59]) that the Largrangian terms respectively equal zero when the problems attain the optimals. i.e.

\[\lambda_{g}^{\top}\mu_{g}^{*}(x)=0\quad\text{and}\quad\lambda_{F}^{\top}\mu_{F} ^{*}(x)=0.\] (44)

Moreoever, the first-order stationary condition requires \(\nabla\tilde{D}_{g}(\mu_{g}^{*}(x))=\nabla D_{g}(\mu_{g}^{*}(x))+\lambda_{g}=0\) and \(\nabla\tilde{D}_{F}(\mu_{F}^{*}(x))=\nabla D_{F}(\mu_{F}^{*}(x))+\lambda_{F}=0\) and therefore

\[\nabla D_{g}(\mu_{g}^{*}(x))=-\lambda_{g}\quad\text{and}\quad\nabla D_{F}(\mu_{F} ^{*}(x))=-\lambda_{F}.\] (45)In this way, for all \(\mu\in\mathcal{B}(\mu_{g}^{*}(x);\delta_{g})\cap\mathbb{R}_{+}^{d_{c}}\).

\[D_{g}(\mu_{g}^{*}(x))-D_{g}(\mu)= \int_{\tau=0}^{1}\langle\nabla D_{g}(\mu+\tau(\mu_{g}^{*}(x)-\mu) ),\mu_{g}^{*}(x)-\mu\rangle d\tau\] \[= \int_{\tau=0}^{1}\frac{1}{\tau}\langle\nabla D_{g}(\mu_{g}^{*}(x ))-D_{g}(\mu+\tau(\mu_{g}^{*}(x)-\mu)),\tau(\mu-\mu_{g}^{*}(x))\rangle d\tau\] \[-\langle\nabla D_{g}(\mu_{g}^{*}(x)),\mu-\mu_{g}^{*}(x)\rangle\] \[\overset{(a)}{\geq} \int_{0}^{1}C_{\delta_{g}}\|\mu-\mu_{g}^{*}(x)\|^{2}\tau d\tau- \langle\nabla D_{g}(\mu_{g}^{*}(x)),\mu-\mu_{g}^{*}(x)\rangle\] \[\overset{(b)}{=} \frac{C_{\delta_{g}}}{2}\|\mu-\mu_{g}^{*}(x)\|^{2}+\langle \lambda_{g},\mu-\mu_{g}^{*}(x)\rangle\] \[\overset{(c)}{\geq} \frac{C_{\delta_{g}}}{2}\|\mu-\mu_{g}^{*}(x)\|^{2},\]

where \((a)\) uses (21a) in Assumption 5 and the fact that the \(\mu,\mu_{g}^{*}(x)\in\mathcal{B}(\mu_{g}^{*}(x);\delta_{g})\cap\mathbb{R}_{+}^ {d_{c}}\) implies \(\mu+\tau(\mu_{g}^{*}(x)-\mu)\in\mathcal{B}(\mu_{g}^{*}(x);\delta_{g})\cap \mathbb{R}_{+}^{d_{c}}\); \((b)\) solves the integral and uses \(\lambda_{g}=-\nabla D_{g}(\mu_{g}^{*}(x))\) in (45); and \((c)\) follows from the fact that \(\langle\lambda,\mu_{g}^{*}(x)\rangle=0\) in (44) and \(\mu,\lambda_{g}\geq 0\).

Analogously, for all \(\mu\in\mathcal{B}(\mu_{F}^{*}(x);\delta_{F})\cap\mathbb{R}_{+}^{d_{c}}\), it follows that

\[D_{F}(\mu_{F}^{*}(x))-D_{F}(\mu)\geq \frac{C_{\delta_{F}}}{2}\|\mu-\mu_{F}^{*}(x)\|^{2}.\]

In this way, for arbitrary \(\epsilon_{g}<\frac{C_{\delta_{g}}}{2}\delta_{g}\), the complexity of Algorithm 2 to solve (7) is \(\tilde{\mathcal{O}}(\epsilon_{F}^{-0.5})\), i.e.,

\[\|\mu_{T_{g}}-\mu_{g}^{*}(x)\|^{2}= \mathcal{O}(\epsilon_{g}),\] \[\text{and }\|y_{T_{g}}-y_{g}^{*}(x)\|^{2}\leq \|y_{T_{g}}-y_{g}^{*}(\mu_{T_{g}};x)\|^{2}+\|\mu_{T_{g}}-\mu_{g}^ {*}(x)\|^{2}\] \[\leq (1/\alpha_{g}+1)\|\mu_{T_{g}}-\mu_{g}^{*}(x)\|^{2}=\mathcal{O}( \epsilon_{g}).\]

At each iteration \(t\) in Algorithm 1, \(x=x_{t}\), and the output \((y_{T_{g}},\mu_{T_{g}})\) is chosen as \((y_{g,t}^{T_{g}},\mu_{g,t}^{T_{g}})\).

Similarly, to solve (5), for arbitrary \(\epsilon_{g}<\frac{C_{\delta_{g}}}{2}\delta_{g}\), applying Algorithm 2 with complexity \(\tilde{\mathcal{O}}(\epsilon_{F}^{-0.5})\) to achieve (43) can achieve

\[\|\mu_{T_{F}}-\mu_{F}^{*}(x)\|^{2}= \mathcal{O}(\epsilon_{F}),\] \[\text{and }\|y_{T_{F}}-y_{F}^{*}(x)\|^{2}\leq \|y_{T_{F}}-y_{F}^{*}(\mu_{T_{F}};x)\|^{2}+\|\mu_{T_{F}}-\mu_{F}^ {*}(x)\|^{2}\] \[\leq (1/\alpha_{F}+1)\|\mu_{T_{F}}-\mu_{F}^{*}(x)\|^{2}=\mathcal{O}( \epsilon_{F}).\]

At each iteration \(t\) in Algorithm 1, \(x=x_{t}\), and the output \((y_{T_{F}},\mu_{T_{F}})\) is chosen as \((y_{F,t}^{T_{F}},\mu_{F,t}^{T_{F}})\).

This completes the proof. 

**Remark 3**.: _Under the same assumptions as in Theorem 3, we can choose \(\eta_{g,1}\leq(l_{g,1}+l_{g^{c},1})^{-1}\), \(\eta_{g,2}\leq\frac{\alpha_{g}}{l_{g^{c},0}}\) as stepsizes for running the accelerated version of Algorithm 2 to solve (7), and \(\eta_{F,1}\leq(l_{f,1}+\gamma l_{g,1}+l_{g^{c},1})^{-1}\), \(\eta_{F,2}\leq\frac{\gamma\alpha_{g}-l_{f,1}}{l_{g^{c},0}}\) as the ones for (5)._

### Proof of Theorem 4

In this section, we consider

\[g^{c}(x,y)=g_{1}^{c}(x)^{\top}y-g_{2}^{c}(x)\] (46)

being affine in \(y\), and \(\mathcal{Y}=\mathbb{R}^{d_{y}}\).

Therefore, for a fixed \(x\), taking either \(L_{g}(\mu,y;x)\) in (7) or \(L_{F}(\mu,y;x)\) in (5) as \(L(\mu,y)\) fits into a special case of _strongly-convex-concave saddle point problems_ in the following form:

\[\max_{\mu\in\mathbb{R}_{+}^{d_{x}}}\min_{y\in\mathbb{R}^{d_{y}}}L(\mu,y)=-h_{1}( \mu)+y^{\top}A\mu+h_{2}(y)\] (47)where \(h_{1}(\mu)\) is smooth and linear (concave) in \(\mu\) and \(h_{2}(y)\) is smooth and strongly convex in \(y\). Specifically, for \(L_{g}(\mu,y;x)\) as \(L(\mu,y)\), \(h_{1}(\mu)=\langle g_{2}^{c}(x),\mu\rangle\) is \(0\)-smooth and linear (concave), \(A=g_{1}^{c}(x)\), and \(h_{2}(y)=g(x,y)\) is \(l_{g,1}\)-smooth and \(\alpha_{g}\)-strongly convex.

In this context, performing PGD on \(L(\mu,y)\) on \(y\) is equivalent to a gradient descent step since \(\mathcal{Y}=\mathbb{R}^{d_{y}}\). The following lemma summarizes the error of \(\|y_{t}-y_{\mu}^{*}(\mu_{t})\|\) where \(y_{2}^{*}(\mu)\) is defined in (16) and the update of \(\mu_{t+1}\) and \(y_{t+1}\) is the non-accelerated version of Algorithm 2 with \(T_{y}=1\).

**Lemma 12** (Update of \(\|y_{t}-\nabla h_{2}^{*}(-A\mu_{t})\|\)).: _Consider the problem (47) where \(A\) is of full column rank and \(h_{2}(y)\) is \(\alpha_{h_{2}}\)-strongly convex and \(l_{f,1}\)-smooth. \(y_{\mu}^{*}(\mu)\) defined in (16) satisfies_

\[y_{\mu}^{*}(\mu)=\nabla h_{2}^{*}(-A\mu)\] (48)

_where \(h_{2}^{*}(y)\) is the conjugate function of \(h_{2}(y)\) by Definition 5. At iteration \(t\), \(\mu_{t},y_{t}\) are known, and conduct \(y_{t+1}=y_{t}-\eta_{1}\nabla_{y}L(\mu_{t},y_{t})\), a gradient descent step for \(L(\mu_{t},y)\) in \(y\). This gives_

\[\|y_{t+1}-\nabla h_{2}^{*}(-A\mu_{t})\|\leq(1-\eta_{1}\alpha_{h_{2}}/2)\|y_{t }-\nabla h_{2}^{*}(-A\mu_{t})\|\] (49)

_when \(\eta_{1}\leq\frac{1}{l_{h_{2},1}}\). Additionally, given another \(\mu_{t+1}\), we know_

\[\|y_{t+1}-\nabla h_{2}^{*}(-A\mu_{t+1})\|\leq (1-\eta_{1}\alpha_{h_{2}}/2)\|y_{t}-\nabla h_{2}^{*}(-A\mu_{t})\| +\frac{\sigma_{\max}(A)}{\alpha_{h_{2}}}\|\mu_{t+1}-\mu_{t}\|.\] (50)

Proof.: Recall the definition \(y_{\mu}^{*}(\mu)=\arg\min_{y}L(\mu,y)\) following (16). The first-order stationary optimality condition requires that for any given \(\mu\), it holds

\[\nabla_{y}L(\mu,y_{\mu}^{*})=A\mu+\nabla h_{2}(y_{\mu}^{*})=0\quad\Leftrightarrow \quad\nabla h_{2}(y_{\mu}^{*})=-A\mu.\]

As the mapping \(\nabla h_{2}\) and \(\nabla h_{2}^{*}\) are the inverse of each other according to Lemma 4, for any \(\mu\):

\[y_{\mu}^{*}=\nabla h_{2}^{*}(-A\mu).\]

At iteration \(t\), conducting a gradient descent step on \(L(\mu_{t},y)\) gives \(y_{t+1}=y_{t}-\eta_{1}\nabla_{y}L(\mu_{t},y_{t})\). As \(L(\mu_{t},y)\) is \(\alpha_{h_{2}}\)-strongly convex and \(l_{h_{2},1}\)-smooth in \(y\), following Lemma 7, take \(\eta_{1}\leq\frac{1}{l_{h_{2},1}}\), we have

\[\|y_{t+1}-\nabla h_{2}^{*}(-A\mu_{t})\|\leq(1-\eta_{1}\alpha_{h_{2}}/2)\|y_{t }-\nabla h_{2}^{*}(-A\mu_{t})\|.\]

Following triangle inequality, we also have

\[\|y_{t+1}-\nabla h_{2}^{*}(-A\mu_{t+1})\|\] \[\leq \|y_{t+1}-\nabla h_{2}^{*}(-A\mu_{t})\|+\|\nabla h_{2}^{*}(-A\mu_ {t})-\nabla h_{2}^{*}(-A\mu_{t+1})\|\] \[\leq (1-\eta_{1}\alpha_{h_{2}}/2)\|y_{t}-\nabla h_{2}^{*}(-A\mu_{t})\| +\frac{\sigma_{\max}(A)}{\alpha_{h_{2}}}\|\mu_{t+1}-\mu_{t}\|\] (51)

where the second term comes from the smoothness of the conjugate function (see Lemma 4). 

In (50), the update behavior of \(\|y_{t}-\nabla h_{2}^{*}(-A\mu_{t})\|\) depends on \(\|\mu_{t+1}-\mu_{t}\|\). Therefore, we are interested in the the update behavior of \(\|\mu_{t+1}-\mu_{t}\|\) where \(\mu_{t+1}=\operatorname{Proj}_{\mathbb{R}^{d_{c}}}(\mu_{t}+\eta\nabla_{\mu}L( \mu_{t},y_{t+1}))\) as in the non-accelerated version of Algorithm 2 with \(T_{y}=1\). Before proceeding, we would like to look into the properties of \(D(\mu)\) defined in (16) under the setting (47):

\[D(\mu)=\min_{y}-h_{1}(\mu)+\langle y,A\mu\rangle+h_{2}(y)\] (52)

where \(h_{1}(\mu)\) is smooth and linear (concave) in \(\mu\), \(h_{2}(y)\) is smooth and strongly convex in \(y\), and \(A\) is of full rank in column. The next lemma shows that \(D(\mu)\) features strong concavity and smoothness.

**Lemma 13** (Smoothness and strongly concavity of \(D(\mu)\)).: _Suppose \(h_{1}\) is concave and \(l_{h_{1},1}\)-smooth, \(h_{2}\) is \(\alpha_{h_{2}}\)-strongly convex and \(l_{h_{2},1}\)-smooth, and \(A\) is full column rank. Then \(D(\mu)\) in (52) satisfies_

\[D(\mu)=-h_{1}(\mu)-h_{2}^{*}(-A\mu),\]

_and is \(\frac{\sigma_{\min}^{2}(A)}{l_{h_{2},1}}\)-strongly concave and \((l_{h_{1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}})\)-smooth with respect to \(\mu\)._Proof.: Following Definition 5, we have

\[D(\mu)=-h_{1}(\mu)-h_{2}^{*}(-A\mu)\]

where \(h_{2}^{*}(y)\) is \(\frac{1}{l_{h_{2},1}}\)-strongly convex and \(\frac{1}{\alpha_{h_{2}}}\)-smooth according to Lemma 4.

For all \(\mu_{1},\mu_{2}\),

\[-D(\mu_{1})-(-D(\mu_{2}))= h_{2}^{*}(-A\mu_{1})-h_{2}^{*}(-A\mu_{2})+h_{1}(\mu_{1})-h_{1}( \mu_{2})\] \[\geq \langle\frac{\partial h_{2}^{*}(-A\mu_{2})}{\partial-A\mu_{2}},-A \mu_{1}+A\mu_{2}\rangle+\frac{1/l_{h_{2},1}}{2}\|A\mu_{1}-A\mu_{2}\|^{2}\] \[+\langle\nabla h_{1}(\mu_{2}),\mu_{1}-\mu_{2}\rangle\rangle\] \[\geq \langle\nabla D(\mu_{2}),\mu_{1}-\mu_{2}\rangle+\frac{\sigma_{ \min}^{2}(A)/l_{h_{2},1}}{2}\|\mu_{1}-\mu_{2}\|^{2}.\]

where the first inequality follows the strong convexity of \(h_{2}^{*}(y)\) and the fact that \(-h_{1}(\mu)\) is convex as \(h_{1}(y)\) is concave. and the second inequality follows the chain rule to formulate \(\nabla D(\mu_{2})\). Therefore, \(-D(\mu)\) is \(\frac{\sigma_{\min}^{2}(A)}{h_{2,1}}\)-strongly convex, and \(D(\mu)\) is \(\frac{\sigma_{\min}^{2}(A)}{l_{h_{2},1}}\)-strongly concave.

Moreover \(D(\mu)\) is \((l_{h_{1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}})\)-smooth as

\[D(\mu_{1})-D(\mu_{2})= -h_{2}^{*}(-A\mu_{1})-(-h_{2}^{*}(-A\mu_{2}))-h_{1}(\mu_{1})+h_{1 }(\mu_{2})\] \[\leq \langle\frac{\partial-h_{2}^{*}(-A\mu_{2})}{\partial-A\mu_{2}},- A\mu_{1}-(-A\mu_{2})\rangle+\frac{1/\alpha_{h_{2}}}{2}\|-A\mu_{1}-(-A\mu_{2}) \|^{2}\] \[+\langle-\nabla h_{1}(\mu_{2}),\mu_{1}-\mu_{2}\rangle\rangle+ \frac{l_{h_{1},1}}{2}\|\mu_{1}-\mu_{2}\|^{2}\] \[\leq \langle\nabla D(\mu_{2}),\mu_{1}-\mu_{2}\rangle+\frac{l_{h_{1}, 1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}}}{2}\|\mu_{1}-\mu_{2}\|^{2}.\]

The first inequality holds as \(h_{2}^{*}(y)\) and \(h_{1}(\mu)\) are smooth. The second follows the chain rule.

Note \(\sigma_{\max}(A)\geq\sigma_{\min}(A)>0\) as \(A\) is full column rank. This completes the proof. 

Knowing \(D(\mu)\) has such favorable properties, we next analyze the update of \(\|\mu_{t+1}-\mu_{t}\|\), where \(\{\mu_{t}\}\) is the sequence generated in the non-accelerated version of Algorithm 2 with \(T_{y}=1\).

**Lemma 14** (Update of \(\|\mu_{t+1}-\mu_{t}\|\)).: _Consider the problem in (47) where \(h_{1}\) is concave and \(l_{h_{1},1}\)-smooth, \(h_{2}\) is \(\alpha_{h_{2}}\)-strongly convex and \(l_{h_{2},1}\)-smooth, and \(A\) is full column rank. Running the non-accelerated version of Algorithm 2 with \(T_{y}=1\) and \(\eta_{1}\leq{l_{h_{2},1}}^{-1}\) gives_

\[\frac{1}{\eta_{2}}\|\mu_{t+1}-\mu_{t}\|\leq \left(l_{h_{1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}} \right)\|\mu_{t}-\mu^{*}\|\] \[+\sigma_{\max}(A)(1-\eta_{1}\alpha_{h_{2}}/2)\|y_{t}-\nabla h_{2} ^{*}(-A\mu_{t})\|+\|\lambda\|\] (53)

_where the constant \(\lambda\) satisfies \(0\leq\lambda<\infty\) and \(\mu^{*}=\arg\max_{\mu\in\mathbb{R}_{+}^{d_{c}}}D(\mu)\) with \(D(\mu)\) defined in (52)._

Proof.: According to Lemma 13,

\[D(\mu)=\min_{y\in\mathbb{R}^{d_{y}}}-h_{1}(\mu)+y^{\top}A\mu+h_{2}(y)=-h_{1}( \mu)-h_{2}^{*}(-A\mu)\]

is \(\frac{\sigma_{\min}^{2}(A)}{h_{h_{2},1}}\)-strongly concave and \((l_{h_{1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}})\)-smooth with respect to \(\mu\). Moreover, the problem \(\max_{\mu\in\mathbb{R}_{+}^{d_{c}}}D(\mu)\) is equivalent to the unconstrained problem with the Lagrange multiplier

\[\max_{\mu\in\mathbb{R}^{d_{c}}}\tilde{D}(\mu):=D(\mu)+\lambda^{\top}\mu\]

where unique \(\lambda\) is non-negative and finite in all dimension, i.e. \(0\leq\lambda<\infty\), as \(D(\mu)\) is strongly convex and \(\mu\in\mathbb{R}_{+}^{d_{c}}\) is equivalent to \(\mu\geq 0\) satisfying the LICQ condition (Lemma 5). In this way,

\[\nabla\tilde{D}(\mu)=\nabla D(\mu)+\lambda=-\nabla h_{1}(\mu)+A^{\top}\nabla h_ {2}^{*}(-A\mu)+\lambda.\] (54)We can see that \(\tilde{D}(\mu)\) is smooth and strongly concave with the same modulus as \(D(\mu)\). The first-order stationary condition requires

\[\nabla\tilde{D}(\mu^{*})=-\nabla h_{1}(\mu^{*})+A^{\top}\nabla h_{2}^{*}(-A\mu^{ *})+\lambda=0.\] (55)

In this way,

\[\frac{1}{\eta_{2}}\|\mu_{t+1}-\mu_{t}\|=\frac{1}{\eta_{2}}\| \operatorname{Proj}_{\mathbb{R}^{d_{c}}_{+}}\big{(}\mu_{t}+\eta_{2}(-\nabla h_ {1}(\mu_{t})+A^{\top}y_{t+1})\big{)}-\mu_{t}\|\] \[\stackrel{{(a)}}{{\leq}} \|-\nabla h_{1}(\mu_{t})+A^{\top}y_{t+1}\|\] \[= \|-\nabla h_{1}(\mu_{t})+A^{\top}\nabla h_{2}^{*}(-A\mu_{t})+ \lambda+A^{\top}y_{t+1}-A^{\top}\nabla h_{2}^{*}(-A\mu_{t})-\lambda\|\] \[\stackrel{{(b)}}{{\leq}} \|\nabla\tilde{D}(\mu_{t})\|+\sigma_{\max}(A)\|y_{t+1}-\nabla h_ {2}^{*}(-A\mu_{t})\|+\|\lambda\|\] \[\stackrel{{(c)}}{{\leq}} \|\nabla\tilde{D}(\mu_{t})-\nabla\tilde{D}(\mu^{*})\|+\sigma_{ \max}(A)(1-\eta_{1}\alpha_{h_{2}}/2)\|y_{t}-\nabla h_{2}^{*}(-A\mu_{t})\|+\|\lambda\|\] \[\stackrel{{(d)}}{{\leq}} \left(l_{h_{1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}} \right)\|\mu_{t}-\mu^{*}\|+\sigma_{\max}(A)(1-\eta_{1}\alpha_{h_{2}}/2)\|y_{t} -\nabla h_{2}^{*}(-A\mu_{t})\|+\|\lambda\|\]

Inequality \((a)\) comes from the non-expansiveness (1-Lipschitzness) of the projection operation, \((b)\) follows triangle inequality and uses (54), \((c)\) uses (55) and (49) in Lemma 12, and \((d)\) comes from the smoothness of \(\tilde{D}(\mu)\), which is of the same modulus as \(D(\mu)\). This completes the proof. 

In (53), the update behavior of \(\|\mu_{t+1}-\mu_{t}\|\) depends on \(\|\mu_{t}-\mu^{*}\|\). We further look into the update of \(\|\mu_{t}-\mu^{*}\|\) and summarize in the following lemma the bound of the update of \(\|\mu_{t}-\mu^{*}\|\).

**Lemma 15** (Update of \(\|\mu_{t}-\mu^{*}\|\)).: _Consider the problem in (47) where \(h_{1}\) is concave and \(l_{h_{1},1}\)-smooth, \(h_{2}\) is \(\alpha_{h_{2}}\)-strongly convex and \(l_{h_{2},1}\)-smooth, and \(A\) is full column rank. Conduct the non-accelerated version of Algorithm 2 with \(T_{y}=1\), gives_

\[\|\mu_{t+1}-\mu^{*}\|\leq \left(1-\eta_{2}\frac{\sigma_{\min}^{2}(A)}{2l_{h_{2},1}}\right) \|\mu_{t}-\mu^{*}\|+\eta_{2}\sigma_{\max}(A)(1-\eta_{1}\alpha_{h_{2}}/2)\|y_ {t}-\nabla h_{2}^{*}(-A\mu_{t})\|.\] (56)

_when \(\eta_{1}\leq l_{h_{2},1}{}^{-1}\) and \(\eta_{2}\leq\left(l_{h_{1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}} \right)^{-1}\). Here \(\mu^{*}=\arg\min_{\mu\in\mathbb{R}^{d_{c}}_{+}}D(\mu)\) where \(D(\mu)\) is defined in (52)._

Proof.: Define an auxiliary update as

\[\tilde{\mu}_{t+1}:=\operatorname{Proj}_{\mathbb{R}^{d_{c}}_{+}}( \mu_{t}+\eta_{2}\nabla D(\mu_{t}))=\operatorname{Proj}_{\mathbb{R}^{d_{c}}_{+}} \left(\mu_{t}+\eta_{2}(-\nabla h_{1}(\mu_{t})+A^{\top}\nabla h_{2}^{*}(-A\mu_ {t}))\right).\] (57)

This is a projected gradient descent on strongly convex \(-D(\mu)\). As \(\mathbb{R}^{d_{c}}_{+}\) is closed and convex, following Lemma 7, for \(\eta_{2}\leq\left(l_{h_{1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}} \right)^{-1}\), where \(\left(l_{h_{1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}}\right)\) is the modulus for smoothness of \(D(\mu)\) by Lemma 13, we have

\[\|\tilde{\mu}_{t+1}-\mu^{*}\|\leq \left(1-\eta_{2}\frac{\sigma_{\min}^{2}(A)}{2l_{h_{2},1}}\right) \|\mu_{t}-\mu^{*}\|.\]

As the real update is \(\mu_{t+1}=\operatorname{Proj}_{\mathbb{R}^{d_{c}}_{+}}\big{(}(\mu_{t}+\eta_{2}( -\nabla h_{1}(\mu_{t})+A^{\top}y_{t})\big{)}\), by the non-expansiveness (1-Lipschitzness) of projection operation, we have

\[\|\tilde{\mu}_{t+1}-\mu_{t+1}\|\leq \|\eta_{2}A^{\top}(y_{t+1}-\nabla h_{2}^{*}(-A\mu_{t}))\|\leq\eta_{ 2}\sigma_{\max}(A)\|y_{t+1}-\nabla h_{2}^{*}(-A\mu_{t})\|\]

By triangle inequality and (49), we have

\[\|\mu_{t+1}-\mu^{*}\|\leq\left(1-\eta_{2}\frac{\sigma_{\min}^{2}( A)}{2l_{h_{2},1}}\right)\|\mu_{t}-\mu^{*}\|+\eta_{2}\sigma_{\max}(A)\|y_{t+1}- \nabla h_{2}^{*}(-A\mu_{t})\|\] \[\leq \left(1-\eta_{2}\frac{\sigma_{\min}^{2}(A)}{2l_{h_{2},1}}\right) \|\mu_{t}-\mu^{*}\|+\eta_{2}\sigma_{\max}(A)(1-\eta_{1}\alpha_{h_{2}}/2)\|y_ {t}-\nabla h_{2}^{*}(-A\mu_{t})\|.\] (58)

This completes the proof.

We are ready to proceed with the convergence analysis for the single-loop algorithm (Algorithm 2) without acceleration and \(T_{y}=1\), on the problems (47), which is a general form to (7) and (5). In this way, Theorem 4 follows directly from the following theorem.

**Theorem 6**.: _Suppose \(L(\mu,y)\) is in the form of (47) where \(A\) is full column rank, \(h_{1}\) is concave and \(l_{h_{1},1}\)-smooth, \(h_{2}\) is \(\alpha_{h_{2}}\)-strongly convex and \(l_{h_{2},1}\)-smooth satisfying \(l_{h_{1},1}=\mathcal{O}(1)\), \(l_{h_{2},1},l_{\alpha_{2}}\geq\mathcal{O}(1)\), and \(\frac{l_{h_{2},1}}{\alpha_{h_{2}}}=\mathcal{O}(1)\). Conduct the non-accelerated version of Algorithm 2 with \(T_{y}=1\). For arbitrary small positive \(\epsilon\leq\left(\frac{4l_{h_{2},1}\sigma_{\max}(A)}{\alpha_{h_{2}}\sigma_{ \min}^{2}(A)}(l_{h_{1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}})\right)^ {-1}\), when \(\eta_{1}=\mathcal{O}(\frac{1}{l_{h_{2},1}})\leq\frac{1}{l_{h_{2},1}}\) and \(\eta_{2}=\mathcal{O}(\epsilon)\leq\frac{1}{l_{h_{1},1}+\sigma_{\max}^{2}(A)/ \alpha_{h_{2}}}\), the algorithm yields output \((\mu_{T},y_{T})\) such that_

\[\|\mu_{T}-\mu^{*}\|^{2}<\epsilon,\quad\text{and}\quad\|y_{T}-y^{*}\|^{2}<\epsilon\]

_with complexity \(T=\mathcal{O}(\ln\bigl{(}\epsilon^{-1}\bigr{)})\). Here, \((\mu^{*},y^{*})=\arg\max_{\mu\in\mathbb{R}^{d_{c}}}\min_{y\in\mathbb{R}^{d_{y }}}L(\mu,y)\)._

Proof.: For some positive constant \(\rho>0\), denote

\[P_{t}:=\rho\|\mu_{t}-\mu^{*}\|+\|y_{t}-\nabla h_{2}^{*}(-A\mu_{t})\|.\] (59)

Plugging (50) in Lemma 12, (53) in Lemma 14, and (56) in Lemma 15 to (59), we know

\[P_{t+1}=\rho\|\mu_{t+1}-\mu^{*}\|+\|y_{t+1}-\nabla h_{2}^{*}(-A \mu_{t+1})\|\] \[\leq \rho\left(\left(1-\eta_{2}\frac{\sigma_{\min}^{2}(A)}{2l_{h_{2}, 1}}\right)\|\mu_{t}-\mu^{*}\|+\eta_{2}\alpha_{\max}(A)(1-\eta_{1}\alpha_{h_{2} }/2)\|y_{t}-\nabla h_{2}^{*}(-A\mu_{t})\|\right)\] \[+(1-\eta_{1}\alpha_{h_{2}}/2)\|y_{t}-\nabla h_{2}^{*}(-A\mu_{t}) \|+\frac{\sigma_{\max}(A)}{\alpha_{h_{2}}}\eta_{2}\] \[\times\left((l_{h_{1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2} }})\|\mu_{t}-\mu^{*}\|+\sigma_{\max}(A)(1-\eta_{1}\alpha_{h_{2}}/2)\|y_{t}- \nabla h_{2}^{*}(-A\mu_{t})\|+\|\lambda\|\right)\] \[= \left(1-\eta_{2}\frac{\sigma_{\min}^{2}(A)}{2l_{h_{2},1}}+\frac{ \sigma_{\max}(A)}{\rho}\frac{\sigma_{\max}(A)}{\alpha_{h_{2}}}\eta_{2}(l_{h_{ 1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}})\right)\rho\|\mu_{t}-\mu^{*}\|\] \[+(1-\eta_{1}\alpha_{h_{2}}/2)\left(1+\rho\eta_{2}\sigma_{\max}(A) +\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}}\eta_{2}\right)\|y_{t}-\nabla h_{ 2}^{*}(-A\mu_{t})\|+\frac{\sigma_{\max}(A)}{\alpha_{h_{2}}}\eta_{2}\|\lambda\|.\]

To construct \(P_{t+1}\leq(1-c)P_{t}+\frac{\sigma_{\max}(A)}{\alpha_{h_{2}}}\eta_{2}\|\lambda\|\) for some constant \(0<c<1\), it is sufficient to find \(\eta_{1}\leq\frac{1}{l_{h_{2},1}},\eta_{2}\leq\frac{1}{(l_{h_{1},1}+\frac{ \sigma_{\max}^{2}(A)}{\alpha_{h_{2}}})}\), and \(\rho>0\) such that

\[\begin{cases}0<\left(1-\eta_{2}\frac{\sigma_{\min}^{2}(A)}{2l_{h_{2},1}}+\frac {1}{\rho}\frac{\sigma_{\max}(A)}{\alpha_{h_{2}}}\eta_{2}(l_{h_{1},1}+\frac{ \sigma_{\max}^{2}(A)}{\alpha_{h_{2}}})\right)\leq 1-\eta_{2}\frac{\sigma_{\min}^{2}(A)}{4l_{h_{2},1}}<1\\ 0<(1-\eta_{1}\alpha_{h_{2}}/2)\left(1+\rho\eta_{2}\sigma_{\max}(A)+\frac{\sigma _{\max}^{2}(A)}{\alpha_{h_{2}}}\eta_{2}\right)\leq(1-\eta_{1}\alpha_{h_{2}}/2)( 1+\eta_{1}\alpha_{h_{2}}/2)<1\end{cases}\]

This can be obtained when

\[\begin{cases}\rho\geq\frac{4l_{h_{2},1}\sigma_{\max}(A)}{\alpha_{h_{2}}\sigma_{ \min}^{2}(A)}(l_{h_{1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}})\\ \eta_{2}\leq\frac{1}{2\left(\rho\sigma_{\max}(A)+\frac{\sigma_{\max}^{2}(A)}{ \alpha_{h_{2}}}\right)}\end{cases}\] (60)

Conditions in (60) can be satisfied when \(\epsilon>0\) is sufficiently small such that \(\rho=\epsilon^{-1}\geq\frac{4l_{h_{2},1}\sigma_{\max}(A)}{\alpha_{h_{2}}\sigma_{ \min}^{2}(A)}(l_{h_{1},1}+\frac{\sigma_{\max}^{2}(A)}{\alpha_{h_{2}}})\), \(\eta_{1}=\mathcal{O}(\frac{1}{l_{h_{2},1}})\) and \(\eta_{2}=\mathcal{O}(\frac{\alpha_{h_{2}}}{l_{h_{2},1}}\rho^{-1})=\mathcal{O}( \epsilon^{-1})\). In this way,

\[P_{t+1}\leq (1-c)P_{t}+\mathcal{O}(\alpha_{h_{2}

Notice \(\mathcal{O}(\alpha_{h_{2}}^{-1})<\mathcal{O}(1)\) and \(P_{0}=\mathcal{O}(\epsilon^{-1})\) as \(\rho=\epsilon^{-1}\). In this way, there exist \(T_{1}=\mathcal{O}(\ln\bigl{(}\epsilon^{-1}\bigr{)})\) such that for all \(t>T_{1}\), \((1-c)^{t}P_{0}=\mathcal{O}(1)\) and \(\mathcal{O}(\alpha_{h_{2}}^{-1})\leq\mathcal{O}(1)\). Accordingly, we can achieve

\[P_{t}=\mathcal{O}(1),\quad\forall t>T_{1}.\]

Moreover, as \(P_{t}=\epsilon^{-1}\|\mu_{t}-\mu^{*}\|+\|y_{t}-\nabla h_{2}^{*}(-A\mu_{t})\|\),

\[\|\mu_{t}-\mu^{*}\|\leq\epsilon P_{t}=\mathcal{O}(\epsilon),\quad\forall t>T_{ 1}.\] (62)

Furthermore, choose \(\eta_{1}=\mathcal{O}(\frac{1}{l_{h_{2,1}}})\) satisfying \(\eta_{1}\leq\frac{1}{l_{h_{2,1}}}\), for \(t>T_{1}\),

\[\|y_{t}-\nabla h_{2}^{*}(-A\mu_{t})\|\leq (1-\eta_{1}\alpha_{h_{2}}/2)^{t-T_{1}}\|y_{T_{1}}-\nabla h_{2}^{*}( -A\mu_{T_{1}})\|+\mathcal{O}(\epsilon).\]

This is an iteration outcome using (50) in Lemma 12, (62), and the fact that \(\eta_{1}\alpha_{h_{2}}/2=\mathcal{O}(\frac{\alpha_{h_{2}}}{l_{h_{2,1}}})= \mathcal{O}(1)\). In this way, for another \(T_{2}=\mathcal{O}(\ln\bigl{(}\epsilon^{-1}\bigr{)})\) steps, we have

\[\begin{split}&\|y_{t}-\nabla h_{2}^{*}(-A\mu_{t})\|=\mathcal{O}( \epsilon),\\ \text{and}&\|y_{t}-y^{*}\|\leq\|y_{t}-\nabla h_{2}^{* }(-A\mu_{t})\|+\|\nabla h_{2}^{*}(-A\mu_{t})-\nabla h_{2}^{*}(-A\mu^{*})\|\\ &\leq\|y_{t}-\nabla h_{2}^{*}(-A\mu_{t})\|+\frac{\sigma_{\max}^{ 2}(A)}{\alpha_{h_{2}}}\|\mu_{t}-\mu^{*}\|\\ &=\mathcal{O}\left(\epsilon+\alpha_{h_{2}}^{-1}\epsilon\right)= \mathcal{O}\left(\epsilon\right),\quad\forall t>T_{1}+T_{2}.\end{split}\]

We can see that the algorithm converges linearly with complexity \(\mathcal{O}(T_{1}+T_{2})=\mathcal{O}(\ln\bigl{(}\epsilon^{-1}\bigr{)})\). In this way, obtaining

\[\|y_{T}-y^{*}\|^{2}=\mathcal{O}(\epsilon)\quad\text{and}\quad\|\mu_{T}-\mu^{*} \|^{2}=\mathcal{O}(\epsilon),\]

requires complexity \(T=\mathcal{O}(\ln\bigl{(}(\sqrt{\epsilon})^{-1}\bigr{)})=\mathcal{O}(\ln \bigl{(}\epsilon^{-1}\bigr{)})\). This completes the proof. 

**Remark 4**.: _Under the same assumptions as in Theorem 4, we can choose \(\eta_{g,2}\lesssim(l_{g,1})^{-1}\), \(\eta_{g,1}\leq\alpha_{g}^{2}\epsilon_{g}(2s_{\max}\alpha_{g}+s_{\max}^{2} \epsilon^{-1})^{-1}\eta_{g,2}\) as stepsizes for running the single-loop version of Algorithm 2 to solve (7), and \(\eta_{F,2}\lesssim(l_{f,1}+\gamma l_{g,1})^{-1}\), \(\eta_{F,2}\leq(\gamma\alpha_{g}-l_{f,1})^{2}\epsilon_{F}(2s_{\max}(\gamma \alpha_{g}-l_{f,1})+s_{\max}^{2}\epsilon^{-1})^{-1}\eta_{F,2}\) as the ones for (5)._

## Appendix E Applications to Hyperparameter Optimization for SVM

In this section, we provide additional details about the SVM model training experiment for the linear SVM model, including the problem formulation and analysis of the results.

### Problem formulation

SVMs train a machine learning model by finding the optimal hyperplane that separates data points of different classes with the maximum margin \(w\). Misclassification is not tolerated for hard-margin SVMs. In contrast, some samples are allowed to be misclassified for soft-margin SVMs. Specifically, one first introduces variables \(\xi_{i}\), which measure the violation associated with the classification of sample \(i\), and then augments the original SVM objective with the norm of \(\xi\), which is a vector collecting the values of \(\xi_{i}\) for all the samples in the training set.

BLO can be applied to the hyperparameter selection task of SVM. For example, it can be used to choose the value of the regularization parameters during soft-margin linear SVM training. Let us consider a classification problem and define \(\mathcal{D}_{\mathrm{tr}}:=\{(z_{\mathrm{tr},i},l_{\mathrm{tr},i})\}_{i=1}^{| \mathcal{D}_{\mathrm{tr},i}|}\) as the training set, with \(z_{\mathrm{tr},i}\) being the input feature vector for sample \(i\) and \(l_{\mathrm{tr},i}\) being its associated binary label. Similarly, let \(\mathcal{D}_{\mathrm{val}}:=\{(z_{\mathrm{val},},l_{\mathrm{val}})\}_{i=1}^{| \mathcal{D}_{\mathrm{val}}|}\) be the validation set. For a linear classification problem, the parameters of the SVM are \(w\), a vector of coefficients with the same size as \(z_{\mathrm{tr},i}\), and the intercept \(b\).

In short, we are interested in the following constrained BLO problem

\[\min_{c}\quad\mathcal{L}_{\mathcal{D}_{\mathrm{val}}}(w^{*},b^{*})=\sum_{(z_{ \mathrm{val},l_{\mathrm{val}}})\in\mathcal{D}_{\mathrm{val}}}\exp\left(1-l_{ \mathrm{val}}\left(z_{\mathrm{val}}^{\top}w^{*}+b^{*}\right)\right)+\frac{1}{2} \|c\|^{2}\] (63a)

[MISSING_PAGE_FAIL:30]

Applications to Transportation Network Planning

This section applies the proposed BLOCC algorithm to a transportation network design problem, comparing it with the baselines from [72] and [75].

### Problem formulation

In transportation network planning, the planning operator is to construct a new transportation network (upper level) connecting a collection of stations \(\mathcal{S}\), and the passengers will decide whether to use the new network (lower-level), considering the options given by the new network and existing alternatives (constraints). The goal is to design a network that maximizes the operator's benefit, knowing the passengers will make rational choices depending on the given design.

The operator considers building a new network on a collection of links \(\mathcal{A}\subseteq\mathcal{S}\times\mathcal{S}\). For any link \((i,j)\in\mathcal{A}\) connecting stations \(i\in\mathcal{S}\) to \(j\in\mathcal{S}\), the operator needs to design the capacity \(x_{ij}\). If the link's capacity is set to zero, then the link is not constructed. The larger the capacity, the larger the number of travelers, thus the larger the revenue while the higher the construction cost \(c_{ij}\).

The passengers are in demand to travel in the network \(\mathcal{K}\subseteq\mathcal{S}\times\mathcal{S}\). For every origin-destination pair \((o,d)\), the traffic demand \(w^{od}\) and the traffic time on the existing route \(t_{\mathrm{ext}}^{od}\) is known. We assume that there is only _one_ existing network. The proportion of passengers choosing the new network \(y^{od}\) and \(y^{od}_{ij}\) the fraction of passengers using link \((i,j)\) to travel from \(o\) to \(d\) will be determined following passengers' rational choice, modeled by logit choice model [5; 11] that will be explained later. If \(y^{od}_{ij}=0\), then the link does not belong to the route that passengers follow to travel from \(o\) to \(d\).

In a) of Figure 6, the station \(\mathcal{S}\) are presented as the dots, and links \(\mathcal{A}\) are as the dashed lines (input topology); b) of Figure 6 shows a heatmap for the demand matrix for each \((o,d)\in\mathcal{K}\) (input to the design); c) is an example of the constructed network connecting some of the stations (output of the design); and d) illustrates the number of passengers using the constructed network (design output).

To summarize, in this experiment, we assume that

* Only one existing alternative network exists;
* Passengers decide whether to use our network rationally, which is modeled by the logit choice model considering a utility depends on travel attributes (travel time) [5; 11]; and,
* The demand per market, the trip prices, and the travel times per link are known to operators.

We summarize the optimization variables as follows

* \(x_{ij}\in\mathbb{R}_{+}\), the capacity constructed for the link \((i,j)\in\mathcal{A}\). The number of capacity variables is \(|\mathcal{A}|\). The link is not constructed if \(x_{ij}=0\).
* \(y^{od}\in[0,1]\), the fraction (proportion) of passengers from market \((o,d)\in\mathcal{K}\) choosing the new network for their travel. The number of flow variables is \(|\mathcal{K}|\). Since we consider only one competitor, \(1-y^{od}\) represents the fraction of incumbent network passengers. If \(y^{od}=0\), then the passengers of market \((o,d)\) do not use the new network.
* \(y^{od}_{ij}\in[0,1]\), the fraction of passengers from market \((o,d)\in\mathcal{K}\) that, when choosing the new network to travel from \(o\) to \(d\), use the link \((i,j)\in\mathcal{A}\) in their route to the destination. The number of link flow variables is \(|\mathcal{A}||\mathcal{K}|\). With this definition, it holds that \(y^{od}_{ij}\leq y^{od}\); and, if \(y^{od}_{ij}=0\), then link \((i,j)\) does not belong to the route when traveling from \(o\) to \(d\).

To simplify the notation and to make it consistent with the notations used in the paper, we denote

* \(x=\{x_{ij}\}_{\forall(i,j)\in\mathcal{A}}\) represents the upper-level variables to be optimized.
* \(\mathcal{X}=\mathbb{R}_{+}^{|\mathcal{A}|}\) represents the domain of \(x\).
* \(y=\{y^{od},\{y^{od}_{ij}\}_{\forall(i,j)\in\mathcal{A}}\}_{\forall(o,d)\in \mathcal{K}}\) represents the lower-level variables to be optimized
* \(\mathcal{Y}=[\varepsilon,1-\varepsilon]^{|\mathcal{K}|}\times[\varepsilon,1- \varepsilon]^{|\mathcal{A}||\mathcal{K}|}\), where \(\varepsilon\) is a small positive number set by the designer of the network, represents the domain of \(y\).

Besides the optimization variables, our objective and constraints include the following parameters

* \(w^{od}\), the total estimated demand (number of passengers) for the market \((o,d)\in\mathcal{K}\).
* \(m^{od}\), the revenue obtained by the operator from a passenger in the market \((o,d)\in\mathcal{K}\).
* \(c_{ij}\), the construction cost per passenger associated with link \((i,j)\in\mathcal{A}\).
* \(t_{ij}\), the travel time for link \((i,j)\in\mathcal{A}\).
* \(t_{\text{ext}}^{od}\), travel time on the alternative network for passengers in the market \((o,d)\in\mathcal{K}\).
* \(\omega_{t}<0\), the coefficient associated with the travel time in passengers' utility function.

In transportation network design, a bilevel formulation is essential due to the interaction between two players with different levels of influence: the operator, who constructs the network, and the passengers, who choose their routes based on the network's characteristics. The operator's goal is to maximize their benefit by minimizing construction costs and maximizing attracted demand, with link capacity as the optimization variable. Conversely, passengers aim to maximize their trip utility, determining the proportion of demand using each link. This dual optimization requires that passenger choices comply with link capacity constraints set by the operator, coupling the variables at both levels. This necessitates a bilevel optimization approach, specifically using BLOCC, to address the interdependent decisions and constraints effectively.

Figure 6: Example of a transportation network design. (a) represents the set of stations \(\mathcal{S}=\{1,2,3,4,5,6,7,8,9\}\) and the set of links \(\mathcal{A}\subseteq\mathcal{S}\times\mathcal{S}\), where the number of links is \(|\mathcal{A}|=30\) (15 segments with two orientations each) and the value on each edge represents the travel time. (b) represents the demand \(\{w^{od}\}\) between all \((o,d)\) pairs, where \(|\mathcal{K}|=9\times 8=72\) values are provided (those in the off-diagonal elements of the heatmap). (c) represents the constructed network, where, to facilitate visualization, we have assumed that the capacity is symmetric and used the width of the edge to represent the capacity of every link. (d) represents \(\{w^{od}y^{od}\}_{\{\forall(o,d)\in\mathcal{K}\}}\), the number of passengers served by the constructed network.

Now, we are ready to introduce the objective formulations of our BLO problem. For the upper level, the network operator aims to maximize profits and minimize costs, and therefore, its interest is

\[\min_{x\in\mathcal{X}}f(x,y_{g}^{*}(x)):=-\Bigg{(}\underbrace{\sum_{\forall(o,d) \in\mathcal{K}}m^{od}y^{\mathrm{od}*}(x)}_{\text{profit}}-\underbrace{\sum_{ \forall(i,j)\in\mathcal{A}}c_{ij}x_{ij}}_{cost}\Bigg{)},\] (64)

where \(y^{\mathrm{od}*}(x)\) are optimal lower-level passenger flows associated with the network design \(x\).

For the lower-level, we model the passenger's behavior by finding the flow variables that maximize utility and minimizes flow entropy cost.

\[\min_{y\in\mathcal{Y}}g(x,y):=-\Bigg{(}\underbrace{\sum_{(o,d)\in \mathcal{K}}\sum_{(i,j)\in\mathcal{A}}w^{od}\omega_{t}t_{ij}y_{ij}^{od}+\sum_{ (o,d)\in\mathcal{K}}w^{od}\omega_{t}t_{\mathrm{ext}}^{od}(1-y^{od})}_{\text{ passengers utility}}\] (65) \[\qquad\qquad+\underbrace{\sum_{(o,d)\in\mathcal{K}}w^{od}y^{od}( \ln\!\big{(}y^{od}\big{)}-1)+\sum_{(o,d)\in\mathcal{K}}w^{od}(1-y^{od})(\ln\! \big{(}1-y^{od}\big{)}-1)}_{\text{flow entropy cost}}\Bigg{)}.\]

The passengers' utility considers the time cost of choosing the new network and the existing network. The users set the flow variables \(y\) so that the transportation network yielding a higher utility is preferred. Here, the probability of chosing new network is modeled by a logistic (softmax) model. However, setting the objective as a simple linear utility maximization would lead to an all-or-nothing policy, which is not the behavior observed in practice. Hence, the second term is brought to consider. The approach considered here is to formulate an objective given by the Legendre transform (cf. Definition 5) of the softmax sharing (see [54, 57, 56] for additional details). Intuitively, this means that rather than imposing the softmax sharing a fortiori, we formulate a _convex_ problem whose KKT conditions lead to the softmax sharing. Using the fact that the Legendre transform of an exponential \(e^{y}\) is the negative entropy function \(y(\ln(y)-1)\), the lower-level objective is traditional as in [57].

Having introduced the optimization variables, parameters, and objective functions, we next formulate our BLO problem, where we also incorporate the network constraints:

\[\min_{x\in\mathcal{X}}\ -\sum_{\forall(o,d)\in\mathcal{K}}m^{od}y^{ \mathrm{od}*}+\sum_{\forall(i,j)\in\mathcal{A}}c_{ij}x_{ij}\] (66a) s.t. \[(y^{o\mathrm{d}*},y_{ij}^{\mathrm{od}*})=\arg\min_{y\in\mathcal{Y }}-\sum_{(o,d)\in\mathcal{K}}\sum_{(i,j)\in\mathcal{A}}w^{od}\omega_{t}t_{ij} y_{ij}^{od}-\sum_{(o,d)\in\mathcal{K}}w^{od}\omega_{t}t_{\mathrm{ext}}^{od}(1-y^{ od})\] (66b) \[\qquad\qquad\qquad\qquad+\sum_{(o,d)\in\mathcal{K}}w^{od}y^{od}( \ln\!\big{(}y^{od}\big{)}-1)+\sum_{(o,d)\in\mathcal{K}}w^{od}(1-y^{od})(\ln\! \big{(}1-y^{od}\big{)}-1)\] s.t. \[\sum_{\forall j|(i,j)\in\mathcal{A}}y_{ij}^{od}-\sum_{\forall j|(j,i)\in\mathcal{A}}y_{ji}^{od}=\begin{cases}y^{od}&\text{if }i=o\\ -y^{od}&\text{if }i=d\\ 0&\text{otherwise}\end{cases}\qquad\forall i,(o,d)\in\mathcal{S}\times\mathcal{K}\] (66c) \[\sum_{\forall(o,d)\in\mathcal{K}}w^{od}y_{ij}^{od}\leq x_{ij} \qquad\qquad\qquad\forall(i,j)\in\mathcal{A}\] (66d)

where (66c) are the flow-conservation constraints, (66d) are the capacity constraints that involve both upper and lower-level variables, coupling the optimization and motivating the use of BLOCC. Note that, for networks with \(n\) stations (nodes): i) the number of CCs is approximately \(n^{2}\); and ii) each of the constraints involves approximately \(n^{2}\) variables. Hence, even for a moderate-size network (say 30-50 nodes), we may have thousands of CCs involving millions of variables.

Experiment roadmap.To provide numerical results illustrating the behavior of our algorithm, we solve the optimization in (66) for three scenarios:

* The design of a 3-node simple synthetic network;

**S2)**: The design of a 9-node synthetic network from the prior transportation literature; and
**S3)**: The design of a (real-world) subway network for the city of Seville, Spain, with 24 nodes

where **S1)** involves 6 CCs and 48 variables, and **S3)** involves around 100 CCs and 50,000 variables.

For the 3-node network scenario, we will conduct a comparative analysis against other algorithms to evaluate the efficacy of our approach. In the other two scenarios, the baseline algorithms cannot find a solution; hence, for the 9-node and Seville networks, we will focus on providing insights into the performance and behavior of our algorithm under varying parameters, shedding light on the versatility and adaptability of our approach to real-world transportation networks.

Before delving into the presentation and analysis of the results, two additional remarks are in order:

* While one of the goals of these experiments was to compare our BLOCC algorithm against LV-HBA [75] and GAM [72], for the scenario at hand, the GAM algorithm cannot be implemented, since the inverse of a matrix at each iteration for the problem in (66) is not tractable. In this way, we only conducted the experiments using our BLOCC and LV-HBA.
* The BLOCC algorithm produces two lower-level variables: \(y_{F,T}^{T_{F}}\) and \(y_{g,T}^{T_{g}}\). While Theorems 1 and 2 guarantee that \((x_{T},y_{F,T}^{T_{g}})\) is an \(\epsilon\)-approximate solution, the pair \((x_{T},y_{g,T}^{T_{g}})\) is strictly feasible, meaning that \(y_{g,T}^{T_{g}}=y_{g}^{*}(x_{T})\). Since strict feasibility is important in the transportation network, this section will report the results using both \(y_{F,T}^{T_{F}}\) and \(y_{g,T}^{T_{g}}\).

### Numerical results for the 3-node network

In this section, we address the problem defined in equation (66) for a network comprising 3 nodes (stations). We assume that the graph of potential links \(\mathcal{A}\) is complete, leading to a total of 6 link capacities that need to be determined in the upper level. Additionally, as in the rest of the manuscript, we assume that there is demand for all markets, meaning that the set \(\mathcal{K}\) is complete and includes all 6 possible origin-destination pairs. The specific values of the key parameters can be found in Table 4, with further details about the simulated scenario available in the online code repository.

For BLOCC, we set the stepsize to \(\eta=1.6\times 10^{-4}\) and analyze the algorithm's convergence for three different values of \(\gamma\): \(\gamma=2\), \(\gamma=3\), and \(\gamma=4\). The upper-level objective values are computed using \(f(x_{t},y_{g,t}^{T_{g}})\) and \(f(x_{t},y_{F,t}^{T_{F}})\). The results are presented in Figures 7 and 8.

Figure 8: Optimality gap of the lower-level problem for a 3-node network design problem \(g(x_{t},y_{t})-g(x_{t},y_{t}^{*})\). Solid lines represent the mean value of the 10 realizations of the upper-level variables, dashed lines represent \(g(x_{t},y_{F,t}^{T_{F}})-g(x_{t},y_{t}^{*})\), and the shaded region is the standard deviation. Three different \(\gamma\) values are represented in our algorithm, and fixed stepsize \(\eta=1.6\times 10^{-4}\).

Figure 7: Upper-level objective \(f(x_{t},y_{t})\) for a 3-node network design problem; Solid lines show mean value of \(f(x_{t},y_{g,t}^{T_{g}})\) with the shaded region as a standard deviation: Dashed lines show the mean value of \(f(x_{t},y_{F,t}^{T_{F}})\) with the shaded region as a standard deviation: Three different \(\gamma\) values (red, purple, blue) and fixed stepsize \(\eta=1.6\times 10^{-4}\); The orange color represents the result of the LV-HBA algorithm.

Figure 7 illustrates the performance of our BLOCC algorithm over time. The orange line represents the evolution of \(f(x_{t},y_{t})\) for the LV-HBA algorithm, while the other six lines represent different implementations of BLOCC. Each color represents a different value of \(\gamma\); solid lines represent \(f(x_{t},y_{g,t}^{T_{g}})\) and dashed lines represent \(f(x_{t},y_{F,t}^{T_{F}})\). Each simulation is conducted 10 times with 10 different random initializations of the upper-level variables, and both the mean and the standard deviation values are displayed. The results indicate that all versions of our BLOCC algorithm converge in less than 10 seconds, while LV-HBA shows slight fluctuations even after running for more than 50 seconds. This may be attributed to the fact that the LV-HBA algorithm requires a joint projection into \(\{\mathcal{X}\times\mathcal{Y}:g^{c}(x,y)\leq 0\}\) at each iteration, involving 42 variables and 6 CCs.

Figure 8 shows the lower-level optimality gap, namely \(g(x_{t},y_{t})-g(x_{t},y^{*}(x_{t}))\) for LV-HBA and BLOCC with 3 different values of \(\gamma\). In the case of LV-HBA, lower-level optimality is not attained within 70 seconds of running time. Conversely, for BLOCC, lower-level optimality is achieved by construction when \(y_{t}\) is set to \(y_{g,T}^{T_{g}}\), resulting in a zero gap. Additionally, when \(y_{t}\) is set to \(y_{F,T}^{T_{F}}\), we observe that: i) lower-level optimality is accomplished for \(\gamma\geq 3\), and ii) when \(\gamma=2\), an optimality gap exists, but it is one order of magnitude smaller than that for LV-HBA.

### Numerical results for the 9-node network

In this case, we consider the network in [21], see also Figure 6, which has \(|\mathcal{S}|=9\) nodes and \(|\mathcal{A}|=30\) potential links. As before, we consider that all markets exist, so that \(|\mathcal{K}|=9\cdot 8=72\). The remaining parameters are described in Figure 6 and the code repository.

\begin{table}
\begin{tabular}{c||c|c|c|c|c|c} \hline \hline  & \multicolumn{6}{c}{Market \((o,d)\)} \\ \hline
**Parameter** & (1,2) & (1,3) & (2,1) & (2,3) & (3,1) & (3,2) \\ \hline demand \(w^{od}\) & 1 & 1 & 1 & 1 & 1 & 1 \\ \hline revenue \(m^{od}\) & 2 & 6 & 2 & 1 & 6 & 1 \\ \hline travel time incumbent \(t_{\rm ext}^{od}\) & 3 & 3 & 3 & 3 & 3 & 3 \\ \hline \hline  & \multicolumn{6}{c}{Link \((i,j)\)} \\ \hline
**Parameter** & (1,2) & (1,3) & (2,1) & (2,2) & (3,1) & (3,2) \\ \hline link construction cost \(c_{ij}\) & 1 & 10 & 1 & 3 & 10 & 3 \\ \hline link travel time \(t_{ij}\) & 1 & 10 & 1 & 2 & 10 & 2 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Value of the parameters for scenario 1 (3-node network). The value of \(\omega_{t}\) is set to \(0.1\).

Figure 9 is the counterpart of Figure 7 for the 9-node scenario, showing the behavior of our BLOCC algorithm for \(\eta=1.6\times 10^{-4}\) and \(\gamma\in\{2,3,4\}\). Each simulation is repeated 10 times (using 10 different random initializations of the upper-level variables), and both the mean and the standard deviation values are shown. Since the number of variables and constraints is almost one order of magnitude larger, the algorithm requires more time to converge. However, convergence takes place in a reasonable amount of time (20-40 times longer than in the previous 3-node test case). Regarding the optimal value, we observe that: i) the sensitivity of the (steady-state) optimal value with respect to \(\gamma\) is not too large; ii) the solutions based on \(y_{F,T}^{T_{p}}\) yield better upper-level values than those based on \(y_{g,T}^{T_{g}}\); and iii) the gap between \(f(x_{T},y_{g,T}^{T_{g}})\) and \(f(x_{T},y_{F,T}^{T_{F}})\) decreases as \(\gamma\) increases. Observation ii) is due to the fact that \(y_{F,T}^{T_{p}}\) is not feasible (meaning that it violates the optimality of the lower-level); hence, it is able to achieve a better upper-level objective. In addition, the behavior observed in iii) is consistent with the discussion in Section 2.2, with the value of \(\gamma\) having an impact on the suboptimality of \(y_{F,t}^{T_{p}}\) at the lower-level. Specifically, higher values of \(\gamma\) push \(y_{F,t}^{T_{p}}\) closer to \(y_{g,t}^{T_{g}}\) and, hence, decrease the lower-level optimality gap. Finally, we must note that for the solid lines (associated with \(y_{g,t}^{T_{g}}\)), it holds that \(f(x_{t},y_{g,t}^{T_{g}})=f(x_{t},y^{*}(x_{t}))\). This implies that if we need a solution that is feasible at the lower-level, then better objective values are associated with higher values of \(\gamma\).

### Numerical results for the Seville network

In this section, we demonstrate the practical use of BLOCC in a real transportation network design problem. Specifically, we address the design of a metro network in the city of Seville, which has approximately one million inhabitants and is located in the south of Spain, with the bus system as its competitor. The data for the demand, number of stations, and locations have been taken from [21]. Information about the construction costs, capacity, and travel time has been obtained from Spanish rapid transit operators (see references in [56; 10] for full details). The city authorities considered \(|\mathcal{S}|=24\) potential station locations. Regarding the links, the following assumptions are made:

* The link between nodes \((i,j)\in\mathcal{S}\times\mathcal{S}\) only exists if node \(j\) is one of the three closest neighbors to \(i\), or vice versa. The distance here is measured in terms of travel time. This assumption limits the number of lines in any station to be at most 3, which is a very mild assumption for a network with 24 stations.
* The link between nodes \((i,j)\in\mathcal{S}\times\mathcal{S}\) only exists if the travel time \(t_{ij}\) is less than 7 minutes. This is also a mild assumption, since it enables all the stations to be connected, including those that are further away from the city center (the airport and the university campus [21]).

Under these two conditions, the set \(\mathcal{A}\) of potential links contains \(|\mathcal{A}|=88\) links. The sets of links and stations, along with their actual locations, are shown in Figure 11. Finally, we consider all possible markets between nodes, so \(|\mathcal{K}|=24\times 23=552\).

Following the narrative in Sections F.2 and F.3, Figure 10 presents the evolution of the upper-level objective function with time for three values of the parameter \(\gamma\in\{2,3,4\}\). The stepsize value has been set to \(\eta=1.6\times 10^{-4}\), and two different initializations have been considered. Regarding the behavior of the algorithm with respect to the value of \(\gamma\) and the particular output chosen (\(y_{T,g}^{T_{g}}\) vs. \(y_{T,F}^{T_{F}}\)), the findings are very similar to those in Figure 9. Namely, smaller gaps are found for larger values of \(\gamma\), and if feasibility at the lower-level (i.e., consistency with the user preference level) must be preserved, better objective values are achieved for larger values of \(\gamma\).

The most important observation, however, is related to the running time. Specifically, Figure 10 reveals that, for this real-world scenario, our BLOCC algorithm converges in 10-20 hours. While this is more than 1,000 times larger than the convergence interval for the 3-node network, the number

Figure 11: Topology of the Seville network.

of variables and constraints here is 100 times larger. More importantly, in the context of network transportation design, optimization times of 100 hours are widely accepted even for single-level formulations. Overall, we believe that the numerical results demonstrate that the BLOCC algorithm proposed in this work can solve problems with a large number of variables and CCs, which can have practical value in real-world applications, such as the one studied in this section.

## Appendix G Sensitivity Analysis

Regarding the selection and impact of hyper-parameters on the performance of BLOCC, we conducted an ablation study on various values of the two critical parameters, \(\gamma\) and \(\eta\), and measured their effects on the optimal value and computational time. In this section, we present the sensitivity analysis on the toy example that we introduced in Section 4.1 and the 3-node network example for the transportation network planning problem in Section 4.3.

### Sensitivity analysis for the toy example

We present in Table 5 the results of lower-level optimality \(\|y_{g}^{*}(x_{T})-y_{F,T}\|\) using different \(\gamma\) and \(\eta\) to conduct BLOCC (Algorithm 1) on the toy example in Section 4.1.

From the table, we can draw the following empirical observations:

* _Larger values of \(\gamma\) bring the upper-level objectives closer to optimal_. This is consistent with Theorem 1 which illustrated that larger \(\gamma\) improves the accuracy of the lower-level optimality. Since the obtained solution \(y_{F,T}\) is closer to \(y_{g}^{*}(x_{T})\) for larger \(\gamma\) values, the distance between the \(f(x_{T},y_{F,T})\) and \(f(x_{T},y_{g}^{*}(x_{T}))\) will be closer as well.
* _For a sufficiently small fixed \(\eta\), larger \(\gamma\) lead to faster convergence_. This implies that _smaller_\(\eta\leq\frac{1}{l_{F,1}}\)_choice due to larger \(\gamma\) will not significantly dampen the convergence time_. This is because a large value of \(\gamma\) increases \(l_{F,1}\), sharpening the function \(F_{\gamma}(x)\) and its gradient will be larger for most points. Thus, the gradient update \(\eta\nabla F_{\gamma}(x_{t})\) will not be very small and thus won't make the convergence slower.

### Sensitivity Analysis for the 3-node network

We present in Table 6 the results of the upper-level objective value \(f(x,y)\) in network planning problem for a 3-node network, whose detailed framework is introduced in Section F.

\begin{table}
\begin{tabular}{c||c|c|c|c} \hline \hline  & \multicolumn{4}{c}{\(\|y_{g}^{*}(x_{T})-y_{F,T}\|\)} \\ \(\eta\) & \(\gamma=0.001\) & \(\gamma=0.01\) & \(\gamma=0.1\) & \(\gamma=1.0\) \\ \hline \hline
0.001 & \(0.028\pm 0.042\) & \(0.035\pm 0.076\) & \(0.027\pm 0.064\) & \(0.000\pm 0.000\) \\  & \((3.314\pm 0.042)\) & \((3.186\pm 0.076)\) & \((2.049\pm 0.064)\) & \((1.967\pm 0.000)\) \\ \hline
0.01 & \(0.020\pm 0.031\) & \(0.020\pm 0.041\) & \(0.009\pm 0.019\) & \(0.000\pm 0.000\) \\  & \((2.242\pm 0.031)\) & \((1.575\pm 0.041)\) & \((1.118\pm 0.019)\) & \(0.585\pm 0.000\) \\ \hline
0.1 & \(0.006\pm 0.010\) & \(0.017\pm 0.027\) & \(0.011\pm 0.033\) & \(0.000\pm 0.000\) \\  & \((1.616\pm 0.010)\) & \((1.475\pm 0.027)\) & \((1.257\pm 0.033)\) & \((0.383\pm 0.000)\) \\ \hline
1.0 & \(0.023\pm 0.019\) & \(0.030\pm 0.022\) & \(0.020\pm 0.045\) & \(0.000\pm 0.000\) \\  & \((7.118\pm 0.019)\) & \((4.570\pm 0.022)\) & \((3.477\pm 0.045)\) & \((1.645\pm 0.000)\) \\ \hline
10.0 & \(0.034\pm 0.123\) & \(0.019\pm 0.014\) & \(0.025\pm 0.070\) & \(0.000\pm 0.000\) \\  & \((6.565\pm 0.123)\) & \((4.365\pm 0.014)\) & \((2.808\pm 0.070)\) & \((1.750\pm 0.000)\) \\ \hline \hline \end{tabular}
\end{table}
Table 5: Sensitivity analysis for the hyperparameters in Section 4.1. Top line in each cell represents the optimality gap \(\|y_{g}^{*}(x_{T})-y_{F,T}\|\), while the bottom line represents the time required for the algorithm to converge. Both the mean and the standard deviation are for 40 simulations.

[MISSING_PAGE_FAIL:38]

**LV-HBA**[75], also a first-order method, has similar gradient calculation costs. However, its projection onto \(\{\mathcal{X}\times\mathcal{Y}:g^{c}(x,y)\leq 0\}\) is expensive, with a complexity of \(\mathcal{O}((d_{x}+d_{y})^{3.5})\) of using interior point method to find the projected point [38], and evaluating \(g^{c}(x,y)\leq 0\) adds \(\mathcal{O}(d_{x}d_{y}d_{c})\) as it requires \(d_{c}\) inequality judgment on functions taking input dimension \(d_{x},d_{y}\).

**GAM**[72] lacks an explicit algorithm for lower-level optimality and Lagrange multipliers. Even if we omit this, calculating \(\nabla_{yy}^{\mathcal{F}}g\) and its inverse incurs a cost of \(\mathcal{O}(d_{y}^{3})\). Additionally, it has cost \(\mathcal{O}(d_{x}^{2}+d_{c}(d_{x}+d_{y}))\) for projection onto \(\mathcal{X}\) and calculating gradients.

We can see that BLOCC stands out with the lowest computational cost in both iterational and overall complexity thanks to its first-order and joint-projection-free nature. Consequently, BLOCC is particularly well-suited for large-scale applications with high-dimensional parameters.

### Complexity analysis of BLOCC

At each iteration \(t\), our proposed BLOCC algorithm in Algorithm 1 involves:

**Step 1:**: Solve two max-min problems.
**Step 2:**: Calculate \(g_{F,t}\) in (13) and update \(x_{t+1}=\operatorname{Proj}_{\mathcal{X}}\big{(}x_{t}-\eta g_{F,t}\big{)}\).

where **Step 1** can be achieved by our proposed max-min solver in Algorithm 2. In the following, we provide analysis for using the accelerated version of the Algorithm 2 in the _general case_ (Theorem 3) and the single-loop version for the _special case_ (Theorem 4) as discussed in Section 3.3.

In the _general case_, we use the accelerated version of Algorithm 2 to solve both (7) and (5). For solving (7), at each inner loop iteration \(t\), line 3 of the algorithm is of computational cost \(\mathcal{O}(d_{c})\). The update of \(y\) in line 4-6 involves calculating \(\nabla_{y}g(x,y)\) with a cost of \(\mathcal{O}(d_{y})\), finding \(\langle\mu,\nabla_{y}g^{c}(x,y)\rangle\) for fixed \(x\) of \(\mathcal{O}(d_{y}d_{c})\) following assumption **A1**), and the projection \(\operatorname{Proj}_{\mathcal{Y}}\) of complexity \(\mathcal{O}(d_{y}^{2})\) according to **A2**). Moreover, \(y\) converges linearly as \(L(\mu,y)\) is strongly convex in \(y\) (Lemma 7), this inner update for \(y\) gives an iteration complexity of \(\mathcal{O}(\ln(\epsilon^{-1}))\). Therefore, the cost of the update for \(y\) totals up to \(\mathcal{O}(\ln(\epsilon^{-1})\big{(}d_{y}d_{c}+d_{y}^{2}))\). The update of \(\mu\) in line 7 involves \(\mathcal{O}(d_{y}d_{c})\) for calculating \(\nabla_{\mu}L(\mu_{t+1/2},y_{t+1})=g^{c}(x,y_{t+1})\) with \(x\) being fixed, and \(\mathcal{O}(d_{c})\) for projection onto \(\mathbb{R}_{+}^{d_{c}}\).

Moreover, to achieve target accuracy \(\epsilon\) on the metric \(\frac{1}{T}\sum_{t=0}^{T}\|G_{\eta}(x_{t})\|^{2}\leq\epsilon\), with \(\gamma=\mathcal{O}(\epsilon^{-1})\) using the BLOCC algorithm, the iteration complexity of the max-min solver is \(\mathcal{O}(\epsilon^{-1})\) according to Theorem 3. Therefore, the complexity for solving (7) in the _general case_ using the accelerated version of Algorithm 2 (Theorem 3) is

\[\mathcal{O}(\epsilon^{-1}(\ln(\epsilon^{-1})(d_{y}d_{c}+d_{y}^{2})+d_{c}d_{y} +d_{c}))=\tilde{\mathcal{O}}(\epsilon^{-1}(d_{y}d_{c}+d_{y}^{2})).\] (67)

Solving (5) is of the same order as the only difference is in calculating \(\nabla_{y}f(x,y)\). In this way, we can conclude that **Step 1** is at a cost of \(\tilde{\mathcal{O}}(\epsilon^{-1}(d_{y}d_{c}+d_{y}^{2}))\) in the _general case_.

In the _special case_ (Theorem 4), the non-accelerated (single-loop) version of Algorithm 2 involves \(y_{t+1}=\operatorname{Proj}_{\mathcal{Y}}(y_{t}-\eta_{1}\nabla_{y}L(\mu_{t},y_ {t}))\) with complexity \(\tilde{\mathcal{O}}(d_{y}^{2}+d_{y}d_{c})\), and \(\mu_{t+1}=\operatorname{Proj}_{\mathbb{R}_{+}^{d_{c}}}(\mu_{t}+\eta_{2}\nabla_{ \mu}L(\mu_{t},y_{t+1}))\) with complexity \(\mathcal{O}(d_{c}+d_{y}d_{c})\) following a similar analysis as in the general case.

Moreover, the algorithm converges linearly in the special case of \(g^{c}\) being affine in \(y\) and the computational complexity is \(\mathcal{O}(\ln(\epsilon^{-1}))\), according to Theorem 4. Therefore, the complexity for the max-min **Step 1** in the _special case_ is

\[\mathcal{O}(\ln(\epsilon^{-1})(d_{y}d_{c}+d_{y}^{2}+d_{c}))=\tilde{\mathcal{O} }(d_{y}d_{c}+d_{y}^{2}+d_{c}).\] (68)

**Step 2** involves calculating \(\nabla_{x}g(x,y)\) with with a fixed \(y\), and \(\langle\mu,\nabla_{x}g^{c}(x,y)\rangle\) for fixed \(\mu,y\), which are of complexity \(\mathcal{O}(d_{x})\) and \(\mathcal{O}(d_{x}d_{c})\) respectively, and conducting a projection on \(\mathcal{X}\) of cost \(\mathcal{O}(d_{x}^{2})\) according to assumption **A2**).

In this way, the computational complexity of **Step 2** is

\[\mathcal{O}(d_{x}d_{c}+d_{x}^{2}).\] (69)

We can therefore conclude the complexity of BLOCC in Table 7.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The abstract and introduction clearly state the claims made, including the contributions made in the paper and important assumptions and limitations.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: yes, we have discussed in the conclusions.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: All have been clearly listed.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The code used to run the experiments is published on GitHub.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: The data files considered and the code used to run the experiments are published on GitHub.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: All the necessary details to run the experiments are available in the code.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: The figures in the paper include confidence intervals representing the standard deviation for different realizations of the experiments. Also, the tables include the standard deviation of the simulations.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA]Justification: The paper is theory paper, and does not include much computation-heavy experiments.
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We follow the NeurIPS Code of Ethics.
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: The work is foundational research, and there is no societal impact of the work performed.
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper poses no such risks.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: The paper does not use existing assets.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: the paper does not release new assets.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA]. Justification: The paper does not involve crowdsourcing nor research with human subjects.