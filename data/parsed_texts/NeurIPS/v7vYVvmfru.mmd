# An Accelerated Algorithm for Stochastic Bilevel Optimization under Unbounded Smoothness

 Xiaochuan Gong  Jie Hao  Mingrui Liu

Department of Computer Science

George Mason University

{xgong2, jhao6, mingruil}@gmu.edu

Corresponding Author.

###### Abstract

This paper investigates a class of stochastic bilevel optimization problems where the upper-level function is nonconvex with potentially unbounded smoothness and the lower-level problem is strongly convex. These problems have significant applications in sequential data learning, such as text classification using recurrent neural networks. The unbounded smoothness is characterized by the smoothness constant of the upper-level function scaling linearly with the gradient norm, lacking a uniform upper bound. Existing state-of-the-art algorithms require \(\widetilde{O}(\epsilon^{-4})\) oracle calls of stochastic gradient or Hessian/Jacobian-vector product to find an \(\epsilon\)-stationary point. However, it remains unclear if we can further improve the convergence rate when the assumptions for the function in the population level also hold for each random realization almost surely (e.g., Lipschitzness of each realization of the stochastic gradient). To address this issue, we propose a new Accelerated Bilevel Optimization algorithm named AccBO. The algorithm updates the upper-level variable by normalized stochastic gradient descent with recursive momentum and the lower-level variable by the stochastic Nesterov accelerated gradient descent algorithm with averaging. We prove that our algorithm achieves an oracle complexity of \(\widetilde{O}(\epsilon^{-3})\) to find an \(\epsilon\)-stationary point, when the lower-level stochastic gradient has a small variance \(O(\epsilon)\). Our proof relies on a novel lemma characterizing the dynamics of stochastic Nesterov accelerated gradient descent algorithm under distribution drift with high probability for the lower-level variable, which is of independent interest and also plays a crucial role in analyzing the hypergradient estimation error over time. Experimental results on various tasks confirm that our proposed algorithm achieves the predicted theoretical acceleration and significantly outperforms baselines in bilevel optimization. The code is available here.

## 1 Introduction

Bilevel optimization receives tremendous attention recently in the machine learning community, due to its applications in meta-learning [27, 59], hyperparameter optimization [27, 25], data hyper-cleaning [44], continual learning [7, 37], and reinforcement learning [47]. The bilevel optimization problem has the following formulation:

\[\min_{x\in\mathbb{R}^{d_{x}}}\Phi(x):=f(x,y^{*}(x)),\ \ \text{s.t.},\ \ y^{*}(x) \in\operatorname*{arg\,min}_{y\in\mathbb{R}^{d_{y}}}g(x,y),\] (1)

where \(f\) and \(g\) are upper-level and lower-level functions respectively. For example, in meta-learning [26, 27], \(x\) denotes the layers of neural networks for shared representation learning, \(y\) denotes the task-specific head encoded in the last layer, and the formulation (1) aims to learn the acommon representation learning encoder \(x\) such that it can be quickly adapted to downstream tasks by only updating the task-specific head \(y\). In machine learning, people typically consider stochastic optimization setting such that \(f(x,y)=\mathbb{E}_{\xi\sim\mathcal{D}_{f}}\left[F(x,y;\xi)\right]\) and \(g(x,y)=\mathbb{E}_{\zeta\sim\mathcal{D}_{g}}\left[G(x,y;\zeta)\right]\), where \(\mathcal{D}_{f}\) and \(\mathcal{D}_{g}\) are the underlying unknown data distributions for \(f\) and \(g\) respectively, and one can access noisy observations of \(f\) and \(g\) based on sampling from \(\mathcal{D}_{f}\) and \(\mathcal{D}_{g}\).

There emerges a wave of studies for algorithmic design and analysis for solving the bilevel optimization problem (1) under different assumptions of \(f\) and \(g\). Most theoretical work assumes the upper-level function is smooth (i.e., gradient is Lipschitz) and nonconvex, and the lower-level function is strongly convex [30, 44, 41, 33, 48]. However, as pointed out by [75, 15], certain neural networks such as recurrent neural networks [22], long-short term memory networks [40] and transformers [65] have smoothness constants that scale with gradient norm, potentially leading to unbounded smoothness constants (i.e., gradient Lipschitz constant can be infinity). Motivated by this, Hao et al. [38] designed the first bilevel optimization algorithm to handle the cases where \(f\) is nonconvex with potentially unbounded smoothness and \(g\) is strongly convex. The algorithm in [38] achieves \(\widetilde{O}(\epsilon^{-4})\) oracle complexity for finding an \(\epsilon\)-stationary point (i.e., a point \(x\) such that \(\|\nabla\Phi(x)\|\leq\epsilon\)). Gong et al. [32] proposed an single-loop algorithm under the same setting as in [38] and also achieved \(\widetilde{O}(\epsilon^{-4})\) oracle complexity. This complexity result is worse than the \(\widetilde{O}(\epsilon^{-3})\) oracle complexity under the relatively easier setting where \(f\) has a Lipschitz gradient, and each realization of the stochastic oracle calls is Lipschitz with respect to its argument (e.g., almost-sure Lipschitz oracle) [71, 46, 18, 34, 43]. This naturally motivates us to study the following question:

**Is it possible to improve the \(\widetilde{O}(\epsilon^{-4})\) oracle complexity for bilevel optimization problems where the upper-level function is nonconvex with unbounded smoothness and the lower-level function is strongly convex, by assuming that the properties of the function at the population level also hold almost surely for each random realization?**

In this paper, we give a positive answer to this question by designing a new algorithm named AccBO with an improved oracle complexity of \(\widetilde{O}(\epsilon^{-3})\), when the lower-level stochastic gradient has a small variance \(O(\epsilon)\). Our algorithm is inspired by momentum-based variance reduction techniques used in nonconvex smooth optimization [18] under the almost-sure Lipschitz stochastic gradient oracle framework. The innovation of AccBO lies in its update rules: it employs normalized stochastic gradient descent with recursive momentum for the upper-level variable and stochastic Nesterov accelerated gradient descent with averaging for the lower-level variable. Our approach differs from existing accelerated bilevel optimization algorithms, such as those proposed by [71, 46] in two key ways: (i) while these algorithms use recursive momentum for the upper-level variable update, AccBO utilizes normalized recursive momentum to address the unbounded smoothness of the upper-level function; (ii) for the lower-level variable update, we use stochastic Nesterov accelerated gradient descent with averaging, in contrast to the recursive momentum method used by the other algorithms. The primary challenge in analyzing the convergence rate of AccBO arises from the need to simultaneously control errors from both upper-level and lower-level variables, given the unbounded smoothness, large learning rate, and recursive momentum in the upper-level problem. Our main contributions are summarized as follows.

* We design a new algorithm named AccBO for solving bilevel optimization problems where the upper-level function is nonconvex with unbounded smoothness and the lower-level function is strongly convex. AccBO leverages normalized recursive momentum for the upper-level variable and Nesterov momentum for the lower-level variable under the stochastic setting to achieve acceleration. To the best of our knowledge, the simultaneous usage of these two techniques in stochastic bilevel optimization is novel and has not been previously explored in the bilevel optimization literature.
* We prove that the AccBO algorithm requires \(\widetilde{O}(\epsilon^{-3})\) oracle calls for finding an \(\epsilon\)-stationary point, when the variance of the lower-level stochastic gradient is \(O(\epsilon)\). This complexity strictly improves the state-of-the-art oracle complexity for unbounded smooth nonconvex upper-level problem and strongly-convex lower-level problem as described in [38, 32]2. To achieve this result, we introduce novel proof techniques for analyzing the dynamics of stochastic Nesterov accelerated gradient descent under distribution drift with high probability for the lower-level variable, which are crucial for analyzing the hypergradient error and also of independent interest.
* We empirically verify the effectiveness of our proposed algorithm on various tasks, including deep AUC maximization and data hypercleaning. Our algorithm indeed achieves the predicted theoretical acceleration and significantly outperforms baselines in bilevel optimization.

## 2 Related Work

**Relaxed Smoothness.** The concept of relaxed smoothness was initially introduced by [75], inspired by the loss landscapes observed in recurrent neural networks and long-short term memory networks. They show that techniques such as gradient clipping and normalization could improve the performance compared with gradient descent in these scenarios. It inspired further investigations that concentrate on various aspects, including improved analysis on gradient clipping and normalization [74; 45], adaptive algorithms [15; 51; 68; 24], federated algorithms [54; 16; 17], generalized assumptions [15; 14], and recursive momentum based methods with faster rates [60; 56]. The work of [38; 32] considered a relaxed smoothness condition for the upper-level problem in the bilevel optimization setting.

**Bilevel Optimization.** Bilevel optimization refers to a special kind of optimization where one problem is embedded within another. It was first introduced by [9]. Early works developed specific bilevel optimization algorithms with asymptotic convergence analysis [67; 1; 69]. Ghadimi and Wang [30] initiated the study of non-asymptotic convergence for gradient-based methods in bilevel optimization where the upper-level problem is smooth and the lower-level problem is strongly convex. This field saw further advancements with improved complexity results [41; 44; 11; 21; 12] and fully first-order algorithms [48; 52]. There is a line of work which leverages almost-sure Lipschitz oracle (e.g., stochastic gradient) to obtain improved convergence rates of bilevel optimization algorithms [71; 46]. When the lower-level function is not strongly convex, several algorithmic framework and approximation schemes were proposed [61; 63; 49; 62; 55; 10]. The setting considered in this paper is very close to [38; 32], where the upper-level function is nonconvex and unbounded smooth, and the lower-level function is strongly convex. However, the work of [38; 32] do not have an accelerated rate \(\widetilde{O}(\epsilon^{-3})\) for finding an \(\epsilon\)-stationary point as established in this paper.

**Nesterov Accelerated Gradient and Variants.** Nesterov Accelerated Gradient (NAG) method was introduced by [58] for deterministic convex optimization problems. The stochastic version of NAG (SNAG) was extensively studied in the literature [3; 5; 66; 13]. To the best of our knowledge, none of them provide a high probability analysis for SNAG. In the online learning setting, there is a line of work focusing on the perspective of sequential stochastic/online optimization with distributional drift [6; 70; 57; 20]. While these studies provide valuable insights into adaptive techniques and performance bounds under distributional drift, they do not explore the potential integration of such methods with bilevel optimization problems, nor do they consider the application of SNAG within this framework.

## 3 Problem Setup and Preliminaries

Define \(\langle\cdot,\cdot\rangle\) and \(\|\cdot\|\) as the inner product and the Euclidean norm. Throughout the paper, we use asymptotic notation \(\widetilde{O}(\cdot)\), \(\widetilde{\Theta}(\cdot)\), \(\widetilde{\Omega}(\cdot)\) to hide polylog factors in \(\epsilon^{-1}\) and \(1/\delta\). Denote \(f\): \(\mathbb{R}^{d_{x}}\times\mathbb{R}^{d_{y}}\rightarrow\mathbb{R}\) as the upper-level function, and \(g\): \(\mathbb{R}^{d_{x}}\times\mathbb{R}^{d_{y}}\rightarrow\mathbb{R}\) as the lower-level function. The hypergradient \(\nabla\Phi(x)\) has the following form [30]:

\[\nabla\Phi(x)=\nabla_{x}f(x,y^{*}(x))-\nabla_{xy}^{2}g(x,y^{*}(x))\left[ \nabla_{yy}^{2}g(x,y^{*}(x))\right]^{-1}\nabla_{y}f(x,y^{*}(x)).\] (2)

To avoid the Hessian inverse computation, we typically use the following Neumann series to approximate the hypergradient [30; 46; 41]. In particular, for the stochastic setting, define

\[\bar{\nabla}f(x,y;\bar{\xi})=\nabla_{x}F(x,y;\xi)-\frac{Q}{l_{g,1}}\nabla_{xy }^{2}G(x,y;\zeta^{(0)})\prod_{i=1}^{\mathfrak{q}(Q)}\left(I-\frac{\nabla_{yy} ^{2}G(x,y;\zeta^{(i)})}{l_{g,1}}\right)\nabla_{y}F(x,y;\xi),\]

where \(\mathfrak{q}(Q)\sim\mathrm{Uniform}\{0,\ldots,Q-1\}\), \(\bar{\xi}:=\{\xi,\zeta^{(0)},\ldots,\zeta^{(\mathfrak{q}(Q))}\}\) and we use the convention that \(\prod_{i=1}^{j}A_{i}=I\) if \(j=0\). Then \(\mathbb{E}_{\bar{\xi}}[\bar{\nabla}f(x,y;\bar{\xi})]\) is a good approximation of \(\nabla\Phi(x)\) if \(y\) and \(y^{*}(x)\) are close [30].

Throughout the paper, we make the following assumptions.

**Assumption 3.1** (\((L_{x,0},L_{x,1},L_{y,0},L_{y,1})\)-smoothness [38]).: _Let \(z=(x,y)\) and \(z^{\prime}=(x^{\prime},y^{\prime})\), there exists \(L_{x,0},L_{x,1},L_{y,0},L_{y,1}>0\) such that for all \(z,z^{\prime}\), if \(\|z-z^{\prime}\|\leq 1/\sqrt{2(L_{x,1}^{2}+L_{y,1}^{2})}\), then \(\|\nabla_{x}f(z)-\nabla_{x}f(z^{\prime})\|\leq(L_{x,0}+L_{x,1}\|\nabla_{x}f(z) \|)\|z-z^{\prime}\|\) and \(\|\nabla_{y}f(z)-\nabla_{y}f(z^{\prime})\|\leq(L_{y,0}+L_{y,1}\|\nabla_{y}f(z) \|)\|z-z^{\prime}\|\)._

**Remark**: Assumption 3.1 is introduced by [38] for describing the bilevel optimization problems with recurrent neural networks. This assumption can be regarded as a block-wise relaxed smoothness assumptions for two blocks \(x\) and \(y\), which is a variant of the relaxed smoothness assumption [75] and the coordinate-wise relaxed smooth assumption [15].

**Assumption 3.2**.: _Suppose the followings hold for objective functions \(f\) and \(g\): (i) \(f\) is continuously differentiable and \((L_{x,0},L_{x,1},L_{y,0},L_{y,1})\)-smooth in \((x,y)\); (ii) For every \(x\), \(\|\nabla_{y}f(x,y)\|\leq l_{f,0}\) for all \(y\); (iii) For every \(x\), \(g(x,y)\) is \(\mu\)-strongly-convex in \(y\) for \(\mu>0\); (iv) \(g\) is \(l_{g,1}\)-smooth jointly in \((x,y)\); (v) \(g\) is twice continuously differentiable, and \(\nabla_{xy}^{2}g,\nabla_{yy}^{2}g\) are \(l_{g,2}\)-Lipschitz jointly in \((x,y)\)._

**Remark**: Assumption 3.2 is standard in the bilevel optimization literature [48; 38; 30]. Assumption 3.2 (i) characterizes the unbounded smoothness of the upper-level function and is empirically observed in recurrent neural networks [38].

**Assumption 3.3**.: _The following stochastic estimators are unbiased and have the following properties:_

\[\mathbb{E}_{\xi\sim\mathcal{D}_{f}}[\|\nabla_{x}F(x,y;\xi)-\nabla _{x}f(x,y)\|^{2}]\leq\sigma_{f,1}^{2},\quad\mathbb{E}_{\xi\sim\mathcal{D}_{f} }[\|\nabla_{y}F(x,y;\xi)-\nabla_{y}f(x,y)\|^{2}]\leq\sigma_{f,1}^{2},\] \[\Pr(\|\nabla_{y}G(x,y;\xi)-\nabla_{y}g(x,y)\|\geq\lambda)\leq 2 \exp(-2\lambda^{2}/\sigma_{g,1}^{2})\quad\forall\lambda>0,\] \[\mathbb{E}_{\zeta\sim\mathcal{D}_{g}}[\|\nabla_{xy}^{2}G(x,y;\zeta )-\nabla_{xy}^{2}g(x,y)\|^{2}]\leq\sigma_{g,2}^{2},\quad\mathbb{E}_{\zeta\sim \mathcal{D}_{g}}[\|\nabla_{yy}^{2}G(x,y;\zeta)-\nabla_{yy}^{2}g(x,y)\|^{2}] \leq\sigma_{g,2}^{2}.\]

**Remark:** Assumption 3.3 assumes the stochastic oracle for the upper-level problem has bounded variance, which is standard in nonconvex stochastic optimization [28; 29; 30]. It also assumes the stochastic oracle for the lower-level problem is light-tailed, which is common for the high probability analysis for the lower-level problem [50; 39]. Note that the same assumption is also made in [38; 32] for the bilevel problems with a unbounded smooth upper-level function.

**Assumption 3.4**.: \(F(x,y;\xi)\) _and \(G(x,y;\zeta)\) satisfy Assumption 3.2 for every \(\xi\) and \(\zeta\) almost surely._

**Remark:** Assumption 3.4 assumes that each random realization of the upper- and lower-level functions satisfies the same property as in the population level. Note that this condition is the key to achieve an improved \(\widetilde{O}(\epsilon^{-3})\) oracle complexity under various settings, including both single-level nonconvex smooth problems [23; 18; 64] and bilevel problems with nonconvex smooth upper-level objectives [71; 46]. Furthermore, this assumption is shown to be necessary for achieving improved oracle complexity in single-level problems [2].

## 4 Algorithm and Analysis

### Main Challenges and Algorithm Design

**Main Challenges.** We begin by explaining why existing bilevel optimization algorithms and their corresponding analysis techniques are insufficient in our setting. First, most algorithms developed for bilevel optimization require the upper-level function is smooth (i.e., the gradient of the upper-level function is Lipschitz) [30; 44; 41; 71; 46; 21; 48]. They characterize the estimation error of the optimal solution for the lower-level problem, utilize an approximate hypergradient descent approach and the descent lemma for \(L\)-smooth functions to prove the convergence. In particular, they demonstrate that a potential function, incorporating both the function value and the bilevel error from the lower-level problem, progressively decreases in expectation. However, when the upper-level function is \((L_{x,0},L_{x,1},L_{y,0},L_{y,1})\)-smooth as illustrated in Assumption 3.1, the previous algorithms and analyses relying on \(L\)-smoothness do not work. The reason is that the hypergradient bias depends on the approximation error of the lower-level variable as well as the hypergradient itself: these elements are statistically dependent and the standard potential function argument with an expectation-based analysis would not work. To address this issue, the work of [38; 32] requires a careful high probability analysis in the unbounded smoothness setting and obtains \(\widetilde{O}(\epsilon^{-4})\) oracle complexity. Such a requirement of high probability analysis prevents us from leveraging the momentum-basedvariance reduction technique for updating the lower-level variable. For example, the work [46] which has \(\widetilde{O}(\epsilon^{-3})\) oracle complexity in the smooth case leverages the momentum-based variance reduction technique [18] for updating the lower-level variable with an expectation-based analysis, but it seems difficult to establish a high probability analysis for the momentum-based variance reduction algorithm in terms of the lower-level variable. Second, the recent work of Hao et al. [38] and Gong et al. [32] considered that the upper-level function is unbounded smooth and addressed this issue by performing normalized stochastic gradient with momentum for the upper-level variable and periodic updates or stochastic gradient descent for the lower-level variable, but their oracle complexity is not better than \(\widetilde{O}(\epsilon^{-4})\). These facts indicate that we need new algorithm design and analysis techniques to get potential acceleration.

**Algorithm Design.** To obtain potential acceleration and enable a high probability analysis for the lower-level variable, our key idea is to update the upper-level variable by normalized stochastic gradient descent with recursive momentum and update the lower-level variable by the stochastic Nesterov accelerated gradient (SNAG) method. Different from [38; 32], the key innovation of our algorithm design is that we achieve acceleration for both upper-level and lower-level problems simultaneously but without affecting each other. The upper-level update rule can be regarded as a generalization of the acceleration technique (e.g., the momentum-based variance reduction technique) [18; 56] from single-level to bilevel problems. The main challenge is that we need to deal with the accumulated error of the recursive momentum over time due to the hypergradient bias, which is caused by the inaccurate estimation of the optimal lower-level variable. Therefore we require a very small tracking error between the iterate of the lower-level variable and the optimal lower-level solution defined by the upper-level variable (i.e., \(y^{*}(x)\)) at every iteration. This requirement is satisfied by executing SNAG method under the distribution drift for the lower-level problem, where the drift is caused by the change of the upper-level variable over time. Note that we can provide a high probability analysis of the SNAG method under distributional drift, which strictly improves the analysis of SGD under distributional drift in [19] in the small stochastic gradient noise regime.

The detailed description of our algorithm is illustrated in Algorithm 2. At the very beginning, we run a certain number of iterations of SNAG for the fixed upper-level variable \(x_{0}\) (line \(2\)) as the warm-start stage, and then update the lower-level variable by SNAG (line \(8\sim 20\)) with averaging (line \(21\)) and update the upper-level variable by normalized stochastic gradient descent with recursive momentum (line \(23\sim 24\)). Note that we have two options for implementing SNAG. In Option I (line \(8\sim 9\)), the algorithm simply runs SNAG under distribution drift caused by the sequence \(\{x_{i}\}\). Option I is specifically designed for a particular subset of bilevel optimization problems where the lower-level function is a quadratic function. Option II (line \(11\sim 20\)) is designed for a broader range of bilevel optimization problems, accommodating general strongly-convex lower-level functions. In Option II, we run SNAG with periodic updates: the lower-level update is performed for \(N\) iterations only when the iteration number \(t\) is a multiple of \(I\).

```
1:Input:\(x,\tilde{y}_{-1},\tilde{y}_{0},\tilde{\alpha},T_{0}\) # SNAG\((x,\tilde{y}_{0},\tilde{\alpha},T_{0})\)
2:for\(t=0,1,\ldots,T_{0}-1\)do
3: Sample \(\tilde{\pi}_{t}\) from distribution \(\mathcal{D}_{g}\)
4:\(\tilde{z}_{t}=\tilde{y}_{t}+\gamma(\tilde{y}_{t}-\tilde{y}_{t-1})\)
5:\(\tilde{y}_{t+1}=\tilde{z}_{t}-\tilde{\alpha}\nabla_{y}G(x,\tilde{z}_{t}; \tilde{\pi}_{t})\)
6:endfor ```

**Algorithm 1** Stochastic Nesterov Accelerated Gradient Method (SNAG)

### Main Results

We first introduce some useful notations. Let \(\sigma(\cdot)\) be the \(\sigma\)-algebra generated by the random variables in the argument. We define the following filtrations for \(t\geq 1\): \(\mathcal{F}^{\mathrm{init}}=\sigma(\tilde{\pi}_{0},\ldots,\tilde{\pi}_{T_{0}-1})\), \(\mathcal{F}_{t}=\sigma(\tilde{\xi}_{0},\ldots,\tilde{\xi}_{t-1})\), \(\widetilde{\mathcal{F}}_{t}^{1}=\sigma(\pi_{0},\ldots,\pi_{t-1})\), and we also define \(\widetilde{\mathcal{F}}_{t}^{2}=\sigma(\pi_{t}^{0},\ldots,\pi_{t}^{N-1})\) when \(t\) is a multiple of \(I\). We use \(\mathbb{E}_{t}\), \(\mathbb{E}_{\mathcal{F}_{t}}\) and \(\mathbb{E}\) to denote the conditional expectation \(\mathbb{E}[\cdot\mid\mathcal{F}_{t}]\), the expectation over \(\mathcal{F}_{t}\) and the total expectation over \(\mathcal{F}_{T}\) respectively.

**Theorem 4.1**.: _Suppose Assumptions 3.1 to 3.4 hold. Let \(\{x_{t}\}\) be the iterates produced by Algorithm 2. For any given \(\delta\in(0,1)\) and small enough \(\epsilon\) (see exact choice in (54)), if \(\sigma_{g,1}=O(\sqrt{\epsilon})\) as defined in (55), and we set parameters \(\alpha^{\mathrm{init}},\alpha,\beta,\gamma,\eta,\tau,I,N,S,Q,T_{0}\) (see exact choices in (56), (57), (58),(59), and (60)) as

\[\alpha^{\rm init}=\widetilde{\Theta}(\epsilon^{4}),\quad\alpha= \widetilde{\Theta}(\epsilon^{2}),\quad 1-\beta=\widetilde{\Theta}(\epsilon^{2}),\quad\eta= \widetilde{\Theta}(\epsilon^{2}),\quad\tau=\widetilde{\Theta}(\epsilon),\quad \gamma=O(1),\] \[T_{0}=\widetilde{O}(\epsilon^{-2}),\quad I=\widetilde{O}( \epsilon^{-1}),\quad N=\widetilde{O}(\epsilon^{-1}),\quad Q=\widetilde{O}(1),\quad S=\widetilde{O}(1).\]

Then with probability at least \(1-2\delta\) over the randomness in \(\sigma(\mathcal{F}^{\rm init}\cup\widetilde{\mathcal{F}}_{T}^{1})\) (for Option I) or \(\sigma(\mathcal{F}^{\rm init}\cup(\cup_{t\leq T}\widetilde{\mathcal{F}}_{t}^{2}))\) (for Option II), Algorithm 2 guarantees \(\frac{1}{T}\sum_{t=1}^{T}\mathbb{E}\|\nabla\Phi(x_{t})\|\leq 20\epsilon\) within \(T=\frac{4d_{0}}{\eta\epsilon}=\widetilde{O}(\epsilon^{-3})\) iterations, where \(d_{0}\coloneqq\Phi(x_{0})-\inf_{x}\Phi(x)\) and the expectation is taken over the randomness over \(\mathcal{F}_{T}\). For Option I, it requires \(T_{0}+SQT=\widetilde{O}(\epsilon^{-3})\) oracle calls of stochastic gradient or Hessian/Jacobian vector product. For Option II, it requires \(T_{0}+\frac{NT}{I}+SQT=\widetilde{O}(\epsilon^{-3})\) oracle calls of stochastic gradient or Hessian/Jacobian vector product._

```
1:Input:\(\alpha^{\rm init},\alpha,\beta,\gamma,\eta,\tau,I,S,T_{0},T\), set \(x_{0},y_{0}^{\rm init}=0\)
2:\(y_{0}=\textsc{NAG}(x_{0},y_{0}^{\rm init},\alpha^{\rm init},T_{0})\), and set \(y_{-1}=y_{0}=y_{0}\)# Warm-start
3:for\(t=0,1,\ldots,T-1\)do
4: Sample \(\mathfrak{q}(Q)\sim\mathrm{Uniform}\{0,\ldots,Q-1\}\) and \(\{\zeta_{t,s}^{(0)},\ldots,\zeta_{t,s}^{(\mathfrak{q}(Q))}\}_{s=1}^{S}\sim \mathcal{D}_{g}\)
5: Sample \(\{\xi_{t,s}\}_{s=1}^{S}\sim\mathcal{D}_{f}\), denote \(\bar{\xi}_{t}\coloneqq\cup_{s=1}^{S}\{\mathfrak{q}(Q),\xi_{t,s},\zeta_{t,s}^ {(0)},\ldots,\zeta_{t,s}^{(\mathfrak{q}(Q))}\}\)
6:# Lower-Level: Stochastic Nesterov Accelerated Gradient Descent with Averaging
7:# Option I: from Line \(8\sim 9\) (for quadratic lower-level function)
8:\(z_{t}=y_{t}+\gamma(y_{t}-y_{t-1})\)
9:\(y_{t+1}=z_{t}-\alpha\nabla_{y}G(x_{t},z_{t};\pi_{t})\), where \(\pi_{t}\sim\mathcal{D}_{g}\)
10:# Option II: from Line \(11\sim 20\) (for general strongly convex lower-level function)
11:if\(t>0\) and \(t\) is a multiple of \(I\)then
12: Set \(y_{0}^{t}=y_{t}^{-1}=y_{t}\)
13:for\(j=0,1,\ldots,N-1\)do
14:\(z_{t}^{j}=y_{t}^{j}+\gamma(y_{t}^{j}-y_{t}^{j-1})\)
15:\(y_{t}^{j+1}=z_{t}^{j}-\alpha\nabla_{y}G(x_{t},z_{t}^{j};\pi_{t}^{j})\), where \(\pi_{t}^{j}\sim\mathcal{D}_{g}\)
16:endfor
17:\(y_{t+1}=y_{t}^{N+1}\)
18:else
19:\(y_{t+1}=y_{t}\)
20:endif
21:\(\hat{y}_{t+1}=(1-\tau)\hat{y}_{t}+\tau y_{t+1}\)# Averaging
22:# Upper-Level: Normalized Stochastic Gradient Descent with Recursive Momentum
23:\(m_{t}=\beta m_{t-1}+(1-\beta)\widetilde{\nabla}f(x_{t},\hat{y}_{t};\bar{\xi}_ {t})+\beta(\widetilde{\nabla}f(x_{t},\hat{y}_{t};\bar{\xi}_{t})-\widetilde{ \nabla}f(x_{t-1},\hat{y}_{t-1};\bar{\xi}_{t}))\) if \(t\geq 1\) else \(m_{0}=\nabla f(x_{0},\hat{y}_{0};\bar{\xi}_{0})\)
24:\(x_{t+1}=x_{t}-\eta\frac{m_{t}}{\|m_{t}\|}\)
25:endfor ```

**Algorithm 2** Accelerated Bilevel Optimization algorithm (AccBO)

**Remark:** Theorem 4.1 established an improved \(\widetilde{O}(\epsilon^{-3})\) oracle complexity for finding an \(\epsilon\)-stationary point when the lower-level standard deviation \(\sigma_{g,1}=O(\sqrt{\epsilon})\). This complexity result strictly improves the \(\widetilde{O}(\epsilon^{-4})\) obtained by [38; 32] when the upper-level function is nonconvex and unbounded smooth. This complexity result also matches that in the single-level unbounded smooth setting [56] and is nearly optimal in terms of the dependency on \(\epsilon\)[2]. The full statement of Theorem 4.1 is included in Theorem E.2.

### Proof Sketch

In this section, we provide a roadmap of proving Theorem 4.1 and the main steps. The detailed proofs can be found in Appendix D and E. The key idea is to prove two things: (1) the lower-level iterate is very close to the optimal lower-level variable at every iteration; (2) two consecutive iterates of the lower-level iterates are close to each other. In particular, define \(y_{t}^{*}=y^{*}(x_{t})\), and we aim to prove that \(\|\hat{y}_{t}-y_{t}^{*}\|\leq O(\epsilon)\) and \(\|\hat{y}_{t+1}-\hat{y}_{t}\|\leq O(\epsilon^{2})\) for every \(t\). These two requirements are essential to control the hypergradient estimation error (i.e., \(\|m_{t}-\nabla\Phi(x_{t})\|\)) caused by inaccurate estimate of the lower-level problem. Lemma 4.7 provides the guarantee for the lower-level problem, and Lemma 4.8characterizes the hypergradient estimation error. Equipped with these two lemmas, we can adapt the momentum-based variance reduction techniques [18, 56] to the upper-level problem and prove the main theorem.

The main technical contribution of this paper is to provide a general framework for proving the convergence of SNAG under distributional drift in Section 4.3.1, which can be leveraged as a tool to control the lower-level error in bilevel optimization and derive the Lemma 4.7, as illustrated in Section 4.3.2. In particular, we can regard the change of the upper-level variable \(x\) at each iteration as the distributional drift for the lower-level problem: the drift is small due to the normalization operator of the upper-level update rule and also the Lipschitzness of \(y^{*}(x)\). Once we have the general lemma for tracking the minimizer for any fixed distributional drift over time, this lemma can be applied to our algorithm analysis and establish guarantees for the bilevel problem.

#### 4.3.1 Stochastic Nesterov Accelerated Gradient Descent under Distributional Drift

In this section, we study the sequences of stochastic optimization problems \(\min_{w\in\mathbb{R}^{d}}\phi_{t}(w)\) indexed by time \(t\in\mathbb{N}\). We denote the minimizer and the minimal value of \(\phi_{t}\) as \(w_{t}^{*}\) and \(\phi_{t}^{*}\), and we define the _minimizer drift_ at time \(t\) to be \(\Delta_{t}:=\|w_{t}^{*}-w_{t+1}^{*}\|\). With a slight abuse of notation 3, we consider the SNAG algorithm applied to the sequence \(\{\phi_{t}\}_{t=1}^{T}\), where \(T\) is the total number of iterations:

Footnote 3: The notation in Section 4.3.1 is independent of that in other sections, although there may be incidental overlaps in terminology.

\[z_{t} =w_{t}+\gamma(w_{t}-w_{t-1})\] (3) \[w_{t+1} =w_{t}+\gamma(w_{t}-w_{t-1})-\alpha g_{t},\]

where \(g_{t}=\nabla\phi_{t}(z_{t};\xi_{t})\) is the stochastic gradient evaluated at \(z_{t}\) with random sample \(\xi_{t}\). Define \(\varepsilon_{t}=g_{t}-\nabla\phi_{t}(z_{t})\) as the stochastic gradient noise at \(t\)-th iteration. Define \(\mathcal{H}_{t}=\sigma(\xi_{1},\ldots,\xi_{t-1})\) as the filtration, which is the \(\sigma\)-algebra generated by all random variables until \(t\)-th iteration. We make the following assumption, which is the same as Assumption 3 in [20] for high probability analysis.

**Assumption 4.2**.: _Function \(\phi_{t}:\mathbb{R}^{d}\to\mathbb{R}\) is \(\mu\)-strongly convex and \(L\)-smooth for constants \(\mu,L>0\). Also, there exists constants \(\Delta,\sigma>0\) such that the drift \(\Delta_{t}^{2}\) is sub-exponential conditioned on \(\mathcal{H}_{t}\) with parameter \(\Delta^{2}\) and the noise \(\varepsilon_{t}\) is norm sub-Gaussian conditioned on \(\mathcal{H}_{t}\) with parameter \(\sigma/2\)._

**Lemma 4.3**.: _Suppose Assumption 4.2 holds and let \(\{w_{t}\}\) be the iterates produced by the update rule (3) with constant learning rate \(\alpha\leq 1/25L\), and set \(\gamma=\frac{1-\sqrt{\mu\alpha}}{1+\sqrt{\mu\alpha}}\). Define \(\theta_{t}=[(w_{t}-w_{t}^{*})^{\top},(w_{t-1}-w_{t}^{*})^{\top}]^{\top}\in \mathbb{R}^{2d}\), and the potential function \(V_{t}\) as_

\[V_{t}=\theta_{t}^{\top}\mathbf{P}\theta_{t}+\phi_{t}(w_{t})-\phi_{t}(w_{t}^{*} ),\quad\text{where}\quad\mathbf{P}=\frac{1}{2\alpha}\begin{bmatrix}1&\sqrt{\mu \alpha}-1\\ \sqrt{\mu\alpha}-1&(1-\sqrt{\mu\alpha})^{2}\end{bmatrix}\otimes\mathbf{I}_{d}.\]

_Then for any given \(\delta\in(0,1)\) and all \(t\geq 0\), the following holds with probability at least \(1-\delta\) over the randomness in \(\mathcal{H}_{t}\) (here \(e\) denotes the base of natural logarithms):_

1. _(With drift) Let_ \(\phi_{t}(w)\coloneqq\frac{\mu}{2}\|w-w_{t}^{*}\|^{2}\)_, then_ \(V_{t}\leq\left(1-\frac{\sqrt{\mu\alpha}}{4}\right)^{t}V_{0}+\left(\frac{5\sqrt{ \alpha}\sigma^{2}}{\sqrt{\mu}}+\frac{80\Delta^{2}}{\alpha}\right)\ln\frac{eT} {\delta}\)_._
2. _(Without drift) Let_ \(\phi_{t}(w)\equiv\phi(w)\) _be any general strongly convex functions with_ \(\Delta=0\)_, then_ \(V_{t}\leq\left(1-\frac{\sqrt{\mu\alpha}}{4}\right)^{t}V_{0}+\frac{5\sqrt{ \alpha}\sigma^{2}}{\sqrt{\mu}}\ln\frac{eT}{\delta}\)_._

**Remark**: When \(\{\phi_{t}\}_{t=1}^{T}\) is a sequence of quadratic functions with moving minimizers, Lemma 4.3 provides a high probability tracking guarantee for SNAG with distributional drift, which is useful to provide guarantees for Option I in Algorithm 2. Note that this guarantee strictly improves the guarantee of stochastic gradient descent with distributional drift (e.g., [20, Theorem 6]) _in the small stochastic gradient noise regime_ and therefore is of independent interest. In particular, for small \(\alpha\), the decaying factor in the first term is improved from \(1-\frac{\mu\alpha}{2}\) to \(1-\frac{\sqrt{\mu\alpha}}{4}\), the drift term is improved from \(\frac{\Delta^{2}}{\mu\alpha^{2}}\) to \(\frac{\Delta^{2}}{\alpha}\), and the variance term becomes a bit worse (from \(\alpha\sigma^{2}\) to \(\frac{\sqrt{\alpha}\sigma^{2}}{\sqrt{\mu}}\)). When \(\sigma\) is small enough, the variance term becomes insignificant compared with the drift term, then Lemma 4.3 provides an improved convergence rate with high probability. To the best of our knowledge, such an improved guarantee for SNAG with distributional drift is first shown in this work. When there is no drift, Lemma 4.3 also provides a high probability guarantee for SNAG. It holds for any smooth and strongly convex function \(\phi\), and it is useful to provide guarantees for Option II of Algorithm 2.

#### 4.3.2 Application of Stochastic Nesterov Accelerated Gradient to Bilevel Optimization

Inspired by [38, 32], we can regard \(\phi_{t}(\cdot)\) as \(\phi_{t}(\cdot):=g(x_{t},\cdot)\) in the bilevel setting, and then we have \(\Delta_{t}=\eta l_{g,1}/\mu\) for every \(t\) due to the upper-level update rule and the Lipschitzness of \(y^{*}(x)\). Therefore we can focus on the high probability analysis on the lower-level variable without worrying about the randomness from the upper-level. Throughout, we assume Assumption 3.1, 3.2, 3.3 and 3.4 hold. In addition, the failure probability \(\delta\in(0,1)\) and \(\epsilon>0\) are chosen in the same way as in Theorem 4.1.

**Lemma 4.4** (Warm-start).: _Let \(\{y_{t}^{\mathrm{init}}\}\) be the iterates produced by line 2 of Algorithm 2. Set \(\alpha^{\mathrm{init}}=\widetilde{\Theta}(\epsilon^{4})\), \(\sigma_{g,1}=(\mu\alpha)^{1/4}\tilde{\sigma}_{g,1}\), and \(\phi_{t}(y)\equiv g(x_{0},y)\). Then \(\|y_{T_{0}}^{\mathrm{init}}-y_{0}^{*}\|\leq\sqrt{\frac{\mu\alpha}{32}}\frac{ \epsilon}{L_{0}}\) holds with probability at least \(1-\delta\) over the randomness in \(\widetilde{\mathcal{F}}^{\mathrm{init}}\) (we denote this event as \(\mathcal{E}_{\mathrm{init}}\)) in \(T_{0}=\widetilde{O}(\epsilon^{-2})\) iterations._

**Remark:** Lemma 4.4 shows that for fixed initialization \(x_{0}\), running SNAG for at most \(T_{0}=\widetilde{O}(\epsilon^{-2})\) iterations can guarantee that the Euclidean distance between the lower-level variable \(y_{T_{0}}^{\mathrm{init}}\) and the optimal solution \(y^{*}(x_{0})\) is at most \(O(\epsilon)\), with high probability.

**Lemma 4.5** (Option I).: _Under event \(\mathcal{E}_{\mathrm{init}}\), let \(\{y_{t}\}\) be the iterates produced by Option I. Set \(\alpha=\widetilde{\Theta}(\epsilon^{2})\), \(\sigma_{g,1}=(\mu\alpha)^{1/4}\tilde{\sigma}_{g,1}\), and \(\phi_{t}(y)=g(x_{t},y)=\frac{\mu}{2}\|y-y_{t}^{*}\|^{2}\). Then for any \(t\in[T]\), Algorithm 2 guarantees with probability at least \(1-\delta\) over the randomness in \(\widetilde{\mathcal{F}}_{T}^{1}\) (we denote this event as \(\mathcal{E}_{y}^{1}\)) that \(\|y_{t}-y_{t}^{*}\|\leq\epsilon/2L_{0}\)._

**Lemma 4.6** (Option II).: _Under event \(\mathcal{E}_{\mathrm{init}}\), let \(\{y_{t}\}\) be the iterates produced by Option II. Set \(\alpha=\widetilde{\Theta}(\epsilon^{2})\), \(N=\widetilde{O}(\epsilon^{-1})\), \(I=\widetilde{O}(\epsilon^{-1})\), \(\sigma_{g,1}=(\mu\alpha)^{1/4}\tilde{\sigma}_{g,1}\), and \(\phi_{t}(y)=g(x_{t},y)\) when \(t\) is a multiple of \(I\) (i.e., \(x_{t}\) is fixed for each update round of Option II so \(g\) can be general functions). Then for any \(t\in[T]\), Algorithm 2 guarantees with probability at least \(1-\delta\) over the randomness in \(\sigma(\cup_{t\leq T}\widetilde{\mathcal{F}}_{t}^{2})\) (we denote this event as \(\mathcal{E}_{y}^{2}\)) that \(\|y_{t}-y_{t}^{*}\|\leq\epsilon/L_{0}\)._

**Remark:** Lemma 4.5 and Lemma 4.6 show that, under event \(\mathcal{E}_{\mathrm{init}}\) and both option I and option II, the algorithm guarantees that each iterate \(y_{t}\) is \(O(\epsilon)\)-close to the the optimal lower-level variable \(y_{t}^{*}\) at every iteration \(t\) with high probability.

**Lemma 4.7** (Averaging).: _Under event \(\mathcal{E}_{\mathrm{init}}\cap\mathcal{E}_{y}^{1}\) (Option I) or \(\mathcal{E}_{\mathrm{init}}\cap\mathcal{E}_{y}^{2}\) (Option II), set \(\tau=\sqrt{\mu\alpha}\) in the averaging step (line 21 of Algorithm 2). Then for any \(t\geq 0\) we have \(\|\hat{y}_{t}-y_{t}^{*}\|\leq\frac{2\epsilon}{L_{0}}\) and \(\|\hat{y}_{t+1}-\hat{y}_{t}\|\leq\frac{\mu\epsilon^{2}}{24L_{0}^{2}\sigma_{g,1}}=:\vartheta\)._

**Remark:** Lemma 4.7 shows that after performing averaging operations over the sequence \(\{y_{t}\}_{t=1}^{T}\), the averaged sequence enjoys stronger guarantees. First, each averaged iterate \(\hat{y}_{t}\) is still \(O(\epsilon)\)-close to the optimal lower-level variable \(y_{t}^{*}\); Second, two consecutive averaged iterates (i.e., \(\hat{y}_{t}\) and \(\hat{y}_{t+1}\)) is \(O(\epsilon^{2})\)-close to each other. The stronger guarantees are crucial to control the hypergradient estimation error as described in Lemma 4.8.

**Lemma 4.8**.: _Under event \(\mathcal{E}_{\mathrm{init}}\cap\mathcal{E}_{y}^{1}\) (Option I) or \(\mathcal{E}_{\mathrm{init}}\cap\mathcal{E}_{y}^{2}\) (Option II), define \(\epsilon_{t}=m_{t}-\mathbb{E}_{t}[\nabla f(x_{t},\hat{y}_{t};\bar{\xi}_{t})]\), then we have the following averaged cumulative error bound:_

\[\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}\|\epsilon_{t}\|\leq\frac{\bar{\sigma}}{T( 1-\beta)}+\sqrt{1-\beta}\bar{\sigma}+\frac{\bar{L}_{0}}{\sqrt{1-\beta}}\sqrt{ \frac{2(\eta^{2}+\vartheta^{2})}{S}}+\bar{L}_{1}\sqrt{\frac{2(\eta^{2}+ \vartheta^{2})}{S(1-\beta)}}\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}\|\nabla\Phi(x _{t})\|,\]

_where \(S\) denotes the batch size, and \(\bar{\sigma},\bar{L}_{0},\bar{L}_{1}\) are defined in Lemmas B.4 and B.6._

**Remark:** Lemma 4.8 characterizes the upper-level hypergradient estimation error under the good event that the lower-level error can be controlled. One can choose hyperparameters appropriately such that the cumulative error (i.e., LHS) grows only sublinearly in terms of \(T\), which is important for establishing the fast convergence of our algorithm.

## 5 Experiments

**Deep AUC Maximization with Recurrent Neural Networks**. AUC (Area Under the ROC Curve) [36] is a critical metric in evaluating the performance of binary classification models. It measures the ability of the model to distinguish between positive and negative classes, andit is defined as the probability that the prediction score of a positive example is higher than that is a negative example [35]. Deep AUC maximization [53; 72] can be formulated as a min-max optimization problem [53]: \(\min_{\bm{w}\in\mathbb{R}^{d},(a,b)\in\mathbb{R}^{2}}\max_{\alpha\in\mathbb{R}}f (\bm{w},a,b,\alpha)\coloneqq\mathbb{E}_{\bm{z}}[F(\bm{w},a,b,\alpha;\bm{z})]\), where \(F(\bm{w},a,b,\alpha;\bm{z})=(1-r)(h(\bm{w};\bm{x})-a)^{2}\mathbb{I}_{[c=1]}+r( h(\bm{w};\bm{x})-b)^{2}\mathbb{I}_{[c=-1]}+2(1+\alpha)(rh(\bm{w};\bm{x}) \mathbb{I}_{[c=-1]}-(1-r)h(\bm{w};\bm{x})\mathbb{I}_{[c=1]})-r(1-r)\alpha^{2}\), \(\bm{w}\) denotes the model parameter, \(\bm{z}=(\bm{x},c)\) is the random data sample (\(\bm{x}\) denote the feature vector and \(c\in\{+1,-1\}\) denotes the label), \(h(\bm{w},\bm{x})\) is the score function defined by a neural network, and \(r=\text{Pr}(c=1)\) denotes the ratio of positive samples in the population. This min-max formulation is an special case of the bilevel problem with \(g=-f\) in (1), which can be reformulated as the following:

\[\min_{\bm{w}\in\mathbb{R}^{d},(a,b)\in\mathbb{R}^{2}}\mathbb{E}_{\bm{z}}[F( \bm{w},a,b,\alpha^{*}(\bm{w},a,b);\bm{z})]\quad\text{s.t.,}\quad\alpha^{*}( \bm{w},a,b)\in\arg\min_{\alpha\in\mathbb{R}}\,-\mathbb{E}_{\bm{z}}[F(\bm{w},a,b,\alpha;\bm{z})]\] (4)

where \((\bm{w},a,b)\) denotes the upper-level variable, and \(\alpha\) denotes the lower-level variable. In this case, the lower-level is a quadratic function in terms of \(\alpha\) and is strongly convex, and the upper-level function is non-convex function with potential unbounded smoothness when using a recurrent neural network as the predictive model.

We aim to perform imbalanced text classification task and maximize the AUC metric. The Deep AUC maximization experiment is performed on imbalanced Sentiment140 [31] dataset (under the license of CC BY 4.0), which is a binary text classification task. Specifically, we follow [73] to make training set imbalanced with a pre-defined imbalanced ratio (\(r\)), and leave the test set unchanged. Given \(r\), we randomly discard the positive samples (with label 1) in original training set until the portion of positive samples equals to \(r\). The imbalance ratio \(r\) is set to 0.2 in our experiment, which means only \(20\%\) data is positive in the training set. We use a two-layer recurrent neural network with input dimension=300, hidden dimension=4096, and output dimension=2 for the model prediction.

We compare with some bilevel optimization baselines, including StocBio [44], TTSA [41], SABA [21], MA-SOBA [12], SUSTAIN [46], VRBO [71] and BO-REP [38]. We show the training and test AUC result with 25 epochs in (a) (b) of Figure 1 and running time in (c), (d) of Figure 1. Our algorithm AccBO achieves highest AUC score among all the baselines over epochs and running time. The running time figure shows AccBO converges to a good result faster than other baselines. The detailed parameter tuning and selection are included in Appendix G.

**Data Hypercleaning.** The Data hypercleaning task tries to learn a set of weights \(\bm{\lambda}\) for the corrupted training data \(\mathcal{D}_{tr}\), such that the model trained on the weighted corrupted training set can achieve good performance on the clean validation set \(\mathcal{D}_{val}\), where the corrupted training set \(\mathcal{D}_{tr}:=\{\bm{x}_{i},\bar{y}_{i}\}\) and the label \(\bar{y}_{i}\) is randomly flipped to one of other labels with probability \(0<p<1\). The data hyper-cleaning can be formulated as a bilevel optimization problem,

\[\min_{\bm{\lambda}}\frac{1}{|\mathcal{D}_{\text{val}}|}\sum_{\xi\in\mathcal{D }_{\text{val}}}\mathcal{L}(\bm{w}^{*}(\bm{\lambda});\xi),\;\text{s.t.}\;\bm{w} ^{*}(\bm{\lambda})\in\operatorname*{arg\,min}_{\bm{w}}\frac{1}{|\mathcal{D}_{ \bm{v}}|}\sum_{\zeta_{i}\in\mathcal{D}_{\bm{v}}}\sigma(\lambda_{i})\mathcal{L }(\bm{w};\zeta_{i})+c\|\bm{w}\|^{2},\] (5)

where \(\bm{w}\) is the model parameter of a neural network, and \(\sigma(x)=\frac{1}{1+e^{-x}}\) is the sigmoid function. We perform bilevel optimization algorithms on the noisy text classification dataset Stanford Natural Language Inference (SNLI) [8] (under the license of CC BY 4.0) with a three-layer recurrent neural network with input dimension=300, hidden dimension=4096, and output dimension=3 for the label prediction. Each of sentence-pairs manually labeled as entailment, contradiction, and neutral.

Figure 1: Results of bilevel optimization on deep AUC maximization. Figure (a), (b) are the results over epochs, and Figure (c), (d) are the results over running time.

Specifically, the label of each training data is randomly flipped to one of the other two labels with probability \(p\). We set \(p=0.1\) and \(p=0.2\) in the experiments, respectively. We compare all the baselines used in the deep AUC maximization experiment. Different from the formulation (4) for the deep AUC maximization, the lower-level function in (5) is not quadratic function of the lower-level variable. Therefore we choose Option II in Algorithm 2, i.e., periodic updates for the lower-level variable. The results are presented in Figure 2 (\(p=0.1\) and \(p=0.2\)). Our algorithm AccBO exhibits the highest classification accuracy on training and test set among all the bilevel baselines, and also shows a high runtime efficiency. More detailed parameter tuning and selection can be found in Appendix G. All the experiments are run on the device of NVIDIA A6000 (48GB memory) GPU and AMD EPYC 7513 32-Core CPU.

## 6 Conclusion

In this paper, we propose a new algorithm named AccBO for solving bilevel optimization problems where the upper-level is nonconvex and unbounded smooth and the lower-level problem is strongly convex. The algorithm achieved \(\widetilde{O}(\epsilon^{-3})\) oracle complexity for finding an \(\epsilon\)-stationary point when the lower-level stochastic gradient variance is \(O(\epsilon)\), which matches the rate of the state-of-the-art single-level relaxed smooth optimization [56] and is nearly optimal in terms of dependency on \(\epsilon\)[2].

**Limitations.** There are two limitations of our work. One limitation of our work is that the convergence analysis for the Option I of our algorithm relies on the lower-level problem being a quadratic function: only under this case the algorithm becomes a single-loop procedure. Another limitation is that we require the lower-level stochastic gradient has variance \(O(\epsilon)\). It remains unclear how to design single-loop algorithms for more general lower-level strongly convex functions and get rid of the small stochastic gradient variance assumption for the lower-level variable.

## Acknowledgments and Disclosure of Funding

We would like to thank the anonymous reviewers for their helpful comments. We would like to thank Tianbao Yang and Qihang Lin for helpful discussions for the quadratic function with distributional drift in the earlier version of our paper. This work has been supported by the Presidential Scholarship, the ORIEI seed funding, and the IDIA P3 fellowship from George Mason University, the Cisco Faculty Research Award, and NSF award #2436217, #2425687. The Computations were run on ARGO, a research computing cluster provided by the Office of Research Computing at George Mason University (URL: https://orc.gmu.edu).

Figure 2: Results of bilevel optimization on data hyper-cleaning with \(p=0.1\). Figure (a), (b), (c), (d) are the results with noise rate \(p=0.1\) where (a), (b) are the results over epochs, and Figure (c), (d) are the results over running time. Figure (e), (f), (g), (h) are the results with noise rate \(p=0.2\).

## References

* [1]G Anandalingam and DJ White. A solution method for the linear static stackelberg problem using penalty functions. _IEEE Transactions on automatic control_, 35(10):1170-1173, 1990.
* [2] Yossi Arjevani, Yair Carmon, John C Duchi, Dylan J Foster, Nathan Srebro, and Blake Woodworth. Lower bounds for non-convex stochastic optimization. _Mathematical Programming_, 199 (1-2):165-214, 2023.
* [3] Mahmoud Assran and Michael Rabbat. On the convergence of nesterov's accelerated gradient method in stochastic settings. _arXiv preprint arXiv:2002.12414_, 2020.
* [4] Necdet Serhat Aybat, Alireza Fallah, Mert Gurbuzbalaban, and Asuman Ozdaglar. A universally optimal multistage accelerated stochastic gradient method. _Advances in neural information processing systems_, 32, 2019.
* [5] Necdet Serhat Aybat, Alireza Fallah, Mert Gurbuzbalaban, and Asuman Ozdaglar. Robust accelerated gradient methods for smooth strongly convex functions. _SIAM Journal on Optimization_, 30(1):717-751, 2020.
* [6] Omar Besbes, Yonatan Gur, and Assaf Zeevi. Non-stationary stochastic optimization. _Operations research_, 63(5):1227-1244, 2015.
* [7] Zalan Boros, Mojmir Mutny, and Andreas Krause. Coresets via bilevel optimization for continual learning and streaming. _Advances in neural information processing systems_, 33:14879-14890, 2020.
* [8] Samuel R Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. A large annotated corpus for learning natural language inference. _arXiv preprint arXiv:1508.05326_, 2015.
* [9] Jerome Bracken and James T McGill. Mathematical programs with optimization problems in the constraints. _Operations research_, 21(1):37-44, 1973.
* [10] Lesi Chen, Jing Xu, and Jingzhao Zhang. On bilevel optimization without lower-level strong convexity. _arXiv preprint arXiv:2301.00712_, 2023.
* [11] Tianyi Chen, Yuejiao Sun, and Wotao Yin. Closing the gap: Tighter analysis of alternating stochastic gradient methods for bilevel problems. _Advances in Neural Information Processing Systems_, 34:25294-25307, 2021.
* [12] Xuxing Chen, Tesi Xiao, and Krishnakumar Balasubramanian. Optimal algorithms for stochastic bilevel optimization under relaxed smoothness conditions. _arXiv preprint arXiv:2306.12067_, 2023.
* [13] You-Lin Chen, Sen Na, and Mladen Kolar. Convergence analysis of accelerated stochastic gradient descent under the growth condition. _Mathematics of Operations Research_, 2023.
* [14] Ziyi Chen, Yi Zhou, Yingbin Liang, and Zhaosong Lu. Generalized-smooth nonconvex optimization is as efficient as smooth nonconvex optimization. _arXiv preprint arXiv:2303.02854_, 2023.
* [15] Michael Crawshaw, Mingrui Liu, Francesco Orabona, Wei Zhang, and Zhenxun Zhuang. Robustness to unbounded smoothness of generalized signsgd. _Advances in neural information processing systems_, 2022.
* [16] Michael Crawshaw, Yajie Bao, and Mingrui Liu. Episode: Episodic gradient clipping with periodic resampled corrections for federated learning with heterogeneous data. In _The Eleventh International Conference on Learning Representations_, 2023.
* [17] Michael Crawshaw, Yajie Bao, and Mingrui Liu. Federated learning with client subsampling, data heterogeneity, and unbounded smoothness: A new algorithm and lower bounds. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.

* [18] Ashok Cutkosky and Francesco Orabona. Momentum-based variance reduction in non-convex sgd. _Advances in neural information processing systems_, 32, 2019.
* [19] Joshua Cutler, Dmitriy Drusvyatskiy, and Zaid Harchaoui. Stochastic optimization under time drift: iterate averaging, step-decay schedules, and high probability guarantees. _Advances in neural information processing systems_, 34:11859-11869, 2021.
* [20] Joshua Cutler, Dmitriy Drusvyatskiy, and Zaid Harchaoui. Stochastic optimization under distributional drift. _Journal of Machine Learning Research_, 24(147):1-56, 2023.
* [21] Mathieu Dagreou, Pierre Ablin, Samuel Vaiter, and Thomas Moreau. A framework for bilevel optimization that enables stochastic and global variance reduction algorithms. _Advances in Neural Information Processing Systems_, 35:26698-26710, 2022.
* [22] Jeffrey L Elman. Finding structure in time. _Cognitive science_, 14(2):179-211, 1990.
* [23] Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator. _Advances in neural information processing systems_, 31, 2018.
* [24] Matthew Faw, Litu Rout, Constantine Caramanis, and Sanjay Shakkottai. Beyond uniform smoothness: A stopped analysis of adaptive sgd. _arXiv preprint arXiv:2302.06570_, 2023.
* [25] Matthias Feurer and Frank Hutter. Hyperparameter optimization. In _Automated Machine Learning_, pages 3-33. Springer, Cham, 2019.
* [26] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. In _International conference on machine learning_, pages 1126-1135. PMLR, 2017.
* [27] Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimiliano Pontil. Bilevel programming for hyperparameter optimization and meta-learning. In _International conference on machine learning_, pages 1568-1577. PMLR, 2018.
* [28] Saeed Ghadimi and Guanghui Lan. Stochastic first-and zeroth-order methods for nonconvex stochastic programming. _SIAM Journal on Optimization_, 23(4):2341-2368, 2013.
* [29] Saeed Ghadimi and Guanghui Lan. Accelerated gradient methods for nonconvex nonlinear and stochastic programming. _Mathematical Programming_, 156(1-2):59-99, 2016.
* [30] Saeed Ghadimi and Mengdi Wang. Approximation methods for bilevel programming. _arXiv preprint arXiv:1802.02246_, 2018.
* [31] Alec Go, Richa Bhayani, and Lei Huang. Twitter sentiment classification using distant supervision. _CS224N project report, Stanford_, 1(12):2009, 2009.
* [32] Xiaochuan Gong, Jie Hao, and Mingrui Liu. A nearly optimal single loop algorithm for stochastic bilevel optimization under unbounded smoothness. In _Forty-first International Conference on Machine Learning_, 2024.
* [33] Riccardo Grazzi, Massimiliano Pontil, and Saverio Salzo. Bilevel optimization with a lower-level contraction: Optimal sample complexity without warm-start. _arXiv preprint arXiv:2202.03397_, 2022.
* [34] Zhishuai Guo, Quanqi Hu, Lijun Zhang, and Tianbao Yang. Randomized stochastic variance-reduced methods for multi-task stochastic bilevel optimization. _arXiv preprint arXiv:2105.02266_, 2021.
* [35] James A Hanley and Barbara J McNeil. The meaning and use of the area under a receiver operating characteristic (roc) curve. _Radiology_, 143(1):29-36, 1982.
* [36] James A Hanley and Barbara J McNeil. A method of comparing the areas under receiver operating characteristic curves derived from the same cases. _Radiology_, 148(3):839-843, 1983.

* [37] Jie Hao, Kaiyi Ji, and Mingrui Liu. Bilevel coreset selection in continual learning: A new formulation and algorithm. _Advances in Neural Information Processing Systems_, 36, 2023.
* [38] Jie Hao, Xiaochuan Gong, and Mingrui Liu. Bilevel optimization under unbounded smoothness: A new algorithm and convergence analysis. In _The Twelfth International Conference on Learning Representations_, 2024.
* [39] Elad Hazan and Satyen Kale. Beyond the regret minimization barrier: optimal algorithms for stochastic strongly-convex optimization. _Journal of Machine Learning Research_, 15(1):2489-2512, 2014.
* [40] Sepp Hochreiter and Jurgen Schmidhuber. Long short-term memory. _Neural computation_, 9(8):1735-1780, 1997.
* [41] Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. A two-timescale stochastic algorithm framework for bilevel optimization: Complexity analysis and application to actor-critic. _SIAM Journal on Optimization_, 33(1):147-180, 2023.
* [42] Bin Hu and Laurent Lessard. Dissipativity theory for nesterov's accelerated method. In _International Conference on Machine Learning_, pages 1549-1557. PMLR, 2017.
* [43] Quanqi Hu, Zi-Hao Qiu, Zhishuai Guo, Lijun Zhang, and Tianbao Yang. Blockwise stochastic variance-reduced methods with parallel speedup for multi-block bilevel optimization. In _International Conference on Machine Learning_, pages 13550-13583. PMLR, 2023.
* [44] Kaiyi Ji, Junjie Yang, and Yingbin Liang. Bilevel optimization: Convergence analysis and enhanced design. In _International conference on machine learning_, pages 4882-4892. PMLR, 2021.
* [45] Jikai Jin, Bohang Zhang, Haiyang Wang, and Liwei Wang. Non-convex distributionally robust optimization: Non-asymptotic analysis. _Advances in Neural Information Processing Systems_, 34:2771-2782, 2021.
* [46] Prashant Khanduri, Siliang Zeng, Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. A near-optimal algorithm for stochastic bilevel optimization via double-momentum. _Advances in Neural Information Processing Systems (NeurIPS)_, 34:30271-30283, 2021.
* [47] Vijay Konda and John Tsitsiklis. Actor-critic algorithms. _Advances in neural information processing systems_, 12, 1999.
* [48] Jeongyeol Kwon, Dohyun Kwon, Stephen Wright, and Robert D Nowak. A fully first-order method for stochastic bilevel optimization. In _International Conference on Machine Learning_, pages 18083-18113. PMLR, 2023.
* [49] Jeongyeol Kwon, Dohyun Kwon, Steve Wright, and Robert Nowak. On penalty methods for nonconvex bilevel optimization and first-order stochastic approximation. _arXiv preprint arXiv:2309.01753_, 2023.
* [50] Guanghui Lan. An optimal method for stochastic composite optimization. _Mathematical Programming_, 133(1-2):365-397, 2012.
* [51] Haochuan Li, Ali Jadbabaie, and Alexander Rakhlin. Convergence of adam under relaxed assumptions. _arXiv preprint arXiv:2304.13972_, 2023.
* [52] Bo Liu, Mao Ye, Stephen Wright, Peter Stone, and Qiang Liu. Bome! bilevel optimization made easy: A simple first-order approach. _Advances in Neural Information Processing Systems_, 35:17248-17262, 2022.
* [53] Mingrui Liu, Zhuoning Yuan, Yiming Ying, and Tianbao Yang. Stochastic auc maximization with deep neural networks. _ICLR_, 2020.
* [54] Mingrui Liu, Zhenxun Zhuang, Yunwen Lei, and Chunyang Liao. A communication-efficient distributed gradient clipping algorithm for training deep neural networks. _Advances in Neural Information Processing Systems_, 35:26204-26217, 2022.

* Liu et al. [2020] Risheng Liu, Pan Mu, Xiaoming Yuan, Shangzhi Zeng, and Jin Zhang. A generic first-order algorithmic framework for bi-level programming beyond lower-level singleton. In _International Conference on Machine Learning_, pages 6305-6315. PMLR, 2020.
* Liu et al. [2023] Zijian Liu, Srikanth Jagabathula, and Zhengyuan Zhou. Near-optimal non-convex stochastic optimization under generalized smoothness. _arXiv preprint arXiv:2302.06032_, 2023.
* Madden et al. [2021] Liam Madden, Stephen Becker, and Emiliano Dall'Anese. Bounds for the tracking error of first-order online optimization methods. _Journal of Optimization Theory and Applications_, 189:437-457, 2021.
* Nesterov [1983] Yurii Nesterov. A method of solving a convex programming problem with convergence rate o (1/k2). In _Soviet Mathematics Doklady_, volume 27, pages 372-376, 1983.
* Rajeswaran et al. [2019] Aravind Rajeswaran, Chelsea Finn, Sham M Kakade, and Sergey Levine. Meta-learning with implicit gradients. In _Advances in Neural Information Processing Systems (NeurIPS)_, pages 113-124, 2019.
* Reisizadeh et al. [2023] Amirhossein Reisizadeh, Haochuan Li, Subhro Das, and Ali Jadbabaie. Variance-reduced clipping for non-convex optimization. _arXiv preprint arXiv:2303.00883_, 2023.
* Sabach and Shtern [2017] Shoham Sabach and Shimrit Shtern. A first order method for solving convex bilevel optimization problems. _SIAM Journal on Optimization_, 27(2):640-660, 2017.
* Shen and Chen [2023] Han Shen and Tianyi Chen. On penalty-based bilevel gradient descent method. _arXiv preprint arXiv:2302.05185_, 2023.
* Sow et al. [2022] Daouda Sow, Kaiyi Ji, Ziwei Guan, and Yingbin Liang. A constrained optimization approach to bilevel optimization with multiple inner minima. _arXiv preprint arXiv:2203.01123_, 2022.
* Tran-Dinh et al. [2019] Quoc Tran-Dinh, Nhan H Pham, Dzung T Phan, and Lam M Nguyen. Hybrid stochastic gradient descent algorithms for stochastic nonconvex optimization. _arXiv preprint arXiv:1905.05920_, 2019.
* Vaswani et al. [2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. _Advances in neural information processing systems_, 30, 2017.
* Vaswani et al. [2022] Sharan Vaswani, Benjamin Dubois-Taine, and Reza Babanezhad. Towards noise-adaptive, problem-adaptive (accelerated) stochastic gradient descent. In _International conference on machine learning_, pages 22015-22059. PMLR, 2022.
* Vicente et al. [1994] Luis Vicente, Gilles Savard, and Joaquim Judice. Descent approaches for quadratic bilevel programming. _Journal of optimization theory and applications_, 81(2):379-399, 1994.
* Wang et al. [2023] Bohan Wang, Huishuai Zhang, Zhiming Ma, and Wei Chen. Convergence of adagrad for non-convex objectives: Simple proofs and relaxed assumptions. In _The Thirty Sixth Annual Conference on Learning Theory_, pages 161-190. PMLR, 2023.
* White and Anandalingam [1993] Douglas J White and G Anandalingam. A penalty function approach for solving bi-level linear programs. _Journal of Global Optimization_, 3:397-419, 1993.
* Wilson et al. [2018] Craig Wilson, Venugopal V Veeravalli, and Angelia Nedic. Adaptive sequential stochastic optimization. _IEEE Transactions on Automatic Control_, 64(2):496-509, 2018.
* Yang et al. [2021] Junjie Yang, Kaiyi Ji, and Yingbin Liang. Provably faster algorithms for bilevel optimization. _Advances in Neural Information Processing Systems_, 34:13670-13682, 2021.
* Ying et al. [2016] Yiming Ying, Longyin Wen, and Siwei Lyu. Stochastic online auc maximization. In _Advances in Neural Information Processing Systems_, pages 451-459, 2016.
* Yuan et al. [2021] Zhuoning Yuan, Yan Yan, Milan Sonka, and Tianbao Yang. Large-scale robust deep auc maximization: A new surrogate loss and empirical studies on medical image classification. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 3040-3049, 2021.

* [74] Bohang Zhang, Jikai Jin, Cong Fang, and Liwei Wang. Improved analysis of clipping algorithms for non-convex optimization. _Advances in Neural Information Processing Systems_, 33:15511-15521, 2020.
* [75] Jingzhao Zhang, Tianxing He, Suvrit Sra, and Ali Jadbabaie. Why gradient clipping accelerates training: A theoretical justification for adaptivity. _International Conference on Learning Representations_, 2020.

Technical Lemmas

In this section, we will introduce a few useful lemmas. The following technical lemma on recursive control is crucial for providing high probability guarantee of the lower-level variables \(y_{t}\) and \(\hat{y}_{t}\) in Algorithm 2 at _anytime_. We follow a similar argument as in [20, Proposition 29] with a slight generalization.

**Lemma A.1** (Recursive control on MGF).: _Consider scalar stochastic processes \((V_{t})\), \((V^{\prime}_{t,1})\), \((V^{\prime}_{t,2})\), \((D_{t,1})\), \((D_{t,2})\) and \((X_{t})\) on a probability space with filtration \((\mathcal{H}_{t})\), which are linked by the inequality_

\[V_{t+1}\leq\alpha_{t}V_{t}+D_{t,1}\sqrt{V^{\prime}_{t,1}}+D_{t,2}\sqrt{V^{ \prime}_{t,2}}+X_{t}+\kappa_{t}\]

_for some deterministic constants \(\alpha_{t}\in(-\infty,1]\) and \(\kappa_{t}\in\mathbb{R}\). Suppose the following properties hold._

* \(V_{t},V^{\prime}_{t,1}\) _and_ \(V^{\prime}_{t,2}\) _are non-negative and_ \(\mathcal{H}_{t}\)_-measurable._
* \(D_{t,i}\) _is mean-zero sub-Gaussian conditioned on_ \(\mathcal{H}_{t}\) _with deterministic parameter_ \(\sigma_{i}\)_, and_ \(V^{\prime}_{t,i}\leq V_{t}\) _for_ \(i=1,2\)_:_ \[\mathbb{E}[\exp(\lambda D_{t,i})\mid\mathcal{H}_{t}]\leq\exp(\lambda^{2}\sigma _{i}^{2}/2)\quad\text{for all}\quad\lambda\in\mathbb{R}.\]
* \(X_{t}\) _is non-negative and sub-exponential conditioned on_ \(\mathcal{H}_{t}\) _with deterministic parameter_ \(\nu_{t}\)_:_ \[\mathbb{E}[\exp(\lambda X_{t})\mid\mathcal{H}_{t}]\leq\exp(\lambda\nu_{t}) \quad\text{for all}\quad 0\leq\lambda\leq 1/\nu_{t}.\]

_Then the estimate_

\[\mathbb{E}[\exp(\lambda V_{t+1})]\leq\exp(\lambda(\nu_{t}+\kappa_{t}))\mathbb{ E}[\exp(\lambda(1+\alpha_{t})V_{t}/2)]\]

_holds for any \(\lambda\) satisfying \(0\leq\lambda\leq\min\left\{\frac{1-\alpha_{t}}{2(\sigma_{1}^{2}+\sigma_{2}^{ 2})},\frac{1}{2\nu_{t}}\right\}\)._

Proof of Lemma a.1.: For any index \(t\geq 0\) and any scalar \(\lambda\geq 0\), the law of total expectation implies

\[\mathbb{E}[\exp(\lambda V_{t+1})] \leq\mathbb{E}\left[\exp(\lambda(\alpha_{t}V_{t}+D_{t,1}\sqrt{V^{ \prime}_{t,1}}+D_{t,2}\sqrt{V^{\prime}_{t,2}}+X_{t}+\kappa_{t}))\right]\] \[=\exp(\lambda\kappa_{t})\mathbb{E}\left[\exp(\lambda\alpha_{t}V_ {t})\mathbb{E}\left[\exp\left(\lambda\left(D_{t,1}\sqrt{V^{\prime}_{t,1}}+D_{t,2}\sqrt{V^{\prime}_{t,2}}\right)\right)\exp(\lambda X_{t})\mid\mathcal{H}_{t }\right]\right].\]

Holder's inequality in turn yields

\[\mathbb{E}\left[\exp(\lambda\alpha_{t}V_{t})\mathbb{E}\left[\exp \left(\lambda\left(D_{t,1}\sqrt{V^{\prime}_{t,1}}+D_{t,2}\sqrt{V^{\prime}_{t, 2}}\right)\right)\exp(\lambda X_{t})\mid\mathcal{H}_{t}\right]\right]\] \[\qquad\leq\sqrt{\mathbb{E}\left[\exp\left(2\lambda\left(D_{t,1} \sqrt{V^{\prime}_{t,1}}+D_{t,2}\sqrt{V^{\prime}_{t,2}}\right)\right)\mid \mathcal{H}_{t}\right]\cdot\mathbb{E}\left[\exp(2\lambda X_{t})\mid\mathcal{ H}_{t}\right]}\] \[\qquad\leq\exp\left(\lambda^{2}(\sigma_{1}^{2}+\sigma_{2}^{2})V_ {t}\right)\exp(\lambda\nu_{t})\]

provided \(0\leq\lambda\leq 1/2\nu_{t}\), where we use \(V^{\prime}_{t,i}\leq V_{t}\) for \(i=1,2\) in the last inequality. Therefore, under the condition that

\[0\leq\lambda\leq\min\left\{\frac{1-\alpha_{t}}{2(\sigma_{1}^{2}+\sigma_{2}^{ 2})},\frac{1}{2\nu_{t}}\right\},\]

the following estimate hold for all \(t\geq 0\):

\[\mathbb{E}[\exp(\lambda V_{t+1})] \leq\exp(\lambda\kappa_{t})\mathbb{E}\left[\exp(\lambda\alpha_{t }V_{t})\exp\left(\lambda^{2}(\sigma_{1}^{2}+\sigma_{2}^{2})V_{t}\right)\exp( \lambda\nu_{t})\right]\] \[=\exp(\lambda(\nu_{t}+\kappa_{t}))\mathbb{E}\left[\exp\left( \lambda(\alpha_{t}+\lambda(\sigma_{1}^{2}+\sigma_{2}^{2}))V_{t}\right)\right]\] \[\leq\exp(\lambda(\nu_{t}+\kappa_{t}))\mathbb{E}[\exp(\lambda(1+ \alpha_{t})V_{t}/2)],\]

where the last inequality follows by the given range of \(\lambda\). Thus the proof is completed. 

Next, we introduce the following Young's inequality beyond Euclidean norm cases. This lemma serves as an important role when dealing with distributional drift for high probability SNAG analysis.

**Lemma A.2** (Young's inequality).: _For any vectors \(v_{1},v_{2}\in\mathbb{R}^{d}\), positive semidefinite (PSD) matrix \(\mathbf{Q}\in\mathbb{R}^{d\times d}\), and scalar \(c>0\), it holds that 4_

Footnote 4: Here we define \(\|v\|_{\mathbf{Q}}\coloneqq\sqrt{v^{\top}\mathbf{Q}v}\) for any vector \(v\in\mathbb{R}^{d}\) and PSD matrix \(\mathbf{Q}\in\mathbb{R}^{d\times d}\).

\[\|v_{1}+v_{2}\|_{\mathbf{Q}}^{2}\leq(1+c)\|v_{1}\|_{\mathbf{Q}}^{2}+\left(1+ \frac{1}{c}\right)\|v_{2}\|_{\mathbf{Q}}^{2}.\]

Proof of Lemma a.2.: By definition of \(\|\cdot\|_{\mathbf{Q}}\), we have

\[\begin{split}\|v_{1}+v_{2}\|_{\mathbf{Q}}^{2}&=(v _{1}+v_{2})^{\top}\mathbf{Q}(v_{1}+v_{2})\\ &=\|v_{1}\|_{\mathbf{Q}}^{2}+\|v_{2}\|_{\mathbf{Q}}^{2}+2v_{1}^{ \top}\mathbf{Q}v_{2}.\end{split}\] (6)

Since \(\mathbf{Q}\in\mathbb{R}^{d\times d}\) is PSD, let \(\mathbf{Q}=\mathbf{U}\mathbf{U}^{\top}\) be the Cholesky decomposition, then

\[\begin{split} 2v_{1}^{\top}\mathbf{Q}v_{2}&=2v_{1}^{ \top}\mathbf{U}\mathbf{U}^{\top}v_{2}=2(\mathbf{U}^{\top}v_{1})^{\top}( \mathbf{U}^{\top}v_{2})\\ &\leq c\|\mathbf{U}^{\top}v_{1}\|^{2}+\frac{1}{c}\|\mathbf{U}^{ \top}v_{2}\|^{2}\\ &=c\|v_{1}\|_{\mathbf{Q}}^{2}+\frac{1}{c}\|v_{2}\|_{\mathbf{Q}}^ {2},\end{split}\] (7)

where we use Young's inequality and definition of \(\|\cdot\|_{\mathbf{Q}}\) for the second and third lines, respectively. Combing (6) and (7) gives the result as claimed. 

## Appendix B Auxiliary Lemmas for Bilevel Optimization

In this section, we provide important properties of the objective function \(\Phi\) in bilevel optimization problems, as well as characterizations (such as variance and bias) for stochastic hypergradient estimator \(\bar{\nabla}f(x,y;\bar{\xi})\) based on Neumann series. For readers' convenience, we only list the results here and defer the detailed proofs to Appendix F.

**Lemma B.1** (Lipschitz property, [38, Lemma 8]).: _Under Assumptions 3.1 and 3.2, \(y^{*}(x)\) is \((l_{g,1}/\mu)\)-Lipschitz continuous._

**Lemma B.2** (\((L_{0},L_{1})\)-smoothness, [38, Lemma 9]).: _Under Assumptions 3.1 and 3.2, for any \(x,x^{\prime}\) we have_

\[\|\nabla\Phi(x)-\nabla\Phi(x^{\prime})\|\leq(L_{0}+L_{1}\|\nabla\Phi(x^{ \prime})\|)\|x-x^{\prime}\|\quad\text{if}\quad\|x-x^{\prime}\|\leq\frac{1}{ \sqrt{2(1+l_{g,1}^{2}/\mu^{2})(L_{x,1}^{2}+L_{y,1}^{2})}},\]

_where \((L_{0},L_{1})\)-smoothness constant \(L_{0}\) and \(L_{1}\) are defined as_

\[L_{0}=\sqrt{1+\frac{l_{g,1}^{2}}{\mu^{2}}}\left(L_{x,0}+L_{x,1}\frac{l_{g,1}l _{f,0}}{\mu}+\frac{l_{g,1}}{\mu}(L_{y,0}+L_{y,1}l_{f,0})+l_{f,0}\frac{l_{g,1}l _{g,2}+l_{g,2}\mu}{\mu^{2}}\right)\quad\text{and}\quad L_{1}=\sqrt{1+\frac{l_ {g,1}^{2}}{\mu^{2}}}L_{x,1}.\]

**Lemma B.3** (Descent inequality, [38, Lemma 10]).: _Suppose Assumptions 3.1 and 3.2 and 3.2 hold. Then for any \(x,x^{\prime}\) we have_

\[\Phi(x)\leq\Phi(x^{\prime})+\langle\nabla\Phi(x^{\prime}),x-x^{\prime}\rangle+ \frac{L_{0}+L_{1}\|\nabla\Phi(x^{\prime})\|}{2}\|x-x^{\prime}\|^{2}\quad \text{if}\quad\|x-x^{\prime}\|\leq\frac{1}{\sqrt{2(1+l_{g,1}^{2}/\mu^{2})(L_{x,1 }^{2}+L_{y,1}^{2})}}.\]

**Lemma B.4** ([46, Lemma B.1]).: _Under Assumptions 3.1 to 3.4, the bias of the stochastic hypergradient estimate of the upper-level objective satisfies_

\[\|\bar{\nabla}f(x,y)-\mathbb{E}_{\bar{\xi}}[\bar{\nabla}f(x,y;\bar{\xi})]\| \leq\frac{l_{g,1}l_{f,0}}{\mu}\left(1-\frac{\mu}{l_{g,1}}\right)^{Q},\]

_where \(Q\) is the number of samples chosen to approximate the Hessian inverse. Moreover, we have_

\[\mathbb{E}_{\bar{\xi}}[\|\bar{\nabla}f(x,y;\bar{\xi})-\mathbb{E}_{\bar{\xi}}[ \bar{\nabla}f(x,y;\bar{\xi})]\|^{2}]\leq\sigma_{f,1}^{2}+\frac{3}{\mu^{2}} \left[(\sigma_{f,1}^{2}+l_{f,0}^{2})(\sigma_{g,2}^{2}+2l_{g,1}^{2})+\sigma_{f,1 }^{2}l_{g,1}^{2}\right]\coloneqq\bar{\sigma}^{2}.\]

**Lemma B.5**.: _Under Assumptions 3.1 to 3.4, we have_

\[\|\bar{\nabla}f(x,y)-\nabla\Phi(x)\|\leq(\bar{L}+L_{x,1}\|\nabla\Phi(x)\|)\|y-y^{ *}(x)\|,\]

_where constant \(\bar{L}\) is defined as_

\[\bar{L}:=L_{x,0}+L_{x,1}\frac{l_{g,1}l_{f,0}}{\mu}+\frac{l_{g,1}}{\mu}(L_{y,0}+ L_{y,1}l_{f,0})+l_{f,0}\frac{\mu l_{g,2}+l_{g,1}l_{g,2}}{\mu^{2}}\leq L_{0}.\]

**Lemma B.6**.: _Under Assumptions 3.1 to 3.4, we have_

1. _For any fixed_ \(y\in\mathbb{R}^{d_{y}}\) _and any_ \(x,x^{\prime}\in\mathbb{R}^{d_{x}}\)_,_ \[\mathbb{E}_{\bar{\xi}}\|\bar{\nabla}f(x,y;\bar{\xi})-\bar{\nabla}f(x^{\prime},y;\bar{\xi})\|^{2}\leq(\bar{L}_{0}^{2}+\bar{L}_{1}^{2}\|\nabla\Phi(x)\|^{2}) \|x-x^{\prime}\|^{2}.\]
2. _For any fixed_ \(x\in\mathbb{R}^{d_{x}}\) _and any_ \(y,y^{\prime}\in\mathbb{R}^{d_{y}}\)_,_ \[\mathbb{E}_{\bar{\xi}}\|\bar{\nabla}f(x,y;\bar{\xi})-\bar{\nabla}f(x,y^{\prime };\bar{\xi})\|^{2}\leq(\bar{L}_{0}^{2}+\bar{L}_{1}^{2}\|\nabla\Phi(x)\|^{2}) \|y-y^{\prime}\|^{2}.\]

_In the above expressions, we define \(\bar{L}_{0}\) and \(\bar{L}_{1}\) as_

\[\bar{L}_{0}=\left\{4\left(L_{x,0}+L_{x,1}\left(\frac{l_{g,1}l_{f,0 }}{\mu}+\left(L_{x,0}+\frac{L_{x,1}l_{g,1}l_{f,0}}{\mu}\right)\|y-y^{*}(x)\| \right)\right)^{2}\right.\] \[\left.+\frac{6Q}{2\mu l_{g,1}-\mu^{2}}\left(l_{g,1}^{2}(L_{y,0}+L _{y,1}l_{f,0})^{2}+l_{f,0}^{2}l_{g,2}^{2}+\frac{l_{f,0}^{2}l_{g,1}^{2}l_{g,2}^ {2}Q^{2}}{(l_{g,1}-\mu)^{2}}\right)\right\}^{1/2},\] \[\bar{L}_{1}=2L_{x,1}(1+L_{x,1}\|y-y^{*}(x)\|).\]

Note that in Lemma B.6, constant \(\bar{L}_{0}\) depends on the value of \(\|y-y^{*}(x)\|\). When we consider this term in Algorithm 2, it turns into \(\|y_{t}-y_{t}^{*}\|\) or \(\|\hat{y}_{t}-y_{t}^{*}\|\), which are both as small as \(O(\epsilon)\) (and thus bounded) with high probability by Lemmas 4.5 to 4.7. In other words, we can treat this term as another constant for our algorithm and analysis.

## Appendix C Proofs of Results in Section 4.3.1

For convenience, we will restate a few concepts included in Section 4.3.1 here. We consider the sequences of stochastic optimization problems

\[\min_{w\in\mathbb{R}^{d}}\phi_{t}(w)\] (8)

indexed by time \(t\in\mathbb{N}\). We denote the minimizer and the minimal value of \(\phi_{t}\) as \(w_{t}^{*}\) and \(\phi_{t}^{*}\), and we define the _minimizer drift_ at time \(t\) to be \(\Delta_{t}:=\|w_{t}^{*}-w_{t+1}^{*}\|\). With a slight abuse of notation, we consider the SNAG algorithm applied to the sequence \(\{\phi_{t}\}_{t=1}^{T}\), where \(T\) is the total number of iterations:

\[z_{t} =w_{t}+\gamma(w_{t}-w_{t-1})\] (9) \[w_{t+1} =w_{t}+\gamma(w_{t}-w_{t-1})-\alpha g_{t},\]

where \(g_{t}=\nabla\phi_{t}(z_{t};\xi_{t})\) is the stochastic gradient evaluated at \(z_{t}\) with random sample \(\xi_{t}\). Define \(\varepsilon_{t}=g_{t}-\nabla\phi_{t}(z_{t})\) as the stochastic gradient noise at \(t\)-th iteration. Define \(\mathcal{H}_{t}=\sigma(\xi_{1},\ldots,\xi_{t-1})\) as the filtration, which is the \(\sigma\)-algebra generated by all random variables until \(t\)-th iteration. We will make the following standard assumption, as illustrated below 5.

Footnote 5: Note that Assumptions C.1 and C.2 are more concrete than that in Section 4.3.1.

**Assumption C.1**.: _The sequences of time-varying functions satisfy that, each function \(\phi_{t}:\mathbb{R}^{d}\rightarrow\mathbb{R}\) is \(\mu\)-strongly convex and \(L\)-smooth for some constants \(\mu,L>0\)._

**Assumption C.2** (Sub-Gaussian drift and noise).: _There exists constants \(\Delta,\sigma>0\) such that the following holds for all \(t\geq 0\):_

1. _(_**Drift**_) The drift_ \(\Delta_{t}^{2}\) _is sub-exponential conditioned on_ \(\mathcal{H}_{t}\) _with parameter_ \(\Delta^{2}\)_:_ \[\mathbb{E}\left[\exp(\lambda\Delta_{t}^{2})\mid\mathcal{H}_{t}\right]\leq \exp(\lambda\Delta^{2})\quad\text{for all}\quad 0\leq\lambda\leq\Delta^{-2}.\]_._
2. _(Noise) The noise_ \(\varepsilon_{t}\) _is norm sub-Gaussian conditioned on_ \(\mathcal{H}_{t}\) _with parameter_ \(\sigma/2\)_:_ \[\Pr\left\{\|\varepsilon_{t}\|\geq\varrho\mid\mathcal{H}_{t}\right\}\leq 2\exp(-2 \varrho^{2}/\sigma^{2})\quad\text{for all}\quad\varrho>0.\]

The following lemma characterize the one-step improvement for stochastic Nesterov accelerated gradient method. Although part of our analysis is similar to [13, 5], our final goal is quite different: we aim to derive a careful formulation (see (13)) such that we can apply Lemma A.1 to recursively control the moment generating function of \(V_{t}\) with distributional drift, thus leading to a high probability bound for \(V_{t}\) at _anytime_ (see Lemma C.5), while [13, 5] only show the convergence in expectation without distributional drift.

**Lemma C.3** (Distance recursion, with drift).: _Suppose that Assumptions C.1 and C.2 hold. Let \(\{w_{t}\}\) be the iterates produced by update rule (9) with constant learning rate \(\alpha\leq 1/2L\) and set constants \(\gamma,\rho>0\), and matrix \(\mathbf{P}\in\mathbb{R}^{2d\times 2d}\) as_

\[\gamma=\frac{1-\sqrt{\mu\alpha}}{1+\sqrt{\mu\alpha}},\quad\rho^{2}=1-\sqrt{ \mu\alpha},\quad\mathbf{P}=\frac{1}{2\alpha}\left[\frac{1}{\sqrt{\mu\alpha}}-1 \quad\begin{array}{c}\sqrt{\mu\alpha}-1\\ (1-\sqrt{\mu\alpha})^{2}\end{array}\right]\otimes\mathbf{I}_{d}.\] (10)

_Define \(\theta_{t}=[(w_{t}-w_{t}^{*})^{\top},(w_{t-1}-w_{t}^{*})^{\top}]^{\top}\in \mathbb{R}^{2d}\), also define the potential function and \(u_{t,1},u_{t,2}\) as_

\[V_{t}=\theta_{t}^{\top}\mathbf{P}\theta_{t}+\phi_{t}(w_{t})-\phi_{t}(w_{t}^{*} ),\qquad u_{t,1}=\frac{w_{t}-w_{t}^{*}}{\|w_{t}-w_{t}^{*}\|},\qquad u_{t,2}= \frac{z_{t}-w_{t}}{\|z_{t}-w_{t}\|}.\] (11)

_Then for all \(t\geq 0\), it holds that_

\[\begin{split}\begin{bmatrix}w_{t+1}-w_{t}^{*}\\ w_{t}-w_{t}^{*}\end{bmatrix}^{\top}\mathbf{P}\begin{bmatrix}w_{t+1}-w_{t}^{*} \\ w_{t}-w_{t}^{*}\end{bmatrix}+\phi_{t}(w_{t+1})-\phi_{t}(w_{t}^{*})\\ \leq\rho^{2}V_{t}-\alpha(1-L\alpha)\langle\nabla\phi_{t}(z_{t}), \varepsilon_{t}\rangle+\frac{L\alpha^{2}}{2}\|\varepsilon_{t}\|^{2}.\end{split}\] (12)

_Specifically, if \(\phi_{t}(w)\coloneqq\frac{\mu}{2}\|w-w_{t}^{*}\|^{2}\), then we have_

\[\begin{split} V_{t+1}&\leq\left(1-\frac{\sqrt{\mu \alpha}}{2}\right)V_{t}+\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\left[-\sqrt{ 2\mu}\alpha(1-L\alpha)\langle u_{t,1},\varepsilon_{t}\rangle\sqrt{\frac{\mu} {2}}\|w_{t}-w_{t}^{*}\|\right.\\ &\left.-\frac{2\mu\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha(1-L \alpha)\langle u_{t,2},\varepsilon_{t}\rangle\frac{1+\sqrt{\mu\alpha}}{2\sqrt {2\alpha}}\|z_{t}-w_{t}\|+\frac{\alpha(1+L\alpha)}{2}\|\varepsilon_{t}\|^{2} \right]+\frac{20\mu\Delta_{t}^{2}}{\sqrt{\mu\alpha}}.\end{split}\] (13)

Proof of Lemma c.3.: We first apply Lemma A.2 with

\[v_{1}+v_{2}=\theta_{t+1}=\begin{bmatrix}w_{t+1}-w_{t+1}^{*}\\ w_{t}-w_{t+1}^{*}\end{bmatrix},\quad v_{1}=\begin{bmatrix}w_{t+1}-w_{t}^{*} \\ w_{t}-w_{t}^{*}\end{bmatrix},\quad v_{2}=\begin{bmatrix}w_{t}^{*}-w_{t+1}^{*}\\ w_{t}^{*}-w_{t+1}^{*}\end{bmatrix},\quad\mathbf{Q}=\mathbf{P}\]

to obtain

\[\begin{split}& V_{t+1}=\theta_{t+1}^{\top}\mathbf{P}\theta_{t+1}+ \phi_{t+1}(w_{t+1})-\phi_{t+1}(w_{t+1}^{*})\\ &\leq\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\begin{bmatrix}w_{t+1}-w_{t }^{*}\\ w_{t}-w_{t}^{*}\end{bmatrix}^{\top}\mathbf{P}\begin{bmatrix}w_{t+1}-w_{t}^{*} \\ w_{t}-w_{t}^{*}\end{bmatrix}+\left(1+\frac{4}{\sqrt{\mu\alpha}}\right)\begin{bmatrix} w_{t}^{*}-w_{t+1}^{*}\\ w_{t}^{*}-w_{t+1}^{*}\end{bmatrix}^{\top}\mathbf{P}\begin{bmatrix}w_{t}^{*}-w_{t+1}^{*} \\ w_{t}^{*}-w_{t+1}^{*}\end{bmatrix}+\phi_{t+1}(w_{t+1})-\phi_{t+1}(w_{t+1}^{*})\\ &=\underbrace{\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\left\{ \begin{bmatrix}w_{t+1}-w_{t}^{*}\\ w_{t}-w_{t}^{*}\end{bmatrix}^{\top}\mathbf{P}\begin{bmatrix}w_{t+1}-w_{t}^{*} \\ w_{t}-w_{t}^{*}\end{bmatrix}+\phi_{t}(w_{t+1})-\phi_{t}(w_{t}^{*})\right\}}_{(A)} \\ &\quad+\underbrace{\phi_{t+1}(w_{t+1})-\phi_{t+1}(w_{t+1}^{*})- \left(1+\frac{\sqrt{\mu\alpha}}{4}\right)(\phi_{t}(w_{t+1})-\phi_{t}(w_{t}^{*})) }_{(B)}+\underbrace{\left(1+\frac{4}{\sqrt{\mu\alpha}}\right)\begin{bmatrix} w_{t}^{*}-w_{t+1}^{*}\\ w_{t}^{*}-w_{t+1}^{*}\end{bmatrix}^{\top}\mathbf{P}\begin{bmatrix}w_{t}^{*}-w_{t+1}^{*} \\ w_{t}^{*}-w_{t+1}^{*}\end{bmatrix}}_{(C)}.\end{split}\]

Now we bound terms \((A)\), \((B)\) and \((C)\) individually.

Bounding \((A)\).Let us define vector \(\omega_{t}\in\mathbb{R}^{d}\) and matrices \(\mathbf{A}\in\mathbb{R}^{2d\times 2d},\mathbf{B}\in\mathbb{R}^{2d\times d}\) as

\[\omega_{t}=\nabla\phi_{t}(z_{t}),\quad\mathbf{A}=\begin{bmatrix}1+\gamma&- \gamma\\ 1&0\end{bmatrix}\otimes\mathbf{I}_{d},\quad\mathbf{B}=\begin{bmatrix}-\alpha \\ 0\end{bmatrix}\otimes\mathbf{I}_{d}.\]

By (9) we have

\[[(w_{t+1}-w_{t}^{*})^{\top},(w_{t}-w_{t}^{*})^{\top}]^{\top}=\mathbf{A}\theta_ {t}+\mathbf{B}(\omega_{t}+\varepsilon_{t})\] (14)

Since \(\phi_{t}\) is \(\mu\)-strongly convex, then

\[\phi_{t}(w_{t})-\phi_{t}(z_{t})\geq\langle\nabla\phi_{t}(z_{t}),w_{t}-z_{t} \rangle+\frac{\mu}{2}\|w_{t}-z_{t}\|^{2}.\] (15)

By \(L\)-smoothness of \(\phi_{t}\) and the fact that \(w_{t+1}=z_{t}-\alpha g_{t}\), we have

\[\phi_{t}(z_{t}) -\phi_{t}(w_{t+1})\geq\langle\nabla\phi_{t}(z_{t}),z_{t}-w_{t+1} \rangle-\frac{L}{2}\|w_{t+1}-z_{t}\|^{2}\] (16) \[=\alpha\langle\nabla\phi_{t}(z_{t}),g_{t}\rangle-\frac{L\alpha^{ 2}}{2}\|g_{t}\|^{2}\] \[=\alpha\|\nabla\phi_{t}(z_{t})\|^{2}+\alpha\langle\nabla\phi_{t}( z_{t}),\varepsilon_{t}\rangle-\frac{L\alpha^{2}}{2}(\|\nabla\phi_{t}(z_{t})\|^{2}+2 \langle\nabla\phi_{t}(z_{t}),\varepsilon_{t}\rangle+\|\varepsilon_{t}\|^{2})\] \[=\frac{\alpha}{2}(2-L\alpha)\|\nabla\phi_{t}(z_{t})\|^{2}-\frac{L \alpha^{2}}{2}\|\varepsilon_{t}\|^{2}+\alpha(1-L\alpha)\langle\nabla\phi_{t}( z_{t}),\varepsilon_{t}\rangle,\]

where we use \(g_{t}=\nabla\phi_{t}(z_{t})+\varepsilon_{t}\) in the second equality. Noting that by (9) we have

\[w_{t}-z_{t}=-\gamma(w_{t}-w_{t}^{*})+\gamma(w_{t-1}-w_{t}^{*}),\]

and combining (15) and (16) we obtain

\[\phi_{t}(w_{t})-\phi_{t}(w_{t+1}) \geq\langle\nabla\phi_{t}(z_{t}),w_{t}-z_{t}\rangle+\frac{\mu}{2 }\|w_{t}-z_{t}\|^{2}\] (17) \[\quad+\frac{\alpha}{2}(2-L\alpha)\|\nabla\phi_{t}(z_{t})\|^{2}- \frac{L\alpha^{2}}{2}\|\varepsilon_{t}\|^{2}+\alpha(1-L\alpha)\langle\nabla \phi_{t}(z_{t}),\varepsilon_{t}\rangle\] \[=\begin{bmatrix}\theta_{t}\\ \omega_{t}\end{bmatrix}^{\top}\mathbf{X}_{1}\begin{bmatrix}\theta_{t}\\ \omega_{t}\end{bmatrix}-\frac{L\alpha^{2}}{2}\|\varepsilon_{t}\|^{2}+\alpha(1- L\alpha)\langle\nabla\phi_{t}(z_{t}),\varepsilon_{t}\rangle,\]

where matrix \(\mathbf{X}_{1}\in\mathbb{R}^{3d\times 3d}\) is defined as

\[\mathbf{X}_{1}=\frac{1}{2}\begin{bmatrix}\mu\gamma^{2}&-\mu\gamma^{2}&-\gamma \\ -\mu\gamma^{2}&\mu\gamma^{2}&\gamma\\ -\gamma&\gamma&\alpha(2-L\alpha)\end{bmatrix}\otimes\mathbf{I}_{d}.\]

Then applying the strong convexity of \(\phi_{t}\) again gives

\[\phi_{t}(w_{t}^{*})-\phi_{t}(z_{t})\geq\langle\nabla\phi_{t}(z_{t}),w_{t}^{*}- z_{t}\rangle+\frac{\mu}{2}\|w_{t}^{*}-z_{t}\|^{2}.\] (18)

Noting that

\[w_{t}^{*}-z_{t} =(w_{t}^{*}-w_{t})-\gamma(w_{t}-w_{t}^{*})+\gamma(w_{t-1}-w_{t}^{*})\] \[=-(1+\gamma)(w_{t}-w_{t}^{*})+\gamma(w_{t-1}-w_{t}^{*}),\]

and combining (16) and (18) we obtain

\[\phi_{t}(w_{t}^{*})-\phi_{t}(w_{t+1}) \geq\langle\nabla\phi_{t}(z_{t}),w_{t}^{*}-z_{t}\rangle+\frac{\mu} {2}\|w_{t}^{*}-z_{t}\|^{2}\] (19) \[\quad+\frac{\alpha}{2}(2-L\alpha)\|\nabla\phi_{t}(z_{t})\|^{2}- \frac{L\alpha^{2}}{2}\|\varepsilon_{t}\|^{2}+\alpha(1-L\alpha)\langle\nabla \phi_{t}(z_{t}),\varepsilon_{t}\rangle\] \[=\begin{bmatrix}\theta_{t}\\ \omega_{t}\end{bmatrix}^{\top}\mathbf{X}_{2}\begin{bmatrix}\theta_{t}\\ \omega_{t}\end{bmatrix}-\frac{L\alpha^{2}}{2}\|\varepsilon_{t}\|^{2}+\alpha(1- L\alpha)\langle\nabla\phi_{t}(z_{t}),\varepsilon_{t}\rangle,\]

where matrix \(\mathbf{X}_{2}\in\mathbb{R}^{3d\times 3d}\) is defined as

\[\mathbf{X}_{2}=\frac{1}{2}\begin{bmatrix}\mu(1+\gamma)^{2}&-\mu\gamma(1+\gamma)& -(1+\gamma)\\ -\mu\gamma(1+\gamma)&\mu\gamma^{2}&\gamma\\ -(1+\gamma)&\gamma&\alpha(2-L\alpha)\end{bmatrix}\otimes\mathbf{I}_{d}.\]Next, we multiply (17) by \(\rho^{2}\) and (19) by \(1-\rho^{2}\), then sum them up to get

\[\begin{split}\rho^{2}(\phi_{t}(w_{t})&-\phi_{t}(w_{t}^ {*}))-(\phi_{t}(w_{t+1})-\phi_{t}(w_{t}^{*}))\\ &\geq\begin{bmatrix}\theta_{t}\\ \omega_{t}\end{bmatrix}^{\top}(\rho^{2}\mathbf{X}_{1}+(1-\rho^{2})\mathbf{X}_ {2})\begin{bmatrix}\theta_{t}\\ \omega_{t}\end{bmatrix}-\frac{L\alpha^{2}}{2}\|\varepsilon_{t}\|^{2}+\alpha(1- L\alpha)\langle\nabla\phi_{t}(z_{t}),\varepsilon_{t}\rangle.\end{split}\] (20)

By [42, Section 3.1] (see also [5, Corollary 4.9], [4, Theorem 2.3]), we have the following fact:

\[\begin{bmatrix}\mathbf{A}^{\top}\mathbf{P}\mathbf{A}-\rho^{2}\mathbf{P}& \mathbf{A}^{\top}\mathbf{P}\mathbf{B}\\ \mathbf{B}^{\top}\mathbf{P}\mathbf{A}&\mathbf{B}^{\top}\mathbf{P}\mathbf{B} \end{bmatrix}-(\rho^{2}\mathbf{X}_{1}+(1-\rho^{2})\mathbf{X}_{2})\preceq 0,\] (21)

which, combined with (20) yields

\[\begin{split}&\begin{bmatrix}w_{t+1}-w_{t}^{*}\\ w_{t}-w_{t}^{*}\end{bmatrix}^{\top}\mathbf{P}\begin{bmatrix}w_{t+1}-w_{t}^{*}\\ w_{t}-w_{t}^{*}\end{bmatrix}-\rho^{2}\theta_{t}^{\top}\mathbf{P}\theta_{t}\\ &=\begin{bmatrix}\theta_{t}\\ \omega_{t}\end{bmatrix}^{\top}\begin{bmatrix}\mathbf{A}^{\top}\mathbf{P} \mathbf{A}-\rho^{2}\mathbf{P}&\mathbf{A}^{\top}\mathbf{P}\mathbf{B}\\ \mathbf{B}^{\top}\mathbf{P}\mathbf{A}&\mathbf{B}^{\top}\mathbf{P}\mathbf{B} \end{bmatrix}\begin{bmatrix}\theta_{t}\\ \omega_{t}\end{bmatrix}+\varepsilon_{t}^{\top}\mathbf{B}^{\top}\mathbf{P} \mathbf{B}\varepsilon_{t}\\ &\leq\begin{bmatrix}\theta_{t}\\ \omega_{t}\end{bmatrix}^{\top}(\rho^{2}\mathbf{X}_{1}+(1-\rho^{2})\mathbf{X}_ {2})\begin{bmatrix}\theta_{t}\\ \omega_{t}\end{bmatrix}+\frac{\alpha}{2}\|\varepsilon_{t}\|^{2}\\ &\leq-(\phi_{t}(w_{t+1})-\phi_{t}(w_{t}^{*}))+\rho^{2}(\phi_{t}(w_{t})-\phi_{ t}(w_{t}^{*}))-\alpha(1-L\alpha)\langle\nabla\phi_{t}(z_{t}),\varepsilon_{t} \rangle+\frac{\alpha+L\alpha^{2}}{2}\|\varepsilon_{t}\|^{2},\end{split}\]

where the first inequality uses (14) and (21), along with the fact that \(\mathbf{B}^{\top}\mathbf{P}\mathbf{B}=(\alpha/2)\otimes\mathbf{I}_{d}\) and hence \(\lambda_{\max}(\mathbf{B}^{\top}\mathbf{P}\mathbf{B})=\alpha/2\); and the last inequality follows by (20). Rearrange the above inequality and by definition of the potential function \(V_{t}\), we obtain

\[\begin{split}\begin{bmatrix}w_{t+1}-w_{t}^{*}\\ w_{t}-w_{t}^{*}\end{bmatrix}^{\top}\mathbf{P}\begin{bmatrix}w_{t+1}-w_{t}^{*} \\ w_{t}-w_{t}^{*}\end{bmatrix}^{\top}&+\phi_{t}(w_{t+1})-\phi_{t}(w_{t}^{*})\\ &\leq\rho^{2}V_{t}-\alpha(1-L\alpha)\langle\nabla\phi_{t}(z_{t}), \varepsilon_{t}\rangle+\frac{\alpha(1+L\alpha)}{2}\|\varepsilon_{t}\|^{2}. \end{split}\] (22)

Now recall that in (8) our objective function has the form of \(\phi_{t}(w)=\frac{\mu}{2}\|w-w_{t}^{*}\|^{2}\), hence \(\nabla\phi_{t}(z_{t})=\mu(z_{t}-w_{t}^{*})\). Plugging this into the above inequality gives

\[\begin{split}\begin{bmatrix}w_{t+1}-w_{t}^{*}\\ w_{t}-w_{t}^{*}\end{bmatrix}^{\top}\mathbf{P}\begin{bmatrix}w_{t+1}-w_{t}^{*} \\ w_{t}-w_{t}^{*}\end{bmatrix}+\phi_{t}(w_{t+1})-\phi_{t}(w_{t}^{*})\\ &\leq\rho^{2}V_{t}-\mu\alpha(1-L\alpha)\langle z_{t}-w_{t}^{*}, \varepsilon_{t}\rangle+\frac{\alpha+L\alpha^{2}}{2}\|\varepsilon_{t}\|^{2}\\ &=\rho^{2}V_{t}-\mu\alpha(1-L\alpha)\langle w_{t}-w_{t}^{*}, \varepsilon_{t}\rangle-\mu\alpha(1-L\alpha)\langle z_{t}-w_{t},\varepsilon_{t }\rangle+\frac{\alpha(1+L\alpha)}{2}\|\varepsilon_{t}\|^{2}\\ &=\rho^{2}V_{t}-\sqrt{2\mu}\alpha(1-L\alpha)\langle u_{t,1}, \varepsilon_{t}\rangle\sqrt{\frac{\mu}{2}}\|w_{t}-w_{t}^{*}\|\\ &\qquad\qquad-\frac{2\mu\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha(1 -L\alpha)\langle u_{t,2},\varepsilon_{t}\rangle\frac{1+\sqrt{\mu\alpha}}{2 \sqrt{2\alpha}}\|z_{t}-w_{t}\|+\frac{\alpha(1+L\alpha)}{2}\|\varepsilon_{t}\|^ {2},\end{split}\] (23)

where \(u_{t,1}\) and \(u_{t,2}\) are defined as

\[u_{t,1}=\frac{w_{t}-w_{t}^{*}}{\|w_{t}-w_{t}^{*}\|},\qquad u_{t,2}=\frac{z_{t}- w_{t}}{\|z_{t}-w_{t}\|}.\]

Therefore, we conclude that

\[\begin{split}(A)&\leq\left(1+\frac{\sqrt{\mu\alpha}}{4} \right)\left[\rho^{2}V_{t}-\sqrt{2\mu}\alpha(1-L\alpha)\langle u_{t,1}, \varepsilon_{t}\rangle\sqrt{\frac{\mu}{2}}\|w_{t}-w_{t}^{*}\|\\ &\qquad\qquad-\frac{2\mu\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha(1 -L\alpha)\langle u_{t,2},\varepsilon_{t}\rangle\frac{1+\sqrt{\mu\alpha}}{2 \sqrt{2\alpha}}\|z_{t}-w_{t}\|+\frac{\alpha(1+L\alpha)}{2}\|\varepsilon_{t}\|^{2 }\right]\\ &\leq\left(1-\frac{3\sqrt{\mu\alpha}}{4}\right)V_{t}+\left[-\sqrt{2 \mu}\alpha(1-L\alpha)\langle u_{t,1},\varepsilon_{t}\rangle\sqrt{\frac{\mu}{2}}\| w_{t}-w_{t}^{*}\|\\ &\qquad\qquad-\frac{2\mu\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha(1 -L\alpha)\langle u_{t,2},\varepsilon_{t}\rangle\frac{1+\sqrt{\mu\alpha}}{2 \sqrt{2\alpha}}\|z_{t}-w_{t}\|+\frac{\alpha(1+L\alpha)}{2}\|\varepsilon_{t}\|^{2 }\right],\end{split}\] (24)where the last inequality follows from the definition of \(\rho\) and simple calculation

\[\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\rho^{2}=\left(1+\frac{\sqrt{\mu\alpha}}{ 4}\right)(1-\sqrt{\mu\alpha})\leq 1-\frac{3\sqrt{\mu\alpha}}{4}.\]

Bounding \((B)\).Recall that under distributional drift, the objective function in (8) has the form of \(\phi_{t}(w)=\frac{\mu}{2}\|w-w_{t}^{*}\|^{2}\), then we have

\[(B) =\phi_{t+1}(w_{t+1})-\phi_{t+1}(w_{t+1}^{*})-\left(1+\frac{\sqrt{ \mu\alpha}}{4}\right)(\phi_{t}(w_{t+1})-\phi_{t}(w_{t}^{*}))\] \[\leq\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)(\phi_{t+1}(w_{t+1} )-\phi_{t+1}(w_{t+1}^{*})-\phi_{t}(w_{t+1})+\phi_{t}(w_{t}^{*}))\] \[=\frac{\mu}{2}\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)(\|w_{t+1 }-w_{t+1}^{*}\|^{2}-\|w_{t+1}-w_{t}^{*}\|^{2})\] \[\leq\frac{\mu}{2}\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\|w_{t }^{*}-w_{t+1}^{*}\|\|w_{t+1}-w_{t}^{*}+w_{t+1}-w_{t+1}^{*}\|\] \[\leq\frac{\mu}{2}\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\Delta _{t}(2\|w_{t+1}-w_{t+1}^{*}\|+\|w_{t+1}^{*}-w_{t}^{*}\|)\]

Since \(\phi_{t+1}\) is \(\mu\)-strongly convex and matrix \(\mathbf{P}\) is PSD, then

\[V_{t+1} =\theta_{t+1}^{\top}\mathbf{P}\theta_{t+1}+\phi_{t+1}(w_{t+1})- \phi_{t}(w_{t+1}^{*})\geq\phi_{t+1}(w_{t+1})-\phi_{t}(w_{t+1}^{*})\] \[\geq\frac{\mu}{2}\|w_{t+1}-w_{t+1}^{*}\|^{2}\qquad\qquad\implies \qquad\qquad\|w_{t+1}-w_{t+1}^{*}\|\leq\sqrt{\frac{2}{\mu}}\sqrt{V_{t+1}}.\]

Plugging the above fact back into the upper bound for \((B)\) gives

\[(B) \leq\frac{\mu}{2}\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\Delta _{t}\left(2\sqrt{\frac{2}{\mu}}\sqrt{V_{t+1}}+\Delta_{t}\right)\] (25) \[=\sqrt{2\mu}\Delta_{t}\left(1+\frac{\sqrt{\mu\alpha}}{4}\right) \sqrt{V_{t+1}}+\frac{\mu}{2}\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\Delta_{ t}^{2}.\]

Bounding \((C)\).For this part, we handle the distributional drift. By definition of \(\mathbf{P}\) in (10), we have

\[(C) =\left(1+\frac{4}{\sqrt{\mu\alpha}}\right)\begin{bmatrix}w_{t}^{* }-w_{t+1}^{*}\\ w_{t}^{*}-w_{t+1}^{*}\end{bmatrix}^{\top}\frac{1}{2\alpha}\begin{bmatrix} \mathbf{I}_{d}&(\sqrt{\mu\alpha}-1)\mathbf{I}_{d}\\ (\sqrt{\mu\alpha}-1)\mathbf{I}_{d}&(1-\sqrt{\mu\alpha})^{2}\mathbf{I}_{d} \end{bmatrix}\begin{bmatrix}w_{t}^{*}-w_{t+1}^{*}\\ w_{t}^{*}-w_{t+1}^{*}\end{bmatrix}\] (26) \[=\frac{\mu}{2}\left(1+\frac{4}{\sqrt{\mu\alpha}}\right)\Delta_{t} ^{2},\]

where in the last equality we use the basic algebra of block matrix multiplication and the definition of \(\Delta_{t}=\|w_{t}^{*}-w_{t+1}^{*}\|\).

Final Bound for \(V_{t+1}\).Now we are ready to derive the upper bound for \(V_{t+1}\). Combining (24), (25) and (26) together yields

\[V_{t+1} \leq(A)+(B)+(C)\] (27) \[\leq\left(1-\frac{3\sqrt{\mu\alpha}}{4}\right)V_{t}+\left[-\sqrt {2\mu}\alpha(1-L\alpha)\langle u_{t,1},\varepsilon_{t}\rangle\sqrt{\frac{\mu}{ 2}}\|w_{t}-w_{t}^{*}\|\right.\] \[\qquad\qquad\left.-\frac{2\mu\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}} \alpha(1-L\alpha)\langle u_{t,2},\varepsilon_{t}\rangle\frac{1+\sqrt{\mu\alpha} }{2\sqrt{2\alpha}}\|z_{t}-w_{t}\|+\frac{\alpha(1+L\alpha)}{2}\|\varepsilon_{ t}\|^{2}\right]\] \[\quad+\sqrt{2\mu}\Delta_{t}\left(1+\frac{\sqrt{\mu\alpha}}{4} \right)\sqrt{V_{t+1}}+\mu\left(1+\frac{\sqrt{\mu\alpha}}{8}+\frac{2}{\sqrt{ \mu\alpha}}\right)\Delta_{t}^{2}.\]

For simplicity, we define \(D\) as the following

\[D =\left(1-\frac{3\sqrt{\mu\alpha}}{4}\right)V_{t}+\left[-\sqrt{2 \mu}\alpha(1-L\alpha)\langle u_{t,1},\varepsilon_{t}\rangle\sqrt{\frac{\mu}{2}} \|w_{t}-w_{t}^{*}\|\right.\] \[\quad\left.-\frac{2\mu\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha (1-L\alpha)\langle u_{t,2},\varepsilon_{t}\rangle\frac{1+\sqrt{\mu\alpha}}{2 \sqrt{2\alpha}}\|z_{t}-w_{t}\|+\frac{\alpha(1+L\alpha)}{2}\|\varepsilon_{t}\|^ {2}\right]+\mu\left(1+\frac{\sqrt{\mu\alpha}}{8}+\frac{2}{\sqrt{\mu\alpha}} \right)\Delta_{t}^{2}.\]Hence (27) turns into

\[V_{t+1}-\sqrt{2\mu}\Delta_{t}\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\sqrt{V_{t+ 1}}-D\leq 0.\]

Solving the above inequality we get

\[\sqrt{V_{t+1}} \leq\frac{1}{2}\left[\sqrt{2\mu}\Delta_{t}\left(1+\frac{\sqrt{\mu \alpha}}{4}\right)+\sqrt{\left(\sqrt{2\mu}\Delta_{t}\left(1+\frac{\sqrt{\mu \alpha}}{4}\right)\right)^{2}+4D}\right]\] \[\leq\sqrt{2\mu}\Delta_{t}\left(1+\frac{\sqrt{\mu\alpha}}{4} \right)+\sqrt{D}\]

Then an application of Young's inequality reveals

\[V_{t+1} \leq\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)D+\left(1+\frac{4}{ \sqrt{\mu\alpha}}\right)\left(\sqrt{2\mu}\Delta_{t}\left(1+\frac{\sqrt{\mu \alpha}}{4}\right)\right)^{2}\] \[=\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\left\{\left(1-\frac{ 3\sqrt{\mu\alpha}}{4}\right)V_{t}+\left[-\sqrt{2\mu}\alpha(1-L\alpha)\langle u _{t,1},\varepsilon_{t}\rangle\sqrt{\frac{\mu}{2}}\|w_{t}-w_{t}^{*}\|\right.\] \[\quad\left.-\frac{2\mu\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha( 1-L\alpha)\langle u_{t,2},\varepsilon_{t}\rangle\frac{1+\sqrt{\mu\alpha}}{2 \sqrt{2\alpha}}\|z_{t}-w_{t}\|+\frac{\alpha(1+L\alpha)}{2}\|\varepsilon_{t}\| ^{2}\right]+\mu\left(1+\frac{\sqrt{\mu\alpha}}{8}+\frac{2}{\sqrt{\mu\alpha}} \right)\Delta_{t}^{2}\right\}\] \[\quad+\left(1+\frac{4}{\sqrt{\mu\alpha}}\right)2\mu\Delta_{t}^{2} \left(1+\frac{\sqrt{\mu\alpha}}{4}\right)^{2}\] \[\leq\left(1-\frac{\sqrt{\mu\alpha}}{2}\right)V_{t}+\left(1+\frac{ \sqrt{\mu\alpha}}{4}\right)\left[-\sqrt{2\mu}\alpha(1-L\alpha)\langle u_{t,1},\varepsilon_{t}\rangle\sqrt{\frac{\mu}{2}}\|w_{t}-w_{t}^{*}\|\right.\] \[\quad\left.-\frac{2\mu\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha( 1-L\alpha)\langle u_{t,2},\varepsilon_{t}\rangle\frac{1+\sqrt{\mu\alpha}}{2 \sqrt{2\alpha}}\|z_{t}-w_{t}\|+\frac{\alpha(1+L\alpha)}{2}\|\varepsilon_{t}\| ^{2}\right]\] \[\quad+\mu\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\left(1+\frac{ \sqrt{\mu\alpha}}{8}+\frac{2}{\sqrt{\mu\alpha}}\right)\Delta_{t}^{2}+\left(1+ \frac{4}{\sqrt{\mu\alpha}}\right)2\mu\Delta_{t}^{2}\left(1+\frac{\sqrt{\mu \alpha}}{4}\right)^{2},\]

where we plug in the definition of \(D\) for the first equality. Since the learning rate \(\alpha\leq 1/L\) and thus \(\mu\alpha\leq 1\), then we have

\[\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\left(1+\frac{\sqrt{\mu\alpha}}{8}+ \frac{2}{\sqrt{\mu\alpha}}\right)\leq\frac{125}{32\sqrt{\mu\alpha}},\qquad 2 \left(1+\frac{4}{\sqrt{\mu\alpha}}\right)\left(1+\frac{\sqrt{\mu\alpha}}{4} \right)^{2}\leq\frac{125}{8\sqrt{\mu\alpha}}.\]

Therefore, we finally conclude that

\[V_{t+1} \leq\left(1-\frac{\sqrt{\mu\alpha}}{2}\right)V_{t}+\left(1+\frac{ \sqrt{\mu\alpha}}{4}\right)\left[-\sqrt{2\mu}\alpha(1-L\alpha)\langle u_{t,1},\varepsilon_{t}\rangle\sqrt{\frac{\mu}{2}}\|w_{t}-w_{t}^{*}\|\right.\] \[\quad\left.-\frac{2\mu\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha(1- L\alpha)\langle u_{t,2},\varepsilon_{t}\rangle\frac{1+\sqrt{\mu\alpha}}{2 \sqrt{2\alpha}}\|z_{t}-w_{t}\|+\frac{\alpha(1+L\alpha)}{2}\|\varepsilon_{t}\| ^{2}\right]+\frac{20\mu\Delta_{t}^{2}}{\sqrt{\mu\alpha}},\]

which is as claimed in (13). 

When there is no drift, the following lemma holds for any general strongly convex functions \(\phi\) in \(\mathbb{R}^{d}\).

**Lemma C.4** (Distance recursion, without drift).: _Under the same settings as in Lemma C.3 with \(\phi_{t}(w)\equiv\phi(w)\), and \(w_{t}^{*}\equiv w^{*}\), where \(\phi(w)\) can be any general strongly functions in \(\mathbb{R}^{d}\). We redefine \(u_{t,1},u_{t,2}\) as_

\[u_{t,1}=\frac{\nabla\phi(w_{t})-\nabla\phi(w^{*})}{\|\nabla\phi(w_{t})-\nabla \phi(w^{*})\|},\qquad u_{t,2}=\frac{\nabla\phi(z_{t})-\nabla\phi(w_{t})}{\| \nabla\phi(z_{t})-\nabla\phi(w_{t})\|}.\] (28)

_Then for all \(t\geq 0\), it holds that_

\[V_{t+1} \leq(1-\sqrt{\mu\alpha})V_{t}-\sqrt{\frac{2}{\mu}}L\alpha(1-L \alpha)\langle u_{t,1},\varepsilon_{t}\rangle\frac{1}{L}\sqrt{\frac{\mu}{2}}\| \nabla\phi_{t}(w_{t})-\nabla\phi_{t}(w^{*})\|\] (29) \[-\frac{2L\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha(1-L\alpha) \langle u_{t,2},\varepsilon_{t}\rangle\frac{1+\sqrt{\mu\alpha}}{2L\sqrt{2 \alpha}}\|\nabla\phi_{t}(z_{t})-\nabla\phi_{t}(w_{t})\|+\frac{\alpha(1+L\alpha) }{2}\|\varepsilon_{t}\|^{2}.\]Proof of Lemma c.4.: By (12) in Lemma C.3 with \(\phi_{t}(w)\equiv\phi(w)\) and \(w_{t}^{*}\equiv w^{*}\), we have

\[V_{t+1} \leq\rho^{2}V_{t}-\alpha(1-L\alpha)\langle\nabla\phi_{t}(z_{t}), \varepsilon_{t}\rangle+\frac{L\alpha^{2}}{2}\|\varepsilon_{t}\|^{2}\] \[=\rho^{2}V_{t}-\alpha(1-L\alpha)\langle\nabla\phi_{t}(w_{t})- \nabla\phi_{t}(w^{*}),\varepsilon_{t}\rangle-\alpha(1-L\alpha)\langle\nabla \phi_{t}(z_{t})-\nabla\phi_{t}(w_{t}),\varepsilon_{t}\rangle+\frac{\alpha(1+L \alpha)}{2}\|\varepsilon_{t}\|^{2}\] \[=(1-\sqrt{\mu\alpha})V_{t}-\sqrt{\frac{2}{\mu}}L\alpha(1-L\alpha )\langle u_{t,1},\varepsilon_{t}\rangle\frac{1}{L}\sqrt{\frac{\mu}{2}}\| \nabla\phi_{t}(w_{t})-\nabla\phi_{t}(w^{*})\|\] \[\qquad-\frac{2L\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha(1-L \alpha)\langle u_{t,2},\varepsilon_{t}\rangle\frac{1+\sqrt{\mu\alpha}}{2L \sqrt{2\alpha}}\|\nabla\phi_{t}(z_{t})-\nabla\phi_{t}(w_{t})\|+\frac{\alpha(1+ L\alpha)}{2}\|\varepsilon_{t}\|^{2}.\]

Hence the proof is completed. 

The following result shows the first part of Lemma 4.3. To the best of our knowledge, this is the first high probability guarantee with improved rate for SNAG under distributional drift.

**Lemma C.5** (High-probability distance tracking, with drift).: _Under the same setting as in Lemma C.3 with \(\alpha\leq 1/25L\), for any given \(\delta\in(0,1)\) and all \(t\in[T]\), the following holds with probability at least \(1-\delta\) over the randomness in \(\mathcal{H}_{t}\):_

\[V_{t}\leq\left(1-\frac{\sqrt{\mu\alpha}}{4}\right)^{t}V_{0}+\left(\frac{5\sqrt {\alpha}\sigma^{2}}{\sqrt{\mu}}+\frac{80\Delta^{2}}{\alpha}\right)\ln\frac{eT }{\delta}.\] (30)

Proof of Lemma c.5.: We will invoke Lemma A.1 to show the results. To apply Lemma A.1, we first need to show the following two facts:

\[\text{Fact (I)}:\quad\sqrt{\frac{\mu}{2}}\|w_{t}-w_{t}^{*}\|\leq\sqrt{V_{t}} \qquad\&\qquad\text{Fact (II)}:\quad\frac{1+\sqrt{\mu\alpha}}{2\sqrt{2\alpha}}\|z_{t}-w_{t}\|\leq \sqrt{V_{t}}.\] (31)

Fact (I) verification.Since \(\phi_{t}\) is \(\mu\)-strongly convex and matrix \(\mathbf{P}\) is PSD, then

\[V_{t} =\theta_{t}^{\top}\mathbf{P}\theta_{t}+\phi_{t}(w_{t})-\phi_{t}(w _{t}^{*})\geq\phi_{t}(w_{t})-\phi_{t}(w_{t}^{*})\] \[\geq\frac{\mu}{2}\|w_{t}-w_{t}^{*}\|^{2}\qquad\qquad\implies \qquad\qquad\sqrt{\frac{\mu}{2}}\|w_{t}-w_{t}^{*}\|\leq\sqrt{V_{t}}.\]

Fact (II) verification.By definition of matrix \(\mathbf{P}\) and simple calculation we have

\[\sqrt{V_{t}} \geq\sqrt{\theta_{t}^{\top}\mathbf{P}\theta_{t}}=\sqrt{\frac{1}{ 2\alpha}}\|(w_{t}-w_{t}^{*})+(\sqrt{\mu\alpha}-1)(w_{t-1}-w_{t}^{*})\|\] \[=\sqrt{\frac{1}{2\alpha}}\|(1-\sqrt{\mu\alpha})(w_{t}-w_{t-1})+ \sqrt{\mu\alpha}(w_{t}-w_{t}^{*})\|\] \[\geq\sqrt{\frac{1}{2\alpha}}(1-\sqrt{\mu\alpha})\|w_{t}-w_{t-1} \|-\sqrt{\frac{\mu}{2}}\|w_{t}-w_{t}^{*}\|\] \[\geq\sqrt{\frac{1}{2\alpha}}(1-\sqrt{\mu\alpha})\|w_{t}-w_{t-1} \|-\sqrt{V_{t}}.\]

Rearrange the above inequality, and recall the update rule of stochastic Nesterov accelerated gradient method, we have

\[\|z_{t}-w_{t}\|=\gamma\|w_{t}-w_{t-1}\|\leq\frac{2\gamma\sqrt{2\alpha}}{1- \sqrt{\mu\alpha}}\sqrt{V_{t}}=\frac{2\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\sqrt{ V_{t}},\]

where for the last equality we use the definition of \(\gamma\) as in (10). Rearrange it gives (31).

By Lemma C.3 and the choice of \(\alpha\leq 1/L\), we have

\[V_{t+1} \leq\left(1-\frac{\sqrt{\mu\alpha}}{2}\right)V_{t}+\left(1+\frac{ \sqrt{\mu\alpha}}{4}\right)\left[\sqrt{2\mu}\alpha(1-L\alpha)\langle u_{t,1}, -\varepsilon_{t}\rangle\sqrt{\frac{\mu}{2}}\|w_{t}-w_{t}^{*}\|\right.\] (32) \[\qquad\left.+\frac{2\mu\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha( 1-L\alpha)\langle u_{t,2},-\varepsilon_{t}\rangle\frac{1+\sqrt{\mu\alpha}}{2 \sqrt{2\alpha}}\|z_{t}-w_{t}\|+\alpha\|\varepsilon_{t}\|^{2}\right]+\frac{20\mu \Delta_{t}^{2}}{\sqrt{\mu\alpha}}.\]Note that under Assumption C.2, there exists an absolute constant \(c\geq 1\) such that for all \(t\geq 0\), \(\|\varepsilon_{t}\|^{2}\) is sub-exponential conditioned on \(\mathcal{H}_{t}\) with parameter \(c\sigma^{2}\), and \(\varepsilon_{t}\) is mean-zero sub-Gaussian conditioned on \(\mathcal{H}_{t}\) with parameter \(c\sigma\)[20, Theorem 30]. For convenience we simply let \(c=1\) here. Thus \(\langle u_{t,1},-\varepsilon_{t}\rangle\) is mean-zero sub-Gaussian conditioned on \(\mathcal{H}_{t}\) with parameter \(\sigma\), and \(\Delta_{t}^{2}\) is sub-exponential conditioned on \(\mathcal{H}_{t}\) with parameter \(\Delta^{2}\) by assumption. Hence, in light of (32), we apply Lemma A.1 with

\[\mathcal{H}_{t}=\mathcal{H}_{t},\quad V_{t}=V_{t},\quad V_{t,1}^{\prime}=\frac {\mu}{2}\|w_{t}-w_{t}^{*}\|^{2},\quad V_{t,2}^{\prime}=\frac{(1+\sqrt{\mu \alpha})^{2}}{8\alpha}\|z_{t}-w_{t}\|^{2},\]

\[D_{t,1}=\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\sqrt{2\mu}\alpha(1-L\alpha) \langle u_{t,1},-\varepsilon_{t}\rangle,\quad D_{t,2}=\left(1+\frac{\sqrt{\mu \alpha}}{4}\right)\frac{2\mu\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha(1-L \alpha)\langle u_{t,2},-\varepsilon_{t}\rangle,\]

\[X_{t}=\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\alpha\|\varepsilon_{t}\|^{2}+ \frac{20\mu\Delta_{t}^{2}}{\sqrt{\mu\alpha}},\quad\alpha_{t}=1-\frac{\sqrt{\mu \alpha}}{2},\quad\kappa_{t}=0,\]

\[\sigma_{1}=\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\sqrt{2\mu}\alpha(1-L \alpha)\sigma,\quad\sigma_{2}=\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\frac{ 2\mu\sqrt{2\alpha}}{1+\sqrt{\mu\alpha}}\alpha(1-L\alpha)\sigma,\]

\[\nu_{t}=\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\alpha\sigma^{2}+\frac{20\mu \Delta^{2}}{\sqrt{\mu\alpha}},\]

yielding the following recursion

\[\mathbb{E}[\exp(\lambda V_{t+1})]\leq\exp\left(\lambda\left[\left(1+\frac{ \sqrt{\mu\alpha}}{4}\right)\alpha\sigma^{2}+\frac{20\mu\Delta^{2}}{\sqrt{\mu \alpha}}\right]\right)\mathbb{E}\left[\exp\left(\lambda\left(1-\frac{\sqrt{ \mu\alpha}}{4}\right)V_{t}\right)\right]\] (33)

for all \(\lambda\) satisfying

\[0\leq\lambda\leq\min\left\{\frac{2}{125\alpha\sqrt{\mu\alpha}\sigma^{2}}, \frac{1}{5\alpha\sigma^{2}/2+40\mu\Delta^{2}/\sqrt{\mu\alpha}}\right\}.\]

We then apply (33) recursively to deduce

\[\mathbb{E}[\exp(\lambda V_{t+1})] \leq\exp\left[\lambda\left(1-\frac{\sqrt{\mu\alpha}}{4}\right)^{ t}V_{0}+\lambda\left(\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\alpha\sigma^{2}+ \frac{20\mu\Delta^{2}}{\sqrt{\mu\alpha}}\right)\sum_{i=0}^{t-1}\left(1-\frac{ \sqrt{\mu\alpha}}{4}\right)^{i}\right]\] \[\leq\exp\left\{\lambda\left[\left(1-\frac{\sqrt{\mu\alpha}}{4} \right)^{t}V_{0}+4\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\frac{\alpha}{ \sqrt{\mu\alpha}}\sigma^{2}+\frac{80\Delta^{2}}{\alpha}\right]\right\}\]

for all \(\lambda\) satisfying

\[0\leq\lambda\leq\min\left\{\frac{2}{125\alpha\sqrt{\mu\alpha}\sigma^{2}}, \frac{1}{5\alpha\sigma^{2}/2+40\mu\Delta^{2}/\sqrt{\mu\alpha}}\right\}.\]

Moreover, setting

\[\nu\coloneqq\frac{5\sqrt{\alpha}\sigma^{2}}{\sqrt{\mu}}+\frac{80\Delta^{2}}{\alpha}\]

and taking into account \(\alpha\leq 1/25L\), then we have

\[4\left(1+\frac{\sqrt{\mu\alpha}}{4}\right)\frac{\alpha}{\sqrt{\mu\alpha}} \sigma^{2}+\frac{80\Delta^{2}}{\alpha}\leq\nu\]

and

\[\frac{1}{\nu}=\frac{1}{5\sqrt{\alpha}\sigma^{2}/\sqrt{\mu}+80\Delta^{2}/ \alpha}\leq\min\left\{\frac{2}{125\alpha\sqrt{\mu\alpha}\sigma^{2}},\frac{1} {5\alpha\sigma^{2}/2+40\mu\Delta^{2}/\sqrt{\mu\alpha}}\right\}.\]

Thus we obtain

\[\mathbb{E}\left[\exp\left(\lambda\left(V_{t}-\left(1-\frac{\sqrt{\mu\alpha}}{4} \right)^{t}V_{0}\right)\right)\right]\leq\exp(\lambda\nu)\quad\text{for all}\quad 0\leq\lambda\leq 1/\nu.\]

Taking \(\lambda=1/\nu\) and applying Markov's inequality and union bound completes the proof.

The following result shows the second part of Lemma 4.3.

**Lemma C.6** (High-probability distance tracking, without drift).: _Under the same setting as in Lemma C.4 with \(\alpha\leq 1/25L\), for any given \(\delta\in(0,1)\) and all \(t\in[T]\), the following holds with probability at least \(1-\delta\) over the randomness in \(\mathcal{H}_{t}\):_

\[V_{t}\leq\left(1-\frac{\sqrt{\mu\alpha}}{4}\right)^{t}V_{0}+\frac{5\sqrt{ \alpha}\sigma^{2}}{\sqrt{\mu}}\ln\frac{eT}{\delta}.\] (34)

Proof of Lemma c.6.: First it is easy to verify that

\[\frac{1}{L}\sqrt{\frac{\mu}{2}}\|\nabla\phi_{t}(w_{t})-\nabla\phi_{t}(w^{*}) \|\leq\sqrt{V_{t}}\qquad\text{and}\qquad\frac{1+\sqrt{\mu\alpha}}{2L\sqrt{2 \alpha}}\|\nabla\phi_{t}(z_{t})-\nabla\phi_{t}(w_{t})\|\leq\sqrt{V_{t}}.\]

Then we apply Lemma A.1 to obtain the final result. We omit the detailed proof here since it follows the same procedure as in proof of Lemma C.5. 

## Appendix D Proofs of Results in Section 4.3.2

We first present the following algebraic fact under suitable choice of parameters.

**Lemma D.1** (Parameter choice, informal).: _For any given \(\delta\in(0,1)\) and any small \(\epsilon\) satisfying_

\[\epsilon\leq\left(\frac{170\cdot 32ed_{0}L_{0}^{2}\tilde{\sigma}_{g,1}^{2}}{ \delta\mu^{2}}\max\left\{\frac{l_{g,1}}{\tilde{\sigma}_{g,1}},\frac{\bar{ \sigma}}{d_{0}}\right\}\right)^{1/3},\] (35)

_if we set parameters \(\alpha,\beta,\eta,T\) as_

\[1-\beta=\frac{\mu^{2}\epsilon^{2}}{170\cdot 64L_{0}^{2}\tilde{\sigma}_{g,1}^{ 2}\ln(P)},\quad\eta=\min\left\{\frac{\tilde{\sigma}_{g,1}}{l_{g,1}},\frac{d_{ 0}}{\bar{\sigma}}\right\}(1-\beta),\quad\alpha=\frac{1}{\mu}(1-\beta),\quad \sigma_{g,1}=\sqrt{\mu\alpha}\tilde{\sigma}_{g,1},\quad T=\frac{4d_{0}}{\eta \epsilon},\] (36)

_where \(\bar{\sigma}\) is defined in Lemma B.4, and \(d_{0}\) and \(P\) are defined as_

\[d_{0}=\Phi(x_{0})-\inf_{x\in\mathbb{R}^{d_{x}}}\Phi(x),\quad P=\left(\frac{17 0\cdot 64ed_{0}L_{0}^{2}\tilde{\sigma}_{g,1}^{2}}{\delta\mu^{2}\epsilon^{3}} \max\left\{\frac{l_{g,1}}{\tilde{\sigma}_{g,1}},\frac{\bar{\sigma}}{d_{0}} \right\}\right)^{2}.\] (37)

_Then the following holds for all \(t\in[T]\):_

\[\left(\frac{4\alpha\tilde{\sigma}_{g,1}^{2}}{\mu}+\frac{160\eta^{2}l_{g,1}^{2} }{\mu^{3}\alpha}\right)\ln\frac{eT}{\delta}\leq\frac{\epsilon^{2}}{64L_{0}^{2 }}.\]

Proof of Lemma d.1.: By Lemma B.1, we have \(\Delta_{t}=\|y_{t}^{*}-y_{t+1}^{*}\|\leq\frac{l_{g,1}}{\mu}\|x_{t}-x_{t+1}\|= \eta l_{g,1}/\mu\). Thus in our bilevel setting, we choose \(\Delta=\eta l_{g,1}/\mu\), where \(\Delta\) is defined in Section 4.3.1. By choice of \(\alpha,\eta,T\) as in (36), we have

\[\left(\frac{10\alpha\tilde{\sigma}_{g,1}^{2}}{\mu}+\frac{160\eta ^{2}l_{g,1}^{2}}{\mu^{3}\alpha}\right)\ln\frac{eT}{\delta} =\left(\frac{10(1-\beta)\tilde{\sigma}_{g,1}^{2}}{\mu^{2}}+\frac{ 160\eta^{2}l_{g,1}^{2}}{\mu^{2}(1-\beta)}\right)\ln\left(\frac{4ed_{0}}{\delta \eta\epsilon}\right)\] \[\leq\frac{170(1-\beta)\tilde{\sigma}_{g,1}^{2}}{\mu^{2}}\ln\left( \frac{4ed_{0}}{\delta\epsilon(1-\beta)}\max\left\{\frac{l_{g,1}}{\tilde{ \sigma}_{g,1}},\frac{\bar{\sigma}}{4d_{0}}\right\}\right).\]

Now we choose \(\beta\) to be

\[1-\beta=\frac{\mu^{2}\epsilon^{2}}{170\cdot 64L_{0}^{2}\tilde{\sigma}_{g,1}^{ 2}\ln(P)},\quad\text{where}\quad P=\left(\frac{170\cdot 64ed_{0}L_{0}^{2} \tilde{\sigma}_{g,1}^{2}}{\delta\mu^{2}\epsilon^{3}}\max\left\{\frac{l_{g,1}}{ \tilde{\sigma}_{g,1}},\frac{\bar{\sigma}}{d_{0}}\right\}\right)^{2}.\]

Then we have

\[\frac{170(1-\beta)\tilde{\sigma}_{g,1}^{2}}{\mu^{2}}\ln\left(\frac{4ed_{0}l_{g,1}}{\delta\epsilon\tilde{\sigma}_{g,1}(1-\beta)}\right)=\frac{\epsilon^{2}}{6 4L_{0}^{2}\ln(P)}\ln\left(\sqrt{P}\ln(P)\right)\leq\frac{\epsilon^{2}}{64L_{0} ^{2}},\]

where we use the fact that \(\ln(\sqrt{P}\ln(P))\leq\ln(P)\leq\ln^{2}(P)\) for any \(P\geq 4\) by choice of \(\epsilon\) as in (35). 

In the rest of this section, we assume Assumptions 3.1 to 3.4 hold. In addition, the failure probability \(\delta\in(0,1)\) and \(\epsilon>0\) are chosen in the same way as in Theorem 4.1.

### Proof of Lemma 4.4

**Lemma D.2** (Warm-start, Restatement of Lemma 4.4).: _Let \(\{y_{t}^{\rm init}\}\) be the iterates produced by line 2 of Algorithm 2. Set \(\alpha_{\rm int}^{\rm init}=\mu\alpha^{2}=\widetilde{\mathcal{O}}(\epsilon^{4})\) with \(\alpha\) defined in (36), \(\sigma_{g,1}=(\mu\alpha)^{1/4}\tilde{\sigma}_{g,1}\), and \(\phi_{t}(y)\equiv g(x_{0},y)\). Then \(\|y_{T_{0}}^{\rm init}-y_{0}^{*}\|\leq\sqrt{\frac{t\alpha^{2}}{32}}\frac{ \epsilon}{L_{0}}\) holds with probability at least \(1-\delta\) over the randomness in \(\widetilde{\mathcal{F}}^{\rm init}\) (we denote this event as \(\mathcal{E}_{\rm init}\)) in \(T_{0}=\widetilde{O}(\epsilon^{-2})\) iterations, where_

\[T_{0}=\ln\left(\frac{\mu^{3}\alpha^{3}\epsilon^{2}}{256L_{0}^{2}\|y_{0}^{\rm init }-y_{0}^{*}\|^{2}}\right)\Big{/}\ln\left(1-\frac{\mu\alpha}{4}\right)= \widetilde{O}(\epsilon^{-2}).\] (38)

Proof of Lemma D.2.: By Lemmas C.6 and D.1 and \(\mu\)-strong convexity of \(g\) in \(y\), we have with probability at least \(1-\delta\) over the randomness in \(\mathcal{F}^{\rm init}\) that

\[\|y_{T_{0}}^{\rm init}-y_{0}^{*}\|^{2} \leq\frac{2}{\mu}\left(1-\frac{\sqrt{\mu^{2}\alpha^{2}}}{4} \right)^{T_{0}}U_{0}^{\rm init}+\frac{10\mu\alpha^{2}\tilde{\sigma}_{g,1}^{2}} {\mu}\ln\frac{eT_{0}}{\delta}\] \[\leq\frac{2}{\mu}\left(1-\frac{\mu\alpha}{4}\right)^{T_{0}}U_{0} ^{\rm init}+\frac{\mu\alpha\epsilon^{2}}{64L_{0}^{2}},\]

where the first inequality uses the choice of \(\alpha^{\rm init}=\mu\alpha^{2}\). By \(l_{g,1}\)-smoothness of \(g\) we have

\[U_{0}^{\rm init} \leq\frac{2-\sqrt{\mu^{2}\alpha^{2}}+\mu^{2}\alpha^{2}}{2\mu \alpha^{2}}\|y_{0}^{\rm init}-y_{0}^{*}\|^{2}+g(x_{0},y_{0}^{\rm init})-g(x_{0},y_{0}^{*})\] \[\leq\frac{3}{2\mu\alpha^{2}}\|y_{0}^{\rm init}-y_{0}^{*}\|^{2}+ \frac{l_{g,1}}{2}\|y_{0}^{\rm init}-y_{0}^{*}\|^{2}\leq\frac{2}{\mu\alpha^{2}} \|y_{0}^{\rm init}-y_{0}^{*}\|^{2},\]

where the last inequality uses \(\alpha\leq 1/l_{g,1}\). Now we set

\[\frac{2}{\mu}\left(1-\frac{\mu\alpha}{4}\right)^{T_{0}}\frac{2}{\mu\alpha^{2}} \|y_{0}^{\rm init}-y_{0}^{*}\|^{2}+\frac{\mu\alpha\epsilon^{2}}{64L_{0}^{2}} \leq\frac{\mu\alpha\epsilon^{2}}{32L_{0}^{2}},\]

which gives

\[T_{0}\geq\ln\left(\frac{\mu^{3}\alpha^{3}\epsilon^{2}}{256L_{0}^{2}\|y_{0}^{ \rm init}-y_{0}^{*}\|^{2}}\right)\Big{/}\ln\left(1-\frac{\mu\alpha}{4}\right).\]

By choice of \(\alpha\) as in (36) and simple calculation we obtain \(T_{0}=\widetilde{O}(\epsilon^{-2})\) when \(\epsilon\) is small. 

### Proof of Lemma 4.5

**Lemma D.3** (Option I, Restatement of Lemma 4.5).: _Under event \(\mathcal{E}_{\rm init}\), let \(\{y_{t}\}\) be the iterates produced by Option I. Set \(\alpha=\widetilde{\mathcal{O}}(\epsilon^{2})\) as in (36), \(\sigma_{g,1}=(\mu\alpha)^{1/4}\tilde{\sigma}_{g,1}\), and \(\phi_{t}(y)=g(x_{t},y)=\frac{\mu}{2}\|y-y_{t}^{*}\|^{2}\). Then for any \(t\in[T]\), Algorithm 2 guarantees with probability at least \(1-\delta\) over the randomness in \(\widetilde{\mathcal{F}}_{T}^{1}\) (we denote this event as \(\mathcal{E}_{y}^{1}\)) that \(\|y_{t}-y_{t}^{*}\|\leq\epsilon/2L_{0}\)._

Proof of Lemma d.3.: By Lemmas C.5 and D.2 we have

\[\|y_{t}-y_{t}^{*}\|^{2} \leq\frac{2}{\mu}\left(1-\frac{\sqrt{\mu\alpha}}{4}\right)^{t}U_ {0}+\left(\frac{10\alpha\tilde{\sigma}_{g,1}^{2}}{\mu}+\frac{160\eta^{2}l_{g,1 }^{2}}{\mu^{3}\alpha}\right)\ln\frac{eT}{\delta}\] \[\leq\frac{2}{\mu}\left(1-\frac{\sqrt{\mu\alpha}}{4}\right)^{t} \frac{2}{\alpha}\|y_{T_{0}}^{\rm init}-y_{0}^{*}\|^{2}+\left(\frac{10\alpha \tilde{\sigma}_{g,1}^{2}}{\mu}+\frac{160\eta^{2}l_{g,1}^{2}}{\mu^{3}\alpha} \right)\ln\frac{eT}{\delta}\] \[\leq\frac{4}{\mu\alpha}\|y_{T_{0}}^{\rm init}-y_{0}^{*}\|^{2}+ \frac{\epsilon^{2}}{64L_{0}^{2}}\leq\frac{\epsilon^{2}}{4L_{0}^{2}}.\]

Thus we conclude that for all \(t\in[T]\), we have \(\|y_{t}-y_{t}^{*}\|\leq\epsilon/2L_{0}\)

### Proof of Lemma 4.6

**Lemma D.4** (Option II, Restatement of Lemma 4.6).: _Under event \(\mathcal{E}_{\mathrm{init}}\), let \(\{y_{t}\}\) be the iterates produced by Option II. Set \(\alpha=\widetilde{\Theta}(\epsilon^{2})\) as in (36), \(\sigma_{g,1}=(\mu\alpha)^{1/4}\tilde{\sigma}_{g,1}\), and run SNAG in each update round for_

\[N=\ln\left(\frac{\mu\alpha}{128}\right)\Big{/}\ln\left(1-\frac{\sqrt{\mu \alpha}}{4}\right)=\widetilde{O}(\epsilon^{-1})\]

_steps in every \(I=\frac{\mu\epsilon}{2(1-\beta)L_{0}\tilde{\sigma}_{g,1}}=\widetilde{O}( \epsilon^{-1})\) iterations, set \(\phi_{t}(y)=g(x_{t},y)\) when \(t\) is a multiple of \(I\) (i.e., \(x_{t}\) is fixed for each update round of Option II so \(g\) can be general functions). Then for any \(t\in[T]\), Algorithm 2 guarantees with probability at least \(1-\delta\) over the randomness in \(\sigma(\cup_{t\leq T}\widetilde{\mathcal{F}}_{t}^{2})\) (we denote this event as \(\mathcal{E}_{y}^{2}\)) that \(\|y_{t}-y_{t}^{*}\|\leq\epsilon/L_{0}\)._

Proof of Lemma d.4.: At the beginning of the first round, by Lemmas D.2 and D.3 we have \(\|y_{0}-y_{0}^{*}\|\leq\epsilon/2L_{0}\), then we do not update the lower-level variable until \(t=I\)-th iteration, then for \(t=I\), we have

\[\|y_{I}-y_{I}^{*}\| =\|y_{0}-y_{I}^{*}\|\leq\|y_{0}-y_{0}^{*}\|+\sum_{i=1}^{I}\|y_{i} ^{*}-y_{i-1}^{*}\|\] \[\leq\frac{\epsilon}{2L_{0}}+\frac{\eta l_{g,1}}{\mu}I=\frac{ \epsilon}{L_{0}},\]

where in the last equality we plug in the definition of \(\eta\) and \(I\). By \(l_{g,1}\)-smoothness of \(g\) we have

\[U_{I} \leq\frac{2-2\sqrt{\mu\alpha}+\mu\alpha}{2\alpha}\|y_{I}-y_{0}^{* }\|^{2}+g(x_{I},y_{I})-g(x_{I},y_{I}^{*})\] \[\leq\frac{3}{2\alpha}\|y_{I}-y_{I}^{*}\|^{2}+\frac{l_{g,1}}{2}\| y_{I}-y_{I}^{*}\|^{2}\leq\frac{2\epsilon^{2}}{\alpha L_{0}^{2}}\]

Then for \(N\) steps update in the inner loops of \(t=I\)-th iteration, we set

\[\frac{2}{\mu}\left(1-\frac{\sqrt{\mu\alpha}}{4}\right)^{N}\frac{2\epsilon^{2 }}{\alpha L_{0}^{2}}+\frac{\epsilon^{2}}{64L_{0}^{2}}\leq\frac{\epsilon^{2}}{ 16L_{0}^{2}},\]

which gives

\[N\geq\ln\left(\frac{\mu\alpha}{128}\right)\Big{/}\ln\left(1-\frac{\sqrt{\mu \alpha}}{4}\right)\]

By choice of \(\alpha\) as in (36) and simple calculation we obtain \(N=\widetilde{O}(\epsilon^{-1})\) when \(\epsilon\) is small. Now we have

\[\|y_{I+1}-y_{I}^{*}\|^{2}=\|y_{I}^{N}-y_{I}^{*}\|^{2}\leq\frac{2}{\mu}\left(1- \frac{\sqrt{\mu\alpha}}{4}\right)^{N}\frac{2\epsilon^{2}}{\alpha L_{0}^{2}}+ \frac{\epsilon^{2}}{64L_{0}^{2}}\leq\frac{\epsilon^{2}}{16L_{0}^{2}},\]

which yields

\[\|y_{I+1}-y_{I+1}^{*}\|\leq\|y_{I+1}-y_{I}^{*}\|+\|y_{I}^{*}-y_{I+1}^{*}\|\leq \frac{\epsilon}{4L_{0}}+\frac{\eta l_{g,1}}{\mu}\leq\frac{\epsilon}{2L_{0}},\]

where we choose \(1-\beta\) to be small (see (56) for details) such that \(\eta\) is small enough to make above inequality holds. Repeating the same process yields the result. 

### Proof of Lemma 4.7

**Lemma D.5** (Averaging, Restatement of Lemma 4.7).: _Under Assumptions 3.1 to 3.4 and event \(\mathcal{E}_{\mathrm{init}}\cap\mathcal{E}_{y}^{1}\) (Option I) or \(\mathcal{E}_{\mathrm{init}}\cap\mathcal{E}_{y}^{2}\) (Option II), we further set \(\tau=\sqrt{\mu\alpha}\) in the averaging step (line 21 of Algorithm 2). Then for any \(t\geq 0\) we have_

\[\|\hat{y}_{t}-y_{t}^{*}\|\leq\frac{2\epsilon}{L_{0}}\quad\text{and}\quad\|\hat {y}_{t+1}-\hat{y}_{t}\|\leq\frac{\mu\epsilon^{2}}{24L_{0}^{2}\tilde{\sigma}_{g,1}}=:\vartheta.\]Proof of Lemma D.5.: We will first show the following result by induction, i.e., for any \(t\geq 0\), the averaged sequence \(\{\hat{y}_{t}\}\) satisfies

\[\|\hat{y}_{t}-y_{t}^{*}\|\leq\frac{(1-\tau)\eta l_{g,1}}{\tau\mu}+\frac{\epsilon }{L_{0}}.\] (39)

For \(t=0\), by Lemma D.2 we have

\[\|\hat{y}_{0}-y_{0}^{*}\|=\|y_{T_{0}}^{\mathrm{init}}-y_{0}^{*}\|\leq\sqrt{ \frac{\mu\alpha}{32}}\frac{\epsilon}{L_{0}}=\sqrt{\frac{1-\beta}{32}}\frac{ \epsilon}{L_{0}}\leq\frac{\epsilon}{L_{0}},\]

thus the base case holds. Now suppose (39) holds for some \(t\geq 0\), then for time step \(t+1\) we have

\[\|\hat{y}_{t+1}-y_{t+1}^{*}\| =\|(1-\tau)(\hat{y}_{t}-y_{t+1}^{*})+\tau(y_{t+1}-y_{t+1}^{*})\|\] \[=\|(1-\tau)(\hat{y}_{t}-y_{t}^{*})+(1-\tau)(y_{t}^{*}-y_{t+1}^{*} )+\tau(y_{t+1}-y_{t+1}^{*})\|\] \[\leq(1-\tau)\|\hat{y}_{t}-y_{t}^{*}\|+(1-\tau)\|y_{t}^{*}-y_{t+1}^ {*}\|+\tau\|y_{t+1}-y_{t+1}^{*}\|\] \[\leq(1-\tau)\left(\frac{(1-\tau)\eta l_{g,1}}{\tau\mu}+\frac{ \epsilon}{L_{0}}\right)+\frac{(1-\tau)\eta l_{g,1}}{\mu}+\frac{\tau\epsilon}{L _{0}}\] \[\leq\frac{(1-\tau)\eta l_{g,1}}{\tau\mu}+\frac{\epsilon}{L_{0}},\]

where we use induction hypothesis in the second inequality. Therefore, we have that (39) holds for any \(t\geq 0\). Also, as a consequence, for any \(t\geq 0\) we have

\[\|\hat{y}_{t+1}-\hat{y}_{t}\| =\|\tau(y_{t+1}-\hat{y}_{t})\|\] \[\leq\tau\|y_{t+1}-y_{t+1}^{*}\|+\tau\|y_{t+1}^{*}-y_{t}^{*}\|+ \tau\|y_{t}^{*}-\hat{y}_{t}\|\] \[\leq\tau\left(\frac{\epsilon}{L_{0}}+\frac{\eta l_{g,1}}{\mu}+ \frac{(1-\tau)\eta l_{g,1}}{\tau\mu}+\frac{\epsilon}{L_{0}}\right)\] \[=\tau\left(\frac{\eta l_{g,1}}{\tau\mu}+\frac{2\epsilon}{L_{0}} \right).\]

Now we plug in the definition of \(\alpha,\beta,\tau,\eta\) as in (36) to obtain

\[\|\hat{y}_{t}-y_{t}^{*}\|\leq\frac{(1-\tau)\eta l_{g,1}}{\tau\mu}+\frac{ \epsilon}{L_{0}}=\frac{\tilde{\sigma}_{g,1}}{\mu}\sqrt{1-\beta}+\frac{\epsilon }{L_{0}}\leq\frac{2\epsilon}{L_{0}}\]

and

\[\|\hat{y}_{t+1}-\hat{y}_{t}\|\leq\tau\left(\frac{\eta l_{g,1}}{\tau\mu}+\frac{ 2\epsilon}{L_{0}}\right)\leq\frac{\mu\epsilon^{2}}{24L_{0}^{2}\tilde{\sigma}_ {g,1}}.\]

### Proof of Lemma 4.8

**Lemma D.6** (Restatement of Lemma 4.8).: _Under Assumptions 3.1 to 3.4 and event \(\mathcal{E}_{\mathrm{init}}\cap\mathcal{E}_{y}^{1}\) (Option I) or \(\mathcal{E}_{\mathrm{init}}\cap\mathcal{E}_{y}^{2}\) (Option II), define \(\epsilon_{t}=m_{t}-\mathbb{E}_{t}[\bar{\nabla}f(x_{t},\hat{y}_{t};\bar{\xi}_{t})]\), then we have the following averaged cumulative error bound:_

\[\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}\|\epsilon_{t}\|\leq\frac{\bar{\sigma}}{T (1-\beta)}+\sqrt{1-\bar{\beta}}\bar{\sigma}+\frac{\bar{L}_{0}}{\sqrt{1-\bar{ \beta}}}\sqrt{\frac{2(\eta^{2}+\bar{\vartheta}^{2})}{S}}+\bar{L}_{1}\sqrt{ \frac{2(\eta^{2}+\bar{\vartheta}^{2})}{S(1-\beta)}}\frac{1}{T}\sum_{t=0}^{T-1} \mathbb{E}\|\nabla\Phi(x_{t})\|.\]

Proof of Lemma D.6.: Define \(\epsilon_{t}=m_{t}-\mathbb{E}_{t}[\bar{\nabla}f(x_{t},\hat{y}_{t};\bar{\xi}_{t })]\), also define \(\tilde{\epsilon}_{t}\) and \(\hat{\epsilon}_{t}\) as

\[\tilde{\epsilon}_{t} =\bar{\nabla}f(x_{t},\hat{y}_{t};\bar{\xi}_{t})-\mathbb{E}_{t}[ \bar{\nabla}f(x_{t},\hat{y}_{t};\bar{\xi}_{t})],\] \[\hat{\epsilon}_{t} =\bar{\nabla}f(x_{t},\hat{y}_{t};\bar{\xi}_{t})-\bar{\nabla}f(x_{ t-1},\hat{y}_{t-1};\bar{\xi}_{t})-\mathbb{E}_{t}[\bar{\nabla}f(x_{t},\hat{y}_{t}; \bar{\xi}_{t})]+\mathbb{E}_{t}[\bar{\nabla}f(x_{t-1},\hat{y}_{t-1};\bar{\xi}_{t })].\]

By definition of \(\epsilon_{t}\), \(\tilde{\epsilon}_{t}\) and \(\hat{\epsilon}_{t}\), we have the following recursion for any \(t\geq 0\):

\[\epsilon_{t+1}=\beta\epsilon_{t}+(1-\beta)\hat{\epsilon}_{t+1}+\beta\tilde{ \epsilon}_{t+1}.\] (40)Then we apply (40) recursively to obtain

\[\epsilon_{t}=\beta^{t}\epsilon_{0}+\beta\sum_{i=1}^{t}\beta^{t-i}\hat{\epsilon}_ {i}+(1-\beta)\sum_{i=1}^{t}\beta^{t-i}\hat{\epsilon}_{i},\]

which by triangle inequality and total expectation gives

\[\mathbb{E}\|\epsilon_{t}\|=\beta^{t}\underbrace{\mathbb{E}\|\epsilon_{0}\|}_{ Err_{1}}+(1-\beta)\underbrace{\mathbb{E}\left\|\sum_{i=1}^{t}\beta^{t-i}\hat{ \epsilon}_{i}\right\|}_{Err_{2}}+\beta\,\mathbb{E}\left\|\sum_{i=1}^{t}\beta^ {t-i}\hat{\epsilon}_{i}\right\|}_{Err_{3}}.\] (41)

Bounding \(Err_{1}\).By definition of \(\epsilon_{0}\) and Lemma B.4, along with Jensen's inequality, we have

\[\mathbb{E}\|\epsilon_{0}\|\leq\sqrt{\mathbb{E}\|\epsilon_{0}\|^{2}}\leq\bar{ \sigma}.\] (42)

Bounding \(Err_{2}\).We apply Lemma B.4 and follow the similar procedure as in [38, Lemma D.9] to obtain

\[\mathbb{E}\left\|\sum_{i=1}^{t}\beta^{t-i}\hat{\epsilon}_{i}\right\|\leq\sqrt {\mathbb{E}\left\|\sum_{i=1}^{t}\beta^{t-i}\hat{\epsilon}_{i}\right\|^{2}} \leq\sqrt{\sum_{i=1}^{t}\beta^{2(t-i)}\mathbb{E}\|\hat{\epsilon}_{i}\|^{2}} \leq\frac{\bar{\sigma}}{\sqrt{1-\beta}},\] (43)

where we use Jensen's inequality for the first step.

Bounding \(Err_{3}\).We will first use induction to show that for \(0\leq i\leq t+1\), the following inequality holds:

\[\mathbb{E}\left[\left\|\sum_{j=1}^{t}\beta^{t-j}\hat{\epsilon}_{j}\right\| \right]\leq\sqrt{\frac{2(\eta^{2}+\vartheta^{2})}{S}}\bar{L}_{1}\sum_{j=t+1-i }^{t}\beta^{t-j}\mathbb{E}\|\nabla\Phi(x_{j})\|+\mathbb{E}\left[\sqrt{\frac{2( \eta^{2}+\vartheta^{2})}{S}\bar{L}_{0}^{2}}\sum_{j=1}^{i}\beta^{2j-2}+\left\| \sum_{j=1}^{t-i}\beta^{t-j}\hat{\epsilon}_{j}\right\|^{2}\right].\] (44)

Then it's easy to check that by setting \(i=t+1\) we can obtain the bound. When \(i=0\), (44) holds obviously since

\[\mathbb{E}\left[\left\|\sum_{j=1}^{t}\beta^{t-j}\hat{\epsilon}_{j}\right\| \right]\leq\mathbb{E}\left[\sqrt{\left\|\sum_{j=1}^{t}\beta^{t-j}\hat{ \epsilon}_{j}\right\|^{2}}\right]=\mathbb{E}\left[\left\|\sum_{j=1}^{t}\beta ^{t-j}\hat{\epsilon}_{j}\right\|\right].\]Hence the base case stands. Now suppose (44) holds for some \(i\geq 0\), and we aim to show that (44) holds for \(i+1\). In fact, we have

\[\mathbb{E}\left[\sqrt{\frac{2(\eta^{2}+\vartheta^{2})\bar{L}_{0}^{2 }}{S}\sum_{j=1}^{i}\beta^{2j-2}+\left\|\sum_{j=1}^{t-i}\beta^{t-j}\hat{\epsilon }_{j}\right\|^{2}}\right]\] (45) \[=\mathbb{E}_{\mathcal{F}_{t-i-1}}\left[\mathbb{E}_{t-i-1}\left[ \sqrt{\frac{2(\eta^{2}+\vartheta^{2})\bar{L}_{0}^{2}}{S}\sum_{j=1}^{i}\beta^{2 j-2}+\left\|\sum_{j=1}^{t-i}\beta^{t-j}\hat{\epsilon}_{j}\right\|^{2}} \right]\right]\] (46) \[\leq\mathbb{E}_{\mathcal{F}_{t-i-1}}\left[\mathbb{E}_{t-i-1} \sqrt{\left[\frac{2(\eta^{2}+\vartheta^{2})\bar{L}_{0}^{2}}{S}\sum_{j=1}^{i} \beta^{2j-2}+\left\|\sum_{j=1}^{t-i}\beta^{t-j}\hat{\epsilon}_{j}\right\|^{2} }\right]\right]\] (47) \[=\mathbb{E}_{\mathcal{F}_{t-i-1}}\left[\mathbb{E}_{t-i-1}\sqrt{ \left[\frac{2(\eta^{2}+\vartheta^{2})\bar{L}_{0}^{2}}{S}\sum_{j=1}^{i}\beta^{2 j-2}+\beta^{2i}\|\hat{\epsilon}_{t-i}\|^{2}+\left\|\sum_{j=1}^{t-i-1}\beta^{t-j} \hat{\epsilon}_{j}\right\|^{2}}\right]\right]\] (48) \[\leq\mathbb{E}_{\mathcal{F}_{t-i-1}}\left[\mathbb{E}_{t-i-1} \sqrt{\left[\frac{2(\eta^{2}+\vartheta^{2})\bar{L}_{0}^{2}}{S}\sum_{j=1}^{i} \beta^{2j-2}+\frac{\beta^{2i}}{S}2(\bar{L}_{0}^{2}+\bar{L}_{1}^{2}\|\nabla \Phi(x_{t-i})\|^{2})(\eta^{2}+\vartheta^{2})+\left\|\sum_{j=1}^{t-i-1}\beta^{t -j}\hat{\epsilon}_{j}\right\|^{2}}\right]\right]\] (49) \[=\mathbb{E}_{\mathcal{F}_{t-i-1}}\left[\sqrt{\frac{2\beta^{2i}}{S }\bar{L}_{1}^{2}(\eta^{2}+\vartheta^{2})\|\nabla\Phi(x_{t-i})\|^{2}+\frac{2( \eta^{2}+\vartheta^{2})\bar{L}_{0}^{2}}{S}\sum_{j=1}^{i+1}\beta^{2j-2}+\left\| \sum_{j=1}^{t-i-1}\beta^{t-j}\hat{\epsilon}_{j}\right\|^{2}}\right]\] (50) \[\leq\mathbb{E}_{\mathcal{F}_{t-i-1}}\left[\sqrt{\frac{2(\eta^{2} +\vartheta^{2})}{S}}\beta^{i}\bar{L}_{1}\|\nabla\Phi(x_{t-i})\|+\sqrt{\frac{2 (\eta^{2}+\vartheta^{2})\bar{L}_{0}^{2}}{S}\sum_{j=1}^{i+1}\beta^{2j-2}+\left\| \sum_{j=1}^{t-i-1}\beta^{t-j}\hat{\epsilon}_{j}\right\|^{2}}\right],\] (51)

where (46) follows by law of total expectation, (47) follows by Jensen's inequality, (48) uses the fact that \(\hat{\epsilon}_{j}\) for \(j<t-i\) are \(\mathcal{F}_{t-i-1}\)-measurable, and are uncorrelated with \(\hat{\epsilon}_{t-i}\); for (49) we use Lemmas B.6 and D.5 to derive

\[\mathbb{E}_{t-i-1}[\|\hat{\epsilon}_{t-i}\|^{2}] =\mathbb{E}_{t-i-1}\left[\|\bar{\nabla}f(x_{t-i},\hat{y}_{t-i}; \bar{\xi}_{t-i})-\bar{\nabla}f(x_{t-i-1},\hat{y}_{t-i-1};\bar{\xi}_{t-i})\right.\] \[\quad\left.-\mathbb{E}_{t-i}[\bar{\nabla}f(x_{t-i},\hat{y}_{t-i}; \bar{\xi}_{t-i})]+\mathbb{E}_{t-i}[\bar{\nabla}f(x_{t-i-1},\hat{y}_{t-i-1};\bar {\xi}_{t-i})]\|^{2}\right]\] \[\leq\mathbb{E}_{t-i-1}\left[\|\bar{\nabla}f(x_{t-i},\hat{y}_{t-i}; \bar{\xi}_{t-i})-\bar{\nabla}f(x_{t-i-1},\hat{y}_{t-i-1};\bar{\xi}_{t-i})\|^{2}\right]\] \[\leq 2\mathbb{E}_{t-i-1}\left[\|\bar{\nabla}f(x_{t-i},\hat{y}_{t-i}; \bar{\xi}_{t-i})-\bar{\nabla}f(x_{t-i},\hat{y}_{t-i-1};\bar{\xi}_{t-i})\|^{2}\right]\] \[\quad+2\mathbb{E}_{t-i-1}\left[\|\bar{\nabla}f(x_{t-i},\hat{y}_{t- i-1};\bar{\xi}_{t-i})-\bar{\nabla}f(x_{t-i-1},\hat{y}_{t-i-1};\bar{\xi}_{t-i})\|^{2}\right]\] \[\leq\frac{2}{S}(\bar{L}_{0}^{2}+\bar{L}_{1}^{2}\|\nabla\Phi(x_{t-i })\|^{2})(\|\hat{y}_{t-i}-\hat{y}_{t-i-1}\|^{2}+\|x_{t-i}-x_{t-i-1}\|^{2})\] \[=\frac{2}{S}(\bar{L}_{0}^{2}+\bar{L}_{1}^{2}\|\nabla\Phi(x_{t-i}) \|^{2})(\eta^{2}+\vartheta^{2}).\]

And (50) follows from the fact that \(x_{t-i}\) is \(\mathcal{F}_{t-i-1}\)-measurable, (51) uses \(\sqrt{a+b}\leq\sqrt{a}+\sqrt{b}\) for \(a,b\geq 0\). Hence the induction proof is completed. We set \(i=t+1\) to obtain

\[\mathbb{E}\left[\left\|\sum_{i=1}^{t}\beta^{t-i}\hat{\epsilon}_{t} \right\|\right] \leq\sqrt{\frac{2(\eta^{2}+\vartheta^{2})}{S}}\bar{L}_{1}\sum_{i=0} ^{t}\beta^{t-i}\mathbb{E}\|\nabla\Phi(x_{i})\|+\sqrt{\frac{2(\eta^{2}+\vartheta^{2 })\bar{L}_{0}^{2}}{S}\sum_{i=0}^{t}\beta^{2i}}\] (52) \[\leq\sqrt{\frac{2(\eta^{2}+\vartheta^{2})}{S}}\bar{L}_{1}\sum_{i=0} ^{t}\beta^{t-i}\mathbb{E}\|\nabla\Phi(x_{i})\|+\frac{\bar{L}_{0}}{\sqrt{1- \beta}}\sqrt{\frac{2(\eta^{2}+\vartheta^{2})}{S}}.\]

Final Bound.Combining (42), (43) and (52) yields

\[\mathbb{E}\|\epsilon_{t}\|\leq\beta^{t}\bar{\sigma}+\sqrt{1-\beta}\bar{\sigma}+ \frac{\bar{L}_{0}}{\sqrt{1-\beta}}\sqrt{\frac{2(\eta^{2}+\vartheta^{2})}{S}}+\sqrt {\frac{2(\eta^{2}+\vartheta^{2})}{S}}\bar{L}_{1}\sum_{i=0}^{t}\beta^{t-i} \mathbb{E}\|\nabla\Phi(x_{i})\|.\]Taking summation and dividing \(1/T\) on both sides gives the final result

\[\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}\|\epsilon_{t}\|\leq\frac{\bar{\sigma}}{T(1 -\beta)}+\sqrt{1-\beta}\bar{\sigma}+\frac{\bar{L}_{0}}{\sqrt{1-\bar{\beta}}} \sqrt{\frac{2(\eta^{2}+\vartheta^{2})}{S}}+\bar{L}_{1}\sqrt{\frac{2(\eta^{2}+ \vartheta^{2})}{S(1-\beta)}}\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}\|\nabla\Phi( x_{t})\|.\]

## Appendix E Proof of Theorem 4.1

Before starting the proof of main results, i.e., Theorem 4.1, we first need the following lemma.

**Lemma E.1**.: _Suppose that Assumptions 3.1 to 3.4 hold. For any \(\eta\) satisfying_

\[\eta\leq\frac{1}{\sqrt{2(1+l_{g,1}^{2}/\mu^{2})(L_{x,1}^{2}+L_{y,1}^{2})}},\]

_it holds that_

\[\left(1-\frac{1}{2}\eta L_{1}-2L_{1}\|\hat{y}_{t}-y_{t}^{*}\|\right) \frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}\|\nabla\Phi(x_{t})\|\] \[\leq\frac{\Phi(x_{0})-\Phi(x_{T})}{T\eta}+\frac{2}{T}\sum_{t=0}^{ T-1}\mathbb{E}\|\epsilon_{t}\|+\frac{2l_{g,1}l_{f,0}}{\mu}\left(1-\frac{\mu}{l_{g,1 }}\right)^{Q}+\frac{2L_{0}}{T}\sum_{t=0}^{T-1}\|\hat{y}_{t}-y_{t}^{*}\|+\frac{ 1}{2}\eta L_{0}.\]

Proof of Lemma E.1.: Define \(h_{t}=m_{t}-\nabla\Phi(x_{t})\). Then we apply Lemma B.3 to obtain

\[\Phi(x_{t+1}) \leq\Phi(x_{t})+\langle\nabla\Phi(x_{t}),x_{t+1}-x_{t}\rangle+ \frac{L_{0}+L_{1}\|\nabla\Phi(x_{t})\|}{2}\|x_{t+1}-x_{t}\|^{2}\] (53) \[=\Phi(x_{t})-\eta\langle\nabla\Phi(x_{t}),\frac{m_{t}}{\|m_{t}\| }\rangle+\frac{1}{2}\eta^{2}(L_{0}+L_{1}\|\nabla\Phi(x_{t})\|)\] \[=\Phi(x_{t})-\eta\langle m_{t}-h_{t},\frac{m_{t}}{\|m_{t}\|} \rangle+\frac{1}{2}\eta^{2}(L_{0}+L_{1}\|\nabla\Phi(x_{t})\|)\] \[=\Phi(x_{t})-\eta\|m_{t}\|+\eta\langle h_{t},\frac{m_{t}}{\|m_{t} \|}\rangle+\frac{1}{2}\eta^{2}(L_{0}+L_{1}\|\nabla\Phi(x_{t})\|)\] \[\leq\Phi(x_{t})-\eta\|m_{t}\|+\eta\|h_{t}\|+\frac{1}{2}\eta^{2}(L _{0}+L_{1}\|\nabla\Phi(x_{t})\|)\] \[\leq\Phi(x_{t})-\eta\|\nabla\Phi(x_{t})\|+2\eta\|h_{t}\|+\frac{1}{ 2}\eta^{2}(L_{0}+L_{1}\|\nabla\Phi(x_{t})\|),\]

where for the last two lines we use Cauchy-Schwarz inequality and \(\|h_{t}\|=\|\nabla\Phi(x_{t})+h_{t}\|\geq\|\nabla\Phi(x_{t})\|-\|h_{t}\|\). Now expanding \(h_{t}\) by triangle inequality, we have

\[\|h_{t}\| =\|m_{t}-\nabla\Phi(x_{t})\|\] \[\leq\|m_{t}-\mathbb{E}_{t}[\bar{\nabla}f(x_{t},\hat{y}_{t};\bar{ \xi}_{t})]\|+\|\mathbb{E}_{t}[\bar{\nabla}f(x_{t},\hat{y}_{t};\bar{\xi}_{t})]- \bar{\nabla}f(x_{t},\hat{y}_{t})\|+\|\bar{\nabla}f(x_{t},\hat{y}_{t})-\nabla \Phi(x_{t})\|\] \[\leq\|\epsilon_{t}\|+\frac{l_{g,1}l_{f,0}}{\mu}\left(1-\frac{\mu} {l_{g,1}}\right)^{Q}+(L_{0}+L_{1}\|\nabla\Phi(x_{t})\|)\|\hat{y}_{t}-y_{t}^{*} \|,\]

where we use definition of \(\epsilon_{t}\), Lemmas B.4 and B.5 in the last inequality. Plugging the above inequality back into (53) we obtain

\[\Phi(x_{t+1}) \leq\Phi(x_{t})-\eta\|\nabla\Phi(x_{t})\|+2\eta\|\epsilon_{t}\|+ 2\eta\frac{l_{g,1}l_{f,0}}{\mu}\left(1-\frac{\mu}{l_{g,1}}\right)^{Q}\] \[\quad+2\eta(L_{0}+L_{1}\|\nabla\Phi(x_{t})\|)\|\hat{y}_{t}-y_{t}^{* }\|+\frac{1}{2}\eta^{2}(L_{0}+L_{1}\|\nabla\Phi(x_{t})\|)\] \[=\Phi(x_{t})-\left(\eta-\frac{1}{2}\eta^{2}L_{1}-2\eta L_{1}\| \hat{y}_{t}-y_{t}^{*}\|\right)\|\nabla\Phi(x_{t})\|+2\eta\|\epsilon_{t}\|\] \[\quad+2\eta\frac{l_{g,1}l_{f,0}}{\mu}\left(1-\frac{\mu}{l_{g,1}} \right)^{Q}+2\eta L_{0}\|\hat{y}_{t}-y_{t}^{*}\|+\frac{1}{2}\eta^{2}L_{0}.\]Dividing \(1/T\eta\) on both sides, then taking telescope sum and total expectation, and rearranging it finally yields

\[\left(1-\frac{1}{2}\eta L_{1}-2L_{1}\|\hat{y}_{t}-y_{t}^{*}\|\right) \frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}\|\nabla\Phi(x_{t})\|\] \[\leq\frac{\Phi(x_{0})-\Phi(x_{T})}{T\eta}+\frac{2}{T}\sum_{t=0}^{ T-1}\mathbb{E}\|\epsilon_{t}\|+\frac{2l_{g,1}l_{f,0}}{\mu}\left(1-\frac{\mu}{l_{g,1}} \right)^{Q}+\frac{2L_{0}}{T}\sum_{t=0}^{T-1}\|\hat{y}_{t}-y_{t}^{*}\|+\frac{1} {2}\eta L_{0}.\]

**Theorem E.2** (Restatement of Theorem 4.1).: _Suppose Assumptions 3.1 to 3.4 hold. Let \(\{x_{t}\}\) be the iterates produced by Algorithm 2. For any given \(\delta\in(0,1)\) and any small \(\epsilon>0\) satisfying_

\[\epsilon\leq\min\left\{\frac{L_{0}}{32L_{1}},\frac{l_{g,1}L_{0}}{\mu\bar{L}_ {1}},\frac{L_{0}}{8\bar{L}_{1}},\frac{L_{0}l_{g,1}\tilde{\sigma}_{g,1}}{\mu^ {2}},\frac{L_{0}}{\mu}\sqrt{\frac{l_{g,1}\tilde{\sigma}_{g,1}}{L_{1}}},\left( \frac{164\cdot 32ed_{0}L_{0}^{2}\tilde{\sigma}_{g,1}^{2}}{\delta\mu^{2}} \max\left\{\frac{l_{g,1}}{\tilde{\sigma}_{g,1}},\frac{\bar{\sigma}}{d_{0}} \right\}\right)^{1/3}\right\},\] (54)

_if \(\sigma_{g,1}\) satisfies_

\[\sigma_{g,1}=\left(\min\left\{\frac{\mu^{2}\epsilon^{2}}{164\cdot 16L_{0}^{2} \tilde{\sigma}_{g,1}^{2}\ln(P)},\frac{l_{g,1}}{4\tilde{\sigma}_{g,1}L_{1}}, \frac{\epsilon^{2}}{4\bar{\sigma}^{2}}\right\}\right)^{1/4}\tilde{\sigma}_{g,1}\] (55)

_with \(\tilde{\sigma}_{g,1}=O(1)\), and we set parameters \(\alpha,\alpha^{\rm init},\beta,\gamma,\eta,\tau,I,N,S,Q,T_{0}\) as_

\[1-\beta=\min\left\{\frac{\mu^{2}\epsilon^{2}}{164\cdot 16L_{0}^{2} \tilde{\sigma}_{g,1}^{2}\ln(P)},\frac{l_{g,1}}{4\tilde{\sigma}_{g,1}L_{1}}, \frac{\epsilon^{2}}{4\bar{\sigma}^{2}}\right\},\quad\eta=\min\left\{\frac{ \tilde{\sigma}_{g,1}}{l_{g,1}},\frac{d_{0}}{\bar{\sigma}}\right\}(1-\beta),\] (56) \[\alpha^{\rm init}=\frac{1-\beta}{\mu+l_{g,1}}\quad\alpha=\frac{1- \beta}{\mu},\quad\gamma=\frac{1-\sqrt{\mu\alpha}}{1+\sqrt{\mu\alpha}},\quad \tau=1-\sqrt{\mu\alpha},\] (57) \[T_{0}=\ln\left(\frac{\mu^{3}\alpha^{3}\epsilon^{2}}{256L_{0}^{2 }\|y_{0}^{\rm init}-y_{0}^{*}\|^{2}}\right)\Big{/}\ln\left(1-\frac{\mu\alpha}{ 4}\right),\] (58) \[I=\frac{\mu\epsilon}{2(1-\beta)L_{0}\tilde{\sigma}_{g,1}},\quad N =\ln\left(\frac{\mu\alpha}{128}\right)\Big{/}\ln\left(1-\frac{\sqrt{\mu \alpha}}{4}\right),\] (59) \[S=\max\left\{128\ln(P),\frac{128\bar{L}_{0}^{2}}{L_{0}^{2}}\ln(P),\frac{\mu^{2}\bar{L}_{0}^{2}}{l_{g,1}^{2}L_{0}^{2}}\right\},\quad Q=\ln\left( 1-\frac{\mu}{l_{g,1}}\right)\Big{/}\ln\left(\frac{\mu\epsilon}{l_{g,1}l_{f,0}} \right),\] (60)

_where \(d_{0}\) and \(P\) are defined in (37). Then with probability at least \(1-2\delta\) over the randomness in \(\sigma(\mathcal{F}^{\rm init}\cup\tilde{\mathcal{F}}_{1}^{T})\) (for Option I) or \(\sigma(\mathcal{F}^{\rm init}\cup(\cup_{t\leq T}\mathcal{\bar{F}}_{1}^{T}))\) (for Option II), Algorithm 2 guarantees \(\frac{1}{T}\sum_{t=1}^{T}\mathbb{E}\|\nabla\Phi(x_{t})\|\leq 20\epsilon\) within \(T=\frac{4d_{0}}{\eta\epsilon}=O(1/\epsilon^{3})\) iterations, where the expectation is taken over the randomness in \(\mathcal{F}_{T}\). For Option I, it requires \(T_{0}+SQT=\widetilde{O}(1/\epsilon^{3})\) oracle calls of stochastic gradient or Hessian/Jacobian vector product. For Option II, it requires \(T_{0}+SQT=\widetilde{O}(1/\epsilon^{3})\) oracle calls of stochastic gradient or Hessian/Jacobian vector product._

Proof of Theorem E.2.: By Lemmas D.6 and E.1, we have

\[\left(1-\frac{1}{2}\eta L_{1}-2L_{1}\|\hat{y}_{t}-y_{t}^{*}\|\right) \frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}\|\nabla\Phi(x_{t})\|\] \[\leq\frac{\Phi(x_{0})-\Phi(x_{T})}{T\eta}+\frac{2}{T}\sum_{t=0}^{ T-1}\mathbb{E}\|\epsilon_{t}\|+\frac{2l_{g,1}l_{f,0}}{\mu}\left(1-\frac{\mu}{l_{g,1}} \right)^{Q}+\frac{2L_{0}}{T}\sum_{t=0}^{T-1}\|\hat{y}_{t}-y_{t}^{*}\|+\frac{1}{2} \eta L_{0}\] \[\leq\frac{d_{0}}{T\eta}+\frac{2l_{g,1}l_{f,0}}{\mu}\left(1-\frac{ \mu}{l_{g,1}}\right)^{Q}+\frac{2L_{0}}{T}\sum_{t=0}^{T-1}\|\hat{y}_{t}-y_{t}^{*} \|+\frac{1}{2}\eta L_{0}\] \[\quad+\frac{2\bar{\sigma}}{T(1-\beta)}+2\sqrt{1-\beta}\bar{\sigma}+ \frac{2\bar{L}_{0}}{\sqrt{1-\beta}}\sqrt{\frac{2(\eta^{2}+\bar{\sigma}^{2})}{S} }+2\bar{L}_{1}\sqrt{\frac{2(\eta^{2}+\bar{\sigma}^{2})}{S(1-\beta)}}\frac{1}{T} \sum_{t=0}^{T-1}\mathbb{E}\|\nabla\Phi(x_{t})\|.\]Rearranging the above inequality gives

\[\underbrace{\left(1-\frac{1}{2}\eta L_{1}-2L_{1}\|\hat{y}_{t}-y_{t}^{*} \|-2\bar{L}_{1}\sqrt{\frac{2(\eta^{2}+\vartheta^{2})}{S(1-\beta)}}\right)}_{ \text{(LHS)}}\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}\|\nabla\Phi(x_{t})\|\] \[\leq\underbrace{\frac{d_{0}}{T\eta}+\frac{2l_{g,1}l_{f,0}}{\mu} \left(1-\frac{\mu}{l_{g,1}}\right)^{Q}+\frac{2L_{0}}{T}\sum_{t=0}^{T-1}\|\hat{y }_{t}-y_{t}^{*}\|+\frac{1}{2}\eta L_{0}+\frac{2\bar{\sigma}}{T(1-\beta)}+2\sqrt {1-\beta}\bar{\sigma}+\frac{2\bar{L}_{0}}{\sqrt{1-\beta}}\sqrt{\frac{2(\eta^{2 }+\vartheta^{2})}{S}}\,.\]

Bounding (LHS).By Lemma D.5, we have

\[\begin{split}\mathrm{(LHS)}&\geq 1-\frac{\bar{ \sigma}_{g,1}L_{1}}{2l_{g,1}}(1-\beta)-2L_{1}\frac{2\epsilon}{L_{0}}-2\bar{L}_{ 1}\sqrt{\frac{2(\eta^{2}+\vartheta^{2})}{S(1-\beta)}}\\ &\geq 1-\frac{1}{8}-\frac{1}{8}-\frac{1}{4}=\frac{1}{2}\end{split}\] (61)

Bounding (RHS).By choice of parameters, we have

\[\begin{split}\mathrm{(RHS)}&\leq\frac{1}{4} \epsilon+2\epsilon+4\epsilon+\epsilon+\frac{1}{2}\epsilon+\epsilon+\epsilon \leq 10\epsilon.\end{split}\] (62)

Combining (61) and (62) finally yields

\[\frac{1}{T}\sum_{t=0}^{T-1}\mathbb{E}\|\nabla\Phi(x_{t})\|\leq 20\epsilon.\]

## Appendix F Omitted Proofs in Appendix B

### Proof of Lemma b.5

**Lemma F.1** (Restatement of Lemma b.5).: _Under Assumptions 3.1 to 3.4, we have_

\[\|\bar{\nabla}f(x,y)-\nabla\Phi(x)\|\leq(\bar{L}+L_{x,1}\|\nabla\Phi(x)\|)\|y- y^{*}(x)\|,\]

_where constant \(\bar{L}\) is defined as_

\[\bar{L}\coloneqq L_{x,0}+L_{x,1}\frac{l_{g,1}l_{f,0}}{\mu}+\frac{l_{g,1}}{\mu} (L_{y,0}+L_{y,1}l_{f,0})+l_{f,0}\frac{\mu l_{g,2}+l_{g,1}l_{g,2}}{\mu^{2}}\leq L _{0}.\]

Proof of Lemma b.5.: Recall that the exact expressions of \(\bar{\nabla}f(x,y)\) and \(\nabla\Phi(x)\) are

\[\bar{\nabla}f(x,y)=\nabla_{x}f(x,y)-\nabla_{xy}^{2}g(x,y)[\nabla_{yy}^{2}g(x, y)]^{-1}\nabla_{y}f(x,y)\]

and

\[\nabla\Phi(x)=\nabla_{x}f(x,y^{*}(x))-\nabla_{xy}^{2}g(x,y^{*}(x))[\nabla_{yy}^ {2}g(x,y^{*}(x))]^{-1}\nabla_{y}f(x,y^{*}(x)).\]

Then by Assumption 3.2 we have

\[\|\nabla f(x,y)-\nabla\Phi(x)\|\leq\|\nabla_{x}f(x,y)-\nabla_{x}f (x,y^{*}(x))\|\] \[\quad+\|\nabla_{xy}^{2}g(x,y)[\nabla_{yy}^{2}g(x,y)]^{-1}\nabla_{y }f(x,y)-\nabla_{xy}^{2}g(x,y^{*}(x))[\nabla_{yy}^{2}g(x,y^{*}(x))]^{-1}\nabla _{y}f(x,y^{*}(x))\|\] \[\leq(L_{x,0}+L_{x,1}\|\nabla_{x}f(x,y^{*}(x))\|)\|y-y^{*}(x)\|\] \[\quad+\|\nabla_{xy}^{2}g(x,y)[\nabla_{yy}^{2}g(x,y)]^{-1}\nabla_{ y}f(x,y)-\nabla_{xy}^{2}g(x,y^{*}(x))[\nabla_{yy}^{2}g(x,y)]^{-1}\nabla_{y}f(x,y)\|\] \[\quad+\|\nabla_{xy}^{2}g(x,y^{*}(x))[\nabla_{yy}^{2}g(x,y)]^{-1} \nabla_{y}f(x,y)-\nabla_{xy}^{2}g(x,y^{*}(x))[\nabla_{yy}^{2}g(x,y^{*}(x))]^{- 1}\nabla_{y}f(x,y)\|\] \[\quad+\|\nabla_{xy}^{2}g(x,y^{*}(x))[\nabla_{yy}^{2}g(x,y^{*}(x) )]^{-1}\nabla_{y}f(x,y)-\nabla_{xy}^{2}g(x,y^{*}(x))[\nabla_{yy}^{2}g(x,y^{*}(x ))]^{-1}\nabla_{y}f(x,y^{*}(x))\|\]\[\leq\left(L_{x,0}+L_{x,1}\left(\frac{l_{g,1}l_{f,0}}{\mu}+\|\nabla \Phi(x)\|\right)\right)\|y-y^{*}(x)\|\] \[\quad+\frac{l_{f,0}}{\mu}l_{g,2}\|y-y^{*}(x)\|+\frac{l_{f,0}l_{g,1 }}{\mu^{2}}l_{g,2}\|y-y^{*}(x)\|+\frac{l_{g,1}}{\mu}(L_{y,0}+L_{y,1}\|\nabla_{y }f(x,y^{*}(x))\|)\|y-y^{*}(x)\|\] \[=\left(L_{x,0}+L_{x,1}\frac{l_{g,1}l_{f,0}}{\mu}+\frac{l_{g,1}}{ \mu}(L_{y,0}+L_{y,1}l_{f,0})+l_{f,0}\frac{\mu l_{g,2}+l_{g,1}l_{g,2}}{\mu^{2}}+ L_{x,1}\|\nabla\Phi(x)\|\right)\|y-y^{*}(x)\|.\]

By definition of \(\bar{L}\) we conclude the proof. 

### Proof of Lemma b.6

**Lemma F.2** (Restatement of Lemma b.6).: _Under Assumptions 3.1 to 3.4, we have_

1. _For any fixed_ \(y\in\mathbb{R}^{d_{y}}\) _and any_ \(x_{1},x_{2}\in\mathbb{R}^{d_{x}}\)_,_ \[\mathbb{E}_{\bar{\xi}}\|\bar{\nabla}f(x_{1},y;\bar{\xi})-\bar{\nabla}f(x_{2},y ;\bar{\xi})\|^{2}\leq(\bar{L}_{0}^{2}+\bar{L}_{1}^{2}\|\nabla\Phi(x_{1})\|^{2} )\|x_{1}-x_{2}\|^{2}.\]
2. _For any fixed_ \(x\in\mathbb{R}^{d_{x}}\) _and any_ \(y_{1},y_{2}\in\mathbb{R}^{d_{y}}\)_,_ \[\mathbb{E}_{\bar{\xi}}\|\bar{\nabla}f(x,y_{1};\bar{\xi})-\bar{\nabla}f(x,y_{2} ;\bar{\xi})\|^{2}\leq(\bar{L}_{0}^{2}+\bar{L}_{1}^{2}\|\nabla\Phi(x_{1})\|^{2} )\|x_{1}-x_{2}\|^{2}.\]

_In the above expressions, we define \(\bar{L}_{0}\) and \(\bar{L}_{1}\) as_

\[\bar{L}_{0}=\left\{4\left(L_{x,0}+L_{x,1}\left(\frac{l_{g,1}l_{f,0 }}{\mu}+\left(L_{x,0}+\frac{L_{x,1}l_{g,1}l_{f,0}}{\mu}\right)\|y_{1}-y_{1}^{*} \|\right)\right)^{2}\right.\] \[\left.+\frac{6Q}{2\mu l_{g,1}-\mu^{2}}\left(l_{g,1}^{2}(L_{y,0}+L_ {y,1}l_{f,0})^{2}+l_{f,0}^{2}l_{g,2}^{2}+\frac{l_{f,0}^{2}l_{g,1}^{2}l_{g,2}^{ 2}K^{2}}{(l_{g,1}-\mu)^{2}}\right)\right\}^{1/2},\] \[\bar{L}_{1}=2L_{x,1}(1+L_{x,1}\|y_{1}-y_{1}^{*}\|).\]

Proof of Lemma b.6.: We show statement \((i)\) of the lemma, and \((ii)\) follows by similar arguments.

For any fixed \(y\in\mathbb{R}^{d_{y}}\) and any \(x_{1},x_{2}\in\mathbb{R}^{d_{x}}\), by definition of \(\bar{\nabla}f(x,y;\bar{\xi})\) we have

\[\|\bar{\nabla}f(x_{1},y;\bar{\xi})-\bar{\nabla}f(x_{2},y;\bar{ \xi})\|^{2}\] \[\leq 2\|\nabla_{x}F(x_{1},y;\xi)-\nabla_{x}F(x_{2},y;\xi)\|^{2}+2 \left\|\nabla_{xy}^{2}G(x_{1},y;\zeta^{(0)})\left[\frac{Q}{l_{g,1}}\prod_{i=1}^ {q}\left(I-\frac{1}{l_{g,1}}\nabla_{yy}^{2}G(x_{1},y;\zeta^{(i)})\right)\right] \nabla_{y}F(x_{1},y;\xi)\right.\] \[\left.-\nabla_{xy}^{2}G(x_{2},y;\zeta^{(0)})\left[\frac{Q}{l_{g,1 }}\prod_{i=1}^{q}\left(I-\frac{1}{l_{g,1}}\nabla_{yy}^{2}G(x_{2},y;\zeta^{(i)} )\right)\right]\nabla_{y}F(x_{2},y;\xi)\right\|^{2}\] \[\leq 2(L_{x,0}+L_{x,1}\|\nabla_{x}f(x_{1},y)\|)^{2}\|x_{1}-x_{2}\| ^{2}+2\left\|\nabla_{xy}^{2}G(x_{1},y;\zeta^{(0)})\left[\frac{Q}{l_{g,1}}\prod_ {i=1}^{q}\left(I-\frac{1}{l_{g,1}}\nabla_{yy}^{2}G(x_{1},y;\zeta^{(i)})\right) \right]\nabla_{y}F(x_{1},y;\xi)\right.\] \[\left.-\nabla_{xy}^{2}G(x_{2},y;\zeta^{(0)})\left[\frac{Q}{l_{g,1 }}\prod_{i=1}^{q}\left(I-\frac{1}{l_{g,1}}\nabla_{yy}^{2}G(x_{2},y;\zeta^{(i)} )\right)\right]\nabla_{y}F(x_{2},y;\xi)\right\|^{2}.\]

For the second term above, we have

\[\left\|\nabla_{xy}^{2}G(x_{1},y;\zeta^{(0)})\left[\frac{Q}{l_{g,1 }}\prod_{i=1}^{q}\left(I-\frac{1}{l_{g,1}}\nabla_{yy}^{2}G(x_{1},y;\zeta^{(i)}) \right)\right]\nabla_{y}F(x_{1},y;\xi)\right.\] \[\left.-\nabla_{xy}^{2}G(x_{2},y;\zeta^{(0)})\left[\frac{Q}{l_{g,1 }}\prod_{i=1}^{q}\left(I-\frac{1}{l_{g,1}}\nabla_{yy}^{2}G(x_{2},y;\zeta^{(i)} )\right)\right]\nabla_{y}F(x_{2},y;\xi)\right\|^{2}\] \[\leq 3l_{g,1}^{2}\frac{Q^{2}}{l_{g,1}^{2}}\left(1-\frac{\mu}{l_{g,1 }}\right)^{2q}\|\nabla_{y}F(x_{1},y;\xi)-\nabla_{y}F(x_{2},y;\xi)\|^{2}\] \[\qquad\qquad+3l_{f,0}^{2}\frac{Q^{2}}{l_{g,1}^{2}}\left(1-\frac{ \mu}{l_{g,1}}\right)^{2q}\|\nabla_{xy}^{2}G(x_{1},y;\zeta^{(0)})-\nabla_{xy}^{2} G(x_{2},y;\zeta^{(0)})\|^{2}\]\[\|\nabla_{x}f(x_{1},y)-\nabla_{x}f(x_{1},y_{1}^{*})\| \leq\left(L_{x,0}+L_{x,1}\|\nabla_{x}f(x_{1},y_{1}^{*})\|\right)\|y _{1}-y_{1}^{*}\|\] \[\leq\left(L_{x,0}+L_{x,1}\left(\frac{l_{g,1}l_{f,0}}{\mu}+\|\nabla \Phi(x_{1})\|\right)\right)\|y_{1}-y_{1}^{*}\|\] \[=\left(L_{x,0}+\frac{L_{x,1}l_{g,1}l_{f,0}}{\mu}+L_{x,1}\|\nabla \Phi(x_{1})\|\right)\|y_{1}-y_{1}^{*}\|,\]

which yields

\[\|\nabla_{x}f(x_{1},y)\| \leq\|\nabla_{x}f(x_{1},y_{1}^{*})\|+\left(L_{x,0}+\frac{L_{x,1}l _{g,1}l_{f,0}}{\mu}+L_{x,1}\|\nabla\Phi(x_{1})\|\right)\|y_{1}-y_{1}^{*}\|\] \[\leq\frac{l_{g,1}l_{f,0}}{\mu}+\|\nabla\Phi(x_{1})\|+\left(L_{x,0 }+\frac{L_{x,1}l_{g,1}l_{f,0}}{\mu}+L_{x,1}\|\nabla\Phi(x_{1})\|\right)\|y_{1} -y_{1}^{*}\|\] \[=\left(\frac{l_{g,1}l_{f,0}}{\mu}+\left(L_{x,0}+\frac{L_{x,1}l_{g,1}l_{f,0}}{\mu}\right)\|y_{1}-y_{1}^{*}\|\right)+(1+L_{x,1}\|y_{1}-y_{1}^{*} \|)\|\nabla\Phi(x_{1})\|.\]Therefore, we conclude that

\[\mathbb{E}_{\bar{\xi}}\|\bar{\nabla}f(x_{1},y;\bar{\xi})-\bar{\nabla}f (x_{2},y;\bar{\xi})\|^{2}\leq 2(L_{x,0}+L_{x,1}\|\nabla_{x}f(x_{1},y)\|)^{2}\|x_{1}-x_ {2}\|^{2}\] \[+\frac{6Q}{2\mu l_{g,1}-\mu^{2}}\left(l_{g,1}^{2}(L_{y,0}+L_{y,1} l_{f,0})^{2}+l_{f,0}^{2}l_{g,2}^{2}+\frac{l_{f,0}^{2}l_{g,1}^{2}l_{g,2}^{2}Q^{2}}{(l _{g,1}-\mu)^{2}}\right)\|x_{1}-x_{2}\|^{2}\] \[\leq 2\left(L_{x,0}+L_{x,1}\left(\frac{l_{g,1}l_{f,0}}{\mu}+\left( L_{x,0}+\frac{L_{x,1}l_{g,1}l_{f,0}}{\mu}\right)\|y_{1}-y_{1}^{*}\|\right)+L_{x,1}(1+ L_{x,1}\|y_{1}-y_{1}^{*}\|)\|\nabla\Phi(x_{1})\|\right)^{2}\|x_{1}-x_{2}\|^{2}\] \[+\frac{6Q}{2\mu l_{g,1}-\mu^{2}}\left(l_{g,1}^{2}(L_{y,0}+L_{y,1} l_{f,0})^{2}+l_{f,0}^{2}l_{g,2}^{2}+\frac{l_{f,0}^{2}l_{g,1}^{2}l_{g,2}^{2}Q^{2}}{(l _{g,1}-\mu)^{2}}\right)\|x_{1}-x_{2}\|^{2}\] \[\leq 4\left(L_{x,0}+L_{x,1}\left(\frac{l_{g,1}l_{f,0}}{\mu}+ \left(L_{x,0}+\frac{L_{x,1}l_{g,1}l_{f,0}}{\mu}\right)\|y_{1}-y_{1}^{*}\| \right)\right)^{2}\|x_{1}-x_{2}\|^{2}\] \[+4L_{x,1}^{2}(1+L_{x,1}\|y_{1}-y_{1}^{*}\|)^{2}\|\nabla\Phi(x_{1} )\|^{2}\|x_{1}-x_{2}\|^{2}\] \[+\frac{6Q}{2\mu l_{g,1}-\mu^{2}}\left(l_{g,1}^{2}(L_{y,0}+L_{y,1} l_{f,0})^{2}+l_{f,0}^{2}l_{g,2}^{2}+\frac{l_{f,0}^{2}l_{g,1}^{2}l_{g,2}^{2}Q^{2}}{(l _{g,1}-\mu)^{2}}\right)\|x_{1}-x_{2}\|^{2}\] \[=(\bar{L}_{0}^{2}+\bar{L}_{1}^{2}\|\nabla\Phi(x_{1})\|^{2})\|x_{1 }-x_{2}\|^{2},\]

where we use the definition of \(\bar{L}_{0}\) and \(\bar{L}_{1}\) in the last equality. 

## Appendix G Additional Experimental Details

Hyperparameter setting.We tune the best hyperparameters for each algorithm, including upper-/lower-level step size, the number of inner loops, momentum parameters, etc. The upper-level learning rate \(\eta_{up}\) and lower-level learing rate \(\eta_{low}\) are tuned in the range of \([0.001,0.1]\) for all the baselines on experiments of AUC maximization and data hyper-cleaning, the best \((\eta_{up},\eta_{low})\) on **AUC maximization** are summarized as follows: StocBio: \((0.01,0.001)\), TTSA: \((0.005,0.01)\), SABA: \((0.01,0.005)\), MA-SOBA: \((0.01,0.005)\), SUSTAIN: \((0.03,0.01)\), VRBO: \((0.05,0.01)\), BO-REP: \((0.001,0.001)\), AccBO: \((0.005,0.005)\). The best learning rate on the experiment of **data hyper-cleaning** are summarized as follows: Stocbio: \((0.01,0.002)\), TTSA: \((0.001,0.01)\), SABA: \((0.05,0.02)\), MA-SOBA: \((0.01,0.01)\), SUSTAIN: \((0.05,0.05)\), VRBO: \((0.1,0.05)\), BO-REP: \((0.02,0.01)\), AccBO: \((0.1,0.1)\). Note that SUSTAIN decays its upper-/lower-level step size with epoch (\(t\)) by \(\eta_{up}=\eta_{up}/(t+2)^{1/3}\), \(\eta_{low}=\eta_{up}/(t+2)^{1/3}\), while other algorithms use a constant learning rate. The number for reumann series estimation in StocBio and VRBO is fixed to 3, while it is uniformly sampled from \(\{1,2,3\}\) in TTSA, SUSTAIN, and AccBO. In AUC maximization, AccBO uses Option I (Option II in data hyper-cleaning) to update the lower-level variable, and sets the Network momentum parameter \(\gamma=0.5\), the averaging parameter \(\tau=0.5\) (\(\gamma=0.1\) and \(\tau=0.5\) in data hyper-cleaning). In AUC maximization, the batch size is set to be \(32\) for all algorithms except VRBO, which uses larger batch size of \(64\) (tuned in the range of \(\{32,64,128,256,512\}\)) at the checkpoint step and \(32\) otherwise. In data hyper-cleaning, the batch size is set to be \(128\) for all algorithms except VRBO, which uses larger batch size of \(256\) (tuned in the range of \(\{63,128,256,512,1024\}\)) at the checkpoint step and \(128\) otherwise. AccBO uses Option II in data hyper-cleaning, and the periodical update for low-level variable sets the iterations \(N=3\) and update interval \(I=2\). Other hyperparameters setting keep the same in AUC maximization and data hyper-cleaning: The momentum parameter \(\beta\) is fixed to \(0.9\) in AccBO, MA-SOBA, BO-REP. The warm start steps for lower-level variable in AccBO is set to \(3\). The number of inner loops for StocBio is set to \(3\). BO-REP uses the periodical update for low-level variable, and set the iterations \(N=3\) and the update interval \(I=2\).

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Every claim made in the abstract is specified a section of the paper, including algorithm design and analysis in Section 4 and experiments in Section 5. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discussed the limitations of our work in Section 6. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: We provide both assumptions and proofs in Appendices C to E. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The experimental details are fully specified in Section 5 and Appendix G. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: The code and data are attached as a supplement with instructions for reproducibility. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: The experimental details are included in Section 5 and Appendix G. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [No] Justification: We only run once due to limited computational budget. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors).

* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The hardware specification is described in Section 5. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We have read and conformed to the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: This paper presents work whose goal is to advance the field of Machine Learning from algorithmic and theoretical aspects. We do not see any direct paths to negative societal impacts. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Our paper does not involve the release of any data or models. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: Our paper uses existing text classification datasets and are cited in Section 5 and their licenses are mentioned. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: Our paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing or research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve crowdsourcing or research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.