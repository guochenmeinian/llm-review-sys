# Rethinking Incentives in Recommender Systems:

Are Monotone Rewards Always Beneficial?

 Fan Yao

University of Virginia

fy4bc@virginia.edu

&Chuanhao Li

Yale University

chuanhao.li.cl2637@yale.edu

&Karthik Abinav Sankararaman

Meta

karthikabinavs@meta.com

&Yiming Liao

Meta

yimigliao@meta.com

&Yan Zhu

Google

yanzhuyz@google.com

&Qifan Wang

Meta

wqcfr@meta.com

&Hongning Wang

University of Virginia

hw5x@virginia.edu

&Haifeng Xu

University of Chicago

haifengxu@uchicago.edu

###### Abstract

The past decade has witnessed the flourishing of a new profession as media content creators, who rely on revenue streams from online content recommendation platforms. The reward mechanism employed by these platforms creates a competitive environment among creators which affects their production choices and, consequently, content distribution and system welfare. It is thus crucial to design the platform's reward mechanism in order to steer the creators' competition towards a desirable welfare outcome in the long run. This work makes two major contributions in this regard: first, we uncover a fundamental limit about a class of widely adopted mechanisms, coined _Merit-based Monotone Mechanisms_, by showing that they inevitably lead to a constant fraction loss of the optimal welfare. To circumvent this limitation, we introduce _Backward Rewarding Mechanisms_ (BRMs) and show that the competition game resultant from BRMs possesses a potential game structure. BRMs thus naturally induce strategic creators' collective behaviors towards optimizing the potential function, which can be designed to match any given welfare metric. In addition, the class of BRM can be parameterized so that it allows the platform to directly optimize welfare within the feasible mechanism space even when the welfare metric is not explicitly defined.

## 1 Introduction

Online recommendation platforms, such as Instagram and YouTube, have become an integral part of our daily life [5]. Their impact extends beyond merely aligning users with the most relevant content: they are also accountable for the online ecosystem it creates and the long-term welfare it promotes, considering the complex dynamics driven by the potential strategic behaviors of content creators [17]. Typically, creators' utilities are directly tied to the visibility of their content or economic incentives they can gather from the platform, and they constantly pursue to maximize these benefits [10; 12]. This fosters a competitive environment that may inadvertently undermine the _social welfare_, i.e., the total utilities of all users and content creators in the system [9]. For example, consider a scenario where the user population contains a majority group and many smaller minority groups, where different groups are interested in distinct topics. The social welfare is maximized when content distribution covers the variety of topics. However, a possible equilibrium of this competition can leadmost content creators to produce homogeneous content catering only to the majority group. This is because the benefits from creating niche content cannot offset the utility loss caused by forgoing the exposure from the majority of users. Such a phenomenon could potentially dampen the engagement of minority user groups or even instigate them to leave the platform altogether. This can consequently hurt the overall social welfare and also impact the platform's long-term revenue.

To counter such effects induced by strategic content creators, the platform can design proper incentives (i.e., rewarding mechanisms) to influence the creators' perceived utilities, thereby steering the equilibrium content distribution towards enhanced social welfare. In reality, many platforms share revenue with creators via various mechanisms [15; 19; 24; 20]. These incentives are typically proportional to user satisfaction measured by various metrics, such as click-through rate and engagement time. We model such competitive environment within a general framework termed _content creator competition_ (\(C^{3}\)) game that generalizes and abstracts a few established models including [23; 4; 14; 13], and frame a class of popular rewarding mechanisms as Merit-based Monotone Mechanisms (\(\mathcal{M}^{3}\)). The \(\mathcal{M}^{3}\) are characterized by a few simple properties, intuitively meaning better content should be rewarded more (i.e., merit-based) and sum of creators' utilities increase whenever any creator increases her content relevance (i.e., monotone). These properties reflect the essence of most employed rewarding mechanisms in practice. However, we show that \(\mathcal{M}^{3}\) necessarily incur a constant fraction of welfare loss in natural scenarios due to failing to encourage content creators who are content with generating popular content for majority user groups to produce niche content.

This surprising negative result uncovers the intrinsic _incompatibility_ within \(\mathcal{M}^{3}\) mechanisms and thus compels us to rethink the incentive design in recommender systems (RS). A key property of \(\mathcal{M}^{3}\) is monotonicity, which stipulates that when the matching quality of exposed creators to a specific user group exhibits a Pareto improvement, the total reward received by those creators also increases. We point out that, while seemingly plausible at the first thought, this property undesirably encourages excessive concentration of creators around the majority user groups and leaves minority groups underserved. To resolve this issue, we question the validity of this monotone property. At a high level, when creators' competition within some user group surpasses a limit that begins to harm welfare, the platform should reduce their total gain. In light of this insight, we introduce a new class of content rewarding mechanism coined the _Backward Rewarding Mechanisms_ (BRM), which drops monotonicity but remains merit-based. The strength of BRM lies in three aspects: **1.**ny \(C^{3}\) game under any BRM mechanism forms a potential game [16]; **2.** we can identify a BRM mechanism such that the induced potential function is equivalent to any given social welfare metric; consequently, the net effect of creators' competition aligns perfectly with maximizing the social welfare; and **3.** BRM contains a parameterized subclass of mechanisms that allows empirical optimization of the social welfare, which is especially useful in practice when the welfare is not explicitly defined. These merits of BRM are supported by our empirical studies, in which we developed simulated environments, demonstrating the welfare induced by BRM outperforms baseline mechanisms in \(\mathcal{M}^{3}\).

## 2 Related Work

The studies of content creators' strategic behavior under the mediation of an RS starts from the original work of [3; 4], who proposed the Shapley mediator that guarantees the existence of pure Nash equilibrium (PNE) and several fairness-related requirements. These works only study the design of the content-user matching probability, and it was observed that user welfare could be significantly compromised. In contrast, our work considers the design of another important "knob" of contemporary platforms -- i.e., the reward for each content creator. We propose a broad class of rewarding mechanisms, namely, the Backward Rewarding Mechanisms (BRM). We show that the Shapley mediator of [4] turns out to be an example of our BRM class; however, by optimizing within the class of BRM mechanisms, the RS can now achieve the goal of maximizing social welfare.

Several recent work [13; 14; 23] studied the properties of creator-side equilibrium in the \(C^{3}\) game, under given creator incentives. In [13; 14], creators are assumed to directly compete for user _exposure_ without the mediation of an RS. These studies focus on characterizing the Nash Equilibrium (NE) and identifying conditions that may trigger specialization among creators' strategies. [23] demonstrate that the user welfare loss under a conventional RS using top-\(K\) ranking is upper-bounded by \(O(\frac{1}{\log K})\) when creators compete for user _engagement_. Our work reveals that any merit-based monotone mechanism, including but not limiting to those based on user exposure or engagement, will inevitably incur at least a \(\frac{1}{K}\) fraction of welfare loss. However, should the platform can design creators' incentive signals, then exactly optimal social welfare could be obtained.

The main goal of the present work is to design incentives for creators to steer their collective behaviors towards social optimum. Such welfare-maximizing mechanism design has been studied extensively in social choice theory as well as in recent algorithmic mechanism design literature. Two of the most fundamental findings in this space are perhaps: (1) Vickrey-Clarke-Groves (VCG) mechanism which maximizes the social welfare of multi-item allocation [22]; and (2) the Arrow's impossibility theorem which employs an axiomatic approach to show the impossibility of welfare-maximization among natural voting mechanisms [1].1 While welfare maximization in resource allocation and social choice has been extensively studied, to the best of our knowledge, our work is the first study of designing optimal mechanisms for welfare maximization in _recommender systems_. Interestingly, both our negative and positive results are inspired by the two fundamental results mentioned above. [1] shows that there is no ranked voting system capable of transforming the ranked preferences of individuals into a communal consensus ranking, while maintaining a natural set of criteria. Drawing a parallel to this concept and using the same axiomatic approach, our Theorem 1 can be interpreted as a similar impossibility result for welfare maximization under certain axioms in recommender systems -- that is, no rewarding mechanism is capable of optimizing the social welfare while adhering to both "merit-based" and "monotone" properties. On the other hand, our positive result shows that there exists a creator rewarding mechanism that can maximize the RS's welfare at the potential-function-maximizing pure Nash equilibrium. The conceptual message of this result bears similarity to VCG's welfare maximization in multi-item allocation at the dominant-strategy equilibrium, but the techniques we employed is significantly different from VCG. To the best of our knowledge, this appear the first attempt to employ potential functions for welfare-maximizing mechanism design.

Footnote 1: The term “welfare” in social choice is classically more concerned with fairness or stability, as opposed to utility maximization.

## 3 A General Model for Content Creator Competition

In this section, we formalize the Content Creator Competition \((C^{3})\) game as well as the platform's rewarding mechanisms. Each \(\mathcal{C}^{3}\) game instance \(\mathcal{G}\) can be described by a tuple

\((\{\mathcal{S}_{i}\}_{i=1}^{n},\{c_{i}\}_{i=1}^{n},\mathcal{F},\sigma,M,\{r_{i }\}_{i=1}^{n})\) illustrated as follows:

1. **Basic setups:** The system has a user population/distribution \(\mathcal{F}\) with (discrete or continuous) support \(\mathcal{X}\subset\mathbb{R}^{d}\), and a set of content creators denoted by \([n]=\{1,\cdots,n\}\). Each creator \(i\) can take an action \(\bm{s}_{i}\), often referred to as a _pure strategy_ in game-theoretic terms, from an action set \(\mathcal{S}_{i}\subset\mathbb{R}^{d}\). Any \(\bm{s}_{i}\in\mathcal{S}_{i}\) can be interpreted as the embedding of a content that creator \(i\) is able to produce. Let \(c_{i}(\bm{s}_{i})\) denote the production cost for creator \(i\) to generate \(\bm{s}_{i}\). As an example, one may think of \(c_{i}(\bm{s}_{i})=\lambda_{i}||\bm{s}_{i}-\bm{s}_{i}||_{2}^{2}\) where \(\bm{s}_{i}\) represents the type of content that creator \(i\) is most comfortable or confident with, though our result is general and does not depend on any assumption of \(c_{i}\). In general, any creator \(i\) may also play a mixed strategy, i.e., a distribution over \(\mathcal{S}_{i}\). However, for the purpose of this study, it suffices to consider pure strategies since it always exists in all our analysis 2 and thus is a more natural solution concept. The connection between any user \(\bm{x}\) (drawn from \(\mathcal{F}\)) and content \(\bm{s}_{i}\) is described by a matching score function \(\sigma(\bm{s};\bm{x}):\mathbb{R}^{d}\times\mathbb{R}^{d}\rightarrow\mathbb{R} _{\geq 0}\) which measures the matching quality between a user \(\bm{x}\in\mathcal{X}\) and content \(\bm{s}\). Without loss of generality, we normalize \(\sigma\) to \([0,1]\), where \(1\) suggests perfect matching. This work focuses on modeling the strategic behavior of creators, thus abstracts away the estimation of \(\sigma\) and simply views it as perfectly given.3 With slight abuse of notation, we use \(\sigma_{i}(\bm{x})\) to denote \(\sigma(\bm{s}_{i};\bm{x})\) given any joint creator action profile \(\bm{s}=(\bm{s}_{1},\cdots,\bm{s}_{n})\in\mathcal{S}=\cup_{i=1}^{n}\mathcal{ S}_{i}\). When it is clear from the context, we often omit the reference to the generic user \(\bm{x}\) (drawn from population \(\mathcal{F}\)) and simply use \(\sigma_{i}\) to denote creator \(i\)'s score. Footnote 2: We will propose mechanisms that induce a potential game structure, which guarantees the existence of PNE[18].
2. **Rewarding mechanisms and resultant creator utilities.** Given joint strategy \(\bm{s}=(\bm{s}_{1},\cdots,\bm{s}_{n})\in\mathcal{S}\), the platform generates a reward \(u_{i}\in[0,1]\) for each user-creator pair \((\bm{s}_{i},\bm{x})\). We generally allow \(u_{i}\) to depend on \(\bm{s}_{i}\)'s matching score \(\sigma_{i}\) and also other creators' score \(\sigma_{-i}=\{\sigma_{t}|1\leq t\leq n,t\neq i\}\). Thus, a rewarding mechanism \(M\) is a mapping from \((\sigma_{i},\{\sigma_{-i}\})\) to \([0,1]\), which is denoted by the function \(M(\sigma_{i};\sigma_{-i})\). Such rewarding mechanisms can be interpreted as the expected payoff for creator \(i\) under any user-content matching strategy _and_ some post-matching rewarding scheme. For example, suppose the platform matches creator \(\bm{s}_{i}\) to user \(\bm{x}\) with probability \(p(\sigma_{i};\sigma_{-i})\) and then reward each matched creator-\(i\) by some \(R_{i}\). Then by letting \(R_{i}=\mathbb{I}[\bm{s}_{i}\) matched to \(\bm{x}]\frac{M(\sigma_{i};\sigma_{-i})}{p(\sigma_{i};\sigma_{-i})}\) we have \(\mathbb{E}[R_{i}]=M(\sigma_{i};\sigma_{-i})\). Given such correspondence between expected creator pair formed and user-content matching/post-matching reward, we can without loss of generality refrain from the modeling of detailed matching policy and rewarding schemes, and simply focus on the design of \(M(\cdot;\cdot)\). A few remarks about the reward mechanism \(M(\cdot;\cdot)\) follow. First, \(M\) is determined only by the profile of matching scores but not directly depend on the specific user \(\bm{x}\). However, our main results can be seamlessly generalized to allow \(M\) directly depend on \(\bm{x}\).4 Second, the definition of \(M(\sigma;\sigma_{-})\) above naturally implies that it is "identity-invariant". That is, it specifies the reward of a matching score \(\sigma\), generated by whichever creator, when facing a set of competitive matching scores in \(\sigma_{-}\). While one could have considered more general identity-dependent rewarding mechanisms, they appear less realistic due to fairness concerns. More importantly, we shall show that such identity-invariant mechanisms already suffice to achieve optimal welfare. Under the rewarding mechanism above, creator-\(i\)'s expected utility is simply the expected reward gained from the user population \(\mathcal{F}\) minus the cost for producing content \(\bm{s}_{i}\), i.e., \[u_{i}(\bm{s})=\mathbb{E}_{\bm{x}\in\mathcal{F}}[M(\sigma_{i}(\bm{x});\sigma_{ -i}(\bm{x}))]-c_{i}(\bm{s}_{i}),\forall i\in[n],\] (1) where \(\sigma_{i}(\bm{x})=\sigma(\bm{s}_{i};\bm{x})\) is the matching score between \(\bm{s}_{i},\bm{x}\) and \(c_{i}\) is the cost function for creator-\(i\). Footnote 4: This may be useful when the system wants to specifically promote a particular user group by providing higher rewards to creators for serving this group.
3. **User utility and the social welfare.** Before formalizing the welfare objective, we first define a generic user \(\bm{x}\)'s utility from consuming a list of ranked content. Since the user attention usually decreases in the rank positions, we introduce discounting weights \(\{r_{k}\in[0,1]\}_{k}\) to represent his/her "attention" over the \(k\)-th _ranked_ content. Naturally, we assume \(r_{1}\geq\cdots\geq r_{n-1}\geq r_{n}\), i.e., higher ranked content receives more user attention. Consequently, the user's utility from consuming a list of content \(\{l(k)\}_{k=1}^{n}\), which is a permutation of \([n]\) ranked in a descending order of match scores (i.e., \(\sigma_{l(1)}\geq\sigma_{l_{j}(2)}\geq\cdots\geq\sigma_{l_{j}(n)}\)), is defined by the following weighted sum \[W(\bm{s};\bm{x})=\sum_{k=1}^{n}r_{k}\sigma_{l(k)}(\bm{x}).\] (2) We provide additional examples that account for top-\(K\) ranking rules with arbitrary ad-hoc permutations in Appendix 8.1. Finally, the social welfare is defined as the sum of total user utilities and total creator utilities, minus the platform's cost: \[W(\bm{s};\{r_{k}\}) =\mathbb{E}_{\bm{x}\sim\mathcal{F}}[W(\bm{s};\bm{x})]+\sum_{i=1}^ {n}u_{i}(\bm{s})-\sum_{i=1}^{n}\mathbb{E}_{\bm{x}\sim\mathcal{F}}[M(\sigma_{i} (\bm{x});\sigma_{-i}(\bm{x}))]\] \[=\mathbb{E}_{\bm{x}\sim\mathcal{F}}[W(\bm{s};\bm{x})]-\sum_{i=1}^ {n}c_{i}(\bm{s}_{i}).\] (3) The set of weights \(\{r_{k}\}\) determines a welfare metric \(W(\cdot;\{r_{k}\})\). For ease of exposure, we assume the sequence \(\{r_{k}\}\) is independent of specific user \(\bm{x}\). However, our results also hold for the more general situation where \(\{r_{k}\}\) is a function of the user profile \(\bm{x}\). In most of our analysis, we assume \(r_{k}\) can be measured and is known to the platform. However, we will later discuss how to address the situations where the platform only has blackbox access to \(W(\cdot,\{r_{k}\})\), but not the individual values of \(r_{k}\).

**The research question: creator incentive design for welfare maximization.** Unlike previous works [14, 2, 13] that primarily focus on designing user-content matching mechanisms, we consider the design of a different, and arguably more general, "knob" to improve the system's welfare, i.e., creators' rewarding schemes. Each rewarding mechanism \(M\) establishes a competitive environment among content creators, encapsulated by a \(C^{3}\) instance \(\mathcal{G}(\{\mathcal{S}_{i}\},\{c_{i}\},\mathcal{F},\sigma,M,\{r_{i}\})\). To characterize the outcome of \(C^{3}\) game, we consider the solution concept called Pure Nash Equilibrium (PNE), which is a joint strategy profile \(\bm{s}^{*}=(\bm{s}_{1}^{*},\cdots,\bm{s}_{n}^{*})\in\mathcal{S}\) such that each player \(i\) cannot increase his/her utility by unilaterally deviating from \(\bm{s}_{i}^{*}\). Our objective is thus to design mechanisms \(M\) that: 1. guarantees the existence of PNE, thereby ensuring a stable outcome, and 2. maximizes social welfare at the PNE. In the upcoming sections, we first demonstrate why many existing rewarding mechanisms can fall short of achieving these goals, and then introduce our proposed new mechanism.

The Fundamental Limit of Merit-based Monotone Mechanisms

In this section, we employ an axiomatic approach to demonstrate the fundamental limit of many employed rewarding mechanisms in today's practice. We identify a few properties (sometimes also called _axioms_[1]) of rewarding mechanisms that are considered natural in many of today's RS platforms, and then show that any mechanism satisfying these properties will necessarily suffer at least \(1/K\) fraction of welfare loss at every equilibrium of some natural RS environments. Specifically, we consider mechanisms with the following properties.

**Definition 1** (Merit-based Monotone Mechanisms (\(\mathcal{M}^{3}\))).: _We say \(M\) is a merit-based monotone mechanism if for any relevance scores \(1\geq\sigma_{1}\geq\cdots\geq\sigma_{n}\geq 0\), \(M\) satisfies the following properties:_

* _(Normality)_ \(M(0;\sigma_{-i})=0\)_,_ \(M(1;\{0,\cdots,0\})>0\)_,_
* _(Fairness)_ \(M(\sigma_{i};\sigma_{-i})\geq M(\sigma_{j};\sigma_{-j}),\forall i>j\)_,_
* _(Negative Externality)_ \(\forall i\)_, if_ \(\sigma_{-i}\preccurlyeq\sigma_{-i}^{\prime}\) _(_\(\sigma_{j}\leq\sigma_{j}^{\prime},\forall j\neq i\)_), then_ \(M(\sigma_{i};\sigma_{-i})\geq M(\sigma_{i};\sigma_{-i}^{\prime})\)_._
* _Monotonicity: the total rewards_ \(\sum_{i=1}^{n}M(\sigma_{i};\sigma_{-i}):[0,1]^{n}\rightarrow\mathbb{R}_{\geq 0}\) _is non-decreasing in_ \(\sigma_{i}\) _for every_ \(i\in[n]\)_._

_We use \(\mathcal{M}^{3}(n)\) to denote the set of all merit-based monotone mechanisms. When the context is clear, we omit the argument \(n\) and simply use the notation \(\mathcal{M}^{3}\)._

The two properties underpinning \(\mathcal{M}^{3}\) are quite intuitive. Firstly, the merit-based property consists of three natural sub-properties: 1. zero relevance content should receive zero reward, whereas the highest relevance content deserves a non-zero reward; 2. within the given pool of content with scores \(\{\sigma_{i}\}_{i\in[n]}\), the higher relevance content should receive a higher reward; 3. any individual content's reward does not increase when other creators improve their content relevance. Secondly, monotonicity means if any content creator \(i\) improves her relevance \(\sigma_{i}\), the total rewards to all creators increase. This property is naturally satisfied by many widely adopted rewarding mechanisms because platforms in today's industry typically reward creators proportionally to user engagement or satisfaction, the _total_ of which is expected to increase as some creator's content becomes more relevant.

Indeed, many popular rewarding mechanisms can be shown to fall into the class of \(\mathcal{M}^{3}\). For instances, the following two mechanisms defined over a descending score sequence \(\{\sigma_{i}\}\) are widely adopted in current industry practices for rewarding creators [15; 19; 20; 24], both of which are in \(\mathcal{M}^{3}\):

1. When players' utilities are set to the total content exposure [2; 13; 14], we have \(M(\sigma_{i};\sigma_{-i})=\mathbb{I}[i\leq K]\frac{\exp(\beta^{-1}\sigma_{i}) }{\sum_{j=1}^{K}\exp(\beta^{-1}\sigma_{j})}\), with a temperature parameter \(\beta>0\) controlling the spread of rewards.
2. When players' utilities are set to the user engagement [23], we have \(M(\sigma_{i};\sigma_{-i})=\mathbb{I}[i\leq K]\frac{\exp(\beta^{-1}\sigma_{i}) }{\sum_{j=1}^{K}\exp(\beta^{-1}\sigma_{j})}\pi(\sigma_{1},\cdots,\sigma_{n})\), where \(\pi(\sigma_{1},\cdots,\sigma_{n})=\beta\log\left(\sum_{j=1}^{K}\exp(\beta^{-1} \sigma_{j})\right)\) is shown to be the total user welfare.

We show that _any_ mechanism in \(\mathcal{M}^{3}\) may result in quite suboptimal welfare, even applied to some natural \(C^{3}\) game environment. We consider the following representative (though idealized) sub-class of \(C^{3}\) instances, which we coin the _Trend v.s. Niche_ (TvN) environments. As outlined in the introduction section, TvN captures the essence of many real-world situations.

**Definition 2** (TvN Games).: _The Trend v.s. Niche_ (TvN) game is specified by the following RS environments:_

* _The user population_ \(\mathcal{F}\) _is a uniform distribution on_ \(\mathcal{X}=\{\bm{x}_{j}\}_{j=1}^{2n}\) _where_ \(\bm{x}_{j}=\bm{e}_{1}\)_, for_ \(1\leq j\leq n+1,\bm{x}_{n+2}=\bm{e}_{2},\cdots,\bm{x}_{2n}=\bm{e}_{n}\) _and_ \(E=\{\bm{e}_{1},\cdots,\bm{e}_{n}\}\subset\mathbb{R}^{n}\) _is the set of unit basis in_ \(\mathbb{R}^{n}\)_;_
* _All creators have zero costs and share the same action set_ \(\mathcal{S}_{i}=E\)_; the relevance is measured by the inner product, i.e.,_ \(\sigma(\bm{s};\bm{x})=\bm{s}^{\top}\bm{x}\)_;_
* _The attention discounting weights_ \(\{r_{i}\}\) _is induced by a top-_\(K\) _environment, i.e.,_ \(r_{1}\geq\cdots\geq r_{K}\geq r_{K+1}=\cdots=r_{n}=0\)_._

_The content creation competition game induced by any mechanism \(M\) is called a TvN game, denoted as \(\mathcal{G}(\{\mathcal{S}_{i}\},\{c_{i}=0\},\mathcal{F},\sigma,M,\{r_{i}\})\)._The TvN game models a scenario where the user population comprises multiple interest groups, each with orthogonal preference representations. In this game, the largest group consists of nearly half the population. Each content creator has the option to cater to one--and only one--user group. While this game is simple and stylized, it captures the essence of real-world user populations and the dilemmas faced by creators. creators often find themselves at a crossroad: they must decide whether to pursue popular trends for a broader audience population, leading to intense competition, or focus on niche topics with a smaller audience and reduced competition. Our subsequent result shows that if the platform adopts \(\mathcal{M}^{3}\) in the TvN game, this tension of content creation turns out to be a curse in the sense that a unique PNE is achieved when all players opt for the same strategy -- catering to the largest user group -- and we quantify the social welfare loss at this PNE in the following.

**Theorem 1**.: _For any rewarding mechanism \(M\in\mathcal{M}^{3}\) applied to any TvN instance, we have_

1. _the resultant game admits a unique NE_ \(\bm{s}^{*}\)_;_
2. _the welfare of this NE is at most_ \(\frac{K}{K+1}\) _fraction of the optimal welfare for large_ \(n\)_. Formally,_ \[\frac{W(\bm{s}^{*})}{\max_{\bm{s}\in\mathcal{S}}W(\bm{s})}\leq\frac{K}{K+1}+O \left(\frac{1}{n}\right).\] (4)

The proof is in Appendix 8.4, where we explicitly characterize both \(\bm{s}^{*}\) and the welfare maximizing strategy profile and calculate their difference in terms of welfare. It is worthwhile to point out that the reciprocal of left-hand side of (4) is commonly known as the Price of Anarchy (PoA). This metric gauges the welfare loss at equilibrium compared to optimal welfare. (4) suggests that the PoA of \(\mathcal{G}\) under \(\mathcal{M}^{3}\) could be as significant as \(1/2\) for users who primarily care about the top relevant content, which is shown to be realistic given the diminishing attention spans of Internet users [6]. This theorem shows that no mechanisms in \(\mathcal{M}^{3}\) can achieve the optimal welfare at the (unique) equilibrium of any TvN game. This naturally motivates our next question about how to design welfare-maximizing rewarding mechanisms in recommender systems.

## 5 Welfare Maximization via Backward Rewarding Mechanisms

The aforementioned failure of the generic \(\mathcal{M}^{3}\) class for welfare maximization urges us to re-think the rewarding mechanism design in recommender systems, especially for platforms where user attention is concentrated on the top few positions. Theorem 1 demonstrates certain inherent incompatibility between merit-based conditions and group monotonicity when it comes to optimizing welfare. Thus, a compromise must be made between the two, and our choice is the latter one. On one hand, any violation to the merit-based properties is challenging to justify as it undermines creators' perceptions about the value of the matching score metric. If creators discover that highly relevant content can receive lower payoffs or no rewards despite being the most relevant, it can be detrimental to the platform's reputation. On the other hand, while an increase in a creator's matching score \(\sigma_{i}\) would naturally lead to an expected increase in his/her reward, it is generally unnecessary for the total rewards to increase as required by the monotonicity property. In fact, such non-monotonicity is widely observed in free markets, e.g., monopoly vs duopoly markets. For instance, consider a monopoly market with a high-quality producer and a low-quality producer, each catering to their distinct consumer bases. Now suppose the low-quality producer dramatically elevates his/her production quality to transition the market into a duopoly. While such an action would naturally augment the producer's profits, it would concurrently establish intensified competition with the high-quality producer, typically resulting in a marked decline in the latter's profitability. This would subsequently result in a decrease in the two producers' total profit [7; 25]. As will be clear later, our designed rewarding mechanism will lead to similar situations among content creators.

To enhance welfare, it is crucial to incentivize content creators who predominantly target larger user groups to also produce content for smaller groups. However, the monotone property encourages creators to continuously increase their matching scores to a user group, even when those users already have abundant options, resulting in diminishing welfare contributions. To address this, we introduce the class of Backward Rewarding Mechanisms (BRMs). The name of BRM suggests its essential characteristic: the reward for a specific creator-\(i\) depends solely on their ranking and the matching scores of creators ranked _lower_ than \(i\). The formal definition of BRM is provided below:

**Definition 3** (BRM and BRCM).: _A Backward Rewarding Mechanism (BRM) \(M\) is determined by a sequence of Riemann integrable functions \(\{f_{i}(t):[0,1]\rightarrow\mathbb{R}_{\geq 0}\}_{i=1}^{n}\), satisfying \(f_{1}(t)\geq\cdots\geq\)\(f_{n}(t)\)\(\forall t\in[0,1]\), such that for any matching score sequence \(1\geq\sigma_{1}\geq\cdots\geq\sigma_{n}\geq 0\), the reward to any creator \(i\) is given by_

\[M(\sigma_{i};\sigma_{-i})=\sum_{k=i}^{n}\int_{\sigma_{k+1}}^{\sigma_{k}}f_{k}(t)dt,\] (5)

_where \(\sigma_{n+1}=0\) and \(f_{1}(t)>0,\forall t\in[0,1]\). We use \(M[f_{1}(t),\cdots,f_{n}(t)]\) to denote the BRM determined by ordered function sequence \(\{f_{i}(t)\}_{i=1}^{n}\). In addition, we identify a sub-class of mechanisms \(\text{BRCM}\subset\text{BRM}\) which includes those \(M\) such that \(\{f_{i}(t)\equiv f_{i}\}\) are a set of constant functions. Any \(M\in\text{BRCM}\) can be parameterized by an \(n\)-dimensional vector in the polytope \(\mathcal{F}=\{(f_{1},\cdots,f_{n})|f_{1}\geq\cdots\geq f_{n}\geq 0\}\)._

Figure 1 illustrates an example of BRM with function \(\{f_{1},f_{2},f_{3}\}\). According to its definition, the blue areas represent the rewards assigned by BRM and we can easily see why BRM preserves the merit-based property. Generally, the function \(f_{i}(\cdot)\) encapsulates the significance of the matching score difference between the \(i\)-th and \((i+1)\)-th ranked content in contributing to the \(i\)-th ranked creator's reward. The constraint \(f_{1}(t)\geq\cdots\geq f_{n}(t)\) is necessary to satisfy merit-based properties, as shown in the proof of Proposition 1. The broad class of BRM offers granular control over creator incentives. Meanwhile, the subclass BRCM provides opportunities for parameterized optimization over welfare, which we will discuss in Section 5.2. Additional concrete examples of BRM are illustrated in Appendix 8.3.

### Properties of BRM

While the class of BRM might appear abstract at the first glance, one can confirm that it preserves all merit-based properties, making it a natural class of rewarding mechanisms. Nevertheless, in order to secure a better welfare guarantee, the monotonicity is dropped, as characterized in the following:

**Proposition 1**.: _Any \(M\in\text{BRM}\) is merit-based but not necessarily monotone._

The detailed proof is provided in the Appendix 8.5. Next we establish formal characterizations about the welfare guarantee of BRM. First, we show that any \(C^{3}\) game under BRM possesses a PNE because it is a potential game [16]. A strategic game is called a potential game if there exists a function \(P:\prod_{i}\mathcal{S}_{i}\rightarrow\mathbb{R}\) such that for any strategy profile \(\bm{s}=(\bm{s}_{1},\cdots,\bm{s}_{n})\), any player-\(i\) and strategy \(\bm{s}^{\prime}_{i}\in\mathcal{S}_{i}\), whenever player-\(i\) deviates from \(\bm{s}_{i}\) to \(\bm{s}^{\prime}_{i}\), the change of his/her utility function is equal to the change of \(P\), i.e.,

\[P(\bm{s}^{\prime}_{i},\bm{s}_{-i})-P(\bm{s}_{i},\bm{s}_{-i})=u_{i}(\bm{s}^{ \prime}_{i},\bm{s}_{-i})-u_{i}(\bm{s}_{i},\bm{s}_{-i}).\]

This leads us to the main result of this section:

**Theorem 2**.: _Consider any \(C^{3}\) game \(\mathcal{G}(\{\mathcal{S}_{i}\},\{c_{i}\},\mathcal{F},\sigma,M,\{r_{i}\})\)._

1. _The_ \(C^{3}\) _game is a potential game under any any mechanism_ \(M\in\text{BRM}\)_, and thus admits a pure Nash equilibrium (PNE);_
2. _Moreover, if the mechanism_ \(M=M[r_{1},\cdots,r_{n}]\in\text{BRCM}\) _(_\(\subset\text{BRM}\)_), the potential function is precisely the welfare function, i.e.,_ \(W(\bm{s})=P(\bm{s};M)\)_. Consequently, the always exists a PNE that obtains the optimal welfare._

Figure 1: An illustration of the BRM parameterized by ordered functions \(\{f_{1},f_{2},f_{3}\}\). There are 3 creators with matching scores \(1\geq\sigma_{1}\geq\sigma_{2}\geq\sigma_{3}\geq 0\). The area of the blue region in each figure precisely gives the corresponding creator’s reward in the BRM.

The proof is in Appendix 8.6, where we construct its potential function explicitly. According to [16], we also conclude: 1. the maximizers of \(P\) are the PNEs of \(\mathcal{G}\), and 2. if the evolution of creators' strategic behavior follows a better response dynamics (i.e., in each iteration, an arbitrary creator deviates to a strategy that increases his/her utility), their joint strategy profile converges to a PNE.

Theorem 2 suggests another appealing property of BRM: one can always select an \(M\) within BRM to align the potential function with the welfare metric, which can be simply achieved by setting each \(f_{i}\) identical to \(r_{i}\). Consequently, any best response dynamic among creators not only converges to a PNE but also generates a strictly increasing sequence of \(W\), thus ensuring at least a local maximizer of \(W\). Denote the set of PNEs of \(\mathcal{G}\) as \(PNE(\mathcal{G})\). When \(PNE(\mathcal{G})\) coincides with the global maximizers of its potential function, i.e., \(PNE(\mathcal{G})=\operatorname*{argmax}_{\boldsymbol{s}}P(\boldsymbol{s};M)\), we conclude that any PNE of \(\mathcal{G}\) also maximizes the welfare \(W\). The following corollary indicates that such an optimistic situation occurs in TvN games, providing a stark contrast to the findings in Theorem 1.

**Corollary 1**.: _For any TvN instance \(\mathcal{G}\), there exists \(M\in\text{BRCM}\) such that any PNE \(\boldsymbol{s}^{*}\in PNE(\mathcal{G})\) attains the optimal \(W\), i.e.,_

\[\max_{\boldsymbol{s}\in\mathcal{S}}W(\boldsymbol{s})=W(\boldsymbol{s}^{*}).\] (6)

The proof is in Appendix 8.7. Despite the promising results presented in Corollary 1, it remains uncertain whether the strong welfare guarantee for TvN can be extended to the entire class of \(C^{3}\). This uncertainty arises because, in general, we only know that \(\operatorname*{argmax}_{\boldsymbol{s}}P(\boldsymbol{s};M)\subseteq PNE( \mathcal{G})\). However, [21] noted that the subset of PNEs corresponding to \(\operatorname*{argmax}_{\boldsymbol{s}}P(\boldsymbol{s};M)\) in any potential game is robust in the following sense: in an incomplete information relaxation of \(\mathcal{G}\), where each creator possesses a private type and must take actions based on their beliefs about other creators' types, they will play the strategies in \(\operatorname*{argmax}_{\boldsymbol{s}}P(\boldsymbol{s};M)\) at the Bayesian Nash equilibrium with a probability close to 1. This insight suggests that BRM has the potential to achieve optimal social welfare in real-world scenarios. While we lack a conclusive theoretical determination of whether BRM can attain globally optimal welfare, our empirical study in Section 6 consistently reveals that BRM outperforms baseline mechanisms in \(\mathcal{M}^{3}\) in terms of improving welfare.

### Welfare Optimization within BRCM

Theorem 2 suggests that, provided the parameters \(\{r_{i}\}\) are known, the platform can select a mechanism within BRCM with a better welfare guarantee. However, in many practical scenarios, the platform may not have access to the exact values of \(\{r_{i}\}\) but can only evaluate the resulting welfare metric using certain aggregated statistics. This presents a challenge as it may not be analytically feasible to pinpoint the optimal \(M\) as suggested by Theorem 2. In these cases, although perfect alignment between the potential function \(P\) and social welfare \(W\) may not be feasible, we can still find a mechanism that approximates the maximizer of \(W\) in creator competition. This leads us to formulate the following bi-level optimization problem:

\[\max_{M\in\text{BRCM}} W(\boldsymbol{s}^{*}(M))\] (7) s.t., \[\boldsymbol{s}^{*}(M)=\operatorname*{argmax}_{\boldsymbol{s}}P( \boldsymbol{s};M)\] (8)

In problem (7), the inner optimization (8) is executed by creators: for any given \(M\), we have justified that the creators' strategies is very likely to settle at a PNE \(\boldsymbol{s}^{*}(M)\) that corresponds to a maximizer of \(P(\boldsymbol{s};M)\). However, the exact solution to the inner problem is neither analytically solvable by the platform (owing to the combinatorial nature of \(P\)) nor observable from real-world feedback (due to creators' potentially long feedback cycles). Therefore, we propose to approximate its solution by simulating creators' strategic response sequences (See Appendix 8.8, Algorithm 1), on top of which we solve (7). Algorithm 1 is a variant of better response dynamics, incorporating randomness and practical considerations to more accurately emulate creator behavior, and will be employed as a subroutine in Algorithm 2. We should note that the specifics of the creator response simulator are not critical to our proposed solution: the optimizer can select any equilibrium-finding dynamic to replace our simulator 1, as long as it is believed to better represent creators' responses in reality.

Another challenge of solving (7) lies in the presence of ranking operations in \(W\), which makes it non-differentiable in \(\boldsymbol{s}\) and renders first-order optimization techniques ineffective. Consequently, we resort to coordinate update and apply finite differences to estimate the ascending direction of \(W\) with respect to each \(M\) parameterized by \(\boldsymbol{f}=(f_{1},\cdots,f_{n})\in\mathcal{F}\). Our proposed optimization algorithm for solving (7) is presented in Algorithm 2 in Appendix 8.9, and is structured into \(L_{1}\) epochs. At the beginning of each epoch, the optimizer randomly perturbs the current \(M\) along a direction within the feasible polytope and simulates creators' responses for \(L_{2}\) steps using Algorithm 1. Welfare is re-evaluated at the end of this epoch, and the perturbation on \(M\) is adopted if it results in a welfare increase.

## 6 Experiments

To validate our theoretical findings and demonstrate the efficacy of Algorithm 2, we simulate the strategic behavior of content creators and compare the evolution of social welfare under various mechanisms. These include Algorithm 2 and several baselines from both the \(\mathcal{M}^{3}\) and BRCM classes.

### Specification of Environments

We conduct simulations on game instances \(\mathcal{G}(\{\mathcal{S}_{i}\},\{c_{i}\},\mathcal{F},\sigma,M,\{r_{i}\})\) constructed from synthetic data. Results on MovieLens-1m dataset [11] are shown in Appendix 8.10. For the synthetic data, we consider a uniform distribution \(\mathcal{F}\) on \(\mathcal{X}\) as follows: we fix the embedding dimension \(d\) and randomly sample \(Y\) cluster centers, denoted as \(\mathbf{c}_{1},\cdots,\mathbf{c}_{Y}\), on the unit sphere \(\mathbb{S}^{d-1}\). For each center \(\mathbf{c}_{i}\), we generate users belonging to cluster-\(i\) by first independently sampling from a Gaussian distribution \(\tilde{\bm{x}}\sim\mathcal{N}(\mathbf{c}_{i},v^{2}I_{d})\), and then normalize it to \(\mathbb{S}^{d-1}\), i.e., \(\bm{x}=\tilde{\bm{x}}/\|\bm{\tilde{x}}\|_{2}\). The sizes of the \(Y\) user clusters are denoted by a vector \(\bm{z}=(z_{1},\cdots,z_{Y})\). In this manner, we generate a population \(\mathcal{X}=\cup_{i=1}^{Y}\mathcal{X}_{i}\) with size \(m=\sum_{i=1}^{Y}z_{i}\). The number of creators is set to \(n=10\), with action sets \(\mathcal{S}_{i}=\mathbb{S}^{d-1}\). The relevance function \(\sigma(\bm{x},\bm{s})=\frac{1}{2}(\bm{s}^{\top}\bm{x}+1)\) is the shifted inner product such that its range is exactly \([0,1]\). \(\{r_{i}\}_{i=1}^{n}\) is set to \(\{\frac{1}{\log_{2}(2)},\cdots,\frac{1}{\log_{2}(5)},\frac{1}{\log_{2}(6)},0, \cdots,0\}\). These synthetic datasets simulate situations where content creators compete over a clustered user preference distribution. We consider two types of game instances, denoted \(\mathcal{G}_{1}\) and \(\mathcal{G}_{2}\), distinguished by their cost functions:

1. In \(\mathcal{G}_{1}\), creators have zero cost and their initial strategies are set to the center of the largest user group. This environment models the situation where the social welfare is already trapped at suboptimal due to its unbalanced content distribution. We aim to evaluate which mechanism is most effective in assisting the platform to escape from such a suboptimal state.
2. In \(\mathcal{G}_{2}\), creators have non-trivial cost functions \(c_{i}=0.5\|\bm{s}_{i}-\bar{\bm{s}}_{i}\|_{2}^{2}\), where the cost center \(\bar{\bm{s}}_{i}\) is randomly sampled on \(\mathbb{S}^{d-1}\). Their initial strategies are set to the corresponding cost centers, i.e., all creators start with strategies that minimize their costs. This environment models a "cold start" situation for creators: they do not have any preference nor knowledge about the user population and gradually learn about the environment under the platform's incentivizing mechanism.

In our experiment, we set \((d,v,Y,m)=(10,0.3,8,52)\) and the cluster sizes \(\bm{z}=(20,10,8,5,3,3,2,1)\). The \(8\) clusters are devided into \(3\) groups \(((20),(10,8),(5,3,3,2,1))\), namely group-1,2,3, corresponding to the majority, minority, and niche groups.

### Algorithm and Baseline Mechanisms

We simulate the welfare curve produced by Algorithm 2 alongside five baseline mechanisms below.

1. BRCM\({}_{opt}\): This refers to the dynamic mechanism realized by optimization Algorithm 2. The parameters are set to \(T=1000,L_{1}=200,L_{2}=5,\eta_{1}=\eta_{2}=0.1,\bm{f}^{(0)}=(1,1,1,1,1,0,\cdots,0)\).
2. BRCM\({}^{*}\): This denotes the theoretically optimal mechanism within BRCM, as indicated by Theorem 2. The corresponding parameters of \(M\) are derived based on the knowledge of \(\{r_{i}\}_{i=1}^{n}\).
3. BRCM\({}_{1}\): BRCM\({}_{1}=M[1,\frac{1}{2},\frac{1}{3},\frac{1}{4},\frac{1}{5},0,\cdots,0]\in\) BRCM. This baseline aims to assess the impact of deviation from the theoretically optimal mechanism on the result.
4. \(M^{3}(0)\): This mechanism assigns each content creator a reward equal to the relevance score, i.e., \(M(\sigma_{i},\sigma_{-i})=\sigma_{i}\). It is obvious that this mechanism belongs to the \(\mathcal{M}^{3}\) class and is therefore denoted as \(M^{3}(0)\). Under \(M^{3}(0)\), each creator's strategy does not affect other creators' rewards at all, and thus every creator will be inclined to match the largest user group as much as their cost allows. This mechanism acts as a reference to indicate the worst possible scenario.
5. \(M^{3}(expo.)\): The mechanism based on exposure, defined in Section 4 with \(K=5,\beta=0.05\).
6. \(M^{3}(enga.)\): The mechanism based on engagement, defined in Section 4 with \(K=5,\beta=0.05\).

### Results

We let creators play \(\mathcal{G}_{1}\) and \(\mathcal{G}_{2}\) repeatedly under mechanisms specified in Section 6.2 and record the social welfare over \(T=1000\) steps with Algorithm 1 in in Figure 2.

As illustrated in Figure 1(a), BRCM family consistently outperformed \(\mathcal{M}^{3}\). As anticipated, \(M^{3}(0)\) does little to enhance social welfare when creators have already primarily focused on the most populous user group. The \(M^{3}(expo.)\) and \(M^{3}(enga.)\) mechanisms demonstrate a notable improvement over \(M^{3}(0)\) as they instigate a competitive environment for creators striving to reach the top-\(K\) positions. Nevertheless, they still do not perform as effectively as BRCM\({}_{1}\), even though BRCM\({}_{1}\)'s parameter deviates from the theoretically optimal one. Within the BRCMs, BRCM\({}_{opt}\) exhibits remarkable performance and even surpasses the theoretically optimal instance BRCM\({}^{*}\). One possible explanation for the empirical sub-optimality of BRCM\({}^{*}\) is the stochastic nature of creators' response dynamics, which might prevent the convergence to PNE associated with the maximum welfare without sufficient optimization. This observation underscores the importance of Algorithm 2, as it empowers the platform to pinpoint an empirically optimal mechanism in more practical scenarios. As depicted in Figure 1(b), the primary source of advantage stems from the increased utility among minority and niche user groups: compared to \(M^{3}(expo.)\) and \(M^{3}(enga.)\), BRCM class results in higher average utility for groups 2 and 3 while preserving overall satisfaction for group-1.

Similar observations can be made for \(\mathcal{G}_{2}\). However, it is worth noting that BRCM\({}_{opt}\) underperformed slightly in comparison to BRCM\({}^{*}\) as shown in Figure 1(c). Despite this, the BRCM class of mechanisms continued to significantly surpass those in \(\mathcal{M}^{3}\). Figure 1(d) further highlights that BRCM mechanisms lead to a more equitable distribution of average user utility across different user groups. Nevertheless, the gap in comparison becomes less pronounced, which is probably due to the existence of costs. Creators burdened with such costs are inherently inclined towards serving specific user groups, making them less susceptible to the influence of platform's incentives.

## 7 Conclusion

Our work reveals an intrinsic limitation of the monotone reward principle, widely used by contemporary online content recommendation platforms to incentivize content creators, in optimizing social welfare. As a rescue, we introduce BRM, a novel class of reward mechanisms with several key advantages. First, BRM ensures a stable equilibrium in content creator competition, thereby fostering a consistent and sustainable content creation environment. Second, BRM can guide content creators' strategic responses towards optimizing social welfare, providing at least a local optimum for any given welfare metric. Finally, BRM offers a parameterized subspace that allows the platform to empirically optimize social welfare, enhancing platform performance dynamically.

For future work, we identify two potential directions. From a theoretical standpoint, it would be intriguing to ascertain whether a stronger welfare guarantee for BRM could be established when the scoring function is equipped with certain simple structures, e.g., dot product. On the empirical side, we look for developments of our suggested mechanism by addressing some practical considerations. For instance, how can we enhance the robustness of BRM to account for the estimation noise in relevance scores? And how can a platform optimize welfare subject to budget constraints? Deeper insights into these questions could significantly enhance our understanding of the rapidly evolving online content ecosystems.

Figure 2: Social welfare curve and average user utilities per group. Error bars represent half standard deviation range (0.5\(\sigma\)), and are generated from simulations on 10 randomly sampled game instances.

AcknowledgmentThis work is supported in part by an NSF Award CCF-2303372, IIS-2128019, and IIS-2007492, an Army Research Office Award W911NF-23-1-0030, and an Office of Naval Research Award N00014-23-1-2802.

## References

* [1] Kenneth J Arrow. A difficulty in the concept of social welfare. _Journal of political economy_, 58(4):328-346, 1950.
* [2] Omer Ben-Porat, Gregory Goren, Itay Rosenberg, and Moshe Tennenholtz. From recommendation systems to facility location games. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 33, pages 1772-1779, 2019.
* [3] Omer Ben-Porat and Moshe Tennenholtz. Shapley facility location games. In _International Conference on Web and Internet Economics_, pages 58-73. Springer, 2017.
* [4] Omer Ben-Porat and Moshe Tennenholtz. A game-theoretic approach to recommendation systems with strategic content providers. _Advances in Neural Information Processing Systems_, 31, 2018.
* [5] Jesus Bobadilla, Fernando Ortega, Antonio Hernando, and Abraham Gutierrez. Recommender systems survey. _Knowledge-based systems_, 46:109-132, 2013.
* [6] Nicholas Carr. _The shallows: What the Internet is doing to our brains_. WW Norton & Company, 2020.
* [7] Bruno De Borger and Kurt Van Dender. Prices, capacities and service levels in a congestible bertrand duopoly. _Journal of Urban Economics_, 60(2):264-283, 2006.
* [8] Jicong Fan and Jieyu Cheng. Matrix completion by deep matrix factorization. _Neural Networks_, 98:34-41, 2018.
* [9] Daniel Fleder and Kartik Hosanagar. Blockbuster culture's next rise or fall: The impact of recommender systems on sales diversity. _Management science_, 55(5):697-712, 2009.
* [10] Angela Glotfelter. Algorithmic circulation: how content creators navigate the effects of algorithms on their work. _Computers and composition_, 54:102521, 2019.
* [11] F Maxwell Harper and Joseph A Konstan. The movielens datasets: History and context. _Acm transactions on interactive intelligent systems (tiis)_, 5(4):1-19, 2015.
* [12] Thomas Hodgson. Spotify and the democratisation of music. _Popular Music_, 40(1):1-17, 2021.
* [13] Jiri Hron, Karl Krauth, Michael I Jordan, Niki Kilbertus, and Sarah Dean. Modeling content creator incentives on algorithm-curated platforms. _arXiv preprint arXiv:2206.13102_, 2022.
* [14] Meena Jagadeesan, Nikhil Garg, and Jacob Steinhardt. Supply-side equilibria in recommender systems. _arXiv preprint arXiv:2206.13489_, 2022.
* [15] Meta. Meta is experimenting with new monetization options for creators, 2022. https://www.digitalinformationworld.com/2022/03/meta-is-experimenting-with-new.html.
* [16] Dov Monderer and Lloyd S Shapley. Potential games. _Games and economic behavior_, 14(1):124-143, 1996.
* [17] Kun Qian and Sanjay Jain. Digital content creation: An analysis of the impact of recommendation systems. _Available at SSRN 4311562_, 2022.
* [18] Robert W Rosenthal. A class of games possessing pure-strategy nash equilibria. _International Journal of Game Theory_, 2:65-67, 1973.
* [19] Savy. Will the new youtube algorithm impact your content?, 2019. https://savyagency.com/new-youtube-algorithm/.

* [20] TikTok. What is the tiktok creator fund? here's how to join + start making money, 2022. https://www.backstage.com/magazine/article/tiktok-creator-fund-explained-how-to-join-75090/.
* [21] Takashi Ui. Robust equilibria of potential games. _Econometrica_, 69(5):1373-1380, 2001.
* [22] Hal R Varian and Christopher Harris. The vcg auction in theory and practice. _American Economic Review_, 104(5):442-445, 2014.
* [23] Fan Yao, Chuanhao Li, Denis Nekipelov, Hongning Wang, and Haifeng Xu. How bad is top-\(k\) recommendation under competing content creators? In _International Conference on Machine Learning_. PMLR, 2023.
* [24] Youtube. Youtube partner program overview & eligibility, 2023. https://support.google.com/youtube/answer/72851.
* [25] Piercarlo Zanchettin. Differentiated duopoly with asymmetric costs. _Journal of Economics \(\&\) Management Strategy_, 15(4):999-1015, 2006.

Supplementary Material

### Additional Examples of User Utility Function

Fix any user \(\bm{x}\in\mathcal{F}\), let \(\sigma_{i}=\sigma(\bm{s}_{i};\bm{x})\) and for simplicity of notations we assume \(\sigma_{1}\geq\cdots\geq\sigma_{n}\). As discussed in Section 3, if the platform presents the top-\(K\) ranked content in terms of their relevance quality, the user utility function has the following form:

\[W(\bm{s};\bm{x})=\sum_{k=1}^{n}r_{k}\sigma_{k},\] (9)

where \(\{r_{k}\}_{k=1}^{n}\) are the user's "attention" over the \(k\)-th ranked content such that \(r_{k}=0,\forall k\geq K+1\). We emphasize that our user utility model given in Eq.(9) is compatible with various matching strategies and here we provide additional examples that incorporate a modified version of the top-\(K\) approach, taking into account considerations of advertised content. For instance, considering a scenario where \(K=5\) and the platform intends to promote the content originally ranked at position \(6\) to position \(2\) with probability \(p\in(0,1)\). Consequently, the resulting utility function can be expressed as follows:

\[\tilde{W}_{j}(\bm{s}) =p(r_{1}\sigma_{1}+r_{2}\sigma_{6}+r_{3}\sigma_{2}+r_{4}\sigma_{3 }+r_{5}\sigma_{4})+(1-p)(r_{1}\sigma_{1}+r_{2}\sigma_{2}+r_{3}\sigma_{3}+r_{4 }\sigma_{4}+r_{5}\sigma_{5})\] \[=r_{1}\sigma_{1}+[pr_{3}+(1-p)r_{2}]\sigma_{2}+[pr_{4}+(1-p)r_{3} ]\sigma_{3}+[pr_{5}+(1-p)r_{4}]\sigma_{4}+(1-p)r_{5}\sigma_{5}+pr_{2}\sigma_{6}\] \[\triangleq\sum_{k=1}^{n}\tilde{r}_{k}\sigma_{k}.\]

This example shows that user utility function under any position-based perturbation of top-\(K\) ranking can be expressed in the form of Eq.(9), and in general the values of \(r_{k},k>K\) can be non-zero.

### Examples of \(\mathcal{M}^{3}\)

In this section we formally justify that the two examples given in Section 4 belong to the class of \(\mathcal{M}^{3}\).

1. When the creators' utilities are set to the total content exposure [2; 13; 14], we have \(M(\sigma_{i};\sigma_{-i})=\mathbb{I}[i\leq K]\frac{\exp(\beta^{-i}\sigma_{i})} {\sum_{j=1}^{K}\exp(\beta^{-1}\sigma_{j})}\), with a temperature parameter \(\beta>0\) controlling the spread of rewards. The validity of three merit-based properties are straightforward. In terms of monotonicity, we have \(\sum_{i=1}^{n}M(\sigma_{i};\sigma_{-i})=1\) which is a constant and thus monotone.
2. When the creators' utilities are set to the total user engagement [23], we have \(M(\sigma_{i};\sigma_{-i})=\mathbb{I}[i\leq K]\frac{\exp(\beta^{-1}\sigma_{i} )}{\sum_{j=1}^{K}\exp(\beta^{-1}\sigma_{j})}\pi(\sigma_{1},\cdots,\sigma_{n})\), where \(\pi(\sigma_{1},\cdots,\sigma_{n})=\beta\log\left(\sum_{j=1}^{K}\exp(\beta^{-1 }\sigma_{j})\right)\). The first two merit-based properties are obvious (Normality and Fairness). In terms of monotonicity, we have \(\sum_{i=1}^{n}M(\sigma_{i};\sigma_{-i})=\beta\log\left(\sum_{j=1}^{K}\exp( \beta^{-1}\sigma_{j})\right)\) which is monotone in each \(\sigma_{j}\). To verify negative externality, it suffices to show the function \(\frac{\log\left(\sum_{j=1}^{K}\exp(\beta^{-1}\sigma_{j})\right)}{\sum_{j=1}^ {K}\exp(\beta^{-1}\sigma_{j})}\) is decreasing in \(\sigma_{j},\forall j\). Since \(\exp(x)\) is increasing in \(x\), and function \(\frac{\log(t)}{t}\) is decreasing when \(t>e\), we conclude that \(M\) satisfies negative externality when \(n\geq 3\).

### Examples of BRM

To get an better intuition of how BRM works, let us consider a special case \(M\in\text{BRCM}\) such that \(f_{1}=\cdots=f_{K}=1\) and \(f_{k}=0,k\geq K+1\). By the definition, any matching score sequence \(\sigma_{1}\geq\cdots\geq\sigma_{n}\) will be mapped to a reward sequence of \((\sigma_{1}-\sigma_{K+1},\cdots,\sigma_{K}-\sigma_{K+1},0,\cdots,0)\). Consequently, the top-\(K\) ranked creators will experience a significant reduction in rewards if the \((K+1)\)-th ranked creator increases its matching score. This mechanism can deter an unnecessary concentration of creators on a specific strategy, as when the number of creators with high scores exceeds a certain threshold, even those ranked highly can receive a decreasing reward. This backward rewarding mechanism thus encourages diversity in content creation and mitigates the risk of oversaturation in any particular group of users.

Another notable special case within BRCM \(\in\) BRM is \(M^{SM}=M[1,\frac{1}{2},\cdots,\frac{1}{n}]\), which coincides with the Shapley mediator proposed in [4]. One key feature of \(M^{SM}\) is that for any sequence \(1\geq\sigma_{1}\geq\cdots\geq\sigma_{n}\geq 0\), it holds that \(\sum_{i=1}^{n}M^{SM}(\sigma_{i};\sigma_{-i})=\sigma_{1}\leq 1\). This implies that the platform can avoid providing explicit incentives and merely implement these rewards as matching probabilities. However, to do so, it must accommodate the possibility of not matching a user with any creators, corresponding to a probability of \(1-\sigma_{1}\). Furthermore, it does not support the top-\(K\) ranking strategy.

A more comprehensive understanding about the construction of BRM can be obtained through the lens of congestion games. As pointed out by [16], every finite potential game is isomorphic to a congestion game. Furthermore, the definition of \(M\) as outlined in Eq.(5) can be interpreted as the utility that creator \(i\) acquires from the following congestion game:

1. The set of congestible elements are given by the continuum \(E=\mathcal{X}\times[0,1]\), where each element \((\bm{x},t)\triangleq\bm{e}\in E\) corresponds to a user \(\bm{x}\) with satisfaction level \(t\).
2. The \(n\) players are \(n\) content creators.
3. Each creator's pure action \(\bm{s}_{i}\in\mathcal{S}_{i}\) can be mapped to a subset of \(E\) in the following way: the action \(\bm{s}_{i}\) determines the matching score \(\sigma(\bm{s}_{i};\bm{x})\) over each \(\bm{x}\in\mathcal{X}\), and then \(\bm{s}_{i}\) is mapped to a subset \(\{(\bm{x},t)|\bm{x}\in\mathcal{X},t\in[0,\sigma(\bm{s}_{i};\bm{x})]\}\triangleq S _{i}\subseteq E\).
4. For each element \(\bm{e}\) and a vector of strategies \((S_{1},\cdots,S_{n})\), the load of element \(\bm{e}\) is defined as \(x_{\bm{e}}=\#\{i:\bm{e}\in S_{i}\}\), i.e., the number of players who occupy \(\bm{e}\).
5. For each element \(\bm{e}\), there is a payoff function \(d_{\bm{e}}:\mathbb{N}\rightarrow\mathbb{R}_{\geq 0}\) that only depends on the load of \(\bm{e}\).
6. For any joint strategy \((S_{1},\cdots,S_{n})\), the utility of player \(i\) is given by \(\sum_{\bm{e}\in S_{i}}d_{\bm{e}}(x_{\bm{e}})\), i.e., the sum of reward he/she collects from all occupied elements. For each occupied element \(\bm{e}\), the reward is determined by its "congestion" level \(x_{\bm{e}}\), which is characterized by the payoff function \(d_{\bm{e}}\).

To better understand the constructed congestion game and the utility definition given in Eq.(5), we can consider each element in \(E\) (i.e., a user with a particular satisfaction level) as an atomic "resource". Each production strategy adopted by an individual creator can be thought of as occupying a subset of these resources. Given a fixed strategy profile, the load of \(\bm{e}=(\bm{x},t)\) is determined by the number of creators who achieve a matching score exceeding \(t\) for user \(\bm{x}\), thereby linking the ranking of each creator in the matching score sequence for \(\bm{x}\). Consequently, we can reformulate the utility for a creator who is ranked in the \(i\)-th position for user \(\bm{x}\) as

\[\sum_{\bm{e}\in S_{i}}d_{\bm{e}}(x_{\bm{e}}) =\sum_{t\in[0,\sigma(\bm{s}_{i};\bm{x})]}d_{t}(x_{\bm{e}})=\sum_ {k=i}^{n}\sum_{t\in[\sigma(\bm{s}_{k+1};\bm{x}),\sigma(\bm{s}_{k};\bm{x})]}d_{ t}(x_{\bm{e}})\] (10) \[=\sum_{k=i}^{n}\sum_{t\in[\sigma(\bm{s}_{k+1};\bm{x}),\sigma(\bm{ s}_{k};\bm{x})]}d_{t}(k)\] \[\triangleq\sum_{k=i}^{n}\int_{\sigma_{k+1}}^{\sigma_{k}}f_{k}(t)dt.\]

Eq.(10) holds because for any resource \(\bm{e}=(\bm{x},t)\) such that \(t\in[\sigma(\bm{s}_{k+1};\bm{x}),\sigma(\bm{s}_{k};\bm{x})]\), the load of \(\bm{e}\) is exactly given by \(k\). As a result, by letting \(f_{k}(t)=d_{t}(k)\), we recover the utility function defined in Eq.(5), where the value of function \(f_{i}(t)\) at \(t=t_{0}\) indicates the atomic reward for each creator if his/her strategy covers "resource" \((\bm{x},t_{0})\), given that there are exactly \(i\) creators occupy \((\bm{x},t_{0})\). This relationship also rationalizes why it is natural to assume that \(f_{1}\geq\cdots\geq f_{n}\): as an increase in competition for the same resource from multiple creators should correspondingly reduce the return that can be accrued from that resource.

### Proof of Theorem 1

Before showing the proof, we define the following notion of _local_ maximizer:

**Definition 4**.: _We say \(\bm{s}=(\bm{s}_{1},\cdots,\bm{s}_{n})\) is a local maximizer of \(W(\bm{s})\) if for any \(i\in[n]\) and any \(\bm{s}_{i}^{\prime}\in\mathcal{S}_{i}\),_

\[W(\bm{s}_{1},\cdots,\bm{s}_{i},\cdots,\bm{s}_{n})\geq W(\bm{s}_{1},\cdots,\bm{ s}_{i}^{\prime},\cdots,\bm{s}_{n}).\]

_The set of all the local maximizers of \(W\) is denoted by \(Loc(W)\)._According to the definition, for any join strategy profile \(\bm{s}\in Loc(W)\), no creator can unilaterally change his/her strategy to increase the value of function \(W\). And clearly we have \(\arg\max_{\bm{s}\in\mathcal{S}}W(\bm{s})\in Loc(W)\). To simplify notation we define \(\pi(\sigma_{1},\cdots,\sigma_{n})=\sum_{i=1}^{n}M(\sigma_{i};\sigma_{-i})\). Now we are ready to present the proof of Theorem 1. To avoid complex notations, with a slight abuse of notation we use \(M(\sigma_{1},\sigma_{2},\cdots,\sigma_{n})\) to denote \(M(\sigma_{1};\{\sigma_{2},\cdots,\sigma_{n}\})\) in the following proof.

Proof.: We start by showing that any TvN game instance with \(M\in\mathcal{M}^{3}\) possesses a unique NE at \(\bm{s}^{*}=(\bm{e}_{1},\cdots,\bm{e}_{1})\). It suffices to show that:

1. For any joint strategy profile \((\bm{s}_{1},\cdots,\bm{s}_{n})\) in which there are \(k<n\) creators occupy \(\bm{e}_{1}\), there exists a creator who can receive a strict utility gain if she change her strategy to \(\bm{e}_{1}\).
2. At \(\bm{s}^{*}=(\bm{e}_{1},\cdots,\bm{e}_{1})\), any player would suffer a utility loss when changing her strategy.

For the first claim, suppose there are \(k\) players in \(\bm{s}\) who play \(\bm{e}_{1}\) and let \(i\) be any player who does not play \(\bm{e}_{1}\). In addition, there are \(t\leq n-k\) players who play the same strategy as \(\bm{s}_{i}\). By the definition of \(M_{3}\), we have

\[u_{i}(\bm{s}_{i};\bm{s}_{-i}) =1\cdot M(\underbrace{1,\cdots,1}_{t},\underbrace{0,\cdots,0}_{n- t})+(n+1)\cdot M(\underbrace{0,\cdots,0}_{n-k},\underbrace{1,\cdots,1}_{k})\] \[=1\cdot\frac{1}{t}\cdot\pi(\underbrace{1,\cdots,1}_{t}, \underbrace{0,\cdots,0}_{n-t})+(n+1)\cdot 0\] \[=\frac{1}{t}\cdot\pi(\underbrace{1,\cdots,1}_{t},\underbrace{0, \cdots,0}_{n-t}).\] (11)

If player-\(i\) changes her strategy from \(\bm{s}_{i}\) to \(\bm{s}^{\prime}_{i}=\bm{e}_{1}\), the new utility would be

\[u_{i}(\bm{s}^{\prime}_{i};\bm{s}_{-i}) =(n+1)\cdot M(\underbrace{1,\cdots,1}_{k+1},\underbrace{0, \cdots,0}_{n-k-1})+\sum_{j\neq i}1\cdot M(0,\cdots)\] \[=(n+1)\cdot\frac{1}{k+1}\cdot\pi(\underbrace{1,\cdots,1}_{k+1}, \underbrace{0,\cdots,0}_{n-k-1})+0\] \[=\frac{n+1}{k+1}\cdot\pi(\underbrace{1,\cdots,1}_{k+1}, \underbrace{0,\cdots,0}_{n-k-1}),\] (12)

From Eq.(11) and Eq.(12), \(u_{i}(\bm{s}^{\prime}_{i};\bm{s}_{-i})>u_{i}(\bm{s}_{i};\bm{s}_{-i})\) holds if and only if

\[\frac{1}{t}\cdot\pi(\underbrace{1,\cdots,1}_{t},\underbrace{0,\cdots,0}_{n-t}) <\frac{n+1}{k+1}\cdot\pi(\underbrace{1,\cdots,1}_{k+1},\underbrace{0,\cdots,0 }_{n-k-1}).\] (13)

And a sufficient condition for Eq.(13) to hold is

\[m=2n>n-1+\max_{0\leq k\leq n-1}\left\{\frac{k+1}{t}\cdot\frac{\pi(\overbrace{ 1,\cdots,1}^{t},\overbrace{0,\cdots,0}^{n-t})}{\pi(\underbrace{1,\cdots,1}_{k +1},\underbrace{0,\cdots,0}_{n-k-1})}\right\}.\] (14)

Denote \(\tilde{\pi}_{k}=\pi(\underbrace{1,\cdots,1}_{k},\underbrace{0,\cdots,0}_{n-k})\). By the monotonicity of \(\pi\), we have \(\tilde{\pi}_{n}\geq\cdots\geq\tilde{\pi}_{1}=M(1,0,\cdots,0)>0\). Therefore, the RHS of Eq.(14) is a finite number. Moreover, when \(t\leq k+1\), we have

\[\frac{k+1}{t}\cdot\frac{\tilde{\pi}_{t}}{\tilde{\pi}_{k+1}}\leq\frac{k+1}{t} \cdot\frac{\tilde{\pi}_{k+1}}{\tilde{\pi}_{k+1}}\leq\frac{n-1+1}{1}=n,\]and when \(t>k+1\), based on the negative externality principle of merit-based rewarding mechanism we have

\[\frac{k+1}{t}\cdot\frac{\tilde{\pi}_{t}}{\tilde{\pi}_{k+1}}=\frac{M( \overbrace{1,\cdots,1}^{t},\overbrace{0,\cdots,0}^{t-t})}{M(\underbrace{1, \cdots,1}_{k+1},\underbrace{0,\cdots,0}_{n-k-1})}\leq 1.\]

Therefore, the RHS of Eq.(14) is strictly less than \(2n-1\).

For the second claim, we have

\[u_{i}(\bm{s}_{i}^{*};\bm{s}_{-i}^{*})=\frac{n+1}{n}\tilde{\pi}_{n},\]

and if player-\(i\) changes her strategy from \(\bm{s}_{i}^{*}=\bm{e}_{1}\) to any \(\bm{s}_{i}^{\prime}=\bm{e}_{j},j\neq 1\), her new utility becomes

\[u_{i}(\bm{s}_{i}^{\prime};\bm{s}_{-i}^{*})=\tilde{\pi}_{1}\leq \tilde{\pi}_{n}<\frac{n+1}{n}\tilde{\pi}_{n}=u_{i}(\bm{s}_{i}^{*};\bm{s}_{-i}^ {*}).\]

Therefore, we conclude that \(\bm{s}^{*}=(\bm{e}_{1},\cdots,\bm{e}_{1})\) is the unique NE of \(\mathcal{G}\).

Next we estimate the welfare loss of \(\bm{s}^{*}\) under any sequence \(\{r_{i}\}_{i=1}^{K}\). First of all, note that for any \(\bm{s}=(\bm{s}_{1},\cdots,\bm{s}_{n})\in Loc(W)\) and any \(2\leq k\leq n\), if there exists \(i\neq j\) such that \(\bm{s}_{i}=\bm{s}_{j}=\bm{e}_{k}\), then there must be \(k^{\prime}\in[n]\) such that \(\bm{e}_{k^{\prime}}\notin\bm{s}_{j}\). In this case, \(W\) strictly increases if \(\bm{s}_{j}\) changes to \(\bm{e}_{k^{\prime}}\). Therefore, for any \(2\leq k\leq n\), the number of elements in \(\bm{s}\) that equal to \(\bm{e}_{k}\) is either 0 or 1. Let the number of elements in \(\bm{s}\) that equal to \(\bm{e}_{1}\) be \(q\). By definition,

\[W(\bm{s}) =(n+1)\sum_{i=1}^{\min(K,q)}r_{i}+(n-q)r_{1},\] (15) \[W(\bm{s}^{*}) =(n+1)\sum_{i=1}^{K}r_{i}.\]

Since \(q\) maximizes the RHS of Eq.(15), we have \(1\leq q\leq K\) and \((n+1)r_{q+1}\leq r_{1}\leq(n+1)r_{q}\). Therefore,

\[\frac{\max_{\bm{s}\in\mathcal{S}}W(\bm{s})}{W(\bm{s}^{*})} \geq\frac{\min_{\bm{s}\in Loc(W)}W(\bm{s})}{W(\bm{s}^{*})}\] \[\geq\frac{(n+1)\sum_{i=1}^{\min(K,q)}r_{i}+(n-q)r_{1}}{(n+1)\sum_ {i=1}^{K}r_{i}}\] \[\geq\frac{(n+1)\sum_{i=1}^{q}r_{i}+(n-q)r_{1}}{(n+1)\sum_{i=1}^{q }r_{i}+(K-q)r_{1}}\] \[=1+\frac{(n-K)r_{1}}{(n+1)\sum_{i=1}^{q}r_{i}+(K-q)r_{1}}\] \[\geq 1+\frac{(n-K)r_{1}}{[(n+1)q+(K-q)]r_{1}}\] \[\to 1-\frac{1+1/q}{1+nq/K}+\frac{1}{q},n\to\infty.\]

Since \(1\leq q\leq K\), we conclude that \(\frac{\max_{\bm{s}\in\mathcal{S}}W(\bm{s})}{W(\bm{s}^{*})}>1-O(\frac{1}{n})+ \frac{1}{K}\) when \(n\) is sufficiently large. And therefore we conclude that

\[\frac{W(\bm{s}^{*})}{\max_{\bm{s}\in\mathcal{S}}W(\bm{s})}\leq \frac{K}{K+1}+O\left(\frac{1}{n}\right).\]

### Proof of Proposition 1

Proof.: To prove that any \(M\in\text{BRM}\) is merit-based, we need to verify the following by definition:

1. \(M(0;\sigma_{-i})=\int_{0}^{0}f_{n}(t)dt=0\), \(M(1;\{0,\cdots,0\})=\int_{0}^{1}f_{1}(t)dt>0\).
2. \(M(\sigma_{i};\sigma_{-i})-M(\sigma_{j};\sigma_{-j})=\sum_{k=j}^{i-1}\int_{ \sigma_{k+1}}^{\sigma_{k}}f_{k}(t)dt\geq 0\).
3. for any \(\{\sigma_{j}\}_{j=1}^{n},\{\sigma_{j}^{\prime}\}_{j=1}^{n}\) such that \(\sigma_{-i}\preccurlyeq\sigma_{-i}^{\prime}\), we can transform \(\{\sigma_{j}\}_{j=1}^{n}\) to \(\{\sigma_{j}^{\prime}\}_{j=1}^{n}\) by taking finite steps of the following operations: 1. increase a certain value of \(\sigma_{j},j\neq i\) to \(\tilde{\sigma}_{j}\) and it does not change the order of the current sequence; 2. increase a certain value of \(\sigma_{j},j\neq i\) to \(\tilde{\sigma}_{j}\), and \(\sigma_{i}\)'s ranking position decreases after this change. We will show that after each operation the value of \(M(\sigma_{i},\cdot)\) under the perturbed sequence does not increase. Let the perturbed sequence be \(\tilde{\sigma}\). For the first type of operation, if \(j<i\), we have \(M(\sigma_{i};\tilde{\sigma}_{-i})=M(\sigma_{i};\sigma_{-i})\). If \(j>i\), we have \[M(\sigma_{i};\tilde{\sigma}_{-i})-M(\sigma_{i};\sigma_{-i}) =\int_{\tilde{\sigma}_{j}}^{\sigma_{-1}}f_{j-1}(t)dt+\int_{ \sigma_{j+1}}^{\tilde{\sigma}_{j}}f_{j}(t)dt-\int_{\sigma_{j}}^{\sigma_{j-1} }f_{j-1}(t)dt-\int_{\sigma_{j+1}}^{\sigma_{j}}f_{j}(t)dt\] \[=\int_{\sigma_{j}}^{\tilde{\sigma}_{j}}(f_{j}-f_{j-1})(t)dt\leq 0.\] For the second type of operation, with out loss of generality let's assume \(\sigma_{i+1}\) has increased to \(\tilde{\sigma}_{i+1}\) such that \(\sigma_{i}\leq\tilde{\sigma}_{i+1}\leq\sigma_{i-1}\). In this case we have \[M(\sigma_{i};\tilde{\sigma}_{-i})-M(\sigma_{i};\sigma_{-i}) =\int_{\sigma_{i+2}}^{\sigma_{i}}f_{i+1}(t)dt-\int_{\sigma_{i+1}} ^{\sigma_{i}}f_{i}(t)dt-\int_{\sigma_{i+2}}^{\sigma_{i+1}}f_{i+1}(t)dt\] \[=\int_{\sigma_{i+1}}^{\sigma_{i}}(f_{i+1}-f_{i})(t)dt\leq 0.\] Therefore, \(M\) is merit-based. On the other hand, there exist instances in BRM that are not monotone. For example, if we let \(f_{1}(t)=1\) and \(f_{k}(t)=0,\forall k\geq 2\). Then we have \[M(1,0,0,\cdots,0) =\int_{0}^{1}f_{1}(t)dt>0,\] \[M(1,1,0,\cdots,0) =\int_{0}^{0}f_{1}(t)dt+\int_{0}^{1}f_{2}(t)dt=0.\] As a result, \(\pi(1,0,0,\cdots,0)>0=\pi(1,1,0,\cdots,0)\), which violates monotonicity. 

### Proof of Theorem 2

Proof.: For the first claim, consider the potential function of the following form:

\[P(\bm{s})=\mathbb{E}_{\bm{x}\in\mathcal{F}}\left[\sum_{i=1}^{n}\int_{0}^{ \sigma_{l(i)}(\bm{x})}f_{i}(t)dt\right]-\sum_{i=1}^{n}c_{i}(\bm{s}_{i}),\]

where \(\sigma_{i}(\bm{x})=\sigma(\bm{s}_{i};\bm{x})\) and \(\{l(i)\}_{i=1}^{n}\) is a permutation such that \(\sigma_{l(1)}(\bm{x})\geq\sigma_{l(2)}(\bm{x})\geq\cdots\geq\sigma_{l(n)}(\bm{ x})\).

By the definition of potential games, we need to verify that for any set of functions \(\{f_{i}\}\) and a strategy pair \(\bm{s}_{i},\bm{s}_{i}^{\prime}\in\mathcal{S}_{i}\) for player-\(i\), it holds that

\[u_{i}(\bm{s}_{i}^{\prime},\bm{s}_{-i})-u_{i}(\bm{s}_{i},\bm{s}_{-i})=P(\bm{s}_{ i}^{\prime},\bm{s}_{-i})-P(\bm{s}_{i},\bm{s}_{-i}).\] (16)

For any user \(\bm{x}\in\mathcal{F}\), let \(\sigma_{i}=\sigma(\bm{s}_{i};\bm{x}_{j}),\sigma_{i}^{\prime}=\sigma(\bm{s}_{i}^{ \prime};\bm{x}),\forall i\in[n]\). It suffices to show that

\[M(\sigma_{i};\sigma_{-i})-M(\sigma_{i}^{\prime};\sigma_{-i})=\sum_{i=1}^{n} \int_{0}^{\sigma_{l(i)}}f_{i}(t)dt-\sum_{i=1}^{n}\int_{0}^{\sigma_{l(i)}^{ \prime}}f_{i}(t)dt.\] (17)Since the expectation of Eq.(17) over \(\bm{x}\in\mathcal{F}\) yields Eq.(16), we focus on the verification of Eq.(17). With out loss of generality, we also assume \(\sigma_{1}\geq\cdots\geq\sigma_{i^{\prime}}\geq\cdots\geq\sigma_{i}\geq\cdots\geq \sigma_{n}\). After player-\(i\) changes her strategy from \(\bm{s}_{i}\) to \(\bm{s}_{i}^{\prime}\), the relevance ranking increases from \(i\) to \(i^{\prime}\), i.e., \(\sigma_{1}\geq\cdots\geq\sigma_{i^{\prime}-1}\geq\sigma_{i}^{\prime}\geq\sigma _{i^{\prime}}\geq\cdots\geq\sigma_{n}\).

Therefore, we have

LHS of Eq.(17) \[=\int_{\sigma_{i^{\prime}}}^{\sigma_{i^{\prime}}^{\prime}}f_{i^{ \prime}}(t)dt+\sum_{k=i^{\prime}+1}^{n}\int_{\sigma_{k-1}}^{\sigma_{k}}f_{k}(t )dt,\] (18) RHS of Eq.(17) \[=\sum_{k=1}^{n}\int_{0}^{\sigma_{k}}f_{k}(t)dt-\left(\sum_{k=1}^{ i^{\prime}-1}\int_{0}^{\sigma_{k}}f_{k}(t)dt+\int_{0}^{\sigma_{i}^{\prime}}f_{i^{ \prime}}(t)dt+\sum_{k=i^{\prime}+1}^{n}\int_{0}^{\sigma_{k-1}}f_{k}(t)dt\right)\] \[=\int_{0}^{\sigma_{i^{\prime}}^{\prime}}f_{i^{\prime}}(t)dt+\sum_ {k=i^{\prime}+1}^{n}\int_{0}^{\sigma_{k}}f_{k}(t)dt-\int_{0}^{\sigma_{i}^{ \prime}}f_{i^{\prime}}(t)dt-\sum_{k=i^{\prime}+1}^{n}\int_{0}^{\sigma_{k-1}}f_{ k}(t)dt\] \[=\int_{\sigma_{i^{\prime}}^{\prime}}f_{i^{\prime}}(t)dt+\sum_{k=i ^{\prime}+1}^{n}\int_{\sigma_{k-1}}^{\sigma_{k}}f_{k}(t)dt.\]

Hence, Eq.(17) holds for any \(j\) which completes the proof.

For the second claim, we can verify that when \(f_{i}=r_{i},\forall i\),

\[P(\bm{s}) =\mathbb{E}_{\bm{x}\in\mathcal{F}}\left[\sum_{i=1}^{n}\int_{0}^{ \sigma_{l(i)}(\bm{x})}f_{i}(t)dt\right]-\sum_{i=1}^{n}c_{i}(\bm{s}_{i})\] \[=\mathbb{E}_{\bm{x}\in\mathcal{F}}\left[\sum_{i=1}^{n}r_{i}\sigma _{l(i)}(\bm{x})\right]-\sum_{i=1}^{n}c_{i}(\bm{s}_{i})\] \[=\mathbb{E}_{\bm{x}\in\mathcal{F}}\left[W(\bm{s};\bm{x})\right]- \sum_{i=1}^{n}c_{i}(\bm{s}_{i})\] \[=W(\bm{s}).\]

### Proof of Corollary 1

Proof.: We show that any TvN game instance \(\mathcal{G}\) with \(M=M[r_{1},\cdots,r_{K},0,\cdots,0]\in\text{BRCM}\) possesses a unique NE \(\bm{s}^{*}\) which maximizes \(W(\bm{s})\). From Theorem 2 we know that under \(M\), \(\mathcal{G}\) is a potential game and its potential function \(P\) is identical to its welfare function \(W\). Therefore, any PNE of \(\mathcal{G}\) belongs to \(Loc(W)\). Next we show that all elements in \(Loc(W)\) yield the same value of \(W\), thus any PNE of \(\mathcal{G}\) maximizes social welfare \(W\).

First of all, note that for any \(\bm{s}=(\bm{s}_{1},\cdots,\bm{s}_{n})\in Loc(W)\) and any \(2\leq k\leq n\), if there exists \(i\neq j\) such that \(\bm{s}_{i}=\bm{s}_{j}=\bm{e}_{k}\), then there must exist \(k^{\prime}\in[n]\) such that \(\bm{e}_{k^{\prime}}\notin\bm{s}_{j}\). In this case, \(W\) strictly increases if \(\bm{s}_{j}\) changes strategy to \(\bm{e}_{k^{\prime}}\). Therefore, for any \(2\leq k\leq n\), the number of elements in \(\bm{s}\) that equal to \(\bm{e}_{k}\) is either 0 or 1. Let the number of elements in \(\bm{s}\) that equal to \(\bm{e}_{1}\) be \(q\). By definition, the welfare function writes

\[W(\bm{s})=(n+1)\sum_{i=1}^{\min(K,q)}r_{i}+(n-q)r_{1}.\] (19)

It is clear that the \(q\) that maximizes Eq.(19) satisfies \(1\leq q\leq K\) and \((n+1)r_{q+1}\leq r_{1}\leq(n+1)r_{q}\), and all such \(q\) yields the same objective value of \(W\). Therefore, we conclude that any PNE of \(\mathcal{G}\) attains the optimal social welfare \(W\). 

### Content Creator Response Simulator

Algorithm 1 functions as follows: at each step, a random creator \(i\) selects a random improvement direction \(\bm{g}_{i}\). If creator \(i\) discovers that adjusting her strategy in this direction yields a higher utility,she updates her strategy along \(\bm{g}_{i}\); otherwise, she retains her current strategy. This approach is designed to more closely mimic real-world scenarios where content creators may not have full access to their utility functions, but instead have to perceive them as black boxes. While they may aim to optimize their responses to the current incentive mechanism, identifying a new strategy that definitively increases their utilities can be challenging. Therefore, we model their strategy evolution as a trial-and-exploration process. We should note that the specifics of the simulator are not critical to our proposed solution: the optimizer can select any equilibrium-finding dynamic to replace our Algorithm 1, as long as it is believed to better represent creators' responses in reality.

### Optimization Algorithm

Our proposed welfare optimization algorithm is presented in Algorithm 2, which is organized into \(L_{1}\) epochs. Each epoch starts with a random perturbation of the current mechanism \(M\) within the feasible polytope and conducts simulations of creators' responses for \(L_{2}\) steps using the simulator specified in Algorithm 1. Welfare is reassessed at the conclusion of each epoch, and the perturbation applied to \(M\) is adopted if it yields an increase in welfare.

``` Input: Time horizon \(T=L_{1}L_{2}\), learning rate \(\eta_{1},\eta_{2}\), \((u_{i}(\bm{s}),\mathcal{S}_{i})\) for each creator. Initialization: Unit basis \(\{\bm{e}_{i}\}_{i=1}^{n}\) in \(\mathbb{R}^{n}\), initial strategy profile \(\bm{s}^{(0)}=(\bm{s}_{1}^{(0)},\cdots,\bm{s}_{n}^{(0)})\), initial parameter \(\bm{f}^{(0)}=(f_{1}^{(0)},\cdots,f_{n}^{(0)})\in\mathcal{F}\) and mechanism \(M[\bm{f}^{(0)}]\). for\(t=0\)to\(L_{1}-1\)do  Generate \(i\in[n]\) and \(\bm{g}_{i}\in\{-\bm{e}_{i},\bm{e}_{i}\}\) uniformly at random.  Update \(\bm{f}_{i}^{(t+\frac{1}{2})}\) as the projection of \(\bm{f}_{i}^{(t)}+\eta_{1}\bm{g}_{i}\) on \(\mathcal{F}\).  Simulate \(\bm{s}^{(t+1)}=\)sim\(\bm{s}\)\(\bm{s}\)\((\bm{s}^{(t)};L_{2},\eta_{2},\{\bm{u}_{i},\mathcal{S}_{i}\}_{i=1}^{n},M[\bm{f}^{(t+ \frac{1}{2})}])\). // Implemented by Algo. 1 if\(W(\bm{s}^{(t+1)})>W(\bm{s}^{(t)})\)then \(\bm{f}^{(t+1)}=\bm{f}^{(t+\frac{1}{2})}\). else \(\bm{f}^{(t+1)}=\bm{f}^{(t)}\). ```

**Algorithm 2** Optimize \(W\) in BRCM

### Additional Experiments

\(\bullet\)**Experiments using MovieLens-1m** We use deep matrix factorization [8] to train user and movie embeddings predicting movie ratings from 1 to 5 and use them to construct the user population \(\mathcal{X}\) and creators' strategy set \(\{\mathcal{S}_{i}\}\). The dataset contains \(6040\) users and \(3883\) movies in total, and the embedding dimension is set to \(d=32\). To validate the quality of the trained representation, we first performed a 5-fold cross-validation and obtain an averaged RMSE \(=0.739\) on the test sets, then train the user/item embeddings with the complete dataset.

To construct a more challenging environment for creators, we avoid using movies that are excessively popular and highly rated or users who are overly active and give high ratings to most movies. Thisensures that the strategy of "producing popular content for the majority of active users" does not become a dominant strategy under any rewarding mechanism. Thus, we filtered out users and movies who have more than 500 predicted ratings higher than 4. After the filtering, we have a user population with size \(|\mathcal{X}|=2550\) and movie set of size \(1783\). The user distribution are set to uniform distribution over \(\mathcal{X}\), and the remaining movies become the action set \(\{\mathcal{S}_{i}\}\) for each creator-\(i\) of \(n=10\) creators. To normalize the relevance score to \([0,1]\), we set \(\sigma(\bm{s},\bm{x})=\text{clip}(\langle\bm{s},\bm{x}\rangle/2.5-1,0,1)\). \(\{r_{i}\}_{i=1}^{n}\) is set to \(\{\frac{1}{\log_{2}(2)},\frac{1}{\log_{3}(3)},\frac{1}{\log_{2}(4)},\frac{1}{ \log_{2}(5)},\frac{1}{\log_{2}(6)},0,\cdots,0\}\). We also consider two types of game instances, namely \(\mathcal{G}_{1}\) and \(\mathcal{G}_{2}\), as we elaborated on in Section 6.1. Specifically, in \(\mathcal{G}_{1}\) creators' initial strategies are set to the most popular movie among all users (i.e., the movie that enjoys the highest average rating among \(\mathcal{X}\)) and the cost functions are set to be zero. In \(\mathcal{G}_{2}\), we set creators' cost functions to \(c_{i}=10\|\bm{s}_{i}-\bar{\bm{s}}_{i}\|_{2}^{2}\) and let creator \(i\) start at the cost center \(\bar{\bm{s}}_{i}\). \(\{\bar{\bm{s}}_{i}\}_{i=1}^{n}\) are sampled at random from all the movies.

For each baseline in Section 6.2, we plot the welfare curve over \(T=500\) steps using Algorithm 1 and also the average user utility distribution at the end of simulations. The parameters of Algorithm 2 are set to \(L_{1}=100,L_{2}=5,\eta_{1}=0.5,\eta_{2}=0.1,\bm{f}^{(0)}=(1,1,1,1,1,0,\cdots,0)\). The results are presented in Figure 3.

The new results obtained reinforce the findings presented in Section 6. In both the \(\mathcal{G}_{1}\) and \(\mathcal{G}_{2}\) environments, the BRCM family continues to outperform \(\mathcal{M}^{3}\) overall. Specifically, \(\text{BRCM}_{opt}\), \(\text{BRCM}_{1}\), and \(\text{BRCM}^{\prime}\) consistently demonstrate strong performance in social welfare, highlighting the robustness of BRCM across different environments. When creators initially adopt the most popular strategy in \(\mathcal{G}_{1}\), \(M^{3}(0)\) does not yield any improvement since no creator would change their strategy in such a situation under \(M^{3}(0)\). In the case of \(\mathcal{G}_{2}\), the advantage of BRCM over \(\mathcal{M}^{3}\) diminishes slightly, which aligns with our observations from the synthetic dataset. The main reason is that the cost function discourages creators to deviate from their default strategies. Additionally, Figure 2(b) provides further evidence that the welfare gain achieved by BRCM arises from enhanced utility for a wider range of users.

Figure 3: Social welfare curve and average user utilities under two different environments. Error bars represent \(0.2\) standard deviation range, and they are generated from 10 independent runs. Game instances are generated from MovieLens-1m dataset.