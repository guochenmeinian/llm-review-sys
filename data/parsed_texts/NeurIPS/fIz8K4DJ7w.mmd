# Rethinking the Diffusion Models for Missing Data Imputation: A Gradient Flow Perspective

 Zhichao Chen\({}^{1}\) Haoxuan Li\({}^{2}\) Fangyikang Wang\({}^{1}\) Odin Zhang\({}^{3}\) Hu Xu\({}^{1}\)

Xiaoyu Jiang\({}^{1}\) Zhihuan Song\({}^{1,4}\) Hao Wang\({}^{1}\)\({}^{*}\)

\({}^{1}\)Zhejiang University \({}^{2}\)Peking University \({}^{3}\)University of Washington

\({}^{4}\)Guangdong University of Petrochemical Technology

12032042@zju.edu.cn hxli@stu.pku.edu.cn wangfangyikang@zju.edu.cn odinz@uw.edu hxu_zju@zju.edu.cn jiangxiaoyu@zju.edu.cn songzhihuan@zju.edu.cn haohaow@zju.edu.cn

Corresponding author.

###### Abstract

Diffusion models have demonstrated competitive performance in missing data imputation (MDI) task. However, directly applying diffusion models to MDI produces suboptimal performance due to two primary defects. First, the sample diversity promoted by diffusion models hinders the accurate inference of missing values. Second, data masking reduces observable indices for model training, obstructing imputation performance. To address these challenges, we introduce Negative Entropy-regularized Wasserstein gradient flow for Imputation (NewImp), enhancing diffusion models for MDI from a gradient flow perspective. To handle the first defect, we incorporate a negative entropy regularization term into the cost functional to suppress diversity and improve accuracy. To handle the second defect, we demonstrate that the imputation procedure of NewImp, induced by the conditional distribution-related cost functional, can equivalently be replaced by that induced by the joint distribution, thereby naturally eliminating the need for data masking. Extensive experiments validate the effectiveness of our method. Code is available at https://github.com/JustusvLiebig/NewImp.

## 1 Introduction

Missing data is a pervasive problem for data analytics in diverse scenarios, including e-commerce [29, 30, 57], healthcare [51, 56], and process industry [33, 58]. For instance, in healthcare, patient monitoring devices may fail or lose connection, leading to missing vital signs data. Similarly, in industrial processes, sensor signals may be incomplete due to inevitable mechanical shock. These incompletenesses hamper data integrity and impede subsequent analysis. Therefore, accurate missing data imputation (MDI) is critical for enabling reliable analysis and decision in real-world applications.

Recently, diffusion models (DMs) have emerged as a powerful tool for MDI [66]. Specifically, these models first estimate the (Stein) score function of the missing data conditioned on the observed data, subsequently reformulating the imputation problem as a generative task grounded in the learned score function. These works are initiated from [51] and evolve to incorporate crafted model architecture [33] and learning objectives [38, 73] for enhancing the accuracy of score estimation [41]. Celebrated for their advantageous capability to model data distributions and generate high-quality synthetic data [41, 50, 65], diffusion models have been a prevalent approach to MDI.

Despite the successes of diffusion models, we argue that directly applying diffusion models to MDI results in suboptimal performance due to two primary limitations. First, diffusion models performimputation by sampling from a learned score function, which inadvertently promotes diversity in the imputed values. This increased diversity contradicts the accuracy required for precise imputation of missing data [38]. Second, the training process involves masking a portion of the observed data as labels. The selection of masking strategy significantly impacts imputation accuracy and is inherently challenging to optimize [51]. Moreover, the masked data during training often differ in missing mechanisms from those encountered during testing, resulting in a discrepancy between training and inference phases that degrades performance. Consequently, diffusion models introduce unintended diversity and impose data masking, both of which impede effective imputation.

To tackle these challenges, we introduce a novel DM-based MDI approach termed Negative Entropy-regularized Wasserstein Gradient Flow Imputation (NewImp). Specifically, to handle the first issue, we revisit DM-based MDI task within the Wasserstein Gradient Flow (WGF) framework, derive the associated cost functionals, and identify that they implicitly promote diversity in the imputed values. Building on this insight, we incorporate a negative entropy-regularized (NER) cost functional to suppress imputation diversity and enhance accuracy. Furthermore, we derive a closed-form imputation procedure based on the proposed cost functional within the reproducing kernel Hilbert space (RKHS). After that, we further prove that within the WGF framework, the imputation procedure of NewImp, induced from the cost functional associated with conditional distribution, can be induced from another cost functional associated with joint distribution equivalently, within which we merely need to estimate the joint distribution during the model training stage, thereby naturally eliminating the need for data masking.

**Contributions.** The main contributions of this paper are summarized as follows:

* We demonstrate that directly applying diffusion models to MDI causes suboptimal performance, as they prompt unintended diversity and require data masking, both impeding accurate imputation.
* We propose NewImp, a novel DM-based MDI approach under the WGF framework which introduces an NER cost functional to suppress unintended diversity. Based on this, we further prove that the imputation procedure of NewImp can be induced from an equivalent joint-distribution-related functional, and consequently introduce an imputation procedure that sidesteps the data masking.
* We conduct various experiments over public numerical tabular datasets to demonstrate the superiority of the NewImp method over prevalent baseline models.

## 2 Preliminaries

### Problem Formulation

Suppose \(\bm{X}^{\text{(ideal)}}\in\mathbb{R}^{\mathrm{N}\times\mathrm{D}}\) represents an ideal numerical tabular dataset without any missing entries, where \(\mathrm{N}\) and \(\mathrm{D}\) denote the number of samples and features, respectively. The observed dataset is expressed as: \(\bm{X}^{\text{(obs)}}=\bm{X}^{\text{(ideal)}}\odot\bm{M}+\texttt{NaN}\odot( \mathbbm{1}_{\mathrm{N}\times\mathrm{D}}-\bm{M}),\) where \(\odot\) denotes the Hadamard product, \(\mathbbm{1}_{\mathrm{N}\times\mathrm{D}}\) is a matrix of ones of size \(\mathrm{N}\times\mathrm{D}\), and \(\bm{M}\in\{0,1\}^{\mathrm{N}\times\mathrm{D}}\) is a binary mask that indicates the presence (1) or absence (0) of data in each entry. The task of MDI involves imputing the missing entries in \(\bm{X}^{\text{(obs)}}\). This is achieved by constructing a matrix \(\dot{\bm{X}}=\bm{X}^{\text{(obs)}}\odot\bm{M}+\bm{X}^{\text{(imp)}}\odot( \mathbbm{1}_{\mathrm{N}\times\mathrm{D}}-\bm{M}),\) where \(\bm{X}^{\text{(imp)}}\) is the matrix containing the imputed values.

The missing mechanism can be classified into three categories [44]: Missing Completely at Random (MCAR), Missing at Random (MAR), and Missing Not at Random (MNAR) (Detailed information about missing mechanisms is given in Appendix E.1). Notably, in the MNAR setting, it is generally difficult to identify the missing data distribution without additional assumptions and constraints [22]. Hence, our discussion primarily focuses on numerical tabular data with MAR and MCAR settings.

### Diffusion Models and Its Application for MDI Task

Diffusion models function by gradually corrupting data towards a tractable noise distribution, such as a standard Gaussian, and subsequently reversing this corruption to generate samples [50]. Specifically, the forward corruption process is modeled as a discretization of a stochastic differential equation (SDE) over time \(\tau\): \(\mathrm{d}\bm{X}_{\tau}=f(\bm{X}_{\tau})\mathrm{d}\tau+g_{\tau}\mathrm{d}W_{\tau}\), where \(f(\bm{X}_{\tau})\) is drift term, \(g_{\tau}\) is volatility term, and \(\mathrm{d}W\tau\) is standard Wiener process. The solution to this SDE creates a continuous trajectory of random variables \(\bm{X}_{\tau}|_{\tau=0}^{\mathbb{T}}\). The density function \(q_{\tau}\) of \(\bm{X}_{\tau}\) adheres to the Fokker-Planck-Kolmogorov (FPK)equation: \(\frac{\partial q_{\tau}}{\partial\tau}=-\nabla\cdot(q_{\tau}f(\bm{X}\tau))+\frac{ 1}{2}g_{\tau}^{2}\nabla\cdot\nabla q_{\tau}\) (see Theorem 5.4 in reference [47]). The reverse process is governed by: \(\mathrm{d}\bm{X}_{\tau}=[f(\bm{X}_{\tau})-g_{\tau}^{2}\nabla\mathrm{log}\,p( \bm{X}_{\tau})]\mathrm{d}\tau+g_{\tau}\mathrm{d}W_{\tau}\)[3], where \(\nabla\mathrm{log}\,p(\bm{X}_{\tau})\) represents the score function, which is often parameterized by neural networks.

Diffusion models treat MDI as a conditional generation task. The score function, \(\nabla\mathrm{log}\,p(\bm{X})\), is defined specifically for MDI as \(\nabla_{\bm{X}^{\text{(miss)}}}\log p(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})\)[51], and the MDI task is executed by generating samples based on this conditional score function. The key challenge is to obtain an estimation \(\nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{ \text{(obs)}})\) that approximates \(\nabla_{\bm{X}^{\text{(miss)}}}\log p(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{( obs)}})\). Given that the true \(\bm{X}^{\text{(miss)}}\) is unknown, existing DM-based approaches utilize a mask matrix to drop some observable data as labels. However, the specification of the mask mechanism, determining the effectiveness of \(\nabla\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})\), is challenging since it should align with the data missing mechanism in the testing dataset [51], which may be unknown in practice.

### Wasserstein Gradient Flow

Wasserstein space \(\mathcal{P}_{2}(\mathbb{R}^{\mathrm{D}})\) is defined as the set of distributions with finite second-order moments. Consider a cost functional \(\mathcal{F}_{\text{cost}}:\mathcal{P}_{2}(\mathbb{R}^{\mathrm{D}})\to\mathbb{R}\); the celebrated Wasserstein gradient flow (WGF) is an absolutely continuous trajectory \((q_{\tau})_{\tau>0}\) in this space, which evolves over time \(\tau\) to minimize \(\mathcal{F}_{\text{cost}}\) efficiently. This dynamic is governed by the continuity equation:

\[\frac{\partial q_{\tau}}{\partial\tau}=-\nabla\cdot(u_{\tau}q_{\tau}),\quad u_ {\tau}=-\nabla\bm{X}\,\frac{\delta\mathcal{F}_{\text{cost}}}{\delta q_{\tau}}\] (1)

where \(u_{\tau}:\mathbb{R}^{\mathrm{D}}\to\mathbb{R}^{\mathrm{D}}\) is a time-dependent _velocity field_[2], whose input is sample \(\bm{X}\in\mathbb{R}^{\mathrm{D}}\), \(\frac{\delta\mathcal{F}_{\text{out}}}{\delta q_{\tau}}\) denotes the first variation of \(\mathcal{F}_{\text{cost}}\) with respect to \(q_{\tau}\). On this basis, the evolution of \(\bm{X}\) over time \(\tau\) in \(\mathcal{P}_{2}(\mathbb{R}^{\mathrm{D}})\) can be modeled by the ordinary differential equation (ODE):

\[\frac{\mathrm{d}\bm{X}}{\mathrm{d}\tau}=u_{\tau}\] (2)

However, simulating this ODE is challenging since \(u_{\tau}\) involves the estimation of \(q_{\tau}\), which involves solving the differential equation \(\frac{\partial q_{\tau}}{\partial\tau}=-\nabla\cdot(u_{\tau}q_{\tau})\) that proves to be not analytically solvable [16].

## 3 Motivations

### Diffusion Models Secretly Foster Diversity

Based on the notations defined in Section 2.1, we can first define the following cost functional for MDI task according to the maximum likelihood estimation principle, where we want to find the value with the highest probability:

\[\bm{X}^{\text{(imp)}}=\operatorname*{arg\,max}_{\bm{X}^{\text{( miss)}}}\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}}),\] (3)

where \(\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})\) is the estimation of \(p(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})\) via neural network [52]. Notably, we can treat \(\bm{X}^{\text{(miss)}}\) as samples from a 'proposal distribution' \(r(\bm{X}^{\text{(miss)}})\), and formulate the following optimization problem based on variational inference [70; 27]:

\[\operatorname*{arg\,max}_{r(\bm{X}^{\text{(miss)}})}\quad\mathbb{E}_{r(\bm{X}^ {\text{(miss)}})}[\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})],\] (4)

where we aim to sample some \(\bm{X}^{\text{(miss)}}\) samples from proposal distribution \(r(\bm{X}^{\text{(miss)}})\), realize the maximum log-likelihood estimation over the sampled results, and 'optimize' the proposal distribution \(r(\bm{X}^{\text{(miss)}})\) that is represented by samples \(\bm{X}^{\text{(miss)}}\). Notably, in Eq. (4), we use the spirit from previous references represented by [32], where optimizing the samples \(\bm{X}^{\text{(miss)}}\) is equivalent to optimizing the distribution \(r(\bm{X}^{\text{(miss)}})\).

Figure 1: Comparison of the optimal point in green triangle and the results obtained by diffusion models in white scatters. See details in Appendix B.

Referring to Eq. (4), it is observed that the MDI task can be formulated as an optimization problem. This prompts a pertinent question: If the conditional distribution \(\log p(\bm{X}_{i}^{(\text{miss})}|\bm{X}_{i}^{(\text{obs})})\) is estimated accurately, _what would happen if we directly apply diffusion models to solve the optimization problem corresponding to MDI task?_ To explore this, we consider a hypothetical scenario: Suppose we are optimizing a cost functional related to a three-dimensional Dirichlet distribution on the simplex \(\Delta^{2}\):

\[\operatorname*{arg\,max}_{\bm{a}_{h}\in\Delta^{2}}\sum_{h=1}^{\mathrm{H}}\{ \log\frac{\Gamma(\sum_{k=1}^{3}\rho_{k})}{\prod_{k=1}^{3}\Gamma(\rho_{k})}+ \sum_{k=1}^{3}\left(\rho_{k}-1\right)\log\bm{a}_{k,h}\},\mathrm{H}=8,\rho|_{k=1 }^{3}=[2.5,2.5,5.0],\]

where \(\bm{a}_{h}|_{1}^{\mathrm{H}}\) are variables, \(\mathrm{H}\) is variable number, \(\rho_{k}|_{k=1}^{3}\) is concentration parameter, and \(\Gamma(\cdot)\) is gamma function. We compare the analytically derived optimal value with the results from diffusion models in Fig. 1. The diffusion model's results tend to surround but do not exactly reach the optimal value, suggesting that there might be _implicit_, _diversity-encouraging terms_ integrated into the diffusion models' objectives that produce the observed inaccuracies. Identifying and modifying these regularization terms is crucial for enhancing the efficacy of diffusion models for MDI tasks.

### Negative Entropy Regularization Term for Diversity Suppression

In this section, we identify and refine the terms in diffusion models' objectives that prompt unintended diversity and impede accurate imputation. We observe that the inference process in diffusion models adheres to the FPK equation, which is a specialized form of the continuity equation in WGF (see Sections 2.2 and 2.3). This alignment inspires us to reframe diffusion models within the WGF framework, enabling the derivation of their underlying cost functionals. By doing so, we can compare these functionals with the objective functional for MDI in Eq. (4)2.

Footnote 2: This paper primarily considers three types of stochastic differential equations (SDEs): variance preserving (VP-SDE), variance exploding (VE-SDE), and sub-VP-SDE, which cover the majority of diffusion models according to Song et al. [50]

**Proposition 3.1**.: _Within WGF framework, DM-based MDI approaches can be viewed as finding the imputed values \(\bm{X}^{(\text{imp})}\) that maximize the following objective:_

\[\operatorname*{arg\,max}_{r(\bm{X}^{(\text{miss})})}\quad\mathbb{E}_{r(\bm{X} ^{(\text{miss})})}[\log\hat{p}(\bm{X}^{(\text{miss})}|\bm{X}^{(\text{obs})})]+ \psi(\bm{X}^{(\text{miss})})+\text{const},\] (5)

_where 'const' is the abbreviation of constant, and \(\psi(\bm{X}^{(\text{miss})})\) is a scalar function determined by the type of SDE underlying the diffusion models._

* _VP-SDE:_ \(\psi(\bm{X}^{(\text{miss})})=\frac{1}{2}\mathbb{H}[r(\bm{X}^{(\text{miss})}) ]+\mathbb{E}_{r(\bm{X}^{(\text{miss})})}\{\frac{1}{4}[\bm{X}^{(\text{miss})}] \top[\bm{X}^{(\text{miss})}]\}\geq 0\)
* _VE-SDE:_ \(\psi(\bm{X}^{(\text{miss})})=\frac{1}{2}\mathbb{H}[r(\bm{X}^{(\text{miss})}) ]\geq 0\)
* _sub-VP-SDE:_ \(\psi(\bm{X}^{(\text{miss})})=\frac{1}{2}\mathbb{H}[r(\bm{X}^{(\text{miss})}) ]+\mathbb{E}_{r(\bm{X}^{(\text{miss})})}\{\frac{1}{4\gamma_{\tau}}[\bm{X}^{( \text{miss})}]\top[\bm{X}^{(\text{miss})}]\}\geq 0\)_,_

_where \(\mathbb{H}[r(\bm{X}^{(\text{miss})})]:=-\int r(\bm{X}^{(\text{miss})})\log r( \bm{X}^{(\text{miss})})\mathrm{d}\bm{X}^{(\text{miss})}\) is the entropy term, \(\gamma_{\tau}\) is determined by noise scale \(\beta_{\tau}\): \(\gamma_{\tau}:=(1-\exp(-2\int_{0}^{\tau}\beta_{s}\mathrm{d}s))>0,0<\beta_{1}< \dots<\beta_{\mathrm{T}}<1\)._

Proposition 3.1 reveals that diffusion models inherently optimize an objective functional that largely aligns with (4), but they secretly include an additional term \(\psi(\bm{X}^{(\text{miss})})>0\). This term makes Eq. (5) an _upper bound_ on Eq. (4), i.e., maximizing the cost functional in Eq. (5) does not guarantee to maximize the MDI objective in Eq. (4). Furthermore, the entropy term included in the models fosters sample diversity, which may compromise the accuracy required in MDI tasks [53; 38]. To address this issue, we propose incorporating a negative entropy term as \(\psi(\bm{X}^{(\text{miss})})\):

\[\psi(\bm{X}^{(\text{miss})})=-\lambda\mathbb{H}[r(\bm{X}^{(\text{miss})})],\] (6)

where \(\lambda>0\) is a predefined regularization strength, and consequently we can define our NER cost functional for MDI task as follows:

\[\mathcal{F}_{\text{NER}}\coloneqq\mathbb{E}_{r(\bm{X}^{(\text{miss})})}[\log \hat{p}(\bm{X}^{(\text{miss})}|\bm{X}^{(\text{obs})})]-\lambda\mathbb{H}[r(\bm {X}^{(\text{miss})})].\] (7)

The objective functional in Eq. (7) provides a _lower bound_ of Eq. (4). Therefore, maximizing \(\mathcal{F}_{\text{NER}}\) guarantees maximizing Eq. (4). Meanwhile, \(\mathcal{F}_{\text{NER}}\) effectively reduces the unintended diversity term, contributing to an improvement in imputation accuracy.

Implementation of the NewImp

### Optimizing the \(\mathcal{F}_{\text{NER}}\) within WGF Framework

In this section, we aim to optimize \(\mathcal{F}_{\text{NER}}\) within the WGF framework [46; 69]. To this end, we plug Eq. (7) into Eq. (1), producing the velocity field below that drives the ODE in Eq. (2):

\[u(\bm{X}^{\text{(miss)}})=-\nabla_{\bm{X}^{\text{(miss)}}}\frac{\delta(- \mathcal{F}_{\text{NER}})}{\delta r(\bm{X}^{\text{(miss)}})}=[\nabla_{\bm{X}^ {\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})+ \lambda\nabla_{\bm{X}^{\text{(miss)}}}\log r(\bm{X}^{\text{(miss)}})],\]

However, as stated in Section 2.3, implementing this ODE in computer code is intricate due to the intractability of the density function \(r(\bm{X}^{\text{(miss)}})\). Fortunately, by restricting the velocity field within the Reproducing Kernel Hilbert Space (RKHS) defined by the kernel function \(u(\bm{X}^{\text{(miss)}})\in K(\bm{X}^{\text{(miss)}},\tilde{\bm{X}}^{\text{ (miss)}})\), an alternative ODE minimizing \(\mathcal{F}_{\text{NER}}\) can be implemented in Proposition 4.1[35; 31] which sidesteps the intractable \(r(\bm{X}^{\text{(miss)}})\)3.

Footnote 3: \(r(\bm{X}^{\text{(miss)}})\) and \(u(\bm{X}^{\text{(miss)}})\) are time-varying functions but do not explicitly involve the evolution time \(\tau\), thus evolution time \(\tau\) is omitted in the input variable.

**Proposition 4.1**.: _Suppose \(u(\bm{X}^{\text{(miss)}})\) is a velocity field regularized by the RKHS norm under the following conditions: 1). The kernel function satisfies: \(\lim_{\|\bm{X}^{\text{(miss)}}\|\to\infty}K(\bm{X}^{\text{(miss)}},\tilde{\bm{X }}^{\text{(miss)}})=0\). 2). The density \(r(\bm{X}^{\text{(miss)}})\) is bounded. Then, the velocity field that minimizes the cost functional \(\mathcal{F}_{\text{NER}}=\mathbb{E}_{r(\bm{X}^{\text{(miss)}})}[\log\hat{p}( \bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})]-\lambda\mathbb{H}[r(\bm{X}^{ \text{(miss)}})]\) can be given by:_

\[u(\bm{X}^{\text{(miss)}})=\mathbb{E}_{r(\tilde{\bm{X}}^{\text{(miss)}})}\left\{ -\lambda\nabla_{\tilde{\bm{X}}^{\text{(miss)}}}K(\bm{X}^{\text{(miss)}},\tilde {\bm{X}}^{\text{(miss)}})\right.\] (8)

_where the expectation term \(\mathbb{E}_{r(\tilde{\bm{X}}^{\text{(miss)}})}\) can be efficiently estimated using Monte Carlo approximation, \(K(\bm{X},\tilde{\bm{X}})\) is set as the radial basis function (RBF) kernel._

### Sidestepping Mask Matrix: Conditional Modeling via Joint Modeling

Simulating the ODE in Eq. (2) with Eq. (8) necessitates an accurate estimation of \(p(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})\). However, this modeling is challenging due to the diverse choices of masking matrices. More specifically, the accuracy of the estimated conditional distribution \(p(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})\) heavily relies on the selection of these matrices, and these matrices should be consistent with the data missing mechanism in the testing dataset, which may be unknown in practice [51]. To bypass this difficulty, we suggest substituting the conditional distribution \(p(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})\) with the joint distribution \(p(\bm{X}^{\text{(joint)}})\), where \(\bm{X}^{\text{(joint)}}=(\bm{X}^{\text{(miss)}},\bm{X}^{\text{(obs)}})\). Building on this substitution, the velocity field is redefined based on the estimated joint distribution \(\hat{p}(\bm{X}^{\text{(joint)}})\) as follows:

\[u(\bm{X}^{\text{(joint)}})=\mathbb{E}_{r(\tilde{\bm{X}}^{\text{(joint)}})} \left\{\begin{aligned} -\lambda\nabla_{\tilde{\bm{X}}^{\text{(miss)}}}K(\bm{X}^{\text{( joint)}},\tilde{\bm{X}}^{\text{(joint)}})\\ +[\nabla_{\tilde{\bm{X}}^{\text{(miss)}}}\log\hat{p}(\tilde{\bm{X}} ^{\text{(joint)}})]^{\top}K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{\text{( joint)}})\end{aligned}\right\},\] (9)

where \(\nabla_{\tilde{\bm{X}}^{\text{(miss)}}}\log\hat{p}(\tilde{\bm{X}}^{\text{( joint)}})\) can be obtained by masking the \(\nabla_{\bm{X}^{\text{(joint)}}}\log\hat{p}(\bm{X}^{\text{(joint)}})\) with the missing data indicator matrix \(\bm{M}\) as follows:

\[\nabla_{\tilde{\bm{X}}^{\text{(miss)}}}\log\hat{p}(\tilde{\bm{X}}^{\text{( joint)}})=\nabla_{\tilde{\bm{X}}^{\text{(joint)}}}\log\hat{p}(\tilde{\bm{X}}^{\text{( joint)}})\odot(\mathbbm{1}_{\mathrm{N}\times\mathrm{D}}-\bm{M})+0\times\bm{M},\] (10)

and the expression of kernel function term can be _directly_ given based on the expression of RBF:

\[K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{\text{(joint)}})=\exp(-\frac{\|\bm{X} ^{\text{(joint)}}-\tilde{\bm{X}}^{\text{(joint)}}\|^{2}}{2h^{2}}),\] (11)

where \(h\) is the bandwidth, _the values of \(\tilde{\bm{X}}^{\text{(joint)}}\) and \(\bm{X}^{\text{(joint)}}\) are identical_, and the tilde notation on \(\tilde{\bm{X}}^{\text{(joint)}}\) is merely used to _distinguish the variable with respect to which the derivative is taken_. Onthis basis, similar to Eq. (10), the gradient term \(\nabla_{\hat{\bm{X}}^{\text{(init)}}}K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{ \text{(joint)}})\) can be given as follows:

\[\nabla_{\hat{\bm{X}}^{\text{(init)}}}K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{ \text{(joint)}})=\nabla_{\hat{\bm{X}}^{\text{(init)}}}K(\bm{X}^{\text{(joint) }},\tilde{\bm{X}}^{\text{(joint)}})\odot(\mathbbm{1}_{\text{N}\times\text{D} }-\bm{M})+0\times\bm{M},\] (12)

and since \(K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{\text{(joint)}})\) is a smooth function, \(\nabla_{\tilde{\bm{X}}^{\text{(init)}}}K(\bm{X}^{\text{(joint)}},\tilde{\bm {X}}^{\text{(joint)}})\) can be _easily_ computed by automatic-differentiation-based deep learning backends like by PyTorch [42].

Proposition 4.2 demonstrates that the cost functional \(\mathcal{F}_{\text{joint-NER}}\), associated with Eq. (10), and \(\mathcal{F}_{\text{NER}}\) exhibit a constant gap, indicating that optimizing \(\mathcal{F}_{\text{joint-NER}}\) is equivalent to optimizing \(\mathcal{F}_{\text{NER}}\).

**Proposition 4.2**.: _Assume that the proposal distribution \(r(\bm{X}^{\text{(joint)}})\) is factorized by \(r(\bm{X}^{\text{(joint)}}):=r(\bm{X}^{\text{(miss)}})p(\bm{X}^{\text{(obs)}})\). The cost functional associated with the joint distribution is defined as follows:_

\[\mathcal{F}_{\text{joint-NER}}:=\mathbb{E}_{r(\bm{X}^{\text{(init)}})}[\log \hat{p}(\bm{X}^{\text{(joint)}})]-\lambda\mathbb{H}[r(\bm{X}^{\text{(joint)} })],\] (13)

_which leads to the velocity field delineated in Eq. (9) and establishes \(\mathcal{F}_{\text{joint-NER}}\) as a lower bound for \(\mathcal{F}_{\text{NER}}\), with the difference being a constant (i.e., \(\mathcal{F}_{\text{joint-NER}}=\mathcal{F}_{\text{NER}}-\text{const},\text{ const}\geq 0\))._

The detailed justification for the factorization \(r(\bm{X}^{\text{(joint)}}):=r(\bm{X}^{\text{(miss)}})p(\bm{X}^{\text{(obs)}})\) is provided in Appendix C. Based on this proposition, the following corollary can be obtained:

**Corollary 4.3**.: _The following equation holds: \(u(\bm{X}^{\text{(joint)}})=u(\bm{X}^{\text{(miss)}})\)._

So far, we know that \(u(\bm{X}^{\text{(joint)}})\) can reduce \(\mathcal{F}_{\text{NER}}\) as effectively as possible, which indicates that the velocity field defined in Eq. (9) can fully substitute for Eq. (8) in optimizing \(\mathcal{F}_{\text{NER}}\) without loss of accuracy. Finally, the imputed value can be obtained by simulating the following ODE:

\[\frac{\mathrm{d}\bm{X}^{\text{(miss)}}}{\mathrm{d}\tau}=u(\bm{X}^{\text{(joint )}}).\] (14)

### Estimating the Joint Distribution

The remaining problem is to determine the estimation of score function \(\nabla_{\bm{X}^{\text{(joint)}}}\log\hat{p}(\bm{X}^{\text{(joint)}})\). To achieve this, we employ Denoising Score Matching (DSM) [21; 52] to train the score function \(\nabla_{\bm{X}^{\text{(joint)}}}\log\hat{p}(\bm{X}^{\text{(joint)}})\) parameterized by a neural network. Specifically, the learning objective is designed to minimize the discrepancy between the actual score and the model's predicted score after introducing Gaussian noise to the clean \(\bm{X}^{\text{(joint)}}\) as \(\hat{\bm{X}}^{\text{(joint)}}\):

\[\mathcal{L}_{\text{DSM}}\coloneqq\frac{1}{2}\mathbb{E}_{q_{\sigma}(\hat{\bm{ X}}^{\text{(init)}}|\bm{X}^{\text{(joint)}})}[\|\nabla_{\hat{\bm{X}}^{\text{( joint)}}}\log\hat{p}(\hat{\bm{X}}^{\text{(joint)}})-\nabla_{\hat{\bm{X}}^{\text{( joint)}}}\log q_{\sigma}(\hat{\bm{X}}^{\text{(joint)}}|\bm{X}^{\text{( joint)}})\|^{2}].\] (15)

Notably, \(\sigma\) is variance scale, \(\hat{\bm{X}}^{\text{(joint)}}\) is obtained by \(\hat{\bm{X}}^{\text{(joint)}}=\bm{X}^{\text{(joint)}}+\epsilon,\epsilon \sim\mathcal{N}(\bm{0},\sigma^{2}\mathbf{I})\), and \(\nabla_{\hat{\bm{X}}^{\text{(joint)}}}\log q_{\sigma}(\hat{\bm{X}}^{\text{( joint)}}|\bm{X}^{\text{(joint)}})=-\frac{\hat{\bm{X}}^{\text{( joint)}}-\bm{X}^{\text{(joint)}}}{\sigma^{2}}\). Once \(\nabla_{\bm{X}^{\text{(joint)}}}\log\hat{p}(\bm{X}^{\text{(joint)}})\) is trained, we can obtain the imputation value by simulating the ODE based on Eqs. (9) and (14).

### Overall Workflow of NewImp

The computation workflow of NewImp is encapsulated in Algorithm 1. Specifically, we perform a mean imputation to the incomplete matrix \(\bm{X}^{\text{(obs)}}\), producing a pre-imputed dataset denoted as \(\bm{X}^{\text{(imp)}}\) (step 1). After that, we iteratively conduct DSM training and ODE simulation. In DSM training (steps 3-5), we form \(\bm{X}^{\text{(joint)}}\) and conduct DSM on it to acquire a score estimator. In ODE simulation (steps 6-8), we set the starting point and perform ODE simulation, where \(u\) is calculated with the score estimator acquired in step 5. The endpoint is treated as the imputation results at the current iteration. After completing \(\mathcal{T}\) iterations of this process, the imputed dataset \(\hat{\bm{X}}\) is calculated, where we preserve the observed indices in \(\bm{X}^{\text{(obs)}}\) (step 10).

## 5 Experiments

### Experimental Setup

**Datasets:** We conduct the case study based on eight real-world datasets from the UCI repository. To simulate missing data, we mask the dataset using a mask matrix, which is realized with a Bernoulli random variable of fixed mean. More detailed information is provided in Appendix E.1.

**Baselines:** We compare NewImp with DM-based MDI models: CSDI for Tabular Data (CSDI_T) [51], MissDiff [41]. In addition, we also select other well-known MDI models like Sinkhorn (Sink) [40], Transform Distribution Matching (TDM) [72], Generative Adversarial Imputation Nets (GAIN) [67], Missing Data Importance-Weighted Autoencoder (MIWAE) [39], Missing data Imputation Refinement And Causal LEarning (MIRACLE) [28], and ReMasker [15]. Details concerning experimental settings are given in Appendix E.2.

**Implementation Details:** In this study, we employ a two-layer multi-layer perceptron to model \(\nabla_{\bm{X}^{\text{(input)}}}\log\hat{p}(\bm{X}^{\text{(joint)}})\). Each layer is configured with 256 hidden units (\(\text{HU}_{\text{score}}\)), and the activation function is set as the 'Swish' function [43]. For DSM training (step 5 of Algorithm 1), the variance scale \(\sigma\) is set as 0.1, the network is trained by the Adam optimizer [26] with the learning rate of \(1.0\times 10^{3}\), and the batch size is dynamically set to dataset size N. Meanwhile, for the ODE simulation part (step 7 of Algorithm 1), we specify a simulation time (T) of 500, a regularization strength of (\(\lambda\)) 10.0, a step size of (\(\eta\)) 0.1, and a bandwidth (\(h\)) of 0.5. The loop time \(\mathcal{T}\) for NewImp is set as 2. Since only missing indices are updated, the evaluation focuses exclusively on imputation errors for these indices. To this end, we modify the mean absolute error (MAE) and squared Wasserstein-2 distance (WASS) according to reference [22] as follows:

\[\text{MAE}\coloneqq\frac{\sum_{i=1}^{\text{N}}\sum_{j=1}^{\text{D}}[|\bm{X}^{ \text{(ideal)}}_{i,j}-\hat{\bm{X}}_{i,j}|\odot(\mathbbm{1}_{\text{N}\times \text{D}}-\bm{M})_{i,j}]}{\sum_{i=1}^{\text{N}}\sum_{j=1}^{\text{D}}(\mathbbm{ 1}_{\text{N}\times\text{D}}-\bm{M})_{i,j}},\]

\[\text{WASS}\coloneqq\mathcal{W}_{2}^{2}[\frac{1}{\bm{m}_{1}}\sum_{i=1}^{\bm{ m}_{1}}\Delta_{[\hat{\bm{X}}_{\bm{M}_{1}}]_{i,:}},\frac{1}{\bm{m}_{1}}\sum_{i=1}^{ \bm{M}_{1}}\Delta_{[\bm{X}^{\text{(data)}}_{\bm{M}_{1}}]_{i,:}}],\]

where \(\mathcal{W}_{2}^{2}\) denotes the squared Wasserstein-2 distance, \(\bm{M}_{1}\coloneqq\{i:\exists j,\bm{M}_{i,j}=0\}\) represents the subset of \(\bm{M}_{i,j}\) with at least one missing value, \(\bm{m}_{1}\) is the number of data points with at least one missing value, and \(\Delta_{\bm{X}}\) is the Dirac distribution (measure) concentrated on \(\bm{X}\).

### Baseline Comparison Results

Table 1 presents the imputation quality of NewImp and other imputation approaches under the MAR and MCAR scenarios. The primary observations are detailed as follows:

* Models with neural architectures such as MIRACLE, MIWAE, and TDM demonstrate superior performance compared to models lacking such architectures. This observation suggests that integrating neural networks into MDI tasks can significantly enhance model performance.
* DM-based imputation approaches generally perform worse than other MDI methods. This outcome indicates that despite the incorporation of complex nonlinear neural architectures to boost performance, employing diversity-oriented generative approaches may not align well with the precision requirements of MDI tasks.

* Our proposed NewImp method consistently ranks as the best or second-best across most comparisons under most of the scenarios and datasets. Notably, NewImp significantly outperforms other DM-based MDI approaches, underscoring the effectiveness of our analytical enhancements and innovations in Sections 3.1, 3.2 and 4.2.

### Ablation Study Results

In this section, we conduct the ablation study to assess the contributions of two key components in NewImp: the NER term and the joint modeling strategy (referred to as 'Joint'). The results of this study are detailed in Table 2. Analysis of the data between the second and last rows of Table 2 reveals that, for most cases, in the absence of the NER, the proposal distribution \(r(\bm{X}^{\text{(miss)}})\) may become pathological, leading to diminished model performance. Additionally, when comparing results from the first, third, and last rows, it becomes evident that modeling the joint distribution directly, rather than inferring it from the conditional distribution, significantly enhances model performance. This finding underscores the effectiveness of the strategies we have implemented, as discussed in Section 4.2. Overall, the ablation study underscores the critical roles of both the NER term and the joint distribution learning strategy in promoting the performance of NewImp.

### Sensitivity Analysis Results

In this section, we analyze the impact of key hyperparameters within the NewImp approach, including the bandwidth \(h\) of the RBF kernel function, the hidden units \(\mathrm{HU}_{\text{score}}\) in the score network, the weight \(\lambda\) of the NER term, and the discretization step size \(\eta\) for simulating the ODE defined in Eq. (9). The profound influence of these hyperparameters on learning objectives and overall performance is substantiated by the experimental results presented in Fig. 2. Initially, we explore the effects of varying

\begin{table}
\begin{tabular}{c|c|c|c c|c c|c c|c c|c c|c c|c c} \hline \hline \multirow{2}{*}{Scenario} & \multirow{2}{*}{Model} & \multirow{2}{*}{MAE} & \multirow{2}{*}{RMSE} & \multirow{2}{*}{MAE} & \multirow{2}{*}{RMSE} & \multirow{2}{*}{MAE} & \multirow{2}{*}{RMSE} & \multirow{2}{*}{MAE} & \multirow{2}{*}{RMSE} & \multirow{2}{*}{MAE} & \multirow{2}{*}{RMSE} & \multirow{2}{*}{MAE} & \multirow{2}{*}{RMSE} & \multirow{2}{*}{MAE} & \multirow{2}{*}{RMSE} & \multirow{2}{*}{MAE} & \multirow{2}{*}{RMSE} & \multirow{2}{*}{MAE} & \multirow{2}{*}{RMSE} & \multirow{2}{*}{MAE} & \multirow{2}{*}{RMSE} & \multirow{2}{*}{RMSE} \\ \cline{1-1} \clinethe bandwidth \(h\). We observe that an increase in bandwidth correlates with a decrease in imputation accuracy. For instance, as the bandwidth increases from 0.5 to 2.0, the MAE and WASS escalate from 0.35 and 0.25 to 0.82 and 0.74, respectively. This trend suggests that excessive bandwidth can lead to an over-smoothed velocity field, expanding the exploration space of the distribution \(r(\bm{X}^{\text{(joint)}})\) excessively and failing to adequately 'concentrate' this distribution, ultimately diminishing performance. Subsequently, we examine changes in the score network's hidden units. Increasing the hidden units from 256 to 512 appears to decrease imputation accuracy, likely due to overfitting issues associated with larger neural networks. Next, we adjust the strength of the NER term and find that increasing its intensity generally improves imputation accuracy. This supports the necessity of the NER term, further validating its effectiveness. Lastly, we investigate the discretization step size for the ODE. We find that accuracy initially increases with smaller step sizes but then decreases. This pattern is consistent with ODE simulation behavior, where smaller step sizes require longer to converge, potentially resulting in lower accuracy within a predefined time. Conversely, larger step sizes increase discretization errors, adversely affecting accuracy as well.

## 6 Related Works

### Diffusion Models for Missing Data Imputation

The impressive ability of diffusion models to synthesize data [54; 76; 7] has inspired extensive research into their application for MDI tasks [59; 66]. Among the pioneering efforts, the Conditional Score-based Diffusion models for Imputation (CSDI) [51] was the first to adapt diffusion models for time-series MDI, substituting the score function with a conditional distribution and pioneering a novel model training strategy by masking parts of the observational data. Building on this, to address categorical data in tabular datasets, CSDL_T [73] introduced an embedding layer within the feature extractor. To enhance inference efficiency, the conditional Schrodinger bridge method for probabilistic time series imputation proposed modeling the diffusion process as a Schrodinger bridge [10]. Meanwhile, MissDiff [41] utilizes the missing data information as the mask matrix to improve the model training procedure.

Despite these advancements from the perspective of feature extraction module [1; 64], loss function [41], and model inference approach [60], as pointed out by reference [38], the reconciliation of the inherent diversity-seeking nature of diffusion models' generative processes and the accuracy-centric demands of MDI task remains underexplored. To our knowledge, this paper is the first to elucidate the relationship between diffusion models' generative processes and MDI tasks from an optimization perspective (Sections 3.1 and 3.2), which has not been discovered by previous reference [38]. Based on these insights, we further propose our NewImp approach by designing the NER term to prioritize the MDI accuracy (Section 3.2).

Figure 2: Parameter sensitivity of NewImp on bandwidth for kernel function (\(h\)), hidden unit of score network \(\text{HU}_{\text{score}}\), NER weight \(\lambda\), and discretization step \(\eta\) for Eq. (9) on CC dataset. Mean values and one standard deviation from mean are represented by scatters and shaded area, respectively.

### Modeling Conditional Distribution by Joint Distribution

Modeling conditional distribution as joint distribution remains an opening question and has a broad potential for application [68; 8; 25]. Conditional sliced WGF [14] first empirically validated that the velocity field of joint distribution and conditional distribution are identical when choosing sliced Wasserstein distance as cost functional. After that, reference [25] extended this relationship and derived the relationship between conditional and joint distribution in various discrepancy metrics like \(f\)-divergence, Wasserstein distance, and integral probability metrics. On this basis, reference [19] further theoretically proved the equivalence of velocity fields for conditional and joint distribution.

However, the objective of NewImp does not belong to any kind of discrepancy metric [25]. The most similar discrepancy metric is negative KL divergence. Notably, negative KL divergence contains diversity-encouraging 'positive' entropy as the regularization term, and the regularization term in our study is diversity-discouraging 'negative' entropy, and thus more than directly applying these results to our research is needed. On this basis, our theoretical contribution proves that this joint distribution modeling approach can still be applied when the functional is regularized by the negative entropy.

### Wasserstein Gradient Flow for Generative Modeling

WGF [2; 46] has been extensively employed in various domains of machine learning, including generative modeling [17; 12; 74; 63], posterior distribution sampling [55; 35; 32; 34], and domain adaptation [75; 36; 37; 71]. In generative modeling [4; 11; 18], the problem is framed as an optimization task, with the objective functional comprising an \(f\)-divergence term that measures the discrepancy between the proposal distribution and the data distribution, alongside an entropy term that promotes diversity in generative results.

WGF is then utilized to address the optimization of this cost functional, with models being constructed during the solution process. However, as indicated by our illustrative example (Section 3.1), and further supported by our theoretical analysis (Section 3.2), pursuing diversity in accuracy-oriented tasks such as MDI may not be appropriate. Our analysis reveals that the inclusion of an entropy term in the cost functional makes the direct application of diffusion models to MDI tasks unsuitable. Based on these insights, one of our major contributions is demonstrating that WGF can be effectively used to analyze and improve the appropriateness of applying diffusion models to non-generative tasks.

## 7 Conclusions

This work demonstrated that directly applying diffusion models to MDI resulted in suboptimal performance due to unintended diversity and the requirement for data masking, both of which impeded accurate imputation. To counteract this, we proposed NewImp, a novel diffusion model-based MDI approach within the Wasserstein gradient flow framework, designed to suppress unintended diversity. We developed an easy-to-implement form for realizing NewImp in computer code by constraining the velocity field within the reproducing kernel Hilbert space. Furthermore, we proved that the imputation procedure of NewImp could be derived from an equivalent joint-distribution-related functional, thereby obviating the need for data masking. Finally, extensive experiments demonstrated that NewImp effectively mitigates these issues and outperforms prevalent baseline models.

## Acknowledgement

This work was supported in part by the National Natural Science Foundation of China (NSFC) under Grants 62473103 and 623B2002. The first author Zhichao Chen and the corresponding author Hao Wang would like to express their sincere gratitude to PhD Candidate Weiming Liu at Zhejiang University for valuable discussions on the implementation of the FPK equation via ODE/SDE.

_Dedicated to the 100th Anniversary of Sun Yat-sen University, the Alma of Zhichao Chen._

## References

* [1] Juan Lopez Alcaraz and Nils Strodthoff. Diffusion-based time series imputation and forecasting with structured state space models. _Trans. Mach. Learn. Res._, 2022.
* [2] Luigi Ambrosio, Nicola Gigli, and Giuseppe Savare. _Gradient flows: in metric spaces and in the space of probability measures_. Springer Science & Business Media, 2005.
* [3] Brian DO Anderson. Reverse-time diffusion equation models. _Stoch. Process. their Appl._, 12(3):313-326, 1982.
* [4] Abdul Fatir Ansari, Ming Liang Ang, and Harold Soh. Refining deep generative models via discriminator gradient flow. In _Proc. Int. Conf. Learn. Represent._, pages 1-24, 2021.
* [5] Matthew James Beal. _Variational algorithms for approximate Bayesian inference_. University of London, University College London (United Kingdom), 2003.
* [6] John Charles Butcher. _Numerical methods for ordinary differential equations_. John Wiley & Sons, 2016.
* [7] Hanqun Cao, Cheng Tan, Zhangyang Gao, Yilun Xu, Guangyong Chen, Pheng-Ann Heng, and Stan Z. Li. A survey on generative diffusion models. _IEEE Trans. Knowl. Data Eng._, 36(7):2814-2830, 2024. doi: 10.1109/TKDE.2024.3361474.
* [8] Jannis Chemseddine, Paul Hagemann, Christian Wald, and Gabriele Steidl. Conditional wasserstein distances with applications in bayesian ot flow matching. _arXiv preprint arXiv:2403.18705_, pages 1-42, 2024.
* [9] Changyou Chen, Ruiyi Zhang, Wenlin Wang, Bai Li, and Liqun Chen. A unified particle-optimization framework for scalable bayesian sampling. _arXiv preprint arXiv:1805.11659_, pages 1-13, 2018.
* [10] Yu Chen, Wei Deng, Shikai Fang, Fengpei Li, Nicole Tianjiao Yang, Yikai Zhang, Kashif Rasul, Shandian Zhe, Anderson Schneider, and Yuriy Nevmyvaka. Provably convergent schrodinger bridge with applications to probabilistic time series imputation. In _Proc. Int. Conf. Mach. Learn._, pages 4485-4513, 2023.
* [11] Xiuyuan Cheng, Jianfeng Lu, Yixin Tan, and Yao Xie. Convergence of flow-based generative models via proximal gradient descent in wasserstein space. _IEEE Trans. Inf. Theory_, pages 1-1, 2024. doi: 10.1109/TIT.2024.3422412.
* [12] Jaemoo Choi, Jaewoong Choi, and Myungjoo Kang. Scalable Wasserstein gradient flow for generative modeling through unbalanced optimal transport. In _Proc. Int. Conf. Mach. Learn._, pages 8629-8650, 2024.
* [13] Hanze Dong, Xi Wang, LIN Yong, and Tong Zhang. Particle-based variational inference with preconditioned functional gradient flow. In _Proc. Int. Conf. Learn. Represent._, pages 1-26, 2022.
* [14] Chao Du, Tianbo Li, Tianyu Pang, Shuicheng Yan, and Min Lin. Nonparametric generative modeling with conditional sliced-wasserstein flows. In _Proc. Int. Conf. Mach. Learn._, pages 8565-8584, 2023.
* [15] Tianyu Du, Luca Melis Melis, and Ting Wang. Remasker: Imputing tabular data with masked autoencoding. In _Proc. Int. Conf. Learn. Represent._, pages 1-23, 2024.
* [16] Lawrence C Evans. _Partial differential equations_, volume 19. American Mathematical Society, 2022.
* [17] Jiaojiao Fan, Qinsheng Zhang, Amirhossein Taghvaei, and Yongxin Chen. Variational Wasserstein gradient flow. In _Proc. Int. Conf. Mach. Learn._, pages 6185-6215, 2022.
* [18] Yuan Gao, Yuling Jiao, Yang Wang, Yao Wang, Can Yang, and Shunkang Zhang. Deep generative learning via variational gradient flow. In _Proc. Int. Conf. Mach. Learn._, pages 2093-2101, 2019.

* [19] Paul Hagemann, Johannes Hertrich, Fabian Altekruger, Robert Beinert, Jannis Chemseddine, and Gabriele Steidl. Posterior sampling based on gradient flows of the MMD with negative distance kernel. In _Proc. Int. Conf. Learn. Represent._, pages 1-32, 2024.
* [20] Ya-Ping Hsieh, Ali Kavis, Paul Rolland, and Volkan Cevher. Mirrored Langevin Dynamics. In _Proc. Adv. Neural Inf. Process. Syst._, pages 1-10, 2018.
* [21] Aapo Hyvarinen. Estimation of non-normalized statistical models by score matching. _J. Mach. Learn. Res._, 6(24):695-709, 2005.
* [22] Daniel Jarrett, Bogdan C Cebere, Tennison Liu, Alicia Curth, and Mihaela van der Schaar. Hyperimpute: Generalized iterative imputation with automatic model selection. In _Proc. Int. Conf. Mach. Learn._, pages 9916-9937, 2022.
* [23] Richard Jordan, David Kinderlehrer, and Felix Otto. The variational formulation of the fokker-planck equation. _SIAM J. Math. Anal._, 29(1):1-17, 1998.
* [24] Valentin Khrulkov, Gleb Ryzhakov, Andrei Chertkov, and Ivan Oseledets. Understanding DDPM latent codes through optimal transport. In _Proc. Int. Conf. Learn. Represent._, pages 1-15, 2022.
* [25] Young-geun Kim, Kyungbok Lee, and Myunghee Cho Paik. Conditional Wasserstein Generator. _IEEE Trans. Pattern Anal. Mach. Intell._, 45(6):7208-7219, 2023. doi: 10.1109/TPAMI.2022.3220965.
* [26] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In _Proc. Int. Conf. Learn. Represent._, pages 1-8, 2015.
* [27] Diederik P Kingma and Max Welling. Auto-encoding Variational Bayes. In _Proc. Int. Conf. Learn. Represent._, pages 1-8, 2014.
* [28] Trent Kyono, Yao Zhang, Alexis Bellot, and Mihaela van der Schaar. MIRACLE: Causally-aware imputation via learning missing data mechanisms. _Proc. Adv. Neural Inf. Process. Syst._, pages 23806-23817, 2021.
* [29] Haoxuan Li, Kunhan Wu, Chunyuan Zheng, Yanghao Xiao, Hao Wang, Zhi Geng, Fuli Feng, Xiangnan He, and Peng Wu. Removing hidden confounding in recommendation: a unified multi-task learning approach. _Proc. Adv. Neural Inf. Process. Syst._, pages 1-13, 2024.
* [30] Haoxuan Li, Chunyuan Zheng, Shuyi Wang, Kunhan Wu, Eric Wang, Peng Wu, Zhi Geng, Xu Chen, and Xiao-Hua Zhou. Relaxing the accurate imputation assumption in doubly robust learning for debiased collaborative filtering. In _Proc. Int. Conf. Mach. Learn._, pages 29448-29460, 2024.
* [31] Yingzhen Li and Richard E. Turner. Gradient estimators for implicit models. In _Proc. Int. Conf. Learn. Represent._, pages 1-19, 2018.
* [32] Chang Liu, Jingwei Zhuo, Pengyu Cheng, Ruiyi Zhang, and Jun Zhu. Understanding and accelerating particle-based variational inference. In _Proc. Int. Conf. Mach. Learn._, pages 4082-4092. PMLR, 2019.
* [33] Diju Liu, Yalin Wang, Chenliang Liu, Xiaofeng Yuan, Kai Wang, and Chunhua Yang. Score-free global multi-condition-aware industrial missing data imputation framework via diffusion transformer. _IEEE Trans. Knowl. Data Eng._, pages 1-12, 2024. doi: 10.1109/TKDE.2024.3392897.
* [34] Qiang Liu. Stein variational gradient descent as gradient flow. In _Proc. Adv. Neural Inf. Process. Syst._, volume 30, pages 1-15, 2017.
* [35] Qiang Liu and Dilin Wang. Stein variational gradient descent: A general purpose bayesian inference algorithm. In _Proc. Adv. Neural Inf. Process. Syst._, volume 29, pages 1-13, 2016.
* [36] Weiming Liu, Jiajie Su, Chaochao Chen, and Xiaolin Zheng. Leveraging distribution alignment via stein path for cross-domain cold-start recommendation. In _Proc. Adv. Neural Inf. Process. Syst._, volume 34, pages 19223-19234, 2021.

* [37] Weiming Liu, Xiaolin Zheng, Jiajie Su, Longfei Zheng, Chaochao Chen, and Mengling Hu. Contrastive proxy kernel stein path alignment for cross-domain cold-start recommendation. _IEEE Trans. Knowl. Data Eng._, 35(11):11216-11230, 2023. doi: 10.1109/TKDE.2022.3233789.
* [38] Yixin Liu, Thalaiyasingam Ajanthan, Hisham Husain, and Vu Nguyen. Self-supervision improves diffusion models for tabular data imputation. In _Proc. ACM Int. Conf. Inf. Knowl. Manag._, pages 1-10, 2024.
* [39] Pierre-Alexandre Mattei and Jes Frellsen. MIWAE: Deep generative modelling and imputation of incomplete data sets. In _Proc. Int. Conf. Mach. Learn._, pages 4413-4423, 2019.
* [40] Boris Muzellec, Julie Josse, Claire Boyer, and Marco Cuturi. Missing data imputation using optimal transport. In _Proc. Int. Conf. Mach. Learn._, pages 7130-7140, 2020.
* [41] Yidong Ouyang, Liyan Xie, Chongxuan Li, and Guang Cheng. MissDiff: Training diffusion models on tabular data with missing values. In _Proc. Int. Conf. Mach. Learn. Workshop on Structured Probabilistic Inference\(\&\) Generative Modeling_, 2023.
* [42] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An imperative style, high-performance deep learning library. In _Proc. Adv. Neural Inf. Process. Syst._, volume 32, pages 1-12, 2019.
* [43] Prajit Ramachandran, Barret Zoph, and Quoc V Le. Searching for activation functions. _arXiv preprint arXiv:1710.05941_, pages 1-13, 2017.
* [44] Donald B Rubin. Inference and missing data. _Biometrika_, 63(3):581-592, 1976.
* [45] Walter Rudin et al. _Principles of mathematical analysis_, volume 3. McGraw-hill New York, 1964.
* [46] Filippo Santambrogio. {Euclidean, Metric, and Wasserstein} gradient flows: an overview. _Bull. Math. Sci._, 7:87-154, 2017.
* [47] Simo Sarkka and Arno Solin. _Applied stochastic differential equations_, volume 10. Cambridge University Press, 2019.
* [48] Jiaxin Shi, Chang Liu, and Lester Mackey. Sampling with Mirrored Stein Operators. _Proc. Int. Conf. Learn. Represent._, pages 1-26, 2022.
* [49] Yang Song, Sahaj Garg, Jiaxin Shi, and Stefano Ermon. Sliced score matching: A scalable approach to density and score estimation. In _Proc. Conf. Uncertainty in Artificial Intelligence_, pages 574-584, 2020.
* [50] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In _Proc. Int. Conf. Learn. Represent._, pages 1-36, 2020.
* [51] Yusuke Tashiro, Jiaming Song, Yang Song, and Stefano Ermon. CSDI: Conditional score-based diffusion models for probabilistic time series imputation. _Proc. Adv. Neural Inf. Process. Syst._, pages 24804-24816, 2021.
* [52] Pascal Vincent. A connection between score matching and denoising autoencoders. _Neural Comput._, 23(7):1661-1674, 2011.
* [53] Dilin Wang and Qiang Liu. Nonlinear stein variational gradient descent for learning diversified mixture models. In _Proc. Int. Conf. Mach. Learn._, pages 6576-6585, 2019.
* [54] Fangyikang Wang, Hubery Yin, Yuejiang Dong, Huminhao Zhu, Chao Zhang, Hanbin Zhao, Hui Qian, and Chen Li. BELM: Bidirectional explicit linear multi-step sampler for exact inversion in diffusion models. In _Proc. Adv. Neural Inf. Process. Syst._, pages 1-33, 2024.

* Wang et al. [2024] Fangyikang Wang, Huminhao Zhu, Chao Zhang, Hanbin Zhao, and Hui Qian. GAD-PVI: A general accelerated dynamic-weight particle-based variational inference framework. In _Proc. AAAI Conf. Artif. Intell._, pages 15466-15473, 2024.
* Wang et al. [2023] Hao Wang, Jiajun Fan, Zhichao Chen, Haoxuan Li, Weiming Liu, Tianqiao Liu, Quanyu Dai, Yichao Wang, Zhenhua Dong, and Ruiming Tang. Optimal transport for treatment effect estimation. In _Proc. Adv. Neural Inf. Process. Syst._, pages 5404-5418, 2023.
* Wang et al. [2024] Hao Wang, Zhichao Chen, Zhaoran Liu, Haozhe Li, Degui Yang, Xinggao Liu, and Haoxuan Li. Entire space counterfactual learning for reliable content recommendations. _IEEE Trans. Inf. Forensics Secur._, pages 1-1, 2024.
* Wang et al. [2024] Hao Wang, Zhichao Chen, Zhaoran Liu, Licheng Pan, Hu Xu, Yilin Liao, Haozhe Li, and Xinggao Liu. SPOT-I: Similarity preserved optimal transport for industrial iot data imputation. _IEEE Trans. Ind. Inform._, pages 1-9, 2024. doi: 10.1109/TII.2024.3452241.
* Wang et al. [2024] Jun Wang, Wenjie Du, Wei Cao, Keli Zhang, Wenjia Wang, Yuxuan Liang, and Qingsong Wen. Deep learning for multivariate time series imputation: A survey. _arXiv preprint arXiv:2402.04059_, pages 1-9, 2024.
* Wang et al. [2023] Xu Wang, Hongbo Zhang, Pengkun Wang, Yudong Zhang, Binwu Wang, Zhengyang Zhou, and Yang Wang. An observed value consistent diffusion model for imputing missing values in multivariate time series. In _Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining_, pages 2409-2418, 2023.
* Wang and Li [2022] Yifei Wang and Wuchen Li. Accelerated information gradient flow. _J. Sci. Comput._, 90:1-47, 2022.
* Welling and Teh [2011] Max Welling and Yee W Teh. Bayesian learning via stochastic gradient langevin dynamics. In _Proc. Int. Conf. Mach. Learn._, pages 681-688. Citeseer, 2011.
* Xu et al. [2023] Chen Xu, Xiuyuan Cheng, and Yao Xie. Normalizing flow neural networks by JKO scheme. In _Proc. Adv. Neural Inf. Process. Syst._, pages 47379-47405, 2023.
* Xu et al. [2023] Jingwen Xu, Fei Lyu, and Pong C Yuen. Density-aware temporal attentive step-wise diffusion model for medical time series imputation. In _Proc. ACM Int. Conf. Inf. Knowl. Manag._, pages 2836-2845, 2023.
* Yang et al. [2023] Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao, Wentao Zhang, Bin Cui, and Ming-Hsuan Yang. Diffusion models: A comprehensive survey of methods and applications. _ACM Comput. Surv._, 56(4):1-39, 2023.
* Yang et al. [2024] Yiyuan Yang, Ming Jin, Haomin Wen, Chaoli Zhang, Yuxuan Liang, Lintao Ma, Yi Wang, Chenghao Liu, Bin Yang, Zenglin Xu, et al. A survey on diffusion models for time series and spatio-temporal data. _arXiv preprint arXiv:2404.18886_, pages 1-27, 2024.
* Yoon et al. [2018] Jinsung Yoon, James Jordon, and Mihaela Schaar. GAIN: Missing data imputation using generative adversarial nets. In _Proc. Int. Conf. Mach. Learn._, pages 5689-5698. PMLR, 2018.
* Yu et al. [2006] Shipeng Yu, Kai Yu, Volker Tresp, Hans-Peter Kriegel, and Mingrui Wu. Supervised probabilistic principal component analysis. In _Proc. ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining_, pages 464-473, 2006.
* Zhang et al. [2022] Chao Zhang, Zhijian Li, Xin Du, and Hui Qian. Dpvi: A dynamic-weight particle-based variational inference framework. In _Proc. Int. Joint Conf. Artif. Intell._, pages 4900-4906, 2022.
* Zhang et al. [2019] Cheng Zhang, Judith Butepage, Hedvig Kjellstrom, and Stephan Mandt. Advances in variational inference. _IEEE Trans. Pattern Anal. Mach. Intell._, 41(8):2008-2026, 2019. doi: 10.1109/TPAMI.2018.2889774.
* Zhang et al. [2023] Yulong Zhang, Shuhao Chen, Weisen Jiang, Yu Zhang, Jiangang Lu, and James T Kwok. Domain-guided conditional diffusion model for unsupervised domain adaptation. _arXiv preprint arXiv:2309.14360_, pages 1-13, 2023.

* [72] He Zhao, Ke Sun, Amir Dezfouli, and Edwin V Bonilla. Transformed distribution matching for missing value imputation. In _Proc. Int. Conf. Mach. Learn._, pages 42159-42186, 2023.
* [73] Shuhan Zheng and Nontawat Charoenphakdee. Diffusion models for missing value imputation in tabular data. In _Proc. Adv. Neural Inf. Process. Syst. Workshop on First Table Representation_, 2022.
* [74] Huminhao Zhu, Fangyikang Wang, Chao Zhang, Hanbin Zhao, and Hui Qian. Neural sinkhorn gradient flow. _arXiv preprint arXiv:2401.14069_, pages 1-17, 2024.
* [75] Zhan Zhuang, Yu Zhang, and Ying Wei. Gradual domain adaptation via gradient flow. In _Proc. Int. Conf. Learn. Represent._, pages 1-27, 2024.
* [76] Zhan Zhuang, Yulong Zhang, Xuehao Wang, Jiangang Lu, Ying Wei, and Yu Zhang. Time-Varying LoRA: Towards effective cross-domain fine-tuning of diffusion models. In _Proc. Adv. Neural Inf. Process. Syst._, pages 1-25, 2024.

## Appendix Contents

* A Detailed Preliminaries of Wasserstein Gradient Flow
* B Detailed Information for Toy Cases in Section 3.1
* C Theoretical Analysis
* C.1 Implementation Difficulty of Velocity Field
* C.2 Proof & Discussions of Concerning Propositions and Corollaries
* D Detailed Explanation for the Workflow of NewImp Approach
* D.1 Forward Euler's Method for ODE Simulation
* D.2 Detailed Information for DSM
* E Detailed Information for Experiments
* E.1 Background & Simulation of Missing Data
* E.2 Hyperparameter Setting of Baseline Models
* F Additional Empirical Evidence
* F.1 Toy Case Experiments
* F.2 Additional Experimental Results with MNAR Scenario
* F.3 Empirical Evidence for Selecting RBF Function
* F.4 Time Complexity Analysis
* F.5 Convergence Analysis
* F.6 Downstream Task Comparison
* F.7 Baseline Comparison Vary Different Missing Rates and Scenarios
* G Limitations & Future Directions and Broader Impact
* G.1 Limitations & Future Directions
* G.2 Broader Impact Statement

## Appendix A Detailed Preliminaries of Wasserstein Gradient Flow

In this section, we want to introduce the WGF framework and its application scenarios to better understand this paper. Before introduction, the following concepts are listed to better understand the WGF framework:

1. **Wasserstein Metric:** Let \(\mathcal{P}_{2}(\mathbb{R}^{\mathrm{D}})\) represent the space of probability measures on \(\mathbb{R}^{\mathrm{D}}\) that possess finite second moments. Formally, this is expressed as \(\mathcal{P}_{2}(\mathbb{R}^{\mathrm{D}})=\{\mu\in\mathcal{M}(\mathbb{R}^{ \mathrm{D}})\mid\int\|x\|^{2}\mathrm{d}\mu(x)<\infty\}\), where \(\mathcal{M}(\mathbb{R}^{\mathrm{D}})\) denotes the set of all probability measures on \(\mathbb{R}^{\mathrm{D}}\). Considering any two probability measures \(\mu,\nu\in\mathcal{P}_{2}(\mathbb{R}^{\mathrm{D}})\), we define the Wasserstein-\(p\) distance between \(\mu\) and \(\nu\) as follows: \[\mathcal{W}_{p}=\left\{\inf_{\pi\in\Gamma(\mu,\nu)}\int_{\mathbb{R}^{\mathrm{ D}}\times\mathbb{R}^{\mathrm{D}}}\|x-y\|^{p}\mathrm{d}\pi(x,y)\right\}^{ \frac{1}{p}}.\] (A.1) Here, \(\Gamma(\mu,\nu)\) represents the collection of all joint distributions (couplings) between \(\mu\) and \(\nu\). For every joint distribution \(\pi\in\Gamma(\mu,\nu)\), it holds that \(\mu(x)=\int_{\mathbb{R}^{\mathrm{D}}}\pi(x,y)\,\mathrm{d}y\) and \(\nu(y)=\int_{\mathbb{R}^{\mathrm{D}}}\pi(x,y)\,\mathrm{d}x\). The integral on the right-hand side encapsulates the transportation cost in the optimal transport (OT) problem, framed by Kantorovich's formulation, where \(\pi^{*}\) denotes the optimal transportation plan. Furthermore, leveraging Jensen's inequality facilitates demonstrating the monotonicity of the Wasserstein-\(p\) distance, affirming that for \(1\leq p\leq q\), the relationship \(\mathcal{W}_{p}(\mu,\nu)\leq\mathcal{W}_{q}(\mu,\nu)\) invariably holds. Building on this principle, we can articulate the inner product within the measurable space \((\mathcal{P}_{2}(\mathbb{R}^{\mathrm{D}}),\mathcal{W})\) as delineated below: \[\langle\mu,\nu\rangle_{\mu_{\tau}}=\int_{\mathbb{R}^{\mathrm{D}}}\langle\mu, \nu\rangle_{\mathbb{R}^{\mathrm{D}}}\mathrm{d}\mu_{\tau}\] (A.2)
2. **Gradient Flow in Wasserstein Space:** Consider a functional \(\mathcal{F}\) associated with \(\mu\in\mathcal{P}_{2}(\mathbb{R}^{\mathrm{D}})\). Our objective is to identify the optimal \(\mu\) that minimizes \(\mathcal{F}\): \[\min_{\mu\in\mathcal{P}_{2}(\mathbb{R}^{\mathrm{D}})}\mathcal{F}(\mu)+\text{ const.}\] (A.3) To facilitate the decrease of \(\mathcal{F}(\mu)\), we introduce a velocity field \(u_{\mu}:\mathbb{R}^{\mathrm{D}}\to\mathbb{R}^{\mathrm{D}}\) designed to expedite the reduction of \(\mathcal{F}(\mu)\) as \(\mu\) evolves under this field. Utilizing the chain rule yields: \[\frac{\mathrm{d}\mathcal{F}(\mu)}{\mathrm{d}\tau}=\int\left\langle\nabla\frac{ \delta\mathcal{F}(\mu)}{\delta\mu},u_{\mu}\right\rangle\,\mathrm{d}\mu,\] (A.4) where \(\delta\) represents the first variation operator. To ensure the decrease of \(\mathcal{F}(\mu)\), i.e., \(\frac{\mathrm{d}\mathcal{F}(\mu)}{\mathrm{d}\tau}\leq 0\), the velocity field is defined as: \[u_{\mu}=-\nabla\frac{\delta\mathcal{F}(\mu)}{\delta\mu}.\] (A.5) The decline of \(\mathcal{F}(\mu)\) aligns with the following partial differential equation (PDE) called the continuity equation: \[\frac{\partial\mu}{\partial\tau}=-\nabla\cdot(\mu u_{\mu}).\] (A.6) Hence, the continuity equation Eq. (A.6), coupled with the velocity field articulated in Eq. (A.5), is recognized as the _Wasserstein Gradient Flow_, delineating the steepest descent direction of cost functional \(\mathcal{F}(\mu)\) in the Wasserstein space.
3. **Simulation of WGF & Sampling:** There are primarily two discretization techniques for the WGF: the forward scheme and the backward scheme.
4. **Forward Scheme:** The forward scheme applies gradient descent within the Wasserstein space to identify the direction of the steepest descent. For an energy functional \(\mathcal{F}(\mu)\) with a specified step size \(\eta\), the update rule in the forward scheme is formulated as: \[\mu_{\tau+1}=(\mathrm{Id}-\nabla\frac{\delta\mathcal{F}(\mu)}{\delta\mu})_{ \#}\mu_{\tau},\] (A.7) facilitating an intuitive and direct update mechanism that emulates the gradient flow in the Euclidean space but transposed into the Wasserstein space.

[MISSING_PAGE_FAIL:18]

## Appendix C Theoretical Analysis

### Implementation Difficulty of Velocity Field

To the best of our knowledge, the difficulty of implementing the velocity field can be given from two perspectives, namely ODE-based implementation and SDE-based implementation. In this section, we want to discuss these two implementation approaches in detail.

**ODE-based Implementation:**

1. **WGF framework:** According to the continuity equation, we can obtain the following velocity field: \[\frac{\mathrm{d}\bm{X}^{\text{(miss)}}}{\mathrm{d}\tau}\overset{ \text{(i)}}{=}u(\bm{X}^{\text{(miss)}})\overset{\text{(ii)}}{=}-[\nabla_{\bm{X} ^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})+ \lambda\nabla_{\bm{X}^{\text{(miss)}}}\log r(\bm{X}^{\text{(miss)}})],\] (C.1) where (i) is based on Section 2.3, and (ii) is based on Section 4.1. The expression of the velocity field involves the computation of density term \(r(\bm{X}^{\text{(miss)}})\)[31; 9], which is intractable during practice as we stated in Section 2.3. Based on this, we conclude that implementing this velocity field within the WGF framework is difficult.
2. **Probability flow ODE:** According to reference [50], if we directly plug Eq. (8) into the FPK equation, we can get the following PDE: \[\frac{\partial r(\bm{X}^{\text{(miss)}})}{\partial\tau}\] (C.2) \[= -\nabla\cdot(u(\bm{X}^{\text{(miss)}})r(\bm{X}^{\text{(miss)}}))\] \[= -\left[\nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{ (miss)}}|\bm{X}^{\text{(obs)}})r(\bm{X}^{\text{(miss)}})\right]-\lambda\nabla \cdot\nabla r(\bm{X}^{\text{(miss)}})\] \[-[\nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{(miss) }}|\bm{X}^{\text{(obs)}})r(\bm{X}^{\text{(miss)}})]-\lambda\nabla\cdot\nabla r( \bm{X}^{\text{(miss)}})\] \[= \underbrace{1}_{=0}^{2}\sigma_{\tau}^{2}\nabla\cdot\nabla r(\bm{X }^{\text{(miss)}})-\frac{1}{2}\sigma_{\tau}^{2}\nabla\cdot\nabla r(\bm{X}^{ \text{(miss)}})}_{=0}\] \[-\left\{\left[\nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^ {\text{(miss)}}|\bm{X}^{\text{(obs)}})+(\lambda+\frac{1}{2}\sigma_{\tau}^{2}) \nabla\log r(\bm{X}^{\text{(miss)}})\right]r(\bm{X}^{\text{(miss)}})\right\}\] \[= +\frac{1}{2}\sigma_{\tau}^{2}\nabla\cdot\nabla r(\bm{X}^{\text{ (miss)}}).\] When we set \(\sigma_{\tau}\) as \(0\), we can find that the corresponding ODE is Eq. (C.1), where we are obliged to compute the intractable density \(r(\bm{X}^{\text{(miss)}})\).

**SDE-based Implementation:**

If we plug Section 4.1 into the FPK equation, the corresponding PDE can be given as follows:

\[\frac{\partial r(\bm{X}^{\text{(miss)}})}{\partial\tau}\] (C.3) \[= -\nabla\cdot(u(\bm{X}^{\text{(miss)}})r(\bm{X}^{\text{(miss)}}))\] \[= -\left[\nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{ (miss)}}|\bm{X}^{\text{(obs)}})r(\bm{X}^{\text{(miss)}})\right]-\lambda\nabla \cdot\nabla r(\bm{X}^{\text{(miss)}}),\]

where the coefficient before the Laplacian operator \(\nabla\cdot\nabla\) is \(-1\). To the best of our knowledge, this structure makes deriving a corresponding SDE impossible by current approaches.

### Proof & Discussions of Concerning Propositions and Corollaries

**Proposition** (3.1).: _Within WGF framework, DM-based MDI approaches can be viewed as finding the imputed values \(\bm{X}^{\text{(imp)}}\) that maximize the following objective:_

\[\operatorname*{arg\,max}_{r(\bm{X}^{\text{(moi)}})}\quad\mathbb{E}_{r(\bm{X}^ {\text{(moi)}})}[\log\hat{p}(\bm{X}^{\text{(mix)}}|\bm{X}^{\text{(obs)}})]+ \psi(\bm{X}^{\text{(miss)}})+\text{const},\] (C.4)

_where 'const' is the abbreviation of constant, and \(\psi(\bm{X}^{\text{(miss)}})\) is a scalar function determined by the type of SDE underlying the DMs._* _VP-SDE:_: \(\psi(\bm{X}^{\text{(miss)}})=\frac{1}{2}\mathbb{H}[r(\bm{X}^{\text{(miss)}})]+ \mathbb{E}_{r(\bm{X}^{\text{(miss)}})}\{\frac{1}{4}[\bm{X}^{\text{(miss)}}]^{ \top}[\bm{X}^{\text{(miss)}}]\}\geq 0\)
* _VE-SDE:_: \(\psi(\bm{X}^{\text{(miss)}})=\frac{1}{2}\mathbb{H}[r(\bm{X}^{\text{(miss)}})]\geq 0\)
* _sub-VP-SDE:_: \(\psi(\bm{X}^{\text{(miss)}})=\frac{1}{2}\mathbb{H}[r(\bm{X}^{\text{(miss)}})]+ \mathbb{E}_{r(\bm{X}^{\text{(miss)}})}\{\frac{1}{4\gamma_{\tau}}[\bm{X}^{\text{ (miss)}}]^{\top}[\bm{X}^{\text{(miss)}}]\}\geq 0\)_,_

_where \(\mathbb{H}[r(\bm{X}^{\text{(miss)}})]\coloneqq-\int r(\bm{X}^{\text{(miss)}}) \log r(\bm{X}^{\text{(miss)}})\mathrm{d}\bm{X}^{\text{(miss)}}\) is the entropy term, \(\gamma_{\tau}\) is determined by noise scale \(\beta_{\tau}\): \(\gamma_{\tau}\coloneqq(1-\exp(-2\int_{0}^{\tau}\beta_{s}\mathrm{d}s))>0,0<\beta _{1}<\dots<\beta_{T}<1\)._

Proof.: Since there are various approaches for reversing the sampling procedure of DMs, for simplicity, as we emphasized in Section 3.2, we mainly consider the VP-SDE, VE-SDE, and sub-VP-SDE as analysis objects in this paper.

* **VP-SDE:** According to reference [50], the density evolution of the generative process for VP-SDE can be delineated by the following PDE: \[\begin{split}\frac{\partial r(\bm{X}^{\text{(miss)}})}{\partial \tau}=&-\nabla_{\bm{X}^{\text{(miss)}}}\cdot\left\{r(\bm{X}^{ \text{(miss)}})\left[\beta_{\tau}\right]\left[\frac{1}{2}\bm{X}^{\text{(miss)} }+\nabla_{\bm{X}^{\text{(miss)}}}\!\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{ \text{(obs)}})\right]\right\}\\ &+\frac{\beta_{\tau}}{2}\nabla_{\bm{X}^{\text{(miss)}}}\cdot \nabla_{\bm{X}^{\text{(miss)}}}r(\bm{X}^{\text{(miss)}})\end{split}\] (C.5) where \(\beta_{\tau}\in(0,1)\) is the time-varying noise scale. On this basis, according to [24], by changing the variable as \(\mathrm{d}\tau\coloneqq\frac{\beta_{\tau}}{2}\mathrm{d}\tau\), we can get the following equation: \[\begin{split}\frac{\partial r(\bm{X}^{\text{(miss)}})}{\partial \tau}=-\nabla_{\bm{X}^{\text{(miss)}}}\cdot\left\{r(\bm{X}^{\text{(miss)}})[ \frac{1}{2}\bm{X}^{\text{(miss)}}+\nabla_{\bm{X}^{\text{(miss)}}}\!\log\hat{p}( \bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})\right\}\\ &\qquad\qquad\qquad-\frac{1}{2}\nabla_{\bm{X}^{\text{(miss)}}} \log r(\bm{X}^{\text{(miss)}})]\end{split}\right\}.\] (C.6) Comparing Eq. (C.6) with Eqs. (A.5) and (A.6), the cost functional to be minimized of this simulation procedure can be given as follows: \[\begin{split}\mathcal{F}_{\text{VP-SDE}}&=-\int r( \bm{X}^{\text{(miss)}})\left\{\begin{aligned} &\frac{1}{4}[\bm{X}^{\text{(miss)}}]^{\top}[\bm{X}^{\text{(miss)}}]+ \log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})\\ &-\frac{1}{2}\log r(\bm{X}^{\text{(miss)}})+\text{const}\end{aligned} \right\}\mathrm{d}\bm{X}^{\text{(miss)}}\\ &=-\mathbb{E}_{r(\bm{X}^{\text{(miss)}})}\left\{\begin{aligned} &\frac{1}{4}[\bm{X}^{\text{(miss)}}]^{\top}[\bm{X}^{\text{(miss)}}]+ \log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})\\ &-\frac{1}{2}\log r(\bm{X}^{\text{(miss)}})+\text{const}\end{aligned} \right\}.\end{split}\] (C.7) Note that \(\frac{1}{4}[\bm{X}^{\text{(miss)}}]^{\top}[\bm{X}^{\text{(miss)}}]\geq 0\) and \(-\frac{1}{2}\int r(\bm{X}^{\text{(miss)}})\log r(\bm{X}^{\text{(miss)}}) \mathrm{d}\bm{X}^{\text{(miss)}}\geq 0\) hold, and thus the proposition for VP-SDE is proved by taking the negative of the abovementioned equation.
* **VE-SDE:** Similarly, based on reference [50], the following PDE can be given to delineate the density evolution of the generative process for VE-SDE: \[\begin{split}\frac{\partial r(\bm{X}^{\text{(miss)}})}{\partial \tau}&=-\nabla_{\bm{X}^{\text{(miss)}}}\cdot\left\{r(\bm{X}^{ \text{(miss)}})\left[-\frac{\mathrm{d}\sigma_{\tau}^{2}}{\mathrm{d}\tau} \right]\nabla_{\bm{X}^{\text{(miss)}}}\!\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X} ^{\text{(obs)}})\right\}\\ &+\frac{1}{2}\frac{\mathrm{d}\sigma_{\tau}^{2}}{\mathrm{d}\tau} \nabla_{\bm{X}^{\text{(miss)}}}\cdot\nabla_{\bm{X}^{\text{(miss)}}r}(\bm{X}^{ \text{(miss)}}),\end{split}\] (C.8) where \(\sigma_{\tau}^{2}\) is a time varying noise scale. As such, by changing the variable as \(\mathrm{d}\tau\coloneqq\left[\frac{\mathrm{d}\sigma_{\tau}^{2}}{\mathrm{d}\tau} \right]\mathrm{d}\tau\)[24], Eq. (C.8) can be reformulated as follows: \[\frac{\partial r(\bm{X}^{\text{(miss)}})}{\partial\tau}=-\nabla_{\bm{X}^{\text{ (miss)}}}\cdot\left\{r(\bm{X}^{\text{(miss)}})\left[\nabla_{\bm{X}^{\text{(miss)}}} \!\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})-\frac{1}{2}\nabla_{ \bm{X}^{\text{(miss)}}}\log r(\bm{X}^{\text{(miss)}})\right]\right\}.\] (C.9)Comparing Eq. (C.9) with Eqs. (A.5) and (A.6), the cost functional to be minimized of this simulation procedure can be given as follows: \[\begin{split}\mathcal{F}_{\text{VE-SDE}}&=\int r( \boldsymbol{X}^{\text{(miss)}})\left\{\frac{1}{2}\log r(\boldsymbol{X}^{\text{ (miss)}})-\log\hat{p}(\boldsymbol{X}^{\text{(miss)}}|\boldsymbol{X}^{\text{ (obs)}})+\text{const}\right\}\mathrm{d}\boldsymbol{X}^{\text{(miss)}}\\ &=-\mathbb{E}_{r(\boldsymbol{X}^{\text{(miss)}})}\left\{-\frac{1}{ 2}\log r(\boldsymbol{X}^{\text{(miss)}})+\log\hat{p}(\boldsymbol{X}^{\text{ (miss)}}|\boldsymbol{X}^{\text{(obs)}})+\text{const}\right\}.\end{split}\] (C.10) Note that the entropy function \(-\frac{1}{2}\int r(\boldsymbol{X}^{\text{(miss)}})\log r(\boldsymbol{X}^{\text {(miss)}})\mathrm{d}\boldsymbol{X}^{\text{(miss)}}\geq 0\) holds, and thus the proposition for VE-SDE is proved by taking the negative of the abovementioned equation.
* **sub-VP-SDE:** Based on reference [50], the following PDE can be given to delineate the density evolution of the generative process for sub-VP-SDE: \[\begin{split}\frac{\partial r(\boldsymbol{X}^{\text{(miss)}})}{ \partial\tau}=&-\nabla_{\boldsymbol{X}^{\text{(miss)}}}\cdot \left\{r(\boldsymbol{X}^{\text{(miss)}})\left[\beta_{\tau}\right]\left[\frac{ 1}{2}\boldsymbol{X}^{\text{(miss)}}+\gamma_{\tau}\nabla_{\boldsymbol{X}^{ \text{(miss)}}}\log\hat{p}(\boldsymbol{X}^{\text{(miss)}}|\boldsymbol{X}^{ \text{(obs)}})\right]\right\}\\ +&\frac{\beta_{\tau}}{2}\gamma_{\tau}\nabla_{ \boldsymbol{X}^{\text{(miss)}}}\cdot\nabla_{\boldsymbol{X}^{\text{(miss)}}}r( \boldsymbol{X}^{\text{(miss)}}),\end{split}\] (C.11) where \(\gamma_{\tau}\coloneqq(1-\exp(-2\int_{0}^{\tau}\beta_{s}\mathrm{d}s))>0\). On this basis, by chaning the variable as \(\mathrm{d}\tau\coloneqq\frac{\beta_{\tau}}{2}\mathrm{d}\tau\), we can get the following equation: \[\frac{\partial r(\boldsymbol{X}^{\text{(miss)}})}{\partial\tau}=-\nabla_{ \boldsymbol{X}^{\text{(miss)}}}\cdot\left\{\begin{aligned} r( \boldsymbol{X}^{\text{(miss)}})&[\frac{1}{2}\boldsymbol{X}^{ \text{(miss)}}+\gamma_{\tau}\nabla_{\boldsymbol{X}^{\text{(miss)}}}\log\hat{p} (\boldsymbol{X}^{\text{(miss)}}|\boldsymbol{X}^{\text{(obs)}})\\ &-\frac{\gamma_{\tau}}{2}\nabla_{\boldsymbol{X}^{\text{(miss)}}} \log r(\boldsymbol{X}^{\text{(miss)}})]\end{aligned}\right\}.\] (C.12) Comparing Eq. (C.12) with Eqs. (A.5) and (A.6), the cost functional to be minimized of this simulation procedure can be given as follows: \[\begin{split}\mathcal{F}_{\text{sub-VP-SDE}}&=- \int r(\boldsymbol{X}^{\text{(miss)}})\left\{\begin{aligned} &\frac{1}{4}[ \boldsymbol{X}^{\text{(miss)}}]^{\top}[\boldsymbol{X}^{\text{(miss)}}]+ \gamma_{\tau}\log\hat{p}(\boldsymbol{X}^{\text{(miss)}}|\boldsymbol{X}^{\text {(obs)}})\\ &-\frac{\gamma_{\tau}}{2}\log r(\boldsymbol{X}^{\text{(miss)}})+ \text{const}\end{aligned}\right\}\mathrm{d}\boldsymbol{X}^{\text{(miss)}}\\ &=-\mathbb{E}_{r(\boldsymbol{X}^{\text{(miss)}})}\left\{\begin{aligned} &\frac{1}{4}[ \boldsymbol{X}^{\text{(miss)}}]^{\top}[\boldsymbol{X}^{\text{(miss)}}]+ \gamma_{\tau}\log\hat{p}(\boldsymbol{X}^{\text{(miss)}}|\boldsymbol{X}^{ \text{(obs)}})\\ &-\frac{\gamma_{\tau}}{2}\log r(\boldsymbol{X}^{\text{(miss)}})+ \text{const}\end{aligned}\right\}\\ &=-\mathbb{E}_{r(\boldsymbol{X}^{\text{(miss)}})}\left\{\begin{aligned} &\frac{1}{4\gamma_{\tau}}[ \boldsymbol{X}^{\text{(miss)}}]^{\top}[\boldsymbol{X}^{\text{(miss)}}]+ \log\hat{p}(\boldsymbol{X}^{\text{(miss)}}|\boldsymbol{X}^{\text{(obs)}})\\ &-\frac{1}{2}\log r(\boldsymbol{X}^{\text{(miss)}})+ \text{const}\end{aligned}\right\}.\end{split}\] (C.13) Note that \(\frac{1}{4\gamma_{\tau}}[\boldsymbol{X}^{\text{(miss)}}]^{\top}[ \boldsymbol{X}^{\text{(miss)}}]\geq 0\) and \(-\frac{1}{2}\int r(\boldsymbol{X}^{\text{(miss)}})\log r(\boldsymbol{X}^{\text{ (miss)}})\mathrm{d}\boldsymbol{X}^{\text{(miss)}}\geq 0\) hold, and thus the proposition for sub-VP-SDE is proved by taking the negative of the abovementioned equation.

In summary, the regularization term \(\psi(\boldsymbol{X}^{\text{(miss)}})\) for VP-SDE is \(\mathbb{E}_{r(\boldsymbol{X}^{\text{(miss)}})}\{\frac{1}{4}[\boldsymbol{X}^{ \text{(miss)}}]^{\top}[\boldsymbol{X}^{\text{(miss)}}]\}+\frac{1}{2}\mathbb{H }[r(\boldsymbol{X}^{\text{(miss)}})]\), for VE-SDE is \(\frac{1}{2}\mathbb{H}(r(\boldsymbol{X}^{\text{(miss)}}))\), and for sub-VP-SDE is \(\mathbb{E}_{r(\boldsymbol{X}^{\text{(miss)}})}\{\frac{1}{4\gamma_{\tau}}[ \boldsymbol{X}^{\text{(miss)}}]^{\top}[\boldsymbol{X}^{\text{(miss)}}]\}+\frac{1 }{2}\mathbb{H}[r(\boldsymbol{X}^{\text{(miss)}})]\). 

Before proving Proposition 4.1, we want to introduce the following lemma to delineate the evolution of cost functional \(\mathcal{F}_{\text{NER}}\) along time \(\tau\):

**Lemma C.1**.: _The evolution of \(\mathcal{F}_{\text{NER}}\) along time \(\tau\) can be characterized by the following ODE, assuming that the boundary condition \(\lim_{\boldsymbol{X}^{\text{(miss)}}\to\infty}[u(\boldsymbol{X}^{\text{(miss)}}) r(\boldsymbol{X}^{\text{(miss)}})]=0\) is satisfied:_

\[\frac{\mathrm{d}\mathcal{F}_{\text{NER}}}{\mathrm{d}\tau}=\mathbb{E}_{r( \boldsymbol{X}^{\text{(min)}})}[u^{\top}(\boldsymbol{X}^{\text{(miss)}})\nabla_{ \boldsymbol{X}^{\text{(noise)}}}\log\hat{p}(\boldsymbol{X}^{\text{(miss)}}| \boldsymbol{X}^{\text{(obs)}})-\lambda\nabla_{\boldsymbol{X}^{\text{(noise)}}}\cdot u (\boldsymbol{X}^{\text{(miss)}})].\] (C.14)

_This boundary condition is achievable, for instance, when \(r(\boldsymbol{X}^{\text{(miss)}})\) is bounded, and the limit of the velocity field as the norm of \(\boldsymbol{X}^{\text{(miss)}}\) approaches infinity is zero (\(\lim_{\|\boldsymbol{X}^{\text{(noise)}}\|\to\infty}u(\boldsymbol{X}^{\text{(miss)}})=0\))._Proof.: Before proving this lemma, we should recognize that the evolution of \(\bm{X}^{\text{(miss)}}\) should promise the probability density function \(r(\bm{X}^{\text{(miss)}})\) unchanged. In other words, the following continuity equation should be satisfied during the optimization of \(r(\bm{X}^{\text{(miss)}})\):

\[\frac{\partial r(\bm{X}^{\text{(miss)}})}{\partial\tau}=-\nabla_{\bm{X}^{\text{ (miss)}}}\cdot[r(\bm{X}^{\text{(miss)}})u(\bm{X}^{\text{(miss)}})].\] (C.15)

On this basis, the evolution of \(\mathcal{F}_{\text{NER}}\) along time \(\tau\), \(\frac{\mathrm{d}\mathcal{F}_{\text{NER}}}{\mathrm{d}\tau}\), can be given as follows based on the chain rule:

\[\frac{\mathrm{d}\mathcal{F}_{\text{NER}}}{\mathrm{d}\tau}\] (C.16) \[= \int\frac{\partial r(\bm{X}^{\text{(miss)}})}{\partial\tau} \left[\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})+\lambda\log r (\bm{X}^{\text{(miss)}})+\lambda\right]\mathrm{d}\bm{X}^{\text{(miss)}}\] \[= \int-\{\nabla_{\bm{X}^{\text{(miss)}}}\cdot[r(\bm{X}^{\text{( miss)}})u(\bm{X}^{\text{(miss)}})]\}[\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})+\lambda\log r (\bm{X}^{\text{(miss)}})+\lambda]\mathrm{d}\bm{X}^{\text{(miss)}}\] \[\overset{\text{(i)}}{=} \int[r(\bm{X}^{\text{(miss)}})u(\bm{X}^{\text{(miss)}})]^{\top} \nabla_{\bm{X}^{\text{(miss)}}}[\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{ \text{(obs)}})+\lambda\log r(\bm{X}^{\text{(miss)}})+\lambda]\mathrm{d}\bm{X}^{ \text{(miss)}}\] \[= \int[r(\bm{X}^{\text{(miss)}})u(\bm{X}^{\text{(miss)}})]^{\top}\{ \nabla_{\bm{X}^{\text{(miss)}}}[\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{ \text{(obs)}})+\lambda\log r(\bm{X}^{\text{(miss)}})]\}\mathrm{d}\bm{X}^{\text {(miss)}}\] \[= \int[u(\bm{X}^{\text{(miss)}})]^{\top}[r(\bm{X}^{\text{(miss)}}) \nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{ \text{(obs)}})+\lambda\pi(\bm{X}^{\text{(miss)}})\nabla_{\bm{X}^{\text{(min)}} }\log r(\bm{X}^{\text{(miss)}})]\mathrm{d}\bm{X}^{\text{(miss)}}\] \[= \int[u(\bm{X}^{\text{(miss)}})]^{\top}[r(\bm{X}^{\text{(miss)}}) \nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{ \text{(obs)}})+\lambda\nabla_{\bm{X}^{\text{(miss)}}}r(\bm{X}^{\text{(miss)}})] \mathrm{d}\bm{X}^{\text{(miss)}}\] \[\overset{\text{(ii)}}{=} \int r(\bm{X}^{\text{(miss)}})[u^{\top}(\bm{X}^{\text{(miss)}}) \nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{ \text{(obs)}})-\lambda\nabla_{\bm{X}^{\text{(miss)}}}\cdot u(\bm{X}^{\text{( miss)}})]\mathrm{d}\bm{X}^{\text{(miss)}}\] \[= \mathbb{E}_{r(\bm{X}^{\text{(miss)}})}[u^{\top}(\bm{X}^{\text{( miss)}})\nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})-\lambda \nabla_{\bm{X}^{\text{(miss)}}}\cdot u(\bm{X}^{\text{(miss)}})],\]

where (i) and (ii) are based on integration by parts. More specifically, when condition \(\lim_{\bm{X}^{\text{(miss)}}\to\infty}[u(\bm{X}^{\text{(miss)}})r(\bm{X}^{ \text{(miss)}})]=0\) is satisfied, for example, \(r(\bm{X}^{\text{(miss)}})\) is bounded, and the limit of the velocity field as the norm of \(\bm{X}^{\text{(miss)}}\) approaches infinity is zero (\(\lim_{\|\bm{X}^{\text{(miss)}}\|\to\infty}u(\bm{X}^{\text{(miss)}})=0\)), we can get the following result [35, 32]:

\[\int\nabla_{\bm{X}^{\text{(miss)}}}\cdot[r(\bm{X}^{\text{(miss)}})u(\bm{X}^{ \text{(miss)}})]\mathrm{d}\bm{X}^{\text{(miss)}}=0,\]

where the left-hand-side can be further decomposed as follows based on the integration by parts:

\[\int\nabla_{\bm{X}^{\text{(miss)}}}\cdot[r(\bm{X}^{\text{(miss)}} )u(\bm{X}^{\text{(miss)}})]\mathrm{d}\bm{X}^{\text{(miss)}}= \int u^{\top}(\bm{X}^{\text{(miss)}})\nabla_{\bm{X}^{\text{(miss)}}} r(\bm{X}^{\text{(miss)}})\mathrm{d}\bm{X}^{\text{(miss)}}\] \[+ \int[\nabla_{\bm{X}^{\text{(miss)}}}\cdot u(\bm{X}^{\text{(miss)}})] r(\bm{X}^{\text{(miss)}})\mathrm{d}\bm{X}^{\text{(miss)}}.\]

Based on Lemma C.1, we can now start proving Proposition 4.1:

**Proposition** (4.1).: _Suppose \(u(\bm{X}^{\text{(miss)}})\) is a velocity field regularized by the RKHS norm under the following conditions: 1). The kernel function satisfies: \(\lim_{\|\bm{X}^{\text{(miss)}}\|\to\infty}K(\bm{X}^{\text{(miss)}},\tilde{\bm{X} }^{\text{(miss)}})=0\). 2). The density \(r(\bm{X}^{\text{(miss)}})\) is bounded. Then, the velocity field that minimizes the cost functional \(\mathcal{F}_{\text{NER}}=\mathbb{E}_{r(\bm{X}^{\text{(miss)}})}[\log\hat{p}( \bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})]-\lambda\mathbb{H}[r(\bm{X}^{\text{ (miss)}})]\) can be given by:_

\[u(\bm{X}^{\text{(miss)}})=\mathbb{E}_{r(\tilde{\bm{X}}^{\text{(miss)}})}\left\{ \begin{aligned} -\lambda\nabla_{\tilde{\bm{X}}^{\text{(miss)}}}K(\bm{X}^{\text{(mix)}}, \tilde{\bm{X}}^{\text{(miss)}})\\ +[\nabla_{\tilde{\bm{X}}^{\text{(miss)}}}\log\hat{p}(\tilde{\bm{X}}^{ \text{(miss)}}|\bm{X}^{\text{(obs)}})]^{\top}K(\bm{X}^{\text{(miss)}},\tilde{\bm{ X}}^{\text{(miss)}})\end{aligned}\right\}.\] (C.17)

_where the expectation term \(\mathbb{E}_{r(\tilde{\bm{X}}^{\text{(miss)}})}\) can be efficiently estimated using Monte Carlo approximation._Proof.: When the velocity is regularized by the RKHS norm, we can first reformulate Eq. (8) as follows to find the steepest direction for the sake of improving \(\mathcal{F}_{\text{NER}}\):

\[u^{*}(\bm{X}^{\text{(miss)}})=\operatorname*{arg\,max}_{u(\bm{X}^{\text{(miss)} })\in\mathcal{H}}\left\{\mathbb{E}_{r(\bm{X}^{\text{(miss)}})}[u^{\top}(\bm{X} ^{\text{(miss)}})\nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{(miss) }}|\bm{X}^{\text{(obs)}})\right.\] (C.18)

Based on this, assume we have a map function \(\phi(x)\), the kernel function can be given as follows:

\[K(x,y)=\left\langle\phi(x),\phi(y)\right\rangle_{\mathcal{H}}.\] (C.19)

Hence, the regularization term that control the magnitude of \(u(\bm{X}^{\text{(miss)}})\) can be given by \(\frac{1}{2}\|u(\bm{X}^{\text{(miss)}})\|_{\mathcal{H}}^{2}\), and the spectral decomposition of kernel function can be given as follows:

\[K(x,y)=\sum_{i=1}^{\infty}\xi_{i}\phi_{i}(x)\phi_{i}(y),\] (C.20)

where \(\phi_{i}(\cdot)\) indicates the orthonormal basis and \(\xi_{i}\) is the corresponding eigen-value. For any function \(u(\bm{X}^{\text{(miss)}})\in\mathcal{H}\), the following decomposition is given:

\[u(\bm{X}^{\text{(miss)}})=\sum_{i=1}^{\infty}u_{i}\sqrt{\xi_{i}}\phi_{i}(\bm{X }^{\text{(miss)}}),\] (C.21)

where \(u_{i}\) and \(\sum_{i=1}^{\infty}\|u_{i}\|^{2}<\infty\).

The learning objective defined in Eq. (8) can be reformulated as follows:

\[u^{*}(\bm{X}^{\text{(miss)}})\] (C.22) \[=\operatorname*{arg\,max}_{u(\bm{X}^{\text{(miss)}})\in\mathcal{H}} \left\{\mathbb{E}_{r(\bm{X}^{\text{(miss)}})}[u^{\top}(\bm{X}^{\text{( miss)}})\nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{ \text{(obs)}})\right.\] \[=\operatorname*{arg\,max}_{u(\bm{X}^{\text{(miss)}})\in\mathcal{H}} -\lambda\nabla_{\bm{X}^{\text{(miss)}}}\cdot u(\bm{X}^{\text{(miss)}})] \}-\frac{1}{2}\|u(\bm{X}^{\text{(miss)}})\|_{\mathcal{H}}^{2},\] \[\overset{\text{(i)}}{=}\operatorname*{arg\,max}_{u(\bm{X}^{\text {(miss)}})\in\mathcal{H}} -\lambda\nabla_{\tilde{\bm{X}}^{\text{(miss)}}}\cdot\sum_{i=1}^{ \infty}u_{i}\sqrt{\xi_{i}}\phi_{i}(\tilde{\bm{X}}^{\text{(miss)}})]\}-\frac{1 }{2}\sum_{i=1}^{\infty}\|u_{i}\|^{2},\]

Take the right-hand-side of (i) with-respect-to \(u_{i}\), and set it to \(0\), we can get:

\[\sqrt{\xi_{i}}\{\mathbb{E}_{r(\tilde{\bm{X}}^{\text{(miss)}})}[[\nabla_{\tilde {\bm{X}}^{\text{(miss)}}}\log\hat{p}(\tilde{\bm{X}}^{\text{(miss)}}|\bm{X}^{ \text{(obs)}})]^{\top}\phi_{i}(\tilde{\bm{X}}^{\text{(miss)}})-\lambda\nabla_{ \tilde{\bm{X}}^{\text{(miss)}}}\phi_{i}(\tilde{\bm{X}}^{\text{(miss)}})]\}-u_{ i}=0.\] (C.23)

On this basis, \(u_{i}^{*}\) can be given as follows:

\[u_{i}^{*}=\sqrt{\xi_{i}}\{\mathbb{E}_{r(\tilde{\bm{X}}^{\text{(miss)}})}[[ \nabla_{\tilde{\bm{X}}^{\text{(miss)}}}\log\hat{p}(\tilde{\bm{X}}^{\text{( miss)}}|\bm{X}^{\text{(obs)}})]^{\top}\phi_{i}(\bm{X}^{\text{(miss)}})-\lambda \nabla_{\tilde{\bm{X}}^{\text{(miss)}}}\phi_{i}(\tilde{\bm{X}}^{\text{(miss)}})]\},\] (C.24)

and hence, \(u(\bm{X}^{\text{(miss)}})\) can be given as follows:

\[u^{*}(\bm{X}^{\text{(miss)}})\] (C.25) \[= \sum_{i=1}^{\infty}\sqrt{\xi_{i}}u_{i}^{*}\phi_{i}(\bm{X}^{\text {(miss)}})\] \[= \mathbb{E}_{r(\tilde{\bm{X}}^{\text{(miss)}})}\left[\begin{array} []{c}-\lambda\nabla_{\tilde{\bm{X}}^{\text{(miss)}}}K(\bm{X}^{\text{(miss)}}, \tilde{\bm{X}}^{\text{(miss)}})\\ +[\nabla_{\tilde{\bm{X}}^{\text{(miss)}}}\log\hat{p}(\tilde{\bm{X}}^{\text{( miss)}}|\bm{X}^{\text{(obs)}})]^{\top}K(\bm{X}^{\text{(miss)}},\tilde{\bm{X}}^{\text{( miss)}})\end{array}\right].\]

**Proposition** (4.2).: _Assume that the proposal distribution \(r(\bm{X}^{\text{(joint)}})\) is factorized by \(r(\bm{X}^{\text{(joint)}}):=r(\bm{X}^{\text{(miss)}})p(\bm{X}^{\text{(obs)}})\). The cost functional associated with the joint distribution is defined as follows:_

\[\mathcal{F}_{\text{joint-NER}}\coloneqq\mathbb{E}_{r(\bm{X}^{\text{(joint)}})}[ \log\hat{p}(\bm{X}^{\text{(joint)}})]-\lambda\mathbb{H}[r(\bm{X}^{\text{( joint)}})],\] (C.26)

_which leads to the velocity field delineated in Eq. (9) and establishes \(\mathcal{F}_{\text{joint-NER}}\) as a lower bound for \(\mathcal{F}_{\text{NER}}\), with the difference being a constant (i.e., \(\mathcal{F}_{\text{joint-NER}}=\mathcal{F}_{\text{NER}}-\text{const},\text{const} \geq 0\))._Before proving this proposition, we want to first clarify the justification of the assumption that \(r(\bm{X}^{\text{(join)}})\coloneqq r(\bm{X}^{\text{(miss)}})r(\bm{X}^{\text{( obs)}})=r(\bm{X}^{\text{(miss)}})p(\bm{X}^{\text{(obs)}})\). In this part, we set \(r(\bm{X}^{\text{(obs)}})=p(\bm{X}^{\text{(obs)}})\). Before stating the justification, we should come to the following agreements:

1. Throughout the imputation procedure, \(\bm{X}^{\text{(obs)}}\) remains invariant regardless of any modifications to \(\bm{X}^{\text{(miss)}}\).
2. Given this invariance, it is justified to state that \(r(\bm{X}^{\text{(obs)}})\) remains constant from the perspective of particle variational inference represented by reference [35, 34], and consequently \(r(\bm{X}^{\text{(obs)}}|\bm{X}^{\text{(miss)}})=r(\bm{X}^{\text{(obs)}})\), reflecting the independence of \(\bm{X}^{\text{(obs)}}\) from \(\bm{X}^{\text{(miss)}}\).

Based on this, we want to show that within the WGF framework, the factorizations \(r(\bm{X}^{\text{(miss)}})r(\bm{X}^{\text{(obs)}})\) and \(r(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})r(\bm{X}^{\text{(obs)}})\) are equivalent. To this end, let us write down the evolution of \(r(\bm{X}^{\text{(obs)}},\bm{X}^{\text{(miss)}})\) along time \(\tau\) as follows when \(r(\bm{X}^{\text{(obs)}},\bm{X}^{\text{(miss)}})\) is factorized by \(r(\bm{X}^{\text{(obs)}},\bm{X}^{\text{(miss)}})=r(\bm{X}^{\text{(miss)}}|\bm{X }^{\text{(obs)}})r(\bm{X}^{\text{(obs)}})\):

\[\frac{\partial r(\bm{X}^{\text{(obs)}},\bm{X}^{\text{(miss)}})}{ \partial\tau}= \frac{\partial r(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})r( \bm{X}^{\text{(obs)}})}{\partial\tau}\] \[= \underbrace{r(\bm{X}^{\text{(obs)}})\frac{\partial r(\bm{X}^{ \text{(miss)}}|\bm{X}^{\text{(obs)}})}{\partial\tau}}_{r(\bm{X}^{\text{(obs)}} |\bm{X}^{\text{(obs)}})=r(\bm{X}^{\text{(obs)}})}+\underbrace{r(\bm{X}^{\text {(miss)}}|\bm{X}^{\text{(obs)}})\frac{\partial r(\bm{X}^{\text{(obs)}})}{ \partial\tau}}_{0},\]

where the first underbrace is the Bayesian formula, and the second underbrace is based on the abovementioned Agreement 2. Consequently, we can further obtain the following results:

\[\frac{\partial r(\bm{X}^{\text{(obs)}},\bm{X}^{\text{(miss)}})}{ \partial\tau}= \underbrace{\frac{r(\bm{X}^{\text{(obs)}})}{r(\bm{X}^{\text{( obs)}})}\frac{\partial r(\bm{X}^{\text{(obs)}}|\bm{X}^{\text{(miss)}})r(\bm{X}^{\text{( miss)}})}{\partial\tau}}_{r(\bm{X}^{\text{(obs)}}|\bm{X}^{\text{( miss)}})=r(\bm{X}^{\text{(obs)}})}\] (C.27) \[= r(\bm{X}^{\text{(obs)}})\frac{\partial r(\bm{X}^{\text{(miss)}} )}{\partial\tau}\]

Similarly, when we factorize \(r(\bm{X}^{\text{(obs)}},\bm{X}^{\text{(miss)}})\) by \(r(\bm{X}^{\text{(obs)}},\bm{X}^{\text{(miss)}})=r(\bm{X}^{\text{(miss)}})r(\bm{X} ^{\text{(obs)}})\), we can get the following result:

\[\frac{\partial r(\bm{X}^{\text{(obs)}},\bm{X}^{\text{(miss)}})}{ \partial\tau}= \frac{\partial r(\bm{X}^{\text{(obs)}})r(\bm{X}^{\text{(miss)}})}{ \partial\tau}\] (C.28) \[= r(\bm{X}^{\text{(obs)}})\frac{\partial r(\bm{X}^{\text{(miss)}} )}{\partial\tau}.\]

Comparing Eq. (C.28) to Eq. (C.27), we can demonstrate our justification of the factorization \(r(\bm{X}^{\text{(obs)}},\bm{X}^{\text{(miss)}})=r(\bm{X}^{\text{(miss)}})r(\bm{X }^{\text{(obs)}})\). Finally, we would like to conclude with a metaphor to further illustrate the plausibility of this mean-filed factorization, which has been widely applied in variational inference [5]:

1. Consider \(r\) as an actor in a play, capable of being molded and shaped. Initially, the actor may not fully embody the role, akin to \(r(\bm{X}^{\text{(miss)}})\) not containing information about \(\bm{X}^{\text{(obs)}}\).
2. However just as a director shapes an actor's performance through guidance and rehearsal, all we need to do is ensure that \(r(\bm{X}^{\text{(miss)}})\) is appropriately molded by the directorial guidance (mirrors the continuity equation \(\frac{\partial r}{\partial\tau}=-\nabla\cdot(ur)\)) of the velocity field \(u\) and the script provided by the critic \(p(\bm{X}^{\text{(obs)}},\bm{X}^{\text{(miss)}})\)/\(p(\bm{X}^{\text{(obs)}}|\bm{X}^{\text{(miss)}})\).
3. As long as \(r\) can adapt based on this feedback (akin to the WGF framework), it can overcome the limitations of its initial portrayal (akin to \(r(\bm{X}^{\text{(joint)}})=r(\bm{X}^{\text{(miss)}})r(\bm{X}^{\text{(obs)}})\) ).

Based on the abovementioned analysis, we can now start the proof of Proposition 4.2:

Proof.: Our proof will be divided into two parts namely'velocity field derivation' and 'upper bound acquirement'.

#### Velocity Field Derivation:

the following continuity equation should be satisfied during the optimization of \(r(\bm{X}^{\text{(miss)}})\):

\[\begin{split}&\frac{\partial r(\bm{X}^{\text{(miss)}})}{\partial \tau}=-\nabla_{\bm{X}^{\text{(min)}}}\cdot[r(\bm{X}^{\text{(miss)}})u(\bm{X}^{ \text{(miss)}})]\\ \Rightarrow&\frac{\partial r(\bm{X}^{\text{(miss)}}) }{\partial\tau}\times p(\bm{X}^{\text{(obs)}})=-\nabla_{\bm{X}^{\text{(min)}} }\cdot[r(\bm{X}^{\text{(miss)}})u(\bm{X}^{\text{(miss)}})]\times p(\bm{X}^{ \text{(obs)}})\\ \overset{\text{(i)}}{=}&\frac{\partial r(\bm{X}^{ \text{(joint)}})}{\partial\tau}=-\nabla_{\bm{X}^{\text{(miss)}}}\cdot[r(\bm{X} ^{\text{(joint)}})u(\bm{X}^{\text{(joint)}})],\end{split}\] (C.29)

where (i) is based on the fact that \(\bm{X}^{\text{(obs)}}\) remains unchanged during the imputation process. Thus, according to Eq. (C.16), the evolution of \(\mathcal{F}_{\text{joint-NER}}\) along time \(\tau\), \(\frac{\mathrm{d}\mathcal{F}_{\text{joint-NER}}}{\mathrm{d}\tau}\), can be given as follows based on the chain rule:

\[\begin{split}&\frac{\mathrm{d}\mathcal{F}_{\text{joint-NER}}}{ \mathrm{d}\tau}\\ =&\int\frac{\partial r(\bm{X}^{\text{(joint)}})}{ \partial\tau}\left[\log\hat{p}(\bm{X}^{\text{(joint)}})+\lambda\log r(\bm{X}^ {\text{(joint)}})+\lambda\right]\mathrm{d}\bm{X}^{\text{(joint)}}\\ =&\int-\{\nabla_{\bm{X}^{\text{(miss)}}}\cdot[r(\bm {X}^{\text{(joint)}})u(\bm{X}^{\text{(joint)}})]\}[\log\hat{p}(\bm{X}^{\text{ (joint)}})+\lambda\log r(\bm{X}^{\text{(joint)}})+\lambda]\mathrm{d}\bm{X}^{ \text{(joint)}}\\ \overset{\text{(i)}}{=}&\int[r(\bm{X}^{\text{( joint)}})u(\bm{X}^{\text{(joint)}})]^{\top}\nabla_{\bm{X}^{\text{(min)}}} \left[\log\hat{p}(\bm{X}^{\text{(joint)}})+\lambda\log r(\bm{X}^{\text{(joint )}})+\lambda\right]\mathrm{d}\bm{X}^{\text{(joint)}}\\ =&\int[r(\bm{X}^{\text{(joint)}})u(\bm{X}^{\text{( joint)}})]^{\top}\{\nabla_{\bm{X}^{\text{(min)}}}[\log\hat{p}(\bm{X}^{\text{( joint)}})+\lambda\log r(\bm{X}^{\text{(joint)}})]\}\mathrm{d}\bm{X}^{ \text{(joint)}}\\ =&\int[u(\bm{X}^{\text{(joint)}})]^{\top}[r(\bm{X}^{ \text{(joint)}})\nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{( joint)}})+\lambda r(\bm{X}^{\text{(joint)}})\nabla_{\bm{X}^{\text{(miss)}}}\log r(\bm{X}^{\text{( joint)}})]\mathrm{d}\bm{X}^{\text{(joint)}}\\ =&\int[u(\bm{X}^{\text{(joint)}})]^{\top}[r(\bm{X}^{ \text{(joint)}})\nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{( joint)}})+\lambda\nabla_{\bm{X}^{\text{(miss)}}}r(\bm{X}^{\text{( joint)}})]\mathrm{d}\bm{X}^{\text{(joint)}}\\ \overset{\text{(ii)}}{=}&\int r(\bm{X}^{\text{( joint)}})[u^{\top}(\bm{X}^{\text{(joint)}})\nabla_{\bm{X}^{\text{(miss)}}}\log\hat{p}(\bm{X}^{\text{( joint)}})-\lambda\nabla_{\bm{X}^{\text{(miss)}}}\cdot u(\bm{X}^{\text{( joint)}})]\mathrm{d}\bm{X}^{\text{(joint)}}\\ =&\mathbb{E}_{r(\bm{X}^{\text{(joint)}})}[u^{\top}(\bm {X}^{\text{(joint)}})\nabla_{\bm{X}^{\text{(min)}}}\log\hat{p}(\bm{X}^{\text{( joint)}})-\lambda\nabla_{\bm{X}^{\text{(miss)}}}\cdot u(\bm{X}^{\text{(joint)}})], \end{split}\] (C.30)

where (i) and (ii) are based on integration by parts. More specifically, when condition \(\lim_{\bm{X}^{\text{(joint)}}\to\infty}[u(\bm{X}^{\text{(joint)}})r(\bm{X}^{ \text{(joint)}})]=0\) is satisfied, for example, \(r(\bm{X}^{\text{(joint)}})\) is bounded, and the limit of the velocity field as the norm of \(\bm{X}^{\text{(joint)}}\) approaches infinity is zero (\(\lim_{\|\bm{X}^{\text{(joint)}}\|\to\infty}u(\bm{X}^{\text{(joint)}})=0\)), we can get the following result [35, 32]:

\[\int\nabla_{\bm{X}^{\text{(miss)}}}\cdot[r(\bm{X}^{\text{(joint)}})u(\bm{X}^{ \text{(joint)}})]\mathrm{d}\bm{X}^{\text{(joint)}}=0,\]

where we omit the gradient operator with respect to the observed variables \(\bm{X}^{\text{(obs)}}\), denoted as \(\nabla_{\bm{X}^{\text{(obs)}}}\), because \(\bm{X}^{\text{(obs)}}\) remains constant during the imputation process. This constancy implies that the divergence \(\nabla_{\bm{X}^{\text{(obs)}}}\cdot[r(\bm{X}^{\text{(joint)}})u(\bm{X}^{ \text{(joint)}})]=0\). Consequently, the left-hand-side of this equation can be further decomposed as follows based on the integration by parts:

\[\begin{split}\int\nabla_{\bm{X}^{\text{(miss)}}}\cdot[r(\bm{X}^{ \text{(joint)}})u(\bm{X}^{\text{(joint)}})]\mathrm{d}\bm{X}^{\text{(joint)}}=& \int u^{\top}(\bm{X}^{\text{(joint)}})\nabla_{\bm{X}^{\text{(miss)}}}r(\bm{X}^{ \text{(joint)}})\mathrm{d}\bm{X}^{\text{(joint)}}\\ &+\int[\nabla_{\bm{X}^{\text{(min)}}}\cdot u(\bm{X}^{\text{(joint)}})]r( \bm{X}^{\text{(joint)}})\mathrm{d}\bm{X}^{\text{(joint)}}.\end{split}\]Similar to the proof of proposition 4.1, we can restrict the velocity field in RKHS and find the steepest gradient boosting direction as follows according to Eqs. (C.19) to (C.21):

\[\begin{split}& u^{*}(\bm{X}^{\text{(joint)}})\\ &=\operatorname*{arg\,max}_{u(\bm{X}^{\text{(join)}})\in\mathcal{ H}^{\text{D}}}\qquad\quad-\lambda\nabla_{\bm{X}^{\text{(tiny)}}}\cdot u(\bm{X}^{ \text{(mix)}})]\}-\frac{1}{2}\|u(\bm{X}^{\text{(joint)}})\|_{\mathcal{H}^{ \text{D}}}^{2},\\ &\overset{\text{(i)}}{=}\operatorname*{arg\,max}_{u(\bm{X}^{ \text{(join)}})\in\mathcal{H}^{\text{D}}}\qquad\quad-\lambda\nabla_{\tilde{ \bm{X}}^{\text{(mix)}}}\cdot\sum_{i=1}^{\infty}u_{i}\sqrt{\xi_{i}}\phi_{i}( \tilde{\bm{X}}^{\text{(joint)}})]\}-\frac{1}{2}\sum_{i=1}^{\infty}\|u_{i}\|^{2},\end{split}\] (C.31)

Take the right-hand-side of (i) with-respect-to \(u_{i}\), and set it to 0, we can get:

\[\sqrt{\xi_{i}}\{\mathbb{E}_{r(\tilde{\bm{X}}^{\text{(joint)}})}[[\nabla_{ \tilde{\bm{X}}^{\text{(mix)}}}\log\hat{p}(\tilde{\bm{X}}^{\text{(joint)}})]^{ \top}\phi_{i}(\tilde{\bm{X}}^{\text{(joint)}})-\lambda\nabla_{\tilde{\bm{X}}^ {\text{(mix)}}}\phi_{i}(\tilde{\bm{X}}^{\text{(joint)}})]\}-u_{i}=0.\] (C.32)

On this basis, \(u_{i}^{*}\) can be given as follows:

\[u_{i}^{*}=\sqrt{\xi_{i}}\{\mathbb{E}_{r(\tilde{\bm{X}}^{\text{( joint)}})}[[\nabla_{\tilde{\bm{X}}^{\text{(mix)}}}\log\hat{p}(\tilde{\bm{X}}^{ \text{(joint)}})]^{\top}\phi_{i}(\tilde{\bm{X}}^{\text{(joint)}})-\lambda \nabla_{\tilde{\bm{X}}^{\text{(mix)}}}\phi_{i}(\tilde{\bm{X}}^{\text{(joint) }})]\},\] (C.33)

and hence, \(u(\bm{X}^{\text{(joint)}})\) can be given as follows:

\[\begin{split}& u(\bm{X}^{\text{(joint)}})\\ =&\sum_{i=1}^{\infty}\sqrt{\xi_{i}}u_{i}^{*}\phi_{i}( \bm{X}^{\text{(joint)}})\\ =&\mathbb{E}_{r(\bm{X}^{\text{(joint)}})}\begin{bmatrix}- \lambda\nabla_{\tilde{\bm{X}}^{\text{(mix)}}}K(\bm{X}^{\text{(joint)}}, \tilde{\bm{X}}^{\text{(joint)}})\\ +\nabla_{\tilde{\bm{X}}^{\text{(mix)}}}\log\hat{p}(\tilde{\bm{X}}^{\text{( joint)}})K(\bm{X}^{\text{(mix)}},\tilde{\bm{X}}^{\text{(miss)}})\end{bmatrix}.\end{split}\] (C.34)

#### Lower Bound Acquirement:

Before starting the proving of this part, we should notice that given the unchanged observational data \(\bm{X}^{\text{(obs)}}\), the distribution \(p(\bm{X}^{\text{(obs)}})\) is a constant. On this basis, consider the definition of \(\mathcal{F}_{\text{NER}}\) (right-hand-side of Eq. (7)), the first term and the second term are denoted by 'term 1' and 'term 2' for simplicity:

\[\underbrace{\mathbb{E}_{r(\bm{X}^{\text{(mix)}})}[\log\hat{p}(\bm{X}^{\text{ (miss)}}|\bm{X}^{\text{(obs)}})]}_{:=\text{term 1}}+\lambda\times\left[\underbrace{- \mathbb{H}[r(\bm{X}^{\text{(miss)}})]}_{:=\text{term 2}}\right].\] (C.35)For term 1, we can obtain the following derivation:

\[\begin{split}&\int r(\bm{X}^{\text{(miss)}})\log\hat{p}(\bm{X}^{ \text{(miss)}}|\bm{X}^{\text{(obs)}})\mathrm{d}\bm{X}^{\text{(miss)}}\\ &\geq\int r(\bm{X}^{\text{(miss)}})\log\hat{p}(\bm{X}^{\text{( miss)}}|\bm{X}^{\text{(obs)}})\mathrm{d}\bm{X}^{\text{(miss)}}+\underbrace{\int p(\bm{X}^{\text{(obs)}})\log p(\bm{X}^{ \text{(obs)}})\mathrm{d}\bm{X}^{\text{(obs)}}}_{\text{negative entropy (negative constant)}}\\ =&\iint p(\bm{X}^{\text{(obs)}})r(\bm{X}^{\text{( miss)}})\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})\mathrm{d}\bm{X}^{\text{(miss)}}\mathrm{d}\bm{X}^{\text{(obs)}}\\ &\quad+\underbrace{\int p(\bm{X}^{\text{(obs)}})\log p(\bm{X}^{ \text{(obs)}})\mathrm{d}\bm{X}^{\text{(obs)}}}_{\text{negative constant}}\\ =&\iint p(\bm{X}^{\text{(obs)}})r(\bm{X}^{\text{( miss)}})\log\hat{p}(\bm{X}^{\text{(miss)}}|\bm{X}^{\text{(obs)}})\mathrm{d}\bm{X}^{\text{( miss)}}\mathrm{d}\bm{X}^{\text{(obs)}}\\ &\quad+\underbrace{\iint r(\bm{X}^{\text{(miss)}})p(\bm{X}^{ \text{(obs)}})\log p(\bm{X}^{\text{(obs)}})\mathrm{d}\bm{X}^{\text{(miss)}} \mathrm{d}\bm{X}^{\text{(obs)}}}_{\text{negative constant}}\\ =&\iint\underbrace{p(\bm{X}^{\text{(obs)}})r(\bm{X}^{ \text{(miss)}})}_{r(\bm{X}^{\text{(obs)}})}\underbrace{[\log\hat{p}(\bm{X}^{ \text{(miss)}}|\bm{X}^{\text{(obs)}})+\log p(\bm{X}^{\text{(obs)}})]}_{\text{ log}\,\hat{p}(\bm{X}^{\text{(mis)}},\bm{X}^{\text{(obs)}})}]\mathrm{d}\bm{X}^{\text{( miss)}}\mathrm{d}\bm{X}^{\text{(obs)}}\\ =&\mathbb{E}_{r(\bm{X}^{\text{(miss)}},\bm{X}^{\text{( obs)}})}[\log\hat{p}(\bm{X}^{\text{(miss)}},\bm{X}^{\text{(obs)}})].\end{split}\] (C.36)

Similarly, the term 2 can be reformulated as follows:

\[\begin{split}&\quad-\mathbb{H}[r(\bm{X}^{\text{(miss)}})]\\ \geq&-\mathbb{H}[r(\bm{X}^{\text{(miss)}})]+ \underbrace{\int p(\bm{X}^{\text{(obs)}})\log p(\bm{X}^{\text{(obs)}}) \mathrm{d}\bm{X}^{\text{(obs)}}}_{\text{negative entropy (negative constant)}}\\ =&\iint p(\bm{X}^{\text{(obs)}})r(\bm{X}^{\text{( miss)}})\log r(\bm{X}^{\text{(miss)}})\mathrm{d}\bm{X}^{\text{(miss)}}\mathrm{d}\bm{X}^{\text{(obs)}}\\ &\quad+\underbrace{\iint p(\bm{X}^{\text{(obs)}})r(\bm{X}^{\text{ (miss)}})\log p(\bm{X}^{\text{(obs)}})\mathrm{d}\bm{X}^{\text{(miss)}}\mathrm{ d}\bm{X}^{\text{(obs)}}}_{\text{negative entropy (negative constant)}}\\ =&\iint p(\bm{X}^{\text{(obs)}})r(\bm{X}^{\text{( miss)}})\underbrace{[\log r(\bm{X}^{\text{(miss)}})+\log p(\bm{X}^{\text{(obs)}})]}_{r(\bm{X}^{ \text{(obs)}},\bm{X}^{\text{(miss)}})}]\mathrm{d}\bm{X}^{\text{(mis)}} \mathrm{d}\bm{X}^{\text{(obs)}}\\ =&-\mathbb{H}[r(\bm{X}^{\text{(obs)}},\bm{X}^{\text{ (miss)}})].\end{split}\] (C.37)

Combine Eqs. (C.36) and (C.37), we can obtain the following relationship:

\[\mathcal{F}_{\text{NER}}-\text{const}=\mathcal{F}_{\text{joint-NER}},\] (C.38)

and constant const is greater than \(0\).

**Corollary** (4.3).: _The following equation holds: \(u(\bm{X}^{\text{(joint)}})=u(\bm{X}^{\text{(miss)}})\)._

Proof.: This corollary can be easily proven by according to Eq. (C.38):

\[\begin{split}&\mathcal{F}_{\text{NER}}=\mathcal{F}_{\text{joint-NER}}+ \text{const}\\ \Rightarrow&\nabla_{\bm{X}^{\text{(miss)}}}\frac{ \delta\mathcal{F}_{\text{NER}}}{\delta r(\bm{X}^{\text{(miss)}})}=\nabla_{\bm{X}^ {\text{(miss)}}}\frac{\delta\mathcal{F}_{\text{joint-NER}}+\text{const}}{ \delta r(\bm{X}^{\text{(miss)}})}\\ \Rightarrow&\nabla_{\bm{X}^{\text{(miss)}}}\frac{ \delta\mathcal{F}_{\text{NER}}}{\delta r(\bm{X}^{\text{(miss)}})}=\nabla_{\bm{X}^ {\text{(miss)}}}\frac{\delta\mathcal{F}_{\text{joint-NER}}}{\delta r(\bm{X}^{ \text{(miss)}})}.\end{split}\] (C.39)Plugging Eq. (C.39) into Eqs. (A.5) and (A.6), we can see that the velocity fields for \(\bm{X}^{\text{(miss)}}\) within functional \(\mathcal{F}_{\text{NER}}\) and \(\mathcal{F}_{\text{joint-NER}}\) are identical. 

## Appendix D Detailed Explanation for the Workflow of NewImp Approach

In this section, we intend to provide detailed information about the implementation of the NewImp approach in Algorithm 1. We will focus on two primary aspects: 1) the numerical implementation of ODE simulation, and 2) the DSM algorithm.

### Forward Euler's Method for ODE Simulation

During step 7 of Algorithm 1, we involve the simulation of the ODE defined by Eqs. (9) and (14). To simulate this ODE we use the forward Euler's method [6] in this paper for simplicity. Specifically, suppose we have the following ODE:

\[\frac{\mathrm{d}x_{\tau}}{\mathrm{d}\tau}=f(x_{\tau}),\] (D.1)

and the initial value at \(\tau=0\) is given \(x_{0}=x_{\text{init}}\), the value at time \(\eta\) can be derived as follows:

\[x_{\eta}=x_{0}+\int_{0}^{\eta}f(x_{\tau})\mathrm{d}\tau.\] (D.2)

To alleviate the intergal term, the forward Euler's method attempts to approximate the integral term to summation term as follows:

\[x_{\eta}\approx x_{0}+f(x_{\tau})\times(\eta-0).\] (D.3)

On this basis, the value at time \(\mathrm{T}\) can be obtained by repeating Eq. (D.3) from \(\tau=0\) to \(\tau=\mathrm{T}\), which is the forward Euler's method.

```
1:Input: ODE \(f(x_{\tau})\); start point \(0\); end point \(\mathrm{T}\); step size \(\eta\); initial value \(x_{0}\).
2:Output: Predicted value \(x_{\mathrm{T}}\) at \(\tau=\mathrm{T}\).
3:\(j\leftarrow\frac{\mathrm{T}-0}{\eta}\)\(\triangleright\) Calculate the Number of Steps
4:for\(\tau=0+\eta,0+2\eta,\dots,0+j\eta\)do
5:\(x_{\tau}\gets x_{\tau-\eta}+f(x_{\tau-\eta})\times\eta\)
6:endfor ```

**Algorithm 2** Algorithm for Forward Euler's Method

### Detailed Information for DSM

During step 5 of Algorithm 1, we involve the training of \(\nabla_{\bm{X}^{\text{(joint)}}}\log\hat{p}(\bm{X}^{\text{(joint)}})\) using the DSM function. In this subsection, we aim to further elaborate on the detailed algorithm for the DSM function to uphold the completeness of this manuscript. As mentioned in Section 2.2, the score function \(\nabla_{\bm{X}^{\text{(joint)}}}\log\hat{p}(\bm{X}^{\text{(joint)}})\) is typically parameterized by a neural network. For simplicity, we denote the parameter set of \(\nabla_{\bm{X}^{\text{(joint)}}}\log\hat{p}(\bm{X}^{\text{(joint)}})\) by \(\theta\).

## Appendix E Detailed Information for Experiments

### Background & Simulation of Missing Data

In this paper, we consider the datasets listed in Table E.1 as our experimental datasets. Based on this, according to reference [44], missing data can be classified into three categories: Missing at Random (MAR), where the likelihood of missing data depends solely on observed data; Missing Completely at Random (MCAR), where the absence of data is completely unrelated to any observed or unobserved variables; and Missing Not at Random (MNAR), where missingness is influenced by unobserved data. In the cases of MCAR and MAR, the patterns of missing data are considered 'ignorable' because it is unnecessary to explicitly model the distribution of the missing values. Conversely, MNAR scenarios, where missing data can introduce significant biases that are not easily corrected without imposing domain-specific assumptions, constraints, or parametric forms on the missingness mechanism, present more complex challenges [40, 22]. Therefore, our discussion is primarily focused on numerical tabular data within the MCAR and MAR contexts.

To simulate missing data, we adopt the methodologies outlined in reference [22]:

* **MAR:** Initially, a random subset of features is selected to remain non-missing. The masking of the remaining features is conducted using a logistic model, which employs the non-missing features as predictors. This model is parameterized with randomly selected weights, and the bias is adjusted to achieve the desired missingness rate.
* **MCAR:** For each data point, the masking variable is generated from a Bernoulli distribution with a predetermined fixed mean, ensuring that the probability of missingness is the same across all data points.
* **MNAR:** Although MNAR scenarios are not the primary focus of this manuscript, we include experiments in this context. Missingness is introduced either by additional masking of the MAR-selected features using a Bernoulli process with a fixed mean, or through direct self-masking of values using interval-censoring techniques. In this paper, we mainly consider the former strategy. In other words, the mechanism of MNAR we used in this paper is identical to the previously described MAR mechanism, but the inputs of the logistic model are then masked by an MCAR mechanism.

\begin{table}
\begin{tabular}{l|l|l|l} \hline \hline Abbreviation & Dataset Name & Numer (N) & Dimension (D) \\ \hline BT & Blood Transfusion & 748 & 4 \\ BCD & Breast Cancer Diagnostic & 569 & 30 \\ CC & Concrete Compression & 1030 & 7 \\ CBV & Connectionist Bench Vowel & 990 & 10 \\ IS & Ionosphere & 351 & 34 \\ PK & Parkinsons & 195 & 23 \\ QB & QSAR Biodegradation & 1055 & 41 \\ WQW & Wine Quality White & 4898 & 11 \\ \hline \hline \end{tabular}
\end{table}
Table E.1: Detailed dataset descriptions, where Dimension denotes the variate number of each dataset. Numer denotes the total number of item.

### Hyperparameter Setting of Baseline Models

In this subsection, we want to report the baseline models' hyperparameter settings to ensure the reproducibility of our paper:

* **Batch-Size-Related:** The batch size for ReMasker is set to 64. For other baseline models, it is uniformly set at 512. (Notably, for Sink and TDM, if \(\mathrm{N}<512\), the batch size is set to \(2^{\lfloor\frac{\mathrm{N}}{2}\rfloor}\). )

* The MIWAE model features a latent dimension of 16 and 32 hidden units.
* The TDM model includes 16 hidden units per layer with the number of layers set to 2.
* MIRACLE's hidden units are set to 32.
* For ReMasker, the embedding dimension is 32, depth is 6, mask ratio is 0.5, encoder depth is 6, decoder depth is 4, number of heads is 4, and the multi-layer perceptron ratio is 4.0.
* For MissDiff and CSDL_T, the channel size is set as 16, the embedding dimension is set to 128, and the layer number is set as 2.
* For the GAIN model, for both the generator and the discriminator, the hidden size is set to \(2\times\mathrm{D}\), and the number of hidden layers is set to 3.
* **Diffusion-Hyperparameters-Related:** The diffusion step is set at 100 and the particle number at 50 for MissDiff and CSDL_T.

## Appendix F Additional Empirical Evidence

### Toy Case Experiments

To demonstrate the effectiveness of the NewImp method vary different type of distributions, we evaluate it across four distinct toy cases, each characterized by different distributions:

* **Standard Gaussian:**\(\bm{X}^{\text{(ideal)}}\sim\mathcal{N}(0,I_{2\times 2})\).
* **Student's-\(t\) (a heavy-tailed distribution):**\(\bm{X}^{\text{(ideal)}}\sim\text{St-}t(0,\begin{bmatrix}1&0.5\\ 0.5&1\end{bmatrix})\).
* **Gaussian Mixture:**\(\bm{X}^{\text{(ideal)}}\sim\frac{1}{3}\times\mathcal{N}([1,2],\begin{bmatrix}0.5&0\\ 0&0.5\end{bmatrix})+\frac{1}{3}\times\mathcal{N}([-1,-2],\begin{bmatrix}0.5&0.1 \\ 0.1&0.5\end{bmatrix})+\frac{1}{3}\times\mathcal{N}([2,-2],\begin{bmatrix}0.3&0 \\ 0&0.3\end{bmatrix})\).
* **Skewed Gaussian (via exponential transformation):**\(\bm{X}^{\text{(ideal)}}=\exp(\epsilon)\), where \(\epsilon\sim\mathcal{N}(0,I_{2\times 2})\).

Based on this, we display the contours of their density values in Fig. F.1, and we list the imputation accuracy comparisons for MAR, MCAR, and MNAR scenarios with a 30% missing rate in Table F.1. The results indicate that our NewImp approach generally performs better on non-standard Gaussian type data, underscoring its universality and applicability. This enhanced performance is attributable to our modeling strategy, which involves modeling the score function of the data [52, 50], which eliminates the need for normalization, and consequently results in the NewImp approach can perform well on complex data distributions, including skewed, heavy-tailed, and mixture distributions.

### Additional Experimental Results with MNAR Scenario

In this section, we expand upon the results presented in Table 1 by including the MNAR scenario, as detailed in Table F.2. Additionally, we report on the outcomes of an ablation study and sensi

\begin{table}
\begin{tabular}{c l c c} \hline \hline Scenario & Distribution Type & MAE & WASS \\ \hline \multirow{4}{*}{MAR} & Gaussian & 0.769\({}_{\pm 0.030}\) & 0.481\({}_{\pm 0.026}\) \\  & Students-\(t\) & 0.737\({}_{\pm 0.053}\) & 0.513\({}_{\pm 0.048}\) \\  & Gaussian Mixture & 0.763\({}_{\pm 0.097}\) & 0.419\({}_{\pm 0.104}\) \\  & Skewed-Gaussian & 0.422\({}_{\pm 0.253}\) & 0.492\({}_{\pm 0.025}\) \\ \hline \multirow{4}{*}{MCAR} & Gaussian & 0.769\({}_{\pm 0.013}\) & 0.287\({}_{\pm 0.014}\) \\  & Students-\(t\) & 0.698\({}_{\pm 0.030}\) & 0.307\({}_{\pm 0.014}\) \\  & Gaussian Mixture & 0.824\({}_{\pm 0.017}\) & 0.391\({}_{\pm 0.023}\) \\  & Skewed-Gaussian & 0.417\({}_{\pm 0.140}\) & 0.210\({}_{\pm 0.026}\) \\ \hline \multirow{4}{*}{MNAR} & Gaussian & 0.778\({}_{\pm 0.034}\) & 0.309\({}_{\pm 0.030}\) \\  & Students-\(t\) & 0.715\({}_{\pm 0.028}\) & 0.323\({}_{\pm 0.019}\) \\  & Gaussian Mixture & 0.807\({}_{\pm 0.042}\) & 0.380\({}_{\pm 0.050}\) \\ \cline{1-1}  & Skewed-Gaussian & 0.421\({}_{\pm 0.111}\) & 0.202\({}_{\pm 0.006}\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: NewImp Performance with Missing Rate at 30%, and 1000 samples are generated.

Figure 1: Contours of Various Distributions Density Value.

[MISSING_PAGE_FAIL:32]

[MISSING_PAGE_FAIL:33]

### Empirical Evidence for Selecting RBF Function

In our derivation process, we specifically selected the RBF kernel to satisfy the 'zero boundary condition': \(\lim_{\bm{X}^{\text{(joint)}}\rightarrow\infty}K(\bm{X}^{\text{(joint)}},\tilde{ \bm{X}}^{\text{(joint)}})=0\) for the sake of avoiding the explicit density estimation of the intractable proposal distribution \(r(\bm{X}^{\text{(joint)}})\). This selection prompts an additional inquiry: What if we replaced the RBF kernel with another that does not fulfill the 'zero boundary condition'? To maintain the rigor of our analysis, we compared the performance of the NewImp with alternative kernel functions under identical settings. Consequently, we consider the following types of kernel functions:

* **linear kernel function (linear):**\(K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{\text{(joint)}})=[\bm{X}^{\text {(joint)}}][\tilde{\bm{X}}^{\text{(joint)}}]^{\top}\)
* **polynomial kernel function (poly):**\(K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{\text{(joint)}})=\{[\bm{X}^{ \text{(joint)}}][\tilde{\bm{X}}^{\text{(joint)}}]^{\top}\}^{2}\)
* **sigmoid kernel function (sigmoid):**\(K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{\text{(joint)}})=\tanh\{[\bm{X}^{ \text{(joint)}}][\tilde{\bm{X}}^{\text{(joint)}}]^{\top}\}\)
* **cosine similarity kernel function (cos):**\(K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{\text{(joint)}})=\{\frac{[\bm{X} ^{\text{(joint)}}}{[\bm{X}^{\text{(joint)}}]]}\}\{\frac{[\tilde{\bm{X}}^{ \text{(joint)}}]}{[\tilde{\bm{X}}^{\text{(joint)}}]}\}^{\top}\)
* **sine kernel function (sin):**\(K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{\text{(joint)}})=\sin(|\bm{X}^{ \text{(joint)}}-\tilde{\bm{X}}^{\text{(joint)}}|_{2}^{2})\)

The experimental results are detailed in Table F.6 (For completeness, we also report the results under the MNAR scenario). From the results, it is evident that other kernel functions, which do not meet the 'zero boundary condition', perform significantly worse compared to the RBF kernel. This demonstrates the critical importance of selecting the appropriate kernel function for achieving accurate imputation results, thereby validating the choice of the RBF kernel for our NewImp approach.

Figure F.2: Parameter sensitivity of NewImp on bandwidth for kernel function (\(h\)), hidden unit of score network \(\text{HU}_{\text{score}}\), NER weight \(\lambda\), and discretization step \(\eta\) for Eq. (9) on CC dataset. Mean values and one standard deviation from mean are represented by scatters and shaded area, respectively.

[MISSING_PAGE_FAIL:35]

* **Kernel function and its gradient:** Employing the RBF kernel \(K(\bm{X},\tilde{\bm{X}})\coloneqq\exp\left(-\frac{\|\bm{X}-\tilde{\bm{X}}\|^{2}}{2 h^{2}}\right)\), the gradient with respect to \(\tilde{\bm{X}}\) is analytically determined as: \[[\nabla_{\tilde{\bm{X}}}K(\bm{X},\tilde{\bm{X}})][:,j]=-\frac{1}{h^{2}}\left\{[ K(\bm{X},\tilde{\bm{X}})\times\tilde{\bm{X}}][:,j]+\tilde{\bm{X}}[:,j] \odot\sum_{j=1}^{\mathrm{D}}K(\bm{X},\tilde{\bm{X}})[:,j]\right\}.\] (F.3) The time complexities for calculating the kernel function and its gradient are specified in Eqs. (F.4) and (F.5): \[\mathcal{O}\left[\mathrm{N}^{2}\times\mathrm{D}+\mathrm{N}^{2} \right],\] (F.4) \[\mathcal{O}\left[\mathrm{N}^{2}\times\mathrm{D}+\mathrm{N}^{2}+ \mathrm{N}\times\mathrm{D}\right].\] (F.5)

Based on the abovementioned analysis, we explore how computational complexity varies with different dataset sizes \(\mathrm{N}\) and the number of features \(\mathrm{D}\), as shown in Figs. F.3 (a) and (b), respectively. From these figures, it is evident that computational time increases with the dataset size \(\mathrm{N}\). However, changes in the number of features \(\mathrm{D}\) do not significantly affect the computation time. This observation underscores that the primary determinant of computational complexity in our context is the dataset size, aligning with our theoretical analysis, which indicates a quadratic relationship between time complexity and the size of the dataset \(\mathrm{N}\) for the 'Imputation' part, and \(\mathrm{N}\gg\mathrm{D}\) for the 'DSM Training' part, aligning with our theoretical analysis.

Moreover, the data reveals that the total computational time is predominantly governed by 'Estimation' part of our NewImp approach. This suggests that the training of the score function represents a critical bottleneck in the efficiency of the NewImp algorithm. Therefore, accelerating the NewImp algorithm crucially hinges on reducing the computational demands of the 'Estimation' part.

### Convergence Analysis

In this section, we want to discuss the convergence of the proposed NewImp approach, prior to delving into this discussion, it is essential to establish a clear definition of convergence:

**Definition F.1**.: _A sequence \(\{\mathcal{F}_{1},\mathcal{F}_{2},...,\mathcal{F}_{\mathrm{T}}\}\) is said to be convergent if there exists a real number \(\mathcal{G}\) such that for any given positive number \(\varepsilon\) (\(\varepsilon>0\)), there exists a positive integer \(N\), such that for all indices \(n\) greater than \(N\), the corresponding terms \(\mathcal{F}_{n},n\geq N\) satisfy the inequality \(|\mathcal{F}_{n}-\mathcal{G}|<\varepsilon\)._

Based on Definition F.1, if a sequence is either monotonically increasing or monotonically decreasing and bounded (either bounded above or bounded below), then it is guaranteed to converge according

Figure F.3: Average computation time, where Estimate indicates the DSM Training Algorithm (step 5 of Algorithm 1), and Impute indicates the imputation algorithm (step 7 of Algorithm 1). The scatters and shaded areas indicate the mean and one standard deviation from the mean, respectively.

to the celebrated monotone convergence theorem (Section 3.14 in reference [45]). Based on this, the convergence of the 'Imputation' part (step 7 of Algorithm 1) and DSM training part (step 5 of Algorithm 1) are proposed in the proceeding parts.

#### c.5.1 Convergence Analysis of the Imputation Part

In this section, we explore the convergence of the imputation part as defined in step 7 of Algorithm 1 within our NewImp approach. Based on this, we first prove the following proposition for the convergence in the 'Imputation' part:

**Proposition F.1**.: _The convergence of the imputation part can be guaranteed, given that the discretization step size \(\eta\) is small enough._

Figure F.4: Evolution of evaluation metrics along iteration time \(\tau\) under MAR scenario at 30% missing rate. The shaded area indicates the \(\pm\) 1.0 standard deviation uncertainty interval.

Proof.: First, let us reformulate the velocity field as follows:

\[u(\bm{X}^{\text{(joint)}})\] \[= \mathbb{E}_{r(\tilde{\bm{X}}^{\text{(joint)}})}\begin{Bmatrix}- \lambda\nabla_{\tilde{\bm{X}}^{\text{(mino)}}}K(\bm{X}^{\text{(joint)}},\tilde {\bm{X}}^{\text{(joint)}})\\ \qquad\qquad+[\nabla_{\tilde{\bm{X}}^{\text{(mino}}}\log\hat{p}(\tilde{\bm{X}} ^{\text{(joint)}})]^{\top}K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{\text{ (joint)}})\end{Bmatrix}\right\}\] \[\overset{\text{(i)}}{=} \mathbb{E}_{r(\tilde{\bm{X}}^{\text{(joint)}})}\begin{Bmatrix} \lambda[\nabla_{\tilde{\bm{X}}^{\text{(mino)}}}\log r(\tilde{\bm{X}}^{\text{ (joint)}})]^{\top}K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{\text{(joint)} })\\ \qquad\qquad+[\nabla_{\tilde{\bm{X}}^{\text{(mino}}}\log\hat{p}(\tilde{\bm{X}} ^{\text{(joint)}})]^{\top}K(\bm{X}^{\text{(joint)}},\tilde{\bm{X}}^{\text{ (joint)}})\end{Bmatrix}\] (F.6) \[= \int r(\tilde{\bm{X}}^{\text{(joint)}})\begin{Bmatrix} \lambda\nabla_{\tilde{\bm{X}}^{\text{(maxo)}}}\log r(\tilde{\bm{X}}^{\text{ (joint)}})\\ \qquad\qquad+\nabla_{\tilde{\bm{X}}^{\text{(mino}}}\log\hat{p}(\tilde{\bm{X}} ^{\text{(joint)}})\end{Bmatrix}\right\}^{\top}K(\bm{X}^{\text{(joint)}}, \tilde{\bm{X}}^{\text{(joint)}})\mathrm{d}\tilde{\bm{X}}^{\text{(joint)}}\] \[= \int\begin{Bmatrix}\lambda\nabla_{\tilde{\bm{X}}^{\text{(mino)}}} \log r(\tilde{\bm{X}}^{\text{(joint)}})\\ \qquad\qquad+\nabla_{\tilde{\bm{X}}^{\text{(mino}}}\log\hat{p}(\tilde{\bm{X}} ^{\text{(joint)}})\end{Bmatrix}\right\}^{\top}K(\bm{X}^{\text{(joint)}}, \tilde{\bm{X}}^{\text{(joint)}})\mathrm{d}r(\tilde{\bm{X}}^{\text{(joint)}}),\]

where (i) is based on integration by parts.

Figure F.5: Evolution of evaluation metrics along iteration time \(\tau\) under MCAR scenario at 30% missing rate. The shaded area indicates the \(\pm\) 1.0 standard deviation uncertainty interval.

[MISSING_PAGE_EMPTY:39]

#### e.5.2 Convergence Analysis of the Dsm Training

Similarly, we can also give the proposition of the DSM training algorithm located in step 5 of Algorithm 1, and summarized in Algorithm 3:

**Proposition F.2**.: _The convergence of the DSM training algorithm can be guaranteed, given that the learning rate \(lr\) is small enough._

Proof.: In the beginning, let us reformulate the parameter learning procedure of the DSM training algorithm as follows:

\[\theta_{\tau+1}=\theta_{\tau}-lr\times\nabla_{\theta}\mathcal{L}_{\text{DSM} }|_{\theta=\theta_{\tau}},\] (F.9)

which can be further reformulated as follows:

\[\frac{\theta_{\tau+1}-\theta_{\tau}}{lr}=-\nabla_{\theta}\mathcal{L}_{\text{ DSM}}|_{\theta=\theta_{\tau}}\] \[\Rightarrow \lim_{l\tau\to 0}\frac{\theta_{\tau+1}-\theta_{\tau}}{lr}=-\nabla_{ \theta}\mathcal{L}_{\text{DSM}}|_{\theta=\theta_{\tau}}\] (F.10) \[\Rightarrow \frac{\mathrm{d}\theta}{\mathrm{d}\tau}=-\nabla_{\theta} \mathcal{L}_{\text{DSM}}\]

Meanwhile, note that:

\[\frac{\mathrm{d}\mathcal{L}_{\text{DSM}}}{\mathrm{d}\tau}=\left\langle\nabla _{\theta}\mathcal{L}_{\text{DSM}},\frac{\mathrm{d}\theta}{\mathrm{d}\tau} \right\rangle.\] (F.11)

Plugging Eq. (F.10) into Eq. (F.11), we can get the following result:

\[\frac{\mathrm{d}\mathcal{L}_{\text{DSM}}}{\mathrm{d}\tau}=-\left\langle \nabla_{\theta}\mathcal{L}_{\text{DSM}},\nabla_{\theta}\mathcal{L}_{\text{DSM} }\right\rangle\leq 0,\] (F.12)

which indicates that the iterative procedure for \(\mathcal{L}_{\text{DSM}}\) is monotonic decreasing along \(\tau\).

Figure F.6: Evolution of evaluation metrics along iteration time \(\tau\) under MNAR scenario at 30% missing rate. The shaded area indicates the \(\pm\) 1.0 standard deviation uncertainty interval.

Finally, recall Eq. (15), we can know that the following condition holds:

\[\mathcal{L}_{\text{DSM}}\geq 0.\] (F.13)

Building on this, employing a smaller step size \(lr\) results in the iteration curve of \(\mathcal{L}_{\text{DSM}}\) more closely approximating the ODE defined in Eq. (F.11). Consequently, a smaller \(lr\) leads to a sequence where \(\mathcal{L}_{\text{DSM}}\) monotonically decreases, aligning with the theoretical expectations of the ODE behavior.

Based on this proposition, we plot the evolution of \(\mathcal{L}_{\text{DSM}}\) along time \(\tau\) in Fig. F.7. These figures illustrate that the \(\mathcal{L}_{\text{DSM}}\) generally decreases as the iteration epochs increase. This observed behavior supports our theoretical findings regarding the convergence of the DSM training algorithm.

Figure F.7: Evolution of \(\mathcal{L}_{\text{DSM}}\), the loss function of Estimation part along iteration time \(\tau\) at 30% missing rate. The shaded area indicates the \(\pm\) 1.0 standard deviation uncertainty interval. The results of \(\mathcal{L}_{\text{DSM}}\) are smoothed by exponential moving average with \(\alpha=0.60\).

### Downstream Task Comparison

To further substantiate the rigor of our manuscript and demonstrate the efficacy of the proposed NewImp approach, we conduct downstream task comparisons as detailed in this subsection. Initially, we evaluate the classification performance on imputed data using the following protocol: 1) Selection of datasets with non-binary labels. 2) Post-imputation, we train a support vector machine equipped with an RBF kernel and an automatic kernel coefficient. We assess the model's performance using 5-fold cross-validation, reporting both the mean and standard deviation of the accuracies across 10 runs with different random seeds. In this procedure, we select classification accuracy as our evaluation metric. 3) Additionally, we include the accuracy of ground-truth data for reference. The comparative results are presented in Table F.8. From Table F.8, it can be seen that the NewImp approach generally has the best performance among all baseline models, this phenomenon reflects the superiority of the proposed NewImp approach in a further way.

Moreover, we also conduct downstream regression task comparisons as detailed in this subsection. Initially, we evaluate the regression performance on imputed data using the following protocol: 1) Selection of datasets with continuous outcome variables. 2) After imputation, we train a support vector regression model equipped with an RBF kernel and an automatic kernel coefficient. We assess the model's performance using 5-fold cross-validation. In this procedure, we report both the mean and standard deviation of the mean squared errors (MSE) and mean absolute error (MAE) across 10 runs with different random seeds. 3) Additionally, we include the MSE and MAE on ground-truth data for reference. The comparative results are presented in Table F.9. As indicated in these results, the NewImp approach consistently outperforms most of the baseline models, further validating its superiority.

\begin{table}
\begin{tabular}{l|l|l|l|l|l|l} \hline \hline Scenario & Model & BCD & CBV & IS & QB & WQW \\ \hline \multirow{8}{*}{MAR} & CSDL\_T & \(0.677^{+}_{2.139:17}\) & \(0.069^{+}_{2.000:00E}\) & \(0.603^{+}_{2.139:17}\) & \(0.640^{+}_{2.000E}\) & \(0.441^{+}_{2.139:17}\) \\  & MissDiff & \(0.839^{+}_{2.49:17}\) & \(0.406^{+}_{2.47:27:17}\) & \(0.900^{+}_{3.30:17}\) & \(0.783^{+}_{2.49:17}\) & \(0.490^{+}_{2.185:17}\) \\  & GAIN & \(0.971^{+}_{2.132:17}\) & \(0.519^{+}_{2.185:17}\) & \(0.941^{+}_{4.99:17}\) & \(0.794^{+}_{2.70:17}\) & \(0.512^{+}_{2.67:17}\) \\  & MIRACLE & \(0.966^{+}_{2.49:17}\) & \(0.579^{+}_{3.70:17}\) & \(0.827^{+}_{2.47:27:17}\) & \(0.789^{+}_{2.47:27:17}\) & \(0.488^{+}_{3.08:17:26}\) \\  & MIWAE & \(0.968^{+}_{2.49:17}\) & \(0.567^{+}_{2.00:12:08:17}\) & \(0.939^{+}_{2.55:17}\) & \(0.858^{+}_{3.83:17:17}\) & \(0.482^{+}_{2.78:27:17}\) \\  & Sink & \(0.958^{+}_{0.000E}\) & \(0.499^{+}_{1.19:17}\) & \(0.891^{+}_{4.16:17}\) & \(0.798^{+}_{2.94:17}\) & \(0.477^{+}_{1.196:17}\) \\  & TDM & \(0.969^{+}_{2.416:17}\) & \(0.581^{+}_{5.55:17}\) & \(0.938^{+}_{4.16:16:17}\) & \(0.796^{+}_{5.55:17}\) & \(0.505^{+}_{4.46:17}\) \\  & ReMasker & \(0.973^{+}_{2.78:17}\) & \(0.517^{+}_{2.028:17}\) & \(0.935^{+}_{0.000E}\) & \(0.859^{+}_{4.16:17}\) & \(0.489^{+}_{1.85:17}\) \\  & **NewImp** & \(\textbf{0.974}_{\pm 0.176:17}\) & \(\textbf{0.595}_{\pm 0.167:17}\) & \(\textbf{0.947}_{\pm 0.93:17}\) & \(\textbf{0.866}_{\pm 0.3:70:17}\) & \(\textbf{0.513}^{+}_{4.46:17}\) \\ \hline \multirow{8}{*}{MCAR} & CSDL\_T & \(0.593^{+}_{1.396:17}\) & \(0.066^{+}_{2.06:18:16}\) & \(0.609^{+}_{1.396:17}\) & \(0.656^{+}_{1.00:00E}\) & \(0.441^{+}_{1.396:17}\) \\  & MissDiff & \(0.756^{+}_{3.306:17}\) & \(0.327^{+}_{3.70:17}\) & \(0.883^{+}_{1.67:17}\) & \(0.732^{+}_{2.74:16:17}\) & \(0.748^{+}_{3.08:17:17}\) \\  & GAIN & \(0.964^{+}_{2.406:17}\) & \(0.489_{\pm 0.38:17}\) & \(0.929^{+}_{2.47:16:17}\) & \(0.837^{+}_{1.67:17:17}\) & \(0.491^{+}_{3.08:17:17}\) \\  & MIRACLE & \(0.923^{+}_{2.46:17:17}\) & \(0.450^{+}_{2.47:27:17}\) & \(0.709^{+}_{2.47:16:17}\) & \(0.770^{+}_{1.00:00E}\) & \(0.474^{+}_{3.08:17:17}\) \\  & MIWAE & \(0.957^{+}_{2.64:94:17}\) & \(0.451^{+}_{1.39:19:17}\) & \(0.917^{+}_{5.55:17}\) & \(0.831^{+}_{4.16:17}\) & \(0.492^{+}_{2.08:17}\) \\  & Sink & \(0.950^{+}_{0.000E}\) & \(0.446^{+}_{2.02:18:17}\) & \(0.877^{+}_{6.94:17}\) & \(0.768^{+}_{0.00E}\) & \(0.462^{+}_{2.08:17}\) \\  & TDM & \(0.961^{+}_{3.83:17:36:17}\) & \(0.486^{+}_{3.47:17}\) & \(0.922^{+}_{3.55:17}\) & \(0.836^{+}_{3.55:17}\) & \(0.489^{+}_{2.78:17}\) \\  & ReMasker & \(0.965^{+}_{3.55:17}\) & \(0.468^{+}_{1.39:17:17}\) & \(0.922^{+}_{3.85:17}\) & \(0.762^{+}_{1.39:17}\) & \(0.479^{+}_{1.18:17:17}\) \\  & **NewImp** & \(\textbf{0.967}_{\pm 0.49:17}\) & \(\textbf{0.494}_{\pm 0.32:17}\) & \(\textbf{0.934}_{\pm 0.49:17}\) & \(\textbf{0.839}_{\pm 2.47:17}\) & \(\textbf{0.495}_{\pm 0.28:17}\) \\ \hline \multirow{8}{*}{MNAR} & CSDL\_T & \(0.658^{+}_{2.416:17}\) & \(0.078^{+}_{2.50:18}\) & \(0.608^{+}_{0.000E}\) & \(0.647^{+}_{0.00E}\) & \(0.440^{+}_{2.69:18}\) \\  & MissDiff & \(0.800^{+}_{2.47:17}\) & \(0.322^{+}_{2.47:17}\) & \(0.884^{+}_{3.30:17:17}\) & \(0.749^{+}_{2.49:17}\) & \(0.480^{+}_{1.18:18:17}\) \\  & GAIN & \(0.963^{+}_{2.617:17}\) & \(0.475^{+}_{1.85:19:17}\) & \(0.925^{+}_{1.37:10:17}\) & \(0.837^{+}_{2.77:16:17}\) & \(0.493^{+}_{2.47:17}\) \\  & MIRACLE & \(0.930^{+}_{4.93:19:17}\) & \(0.457^{+}_{3.03:18:17}\) & \(0.

[MISSING_PAGE_EMPTY:43]

[MISSING_PAGE_EMPTY:44]

[MISSING_PAGE_EMPTY:45]

[MISSING_PAGE_FAIL:46]

[MISSING_PAGE_EMPTY:47]

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The main claims made in the abstract and introduction accurately reflect our paper's contributions and scope. We restrict our application in missing value imputation task in numerical tabular, and our analysis is mainly focused on diffusion models, where the score function is required. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Our limitations are listed in Appendix G.1. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [Yes] Justification: To uphold the rigor of our manuscript, we provide all proofs of our proposition as outlined in Appendix C. Besides, all theorems are properly cited in the manuscript. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We attempt to list all hyperparameters in Appendices D and E to ensure reproducibility. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We used the open access UCI datasets, and we uploaded our algorithm in this github link https://github.com/JustusvLiebig/NewImp. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We have included all detailed information in Appendices D and E. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: In Tables F.3 to F.9 and G.1 to G.8, and Figs. F.4 to F.7, we report standard deviation errors suitably and correctly defined or other appropriate information about the statistical significance and error bar of the experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.

* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The required information is given in Appendices E.2 and F.4. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: Since it is an algorithm-oriented research, there is no societal impact of the work performed. Guidelines: * The answer NA means that there is no societal impact of the work performed.

* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This paper does not involve the safeguards issue. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.

12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: The creators or original owners of assets (e.g., code, data, models), used in the paper, are properly credited. The license and terms of use are explicitly mentioned and properly respected. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset.

* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: We do not not release new assets in this manuscript. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: Our experiments did not involve 'Crowdsourcing and Research with Human Subjects'. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Our answer is NA since our paper does not involve crowdsourcing or research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.

* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.