# Copycats: the many lives of a publicly available medical imaging dataset

 Amelia Jimenez-Sanchez\({}^{1}\) Natalia-Rozalia Avlona\({}^{2}\) Dovile Juodelyte\({}^{1}\) Theo Sourget\({}^{1}\) Caroline Vang-Larsen\({}^{1}\) Anna Rogers\({}^{1}\) Hubert Dariusz Zajac\({}^{2}\) Veronika Cheplygina\({}^{1}\)

\({}^{1}\)IT University of Copenhagen \({}^{2}\)University of Copenhagen {amji,vech}@itu.dk

###### Abstract

Medical Imaging (MI) datasets are fundamental to artificial intelligence in healthcare. The accuracy, robustness, and fairness of diagnostic algorithms depend on the data (and its quality) used to train and evaluate the models. MI datasets used to be proprietary, but have become increasingly available to the public, including on community-contributed platforms (CCPs) like Kaggle or HuggingFace. While open data is important to enhance the redistribution of data's public value, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating datasets. In this paper, we conduct an analysis of publicly available machine learning datasets on CCPs, discussing datasets' context, and identifying limitations and gaps in the current CCP landscape. We highlight differences between MI and computer vision datasets, particularly in the potentially harmful downstream effects from poor adoption of recommended dataset management practices. We compare the analyzed datasets across several dimensions, including data sharing, data documentation, and maintenance. We find vague licenses, lack of persistent identifiers and storage, duplicates, and missing metadata, with differences between the platforms. Our research contributes to efforts in responsible data curation and AI algorithms for healthcare.

## 1 Introduction

Datasets are fundamental to the fields of machine learning (ML) and computer vision (CV), from interpreting performance metrics and conclusions of research papers to assessing adverse impacts of algorithms on individuals, groups, and society. Within these fields, medical imaging (MI) datasets are especially important to the safe realization of Artificial Intelligence (AI) in healthcare. Although MI datasets share certain similarities to general CV datasets, they also possess distinctive properties, and treating them as equivalent can lead to various harmful effects. In particular, we highlight three properties of MI datasets: (i) de-identification is required for patient-derived data; (ii) since multiple images can belong to one patient, data splits should clearly differentiate images from each patient; and (iii) metadata containing crucial information such as demographics or hospital scanner is necessary, as models without this information could lead to inaccurate and biased results.

In the past, MI datasets were frequently proprietary, confined to particular institutions, and stored in private repositories. In this particular setting, there is a pressing need for alternative models of data sharing, documentation, and governance. Within this context, the emergence of Community-Contributed Platforms (CCPs) presented a potential for the public sharing of medical datasets. Nowadays, more MI datasets have become publicly available and are hosted on open platforms such as grand-challenges1, or CCP - including companies like Kaggle or HuggingFace.

Footnote 1: https://grand-challenge.org

Although the increasing availability of MI datasets is generally an advancement for sharing and adding public value, it also presents several challenges. First, according to the FAIR (Findable, Accessible, Interoperable, Reusable) guiding principles for scientific data management and stewardship [122], (meta)data should be released with a clear and accessible data usage license and should be permanently accessible. Second, tracking dataset versions is becoming increasingly difficult, especially when publications use derived versions [89] or the citation practices are not followed [109]. This hampers the analysis of usage patterns to identify possible ethical concerns that might arise after releasing a dataset [33], potentially leading to its retraction [89; 60]. To mitigate the harms associated with datasets, ongoing maintenance, and stewardship are necessary [89]. Lastly, rich documentation is essential to avoiding over-optimistic and biased results [15; 68; 32; 125; 86], attributed to a lack of meta-data in MI datasets, such as information linking images to specific patients and their demographics. Documentation needs to reflect all the stages in the dataset development cycle, such as acquisition, storage, and maintenance [51; 40]. Although CCPs offer ways to enhance the redistribution of data's public value and alleviate some of these problems providing structured summaries, we find that the current CCP governance model fails to uphold the quality needed and recommended practices for sharing, documenting, and evaluating MI datasets.

In this paper, we investigate MI datasets hosted on CCPs, particularly how they are documented, shared, and maintained. First, we provide relevant background information, highlighting the differences between open MI and CV datasets, especially in the potential for harmful downstream effects of poor documentation and distribution practices (Section 2.1). Second, we present key aspects of data governance in the context of ML and healthcare, specifically affecting MI datasets (Section 2.2). Third, we analyze _access, quality_ and _documentation_ of 30 popular datasets hosted on CCPs (10 medical, 10 computer vision, and 10 natural language processing). We find issues across platforms related to vague licenses, lack of persistent identifiers and storage, duplicates, and missing metadata (Section 3). We discuss the limitations of the current dataset management practices and data governance on CCPs, provide recommendations for MI datasets, and conclude with a discussion of limitations of our work and open questions (Section 4).

## 2 Background

### Characteristics of medical imaging datasets

Anatomy of a medical imaging dataset.A MI dataset begins with a collection of images from various imaging modalities, such as X-rays, magnetic resonance imaging (MRI), computed tomography (CT) scans, and others. The scans are often initially captured for a clinical purpose, such as diagnosis or treatment planning, and are associated with a specific patient and their medical data. The scans might undergo various processing steps, such as denoising, registration (aligning different scans together), or segmentation (delineating anatomical structures or pathologies). Clinical experts might then associate the scans with additional information, _e.g_., free text reports or diagnostic labels.

Figure 1: A Medical Imaging (MI) dataset containing images, labels, metadata (patient id, patient sex, etc.), and license (left). After user interaction, on Community-Contributed Platforms we find duplicated data, missing licenses and metadata, which can lead to overoptimistic results (right).

A collection of scans and associated annotations, _i.e._, a MI dataset, might be later used for the purpose of training and evaluating ML models supporting the work of medical professionals [133, 115]. However, before a dataset is "ready" for ML, further steps are required [123], including cleaning (for example, removing scans that are too blurry), sampling (for example, only selecting scans with a particular disease), and removing identifying patient information. Additional annotations, not collected during clinical practice, may be required to train ML models, _e.g._, organ delineations for patients not undergoing radiotherapy. These annotations might be provided by clinical experts, PhD students, or paid annotators at tech companies.

Not just "small computer vision"!While MI datasets share some similarities with general CV datasets, they also have unique properties. The diversity of image modalities and data preprocessing needed for each specific application is vast. For instance 3D images from modalities like MRI can vary significantly depending on the sequence used. For example, brain MRI sequences (T1-weighted, T2, FLAIR, etc.), are designed to emphasize different brain structures, offering specific physiological and anatomical details. Whole-slide images of histopathology are extremely large (gigapixel) images, making preprocessing both challenging and essential for accurate analysis. A crucial part of this process is stain normalization, which standardizes color variations caused by different staining processes, ensuring consistency across slides for more reliable analysis and comparison [29]. We refer interest readers in knowing more about preparing MI data of different modalities for ML for example to [123, 67].

Nevertheless, the complexity of medical image data above is often reduced to a collection of ML-library-ready images and labels. Yet treating MI datasets as equivalent to benchmark CV datasets is problematic and leads to harmful effects, also termed _data cascades_ by [102]. _Data cascades_ can lead to degraded model performance, reinforce biases, increase maintenance costs, and reduce trust in AI systems. These problems often stem from poor data quality, lack of domain expertise, and insufficient documentation, which become increasingly difficult to correct once models are deployed.

First, unlike traditional CV datasets, medical images often require de-identification processes to remove personally identifiable data, which are more complex than complete anonymization. Certain attributes like sex and age, need to be preserved for clinical tasks. These attributes are typically included in an "original release" of MI datasets, they might be removed later in a dataset's lifecycle. For example, when medical datasets are shared on CCPs, often only the input desired by ML practitioners remains: inputs (images) and outputs (disease labels), as shown in Figure 1.

Second, MI datasets often include multiple images associated with a single patient. This can occur if a patient has multiple skin lesions, follow-up chest X-rays, or 3D scans split into 2D images. If images from the same patient end up in both training and test data, reported results may be overly optimistic as classifiers memorize patients rather than disease characteristics. Therefore, data splitting at the patient level is crucial to avoid model overfitting. While this practice is common in the MI community, it may be overlooked if datasets are simply shared as a general CV dataset.

Third, MI datasets should contain metadata about patient demographics. Several studies have shown how demographic data may alleviate systematic biases and impact disease classification performance in chest X-rays [68, 106] and skin lesions [4]. These datasets are often the subject of research on bias and fairness because they include variables for age and sex or gender (typically not described which). However, many MI datasets lack these variables, possibly due to removal in a ML-ifying step rather than actual anonymization. Unlike CV datasets where bias can be identified by annotating individuals in the images based on their gender expression [131], such information is often unrecoverable from medical images. Additionally, images may be duplicated; see, _e.g._, [20] for an analysis of the ISIC datasets, with overlaps between versions and duplication of cases between training and test sets.

Finally, MI datasets should include metadata about the origin of scans. Lack of such data may lead to "shortcuts" and other systematic biases. For example, if disease severity correlates with the hospital where the scans were made (general _vs_. cancer clinic), a model might learn the clinic's scanner signature as a shortcut for the disease [27]. In other words, the shortcut is a spurious correlation between an artifact in the image and the diagnostic label. Some examples of shortcuts include patient position in COVID-19 [32], chest drains in pneumothorax classification [86, 57], or pen marks in skin lesion classification [125, 15, 26]. High overall performance can hide biases in benchmark evaluations serving underrepresented groups. This cannot be detected without appropriate metadata.

[MISSING_PAGE_EMPTY:4]

[MISSING_PAGE_FAIL:5]

[MISSING_PAGE_FAIL:6]

research outcomes. Besides ISIC, on Kaggle we find other examples of unnecessary duplication of data, see Table 3 of the Supplementary Material for details.

After this finding about ISIC, we examined several other datasets for duplication. On Kaggle, we find 350 datasets related to BraTS (Brain Tumor Segmentation) [80], and 24 datasets of INBreast [82], one of them with the rephrased description "I'm just uploading here this data as a backup". Additionally, there are 10 instances of PAD-UFES-20 [88] (also a skin lesion dataset, one instance actually contains data from ISIC). The ACDC (Automated Cardiac Diagnosis Challenge) dataset [13] consists of MRIs, while ACDC-LungHP (Automatic Cancer Detection and Classification in Lung Histopathology) dataset [73, 74] contains histopathological images. On Kaggle, we find an example of a dataset titled "ACDC lung" that contains cardiac images.

The lack of documentation for _all_ ML, not just MI datasets, hampers tracking their usage, potentially violates sharing agreements or licenses, and hinders reproducibility. Additionally, due to the characteristics of MI datasets, models trained on datasets missing metadata could result into overoptimistic performance due to data splits mixing patient data, or bias [68] or shortcuts [86, 125]. We therefore reviewed the documentation on the original websites and related papers for the MI datasets, and found that patient data splits were clearly reported for 6 out of 10 datasets - "clearly reported" means that a field like "patient_id" was provided for each case. However, tracking whether data splits are defined at the subject level for duplicates on CCPs is challenging, as the relevant information is not always in the same location. One must examine the file contents (often requiring downloading the entire dataset) of each duplicated dataset to determine if a field like "patient_id" is available.

Limited implementation of structured summaries.We find that overall HuggingFace follows a much more structured and complete documentation than Kaggle, as reflected in their guides [1, 3]. From our list of MI datasets, on HF we find an instance of MIMIC-CXR with no documentation or reference at all, and other medical datasets (_e.g._ Alzheimer's disease or skin cancer classification) without source citation. We find the lack of source citations for patient-related data deeply concerning. Kaggle automatically computes _usability score_, which is associated with the tag "well-documented" and used for ranking results when searching for a dataset. This score is based on completeness, credibility, and compatibility, we show detailed information about these parameters in Section A.1 of the Supplementary Material. However, we find that even datasets with 100% usability present some issues. For example, based on our observations, the parameter _update frequency_ from maintenance is rarely used. However, an option for this parameter is to set it as "never" while still achieving a high _usability score_. Details about _provenance_ might be filled in on the data card but may be vague, such as "uses internet sources".

We compare the categories analyzed in Kaggle and HuggingFace's data cards with those in Datasheets [40]. Despite making various efforts to integrate dataset documentation, such as the recent inclusion of Croissant [5], a metadata format designed for ML-ready datasets, we have noticed a prevalent issue:

Figure 2: Representation of the storage size for ISIC (skin lesion) datasets. While the ISIC website hosts a total of 38 GB of data (left), on Kaggle there are a total of 640 datasets related to ISIC (some preprocessed, other with additional annotations), that sum up to 2.35 TB of data (right). Each block on the (right) represents a single instance of ISIC-derived dataset on Kaggle. Block size represents dataset size. Data was retrieved on May 15, 2024.

many of the documentation fields remain empty. While these platforms strive to provide structured summaries, the practical outcome often falls short. Overall, we find composition and collection process are the two fields most represented; motivation of the creation of the dataset is rarely included in the general description of the dataset; information about preprocessing/cleaning/labeling or about uses is usually missing. Only for HuggingFace the field _task_categories_ can point to some possible uses, potentially enabling systematic analysis of a specific task or tag. Kaggle provides a parameter for maintenance of the dataset, although we have already mentioned its limitations. HuggingFace does not provide a specific parameter for maintenance but it is possible to track on their website the history of files and versions. We detail the parameter categorization in Table 2 (Suppl. Material).

## 4 Discussion

Asymmetry between open data and proprietary datasets.Commercial AI systems in clinical settings are unlikely to rely solely on open MI datasets for training. They ensure data quality through agreements or obtaining high-quality medical images [95]. Companies providing proprietary MI datasets or labeling services handle challenges such as licensing, documentation, and data quality, offering greater customization and flexibility. Such proprietary datasets remain unaffected by the mentioned challenges [95; 130]. Similarly, [130] have shown how regulatory compliance and internal organizational requirements, transverse and often define dataset quality.

This asymmetry between the issues of open data and the value offered by proprietary datasets highlights the shortcomings of publicly available MI data. While open data initiatives like CCPs offer the potential to redistribute data value for the common good and public interest, the current status of MI datasets falls short in reliably training high-performing, equitable, and responsible AI models. Due to these limitations, we suggest rethinking and evaluating open datasets within CCPs through the concepts of _access, quality, and documentation_ drawing upon the FAIR principles [122]. We argue that these concerns need to be accounted for if the MI datasets are to live up to the ideals of open data.

Access to open datasets should be predictable, compliant with open licensing, and persistent.In this paper, we show that a proper dataset infrastructure (both legal and technical) is crucial for their effective utilization. Open datasets must be properly licensed to prevent harm to end-users by models trained on legally ambiguous open data with the potential for bias and unfairness [104; 69]. Moreover, vague licensing pushes the users of open datasets into a legal grey zone [41]. [28] noticed such a legal gap in the "inappropriate" use of open AI models and pointed out the danger of their possible unrestricted and unethical use. To ensure the responsible use of AI models, they envisioned enforceable licensing. Legal clarity should also span persistent and deterministic storage. The most popular ML datasets are mostly hosted by established academic institutions. However, the CCPs host a plethora of duplicated or altered MI datasets. Instead of boosting the opportunities for AI creators, this abundance may become a hindrance when _e.g._, developers cannot possibly track changes introduced between different versions of a dataset. We argue that open data has to be predictably and persistently accessible under clear conditions and for clear purposes.

Open datasets should be evaluated against the context of real-world use.The understanding of high-quality data for AI training purposes is constantly evolving [120]. After a thorough evaluation focused on real-world use, MI datasets, once considered high-quality [52; 118; 22; 113], were revealed to contain flaws (chest drains, dark corners, ruler markers, etc.) questioning their clinical usefulness [86; 57; 15; 115]. Maintaining open datasets is often an endeavor that is too costly for their creators, resulting in the deteriorating quality of available datasets. Moreover, we showed the prevalence of information about shortcuts and missing metadata in MI datasets hosted on CCPs. These issues can reduce the clinical usefulness of developed systems and, in extreme scenarios, potentially cause harm to the intended beneficiaries. We encourage the MI and other ML communities to expand the understanding of high-quality data by incorporating rich metadata and emphasizing real-world evaluations, including testing to uncover biases or shortcuts [86; 43].

Datasets documentation should be complete and up-to-date.Research has shown that access to large amounts of data does not necessarily warrant the creation of responsible and equitable AI models [94]. Instead, it is the connection between the dataset's size and the understanding of the work that resulted in the creation of a dataset. This connection is the premise behind the creation of proprietary datasets designed for use in private enterprises. When that direct connection is broken, a fairly common scenario in the case of open datasets, the knowledge of the decisions taken during dataset creation is lost. Critical data and data science scholars are concerned about the social and technical consequences of using such undocumented data. Thus, a range of documentation frameworks were proposed [48, 12, 94, 40, 34, 51]. Each documentation method slightly differs, focusing on various aspects of dataset quality. However, their overall goal is to introduce greater transparency and accountability in design choices. These conscious approaches aim to foster greater reproducibility and contribute to the development of responsible AI. Unfortunately, as shown in this paper, the real-world implementation of these frameworks is lacking. Even when a CCP provides a documentation framework, the content rarely aligns with the frameworks' principles. CCPs could take inspiration from PhysioNet [44], which implements checks on new contributions. Any new submissions are first vetted7 by the editors and may require re-submission if the expected metadata is not provided. When the supplied documentation does not adhere to the frameworks' principles, it fails to fulfill its intended purpose, placing users of open datasets at a disadvantage compared to users of proprietary datasets. We note that while we talk about completeness of documentation and the frameworks provide guidelines on what kind of information that might entail, it is not clear how one would quantify that the documentation is 86% complete in a way that reflects the data stakeholders' needs and is not merely a box-ticking exercise.

Footnote 7: https://physionet.org/about/publish/

CCPs could benefit from commons-based governance.Data governance can help mitigate the issues of accountability, fairness, discrimination, and trust. Inspired by the Wikipedia model [37], we recommend that CCPs implement norms and principles derived from this commons-based governance model. We suggest incorporating at least the roles of _data administrator_, and _data steward_. We define the role of _data administrator_ as the first-level of data stewardship, a sanctioning mechanism that ensures proper (1) licensing, (2) persistent identifiers, and (3) completeness of metadata for open MI datasets that enter the platform. We define as the second-level of data stewardship, the role of _data steward_, who will be responsible for the ongoing monitoring of the (1) maintenance, (2) storage, and (3) implementation of documentation practices.

Nevertheless, these data stewardship proposals, as a commons-based governance model, need further exploration within a broader community of CCP practitioners. Recognizing the limited resources (monetary and/or human labor) in CCP initiatives, we are very careful in suggesting a complex governance system that would solely rely on the unpaid labor of dataset creators. Instead, we propose this direction for future applied research to enhance the dataset management and stewardship of MI datasets on CCP through commons-based approaches. We sincerely hope that more institutions will support efforts to improve the value of open datasets, which will require additional structural support, such as permanent and paid roles for data stewards [90].

Initiatives to work on data and improve the data lifecycle.Several fairly recent initiatives aim to address the overlooked role of datasets like the NeurIPS Datasets and Benchmarks Track or the Journal of Data-centric Machine Learning Research (DMLR). New develop platforms, like the data providence explorer [76], help developers track and filter thousands of datasets for legal and ethical issues, and allow scholars and journalists to examine the composition and origins of popular AI datasets. Other newly born initiative is Croissant [5], a metadata format for ML-ready datasets, which is currently supported by Kaggle, HuggingFace and other platforms. ML and NLP conferences have started to require ethics statements and various checklists with submissions [14, 18, 98] for the reviewer use, and even include them in the camera-ready versions of accepted papers [99] to incentive better documentation. Such checklists typically include questions about data license and documentation, and they could be extended to help develop the norm of not just sharing, but also documenting any new data accompanying research papers, or encourage the use of the 'official' documented dataset versions.

In the MI context, conferences like MICCAI have incorporated a structured format for challenge datasets to ensure high-quality data. Initiatives like Project MONAI [17] introduce a platform to facilitate collaborative frameworks for medical image analysis and accelerate research and clinical collaboration. Drawing inspiration from CV, benchmark datasets are now emerging in MI, such as MedMNIST [127] and MedMNIST v2 [128]. These multi-dataset benchmarks have their pros and cons. They are hosted on Zenodo, which facilitates version control, provides persistent identifiers, and ensures proper storage. However, the process of standardizing MI datasets to the CV format means they lack details about patient demographics (such as age, gender, and race), information on the medical acquisition devices used, and other metadata, including patient splits for training and testing. Recent works have investigated data sharing and citations practices at MICCAI and MIDL [109], and reproducibility and quality of MIDL public repositories [107].

More insights needed from all people involved.A limitation of our study is that it is primarily based on our quantitative evidence and our subjective perceptions of the fields and practices we describe of a limited number of screened datasets, yet the most cited ones. However, a recent study [129] has quantitatively and qualitatively confirmed our observations about the lack of documentation for datasets on HuggingFace. However, we did not reach out to Kaggle or HuggingFace. To gain a better understanding of data curation, maintenance, and re-use practices, it would be valuable to do a qualitative analysis with MI and ML practitioners to understand their use of datasets. For example, [130] is a recent study, based on interviews with researchers from companies and the public health sector, of how several medical datasets were created. It would be interesting to investigate how researchers select datasets to work on, looking beyond mere correlations with popularity and quantitative metrics. We might be able to learn valuable lessons from other communities that we have not explored in this paper, for example neuroimaging (which might appear to be a subset of medical imaging, but in terms of people and conferences is a fairly distinct community), where various issues around open data have been explored [92, 91, 114, 121, 50, 11, 84].

However, we should not forget that understanding research practices around datasets is not just of relevance to ML and adjacent communities. These datasets have broader importance as these datasets are affecting people who are not necessarily represented at research conferences, so further research should involve these most affected groups [112]. Public participation in data use [42], alternative data sharing, documenting, and governance models [35] are crucial to addressing power imbalances and enhancing data's generation of value as a common good [87, 93, 111]. Furthermore, neglecting the importance of recognizing and prioritizing the foundational role of data when working with MI datasets can lead to downstream harmful effects, such as _data cascades_[102]. **In conclusion**, our observations reveal that the existing CCP governance model falls short of maintaining the necessary quality standards and recommended practices for sharing, documenting, and evaluating open MI datasets. Our recommendations aim to promote better data governance in the context of MI datasets to mitigate these risks and uphold the reliability and fairness of AI models in healthcare.

## Acknowledgments

This project has received funding from the Independent Research Council Denmark (DFF) Inge Lehmann 1134-00017B. We would like to thank the reviewers for their their valuable feedback, which has contributed to the improvement of this work.

## References

* [1] Huggingface datasets card creation guide. https://huggingface.co/docs/datasets/v1.12.0/dataset_card.html. Accessed: 2024-01-10.
* [2] Isic archive. https://www.isic-archive.com/. Accessed: 2024-05-22.
* [3] Kaggle datasets documentation. https://www.kaggle.com/docs/datasets. Accessed: 2024-01-10.
* [4] Samaneh Abbasi-Sureshjani, Ralf Raumanns, Britt EJ Michels, Gerard Schouten, and Veronika Cheplygina. Risk of training diagnostic algorithms on data with demographic bias. In _MICCAI LABELS workshop, Lecture Notes in Computer Science_, volume 12446, pages 183-192. Springer, 2020.
* [5] Mubashara Akhtar, Omar Benjelloun, Costanza Conforti, Joan Giner-Miguelez, Nitisha Jain, Michael Kuchnik, Quentin Lhoest, Pierre Marcenac, Manil Maskey, et al. Croissant: A Metadata Format for ML-Ready Datasets. _arXiv preprint arXiv:2403.19546_, 2024.
* [6] Majid Al-Ruithe, Elhadj Benkhelifa, and Khawar Hameed. A systematic literature review of data governance and cloud data governance. _Personal and Ubiquitous Computing_, 23:839-859, 2019.

* [7] Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, and Devi Parikh. VQA: Visual Question Answering. In _International Conference on Computer Vision (ICCV)_, 2015.
* [8] Samuel G Armato, Geoffrey McLennan, Luc Bidaut, Michael F McNitt-Gray, Charles R Meyer, Anthony P Reeves, Binsheng Zhao, Denise R Aberle, Claudia I Henschke, Eric A Hoffman, et al. The lung image database consortium (LIDC) and image database resource initiative (IDRI): a completed reference database of lung nodules on CT scans. _Medical Physics_, 38(2):915-931, 2011.
* [9] Muhammad Ayaz, Muhammad F Pasha, Mohammed Y Alzahrani, Rahmat Budiarto, and Deris Stiawan. The Fast Health Interoperability Resources (FHIR) standard: systematic literature review of implementations, applications, challenges and opportunities. _JMIR Medical Informatics_, 9(7):e21929, 2021.
* [10] Andrew L Beam, Arjun K Manrai, and Marzyeh Ghassemi. Challenges to the Reproducibility of Machine Learning Models in Health Care. _JAMA_, 323(4):305-306, 2020.
* [11] Michael JS Beauvais, Bartha Maria Knoppers, and Judy Illes. A marathon, not a sprint-neuroimaging, Open science and ethics. _Neuroimage_, 236:118041, 2021.
* [12] Emily M. Bender and Batya Friedman. Data statements for natural language processing: Toward mitigating system bias and enabling better science. _Transactions of the Association for Computational Linguistics_, 6:587-604, 2018.
* [13] Olivier Bernard, Alain Lalande, Clement Zotti, Frederick Cervenansky, Xin Yang, Pheng-Ann Heng, Irem Cetin, Karim Lekadir, Oscar Camara, Miguel Angel Gonzalez Ballester, et al. Deep learning techniques for automatic mri cardiac multi-structures segmentation and diagnosis: is the problem solved? _IEEE Transactions on Medical Imaging_, 37(11):2514-2525, 2018.
* [14] Alina Beygelzimer, Yann Dauphin, Percy Liang, and Jennifer Wortman Vaughan. Introducing the NeurIPS 2021 Paper Checklist, March 2021.
* [15] Alceu Bissoto, Eduardo Valle, and Sandra Avila. Debiasing Skin Lesion Datasets and Models? Not So Fast. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops_, pages 740-741, 2020.
* [16] Samuel Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. A large annotated corpus for learning natural language inference. In _Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing_, pages 632-642, 2015.
* [17] M Jorge Cardoso, Wenqi Li, Richard Brown, Nic Ma, Eric Kerfoot, Yiheng Wang, Benjamin Murrey, Andriy Myronenko, Can Zhao, Dong Yang, et al. MONAI: An open-source framework for deep learning in healthcare. _arXiv preprint arXiv:2211.02701_, 2022.
* [18] Marine Carpuat, Marie-Catherine de Marneffe, and Ivan Vladimir Meza Ruiz. Responsible NLP research Checklist, December 2021.
* [19] Stephanie Russo Carroll, Ibrahim Garba, Oscar L Figueroa-Rodriguez, Jarita Holbrook, Raymond Lovett, Simeon Materechera, Mark Parsons, Kay Raseroka, Desi Rodriguez-Lonebear, Robyn Rowe, et al. The CARE Principles for Indigenous Data Governance. _Data Science Journal_, 2020.
* [20] Bill Cassidy, Connah Kendrick, Andrzej Brodzicki, Joanna Jaworek-Korjakowska, and Moi Hoon Yap. Analysis of the ISIC image datasets: Usage, benchmarks and recommendations. _Medical Image Analysis_, 75:102305, 2022.
* [21] Adam Coates, Andrew Ng, and Honglak Lee. An analysis of single-layer networks in unsupervised feature learning. In Geoffrey Gordon, David Dunson, and Miroslav Dudik, editors, _Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics_, volume 15 of _Proceedings of Machine Learning Research_, pages 215-223, Fort Lauderdale, FL, USA, 11-13 Apr 2011. PMLR.

* [22] Noel CF Codella, David Gutman, M Emre Celebi, Brian Helba, Michael A Marchetti, Stephen W Dusza, Aadi Kalloo, Konstantinos Liopyris, Nabin Mishra, Harald Kittler, et al. Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017 International Symposium on Biomedical Imaging (ISBI), Hosted by the International Skin Imaging Collaboration (ISIC). In _2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)_, pages 168-172. IEEE, 2018.
* [23] Giovanni Colavizza, Iain Hrynaszkiewicz, Isla Staden, Kirstie Whitaker, and Barbara McGillivray. The citation advantage of linking publications to research data. _PloS One_, 15(4):e0230416, 2020.
* [24] Gary S Collins, Karel G M Moons, Paula Dhiman, Richard D Riley, Andrew L Beam, Ben Van Calster, Marzyeh Ghassemi, Xiaoxuan Liu, Johannes B Reitsma, Maarten van Smeden, Anne-Laure Boulesteix, Jennifer Catherine Camaradou, Leo Anthony Celi, Spiros Denaxas, Alastair K Denniston, Ben Glocker, Robert M Golub, Hugh Harvey, Georg Heinze, Michael M Hoffman, Andre Pascal Kengne, Emily Lam, Naomi Lee, Elizabeth W Loder, Lena Maier-Hein, Bilal A Mateen, Melissa D McCradden, Lauren Oakden-Rayner, Johan Ordish, Richard Parnell, Sherri Rose, Karandeep Singh, Laure Wynants, and Patricia Logullo. TRIPOD+AI statement: updated guidance for reporting clinical prediction models that use regression or machine learning methods. _BMJ_, page e078378, April 2024.
* [25] Gary S Collins and Karel GM Moons. Reporting of artificial intelligence prediction models. _The Lancet_, 393(10181):1577-1579, 2019.
* [26] Marc Combalia, Noel Codella, Veronica Rotemberg, Cristina Carrera, Stephen Dusza, David Gutman, Brian Helba, Harald Kittler, Nicholas R Kuransky, Konstantinos Liopyris, Michael A Marchetti, Sebastian Podlipnik, Susana Puig, Christoph Rinner, Philipp Tschandl, Jochen Weber, Allan Halpern, and Josep Malvehy. Validation of artificial intelligence prediction models for skin cancer diagnosis using dermoscopy images: the 2019 international skin imaging collaboration grand challenge. _The Lancet Digital Health_, 4(5):e330-e339, 2022.
* [27] Rhys Compton, Lily Zhang, Aahlad Puli, and Rajesh Ranganath. When more is less: Incorporating additional datasets can hurt performance by introducing spurious correlations. In _Machine Learning for Healthcare Conference_, pages 110-127. PMLR, 2023.
* [28] Danish Contractor, Daniel McDuff, Julia Katherine Haines, Jenny Lee, Christopher Hines, Brent Hecht, Nicholas Vincent, and Hanlin Li. Behavioral use licensing for responsible ai. In _Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency_, FAccT '22, page 778-788, New York, NY, USA, 2022. Association for Computing Machinery.
* [29] Miao Cui and David Y Zhang. Artificial intelligence and computational pathology. _Laboratory Investigation_, 101(4):412-422, 2021.
* [30] Arianna Dagliati, Alberto Malovini, Valentina Tibollo, and Riccardo Bellazzi. Health informatics and EHR to support clinical research in the COVID-19 pandemic: an overview. _Briefings in Bioinformatics_, 22(2):812-822, 2021.
* [31] Roxana Daneshjou, Mary P Smith, Mary D Sun, Veronica Rotemberg, and James Zou. Lack of transparency and potential bias in artificial intelligence data sets and algorithms: a scoping review. _JAMA dermatology_, 157(11):1362-1369, 2021.
* [32] Alex J DeGrave, Joseph D Janizek, and Su-In Lee. AI for radiographic COVID-19 detection selects shortcuts over signal. _Nature Machine Intelligence_, pages 1-10, 2021.
* [33] Emily Denton, Alex Hanna, Razvan Amironesei, Andrew Smart, and Hilary Nicole. On the genealogy of machine learning datasets: A critical history of ImageNet. _Big Data & Society_, 8(2):20539517211035955, 2021.
* [34] Mark Diaz, Ian Kivlichan, Rachel Rosen, Dylan Baker, Razvan Amironesei, Vinodkumar Prabhakaran, and Emily Denton. Crowdworksheets: Accounting for individual and collective identities underlying crowdsourced dataset annotation. In _Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency_, pages 2342-2351, 2022.

* [35] Jamie Duncan. Data protection beyond data rights: Governing data production through collective intermediaries. _Internet Policy Review_, 12(3):1-22, 2023.
* [36] European Organization For Nuclear Research and OpenAIRE. Zenodo, 2013.
* [37] Andrea Forte, Vanesa Larco, and Amy Bruckman. Decentralization in wikipedia governance. _Journal of Management Information Systems_, 26(1):49-72, 2009.
* [38] Erin D Foster and Ariel Deardorff. Open science framework (OSF). _Journal of the Medical Library Association: JMLA_, 105(2):203, 2017.
* [39] Christian Garbin, Pranav Rajpurkar, Jeremy Irvin, Matthew P Lungren, and Oge Marques. Structured dataset documentation: a datasheet for CheXpert. _arXiv preprint arXiv:2105.03020_, 2021.
* [40] Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daume Iii, and Kate Crawford. Datasheets for datasets. _Communications of the ACM_, 64(12):86-92, 2021.
* [41] Edd Gent. Public AI Training Datasets Are Rife With Licensing Errors, 2023.
* [42] Saira Ghafur, Jackie Van Dael, Melanie Leis, Ara Darzi, and Aziz Sheikh. Public perceptions on data sharing: key insights from the uk and the usa. _The Lancet Digital Health_, 2(9):e444-e446, 2020.
* [43] Judy Wawira Gichoya, Imon Banerjee, Ananth Reddy Bhimireddy, John L Burns, Leo Anthony Celi, Li-Ching Chen, Ramon Correa, Natalie Dullerud, Marzyeh Ghassemi, Shih-Cheng Huang, et al. AI recognition of patient race in medical imaging: a modelling study. _The Lancet Digital Health_, 4(6):e406-e414, 2022.
* [44] Ary L Goldberger, Luis AN Amaral, Leon Glass, Jeffrey M Hausdorff, Plamen Ch Ivanov, Roger G Mark, Joseph E Mietus, George B Moody, Chung-Kang Peng, and H Eugene Stanley. PhysioBank, PhysioToolkit, and PhysioNet: components of a new research resource for complex physiologic signals. _Circulation_, 101(23):e215-e220, 2000.
* [45] Kalinda E Griffiths, Jessica Blain, Claire M Vajdic, and Louisa Jorm. Indigenous and Tribal Peptides Data Governance in Health Research: A Systematic Review. _International Journal of Environmental Research and Public Health_, 18(19):10318, 2021.
* [46] Paul Groth, Helena Cousijn, Tim Clark, and Carole Goble. FAIR data reuse-the path through data citation. _Data Intelligence_, 2(1-2):78-86, 2020.
* [47] Carlos Hernandez-Perez, Marc Combalia, Sebastian Podlipnik, Noel C. F. Codella, Veronica Rotemberg, Allan C. Halpern, Ofer Reiter, Cristina Carrera, Alicia Barreiro, Brian Helba, Susana Puig, Veronica Vilaplana, and Josep Malvehy. BCN20000: Dermoscopic Lesions in the Wild. _Scientific Data_, 11(1), June 2024.
* [48] Sarah Holland, Ahmed Hosny, Sarah Newman, Joshua Joseph, and Kasia Chmielinski. The dataset nutrition label. _Data Protection and Privacy_, 12(12):1, 2020.
* [49] AD Hoover, Valentina Kouznetsova, and Michael Goldbaum. Locating blood vessels in retinal images by piecewise threshold probing of a matched filter response. _IEEE Transactions on Medical Imaging_, 19(3):203-210, 2000.
* [50] Corey Horien, Stephanie Noble, Abigail S Greene, Kangjoo Lee, Daniel S Barron, Siyuan Gao, David O'Connor, Mehraveh Salehi, Javid Dadashkarimi, Xilin Shen, et al. A hitchhiker's guide to working with large, open-source neuroimaging datasets. _Nature Human Behaviour_, 5(2):185-193, 2021.
* [51] Ben Hutchinson, Andrew Smart, Alex Hanna, Emily Denton, Christina Greer, Oddur Kjartansson, Parker Barnes, and Margaret Mitchell. Towards accountability for machine learning datasets: Practices from software engineering and infrastructure. In _Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency_, pages 560-575, 2021.

* [52] Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Siliviana Ciurea-Ilcus, Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, et al. CheXpert: A large chest radiograph dataset with uncertainty labels and expert comparison. In _AAAI Conference on Artificial Intelligence_, volume 33, pages 590-597, 2019.
* [53] Clifford R Jack Jr, Matt A Bernstein, Nick C Fox, Paul Thompson, Gene Alexander, Danielle Harvey, Bret Borowski, Paula J Britson, Jennifer L. Whitwell, Chadwick Ward, et al. The Alzheimer's disease neuroimaging initiative (ADNI): MRI methods. _Journal of Magnetic Resonance Imaging: An Official Journal of the International Society for Magnetic Resonance in Medicine_, 27(4):685-691, 2008.
* [54] Marijn Janssen, Paul Brous, Elsa Estevez, Luis S. Barbosa, and Tomasz Janowski. Data governance: Organizing data for trustworthy Artificial Intelligence. _Government Information Quarterly_, 37(3):101493, 2020.
* [55] Yacine Jernite, Huu Nguyen, Stella Biderman, Anna Rogers, Mraaim Masoud, Valentin Danchev, Samson Tan, Alexandra Sasha Luccioni, Nishant Subramani, Isaac Johnson, et al. Data governance in the age of large-scale data-driven language technology. In _Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency_, pages 2206-2222, 2022.
* [56] Debesh Jha, Pia H Smedsrud, Michael A Riegler, Pal Halvorsen, Thomas de Lange, Dag Johansen, and Havard D Johansen. Kvasir-seg: A segmented polyp dataset. In _MultiMedia Modeling: 26th International Conference, MMM 2020, Daejeon, South Korea, January 5-8, 2020, Proceedings, Part II 26_, pages 451-462. Springer, 2020.
* A Case Study in Chest X-rays. In _2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI)_, pages 1-5, 2023.
* [58] Alistair EW Johnson, Tom J Pollard, Seth J Berkowitz, Nathaniel R Greenbaum, Matthew P Lungren, Chih-ying Deng, Roger G Mark, and Steven Horng. MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports. _Scientific Data_, 6(1):317, 2019.
* [59] Florian Knoll, Jure Zbontar, Anuroop Sriram, Matthew J Muckley, Mary Bruno, Aaron Defazio, Marc Parente, Krzysztof J Geras, Joe Katsnelson, Hersh Chandarana, et al. fastMRI: A publicly available raw k-space and DICOM dataset of knee images for accelerated MR image reconstruction using machine learning. _Radiology: Artificial Intelligence_, 2(1):e190007, 2020.
* [60] Bernard Koch, Emily Denton, Alex Hanna, and Jacob Gates Foster. Reduced, reused and recycled: The life of a dataset in machine learning research. In _Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)_, 2021.
* [61] Lauren N. Koenig, Gregory S. Day, Amber Salter, Sarah Keefe, Laura M. Marple, Justin Long, Pamela LaMontagne, Parinaz Massoumzadeh, B. Joy Snider, Manasa Kanthamneni, Cyrus A. Raji, Nupur Ghoshal, Brian A. Gordon, Michelle Miller-Thomas, John C. Morris, Joshua S. Shimony, and Tammie L.S. Benzinger. Select Atrophied Regions in Alzheimer disease (SARA): An improved volumetric model for identifying Alzheimer disease dementia. _NeuroImage: Clinical_, 26:102248, 2020.
* [62] Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A Shamma, et al. Visual genome: Connecting language and vision using crowdsourced dense image annotations. _International Journal of Computer Vision_, 123:32-73, 2017.
* [63] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
* [64] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. Natural questions: a benchmark for question answering research. _Transactions of the Association for Computational Linguistics_, 7:453-466, 2019.

* [65] Samuli Laato, Teemu Birskstedt, Matti Maantymaki, Matti Minkkinen, and Tommi Mikkonen. AI governance in the system development life cycle: Insights on responsible machine learning engineering. In _Proceedings of the 1st International Conference on AI Engineering: Software Engineering for AI_, pages 113-123, 2022.
* [66] Pamela J LaMontagne, Tammie LS Benzinger, John C Morris, Sarah Keefe, Russ Hornbeck, Chengjie Xiong, Elizabeth Grant, Jason Hassenstab, Krista Moulder, Andrei G Vlassenko, et al. OASIS-3: longitudinal neuroimaging, clinical, and cognitive dataset for normal aging and Alzheimer disease. _medrxiv_, pages 2019-12, 2019.
* [67] Curtis P Langlotz, Bibb Allen, Bradley J Erickson, Jayashree Kalpathy-Cramer, Keith Bigelow, Tessa S Cook, Adam E Flanders, Matthew P Lungren, David S Mendelson, Jeffrey D Rudie, et al. A Roadmap for Foundational Research on Artificial Intelligence in Medical Imaging: From the 2018 NIH/RSNA/ACR/The Academy Workshop. _Radiology_, 291(3):781-791, 2019.
* [68] Agostina J Larrazabal, Nicolas Nieto, Victoria Peterson, Diego H Milone, and Enzo Ferrante. Gender imbalance in medical imaging datasets produces biased classifiers for computer-aided diagnosis. _Proceedings of the National Academy of Sciences_, 117(23):12592-12594, 2020.
* [69] Susan Leavy, Eugenia Siapera, and Barry O'Sullivan. Ethical Data Curation for AI: An Approach based on Feminist Epistemology and Critical Theories of Race. In _Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society_, pages 695-703, 2021.
* [70] Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. _Proceedings of the IEEE_, 86(11):2278-2324, 1998.
* [71] Karim Lekadir, Aasa Feragen, Abdul Joseph Foranah, Alejandro F Frangi, Alena Buyx, Anais Emelie, Andrea Lara, Antonio R Porras, An-Wen Chan, Arcadi Navarro, et al. FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare. _arXiv preprint arXiv:2309.12325_, 2023.
* [72] Johann Li, Guangming Zhu, Cong Hua, Mingtao Feng, Basheer Bennamoun, Ping Li, Xiaoyuan Lu, Juan Song, Peiyi Shen, Xu Xu, et al. A systematic collection of medical image datasets for deep learning. _ACM Computing Surveys_, 56(5):1-51, 2023.
* [73] Zhang Li, Zheyu Hu, Jiaolong Xu, Tao Tan, Hui Chen, Zhi Duan, Ping Liu, Jun Tang, Guoping Cai, Quchang Ouyang, et al. Computer-aided diagnosis of lung carcinoma using deep learning-a pilot study. _arXiv preprint arXiv:1803.05471_, 2018.
* [74] Zhang Li, Jiehua Zhang, Tao Tan, Xichao Teng, Xiaoliang Sun, Hong Zhao, Lihong Liu, Yang Xiao, Byungjae Lee, Yilong Li, Qianni Zhang, Shujiao Sun, Yushan Zheng, Junyu Yan, Ni Li, Yiyu Hong, Junsu Ko, Hyun Jung, Yanling Liu, Yu-cheng Chen, Ching-wei Wang, Vladimir Yurovskiy, Pavel Maevskikh, Vahid Khanagha, Yi Jiang, Li Yu, Zhihong Liu, Daiqiang Li, Peter J. Schuffler, Qifeng Yu, Hui Chen, Yuling Tang, and Geert Litjens. Deep Learning Methods for Lung Cancer Segmentation in Whole-Slide Histopathology Images--The ACDC@LungHP Challenge 2019. _IEEE Journal of Biomedical and Health Informatics_, 25(2):429-440, 2021.
* [75] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In _Proceedings of International Conference on Computer Vision (ICCV)_, December 2015.
* [76] Shayne Longpre, Robert Mahari, Anthony Chen, Naana Obeng-Marnu, Damien Sileo, William Brannon, Niklas Muennighoff, Nathan Khazam, Jad Kabbara, Kartik Periselta, et al. The data provenance initiative: A large scale audit of dataset licensing & attribution in AI. _arXiv preprint arXiv:2310.16787_, 2023.
* [77] Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. Learning word vectors for sentiment analysis. In _Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies_, pages 142-150, Portland, Oregon, USA, June 2011. Association for Computational Linguistics.
* [78] Daniel S Marcus, Anthony F Fotenos, John G Csernansky, John C Morris, and Randy L Buckner. Open access series of imaging studies: longitudinal mri data in nondemented and demented older adults. _Journal of Cognitive Neuroscience_, 22(12):2677-2684, 2010.

* [79] Daniel S. Marcus, Tracy H. Wang, Jamie Parker, John G. Csernansky, John C. Morris, and Randy L. Buckner. Open Access Series of Imaging Studies (OASIS): Cross-sectional MRI Data in Young, Middle Aged, Nondemented, and Demented Older Adults. _Journal of Cognitive Neuroscience_, 19(9):1498-1507, 09 2007.
* [80] Bjoern H Menze, Andras Jakab, Stefan Bauer, Jayashree Kalpathy-Cramer, Keyvan Farahani, Justin Kirby, Yuliya Burren, Nicole Porz, Johannes Slotboom, Roland Wiest, et al. The multimodal brain tumor image segmentation benchmark (BRATS). _IEEE Transactions on Medical Imaging_, 34(10):1993-2024, 2014.
* [81] Suranna R Monah, Matthias W Wagner, Asthik Biswas, Farzad Khalvati, Lauren E Erdman, Afsaneh Amirabadi, Logi Vidarsson, Melissa D McCradden, and Birgit B Ertl-Wagner. Data governance functions to support responsible data stewardship in pediatric radiology research studies using artificial intelligence. _Pediatric Radiology_, 52(11):2111-2119, 2022.
* [82] Ines C. Moreira, Igor Amaral, Ines Domingues, Antonio Cardoso, Maria Joao Cardoso, and Jaime S. Cardoso. INbreast. _Academic Radiology_, 19(2):236-248, feb 2012.
* [83] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y. Ng. Reading digits in natural images with unsupervised feature learning. In _NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011_, 2011.
* [84] Guiomar Niso, Rotem Botvinik-Nezer, Stefan Appelhoff, Alejandro De La Vega, Oscar Esteban, Joseet A Etzel, Karolina Finc, Melanie Ganz, Remi Gau, Yaroslav O Halchenko, et al. Open and reproducible neuroimaging: from study inception to publication. _NeuroImage_, 263:119623, 2022.
* [85] Lauren Oakden-Rayner. Exploring large-scale public medical image datasets. _Academic Radiology_, 27(1):106-112, 2020.
* [86] Lauren Oakden-Rayner, Jared Dunnmon, Gustavo Carneiro, and Christopher Re. Hidden stratification causes clinically meaningful failures in machine learning for medical imaging. In _ACM Conference on Health, Inference, and Learning_, pages 151-159, 2020.
* [87] Elinor Ostrom. _Governing the commons: The evolution of institutions for collective action_. Cambridge University Press, 1990.
* [88] Andre GC Pacheco, Gustavo R Lima, Amanda S Salomao, Breno Krohling, Igor P Biral, Gabriel G de Angelo, Fabio CR Alves Jr, Jose GM Esgario, Alana C Simora, Pedro BC Castro, et al. PAD-UFES-20: A skin lesion dataset composed of patient data and clinical images collected from smartphones. _Data in Brief_, 32:106221, 2020.
* [89] Kenneth Peng, Arunesh Mathur, and Arvind Narayanan. Mitigating dataset harms requires stewardship: Lessons from 1000 papers. In J. Vanschoren and S. Yeung, editors, _Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks_, volume 1, 2021.
* [90] Esther Plomp, Nicolas Dintzner, Marta Teperek, and Alastair Dunning. Cultural obstacles to research data management and sharing at TU Delft. _Insights_, 32(1), 2019.
* [91] Russell A Poldrack and Krzysztof J Gorgolewski. Making big data open: data sharing in neuroimaging. _Nature neuroscience_, 17(11):1510-1517, 2014.
* [92] Jean-Baptiste Poline, Janis L Breeze, Satrajit Ghosh, Krzysztof Gorgolewski, Yaroslav O Halchenko, Michael Hanke, Christian Haselgrove, Karl G Helmer, David B Keator, Daniel S Marcus, et al. Data sharing in neuroimaging research. _Frontiers in Neuroinformatics_, 6:9, 2012.
* [93] Nadya Putrova and Gijs van Maanen. Data as an economic good, data as a commons, and data governance. _Law, Innovation and Technology_, pages 1-42, 2023.
* [94] Mahima Pushkarna, Andrew Zaldivar, and Oddur Kjartansson. Data cards: Purposeful and transparent dataset documentation for responsible AI. In _Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency_, pages 1776-1826, 2022.

* [95] Pranav Rajpurkar, Emma Chen, Oishi Banerjee, and Eric J Topol. AI in health and medicine. _Nature Medicine_, 28(1):31-38, 2022.
* [96] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad: 100,000+ questions for machine comprehension of text. _arXiv preprint arXiv:1606.05250_, 2016.
* [97] Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, Holger R Roth, Shadi Albarqouni, Spyridon Bakas, Mathieu N Galtier, Bennett A Landman, Klaus Maier-Hein, et al. The future of digital health with federated learning. _NPJ digital medicine_, 3(1):1-7, 2020.
* [98] Anna Rogers, Timothy Baldwin, and Kobi Leins. 'Just What do You Think You're Doing, Dave?' A Checklist for Responsible Data Use in NLP. In _Findings of the Association for Computational Linguistics: EMNLP 2021_, pages 4821-4833, Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics.
* [99] Anna Rogers, Marzena Karpinska, Jordan Boyd-Graber, and Naoaki Okazaki. Program Chairs' Report on Peer Review at ACL 2023. In _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages xl-lxxv, Toronto, Canada, July 2023. Association for Computational Linguistics.
* [100] Dewinda J Rumala. How You Split Matters: Data Leakage and Subject Characteristics Studies in Longitudinal Brain MRI Analysis. In _Workshop on Clinical Image-Based Procedures_, pages 235-245. Springer, 2023.
* [101] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. ImageNet Large Scale Visual Recognition Challenge. _International Journal of Computer Vision_, 115(3):211-252, 2015.
* [102] Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh, and Lora M Aroyo. "Everyone wants to do the model work, not the data work": Data Cascades in High-Stakes AI. In _Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems_, CHI '21, New York, NY, USA, 2021. Association for Computing Machinery.
* [103] Kenneth F Schulz, Douglas G Altman, and David Moher. CONSORT 2010 statement: updated guidelines for reporting parallel group randomised trials. _Journal of Pharmacology and Pharmacotherapeutics_, 1(2):100-107, 2010.
* [104] Candice Schumann, Susanna Ricco, Utsav Prabhu, Vittorio Ferrari, and Caroline Pantofaru. A step toward more inclusive people annotations for fairness. In _Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society_, pages 916-925, 2021.
* [105] Arnaud Arindra Adiyoso Setio, Alberto Traverso, Thomas De Bel, Moira SN Berens, Cas Van Den Bogaard, Piergiorgio Cerello, Hao Chen, Qi Dou, Maria Evelina Fantacci, Bram Geurts, et al. Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: the LUNA16 challenge. _Medical Image Analysis_, 42:1-13, 2017.
* [106] Laleh Seyyed-Kalantari, Guanxiong Liu, Matthew McDermott, Irene Y Chen, and Marzyeh Ghassemi. CheXclusion: Fairness gaps in deep chest X-ray classifiers. In _Pacific Symposium on Biocomputing_, pages 232-243. World Scientific, 2020.
* [107] Attila Simko, Anders Garpehring, Joakim Jonsson, Tufve Nyholm, and Tommy Lofstedt. Reproducibility of the methods in medical imaging with deep learning. In _Medical Imaging with Deep Learning_, pages 95-106. PMLR, 2024.
* [108] Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In _Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing_, pages 1631-1642, 2013.

* [109] Theo Sourget, Ahmet Akkoc, Stinna Winther, Christine Lyngbye Galsgaard, Amelia Jimenez-Sanchez, Dovile Juodelyte, Caroline Petitjean, and Veronika Cheplygina. [Citation needed] data usage and citation practices in medical imaging conferences. In _Medical Imaging with Deep Learning (MIDL), in press_, 2024.
* [110] Joes Staal, Michael D Abramoff, Meindert Niemeijer, Max A Viergever, and Bram Van Ginneken. Ridge-based vessel segmentation in color images of the retina. _IEEE Transactions on Medical Imaging_, 23(4):501-509, 2004.
* A public-interest framework for B2G data sharing in the Data Act, 2022.
* [112] Rachel Thomas and David Uminsky. The problem with metrics is a fundamental problem for AI. _arXiv preprint arXiv:2002.08512_, 2020.
* [113] Philipp Tschandl, Cliff Rosendahl, and Harald Kittler. The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. _Scientific data_, 5(1):1-9, 2018.
* [114] John Darrell Van Horn and Arthur W Toga. Human neuroimaging as a "big data" science. _Brain Imaging and Behavior_, 8:323-331, 2014.
* [115] Gael Varoquaux and Veronika Cheplygina. Machine learning for medical imaging: methodological failures and recommendations for the future. _Nature Digital Medicine_, 5(1):1-8, 2022.
* [116] Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie. The Caltech-UCSD Birds-200-2011 dataset. 2011.
* [117] Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding. _arXiv preprint arXiv:1804.07461_, 2018.
* [118] Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, and Ronald M Summers. Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases. In _Computer Vision and Pattern Recognition_, pages 2097-2106, 2017.
* [119] David Wen, Saad M Khan, Antonio Ji Xu, Hussein Ibrahim, Luke Smith, Jose Caballero, Luis Zepeda, Carlos de Blas Perez, Alastair K Denniston, Xiaoxuan Liu, et al. Characteristics of publicly available skin cancer image datasets: a systematic review. _The Lancet Digital Health_, 4(1):e64-e74, 2022.
* [120] Steven Euijong Whang, Yuji Roh, Hwanjun Song, and Jae-Gil Lee. Data Collection and Quality Challenges in Deep Learning: A Data-Centric AI Perspective. _The VLDB Journal_, 32(4):791-813, 2023.
* [121] Tonya White, Elisabet Blok, and Vince D Calhoun. Data sharing and privacy issues in neuroimaging research: Opportunities, obstacles, challenges, and monsters under the bed. _Human Brain Mapping_, 43(1):278-291, 2022.
* [122] Mark D Wilkinson, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, Jan-Willem Boiten, Luiz Bonino da Silva Santos, Philip E Bourne, et al. The FAIR Guiding Principles for scientific data management and stewardship. _Scientific data_, 3(1):1-9, 2016.
* [123] Martin J Willemink, Wojciech A Koszek, Cailin Hardell, Jie Wu, Dominik Fleischmann, Hugh Harvey, Les R Folio, Ronald M Summers, Daniel L Rubin, and Matthew P Lungren. Preparing medical imaging data for machine learning. _Radiology_, 295(1):4-15, 2020.
* [124] Adina Williams, Nikita Nangia, and Samuel Bowman. A broad-coverage challenge corpus for sentence understanding through inference. In _Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)_, pages 1112-1122. Association for Computational Linguistics, 2018.

* [125] Julia K Winkler, Christine Fink, Ferdinand Toberer, Alexander Enk, Teresa Deinlein, Rainer Hofmann-Wellenhof, Luc Thomas, Aimilios Lallas, Andreas Blum, Wilhelm Stolz, et al. Association Between Surgical Skin Markings in Dermoscopic Images and Diagnostic Performance of a Deep Learning Convolutional Neural Network for Melanoma Recognition. _JAMA Dermatology_, 155(10):1135-1141, 2019.
* [126] Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. _arXiv preprint arXiv:1708.07747_, 2017.
* [127] Jiancheng Yang, Rui Shi, and Bingbing Ni. MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis. In _2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)_, pages 191-195, 2021.
* A large-scale lightweight benchmark for 2D and 3D biomedical image classification. _Scientific Data_, 10(1):41, 2023.
* [129] Xinyu Yang, Weixin Liang, and James Zou. Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on HuggingFace. In _The Twelfth International Conference on Learning Representations_, 2024.
* [130] Hubert Dariusz Zajac, Natalia Rozalia Avlona, Finn Kensing, Tariq Osman Andersen, and Irina Shklovski. Ground Truth Or Dare: Factors Affecting The Creation Of Medical Datasets For Training AI. In _Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society_, pages 351-362, 2023.
* [131] Dora Zhao, Angelina Wang, and Olga Russakovsky. Understanding and evaluating racial biases in image captioning. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 14830-14840, 2021.
* [132] Bolei Zhou, Agata Lapedriza, Jianxiong Xiao, Antonio Torralba, and Aude Oliva. Learning deep features for scene recognition using places database. _Advances in Neural Information Processing Systems_, 27, 2014.
* [133] S. Kevin Zhou, Hayit Greenspan, Christos Davatzikos, James S. Duncan, Bram Van Ginneken, Anant Madabhushi, Jerry L. Prince, Daniel Rueckert, and Ronald M. Summers. A Review of Deep Learning in Medical Imaging: Imaging Traits, Technology Trends, Case Studies With Progress Highlights, and Future Promises. _Proceedings of the IEEE_, 109(5):820-838, 2021.

## Checklist

1. For all authors... 1. Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes] 2. Did you describe the limitations of your work? [Yes] See Section 4. 3. Did you discuss any potential negative societal impacts of your work? [Yes] See Section 4. 4. Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes]
2. If you are including theoretical results... 1. Did you state the full set of assumptions of all theoretical results? [N/A] 2. Did you include complete proofs of all theoretical results? [N/A]
3. If you ran experiments (e.g. for benchmarks)... 1. Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [N/A] We do not include code because we don't develop any method. We justify the choice of the analyzed datasets. 2. Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [N/A] We do not train any model. 3. Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [N/A] We do not report model evaluation. 4. Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [N/A] We do not train any model.
4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets... 1. If your work uses existing assets, did you cite the creators? [Yes] We cite the dataset creators, as well as data documentation practices. 2. Did you mention the license of the assets? [Yes] See Table 1. 3. Did you include any new assets either in the supplemental material or as a URL? [No] 4. Did you discuss whether and how consent was obtained from people whose data you're using/curating? [Yes] We investigate publicly available datasets, thus, we did not explicitly contact the creators. We mention in Section 4 that we did not contact the analyzed CCPs: HuggingFace and Kaggle. 5. Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [Yes] We discuss that medical imaging datasets are anonymized by clinicians before being shared or made publicly available. We ourselves only analyze documentation and metadata about all the datasets.
5. If you used crowdsourcing or conducted research with human subjects... 1. Did you include the full text of instructions given to participants and screenshots, if applicable? [N/A] We did not do crowdsourcing. 2. Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [N/A] 3. Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A]Supplementary Material

### Data Cards

Table 2 shows the extracted documentation parameters from Kaggle and HuggingFace, which we categorized according to Datasheets [40].

On **HuggingFace**, we find information about the annotation creators (_e.g._, crowdsource, experts, ml-generated) or specific task categories (_e.g._, image-classification, image-to-text, text-to-image). Such parameters can be used to filter results when searching on HuggingFace, potentially enabling systematic analysis of a specific task or tag.

On **Kaggle**, we notice that some important parameters shown in the dataset website such as _temporal and geospatial coverage_, _data collection methodology_, _provenance_, _DOI citation_, and _update frequency_ cannot be automatically extracted with their API, so we manually included them.

Kaggle automatically computes a _usability score_, which is associated with the tag "well-documented", and used for ranking results when searching for a dataset. Kaggle's _usability score_ is based on:

* Completeness: _subtitle_, _tag_, _description_, _cover image_.
* Credibility: _provenance_, _public notebook_, _update frequency_.
* Compatibility: _license_, _file format_, _file description_, _column description_.

The _usability score_ is based on only 4 out of 7 aspects from Datasheets [40].

### Duplicates on Kaggle

We automatically retrieve all the duplicates for the top-10 listed MI datasets on Kaggle, as well as some popular datasets (suggested by the reviewers). In Table 3, we show the number of duplicates on Kaggle, the size of the original dataset, the cumulative size of the duplicates, and information about the license and description on Kaggle for the duplicates. We query the name of each dataset as shown in Table 3, except for DRIVE and NIH-CXR14. For NIH-CXR14, we use "nih chest x-ray" as query. When querying "DRIVE" (not case-sensitive) we got over 1800 datasets related to cars, Formula One, and similar topics. To refine results, we applied a case-sensitive filter, retaining only those with capitalized "DRIVE". We also queried Kaggle using "drive retina" and found 13 datasets, of which only 5 were new when compared to our filtered query. Combining the two set of results, we identified 41 duplicates.

\begin{table}
\begin{tabular}{l|l|l}  & Kaggle & HuggingFace \\ \hline \multirow{2}{*}{Motivation} & _issemane_ & _username_ \\  & _dataset name_ & _dataset name_ \\  & _description_ & _description_ \\ \hline \multirow{4}{*}{Composition} & _temporal coverage_ & _sive categories:_\(n<1K,1K<n<10k,1M<n<10M\) \\  & _geospatial coverage_ & _language_, en. s.h., air, j.m.,... \\  & _dataset name_ & _dataset name_ \\  & & _data replica_, training, validation \\  & _region_ & \\  & _version_ & \\ \hline \multirow{2}{*}{Collection} & _data collection method_ & _source dataset_: wikipedia... \\  & _provenance_ & _annotation creative_: crowdsourced, found, expert-generated, machine-generated,... \\ \hline \multirow{2}{*}{Preprocessing cleaning / labeling} & & \\ \hline Uses & & _task_, _categories_: image-classification, image-to-text, question-answering \\  & & _task_, _idr_: multi-class-image-classification, extractiv-api... \\ \hline \multirow{2}{*}{Distribution} & _license_: cc, gpl, open data commons,... & _license_: apende-2.0, mitt, opermail, cc,... \\  & _DOI citation_ & _location_ \\ \hline Maintenance & _update frequency_: weekly, never, not specified,... \\ \hline \hline \multirow{4}{*}{Other} & _Levevends_ & _agg_ \\  & _number of views_ & _number of links_ \\  & _number of downloads_ & _number of downloads_ \\  & _number of votes_ & _arXiv_ \\ \end{tabular}
\end{table}
Table 2: Documentation parameters extracted from Kaggle and HuggingFace categorized according to Datasheets [40], except the last rows (Other). We represent in italic the extracted parameter, and show examples values for them. We include _description_ in Motivation, although we find that this parameter can contain any type of dataset information.

[MISSING_PAGE_FAIL:22]