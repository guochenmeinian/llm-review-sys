# Realizable \(\mathcal{H}\)-Consistent and Bayes-Consistent

Loss Functions for Learning to Defer

 Anqi Mao

Courant Institute

New York, NY 10012

aqmao@cims.nyu.edu &Mehrvar Mohri

Google Research & CIMS

New York, NY 10011

mohri@google.com &Yutao Zhong

Courant Institute

New York, NY 10012

yutao@cims.nyu.edu

###### Abstract

We present a comprehensive study of surrogate loss functions for learning to defer. We introduce a broad family of surrogate losses, parameterized by a non-increasing function \(\Psi\), and establish their realizable \(\mathcal{H}\)-consistency under mild conditions. For cost functions based on classification error, we further show that these loss functions admit \(\mathcal{H}\)-consistency bounds when the hypothesis set is symmetric and complete, a property satisfied by common neural network and linear function hypothesis sets. Our results also resolve an open question raised in previous work [11] by proving the realizable \(\mathcal{H}\)-consistency and Bayes-consistency of a specific surrogate loss. Furthermore, we identify choices of \(\Psi\) that lead to \(\mathcal{H}\)-consistent surrogate losses for _any general cost function_, thus achieving Bayes-consistency, realizable \(\mathcal{H}\)-consistency, and \(\mathcal{H}\)-consistency bounds _simultaneously_. We also investigate the relationship between \(\mathcal{H}\)-consistency bounds and realizable \(\mathcal{H}\)-consistency in learning to defer, highlighting key differences from standard classification. Finally, we empirically evaluate our proposed surrogate losses and compare them with existing baselines.

## 1 Introduction

In many practical scenarios, combining expert insights with established models can yield significant enhancements. These experts can be human domain specialists or more complex, albeit resource-intensive, models. For example, modern language and dialogue models are prone to producing _hallucinations_ or inaccurate information. The quality of their responses can be significantly enhanced by delegating uncertain predictions to more specialized or advanced pre-trained models. This problem is particularly crucial for large language models (LLMs), as noted in [23, 24]. The same principle applies to other generative systems, like those for images or videos, and to learning models in diverse applications such as image classification, annotation, and speech recognition. Thus, the task of _learning to defer_ (L2D) with experts has become increasingly critical across a wide array of applications.

Directly optimizing the deferral loss function, which is the target loss in L2D, is computationally intractable for many choices of the hypothesis set. Therefore, a common approach is to optimize a surrogate loss that facilitates the optimization of the deferral loss function. Recent work in L2D has proposed several surrogate losses [11, 25, 12, 13] and studied their consistency guarantees, including Bayes-consistency, realizable \(\mathcal{H}\)-consistency, and \(\mathcal{H}\)-consistency bounds (see definitions in Section 3.2). In particular, Mozannar and Sontag [24] proposed the first Bayes-consistent surrogate loss by generalizing the cross-entropy loss for L2D. Verma and Nalisnick [20] proposed an alternative Bayes-consistent surrogate loss by generalizing the one-versus-all loss for L2D. Mozannar et al. [24] showed that these surrogate losses are not realizable \(\mathcal{H}\)-consistent. They proposed an alternative surrogate lossthat is realizable \(\mathcal{H}\)-consistent, but they were unable to prove or disprove whether the proposed surrogate loss is Bayes-consistent. All the surrogate losses mentioned above and their consistency guarantees hold only for cost functions based on classification error. Mao et al. (2024) generalized the surrogate loss in (Mozannar and Sontag, 2020) to incorporate general cost functions and any multi-class surrogate losses. They provided \(\mathcal{H}\)-consistency bounds for the novel family of surrogate losses, offering a stronger guarantee than Bayes-consistency.

However, none of these surrogate losses satisfies all these guarantees simultaneously. In particular, a recent AISTATS notable award paper by Mozannar et al. (2023) left open the problem of finding surrogate losses that are both Bayes-consistent and realizable \(\mathcal{H}\)-consistent when the cost function for the expert is its classification error. The problem becomes even more challenging when considering more general and realistic cost functions.

We present a comprehensive analysis of surrogate loss functions for L2D. Our contributions address the limitations of previous approaches and provide a unified framework for designing surrogate losses with strong theoretical guarantees. In Section 4, we first introduce a broad family of surrogate losses for L2D, derived from first principles (Section 4.1). This family is parameterized by a non-increasing function \(\Psi\), which provides some flexibility in tailoring the loss function to specific requirements. We establish that under mild conditions on \(\Psi\), these surrogate losses achieve realizable \(\mathcal{H}\)-consistency, a key guarantee for many applications (Section 4.2).

Next, for cost functions based on classification error, we further establish that our surrogate loss functions admit \(\mathcal{H}\)-consistency bounds when the hypothesis set is symmetric and complete (Section 4.3). This result holds for commonly used neural network and linear function hypothesis sets, further strengthening the applicability of our results. Additionally, our results resolve an open question raised by Mozannar et al. (2023) by proving the realizable \(\mathcal{H}\)-consistency and Bayes-consistency of their proposed surrogate loss, which the authors had left as an open question (Section 4.4).

In Section 4.3, we further identify specific choices of \(\Psi\), such as the one corresponding to the mean absolute error loss, that lead to \(\mathcal{H}\)-consistent surrogate losses for _any general cost function_. These loss functions are adapted to general cost functions and benefit from Bayes-consistency (Section 4.4), realizable \(\mathcal{H}\)-consistency, and \(\mathcal{H}\)-consistency bounds _simultaneously_.

In Section 5, we also study the relationship between \(\mathcal{H}\)-consistency bounds and realizable \(\mathcal{H}\)-consistency in the context of L2D, highlighting key distinctions from the standard classification setting. Finally, we further report the results of experiments with our new surrogate losses and their comparison with the baselines in different settings (Section 6).

We discuss the related work in Section 2 and then begin with the preliminaries in Section 3.

## 2 Related work

The approach of _single-stage learning to defer_, where a predictor and a deferral function are trained together, was pioneered by Cortes, DeSalvo, and Mohri (2016, 2016, 2023) and further developed in subsequent studies on abstention, where the cost is constant (Chaoenphakdee et al., 2021; Cao et al., 2022; Li et al., 2023; Cheng et al., 2023; Mao et al., 2024, 2024) and on deferral, where the cost can vary depending on the instance and the label (Mozannar and Sontag, 2020; Verma and Nalisnick, 2022; Mozannar et al., 2023; Verma et al., 2023; Cao et al., 2023; Mao et al., 2023; Mao et al., 2023; Mao et al., 2024). In this approach, the deferral function determines whether to defer to an expert for each input. This approach has been shown to be superior to _confidence-based_ approaches, where the decision to abstain or defer is based solely on the magnitude of the predictor's value (Chow, 1957, 1970; Bartlett and Wegkamp, 2008; Yuan and Wegkamp, 2010, 2011; Ramaswamy et al., 2018; Ni et al., 2019; Jitkrittum et al., 2023); and to _selective classification_ approaches, where the selection rate is fixed and a cost function modeled by an expert cannot be taken into account (El-Yaniv et al., 2010; El-Yaniv and Wiener, 2012; Wiener and El-Yaniv, 2011, 2012, 2015; Geifman and El-Yaniv, 2017, 2019; Acar et al., 2020; Gangrade et al., 2021; Zaoui et al., 2020; Jiang et al., 2020; Shah et al., 2022).

Madras et al. (2018) initiated the _learning to defer_ (L2D) problem scenario, which integrates human expert decisions into the cost function. This approach has been further explored in subsequent studies (Raghu et al., 2019; Wilder et al., 2021; Pradier et al., 2021). Mozannar and Sontag (2020) introduced the first Bayes-consistent surrogate loss for L2D, which was further refined in (Raman and Yee, 2021; Liu et al., 2022). Verma and Nalisnick (2022) proposed an alternative Bayes-consistent surrogate loss,the one-versus-all loss, which was later examined within a broader family of loss functions (Charusaie et al., 2022). Cao et al. (2023) proposed an asymmetric softmax function, which can induce a valid probability estimator for learning to defer. Mozannar et al. (2023) showed that the surrogate losses in (Mozannar and Sontag, 2020, Verma and Nalisnick, 2022) are not realizable \(\mathcal{H}\)-consistent. They proposed an alternative surrogate loss that is realizable \(\mathcal{H}\)-consistent, but they were unable to prove or disprove whether the proposed surrogate loss is Bayes-consistent. All the surrogate losses mentioned above and their consistency guarantees hold only for cost functions based on classification error. Mao et al. (2024) generalized the surrogate loss in (Mozannar and Sontag, 2020) to incorporate general cost functions and any multi-class surrogate losses. They provided \(\mathcal{H}\)-consistency bounds for the novel family of surrogate losses, offering a stronger guarantee than Bayes-consistency.

Additional studies have focused on post-hoc methods, with Okati et al. (2021) suggesting an alternative optimization technique between the predictor and rejector, and Narasimhan et al. (2022) offering corrections for underfitting surrogate losses (Liu et al., 2024), and Charusaie and Samadi (2024) providing a unifying post-processing framework for multi-objective L2D based on a generalization of the Neyman-Pearson Lemma (Neyman and Pearson, 1933). The L2D framework or variations thereof have found applications in diverse scenarios, spanning regression, reinforcement learning, and human-in-the-loop systems, among others (De et al., 2020, 2021, Straitouri et al., 2021, Zhao et al., 2021, Joshi et al., 2021, Gao et al., 2021, Mozannar et al., 2022, Hemmer et al., 2023, Chen et al., 2024, Palomba et al., 2024). More recently, the problem of _learning to defer with multiple experts_ has been analyzed in several publications (Hemmer et al., 2022, Keswani et al., 2021, Kerrigan et al., 2021, Straitouri et al., 2022, Benz and Rodriguez, 2022, Verma et al., 2023, Mao et al., 2023, 2024a,g, Tailor et al., 2024). Meanwhile, Mao et al. (2023) also proposed a _two-stage learning to defer_ framework. They introduced two-stage surrogate losses that are both Bayes-consistent and realizable \(\mathcal{H}\)-consistent with constant costs. However, realizable \(\mathcal{H}\)-consistency does not hold for cost functions based on classification error. As with (Mozannar and Sontag, 2020, Verma and Nalisnick, 2022, Mozannar et al., 2023), our work focuses on the single-stage and single-expert setting, and we plan to explore a similar approach in a multi-expert/two-stage setting in the future.

## 3 Preliminaries

We start with the definitions and notations used in the learning-to-defer scenario considered in this paper. We will then introduce consistency guarantees, including _Bayes consistency_, _Realizable \(\mathcal{H}\)-consistency_, and \(\mathcal{H}\)-_consistency bounds_. Finally, we will review existing consistent surrogate losses for L2D.

### Learning to defer: problem setup

Let \(\mathcal{X}\) be an input space and \(\mathcal{Y}=[n]:=\{1,\ldots,n\}\) be the label space in the standard multi-class classification setting. We study the _learning to defer_ (L2D) scenario, where a learner can either predict a label from \(\mathcal{Y}\) or defer to an expert.

To model this, we introduce an augmented label space \(\overline{\mathcal{Y}}=\{1,\ldots,n,n+1\}\), where the label \(n+1\) corresponds to deferral. An expert is a fixed predictor \(g\colon\mathcal{X}\times\mathcal{Y}\to\mathbb{R}\). The goal of L2D is to select a predictor \(h\) out of a hypothesis set \(\mathcal{H}\) of functions mapping from \(\mathcal{X}\times\overline{\mathcal{Y}}\) to \(\mathbb{R}\) with small expected _deferral loss_. Let \(\mathsf{h}(x)\) denote the prediction of \(h\) on input \(x\in\mathcal{X}\), defined as \(\mathsf{h}(x)=\operatorname*{argmax}_{y\overline{\mathcal{Y}}}h(x,y)\), that is the label in the augmented label space \(\overline{\mathcal{Y}}\) with the highest score, with an arbitrary but fixed deterministic strategy for breaking ties. Then, the _deferral loss function_\(\mathsf{L}_{\mathrm{def}}\) is defined as follows:

\[\forall(x,y)\in\mathcal{X}\times\mathcal{Y},\quad\mathsf{L}_{\mathrm{def}}(h,x,y)=\mathsf{1}_{\mathsf{h}(x)*y}\mathsf{1}_{\mathsf{h}(x)\in[n]}+c(x,y)\mathsf{ 1}_{\mathsf{h}(x)=n+1},\]

where \(c(x,y)\) is the the cost of deferring on input \(x\) with true label \(y\). If the deferral option is selected, that is \(\mathsf{h}(x)=n+1\), the deferral cost \(c(x,y)\) is incurred. Otherwise, the prediction of \(h\) is within the standard label space, \(\mathsf{h}(x)\in[n]\), and the loss incurred coincides with the standard zero-one classification loss, \(\mathsf{1}_{\mathsf{h}(x)*y}\).

The choice of the cost function \(c\) is flexible. For example, the cost can be defined as the expert's classification error: \(c(x,y)=\mathsf{1}_{\mathsf{g}(x)*y}\), as in previous work (Mozannar and Sontag, 2020, Verma and Nalisnick, 2022, Mozannar et al., 2023). Here, \(\mathsf{g}(x)=\operatorname*{argmax}_{y\in[n]}g(x,y)\) is the prediction made by the expert \(g\). More generally, it can incorporate the inference cost for the expert (Mao et al., 2024a): \(c(x,y)=\alpha\mathsf{1}_{\mathsf{g}(x)\ast y}+\beta\), with \(\alpha,\beta>0\). We assume, without loss of generality, that the cost is bounded by 1: \(0\leq c(x,y)\leq 1\), which can be achieved through normalization in practice.

### Consistency guarantees

Directly optimizing the deferral loss function, which is the target loss in L2D, is generally computationally intractable for complex hypothesis sets \(\mathcal{H}\). Therefore, a common approach is to optimize a surrogate loss that facilitates the optimization of the deferral loss function. A natural learning guarantee for such surrogate losses is _Bayes-consistency_(Zhang, 2004; Bartlett et al., 2006; Zhang, 2004b; Tewari and Bartlett, 2007; Steinwart, 2007):

**Definition 3.1** (Bayes-consistency).: A surrogate loss \(\mathsf{L}\) is Bayes-consistent with respect to \(\mathsf{L}_{\mathrm{def}}\), if minimizing the surrogate loss over the family of all measurable functions leads to the minimization of the deferral loss:

\[\lim_{n\to+\infty}\mathcal{E}_{\mathsf{L}}(h_{n})-\mathcal{E}_{\mathsf{L}}^{ \ast}(\mathcal{H}_{\mathrm{all}})=0\implies\lim_{n\to+\infty}\mathcal{E}_{ \mathsf{L}_{\mathrm{def}}}(h_{n})-\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}^{ \ast}(\mathcal{H}_{\mathrm{all}})=0.\]

Here, given a distribution \(\mathcal{D}\) over \(\mathcal{X}\times\mathcal{Y}\) and a loss function \(\mathsf{L}\colon\mathcal{H}\times\mathcal{X}\times\mathcal{Y}\to\mathbb{R}\), we denote by \(\mathcal{E}_{\mathsf{L}}(h)\) the _generalization error_ of a hypothesis \(h\in\mathcal{H}\), \(\mathcal{E}_{\mathsf{L}}(h)=\mathbb{E}_{(x,y)\sim\mathcal{D}}[\mathsf{L}(h,x,y)]\), and by \(\mathcal{E}_{\mathsf{L}}^{\ast}(\mathcal{H})\) the _best-in-class generalization error_, \(\mathcal{E}_{\mathsf{L}}^{\ast}(\mathcal{H})=\inf_{h\in\mathcal{H}}\mathcal{E} _{\mathsf{L}}(h)\). Bayes-consistency assumes that the optimization occurs over the family of all measurable functions, \(\mathcal{H}_{\mathrm{all}}\). However, in practice, the hypothesis set of interest is typically a restricted one, such as a family of neural networks. Therefore, a hypothesis-dependent learning guarantee, such as \(\mathcal{H}\)_-consistency bounds_(Awasthi et al., 2022a,b)(see also (Awasthi et al., 2021a,b, 2023; Mao et al., 2023; Mao et al., 2023; Mao et al., 2023; Mao et al., 2023; Mao et al., 2023; Mao et al., 2024; LeCun et al., 2024; LeCun et al., 2024)) and _realizable \(\mathcal{H}\)-consistency_(Long and Servedio, 2013; Zhang and Agarwal, 2020), is more informative and relevant. Realizable \(\mathcal{H}\)-consistency, defined as follows, requires that a minimizer of the surrogate loss over the given hypothesis set \(\mathcal{H}\) also minimizes the target loss, provided that the underlying distribution is realizable.

**Definition 3.2** (Realizable \(\mathcal{H}\)-consistency).: A surrogate loss \(\mathsf{L}\) is realizable \(\mathcal{H}\)-consistent with respect to \(\mathsf{L}_{\mathrm{def}}\), if for any distribution over which there exists a predictor \(h^{\ast}\in\mathcal{H}\) achieving zero deferral loss, \(\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h^{\ast})=0\), minimizing the surrogate loss also leads to a zero-error solution:

\[\hat{h}\in\operatorname*{argmin}_{h\in\mathcal{H}\times}\mathcal{E}_{\mathsf{ L}}(h)\implies\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(\hat{h})=0.\]

Note that realizable \(\mathcal{H}\)-consistency does not imply Bayes-consistency, even if we set \(\mathcal{H}=\mathcal{H}_{\mathrm{all}}\) in Definition 3.2, since Bayes-consistency requires that the relationship holds for all distributions, not just realizable ones. \(\mathcal{H}\)_-consistency bounds_, on the other hand, always imply Bayes-consistency. Given a hypothesis set \(\mathcal{H}\), a surrogate loss \(\mathsf{L}\) admits an _\(\mathcal{H}\)-consistency bound_, if for some non-decreasing concave function \(\mathsf{\Gamma}\colon\mathbb{R}_{+}\to\mathbb{R}_{+}\) with \(\mathsf{\Gamma}(0)=0\), a bound of the following form holds for any hypothesis \(h\in\mathcal{H}\) and any distribution:

\[\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{ def}}}^{\ast}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{def}}}( \mathcal{H})\leq\mathsf{\Gamma}(\mathcal{E}_{\mathsf{L}}(h)-\mathcal{E}_{ \mathsf{L}}^{\ast}(\mathcal{H})+\mathcal{M}_{\mathsf{L}}(\mathcal{H})),\] (1)

where \(\mathcal{M}_{\mathsf{L}}(\mathcal{H})\) is _the minimizability gap_, defined as the difference between the best-in-class generalization error and the expected pointwise infimum loss: \(\mathcal{M}_{\mathsf{L}}(\mathcal{H})=\mathcal{E}_{\mathsf{L}}^{\ast}( \mathcal{H})-\mathbb{E}_{x}\big{[}\inf_{h\in\mathcal{H}\times}\mathbb{E}_{y|x }[\mathsf{L}(h,x,y)]\big{]}\). The minimizability gap can be upper-bounded by the approximation error and vanishes when \(\mathcal{H}=\mathcal{H}_{\mathrm{all}}\)(Awasthi et al., 2022a,b). Thus, an \(\mathcal{H}\)-consistency bound implies Bayes-consistency. The relationship between the two hypothesis-dependent learning guarantees--realizable \(\mathcal{H}\)-consistency and \(\mathcal{H}\)-consistency bounds--depends on the target loss adopted in the specific learning scenario. In Section 5, we will demonstrate that in the standard multi-class classification setting, an \(\mathcal{H}\)-consistency bound is a stronger notion than realizable \(\mathcal{H}\)-consistency. However, in L2D, these guarantees do not imply one another.

### Existing surrogate losses

Here, we will review several consistent surrogate losses used in L2D. For convenience, we use \(\widetilde{c}(x,y)=\mathsf{1}_{\mathsf{g}(x)\ast y}\) to denote the cost when it specifically represents the expert's classification error, and use \(c(x,y)\) when it represents a general cost function.

Mozannar and Sontag (2020) proposed the first Bayes-consistent surrogate loss by generalizing the cross-entropy loss for L2D, with cost functions based on classification error, which is defined as

\[\mathsf{L}_{\mathrm{CE}}(h,x,y)=-\log\!\left(\frac{e^{h(x,y)}}{\sum_{y^{\prime} \in\overline{y}}e^{h(x,y^{\prime})}}\right)-(1-\widetilde{c}(x,y))\log\!\left( \frac{e^{h(x,n+1)}}{\sum_{y^{\prime}\in\overline{y}}e^{h(x,y^{\prime})}} \right)\!.\]

Verma and Nalisnick (2022) proposed an alternative one-vs-all surrogates loss with cost functions based on expert's classification error, that is Bayes-consistent as well:

\[\mathsf{L}_{\mathrm{OvA}}(h,x,y)=\Phi(h(x,y))+\sum_{\begin{subarray}{c}y^{ \prime}\in\overline{y}\\ y^{\prime}\neq y\end{subarray}}\Phi(-h(x,y^{\prime}))+(1-\widetilde{c}(x,y)) [\Phi(h(x,n+1))-\Phi(-h(x,n+1))],\]

where \(\Phi\) is a strictly proper binary composite loss (Reid and Williamson, 2010), such as the logistic loss \(t\mapsto\log(1+e^{-t})\). \(\mathsf{L}_{\mathrm{CE}}\) and \(\mathsf{L}_{\mathrm{OvA}}\) are not realizable \(\mathcal{H}\)-consistent. Instead, Mozannar et al. (2023) proposed the following loss function that is realizable \(\mathcal{H}\)-consistent when \(\mathcal{H}\) is closed under scaling:

\[\mathsf{L}_{\mathrm{RS}}(h,x,y)=-2\log\!\left(\frac{e^{h(x,y)}+(1-\widetilde {c}(x,y))e^{h(x,n+1)}}{\sum_{y^{\prime}\in\overline{y}}e^{h(x,y^{\prime})}} \right)\!.\]

However, they were unable to prove or disprove whether the surrogate loss \(\mathsf{L}_{\mathrm{RS}}\) is Bayes-consistent.

All the surrogate losses mentioned above and their consistency guarantees hold only for cost functions based on the classification error: \(\widetilde{c}(x,y)=1_{\mathsf{g}(x)\ast y}\). Mao et al. (2024) generalized the surrogate loss \(\mathsf{L}_{\mathrm{CE}}\) to incorporate general cost functions and any multi-class surrogate losses:

\[\mathsf{L}_{\mathrm{general}}(h,x,y)=\ell(h,x,y)+(1-c(x,y))\ell(h,x,n+1).\]

Here, \(\ell\) is a Bayes-consistent surrogate loss for the multi-class zero-one loss over the augmented label set \(\overline{\mathcal{Y}}\). In particular, \(\ell\) can be chosen as a comp-sum loss (Mao et al., 2023), for example, the generalized cross entropy loss (see Section 4.1). As shown by Mao et al. (2024), \(\mathsf{L}_{\mathrm{general}}\) benefits from \(\mathcal{H}\)-consistency bounds, which implies its Bayes-consistency.

## 4 Novel surrogate losses

In this section, we introduce a new family of surrogate losses for L2D that benefit from Bayes-consistency, realizable \(\mathcal{H}\)-consistency and \(\mathcal{H}\)-consistency bounds, starting from first principles.

### Derivation from first principles

Observe that for any \((x,y)\in\mathcal{X}\times\mathcal{Y}\), we have \(1_{\mathsf{h}(x)=n+1}=1_{\mathsf{h}(x)\ast y}1_{\mathsf{h}(x)=n+1}\), since \(\mathsf{h}(x)=n+1\) implies \(\mathsf{h}(x)\neq y\). Thus, using additionally \(1_{\mathsf{h}(x)\in[n]}=1_{\mathsf{h}(x)\ast n+1}\), the deferral loss can be rewritten as follows for all \((x,y)\in\mathcal{X}\times\mathcal{Y}\):

\[\mathsf{L}_{\mathrm{def}}(h,x,y) =1_{\mathsf{h}(x)\ast y}1_{\mathsf{h}(x)\in[n]}+c(x,y)1_{\mathsf{ h}(x)=n+1}\] \[=1_{\mathsf{h}(x)\ast y}1_{\mathsf{h}(x)\ast n+1}+c(x,y)1_{ \mathsf{h}(x)\ast y}1_{\mathsf{h}(x)=n+1}\] \[=1_{\mathsf{h}(x)\ast y}1_{\mathsf{h}(x)\ast n+1}+c(x,y)1_{ \mathsf{h}(x)\ast y}(1-1_{\mathsf{h}(x)\ast n+1})\] \[=c(x,y)1_{\mathsf{h}(x)\ast y}+(1-c(x,y))1_{\mathsf{h}(x)\ast y \wedge\mathsf{h}(x)\ast n+1}.\] (2)

Next, we will derive the new surrogate losses for L2D by replacing the indicator functions in (2) with smooth loss functions. The first indicator function \(1_{\mathsf{h}(x)\ast y}\) is just the multi-class zero-one loss. Thus, a natural choice is to replace it with a surrogate loss in standard multi-class classification. We will specifically consider the family of comp-sum losses (Mao et al., 2023), defined as follows for any \((h,x,y)\in\mathcal{H}\times\mathcal{X}\times\mathcal{Y}\):

\[\ell_{\mathrm{comp}}(h,x,y)=\Psi\!\left(\frac{e^{h(x,y)}}{\sum_{y^{\prime}\in \overline{y}}e^{h(x,y^{\prime})}}\right)\!,\]

where \(\Psi\colon[0,1]\to\mathbb{R}_{\ast}\cup\{+\infty\}\) is a non-increasing function. For example, by taking \(\Psi(t)=-\log(t)\), \(\frac{1}{q}(1-t^{q})\) with \(q\in(0,1)\), \(1-t\), we obtain the _logistic loss_(Verhulst, 1838, 1845; Berkson, 1944,1951], the _generalized cross entropy loss_[Zhang and Sabuncu, 2018], and the _mean absolute error loss_[Ghosh et al., 2017], respectively:

\[\text{Logistic loss:}\qquad\qquad\qquad\qquad\ell_{\log}(h,x,y)=- \log\!\left[\frac{e^{h(x,y)}}{\sum_{y^{\prime}\in\overline{y}}e^{h(x,y^{\prime}) }}\right]\] \[\text{Generalized cross entropy loss:}\quad\ell_{\text{gce}}(h,x,y)= \frac{1}{q}\!\left[1-\left[\frac{e^{h(x,y)}}{\sum_{y^{\prime}\in\overline{y}}e ^{h(x,y^{\prime})}}\right]^{q}\right]\] \[\text{Mean absolute error loss:}\qquad\qquad\ell_{\text{mae}}(h,x,y)= 1-\frac{e^{h(x,y)}}{\sum_{y^{\prime}\in\overline{y}}e^{h(x,y^{\prime})}}.\]

For any \((h,x,y)\in\mathcal{H}\times\mathcal{X}\times\overline{\mathcal{Y}}\), the confidence margin \(\rho_{h}(x,y)\) is defined by \(\rho_{h}(x,y)=h(x,y)-\max_{y^{\prime}\in\overline{y},y^{\prime}\neq y}h(x,y^{ \prime})\). Thus, the second indicator function \(1_{\text{h}(x)\neq y\wedge h(x)\in n+1}\) can be expressed as follows in terms of the confidence margin:

\[1_{\text{h}(x)\neq y\wedge h(x)\in n+1} =1_{\left(h(x,y)\leq\max_{y^{\prime}\in\overline{y},y^{\prime} \neq y}h(x,y^{\prime})\right)\wedge\left(h(x,n+1)\leq\max_{y^{\prime}\in \overline{y},y^{\prime}\neq n+1}h(x,y^{\prime})\right)}\] \[=1_{(\rho_{h}(x,y)\leq 0)\wedge(\rho_{h}(x,n+1)\leq 0)}\] \[=1_{\max(\rho_{h}(x,y),\rho_{h}(x,n+1))\leq 0}.\]

Note that the first indicator function can also be written in terms of margin: \(1_{\text{h}(x)\neq y}=1_{\rho_{h}(x,y)\leq 0}\). Unlike the first indicator function, which presses \(h(x,y)\) to be the largest score among \(\overline{y}\), that is the margin \(\rho_{h}(x,y)\) to be positive, the second indicator function only enforces \(h(x,y)\) or \(h(x,n+1)\) to be the largest score among \(\overline{\mathcal{Y}}\), that is the maximum of two margins, \(\max\{\rho_{h}(x,y),\rho_{h}(x,n+1)\}\), to be positive. This condition can be further strengthened by requiring the sum of two margins, \(\rho_{h}(x,y)+\rho_{h}(x,n+1)\), to be positive. In view of this observation, we adopt the following modified comp-sum surrogate loss for the second indicator function:

\[\widetilde{\ell}_{\mathrm{comp}}(h,x,y)=\Psi\!\left(\frac{e^{h(x,y)}+e^{h(x,n+ 1)}}{\sum_{y^{\prime}\in\overline{y}}e^{h(x,y^{\prime})}}\right)\!,\]

where \(\Psi\colon[0,1]\to\mathbb{R}_{+}\cup\{+\infty\}\) is a non-increasing function. In other words, \(\widetilde{\ell}_{\mathrm{comp}}\) replaces the term \(e^{h(x,y)}\) in the softmax function in \(\ell_{\mathrm{comp}}\) with the sum \(e^{h(x,y)}+e^{h(x,n+1)}\). The effect is to encourage the sum of the two margins, \(\rho_{h}(x,y)+\rho_{h}(x,n+1)\), to be positive, rather than just the single margin \(\rho_{h}(x,y)\). Following this principle, we derive the following expression for a new family of surrogate losses, \(\text{L}_{\mathrm{RL2D}}\), dubbed _realizable L2D_:

\[\text{L}_{\mathrm{RL2D}}(h,x,y)=c(x,y)\ell_{\mathrm{comp}}(h,x,y)+(1-c(x,y)) \widetilde{\ell}_{\mathrm{comp}}(h,x,y).\] (3)

For the choices of \(\Psi(t)=-\log(t)\), \(\frac{1}{q}(1-t^{q})\) with \(q\in(0,1)\) and \(1-t\), we obtain the new surrogate losses for L2D in Table 1. In the next sections, we will prove both realizable \(\mathcal{H}\)-consistency guarantees and \(\mathcal{H}\)-consistency bounds for this family of surrogate losses, which imply their excess error bounds and Bayes-consistency as well.

### Realizable \(\mathcal{H}\)-consistency

Here, we show that \(\text{L}_{\mathrm{RL2D}}\) is realizable \(\mathcal{H}\)-consistent with respect to \(\text{L}_{\mathrm{def}}\). We say that a hypothesis set \(\mathcal{H}\) is _closed under scaling_ if, \(h\in\mathcal{H}\implies\alpha h\in\mathcal{H}\) for any \(\alpha\in\mathbb{R}\).

\begin{table}
\begin{tabular}{l l} \hline \hline \(\Psi(t)\) & \(\text{L}_{\mathrm{RL2D}}\) \\ \hline \(-\log(t)\) & \(-c(x,y)\log\!\left[\frac{e^{h(x,y)}}{\sum_{y^{\prime}\in\overline{y}}e^{h(x,y^{ \prime})}}\right]-(1-c(x,y))\log\!\left[\frac{e^{h(x,y)}+e^{h(x,n+1)}}{\sum_{y^{ \prime}\in\overline{y}}e^{h(x,y^{\prime})}}\right]\) \\ \(\frac{1}{q}(1-t^{q})\) & \(\frac{c(x,y)}{q}\!\left[1-\left[\frac{e^{h(x,y)}}{\sum_{y^{\prime}\in \overline{y}}e^{h(x,y^{\prime})}}\right]^{q}\right]\!+\frac{(1-c(x,y))}{q}\! \left[1-\left[\frac{e^{h(x,y)}+e^{h(x,n+1)}}{\sum_{y^{\prime}\in\overline{y}} e^{h(x,y^{\prime})}}\right]^{q}\right]\!\) \\ \(1-t\) & \(c(x,y)\!\left(1-\frac{e^{h(x,y)}}{\sum_{y^{\prime}\in\overline{y}}e^{h(x,y^{ \prime})}}\right)+(1-c(x,y))\!\left(1-\frac{e^{h(x,y)}+e^{h(x,n+1)}}{\sum_{y^{ \prime}\in\overline{y}}e^{h(x,y^{\prime})}}\right)\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: A new family of surrogate losses \(\text{L}_{\mathrm{RL2D}}\) for L2D.

**Theorem 4.1**.: _Assume that \(\mathcal{H}\) is closed under scaling. Suppose that \(\Psi\) is non-increasing, \(\Psi\big{(}\frac{2}{3}\big{)}>0\) and \(\lim_{t\to 1}\Psi(t)=0\). Then, the surrogate loss \(\mathsf{L}_{\mathrm{RL2D}}\) is realizable \(\mathcal{H}\)-consistent with respect to \(\mathsf{L}_{\mathrm{def}}\)._

The proof, detailed in Appendix A, begins by establishing an upper bound on the deferral loss in terms of the comp-sum loss: \(\mathsf{L}_{\mathrm{def}}\leq\frac{\mathsf{L}_{\mathrm{RL2D}}}{\Psi\big{(} \frac{2}{3}\big{)}}\). Letting \(\hat{h}\) be the minimizer of \(\mathsf{L}_{\mathrm{RL2D}}\) and \(\alpha\) be any real number, we then show that \(\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(\hat{h})\leq\frac{1}{\Psi\big{(}\frac {2}{3}\big{)}}\mathcal{E}_{\mathsf{L}_{\mathrm{RL2D}}}(\alpha h^{*})\). The generalization error is then split by conditioning on whether \(h^{*}(x)\) is the deferral class \((n+1)\) or not. Finally, we demonstrate that each conditional term converges to zero as \(\alpha\) tends to \(+\infty\), and apply the monotone convergence theorem to complete the proof.

### \(\mathcal{H}\)-Consistency bounds

Here, we show that \(\mathsf{L}_{\mathrm{RL2D}}\) admits an \(\mathcal{H}\)-consistency bound with respect to \(\mathsf{L}_{\mathrm{def}}\), which implies its Bayes-consistency as well. We say that a hypothesis set is symmetric if there exists a family \(\mathcal{F}\) of functions \(f\) mapping from \(\mathcal{X}\) to \(\mathbb{R}\) such that \(\{[h(x,1),\ldots,h(x,n+1)]\colon h\in\mathcal{H}\}=\{[f_{1}(x),\ldots,f_{n+1} (x)]\colon f_{1},\ldots,f_{n+1}\in\mathcal{F}\}\), for any \(x\in\mathcal{X}\). We say that a hypothesis set \(\mathcal{H}\) is complete if for any \((x,y)\in\mathcal{X}\times\mathcal{H}\), the set of scores generated by it spans across the real numbers: \(\{h(x,y)\mid h\in\mathcal{H}\}=\mathbb{R}\). Common neural network and linear function hypothesis sets are all symmetric and complete. We first consider the case where the cost is expert's classification error.

**Theorem 4.2**.: _Assume that \(\mathcal{H}\) is symmetric and complete and that \(c(x,y)=1_{\mathtt{g}(x)u_{y}}\). Then, for all \(h\in\mathcal{H}\) and any distribution, the following \(\mathcal{H}\)-consistency bound holds:_

\[\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{ def}}}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{def}}}(\mathcal{H})\leq \Gamma(\mathcal{E}_{\mathsf{L}_{\mathrm{RL2D}}}(h)-\mathcal{E}_{\mathsf{L}_{ \mathrm{RL2D}}}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{RL2D}}}( \mathcal{H})),\]

_where \(\Gamma(t)=\sqrt{2t}\) when \(\Psi(t)=-\log(t)\) and \(\Gamma(t)=\sqrt{2(n+1)^{q}t}\) when \(\Psi(t)=\frac{1}{q}(1-t^{q})\) with \(q\in(0,1)\)._

The proof, detailed in Appendix B.3 and B.4, establishes strong consistency guarantees for our new surrogate loss \(\mathsf{L}_{\mathrm{RL2D}}\) (Theorem 4.2). We first introduce \(y_{\max}=\operatorname*{argmax}_{y\in\mathcal{H}}p(x,y)\), the label with the highest conditional probability. We then show that for any hypothesis \(h\) and input \(x\), if \(y_{\max}\) is not the predicted label \(h_{\max}\), the conditional error of \(h\) is lower bounded by a modified hypothesis \(\overline{h}\) (obtained by swapping the scores of \(y_{\max}\) and \(h_{\max}\)). Next, for hypotheses where \(y_{\max}=h_{\max}\), we lower bound their conditional regret in terms of the conditional regret of the deferral loss using a new hypothesis \(h_{\mu}\). This proof is novel and significantly different from existing approaches for establishing \(\mathcal{H}\)-consistency bounds in either the standard or deferral settings (Mao et al., 2023, 2024a).

The next result further shows that when \(\Psi(t)=1-t\), our surrogate losses benefit from \(\mathcal{H}\)-consistency bounds for any general cost function.

**Theorem 4.3**.: _Assume that \(\mathcal{H}\) is symmetric and complete. Suppose that \(\Psi(t)=1-t\). Then, for all \(h\in\mathcal{H}\) and any distribution, the following \(\mathcal{H}\)-consistency bounds hold:_

\[\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{ def}}}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{def}}}(\mathcal{H})\leq(n+1)( \mathcal{E}_{\mathsf{L}_{\mathrm{RL2D}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{ RL2D}}}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{RL2D}}}(\mathcal{H})).\]

The proof is included in Appendix B.2. Theorem 4.2 provides stronger consistency guarantees for our new surrogate loss \(\mathsf{L}_{\mathrm{RL2D}}\) with \(\Psi(t)=1-t\) since it holds for any general cost function. The proof idea is similar to that of Theorem 4.2, albeit with more cases to analyze due to the general cost function. This occurs when lower bounding the conditional regret of a hypothesis \(h\), which satisfies \(y_{\max}=h_{\max}\), in terms of the conditional regret of the deferral loss by introducing a new hypothesis \(h_{\mu}\). The additional cases necessitate a more stringent condition for the guarantee, such that the functions \(\Psi(t)=-\log(t)\) and \(\Psi(t)=\frac{1}{q}\left(1-t^{q}\right)\) do not apply.

### Excess error bounds and Bayes-consistency

For the family of all measurable functions \(\mathcal{H}=\mathcal{H}_{\mathrm{all}}\), the minimizability gaps vanish. In this case, Theorems 4.2 and 4.3 imply the following excess error bounds and Bayes-consistency guarantees.

**Corollary 4.4**.: _Suppose that \(c(x,y)=1_{\mathtt{g}(x)u_{y}}\). For all \(h\in\mathcal{H}_{\mathrm{all}}\) and any distribution, the following excess error bounds hold:_

\[\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{def }}}(\mathcal{H}_{\mathrm{all}})\leq\Gamma(\mathcal{E}_{\mathsf{L}_{\mathrm{ RL2D}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{RL2D}}}(\mathcal{H}_{\mathrm{all}})),\]_where \(\Gamma(t)=\sqrt{2t}\) when \(\Psi(t)=-\log(t)\) and \(\Gamma(t)=\sqrt{2(n+1)^{q}t}\) when \(\Psi(t)=\frac{1}{q}(1-t^{q})\) with \(q\in(0,1)\). Furthermore, the surrogate loss \(\mathsf{L}_{\mathrm{RL2D}}\) is Bayes-consistent with respect to \(\mathsf{L}_{\mathrm{def}}\) in these cases._

**Corollary 4.5**.: _Suppose that \(\Psi(t)=1-t\). For all \(h\in\mathcal{H}_{\mathrm{all}}\) and any distribution, the following excess error bounds hold:_

\[\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{ def}}}(\mathcal{H}_{\mathrm{all}})\leq(n+1)(\mathcal{E}_{\mathsf{L}_{\mathrm{ RL2D}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{RL2D}}}(\mathcal{H}_{\mathrm{all}})).\]

_Furthermore, the surrogate loss \(\mathsf{L}_{\mathrm{RL2D}}\) is Bayes-consistent with respect to \(\mathsf{L}_{\mathrm{def}}\) in this case._

Therefore, Theorem 4.1 and Corollary 4.4 show that \(\mathsf{L}_{\mathrm{RL2D}}\) is both realizable \(\mathcal{H}\)-consistent and Bayes-consistent with respect to \(\mathsf{L}_{\mathrm{def}}\). This solves the open problem raised by Mozannar et al. (2023).

In particular, for cost functions based on classification error, \(c(x,y)=1_{\mathtt{g}(x)\neq y}\), our surrogate loss \(\mathsf{L}_{\mathrm{RL2D}}\) with \(\Psi(t)=-\log(t)\) coincides with the surrogate loss \(\mathsf{L}_{\mathrm{RS}}\) in (Mozannar et al., 2023), modulo a constant. This affirmatively answers the question of whether their surrogate loss is Bayes-consistent when \(c(x,y)=1_{\mathtt{g}(x)\neq y}\). However, their surrogate loss cannot be shown to be Bayes-consistent for a general cost function. In contrast, our surrogate losses \(\mathsf{L}_{\mathrm{RL2D}}\) with \(\Psi(t)=1-t\) are adaptable to general cost functions and benefit from both \(\mathcal{H}\)-consistency bounds and realizable \(\mathcal{H}\)-consistency guarantees. We also provide a more general family of comp-sum loss functions with \(\Psi(t)=\frac{1}{q}\left(1-t^{q}\right)\) that benefit from both \(\mathcal{H}\)-consistency bounds and realizable \(\mathcal{H}\)-consistency when \(c(x,y)=1_{\mathtt{g}(x)\neq y}\).

### Summary

Here, we summarize the consistency properties of existing surrogate losses and ours. As mentioned earlier, most surrogate losses proposed in previous work, except for \(\mathsf{L}_{\mathrm{general}}\), are analyzed under the condition \(c(x,y)=1_{\mathtt{g}(x)\neq y}\). This naturally leads to a summary of these surrogate losses in this context, as presented in Table 1. Additionally, we provide analyses and the consistency properties of our surrogate loss, \(\mathsf{L}_{\mathrm{RL2D}}\), with general cost functions.

More specifically, our surrogate losses \(\mathsf{L}_{\mathrm{RL2D}}\) satisfying Theorem 4.1 perform better in realizable scenarios than the surrogate losses \(\mathsf{L}_{\mathrm{CE}}\), \(\mathsf{L}_{\mathrm{OVA}}\), and \(\mathsf{L}_{\mathrm{general}}\) from prior work, as ours are realizable \(\mathcal{H}\)-consistent while theirs are not. This will be illustrated by our experiment results in the realizable case (Figure 0(a)). Our surrogate losses \(\mathsf{L}_{\mathrm{RL2D}}\) satisfying Theorem 4.2 and Corollary 4.4 are comparable to the surrogate losses in prior work in non-realizable scenarios when the cost is the expert's classification error, as all of them are Bayes-consistent and supported by H-consistency bounds. This is demonstrated by our experiment in the non-realizable case with the cost function being the expert's classification error (Table 3). Our surrogate losses \(\mathsf{L}_{\mathrm{RL2D}}\) satisfying Theorem 4.3 and Corollary 4.5 are superior to the surrogate loss \(\mathsf{L}_{\mathrm{RS}}\) in non-realizable scenarios with general cost functions, as ours are supported by H-consistency bounds and Bayes-consistency while theirs are not. This is evidenced by our experiment in the non-realizable case with general cost functions (Figure 0(b)).

5 Relationship between \(\mathcal{H}\)-consistency bounds and realizable \(\mathcal{H}\)-consistency

Here, we discuss the relationship between \(\mathcal{H}\)-consistency bounds and realizable \(\mathcal{H}\)-consistency. First, realizable \(\mathcal{H}\)-consistency does not imply \(\mathcal{H}\)-consistency bounds, since \(\mathcal{H}\)-consistency bounds require that the relationship holds for all distributions, not just realizable ones. Moreover, \(\mathcal{H}\)-consistency bounds provide non-asymptotic guarantees, while realizable \(\mathcal{H}\)-consistency provides only asymptotic guarantees. Second, \(\mathcal{H}\)-consistency bounds imply realizable \(\mathcal{H}\)-consistency in the standard multi-class classification setting. This is because minimizability gaps vanish under the realizable assumption in standard case. In particular, for comp-sum losses, the following holds (see Appendix C for proof).

\begin{table}
\begin{tabular}{l|l l l} \hline Surrogate losses & Realizable H-consistency & Bayes-consistency & H-consistency bounds \\ \hline \(\mathsf{L}_{\mathrm{CE}}\) & no & yes & yes \\ \(\mathsf{L}_{\mathrm{OVA}}\) & no & yes & yes \\ \(\mathsf{L}_{\mathrm{general}}\) & no & yes & yes \\ \(\mathsf{L}_{\mathrm{RS}}\) (\(\mathsf{L}_{\mathrm{RL2D}}\) with \(\Psi(t)=-\log(t)\)) & yes & yes (proved by us) & yes (proved by us) \\ \(\mathsf{L}_{\mathrm{RL2D}}\) with \(\Psi(t)=\frac{1}{q}(1-t^{q}),q\in(0,1)\) & yes & yes & yes \\ \(\mathsf{L}_{\mathrm{RL2D}}\) with \(\Psi(t)=1-t\) & yes & yes & yes \\ \hline \end{tabular}
\end{table}
Table 2: Consistency properties of existing surrogate losses and ours in the case of \(c(x,y)=1_{\mathtt{g}(x)\neq y}\).

**Theorem 5.1**.: _Assume that there exists a zero error solution \(h^{*}\in\mathcal{H}\) with \(\mathcal{E}_{\ell_{0-1}}(h^{*})=0\) and \(\mathcal{H}\) is closed under scaling. Assume that \(\lim_{t\to 1}\Psi(t)=0\). Then, the minimizability gap of comp-sum loss \(\ell_{\mathrm{comp}}\) vanishes: \(\mathcal{M}_{\ell_{\mathrm{comp}}}(\mathcal{H})=0\)._

However, in the deferral setting, this relationship no longer holds: \(\mathcal{H}\)-consistency bounds cannot imply realizable \(\mathcal{H}\)-consistency. In particular, Mao et al. (2023) showed that \(\mathrm{L}_{\mathrm{CE}}\) benefits from \(\mathcal{H}\)-consistency bounds, while Mozannar et al. (2023) showed that it is not realizable \(\mathcal{H}\)-consistent. The loss function in (Madras et al., 2018) is not Bayes-consistent, and thus does not have \(\mathcal{H}\)-consistency bound guarantees, but is actually realizable \(\mathcal{H}\)-consistent (Mozannar et al., 2023).

## 6 Experiments

In this section, we empirically evaluate our proposed surrogate losses and compare them with existing baselines.

**Experimental settings.** We follow the setting of Mozannar et al. (2023) and conduct experiments on a synthetic dataset: Mixture-of-Gaussians (Mozannar et al., 2023), and three real-world datasets: CIFAR-10H (Battleday et al., 2020), HateSpeech (Davidson et al., 2017), and COMPASS (Dressel and Farid, 2018). For these three datasets, we adopt the same model class as that in (Mozannar et al., 2023, Table 1). Each dataset is randomly split into 70%, 10%, and 20% for training, validation, and testing, respectively. For the Mixture-of-Gaussians, we adopt the exact realizable setting from (Mozannar et al., 2023, Section 7.2), which is realizable by linear functions: there exists a linear hypothesis \(h^{*}\in\mathcal{H}\) achieving zero deferral loss, \(\mathcal{E}_{\mathrm{L}_{\mathrm{def}}}(h^{*})=0\).

As with (Mozannar et al., 2023), we choose the cost function to be the expert's classification error: \(c(x,y)=1_{\mathcal{B}(x)ay}\). We compare our surrogate to four baselines as described in Section 3.3: the cross-entropy surrogate \(\mathrm{L}_{\mathrm{CE}}\) from (Mozannar and Sontag, 2020), the one-vs-all surrogate \(\mathrm{L}_{\mathrm{OVA}}\) from (Mozannar and Sontag, 2020), the realizable surrogate \(\mathrm{L}_{\mathrm{RS}}\) from (Mozannar et al., 2023), and the general surrogate \(\mathrm{L}_{\mathrm{general}}\) from (Mao et al., 2024). For \(\mathrm{L}_{\mathrm{OVA}}\), we choose \(\Phi\) as the logistic loss, following (Verma and Nalisnick, 2022). For \(\mathrm{L}_{\mathrm{general}}\), we choose \(\ell\) as the generalized cross entropy loss with \(q=0.7\), following (Mao et al., 2024). For our Realizable L2D surrogate \(\mathrm{L}_{\mathrm{RL2D}}\), we consider two choices: \(\ell\) as the generalized cross entropy loss with \(q=0.7\), following (Zhang and Sabuncu, 2018; Mao et al., 2024), and \(\ell\) as the mean absolute error loss (\(q=1\)). Among these, \(\mathrm{L}_{\mathrm{CE}}\), \(\mathrm{L}_{\mathrm{OVA}}\) and \(\mathrm{L}_{\mathrm{general}}\) are Bayes-consistent but not realizable \(\mathcal{H}\)-consistent; \(\mathrm{L}_{\mathrm{RS}}\), \(\mathrm{L}_{\mathrm{RL2D}}\) with \(q=0.7\) and \(\mathrm{L}_{\mathrm{RL2D}}\) with \(q=1\) are both Bayes-consistent and realizable \(\mathcal{H}\)-consistent, as shown in Sections 4.2 and 4.4. Note that in this case, \(\mathrm{L}_{\mathrm{RS}}\) is a special case of \(\mathrm{L}_{\mathrm{RL2D}}\) when \(\Psi\) is chosen as \(t\mapsto-\log(t)\). We use the same optimizer, learning rate, and number of epochs as chosen in (Mozannar et al., 2023), and we select the model that achieves the highest _system accuracy_, that is average \([1-\mathrm{L}_{\mathrm{def}}(h,x,y)]\), on a validation set.

\begin{table}
\begin{tabular}{l c c c c} Method & Dataset & System Accuracy & Accepted Accuracy & Coverage \\ \hline Mozannar and Sontag (2020) (\(\mathrm{L}_{\mathrm{CE}}\)) & & \(91.60\pm 0.15\) & \(94.61\pm 0.67\) & \(44.55\pm 1.68\) \\ Verma and Nalisnick (2022) (\(\mathrm{L}_{\mathrm{OVA}}\)) & & \(92.18\pm 0.10\) & \(95.43\pm 0.36\) & \(58.56\pm 3.18\) \\ Mazannar et al. (2023) (\(\mathrm{L}_{\mathrm{RS}}\)) & & \(91.83\pm 0.63\) & \(95.37\pm 0.72\) & \(54.78\pm 3.70\) \\ Mao et al. (2024) (\(\mathrm{L}_{\mathrm{general}}\)) & HateSpeech & \(92.05\pm 0.04\) & \(96.28\pm 0.35\) & \(46.74\pm 2.80\) \\ Realizable L2D (\(\mathrm{L}_{\mathrm{RL2D}},q=0.7\)) & & \(92.20\pm 0.54\) & \(96.06\pm 0.39\) & \(57.85\pm 0.76\) \\ Realizable L2D (\(\mathrm{L}_{\mathrm{RL2D}},q=1\)) & & \(91.97\pm 0.29\) & \(96.57\pm 0.69\) & \(53.25\pm 2.49\) \\ \hline Mozannar and Sontag (2020) (\(\mathrm{L}_{\mathrm{CE}}\)) & & \(66.33\pm 0.47\) & \(73.65\pm 1.83\) & \(55.17\pm 9.51\) \\ Verma and Nalisnick (2022) (\(\mathrm{L}_{\mathrm{OVA}}\)) & & \(66.33\pm 1.31\) & \(71.03\pm 5.10\) & \(53.33\pm 4.73\) \\ Mozannar et al. (2023) (\(\mathrm{L}_{\mathrm{RS}}\)) & & \(66.00\pm 2.27\) & \(63.20\pm 4.23\) & \(69.50\pm 10.8\) \\ Mao et al. (2024) (\(\mathrm{L}_{\mathrm{general}}\)) & & \(66.67\pm 0.62\) & \(76.25\pm 2.42\) & \(48.33\pm 5.31\) \\ Realizable L2D (\(\mathrm{L}_{\mathrm{RL2D}},q=0.7\)) & & \(66.17\pm 0.21\) & \(69.33\pm 0.30\) & \(55.67\pm 5.95\) \\ Realizable L2D (\(\mathrm{L}_{\mathrm{RL2D}},q=1\)) & & \(66.83\pm 0.85\) & \(69.02\pm 2.42\) & \(54.83\pm 0.62\) \\ \hline Mozannar and Sontag (2020) (\(\mathrm{L}_{\mathrm{CE}}\)) & & \(96.27\pm 0.51\) & \(98.77\pm 0.71\) & \(64.33\pm 6.13\) \\ Verma and Nalisnick (2022) (\(\mathrm{L}_{\mathrm{OVA}}\)) & & \(96.25\pm 0.45\) & \(98.74\pm 0.54\) & \(67.88\pm 6.16\) \\ Mozannar et al. (2023) (\(\mathrm{L}_{\mathrm{RS}}\)) & & \(96.63\pm 0.18\) & \(98.23\pm 0.78\) & \(66.63\pm 1.80\) \\ Mao et al. (2024) (\(\mathrm{L}_{\mathrm{general}}\)) & & \(96.75\pm 0.55\) & \(98.65\pm 0.80\) & \(65.68\pm 3.36\) \\ Realizable L2D (\(\mathrm{L}_{\mathrm{RL2D}},q=0.7\)) & & \(96.80\pm 0.25\) & \(98.37\pm 0.20\) & \(76.77\pm 3.63\) \\ Realizable L2D (\(\mathrm{L}_{\mathrm{RL2D}},q=1\)) & & \(96.57\pm 0.05\) & \(98.34\pm 0.24\) & \(77.37\pm 2.43\) \\ \hline \end{tabular}
\end{table}
Table 3: Comparison of system accuracy, accepted accuracy and coverage; mean \(\pm\) standard deviation over three runs. Realizable L2D outperforms or is comparable to baselines in all the settings.

**Evaluation.** For the three real-world datasets, we report the _system accuracy_, that is average value of \(\left[1-\mathsf{L}_{\mathrm{def}}(h,x,y)\right]\) on the test data. For completeness, we also include the _accepted accuracy_, that is the average value of \(\left[1_{\mathsf{h}(x)\neq y}1_{\mathsf{h}(x)\in[n]}\right]\). This metric considers only incorrect predictions (\(\mathsf{h}(x)\neq y\)) and measures the fraction of those where the system's output (\(\mathsf{h}(x)\)) falls within the valid range of possible outputs (\([n]\)). We also report the _coverage_, that is the average value of \(\left[1_{\mathsf{h}(x)\in[n]}\right]\) on the test set, or the fraction of test instances where the system's prediction falls within the valid range (\([n]\)). For each metric, we average results over three runs and report the mean accuracy along with the standard deviation for both our proposed methods and the baseline approaches. For the realizable Mixture-of-Gaussians, we plot the system accuracy of various methods on a held-out test dataset consisting of 5,000 points as we increase the size of the training data.

**Results.** Table 3 shows that for the real-world datasets, \(\mathrm{L}_{\mathrm{RL2D}}\) with \(q=0.7\), and \(\mathrm{L}_{\mathrm{RL2D}}\) with \(q=1\) either outperform or are comparable to the best baseline in terms of system accuracy on each dataset. This performance is supported by our \(\mathcal{H}\)-consistency bounds and Bayes-consistency results for our Realizable L2D surrogate with respect to the deferral loss \(\mathsf{L}_{\mathrm{def}}\), as shown in Sections 4.3 and 4.4. Table 3 also shows that \(\mathsf{L}_{\mathrm{RL2D}}\) achieves reasonable coverage and acceptable accuracy. The system accuracy, coverage, and standard deviations of the baselines match those in (Mozannar et al., 2023). Moreover, \(\mathrm{L}_{\mathrm{RS}}\), \(\mathrm{L}_{\mathrm{RL2D}}\) with \(q=0.7\), and \(\mathrm{L}_{\mathrm{RL2D}}\) with \(q=1\) perform differently across various datasets: \(\mathsf{L}_{\mathrm{RL2D}}\) with \(q=0.7\) outperforms the others on HateSpeech and CIFAR-10H, while \(\mathsf{L}_{\mathrm{RL2D}}\) with \(q=1\) outperforms the others on COMPASS. Note that in this case, \(\mathsf{L}_{\mathrm{RS}}\) is a special case of \(\mathsf{L}_{\mathrm{RL2D}}\) when \(\Psi\) is chosen as \(t\mapsto-\log(t)\). These results show that Realizable L2D can benefit from the flexibility in the choice of \(\Psi\).

Figure 0(a) shows system accuracy versus training samples on the realizable Mixture-of-Gaussians distribution. Our surrogate loss \(\mathsf{L}_{\mathrm{RL2D}}\) with \(q=0.7\) and \(q=1\) are realizable \(\mathcal{H}\)-consistent, while \(\mathsf{L}_{\mathrm{CE}}\), \(\mathsf{L}_{\mathrm{OVA}}\) and \(\mathsf{L}_{\mathrm{general}}\) are not. This verifies our theory.

Figure 0(b) shows system accuracy versus coverage on the HateSpeech dataset by varying \(\beta\) in the general cost functions \(c(x,y)=1_{\mathsf{g}(x)\neq y}+\beta\). As \(\beta\) increases, deferral algorithms yield solutions with higher coverage and decreased system accuracy. This is because \(\beta\) controls the trade-off between expert's inference cost and accuracy. \(\mathsf{L}_{\mathrm{RL2D}}\) with \(q=1\) performs comparably to the surrogate loss \(\mathsf{L}_{\mathrm{general}}\), as both are supported by \(\mathcal{H}\)-consistency bounds and Bayes-consistency with general cost functions. Our surrogate loss \(\mathsf{L}_{\mathrm{RL2D}}\) with \(q=1\) outperforms \(\mathsf{L}_{\mathrm{RS}}\) because the latter does not benefit from Bayes-consistency with general cost functions.

## 7 Conclusion

We introduced a broad family of surrogate losses and algorithms for learning to defer, parameterized by a non-increasing function. We established their realizable \(\mathcal{H}\)-consistency properties under mild conditions and proved that several of these surrogate losses benefit from \(\mathcal{H}\)-consistency bounds for cost functions based on classification error and general cost functions, which also imply their Bayes-consistency. This research not only resolves an open question posed in previous work but also lays the groundwork for comparing various consistency notions in learning to defer and standard classification. Looking forward, our approach offers a promising avenue for analyzing multi-expert and two-stage settings.

Figure 1: Results for the realizable case and the non-realizable case with general cost functions.

## References

* Acar et al. (2020) D. A. E. Acar, A. Gangrade, and V. Saligrama. Budget learning via bracketing. In _International Conference on Artificial Intelligence and Statistics_, pages 4109-4119, 2020.
* Awasthi et al. (2021a) P. Awasthi, N. Frank, A. Mao, M. Mohri, and Y. Zhong. Calibration and consistency of adversarial surrogate losses. _Advances in Neural Information Processing Systems_, pages 9804-9815, 2021a.
* Awasthi et al. (2021b) P. Awasthi, A. Mao, M. Mohri, and Y. Zhong. A finer calibration analysis for adversarial robustness. _arXiv preprint arXiv:2105.01550_, 2021b.
* Awasthi et al. (2022a) P. Awasthi, A. Mao, M. Mohri, and Y. Zhong. \(\mathcal{H}\)-consistency bounds for surrogate loss minimizers. In _International Conference on Machine Learning_, 2022a.
* Awasthi et al. (2022b) P. Awasthi, A. Mao, M. Mohri, and Y. Zhong. Multi-class \(\mathcal{H}\)-consistency bounds. In _Advances in neural information processing systems_, 2022b.
* Awasthi et al. (2023) P. Awasthi, A. Mao, M. Mohri, and Y. Zhong. Theoretically grounded loss functions and algorithms for adversarial robustness. In _International Conference on Artificial Intelligence and Statistics_, pages 10077-10094, 2023.
* Awasthi et al. (2024) P. Awasthi, A. Mao, M. Mohri, and Y. Zhong. DC-programming for neural network optimizations. _Journal of Global Optimization_, 2024.
* Bartlett and Wegkamp (2008) P. L. Bartlett and M. H. Wegkamp. Classification with a reject option using a hinge loss. _Journal of Machine Learning Research_, 9(8), 2008.
* Bartlett et al. (2006) P. L. Bartlett, M. I. Jordan, and J. D. McAuliffe. Convexity, classification, and risk bounds. _Journal of the American Statistical Association_, 101(473):138-156, 2006.
* Battleday et al. (2020) R. M. Battleday, J. C. Peterson, and T. L. Griffiths. Capturing human categorization of natural images by combining deep networks and cognitive models. _Nature communications_, 11(1):5418, 2020.
* Benz and Rodriguez (2022) N. L. C. Benz and M. G. Rodriguez. Counterfactual inference of second opinions. In _Uncertainty in Artificial Intelligence_, pages 453-463, 2022.
* Berkson (1944) J. Berkson. Application of the logistic function to bio-assay. _Journal of the American Statistical Association_, 39:357---365, 1944.
* Berkson (1951) J. Berkson. Why I prefer logits to probits. _Biometrics_, 7(4):327---339, 1951.
* Bubeck et al. (2022) S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz, E. Kamar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg, et al. Sparks of artificial general intelligence: Early experiments with gpt-4. _arXiv preprint arXiv:2303.12712_, 2023.
* Cao et al. (2022) Y. Cao, T. Cai, L. Feng, L. Gu, J. Gu, B. An, G. Niu, and M. Sugiyama. Generalizing consistent multi-class classification with rejection to be compatible with arbitrary losses. In _Advances in neural information processing systems_, 2022.
* Cao et al. (2023) Y. Cao, H. Mozannar, L. Feng, H. Wei, and B. An. In defense of softmax parametrization for calibrated and consistent learning to defer. In _Advances in Neural Information Processing Systems_, 2023.
* Charoenphakdee et al. (2021) N. Charoenphakdee, Z. Cui, Y. Zhang, and M. Sugiyama. Classification with rejection based on cost-sensitive classification. In _International Conference on Machine Learning_, pages 1507-1517, 2021.
* Charusaie and Samadi (2024) M.-A. Charusaie and S. Samadi. A unifying post-processing framework for multi-objective learn-to-defer problems. _arXiv preprint arXiv:2407.12710_, 2024.
* Charusaie et al. (2022) M.-A. Charusaie, H. Mozannar, D. Sontag, and S. Samadi. Sample efficient learning of predictors that complement humans. In _International Conference on Machine Learning_, pages 2972-3005, 2022.
* Chen et al. (2024) G. Chen, X. Li, C. Sun, and H. Wang. Learning to make adherence-aware advice. In _International Conference on Learning Representations_, 2024.
* Chen et al. (2020)X. Cheng, Y. Cao, H. Wang, H. Wei, B. An, and L. Feng. Regression with cost-based rejection. In _Advances in Neural Information Processing Systems_, 2023.
* Chow (1957) C. Chow. An optimum character recognition system using decision function. _IEEE T. C._, 1957.
* Chow (1970) C. Chow. On optimum recognition error and reject tradeoff. _IEEE Transactions on information theory_, 16(1):41-46, 1970.
* Cortes et al. (2016a) C. Cortes, G. DeSalvo, and M. Mohri. Learning with rejection. In _International Conference on Algorithmic Learning Theory_, pages 67-82, 2016a.
* Cortes et al. (2016b) C. Cortes, G. DeSalvo, and M. Mohri. Boosting with abstention. In _Advances in Neural Information Processing Systems_, pages 1660-1668, 2016b.
* Cortes et al. (2023) C. Cortes, G. DeSalvo, and M. Mohri. Theory and algorithms for learning with rejection in binary classification. _Annals of Mathematics and Artificial Intelligence_, pages 1-39, 2023.
* Cortes et al. (2024) C. Cortes, A. Mao, C. Mohri, M. Mohri, and Y. Zhong. Cardinality-aware set prediction and top-\(k\) classification. In _Advances in neural information processing systems_, 2024.
* Davidson et al. (2017) T. Davidson, D. Warmsley, M. Macy, and I. Weber. Automated hate speech detection and the problem of offensive language. In _Proceedings of the international AAAI conference on web and social media_, volume 11, pages 512-515, 2017.
* De et al. (2020) A. De, P. Koley, N. Ganguly, and M. Gomez-Rodriguez. Regression under human assistance. In _Proceedings of the AAAI Conference on Artificial Intelligence_, pages 2611-2620, 2020.
* De et al. (2021) A. De, N. Okati, A. Zarezade, and M. G. Rodriguez. Classification under human assistance. In _Proceedings of the AAAI Conference on Artificial Intelligence_, pages 5905-5913, 2021.
* Dressel and Farid (2018) J. Dressel and H. Farid. The accuracy, fairness, and limits of predicting recidivism. _Science advances_, 4(1):eaao5580, 2018.
* El-Yaniv and Wiener (2012) R. El-Yaniv and Y. Wiener. Active learning via perfect selective classification. _Journal of Machine Learning Research_, 13(2), 2012.
* El-Yaniv et al. (2010) R. El-Yaniv et al. On the foundations of noise-free selective classification. _Journal of Machine Learning Research_, 11(5), 2010.
* Gangrade et al. (2021) A. Gangrade, A. Kag, and V. Saligrama. Selective classification via one-sided prediction. In _International Conference on Artificial Intelligence and Statistics_, pages 2179-2187, 2021.
* Gao et al. (2021) R. Gao, M. Saar-Tsechansky, M. De-Arteaga, L. Han, M. K. Lee, and M. Lease. Human-ai collaboration with bandit feedback. _arXiv preprint arXiv:2105.10614_, 2021.
* Geifman and El-Yaniv (2017) Y. Geifman and R. El-Yaniv. Selective classification for deep neural networks. In _Advances in neural information processing systems_, 2017.
* Geifman and El-Yaniv (2019) Y. Geifman and R. El-Yaniv. SelectiveNet: A deep neural network with an integrated reject option. In _International conference on machine learning_, pages 2151-2159, 2019.
* Ghosh et al. (2017) A. Ghosh, H. Kumar, and P. S. Sastry. Robust loss functions under label noise for deep neural networks. In _Proceedings of the AAAI conference on artificial intelligence_, 2017.
* Hemmer et al. (2022) P. Hemmer, S. Schellhammer, M. Vossing, J. Jakubik, and G. Satzger. Forming effective human-ai teams: Building machine learning models that complement the capabilities of multiple experts. _arXiv preprint arXiv:2206.07948_, 2022.
* Hemmer et al. (2023) P. Hemmer, L. Thede, M. Vossing, J. Jakubik, and N. Kuhl. Learning to defer with limited expert predictions. _arXiv preprint arXiv:2304.07306_, 2023.
* Jiang et al. (2020) W. Jiang, Y. Zhao, and Z. Wang. Risk-controlled selective prediction for regression deep neural network models. In _2020 International Joint Conference on Neural Networks (IJCNN)_, pages 1-8, 2020.
* Jiang et al. (2020)W. Jitkrittum, N. Gupta, A. K. Menon, H. Narasimhan, A. Rawat, and S. Kumar. When does confidence-based cascade deferral suffice? In _Advances in Neural Information Processing Systems_, 2023.
* Joshi et al. (2021) S. Joshi, S. Parbhoo, and F. Doshi-Velez. Pre-emptive learning-to-defer for sequential medical decision-making under uncertainty. _arXiv preprint arXiv:2109.06312_, 2021.
* Kerrigan et al. (2021) G. Kerrigan, P. Smyth, and M. Steyvers. Combining human predictions with model probabilities via confusion matrices and calibration. _Advances in Neural Information Processing Systems_, 34:4421-4434, 2021.
* Keswani et al. (2021) V. Keswani, M. Lease, and K. Kenthapadi. Towards unbiased and accurate deferral to multiple experts. In _Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society_, pages 154-165, 2021.
* Li et al. (2023) X. Li, S. Liu, C. Sun, and H. Wang. When no-rejection learning is optimal for regression with rejection. _arXiv preprint arXiv:2307.02932_, 2023.
* Liu et al. (2022) J. Liu, B. Gallego, and S. Barbieri. Incorporating uncertainty in learning to defer algorithms for safe computer-aided diagnosis. _Scientific reports_, 12(1):1762, 2022.
* Liu et al. (2024) S. Liu, Y. Cao, Q. Zhang, L. Feng, and B. An. Mitigating underfitting in learning to defer with consistent losses. In _International Conference on Artificial Intelligence and Statistics_, pages 4816-4824, 2024.
* Long and Servedio (2013) P. Long and R. Servedio. Consistency versus realizable H-consistency for multiclass classification. In _International Conference on Machine Learning_, pages 801-809, 2013.
* Madras et al. (2018) D. Madras, E. Creager, T. Pitassi, and R. Zemel. Learning adversarially fair and transferable representations. _arXiv preprint arXiv:1802.06309_, 2018.
* Mao et al. (2023a) A. Mao, C. Mohri, M. Mohri, and Y. Zhong. Two-stage learning to defer with multiple experts. In _Advances in neural information processing systems_, 2023a.
* Mao et al. (2023b) A. Mao, M. Mohri, and Y. Zhong. H-consistency bounds: Characterization and extensions. In _Advances in Neural Information Processing Systems_, 2023b.
* Mao et al. (2023c) A. Mao, M. Mohri, and Y. Zhong. H-consistency bounds for pairwise misranking loss surrogates. In _International conference on Machine learning_, 2023c.
* Mao et al. (2023d) A. Mao, M. Mohri, and Y. Zhong. Ranking with abstention. In _ICML 2023 Workshop The Many Facets of Preference-Based Learning_, 2023d.
* Mao et al. (2023e) A. Mao, M. Mohri, and Y. Zhong. Structured prediction with stronger consistency guarantees. In _Advances in Neural Information Processing Systems_, 2023e.
* Mao et al. (2023f) A. Mao, M. Mohri, and Y. Zhong. Cross-entropy loss functions: Theoretical analysis and applications. In _International Conference on Machine Learning_, 2023f.
* Mao et al. (2024a) A. Mao, M. Mohri, and Y. Zhong. Principled approaches for learning to defer with multiple experts. In _International Symposium on Artificial Intelligence and Mathematics_, 2024a.
* Mao et al. (2024b) A. Mao, M. Mohri, and Y. Zhong. Predictor-rejector multi-class abstention: Theoretical analysis and algorithms. In _International Conference on Algorithmic Learning Theory_, pages 822-867, 2024b.
* Mao et al. (2024c) A. Mao, M. Mohri, and Y. Zhong. Theoretically grounded loss functions and algorithms for score-based multi-class abstention. In _International Conference on Artificial Intelligence and Statistics_, pages 4753-4761, 2024c.
* Mao et al. (2024d) A. Mao, M. Mohri, and Y. Zhong. Enhanced \(H\)-consistency bounds. _arXiv preprint arXiv:2407.13722_, 2024d.
* Mao et al. (2024e) A. Mao, M. Mohri, and Y. Zhong. \(H\)-consistency guarantees for regression. In _International Conference on Machine Learning_, pages 34712-34737, 2024e.

A. Mao, M. Mohri, and Y. Zhong. Multi-label learning with stronger consistency guarantees. In _Advances in neural information processing systems_, 2024f.
* Mao et al. [2024g] A. Mao, M. Mohri, and Y. Zhong. Regression with multi-expert deferral. In _International Conference on Machine Learning_, pages 34738-34759, 2024g.
* Mao et al. [2024h] A. Mao, M. Mohri, and Y. Zhong. A universal growth rate for learning with smooth surrogate losses. In _Advances in neural information processing systems_, 2024h.
* Mohri et al. [2024] C. Mohri, D. Andor, E. Choi, M. Collins, A. Mao, and Y. Zhong. Learning to reject with a fixed predictor: Application to decontextualization. In _International Conference on Learning Representations_, 2024.
* Mohri et al. [2018] M. Mohri, A. Rostamizadeh, and A. Talwalkar. _Foundations of Machine Learning_. MIT Press, second edition, 2018.
* Mozannar and Sontag [2020] H. Mozannar and D. Sontag. Consistent estimators for learning to defer to an expert. In _International Conference on Machine Learning_, pages 7076-7087, 2020.
* Mozannar et al. [2022] H. Mozannar, A. Satyanarayan, and D. Sontag. Teaching humans when to defer to a classifier via exemplars. In _Proceedings of the AAAI Conference on Artificial Intelligence_, pages 5323-5331, 2022.
* Mozannar et al. [2023] H. Mozannar, H. Lang, D. Wei, P. Sattigeri, S. Das, and D. Sontag. Who should predict? exact algorithms for learning to defer to humans. In _International Conference on Artificial Intelligence and Statistics_, pages 10520-10545, 2023.
* Narasimhan et al. [2022] H. Narasimhan, W. Jitkrittum, A. K. Menon, A. S. Rawat, and S. Kumar. Post-hoc estimators for learning to defer to an expert. In _Advances in Neural Information Processing Systems_, pages 29292-29304, 2022.
* Neyman and Pearson [1933] J. Neyman and E. S. Pearson. Ix. on the problem of the most efficient tests of statistical hypotheses. _Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character_, 231(694-706):289-337, 1933.
* Ni et al. [2019] C. Ni, N. Charoenphakdee, J. Honda, and M. Sugiyama. On the calibration of multiclass classification with rejection. In _Advances in Neural Information Processing Systems_, pages 2582-2592, 2019.
* Okati et al. [2021] N. Okati, A. De, and M. Rodriguez. Differentiable learning under triage. _Advances in Neural Information Processing Systems_, 34:9140-9151, 2021.
* Palomba et al. [2024] F. Palomba, A. Pugnana, J. M. Alvarez, and S. Ruggieri. A causal framework for evaluating deferring systems. _arXiv preprint arXiv:2405.18902_, 2024.
* Pradier et al. [2021] M. F. Pradier, J. Zazo, S. Parbhoo, R. H. Perlis, M. Zazzi, and F. Doshi-Velez. Preferential mixture-of-experts: Interpretable models that rely on human expertise as much as possible. _AMIA Summits on Translational Science Proceedings_, 2021:525, 2021.
* Raghu et al. [2019] M. Raghu, K. Blumer, G. Corrado, J. Kleinberg, Z. Obermeyer, and S. Mullainathan. The algorithmic automation problem: Prediction, triage, and human effort. _arXiv preprint arXiv:1903.12220_, 2019.
* Raman and Yee [2021] N. Raman and M. Yee. Improving learning-to-defer algorithms through fine-tuning. _arXiv preprint arXiv:2112.10768_, 2021.
* Ramaswamy et al. [2018] H. G. Ramaswamy, A. Tewari, and S. Agarwal. Consistent algorithms for multiclass classification with an abstain option. _Electronic Journal of Statistics_, 12(1):530-554, 2018.
* Reid and Williamson [2010] M. D. Reid and R. C. Williamson. Composite binary losses. _The Journal of Machine Learning Research_, 11:2387-2422, 2010.
* Shah et al. [2022] A. Shah, Y. Bu, J. K. Lee, S. Das, R. Panda, P. Sattigeri, and G. W. Wornell. Selective regression under fairness criteria. In _International Conference on Machine Learning_, pages 19598-19615, 2022.
* Shah et al. [2021]I. Steinwart. How to compare different loss functions and their risks. _Constructive Approximation_, 26(2):225-287, 2007.
* Straitouri et al. [2021] E. Straitouri, A. Singla, V. B. Meresht, and M. Gomez-Rodriguez. Reinforcement learning under algorithmic triage. _arXiv preprint arXiv:2109.11328_, 2021.
* Straitouri et al. [2022] E. Straitouri, L. Wang, N. Okati, and M. G. Rodriguez. Provably improving expert predictions with conformal prediction. _arXiv preprint arXiv:2201.12006_, 2022.
* Tailor et al. [2024] D. Tailor, A. Patra, R. Verma, P. Manggala, and E. Nalisnick. Learning to defer to a population: A meta-learning approach. In _International Conference on Artificial Intelligence and Statistics_, pages 3475-3483, 2024.
* Tewari and Bartlett [2007] A. Tewari and P. L. Bartlett. On the consistency of multiclass classification methods. _Journal of Machine Learning Research_, 8(36):1007-1025, 2007.
* Verhulst [1838] P. F. Verhulst. Notice sur la loi que la population suit dans son accroissement. _Correspondance mathematique et physique_, 10:113---121, 1838.
* Verhulst [1845] P. F. Verhulst. Recherches mathematiques sur la loi d'accroissement de la population. _Nouveaux Memoires de l'Academie Royale des Sciences et Belles-Lettres de Bruxelles_, 18:1---42, 1845.
* Verma and Nalisnick [2022] R. Verma and E. Nalisnick. Calibrated learning to defer with one-vs-all classifiers. In _International Conference on Machine Learning_, pages 22184-22202, 2022.
* Verma et al. [2023] R. Verma, D. Barrejon, and E. Nalisnick. Learning to defer to multiple experts: Consistent surrogate losses, confidence calibration, and conformal ensembles. In _International Conference on Artificial Intelligence and Statistics_, pages 11415-11434, 2023.
* Wei et al. [2022] J. Wei, Y. Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borgeaud, D. Yogatama, M. Bosma, D. Zhou, D. Metzler, E. H. Chi, T. Hashimoto, O. Vinyals, P. Liang, J. Dean, and W. Fedus. Emergent abilities of large language models. _CoRR_, abs/2206.07682, 2022.
* Wiener and El-Yaniv [2011] Y. Wiener and R. El-Yaniv. Agnostic selective classification. In _Advances in neural information processing systems_, 2011.
* Wiener and El-Yaniv [2012] Y. Wiener and R. El-Yaniv. Pointwise tracking the optimal regression function. _Advances in Neural Information Processing Systems_, 25, 2012.
* Wiener and El-Yaniv [2015] Y. Wiener and R. El-Yaniv. Agnostic pointwise-competitive selective classification. _Journal of Artificial Intelligence Research_, 52:171-201, 2015.
* Wilder et al. [2021] B. Wilder, E. Horvitz, and E. Kamar. Learning to complement humans. In _International Joint Conferences on Artificial Intelligence_, pages 1526-1533, 2021.
* Yuan and Wegkamp [2010] M. Yuan and M. Wegkamp. Classification methods with reject option based on convex risk minimization. _Journal of Machine Learning Research_, 11(1), 2010.
* Yuan and Wegkamp [2011] M. Yuan and M. Wegkamp. SVMs with a reject option. In _Bernoulli_, 2011.
* Zaoui et al. [2020] A. Zaoui, C. Denis, and M. Hebiri. Regression with reject option and application to knn. In _Advances in Neural Information Processing Systems_, pages 20073-20082, 2020.
* Zhang and Agarwal [2020] M. Zhang and S. Agarwal. Bayes consistency vs. H-consistency: The interplay between surrogate loss functions and the scoring function class. In _Advances in Neural Information Processing Systems_, 2020.
* Zhang [2004a] T. Zhang. Statistical behavior and consistency of classification methods based on convex risk minimization. _The Annals of Statistics_, 32(1):56-85, 2004a.
* Zhang [2004b] T. Zhang. Statistical analysis of some multi-category large margin classification methods. _Journal of Machine Learning Research_, 5(Oct):1225-1251, 2004b.
* Zhang and Sabuncu [2018] Z. Zhang and M. Sabuncu. Generalized cross entropy loss for training deep neural networks with noisy labels. In _Advances in neural information processing systems_, 2018.
* Zhang et al. [2018]J. Zhao, M. Agrawal, P. Razavi, and D. Sontag. Directing human attention in event localization for clinical timeline creation. In _Machine Learning for Healthcare Conference_, pages 80-102, 2021.
* Zheng et al. [2023] C. Zheng, G. Wu, F. Bao, Y. Cao, C. Li, and J. Zhu. Revisiting discriminative vs. generative classifiers: Theory and implications. In _International Conference on Machine Learning_, pages 42420-42477, 2023.

###### Contents of Appendix

* A Proof of realizable \(\mathcal{H}\)-consistency
* B Proof of \(\mathcal{H}\)-consistency bounds
* B.1 Auxiliary lemma
* B.2 \(\Psi(t)=1-t\)
* B.3 \(\Psi(t)=-\log(t)\)
* B.4 \(\Psi(t)=\frac{1}{q}(1-t^{q})\)
* C Proof of Theorem 5.1
* D Future work
Proof of realizable \(\mathcal{H}\)-consistency

**Theorem 4.1**.: _Assume that \(\mathcal{H}\) is closed under scaling. Suppose that \(\Psi\) is non-increasing, \(\Psi\big{(}\frac{2}{3}\big{)}>0\) and \(\lim_{t\to 1}\Psi(t)=0\). Then, the surrogate loss \(\mathsf{L}_{\mathrm{RL2D}}\) is realizable \(\mathcal{H}\)-consistent with respect to \(\mathsf{L}_{\mathrm{def}}\)._

Proof.: We first prove that for every \((h,x,y)\in\mathcal{H}\times\mathcal{X}\times\mathcal{Y}\), the following inequality holds:

\[\mathsf{L}_{\mathrm{def}}(h,x,y)\leq\frac{\mathsf{L}_{\mathrm{RL2D}}(h,x,y)}{ \Psi\big{(}\frac{2}{3}\big{)}}.\]

We will analyze case by case.

1. **Case I**: If \(\mathsf{h}(x)\in[n]\) (deferral does not occur): 1. If \(1_{\mathsf{h}(x)*y}=1\), then we must have \[\mathsf{L}_{\mathrm{def}}(h,x,y)=1,\quad\frac{e^{h(x,y)}}{\sum_{y^{ \prime}\in\overline{y}}e^{h(x,y^{\prime})}}\leq\frac{1}{2},\quad\frac{e^{h(x, y)}+e^{h(x,n+1)}}{\sum_{y^{\prime}\in\overline{y}}e^{h(x,y^{\prime})}}\leq \frac{2}{3}\] 2. If \(1_{\mathsf{h}(x)*y}=0\), then we must have \[\mathsf{L}_{\mathrm{RL2D}}(h,x,y)\geq 0=\mathsf{L}_{\mathrm{def}}(h,x,y).\]
2. **Case II**: If \(\mathsf{h}(x)=n+1\) (deferral occurs): then we must have \[\mathsf{L}_{\mathrm{def}}(h,x,y)=c(x,y),\quad\frac{e^{h(x,y)}}{ \sum_{y^{\prime}\in\overline{y}}e^{h(x,y^{\prime})}}\leq\frac{1}{2}\] \[\implies\mathsf{L}_{\mathrm{RL2D}}(h,x,y)\geq c(x,y)\Psi\bigg{(} \frac{1}{2}\bigg{)}\geq\Psi\bigg{(}\frac{2}{3}\bigg{)}\mathsf{L}_{\mathrm{def} }(h,x,y).\]

This concludes that \(\mathsf{L}_{\mathrm{def}}(h,x,y)\leq\frac{\mathsf{L}_{\mathrm{RL2D}}(h,x,y)}{ \Psi\big{(}\frac{2}{3}\big{)}}\). Next, we prove that \(\mathsf{L}_{\mathrm{RL2D}}\) is realizable \(\mathcal{H}\)-consistent under the assumptions. Consider a distribution and an expert under which there exists a zero error solution \(h^{*}\in\mathcal{H}\) with \(\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h^{*})=0\). Let \(\hat{h}\) be the minimizer of the surrogate loss: \(\hat{h}\in\operatorname*{argmin}_{h\in\mathcal{H}}\mathcal{E}_{\mathsf{L}_{ \mathrm{RL2D}}}(h)\). Let \(\alpha\) be any real number. Then, the following inequality holds:

\[\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(\hat{h}) \leq\frac{1}{\Psi\big{(}\frac{2}{3}\big{)}}\mathcal{E}_{\mathsf{ L}_{\mathrm{RL2D}}}(\hat{h})\] ( \[\mathsf{L}_{\mathrm{def}}\leq\frac{1}{\Psi\big{(}\frac{2}{3}\big{)} }\mathcal{L}_{\mathrm{RL2D}}\] ) \[\leq\frac{1}{\Psi\big{(}\frac{2}{3}\big{)}}\mathcal{E}_{\mathsf{ L}_{\mathrm{RL2D}}}(\alpha h^{*})\] ( \[\hat{h}\in\operatorname*{argmin}_{h\in\mathcal{H}}\mathcal{E}_{ \mathsf{L}_{\mathrm{RL2D}}}(h)\]  and \[\mathcal{H}\] is closed under scaling) \[=\frac{1}{\Psi\big{(}\frac{2}{3}\big{)}}\mathbb{E}\big{[} \mathsf{L}_{\mathrm{RL2D}}(\alpha h^{*},x,y)\,|\,\mathsf{h}^{*}(x)=n+1]\mathbb{P }(\mathsf{h}^{*}(x)=n+1)\] \[\qquad+\frac{1}{\Psi\big{(}\frac{2}{3}\big{)}}\mathbb{E}\big{[} \mathsf{L}_{\mathrm{RL2D}}(\alpha h^{*},x,y)\,|\,\mathsf{h}^{*}(x)\in[n]\big{]} \mathbb{P}(\mathsf{h}^{*}(x)\in[n]\big{)}.\]

For the first term conditional on \(\mathsf{h}^{*}(x)=n+1\), we must have \(h^{*}(x,n+1)>\max_{y\in y}h^{*}(x,y)\) and \(c(x,y)=0\) since the data is realizable. Therefore,

\[\lim_{\alpha\to+\infty}\mathbb{E}\big{[}\mathsf{L}_{\mathrm{RL2D}} (\alpha h^{*},x,y)\,|\,\mathsf{h}^{*}(x)=n+1\big{]}\mathbb{P}(\mathsf{h}^{*}(x )=n+1)\] \[=\mathbb{E}\big{[}0\,|\,\mathsf{h}^{*}(x)=n+1\big{]}\mathbb{P}( \mathsf{h}^{*}(x)=n+1)\] \[=0.\]For the second term conditional on \(\mathsf{h}^{*}(x)\in[n]\), we must have \(h^{*}(x,y)>\max_{y^{\prime}\in\overline{\mathsf{y}},y^{\prime}=y}h(x,y^{\prime})\) since the data is realizable. Therefore,

\[\lim_{\alpha\to+\infty}\mathbb{E}[\mathsf{L}_{\mathrm{RL2D}}( \alpha h^{*},x,y)\mid\mathsf{h}^{*}(x)\in[n]]\mathbb{P}(\mathsf{h}^{*}(x)\in[n])\] \[=\lim_{\alpha\to+\infty}\mathbb{E}\Bigg{[}c(x,y)\Psi\Bigg{(} \frac{e^{\alpha h^{*}(x,y)}}{\sum_{y^{\prime}\in\overline{\mathsf{y}}}e^{ \alpha h^{*}(x,y^{\prime})}}\Bigg{)}\] \[\qquad+(1-c(x,y))\Psi\Bigg{(}\frac{e^{\alpha h^{*}(x,y)}+e^{ \alpha h^{*}(x,n+1)}}{\sum_{y^{\prime}\in\overline{\mathsf{y}}}e^{\alpha h^{* }(x,y^{\prime})}}\Bigg{)}\mid\mathsf{h}^{*}(x)\in[n]\Bigg{]}\mathbb{P}( \mathsf{h}^{*}(x)\in[n])\] \[=\mathbb{E}[0\mid\mathsf{h}^{*}(x)\in[n]]\mathbb{P}(\mathsf{h}^{ *}(x)\in[n])\qquad(\lim_{t\to 1}\Psi(t)=0\text{ and monotone convergence theorem})\] \[=0.\]

Combining the two analyses, we conclude that \(\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(\hat{h})=0\) and thus \(\mathsf{L}_{\mathrm{RL2D}}\) is realizable \(\mathcal{H}\)-consistent with respect to \(\mathsf{L}_{\mathrm{def}}\). 

## Appendix B Proof of \(\mathcal{H}\)-consistency bounds

Before delving into the proof, we first establish some essential notation and definitions. Let \(\mathsf{L}\) represent a deferral surrogate loss and \(\mathcal{H}\) denote a hypothesis set. We define the conditional error as \(\mathcal{C}_{\mathsf{L}}(h,x)=\mathbb{E}_{y|x}[\mathsf{L}(h,x)]\), the best-in-class conditional error as \(\mathcal{C}_{\mathsf{L}}^{*}(\mathcal{H},x)=\inf_{h\in\mathcal{H}}\mathcal{C} _{\mathsf{L}}(h,x)\), and the conditional regret as \(\Delta\mathcal{C}_{\mathsf{L},\mathcal{H}}(h,x)=\mathcal{C}_{\mathsf{L}}(h,x) -\mathcal{C}_{\mathsf{L}}^{*}(\mathcal{H},x)\). We proceed to present a general theorem demonstrating that, to establish \(\mathcal{H}\)-consistency bounds (1) with a concave function \(\Gamma\), it suffices to lower bound the conditional regret of the surrogate loss by that of the deferral loss, using the same function \(\Gamma\).

**Theorem B.1**.: _If the following holds for all \(h\in\mathcal{H}\) and \(x\in\mathcal{X}\), for some concave function \(\Gamma\):_

\[\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{def}},\mathcal{H}}(h,x)\leq\Gamma( \Delta\mathcal{C}_{\mathsf{L},\mathcal{H}}(h,x)),\] (4)

_then, for all hypotheses \(h\in\mathcal{H}\) and for any distribution,_

\[\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{ def}}}^{*}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{def}}}(\mathcal{H}) \leq\Gamma(\mathcal{E}_{\mathsf{L}}(h)-\mathcal{E}_{\mathsf{L}}^{*}(\mathcal{H })+\mathcal{M}_{\mathsf{L}}(\mathcal{H})).\]

Proof.: We can express the expectations of the conditional regrets for \(\mathsf{L}_{\mathrm{def}}\) and \(\mathsf{L}\) as follows:

\[\mathbb{E}_{x}[\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{def}}, \mathcal{H}}(h,x)] =\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h)-\mathcal{E}_{\mathsf{ L}_{\mathrm{def}}}^{*}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{def}}}( \mathcal{H})\] \[\mathbb{E}_{x}[\Delta\mathcal{C}_{\mathsf{L},\mathcal{H}}(h,x)] =\mathcal{E}_{\mathsf{L}}(h)-\mathcal{E}_{\mathsf{L}}^{*}(\mathcal{H })+\mathcal{M}_{\mathsf{L}}(\mathcal{H}).\]

Then, by using (4) and taking the expectation, we obtain:

\[\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h)-\mathcal{E}_{\mathsf{ L}_{\mathrm{def}}}^{*}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{def}}}( \mathcal{H}) =\mathbb{E}_{x}[\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{def}}, \mathcal{H}}(h,x)]\] \[\leq\mathbb{E}_{x}[\Gamma(\Delta\mathcal{C}_{\mathsf{L},\mathcal{H} }(h,x))]\] (Eq. ( 4 ) \[\leq\Gamma\Big{(}\mathbb{E}_{x}[\Delta\mathcal{C}_{\mathsf{L}, \mathcal{H}}(h,x)]\Big{)}\] (concavity of \[\Gamma\] ) \[=\Gamma(\mathcal{E}_{\mathsf{L}}(h)-\mathcal{E}_{\mathsf{L}}^{*}( \mathcal{H})+\mathcal{M}_{\mathsf{L}}(\mathcal{H})).\]

Thus, the proof is complete. 

Next, to prove \(\mathcal{H}\)-consistency bounds using Theorem B.1, we will characterize the conditional regret of the deferral loss \(\mathsf{L}_{\mathrm{def}}\) in the following section.

### Auxiliary lemma

To simplify the presentation, we introduce the following notation. For any \(y\in\mathcal{Y}\), define \(p(x,y)=\mathbb{P}(Y=y\mid X=x)\) as the conditional probability that \(Y=y\) given \(X=x\). For brevity, we will omit the dependency on \(x\) in our notation. We denote by \(h_{y}=h(x,y)\) for any \(y\in\overline{\mathcal{Y}}\). We also denote by \(p_{y}=p(x,y)\) and \(q_{y}=p(x,y)c(x,y)\) for any \(y\in\mathcal{Y}\), and \(p_{n+1}=\sum_{y\in\mathcal{Y}}p(x,y)(1-c(x,y))\)Note that \(p(x,y)(1-c(x,y))=p_{y}-q_{y}\), \(\forall\,y\in\mathcal{Y}\). Let \(p_{\text{h}}=p_{\text{h}(x)}=\begin{cases}p_{\text{h}(x)}&\text{h}(x)\in[n]\\ p_{n+1}&\text{h}(x)=n+1.\end{cases}\). Let \(y_{\max}=\operatorname*{argmax}_{y\in\mathcal{Y}}p_{y}\) and \(h_{\max}=\operatorname*{argmax}_{y\in\mathcal{Y}}h_{y}\). Note that both \(y_{\max}\) and \(h_{\max}\) are in the label space \(\mathcal{Y}\), while \(\text{h}(x)\) is in the augmented label space \(\overline{y}\). We characterize the conditional regret of the deferral loss \(\mathsf{L}_{\mathrm{def}}\) as follows.

**Lemma B.2**.: _Assume that \(\mathcal{H}\) is symmetric and complete. Then, the conditional regret of the deferral loss \(\mathsf{L}_{\mathrm{def}}\) can be expressed as follows: \(\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{def}},\mathcal{H}}(h,x)=\max\{p_{y_{ \max}},p_{n+1}\}-p_{\text{h}}\)._

Proof.: We can write the conditional error of the deferral loss as follows:

\[\mathcal{C}_{\mathsf{L}_{\mathrm{def}}}(h,x)\] \[=\sum_{y\in\mathcal{Y}}p(x,y)\mathsf{L}_{\mathrm{def}}(h,x,y)\] \[=\sum_{y\in\mathcal{Y}}p(x,y)1_{\text{h}(x)\neq y}1_{\text{h}(x) \in[n]}+\sum_{y\in\mathcal{Y}}p(x,y)c(x,y)1_{\text{h}(x)=n+1}\] \[=(1-p_{\text{h}(x)})1_{\text{h}(x)\in[n]}+(1-p_{n+1})1_{\text{h}( x)=n+1}\] \[=1-p_{\text{h}}.\]

Since \(\mathcal{H}\) is symmetric and complete, for any \(x\in\mathcal{X}\), \(\{\text{h}(x)\colon h\in\mathcal{H}\}=\overline{\mathcal{Y}}\). Then, the best-in-class conditional error of \(\mathsf{L}_{\mathrm{def}}\) can be expressed as follows:

\[\mathcal{C}^{*}_{\mathsf{L}_{\mathrm{def}}}(\mathcal{H},x)=\inf_{h\in\mathcal{H }}\mathcal{C}_{\mathsf{L}_{\mathrm{def}}}(h,x)=1-\max\{p_{n+1},p_{y_{\max}}\}\] (5)

Therefore, \(\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{def}},\mathcal{H}}(h,x)=\mathcal{C}_{ \mathsf{L}_{\mathrm{def}}}(h,x)-\mathcal{C}^{*}_{\mathsf{L}_{\mathrm{def}}}( \mathcal{H},x)=\max\{p_{y_{\max}},p_{n+1}\}-p_{\text{h}}\). 

Next, we will present the proofs separately in the following sections, by lower bounding the conditional regret of the surrogate loss \(\mathsf{L}\) by that of the deferral loss \(\mathsf{L}_{\mathrm{def}}\) using Lemma B.2.

### \(\Psi(t)=1-t\)

**Theorem B.3**.: _Assume that \(\mathcal{H}\) is symmetric and complete. Then, for all \(h\in\mathcal{H}\) and any distribution, the following \(\mathcal{H}\)-consistency bound holds:_

\[\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{ def}}}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{def}}}(\mathcal{H})\leq n \big{(}\mathcal{E}_{\mathsf{L}_{\mathrm{RL2D}}}(h)-\mathcal{E}_{\mathsf{L}_{ \mathrm{RL2D}}}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{RL2D}}}(\mathcal{ H})\big{)}.\]

Proof.: We can write the conditional error of the surrogate loss as follows:

\[\mathcal{C}_{\mathsf{L}_{\mathrm{RL2D}}}(h,x)\] \[=\sum_{y\in\mathcal{Y}}p(x,y)\mathsf{L}_{\mathrm{RL2D}}(h,x,y)\] \[=\sum_{y\in\mathcal{Y}}p(x,y)c(x,y)\Bigg{(}1-\frac{e^{h(x,y)}}{ \sum_{y^{\prime}\in\overline{\mathcal{Y}}}e^{h(x,y^{\prime})}}\Bigg{)}+\sum_{y \in\mathcal{Y}}p(x,y)\big{(}1-c(x,y)\big{)}\Bigg{(}1-\frac{e^{h(x,y)}+e^{h(x,n+ 1)}}{\sum_{y^{\prime}\in\overline{\mathcal{Y}}}e^{h(x,y^{\prime})}}\Bigg{)}\] \[=\sum_{y\in\mathcal{Y}}q_{y}\Bigg{(}1-\frac{e^{h_{y}}}{\sum_{y^{ \prime}\in\overline{\mathcal{Y}}}e^{h_{y^{\prime}}}}\Bigg{)}+\sum_{y\in \mathcal{Y}}\big{(}p_{y}-q_{y}\Bigg{)}\Bigg{(}1-\frac{e^{h_{y}}+e^{h_{n+1}}}{ \sum_{y^{\prime}\in\overline{\mathcal{Y}}}e^{h_{y^{\prime}}}}\Bigg{)}.\]

By Lemma B.2, the conditional regret of the deferral loss can be expressed as

\[\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{def}},\mathcal{H}}(h,x)=\max\{p_{y_{ \max}},p_{n+1}\}-p_{\text{h}}.\]

Next, we will show that the conditional regret of the surrogate loss can be lower bounded as follows:

\[\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{RL2D}},\mathcal{H}}(h,x)=\mathcal{C}_{ \mathsf{L}_{\mathrm{RL2D}}}(h)-\mathcal{C}^{*}_{\mathsf{L}_{\mathrm{RL2D}}}( \mathcal{H})\geq\frac{1}{n+1}\big{(}\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{ def}},\mathcal{H}}(h,x)\big{)}.\] (6)We first prove that for any hypothesis \(h\) and \(x\in\mathcal{X}\), if \(y_{\max}\neq h_{\max}\), then the conditional error of \(h\) can be lower bounded by that of \(\overline{h}\), which satisfies that \(\overline{h}(x,y)=\begin{cases}h_{h_{\max}}&y=y_{\max}\\ h_{y_{\max}}&y=h_{\max}\\ h_{y}&\text{otherwise}.\end{cases}\). Indeed,

\[\mathcal{C}_{\text{LRL2D}}(h)-\mathcal{C}_{\text{LRL2D}}(\overline{h}) =q_{y_{\max}}\Bigg{(}1-\frac{e^{h_{y_{\max}}}}{\sum_{y^{\prime}\in \overline{y}}e^{h_{y^{\prime}}}}\Bigg{)}+(p_{y_{\max}}-q_{y_{\max}})\Bigg{(}1- \frac{e^{h_{y_{\max}}}+e^{h_{n+1}}}{\sum_{y^{\prime}\in\overline{y}}e^{h_{y^{ \prime}}}}\Bigg{)}\] \[\qquad+q_{h_{\max}}\Bigg{(}1-\frac{e^{h_{h_{\max}}}}{\sum_{y^{ \prime}\in\overline{y}}e^{h_{y^{\prime}}}}\Bigg{)}+(p_{h_{\max}}-q_{h_{\max}} )\Bigg{(}1-\frac{e^{h_{h_{\max}}}+e^{h_{n+1}}}{\sum_{y^{\prime}\in\overline{y }}e^{h_{y^{\prime}}}}\Bigg{)}\] \[\qquad-q_{y_{\max}}\Bigg{(}1-\frac{e^{h_{h_{\max}}}}{\sum_{y^{ \prime}\in\overline{y}}e^{h_{y^{\prime}}}}\Bigg{)}-(p_{y_{\max}}-q_{y_{\max}} )\Bigg{(}1-\frac{e^{h_{h_{\max}}}+e^{h_{n+1}}}{\sum_{y^{\prime}\in\overline{y }}e^{h_{y^{\prime}}}}\Bigg{)}\] \[\qquad-q_{h_{\max}}\Bigg{(}1-\frac{e^{h_{\max}}}{\sum_{y^{\prime }\in\overline{y}}e^{h_{y^{\prime}}}}\Bigg{)}-(p_{h_{\max}}-q_{h_{\max}}) \Bigg{(}1-\frac{e^{h_{y_{\max}}}+e^{h_{n+1}}}{\sum_{y^{\prime}\in\overline{y }}e^{h_{y^{\prime}}}}\Bigg{)}\] \[=\frac{1}{\sum_{y^{\prime}\in\overline{y}}e^{h_{y^{\prime}}}}(p_{ y_{\max}}-p_{h_{\max}})\big{(}e^{h_{h_{\max}}}-e^{h_{y_{\max}}}\big{)} \geq 0.\]

Therefore, we only need to lower bound the conditional regret of hypothesis \(h\) satisfying \(y_{\max}=h_{\max}\). Next, we will analyze case by case. Note that when \((p_{y_{\max}}-p_{n+1})(h_{y_{\max}}-h_{n+1})>0\), we have \(\Delta\mathcal{C}_{\text{L}_{\text{Ldef}},\mathcal{H}}(h,x)=\max\{p_{y_{\max}},p_{n+1}\}-p_{\text{h}}=0\).

1. **Case I**: If \(p_{y_{\max}}-p_{n+1}\geq 0\) and \(h_{y_{\max}}-h_{n+1}\leq 0\): we define a new hypothesis \(h_{\mu}\) such that \(h_{\mu}(x,y)=\begin{cases}\log\big{(}e^{h_{n+1}}+\mu\big{)}&y=y_{\max}\\ \log\big{(}e^{h_{y_{\max}}}-\mu\big{)}&y=n+1\\ h(x,y)&\text{otherwise}.\end{cases}\), where \(e^{h_{y_{\max}}}\geq\mu\geq 0\). Then, we can lower bound the conditional regret of \(\text{L}_{\text{RL2D}}\) by using \(\Delta\mathcal{C}_{\text{L}_{\text{RL2D}},\mathcal{H}}(h,x)\geq\mathcal{C}_{ \text{L}_{\text{RL2D}}}(h)-\mathcal{C}_{\text{L}_{\text{RL2D}}}^{*}(h_{\mu})\) for any \(e^{h_{y_{\max}}}\geq\mu\geq 0\): \[\Delta\mathcal{C}_{\text{L}_{\text{RL2D}},\mathcal{H}}(h,x)\] \[\geq\sup_{e^{h_{y_{\max}}}\geq\mu\geq 0}\Bigg{(}q_{y_{\max}} \Bigg{(}1-\frac{e^{h_{y_{\max}}}}{\sum_{y^{\prime}\in\overline{y}}e^{h_{y^{ \prime}}}}\Bigg{)}+(p_{y_{\max}}-q_{y_{\max}})\Bigg{(}1-\frac{e^{h_{y_{\max}}} +e^{h_{n+1}}}{\sum_{y^{\prime}\in\overline{y}}e^{h_{y^{\prime}}}}\Bigg{)}\] \[\qquad+\sum_{y^{\prime}\in\mathcal{Y},y^{\prime}y_{\max}}(p_{y^{ \prime}}-q_{y^{\prime}})\Bigg{(}1-\frac{e^{h_{y^{\prime}}}+e^{h_{n+1}}}{\sum_{y ^{\prime}\in\overline{y}}e^{h_{y^{\prime}}}}\Bigg{)}\] \[\qquad-q_{y_{\max}}\Bigg{(}1-\frac{e^{h_{n+1}}+\mu}{\sum_{y^{ \prime}\in\overline{y}}e^{h_{y^{\prime}}}}\Bigg{)}-(p_{y_{\max}}-q_{y_{\max}} )\Bigg{(}1-\frac{e^{h_{n+1}}+e^{h_{h_{\max}}}}{\sum_{y^{\prime}\in\overline{y} }e^{h_{y^{\prime}}}}\Bigg{)}\Bigg{)}\] \[\qquad-\sum_{y^{\prime}\in\mathcal{Y},y^{\prime}y_{\max}}(p_{y^{ \prime}}-q_{y^{\prime}})\Bigg{(}1-\frac{e^{h_{y^{\prime}}}+e^{h_{y_{\max}}}-\mu}{ \sum_{y^{\prime}\in\overline{y}}e^{h_{y^{\prime}}}}\Bigg{)}\] \[=\frac{1}{\sum_{y^{\prime}\in\overline{y}}e^{h_{y^{\prime}}}}\sup_{e ^{h_{y}}\max\mu\geq 0}\big{(}q_{y_{\max}}\big{(}e^{h_{n+1}}+\mu-e^{h_{y_{\max}}} \big{)}+(p_{n+1}-p_{y_{\max}}+q_{y_{\max}})\big{(}e^{h_{y_{\max}}}-\mu-e^{h_{n +1}}\big{)}\big{)}\] \[=(p_{y_{\max}}-p_{n+1})\frac{e^{h_{n+1}}}{\sum_{y^{\prime}\in \overline{y}}e^{h_{y^{\prime}}}}\hskip 113.811024pt(\mu=e^{h_{y_{\max}}}\text{ achieves the maximum})\] \[\geq\frac{1}{n+1}\big{(}p_{y_{\max}}-p_{n+1})\hskip 113.811024pt( \text{by the assumption }h_{n+1}\geq h_{y_{\max}}=h_{h_{\max}})\] \[=\frac{1}{n+1}(\Delta\mathcal{C}_{\text{Ldef}},\mathcal{H}}(h,x)) \hskip 28.452756pt(\text{by the assumption }p_{y_{\max}}\geq p_{n+1}\text{ and }h_{y_{\max}}-h_{n+1}\leq 0)\]

[MISSING_PAGE_FAIL:22]

### \(\Psi(t)=-\log(t)\)

**Theorem B.4**.: _Assume that \(\mathcal{H}\) is symmetric and complete. Assume that \(c(x,y)=1_{\mathsf{g}(x)*y}\). Then, for all \(h\in\mathcal{H}\) and any distribution, the following \(\mathcal{H}\)-consistency bound holds:_

\[\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{ def}}}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{def}}}(\mathcal{H})\leq 2\sqrt{ \mathcal{E}_{\mathsf{L}_{\mathrm{RL2D}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{ RL2D}}}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{RL2D}}}(\mathcal{H})}.\]

Proof.: We can write the conditional error of the surrogate loss as follows:

\[\mathcal{C}_{\mathsf{L}_{\mathrm{RL2D}}}(h,x)\] \[=\sum_{y\in\mathfrak{f}}p(x,y)\mathsf{L}_{\mathrm{RL2D}}(h,x,y)\] \[=-\sum_{y\in\mathfrak{f}}q_{y}\log\!\left(\frac{e^{h_{y}}}{\sum_ {y^{\prime}\in\mathfrak{f}}e^{h_{y^{\prime}}}}\right)-\sum_{y\in\mathfrak{f}}( p_{y}-q_{y})\log\!\left(\frac{e^{h_{y}}+e^{h_{n+1}}}{\sum_{y^{\prime}\in\mathfrak{f}}e ^{h_{y^{\prime}}}}\right).\]

By Lemma B.2, the conditional regret of the deferral loss can be expressed as

\[\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{def}},\mathcal{H}}(h,x)=\max\{p_{y_{ \max}},p_{n+1}\}-p_{\mathrm{h}}.\]

Next, we will show that the conditional regret of the surrogate loss can be lower bounded as follows:

\[\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{RL2D}},\mathcal{H}}(h,x)=\mathcal{C}_{ \mathsf{L}_{\mathrm{RL2D}}}(h)-\mathcal{C}_{\mathsf{L}_{\mathrm{RL2D}}}^{*}( \mathcal{H})\geq\frac{1}{2}\big{(}\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{def} },\mathcal{H}}(h,x)\big{)}^{2}.\] (7)

We first consider the case where \(\mathsf{g}(x)\neq y_{\max}\). Otherwise, it would be straightforward to see that the bound holds. In the case where \(\mathsf{g}(x)\neq y_{\max}\), we have \(q_{y_{\max}}=p_{y_{\max}}\). We first prove that for any hypothesis \(h\) and \(x\in\mathcal{X}\), if \(y_{\max}\neq h_{\max}\), then the conditional error of \(h\) can be lower bounded by that of \(\overline{h}\), which satisfies that \(\overline{h}(x,y)=\begin{bmatrix}h_{h_{\max}}&y=y_{\max}\\ h_{y_{\max}}&y=h_{\max}\\ h_{y}&\text{otherwise}.\end{bmatrix}\)

\[\mathcal{C}_{\mathsf{L}_{\mathrm{RL2D}}}(h)-\mathcal{C}_{\mathsf{L}_{ \mathrm{RL2D}}}(\overline{h})\] \[=-q_{y_{\max}}\log\!\left(\frac{e^{h_{y_{\max}}}}{\sum_{y^{ \prime}\in\mathfrak{f}}e^{h_{y^{\prime}}}}\right)-(p_{y_{\max}}-q_{y_{\max}}) \log\!\left(\frac{e^{h_{y_{\max}}}+e^{h_{n+1}}}{\sum_{y^{\prime}\in\mathfrak{f }}e^{h_{y^{\prime}}}}\right)\] \[\quad\quad-q_{h_{\max}}\log\!\left(\frac{e^{h_{h_{\max}}}}{\sum_ {y^{\prime}\in\mathfrak{f}}e^{h_{y^{\prime}}}}\right)-(p_{h_{\max}}-q_{h_{ \max}})\log\!\left(\frac{e^{h_{h_{\max}}}+e^{h_{n+1}}}{\sum_{y^{\prime}\in \mathfrak{f}}e^{h_{y^{\prime}}}}\right)\] \[\quad\quad+q_{y_{\max}}\log\!\left(\frac{e^{h_{h_{\max}}}}{\sum_ {y^{\prime}\in\mathfrak{f}}e^{h_{y^{\prime}}}}\right)+(p_{y_{\max}}-q_{y_{ \max}})\log\!\left(\frac{e^{h_{h_{\max}}}+e^{h_{n+1}}}{\sum_{y^{\prime}\in \mathfrak{f}}e^{h_{y^{\prime}}}}\right)\] \[\quad\quad+q_{h_{\max}}\log\!\left(\frac{e^{h_{y_{\max}}}}{\sum_ {y^{\prime}\in\mathfrak{f}}e^{h_{y^{\prime}}}}\right)+(p_{h_{\max}}-q_{h_{ \max}})\log\!\left(\frac{e^{h_{y_{\max}}}+e^{h_{n+1}}}{\sum_{y^{\prime}\in \mathfrak{f}}e^{h_{y^{\prime}}}}\right)\] \[=(q_{y_{\max}}-q_{h_{\max}})\log\!\left(\frac{e^{h_{h_{\max}}}}{e ^{h_{y_{\max}}}}\right)+(p_{y_{\max}}-q_{y_{\max}}-p_{h_{\max}}+q_{h_{\max}}) \log\!\left(\frac{e^{h_{h_{\max}}}+e^{h_{n+1}}}{e^{h_{y_{\max}}}+e^{h_{n+1}}}\right)\] \[\geq(p_{y_{\max}}-p_{h_{\max}})\log\!\left(\frac{e^{h_{h_{\max}}} +e^{h_{n+1}}}{e^{h_{y_{\max}}}+e^{h_{n+1}}}\right)\] \[\geq 0.\]

Therefore, we only need to lower bound the conditional regret of hypothesis \(h\) satisfying \(y_{\max}=h_{\max}\). Since \(c(x,y)=1_{\mathsf{g}(x)*y}\), we have \(p_{y_{\max}}\geq p_{n+1}=p_{\mathsf{g}(x)}\). Note that when \((p_{y_{\max}}-p_{n+1})(h_{y_{\max}}-h_{n+1})>0\), we have \(\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{def}},\mathcal{H}}(h,x)=\max\{p_{y_{\max}},p_{n+1}\}-p_{\mathrm{h}}=0\). When \(h_{y_{\max}}-h_{n+1}\leq 0\), we define a new hypothesis \(h_{\mu}\) such that \(h_{\mu}(x,y)=\begin{cases}\log\!\left(e^{h_{n+1}}+\mu\right)&y=y_{\max}\\ \log\!\left(e^{h_{y_{\max}}}-\mu\right)&y=n+1\\ h(x,y)&\text{otherwise}.\end{cases}\)

[MISSING_PAGE_EMPTY:24]

By applying Pinsker's inequality (Mohri et al., 2018, Proposition E.7), we obtain

\[\Delta\mathcal{C}_{\mathrm{L}_{\mathrm{RLL2D}},\mathcal{H}}(h,x)\] \[\geq\left[q_{y_{\max}}+p_{n+1}-\left(p_{y_{\max}}-q_{y_{\max}} \right)\right]\] \[\qquad\times\frac{1}{2}\Bigg{[}\Bigg{|}\frac{q_{y_{\max}}}{q_{y_ {\max}}+p_{n+1}-\left(p_{y_{\max}}-q_{y_{\max}}\right)}-\frac{1}{2}\Bigg{|}+ \Bigg{|}\frac{p_{n+1}-\left(p_{y_{\max}}-q_{y_{\max}}\right)}{q_{y_{\max}}+p_{ n+1}-\left(p_{y_{\max}}-q_{y_{\max}}\right)}-\frac{1}{2}\Bigg{|}\Bigg{]}^{2}\] \[\geq\frac{1}{2}\frac{\left(p_{y_{\max}}-p_{n+1}\right)^{2}}{q_{y _{\max}}+p_{n+1}-\left(p_{y_{\max}}-q_{y_{\max}}\right)}\] \[\geq\frac{1}{2}(p_{y_{\max}}-p_{n+1})^{2}\] ( \[q_{y_{\max}}+p_{n+1}-\left(p_{y_{\max}}-q_{y_{\max}}\right)\leq 1\] ) \[=\frac{1}{2}\big{(}\Delta\mathcal{C}_{\mathrm{L}_{\mathrm{def}}, \mathcal{H}}(h,x)\big{)}^{2}\] (by the assumption

\[p_{y_{\max}}\geq p_{n+1}\]

 and

\[h_{y_{\max}}\leq h_{n+1}\]

)

This proves the inequality (7). In the case where \(\mathsf{g}(x)=y_{\max}\), we have \(p_{n+1}=p_{y_{\max}}\). By Lemma B.2, the conditional regret of the deferral loss can be expressed as \(\Delta\mathcal{C}_{\mathrm{L}_{\mathrm{def}},\mathcal{H}}(h,x)=p_{n+1}-p_{n}\). If \(\mathsf{h}(x)=n+1\), then we have \(\Delta\mathcal{C}_{\mathrm{L}_{\mathrm{def}},\mathcal{H}}(h,x)=0\). Otherwise, when \(\mathsf{h}(x)\neq n+1\), we can proceed in the similar way as above, by defining a new hypothesis \(h_{\mu}\) such that \(h_{\mu}(x,y)=\begin{cases}\log\bigl{(}e^{h_{n+1}}+\mu\bigr{)}&y=\mathsf{h}(x) \\ \log\bigl{(}e^{h_{\mathsf{h}(x)}}-\mu\bigr{)}&y=n+1\\ h(x,y)&\text{otherwise}\end{cases}.\)

Then, we can lower bound the conditional regret of \(\mathrm{L}_{\mathrm{RLL2D}}\) by using \(\Delta\mathcal{C}_{\mathrm{L}_{\mathrm{RLL2D}},\mathcal{H}}(h,x)\geq\mathcal{ C}_{\mathrm{L}_{\mathrm{RLL2D}}}(h)-\mathcal{C}_{\mathrm{L}_{\mathrm{RLL2D}}}^{*} (h_{\mu})\), by applying the same derivation as above, modulo replacing \(y_{\max}\) with \(\mathsf{h}(x)\). This leads to the inequality (7) as well. By Theorem B.1, we complete the proof.

### \(\Psi(t)=\frac{1}{q}(1-t^{q})\)

**Theorem B.5**.: _Assume that \(\mathcal{H}\) is symmetric and complete. Assume that \(c(x,y)=1_{\mathsf{g}(x)\neq y}\). Then, for all \(h\in\mathcal{H}\) and any distribution, the following \(\mathcal{H}\)-consistency bound holds:_

\[\mathcal{E}_{\mathsf{L}_{\mathrm{def}}}(h)-\mathcal{E}_{\mathsf{L}_{\mathrm{ def}}}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{def}}}(\mathcal{H})\leq 2\sqrt{(n+1)^{ \alpha}(\mathcal{E}_{\mathsf{L}_{\mathrm{RLDD}}}(h)-\mathcal{E}_{\mathsf{L}_{ \mathrm{RLDD}}}(\mathcal{H})+\mathcal{M}_{\mathsf{L}_{\mathrm{RLDD}}}( \mathcal{H}))}.\]

Proof.: We can write the conditional error of the surrogate loss as follows:

\[\mathcal{C}_{\mathsf{L}_{\mathrm{RLDD}}}(h,x) =\sum_{y\in\mathcal{Y}}p(x,y)\mathsf{L}_{\mathrm{RLDD}}(h,x,y)\] \[=\frac{1}{q}\sum_{y\in\mathcal{Y}}p(x,y)c(x,y)\!\left(1-\left( \frac{e^{h(x,y)}}{\Sigma_{y^{\prime}\overline{\epsilon}\overline{y}}\,e^{h(x,y^{\prime})}}\right)^{\!q}\right)\] \[\qquad+\frac{1}{q}\sum_{y\in\mathcal{Y}}p(x,y)(1-c(x,y))\!\left(1 -\left(\frac{e^{h(x,y)}+e^{h(x,n+1)}}{\sum_{y^{\prime}\overline{\epsilon} \overline{y}}e^{h(x,y^{\prime})}}\right)^{\!q}\right)\] \[=\frac{1}{q}\sum_{y\in\mathcal{Y}}q_{y}\!\left(1-\left(\frac{e^{h_ {y}}}{\Sigma_{y^{\prime}\overline{\epsilon}\overline{y}}\,e^{h_{y^{\prime}}}} \right)^{\!q}\right)+\frac{1}{q}\sum_{y\in\mathcal{Y}}(p_{y}-q_{y})\!\left(1- \left(\frac{e^{h_{y}}+e^{h_{n+1}}}{\sum_{y^{\prime}\overline{\epsilon} \overline{y}}e^{h_{y^{\prime}}}}\right)^{\!q}\right)\!.\]

By Lemma B.2, the conditional regret of the deferral loss can be expressed as

\[\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{def}},\mathcal{H}}(h,x)=\max\{p_{y_{ \max}},p_{n+1}\}-p_{n}.\]

Next, we will show that the conditional regret of the surrogate loss can be lower bounded as follows:

\[\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{RLDD}},\mathcal{H}}(h,x)=\mathcal{C}_{ \mathsf{L}_{\mathrm{RLDD}}}(h)-\mathcal{C}_{\mathsf{L}_{\mathrm{RLDD}}}^{*}( \mathcal{H})\geq\frac{1}{2(n+1)^{q}}(\Delta\mathcal{C}_{\mathsf{L}_{\mathrm{ def}},\mathcal{H}}(h,x))^{2}.\] (8)

We first consider the case where \(\mathsf{g}(x)\neq y_{\max}\). Otherwise, it would be straightforward to see that the bound holds. In the case where \(\mathsf{g}(x)\neq y_{\max}\), we have \(q_{y_{\max}}=p_{y_{\max}}\). We first prove that for any hypothesis \(h\) and \(x\in\mathcal{X}\), if \(y_{\max}\neq h_{\max}\), then the conditional error of \(h\) can be lower bounded by that of \(\overline{h}\), which satisfies that \(\overline{h}(x,y)=\begin{pmatrix}h_{h_{\max}}&y=y_{\max}\\ h_{y_{\max}}&y=h_{\max}\\ h_{y}&\text{otherwise}.\end{pmatrix}\)

\[q\!\left(\mathcal{C}_{\mathsf{L}_{\mathrm{RLDD}}}(h)-\mathcal{C}_{ \mathsf{L}_{\mathrm{RLDD}}}(\overline{h})\right)\] \[=q_{y_{\max}}\!\left(1-\left(\frac{e^{h_{y_{\max}}}}{\Sigma_{y^{ \prime}\overline{\epsilon}\overline{y}}\,e^{h_{y^{\prime}}}}\right)^{\!q} \right)+\left(p_{y_{\max}}-q_{y_{\max}}\right)\!\left(1-\!\left(\frac{e^{h_{y_ {\max}}}+e^{h_{n+1}}}{\Sigma_{y^{\prime}\overline{\epsilon}\overline{y}}\,e^{ h_{y^{\prime}}}}\right)^{\!q}\right)\] \[\qquad+q_{h_{\max}}\!\left(1-\left(\frac{e^{h_{h_{\max}}}}{ \Sigma_{y^{\prime}\overline{\epsilon}\overline{y}}\,e^{h_{y^{\prime}}}}\right)^ {\!q}\right)+\left(p_{h_{\max}}-q_{h_{\max}}\right)\!\left(1-\!\left(\frac{e^{h _{h_{\max}}}+e^{h_{n+1}}}{\Sigma_{y^{\prime}\overline{\epsilon}\overline{y}} \,e^{h_{y^{\prime}}}}\right)^{\!q}\right)\] \[\qquad-q_{y_{\max}}\!\left(1-\left(\frac{e^{h_{y_{\max}}}}{ \Sigma_{y^{\prime}\overline{\epsilon}\overline{y}}\,e^{h_{y^{\prime}}}}\right)^ {\!q}\right)-\left(p_{y_{\max}}-q_{y_{\max}}\right)\!\left(1-\!\left(\frac{e^{h _{h_{\max}}}+e^{h_{n+1}}}{\Sigma_{y^{\prime}\overline{\epsilon}\overline{y}} \,e^{h_{y^{\prime}}}}\right)^{\!q}\right)\] \[\qquad-q_{h_{\max}}\!\left(1-\left(\frac{e^{h_{y_{\max}}}}{ \Sigma_{y^{\prime}\overline{\epsilon}\overline{y}}\,e^{h_{y^{\prime}}}}\right)^ {\!q}\right)+\left(p_{h_{\max}}-q_{h_{\max}}\right)\!\left(1-\!\left(\frac{e^{h _{y_{\max}}}+e^{h_{n+1}}}{\Sigma_{y^{\prime}\overline{\epsilon}\overline{y}} \,e^{h_{y^{\prime}}}}\right)^{\!q}\right)\] \[=\left(q_{y_{\max}}-q_{h_{\max}}\right)\!\left[\left(1-\left( \frac{e^{h_{y_{\max}}}}{\Sigma_{y^{\prime}\overline{\epsilon}\overline{y}}\,e^{h_{y ^{\prime}}}}\right)^{\!q}\right)-\left(1-\left(\frac{e^{h_{h_{\max}}}}{\Sigma_{y^{ \prime}\overline{\epsilon}\overline{y}}\,e^{h_{y^{\prime}}}}\right)^{\!q} \right)\right]\] \[\qquad+\left(p_{y_{\max}}-q_{y_{\max}}-p_{h_{\max}}+q_{h_{\max}} \right)\!\left[\left(1-\left(\frac{e^{h_{y_{\max}}}+e^{h_{n+1}}}{\Sigma_{y^{ \prime}\overline{\epsilon}\overline{y}}\,e^{h_{y^{\prime}}}}\right)^{\!q} \right)\!-\left(1-\left(\frac{e^{h_{h_{\max}}}+e^{h_{n+1}}}{\Sigma_{y^{\prime} \overline{\epsilon}\overline{y}}\,e^{h_{y^{\prime}}}}\right)^{\!q}\right)\right]\] \[\geq\left(p_{y_{\max}}-p_{h_{\max}}\right)\!\left[\left(1- \left(\frac{e^{h_{y_{\max}}}+e^{h_{n+1}}}{\Sigma_{y^{\prime}\overline{y}}\,e^{h_{y ^{\prime}}}}\right)^{\!q}\right)\!-\left(1-\left(\frac{e^{h_{h_{\max}}}+e^{h_{n+ 1}}}{\Sigma_{y^{\prime}\overline{\epsilon}\overline{y}}\,e^{h_{y^{\prime}}}} \right)^{\!q}\right)\right]\] \[\geq 0.\]

[MISSING_PAGE_EMPTY:27]

This can be further lower bounded by taking the minimum over \(h\in\mathcal{H}\), where the minimum is attained when \(e^{h_{n+1}}=e^{h_{\mathrm{ymax}}}=e^{h_{\mathrm{y}}}\) for all \(y\in\mathcal{Y}\). Therefore,

\[\Delta\mathcal{C}_{\mathrm{L}_{\mathrm{RL2D}},\mathcal{H}}(h,x)\geq \frac{2}{(n+1)^{q}}\!\left(\!\left(\frac{q_{y_{\max}}^{\frac{1}{1- q}}+\left(p_{n+1}-\left(p_{y_{\max}}-q_{y_{\max}}\right)\right)^{\frac{1}{1-q}}}{2} \right)^{1-q}-\frac{p_{n+1}-p_{y_{\max}}}{2}\right)\] (minimum is attained when \[e^{h_{n+1}}=e^{h_{\mathrm{ymax}}}=e^{h_{\mathrm{y}}},\,\forall y\in \mathcal{Y}\] ) \[\geq\frac{1}{2(n+1)^{q}}(p_{y_{\max}}-p_{n+1})^{2}\] ( \[q_{y_{\max}}+(p_{n+1}-(p_{y_{\max}}-q_{y_{\max}}))\leq 1\] and by analyzing the Taylor expansion) \[=\frac{1}{2(n+1)^{q}}(\Delta\mathcal{C}_{\mathrm{L}_{\mathrm{ def}},\mathcal{H}}(h,x))^{2}\qquad\qquad(p_{y_{\max}}\geq p_{n+1}\text{ and }h_{y_{\max}}\leq h_{n+1})\]

This proves the inequality (8). In the case where \(\mathsf{g}(x)=y_{\max}\), we have \(p_{n+1}=p_{y_{\max}}\). By Lemma B.2, the conditional regret of the deferral loss can be expressed as \(\Delta\mathcal{C}_{\mathrm{L}_{\mathrm{def}},\mathcal{H}}(h,x)=p_{n+1}-p_{ \mathsf{h}}\). If \(\mathsf{h}(x)=n+1\), then we have \(\Delta\mathcal{C}_{\mathrm{L}_{\mathrm{def}},\mathcal{H}}(h,x)=0\). Otherwise, when \(\mathsf{h}(x)\neq n+1\), we can proceed in the similar way as above, by defining a new hypothesis \(h_{\mu}\) such that \(h_{\mu}(x,y)=\begin{cases}\log\!\left(e^{h_{n+1}}+\mu\right)&y=\mathsf{h}(x)\\ \log\!\left(e^{h_{\mathsf{H}}(x)}-\mu\right)&y=n+1\\ h(x,y)&\text{otherwise}\end{cases}.\)

Then, we can lower bound the conditional regret of \(\mathsf{L}_{\mathrm{RL2D}}\) by using \(\Delta\mathcal{C}_{\mathrm{L}_{\mathrm{RL2D}},\mathcal{H}}(h,x)\geq\mathcal{C} _{\mathrm{L}_{\mathrm{RL2D}}}(h)-\mathcal{C}_{\mathrm{LR2D}}^{*}(h_{\mu})\), by applying the same derivation as above, modulo replacing \(y_{\max}\) with \(\mathsf{h}(x)\). This leads to the inequality (8) as well. By Theorem B.1, we complete the proof. 

## Appendix C Proof of Theorem 5.1

**Theorem 5.1**.: _Assume that there exists a zero error solution \(h^{*}\in\mathcal{H}\) with \(\mathcal{E}_{\ell_{0-1}}(h^{*})=0\) and \(\mathcal{H}\) is closed under scaling. Assume that \(\lim_{t\to 1}\Psi(t)=0\). Then, the minimizability gap of comp-sum loss \(\ell_{\mathrm{comp}}\) vanishes: \(\mathcal{M}_{\ell_{\mathrm{comp}}}(\mathcal{H})=0\)._

Proof.: By definition and the Lebesgue dominated convergence theorem, we have

\[\mathcal{M}_{\ell_{\mathrm{comp}}}(\mathcal{H})\leq\mathcal{E}_{\ell_{\mathrm{ comp}}}^{*}(\mathcal{H})\leq\lim_{\alpha\to+\infty}\mathbb{E}\left[\Psi \left(\frac{e^{\alpha h^{*}(x,y)}}{\sum_{y^{\prime}\in\mathcal{H}}e^{\alpha h ^{*}(x,y^{\prime})}}\right)\right]=0.\]

This completes the proof. 

## Appendix D Future work

While we presented a comprehensive study of surrogate loss functions for learning to defer, our work focused on the standard single-expert and single-stage setting, aligning with previous work (Mozannar et al., 2023). However, an interesting direction is to extend our approach to multi-expert (Verma et al., 2023) and two-stage settings (Mao et al., 2023a), which we have left for future work.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: See Section 1. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: See Appendix D. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: See Section 4, Section 5, Appendix A, Appendix B and Appendix C. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: See Section 6. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: See Section 6. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: See Section 6. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: See Table 3. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. ** It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: For each model training, we use an Nvidia A100 GPU. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The authors have reviewed the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: The machine learning community has started to address the fairness implications of involving downstream decision-makers. This represents a broader impact for any learning to defer (L2D) methods. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: See Section 6. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA]. Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.