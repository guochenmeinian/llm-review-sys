Exploring the Optimal Choice for Generative Processes in Diffusion Models: Ordinary vs Stochastic Differential Equations

 Yu Cao &Jingrun Chen &Yixin Luo &Xiang Zhou

Institute of Natural Sciences and School of Mathematical Sciences, Shanghai Jiao Tong University, Shanghai 200240, China, yucao@sjtu.edu.cn University of Science and Technology of China, Hefei 230026, China; Suzhou Institute of Advanced Research, University of Science and Technology of China, Suzhou 215123, China, jingrunchen@ustc.edu.cn University of Science and Technology of China, Hefei 230026, China; Suzhou Institute of Advanced Research, University of Science and Technology of China, Suzhou 215123, China, seeing@mail.ustc.edu.cn School of Data Science and Department of Mathematics, City University of Hong Kong, Kowloon, Hong Kong SAR, xizhou@cityu.edu.hk

###### Abstract

The diffusion model has shown remarkable success in computer vision, but it remains unclear whether the ODE-based probability flow or the SDE-based diffusion model is more superior and under what circumstances. Comparing the two is challenging due to dependencies on data distributions, score training, and other numerical issues. In this paper, we study the problem mathematically for two limiting scenarios: the zero diffusion (ODE) case and the large diffusion case. We first introduce a pulse-shape error to perturb the score function and analyze error accumulation of sampling quality, followed by a thorough analysis for generalization to _arbitrary error_. Our findings indicate that when the perturbation occurs at the end of the generative process, the ODE model outperforms the SDE model with a large diffusion coefficient. However, when the perturbation occurs earlier, the SDE model outperforms the ODE model, and we demonstrate that the error of sample generation due to such a pulse-shape perturbation is exponentially suppressed as the diffusion term's magnitude increases to infinity. Numerical validation of this phenomenon is provided using Gaussian, Gaussian mixture, and Swiss roll distribution, as well as realistic datasets like MNIST and CIFAR-10.

## 1 Introduction

Diffusion models have achieved remarkable success in various artificial intelligence context generation tasks, particularly in computer vision [13]. This technique is rapidly evolving with industrial-level products like DALL-E series. The diffusion model was first proposed and studied by Sohl-Dickstein et al. [26] in 2015. Later, Song and Ermon [29] proposed score matching with Langevin dynamics (SMLD) and Ho et al. [16] further explored the Denoising Diffusion Probabilistic Models (DDPM). Both formalisms can be interpreted as time-discretization of stochastic differential equations (SDEs) [30]. Since the publication of these seminal works, many techniques have been proposed to improve the efficiency and accuracy of diffusion models, such as DDIM [28], Analytic-DPM [4], gDDIM [36], EDM [19], and consistency model [31], among others.

The score-based diffusion model involves two steps [30; 17]. Firstly, one estimates the score function, which is the gradient of the logarithm of the probability density function, in the form of a neural network. This step uses trajectories of an Ornstein-Uhlenbeck (OU) process starting with given data samples. This process of injecting noise into structured data is usually referred to as the _inference process_. Secondly, new samples are generated by simulating a time-reversed SDE, with a drift term depending on the learned score function from the first step. This is known as the _generative process_.

In general, there are two diffusion coefficients \(g\) in the inference process and \(h\) in the generative process; see SS 2. Regardless of the choice of \(h\) and \(g\), it is always possible to design an SDE in the generative process that matches the forward inference process in the weak sense, i.e., the probability density functions match for both processes. We highlight that this function \(h\) (unlike \(g\)) does not only appear in the diffusion term, but also enters the drift term in the generative SDE. The choice of \(g\) is equivalent to time re-scaling (see Appx. B.2), while the choice of \(h\) is an important topic in practice. Two common choices of \(h\) are Probability Flow \(h=0\)[9, 32], which refers to as an ODE, and an SDE-based diffusion model with \(h=g\)[16, 29, 30]. When the score training is accurate, the choice of this function \(h\) does not affect the sample generation quality in the continuous-time setting.

In practice, numerical error is inevitable during training the score function. Recent theoretical works [10, 7] have shown that the sample generation quality are affected by three aspects: (1) the truncation of simulation time to a finite \(T\); (2) the inexact score function; (3) the time-discretization error. The first error is not significantly since the forward OU process converges to the equilibrium Gaussian measure exponentially fast in \(T\). The third error can be reduced systematically by more efficient numerical schemes [21], such as exponential integrator proposed in [35, 36]. The inexact training of score function has a few important but subtle consequences. Recent works [10, 7] analyzed the convergence rate of diffusion models, provided that the score training error is sufficient small. However, once the score training is not accurate, the nice equivalence of the generated distribution free of the generative diffusion coefficient \(h\) no longer holds as in the idealized situation of exact score function. This raises a key question of our interest about how the choice of \(h\) can affect the sample quality in the face of the inexact score training error. Qualitatively, there are two distinctive cases: \(h=0\) or \(h\) is large. An important question to ask is: **in the presence of non-negligible score training errors, which \(h\) will produce better sampling quality?** Is it the probability flow (\(h=0\)) or the SDE? More quantitatively, what magnitude of \(h\) is optimal?

Related worksThe impact of \(h\) on the generative process seems not yet fully investigated in recent literature, as most experiments used the default choice of this parameter. However, some authors have reported related empirical observations. For example, Song et al. [30] empirically observed that the choice of \(h=g\) produces better sample generation quality than the ODE case (\(h=0\)) with real datasets. On the other hand, Denoising Diffusion Implicit Models (DDIM) in [28] includes both deterministic and stochastic samplers and points out that the probability flow (\(h=0\)) can produce better samples with improved numerical schemes for the generative process. [36] generalized the DDIM and tried to explain the advantages of a deterministic sampling scheme over the stochastic one for fast sampling. Moreover, Karras et. al., [19] had empirically searched for optimal coefficients which had shown to bring practical advantages. None of these empirical results delivered comprehensive investigations on the influence of the diffusion coefficient, and a consistent and affirmative answer to our question still awaits. Recently, there has been rapid progress in theoretical works on error analysis for diffusion models, as seen in [10, 7] and references therein. However, these analyses usually assume specific settings of \(h\), such as \(h=g\). Furthermore, it seems that directly analyzing upper bounds based on these error estimations cannot provide adequate information about choosing the optimal \(h\); see Appx. B.4. Albergo et al. proposed a unified framework known as stochastic interpolants and slightly discussed the optimal choice between the probability flow and diffusion models [1, Sec. 2.4]. It is interesting to see how our theoretical analysis below can generalize to their promising unified settings [1].

Our approachTo investigate the effect of the diffusion coefficient \(h\) on sampling quality, we adopt the continuous-time framework, which precludes time discretization errors. We measure sample quality by the KL divergence between the data distribution \(p_{0}\) and the distribution of the generative SDE at the terminal time \(T\). Given the assumption that the score function carries numerical errors, we consider \(h\) as a controller and aim to minimize the KL divergence with respect to \(h\). While the optimization problem is straightforward to set up, it is challenging to draw valuable theoretical insights in a general setting of approximate score functions. Therefore, we choose the asymptotic approach, assuming that the error from the training score is reasonably small with a magnitude of \(\epsilon\). Under this assumption, the leading-order term of the KL divergence takes the form

\[\text{error of sample generation in KL divergence}=L(h)\ \epsilon^{2}+\mathcal{O}\big{(} \epsilon^{3}\big{)}.\]This \(\epsilon^{2}\) order is known in [7; 10], but the dependence of this Gateaux differential \(L(h)\) on \(h\) and other factors has yet to be understood at all. Our contribution is to analyze how \(L(h)\) behaves as \(h\) varies; in particular, by considering the constant \(h\) in two limiting situations: \(h=0\) and \(h\gg 1\).

Main ContributionsWe summarize main contributions below:

* We prove that when the error in score function approximation is a time-localized function only at the beginning of the inference step (i.e., at the end of the generative process), the ODE case (\(h=0\)) outperforms the SDE case (\(h\to\infty\)); see Prop. 3.5. If this (time-localized) error occurs in the middle, then the SDE case has an _exponentially smaller error_ than the ODE case (\(h=0\)), as \(h\to\infty\) (see Prop. 3.4). See Appx. E.4 for reasons behind the time-localized choice.
* For a **general** score training error, we prove that as \(h\to\infty\), the leading-order term \(L(h)\) above converges exponentially fast to a constant, which only depends on the distribution \(p_{0}\) and the score training error at the end of the generative process; see Prop. 3.6. The conclusion about the optimal \(h\) depends on how the score training error is distributed over the time horizon \([0,T]\).

Numerically, we validate the above phenomenon for 1D Gaussian, 2D Gaussian mixture, and Swiss roll distribution, as well as realistic datasets like MNIST and CIFAR-10. Due to the tight connection between the distribution of score training error and \(h\), our results may suggest backwardly modifying loss functions during training to adapt to a particular diffusion coefficient of interest. This is a topic of independent interest and we report some preliminary experiments in Appx. 1 to validate potential applications of our theoretical analysis. A comprehensive investigation will be left as future works.

Notation conventionThe time duration \(T>0\) is a fixed parameter. For any time-dependent function \((t,x)\mapsto f_{t}(x)\), where \(x\in\mathbb{R}^{d}\) and \(t\in[0,T]\), we denote \(f_{t}^{\leftarrow}(x)\equiv f_{T-t}(x)\). Sometimes we directly use the "arrowed" variables \(f_{t}^{\leftarrow}(x)\) to highlight the direction of time is from reference noise to the data distribution (i.e., the generative direction) even without referring to \(f\) first. The notation \(f\lesssim g\) means that \(f\leq cg\) where \(c\to 1\) in a certain limit, i.e., \(\lim\sup^{f}/g\leq 1\); \(f\sim g\) means \(\lim(f/g)=1\). The asymptotic parameter will be explained below explicitly. When two matrices \(A\preceq B\), it means \(B-A\) is positive semidefinite. \(\bm{I}_{d}\) is the \(d\)-dimensional identity matrix; \(\mathbb{I}_{A}\) means an indicator function of a set \(A\); Id is the identity operator. For a random variable \(X\), \(\text{law}(X)\) means the distribution of \(X\). Some important quantities are summarized in Appx. 1.

## 2 Background

Score-based generative modelsSuppose we have a collection of data from an unknown distribution with density \(p_{0}\), we can inject noise into data via the following SDEs:

\[\mathrm{d}X_{t}=f_{t}(X_{t})\;\mathrm{d}t+g_{t}\;\mathrm{d}W_{t},\qquad\text{ law}(X_{0})=p_{0},\] (1)

where the drift coefficient \(f_{(\cdot)}(\cdot):\mathbb{R}^{d}\times\mathbb{R}\to\mathbb{R}^{d}\) is a time-dependent vector field, and the diffusion coefficient \(g_{(\cdot)}:\mathbb{R}\to\mathbb{R}\) is a scalar-valued function (for simplicity). A widely used example is variance-preserving SDE (VP-SDE) with \(f_{t}(x)=-\nicefrac{{1}}{{2}}\;g_{t}^{2}\;x\) and \(g>0\) is typically chosen as a non-decreasing function in literature [30]. Without loss of generality, we can assume \(g_{t}=1\) since for any non-zero \(g\), its effect is simply to re-scale the time; see Appx. 2.

Denote the probability density of \(X_{t}\) as \(p_{t}\) and the score function is defined as \(\nabla\log p_{t}\). One main innovation in diffusion models is to find a "backward" SDE \(Y_{t}\) such that \(Y_{t}\) drives the state with distribution \(p_{T}\) back to \(p_{0}\). We adopt the arrow of time in this backward direction now and write \(Y_{t}\) as

\[\mathrm{d}Y_{t}=A_{t}^{\leftarrow}(Y_{t})\;\mathrm{d}t+h_{t}^{\leftarrow}\; \mathrm{d}W_{t}\,,\qquad\text{law}(Y_{0})=p_{T},\] (2)

where \(h_{t}^{\leftarrow}\) is an arbitrary real-valued function of time. The distribution of \(Y_{t}\) is denoted as \(q_{t}\). Provided that the score function is available, we can select \(A^{\leftarrow}\) such that \(q_{t}\) is the same as \(p_{T-t}\), in particular, \(q_{T}=p_{0}\). It is not hard to derive that we can ensure \(q_{t}\equiv p_{T-t}\) if we choose

\[A_{t}^{\leftarrow}(x)=-f_{t}^{\leftarrow}(x)+\frac{(g_{t}^{\leftarrow})^{2}+ (h_{t}^{\leftarrow})^{2}}{2}\nabla\log p_{t}^{\leftarrow}(x).\] (3)

A self-contained proof is provided in Appx. 1. When \(h^{\leftarrow}=g^{\leftarrow}\), it refers to the backward SDE used in [30]; when \(h^{\leftarrow}=0\), it refers to the probability flow therein. More general interpolation of diffusion and flow can be found in, e.g., [1].

Training of score functionsThe above score function \((t,x)\mapsto\nabla\log p_{t}^{\leftarrow}(x)\) needs to be trained from data. Denoising score matching [33] refers to the following score-matching loss (SML) function to train the score whose parameterized architecture is denoted as \(\mathfrak{S}\):

\[\min_{\mathfrak{S}}\int_{0}^{T}\omega_{t}\;\mathbb{E}_{X_{0}\sim p_{0}}\mathbb{ E}_{X_{t}\sim p_{t|0}(\cdot\left\|X_{0}\right\|}\Big{[}\big{\|}\mathfrak{S}_{t}(X_{t} )-\nabla\log p_{t|0}(X_{t}|X_{0})\big{\|}^{2}\Big{]}\mathrm{d}t,\] (4)

where \(p_{t|0}(x_{t}|x_{0})\) is the transition probability of the state \(x_{0}\) at time \(0\) towards the state \(x_{t}\) at time \(t\) for the forward process (1). The function \(\omega_{t}\geq 0\) is a weight function. The default choice in many literature is that \(g_{t}=\sqrt{\beta_{0}+(\beta_{1}-\beta_{0})t}\), \(0<\beta_{0}<\beta_{1}\) are parameters, and one chooses the weight function as follows:

\[\textbf{Default weight:}\qquad\omega_{t}=\varpi_{t}^{2},\qquad\varpi_{t}= \sqrt{1-e^{-\frac{1}{2}t^{2}(\beta_{1}-\beta_{0})-t\beta_{0}}}.\] (5)

The quantity \(\varpi_{t}\) has the meaning as the standard deviation of \(X_{t}\) conditioned on a fixed \(X_{0}\) in the forward process. See SS 3.7 and Appx. I for more weight functions.

Source of errorsThere is usually intrinsic error due to an inexact score function. It is not negligible in many scenarios, e.g., there is only a finite amount of samples of \(p_{0}\) available or only a small neural network architecture is achievable. However, it is reasonable to assume that this non-negligible error is reasonably small, and we decompose the trained score function \(\mathfrak{S}_{t}^{\leftarrow}\) into

\[\mathfrak{S}_{t}^{\leftarrow}(x)=\nabla\log p_{t}^{\leftarrow}(x)+\epsilon \mathscr{E}_{t}^{\leftarrow}(x),\] (6)

where \(\epsilon\) is small, \(\mathscr{E}_{t}^{\leftarrow}\) is assumed to be \(\mathcal{O}(1)\) and the total error is \(\epsilon\mathscr{E}_{t}^{\leftarrow}\). The generative process used in practice has to use \(\text{law}(Y_{0})=\mathcal{N}(0,I_{d})\) instead since \(p_{T}\) is intractable in (2). By choosing \(T\) large enough so that \(p_{T}\approx\mathcal{N}(0,I_{d})\), we can neglect this error due to the finite \(T\). Besides, we also need some numerical schemes to simulate this generative SDE, which also leads into discretization errors. **In summary**, there are three sources of errors (1) \(p_{T}\neq\mathcal{N}(0,I_{d})\): this is the source of errors in the initial distribution of the generative process; (2) \(\mathscr{E}^{\leftarrow}\neq 0\): error from imperfect score function from training; (3) numerical discretization of the generative process. The third error can be systemically eliminated by choosing a high-order scheme [21] or an extremely small time step. It has been observed that by choosing a more accurate numerical scheme, e.g., exponential integrator, one can reduce the computational costs [35; 36]. As for the first error, if one chooses the OU process for (1), \(p_{T}\) converges to \(\mathcal{N}(0,I_{d})\) exponentially fast and thus \(T=\mathcal{O}(\ln(\delta))\) where \(\delta\) is the error between \(p_{0}\) and the distribution of generated samples. Therefore, the choice of \(T\) is, in practice, not hard to manage. More details about these three error sources can be found in, e.g., [7; 10] or Appx. B.3.

## 3 Asymptotic analysis of terminal errors

We use the KL divergence between the data distribution \(p_{0}\) and the distribution of generated samples to quantify the performance of generative model, which depends on the error of score function \(\epsilon\mathscr{E}^{\leftarrow}\)

Figure 1: _Schematic illustration_ of the main message: the distribution of the score error \(\mathscr{E}_{t}^{\leftarrow}\) w.r.t. time also matters, in addition to the score-matching loss (4). Asymptotically, the score error can be viewed as “additive” and the error from two time regions (blue and green) might decay or magnify as the magnitude of diffusion coefficient \(h^{\leftarrow}\) increases (see the right picture). The yellow region is a transitional region whether the effect of h is not easy to decide.

the diffusion coefficient \(h^{\leftarrow}\), and data distribution \(p_{0}\). To extract the main feature, we first let \(\epsilon\to 0\) and estimate

\[\text{sample generation error in KL divergence}=L(h^{\leftarrow},\mathscr{E}^{ \leftarrow},p_{0})\epsilon^{2}+\mathcal{O}\big{(}\epsilon^{3}\big{)}.\]

Whenever \(p_{0}\) and \(\mathscr{E}^{\leftarrow}\) are obvious from the context, we simply write \(L(h^{\leftarrow})\equiv L(h^{\leftarrow},\mathscr{E}^{\leftarrow},p_{0})\). Next, we formulate the main problem setup and assumptions in SS 3.1. The expression of \(L\) is shown in Prop. 3.2. Then we let \(h_{t}^{\leftarrow}\equiv\text{h}\) be independent of time, and study how the leading order function \(L\) depends on \(\text{h}\) in various settings of the error function \(\mathscr{E}_{t}^{\leftarrow}\). Firstly, we consider \(\mathscr{E}_{t}^{\leftarrow}(x)=\delta_{t-s}E(x)\) as a time-localized function and two limiting scenarios: \(h^{\leftarrow}=\text{h}\) where \(\text{h}=0\) (ODE case) and \(\text{h}\rightarrow\infty\) (SDE case with large diffusion). When \(\mathscr{E}_{t}^{\leftarrow}(x)=\delta_{t-s}E(x)\) is a time-localized function at the end of the generative process (i.e., \(s\) is close to \(T\)), the ODE case will outperform the SDE case (see Prop. 3.5); otherwise, the SDE case has an exponentially smaller error than the ODE case as \(\text{h}\rightarrow\infty\) (see Prop. 3.4). Secondly, by combing Prop. 3.4 and Prop. 3.5, the tail behavior of \(\text{h}\mapsto L(\text{h})\) for a general \(\mathscr{E}^{\leftarrow}\) is described in Prop. 3.6. The reasons behind considering this pulse-shape \(\mathscr{E}_{t}^{\leftarrow}\) will be discussed in Appx. E.4.

### Set-up and assumptions

We fix the time \(T\) and consider the following SDE for the generative process in \(t\in[0,T]\),

\[\mathrm{d}\widetilde{Y}_{t}=\Big{(}-f_{t}^{\leftarrow}(\widetilde{Y}_{t})+ \frac{(g_{t}^{\leftarrow})^{2}+(h_{t}^{\leftarrow})^{2}}{2}\mathfrak{S}_{t}^{ \leftarrow}(\widetilde{Y}_{t})\Big{)}\ \mathrm{d}t+h_{t}^{\leftarrow}\ \mathrm{d}W_{t},\ \ \text{ law}(\widetilde{Y}_{0})=p_{T},\] (7)

which can be regarded as a perturbed equation (2) of \(Y_{t}\). Denote the distribution of \(\widetilde{Y}_{t}\) as \(\widetilde{q}_{t}\). Note that \(\widetilde{q}_{T}\) depends on both \(h^{\leftarrow}\) and \(\epsilon\mathscr{E}_{t}^{\leftarrow}\) (hidden inside \(\mathfrak{S}_{t}^{\leftarrow}\equiv\nabla\log p_{t}^{\leftarrow}+\epsilon \mathscr{E}_{t}^{\leftarrow}\)); however, when \(\epsilon=0\), by (3), \(\widetilde{q}_{T}\equiv q_{T}\equiv p_{0}\) for _any_\(h^{\leftarrow}\). We quantify the sample generation quality via

\[\text{KL}\big{(}p_{0}||\widetilde{q}_{T}\big{)}=\int p_{0}\log(p_{0}/ \widetilde{q}_{T}).\]

Due to the presence of \(\epsilon\mathscr{E}^{\leftarrow}\) with non-zero \(\epsilon\), in general \(\text{KL}\big{(}p_{0}||\widetilde{q}_{T}\big{)}>0\).

**Assumption 3.1**.: _Throughout this section, we assume that:_

1. _For the forward process, we assume_ \(f_{t}(x)=-\frac{1}{2}x\)_,_ \(g_{t}=1\) _without loss of generality._
2. _The data distribution has the density_ \(p_{0}\)_._
3. _There exists_ \(c_{U}\in\mathbb{R}\) _such that_ \(U_{0}(x)-\nicefrac{{|x|^{2}}}{{2}}\geq c_{U}\)_, for any_ \(x\in\mathbb{R}^{d}\)_, where_ \(U_{0}:=-\log p_{0}\)_._

Recall that a generic \(g_{t}\) is equivalent to the time re-scaling (Appx. B.2). So this choice of \(g_{t}=1\) refers to the generic choice in VP-SDE [30]. The second assumption is also mild; in practice, if \(p_{0}\) is a delta distribution, a common practice is that one tries to learn the mollified version \(p_{\sigma}(x):=\int_{\mathbb{R}^{d}}\frac{1}{(2\pi\sigma^{2})^{d/2}}\exp \big{(}-\nicefrac{{(x-y)^{2}}}{{2\sigma^{2}}}\big{)}p_{0}(y)\mathrm{d}y\) instead, as in the GAN [27] and early-stop techniques [7, 10]. The third assumption is not restrict, for example, \(U_{0}(x)=\big{|}x\big{|}^{2}\) and \(c_{U}=0\). As many realistic datasets are almost compactly supported, we expect that \(\rho_{0}=e^{-U_{0}}\) decays faster than a Gaussian, namely, \(\rho_{0}(x)\leq\widetilde{C}e^{-|x|^{2}/2}\) for some \(\widetilde{C}>0\), which reduces to the third one.

### Asymptotic expansion of the KL divergence with respect to \(\epsilon\)

We introduce a time-dependent operator

\[\mathcal{L}_{t}^{(h^{\leftarrow})}(\mu)(x):=-\bm{\nabla}\cdot\Big{(}\big{(} \frac{1}{2}x+\frac{1+h_{t}^{\leftarrow 2}}{2}\nabla\log p_{t}^{\leftarrow}(x)\big{)}\mu(x) \Big{)}+\frac{h_{t}^{\leftarrow 2}}{2}\Delta\mu(x),\] (8)

which is the generator in the Fokker-Planck equation of \(q_{t}\) for (2). Define an operator \(\Phi_{s,t}^{(h^{\leftarrow})}\) as follows: given any function \(\mu\), define \(\Phi_{s,t}^{(h^{\leftarrow})}(\mu)\) to be the solution at time \(t\) of the following Fokker-Planck equation with \(r\in[s,t]\): \(\partial_{r}\theta_{r}=\mathcal{L}_{r}^{(h^{\leftarrow})}(\theta_{r}),\) and with initial condition \(\theta_{s}=\mu\). We define \(\Phi_{s,t}^{(h^{\leftarrow})}(\mu):=\theta_{t}\). Properties of this operator are collected in Appx. C.1.

We use the notation \(\widetilde{q}^{\leftarrow}\) to refer to \(\widetilde{q}\) since we need to calculate the its derivative for the small parameter \(\epsilon\). The dependence of \(\widetilde{q}\) on \(h^{\leftarrow}\) is suppressed for short notations. We have the following asymptotic result with the proof given in Appx. C.3.

**Proposition 3.2**.: _Define \(v_{T}:=\partial_{t}\widetilde{q}^{v}_{T}|_{\epsilon=0}\) as the first-order perturbation of \(\widetilde{q}^{v}_{T}\). We have_

\[\text{KL}\big{(}p_{0}||\widetilde{q}^{v}_{T}\big{)}=L(h^{\leftarrow})\epsilon^ {2}+\mathcal{O}\big{(}\epsilon^{3}\big{)},\] (9)

_where_

\[L(h^{\leftarrow})=\frac{1}{2}\int_{\mathbb{R}^{d}}\frac{v_{T}^{2}(x)}{p_{0}( x)}\;\mathrm{d}x,\qquad v_{T}=-\frac{1}{2}\int_{0}^{T}(1+h_{t}^{\leftarrow -2})\Phi_{t,T}^{(h^{\leftarrow})}\big{(}\boldsymbol{\nabla}\boldsymbol{\cdot }(p_{t}^{\leftarrow}\mathscr{E}_{t}^{\leftarrow})\big{)}\;\mathrm{d}t.\] (10)

### The role of \(h^{\leftarrow}\) in the Fokker-Planck operator \(\mathcal{L}_{t}^{(h^{\leftarrow})}\)

Let the potential \(U_{t}:=-\log p_{t}\), and by the notation of time-reversal, \(U_{t}^{\leftarrow}\equiv U_{T-t}\). When \(h^{\leftarrow}>0\), we can rewrite

\[\mathcal{L}_{t}^{(h^{\leftarrow})}(\mu)=\nicefrac{{h^{\leftarrow}}}{{2}} \Big{(}\bigtriangleup\mu+\boldsymbol{\nabla}\boldsymbol{\cdot}(\nabla V_{t}^{ \leftarrow}\mu)\Big{)},\qquad V_{t}^{\leftarrow}(x):=(1+\nicefrac{{1}}{{h_{t }^{\leftarrow 2}}})U_{t}^{\leftarrow}(x)-\frac{|x|^{2}}{2h_{t}^{\leftarrow 2}}.\] (11)

We now introduce a probability distribution induced by the potential \(V_{t}^{\leftarrow}\):

\[\rho_{t}^{\leftarrow}\propto\exp(-V_{t}^{\leftarrow}).\] (12)

By convection, we also have \(V_{t}=V_{T-t}^{\leftarrow}\) and \(\rho_{t}=\rho_{T-t}^{\leftarrow}\). Note that \(V_{t}^{\leftarrow}\) depends on \(h^{\leftarrow}\) and when \(h^{\leftarrow}\to\infty\), we have \(V_{t}^{\leftarrow,\infty}=U_{t}^{\leftarrow}\). The role of \(h^{\leftarrow}\) in \(\mathcal{L}_{t}^{(h^{\leftarrow})}\) now can be viewed as the time re-scaling and the effect of \(\mathcal{L}_{t}^{(h^{\leftarrow})}\) at a local time \(t\) can be viewed as evolving the Fokker-Planck equation associated with the overdamped Langevin dynamics in the time-dependent potential \(V_{t}^{\leftarrow}\) for \(\mathcal{O}\big{(}\nicefrac{{h_{t}^{\leftarrow}}}{{2}}\big{)}\) amount of time. When \(h^{\leftarrow}\to\infty\), \(\mathcal{L}_{t}^{(h^{\leftarrow})}\) can be roughly viewed as constructing an "almost quasi-static" thermodynamics [6] bridging the initial \(p_{T}\) and the (quasi-)equilibrium \(p_{0}=e^{-U_{T}^{\leftarrow}}\) : for any distribution \(\mu_{t}^{\leftarrow}\) (probably far away from \(\rho_{t}^{\leftarrow}\)), within a short time period \(\Delta t\) slightly larger than \(\mathcal{O}\big{(}1/h_{t}^{\leftarrow 2}\big{)}\), we have \(\mu_{t+\Delta t}^{\leftarrow}\approx\rho_{t+\Delta t}^{\leftarrow}\), provided that \(s\mapsto\mu_{s}^{\leftarrow}\) evolves according to \(\mathcal{L}_{s}^{(h^{\leftarrow})}\); see Appx. C.2. This key finding will guide our analysis of the solution operator \(\Phi_{t,T}^{(h^{\leftarrow})}\).

### Score function is perturbed by a pulse

From (10), we know that \(v_{T}\) combines the averaged effect of \(\Phi_{t,T}^{(h^{\leftarrow})}(\boldsymbol{\nabla}\boldsymbol{\cdot}(p_{t}^{ \leftarrow}\mathscr{E}_{t}^{\leftarrow}))\) for various \(t\). As a first result, we consider \(\mathscr{E}_{t}^{\leftarrow}(x)=E(x)\delta_{t-s}\) for a fixed time instance \(s\in[0,T)\), where \(\delta_{t-s}\) is the Dirac function. In this case, \(v_{T}\) no longer involves time integration and we have

\[\begin{split} v_{T}&=-\frac{(1+h_{s}^{\gets 2})}{2}\Phi_{s,T}^{(h^ {\leftarrow})}\big{(}\boldsymbol{\nabla}\boldsymbol{\cdot}(p_{s}^{ \leftarrow}E)\big{)},\\ L(h^{\leftarrow})&=\frac{(1+h_{s}^{\gets 2})^{2}}{8} \int_{\mathbb{R}^{d}}\frac{\big{(}\Phi_{s,T}^{(h^{\leftarrow})}\big{(} \boldsymbol{\nabla}\boldsymbol{\cdot}(p_{s}^{\leftarrow}E)\big{)}\big{)}^{2}}{p _{0}}.\end{split}\] (13)

To proceed, we need to make additional assumptions:

**Assumption 3.3**.:
1. _For any_ \(t\in[0,T]\)_,_ \(U_{t}=-\log p_{t}\) _is assumed to be strongly convex and the Hessian of_ \(U_{t}\) _is bounded by two positive numbers_ \(m_{t}\) _and_ \(M_{t}\) _as below_ \[m_{t}\boldsymbol{I}_{d}\;\preceq\nabla^{2}U_{t}(x)\preceq M_{t}\boldsymbol{ I}_{d},\qquad\forall x\in\mathbb{R}^{d}.\] (14) _Moreover, assume that_ \[m_{t}\geq 1,\qquad t\in[0,T],\qquad\text{ and }\qquad m_{0}>1.\] (15)
2. _For all_ \(t\in[0,T]\)_, we choose_ \(h_{t}^{\leftarrow}=\mathsf{h}\) _as constant._

Introduce

\[\kappa_{t}^{\leftarrow}:=(1+\mathsf{h}^{-2})m_{t}^{\leftarrow}-\mathsf{h}^{-2 }\equiv(1+\mathsf{h}^{-2})m_{T-t}-\mathsf{h}^{-2},\] (16)which characterizes the Hessian lower bound of \(V_{t}^{\leftarrow}\) (11). Note \(\kappa_{t}^{\leftarrow}\approx m_{t}^{\leftarrow}\) when \(\mathsf{h}\gg 1\). We would like to explain the reason behind the above assumptions, in particular, their practical relevance. **Part (1) Strong convexity:** this is a common assumption for Langevin sampling analysis [11; 14]. As the role of \(\mathcal{L}_{t}^{(h^{\leftarrow})}\) is essentially simulating a Langevin dynamics with time-dependent potential, it is reasonable to use this assumption as a starting point. Moreover, the algorithmic improvement in gDDIM [10] is highly inspired by a form with assuming the data distribution as a Gaussian; Frechet inception distance (FID) [15], a widely used metric to evaluate the quality of generative model, essentially treats the data (in the feature space) as Gaussians. Therefore, we believe that this assumption can still capture some main features of realistic datasets. **Part (2) \(m_{t}\geq 1\) for any \(t\in[0,T]\):** The second assumption \(m_{t}\geq 1\) means that \(p_{t}\) is more localized (smaller variance) than the standard Gaussian (unit variance), which is compatible with Assumption 3.1 (3). It can also ensure that \(V_{t}\) is strongly convex with positive Hessian lower bounds, i.e., \(\kappa_{t}^{\leftarrow}\geq 1\), for any \(t\in[0,T]\) and \(\mathsf{h}\in(0,\infty)\).

**Proposition 3.4**.: _Under Assumptions 3.1 and 3.3, suppose that \(\mathscr{E}_{t}^{\leftarrow}(x)=E(x)\delta_{t-s}\) for some fixed \(s\in[0,T)\). If \(\mathsf{h}\geq\mathsf{h}_{lb}:=\max\left\{\nicefrac{{1}}{{2}},\mathsf{h}_{0 }(\nicefrac{{1}}{{2}}),\sqrt{\max\{0,-\frac{c_{U}}{\ln(2)},\sup_{t\in[s,T]}C_ {t}^{\leftarrow,(2)}\}}\right\},\) we have the upper bound of \(L(h)\) in (13):_

\[L(\mathsf{h})\leq C_{\mathsf{h}}(1+\mathsf{h}^{2})^{2}\exp\big{(}-\int_{s}^{T} (\mathsf{h}^{2}-C_{r}^{\leftarrow,(2)})\kappa_{r}^{\leftarrow}-C_{r}^{ \leftarrow,(1)}\mathrm{d}r\big{)},\] (17)

_where \(C_{\mathsf{h}}=\frac{1}{2}\int\big{(}\boldsymbol{\nabla}\cdot(p_{s}^{ \leftarrow}E)\big{)}^{2}/\rho_{s}^{\leftarrow}\), \(C_{t}^{\leftarrow,(2)}=\frac{20+30M_{t}^{\leftarrow 2}}{m_{t}^{ \leftarrow 2}}\); see Appx. E.1 for details about \(C_{t}^{\leftarrow,(1)}\) and \(\mathsf{h}_{0}(\nicefrac{{1}}{{2}})\); \(c_{U}\in\mathbb{R}\) comes from Assumption 3.1. Moreover, \(\lim_{\mathsf{h}\to\infty}C_{\mathsf{h}}\), \(\lim_{\mathsf{h}\to\infty}C_{t}^{\leftarrow,(1)}\) exist._

See Appx. E.1 for proofs. We remark that the above bound focuses on capturing the scaling with respect to \(\mathsf{h}^{2}\) but may not be tight for other parameters. It remains interesting to see how we can improve the above upper bound. The _main conclusion_ is that: if the error function \(\mathscr{E}_{t}^{\leftarrow}\) is a pulse at time \(t=s\), then for a large \(\mathsf{h}\), \(L(\mathsf{h})\) will decay to zero exponentially fast with respect to \(\mathsf{h}\). For 1D Gaussian case, we can clearly observe such an exponential decay in Fig. 1(a), where we pick \(\mathscr{E}_{t}^{\leftarrow}=\mathbb{I}_{t\leq 0.95T}\nabla\log p_{t}^{ \leftarrow}\). The intuition behind this exponential suppressed prefactor is that for large \(h\), \(\Phi_{s,T}^{(h^{\leftarrow})}\) can be viewed as an almost quasi-static thermodynamics dragging any positive measure towards \(\rho_{T}^{\leftarrow}\approx p_{0}\), as mentioned above in SS 3.3. As \(\nu=\boldsymbol{\nabla}\boldsymbol{\cdot}\left(p_{s}^{\leftarrow}E\right)\) has measure zero, we can split it into positive and negative parts: \(\nu=\nu^{+}-\nu^{-}\) ( assume \(\int\nu^{\pm}=1\) WLOG). Each term \(\Phi_{s,T}^{(h^{\leftarrow})}\big{(}\nu^{+}\big{)}\approx\rho_{T}^{\leftarrow} \approx\Phi_{s,T}^{(h^{\leftarrow})}\big{(}\nu^{-}\big{)}\), which explains that \(\Phi_{s,T}^{(h^{\leftarrow})}(\nu)\approx 0\) for large \(\mathsf{h}\).

### Score function is only perturbed near the end of the generative process

**Proposition 3.5**.: _Under Assumptions 3.1 and 3.3, suppose that \(\mathscr{E}_{t}^{\leftarrow}(x)=\mathbb{I}_{t\in[T-a,T]}E(x)\) where \(a\ll 1\). Then when \(a\ll 1\) and \(\mathsf{h}\gg 1\), asymptotically,_

\[L(0)\sim\frac{a^{2}}{8}\int_{\mathbb{R}^{d}}\frac{(\boldsymbol{\nabla} \boldsymbol{\cdot}(p_{0}E))^{2}}{p_{0}},\qquad L(\mathsf{h})\lesssim\frac{ \big{(}1-e^{-a\frac{b^{2}}{2}\kappa_{0}}\big{)}^{2}}{2\kappa_{0}^{2}}\int_{ \mathbb{R}^{d}}\frac{(\boldsymbol{\nabla}\boldsymbol{\cdot}(p_{0}E))^{2}}{p_ {0}},\]

Figure 2: 1D Gaussian \(p_{0}=\mathcal{N}(0,\sigma_{0}^{2})\) (with different \(\sigma_{0}\) smaller than one) and \(T=2\). Panel (a) validates the exponential decay of \(L(\mathsf{h})\) when the score function has no error near \(t\approx T\), similar to Prop. 3.4. Panel (b) validates Prop. 3.5 that the ODE model (\(h=0\)) outperforms the SDE model when there is a large score error at \(t\approx T\). Panel (c) validates Prop. 3.6 that \(\lim_{\mathsf{h}\to\infty}L(\mathsf{h})\) exists.

_with \(\kappa_{0}=(1+\nicefrac{{1}}{{h^{2}}})m_{0}-\nicefrac{{1}}{{h^{2}}}\) as in (16). The upper bound of \(L(\mathsf{h})\) is tight asymptotically._

We remark that we made _no assumption on how \(ah^{2}\) scales_. If \(\mathsf{h}\gg 1\), \(\nicefrac{{L(\mathsf{h})}}{{L(0)}}\lesssim 4\big{(}1-e^{-ah^{2}\kappa_{0}/2} \big{)}^{2}/a^{2}\kappa_{0}^{2}\). **Case (I):** If \(ah^{2}\gg 1\), then \(\nicefrac{{L(\mathsf{h})}}{{L(0)}}\lesssim\nicefrac{{4}}{{a^{2}\kappa_{0}^{2}}}\), which is large as \(a\ll 1\). **Case (II):** If \(ah^{2}\ll 1\), then \(\nicefrac{{L(\mathsf{h})}}{{L(0)}}\lesssim\mathsf{h}^{4}\), which is still large. In either case, \(\nicefrac{{L(\mathsf{h})}}{{L(0)}}\) is expected to be large for a general \(E\) and the ODE model is preferred in this case. The intuition is that there is almost no time for the operator \(\mathcal{L}_{h}^{(h^{*})}\) to suppress the error \(E\), so the prefactor \(1+(h_{t}^{-})^{2}\) in \(v_{T}\) (10) dominates (which is the key difference compared with Prop. 3.4). The proof is postponed to Appx. E.3. In Fig. 1(b), we consider 1D Gaussian and only perturb the score function at the end of the generative process (\(\mathcal{E}_{t}^{\leftarrow}=\mathbb{I}_{t\geq 0.995T}\nabla\log p_{t}^{ \leftarrow}\)); clearly, the SDE-based models have comparatively larger error.

### General error in score function

We can generalize Prop. 3.4 and Prop. 3.5 to a general error function \(\mathscr{E}^{\leftarrow}\), and observe that \(L(\mathsf{h})\) will converge to a constant exponentially fast as \(\mathsf{h}\to\infty\).

**Proposition 3.6**.: _Under Assumptions 3.1 and 3.3, we consider a general error function \((t,x)\mapsto\mathscr{E}_{t}^{\leftarrow}(x)\). Let \(\gamma=\inf_{\mathsf{h}\geq\mathsf{h}_{\mathsf{h}_{\mathsf{h}}}}\inf_{t\in[0,T ]}\kappa_{+}^{\leftarrow}\). For any \(\alpha\in(0,1)\) and \(\beta\in(0,2)\), when \(\mathsf{h}\gg 1\),_

\[L(\mathsf{h}) \lesssim(1+\alpha^{2})\mathcal{T}+(1+\alpha^{-2})\;C\;\gamma^{-1 }(1+\mathsf{h}^{2})\exp\big{(}-\mathsf{h}^{2-\beta}\gamma\big{)},\] \[L(\mathsf{h}) \gtrsim(1-\alpha^{2})\mathcal{T}-(\alpha^{-2}-1)C\;\gamma^{-1}(1 +\mathsf{h}^{2})\exp\big{(}-\mathsf{h}^{2-\beta}\gamma\big{)},\]

_where \(C\) is given in Appx. F.1 and \(\mathcal{T}\) (only depending on \(p_{0}\) and \(\mathscr{E}_{T}^{\leftarrow}\)) is upper bounded by_

\[0\leq\mathcal{T}\lesssim\frac{1}{2m_{0}^{2}}\int_{\mathbb{R}^{d}}\frac{\big{(} \boldsymbol{\nabla}\cdot(p_{0}\mathscr{E}_{T}^{\leftarrow})\big{)}^{2}}{p_{0 }}\hskip-1.422638pt\equiv\frac{1}{2m_{0}^{2}}\int_{\mathbb{R}^{d}}\left( \nabla\log p_{0}\cdot\mathscr{E}_{T}^{\leftarrow}+\boldsymbol{\nabla}\boldsymbol {\cdot}\mathscr{E}_{T}^{\leftarrow}\right)^{2}p_{0}.\] (18)

In the limit \(\mathsf{h}\to\infty\), \((1-\alpha^{2})\mathcal{T}\lesssim L(\mathsf{h})\lesssim(1+\alpha^{2})\mathcal{T}\), where \(\alpha\in(0,1)\) is arbitrary. Hence, the tail behavior is that \(L(\mathsf{h})\) converges to \(\mathcal{T}\) exponentially fast as \(\mathsf{h}\to\infty\). If we assume that \(\mathscr{E}_{T}^{\leftarrow}=\nabla\log p_{0}\), \(p_{0}=\mathcal{N}(0,\sigma_{0}^{2}\boldsymbol{I}_{d})\) in \(d\)-dimension, then the above upper bound is simply \(\mathcal{T}\lesssim d\), which is independent of \(\sigma_{0}\) (see Appx. F.2). For 1D Gaussian in Fig. 1(c), we can indeed observe that \(\lim_{\mathsf{h}\to\infty}L(\mathsf{h})\) exists, and is bounded above by \(d=1\); see Appx. G for more types of error functions.

The above upper bound has an interesting tight connection to the generator of (overdamped) Langevin dynamics with drift \(-\nabla U_{0}\equiv\nabla p_{0}\). If we adopt constrained score models [23, 25], namely, parameterizing \(\log p_{t}\) instead of the score function \(\nabla\log p_{t}\) during training, the error \(\mathscr{E}_{T}^{\leftarrow}=\nabla\varphi\) for some scalar-valued function \(\varphi\). Then the above upper bound becomes

\[\frac{1}{2m_{0}^{2}}\int_{\mathbb{R}^{d}}(\triangle\varphi-\nabla U_{0}\cdot \nabla\varphi)^{2}e^{-U_{0}}=\frac{1}{2m_{0}^{2}}\int_{\mathbb{R}^{d}}( \mathcal{L}^{*}\varphi)^{2}e^{-U_{0}},\] (19)

where \(\mathcal{L}^{*}(\varphi):=\triangle\varphi-\nabla U_{0}\cdot\nabla\varphi\) whose adjoint operator \(\mathcal{L}(\mu)=\nabla\cdot(\nabla U_{0}\mu)+\triangle\mu\) is the Fokker-Planck generator of the following Langevin dynamics \(\mathrm{d}X_{t}=-\nabla U_{0}(X_{t})\;\mathrm{d}t+\sqrt{2}\;\mathrm{d}W_{t}\) where \(W_{t}\) is the standard Brownian motion. We remark that this formula (19) is general for constrained score models [23, 25]; see also F.2 for elaborations. An interesting open question is whether and how we can take the above upper bound into consideration when designing the loss function.

### An application: exploring the effect of training weight

The above theoretical discussions suggest that diffusion models with large diffusion coefficients are more negatively affected by score error near data's side, whereas the ODE model is more negatively affected by the score error near the noise end. This leads us to conjecture that if we can control the training (e.g., by optimizing the training weight \(\omega_{t}\)), so that the score error distribution near the noise end is reduced and meanwhile the score-matching loss is not significantly impacted, then it will very likely improve the ODE models. We report preliminary numerical experiments to support this idea in Appx. 1, whereas a comprehensive study will be left as future works.

Numerical experiments

We present experiments on 2D Gaussian mixture model, Swiss roll, CIFAR10 to support our theoretical results: when numerical discretization error is not dominating, the sampling quality increases as h increases, a reminiscent of Prop. 3.4. Experimental details are postponed to Appx. H, as well as more numerical results (e.g., results about 1D Gaussian mixture and MNIST). Results by adopting various weight functions, a technique arising from theoretical predictions, are postponed to Appx. I. Source codes are available at https://github.com/yucaoyc/OptimalDiffusion.

Example 1: 2D 4-mode Gaussian mixture.We verify the theoretical results on 2D Gaussian mixture with a specified score error. In Fig. 3, a clear trend is that a higher h produces generated distributions that better match the marginal densities of \(p_{0}\), and it is numerically verified by the purple line of Fig. 3(a). In Fig. 4, with multiple settings of \(\mathscr{E}_{t}^{\leftarrow}\) and \(\epsilon\), we observe a consistent phenomenon that as h increases, the KL divergence of true data and generated data converges exponentially fast, thus validating Prop. 3.6. It worths noticing that in all three settings of \(\mathscr{E}_{t}^{\leftarrow}\), by simply adopting a larger diffusion coefficient \(h\) in (3), we can obtain better generative models without any extra training costs.

Example 2: Swiss roll.We consider Swiss roll, a more complex distribution without exact score function available. We train the score function with the denoising score-matching objective [33] (Appx. H). The first plot in Fig. 4(a) shows the difference between true data and generated data measured by Wasserstein distance, which decays to zero exponentially fast, verifying Prop. 3.6. In the second plot of Fig. 4(a), we tested various \(h\) and time steps for the generative process. The ODE model (\(h=0\)) does not improve, as the number of time discretization steps increases, but near the continuous-time limit, all SDE cases (\(h>0\)) are better than the ODE model. It suggests that our conclusions here is limited to the continuous-time setting. The exploration of time discretization errors will be future works. The generated data results in Fig. 4(b) demonstrate that with increasing \(h\), the sample quality is improved; see Appx. H.6 for more results.

Figure 4: Numerical results of 2D 4-mode Gaussian mixture. The above panels show that the KL divergences between the true distribution and the generated samples overall decay as h increases for various types of error perturbation of score functions.

Figure 3: Visualization of marginal densities of 2D 4-mode Gaussian mixture, where \(\mathscr{E}_{t}^{\leftarrow}=\nabla\log p_{t}^{\leftarrow}\) and \(\epsilon=0.2\). The top row shows the marginal distribution of the first coordinate and the bottom row for the second coordinate. The red lines are the exact marginal distributions of \(p_{0}\) and the histograms (blue) visualize the empirical densities of generated samples.

Example 3: CIFAR-10.When using a large amount of parameters for score matching in practice, we observe that SDEs appear to perform better than ODEs as discretization error descreases, a result similarly observed on Swiss roll. This implicates the practical applications on generating samples of better quality under a given (pre-trained) score-matching model.

## 5 Summary and outlook

In this work, we study the effect of the diffusion coefficient on the quality of overall sample generation in the generative process. Theoretically, we provide understandings of scenarios in which the ODE-based model and the SDE-based model is superior than the other; see Prop. 3.4 and Prop. 3.5. Numerically, these results are validated via toy examples as well as benchmark datasets.

There are many interesting directions for continuing works. (1) As we focus on the asymptotic case, a time-dependent \(h_{t}^{\leftarrow}\) with large magnitude (i.e., \(h_{t}^{\leftarrow}\gg 1\) for all \(t\)) is essentially no different from a constant \(h_{t}^{\leftarrow}\equiv\mathsf{h}\) with \(\mathsf{h}\gg 1\). Whether it is possible to use time-dependent \(t\mapsto h_{t}^{\leftarrow}\) to combine the advantages of ODE and large diffusion cases in dealing with different types of error of score functions in the non-asymptotic region is still an open question. (2) Can we design a practical criterion that directly learn the optimal magnitude of the noise-level function \(h_{t}^{\leftarrow}\) by looking at the score-training error distribution? Can we develop certain theoretical understanding of the empirical results in [19]? (3) How can we find a stable and accurate numerical scheme to deal with the fast diffusion case? (4) How can we generalize the above theoretical results by removing the convexity assumption, and including the low-dimensional feature of datasets into the theory [8; 5; 18]?

Concerning the broad impact, though we don't foresee any negative social impact of this work, the potential improvement of generative model might relate to creation of "deep fakes".

## Acknowledgments and Disclosure of Funding

YC is sponsored by Shanghai Pujiang Program, and acknowledges the support from City University of Hong Kong during his visit. JC and YL are supported by the NSFC Major Research Plan - Interpretable and General-purpose Next-generation Artificial Intelligence (92370205). XZ is supported by General Research Funds from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No. 11308121, 11318522) and the NSFC/RGC Joint Research Scheme [RGC Project No. N-CityU102/20 and NSFC Project No. 12061160462].

\begin{table}
\begin{tabular}{l c c c c c c c} Discretization steps & 100 & 200 & 500 & 1000 & 2000 & 3000 & 4000 \\ \hline \(\nicefrac{{h^{2}}}{{g^{2}}}=0\) & **22.43** & **8.12** & **7.20** & 6.89 & 6.98 & 7.27 & 7.33 \\ \(\nicefrac{{h^{2}}}{{g^{2}}}=1\) & 31.72 & 15.72 & 7.23 & **6.70** & 6.71 & 6.95 & 7.08 \\ \(\nicefrac{{h^{2}}}{{g^{2}}}=2\) & 52.77 & 26.68 & 10.78 & 6.99 & **6.70** & **6.69** & **6.98** \\ \(\nicefrac{{h^{2}}}{{g^{2}}}=4\) & 92.83 & 46.11 & 20.47 & 10.17 & 7.20 & 7.09 & 7.01 \\ \end{tabular}
\end{table}
Table 1: **CIFAR-10:** We evaluate FIDs with different discretization steps and \(\nicefrac{{h^{2}}}{{g^{2}}}\) on a pre-trained checkpoint entitled “vp/cifar10_ddpmp_continuous” in [30]. We do not use any correctors and evaluate FIDs on \(10^{4}\) samples, thus the results for \(\nicefrac{{h^{2}}}{{g^{2}}}=0,1\) are different from the reported values.

Figure 5: Numerical results of Swiss roll. Panel (a) shows the decay of Wasserstein distance between the true distribution and the generated samples with increasing \(h\) and 20,000 time-discretization steps, and the decay of Wasserstein distance with the increasing number of time-discretization steps and different \(h\). Panel (b) shows generated samples with different \(h\).

## References

* Albergo et al. [2023] Michael S. Albergo, Nicholas M. Boffi, and Eric Vanden-Eijnden. Stochastic Interpolants: A Unifying Framework for Flows and Diffusions, 2023. arXiv:2303.08797 [cond-mat].
* Bakry and Emery [1985] D. Bakry and M. Emery. Diffusions hypercontractives. In _Lecture Notes in Mathematics_, pages 177-206. Springer Berlin Heidelberg, 1985. doi: 10.1007/bfb0075847.
* Bakry et al. [2014] Dominique Bakry, Ivan Gentil, and Michel Ledoux. _Analysis and Geometry of Markov Diffusion Operators_. Springer International Publishing, 2014. doi: 10.1007/978-3-319-00227-9.
* Bao et al. [2022] Fan Bao, Chongxuan Li, Jun Zhu, and Bo Zhang. Analytic-DPM: an analytic estimate of the optimal reverse variance in diffusion probabilistic models. In _International Conference on Learning Representations_, 2022.
* De Bortoli [2022] Valentin De Bortoli. Convergence of denoising diffusion models under the manifold hypothesis. _Transactions on Machine Learning Research_, 2022.
* Callen [1985] Herbert B Callen. _Thermodynamics and an Introduction to Thermostatistics_. John Wiley & Sons, Nashville, TN, 2 edition, 1985.
* Chen et al. [2023] Hongrui Chen, Holden Lee, and Jianfeng Lu. Improved analysis of score-based generative modeling: User-friendly bounds under minimal smoothness assumptions. In _Proceedings of the 40th International Conference on Machine Learning_, volume 202, pages 4735-4763, 2023.
* Chen et al. [2022] Minshuo Chen, Kaixuan Huang, Tuo Zhao, and Mengdi Wang. Score approximation, estimation and distribution recovery of diffusion models on low-dimensional data. In _Proceedings of the 40th International Conference on Machine Learning_, volume 202, pages 4672-4712, 2023.
* Chen et al. [2018] Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural Ordinary Differential Equations. In _Advances in Neural Information Processing Systems_, volume 31. Curran Associates, Inc., 2018.
* Chen et al. [2023] Sitan Chen, Sinho Chewi, Jerry Li, Yuanzhi Li, Adil Salim, and Anru Zhang. Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions. In _The Eleventh International Conference on Learning Representations_, 2023.
* Cheng and Bartlett [2018] Xiang Cheng and Peter Bartlett. Convergence of Langevin MCMC in KL-divergence. In _Algorithmic Learning Theory_, pages 186-211, 2018.
* Choi et al. [2022] Jooyoung Choi, Jungbeom Lee, Chaehun Shin, Sungwon Kim, Hyunwoo Kim, and Sungroh Yoon. Perception prioritized training of diffusion models. In _2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 11462-11471, 2022. doi: 10.1109/CVPR52688.2022.01118.
* Croitoru et al. [2023] Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, and Mubarak Shah. Diffusion models in vision: A survey. _IEEE Transactions on Pattern Analysis and Machine Intelligence_, pages 1-20, 2023. doi: 10.1109/TPAMI.2023.3261988.
* Dalalyan and Riou-Durand [2020] Arnak S. Dalalyan and Lionel Riou-Durand. On sampling from a log-concave density using kinetic Langevin diffusions. _Bernoulli_, 26(3):1956-1988, 2020. doi: 10.3150/19-BEJ1178.
* Heusel et al. [2017] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. In _Advances in Neural Information Processing Systems_, volume 30. Curran Associates, Inc., 2017.
* Ho et al. [2020] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In _Advances in Neural Information Processing Systems_, volume 33, pages 6840-6851. Curran Associates, Inc., 2020.
* Huang et al. [2021] Chin-Wei Huang, Jae Hyun Lim, and Aaron Courville. A variational perspective on diffusion-based generative models and score matching. In _Advances in Neural Information Processing Systems_, 2021.

* Jolliffe and Cadima [2016] Ian T. Jolliffe and Jorge Cadima. Principal component analysis: a review and recent developments. _Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences_, 374(2065):20150202, 2016. doi: 10.1098/rsta.2015.0202.
* Karras et al. [2022] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. In _Advances in Neural Information Processing Systems_, 2022.
* Klebaner [1998] Fima C Klebaner. _Introduction to Stochastic Calculus with Applications_. Imperial College Press, 1998. doi: 10.1142/p110.
* Kloeden and Platen [1992] Peter E. Kloeden and Eckhard Platen. _Numerical Solution of Stochastic Differential Equations_. Springer Berlin Heidelberg, 1992. doi: 10.1007/978-3-662-12616-5.
* Krizhevsky [2009] Alex Krizhevsky. Learning multiple layers of features from tiny images. 2009.
* Lai et al. [2023] Chieh-Hsin Lai, Yuhta Takida, Naoki Murata, Toshimitsu Uesaka, Yuki Mitsufuji, and Stefano Ermon. FP-Diffusion: Improving Score-based Diffusion Models by Enforcing the Underlying Score Fokker-Planck Equation. In _Proceedings of the 40 th International Conference on Machine Learning_, 2023.
* 400, 2000. doi: https://doi.org/10.1006/jfian.1999.3557.
* Salimans and Ho [2021] Tim Salimans and Jonathan Ho. Should EBMs model the energy or the score? In _Energy Based Models Workshop-ICLR 2021_, 2021.
* Sohl-Dickstein et al. [2015] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In _Proceedings of the 32nd International Conference on Machine Learning_, volume 37 of _Proceedings of Machine Learning Research_, pages 2256-2265, Lille, France, 2015. PMLR.
* Sonderby et al. [2017] Casper Kaae Sonderby, Jose Caballero, Lucas Theis, Wenzhe Shi, and Ferenc Huszar. Amortised MAP inference for image super-resolution. In _International Conference on Learning Representations_, 2017.
* Song et al. [2021] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In _International Conference on Learning Representations_, 2021.
* Song and Ermon [2019] Yang Song and Stefano Ermon. Generative Modeling by Estimating Gradients of the Data Distribution. In _Advances in Neural Information Processing Systems_, volume 32. Curran Associates, Inc., 2019.
* Song et al. [2021] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In _International Conference on Learning Representations_, 2021.
* Song et al. [2022] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever. Consistency models. In _Proceedings of the 40th International Conference on Machine Learning_, volume 202, pages 32211-32252. PMLR, 2023.
* Tabak and Vanden-Eijnden [2010] Esteban G. Tabak and Eric Vanden-Eijnden. Density estimation by dual ascent of the log-likelihood. _Communications in Mathematical Sciences_, 8(1):217-233, 2010.
* Vincent [2011] Pascal Vincent. A connection between score matching and denoising autoencoders. _Neural Comput._, 23(7):1661-1674, 2011. doi: 10.1162/NECO_a_00142.
* Yann [1998] LeCun Yann. MNIST, 1998. URL http://yann.lecun.com/exdb/mnist/.
* Zhang and Chen [2023] Qinsheng Zhang and Yongxin Chen. Fast sampling of diffusion models with exponential integrator. In _The Eleventh International Conference on Learning Representations_, 2023.
* Zhang et al. [2023] Qinsheng Zhang, Molei Tao, and Yongxin Chen. gDDIM: Generalized denoising diffusion implicit models. In _The Eleventh International Conference on Learning Representations_, 2023.

**Supplementary Material for "Exploring the Optimal Choice for Generative Processes in Diffusion Models: Ordinary vs Stochastic Differential Equations"**

## Appendix A Notation Convention.

## Appendix B Discussion and proof for SS 2

### Proof of (3)

We re-state the conclusion in (3) in the following lemma:

**Lemma B.1**.: _For any function \(h_{t}^{\leftarrow}\), if one chooses \(A^{\leftarrow}\) as in (3), then we have \(q_{t}(x)=p_{T-t}(x)\) for any \(t\in[0,T]\) and \(x\in\mathbb{R}^{d}\)._

Proof.: We can easily write down the Fokker-Planck equation of (1)

\[\partial_{t}p_{t}(x)=-\bm{\nabla}\bm{\cdot}\big{(}f_{t}(x)p_{t}(x)\big{)}+ \frac{g_{t}^{2}}{2}\bigtriangleup p_{t}(x).\]

Since we need to ensure \(q_{t}=p_{T-t}\), we require

\[\partial_{t}q_{t}(x) =\bm{\nabla}\bm{\cdot}\big{(}f_{t}^{\leftarrow}(x)q_{t}(x)\big{)} -\frac{g_{t}^{\leftarrow 2}}{2}\bigtriangleup q_{t}(x)\] \[=\bm{\nabla}\bm{\cdot}\Big{(}f_{t}^{\leftarrow}(x)q_{t}(x)-\frac {g_{t}^{\leftarrow 2}+h_{t}^{\leftarrow 2}}{2}\nabla q_{t}(x)\Big{)}+\frac{h_{t}^{ \leftarrow 2}}{2}\bigtriangleup q_{t}(x)\] \[=\bm{\nabla}\bm{\cdot}\Big{(}(f_{t}^{\leftarrow}(x)-\frac{g_{t }^{\leftarrow 2}+h_{t}^{\leftarrow 2}}{2}\nabla\log q_{t}(x)\Big{)}q_{t}(x) \Big{)}+\frac{h_{t}^{\leftarrow 2}}{2}\bigtriangleup q_{t}(x)\] \[=-\bm{\nabla}\bm{\cdot}\Big{(}A_{t}^{\leftarrow}(x)q_{t}(x)\Big{)} +\frac{h_{t}^{\leftarrow 2}}{2}\bigtriangleup q_{t}(x),\]

by noting that \(A_{t}^{\leftarrow}(x)\) is specified in (3). This equation is exactly the Fokker-Planck equation of (2). 

### The role of \(g_{t}\)

The function \(t\mapsto g_{t}\) as the diffusion coefficient in the forward Fokker-Planck equation (1), in fact, plays a role as time re-scaling as long as \(g_{t}>0\) for any \(t\). Indeed, if we have an SDE in the following

\begin{table}
\begin{tabular}{l l l} Quantity & Notation & Notes \\ \hline Forward process & \(X_{t}\) & \(t=0\): data distribution \\ Backward/generative process & \(Y_{t}\) & \(t=0\): noise distribution \\ Backward process with inexact score & \(\widetilde{Y}_{t}\) & \\ Distribution of forward process & \(p_{t}\) & \(p_{t}:=\text{law}(X_{t})\) \\ Distribution of backward process & \(q_{t}\) & \(\text{law}(Y_{t}):=q_{t}\equiv p_{T-t}\equiv p_{t}^{\leftarrow}\) \\ Distribution of approximated backward process & \(\widetilde{q}_{t}\) & \(\widetilde{q}_{t}:=\text{law}(\widetilde{Y}_{t})\), \(\widetilde{q}_{t}=q_{t}\) when \\ Error function of the score & \(\epsilon\mathscr{E}_{t}^{\leftarrow}\) & \(0\leq\epsilon\ll 1\) and \(\mathscr{E}_{t}^{\leftarrow}=\mathcal{O}(1)\) \\ The exact potential & \(U_{t}\) & \(p_{t}:=e^{-U_{t}}\) \\ Modified potential & \(V_{t}^{\leftarrow}\) & see (11) \\ Normalizing constants & \(Z_{V}:=\int e^{-V}\) & \(V\) is arbitrary \\ \end{tabular}
\end{table}
Table 2: Summary of important quantities in this paper

[MISSING_PAGE_FAIL:14]

From the analysis by Chen et al. [7, Theorem 2.1] for the case \(h^{\leftarrow}=g^{\leftarrow}\), one has

\[\text{KL}\big{(}p_{0}||\widehat{q}\big{)}\leq\text{KL}\big{(}p_{T}||\mathcal{N}( 0,I_{d})\big{)}+\mathcal{O}\big{(}T\epsilon^{2}\big{)}+\mathcal{O}\big{(}^{T 2}\nicefrac{{d}}{{N}}\big{)},\]

where \(\widehat{q}\) is the distribution of \(Z_{T}\) after applying the exponential integrator to (21) and \(N\) is the number of time-discretization steps. The first term \(\text{KL}\big{(}p_{T}\|\mathcal{N}(0,I_{d})\big{)}\leq(\mathcal{M}_{2}+d)e^{-T}\), where \(\mathcal{M}_{2}=\mathbb{E}_{p_{0}}{|x|}^{2}\) is the second moment of data distribution.

Therefore, to ensure that \(\text{KL}\big{(}p_{0}||\widehat{q}\big{)}\leq\delta\), it is sufficient to choose

\[T=\mathcal{O}\big{(}\log\big{(}\nicefrac{{(\mathcal{M}_{2}+d)}}{{\delta}} \big{)}\big{)}.\]

The time-discretization error can be eliminated by choosing \(N\to\infty\). What is so far less clear in literature is the term \(\mathcal{O}\big{(}T\epsilon^{2}\big{)}\).

### Existing error bounds appear to fail to characterize the optimal \(h^{\leftarrow}\)

Note that the target dynamics \(q_{t}\) in (2) and the approximated dynamics \(\widetilde{q}_{t}\) in (7) only differ in the drift term. Recall that \(q_{T}=p_{0}\), and to estimate \(\text{KL}\big{(}p_{0}||\widetilde{q}_{T}\big{)}\equiv\text{KL}\big{(}q_{T}|| \widetilde{q}_{T}\big{)}\), we can simply estimate how the quantity \(\text{KL}\big{(}q_{t}||\widetilde{q}_{t}\big{)}\) changes for \(t\in(0,T)\). By [7, Lemma C.1], for any \(t\in\mathbb{R}\),

\[\partial_{t}\text{KL}\big{(}q_{t}||\widetilde{q}_{t}\big{)}=-\frac{h_{t}^{ \leftarrow 2}}{2}\mathscr{J}\big{(}q_{t}\|\widetilde{q}_{t}\big{)}+\frac{g_{t}^{ \leftarrow 2}+h_{t}^{\leftarrow 2}}{2}\mathbb{E}\Big{[}\langle-\epsilon \phi_{t}^{\leftarrow}(Y_{t}),\nabla\log\frac{q_{t}(Y_{t})}{\widetilde{q}_{t}(Y _{t})}\rangle\Big{]},\] (22)

where the Fisher information \(\mathscr{J}\big{(}p||q\big{)}:=\int\mathrm{d}p\left|\nabla\log\frac{p}{q} \right|^{2}.\) By Cauchy-Schwarz inequality,

\[\partial_{t}\text{KL}\big{(}q_{t}||\widetilde{q}_{t}\big{)}\] (23) \[\leq -\frac{h_{t}^{\leftarrow 2}}{2}\mathscr{J}\big{(}q_{t}||\widetilde{q }_{t}\big{)}+\frac{g_{t}^{\leftarrow 2}+h_{t}^{\leftarrow 2}}{2}\big{(}\frac{c^{2}}{2} \mathbb{E}\Big{[}\|\epsilon\mathcal{E}_{t}^{\leftarrow}(Y_{t})\|^{2}\Big{]}+ \frac{1}{2c^{2}}\mathbb{E}\left[\left\|\nabla\log\frac{q_{t}(Y_{t})}{\widetilde {q}_{t}(Y_{t})}\right\|^{2}\right]\big{)}\] \[= \frac{(h_{t}^{\leftarrow 2}+g_{t}^{\leftarrow 2})^{2}}{8h_{t}^{ \leftarrow 2}}\epsilon^{2}\mathbb{E}\big{[}\|\phi_{t}^{\leftarrow}(Y_{t})\|^{2}\big{]},\]

where we chose \(c^{2}=\frac{h_{t}^{\leftarrow 2}+g_{t}^{\leftarrow 2}}{2h_{t}^{\leftarrow 2}}\) in the last line. This bound captures the scaling extremely well when \(h^{\leftarrow}=g^{\leftarrow}\), which helps to establish the effectiveness of score-based diffusion method in [7]. However, this bound is not directly applicable for a general \(h^{\leftarrow}\), as it is clear that this bound fails to provide useful information when \(h^{\leftarrow}\approx 0\) (namely, the probability flow), as well as the large diffusion case (\(h^{\leftarrow}\to\infty\)). From directly optimizing the upper bound, i.e., minimizing \(\frac{(h_{t}^{\leftarrow 2}+g_{t}^{\leftarrow 2})^{2}}{8h_{t}^{ \leftarrow 2}}\), one ends up with the choice \(h^{\leftarrow}=g^{\leftarrow}\), which has been used in many literature. We acknowledge that \(h^{\leftarrow}=g^{\leftarrow}\) is an effective choice; however, as we show in SS 4, this is not really the optimal case in general, and the above argument cannot justify choosing the diffusion model over the probability flow.

## Appendix C Discussion for SS 3 and proof of Prop. 3.2

### The operator \(\Phi_{s,t}^{(h^{\leftarrow})}\)

**Lemma C.1**.:
* \(\Phi_{(\cdot),(\cdot)}^{(h^{\leftarrow})}\) _satisfies the following property, i.e., for any_ \(s,t,r\in\mathbb{R}\)_,_ \[\Phi_{t,r}^{(h^{\leftarrow})}\circ\Phi_{s,t}^{(h^{\leftarrow})}=\Phi_{s,r}^{(h ^{\leftarrow})}.\] (24) _Moreover,_ \(\Phi_{t,t}^{(h^{\leftarrow})}=\text{Id}\) _is an identity operator for any_ \(t\)_._
* _For any_ \(s,t\in\mathbb{R}\)_,_ \[\partial_{s}\big{(}\Phi_{s,t}^{(h^{\leftarrow})}(\mu)\big{)}=-\Phi_{s,t}^{(h^{ \leftarrow})}\big{(}\mathcal{L}_{s}^{(h^{\leftarrow})}\mu\big{)}\qquad \partial_{t}\big{(}\Phi_{s,t}^{(h^{\leftarrow})}(\mu)\big{)}=\mathcal{L}_{t}^{(h ^{\leftarrow})}\big{(}\Phi_{s,t}^{(h^{\leftarrow})}(\mu)\big{)}.\] (25)

[MISSING_PAGE_EMPTY:16]

### Proof of Prop. 3.2

Denote

\[v_{t}(x):=\partial_{\epsilon}q_{t}^{\epsilon}(x)|_{\epsilon=0},\qquad\zeta_{t}(x):= \partial_{\epsilon}^{2}q_{t}^{\epsilon}(x)|_{\epsilon=0}.\]

Namely, we expand \(\widetilde{q}_{t}^{\epsilon}\) via the following

\[\widetilde{q}_{t}^{\epsilon}(x)=\underbrace{\widetilde{q}_{t}^{0}(x)}_{ \equiv q_{t}(x)}+\epsilon v_{t}(x)+\frac{\epsilon^{2}}{2}\zeta_{t}(x)\ +\mathcal{O}\big{(}\epsilon^{3}\big{)}.\]

Recall that when \(\epsilon=0\), \(\widetilde{q}_{t}^{0}\equiv q_{t}\); in particular, \(\widetilde{q}_{T}^{0}=q_{T}^{\text{ Lem.~{}B1}}p_{0}\). The cost function can be easily expanded via Taylor's formula:

\[\text{KL}\big{(}p_{0}||\widetilde{q}_{T}^{\epsilon}\big{)}=-\epsilon\int_{ \mathbb{R}^{d}}v_{T}(x)\ \mathrm{d}x-\frac{\epsilon^{2}}{2}\int_{\mathbb{R}^{d}}\big{(}\zeta_{T}(x)- \frac{v_{T}^{2}(x)}{p_{0}(x)}\big{)}\ \mathrm{d}x+\mathcal{O}\big{(}\epsilon^{3}\big{)}.\]

Since \(\int\widetilde{q}_{T}^{\epsilon}\equiv 1\), it is easy to know that \(\int v_{T}=\int\zeta_{T}=0\) and thus

\[\text{KL}\big{(}p_{0}||\widetilde{q}_{T}^{\epsilon}\big{)}=\frac{\epsilon^{2 }}{2}\int_{\mathbb{R}^{d}}\frac{v_{T}^{2}(x)}{p_{0}(x)}\ \mathrm{d}x+\mathcal{O}\big{(}\epsilon^{3}\big{)}.\]

Next we need to study \(v_{T}\). Recall from (7) that the Fokker-Planck equation of \(\widetilde{q}_{t}\) is

\[\partial_{t}\widetilde{q}_{t}^{\epsilon}=\mathcal{L}_{t}^{(h^{-})}(\widetilde {q}_{t}^{\epsilon})-\epsilon\bm{\nabla}\cdot\big{(}\frac{1+h_{t}^{\epsilon-2}} {2}\mathscr{E}_{t}^{\epsilon}\widetilde{q}_{t}^{\epsilon}\big{)}.\]

By taking derivatives with respect to \(\epsilon\) on both sides of this equation and then passing \(\epsilon\to 0\),

\[\partial_{t}v_{t}=\mathcal{L}_{t}^{(h^{-\epsilon})}(v_{t})-\bm{\nabla}\cdot \big{(}\frac{1+h_{t}^{\epsilon-2}}{2}\mathscr{E}_{t}^{\epsilon}q_{t}\big{)}.\]

By Lem. C.2,

\[v_{T}=-\frac{1}{2}\int_{0}^{T}(1+h_{t}^{\epsilon-2})\Phi_{t,T}^{(h^{-})}\big{(} \bm{\nabla}\cdot\big{(}\underbrace{q_{t}}_{\equiv p_{t}^{\epsilon-}}\mathscr{E }_{t}^{\epsilon-}\big{)}\big{)}\ \mathrm{d}t.\] (27)

## Appendix D Preliminary results

We collect two lemmas which will be useful in proving Prop. 3.5 and Prop. 3.6 later.

**Lemma D.1**.:
1. _The operator_ \(\mathcal{K}(f):=\triangle f+\bm{\nabla}\cdot\big{(}\nabla V\cdot f\big{)}\) _is a Hermitian/self-adjoint operator in the space_ \(\langle\cdot,\cdot\rangle_{L^{2}(\rho^{-1})}\) _where_ \(\rho\propto e^{-V}\)_. Therefore,_ \(\mathcal{K}\) _has the eigen-decomposition in this weighted_ \(L^{2}(\rho^{-1})\) _space._
2. _Assume that_ \(\nabla^{2}V(x)\geq m\bm{I}_{d}\) _for any_ \(x\in\mathbb{R}^{d}\) _for some_ \(m>0\)_. Then the operator_ \(-\mathcal{K}\) _is a positive operator on the space_ \(\{f:\ \int f=0\}\) _with spectrum gap at least_ \(m\)_._

Proof.: For any \(f,g\), note that

\[\langle f,\mathcal{K}g\rangle_{L^{2}(\rho^{-1})}=-\int_{\mathbb{R}^{d}}\nabla (f/\rho)\cdot\nabla(g/\rho)\rho.\]

Therefore, \(\mathcal{K}\) is a Hermitian operator. In the space \(\{f:\int f=0\}\), we know

\[-\langle f,\mathcal{K}f\rangle_{L^{2}(\rho^{-1})}=\int_{\mathbb{R}^{d}}| \nabla(f/\rho)|^{2}\rho\]

\[\stackrel{{\text{Poincare inequo}}}{{\geq}} m\int_{\mathbb{R}^{d}}\big{(}f^{2}/\rho^{2}\big{)}\rho=m\langle f,f\rangle_{L^{2}( \rho^{-1})}.\]

The validity of Poincare inequality under the strong convexity assumption is well-known in literature; see, e.g., [2, 24] and [3, Corollary 4.8.2].

**Lemma D.2**.: _Suppose the operator \(\mathcal{K}\) is defined as \(\mathcal{K}(f):=\triangle f+\boldsymbol{\nabla\cdot}\big{(}\nabla V\cdot(f)\big{)}\) with \(\nabla^{2}V(x)\geq m\boldsymbol{I}_{d}\) for any \(x\in\mathbb{R}^{d}\). Then for any \(c,a\in\mathbb{R}^{+}\), and any function \(\varphi\) with \(\int\varphi=0\),_

\[\int_{\mathbb{R}^{d}}\frac{1}{\rho}\Big{(}\int_{0}^{a}\exp\big{(} ct\mathcal{K}\big{)}(\varphi)\;\mathrm{d}t\Big{)}^{2} =\sum_{k=1}^{\infty}\big{(}\frac{1-e^{-ac\lambda_{k}}}{c\lambda_{ k}}\big{)}^{2}\alpha_{k}^{2}\] \[\leq\Big{(}\frac{1-e^{-acm}}{cm}\Big{)}^{2}\int_{\mathbb{R}^{d}} \frac{\varphi^{2}}{\rho},\]

_where \(\rho\propto e^{-V}\), \(\{(\lambda_{k},\phi_{k})\}_{k=1}^{\infty}\) are eigen pairs for the operator \(-\mathcal{K}\), and \(\varphi=\sum_{k=1}^{\infty}\alpha_{k}\phi_{k}\)._

**Remark**.: Note that as \(\mathcal{K}\) is an operator, \(\exp\big{(}ct\mathcal{K}\big{)}:=\sum_{k=0}^{\infty}\frac{(ct\mathcal{K})^{k} }{k!}\) is the operator exponential.

Proof.: Let us first denote the eigenvalue decomposition of \(\mathcal{K}\) as \(\mathcal{K}(\phi_{k})=-\lambda_{k}\phi_{k}\) where \(\lambda_{k}\geq m\) for \(k\in\mathbb{N}\) and \(\langle\phi_{j},\phi_{k}\rangle_{L^{2}(\rho^{-1})}=\delta_{j,k}\) for any \(j,k\in\mathbb{N}\) by Lem. D.1. Then we can decompose \(\varphi\) by \(\varphi=\sum_{k}\alpha_{k}\phi_{k}\). It is not hard to verify that

\[\exp\big{(}ct\mathcal{K}\big{)}(\varphi)=\sum_{k=1}^{\infty}e^{ -ct\lambda_{k}}\alpha_{k}\phi_{k}.\]

Then

\[\int_{0}^{a}\exp\big{(}ct\mathcal{K}\big{)}(\varphi)\;\mathrm{d}t =\sum_{k=1}^{\infty}\frac{1-e^{-ac\lambda_{k}}}{c\lambda_{k}} \alpha_{k}\phi_{k}.\]

Hence,

\[\int_{\mathbb{R}^{d}}\frac{1}{\rho}\Big{(}\int_{0}^{a}\exp\big{(} ct\mathcal{K}\big{)}(\varphi)\;\mathrm{d}t\Big{)}^{2} =\int_{\mathbb{R}^{d}}\frac{1}{\rho}\Big{(}\sum_{k=1}^{\infty} \frac{1-e^{-ac\lambda_{k}}}{c\lambda_{k}}\alpha_{k}\phi_{k}\Big{)}^{2}\] \[=\sum_{k=1}^{\infty}\big{(}\frac{1-e^{-ac\lambda_{k}}}{c\lambda_ {k}}\big{)}^{2}\alpha_{k}^{2}\] \[\leq\Big{(}\frac{1-e^{-acm}}{cm}\Big{)}^{2}\sum_{k=1}^{\infty} \alpha_{k}^{2}\] \[=\Big{(}\frac{1-e^{-acm}}{cm}\Big{)}^{2}\int_{\mathbb{R}^{d}} \frac{\varphi^{2}}{\rho}.\]

## Appendix E Proof of Prop. 3.4, Prop. 3.5, and a discussion on the pulse-shape error

### Proof of Prop. 3.4

For convenience, we summarize some notations below; see also Appx. A.

* Denote the global minimum of \(U_{t}^{\leftarrow}\) as \(\mathcal{X}_{t}^{\leftarrow}\) and denote the global minimum of \(V_{t}^{\leftarrow}\) as \(\mathcal{Y}_{t}^{\leftarrow}\). When \(\mathsf{h}\to\infty\), we know \[\lim_{\mathsf{h}\to\infty}\mathcal{Y}_{t}\to\mathcal{X}_{t}.\]
* Denote the normalizing constant \(Z_{V}:=\int e^{-V}\) for an arbitrary potential \(V\).
* Recall that the distribution of the exact dynamics \(Y_{t}\) is \(q_{t}\equiv p_{T-t}\equiv p_{t}^{\leftarrow}\) and the distribution of the approximated dynamics \(\tilde{Y}_{t}\) is \(\widetilde{q}_{t}\).
* Recall that \(p_{t}:=e^{-U_{t}}\) and \(\rho_{t}\propto e^{-V_{t}}\) in (12).

**Lemma E.1**.: _Under_ **Assumption 3.3**_, we have:_

1. _Assumption_ 3.1 _(_3_) is valid, i.e., the existence of_ \(c_{U}\)_._
2. _For any_ \(t\in[0,T]\)_, the probability distribution_ \(\rho_{t}\) _defined in (_12_) satisfies the Poincare inequality with constant_ \(\kappa_{t}\)__(_16_):_ \[\int_{\mathbb{R}^{d}}\left|\nabla\varphi\right|^{2}\,\mathrm{d}\rho_{t}\geq \kappa_{t}\int_{\mathbb{R}^{d}}\varphi^{2}\,\mathrm{d}\rho_{t},\qquad\forall \varphi\;\;\text{with}\;\int_{\mathbb{R}^{d}}\varphi\rho_{t}=0.\] (28)
3. \(Z_{V_{0}}:=\int_{\mathbb{R}^{d}}e^{-V_{0}}\) _is both upper and lower bounded: for any_ \(\delta\in(0,1)\)_, there exists_ \(\mathsf{h}_{0}(\delta)>0\) _such that whenever_ \(\mathsf{h}\geq\mathsf{h}_{0}(\delta)\)_,_ \[1-\delta\leq Z_{V_{0}}\leq e^{-\mathsf{h}^{-2}c_{U}}.\] _and_ \[\frac{\rho_{0}}{p_{0}}\leq\frac{e^{-\mathsf{h}^{-2}c_{U}}}{1-\delta}.\]
4. _If we pick_ \(\delta=1/2\)_, for_ \(\mathsf{h}\geq\max\{\mathsf{h}_{0}(1/2),\sqrt{\max\{0,-\frac{c_{U}}{\ln(2)}\}}\)_, the function_ \(\rho_{0}/p_{0}\) _is uniformly bounded:_ \[\frac{\rho_{0}}{p_{0}}\leq 4.\] (29)

**Proposition E.2**.: _For any \(\mathsf{h}\geq\nicefrac{{1}}{{2}}\), we have_

\[\left|\int_{\mathbb{R}^{d}}\varphi^{2}\frac{\mathrm{d}}{\mathrm{d}t}\rho_{t}^{ \leftarrow}\right|\leq C_{t}^{\leftarrow,(1)}\int_{\mathbb{R}^{d}}\varphi^{2 }\;\rho_{t}^{\leftarrow}+C_{t}^{\leftarrow,(2)}\int_{\mathbb{R}^{d}}\left| \nabla\varphi\right|^{2}\rho_{t}^{\leftarrow},\qquad\forall\varphi\in C_{0}^{ 2}(\mathbb{R}^{d}).\]

_where_

\[\begin{cases}C_{t}^{\leftarrow,(1)}:=\xi_{t}^{\leftarrow}+2\varsigma_{t}^{ \leftarrow}|\mathcal{Y}_{t}^{\leftarrow}-\mathcal{X}_{t}^{\leftarrow}|^{2}+ \frac{20dM_{t}^{\leftarrow}\varsigma_{t}^{\leftarrow}}{m_{t}^{\leftarrow 2}},\\ C_{t}^{\leftarrow,(2)}:=\frac{8\varsigma_{t}^{\leftarrow}}{m_{t}^{\gets 2 }}\equiv\frac{20+30M_{t}^{\leftarrow 2}}{m_{t}^{\leftarrow 2}},\\ \xi_{t}^{\leftarrow}:=\left|\partial_{t}\log Z_{V_{t}^{\leftarrow}}\right|+ \frac{5d(1+M_{t}^{\leftarrow})}{2}+\frac{5}{2}|\mathcal{X}_{t}^{\leftarrow}| ^{2},\\ \varsigma_{t}^{\leftarrow}:=5\big{(}\frac{1}{2}+\frac{3M_{t}^{ \leftarrow 2}}{4}\big{)}.\end{cases}\] (30)

\(Z_{V_{t}^{\leftarrow}}=\int e^{-V_{t}^{\leftarrow}}\)_, \(M_{t}^{\leftarrow}\) and \(m_{t}^{\leftarrow}\) are shown in_ _Assumption 3.3, and \(\mathcal{X}_{t}^{\leftarrow}\) and \(\mathcal{Y}_{t}^{\leftarrow}\) are the global minimum points of functions \(x\mapsto U_{t}^{\leftarrow}(x)\) and \(x\mapsto V_{t}^{\leftarrow}(x)\), respectively._

**Remark**.: A similar result holds for any \(\mathsf{h}>0\); we choose \(\mathsf{h}\geq\nicefrac{{1}}{{2}}\) in order to simplify the above constants (30).

Note that the constant \(C_{t}^{\leftarrow,(2)}\) is independent of \(h\). We remark that when \(\mathsf{h}\gg 1\), \(C_{t}^{\leftarrow,(1)}\) approximately behaves as follows:

**Lemma E.3**.: _When \(\mathsf{h}\to\infty\), we have_

\[\lim_{\mathsf{h}\to\infty}C_{t}^{\leftarrow,(1)}=\frac{5d(1+M_{t}^{\leftarrow })}{2}+\frac{5}{2}|\mathcal{X}_{t}^{\leftarrow}|^{2}+\frac{\big{(}50+75M_{t}^{ \leftarrow 2}\big{)}dM_{t}^{\leftarrow}}{m_{t}^{\leftarrow 2}}.\]

We now proceed to finish the proof of Prop. 3.4. The detailed proofs of Lem. E.1, Prop. E.2, and Lem. E.3 are postponed to Appx. E.2.

Proof of Prop. 3.4.: By Lem. E.1,

\[\begin{split} L(\mathsf{h})&\stackrel{{ \eqref{eq:L_t}}}{{=}}\frac{(1+\mathsf{h}^{2})^{2}}{8}\int_{\mathbb{R}^{d}} \frac{\left(\Phi_{s,T}^{(h^{\leftarrow})}(\boldsymbol{\nabla}\boldsymbol{ \cdot}(p_{s}^{\leftarrow}E))\right)^{2}}{\rho_{0}}\,\frac{\rho_{0}}{p_{0}}\\ &\stackrel{{\eqref{eq:L_t}}}{{\leq}}\frac{1}{2}(1+ \mathsf{h}^{2})^{2}\int_{\mathbb{R}^{d}}\frac{\left(\Phi_{s,T}^{(h^{\leftarrow })}(\boldsymbol{\nabla}\boldsymbol{\cdot}(p_{s}^{\leftarrow}E))\right)^{2}}{ \rho_{0}}.\end{split}\] (31)

[MISSING_PAGE_EMPTY:20]

### Proof of Lem. E.1, Prop. E.2, and Lem. E.3

Proof of Lem. E.1.:
1. From \(m_{0}>1\) in **Assumption 3.3**, \(x\mapsto U_{0}(x)-x^{2}/2\) is strongly convex and thus is surely bounded from below by some \(c_{U}\in\mathbb{R}\).
2. The second result is a classical result by Bakry-Emery criterion [2, 3], as \(V_{t}^{\leftarrow}\) (12) is strongly convex with Hessian lower bound \(\kappa_{t}^{\leftarrow}\) (16).
3. To prove the third one, note that \[Z_{V_{0}} :=\int_{\mathbb{R}^{d}}e^{-V_{0}}\stackrel{{\eqref{eq: 1}}}{{=}}\int_{\mathbb{R}^{d}}e^{-(1+\mathsf{h}^{-2})U_{0}(x)+\mathsf{h}^{-2}| x|^{2}/2}\;\mathrm{d}x\] \[=\int_{\mathbb{R}^{d}}e^{-U_{0}(x)}e^{-\mathsf{h}^{-2}(U_{0}(x)- |x|^{2}/2)}\;\mathrm{d}x\] \[\leq e^{-\mathsf{h}^{-2}c_{U}}\int_{\mathbb{R}^{d}}e^{-U_{0}}=e^ {-\mathsf{h}^{-2}c_{U}}.\] To prove the lower bound, \[Z_{V_{0}}\geq\int_{\mathbb{R}^{d}}e^{-(1+\mathsf{h}^{-2})U_{0}(x)}\;\mathrm{ d}x=e^{-(1+\mathsf{h}^{-2})U_{0}(X_{0})}\int_{\mathbb{R}^{d}}e^{-(1+\mathsf{h}^{-2 })\big{(}U_{0}(x)-U_{0}(X_{0})\big{)}}\;\mathrm{d}x.\] (35) Recall from the beginning of this Appendix, \(\mathcal{X}_{0}\) is defined as the global minimum of \(x\mapsto U_{0}(x)\). Then, \(U_{0}(x)\geq U_{0}(\mathcal{X}_{0})\) for any \(x\) and we know \(\mathsf{h}\mapsto e^{-(1+\mathsf{h}^{-2})\big{(}U_{0}(x)-U_{0}(X_{0})\big{)}}\) is monotone increasing. By monotone convergence theorem, \[\lim_{\mathsf{h}\to\infty}\int_{\mathbb{R}^{d}}e^{-(1+\mathsf{h}^ {-2})\big{(}U_{0}(x)-U_{0}(\mathcal{X}_{0})\big{)}}\;\mathrm{d}x =\int_{\mathbb{R}^{d}}\lim_{\mathsf{h}\to\infty}e^{-(1+\mathsf{h}^ {-2})\big{(}U_{0}(x)-U_{0}(X_{0})\big{)}}\;\mathrm{d}x\] \[=\int_{\mathbb{R}^{d}}e^{-U_{0}(x)+U_{0}(\mathcal{X}_{0})}\; \mathrm{d}x=e^{U_{0}(\mathcal{X}_{0})}.\] Thus, the limit of the right-hand side of (35) is \(1\) when \(\mathsf{h}\to\infty\). Hence, the lower bound of \(Z_{V_{0}}\) follows immediately. Finally, when \(\mathsf{h}\geq\mathsf{h}_{0}(\delta)\), \[\frac{\rho_{0}}{p_{0}}(x)=\frac{e^{-(1+\mathsf{h}^{-2})U_{0}(x)+\mathsf{h}^{-2 }|x|^{2}/2}}{Z_{V_{0}}e^{-U_{0}}}\leq\frac{e^{-\mathsf{h}^{-2}c_{U}}}{1-\delta}.\] (36)
4. When we pick \(\delta=1/2\) and choose \(\mathsf{h}\) as specified, we can immediately obtain (29).

Before we prove Prop. E.2, we need the following three lemmas.

**Lemma E.4**.: _Under **Assumption 3.3**, we have_

\[|\partial_{t}U_{t}(x)|\leq\frac{d(1+M_{t})}{2}+\frac{\left|x\right|^{2}}{4}+ \frac{3M_{t}^{2}}{4}|x-\mathcal{X}_{t}|^{2}.\]

Proof.: Since \(p_{t}\) follows the Fokker-Planck equation \(\partial_{t}p_{t}=\boldsymbol{\nabla}\boldsymbol{\cdot}\left(\frac{1}{2}xp_{t }\right)+\frac{1}{2}\bigtriangleup p_{t}\), then \(U_{t}=-\log p_{t}\) satisfies \(\partial_{t}U_{t}(x)=-\frac{1}{2}\big{(}d-x\cdot\nabla U_{t}(x)-\bigtriangleup U _{t}(x)+\left|\nabla U_{t}(x)\right|^{2}\big{)}\). Then by **Assumption 3.3**,

\[|\partial_{t}U_{t}(x)| \leq\frac{d}{2}+\frac{1}{2}|x\cdot\nabla U_{t}(x)|+\frac{1}{2} \bigtriangleup U_{t}(x)+\frac{1}{2}\big{|}\nabla U_{t}(x)\big{|}^{2}\qquad \text{(triangle inequality)}\] \[\leq\frac{d}{2}+\frac{1}{4}\big{(}|x|^{2}+\left|\nabla U_{t}(x) \right|^{2}\big{)}+\frac{1}{2}\bigtriangleup U_{t}(x)+\frac{1}{2}\big{|} \nabla U_{t}(x)\big{|}^{2}\qquad\text{(Cauchy inequality)}\] \[\leq\frac{d}{2}+\frac{1}{4}|x|^{2}+\frac{3}{4}|\nabla U_{t}(x)- \nabla U_{t}(\mathcal{X}_{t})|^{2}+\frac{dM_{t}}{2}\qquad\text{(by $\nabla U_{t}(\mathcal{X}_{t})\equiv 0$)}\] \[\leq\frac{d(1+M_{t})}{2}+\frac{|x|^{2}}{4}+\frac{3M_{t}^{2}}{4}| x-\mathcal{X}_{t}|^{2}.\]

Recall that \(\mathcal{X}_{t}\) is defined as the global minimum of \(U_{t}\) and thus \(\nabla U_{t}(\mathcal{X}_{t})=0\)

**Lemma E.5**.: _When \(\mathsf{h}\geq\frac{1}{2}\),_

\[\frac{\big{|}\frac{\mathrm{d}}{\mathrm{d}t}\rho_{t}^{\leftarrow} \big{|}}{\rho_{t}^{\leftarrow}}(x)\leq\xi_{t}^{\leftarrow}+\varsigma_{t}^{ \leftarrow}|x-\mathcal{X}_{t}^{\leftarrow}|^{2},\] (37)

_where_

\[\begin{cases}\xi_{t}^{\leftarrow}:=\big{|}\partial_{t}\log Z_{V_{t }^{\leftarrow}}\big{|}+\frac{5d(1+M_{t}^{\leftarrow})}{2}+\frac{5}{2}| \mathcal{X}_{t}^{\leftarrow}|^{2},\\ \varsigma_{t}^{\leftarrow}:=5\big{(}\frac{1}{2}+\frac{3M_{t}^{ \leftarrow 2}}{4}\big{)}.\end{cases}\]

Proof.: By direct calculation from the definitions of \(\rho_{t}^{\leftarrow}\) in (12) and \(V_{t}^{\leftarrow}\) in (11),

\[\partial_{t}\rho_{t}^{\leftarrow}=-(\partial_{t}\log Z_{V_{t}^{ \leftarrow}})\rho_{t}^{\leftarrow}-(1+\mathsf{h}^{-2})\rho_{t}^{\leftarrow} \partial_{t}U_{t}^{\leftarrow}.\]

Hence, by Lem. E.4 and \(\mathsf{h}\geq\frac{1}{2}\),

\[\frac{|\partial_{t}\rho_{t}^{\leftarrow}|}{\rho_{t}^{ \leftarrow}}(x)\leq \big{|}\partial_{t}\log Z_{V_{t}^{\leftarrow}}\big{|}+(1+\mathsf{ h}^{-2})\big{(}\frac{d(1+M_{t}^{\leftarrow})}{2}+\frac{|x|^{2}}{4}+\frac{3M_{t}^{ \leftarrow 2}}{4}|x-\mathcal{X}_{t}^{\leftarrow}|^{2}\big{)}\] \[\leq \Big{(}\big{|}\partial_{t}\log Z_{V_{t}^{\leftarrow}}\big{|}+\frac {5d(1+M_{t}^{\leftarrow})}{2}\Big{)}\] \[\qquad+5\big{(}\frac{|\mathcal{X}_{t}^{\leftarrow}|^{2}}{2}+\frac {|x-\mathcal{X}_{t}^{\leftarrow}|^{2}}{2}+\frac{3M_{t}^{\leftarrow 2}}{4}|x- \mathcal{X}_{t}^{\leftarrow}|^{2}\big{)}\] \[= \xi_{t}^{\leftarrow}+5\big{(}\frac{1}{2}+\frac{3M_{t}^{\gets 2 }}{4}\big{)}|x-\mathcal{X}_{t}^{\leftarrow}|^{2}.\]

**Lemma E.6**.: _Assume that \(\rho\propto e^{-V}\) and \(\varphi\) decays fast enough such that_

\[\int_{B_{0}(R)}\boldsymbol{\nabla\cdot}\big{(}\varphi^{2}\nabla \rho\big{)}\to 0,\]

_as the radius \(R\to\infty\) (\(B_{0}(R)\) is the ball centered at \(0\) with radius \(R\)), e.g., \(\varphi\in C_{0}^{2}(\mathbb{R}^{d})\). Then_

\[\int_{\mathbb{R}^{d}}|\nabla V|^{2}\varphi^{2}\rho\leq 4\int_{ \mathbb{R}^{d}}|\nabla\varphi|^{2}\rho+2\int_{\mathbb{R}^{d}}\varphi^{2}\, \triangle V\rho.\] (38)

Proof.: The identity \(\boldsymbol{\nabla\cdot}\big{(}\varphi^{2}\nabla\rho\big{)}=\nabla\varphi^{2 }\cdot\nabla\rho+\varphi^{2}\,\triangle\rho\) and the trivial facts \(\nabla\rho=-\rho\nabla V\), \(\triangle\rho=(|\nabla V|^{2}-\triangle V)\rho\) show that

\[0 =\int\nabla\varphi^{2}\cdot\nabla\rho+\varphi^{2}\,\triangle\rho\] \[=-2\int(\nabla V\cdot\nabla\varphi)\varphi\rho+\int\varphi^{2}(- \,\triangle V+|\nabla V|^{2})\rho\] \[\stackrel{{\text{Cauchy into }}}{{\geq}} -\frac{1}{2}\int|\nabla V|^{2}\varphi^{2}\rho-2\int|\nabla \varphi|^{2}\rho-\int\varphi^{2}\,\triangle V\rho+\int|\nabla V|^{2}\varphi^ {2}\rho\] \[=\frac{1}{2}\int|\nabla V|^{2}\varphi^{2}\rho-2\int|\nabla \varphi|^{2}\rho-\int\varphi^{2}\,\triangle V\rho.\]

Therefore,

\[\int|\nabla V|^{2}\varphi^{2}\rho\leq 4\int|\nabla\varphi|^{2}\rho+2\int \varphi^{2}\,\triangle V\rho.\]

[MISSING_PAGE_EMPTY:23]

[MISSING_PAGE_EMPTY:24]

with its error at e.g., \(t=0.8\) in general; how the error function exactly looks like depend on a vast amount of hyper-parameters in training. Therefore, we might as well treat each \(\phi_{j}\) as "mostly independent" in order to handle the _worst case_ situation. If we consider how each \(\phi_{j}\) contributes to the final sample generation error (quantified via KL divergence), then we might as well study each one independently. We remark that this is simply a reasonable assumption in order to treat generic error types.

More specifically, recall that in Prop. 3.2, \(v_{T}\) linearly depends on each \(\phi_{j}\)

\[v_{T} =-\frac{1}{2}\int_{0}^{T}(1+(h_{t}^{\leftarrow})^{2})\Phi_{t,T}^ {(h^{\leftarrow})}\big{(}\bm{\nabla}\bm{\cdot}\left(p_{t}^{\leftarrow}\mathscr{ E}_{t}^{\leftarrow}\right)\big{)}\;\mathrm{d}t\] \[\approx-\frac{1}{2}\sum_{j}(1+(h_{t_{j}}^{\leftarrow})^{2})\Phi_ {t_{j},T}^{(h^{\leftarrow})}\Big{(}\bm{\nabla}\bm{\cdot}\left(p_{t_{j}}^{ \leftarrow}\phi_{j}\right)\Big{)}\;\Delta t,\]

and recall that the leading order term (10) is simply

\[L(h^{\leftarrow})=\frac{1}{2}\int_{\mathbb{R}^{d}}\frac{v_{T}^{2}(x)}{p_{0}( x)}\;\mathrm{d}x.\]

Therefore, after plugging the decomposition of \(\mathscr{E}_{t}^{\leftarrow}\) into \(L(h^{\leftarrow})\), we have

\[L(h^{\leftarrow})=\frac{(1+\mathsf{h}^{2})^{2}}{8}\;(\Delta t)^{2}\;\sum_{j,k} \int_{\mathbb{R}^{d}}\frac{\Phi_{t_{j},T}^{(h^{\leftarrow})}\Big{(}\bm{\nabla} \bm{\cdot}\left(p_{t_{j}}^{\leftarrow}\phi_{j}\right)\Big{)}\Phi_{t_{k},T}^{(h ^{\leftarrow})}\Big{(}\bm{\nabla}\bm{\cdot}\left(p_{t_{k}}^{\leftarrow}\phi_{k }\right)\Big{)}}{p_{0}}.\]

We had chosen \(h_{t}^{\leftarrow}=\mathsf{h}\) for all \(t\in[0,T]\) for simplicity. Either by Cauchy-Schwartz inequality, or by assumptions on the independence of each \(\phi_{j}\) as discussed above, the main feature is the following term

\[\frac{(1+\mathsf{h}^{2})^{2}}{8}\;\Delta t\;\int_{\mathbb{R}^{d}}\frac{1}{p_{0 }}\Big{[}\Phi_{t_{j},T}^{(h^{\leftarrow})}\Big{(}\bm{\nabla}\bm{\cdot}\left(p _{t_{j}}^{\leftarrow}\phi_{j}\right)\Big{)}\Big{]}^{2}.\]

Therefore, it makes sense to study how this quantity scales for each \(j\), and for two asymptotic regions \(\mathsf{h}=0\) and \(\mathsf{h}\to\infty\). For each fixed \(j\), we can easily observe that the above quantity arises from choosing the error function as a pulse-shape error, i.e., \(\phi_{k}=0\) if \(k\neq j\) (with certain normalization rescaling).

## Appendix F Proof of Prop. 3.6 and the discussion of the large diffusion limit

### Proof of Prop. 3.6

Let us pick an \(a=\mathsf{h}^{-\beta}\ll 1\). We split \(v_{T}\) (10) into two parts:

\[v_{T} =-\frac{1+\mathsf{h}^{2}}{2}\int_{0}^{T}\Phi_{t,T}^{(h^{ \leftarrow})}\big{(}\underbrace{\bm{\nabla}\bm{\cdot}\left(p_{t}^{\leftarrow }\mathscr{E}_{t}^{\leftarrow}\right)}_{=:\Gamma_{t}^{\leftarrow}}\big{)}\; \mathrm{d}t\] \[=-\frac{1+\mathsf{h}^{2}}{2}\int_{T-a}^{T}\Phi_{t,T}^{(h^{ \leftarrow})}\big{(}\Gamma_{t}^{\leftarrow}\big{)}\;\mathrm{d}t-\frac{1+ \mathsf{h}^{2}}{2}\int_{0}^{T-a}\Phi_{t,T}^{(h^{\leftarrow})}\big{(}\Gamma_{t }^{\leftarrow}\big{)}\;\mathrm{d}t.\]

### Upper bound

By Cauchy-Schwartz inequality (\((x+y)^{2}=x^{2}+y^{2}+2xy\leq(1+\alpha^{2})x^{2}+(1+\alpha^{-2})y^{2}\) for any \(x,y\) and \(\alpha>0\)),

\[L(\mathsf{h}) =\frac{1}{2}\int\frac{v_{T}^{2}}{p_{0}}\] \[\leq(1+\alpha^{2})\underbrace{\frac{\left(1+\mathsf{h}^{2}\right) ^{2}}{8}\int_{\mathbb{R}^{d}}\frac{\left(\int_{T-a}^{T}\Phi_{t,T}^{(h^{-})}( \Gamma_{t}^{\leftarrow})\mathrm{d}t\right)^{2}}{p_{0}}}_{=:\mathcal{T}_{1}}\] \[\qquad+(1+\alpha^{-2})\underbrace{\frac{\left(1+\mathsf{h}^{2} \right)^{2}}{8}\int_{\mathbb{R}^{d}}\frac{\left(\int_{0}^{T-a}\Phi_{t,T}^{(h^{ -})}(\Gamma_{t}^{\leftarrow})\mathrm{d}t\right)^{2}}{p_{0}}}_{=:\mathcal{T}_{2}}.\]

For the second term \(\mathcal{T}_{2}\),

\[\mathcal{T}_{2} =\frac{(1+\mathsf{h}^{2})^{2}}{8}\int_{\mathbb{R}^{d}}\frac{ \left(\int_{0}^{T-a}\Phi_{t,T}^{(h^{-})}(\Gamma_{t}^{\leftarrow})\mathrm{d}t \right)^{2}}{p_{0}}\] \[\stackrel{{\text{\tiny Cauchy ineq.}}}{{\leq}} \frac{(1+\mathsf{h}^{2})^{2}(T-a)}{8}\int_{0}^{T-a}\big{(}\int_{\mathbb{R}^{ d}}\frac{\Phi_{t,T}^{(h^{-})}(\Gamma_{t}^{\leftarrow})^{2}}{p_{0}}\big{)}\, \mathrm{d}t\] \[\stackrel{{\text{\tiny(\ref{eq:1})}}}{{\leq}} \frac{(1+\mathsf{h}^{2})^{2}T}{2}\int_{0}^{T-a}\big{(}\int_{\mathbb{R}^{d}} \frac{\Phi_{t,T}^{(h^{-})}(\Gamma_{t}^{\leftarrow})^{2}}{\rho_{0}}\big{)}\, \mathrm{d}t\] \[\stackrel{{\text{\tiny(\ref{eq:2})}}}{{\leq}} \frac{(1+\mathsf{h}^{2})^{2}T}{2}\int_{0}^{T-a}\big{(}\int_{\mathbb{R}^{d}} \frac{\Gamma_{t}^{\leftarrow-2}}{\rho_{t}^{\leftarrow}}\big{)}\exp\Big{(}- \int_{t}^{T}\big{(}(\mathsf{h}^{2}-C_{r}^{\leftarrow,(2)})\kappa_{r}^{ \leftarrow}-C_{r}^{\leftarrow,(1)}\big{)}\mathrm{d}r\Big{)}\,\mathrm{d}t\] \[\leq\frac{(1+\mathsf{h}^{2})^{2}T}{2}\sup_{t\in[0,T]}\big{(}\int_ {\mathbb{R}^{d}}\frac{\Gamma_{t}^{\leftarrow-2}}{\rho_{t}^{\leftarrow}} \big{)}\exp\big{(}\int_{0}^{T}C_{r}^{\leftarrow,(2)}\kappa_{r}^{\leftarrow}+C _{r}^{\leftarrow,(1)}\mathrm{d}r\Big{)}\int_{0}^{T-a}e^{-\mathsf{h}^{2}\gamma(T- t)}\,\mathrm{d}t\] \[\leq\frac{(1+\mathsf{h}^{2})T}{2\mathsf{h}^{2}}\sup_{t\in[0,T]} \big{(}\int_{\mathbb{R}^{d}}\frac{\Gamma_{t}^{\leftarrow-2}}{\rho_{t}^{ \leftarrow}}\big{)}\exp\big{(}\int_{0}^{T}C_{r}^{\leftarrow,(2)}\kappa_{r}^{ \leftarrow}+C_{r}^{\leftarrow,(1)}\mathrm{d}r\big{)}\frac{(1+\mathsf{h}^{2})e ^{-\mathsf{a}\mathsf{h}^{2}\gamma}}{\gamma},\]

which decays exponentially fast as \(\mathsf{h}\to\infty\) as long as \(\mathsf{h}^{2}\gg a^{-1}\gg 1\). To get the second line above, we used Cauchy-Schwarz inequality and Fubini's theorem. Recall the definition of \(\gamma\in\mathbb{R}^{+}\) in the statement of Prop. 3.6.

Overall, when \(a=\mathsf{h}^{-\beta}\ll 1\),

\[L(\mathsf{h})\leq(1+\alpha^{-2})\;C\frac{(1+\mathsf{h}^{2})\exp\big{(}- \mathsf{h}^{2-\beta}\gamma\big{)}}{\gamma}+(1+\alpha^{2})\mathcal{T}_{1},\]

where

\[C =\frac{(1+\mathsf{h}^{2})}{2\mathsf{h}^{2}}T\sup_{t\in[0,T]} \big{(}\int_{\mathbb{R}^{d}}\frac{\Gamma_{t}^{\leftarrow-2}}{\rho_{t}^{ \leftarrow}}\big{)}\exp\big{(}\int_{0}^{T}C_{r}^{\leftarrow,(2)}\kappa_{r}^{ \leftarrow}+C_{r}^{\leftarrow,(1)}\mathrm{d}r\big{)}\] \[\lesssim\frac{T}{2}\sup_{t\in[0,T]}\big{(}\int_{\mathbb{R}^{d}} \frac{\Gamma_{t}^{\leftarrow-2}}{p_{t}^{\leftarrow}}\big{)}\exp\big{(}\int_{0} ^{T}C_{r}^{\leftarrow,(2)}m_{r}^{\leftarrow}+(\lim_{\mathsf{h}\to\infty}C_{r}^{ \leftarrow,(1)})\mathrm{d}r\big{)}.\]

Please refer to Lem. E.3 for \(\lim_{\mathsf{h}\to\infty}C_{r}^{\leftarrow,(1)}\).

### Lower bound

The lower bound can be proved in the same way: by Cauchy-Schwarz inequality again,

\[L(\mathsf{h}) \geq(1-\alpha^{2})\mathcal{T}_{1}+(1-\alpha^{-2})\mathcal{T}_{2}\] \[\geq(1-\alpha^{2})\mathcal{T}_{1}-(\alpha^{-2}-1)C\frac{(1+ \mathsf{h}^{2})\exp\big{(}-\mathsf{h}^{2-\beta}\gamma\big{)}}{\gamma}.\]

The remaining task is to estimate \(\mathcal{T}_{1}\).

#### Asymptotic limit of \(\mathcal{T}_{1}\)

We only provide an asymptotic result below. As \(a\ll 1\),

\[\mathcal{T}_{1} :=\frac{(1+\mathsf{h}^{2})^{2}}{8}\int_{\mathbb{R}^{d}}\frac{ \big{(}\int_{T-a}^{T}\Phi_{t,T}^{(h^{-})}(\Gamma_{t}^{\leftarrow})\mathrm{d}t \big{)}^{2}}{p_{0}}\] \[\sim\frac{(1+\mathsf{h}^{2})^{2}}{8}\int_{\mathbb{R}^{d}}\frac{1} {p_{0}}\Big{(}\big{(}\int_{T-a}^{T}\Phi_{t,T}^{(h^{-})}\ \mathrm{d}t\big{)}(\Gamma_{T}^{\leftarrow})\Big{)}^{2}\] \[\sim\frac{(1+\mathsf{h}^{2})^{2}}{8}\int_{\mathbb{R}^{d}}\frac{1} {p_{0}}\Big{(}\int_{T-a}^{T}\exp\big{(}\frac{\mathsf{h}^{2}}{2}(T-t)\mathcal{K }_{T}^{\leftarrow})\Gamma_{T}^{\leftarrow}\ \mathrm{d}t\Big{)}^{2}\] \[\sim\frac{(1+\mathsf{h}^{2})^{2}}{8}\int_{\mathbb{R}^{d}}\frac{1} {\rho_{0}}\Big{(}\int_{T-a}^{T}\exp\big{(}\frac{\mathsf{h}^{2}}{2}(T-t) \mathcal{K}_{T}^{\leftarrow})\Gamma_{T}^{\leftarrow}\ \mathrm{d}t\Big{)}^{2},\]

where we used \(\Gamma_{t}^{\leftarrow}\approx\Gamma_{T}^{\leftarrow}\), when \(t\approx T\) in the second line; we used \(\frac{\mathcal{L}_{t}^{(h^{-})}}{\mathsf{h}^{2/2}}\approx\frac{\mathcal{L}_{T }^{(h^{\leftarrow})}}{\mathsf{h}^{2/2}}\) when \(t\approx T\) in the third line; \(\mathcal{L}_{T}^{(h^{-})}=\nicefrac{{\mathsf{h}^{2}}}{{2}}/\mathcal{K}_{T}^{ \leftarrow}\) (40) herein. In the last line, we used the fact that \(\rho_{0}\sim p_{0}\) when \(\mathsf{h}\to\infty\).

By Lem. D.2,

\[\mathcal{T}_{1}\sim \frac{(1+\mathsf{h}^{2})^{2}}{8}\sum_{k=1}^{\infty}\big{(}\frac{ 1-e^{-a\frac{\mathsf{h}^{2}}{2}\lambda_{k}^{(\mathsf{h})}}}{\frac{\mathsf{h}^ {2}}{2}\lambda_{k}^{(\mathsf{h})}}\big{)}^{2}\big{(}\alpha_{k}^{(\mathsf{h})} \big{)}^{2}\] \[\sim \frac{1}{2}\sum_{k=1}^{\infty}\big{(}\frac{\alpha_{k}^{(\mathsf{ h})}}{\lambda_{k}^{(\mathsf{h})}}\big{)}^{2}\qquad(\text{by }a=\mathsf{h}^{-\beta},\ \mathsf{h}\gg 1),\]

where \((\lambda_{k}^{(\mathsf{h})},\phi_{k}^{(\mathsf{h})})\) are eigen pairs of \(\mathcal{K}_{T}^{\leftarrow}\) and \(\Gamma_{T}^{\leftarrow}=\sum_{k=1}^{\infty}\alpha_{k}^{(\mathsf{h})}\phi_{k}^ {(\mathsf{h})}\). When \(\mathsf{h}\to\infty\), we know that the eigenvalues of \(\mathcal{K}_{T}^{\leftarrow}\), which depends on \(\mathsf{h}\) and has the form

\[\mathcal{K}_{T}^{\leftarrow}(\mu)(x)=\bigtriangleup\mu(x)+\bm{\nabla}\bm{ \cdot}\big{(}\nabla U_{0}(x)\mu(x)\big{)}+\mathsf{h}^{-2}\bm{\nabla}\bm{\cdot }\Big{(}\big{(}\nabla U_{0}(x)-x\big{)}\mu\Big{)},\]

should converge to \(\mathcal{K}^{\infty}\), defined as

\[\mathcal{K}^{\infty}(\mu):=\bigtriangleup\mu+\bm{\nabla}\bm{\cdot}(\nabla U_ {0}\mu).\]

Therefore, in the limit,

\[\lim_{\mathsf{h}\to\infty}\mathcal{T}_{1}=\frac{1}{2}\sum_{k=1}^{\infty} \big{(}\alpha_{k}^{(\infty)}/\lambda_{k}^{(\infty)}\big{)}^{2},\]

where \((\lambda_{k}^{(\infty)},\phi_{k}^{(\infty)})\) are eigen pairs of \(\mathcal{K}^{\infty}\) and \(\Gamma_{T}^{\leftarrow}=\sum_{k=1}^{\infty}\alpha_{k}^{(\infty)}\phi_{k}^{( \infty)}\).

#### Upper bound of \(\mathcal{T}_{1}\)

By the upper bound in Lem. D.2 (together with \(a=\mathsf{h}^{-\beta}\) and \(\mathsf{h}\gg 1\)) or by applying \(\lambda_{k}^{(\mathsf{h})}\geq\kappa_{0}\) directly to the asymptotic of \(\mathcal{T}_{1}\), when \(\mathsf{h}\gg 1\),

\[\mathcal{T}_{1}\lesssim\frac{1}{2\kappa_{0}^{2}}\int_{\mathbb{R}^{d}}\frac{ \Gamma_{T}^{\leftarrow-2}}{\rho_{0}}=\frac{1}{2\kappa_{0}^{2}}\int_{\mathbb{R} ^{d}}\frac{(\bm{\nabla}\bm{\cdot}(p_{T}^{\leftarrow}\mathcal{E}_{T}^{ \leftarrow}))^{2}}{\rho_{0}}\sim\frac{1}{2m_{0}^{2}}\int_{\mathbb{R}^{d}}\frac{( \bm{\nabla}\bm{\cdot}(p_{0}\mathcal{E}_{T}^{\leftarrow}))^{2}}{p_{0}}.\]

The term \(\mathcal{T}\) in Prop. 3.6 is simply the limit of \(\mathcal{T}_{1}\).

### Remark on the large diffusion limit

#### Score function parameterization in constrained score models

We would like to remark on the parameterization of score function. It is common in literature to directly parameterize \(\mathfrak{S}_{t}\) (4) via some neural network. However, in general, this practice can

[MISSING_PAGE_EMPTY:28]

In this example, there is only one source of error, which is \(\mathscr{E}^{\leftarrow}\), as we know explicitly the distribution \(p_{T}\) and we can choose the time step small enough such that numerical discretization error is negligible. Due to the structure of the score function, it is reasonable to consider the following ansatz

\[\mathscr{E}^{\leftarrow}_{t}(x)=\alpha_{t}x.\] (43)

This example has explicit formulas: \(\widetilde{Y}_{T}\) is a Gaussian distribution with \(\mathbb{E}[\widetilde{Y}_{T}]=0\) and

\[\text{Var}(\widetilde{Y}_{T})=G_{T}^{-2}\text{Var}(\widetilde{Y}_{0})+\int_{0 }^{T}G_{T}^{-2}G_{t}^{2}h_{t}^{\leftarrow 2}\;\mathrm{d}t,\]

where

\[G_{t}:=\exp\big{(}-\int_{0}^{t}\frac{1}{2}+\frac{1+h_{s}^{\leftarrow 2}}{2}(- \frac{1}{\sigma_{T-s}^{2}}+\epsilon\alpha_{s})\mathrm{d}s\big{)}.\]

The sample generation error quantified by KL divergence also has an explicit formula:

\[\text{KL}\big{(}p_{0}||\widetilde{q}_{T}\big{)}=\frac{1}{2}\log\big{(}\frac{ \text{Var}(\widetilde{Y}_{T})}{\sigma_{0}^{2}}\big{)}+\frac{\sigma_{0}^{2}}{ 2\text{Var}(\widetilde{Y}_{T})}-\frac{1}{2}.\]

### Experiment 1: Fix error magnitude \(\epsilon\) and consider various error types

We choose \(T=2\), \(h_{t}^{\leftarrow}=\mathsf{h}\) for all \(t\in[0,T]\), and the error function is chosen as

\[\epsilon=0.02,\qquad\mathscr{E}^{\leftarrow}_{t}(x)=\nabla\log p_{t}^{ \leftarrow}(x)\times\begin{cases}\begin{array}{rl}1&\text{case }1;\\ -1&\text{case }2;\end{array}\\ \frac{1+\sin(2\pi t/T)}{2}&\text{case }3;\\ \mathbb{I}_{t<0.95T}&\text{case }4;\\ \mathbb{I}_{t>0.99T}&\text{case }5.\end{cases}\] (44)

For these choices, we only perturb the true score function by a bounded prefactor. We can observe that the error \(\text{KL}\big{(}p_{0}||\widetilde{q}_{T}\big{)}\) is a complicated function of \(\mathsf{h}\) in general in Fig. 6. When we only perturb the score function during the initial period of the generative process (case 4), we can clearly observe that the sampling error decays exponentially fast with respect to \(\mathsf{h}^{2}\), which numerically validates Prop. 3.4. When we only perturb the score function near the end of the generative process (case 5), increasing the diffusion coefficient \(\mathsf{h}\) will actually increase the error, which is predicted by Prop. 3.5. For a general error (case 1, 2, 3), overall we can still expect that increasing diffusion coefficient \(\mathsf{h}\) will generally suppress the error when \(\sigma_{0}\) is small.

### Experiment 2: consider \(L(\mathsf{h})\) for various error types

We further numerically approximate \(L(\mathsf{h})\equiv L(\mathsf{h},\mathscr{E}^{\leftarrow},p_{0})\) by linear regression and study how \(\sigma_{0}\) (i.e., the data distribution \(p_{0}\)), error type \(\mathscr{E}^{\leftarrow}\), and diffusion coefficient \(\mathsf{h}\) affect the leading order term \(L(\mathsf{h},\mathscr{E}^{\leftarrow},p_{0})\). Recall that we use \(L(\mathsf{h})\) as a simplified notation when \(\mathscr{E}^{\leftarrow}\) and \(p_{0}\) are clear from context; see SS 3. As a remark, to approximate \(L(\mathsf{h})\), we used the leading-order approximation that \(\text{KL}\big{(}p_{0}||\widetilde{q}_{T}\big{)}=L(\mathsf{h})\epsilon^{2}+ \mathcal{O}\big{(}\epsilon^{3}\big{)}\): we choose a few \(\epsilon\) values and use linear regression to estimate \(L(\mathsf{h})\)

\begin{table}
\begin{tabular}{c c c c} \(\sigma_{0}\) & Case 1 & Case 2 & Case 3 \\ \hline
0.2 & 0.2567 & 0.3032 & 0.0658 \\
0.4 & 0.2569 & 0.3028 & 0.0636 \\
0.6 & 0.2570 & 0.3018 & 0.0597 \\
0.8 & 0.2569 & 0.3023 & 0.0544 \\ \hline
1.5 & 0.2570 & 0.3017 & 0.0321 \\
2.0 & 0.2564 & 0.3022 & 0.0198 \\
3.0 & 0.2566 & 0.3020 & 0.0121 \\ \end{tabular}
\end{table}
Table 3: Approximated value of \(L(\mathsf{h})\) when \(\mathsf{h}^{2}\approx 20\). We can observe that in each column (referring to a specific error type) the value is almost independent of the \(\sigma_{0}\) in particular when \(\sigma_{0}<1\).

In Fig. 7, we can clearly observe that \(L(\text{h})\) converges to a constant extremely fast when \(\text{h}\) increases for cases \(\sigma_{0}<1\). The value of \(\mathcal{E}_{T}^{\text{e}+}\) for the case 3 is only \(1/2\) of that for case 1 and case 2. By Prop. 3.6, we know that \(\lim_{\text{h}\rightarrow\infty}L(\text{h})\) for the case 3 should be approximated \(1/4\) of that for cases 1 and 2. This is also (approximately) numerically observed in Table 3.

## Appendix H More details about numerical experiments in SS 4

In this section, we discuss datasets, network architectures, evaluation metrics, numerical schemes (exponential integrator), and the default weight in denoising score matching.

### Datasets

* **1D 2-mode Gaussian mixture**: \(p_{0}(x)=\sum_{i=1}^{2}0.5\mathcal{N}\big{(}x;(-1.0)^{i},0.01\big{)}\).
* **2D 4-mode Gaussian mixture**: \(p_{0}(x)=\sum_{i,j=1}^{2}0.25\mathcal{N}\big{(}x;((-1.0)^{i},(-1.0)^{j}),0.05^{ 2}\bm{I}_{2}\big{)}\).
* **Swiss roll**: Swiss roll generates samples by \((x,y)=\big{(}t\sin(t),t\cos(t)\big{)}\) with \(t\) drawn from the uniform distribution \(\mathcal{U}(\frac{3\pi}{2},\frac{9\pi}{2})\).

Figure 7: We show \(\log_{10}\left(L(\mathrm{h})\right)\) as a function of \(\mathrm{h}^{2}\) for the 1D Gaussian model. \(T=2\), different \(\sigma_{\mathrm{u}}\) and error functions in (44) are considered.

* **MNIST**: MNIST [34] contains 60,000 28 \(\times\) 28 gray-scale images with hand-written digits.
* **CIFAR-10**: CIFAR-10 [22] contains 60,000 32 \(\times\) 32 RGB images with ten categories.

### Network architectures and other parameters

For experiments on 1D/2D Gaussian mixtures, the exact scores can be obtained analytically if we use VP-SDE. We set \(T=4\) and \(g_{t}=1\) for \(t\in[0,T]\). For the time discretization when solving the reverse SDE with Euler-Maruyama method, we apply 40,000 steps and 80,000 steps for 1D and 2D Gaussian mixtures, respectively.

For experiments on Swiss roll, we apply a three-layer neural network for score matching, where the width of each layer is set as \(50\), \(50\), and \(2\) and we apply ReLU as the nonlinear activation for two hidden layers. We set \(T=1\) and \(g_{t}=\sqrt{0.1(1-t)+20t}\) for \(t\in[0,T]\). The learning rate is set as 0.01 and decays by \(0.5\) every 8,000 steps. The batch size is set as 400. We train the neural network for 20,000 steps. For the time discretization when solving the reverse SDE with Euler-Maruyama method, we apply 20,000 steps.

For experiments on MNIST, we apply the net architecture in [17] for score matching, where we use two resolution blocks in U-net and set the multipliers of channels to be one and two. We set \(T=1.4\) and \(g_{t}=\sqrt{0.1(1-t)+20t}\) for \(t\in[0,T]\). The number of iteration is \(20,000\), the batch size is set as \(64\). We solve the reverse SDE with exponential integrator; see also Appx. H.4.

For experiments on CIFAR-10, we apply the DDPM++ cont. in [30] as the net architecture, and use their pretrained checkpoint in for score estimation. We use the same setting as [30], i.e., \(T=1\) and \(g_{t}=\sqrt{0.1(1-t)+20t}\) for \(t\in[0,T]\). For the time discretization when sampling with Euler-Maruyama method, we apply 100, 200, 500, 1000, 2000, 3000 and 4000 steps.

### Evaluation metrics

For experiments of 1D/2D Gaussian mixtures and Swiss roll, we apply approximated divergences for evaluating the performances. Specifically, we discretize the space into 100 bins in each dimension, then obtain the empirical densities of 10,000 true samples and 10,000 generated samples, and use Jensen-Shannon divergence, Kullback-Leibler divergence and Wasserstein distance between both empirical densities as the metrics for evaluation.

### Exponential integrator

We shall explain the exponential integrator for (2) with \(t\in[0,T]\), i.e., the following equation

\[\mathrm{d}Y_{t} =-f_{t}^{\leftarrow}(Y_{t})\;\mathrm{d}t+\frac{(g_{t}^{ \leftarrow})^{2}+(h_{t}^{\leftarrow})^{2}}{2}\nabla\log p_{t}^{\leftarrow}(Y_ {t})\;\mathrm{d}t+h_{t}^{\leftarrow}\;\mathrm{d}W_{t}\] \[=\frac{1}{2}g_{t}^{\leftarrow 2}Y_{t}\;\mathrm{d}t+\frac{(g_{t}^{ \leftarrow})^{2}+(h_{t}^{\leftarrow})^{2}}{2}\nabla\log p_{t}^{\leftarrow}(Y_ {t})\;\mathrm{d}t+h_{t}^{\leftarrow}\;\mathrm{d}W_{t}\,.\]

Then for any time \(t\in[t_{k},t_{k+1}]\), and given \(\hat{Y}_{t_{k}}\), we approximate the above dynamics by

\[\mathrm{d}\hat{Y}_{t} \approx\frac{1}{2}g_{t}^{\leftarrow 2}\hat{Y}_{t}\;\mathrm{d}t+ \frac{(g_{t}^{\leftarrow})^{2}+(h_{t}^{\leftarrow})^{2}}{2}\nabla\log p_{t_{k }}^{\leftarrow}(\hat{Y}_{t_{k}})\;\mathrm{d}t+h_{t}^{\leftarrow}\;\mathrm{d}W _{t}\,.\]

This dynamics is a linear SDE and we can solve it exactly

\[\hat{Y}_{t_{k+1}} =\underbrace{e^{\frac{1}{2}\int_{t_{k}}^{t_{k+1}}g_{s}^{ \leftarrow 2}\;\mathrm{d}s}\hat{Y}_{t_{k}}+\Big{[}\int_{t_{k}}^{t_{k+1}}e^{\frac{1}{2} \int_{t_{k}}^{t_{k+1}}g_{s}^{\leftarrow 2}\;\mathrm{d}s}\frac{g_{t}^{ \leftarrow 2}+h_{t}^{\leftarrow 2}}{2}\;\mathrm{d}t\Big{]}\bm{S}_{k}}_{=:\hat{\mathcal{S}_{1}}}\] \[\bm{S}_{k} :=\nabla\log p_{t_{k}}^{\leftarrow}(\hat{Y}_{t_{k}}).\]Therefore,

\[\hat{Y}_{t_{k+1}}=\mathscr{T}_{1}+\sqrt{\int_{t_{k}}^{t_{k+1}}\big{(} \mathscr{T}_{2}\big{)}^{2}\;\mathrm{d}t}\;Z_{k},\qquad Z_{k}\sim\mathcal{N}(0,I_ {d}).\]

If we pick

\[\begin{cases}h_{t}^{\leftarrow}=\alpha g_{t}^{\leftarrow}, \qquad\alpha\in\mathbb{R}^{+},\\ g_{t}=\sqrt{\beta_{0}+(\beta_{1}-\beta_{0})t}\qquad\text{which implies that}\qquad g_{t}^{\leftarrow}=\sqrt{\beta_{0}+(\beta_{1}-\beta_{0})(T-t)}, \end{cases}\]

then after straightforward calculations,

\[\hat{Y}_{t_{k+1}}=\gamma_{k}\hat{Y}_{t_{k}}+(1+\alpha^{2})\Big{(} \gamma_{k}-1\Big{)}\bm{S}_{k}+\sqrt{\alpha^{2}\Big{(}\gamma_{k}^{2}-1\Big{)}} Z_{k},\]

where \(\delta_{k}:=t_{k+1}-t_{k}\) and \(\gamma_{k}:=\exp\big{(}\frac{\delta_{k}\big{(}2\beta_{0}+(2t_{k}-2T+\delta_{ k})(\beta_{0}-\beta_{1})\big{)}}{4}\big{)}\).

### Default training weight

Given the fixed \(X_{0}\), we can explicitly solve (1) (with the choice \(f_{t}(x)=-\frac{g_{t}^{2}}{2}x\)):

\[X_{t}=(G_{t})^{-1}X_{0}+\int_{0}^{t}G_{t}^{-1}G_{s}g_{s}\;\mathrm{d}W_{s},\]

where \(G_{t}=\exp\big{(}\int_{0}^{t}\frac{g_{s}^{2}}{2}\;\mathrm{d}s\big{)}\). The standard deviation of the Brownian motion term above is

\[\varpi_{t}:=\sqrt{\int_{0}^{t}G_{t}^{-2}G_{s}^{2}\;g_{s}^{2}\; \mathrm{d}s}.\]

When \(g_{t}=\sqrt{\beta_{0}+(\beta_{1}-\beta_{0})t}\) as used in many literature [30, 17], we can explicitly solve for \(\varpi_{t}\):

\[\varpi_{t}=\sqrt{1-\exp\!\left(-\frac{1}{2}t^{2}(\beta_{1}-\beta_{0})-t\beta _{0}\right)}.\]

In literatures, to balance the noise over time in training the score function, a common practice is to use the default weight \(\omega_{t}=\varpi_{t}^{2}\) (5) in the (denoising) score-matching loss function (4).

### Additional numerical results for experiments in SS 4

We present more numerical results on 1D Gaussian mixture, Swiss roll, and MNIST to further verify theoretical results.

#### 1D Gaussian mixture

We evaluate the performances of generative models under different values of h for 1D Gaussian mixture, and present the visualization and numerical results in Fig. 8 and Fig. 9, respectively. In Fig. 8, a clear trend shows that with increasing h, the empirical density of generated samples better matches the true density function. This trend is more quantitatively captured in Fig. 9, from which we clearly observe that the distance between the empirical and the true density function decreases to the numerical threshold exponentially fast. Numerical threshold means the error of various distances when \(\epsilon=0\); due to the space discretization when computing various distances, the numerical values of various distances are not exactly zero even when we use the exact score function. However, increasing h can help us to almost reach this limit and this phenomenon is theoretically described in Prop. 3.4.

Figure 8: Visualization of 1D GMM, where \(\mathscr{E}_{t}^{\leftarrow}(x)=\nabla\log p_{t}^{\leftarrow}(x)\). We can observe that increasing h can help to generate samples with a distribution closer to the true \(p_{0}\).

#### Swiss roll

In Fig. 10, we provide additional figures to discuss the effect of time-discretization. When the numerical error is negligible, we can observe that the generative process with a larger \(\mathsf{h}\) can provide a clearer picture of Swiss roll, as shown in Fig. 9(c). However, when the discretization error cannot be ignored, the conclusion may be reversed. Therefore, it is necessary to design and employ more accurate numerical methods for models with large \(\mathsf{h}\) in order to fully benefit from diffusion models with a large diffusion coefficient.

In Fig. 11, we display JS and KL divergences between the true density \(p_{0}\) and the generated samples. Since the data distribution of Swiss roll is highly localized (data is concentrated on a curve embed in 2D), accurately computing the KL divergence poses a significant numerical challenge. That is why we use Wasserstein distance instead in Fig. 4(a). Based on more robust symmetric metrics (i.e., the JS and Wasserstein distance herein), we can observe that a larger \(\mathsf{h}\) can indeed diminish the error in sample generation.

Figure 10: Visualization results of Swiss roll with different number of time steps.

Figure 9: Numerical results of 1D 2-mode Gaussian mixture. We can observe that the distance between the empirical density and the true density function decreases as \(\mathsf{h}\) increases, when \(\mathcal{E}_{T}^{\leftarrow}\) is not extremely large.

### Mnist

We conduct further experiments to explore the effect of \(h^{\leftarrow}\) and the time discretization steps. It is important to note that if one has an extremely well trained score function, then the effect of \(h^{\leftarrow}\) is indeed negligible, as shown in (3). To somewhat magnify the score training error for MNIST (but with a reasonable score function), we increase the time \(T\) and use a smaller architecture with fewer parameters; the reason of the occasional failure to generate clear MNIST images in later figures comes from this **deliberate experimental design**.

For an existing pre-trained score function with non-negligible error, we notice that increasing \(h^{\leftarrow}\) can almost **ubiquitously** improve the quality of sample generation; see Fig. 12 (as well as Fig. 15 and Fig. 16 under different training setup). This improvement is supported by our theoretical results, particularly Prop. 3.4. Notably, even when choosing \(h^{\leftarrow}=0\) (ODE) and \(h^{\leftarrow}=g^{\leftarrow}\) (the default diffusion model in many studies) occasionally fail to generate an image, simply by increasing the magnitude of \(h^{\leftarrow}\) (possibly at the cost of more computational resources), we have a larger chance of generating an image with reasonable quality; for instance, see the last row in Fig. 12 (particularly see the last row in Fig. 15). The ODE-based model sometimes fails to generate hand-writing digits even when the step number is \(10^{3}\), whereas the diffusion model (with large \(h^{\leftarrow}\)) does **not** encounter this issue. This conclusion might be reversed when the time step size is large, which is similarly observed in the Swiss roll.

The computational cost of SDE-based models with large diffusion (\(h^{\leftarrow}>g^{\leftarrow}\)) is relatively high due to the necessity of a larger number of time steps: a larger \(h^{\leftarrow}\) has the similar effect as running Langevin for a larger time horizon as discussed in SS 3.3 and a longer time simulation is expected to be more expensive and also its accuracy largely relies on a well-chosen time step. However, this can be offset by the ability to use a lightweight architecture that possibly speeds up the generative process. A detailed comparison of various diffusion-based models with the same computational budget constraint is challenging and is slightly beyond the scope of this work, and we will leave this task to future work.

Figure 11: Numerical results of Jensen-Shannon divergence and Kullback-Leibler divergence of Swiss roll.

Figure 12: Visualization of sample generation in MNIST where we used **default weight**\(\omega\) (5). We use different random seed to ensure robustness and this is the result for trial \(1\). Results for trial \(2\) is not included in this work as the overall tendency remains the same.

Numerical experiments for adopting different weight in training

We have two reasons to explore the effects of various weight functions in training.

The first reason is that theoretically, any positive scalar-valued functions \(\omega_{t}\) on \((0,T)\) is a valid candidate. This prompts the question of whether such a default weight function (5) is optimal in designing the loss function. We fully acknowledge that the default choice adopted in most literatures is a very effective one. However, the mathematical reason behind it is still not satisfactory in our opinion. This motivates us to ask whether the default choice is really the optimal one, at least in certain circumstances.

The second (and actually the primary reason) comes from our theoretical predictions discussed in SS 3.7. As there is a tight connection between the optimal reverse-time generative process and the time-distribution of the score error (see Prop. 3.4, Prop. 3.5 and Prop. 3.6), if we are willing to train or re-train the score function and are interested in using the ODE-based model (for fast sample generation), it appears that we should focus more on the noise's end comparatively. To achieve this goal, namely, to control the distribution of score error, we adopt different weight schemes in the loss function **only** for training: default weight in (5), a data-driven case (more weight in the data side) and a noise-driven case (more weight in the noise side):

\[\omega_{t}=\begin{cases}\frac{\varpi_{t}^{3}}{0.25+\varpi_{t}}&\text{\text{ \text{data-driven, or simply referred as ``**data"**}}.}\end{cases}\] (45)

There is no theoretical reasons behind the noise-driven and data-driven choices in the last equation. We merely experiment with two reasonable choices and at the same time they are expected to help us control the time distribution of the score error.

After the initial camera-ready version of this work, we notice that such a weight design (in particular the noise-driven weight) has also been studied in [12]. Their experiments seem to provide further evidence about the validity of our arguments. However, we would like to emphasize that the approaches and perspectives towards proposing such a weight design are different: in [12], their conjecture is based on an insightful perception argument, whereas we take a mathematical approach and come up with the design based on the above error accumulation analysis.

### Our guess

Based on our theoretical results, we guess that if a different weight function can really achieve our expected goal (namely, control the time distribution of the score function), the noise-driven case should be more suitable for ODE models, and the data-driven weight should give us the worst performance for ODE models.

We remark that this conjecture is surely **not universal**, and its validity remains to be fully validated by more benchmark experiments. Nevertheless, our numerical experiments below suggest its potential usefulness and it prompts an interesting question to explore and design the optimal score-matching loss function, which is **rarely** studied in literature. In what follows, we report numerical experiments for MNIST and CIFAR-10.

### Mnist

We used different weights to train the score function and then visualize their generated samples in Fig. 13. We can clearly observe that the score function trained by the noise-driven weight produces comparatively better samples in ODE models. We plot the denoising score-matching loss for score functions obtained from training with various weights in Fig. 14:

* to make the comparison more straightforward, we visualize the time-distribution of **relative score-matching loss** rather than the absolute value, namely, we demonstrate: \[t\mapsto\frac{\mathbb{E}_{X_{0}\sim p_{0}}\mathbb{E}_{X_{t}\sim p _{t|0}(\cdot|X_{0})}\Big{[}\big{\|}\big{(}\mathfrak{S}^{(i)}\big{)}_{t}(X_{t} )-\nabla\log p_{t|0}(X_{t}|X_{0})\big{\|}^{2}\Big{]}}{\mathbb{E}_{X_{0}\sim p_{ 0}}\mathbb{E}_{X_{t}\sim p_{t|0}(\cdot|X_{0})}\Big{[}\big{\|}\big{(}\mathfrak{S }^{(\text{default})}\big{)}_{t}(X_{t})-\nabla\log p_{t|0}(X_{t}|X_{0})\big{\|}^ {2}\Big{]}},\;\;i\in\big{\{}\text{noise},\;\text{data}\big{\}},\] (46)

[MISSING_PAGE_EMPTY:39]

Figure 14: Score-matching loss for data-driven and noise-driven case on MNIST, compared with the default case

Figure 15: Visualization of sample generation in MNIST where we used **data-driven weight**\(\omega\) (45). We use different random seed to ensure robustness and this is the result for trial 1. Results for trial 2 is not included in this work as the overall tendency remains the same.

Figure 16: Visualization of sample generation in MNIST where we used **noise-driven weight**\(\omega\) (45). We use different random seed to ensure robustness and this is the result for trial 1. Results for trial 2 is not included in this work as the overall tendency remains the same.

### Cifar-10

We carry out a similar experiment for CIFAR-10 to test the effect of training weights \(\omega_{t}\): we used the same initialization (referred to as the trial number below) and all other hyper-parameters, except that we employ different weights in score-matching loss (4). The same architecture is used as in [17] for CIFAR-10 and the detailed hyper-parameters can be found in source codes.

In Fig. 17, we observe that overall over the whole training period, the noise-driven weight leads into a score function estimate no worsen than that by the default weight: due to stochastic fluctuations and other uncertainties (in particular if we adopt the mixed precision training), there is no guarantee that the noise-driven one is always better, but the overall tendency is still observable and clear. In Fig. 18, the noise-driven one actually has a slightly larger score-matching loss (SML) than the default one (which could be possibly explained by how we measure the SML in Fig. 18). What is interesting is that score functions trained by the noise-driven weight and the data-driven weight have a similar SML, which both decay at the similar pace; however, the FID values for the score function estimate by noise-driven weight are much smaller than that by the data-driven weight. This apparent gap clearly explains that apart from the total score-matching loss (which does matter), **the time distribution of the score error plays an important role in determining the final sampling error,** echoing our theoretical results in SS 3.

For instance, in Fig. 17, if we consider the first experiment (i.e., trial=0) with float16 mixed-precision training (i.e., mixed=True), we notice that relatively near 80k and 120k training iterations, the performance of noise-driven one is much better than the default one, which is consistent with Fig. 19 that the relative loss near \(t\approx T\) is more minimised for iterations 80k and 120k, compared with other iteration stages. Moreover, for the same experiment in Fig. 17, the data-driven one has a much worsen FID value at iteration 200k, which is compatible with the increasing relative error near the noise's end (i.e., \(t\approx T\)) in the last row of Fig. 19. For the remaining three experimental setup (either different initialization or training precision), we notice a similar consistency between how the **time-distribution of the SML behaves** and how **FID values change**. This relation, so far, still cannot be used as a rigorous quantitative indicator to predict one based on the other quantity, but qualitatively, the above explained relationship does appear to be numerically valid and theoretically sound.

**In summary**, if we have two score functions \(\mathfrak{S}_{1}\) and \(\mathfrak{S}_{2}\) from training:

* If the SML for \(\mathfrak{S}_{1}\) is much larger than the SML for \(\mathfrak{S}_{2}\), then we can probably confidently expect that \(\mathfrak{S}_{2}\) is a more accurate estimate.
* However, when the total SML (4) for both are close, then the time-distribution of the score-matching loss together with which generative dynamics is chosen will play a significant role in determining the final sample generation quality, which is probably largely overlooked in current literature as far as we know. A full investigation and in particular whether it is possible to adapt this observation to achieve the state-of-art models will be left to the next stage of research.

Figure 17: We visualize FIDs of score-training estimates by various weights with respect to the number of training iteration. We consider ODE models (i.e., \(h=0\)) when computing FIDs. Trial = 0, 1 refers to different neural network initialization; mixed=True means we use float16 mixed-precision for training; mixed=False means we use 32-bit precision.

Figure 18: We visualize score-matching loss (4) for score function trained using various weights with respect to the number of training iteration’s. Trial = 0, 1 refers to different training initialization; mixed=True means we use float16 mixed-precision for training; mixed=False means we use 32-bit precision. When we compare SML for different score functions above, we consistently use the “default” weight for fairer comparison, even though some score functions are trained using different weight functions; we also use the test dataset to approximately represent \(p_{0}\).

Figure 19: **The first independent experiment with the float16 mixed precision training**: We visualize the relative time distribution of the SML (46) (on the left) and the time distribution of SML (on the right) for various training weights and for various training stages (each row).

Figure 20: **The first independent experiment with the full 32-bit precision training**: We visualize the relative time distribution of the SML (46) (on the left) and the time distribution of SML (on the right) for various training weights and for various training stages (each row).

Figure 21: **The second independent experiment with the float16 mixed precision training**: We visualize the relative time distribution of the SML (46) (on the left) and the time distribution of SML (on the right) for various training weights and for various training stages (each row).

Figure 22: **The second independent experiment with the full 32-bit precision training**: We visualize the relative time distribution of the SML (46) (on the left) and the time distribution of SML (on the right) for various training weights and for various training stages (each row).