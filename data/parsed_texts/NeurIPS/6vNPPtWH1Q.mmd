# Energy-based Epistemic Uncertainty

for Graph Neural Networks

 Dominik Fuchsgruber, Tom Wollschlager, and Stephan Gunnemann

School of Computation, Information and Technology & Munich Data Science Institute

Technical University of Munich, Germany

{d.fuchsgruber, tom.wollschlaeger, s.guennemann}@tum.de

###### Abstract

In domains with interdependent data, such as graphs, quantifying the epistemic uncertainty of a Graph Neural Network (GNN) is challenging as uncertainty can arise at different structural scales. Existing techniques neglect this issue or only distinguish between structure-aware and structure-agnostic uncertainty without combining them into a single measure. We propose GEBM, an energy-based model (EBM) that provides high-quality uncertainty estimates by aggregating energy at different structural levels that naturally arise from graph diffusion. In contrast to logit-based EBMs, we provably induce an integrable density in the data space by regularizing the energy function. We introduce an evidential interpretation of our EBM that significantly improves the predictive robustness of the GNN. Our framework is a simple and effective post hoc method applicable to any pre-trained GNN that is sensitive to various distribution shifts. It consistently achieves the best separation of in-distribution and out-of-distribution data on 6 out of 7 anomaly types while having the best average rank over shifts on _all_ datasets.

## 1 Introduction

Quantifying and understanding uncertainty is crucial to developing safe and reliable machine learning systems. Many applications such as Reinforcement Learning [42], Active Learning [5, 31] or Out-of-Distribution detection [60] benefit from disentangling different facets of uncertainty [54, 17, 46]. Typically, one distinguishes between an irreducible _aleatoric_ component and reducible _epistemic_ factors [29]. The former is inherent to the data, while the latter is rooted in a lack of knowledge. One way to quantify epistemic uncertainty is to define a classifier-dependent density over the data domain [55]. High values indicate similarity to the training data and thus imply low epistemic uncertainty. Energy-based models (EBMs) induce this density by defining an energy function that assumes low values near the training data [38]. A common choice is the logits of the classifier as their magnitude is supposed to correlate with the model confidence [40]. However, many architectures have been shown to produce arbitrarily overconfident predictions far from the training data [28]. The negative implications for logit-based EBMs are only scarcely discussed in the literature [35, 36].

While substantial effort has been directed toward uncertainty estimation for independent and identically distributed (i.i.d.) problems [1, 24, 49, 37, 6, 22], graphs have only recently received attention within the community [71, 64, 67, 21]. There, uncertainty can arise at different structural scales, e.g., from only a single node, clusters, or global properties. Previous work only accounts for this implicitly by applying techniques from i.i.d. domains to Graph Neural Networks (GNNs) [67, 49]. A recent approach distinguishes only between structure-aware and structure-agnostic uncertainty [64] while not combining them into a single measure, which is often required in downstream applications [42, 54]. Consequently, estimates are often only sensitive to shifts that match their structural resolution. They may overfit certain anomaly types and not be reliable in general.

We address these shortcomings and propose a novel graph-based EBM (GEBM) that is structure-aware at different levels. The core idea behind GEBM is to define energy functions at different structural abstractions and facilitate the flexibility of the EBMs to aggregate them into a single, theoretically grounded measure. Interestingly, we find that interleaving a graph diffusion process with energy marginalization gives rise to energy functions that naturally capture patterns of different granularity. As depicted in Figure 1, we utilize three energy types: (i) _Group_ energy corresponds to evidence smoothing and emphasizes anomalies clusters within the graph while not distinguishing between their type locally. (ii) _Local_ energy is more granular and sensitive to evidence disagreements in the neighborhood of a node. (iii) _Independent_ energy is fully structure-agnostic and describes patterns that are limited to individual nodes. Aggregating them using soft maximum selection induces a single energy measure that assigns high uncertainty to anomalies at various scales. A Gaussian regularizer provably ensures that GEBM converges to low confidence far from the training data.

We evaluate GEBM over an extensive suite of datasets, distribution shifts, and baselines1. It consistently exhibits state-of-the-art performance in detecting out-of-distribution (o.o.d.) instances, while other approaches are only effective in a subset of settings. On all datasets, GEBM ranks the best on average over all distribution shifts. Beyond o.o.d. detection, we discover a novel theoretical connection between EBMs and evidential models. This interpretation of GEBM enables the GNN backbone to provide accurate predictions even under severe distribution shifts.

Footnote 1: We provide our code at cs.cit.tum.de/daml/gebm/

In summary, we tackle three main deficiencies of energy-based uncertainty for graphs by:

1. Proposing GEBM, an EBM that is aware of interdependence and provides a single uncertainty estimate incorporating different structural scales.
2. Formally showing that a Gaussian regularizer mitigates the overconfidence problem of logit-based EBMs and enables GEBM to provably induce an integrable data density.
3. Showing how to interpret GEBM as an evidential approach which considerably improves the predictive robustness of the classifier under distribution shifts.

## 2 Background

**Semi-Supervised Node Classification.** We consider (semi-supervised) node classification on an attributed graph \(\mathcal{G}=(\bm{A},\bm{X})\) with \(n\) nodes \(\mathcal{V}\) and \(m\) edges \(\mathcal{E}\) that is represented by an adjacency matrix \(\bm{A}=\{0,1\}^{n\times n}\) and a node feature matrix \(\bm{X}\in\mathbb{R}^{n\times d}\). Each node has a label \(\bm{y}_{i}\in\{1,\dots C\}\). Given the labels of training nodes, the task is to infer the labels of the remaining nodes. Lastly, we focus on homophilic graphs, i.e. edges are predominantly present between nodes of the same class.

Figure 1: Overview of the Graph Energy-based Model (GEBM). Graph-agnostic energy (uncertainty) of a trained GNN \(f_{\theta}(\mathcal{G})\) is first regularized to mitigate overconfidence and then aggregated at a local, cluster, and structure-independent scale by interleaving energy marginalization and graph diffusion. While group energy marginalizes before diffusion, local energy is fine-grained and can pick up conflicting evidence. GEBM assigns high uncertainty to several anomaly types simultaneously.

**Uncertainty in Machine Learning.** Usually, uncertainty regarding the prediction of a model is disentangled into aleatoric and epistemic factors \(u^{\text{alea}}\) and \(u^{\text{epi}}\), respectively. The former encompasses irreducible sources of uncertainty like measurement noise and inherent ambiguities. The latter is commonly defined as the non-aleatoric components of the overall uncertainty and can in general, be reduced, for example by acquiring additional data.

**Energy-based Models.** Epistemic uncertainty is commonly defined to be anti-correlated to a classifier-dependent density \(p_{\theta}(\bm{x})\) over the input space [55]. We study Energy-based Models (EBMs) [38] which define a joint energy \(E_{\theta}(\bm{x},y)\) over features and labels \(p_{\theta}(\bm{x},y)\propto\exp\left(-E_{\theta}\left(\bm{x},y\right)\right)\). Marginalization over the labels induces a feature density with normalizer \(Z_{\theta}\).

\[p_{\theta}(\bm{x})=Z_{\theta}^{-1}\sum_{y}\exp\left(-E_{\theta}\left(\bm{x},y \right)\right))=Z_{\theta}^{-1}\exp\left(-E_{\theta}(\bm{x})\right)\] (1)

Intuitively, the energy \(E_{\theta}(\bm{x})=-\log\sum_{y}\exp\left(-E_{\theta}(\bm{x},y)\right)\) can be interpreted as a soft minimum of the joint energies. It is low in regions of high confidence and high elsewhere. The measure of epistemic uncertainty implied by an EBM therefore is: \(u^{\text{epi}}(\bm{x})=-\log p_{\theta}(\bm{x})=E_{\theta}(\bm{x})+\text{const}\). We can also write the conditional class probabilities as:

\[p_{\theta}(y\mid\bm{x})=\exp\left(-E_{\theta}\left(\bm{x},y\right)\right))/ \sum_{y^{\prime}}\exp\left(-E_{\theta}\left(\bm{x},y^{\prime}\right)))\] (2)

This is exactly the softmax distribution applied to \(-E_{\theta}(\bm{x},y)\) which directly connects the logits \(f_{\theta}(\bm{x})\in\mathbb{R}^{C}\) predicted by a classifier to the joint energy by defining \(E_{\theta}(\bm{x},y):=-f_{\theta}(\bm{x})_{y}\)[40].

**Evidential Deep Learning.** In contrast to first-order methods that directly predict \(p(\bm{y}\mid\bm{x})\), evidential methods [62; 43] instead parameterize the corresponding second-order distribution from which first-order distributions are sampled [32]. In classification, this second-order distribution is a Dirichlet distribution with parameters \(\bm{\alpha}>\bm{0}\) called _evidence_. They indicate the confidence of the classifier. For inference, a first-order prediction can be obtained by taking the expectation:

\[\mathbb{E}_{\bm{p}\sim\text{Dir}(\bm{\alpha})}\left[\bm{p}(\bm{y}\mid\bm{x}) \right]=\bm{\alpha}/\sum_{y^{\prime}}\bm{\alpha}_{y^{\prime}}\] (3)

## 3 Related Work

**Uncertainty Estimation for i.i.d. Data.** Disentangling uncertainty has been approached from various perspectives. A family of sampling-based approaches uses a Bayesian Information-theoretic framework [29] that relies on stochastic predictions derived from a posterior over model weights. The total uncertainty is defined on the mean predictor, epistemic uncertainty as the deviation of each sample from that mean, and aleatoric uncertainty as the difference of both estimates [1]. The posterior can either be explicitly modeled by Bayesian Neural Networks (BNNs) [6; 13; 15; 18], Monte-Carlo Dropout (MCD) [22], or implicitly realized by ensemble methods [37; 77]. Test-time augmentation [72; 73] and Stochastic Centering [66] also provide samples from this posterior. Sampling-free approaches are deterministic and estimate uncertainty with a single forward pass. Evidential methods [62; 68] predict a second-order distribution from which epistemic uncertainty is derived. Distance-based approaches quantify epistemic uncertainty as similarity to the training data [46; 48; 20; 65] and are closely related to density-based uncertainty estimation. (Deep) Gaussian Processes (GPs) [52; 45; 39] use a kernel function to measure this similarity but do not disentangle epistemic and aleatoric uncertainty. Posterior Networks combine evidential and density-based approaches by predicting density-based updates to the evidence [11; 10].

**Uncertainty Estimation for Graphs.** Many of these approaches transfer to graphs: DropEdge [59] applies MCD to edges and GPs can utilize a structure-aware kernel [53; 83; 41; 60]. SGCN [82] proposes an evidential student-teacher approach while G-\(\Delta\)UQ [67] applies Stochastic Centering to a GNN and improves on calibration. Graph Posterior Network (GPN) [34] diffuses the density-based evidence of a Posterior Network but provides separate measures for structure-aware and structure-agnostic uncertainty, each of which is only effective on some distribution shifts.

**Energy-based Models.** EBMs [38; 3; 2] are typically employed in generative modelling [14] but have also been applied to uncertainty estimation [16] and anomaly detection [40; 81]. To address the overconfidence of logit-based EBMs far from training data, a Gaussian regularization term hasrecently been proposed [35] that we employ in our framework as well. While their work empirically validates this adjustment, we formally prove the overconfidence of logit-based EBMs to happen with high probability and Gaussian regularization to mitigate the issue. The HEAT framework [36] learns multiple corrected EBMs via stochastic gradient Langevin dynamics [76] and composes them into a single measure. In contrast, our approach does not require additional training and aggregates energy that emerges naturally at different scales in the graph from a single logit-based joint energy model. Lastly, GNNSafe [79] diffuses the logit-based energy of a GNN to improve its out-of-distribution detection. In contrast, our model considers energy beyond the cluster scale.

## 4 Method

We develop a simple yet effective **G**raph-**E**nergy-**B**ased **M**odel (GEBM) for post hoc epistemic uncertainty that is sensitive to a variety of distribution shifts from any pre-trained GNN.

### Energy at Different Scales

Previous work either does not distinguish between uncertainty at different structural resolutions at all [79] or only disentangles structure-aware and structure-agnostic factors without combining them [64]. However, for many practical purposes, epistemic uncertainty must be quantified with a single measure [42; 5; 60]. We address these issues by proposing an EBM-based uncertainty that incorporates patterns on different natural abstractions of a graph. The density induced by GEBM, \(p_{\theta}(\bm{x})\), serves as a singular uncertainty measure that is sensitive to multiple distribution shifts simultaneously.

Inspired by the success of graph diffusion [9; 23], we propose energy on different structural levels: (i) Graph-agnostic, for node features in isolation. (ii) Based on the evidence in the local neighborhood of a node. (iii) Within clusters in the graph. Note that defining global energy on the whole graph induces no differences at the node level and therefore we do not consider it in this work. We point to appropriate measures for a potential extension of GEBM in the existing literature [84].

We make the intriguing observation that interleaving a diffusion process \(P_{\bm{A}}:\mathbb{R}^{k}\rightarrow\mathbb{R}^{k}\) with the marginalization of structure-agnostic joint energy \(E_{\theta}(\bm{x},y)\) as in Equation (1) induces energy functions that describe the aforementioned natural abstraction levels. Based on this insight, we can derive definitions for three types of energy functions:

**Independent Energy.** On the finest scale, we consider energy independent of structural effects by omitting the diffusion operator. This term captures uncertainty regarding node features in isolation.

\[E_{\theta,I}(\bm{x})=-\log\sum_{y}\exp\left(-E_{\theta}(\bm{x},y)\right)\] (4)

**Local Energy.** On a coarser scale, we diffuse the joint energy _before_ marginalization. This retains local information like conflicting feature-based evidence within the neighborhood of a node as the class-specific information is marginalized _after propagation_:

\[E_{\theta,L}(\bm{x})=-\log\sum_{y}\exp\left[P_{\bm{A}}\left(-E_{\theta}(\bm{ x},y)\right)\right]\] (5)

**Group Energy.** By interchanging marginalization and diffusion, we effectively smooth the marginal evidence \(E_{\theta}(\bm{x})\). Therefore, energy gets propagated predominantly within clusters of the graph.

\[E_{\theta,G}(\bm{x})=-P_{\bm{A}}\left[\log\sum_{y}\exp\left(-E_{\theta}(\bm{ x},y)\right)\right]\] (6)

Since marginalization is done _before propagation_, less local information is preserved: The energy of a node will increase when its cluster is anomalous, regardless of whether the type of anomaly matches its own. As can be seen exemplary in Figure 1, this loss of local information comes at the benefit of being less exposed to local variability within coarser clustered patterns.

Each energy type captures anomalies that affect the corresponding structural scale. We provide synthetic experiments in Appendix C.7 as an additional intuitive explanation for the aforementioned energy terms. In practice, GEBM enables practitioners to augment our framework with further, potentially task-specific, energy functions. We empirically find however that the combination of the three naturally arising energy terms already detects a broad range of distribution shifts.

### Regularizing Logit-based EBMs

Following Equation (1), EBMs imply a density over the data domain \(p_{\theta}(\bm{x})\) with normalization constant:

\[Z_{\theta}=\int_{\mathcal{X}}\sum_{y}\exp\left(-E_{\theta}(\bm{x},y)\right)d \bm{x}\] (7)

When quantifying epistemic uncertainty with this density, the energy must be low in regions of the input feature space close to the training data, while high values should be assumed far away. To that end, \(p_{\theta}(\bm{x})\) must be integrable, that is, have a finite normalizer \(Z_{\theta}\). However, previous work has shown that piecewise affine classifiers which are the backbone of modern GNNs will converge to overconfident logits far from training data [28]. We remark that previous studies found GNNs to be underconfident on in-distribution data [74; 75] while the aforementioned issue of overconfidence arises from high distance to training data induced by a distribution shift (see Appendix C.8). This overconfidence is problematic, as logit-based energy can suffer from the same issue and \(E_{\theta}(\bm{x})\) may assume arbitrarily small values far from the training data. This contradicts the aforementioned desideratum of low confidence and the implied uncertainty measure breaks under severe distribution shifts. The normalizer of the logit-based joint energy \(Z_{\theta}\) is not finite with a high probability and therefore the EBM can not induce an integrable density \(p_{\theta}(\bm{x})\).

**Proposition 4.1**.: _Let \(f_{\theta}:\mathbb{R}^{d}\to\mathbb{R}^{C}\) be a piecewise affine function and \(\mathbb{R}^{h}=\bigcup_{l}^{L}Q_{l}\) be the disjoint set of polytopes on which \(f_{\theta}\) is affine, i.e. \(f_{\theta}(\bm{x})=\bm{W}^{(l)}\bm{x}+\bm{b}^{(l)}\) for \(\bm{x}\in Q_{l}\). Assuming the direction of the rows of each \(\bm{W}^{(l)}\) to be uniformly distributed, the probability that \(Z_{\theta}\) converges decreases exponentially in the number of non-closed linear regions \(L^{\prime}\) and classes \(C\)._

\[\Pr\left[Z_{\theta}<\infty\right]=(1/2)^{C\cdot L^{\prime}}\]

We provide proofs for all claims in Appendix A. Intuitively, since \(f_{\theta}\) behaves like an affine function in the limit \(\|\bm{x}\|_{2}\to\infty\), its predicted logits may diverge toward \(\infty\). If for any class the model produces overconfident predictions in one of its affine regions, the marginal energy \(E_{\theta}(\bm{x})\) will diverge toward maximal confidence. As classifiers are trained to output high values for one of the classes, we expect the actual probability of a well-behaved energy function to be even lower than our theoretical bound that assumes uniform weight directions. In practice, this pathological behavior of logit-based EBMs has been observed in previous work [64; 36; 35]. We mitigate this issue by augmenting the logit-based energy and we prove that this regularization induces an integrable density.

### Our Model

Similarly to recent work on EBMs [35], we employ a class-conditional Gaussian prior \(\mathcal{N}(\bm{f}_{\theta}(\bm{x})_{y}|\ \bm{\mu}_{y},\bm{\Sigma}_{y})\) as a regularizer for the logit-based energy. We learn the parameters \(\{\bm{\mu}_{y},\bm{\Sigma}_{y}\}_{y=1}^{L}\) as the maximum likelihood estimates from the training instances of each class.

\[\hat{E}_{\theta}(\bm{x},y)=E_{\theta}(\bm{x},y)-\gamma\log\mathcal{N}(\bm{f}_ {\theta}(\bm{x})_{y}\mid\bm{\mu}_{y},\bm{\Sigma}_{y})\] (8)

The regularization strength \(\gamma>0\) and the choice of the diffusion operator \(P_{\bm{A}}\) are the only hyperparameters of GEBM. Each of them has an intuitive interpretation: \(\gamma\) controls the trade-off between the predictive dependency and distance-awareness of the EBM while \(P_{\bm{A}}\) encapsulates how information is propagated over \(\mathcal{G}\). Regularization ensures that the corresponding marginal density \(\hat{p}_{\theta}(\bm{x})\) has a finite normalizer \(\hat{Z}_{\theta}\) and is therefore integrable.

**Theorem 4.2**.: _For a piecewise affine classifier \(f_{\theta}\) as in Proposition 4.1, \(\hat{p}_{\theta}\) is well-defined._

\[\hat{Z}_{\theta}=\int_{\mathcal{X}}\sum_{y}\exp(-E_{\theta}(\bm{x},y))\, \mathcal{N}(\bm{f}_{\theta}(\bm{x})_{y}\mid\bm{\mu}_{y},\bm{\Sigma}_{y})^{ \gamma}d\bm{x}<\infty\]

This regularized joint energy diverges toward maximal uncertainty in the limit. Consequently, its induced density provides an uncertainty estimator that is reliable even far away from the training data.

**Corollary 4.3**.: _For a piecewise affine classifier \(f_{\theta}\) as in Proposition 4.1, and any \(\bm{x}\in\mathbb{R}^{d}\) almost surely:_

\[\lim_{\alpha\to\infty}\hat{p}_{\theta}(\alpha\bm{x})=0\]We then combine the _regularized energy_\(\hat{E}_{\theta}(\bm{x},y)\) at different structural scales (Equations (4) to (6)).

\[\hat{E}_{\theta,\text{GEBM}}(\bm{x})=\log\left[\exp\left(\hat{E}_{\theta,I}(\bm{ x})\right)+\exp\left(\hat{E}_{\theta,L}(\bm{x})\right)+\exp\left(\hat{E}_{ \theta,G}(\bm{x})\right)\right]\] (9)

Since energy is defined per node, most diffusion processes (Appendix C.6) act on individual nodes as an affine function with a positive coefficient (see Appendix A.2). Therefore, each individual energy and their aggregate, \(\hat{E}_{\theta,\text{GEBM}}\), induce an integrable density when using a linear diffusion operator \(P_{\bm{A}}\).

**Theorem 4.4**.: _For a linear diffusion operator \(P_{\bm{A}}(\bm{x})=\alpha\bm{x}+\text{const}\), \(\alpha>0\) and the regularized energy \(\hat{E}_{\theta}(\bm{x},y)\), GEBM induces an integrable density:_

\[\int_{\mathcal{X}}\exp\left(-\hat{E}_{\theta,\text{GEBM}}\left(\bm{x}\right) \right)d\bm{x}<\infty\]

GEBM is lightweight and can be applied post hoc to _any_ logit-based GNN without additional training. Its induced density is a proxy for epistemic uncertainty: \(w^{\text{epi}}(\bm{x})=-\log\hat{p}_{\theta}(\bm{x})\) and we compute aleatoric uncertainty as the entropy of the predictive distribution of the GNN [29]. Following [79], we realize the diffusion operator as a repeated application of a label-propagation scheme (see Appendix C.6). Intuitively, this operator is a smoothing process which is only appropriate when assuming the in-distribution data to be homophilic. In the case of non-smooth (heterophilic) training data, the proposed energy would be high for in-distribution data which is undesired behaviour for an EBM-based uncertainty estimator. To disentangle effects at different structural scales, we define each of GEBM's components on structure-agnostic regularized joint energies \(\hat{E}_{\theta}(\bm{x},y)\). To that end, we compute the outputs of the classifier by omitting the structure _for the computation of \(\hat{E}_{\theta}\) only_ by evaluating \(f_{\theta}(\bm{I},\bm{X})\), i.e. setting \(\bm{A}=\bm{I}\). These outputs depend only on the node features.

### EBMs as Evidential Models

Beyond using epistemic uncertainty to detect anomalies, we also show how the joint density induced by GEBM enables predictions that are robust against distribution shifts. First, we discover a correspondence between first-order predictions of logit-based classifiers (Equation (2)) and evidential predictions (Equation (3)). This connects the joint energy \(E_{\theta}(\bm{x},\bm{y})\) of an EBM to the evidence \(\bm{\alpha}\):

\[\bm{\alpha}\simeq\exp\left(-E_{\theta}(\bm{x},\bm{y})\right)\propto p_{ \theta}(\bm{x},\bm{y})\] (10)

For an integrable density \(p_{\theta}(\bm{x},\bm{y})\), the evidence \(\bm{\alpha}\) will vanish in the limit far away from training data. Previous work on Posterior Networks [11; 10] fits a normalizing flow to obtain class-conditional densities \(p_{\theta}(\bm{x}\mid\bm{y})\) and uses them to compute a Bayesian update to a prior evidence \(\bm{\alpha}^{\text{prior}}\). Its extension to graphs, GPN [64], diffuses these structure-agnostic updates with an operator \(P_{\bm{A}}\). Similarly, our GEBM framework induces a normalized joint density \(\hat{p}_{\theta}(\bm{x},\bm{y})\) through its regularized energy function at no additional cost. Therefore, it can also be interpreted as an evidential classifier that enables inference according to Equation (3).

\[\overbrace{\bm{\alpha}^{\text{post}}=\bm{\alpha}^{\text{prior}}+P_{\bm{A}} \left(\bm{N}*p_{\theta}(\bm{x},\bm{y})\right)}^{\text{GPN [64] (Evidential)}}\quad\overbrace{\bm{\alpha}^{\text{post}}=\bm{\alpha}^{\text{ prior}}+P_{\bm{A}}\left(Z_{\theta}^{-1}*\exp(-\hat{E}_{\theta}(\bm{x},\bm{y}) \right)}^{\text{GEBM (ours)}}\]

Here, \(\bm{N}\) is called an uncertainty budget and it roughly corresponds to the normalizer of the joint energy. This interpretation of EBMs recovers desirable properties of density-based evidential methods [11; 64]: Predictions will converge toward a prior \(\bm{\alpha}^{\text{prior}}\) far from the training distribution. They will be less affected by anomalies in the neighborhood of a node and therefore be more robust against distribution shifts. We remark that while our framework enables this evidential inference scheme, it is also possible to instead use the backbone classifier as-is and preserve its predictive performance.

## 5 Experiments

We evaluate the efficacy of GEBM by extending the evaluation proposed in [64] and expose it to a suite of 7 distribution shifts from three families that cover a broad range of anomaly types.

### Setup

**Datasets and Distribution Shifts.** We use seven common benchmark datasets for node classification: The five citation datasets _CoraML[4]_, _CoraML-LLM[4; 78]_[4]_, _Citeseer_[61; 25], _PubMed_[51], _Coauthor-Physics_ and _Coauthor-Computers_[63], and the co-purchase graphs _Amazon Photos_ and _Amazon Computers_[44]. We expose all methods to three families of distribution shifts:

1. **Structural**. We select nodes with the lowest _homophily_ as o.o.d. and train on homophilic nodes only. This induces a shift in the local connectivity pattern of the nodes. Furthermore, we include a setting in which nodes with low _Page-Rank_ (PR) centrality [56] are considered o.o.d.
2. **Leave-out-Class.** We withhold nodes belonging to a subset of classes during training and reintroduce them during inference. In practice, this might, for example, correspond to a new type of user joining a social network. We either select the held-out classes randomly or pick those with the lowest average homophily to make them more dissimilar to the retained classes.
3. **Feature Perturbations**. We randomly choose a subset of nodes and perturb their features by replacing them with noise. Since most datasets have categorical bag-of-words features, we have fine-grained control over the severity of the shift in this setting. We generate _near-o.o.d._ data by sampling from a Bernoulli distribution \(\bar{p}\) fitted on the node features of the dataset \(\bm{X}\). A stronger shift is induced by fixing the success probability at a value of \(p=0.5\). Drawing node features from \(\mathcal{N}(0,1)\) constitutes a domain shift (_far-o.o.d._) for categorical data.

Existing work concerns transductive node classification which enables leakage of o.o.d. information during training [64; 79]. Instead, we study the inductive setting and remove o.o.d. nodes and their edges during training, and provide results for the transductive setting in Appendix C. All results were averaged over \(5\) splits and \(5\) initializations each (for standard deviations, see Appendix C).

**Model and Baselines.** We compare GEBM to different baselines for (epistemic) uncertainty estimation: Ensembles (**GCN-Ens**), MC-dropout (**GCN-MCD**), DropEdge (**GCN-DropEdge**), a combination of MC-dropout and DropEdge (**GCN-MCD+DropEdge**) and a Bayesian GCN (**BGCN**) are sampling-based approaches. We also compare against the logit-based EBM (**GCN-Energy**), **GNNSafe**, and **HEAT** as EBM baselines. Lastly, we consider **GPN** and **SGCN** as evidential methods. For all models, including GEBM, we use the same backbone architecture (see Appendix B.2).

**Metrics.** We evaluate epistemic uncertainty by detecting distribution shifts. That is, we report the AUC-ROC and AUC-PR metrics for the binary _out-of-distribution detection_ problem of separating in-distribution (i.d.) from out-of-distribution (o.o.d.) nodes. Additionally, we report how well uncertainty correlates with erroneous (_miscalification detection_) in Appendix C.3. Since our proposed method does not alter the softmax predictions of the backbone model, it will affect neither the aleatoric estimates nor their _calibration_. Consequently, our framework is open to additional post hoc calibration methods such as temperature scaling [26]. For completeness, we report the Expected Calibration Error (ECE) [50] and the Brier score [7] in Appendix C.4 for the GNN backbone.

### Results

**Out-of-Distribution Detection.** Table 1 shows the performance of different aleatoric and epistemic uncertainty methods on various distribution shifts (full results in Table 6). Across all datasets and distribution shifts, our model provides the best or second-best separation of o.o.d. data from i.d. data. In practice, an estimator that is effective on all distribution shifts simultaneously is desirable. Therefore, we rank (\(\downarrow\)) all estimators individually for each shift and dataset and report its average rank over all distribution shifts for each dataset. To not favor one distribution shift family, we adjust the weight such that Leave-out-Class, structural shifts, and feature perturbations contribute the same amount. We rank all epistemic uncertainty proxies both against other epistemic measures and aleatoric uncertainty separately. In both cases, Tables 2 and 7 show that our proposed EBM-based epistemic uncertainty is the only estimator that is effective under different distribution shifts at the same time. On all datasets, GEBM improves the AUC-ROC scores by \(5.8\) to \(10.9\) percentage points on average (\(16\%\)-\(32\%\) relative improvement) over a vanilla EBM, the second best-ranked estimator (Appendix C.2). Since all EBM-based approaches (GCN-EBM, GCNSafe, GEBM) are post hoc methods, they share the aleatoric uncertainty and high predictive accuracy of the backbone.

Out of all 7 distribution shifts, our framework is only less sensitive to the centrality shift. Many baselines only perform well because of their symmetric diffusion operator that biases any arbitrarysignal toward high-degree nodes regardless of the quality of the uncertainty (see Appendix C.6). While this bias could be explicitly incorporated into GEBM by defining an additional energy term, the goal of our work is not to engineer our measure toward certain downstream settings. GEBM is already sensitive to many distribution shifts as-is. Even after accounting for this setting, our estimator achieves the best average rank over all shifts. We defer further discussion to Appendix B.

**Misclassification Detection.** In alignment with previous work [64], we observe aleatoric uncertainty to be more effective for misclassification detection than epistemic estimates. Our method performs competitively among other epistemic measures as shown in Table 16. As previously discussed, improving aleatoric uncertainty for GNNs is beyond the scope of this work.

**Robust Evidential Inference.** As described in Section 4.4, GEBM enables evidential inference. We expose our model to feature shifts sampled from \(\mathcal{N}(0,1)\) and increase the fraction of perturbed nodes. Figure 2 shows the predictive performance of the classifier induced by an evidential interpretation of the EBM at different regularization weights \(\gamma\) compared to a vanilla EBM and the evidential model, GPN. We maintain high accuracy like an evidential model, while the performance of the baselines rapidly deteriorates. The hyperparameter \(\gamma\) can be seen as interpolating between an unregularized overconfident logit-based EBM and an uncertainty-aware evidential method. While GPN requires explicit evidential training, our method enables robust inference at negligible additional cost from a pre-trained GNN. Furthermore, GPN notably sacrifices predictive capability on clean data, while GEBM enables more control over the trade-off between accuracy on clean and perturbed data.

\begin{table}
\begin{tabular}{l l|c c|c c c|c c c} \hline \hline \multirow{2}{*}{**Model**} & \multirow{2}{*}{**Model**} & \multicolumn{2}{c|}{LoC (_last_)} & \multicolumn{2}{c|}{Ber(0.5)} & \multicolumn{2}{c|}{\(\mathcal{N}(0,1)\) (_for_)} & \multicolumn{2}{c}{Homophily} \\  & & AUC-ROC\(\uparrow\) & Acc.\(\uparrow\) & AUC-ROC\(\uparrow\) & Acc.\(\uparrow\) & AUC-ROC\(\uparrow\) & Acc.\(\uparrow\) & AUC-ROC\(\uparrow\) & Acc.\(\uparrow\) \\  & (Alex. / Epi.) & (Alex. / Epi.) & (Alex. / Epi.) & (Alex. / Epi.) & (Alex. / Epi.) & (Alex. / Epi.) & (Alex. / Epi.) \\ \hline \multirow{6}{*}{**Model**} & GCN-DE & 86.27/3.0 & 87.2 & 4.716/8.8 & 71.9 & 26.85/7.8 & 71.9 & 70.8/54.5 & 85.6 \\  & GCN-Ens & 89.87/3.9 & 90.4 & 59.46/4.1 & 75.9 & 30.45/2.7 & 75.9 & 71.5/68.5 & 91.5 \\  & GPN & 85.3/88.1 & 88.5 & 53.45/2.4 & 72.8 & 51.4/55.5 & 72.8 & 66.9/51.5 & 87.6 \\  & GCN-EBM & 89.78/9.9 & 90.3 & 59.95/8.6 & 75.8 & 31.7/25.7 & 75.8 & 71.3/71.2 & 91.2 \\  & GCN-HEAT & 89.78/1.1 & 90.3 & 59.96/4.4 & 75.8 & 31.7/76.0 & 75.8 & 71.3/70.0 & 91.2 \\  & GCN-safe & 89.79/1.6 & 90.3 & 59.95/3.4 & 75.8 & 31.7/35.3 & 75.8 & 71.3/73.1 & 91.2 \\  & **GCN-GEBM** & 89.79/1.6 & 90.3 & 59.99/**94.5** & 75.8 & 31.7/**86.4** & 75.8 & 71.3/**76.7** & 91.2 \\ \hline \multirow{6}{*}{**Model**} & GCN-DE & 76.46/1.2 & 91.7 & 52.8/51.4 & 88.5 & 41.8/51.5 & 88.5 & 62.7/52.0 & 96.6 \\  & GCN-Ens & 74.7/80.3 & 91.9 & 52.3/51.3 & 89.9 & 42.6/55.0 & 89.9 & 62.0/65.2 & 97.5 \\  & GPN & 74.58/7.3 & 88.8 & 55.3/54.9 & 86.5 & 54.2/55.5 & 86.5 & 65.9/47.0 & 97.1 \\  & GCN-EBM & 74.67/7.5 & 91.8 & 52.1/52.1 & 89.8 & 44.2/42.6 & 89.8 & 61.9/60.0 & 97.4 \\  & GCN-HEAT & 74.67/7.3 & 91.8 & 52.1/51.8 & 89.8 & 44.2/57.3 & 89.8 & 61.9/62.6 & 97.4 \\  & GCNSafe & 74.67/75.6 & 91.8 & 52.1/50.9 & 89.8 & 44.2/46.4 & 89.8 & 61.9/60.5 & 97.4 \\  & **GCN-GEBM** & 74.6/83.6 & 91.8 & 52.1/**64.2** & 89.8 & 44.2/**92.4** & 89.8 & 61.9/68.3 & 97.4 \\ \hline \multirow{6}{*}{**Model**} & GCN-DE & 89.27/3.7 & 91.3 & 64.30/7.9 & 88.8 & 37.3/60.3 & 88.8 & 69.5/57.5 & 97.1 \\  & GCN-Ens & 89.78/3.7 & 92.4 & 69.6/67.8 & 90.0 & 32.8/60.7 & 90.0 & 63.9/69.1 & 97.9 \\  & GPN & 73.78/8.3 & 86.6 & 54.1/59.7 & 81.7 & 53.6/59.9 & 81.7 & 61.3/45.5 & 97.9 \\  & GCN-EBM & 89.78/9.9 & 92.3 & 69.3/71.6 & 89.8 & 34.7/28.8 & 89.8 & 63.8/60.5 & 97.8 \\  & GCN-HEAT & 89.78/86.9 & 92.3 & 69.3/70.0 & 89.8 & 34.7/69.8 & 89.8 & 63.8/66.6 & 97.8 \\  & GCNSafe & 89.79/2.1 & 92.3 & 69.3/63.0 & 89.8 & 34.7/36.9 & 89.8 & 63.8/62.4 & 97.8 \\  & **GCN-GEBM** & 89.79/**92.8** & 92.3 & 69.3/**99.5** & 89.8 & 34.7/**90.0** & 89.8 & 63.8/**69.5** & 97.8 \\ \hline \hline \end{tabular}
\end{table}
Table 1: Out-of-Distribution detection AUC-ROC (\(\uparrow\)) using aleatoric or epistemic uncertainty (best and runner-up). Our epistemic measure achieves the strongest performance on most datasets and shifts while maintaining the classification accuracy of the GCN backbone.

\begin{table}
\begin{tabular}{l|c c c c c c c c} \hline \hline \hline \multirow{2}{*}{**Model**} & \multirow{2}{*}{CoraML} & \multicolumn{2}{c|}{CoraML} & \multirow{2}{*}{Citeseer} & \multirow{2}{*}{PubMed} & \multicolumn{2}{c}{Amazon} & \multirow{2}{*}{Amazon} & \multirow{2}{*}{Coauthor} & \multirow{2}{*}{Coauthor} \\  & & LLM & & & & & Computers & Photo & CS & Physics \\ \hline GCN-DE & 6.3/14.2 & 8.0/16.9 & 7.8/16.2 & 7.3/13.6 & 7.2/15.9 & 7.1/15.8 & 6.5/13.2 & 8.1/16.8 \\ GCN-Ens & 7.8/16.1 & 6.3/15.0 & 6.4/12.9 & 6.2/12.4 & 5.7/11.6 & 4.7/9.0 & 4.8/10.4 & 6.2/13.3 \\ GPN & 7.0/15.2 & 5.4/11.2 & 6.6/12.9 & 5.8/12.4 & 5.7/11.8 & 5.3/11.7 & 7.2/13.9 & 6.1/14.5 \\ GCN-EBM & 4.5/7.9 & 4.0/8.2 & 5.2/10.3 & 5.2/12.0 & 4.2/10.7 & 4.9/10.9 & 4.1/7.1 & 4.4/8.4 \\ GCN-HEAT & 4.4/10.4 & 5.4/12.9 & 3.8/9.2 & 5.6/12.8 & 3.5/8.6 & 4.5/10.2 & 4.2/8.3 & 4.7/10.4 \\ GCN-Safe & 5.3/9.1 & 4.4/8.1 & 5.2/9.5 & 5.4/8.9 & 5.9/13.2 & 6.4/12.9 & 5.5/10.7 & 5.8/11.7 \\
**GCN-GEBM** & **2.7**/ **4.5** & **2.9**/ **4.9** & **3.3**/ **6** & **3.8**/ **5** & **3.8**/ **7.4** & **2.5**/ **4.2** & **2.7**/ **4.5** & **2.7**/ **4.3** & **3.0**/ **5.0** \\ \hline \hline \end{tabular}
\end{table}
Table 2: Average o.

The advantage of this evidential perspective is that the evidence approaches zero under increasingly severe distribution shifts. Therefore, a fixed number of diffusion steps suffices to effectively counteract the influence of anomalous neighbors when making predictions for a node. In contrast, using diffusion at, for example, the predictive level is inadequate: As shown in Proposition 4.1, the energy is likely to diverge and, therefore, the number of diffusion steps necessary to mitigate arbitrarily severe distribution shifts is unbounded. Consequentially, we find that even compared to models like APPNP that heavily rely on graph diffusion at the predictive level, the evidential interpretation of GEBM notably improves robustness (see Figure 6).

### Ablations.

Energy at Different Scales.In Table 3, we compare GEBM to energy at specific structural scales and a variant without regularization (\(\gamma=0\)). Each of the former corresponds to one of the energies that the GEBM framework is composed of. Group energy is equivalent to a regularized logit-based EBM which is therefore also ablated implicitly. As expected, each component is sensitive to different shifts. This confirms that interleaving marginalization and diffusion captures patterns at different resolutions. As shown in Table 26, a variant of the aggregate GEBM achieves the best rank on \(7\) of \(8\) datasets. This shows that scale-awareness is the key ingredient for effective uncertainty estimation on graphs which can be further improved with energy regularization. In far-o.o.d. settings, this regularization is crucial to obtain reliable estimates as it mitigates overconfidence issues.

Energy Regularization.We also ablate the effect of regularizing the joint logit-based energy in Figure 3. At increasing distance from the training data, logit-based energy becomes overconfident. In contrast, the regularized \(E_{\theta}\) follows the logit-based energy near the training data and is dominated by the regularizer far away. This is reflected in the clear separation between perturbed and unperturbed nodes. When computing structure-aware energy, feature corruptions affect unperturbed nodes through the diffusion operation, making a clean separation difficult. This justifies our choice to compute structure-agnostic joint energy \(\hat{E}_{\theta}(\bm{x},\bm{y})\) and factor in the graph afterward by applying \(P_{\bm{A}}\).

Backbone Architecture.Our method can be applied post hoc to any logit-based GNN. Table 4 evaluates the o.o.d.-detection performance of our EBM framework using different

\begin{table}
\begin{tabular}{c c|c|c|c|c} \hline \hline \multicolumn{2}{c|}{Model} & \multicolumn{1}{c|}{LoC} & \multicolumn{1}{c|}{Ber(\(\hat{\rho}\))} & \multicolumn{1}{c|}{\(\mathcal{N}(0,1)\)} & Homo. \\ \hline \multirow{4}{*}{EBM} & EBM & \(89.9\) & \(67.1\) & \(26.4\) & \(71.2\) \\  & Safe & **91.6** & \(56.9\) & \(36.1\) & \(73.1\) \\  & GEBM & **91.6** & **77.1** & **86.6** & **76.7** \\ \hline \multirow{4}{*}{EBM} & EBM & \(90.2\) & \(55.6\) & \(44.1\) & \(72.1\) \\  & Safe & **91.5** & \(53.2\) & \(45.4\) & \(70.3\) \\  & GEBM & \(85.0\) & **69.3** & **76.5** & **72.6** \\ \hline \multirow{4}{*}{EBM} & EBM & \(76.5\) & **52.3** & \(42.8\) & \(53.2\) \\  & Safe & \(79.0\) & \(49.3\) & \(46.2\) & \(51.2\) \\ \cline{1-1}  & GEBM & **80.7** & 51.4 & **53.6** & **65.4** \\ \hline \multirow{4}{*}{EBM} & EBM & \(74.0\) & **52.7** & \(42.2\) & \(53.2\) \\ \cline{1-1}  & Safe & **77.3** & \(49.2\) & \(46.6\) & \(51.1\) \\ \cline{1-1}  & GEBM & **77.3** & \(51.6\) & **54.7** & **62.7** \\ \hline \hline \end{tabular}
\end{table}
Table 4: O.o.d. detection AUC-ROC(\(\uparrow\)) using different backbones. Our method is effective on all architectures.

ent commonly used GNN backbones: GCN [34], GAT (v2) [70; 8], GIN [80] and GraphSAGE [27]. Standard deviations and AUC-PR are reported in Appendix C.5. Over different distribution shifts, our proposed approach consistently outperforms the logit-based EBM and the graph-specific GNNSafe variation. This shows the broad applicability of our framework that enables reliable high-quality epistemic uncertainty estimation from a large family of logit-based GNNs.

## 6 Limitations and Broader Impact

**Limitations.** As GEBM is a post hoc epistemic estimator, it does not improve aleatoric uncertainty or its calibration. In particular, the GCN backbone used in this work does not consistently achieve the strongest performance in both tasks. While the structural scales that arise naturally from graph diffusion cover many distribution shifts as-is, specific applications may require augmenting GEBM with additional energy terms, as we also observe for centrality-based shifts. While GEBM enables robust evidential inference, future work may build upon its paradigm of aggregating different structural scales in the graph for fully evidential methods. Lastly, we study homophilic node classification problems and leave an extension of GEBM beyond this setting to future work.

**Broader Impact.** GEBM enables cheap and simple uncertainty quantification for GNNs which we believe to contribute to the development of more reliable AI. Nonetheless, we encourage practitioners to actively reevaluate our measure of uncertainty to mitigate risks in safety-critical domains.

## 7 Conclusion

We propose GEBM, a simple and efficient EBM for post-hoc epistemic uncertainty estimation for GNNs. To the best of our knowledge, we are the first to consider uncertainty at different structural scales and address this gap by proposing a model that aggregates energy that naturally arises from graph diffusion. It consistently outperforms existing approaches over an extensive suite of datasets at detecting various distribution shifts. We formally and empirically confirm that logit-based EBMs suffer from overconfidence and prove that the regularized GEBM mitigates this issue by inducing an integrable data density. We exploit this property by discovering a link to evidential methods that enables the backbone to provide accurate predictions even under severe distribution shifts.

## Acknowledgements

We want to give special thank to Leo Schwinn and Franz Rieger for giving helpful suggestions on an early draft of the manuscript. The research presented has been performed in the frame of the RADELN project funded by TUM Georg Nemetschek Institute Artificial Intelligence for the Built World (GNI). It is further supported by the Bavarian Ministry of Economic Affairs, Regional Development and Energy with funds from the Hightech Agenda Bayern.

## References

* [1] Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U Rajendra Acharya, et al. A review of uncertainty quantification in deep learning: Techniques, applications and challenges. _Information fusion_, 76:243-297, 2021.
* [2] David H. Ackley, Geoffrey E. Hinton, and Terrence J. Sejnowski. A learning algorithm for boltzmann machines. _Cognitive Science_, 9(1):147-169, 1985.
* [3] Michael Arbel, Liang Zhou, and Arthur Gretton. Generalized energy based models. _arXiv preprint arXiv:2003.05033_, 2020.
* [4] Sanghamitra Bandyopadhyay, Ujjwal Maulik, Lawrence B Holder, Diane J Cook, and Lise Getoor. Link-based classification. _Advanced methods for knowledge discovery from complex data_, pages 189-207, 2005.
* [5] William H. Beluch, Tim Genewein, Andreas Nurnberger, and Jan M. Kohler. The power of ensembles for active learning in image classification. In _2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 9368-9377, 2018.

* [6] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural networks, 2015.
* [7] Glenn W Brier. Verification of forecasts expressed in terms of probability. _Monthly weather review_, 78(1):1-3, 1950.
* [8] Shaked Brody, Uri Alon, and Eran Yahav. How attentive are graph attention networks? _arXiv preprint arXiv:2105.14491_, 2021.
* [9] Ben Chamberlain, James Rowbottom, Maria I Gorinova, Michael Bronstein, Stefan Webb, and Emanuele Rossi. Grand: Graph neural diffusion. In _International Conference on Machine Learning_, pages 1407-1418. PMLR, 2021.
* [10] Bertrand Charpentier, Oliver Borchert, Daniel Zugner, Simon Geisler, and Stephan Gunnemann. Natural posterior network: Deep bayesian uncertainty for exponential family distributions. _arXiv preprint arXiv:2105.04471_, 2021.
* [11] Bertrand Charpentier, Daniel Zugner, and Stephan Gunnemann. Posterior network: Uncertainty estimation without ood samples via density-based pseudo-counts. _Advances in neural information processing systems_, 33:1356-1367, 2020.
* [12] Fan RK Chung. _Spectral graph theory_, volume 92. American Mathematical Soc., 1997.
* [13] Stefan Depeweg, Jose Miguel Hernandez-Lobato, Finale Doshi-Velez, and Steffen Udluft. Learning and policy search in stochastic dynamical systems with bayesian neural networks. _arXiv preprint arXiv:1605.07127_, 2016.
* [14] Yilun Du and Igor Mordatch. Implicit generation and modeling with energy based models. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alche-Buc, E. Fox, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 32. Curran Associates, Inc., 2019.
* [15] Michael Dusenberry, Ghassen Jerfel, Yeming Wen, Yian Ma, Jasper Snoek, Katherine Heller, Balaji Lakshminarayanan, and Dustin Tran. Efficient and scalable bayesian neural nets with rank-1 factors. In _International conference on machine learning_, pages 2782-2792. PMLR, 2020.
* [16] Sven Elflein, Bertrand Charpentier, Daniel Zugner, and Stephan Gunnemann. On out-of-distribution detection with energy-based models, 2021.
* [17] Derek Everett, Andre T Nguyen, Luke E Richards, and Edward Raff. Improving out-of-distribution detection via epistemic uncertainty adversarial training. _arXiv preprint arXiv:2209.03148_, 2022.
* [18] Sebastian Farquhar, Lewis Smith, and Yarin Gal. Liberty or depth: Deep bayesian neural nets do not need complex weight posterior approximations. _Advances in Neural Information Processing Systems_, 33:4346-4357, 2020.
* [19] Matthias Fey and Jan E. Lenssen. Fast graph representation learning with PyTorch Geometric. In _ICLR Workshop on Representation Learning on Graphs and Manifolds_, 2019.
* [20] Stanislav Fort, Jie Ren, and Balaji Lakshminarayanan. Exploring the limits of out-of-distribution detection. _Advances in Neural Information Processing Systems_, 34:7068-7081, 2021.
* [21] Dominik Fuchsgruber, Tom Wollschlager, Bertrand Charpentier, Antonio Oroz, and Stephan Gunnemann. Uncertainty for active learning on graphs, 2024.
* [22] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty in deep learning, 2016.
* [23] Johannes Gasteiger, Stefan Weissenberger, and Stephan Gunnemann. Diffusion improves graph learning. _Advances in neural information processing systems_, 32, 2019.

* [24] Jakob Gawlikowski, Cedrique Rovile Nijeutcheu Tassi, Mohsin Ali, Jongseok Lee, Matthias Humt, Jianxiang Feng, Anna Kruspe, Rudolph Triebel, Peter Jung, Ribana Roscher, et al. A survey of uncertainty in deep neural networks. _Artificial Intelligence Review_, 56(Suppl 1):1513-1589, 2023.
* [25] C Lee Giles, Kurt D Bollacker, and Steve Lawrence. Citeseer: An automatic citation indexing system. In _Proceedings of the third ACM conference on Digital libraries_, pages 89-98, 1998.
* [26] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern neural networks. In Doina Precup and Yee Whye Teh, editors, _Proceedings of the 34th International Conference on Machine Learning_, volume 70 of _Proceedings of Machine Learning Research_, pages 1321-1330. PMLR, 06-11 Aug 2017.
* [27] Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. _Advances in neural information processing systems_, 30, 2017.
* [28] Matthias Hein, Maksym Andriushchenko, and Julian Bitterwolf. Why relu networks yield high-confidence predictions far away from the training data and how to mitigate the problem. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 41-50, 2019.
* [29] Eyke Hullermeier and Willem Waegeman. Aleatoric and epistemic uncertainty in machine learning: An introduction to concepts and methods. _Machine learning_, 110(3):457-506, 2021.
* [30] Ahmet Iscen, Giorgos Tolias, Yannis Avrithis, and Ondrej Chum. Label propagation for deep semi-supervised learning. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 5070-5079, 2019.
* [31] Ajay J. Joshi, Fatih Murat Porikli, and Nikolaos Papanikolopoulos. Multi-class active learning for image classification. _2009 IEEE Conference on Computer Vision and Pattern Recognition_, pages 2372-2379, 2009.
* [32] Mira Jurgens, Nis Meinert, Viktor Benggs, Eyke Hullermeier, and Willem Waegeman. Is epistemic uncertainty faithfully represented by evidential deep learning methods?, 2024.
* [33] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_, 2014.
* [34] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. _arXiv preprint arXiv:1609.02907_, 2016.
* [35] Marc Lafon, Clement Rambour, and Nicolas Thome. Energy correction model in the feature space for out-of-distribution detection. _arXiv preprint arXiv:2403.10403_, 2024.
* [36] Marc Lafon, Elias Ramzi, Clement Rambour, and Nicolas Thome. Hybrid energy based model in the feature space for out-of-distribution detection, 2023.
* [37] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles, 2017.
* [38] Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, and Fujie Huang. A tutorial on energy-based learning. _Predicting structured data_, 1(0), 2006.
* [39] Jeremiah Liu, Zi Lin, Shreyas Padhy, Dustin Tran, Tania Bedrax Weiss, and Balaji Lakshminarayanan. Simple and principled uncertainty estimation with deterministic deep learning via distance awareness. _Advances in neural information processing systems_, 33:7498-7512, 2020.
* [40] Weitang Liu, Xiaoyun Wang, John D. Owens, and Yixuan Li. Energy-based out-of-distribution detection, 2021.
* [41] Zhao-Yang Liu, Shao-Yuan Li, Songcan Chen, Yao Hu, and Sheng-Jun Huang. Uncertainty aware graph gaussian process for semi-supervised learning. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 34, pages 4957-4964, 2020.

* [42] Owen Lockwood and Mei Si. A review of uncertainty for deep reinforcement learning. In _Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment_, volume 18, pages 155-162, 2022.
* [43] Andrey Malinin and Mark Gales. Predictive uncertainty estimation via prior networks. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 31. Curran Associates, Inc., 2018.
* [44] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. Image-based recommendations on styles and substitutes. In _Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval_, pages 43-52, 2015.
* [45] Pablo Morales-Alvarez, Daniel Hernandez-Lobato, Rafael Molina, and Jose Miguel Hernandez-Lobato. Activation-level uncertainty in deep neural networks. In _International Conference on Learning Representations_, 2020.
* [46] Jishnu Mukhoti, Andreas Kirsch, Joost van Amersfoort, Philip HS Torr, and Yarin Gal. Deep deterministic uncertainty: A simple baseline. _arXiv preprint arXiv:2102.11582_, 2021.
* [47] Jishnu Mukhoti, Andreas Kirsch, Joost van Amersfoort, Philip H.S. Torr, and Yarin Gal. Deep deterministic uncertainty: A new simple baseline. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 24384-24394, June 2023.
* [48] Jishnu Mukhoti, Joost van Amersfoort, Philip HS Torr, and Yarin Gal. Deep deterministic uncertainty for semantic segmentation. _arXiv preprint arXiv:2111.00079_, 2021.
* [49] Sai Munikoti, Deepesh Agarwal, Laya Das, and Balasubramaniam Natarajan. A general framework for quantifying aleatoric and epistemic uncertainty in graph neural networks. _Neurocomputing_, 521:1-10, 2023.
* [50] Mahdi Pakdaman Naeini, Gregory Cooper, and Milos Hauskrecht. Obtaining well calibrated probabilities using bayesian binning. In _Proceedings of the AAAI conference on artificial intelligence_, volume 29, 2015.
* [51] Galileo Namata, Ben London, Lise Getoor, Bert Huang, and U Edu. Query-driven active surveying for collective classification. In _10th international workshop on mining and learning with graphs_, volume 8, page 1, 2012.
* [52] Yin Cheng Ng, Nicolo Colombo, and Ricardo Silva. Bayesian semi-supervised learning with graph gaussian processes. _Advances in Neural Information Processing Systems_, 31, 2018.
* [53] Yin Cheng Ng, Nicolo Colombo, and Ricardo Silva. Bayesian semi-supervised learning with graph gaussian processes. _Advances in Neural Information Processing Systems_, 31, 2018.
* [54] Vu-Linh Nguyen, Sebastien Destercke, and Eyke Hullermeier. Epistemic uncertainty sampling. In _Discovery Science: 22nd International Conference, DS 2019, Split, Croatia, October 28-30, 2019, Proceedings 22_, pages 72-86. Springer, 2019.
* [55] CAZHAOw SALIH OAZA. Bayesian error bars for regression. 1996.
* [56] Lawrence Page, Sergey Brin, Rajeev Motwani, Terry Winograd, et al. The pagerank citation ranking: Bringing order to the web. 1999.
* [57] John Palowitch, Anton Tsitsulin, Brandon Mayer, and Bryan Perozzi. Graphworld: Fake graphs bring real insights for gnns. In _Proceedings of the 28th ACM SIGKDD conference on knowledge discovery and data mining_, pages 3691-3701, 2022.
* [58] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. In _NIPS-W_, 2017.
* [59] Yu Rong, Wenbing Huang, Tingyang Xu, and Junzhou Huang. Dropedge: Towards deep graph convolutional networks on node classification. _arXiv preprint arXiv:1907.10903_, 2019.

* [60] Adrian Schwaiger, Poulami Sinhamahapatra, Jens Gansloser, and Karsten Roscher. Is uncertainty quantification in deep learning sufficient for out-of-distribution detection? _Aisafety@ ijcai_, 54, 2020.
* [61] Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. Collective classification in network data. _AI magazine_, 29:93-93, 2008.
* [62] Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty. _Advances in neural information processing systems_, 31, 2018.
* [63] Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan Gunnemann. Pitfalls of graph neural network evaluation. _arXiv preprint arXiv:1811.05868_, 2018.
* [64] Maximilian Stadler, Bertrand Charpentier, Simon Geisler, Daniel Zugner, and Stephan Gunnemann. Graph posterior network: Bayesian predictive uncertainty for node classification. _Advances in Neural Information Processing Systems_, 34:18033-18048, 2021.
* [65] Yiyou Sun, Yifei Ming, Xiaojin Zhu, and Yixuan Li. Out-of-distribution detection with deep nearest neighbors. In _International Conference on Machine Learning_, pages 20827-20840. PMLR, 2022.
* [66] Jayaraman Thiagarajan, Rushil Anirudh, Vivek Sivaraman Narayanaswamy, and Timo Bremer. Single model uncertainty estimation via stochastic data centering. _Advances in Neural Information Processing Systems_, 35:8662-8674, 2022.
* [67] Puja Trivedi, Mark Heimann, Rushil Anirudh, Danai Koutra, and Jayaraman J Thiagarajan. Accurate and scalable estimation of epistemic uncertainty for graph neural networks. _arXiv preprint arXiv:2401.03350_, 2024.
* [68] Dennis Ulmer. A survey on evidential deep learning for single-pass uncertainty estimation. 2021.
* [69] Joost Van Amersfoort, Lewis Smith, Andrew Jesson, Oscar Key, and Yarin Gal. On feature collapse and deep kernel learning for single forward pass uncertainty. _arXiv preprint arXiv:2102.11409_, 2021.
* [70] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio, et al. Graph attention networks. _stat_, 1050(20):10-48550, 2017.
* [71] Fangxin Wang, Yuqing Liu, Kay Liu, Yibo Wang, Sourav Medya, and Philip S Yu. Uncertainty in graph neural networks: A survey. _arXiv preprint arXiv:2403.07185_, 2024.
* [72] Guotai Wang, Wenqi Li, Michael Aertsen, Jan Deprest, Sebastien Ourselin, and Tom Vercauteren. Aleatoric uncertainty estimation with test-time augmentation for medical image segmentation with convolutional neural networks. _Neurocomputing_, 338:34-45, 2019.
* [73] Guotai Wang, Wenqi Li, Michael Aertsen, Jan Deprest, Sebastien Ourselin, and Tom Vercauteren. Test-time augmentation with uncertainty estimation for deep learning-based medical image segmentation. 2022.
* [74] Min Wang, Hao Yang, Jincai Huang, and Qing Cheng. Moderate message passing improves calibration: A universal way to mitigate confidence bias in graph neural networks. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 38, pages 21681-21689, 2024.
* [75] Xiao Wang, Hongrui Liu, Chuan Shi, and Cheng Yang. Be confident! towards trustworthy graph neural networks via confidence calibration, 2022.
* [76] Max Welling and Yee Whye Teh. Bayesian learning via stochastic gradient langevin dynamics. In _Proceedings of the 28th International Conference on International Conference on Machine Learning_, ICML'11, page 681-688, Madison, WI, USA, 2011. Omnipress.
* [77] Yeming Wen, Dustin Tran, and Jimmy Ba. Batchensemble: an alternative approach to efficient ensemble and lifelong learning. _arXiv preprint arXiv:2002.06715_, 2020.

* [78] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, et al. Huggingface's transformers: State-of-the-art natural language processing. _arXiv preprint arXiv:1910.03771_, 2019.
* [79] Qitian Wu, Yiting Chen, Chenxiao Yang, and Junchi Yan. Energy-based out-of-distribution detection for graph neural networks. _arXiv preprint arXiv:2302.02914_, 2023.
* [80] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? _arXiv preprint arXiv:1810.00826_, 2018.
* [81] Shuangfei Zhai, Yu Cheng, Weining Lu, and Zhongfei Zhang. Deep structured energy based models for anomaly detection. In Maria Florina Balcan and Kilian Q. Weinberger, editors, _Proceedings of The 33rd International Conference on Machine Learning_, volume 48 of _Proceedings of Machine Learning Research_, pages 1100-1109, New York, New York, USA, 20-22 Jun 2016. PMLR.
* [82] Xujiang Zhao, Feng Chen, Shu Hu, and Jin-Hee Cho. Uncertainty aware semi-supervised learning on graph data. _Advances in Neural Information Processing Systems_, 33:12827-12836, 2020.
* [83] Yin-Cong Zhi, Yin Cheng Ng, and Xiaowen Dong. Gaussian processes on graphs via spectral kernel learning. _IEEE Transactions on Signal and Information Processing over Networks_, 2023.
* [84] Kaixiong Zhou, Xiao Huang, Daochen Zha, Rui Chen, Li Li, Soo-Hyun Choi, and Xia Hu. Dirichlet energy constrained learning for deep graph neural networks. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, _Advances in Neural Information Processing Systems_, volume 34, pages 21834-21846. Curran Associates, Inc., 2021.

Proofs

### EBMs for i.i.d. Data

We first consider proofs for formal statements regarding logit-based EBMs in general (i.e. for i.i.d. data).

**Proposition 4.1**.: _Let \(f_{\theta}:\mathbb{R}^{d}\to\mathbb{R}^{C}\) be a piecewise affine function and \(\mathbb{R}^{h}=\bigcup_{l}^{L}Q_{l}\) be the disjoint set of polytopes on which \(f_{\theta}\) is affine, i.e. \(f_{\theta}(\bm{x})=\bm{W}^{(l)}\bm{x}+\bm{b}^{(l)}\) for \(\bm{x}\in Q_{l}\). Assuming the direction of the rows of each \(\bm{W}^{(l)}\) to be uniformly distributed, the probability that \(Z_{\theta}\) converges decreases exponentially in the number of non-closed linear regions \(L^{\prime}\) and classes \(C\)._

\[\Pr\left[Z_{\theta}<\infty\right]\approx(1/2)^{C\cdot L^{\prime}}\]

Proof.: Consider an arbitrary direction \(\bm{x}\in\mathbb{R}^{d}\) such that \(\|\bm{x}\|=1\). As shown in [28] (Lemma 3.1), there exists some \(t\) and \(\alpha_{0}\) such that for all \(\alpha>\alpha_{0}\) it holds that \(\alpha\bm{x}\in Q_{t}\). We have \(f_{\theta}(\alpha\bm{x})=\bm{W}^{(l)}\alpha\bm{x}+\bm{b}^{(l)}\), and therefore:

\[-E_{\theta}(\alpha\bm{x},y)=\bm{W}^{(l)}_{y}\alpha\bm{x}+\bm{b}^{(l)}_{y}\]

We now distinguish between two cases as \(\alpha\to\infty\):

If \(\bm{W}^{(l)}_{y}\bm{x}\geq 0\), we have:

\[\lim_{\alpha\to\infty}\alpha\bm{W}^{(l)}_{y}\bm{x} =\infty\] \[\lim_{\alpha\to\infty}\alpha\bm{W}^{(l)}_{y}\bm{x}+\bm{b}^{(l)}_ {y} =\infty\] \[\lim_{\alpha\to\infty}E_{\theta}(\alpha\bm{x},y) =-\infty\]

And conversely if \(\bm{W}^{(l)}_{y}\bm{x}\leq 0\), we have:

\[\lim_{\alpha\to\infty}E_{\theta}(\alpha\bm{x},y)=\infty\]

Since we assumed the direction of \(\bm{W}^{(l)}_{y}\) to be uniformly distributed, both cases occur with probability \(0.5\). Now we consider the marginal energy assigned to \(\alpha\bm{x}\):

\[E_{\theta}(\alpha\bm{x}) =-\log\sum_{y}\exp\left(-E_{\theta}(\alpha\bm{x},y)\right)\] \[\leq\alpha\min_{y}\left\{-E_{\theta}(\bm{x},y)\right\}\]

We now analyze when the marginal energy \(E_{\theta}(\alpha\bm{x})\) diverges toward \(\infty\) and \(-\infty\) respectively. If for any \(y\in\{1,\dots,C\}\) we have that \(\bm{W}^{(l)}_{y}\bm{x}\leq 0\), then:

\[\lim_{\alpha\to\infty}E_{\theta}(\alpha\bm{x}) \leq\lim_{\alpha\to\infty}\alpha\min_{y}\left\{E_{\theta}(\bm{x},y)\right\}\] \[=-\infty\]

Since each \(\bm{W}^{(l)}_{y}\bm{x}>0\) with probability \(1/2\), the limit diverges toward \(-\infty\), with probability at most \((1/2)^{C}\).

Now consider some open set \(Q^{(l)}\) with a non-zero measure for over which the classifier \(f_{\theta}\) is linear. With probability at least \(1/2\), for \(\bm{x}\in Q^{(l)}\), \(f_{\theta}\) diverges toward \(\infty\).

[MISSING_PAGE_FAIL:17]

\[\hat{E}_{\theta}(\alpha\bm{x}) =-\log\sum_{y}\exp\left(-\hat{E}_{\theta}(\alpha\bm{x},y)\right)\] \[\geq-\log\sum_{y}\exp\left(-\alpha\bm{x}^{T}\bm{\Sigma}_{*}^{-1} \alpha\bm{x}\right)\] \[=\alpha\bm{x}^{T}\bm{\Sigma}_{*}^{-1}\alpha\bm{x}-\log C\] \[\geq\alpha\bm{x}^{T}\bm{\Sigma}_{*}^{\prime-1}\alpha\bm{x}\]

Here, we absorb the constant \(\log C\) into the quadratic term. Similar to the proof of Proposition 4.1, we now analyze the integral of the implied density for each linear region of the classifier \(Q^{(l)}\).

\[\int_{Q^{(l)}}\exp\left(-\hat{E}_{\theta}(\bm{x})\right)d\bm{x}=\int_{\|\bm{x} \|_{2}\leq\alpha_{0}}\exp\left(-\hat{E}_{\theta}(\bm{x})\right)d\bm{x}+\int_{ \|\bm{x}\|_{2}>\alpha_{0}}\exp\left(-\hat{E}_{\theta}(\bm{x})\right)d\bm{x}\]

The first term is an integral of a finite function over a finite region, which therefore will also be finite:

\[I_{\alpha\leq\alpha_{0}}^{(l)}:=\int_{\|\bm{x}\|_{2}\leq\alpha_{0}}\exp\left( -\hat{E}_{\theta}(\bm{x})\right)d\bm{x}<\infty\]

For the second term, we notice that it is bounded by the (finite) Gaussian integral:

\[I_{\alpha>\alpha_{0}}^{(l)} :=\int_{\|\bm{x}\|_{2}>\alpha_{0}}\exp\left(-\hat{E}_{\theta}( \bm{x})\right)d\bm{x}\] \[\leq\int_{\|\bm{x}\|_{2}>\alpha_{0}}\exp\left(-\bm{x}^{T}\bm{ \Sigma}_{*}^{\prime-1}\bm{x}\right)d\bm{x}\] \[<\infty\]

Lastly, since we can decompose \(\mathbf{R}^{d}\) into a finite set of linear regions over each of which the integral is finite, the entire integral is finite.

\[\int_{\mathbb{R}^{d}}\exp\left(-\hat{E}_{\theta}(\bm{x})\right)d \bm{x} =\sum_{l=1}^{L}\int_{Q^{(l)}}\exp\left(-\hat{E}_{\theta}(\bm{x}) \right)d\bm{x}\] \[=\sum_{l=1}^{L}\left(I_{\alpha\leq\alpha_{0}}^{(l)}+I_{\alpha> \alpha_{0}}^{(l)}\right)\] \[<\infty\]

**Theorem A.1.1**.: _For a piecewise affine classifier \(f_{\theta}\) as in Proposition 4.1, and a piecewise affine feature extractor \(g_{\theta}(\bm{x})\), \(\hat{p}_{\theta}\) is integrable._

\[\hat{Z}_{\theta}=\int_{\mathcal{X}}\sum_{y}\exp(-E_{\theta}(\bm{x},y))\, \mathcal{N}(\bm{g}_{\theta}(\bm{x})\mid\bm{\mu}_{y},\bm{\Sigma}_{y})^{\gamma} d\bm{x}<\infty\]

Proof.: Note that both affine functions \(f_{\theta}\) and \(g_{\theta}\) partition the input space \(\mathbb{R}^{d}\) into a finite set of linear regions. Intersecting their boundaries again gives rise to a finite set of linear regions. For bounded regions, the integral over the induced density will be finite, so we discuss the unbounded regions here. For any such region \(Q^{(l)}\), we have \(f_{\theta}(\bm{x})=\bm{w}_{f}^{T}\bm{x}+\bm{b}_{f}\) and \(g_{\theta}(\bm{x})=\bm{W}_{g}\bm{x}+\bm{b}_{g}\).

We now partition the \(\mathbb{R}^{d}\cap Q^{(l)}\) into four regions using the kernel spaces of \(\bm{w}_{f}\) and \(\bm{W}_{g}\) respectively, i.e. \(\mathbb{R}^{d}\cap Q^{(l)}=\bm{0}_{f+g}\cup\bm{0}_{f-g}\cup\bm{0}_{g-f}\cup \bm{I}_{f+g}\), where we define \(\bm{0}_{f+g}:=\ker(\bm{w}_{f})\cap\ker(\bm{W}_{g})\cap Q^{(l)}\), \(\bm{0}_{f-g}:=\ker(\bm{w}_{f})\setminus\ker(\bm{W}_{g})\cap Q^{(l)}\), \(\bm{0}_{g-f}:=\ker(\bm{W}_{g})\setminus\ker(\bm{w}_{f})\cap Q^{(l)}\) and \(\bm{I}_{f+g}:=\text{im}(\bm{w}_{f})\cap\text{im}(\bm{W}_{g})\cap Q^{(l)}\).

We can now decompose the integral over \(Q^{(l)}\) into integrals over all four regions. Note that of these sets, only \(\bm{I}_{f+g}\) has a non-zero measure (if the affine classifier is not the null function). Therefore, we only have to focus on this domain. For some \(\alpha_{0}\) and \(\bm{x}\in\bm{I}_{f+g},\|\bm{x}\|_{2}\geq\alpha_{0}\), we have:

\[\hat{p}_{\theta}(\bm{x}) \propto\exp\left(-E_{\theta}(\bm{x},y)\right)\mathcal{N}(g_{ \theta}(\bm{x})\mid\bm{\mu}_{y},\bm{\Sigma}_{y})\] \[\propto\exp\left(\bm{w}_{f}^{T}\bm{x}+\bm{b}_{f}\right)\exp\left( -(\bm{W}_{g}\bm{x}+\bm{b}_{g})^{T}\bm{\Sigma}_{g}^{-1}(\bm{W}_{g}\bm{x}+\bm{ b}_{g})\right)\] \[\leq\exp\left(-\bm{x}^{T}\bm{\Sigma}_{*,y}^{-1}\bm{x}\right)\]

For some \(\bm{\Sigma}_{*,y}^{-1}\) that bounds the quadratic function in the exponential for \(\|\bm{x}\|_{2}\geq\alpha_{0}\). The integral over the region \(Q^{(l)}\) now reduces to:

\[I^{(l)} =\int_{\bm{x}\in Q^{(l)}}\sum_{y}\text{const}*\exp\left(-E_{\theta }(\bm{x},y)\right)\mathcal{N}(g_{\theta}(\bm{x})\mid\bm{\mu}_{y},\bm{\Sigma}_ {y})d\bm{x}\] \[=\text{const}+\int_{\begin{subarray}{c}Q^{(l)}\\ \|\bm{x}\|_{2}\geq\alpha_{0}\end{subarray}}\sum_{y}\text{const}*\exp\left(-E_ {\theta}(\bm{x},y)\right)\mathcal{N}(g_{\theta}(\bm{x})\mid\bm{\mu}_{y},\bm{ \Sigma}_{y})d\bm{x}\] \[\leq\text{const}+\int_{\begin{subarray}{c}Q^{(l)}\\ \|\bm{x}\|_{2}\geq\alpha_{0}\end{subarray}}\sum_{y}\text{const}*\exp\left(- \bm{x}^{T}\bm{\Sigma}_{*,y}^{-1}\bm{x}\right)d\bm{x}\] \[\leq\text{const}+\int_{\begin{subarray}{c}Q^{(l)}\\ \|\bm{x}\|_{2}\geq\alpha_{0}\end{subarray}}\text{const}*\exp\left(-\bm{x}^{T} \bm{\Sigma}_{*}^{-1}\bm{x}\right)d\bm{x}\] \[<\infty\]

Here, we pick \(\bm{\Sigma}_{*}\) to bound the quadratic terms of all \(\bm{\Sigma}_{y,*}\). As previously mentioned, the kernel spaces of \(\bm{w}_{f}\) and \(\bm{W}_{g}\) have zero measure and therefore do not contribute to the integral. As previously, the integral over the entire domain \(\mathbb{R}^{d}\) decomposes into finite integrals over all \(Q^{(l)}\).

\[\int_{\mathbb{R}}\sum_{y}\text{const}*\exp\left(-E_{\theta}(\bm{x },y)\right)\mathcal{N}(g_{\theta}(\bm{x})\mid\bm{\mu}_{y},\bm{\Sigma}_{y})d\bm{x} =\text{const}+\sum_{l=1}^{L}I^{(l)}\] \[<\infty\]

**Corollary 4.3**.: _For a piecewise affine classifier \(f_{\theta}\) as in Proposition 4.1, and any \(\bm{x}\in\mathbb{R}^{d}\) almost surely:_

\[\lim_{\alpha\rightarrow\infty}\hat{p_{\theta}}(\alpha\bm{x})=0\]

Proof.: As per the proof of Theorem 4.2, for sufficiently large \(\alpha\) we have for some \(\bm{\Sigma}_{*}^{-1}\):

\[\hat{E}_{\theta}(\alpha\bm{x})\geq\bm{x}^{T}\bm{\Sigma}_{*}^{-1}\bm{x}\]From there, it follows directly that:

\[\lim_{\alpha\to\infty}\hat{p}_{\theta}(\alpha\bm{x}) =\lim_{\alpha\to\infty}\exp(-\hat{E}_{\theta}(\alpha\bm{x}))\] \[=\exp\Big{(}\lim_{\alpha\to\infty}-\hat{E}_{\theta}(\alpha\bm{x}) \Big{)}\] \[\leq\exp\Big{(}\lim_{\alpha\to\infty}-\bm{x}^{T}\bm{\Sigma}_{*}^{- 1}\bm{x}\Big{)}\] \[=0\]

### Graph-based Energies at Different Scales

Here, we show that local energy (Equation (5)) and group energy (Equation (6)) induce a valid probability density when using a linear diffusion operator \(P_{\bm{A}}\) and regularized energy according to Equation (8). Note that independent energy (Equation (4)) is shown to induce a well-defined probability density as it is just a graph-independent regularized energy.

**Proposition A.2.1**.: _For a linear diffusion operator \(P_{\bm{A}}(\bm{x})=\alpha\bm{x}+\text{const}\), \(\alpha>0\) and the regularized energy \(\hat{E}_{\theta}(\bm{x},y)\), the local energy \(\hat{E}_{L}(\bm{x})\) induces a well-defined density:_

\[\int_{\mathcal{X}}\exp(-\hat{E}_{\theta,L}(\bm{x}))d\bm{x}<\infty\]

Proof.: \[\hat{E}_{\theta,L}(\bm{x}) =-\log\sum_{y}\exp\Big{(}P_{\bm{A}}\left(-\hat{E}_{\theta}(\bm{x },y)\right)\Big{)}\] \[=-\log\sum_{y}\exp\left(-\alpha\hat{E}_{\theta}(\bm{x},y)+\text{ const}\right)\] \[\geq-\log\sum_{y}\exp\left(-\alpha\bm{x}^{T}\bm{\Sigma}^{-1}\bm{ x}+\text{const}\right)\] \[=\alpha\bm{x}^{T}\bm{\Sigma}^{-1}\bm{x}+\text{const}+\log C\] \[\geq\bm{x}^{T}\bm{\Sigma}^{\prime}_{*}{}^{-1}\bm{x}\]

Again, we absorbed the constant terms as well as \(\alpha\) into the quadratic term for large enough \(\|\bm{x}\|_{2}\) and used the quadratic bound from Theorem 4.2. From here, it is straightforward that:

\[\int_{\mathcal{X}}\exp\left(-\hat{E}_{\theta,L}(\bm{x})\right)d\bm{x}\leq \text{const}+\int_{\mathcal{X}}\exp\left(-\bm{x}^{T}\bm{\Sigma}^{\prime}_{*}{} ^{-1}\bm{x}\right)d\bm{x}<\infty\]

**Proposition A.2.2**.: _For a linear diffusion operator \(P_{\bm{A}}(\bm{x})=\alpha\bm{x}+\text{const}\), \(\alpha>0\) and the regularized energy \(\hat{E}_{\theta}(\bm{x},y)\), the group energy \(\hat{E}_{G}(\bm{x})\) induces a well-defined density:_

\[\int_{\mathcal{X}}\exp(-\hat{E}_{\theta,G}(\bm{x}))d\bm{x}<\infty\]

Proof.: \[\hat{E}_{\theta,G}(\bm{x}) =P_{\bm{A}}\left(\hat{E}_{\theta}(\bm{x})\right)\] \[=\alpha\hat{E}_{\theta}(\bm{x})+\text{const}\] \[\geq\alpha\bm{x}^{T}\bm{\Sigma}^{-1}_{*}\bm{x}+\text{const}\] \[\geq\bm{x}^{T}\bm{\Sigma}^{\prime}_{*}{}^{-1}\bm{x}\]Again, we have used the quadratic bound of Theorem 4.2 and absorbed \(\alpha>0\) for large enough \(\|\bm{x}\|_{2}\). From there, it follows:

\[\int_{\mathcal{X}}\exp\left(-\hat{E}_{\theta,G}(\bm{x})\right)d\bm{x}\leq\text{ const}+\int_{\mathcal{X}}\exp\left(-\bm{x}^{T}\bm{\Sigma^{\prime}}_{*}^{-1}\bm{x} \right)d\bm{x}<\infty\]

**Remark.** We want to point out that most diffusion operations, especially the ones discussed in Appendix C.6 including the label-propagation smoothing used in our experiments, are of the form \(P_{\bm{A}}(\bm{x})=\alpha\bm{x}+\text{const}\) with \(\alpha>0\). Since we only integrate over the features of a single node and keep all other features fixed, all of these diffusion processes can be expressed as a weighted sum over nodes in the graph. Since we consider unweighted graphs, there are no negative edge weights which ensures that \(\alpha>0\) (as long as some sort of self-loop is included). Therefore, linear diffusion processes can be seen as positive affine transformations.

**Theorem 4.4**.: _For a linear diffusion operator \(P_{\bm{A}}(\bm{x})=\alpha\bm{x}+\text{const}\), \(\alpha>0\) and the regularized energy \(\hat{E}_{\theta}(\bm{x},y)\), GEBM induces a well-defined density:_

\[\int_{\mathcal{X}}\exp\left(-\hat{E}_{\theta,\text{GEBM}}\left(\bm{x}\right) \right)d\bm{x}<\infty\]

Proof.: We previously established quadratic bounds on all three constituents of the aggregate energy for large enough \(\|\bm{x}\|_{2}\):

\[\hat{E}_{\theta,I}(\bm{x}) \geq\bm{x}^{T}\bm{\Sigma}_{I}^{-1}\bm{x}\] \[\hat{E}_{\theta,L}(\bm{x}) \geq\bm{x}^{T}\bm{\Sigma}_{L}^{-1}\bm{x}\] \[\hat{E}_{\theta,G}(\bm{x}) \geq\bm{x}^{T}\bm{\Sigma}_{G}^{-1}\bm{x}\]

Hence, there must be one \(\bm{\Sigma}_{*}^{-1}\in\{\bm{\Sigma}_{I}^{-1},\bm{\Sigma}_{L}^{-1},\bm{ \Sigma}_{G}^{-1}\}\) that bounds all three energy types. We now look at the GEBM model:

\[\hat{E}_{\theta,\text{GEBM}}(\bm{x}) =\log\left(\exp\left(\hat{E}_{\theta,I}(\bm{x})\right)+\exp\left( \hat{E}_{\theta,L}(\bm{x})\right)+\exp\left(\hat{E}_{\theta,G}(\bm{x})\right)\right)\] \[\geq\log\left(3*\exp\left(\bm{x}^{T}\bm{\Sigma}_{*}^{-1}\bm{x} \right)\right)\] \[=\bm{x}^{T}\bm{\Sigma}_{*}^{-1}\bm{x}+\log 3\] \[\geq\bm{x}^{T}\bm{\Sigma^{\prime}}_{*}^{-1}\bm{x}\]

As before, this bounds the density induced by GEBM:

\[\int_{\mathcal{X}}\exp\left(-\hat{E}_{\theta,\text{GEBM}}\left(\bm{x}\right) \right)d\bm{x}\leq\text{const}+\int_{\mathcal{X}}\exp\left(-\bm{x}^{T}\bm{ \Sigma^{\prime}}_{*}^{-1}\bm{x}\right)d\bm{x}<\infty\]

**Remark.** This directly imposes a restriction on which energies can be included in GEBM beyond the three naturally arising graph-specific terms we propose: As long as the energy term can be bounded by an energy that grows fast enough to ensure convergence, our framework accommodates it.

We also can explicitly write out the (unnormalized) GEBM density \(p_{\theta,\text{GEBM}}(\bm{x})\) in terms of its constituents \(p_{\theta,I}(\bm{x})\), \(p_{\theta,L}(\bm{x})\) and \(p_{\theta,G}(\bm{x})\).

\[p_{\theta,\text{GEBM}}(\bm{x})\propto\frac{1}{p_{\theta,I}(\bm{x})^{-1}+p_{ \theta,L}(\bm{x})^{-1}+p_{\theta,G}(\bm{x})^{-1}}\]

## Appendix B Experimental Setup

### Datasets and Distribution Shifts

We use eight datasets in this work that we expose to similar kinds of distribution shifts. For CoraML, we also create a version that uses continuous word embeddings instead of categorical bag-of-word features. We use the _all-MiniLM-L6-v2_ sentence transformer provided by Hugging Face [78] to embed the abstracts that are provided for each paper (node) in the citation network. All datasets are taken from PyTorch Geometric [19]. They are licensed as C.C.0 1.0 (CoraML, CoraML LLM), C.C. Attribution-NonCommercial-Share Alike 3.0 (Citeseer), QbL 1.0 (PubMed).

We expose each dataset to the same distribution shifts which can be categorized into three families:

1. **Leave-out-Classes.** We pre-select a subset of classes and designate them as out-of-distribution. That is, we remove them from the training set and train the GNN on the remaining set of nodes. We focus on an inductive setting, where we also remove all edges linking o.o.d. left-out-class nodes to the training graph, thus preventing information leakage. In the transductive setting, o.o.d. nodes still contribute to the training signal as they may be connected to i.d. nodes. This distribution shift can be seen as occurring on a cluster level, as we introduce anomalous nodes that are likely to cluster together. We distinguish between two kinds of selection processes for the classes to be left out: We either pick the last classes in the dataset (_Loc (last)_) or choose classes with the most heterophilic connection pattern, which distinguishes them even further from i.d. classes (_Loc (hetero.)_).
2. **Feature Perturbations.** We select \(50\)% of nodes at random to be o.o.d. and perturb their features by replacing them with random noise. We distinguish between three perturbation types that control the similarity of node features to training data: We generate features that are similar to i.d. data (_near-o.o.d._ in the following way: For each of the \(d\) features, we compute how frequent it occurs in the dataset. We then proceed to sample each of these features independently with the corresponding success probability \(\hat{\bm{p}}\) from a Bernoulli \(\text{Ber}(\hat{\bm{p}})\). Instead, we can also set the success probability to \(p=0.5\) for each of the features and induce a more severe distribution shift within the bag-of-words domain of the dataset. Lastly, when sampling features according to a normal distribution \(\mathcal{N}(0,1)\), we generate out-of-domain data that should, in theory, be easy to detect _far-o.o.d._. For the CoraML-LM and the PubMed datasets, features a not bag-of-word. Therefore, the near-o.o.d shift is omitted and the far-o.o.d. shift needs to be considered within the domain of the data.
3. **Structural.** We induce structure-related shifts in two ways: The first option we consider is to rank all nodes according to their local homophily. That is, we compute the ratio of neighbors with the same class: \(h_{i}=|\{v_{j}\in\mathcal{N}_{i}:\bm{y}_{i}=\bm{y}_{j}\}|/|\mathcal{N}_{i}|\). We then designate \(50\)% of nodes with the highest heterophily (i.e. lowest homophily) as o.o.d (_homophily_). The second structural shift ranks nodes according to their (approximate) Page Rank centrality and declares nodes with low values as o.o.d. (_Page Rank_).

In the inductive setting, we remove the o.o.d. nodes from the training graph and re-introduce them during inference. We evaluate o.o.d. detection metrics on a validation/test set that includes both i.d. and o.o.d. nodes. While the training and validation set are randomized for each split, the test set is shared across all splits to prevent data leakage. All results are reported over five different splits and five independent model weight initializations for each of them. Where appropriate, we also report standard deviations in Appendix C.

\begin{table}
\begin{tabular}{l|c|c|c|c|c|c|c|c} \hline \hline
**Dataset** & **\#Nodes \(n\)** & **\#Edges \(m\)** & **\#Features \(d\)** & **\#Classes \(c\)** & \begin{tabular}{c} **Avg. Feature** \\ **Density (\%)** \\ \end{tabular} & **Homophily (\%)** & \begin{tabular}{c} **Edge Density** \\ \end{tabular} & \begin{tabular}{c} **Left-out-** \\ \(\text{m}/\text{m}^{2}\) **(\%)** \\ \end{tabular} & 
\begin{tabular}{c} **\#Nodes-i.d.** \\ **Classes (Loc) \(\text{m}_{d}\)** \\ \end{tabular} \\ \hline CoraML & \(2993\) & \(18316\) & \(2879\) & 7 & \(1.75\) & \(78.9\) & \(0.18\) & \(3\) & \(1650\) \\ CoraML LLM & \(2995\) & \(16316\) & \(384\) & 7 & a.a. & \(78.9\) & \(0.18\) & \(3\) & \(1650\) \\ Citeseer & \(4230\) & \(10674\) & \(602\) & 6 & \(0.76\) & \(94.9\) & \(0.06\) & \(2\) & \(2977\) \\ PubMed & \(19717\) & \(85648\) & 500 & 3 & a.a. & \(80.2\) & \(0.02\) & \(1\) & \(18142\) \\ Amazon Photo & \(7650\) & \(238162\) & 745 & 8 & 34.74 & \(82.7\) & \(0.41\) & \(3\) & \(4555\) \\ Amazon Computers & \(13752\) & \(491122\) & 767 & 10 & 34.84 & \(77.7\) & \(0.26\) & \(4\) & \(10000\) \\ Coauthor CS & \(18333\) & \(168788\) & 6805 & 15 & 0.88 & \(80.8\) & \(0.05\) & \(5\) & \(9424\) \\ Coauthor Physics & \(34493\) & \(489524\) & 8415 & 5 & 0.39 & \(93.1\) & \(0.04\) & \(2\) & \(28221\) \\ \hline \hline \end{tabular}
\end{table}
Table 5: Statistics about the datasets used in this work.

**Remarks regarding Page Rank Shifts.** We study the centrality-based shift (which heavily correlates with a degree-based shift) for completeness reasons as a similar generation process is used in [79]. However, to which extent methods should be expected to assign high uncertainty to low-degree nodes is questionable: First, centrality and/or degree are feature-irrespective quantities. In contrast to homophily (nodes of similar classes have similar features), the confidence of a classifier may not (and should not) depend on the node degree/centrality. Furthermore, many baselines use symmetric normalization (Appendix C.6) that inherently favors high-degree nodes. Therefore, an evaluation regarding node degree/centrality as a distribution shift will not test the quality of an uncertainty measure but instead favor all models that use appropriate diffusion processes for most baselines. Regardless of our concerns regarding a centrality-based shift, we report results regarding that shift as well in Appendix C. Note that while GEBM is not among the best-performing estimators in this setting, it still achieves the highest average o.o.d. detection rank overall, indicating that its merits in all other settings heavily outweigh its performance on the Page Rank shift.

### Models and Training

At the backbone of all models, we use the same GCN [34] architecture if not specified explicitly otherwise. We use one hidden layer of dimension \(64\), symmetric normalization Appendix C.6, and add self-loops to the undirected (symmetric) adjacency matrix. We use ReLU nonlinearities, enable the bias term, and use dropout at \(p=0.5\).

All models are trained with the ADAM optimizer [33] with a learning rate of \(10^{-3}\), weight decay of \(10^{-4}\), and a cross-entropy objective. We use early stopping on the validation loss with a patience of \(50\), an absolute improvement threshold of \(10^{-1}\), and select the model with the best validation loss. We implement our models in PyTorch [58] and PyTorch Geometric [19] and train on two types of machines: (i) Xeon E5-2630 v4 CPU @ 2.20GHz with a NVIDIA GTX 1080TI GPU and 128 GB of RAM. (ii) AMD EPYC 7543 CPU @ 2.80GHz with a NVIDIA A100 GPU and 128 GB of RAM.

As the GCN backbone used in our experiments is lightweight, model training finishes within a few minutes and VRAM consumption is dominated by the datasets. Our post hoc method can be fitted and evaluated in negligible time (<1s).

For MC-Dropout [22], we use a dropout probability of \(p=0.5\) which we also use for DropEdge [59]. At inference, we evaluate \(50\) samples to compute uncertainty. For ensembles, we train \(10\) backbones from different weight initializations independently. The Bayesian GNN [6, 15, 18] also is evaluated with \(50\) samples during inference and uses a KL-loss with weight \(10^{-1}\) and is trained with learning rate \(10^{-2}\) and no weight-decay. We parametrize the weight distribution using a log transform and initialize the mean and log scale to \(1.0\) and \(-3.0\) respectively. Weight distributions are regularized to follow a standard normal.

For GPN [64], we follow the hyperparameters suggested by the authors and use warmup training on the normalizing flow for \(5\) epochs with a learning rate of \(1e-2\), no weight decay during joint training and \(1e-2\) during warmup. The flow dimension is \(16\) and is composed of \(10\) radial layers. The cross-entropy regularization weight is \(10^{-4}\). We use Page Rank propagation for \(10\) iterations at a teleport probability of \(0.1\).

For SGCN [82], we use the same GCN backbone and a GDK-prior at cutoff distance \(10\) and scale \(\sigma=1.0\). For teacher training, we use a learning rate of \(10^{-2}\), weight decay of \(5*10^{-4}\) and a KL-loss weight of \(10^{-1}\).

For HEAT [36], we use the hyperparameters suggested by the authors. In contrast to their study on the image domain, we do not have features with spatial extent and can not use standard deviation pooling on the volume. We set the temperature parameter of the combined HEAT model to \(-1\), following the suggestion of the authors. Similar to their EBM backbone, we imitate the structure of the classifier and use a 2-layer MLP with a hidden dimension of \(64\) akin to the GCN backbone.

Our GEBM framework regularizes logit-based joint energy at a strength \(\gamma\). For downstream tasks, this parameter can, in general, be tuned. We find that an equal weighting of predictive energy and regularization performs well: We choose \(\gamma\) such that the \(95\)% quantiles of both the training logits and the representations on which the Gaussian density model is fit are in the same range. Furthermore, recent work on deterministic uncertainty argues that density-based epistemic uncertainty should not be estimated directly from the logits [46]. We follow this advice and do not fit and evaluate theregularizer on the output layer (logits) of the GNN but instead on its penultimate layer representations. Note that for the ReLU networks we use, all formal proofs still hold in this setting as the penultimate representation of a node \(v\) is also described by a piecewise affine function [28] (see A.1.1. As a smoothing operator \(P_{\bm{A}}\), we employ label-propagation smoothing with \(\alpha=0.5\) for \(t=10\) iterations. Lastly, we found that aggregating the energy terms at different scales (Equation (9)) using a sum operation instead of logsumexp to perform better in practice and use it for our experiments.

In our ablation regarding different model backbones, we use the default hyperparameters from the GCN backbone (e.g. number of hidden layers). For each model additional hyperparameters are set to the following values: For GATv2 [70, 8] we use \(8\) heads and use summation to aggregate them. For SAGE [27], we use no normalization at the layers.

### Uncertainty Evaluation

For sampling-based approaches, we compute aleatoric and epistemic uncertainty as entropy and mutual information respectively according to [24]:

\[u^{\text{alea}}=\mathbb{E}_{\theta\sim p(\theta|\mathcal{D})}\left[\mathbb{H }\left[\bm{p}(y\mid\bm{x})\right]\right]\]

\[u^{\text{epi}}=\mathbb{MI}\left[\theta,\bm{y}\mid\bm{x},\mathcal{D}\right]= \mathbb{H}\left[\mathbb{E}_{\theta\sim p(\theta|\mathcal{D})}\left[\bm{p}(y \mid\bm{x})\right]\right]-\mathbb{E}_{\theta\sim p(\theta|\mathcal{D})}\left[ \mathbb{H}\left[\bm{p}(y\mid\bm{x})\right]\right]\]

For evidential approaches, we follow [64] and use the maximum softmax response \(\max_{c}\bm{p}(y=c\mid\bm{x})\) as aleatoric uncertainty and the total evidence \(\sum_{c}\bm{\alpha}_{c}\) as an epistemic estimate. Since we want to compare single measures of epistemic uncertainty, we evaluate GPN's epistemic uncertainty _in the presence of network effects_. For deterministic models (that are at the backbone of EBM-based approaches), we use the predictive entropy as a measure of aleatoric uncertainty \(\mathbb{H}\left[p(y\mid\bm{x})\right]\) and the energy \(E_{\theta}(\bm{x})\) as a measure of epistemic uncertainty. For all EBMs, we use a temperature of \(\tau=1.0\).

## Appendix C Additional Results

### Out-of-Distribution Detection

We report AUC-ROC and AUC-PR metrics for the o.o.d. detection problem in an inductive and transductive setting with corresponding standard deviations over all five splits and five model initializations each in Tables 6, 8, 10 and 12. Again, we report the average performance ranks are in Tables 2, 9, 11 and 13. As mentioned in Section 5.2, we consider a weighted average that does not favor any distribution shift family. That is, we assign a weight of \(1/6\) to structural and leave-out-class settings and factor in feature perturbations at a weight of \(1/9\) each.

In an inductive setting, GEBM outperforms all other baselines and achieves the best rank regarding both AUC-ROC and AUC-PR metrics. In the transductive setting, the two evidential methods GPN and SGCN outperform GEBM on two datasets: We argue that this is due to feature leakage as o.o.d. data is present during training and evidential models are explicitly encouraged to assign low evidence to anomalous nodes. We want to point out that it is unrealistic to assume that o.o.d. data is available in practice and therefore strongly argue in favor of the inductive scenario as a more realistic benchmark. Nonetheless, GEBM is highly effective for transductive problems as well.

### Improvement over Second Best Method

We evaluate the improvement in AUC-ROC scores of GEBM over the estimator assigned the overall second-best rank. To that end, we average the model ranks not individually for each estimator and dataset, but instead compute an average over datasets and splits simultaneously. This way, we obtain a global rank (over datasets and shifts) for each epistemic estimate. Again, to not favor certain classes of shifts, we assign weights such that each distribution shift family has an equal contribution. Based on AUC-ROC scores listed in Table 6, we list the rank of each model in Table 14:

While our approach, GEBM, also ranks the highest globally, a vanilla logit-based EBM is the next best approach. Therefore, we compute the improvement in AUC-ROC scores over this model achieved by 

[MISSING_PAGE_FAIL:25]

for the GCN used at the backbone of our experiments. Note that since our model does not change the output of the classifier, the calibration could be further improved using post hoc methods like temperature scaling [26]. This, however, is beyond the scope of this work.

**Expected Calibration Error (ECE).** The expected calibration error (\(\downarrow\)) [50] measures how well the predicted probabilities that are normalized to the interval \([0,1]\) match the true predictive accuracy. To that end, we bin each prediction into \(B=20\) bins according to their confidence (i.e. maximum softmax response \(\max_{c}\mathbf{p}(y=c\mid\bm{x})\). For each bin, we then compute the average accuracy and compute the ECE as the mean over all bins weighted by their size.

\[\text{ECE}=\sum_{k}\frac{|B_{k}|}{n}|\text{accuracy}(B_{k})-\text{confidence}(B_ {k})|\]

**Brier Score.** A similar metric is the Brier score [7] (\(\downarrow\)) which computes the mean squared distance between the predicted probabilities and the one-hot encoded true labels.

\[\text{Brier}=\frac{1}{n}\sum_{i}\lVert\bm{p}(\bm{y}\mid\bm{x}_{i})-\bm{y}_{i} \rVert_{2}^{2}\]

We report ECE and Brier scores for inductive and transductive settings in Tables 20 to 23. In terms of calibration metrics, none of the considered approaches consistently shows strong merits. We remark that work on GEBM and GNN calibration is somewhat orthogonal and our framework can be applied to any well-calibrated GNN backbone.

### Backbone Architecture

We report AUC-ROC and AUC-PR for o.o.d. detection using GEBM and different GNN backbones with corresponding standard deviations in Tables 24 and 25. GEBM is effective on all models and achieves the highest scores on most distribution shifts.

### Bias of Diffusion Operators

At the core of many GNNs and also our GEBM framework lies a diffusion operator \(P_{\bm{A}}:\mathbb{R}^{n}\rightarrow\mathbb{R}^{n}\). Here, we discuss three typical realizations and the bias the introduce.

**Symmetric Diffusion.** Symmetric diffusion normalizes the adjacency matrix as \(\hat{\bm{A}}=\bm{D}^{-1/2}\bm{A}\bm{D}^{-1/2}\). Here, \(\bm{D}=\text{diag}(\text{deg}(v_{1}),\cdots\text{deg}(v_{n}))\) is a diagonal matrix of node degrees. The symmetric diffusion operator has a dominant eigenvector that correlates with the node degree \(\bm{v}_{\max}\propto\bm{d}^{1/2}\) and therefore also centrality [12]. Repeated application of this diffusion process to any arbitrary signal will concentrate confidence at high degree nodes. Applying this diffusion to a confidence measure like the logits of GNN will therefore always favor high degree nodes.

\begin{table}
\begin{tabular}{l|c c c c c c c c} \hline \hline \multirow{2}{*}{**Model**} & \multirow{2}{*}{CoraML} & \multicolumn{2}{c}{CoraML} & \multirow{2}{*}{Citeseer} & \multirow{2}{*}{PubMed} & \multirow{2}{*}{\begin{tabular}{c} Amazon \\ Computers \\ \end{tabular} } & \multirow{2}{*}{\begin{tabular}{c} Amazon \\ Photo \\ \end{tabular} } & \multirow{2}{*}{\begin{tabular}{c} Coauthor \\ CS \\ \end{tabular} } & \multirow{2}{*}{
\begin{tabular}{c} Coauthor \\ Physics \\ \end{tabular} } \\ \hline GCN-MCD & 10.7/20.1 & 10.1/19.9 & 9.8/19.3 & 9.2/18.8 & 10.2/19.6 & 10.2/19.7 & 10.0/19.3 & 10.5/20.4 \\ GCN-DE & 6.3/14.2 & 8.0/16.9 & 7.8/16.2 & 7.3/16.6 & 7.2/15.9 & 7.1/15.8 & 6.5/13.2 & 8.1/16.8 \\ GCN-MCD+DE & 6.9/14.8 & 7.2/15.9 & 6.6/14.7 & 7.3/13.6 & 7.7/16.3 & 7.7/16.2 & 6.8/13.5 & 7.8/16.4 \\ GCN-BNN & 5.2/11.4 & 6.0/13.4 & 5.4/11.0 & 5.3/10.9 & 4.3/9.0 & 5.1/9.8 & 4.9/10.5 & 4.8/9.9 \\ GCN-Ens & 7.8/16.1 & 6.3/15.0 & 6.4/12.9 & 6.2/12.4 & 5.7/11.6 & 4.7/9.0 & 4.8/10.4 & 6.2/13.3 \\ GPN & 7.0/15.2 & 5.4/11.2 & 6.6/12.9 & 5.8/12.4 & 5.7/11.8 & 5.3/11.7 & 7.2/13.9 & 6.1/14.5 \\ SGCN & 5.2/9.5 & 6.1/14.6 & 6.0/12.6 & 5.0/11.7 & 9.1/15.5 & 7.6/15.1 & 9.3/17.9 & 4.6/11.2 \\ GCN-EBM & 4.5/7.9 & 4.0/8.2 & 5.2/10.3 & 5.2/12.0 & 4.2/10.7 & 4.0/10.9 & 4.1/1.7 & 4.4/8.4 \\ GCN-HEAT & 4.4/10.4 & 5.4/12.9 & 3.8/9.2 & 5.6/12.8 & 3.5/8.6 & 4.5/10.2 & 4.2/8.3 & 4.7/10.4 \\ GCN-safe & 5.3/9.1 & 4.4/8.1 & 5.2/9.5 & 5.4/8.9 & 5.9/13.2 & 6.4/12.9 & 5.5/10.7 & 5.8/11.7 \\
**GCN-GEBM** & **2.7/4.5** & **5.2/9.4** & **3.8/5.7** & **3.8/7.4** & **2.5/ 7.4** & **2.7/4.5** & **2.7/4.3** & **3.0/5.0** \\ \hline \hline \end{tabular}
\end{table}
Table 7: Average o.o.d. detection rank (AUC-ROC) (\(\downarrow\)) of epistemic uncertainty versus other epistemic measures / all uncertainty measures over all distribution shifts in an inductive setting (best and runner-up).

[MISSING_PAGE_FAIL:27]

marginalization, as discussed in Section 4.3. We want to highlight that GEBM allows to incorporate additional energy functions as well, e.g. if such information is available in designated downstream applications. As shown in this study, we find that the proposed energy functions already suffice to enable GEBM to be highly sensitive to various distribution shifts.

**Node-Level Anomalies.** We study node level anomalies by generating synthetic CSBM graphs [57] (intra-edge probability \(0.05\), inter-edge probability \(0.001\), \(n=1000\), \(c=7\)). We then generate \(c\)-dimensional logits (intuitively confidence scores) according to a standard normal distribution that is centered at \(l_{\text{disp}}=4\) for the dimension of the true class label of a node and \(0\) otherwise. This roughly resembles the logits of a well-trained classifier which peak at the true unknown class. We then perturb a fraction \(p=0.05\) of the logits by replacing them with positive noise from a standard normal distribution that is rescaled by an increasing magnitude. For each magnitude, we compute all three energy terms for each node and compare the difference in energy to the corresponding unperturbed energy. Effectively, this monitors how the energy of a node changes under increasingly severe distribution shifts that affect the logits of a classifier. We visualize the median of the energy differences in Figure 3(b): While all energies increase with higher magnitudes, the structure-agnostic energy term of GEBM is the most sensitive to anomalies that are located at individual nodes. It does not suffer from the smoothing of anomalous scores induced by graph diffusion.

**Cluster-Level Anomalies.** We study anomalies that affect an entire cluster of nodes by iteratively introducing an anomalous cluster to the graph. To that end, we leave out \(k\) classes and train a GCN on the Amazon Photos dataset. At inference, we re-introduce nodes (and edges) of the left-out classes which can be seen as anomalous from the perspective of the classifier. Similar to the aforementioned node-level anomaly, we monitor how each energy type changes while iteratively introducing the entire cluster(s) of o.o.d. nodes into the graph. Again, we see that the cluster-level energy term of GEBM is the most sensitive to this distribution shift in Figure 3(a).

Figure 4: Energy of different types for anomalies of increasing severity on synthetic data. We vary the size of an o.o.d. cluster on real data (left), insert per-node anomalies to the energies of an SBM (middle), and increase the heterophily in an SBM (right).

\begin{table}
\begin{tabular}{l|c c c c c c c c} \hline \hline \multirow{2}{*}{**Model**} & \multirow{2}{*}{CoraML} & \multicolumn{2}{c|}{\begin{tabular}{c} CoraML \\ LLM \\ \end{tabular} } & \multirow{2}{*}{Citeseer} & \multirow{2}{*}{PubMed} & \multicolumn{1}{c}{\begin{tabular}{c} Amazon \\ Computers \\ \end{tabular} } & \multirow{2}{*}{\begin{tabular}{c} Amazon \\ Photo \\ \end{tabular} } & \multirow{2}{*}{\begin{tabular}{c} Coauthor \\ CS \\ \end{tabular} } & \multirow{2}{*}{
\begin{tabular}{c} Coauthor \\ Physics \\ \end{tabular} } \\ \hline GCN-MCD & 10.5/20.3 & 10.2/20.0 & 10.2/19.8 & 8.9/18.5 & 10.4/19.9 & 10.7/20.2 & 10.2/19.3 & 10.7/20.6 \\ GCN-DE & 6.7/14.3 & 8.0/16.9 & 7.5/15.6 & 7.2/13.5 & 6.6/15.4 & 7.3/15.8 & 6.6/14.3 & 7.8/16.6 \\ GCN-MCD+DE & 6.8/14.5 & 7.6/16.5 & 7.2/15.2 & 7.0/13.3 & 6.5/15.3 & 6.6/14.7 & 6.8/13.7 & 7.9/16.7 \\ GCN-BNN & 5.7/11.9 & 6.1/13.7 & 5.3/11.3 & 5.1/11.4 & 4.7/11.9 & 3.8/7.9 & 5.1/10.8 & 4.9/11.6 \\ GCN-Ens & 7.4/14.1 & 5.7/14.1 & 5.8/12.4 & 7.7/14.2 & 7.3/15.9 & 5.3/11.5 & 4.3/9.5 & 5.7/12.8 \\ GPN & 6.5/12.8 & 6.1/10.9 & 7.5/15.7 & 5.8/11.3 & 4.8/10.8 & 5.1/11.1 & 6.7/13.1 & 6.2/13.0 \\ SGCN & 3.9/6.3 & 4.4/7.5 & 4.3/7.9 & 3.9/8.2 & 8.1/17.2 & 6.7/14.0 & 9.2/17.7 & 4.4/49.9 \\ GCN-EBM & 5.2/9.7 & 5.1/10.7 & 5.1/11.4 & 5.9/13.4 & 4.6/12.5 & 5.6/13.3 & 4.3/8.3 & 4.6/9.4 \\ GCN-HEAT & 4.7/9.3 & 4.8/12.2 & **3.8/9.2** & 5.1/12.2 & 3.9/9.9 & 5.6/14.1 & 4.4/9.2 & 4.9/11.1 \\ GCN-Safe & 5.8/9.6 & 4.4/9.4 & 5.4/9.9 & 5.6/9.1 & 6.5/13.8 & 6.5/13.4 & 5.7/11.0 & 5.9/11.6 \\
**GCN-GEBM** & **2.8** & **4.7** & **3.4** & **5.9** & 3.9/**6.9** & **3.8**/**5.8** & **2.7**/**6.0** & **3.0**/**5.2** & **2.7**/**4.7** & **3.0**/**5.0** \\ \hline \hline \end{tabular}
\end{table}
Table 9: Average o.o.d. detection rank (AUC-ROC) (\(\downarrow\)) of epistemic uncertainty versus other epistemic measures / all uncertainty measures over all distribution shifts in a transductive setting (best and runner-up).

[MISSING_PAGE_FAIL:29]

of GNNs on in-distribution data, and provides strong evidence for models to be underconfident. This does not conflict with our claim that with increasing distance from the training distribution, i.e. on out-of-distribution data, piece affine GNNs become overconfident. We empirically verify this in Figure 5: Both the energy and the maximum softmax probability - confidence measures - of the GNN architectures visualized increase (or converge to their maximum) under more severe normal feature perturbations.

### Robust Evidential Inference

\begin{table}
\begin{tabular}{l|c c c c c c c c} \hline \hline
**Model** & CoraML & \begin{tabular}{c} CoraML \\ LLM \\ \end{tabular} & Citeseer & PubMed & \begin{tabular}{c} Amazon \\ Computers \\ \end{tabular} & \begin{tabular}{c} Amazon \\ Photo \\ \end{tabular} & \begin{tabular}{c} Coauthor \\ CS \\ \end{tabular} & 
\begin{tabular}{c} Coauthor \\ Physics \\ \end{tabular} \\ \hline GCN-MCD & 9.7/18.9 & 9.2/19.0 & 9.4/18.7 & 9.1/18.7 & 9.1/18.3 & 9.9/19.1 & 10.0/19.2 & 10.5/20.4 \\ GCN-DE & 6.3/14.1 & 7.9/16.9 & 7.2/15.3 & 7.1/13.3 & 7.4/16.4 & 6.9/15.9 & 6.3/13.2 & 7.8/15.4 \\ GCN-MCD+DE & 6.8/14.7 & 7.2/15.9 & 6.0/13.9 & 6.6/12.8 & 7.9/16.9 & 7.6/16.6 & 6.7/13.5 & 7.4/15.1 \\ GCN-BNN & 5.9/12.3 & 6.6/14.1 & 5.6/11.8 & 5.7/11.4 & 4.6/10.4 & 5.3/9.7 & 5.2/11.6 & 5.3/11.9 \\ GCN-Ens & 7.4/15.7 & 6.8/16.0 & 6.8/13.5 & 7.2/13.4 & 6.4/14.9 & 4.4/8.9 & 4.9/11.1 & 6.4/13.6 \\ GPN & 7.1/15.3 & 6.0/14.8 & 6.4/13.1 & 4.8/9.0 & 5.4/12.9 & 5.3/11.8 & 6.8/13.5 & 5.6/12.5 \\ SGCN & 4.7/9.1 & 5.9/14.8 & 5.8/13.1 & 4.2/7.4 & 9.4/18.7 & 7.4/14.8 & 9.4/18.6 & 4.6/9.9 \\ GCN-EBM & 4.2/8.6 & 3.8/7.6 & 4.8/11.9 & 6.5/12.5 & 3.4/8.7 & 4.6/10.7 & 3.8/6.6 & 4.2/8.7 \\ GCN-HEAT & 4.8/11.8 & 4.6/13.1 & 4.7/11.0 & 5.5/12.7 & 3.6/10.9 & 4.7/12.4 & 4.6/10.6 & 5.2/13.7 \\ GCNSafe & 6.4/11.9 & 4.8/10.1 & 5.6/11.2 & 5.4/8.9 & 5.8/13.3 & 6.9/14.7 & 5.4/10.3 & 6.1/11.9 \\
**GCN-GEBM** & **2.7**/**4.5** & **3.2**/**5.7** & **3.6**/**7.7** & **3.6**/**7.0** & **2.8**/**6.5** & **3.0**/**5.0** & **2.8**/**4.7** & **3.0**/**4.8** \\ \hline \hline \end{tabular}
\end{table}
Table 11: Average o.o.d. detection rank (AUC-PR) (\(\downarrow\)) of epistemic uncertainty versus other epistemic measures / all uncertainty measures over all distribution shifts in an inductive setting (best and runner-up).

Figure 5: Confidence (Maximum Softmax Probability and negative energy) for different GNNs at increasing distribution shift severity.

Figure 6: Robust evidential inference using APPNP as a backbone for GEBM at increasingly severity feature perturbations.

[MISSING_PAGE_EMPTY:31]

We compare the AUC-ROC of different uncertainty estimators while increasing the fraction of perturbed features for each o.o.d. node in Figure 7. While both the softmax-level uncertainty of the vanilla GCN and the EBM again become overconfident, GEBM can reliably identify this distribution shift. This coincides with observations made for feature perturbations that affect all node features simultaneously and justifies focusing on that distribution shift for the bulk of our study.

## Appendix D Ablations

### Energy at Different Scales

We report AUC-ROC and AUC-PR for o.o.d.-detection ablating GEBM in an inductive and transductive setting with standard deviations in Tables 26 to 29. Additionally, we rank all variants of GEBM (i.e. energies at different structural scales) similar to the o.o.d. detection experiments in Section 5.2. We observe our proposed GEBM to consistently be the most effective over different shifts simultaneously. We can also confirm the effectiveness of the scale-specific energies at detecting distribution shifts that should be covered from their definition. Both the best and second-best ranking methods are GEBM and a variant that uses unregularized energy: This shows the efficacy of a scale-aware EBM for graph problems.

### Diffusion Process

We also ablate the diffusion operator \(P_{A}\) and its hyperparameters, i.e. the type of diffusion process (see Appendix C.6), the number of diffusion steps \(t\) as well the teleport probability \(\alpha\), in Figure 8. We evaluate the performance of GEBM on a representative of each distribution shift family. As expected, low \(t\) and high \(\alpha\) aid node-level anomaly detection while the opposite holds for cluster and local shifts. Label-Propagation achieves satisfactory performance over the entire range of diffusion hyperparameters which justifies using it in our experiments. In particular, we did not tune any hyperparameters for good o.o.d.-detection. As stated in Appendix C.6, it does not bias the energy toward high-degree nodes which explains its advantages over the other diffusion types. It performs well over a broad range of hyperparameters making GEBM less sensitive to those.

\begin{table}
\begin{tabular}{l|c c c c c c c c c} \hline \hline \multirow{2}{*}{**Model**} & \multirow{2}{*}{CoraML} & \multicolumn{2}{c}{CoraML} & \multirow{2}{*}{Citeseer} & \multirow{2}{*}{PubMed} & \multirow{2}{*}{\begin{tabular}{c} Amazon \\ Computers \\ \end{tabular} } & \multirow{2}{*}{\begin{tabular}{c} Amazon \\ Photo \\ \end{tabular} } & \multirow{2}{*}{\begin{tabular}{c} Coauthor \\ CS \\ \end{tabular} } & \multirow{2}{*}{
\begin{tabular}{c} Coauthor \\ Physics \\ \end{tabular} } \\ \hline GCN-MCD & 9.9/18.9 & 9.4/19.0 & 9.1/18.5 & 9.5/19.1 & 8.9/18.2 & 10.1/19.4 & 10.0/18.9 & 10.5/20.3 \\ GCN-DE & 6.3/13.9 & 7.4/16.1 & 7.2/15.6 & 6.8/12.9 & 7.6/16.7 & 7.3/16.4 & 6.7/13.3 & 7.1/14.4 \\ GCN-MCD+DE & 6.7/14.5 & 7.5/16.2 & 6.9/15.3 & 6.1/12.3 & 7.6/16.7 & 6.2/15.3 & 6.0/12.7 & 7.2/14.7 \\ GCN-BNN & 5.7/12.1 & 6.7/14.1 & 6.2/12.8 & 5.6/12.8 & 5.3/12.6 & 4.9/8.9 & 6.0/12.6 & 5.7/12.9 \\ GCN-Ens & 7.2/14.2 & 6.8/16.1 & 6.3/12.9 & 7.6/13.9 & 7.2/16.1 & 5.9/12.3 & 4.5/11.0 & 6.4/13.8 \\ GPN & 7.0/15.1 & 6.2/12.9 & 7.0/15.4 & 5.1/8.4 & 5.1/11.2 & 5.4/11.6 & 6.6/12.0 & 5.9/9.8 \\ SGCN & 3.9/6.9 & 4.2/8.8 & **4.2/8.4** & **3.5/6.3** & 7.6/16.5 & 6.3/13.7 & 9.3/18.4 & 4.7/8.5 \\ GCN-EBM & 4.8/9.3 & 4.4/11.2 & 4.8/13.1 & 6.4/13.3 & 3.8/11.3 & 4.6/11.3 & 4.0/17.4 & 4.1/8.6 \\ GCN-HEAT & 4.7/10.2 & 4.4/12.9 & **3.5**/9.8 & 5.2/12.7 & 3.9/11.3 & 4.9/14.1 & 4.4/10.7 & 5.2/14.0 \\ GCNSafe & 6.7/12.1 & 5.3/10.8 & 6.7/12.5 & 5.8/9.5 & 6.4/14.7 & 6.5/15.6 & 5.7/10.9 & 6.1/11.8 \\
**GEN-GEBM** & **3.2**/**5.2** & **3.6**/**6.5** & 4.2/9.3 & 4.4/8.5 & **2.7**/**6.7** & **3.9**/**8.6** & **2.8**/**5.8** & **3.2**/**5** \\ \hline \hline \end{tabular}
\end{table}
Table 13: Average o.o.d. detection rank (AUC-PR) (\(\downarrow\)) of epistemic uncertainty versus other epistemic measures / all uncertainty measures over all distribution shifts in a transductive setting (best and runner-up).

\begin{table}
\begin{tabular}{l|c c c c c c c c c c c} \hline \hline \multirow{2}{*}{Model} & GCN & GCN & GCN & GCN & GCN & GCN & GCN & GCN & GCN & GCN & GCN & GCN & GCN & GCN \\ MCD & DE & MCD+DE & BNN & Ens & GPN & SGCN & EBM & HEAT & GCN & GEBM \\ \hline Global Rank \(\downarrow\) & \(19.6\) & \(15.3\) & \(15.2\) & \(10.7\) & \(12.6\) & \(13.0\) & \(13.9\) & 9.4 & \(10.3\) & \(10.6\) & **5.0** \\ \hline \hline \end{tabular}
\end{table}
Table 14: Global o.o.d. detection rank of each model, averaged over all datasets and distribution shifts in an inductive setting based on AUC-ROC scores (best and runner-up).

[MISSING_PAGE_EMPTY:33]

[MISSING_PAGE_EMPTY:34]

[MISSING_PAGE_FAIL:35]

[MISSING_PAGE_EMPTY:37]

[MISSING_PAGE_FAIL:39]

\begin{table}
\begin{tabular}{l l l|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c} \hline \hline  & \multicolumn{2}{c|}{Model} & \multicolumn{2}{c|}{LoC _(last)_} & \multicolumn{2}{c|}{LoC _(hereto)_} & \multicolumn{2}{c|}{Ber(0.5)} & \multicolumn{2}{c|}{Ber(\(\hat{p}\)_near_} & \multicolumn{2}{c|}{\(\mathcal{N}(\mathbf{0},\boldsymbol{I})\) _(fair)_} & \multicolumn{2}{c|}{Homophily} & \multicolumn{2}{c|}{Page Rank} \\ \hline \multirow{3}{*}{**Model**} & EBM & \(89.9_{\pm 0.9}\) & \(88.4_{\pm 2.3}\) & \(58.7_{\pm 4.6}\) & \(67.1_{\pm 2.0}\) & \(26.4_{\pm 1.2}\) & \(71.2_{\pm 1.6}\) & \(\mathbf{74.2}_{\pm 2.1}\) & \(\mathbf{74.2}_{\pm 2.1}\) \\  & Safe & \(\mathbf{91.6}_{\pm 0.7}\) & \(\mathbf{90.5}_{\pm 1.8}\) & \(53.5_{\pm 3.3}\) & \(56.9_{\pm 1.7}\) & \(36.1_{\pm 1.2}\) & \(73.1_{\pm 1.5}\) & \(50.6_{\pm 0.6}\) & \(\mathbf{65.0}\) & \(\mathbf{91.6}_{\pm 0.8}\) & \(\mathbf{76.7}_{\pm 13.3}\) & \(\mathbf{57.7}_{\pm 13.3}\) \\ \cline{2-19}  & GEMM & \(\mathbf{91.6}_{\pm 0.8}\) & \(89.5_{\pm 1.7}\) & \(\mathbf{94.3}_{\pm 2.4}\) & \(\mathbf{77.1}_{\pm 1.8}\) & \(\mathbf{86.6}_{\pm 0.9}\) & \(\mathbf{76.7}_{\pm 13.3}\) & \(\mathbf{57.7}_{\pm 13.3}\) & \(\mathbf{57.7}_{\pm 13.3}\) & \\ \hline \multirow{3}{*}{**Model**} & EBM & \(90.2_{\pm 1.2}\) & \(89.7_{\pm 1.0}\) & \(58.1_{\pm 2.7}\) & \(55.6_{\pm 1.6}\) & \(44.1_{\pm 2.0}\) & \(72.1_{\pm 1.6}\) & \(51.4_{\pm 1.0}\) & \(51.4_{\pm 1.0}\) & \(\mathbf{50.6}_{\pm 0.8}\) & \(\mathbf{50.1}_{\pm 0.8}\) & \(\mathbf{50.1}_{\pm 0.8}\) & \(\mathbf{50.1}_{\pm 0.8}\) \\  & Safe & \(\mathbf{91.5}_{\pm 0.5}\) & \(\mathbf{90.8}_{\pm 0.9}\) & \(54.6_{\pm 2.2}\) & \(53.2_{\pm 1.0}\) & \(45.4_{\pm 1.6}\) & \(70.3_{\pm 1.9}\) & \(49.9_{\pm 1.1}\) & \(49.9_{\pm 1.1}\) & \(49.9_{\pm 1.1}\) & \(\mathbf{49.9}_{\pm 1.1}\) & \(\mathbf{49.9}_{\pm 1.1}\) \\  & GEMM & \(\mathbf{85.0}_{\pm 0.5}\) & \(\mathbf{85.5}_{\pm 3.8}\) & \(\mathbf{89.5}_{\pm 3.9}\) & \(\mathbf{69.3}_{\pm 2.5}\) & \(\mathbf{69.3}_{\pm 2.4}\) & \(\mathbf{76.5}_{\pm 3.5}\) & \(\mathbf{72.6}_{\pm 2.5}\) & \(\mathbf{53.3}_{\pm 1.8}\) & \(\mathbf{53.2}_{\pm 1.9}\) & \(\mathbf{69.2}_{\pm 0.8}\) & \(\mathbf{53.3}_{\pm 1.8}\) \\ \hline \multirow{3}{*}{**Model**} & EBM & \(76.5_{\pm 6.1}\) & \(71.9_{\pm 4.9}\) & \(46.6_{\pm 2.5}\) & \(\mathbf{52.3}_{\pm 2.4}\) & \(42.8_{\pm 1.9}\) & \(53.2_{\pm 1.9}\) & \(69.2_{\pm 0.8}\) & \(\mathbf{69.2}_{\pm 0.8}\) & \(\mathbf{69.2}_{\pm 0.8}\) & \(\mathbf{69.2}_{\pm 0.8}\) & \(\mathbf{69.2}_{\pm 0.8}\) \\  & Safe & \(79.0_{\pm 5.0}\) & \(\mathbf{76.4}_{\pm 3.3}\) & \(47.6_{\pm 1.2}\) & \(49.3_{\pm 1.3}\) & \(46.2_{\pm 1.6}\) & \(51.2_{\pm 1.8}\) & \(47.7_{\pm 0.5}\) & \(\mathbf{47.7}_{\pm 0.5}\) & \(\mathbf{51.2}_{\pm 1.8}\) & \(\mathbf{47.7}_{\pm 0.5}\) & \(\mathbf{47.7}_{\pm 0.5}\) \\  & GEMM & \(\mathbf{80.7}_{\pm 3.5}\) & \(\mathbf{76.4}_{\pm 6.3}\) & \(\mathbf{51.6}_{\pm 0.9}\) & \(51.4_{\pm 2.3}\) & \(\mathbf{53.6}_{\pm 2.3}\) & \(\mathbf{65.3}_{\pm 2.7}\) & \(\mathbf{65.4}_{\pm 1.8}\) & \(\mathbf{52.4}_{\pm 1.8}\) & \(\mathbf{52.4}_{\pm 1.3}\) & \(\mathbf{53.2}_{\pm 3.3}\) & \(\mathbf{65.4}_{\pm 1.3}\) \\ \hline \multirow{3}{*}{**Model**} & EBM & \(74.0_{\pm 6.4}\) & \(75.0_{\pm 7.1}\) & \(47.1_{\pm 3.0}\) & \(\mathbf{52.7}_{\pm 2.5}\) & \(42.2_{\pm 2.8}\) & \(53.2_{\pm 3.8}\) & \(\mathbf{68.9}_{\pm 1.2}\) \\  & Safe & \(\mathbf{77.3}_{\pm 5.4}\) & \(\mathbf{78.2}_{\pm 4.7}\) & \(48.1_{\pm 1.1}\) & \(49.2_{\pm 1.3}\) & \(46.6_{\pm 1.5}\) & \(51.1_{\pm 5.5}\) & \(48.0_{\pm 0.5}\) & \(\mathbf{48.0}_{\pm 0.5}\) & \(\mathbf{55.1}_{\pm 0.5}\) & \(\mathbf{48.0}_{\pm 0.5}\) & \(\mathbf{55.0}_{\pm 0.5}\) \\ \cline{2-19}  & GEMM & \(\mathbf{77.3}_{\pm 8.2}\) & \(73.3_{\pm 7.8}\) & \(\mathbf{51.9}_{\pm 1.2}\) & \(51.6_{\pm 1.7}\) & \(54.7_{\pm 1.3}\) & \(\mathbf{62.7}_{\pm 1.3}\) & \(\mathbf{54.7}_{\pm 1.3}\) & \(\mathbf{62.7}_{\pm 3.3}\) & \(\mathbf{53.0}_{\pm 2.1}\) & \(\mathbf{53.0}_{\pm 2.1}\) & \(\mathbf{53.0}_{\pm 2.1}\) & \(\mathbf{53.0}_{\pm 2.1}\) \\ \hline \hline \end{tabular}
\end{table}
Table 24: O.o.d. detection AUC-ROC(\(\uparrow\)) using different backbones on CoraML in an inductive setting.

\begin{table}
\begin{tabular}{l l|c|c|c|c|c|c|c|c|c|c|c|c} \hline \hline \hline  & \multicolumn{2}{c|}{Model} & \multicolumn{2}{c|}{LoC _(last)_} & \multicolumn{2}{c|}{LoC _(hereto)_} & \multicolumn{2}{c|}{Ber(0.5)} & \multicolumn{2}{c|}{Ber(\(\hat{p}\)_near_} & \multicolumn{2}{c|}{\(\mathcal{N}(\mathbf{0},\boldsymbol{I})\) _(fair)_} & \multicolumn{2}{c|}{Homophily} & \multicolumn{2}{c|}{Page Rank} \\ \hline \multirow{3}{*}{**Model**} & EBM & \(89.9_{\pm 0.9}\) & \(88.4_{\pm 2.3}\) & \(

[MISSING_PAGE_FAIL:41]

[MISSING_PAGE_EMPTY:42]

[MISSING_PAGE_FAIL:43]

\begin{table}
\begin{tabular}{l l|l|c|c|c|c|c|c|c|c} \hline \hline  & \multicolumn{2}{c|}{**Model**} & \multicolumn{2}{c|}{**LoC (\(l_{1}\))**} & \multicolumn{2}{c|}{**LoC (\(l_{2}\))**} & \multicolumn{2}{c|}{**Ber(\(\hat{p}\)) (\(near\))**} & \multicolumn{2}{c|}{**Ber(0.5)**} & \multicolumn{2}{c|}{\(\mathcal{N}(0,1)\) (\(\hat{p}\))**} & \multicolumn{2}{c|}{**Page Rank**} & \multicolumn{1}{c}{**Homophily**} & \multicolumn{1}{c}{**Rank(\(\downarrow\))**} \\ \hline \multirow{6}{*}{**O.0**} & EBM & 83.0\({}_{\pm 1}\) & 69.6\({}_{\pm 4.3}\) & 66.1\({}_{\pm 1.1}\) & 56.3\({}_{\pm 4.9}\) & 35.0\({}_{\pm 1.4}\) & **70.2\({}_{\pm 2.8}\)** & 62.5\({}_{\pm 2.8}\) & 3.6 \\  & Indep. & 72.2\({}_{\pm 1.0}\) & 55.5\({}_{\pm 2.3}\) & **82.1\({}_{\pm 1.3}\)** & **89.1\({}_{\pm 1.0}\)** & **99.8\({}_{\pm 2.0}\)** & 63.2\({}_{\pm 1.1}\) & 56.6\({}_{\pm 1.4}\) & 3.7 \\  & Local & 78.0\({}_{\pm 1.5}\) & 77.3\({}_{\pm 1.3}\) & 58.3\({}_{\pm 2.3}\) & 52.4\({}_{\pm 2.4}\) & 61.9\({}_{\pm 3.9}\) & 54.1\({}_{\pm 1.0}\) & **76.0\({}_{\pm 1.0}\)** & 4.0 \\  & Group & **88.0\({}_{\pm 1.5}\)** & 72.0\({}_{\pm 1.7}\) & 55.5\({}_{\pm 3.5}\) & 60.0\({}_{\pm 1.9}\) & 61.7\({}_{\pm 3.7}\) & 50.5\({}_{\pm 0.5}\) & 57.6\({}_{\pm 1.4}\) & 3.8 \\  & GEBM-\(F_{\theta}\) & 56.5\({}_{\pm 2.3}\) & 71.6\({}_{\pm 1.1}\) & 71.4\({}_{\pm 3.4}\) & 67.5\({}_{\pm 1.0}\) & 30.1\({}_{\pm 1.4}\) & 52.8\({}_{\pm 1.0}\) & 61.4\({}_{\pm 2.3}\) & 3.6 \\  & GEBM & 86.1\({}_{\pm 1.5}\) & 73.2\({}_{\pm 2.8}\) & 71.2\({}_{\pm 2.4}\) & 91.6\({}_{\pm 3.8}\) & 91.7\({}_{\pm 3.8}\) & 53.3\({}_{\pm 3.9}\) & 64.3\({}_{\pm 1.8}\) & **2.4** \\ \hline \multirow{6}{*}{**O.0**} & EBM & 84.0\({}_{\pm 1.7}\) & 73.0\({}_{\pm 0.5}\) & n.a. & 66.0\({}_{\pm 4.4}\) & 41.0\({}_{\pm 2.8}\) & **69.6\({}_{\pm 2.5}\)** & 64.7\({}_{\pm 1.6}\) & 3.3 \\  & Indep. & 85.9\({}_{\pm 2.9}\) & 58.8\({}_{\pm 3.3}\) & n.a. & 82.6\({}_{\pm 1.1}\) & **97.2\({}_{\pm 1.4}\)** & 52.5\({}_{\pm 0.4}\) & 55.3\({}_{\pm 0.8}\) & 3.7 \\  & Local & 85.9\({}_{\pm 2.9}\) & 64.0\({}_{\pm 0.8}\) & n.a. & 52.5\({}_{\pm 1.7}\) & 61.9\({}_{\pm 3.8}\) & 52.5\({}_{\pm 0.4}\) & 77.2\({}_{\pm 0.9}\) & 3.3 \\  & Group & 85.9\({}_{\pm 2.9}\) & 75.0\({}_{\pm 0.8}\) & n.a. & 55.9\({}_{\pm 2.3}\) & 61.7\({}_{\pm 2.3}\) & 52.5\({}_{\pm 0.4}\) & 57.7\({}_{\pm 1.4}\) & 3.5 \\  & GEBM-\(F_{\theta}\) & **88.3\({}_{\pm 1.2}\)** & **78.3\({}_{\pm 0.3}\)** & n.a. & **84.8\({}_{\pm 2.2}\)** & 31.7\({}_{\pm 1.3}\) & 52.6\({}_{\pm 0.7}\) & 62.6\({}_{\pm 1.6}\) & **2.1** \\ \hline \multirow{6}{*}{**O.0**} & EBM & 85.9\({}_{\pm 3.8}\) & 74.6\({}_{\pm 0.8}\) & **n.a.** & 72.4\({}_{\pm 3.8}\) & 88.4\({}_{\pm 3.9}\) & 52.5\({}_{\pm 0.4}\) & 65.2\({}_{\pm 0.8}\) & 2.7 \\  & Indep. & 48.6\({}_{\pm 2.2}\) & 57.7\({}_{\pm 3.5}\) & **62.7\({}_{\pm 2.2}\)** & **100.0\({}_{\pm 0.0}\)** & **96.2\({}_{\pm 2.5}\)** & 50.0\({}_{\pm 1.5}\) & 49.6\({}_{\pm 0.8}\) & 3.7 \\  & Local & 60.4\({}_{\pm 0.4}\) & **78.7\({}_{\pm 1.8}\)** & 58.6\({}_{\pm 1.4}\) & 73.4\({}_{\pm 3.5}\) & 65.8\({}_{\pm 0.7}\) & 48.3\({}_{\pm 0.5}\) & **54.7\({}_{\pm 1.1}\)** & 2.9 \\  & Group & 67.0\({}_{\pm 0.4}\) & 71.9\({}_{\pm 3.5}\) & 52.2\({}_{\pm 2.2}\) & 74.4\({}_{\pm 1.2}\) & 64.5\({}_{\pm 2.4}\) & 45.7\({}_{\pm 2.8}\) & 51.4\({}_{\pm 0.8}\) & 3.9 \\  & GEBM-\(F_{\theta}\) & **68.8\({}_{\pm 4.6}\)** & 69.8\({}_{\pm 3.2}\) & 56.4\({}_{\pm 4.7}\) & 51.7\({}_{\pm 1.8}\) & 31.2\({}_{\pm 0.6}\) & 47.2\({}_{\pm 0.8}\) & 51.3\({}_{\pm 0.4}\) & 4.4 \\  & GEBM & 65.8\({}_{\pm 3.4}\) & 74.1\({}_{\pm 3.9}\) & 59.1\({}_{\pm 3.8}\) & 96.6\({}_{\pm 0.8}\) & 83.3\({}_{\pm 3.8}\) & 47.6\({}_{\pm 0.5}\) & 51.4\({}_{\pm 0.8}\) & 2.9 \\ \hline \multirow{6}{*}{**O.0**} & EBM & 53.9\({}_{\pm 9.9}\) & 28.6\({}_{\pm 1.4}\) & n.a. & 53.1\({}_{\pm 1.3}\) & 38.0\({}_{\pm 0.4}\) & 64.4\({}_{\pm 1.1}\) & 55.1\({}_{\pm 1.3}\) & 3.2 \\  & Indep. & 50.5\({}_{\pm 1.8}\) & 23.3\({}_{\pm 1.4}\) & n.a. & **90.3\({}_{\pm 3.8}\)** & **84.9\({}_{\pm 4.5}\)** & 50.1\({}_{\pm 0.9}\) & 52.5\({}_{\pm 0.8}\) & 3.4 \\  & Local & 50.6\({}_{\pm 1.3}\) & 27.2\({}_{\pm 2.8}\) & n.a. & 56.4\({}_{\pm 1.6}\) & 60.2\({}_{\pm 2.9}\

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: We identify three main contributions in the introduction Section 1. Our novel model is described in Section 4.3, the formal proofs regarding integrability of EBMs and Gaussian regularization are given in Sections 4.2 and 4.3 and a novel evidential interpretation of our EBM framework can be found in Section 4.4. We support the claimed efficacy of our model at different structural scales by its strong out-of-distribution detection performance on a comprehensive suite of distribution shifts (Appendix C). Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discuss limitations in Section 6: We only aim at epistemic uncertainty estimation and can not improve on aleatoric metrics. Our method is tailored toward node classification in a homophilic setting, which is also acknowledged. Our method is less effective on centrality-based splits, which is discussed in Sections 5.2 and 6 and in-depth in Appendix C.6. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best

[MISSING_PAGE_FAIL:46]

3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We provide code to reproduce our experiments. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Experimental details, entailing dataset splits, architecture choices, optimization, etc., are provided in Appendix B. Additionally, they are listed as default configurations in the public code. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?Answer: [Yes] Justification: We omit error-bars and standard deviations in the main text for clarity, but supply them in Appendix C. They are explicitly referred to as standard deviations. Guidelines:

* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: Details about compute resources and a discussion about memory and training time are provided in Appendix B. Guidelines:

* The answer NA means that the paper does not include experiments.
* The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.
* The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.
* The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Our research aims to improve reliability of GNNs. All datasets are commonly used benchmarks that are publicly available. Our paper fully conforms with the code of ethics. Guidelines:

* The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
* If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.

* The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: We aim to contribute to making AI more reliable by improving on uncertainty quantification. We discuss the impact of our work beyond commonly known risks and concerns in research on AI in Section 6. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: We do not believe that model has an increased risk for misuse. We encourage users for active evaluation of the uncertainty provided in Section 6. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?Answer: [Yes] Justification: We cite papers producing the commonly used node classification benchmark. We downloaded all datasets from PyTorch Geometric, as described in Appendix B. We report licenses where we could find them. All datasets have been used in open research for several years and form a well-establish benchmark. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: Our paper does not provide new assets. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects**Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?

Answer: [NA]

Justification: Our paper does not involve crowdsourcing nor research with human subjects. Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.