# A Measure-Theoretic Axiomatisation of Causality

 Junhyung Park

Empirical Inference Department

MPI for Intelligent Systems

72076 Tubingen, Germany

junhyung.park@tuebingen.mpg.de&Simon Buchholz

Empirical Inference Department

MPI for Intelligent Systems

72076 Tubingen, Germany

simon.buchholz@tuebingen.mpg.de&Bernhard Scholkopf

Empirical Inference Department

MPI for Intelligent Systems

72076 Tubingen, Germany

bs@tuebingen.mpg.de&Krikamol Muandet

CISPA

Helmholtz Center for Information Security

66123 Saarbrucken, Germany

muandet@cispa.de

###### Abstract

Causality is a central concept in a wide range of research areas, yet there is still no universally agreed axiomatisation of causality. We view causality both as an extension of probability theory and as a study of _what happens when one intervenes on a system,_ and argue in favour of taking Kolmogorov's measure-theoretic axiomatisation of probability as the starting point towards an axiomatisation of causality. To that end, we propose the notion of a _causal space_, consisting of a probability space along with a collection of transition probability kernels, called _causal kernels_, that encode the causal information of the space. Our proposed framework is not only rigorously grounded in measure theory, but it also sheds light on long-standing limitations of existing frameworks including, for example, cycles, latent variables and stochastic processes.

## 1 Introduction

Causal reasoning has been recognised as a hallmark of human and machine intelligence, and in the recent years, the machine learning community has taken up a rapidly growing interest in the subject [46, 53, 54], in particular in representation learning [55, 41, 62, 57, 11, 40] and natural language processing [35, 19]. Causality has also been extensively studied in a wide range of other research domains, including, but not limited to, philosophy [39, 64, 16], psychology [60], statistics [45, 56] including social, biological and medical sciences [51, 31, 29, 26], mechanics and law [6].

The field of causality was born from the observation that probability theory and statistics (Figure 0(a)) cannot encode the notion of causality, and so we need additional mathematical tools to support the enhanced view of the world involving causality (Figure 0(b)). Our goal in this paper is to give an axiomatic framework of the forwards direction of Figure 0(b), which currently consists of many competing models (see Related Works). As a starting point, we observe that the forwards direction of Figure 0(a), i.e. _probability theory_, has a set of axioms based on measure theory (Axioms 2.1) that are widely accepted and used1, and hence argue that it is natural to take the primitive objects of this framework as the basic building blocks. Despite the fact that all of the existing mathematical frameworks of causality recognise the crucial role that probability plays / should play in any causaltheory, it is surprising that few of them try to build directly upon the axioms of probability theory, and those that do fall short in different ways (see Related Works).

On the other hand, we place _manipulations_ at the heart of our approach to causality; in other words, we make changes to some parts of a system, and we are interested in what happens to the rest of this system. This manipulative philosophy towards causality is shared by many philosophers [64], and is the essence behind almost all causal frameworks proposed and adopted in the statistics/machine learning community that we are aware of.

To this end, we propose the notion of _causal spaces_ (Definition 2.2), constructed by adding causal objects, called _causal kernels_, directly to probability spaces. We show that causal spaces strictly generalise (the interventional aspects of) existing frameworks, i.e. given any configuration of, for example, a structural causal model or potential outcomes framework, we can construct a causal space that can carry the same (interventional) information. Further, we show that causal spaces can seamlessly support situations where existing frameworks struggle, for example those with hidden confounders, cyclic causal relationships or continuous-time stochastic processes.

Related WorksWe stress that our paper should _not_ be understood as a criticism of the existing frameworks, or that somehow our goal is to replace them. On the contrary, we foresee that they will continue to thrive in whatever domains they have been used in, and will continue to find novel application areas.

Most prominently, there are the _structural causal models_ (SCMs) [43, 46], based most often on directed acyclic graphs (DAGs). Here, the theory of causality is built around variables and structural equations, and probability only enters the picture through a distribution on the exogeneous variables [33]. Efforts have been made to axiomatise causality based on this framework [21, 23, 28], but models based on structural equations or graphs inevitably rely on assumptions even for the definitions themselves, such as being confined to a finite number of variables, the issue of solvability in the case of non-recursive (or cyclic) cases, that all common causes (whether latent or observed) are modeled, or that the variables in the model do not causally affect anything outside the model. Hence, these cannot be said to be an "axiomatic definition" in the strictest sense. In a series of examples in Section 4, we highlight cases for which causal spaces have a natural representation but SCMs do not, including common causes, cycles and continuous-time stochastic processes.

The _potential outcomes framework_ is a competing model, most often used in economics, social sciences or medicine research, in which we have a designated _treatment_ variable, whose causal effect we are interested in, and for each value of the treatment variable, we have a separate, _potential outcome_ variable [31, 26]. There are other, perhaps lesser-known approaches to model causality, such as that based on decision theory [17, 52], on category theory [32, 20], on an agent explicitly performing actions that transform the state space [15], or settable systems [63].

Perhaps the works that are the most relevant to this paper are those that have already recognised the need for an axiomatisation of causality based on measure-theoretic probability theory. Ortega [42] uses a particular form of a _tree_ to define a causal space, and in so doing, uses an alternative, Bayesian set-up of probability theory [34]. It has an obvious drawback that it only considers _countable_ sets of "realisations", clearly ruling out many interesting and commonly-occurring cases, and also does not seem to accommodate cycles. Heymann et al. [27] define the _information dependency model_ based on measurable spaces to encode causal information. We find this to be a highly interesting and relevant approach, but the issue of cycles and solvability arises, and again, only countable sets of outcomes are considered, with the authors admitting that the results are likely not to hold with uncountable sets. Moreover, probabilities and interventions require additional work to be taken care of. Lastly, Cabreros and Storey [12] attempt to provide a measure-theoretic grounding to the potential

Figure 1: Data generating processes and data.

outcomes framework, but thereby confine attention to the setting of a finite number of variables, and even restrict the random variables to be discrete.

Finally, we mention the distinction between _type_ causality and _actual_ causality. The former is a theory about general causality, involving statements such as "in general, smoking makes lung cancer more likely". Type causality is what we will be concerned with in this paper. Actual causality, on the other hand, is interested in whether a _particular_ event was caused by a _particular_ action, dealing with statements such as "Bob got lung cancer because he smoked for 30 years". It is an extremely interesting area of research that has far-reaching implications for concepts such as responsibility, blame, law, harm [4, 5], model explanation [7] and algorithmic recourse [36]. Many definitions of actual causality have been proposed [25, 22, 24], but the question of how to define actual causality is still not settled [1]. The current definitions of actual causality are all grounded on (variants) of SCMs, and though out of the scope of this paper, it will be an interesting future research direction to consider how actual causality can be incorporated into our proposed framework.

## 2 Causal Spaces and Interventions

Familiarity with measure-theoretic probability theory is necessary, and we succinctly collect the most essential definitions and results in Appendix A. Most important to note is the definition of a _transition probability kernel_ (also given at the end of Appendix A.1): for measurable spaces \((E,\mathcal{E})\) and \((F,\mathcal{F})\), a mapping \(K:E\times\mathcal{F}\to[0,\infty]\) is called a _transition probability kernel_ from \((E,\mathcal{E})\) into \((F,\mathcal{F})\) if the mapping \(x\mapsto K(x,B)\) is measurable for every set \(B\in\mathcal{F}\) and the mapping \(B\mapsto K(x,B)\) is a probability measure on \((F,\mathcal{F})\) for every \(x\in E\). Also worthy of mention is the definition of a _measurable rectangle_: if \((E,\mathcal{E})\) and \((F,\mathcal{F})\) are measurable spaces and \(A\in\mathcal{E}\) and \(B\in\mathcal{F}\), then the _measurable rectangle_\(A\times B\) is the set of all pairs \((x,y)\) with \(x\in A\) and \(y\in B\). All proofs are deferred to Appendix F. We start by recalling the axioms of probability theory, which we will use as the starting point of our work.

**Axioms 2.1** (Kolmogorov [38]).: _A probability space is a triple \((\Omega,\mathcal{H},\mathbb{P})\), where:_

* \(\Omega\) _is a set of outcomes;_
* \(\mathcal{H}\) _is a collection of events forming a_ \(\sigma\)_-algebra, i.e. a collection of subsets of_ \(\Omega\) _such that_ _(a)_ \(\Omega\in\mathcal{H}\)_; (b) if_ \(A\in\mathcal{H}\)_, then_ \(\Omega\setminus A\in\mathcal{H}\)_; (c) if_ \(A_{1},A_{2},...\in\mathcal{H}\)_, then_ \(\cup_{n}A_{n}\in\mathcal{H}\)_;_
* \(\mathbb{P}\) _is a probability measure on_ \((\Omega,\mathcal{H})\)_, i.e. a function_ \(\mathbb{P}:\mathcal{H}\to[0,1]\) _satisfying (a)_ \(\mathbb{P}(\emptyset)=0\)_; (b)_ \(\mathbb{P}(\cup_{n}A_{n})=\sum_{n}\mathbb{P}(A_{n})\) _for any disjoint sequence_ \((A_{n})\) _in_ \(\mathcal{H}\) _(c)_ \(\mathbb{P}(\Omega)=1\)_._

In the development of probability theory, one starts by assuming the existence of a probability space \((\Omega,\mathcal{H},\mathbb{P})\). However, the actual construction of probability spaces that can carry random variables corresponding to desired random experiments is done through (repeated applications of) two main results - those of Ionescu-Tulcea and Kolmogorov [14, p.160, Chapter IV, Section 4]; the former constructs a probability space that can carry a finite or countably infinite chain of trials, and the latter shows the existence of a probability space that can carry a process with an arbitrary index set. In both cases, the measurable space \((\Omega,\mathcal{H})\) is constructed as a product space:

* for a finite set of trials, each taking place in some measurable space \((E_{t},\mathcal{E}_{t}),t=1,...,n\), we have \((\Omega,\mathcal{H})=\otimes_{t=1}^{n}(E_{t},\mathcal{E}_{t})\);
* for a countably infinite set of trials, each taking place in some measurable space \((E_{t},\mathcal{E}_{t})\), \(t\in\mathbb{N}\), we have \((\Omega,\mathcal{H})=\otimes_{t\in\mathbb{N}}(E_{t},\mathcal{E}_{t})\);
* for a process \(\{X_{t}:t\in T\}\) with an arbitrary index set \(T\), we assume that all the \(X_{t}\) live in the same standard measurable space \((E,\mathcal{E})\), and let \((\Omega,\mathcal{H})=(E,\mathcal{E})^{T}=\otimes_{t\in T}(E,\mathcal{E})\).

In the construction of a _causal space_, we will take as our starting point a probability space \((\Omega,\mathcal{H},\mathbb{P})\), where the measure \(\mathbb{P}\) is defined on a product measurable space \((\Omega,\mathcal{H})=\otimes_{t\in T}(E_{t},\mathcal{E}_{t})\) with the \((E_{t},\mathcal{E}_{t})\) being the same standard measurable space if \(T\) is uncountable. Denote by \(\mathcal{P}(T)\) the power set of \(T\), and for \(S\in\mathcal{P}(T)\), we denote by \(\mathcal{H}_{S}\) the sub-\(\sigma\)-algebra of \(\mathcal{H}=\otimes_{t\in T}\mathcal{E}_{t}\) generated by measurable rectangles \(\times_{t\in T}A_{t}\), where \(A_{t}\in\mathcal{E}_{t}\) differs from \(E_{t}\) only for \(t\in S\). In particular, \(\mathcal{H}_{\emptyset}=\{\emptyset,\mathcal{H}\}\) is the trivial \(\sigma\)-algebra of \(\Omega=\times_{t\in T}E_{t}\). Also, we denote by \(\Omega_{S}\) the subspace \(\times_{s\in S}E_{s}\) of \(\Omega=\times_{t\in T}E_{t}\), and for \(T\supseteq S\supseteq U\), we let \(\pi_{SU}\) denote the natural projection from \(\Omega_{S}\) onto \(\Omega_{U}\).

**Definition 2.2**.: A _causal space_ is defined as the quadruple \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})\), where \((\Omega,\mathcal{H},\mathbb{P})=(\times_{t\in T}E_{t},\otimes_{t\in T}E_{t}, \mathbb{P})\) is a probability space and \(\mathbb{K}=\{K_{S}:S\in\mathcal{P}(T)\}\), called the _causal mechanism_, is a collection of transition probability kernels \(K_{S}\) from \((\Omega,\mathcal{H}_{S})\) into \((\Omega,\mathcal{H})\), called the _causal kernel on \(\mathcal{H}_{S}\)_, that satisfy the following axioms:

1. for all \(A\in\mathcal{H}\) and \(\omega\in\Omega\), \[K_{\emptyset}(\omega,A)=\mathbb{P}(A);\]
2. for all \(\omega\in\Omega\), \(A\in\mathcal{H}_{S}\) and \(B\in\mathcal{H}\), \[K_{S}(\omega,A\cap B)=1_{A}(\omega)K_{S}(\omega,B)=\delta_{\omega}(A)K_{S}( \omega,B);\] \[\text{in particular, for }A\in\mathcal{H}_{S}\text{, }K_{S}(\omega,A)=1_{A}(\omega)K_{S}(\omega,\Omega)=1_{A}(\omega)=\delta_{ \omega}(A).\]

Here, the probability measure \(\mathbb{P}\) should be viewed as the "observational measure", and the causal mechanism \(\mathbb{K}\), consisting of causal kernels \(K_{S}\) for \(S\in\mathcal{P}(T)\), contains the "causal information" of the space, by directly specifying the interventional distributions. We write \(1_{A}(\omega)\) when viewed as a function in \(\omega\) for a fixed \(A\), and \(\delta_{\omega}(A)\) when viewed as a measure for a fixed \(\omega\in\Omega\). Note that \(\mathbb{K}\) cannot be determined "independently" of the probability measure \(\mathbb{P}\), since, for example, \(K_{\emptyset}\) is clearly dependent on \(\mathbb{P}\) by (i).

Before we discuss the meaning of the two axioms, we immediately give the definition of an _intervention_. An intervention is carried out on a sub-\(\sigma\)-algebra of the form \(\mathcal{H}_{U}\) for some \(U\in\mathcal{P}(T)\). In the following, for \(S\in\mathcal{P}(T)\), we denote \(\omega_{S}=\pi_{TS}(\omega)\). Then note that \(\Omega=\Omega_{S}\times\Omega_{T\setminus S}\) and for any \(\omega\in\Omega\), we can decompose it into components as \(\omega=(\omega_{S},\omega_{T\setminus S})\). Then \(K_{S}(\omega,A)=K_{S}((\omega_{S},\omega_{T\setminus S}),A)\) for any \(A\in\mathcal{H}\) only depends on the first \(\omega_{S}\) component of \(\omega=(\omega_{S},\omega_{T\setminus S})\). As a slight abuse of notation, we will sometimes write \(K_{S}(\omega_{S},A)\) for conciseness.

**Definition 2.3**.: Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t\in T }E_{t},\mathbb{P},\mathbb{K})\) be a causal space, and \(U\in\mathcal{P}(T)\), \(\mathbb{Q}\) a probability measure on \((\Omega,\mathcal{H}_{U})\) and \(\mathbb{L}=\{L_{V}:V\in\mathcal{P}(U)\}\) a causal mechanism on \((\Omega,\mathcal{H}_{U},\mathbb{Q})\). An _intervention on \(\mathcal{H}_{U}\) via \((\mathbb{Q},\mathbb{L})\)_ is a new causal space \((\Omega,\mathcal{H},\mathbb{P}^{\text{do}(U,\mathbb{Q})},\mathbb{K}^{\text{do }(U,\mathbb{Q},\mathbb{L})})\), where the _intervention measure_\(\mathbb{P}^{\text{do}(U,\mathbb{Q})}\) is a probability measure on \((\Omega,\mathcal{H})\) defined, for \(A\in\mathcal{H}\), by

\[\mathbb{P}^{\text{do}(U,\mathbb{Q})}(A)=\int\mathbb{Q}(d\omega)K_{U}(\omega,A)\] (1)

and \(\mathbb{K}^{\text{do}(U,\mathbb{Q},\mathbb{L})}=\{K_{S}^{\text{do}(U,\mathbb{ Q},\mathbb{L})}:S\in\mathcal{P}(T)\}\) is the _intervention causal mechanism_ whose _intervention causal kernels_ are

\[K_{S}^{\text{do}(U,\mathbb{Q},\mathbb{L})}(\omega,A)=\int L_{S\cap U}(\omega_ {S\cap U},d\omega_{U}^{\prime})K_{S\cup U}((\omega_{S\setminus U},\omega_{U}^ {\prime}),A).\] (2)

The intuition behind these definitions is as follows. Starting from the probability space \((\Omega,\mathcal{H},\mathbb{P})\), we choose a "subspace" on which to intervene, namely a sub-\(\sigma\)-algebra \(\mathcal{H}_{U}\) of \(\mathcal{H}\). The _intervention_ is the process of placing any desired measure \(\mathbb{Q}\) on this "subspace" \((\Omega,\mathcal{H}_{U})\), along with an _internal_ causal mechanism \(\mathbb{L}\) on this "subspace"2. The causal kernel \(K_{U}\) corresponding to the "subspace" \(\mathcal{H}_{U}\), which is encoded in the original causal space, determines what the _intervention measure_ on the whole space \(\mathcal{H}\) will be, via equation (1). For the causal kernels after intervention, the causal effect first takes place within \(\mathcal{H}_{U}\) via the internal causal mechanism \(\mathbb{L}\), then propagates to the rest of \(\mathcal{H}\) via equation (2).

Footnote 2: Choosing \(\mathbb{Q}\) to have measure 1 on a single element would correspond to what is known as a “hard intervention” in the SCM literature. Letting \(\mathbb{Q}\) and \(\mathbb{L}\) be arbitrary would allow us to obtain any “soft intervention”.

The definition of intervening on a \(\sigma\)-algebra of the form \(\mathcal{H}_{U}\) given in Definition 2.3 sheds light on the two axioms of causal spaces given in Definition 2.2.

**Remark 2.4**.: **Trivial Intervention**: Axiom (i) of causal mechanisms in Definition 2.2 ensures that intervening on the trivial \(\sigma\)-algebra (i.e. not intervening at all) leaves the probability measure intact, i.e. writing \(\mathbb{Q}\) for the trivial probability measure on \(\{\emptyset,\Omega\}\), we have \(\mathbb{P}^{\text{do}(\emptyset,\mathbb{Q})}=\mathbb{P}\).
**Interventional Determinism**: Axiom (ii) of Definition 2.2 ensures that for any \(A\in\mathcal{H}_{U}\), we have \(\mathbb{P}^{\text{do}(U,\mathbb{Q})}(A)=\mathbb{Q}(A)\), which means that if we intervene on the causal space by giving \(\mathcal{H}_{U}\) a particular probability measure \(\mathbb{Q}\), then \(\mathcal{H}_{U}\) indeed has that measure with respect to the intervention probability measure.

The following example should serve as further clarification of the concepts.

**Example 2.5**.: _Let \(E_{1}=E_{2}=\mathbb{R}\), and \(\mathcal{E}_{1},\mathcal{E}_{2}\) be Lebesgue \(\sigma\)-algebras on \(E_{1}\) and \(E_{2}\). Each \(e_{1}\in E_{1}\) and \(e_{2}\in E_{2}\) respectively represent the altitude in metres and temperature in Celsius of a random location. For simplicity, we assume a jointly Gaussian measure \(\mathbb{P}\) on \((\Omega,\mathcal{H})=(E_{1}\times E_{2},\mathcal{E}_{1}\otimes\mathcal{E}_{2})\), say with mean vector \(\begin{pmatrix}1000\\ 1\end{pmatrix}\) and covariance matrix \(\begin{pmatrix}300&-15\\ -15&1\end{pmatrix}\). For each \(e_{1}\in E_{1}\) and \(A\in\mathcal{E}_{2}\), we let \(K_{1}(e_{1},A)\) be the conditional measure of \(\mathbb{P}\) given \(e_{1}\), i.e. Gaussian with mean \(\frac{1200-e_{1}}{20}\) and variance \(\frac{1}{4}\). This represents the fact that, if we intervene by fixing the altitude of a location, then the temperature of that location will be causally affected. However, if we intervene by fixing a temperature of a location, say by manually heating up or cooling down a place, then we expect that this has no causal effect on the altitude of the place. This can be represented by the causal kernel \(K_{2}(e_{2},B)=\mathbb{P}(B)\) for each \(B\in\mathcal{E}_{1}\), i.e. Gaussian measure with mean \(1000\) and variance \(300\), regardless of the value of \(e_{2}\). The corresponding "causal graph" would be Figure 2. If we intervene on \(\mathcal{E}_{1}\) with measure \(\delta_{1000}\), i.e. we fix the altitude at \(1000\)m, then the intervention measure \(\mathbb{P}^{\mathrm{do}(1,\delta_{1000})}\) on \((E_{2},\mathcal{E}_{2})\) would be Gaussian with mean \(10\) and variance \(\frac{1}{4}\). If we intervene on \(\mathcal{E}_{2}\) with any measure \(\mathbb{Q}\), the intervention measure \(\mathbb{P}^{\mathrm{do}(2,\mathbb{Q})}\) on \((E_{1},\mathcal{E}_{1})\) would still be Gaussian with mean \(1000\) and variance \(300\)._

The following theorem proves that the intervention measure and causal mechanism are indeed valid.

**Theorem 2.6**.: _From Definition 2.3, \(\mathbb{P}^{\mathrm{do}(U,\mathbb{Q})}\) is indeed a measure on \((\Omega,\mathcal{H})\), and \(\mathbb{K}^{\mathrm{do}(U,\mathbb{Q},\mathbb{L})}\) is indeed a valid causal mechanism on \((\Omega,\mathcal{H},\mathbb{P}^{\mathrm{do}(U,\mathbb{Q})})\), i.e. they satisfy the axioms of Definition 2.2._

To end this section, we make a couple of further remarks on the definition of causal spaces.

**Remark 2.7**.:
1. We require causal spaces to be built on top of product probability spaces, as opposed to general probability spaces, and causal kernels are defined on sub-\(\sigma\)-algebras of \(\mathcal{H}\) of the form \(\mathcal{H}_{\mathcal{S}}\) for \(S\in\mathcal{P}(T)\), as opposed to general sub-\(\sigma\)-algebras of \(\mathcal{H}\). This is because, for two events that are not in separate components of a product space, one can always intervene on one of those events in such a way that the measure on the other event will have to change, meaning the causal kernel cannot be decoupled from the intervention itself. For example, in a dice-roll with outcomes \(\{1,2,3,4,5,6\}\) each with probability \(\frac{1}{6}\), if we intervene to give measure \(1\) to roll \(6\), then the other outcomes are forced to have measure \(0\). Only if we consider separate components of product measurable spaces can we set meaningful causal relationships that are decoupled from the act of intervention itself.
2. We do not distinguish between interventions that are practically possible and those that are not. For example, the "causal effect of sunlight on the moon's temperature" cannot be measured realistically, as it would require covering up the sun, but the information encoded in the causal kernel would still correspond to what would happen when we cover up the sun.

## 3 Comparison with Existing Frameworks

In this section, we show how causal spaces can encode the interventional aspects of the two most widely-used frameworks of causality, i.e. structural causal models and the potential outcomes.

### Structural Causal Models (SCMs)

Consider an SCM in its most basic form, given in the following definition.

**Definition 3.1** ([46, p.83, Definition 6.2]).: A structural causal model \(\mathfrak{C}=(\mathbf{S},\tilde{\mathbb{P}})\) consists of a collection \(\mathbf{S}\) of \(d\) (structural) assignments \(X_{j}:=f_{j}(\mathbf{PA}_{j},N_{j}),j=1,...,d\), where \(\mathbf{PA}_{j}\subseteq\{X_{1},...,X_{d}\}\backslash\{X_{j}\}\) are called the _parents of_\(X_{j}\) and \(N_{j}\) are the _noise_ variables; and a distribution \(\mathbb{P}\) over the noise variables such that they are jointly independent.

The graph \(\mathcal{G}\) of an SCM is obtained by creating one vertex for each \(X_{j}\) and drawing directed edges from each parent in \(\mathbf{PA}_{j}\) to \(X_{j}\). This graph is assumed to be acyclic.

Below, we show that a unique causal space that corresponds to such an SCM can be constructed.

Figure 2: Altitude and Temperature.

First, we let the variables \(X_{j},j=1,...,d\) take values in measurable spaces \((E_{j},\mathcal{E}_{j})\) respectively, and let \((\Omega,\mathcal{H})=\otimes_{j=1}^{d}(E_{j},\mathcal{E}_{j})\). An SCM \(\mathfrak{C}\) entails a unique distribution \(\mathbb{P}\) over the variables \(\mathbf{X}=(X_{1},...,X_{d})\) by the propagation of the noise distribution \(\tilde{\mathbb{P}}\) through the structural equations \(f_{j}\)[46, p.84, Proposition 6.3], and we take this \(\mathbb{P}\) as the observational measure of the causal space. More precisely, assuming \(\{1,...,d\}\) is a topological ordering, we have, for \(A_{j}\in\mathcal{E}_{j},j=1,...,d\),

\[\mathbb{P}(A_{1}\times E_{2}\times...\times E_{d})=\tilde{\mathbb{ P}}(\{n_{1}:f_{1}(n_{1})\in A_{1}\})\] \[\mathbb{P}(A_{1}\times A_{2}\times E_{3}\times...\times E_{d})= \tilde{\mathbb{P}}(\{(n_{1},n_{2}):(f_{1}(n_{1}),f_{2}(f_{1}(n_{1}),n_{2})) \in A_{1}\times A_{2}\})\] \[\qquad\vdots\] \[\mathbb{P}(A_{1}\times...\times A_{d})=\tilde{\mathbb{P}}(\{(n_{ 1},...,n_{d}):(f_{1}(n_{1}),...,f_{d}(f_{1}(n_{1}),...,n_{d}))\in A_{1}\times...\times A_{d}\}).\]

Finally, for each \(S\in\mathcal{P}(\{1,...,d\})\) and for each \(\omega\in\Omega\), define \(f_{j}^{S,\omega}=f_{j}\) if \(j\notin S\) and \(f_{j}^{S,\omega}=\omega_{j}\) if \(j\in S\). Then we have

\[K_{S}(\omega,A_{1}\times...\times A_{d})=\tilde{\mathbb{P}}(\{(n_{1},...,n_{d }):(f_{1}^{S,\omega}(n_{1}),...,f_{d}^{S,\omega}(f_{1}^{S,\omega}(n_{1}),...,n _{d}))\in A_{1}\times...\times A_{d}\}).\]

This uniquely specifies the causal space \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})\) that corresponds to the SCM \(\mathfrak{C}\). While this shows that causal spaces strictly generalise (interventional aspects of) SCMs, there are fundamental philosophical differences between the two approaches, as highlighted in the following remark.

**Remark 3.2**.:
1. The "system" in an SCM can be viewed as the collection of all variables \(X_{1},...,X_{d}\), and the "subsystems" the individual variables or the groups of variables. Each _structural equation_\(f_{j}\) encodes how the whole system, when intervened on, affects a subsystem \(X_{j}\), i.e. how the collection of all other variables affects the individual variables (even though, in the end, the equations only depend on the parents). This way of encoding causal effects seems somewhat inconsistent with the philosophy laid out in the Introduction, that we are interested in what happens to the "system" when we intervene on a "subsystem". It also seems inconsistent with the actual action taken, which is to intervene on subsystems, not the whole system, or the parents of a particular variable. In contrast, the causal kernels encode exactly what happens to the whole system, i.e. what measure we get on the whole measurable space \((\Omega,\mathcal{H})\), when we intervene on a "subsystem", i.e. put a desired measure on a sub-\(\sigma\)-algebra of \(\mathcal{H}^{3}\).
2. The primitive objects of SCMs are the variables \(X_{j}\), the structural equations \(f_{j}\) and the distribution \(P_{\mathbf{N}}\) over the noise variables. The observational distribution, as well as the interventional distributions, are derived from these objects. It turns out that unique existence of observational and interventional distributions are not guaranteed, and can only be shown under the acyclicity assumption or rather stringent and hard-to-verify conditions on the structural equations and the noise distributions [10]. Moreover, it means that the observational and interventional distributions are not decoupled, and rather are linked through the structural equations \(f_{j}\), and as a result, it is not possible to encode the full range of observational and interventional distributions using just the variables of interest (see Example 4.1). In contrast, in causal spaces, the observational distribution \(\mathbb{P}\), as well as the interventional distributions (via the causal kernels), are the primitive objects. Not only does this automatically guarantee their unique existence, but it also allows the interventional distributions (i.e. the causal information) to be completely decoupled from the observational distribution.
3. Galles and Pearl [21, Section 3] propose three axioms of counterfactuals based on SCMs (called _causal models_ in that paper), namely, composition, effectiveness and reversibility. Even though these three concepts can be carried over to causal spaces, the mathematics through which they are represented needs to be adapted, since the tools that are used in causal spaces are different from those used in causal models of Galles and Pearl [21]. In particular, we work directly with measures as the primitive objects, whereas Galles and Pearl [21] use the structural equations as the primitive objects, and the probabilities only enter through a measure on the exogenous variables. Thus, the three properties can be phrased in the causal space language as follows:

**Composition**: For \(S,R\subseteq T\), denote by \(\mathbb{Q}^{\prime}\) the measure on \(\mathcal{H}_{S\cup R}\) obtained by restricting \(\mathbb{P}^{\text{do}(S,\mathbb{Q})}\). Then \(\mathbb{P}^{\text{do}(S,\mathbb{Q})}=\mathbb{P}^{\text{do}(S\cup R,\mathbb{Q}^{ \prime})}\). In words, intervening on \(\mathcal{H}_{S}\) via the measure \(\mathbb{Q}\) is the same as intervening on \(\mathcal{H}_{S\cup R}\) via the measure that it would have if we intervened on \(\mathcal{H}_{S}\) via \(\mathbb{Q}\).

This is not in general true. A counterexample can be demonstrated with a simple SCM, where \(X_{1}\), \(X_{2}\) and \(X_{3}\) causally affect \(Y\), in a way that depends not only on the marginal distributions of \(X_{1}\), \(X_{2}\) and \(X_{3}\) but their joint distribution, and \(X_{1}\), \(X_{2}\) and \(X_{3}\) have no causal relationships among them. Then intervening on \(X_{1}\) with some measure \(\mathbb{Q}\) cannot be the same as intervening on \(X_{1}\) and \(X_{2}\) with \(\mathbb{Q}\otimes\mathbb{P}\), since such an intervention would change the joint distribution of \(X_{1}\), \(X_{2}\) and \(X_{3}\), even if we give them the same marginal distributions.
**Effectiveness**: For \(S\subseteq R\subseteq T\), if we intervene on \(\mathcal{H}_{R}\) via a measure \(\mathbb{Q}\), then \(\mathcal{H}_{S}\) has measure \(\mathbb{Q}\) restricted to \(\mathcal{H}_{S}\).

This is indeed guaranteed by interventional determinism (Definition 2.2(ii)), so effectiveness continues to hold in causal spaces.
**Reversibility**: For \(S,R,U\subseteq T\), let \(\mathbb{Q}\) be some measure on \(\mathcal{H}_{S}\), and \(\mathbb{Q}_{1}\) and \(\mathbb{Q}_{2}\) be measures on \(\mathcal{H}_{S\cup R}\) and \(\mathcal{H}_{S\cup U}\) respectively such that they coincide with \(\mathbb{Q}\) when restricted to \(\mathcal{H}_{S}\). Then if \(\mathbb{P}^{\text{do}(S\cup R,\mathbb{Q}_{1})}(B)=\mathbb{Q}_{2}(B)\) for all \(B\in\mathcal{H}_{U}\) and if \(\mathbb{P}^{\text{do}(S\cup U,\mathbb{Q}_{2})}(C)=\mathbb{Q}_{1}(C)\) for all \(C\in\mathcal{H}_{R}\), then \(\mathbb{P}^{\text{do}(S,\mathbb{Q})}(A)=\mathbb{Q}_{1}(A)\) for all \(A\in\mathcal{H}_{R}\).

This does not hold in general in causal spaces; in fact, Example 4.2 is a counterexample of this, with \(S=\emptyset\).

### Potential Outcomes (PO) Framework

In the PO framework, the treatment and outcome variables of interest are fixed in advance. Although much of the literature begins with individual units, these units are in the end i.i.d. copies of random variables under the stable unit treatment value assumption (SUTVA), and that is how we begin.

Denote by \((\tilde{\Omega},\tilde{\mathcal{H}},\tilde{\mathbb{P}})\) the underlying probability space. Let \(Z:\tilde{\Omega}\to\mathcal{Z}\) be the "treatment" variable, taking values in a measurable space \((\mathcal{Z},\mathfrak{Z})\). Then for each value \(z\) of the treatment, there is a separate random variable \(Y_{z}:\tilde{\Omega}\to\mathcal{Y}\), called the "potential outcome given \(Z=z\)" taking values in a measurable space \((\mathcal{Y},\mathfrak{Y})\); we also have the "observed outcome", which is the potential outcome consistent with the treatment, i.e. \(Y=Y_{Z}\). The researcher is interested in quantities such as the "average treatment effect", \(\tilde{\mathbb{E}}[Y_{z_{1}}-Y_{z_{2}}]\), where \(\tilde{\mathbb{E}}\) is the expectation with respect to \(\tilde{\mathbb{P}}\), to measure the causal effect of the treatment. Often, there are other, "pre-treatment variables" or "covariates", which we denote by \(X:\tilde{\Omega}\to\mathcal{X}\), taking values in a measurable space \((\mathcal{X},\mathfrak{X})\). Given these, another object of interest is the "conditional average treatment effect", defined as \(\tilde{\mathbb{E}}[Y_{z_{1}}-Y_{z_{2}}\mid X]\).

It is relatively straightforward to construct a causal space that can carry this framework. We define \(\Omega=\mathcal{Z}\times\mathcal{Y}\times\mathcal{X}\) and \(\mathcal{H}=\mathfrak{Z}\otimes\mathfrak{Z})\otimes\mathfrak{X}\). We also define \(\mathbb{P}\), for each \(A\in\mathfrak{Z}\), \(B\in\mathfrak{Y}\) and \(C\in\mathfrak{X}\), as \(\mathbb{P}(A\times B\times C)=\tilde{\mathbb{P}}(Z\in A,Y\in B,X\in C)\). As for causal kernels, we are essentially only interested in \(K_{Z}(z,B)\) for \(B\in\mathfrak{Y}\), and we define these to be \(K_{Z}(z,B)=\tilde{\mathbb{P}}(Y_{z}\in B)\).

## 4 Examples

In this section, we give a few more concrete constructions of causal spaces. In particular they are designed to highlight cases which are hard to represent with existing frameworks, but which have natural representations in terms of causal spaces. Comparisons are made particularly with SCMs.

### Confounders

The following example highlights the fact that, with graphical models, there is no way to encode correlation but no causation between two variables, using just the variables of interest.

**Example 4.1**.: _Consider the popular example of monthly ice cream sales and shark attacks in the US (Figure 2(a)), that shows that correlation does not imply causation. This cannot be encoded by an SCM with just two variables as in Figure 2(b), since no causation means no arrows between the variables, which in turn also means no dependence. One needs to add the common causes into themodel (whether observed or latent), the most obvious one being the temperature (high temperatures make people desire ice cream more, as well as to go to the beach more), as seen in Figure 2(c). Now we have a model in which both dependence and no causation are captured. But can we stop here? There are probably other factors that affect both variables, such as the economy (the better the economic situation, the more likely people are to buy ice cream, and to take beach holidays) - see Figure 2(d). Not only is the model starting to lose parsimony, but as soon as we stop adding variables to the model, we are making an assumption that there are no further confounding variables out there in the world4._

Footnote 4: One solution could be to add a single “variable” that collects all of the confounders into one, but then the numerical value of this “variable”, as well as its distribution and the structural equations from this “variable” into S and I, would be completely meaningless.

_In contrast, causal spaces allow us to model any observational and causal relationships with just the variables that we were interested in, without any restrictions or the need to add more variables. In this particular example, we would take as our causal space \((E_{1}\times E_{2},\mathcal{E}_{1}\otimes\mathcal{E}_{2},\mathbb{P},\mathbb{K})\), where \(E_{1}=E_{2}=\mathbb{R}\) with values in \(E_{1}\) and \(E_{2}\) corresponding to ice cream sales and shark attacks respectively, and \(\mathcal{E}_{1}=\mathcal{E}_{2}\) being Lebesgue \(\sigma\)-algebras. Then we can let \(\mathbb{P}\) be a measure that has a strong dependence between any \(A\in\mathcal{E}_{1}\) and \(B\in\mathcal{E}_{2}\), but let the causal kernels be \(K_{1}(x,B)=\mathbb{P}(B)\) for any \(x\in E_{1}\) and \(B\in\mathcal{E}_{2}\), and likewise \(K_{2}(x,A)=\mathbb{P}(A)\) for any \(x\in E_{2}\) and \(A\in\mathcal{E}_{1}\)._

Nancy Cartwright argued against the completeness of causal Markov condition, using an example of two factories [13, p.108], in which there may not even be any confounders between dependent variables, not even an unobserved one. If we accept her position, then there are situations which SCMs would not be able to represent, whereas causal spaces would have no problems at all.

### Cycles

As mentioned before, cycles in SCMs cause serious problems, namely that observational and interventional distributions that are consistent with the given structural equations and noise distribution may not exist, and when they do, they may not exist uniquely. This is an artefact of the fact that these distributions are derived from the structural equations rather than taken as the primitive objects. In the vast majority of the cases, cycles are excluded from consideration from the beginning and only directed acyclic graphs (DAGs) are considered. Some works study the _solvability_ of cyclic SCMs [23, 10], where the authors investigate under what conditions on the structural equations and the noise variables there exist random variables and distributions that _solve_ the given structural equations, and if so, when that happens _uniquely_. Other works have allowed cycles to exist, but restricted the definition of an SCM only to those that have a unique solution [23, 43, 49].

Of course, cyclic causal relationships abound in the real world. In our proposed causal space (Definition 2.2), given two sub-\(\sigma\)-algebras \(\mathcal{H}_{S}\) and \(\mathcal{H}_{U}\) of \(\mathcal{H}\), nothing stops both of them from having a causal effect on the other (see Definition B.1 for a precise definition of causal effects), but we are still guaranteed to have a unique causal space, both before intervention and after intervention on either \(\mathcal{H}_{S}\) or \(\mathcal{H}_{U}\). The following is an example of a situation with "cyclic" causal relationship.

**Example 4.2**.: _We want to model the relationship between the amount of rice in the market and its price per kg. Take as the probability space \((E_{1}\times E_{2},\mathcal{E}_{1}\otimes\mathcal{E}_{2},\mathbb{P})\), where \(E_{1}=E_{2}=\mathbb{R}\) with values in \(E_{1}\) and \(E_{2}\) representing the amount of rice in the market in million tonnes and the price

Figure 3: Correlation but no causation between ice-cream sales and shark attacks. S stands for the number of shark attacks, I for ice cream sales, T for temperature and E for economy.

of rice per kg in KRW respectively, \(\mathcal{E}_{1},\mathcal{E}_{2}\) are Lebesgue \(\sigma\)-algebras and \(\mathbb{P}\) is for simplicity taken to be jointly Gaussian. Without any intervention, the higher the yield, the more rice there is in the market and lower the price, as in Figure 3(b). If the government intervenes on the market by buying up extra rice or releasing rice into the market from its stock, with the goal of stabilising supply at 3 million tonnes, then the price will stabilise accordingly, say with Gaussian distribution with mean 4.5 and standard deviation 0.5, as in Figure 3(c). The corresponding causal kernel will be \(K_{1}(3,x)=\frac{2}{\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-4.5}{0.5})^{2}}\). On the other hand, if the government fixes the price of rice at a price, say at 6,000 KRW per kg, then the farmers will be incentivised to produce more, say with Gaussian distribution with mean 4 and standard deviation 0.5, as in Figure 3(d). The corresponding causal kernel will be \(K_{2}(6,y)=\frac{2}{\sqrt{2\pi}}e^{-\frac{1}{2}(\frac{y-4}{0.5})^{2}}\)._

Causal spaces treat causal effects really as what happens after an intervention takes place, and with this approach, cycles can be rather naturally encoded, as shown above. We do not view cyclic causal relationships as an equilibrium of a dynamical system, or require it to be viewed as an acyclic stochastic process, as done by some authors [46, p.85, Remark 6.5].

### Continuous-time Stochastic Processes, and Parents

A very well established sub-field of probability theory is the field of stochastic processes, in which the index set representing (most often) time can be either discrete or continuous, and in both cases, infinite. However, most causal models start by assuming a finite number of variables, which immediately rules out considering stochastic processes, and efforts to extend to infinite number of variables usually consider only discrete time steps [46, Chapter 10] or dynamical systems [9, 47, 8, 50]. Since probability spaces have proven to accommodate continuous time stochastic processes in a natural way, it is natural to believe that causal spaces, being built up from probability spaces, should be able to enable the incorporation of the concept of causality in the theory of stochastic processes.

Let \(W\) be a totally-ordered set, in particular \(W=\mathbb{N}=\{0,1,...\}\), \(W=\mathbb{Z}=\{...,-2,-1,0,1,2,...\}\), \(W=\mathbb{R}_{+}=[0,\infty)\) or \(W=\mathbb{R}=(-\infty,\infty)\) considered as the time set. Then, we consider causal spaces of the form \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\), where the index set \(T\) can be written as \(T=W\times\tilde{T}\) for some other index set \(\tilde{T}\). The following notion captures the intuition that causation can only go forwards in time.

**Definition 4.3**.: Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, where the index set \(T\) can be written as \(T=W\times\tilde{T}\), with \(W\) representing time. Then we say that the causal mechanism \(\mathbb{K}\)_respects time_, or that \(\mathbb{K}\) is a _time-respecting causal mechanism_, if, for all \(w_{1},w_{2}\in W\) with \(w_{1}<w_{2}\), we have that \(\mathcal{H}_{w_{2}\times\tilde{T}}\) has no causal effect (in the sense of Definition B.1) on \(\mathcal{H}_{w_{1}\times\tilde{T}}\).

In a causal space where the index set \(T\) has a time component, the fact that causal mechanism \(\mathbb{K}\) respects time means that the past can affect the future, but the future cannot affect the past. This already distinguishes itself from the concept of conditioning - conditioning on the future does have implications for past events. We illustrate this point in the example of a Brownian motion.

**Example 4.4**.: _We consider a 1-dimensional Brownian motion. Take \((\times_{t\in\mathbb{R}_{+}}E_{t},\otimes_{t\in\mathbb{R}_{+}}\mathcal{E}_{t },\mathbb{P},\mathbb{K})\), where, for each \(t\in\mathbb{R}_{+}\), \(E_{t}=\mathbb{R}\) and \(\mathcal{E}_{t}\) is the Lebesgue \(\sigma\)-algebra, and \(\mathbb{P}\) is the Wiener measure. For \(s<t\), we have causal kernels \(K_{s}(x,y)=\frac{1}{\sqrt{2\pi(t-s)}}e^{-\frac{1}{2(\overline{t-s})}(y-x)^{2}}\) and \(K_{t}(x,y)=\frac{1}{\sqrt{2\pi s}}e^{-\frac{1}{2s}y^{2}}\)._

_The former says that, if we intervene by setting the value of the process to \(x\) at time \(s\), then the process starts again from \(x\), whereas the latter says that if we intervene at time \(t\), the past values at time \(s\) are not affected. On the left-hand plot of Figure 5, we set the value of the process at time \(1\) to \(0\). The past values of the process are not affected, and there is a discontinuity at time \(1\) where the process starts

Figure 4: Rice in the market in million tonnes and price per kg in KRW.

again from \(0\). Contrast this to the right-hand plot, where we condition on the process having value \(0\) at time \(1\). This does affect past values, and creates a Brownian bridge from time \(0\) to time \(1\)._

_Note, Brownian motion is not differentiable, so no approach based on dynamical systems is applicable._

**Remark 4.5**.: The concept of _parents_ is central in SCMs - the structural equations are defined on the parents of each variable. However, continuous time is dense, so given two distinct points in time, there is always a time point in between. Suppose we have a one-dimensional continuous time Markov process \((X_{t})_{t\in\mathbb{R}}\)[14, p.169], and a point \(t_{0}\) in time. Then for any \(t<t_{0}\), \(X_{t}\) has a causal effect on \(X_{t_{0}}\), but there always exists some \(t^{\prime}\) with \(t<t^{\prime}<t_{0}\) such that conditioned on \(X_{t^{\prime}}\), \(X_{t}\) does not have a causal effect on \(X_{t_{0}}\), meaning \(X_{t}\) cannot be a parent of \(X_{t_{0}}\). In such a case, \(X_{t_{0}}\) cannot be said to have any parents, and hence no corresponding SCM can be defined.

## 5 Conclusion

In this work, we discussed the lack of a universally agreed axiomatisation of causality, and some arguments as to why measure-theoretic probability theory can provide a good foundation on which to build such an axiomatisation. We proposed _causal spaces_, by enriching probability spaces with causal kernels that encode information about what happens after an intervention. We showed how the interventional aspects of existing frameworks can be captured by causal spaces, and finally we gave some explicit constructions, highlighting cases in which existing frameworks fall short.

Even if causal spaces prove with time to be the correct approach to axiomatise causality, there is much work to be done - in fact, all the more so in that case. Most conspicuously, we only discussed the _interventional_ aspects of the theory of causality, but the notion of _counterfactuals_ is also seen as a key part of the theory, both _interventional counterfactuals_ as advocated by Pearl's ladder of causation [44, Figure 1.2] and _backtracking counterfactuals_[58]. We provide some discussions and possible first steps towards this goal in Appendix E, but mostly leave it as essential future work. Only then will we be able to provide a full comparison with the counterfactual aspects of SCMs and the potential outcomes. As discussed in Section 1, the notion of _actual causality_ is also important, and it would be interesting to investigate how this notion can be embedded into causal spaces. Many important definitions, including causal effects, conditional causal effects, hard interventions and sources, as well as technical results, were deferred to the appendix purely due to space constraints, but we foresee that there would be many more interesting results to be proved, inspired both from theory and practice. In particular, the theory of _causal abstraction_[49, 2, 3] should benefit from our proposal, through extensions of homomorphisms of probability spaces to causal spaces5.

Footnote 5: In a similar vein, Keurti et al. [37] consider homomorphisms between groups of interventions.

As a final note, we stress again that our goal should _not_ be understood as replacing existing frameworks. Indeed, causal spaces cannot compete in terms of interpretability, and in the vast majority of situations in which SCMs, potential outcomes or any of the other existing frameworks are suitable, we expect them to be much more useful. In particular, assumptions are unavoidable for identifiability from observational data, and those assumptions are much better captured by existing frameworks6, However, just as measure-theoretic probability theory has its value despite not being useful for practitioners in applied statistics, we believe that it is a worthy endeavour to formally axiomatise causality.

Figure 5: 1-dimensional Brownian motion, intervened and conditioned to have value \(0\) at time \(1\).

## Acknowledgments and Disclosure of Funding

We express our sincere gratitude to Robin Evans at the University of Oxford, Michel de Lara at Ecole des Ponts ParisTech and Wojciech Niemiro at the University of Warsaw for fruitful discussions and providing valuable feedback on earlier drafts. We also thank anonymous reviewers for their suggestions for improvements.

This work was supported by the Tubingen AI Center.

## References

* [1] S. Beckers. Causal Sufficiency and Actual Causation. _Journal of Philosophical Logic_, 50(6):1341-1374, 2021.
* [2] S. Beckers and J. Y. Halpern. Abstracting Causal Models. In _Proceedings of the aaai conference on artificial intelligence_, volume 33, pages 2678-2685, 2019.
* [3] S. Beckers, F. Eberhardt, and J. Y. Halpern. Approximate Causal Abstractions. In _Uncertainty in Artificial Intelligence_, pages 606-615. PMLR, 2020.
* [4] S. Beckers, H. Chockler, and J. Halpern. A Causal Analysis of Harm. _Advances in Neural Information Processing Systems_, 35:2365-2376, 2022.
* [5] S. Beckers, H. Chockler, and J. Y. Halpern. Quantifying Harm. In _Proceedings of the 32nd International Joint Conference on Artificial Intelligence (IJCAI 2023)_, 2023.
* [6] H. Beebee, C. Hitchcock, and P. Menzies. _The Oxford Handbook of Causation_. Oxford University Press, 2009.
* [7] G. Biradar, V. Viswanathan, and Y. Zick. Model Explanations via the Axiomatic Causal Lens. _arXiv preprint arXiv:2109.03890_, 2021.
* [8] T. Blom, S. Bongers, and J. M. Mooij. Beyond Structural Causal Models: Causal Constraints Models. In _Uncertainty in Artificial Intelligence_, pages 585-594. PMLR, 2020.
* [9] S. Bongers, T. Blom, and J. M. Mooij. Causal Modeling of Dynamical Systems. _arXiv preprint arXiv:1803.08784_, 2018.
* [10] S. Bongers, P. Forre, J. Peters, and J. M. Mooij. Foundations of Structural Causal Models with Cycles and Latent Variables. _The Annals of Statistics_, 49(5):2885-2915, 2021.
* [11] J. Brehmer, P. De Haan, P. Lippe, and T. S. Cohen. Weakly Supervised Causal Representation Learning. _Advances in Neural Information Processing Systems_, 35:38319-38331, 2022.
* [12] I. Cabreros and J. D. Storey. Causal Models on Probability Spaces. _arXiv preprint arXiv:1907.01672_, 2019.
* [13] N. Cartwright. _The Dampled World: A Study of the Boundaries of Science_. Cambridge University Press, 1999.
* [14] E. Cinlar. _Probability and Stochastics_, volume 261. Springer Science & Business Media, 2011.
* [15] T. Cohen. Towards a Grounded Theory of Causation for Embodied AI. In _UAI 2022 Workshop on Causal Representation Learning_, 2022.
* [16] J. Collins, N. Hall, and L. A. Paul. _Causation and Counterfactuals_. The MIT Press, 2004.
* [17] P. Dawid. Decision-Theoretic Foundations for Statistical Causality. _Journal of Causal Inference_, 9(1):39-77, 2021.
* [18] H. B. Enderton. _Elements of Set Theory_. Academic press, 1977.
* [19] A. Feder, K. A. Keith, E. Manzoor, R. Pryzant, D. Sridhar, Z. Wood-Doughty, J. Eisenstein, J. Grimmer, R. Reichart, M. E. Roberts, et al. Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond. _Transactions of the Association for Computational Linguistics_, 10:1138-1158, 2022.

* [20] T. Fritz, T. Gonda, N. G. Houghton-Larsen, P. Perrone, and D. Stein. Dilations and Information Flow Axioms in Categorical Probability. _arXiv preprint arXiv:2211.02507_, 2022.
* [21] D. Galles and J. Pearl. An Axiomatic Characterization of Causal Counterfactuals. _Foundations of Science_, 3(1):151-182, 1998.
* [22] J. Halpern. A Modification of the Halpern-Pearl Definition of Causality. In _Twenty-Fourth International Joint Conference on Artificial Intelligence_, 2015.
* [23] J. Y. Halpern. Axiomatizing Causal Reasoning. _Journal of Artificial Intelligence Research_, 12:317-337, 2000.
* [24] J. Y. Halpern. _Actual Causality_. MIT Press, 2016.
* [25] J. Y. Halpern and J. Pearl. Causes and Explanations: A Structural-Model Approach. Part I: Causes. _British Journal for the Philosophy of Science_, 56(4):843-843, 2005.
* [26] M. Hernan and J. Robins. _Causal Inference: What If_. Boca Raton: Chapman & Hall/CRC, 2020.
* [27] B. Heymann, M. De Lara, and J.-P. Chancelier. Causal inference theory with information dependency models. _arXiv preprint arXiv:2108.03099_, 2021.
* [28] D. Ibeling and T. Icard. Probabilistic Reasoning Across the Causal Hierarchy. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 34, pages 10170-10177, 2020.
* [29] P. M. Illari, F. Russo, and J. Williamson. _Causality in the Sciences_. Oxford University Press, 2011.
* [30] G. Imbens. Potential Outcome and Directed Acyclic Graph Approaches to Causality: Relevance for Empirical Practice in Economics. Technical report, National Bureau of Economic Research, 2019.
* [31] G. W. Imbens and D. B. Rubin. _Causal Inference in Statistics, Social, and Biomedical sciences_. Cambridge University Press, 2015.
* [32] B. Jacobs, A. Kissinger, and F. Zanasi. Causal Inference by String Diagram Surgery. In _Foundations of Software Science and Computation Structures: 22nd International Conference, FOSSACS 2019, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2019, Prague, Czech Republic, April 6-11, 2019, Proceedings 22_, pages 313-329. Springer, 2019.
* [33] D. Janzing and B. Scholkopf. Causal Inference Using the Algorithmic Markov Condition. _IEEE Transactions on Information Theory_, 56(10):5168-5194, 2010.
* [34] E. T. Jaynes. _Probability Theory: The Logic of Science_. Cambridge university press, 2003.
* [35] Z. Jin, A. Feder, and K. Zhang. CausalNLP Tutorial: An Introduction to Causality for Natural Language Processing. In _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts_, pages 17-22, 2022.
* [36] A.-H. Karimi, G. Barthe, B. Scholkopf, and I. Valera. A Survey of Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations. _ACM Computing Surveys_, 55(5):1-29, 2022.
* Learning Group Structured Representations from Observed Transitions. In _International Conference on Machine Learning_, pages 16190-16215. PMLR, 2023.
* [38] A. N. Kolmogorov. Foundations of the Theory of Probability. _NY: Chelsea Publishing Co_, 1933.
* [39] D. Lewis. _Counterfactuals_. John Wiley & Sons, 2013.

* [40] F. Locatello, S. Bauer, M. Lucic, G. Raetsch, S. Gelly, B. Scholkopf, and O. Bachem. Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations. In _international conference on machine learning_, pages 4114-4124. PMLR, 2019.
* [41] J. Mitrovic, B. McWilliams, J. C. Walker, L. H. Buesing, and C. Blundell. Representation learning via invariant causal mechanisms. In _International Conference on Learning Representations_, 2020.
* [42] P. A. Ortega. Subjectivity, bayesianism, and causality. _Pattern Recognition Letters_, 64:63-70, 2015.
* [43] J. Pearl. _Causality_. Cambridge university press, 2009.
* [44] J. Pearl and D. Mackenzie. _The Book of Why_. Basic Books, New York, 2018.
* [45] J. Pearl, M. Glymour, and N. P. Jewell. _Causal Inference in Statistics: A Primer_. John Wiley & Sons, 2016.
* [46] J. Peters, D. Janzing, and B. Scholkopf. _Elements of Causal Inference_. The MIT Press, 2017.
* [47] J. Peters, S. Bauer, and N. Pfister. Causal Models for Dynamical Systems. In _Probabilistic and Causal Inference: The Works of Judea Pearl_, pages 671-690. ACM, 2022.
* [48] S. Peters and J. Y. Halpern. Causal Modeling with Infinitely Many Variables. _arXiv preprint arXiv:2112.09171_, 2021.
* [49] P. Rubenstein, S. Weichwald, S. Bongers, J. Mooij, D. Janzing, M. Grosse-Wentrup, and B. Scholkopf. Causal Consistency of Structural Equation Models. In _33rd Conference on Uncertainty in Artificial Intelligence (UAI 2017)_, pages 808-817. Curran Associates, Inc., 2017.
* [50] P. K. Rubenstein, S. Bongers, B. Scholkopf, and J. M. Mooij. From Deterministic ODEs to Dynamic Structural Causal Models. In _34th Conference on Uncertainty in Artificial Intelligence (UAI 2018)_, 2018.
* [51] F. Russo. _Causality and Causal Modelling in the Social Sciences_. Springer, 2010.
* [52] P. Schenone. Causality: A Decision Theoretic Foundation. _arXiv preprint arXiv:1812.07414_, 2018.
* [53] B. Scholkopf. Causality for Machine Learning. In _Probabilistic and Causal Inference: The Works of Judea Pearl_, pages 765-804. ACM, 2022.
* [54] B. Scholkopf and J. von Kugelgen. From Statistical to Causal Learning. _arXiv preprint arXiv:2204.00607_, 2022.
* [55] B. Scholkopf, F. Locatello, S. Bauer, N. R. Ke, N. Kalchbrenner, A. Goyal, and Y. Bengio. Toward Causal Representation Learning. _Proceedings of the IEEE_, 109(5):612-634, 2021.
* [56] P. Spirtes, C. N. Glymour, R. Scheines, and D. Heckerman. _Causation, Prediction, and Search_. MIT press, 2000.
* [57] J. Von Kugelgen, Y. Sharma, L. Gresele, W. Brendel, B. Scholkopf, M. Besserve, and F. Locatello. Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style. _Advances in neural information processing systems_, 34:16451-16467, 2021.
* [58] J. Von Kugelgen, A. Mohamed, and S. Beckers. Backtracking Counterfactuals. In _Conference on Causal Learning and Reasoning_, pages 177-196. PMLR, 2023.
* [59] V. Vovk and G. Shafer. Game-Theoretic Probability. _Introduction to Imprecise Probabilities_, pages 114-134, 2014.
* [60] M. Waldmann. _The Oxford Handbook of Causal Reasoning_. Oxford University Press, 2017.
* [61] P. Walley. _Statistical Reasoning with Imprecise Probabilities_, volume 42. Springer, 1991.

* [62] Y. Wang and M. I. Jordan. Desiderata for Representation Learning: A Causal Perspective. _arXiv preprint arXiv:2109.03795_, 2021.
* [63] H. White and K. Chalak. Settable Systems: An Extension of Pearl's Causal Model with Optimization, Equilibrium, and Learning. _Journal of Machine Learning Research_, 10(8), 2009.
* [64] J. Woodward. _Making Things Happen: A Theory of Causal Explanation_. Oxford university press, 2005.

Mathematical Preliminaries

In this section, we recall some basic facts about measure and probability theory that we need for the development in the main body of the paper. We follow Cinlar [14].

### Measure Theory

Suppose that \(E\) is a set. We first define the notion of a \(\sigma\)-algebra. A non-empty collection \(\mathcal{E}\) of \(E\) is called a _\(\sigma\)-algebra_ on \(E\) if it is closed under complements and countable unions, that is, if

* \(A\in\mathcal{E}\implies E\backslash A\in\mathcal{E}\);
* \(A_{1},A_{2},...\in\mathcal{E}\implies\cup_{n=1}^{\infty}A_{n}\in\mathcal{E}\)

[14, p.2]. We call \(\{\emptyset,E\}\) the _trivial \(\sigma\)-algebra_ of \(E\). If \(\mathcal{C}\) is an arbitrary collection of subsets of \(E\), then the smallest \(\sigma\)-algebra that contains \(\mathcal{C}\), or equivalently, the intersection of all \(\sigma\)-algebras that contain \(\mathcal{C}\), is called the _\(\sigma\)-algebra generated by \(\mathcal{C}\)_, and is denoted \(\sigma\mathcal{C}\).

A _measurable space_ is a pair \((E,\mathcal{E})\), where \(E\) is a set and \(\mathcal{E}\) is a \(\sigma\)-algebra on \(E\)[14, p.4].

Suppose \((E,\mathcal{E})\) and \((F,\mathcal{F})\) are measurable spaces. For \(A\in\mathcal{E}\) and \(B\in\mathcal{F}\), we define the _measurable rectangle_\(A\times B\) as the set of all pairs \((x,y)\) with \(x\in A\) and \(y\in B\). We define the _product \(\sigma\)-algebra_\(\mathcal{E}\otimes\mathcal{F}\) on \(E\times F\) as the \(\sigma\)-algebra generated by the collection of all measurable rectangles. The measurable space \((E\times F,\mathcal{E}\otimes\mathcal{F})\) is the _product_ of \((E,\mathcal{E})\) and \((F,\mathcal{F})\)[14, p.4]. More generally, if \((E_{1},\mathcal{E}_{1}),...,(E_{n},\mathcal{E}_{n})\) are measurable spaces, their product is

\[\bigotimes_{i=1}^{n}(E_{i},\mathcal{E}_{i})=(\bigtimes_{i=1}^{n}E_{i},\bigotimes _{i=1}^{n}\mathcal{E}_{i}),\]

where \(E_{1}\times...\times E_{n}\) is the set of all \(n\)-tuples \((x_{1},...,x_{n})\) with \(x_{i}\) in \(E_{i}\) for \(i=1,...,n\) and \(\mathcal{E}_{1}\otimes...\otimes\mathcal{E}_{n}\) is the \(\sigma\)-algebra generated by the _measurable rectangles_\(A_{1}\times...\times A_{n}\) with \(A_{i}\) in \(\mathcal{E}_{i}\) for \(i=1,...,n\)[14, p.44]. If \(T\) is an arbitrary (countable or uncountable) index set and \((E_{t},\mathcal{E}_{t})\) is a measurable space for each \(t\in T\), the _product space_ of \(\{E_{t}:t\in T\}\) is the set of all collections \((x_{t})_{t\in T}\) with \(x_{t}\in E_{t}\) for each \(t\in T\). A rectangle in \(\bigtimes_{t\in T}E_{t}\) is a subset of the form

\[\bigtimes_{t\in T}A_{t}=\{x=(x_{t})_{t\in T}\in\bigtimes_{t\in T}E_{t}:x_{t} \in A_{t}\text{ for each }t\text{ in }T\}\]

where \(A_{t}\) differs from \(E_{t}\) for only a finite number of \(t\). It is said to be measurable if \(A_{t}\in\mathcal{E}_{t}\) for every \(t\) (for which \(A_{t}\) differs from \(E_{t}\)). The \(\sigma\)-algebra on \(\bigtimes_{t\in T}E_{t}\) generated by the collection of all measurable rectangles is called the _product \(\sigma\)-algebra_ and is denoted by \(\bigotimes_{t\in T}\mathcal{E}_{t}\)[14, p.45].

A collection \(\mathcal{C}\) of subsets of \(E\) is called a p-system if it is closed under intersections [14, p.2]. If two measures \(\mu\) and \(\nu\) on a measurable space \((E,\mathcal{E})\) with \(\mu(E)=\nu(E)<\infty\) agree on a p-system generating \(\mathcal{E}\), then \(\mu\) and \(\nu\) are identical [14, p.16, Proposition 3.7].

Let \((E,\mathcal{E})\) and \((F,\mathcal{F})\) be measurable spaces. A mapping \(f:E\to F\) is _measurable_ if \(f^{-1}B\in\mathcal{E}\) for every \(B\in\mathcal{F}\)[14, p.6].

Let \((E,\mathcal{E})\) and \((F,\mathcal{F})\) be measurable spaces. Let \(f\) be a bijection between \(E\) and \(F\), and let \(\hat{f}\) denote its functional inverse. Then, \(f\) is an _isomorphism_ if \(f\) is measurable relative to \(\mathcal{E}\) and \(\mathcal{F}\), and \(\hat{f}\) is measurable with respect to \(\mathcal{F}\) and \(\mathcal{E}\). The measurable spaces \((E,\mathcal{E})\) and \((F,\mathcal{F})\) are _isomorphic_ if there exists an isomorphism between them [14, p.11].

A measurable space \((E,\mathcal{E})\) is a _standard measurable space_ if it is isomorphic to \((F,\mathcal{B}_{F})\) for some Borel subset \(F\) of \(\mathbb{R}\). Polish spaces with their Borel \(\sigma\)-algebra are standard measurable spaces [14, p.11].

Let \(A\subset E\). Its _indicator_, denoted by \(1_{A}\), is the function defined by

\[1_{A}(x)=\begin{cases}1&\text{if }x\in A\\ 0&\text{if }x\notin A\end{cases}\][14, p.8]. Obviously, \(1_{A}\) is \(\mathcal{E}\)-measurable if and only if \(A\in\mathcal{E}\). A function \(f:E\rightarrow\mathbb{R}\) is said to be _simple_ if it is of the form

\[f=\sum_{i=1}^{n}a_{i}1_{A_{i}}\]

for some \(n\in\mathbb{N}\), \(a_{1},...,a_{n}\in\mathbb{R}\) and \(A_{1},...,A_{n}\in\mathcal{E}\)[14, p.8]. The \(A_{1},...,A_{n}\in\mathcal{E}\) can be chosen to be a measurable partition of \(E\), and is then called the _canonical form_ of the simple function \(f\). A positive function on \(E\) is \(\mathcal{E}\)-measurable if and only if it is the limit of an increasing sequence of positive simple functions [14, p.10, Theorem 2.17].

A _measure_ on a measurable space \((E,\mathcal{E})\) is a mapping \(\mu:\mathcal{E}\rightarrow[0,\infty]\) such that

1. \(\mu(\emptyset)=0\);
2. \(\mu(\cup_{n=1}^{\infty}A_{n})=\sum_{n=1}^{\infty}\mu(A_{n})\) for every disjoint sequence \((A_{n})\) in \(\mathcal{E}\)

[14, p.14]. A _measure space_ is a triplet \((E,\mathcal{E},\mu)\), where \((E,\mathcal{E})\) is a measurable space and \(\mu\) is a measure on it.

A measurable set \(B\) is said to be _negligible_ if \(\mu(B)=0\), and an arbitrary subset of \(E\) is said to be _negligible_ if it is contained in a measurable negligible set. The measure space is said to be _complete_ if every negligible set is measurable [14, p.17].

Next, we review the notion of integration of a real-valued function \(f:E\rightarrow\mathbb{R}\) with respect to \(\mu\)[14, p.20, Definition 4.3].

1. Let \(f:E\rightarrow[0,\infty]\) be simple. If its canonical form is \(f=\sum_{i=1}^{n}a_{i}1_{A_{i}}\) with \(a_{i}\in\mathbb{R}\), then we define \[\int fd\mu=\sum_{i=1}^{n}a_{i}\mu(A_{i}).\]
2. Suppose \(f:E\rightarrow[0,\infty]\) is measurable. Then by above, we have a sequence \((f_{n})\) of positive simple functions such that \(f_{n}\to f\) pointwise. Then we define \[\int fd\mu=\lim_{n\rightarrow\infty}\int f_{n}d\mu,\] where \(\int f_{n}d\mu\) is defined for each \(n\) by (a).
3. Suppose \(f:E\rightarrow[-\infty,\infty]\) is measurable. Then \(f^{+}=\max\{f,0\}\) and \(f^{-}=-\min\{f,0\}\) are measurable and positive, so we can define \(\int f^{+}d\mu\) and \(\int f^{-}d\mu\) as in (b). Then we define \[\int fd\mu=\int f^{+}d\mu-\int f^{-}d\mu\] provided that at least one term on the right be positive. Otherwise, \(\int fd\mu\) is undefined. If \(\int f^{+}d\mu<\infty\) and \(\int f^{-}d\mu<\infty\), then we say that \(f\) is _integrable_.

Finally, we review the notion of _transition kernels_, which are crucial in the consideration of conditional distributions. Let \((E,\mathcal{E})\) and \((F,\mathcal{F})\) be measurable spaces. Let \(K\) be a mapping \(E\times\mathcal{F}\rightarrow[0,\infty]\). Then, \(K\) is called a _transition kernel_ from \((E,\mathcal{E})\) into \((F,\mathcal{F})\) if

1. the mapping \(x\mapsto K(x,B)\) is measurable for every set \(B\in\mathcal{F}\); and
2. the mapping \(B\mapsto K(x,B)\) is a measure on \((F,\mathcal{F})\) for every \(x\in E\).

A transition kernel from \((E,\mathcal{E})\) into \((F,\mathcal{F})\) is called a _probability transition kernel_ if \(K(x,F)=1\) for all \(x\in E\). A probability transition kernel \(K\) from \((E,\mathcal{E})\) into \((E,\mathcal{E})\) is called a _Markov kernel on \((E,\mathcal{E})\)_[14, p.37,39,40].

### Probability Theory

Now we translate the above measure-theoretic notions into the language of probability theory, and introduce some additional concepts. A _probability space_ is a measure space \((\Omega,\mathcal{H},\mathbb{P})\) such that \(\mathbb{P}(\Omega)=1\)[14, p.49]. We call \(\Omega\) the _sample space_, and each element \(\omega\in\Omega\) an _outcome_. We call \(\mathcal{H}\) a collection of _events_, and for any \(A\in\mathcal{H}\), we read \(\mathbb{P}(A)\) as the _probability that the event \(A\) occurs_[14, p.50].

A _random variable_ taking values in a measurable space \((E,\mathcal{E})\) is a function \(X:\Omega\to E\), measurable with respect to \(\mathcal{H}\) and \(\mathcal{E}\). The _distribution_ of \(X\) is the measure \(\mu\) on \((E,\mathcal{E})\) defined by \(\mu(A)=\mathbb{P}(X^{-1}A)\)[14, p.51]. For an arbitrary set \(T\), let \(X_{t}\) be a random variable taking values in \((E,\mathcal{E})\) for each \(t\in T\). Then the collection \(\{X_{t}:t\in T\}\) is called a _stochastic process_ with _state space_\((E,\mathcal{E})\) and _parameter set_\(T\)[14, p.53].

Henceforth, random variables are defined on \((\Omega,\mathcal{H},\mathbb{P})\) and take values in \([-\infty,\infty]\). We define the _expectation_ of a random variable \(X:\Omega\to[-\infty,\infty]\) as \(\mathbb{E}[X]=\int_{\Omega}Xd\mathbb{P}\)[14, p.57-58]. We also define the _conditional expectation_[14, p.140, Definition 1.3]. Suppose \(\mathcal{F}\) is a sub-\(\sigma\)-algebra of \(\mathcal{H}\).

* Suppose \(X\) is a positive random variable. Then the _conditional expectation of \(X\) given \(\mathcal{F}\)_ is any positive random variable \(\mathbb{E}_{\mathcal{F}}X\) satisfying \[\mathbb{E}[VX]=\mathbb{E}\left[V\mathbb{E}_{\mathcal{F}}X\right]\] for all \(V:\Omega\to[0,\infty]\) measurable with respect to \(\mathcal{F}\).
* Suppose \(X:\Omega\to[-\infty,\infty]\) is a random variable. If \(\mathbb{E}[X]\) exists, then we define \[\mathbb{E}_{\mathcal{F}}X=\mathbb{E}_{\mathcal{F}}X^{+}-\mathbb{E}_{\mathcal{ F}}X^{-},\] where \(\mathbb{E}_{\mathcal{F}}X^{+}\) and \(\mathbb{E}_{\mathcal{F}}X^{-}\) are defined in (a).

Next, we define _conditional probabilities_, and regular versions thereof [14, pp.149-151]. Suppose \(H\in\mathcal{H}\), and let \(\mathcal{F}\) be a sub-\(\sigma\)-algebra of \(\mathcal{H}\). Then the _conditional probability_ of \(H\) given \(\mathcal{F}\) is defined as

\[\mathbb{P}_{\mathcal{F}}H=\mathbb{E}_{\mathcal{F}}1_{H}.\]

Let \(Q(H)\) be a version of \(\mathbb{P}_{\mathcal{F}}H\) for every \(H\in\mathcal{H}\). Then \(Q:(\omega,H)\mapsto Q_{\omega}(H)\) is said to be a _regular version_ of the conditional probability \(\mathbb{P}_{\mathcal{F}}\) provided that \(Q\) be a probability transition kernel from \((\Omega,\mathcal{F})\) into \((\Omega,\mathcal{H})\). Regular versions exist if \((\Omega,\mathcal{H})\) is a standard measurable space [14, p.151, Theorem 2.7].

The _conditional distribution_ of a random variable \(X\) given \(\mathcal{F}\) is any transition probability kernel \(L:(\omega,B)\mapsto L_{\omega}(B)\) from \((\Omega,\mathcal{F})\) into \((E,\mathcal{E})\) such that

\[P_{\mathcal{F}}\{Y\in B\}=L(B)\qquad\text{for all $B\in\mathcal{E}$}.\]

If \((E,\mathcal{E})\) is a standard measurable space, then a version of the conditional distribution of \(X\) given \(\mathcal{F}\) exists [14, p.151].

Suppose that \(T\) is a totally ordered set, i.e. whenever \(r,s,t\in T\) with \(r<s\) and \(s<t\), we have \(r<t\) and for any \(s,t\in T\), exactly one of \(s<t,s=t\) and \(t<s\) holds [18, p.62]. For each \(t\in T\), let \(\mathcal{F}_{t}\) be a sub-\(\sigma\)-algebra of \(\mathcal{H}\). The family \(\mathcal{F}=\{\mathcal{F}_{t}:t\in T\}\) is called a _filtration_ provided that \(\mathcal{F}_{s}\subset\mathcal{F}_{t}\) for \(s<t\)[14, p.79]. A _filtered probability space_\((\Omega,\mathcal{H},\mathcal{F},\mathbb{P})\) is a probability space \((\Omega,\mathcal{H},\mathbb{P})\) endowed with a filtration \(\mathcal{F}\).

Finally, we review the notion of _independence_ and _conditional independence_. For a fixed integer \(n\geq 2\), let \(\mathcal{F}_{1},...,\mathcal{F}_{n}\) be sub-\(\sigma\)-algebras of \(\mathcal{H}\). Then \(\{\mathcal{F}_{1},...,\mathcal{F}_{n}\}\) is called an _independency_ if

\[\mathbb{P}\left(H_{1}\cap...\cap H_{n}\right)=\mathbb{P}\left(H_{1}\right)... \mathbb{P}\left(H_{n}\right)\]

for all \(H_{1}\in\mathcal{F}_{1},...,H_{n}\in\mathcal{F}_{n}\). Let \(T\) be an arbitrary index set. Let \(\mathcal{F}_{t}\) be a sub-\(\sigma\)-algebra of \(\mathcal{H}\) for each \(t\in T\). The collection \(\{\mathcal{F}_{t}:t\in T\}\) is called an _independency_ if its every finite subset is an independency [14, p.82].

Moreover, \(\mathcal{F}_{1},...,\mathcal{F}_{n}\) are said to be _conditional independent_ given \(\mathcal{F}\) if

\[\mathbb{P}_{\mathcal{F}}\left(H_{1}\cap...\cap H_{n}\right)=\mathbb{P}_{ \mathcal{F}}\left(H_{1}\right)...\mathbb{P}_{\mathcal{F}}\left(H_{n}\right)\]

for all \(H_{1}\in\mathcal{F}_{1},...,H_{n}\in\mathcal{F}_{n}\)[14, p.158].

Causal Effect

In this section, we define what it means for a sub-\(\sigma\)-algebra of the form \(\mathcal{H}_{S}\) to have a _causal effect_ on an event \(A\in\mathcal{H}\).

**Definition B.1**.: Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t\in T }\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, \(U\in\mathcal{P}(T)\), \(A\in\mathcal{H}\) an event and \(\mathcal{F}\) a sub-\(\sigma\)-algebra of \(\mathcal{H}\) (not necessarily of the form \(\mathcal{H}_{S}\) for some \(S\in\mathcal{P}(T)\)).

1. If \(K_{S}(\omega,A)=K_{S\setminus U}(\omega,A)\) for all \(S\in\mathcal{P}(T)\) and all \(\omega\in\Omega\), then we say that \(\mathcal{H}_{U}\) has _no causal effect on_\(A\), or that \(\mathcal{H}_{U}\) is _non-causal to_\(A\). We say that \(\mathcal{H}_{U}\) has _no causal effect on_\(\mathcal{F}\), or that \(\mathcal{H}_{U}\) is _non-causal to_\(\mathcal{F}\), if, for all \(A\in\mathcal{F}\), \(\mathcal{H}_{U}\) has no causal effect on \(A\).
2. If there exists \(\omega\in\Omega\) such that \(K_{U}(\omega,A)\neq\mathbb{P}(A)\), then we say that \(\mathcal{H}_{U}\) has an _active causal effect on_\(A\), or that \(\mathcal{H}_{U}\) is _actively causal to_\(A\). We say that \(\mathcal{H}_{U}\) has an _active causal effect on_\(\mathcal{F}\), or that \(\mathcal{H}_{U}\) is _actively causal to_\(\mathcal{F}\), if \(\mathcal{H}_{U}\) has an active causal effect on some \(A\in\mathcal{F}\).
3. Otherwise, we say that \(\mathcal{H}_{U}\) has a _dormant causal effect on_\(A\), or that \(\mathcal{H}_{U}\) is _dormantly causal to_\(A\). We say that \(\mathcal{H}_{U}\) has a _dormant causal effect on_\(\mathcal{F}\), or that \(\mathcal{H}_{U}\) is _dormantly causal to_\(\mathcal{F}\), if \(\mathcal{H}_{U}\) does not have an active causal effect on any event in \(\mathcal{F}\) and there exists \(A\in\mathcal{F}\) on which \(\mathcal{H}_{U}\) has a dormant causal effect.

Sometimes, we will say that \(\mathcal{H}_{U}\) has a _causal effect_ on \(A\) to mean that \(\mathcal{H}_{U}\) has either an active or a dormant causal effect on \(A\).

The intuition is as follows. For any \(S\in\mathcal{P}(T)\) and any fixed event \(A\in\mathcal{H}\), consider the function \(\omega_{S}\mapsto K_{S}((\omega_{S\cap U},\omega_{S\setminus U}),A)\). If \(\mathcal{H}_{U}\) has no causal effect on \(A\), then it means that the causal kernel does not depend on the \(\omega_{S\cap U}\) component of \(\omega_{S}\). Since this has to hold for all \(S\in\mathcal{P}(T)\), it means that it is possible to have, for example, \(K_{U}(\omega,A)=\mathbb{P}(A)\) for all \(\omega\in\Omega\) and yet for \(\mathcal{H}_{U}\) to have a causal effect on \(A\). This would be precisely the case where \(\mathcal{H}_{U}\) has a dormant causal effect on \(A\), and it means that, for some \(S\in\mathcal{P}(T)\), \(\omega_{S}\mapsto K_{S}((\omega_{S\cap U},\omega_{S\setminus U},A)\) does depend on the \(\omega_{S\cap U}\) component.

We collect some straightforward but important special cases in the following remark.

**Remark B.2**.:
1. If \(\mathcal{H}_{U}\) has no causal effect on \(A\), then letting \(S=U\) in Definition B.1(i) and applying Definition 2.2(i), we can see that, for all \(\omega\in\Omega\), \[K_{U}(\omega,A)=K_{U\setminus U}(\omega,A)=K_{\emptyset}(\omega,A)=\mathbb{P }(A).\] In particular, this means that \(\mathcal{H}_{U}\) cannot have both no causal effect and active causal effect on \(A\).
2. It is immediate that the trivial \(\sigma\)-algebra \(\mathcal{H}_{\emptyset}=\{\emptyset,\Omega\}\) has no causal effect on any event \(A\in\mathcal{H}\). Conversely, it is also clear that \(\mathcal{H}_{U}\) for any \(U\in\mathcal{P}(T)\) has no causal effect on the trivial \(\sigma\)-algebra.
3. Let \(U\in\mathcal{P}(T)\) and \(\mathcal{F}\) a sub-\(\sigma\)-algebra of \(\mathcal{H}\). If \(\mathcal{H}_{U}\cap\mathcal{F}\neq\{\emptyset,\Omega\}\), then \(\mathcal{H}_{U}\) has an active causal effect on \(\mathcal{F}\), since, for \(A\in\mathcal{H}_{U}\cap\mathcal{F}\) with \(A\neq\emptyset\) and \(A\neq\Omega\), Definition 2.2(ii) tells us that \(K_{U}(\cdot,A)=1_{A}(\cdot)\neq\mathbb{P}(A)\). In particular, \(\mathcal{H}_{U}\) has an active causal effect on itself. Further, the full \(\sigma\)-algebra \(\mathcal{H}=\mathcal{H}_{T}\) has an active causal effect on all of its sub-\(\sigma\)-algebras except the trivial \(\sigma\)-algebra, and every \(\mathcal{H}_{U},U\in\mathcal{P}(T)\) except the trivial \(\sigma\)-algebra has an active causal effect on the full \(\sigma\)-algebra \(\mathcal{H}\).
4. Let \(U\in\mathcal{P}(T)\) and \(\mathcal{F}_{1},\mathcal{F}_{2}\) be sub-\(\sigma\)-algebras of \(\mathcal{H}\). If \(\mathcal{F}_{1}\subseteq\mathcal{F}_{2}\) and \(\mathcal{H}_{U}\) has no causal effect on \(\mathcal{F}_{2}\), then it is clear that \(\mathcal{H}_{U}\) has no causal effect on \(\mathcal{F}_{1}\).
5. If \(\mathcal{H}_{U}\) has no causal effect on an event \(A\), then for any \(V\in\mathcal{P}(T)\) with \(V\subseteq U\), \(\mathcal{H}_{V}\) has no causal effect on \(A\). Indeed, take any \(S\in\mathcal{P}(T)\). Then using the fact that \(\mathcal{H}_{U}\) has no causal effect on \(A\), see that, for any \(\omega\in\Omega\), \[K_{S\setminus V}(\omega,A)=K_{(S\setminus V)\setminus U}(\omega,A)\qquad\text{ applying Definition B.1(i) with }S\setminus V\]\[=K_{S\setminus U}(\omega,A)\] since \[V\subseteq U\] \[=K_{S}(\omega,A)\] applying Definition B.1(i) with \(S\). Since \(S\in\mathcal{P}(T)\) was arbitrary, we have that \(\mathcal{H}_{V}\) has no causal effect on \(A\).
* Contrapositively, if \(U,V\in\mathcal{P}(T)\) with \(V\subseteq U\) and \(\mathcal{H}_{V}\) has a causal effect on \(A\), then \(\mathcal{H}_{U}\) has a causal effect on \(A\).
* If \(U\in\mathcal{P}(T)\) has no causal effect on \(A\), then for any \(V\in\mathcal{P}(T)\), we have \[K_{V}(\omega,A)=K_{U\cup V}(\omega,A).\] Indeed, \[K_{U\cup V}(\omega,A) =K_{(U\cup V)\setminus(U\setminus V)}(\omega,A)\] since \[U\setminus V\] has no causal effect on \(A\) by (e) \[=K_{V}(\omega,A)\] since \[(U\cup V)\setminus(U\setminus V)=V.\]
* If \(U,V\in\mathcal{P}(T)\) and neither \(\mathcal{H}_{U}\) nor \(\mathcal{H}_{V}\) has a causal effect on \(A\), then \(\mathcal{H}_{U\cup V}\) has no causal effect on \(A\). Indeed, for any \(S\in\mathcal{P}(T)\) and any \(\omega\in\Omega\), \[K_{S\setminus(U\cup V)}(\omega,A) =K_{(S\setminus U)\setminus V}(\omega,A)\] \[=K_{S\setminus U}(\omega,A)\] as \[V\] has no causal effect on \(A\) \[=K_{S}(\omega,A)\] as \[U\] has no causal effect on \(A\). Since \(S\in\mathcal{P}(T)\) was arbitrary, \(\mathcal{H}_{U\cup V}\) has no causal effect on \(A\).
* Contrapositively, if \(U,V\in\mathcal{P}(T)\) and \(\mathcal{H}_{U\cup V}\) has a causal effect on \(A\), then either \(\mathcal{H}_{U}\) or \(\mathcal{H}_{V}\) has a causal effect on \(A\).

Following the definition of no causal effect, we define the notion of a _trivial causal kernel_.

**Definition B.3**.: Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t\in T }\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, and \(U\in\mathcal{P}(T)\). We say that the causal kernel \(K_{U}\) is _trivial_ if \(\mathcal{H}_{U}\) has no causal effect on \(\mathcal{H}_{T\setminus U}\).

Note that we can decompose \(\mathcal{H}\) as \(\mathcal{H}=\mathcal{H}_{U}\otimes\mathcal{H}_{T\setminus U}\), and so \(\mathcal{H}\) is generated by events of the form \(A\times B\) for \(A\in\mathcal{H}_{U}\) and \(B\in\mathcal{H}_{T\setminus U}\). But if \(K_{U}\) is trivial, then we have, by Axiom 2.2(ii), \(K_{U}(\omega,A\times B)=1_{A}(\omega)\mathbb{P}(B)\) for such a rectangle.

We also define a "conditional" version of causal effects.

**Definition B.4**.: Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, \(U,V\in\mathcal{P}(T)\), \(A\in\mathcal{H}\) an event and \(\mathcal{F}\) a sub-\(\sigma\)-algebra of \(\mathcal{H}\) (not necessarily of the form \(\mathcal{H}_{S}\) for some \(S\in\mathcal{P}(T)\)).

* If \(K_{S\cup V}(\omega,A)=K_{(S\cup V)\setminus(U\setminus V)}(\omega,A)\) for all \(S\in\mathcal{P}(T)\) and all \(\omega\in\Omega\), then we say that \(\mathcal{H}_{U}\) has _no causal effect on \(A\) given \(\mathcal{H}_{V}\)_, or that \(\mathcal{H}_{U}\) is _non-causal to \(A\) given \(\mathcal{H}_{V}\)_. We say that \(\mathcal{H}_{U}\) has _no causal effect on \(\mathcal{F}\) given \(\mathcal{H}_{V}\)_, or that \(\mathcal{H}_{U}\) is _non-causal to \(\mathcal{F}\) given \(\mathcal{H}_{V}\)_, if, for all \(A\in\mathcal{F}\), \(\mathcal{H}_{U}\) has no causal effect on \(A\) given \(\mathcal{H}_{V}\).
* If there exists \(\omega\in\Omega\) such that \(K_{U\cup V}(\omega,A)\neq K_{V}(\omega,A)\), then we say that \(\mathcal{H}_{U}\) has an _active causal effect on \(A\) given \(\mathcal{H}_{V}\)_, or that \(\mathcal{H}_{U}\) is _actively causal to \(A\) given \(\mathcal{H}_{V}\)_. We say that \(\mathcal{H}_{U}\) has an _active causal effect on \(\mathcal{F}\) given \(\mathcal{H}_{V}\)_, or that \(\mathcal{H}_{U}\) is _actively causal to \(\mathcal{F}\) given \(\mathcal{H}_{V}\)_, if \(\mathcal{H}_{U}\) has an active causal effect on some \(A\in\mathcal{F}\).
* Otherwise, we say that \(\mathcal{H}_{U}\) has a _dormant causal effect on \(A\) given \(\mathcal{H}_{V}\)_, or that \(\mathcal{H}_{U}\) is _dormantly causal to \(A\) given \(\mathcal{H}_{V}\)_. We say that \(\mathcal{H}_{U}\) has a _dormant causal effect on \(\mathcal{F}\) given \(\mathcal{H}_{V}\)_, or that \(\mathcal{H}_{U}\) is _dormantly causal to \(\mathcal{F}\) given \(\mathcal{H}_{V}\)_, if \(\mathcal{H}_{U}\) does not have an active causal effect on any event in \(\mathcal{F}\) given \(\mathcal{H}_{V}\) and there exists \(A\in\mathcal{F}\) on which \(\mathcal{H}_{U}\) has a dormant causal effect given \(\mathcal{H}_{V}\).

Sometimes, we will say that \(\mathcal{H}_{U}\) has a _causal effect on \(A\) given \(\mathcal{H}_{V}\)_ to mean that \(\mathcal{H}_{U}\) has either an active or a dormant causal effect on \(A\) given \(\mathcal{H}_{V}\).

The intuition is as follows. For any fixed \(S\in\mathcal{P}(T)\) and any fixed event \(A\in\mathcal{H}\). consider the function \(\omega_{S\cup V}\mapsto K_{S\cup V}\big{(}(\omega_{(S\cup V)\setminus(U\setminus V )},\omega_{S\cap(U\setminus V)}),A\big{)}\). If \(\mathcal{H}_{U}\) has no causal effect on \(A\) given \(\mathcal{H}_{V}\), then it means that the causal kernel does not depend on the \(\omega_{S\cap(U\setminus V)}\) component of \(\omega_{S\cup V}\); in other words, \(\mathcal{H}_{U}\) only has an influence on \(A\) through its \(V\) component.

We collect some important special cases in the following remark.

**Remark B.5**.:
1. Letting \(V=U\), we always have \(K_{S\cup U}(\omega,A)=K_{(S\cup U)\setminus(U\setminus U)}(\omega,A)=K_{S \cup U}(\omega,A)\) for all \(\omega\in\Omega\) and \(A\in\mathcal{H}\), which means that \(\mathcal{H}_{U}\) has no causal effect on any event \(A\in\mathcal{H}\) given itself.
2. If \(\mathcal{H}_{U}\) has no causal effect on \(A\) given \(\mathcal{H}_{V}\), then letting \(U=S\) in Definition B.4(i), we see that, for all \(\omega\in\Omega\), \[K_{U\cup V}(\omega,A)=K_{V}(\omega,A).\] In particular, this means that \(\mathcal{H}_{U}\) cannot have both no causal effect and active causal effect on \(A\) given \(\mathcal{H}_{V}\).
3. The case \(V=\emptyset\) reduces Definition B.4 to Definition B.1, i.e. \(\mathcal{H}_{U}\) having no causal effect in the sense of Definition B.1 is the same as \(\mathcal{H}_{U}\) having no causal effect given \(\{\emptyset,\Omega\}\) in the sense of Definition B.4, etc.
4. It is possible for \(\mathcal{H}_{U}\) to be causal to an event \(A\), and for there to exist \(V\in\mathcal{P}(T)\) such that \(\mathcal{H}_{U}\) has no causal effect on \(A\) given \(\mathcal{H}_{V}\). However, if \(\mathcal{H}_{U}\) has no causal effect on \(A\), then for any \(V\in\mathcal{P}(T)\), \(\mathcal{H}_{U}\) has no causal effect on \(A\) given \(\mathcal{H}_{V}\). To see this, note that Remark B.2(e) tells us that \(U\setminus V\) also does not have any causal effect on \(A\). Then given any \(S\in\mathcal{P}(T)\), \[K_{S\cup V}(\omega,A)=K_{(S\cup V)\setminus(U\setminus V)}(\omega,A),\] applying Definition B.1(i) to \(S\cup V\). Since \(S\in\mathcal{P}(T)\) was arbitrary, \(\mathcal{H}_{U}\) has no causal effect on \(A\) given \(\mathcal{H}_{V}\).

## Appendix C Interventions

In this section, we provide a few more definitions and results related to the notion of interventions, introduced in Definition 2.3.

First, we make a few remarks on how the intervention causal kernels \(K_{S}^{\mathsf{do}(U,\mathbb{Q},\mathbb{L})}\) behave in some special cases, depending on the relationship between \(U\) and \(S\).

**Remark C.1**.:
1. For \(S\in\mathcal{P}(T)\) with \(U\subseteq S\), we have, for all \(\omega\in\Omega\) and all \(A\in\mathcal{H}\), \[K_{S}^{\mathsf{do}(U,\mathbb{Q},\mathbb{L})}(\omega,A) =\int L_{U}(\omega_{U},d\omega_{U}^{\prime})K_{S}((\omega_{S\setminus U },\omega_{U}^{\prime}),A)\] \[=\int\delta_{\omega_{U}}(d\omega_{U}^{\prime})K_{S}((\omega_{S \setminus U},\omega_{U}^{\prime}),A)\quad\text{ by Definition \ref{def:2}(ii)}\] \[=K_{S}((\omega_{S\setminus U},\omega_{U}),A)\] \[=K_{S}(\omega,A).\] This means that, after an intervention on \(\mathcal{H}_{U}\), subsequent interventions on \(\mathcal{H}_{S}\) with \(\mathcal{H}_{U}\subseteq\mathcal{H}_{S}\) simply overwrite the original intervention. Note that this is reminiscent of the "partial ordering on the set of interventions" in [49], but in our setting, this is given by the partial ordering induced by the inclusion structure of sub-\(\sigma\)-algebras of \(\mathcal{H}\).
2. For \(S\in\mathcal{P}(T)\) with \(S\subseteq U\), \[K_{S}^{\mathsf{do}(U,\mathbb{Q},\mathbb{L})}(\omega,A)=\int L_{S}(\omega_{S}, d\omega_{U}^{\prime})K_{U}(\omega_{U}^{\prime},A)\] for all \(\omega\in\Omega\) and \(A\in\mathcal{H}\), i.e. \(K_{S}^{\mathsf{do}(U,\mathbb{Q},\mathbb{L})}\) is a product of the two kernels \(K_{U}\) and \(L_{S}\)[14, p.39]; in particular, \(K_{S}^{\mathsf{do}(U,\mathbb{Q},\mathbb{L})}(\omega,A)=L_{S}(\omega,A)\) for all \(A\in\mathcal{H}_{U}\).

[MISSING_PAGE_EMPTY:21]

The next result tells us that if a sub-\(\sigma\)-algebra \(\mathcal{H}_{U}\) has a dormant causal effect on an event \(A\), then there is a sub-\(\sigma\)-algebra of \(\mathcal{H}_{U}\) and a hard intervention after which that sub-\(\sigma\)-algebra has an active causal effect on \(A\).

**Lemma C.5**.: _Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, and \(U\in\mathcal{P}(T)\). For an event \(A\in\mathcal{H}\), if \(\mathcal{H}_{U}\) has a dormant causal effect on \(A\) in the original causal space, then there exists a hard intervention and a subset \(V\subseteq U\) such that in the intervention causal space, \(\mathcal{H}_{V}\) has an active causal effect on \(A\)._

The next result is about what happens to a causal effect of a sub-\(\sigma\)-algebra that has no causal effect on an event conditioned on another sub-\(\sigma\)-algebra, after intervening on that sub-\(\sigma\)-algebra.

**Lemma C.6**.: _Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, and \(U,V\in\mathcal{P}(T)\). For an event \(A\in\mathcal{H}\), suppose that \(\mathcal{H}_{U}\) has no causal effect on \(A\) given \(\mathcal{H}_{V}\) (see Definition B.4). Then after an intervention on \(\mathcal{H}_{V}\) via any \((\mathbb{Q},\mathbb{L})\), \(\mathcal{H}_{U\setminus V}\) has no causal effect on \(A\)._

The next result shows that, under a hard intervention, a time-respecting causal mechanism stays time-respecting.

**Theorem C.7**.: _Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, where the index set \(T\) can be written as \(T=W\times\hat{T}\), with \(W\) representing time and \(\mathbb{K}\) respecting time. Take any \(U\in\mathcal{P}(T)\) and any probability measure \(\mathbb{Q}\) on \(\mathcal{H}_{U}\). Then the intervention causal mechanism \(\mathbb{K}^{\mathsf{do}(U,\mathbb{Q},\mathsf{hard})}\) also respects time._

## Appendix D Sources

In causal spaces, the observational distribution \(\mathbb{P}\) and the causal mechanism \(\mathbb{K}\) are completely decoupled. In Section 3.1, we give a detailed argument as to why this is desirable, but of course, there is no doubt that the special case in which the causal kernels coincide with conditional measures with respect to \(\mathbb{P}\) is worth studying. To that end, we introduce the notion of _sources_.

**Definition D.1**.: Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, \(U\in\mathcal{P}(T)\), \(A\in\mathcal{H}\) an event and \(\mathcal{F}\) a sub-\(\sigma\)-algebra of \(\mathcal{H}\). We say that \(\mathcal{H}_{U}\) is a _(local) source_ of \(A\) if \(K_{U}(\cdot,A)\) is a version of the conditional probability \(\mathbb{P}_{\mathcal{H}_{U}}(A)\). We say that \(\mathcal{H}_{U}\) is a _(local) source_ of \(\mathcal{F}\) if \(\mathcal{H}_{U}\) is a source of all \(A\in\mathcal{F}\). We say that \(\mathcal{H}_{U}\) is a _global source_ of the causal space if \(\mathcal{H}_{U}\) is a source of all \(A\in\mathcal{H}\).

Clearly, source \(\sigma\)-algebras are not unique (whether local or global). It is easy to see that \(\mathcal{H}_{\emptyset}=\{\emptyset,\Omega\}\) and \(\mathcal{H}=\mathcal{H}_{T}=\otimes_{t\in T}\mathcal{E}_{t}\) are global sources, and axiom (ii) of Definition 2.2 implies that any \(\mathcal{H}_{S}\) is a local source of any of its sub-\(\sigma\)-algebras, including itself, since, for any \(A\in\mathcal{H}_{U},\mathbb{P}_{\mathcal{H}_{U}}(A)=1_{A}\). Also, a sub-\(\sigma\)-algebra of a source is not necessarily a source, nor is a \(\sigma\)-algebra that contains a source necessarily a source (whether local or global). In Example 2.5 above, altitude is a source of temperature (and hence a global source), since the causal kernel corresponding to temperature coincides with the conditional measure given altitude, but temperature is not a source of altitude.

When we intervene on \(\mathcal{H}_{U}\) (via any \((\mathbb{Q},\mathbb{L})\)), \(\mathcal{H}_{U}\) becomes a global source. This precisely coincides with the "gold standard" that is randomised control trials in causal inference, i.e. the idea that, if we are able to intervene on \(\mathcal{H}_{U}\), then the causal effect of \(\mathcal{H}_{U}\) on any event can be obtained by first intervening on \(\mathcal{H}_{U}\), then considering the conditional distribution on \(\mathcal{H}_{U}\). Next is a theorem showing that when one intervenes on \(\mathcal{H}_{U}\), then \(\mathcal{H}_{U}\) becomes a source.

**Theorem D.2**.: _Suppose we have a causal space \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\), and let \(U\in\mathcal{P}(T)\)._

1. _For any measure_ \(\mathbb{Q}\) _on_ \(\mathcal{H}_{U}\) _and any causal mechanism_ \(\mathbb{L}\) _on_ \((\Omega,\mathcal{H}_{U},\mathbb{Q})\)_, the causal kernel_ \(K_{U}^{\mathsf{do}(U,\mathbb{Q},\mathbb{L})}=K_{U}\) _is a version of_ \(\mathbb{P}_{\mathcal{H}_{U}}^{\mathsf{do}(U,\mathbb{Q})}\)_, which means that_ \(\mathcal{H}_{U}\) _is a global source_ \(\sigma\)_-algebra of the intervened causal space_ \((\Omega,\mathcal{H},\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})},\mathbb{K}^{ \mathsf{do}(U,\mathbb{Q},\mathbb{L})})\)_._
2. _Suppose_ \(V\in\mathcal{P}(T)\) _with_ \(V\subseteq U\)_. Suppose that the measure_ \(\mathbb{Q}\) _on_ \((\Omega,\mathcal{H}_{U})\) _factorises over_ \(\mathcal{H}_{V}\) _and_ \(\mathcal{H}_{U\setminus V}\)_, i.e. for any_ \(A\in\mathcal{H}_{V}\) _and_ \(B\in\mathcal{H}_{U\setminus V}\)_,_ \(\mathbb{Q}(A\cap B)=\mathbb{Q}(A)\mathbb{Q}(B)\)_. Then after a hard intervention on_ \(\mathcal{H}_{U}\) _via_ \(\mathbb{Q}\)_, the causal kernel_ \(K_{V}^{\mathsf{do}(U,\mathsf{Q},\mathsf{hard})}\) _is a version of_ \(\mathbb{P}_{V}^{\mathsf{do}(U,\mathbb{Q})}\)_, which means that_ \(\mathcal{H}_{V}\) _is a global source_ \(\sigma\)_-algebra of the intervened causal space_ \((\Omega,\mathcal{H},\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})},\mathbb{K}^{ \mathsf{do}(U,\mathbb{Q},\mathsf{hard})})\)_._Let \(A\in\mathcal{H}\) be an event, and \(U\in\mathcal{P}(T)\). By the definition of the intervention measure (Definition 2.3), we always have

\[\mathbb{P}^{\text{do}(U,\mathbb{Q})}(A)=\int\mathbb{Q}(d\omega)K_{U}(\omega,A),\]

hence \(\mathbb{P}^{\text{do}(U,\mathbb{Q})}(A)\) can be written in terms of \(\mathbb{P}\) and \(\mathbb{Q}\) if \(K_{U}(\omega,A)\) can be written in terms of \(\mathbb{P}\). This can be seen to occur in three trivial cases: first, if \(\mathcal{H}_{U}\) is a local source of \(A\) (see Definition D.1), in which case \(K_{U}(\omega,A)=\mathbb{P}_{\mathcal{H}_{U}}(\omega,A)\); secondly, if \(\mathcal{H}_{U}\) has no causal effect on \(A\) (see Definition B.1), in which case \(K_{U}(\omega,A)=\mathbb{P}(A)\); and finally, if \(A\in\mathcal{H}_{U}\), in which case, by intervention determinism (Definition 2.2(ii), we have \(K_{U}(\omega,A)=1_{A}(\omega)\). In the latter case, we do not even have dependence on \(\mathbb{P}\). Can we generalise these results?

**Lemma D.3**.: _Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space. Let \(A\in\mathcal{H}\) be an event, and \(U\in\mathcal{P}(T)\). If there exists a sub-\(\sigma\)-algebra \(\mathcal{S}\) of \(\mathcal{H}\) (not necessarily of the form \(\mathcal{H}_{V}\) for some \(V\in\mathcal{P}(T)\)) such that_

1. _the conditional probability_ \(\mathbb{P}^{\text{do}(U,\mathbb{Q})}_{\mathcal{H}_{U}\vee\mathcal{S}}(\cdot,A)\) _can be written in terms of_ \(\mathbb{P}\) _and_ \(\mathbb{Q}\)_;_
2. _the causal kernel_ \(K_{U}(\cdot,B)\) _can be written in terms of_ \(\mathbb{P}\) _for all_ \(B\in\mathcal{S}\)_;_

_then \(\mathbb{P}^{\text{do}(U,\mathbb{Q})}(A)\) can be written in terms of \(\mathbb{P}\) and \(\mathbb{Q}\)._

**Remark D.4**.: The three cases discussed in the paragraph above Lemma D.3 are special cases of the Lemma with \(\mathcal{G}\) being any sub-\(\sigma\)-algebra of \(\mathcal{H}\) with \(\{\emptyset,\Omega\}\subseteq\mathcal{G}\subseteq\mathcal{H}_{U}\). In this case, condition (ii) is trivially satisfied since we have \(K_{U}(\cdot,B)=1_{B}(\cdot)\) by intervention determinism (Definition 2.2(ii)), and for condition (i), by Theorem D.2(i), we have \(\mathbb{P}^{\text{do}(U,\mathbb{Q})}_{\mathcal{H}_{U}}(\cdot,A)=K_{U}(\cdot,A)\), which means that the problem reduces to checking if \(K_{U}(\cdot,A)\) can be written in terms of \(\mathbb{P}\).

Proof.: By law of total expectations, for any \(V\in\mathcal{P}(T)\), we have

\[\mathbb{P}^{\text{do}(U,\mathbb{Q})}(A) =\int\mathbb{P}^{\text{do}(U,\mathbb{Q})}_{\mathcal{H}_{U}\lor \mathcal{S}}(\omega,A)\mathbb{P}^{\text{do}(U,\mathbb{Q})}(d\omega)\] \[=\int\mathbb{P}^{\text{do}(U,\mathbb{Q})}_{\mathcal{H}_{U}\lor \mathcal{S}}(\omega,A)\int\mathbb{Q}(d\omega^{\prime})K_{U}(\omega^{\prime},d \omega).\]

Here, \(\mathbb{P}^{\text{do}(U,\mathbb{Q})}_{\mathcal{H}_{U}\lor\mathcal{S}}(\omega,A)\) can be written in terms of \(\mathbb{P}\) and \(\mathbb{Q}\) by condition (i). Moreover, note that it suffices to be able to write the restriction of \(K_{U}(\omega^{\prime},\cdot)\) to \(\mathcal{H}_{U}\lor\mathcal{S}\) in terms of \(\mathbb{P}\), since the integration is of a \(\mathcal{H}_{U}\lor\mathcal{S}\)-measurable function. Since the collection of intersections \(\{D\cap B,D\in\mathcal{H}_{U},B\in\mathcal{G}\}\) is a \(\pi\)-system that generates \(\mathcal{H}_{U}\lor\mathcal{S}\)[14, p. 5. 1.18], it suffices to check that \(K_{U}(\omega^{\prime},D\cap B)\) can be written in terms of \(\mathbb{P}\) for all \(D\in\mathcal{H}_{U}\) and \(B\in\mathcal{G}\). But by interventional determinism (Definition 2.2(ii)), we have \(K_{U}(\omega^{\prime},D\cap B)=1_{D}(\omega^{\prime})K_{U}(\omega^{\prime},B)\). Since \(K_{U}(\omega^{\prime},B)\) can be written in terms of \(\mathbb{P}\) by condition (ii), the restriction of \(K_{U}(\omega^{\prime},\cdot)\) to \(\mathcal{H}_{U}\lor\mathcal{S}\) can be written in terms of \(\mathbb{P}\), and hence \(\mathbb{P}^{\text{do}(U,\mathbb{Q})}(A)\) can be written in terms of \(\mathbb{P}\) and \(\mathbb{Q}\). 

**Corollary D.5**.: _Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space. Let \(A\in\mathcal{H}\) be an event, and \(U\in\mathcal{P}(T)\). If there exists a \(V\in\mathcal{P}(T)\) such that condition (i) of Lemma D.3 is satisfied with \(\mathcal{G}=\mathcal{H}_{V}\) and one of the following conditions is satisfied:_

1. \(\mathcal{H}_{U}\) _is a local source of_ \(\mathcal{H}_{V}\)_; or_
2. \(\mathcal{H}_{U}\) _has no causal effect on_ \(\mathcal{H}_{V}\)_; or_
3. \(V\subseteq U\)_,_

_then \(\mathbb{P}^{\text{do}(U,\mathbb{Q})}(A)\) can be written in terms of \(\mathbb{P}\) and \(\mathbb{Q}\)._

Proof.: Condition (i) of Lemma D.3 is satisfied by hypothesis. If one of (a), (b) or (c) is satisfied, then trivially, condition (ii) of Lemma D.3 is also satisfied. The result now follows from Lemma D.3. 

The above is reminiscent of "valid adjustments" in the context of structural causal models [46, p.115, Proposition 6.41], and in fact contains the valid adjustments.

Counterfactuals

There are various notions of counterfactuals in the literature. The one considered in the SCM literature is the _interventional counterfactual_, which captures the notion of "what would have happened if we intervened on the space, given some observations (that are possibly contradictory to the intervention we imagine we would have done)". Recently, _backtracking counterfactuals_ have also been integrated into the SCM framework [58]. This captures the notion of "what would have happened if background conditions of the world had been different, given that the causal laws of the system stay the same?" Finally, we note that in the potential outcomes framework, the random variables representing "potential outcomes" that form the primitives of the framework can be directly counterfactual.

Vanilla probability measures have just one argument, i.e. the event. Conditional measures and causal kernels (in the sense of our Definition 2.2) have two arguments, the first being the outcome which we either observe or force the occurrence of, and the second being the event in whose measure we are interested. For both of the above concepts of counterfactuals, we need to go one step further and consider three arguments. The first is the outcome which we observe, just like in conditioning, and the last should be the event in whose measure we are interested. For interventional counterfactuals, the second argument should be an outcome which we imagine to have forced the occurrence of given that we observed the outcome of the first argument, and for backtracking counterfactuals, the second argument should be an outcome which we imagine to have observed instead of the outcome in the first argument which we actually observed.

From these principles, we tentatively propose to extend Definition 2.2 to account for _interventional counterfactuals_ as follows.

**Definition E.1**.: A _causal space_ is defined as the quadruple \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})\), where \((\Omega,\mathcal{H},\mathbb{P})=(\times_{t\in T}E_{t},\otimes_{t\in T}\mathcal{ E}_{t},\mathbb{P})\) is a probability space and \(\mathbb{K}=\{K_{S,\mathcal{T}}:S\in\mathcal{P}(T),\mathcal{F}\text{ sub-} \sigma\text{-algebra of }\mathcal{H}\}\), called the _causal mechanism_, is a collection of functions \(K_{S,\mathcal{T}}:\Omega\times\Omega\times\mathcal{H}\to[0,1]\), called the _causal kernel on \(\mathcal{H}_{S}\) after observing \(\mathcal{F}\)_, such that

1. for each fixed \(\eta\in\Omega\) and \(A\in\mathcal{H}\), \(K_{S,\mathcal{F}}(\cdot,\eta,A)\) is measurable with respect to \(\mathcal{H}_{S}\);
2. for each fixed \(\omega\in\Omega\) and \(A\in\mathcal{H}\), \(K_{S,\mathcal{F}}(\omega,\cdot,A)\) is measurable with respect to \(\mathcal{F}\);
3. for each fixed pair \((\omega,\eta)\in\Omega\times\Omega\), \(K_{S,\mathcal{F}}(\omega,\eta,\cdot)\) is a measure on \(\mathcal{H}\);
4. for all \(A\in\mathcal{H}\) and \(\omega,\eta\in\Omega\), \[K_{\emptyset,\mathcal{F}}(\omega,\eta,A)=\mathbb{P}_{\mathcal{F}}(\eta,A);\]
5. for all \(A\in\mathcal{H}_{S}\), all \(B\in\mathcal{H}\) and all \(\omega,\eta\in\Omega\), \[K_{S,\mathcal{F}}(\omega,\eta,A\cap B)=1_{A}(\omega)K_{S}(\omega,\eta,B);\] in particular, for \(A\in\mathcal{H}_{S}\), \(K_{S,\mathcal{F}}(\omega,\eta,A)=1_{A}(\omega)K_{S,\mathcal{F}}(\omega,\eta, \Omega)=1_{A}(\omega)\);
6. for all \(A\in\mathcal{H}\), \(\omega\in\Omega\) and sub-\(\sigma\)-algebras \(\mathcal{F}\subseteq\mathcal{G}\subseteq\mathcal{H}\), \[\mathbb{E}_{\mathcal{F}}\left[K_{S,\mathcal{G}}(\omega,\cdot,A)\right]=K_{S, \mathcal{F}}(\omega,\cdot,A).\]

Note that letting \(\mathcal{F}=\{\emptyset,\Omega\}\) trivially recovers the causal space as defined in Definition 2.2. Moreover, letting \(S=\emptyset\), we recover the conditional distribution given \(\mathcal{F}\).

Recall that the one of the biggest philosophical differences between the SCM framework and our proposed causal spaces (Definition 2.2) was the fact that SCMs start with the variables, the structural equations and the noise distributions as the _primitive objects_, and the observational and interventional distributions over the endogenous variables are _derived_ from these, whereas causal spaces take the observational and interventional distributions as the _primitive objects_ (the latter via causal kernels). Note that, in the above extended definition of causal spaces incorporating interventional counterfactuals (Definition E.1), we applied the same principles, in that we treated the observational distribution (\(\mathbb{P}\)), interventional distributions (\(K_{S,\{\emptyset,\Omega\}}\)) and the (interventional) counterfactual distributions (\(K_{S,\mathcal{F}}\)) as the primitive objects.

This differs significantly from the SCM framework, where again, the (interventional) counterfactual distributions are _derived_ from the structural equations, by first conditioning on the observed values of the endogenous variables to get a modified (often Dirac) measure on the exogenous variables, then intervening on some of the endogenous variables, deriving the measure on the rest of the endogenous variables by propagating these through the same structural equations. We see the value in this approach in that the (interventional) counterfactual distributions can be neatly derived from the same primitive objects that are used to calculate the observational and interventional distribution. However, we argue that this cannot be an _axiomatisation_ of (interventional) counterfactual distributions in the strictest sense, because it relies on assumptions. In particular, it strongly relies on the assumption that the endogenous variables have no causal effect on the exogenous variables, and when this assumption is violated, i.e. when there is a hidden mediator, calculation of (interventional) counterfactual distributions is not possible. In contrast, Definition E.1 treat the (interventional) counterfactual measures as the primitive objects, and does not impose any a priori assumptions about the system.

As mentioned in Section 5 of the main body of the paper, we leave further developments of this interventional counterfactual causal space, as well as the definition of backtracking counterfactual causal space, as essential future work.

## Appendix F Proofs

**Theorem 2.6**.: From Definition 2.3, \(\mathbb{P}^{\text{do}(U,\mathbb{Q})}\) is indeed a measure on \((\Omega,\mathcal{H})\), and \(\mathbb{K}^{\text{do}(U,\mathbb{Q},\mathbb{L})}\) is indeed a valid causal mechanism on \((\Omega,\mathcal{H},\mathbb{P}^{\text{do}(U,\mathbb{Q})})\), i.e. they satisfy the axioms of Definition 2.2.

Proof.: That \(\mathbb{P}^{\text{do}(U,\mathbb{Q})}\) is a measure on \((\Omega,\mathcal{H})\) follows immediately from the usual construction of measures from measures and transition probability kernels, see e.g. Cmlar [14, p.38, Theorem 6.3]. It remains to check that \(\mathbb{K}^{\text{do}(U,\mathbb{Q},\mathbb{L})}\) is a valid causal mechanism in the sense of Definition 2.2.

1. For all \(A\in\mathcal{H}\) and \(\omega\in\Omega\), \[K^{\text{do}(U,\mathbb{Q},\mathbb{L})}_{\emptyset}(\omega,A) =\int L_{\emptyset}(\omega_{\emptyset},d\omega^{\prime}_{U})K_{U}( (\omega_{\emptyset},\omega^{\prime}_{U}),A)\] \[=\int\mathbb{Q}(d\omega^{\prime})K_{U}(\omega^{\prime},A)\] \[=\mathbb{P}^{\text{do}(U,\mathbb{Q})}(A),\] where we applied Axiom 2.2(i) to \(L_{\emptyset}\).
2. For all \(A\in\mathcal{H}_{S}\) and \(B\in\mathcal{H}\), we have, by Axiom 2.2(ii) using the fact that \(A\in\mathcal{H}_{S}\subseteq\mathcal{H}_{S\cup U}\), \[K^{\text{do}(U,\mathbb{Q},\mathbb{L})}_{S}(\omega,A\cap B)\] \[=\int L_{S\cap U}(\omega_{S\cap U},d\omega^{\prime}_{U})K_{S\cup U }((\omega_{S\setminus U},\omega^{\prime}_{U}),A\cap B)\] \[=\int L_{S\cap U}(\omega_{S\cap U},d\omega^{\prime}_{U})1_{A}(( \omega_{S\setminus U},\omega^{\prime}_{U}))K_{S\cup U}((\omega_{S\setminus U},\omega^{\prime}_{U}),B)\] \[=\int L_{S\cap U}(\omega_{S\cap U},d\omega^{\prime}_{U})1_{A}(( \omega_{S\setminus U},\omega^{\prime}_{S\cap U}))K_{S\cup U}((\omega_{S\setminus U },\omega^{\prime}_{U}),B),\] where, in going from the third line to the fourth, we split the \(\omega^{\prime}_{U}\) in \(1_{A}((\omega_{S\setminus U},\omega^{\prime}_{U}))\) into components \((\omega^{\prime}_{S\cap U},\omega^{\prime}_{U\setminus S})\) and notice that since \(A\in\mathcal{H}_{S}\), \(1_{A}\) does not depend on the component \(\omega^{\prime}_{U\setminus S}\). Here, the map \(\omega^{\prime}_{S\cap U}\mapsto 1_{A}((\omega_{S\setminus U},\omega^{\prime}_{S \cap U}))\) is \(\mathcal{H}_{S\cap U}\)-measurable, so we can write it as the limit of an increasing sequence of positive \(\mathcal{H}_{S\cap U}\)-simple functions (see Section A.1), say \((f_{n})_{n\in\mathbb{N}}\) with \(f_{n}=\sum_{i=1}^{m_{n}}b_{i_{n}}1_{B_{i_{n}}}\), where \(B_{i_{n}}\in\mathcal{H}_{S\cap U}\). Likewise, the map \(\omega^{\prime}_{U}\mapsto K_{S\cup U}((\omega_{S\setminus U},\omega^{\prime} _{U}),B)\) is \(\mathcal{H}_{U}\)-measurable, so we can write it as the limit of an increasing sequence of positive \(\mathcal{H}_{U}\)-simple functions, say \((g_{n})_{n\in\mathbb{N}}\) with \(g_{n}=\sum_{j_{n}=1}^{l_{n}}c_{j_{n}}1_{C_{j_{n}}}\), where \(C_{j_{n}}\in\mathcal{H}_{U}\). Hence \[K^{\text{do}(U,\mathbb{Q},\mathbb{L})}_{S}(\omega,A\cap B)=\int L_{S\cap U}( \omega_{S\cap U},d\omega^{\prime}_{U})\left(\lim_{n\to\infty}f_{n}(\omega^{ \prime}_{S\cap U})\right)\left(\lim_{n\to\infty}g_{n}(\omega^{\prime}_{U}) \right).\]Since, for each \(\omega^{\prime}_{U}\), both of the limits exist by construction, namely the original measurable functions, we have that the product of the limits is the limit of the products:

\[K_{S}^{\mathsf{do}(U,\mathbb{Q},\mathbb{L})}(\omega,A\cap B)=\int L_{S\cap U}( \omega_{S\cap U},d\omega^{\prime}_{U})\lim_{n\to\infty}\left(f_{n}(\omega^{ \prime}_{S\cap U})g_{n}(\omega^{\prime}_{U})\right).\]

Here, since \(f_{n}\) and \(g_{n}\) were individually sequences of increasing functions, the pointwise products \(f_{n}g_{n}\) also form an increasing sequence of functions. Hence, we can apply the monotone convergence theorem to see that

\[K_{S}^{\mathsf{do}(U,\mathbb{Q},\mathbb{L})}(\omega,A\cap B)\] \[=\lim_{n\to\infty}\int L_{S\cap U}(\omega_{S\cap U},d\omega^{ \prime}_{U})f_{n}(\omega^{\prime}_{S\cap U})g_{n}(\omega^{\prime}_{U})\] \[=\lim_{n\to\infty}\sum_{i_{n}=1}^{m_{n}}\sum_{j_{n}=1}^{l_{n}}b_ {i_{n}}c_{j_{n}}\int L_{S\cap U}(\omega_{S\cap U},d\omega^{\prime}_{U})1_{B_{ i_{n}}}(\omega^{\prime}_{S\cap U})1_{C_{j_{n}}}(\omega^{\prime}_{U})\] \[=\lim_{n\to\infty}\sum_{i_{n}=1}^{m_{n}}\sum_{j_{n}=1}^{l_{n}}b_ {i_{n}}c_{j_{n}}L_{S\cap U}(\omega_{S\cap U},B_{i_{n}}\cap C_{j_{n}})\] \[=\lim_{n\to\infty}\sum_{i_{n}=1}^{m_{n}}\sum_{j_{n}=1}^{l_{n}}b_ {i_{n}}c_{j_{n}}1_{B_{i_{n}}}(\omega_{S\cap U})L_{S\cap U}(\omega_{S\cap U},C _{j_{n}})\] \[=\lim_{n\to\infty}\sum_{i_{n}=1}^{m_{n}}b_{i_{n}}1_{B_{i_{n}}}( \omega_{S\cap U})\sum_{j_{n}=1}^{l_{n}}c_{j_{n}}L_{S\cap U}(\omega_{S\cap U}, C_{j_{n}})\] \[=\left(\lim_{n\to\infty}\sum_{i_{n}=1}^{m_{n}}b_{i_{n}}1_{B_{i_{n} }}(\omega_{S\cap U})\right)\left(\lim_{n\to\infty}\sum_{j_{n}=1}^{l_{n}}c_{j_{ n}}L_{S\cap U}(\omega_{S\cap U},C_{j_{n}})\right)\] \[=\left(\lim_{n\to\infty}f_{n}(\omega_{S\cap U})\right)\left(\lim _{n\to\infty}\int L_{S\cap U}(\omega_{S\cap U},d\omega^{\prime}_{U})\sum_{j_{ n}=1}^{l_{n}}c_{j}1_{C_{j_{n}}}(\omega^{\prime}_{U})\right)\] \[=1_{A}((\omega_{S\setminus U},\omega_{S\cap U}))\int L_{S\cap U}( \omega_{S\cap U},d\omega^{\prime}_{U})\lim_{n\to\infty}g_{n}(\omega^{\prime}_ {U})\] \[=1_{A}(\omega_{S})\int L_{S\cap U}(\omega_{S\cap U},d\omega^{ \prime}_{U})K_{S\cup U}((\omega_{S\setminus U},\omega^{\prime}_{U}),B)\] \[=1_{A}(\omega_{S})K_{S}^{\mathsf{do}(U,\mathbb{Q},\mathbb{L})}( \omega_{S},B)\]

where, from the fourth line to the fifth, we used Axiom 2.2(ii); from the sixth line to the seventh, we used that limit of the products is the product of the limits again, noting that both of the limits exist by construction; from the eighth line to the ninth, we used monotone convergence theorem again. This is the required result.

**Theorem C.3**.: Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, and \(U\in\mathcal{P}(T)\) and \(\mathbb{Q}\) a probability measure on \((\Omega,\mathcal{H}_{U})\). Then after a hard intervention on \(\mathcal{H}_{U}\) via \(\mathbb{Q}\), the intervention causal kernels \(K_{S}^{\mathsf{do}(U,\mathbb{Q},\mathbb{hard})}\) are given by

\[K_{S}^{\mathsf{do}(U,\mathbb{Q},\mathbb{hard})}(\omega,A)=K_{S}^{\mathsf{do}( U,\mathbb{Q},\mathbb{hard})}(\omega_{S},A)=\int\mathbb{Q}(d\omega^{\prime}_{U \setminus S})K_{S\cup U}((\omega_{S},\omega^{\prime}_{U\setminus S}),A).\]

Proof.: We decompose \(\mathcal{H}_{U}\) as a product \(\sigma\)-algebra into \(\mathcal{H}_{S\cap U}\otimes\mathcal{H}_{U,S}\). Then events of the form \(B\cap C\) with \(B\in\mathcal{H}_{S\cap U}\) and \(C\in\mathcal{H}_{U\setminus S}\) generate \(\mathcal{H}_{U}\), so for fixed \(\omega_{S\cap U}\), the measure \(L_{S\cap U}(\omega_{S\cap U},\cdot)\) is completely determined by \(L_{S\cap U}(\omega_{S\cap U},B\cap C)\) for all \(B\in\mathcal{H}_{S\cap U}\), \(C\in\mathcal{H}_{U\setminus S}\). But we have

\[L_{S\cap U}(\omega_{S\cap U},B\cap C)=\delta_{\omega_{S\cap U}}(B)L_{S\cap U}( \omega_{S\cap U},C)\qquad\text{by Axiom 2.2(ii)}\]\[=\delta_{\omega_{S^{\cap U}}}(B)\mathbb{Q}(C),\]

since \(L_{S^{\cap U}}\) is trivial and \(C\in\mathcal{H}_{U\setminus S}\). So the measure \(L_{S^{\cap U}}(\omega_{S^{\cap U}},\cdot)\) is a product measure of \(\delta_{\omega_{S^{\cap U}}}\) and \(\mathbb{Q}\). Hence, applying Fubini's theorem,

\[K_{S}^{\mathsf{do}(U,\mathbb{Q},\mathsf{hard})}(\omega,A) =\int L_{S^{\cap U}}(\omega_{S^{\cap U}},d\omega_{U}^{\prime})K_{S ^{\cup U}}((\omega_{S^{\setminus}U},\omega_{U}^{\prime}),A)\] \[=\int\int K_{S^{\cup U}}((\omega_{S^{\setminus}U},\omega_{S^{\cap U }}^{\prime},\omega_{U\setminus S}^{\prime}),A)\delta_{\omega_{S^{\cap U}}}(d \omega_{S^{\cap U}}^{\prime})\mathbb{Q}(d\omega_{U\setminus S}^{\prime})\] \[=\int K_{S^{\setminus U}}((\omega_{S^{\setminus}U},\omega_{S^{ \cap U}},\omega_{U\setminus S}^{\prime}),A)\mathbb{Q}(d\omega_{U\setminus S }^{\prime})\] \[=\int\mathbb{Q}(d\omega_{U\setminus S}^{\prime})K_{S^{\cup U}}(( \omega_{S},\omega_{U\setminus S}^{\prime}),A),\]

as required.

**Theorem D.2**.: Suppose we have a causal space \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\), and let \(U\in\mathcal{P}(T)\).

1. For any measure \(\mathbb{Q}\) on \(\mathcal{H}_{U}\) and any causal mechanism \(\mathbb{L}\) on \((\Omega,\mathcal{H}_{U},\mathbb{Q})\), the causal kernel \(K_{U}^{\mathsf{do}(U,\mathbb{Q},\mathbb{L})}=K_{U}\) is a version of \(\mathbb{P}_{\mathcal{H}_{U}}^{\mathsf{do}(U,\mathbb{Q})}\), which means that \(\mathcal{H}_{U}\) is a global source \(\sigma\)-algebra of the intervened causal space \((\Omega,\mathcal{H},\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})},\mathbb{K}^{ \mathsf{do}(U,\mathbb{Q},\mathbb{L})})\).
2. Suppose \(V\in\mathcal{P}(T)\) with \(V\subseteq U\). Suppose that the measure \(\mathbb{Q}\) on \((\Omega,\mathcal{H}_{U})\) factorises over \(\mathcal{H}_{V}\) and \(\mathcal{H}_{U\setminus V}\), i.e. for any \(A\in\mathcal{H}_{V}\) and \(B\in\mathcal{H}_{U\setminus V}\), \(\mathbb{Q}(A\cap B)=\mathbb{Q}(A)\mathbb{Q}(B)\). Then after a hard intervention on \(\mathcal{H}_{U}\) via \(\mathbb{Q}\), the causal kernel \(K_{V}^{\mathsf{do}(U,\mathbb{Q})}\) is a version of \(\mathbb{P}_{V}^{\mathsf{do}(U,\mathbb{Q})}\), which means that \(\mathcal{H}_{V}\) is a global source \(\sigma\)-algebra of the intervened causal space \((\Omega,\mathcal{H},\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})},\mathbb{K}^{ \mathsf{do}(U,\mathbb{Q})})\).

Proof.: Suppose that \(f=\sum_{i=1}^{m}b_{i}1_{B_{i}}\) is a \(\mathcal{H}_{U}\)-simple function, i.e. with \(B_{i}\in\mathcal{H}_{U}\) for \(i=1,...,m\). Then for any \(B\in\mathcal{H}_{U}\),

\[\int_{B}f(\omega)\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})}(d\omega) =\int_{B}\sum_{i=1}^{m}b_{i}1_{B_{i}}(\omega)\mathbb{P}^{\mathsf{do }(U,\mathbb{Q})}(d\omega)\] \[=\sum_{i=1}^{m}b_{i}\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})}(B\cap B _{i})\] \[=\sum_{i=1}^{m}b_{i}\int\mathbb{Q}(d\omega)K_{U}(\omega,B\cap B_{i })\quad\text{by the definition of $\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})}$}\] \[=\sum_{i=1}^{m}b_{i}\int\mathbb{Q}(d\omega)1_{B\cap B_{i}}(\omega) \quad\quad\quad\quad\text{by Axiom 2.2(ii)}\] \[=\int_{B}\sum_{i=1}^{m}b_{i}1_{B_{i}}(\omega)\mathbb{Q}(d\omega)\] \[=\int_{B}f(\omega)\mathbb{Q}(d\omega).\]

Now, for any \(\mathcal{H}_{U}\)-measurable map \(g:\Omega\to\mathbb{R}\), we can write it as a limit of an increasing sequence of positive \(\mathcal{H}_{U}\)-simple functions \(f_{n}\) (see Section A.1), so for any \(B\in\mathcal{H}_{U}\),

\[\int_{B}g(\omega)\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})}(d\omega) =\int_{B}\lim_{n\to\infty}f_{n}(\omega)\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})}(d\omega)\] \[=\lim_{n\to\infty}\int_{B}f_{n}(\omega)\mathbb{P}^{\mathsf{do}(U, \mathbb{Q})}(d\omega)\quad\quad\text{by the monotone convergence theorem}\]\[=\lim_{n\to\infty}\int_{B}f_{n}(\omega)\mathbb{Q}(d\omega)\] by above \[=\int_{B}\lim_{n\to\infty}f_{n}(\omega)\mathbb{Q}(d\omega)\] by the monotone convergence theorem \[=\int_{B}g(\omega)\mathbb{Q}(d\omega).\]

We use this fact in the proof of both parts of this theorem.

1. First note that we indeed have \(K_{U}^{\mathsf{do}(U,\mathbb{Q},\mathbb{L})}=K_{U}\), by Remark C.1(a). For any \(A\in\mathcal{H}\), the map \(\omega\mapsto K_{U}(\omega,A)\) is \(\mathcal{H}_{U}\)-measurable, so for any \(B\in\mathcal{H}_{U}\), \[\int_{B}K_{U}(\omega,A)\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})}(d\omega) =\int_{B}K_{U}(\omega,A)\mathbb{Q}(d\omega)\] by above fact \[=\int 1_{B}(\omega)K_{U}(\omega,A)\mathbb{Q}(d\omega)\] \[=\int K_{U}(\omega,A\cap B)\mathbb{Q}(d\omega)\] by Axiom 2.2(ii) \[=\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})}(A\cap B)\] \[=\int 1_{A\cap B}(\omega)\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})}(d\omega)\] \[=\int 1_{B}(\omega)1_{A}(\omega)\mathbb{P}^{\mathsf{do}(U, \mathbb{Q})}(d\omega)\] \[=\int_{B}A(\omega)\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})}(d\omega).\] So \(K_{U}(\cdot,A)=K_{U}^{\mathsf{do}(U,\mathbb{Q},\mathbb{L})}(\cdot,A)\) is indeed a version of the conditional probability \(\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})}_{\mathcal{H}_{U}}(A)\), which means that \(\mathcal{H}_{U}\) is a global source of \((\Omega,\mathcal{H},\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})},\mathbb{K}^{ \mathsf{do}(U,\mathbb{Q},\mathbb{L})})\).
2. For any \(A\in\mathcal{H}\), the map \(\omega\mapsto K_{V}^{\mathsf{do}(U,\mathbb{Q})}(\omega,A)\) is \(\mathcal{H}_{V}\)-measurable and hence \(\mathcal{H}_{U}\)-measurable, so for any \(B\in\mathcal{H}_{V}\subseteq\mathcal{H}_{U}\), \[\int_{B}K_{V}^{\mathsf{do}(U,\mathbb{Q})}(\omega_{V},A)\mathbb{P }^{\mathsf{do}(U,\mathbb{Q})}(d\omega_{V})\] \[=\int_{B}K_{V}^{\mathsf{do}(U,\mathbb{Q})}(\omega_{V},A)\mathbb{ Q}(d\omega_{V})\] by above fact \[=\int K_{V}^{\mathsf{do}(U,\mathbb{Q})}(\omega_{V},A\cap B) \mathbb{Q}(d\omega_{V})\] by Axiom 2.2(ii) \[=\int\int\mathbb{Q}(d\omega_{U\setminus V}^{\prime})K_{U}(( \omega_{V},\omega_{U\setminus V}^{\prime}),A\cap B)\mathbb{Q}(d\omega_{V})\] \[=\int K_{U}(\omega_{U},A\cap B)\mathbb{Q}(d\omega_{U})\] \[=\int_{B}1_{A}(\omega)\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})}(d\omega).\] where, in going from the third line to the fourth, we used Theorem C.3, and to go from the fourth line to the fifth, we used the hypothesis that \(\mathbb{Q}\) factorises over \(\mathcal{H}_{V}\) and \(\mathcal{H}_{U\setminus V}\), meaning \(\mathbb{Q}(d\omega_{U\setminus V})\mathbb{Q}(d\omega_{V})=\mathbb{Q}(d\omega _{U})\). So \(K_{V}^{\mathsf{do}(U,\mathbb{Q})}(\omega,A)\) is indeed a version of the conditional probability \(\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})}_{\mathcal{H}_{V}}(A)\), which means that \(\mathcal{H}_{V}\) is a global source of \((\Omega,\mathcal{H},\mathbb{P}^{\mathsf{do}(U,\mathbb{Q})},\mathbb{K}^{ \mathsf{do}(U,\mathbb{Q})})\).

**Lemma C.4**.: Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, and \(U\in\mathcal{P}(T)\), \(\mathbb{Q}\) a probability measure on \((\Omega,\mathcal{H}_{U})\) and \(\mathbb{L}=\{L_{V}:V\in\mathcal{P}(U)\}\) a causal mechanism on \((\Omega,\mathcal{H}_{U},\mathbb{Q})\). Suppose we intervene on \(\mathcal{H}_{U}\) via \((\mathbb{Q},\mathbb{L})\).

1. For \(A\in\mathcal{H}_{U}\) and \(V\in\mathcal{P}(T)\) with \(V\cap U=\emptyset\), \(\mathcal{H}_{V}\) has no causal effect on \(A\) (c.f. Definition B.1(i)) in the intervention causal space \((\Omega,\mathcal{H},\mathbb{P}^{\text{do}(U,\mathbb{Q})},\mathbb{K}^{\text{do} (U,\mathbb{Q},\mathbb{L})})\), i.e. events in the \(\sigma\)-algebra \(\mathcal{H}_{U}\) on which intervention took place are not causally affected by \(\sigma\)-algebras outside \(\mathcal{H}_{U}\).
2. Again, let \(V\in\mathcal{P}(T)\) with \(V\cap U=\emptyset\), and also let \(A\in\mathcal{H}\) be any event. If, in the original causal space, \(\mathcal{H}_{V}\) had no causal effect on \(A\), then in the intervention causal space, \(\mathcal{H}_{V}\) has no causal effect on \(A\) either.
3. Now let \(V\in\mathcal{P}(T)\), \(A\in\mathcal{H}\) any event and suppose that the intervention on \(\mathcal{H}_{U}\) via \(\mathbb{Q}\) is hard. Then if \(\mathcal{H}_{V}\) had no causal effect on \(A\) in the original causal space, then \(\mathcal{H}_{V}\) has no causal effect on \(A\) in the intervention causal space either.

Proof.:
1. Take any \(S\in\mathcal{P}(T)\). See that \[K_{S}^{\text{do}(U,\mathbb{Q},\mathbb{L})}(\omega,A) =\int L_{S\cap U}(\omega_{S\cap U},d\omega^{\prime}_{U})K_{S\cup U }((\omega_{S\setminus U},\omega^{\prime}_{U}),A)\] \[=\int L_{S\cap U}(\omega_{S\cap U},d\omega^{\prime}_{U})1_{A}( \omega^{\prime}_{U})\] \[=\int L_{S\cap U}(\omega_{S\cap U},d\omega^{\prime}_{U})K_{(S \setminus V)\cup U}((\omega_{(S\setminus V)\setminus U},\omega^{\prime}_{U}),A)\] \[=\int L_{(S\setminus V)\cap U}(\omega_{(S\setminus V)\cap U},d \omega^{\prime}_{U})K_{(S\setminus V)\cup U}((\omega_{(S\setminus V)\setminus U },\omega^{\prime}_{U}),A)\] \[=K_{S\setminus V}^{\text{do}(U,\mathbb{Q},\mathbb{L})}(\omega,A)\] where, in going from the first line to the second and from the second line to the third, we used the fact that \(A\in\mathcal{H}_{U}\), and in going from the third line to the fourth, we applied the fact that \((S\setminus V)\cap U=S\cap U\) since \(V\cap U=\emptyset\). Since \(S\in\mathcal{P}(T)\) was arbitrary, \(\mathcal{H}_{V}\) has no causal effect on \(A\) in the intervention causal space.
2. Take any \(S\in\mathcal{P}(T)\). See that \[K_{S}^{\text{do}(U,\mathbb{Q},\mathbb{L})}(\omega,A) =\int L_{S\cap U}(\omega_{S\cap U},d\omega^{\prime}_{U})K_{S\cup U }((\omega_{S\setminus U},\omega^{\prime}_{U}),A)\] \[=\int L_{S\cap U}(\omega_{S\cap U},d\omega^{\prime}_{U})K_{(S \cup U)\setminus V}((\omega_{(S\setminus V)\setminus U},\omega^{\prime}_{U}),A)\] \[=\int L_{(S\setminus V)\cap U}(\omega_{(S\setminus V)\cap U},d \omega^{\prime}_{U})K_{(S\setminus V)\cup U}((\omega_{(S\setminus V) \setminus U},\omega^{\prime}_{U}),A)\] \[=K_{S\setminus V}^{\text{do}(U,\mathbb{Q},\mathbb{L})}(\omega,A)\] where, in going from the first line to the second, we used the fact that \(\mathcal{H}_{V}\) has no causal effect on \(A\) in the original causal space, and in going from the second line to the third, we used \(U\cap V=\emptyset\), which gives us \(S\cap U=(S\setminus V)\cap U\) and \((S\cup U)\setminus V=(S\setminus V)\cup U\). Since \(S\in\mathcal{P}(T)\) was arbitrary, \(\mathcal{H}_{V}\) has no causal effect on \(A\) in the intervention causal space.
3. Take any \(S\in\mathcal{P}(T)\). Apply Theorem C.3 to see that \[K_{S}^{\text{do}(U,\mathbb{Q},\text{hard})}(\omega,A) =\int\mathbb{Q}(d\omega^{\prime}_{U\setminus S})K_{S\cup U}(( \omega_{S},\omega^{\prime}_{U\setminus S}),A)\] \[=\int\mathbb{Q}(d\omega^{\prime}_{U\setminus S})K_{(S\cup U) \setminus V}((\omega_{S},\omega^{\prime}_{U\setminus S}),A)\] Def. B.1 (i) \[=\int\mathbb{Q}(d\omega^{\prime}_{U\setminus S})K_{((S\setminus V )\cup U)\setminus V}((\omega_{S},\omega^{\prime}_{U\setminus S}),A)\] \[=\int\mathbb{Q}(d\omega^{\prime}_{U\setminus S})K_{(S\setminus V) \cup U}((\omega_{S},\omega^{\prime}_{U\setminus S}),A)\] Def. B.1 (i) \[=\int\mathbb{Q}(d\omega^{\prime}_{U\setminus(S\setminus V)})K_{(S \setminus V)\cup U}((\omega_{S\setminus V},\omega^{\prime}_{U\setminus(S \setminus V)}),A)\]\[=K_{S\setminus U}^{\text{do}(U,\mathbb{Q})}(\omega,A),\]

where, in going from the second line to the third, we used that \((S\cup U)\setminus V=((S\setminus V)\cup U)\setminus V\). Since \(S\in\mathcal{P}(T)\) was arbitrary, \(\mathcal{H}_{V}\) has no causal effect on \(A\) in the intervention causal space.

**Lemma C.5**.: Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, and \(U\in\mathcal{P}(T)\). For an event \(A\in\mathcal{H}\), if \(\mathcal{H}_{U}\) has a dormant causal effect on \(A\) in the original causal space, then there exists a hard intervention and a subset \(V\subseteq U\) such that in the intervention causal space, \(\mathcal{H}_{V}\) has an active causal effect on \(A\).

Proof.: That \(\mathcal{H}_{U}\) has a dormant causal effect on \(A\) tells us that \(K_{U}(\omega,A)=\mathbb{P}(A)\) for all \(\omega\in\Omega\), but there exists some \(S\in\mathcal{P}(T)\) and some \(\omega_{0}\in\Omega\) such that \(K_{S}(\omega_{0},A)\neq K_{S\setminus U}(\omega_{0},A)\). We must have \(S\cap U\neq\emptyset\), since otherwise \(S\setminus U=S\) and we cannot possibly have \(K_{S}(\omega_{0},A)\neq K_{S\setminus U}(\omega_{0},A)\). Then we hard-intervene on \(\mathcal{H}_{S\setminus U}\) with the Dirac measure on \(\omega_{0}\). Then apply Theorem C.3 to see that

\[K_{S\cap U}^{\text{do}(S\setminus U,\delta_{\omega_{0}},\text{ hard})}((\omega_{0})_{U\cap S},A) =\int\delta_{\omega_{0}}(d\omega^{\prime}_{S\setminus U})K_{S}((( \omega_{0})_{U\cap S},\omega^{\prime}_{S\setminus U}),A)\] \[=K_{S}(\omega_{0},A)\] \[\neq K_{S\setminus U}(\omega_{0},A)\]

Note that the intervention measure on \(A\) is equal to \(K_{S\setminus U}(\omega_{0},A)\):

\[\mathbb{P}^{\text{do}(S\setminus U,\delta_{\omega_{0}})}(A)=\int\delta_{ \omega_{0}}(d\omega^{\prime}_{S\setminus U})K_{S\setminus U}(\omega^{\prime},A)=K_{S\setminus U}(\omega_{0},A).\]

Putting these together, we have

\[K_{S\cap U}^{\text{do}(S\setminus U,\delta_{\omega_{0}},\text{ hard})}(\omega_{0},A)\neq\mathbb{P}^{\text{do}(S\setminus U,\delta_{\omega_{0}})}(A),\]

i.e. in the intervention causal space \((\Omega,\mathcal{H},\mathbb{P}^{\text{do}(S\setminus U,\delta_{\omega_{0}})},K_{S\cap U}^{\text{do}(S\setminus U,\delta_{\omega_{0}},\text{ hard})})\), \(\mathcal{H}_{S\cap U}\) has an active causal effect on \(A\). 

**Lemma C.6**.: Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t \in T}\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, and \(U,V\in\mathcal{P}(T)\). For an event \(A\in\mathcal{H}\), suppose that \(\mathcal{H}_{U}\) has no causal effect on \(A\) given \(\mathcal{H}_{V}\) (see Definition B.4). Then after an intervention on \(\mathcal{H}_{V}\) via any \((\mathbb{Q},\mathbb{L})\), \(\mathcal{H}_{U\setminus V}\) has no causal effect on \(A\).

Proof.: Take any probability measure \(\mathbb{Q}\) on \((\Omega,\mathcal{H}_{V})\) and any causal mechanism \(\mathbb{L}\) on \((\Omega,\mathcal{H}_{V},\mathbb{Q})\). Then see that, for any \(S\in\mathcal{P}(T)\) and all \(\omega\in\Omega\),

\[K_{S}^{\text{do}(V,\mathbb{Q},\mathbb{L})}(\omega,A) =\int L_{S\cap V}(\omega_{S\cap V},d\omega^{\prime}_{V})K_{S \cup V}((\omega_{S\setminus V},\omega^{\prime}_{V}),A)\] \[=\int L_{S\cap V}(\omega_{S\cap V},d\omega^{\prime}_{V})K_{(S \cup V)\setminus(U\setminus V)}((\omega_{S\setminus(U\cup V)},\omega^{ \prime}_{V}),A)\] \[=\int L_{(S\setminus(U\setminus V))\cap V}(\omega_{(S\setminus(U \setminus V))\cap V},d\omega^{\prime}_{V})K_{(S\setminus(U\setminus V))\cup V }((\omega_{S\setminus(U\cup V)},\omega^{\prime}_{V}),A)\] \[=K_{S\setminus(U\setminus V)}^{\text{do}(V,\mathbb{Q},\mathbb{L} )}(\omega,A),\]

where, in going from the first line to the second, we used the fact that \(\mathcal{H}_{U}\) has no causal effect on \(A\) given \(\mathcal{H}_{V}\), and in going from the second line to the third, we used identities \(S\cap V=(S\setminus(U\setminus V))\cap V\) and \((S\cup V)\setminus(U\setminus V)=(S\setminus(U\setminus V))\cup V\). Since \(S\in\mathcal{P}(T)\) was arbitrary, we have that \(\mathcal{H}_{U\setminus V}\) has no causal effect on \(A\) in the intervention causal space. 

**Theorem C.7**.: Let \((\Omega,\mathcal{H},\mathbb{P},\mathbb{K})=(\times_{t\in T}E_{t},\otimes_{t\in T }\mathcal{E}_{t},\mathbb{P},\mathbb{K})\) be a causal space, where the index set \(T\) can be written as \(T=W\times\tilde{T}\), with \(W\) representing time and \(\mathbb{K}\) respecting time. Take any \(U\in\mathcal{P}(T)\) and any probability measure \(\mathbb{Q}\) on \(\mathcal{H}_{U}\). Then the intervention causal mechanism \(\mathbb{K}^{\text{do}(U,\mathbb{Q},\text{hard})}\) also respects time.

Proof.: Take any \(w_{1},w_{\varnothing}\in W\) with \(w_{1}<w_{2}\). Since \(\mathbb{K}\) respects time, we have that \(\mathcal{H}_{w_{2}\times\hat{T}}\) has no causal effect on \(\mathcal{H}_{w_{1}\times\hat{T}}\) in the original causal space. To show that \(\mathcal{H}_{w_{2}\times\hat{T}}\) has no causal effect on \(\mathcal{H}_{w_{1}\times\hat{T}}\) after a hard intervention on \(\mathcal{H}_{U}\) via \(\mathbb{Q}\), take any \(S\in\mathcal{P}(T)\) and any event \(A\in\mathcal{H}_{w_{1}\times\hat{T}}\). Then using Theorem C.3,

\[K_{S}^{\text{do}(U,\mathbb{Q},\text{hard})}(\omega,A)\] \[=\int\mathbb{Q}(d\omega^{\prime})K_{S\cup U}((\omega_{S},\omega^ {\prime}_{U\setminus S}),A)\] \[=\int\mathbb{Q}(d\omega^{\prime})K_{(S\cup U)\setminus\mathcal{H }_{w_{2}\times\hat{T}}}((\omega_{S\setminus\mathcal{H}_{w_{2}\times\hat{T}}}, \omega^{\prime}_{U\setminus(S\cup\mathcal{H}_{w_{2}\times\hat{T}})}),A)\] \[=\int\mathbb{Q}(d\omega^{\prime})K_{((S\cup U)\setminus\mathcal{H }_{w_{2}\times\hat{T}})\cup(U\cap\mathcal{H}_{w_{2}\times\hat{T}})}((\omega_{S \setminus\mathcal{H}_{w_{2}\times\hat{T}}},\omega^{\prime}_{(U\setminus(S \cup\mathcal{H}_{w_{2}\times\hat{T}}))\cup(U\cap\mathcal{H}_{w_{2}\times\hat{ T}})}),A)\] \[=\int\mathbb{Q}(d\omega^{\prime})K_{(S\setminus\mathcal{H}_{w_{2} \times\hat{T}})\cup U}((\omega_{S\setminus\mathcal{H}_{w_{2}\times\hat{T}}}, \omega^{\prime}_{U\setminus(S\setminus\mathcal{H}_{w_{2}\times\hat{T}})}),A)\] \[=K_{S\setminus\mathcal{H}_{w_{2}\times\hat{T}}}^{\text{do}(U, \mathbb{Q},\text{hard})}(\omega,A)\]

where, from the second line to the third, we used the fact that \(\mathcal{H}_{w_{2}\times\hat{T}}\) has no causal effect on \(A\), from the third line to the fourth we used the fact that \(U\cap\mathcal{H}_{w_{2}\times\hat{T}}\) has no causal effect on \(A\) (by Remark B.2(e)) and Remark B.2(g), and from the fourth line to the fifth, we used that \(((S\cup U)\setminus\mathcal{H}_{w_{2}\times\hat{T}})\cup(U\cap\mathcal{H}_{w_ {2}\times\hat{T}})=(S\setminus\mathcal{H}_{w_{2}\times\hat{T}})\cup U\) and \((U\setminus(S\cup\mathcal{H}_{w_{2}\times\hat{T}}))\cup(U\cap\mathcal{H}_{w_{2 }\times\hat{T}})=U\setminus(S\setminus\mathcal{H}_{w_{2}\times\hat{T}})\). Since \(S\in\mathcal{P}(T)\) was arbitrary, we have that \(\mathcal{H}_{w_{2}\times\hat{T}}\) has no causal effect on \(A\) (Definition B.1(i)). Since \(A\in\mathcal{H}_{w_{1}\times\hat{T}}\) was arbitrary, \(\mathcal{H}_{w_{2}\times\hat{T}}\) has no causal effect on \(\mathcal{H}_{w_{1}\times\hat{T}}\), and so \(\mathbb{K}^{\text{do}(U,\mathbb{Q},\text{hard})}\) respects time.