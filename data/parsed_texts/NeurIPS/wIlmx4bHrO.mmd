A Single-Loop Accelerated Extra-Gradient Difference Algorithm with Improved Complexity Bounds for Constrained Minimax Optimization

 Yuanyuan Liu1, Fanhua Shang2, Weixin An1, Junhao Liu1, Hongying Liu3,2, Zhouchen Lin4,5,6

Footnote 1: Corresponding authors

[MISSING_PAGE_POST]

###### Abstract

In this paper, we propose a novel extra-gradient difference acceleration algorithm for solving constrained nonconvex-nonconcave (NC-NC) minimax problems. In particular, we design a new extra-gradient difference step to obtain an important quasi-cocoercivity property, which plays a key role to significantly improve the convergence rate in the constrained NC-NC setting without additional structural assumption. Then momentum acceleration is also introduced into our dual accelerating update step. Moreover, we prove that, to find an \(\epsilon\)-stationary point of the function \(f\), the proposed algorithm attains the complexity \(\mathcal{O}(\epsilon^{-2})\) in the constrained NC-NC setting, while the best-known complexity bound is \(\widetilde{\mathcal{O}}(\epsilon^{-4})\), where \(\widetilde{\mathcal{O}}(\cdot)\) hides logarithmic factors compared to \(\mathcal{O}(\cdot)\). As the special cases of the constrained NC-NC setting, the proposed algorithm can also obtain the same complexity \(\mathcal{O}(\epsilon^{-2})\) for both the nonconvex-concave (NC-C) and convex-nonconcave (C-NC) cases, while the best-known complexity bounds are \(\widetilde{\mathcal{O}}(\epsilon^{-2.5})\) for the NC-C case and \(\widetilde{\mathcal{O}}(\epsilon^{-4})\) for the C-NC case. For fair comparison with existing algorithms, we also analyze the complexity bound to find \(\epsilon\)-stationary point of the primal function \(\phi\) for the constrained NC-C problem, which shows that our algorithm can improve the complexity bound from \(\widetilde{\mathcal{O}}(\epsilon^{-3})\) to \(\mathcal{O}(\epsilon^{-2})\). To the best of our knowledge, this is the first time that the proposed algorithm improves the best-known complexity bounds from \(\widetilde{\mathcal{O}}(\epsilon^{-4})\) and \(\widetilde{\mathcal{O}}(\epsilon^{-3})\) to \(\mathcal{O}(\epsilon^{-2})\) in both the NC-NC and NC-C settings.

## 1 Introduction

This paper considers the following smooth minimax optimization problem,

\[\min_{x\in\mathcal{X}}\max_{y\in\mathcal{Y}}\,f(x,y),\] (1)where \(\mathcal{X}\subseteq\mathbb{R}^{m}\) and \(\mathcal{Y}\subseteq\mathbb{R}^{n}\) are nonempty closed and convex feasible sets, and \(f:\mathbb{R}^{m}\times\mathbb{R}^{n}\to\mathbb{R}\) is a smooth function. In recent years, this problem has drawn considerable interest from machine learning and other engineering communities such as generative adversarial networks [14], adversarial machine learning [15; 28], game theory [3], reinforcement learning [12; 41], empirical risk minimization [54; 39], and robust optimization [36; 13; 5]. While there is an extensive body of literature on minimax optimization, most prior works such as [54; 39; 42; 33; 50] focus on the convex-concave setting, where \(f(x,y)\) is convex in \(x\) and concave in \(y\). However, in many nonconvex minimax machine learning problems as in [35; 6], \(f(x,y)\) is nonconvex in \(x\) and (strongly) concave in \(y\), or \(f(x,y)\) is (strongly) convex in \(x\) and nonconcave in \(y\). For _nonconvex-strongly-concave_ (NC-SC) minimax problems, a number of efficient algorithms such as [34; 25; 27] were proposed, and their complexity can be \(\widetilde{\mathcal{O}}(\kappa_{y}^{2}\epsilon^{-2})\) for achieving an \(\epsilon\)-stationary point \(\hat{x}\) (e.g., \(\|\nabla\phi(\hat{x})\|\leq\epsilon\)) of the primal function \(\phi(\cdot):=\max_{y\in\mathcal{Y}}f(\cdot,y)\), where \(\kappa_{y}\) is the condition number for \(f(x,\cdot)\), and \(\widetilde{\mathcal{O}}\) hides logarithmic factors. More recently, [24] proposed an accelerated algorithm, which improves the gradient complexity to \(\widetilde{\mathcal{O}}(\sqrt{\kappa_{y}}\epsilon^{-2})\), which exactly matches the lower complexity bound in [52; 23]. Therefore, we mainly consider the problem (1) in nonconvex-nonconcave (NC-NC), nonconvex-concave (NC-C) and convex-nonconcave (C-NC) settings.

### Algorithms in NC-C and C-NC Settings

For _nonconvex-concave_ (NC-C, but not strongly concave) and _convex-nonconcave_ (C-NC) problems, there are two types of algorithms (i.e., multi-loop (including double-loop and triple-loop) and single-loop algorithms), and most of them are multi-loop algorithms such as [18; 31; 40; 24]. [31] proposed a multi-step framework that finds an \(\epsilon\)-first order Nash equilibrium of \(f(x,y)\) with the complexity \(\widetilde{\mathcal{O}}(\epsilon^{-3.5})\). [40] designed a proximal dual implicit accelerated algorithm and proved that their algorithm finds an \(\epsilon\)-stationary point of \(\phi\) with the complexity \(\widetilde{\mathcal{O}}(\epsilon^{-3})\). More recently, [24] proposed an accelerated algorithm, which achieves the complexity \(\widetilde{\mathcal{O}}(\epsilon^{-2.5})\) to find an \(\epsilon\)-stationary point of \(f\). These multi-loop algorithms require at least \(\mathcal{O}(\epsilon^{-2})\) outer iterations, and thus their complexities are more than \(\mathcal{O}(\epsilon^{-2})\). Even though single-loop methods are more popular in practice due to their simplicity, few single-loop algorithms have been proposed for NC-C setting. The most natural approach is the gradient descent-ascent (GDA) method, which performs a gradient descent step on \(x\) and a gradient ascent step on \(y\) at each iteration. However, GDA fails to converge even for simple bilinear zero-sum games [22]. Subsequently, several improved GDA algorithms such as [8; 25; 27; 44] were proposed. For instance, [25] proved that the complexity of their two-time-scale GDA to find an \(\epsilon\)-stationary point of \(\phi\) is \(\mathcal{O}(\epsilon^{-6})\) for NC-C problems. Moreover, [27] presented an efficient algorithm, which obtains an \(\epsilon\)-stationary point of \(f\) with the complexity \(\mathcal{O}(\epsilon^{-4})\). In fact, the complexity only counts the number of times the maximization subproblem is solved, and does not consider the complexity of solving this subproblem. [44] proposed a unified algorithm, and proved that the complexity of their algorithm to find an \(\epsilon\)-stationary point of \(f\) is \(\mathcal{O}(\epsilon^{-4})\) for both NC-C and C-NC problems. More recently, [51] presented a smoothed-GDA algorithm and proved that the complexity can be improved to \(\mathcal{O}(\epsilon^{-2})\) for optimizing a special case of NC-C problems (i.e., minimizing the pointwise maximum of a finite collection of nonconvex functions). However, its complexity is still \(\mathcal{O}(\epsilon^{-4})\) for both NC-C and C-NC problems. One natural question is: can we design a single-loop accelerated algorithm with the optimal complexity bound \(\mathcal{O}(\epsilon^{-2})\) for _both NC-C and C-NC problems_?

### Algorithms in NC-NC Settings

This paper mainly considers constrained NC-NC minimax problems, i.e., \(f(x,y)\) is nonconvex in \(x\) and nonconcave in \(y\) in the constrained setting (called constrained NC-NC). In recent years, some works such as [7; 31; 46; 38; 20] focus on structured NC-NC problems. That is, the saddle gradient operator of such minimax problems or their objectives must satisfy one of the structured assumptions: the minty variational inequality (MVI) condition, the weak MVI condition, or negative comonotone condition and the Polyak-Lojasiewicz condition. However, structured NC-NC problems have limited practical applications because they are required to satisfy strong structural assumptions. For more practical constrained NC-NC problems or more general NC-NC problems, the convergence guarantee of the algorithms is still a challenge. In this paper, we also focus on convergence analysis for solving more practical constrained NC-NC problems. _Another natural question is: can we design a single-loop accelerated algorithm to further improve the bound in the constrained NC-NC setting?_

### Motivations and Our Contributions

**Motivations:** For NC-C minimax problems, can we design a single-loop directly accelerated algorithm with the gradient complexity lower than the best-known result \(\widetilde{\mathcal{O}}(\epsilon^{-2.5})\)? Though Smoothed-GDA [51] can obtain the complexity \(\mathcal{O}(\epsilon^{-2})\) for a special case of Problem (1), it only attains the complexity \(\mathcal{O}(\epsilon^{-4})\) for NC-C minimax problems. For C-NC minimax problems, for any given \(x\), to solve the nonconcave maximization subproblem with respect to \(y\) is NP-hard. As a result, all existing multi-loop algorithms will lose their theoretical guarantees as discussed in [44]. Can we propose a single-loop directly accelerated algorithm with the complexity lower than the best-known result \(\mathcal{O}(\epsilon^{-4})\) for C-NC and NC-NC minimax problems?

**Our Contributions:** This paper proposes a novel single-loop extra-gradient difference acceleration algorithm to push towards optimal gradient complexities for constrained NC-NC minimax problems (1), and answer the above-mentioned problems.

We summarize the major contributions of this paper.

\(\bullet\) We design a new single-loop accelerating algorithm for solving _constrained NC-NC_ problems. In the proposed algorithm, we design a new extra-gradient difference scheme, and combine the gradient ascent and momentum acceleration steps for the dual variable update. In our algorithm, we present an important quasi-cocoercivity property. By leveraging the quasi-cocoercivity property, we can improve the complexity bound in our theoretical analysis.

\(\bullet\) We analyze the convergence properties of the proposed algorithm for _constrained NC-NC_ problems. Theorem 1 shows that to find an \(\epsilon\)-stationary point of \(f\), the proposed algorithm can obtain the gradient complexity \(\mathcal{O}(\epsilon^{-2})\), which is the first time to attains the complexity bound in constrained NC-NC setting. The _constrained NC-C and C-NC_ problems can be viewed as two special cases of the _constrained NC-NC_ problem, and the proposed algorithm is also applicable to these two special problems. And its complexity is still \(\mathcal{O}(\epsilon^{-2})\) for both NC-C and C-NC problems, which significantly improves the gradient complexity from \(\mathcal{O}(\epsilon^{-4})\) of existing single-loop algorithms or \(\widetilde{\mathcal{O}}(\epsilon^{-2.5})\) of existing multi-loop algorithms to \(\mathcal{O}(\epsilon^{-2})\). The complexities of some recently proposed algorithms are listed in Table 1.

\begin{table}
\begin{tabular}{|c|c|c|c|c|c|} \hline Optimality Criteria & References & NC-C & C-NC & NC-NC & Simplicity \\ \hline \hline \multirow{4}{*}{Stationarity of \(f\) with smoothness and compact sets assumptions} & Lu et al. [27] & \(\widetilde{\mathcal{O}}(\epsilon^{-4})\) & - & - & Single-Loop \\  & Nouiehed et al. [31] & \(\widetilde{\mathcal{O}}(\epsilon^{-3.5})\) & - & - & Multi-Loop \\  & Lin et al. [24] & \(\widetilde{\mathcal{O}}(\epsilon^{-2.5})\) & - & - & Multi-Loop \\  & Zhang et al. [51] & \(\mathcal{O}(\epsilon^{-4})\) & - & - & Single-Loop \\  & Xu et al. [44] & \(\mathcal{O}(\epsilon^{-4})\) & \(\mathcal{O}(\epsilon^{-4})\) & - & Single-Loop \\  & **This work** (Theorem 1) & \(\mathcal{O}(\epsilon^{-2})\) & \(\mathcal{O}(\epsilon^{-2})\) & \(\mathcal{O}(\epsilon^{-2})\) & Single-Loop \\ \hline \end{tabular}
\end{table}
Table 1: Comparison of complexities of the minimax algorithms to find an \(\epsilon\)-stationary point of \(f(\cdot,\cdot)\) in the NC-C, C-NC and NC-NC settings. Note that Smoothed-GDA [51] can find an \(\epsilon\)-stationary point for a special problem of (1) with \(\mathcal{O}(\epsilon^{-2})\), and \(\widetilde{\mathcal{O}}\) hides logarithmic factors compared to \(\mathcal{O}(\cdot)\).

\begin{table}
\begin{tabular}{|c|c|c|c|c|} \hline NC-C Settings & References & Compact set & Complexity & Simplicity \\ \hline \hline \multirow{4}{*}{
\begin{tabular}{c} (Stationarity of \(\phi\)) \\ \end{tabular} } & Rafique et al. [34], Jin et al. [17] & \(\mathcal{X},\mathcal{Y}\) & \(\widetilde{\mathcal{O}}(\epsilon^{-6})\) & Multi-Loop \\  & Lin et al. [25] & \(\mathcal{X},\mathcal{Y}\) & \(\widetilde{\mathcal{O}}(\epsilon^{-6})\) & Single-Loop \\ \cline{1-1}  & Thekumprampil et al. [40] & \(\mathcal{X},\mathcal{Y}\) & \(\widetilde{\mathcal{O}}(\epsilon^{-3})\) & Multi-Loop \\  & Zhao [55], Lin et al. [24] & \(\mathcal{X},\mathcal{Y}\) & \(\widetilde{\mathcal{O}}(\epsilon^{-3})\) & Multi-Loop \\  & **This work** (Theorem 2) & \(\mathcal{Y}\) & \(\mathcal{O}(\epsilon^{-2})\) & Single-Loop \\ \hline \end{tabular}
\end{table}
Table 2: Comparison of complexities of existing minimax algorithms and the proposed algorithm to find an \(\phi(\cdot):=\max_{y\in\mathcal{Y}}f(\cdot,y)\) in the nonconvex-concave (NC-C) setting. This table only highlights the dependence of \(\epsilon\), and compared with \(\mathcal{O}(\cdot)\), \(\widetilde{\mathcal{O}}(\cdot)\) hides logarithmic factors.

\(\bullet\) In order to make a comprehensive comparison with existing algorithms, we also provide the theoretical analysis of our algorithm in terms of another convergence criteria (i.e., an \(\epsilon\)-stationary point of \(\phi\)) for constrained NC-C problems. The result shows that our algorithm improves the best-known result as in [40; 24; 55] from \(\widetilde{\mathcal{O}}(\epsilon^{-3})\) to \(\mathcal{O}(\epsilon^{-2})\), as shown in Table 2.

## 2 Preliminaries and Related Works

**Notation:** Throughout this paper, we use lower-case letters to denote vectors such as \(x,y\), and calligraphic upper-case letters to denote sets such as \(\mathcal{X},\mathcal{Y}\). For a differentiable function \(f\), \(\nabla\!f(x)\) is the gradient of \(f\) at \(x\). For a function \(f(\cdot,\cdot)\) of two variables, \(\nabla_{x}f(x,y)\) (or \(\nabla_{y}f(x,y)\)) is the partial gradient of \(f\) with respect to the first variable (or the second variable) at \((x,y)\). For a vector \(x\), \(\|x\|\) denotes its \(\ell_{2}\)-norm. We use \(\mathcal{P}_{\mathcal{X}}\) and \(\mathcal{P}_{\mathcal{Y}}\) to denote projections onto the sets \(\mathcal{X}\) and \(\mathcal{Y}\).

**Assumption 1** (Smoothness).: \(f(\cdot,\cdot)\) _is continuously differentiable, and there exists a positive constant \(L\) such that_

\[\|\nabla_{x}f(x_{1},y_{1})\!-\!\nabla_{x}f(x_{2},y_{2})\|\leq L\|x_{1}\!-\!x_ {2}\|,\ \|\nabla_{y}f(x_{1},y_{1})\!-\!\nabla_{y}f(x_{2},y_{2})\|\leq L\|y_{1}\!-\!y_ {2}\|\]

_holds for all \(x_{1},x_{2}\in\mathbb{R}^{m}\), \(y_{1},y_{2}\in\mathbb{R}^{n}\)._

**Definitions of the monotone operators:** A operator \(F(\cdot):\mathbb{R}^{n}\to\mathbb{R}^{n}\) is monotone, if \([F(s)-F(t)]^{T}(s-t)\geq 0,\,\forall s,t\in\mathbb{R}^{n}\). If \([F(s)-F(t)]^{T}(s-t)\leq 0\), \(F\) is negative monotone.

A mapping \(F(\cdot)\) is co-coercive if there is a positive constant \(\alpha\), such that

\[[F(s)-F(t)]^{T}(s-t)\geq\alpha\|F(s)-F(t)\|^{2},\,\forall s,t\in\mathbb{R}^{n}.\]

**Nonconvex-Concave Minimax Optimization:** Due to the nonconvex nature of these minimax problems, finding the global solution is NP-hard in general. The recently proposed algorithms aim to find stationary solutions to such problems. For instance, the first-order Nash equilibrium condition (called game stationary) is used as an optimality condition in [31]. Besides game stationary, there are two main optimality criteria (i.e., an \(\epsilon\)-stationary point of \(f(\cdot,\cdot)\) or \(\phi(\cdot):=\max_{y\in\mathcal{Y}}f(\cdot,y)\)) for the convergence analysis of the algorithms such as [4; 44; 24].

For solving NC-C minimax problems, there exist a number of efficient multi-loop and single-loop algorithms such as [31; 25; 4; 44; 24]. Most of them are multi-loop algorithms, which either employ an accelerated update rule of \(x\) by adding regularization terms to its subproblem, or use multiple gradient ascent steps for the update of \(y\) to solve the subproblem exactly or inexactly. Compared with multi-loop algorithms, single-loop algorithms are easier to implement. One of the most popular single-loop algorithms is GDA. However, GDA with a constant stepsize can fail to converge even for a simple bilinear minimax problem [29].

To address this issue, only a few single-loop algorithms such as [25; 27; 44] were proposed, and most of them employed a smoothing or proximal point technique. For instance, Smoothed-GDA [51] introduces a smooth function \(\varphi(x,y,z)\!=\!f(x,y)+\frac{\alpha}{2}\|x\!-\!z\|^{2}\) for the update of the primal variable \(x\), where \(z\) is an auxiliary variable and \(a\) is a constant, and its main update steps are

\[x_{t+1}\!=\!\mathcal{P}_{\mathcal{X}}(x_{t}\!-\!\eta_{x}\nabla_{x}\varphi(x_{ t},z_{t},y_{t}))\,,\,y_{t+1}\!=\!\mathcal{P}_{\mathcal{Y}}(y_{t}\!+\!\eta_{y} \nabla_{y}f(x_{t+1},y_{t}))\,,\,z_{t+1}\!=\!z_{t}\!+\!\beta(x_{t+1}\!-\!z_{t}),\]

where \(\eta_{x},\eta_{y}\!>\!0\) are two stepsizes, and \(0\!<\!\beta\!\leq\!1\). Smoothed-GDA can obtain the gradient complexity, \(\mathcal{O}(\epsilon^{-4})\), for nonconvex-concave minimax problems.

**Extra-Gradient Methods:** There are some extra-gradient methods such as [48] for solving minimax problems. Let \(\eta_{0}>0\) and \(u_{t}\) be the \(t\)-th iterate, the extra-gradient method [53] has the following projection-type prediction-correction step:

\[\text{Prediction}:u_{t+1/2}=\mathcal{P}_{\Omega}\left(u_{t}-\eta_{t}F(u_{t}) \right),\,\text{Correction}:u_{t+1}=\mathcal{P}_{\Omega}\left(u_{t}-\eta_{t}F( u_{t+1/2})\right).\]

In this paper, we call \(u_{t+1/2}\) as the prediction point at the \(t\)-iteration.

## 3 Single-Loop Extra-Gradient Difference Acceleration Algorithm

In this section, we propose a single-loop Extra-Gradient Difference Acceleration algorithm (EGDA) for solving constrained NC-NC minimax problems.

### Extra-Gradient Difference Acceleration

In recent years, many algorithms such as [27; 31; 32; 24; 51; 44] have been proposed for solving NC-C minimax problems. In essence, most of them are "indirect" acceleration algorithms, which are used to optimize the surrogate functions with a smoothing or proximal point term instead of the original function. However, this may hurt the performance of these algorithms both in theory and in practice [2; 1]. To address this issue, we propose a single-loop directly accelerating algorithm to find an \(\epsilon\)-stationary points of \(f\) and \(\phi\) with a significantly improved complexity \(\mathcal{O}(\epsilon^{-2})\). The main update steps of our EGDA algorithm are designed as follows.

\(\bullet\) Gradient descent:

\[x_{t+1}=\arg\min_{x\in\mathcal{X}}\{\langle\nabla_{\!x}f(x_{t},y_{t}),\,x \rangle+\|x\!-\!x_{t}\|^{2}/\eta_{x}\}.\] (2)

\(\bullet\) Extra-gradient difference prediction:

\[u_{t+1/2}=y_{t}+\beta[\nabla_{\!y}f(x_{t},u_{t-1/2})\!-\!\nabla_{\!y}f(x_{t},y _{t-1})].\] (3)

\(\bullet\) Gradient ascent correction:

\[u_{t+1}\!=\!\arg\max_{u\in\mathcal{Y}}\{\langle\nabla_{\!y}f(x_{t},u_{t-1/2}), \,u\rangle-\|u\!-\!y_{t}\|^{2}/\eta_{y}^{t}\}.\] (4)

\(\bullet\) Momentum acceleration:

\[y_{t+1}=\tau y_{t}+(1-\tau)u_{t+1}.\] (5)

Here, \(0<\beta<\frac{1}{L}\), \(\eta_{x},\eta_{y}^{t}>0\) are two stepsizes, \(u_{t+1/2},u_{t+1}\) are auxiliary variables, \(u_{t+1/2}\) is a prediction point, and \(1/2<\tau\leq 1\) is a momentum parameter. Our EGDA algorithm is formally presented in Algorithm 1. Our EGDA algorithm first performs one proximal gradient descent step on the primal variable \(x\), and then we design a new dual-accelerating scheme in (3), (4) and (5) for the dual variable \(y\).

```
1:Initialize:\(x_{0},y_{0},u_{0},u_{-1/2}\),\(\tau>0.5\), \(\eta_{x}\), \(\eta_{y}^{t}\), \(\beta\).
2:for\(t=0,1,\ldots,T-1\)do
3:\(x_{t+1}=\mathcal{P}_{\!\mathcal{X}}\big{[}x_{t}\!-\!\eta_{x}\nabla_{\!x}f(x_ {t},y_{t})\big{]}\); \(u_{t+1/2}\!=\!y_{t}\!+\!\beta[\nabla_{\!y}f(x_{t},u_{t-1/2})\!-\!\nabla_{\!y }f(x_{t},y_{t-1})]\);
4:\(u_{t+1}\!=\!\mathcal{P}_{\!\mathcal{Y}}\left[y_{t}\!+\!\eta_{y}^{t}\nabla_{\!y }f(x_{t},u_{t\!-\!1/2})\right]\); \(y_{t+1}=\tau y_{t}+(1-\tau)u_{t+1}\);
5:endfor
6:Output:\((x_{T},y_{T})\). ```

**Algorithm 1** EGDA for NC-NC minimax problems

### Advantages of Our Algorithm and Comparison to Related Work

We first design a new prediction point \(u_{t+1/2}\) in Eq. (3). Compared with extra-gradient-type methods such as [7; 16; 20], one of the main differences is that the proposed prediction point \(u_{t+1/2}\) in (3) is updated by the gradient difference (i.e., \(\nabla_{\!y}f(x_{t},u_{t-1/2})-\nabla_{\!y}f(x_{t},y_{t-1})\)), while the prediction point in other extra-gradient-type algorithms is updated only by using the gradient information at the correction point \(u_{t}\). Then the gradient at the new prediction point \(u_{t+1/2}\) is used in the gradient ascent step (4). And the dual variable \(y\) is update by the momentum acceleration step in (5).

\(\bullet\)**Prediction Point:** The monotonicity and co-coercivity properties of gradient operators play a crucial role for convergence analysis. However, these important properties do not always hold for nonconvex problems. Some researchers have made great progress in some special nonconvex settings, such as structured nonconvex and weakly convex settings, which require a weaker condition such as weakly monotone [26], pseudo-monotone [16], and MVI [7]. However, such conditions seriously limit the application scope of Problem (1).

To address this challenge, we design a new prediction point scheme in (3), which can help us obtain a useful quasi-cocoercivity property. As a result, it does not require any monotone or structural assumption. Specifically, we find that we only require a weaker property in our theoretical analysis, that is, the co-coercivity is required at some special points \(\{u_{t+1/2},y_{t}\}\) (\(\langle\nabla_{\!y}f(x_{t},u_{t+1/2})-\nabla_{\!y}f(x_{t},y_{t}),u_{t+1/2}-y_{ t}\rangle\geq\beta\|\nabla_{\!y}f(x_{t},u_{t+1/2})-\nabla_{\!y}f(x_{t},y_{t})\|^{2}\) with \(\beta>0\)). Thus, we develop adecoupling idea to construct the prediction point \(u_{t+1/2}\). That is, we use the gradients with respect to \(y\) at \(u_{t-1/2},y_{t-1}\) instead of those at the points \(u_{t+1/2},y_{t}\). We can obtain a property (called the quasi-co-coercivity) in Section 4.2, which plays a key role in our theoretical analysis.

\(\bullet\)**Gradient Difference:** We also briefly discuss the underlying intuition of the proposed gradient difference in (3). We find that the proposed update in (3) is similar to the forms in [43] (see Eqs. (12) and (14) in [43]). [43] proposed a first-order procedure (i.e., difference of gradients) to achieve the negative curvature of a Hessian matrix. Therefore, our algorithm has a similar procedure, which contains second-order information. Moreover, we use the difference of gradients in the gradient ascent procedure for the dual update. But our EGDA algorithm only requires the Lipschitz gradient assumption for minimax problems to find first-order stationary points, while [43] requires both the Lipschitz gradient and Lipschitz Hessian assumptions for solving second-order stationary points of nonconvex minimization problems.

\(\bullet\)**Momentum Acceleration:** We design a dual-accelerating update rule in (4) for the dual variable \(y\) in our EGDA algorithm, which is different from standard momentum acceleration schemes as in [31; 40; 24]. That is, the accelerated rules of existing algorithms are for the primal variable \(x\), while our accelerated rule is designed for the dual variable \(y\).

Therefore, the proposed new dual-accelerating step (including the gradient different prediction step in (3), the gradient ascent correction in (4) and momentum acceleration in (5)) is a key accelerated technique for our EGDA algorithm, and can help to improve the complexity bound from \(\mathcal{O}(\epsilon^{-4})\) to \(\mathcal{O}(\epsilon^{-2})\). In particular, our EGDA algorithm performs both gradient descent and ascent steps to the original function \(f\). In contrast, many existing algorithms such as [51; 47; 44; 18] optimize their surrogate functions with smoothing terms instead of the original function. In particular, their smoothing parameters need to tune by repeatedly executing the algorithms, which may make them impractical [1]. As in our theoretical guarantees below, the proposed single-loop algorithm is able to significantly improve the best-known gradient complexity, \(\mathcal{O}(\epsilon^{-4})\), of existing single-loop algorithms such as [27; 51; 44] to \(\mathcal{O}(\epsilon^{-2})\).

## 4 Convergence Guarantees

In this section, we provide the convergence guarantees of our EGDA algorithm (i.e., Algorithm 1) for solving constrained NC-NC and NC-C problems. We first present the definitions of the two optimality criteria (i.e., an \(\epsilon\)-stationary point of \(f\) or \(\phi\)). All the proofs of the lemmas, properties and theorems below are included in the Supplementary Material.

### Optimality Criteria and Key Property

Since finding a global minimum of a nonconvex optimization problem is NP-hard, finding a global saddle point (or Nash equilibrium) of a NC-NC function \(f\) is intractable [30]. As in the literature in the _NC-NC_ setting, we introduce the local surrogates (i.e., the stationary point of \(f\)) and in the _NC-C setting_, we introduce the local surrogates (i.e., the stationary point of \(f\) or \(\phi\)), whose gradient mappings are equal to zero. Below we define the following two optimality measures (i.e., an \(\epsilon\)-stationary points of \(f\) or \(\phi\)) for our theoretical analysis.

**Definition 1** (An \(\epsilon\)-stationary point of \(f\)[27]).: _A point \((\overline{x},\overline{y})\in\mathcal{X}\times\mathcal{Y}\) is an \(\epsilon\)-stationary point of \(f(\cdot,\cdot)\) if \(\|\pi(\overline{x},\overline{y})\|\leq\epsilon\), where \(\eta_{x}\) and \(\eta_{y}\) are two constants, and_

\[\pi(\overline{x},\overline{y}):=\begin{bmatrix}(1/\eta_{x})(\overline{x}- \mathcal{P}_{\mathcal{X}}(\overline{x}-\eta_{x}\nabla_{x}f(\overline{x}, \overline{y})))\\ (1/\eta_{y})(\overline{y}-\mathcal{P}_{\mathcal{Y}}(\overline{y}+\eta_{y} \nabla_{y}f(\overline{x},\overline{y})))\end{bmatrix}.\] (6)

_If \(\epsilon=0\), then \((\overline{x},\overline{y})\) is a stationary point of \(f\)._

For the _NC-C_ setting, we also present another convergence criterion used in [40; 24]. Let \(\phi(x):=\max_{y\in\mathcal{Y}}f(x,y)\), \(\hat{x}\) is called an \(\epsilon\)-stationary point of a smooth primal function \(\phi:\mathbb{R}^{m}\to\mathbb{R}\), if \(\|\nabla\phi(\hat{x})\|\leq\epsilon\). However, the function \(\phi\) is not necessarily differentiable for minimax problems. Following [9; 40; 24], we introduce the Moreau envelope of \(\phi\) for the optimality criterion, especially when \(\phi\) is a weakly convex function, i.e., \(\phi\) is \(L\)-weakly convex if the function \(\phi(\cdot)+\frac{L}{2}\|\cdot\|^{2}\) is convex. We refer readers to [9; 24] for the comparison of these two criteria.

**Definition 2** (An \(\epsilon\)-stationary point of \(L\)-weakly convex function \(\phi\)).: \(\hat{x}\) _is an \(\epsilon\)-stationary point of an \(L\)-weakly convex function \(\phi:\mathbb{R}^{m}\!\to\!\mathbb{R}\), if \(\|\nabla\phi_{1/(2L)}(\hat{x})\|\!\leq\!\epsilon\), where \(\phi_{1/(2L)}\) is the Moreau envelope of \(\phi\) and is defined as: \(\phi_{\rho}(x)\!:=\!\min_{z}\phi(z)\!+\!(1/2\rho)\|z\!-\!x\|^{2}\). If \(\epsilon=0\), then \(\hat{x}\) is a stationary point._

Then we give the following important property for the analysis of the proposed algorithm. By leveraging the property, we can obtain the complexity bound of the proposed algorithm.

**Property 1** (**Quasi-Cocoercivity**).: _Let \(u_{t+1/2}\) be updated in Eq. (3), then_

\[\big{\langle}\nabla_{y}f(x_{t},u_{t-1/2})-\nabla_{y}f(x_{t},y_{t-1}),\ u_{t+1/ 2}-y_{t}\big{\rangle}=\beta\|\nabla_{y}f(x_{t},u_{t-1/2})-\nabla_{y}f(x_{t},y_ {t-1})\|^{2}.\]

### Core Lemma

Our theoretical results mainly rely on Lemma 1 below, which plays a key role in the proofs of Theorems 1 and 2. Let \(\{(x_{t},y_{t},u_{t},u_{t-1/2})\}\) be a sequence generated by Algorithm 1, and we define the potential function

\[G_{t}:=f(x_{t},y_{t})\!+\!9L\|u_{t}\!-\!y_{t\!-\!1}\|^{2}\!+\!8L\beta^{2}\| \nabla_{y}f(x_{t-1},u_{t-3/2})\!-\!\nabla_{y}f(x_{t-1},y_{t-2})\|^{2}.\]

Next, we need to prove that our defined potential function can make sufficient decrease at each iteration, i.e., \(G_{t}-G_{t+1}\!>\!0\) as in Lemma 1 below. To prove Lemma 1, we will provide and prove the following upper bounds.

**Proposition 1** (Upper bound of primal-dual updates).: _Suppose Assumption 1 holds. Let \(\{(x_{t},y_{t},u_{t})\}\) be a sequence generated by Algorithm 1 with \(\eta_{y}^{t}\!\!=\!\!\min\{\frac{\beta\|\nabla_{y}f(x_{t}\,u_{t-1/2})-\nabla_ {y}f(x_{t},y_{t-1})\|^{2}}{2\|\nabla_{y}f(x_{t},u_{t-1/2})\|^{2}},\frac{1}{28L },\eta_{x}\}\)._

\[f(x_{t+1},u_{t+1/2})\!-\!f(x_{t},y_{t})\] \[\leq\!\!-\left(\frac{1}{\eta_{x}}-\frac{L}{2}\right)\|x_{t+1}\!- \!x_{t}\|^{2}\!+\!L\|u_{t+1/2}-y_{t}\|^{2}+L\|y_{t}-y_{t-1}\|^{2}\!+\!\underbrace {\big{\langle}\nabla_{y}f(x_{t},y_{t-1}),u_{t+1/2}\!-\!y_{t}\big{\rangle}}_{A _{1}}.\]

**Proposition 2** (Upper bound of dual updates).: _Suppose Assumption 1 holds. Let \(\{(x_{t},y_{t},u_{t})\}\) be a sequence generated by Algorithm 1, then_

\[f(x_{t\!+\!1},y_{t\!+\!1})\!-\!f(x_{t+1},u_{t+1/2})\] \[\leq\!\underbrace{\tau\big{\langle}\nabla_{y}f(x_{t}\,u_{t-1/2}), y_{t}\!-\!u_{t+1}\big{\rangle}}_{A_{2}}\!+\!\underbrace{\big{\langle}\nabla_{y}f(x_{t},\!u_{t-1/2}),\!u_{t+1}\!-\!u_{t+1/2}\big{\rangle}}_{A_{3}}+\!a_{t},\]

_where \(a_{t}:=2L\|x_{t+1}\!-\!x_{t}\|^{2}\!+\!6L\beta^{2}\|\nabla_{y}f(x_{t},u_{t-1/ 2})\!-\!\nabla_{y}f(x_{t},y_{t-1})\|^{2}\!+\!8L(1-\tau)^{2}\|u_{t}\!-\!y_{t\!- \!1}\|^{2}+8L\beta^{2}\|\nabla_{y}f(x_{t-1},u_{t-3/2})\!-\!\nabla_{y}f(x_{t-1}, y_{t-2})\|^{2}+3L\|u_{t+1}\!-\!y_{t}\|^{2}\)._

Using the optimal condition of Problem (4) and our quasi-cocoercivity in Property 1, we can further bound \(A_{1}+A_{2}+A_{3}\). The proof sketch of Lemma 1 is listed as follows:

\[G_{t+1}\!\!-\!G_{t} :=\!\underbrace{f(x_{t\!+\!1},y_{t\!+\!1})\!-\!f(x_{t\!+\!1},u_{t \!+\!1/2})}_{\text{Proposition 1}}\!+\!\underbrace{f(x_{t\!+\!1},u_{t\!+\!1/2})\!-\!f(x_{t},y_{t })}_{\text{Proposition 2}}+\!\text{other terms}\] \[=\underbrace{A_{1}+A_{2}+A_{3}}_{\text{Quasi-Cocoercivity in Property 1}}+\quad\text{other terms}.\]

Combining the above results and the definition of \(G_{t}\), we can get the descent estimate of the potential function in Lemma 1, which is a main lemma for Theorems 1 and 2 below.

**Lemma 1** (Descent estimate of \(G\)).: _Suppose Assumption 1 holds. Let \(\{(x_{t},y_{t},u_{t})\}\) be a sequence generated by Algorithm 1, then_

\[G_{0}-G_{T}\] \[=\sum_{t=0}^{T-1}\left(G_{t}-G_{t+1}\right)\] \[\geq\sum_{t=0}^{T-1}\left(\!\frac{1}{4\eta_{y}^{t}}\|u_{t+1}-y_{t }\|^{2}\!+\!\frac{\beta\!-\!30L\beta^{2}}{2}\|\nabla_{y}f(x_{t},u_{t-1/2})\!- \!\nabla_{y}f(x_{t},y_{t-1})\|^{2}\!+\!\frac{1}{2\eta_{x}}\|x_{t\!+\!1}\!-\!x_{t }\|^{2}\!\right).\]

### Convergence Results

In this subsection, by using the optimality measure in Definitions 1 and 2, we present the following theoretical results in Theorem 1 and Theorem 2 for the constrained NC-NC setting and NC-C setting, respectively.

**Assumption 2**.: \(\mathcal{Y}\) _is a closed, convex and compact set with a diameter \(D_{\mathcal{Y}}>0\), and \(\mathcal{X}\) is a closed and convex set._

Furthermore, using Lemma 1 and the optimality measure in Definition 1, we will study the relation between \(\pi(x_{t},u_{t})\) and the difference (i.e., \(G_{t}-G_{t+1}\)) to obtain the gradient complexity in Theorem 1 by computing the number of iterations to achieve an \(\epsilon\)-stationary point of \(f\).

**Theorem 1** (Stationarity of \(f\) in constrained NC-NC settings).: _Suppose Assumptions 1 and 2 hold. Let the two stepsizes \(\eta_{x}\leq\frac{1}{4L}\), \(\eta_{y}^{t}=\min\{\frac{\beta\|\nabla_{y}f(x_{t},u_{t-1/2})-\nabla_{y}f(x_{t},y_{t-1})\|^{2}}{2\|\nabla_{y}f(x_{t},u_{t-1/2})\|^{2}},\frac{1}{2\delta L}, \eta_{x}\}\), \(\beta\leq\frac{1}{60L}\) and \(\tau\geq 1/2\), then the complexity of Algorithm 1 to find an \(\epsilon\)-stationary point of \(f\) is bounded by_

\[\mathcal{O}\Big{(}\frac{G_{0}-\underline{G}+2LD_{\mathcal{Y}}^{2}}{\epsilon^{ 2}}\Big{)},\]

_where \(G_{0}:=G(x_{0},y_{0})\), and \(\underline{G}:=\min_{x\in\mathcal{X}}\phi(x)\)._

**Remark 1**.: _For constrained NC-NC problems, the gradient complexity of our EgDA algorithm to find an \(\epsilon\)-stationary point of \(f\) is \(\mathcal{O}(\epsilon^{-2})\). That is, our EgDA algorithm is first to obtain the gradient complexity in constrained NC-NC setting. In addition, our method can achieve the same complexity, \(\mathcal{O}(\epsilon^{-2})\), as the algorithm with an additional structured assumption for NC-NC problems. However, different from existing algorithms, our algorithm is more practical. That is, it only requires that \(\mathcal{Y}\) is a compact set, while existing algorithms need some stronger structured assumptions in the structured NC-NC setting. The detailed comparison is shown in Table 1. As two special cases of the constrained NC-NC problem, this theoretical result in Theorem 1 can be extended to the constrained NC-C and C-NC settings. For NC-C problems, the gradient complexity of our EgDA algorithm to find an \(\epsilon\)-stationary point of \(f\) is \(\mathcal{O}(\epsilon^{-2})\), while the best-known result of single-loop algorithms such as [27; 51; 44] is \(\mathcal{O}(\epsilon^{-4})\), and the best-known result of multi-loop algorithms such as [24] is \(\widetilde{\mathcal{O}}(\epsilon^{-2.5})\). That is, our EgDA algorithm improves the best-known gradient complexity from \(\widetilde{\mathcal{O}}(\epsilon^{-2.5})\) to \(\mathcal{O}(\epsilon^{-2})\). Smoothed-GDA [51] can also obtain the complexity \(\mathcal{O}(\epsilon^{-2})\) for a special case of Problem (1) and \(\mathcal{O}(\epsilon^{-4})\) for general NC-C minimax problems, while our algorithm attains the optimal result \(\mathcal{O}(\epsilon^{-2})\) for all NC-C minimax problems. Existing algorithms such as HiBSA [27] and AGP [44] require the compactness of the domain \(\mathcal{X}\) in the NC-C setting, while our EgDA algorithm does not, which significantly extends its applicability. For C-NC minimax problems, the proposed algorithm can obtain the complexity, \(\mathcal{O}(\epsilon^{-2})\), while the best-known complexity as in [44] is \(\mathcal{O}(\epsilon^{-4})\). In other words, the proposed algorithm can improve the best-known result from \(\mathcal{O}(\epsilon^{-4})\) to \(\mathcal{O}(\epsilon^{-2})\)._

By using the criterion in Definition 2 as the optimality measure, we use the definition of \(\phi_{1/2L}\) and introduce the property of \(\nabla\phi_{1/2L}\) as in [24]. With a similar setting for varying stepsizes as in [24], we study the relation between \(\nabla\phi_{1/2L}\) and the basic descent estimation of the potential function in Lemma 1 by using the property of \(\nabla\phi_{1/2L}\), and compute the number of iterations to achieve an \(\epsilon\)-stationary point of \(\phi\). We provide the following theoretical result and its detailed proof in the Supplementary Material.

**Theorem 2** (Stationarity of \(\phi\) for constrained NC-C settings).: _Using the same notation as in Theorem 1, and \(f\) is concave with respect to \(y\). Let \(\{(x_{t},y_{t},u_{t})\}\) be a sequence generated by Algorithm 1 with the stepsizes \(\eta_{y}^{t}\!=\!\min\{\frac{\beta a_{t}^{2}}{2b_{t}^{2}},\frac{1}{2\delta L}, \frac{\beta a_{t}^{2}}{2b_{t}^{2}},\frac{\beta c_{t}^{2}}{2d_{t}}\}\), where \(a_{t}\!:=\!\|\nabla_{y}f(x_{t},\!u_{t\!-\!1/2})\!-\!\nabla_{y}f(x_{t},y_{t\!- \!1})\|\!,b_{t}\!:=\!\|\nabla_{y}f(x_{t},u_{t\!-\!1/2})\|\!,c_{t}\!:=\!\|\nabla_ {y}f(x_{t},u_{t\!-\!1/2})\|\!,d_{t}\!:=\!\|\nabla_{y}f(x_{t},u_{t\!-\!1/2})\!- \!\nabla_{y}f(x_{t},u_{t\!-\!1/2})\|\). Then the gradient complexity of Algorithm 1 to find an \(\epsilon\)-stationary point of \(\phi\) is bounded by_

\[\mathcal{O}\Big{(}\frac{D_{\mathcal{Y}}(G_{0}-\underline{G}+2LD_{\mathcal{Y}}^{ 2})}{\epsilon^{2}}\Big{)}.\]

**Remark 2**.: _From Theorem 2, it is clear that the gradient complexity of the proposed algorithm is \(\mathcal{O}(\epsilon^{-2})\). That is, Algorithm 1 can improve the best-known gradient complexity from \(\widetilde{\mathcal{O}}(\epsilon^{-3})\) as in [24] to \(\mathcal{O}(\epsilon^{-2})\). Therefore, Algorithm 1 is the first algorithm, which attains the gradient complexity \(\mathcal{O}(\epsilon^{-2})\) to find an \(\epsilon\)-stationary point of \(\phi\) for NC-C minimax problems._

## 5 Numerical Results

We conduct many experiments to illustrate the performance of the proposed algorithm for solving NC-NC, NC-C and convex-concave problems.

**NC-NC Problems.** We conduct some experiments to illustrate the performance of the proposed algorithm, EGDA, for solving NC-NC problems. Moreover, we compare it against existing methods such as GDA [46], EG [10], EAG [49] and FEG [20]. Detailed setup is provided in the Supplementary Material.

We compare EGDA with GDA, EG and FEG for solving a simple NC-NC minimax problem (i.e., \(f(x,y)\!=\!x^{2}+3\sin^{2}\!x\sin^{2}\!y\!-\!4y^{2}\!-\!4y^{2}\!-\!10\sin^{2}\!y\)), which satisfies the Polyak-Lojasiewicz condition, as shown in Fig. 1. All the results show that EGDA indeed converges to the global saddle point and is significantly faster than other methods including GDA and FEG in terms of both \(\|x_{t}-x^{*}\|^{2}+\|y_{t}-y^{*}\|^{2}\) and \(\|\nabla_{\!x}f\|^{2}+\|\nabla_{\!y}f\|^{2}\). Although FEG has a fast theoretical rate, \(\mathcal{O}(1/t^{2})\), with a negative monotone assumption, it converges much slower than EGDA in practice.

**Convex-Concave Problems.** Fig. 2 shows the convergence results of the methods including GDA, EAG [49] and EGDA for solving the convex-concave problem, \(f(x,y)=\log(1+e^{x})+3xy-\log(1+e^{y})\). It is clear that EGDA converges much faster than other methods such as EAG. We also observe empirically when the same step-size is used, even if small, GDA may not converge to stationary points, and it is proven to always have bounded iterates.

**NC-C Problems.** We also apply our EGDA algorithm to train robust neural networks against adversarial attacks on Fashion MNIST and MNIST, and verify our theoretical results. In [15; 28; 31],

Figure 1: Comparison of all the methods for solving the NC-NC problem, \(f(x,y)=x^{2}+3\sin^{2}\!x\sin^{2}\!y-4y^{2}-10\sin^{2}\!y\). Left: Convergence in terms of \(\|x_{t}-x^{*}\|^{2}+\|y_{t}-y^{*}\|^{2}\), where \((x^{*},y^{*})\) is the global saddle point; Right: Convergence in terms of \(\|\nabla_{\!x}f\|^{2}+\|\nabla_{\!y}f\|^{2}\).

Figure 2: Comparison of all the methods for solving the convex-concave problem, \(f(x,y)=\log(1+e^{x})+3xy-\log(1+e^{y})\). Left: Trajectories of the three algorithms; Right: Convergence in terms of \(\|x_{t}-x^{*}\|^{2}+\|y_{t}-y^{*}\|^{2}\).

the robust training procedure can be formulated into a NC-C minimax optimization problem. It is clear that the minimax problem is nonconvex in \(x\), but concave in \(y\).

FGSM [15] and PGD [19] are two popular methods for generating adversarial examples. To obtain the targeted attack \(\hat{x}_{ij}\), we use the same procedure as in [31; 51] as follows. The perturbation level \(\varepsilon\) is chosen from \(\{0.0,0.1,0.2,0.3,0.4\}\), and the stepsize is \(0.01\). Note that the number of iterations is set to \(40\) for FGSM and \(10\) for PGD, respectively. The details of the network are included in the Supplementary Material. We compare our EGDA method with GDA [25], MGDA [31] and Smoothed-GDA [51], and illustrate the convergence of all the algorithms on the loss function in Fig. 3. The results show that Smoothed-GDA and EGDA converge significantly faster than other algorithms. This verifies that they have a faster convergence rate, \(\widetilde{\mathcal{O}}(\epsilon^{-\mathcal{I}})\). Moreover, EGDA converges much faster than Smoothed-GDA.

## 6 Conclusions and Future Work

In this paper, we proposed a new single-loop accelerated algorithm for solving various constrained NC-NC minimax problems. In the proposed algorithm, we designed a novel extra-gradient difference scheme for dual updates. Moreover, we provided the convergence guarantees for the proposed algorithm, and the theoretical results show that to find an \(\epsilon\)-stationary point of \(f\), the proposed algorithm obtains the complexity bound \(\mathcal{O}(\epsilon^{-2})\) for constrained NC-NC problems. That is, this is the first time that the proposed algorithm attains the complexity bound \(\mathcal{O}(\epsilon^{-2})\) in constrained NC-NC settings (including constrained NC-C and C-NC). For NC-C problems, we provided the theoretical guarantees of the proposed algorithm under the stationarity of \(\phi\), which show that our algorithm improves the complexity bound from \(\widetilde{\mathcal{O}}(\epsilon^{-3})\) to \(\mathcal{O}(\epsilon^{-2})\). Experimental results also verified the theoretical results of the proposed algorithm, which have the factors of \(\epsilon^{-1}\) and \(\epsilon^{-2}\) faster than existing algorithms, respectively. For further work, we will extend our directly accelerating algorithm to stochastic, non-smooth, nonconvex-nonconcave and federated learning settings as in [47; 11; 4; 55; 45; 21; 37].

## Acknowledgments

We want to thank the anonymous reviewers for their valuable suggestions and comments. This work was supported by the National Key R&D Program of China (No. 2022ZD0160302), the National Natural Science Foundation of China (Nos. 6227071567, 61976164, 62276004 and 61836009), the National Science Basic Research Plan in Shaanxi Province of China (No. 2022GY-061), the major key project of PCL, China (No. PCL2021A12), and Qualcomm.

## References

* [1] Z. Allen-Zhu. Katyusha: The first direct acceleration of stochastic gradient methods. In _STOC_, 2017.
* [2] Z. Allen-Zhu and Y. Yuan. Improved SVRG for non-strongly-convex or sum-of-non-convex objectives. In _ICML_, pages 1080-1089, 2016.

Figure 3: Convergence speed of all the algorithms on Fashion MNIST (left) and MNIST (right).

* [3] J. P. Bailey, G. Gidel, and G. Piliouras. Finite regret and cycles with fixed step-size via alternating gradient descent-ascent. In _The Annual Conference on Learning Theory (COLT)_, pages 391-407, 2020.
* [4] R. I. Bot and A. Bohm. Alternating proximal-gradient steps for (stochastic) nonconvex-concave minimax problems. _SIAM J. Optim._, 2023.
* [5] Y. Cai and W. Zheng. Accelerated single-call methods for constrained min-max optimization. In _International Conference on Learning Representations (ICLR)_, 2023.
* [6] Z. Chen, Z. Hu, Q. Li, Z. Wang, and Y. Zhou. A cubic regularization approach for finding local minimax points in nonconvex minimax optimization. _Transactions on Machine Learning Research_, pages 1-43, 2023.
* [7] C. D. Dang and G. Lan. On the convergence properties of non-euclidean extragradient methods for variational inequalities with generalized monotone operators. _Comput. Optim. Appl._, 60(2):277-310, 2015.
* [8] C. Daskalakis and I. Panageas. The limit points of (optimistic) gradient descent in min-max optimization. In _The Annual Conference on Neural Information Processing Systems (NeurIPS)_, pages 9256-9266, 2018.
* [9] D. Davis and D. Drusvyatskiy. Stochastic model-based minimization of weakly convex functions. _SIAM J. Optim._, 29(1):207-239, 2019.
* [10] J. Diakonikolas, C. Daskalakis, and M. I. Jordan. Efficient methods for structured nonconvex-nonconcave min-max optimization. In _AISTATS_, pages 2746-2754, 2021.
* [11] J. Diakonikolas, C. Daskalakis, and M. I. Jordan. Efficient methods for structured nonconvex-nonconcave min-max optimization. In _The International Conference on Artificial Intelligence and Statistics (AISTATS)_, pages 2746-2754, 2021.
* [12] S. S. Du, J. Chen, L. Li, L. Xiao, and D. Zhou. Stochastic variance reduction methods for policy evaluation. In _International Conference on Machine Learning (ICML)_, pages 1049-1058, 2017.
* [13] J. C. Duchi and H. Namkoong. Variance-based regularization with convex objectives. _J. Mach. Learn. Res._, 20:1-55, 2019.
* [14] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In _The Annual Conference on Neural Information Processing Systems (NIPS)_, pages 2672-2680, 2014.
* [15] I. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. In _International Conference on Learning Representations (ICLR)_, 2015.
* [16] A. N. Iusem, A. Jofre, R. I. Oliveira, and P. Thompson. Extragradient method with variance reduction for stochastic variational inequalities. _SIAM J. Optim._, 27(2):686-724, 2017.
* [17] C. Jin, P. Netrapalli, and M. I. Jordan. What is local optimality in nonconvex-nonconcave minimax optimization? In _International Conference on Machine Learning (ICML)_, pages 4880-4889, 2020.
* [18] W. Kong and R. D. Monteiro. An accelerated inexact proximal point method for solving nonconvex-concave min-max problems. In _arXiv preprint arXiv:1905.13433v3_, 2021.
* [19] A. Kurakin, I. Goodfellow, and S. Bengio. Adversarial machine learning at scale. In _International Conference on Learning Representations (ICLR)_, 2017.
* [20] S. Lee and D. Kim. Fast extra gradient methods for smooth structured nonconvex-nonconcave minimax problems. In _NeurIPS_, 2021.
* [21] Y. Lei, Z. Yang, T. Yang, and Y. Ying. Stability and generalization of stochastic gradient methods for minimax problems. In _International Conference on Machine Learning (ICML)_, pages 6175-6186, 2021.
* [22] A. Letcher, D. Balduzzi, S. Racaniere, J. Martens, J. N. Foerster, K. Tuyls, and T. Graepel. Differentiable game mechanics. _J. Mach. Learn. Res._, 20:1-40, 2019.
* [23] H. Li, Y. Tian, J. Zhang, and A. Jadbabaie. Complexity lower bounds for nonconvex-strongly-concave min-max optimization. In _arXiv preprint arXiv:2104.08708v1_, 2021.
* [24] T. Lin, C. Jin, and M. I. Jordan. Near-optimal algorithms for minimax optimization. In _The Annual Conference on Learning Theory (COLT)_, pages 2738-2779, 2020.

* [25] T. Lin, C. Jin, and M. I. Jordan. On gradient descent ascent for nonconvex-concave minimax problems. In _International Conference on Machine Learning (ICML)_, pages 6083-6093, 2020.
* [26] M. Liu, H. Rafique, Q. Lin, and T. Yang. First-order convergence theory for weakly-convex-weakly-concave min-max problems. _J. Mach. Learn. Res._, 22:169:1-169:34, 2021.
* [27] S. Lu, I. Tsaknakis, M. Hong, and Y. Chen. Hybrid block successive approximation for one-sided nonconvex min-max problems: algorithms and applications. _IEEE Trans. Signal Process._, 68:3676-3691, 2020.
* [28] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant to adversarial attacks. In _International Conference on Learning Representations (ICLR)_, 2018.
* [29] A. Mokhtari, A. Ozdaglar, and S. Pattathil. A unified analysis of extra-gradient and optimistic gradient methods for saddle point problems: Proximal point approach. In _The International Conference on Artificial Intelligence and Statistics (AISTATS)_, pages 1497-1507, 2020.
* [30] K. G. Murty and S. N. Kabadi. Some NP-complete problems in quadratic and nonlinear programming. _Mathematical Programming_, 39(2):117-129, 1987.
* [31] M. Nouiehed, M. Sanjabi, T. Huang, J. D. Lee, and M. Razaviyayn. Solving a class of non-convex min-max games using iterative first order methods. In _NeurIPS_, pages 14905-14916, 2019.
* [32] D. M. Ostrovskii, A. Lowy, and M. Razaviyayn. Efficient search of first-order Nash equilibria in nonconvex-concave smooth min-max problems. _SIAM J. Optim._, 2021.
* [33] Y. Ouyang and Y. Xu. Lower complexity bounds of first-order methods for convex-concave bilinear saddle-point problems. _Mathematical Programming_, 185:1-35, 2021.
* [34] H. Rafique, M. Liu, Q. Lin, and T. Yang. Weakly-convex concave min-max optimization: Provable algorithms and applications in machine learning. _Optim. Method Softw._, 2022.
* [35] M. Razaviyayn, T. Huang, S. Lu, M. Nouiehed, M. Sanjabi, and M. Hong. Nonconvex min-max optimization: Applications, challenges, and recent theoretical advances. _IEEE Signal Process. Mag._, 37(5):55-66, 2020.
* [36] S. Shafieezadeh-Abadeh, P. M. Esfahani, and D. Kuhn. Distributionally robust logistic regression. In _The Annual Conference on Neural Information Processing Systems (NIPS)_, pages 1576-1584, 2015.
* [37] P. Sharma, R. Panda, G. Joshi, and P. K. Varshney. Federated minimax optimization: Improved convergence analyses and algorithms. In _International Conference on Machine Learning (ICML)_, pages 19683-19730, 2022.
* [38] C. Song, Z. Zhou, Y. Zhou, Y. Jiang, and Y. Ma. Optimistic dual extrapolation for coherent non-monotone variational inequalities. In _NeurIPS_, 2020.
* [39] C. Tan, T. Zhang, S. Ma, and J. Liu. Stochastic primal-dual method for empirical risk minimization with \(o(1)\) per-iteration complexity. In _The Annual Conference on Neural Information Processing Systems (NeurIPS)_, pages 8376-8385, 2018.
* [40] K. K. Thekumprampil, P. Jain, P. Netrapalli, and S. Oh. Efficient algorithms for smooth minimax optimization. In _The Annual Conference on Neural Information Processing Systems (NeurIPS)_, pages 12659-12670, 2019.
* [41] H.-T. Wai, Z. Yang, Z. Wang, and M. Hong. Multi-agent reinforcement learning via double averaging primal-dual optimization. In _The Annual Conference on Neural Information Processing Systems (NeurIPS)_, pages 9672-9683, 2018.
* [42] G. Xie, L. Luo, Y. Lian, and Z. Zhang. Lower complexity bounds for finite-sum convex-concave minimax optimization problems. In _International Conference on Machine Learning (ICML)_, pages 10504-10513, 2020.
* [43] Y. Xu, R. Jin, and T. Yang. First-order stochastic algorithms for escaping from saddle points in almost linear time. In _NeurIPS_, pages 5535-5545, 2018.
* [44] Z. Xu, H. Zhang, Y. Xu, and G. Lan. A unified single-loop alternating gradient projection algorithm for nonconvex-concave and convex-nonconcave minimax problems. _Mathematical Programming_, 2023.

* [45] J. Yang, N. Kiyavash, and N. He. Global convergence and variance-reduced optimization for a class of nonconvex-nonconcave minimax problems. In _The Annual Conference on Neural Information Processing Systems (NeurIPS)_, 2020.
* [46] J. Yang, N. Kiyavash, and N. He. Global convergence and variance reduction for a class of nonconvex-nonconcave minimax problems. In _NeurIPS_, 2020.
* [47] J. Yang, S. Zhang, N. Kiyavash, and N. He. A catalyst framework for minimax optimization. In _The Annual Conference on Neural Information Processing Systems (NeurIPS)_, 2020.
* [48] T. Yoon and E. K. Ryu. Accelerated algorithms for smooth convex-concave minimax problems with o(1/k^2) rate on squared gradient norm. In M. Meila and T. Zhang, editors, _ICML_, pages 12098-12109, 2021.
* [49] T. Yoon and E. K. Ryu. Accelerated algorithms for smooth convex-concave minimax problems with \(o(1/k^{2})\) rate on squared gradient norm. In _ICML_, pages 12098-12109, 2021.
* [50] J. Zhang, M. Hong, and S. Zhang. On lower iteration complexity bounds for the saddle point problems. _Mathematical Programming_, 194:901-935, 2022.
* [51] J. Zhang, P. Xiao, R. Sun, and Z. Luo. A single-loop smoothed gradient descent-ascent algorithm for nonconvex-concave min-max problems. In _The Annual Conference on Neural Information Processing Systems (NeurIPS)_, pages 7377-7389, 2020.
* [52] S. Zhang, J. Yang, C. Guzman, N. Kiyavash, and N. He. The complexity of nonconvex-strongly-concave minimax optimization. In _The Conference on Uncertainty in Artificial Intelligence (UAI)_, 2021.
* [53] W. Zhang and D. Han. A new alternating direction method for co-coercive variational inequality problems. _Comput. Math. Appl._, 57(7):1168-1178, 2009.
* [54] Y. Zhang and L. Xiao. Stochastic primal-dual coordinate method for regularized empirical risk minimization. _J. Mach. Learn. Res._, 18:1-42, 2017.
* [55] R. Zhao. A primal dual smoothing framework for max-structured nonconvex optimization. _Mathematics of Operations Research_, 2023.