# Symmetric Linear Bandits with Hidden Symmetry

 Nam Phuong Tran

Department of Computer Science

University of Warwick

Coventry, United Kingdom

nam.p.tran@warwick.ac.uk &The Anh Ta

CSIRO's Data61

Marsfield, NSW, Australia

theanh.ta@csiro.au &Debmalya Mandal

Department of Computer Science

University of Warwick

Coventry, United Kingdom

debmalya.mandal@warwick.ac.uk &Long Tran-Thanh

Department of Computer Science

University of Warwick

Coventry, United Kingdom

long.tran-thanh@warwick.ac.uk

###### Abstract

High-dimensional linear bandits with low-dimensional structure have received considerable attention in recent studies due to their practical significance. The most common structure in the literature is sparsity. However, it may not be available in practice. Symmetry, where the reward is invariant under certain groups of transformations on the set of arms, is another important inductive bias in the high-dimensional case that covers many standard structures, including sparsity. In this work, we study high-dimensional symmetric linear bandits where the symmetry is hidden from the learner, and the correct symmetry needs to be learned in an online setting. We examine the structure of a collection of hidden symmetry and provide a method based on model selection within the collection of low-dimensional subspaces. Our algorithm achieves a regret bound of \(O(d_{0}^{2/3}T^{2/3}\log(d))\), where \(d\) is the ambient dimension which is potentially very large, and \(d_{0}\) is the dimension of the true low-dimensional subspace such that \(d_{0}\ll d\). With an extra assumption on well-separated models, we can further improve the regret to \(O(d_{0}\sqrt{T\log(d)})\).

## 1 Introduction

Stochastic bandit is a sequential decision-making problem in which a player, who aims to maximize her reward, selects an action at each step and receives a stochastic reward, drawn from an initially unknown distribution of the selected arm, in response. Linear stochastic bandit (LSB) [1] is an important variant in which the expected value of the reward is a linear function of the action. It is one of the most studied bandit variants and has many practical applications [27].

Actions in LSB are specified as feature vectors in \(\mathbb{R}^{d}\) for very large feature dimension \(d\), with performance i.e. the resulting regret scaling with \(d\). Many works have addressed this curse of dimensionality by leveraging different low-dimensional structures as inductive biases for the learner. For example, sparsity, which assumes that the reward is a sparse linear function, has been used extensively in LSB to design bandit algorithms with better performance [2, 36, 23]. However, when the reward function lacks the structure for sparsity (which may occur in many real-world situations), a question arises: Are there different structures in the features of LSB that we can exploit to overcome the curse of dimensionality and design bandit algorithms with better performance?

In this paper, we study the inductive bias induced by symmetry structures in LSB, which is a more general model inductive bias than sparsity, and can facilitate efficient and effective learning [9]. Symmetry describes how, under certain transformations of the input of the problem, the outcomeshould either remain unchanged (_invariance_) or shift predictably (_equivariance_). In supervised learning, it has been empirically observed [17, 12] and theoretically proven [16, 6] that explicitly integrating symmetry into models leads to improved generalization error. However, in the literature on sequential decision-making, unlike sparsity, symmetry is rarely considered to date. This leads us to the following research question: Can one leverage _symmetry in sequential decision-making_ tasks to enable effective exploration, and eventually break the curse of dimensionality?

In the machine learning literature, especially in supervised learning, most studies on symmetry assume prior knowledge of symmetry structures of the tasks under consideration [31, 16]. However, in numerous practical scenarios, the learner can only access to partial knowledge of the symmetry, necessitating the incorporation of symmetry learning mechanisms into the algorithms to achieve better performance. Examples of hidden symmetry can be found in multi-agent learning with cooperative behavior. As a motivating example, consider a company undertaking a large project that consists of several subtasks. The company must hire subcontractors with the goal of maximizing project quality while staying within budget constraints. Symmetry may arise in this situation when coalitions form among subcontractors, where members of a coalition work together to complete their allocated tasks using shared resources. In particular, the allocation of tasks within a coalition can be swapped without affecting overall team performance, inducing symmetry (i.e., performance remains invariant under permutation) in the task assignments. Coalitions among subcontractors often arise since sharing labor and resources reduces operational costs, making their work more efficient and cost-effective. However, these coalitions are typically _hidden_ from the hiring company. One reason is that if the hiring company were aware of these collaborations, they could use this information to negotiate lower prices, knowing that the subcontractors are benefiting from shared resources. Another reason is that coalitions may raise concerns about collusion. In particular, in a competitive market, such as when subcontractors are hired through a bidding platform, coalition members can collaborate to manipulate the bidding process, which is considered unfair and could undermine the integrity of the bidding. For more practical examples of hidden symmetry in multi-agent reinforcement learning [34] and robotics [3], we refer the reader to Appendix D.2. Motivated by these examples, we believe that hidden symmetry is much more relevant in the context of sequential decision-making because the environment and its symmetry structure may not be readily available to the learner, as opposed to supervised learning and offline settings where data are provided during the training phase. As the learner has the power to freely collect data, it is expected that they will learn the hidden symmetry structures as they explore the environment.

Against this background, we ask the question of whether learner can leverage symmetry to enable effective exploration, and break the curse of dimensionality _without a prior knowledge_ of the symmetry structure? Moreover, in the presence of symmetry, when can we design learning algorithms with optimal regret bounds? Towards answering this question, we investigate the setting of symmetric linear stochastic bandit in \(\mathbb{R}^{d}\), where \(d\) is potentially very large, and the expected reward function is invariant with respect to the actions of a _hidden_ group \(\mathcal{G}\) of coordinate permutations. Our contributions are summarised as follows:

1. We first give an impossibility result that _no algorithm can get any benefit by solely knowing that \(\mathcal{G}\) is a subgroup of permutation matrices_. We achieve this by formally establishing a relation between the class of subgroup to the partition over the set \(\{1,...,d\}\). A direct implication of this impossibility result is that it is necessary to have further information about the structure of the hidden subgroup in order to achieve improved regret bounds.
2. Given this, we establish a cardinality condition on the class of symmetric linear bandits with hidden \(\mathcal{G}\), in which the learner can learn the true symmetry structure and overcome the curse of dimensionality. Notably, this class includes a sparsity as a special case, and therefore inherits all the computational and statistical complexities of sparsity. Apart from sparsity, this class includes many other practically relevant classes, such as partitions that respect underlying hierarchies, non-crossing partitions, and non-nesting partitions (see Subsection 4.2.1 and Appendix D.2).
3. We cast our problem of learning with hidden subgroup \(\mathcal{G}\) into model selection with collection of low-dimensional subspaces [25, 35]. To address the polynomial scaling of regret bounds with respect to the number of models and arms in previous works, we depart from model aggregation, which is typically used in LSB model selection, and introduce a new framework inspired by Gaussian model selection [7]1 and compressed sensing [8]. Based on this framework, we introduce a new algorithm, called EMC (for Explore Models then Commit). Under the assumption that the set of arm is exploratory, we prove that the regret bound of the EMC algorithm is \(O(d_{0}^{2/3}T^{2/3}\log(d))\), and \(O(d_{0}\sqrt{T}\log(d))\) with an additional assumption on well-separated partitions, where \(d_{0}\ll d\) is the dimension of the low-dimensional subspace associated with group \(\mathcal{G}\).

Footnote 1: We note that “Gaussian model selection” is a technique in statistics, similar to model aggregation (see [21]’s chapter 2 and 4), which should not be confused with “model selection” in the bandit literature.

To the best of our knowledge, our work is the first in the linear stochastic bandits literature that leverages symmetry in designing provably efficient algorithms. To save space, all proofs in this paper are deferred to the Appendix.

### Related Work

We now briefly outline related work and compare them with our results. We refer the reader to Appendix F for a more in-depth literature review.

**Sparse linear bandits.** As we will explain in Section 4.2, sparsity is equivalent to a subset symmetry structures, and thus, can be seen as a special case of our setting. As such, we first review the literature of sparsity. Sparse linear bandits were first investigated in [2], where the authors achieve a regret of \(\tilde{O}(\sqrt{dsT})\), with \(\tilde{O}\) disregarding the logarithmic factor, and \(s\) representing the sparsity level, and \(T\) is the time horizon. This matches the regret lower bound for sparse bandits, which is \(\Omega(\sqrt{dsT})\)[27]. More recently, the contextual version of linear bandits has gained popularity, where additional assumptions are made regarding the context distribution and set of arms [26, 36, 28, 11, 23] to avoid polynomial dependence on \(d\). Notably, with the assumption on exploratory set of arms, [23] propose an Explore then Commit style strategy that achieves \(\tilde{O}(s^{\frac{2}{3}}T^{\frac{2}{3}})\), nearly matching the regret lower bound \(\Omega(s^{\frac{2}{3}}T^{\frac{2}{3}})\)[24] in the data-poor regime. As sparsity is equivalent to a subclass of hidden symmetry, all the lower bounds for sparse problems apply to our setting of learning with hidden symmetry.

**Model selection.** Our problem is also closely related to the problem of model selection in linear bandits, as the learner can collect potential candidates for the hidden symmetry model. Particularly, in model selection, there is a collection of \(M\) features, and different linear bandits running with each of these features serve as base algorithms. By exploiting the fact that the data can be shared across all the base algorithms, the dependence of regret in terms of the number of features can be reduced to \(\log(M)\). In particular, [25] propose a method that concatenates all \(M\) features of dimension \(d\) into one feature of dimension \(Md\), and uses the Lasso estimation as a aggregation of models. Their algorithm achieves a regret bound of \(O(T^{\frac{2}{3}}\sqrt{\log(M)})\) under the assumption that the Euclidean norm of the concatenated feature is bounded by a constant. However, in our case, the Euclidean norm of the concatenated feature vector can be as large as \(\sqrt{M}\), which leads to a \(\sqrt{M}\) multiplicative factor in the regret bound. Besides, [35] uses the online aggregation oracle approach, and is able to obtain regret of \(O(\sqrt{KdT\log(M)})\), where \(K\) is the number of arms. In contrast, _we use algorithmic mechanisms that are different from aggregation of models_. In particular, we explicitly exploit the structure of the model class as a collection of subspaces and invoke results from Gaussian model selection [21, 7] and dimension reduction on the union of subspaces [8]. With this technique, we are able to achieve \(O(T^{\frac{2}{3}}\log(M))\), which is rate-optimal in the data-poor regime, has logarithmic dependence on \(M\) without strong assumptions on the norm of concatenated features, and is independent of the number of arms \(K\). We refer the reader to Section 4.2 for a more detailed explanation.

**Symmetry in online learning.** The notion of symmetry in Markov decision process dates back to works such as [22, 40]. Generally, the reward function and probability transition are preserved under an action of a group on the state-action space. Exploiting known symmetry has been shown to help achieve better performance empirically [43, 42] or tighter regret bounds theoretically [41]. However, all these works requires knowledge of symmetry group, while our setting consider hidden symmetry group which may be considerably harder. Hidden symmetry on the context or state space has been studied by few authors, with the term context-lumpable bandits [29], meaning that the set of contexts can be partitioned into classes of similar contexts. It is important to note that the symmetry group acts differently on the context space and the action space. As we shall explain in detail in Section 3, while one can achieve a reduction in terms of regret in the case of hidden symmetry acting on context spaces [29], this is not the case when the symmetry group acts on the action space. The work closest to ours is [39], where the authors consider the setting of a \(K\)-armed bandit, where the set of arms can be partitioned into groups with similar mean rewards, such that each group has at least \(q>2\) arms. With the constrained partition, the instance-dependent regret bounds are shown asymptotically to be of order \(O\left(\frac{K}{q}\log T\right)\). Comparing to [39], we study the setting of stochastic linear bandits with similar arms, in which the (hidden) symmetry and linearity structure may intertwine, making the problem more sophisticated. We also impose different constraints on the way one partitions the set of arms, which is more natural in the setting of linear bandits with infinite arms.

## 2 Problem Setting

For any \(k\in\mathbb{N}^{+}\), denote \([k]=\{1,\ldots,k\}\). For \(\mathcal{X}\subseteq\mathbb{R}^{d}\), let \(\Delta(\mathcal{X})\) denote the set of all probability measures supported on \(\mathcal{X}\). Given a set \(S\subset\mathbb{R}^{k}\), for some \(k>1\), denote \(\Pi_{S}(x)\) as the Euclidean projection of \(x\in\mathbb{R}^{k}\) on \(S\), and \(\operatorname{conv}(S)\) as the convex hull of \(S\).

We denote by \(T\) the number of rounds, which is assumed to be known in advance. Each round \(t\in[T]\), the agent chooses an arm \(x_{t}\in\mathcal{X}\subset\mathbb{R}^{d}\), and nature returns a stochastic reward \(y_{t}=\langle x_{t},\theta_{\star}\rangle+\eta_{t},\) where \(\eta_{t}\) is an i.i.d. \(\sigma\)-Gaussian random variable. Now, denote \(f(x_{t})=\mathbb{E}[y_{t}\mid x_{t}]\). A bandit strategy is a decision rule for choosing an arm \(x_{t}\) in round \(t\in[T]\), given past observations up to round \(t-1\). Formally, a bandit strategy is a mapping \(\mathcal{A}:(\mathcal{X}\times\mathbb{R})^{T}\rightarrow\Delta(\mathcal{X})\).

Let \(x_{\star}=\arg\max_{x\in\mathcal{X}}f(x)\), and let \(\mathbf{R}_{T}=\mathbb{E}\left[\sum_{t=1}^{T}\left\langle x_{\star}-x_{t}, \theta_{\star}\right\rangle\right]\) denote the expected cumulative regret. In this paper, we investigate the question whether one can get any reduction in term of regret, if the reward function is invariant under the action of a hidden group of transformations on the set of arms. We define the notion of group of symmetry as follows:

Group and group action.Given \(d\in\mathbb{N}^{+}\), let \(\mathcal{S}_{d}\) denote the symmetry group of \([d]\), that is, \(\mathcal{S}_{d}:=\{h:[d]\rightarrow[d]\mid h\text{ is bijective}\}\) the collection of all bijective mappings from \([d]\) to itself. We also define the group action \(\dot{\phi}\) of \(\mathcal{S}_{d}\) on the vector space \(\mathbb{R}^{d}\) as

\[\begin{split}\phi:\mathcal{S}_{d}\times\mathbb{R}^{d}& \rightarrow\mathbb{R}^{d}\\ &\left(g,(x_{i})_{i\in[d]}\right)&\mapsto(x_{g(i)})_{i \in[d]}\end{split}\] (1)

In other words, a group element \(g\) acts on an arm \(x\in\mathbb{R}^{d}\) by permuting the coordinates of \(x\). In the setting of linear bandit, the permutation group action also acts on the set of parameters via coordinate permutation. For brevity, we simply denote \(g\cdot\theta\) and \(g\cdot x\) as \(\phi(g,\theta)\) and \(\phi(g,x)\), respectively. Denote by \(A_{g}\) the permutation matrix corresponding to \(g\). We write \(\mathcal{G}\leq\mathcal{S}_{d}\) to denote that \(\mathcal{G}\) is a subgroup of \(\mathcal{S}_{d}\). Given any point \(\theta\in\mathbb{R}^{d}\), we write \(\mathcal{G}\cdot\theta=\{g\cdot\theta\mid g\in\mathcal{G}\}\) to denote the orbit of \(\theta\) under \(\mathcal{G}\). It is well known that the orbit induced by the induced action of a subgroup \(\mathcal{G}\leq\mathcal{S}_{d}\) corresponds to a set partition of \([d]\). We denote this partition as \(\pi_{\mathcal{G}}\).

Let \(\mathcal{G}\) be a subgroup of \(\mathcal{S}_{d}\) that acts on \(\mathbb{R}^{d}\) via the action \(\phi\). In a symmetric linear bandit, the expected reward is invariant under the group action of \(\mathcal{G}\) on \(\mathcal{X}\), that is, \(f(g\cdot x)=f(x)\). Due to the linear structure of \(f\), this is equivalent to \(g\cdot\theta_{\star}=\theta_{\star}\) for all \(g\in\mathcal{G}\). We assume that, _while the group action \(\phi\) is known to the learner, the specific subgroup \(\mathcal{G}\) is hidden and must be learned in an online manner_.

## 3 Impossibility Result of Learning with General Hidden Subgroups

We now show how to frame the learning problem with hidden symmetry group as the problem of model selection. We further analyse the structure of the collection of models, and show that no algorithm can benefit by solely knowing that \(\mathcal{G}\leq\mathcal{S}_{d}\), which implies that further assumptions are required to achieve significant improvement in term of regret.

### Fixed Point Subspace and Partition

The analysis of learning with hidden subgroup requires a group-theoretic notion which is referred to as fixed-point subspaces [10]. As we shall explain promptly, there is a tight connection between the collection of fixed-point subspaces and set partitions.

Fixed-point subspaces.For a subset \(\mathcal{X}\subseteq\mathbb{R}^{d}\), denote \(\operatorname{Fix}_{\mathcal{G}}(\mathcal{X}):=\{x\in\mathcal{X}\mid g\cdot x=x, \ \forall g\in\mathcal{G}\}\) as the fixed-point subspace of \(\mathcal{G}\); and \(\mathcal{F}_{\mathcal{S}_{d}}(\mathcal{X}):=\{\operatorname{Fix}_{\mathcal{G} }(\mathcal{X})\mid\mathcal{G}\leq\mathcal{S}_{d}\}\) as the collection of all fixed-point subspaces of all subgroups of \(\mathcal{S}_{d}\). We simply write \(\mathcal{F}_{\mathcal{S}_{d}}=\mathcal{F}_{\mathcal{S}_{d}}(\mathbb{R}^{d})\) and \(\operatorname{Fix}_{\mathcal{G}}=\operatorname{Fix}_{\mathcal{G}}(\mathbb{R} ^{d})\) for brevity.

Set partition.Given \(d\in\mathbb{N}^{+}\), we denote \(\mathcal{P}_{d}\) as the set of all partitions of \([d]\). Let \(\mathcal{P}_{d,k}\) as the set of all partitions of \([d]\) with exactly \(k\) classes, and \(\mathcal{P}_{d,\leq k}\) be the set of all partitions of \([d]\) with at most \(k\) classes. The number of set partitions with \(k\) classes \(|\mathcal{P}_{d,k}|\) is known as the Stirling number of the second kind, and \(|\mathcal{P}_{d}|\) is known as Bell number.

### Impossibility Result

Problem with known symmetry.Before discussing the problem of hidden symmetry, let us explain why the learner with an exact knowledge of \(\mathcal{G}\) can trivially achieve smaller regret. The reason is that \(\theta_{\star}\in\operatorname{Fix}_{\mathcal{G}}\) by the assumption that \(\theta_{\star}\) is invariant w.r.t the action of group \(\mathcal{G}\). If \(\mathcal{G}\) is known in advance, the learner can restrict the support of \(\theta_{\star}\) in \(\operatorname{Fix}_{\mathcal{G}}\), and immediately obtains that the regret scales with \(\dim(\operatorname{Fix}_{\mathcal{G}})\) instead of \(d\), which can be significantly smaller (e.g., if \(\mathcal{G}=\mathcal{S}_{d}\), then \(\dim(\operatorname{Fix}_{\mathcal{G}})=1\)).

For any subgroup, there exists a fixed point subspace, and some subgroups may share the same fixed point subspace. Therefore, instead of constructing a collection of subgroups, one can create a smaller collection of models using the collection of fixed point subspaces. As \(\mathcal{G}\) is hidden, one must learn \(\operatorname{Fix}_{\mathcal{G}}\) within the set of candidates \(\mathcal{F}_{\mathcal{S}_{d}}\), leading to the formulation of the model selection.

From the setting with hidden subgroup to the setting with hidden set partition.Now, we discuss the structure of the collection of models \(\mathcal{F}_{\mathcal{S}_{d}}\). First, we show the equivalent structure between the collection of fixed point subspaces and the set partitions as follows.

**Proposition 1**.: _There is a bijection \(\mathbf{H}\) between \(\mathcal{P}_{d}\) and \(\mathcal{F}_{\mathcal{S}_{d}}\)._

As there is a bijection between \(\mathcal{P}_{d}\) and \(\mathcal{F}_{\mathcal{S}_{d}}\), we can count the number of subspaces of each dimension \(k\) explicitly using the following.

**Proposition 2** ([10]'s Theorem 14).: _Given a subgroup \(\Gamma\leq\mathcal{S}_{d}\) and its fixed-point subspace \(\operatorname{Fix}_{\Gamma}\), suppose that \(\pi_{\Gamma}\) partitions \([d]\) into \(k\) classes, then \(\dim(\operatorname{Fix}_{\Gamma})=k\)._

By Proposition 2, we have that the number of subspaces of dimension \(k\) in \(\mathcal{F}_{\mathcal{S}_{d}}\) is exactly the number of set partitions with \(k\)-classes. Suppose that the learner knows that the orbit under action of \(\mathcal{G}\) partitions the index of \(\theta_{\star}\) into 2 equivalent classes that is, \(\dim(\operatorname{Fix}_{\mathcal{G}})=2\). The learner cannot get any reduction in terms of regret.

**Proposition 3**.: _Assume that the action set is the unit cube \(\mathcal{X}=\{x\in\mathbb{R}^{d}\mid\|x\|_{\infty}\leq 1\}\), and \(f\) is invariant w.r.t. action of subgroup \(\mathcal{G}\leq\mathcal{S}_{d}\), such that \(\dim(\operatorname{Fix}_{\mathcal{G}})=2\). Then, the regret of any bandit algorithm is lower bounded by \(\mathbf{R}_{T}=\Omega(d\sqrt{T})\)._

The implication of Proposition 3 is that even if the learner knows \(\theta_{\star}\) lies in an extremely low-dimensional subspace within the finite pools of candidates, they _still suffer a regret that scales linearly with the ambient dimension \(d\)_. This suggests that _further information about the group \(\mathcal{G}\)_ must assumed to be known in order to break this polynomial dependence on \(d\) in the regret bound.

## 4 The Case of Hidden Subgroups with Subexponential Size

As indicated by Proposition 3, there is no improvement in terms of regret, despite the learner having access to a collection of extremely low-dimensional fixed point subspaces. Therefore, we assume that the learner can access only a reasonably small subset of the collection of low-dimensional fixed point subspaces. Let \(d_{0}\) be the upper bound for the dimension of fixed point subspaces; that is, we know that the orbit of \(\mathcal{G}\) partitions \([d]\) into at most \(d_{0}\) classes. Now, let us assume that the learner knows that \(\mathcal{G}\) does not partition \([d]\) freely, but must satisfy certain constraints, that is, \(\pi_{\mathcal{G}}\in\mathcal{Q}_{d,\leq d_{0}}\subset\mathcal{P}_{d,\leq d_{0}}\). Here, \(\mathcal{Q}_{d,\leq d_{0}}\) is a small collection of partitions with at most \(d_{0}\) classes, which encodes the constraints on the way \(\mathcal{G}\) partitions \([d]\). We introduce an assumption regarding the cardinality of \(\mathcal{Q}_{d,\leq d_{0}}\), which is formally stated in Section 4.2. Using the Proposition 1, we can define the collection of fixed point subspaces associated with the collection of partition \(\mathcal{Q}_{d,\leq d_{0}}\) via the bijection \(\mathbf{H}\) as

\[\mathcal{M}:=\mathbf{H}\left(\mathcal{Q}_{d,\leq d_{0}}\right)\quad\text{and} \quad M:=|\mathcal{M}|.\]

In addition, let us define the extension of the collection \(\mathcal{M}\) as \(\overline{\mathcal{M}}:=\left\{\operatorname{conv}\left(m\cup m^{\prime} \right)\mid m,\,m^{\prime}\in\mathcal{M}\right\},\) where \(\operatorname{conv}(S)\) is the convex hull of the set \(S\subset\mathbb{R}^{n}\)We have that \(\overline{\mathcal{M}}\) is a collection of subspaces, that is, \(\operatorname{conv}\left(m\cup m^{\prime}\right)\) is indeed a subspace [8]. Denote \(\overline{M}:=|\overline{\mathcal{M}}|\), then we have \(\overline{M}=(M^{2}-M)/2\). Moreover, if dimension of subspace in \(\mathcal{M}\) is at most \(d_{0}\), then the dimension of subspace in \(\overline{\mathcal{M}}\) is at most \(2d_{0}\).

### The Explore-Models-then-Commit Algorithm

Given some \(n\in[T]\), we define

\[Y=X\theta_{\star}+\bm{\eta},\] (2)

where \(Y\in\mathbb{R}^{n}\), \(X=\left[x_{1},\ldots,x_{n}\right]^{\top}\in\mathbb{R}^{n\times d}\) is the design matrix, \(\theta_{\star}\in\mathbb{R}^{d}\) is the true model; \(\bm{\eta}=[\eta_{1},\ldots,\eta_{n}]\). We have the information that \(\theta_{\star}\) must be contained in some (not necessarily unique) subspace \(m\in\mathcal{M}\). Denote by \(d_{m}\) the dimension of \(m\), we have \(d_{m}\leq d_{0}\) for any \(m\in\mathcal{M}\). Let \(X_{m}=[\Pi_{m}(x_{t})]_{t\in[n]}^{\top},\) and \(S_{m}\) be the column space of \(X_{m}\), one has \(\dim(S_{m})\leq d_{m}\). For any \(m\in\mathcal{M}\), and given \(Y\), let \(\Pi_{S_{m}}(\cdot)\) be the projection onto \(S_{m}\). Define

\[\widehat{\bm{f}}_{m}:=\Pi_{S_{m}}(Y);\quad\widehat{\theta}_{m}:=\operatorname {arg\,min}_{\theta\in m}\left\|Y-X\theta\right\|_{2}^{2}.\] (3)

Now, given \(n\) data points, we can choose the model \(\widehat{m}\in\mathcal{M}\) that minimises the least square error

\[\widehat{m}\in\operatorname*{arg\,min}_{m\in\mathcal{M}}\|Y-\widehat{\bm{f}}_ {m}\|_{2}^{2}.\] (4)

Based on the framework of model selection, we now introduce our Algorithm 1, Explore-Models-then-Commit (EMC). Our algorithm falls into the class explore-then-commit bandit algorithms. The exploration phase consists of \(t_{1}\) rounds. During this phase, one samples data independently and identically distributed (i.i.d.) from an exploratory distribution \(\nu\). After the exploration phase, one computes the solution to the model selection problem and then commits to the best arm corresponding to the chosen model.

**Remark 4**.: The key step of Algorithm 1 that may incur significant costs is solving equation (4) (line 6). Without additional information about \(\mathcal{M}\), one might need to enumerate all models in \(\mathcal{M}\) and optimize among them, which would induce a time complexity of \(O(nd^{cd_{0}})\). However, if we have more information about the partitions, e.g., if they are non-crossing or non-nesting partitions, their lattice structures can be exploited to speed up the optimization process of solving equation (4). Due to space limitations, we refer readers to Appendix D.3 for a detailed explanation of a subroutine that leverages these lattice structures for more efficient computation. Additionally, Section 6 demonstrates that our Algorithm 1, when using the lattice search algorithm for non-crossing partitions and non-nesting partitions as a subroutine, achieves polynomial computational complexity of \(O(nd^{5})\) and guarantees low regret.

### Regret Analysis

The regret analysis of Algorithm 1 uses results from the Gaussian model selection literature [7; 21] as a basis. As such, we first state the assumptions that are common in the Gaussian model selection literature on the collection of models \(\mathcal{M}\) and the set of arms \(\mathcal{X}\) (Section 4.2.1). We then provide our main analysis in Section 4.2.2, highlighting the key technical novelties of our approach.

#### 4.2.1 Assumptions

Recall that due to our lower bound in Proposition 3, further assumptions are required on the collection of fixed-point subspaces to achieve a reduction in terms of regret. As suggested by the model selection literature [25; 35], one can achieve regret in terms of \(\log(M)\) for a collection of \(M\) models. Adopting this idea, we make the following assumption regarding the number of potential fixed-point subspaces and the set of arms.

**Assumption 5** (**Sub-exponential number of partitions**).: _The partition corresponding to \(\mathcal{G}\) belongs to a small subclass of partitions \(\mathcal{Q}_{d,\leq d_{0}}\subset\mathcal{P}_{d,\leq d_{0}}\). In particular, \(\pi_{\mathcal{G}}\in\mathcal{Q}_{d,d_{\star}},\) for some \(d_{\star}\leq d_{0}\), and for each \(k\in[d_{0}]\), there exists a constant \(c>0\), such that \(|\mathcal{Q}_{d,k}|\leq O(d^{\text{ck}})\)._

**Assumption 6** (**Bounded set of arms**).: _There are positive numbers \(K_{x},R_{\max}\), such that, for all \(x\in\mathcal{X}\) and \(m\in\overline{\mathcal{M}}\), \(\left\|\Pi_{m}(x)\right\|_{2}^{2}\leq K_{x}\), and \(\left|\left\langle x,\theta_{\star}\right\rangle\right.|\leq R_{\max}.\)_

As a consequence of Assumption 5, the cardinality of the collection of fixed point subspaces is not too large, particularly, \(M=O(d^{\text{cd}0})\). First, we note that this class includes interval partitions, a structure equivalent to sparsity as a _strict_ subset, as explained below.

**Remark 7** (**Equivalence between sparsity and interval partition**).: A set partition of \([d]\) is an interval partition or partition of interval if its parts are interval. We denote \(\mathcal{I}_{d}\) as the collection of all interval partition of \(d\). \(\mathcal{I}_{d}\) admits a Boolean lattice of order \(2^{d-1}\), making it equivalent to the sparsity structure in \(d-1\) dimensions. Specifically, consider the set of entries of parameters \(\varphi\in\mathbb{R}^{d}\) with a linear order, that is, \(\varphi_{1}\geq\varphi_{2}\geq\cdots\geq\varphi_{d}\). Then define the variable \(\theta\in\mathbb{R}^{d-1}\) such that \(\theta_{i}=(\varphi_{i}-\varphi_{i+1})\). Each interval partition on the entries of \(\varphi\) will determine a unique sparse pattern of \(\theta\). Therefore, it is clear that the cardinality of the set of interval partition with \(d_{0}\) classes is bounded as \([\mathcal{I}_{d,\leq d_{0}}]=O(d^{d_{0}})\). Moreover, as a result, symmetric linear bandit is strictly harder than sparse bandit and inherits all the computational complexity challenges of sparse linear bandit, including the _NP-hardness_ of computational complexity.

Apart from sparsity, class of partitions with sub-exponential size also naturally appears when there is a hierarchical structure on the set \([d]\), and the partitioning needs to respect this hierarchical structure. A partition that respects an ordered tree groups the children of the same node into a single equivalence class, for example, see Figure 1. It is shown in [15] and the cardinality of the set of partitions that respect ordered trees is sub-exponential. Furthermore, as shown in [15] there is a bijection between partitions that respect ordered trees and the set of non-crossing partitions.

A real-life example that meets these assumptions is the subcontractor example in the introduction: A hierarchical structure may exist, where a hired subcontractor can further subcontract parts of the work to others. A tree represents the hierarchical order among subcontractors, where subcontractors hired by another contractor can be grouped into one class. Further real-life examples of non-crossing partitions and other structured partitions that satisfy sub-exponential cardinality, such as non-nesting partitions and pattern-avoidance partitions [33], can be found in Appendix D.2.

Next, similar as [23], we define the exploratory distribution as follows.

**Definition 8** (**Exploratory distribution**).: The exploratory distribution \(\nu\in\Delta(\mathcal{X})\) is solution of the following optimisation problem

\[\nu=\operatorname*{arg\,max}_{\omega\in\Delta(\mathcal{X})}\lambda_{\min} \left(\mathbb{E}_{x\sim\omega}[xx^{\top}]\right),\quad V:=\mathbb{E}_{x\sim \nu}[xx^{\top}],\quad C_{\min}(\mathcal{X}):=\lambda_{\min}(V).\] (5)

Since our setting includes sparsity as a special case, the regret lower bound in [24] applies to our setting as well. In particular, we have:

**Proposition 9** (**Regret lower bound**).: _There exist symmetric linear bandit instances in which Assumption 5, 6 hold with \(K_{x}=8d_{0}\), such that, any bandit algorithm must suffer regret \(\mathbf{R}_{T}=\Omega\left(\min\left(C_{\min}(\mathcal{X})^{-\frac{1}{3}}d_{0} ^{\frac{2}{3}}T^{\frac{2}{3}},\sqrt{dT}\right)\right)\)._

We note that the lower bound can be relaxed if we have a stronger assumption on the group \(\mathcal{G}\), which allows algorithm to go beyond the lower bound in Proposition 9 of the sparsity class. For example, if we consider a collection of fixed-point subspaces with a nested structure, similar to those discussed in [20], the algorithm may achieve a \(O(d_{0}\sqrt{T})\) rate. The key takeaway is that symmetry exhibits significant flexibility in structure. Depending on the specific class of symmetry, one may achieve either no reduction at all or significant reduction in terms of regret bound.

Figure 1: Partition that respects the underlying ordered tree.

#### 4.2.2 Main Regret Upper Bound Result

We now state the main result of the regret upper bound for Algorithm 1.

**Theorem 10** (**Regret upper bound**).: _Suppose the Assumptions 5, 6 hold. With the choice of \(t_{1}=R_{\max}^{-\frac{2}{3}}\sigma^{\frac{2}{3}}C_{\min}^{-\frac{1}{3}}(\mathcal{ X})K_{x}^{\frac{1}{3}}d_{0}^{\frac{1}{3}}T^{\frac{2}{3}}(\log(dT))^{\frac{1}{3}}\), then the regret of Algorithm 1 is upper bounded as_

\[\mathbf{R}_{T}=O\left(R_{\max}^{\frac{1}{3}}\sigma^{\frac{2}{3}}C_{\min}^{- \frac{1}{3}}(\mathcal{X})K_{x}^{\frac{1}{3}}d_{0}^{\frac{1}{3}}T^{\frac{2}{3}} (\log(dT))^{\frac{1}{3}}\right)\] (6)

**Remark 11**.: We note that when \(K_{x}=O(d_{0})\), as in the lower bound instances, our upper bound is \(\tilde{O}\left(C_{\min}^{-\frac{1}{3}}(\mathcal{X})d_{0}^{\frac{2}{3}}T^{\frac {2}{3}}\right)\), which matches the lower bound in Proposition 9.

The main idea is to bound the risk error after exploration rounds, as stated in the following lemma which implies the regret bound after standard manipulations.

**Lemma 12**.: _Suppose the Assumptions 5, 6 hold. For \(t_{1}=\Omega(K_{x}^{2}d_{0}C_{\min}^{-2}(\mathcal{X})\log(d/\delta))\), with probability at least \(1-\delta\), one has the estimate_

\[\left\|\theta_{\star}-\widehat{\theta}_{t_{1}}\right\|_{2}=O\left(\sqrt{ \frac{\sigma^{2}d_{0}\log(d/\delta)}{C_{\min}(\mathcal{X})t_{1}}}\right).\] (7)

**Remark 13** (**Non-triviality of Lemma 12**).: At the first glance, it seems that we can cast the problem of learning with a collection of \(M\) subspaces into a model selection problem in linear bandit with \(M\) features. This leads to a question: _Can we apply the model selection framework based on model aggregation in [35, 25] to our case?_

First, let us explain how to cast our problem into a model selection problem in linear bandit. For each subspace \(m\), let \(\Phi_{m}:\mathbb{R}^{d}\rightarrow\mathbb{R}^{d_{0}}\) be the feature map that computes the image of the projection \(\Pi_{m}\) with respect to the orthogonal basis of subspace \(m\). Thus, we then have a collection of \(M\) features \(\{\Phi_{m}\}_{m\in\mathcal{M}}\). Consider the algorithm introduced in [25], which concatenates the feature maps into \(\mathbf{\Phi}(x)=[\Phi_{1}(x),\dots,\Phi_{M}(x)]\in\mathbb{R}^{Md_{0}}\), and the regret bound depends on \(\|\mathbf{\Phi}(x)\|_{2}\).

However, in our case where \(\|\Phi_{m}(x)\|_{2}<1\), we can only bound \(\|\mathbf{\Phi}(x)\|_{2}\leq\sqrt{M}\), which leads to a \(\sqrt{M}\) dependence on regret, if we use their algorithm. Regarding [35], their algorithm aggregates the predictions among models for each arm, and based on that, they compute the distribution for choosing each arm. This leads to the regret scaling with the number of arms \(K\), which is not feasible in our case when \(K=\infty\).

We note that the similarity with the model selection technique in [25, 35] is that they use model aggregation among \(\mathcal{M}\) to bound the prediction error \(\sum_{t=1}^{T}\left\langle x_{t},\widehat{\theta}-\theta_{\star}\right\rangle^ {2}\), but this does not necessarily guarantee the risk error \(\|\widehat{\theta}-\theta_{\star}\|_{2}\). The reason is that, although model aggregation can guarantee a small prediction error, it imposes no restriction on the estimator \(\widehat{\theta}\), which limits its ability to leverage the further benign property of designed matrix \(X\). Instead of model aggregation, our algorithm explicitly picks the best model from the pool \(\mathcal{M}\), ensuring the following two properties: (1) The prediction error is small, similar to model aggregation; and (2) We can guarantee that \(\widehat{\theta}\) lies in one of the subspaces of \(\mathcal{M}\). The second property gives us control over \((\widehat{\theta}-\theta_{\star})\) by ensuring it lies in at most \(M^{2}\) subspaces. Then, exploiting the restricted isometry property (see Definition 15) of designed matrix \(X\), we can guarantee that with \(O(\log(M))\) exploratory samples, we can bound the risk error \(\|\widehat{\theta}-\theta_{\star}\|_{2}\). This is crucial for eliminating polynomial dependence on \(M\) and the number of arms \(K\).

Proof sketch of Lemma 12.We provide a proof sketch here and defer their full proof to Appendix B.1. Our proof borrows techniques from Gaussian model selection [21] and the compressed sensing literature [8]. There are two steps to bound the risk error as in Lemma 12:

Step 1 - Bounding the prediction error.We can bound the prediction error \(\left\|X\theta_{\star}-X\widehat{\theta}_{t_{1}}\right\|_{2}\) using the Gaussian model selection technique [21] as follows.

**Proposition 14**.: _Let \(\bm{f}_{\star}=X\theta_{\star}\). For the choice of \(\widehat{\bm{f}}_{\widehat{m}}\) as in Eqn. (3) & Eqn. (4), with probability at least \(1-\delta\), there exists a constant \(C>1\) such that_

\[\left\|\widehat{\bm{f}}_{\widehat{m}}-\bm{f}_{\star}\right\|_{2}^{2}\leq C \sigma^{2}\log\left(M\delta^{-1}\right).\] (8)Step 2 - Bounding the risk error from prediction error.To bound the risk error from the prediction error, we invoke the restricted isometry property on the union of subspaces of a sub-Gaussian random matrix as in [8]. Note that \(\widehat{\theta}\) and \(\theta_{\star}\) can belong to two different subspaces of \(\mathcal{M}\), and \(\widehat{\theta}-\theta_{\star}\) may not lie in any subspace of \(\mathcal{M}\), but in \(\overline{\mathcal{M}}\). An important property of the design matrix \(X\), which allows one to recover \(\theta_{\star}\) with the knowledge that \(\theta_{\star}\) is in a subspace \(m\in\mathcal{M}\), can be captured by the following notion of restricted isometry property (RIP):

**Definition 15** (Restricted isometry property).: For any matrix \(X\), any collection of subspaces \(\overline{\mathcal{M}}\) and any \(\theta\in m\in\overline{\mathcal{M}}\), we define \(\overline{\mathcal{M}}\)-restricted isometry constant \(\delta_{\overline{\mathcal{M}}}(X)\) to be the smallest quantity such that

\[(1-\delta_{\overline{\mathcal{M}}}(X))\|\theta\|_{2}^{2}\leq\|X\theta\|_{2}^{ 2}\leq(1+\delta_{\overline{\mathcal{M}}}(X))\|\theta\|_{2}^{2}.\] (9)

We have the minimum number of samples required so that a random matrix \(X\) satisfies RIP for a given constant with high probability as Proposition 16 below. Then, Lemma 12 is followed by combining Proposition 16 and Proposition 14.

**Proposition 16**.: _Let \(X=[x_{t}]_{t\in[n]}\), where \(x_{t}\)'s are is i.i.d. drawn from \(\nu\), and let \(n=\Omega\left(C_{\min}^{-2}(\mathcal{X})K_{x}^{2}\left(\log(2\overline{M}d_{0} \delta^{-1})\right)\right).\) Then, with probability at least \(1-\delta\), and for any \(\theta_{1},\theta_{2}\) in subspaces of \(\mathcal{M}\), one has that_

\[\left\|\theta_{1}-\theta_{2}\right\|_{2}^{2}\leq 2C_{\min}^{-1}(\mathcal{X})n^ {-1}\left\|X(\theta_{1}-\theta_{2})\right\|_{2}^{2}.\] (10)

## 5 Improved Regret Upper Bound with Well-Separated Partitions

We now show that by adding more structure (i.e., well-separatedness) to the setting, we can further improve the regret upper bound to \(O(\sqrt{T})\). In particular, we will introduce the notion of well-separatedness in this section, and show that this notion can lead to improved (i.e., \(O(\sqrt{T})\)) regret bounds.

For each partition \(p\in\mathcal{P}_{d}\), there is a unique equivalence relation on \([d]\) corresponding to \(p\). Denote by \(\nearrow\) the equivalence relation corresponding to \(p\). Next, we define well-separatedness.

**Assumption 17** (**Well-separated partitioning)**.: _Given the true subgroup \(\mathcal{G}\), and the corresponding partition \(\pi_{\mathcal{G}}\). For all \((i,j)\) such that \(i\)\(\overset{\pi_{\mathcal{G}}}{\sim}j\), it holds that \(|\theta_{\star,i}-\theta_{\star,j}|\geq\varepsilon_{0}\), for some \(\varepsilon_{0}>0\)._

The implication of Assumption 17 is that the projection of \(\theta_{\star}\) to any subspace \(m\in\mathcal{M}\) not containing \(\theta_{\star}\) will cause some bias in the estimation error. In particular, one can show that for any \(m\in\mathcal{M}\) such that \(\theta_{\star}\notin m\), it holds that

\[\left\|\theta_{\star}-\Pi_{m}(\theta_{\star})\right\|_{2}^{2}\geq\varepsilon_ {0}^{2}/2.\] (11)

We now show that under the Assumption 17, after the exploring phase, the algorithm returns a true fixed-point subspace \(\widehat{m}\ni\theta_{\star}\) with high probability.

**Theorem 18**.: _Suppose the Assumptions 5, 6, 17 hold. Let \(t_{2}=\Omega\left(\frac{\sigma^{2}K_{x}^{2}d_{0}\log(dT)}{C_{\min}^{2}( \mathcal{X})\varepsilon_{0}^{2}}\right)\). Then, Algorithm 2 returns \(\widehat{m}\ni\theta_{\star}\) with probability at least \(1-1/T\), and its regret is upper bounded as_

\[\mathbf{R}_{T}=O\left(\frac{R_{\max}\sigma^{2}K_{x}^{2}d_{0}\log(dT)}{C_{\min} ^{2}(\mathcal{X})\varepsilon_{0}^{2}}+\sigma d_{0}\sqrt{T\log(K_{x}T)}\right).\] (12)

That is, if the separating constant \(\varepsilon_{0}\) is known in advance and \(\varepsilon_{0}\geq T^{-1/4}\), then we can achieve \(O(d_{0}\sqrt{T}\log(K_{x}T))\) regret upper bound.

**Remark 19**.: A weakness of Algorithm 2 is that without knowing that \(\varepsilon_{0}\geq T^{-1/4}\) is true a priori, there may be possible mis-specification error, which leads to linear regret if one applies the algorithm naively. On the other hand, Algorithm 1 can always achieve regret \(O(T^{2/3})\) in the worst case. As such, the following question arises: _Does there exist an algorithm that, without the knowledge of \(\varepsilon_{0}\), can achieve regret \(O(\sqrt{T})\) whenever \(\varepsilon_{0}\geq T^{-1/4}\), but guarantees the worst-case regret of \(O(T^{2/3})\)?_ Toward answering this question, we propose a simple method which has \(O(\sqrt{T})\) regret whenever the separating constant is large, and enjoys a worst-case regret guarantee of \(O(T^{3/4})\) (slightly worse than \(O(T^{2/3})\)). We refer the reader to Appendix C.2 for a detailed description of the algorithm, its regret bound and further discussion.

## 6 Experiment

To illustrate the performance of our algorithm, we conduct simulations where the entries of \(\theta_{\star}\) satisfy three cases: sparsity, non-crossing partitions and non-nesting partitions. We refer readers to Appendix D.1 for a more formal description of non-crossing partitions, non-nesting partitions, and why the interval partition (i.e., the partition structure equivalent to sparsity) is a strict subset of both non-crossing and non-nesting partitions. Since sparsity is equivalent to a strict subset of non-crossing and non-nesting partitions, we compare our Algorithm 1 with the sparse-bandit ESTC algorithm proposed in [23] as a benchmark in all environments. The set of arms \(\mathcal{X}\) is \(\sqrt{d}\mathbb{S}^{d-1}\), \(\sigma=0.1\), and \(d=100\), \(d_{0}=15\). The ground-truth sparse patterns, partitions and \(\theta_{\star}\) are randomized before each simulation.

The regret of both algorithms is shown in Figure 2, which indicates that our algorithm performs competitively in the sparsity case and significantly outperforms the sparse-bandit algorithm in cases of non-crossing and non-nesting partitions. Due to space limitations, we refer the reader to Appendix E for a detailed description of the experiments, including how we applied the sparse-bandit algorithm in the cases of non-crossing and non-nesting partitions, and how we ran Algorithm 1 in the case of sparsity. Additionally, we explain how we exploited the particular structure of non-crossing and non-nesting partitions to enable efficient computation in Appendix E.

## 7 Conclusion and Future Work

In this paper, we study symmetric linear stochastic bandits in high dimensions, where the linear reward function is invariant with respect to some hidden subgroup \(\mathcal{G}\leq\mathcal{S}_{d}\). We first prove that no algorithm can gain any advantage solely by knowing \(\mathcal{G}\leq S_{d}\). Given this, we introduce a cardinality condition on the hidden subgroup \(\mathcal{G}\), allowing the learner to overcome the curse of dimensionality. Under this condition, we propose novel model selection algorithms that achieve regrets of \(\tilde{O}(d_{0}^{2/3}T^{2/3})\) and \(\tilde{O}(d_{0}\sqrt{T})\) with an additional assumption on the well-separated partition. For future work, we will explore convex relaxation techniques for efficient computation, leveraging specific structures of symmetries.

Figure 2: Regret of EMC (Algorithm 1) and of ESTC proposed in [23], in cases of sparsity, non-crossing partitions, and non-nesting partitions.

## References

* [1] Yasin Abbasi-yadkori, David Pal, and Csaba Szepesvari. Improved algorithms for linear stochastic bandits. In _Advances in Neural Information Processing Systems_, 2011.
* [2] Yasin Abbasi-Yadkori, David Pal, and Csaba Szepesvari. Online-to-confidence-set conversions and application to sparse stochastic bandits. In _Journal of Machine Learning Research_, 2012.
* [3] Miguel Abreu, Luis Paulo Reis, and Nuno Lau. Addressing imperfect symmetry: a novel symmetry-learning actor-critic extension. _arXiv preprint arXiv:2309.02711_, 2023.
* [4] Alekh Agarwal, Haipeng Luo, Behnam Neyshabur, and Robert E. Schapire. Corralling a band of bandit algorithms. In _Proceedings of the 2017 Conference on Learning Theory_, 2016.
* [5] Richard Baraniuk, Mark Davenport, Ronald DeVore, and Michael Wakin. A simple proof of the restricted isometry property for random matrices. _Constructive Approximation_, 2008.
* [6] Arash Behboodi, Gabriele Cesa, and Taco Cohen. A pac-bayesian generalization bound for equivariant networks. In _Advances in Neural Information Processing Systems_, 2022.
* [7] Lucien Birge and Pascal Massart. Minimal penalties for gaussian model selection. _Probability Theory and Related Fields_, 2007.
* [8] Thomas Blumensath and Mike E. Davies. Sampling theorems for signals from the union of finite-dimensional linear subspaces. _IEEE Transactions on Information Theory_, 55, 2009.
* [9] Michael M. Bronstein, Joan Bruna, Taco Cohen, and Petar Velickovic. Geometric deep learning: Grids, groups, graphs, geodesics, and gauges, 2021.
* [10] R. Bodi and K. Herr. Symmetries in linear and integer programs. _arXiv preprint arXiv:0908.3329_, 2009.
* [11] Alexandra Carpentier and Remi Munos. Bandit theory meets compressed sensing for high-dimensional stochastic linear bandit. In _Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics_, 2012.
* [12] Gabriele Cesa, Leon Lang, and Maurice Weiler. A program to build e(n)-equivariant steerable cnns. In _International Conference on Learning Representations_, 2022.
* [13] Minshuo Chen, Yan Li, Ethan Wang, Zhuoran Yang, Zhaoran Wang, and Tuo Zhao. Pessimism meets invariance: Provably efficient offline mean-field multi-agent rl. In _Advances in Neural Information Processing Systems_, 2021.
* [14] William Chen, Eva Deng, Rosena Du, Richard Stanley, and Catherine Yan. Crossings and nestings of matchings and partitions. _Transactions of the American Mathematical Society_, 2006.
* [15] Nachum Dershowitz and Shmuel Zaks. Ordered trees and non-crossing partitions. _Discrete Mathematics_, 1986.
* [16] Bryn Elesedy and Sheheryar Zaidi. Provably strict generalisation benefit for equivariant models. In _International Conference on Machine Learning_, 2021.
* [17] Marc Finzi, Samuel Stanton, Pavel Izmailov, and Andrew Gordon Wilson. Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data. In _International Conference on Machine Learning_, 2020.
* [18] Dylan J. Foster, Akshay Krishnamurthy, and Haipeng Luo. Model selection for contextual bandits. In _Advances in Neural Information Processing Systems_, 2019.
* [19] Dylan J Foster, Claudio Gentile, Mehryar Mohri, and Julian Zimmert. Adapting to misspecification in contextual bandits. In _Advances in Neural Information Processing Systems_, 2020.
* [20] Avishek Ghosh, Abishek Sankararaman, and Kannan Ramchandran. Problem-complexity adaptive model selection for stochastic linear bandits. _arXiv preprint arXiv:2006.02612_, 2020.
* [21] Christophe Giraud. _Introduction to High-Dimensional Statistics_. 2021.

* [22] Robert Givan, Thomas Dean, and Matthew Greig. Equivalence notions and model minimization in markov decision processes. _Artificial Intelligence_, 7 2003.
* [23] Botao Hao, Tor Lattimore, and Mengdi Wang. High-dimensional sparse linear bandits. In _Advances in Neural Information Processing Systems_, 2020.
* [24] Kyoungseok Jang, Chicheng Zhang, and Kwang-Sung Jun. Popart: Efficient sparse regression and experimental design for optimal sparse linear bandits. In _Advances in Neural Information Processing Systems_, 2022.
* [25] Parnian Kassraie, Aldo Pacchiano, Nicolas Emmenegger, and Andreas Krause. Anytime model selection in linear bandits. In _Advances in Neural Information Processing Systems_, 2023.
* [26] Gi-Soo Kim and Myunghee Cho Paik. Doubly-robust lasso bandit. In _Advances in Neural Information Processing Systems_, 2019.
* [27] Tor Lattimore and Csaba Szepesvari. _Bandit Algorithms_. Cambridge University Press, 7 2020.
* [28] Tor Lattimore, Koby Crammer, and Csaba Szepesvari. Linear multi-resource allocation with semi-bandit feedback. In _Advances in Neural Information Processing Systems_, 2015.
* [29] Chung-Wei Lee, Qinghua Liu, Yasin Abbasi-Yadkori, Chi Jin, Tor Lattimore, and Csaba Szepesvari. Context-lumpable stochastic bandits. 6 2023.
* [30] Chi Kwong Li and Roy Mathias. The lidskii-mirsky-wielandt theorem-additive and multiplicative versions. _Numerische Mathematik_, 1999.
* [31] Zhiyuan Li, Ruosong Wang, Dingli Yu, Simon S. Du, Wei Hu, Ruslan Salakhutdinov, and Sanjeev Arora. Enhanced convolutional neural tangent kernels. 11 2019.
* [32] Anuj Mahajan and Theja Tulabandhula. Symmetry learning for function approximation in reinforcement learning. _arXiv preprint arXiv:1706.02999_, 2017.
* [33] Toufik Mansour. _Combinatorics of Set Partitions_. 2012.
* [34] Washim Uddin Mondal, Mridul Agarwal, Vaneet Aggarwal, and Satish V. Ukkusuri. On the approximation of cooperative heterogeneous multi-agent reinforcement learning (marl) using mean field control (mfc). _Journal of Machine Learning Research_, 2022.
* [35] Ahmadreza Moradipari, Berkay Turan, Yasin Abbasi-Yadkori, Mahnoosh Alizadeh, and Mohammad Ghavamzadeh. Feature and parameter selection in stochastic linear bandits. In _International Conference on Machine Learning_, 2022.
* [36] Min-hwan Oh, Garud Iyengar, and Assaf Zeevi. Sparsity-agnostic lasso bandit. In _International Conference on Machine Learning_, 2021.
* [37] Aldo Pacchiano, Christoph Dann, Claudio Gentile, and Peter Bartlett. Regret bound balancing and elimination for model selection in bandits and rl. _arXiv preprint arXiv:2012.13045_, 2020.
* [38] Aldo Pacchiano, Christoph Dann, and Claudio Gentile. Data-driven online model selection with regret guarantees. In _International Conference on Artificial Intelligence and Statistics_, 2024.
* [39] Fabien Pesquerel, Hassan Saber, and Odalric Ambrym Maillard. Stochastic bandits with groups of similar arms. In _Advances in Neural Information Processing Systems_, 2021.
* [40] B Ravindran and A G Barto. Approximate homomorphisms: A framework for non-exact minimization in markov decision processes. _Proceedings of the Fifth International Conference on Knowledge Based Computer Systems (KBCS 04)_, 2004.
* [41] Nam Phuong Tran and Long Tran-Thanh. Invariant lipschitz bandits: A side observation approach. In _Machine Learning and Knowledge Discovery in Databases: Research Track_, 12 2022.
* [42] Elise van der Pol, Thomas Kipf, Frans A. Oliehoek, and Max Welling. Plamnable approximations to mdp homomorphisms: Equivariance under actions. In _International Joint Conference on Autonomous Agents and Multiagent Systems_, 2020.

* [43] Elise van der Pol, Daniel E. Worrall, Herke van Hoof, Frans A. Oliehoek, and Max Welling. Mdp homomorphic networks: Group symmetries in reinforcement learning. In _Advances in Neural Information Processing Systems_, 2020.

###### Contents of Appendix

* A Impossibility Result of Learning with General Hidden Subgroups
* B The Case of Hidden Subgroups with Subexponential Size
* B.1 Lower Bound for the Case of Hidden Subgroups with Subexponential Size
* B.2 High Probability Prediction Error of Model Selection
* B.3 Regret Upper bound
* C Improved Regret Bound
* C.1 Improve Regret Bound with Well-Separated Partitions
* C.2 Adapting to Separating Constant \(\varepsilon_{0}\)
* D On Collections of Partitions with Subexponential-Size
* D.1 Important Classes of Partitions with Subexponential-Size
* D.2 Practical Examples of Partitions with Subexponential-Size
* D.3 Efficient Greedy Algorithm for Specific Classes of Partitions
* E Experiment details
* F Extended Related Work

### Additional notations

For any subset \(S\subseteq\mathbb{R}^{d}\), and matrix \(W\in\mathbb{R}^{d\times d}\), we write \(W(S):=\{Wx\mid x\in S\}\).

## Appendix A Impossibility Result of Learning with General Hidden Subgroups

To prove Proposition 1, we need to prove Proposition 20 and use Proposition 21.

**Proposition 20**.: _For each \(\Gamma\leq\mathcal{S}_{d}\) acting naturally on \([d]\), the orbit of \(\Gamma\) on \([d]\) forms a unique partition of \([d]\). Moreover, for each partition \(\rho\in\mathcal{P}_{d}\), there exists at least one \(\Gamma\leq\mathcal{S}_{d}\) such that its orbit on \([d]\) under natural action is exactly \(\rho\)._

Proof.: The first claim is obvious by the property of orbit, that is, orbit consists of non-empty and disjoint subsets of \([d]\), whose union is \([d]\).

We prove the second claim. Let \(\rho=\{\rho_{i}\}_{i\in I}\), where \(I\) is the index of partition; note that \(\rho_{i}\) is nonempty and mutually disjoint. Define a group as follows

\[\Gamma_{i}=\{f:\rho_{i}\rightarrow\rho_{i}\mid f\text{ is bijective}\}\,;\] (13)

It is clear that \(\Gamma_{i}\) is a group under function composition. Now, define the product group

\[\Gamma:=\prod_{i\in I}\Gamma_{i},\]

and the action \(\psi:\ \Gamma\times[d]\rightarrow[d]\) such that

\[\psi\left((f_{i})_{i\in I},x\right):=f_{j}(x),\quad\text{for }\rho_{j} \ni x.\] (14)

Therefore, it is clear that \((f_{i})_{i\in I}\) is a bijection from \([d]\) onto itself, hence, \(\Gamma\) is a subgroup of \(\mathcal{S}_{d}\)Let \(E=(e_{i})_{i\in[d]}\) be the standard basis. Given that group \(\mathcal{G}\) partition \([d]\) into \(k\) disjoint orbits, \(\mathcal{G}\) also partition \(E\) into \(k\) disjoint orbits corresponding to its action \(\phi\) on \(\mathbb{R}^{d}\), that is,

\[E=\bigcup_{i=1}^{k}E_{i}.\]

Let \(V_{i}=\operatorname{Span}(E_{i})\), then, one has the following.

**Proposition 21** ([10]'s Theorem 14).: \[\operatorname{Fix}_{\mathcal{G}}(\mathbb{R}^{d})=\bigoplus_{i=1}^{k} \operatorname{Fix}_{\mathcal{G}}(V_{i}).\] (15)

We now state the proof of Proposition 1 as a corollary of Proposition 20 and Proposition 21.

**Proposition 1**.: _There is a bijection \(\mathbf{H}\) between \(\mathcal{P}_{d}\) and \(\mathcal{F}_{\mathcal{S}_{d}}\)._

Proof.: **First**, we show that for each set partition of \([d]\), there exists a unique \(H\in\mathcal{F}_{\mathcal{S}_{d}}(\mathbb{R}^{d})\). This is straightforward due to the fact that, given a set partition \(P\), the partition of basis \((E_{i})_{i\in I}\) is unique by definition, so as \(V_{i}=\operatorname{span}(E_{i})\). As a result, let \(H=\bigoplus_{i=1}^{k}\operatorname{Fix}_{\Gamma}(V_{i})\), by Proposition 21, \(H\in\mathcal{F}_{\mathcal{S}_{d}}(\mathbb{R}^{d})\). As \((V_{i})_{i\in I}\) is unique, \(H\) is unique.

**Second**, we show that for each \(H\in\mathcal{F}_{\mathcal{S}_{d}}(\mathbb{R}^{d})\), there is a unique set partition/equivalent relation \(P\). Denote \(\overset{\mathrm{P}}{\sim}\) as an equivalent relation under the set partition \(P\). Suppose there are two different set partitions \(P,\ Q\), there must be two set element \(p\ q\) such that \(p\overset{\mathrm{P}}{\sim}q\) under \(P\), and \(p\overset{\mathrm{Q}}{\sim}q\) under \(Q\). Denote \(H_{P},\ H_{Q}\) as the subspaces defined by \(P\) and \(Q\) respectively. As \(p\overset{\mathrm{Q}}{\sim}q\), there must exist a point \(x\in H_{Q}\) such that \(x_{p}\neq x_{q}\). However, \(x_{p}=x_{q}\) for all \(x\in H_{P}\). Hence, \(H_{P}\) cannot be the same as \(H_{Q}\). 

**Proposition 3**.: _Assume that the action set is the unit cube \(\mathcal{X}=\{x\in\mathbb{R}^{d}\ |\ \|x\|_{\infty}\leq 1\}\), and \(f\) is invariant w.r.t. action of subgroup \(\mathcal{G}\leq\mathcal{S}_{d}\), such that \(\dim(\operatorname{Fix}_{\mathcal{G}})=2\). Then, the regret of any bandit algorithm is lower bounded by \(\mathbf{R}_{T}=\Omega(d\sqrt{T})\)._

Proof.: Suppose there is a collection of model parameter \(\Theta=\{-\varepsilon,\ \varepsilon\}^{d}\), for some \(\varepsilon>0\). For each \(\theta\in\Theta\), it is straightforward that since \(\theta\) has two classes of indices, by Proposition 1 and \(2\), there must be a subgroup \(\mathcal{G}\leq\mathcal{S}_{d}\) such that \(\theta\in\operatorname{Fix}_{\mathcal{G}}\) and \(\dim{(\operatorname{Fix}_{\mathcal{G}})}=2\).

Now, \(\Theta\) can be used as a family of problem instances for minimax lower bound of linear bandit. By Theorem 24.1 in [27], we have that with the choice of \(\varepsilon=T^{-1/2}\), one has that

\[\mathbf{R}_{T}\geq\frac{\exp-2}{\sqrt{8}}d\sqrt{T}.\] (16)

## Appendix B The Case of Hidden Subgroups with Subexponential Size

### Lower Bound for the Case of Hidden Subgroups with Subexponential Size

**Proposition 9** (Regret lower bound).: _There exist symmetric linear bandit instances in which Assumption 5, 6 hold with \(K_{x}=8d_{0}\), such that, any bandit algorithm must suffer regret \(\mathbf{R}_{T}=\Omega\left(\min\left(C_{\min}(\mathcal{X})^{-\frac{1}{3}}d_{0 }^{\frac{2}{3}}T^{\frac{3}{3}},\sqrt{dT}\right)\right)\)._

Proof sketch.: First, we show a change of variable between the sparsity and interval partition cases, including the parameter space and set of arms. Next, we demonstrate that mapping the problem instances in the lower bound of sparse bandits in [23, 24] satisfies the constraints in Assumption 6. After that, the proof follows immediately by carrying out step-by-step calculations similar to those in [23, 24].

First, let us define the sparse bandit instances. Let \(\mathcal{Z}\) be the set of arm of sparse bandit problem, such that \(\forall z\in\mathcal{Z},\ \|z\|_{\infty}\leq 1\). Let \(\varphi\in\mathbb{R}^{d}\) be a \(d_{0}\)-sparse parameters. Now, let us define the mapping that corresponds to change of variable between \(\theta\) and \(\varphi\) as follows: (1) For \(i\in[d-1]\), \(\varphi_{i}=\theta_{i}-\theta_{i+1}\), (2) \(\varphi_{d}=\theta_{d}\). Therefore, one can write

\[\varphi=\underbrace{\begin{bmatrix}1&-1&0&0&\cdots&0&0\\ 0&1&-1&0&\cdots&0&0\\ 0&0&1&-1&\cdots&0&0\\ \vdots&\vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\ \vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\ 0&0&0&0&\cdots&1&-1\\ 0&0&0&0&\cdots&0&1\end{bmatrix}}_{W\in\mathbb{R}^{d\times d}}\theta.\] (17)

It is easy to verify that entries of \(\theta\) has \(k\) equivalent classes if and only if \(\varphi\) is \(k\) sparse. Now, suppose expected reward for a arm \(x\) in interval-partition instance is equal to expected reward for an arm \(z\) in sparsity instance, that is,

\[\left\langle x,\theta\right\rangle=\left\langle(W^{\top})^{-1}x,W\theta \right\rangle=\left\langle z,\varphi\right\rangle.\] (18)

Therefore, to guarantee the bijection between sparsity and interval partition instance, we define the set of arm \(\mathcal{X}=W^{\top}(\mathcal{Z}):=\left\{W^{\top}z\mid z\in\mathcal{Z}\right\}\).

We need to prove that \(\mathcal{X}\) satisfies Assumption 6. Therefore, \(x=W^{\top}z\), and \(\mathcal{X}=W^{\top}(\mathcal{Z})\). Our job is to verify that, for all \(z\in[-1,\ 1]^{d}\), the projection \(\|\Pi_{m}(Vz)\|_{2}\leq\sqrt{8d_{0}}\), for any \(m\) such that \(\dim(m)\leq 2d_{0}\). Let \(S_{1},...,S_{\dim(m)}\) be the classes according to the interval partition corresponding to \(m\), such that

\[\begin{split}\|\Pi_{m}(x)\|_{2}^{2}&=\sum_{k=1}^{\dim(m )}\left(\underbrace{\frac{1}{|S_{k}|}\sum_{i=(\sum_{j<k}|S_{j}|)+1}^{\sum_{j \leq k}|S_{k}|}x_{i}}_{\text{average of entries within class $S_{k}$}}\right)^{2}|S_{k}|\\ &=\sum_{k=1}^{\dim(m)}\frac{1}{|S_{k}|}\left(\sum_{i=(\sum_{j<k}| S_{j}|+1)}^{\sum_{j\leq k}|S_{k}|}x_{i}\right)^{2}.\end{split}\] (19)

Since \(x=W^{\top}z\), we have that \(x_{i}=-z_{i-1}+z_{i},\ \forall i\in[d]\), with \(z_{0}=0\) for convenience. Note that \(z_{i}\in[-1,1]\forall i\in[d]\). We have that

\[\begin{split}\|\Pi_{m}(W^{\top}z)\|_{2}^{2}&=\sum_{k=1}^ {\dim(m)}\frac{1}{|S_{k}|}\left(\underbrace{\sum_{i=(\sum_{j<k}|S_{j}|+1)}^{ \sum_{j\leq k}|S_{j}|}-z_{i-1}+z_{i}}_{\text{Telescoping sum}}\right)^{2}\\ &\leq\sum_{k=1}^{\dim(m)}\frac{4}{|S_{k}|}\leq 8d_{0}.\end{split}\] (20)

Therefore, we have that, for all \(x\in\mathcal{X}=W^{\top}(\mathcal{Z})\), \(\left\|\Pi_{m}(x)\right\|_{2}\leq 2\sqrt{2d_{0}}\).

Moreover, we also have that \(C_{\min}(\mathcal{X})\geq C_{\min}(\mathcal{Z})\). Particularly, let us denote the exploratory distribution on \(\mathcal{Z}\) as

\[\rho=\operatorname*{arg\,max}_{\omega\in\Delta(\mathcal{Z})}\lambda_{\min} \left(\mathbb{E}_{z\sim\omega}[zz^{\top}]\right),\quad P:=\mathbb{E}_{z\sim \rho}[zz^{\top}],\quad C_{\min}(\mathcal{Z}):=\lambda_{\min}(P).\] (21)Define \(\mu(x):=\rho((W^{\top})^{-1}z)\), and let \(U:=\mathbb{E}_{x\sim\mu}[x^{\top}x]\), we have that \(U=W^{\top}PW\). Since all eigenvalue of \(W\) is \(1\), according to [30], we have that \(\lambda_{i}(P)=\lambda_{i}(U)\) for all \(i\in[d]\). Therefore, we have that \(C_{\min}(\mathcal{X})\geq C_{\min}(\mathcal{Z})\).

Then, using change of variable argument, the calculation of the lower bound is identical to that of [23, 24]. Therefore, we can conclude that all policies must suffer regret

\[\mathbf{R}_{T}=\Omega(C_{\min}(\mathcal{X})^{-\frac{1}{3}}d_{0}^{\frac{2}{3}}T ^{\frac{2}{3}},\sqrt{dT}).\]

### High Probability Prediction Error of Model Selection

The proof of Proposition 14 uses the following concentration.

**Proposition 22** ([21]'s Theorem B.7).: _For some subspace \(S\subset\mathbb{R}^{n}\) of dimension \(d_{S}\), with probability at least \(1-\delta\), one has that_

\[\left|\left|\left|\Pi_{S}(\boldsymbol{\eta})\right|\right|_{2}-\sigma\sqrt{d _{S}}\right|\leq\sigma\sqrt{2\log\left(\frac{1}{\delta}\right)}.\] (22)

**Proposition 14**.: _Let \(\boldsymbol{f}_{\star}=X\theta_{\star}\). For the choice of \(\widehat{\boldsymbol{f}}_{\widehat{m}}\) as in Eqn. (3) & Eqn. (4), with probability at least \(1-\delta\), there exists a constant \(C>1\) such that_

\[\left\|\widehat{\boldsymbol{f}}_{\widehat{m}}-\boldsymbol{f}_{\star}\right\| _{2}^{2}\leq C\sigma^{2}\log\left(M\delta^{-1}\right).\] (8)

Proof.: Define \(\mathcal{E}_{1}\) as the event such that for all \(m\in\mathcal{M}\),

\[\left\|\Pi_{S_{m}}(\boldsymbol{\eta})\right\|_{2}\leq\sigma\sqrt{d_{m}}+\sigma \sqrt{2\log\left(\frac{1}{\delta_{0}}\right)}.\] (23)

By Proposition 22 and union bound, \(\mathcal{E}_{1}\) occurs with probability \(1-M\delta_{0}\). For the rest of the proof, we assume \(\mathcal{E}_{1}\) occurs.

Let us denote \(\widehat{\boldsymbol{f}}:=\widehat{\boldsymbol{f}}_{\widehat{m}}\). By the model selection procedure (4), one has that

\[\|Y-\widehat{\boldsymbol{f}}\|^{2}\leq\|Y-\widehat{\boldsymbol{f}}_{m_{\star} }\|^{2}.\] (24)

Also, as \(Y=\boldsymbol{f}_{\star}+\boldsymbol{\eta}\), one has that, for some \(K>1\)

\[\left\|\widehat{\boldsymbol{f}}-\boldsymbol{f}_{\star}\right\|_{2}^{2}\leq \left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{m_{\star}}\right\|_{2 }^{2}+2\left\langle\boldsymbol{\eta},\boldsymbol{f}_{\star}-\widehat{ \boldsymbol{f}}_{m_{\star}}\right\rangle+K\sigma^{2}d_{\widehat{m}}-2\left \langle\boldsymbol{\eta},\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}} \right\rangle-K\sigma^{2}d_{\widehat{m}}.\] (25)

**First**, consider the term \(\left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{m_{\star}}\right\|_{2 }^{2}\). Note that, \(\Pi_{S_{m_{\star}}}(\boldsymbol{f}_{\star})=\boldsymbol{f}_{\star}\), as \(\boldsymbol{f}_{\star}\in S_{m_{\star}}\). We have that,

\[\left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{m_{\star}}\right\|_ {2}^{2} =\left\|\boldsymbol{f}_{\star}-\Pi_{S_{m_{\star}}}(\boldsymbol{f}_{ \star}+\boldsymbol{\eta})\right\|_{2}^{2}\] (26) \[=\left\|\boldsymbol{f}_{\star}-\boldsymbol{f}_{\star}\right\|_{2}^ {2}-2\left\langle\Pi_{S_{m_{\star}}}(\boldsymbol{\eta}),\boldsymbol{f}_{\star}- \boldsymbol{f}_{\star}\right\rangle+\left\|\Pi_{S_{m_{\star}}}(\boldsymbol{\eta })\right\|_{2}^{2}\] \[\leq\left(\sigma\sqrt{d_{m_{\star}}}+\sigma\sqrt{2\log\left(\frac {1}{\delta_{0}}\right)}\right)^{2}\] \[\leq 2\sigma^{2}d_{0}+4\sigma^{2}\log\left(\frac{1}{\delta_{0}} \right).\]

**Second**, consider the term \(\left\langle\bm{\eta},\bm{f}_{\star}-\widehat{\bm{f}}_{m_{\star}}\right\rangle\). We have that,

\[\left\langle\bm{\eta},\bm{f}_{\star}-\widehat{\bm{f}}_{m_{\star}}\right\rangle =\left\langle\bm{\eta},\bm{f}_{\star}-\Pi_{S_{m_{\star}}}(\bm{f}_ {\star}+\bm{\eta})\right\rangle\] (27) \[=\left\langle\bm{\eta},\bm{f}_{\star}-\bm{f}_{\star}\right\rangle- \left\|\Pi_{S_{m_{\star}}}(\bm{\eta})\right\|_{2}^{2}\leq 0.\]

**Third**, we need to control the magnitude of the term \(2\left\langle\bm{\eta},\widehat{\bm{f}}-\bm{f}_{\star}\right\rangle-K\sigma^{ 2}d_{\widehat{m}}\). We show that this term can be bounded as

\[2\left\langle\bm{\eta},\widehat{\bm{f}}-\bm{f}_{\star}\right\rangle-K\sigma^ {2}d_{\widehat{m}}\leq a^{-1}\left\|\widehat{\bm{f}}-\bm{f}_{\star}\right\|_ {2}^{2}+O(\log(1/\delta_{0})),\]

with probability at least \(1-M\delta_{0}\), for any constant \(a>0\). Denote \(\left\langle\bm{f}_{\star}\right\rangle\) be the line that is spanned by \(\bm{f}_{\star}\). For each \(m\in\mathcal{M}\), let us define the subspace \(\tilde{S}_{m}=S_{m}+\left\langle\bm{f}_{\star}\right\rangle\). Define \(\tilde{S}_{m}\subset\tilde{S}_{m}\) as the subspace that is orthogonal to \(\left\langle\bm{f}_{\star}\right\rangle\), that is, one can write \(\tilde{S}_{m}=\tilde{S}_{m}\bigoplus\left\langle\bm{f}_{\star}\right\rangle\). By AM-GM inequality, for some \(a>0\), we have that

\[2\left\langle\bm{\eta},\widehat{\bm{f}}-\bm{f}_{\star}\right\rangle=2 \left\langle\Pi_{\tilde{S}_{\widehat{m}}}(\bm{\eta}),\widehat{\bm{f}}-\bm{f}_ {\star}\right\rangle =2\left\langle\sqrt{a}\cdot\Pi_{\tilde{S}_{\widehat{m}}}(\bm{ \eta}),\frac{1}{\sqrt{a}}\left(\widehat{\bm{f}}-\bm{f}_{\star}\right)\right\rangle\] (28) \[\leq a\left\|\Pi_{\tilde{S}_{\widehat{m}}}(\bm{\eta})\right\|_{2 }^{2}+a^{-1}\left\|\widehat{\bm{f}}-\bm{f}_{\star}\right\|_{2}^{2}\] \[=a\sigma^{2}V+a\sigma^{2}U_{\hat{m}}+a^{-1}\left\|\widehat{\bm{f }}-\bm{f}_{\star}\right\|_{2}^{2},\]

where \(V=\sigma^{-2}\left\|\Pi_{\left\langle\bm{f}_{\star}\right\rangle}(\bm{\eta}) \right\|_{2}^{2}\) and \(U_{\hat{m}}=\sigma^{-2}\left\|\Pi_{\tilde{S}_{\hat{m}}}(\bm{\eta})\right\|_{2} ^{2}\). Note that, as \(\dim(\left\langle\bm{f}_{\star}\right\rangle)=1\), with probability at least \(1-\delta_{0}\), one has that

\[V\leq 2+4\log(\delta_{0}^{-1}).\] (29)

Define the event \(\mathcal{E}_{2}\) as the event where the above inequality holds.

Therefore, our final task is to control the quantity \(aU_{\hat{m}}-Kd_{\widehat{m}}\). Choose \(a=(K+1)/2>1\), one has that

\[aU_{\hat{m}}-Kd_{\widehat{m}}=\frac{K+1}{2}\left(U_{\hat{m}}-\frac{2K}{K+1}d_ {\widehat{m}}\right)\leq\frac{K+1}{2}\max_{m\in\mathcal{M}}\left(U_{m}-\frac {2K}{K+1}d_{m}\right).\]

Now, directly control the magnitude of \(U_{\hat{m}}-\frac{2K}{K+1}d_{\widehat{m}}\) is difficult, as \(\widehat{m}\) depends on \(\bm{\eta}\), and their distribution might be complicated. Instead, we will control the maximum of the above quantity \(U_{m}-\frac{2K}{K+1}d_{m}\) over all \(m\in\mathcal{M}\). Since the dimension of \(\tilde{S}_{m}\) is at most \(d_{m}\), similar as the event \(\mathcal{E}_{1}\), we define the event \(\mathcal{E}_{3}\) as for all \(m\in\mathcal{M}\), we have that

\[\left\|\Pi_{\tilde{S}_{m}}(\bm{\eta})\right\|_{2}\leq\sigma\sqrt{d_{m}}+\sigma \sqrt{2\log\left(\frac{1}{\delta_{0}}\right)}.\] (30)

By Proposition 22 and the union bound, \(\mathcal{E}_{3}\) occurs with probability at least \(1-M\delta_{0}\). We assume that \(\mathcal{E}_{3}\) occurs, then for all \(m\in\mathcal{M}\),

\[U_{m} \leq\left(\sqrt{d_{m}}+\sqrt{2\log\left(\frac{1}{\delta_{0}} \right)}\right)^{2}\] (31) \[\leq\frac{2K}{K+1}d_{m}+\frac{4K}{K-1}\log\left(\frac{1}{\delta_{0 }}\right).\]Therefore, one has that for all \(m\in\mathcal{M}\),

\[\begin{split}\frac{K+1}{2}\left(U_{\hat{m}}-\frac{2K}{K+1}d_{\hat{m} }\right)&\leq\frac{K+1}{2}\max_{m\in\mathcal{M}}\left(U_{m}- \frac{2K}{K+1}d_{m}\right)\\ &\leq\frac{2K(K+1)}{K-1}\log\left(\frac{1}{\delta_{0}}\right). \end{split}\] (32)

**Putting things together,** let \(\delta=(2M+1)\delta_{0}\), we assure that event \(\mathcal{E}_{1}\cap\mathcal{E}_{2}\cap\mathcal{E}_{3}\) occurs with probability at least \(1-\delta\). Combining (26), (27), (29), (32), with (25), one has that

\[\begin{split}\frac{K-1}{K+1}\left\|\widehat{\bm{f}}-\bm{f}_{ \star}\right\|_{2}^{2}&\leq 2\sigma^{2}d_{0}+4\sigma^{2}\log \left(\frac{2M+1}{\delta}\right)+K\sigma^{2}d_{0}\\ &+\sigma^{2}(K+1)+2\sigma^{2}(K+1)\log\left(\frac{2M+1}{\delta} \right)+\sigma^{2}\frac{2K(K+1)}{K-1}\log\left(\frac{2M+1}{\delta}\right). \end{split}\] (33)

Note that, the dominating term in the above equation is \(\log\left(\frac{M}{\delta}\right)\), we have that, there is some constant \(C>0\).

\[\left\|\widehat{\bm{f}}-\bm{f}_{\star}\right\|_{2}^{2}\leq C\sigma^{2}\log \left(\frac{M}{\delta}\right).\] (34)

**Proposition 16**.: _Let \(X=[x_{t}]_{t\in[n]}\), where \(x_{t}\)'s are is i.i.d. drawn from \(\nu\), and let \(n=\Omega\left(C_{\min}^{-2}(\mathcal{X})K_{x}^{2}\left(\log(2\overline{M}d_{0} \delta^{-1})\right)\right).\) Then, with probability at least \(1-\delta\), and for any \(\theta_{1},\theta_{2}\) in subspaces of \(\mathcal{M}\), one has that_

\[\left\|\theta_{1}-\theta_{2}\right\|_{2}^{2}\leq 2C_{\min}^{-1}(\mathcal{X})n^{ -1}\left\|X(\theta_{1}-\theta_{2})\right\|_{2}^{2}.\] (10)

Proof.: Our proof strategy is inspired by [8].

First, we compute the subgaussian norm for the normalised distribution along fews directions \(\nu\). For any \(x\in\mathcal{X}\), we have that

\[\begin{split}\max_{\begin{subarray}{c}\left\|v\right\|_{2}=1, \\ v\in V^{1/2}(\overline{m}),\ \overline{m}\in\overline{\mathcal{M}}\end{subarray}}\left\langle V^{-1/2}x, v\right\rangle^{2}&=\max_{\begin{subarray}{c}\left\|V^{1/2}\omega \right\|_{2}=1,\\ \omega\in\overline{m},\ \overline{m}\in\overline{\mathcal{M}}\end{subarray}} \left\langle V^{-1/2}x,V^{1/2}\omega\right\rangle^{2}\\ &=\max_{\begin{subarray}{c}\left\|V^{1/2}\omega\right\|_{2}=1,\\ \omega\in\overline{m},\ \overline{m}\in\overline{\mathcal{M}}\end{subarray}} \left\langle x,\omega\right\rangle^{2}\\ &\leq\max_{\overline{m}\in\overline{\mathcal{M}}}\left\|\Pi_{ \overline{m}}(x)\right\|_{2}^{2}C_{\min}^{-1}(\mathcal{X})\leq\frac{K_{x}}{C_ {\min}(\mathcal{X})}.\end{split}\] (35)

This means that, the distribution \(\left\langle V^{-1/2}x,v\right\rangle^{2}\) has bounded support \([0,\ \frac{K_{x}}{C_{\min}}]\) for any above direction of \(v\).

Next, for any \(\theta\in\overline{m}\), denote \(\theta_{V}:=V^{1/2}\theta\), note that the direction \(v\) corresponding to \(\theta_{V}\) satisfies (35). Using Hoeffding's inequality for bounded random variable, there is an absolute constant \(c_{1}>0\) such that

\[\begin{split}&\Pr\left\{\left|\frac{1}{n}\sum_{i=1}^{n}\left\langle V ^{-1/2}x_{i},\theta_{V}\right\rangle^{2}-\left\|\theta_{V}\right\|_{2}^{2} \right|\geq\epsilon\left\|\theta_{V}\right\|_{2}^{2}\right\}\leq 2\exp\left(- \frac{nc_{1}C_{\min}^{2}(\mathcal{X})\epsilon^{2}}{K_{x}^{2}}\right)\\ &\Longleftrightarrow\Pr\left\{\left|\frac{1}{n}\left\|XV^{-1/2} \theta_{V}\right\|_{2}^{2}-\left\|\theta_{V}\right\|_{2}^{2}\right|\geq \epsilon\left\|\theta_{V}\right\|_{2}^{2}\right\}\leq 2\exp\left(-\frac{nc_{1}C_{\min}^{2}( \mathcal{X})\epsilon^{2}}{K_{x}^{2}}\right).\end{split}\] (36)

Let \(Z:=\frac{1}{\sqrt{n}}XV^{-1/2}\). From Lemma 5.1 in [5], we know that if the above inequality holds, then

\[\left(1-\delta_{\overline{M}}\left(Z\right)\left\|\theta_{V}\right\|_{2} \right)\leq\left\|Z\theta_{V}\right\|_{2}\leq\left(1+\delta_{\overline{M}} \left(Z\right)\left\|\theta_{V}\right\|_{2}\right),\] (37)holds with probability more than

\[1-2\left(\frac{12}{\delta_{\overline{M}}\left(Z\right)}\right)^{2d_{0}}\exp\left( -\frac{c_{1}C_{\min}^{2}(\mathcal{X})n\delta_{\overline{M}}^{2}\left(Z\right)}{ K_{x}^{2}}\right),\]

for any \(\theta_{V}\in V^{1/2}(\overline{m})\) in a subspace \(\overline{m}\in\overline{M}\). Take union bound for \(\overline{M}\) subspaces, and let

\[\delta =2\overline{M}\left(\frac{2}{\delta_{\overline{M}}\left(Z\right)} \right)^{2d_{0}}\exp\left(-\frac{c_{1}C_{\min}^{2}(\mathcal{X})n\delta_{ \overline{M}}^{2}\left(Z\right)}{K_{x}^{2}}\right),\] \[\Longleftrightarrow n =O\left(\frac{K_{x}^{2}}{\delta_{\overline{M}}^{2}\left(Z\right)C_{\min}^{ 2}(\mathcal{X})}\left(\log(2\overline{M})+d_{0}\log\left(\frac{1}{\delta_{ \overline{M}}\left(Z\right)}\right)+\log(\delta^{-1})\right)\right).\]

Let \(\delta_{\overline{M}}^{2}\left(Z\right)=1/2\). Then, Given \(n=O\left(\frac{K_{x}^{2}}{C_{\min}^{2}(\mathcal{X})}\left(\log(2\overline{M} )+d_{0}+\log(\delta^{-1})\right)\right)\), for probability at least \(1-\delta\), we have that

\[\frac{1}{2}\left\|V^{1/2}\theta\right\|_{2}^{2} \leq\frac{1}{n}\left\|XV^{-1/2}V^{1/2}\theta\right\|_{2}^{2},\] \[\Longrightarrow\frac{1}{2}C_{\min}(\mathcal{X})\left\|\theta \right\|_{2}^{2} \leq\frac{1}{n}\left\|X\theta\right\|_{2}^{2}.\]

Let \(\theta:=\theta_{1}-\theta_{2}\), for any \(\theta_{1}\in m\), \(\theta_{2}\in m^{\prime}\), for any \(m,m^{\prime}\in\mathcal{M}\). We conclude the proof. 

### Regret Upper bound

**Lemma 12**.: _Suppose the Assumptions 5, 6 hold. For \(t_{1}=\Omega(K_{x}^{2}d_{0}C_{\min}^{-2}(\mathcal{X})\log(d/\delta))\), with probability at least \(1-\delta\), one has the estimate_

\[\left\|\theta_{\star}-\widehat{\theta}_{t_{1}}\right\|_{2}=O\left(\sqrt{ \frac{\sigma^{2}d_{0}\log(d/\delta)}{C_{\min}(\mathcal{X})t_{1}}}\right).\] (7)

Proof.: First, let consider Proposition 16, and recall that \(\log(M)\) and \(\log(\overline{M})\) are both \(O(d_{0}\log(d))\). Therefore, for the choice of \(t_{1}=\Omega(K_{x}^{2}d_{0}C_{\min}^{-2}(\mathcal{X})\log(d/\delta))\), with probability at least \(1-\delta/2\), one has that

\[C_{\min}(\mathcal{X})\left\|\theta_{\star}-\widehat{\theta}_{t_{1}}\right\|_ {2}^{2}\leq\frac{2}{t_{1}}\left\|X(\theta_{\star}-\widehat{\theta}_{t_{1}}) \right\|_{2}^{2}\] (38)

Second, by Proposition 14, one has that with probability at least \(1-\delta/2\).

\[\left\|X(\theta_{\star}-\widehat{\theta}_{t_{1}})\right\|_{2}^{2}\leq c_{1} \sigma^{2}d_{0}\log\left(\frac{d}{\delta}\right),\] (39)

for some constant \(c_{1}>0\).

Therefore, putting thing together, we have that with probability at least \(1-\delta\), one has that

\[\left\|\theta_{\star}-\widehat{\theta}_{t_{1}}\right\|_{2}\leq c_{2}\sqrt{ \frac{\sigma^{2}d_{0}\log\left(\frac{d}{\delta}\right)}{C_{\min}(\mathcal{X}) t_{1}}},\] (40)

for some constant \(c_{2}>0\). 

**Theorem 10** (**Regret upper bound**).: _Suppose the Assumptions 5, 6 hold. With the choice of \(t_{1}=R_{\max}^{-\frac{2}{3}}\sigma^{\frac{2}{3}}C_{\min}^{-\frac{1}{3}}( \mathcal{X})K_{x}^{\frac{1}{3}}d_{0}^{\frac{1}{3}}T^{\frac{2}{3}}(\log(dT))^{ \frac{1}{3}}\), then the regret of Algorithm 1 is upper bounded as_

\[\mathbf{R}_{T}=O\left(R_{\max}^{\frac{1}{3}}\sigma^{\frac{2}{3}}C_{\min}^{- \frac{1}{3}}(\mathcal{X})K_{x}^{\frac{1}{3}}d_{0}^{\frac{1}{3}}T^{\frac{1}{3}}( \log(dT))^{\frac{1}{3}}\right)\] (6)

Proof.: Let define the pesudo regret as \(\widehat{\mathbf{R}}_{T}=\sum_{t=1}^{T}\left\langle x_{\star}-x_{t},\theta_{ \star}\right\rangle\). Denote \(\overline{m}\in\overline{M}\) be the subspace contains \(\theta_{\star}-\widehat{\theta}_{t_{1}}\). We start by simple regret decomposition as follows.

\[\widehat{\mathbf{R}}_{T} =\sum_{t=1}^{T}\left\langle\theta_{\star},x_{\star}-x_{t}\right\rangle =\sum_{t=1}^{t_{1}}\left\langle\theta_{\star},x_{\star}-x_{t}\right\rangle+ \sum_{t=t_{1}+1}^{T}\left\langle\theta_{\star},x_{\star}-x_{t}\right\rangle\] \[\leq R_{\max}t_{1}+\sum_{t=t_{1}+1}^{T}\left\langle\theta_{\star} -\widehat{\theta}_{t_{1}},x_{\star}-x_{t}\right\rangle+\sum_{t=t_{1}+1}^{T} \underbrace{\left\langle\widehat{\theta}_{t_{1}},x_{\star}-x_{t}\right\rangle} _{\leq 0}\] \[\leq R_{\max}t_{1}+\sum_{t=t_{1}+1}^{T}\left\langle\theta_{\star} -\widehat{\theta}_{t_{1}},x_{\star}-x_{t}\right\rangle\] \[=R_{\max}t_{1}+\sum_{t=t_{1}+1}^{T}\left\langle\theta_{\star}- \widehat{\theta}_{t_{1}},\Pi_{\overline{m}}(x_{\star}-x_{t})\right\rangle \left[\text{As }\theta_{\star}-\widehat{\theta}_{t_{1}}\in \overline{m},\right]\] \[\leq R_{\max}t_{1}+\sum_{t=t_{1}+1}^{T}2\sqrt{K_{x}}\left\| \theta_{\star}-\widehat{\theta}_{t_{1}}\right\|_{2}; \left[\text{Since }\left\|\Pi_{\overline{m}}(x_{\star}-x_{t}) \right\|_{2}\leq 2\sqrt{K_{x}}\,\right].\] (41)

Now, we invoke Lemma 12. Let \(\mathcal{E}\) is the event in that the exploration error is bounded as in Lemma 12, then there is an absolute constant \(c_{1}>0\) such that,

\[\mathbf{R}_{T} \leq R_{\max}t_{1}+\mathbb{E}\left[\sum_{t=t_{1}+1}^{T}2\sqrt{K_{ x}}\left\|\theta_{\star}-\widehat{\theta}_{t_{1}}\right\|_{2}\left|\mathcal{E} \right.\right]+T\mathrm{Pr}(\mathcal{E})R_{\max}\] (42) \[\leq R_{\max}t_{1}+c_{1}\sqrt{K_{x}}\sqrt{\frac{\sigma^{2}d_{0} \log(d/\delta)}{C_{\min}(\mathcal{X})t_{1}}}T+T\delta R_{\max}.\]

Let \(\delta=1/T\), and \(t_{1}=R_{\max}^{-\frac{2}{3}}\sigma^{\frac{2}{3}}C_{\min}^{-\frac{1}{3}}( \mathcal{X})K_{x}^{\frac{1}{3}}d_{0}^{\frac{1}{3}}T^{\frac{2}{3}}(\log(dT))^{ \frac{1}{3}}\), one has that

\[\mathbf{R}_{T}=O\left(R_{\max}^{\frac{1}{3}}\sigma^{\frac{2}{3}}C_{\min}^{- \frac{1}{3}}(\mathcal{X})K_{x}^{\frac{1}{3}}d_{0}^{\frac{1}{3}}T^{\frac{2}{3}} (\log(dT))^{\frac{1}{3}}\right)\] (43)

## Appendix C Improved Regret Bound

### Improve Regret Bound with Well-Separated Partitions

**Theorem 18**.: _Suppose the Assumptions 5, 6, 17 hold. Let \(t_{2}=\Omega\left(\frac{\sigma^{2}K_{x}^{2}d_{0}\log(dT)}{C_{\min}^{2}( \mathcal{X})\varepsilon_{0}^{2}}\right)\). Then, Algorithm 2 returns \(\widehat{m}\ni\theta_{\star}\) with probability at least \(1-1/T\), and its regret is upper bounded as_

\[\mathbf{R}_{T}=O\left(\frac{R_{\max}\sigma^{2}K_{x}^{2}d_{0}\log(dT)}{C_{\min} ^{2}(\mathcal{X})\varepsilon_{0}^{2}}+\sigma d_{0}\sqrt{T\log(K_{x}T)}\right).\] (12)

Proof.: Define the event \(\mathcal{E}\) as

\[\mathcal{E}=\left\{\left\|Y-\Pi_{S_{\overline{m}}}(Y)\right\|_{2}^{2}\leq\left\| Y-\Pi_{S_{m}}(Y)\right\|_{2}^{2}\,|\,\theta_{\star}\in\widehat{m},\,\,\theta_{ \star}\notin m\right\},\] (44)The event \(\mathcal{E}\) is equivalent as

\[\left\|Y-\Pi_{S_{\widetilde{m}}}(Y)\right\|_{2}^{2} \leq\left\|Y-\Pi_{S_{m}}(Y)\right\|_{2}^{2}\] (45) \[\Longleftrightarrow \left\|\boldsymbol{f}_{\star}+\boldsymbol{\eta}-\widehat{ \boldsymbol{f}}_{\widehat{m}}\right\|_{2}^{2} \leq\left\|\boldsymbol{f}_{\star}+\boldsymbol{\eta}-\widehat{ \boldsymbol{f}}_{m}\right\|_{2}^{2}\] \[\Longleftrightarrow \left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{ \widehat{m}}\right\|_{2}^{2}+2\left\langle\boldsymbol{\eta},\boldsymbol{f}_{ \star}-\widehat{\boldsymbol{f}}_{\widehat{m}}\right\rangle\leq\left\| \boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{m}\right\|_{2}^{2}+2\left \langle\boldsymbol{\eta},\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{m} \right\rangle.\]

**First**, we upper the LHS of (45) with high probability.

\[\left\|\boldsymbol{f}_{\star}-\boldsymbol{f}_{\star}-\Pi_{S_{\widetilde{m}}}( \boldsymbol{\eta})\right\|_{2}^{2}+2\left\langle\boldsymbol{\eta},-\Pi_{S_ {\widetilde{m}}}(\boldsymbol{\eta})\right\rangle=\left\|\Pi_{S_{\widetilde{m }}}(\boldsymbol{\eta})\right\|_{2}^{2}-2\left\|\Pi_{S_{\widetilde{m}}}( \boldsymbol{\eta})\right\|_{2}^{2}\leq 0\quad\text{[as $\theta_{\star}\in\widehat{m}$]}\] (46)

with probability at least \(1-\delta\). The above inequality uses the union bound for all \(m\in\mathcal{M}\).

**Second**, we lower bound the RHS of (45), \(\left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{m}\right\|_{2}^{2}+2 \left\langle\boldsymbol{\eta},\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f} }_{m}\right\rangle\), with high probability. Let \(\bar{S}_{m}=S_{m}\bigoplus\left\langle\boldsymbol{f}_{\star}\right\rangle\), then \(\left\langle\boldsymbol{\eta},\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f} }_{m}\right\rangle=\left\langle\Pi_{S_{m}}(\boldsymbol{\eta}),\boldsymbol{f}_{ \star}-\widehat{\boldsymbol{f}}_{m}\right\rangle\). Therefore, we have that, with probability at least \(1-\delta/3\).

\[\left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{m}\right\| _{2}^{2}+2\left\langle\Pi_{S_{m}}(\boldsymbol{\eta}),\boldsymbol{f}_{\star}- \widehat{\boldsymbol{f}}_{m}\right\rangle \geq\left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{m} \right\|_{2}^{2}-2\left\|\Pi_{S_{m}}(\boldsymbol{\eta})\right\|_{2}^{2}-\frac{ 1}{2}\left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{m}\right\|_{2}^{2}\] \[\geq\frac{1}{2}\left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol {f}}_{m}\right\|_{2}^{2}-4\left(\sigma^{2}(d_{0}+1)+\sigma^{2}(\log(3M\delta^{ -1}))\right)\] \[\geq\frac{1}{2}\left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol {f}}_{m}\right\|_{2}^{2}-5\left(\sigma^{2}d_{0}+\sigma^{2}(\log(3M\delta^{-1}) )\right),\] (47)

as \(d_{m}\leq d_{0}\).

Also, we have that, with probability at least \(1-\delta/3\)

\[\left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{m}\right\| _{2}^{2} =\left\|\boldsymbol{f}_{\star}-\Pi_{S_{m}}(\boldsymbol{f}_{\star}) -\Pi_{S_{m}}(\boldsymbol{\eta})\right\|_{2}^{2}\] \[\geq\left\|\boldsymbol{f}_{\star}-\Pi_{S_{m}}(\boldsymbol{f}_{ \star})\right\|_{2}^{2}\]

Where the inequalities holds because \(\Pi_{S_{m}}(\boldsymbol{f}_{\star})\) is the projection of \(\boldsymbol{f}_{\star}\) to \(S_{m}\). Therefore, we have that

\[\left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{m}\right\|_{2}^{2}+2 \left\langle\boldsymbol{\eta},\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f} }_{m}\right\rangle\geq\frac{1}{2}\left\|\boldsymbol{f}_{\star}-\Pi_{S_{m}}( \boldsymbol{f}_{\star})\right\|_{2}^{2}-5\left(\sigma^{2}d_{0}+\sigma^{2}(\log (M\delta^{-1}))\right).\] (48)

Now, by choosing \(t_{2}=\Omega\left(C_{\min}^{-2}(\mathcal{X})K_{x}^{2}\log(M\delta^{-1})\right)\), by Proposition 16, we have that with probability at least \(1-\delta/3\),

\[\left\|\boldsymbol{f}_{\star}-\Pi_{S_{m}}(\boldsymbol{f}_{\star})\right\|_{2}^ {2}=\left\|X(\theta_{\star}-\Pi_{S_{m}}(\theta_{\star}))\right\|_{2}^{2}\geq \frac{t_{2}}{2C_{\min}(\mathcal{X})}\left\|\theta_{\star}-\Pi_{S_{m}}(\theta_{ \star})\right\|_{2}^{2}\geq\frac{t_{2}\varepsilon_{0}^{2}}{4C_{\min}( \mathcal{X})}\] (49)

Therefore, the RHS of (45) is lower bounded as follows

\[\left\|\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f}}_{m}\right\|_{2}^{2}+2 \left\langle\boldsymbol{\eta},\boldsymbol{f}_{\star}-\widehat{\boldsymbol{f} }_{m}\right\rangle\geq\frac{t_{2}\varepsilon_{0}^{2}}{8C_{\min}(\mathcal{X}) }-5\left(\sigma^{2}d_{0}+\sigma^{2}(\log(3M\delta^{-1}))\right).\] (50)

Therefore, the sufficient condition for event \(\mathcal{E}\) holds with probability at least \(1-\delta\) is that

\[\frac{t_{2}\varepsilon_{0}^{2}}{8C_{\min}(\mathcal{X})}-5\left(\sigma^{2}d_{0}+ \sigma^{2}(\log(M\delta^{-1}))\right)\geq 0;\] (51)

Note that as \(M=O(d_{0}\log(d))\), for \(\mathcal{E}\) holds with probability at least \(1-\delta\), it suffice to choose

\[t_{2}=\Omega\left(\frac{\sigma^{2}K_{x}^{2}d_{0}\log(d\delta^{-1})}{C_{\min}^{2} (\mathcal{X})\varepsilon_{0}^{2}}\right).\] (52)The regret upper bound is an immediate consequence of the fact that Algorithm 2 return the true subspace \(\hat{m}\ni\theta_{\star}\), combined with the regret bound of OFUL in the exploitation phase and \(\delta=1/T\). 

### Adapting to Separating Constant \(\varepsilon_{0}\)

As stated in Theorem 18, if one knows in advance that the separating constant \(\varepsilon_{0}\geq T^{-1/4}\), then using Algorithm 2 leads to \(\sqrt{T}\) regret. The reason is that the learner can learn the true subspace \(m_{\star}\) after \(\sqrt{T}\) steps with no mis-specification errors. However, without knowing \(\varepsilon_{0}\geq T^{-1/4}\) a priori, one cannot guarantee to recover the true subspace. Hence, naively using Algorithm 2, which is not aware of potential mis-specification errors, leads to linear regret. On the other hand, using Algorithm 1 can achieve regret \(T^{2/3}\) in the worst case (without the knowledge of \(\varepsilon_{0}\geq T^{-1/4}\)). A question arises: _does there exist an algorithm that, without the knowledge of \(\varepsilon_{0}\), can achieve regret \(\sqrt{T}\) whenever \(\varepsilon_{0}\geq T^{-1/4}\), but guarantee the worst-case regret as \(T^{2/3}\)?_

We note that the role of \(\varepsilon_{0}\) is similar to the minimum signal in sparsity, and it is somewhat surprising that the question of adapting to unknown minimum signal has not been resolved in the literature of sparse linear bandits. Towards answering the question, we propose a simple method using adaptation to misspecified error in linear bandit [19], which has a \(\sqrt{T}\) regret whenever the separating constant is large, and enjoys a worst-case regret guarantee of slightly worse \(T^{3/4}\) regret.

The algorithm described in 4 is a direct application of the algorithm proposed in [19], designed for adapting to misspecification errors in linear bandits. Particularly, the algorithm in [19] can adapt to unknown misspecification errors and achieve a regret bound of \(\tilde{O}(d_{0}\sqrt{T}+\epsilon_{\mathrm{mis}}T)\), where \(\epsilon_{\mathrm{mis}}\) is the misspecification error. At a high level, our algorithm exploring \(\sqrt{T}\) rounds using exploratory distribution, which ensures that the misspecification error \(\epsilon_{\mathrm{mis}}\) of the chosen subspace \(\hat{m}\) is at most \(T^{-1/4}\). Therefore, we can run multiple linear bandit algorithms using different levels of misspecification error. Particularly, we use a collection of \(K=\lfloor\log(T)\rfloor\) base algorithms, where a base algorithm \(k\in[K]\) is a linear bandit algorithm with misspecified level \(\varepsilon_{k}=2^{-k}\). Note that the base algorithm \(K\) has the same order of regret \(\sqrt{T}\) as a well-specified model. Therefore, in exploitation phase, one can guarantee that in the case of well-separated partitions where \(\epsilon_{\mathrm{mis}}=0\), the algorithm can achieve a regret of \(d_{0}\sqrt{T}\), while in the general case, the regret caused by misspecification error is at most \(T^{3/4}\sqrt{d_{0}}\).

```
1:Input \(T,~{}\nu,~{}t_{3}\).
2:for\(t=1,\cdots,t_{3}\)do
3: Independently pull arm \(x_{t}\) according to \(\nu\) and receive a reward \(y_{t}\).
4:endfor
5:\(X\leftarrow[x_{1},...,x_{t_{1}}]^{\top}\), \(Y\leftarrow[y_{t}]_{t\in[t_{1}]}\).
6: Compute \(\widehat{m}\) as (4).
7: Let \(K=\lfloor\log(T^{1/4})\rfloor\), \(\mathcal{E}=\big{\{}\varepsilon_{k}:=2^{-k},~{}k\in[K]\big{\}}\).
8:for\(t=t_{2}+1\) to \(T\)do
9: Corralling \(K\) base misspecified linear bandit algorithms SquareCB.Lin+(\(\varepsilon_{k}\)) [19] on \(\widehat{m}\).
10:endfor ```

**Algorithm 3** Adaptive algorithm

**Corollary 23**.: _Suppose the Assumptions 5, 6 hold. Then, there exists an algorithm which achieves regret bound as follows:_

1. _[label=()]_
2. _[_**Well-separated partitions**_]_ _If_ \(\varepsilon_{0}\geq T^{-1/4}\)_, then_ \(\mathbf{R}_{T}=\tilde{O}(d_{0}\sqrt{T})\)_._
3. _[_Non-well-separated partitions**_]_ _If_ \(\varepsilon_{0}<T^{-1/4}\)_, then_ \(\mathbf{R}_{T}=\tilde{O}(d_{0}\sqrt{T}+T^{\frac{3}{4}}\sqrt{d_{0}})\)_._

Proof sketch.: Denote \(\epsilon_{\mathrm{mis}}=\|\theta_{\star}-\Pi_{\widehat{m}}(\theta_{\star})\|_{2}\) as the misspecification error. With

\[t_{3}=\Omega\left(\sigma^{2}d_{0}\log(d\delta^{-1})\sqrt{T}\right),\]

We can guarantee that, with probability at least \(1-\delta\), if:1. If \(\varepsilon_{0}>T^{-1/4}\), then by Theorem 18, \(\theta_{\star}\in\widehat{m}\), that is, \(\epsilon_{\mathrm{mis}}=0\);
2. If \(\varepsilon_{0}>T^{-1/4}\), then by Lemma 12, we can bound \(\epsilon_{\mathrm{mis}}\leq T^{-1/4}\).

The regret of adaptive algorithm in [19] is of the form \(\tilde{O}(d_{0}\sqrt{T}+\epsilon_{\mathrm{mis}}T\sqrt{d_{0}})\). Let \(\delta=1/T\). Consider case (i) where \(\epsilon_{\mathrm{mis}}=0\), we have \(\mathbf{R}_{T}=\tilde{O}(d_{0}\sqrt{T})\). Consider case (ii), where \(\epsilon_{\mathrm{mis}}=T^{-1/4}\), we have \(\mathbf{R}_{T}=\tilde{O}(d_{0}\sqrt{T}+T^{3/4}\sqrt{d_{0}})\). 

The result in Corollary 23 is still sub-optimal in the worst case, as it can only achieve \(O(T^{3/4})\) regret bound instead of \(O(T^{2/3})\). We conjecture that new techniques are required to achieve order-optimal regret in both cases, and will continue to investigate this question in future works.

## Appendix D On Collections of Partitions with Subexponential-Size

### Important Classes of Partitions with Subexponential-Size

In this section, we discuss several important classes of partitions which satisfy Assumption 5.

Pattern-avoidance partitions is arguable the most important class of studied partition [33], in which, non-crossing partition is one the most studied.

**Definition 24** (**Non-Crossing Partition**).: Let \([d]\) admits a cylic order as \(1<2<...<d\), and \(d<1\). A non-crossing partition of \([d]\) is a partition such that for if \(i,\ j\) in one block and \(p,\ q\) in one block, then they are not arranged in the order \(i<p<j<q\).

Similarly, we denote \(\mathcal{NC}_{d}\), \(\mathcal{NC}_{d,k}\), \(\mathcal{NC}_{d,\leq k}\) as the set of all non-crossing partition of \([d]\), the set of all partition of \([d]\) with \(k\) classes, and the set of all partition of \([d]\) with at most \(k\) classes. We have the following fact ([33]' section 3.2).

\[|\mathcal{NC}_{d}|=\frac{1}{d+1}\binom{2d}{d},\quad|\mathcal{NC}_{d,k}|=\frac{ 1}{d}\binom{d}{k}\binom{d}{k-1},\] (53)

which is the Catalan number and the Narayana number. Note that,

\[\frac{1}{d}\binom{d}{k}\binom{d}{k-1}\leq\frac{1}{d}\left(\frac{ed}{k}\right) ^{k}\left(\frac{ed}{k-1}\right)^{k-1}\leq\frac{1}{d}\left(\frac{ed}{k}\right) ^{2k}.\] (54)

Therefore, non-crossing partition satisfied the cardinality restriction as Assumption 5, that is,

\(\mathcal{NC}_{d,\leq d_{0}}\subset\mathcal{Q}_{d,\leq d_{0}}\).

Another important class of pattern-avoidence partitions is nonnesting partition [14].

**Definition 25** (**Non-Nesting Partition**).: Let \([d]\) admits a cylic order as \(1<2<...<d\), and \(d<1\). A non-crossing partition of \([d]\) is a partition such that for if \(i,\ j\) in one block and \(p,\ q\) in one block, then they are not arranged in the order \(i<p<q<j\).

Similarly, we denote \(\mathcal{NN}_{d}\), \(\mathcal{NN}_{d,k}\), \(\mathcal{NN}_{d,\leq k}\) as the set of all non-crossing partition of \([d]\), the set of all partition of \([d]\) with \(k\) classes, and the set of all partition of \([d]\) with at most \(k\) classes. There is bijections between class of \(\mathcal{NN}_{d}\) and \(\mathcal{NC}_{d}\), non-nesting partitions also satisfy the sub-exponential constraint (Assumption 5).

One special case of both non-crossing partitions and non-nesting partitions is interval partition, which has _identical structure as sparsity_.

**Definition 26** (**Interval Partition**).: A set partition of \([d]\) is an interval partition or partition of interval if its parts are interval.

We denote \(\mathcal{I}_{d}\) as the collection of all interval partition of \(d\), we have that \(\mathcal{I}_{d}\subset\mathcal{NC}_{d}\subset\mathcal{P}_{d}\), and \(\mathcal{I}_{d}\subset\mathcal{NN}_{d}\subset\mathcal{P}_{d}\).

**Remark 27**.: \(\mathcal{I}_{d}\) admits a Boolean lattice of order \(2^{d-1}\), making it equivalent to the sparsity structure in \(d-1\) dimensions. Specifically, consider the set of entries of parameters \(\varphi\in\mathbb{R}^{d}\) with a linear order, that is, \(\varphi_{1}<\varphi_{2}<\cdots<\varphi_{d}\). Then define the variable \(\theta\in\mathbb{R}^{d-1}\) such that \(\theta_{i}=(\varphi_{i+1}-\varphi_{i})\). Each interval partition on the entries of \(\varphi\) will determine a unique sparse pattern of \(\theta\). In other words, symmetric linear bandit is strictly harder than sparse bandit and inherits all the computational complexity challenges of sparse linear bandit, including the _NP-hardness_ of computational complexity.

Inspired by the literature on sparse linear regression, where one can relax solving exact sparse linear regression by using norm-\(1\) minimization, also known as LASSO methods, we ask whether there is a convex relaxation for the case of non-crossing partitions or pattern-avoidance partitions in general.

### Practical Examples of Partitions with Subexponential-Size

General hidden symmetries.Examples of hidden symmetry in reinforcement learning tasks can be found in robotic control [32, 3], where robot is initially designed symmetrical, but part of symmetry is destroyed by mechanical imperfection. Further examples of hidden symmetry can be also found in the literature on multi-agent reinforcement learning with a large number of agents. To avoid the curse of dimensionality, researchers often rely on the assumption of the existence of homogeneous agents [13, 34]. In the extreme case where all agents are homogeneous, such as in mean-field games, sample complexity becomes independent of the number of agents [13]. However, in practice, agents can be clustered into different types [34], and this information may not be known in advance to the learner (here symmetry occurs between different agents from the same type).

Non-crossing partitions.Sub-exponential size naturally appears when there is a hierarchical structure on the set \([d]\), and the partitioning needs to respect this hierarchical structure. Particularly, let \(T(d,d_{0})\) be the set of ordered trees with \((d+1)\) nodes and \(d_{0}\) internal nodes (i.e., nodes that are not the leaves). A partition that respects an ordered tree groups the children of the same node into a single equivalence class (for example, see Figure 1). It is shown in [15] that the cardinality of the set of partitions that respect ordered trees in \(T(d,d_{0})\) is sub-exponential. More precisely, it is \(O(d^{2d_{0}})\). Furthermore, there is a natural bijection between partitions that respect ordered trees in \(T(d,d_{0})\) and the set of non-crossing partitions \(\mathcal{NC}_{d,d_{0}}\)[15].

Recall the subcontractor example in the introduction. Here, after the company hires subcontractors \(\{1,4,6\}\) to do the job, these subcontractors further break down the tasks into smaller subtasks and hire additional subcontractors \(\{2,3\}\), \(\{5\}\), and \(\{7,8,9\}\), respectively, to execute the subtasks.

Non-nesting partitions.Besides non-crossing partitions, another sub-exponential-size class of partitions with practical relevance is non-nesting partitions. Consider the resource allocation task where there are \(d\) upcoming tasks and \(d_{0}\) machines. The job of the designer is to allocate these tasks to each machine.

Now, assume each task will appear in time \(t_{1}<t_{2}<\cdots<t_{d}\), but the exact time (the value of \(t_{i}\)) is unknown to the designer. Moreover, the cost of machine \(k\in[d_{0}]\), given a subset of tasks \(A_{k}\) (ordered according to execution time), is \(c_{k}=t_{\max(A_{k})}-t_{\min(A_{k})}\).

The goal of the designer is to minimize the maximum cost of all machines:

\[\min\max_{k\in[d_{0}]}c_{k}.\]

To achieve this, the designer should avoid nesting allocations (i.e., searching among non-nesting partitions). In particular, assuming that if tasks at times \(t_{i}\) and \(t_{j}\) are assigned to machine \(k\), (where \(t_{i}<t_{j}\)), and tasks at times \(t_{p}\) and \(t_{q}\) are assigned to machine \(k^{\prime}\) (where \(t_{p}<t_{q}\)), then it should not be the case that \(t_{i}<t_{p}<t_{q}<t_{j}\). This is because the cost of machine \(k\) would be significantly higher than that of machine \(k^{\prime}\), and the cost could be reduced by swapping task \(t_{q}\) for machine \(k\) with task \(t_{j}\) for machine \(k^{\prime}\).

### Efficient Greedy Algorithm for Specific Classes of Partitions

The model selection procedure in the exploration phase of Algorithms 1 and 2 requires finding the best subspace in the pool \(m\in\mathcal{M}\) with respect to least square errors. In the worst case, the algorithm needs to solve \(M\) linear regression approaches. While the exact computation of the best subspace \(\hat{m}\) as in (4) is an NP-hard problem in general (since it contains interval partition as a subclass), we argue that an greedy algorithm can find the ground-truth subspace \(m_{\star}\) in \(O(nd^{5})\) time complexity, given sufficient large number of samples.

The pseudo code of the greedy algorithm is given in Figure 4. Given that the set of partitions \(\mathcal{Q}_{d}\) is equipped with a lattice structure, in which the finest partition is \((1|2|\ldots|d)\) and the coarsest partition is \((1,2,\ldots,d)\).

The algorithm starts with the finest partition \(\hat{\pi}=(1|2|\ldots|d)\). In each iteration, the algorithm finds the finest coarsening of the current partition \(\hat{\pi}\). In graph-theoretic terms, it finds all neighbors of \(\hat{\pi}\) in the lattice that are coarsenings of \(\hat{\pi}\). The operator for finding the finest coarsening of \(\hat{\pi}\) is denoted as \(\texttt{Coarsen}(\hat{\pi})\), and it returns a collection of the finest coarsened partitions. Next, the algorithm finds the partition that minimizes the prediction error \(\|Y-\Pi_{S_{m}}(Y)\|_{2}^{2}\) among the current coarsening collection. At the end of each iteration, as the number of classes in \(\hat{\pi}\) is reduced by one, the dimension variable is also reduced by \(1\). The while loop stops when the dimension equals \(d_{0}\).

Since the algorithm only optimizes locally within the current coarsening collection, it exhibits a behavior similar to a greedy algorithm. We note that for non-crossing and non-nesting partitions, the cardinality of the coarsening collection at any level of the lattice is at most \(d^{2}\). Therefore, assuming that creating a finest coarsening partition take \(O(d)\) operator, and solving least square takes \(O(nd^{2})\), the algorithms time complexity is \(O(nd^{5})\).

```
1:Input: Compact representation of \(\mathcal{M}\), design matrix \(X\), reward vector \(Y\).
2:Initialise \(\hat{\pi}=(1|2|3|4...|d)\), \(\mathrm{dimension}=d\).
3:while\(\mathrm{dimension}>d_{0}\)do
4: Collection = Coarsen(\(\hat{\pi}\)).
5:\(\hat{m}=\arg\min_{m\in\mathbf{H}(\mathrm{Collection})}\|Y-\Pi_{S_{m}}(Y)\|_{2}^{2}\).
6:\(\hat{\pi}=\mathbf{H}^{-1}(\hat{m})\).
7:\(\mathrm{dimension}=\mathrm{dimension}-1\).
8:endwhile
9:\(\hat{\theta}=\arg\min_{\theta\in\hat{m}}\|Y-X\theta\|_{2}^{2}\).
10: Return \(\hat{m},\ \hat{\theta}\). ```

**Algorithm 4** Greedily Search within Lattice

## Appendix E Experiment details

We conduct simulations where the entries of \(\theta_{\star}\) satisfy non-crossing partition constraints. The set of arms \(\mathcal{X}\) is \(\sqrt{d}\mathbb{S}^{d-1}\), \(\sigma=0.1\), and \((d,d_{0})\in\{(40,4),(80,10),(100,15)\}\). We let exploratory distribution \(\nu\) be the uniform distribution on the unit sphere. The ground-truth partition \(\pi_{\mathcal{G}}\) and \(\theta_{\star}\) are randomized before each simulation.

To run ESTC-Lasso algorithm [23], we introduce an auxiliary sparse vector \(\varphi\) corresponding to \(\theta_{\star}\), whose entries are defined as \(\varphi_{i}=\theta_{i+1}-\theta_{i}\), and \(\varphi_{d}=\theta_{d}\). We apply Lasso regression for \(\varphi_{\star}\), get the estimate \(\hat{\varphi}\), then convert back to \(\hat{\theta}\) using the map that transforms sparse vector to interval-partition vector (inversion of the map we defined above).

Regarding implementing our algorithm, we use greedy Algorithm 4 as introduced in Appendix D.3, to solve the optimisation in equation (3), (4), and its complexity is \(O(t_{1}d^{5})\). It is shown in the simulation result (Figure 2, 3, 4), the greedy algorithm achieves small risk error and consequently leads to small regret. Code is available at:

https://github.com/NamTrankKeL/Symmetric-Linear-Bandit-with-Hidden-Symmetry.git.

Figure 3: Regret of EMC (Algorithm 1) and of ESTC proposed in [23], in cases of sparsity, non-crossing partitions, and non-nesting partitions, with \(d=40,\ d_{0}=4\).

## Appendix F Extended Related Work

**Sparse linear bandits.** As we will explain in Section 4.2, sparsity is equivalent to a subset symmetry structures, and thus, can be seen as a special case of our setting. As such, we first review the literature of sparsity. Sparse linear bandits were first investigated in [2], where the authors achieve a regret of \(\tilde{O}(\sqrt{dsT})\), with \(\tilde{O}\) disregarding the logarithmic factor, and \(s\) representing the sparsity level, and \(T\) is the time horizon. Without additional assumptions on the arm set and feature distribution, the lower bound for regret in the sparsity case is \(\Omega(\sqrt{dsT})\)[27]. Consequently, the contextual setting has recently gained popularity in the sparsity literature, where additional assumptions are made regarding the context distribution and set of arms. With this assumption, it can be shown that one can achieve regret of the form \(\tilde{O}(\tau s\sqrt{T})\), where \(\tau\) is a problem-dependent constant that may have a complex form and varies from paper to paper [26; 36]. Apart from the contextual assumption, to avoid polynomial dependence on \(T\) in the regret bound, assumptions are required for the set of arms [28; 11; 23]. Recently, [23] offers a unified perspective on the assumption regarding the set of arms by assuming the existence of an exploratory distribution on the set of arms. With this assumption, the authors propose an Explore then Commit style strategy that achieves \(\tilde{O}(s^{\frac{3}{2}}T^{\frac{3}{3}})\), nearly matching the lower bound \(\Omega(s^{\frac{3}{2}}T^{\frac{3}{3}})\) in the poor data regime [24]. As the sparsity structure can be reduced to a subset of the symmetry structure, all the lower bounds for sparse problems apply to (unknown) symmetric problems.

**Model selection.** Our problem is also closely related to model selection in linear bandits, as the learner can collect potential candidates for the unknown symmetry. Bandit model selection involves the problem where there is a collection of \(M\) base algorithms (with unknown performance guarantees) and a master algorithm, aiming to perform as well as the best base algorithm. The majority of the literature assumes the black-box collection of models \(M\) base algorithms and employs a variant of online mirror descent to select the recommendations of the base agent [4; 37; 38]. Due to the black-box nature, the regret guarantee bound depends on \(\text{poly}(M)\). There is a growing literature on model selection in stochastic linear bandits, where there is a collection of \(M\) features, and linear bandits running with these features serve as base algorithms. By exploiting the fact that the data can be shared across all the base algorithms, the dependence of regret in terms of the number of models can be reduced to \(\log(M)\). In particular, [25] propose a method that concatenates all \(M\) features of dimension \(d\) into one feature of dimension \(Md\), and then runs a group-Lasso bandit algorithm on top of this concatenated feature space, using the Lasso estimation as a aggregation of models. Their algorithm achieves a regret bound of \(O(T^{\frac{3}{4}}\sqrt{\log(M)})\) under the assumption that the Euclidean norm of the concatenated feature is bounded by a constant. However, in our case, the Euclidean norm of concatenated feature can be as large as \(\sqrt{M}\), which leads to \(\sqrt{M}\) multiplicative factor in regret. Besides, [35] uses the online aggregation oracle approach, and able to obtain regret as \(O(\sqrt{KdT\log(M)})\), where \(K\) is the number of arms. In contrast, we use different algorithmic mechanism than aggregation of models. In particular, we explicitly exploiting the structure of the model class as a collection of subspaces and invoking results from Gaussian model selection [21] and dimension reduction on the union of subspaces [8]. With this technique, we are able to achieve \(O(T^{\frac{3}{3}}\log(M))\), which is rate-optimal in the data-poor regime, has logarithmic dependence on \(M\) without strong assumptions on the norm of concatenated features, and is independent of the number of arms \(K\). A special case of feature selection where one can achieve a very tight regret compared to the best model is the nested feature class [18; 20]. In particular, in the nested feature class where

Figure 4: Regret of EMC (Algorithm 1) and of ESTC proposed in [23], in cases of sparsity, non-crossing partitions, and non-nesting partitions, with \(d=80,\ d_{0}=10\).

[MISSING_PAGE_FAIL:28]

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Our claims made in the abstract and introduction reflect the paper's contributions and scope. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discussed the limitations of the work in the main paper and the conclusion. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.

3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: We stated the assumptions in the main paper and provide the proof in the appendix. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We described our simulations and provided a link to the code available online. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.

3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We provided a link to the code available online. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We described our simulations and provided a link to the code available online. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.

7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We described our simulations and statistical significance of the experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We discussed the time complexity of our algorithm. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We have reviewed the NeurIPS Code of Ethics.

Guidelines:

* The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
* If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.
* The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).

**Broader Impacts**

Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?

Answer: [NA]

Justification: This paper is primarily theoretical and may have limited direct impact or implications.

Guidelines:

* The answer NA means that there is no societal impact of the work performed.
* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

**Safeguards**

Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?

Answer: [NA]

Justification: This paper poses no such risks.

Guidelines:

* The answer NA means that the paper poses no such risks.
* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.

* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: We does not use existing assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This paper does not release new assets Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA]Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. * We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. * For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.