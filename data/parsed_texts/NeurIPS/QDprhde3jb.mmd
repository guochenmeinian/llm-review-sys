# Learning Optimal Tax Design in Nonatomic Congestion Games

Qiwen Cui

Paul G. Allen School of Computer Science

Engineering

University of Washington

Seattle, WA 98195

qwcui@cs.washington.edu

&Maryam Fazel

Department of Electrical

Computer Engineering

University of Washington

Seattle, WA 98195

mfazel@uw.edu

&Simon S. Du

Paul G. Allen School of Computer Science

Engineering

University of Washington

Seattle, WA 98195

ssdu@cs.washington.edu

###### Abstract

In multiplayer games, self-interested behavior among the players can harm the social welfare. Tax mechanisms are a common method to alleviate this issue and induce socially optimal behavior. In this work, we take the initial step of learning the optimal tax that can maximize social welfare with limited feedback in congestion games. We propose a new type of feedback named _equilibrium feedback_, where the tax designer can only observe the Nash equilibrium after deploying a tax plan. Existing algorithms are not applicable due to the exponentially large tax function space, nonexistence of the gradient, and nonconvexity of the objective. To tackle these challenges, we design a computationally efficient algorithm that leverages several novel components: (1) a piece-wise linear tax to approximate the optimal tax; (2) extra linear terms to guarantee a strongly convex potential function; (3) an efficient subroutine to find the exploratory tax that can provide critical information about the game. The algorithm can find an \(\epsilon\)-optimal tax with \(O(\beta F^{2}/\epsilon)\) sample complexity, where \(\beta\) is the smoothness of the cost function and \(F\) is the number of facilities.

## 1 Introduction

In modern society, large-scale systems often consist of many self-interested players with shared resources, such as transportation and communication networks. Importantly, the objectives of individual players are not always aligned with the system efficiency, and the system designer should take this into consideration. A widely known example is Braess's paradox, where adding more roads to a network can make the network more congested [1]. Price of anarchy is a notion that measures the inefficiency caused by selfish behavior compared with optimal centralized behavior [13]. Characterizing such inefficiency has been an active research area with applications in resource allocation [10], traffic congestion [14], and others. The inefficiency motivates research on how to design mechanisms to improve performance even when the players are still behaving selfishly.

Tax mechanisms are a standard approach to resolving the inefficiency issue, which are widely studied in economics, operations research, and game theory. The goal of tax mechanisms is to incentivize self-interested players to follow socially optimal behavior by applying tax/subsidy. Congestion game is a widely studied class of game theory models characterizing the interactions between players sharing facilities, where the cost of each facility depends on the "congestion" level (Wadrop, 1952; Rosenthal, 1973). As a motivating example, in traffic routing games, each facility corresponds to an edge in a network, and each player chooses a path that connects her source node and target node. The cost of each facility corresponds to the latency of each edge, which depends on the number of players using that edge. Then, the tax can be interpreted as the toll collected by the road owner or the government to improve overall traffic efficiency (Bergendorff et al., 1997).

Most existing works on congestion game tax design focus on the computation complexity of the optimal tax (Nisan et al., 2007; Caragiannis et al., 2010). They assume the tax designer has full knowledge of the underlying game, which is unrealistic in many applications. As Nash equilibrium is the only stable state of the system, we study a partial information feedback setting named "equilibrium feedback", where the tax designer can only observe information about the Nash equilibrium. The limited feedback information brings new challenges to the tax designer, and strategic exploration is necessary to learn or design the optimal tax. In this work, we aim to take the first step in learning optimal tax design for congestion games, and we study the following problem:

_How can we learn the optimal tax design in congestion games with equilibrium feedback?_

Below we highlight our contributions.

### Main Contributions and Technical Novelties

**1. The first algorithm for learning optimal tax design in congestion games.** To the best of our knowledge, this is the first result for learning optimal tax in congestion games with partial information feedback. Our algorithm enjoys \(O(F^{2}\beta/\epsilon)\) sample complexity for learning an \(\epsilon\)-optimal tax, where \(F\) is the number of facilities and \(\beta\) is the smoothness coefficient of the cost function. The sample complexity has no dependence on the number of actions, which could be exponential in \(F\). In addition, we provide an efficient implementation for network congestion games with \(\widetilde{O}(\mathrm{poly}(V,E,\epsilon))\) computational complexity, where \(V\) and \(E\) are the numbers of the vertexes and edges in the network. Due to space limitation, we defer the computation analysis and experiments to Appendix C and Appendix E.

**2. Piece-wise linear function approximation.** We only assume the cost functions are smooth and make no parameterization assumptions as they are too strong to be satisfied in real-world applications. To tackle this challenge, we use piece-wise linear functions to approximate the optimal tax function. While only the values of the cost functions can be observed, we show that a carefully designed piece-wise linear function can approximate the unobservable optimal tax function well.

**3. Strongly convex potential function.** One challenge in tax design is controlling the sensitivity of Nash equilibrium w.r.t. tax perturbation. We always enforce tax functions with subgradient lower bounded by some positive value, which leads to a strongly convex potential function. As a result, the Nash equilibrium will be unique and Lipschitz with respect to tax perturbation. As the potential function for optimal tax is not necessarily strongly convex, we carefully choose the strong-convexity coefficient to balance the induced bias.

**4. Exploratory tax design.** Given the equilibrium feedback, the tax designer can only indirectly query the cost function by applying tax. Consequently, exploration in tax design becomes much more difficult than that in standard bandit problems where the player can directly query the value of an action (Lattimore and Szepesvari, 2020). We design an exploratory tax that pushes the equilibrium to the "boundary", where an additional tax perturbation will change the equilibrium and reveal information about at least one unknown facility.

In this work, we focus on the well-known nonatomic congestion games. We hope our algorithm and analysis provide new insight on the intriguing structure of nonatomic congestion games. In addition, the tax design algorithm might find applications in real-world problems such as toll design in traffic networks. Due to space limitation, most proofs are deferred to the appendix.

**Notations.**\([m]=\{1,2,\cdots,m\}\). For a set of real numbers \(\mathcal{K}\) and a real number \(x:\min\{\mathcal{K}\}\leq x\leq\max\{\mathcal{K}\}\), we define \([x]_{\mathcal{K}}^{+}:=\min_{y\in\mathcal{K}:y\geq x}y\) and \([x]_{\mathcal{K}}^{-}:=\max_{y\in\mathcal{K}:y\leq x}y\). The clip operation \(\operatorname{clip}(a,l,r):=\min\{\max\{a,l\},r\}\) clips \(a\) into the interval \([l,r]\). We use \(O(\cdot)\) to hide absolute constants and \(\widetilde{O}(\cdot)\) to hide \(\operatorname{polylog}\) terms as well. A function \(f:\mathcal{X}\mapsto\mathbb{R}\) is \(\alpha\)-strongly convex if \(f(y)\geq f(x)+\nabla f(x)^{\top}(y-x)+\frac{\alpha}{2}\left\|y-x\right\|_{2}^{ 2},\forall x,y\in\mathcal{X}\). \(f\) is \(\beta\)-smooth if \(\left\|\nabla f(x)-\nabla f(y)\right\|_{2}\leq\beta\left\|x-y\right\|_{2}, \forall x,y\in\mathcal{X}\).

## 2 Related Work

Learning in congestion games.We refer the readers to the textbook (Nisan et al., 2007) for a general introduction to congestion games, the price of anarchy and tax mechanisms. Nonatomic congestion games were first studied in (Pigou, 1912) and formalized by (Wardrop, 1952). Atomic congestion games were introduced by (Rosenthal, 1973) and the connection with potential games is developed by (Monderer and Shapley, 1996). In contrast to general-sum games without structures, (approximate) Nash equilibrium can be computed efficiently in congestion games due to the existence of the potential function. Recently, various algorithms are developed to learn the Nash equilibrium in congestion games with different feedback oracles (Krichene et al., 2015; Chen and Lu, 2016; Cui et al., 2022; Jiang et al., 2022; Panagasa et al., 2023; Dong et al., 2023; Dadi et al., 2024). These algorithms are derived from the perspective of the players in the system, while our algorithm is essentially different in that it is utilized by the system designer to induce better equilibrium.

Optimal tax design in congestion games.For nonatomic congestion games, optimal tax design has a closed-form solution known as the marginal cost mechanism (Nisan et al., 2007). For atomic congestion games, the marginal cost mechanism can no longer improve the efficiency (Paccagnan et al., 2021). Instead, other mechanisms are proposed for optimal local/global and congestion dependent/independent tax in atomic congestion games (Caragiannis et al., 2010; Bilo and Vinci, 2019; Paccagnan et al., 2021; Paccagnan and Gairing, 2021; Harks et al., 2015). Notably, all of these mechanisms assume full knowledge of the game while we consider learning with partial information feedback.

Stackelberg games.Stackelberg game (Von Stackelberg, 2010) models the interactions between leaders and followers such that leaders take actions first and the followers make decisions after observing leaders' actions. Tax design can be formulated as a Stackelberg game where the designer is the leader and the game players are the followers. Equipped with a best response oracle to predict followers' actions, Letchford et al. (2009); Blum et al. (2014); Peng et al. (2019) propose algorithms for learning Stackelberg equilibrium. Recently, Bai et al. (2021); Zhong et al. (2021); Zhao et al. (2023) generalize these results to learning Stackelberg equilibrium with bandit feedback, under finite actions or linear function approximation assumptions. For tax design, the search space is an exponentially large function space with complicated dependence on the objective. Consequently, existing results for Stackelberg games become vacuous when specialized to our problem.

Mathematical programming under equilibrium constraint.Tax design can be formulated as minimizing social cost with respect to tax under the constraint that players are following the equilibrium. This is known as mathematical programs with equilibrium constraints (MPEC). MPEC is a bilevel optimization problem and is NP-hard in general (Luo et al., 1996). Existing approaches use specific inner loop algorithms to approach the equilibrium so that the gradient can be propagated to the outer loop (Li et al., 2020; Liu et al., 2022; Li et al., 2022; Maheshwari et al., 2023; Li et al., 2023; Grontas et al., 2024), relying on a unique and differentiable equilibrium (Colson et al., 2007). However, such an approach requires many strong assumptions, such as the tax designer can control the algorithm of the agents, convex objective function and parameterized tax function. In contrast, our results make none of these assumptions.

## 3 Preliminaries

Nonatomic congestion games.A weighted nonatomic congestion game (congestion game) is described by the tuple \((\mathcal{F},\mathcal{A}_{[m]},w_{[m]},c_{\mathcal{F}})\), where \(\mathcal{F}\) is the set of facilities with cardinality \(F\), \(m\) is the number of commodities, \(\mathcal{A}_{i}\) is the action set for commodity \(i\in[m]\), \(w_{i}\in[0,1]\) is the weight forcommodity \(i\in[m]\) such that \(\sum_{i\in[m]}w_{i}=1\), and \(c_{f}:[0,1]\mapsto[0,1]\) is the cost function for facility \(f\in\mathcal{F}\). Each commodity consists of infinite number of infinitesimal players with a total load to be \(w_{i}\). Each individual player is self-interested and has a negligible effect on the game.

In congestion games, action \(a\in\mathcal{A}_{i},i\in[m]\) is a subset of \(\mathcal{F}\), i.e. \(a\subseteq\mathcal{F}\), which denotes the facilities utilized by action \(a\). For commodity \(i\in[m]\), we use strategy \(x_{i}=(x_{i,a})_{a\in\mathcal{A}_{i}}\in[0,w_{i}]^{|\mathcal{A}_{i}|}\) with constraint \(\sum_{a\in\mathcal{A}_{i}}x_{i,a}=w_{i}\) to denote how the load is distributed over all the actions. The joint strategy for the game is represented by \(x=(x_{1},x_{2},\cdots,x_{m})\in[0,1]^{A},\) where \(A=\sum_{i\in[m]}|\mathcal{A}_{i}|\). We use \(\mathcal{X}\) to denote the set of all feasible strategies.

A decentralized perspective of strategy \(x_{i}\) for commodity \(i\) is that each self-interested infinitesimal player follows a randomized strategy that chooses \(a\in\mathcal{A}_{i}\) with probability proportional to \(x_{i,a}\). With the law of large number, the load on action \(a\) would be \(x_{i,a}\).

Cost function.For a strategy \(x\), the cost of a facility is \(c_{f}(l_{f}(x))\), where \(l_{f}(x)=\sum_{i\in[m]}\sum_{a\in\mathcal{A}_{i}:f\in a}x_{i,a}\) is the load on facility \(f\). The cost of an action \(a\) is the sum of the facility cost that \(a\) utilizes: \(c_{a}(x):=\sum_{f\in a}c_{f}(l_{f}(x))\).

We make the following assumption on the cost function. Monotonicity is a standard congestion game assumption, which is also observed in many real-world applications as more players sharing one facility, each player will have less gain or more cost (Nisan et al., 2007). Smoothness is a standard technical assumption for analysis.

**Assumption 1**.: _We assume the cost function satisfies:_

1. _Monotonicity:_ \(c_{f}(\cdot)\) _is non-decreasing for all_ \(f\in\mathcal{F}\)_,_
2. _Smoothness:_ \(c_{f}(\cdot)\) _is_ \(\beta\)_-smooth for all_ \(f\in\mathcal{F}\)_._

Nash equilibrium.Nash equilibrium in nonatomic congestion games, also known as the Wardrop equilibrium (Wardrop, 1952), is the strategy that no player has the incentive to deviate from its strategy as formalized in Definition 1. In other words, Nash equilibrium is a stable state for a system with selfish players.

**Definition 1**.: _A Nash equilibrium strategy \(x\) is a joint strategy such that each player is choosing the best action: for any commodity \(i\in[m]\) and actions \(a,a^{\prime}\in\mathcal{A}_{i}\), we have_

\[c_{a}(x)\leq c_{a^{\prime}}(x),\ \mathrm{if}\ x_{i,a}>0.\]

_Similarly, an \(\epsilon\)-approximate Nash equilibrium \(x\) satisfies that_

\[\forall i\in[m],a,a^{\prime}\in\mathcal{A}_{i},c_{a}(x)\leq c_{a^{\prime}}(x)+ \epsilon,\ \mathrm{if}\ x_{i,a}>0.\]

For a strategy \(x\) and commodity \(i\), actions \(a\in\mathcal{A}_{i}\) such that \(x_{i,a}>0\) are named as the "in-support" actions and the others are "off-support" actions. For a Nash equilibrium, in-support actions must all have the same cost and off-support actions are no better than in-support actions. It is well known that Nash equilibrium always exists in congestion games (Beckmann et al., 1956).

Potential Function.An important concept in congestion games is the potential function:

\[\Phi(x):=\sum_{f}\int_{0}^{l_{f}(x)}c_{f}(u)du.\]

If Assumption 1 is satisfied, then \(\Phi(x)\) is a convex function and Nash equilibrium is equivalent to the minimizer of the potential function (Beckmann et al., 1956).

Network congestion games.Network congestion games are congestion games with multicommodity network structure, which are also known as the selfish routing games (Roughgarden, 2005). A multicommodity network is described by a directed graph \((\mathcal{V},\mathcal{E})\) where \(\mathcal{V}\) is the vertex set and \(\mathcal{E}\) is the edge (facility) set. In addition, each commodity \(i\in[m]\) corresponds to a pair of source and target vertex \((s_{i},t_{i})\), and actions are all feasible paths connecting \(s_{i}\) and \(t_{i}\). Each edge is associated with a nondecreasing cost (latency) function.

## 4 Tax Design for Congestion Games

In this section, we introduce tax design in congestion games. Before we get into the details, we will first introduce some notions to simplify the problem.

### Polytope Description for Congestion Games

For a strategy \(x_{i}\in\mathbb{R}^{|\mathcal{A}_{i}|}\), the dimension \(|\mathcal{A}_{i}|\) can be as large as \(2^{F}\). Instead, it would be convenient to consider the facility load \(y_{i}\in\mathbb{R}^{F}\) such that \(y_{i,f}=\sum_{a\in\mathcal{A}_{i}:f\in a}x_{i,a}\). In addition, we define \(y=\sum_{i\in[m]}y_{i}\in\mathbb{R}^{F}\) to be the total facility load. We use \(\phi_{(i)}(\cdot)\) to denote the reparameterization mapping:

\[\phi(x)=y,\phi_{i}(x_{i})=y_{i},\forall i\in[m],\]

and we set \(\mathcal{Y}=\{y\in\mathbb{R}^{F}:\exists x\in\mathcal{X},y=\phi(x)\}\) to be the set of all feasible loads. Note that \(\phi\) is not necessarily a bijection, i.e., there could exist multiple strategies sharing the same load. We use \(\phi^{-1}(y):=\{x\in\mathcal{X}:\phi(x)=y\}\) to denote the set of strategies that are mapped to load \(y\). The potential function can be defined after the reparameterization as well:

\[\Phi^{\mathrm{repa}}(y):=\sum_{f}\int_{0}^{y_{f}}c_{f}(u)du=\Phi(x),\forall x \in\Phi^{-1}(y).\]

Importantly, \(\Phi^{\mathrm{repa}}(y)\) does not depend on the choice of strategy \(x\in\phi^{-1}(y)\). For the reparameterized potential function, we have the following lemma showing that it is almost equivalent to the original potential function. When it is clear from the context, we will simplify \(\Phi^{\mathrm{repa}}\) as \(\Phi\).

**Lemma 1**.: \(\Phi^{\mathrm{repa}}\) _is convex under Assumption 1. If \(y^{*}=\operatorname*{argmin}_{y}\Phi^{\mathrm{repa}}(y)\), then for any \(x\in\phi^{-1}(y^{*})\), \(x\) is a Nash equilibrium._

For any Nash equilibrium strategy \(x\), we call \(y=\phi(x)\) the Nash equilibrium load (Nash load).

### Optimal Tax for Congestion Games

Nash equilibrium is a stable state for a system with self-interested players, as no player has the incentive to deviate unilaterally. However, Nash equilibrium does not efficiently utilize the facilities, which is measured by the social cost:

\[\Psi(y):=\sum_{f}y_{f}c_{f}(y_{f}).\]

Price of anarchy is a concept that measures the efficiency of selfish agents in a system, defined as the ratio between the worst-case social cost for equilibria and the optimal social cost:

\[\mathrm{PoA}=\frac{\max_{y\text{ is a Nash equilibrium load }}\Psi(y)}{\min_{y\in \mathcal{Y}}\Psi(y)}\]

For example, in nonatomic congestion games with polynomial cost functions, the price of anarchy grows as \(\Theta(d/\ln d)\) where \(d\) is the degree of the polynomials (Nisan et al., 2007).

To reduce the price of anarchy, one standard approach is to enforce a tax on each facility to change the behavior of the self-interested players. Formally, a taxed congestion game is described by \((\mathcal{F},\mathcal{A}_{[m]},w_{[m]},c_{\mathcal{F}},\tau_{\mathcal{F}})\) with an additional tax function \(\tau_{f}:[0,1]\to\mathbb{R}\) on facility \(f\in\mathcal{F}\). The cost of facility \(f\) with load \(u\) under tax becomes \(c_{f}(u)+\tau_{f}(u)\). Correspondingly, we define the potential function with tax \(\tau\) as

\[\Phi(y;\tau):=\sum_{f}\int_{0}^{y_{f}}\left[c_{f}(u)+\tau_{f}(u)\right]du,\]

and the Nash load would satisfy \(y^{*}\in\operatorname*{argmin}_{y}\Phi(y;\tau)\).

The optimal tax is defined as the tax that can induce optimal social behavior for self-interested players. We want to note that tax is not included in social cost following the convention in tax design.

**Definition 2**.: _A tax \(\tau\) is an optimal tax if all Nash equilibria under tax \(\tau\) can minimize the social cost:_

\[\operatorname*{argmin}_{y\in\mathcal{Y}}\Phi(y;\tau)\subseteq \operatorname*{argmin}_{y\in\mathcal{Y}}\Psi(y).\]

_In addition, a tax \(\tau\) is an \(\epsilon\)-optimal tax if we have_

\[\Psi(y)\leq\min_{y^{\prime}\in\mathcal{Y}}\Psi(y^{\prime})+\epsilon,\forall y \in\operatorname*{argmin}_{y^{\prime\prime}\in\mathcal{Y}}\Phi(y^{\prime\prime };\tau).\]

The marginal cost tax is defined as

\[\tau^{*}:\tau^{*}_{f}(u)=uc^{\prime}_{f}(u),\forall f\in\mathcal{F}.\]

As \(\Phi(y;\tau^{*})=\Psi(y)\), the Nash equilibrium under tax \(\tau^{*}\) will minimize the social cost and \(\tau^{*}\) is an optimal tax (Nisan et al., 2007). We will make the following assumption so that the cost combined with tax \(c+\tau^{*}\) is still non-decreasing. In many real world problems, \(c^{\prime}_{f}(u)\) is non-decreasing due to the law of diminishing marginal utility, which guarantees Assumption 2.

**Assumption 2**.: _Marginal cost tax \(\tau^{*}_{f}(u)=uc^{\prime}_{f}(u)\) is non-decreasing for all \(f\in\mathcal{F}\)._

### Tax Design for Congestion Games

In this paper, we consider the case where the system designer (e.g. government) wants to enforce an (approximate) optimal tax to induce optimal social behavior and maximize social welfare. However, the cost function is unknown so the optimal tax function cannot be computed directly via the marginal cost mechanism. On the other hand, the designer can enforce several taxes and observe the feedback. As Nash equilibrium is the stable state of the system, we assume the designer can observe the equilibrium feedback.

Formally, tax design is formulated as an online learning problem as shown in Protocol 1. At round \(t\), the designer can choose a tax \(\tau^{t}\) and observe the corresponding Nash equilibrium load \(y^{t}\in\mathbb{R}^{F}\) and Nash equilibrium cost \(c^{t}\in\mathbb{R}^{F}\). The sample complexity of a tax design algorithm is the number of rounds for designing an \(\epsilon\)-optimal tax.

A naive approach is the designer first enumerates all of the \(\epsilon\)-approximations of \(\tau^{*}\) and chooses the tax with minimal social cost. However, such an approach would require \(O((1/\epsilon)^{F\beta/\epsilon})\) samples as the complexity of using piece-wise linear function to approximate \(\tau^{*}_{f}\) (a \(\beta\)-smooth function) with \(\epsilon\) error is \(O((1/\epsilon)^{\beta/\epsilon})\), resulting in exponential dependence on the parameters \(\beta\), \(1/\epsilon\) and \(F\).

Another approach is applying algorithms for mathematical programming under equilibrium constraints. Specifically, we can formulate tax design as solving

\[\min_{\tau}\Psi(y(\tau)),\;\text{s.t.}\;y(\tau)=\operatorname*{argmin}_{y\in \mathcal{Y}}\Phi(y;\tau).\]

However, \(y(\tau)\) can be non-differentiable or even discontinuous w.r.t. \(\tau\), and \(\Psi(y(\tau))\) can be non-convex w.r.t. \(\tau\) (Lemma 5). As a result, previous results do not apply to our problem as they apply gradient-based methods and make convexity assumptions (Li et al., 2020; Liu et al., 2022).

## 5 Learning Optimal Tax in Nonatomic Congestion Games

In this section, we describe our algorithm that can learn an \(\epsilon\)-optimal tax with \(O(F^{2}\beta/\epsilon)\) samples. First, we introduce piece-wise linear functions as a nonparametric way to approximate the marginal cost tax \(\tau^{*}\)(Takezawa, 2005).

**Definition 3**.: _(Piece-wise Linear Function) We use a dictionary1\(d=\{(x_{1},y_{1}),\cdots,(x_{n},y_{n})\}\) for \(x_{i}\neq x_{j},\forall i\neq j\) (w.l.o.g. we let \(x_{1}<x_{2}<\cdots<x_{n}\)) to represent a piece-wise linear function \(d(\cdot)\) on \([x_{1},x_{n}]\) such that_

Footnote 1: In this dictionary, key is \(x_{i}\) and value is \(y_{i}\). For readers unfamiliar with the dictionary data structure, it can be regarded as a set with a special update operation.

\[d(x)=\frac{x-x_{i+1}}{x_{i}-x_{i+1}}y_{i}+\frac{x_{i}-x}{x_{i}-x_{i+1}}y_{i+1}, \forall x\in[x_{i},x_{i+1}].\]

_In addition, we use \(\bigcup\) to represent the update method for dictionary. I.e., \(d\bigcup(x,y)\) is the piece-wise linear function interpolating one more point \((x,y)\) if \((x,d(x))\) is not already in \(d\), otherwise it will update \(d(x)\) to \(y\)._

We will maintain the piece-wise function on a grid \(\mathcal{L}=\{0,\Delta,2\Delta,\cdots,K\Delta=1\}\) with \(K=\left\lceil\frac{2\beta}{\epsilon}\right\rceil\) and \(\Delta=1/K\). The time complexity for computing \(d(x)\) is \(O(\log K)\) for any \(x\in[0,1]\).

### Main Algorithm

```
1:Initialize: Facility set \(\mathcal{F}\), number of rounds \(T\), tolerance \(\epsilon\), smoothness \(\beta\), perturbation \(\delta=\epsilon\Delta^{2}/8\).
2:Set initial tax \(\tau^{1}:\tau^{1}_{f}=\{(0,0),(1,\beta+\epsilon)\}\) for all \(f\in\mathcal{F}\). Set \(\mathcal{K}^{1}_{f}\) to be \(\{0\}\) for all \(f\in\mathcal{F}\).
3:for\(t=1,2,\ldots,T\)do
4: Observe Nash load \(y^{t}\in\mathbb{R}^{F}\) and Nash cost \(c^{t}\in\mathbb{R}^{F}\) under tax \(\tau^{t}\).
5: Set \(\bar{\mathcal{F}}\) to be the unknown facility set (Definition 4).
6: Set \(l_{f}=\tau^{t}_{f}([y^{t}_{f}]^{\perp_{\mathcal{K}^{1}_{f}}}_{\mathcal{K}^{1}_ {f}})+\epsilon(y^{t}_{f}-[y^{t}_{f}]^{\perp_{\mathcal{K}^{1}_{f}}}_{\mathcal{ K}^{1}_{f}})\) and \(r_{f}=\tau^{t}_{f}([y^{t}_{f}]^{+}_{\mathcal{K}^{t}_{f}\bigcup\{1\}})+\epsilon( y^{t}_{f}-[y^{t}_{f}]^{+}_{\mathcal{K}^{1}_{f}\bigcup\{1\}})\) for each \(f\in\bar{\mathcal{F}}\).
7: Run Algorithm 2 with input \(y^{t}\), \(c^{t}\), \(\tau^{t}=[\tau^{t}_{f}(y^{t}_{f})]_{f}\), \(\bar{\mathcal{F}}\) and \([l_{f},r_{f}]_{f\in\bar{\mathcal{F}}}\).
8:if Algorithm 2 return \(\mathrm{False}\)then
9:return\(\tau^{t}\)
10:else
11: Algorithm 2 return \(\widetilde{\tau}\in\mathbb{R}^{F},\widetilde{f}\in\bar{\mathcal{F}},\mathrm{ sign}\in\{-1,1\}\).
12: Apply tax \(\hat{\tau}^{t}:\hat{\tau}^{t}_{f}=\tau^{t}_{f}\bigcup(y^{t}_{\widetilde{f}}, \widetilde{\tau}^{t}_{f})+\mathrm{sign}\cdot\delta\) and \(\hat{\tau}^{t}_{f}=\tau^{t}_{f}\bigcup(y^{t}_{f},\widetilde{\tau}^{t}_{f})\) for \(f\neq\widetilde{f}\).
13: Observe \(\hat{y}^{t},\hat{c}^{t}\in\mathbb{R}^{F}\) as the Nash load and the Nash cost of each facility.
14: Update \(\tau_{t+1}\) and \(\mathcal{K}_{t+1}\) according to (1).
15:endif
16:endfor ```

**Algorithm 1** Tax Design for Congestion Game

In this section, we introduce our main algorithm. At each round \(t\), we will maintain a known index set \(\mathcal{K}^{t}_{f}\subseteq\mathcal{L}\) where the marginal cost tax can be accurately estimated (Lemma 7), and use a piece-wise linear function to approximate the tax function by interpolating the values at the known indexes. The piece-wise linear function takes the form \(\tau^{t}_{f}=\{(x^{t}_{i},y^{t}_{i})\}_{i}\) and the known index set \(\mathcal{K}^{t}_{f}\) satisfies \(\{x^{t}_{i}\}_{i}=\mathcal{K}^{t}_{f}\bigcup\{1\}\) and \(\mathcal{K}^{t}_{f}\subseteq\mathcal{L}\). Here \(1\) is a special case as it is not in the known index set initially but it is needed as the boundary for the piece-wise linear function \(\tau^{t}_{f}\). Initially, the tax is set to be \(\tau^{1}_{f}(u)=\{(0,0),(1,\beta+\epsilon)\}\) and the auxiliary tax is \(\widehat{\tau}^{1}_{f}=\{(0,0),(1,\beta)\}\) for \(f\in\mathcal{F}\) (Line 2). Here we set \(\widehat{\tau}^{1}_{f}(1)=\beta\) as \(\beta\) is always an upper bound on \(\tau^{t}_{f}(1)\). The auxiliary tax \(\widehat{\tau}^{t}_{f}\) is a non-decreasing piece-wise linear approximation of \(\tau^{*}_{f}\) and we always set tax \(\tau^{t}_{f}(u)=\widehat{\tau}^{t}_{f}(u)+\epsilon u\) to ensure that the subgradient of the tax enforced is lower bounded by \(\epsilon\).

At round \(t\), after observing Nash equilibrium load \(y^{t}\in\mathbb{R}^{F}\) and Nash equilibrium cost \(c^{t}\in\mathbb{R}^{F}\), the facilities are split into two sets: known facilities and unknown facilities.

**Definition 4**.: _For each round \(t\), facility \(f\) is known if the Nash load \(y^{t}_{f}\in[0,1]\) satisfies \([y^{t}_{f}]^{-}_{\mathcal{L}}\in\mathcal{K}^{t}_{f}\) and \([y^{t}_{f}]^{+}_{\mathcal{L}}\in\mathcal{K}^{t}_{f}\). Otherwise, facility \(f\) is unknown for round \(t\)._

For a known facility \(f\), the Nash load is either in the known index set or sandwiched by two consecutive known indexes. As a result, the tax estimate for the Nash load \(\tau^{t}_{f}(y^{t}_{f})\) will be close to thetrue optimal tax \(\tau^{*}_{f}(y^{t}_{f})\) with error \(2\epsilon\) (Lemma 8). We will apply Algorithm 2 to find the exploratory tax to gather information about unknown facilities (Line 7).

**Proposition 1**.: _If Algorithm 2 return \(\operatorname{False}\) at round \(t\), then tax \(\tau^{t}\) is an \(6\epsilon F\)-optimal tax. If Algorithm 2 output \(\widetilde{\tau}^{t},\widetilde{f}^{t},\operatorname{sign}^{t}\) at round \(t\), then we have_

\[0<\left|y^{t}_{\widetilde{f}^{t}}-\hat{y}^{t}_{\widetilde{f}^{t}}\right|\leq\Delta.\]

If Algorithm 2 output \(\widetilde{\tau}^{t},\widetilde{f}^{t},\operatorname{sign}^{t}\) at round \(t\), we update the tax and the known index set by the following rule. For \(u\in\{[y^{t}_{\widetilde{f}^{t}}]^{+}_{\mathcal{L}},[y^{t}_{\widetilde{f}^{ t}}]^{-}_{\mathcal{L}}\}\backslash\mathcal{F}^{t}_{\widetilde{f}^{t}}\) (this set is not empty as \(\widetilde{f}^{t}\) is an unknown facility), we set

\[\widetilde{\tau}^{t+1}_{\widetilde{f}^{t}}= \widetilde{\tau}^{t}_{\widetilde{f}^{t}}\bigcup\Bigl{(}u, \operatorname{clip}\bigl{(}u\cdot\frac{c^{t}_{\widetilde{f}^{t}}-\hat{c}^{t} _{\widetilde{f}^{t}}}{y^{t}_{\widetilde{f}^{t}}-\hat{y}^{t}_{\widetilde{f}^{t} }},\widetilde{\tau}^{t}_{\widetilde{f}^{t}}([y^{t}_{\widetilde{f}^{t}}]^{-}_{ \mathcal{K}^{t}_{\widetilde{f}^{t}}}),\widetilde{\tau}^{t}_{\widetilde{f}^{t} }([y^{t}_{\widetilde{f}^{t}}]^{+}_{\mathcal{K}^{t}_{\widetilde{f}^{t}}} \cup\{1\})\bigr{)}\Bigr{)},\] (1) \[\mathcal{K}^{t+1}_{\widetilde{f}^{t}}= \mathcal{K}^{t}_{\widetilde{f}^{t}}\bigcup\{u\}.\] (2)

and \(\widetilde{\tau}^{t+1}_{f}=\widetilde{\tau}^{t}_{f},\mathcal{K}^{t+1}_{f}= \mathcal{K}^{t}_{f}\) for \(f\neq\widetilde{f}^{t}\). Then we set \(\tau^{t+1}_{f}(u)=\widetilde{\tau}^{t+1}_{f}(u)+\epsilon u\) for all \(f\in\mathcal{F}\) and \(u\in[0,1]\).

In words, we clip the two-point estimate \(u\cdot\frac{c^{t}_{\widetilde{f}^{t}}-\hat{c}^{t}_{\widetilde{f}^{t}}}{y^{t}_ {\widetilde{f}^{t}}-\hat{y}^{t}_{\widetilde{f}^{t}}}\) on the left and right known index of \(\widetilde{\tau}^{t}_{\widetilde{f}_{i}}(u)\) so that \(\widetilde{\tau}^{t+1}_{\widetilde{f}^{t}}(u)\) is still a non-decreasing piece-wise linear approximation of the marginal cost tax \(\tau^{*}_{f}\). \(\tau^{t+1}_{f}\) is added with an extra linear term to guarantee a strongly convex potential function (Lemma 2). As \(0<\left|y^{t}_{f}-\hat{y}^{t}_{f}\right|\leq\Delta\), the two point estimate of the gradient \(\frac{c^{t}_{f}-\hat{c}^{t}_{f}}{y^{t}_{f}-\hat{y}^{t}_{f}}\) is accurate enough for \(c^{\prime}_{f}(u)\) such that \(\left|\tau^{t+1}_{\widetilde{f}^{t}}(u)-\tau_{f}(u)\right|\leq\epsilon\) (Lemma 6).

As \(|\mathcal{K}^{t}_{\widetilde{f}^{t}}|\) increases by 1 at round \(t\) and there are \(F\) such sets with size bounded by \(O(\beta/\epsilon)\), Algorithm 2 will output \(\operatorname{False}\) within at most \(O(F\beta/\epsilon)\) rounds, which implies \(\tau^{t}\) is an \(\epsilon F\)-optimal tax (Proposition 1). With proper rescaling, the sample complexity for learning \(\epsilon\)-optimal tax is \(O(F^{2}\beta/\epsilon)\).

**Theorem 1**.: _Under Assumption 1 and Assumption 2, Algorithm 1 will output a \(6\epsilon F\) tax within \(T\leq 2F\beta/\epsilon\) rounds. In addition, each round has at most two tax realizations._

**Remark 1**.: _To uniformly approximate a \(\beta\)-smooth function, we have to know its value at \(O(\beta/\epsilon)\) points [Takezawa, 2005]. For an \(\epsilon\)-optimal tax, we need to estimate \(\tau^{*}_{f}\) with \(\epsilon/F\) accuracy as the error accumulates with all the facilities. As a result, we conjecture that \(O(F^{2}\beta/\epsilon)\) sample complexity is tight and we leave the lower bound to future work._

**Remark 2**.: _Our algorithm can be easily adapted to the case where we have feedback other than only the equilibrium feedback. Specifically, when the tax designer obtain a non-equilibrium feedback, she can still update the optimal tax estimate if the feedback provides new information. It is possible for our algorithm to find the optimal tax even if no equilibrium feedback is provided. In addition, as long as the equilibrium can be reached after applying a tax, the algorithm can always find the optimal tax._

### Subroutine for Finding Exploratory Tax

In this section, we describe Algorithm 2, which can find an exploratory tax that satisfies Proposition 1. The idea is we can observe another similar but different Nash equilibrium load by perturbing the tax. However, there are two challenges:

1. Perturbing the tax might change the Nash equilibrium load drastically.
2. Perturbing the tax might not change the Nash equilibrium load at all.

To resolve the first issue, we always apply taxes that have (sub)gradient lower bounded by \(\epsilon>0\). The feasible range \([l_{f},r_{f}]\) for updating tax \(\tau^{*}_{f}\) with \((y^{t}_{f},\cdot)\) guarantees that the updated tax still maintains the subgradient lower bound. By Lemma 2, the potential function is always \(\epsilon\)-strongly convex. As a result, the Nash load for any feasible tax is unique and Lipschitz w.r.t. tax perturbation. To resolve the second issue, we find the tax that makes the current Nash equilibrium on the "boundary". I.e., an additional perturbation will make the Nash equilibrium change. Intuitively, this is similar to removing the slackness in a constrained optimization problem. By Lemma 3, we can observe a different Nash load on \(f\) if we make the additional perturbation.

**Lemma 2**.: _If the subgradient of the cost function \(c_{f}\) is lower bounded by \(\epsilon>0\) for all \(f\in\mathcal{F}\), then the potential function \(\Phi^{\mathrm{repa}}(y)\) is \(\epsilon\)-strongly convex. However, \(\Phi(x)\) is not necessarily strongly convex._

**Lemma 3**.: _If two taxes \(\tau\) and \(\hat{\tau}\) only differ in facility \(f\) and the Nash loads \(y\) and \(\dot{y}\) are different, then \(y_{f}\neq\dot{y}_{f}\)._

**Definition 5**.: _The gap for a strategy \(x\in\mathcal{X}\) with cost \(c\in\mathbb{R}^{F}\) is defined as_

\[\mathrm{Gap}_{i}(x,c)=\min_{a:x_{i,a}=0}\sum_{f:f\in a}c_{f}-\max_{a:x_{i,a} \neq 0}\sum_{f:f\in a}c_{f}.\] (3)

In the algorithm, we use \(\mathrm{Gap}_{i}(x,c)\) to measure the cost gap between in-support actions and off-support actions for commodity \(i\) and strategy \(x\). If \(x\) is a Nash equilibrium and \(c\) is the Nash cost, then all of the in-support actions have the same minimal cost and \(\mathrm{Gap}_{i}(x,c)\geq 0\) holds. Informally, "boundary" tax \(\tau\) means that \(\mathrm{Gap}_{i}(x,c+\tau)=0\) for a Nash equilibrium \(x\) and perturbing \(\tau\) results in \(\mathrm{Gap}_{i}(x,c+\tau)<0\), so the Nash equilibrium under the perturbed tax will be different from \(x\).

Now we discuss how Algorithm 2 finds the "boundary" tax in detail. The input to the algorithm is the Nash flow \(y\), the Nash cost \(c\), the Nash tax \(\tau\), the unknown facility set \(\bar{\mathcal{F}}\) and the feasible tax range \([l_{f},r_{f}]\) for each unknown facility \(f\in\bar{\mathcal{F}}\). We emphasize that here the Nash cost/tax are the values of the cost/tax function on the Nash load and they are vectors in \(\mathbb{R}^{F}\) instead of functions. \([l_{f},r_{f}]\) is the feasible range for the perturbed tax value at facility \(f\). By the definition of \(l_{f}\) and \(r_{f}\), current tax \(\tau_{f}^{t}\) updated with \((y_{f}^{t},u),u\in[l_{f},r_{f}]\) is still a tax with subgradient lower bounded by \(\epsilon\).

For the first step, the algorithm will compute strategy \(x\in\phi^{-1}(y)\) as the Nash equilibrium strategy (Line 2). If there exists an unknown facility \(f\) and commodity \(i\) such that not all load of commodity \(i\) is using \(f\) or not using \(f\) (Line 4), then perturbing the tax at facility \(f\) will make \(x\) not longer a Nash equilibrium as in-support actions have different costs.

Otherwise, for each unknown facility \(f\) and commodity \(i\), either all of the load is using \(f\) or all of the load is not using \(f\). As a result, in-support actions always have the same cost after perturbing the tax. For the next step, we verify if there exists a tax within the feasible ranges for unknown facilities that makes \(x\) not a Nash equilibrium. However, there does not exist a universal worst-case tax that can verify if \(x\) is always a Nash equilibrium or not.

Fortunately, the worst-case tax has a closed form for each commodity separately: the taxes for facilities used by all of the Nash load would be the upper bound \(r_{f}\) and the taxes for facilities used by none of the Nash load would be the lower bound \(l_{f}\), thus maximizing the cost for in-support actions and minimizing the cost for off-support actions (Line 9). For each commodity \(i\), we apply the corresponding worst-case tax and check if the in-support actions are still the optimal actions (Line 10). If for all commodities, the in-support actions are optimal under the worst-case tax, then for any tax within the feasible range, \(y\) is the Nash load and the algorithm will output \(\operatorname{False}\) (Line 16). As \(\tau^{*}\) is approximately within the range, \(y^{t}\) approximately minimizes the social cost (Lemma 10).

Otherwise, the algorithm finds commodity \(i\) such that \(x\) is not the Nash equilibrium under the worst-case tax (Line 11). For the last step, we gradually transform the initial tax to this worst-case tax and stop when \(x\) is not the Nash equilibrium for some commodity. Specifically, the algorithm iteratively changes the tax in the unknown facility set \(\bar{\mathcal{F}}=\bar{\mathcal{F}}_{i}\bigcup\bar{\mathcal{F}}_{i}^{\prime}\) (Line 19 and Line 27) to the worst-case tax.

For facility \(f\in\bar{\mathcal{F}}_{i}\), the algorithm finds the boundary tax for facility \(f\) that satisfies

\[u=\operatorname*{argmax}_{u}\{u:\operatorname{Gap}_{j}(x,c+\widetilde{\tau}^ {u})\geq 0,\forall j\in[m]\}.\]

If \(u\leq r_{f}\), we will output \(\widetilde{\tau}^{u},f,1\). By the definition of \(u\), if we further increase \(u\), one of the gaps will become negative and \(x\) is no longer the Nash equilibrium. Otherwise, all feasible taxes for \(f\) have a nonnegative gap for all commodities, which means \(x\) is still the Nash equilibrium, and we continue for the next facility. After enumerating all the facilities in \(\bar{\mathcal{F}}_{i}\), we enumerate \(\bar{\mathcal{F}}_{i}^{\prime}\) in the same way. Eventually, the tax is transformed into the worst-case tax with negative gap for commodity \(i\), so this process will end and output \(\widetilde{\tau}^{u},f,\operatorname{sign}\) such that \(\widetilde{\tau}^{u}\) is the tax that makes the Nash equilibrium on the boundary, \(f\) is the facility to perturb and \(\operatorname{sign}\) is the direction to perturb the tax at \(f\).

## 6 Conclusion

We proposed the first algorithm with polynomial sample complexity for learning optimal tax in nonatomic congestion games. The algorithm leverages several novel designs to exploit the special structure of congestion games, which can also be implemented efficiently. Below we list a few potential future research directions:

1. Relaxing the Nash equilibrium assumption to players following no-regret dynamics or quantal response equilibrium.
2. Design algorithms that do not require prior knowledge of the smoothness coefficient.
3. Generalize the algorithm to atomic congestion games.

## 7 Acknowledgement

SSD acknowledges the support of NSF IIS 2110170, NSF DMS 2134106, NSF CCF 2212261, NSF IIS 2143493, NSF CCF 2019844, and NSF IIS 2229881. MF acknowledges the support of NSF awards CCF 2007036, TRIPODS II DMS 2023166, CCF 2212261, and CCF-AF 2312775.

## References

* Bai et al. (2021) Yu Bai, Chi Jin, Huan Wang, and Caiming Xiong. Sample-efficient learning of stackelberg equilibria in general-sum games. _Advances in Neural Information Processing Systems_, 34:25799-25811, 2021.
* Beckmann et al. (1956) Martin Beckmann, Charles B McGuire, and Christopher B Winsten. Studies in the economics of transportation. Technical report, 1956.
* Bergendorff et al. (1997) Pia Bergendorff, Donald W Hearn, and Motakuri V Ramana. _Congestion toll pricing of traffic networks_. Springer, 1997.
* Bilo and Vinci (2019) Vittorio Bilo and Cosimo Vinci. Dynamic taxes for polynomial congestion games. _ACM Transactions on Economics and Computation (TEAC)_, 7(3):1-36, 2019.
* Blum et al. (2014) Avrim Blum, Nika Haghtalab, and Ariel D Procaccia. Learning optimal commitment to overcome insecurity. _Advances in Neural Information Processing Systems_, 27, 2014.
* Braess (1968) Dietrich Braess. Uber ein paradoxon aus der verkehrsplanung. _Unternehmensforschung_, 12:258-268, 1968.
* Caragiannis et al. (2010) Ioannis Caragiannis, Christos Kaklamanis, and Panagiotis Kanellopoulos. Taxes for linear atomic congestion games. _ACM Transactions on Algorithms (TALG)_, 7(1):1-31, 2010.
* Chen and Lu (2016) Po-An Chen and Chi-Jen Lu. Generalized mirror descents in congestion games. _Artificial Intelligence_, 241:217-243, 2016.
* Cohen et al. (2021) Michael B Cohen, Yin Tat Lee, and Zhao Song. Solving linear programs in the current matrix multiplication time. _Journal of the ACM (JACM)_, 68(1):1-39, 2021.
* Colson et al. (2007) Benoit Colson, Patrice Marcotte, and Gilles Savard. An overview of bilevel optimization. _Annals of operations research_, 153:235-256, 2007.
* Cui et al. (2022) Qiwen Cui, Zhihan Xiong, Maryam Fazel, and Simon S Du. Learning in congestion games with bandit feedback. _Advances in Neural Information Processing Systems_, 35:11009-11022, 2022.
* Dadi et al. (2024) Leello Dadi, Ioannis Panageas, Stratis Skoulakis, Luca Viano, and Volkan Cevher. Polynomial convergence of bandit no-regret dynamics in congestion games. _arXiv preprint arXiv:2401.09628_, 2024.
* Dong et al. (2023) Jing Dong, Jingyu Wu, Siwei Wang, Baoxiang Wang, and Wei Chen. Taming the exponential action set: Sublinear regret and fast convergence to nash equilibrium in online congestion games. _arXiv preprint arXiv:2306.13673_, 2023.
* Grontas et al. (2024) Panagiotis D Grontas, Giuseppe Belgioioso, Carlo Cenedese, Marta Fochesato, John Lygeros, and Florian Dorfler. Big hype: Best intervention in games via distributed hypergradient descent. _IEEE Transactions on Automatic Control_, 2024.
* Harks et al. (2015) Tobias Harks, Ingo Kleinert, Max Klimm, and Rolf H Mohring. Computing network tolls with support constraints. _Networks_, 65(3):262-285, 2015.
* Jiang et al. (2022) Haozhe Jiang, Qiwen Cui, Zhihan Xiong, Maryam Fazel, and Simon S Du. Offline congestion games: How feedback type affects data coverage requirement. _arXiv preprint arXiv:2210.13396_, 2022.
* Koutsoupias and Papadimitriou (1999) Elias Koutsoupias and Christos Papadimitriou. Worst-case equilibria. In _Annual symposium on theoretical aspects of computer science_, pages 404-413. Springer, 1999.
* Krichene et al. (2015) Walid Krichene, Benjamin Drighes, and Alexandre M Bayen. Online learning of nash equilibria in congestion games. _SIAM Journal on Control and Optimization_, 53(2):1056-1081, 2015.
* Lattimore and Szepesvari (2020) Tor Lattimore and Csaba Szepesvari. _Bandit algorithms_. Cambridge University Press, 2020.
* Letchford et al. (2009) Joshua Letchford, Vincent Conitzer, and Kamesh Munagala. Learning and approximating the optimal strategy to commit to. In _Algorithmic Game Theory: Second International Symposium, SAGT 2009, Paphos, Cyprus, October 18-20, 2009. Proceedings 2_, pages 250-262. Springer, 2009.
* Lafferty et al. (2015)Jiayang Li, Jing Yu, Yu Nie, and Zhaoran Wang. End-to-end learning and intervention in games. _Advances in Neural Information Processing Systems_, 33:16653-16665, 2020.
* Li et al. (2022) Jiayang Li, Jing Yu, Qianni Wang, Boyi Liu, Zhaoran Wang, and Yu Marco Nie. Differentiable bilevel programming for stackelberg congestion games. _arXiv preprint arXiv:2209.07618_, 2022.
* Li et al. (2023) Jiayang Li, Jing Yu, Boyi Liu, Yu Nie, and Zhaoran Wang. Achieving hierarchy-free approximation for bilevel programs with equilibrium constraints. In _International Conference on Machine Learning_, pages 20312-20335. PMLR, 2023.
* Liu et al. (2022) Boyi Liu, Jiayang Li, Zhuoran Yang, Hoi-To Wai, Mingyi Hong, Yu Nie, and Zhaoran Wang. Inducing equilibria via incentives: Simultaneous design-and-play ensures global convergence. _Advances in Neural Information Processing Systems_, 35:29001-29013, 2022.
* Luo et al. (1996) Zhi-Quan Luo, Jong-Shi Pang, and Daniel Ralph. _Mathematical programs with equilibrium constraints_. Cambridge University Press, 1996.
* Maheshwari et al. (2023) Chinmay Maheshwari, S Shankar Sasty, Lillian Ratliff, and Eric Mazumdar. Convergent first-order methods for bi-level optimization and stackelberg games. _arXiv preprint arXiv:2302.01421_, 2023.
* Marden and Roughgarden (2014) Jason R Marden and Tim Roughgarden. Generalized efficiency bounds in distributed resource allocation. _IEEE Transactions on Automatic Control_, 59(3):571-584, 2014.
* Monderer and Shapley (1996) Dov Monderer and Lloyd S Shapley. Potential games. _Games and economic behavior_, 14(1):124-143, 1996.
* Nisan et al. (2007) Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay V. Vazirani. _Algorithmic Game Theory_. Cambridge University Press, New York, NY, USA, 2007.
* Paccagnan and Gairing (2021) Dario Paccagnan and Martin Gairing. In congestion games, taxes achieve optimal approximation. In _Proceedings of the 22nd ACM Conference on Economics and Computation_, pages 743-744, 2021.
* Paccagnan et al. (2021) Dario Paccagnan, Rahul Chandan, Bryce L Ferguson, and Jason R Marden. Optimal taxes in atomic congestion games. _ACM Transactions on Economics and Computation (TEAC)_, 9(3):1-33, 2021.
* Panageas et al. (2023) Ioannis Panageas, Stratis Skoulakis, Luca Viano, Xiao Wang, and Volkan Cevher. Semi bandit dynamics in congestion games: Convergence to nash equilibrium and no-regret guarantees. In _International Conference on Machine Learning_, pages 26904-26930. PMLR, 2023.
* Peng et al. (2019) Binghui Peng, Weiran Shen, Pingzhong Tang, and Song Zuo. Learning optimal strategies to commit to. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 33, pages 2149-2156, 2019.
* Pigou (1912) Arthur Cecil Pigou. _Wealth and welfare_. Macmillan and Company, limited, 1912.
* Rosenthal (1973) Robert W Rosenthal. A class of games possessing pure-strategy nash equilibria. _International Journal of Game Theory_, 2:65-67, 1973.
* Roughgarden (2005) Tim Roughgarden. _Selfish routing and the price of anarchy_. MIT press, 2005.
* Roughgarden and Tardos (2004) Tim Roughgarden and Eva Tardos. Bounding the inefficiency of equilibria in nonatomic congestion games. _Games and economic behavior_, 47(2):389-403, 2004.
* Takezawa (2005) Kunio Takezawa. _Introduction to nonparametric regression_. John Wiley & Sons, 2005.
* Von Stackelberg (2010) Heinrich Von Stackelberg. _Market structure and equilibrium_. Springer Science & Business Media, 2010.
* Wardrop (1952) John Glen Wardrop. Road paper. some theoretical aspects of road traffic research. _Proceedings of the institution of civil engineers_, 1(3):325-362, 1952.
* Zhao et al. (2023) Geng Zhao, Banghua Zhu, Jiantao Jiao, and Michael Jordan. Online learning in stackelberg games with an omniscient follower. In _International Conference on Machine Learning_, pages 42304-42316. PMLR, 2023.
* Zhong et al. (2021) Han Zhong, Zhuoran Yang, Zhaoran Wang, and Michael I Jordan. Can reinforcement learning find stackelberg-nash equilibria in general-sum markov games with myopic followers? _arXiv preprint arXiv:2112.13521_, 2021.

## Appendix A Basics about Congestion Games

**Lemma 4**.: _If strategy \(x\) is an \(\epsilon\)-NE in a congestion game, then \(x\) is an \(\epsilon\)-minimizer of the corresponding potential function \(\Phi(\cdot)\)._

Proof.: Let \(x^{*}=\operatorname*{argmin}_{x\in\mathcal{X}}\Phi(x)\) and \(y=\phi(x)\). First, we show that

\[\nabla_{i,a}\Phi(x)= \nabla_{i,a}\sum_{f}\int_{0}^{y_{f}}c_{f}(u)du\] \[= \nabla_{i,a}\sum_{f\in a}\int_{0}^{y_{f}}c_{f}(u)du\] \[= \sum_{f\in a}c_{f}(y_{f})\nabla_{i,a}y_{f}\] \[= \sum_{f\in a}c_{f}(y_{f})\nabla_{i,a}\sum_{i^{\prime},a^{\prime} :f\in a^{\prime}}x_{i^{\prime},a^{\prime}}\] \[= \sum_{f\in a}c_{f}(y_{f}).\]

Then we have

\[\Phi(x)-\Phi(x^{*}) \leq\langle x-x^{*},\nabla\Phi(x)\rangle\] (Convexity) \[\leq\sum_{i\in[m]}\langle x_{i}-x_{i}^{*},\nabla_{i}\Phi(x)\rangle\] \[\leq\sum_{i\in[m]}\left[\sum_{a\in\mathcal{A}_{i}}x_{i,a}\sum_{f \in a}c_{f}(y_{f})-\min_{a\in\mathcal{A}_{i}}w_{i}\sum_{f\in a}c_{f}(y_{f})\right]\] \[\leq\sum_{i\in[m]}\sum_{a\in\mathcal{A}_{i}}x_{i,a}\epsilon\] \[=\sum_{i\in[m]}w_{i}\epsilon\] \[=\epsilon.\]

**Lemma 1**.: \(\Phi^{\mathrm{repa}}\) _is convex under Assumption 1. If \(y^{*}=\operatorname*{argmin}_{y}\Phi^{\mathrm{repa}}(y)\), then for any \(x\in\phi^{-1}(y^{*})\), \(x\) is a Nash equilibrium._

Proof.: For \(y^{1},y^{2}\in\mathcal{Y}\), we have

\[\Phi^{\mathrm{repa}}(y^{1})+\Phi^{\mathrm{repa}}(y^{2})-2\Phi^{ \mathrm{repa}}(\frac{y^{1}+y^{2}}{2})= \sum_{f}\left[\int_{0}^{y_{f}^{1}}c_{f}(u)du+\int_{0}^{y_{f}^{2} }c_{f}(u)du-2\int_{0}^{\frac{y_{f}^{1}+y_{f}^{2}}{2}}c_{f}(u)du\right].\]

Now we show that \(\int_{0}^{y_{f}^{1}}c_{f}(u)du+\int_{0}^{y_{f}^{2}}c_{f}(u)du-2\int_{0}^{\frac {y_{f}^{1}+y_{f}^{2}}{2}}c_{f}(u)du\) is nonnegative for all \(f\in\mathcal{F}\). W.l.o.g., we assume \(y_{f}^{1}\leq y_{f}^{2}\) and we have

\[\int_{0}^{y_{f}^{1}}c_{f}(u)du+\int_{0}^{y_{f}^{2}}c_{f}(u)du-2 \int_{0}^{\frac{y_{f}^{1}+y_{f}^{2}}{2}}c_{f}(u)du= \int_{\frac{y_{f}^{1}+y_{f}^{2}}{2}}^{y_{f}^{2}}c_{f}(u)du-\int_{y_ {f}^{1}}^{\frac{y_{f}^{1}+y_{f}^{2}}{2}}c_{f}(u)du\] \[= \int_{y_{f}^{1}}^{\frac{y_{f}^{1}+y_{f}^{2}}{2}}\left[c_{f}(u+ \frac{y_{f}^{2}-y_{f}^{1}}{2})-c_{f}(u)\right]du\] \[\geq 0,\]where the last step is from Assumption 1 (monotonicity). As a result, \(\Phi^{\mathrm{repa}}\) is convex.

Let \(y^{*}=\operatorname*{argmin}_{y}\Phi^{\mathrm{repa}}(y)\) and \(x\in\phi^{-1}(y^{*})\). If there exists \(x^{\prime}\in\mathcal{X}\) such that \(\Phi(x^{\prime})<\Phi(x)\), then we have \(\Phi^{\mathrm{repa}}(\phi(x^{\prime}))<\Phi^{\mathrm{repa}}(y^{*})\), which contradicts the definition of \(y^{*}\). As a result, \(x\) is the minimizer of \(\Phi(\cdot)\), which means \(x\) is a Nash equilibrium. 

**Lemma 5**.: _The Nash load under tax \(\tau\): \(y(\tau)=\operatorname*{argmin}_{y\in\mathcal{Y}}\Phi(y;\tau)\) is not continuous w.r.t. \(\tau\). In addition, the social welfare \(\Psi(y(\tau))\) is not convex w.r.t. \(\tau\)._

Proof.: For the first part, we construct a congestion game with two facilities \(f_{1},f_{2}\), one commodity with action set \(\{f_{1},f_{2}\}\), and constant cost \(c_{1}=1,c_{2}=1-\epsilon\) with \(\epsilon>0\). Then for tax \(\tau=0\), we have \(y(\tau)=[0,1]\). For constant tax \(\tau_{1}=0,\tau_{2}=2\epsilon\), we have \(y(\tau)=[1,0]\). As \(\epsilon\) can be arbitrarily small, \(y(\tau)\) is not continuous w.r.t. \(\tau\).

For the second part, we construct a congestion game with two facilities \(f_{1},f_{2}\), one commodity with action set \(\{f_{1},f_{2}\}\), and cost function \(c_{1}=1,c_{2}(u)=\sqrt{u}\) for \(u\in[0,1]\). We apply constant tax \(\tau:\tau_{1}=t,\tau_{2}=0\) for \(t\in[-1,0]\). The Nash equilibrium under tax \(\tau\) is \(y(\tau)=[1-(1+t)^{2},(1+t)^{2}]\). Then the social cost is \(\Psi(y(\tau))=1-t(1+t)^{2}\), which is not convex on \([-1,0]\). 

## Appendix B Missing Proofs in Section 5

**Lemma 2**.: _If the subgradient of the cost function \(c_{f}\) is lower bounded by \(\epsilon>0\) for all \(f\in\mathcal{F}\), then the potential function \(\Phi^{\mathrm{repa}}(y)\) is \(\epsilon\)-strongly convex. However, \(\Phi(x)\) is not necessarily strongly convex._

Proof.: First, by the definition of the potential function \(\Phi\), it is easy to show that \(\nabla\Phi(y)=[c_{f}(y_{f})]_{f\in\mathcal{F}}\). For \(y^{1},y^{2}\in\mathcal{Y}\), we have

\[(\nabla\Phi(y^{1})-\nabla\Phi(y^{2}))^{\top}(y^{1}-y^{2})=\sum_{f\in\mathcal{ F}}(c_{f}(y^{1}_{f})-c_{f}(y^{2}_{f}))(y^{1}_{f}-y^{2}_{f})\geq\sum_{f\in\mathcal{ F}}\epsilon(y^{1}_{f}-y^{2}_{f})^{2}=\epsilon\left\|y^{1}-y^{2}\right\|_{2}^{2},\]

which implies \(\Phi(\cdot)\) is a \(\epsilon\)-strongly convex function.

For the second argument, we only need to construct a congestion game such that there exists two strategy \(x^{1},x^{2}\in\mathcal{X}\) such that for \(\phi(tx^{1}+(1-t)x^{2})\) is a constant for \(t\in[0,1]\), which implies the potential function \(\Phi(tx^{1}+(1-t)x^{2})=\Phi^{\mathrm{repa}}(\phi(tx^{1}+(1-t)x^{2}))\) is a constant w.r.t. \(t\). However, a strongly convex function cannot be a constant on a line, which implies \(\Phi\) is not strongly convex.

We construct a congestion game with three facilities \(f_{1},f_{2},f_{3}\), three actions \(a_{1}=\{f_{1}\},a_{2}=\{f_{2}\},a_{3}=\{f_{3}\}\) and three commodities with action set \(\{a_{1},a_{2}\},\{a_{2},a_{3}\},\{a_{3},a_{1}\}\). Strategy \(x^{1}:x^{1}=[1,0,0],x^{1}_{2}=[0,1,0],x^{1}_{3}=[0,0,1]\) and \(x^{2}:x^{2}_{1}=[0,1,0],x^{2}_{2}=[0,0,1],x^{2}_{3}=[1,0,0]\). Then \(tx^{1}+(1-t)x^{2}\) is a feasible strategy and we have \(\phi(tx^{1}+(1-t)x^{2})=[1,1,1]\) for all \(t\in[0,1]\). 

**Lemma 3**.: _If two taxes \(\tau\) and \(\dot{\tau}\) only differ in facility \(f\) and the Nash loads \(y\) and \(\dot{y}\) are different, then \(y_{f}\neq\dot{y}_{f}\)._

Proof.: For simplicity, we consider the equivalent tax-free case that we have two costs \(c,\dot{c}\) with subgradient lower bounded by \(\epsilon\) and they only differ in facility \(\dot{f}\). The potential functions are

\[\Phi(Y)=\sum_{f}\int_{0}^{Y_{f}}c_{f}(u)du,\dot{\Phi}(Y)=\sum_{f}\int_{0}^{Y_{f }}\dot{c}_{f}(u)du.\]

By Lemma 2, \(\Phi\) and \(\dot{\Phi}\) are strongly convex and thus the Nash equilibrium load \(y\) and \(\dot{y}\) are unique. Suppose \(y_{f}=\dot{y}_{f}\). Consider any \(Y\in\mathcal{Y}\) such that \(Y_{f}=y_{f}\), we have

\[\dot{\Phi}(Y)-\dot{\Phi}(y)= \sum_{f}\int_{y_{f}}^{Y_{f}}\dot{c}_{f}(u)du=\sum_{f\neq\dot{f}} \int_{y_{f}}^{Y_{f}}\dot{c}_{f}(u)du+\int_{y_{f}}^{Y_{f}}\dot{c}_{\dot{f}}(u)du\] \[= \sum_{f\neq\dot{f}}\int_{y_{f}}^{Y_{f}}c_{f}(u)du=\Phi(Y)-\Phi(y) \geq 0.\]As a result, we have \(\Phi(y)\leq\hat{\Phi}(\hat{y})\). By the optimality of \(\hat{y}\), we have \(y=\hat{y}\). By contradiction, if \(y\neq\hat{y}\), we have \(y_{f}=\hat{y}_{f}\). 

**Lemma 6**.: _If \(|u_{1}-u_{2}|\leq\Delta\), then for any \(|u_{3}-u_{1}|\leq\Delta\), we have_

\[\left|\frac{c_{f}(u_{1})-c_{f}(u_{2})}{u_{1}-u_{2}}-c_{f}^{\prime}(u_{3}) \right|\leq\epsilon.\]

Proof.: This is a direct corollary of the \(\beta\)-smoothness. By mean value theorem, we have \(\frac{c_{f}(u_{1})-c_{f}(u_{2})}{u_{1}-u_{2}}=c_{f}^{\prime}(u)\) for some \(u\in[u_{1},u_{2}].\) As \(|u-u_{3}|\leq|u-u_{1}|+|u_{1}-u_{3}|\leq 2\Delta\leq\frac{\epsilon}{2\beta}\), we have

\[\left|\frac{c_{f}(u_{1})-c_{f}(u_{2})}{u_{1}-u_{2}}-c_{f}^{\prime}(u_{3}) \right|\leq\epsilon.\]

**Lemma 7**.: _For round \(t\) and facility \(f\), if \(u\in\mathcal{K}_{f}^{t}\), then we have \(\left|\tau_{f}^{t}(u)-\tau_{f}^{*}(u)\right|\leq 2\epsilon\)._

Proof.: By the algorithm design, for each \(u\in\mathcal{K}_{f}^{t}\), \(\tau_{f}^{t}(u)\) will not change after \(u\) is added to \(\mathcal{K}_{f}\). We will use induction on \(t\) to prove \(\left|\widehat{\tau}_{f}^{t}(u)-\tau_{f}(u)\right|\leq\epsilon\) for \(u\in\mathcal{K}_{f}^{t}\). At round \(t=1\), \(\mathcal{K}_{f}^{1}=\{0\}\) and \(\widehat{\tau}_{f}^{1}(0)=\tau_{f}^{*}(0)=0\) holds.

Suppose at round \(t\), we have \(\mathcal{K}_{\widehat{f}^{t}}^{t+1}=\mathcal{K}_{\widehat{f}^{t}}^{t}\bigcup\{u\}\) with \(u\in\{[y_{\widehat{f}^{t}}^{t}]^{+}_{\mathcal{L}},[y_{\widehat{f}^{t}}^{t}]^{- }_{\mathcal{L}}\}\backslash\mathcal{K}_{f^{t}}^{t}\), and \(\mathcal{K}_{f}^{t+1}=\mathcal{K}_{f}^{t}\) for \(f\neq\widehat{f}^{t}\). By the induction hypothesis, we only need to prove \(\left|\widehat{\tau}_{\widehat{f}^{t}}^{t+1}(u)-\tau_{\widehat{f}^{t}}^{*}(u) \right|\leq 2\epsilon\). Recall that

\[\widehat{\tau}_{\widehat{f}^{t}}^{t+1}(u)=\operatorname{clip}\bigl{(}u\cdot \frac{c_{\widehat{f}^{t}}^{t}-\hat{c}_{\widehat{f}^{t}}^{t}}{y_{f}^{t}-\hat{y }_{\widehat{f}^{t}}^{t}},\widehat{\tau}_{\widehat{f}^{t}}^{t}([y_{\widehat{f} ^{t}}^{t}]^{-}_{\mathcal{K}_{f}^{t}}),\widehat{\tau}_{\widehat{f}^{t}}^{t}([y_ {\widehat{f}^{t}}^{t}]^{+}_{\mathcal{K}_{f}^{t}}\bigcup\{1\})\bigr{)}.\]

Then we have the following three cases. For simplicity we replace \(\widehat{f}^{t}\) with \(f\).

(1) \(\widehat{\tau}_{f}^{t+1}(u)=u\cdot\frac{c_{f}^{t}-\hat{c}_{f}^{t}}{y_{f}^{t}- \hat{y}_{f}^{t}}\). By Lemma 11 and Lemma 6, we have

\[\left|\widehat{\tau}_{f}^{t+1}(u)-\tau_{f}^{*}(u)\right|=\left|u\frac{c_{f}^{t }-\hat{c}_{f}^{t}}{y_{f}^{t}-\hat{y}_{f}^{t}}-wc_{f}^{\prime}(u)\right|\leq\epsilon.\]

(2) \(\widehat{\tau}_{f}^{t+1}(u)=\widehat{\tau}_{f}^{t}([y_{f}^{t}]^{-}_{\mathcal{ K}_{f}^{t}})\) and \(u\cdot\frac{c_{f}^{t}-\hat{c}_{f}^{t}}{y_{f}^{t}-\hat{y}_{f}^{t}}\leq\widehat{ \tau}_{f}^{t}([y_{f}^{t}]^{-}_{\mathcal{K}_{f}^{t}})\). Then we have

\[\widehat{\tau}_{f}^{t+1}(u)=\widehat{\tau}_{f}^{t}([y_{f}^{t}]^{-}_{\mathcal{ K}_{f}^{t}})\leq\tau_{f}^{*}([y_{f}^{t}]^{-}_{\mathcal{K}_{f}^{t}})+ \epsilon\leq\tau_{f}^{*}(u)+\epsilon,\]

where the first inequality is from the induction hypothesis as \([y_{f}^{t}]^{-}_{\mathcal{K}_{f}^{t}}\in\mathcal{K}_{f}^{t}\) and the second inequality is from Assumption 2. In addition, we have

\[\widehat{\tau}_{f}^{t+1}(u)\geq u\cdot\frac{c_{f}^{t}-\hat{c}_{f}^{t}}{y_{f}^{ t}-\hat{y}_{f}^{t}}\gequc_{f}^{\prime}(u)-\epsilon=\tau_{f}^{*}(u)-\epsilon.\]

(3) \(\widehat{\tau}_{f}^{t+1}(u)=\widehat{\tau}_{f}^{t}([y_{f}^{t}]^{+}_{\mathcal{ K}_{f}^{t}\bigcup\{1\}})\) and \(u\cdot\frac{c_{f}^{t}-\hat{c}_{f}^{t}}{y_{f}^{t}-\hat{y}_{f}^{t}}\geq\widehat{ \tau}_{f}^{t}([y_{f}^{t}]^{+}_{\mathcal{K}_{f}^{t}\bigcup\{1\}})\). Then we have

\[\widehat{\tau}_{f}^{t+1}(u)\leq u\frac{c_{f}^{t}-\hat{c}_{f}^{t}}{y_{f}^{t}- \hat{y}_{f}^{t}}\lequc_{f}^{\prime}(u)+\epsilon\leq\tau_{f}^{*}(u)+\epsilon.\]

If \([y_{f}^{t}]^{+}_{\mathcal{K}_{f}^{t}\bigcup\{1\}}\in\mathcal{K}_{f}^{t}\), then we have

\[\widehat{\tau}_{f}^{t}(u)=\widehat{\tau}_{f}^{t}([y_{f}^{t}]^{+}_{\mathcal{K}_{f} ^{t}\bigcup\{1\}})\geq\tau_{f}^{*}([y_{f}^{t}]^{+}_{\mathcal{K}_{f}^{t}\bigcup \{1\}})-\epsilon\geq\tau_{f}^{*}(u)-\epsilon.\]If \([y_{f}^{t}]_{\mathcal{K}_{f}^{t}\bigcup\{1\}}^{+}=1\) and \(1\notin\mathcal{K}_{f}^{t}\), we still have

\[\widehat{\tau}_{f}^{t}(u)=\beta\geq uc_{f}^{\prime}(u)=\tau_{f}^{*}(u).\]

For each of these three cases, the induction holds.

As \(\tau_{f}^{t}(u)=\widehat{\tau}_{f}^{t}(u)+\epsilon u\) for all \(f\in\mathcal{F}\) and \(u\in[0,1]\), we have \(\left|\tau_{f}^{t}(u)-\tau_{f}^{*}(u)\right|\leq 2\epsilon\). 

**Lemma 8**.: _For round \(t\), if facility \(f\) is known, then we have \(\left|\tau_{f}^{t}(y_{f}^{t})-\tau_{f}^{*}(y_{f}^{t})\right|\leq 3\epsilon\)._

Proof.: If \(y_{f}^{t}\in\mathcal{K}_{f}^{t}\), we can directly apply Lemma 7. Otherwise, we set \(u_{1}=[y_{f}^{t}]_{\mathcal{L}}^{-}\) and \(u_{2}=[y_{f}^{t}]_{\mathcal{L}}^{+}\). Then we have \(u_{1}<y_{f}^{t}<u_{2}\) and \(u_{1},u_{2}\in\mathcal{K}_{f}^{t}\). There exists \(\lambda_{1}\in[0,1],\lambda_{1}+\lambda_{2}=1\) such that \(y_{f}^{t}=\lambda_{1}u_{1}+\lambda_{2}u_{2}\). By Lemma 6, we have \(\left|\tau_{f}^{t}(u_{i})-\tau_{f}^{*}(u_{i})\right|\leq 2\epsilon\) for \(i\in\{1,2\}\). Then we have

\[\left|\tau_{f}^{t}(y_{f}^{t})-\tau_{f}(y_{f}^{t})\right|\] \[= \left|\lambda_{1}\tau_{f}^{t}(u_{1})+\lambda_{2}\tau_{f}^{t}(u_{2 })-(\lambda_{1}u_{1}+\lambda_{2}u_{2})c_{f}^{\prime}(u)\right|\] \[\leq \left|\lambda_{1}\tau_{f}^{t}(u_{1})-\lambda_{1}u_{1}c_{f}^{ \prime}(u)\right|+\left|\lambda_{2}\tau_{f}^{t}(u_{2})-\lambda_{2}u_{2}c_{f}^{ \prime}(u)\right|\] \[\leq \lambda_{1}\left|\tau_{f}^{t}(u_{1})-\tau_{f}^{*}(u_{1})\right|+ \lambda_{1}u_{1}\left|c_{f}^{\prime}(u_{1})-c_{f}^{\prime}(u)\right|+\lambda_ {2}\left|\tau_{f}^{t}(u_{2})-\tau_{f}^{*}(u_{2})\right|+\lambda_{2}u_{2}\left| c_{f}^{\prime}(u_{2})-c_{f}^{\prime}(u)\right|\] \[\leq 2\lambda_{1}\epsilon+\lambda_{1}\epsilon+2\lambda_{2} \epsilon+\lambda_{2}\epsilon\] (Lemma 6, \(\beta\)-smoothness and \(|u-u_{i}|\leq\epsilon/\beta\).) \[\leq 3\epsilon.\]

**Lemma 9**.: _If Algorithm 2 return \(\operatorname{False}\) at round \(t\), then for any \(\widetilde{\tau}\in\mathbb{R}^{F}\) such that \(\widetilde{\tau}_{f}=\tau_{f}^{t}(y_{f})\) for \(f\in\mathcal{F}\backslash\bar{\mathcal{F}}^{t}\) and \(\widetilde{\tau}_{f}\in[l_{f}^{t},r_{f}^{t}]\) for \(f\in\bar{\mathcal{F}}^{t}\), we have \(\operatorname{Gap}_{i}(x^{t},c^{t}+\widetilde{\tau})\geq 0\) for all \(i\in[m]\). In addition, \(x^{t}\) is a Nash equilibrium for tax \(\widetilde{\tau}\)._

Proof.: For simplicity, we will omit \(t\) when there is no confusion. Algorithm 2 return \(\operatorname{False}\) if and only if for all \(i\in[m]\) and tax \(\bar{\tau}_{i}:\bar{\tau}_{\bar{F}_{i}}=r_{\bar{F}_{i}},\bar{\tau}_{\bar{F}_{i} ^{\prime}}=l_{\bar{F}_{i}^{\prime}},\bar{\tau}_{F\backslash\left(\bar{F}_{i} \bigcup\bar{F}_{i}^{\prime}\right)}=\tau_{F\backslash\left(\bar{F}_{i} \bigcup\bar{F}_{i}^{\prime}\right)}\), we have

\[\operatorname{Gap}_{i}(x,c+\bar{\tau})=\min_{a:x_{i,a}=0}\sum_{f:f\in a}(c_{f} +\bar{\tau}_{f})-\max_{a:x_{i,a}\neq 0}\sum_{f:f\in a}(c_{f}+\bar{\tau}_{f})\geq 0.\]

By the definition of \(\bar{F}_{i}\), for any \(f\in\bar{F}_{i}\) and \(a:x_{i,a}\neq 0\), we have \(f\in a\). Similarly, for any \(f\in\bar{F}_{i}^{\prime}\) and \(a:x_{i,a}\neq 0\), we have \(f\notin a\). Thus for any \(a:x_{i,a}\neq 0\), we have

\[\sum_{f:f\in a}(c_{f}+\bar{\tau}_{f})-\sum_{f:f\in a}(c_{f}+\widetilde{\tau}_{f })=\sum_{f\in\bar{F}_{i}}(r_{f}-\widetilde{\tau}_{f})\geq 0.\]

For any \(a:x_{i,a}=0\), we have

\[\sum_{f:f\in a}(c_{f}+\bar{\tau}_{f})-\sum_{f:f\in a}(c_{f}+\widetilde{\tau}_{f })=\sum_{f\in\bar{F}_{i}^{\prime}\bigcap a}(l_{f}-\widetilde{\tau}_{f})\leq 0.\]

As a result, we have

\[\operatorname{Gap}_{i}(x^{t},c^{t}+\widetilde{\tau}) =\min_{a:x_{i,a}=0}\sum_{f:f\in a}(c_{f}+\widetilde{\tau}_{f})- \max_{a:x_{i,a}\neq 0}\sum_{f:f\in a}(c_{f}+\widetilde{\tau}_{f})\] \[\geq\min_{a:x_{i,a}=0}\sum_{f:f\in a}(c_{f}+\bar{\tau}_{f})-\max_{a: x_{i,a}\neq 0}\sum_{f:f\in a}(c_{f}+\bar{\tau}_{f})\geq 0.\]

To prove that \(x^{t}\) is Nash equilibrium for tax \(\widetilde{\tau}\), we only need to show that for in-support actions \(a:x_{i,a}^{t}\neq 0\), the action costs \(\sum_{f:f\in a}(c_{f}^{t}+\widetilde{\tau}_{f})\) are the same. This can be derived by

\[\sum_{f:f\in a}(c_{f}^{t}+\tau_{f}^{t})-\sum_{f:f\in a}(c_{f}^{t}+\widetilde{ \tau}_{f})=\sum_{f\in\bar{F}_{i}}(\tau_{f}^{t}-\widetilde{\tau}_{f}),\forall a:x_{i,a }^{t}\neq 0,\]

which is independent of \(a\). As \(x^{t}\) is Nash equilibrium for tax \(\tau^{t}\), \(\sum_{f:f\in a}(c_{f}^{t}+\tau_{f}^{t})\) is also independent of \(a\).

**Lemma 10**.: _If Algorithm 2 return \(\operatorname{False}\) at round \(t\), then tax \(\tau^{t}\) is an \(6F\epsilon\)-optimal tax._

Proof.: For known facility \(f\), by Lemma 8, we have \(\left|\tau_{f}^{*}(y_{f}^{t})-\tau_{f}^{t}(y_{f}^{t})\right|\leq 3\epsilon\). By Lemma 7, for any \(u\in\mathcal{K}_{f}^{t}\), we have \(\left|\tau_{f}^{*}(u)-\tau_{f}^{t}(u)\right|\leq 2\epsilon\). Thus for unknown facility \(f\), we have

\[l_{f}^{t}=\tau_{f}^{t}([y_{f}^{t}]_{\mathcal{K}_{f}^{t}}^{-})+\epsilon\cdot(y _{f}^{t}-[y_{f}^{t}]_{\mathcal{K}_{f}^{t}}^{-})\leq\tau_{f}^{*}([y_{f}^{t}]_{ \mathcal{K}_{f}^{t}}^{-})+2\epsilon+\epsilon=\tau_{f}^{*}([y_{f}^{t}]_{ \mathcal{K}_{f}^{t}}^{-})+3\epsilon,\]

\[r_{f}^{t}=\tau_{f}^{t}([y_{f}^{t}]_{\mathcal{K}_{f}^{t}\bigcup\{1\}}^{+})+ \epsilon\cdot(y_{f}^{t}-[y_{f}^{t}]_{\mathcal{K}_{f}^{t}\bigcup\{1\}}^{+}) \geq\tau_{f}^{*}([y_{f}^{t}]_{\mathcal{K}_{f}^{t}\bigcup\{1\}}^{+})-2\epsilon -\epsilon=\tau_{f}^{*}([y_{f}^{t}]_{\mathcal{K}_{f}^{t}\bigcup\{1\}}^{+})-3\epsilon,\]

As \(\tau_{f}^{*}\) is nondecreasing (Assumption 2), we have

\[l_{f}^{t}-3\epsilon\leq\tau_{f}^{*}([y_{f}^{t}]_{\mathcal{K}_{f}^{t}}^{-}) \leq\tau_{f}^{*}(y_{f}^{t})\leq\tau_{f}^{*}([y_{f}^{t}]_{\mathcal{K}_{f}^{t} \bigcup\{1\}}^{+})\leq r_{f}^{t}+3\epsilon.\]

Thus there exists tax \(\widetilde{\tau}^{t}\) such that \(\widetilde{\tau}_{f}^{t}(y_{f}^{t})\) satisfies the condition of Lemma 9 and \(\left|\tau_{f}^{*}(y_{f}^{t})-\widetilde{\tau}_{f}^{t}(y_{f}^{t})\right|\leq 3\epsilon\) for all \(f\in\mathcal{F}\). \(x^{t}\) is the Nash equilibrium for tax \(\widetilde{\tau}^{t}\), we have

\[\forall i\in[m],a,a^{\prime}\in\mathcal{A}_{i},\sum_{f\in a}c_{f}(y_{f}^{t})+ \widetilde{\tau}_{f}^{t}(y_{f}^{t})\leq\sum_{f\in a^{\prime}}c_{f}(y_{f}^{t}) +\widetilde{\tau}_{f}^{t}(y_{f}^{t}),\;\text{if}\;x_{i,a}^{t}>0.\]

Thus we have

\[\forall i\in[m],a,a^{\prime}\in\mathcal{A}_{i},\sum_{f\in a}c_{f}(y_{f}^{t}) +\tau_{f}^{*}(y_{f}^{t})\leq\sum_{f\in a^{\prime}}c_{f}(y_{f}^{t})+\tau_{f}^{ *}(y_{f}^{t})+6F\epsilon,\;\text{if}\;x_{i,a}^{t}>0.\]

By Lemma 4, \(\Psi(y_{f}^{t})-\min_{y\in\mathcal{Y}}\Psi(y)\leq 6F\epsilon\). 

**Lemma 11**.: _If Algorithm 2 output \(\widetilde{\tau}^{t},\widetilde{f}^{t},\operatorname{sign}^{t}\) at round \(t\), then we have_

\[0<\left|y_{\widetilde{f}^{t}}^{t}-\dot{y}_{\widetilde{f}^{t}}^{t}\right|\leq\Delta.\]

Proof.: First, we prove \(\left|y_{\widetilde{f}^{t}}^{t}-\dot{y}_{\widetilde{f}^{t}}^{t}\right|>0\). We consider the following two cases.

(1) Algorithm 2 return at Line 5. As we have \(0<y_{i}(\widetilde{f}^{t})<w_{i}\), there exists \(a,a^{\prime}\in\mathcal{A}_{i}\) such that \(x_{i,a}>0,x_{i,a^{\prime}}>0\) and \(\widetilde{f}^{t}\in a,\widetilde{f}^{t}\notin a^{\prime}\). Suppose \(y_{\widetilde{f}^{t}}^{t}=\dot{y}_{\widetilde{f}^{t}}^{t}\). Then by Lemma 3, we have \(y^{t}=\dot{y}^{t}\) as \(\tau^{t}\) and \(\dot{\tau}^{t}\) only differ in facility \(\widetilde{f}^{t}\). As a result, \(x^{t}\) is Nash equilibrium for tax \(\dot{\tau}^{t}\). However, \(x^{t}\) is the Nash equilibrium for tax \(\tau_{f}^{t}\) implies

\[\sum_{f\in a}c_{f}(y_{f}^{t})+\tau_{f}^{t}(y_{f}^{t})=\sum_{f\in a^{\prime}}c_{ f}(y_{f}^{t})+\tau_{f}^{t}(y_{f}^{t}).\]

As \(\tau^{t}\) and \(\dot{\tau}^{t}\) only differ in facility \(\widetilde{f}^{t}\) and \(\widetilde{f}^{t}\in a,\widetilde{f}^{t}\notin a^{\prime}\), we have

\[\sum_{f\in a}c_{f}(y_{f}^{t})+\dot{\tau}_{f}^{t}(y_{f}^{t})\neq\sum_{f\in a^{ \prime}}c_{f}(y_{f}^{t})+\dot{\tau}_{f}^{t}(y_{f}^{t}),\]

which means \(x^{t}\) is not the Nash equilibrium for tax \(\dot{\tau}\). By contradiction, we have \(y_{\widetilde{f}^{t}}^{t}=\dot{y}_{\widetilde{f}^{t}}^{t}\).

(2) Algorithm 2 return \(\widetilde{\tau}^{u},\widetilde{f},\operatorname{sign}\) at Line 23 or Line 31. As there exists \(j\in[m]\) such that \(\operatorname{Gap}_{j}(x,c+\widetilde{\tau}^{u+\operatorname{sign}\epsilon})<0\), \(x\) is not a Nash equilibrium under tax \(\dot{\tau}^{t}\). Let \(\tilde{\tau}^{t}:\tilde{\tau}_{f}^{t}=\tau_{f}^{t}\bigcup(y_{f}^{t}, \widetilde{\tau}_{f}^{u})\) for \(f\in\mathcal{F}\). Then \(\dot{\tau}^{t}\) and \(\tilde{\tau}^{t}\) only differs in \(\widetilde{f}\) and \(x\) is the Nash equilibrium under tax \(\dot{\tau}^{t}\). By applying Lemma 3 with \(\dot{\tau}^{t}\) and \(\tilde{\tau}^{u}\), we have \(y_{\widetilde{f}^{t}}^{t}=\dot{y}_{\widetilde{f}^{t}}^{t}\).

Second, we prove \(\left|y_{f_{f}^{t}}^{t}-\dot{y}_{\widetilde{f}^{t}_{i}}^{t}\right|\leq\Delta\). (1) Algorithm 2 return at Line 5. Suppose we have \(\left|y_{f}^{t}-\dot{y}_{f}^{t}\right|>\Delta\). By the tax design, the (sub)gradient of the tax \((\tau_{f}^{t})^{\prime}(u)\geq\epsilon\) for \(u\in[0,1]\). As a result, \(\Phi(y,c+\tau^{t})\) is \(\epsilon\)-strongly convex by Lemma 2. As \(y^{t}=\operatorname{argmin}_{y\in\mathcal{Y}}\Phi(y;c+\tau^{t})\), we have

\[\Phi(\dot{y}^{t};c+\tau^{t})-\Phi(y^{t};c+\tau^{t})>\epsilon\Delta^{2}/2.\]However, we have \(\left|\Phi(y;c+\tau^{t})-\Phi(y;c+\hat{\tau}^{t})\right|\leq\delta\) for all \(y\in\mathcal{Y}\). Thus we have

\[\Phi(\dot{y}^{t};c+\hat{\tau}^{t})-\delta\leq\Phi(y^{t};c+\hat{\tau}^{t})-\delta /2\leq\Phi(y^{t};c+\tau^{t})\leq\Phi(\dot{y}^{t};c+\tau^{t})\leq\Phi(\dot{y}^{ t};c+\hat{\tau}^{t})+\delta.\]

Comparing to the inequality above, we have \(2\delta>\epsilon\Delta^{2}/2\), which is incorrect by the definition of \(\delta\). By contradiction, we have \(\left|y_{f}^{t}-\dot{y}_{f}^{t}\right|\leq\Delta\).

(2) Algorithm 2 return \(\widetilde{\tau}^{u},\widetilde{f},\mathrm{sign}\) at Line 23 or Line 31. Let \(\widetilde{\tau}^{t}:\widetilde{\tau}_{f}^{t}=\tau_{f}^{t}\bigcup(y_{f}^{t}, \widetilde{\tau}_{f}^{u})\) for \(f\in\mathcal{F}\). Then \(x\) is the Nash equilibrium under tax \(\widetilde{\tau}^{t}\). Let \(\widetilde{\tau}:\widetilde{\tau}_{f}^{t}=\tau_{f}^{t}\bigcup(y_{f}^{t}, \widetilde{\tau}_{f})\) for all \(f\in\mathcal{F}\). By the definition of \(\widetilde{\tau}^{t}\) and the feasible range \(\widetilde{\tau}_{f}\in[l_{f},r_{f}]\), the subgradient of \(\widetilde{\tau}_{f}^{t}\) is lower bounded by \(\epsilon\). As a result, \(\Phi(\cdot;c+\tilde{\tau}^{t})\) is \(\epsilon\)-strongly convex on \([0,1]\). We can prove \(\left|y_{f}^{t}-\dot{y}_{f}^{t}\right|\leq\Delta\) by following the analysis for case (1) and replacing \(\tau^{t}\) with \(\widetilde{\tau}^{t}\).

**Proposition 1**.: _If Algorithm 2 return \(\mathrm{False}\) at round \(t\), then tax \(\tau^{t}\) is an \(6\epsilon F\)-optimal tax. If Algorithm 2 output \(\widetilde{\tau}^{t},\widetilde{f}^{t},\mathrm{sign}^{t}\) at round \(t\), then we have_

\[0<\left|y_{\widetilde{f}^{t}}^{t}-\dot{y}_{\widetilde{f}^{t}}^{t}\right|\leq\Delta.\]

Proof.: This is directly from Lemma 10 and Lemma 11. 

**Lemma 12**.: _Algorithm 1 return \(\mathrm{False}\) in at most \(KF\) rounds._

Proof.: By Lemma 11 and the update rule (1), if Algorithm 2 return \(\widetilde{\tau}^{t},f,\mathrm{sign}\) at round \(t\), then we will have one more known point, i.e., \(\sum_{f\in\mathcal{F}}\mathcal{K}_{f}^{t+1}=\sum_{f\in\mathcal{F}}\mathcal{K} _{f}^{t}+1\). As \(\mathcal{K}_{f}^{t}\subseteq\mathcal{L}\) for all \(f\in\mathcal{F}\) and \(|\mathcal{L}|=K+1\), we proved the lemma.

**Theorem 1**.: _Under Assumption 1 and Assumption 2, Algorithm 1 will output a \(6\epsilon F\) tax within \(T\leq 2F\beta/\epsilon\) rounds. In addition, each round has at most two tax realizations._

Proof.: The proof is directly from Proposition 1 and Lemma 12. 

## Appendix C Computation Complexity

In this section, we discuss the computation complexity of Algorithm 1 and Algorithm 2. We will show that these two algorithms can be implemented with \(\widetilde{O}(\mathrm{poly}(A,F,m))\) complexity for each round. For network congestion games, the computation complexity can be sharpened to \(\widetilde{O}(\mathrm{poly}(V,E,m))\), avoiding the dependence on \(A\) that can be exponential in \(V\) and \(E\).

### General Congestion Games

For Algorithm 1, we compute/update the value of the cost/tax function for each facility. As we use the dictionary data structure, computing value and updating value only have \(O(\log K)=O(\log\beta/\epsilon)\) complexity. As a result, the complexity of one round in Algorithm 1 is \(\widetilde{O}(F)\).

For Algorithm 2, \(x\in\phi^{-1}(y)\) is a Caratheodory decomposition problem and can be formulated as a linear program with \(A\) variables, \(F+m\) equation constraints and \(A\) inequality constraints (Proposition 2), which can be solved in polynomial time [Cohen et al., 2021].

The bottleneck is in computing \(u=\operatorname*{argmax}_{u}\{u:\mathrm{Gap}_{j}(x,c+\widetilde{\tau}^{u})\geq 0,\forall j\in[m]\}\) for \(\widetilde{\tau}^{u}:\widetilde{\tau}_{f}^{u}=u,\widetilde{\tau}_{\mathcal{F} \setminus\{f\}}^{u}=\tau_{\mathcal{F}\setminus\{f\}}^{\prime}\), \(f\in\bar{F}_{i}\). For simplicity, we use the notation: \(\widetilde{c}^{u}=c+\widetilde{\tau}^{u}\) as the cost with tax \(\widetilde{\tau}^{u}\). By Definition 5 and the definition of action cost, we have

\[\mathrm{Gap}_{j}(x,c+\widetilde{\tau}^{u})=\min_{a:x_{j,a}=0}\widetilde{c}_{a }^{u}-\max_{a:x_{j,a}\neq 0}\widetilde{c}_{a}^{u}.\] (4)For action cost \(\widetilde{c}^{u}_{a}\), if \(f\in a\), it is a linear function w.r.t. \(u\) in the form of \(u+C\) for some constant \(C\). Otherwise, it is a constant w.r.t. \(u\). As a result, we can determine the function \(\widetilde{c}^{u}_{a}\) with \(O(F)\) computation as we only need to compute \(\widetilde{c}^{\gamma^{\prime}}_{a}\) to decide the constant. Then we can compute \(\operatorname{Gap}_{j}(x,c+\widetilde{\tau}^{u})\) in closed form and compute \(u_{j}=\operatorname{argmax}_{u}\{u:\operatorname{Gap}_{j}(x,c+\widetilde{ \tau}^{u})\geq 0\}\) with \(O(AF)\) complexity. Finally, \(u=\min_{j\in[m]}u_{j}\) can be computed with \(\mathcal{O}(mAF)\) complexity. Similarly, \(u=\operatorname{argmin}_{u}\{u:\operatorname{Gap}_{j}(x,c+\widetilde{\tau}^{u} )\geq 0,\forall j\in[m]\}\) has \(\widetilde{O}(mAF)\) computation complexity.

### Network Congestion Games

For network congestion games, Algorithm 2 can be implemented by applying shortest path algorithms on a modified network, thus avoiding the dependence on \(A\). We will apply Dijkstra's algorithm with \(\widetilde{O}(V+E)\) complexity while other shortest path algorithms can be used as well.

First, the Caratheodory decomposition \(x\in\phi^{-1}(y)\) can be done efficiently with \(O(VE+E^{2})\) steps similar to the decomposition algorithm in [Panageas et al., 2023]. While their algorithm is for the flow polytopes with one commodity, it can be directly generalized to the multi-commodity case. We defer the algorithm and analysis to Appendix D.

For \(u=\operatorname{argmax}_{u}\{u:\operatorname{Gap}_{j}(x,c+\widetilde{\tau}^{ u})\geq 0,\forall j\in[m]\}\), the computation complexity can be boosted to \(\widetilde{O}(m(E+V))\). To achieve this, we consider how (4) changes as \(u\) increases from \(\tau^{\prime}_{f}\) to \(r_{f}\). By Algorithm 2, we have \(\operatorname{Gap}_{j}(x,c+\widetilde{\tau}^{u})\geq 0\) when \(u=\tau^{\prime}_{f}\) as otherwise the algorithm ends at the previous iteration. In addition, facility \(f\) either has none of the Nash load or has all of the Nash load for facility \(j\) according to the algorithm design. For the first case, the in-support action costs will not change as \(u\) increases. \(\operatorname{Gap}_{j}(x,c+\widetilde{\tau}^{u})\geq 0\) always holds as the off-support action costs are nondecreasing w.r.t. \(u\).

For the second case (all in-support actions use \(f\)), the in-support action costs take the form of \(u+C\) and \(C\) can be determined by applying shortest path algorithm with edge weight \(c+\widetilde{\tau}^{r_{f}}\). For off-support action cost, we observe that

\[\min_{a:x_{j,a}=0}\widetilde{c}^{u}_{a}=\min\bigl{\{}\min_{a:x_{j,a}=0,f\in a }\widetilde{c}^{u}_{a},\min_{a:x_{j,a}=0,f\notin a}\widetilde{c}^{u}_{a} \bigr{\}}=\min\bigl{\{}\min_{a:x_{j,a}=0,f\in a}\widetilde{c}^{u}_{a},\min_{a: f\notin a}\widetilde{c}^{\tau^{\prime}_{f}}_{a}\bigr{\}},\] (5)

where the second equation is from that the action cost does not depend on \(u\) and \(x_{j,a}=0\) if \(f\notin a\). The first term in (5) grows linearly w.r.t. \(u\) as \(\widetilde{f}\in a\), so it is always larger than the in-support action cost. The second term in (5) is the shortest path length for commodity \(j\) that does not use facility \(f\), which can be computed as the shortest path in the network after removing edge \(f\). As a result, \(u_{j}=\operatorname{argmax}_{u}\{u:\operatorname{Gap}_{j}(x,c+\widetilde{ \tau}^{u})\geq 0\}\) can be computed with \(O(E+V)\) complexity. Then the complexity for computing \(u=\min_{j\in[m]}u_{j}\) is \(\widetilde{O}(m(E+V))\).

Similarly, \(u_{j}=\operatorname{argmin}_{u}\{u:\operatorname{Gap}_{j}(x,c+\widetilde{ \tau}^{u})\geq 0\}\) can be reduced to solving the shortest path that must use edge \(f\) in the network. We consider how (4) changes as \(u\) decreases from \(\tau_{f}\) to \(l_{f}\). Initially, the gap is nonnegative. If \(f\) has all of the Nash load, then the in-support action cost is a linear function \(u+C\) and it decreases at least as fast as the first term. As a result, the gap is always nonnegative. Otherwise, \(f\) has none of the Nash load and in-support action costs remain constant.

We notice the following equation:

\[\min_{a:x_{j,a}=0}\widetilde{c}^{u}_{a}=\min\bigl{\{}\min_{a:x_{j,a}=0,f\in a} \widetilde{c}^{u}_{a},\min_{a:x_{j,a}=0,f\notin a}\widetilde{c}^{u}_{a} \bigr{\}}=\min\bigl{\{}\min_{a:f\in a}\widetilde{c}^{u}_{a},\min_{a:x_{j,a},f \notin a}\widetilde{c}^{\tau^{\prime}_{f}}_{a}\bigr{\}},\] (6)

where the second equation is from that \(f\in a\) implies \(a\) is off-support (\(x_{j,a}=0\)) and \(f\notin a\) implies \(\widetilde{c}^{u}_{a}\) is independent of \(u\). The second term in (6) is a constant and is always greater than the in-support action cost. The first term in (6) is a linear function \(u\) and it can be determined by computing the shortest path that always uses \(\widetilde{f}\) and with edge weights \(c+\widetilde{\tau}^{\tau_{f}}\). This subproblem can be solved by applying the shortest path algorithm twice: the first one is to connect the source node and the starting node of \(\widetilde{f}\), and the second one is to connect the end node of \(\widetilde{f}\) and the target node. As a result, the complexity for \(u=\max_{j\in[m]}u_{j}\) is \(\widetilde{O}(m(E+V))\) as well. Thus the computation complexity for Algorithm 2 in network congestion games is \(O(VE+E^{2}+mV+mE)\).

Missing Proofs in Section C

**Proposition 2**.: _Finding \(x\in\phi^{-1}(y)\) can be formulated as the following linear program._

\[\min_{x\in\mathbb{R}^{A}}1\] _s.t._ \[y=\sum_{i\in[m]}\sum_{a_{i}\in\mathcal{A}_{i}}x_{i,a_{i}}a_{i}\] \[w_{i}=\sum_{a_{i}\in\mathcal{A}_{i}}x_{i,a_{i}},\forall i\in[m]\] \[x_{i,a_{i}}\geq 0,\forall i\in[m],a_{i}\in\mathcal{A}_{i}\]

Proof.: The second and third constraints guarantees \(x\) is a feasible strategy. The first constraint indicates \(y=\phi(x)\). As a result, any feasible point of the program is a solution of \(\phi^{-1}(y)\). 

```
1:Input: A load \(y\in\mathcal{Y}\).
2:\(x_{i,a}=0\) for all \(i\in[m]\) and \(a\in\mathcal{A}_{i}\).
3:while\(\exists f:y_{f}>0\)do
4: Let \(A=\{f:y_{f}>0\}\).
5: Let \(f_{\min}=\operatorname*{argmin}_{f\in A}y_{f}\) and \(y_{\min}=\min_{f\in A}y_{f}\).
6: Let \(a\) be a \((s_{i},t_{i})\) path of network \(G(V,A)\) with \(f_{\min}\in p\).
7: Let \(x_{i,a}=y_{\min}\), \(y_{f}=y_{f}-y_{\min}\) if \(f\in a\).
8:endwhile ```

**Algorithm 3** Efficient Computation of Flow Decomposition (Modified from [Panageas et al., 2023])

**Proposition 3**.: _Algorithm 3 can output a Caratheodory decomposition of \(y\) within \(E\) steps._

Proof.: During the algorithm, load \(y\) will always be nonnegative: \(y_{f}\geq 0,\forall f\in\mathcal{F}\). For each round, we will have \(y_{f_{min}}\) reduced to 0. As a result, the algorithm will end within at most \(E\) rounds.

We only need to prove that path \(a\) always exists in Line (6) for each round. First, \(y\) always remains a multi-commodity flow as Line (7) will not affect the law of conservation in the network. By flow decomposition theorem, there exists simple paths \(a_{1},a_{2},\cdots,a_{p}\) such that

\[y=\sum_{i\in[p]}w_{i}a_{i},\]

where \(w_{i}>0\) are positive flow weights. As \(y_{f_{\min}}>0\), there exists \(a_{i}\) such that \(f_{\min}\in a_{i}\). Then for any \(f\in a_{i}\), \(y_{f}\geq w_{i}>0\). As a result, path \(a\) exists for Line (6). 

## Appendix E Experiments

We implemented our algorithm and conducted experiments on a classic example known as the nonlinear variant of Pigou's example [Nisan et al., 2007]. Concretely, nonlinear variant of Pigou's example is a routing game with one source node \(s\) and one target node \(t\). There are two edges connecting \(s\) and \(t\). One edge has constant cost \(c_{0}(x)=c,\forall x\in[0,1]\) for some \(c\in[0,1]\), and the other edge has polynomial cost \(c_{1}(x)=x^{p}\). One important property of such games is the price of anarchy grows without bound as \(p\to\infty\), which urges proper tax to induce socially optimal behavior.

We apply our algorithm to learn the optimal tax with different \(c_{0}\) and \(p\). As we can see, the social welfare quickly converges to the optimal one. Another important observation is the learned tax function does not uniformly converge to the marginal cost tax, which is reasonable as accurate estimate is only necessary around the Nash equilibrium induced by the tax.

Figure 1: Social Welfare Curves of the Algorithm for various values of \(c\) and \(p\). We can observe that the social welfare converges to the optimal one quickly.

Figure 2: Estimated Tax Functions at the Last Iteration for various values of \(c\) and \(p\). The estimation is not uniformly accurate but they are accurate at the induced Nash equilibrium.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The abstract and introduction accurately reflect the paper's contribution. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discussed the limitations of our assumptions and algorithms. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: We provide the proof in the appendix.

Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: Our experiment is a direct implementation of our algorithm on a well-known task and can be reproduced. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [No]

Justification:

Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Our experiment is a direct implementation of our algorithm on a well-known task and can be reproduced. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: Our experiments are deterministic. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors).

* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: Our experiment require minimal computation resources. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: Our research can be potentially applied to real-world tax design. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: We did not use public dataset. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.