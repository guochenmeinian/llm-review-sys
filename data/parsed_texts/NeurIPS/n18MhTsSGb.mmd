# 2Direction: Theoretically Faster Distributed Training with Bidirectional Communication Compression

 Alexander Tyurin

KAUST

Saudi Arabia

alexandertiurin@gmail.com &Peter Richtarik

KAUST

Saudi Arabia

richtarik@gmail.com

###### Abstract

We consider distributed convex optimization problems in the regime when the communication between the server and the workers is expensive in both uplink and downlink directions. We develop a new and provably accelerated method, which we call 2Direction, based on fast bidirectional compressed communication and a new bespoke error-feedback mechanism which may be of independent interest. Indeed, we find that the EF and EF21-P mechanisms (Seide et al., 2014; Gruntkowska et al., 2023) that have considerable success in the design of efficient non-accelerated methods are not appropriate for accelerated methods. In particular, we prove that 2Direction improves the previous state-of-the-art communication complexity \(\widetilde{\Theta}\left(K\times\left(\nicefrac{{L}}{{\alpha\mu}}+\nicefrac{{L_{ \max}\omega}}{{n\mu}}+\omega\right)\right)\)(Gruntkowska et al., 2023) to \(\widetilde{\Theta}(K\times\left(\nicefrac{{L(\omega+1)}}{{\alpha\mu}}+ \nicefrac{{\sqrt{L_{\max}\omega^{2}}}}{{n\mu}}+\nicefrac{{1}}{{\alpha}}+ \omega\right))\) in the \(\mu\)-strongly-convex setting, where \(L\) and \(L_{\max}\) are smoothness constants, \(n\) is # of workers, \(\omega\) and \(\alpha\) are compression errors of the Rand\(K\) and Top\(K\) sparsifiers (as examples), \(K\) is # of coordinates/bits that the server and workers send to each other. Moreover, our method is the first that improves upon the communication complexity of the vanilla accelerated gradient descent (AGD) method (Nesterov, 2018). We obtain similar improvements in the general convex regime as well. Finally, our theoretical findings are corroborated by experimental evidence.

## 1 Introduction

We consider convex optimization problems in the centralized distributed setting. These types of problems appear in federated learning (Konecny et al., 2016; McMahan et al., 2017) and distributed optimization (Ramesh et al., 2021). In this setting, one of the main problems is the communication bottleneck: the connection link between the server and the workers can be very slow. We focus our attention on methods that aim to address this issue by applying _lossy compression_ to the communicated messages (Alistarh et al., 2017; Mishchenko et al., 2019; Gruntkowska et al., 2023).

### The problem

Formally, we consider the optimization problem

\[\min_{x\in\mathbb{R}^{d}}\left\{f(x):=\tfrac{1}{n}\sum\limits_{i=1}^{n}f_{i}(x )\right\},\] (1)

where \(n\) is the number of workers and \(f_{i}\,:\,\mathbb{R}^{d}\to\mathbb{R}\) are smooth convex functions for all \(i\in[n]:=\{1,\ldots,n\}\). We consider the _centralized distributed optimization_ setting in which each \(i^{\text{th}}\) worker contains the function \(f_{i},\) and all workers are directly connected to a server (Kairouz et al., 2021). In general, we want to find a (possibly random) point \(\widehat{x}\) such that \(\mathbb{E}\left[f(\widehat{x})\right]-f(x^{*})\leq\varepsilon,\) where \(x^{*}\) isan optimal point. In the strongly convex setup, we also want to guarantee that \(\mathbb{E}[\|\widetilde{x}-x^{*}\|^{2}]\leq\varepsilon\) for some point \(\widetilde{x}\).

Virtually all other theoretical works in this genre assume that, compared to the worker-to-server (w2s) communication cost, the server-to-workers (s2w) broadcast is so fast that it can be ignored. We lift this limitation and instead associate a relative cost \(r\in[0,1]\) with the two directions of communication. If \(r=0\), then s2w communication is free, if \(r=1\), then w2s communication is free, and if \(r=\nicefrac{{1}}{{2}}\), then the s2w and w2s costs are equal. All our theoretical results hold for any \(r\in[0,1]\). We formalize and elaborate upon this setup in Section 2.

### Assumptions

Throughout the paper we rely on several standard assumptions on the functions \(f_{i}\) and \(f\).

**Assumption 1.1**.: Functions \(f_{i}\) are \(L_{i}\)-smooth, i.e., \(\|\nabla f_{i}(x)-\nabla f_{i}(y)\|\leq L_{i}\,\|x-y\|\) for all \(x,y\in\mathbb{R}^{d}\), for all \(i\in[n]\). We let \(L_{\max}:=\max_{i\in[n]}L_{i}\). Further, let \(\widehat{L}>0\) be a constant such that \(\frac{1}{n}\sum_{i=1}^{n}\|\nabla f_{i}(x)-\nabla f_{i}(y)\|^{2}\leq\widehat{ L}^{2}\,\|x-y\|^{2}\) for all \(x,y\in\mathbb{R}^{d}\).

Note that if the functions \(f_{i}\) are \(L_{i}\)-smooth for all \(i\in[n]\), then \(\widehat{L}\leq L_{\max}\).

**Assumption 1.2**.: Function \(f\) is \(L\)-smooth, i.e., \(\|\nabla f(x)-\nabla f(y)\|\leq L\,\|x-y\|\) for all \(x,y\in\mathbb{R}^{d}\).

**Assumption 1.3**.: Functions \(f_{i}\) are convex for all \(i\in[n],\) and \(f\) is \(\mu\)-strongly convex with \(\mu\geq 0\), attaining a minimum at some point \(x^{*}\in\mathbb{R}^{d}\).

It is known that the above smoothness constants are related in the following way.

**Lemma 1.4** (Gruntkowska et al. (2023)).: _If Assumptions 1.2, 1.1 and 1.3 hold, then \(\widehat{L}\leq L_{\max}\leq nL\) and \(L\leq\widehat{L}\leq\sqrt{L_{\max}L}\)._

## 2 Motivation: From Unidirectional to Bidirectional Compression

In this work, we distinguish between worker-to-server (w2s=uplink) and server-to-worker (s2w=downlink) communication cost, and define w2s and s2w communication complexities of methods in the following natural way.

**Definition 2.1**.: For a centralized distributed method \(\mathcal{M}\) aiming to solve problem (1), the communication complexity \(\mathfrak{m}_{\mathcal{M}}^{\times 2}\) is the expected number of coordinates/floats1 that each worker sends to the server to solve problem (1). The quantity \(\mathfrak{m}_{\mathcal{M}}^{\times\mu}\) is the expected number of floats/coordinates the server broadcasts to the workers to solve problem (1). If \(\mathfrak{m}_{\mathcal{M}}^{\times\mu}=\mathfrak{m}_{\mathcal{M}}^{\times\mu},\) then we use the simplified notation \(\mathfrak{m}_{\mathcal{M}}:=\mathfrak{m}_{\mathcal{M}}^{\times\mu}=\mathfrak{ m}_{\mathcal{M}}^{\times\mu}\).

Footnote 1: Some works measure bits instead of coordinates. For computer systems, where coordinates are represented by 32 or 64 bits, these measures are equivalent up to the constant factors 32 or 64.

Let us illustrate the above concepts on the simplest baseline: vanilla gradient descent (GD). It is well known (Nesterov, 2018) that for \(L\)-smooth, \(\mu\)-strongly convex problems, GD returns an \(\varepsilon\)-solution after \(\mathcal{O}\left(\nicefrac{{L}}{{\mu}}\log\nicefrac{{1}}{{\varepsilon}}\right)\) iterations. In each iteration, the workers and the server communicate all \(\Theta(d)\) coordinates to each other (since no compression is applied). Therefore, the communication complexity of GD is \(\mathfrak{m}_{\mathcal{C}0}=\Theta\left(\nicefrac{{dL}}{{\mu}}\log\nicefrac{{ 1}}{{\varepsilon}}\right).\) The same reasoning applies to the accelerated gradient method (AGD) (Nesterov, 2018), whose communication complexity is \(\mathfrak{m}_{\text{sGD}}=\Theta(d\sqrt{\nicefrac{{L}}{{\mu}}}\log\nicefrac{{ 1}}{{\varepsilon}}).\)

### Compression mappings

In the literature, researchers often use the following two families of compressors:

**Definition 2.2**.: A (possibly) stochastic mapping \(\mathcal{C}\;:\;\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}\) is a _biased compressor_ if there exists \(\alpha\in(0,1]\) such that

\[\mathbb{E}\left[\left\|\mathcal{C}(x)-x\right\|^{2}\right]\leq(1-\alpha)\left\| x\right\|^{2},\qquad\forall x\in\mathbb{R}^{d}.\] (2)

**Definition 2.3**.: A stochastic mapping \(\mathcal{C}\;:\;\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}\) is an _unbiased compressor_ if there exists \(\omega\geq 0\) such that

\[\mathbb{E}\left[\mathcal{C}(x)\right]=x,\qquad\mathbb{E}\left[\left\| \mathcal{C}(x)-x\right\|^{2}\right]\leq\omega\left\|x\right\|^{2},\qquad \forall x\in\mathbb{R}^{d}.\] (3)We will make use of the following assumption.

**Assumption 2.4**.: The randomness in all compressors used in our method is drawn independently.

Let us denote the set of mappings satisfying Definition 2.2 and 2.3 by \(\mathbb{B}(\alpha)\) and \(\mathbb{U}(\omega)\), respectively. The family of biased compressors \(\mathbb{B}\) is wider. Indeed, it is well known if \(\mathcal{C}\in\mathbb{U}(\omega)\), then \(\nicefrac{{1}}{{(\omega+1)}}\cdot\mathcal{C}\in\mathbb{B}\left(\nicefrac{{1}}{{ (\omega+1)}}\right)\). The canonical sparsification operators belonging to these classes are \(\text{Top}K\in\mathbb{B}(\nicefrac{{K}}{{d}})\) and \(\text{Rand}K\in\mathbb{U}(\nicefrac{{d}}{{K}}-1)\). The former outputs the \(K\) largest values (in magnitude) of the input vector, while the latter outputs \(K\) random values of the input vector, scaled by \(\nicefrac{{d}}{{K}}\)(Beznosikov et al., 2020). Following (Gorbunov et al., 2021; Tyurin and Richtarik, 2023), we now define the _expected density_ of a sparsifier as a way to formalize its _compression_ performance.

**Definition 2.5**.: The expected density of a sparsifier \(\mathcal{C}:\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}\) is the quantity \(K_{\mathcal{C}}:=\sup_{x\in\mathbb{R}^{d}}\mathbb{E}\left[\left\|\mathcal{C}( x)\right\|_{0}\right],\) where \(\left\|y\right\|_{0}\) is the number of of non-zero components of \(y\in\mathbb{R}^{d}\).

Trivially, for the Rand\(K\) and Top\(K\) sparsifiers we have \(K_{\mathcal{C}}=K\).

### Unidirectional (i.e., w2s) compression

As mentioned in the introduction, virtually all theoretical works in the area of compressed communication ignore s2w communication cost and instead aim to minimize \(\mathfrak{m}_{\mathcal{M}}^{\times\lambda}\). Algorithmic work related

\begin{table}
\begin{tabular}{c c c} \hline \hline
**Method** & **\# Communication Rounds** & **Round Cost\({}^{\text{\tiny(\ref{eq:m})}}\)** \\ \hline \begin{tabular}{c} Dore, Artemis, MURANANA\({}^{\text{\tiny(\ref{eq:m})}}\) \\ (Philipperko and Dieuleveut, 2020) \\ (Condat and Richtarik, 2022) \\ \end{tabular} & \(\widetilde{\Omega}\left(\frac{\omega}{\alpha n}\frac{L_{\max}}{\mu}\right)^{ \text{\tiny(\ref{eq:m})}}\) & \((1-r)K_{\omega}+rK_{\alpha}\) \\ (Condat and Richtarik, 2022) \\ \end{tabular} & \(\widetilde{\Omega}\left(\left(\frac{1}{\alpha\nicefrac{{3}}{{2}}}+\frac{ \nicefrac{{1}}{{\alpha}}+\nicefrac{{1}}{{\alpha}}}{\sqrt{\nicefrac{{1}}{{ \alpha}}}}+\frac{\omega}{n}\right)\frac{L_{\max}}{\mu}\right)^{\text{\tiny(\ref {eq:m})}}\) & \((1-r)K_{\omega}+rK_{\alpha}\) \\ \hline \begin{tabular}{c} GD \\ (Nesterov, 2018) \\ \end{tabular} & \(\frac{L}{\mu}\) & \(d\) \\ \hline \begin{tabular}{c} EF21-P + DIANA \\ (Gruntkowska et al., 2023) \\ \end{tabular} & \(\frac{L}{\alpha\mu}+\frac{L_{\max}}{n\mu}+\omega\) & \((1-r)K_{\omega}+rK_{\alpha}\) \\ \hline \begin{tabular}{c} GD \\ (Nesterov, 2018) \\ \end{tabular} & \(\sqrt{\frac{L}{\mu}}\) & \(d\) \\ \hline \begin{tabular}{c} 20Direction \\ (Remark 5.3)\({}^{\text{\tiny(\ref{eq:m})}}\) \\ \end{tabular} & \(\sqrt{\frac{L\max\{1,r(\omega+1)\}}{\mu}+\sqrt{\frac{L_{\max}}{n\mu}+\frac{1} {\alpha}+\omega}}\) & \((1-r)K_{\omega}+rK_{\alpha}\) \\ \hline \begin{tabular}{c} 20Direction \\ (Remark 5.5)\({}^{\text{\tiny(\ref{eq:m})}}\) \\ (requires \({}^{L_{\max}}/k^{\text{\tiny(\ref{eq:m})}}\)) \\ \end{tabular} & \(\sqrt{\frac{L\max\{1,r(\omega+1)\}}{\mu}+\sqrt{\frac{L_{\max}}{n\mu}+\frac{1} {\alpha}+\omega}}+\) & \((1-r)K_{\omega}+rK_{\alpha}\) \\ \hline 
\begin{tabular}{c} 20Direction \\ (Remark 5.5)\({}^{\text{\tiny(\ref{eq:m})}}\) \\ (requires \({}^{L_{\max}}/k^{\text{\tiny(\ref{eq:m})}}\)) \\ \end{tabular} & \(\sqrt{\frac{L^{2}/2}{\alpha\mu}+\frac{1}{\alpha}+\omega}\) & \(\sqrt{\frac{L^{2}/2}{\alpha\mu}+\frac{1}{\alpha}+\omega}\) & \((1-r)K_{\omega}+rK_{\alpha}\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: **Communication Rounds in the Strongly Convex Case.** The number of communication rounds and rounds costs to get an \(\varepsilon\)-solution (\(\mathbb{E}\left[\left\|\bar{x}-x^{*}\right\|^{2}\right]\leq\varepsilon\)) up to logarithmic factors. The table shows the most relevant bidirectional compressed methods that are ordered by the total communication complexity # **Communication Rounds \(\times\) Round Cost** (see 4) for details).

i. The parameter \(r\) weights the importance/speed of uplink and downlink connections. When \(r=\nicefrac{{1}}{{2}},\) it means that the uplink and downlink speeds are equal.

ii. The parameters \(K_{\omega}\) and \(K_{\alpha}\) are the expected densities Definition 2.5 of compressors \(\mathcal{C}^{D}\in\mathbb{U}(\omega)\) and \(\mathcal{C}^{P}\in\mathbb{B}(\nicefrac{{\alpha}}{{\alpha}})^{\text{\tiny(\ref{eq: m})}},\) that operate in the workers and the server accordingly. Less formally, \(K_{\omega}\) and \(K_{\alpha}\) are the number of coordinates/bits that the workers and the server send to each other in each communication round.

to methods that only perform w2s compression has a long history, and this area is relatively well understood (Alistarh et al., 2017; Mishchenko et al., 2019; Richtarik et al., 2021).

We refer to the work of Gruntkowska et al. (2023) for a detailed discussion of the communication complexities of _non-accelerated_ methods in the convex and non-convex settings. For instance, using \(\mathsf{Rand}K\), the \(\mathsf{DIANA}\) method of Mishchenko et al. (2019) provably improves2 the communication complexity of \(\mathsf{GD}\) to \(\mathfrak{m}^{\mbox{\tiny w2}}_{\mathsf{DIANA}}=\widetilde{\Theta}\left(d+{{}^ {KL}}_{\mu}+{{}^{dL_{\max}}}/{n_{\mu}}\right).\)_Accelerated_ methods focusing on w2s compression are also well investigated. For example, Li et al. (2020) and Li and Richtarik (2021) developed accelerated methods, which are based on (Mishchenko et al., 2019; Kovalev et al., 2020), and provably improve the w2s complexity of \(\mathsf{DIANA}\). Moreover, using \(\mathsf{Rand}K\) with \(K\leq{{}^{d}}_{n}\), \(\mathsf{ADI}\)-\(\mathsf{ANA}\) improves the communication complexity of \(\mathsf{AGD}\) to \(\mathfrak{m}^{\mbox{\tiny w2}}_{\mathsf{DIANA}}=\widetilde{\Theta}(d+d{{}^{ \sqrt{L_{\max}}}}/{n_{\mu}}).\)

Footnote 2: Indeed, using Lemma 1.4, \(K\leq d,\) and \(L\geq\mu\), one can easily show that \(d+{{}^{KL}}_{\mu}+{{}^{dL_{\max}}}/{n_{\mu}}=\mathcal{O}\!\left(d{{}^{dL}}_{ \mu}\right)\).

### Bidirectional (i.e., w2s and s2w) compression

The methods mentioned in Section 2.2 do _not_ perform server-to-workers (s2w) compression, and one can show that the server-to-workers (s2w) communication complexities of these methods are worse than \(\mathfrak{m}_{\mbox{\tiny AGD}}=\widetilde{\Theta}(d\sqrt{\nicefrac{{L}}{{ \mu}}}).\) For example, using the \(\mathsf{Rand}K\), the s2w communication complexity of \(\mathsf{ADIANA}\) is at least \(\mathfrak{m}^{\mbox{\tiny w2}}_{\mathsf{DIANA}}=\widetilde{\Omega}(d\times \omega)=\widetilde{\Omega}({{}^{d}}/{K}),\) which can be \({{}^{d}}/{K}\) times larger than in \(\mathsf{GD}\) or \(\mathsf{AGD}\). Instead of \(\mathfrak{m}^{\mbox{\tiny w2}}_{\mathsf{DIANA}}\), methods performing bidirectional compression attempt to minimize _the total communication complexity_, which we define as a convex combination of the w2s and s2w communication complexities:

\[\mathfrak{m}^{r}_{\mathsf{M}}:=(1-r)\mathfrak{m}^{\mbox{\tiny w2s}}_{\mathsf{ M}}+r\mathfrak{m}^{\mbox{\tiny w2s}}_{\mathsf{M}}.\] (4)

The parameter \(r\in[0,1]\) weights the importance of uplink (w2s) and downlink (s2w) connections3. Methods from Section 2.2 assume that \(r=0\), thus ignoring the s2w communication cost. On the other hand, when \(r=\nicefrac{{1}}{{2}}\), the uplink and downlink communication speeds are equal. By considering any \(r\in[0,1]\), our methods and findings are applicable to more situations arising in practice. Obviously, \(\mathfrak{m}^{r}_{\mbox{\tiny GD}}=\mathfrak{m}_{\mbox{\tiny GD}}\) and \(\mathfrak{m}^{r}_{\mbox{\tiny AGD}}=\mathfrak{m}_{\mbox{\tiny AGD}}\) for all \(r\in[0,1]\). Recently, Gruntkowska et al. (2023) proposed the EF21-P + \(\mathsf{DIANA}\) method. This is the first method supporting bidirectional compression that provably improves both the w2s and s2w complexities of \(\mathsf{GD}\): \(\mathfrak{m}^{r}_{\mbox{\tiny w2s}\mbox{\tiny F21-P, DIANA}}\leq\mathfrak{m}_{\mathsf{GD}}\) for all \(r\in[0,1]\). Bidirectional methods designed before EF21-P + \(\mathsf{DIANA}\), including (Tang et al., 2020; Liu et al., 2020; Philippenko and Dieuleveut, 2021), do not guarantee the total communication complexities better than that of \(\mathsf{GD}\). The EF21-P + \(\mathsf{DIANA}\) method is _not_ an accelerated method and, in the worst case, can have communication complexities worse than \(\mathsf{AGD}\) when the condition number \(\nicefrac{{L}}{{\mu}}\) is large.

Footnote 3: \(\mathfrak{m}^{r}_{\mbox{\tiny AGD}}\propto\nicefrac{{s^{\mbox{\tiny 2}}}}{{ \mathfrak{m}^{r}_{\mbox{\tiny AGD}}}}+s^{\mbox{\tiny 2w}}\mathfrak{m}^{\mbox{\tiny w2}}_{\mathsf{M}}\), where \(s^{\mbox{\tiny w2s}}\) and \(s^{\mbox{\tiny 2w}}\) are connection speeds, and \(r=s^{\mbox{\tiny e2w}}\nicefrac{{s^{\mbox{\tiny e2w}}}}{{s^{\mbox{\tiny e2w}}}}.\)

## 3 Contributions

Motivated by the above discussion, in this work we aim to address the following

**Main Problem**:

**Is it possible to develop a method supporting bidirectional communication compression that improves the current best theoretical total communication complexity of EF21-P + \(\mathsf{DIANA}\), and guarantees the total communication complexity to be no worse than the communication complexity \(\mathfrak{m}_{\mbox{\tiny AGD}}=\widetilde{\Theta}(d\sqrt{\nicefrac{{L}}{{ \mu}}})\) of \(\mathsf{AGD}\), while improving on \(\mathsf{AGD}\) in at least some regimes?**

**A)** We develop a new fast method (2Direction; see Algorithm 1) supporting bidirectional communication compression. Our analysis leads to new state-of-the-art complexity rates in the centralized distributed setting (see Table 1), and as a byproduct, we answer Main Problem in the affirmative.

**B)** Gruntkowska et al. (2023) proposed to use the EF21-P error-feedback mechanism (8) to improve the convergence rates of _non-accelerated_ methods supporting bidirectional communication compression. EF21-P is a reparameterization of the celebrated EF mechanism (Seide et al., 2014). We tried to use EF21-P in our method as well, but failed. Our failures indicated that a fundamentally new approach is needed, and this eventually led us to design a new error-feedback mechanism (9) that is more appropriate for _accelerated_ methods. We believe that this is a contribution of independent interest that might motivate future growth in the area.

**C)** Unlike previous theoretical works (Li et al., 2020; Li and Richtarik, 2021) on accelerated methods, we present a unified analysis in both the \(\mu\)-strongly-convex and general convex cases. Moreover, in the general convex setting and low accuracy regimes, our analysis improves the rate \(\mathcal{O}\left(\nicefrac{{1}}{{\varepsilon^{1/3}}}\right)\) of Li and Richtarik (2021) to \(\mathcal{O}\left(\log\nicefrac{{1}}{{\varepsilon}}\right)\) (see details in Section R).

**D)** Even though our central goal was to obtain new SOTA _theoretical_ communication complexities for centralized distributed optimization, we show that the newly developed algorithm enjoys faster communication complexities in practice as well (see details in Section Q).

```
1:Parameters: Lipschitz-like parameter \(\bar{L}>0\), strong-convexity parameter \(\mu\geq 0\), probability \(p\in(0,1]\), parameter \(\Gamma_{0}\geq 1\), momentum \(\tau\in(0,1]\), contraction parameter \(\alpha\in(0,1]\) from (2), initial point \(x^{0}\in\mathbb{R}^{d}\), initial gradient shifts \(h^{0}_{1},\ldots,h^{0}_{n}\in\mathbb{R}^{d}\), gradient shifts \(k^{0}\in\mathbb{R}^{d}\) and \(v^{0}\in\mathbb{R}^{d}\)
2:Initialize \(\beta=\nicefrac{{1}}{{(\omega+1)}},w^{0}=z^{0}=u^{0}=x^{0}\), and \(h^{0}=\frac{1}{n}\sum_{i=1}^{n}h^{0}_{i}\)
3:for\(t=0,1,\ldots,T-1\)do
4:\(\Gamma_{t+1},\gamma_{t+1},\theta_{t+1}=\text{CalculateLearning Rates}(\Gamma_{t},\bar{L},\mu,p,\alpha,\tau,\beta)\)  Get learning rates using Algorithm 2
5:for\(i=1,\ldots,n\) in parallel do
6:\(y^{t+1}=\theta_{t+1}w^{t}+(1-\theta_{t+1})z^{t}\)
7:\(m^{t,y}_{i}=\mathcal{C}^{D,y}_{i}(\nabla f_{i}(y^{t+1})-h^{t}_{i})\)  Worker \(i\) compresses the shifted gradient via the compressor \(\mathcal{C}^{D,y}_{i}\in\mathbb{U}(\omega)\)
8: Send compressed message \(m^{t,y}_{i}\) to the server
9:endfor
10:\(g^{t+1}=h^{t}+\frac{1}{n}\sum_{i=1}^{n}m^{t,y}_{i}\)
11:\(u^{t+1}=\arg\min_{x\in\mathbb{R}^{d}}\left\langle g^{t+1},x\right\rangle+\frac {L+\Gamma_{t\mu}}{2\gamma_{t+1}}\left\|x-u^{t}\right\|^{2}+\frac{\mu}{2}\left\| x-y^{t+1}\right\|^{2}\)  A gradient-like descent step
12:\(q^{t+1}=\arg\min_{x\in\mathbb{R}^{d}}\left\langle k^{t},x\right\rangle+\frac {L+\Gamma_{t\mu}}{2\gamma_{t+1}}\left\|x-w^{t}\right\|^{2}+\frac{\mu}{2}\left\| x-y^{t+1}\right\|^{2}\)
13:\(p^{t+1}=\mathcal{C}^{P}\left(u^{t+1}-q^{t+1}\right)\)  Server compresses the shifted model via the compressor \(\mathcal{C}^{P}\in\mathbb{B}\left(\alpha\right)\)
14:\(w^{t+1}=q^{t+1}+p^{t+1}\)
15:\(x^{t+1}=\theta_{t+1}u^{t+1}+(1-\theta_{t+1})z^{t}\)
16: Send compressed message \(p^{t+1}\) to all \(n\) workers
17:Fip a coin \(\boldsymbol{c}^{t}\thicksim\text{Bernoulli}(p)\)
18:\(k^{t+1}=\begin{cases}v^{t},&\boldsymbol{c}^{t}=1\\ k^{t},&\boldsymbol{c}^{t}=0\end{cases}\) and \(z^{t+1}=\begin{cases}x^{t+1},&\boldsymbol{c}^{t}=1\\ z^{t},&\boldsymbol{c}^{t}=\boldsymbol{0}\end{cases}\)
19:if\(\boldsymbol{c}^{t}=\boldsymbol{1}\)then
20: Broadcast non-compressed messages \(x^{t+1}\) and \(k^{t+1}\) to all \(n\) workers With small probability \(p!\)
21:endif
22:for\(i=1,\ldots,n\) in parallel do
23:\(q^{t+1}=\arg\min_{x\in\mathbb{R}^{d}}\left\langle k^{t},x\right\rangle+\frac {\bar{L}+\Gamma_{t\bar{L}}}{2\gamma_{t+1}}\left\|x-w^{t}\right\|^{2}+\frac{ \mu}{2}\left\|x-y^{t+1}\right\|^{2}\)
24:\(w^{t+1}=q^{t+1}+p^{t+1}\)
25:\(z^{t+1}=\begin{cases}x^{t+1},&\boldsymbol{c}^{t}=1\\ z^{t},&\boldsymbol{c}^{t}=0\end{cases}\)
26:\(m^{t,z}_{i}=\mathcal{C}^{D,z}_{i}(\nabla f_{i}(z^{t+1})-h^{t}_{i})\)  Worker \(i\) compresses the shifted gradient via the compressor \(\mathcal{C}^{D,z}_{i}\in\mathbb{U}(\omega)\)
27:\(h^{t+1}_{i}=h^{t}_{i}+\beta m^{t,z}_{i}\)
28: Send compressed message \(m^{t,z}_{i}\) to the server
29:endfor
30:\(v^{t+1}=(1-\tau)v^{t}+\tau\left(h^{t}+\frac{1}{n}\sum_{i=1}^{n}m^{t,z}_{i}\right)\)
31:\(h^{t+1}=h^{t}+\beta\frac{1}{n}\sum_{i=1}^{n}m^{t,z}_{i}\)
32:endfor ```

**Algorithm 1**2Direction: A Fast Gradient Method Supporting Bidirectional Compression

## 4 New Method: 2Direction

In order to provide an answer to Main Problem, at the beginning of our research journey we hoped that a rather straightforward approach might bear fruit. In particular, we considered the current state-the-art methods ADIANA (Algorithm 3) (Li et al., 2020), CANITA (Li and Richtarik, 2021) and EF21-P + DIANA (Algorithm 4) (Gruntkowska et al., 2023), and tried to combine the EF21-P compression 

[MISSING_PAGE_FAIL:6]

[MISSING_PAGE_FAIL:7]

### The ratio \(L_{\max}/L\) is not known

In the following theorem, we consider the regime when the exact value of \(\nicefrac{{L_{\max}}}{{L}}\) is not known. Hence, we seek to find \(p\) and \(\tau\) that minimize the worst case \(\mathfrak{m}_{\text{new}}^{r}\) (see (4)) w.r.t. \(L_{\max}\in[L,nL]\).

**Theorem 5.2**.: _Choose \(r\in[0,1]\) and let \(\mu_{\omega,\alpha}^{r}:=\frac{rd}{(1-r)K_{\omega}+rK_{\alpha}}\). In view of Theorem 5.1, the values \(p=\min\left\{\frac{1}{\omega+1},\frac{1}{\mu_{\omega,\alpha}^{r}}\right\}\) and \(\tau=\frac{p^{1/3}}{(\omega+1)^{2/3}}\) minimize \(\max_{L_{\max}\in[L,nL]}\mathfrak{m}_{\text{new}}^{r}\). This choice leads to the following number of communication rounds:_

\[T^{\text{realistic}}:=\widetilde{\Theta}\Bigg{(}\max\Bigg{\{}\sqrt{\frac{L\max (\omega+1,\mu_{\omega,\alpha}^{r})}{\alpha\mu}},\sqrt{\frac{L_{\max}\omega+ \max(\omega+1,\mu_{\omega,\alpha}^{r})}{n\mu}},\frac{1}{\alpha},(\omega+1), \mu_{\omega,\alpha}^{r}\Bigg{\}}\Bigg{)}.\] (13)

_The total communication complexity thus equals \(\mathfrak{m}_{\text{satisfies}}^{r}=\widetilde{\Theta}\left(\left((1-r)K_{ \omega}+rK_{\alpha}\right)T_{\text{static}}+d\right).\)_

_Remark 5.3_.: To simplify the rate (13) and understand the quantity \(\mu_{\omega,\alpha}^{r}\), let \(\mathcal{C}_{i}^{D,\cdot}\) be the Rand\(K\) sparsifier5 and consider the case when the s2w communication is not slower than the w2s communication, i.e., \(r\leq\nicefrac{{1}}{{2}}\). Then \(T^{\text{realistic}}=\widetilde{\Theta}\left(\max\left\{\sqrt{\frac{L(\omega+1)} {\alpha\mu}},\sqrt{\frac{L_{\max}\omega(\omega+1)}{np\mu}},\frac{1}{\alpha},( \omega+1)\right\}\right)\) and \(\mu_{\omega,\alpha}^{r}\leq\omega+1\). Indeed, this follows from \(r\leq\nicefrac{{1}}{{2}}\) and the fact that \(\omega+1=\nicefrac{{d}}{{K_{\omega}}}\) for the Rand\(K\) compressor: \(\mu_{\omega,\alpha}^{r}:=\frac{rd}{(1-r)K_{\omega}+rK_{\alpha}}\leq\frac{r}{1-r} \times\frac{d}{K_{\omega}}\leq\omega+1\).

Footnote 5: It is sufficient to assume that \(\omega+1=\Theta\left(\nicefrac{{d}}{{K_{\omega}}}\right)\).

### The ratio \(L_{\max}/L\) is known

We now consider the case when we have information about the ratio \(\nicefrac{{L_{\max}}}{{L}}\).

**Theorem 5.4**.: _Choose \(r\in[0,1],\) and let \(\mu_{\omega,\alpha}^{r}:=\frac{rd}{(1-r)K_{\omega}+rK_{\alpha}^{r}}\). In view of Theorem 5.1, the values \(p\) and \(\tau\) given by (63) and (58), respectively, minimize \(\mathfrak{m}_{\text{new}}^{r}\) from (10). This choice leads to the following number of communication rounds:_

\[T^{\text{optimistic}}=\widetilde{\Theta}\Bigg{(}\max\Bigg{\{} \sqrt{\frac{L\max\{1,\mu_{\omega,\alpha}^{r}\}}{\alpha\mu}},\sqrt{\frac{L^{2/3 }L_{\max}^{1/3}(\omega+1)}{\alpha n^{1/3}\mu}},\sqrt{\frac{L^{1/2}L_{\max}^{1/ 2}(\omega+1)^{3/2}}{\sqrt{\alpha n\mu}}},\] (14) \[\sqrt{\frac{L_{\max}\omega\max\{\omega+1,\mu_{\omega,\alpha}^{r} \}}{n\mu}},\frac{1}{\alpha},(\omega+1),\mu_{\omega,\alpha}^{r}\Bigg{\}} \Bigg{)}.\]

_The total communication complexity thus equals \(\mathfrak{m}_{\text{\tiny{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{ \rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{ \rm{ }}}}}}}}}}}}}}}}}}}}}^{r}\) =\widetilde{\Theta}\left(\left((1-r)K_{\omega}+rK_{\alpha}\right)T_{\text{ \tiny{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{\rm{{\rm{\rm{\rm{ \rm{\rm{ \rm{\rm{ \rm{ } }}}}}}}}}}}}}}}}}}}+d \right).\)_

Note that information about \(L_{\max}/L\) leads to a better rate that in Theorem 5.2.

_Remark 5.5_.: To simplify the rate (14), let \(\mathcal{C}_{i}^{D,\cdot}\) be the Rand\(K\) sparsifier6 and consider the case when the s2w communication is not slower than the w2s communication, i.e., \(r\leq\nicefrac{{1}}{{2}}\). Then \(T^{\text{optimistic}}=\widetilde{\Theta}\left(\max\Bigg{\{}\sqrt{\frac{L\max\{1,r(\omega+1)\}}{\alpha\mu}},\sqrt{\frac{L^{2/3}L_{\max}^{1/3}(\omega+1)}{ \alpha n^{1/3}\mu}},\sqrt{\frac{L^{1/2}L_{\max}^{1/2}(\omega+1)^{3/2}}{\sqrt{ \alpha n\mu}}},\sqrt{\frac{L_{\max}\omega(\omega+1)}{n\mu}},\frac{1}{\alpha},( \omega+1)\Bigg{\}}\right).\) Indeed, this follows from \(r\leq\nicefrac{{1}}{{2}}\) and the fact that \(\omega+1=\nicefrac{{d}}{{K_{\omega}}}\) for the Rand\(K\) compressor: \(\mu_{\omega,\alpha}^{r}:=\frac{rd}{(1-r)K_{\omega}+rK_{\alpha}}\leq\frac{r}{1-r} \times\frac{d}{K_{\omega}}\leq 2r\left(\omega+1\right)\).

Footnote 6: It is sufficient to assume that \(\omega+1=\Theta\left(\nicefrac{{d}}{{K_{\omega}}}\right)\).

## 6 Theoretical Comparison with Previous State of the Art

We now show that the communication complexity of 2Direction is always _no worse_ than that of EF21 + DIANA and AGD. Crucially, in some regimes, it can be substantially better. Furthermore, we show that if the s2w communication cost is zero (i.e., if \(r=0\)), the 2Direction obtains the same communication complexity as ADIANA (Li et al., 2020) (see Section S).

**Comparison with EF21 + DIANA.** The EF21-P + DIANA method has the communication complexities that equal

[MISSING_PAGE_EMPTY:9]

probability \(p\) (see Line 20). While in Section 6 we explain that this does not have an adverse effect on the theoretical communication complexity since \(p\) is small, one may wonder whether it might be possible to achieve the same (or better) bounds as ours without having to resort to intermittent non-compressed broadcasts. This remains an open problem; possibly a challenging one. Another limitation comes from the fact that 2Direction requires more iterations than \(\mathsf{AGD}\) in general (this is the case of all methods that reduce communication complexity). While, indeed, (10) can be higher than \(\widetilde{\Theta}(\sqrt{\nicefrac{{L}}{{\mu}}})\), the total communication complexity of 2Direction is not worse than that of \(\mathsf{AGD}\).

#### Acknowledgements

This work of P. Richtarik and A. Tyurin was supported by the KAUST Baseline Research Scheme (KAUST BRF) and the KAUST Extreme Computing Research Center (KAUST ECRC), and the work of P. Richtarik was supported by the SDAIA-KAUST Center of Excellence in Data Science and Artificial Intelligence (SDAIA-KAUST AI).

## References

* Alistarh et al. (2017) Alistarh, D., Grubic, D., Li, J., Tomioka, R., and Vojnovic, M. (2017). QSGD: Communication-efficient SGD via gradient quantization and encoding. In _Advances in Neural Information Processing Systems (NIPS)_, pages 1709-1720.
* Beznosikov et al. (2020) Beznosikov, A., Horvath, S., Richtarik, P., and Safaryan, M. (2020). On biased compression for distributed learning. _arXiv preprint arXiv:2002.12410_.
* Chang and Lin (2011) Chang, C.-C. and Lin, C.-J. (2011). LIBSVM: a library for support vector machines. _ACM Transactions on Intelligent Systems and Technology (TIST)_, 2(3):1-27.
* Condat and Richtarik (2022) Condat, L. and Richtarik, P. (2022). Murana: A generic framework for stochastic variance-reduced optimization. In _Mathematical and Scientific Machine Learning_, pages 81-96. PMLR.
* Gorbunov et al. (2021) Gorbunov, E., Burlachenko, K., Li, Z., and Richtarik, P. (2021). MARINA: Faster non-convex distributed learning with compression. In _38th International Conference on Machine Learning_.
* Gorbunov et al. (2020) Gorbunov, E., Hanzely, F., and Richtarik, P. (2020). A unified theory of SGD: Variance reduction, sampling, quantization and coordinate descent. In _International Conference on Artificial Intelligence and Statistics_, pages 680-690. PMLR.
* Gruntkowska et al. (2023) Gruntkowska, K., Tyurin, A., and Richtarik, P. (2023). EF21-P and friends: Improved theoretical communication complexity for distributed optimization with bidirectional compression. In _International Conference on Machine Learning_.
* Kairouz et al. (2021) Kairouz, P., McMahan, H. B., Avent, B., Bellet, A., Bennis, M., Bhagoji, A. N., Bonawitz, K., Charles, Z., Cormode, G., Cummings, R., et al. (2021). Advances and open problems in federated learning. _Foundations and Trends\(\otimes\) in Machine Learning_, 14(1-2):1-210.
* Konecny et al. (2016) Konecny, J., McMahan, H. B., Yu, F. X., Richtarik, P., Suresh, A. T., and Bacon, D. (2016). Federated learning: Strategies for improving communication efficiency. _arXiv preprint arXiv:1610.05492_.
* Kovalev et al. (2020) Kovalev, D., Horvath, S., and Richtarik, P. (2020). Don't jump through hoops and remove those loops: Svrg and katyusha are better without the outer loop. In _Algorithmic Learning Theory_, pages 451-467. PMLR.
* Krizhevsky et al. (2009) Krizhevsky, A., Hinton, G., et al. (2009). Learning multiple layers of features from tiny images. Technical report, University of Toronto, Toronto.
* Lan (2020) Lan, G. (2020). _First-order and stochastic optimization methods for machine learning_. Springer.
* Lan et al. (2019) Lan, G., Li, Z., and Zhou, Y. (2019). A unified variance-reduced accelerated gradient method for convex optimization. _Advances in Neural Information Processing Systems_, 32.
* Li et al. (2020) Li, Z., Kovalev, D., Qian, X., and Richtarik, P. (2020). Acceleration for compressed gradient descent in distributed and federated optimization. In _International Conference on Machine Learning_.
* Li et al. (2021)Li, Z. and Richtarik, P. (2021). CANITA: Faster rates for distributed convex optimization with communication compression. _Advances in Neural Information Processing Systems_, 34:13770-13781.
* Liu et al. (2020) Liu, X., Li, Y., Tang, J., and Yan, M. (2020). A double residual compression algorithm for efficient distributed learning. In _International Conference on Artificial Intelligence and Statistics_, pages 133-143. PMLR.
* McMahan et al. (2017) McMahan, B., Moore, E., Ramage, D., Hampson, S., and y Arcas, B. A. (2017). Communication-efficient learning of deep networks from decentralized data. In _Artificial intelligence and statistics_, pages 1273-1282. PMLR.
* Meurer et al. (2017) Meurer, A., Smith, C. P., Paprocki, M., Certik, O., Kirpichev, S. B., Rocklin, M., Kumar, A., Ivanov, S., Moore, J. K., Singh, S., Rathnayake, T., Vig, S., Granger, B. E., Muller, R. P., Bonazzi, F., Gupta, H., Vats, S., Johansson, F., Pedregosa, F., Curry, M. J., Terrel, A. R., Roucka, v., Saboo, A., Fernando, I., Kulal, S., Cimrman, R., and Scopatz, A. (2017). Sympy: symbolic computing in python. _PeerJ Computer Science_, 3:e103.
* Mishchenko et al. (2019) Mishchenko, K., Gorbunov, E., Takac, M., and Richtarik, P. (2019). Distributed learning with compressed gradient differences. _arXiv preprint arXiv:1901.09269_.
* Nesterov (2018) Nesterov, Y. (2018). _Lectures on convex optimization_, volume 137. Springer.
* Philippenko and Dieuleveut (2020) Philippenko, C. and Dieuleveut, A. (2020). Artemis: tight convergence guarantees for bidirectional compression in federated learning. _arXiv preprint arXiv:2006.14591_.
* Philippenko and Dieuleveut (2021) Philippenko, C. and Dieuleveut, A. (2021). Preserved central model for faster bidirectional compression in distributed settings. _Advances in Neural Information Processing Systems_, 34:2387-2399.
* Ramesh et al. (2021) Ramesh, A., Pavlov, M., Goh, G., Gray, S., Voss, C., Radford, A., Chen, M., and Sutskever, I. (2021). Zero-shot text-to-image generation. _arXiv preprint arXiv:2102.12092_.
* Richtarik et al. (2021) Richtarik, P., Sokolov, I., and Fatkhullin, I. (2021). EF21: A new, simpler, theoretically better, and practically faster error feedback. _In Neural Information Processing Systems, 2021_.
* Seide et al. (2014) Seide, F., Fu, H., Droppo, J., Li, G., and Yu, D. (2014). 1-bit stochastic gradient descent and its application to data-parallel distributed training of speech DNNs. In _Fifteenth Annual Conference of the International Speech Communication Association_.
* Stonyakin et al. (2021) Stonyakin, F., Tyurin, A., Gasnikov, A., Dvurechensky, P., Agafonov, A., Dvinskikh, D., Alkousa, M., Pasechnyuk, D., Artamonov, S., and Piskunova, V. (2021). Inexact model: a framework for optimization and variational inequalities. _Optimization Methods and Software_, 36(6):1155-1201.
* Tang et al. (2020) Tang, H., Lian, X., Yu, C., Zhang, T., and Liu, J. (2020). DoubleSqueeze: Parallel stochastic gradient descent with double-pass error-compensated compression. In _Proceedings of the 36th International Conference on Machine Learning (ICML)_.
* Tyurin and Richtarik (2023) Tyurin, A. and Richtarik, P. (2023). DASHA: Distributed nonconvex optimization with communication compression and optimal oracle complexity. _International Conference on Learning Representations (ICLR)_.

## Appendix

### 1 Introduction

1.1 The problem 1.2 Assumptions

2 Motivation: From Unidirectional to Bidirectional Compression 2.1 Compression mappings 2.2 Unidirectional (i.e., w2s) compression 2.3 Bidirectional (i.e., w2s and s2w) compression

3 Contributions

4 New Method: 2Direction

5 Theoretical Communication Complexity of 2Direction 5.1 The ratio \({}^{L_{\max}/L}\) is not known 5.2 The ratio \({}^{L_{\max}/L}\) is known

6 Theoretical Comparison with Previous State of the Art

7 Proof Sketch

8 Limitations and Future Work

A Table of Notations

B The Original ADIANA Algorithm

C The Original EF21-P + DIANA Algorithm

D Useful Identities and Inequalities

E Proofs of Theorems 1.1 Analysis of learning rates 1.2 Generic lemmas 1.3 Construction of the Lyapunov function 1.4 Main theorem 1.5 Strongly-convex case 1.6 General convex case 1.7 Choosing optimal parameters 1.8 Comparison with EF21 + DIANA* F Auxiliary Inequalities For \(\bar{L}\)
* G Proof of Lemma e.10 (First Symbolically Computed)
* H Proof of Lemma e.11 (Second Symbolically Computed)
* I Symbolically Computed Constraints for \(\bar{L}\) Such That The Term w.r.t. \(\kappa\) is less or equal \(\sfrac{1}{2}\) in (87)
* J Symbolically Computed Constraints for \(\bar{L}\) Such That The Term w.r.t. \(\rho\) is less or equal \(\sfrac{1}{2}\) in (89)
* K Symbolically Computed Expression (91)
* L Symbolically Computed Constraints for \(\bar{L}\) Such That The Inequality from Section K holds
* M Symbolically Computed Expression (92)
* N Symbolically Computed Constraints for \(\bar{L}\) Such That The Inequality from Section M holds
* O Symbolical Check That The Constraints from Sections I, J, L and N Follow From The Constraint (44)
* P Jupyter Notebook for Symbolic Computations
* P.1 File utils.py
* Q Experiments
* Q.1 Setup
* Q.2 Results
* R Convergence Rate of CANITA obtained by Li and Richtarik (2021)
* S Comparison with ADINA

[MISSING_PAGE_FAIL:14]

The Original EF21-P + Diana Algorithm

In this section, we present the EF21-P + Diana algorithm from (Gruntkowska et al., 2023). In the following method, the notations, parameterization, and order of steps can be slightly different, but the general idea is the same.

```
1:Parameters: learning rates \(\gamma>0\) and \(\beta>0\), initial model \(u^{0}\in\mathbb{R}^{d}\), initial gradient shifts \(h_{1}^{0},\ldots,h_{n}^{0}\in\mathbb{R}^{d}\), average of the initial gradient shifts \(h^{0}=\frac{1}{n}\sum_{i=1}^{n}h_{i}^{0}\), initial model shift \(w^{0}=u^{0}\in\mathbb{R}^{d}\)
2:for\(t=0,1,\ldots,T-1\)do
3:for\(i=1,\ldots,n\) parallel do
4:\(m_{i}^{t}=\mathcal{C}_{i}^{D}(\nabla f_{i}(w^{t})-h_{i}^{t})\) Worker \(i\) compresses the shifted gradient via the dual compressor \(\mathcal{C}_{i}^{D}\in\mathbb{U}(\omega)\)
5:\(h_{i}^{t+1}=h_{i}^{t}+\beta m_{i}^{t}\) Worker \(i\) updates its local gradient shift with stepsize \(\beta\)
6:endfor
7:\(m^{t}=\frac{1}{n}\sum_{i=1}^{n}m_{i}^{t}\) Server averages the \(n\) messages received from the workers
9:\(h^{t+1}=h^{t}+\beta m^{t}\) Server updates the average gradient shift so that \(h^{t}=\frac{1}{n}\sum_{i=1}^{n}h_{i}^{t}\)
10:\(g^{t}=h^{t}+m^{t}\) Server Server computes the gradient estimator
11:\(u^{t+1}=u^{t}-\gamma g^{t}\) Server takes a gradient-type step with stepsize \(\gamma\)
12:\(p^{t+1}=\mathcal{C}^{P}\left(u^{t+1}-w^{t}\right)\) Server compresses the shifted model via the primal compressor \(\mathcal{C}^{P}\in\mathbb{B}\left(\alpha\right)\)
13:\(w^{t+1}=w^{t}+p^{t+1}\) Server updates the model shift
14: Broadcast compressed message \(p^{t+1}\) to all \(n\) workers Server updates the model shift
15:for\(i=1,\ldots,n\) in parallel do
16:\(w^{t+1}=w^{t}+p^{t+1}\) Worker \(i\) updates its local copy of the model shift
17:endfor ```

**Algorithm 4**EF21-P + Diana by Gruntkowska et al. (2023)

## Appendix D Useful Identities and Inequalities

For all \(x,y,x_{1},\ldots,x_{n}\in\mathbb{R}^{d}\), \(s>0\) and \(\alpha\in(0,1]\), we have:

\[\left\|x+y\right\|^{2} \leq(1+s)\left\|x\right\|^{2}+(1+s^{-1})\left\|y\right\|^{2},\] (17) \[\left\|x+y\right\|^{2} \leq 2\left\|x\right\|^{2}+2\left\|y\right\|^{2},\] (18) \[\left\langle x,y\right\rangle \leq\frac{\left\|x\right\|^{2}}{2s}+\frac{s\left\|y\right\|^{2} }{2},\] (19) \[(1-\alpha)\left(1+\frac{\alpha}{2}\right) \leq 1-\frac{\alpha}{2},\] (20) \[(1-\alpha)\left(1+\frac{2}{\alpha}\right) \leq\frac{2}{\alpha},\] (21) \[\left\langle a,b\right\rangle =\frac{1}{2}\left(\left\|a\right\|^{2}+\left\|b\right\|^{2}- \left\|a-b\right\|^{2}\right).\] (22)

**Variance decomposition:** For any random vector \(X\in\mathbb{R}^{d}\) and any non-random \(c\in\mathbb{R}^{d}\), we have

\[\mathbb{E}\left[\left\|X-c\right\|^{2}\right]=\mathbb{E}\left[\left\|X- \mathbb{E}\left[X\right]\right\|^{2}\right]+\left\|\mathbb{E}\left[X\right]-c \right\|^{2}.\] (23)

**Lemma D.1** (Nesterov (2018)).: _Let \(f:\mathbb{R}^{d}\rightarrow\mathbb{R}\) be a function for which Assumptions 1.2 and 1.3 are satisfied. Then for all \(x,y\in\mathbb{R}^{d}\) we have:_

\[\left\|\nabla f(x)-\nabla f(y)\right\|^{2}\leq 2L(f(x)-f(y)-\left\langle \nabla f(y),x-y\right\rangle).\] (24)

## Appendix E Proofs of Theorems

### Analysis of learning rates

In this section, we establish inequalities for the sequences from Algorithm 2.

**Lemma E.1**.: _Suppose that parameter \(\bar{L}>0,\) strong-convexity parameter \(\mu\geq 0,\) probability \(p\in(0,1],\)\(\bar{L}\geq\mu,\) and \(\Gamma_{0}\geq 1.\) Then the sequences generated by Algorithm 2 have the following properties:_

1. _The quantities_ \(\theta_{t+1},\gamma_{t+1},\) _and_ \(\Gamma_{t+1}\) _are well-defined and_ \(\theta_{t+1},\gamma_{t+1}\geq 0\) _for all_ \(t\geq 0.\)__
2. \(\gamma_{t+1}=p\theta_{t+1}\Gamma_{t+1}\) _for all_ \(t\geq 0.\)__
3. \(\bar{L}\theta_{t+1}\gamma_{t+1}\leq(\bar{L}+\Gamma_{t}\mu)\) _for all_ \(t\geq 0.\)__
4. \[\Gamma_{t}\geq\frac{\Gamma_{0}}{2}\exp\left(t\min\left\{\sqrt{\frac{p\mu}{4 \bar{L}}},p\theta_{\min}\right\}\right)\] _for all_ \(t\geq 0.\)__
5. \[\Gamma_{t}\geq\left\{\frac{\Gamma_{0}}{2}\exp\left(tp\theta_{\min}\right), \quad t<\bar{t}\right.\] \[\left.\frac{1}{4p\theta_{\min}^{2}}+\frac{p(t-\bar{t})^{2}}{16}, \quad t\geq\bar{t}.\right.\] _where_ \(\bar{t}:=\max\left\{\left|\frac{1}{p\theta_{\min}^{2}}\log\frac{1}{2\Gamma_{0 }p\theta_{\min}^{2}}\right|,0\right\}.\)__
6. \(\{\theta_{t+1}\}_{t=0}^{\infty}\) _is a non-increasing sequence._

Proof.:
1. Note that \(\bar{\theta}_{t+1}\) is the largest root of \[p\bar{L}\Gamma_{t}\bar{\theta}_{t+1}^{2}+p(\bar{L}+\Gamma_{t}\mu)\bar{\theta} _{t+1}-(\bar{L}+\Gamma_{t}\mu)=0.\] (25) We fix \(t\geq 0.\) Assume that \(\Gamma_{t}>0.\) Then \[p\bar{L}\Gamma_{t}\times 0+p(\bar{L}+\Gamma_{t}\mu)\times 0-(\bar{L}+\Gamma_{t} \mu)<0.\] Therefore, the largest root \(\bar{\theta}_{t+1}\) is well-defined and \(\bar{\theta}_{t+1}\geq 0,\) and \(\theta_{t+1}=\min\{\bar{\theta}_{t+1},\theta_{\min}\}\geq 0.\) Next, \(\gamma_{t+1}\) is well-defined and \[\gamma_{t+1}=p\theta_{t+1}\Gamma_{t}/(1-p\theta_{t+1})\geq 0\] since \(p\theta_{t+1}\in[0,\nicefrac{{1}}{{4}}].\) Finally, \(\Gamma_{t+1}=\Gamma_{t}+\gamma_{t+1}>0.\) We showed that, for all \(t\geq 0,\) if \(\Gamma_{t}>0,\) then \(\theta_{t+1},\gamma_{t+1}\geq 0\) and \(\Gamma_{t+1}>0.\) Note that \(\Gamma_{0}>0,\) thus \(\theta_{t+1},\gamma_{t+1}\geq 0\) and \(\Gamma_{t+1}>0\) for all \(t\geq 0.\)
2. From the definition of \(\gamma_{t+1}\) and \(\Gamma_{t+1},\) we have \[(1-p\theta_{t+1})\gamma_{t+1}=p\theta_{t+1}\Gamma_{t},\] which is equivalent to \[\gamma_{t+1}=p\theta_{t+1}\left(\Gamma_{t}+\gamma_{t+1}\right)=p\theta_{t+1} \Gamma_{t+1}.\]
3. Recall again that \(\bar{\theta}_{t+1}\geq 0\) is the largest root of \[p\bar{L}\Gamma_{t}\bar{\theta}_{t+1}^{2}+p(\bar{L}+\Gamma_{t}\mu)\bar{\theta} _{t+1}-(\bar{L}+\Gamma_{t}\mu)=0.\] If \(\bar{\theta}_{t+1}\leq\theta_{\min},\) then \[p\bar{L}\Gamma_{t}\theta_{t+1}^{2}+p(\bar{L}+\Gamma_{t}\mu)\theta_{t+1}-(\bar{L }+\Gamma_{t}\mu)=0.\] Otherwise, if \(\bar{\theta}_{t+1}>\theta_{\min},\) since \[p\bar{L}\Gamma_{t}\times 0+p(\bar{L}+\Gamma_{t}\mu)\times 0-(\bar{L}+\Gamma_{t}\mu)<0,\]and \(\theta_{t+1}=\theta_{\min}<\bar{\theta}_{t+1},\) then \[p\bar{L}\Gamma_{t}\theta_{t+1}^{2}+p(\bar{L}+\Gamma_{t}\mu)\theta_{t+1}-(\bar{L}+ \Gamma_{t}\mu)\leq 0.\] (26) In all cases, the inequality (26) holds. From this inequality, we can get \[p\bar{L}\Gamma_{t}\theta_{t+1}^{2}\leq\left(\bar{L}+\Gamma_{t}\mu\right)(1-p \theta_{t+1})\] and \[\bar{L}\theta_{t+1}\frac{p\theta_{t+1}\Gamma_{t}}{(1-p\theta_{t+1})}\leq( \bar{L}+\Gamma_{t}\mu).\] Using the definition of \(\gamma_{t+1},\) we obtain \[\bar{L}\theta_{t+1}\gamma_{t+1}\leq(\bar{L}+\Gamma_{t}\mu)\] for all \(t\geq 0.\)
4. Let us find the largest root of the quadratic equation (25): \[\bar{\theta}_{t+1}:=\frac{-p(\bar{L}+\Gamma_{t}\mu)+\sqrt{p^{2}(\bar{L}+\Gamma _{t}\mu)^{2}+4p\bar{L}\Gamma_{t}(\bar{L}+\Gamma_{t}\mu)}}{2p\bar{L}\Gamma_{t}}.\] (27) Let us define \(a:=p^{2}\left(\bar{L}+\Gamma_{t}\mu\right)^{2}\) and \(b:=4\bar{L}p\left(\bar{L}+\Gamma_{t}\mu\right)\Gamma_{t},\) then \[\bar{\theta}_{t+1}=\frac{-\sqrt{a}+\sqrt{a+\bar{b}}}{2\bar{L}p\Gamma_{t}}\] Since \(\Gamma_{t}\geq 1\) for all \(t\geq 0,\) and \(\bar{L}\geq\mu,\) we have \[a=p^{2}\left(\bar{L}+\Gamma_{t}\mu\right)^{2}\leq p\left(\bar{L}+\Gamma_{t}\mu \right)^{2}\leq p\left(\bar{L}+\Gamma_{t}\mu\right)\left(\Gamma_{t}\bar{L}+ \Gamma_{t}\mu\right)\leq 2\bar{L}p\left(\bar{L}+\Gamma_{t}\mu\right)\Gamma_{t}= \frac{b}{2}.\] Using \(\sqrt{x+y}\geq\left(\sqrt{x}+\sqrt{y}\right)/\sqrt{2}\) for all \(x,y\geq 0,\) and \(\sqrt{b}\geq\sqrt{2}\sqrt{a}\) we have \[\bar{\theta}_{t+1} =\frac{-\sqrt{a}+\sqrt{a+b}}{2\bar{L}p\Gamma_{t}}\geq\frac{-\sqrt{ a}+\frac{1}{\sqrt{2}}\sqrt{a}+\frac{1}{\sqrt{2}}\sqrt{b}}{2\bar{L}p\Gamma_{t}}\] \[=\frac{\left(\frac{1}{\sqrt{2}}-1\right)\sqrt{a}+\frac{1}{\sqrt{2 }}\left(\frac{1}{\sqrt{2}}+1-\frac{1}{\sqrt{2}}\right)\sqrt{b}}{2\bar{L}p \Gamma_{t}}\geq\frac{\frac{1}{\sqrt{2}}\left(\frac{1}{\sqrt{2}}\right)\sqrt{b} }{2\bar{L}p\Gamma_{t}}=\frac{\sqrt{b}}{4\bar{L}p\Gamma_{t}}.\] Therefore \[\bar{\theta}_{t+1}\geq\frac{\sqrt{4\bar{L}p\left(\bar{L}+\Gamma_{t}\mu\right) \Gamma_{t}}}{4\bar{L}p\Gamma_{t}}=\sqrt{\frac{(\bar{L}+\Gamma_{t}\mu)}{4\bar {L}p\Gamma_{t}}}\geq\max\left\{\sqrt{\frac{1}{4p\Gamma_{t}}},\sqrt{\frac{\mu }{4p\bar{L}}}\right\}\] and \[\theta_{t+1}\geq\min\left\{\max\left\{\sqrt{\frac{1}{4p\Gamma_{t}}},\sqrt{\frac {\mu}{4p\bar{L}}}\right\},\theta_{\min}\right\}.\] (28) Next, since \(p\theta_{t+1}\in[0,\nicefrac{{1}}{{4}}],\) we have \[\gamma_{t+1}:=p\theta_{t+1}\Gamma_{t}/(1-p\theta_{t+1})\geq p\theta_{t+1} \Gamma_{t}\left(1+p\theta_{t+1}\right)\] (29) and \[\Gamma_{t+1}:=\Gamma_{t}+\gamma_{t+1}\geq\left(1+p\theta_{t+1}+p^{2}\theta_{t+ 1}^{2}\right)\Gamma_{t}.\] Using (28) and (29), we obtain \[\Gamma_{t+1} \geq\left(1+p\min\left\{\sqrt{\frac{\mu}{4p\bar{L}}},\theta_{ \min}\right\}\right)\Gamma_{t}=\left(1+\min\left\{\sqrt{\frac{p\mu}{4\bar{L}}},p\theta_{\min}\right\}\right)\Gamma_{t}\] \[\geq\Gamma_{0}\left(1+\min\left\{\sqrt{\frac{p\mu}{4\bar{L}}},p \theta_{\min}\right\}\right)^{t+1}\geq\frac{\Gamma_{0}}{2}\exp\left((t+1)\min \left\{\sqrt{\frac{p\mu}{4\bar{L}}},p\theta_{\min}\right\}\right),\] (30) where we use that \(1+x\geq e^{x}/2\) for all \(x\in[0,1].\)5. Using (28) and (29), we have \[\Gamma_{t+1} \geq\left(1+p\theta_{t+1}+p^{2}\theta_{t+1}^{2}\right)\Gamma_{t}\] \[\geq\Gamma_{t}+p\min\left\{\sqrt{\frac{1}{4p\Gamma_{t}}},\theta_{ \min}\right\}\Gamma_{t}+p^{2}\min\left\{\sqrt{\frac{1}{4p\Gamma_{t}}},\theta_{ \min}\right\}^{2}\Gamma_{t}.\] The sequence \(\Gamma_{t+1}\) is strongly increasing. Thus, exists the minimal \(\widehat{t}\geq 0\) such that \(\Gamma_{\widehat{t}}\geq(4p\theta_{\min}^{2})^{-1}\). For all \(0\leq t<\widehat{t}\), it holds that \(\Gamma_{t}<(4p\theta_{\min}^{2})^{-1}\), \(\sqrt{\frac{1}{4p\Gamma_{t}}}>\theta_{\min}\), and \[\Gamma_{t+1}\geq\Gamma_{t}+p\theta_{\min}\Gamma_{t}+p^{2}\theta_{\min}^{2} \Gamma_{t}\geq\Gamma_{t}+p\theta_{\min}\Gamma_{t}\geq\Gamma_{0}\left(1+p \theta_{\min}\right)^{t+1}\geq\frac{\Gamma_{0}}{2}\exp\left((t+1)p\theta_{ \min}\right).\] (31) Therefore, if \(\widehat{t}>0\), then \[\frac{1}{4p\theta_{\min}^{2}}>\Gamma_{\widehat{t}-1}\geq\frac{\Gamma_{0}}{2} \exp\left((\widehat{t}-1)p\theta_{\min}\right).\] Thus, we have the following bound for \(\widehat{t}\): \[\widehat{t}\leq\bar{t}:=\max\left\{\left\lceil\frac{1}{p\theta_{\min}}\log \frac{1}{2\Gamma_{0}p\theta_{\min}^{2}}\right\rceil,0\right\}.\] For all \(t\geq\widehat{t}\), we have \(\sqrt{\frac{1}{4p\Gamma_{t}}}\leq\theta_{\min}\) and \[\Gamma_{t+1}\geq\Gamma_{t}+p\sqrt{\frac{1}{4p\Gamma_{t}}}\Gamma_{t}+p^{2}\frac {1}{4p\Gamma_{t}}\Gamma_{t}=\Gamma_{t}+\sqrt{\frac{p}{4}}\sqrt{\Gamma_{t}}+ \frac{p}{4}.\] Using mathematical induction, let us show that \[\Gamma_{t}\geq\frac{1}{4p\theta_{\min}^{2}}+\frac{p(t-\widehat{t})^{2}}{16}\] (32) for all \(t\geq\widehat{t}\). For \(t=\widehat{t}\) it is true since \(\Gamma_{\widehat{t}}\geq\left(4p\theta_{\min}^{2}\right)^{-1}\) by the definition of \(\widehat{t}\). Next, for some \(t\geq\widehat{t}\), assume that (32) holds, then \[\Gamma_{t+1} \geq\Gamma_{t}+\frac{\sqrt{p}}{2}\sqrt{\Gamma_{t}}+\frac{p}{4}\] \[\geq\frac{1}{4p\theta_{\min}^{2}}+\frac{p(t-\widehat{t})^{2}}{16} +\frac{\sqrt{p}}{2}\sqrt{\frac{1}{4p\theta_{\min}^{2}}+\frac{p(t-\widehat{t})^ {2}}{16}}+\frac{p}{4}\] \[\geq\frac{1}{4p\theta_{\min}^{2}}+\frac{p(t-\widehat{t})^{2}}{16} +\frac{p(t-\widehat{t})}{8}+\frac{p}{4}\] \[\geq\frac{1}{4p\theta_{\min}^{2}}+\frac{p(t-\widehat{t}+1)^{2}}{16}.\] We proved the inequality using mathematical induction. Combining (31) and (32), we obtain the unified inequality for \(\Gamma_{t}\): \[\Gamma_{t}\geq\min\left\{\frac{\Gamma_{0}}{2}\exp\left(tp\theta_{\min}\right), \frac{1}{4p\theta_{\min}^{2}}+\frac{p(t-\widehat{t})^{2}}{16}\right\}\] for all \(t\geq 0\). Also, if \(t<\bar{t}\), then the first term in the minimum is less or equal than the second one. Therefore, \[\Gamma_{t}\geq\begin{cases}\frac{\Gamma_{0}}{2}\exp\left(tp\theta_{\min} \right),&t<\bar{t}\\ \min\left\{\frac{\Gamma_{0}}{2}\exp\left(tp\theta_{\min}\right),\frac{1}{4p \theta_{\min}^{2}}+\frac{p(t-\widehat{t})^{2}}{16}\right\},&t\geq\bar{t}. \end{cases}\] (33)Let us bound the second term. Recall that \(\bar{t}\geq\bar{t}\), thus, if \(t\geq\bar{t}\), then \((t-\bar{t})^{2}\geq(t-\bar{t})^{2}\). In (33), we can change \(\bar{t}\) to \(\bar{t}\) and get \[\Gamma_{t}\geq\begin{cases}\frac{\Gamma_{0}}{2}\exp\left(tp\theta_{\min} \right),&t<\bar{t}\\ \min\left\{\frac{\Gamma_{0}}{2}\exp\left(tp\theta_{\min}\right),\frac{1}{4\theta _{\min}^{2}}+\frac{p(t-\bar{t})^{2}}{16}\right\},&t\geq\bar{t}.\end{cases}\] Using the Taylor expansion of the exponent at the point \(\bar{t}\), we get \[\frac{\Gamma_{0}}{2}\exp\left(tp\theta_{\min}\right) \geq\frac{\Gamma_{0}}{2}\exp\left(\bar{t}p\theta_{\min}\right)+ \frac{\Gamma_{0}}{2}p^{2}\theta_{\min}^{2}\exp\left(\bar{t}p\theta_{\min} \right)\frac{(t-\bar{t})^{2}}{2}\] \[\geq\frac{1}{4p\theta_{\min}^{2}}+\frac{p}{8}(t-\bar{t})^{2} \geq\frac{1}{4p\theta_{\min}^{2}}+\frac{p}{16}(t-\bar{t})^{2}.\] for all \(t\geq\bar{t}\). Finally, we can conclude that \[\Gamma_{t}\geq\begin{cases}\frac{\Gamma_{0}}{2}\exp\left(tp\theta_{\min} \right),&t<\bar{t}\\ \frac{1}{4p\theta_{\min}^{2}}+\frac{p(t-\bar{t})^{2}}{16},&t\geq\bar{t}.\end{cases}\]
6. Let us rewrite (27): \[\bar{\theta}_{t+1} =\frac{-p(\bar{L}+\Gamma_{t}\mu)+\sqrt{p^{2}(\bar{L}+\Gamma_{t} \mu)^{2}+4p\bar{L}\Gamma_{t}(\bar{L}+\Gamma_{t}\mu)}}{2p\bar{L}\Gamma_{t}}\] \[=-\frac{1}{2}\left(\frac{1}{\Gamma_{t}}+\frac{\mu}{\bar{L}} \right)+\sqrt{\frac{1}{4}\left(\frac{1}{\Gamma_{t}}+\frac{\mu}{\bar{L}} \right)^{2}+\frac{1}{p}\left(\frac{1}{\Gamma_{t}}+\frac{\mu}{\bar{L}}\right)}.\] Let us temporarily denote \(a_{t}:=\left(\frac{1}{\Gamma_{t}}+\frac{\mu}{\bar{L}}\right)\) for all \(t\geq 0\). Note that \(a_{t}\) is a non-increasing sequence, since \(\Gamma_{t+1}\geq\Gamma_{t}\) for all \(t\geq 0\). Therefore, \[\bar{\theta}_{t+1}=-\frac{1}{2}a_{t}+\sqrt{\frac{1}{4}a_{t}^{2}+\frac{1}{p}a_ {t}}.\] Let us take the derivative of the last term w.r.t. \(a_{t}\) and compare it to zero: \[-\frac{1}{2}+\frac{\frac{1}{2}a_{t}+\frac{1}{p}}{2\sqrt{\frac{1}{4 }a_{t}^{2}+\frac{1}{p}a_{t}}}\geq 0 \Leftrightarrow\frac{1}{2}a_{t}+\frac{1}{p}\geq\sqrt{\frac{1}{4 }a_{t}^{2}+\frac{1}{p}a_{t}}\] \[\Leftrightarrow\frac{1}{4}a_{t}^{2}+\frac{1}{p}a_{t}+\frac{1}{p^{ 2}}\geq\frac{1}{4}a_{t}^{2}+\frac{1}{p}a_{t}\Leftrightarrow\frac{1}{p^{2}} \geq 0.\] Thus, \(\bar{\theta}_{t+1}\) is a non-decreasing sequence w.r.t. \(a_{t}\). But the sequence \(a_{t}\) is non-increasing, therefore \(\bar{\theta}_{t+1}\) is a non-increasing sequence w.r.t. \(t\). It is left to use that \(\theta_{t+1}\) is the minimum of \(\bar{\theta}_{t+1}\) and the constant quantity.

### Generic lemmas

First, we prove a well-known lemma from the theory of accelerated methods (Lan, 2020; Stonyakin et al., 2021).

**Lemma E.2**.: _Let us take vectors \(a,b,g\in\mathbb{R}^{d}\), numerical quantities \(\alpha,\beta\geq 0,\) and_

\[u=\operatorname*{arg\,min}_{x\in\mathbb{R}^{d}}\left\langle g,x\right\rangle+ \frac{\alpha}{2}\left\|x-a\right\|^{2}+\frac{\beta}{2}\left\|x-b\right\|^{2}.\]

_Then_

\[\left\langle g,x\right\rangle+\frac{\alpha}{2}\left\|x-a\right\|^{2}+\frac{ \beta}{2}\left\|x-b\right\|^{2}\geq\left\langle g,u\right\rangle+\frac{ \alpha}{2}\left\|u-a\right\|^{2}+\frac{\beta}{2}\left\|u-b\right\|^{2}+\frac{ \alpha+\beta}{2}\left\|x-u\right\|^{2}\] (34)

_for all \(x\in\mathbb{R}^{d}\)._

[MISSING_PAGE_FAIL:20]

\[+p\left(\frac{4\omega L_{\max}}{n\bar{L}}+\theta_{t+1}-1\right)D_{f}(z ^{t},y^{t+1})\] \[+\frac{pL}{2}\mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t+1}\right\|^{2 }\right]-\frac{p\theta_{t+1}^{2}\bar{L}}{2}\mathbb{E}_{t}\left[\left\|u^{t+1}- u^{t}\right\|^{2}\right].\]

Proof.: Using Assumption 1.2, we have

\[f(x^{t+1})-f(x^{*})\leq f(y^{t+1})-f(x^{*})+\left\langle\nabla f(y^{t+1}),x^{ t+1}-y^{t+1}\right\rangle+\frac{L}{2}\left\|x^{t+1}-y^{t+1}\right\|^{2}.\]

Using the definition of \(x^{t+1},\) we obtain

\[f(x^{t+1})-f(x^{*})\leq(1-\theta_{t+1})\left(f(y^{t+1})-f(x^{*}) +\left\langle\nabla f(y^{t+1}),z^{t}-y^{t+1}\right\rangle\right)\] (36) \[+\theta_{t+1}\left(f(y^{t+1})-f(x^{*})+\left\langle\nabla f(y^{t+ 1}),u^{t+1}-y^{t+1}\right\rangle\right)\] \[+\frac{L}{2}\left\|x^{t+1}-y^{t+1}\right\|^{2}\] \[=(1-\theta_{t+1})\left(f(y^{t+1})-f(x^{*})+\left\langle\nabla f(y ^{t+1}),z^{t}-y^{t+1}\right\rangle\right)\] \[+\theta_{t+1}\left(f(y^{t+1})-f(x^{*})+\left\langle g^{t+1},u^{ t+1}-y^{t+1}\right\rangle\right)\] \[+\theta_{t+1}\left(\left\langle\nabla f(y^{t+1})-g^{t+1},u^{t+1}- y^{t+1}\right\rangle\right)\] \[+\frac{L}{2}\left\|x^{t+1}-y^{t+1}\right\|^{2},\]

in the last inequality we add and subtract \(g^{t+1}.\) Using the definition of \(u^{t+1}\) and Lemma E.2 with \(x=x^{*},\) we have

\[\left\langle g^{t+1},u^{t+1}-y^{t+1}\right\rangle\leq\left\langle g ^{t+1},x^{*}-y^{t+1}\right\rangle+\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \left\|x^{*}-u^{t}\right\|^{2}+\frac{\mu}{2}\left\|x^{*}-y^{t+1}\right\|^{2}\] \[-\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}}\left\|u^{t+1}-u^{t} \right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+1}}\left\|x^{*}-u^{t+1 }\right\|^{2}.\]

We use the fact that \(\Gamma_{t+1}=\Gamma_{t}+\gamma_{t+1}.\) Since \(\left\|u^{t}-y^{t+1}\right\|^{2}\geq 0,\) we have

\[\left\langle g^{t+1},u^{t+1}-y^{t+1}\right\rangle\leq\left\langle g ^{t+1},x^{*}-y^{t+1}\right\rangle+\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \left\|x^{*}-u^{t}\right\|^{2}+\frac{\mu}{2}\left\|x^{*}-y^{t+1}\right\|^{2}\] \[-\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}}\left\|u^{t+1}-u^{t} \right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+1}}\left\|x^{*}-u^{t+1 }\right\|^{2}.\]

By substituting this inequality to (36), we get

\[f(x^{t+1})-f(x^{*})\] \[\leq(1-\theta_{t+1})\left(f(y^{t+1})-f(x^{*})+\left\langle\nabla f (y^{t+1}),z^{t}-y^{t+1}\right\rangle\right)\] \[+\theta_{t+1}\left(f(y^{t+1})-f(x^{*})+\left\langle g^{t+1},x^{*} -y^{t+1}\right\rangle\right)\] \[+\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \left\|x^{*}-u^{t}\right\|^{2}+\frac{\mu}{2}\left\|x^{*}-y^{t+1}\right\|^{2}- \frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}}\left\|u^{t+1}-u^{t}\right\|^{2}- \frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+1}}\left\|x^{*}-u^{t+1}\right\|^{2}\right)\] \[+\theta_{t+1}\left(\left\langle\nabla f(y^{t+1})-g^{t+1},u^{t+1}- y^{t+1}\right\rangle\right)\] \[+\frac{L}{2}\left\|x^{t+1}-y^{t+1}\right\|^{2}.\]

Using \(\mu\)-strong convexity, we have

\[f(x^{*})\geq f(y^{t+1})+\left\langle\nabla f(y^{t+1}),x^{*}-y^{t+1}\right\rangle +\frac{\mu}{2}\left\|x^{*}-y^{t+1}\right\|^{2}\]

and

\[f(x^{t+1})-f(x^{*})\] \[\leq(1-\theta_{t+1})\left(f(y^{t+1})-f(x^{*})+\left\langle\nabla f (y^{t+1}),z^{t}-y^{t+1}\right\rangle\right)\]\[+\theta_{t+1}\left(\left\langle g^{t+1}-\nabla f(y^{t+1}),x^{*}-y^{t+1} \right\rangle\right)\] (37) \[+\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \left\|x^{*}-u^{t}\right\|^{2}-\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \mathbb{E}_{t}\left[\left\|u^{t+1}-u^{t}\right\|^{2}\right]-\frac{\bar{L}+ \Gamma_{t+1}\mu}{2\gamma_{t+1}}\mathbb{E}_{t}\left[\left\|x^{*}-u^{t+1}\right\| ^{2}\right]\right)\] \[+\theta_{t+1}\mathbb{E}_{t}\left[\left\langle\nabla f(y^{t+1})-g^ {t+1},u^{t+1}-y^{t+1}\right\rangle\right]\] \[+\frac{L}{2}\mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t+1}\right\|^{ 2}\right],\]

where use that \(\mathbb{E}_{t}\left[g^{t+1}\right]=\nabla f(y^{t+1})\). We can find \(u^{t+1}\) analytically and obtain that

\[u^{t+1}=\frac{\bar{L}+\Gamma_{t}\mu}{\bar{L}+\Gamma_{t+1}\mu}u^{t}+\frac{\mu \gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu}y^{t+1}-\frac{\gamma_{t+1}}{\bar{L}+ \Gamma_{t+1}\mu}g^{t+1}.\]

Therefore, using that \(\mathbb{E}_{t}\left[g^{t+1}\right]=\nabla f(y^{t+1})\) and \(u^{t}\) and \(y^{t+1}\) are conditionally nonrandom, we obtain

\[\mathbb{E}_{t}\left[\left\langle\nabla f(y^{t+1})-g^{t+1},u^{t+1}-y^{t+1} \right\rangle\right]=\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu}\mathbb{E}_{ t}\left[\left\|g^{t+1}-\nabla f(y^{t+1})\right\|^{2}\right].\] (38)

Combining (35) from Lemma E.3 with (37) and (38), one can get

\[\mathbb{E}_{t}\left[f(x^{t+1})-f(x^{*})\right]\] (39) \[\leq(1-\theta_{t+1})\left(f(y^{t+1})-f(x^{*})+\left\langle\nabla f (y^{t+1}),z^{t}-y^{t+1}\right\rangle\right)\] \[\quad+\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1 }}\left\|x^{*}-u^{t}\right\|^{2}-\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \mathbb{E}_{t}\left[\left\|u^{t+1}-u^{t}\right\|^{2}\right]-\frac{\bar{L}+ \Gamma_{t+1}\mu}{2\gamma_{t+1}}\mathbb{E}_{t}\left[\left\|x^{*}-u^{t+1} \right\|^{2}\right]\right)\] \[\quad+\frac{\theta_{t+1}\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu} \left(\frac{2\omega}{n^{2}}\sum_{i=1}^{n}\left\|\nabla f_{i}(z^{t})-h_{i}^{t} \right\|^{2}+\frac{4\omega L_{\max}}{n}(f(z^{t})-f(y^{t+1})-\left\langle\nabla f (y^{t+1}),z^{t}-y^{t+1}\right\rangle)\right)\] \[\quad+\frac{L}{2}\mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t+1}\right\| ^{2}\right].\]Using the notation \(D_{f}(x,y):=f(x)-f(y)-\left\langle\nabla f(y),x-y\right\rangle,\) we get

\[\mathbb{E}_{t}\left[f(x^{t+1})-f(x^{*})\right]\] \[\leq(1-\theta_{t+1})\left(f(z^{t})-f(x^{*})-D_{f}(z^{t},y^{t+1})\right)\] \[\quad+\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1 }}\left\|x^{*}-u^{t}\right\|^{2}-\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \mathbb{E}_{t}\left[\left\|u^{t+1}-u^{t}\right\|^{2}\right]-\frac{\bar{L}+ \Gamma_{t+1}\mu}{2\gamma_{t+1}}\mathbb{E}_{t}\left[\left\|x^{*}-u^{t+1}\right\| ^{2}\right]\right)\] \[\quad+\frac{\theta_{t+1}\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu} \left(\frac{2\omega}{n^{2}}\sum_{i=1}^{n}\left\|\nabla f_{i}(z^{t})-h_{i}^{t} \right\|^{2}+\frac{4\omega L_{\max}}{n}D_{f}(z^{t},y^{t+1})\right)\] \[\quad+\frac{L}{2}\mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t+1} \right\|^{2}\right]\] \[=(1-\theta_{t+1})\left(f(z^{t})-f(x^{*})\right)\] \[\quad+\frac{\theta_{t+1}\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu} \frac{2\omega}{n}\left(\frac{1}{n}\sum_{i=1}^{n}\left\|\nabla f_{i}(z^{t})-h_{ i}^{t}\right\|^{2}\right)\] \[\quad+\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1 }}\left\|x^{*}-u^{t}\right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+1} }\mathbb{E}_{t}\left[\left\|x^{*}-u^{t+1}\right\|^{2}\right]\right)\] \[\quad+\left(\frac{\theta_{t+1}\gamma_{t+1}}{\bar{L}+\Gamma_{t+1} \mu}\frac{4\omega L_{\max}}{n}+\theta_{t+1}-1\right)D_{f}(z^{t},y^{t+1})\] \[\quad+\frac{L}{2}\mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t+1} \right\|^{2}\right]-\frac{\theta_{t+1}\left(\bar{L}+\Gamma_{t}\mu\right)}{2 \gamma_{t+1}}\mathbb{E}_{t}\left[\left\|u^{t+1}-u^{t}\right\|^{2}\right].\]

In the last equality, we simply regrouped the terms. Using the definition of \(z^{t+1}\), we get

\[\mathbb{E}_{t}\left[f(z^{t+1})-f(x^{*})\right]=p\mathbb{E}_{t} \left[f(x^{t+1})-f(x^{*})\right]+(1-p)\left(f(z^{t})-f(x^{*})\right)\] \[\leq p(1-\theta_{t+1})\left(f(z^{t})-f(x^{*})\right)\] \[\quad+p\frac{\theta_{t+1}\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu} \frac{2\omega}{n}\left(\frac{1}{n}\sum_{i=1}^{n}\left\|\nabla f_{i}(z^{t})-h_{ i}^{t}\right\|^{2}\right)\] \[\quad+p\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+ 1}}\left\|x^{*}-u^{t}\right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+ 1}}\mathbb{E}_{t}\left[\left\|x^{*}-u^{t+1}\right\|^{2}\right]\right)\] \[\quad+p\left(\frac{\theta_{t+1}\gamma_{t+1}}{\bar{L}+\Gamma_{t+1} \mu}\frac{4\omega L_{\max}}{n}+\theta_{t+1}-1\right)D_{f}(z^{t},y^{t+1})\] \[\quad+p\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t +1}}\left\|x^{*}-u^{t}\right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+ 1}}\mathbb{E}_{t}\left[\left\|x^{*}-u^{t+1}\right\|^{2}\right]\right)\] \[\quad+p\left(\frac{\theta_{t+1}\gamma_{t+1}}{\bar{L}+\Gamma_{t+1 }\mu}\frac{4\omega L_{\max}}{n}+\theta_{t+1}-1\right)D_{f}(z^{t},y^{t+1})\] \[\quad+\frac{pL}{2}\mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t+1} \right\|^{2}\right]-\frac{p\theta_{t+1}\left(\bar{L}+\Gamma_{t}\mu\right)}{2 \gamma_{t+1}}\mathbb{E}_{t}\left[\left\|u^{t+1}-u^{t}\right\|^{2}\right].\]

In the last equality, we grouped the terms with \(f(z^{t})-f(x^{*})\). In Algorithm 2, we choose the learning rates so that (see Lemma E.1)

\[\bar{L}\theta_{t+1}\gamma_{t+1}\leq\bar{L}+\Gamma_{t}\mu.\]

Since \(\Gamma_{t+1}\geq\Gamma_{t}\) for all \(t\in\mathbb{N}_{0},\) thus

\[\frac{\theta_{t+1}\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu}\leq\frac{\theta_{t+1} \gamma_{t+1}}{\bar{L}+\Gamma_{t}\mu}\leq\frac{1}{\bar{L}}\]\[\mathbb{E}_{t}\left[f(z^{t+1})-f(x^{*})\right]\] \[\leq\left(1-p\theta_{t+1}\right)\left(f(z^{t})-f(x^{*})\right)\] \[\quad+p\frac{2\omega}{n\bar{L}}\left(\frac{1}{n}\sum_{i=1}^{n} \left\|\nabla f_{i}(z^{t})-h_{i}^{t}\right\|^{2}\right)\] \[\quad+p\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+ 1}}\left\|x^{*}-u^{t}\right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+1} }\mathbb{E}_{t}\left[\left\|x^{*}-u^{t+1}\right\|^{2}\right]\right)\] \[\quad+p\left(\frac{4\omega L_{\max}}{n\bar{L}}+\theta_{t+1}-1 \right)D_{f}(z^{t},y^{t+1})\] \[\quad+\frac{pL}{2}\mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t+1} \right\|^{2}\right]-\frac{p\theta_{t+1}^{2}\bar{L}}{2}\mathbb{E}_{t}\left[ \left\|u^{t+1}-u^{t}\right\|^{2}\right].\]

### Construction of the Lyapunov function

In this section, we provide lemmas that will help us to construct a Lyapunov function.

**Lemma E.5**.: _Suppose that Assumptions 1.2, 1.1, 1.3 and 2.4 hold. The parameter \(\beta\leq\nicefrac{{1}}{{\omega+1}}\). Then, for Algorithm 1, the following inequality holds:_

\[\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t+1}- \nabla f_{i}(z^{t+1})\right\|^{2}\right]\] (39) \[\leq 8p\left(1+\frac{p}{\beta}\right)L_{\max}D_{f}(z^{t},y^{t+1})+ 4p\left(1+\frac{p}{\beta}\right)\widehat{L}^{2}\mathbb{E}_{t}\left[\left\|x^ {t+1}-y^{t+1}\right\|^{2}\right]+\left(1-\frac{\beta}{2}\right)\frac{1}{n} \sum_{i=1}^{n}\left\|h_{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}.\] (40)

Proof.: Using the definition of \(h_{i}^{t+1}\), we have

\[\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t+1}- \nabla f_{i}(z^{t+1})\right\|^{2}\right]\] \[=\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t}+ \beta\mathcal{C}_{i}^{D,z}(\nabla f_{i}(z^{t+1})-h_{i}^{t})-\nabla f_{i}(z^{t +1})\right\|^{2}\right]\] \[=\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t}- \nabla f_{i}(z^{t+1})\right\|^{2}\right]\] \[\quad+\mathbb{E}_{t}\left[\frac{2\beta}{n}\sum_{i=1}^{n}\left\langle h _{i}^{t}-\nabla f_{i}(z^{t+1}),\mathcal{C}_{i}^{D,z}(\nabla f_{i}(z^{t+1})-h_ {i}^{t})\right\rangle+\frac{\beta^{2}}{n}\sum_{i=1}^{n}\left\|\mathcal{C}_{i} ^{D,z}(\nabla f_{i}(z^{t+1})-h_{i}^{t})\right\|^{2}\right].\]

Note that \(\mathbb{E}_{\mathcal{C}}\left[\mathcal{C}_{i}^{D,z}(\nabla f_{i}(z^{t+1})-h_ {i}^{t})\right]=\nabla f_{i}(z^{t+1})-h_{i}^{t}\) and

\[\mathbb{E}_{\mathcal{C}}\left[\left\|\mathcal{C}_{i}^{D,z}(\nabla f_{i}(z^{t+1 })-h_{i}^{t})\right\|^{2}\right]\leq(\omega+1)\left\|\nabla f_{i}(z^{t+1})-h_ {i}^{t}\right\|^{2},\]

where \(\mathbb{E}_{\mathcal{C}}\left[\cdot\right]\) is a conditional expectation that is conditioned on \(z^{t+1}\) and \(h_{i}^{t}\). Therefore,

\[\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t+1}- \nabla f_{i}(z^{t+1})\right\|^{2}\right]\] \[\leq\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t} -\nabla f_{i}(z^{t+1})\right\|^{2}\right]\]\[+\mathbb{E}_{t}\left[\frac{2\beta}{n}\sum_{i=1}^{n}\left\langle h_{i} ^{t}-\nabla f_{i}(z^{t+1}),\nabla f_{i}(z^{t+1})-h_{i}^{t}\right\rangle+\frac{ \beta^{2}(\omega+1)}{n}\sum_{i=1}^{n}\left\|\nabla f_{i}(z^{t+1})-h_{i}^{t} \right\|^{2}\right]\] \[=\left(1-2\beta+\beta^{2}(\omega+1)\right)\mathbb{E}_{t}\left[ \frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t}-\nabla f_{i}(z^{t+1})\right\|^{2} \right].\]

Since \(\beta\leq\nicefrac{{1}}{{\omega+1}}\), we have

\[\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t+1}-\nabla f_{i}( z^{t+1})\right\|^{2}\right]\leq\left(1-\beta\right)\mathbb{E}_{t}\left[\frac{1}{n} \sum_{i=1}^{n}\left\|h_{i}^{t}-\nabla f_{i}(z^{t+1})\right\|^{2}\right].\]

Next, we use the definition of \(z^{t+1}\) and obtain

\[\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t+1}- \nabla f_{i}(z^{t+1})\right\|^{2}\right]\] \[\leq\left(1-\beta\right)p\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1 }^{n}\left\|h_{i}^{t}-\nabla f_{i}(x^{t+1})\right\|^{2}\right]+\left(1-\beta \right)\left(1-p\right)\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t}-\nabla f_{i}( z^{t})\right\|^{2}\] \[\stackrel{{\eqref{eq:2.1}}}{{\leq}}\left(1+\frac{2p} {\beta}\right)\left(1-\beta\right)p\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{ n}\left\|f_{i}(z^{t})-\nabla f_{i}(x^{t+1})\right\|^{2}\right]+\left(1+\frac{\beta}{2p} \right)\left(1-\beta\right)p\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t}-\nabla f _{i}(z^{t})\right\|^{2}\] \[\quad+\left(1-\beta\right)\left(1-p\right)\mathbb{E}_{t}\left[ \frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}\right]\] \[=\left(1+\frac{2p}{\beta}\right)\left(1-\beta\right)p\mathbb{E}_{ t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|f_{i}(z^{t})-\nabla f_{i}(x^{t+1}) \right\|^{2}\right]+\left(1-\beta\right)\left(1+\frac{\beta}{2}\right)\frac{1} {n}\sum_{i=1}^{n}\left\|h_{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}.\]

Using \(1-\beta\leq 1\), (18) and (20), we get

\[\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t+1}- \nabla f_{i}(z^{t+1})\right\|^{2}\right]\] \[\leq 4p\left(1+\frac{p}{\beta}\right)\frac{1}{n}\sum_{i=1}^{n} \left\|f_{i}(z^{t})-\nabla f_{i}(y^{t+1})\right\|^{2}+4p\left(1+\frac{p}{\beta }\right)\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|f_{i}(x^{t+1})- \nabla f_{i}(y^{t+1})\right\|^{2}\right]\] \[\quad+\left(1-\frac{\beta}{2}\right)\frac{1}{n}\sum_{i=1}^{n} \left\|h_{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}.\]

From Assumptions 1.1 and 1.3 and Lemma D.1, we obtain

\[\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t+1}- \nabla f_{i}(z^{t+1})\right\|^{2}\right]\] \[\leq 8p\left(1+\frac{p}{\beta}\right)L_{\max}\left(f(z^{t})-f(y^{t+1 })-\left\langle\nabla f(y^{t+1}),z^{t}-y^{t+1}\right\rangle\right)+4p\left(1+ \frac{p}{\beta}\right)\widehat{L}^{2}\mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t+1 }\right\|^{2}\right]\] \[\quad+\left(1-\frac{\beta}{2}\right)\frac{1}{n}\sum_{i=1}^{n} \left\|h_{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}\] \[=8p\left(1+\frac{p}{\beta}\right)L_{\max}D_{f}(z^{t},y^{t+1})+4p \left(1+\frac{p}{\beta}\right)\widehat{L}^{2}\mathbb{E}_{t}\left[\left\|x^{t+1}- y^{t+1}\right\|^{2}\right]+\left(1-\frac{\beta}{2}\right)\frac{1}{n}\sum_{i=1}^{n} \left\|h_{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}.\]

[MISSING_PAGE_EMPTY:26]

\[+\frac{4}{\alpha}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu} \right)^{2}\left\|\nabla f(z^{t})-\nabla f(y^{t+1})\right\|^{2}\] \[+(1-\alpha)\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu} \right)^{2}\left(\frac{2\omega}{n^{2}}\sum_{i=1}^{n}\left\|\nabla f_{i}(z^{t}) -h_{i}^{t}\right\|^{2}+\frac{4\omega L_{\max}}{n}D_{f}(z^{t},y^{t+1})\right).\]

Using Lemma D.1 and \(1-\alpha\leq 1\), we obtain

\[\mathbb{E}_{t}\left[\left\|w^{t+1}-u^{t+1}\right\|^{2}\right]\] \[\leq\left(1-\frac{\alpha}{2}\right)\left(\frac{\bar{L}+\Gamma_{t }\mu}{\bar{L}+\Gamma_{t+1}\mu}\right)^{2}\left\|w^{t}-u^{t}\right\|^{2}\] \[\quad+\frac{4}{\alpha}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{ t+1}\mu}\right)^{2}\left\|k^{t}-\nabla f(z^{t})\right\|^{2}\] \[\quad+\frac{2\omega}{n}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_ {t+1}\mu}\right)^{2}\frac{1}{n}\sum_{i=1}^{n}\left\|\nabla f_{i}(z^{t})-h_{i}^ {t}\right\|^{2}+\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu}\right)^{2} \left(\frac{4\omega L_{\max}}{n}+\frac{8L}{\alpha}\right)D_{f}(z^{t},y^{t+1})\] \[\leq\left(1-\frac{\alpha}{2}\right)\left\|w^{t}-u^{t}\right\|^{2}\] \[\quad+\frac{4}{\alpha}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{ t+1}\mu}\right)^{2}\left\|k^{t}-\nabla f(z^{t})\right\|^{2}\] \[\quad+\frac{2\omega}{n}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_ {t+1}\mu}\right)^{2}\frac{1}{n}\sum_{i=1}^{n}\left\|\nabla f_{i}(z^{t})-h_{i}^ {t}\right\|^{2}+\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu}\right)^{2} \left(\frac{4\omega L_{\max}}{n}+\frac{8L}{\alpha}\right)D_{f}(z^{t},y^{t+1}),\]

where we use that \(\Gamma_{t+1}\geq\Gamma_{t}\) for all \(t\geq 0\). 

**Lemma E.7**.: _Suppose that Assumptions 1.2 and 1.3 hold. Then, for Algorithm 1, the following inequality holds:_

\[\mathbb{E}_{t}\left[\left\|k^{t+1}-\nabla f(z^{t+1})\right\|^{2}\right]\] \[\leq 2p\mathbb{E}_{t}\left[\left\|v^{t}-\nabla f(z^{t})\right\|^{2} \right]+8pLD_{f}(z^{t},y^{t+1})+4pL^{2}\mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t +1}\right\|^{2}\right]+(1-p)\left\|k^{t}-\nabla f(z^{t})\right\|^{2}.\] (42)

Proof.: Note that \(k^{t+1}\) and \(z^{t+1}\) are coupled by the same random variable \(c^{t}\). Therefore,

\[\mathbb{E}_{t}\left[\left\|k^{t+1}-\nabla f(z^{t+1})\right\|^{2}\right]\] \[=p\mathbb{E}_{t}\left[\left\|v^{t}-\nabla f(x^{t+1})\right\|^{2} \right]+(1-p)\left\|k^{t}-\nabla f(z^{t})\right\|^{2}\] (18) \[\overset{(\ref{eq:1})}{\leq}2p\mathbb{E}_{t}\left[\left\|v^{t}- \nabla f(z^{t})\right\|^{2}\right]+4p\left\|\nabla f(z^{t})-\nabla f(y^{t+1}) \right\|^{2}+4p\mathbb{E}_{t}\left[\left\|\nabla f(y^{t+1})-\nabla f(x^{t+1}) \right\|^{2}\right]\] \[\quad+(1-p)\left\|k^{t}-\nabla f(z^{t})\right\|^{2}\] \[\leq 2p\mathbb{E}_{t}\left[\left\|v^{t}-\nabla f(z^{t})\right\|^{2} \right]+8pLD_{f}(z^{t},y^{t+1})+4pL^{2}\mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t +1}\right\|^{2}\right]+(1-p)\left\|k^{t}-\nabla f(z^{t})\right\|^{2},\]

where we use Assumptions 1.2 and Lemma D.1. 

**Lemma E.8**.: _Suppose that Assumptions 1.2, 1.1 and 1.3 hold. The momentum \(\tau\in(0,1]\) and the probability \(p\in(0,1]\). Then, for Algorithm 1, the following inequality holds:_

\[\mathbb{E}_{t}\left[\left\|v^{t+1}-\nabla f(z^{t+1})\right\|^{2}\right]\] \[\leq\left(1-\frac{\tau}{2}\right)\left\|v^{t}-\nabla f(z^{t}) \right\|^{2}+\frac{2\tau^{2}\omega}{n^{2}}\sum_{i=1}^{n}\left\|h_{i}^{t}- \nabla f_{i}(z^{t})\right\|^{2}\] \[\quad+\left(4p\left(1+\frac{2p}{\tau}\right)L+\frac{8p\tau^{2} \omega L_{\max}}{n}\right)D_{f}(z^{t},y^{t+1})+\left(2p\left(1+\frac{2p}{\tau} \right)L^{2}+\frac{4p\tau^{2}\omega\tilde{L}^{2}}{n}\right)\mathbb{E}_{t}\left[ \left\|x^{t+1}-y^{t+1}\right\|^{2}\right].\] (43)

[MISSING_PAGE_EMPTY:28]

[MISSING_PAGE_EMPTY:29]

\[+\rho\mathbb{E}_{t}\left[\left\|k^{t+1}-\nabla f(z^{t+1})\right\|^{2} \right]+\lambda\mathbb{E}_{t}\left[\left\|v^{t+1}-\nabla f(z^{t+1})\right\|^{2}\right]\] \[\leq\left(1-p\theta_{t+1}\right)\left(f(z^{t})-f(x^{*})\right)\] \[+\frac{2p\omega}{n\bar{L}}\left(\frac{1}{n}\sum_{i=1}^{n}\left\|h _{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}\right)\] \[+p\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \left\|u^{t}-x^{*}\right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+1}} \mathbb{E}_{t}\left[\left\|u^{t+1}-x^{*}\right\|^{2}\right]\right)\] \[+p\left(\frac{4\omega L_{\max}}{n\bar{L}}+\theta_{t+1}-1\right) D_{f}(z^{t},y^{t+1})\] \[+\frac{p\bar{L}}{2}\mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t+1} \right\|^{2}\right]-\frac{p\theta_{t+1}^{2}\bar{L}}{2}\mathbb{E}_{t}\left[ \left\|u^{t+1}-u^{t}\right\|^{2}\right]\] \[+\kappa\left(8p\left(1+\frac{p}{\beta}\right)L_{\max}D_{f}(z^{t}, y^{t+1})+4p\left(1+\frac{p}{\beta}\right)\widehat{L}^{2}\mathbb{E}_{t}\left[ \left\|x^{t+1}-y^{t+1}\right\|^{2}\right]+\left(1-\frac{\beta}{2}\right)\frac{ 1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}\right)\] \[+\nu_{t}\left(\left(1-\frac{\alpha}{2}\right)\left\|w^{t}-u^{t} \right\|^{2}+\frac{4}{\alpha}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1} \mu}\right)^{2}\left\|k^{t}-\nabla f(z^{t})\right\|^{2}\right.\] \[\left.\qquad\qquad+\frac{2\omega}{n}\left(\frac{\gamma_{t+1}}{ \bar{L}+\Gamma_{t+1}\mu}\right)^{2}\frac{1}{n}\sum_{i=1}^{n}\left\|\nabla f_{ i}(z^{t})-h_{i}^{t}\right\|^{2}+\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1} \mu}\right)^{2}\left(\frac{4\omega L_{\max}}{n}+\frac{8L}{\alpha}\right)D_{f} (z^{t},y^{t+1})\right)\] \[+\rho\left(2p\mathbb{E}_{t}\left[\left\|v^{t}-\nabla f(z^{t}) \right\|^{2}\right]+8pLD_{f}(z^{t},y^{t+1})+4pL^{2}\mathbb{E}_{t}\left[\left\| x^{t+1}-y^{t+1}\right\|^{2}\right]+\left(1-p\right)\left\|k^{t}-\nabla f(z^{t}) \right\|^{2}\right)\] \[+\lambda\left(\left(1-\frac{\tau}{2}\right)\left\|v^{t}-\nabla f (z^{t})\right\|^{2}+\frac{2\tau^{2}\omega}{n^{2}}\sum_{i=1}^{n}\left\|h_{i}^{t }-\nabla f_{i}(z^{t})\right\|^{2}\right.\] \[\left.\qquad\qquad+\left(4p\left(1+\frac{2p}{\tau}\right)L+\frac {8p\tau^{2}\omega L_{\max}}{n}\right)D_{f}(z^{t},y^{t+1})+\left(2p\left(1+ \frac{2p}{\tau}\right)L^{2}+\frac{4p\tau^{2}\omega\widehat{L}^{2}}{n}\right) \mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t+1}\right\|^{2}\right]\right).\]

We regroup the terms and obtain

\[\mathbb{E}_{t}\left[f(z^{t+1})-f(x^{*})\right]+\kappa\mathbb{E}_ {t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t+1}-\nabla f_{i}(z^{t+1}) \right\|^{2}\right]+\nu_{t}\mathbb{E}_{t}\left[\left\|w^{t+1}-u^{t+1}\right\|^ {2}\right]\] \[+\rho\mathbb{E}_{t}\left[\left\|k^{t+1}-\nabla f(z^{t+1})\right\|^ {2}\right]+\lambda\mathbb{E}_{t}\left[\left\|v^{t+1}-\nabla f(z^{t+1})\right\| ^{2}\right]\] \[\leq\left(1-p\theta_{t+1}\right)\left(f(z^{t})-f(x^{*})\right)\] \[+p\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \left\|u^{t}-x^{*}\right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+1}} \mathbb{E}_{t}\left[\left\|u^{t+1}-x^{*}\right\|^{2}\right]\right)\] \[+p\left(\frac{4\omega L_{\max}}{n\bar{L}}+\kappa 8\left(1+\frac{p}{ \beta}\right)L_{\max}+\nu_{t}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1} \mu}\right)^{2}\left(\frac{4\omega L_{\max}}{pn}+\frac{8L}{p\alpha}\right)+ \rho 8L+\] \[+\lambda\left(4\left(1+\frac{2p}{\tau}\right)L+\frac{8\tau^{2} \omega L_{\max}}{n}\right)+\theta_{t+1}-1\right)D_{f}(z^{t},y^{t+1})\] \[+\left(\frac{pL}{2}+\kappa 4p\left(1+\frac{p}{\beta}\right)\widehat{L}^{2}+ \rho 4pL^{2}+\lambda\left(2p\left(1+\frac{2p}{\tau}\right)L^{2}+\frac{4p\tau^{2} \omega\widehat{L}^{2}}{n}\right)\right)\mathbb{E}_{t}\left[\left\|x^{t+1}-y^{t+ 1}\right\|^{2}\right]\] \[-\frac{p\theta_{t+1}^{2}\bar{L}}{2}\mathbb{E}_{t}\left[\left\|u^{t +1}-u^{t}\right\|^{2}\right]\] \[+\nu_{t}\left(1-\frac{\alpha}{2}\right)\left\|w^{t}-u^{t}\right\|^ {2}\] \[+\left(\nu_{t}\frac{4}{\alpha}\left(\frac{\gamma_{t+1}}{\bar{L}+ \Gamma_{t+1}\mu}\right)^{2}+\rho(1-p)\right)\left\|k^{t}-\nabla f(z^{t}) \right\|^{2}\]\[+\rho\mathbb{E}_{t}\left[\left\|k^{t+1}-\nabla f(z^{t+1})\right\|^{2} \right]+\lambda\mathbb{E}_{t}\left[\left\|v^{t+1}-\nabla f(z^{t+1})\right\|^{2}\right]\] \[\leq\left(1-p\theta_{t+1}\right)\left(f(z^{t})-f(x^{*})\right)\] \[+p\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \left\|u^{t}-x^{*}\right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+1}} \mathbb{E}_{t}\left[\left\|u^{t+1}-x^{*}\right\|^{2}\right]\right)\] \[+p\left(\frac{4\omega L_{\max}}{n\bar{L}}+\kappa 8\left(1+\frac{p}{ \beta}\right)L_{\max}+\nu_{t}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1} \mu}\right)^{2}\left(\frac{4\omega L_{\max}}{pn}+\frac{8L}{p\alpha}\right)+ \rho 8L+\right.\] \[\left.\qquad+\left.\lambda\left(4\left(1+\frac{2p}{\tau}\right)L+ \frac{8\tau^{2}\omega L_{\max}}{n}\right)+\theta_{t+1}-1\right)D_{f}(z^{t},y ^{t+1})\] \[+\theta_{t+1}^{2}\left(\frac{pL}{2}+\kappa 4p\left(1+\frac{p}{ \beta}\right)\widehat{L}^{2}+\rho 4pL^{2}+\lambda\left(2p\left(1+\frac{2p}{\tau} \right)L^{2}+\frac{4p\tau^{2}\omega\widehat{L}^{2}}{n}\right)\right)\mathbb{E }_{t}\left[\left\|u^{t+1}-w^{t}\right\|^{2}\right]\] \[-\frac{p\theta_{t+1}^{2}\bar{L}}{2}\mathbb{E}_{t}\left[\left\|u^ {t+1}-u^{t}\right\|^{2}\right]\] \[+\nu_{t}\left(1-\frac{\alpha}{2}\right)\left\|w^{t}-u^{t}\right\| ^{2}\] \[+\left(\nu_{t}\frac{4}{\alpha}\left(\frac{\gamma_{t+1}}{\bar{L}+ \Gamma_{t+1}\mu}\right)^{2}+\rho(1-p)\right)\left\|k^{t}-\nabla f(z^{t})\right\| ^{2}\] \[+\left(\rho 2p+\lambda\left(1-\frac{\tau}{2}\right)\right)\left\|v^ {t}-\nabla f(z^{t})\right\|^{2}\] \[+\left(\frac{2p\omega}{n\bar{L}}+\nu_{t}\frac{2\omega}{n}\left( \frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu}\right)^{2}+\lambda\frac{2\tau^{2} \omega}{n}+\kappa\left(1-\frac{\beta}{2}\right)\right)\left(\frac{1}{n}\sum_ {i=1}^{n}\left\|h_{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}\right).\]

The inequality (17) implies \(\left\|u^{t+1}-w^{t}\right\|^{2}\leq 2\left\|u^{t+1}-u^{t}\right\|^{2}+2\left\|u^{ t}-w^{t}\right\|^{2}\) and

\[\mathbb{E}_{t}\left[f(z^{t+1})-f(x^{*})\right]+\kappa\mathbb{E}_{ t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t+1}-\nabla f_{i}(z^{t+1}) \right\|^{2}\right]+\nu_{t}\mathbb{E}_{t}\left[\left\|w^{t+1}-u^{t+1}\right\|^ {2}\right]\] \[\leq\left(1-p\theta_{t+1}\right)\left(f(z^{t})-f(x^{*})\right)\] \[+p\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \left\|u^{t}-x^{*}\right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+1}} \mathbb{E}_{t}\left[\left\|u^{t+1}-x^{*}\right\|^{2}\right]\right)\] \[+p\left(\frac{4\omega L_{\max}}{n\bar{L}}+\kappa 8\left(1+\frac{p}{ \beta}\right)L_{\max}+\nu_{t}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1} \mu}\right)^{2}\left(\frac{4\omega L_{\max}}{pn}+\frac{8L}{p\alpha}\right)+ \rho 8L+\right.\] \[\left.\qquad\qquad+\left.\lambda\left(4\left(1+\frac{2p}{\tau} \right)L+\frac{8\tau^{2}\omega L_{\max}}{n}\right)+\theta_{t+1}-1\right)D_{f} (z^{t},y^{t+1})\] \[+2\theta_{t+1}^{2}\left(\frac{p\bar{L}}{2}+\kappa 4p\left(1+\frac{p}{ \beta}\right)\widehat{L}^{2}+\rho 4pL^{2}+\lambda\left(2p\left(1+\frac{2p}{\tau}\right)L^{2}+ \frac{4p\tau^{2}\omega\widehat{L}^{2}}{n}\right)\right)\mathbb{E}_{t}\left[ \left\|u^{t+1}-u^{t}\right\|^{2}\right]\] \[-\frac{p\theta_{t+1}^{2}\bar{L}}{2}\mathbb{E}_{t}\left[\left\|u^{ t+1}-u^{t}\right\|^{2}\right]\]\[+\left(2\theta_{t+1}^{2}\left(\frac{pL}{2}+\kappa 4p\left(1+\frac{p}{ \beta}\right)\widehat{L}^{2}+\rho 4pL^{2}+\lambda\left(2p\left(1+\frac{2p}{\tau} \right)L^{2}+\frac{4p\tau^{2}\omega\widehat{L}^{2}}{n}\right)\right)+\nu_{t} \left(1-\frac{\alpha}{2}\right)\right)\left\|w^{t}-u^{t}\right\|^{2}\] \[+\left(\nu_{t}\frac{4}{\alpha}\left(\frac{\gamma_{t+1}}{\bar{L}+ \Gamma_{t+1}\mu}\right)^{2}+\rho(1-p)\right)\left\|k^{t}-\nabla f(z^{t})\right\| ^{2}\] \[+\left(\rho 2p+\lambda\left(1-\frac{\tau}{2}\right)\right)\left\|v^{t }-\nabla f(z^{t})\right\|^{2}\] \[+\left(\frac{2p\omega}{n\bar{L}}+\nu_{t}\frac{2\omega}{n}\left( \frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu}\right)^{2}+\lambda\frac{2\tau^{2} \omega}{n}+\kappa\left(1-\frac{\beta}{2}\right)\right)\left(\frac{1}{n}\sum_{ i=1}^{n}\left\|h_{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}\right).\]

Now, we want to find appropriate \(\kappa\), \(\rho\), \(\lambda\), and \(\nu_{t}\) such that

\[2\theta_{t+1}^{2}\left(\frac{pL}{2}+\kappa 4p\left(1+\frac{p}{ \beta}\right)\widehat{L}^{2}+\rho 4pL^{2}+\lambda\left(2p\left(1+\frac{2p}{\tau} \right)L^{2}+\frac{4p\tau^{2}\omega\widehat{L}^{2}}{n}\right)\right)+\nu_{t} \left(1-\frac{\alpha}{2}\right)\leq\nu_{t}\left(1-\frac{\alpha}{4}\right),\] \[\nu_{t}\frac{4}{\alpha}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_ {t+1}\mu}\right)^{2}+\rho(1-p)\leq\rho\left(1-\frac{p}{2}\right),\] \[\rho 2p+\lambda\left(1-\frac{\tau}{2}\right)\leq\lambda\left(1- \frac{\tau}{4}\right),\] \[\frac{2p\omega}{n\bar{L}}+\nu_{t}\frac{2\omega}{n}\left(\frac{ \gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu}\right)^{2}+\lambda\frac{2\tau^{2} \omega}{n}+\kappa\left(1-\frac{\beta}{2}\right)\leq\kappa\left(1-\frac{\beta} {4}\right).\] (46)

We analyze inequalities (46) in the following lemma:

**Lemma E.10** (First Symbolically Computed).: _Assume that for the parameter \(\bar{L}\), the inequalities from Sections I and J hold. Then, for all \(t\geq 0,\) exists \(\rho\) in (90), \(\kappa\) in (88), \(\lambda\) in (82), and \(\nu_{t}\) in (83) such that (46) holds._

We proof lemma separately in Section G. Using the lemma, we have

\[\mathbb{E}_{t}\left[f(z^{t+1})-f(x^{*})\right]+\kappa\mathbb{E}_ {t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t+1}-\nabla f_{i}(z^{t+1}) \right\|^{2}\right]+\nu_{t}\mathbb{E}_{t}\left[\left\|w^{t+1}-u^{t+1}\right\|^ {2}\right]\] \[+\rho\mathbb{E}_{t}\left[\left\|k^{t+1}-\nabla f(z^{t+1})\right\| ^{2}\right]+\lambda\mathbb{E}_{t}\left[\left\|v^{t+1}-\nabla f(z^{t+1}) \right\|^{2}\right]\] \[\leq\left(1-p\theta_{t+1}\right)\left(f(z^{t})-f(x^{*})\right)\] \[+p\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \left\|u^{t}-x^{*}\right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+1}} \mathbb{E}_{t}\left[\left\|u^{t+1}-x^{*}\right\|^{2}\right]\right)\] \[+p\left(\frac{4\omega L_{\max}}{n\bar{L}}+\kappa 8\left(1+\frac{p}{ \beta}\right)L_{\max}+\nu_{t}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu} \right)^{2}\left(\frac{4\omega L_{\max}}{pn}+\frac{8L}{p\alpha}\right)+\rho 8L+\right.\] \[\left.\qquad\qquad+\lambda\left(4\left(1+\frac{2p}{\tau}\right)L+ \frac{8\tau^{2}\omega L_{\max}}{n}\right)+\theta_{t+1}-1\right)D_{f}(z^{t},y^{ t+1})\] \[+2\theta_{t+1}^{2}\left(\frac{pL}{2}+\kappa 4p\left(1+\frac{p}{ \beta}\right)\widehat{L}^{2}+\rho 4pL^{2}+\lambda\left(2p\left(1+\frac{2p}{\tau}\right)L^{2}+ \frac{4p\tau^{2}\omega\widehat{L}^{2}}{n}\right)\right)\mathbb{E}_{t}\left[ \left\|u^{t+1}-u^{t}\right\|^{2}\right]\] \[-\frac{p\theta_{t+1}^{2}\bar{L}}{2}\mathbb{E}_{t}\left[\left\|u^{t +1}-u^{t}\right\|^{2}\right]\] \[+\nu_{t}\left(1-\frac{\alpha}{4}\right)\left\|w^{t}-u^{t}\right\| ^{2}\] \[+\rho\left(1-\frac{p}{2}\right)\left\|k^{t}-\nabla f(z^{t}) \right\|^{2}\] \[+\lambda\left(1-\frac{\tau}{4}\right)\left\|v^{t}-\nabla f(z^{t}) \right\|^{2}\] \[+\kappa\left(1-\frac{\beta}{4}\right)\left(\frac{1}{n}\sum_{i=1}^{n }\left\|h_{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}\right).\]Let us separately analyze the terms w.r.t. \(D_{f}(z^{t},y^{t+1})\) and \(\mathbb{E}_{t}\left[\left\|u^{t+1}-u^{t}\right\|^{2}\right]\):

**Lemma E.11** (Second Symbolically Computed).: _Consider the parameters \(\rho,\,\kappa,\,\lambda,\) and \(\nu_{t}\) from Lemma E.10. Assume that for the parameter \(\bar{L},\) the inequalities from Sections L and N hold, and the step size \(\theta_{t+1}\leq\nicefrac{{1}}{{4}}\) for all \(t\geq 0.\) Then, for all \(t\geq 0,\) the following inequalities are satisfied:_

\[\begin{split}& p\left(\frac{4\omega L_{\max}}{n\bar{L}}+\kappa 8\left(1+\frac{p}{\beta}\right)L_{\max}+\nu_{t}\left(\frac{\gamma_{t+1}}{L+ \Gamma_{t+1}\mu}\right)^{2}\left(\frac{4\omega L_{\max}}{pn}+\frac{8L}{p \alpha}\right)+\rho 8L+\\ &\qquad\qquad\qquad+\,\lambda\left(4\left(1+\frac{2p}{\tau} \right)L+\frac{8\tau^{2}\omega L_{\max}}{n}\right)+\theta_{t+1}-1\right)D_{f}( z^{t},y^{t+1})\leq 0\end{split}\] (47)

_and_

\[\begin{split}& 2\theta_{t+1}^{2}\left(\frac{pL}{2}+\kappa 4p \left(1+\frac{p}{\beta}\right)\tilde{L}^{2}+\rho 4pL^{2}+\lambda\left(2p\left(1+ \frac{2p}{\tau}\right)L^{2}+\frac{4p\tau^{2}\omega\tilde{L}^{2}}{n}\right) \right)\mathbb{E}_{t}\left[\left\|u^{t+1}-u^{t}\right\|^{2}\right]\\ &\quad-\frac{p\theta_{t+1}^{2}\bar{L}}{2}\mathbb{E}_{t}\left[ \left\|u^{t+1}-u^{t}\right\|^{2}\right]\leq 0.\end{split}\] (48)

We prove Lemma E.11 in Section H. Using the lemma, we get

\[\begin{split}&\mathbb{E}_{t}\left[f(z^{t+1})-f(x^{*})\right]+ \kappa\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t+1}-\nabla f _{i}(z^{t+1})\right\|^{2}\right]+\nu_{t}\mathbb{E}_{t}\left[\left\|w^{t+1}-u^{ t+1}\right\|^{2}\right]\\ &\quad+\rho\mathbb{E}_{t}\left[\left\|k^{t+1}-\nabla f(z^{t+1}) \right\|^{2}\right]+\lambda\mathbb{E}_{t}\left[\left\|v^{t+1}-\nabla f(z^{t+1 })\right\|^{2}\right]\\ &\leq\left(1-p\theta_{t+1}\right)\left(f(z^{t})-f(x^{*})\right) \\ &\quad+p\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+ 1}}\left\|u^{t}-x^{*}\right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+1} }\mathbb{E}_{t}\left[\left\|u^{t+1}-x^{*}\right\|^{2}\right]\right)\\ &\quad+\nu_{t}\left(1-\frac{\alpha}{4}\right)\left\|w^{t}-u^{t} \right\|^{2}\\ &\quad+\rho\left(1-\frac{p}{2}\right)\left\|k^{t}-\nabla f(z^{t}) \right\|^{2}\\ &\quad+\lambda\left(1-\frac{\tau}{4}\right)\left\|v^{t}-\nabla f (z^{t})\right\|^{2}\\ &\quad+\kappa\left(1-\frac{\beta}{4}\right)\left(\frac{1}{n}\sum_ {i=1}^{n}\left\|h_{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}\right).\end{split}\]

Note that \(0\leq\nu_{t+1}\leq\nu_{t}\) for all \(t\geq 0,\) since \(\theta_{t+1}\) is a non-increasing sequence (see Lemma E.1 and the definition of \(\nu_{t}\) in (83)). Using

\[\theta_{t+1}\leq\frac{1}{4}\min\left\{1,\frac{\alpha}{p},\frac{\tau}{p},\frac{ \beta}{p}\right\}\]

for all \(t\geq 0,\) we obtain

\[\begin{split}&\mathbb{E}_{t}\left[f(z^{t+1})-f(x^{*})\right]+ \kappa\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t+1}-\nabla f _{i}(z^{t+1})\right\|^{2}\right]+\nu_{t+1}\mathbb{E}_{t}\left[\left\|w^{t+1}- u^{t+1}\right\|^{2}\right]\\ &\quad+\rho\mathbb{E}_{t}\left[\left\|k^{t+1}-\nabla f(z^{t+1}) \right\|^{2}\right]+\lambda\mathbb{E}_{t}\left[\left\|v^{t+1}-\nabla f(z^{t+1 })\right\|^{2}\right]\\ &\leq(1-p\theta_{t+1})\Bigg{(}f(z^{t})-f(x^{*})+\kappa\left( \frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{t}-\nabla f_{i}(z^{t})\right\|^{2} \right)+\nu_{t}\left\|w^{t}-u^{t}\right\|^{2}\\ &\qquad\qquad\qquad\qquad+\rho\left\|k^{t}-\nabla f(z^{t})\right\| ^{2}+\lambda\left\|v^{t}-\nabla f(z^{t})\right\|^{2}\Bigg{)}\end{split}\]\[+p\theta_{t+1}\left(\frac{\bar{L}+\Gamma_{t}\mu}{2\gamma_{t+1}} \left\|u^{t}-x^{*}\right\|^{2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2\gamma_{t+1}} \mathbb{E}_{t}\left[\left\|u^{t+1}-x^{*}\right\|^{2}\right]\right).\]

Let us multiply the inequality by \(\frac{\gamma_{t+1}}{p\theta_{t+1}}:\)

\[\frac{\gamma_{t+1}}{p\theta_{t+1}}\left(\mathbb{E}_{t}\left[f(z^ {t+1})-f(x^{*})\right]+\kappa\mathbb{E}_{t}\left[\frac{1}{n}\sum_{i=1}^{n} \left\|h_{i}^{t+1}-\nabla f_{i}(z^{t+1})\right\|^{2}\right]+\nu_{t+1}\mathbb{E }_{t}\left[\left\|w^{t+1}-u^{t+1}\right\|^{2}\right]\right.\] \[\left.\quad+\rho\mathbb{E}_{t}\left[\left\|k^{t+1}-\nabla f(z^{t +1})\right\|^{2}\right]+\lambda\mathbb{E}_{t}\left[\left\|v^{t+1}-\nabla f(z^ {t+1})\right\|^{2}\right]\right)\] \[\leq\left(\frac{\gamma_{t+1}}{p\theta_{t+1}}-\gamma_{t+1} \right)\left(f(z^{t})-f(x^{*})+\kappa\left(\frac{1}{n}\sum_{i=1}^{n}\left\|h_ {i}^{t}-\nabla f_{i}(z^{t})\right\|^{2}\right)+\nu_{t}\left\|w^{t}-u^{t} \right\|^{2}\] \[\left.\quad\quad\quad\quad\quad\quad\quad+\rho\left\|k^{t}- \nabla f(z^{t})\right\|^{2}+\lambda\left\|v^{t}-\nabla f(z^{t})\right\|^{2}\right)\] \[+\left(\frac{\bar{L}+\Gamma_{t}\mu}{2}\left\|u^{t}-x^{*}\right\|^ {2}-\frac{\bar{L}+\Gamma_{t+1}\mu}{2}\mathbb{E}_{t}\left[\left\|u^{t+1}-x^{*} \right\|^{2}\right]\right).\]

It is left to use that \(\Gamma_{t+1}:=\Gamma_{t}+\gamma_{t+1}\) and \(\gamma_{t+1}=p\theta_{t+1}\Gamma_{t+1}\) (see Lemma E.1) and take the full expectation to obtain (45).

In the proof we require that, for the parameter \(\bar{L}\), the inequalities from Sections I, J, L and N hold. In Section O, we show that these inequalities follow from (44). 

### Strongly-convex case

**Theorem E.12**.: _Suppose that Assumptions 1.2, 1.1, 1.3, 2.4 hold. Let_

\[\bar{L}=660508\times\max\left\{\frac{L}{\alpha},\frac{Lp}{\alpha\tau},\frac{ \sqrt{LL_{\max}}p\sqrt{\omega\tau}}{\alpha\beta\sqrt{n}},\frac{\sqrt{LL_{\max} }\sqrt{p}\sqrt{\omega\tau}}{\alpha\sqrt{\beta}\sqrt{n}},\frac{L_{\max}\omega p ^{2}}{\beta^{2}n},\frac{L_{\max}\omega}{n}\right\},\] (49)

\(\beta=\frac{1}{\omega+1},\,\theta_{\min}=\frac{1}{4}\min\left\{1,\frac{\alpha} {p},\frac{\tau}{p},\frac{\beta}{p}\right\},\,h_{i}^{0}=\nabla f_{i}(z^{0})\) _for all_ \(i\in[n],\,w^{0}=u^{0},\,k^{0}=\nabla f(z^{0}),\)__\(v^{0}=\nabla f(z^{0}),\) _and_ \(\Gamma_{0}\geq 1\)_. Then Algorithm 1 guarantees that_

\[\mathbb{E}\left[f(z^{T})-f(x^{*})\right]+\frac{\mu}{2}\mathbb{E}\left[\left\|u ^{T}-x^{*}\right\|^{2}\right]\leq 2\exp\left(-\frac{T}{Q}\right)\left(\left(f(z^{0})-f(x^ {*})\right)+\left(\frac{\bar{L}}{\Gamma_{0}}+\mu\right)\left\|u^{0}-x^{*} \right\|^{2}\right),\] (50)

_where_

\[Q:=2\times\sqrt{660508}\times\] \[\max\left\{\sqrt{\frac{L}{\alpha p\mu}},\sqrt{\frac{L}{\alpha \tau\mu}},\sqrt{\frac{\sqrt{LL_{\max}}(\omega+1)\sqrt{\omega\tau}}{\alpha \sqrt{n}\mu}},\sqrt{\frac{\sqrt{LL_{\max}}\sqrt{\omega+1}\sqrt{\omega\tau}}{ \alpha\sqrt{p}\sqrt{n}\mu}},\sqrt{\frac{L_{\max}\omega(\omega+1)^{2}p}{n\mu}},\sqrt{\frac{L_{\max}\omega}{np\mu}},\] \[\frac{1}{\alpha},\frac{1}{\tau},(\omega+1),\frac{1}{p}\right\}.\]

_Remark E.13_.: Up to a constant factor of \(2\), one can see that the optimal \(\Gamma_{0}\) in (50) from Theorem E.12 equals \(\Gamma_{0}=\nicefrac{{L}}{{\mu}}\). But the dependence on \(\Gamma_{0}\) is under the logarithm, so if the dependence on the logarithm is not critical, one can take any \(\Gamma_{0}\geq 1\).

Proof.: All conditions from Theorem E.9 are satisfied. Let us sum the inequality (45) for \(t=0\) to \(T-1:\)

\[\Gamma_{T}\left(\mathbb{E}\left[f(z^{T})-f(x^{*})\right]+\kappa \mathbb{E}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{T}-\nabla f_{i}(z^{T}) \right\|^{2}\right]+\nu_{T}\mathbb{E}\left[\left\|w^{T}-u^{T}\right\|^{2}\right]\right.\] \[\left.\quad+\rho\mathbb{E}\left[\left\|k^{T}-\nabla f(z^{T}) \right\|^{2}\right]+\lambda\mathbb{E}\left[\left\|v^{T}-\nabla f(z^{T})\right\|^ {2}\right]\right)\]\[\leq\Gamma_{0}\Bigg{(}\mathbb{E}\left[f(z^{0})-f(x^{*})\right]+ \kappa\mathbb{E}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{0}-\nabla f_{i}(z^{0 })\right\|^{2}\right]+\nu_{0}\mathbb{E}\left[\left\|w^{0}-u^{0}\right\|^{2}\right]\] \[\qquad\qquad+\rho\mathbb{E}\left[\left\|k^{0}-\nabla f(z^{0}) \right\|^{2}\right]+\lambda\mathbb{E}\left[\left\|v^{0}-\nabla f(z^{0}) \right\|^{2}\right]\Bigg{)}\] \[+\left(\frac{\bar{L}+\Gamma_{0}\mu}{2}\mathbb{E}\left[\left\|u^{ 0}-x^{*}\right\|^{2}\right]-\frac{\bar{L}+\Gamma_{T}\mu}{2}\mathbb{E}\left[ \left\|u^{T}-x^{*}\right\|^{2}\right]\right).\]

Using the initial conditions and the non-negativity of the terms, we get

\[\Gamma_{T}\mathbb{E}\left[f(z^{T})-f(x^{*})\right]+\frac{\Gamma_{T}\mu}{2} \mathbb{E}\left[\left\|u^{T}-x^{*}\right\|^{2}\right]\leq\Gamma_{0}\left(f(z^ {0})-f(x^{*})\right)+\frac{\bar{L}+\Gamma_{0}\mu}{2}\left\|u^{0}-x^{*}\right\| ^{2}.\]

Using Lemma E.1, we have

\[\mathbb{E}\left[f(z^{T})-f(x^{*})\right]+\frac{\mu}{2}\mathbb{E} \left[\left\|u^{T}-x^{*}\right\|^{2}\right]\] \[\leq\exp\left(-T\min\left\{\sqrt{\frac{p\mu}{4\bar{L}}},p\theta_{ \min}\right\}\right)\left(2\left(f(z^{0})-f(x^{*})\right)+\left(\frac{\bar{L} }{\Gamma_{0}}+\mu\right)\left\|u^{0}-x^{*}\right\|^{2}\right).\]

It is left to use the definitions of \(\bar{L}\) and \(\theta_{\min}\). 

### General convex case

Let us use Theorem E.9 to analyze the general convex case (\(\mu\) can possibly be equal to zero):

**Theorem E.14**.: _Suppose that Assumptions 1.2, 1.1, 1.3, 2.4 hold. Let_

\[\bar{L}=660508\times\max\left\{\frac{L}{\alpha},\frac{Lp}{\alpha\tau},\frac{ \sqrt{LL_{\max}}p\sqrt{\omega\tau}}{\alpha\sqrt{\beta}n},\frac{\sqrt{LL_{\max} }\sqrt{p}\sqrt{\omega\tau}}{\alpha\sqrt{\beta}\sqrt{n}},\frac{L_{\max}\omega p^ {2}}{\beta^{2}n},\frac{L_{\max}\omega}{n}\right\},\] (51)

\(\beta=\frac{1}{\omega+1},\,\theta_{\min}=\frac{1}{4}\min\left\{1,\frac{\alpha }{p},\frac{\tau}{p},\frac{\beta}{p}\right\},\,h_{i}^{0}=\nabla f_{i}(z^{0})\) _for all_ \(i\in[n],\,w^{0}=u^{0},\,k^{0}=\nabla f(z^{0}),\)__\(v^{0}=\nabla f(z^{0}),\) _and_ \(\Gamma_{0}\in[1,\nicefrac{{L}}{{L}}]\)_. Then Algorithm 1 returns_ \(\varepsilon\)_-solution, i.e.,_ \(\mathbb{E}\left[f(z^{T})\right]-f(x^{*})\leq\varepsilon,\) _after_

\[T=\begin{cases}\Theta\left(\frac{1}{p\theta_{\min}}\log\frac{\bar{L}\left\|z^ {0}-x^{*}\right\|^{2}}{\Gamma_{0}\varepsilon}\right),&\frac{\bar{L}\left\|z^ {0}-x^{*}\right\|^{2}}{\varepsilon}<\frac{1}{p\theta_{\min}^{2}}\\ \Theta\left(\max\left\{\frac{1}{p\theta_{\min}}\log\frac{1}{\Gamma_{0}p \theta_{\min}^{2}},0\right\}+Q\sqrt{\frac{\left\|z^{0}-x^{*}\right\|^{2}}{ \varepsilon}}\right),&\text{otherwise}\end{cases}\] (52)

_iterations, where_

\[Q:=\Theta\left(\max\left\{\sqrt{\frac{L}{\alpha p}},\sqrt{\frac{L}{\alpha\tau} },\sqrt{\frac{\sqrt{LL_{\max}}(\omega+1)\sqrt{\omega\tau}}{\alpha\sqrt{n}}}, \sqrt{\frac{\sqrt{LL_{\max}}\sqrt{\omega+1}\sqrt{\omega\tau}}{\alpha\sqrt{p} \sqrt{n}}},\sqrt{\frac{L_{\max}\omega(\omega+1)^{2}p}{n}},\sqrt{\frac{L_{\max }\omega}{np}}\right\}\right).\]

_Remark E.15_.: One can see that the optimal \(\Gamma_{0}\) in (52) from Theorem E.14 equals \(\Gamma_{0}=\nicefrac{{L}}{{L}}\). But the dependence on \(\Gamma_{0}\) is under the logarithm, so if the dependence on the logarithm is not critical, one can take any \(\Gamma_{0}\in[1,\nicefrac{{L}}{{L}}]\).

Proof.: All conditions from Theorem E.9 are satisfied. Let us sum the inequality (45) for \(t=0\) to \(T-1:\)

\[\Gamma_{T}\left(\mathbb{E}\left[f(z^{T})-f(x^{*})\right]+\kappa \mathbb{E}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{T}-\nabla f_{i}(z^{T}) \right\|^{2}\right]+\nu_{T}\mathbb{E}\left[\left\|w^{T}-u^{T}\right\|^{2}\right]\] \[\quad+\rho\mathbb{E}\left[\left\|k^{T}-\nabla f(z^{T})\right\|^{2 }\right]+\lambda\mathbb{E}\left[\left\|v^{T}-\nabla f(z^{T})\right\|^{2} \right]\right)\] \[\leq\Gamma_{0}\Bigg{(}\mathbb{E}\left[f(z^{0})-f(x^{*})\right]+ \kappa\mathbb{E}\left[\frac{1}{n}\sum_{i=1}^{n}\left\|h_{i}^{0}-\nabla f_{i}(z^ {0})\right\|^{2}\right]+\nu_{0}\mathbb{E}\left[\left\|w^{0}-u^{0}\right\|^{2}\right]\]\[+\rho\mathbb{E}\left[\left\|k^{0}-\nabla f(z^{0})\right\|^{2} \right]+\lambda\mathbb{E}\left[\left\|v^{0}-\nabla f(z^{0})\right\|^{2}\right]\] \[+\left(\frac{\bar{L}+\Gamma_{0}\mu}{2}\mathbb{E}\left[\left\|u^{0} -x^{*}\right\|^{2}\right]-\frac{\bar{L}+\Gamma_{T}\mu}{2}\mathbb{E}\left[ \left\|u^{T}-x^{*}\right\|^{2}\right]\right).\]

Using the initial conditions, the non-negativity of the terms, and \(\Gamma_{0}\leq\nicefrac{{L}}{{L}}\), we get

\[\Gamma_{T}\mathbb{E}\left[f(z^{T})-f(x^{*})\right] \leq\Gamma_{0}\left(f(z^{0})-f(x^{*})\right)+\frac{\bar{L}+\Gamma _{0}\mu}{2}\left\|u^{0}-x^{*}\right\|^{2}\] \[\leq\frac{\bar{L}}{L}\left(f(z^{0})-f(x^{*})\right)+\bar{L} \left\|z^{0}-x^{*}\right\|^{2}.\]

Using the \(L\)-smoothness and \(\mu\leq L\leq\bar{L}\), we have

Using Lemma E.1, we have

\[\begin{cases}\frac{\Gamma_{0}}{2}\exp\left(tp\theta_{\min}\right)\mathbb{E} \left[f(z^{T})-f(x^{*})\right]\leq 2\bar{L}\left\|z^{0}-x^{*}\right\|^{2},&t< \bar{t}\\ \frac{p(t-\bar{t})^{2}}{16}\mathbb{E}\left[f(z^{T})-f(x^{*})\right]\leq 2 \bar{L}\left\|z^{0}-x^{*}\right\|^{2},&t\geq\bar{t},\end{cases}\]

where \(\bar{t}:=\max\left\{\left\lceil\frac{1}{p\theta_{\min}^{\text{min}}}\log\frac{ 1}{2\Gamma_{0}p\theta_{\min}^{\text{min}}}\right\rceil,0\right\}.\) The last inequalities guarantees that Algorithm 1 returns \(\varepsilon\)-solution after (52) iterations.

### Choosing optimal parameters

**Theorem 5.2**.: _Choose \(r\in[0,1]\) and let \(\mu_{\omega,\alpha}^{r}:=\frac{rd}{(1-r)K_{\omega}+rK_{\alpha}}\). In view of Theorem 5.1, the values \(p=\min\left\{\frac{1}{\omega+1},\frac{1}{\mu_{\omega,\alpha}^{r}}\right\}\) and \(\tau=\frac{p^{1/3}}{(\omega+1)^{2/3}}\) minimize \(\max\limits_{L_{\max}\in[L,nL]}\mathfrak{m}_{\text{\tiny{new}}}^{r}\). This choice leads to the following number of communication rounds:_

\[T^{\text{\tiny{realistic}}}:=\widetilde{\Theta}\Bigg{(}\max\left\{\sqrt{\frac{L \max\left(\omega+1,\mu_{\omega,\alpha}^{r}\right)}{\alpha\mu}},\sqrt{\frac{L_ {\max}\omega\max\left(\omega+1,\mu_{\omega,\alpha}^{r}\right)}{n\mu}},\frac{1} {\alpha},(\omega+1),\mu_{\omega,\alpha}^{r}\right\}\Bigg{)}.\] (13)

_The total communication complexity thus equals \(\mathfrak{m}_{\text{\tiny{subsize}}}^{r}=\widetilde{\Theta}\left(\left((1-r) K_{\omega}+rK_{\alpha}\right)T_{\text{\tiny{finite}}}+d\right).\)_

Proof.: We implicitly assume that \(p\in(0,1]\) and \(\tau\in(0,1]\). Using (12) and (4), we have

\[\operatorname*{arg\,min}_{p,\tau}\max_{L_{\max}\in[L,nL]}\mathfrak{m}_{\text{ \tiny{new}}}^{r}=\operatorname*{arg\,min}_{p,\tau}\max_{L_{\max}\in[L,nL]} \widetilde{\Theta}\left((1-r)K_{\omega}T+r\left(K_{\alpha}+pd\right)T\right).\]

Note that only \(T\) depends on \(L_{\max}\) and \(\tau\). We have

\[\min_{\tau}\max_{L_{\max}\in[L,nL]}T\] \[\overset{\eqref{eq:T_max}}{=}\min_{\tau}\max_{L_{\max}\in[L,nL]} \widetilde{\Theta}\Bigg{(}\max\left\{\sqrt{\frac{L}{\alpha p\mu}},\sqrt{\frac{L }{\alpha\tau\mu}},\sqrt{\frac{\sqrt{LL_{\max}}(\omega+1)\sqrt{\omega\tau}}{ \alpha\sqrt{n}\mu}},\right.\] \[\left.\sqrt{\frac{\sqrt{LL_{\max}}\sqrt{\omega+1}\sqrt{\omega\tau }}{\alpha\sqrt{p}\sqrt{n}\mu}},\sqrt{\frac{L_{\max}\omega(\omega+1)^{2}p}{n \mu}},\sqrt{\frac{L_{\max}\omega}{np\mu}},\frac{1}{\alpha},\frac{1}{\tau},( \omega+1),\frac{1}{p}\right\}\Bigg{)}\] \[=\min_{\tau}\widetilde{\Theta}\Bigg{(}\max\left\{\sqrt{\frac{L} {\alpha p\mu}},\sqrt{\frac{L}{\alpha\tau\mu}},\sqrt{\frac{L(\omega+1)\sqrt{ \omega\tau}}{\alpha\mu}},\sqrt{\frac{L\sqrt{\omega+1}\sqrt{\omega\tau}}{\alpha \sqrt{p}\mu}},\sqrt{\frac{L\omega(\omega+1)^{2}p}{\mu}},\sqrt{\frac{L\omega}{p \mu}},\right.\] \[\left.\frac{1}{\alpha},\frac{1}{\tau},(\omega+1),\frac{1}{p} \right\}\Bigg{)}\]The last term attains the minimum when

\[\tau=\min\left\{\frac{1}{\omega+1},\frac{p^{1/3}}{(\omega+1)^{2/3}}\right\}.\] (53)

Therefore, we get

\[\begin{split}& T^{\prime}:=\min_{\tau}\max_{L_{\max}\in[L,nL]}T\\ &=\widetilde{\Theta}\Bigg{(}\max\left\{\sqrt{\frac{L}{\alpha p \mu}},\sqrt{\frac{L(\omega+1)}{\alpha\mu}},\sqrt{\frac{L(\omega+1)^{2/3}}{ \alpha p^{1/3}\mu}},\sqrt{\frac{L\omega(\omega+1)^{2}p}{\mu}},\sqrt{\frac{L \omega}{p\mu}},\frac{1}{\alpha},(\omega+1),\frac{1}{p}\right\}\Bigg{)},\end{split}\] (54)

where we use that

\[\frac{1}{\tau}=\max\left\{\omega+1,\frac{(\omega+1)^{2/3}}{p^{1/3}}\right\} \leq\max\left\{\omega+1,\frac{2}{3}\left(\omega+1\right)+\frac{1}{3p}\right\} =\Theta\left(\max\left\{\left(\omega+1\right),\frac{1}{p}\right\}\right).\]

It is left to find

\[\arg\min_{p}\left(\min_{\tau}\max_{L_{\max}\in[L,nL]}\mathfrak{m} _{\infty}^{r}\right) =\arg\min_{p}\widetilde{\Theta}\left((1-r)K_{\omega}T^{\prime}+r \left(K_{\alpha}+pd\right)T^{\prime}\right)\] \[=\arg\min_{p}\widetilde{\Theta}\left(A\times T^{\prime}+B\times pT ^{\prime}\right),\] (55)

where \(A:=(1-r)K_{\omega}+rK_{\alpha}\geq 0\) and \(B:=rd\geq 0\). Note that \(A\) and \(B\) do not depend on \(p\). If \(p\geq\nicefrac{{A}}{{B}}\), then \(\widetilde{\Theta}\left(AT^{\prime}+BpT^{\prime}\right)=\widetilde{\Theta} \left(BpT^{\prime}\right).\) The term \(pT^{\prime}\) is non-decreasing function w.r.t. \(p\). For \(p\geq\nicefrac{{A}}{{B}}\), it means that an optimal point \(p=\nicefrac{{A}}{{B}}\). Thus the argmin (55) is equivalent to

\[\arg\min_{p\in Q_{0}}\widetilde{\Theta}\left(A\times T^{\prime}+B\times pT^{ \prime}\right)=\arg\min_{p\in Q_{0}}\widetilde{\Theta}\left(T^{\prime}\right),\]

where \(Q_{0}:=\left\{p\,\big{|}\,p\leq\frac{A}{B}\right\}.\) Thus, we have

\[\arg\min_{p\in Q_{0}}\widetilde{\Theta}\Bigg{(}\max\left\{\sqrt{\frac{L}{ \alpha p\mu}},\sqrt{\frac{L(\omega+1)}{\alpha\mu}},\sqrt{\frac{L(\omega+1)^{2 /3}}{\alpha p^{1/3}\mu}},\sqrt{\frac{L\omega(\omega+1)^{2}p}{\mu}},\sqrt{ \frac{L\omega}{p\mu}},\frac{1}{\alpha},(\omega+1),\frac{1}{p}\right\}\Bigg{)}.\]

The next observation is that this argmin is non-decreasing when \(p\geq\nicefrac{{1}}{{\omega+1}}\). It means that the minimum attains at some point \(p\in Q_{1}:=\left\{p\,\big{|}\,p\leq\nicefrac{{1}}{{\omega+1}},p\in Q_{0}\right\}\). Using this information, we can eliminate the redundant terms (for instance, \(A\sqrt{\frac{L(\omega+1)}{\alpha\mu}}\leq A\sqrt{\frac{L}{\alpha p\mu}}\) for \(p\in Q_{1}\)) and get an equivalent argmin

\[\arg\min_{p\in Q_{1}}\widetilde{\Theta}\Bigg{(}\max\left\{\sqrt{\frac{L}{ \alpha p\mu}},\sqrt{\frac{L\omega}{p\mu}},\frac{1}{\alpha},\frac{1}{p}\right\} \Bigg{)},\]

The last term attains the minimum at

\[p=\min\left\{\frac{1}{\omega+1},\frac{A}{B}\right\}.\] (56)

Using (56) and (53), an optimal \(\tau\) is

\[\tau=\frac{p^{1/3}}{(\omega+1)^{2/3}}.\] (57)

We substitute (56) and (57) to (10) and obtain (13). We use Lemma 1.4 to eliminate the redundant terms. Note that \(\mu_{\omega,\alpha}^{r}:=\nicefrac{{B}}{{A}}\).

Using (12) and (56), we have

\[\mathfrak{m}_{\text{\tiny{ranking}}}^{r}=(1-r)K_{\omega}T_{\text{\tiny{ranking}}}+r \left(K_{\alpha}+pd\right)T_{\text{\tiny{ranking}}}+d\]\[\leq(1-r)K_{\omega}T_{\text{\tiny{noise}}}+r\left(K_{\alpha}+\frac{(1-r)K_{ \omega}+rK_{\alpha}}{rd}d\right)T_{\text{\tiny{noise}}}+d\] \[=2(1-r)K_{\omega}T_{\text{\tiny{noise}}}+2rK_{\alpha}T_{\text{ \tiny{noise}}}+d.\]

Note that

\[\mathfrak{m}_{\text{\tiny{noise}}}^{r} =(1-r)K_{\omega}T_{\text{\tiny{noise}}}+r\left(K_{\alpha}+pd \right)T_{\text{\tiny{noise}}}+d\] \[\geq(1-r)K_{\omega}T_{\text{\tiny{noise}}}+rK_{\alpha}T_{\text {\tiny{noise}}}+d.\]

**Theorem 5.4**.: _Choose \(r\in[0,1],\) and let \(\mu_{\omega,\alpha}^{r}:=\frac{rd}{(1-r)K_{\omega}+rK_{\alpha}}.\) In view of Theorem 5.1, the values \(p\) and \(\tau\) given by (63) and (58), respectively, minimize \(\mathfrak{m}_{\text{\tiny{noise}}}^{r}\) from (10). This choice leads to the following number of communication rounds:_

\[\begin{split} T^{\text{\tiny{optimistic}}}&=\widetilde {\Theta}\Bigg{(}\max\left\{\sqrt{\frac{L\max\{1,\mu_{\omega,\alpha}^{r}\}}{ \alpha\mu}},\sqrt{\frac{L^{2/3}L_{\max}^{1/3}(\omega+1)}{\alpha n^{1/3}\mu}}, \sqrt{\frac{L^{1/2}L_{\max}^{1/2}(\omega+1)^{3/2}}{\sqrt{\alpha n\mu}}},\\ &\sqrt{\frac{L_{\max}\omega\max\{\omega+1,\mu_{\omega,\alpha}^{r} \}}{n\mu}},\frac{1}{\alpha},(\omega+1),\mu_{\omega,\alpha}^{r}\Bigg{\}}\Bigg{)}.\end{split}\] (14)

_The total communication complexity thus equals \(\mathfrak{m}_{\text{\tiny{optimistic}}}^{r}=\widetilde{\Theta}\left(((1-r)K_{ \omega}+rK_{\alpha})\,T_{\text{\tiny{optimistic}}}+d\right).\)_

Proof.: We implicitly assume that \(p\in(0,1]\) and \(\tau\in(0,1].\) We start the proof as in Theorem 5.2. Using (12) and (4), we have

\[\operatorname*{arg\,min}_{p,\tau}\mathfrak{m}_{\text{\tiny{noise}}}^{r}= \operatorname*{arg\,min}_{p,\tau}\widetilde{\Theta}\left((1-r)K_{\omega}T+r \left(K_{\alpha}+pd\right)T\right).\]

Unlike Theorem 5.2, we know the ratio \(L_{\max}/L,\) thus

\[\min_{\tau}T\] (58) \[\qquad\qquad\qquad\qquad\sqrt{\frac{\sqrt{LL_{\max}\sqrt{\omega+1 }\sqrt{\omega\tau}}}{\alpha\sqrt{p}\sqrt{n\mu}}},\sqrt{\frac{L_{\max}\omega( \omega+1)^{2}p}{n\mu}},\sqrt{\frac{L_{\max}\omega}{np\mu}},\frac{1}{\alpha}, \frac{1}{\tau},(\omega+1),\frac{1}{p}\Bigg{\}}\Bigg{)}\]

The last term attains the minimum when

\[\tau=\min\left\{1,\left(\frac{Ln}{L_{\max}}\right)^{1/3}\min\left\{\frac{1}{ \omega+1},\frac{p^{1/3}}{(\omega+1)^{2/3}}\right\}\right\}.\] (59)

Therefore, we get

\[\begin{split}& T^{\prime}:=\min_{\tau}T\\ &=\widetilde{\Theta}\Bigg{(}\max\left\{\sqrt{\frac{L}{\alpha p \mu}},\sqrt{\frac{L^{2/3}L_{\max}^{1/3}(\omega+1)}{\alpha n^{1/3}\mu}},\sqrt{ \frac{L^{2/3}L_{\max}^{1/3}(\omega+1)^{2/3}}{\alpha n^{1/3}p^{1/3}\mu}},\sqrt{ \frac{L_{\max}\omega(\omega+1)^{2}p}{n\mu}},\sqrt{\frac{L_{\max}\omega}{np\mu} },\frac{1}{\alpha},\omega+1,\frac{1}{p}\Bigg{\}}\Bigg{)}.\end{split}\] (60)

It is left to find

\[\operatorname*{arg\,min}_{p}\left(\min_{\tau}\mathfrak{m}_{\text{ \tiny{noise}}}^{r}\right) =\operatorname*{arg\,min}_{p}\widetilde{\Theta}\left((1-r)K_{\omega }T^{\prime}+r\left(K_{\alpha}+pd\right)T^{\prime}\right)\] \[=\operatorname*{arg\,min}_{p}\widetilde{\Theta}\left(A\times T^{ \prime}+B\times pT^{\prime}\right),\] (61)

where \(A:=(1-r)K_{\omega}+rK_{\alpha}\geq 0\) and \(B:=rd\geq 0.\) Note that \(A\) and \(B\) do not depend on \(p.\) If \(p\geq\nicefrac{{A}}{{B}},\) then \(\widetilde{\Theta}\left(AT^{\prime}+BpT^{\prime}\right)=\widetilde{\Theta} \left(BpT^{\prime}\right).\) The term \(pT^{\prime}\) is non-decreasing function w.r.t. \(p.\) For \(p\geq\nicefrac{{A}}{{B}},\) it means that an optimal point \(p=\nicefrac{{A}}{{B}}.\) Thus the argmin (61) is equivalent to

\[\operatorname*{arg\,min}_{p\in Q_{0}}\widetilde{\Theta}\left(A\times T^{ \prime}+B\times pT^{\prime}\right)=\operatorname*{arg\,min}_{p\in Q_{0}} \widetilde{\Theta}\left(T^{\prime}\right),\]where \(Q_{0}:=\left\{p\left|\,p\leq\frac{A}{B}\right.\right\}.\) Next, we have

\[\mathop{\arg\min}_{p\in Q_{0}}\widetilde{\Theta}\left(T^{\prime}\right)\] \[=\mathop{\arg\min}_{p\in Q_{0}}\] \[\widetilde{\Theta}\Bigg{(}\max\Bigg{\{}\sqrt{\frac{L}{\alpha p \mu}},\sqrt{\frac{L^{2/3}L_{\max}^{1/3}(\omega+1)}{\alpha n^{1/3}\mu}},\sqrt{ \frac{L^{2/3}L_{\max}^{1/3}(\omega+1)^{2/3}}{\alpha n^{1/3}p^{1/3}\mu}},\sqrt {\frac{L_{\max}\omega(\omega+1)^{2}p}{n\mu}},\sqrt{\frac{L_{\max}\omega}{np\mu} },\frac{1}{\alpha},(\omega+1),\frac{1}{p}\Bigg{\}}\Bigg{)}.\] (61)

For \(p\geq\left(\frac{Ln}{L_{\max}}\right)^{1/3}\frac{1}{\omega+1},\) using Lemma 1.4, we have \(p\geq\frac{1}{\omega+1},\)

\[\sqrt{\frac{L}{\alpha p\mu}}\leq\sqrt{\frac{L^{2/3}L_{\max}^{1/3 }(\omega+1)}{\alpha n^{1/3}\mu}},\] \[\sqrt{\frac{L^{2/3}L_{\max}^{1/3}(\omega+1)^{2/3}}{\alpha n^{1/3 }p^{1/3}\mu}}\leq\sqrt{\frac{L^{2/3}L_{\max}^{1/3}(\omega+1)}{\alpha n^{1/3} \mu}}\] \[\sqrt{\frac{L_{\max}\omega}{np\mu}}\leq\sqrt{\frac{L_{\max} \omega(\omega+1)^{2}p}{n\mu}}\] \[\frac{1}{p}\leq\left(\frac{L_{\max}}{Ln}\right)^{1/3}(\omega+1) \leq(\omega+1).\]

It means that for \(p\geq\left(\frac{Ln}{L_{\max}}\right)^{1/3}\frac{1}{\omega+1},\) the argmin (61) is equivalent to

\[\mathop{\arg\min}_{p\in Q_{0}}\widetilde{\Theta}\Bigg{(}\max\Bigg{\{}\sqrt{ \frac{L^{2/3}L_{\max}^{1/3}(\omega+1)}{\alpha n^{1/3}\mu}},\sqrt{\frac{L_{ \max}\omega(\omega+1)^{2}p}{n\mu}},\frac{1}{\alpha},(\omega+1)\Bigg{\}}\Bigg{)}.\]

Since all terms are non-increasing functions of \(p,\) the minimum is attained at a point \(p=\left(\frac{Ln}{L_{\max}}\right)^{1/3}\frac{1}{\omega+1}\) for all \(p\geq\left(\frac{Ln}{L_{\max}}\right)^{1/3}\frac{1}{\omega+1}\). Let us define

\[Q_{1}:=\left\{p\left|\,p\leq\left(\frac{Ln}{L_{\max}}\right)^{1/3}\frac{1}{ \omega+1},p\in Q_{0}\right\}.\]

The last observation means that the argmin (61) is equivalent to

\[\mathop{\arg\min}_{p\in Q_{1}}\] \[\widetilde{\Theta}\Bigg{(}\max\Bigg{\{}\sqrt{\frac{L}{\alpha p\mu }},\sqrt{\frac{L^{2/3}L_{\max}^{1/3}(\omega+1)}{\alpha n^{1/3}\mu}},\sqrt{ \frac{L^{2/3}L_{\max}^{1/3}(\omega+1)^{2/3}}{\alpha n^{1/3}p^{1/3}\mu}},\sqrt {\frac{L_{\max}\omega(\omega+1)^{2}p}{n\mu}},\sqrt{\frac{L_{\max}\omega}{np\mu }},\frac{1}{\alpha},(\omega+1),\frac{1}{p}\Bigg{\}}\Bigg{)}\] \[=\mathop{\arg\min}_{p\in Q_{1}}\widetilde{\Theta}\Bigg{(}\max \Bigg{\{}\sqrt{\frac{L}{\alpha p\mu}},\sqrt{\frac{L_{\max}\omega(\omega+1)^{2 }p}{n\mu}},\sqrt{\frac{L_{\max}\omega}{np\mu}},\frac{1}{\alpha},(\omega+1), \frac{1}{p}\Bigg{\}}\Bigg{)},\] (62)

where we eliminate the redundant terms using the additional information \(p\leq\left(\frac{Ln}{L_{\max}}\right)^{1/3}\frac{1}{\omega+1}\). In particular,

\[\sqrt{\frac{L^{2/3}L_{\max}^{1/3}(\omega+1)}{\alpha n^{1/3}\mu}}\leq\sqrt{ \frac{L}{\alpha p\mu}}\text{ and }\sqrt{\frac{L^{2/3}L_{\max}^{1/3}(\omega+1)^{2/3}}{\alpha n^{1/3}p^{1/3}\mu}} \leq\sqrt{\frac{L}{\alpha p\mu}}.\]for all \(p\leq\left(\frac{Ln}{L_{\max}}\right)^{1/3}\frac{1}{\omega+1}\). Without the condition \(p\in Q_{1},\) the argmin (62) attains the minimum at a point

\[p=\max\left\{\frac{1}{\omega+1},\left(\frac{Ln}{L_{\max}}\right)^{1/2}\frac{1}{ \sqrt{\alpha}(\omega+1)^{3/2}}\right\}.\]

Considering the condition \(p\in Q_{1}\) and \(\mu^{r}_{\omega,\alpha}:=\nicefrac{{B}}{{A}}\), we have

\[p=\min\left\{1,\frac{1}{\mu^{r}_{\omega,\alpha}},\left(\frac{Ln}{L_{\max}} \right)^{1/3}\frac{1}{\omega+1},\max\left\{\frac{1}{\omega+1},\left(\frac{Ln} {L_{\max}}\right)^{1/2}\frac{1}{\sqrt{\alpha}(\omega+1)^{3/2}}\right\}\right\}.\] (63)

It is left carefully to substitute (63) to

\[\widetilde{\Theta}\Bigg{(}\max\left\{\sqrt{\frac{L}{\alpha p\mu}},\sqrt{ \frac{L_{\max}\omega}{np\mu}},\frac{1}{\alpha},(\omega+1),\frac{1}{p}\right\} \Bigg{)}\]

and obtain (14). The proof of \(\mathfrak{m}^{r}_{\text{\tiny{stable}}}=\widetilde{\Theta}\left(\left((1-r)K _{\omega}+rK_{\alpha}\right)T_{\text{\tiny{noise}}}\right)\) is the same as in Theorem 5.2. 

### Comparison with \(\mathtt{EF21}+\mathtt{DINANA}\)

**Theorem 6.1**.: _For all \(r\in[0,1],\)\(\mathfrak{m}^{r}_{\text{\tiny{stable}}}=\widetilde{\mathcal{O}}\left( \mathfrak{m}^{r}_{\mathtt{EF21}+\mathtt{DINANA}}\right).\)_

Proof.: Using the inequality of arithmetic and geometric means, i.e., \(\sqrt{xy}\leq\frac{x+y}{2}\) for all \(x,y\geq 0,\) and \(L\geq\mu,\) we have

\[\mathfrak{m}^{r}_{\text{\tiny{stable}}} =\widetilde{\Theta}\Bigg{(}K^{r}_{\omega,\alpha}\Bigg{(}\sqrt{ \frac{L(\omega+1)}{\alpha\mu}}+\sqrt{\frac{L_{\max}\omega(\omega+1)}{n\mu}}+ \sqrt{\frac{L\mu^{r}_{\omega,\alpha}}{\alpha\mu}}+\sqrt{\frac{L_{\max}\omega \mu^{r}_{\omega,\alpha}}{n\mu}}+\frac{1}{\alpha}+\omega+\mu^{r}_{\omega,\alpha }\Bigg{)}+d\Bigg{)}\] \[=\widetilde{\mathcal{O}}\Bigg{(}K^{r}_{\omega,\alpha}\Bigg{(} \frac{L}{\alpha\mu}+\frac{L_{\max}\omega}{n\mu}+\omega+\sqrt{\frac{L\mu^{r}_{ \omega,\alpha}}{\alpha\mu}}+\sqrt{\frac{L_{\max}\omega\mu^{r}_{\omega,\alpha}} {n\mu}}+\mu^{r}_{\omega,\alpha}\Bigg{)}+d\Bigg{)}.\]

From the definition of \(\mu^{r}_{\omega,\alpha}:=\nicefrac{{rd}}{{K^{r}_{\omega,\alpha}}}\), we get

\[\mathfrak{m}^{r}_{\text{\tiny{stable}}} =\widetilde{\mathcal{O}}\Bigg{(}K^{r}_{\omega,\alpha}\Bigg{(} \frac{L}{\alpha\mu}+\frac{L_{\max}\omega}{n\mu}+\omega\Bigg{)}+\Bigg{(}\sqrt {\frac{LK^{r}_{\omega,\alpha}\times rd}{\alpha\mu}}+\sqrt{\frac{L_{\max}\omega K ^{r}_{\omega,\alpha}\times rd}{n\mu}}+rd\Bigg{)}+d\Bigg{)}.\]

Using the inequality of arithmetic and geometric means again and \(r\leq 1\), we obtain

\[\mathfrak{m}^{r}_{\text{\tiny{stable}}} =\widetilde{\mathcal{O}}\Bigg{(}K^{r}_{\omega,\alpha}\Bigg{(} \frac{L}{\alpha\mu}+\frac{L_{\max}\omega}{n\mu}+\omega\Bigg{)}+K^{r}_{\omega, \alpha}\Bigg{(}\frac{L}{\alpha\mu}+\frac{L_{\max}\omega}{n\mu}\Bigg{)}+d \Bigg{)}.\]

The last equality means that \(\mathfrak{m}^{r}_{\text{\tiny{stable}}}=\widetilde{\mathcal{O}}\left( \mathfrak{m}^{r}_{\mathtt{EF21}+\mathtt{DINANA}}\right)\) for all \(r\in[0,1]\). 

### Comparison with \(\mathtt{AGD}\)

**Theorem 6.2**.: _For all \(r\in[0,1]\) and for all \(K\in[d],\) let us take the \(\text{Band}K\) and \(\text{Top}K\) compressors with the parameters (expected densities) i) \(K_{\omega}=K\) and \(K_{\alpha}=\min\{\lceil\nicefrac{{1-r}}{{r}}K\rceil,d\}\) for \(r\in[0,\nicefrac{{1}}{{2}}],\) ii) \(K_{\omega}=\min\{\lceil\nicefrac{{r}}{{1-r}}K\rceil,d\}\) and \(K_{\alpha}=K\) for \(r\in(\nicefrac{{1}}{{2}},1]\). Then we have \(\mathfrak{m}^{r}_{\text{\tiny{finite}}}=\widetilde{\mathcal{O}}\left(\mathfrak{m} _{\mathtt{AGD}}\right).\)_

Proof.: Consider that \(r\in[0,1/2],\) then \(K_{\omega}=K,\)\(K_{\alpha}=\min\{\lceil\nicefrac{{1-r}}{{r}}K\rceil,d\}.\) Therefore, we have

\[K^{r}_{\omega,\alpha}:=(1-r)K_{\omega}+rK_{\alpha}\leq(1-r)K+r\lceil\nicefrac{{1 -r}}{{r}}K\rceil\leq 3(1-r)K\]

and

\[K^{r}_{\omega,\alpha}:=(1-r)K_{\omega}+rK_{\alpha}\geq(1-r)K.\]

[MISSING_PAGE_FAIL:41]

\[\bar{L}\geq c\frac{\widehat{L}p\sqrt{\omega}}{\beta\sqrt{n}}\] (75) \[\bar{L}\geq c\frac{\widehat{L}\sqrt{p\omega}}{\sqrt{\beta n}}\] (76) \[\bar{L}\geq c\frac{L}{\alpha}\] (77) \[\bar{L}\geq c\frac{Lp}{\alpha\tau}\] (78) \[\bar{L}\geq c\left(\frac{L\widehat{L}^{2}\omega p^{4}}{\alpha^{2 }\beta^{2}n\tau^{2}}\right)^{1/3}\] (80)

Proof.: The inequalities (64) and (66) follow from (44). The inequality (65) follows from (64) and (66):

\[c\frac{L_{\max}\omega p}{\beta n}\leq c\frac{L_{\max}\omega}{n} \left(\frac{1}{2}\times\frac{p^{2}}{\beta^{2}}+\frac{1}{2}\times 1^{2} \right)=\frac{c}{2}\times\frac{L_{\max}\omega p^{2}}{\beta^{2}n}+\frac{c}{2} \times\frac{L_{\max}\omega}{n}\leq\bar{L}.\]

The inequalities (67) and (68) follow from (44). The inequality (69) follows from (68) and \(\beta\in(0,1]\):

\[\bar{L}\geq c\frac{\sqrt{LL_{\max}}\sqrt{p}\sqrt{\omega\tau}}{ \alpha\sqrt{\beta}\sqrt{n}}\geq c\frac{\sqrt{LL_{\max}}\sqrt{p}\sqrt{\omega \tau}}{\alpha\sqrt{\beta}\sqrt{n}}.\]

Using Lemma 1.4, (67), (68), and (69), the inequalities (70), (71), and (72) follow from

\[\bar{L}\geq c\frac{\sqrt{LL_{\max}}p\sqrt{\omega\tau}}{\alpha \beta\sqrt{n}}\geq c\frac{\widehat{L}p\sqrt{\omega\tau}}{\alpha\beta\sqrt{n}},\] \[\bar{L}\geq c\frac{\sqrt{LL_{\max}}\sqrt{p}\sqrt{\omega\tau}}{ \alpha\sqrt{\beta}\sqrt{n}}\geq c\frac{\widehat{L}\sqrt{p}\sqrt{\omega\tau}}{ \alpha\sqrt{\beta}\sqrt{n}},\] \[\bar{L}\geq c\frac{\sqrt{LL_{\max}}\sqrt{p}\sqrt{\omega\tau}}{ \alpha\sqrt{n}}\geq c\frac{\widehat{L}\sqrt{p}\sqrt{\omega\tau}}{\alpha\sqrt{n}}.\]

Next, using Lemma 1.4, and \(\frac{x+y}{2}\geq\sqrt{xy}\) for all \(x,y\geq 0,\) the inequality (73) follows from

\[c\frac{\widehat{L}p\sqrt{\omega}}{\sqrt{\alpha}\beta\sqrt{n}} \leq c\frac{\sqrt{LL_{\max}}p\sqrt{\omega}}{\sqrt{\alpha}\beta\sqrt{n}}\leq \frac{c}{2}\times\frac{L}{\alpha}+\frac{c}{2}\times\frac{L_{\max}p^{2}\omega}{ \beta^{2}n}\stackrel{{\eqref{eq:c_1}}}{{\leq}}\bar{L}.\]

The inequality (74) follows from

\[c\frac{\widehat{L}\sqrt{p}\sqrt{\omega}}{\sqrt{\alpha}\sqrt{\beta }\sqrt{n}}\leq c\frac{\sqrt{LL_{\max}}\sqrt{p}\sqrt{\omega}}{\sqrt{\alpha} \sqrt{\beta}\sqrt{n}}\leq\frac{c}{2}\times\frac{L}{\alpha}+\frac{c}{2}\times \frac{L_{\max}p\omega}{\beta n}\stackrel{{\eqref{eq:c_1}}}{{\leq}} \bar{L}.\]

The inequalities (75) and (76) follow from (73), (74), and \(\alpha\in(0,1]:\)

\[\bar{L}\geq c\frac{\widehat{L}p\sqrt{\omega}}{\sqrt{\alpha}\beta \sqrt{n}}\geq c\frac{\widehat{L}p\sqrt{\omega}}{\sqrt{\beta}\sqrt{n}},\] \[\bar{L}\geq c\frac{\widehat{L}\sqrt{p}\sqrt{\omega}}{\sqrt{\alpha }\sqrt{\beta}\sqrt{n}}\geq c\frac{\widehat{L}\sqrt{p}\sqrt{\omega}}{\sqrt{ \beta}\sqrt{n}}.\]

The inequalities (77) and (78) follow from (44), and (79) follows from (77) and \(\alpha\in(0,1].\) Using Lemma 1.4, and \(\frac{x+y+z}{3}\geq(xyz)^{1/3}\) for all \(x,y,z\geq 0,\) the inequalities (80) and (81) follows from

\[c\left(\frac{L\widehat{L}^{2}\omega p^{4}}{\alpha^{2}\beta^{2}n \tau^{2}}\right)^{1/3}\leq c\left(\frac{L^{2}L_{\max}\omega p^{4}}{\alpha^{2} \beta^{2}n\tau^{2}}\right)^{1/3}\leq\frac{c}{3}\times\frac{Lp}{\alpha\tau}+ \frac{c}{3}\times\frac{Lp}{\alpha\tau}+\frac{c}{3}\times\frac{L_{\max}\omega p ^{2}}{\beta^{2}n}\stackrel{{\eqref{eq:c_1}}}{{\leq}}\bar{L},\] \[c\left(\frac{L\widehat{L}^{2}\omega p^{3}}{\alpha^{2}\beta n \tau^{2}}\right)^{1/3}\leq c\left(\frac{L^{2}L_{\max}\omega p^{3}}{\alpha^{2} \beta n\tau^{2}}\right)^{1/3}\leq\frac{c}{3}\times\frac{Lp}{\alpha\tau}+\frac{c} {3}\times\frac{Lp}{\alpha\tau}+\frac{c}{3}\times\frac{L_{\max}\omega p}{\beta n }\stackrel{{\eqref{eq:c_1}}}{{\leq}}\bar{L}.\]Proof of Lemma e.10 (First Symbolically Computed)

We use the notations from the proof of Theorem E.9.

**Lemma E.10** (First Symbolically Computed).: _Assume that for the parameter \(\bar{L}\), the inequalities from Sections I and J hold. Then, for all \(t\geq 0\), exists \(\rho\) in (90), \(\kappa\) in (88), \(\lambda\) in (82), and \(\nu_{t}\) in (83) such that (46) holds._

Proof.: The inequalities (46) are equivalent to

\[\frac{8\theta_{t+1}^{2}}{\alpha}\left(\frac{pL}{2}+\kappa 4p\left(1+\frac{p}{\beta}\right)\widehat{L}^{2}+\rho 4pL^{2}+\lambda\left(2p\left(1+\frac{2p}{\tau}\right)L^{2}+ \frac{4p\tau^{2}\omega\widehat{L}^{2}}{n}\right)\right)\leq\nu_{t},\] \[\nu_{t}\frac{8}{\alpha p}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma _{t+1}\mu}\right)^{2}\leq\rho,\] \[\rho\frac{8p}{\tau}\leq\lambda,\] \[\frac{8p\omega}{n\bar{L}\beta}+\nu_{t}\frac{8\omega}{n\beta} \left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu}\right)^{2}+\lambda\frac{8 \tau^{2}\omega}{n\beta}\leq\kappa.\]

Let us take

\[\lambda:=\rho\frac{8p}{\tau}\] (82)

to ensure that the third inequality holds. It left to find the parameters such that

\[\frac{8\theta_{t+1}^{2}}{\alpha}\left(\frac{pL}{2}+\kappa 4p \left(1+\frac{p}{\beta}\right)\widehat{L}^{2}+\rho 4pL^{2}+\rho\frac{8p}{\tau}\left(2p\left(1+\frac{2p}{\tau} \right)L^{2}+\frac{4p\tau^{2}\omega\widehat{L}^{2}}{n}\right)\right)\leq\nu_{ t},\] \[\nu_{t}\frac{8}{\alpha p}\left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma _{t+1}\mu}\right)^{2}\leq\rho,\] \[\frac{8p\omega}{n\bar{L}\beta}+\nu_{t}\frac{8\omega}{n\beta} \left(\frac{\gamma_{t+1}}{\bar{L}+\Gamma_{t+1}\mu}\right)^{2}+\rho\frac{8p}{ \tau}\cdot\frac{8\tau^{2}\omega}{n\beta}\leq\kappa.\]

Let us take

\[\nu_{t}:=\theta_{t+1}^{2}\widehat{\nu}(\kappa,\rho),\] (83)

where we additionally define

\[\widehat{\nu}\equiv\widehat{\nu}(\kappa,\rho):=\frac{8}{\alpha} \left(\frac{pL}{2}+\kappa 4p\left(1+\frac{p}{\beta}\right)\widehat{L}^{2}+\rho 4pL^{2}+\rho\frac{8p}{\tau}\left(2p\left(1+\frac{2p}{\tau} \right)L^{2}+\frac{4p\tau^{2}\omega\widehat{L}^{2}}{n}\right)\right),\] (84)

to ensure that the first inequality holds. It left to find the parameters \(\kappa\) and \(\rho\) such that

\[\widehat{\nu}(\kappa,\rho)\frac{8}{\alpha p}\left(\frac{\gamma_ {t+1}\theta_{t+1}}{\bar{L}+\Gamma_{t+1}\mu}\right)^{2}\leq\rho,\] \[\frac{8p\omega}{n\bar{L}\beta}+\widehat{\nu}(\kappa,\rho)\frac{8 \omega}{n\beta}\left(\frac{\gamma_{t+1}\theta_{t+1}}{\bar{L}+\Gamma_{t+1}\mu} \right)^{2}+\rho\frac{8p}{\tau}\cdot\frac{8\tau^{2}\omega}{n\beta}\leq\kappa.\]

Using Lemma E.1, we have \(\frac{\gamma_{t+1}\theta_{t+1}}{L+\Gamma_{t+1}\mu}\leq\frac{\gamma_{t+1} \theta_{t+1}}{L+\Gamma_{t}\mu}\leq\frac{1}{L}\), so it is sufficient to show that stronger inequalities hold:

\[\widehat{\nu}(\kappa,\rho)\frac{8}{\alpha p\bar{L}^{2}} \leq\rho,\] (85) \[\frac{8p\omega}{n\bar{L}\beta}+\widehat{\nu}(\kappa,\rho)\frac{8 \omega}{n\beta\bar{L}^{2}}+\rho\frac{8p}{\tau}\cdot\frac{8\tau^{2}\omega}{n \beta}\leq\kappa.\] (86)From this point all formulas in this lemma are generated by the script from Section P (see Section 4 in Section P). We use the SymPy library (Meurer et al., 2017).

Using the definition of \(\widehat{\nu},\) the left hand side of (86) equals

\[\begin{split}&\frac{2048L^{2}\omega p^{3}\rho}{\bar{L}^{2}\alpha \beta n\tau^{2}}+\frac{1024L^{2}\omega p^{2}\rho}{\bar{L}^{2}\alpha\beta n\tau} +\frac{256L^{2}\omega p\rho}{\bar{L}^{2}\alpha\beta n}+\frac{32L\omega p}{\bar{ L}^{2}\alpha\beta n}\\ &\quad+\kappa\left(\frac{256\hat{L}^{2}\omega p}{\bar{L}^{2} \alpha\beta n}+\frac{256\hat{L}^{2}\omega p^{2}}{\bar{L}^{2}\alpha\beta^{2}n} \right)+\frac{64\omega p\rho\tau}{\beta n}+\frac{8\omega p}{\bar{L}\beta n}+ \frac{2048\hat{L}^{2}\omega^{2}p^{2}\rho\tau}{\bar{L}^{2}\alpha\beta n^{2}}, \end{split}\] (87)

where we grouped the terms w.r.t. \(\kappa.\) Let us take \(\bar{L}\) such that the bracket is less or equal to \(1/2.\) We define the constraints in Section I. Therefore, (86) holds if

\[\kappa:=\frac{4096L^{2}\omega p^{3}\rho}{\bar{L}^{2}\alpha\beta n\tau^{2}}+ \frac{2048L^{2}\omega p^{2}\rho}{\bar{L}^{2}\alpha\beta n\tau}+\frac{512L^{2} \omega p\rho}{\bar{L}^{2}\alpha\beta n}+\frac{64L\omega p}{\bar{L}^{2}\alpha \beta n}+\frac{128\omega p\rho\tau}{\bar{L}\beta n}+\frac{16\omega p}{\bar{L} \beta n}+\frac{4096\hat{L}^{2}\omega^{2}p^{2}\rho\tau}{\bar{L}^{2}\alpha\beta n ^{2}}.\] (88)

Using the definition of \(\widehat{\nu}\) and \(\kappa,\) the left hand side of (85) equals

\[\begin{split}&\frac{32L}{\bar{L}^{2}\alpha^{2}}+\frac{16384L \hat{L}^{2}\omega p}{\bar{L}^{4}\alpha^{3}\beta n}+\frac{16384L\hat{L}^{2} \omega p^{2}}{\bar{L}^{4}\alpha^{3}\beta^{2}n}\\ &\quad+\rho\left(\frac{2048L^{2}p^{2}}{\bar{L}^{2}\alpha^{2}\tau^ {2}}+\frac{1024L^{2}p}{\bar{L}^{2}\alpha^{2}\tau}+\frac{256L^{2}}{\bar{L}^{2} \alpha^{2}}+\frac{1048576L^{2}\hat{L}^{2}\omega p^{3}}{\bar{L}^{4}\alpha^{3} \beta n\tau^{2}}+\frac{524288L^{2}\hat{L}^{2}\omega p^{2}}{\bar{L}^{4}\alpha^ {3}\beta n\tau}\right.\\ &\quad+\frac{131072L^{2}\hat{L}^{2}\omega p}{\bar{L}^{4}\alpha^{3 }\beta n}+\frac{1048576L^{2}\hat{L}^{2}\omega p^{4}}{\bar{L}^{4}\alpha^{3} \beta^{2}n\tau^{2}}+\frac{524288L^{2}\hat{L}^{2}\omega p^{3}}{\bar{L}^{4} \alpha^{3}\beta^{2}n\tau}\\ &\quad+\frac{131072L^{2}\hat{L}^{2}\omega p^{2}}{\bar{L}^{4} \alpha^{3}\beta^{2}n}+\frac{2048\hat{L}^{2}\omega p\tau}{\bar{L}^{2}\alpha^{2 }n}+\frac{32768\hat{L}^{2}\omega p\tau}{\bar{L}^{2}\alpha^{2}\beta n}+\frac{32 768\hat{L}^{2}\omega p^{2}\tau}{\bar{L}^{2}\alpha^{2}\beta^{2}n}\\ &\quad+\frac{1048576\hat{L}^{4}\omega^{2}p^{2}\tau}{\bar{L}^{4} \alpha^{3}\beta n^{2}}+\frac{1048576\hat{L}^{4}\omega^{2}p^{3}\tau}{\bar{L}^{4 }\alpha^{3}\beta^{2}n^{2}}\right)+\frac{4096\hat{L}^{2}\omega p}{\bar{L}^{3} \alpha^{2}\beta n}+\frac{4096\hat{L}^{2}\omega p^{2}}{\bar{L}^{3}\alpha^{2} \beta^{2}n},\end{split}\] (89)

where we grouped the terms w.r.t. \(\rho.\) Let us take \(\bar{L}\) such that the bracket is less or equal to \(1/2.\) We define the constraints in Section J. Therefore, (85) holds if

\[\rho:=\frac{64L}{\bar{L}^{2}\alpha^{2}}+\frac{32768L\hat{L}^{2}\omega p}{\bar{ L}^{4}\alpha^{3}\beta n}+\frac{32768L\hat{L}^{2}\omega p^{2}}{\bar{L}^{4} \alpha^{3}\beta^{2}n}+\frac{8192\hat{L}^{2}\omega p}{\bar{L}^{3}\alpha^{2} \beta n}+\frac{8192\hat{L}^{2}\omega p^{2}}{\bar{L}^{3}\alpha^{2}\beta^{2}n}.\] (90)

Finally, under the constraints from Sections I and J on \(\bar{L},\) the choices of parameters (90), (88), (83) and (82) insure that (46) holds. 

## Appendix H Proof of Lemma e.11 (Second Symbolically Computed)

We use the notations from the proof of Theorem E.9.

**Lemma E.11** (Second Symbolically Computed).: _Consider the parameters \(\rho,\)\(\kappa,\)\(\lambda,\) and \(\nu_{t}\) from Lemma E.10. Assume that for the parameter \(\bar{L},\) the inequalities from Sections L and N hold, and the step size \(\theta_{t+1}\leq\nicefrac{{1}}{{4}}\) for all \(t\geq 0.\) Then, for all \(t\geq 0,\) the following inequalities are satisfied:_

\[\begin{split} p\left(\frac{4\omega L_{\max}}{n\bar{L}}+\kappa 8\left(1+\frac{p}{\beta}\right)L_{\max}+\nu_{t}\left(\frac{\gamma_{t+1}}{ \bar{L}+\Gamma_{t+1}\mu}\right)^{2}\left(\frac{4\omega L_{\max}}{pn}+\frac{8L}{ p\alpha}\right)+\rho 8L+\\ +\lambda\left(4\left(1+\frac{2p}{\tau}\right)L+\frac{8\tau^{2} \omega L_{\max}}{n}\right)+\theta_{t+1}-1\right)D_{f}(z^{t},y^{t+1})\leq 0 \end{split}\] (47)\[2\theta_{t+1}^{2}\left(\frac{pL}{2}+\kappa 4p\left(1+\frac{p}{\beta} \right)\widehat{L}^{2}+\rho 4pL^{2}+\lambda\left(2p\left(1+\frac{2p}{\tau}\right)L^{2}+ \frac{4p\tau^{2}\omega\widehat{L}^{2}}{n}\right)\right)\mathbb{E}_{t}\left[ \left\|u^{t+1}-u^{t}\right\|^{2}\right]\] (48) \[-\frac{p\theta_{t+1}^{2}\widetilde{L}}{2}\mathbb{E}_{t}\left[ \left\|u^{t+1}-u^{t}\right\|^{2}\right]\leq 0.\]

Proof.: Since \(p\geq 0\) and \(D_{f}(z^{t},y^{t+1})\geq 0\) for all \(t\geq 0,\) the inequality (47) is satisfied if

\[\frac{4\omega L_{\max}}{n\widetilde{L}} +\kappa 8\left(1+\frac{p}{\beta}\right)L_{\max}+\nu_{t}\left( \frac{\gamma_{t+1}}{\widetilde{L}+\Gamma_{t+1}\mu}\right)^{2}\left(\frac{4 \omega L_{\max}}{pn}+\frac{8L}{p\alpha}\right)+\rho 8L+\] \[+\lambda\left(4\left(1+\frac{2p}{\tau}\right)L+\frac{8\tau^{2} \omega L_{\max}}{n}\right)+\theta_{t+1}-1\leq 0.\]

Note that \(\theta_{t+1}\leq\frac{1}{4}\) for all \(t\geq 0.\) Therefore, it is sufficient to show that

\[\frac{4\omega L_{\max}}{n\widetilde{L}} +\kappa 8\left(1+\frac{p}{\beta}\right)L_{\max}+\nu_{t}\left( \frac{\gamma_{t+1}}{\widetilde{L}+\Gamma_{t+1}\mu}\right)^{2}\left(\frac{4 \omega L_{\max}}{pn}+\frac{8L}{p\alpha}\right)+\rho 8L+\] \[+\lambda\left(4\left(1+\frac{2p}{\tau}\right)L+\frac{8\tau^{2} \omega L_{\max}}{n}\right)\leq\frac{3}{4}.\]

In the view of (83), we have to show that

\[\frac{4\omega L_{\max}}{n\widetilde{L}} +\kappa 8\left(1+\frac{p}{\beta}\right)L_{\max}+\widehat{\nu} \left(\frac{\gamma_{t+1}\theta_{t+1}}{\widetilde{L}+\Gamma_{t+1}\mu}\right)^{ 2}\left(\frac{4\omega L_{\max}}{pn}+\frac{8L}{p\alpha}\right)+\rho 8L+\] \[+\lambda\left(4\left(1+\frac{2p}{\tau}\right)L+\frac{8\tau^{2} \omega L_{\max}}{n}\right)\leq\frac{3}{4}.\]

Using Lemma E.1, we have \(\frac{\gamma_{t+1}\theta_{t+1}}{L+\Gamma_{t+1}\mu}\leq\frac{\gamma_{t+1} \theta_{t+1}}{L+\Gamma_{t}\mu}\leq\frac{1}{L},\) so it is sufficient to show that

\[\frac{4\omega L_{\max}}{n\widetilde{L}} +\kappa 8\left(1+\frac{p}{\beta}\right)L_{\max}+\frac{\widehat{\nu} }{\widetilde{L}^{2}}\left(\frac{4\omega L_{\max}}{pn}+\frac{8L}{p\alpha} \right)+\rho 8L+\] (91) \[+\lambda\left(4\left(1+\frac{2p}{\tau}\right)L+\frac{8\tau^{2} \omega L_{\max}}{n}\right)\leq\frac{3}{4}.\]

From this point all formulas in this lemma are generated by the script from Section P (see Section 5 in Section P).

Let us substitute (90), (88), (82), and (84) to the last inequality and obtain the inequality from Section K. The conditions from Section L insure that the inequality from Section K holds. It left to prove (48). Since \(p\geq 0,\)\(\mathbb{E}_{t}\left[\left\|u^{t+1}-u^{t}\right\|^{2}\right]\geq 0\) and \(\theta_{t+1}^{2}\geq 0\) for all \(t\geq 0,\) the inequality (48) holds if

\[\frac{4}{\widetilde{L}}\left(\frac{L}{2}+\kappa 4\left(1+\frac{p}{\beta} \right)\widehat{L}^{2}+\rho 4L^{2}+\lambda\left(2\left(1+\frac{2p}{\tau} \right)L^{2}+\frac{4\tau^{2}\omega\widehat{L}^{2}}{n}\right)\right)\leq 1.\] (92)

Let us substitute (90), (88) and (82) to the last inequality and obtain the inequality from Section M. The inequality from Section M holds if \(\widetilde{L}\) satisfy the inequalities from Section N. 

Appendix I Symbolically Computed Constraints for \(\bar{L}\) Such That The Term w.r.t. \(\kappa\) is less or equal \(\nicefrac{{1}}{{2}}\) in (87)

\[\frac{256\hat{L}^{2}\omega p}{\bar{L}^{2}\alpha\beta n}\leq\frac{1}{4}\qquad \text{ (\ref{eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq: eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq:eq: eqSymbolically Computed Constraints for \(\bar{L}\) Such That The Term w.r.t. \(\rho\) is less or equal \(\nicefrac{{1}}{{2}}\) in (89)

\[\frac{256L^{2}}{\bar{L}^{2}\alpha^{2}}\leq\frac{1}{28} \frac{1024L^{2}p}{\bar{L}^{2}\alpha^{2}\tau}\leq\frac{1}{28} \frac{2048L^{2}p^{2}}{\bar{L}^{2}\alpha^{2}\tau^{2}}\leq\frac{1}{28}\frac{1}{28}\] (97) \[\frac{2048\hat{L}^{2}\omega p\tau}{\bar{L}^{2}\alpha^{2}n}\leq \frac{1}{28} \frac{32768\hat{L}^{2}\omega p\tau}{\bar{L}^{2}\alpha^{2}\beta n} \leq\frac{1}{28}\frac{32768\hat{L}^{2}\omega p\tau}{\bar{L}^{2}\alpha^{2}\beta n }\leq\frac{1}{28}\] (98) \[\frac{131072L^{2}\hat{L}^{2}\omega p}{\bar{L}^{4}\alpha^{3}\beta n }\leq\frac{1}{28} \frac{101}{\frac{131072L^{2}\hat{L}^{2}\omega p^{2}}{\bar{L}^{4} \alpha^{3}\beta^{2}n}}\leq\frac{1}{28}\frac{102}{\frac{1048576\hat{L}^{4} \omega^{2}p^{2}\tau}{\bar{L}^{4}\alpha^{3}\beta n^{2}}}\leq\frac{1}{28}\] (100) \[\frac{1048576\hat{L}^{4}\omega^{2}p^{3}\tau}{\bar{L}^{4}\alpha^{3 }\beta^{2}n^{2}}\leq\frac{1}{28} \frac{524288L^{2}\hat{L}^{2}\omega p^{3}}{\bar{L}^{4}\alpha^{3}\beta n\tau} \leq\frac{1}{28}\frac{524288L^{2}\hat{L}^{2}\omega p^{3}}{\bar{L}^{4}\alpha^{ 3}\beta^{2}n\tau}\leq\frac{1}{28}\] (101) \[\frac{1048576L^{2}\hat{L}^{2}\omega p^{3}}{\bar{L}^{4}\alpha^{3} \beta n\tau^{2}}\leq\frac{1}{28} \frac{107}{\frac{1048576L^{2}\hat{L}^{2}\omega p^{4}}{\bar{L}^{4} \alpha^{3}\beta^{2}n\tau^{2}}}\leq\frac{1}{28}\frac{1}{28}\] (102)

## Appendix K Symbolically Computed Expression (91)

\[\frac{544L^{2}}{\bar{L}^{2}\alpha^{2}}+\frac{16384L^{4}}{\bar{L} ^{4}\alpha^{4}}+\frac{4L_{\max}\omega}{\bar{L}n}\] \[+\frac{2048L^{2}p}{\bar{L}^{2}\alpha^{2}\tau}+\frac{4096L^{2}p^{ 2}}{\bar{L}^{2}\alpha^{2}\tau^{2}}+\frac{65536L^{4}p}{\bar{L}^{4}\alpha^{4}\tau}\] \[+\frac{131072L^{4}p^{2}}{\bar{L}^{4}\alpha^{4}\tau^{2}}+\frac{16 LL_{\max}\omega}{\bar{L}^{2}\alpha n}+\frac{128L_{\max}\omega p}{\bar{L} \beta n}\] \[+\frac{128L_{\max}\omega p^{2}}{\bar{L}^{2}\alpha^{2}n}+\frac{819 2L^{3}L_{\max}\omega}{\bar{L}^{4}\alpha^{3}n}+\frac{512LL_{\max}\omega p}{\bar {L}^{2}\alpha\beta n}\] \[+\frac{512LL_{\max}\omega p^{2}}{\bar{L}^{2}\alpha\beta^{2}n}+ \frac{2048L_{\max}\hat{L}^{2}\omega^{2}p}{\bar{L}^{3}\alpha\beta n^{2}}+ \frac{2048L_{\max}\hat{L}^{2}\omega^{2}p^{2}}{\bar{L}^{3}\alpha\beta^{2}n^{2}}\] \[+\frac{4096LL_{\max}\omega p\tau}{\bar{L}^{2}\alpha^{2}n}+\frac{32 768L^{3}L_{\max}\omega p}{\bar{L}^{4}\alpha^{3}n\tau}+\frac{65536L^{3}L_{\max }\omega p^{2}}{\bar{L}^{4}\alpha^{3}n\tau^{2}}\] \[+\frac{69632L\hat{L}^{2}\omega p}{\bar{L}^{3}\alpha^{2}\beta n}+ \frac{69632L\hat{L}^{2}\omega p^{2}}{\bar{L}^{3}\alpha^{2}\beta n}+\frac{13107 2L^{2}\hat{L}^{2}\omega p\tau}{\bar{L}^{4}\alpha^{4}n}\] \[+\frac{262144L^{3}L_{\max}\omega p}{\bar{L}^{4}\alpha^{3}\beta n}+ \frac{262144L^{3}L_{\max}\omega p^{2}}{\bar{L}^{4}\alpha^{3}\beta^{2}n}+\frac {278528L^{2}\hat{L}^{2}\omega p}{\bar{L}^{4}\alpha^{3}\beta n}\] \[+\frac{278528L^{2}\hat{L}^{2}\omega p^{2}}{\bar{L}^{4}\alpha^{3} \beta^{2}n}+\frac{2097152L^{3}\hat{L}^{2}\omega p}{\bar{L}^{5}\alpha^{4}\beta n }+\frac{2097152L^{3}\hat{L}^{2}\omega p^{2}}{\bar{L}^{5}\alpha^{4}\beta^{2}n}\] \[+\frac{16777216L^{4}\hat{L}^{2}\omega p}{\bar{L}^{6}\alpha^{5} \beta n}+\frac{16777216L^{4}\hat{L}^{2}\omega p^{2}}{\bar{L}^{6}\alpha^{5}\beta ^{2}n}+\frac{1073741824L^{3}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{7}\alpha^{5} \beta^{4}n^{2}}\] \[+\frac{1073741824L^{3}\hat{L}^{4}\omega^{2}p^{2}}{\bar{L}^{7} \alpha^{5}\beta^{2}n^{2}}+\frac{2147483648L^{3}\hat{L}^{4}\omega^{2}p^{3}}{\bar{L }^{7}\alpha^{5}\beta^{3}n^{2}}+\frac{4294967296L^{4}\hat{L}^{4}\omega^{2}p^{4} }{\bar{L}^{8}\alpha^{6}\beta^{4}n^{2}}\]

[MISSING_PAGE_EMPTY:47]

\[+\frac{4294967296L^{3}L_{\max}\hat{L}^{4}\omega^{3}p^{3}}{\bar{L}^{ 7}\alpha^{5}\beta^{3}n^{3}}+\frac{4294967296L^{3}\hat{L}^{4}\omega^{2}p^{4}}{ \bar{L}^{7}\alpha^{5}\beta^{4}n^{2}\tau}+\frac{4294967296L^{3}\hat{L}^{4}\omega^ {2}p^{3}}{\bar{L}^{7}\alpha^{5}\beta^{2}n^{2}\tau}\] \[+\frac{8589934592L\hat{L}^{6}\omega^{3}p^{5}\tau}{\bar{L}^{7} \alpha^{5}\beta^{4}n^{3}}+\frac{8589934592L\hat{L}^{6}\omega^{3}p^{3}\tau}{ \bar{L}^{7}\alpha^{5}\beta^{2}n^{3}}+\frac{8589934592L_{\max}\hat{L}^{6}\omega^ {4}p^{4}\tau}{\bar{L}^{7}\alpha^{5}\beta^{3}n^{4}}\] \[+\frac{8589934592L\hat{L}^{4}\omega^{2}p^{6}}{\bar{L}^{7}\alpha^{5 }\beta^{4}n^{2}\tau^{2}}+\frac{8589934592L^{3}\hat{L}^{4}\omega^{2}p^{4}}{\bar {L}^{7}\alpha^{5}\beta^{3}n^{2}\tau}+\frac{8589934592L^{3}\hat{L}^{4}\omega^{2} p^{3}}{\bar{L}^{7}\alpha^{5}\beta^{3}n^{2}\tau}\] \[+\frac{17179869184L\hat{L}^{6}\omega^{3}p^{4}\tau}{\bar{L}^{7} \alpha^{5}\beta^{3}n^{3}}+\frac{17179869184L\hat{L}^{3}\hat{L}^{4}\omega^{2}p^ {5}}{\bar{L}^{7}\alpha^{5}\beta^{3}n^{3}}+\frac{17179869184L\hat{L}^{4}\omega^ {2}p^{5}}{\bar{L}^{8}\alpha^{6}\beta^{4}n^{2}\tau}\] \[+\frac{17179869184L^{4}\hat{L}^{4}\omega^{2}p^{3}}{\bar{L}^{8} \alpha^{6}\beta^{2}n^{2}\tau^{2}}+\frac{34359738368L^{2}\hat{L}^{6}\omega^{3} p^{5}\tau}{\bar{L}^{8}\alpha^{6}\beta^{4}n^{3}}+\frac{34359738368L^{2}\hat{L}^{6} \omega^{3}p^{3}\tau}{\bar{L}^{8}\alpha^{6}\beta^{2}n^{3}}\] \[+\frac{34359738368L^{4}\hat{L}^{4}\omega^{2}p^{6}}{\bar{L}^{8} \alpha^{6}\beta^{4}n^{2}\tau^{2}}+\frac{34359738368L^{4}\hat{L}^{4}\omega^{2} p^{4}}{\bar{L}^{8}\alpha^{6}\beta^{3}n^{2}\tau}+\frac{34359738368L^{4}\hat{L}^{4} \omega^{2}p^{4}}{\bar{L}^{8}\alpha^{6}\beta^{2}n^{2}\tau^{2}}\] \[+\frac{68719476736L^{2}\hat{L}^{6}\omega^{3}p^{4}\tau}{\bar{L}^{8 }\alpha^{6}\beta^{3}n^{3}}+\frac{68719476736L^{4}\hat{L}^{4}\omega^{2}p^{5}}{ \bar{L}^{8}\alpha^{6}\beta^{3}n^{2}\tau^{2}}+\frac{1048576LL_{\max}\hat{L}^{2 }\omega^{2}p\tau}{\bar{L}^{4}\alpha^{3}\beta^{2}}\] \[+\frac{4194304LL_{\max}\hat{L}^{2}\omega^{2}p^{2}\tau}{\bar{L}^{4 }\alpha^{3}\beta^{2}n^{2}}+\frac{4194304LL_{\max}\hat{L}^{2}\omega^{2}p^{3} \tau}{\bar{L}^{4}\alpha^{3}\beta^{2}n^{2}}+\frac{4194304L^{2}L_{\max}\hat{L}^ {2}\omega^{2}p^{2}}{\bar{L}^{5}\alpha^{3}\beta^{2}n^{2}\tau}\] \[+\frac{8388608L^{2}L_{\max}\hat{L}^{2}\omega^{2}p^{3}}{\bar{L}^{5 }\alpha^{3}\beta n^{2}\tau^{2}}+\frac{33554432LL_{\max}\hat{L}^{2}\omega^{2} p^{4}\tau}{\bar{L}^{4}\alpha^{3}\beta^{4}n^{2}}+\frac{33554432L_{\max}\hat{L}^{2 }\omega^{2}p^{2}}{\bar{L}^{6}\alpha^{4}\beta^{2}n^{2}\tau^{2}}\] \[+\frac{34603008LL_{\max}\hat{L}^{2}\omega^{2}p^{2}\tau}{\bar{L}^{4 }\alpha^{3}\beta^{2}n^{2}}+\frac{67108864LL_{\max}\hat{L}^{2}\omega^{2}p^{3} \tau}{\bar{L}^{4}\alpha^{3}\beta^{3}n^{2}}+\frac{67108864LL_{\max}\hat{L}^{4} \omega^{3}p^{2}\tau}{\bar{L}^{6}\alpha^{4}\beta n^{3}}\] \[+\frac{67108864L^{3}L_{\max}\hat{L}^{2}\omega^{2}p^{3}}{\bar{L}^{ 6}\alpha^{4}\beta^{2}n^{2}\tau^{2}}+\frac{134217728L^{2}L_{\max}\hat{L}^{2} \omega^{2}p^{5}}{\bar{L}^{5}\alpha^{3}\beta^{4}n^{2}\tau}+\frac{138412032L^{2} L_{\max}\hat{L}^{2}\omega^{2}p^{3}}{\bar{L}^{5}\alpha^{3}\beta^{2}n^{2}\tau}\] \[+\frac{268435456L^{2}L_{\max}\hat{L}^{2}\omega^{2}p^{6}}{\bar{L}^{ 5}\alpha^{3}\beta^{4}n^{2}\tau^{2}}+\frac{268435456L^{2}L_{\max}\hat{L}^{2} \omega^{2}p^{4}}{\bar{L}^{5}\alpha^{3}\beta^{3}n^{2}\tau}+\frac{276824064L^{2}L_{ \max}\hat{L}^{2}\omega^{2}p^{4}}{\bar{L}^{5}\alpha^{3}\beta^{2}n^{2}\tau^{2}}\] \[+\frac{536870912LL_{\max}\hat{L}^{4}\omega^{3}p^{4}\tau}{\bar{L}^{6 }\alpha^{4}\beta^{4}n^{3}}+\frac{536870912LL_{\max}\hat{L}^{4}\omega^{3}p^{2} \tau}{\bar{L}^{6}\alpha^{4}\beta^{2}n^{3}}+\frac{536870912L^{2}L_{\max}\hat{L}^{2 }\omega^{2}p^{5}}{\bar{L}^{5}\alpha^{3}\beta^{3}n^{2}\tau^{2}}\] \[+\frac{536870912L^{3}L_{\max}\hat{L}^{2}\omega^{2}p^{5}}{\bar{L}^{6 }\alpha^{4}\beta^{4}n^{2}\tau}+\frac{570425344L^{3}L_{\max}\hat{L}^{2}\omega^{2} p^{3}}{\bar{L}^{6}\alpha^{4}\beta^{2}n^{2}\tau}+\frac{1073741824LL_{\max}\hat{L}^{4} \omega^{3}p^{5}\tau}{\bar{L}^{6}\alpha^{4}\beta^{4}n^{3}}\] \[+\frac{1073741824LL_{\max}\hat{L}^{4}\omega^{3}p^{3}\tau}{\bar{L}^{6 }\alpha^{4}\beta^{3}n^{3}}+\frac{1073741824L^{3}L_{\max}\hat{L}^{2}\omega^{2} p^{6}}{\bar{L}^{6}\alpha^{4}\beta^{4}n^{2}\tau^{2}}+\frac{1073741824L^{3}L_{\max} \hat{L}^{2}\omega^{2}p^{4}}{\bar{L}^{6}\alpha^{4}\beta^{3}n^{2}\tau}\] \[+\frac{1140850688LL_{\max}\hat{L}^{4}\omega^{3}p^{3}\tau}{\bar{L}^{6 }\alpha^{4}\beta^{2}n^{3}}+\frac{1140850688L^{3}L_{\max}\hat{L}^{2}\omega^{2} p^{4}}{\bar{L}^{6}\alpha^{4}\beta^{2}n^{2}\tau^{2}}+\frac{2147483648LL_{\max}\hat{L}^{4} \omega^{3}p^{4}\tau}{\bar{L}^{6}\alpha^{4}\beta^{3}n^{3}}\] \[+\frac{2

[MISSING_PAGE_EMPTY:49]

[MISSING_PAGE_EMPTY:50]

\[\frac{16777216L\hat{L}^{4}\omega^{2}p^{3}\tau}{\bar{L}^{5}\alpha^{4}\beta n\tau^{2} }\leq\frac{1}{326} \frac{16777216L_{\max}\hat{L}^{2}\omega p^{4}}{\bar{L}^{5}\alpha^{4}\beta^{2} n\tau^{2}}\leq\frac{1}{326} \frac{16777216L_{\max}\hat{L}^{2}\omega^{2}p^{3}\tau}{\bar{L}^{5}\alpha^{4} \beta^{2}n^{2}}\leq\frac{1}{326} \frac{33554432L^{2}L_{\max}\hat{L}^{2}\omega^{2}p^{4}}{\bar{L}^{5}\alpha^{3} \beta^{4}n^{2}}\leq\frac{1}{326}\] (176)

\[\frac{34603008L^{2}L_{\max}\hat{L}^{2}\omega^{2}p^{2}}{\bar{L}^{5}\alpha^{3} \beta^{2}n^{2}}\leq\frac{1}{326} \frac{67108864L^{4}\hat{L}^{2}\omega p^{2}}{\bar{L}^{6}\alpha^{5} \beta n\tau}\leq\frac{1}{326} \frac{67108864L^{4}\hat{L}^{2}\omega p^{3}}{\bar{L}^{6}\alpha^{5}\beta^{2} n\tau}\leq\frac{1}{326}\] (177)

\[\frac{67108864L^{2}L_{\max}\hat{L}^{2}\omega^{2}p^{3}}{\bar{L}^{5}\alpha^{3} \beta^{3}n^{2}}\leq\frac{1}{326} \frac{134217728L^{4}\hat{L}^{2}\omega p^{4}}{\bar{L}^{6}\alpha^{5} \beta n\tau^{2}}\leq\frac{1}{326} \frac{134217728L^{4}\hat{L}^{2}\omega p^{4}}{\bar{L}^{6}\alpha^{5}\beta^{2} n\tau^{2}}\leq\frac{1}{326}\] (181)

\[\frac{134217728L_{\max}\hat{L}^{4}\omega^{3}p^{4}\tau}{\bar{L}^{5}\alpha^{3} \beta^{4}n^{3}}\leq\frac{1}{326} \frac{134217728L_{\max}\hat{L}^{4}\omega^{3}p^{2}\tau}{\bar{L}^{5}\alpha^{3} \beta^{2}n^{3}}\leq\frac{1}{326} \frac{134217728L^{3}L_{\max}\hat{L}^{2}\omega^{2}p^{4}}{\bar{L}^{6}\alpha^{ 4}\beta^{4}n^{2}}\leq\frac{1}{326}\] (182)

\[\frac{134217728L^{2}\hat{L}^{4}\omega^{2}p^{2}\tau}{\bar{L}^{6}\alpha^{5}\beta n ^{2}}\leq\frac{1}{326} \frac{134217728L^{2}\hat{L}^{4}\omega^{2}p^{3}\tau}{\bar{L}^{6}\alpha^{5} \beta^{2}n^{2}}\leq\frac{1}{326} \frac{142606336L^{3}L_{\max}\hat{L}^{2}\omega^{2}p^{2}}{\bar{L}^{6}\alpha^{ 4}\beta^{2}n^{2}}\leq\frac{1}{326}\] (183)

\[\frac{268435456L\hat{L}^{4}\omega^{2}p^{4}\tau}{\bar{L}^{5}\alpha^{4}\beta^{4} n^{2}}\leq\frac{1}{326} \frac{268435456L\hat{L}^{4}\omega^{2}p^{2}\tau}{\bar{L}^{5}\alpha^{4}\beta^{2} n^{2}}\leq\frac{1}{326} \frac{268435456L_{\max}\hat{L}^{4}\omega^{3}p^{5}\tau}{\bar{L}^{5}\alpha^{3} \beta^{4}n^{3}}\leq\frac{1}{326}\] (191)

\[\frac{268435456L_{\max}\hat{L}^{4}\omega^{3}p^{3}\tau}{\bar{L}^{5}\alpha^{3} \beta^{3}n^{3}}\leq\frac{1}{326} \frac{268435456L^{3}L_{\max}\hat{L}^{2}\omega^{2}p^{3}}{\bar{L}^{6}\alpha^{4} \beta^{3}n^{2}}\leq\frac{1}{326} \frac{276824064L_{\max}\hat{L}^{4}\omega^{3}p^{3}\tau}{\bar{L}^{5}\alpha^{3} \beta^{2}n^{3}}\leq\frac{1}{326}\] (192)

\[\frac{268435456L_{\max}\hat{L}^{4}\omega^{3}p^{3}\tau}{\bar{L}^{5}\alpha^{3} \beta^{3}n^{3}}\leq\frac{1}{326} \frac{268435456L^{3}L_{\max}\hat{L}^{2}\omega^{2}p^{3}}{\bar{L}^{6}\alpha^{4} \beta^{3}n^{2}}\leq\frac{1}{326} \frac{276824064L_{\max}\hat{L}^{4}\omega^{3}p^{3}\tau}{\bar{L}^{5}\alpha^{3} \beta^{2}n^{3}}\leq\frac{1}{326}\] (193)

\[\frac{536870912L\hat{L}^{4}\omega^{2}p^{3}\tau}{\bar{L}^{5}\alpha^{3}\beta^{3} n^{2}}\leq\frac{1}{326} \frac{536870912L_{\max}\hat{L}^{4}\omega^{3}p^{4}\tau}{\bar{L}^{5}\alpha^{3} \beta^{3}n^{3}}\leq\frac{1}{326} \frac{536870912L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{4}}{\bar{L}^{7}\alpha^{4} \beta^{4}n^{3}}\leq\frac{1}{326}\] (194)

\[\frac{536870912L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{2}}{\bar{L}^{7}\alpha^{4} \beta^{2}n^{3}}\leq\frac{1}{326} \frac{1073741824L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{3}}{\bar{L}^{7}\alpha^{4} \beta^{3}n^{3}}\leq\frac{1}{326} \frac{1073741824L^{2}\hat{L}^{4}\omega^{2}p^{4}\tau}{\bar{L}^{6}\alpha^{5} \beta^{4}n^{2}}\leq\frac{1}{326}\] (195)

\[\frac{536870912L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{2}}{\bar{L}^{7}\alpha^{4} \beta^{2}n^{3}}\leq\frac{1}{326} \frac{1073741824L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{3}}{\bar{L}^{7}\alpha^{4} \beta^{3}n^{3}}\leq\frac{1}{326} \frac{1073741824L^{2}\hat{L}^{4}\omega^{2}p^{4}\tau}{\bar{L}^{6}\alpha^{5} \beta^{4}n^{2}}\leq\frac{1}{326}\] (196)

\[\frac{536870912L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{2}}{\bar{L}^{7}\alpha^{4} \beta^{2}n^{3}}\leq\frac{1}{326} \frac{1073741824L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{3}}{\bar{L}^{7}\alpha^{4} \beta^{3}n^{3}}\leq\frac{1}{326} \frac{1073741824L^{2}\hat{L}^{4}\omega^{2}p^{4}\tau}{\bar{L}^{6}\alpha^{5} \beta^{2}n^{2}}\leq\frac{1}{326}\] (197)

\[\frac{536870912L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{2}}{\bar{L}^{7}\alpha^{4} \beta^{2}n^{3}}\leq\frac{1}{326} \frac{1073741824L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{3}}{\bar{L}^{7}\alpha^{4} \beta^{3}n^{3}}\leq\frac{1}{326} \frac{1073741824L^{2}\hat{L}^{4}\omega^{2}p^{4}\tau}{\bar{L}^{6}\alpha^{5} \beta^{4}n^{2}}\leq\frac{1}{326}\] (200)\[\frac{1073741824L^{2}\hat{L}^{4}\omega^{2}p^{2}\tau}{\bar{L}^{6} \alpha^{5}\beta^{2}n^{2}}\leq\frac{1}{326} \frac{2147483648L^{3}L_{\max}\hat{L}^{4}\omega^{3}p^{4}}{\bar{L}^{8}\alpha^{5} \beta^{4}n^{3}}\leq\frac{1}{326} \frac{2147483648L^{3}L_{\max}\hat{L}^{4}\omega^{3}p^{2}}{\bar{L}^{8} \alpha^{5}\beta^{2}n^{3}}\leq\frac{1}{326}\] (202)

\[\frac{2147483648L^{2}\hat{L}^{4}\omega^{2}p^{3}}{\bar{L}^{6}\alpha^{5}\beta^{3} n^{2}}\leq\frac{1}{326} \frac{4294967296L_{\max}\hat{L}^{6}\omega^{4}p^{5}\tau}{\bar{L}^{7}\alpha^{4} \beta^{4}n^{4}}\leq\frac{1}{326} \frac{4294967296L_{\max}\hat{L}^{6}\omega^{4}p^{3}\tau}{\bar{L}^{7} \alpha^{4}\beta^{4}n^{4}}\leq\frac{1}{326}\] (203)

\[\frac{2147483648L^{3}L_{\max}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{8}\alpha^{5} \beta^{2}n^{2}}\leq\frac{1}{326} \frac{34359738368L^{4}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{8}\alpha^{6} \beta^{2}n^{3}}\leq\frac{1}{326} \frac{34359738368L^{4}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{8}\alpha^{6} \beta^{2}n^{3}}\leq\frac{1}{326}\] (204)

\[\frac{34359738368L^{4}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{8}\alpha^{6}\beta^{ 4}n^{2}\tau^{2}}\leq\frac{1}{326} \frac{34359738368L^{4}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{8}\alpha^{6}\beta ^{2}n^{3}}\leq\frac{1}{326} \frac{34359738368L^{4}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{8}\alpha^{6} \beta^{2}n^{3}}\leq\frac{1}{326}\] (205)

\[\frac{68719476736L^{2}\hat{L}^{6}\omega^{3}p^{4}\tau}{\bar{L}^{8}\alpha^{6} \beta^{3}n^{3}}\leq\frac{1}{326} \frac{68719476736L^{4}\hat{L}^{4}\omega^{2}p^{5}}{\bar{L}^{8}\alpha^{6}\beta ^{3}n^{2}\tau^{2}}\leq\frac{1}{326} \frac{1048576LL_{\max}\hat{L}^{2}\omega^{2}p\tau}{\bar{L}^{4}\alpha^{3}\beta ^{2}n^{2}}\leq\frac{1}{326}\] (206)

\[\frac{4294967296L^{3}L_{\max}\hat{L}^{4}\omega^{2}p^{5}}{\bar{L}^{8}\alpha^{5} \beta^{3}n^{3}}\leq\frac{1}{326} \frac{4294967296L^{3}\hat{L}^{4}\omega^{2}p^{3}}{\bar{L}^{7}\alpha^{5}\beta ^{4}n^{2}\tau}\leq\frac{1}{326}\] (207)

\[\frac{4294967296L^{3}\hat{L}^{4}\omega^{2}p^{3}}{\bar{L}^{7}\alpha^{5}\beta^{ 3}n^{3}}\leq\frac{1}{326} \frac{4294967296L^{3}\hat{L}^{4}\omega^{2}p^{3}}{\bar{L}^{7}\alpha^{5}\beta ^{4}n^{2}\tau}\leq\frac{1}{326} \frac{1}{326} \frac{4294967296L^{3}\hat{L}^{4}\omega^{2}p^{3}}{\bar{L}^{7}\alpha^{5}\beta ^{2}n^{2}\tau}\leq\frac{1}{326}\] (208)

\[\frac{85899345992L^{3}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{7}\alpha^{5}\beta^{ 4}n^{2}\tau^{2}}\leq\frac{1}{326} \frac{8589934592L^{3}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{7}\alpha^{5}\beta ^{2}n^{2}\tau^{2}}\leq\frac{1}{326}\] (210)

\[\frac{8589934592L^{3}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{7}\alpha^{5}\beta^{4} n^{2}\tau^{2}}\leq\frac{1}{326} \frac{8589934592L^{3}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{7}\alpha^{5}\beta^{ 2}n^{2}\tau^{2}}\leq\frac{1}{326}\] (211)

\[\frac{17179869184L^{4}\hat{L}^{4}\omega^{2}p^{3}}{\bar{L}^{8}\alpha^{6}\beta^{ 2}n^{2}\tau}\leq\frac{1}{326} \frac{34359738368L^{2}\hat{L}^{6}\omega^{3}p^{5}\tau}{\bar{L}^{8}\alpha^{6} \beta^{4}n^{3}}\leq\frac{1}{326} \frac{34359738368L^{2}\hat{L}^{6}\omega^{3}p^{3}\tau}{\bar{L}^{8}\alpha^{6} \beta^{2}n^{3}}\leq\frac{1}{326}\] (212)

\[\frac{34359738368L^{4}\hat{L}^{4}\omega^{2}p^{6}}{\bar{L}^{8}\alpha^{6}\beta^{ 4}n^{2}\tau^{2}}\leq\frac{1}{326} \frac{34359738368L^{4}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{8}\alpha^{6}\beta ^{3}n^{2}\tau}\leq\frac{1}{326} \frac{34359738368L^{4}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{8}\alpha^{6}\beta^{ 2}n^{2}\tau^{2}}\leq\frac{1}{326}\] (213)

\[\frac{68719476736L^{2}\hat{L}^{6}\omega^{3}p^{4}\tau}{\bar{L}^{8}\alpha^{6}\beta ^{3}n^{3}}\leq\frac{1}{326} \frac{68719476736L^{4}\hat{L}^{4}\omega^{2}p^{5}}{\bar{L}^{8}\alpha^{6}\beta^{ 3}n^{2}\tau^{2}}\leq\frac{1}{326} \frac{1048576LL_{\max}\hat{L}^{2}\omega^{2}p\tau}{\bar{L}^{4}\alpha^{3}\beta^{ 2}n^{2}}\leq\frac{1}{326}\] (214)

\[\frac{4194304LL_{\max}\hat{L}^{2}\omega^{2}p^{2}\tau}{\bar{L}^{4}\alpha^{3}\beta n ^{2}}\leq\frac{1}{326} \frac{4194304LL_{\max}\hat{L}^{2}\omega^{2}p^{3}\tau}{\bar{L}^{4}\alpha^{3} \beta^{2}n^{2}}\leq\frac{1}{326} \frac{4194304LL^{2}L_{\max}\hat{L}^{2}\omega^{2}p^{2}\tau}{\bar{L}^{5}\alpha^{3} \beta n^{2}\tau}\leq\frac{1}{326}\] (215)\[\frac{8388608L^{2}L_{\max}\hat{L}^{2}\omega^{2}p^{3}}{\bar{L}^{5} \alpha^{3}\beta n^{2}\tau^{2}}\leq\frac{1}{326}\quad\quad\frac{33554432LL_{\max} \hat{L}^{2}\omega^{2}p^{4}\tau}{\bar{L}^{4}\alpha^{3}\beta^{4}n^{2}}\leq\frac{1 }{326}\quad\quad\frac{33554432LL_{\max}\hat{L}^{2}\omega^{2}p^{4}\tau}{\bar{L}^ {6}\alpha^{4}\beta^{2}n^{2}}\leq\frac{1}{326}\quad\quad\frac{33554432LL_{\max} \hat{L}^{2}\omega^{2}p^{4}\tau}{\bar{L}^{6}\alpha^{4}\beta^{2}\tau}\leq\frac{1} {326}\quad\quad\frac{33554432LL_{\max}\hat{L}^{2}\omega^{2}p^{4}\tau}{\bar{L}^ {6}\alpha^{4}\beta^{2}\tau}\leq\frac{1}{326}\quad\quad\frac{67108864LL_{\max} \hat{L}^{2}\omega^{2}p^{3}\tau}{\bar{L}^{6}\alpha^{4}\beta^{3}n^{2}}\leq\frac{ 1}{326}\quad\quad\frac{67108864LL_{\max}\hat{L}^{4}\omega^{3}p^{2}\tau}{\bar{L }^{6}\alpha^{4}\beta n^{3}}\leq\frac{1}{326}\quad\quad\] (236)

\[\frac{67108864L^{3}L_{\max}\hat{L}^{2}\omega^{2}p^{3}}{\bar{L}^{6} \alpha^{4}\beta n^{2}\tau^{2}}\leq\frac{1}{326}\quad\quad\frac{134217728L^{2} L_{\max}\hat{L}^{2}\omega^{2}p^{5}}{\bar{L}^{5}\alpha^{3}\beta^{4}n^{2}\tau}\leq \frac{1}{326}\quad\quad\frac{138412032L^{2}L_{\max}\hat{L}^{2}\omega^{2}p^{3} }{\bar{L}^{5}\alpha^{3}\beta^{2}n^{2}\tau}\leq\frac{1}{326}\quad\quad\frac{13 8412032L^{2}L_{\max}\hat{L}^{2}\omega^{2}p^{3}}{\bar{L}^{5}\alpha^{3}\beta^{2} n^{2}\tau}\leq\frac{1}{326}\quad\quad\] (239)

\[\frac{268435456L^{2}L_{\max}\hat{L}^{2}\omega^{2}p^{6}}{\bar{L}^{5} \alpha^{3}\beta^{4}n^{2}\tau^{2}}\leq\frac{1}{326}\quad\quad\frac{268435456L^ {2}L_{\max}\hat{L}^{2}\omega^{2}p^{4}}{\bar{L}^{5}\alpha^{3}\beta^{3}n^{2}\tau }\leq\frac{1}{326}\quad\quad\frac{276824064L^{2}L_{\max}\hat{L}^{2}\omega^{2}p ^{4}}{\bar{L}^{5}\alpha^{3}\beta^{2}n^{2}\tau^{2}}\leq\frac{1}{326}\quad \quad\frac{1}{243}\quad\quad\] (241)

\[\frac{536870912LL_{\max}\hat{L}^{4}\omega^{3}p^{4}\tau}{\bar{L}^{6} \alpha^{4}\beta^{4}n^{3}}\leq\frac{1}{326}\quad\quad\frac{536870912LL_{\max} \hat{L}^{4}\omega^{3}p^{2}\tau}{\bar{L}^{6}\alpha^{4}\beta^{2}n^{3}}\leq\frac{ 1}{326}\quad\quad\frac{536870912LL_{\max}\hat{L}^{4}\omega^{3}p^{2}\tau}{\bar{ L}^{6}\alpha^{4}\beta^{2}n^{3}}\leq\frac{1}{326}\quad\quad\frac{536870912L^{2}L_{\max} \hat{L}^{2}\omega^{2}p^{5}}{\bar{L}^{5}\alpha^{3}\beta^{3}n^{2}\tau^{2}}\leq \frac{1}{326}\quad\quad\] (242)

\[\frac{536870912L^{3}L_{\max}\hat{L}^{2}\omega^{2}p^{5}}{\bar{L}^{6} \alpha^{4}\beta^{4}n^{2}\tau}\leq\frac{1}{326}\quad\quad\frac{570425344L^{3}L_ {\max}\hat{L}^{2}\omega^{2}p^{3}}{\bar{L}^{6}\alpha^{4}\beta^{2}n^{2}\tau}\leq \frac{1}{326}\quad\quad\frac{1073741824LL_{\max}\hat{L}^{4}\omega^{3}p^{5} \tau}{\bar{L}^{6}\alpha^{4}\beta^{4}n^{3}}\leq\frac{1}{326}\quad\quad\] (243)

\[\frac{1073741824LL_{\max}\hat{L}^{4}\omega^{3}p^{3}\tau}{\bar{L}^{6} \alpha^{4}\beta^{3}n^{3}}\leq\frac{1}{326}\quad\frac{1073741824L^{3}L_{\max} \hat{L}^{2}\omega^{2}p^{6}}{\bar{L}^{6}\alpha^{4}\beta^{3}n^{2}\tau^{2}}\leq \frac{1}{326}\quad\quad\frac{1073741824L^{3}L_{\max}\hat{L}^{2}\omega^{2}p^{ 4}}{\bar{L}^{6}\alpha^{4}\beta^{3}n^{2}\tau}\leq\frac{1}{326}\quad\quad\] (251)

\[\frac{1140850688LL_{\max}\hat{L}^{4}\omega^{3}p^{3}\tau}{\bar{L}^{6} \alpha^{4}\beta^{2}n^{3}}\leq\frac{1}{326}\quad\frac{1140850688L^{3}L_{\max} \hat{L}^{2}\omega^{2}p^{4}}{\bar{L}^{6}\alpha^{4}\beta^{2}n^{2}\tau^{2}}\leq \frac{1}{326}\quad\frac{2147483648LL_{\max}\hat{L}^{4}\omega^{3}p^{4}\tau}{ \bar{L}^{6}\alpha^{4}\beta^{3}n^{3}}\leq\frac{1}{326}\quad\quad\] (252)

\[\frac{2147483648L_{\max}\hat{L}^{4}\omega^{3}p^{4}}{\bar{L}^{6} \alpha^{4}\beta^{3}n^{2}\tau^{2}}\leq\frac{1}{326}\quad\frac{2147483648L^{2}L_ {\max}\hat{L}^{4}\omega^{3}p^{4}}{\bar{L}^{7}\alpha^{4}\beta^{4}n^{3}\tau}\leq \frac{1}{326}\quad\frac{2147483648L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{4}}{ \bar{L}^{7}\alpha^{4}\beta^{2}n^{3}\tau}\leq\frac{1}{326}\] (253)

\[\frac{2147483648L_{\max}\hat{L}^{4}\omega^{3}p^{4}}{\bar{L}^{6} \alpha^{4}\beta^{3}n^{2}\tau^{2}}\leq\frac{1}{326}\quad\frac{2147483648L^{2}L_ {\max}\hat{L}^{4}\omega^{3}p^{5}}{\bar{L}^{7}\alpha^{4}\beta^{4}n^{3}\tau}\leq \frac{1}{326}\quad\frac{2147483648L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{3}}{ \bar{L}^{7}\alpha^{4}\beta^{2}n^{3}\tau}\leq\frac{1}{326}\] (254)

\[\frac{4294967296L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{6}}{\bar{L}^{7} \alpha^{4}\beta^{4}n^{3}\tau^{2}}\leq\frac{1}{326}\quad\frac{4294967296L^{2}L_{ \max}\hat{L}^{4}\omega^{3}p^{4}}{\bar{L}^{7}\alpha^{4}\beta^{3}n^{3}\tau}\leq \frac{1}{326}\quad\frac{4294967296L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{4}}{ \bar{L}^{7}\alpha^{4}\beta^{2}n^{3}\tau^{2}}\leq\frac{1}{326}\] (255)\[\frac{8589934592L^{2}L_{\max}\hat{L}^{4}\omega^{3}p^{5}}{\bar{L}^{7} \alpha^{4}\beta^{3}n^{3}\tau^{2}}\leq\frac{1}{326}\quad\frac{8589934592L^{3}L_{ \max}\hat{L}^{4}\omega^{3}p^{5}}{\bar{L}^{8}\alpha^{5}\beta^{4}n^{3}\tau}\leq \frac{1}{326}\quad\frac{8589934592L^{3}L_{\max}\hat{L}^{4}\omega^{3}p^{5}}{ \bar{L}^{8}\alpha^{5}\beta^{2}n^{3}\tau}\leq\frac{1}{326}\] (263)

\[\frac{17179869184LL_{\max}\hat{L}^{6}\omega^{4}p^{5}\tau}{\bar{L}^{8}\alpha^{5} \beta^{4}n^{4}}\leq\frac{1}{326}\quad\frac{17179869184LL_{\max}\hat{L}^{6} \omega^{4}p^{3}\tau}{\bar{L}^{8}\alpha^{5}\beta^{2}n^{4}}\leq\frac{1}{326} \quad\frac{17179869184L^{3}L_{\max}\hat{L}^{4}\omega^{3}p^{6}}{\bar{L}^{8} \alpha^{5}\beta^{4}n^{3}\tau^{2}}\leq\frac{1}{326}\] (264)

\[\frac{17179869184L^{3}L_{\max}\hat{L}^{4}\omega^{3}p^{4}}{\bar{L}^{8}\alpha^{5} \beta^{3}n^{3}\tau}\leq\frac{1}{326}\quad\frac{17179869184L^{3}L_{\max}\hat{L} ^{4}\omega^{3}p^{4}}{\bar{L}^{8}\alpha^{5}\beta^{2}n^{3}\tau^{2}}\leq\frac{1}{ 326}\quad\frac{34359738368LL_{\max}\hat{L}^{6}\omega^{4}p^{4}\tau}{\bar{L}^{8} \alpha^{5}\beta^{3}n^{4}}\leq\frac{1}{326}\] (265)

\[\frac{34359738368L^{3}L_{\max}\hat{L}^{4}\omega^{3}p^{5}}{\bar{L}^{8}\alpha^{5 }\beta^{3}n^{3}\tau^{2}}\leq\frac{1}{326}\] (266)

## Appendix M Symbolically Computed Expression (92)

\[\frac{2L}{\bar{L}}+\frac{1024L^{3}}{\bar{L}^{3}\alpha^{2}}+\frac{4 096L^{3}p}{\bar{L}^{3}\alpha^{2}\tau}\] \[+\frac{8192L^{3}p^{2}}{\bar{L}^{3}\alpha^{2}\tau^{2}}+\frac{256 \hat{L}^{2}\omega p}{\bar{L}^{2}\beta n}+\frac{256\hat{L}^{2}\omega p^{2}}{ \bar{L}^{2}\beta^{2}n}\] \[+\frac{1024L\hat{L}^{2}\omega p}{\bar{L}^{3}\alpha\beta n}+\frac {1024L\hat{L}^{2}\omega p^{2}}{\bar{L}^{3}\alpha\beta^{2}n}+\frac{8192L\hat{L }^{2}\omega p\tau}{\bar{L}^{3}\alpha^{2}n}\] \[+\frac{131072L^{2}\hat{L}^{2}\omega p}{\bar{L}^{4}\alpha^{2}\beta n }+\frac{131072L^{2}\hat{L}^{2}\omega p^{2}}{\bar{L}^{4}\alpha^{2}\beta^{2}n}+ \frac{1048576L^{3}\hat{L}^{2}\omega p}{\bar{L}^{5}\alpha^{3}\beta n}\] \[+\frac{1048576L^{3}\hat{L}^{2}\omega p^{2}}{\bar{L}^{5}\alpha^{3} \beta^{2}n}+\frac{1048576\hat{L}^{4}\omega^{2}p^{2}\tau}{\bar{L}^{4}\alpha^{2 }\beta^{2}n^{2}}+\frac{1048576\hat{L}^{4}\omega^{2}p^{3}\tau}{\bar{L}^{4} \alpha^{2}\beta^{2}n^{2}}\] \[+\frac{16777216\hat{L}^{4}\omega^{2}p^{4}\tau}{\bar{L}^{4}\alpha^ {2}\beta^{4}n^{2}}+\frac{16777216\hat{L}^{4}\omega^{2}p^{2}\tau}{\bar{L}^{4} \alpha^{2}\beta^{2}n^{2}}+\frac{33554432\hat{L}^{4}\omega^{2}p^{3}\tau}{\bar{ L}^{4}\alpha^{2}\beta^{3}n^{2}}\] \[+\frac{67108864L^{2}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{6}\alpha^ {3}\beta^{4}n^{2}}+\frac{67108864L^{2}\hat{L}^{4}\omega^{2}p^{2}}{\bar{L}^{6} \alpha^{3}\beta^{2}n^{2}}+\frac{134217728L^{2}\hat{L}^{4}\omega^{2}p^{3}}{ \bar{L}^{6}\alpha^{3}\beta^{3}n^{2}}\] \[+\frac{268435456L^{3}\hat{L}^{4}\omega^{2}p^{4}}{\bar{L}^{7}\alpha ^{4}\beta^{4}n^{2}}+\frac{268435456L^{3}\hat{L}^{4}\omega^{2}p^{2}}{\bar{L}^{7} \alpha^{4}\beta^{2}n^{2}}+\frac{536870912\hat{L}^{6}\omega^{3}p^{5}\tau}{\bar{L }^{6}\alpha^{3}\beta^{4}n^{3}}\] \[+\frac{536870912\hat{L}^{6}\omega^{3}p^{3}\tau}{\bar{L}^{6}\alpha^ {3}\beta^{2}n^{3}}+\frac{536870912L^{3}\hat{L}^{4}\omega^{2}p^{3}}{\bar{L}^{7} \alpha^{4}\beta^{3}n^{2}}+\frac{1073741824\hat{L}^{6}\omega^{3}p^{4}\tau}{\bar{L }^{6}\alpha^{3}\beta^{3}n^{3}}\] \[+\frac{131072L\hat{L}^{2}\omega p\tau}{\bar{L}^{3}\alpha^{2}\beta n }+\frac{131072L\hat{L}^{2}\omega p^{2}\tau}{\bar{L}^{3}\alpha^{2}\beta^{2}n}+ \frac{524288L^{2}\hat{L}^{2}\omega p^{2}}{\bar{L}^{4}\alpha^{2}\beta n\tau}\] \[+\frac{524288L^{2}\hat{L}^{2}\omega p^{3}}{\bar{L}^{4}\alpha^{2} \beta^{2}n\tau}+\frac{1048576L^{2}\hat{L}^{2}\omega p^{3}}{\bar{L}^{4}\alpha^{2} \beta n\tau^{2}}+\frac{1048576L^{2}\hat{L}^{2}\omega p^{4}}{\bar{L}^{4}\alpha^{2 }\beta^{2}n\tau^{2}}\] \[+\frac{4194304L^{3}\hat{L}^{2}\omega p^{2}}{\bar{L}^{5}\alpha^{3} \beta n\tau}+\frac{4194304L^{3}\hat{L}^{2}\omega p^{3}}{\bar{L}^{5}\alpha^{3} \beta^{2}n\tau}+\frac{8386808L^{3}\hat{L}^{2}\omega p^{3}}{\bar{L}^{5}\alpha^{3} \beta n\tau^{2}}\]

[MISSING_PAGE_EMPTY:55]

[MISSING_PAGE_EMPTY:56]

[MISSING_PAGE_EMPTY:57]

[MISSING_PAGE_EMPTY:58]

[MISSING_PAGE_EMPTY:59]

[MISSING_PAGE_EMPTY:60]

[MISSING_PAGE_EMPTY:61]

[MISSING_PAGE_EMPTY:62]

Jupyter Notebook for Symbolic Computations

## 1 Import Necessary Libraries

[ ]: import os from IPython.display import display imports sympy from sympy import Symbol from utils import FileWriter, ConstraintsAggregator from utils import get_factors, get_term, search_factors, \(\ll\) latex_repres_of_inequality

## 2 Initialize a File for Results

[ ]: file_path = '../paper/result.txt' if os.path.exists(file_path): os.remove(file_path) fw = FileWriter(file_path)

## 3 Initialize Symbols From the Paper

[ ]: rho = Symbol('rho', nonnegative=True) kappa = Symbol('kappa', nonnegative=True) lmbda = Symbol('lambda', nonnegative=True) omega = Symbol('omega', nonnegative=True) p = Symbol('p', positive=True) tau = Symbol('tau', positive=True) beta = Symbol('beta', positive=True) alpha = Symbol('alpha', positive=True) n = Symbol('n', positive=True) L = Symbol('L', positive=True) L_hat = Symbol(r'\hat[L]', positive=True)L_max=Symbol(r^L_{max}',positive=True) L_bar=Symbol(r^\bar{L}',positive=True) ```

## 4 Assistant for "First Symbolically Computed" Lemma

### Calculate Expressions

``` [.]:nu_hat_exp=(8/alpha)*(p*L/2+kappa*4*p*(1+p/beta)*L_hat**2+rho*4*p*L**2+rho*(8*p/tau)*(2*p*(1+2*p/tau)*_-L**2+4*p*tau**2*omega*_-L_hat**2/n)) nu_hat=Symbol(r^\hat{\nu}',nonnegative=True) #Theleft hand sides of the inequalities rho_lhs=nu_hat*(8/(alpha*p*L_bar**2)) kappa_lhs=((8*p*omega)/(n*L_bar*beta)+nu_hat*(8*omega)/(n*beta*L_bar**2)+rho*(8*p)/tau*(8*tau**2*omega)/(n*beta)) ```

### Display Them

``` [.]:display(nu_hat_exp) display(rho_lhs) display(kappa_lhs) ```

### Symbolically Calculate The Steps From The Proof

``` [.]:constraints_agg=ConstraintsAggregator() rho_lhs=rho_lhs.subs(nu_hat,nu_hat_exp) kappa_lhs=kappa_lhs.subs(nu_hat,nu_hat_exp)
#GroupTermsw.r.t.kappakappa_lhs_poly=sympy.poly(kappa) kappa_coef=kappa_lhs_poly.all_coeffs() kappa_lhs=kappa_lhs.expand().collect(kappa) fw.write(sympy.latex(kappa_lhs)+",\label{eq:kappa_expand}")
#FindConditionsWhenTheCoefficientsNearKappa<=1/2 terms=sympy.expand(kappa_coef[0]).args latex_string=constraints_agg.add_constraints(terms) fw.write(latex_string)

Definekappa kappa_solution = (2 * kappa_coef[1]).expand() fw.write("\kappa\eqdef " + sympy.latex(kappa) + ". \label{eq: _~kappa_sol}")

GroupTermsw.r.t. rho_lhs = rho_lhs.subs(kappa, kappa_solution) rho_lhs = rho_lhs.expand().collect(rho) fw.write(sympy.latex(rho_lhs) + ", \label{eq:rho_expand}")

FindConditionsWhenTheCoefficientsNearrho<=1/2 rho_lhs_poly = sympy.poly(rho_lhs, rho) rho_coef = rho_lhs_poly.all_coeffs() terms = sympy.expand(rho_coef[0]).args latex_string = constraints_agg.add_constraints(terms) fw.write(latex_string)

Definerho rho_solution = (2 * rho_coef[1]).expand() fw.write("\rho\eqdef " + sympy.latex(rho_solution) + ". \label{eq:rho_sol}")

## 5 Assistant for "Second Symbolically Computed" Lemma

### First Inequality

```
[]:bregman_coef=((4 * omega * L_max) / (n * L_bar) + kappa * 8 * (1 + p / beta) * L_max + (nu_hat / L_bar**2) * (4 * omega * L_max / (p * n) + 8 * L / _~(p * alpha)) + rho * 8 * L + lmbda * (4 * (1 + (2 * p) / tau) * L + 8 * tau**2 * omega * _~L_max / n)) display(bregman_coef) lmbda_solution = rho * 8 * p / tau
Substitueallknownexpressionstotheterm bregman_coef= \ bregman_coef.subs(nu_hat,nu_hat_exp).subs(lmbda,lmbda_solution).subs(kappa,kappa_solution).subs(rho,rho_solution) bregman_coef = bregman_coef.expand().simplify().expand() latex_string = latex_repres_of_inequality(bregman_coef) fw.write(latex_string)
latex_string=constraints_agg.add_constraints(terms) fw.write(latex_string) ```

### Second Inequality

```
[]:dist_coef=(4/L_bar)*(L/2+kappa*4*(1+p/beta)*L_hat**2+rho*4*L**2+lmbda*(2*(1+2*p/tau)*L**2+4*tau**2*_omega*L_hat**2/n)) display(dist_coef) dist_coef=\ dist_coef.subs(lmbda,lmbda_solution).subs(kappa,kappa).subs(rho,\_ rho_solution) dist_coef=dist_coef.expand().simplify().expand() latex_string=latex_repres_of_inequality(dist_coef,rhs="1") fw.write(latex_string) terms=dist_coef.args latex_string=constraints_agg.add_constraints(terms) fw.write(latex_string) ```

## 6 Check That The Constraints Follow From The Inequalities from The "Auxillary Inequalities" Lemma.

### The Inequalities from The "Auxillary Inequalities" Lemma:

```
[]:fromcollectionsimportOrderedDict__contstant=1 proposals=OrderedDict([ ("eq:lipt:max_2",(L_max*omega*p**2)/(beta**2*n)), ("eq:lipt:max_1",(L_max*omega*p)/(beta*n)), ("eq:lipt:max",(L_max*omega)/(n)), ("eq:lipt:l_max_2",(sympy.sqrt(L*L_max)*p*sympy.sqrt(omega*_\(\_\) tau))/(alpha*beta*sympy.sqrt(n))), ("eq:lipt:l_max_1",(sympy.sqrt(L*L_max)*sympy.sqrt(p*omega*_\(\_\) tau))/(alpha*sympy.sqrt(beta*n))), ("eq:lipt:l_max_p",(sympy.sqrt(L*L_max)*sympy.sqrt(p*omega*_\(\_\) tau))/(alpha*sympy.sqrt(n))), ("eq:lipt:hat_2",(L_hat*p*sympy.sqrt(omega*tau))/(alpha*_\(\_\) beta*sympy.sqrt(n))), ("eq:lipt:hat_1",(L_hat*sympy.sqrt(p*omega*tau))/(alpha*_\(\_\) sympy.sqrt(beta*n))), ("eq:lipt:hat_p",(L_hat*sympy.sqrt(p*omega*tau))/(alpha*_\(\_\) sympy.sqrt(n))),("eq:lipt:hat_alpha_2", (L_hat * p * sympy.sqrt(omega)) / (beta * sympy. - sqrt(alpha * n))),  ("eq:lipt:hat_alpha_1", (L_hat * sympy.sqrt(p * omega)) / (sympy.sqrt(beta_ -* alpha * n))),  ("eq:lipt:hat_no_alpha_2",(L_hat * p * sympy.sqrt(omega)) / (beta * sympy. - sqrt(n))),  ("eq:lipt:hat_no_alpha_1",(L_hat * sympy.sqrt(p * omega)) / (sympy.sqrt(beta_ -* n))),  ("eq:lipt:plain", (L) / (alpha)),  ("eq:lipt:plain_p_alpha", (L * p) / (alpha * tau)),  ("eq:lipt:plain_no_alpha",(L)),  ("eq:lipt:double_lipt_2", sympy.cbrt((L * L_hat**2 * omega * p**4) /\(\ll\) -(alpha**2 * beta**2 * n * tau**2))),  ("eq:lipt:double_lipt_1", sympy.cbrt((L * L_hat**2 * omega * p**3) /\(\ll\) -(alpha**2 * beta * n * tau**2))),  ]) const = 660508 for k, proposal in proposals.items(): proposals[k] = (const * proposal / L_bar).expand() proposals_factors = [get_factors(proposal) for _, proposal in proposals.items()]

### Search The Right Inequalities for Each Constraint

``` []:#Takes~1houronalaptop importtqdm constraints=constraints_agg.get_constraints() constraints_inequalities=[] fori,factorinenumerate(tqdm.tqdm(constraints)): num_of_base_factors_to_use=-int(factor[L_bar]) path=search_factors(factor,num_of_base_factors_to_use,proposals_factors, pos_hints=[L,L_max,L_hat,omega,p], neg_hints=[alpha,n]) constraints_inequalities.append(path) assertpathisnotNone ```
[ ]:text=constraints_agg.prepare_text_from_proposals(proposals,\(\ll\) -constraints_inequalities) fw.write(text) ```

### File utils.py

```
1importos
2fromcollectionsimportdefaultdict
3fromcopyimportcopy
4
5importsympy
6
7class_defaultdictwithconst(defaultdict):
9def_init__(self,*args,**kwargs):
10super(_defaultdictwithconst,self)__init__(*args,**kwargs)
11self.const=None
12
13def_copy__(self):
14obj=super(_defaultdictwithconst,self)__copy__()
15obj.const=self.const
16returnobj
17
18
19def_factors(term):
20"""Convertsasympyexpressionwiththesympy.Multypetoadictionarywithfactors.
21Ex:A^2/B^(1/2)->{A:2,B:-1/2}
22Args:
23param1:sympyexpression(sympy.Mul).
24"""
25factors=_defaultdictwithconst(int)
26factors.const=1
27const_assigned=False
28assertisinstance(term,sympy.Mul)
29forelinterm.args:
21fore_symbols=list(el.free_symbols)
22iflen(free_symbols)==0:
23assertnotconst_assigned=True
24factors.const=int(el) continue
25assertlen(free_symbols)==1
26power=el.as_powers_dict()[free_symbols[0]]
27assert isinstance(power,sympy.Rational)
28factors[free_symbols[0]]=power
29returnfactors
30
31
32
33def_term(factors):
34"""Theinversefunctionotheget_factorsfunction:convertsfactorstoaterm
35Ex:{A:2,B:-1/2}->A^2/B^(1/2)
36Args:
37param1:dictionarywithfactors
38"""
39result=factors.const
40fork,vinfactors.items():
41result=result*k**v
42returnresult
43
44
45defsearch_factors(factors,num_of_base_factors_to_use,base_factors,pos_hints=[],neg_hints=[]):
46"""Checksifippossibletodecompose'factors'usingnum_of_base_factorsfactorsfrom'base_factors'Args:
47Args:
48param1:dictionarywithfactors
49param2:numberofbasefactorstouse
50param3:listofdictionarieswithfactors* [61] param4andparam5:hintstothealgorithmthathelpstoimproverformance
* [62] Returns:
* [63]Alistwithindices(withrepetitions)of'base_factors'thatcompose'factors'.
* [64]Ifintopossible,thenthefunctionreturnsNone.
* [65]"""
* [66]def_check_hints(factors_):
* [67]forkinpos_hints:
* [68]assertfactors.[k]>=0
* [69]forkinneg_hints:
* [70]assertfactors.[k]<=0
* [71]_check_hints(factors)
* [72]forbaseinbase_factors:
* [73]_check_hints(base)
* [74]def_search_factors(factors,num_of_base_factors_to_use,path,base_factors):
* [75]ifnum_of_base_factors_to_use==0:
* [76]returnfactors.const<=1andall([factors[k]==0forkinfactors])
* [77]forindex,choiceinenumerate(base_factors):
* [78]factor_choice=copy(factors)
* [79]factor_choice.const=factor_choice.const/choice.const
* [80]fork,vincoice.items():
* [81]factor_choice[k]=factor_choice[k]-v
* [82]skip=False
* [83]forkinpos_hints:
* [84]iffactor_choice[k]<0:
* [85]skip=True
* [86]break
* [87]forkinneg_hints:
* [88]iffactor_choice[k]>0:
* [89]skip=True
* [90]break
* [91]ifnotskipand_search_factors(factor_choice,num_of_base_factors_to_use,path,base_factors):
* [92]path.append(index)
* [93]returnTrue
* [94]returnFalse
* [95]path=[]
* [96]if_search_factors(factors,num_of_base_factors_to_use,path,base_factors):
* [97]returnpath
* [98]else:
* [99]returnNone
* [90]
* [91]classFileWriter(object):
* [93]def__init__(self,file_path):
* [94]self..file_path=file_path
* [95]assertnotos.path.exists(file_path)
* [96]
* [97]defwrite(self,text):
* [98]withopen(self..file_path,"a")asfd:
* [99]fd.write("{}\n".format(text))
* [91]
* [91]
* [92]classConstraintsAggregator(object):
* [93]def__init__(self):
* [94]self..constraints=[]
* [95]
* [96]defget_constraints(self):
* [97]returnself..constraints
* [98]defadd_constraints(self,terms):
* [99]denom_constant=self..denom_constant(terms)
* [99]terms_global_index=[]
* [90]forterminers:
* [91]terms_global_index.append(len(self..constraints))

[MISSING_PAGE_FAIL:70]

[MISSING_PAGE_FAIL:71]

## Appendix R Convergence Rate of Canita obtained by Li and Richtarik (2021)

In their Equation (54), Li and Richtarik (2021) derive the following bound for their CANITA method:

\[\mathbb{E}\left[F^{T+1}\right] \leq\mathcal{O}\left(\max\left\{\frac{(1+\omega)^{3}}{T^{3}},\frac{ (1+b)(\beta+3/2)L}{T^{2}}\right\}\right).\]

In the regime when \(\omega\geq n,\) choosing \(b=\omega\) and \(\beta=\Theta\left(\frac{\omega}{n}\right)\) in their Equation (10) gives

\[\mathbb{E}\left[F^{T+1}\right] \leq\mathcal{O}\left(\max\left\{\frac{(1+\omega)^{3}}{T^{3}}, \frac{(1+b)(\beta+3/2)L}{T^{2}}\right\}\right)\] \[=\mathcal{O}\left(\max\left\{\frac{(1+\omega)^{3}}{T^{3}},\frac{ \omega(\omega/n+3/2)L}{T^{2}}\right\}\right)\] \[=\mathcal{O}\left(\max\left\{\frac{(1+\omega)^{3}}{T^{3}},\frac{ \omega^{2}L}{nT^{2}}\right\}\right).\]

This means that the correct convergence rate of the CANITA method (Li and Richtarik, 2021) is

\[T=\begin{cases}\Theta\left(\frac{\omega}{\varepsilon^{1/3}}+\frac{\omega}{ \sqrt{n}}\sqrt{\frac{L}{\varepsilon}}\right),&\omega\geq n,\\ \Theta\left(\frac{\omega}{\varepsilon^{1/3}}+\left(1+\frac{u^{3/4}}{n^{1/4}} \right)\sqrt{\frac{L}{\varepsilon}}\right),&\omega<n.\end{cases}\] (329)

Comparing this result with our Theorem E.14 describing the convergence of our method 2Direction, one can see that in the low accuracy regimes (in particular, when \(\frac{\omega}{\varepsilon^{1/3}}\) dominates in (329)), our result improves \(\Theta\left(\frac{1}{\varepsilon^{1/3}}\right)\) to at least \(\Theta\left(\log\frac{1}{\varepsilon}\right).\) However, the dependence \(\Theta\left(\log\frac{1}{\varepsilon}\right)\) should not be overly surprising as it was observed by Lan et al. (2019) already, albeit in a somewhat different context.

## Appendix S Comparison with Adiana

We now want to check that our rate (14) restores the rate from (Li et al., 2020). Since ADIANA only compresses from the workers to the server, let us take \(r=0,\) the identity compressor operator \(\mathcal{C}^{P}(x)=x\) for all \(x\in\mathbb{R}^{d},\) which does not perform compression, and, as in (Li et al., 2020), consider the optimistic case, when \(L_{\text{max}}=L\). For this compressor, we have \(\alpha=1\) in (2). Note that \(\mu^{r}_{\omega,\alpha}=0.\) Thus the iteration complexity (14) equals

\[T^{\text{optimistic}} =\widetilde{\Theta}\Bigg{(}\max\left\{\sqrt{\frac{L}{\mu}}, \sqrt{\frac{L(\omega+1)}{n^{1/3}\mu}},\sqrt{\frac{L(\omega+1)^{3/2}}{\sqrt{n} \mu}},\sqrt{\frac{L\omega(\omega+1)}{n\mu}},(\omega+1)\right\}\Bigg{)}\] \[=\widetilde{\Theta}\Bigg{(}\max\left\{\sqrt{\frac{L}{\mu}},\sqrt{ \frac{L(\omega+1)^{3/2}}{\sqrt{n}\mu}},\sqrt{\frac{L\omega(\omega+1)}{n\mu}}, (\omega+1)\right\}\Bigg{)},\] (330)

where we use Young's inequality: \(\sqrt{\frac{L}{\mu}}\sqrt{\frac{(\omega+1)}{n^{1/3}}}\leq\sqrt{\frac{L}{\mu} }\sqrt{\frac{1}{3}\times 1^{3}+\frac{2}{3}\frac{(\omega+1)^{3/2}}{\sqrt{n}}}.\) Without the server-to-worker compression, Algorithm 1 has the same iteration (330) and communication complexity as (Li et al., 2020).

Figure 4: Logistic Regression with _CIFAR10_ dataset. # of workers \(n=100.\)\(K=1000\) in all compressors.