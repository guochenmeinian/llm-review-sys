TFLEX: Temporal Feature-Logic Embedding Framework for Complex Reasoning over Temporal Knowledge Graph

Xueyuan Lin\({}^{1}\) Haihong E\({}^{1}\)1 Chengjin Xu\({}^{2}\)1 Gengxian Zhou\({}^{1}\)

Haoran Luo\({}^{1}\) Tianyi Hu\({}^{1}\) Fenglong Su\({}^{3}\) Ningyuan Li\({}^{1}\) Mingzhi Sun\({}^{1}\)

\({}^{1}\) Beijing University of Posts and Telecommunications

\({}^{2}\) University of Bonn

\({}^{3}\) National University of Defense Technology

linxy59@mail2.sysu.edu.cn, ehaihong@bupt.edu.cn, xuc@iai.uni-bonn.de

z.gengxian@se18.qmul.ac.uk, {luohaoran, hutianyi}@bupt.edu.cn

sufenglong18@nudt.edu.cn, {jason.ningyuan.li, sunmingzhi}@bupt.edu.cn

###### Abstract

Multi-hop logical reasoning over knowledge graph plays a fundamental role in many artificial intelligence tasks. Recent complex query embedding methods for reasoning focus on static KGs, while temporal knowledge graphs have not been fully explored. Reasoning over TKGs has two challenges: 1. The query should answer entities or timestamps; 2. The operators should consider both set logic on entity set and temporal logic on timestamp set. To bridge this gap, we introduce the multi-hop logical reasoning problem on TKGs and then propose the first temporal complex query embedding named Temporal Feature-Logic Embedding framework (TFLEX) to answer the temporal complex queries. Specifically, we utilize fuzzy logic to compute the logic part of the Temporal Feature-Logic embedding, thus naturally modeling all first-order logic operations on the entity set. In addition, we further extend fuzzy logic on timestamp set to cope with three extra temporal operators (**After**, **Before** and **Between**). Experiments on numerous query patterns demonstrate the effectiveness of our method.

## 1 Introduction

Multi-hop logical reasoning over knowledge graphs (KGs) is a fundamental issue in artificial intelligence. It aims to find the answer entities for a first-order logic (FOL) query which involves logical operators (existential quantification \(\exists\), conjunction \(\wedge\), disjunction\(\vee\) and negation\(\neg\)). Generally, the query is parsed into computation graph, according to which subgraph matching is executed on KG to find the answers. The computation graph is a directed acyclic graph (DAG) whose nodes represent entity sets, and edges represent logical operators acting on entity sets. However, results are inevitably incorrect as KGs are incomplete and noisy. Besides, the computation complexity will spiral for large-scale KGs or large queries. Therefore, people propose to embed query into low-dimensional space to solve the problem.

Query embedding (QE) learns the embeddings of queries and entities, so that answer entities are close to its queries in the embedding space. It has attracted arising attention, as low-dimension embeddings can model implicit dependency and reduce computation. There follows a series of QE methods, including GQE[1], Query2box[2], BetaE[3], ConE[4], etc. However, existing works only focus on queries over static KGs. These methods can neither handle an entity query involving temporal information and operators, nor answer the timestamp set for a temporal query.

Temporal knowledge graph (TKG) augments triples in static knowledge graphs with temporal information, represented as \(<\)**head, relation, tail, timestamp\(>\)** named fact. For example, the fact \(<\)**Angela Merkel, make a visit, China, 2010-07-16\(>\)** specifies the time when the event happens. Generally speaking, TKGs are more close to real world than static KGs, because most knowledge needs to be updated with time, and static KGs cannot express this change. In recommendation systems, TKGs are used to model user behaviors, which includes liking, buying, reading, commenting and so on. In financial applications, TKGs involve stock holding behaviors, trading behaviors, and financial events. These applications require reasoning over TKGs to answer complex queries. However, recent researches in TKGs focus on temporal link prediction, which is simply single-hop. A complex logical query involving multiple facts for multi-hop reasoning is not fully explored yet.

To fill the gap, we introduce a temporal multi-hop logical reasoning task over TKGs. The task aims to answer temporal complex queries, which have two main distinctions from existing queries over static KGs. Firstly, the answer sets for queries over TKGs are either entity sets or timestamp sets, while that for existing queries over static KGs can only be entity sets. Secondly, as temporal information is included in the query, temporal operators such as **After**, **Before** should be considered apart from FOL operators. To understand this new task, we provide the definition of temporal complex query in Section 3. In addition, an example of a temporal complex query is shown in Figure 1. This example query pertains to the financial event of China's visit and may be of interest to financial analysts.

According to the definition of the temporal complex query, we then generate datasets of temporal complex queries on three popular TKGs, and propose the first temporal complex query embedding framework, Temporal Feature-Logic Embedding framework (TFLEX) to answer these queries. In our framework, embeddings of objects (entity, query, timestamp) are divided into two parts, the entity part, and the timestamp part. The entity part handles the FOL operations over entities, while the timestamp part copes with the temporal operations over timestamps. Each part is further divided into feature and logic components. On the one hand, the computation of the logic components follows fuzzy logic, which enables our framework to handle all FOL operations. On the other hand, feature components are mingled and transformed under the guidance of logic components, thereby integrating logical information into the feature. Moreover, we extend fuzzy logic to support extra temporal operations (**After**, **Before** and **Between**) to handle temporal operations in the queries.

The contributions of our work are summarized as follows: (1) For the first time, the definition of the task of multi-hop logical reasoning over TKGs is given. (2) We propose the first multi-hop logical reasoning framework on TKGs, namely Temporal Feature-Logic Embedding framework (TFLEX),

Figure 1: A typical multi-hop temporal complex query and its computation graph: “During François Hollande was the president of France, which countries did Xi Jinping visit but Barack Obama did not visit?”. In the computation graph, there are entity set (blue circle), timestamp set (green triangle), time set projection (green arrow), entity set projection (blue arrow) and logical operators (red rectangle).

which supports all FOL operations and extra temporal operations (**After**, **Before** and **Between**). (3) We generate three new TKG datasets for the task of multi-hop logical reasoning. Experiments on three generated datasets demonstrate the efficacy of the proposed framework. The source code of our framework and the datasets are available online *.

Footnote *: https://github.com/LinXueyuanStdio/TFLEX

## 2 Related Work

**Complex Query Embedding**. It learns embeddings of queries and entities, and the answer entities are close to queries in the embedding space. Existing methods utilize a lot of objects to create the embeddings, such as (1) probability distribution [3; 5] (2) geometric object [1; 2; 4; 6; 7] (3) fuzzy logic [8; 9; 10] and (4) others [11; 12; 13]. However, existing embedding-based methods are considered on static KGs. They cannot utilize temporal information in the TKGs, and therefore cannot handle temporal queries on a temporal KG. Firstly, static query embeddings (QEs) are built over (s, r, o) triples instead of (s, r, o, t) quartets, thus ignoring the timestamps for temporal complex reasoning. The second reason is the order property of timestamps, which is on the contrary that entities are unordered, leading to that static QEs are unable to handle **Before** and **After** temporal logic. In addition, we also notice the semantic conflict in experiments (see section 5.2) when concatenating the geometric embedding (static QE) with the fuzzy embedding (that can handle temporal logic) to promote the static QE to temporal one. Therefore, it is challenging for static QEs to utilize temporal information in the TKGs.

**Temporal Knowledge Graph Completion (TKGC)**. It aims at inferencing new facts in the TKGs. Existing TKGC methods could be categorized to (1) tensor decomposition [14; 15; 16], (2) timestamp-based transformation [17; 18; 19; 20; 21], (3) dynamic embedding [22; 23; 24; 25], (4) Markov process models [26; 27], (5) autoregressive models [28; 29; 30], (6) others [31; 32; 33] and so on. Among these works, most of them only confined to the one-hop link prediction task, also known as one-hop reasoning. Some works [28; 29; 30; 25; 32] can perform multi-hop reasoning via a path consisting of connected quartets. But none of them could answer logical queries that involve multiple logical operations (conjunction, negation and disjunction). In this paper, we focus on the temporal complex query answering task, which is more challenging than TKGC task.

## 3 Definitions

**Temporal Knowledge Graph (TKG)**\(G=\{\mathcal{V},\mathcal{R},\mathcal{T},\mathcal{F}\}\) consists of entity set \(\mathcal{V}\), relation set \(\mathcal{R}\), timestamp set \(\mathcal{T}\) and fact set \(\mathcal{F}=\{(s,r,o,t)\}\subseteq\mathcal{V}\times\mathcal{R}\times\mathcal{ V}\times\mathcal{T}\) containing subject-predicate-object-timestamp \((s,r,o,t)\) quartets. Without loss of generality, \(G\) is a first-order logic knowledge base, where each quartet \((s,r,o,t)\) denotes an atomic formula \(r(s,o,t)\), with \(r\) a predicate and \(s,o,t\) its arguments.

**Multi-hop Logical Reasoning over TKG** is the task to answer Temporal Complex Query \(q\) when given a TKG \(G\). We focus on Existential Positive First-Order (EPFO) query [34] over TKG, namely **Temporal Complex Query**\(q\), which is categorized into entity query and timestamp query. Formally, the query \(q\) consists of a target variable \(A\), a non-variable anchor entity set \(V_{a}\subseteq\mathcal{V}\), a non-variable anchor timestamp set \(T_{a}\subseteq\mathcal{T}\), bound variables \(V_{1},\cdots,V_{k}\) and \(T_{1},\cdots,T_{l}\), logical operations (existential quantification \(\exists\), conjunction \(\wedge\), disjunction \(\vee\), identity \(1\), negation \(\neg\)), and extra temporal operations (**After**, **Before**). \(\textbf{After}(t_{1},t_{2})\) means \(t_{2}\) is after \(t_{1}\), while \(\textbf{Before}(t_{1},t_{2})\) means \(t_{2}\) is before \(t_{1}\). Inspired by [2; 3], the disjunctive normal form (DNF) of temporal query \(q\) is defined as:

\[q[A]=A :\exists V_{1},\cdots,V_{k},T_{1},\cdots,T_{l}:(e_{1}^{1}\wedge \cdots\wedge e_{n_{1}}^{1})\vee\cdots\vee(e_{1}^{m}\wedge\cdots\wedge e_{n_{m} }^{m})\] \[\text{where}\;\;e=f\circ r(V_{s},V_{o}\text{ or }A,T)\text{ or }f \circ r(V_{s}\text{ or }A,V_{o},T)\text{ or }g(T_{i},T_{j})\;\text{ if }q\text{ is entity query,}\] \[e=f\circ r(V_{s},V_{o},T\text{ or }A)\text{ or }g(T_{i},T_{j}) \text{ or }g(T,A)\text{ or }g(A,T)\text{ if }q\text{ is timestamp query}\] \[\text{with}\;\;V_{s},V_{o}\in V_{a}\cup\{V_{1},\cdots,V_{k}\}, \quad T,T_{i},T_{j}\in T_{a}\cup\{T_{1},\cdots,T_{l}\},\] \[r\in\mathcal{R},f\in\{1,\neg\},g\in\{\textbf{After},\textbf{ Before}\}\]

In the equation, the DNF is a disjunction of \(m\) conjunctions, where \(e_{1}^{j}\wedge\cdots\wedge e_{n_{j}}^{j}\) denotes a conjunction between \(n_{j}\) logical atoms, and each \(e_{i}^{j}\) denotes a logical atom. We ignore indices in the definition of \(e_{i}^{j}\) to keep the formula clean. The goal of answering the query \(q\) is to find the set of entities (or timestamps) \(\llbracket q\rrbracket\) that satisfy the query, such that \(A\in\llbracket q\rrbracket\) iff \(q[A]\) holds true, where \(\llbracket q\rrbracket\) is the answer set of the query \(q\).

Following existing static query embedding works, we introduce **Computation Graph**, which is a directed acyclic graph (DAG) representing the structure of temporal complex query. Its nodes represent entity/timestamp sets \(S\subseteq V_{a}\cup V\cup T_{a}\cup T\), while directed edges represent logical or relational operations acting on these sets. A computation graph specifies how the reasoning of the query has proceeded on the TKG. Starting from anchor sets, we obtain the answer set after applying operations iteratively on non-answer sets according to the directed edges in the computation graph. The edge types on the computation graph are defined as follows:

1. Relational Projection \(\mathcal{P}\). Given an entity set \(S_{1}\subseteq\mathcal{V}\), a timestamp set \(S_{2}\subseteq\mathcal{T}\)(or an entity set \(S_{2}\subseteq\mathcal{V}\) for entity projection) and a relation \(r\in\mathcal{R}\), projection operation maps \(S_{1}\) and \(S_{2}\) to another set: \(S^{\prime}=\begin{cases}\cup_{(v\in S_{1},t\in S_{2})}\{v^{\prime}|(v,r,v^{ \prime},t)\in\mathcal{F}\},&\mathcal{P}\text{ is entity projection}\\ \cup_{(v\in S_{1},v^{\prime}\in S_{2})}\{t|(v,r,v^{\prime},t)\in\mathcal{F}\},&\mathcal{P}\text{ is timestamp projection}\end{cases}\)
2. Intersection \(\mathcal{I}\) (Union \(\mathcal{U}\), etc.). Given entity sets or timestamp sets \(\{S_{1},\cdots,S_{n}\}\), the intersection (union, etc.) operation computes logical intersection (union, etc.) of these sets \(\cap_{i=1}^{n}S_{i}\) (\(\cup_{i=1}^{n}S_{i}\), etc.).
3. Complement/Negation \(\mathcal{C}\). The complement set of a given set \(S\) is \(\bar{S}=\begin{cases}\mathcal{V}-S,&S\subseteq\mathcal{V}\\ \mathcal{T}-S,&S\subseteq\mathcal{T}\end{cases}\)
4. Extended temporal operators \(f\). Given a timestamp set \(S\), extended operators compute a certain set of timestamps \(S^{\prime}\): \(S^{\prime}=\begin{cases}\{t^{\prime}|\text{for some }t^{\prime}\in\mathcal{T},t^{ \prime}>\max(S)\},&f\text{ is After}\\ \{t^{\prime}|\text{for some }t^{\prime}\in\mathcal{T},t^{\prime}<\min(S)\},&f \text{ is Before}\end{cases}\)

In order to efficiently compute the answer set of a temporal complex query, we consider embedding the query set into a low-dimensional vector space, where the answer set is also represented by a continuous embedding vector. Formally, the **Temporal Query Embedding**\(\mathbf{V}_{q}\) of a query \(q\) is a continuous embedding vector, generated by executing operations according to the computation graph, starting from the temporal embeddings of anchor entity or timestamp sets. The **Temporal Query Answer** to the query \(q\) is the entity \(v\) (or timestamp \(t\)) whose embedding \(\mathbf{v}\) (or \(\mathbf{t}\)) has the smallest distance \(dist(\mathbf{v},\mathbf{V}_{q})\) (or \(dist(\mathbf{t},\mathbf{V}_{q})\)) to the embedding of query \(q\).

## 4 Method

In this section, we replace the variables in the query formulation with temporal feature-logic embeddings, and perform logical operations via neural networks. We first introduce the temporal feature-logic embedding for entities, timestamps, and queries in Section 4.1. Afterwards, we introduce logical operators in Section 4.2 and how to train the model in Section 4.3.

### Temporal Feature-Logic Embeddings for Queries and Entities

In this section, we design temporal embeddings for queries, entities and timestamps. In general, the answers to queries may be entities or timestamps. Therefore, we consider a part of the embedding as an entity part to answer entities, while the other is the timestamp part to answer timestamps. Formally, the embedding of query \(\llbracket q\rrbracket\) is \(\mathbf{V}_{q}=(\bm{q}_{f}^{e},\bm{q}_{i}^{e},\bm{q}_{f}^{t},\bm{q}_{l}^{t})\) where \(\bm{q}_{f}^{e}\in\mathbb{R}^{d}\) is entity feature, \(\bm{q}_{i}^{e}\in[0,1]^{d}\) is entity logic, \(\bm{q}_{f}^{t}\in\mathbb{R}^{d}\) is time feature, \(\bm{q}_{l}^{t}\in[0,1]^{d}\) is time logic respectively, \(d\) is the embedding dimension. The parameter \(\bm{q}_{l}\) is the uncertainty \(\bm{q}_{l}\vec{s}+(1-\bm{q}_{l})\vec{n}\) of the feature, according to fuzzy logic. An entity \(v\in\mathcal{V}\) is a special query without uncertainty. We propose to represent an entity as the query with logic part \(\mathbf{0}\), which indicates that the entity's uncertainty is \(0\). Formally, the embedding of entity \(v\) is \(\mathbf{v}=(\bm{v}_{f}^{e},\mathbf{0},\mathbf{0},\mathbf{0})\), where \(\bm{v}_{f}^{e}\in\mathbb{R}^{d}\) is the entity feature part and \(\mathbf{0}\) is a \(d\)-dimensional vector with all elements being \(0\). Similarly, the embedding of timestamp \(t\) is \(\mathbf{t}=(\mathbf{0},\mathbf{0},\bm{t}_{f}^{t},\mathbf{0})\) with entity part and time logic being \(\mathbf{0}\).

Attention that we introduce vector logic, which is a type of fuzzy logic over vector space, to cope with logical transformation in the vector space. Fuzzy logic is a generalization of Boolean logic, such that the truth value of a logical atom is a real number in \([0,1]\). In comparison, as a generalization of a real number, the truth value in vector logic is a vector \([0,1]^{d}\) in the semantic space. We denote the logical operations in vector logic as \(\textbf{AND}(\wedge)\), \(\textbf{OR}(\vee)\), \(\textbf{NOT}(\neg)\), and so on, which receive one or multiple vectors and output one vector as answer. For more details about fuzzy logic, please refer to Appendix A.1.

### Logical Operators for Temporal Feature-Logic Embeddings

In this section, we introduce the designed neural logical operators, including projection, intersection, complement, and all other dyadic operators.

**Projection Operator \(\mathcal{P}_{e}\) and \(\mathcal{P}_{t}\)**. The goal of operator \(\mathcal{P}_{e}\) is to map an entity set to another entity set under a given relation and a given timestamp, while operator \(\mathcal{P}_{t}\) outputting timestamp set given relation and two entity queries. We define a function \(\mathcal{P}_{e}:\mathbf{V}_{q},\mathbf{r},\mathbf{V}_{t}\mapsto\mathbf{V}_{q}^ {\prime}\) in the embedding space to represent \(\mathcal{P}_{e}\), and \(\mathcal{P}_{t}:\mathbf{V}_{q_{1}},\mathbf{r},\mathbf{V}_{q_{2}}\mapsto \mathbf{V}_{q}^{\prime}\) for \(\mathcal{P}_{t}\) respectively. To implement \(P_{e}\) and \(P_{t}\), we first represent relations as translations on query embeddings and assign each relation with relational embedding \(\mathbf{r}=(\boldsymbol{r}_{f}^{e},\boldsymbol{r}_{i}^{e},\boldsymbol{r}_{f}^ {t},\boldsymbol{r}_{i}^{t})\). We follow the assumption of translation-based methods: \(q_{o}\approx q_{s}+r+t\). As a comparison, static KGE TransE [35] has \(o\approx s+r\), and temporal KGE TTransE [36] has \(o_{t}\approx s_{t}+r\). The addition represents a semantic translation starting from the source entity set, following the relation and timestamp conditioning, ending at the target entity set. Therefore, we define \(\mathcal{P}_{e}\) and \(\mathcal{P}_{t}\) as:

\[\mathcal{P}_{e}(\mathbf{V}_{q},\mathbf{r},\mathbf{V}_{t}) =g(\textbf{MLP}_{0}^{e}(\mathbf{V}_{q}+\mathbf{r}+\mathbf{V}_{t}))\] (1) \[\mathcal{P}_{t}(\mathbf{V}_{q_{1}},\mathbf{r},\mathbf{V}_{q_{2}}) =g(\textbf{MLP}_{0}^{t}(\mathbf{V}_{q_{1}}+\mathbf{r}+\mathbf{V}_ {q_{2}}))\]

where \(\textbf{MLP}:\mathbb{R}^{4d}\rightarrow\mathbb{R}^{4d}\) is a multi-layer perception network (MLP), \(+\) is element-wise addition and \(g\) is an activate function to generate \(\boldsymbol{q}_{i}^{e}\in[0,1]^{d}\), \(\boldsymbol{q}_{i}^{t}\in[0,1]^{d}\). We use MLP and activation function \(g(.)\) to make projection operator output a valid query embedding, which shows the closure property of the operator. \(\mathcal{P}_{e}\) and \(\mathcal{P}_{t}\) do not share parameters so the MLPs are different. We define \(g\) as:

\[g(\mathbf{x})=[\mathbf{x}[0:d];\sigma(\mathbf{x}[d:2d]);\mathbf{x}[2d:3d]; \sigma(\mathbf{x}[3d:4d])]\] (2)

where \(\mathbf{x}[0:d]\) is the slice containing element \(x_{i}\) of vector \(\mathbf{x}\) with index \(0\leq i<d\), \(\sigma(\cdot)\) is Sigmoid function and \([\cdot;\cdot]\) is the concatenation operator.

**Dyadic Operators**. There are two types of dyadic operators for our framework. One for entity set and the other for timestamp set. Each type includes intersection (AND), union (OR), the symmetric difference (XOR), etc. With the help of fuzzy logic, our framework can model all dyadic operators directly. Below we take a unified way to build these operators.

We start from intersection operators \(\mathcal{I}_{e}\) (on entity set) and \(\mathcal{I}_{t}\) (on timestamp set). The goal of intersection operator \(\mathcal{I}_{e}\) (\(\mathcal{I}_{t}\)) is to represent \([\![q]\!]=\cap_{i=1}^{n}[\![q_{i}]\!]\) based on their entity parts (times-tamp parts). Suppose that \(\mathbf{V}_{q_{i}}=(\boldsymbol{q}_{i,f}^{e},\boldsymbol{q}_{i,l}^{e}, \boldsymbol{q}_{i,f}^{t},\boldsymbol{q}_{i,l}^{t})\) is temporal feature-logic embedding for \([\![q_{i}]\!]\). We notice that there exists **Alignment Rule** in the process of reasoning. When performing entity set intersection \(\mathcal{I}_{e}\), we should also perform intersection on timestamp parts in order to align the entities into the same time set. The same also holds for timestamp set intersection \(\mathcal{I}_{t}\) and all other dyadic operators. Therefore, we firstly define the intersection operators as follows:

\[\mathcal{I}_{e}(\mathbf{V}_{q_{1}},\cdots,\mathbf{V}_{q_{n}}) =(\sum_{i=1}^{n}\boldsymbol{\alpha}_{i}^{e}\boldsymbol{q}_{i,f}^ {e},\underbrace{\textbf{AND}^{n}_{i}\{\boldsymbol{q}_{i,l}^{e}\}},\sum_{i=1}^ {n}\boldsymbol{\beta}_{i}^{e}\boldsymbol{q}_{i,f}^{t},\ \ \mathbf{\stackrel{{ n}}{{ \textbf{AND}}}}\{\boldsymbol{q}_{i,l}^{t}\}\ )\] \[\mathcal{I}_{t}(\mathbf{V}_{q_{1}},\cdots,\mathbf{V}_{q_{n}}) =(\sum_{i=1}^{n}\boldsymbol{\alpha}_{i}^{t}\boldsymbol{q}_{i,f}^ {e},\ \mathbf{\stackrel{{ n}}{{ \textbf{AND}}}}\{\boldsymbol{q}_{i,l}^{e}\},\ \mathbf{\stackrel{{ n}}{{ \textbf{AND}}}}\{\boldsymbol{q}_{i,l}^{e}\},\ \mathbf{\stackrel{{ n}}{{ \textbf{AND}}}}\{\boldsymbol{q}_{i,l}^{t}\},\ \mathbf{\stackrel{{ n}}{{ \textbf{AND}}}}\{\boldsymbol{q}_{i,l}^{t}\}\ )\] \[\mathcal{I}_{t}(\mathbf{V}_{q_{1}},\cdots,\mathbf{V}_{q_{n}}) =(\sum_{i=1}^{n}\boldsymbol{\alpha}_{i}^{t}\boldsymbol{q}_{i,f}^ {e},\ \mathbf{\stackrel{{ n}}{{\textbf{AND}}}}\{\boldsymbol{q}_{i,l}^{e}\}, \ \mathbf{\stackrel{{ n}}{{\textbf{AND}}}}\{\boldsymbol{q}_{i,l}^{e}\}, \mathbf{\stackrel{{ n}}{{\textbf{AND}}}}\{\boldsymbol{q}_{i,l}^{t}\}, \ \mathbf{\stackrel{{ n}}{{\textbf{AND}}}}\{\boldsymbol{q}_{i,l}^{t}\})\]

where **AND** is the conjunction in fuzzy logic, \(\boldsymbol{\alpha}_{i}\) and \(\boldsymbol{\beta}_{i}\) are attention weights. To notice the changes of logic, we compute \(\boldsymbol{\alpha}_{i}^{e,t}\) and \(\boldsymbol{\beta}_{i}^{e,t}\) via the following attention mechanism:

\[\boldsymbol{\alpha}_{i}^{e,t}=\frac{\exp(\textbf{MLP}_{1}^{e,t}([\boldsymbol{q}_{ i,f}^{t};\boldsymbol{q}_{i,l}^{e}]))}{\sum_{j=1}^{n}\exp(\textbf{MLP}_{1}^{e,t}([ \boldsymbol{q}_{j,f}^{t};\boldsymbol{q}_{j,l}^{t}]))},\qquad\boldsymbol{\beta}_ {i}^{e,t}=\frac{\exp(\textbf{MLP}_{2}^{e,t}([\boldsymbol{q}_{i,f}^{t}; \boldsymbol{q}_{i,l}^{t}]))}{\sum_{j=1}^{n}\exp(\textbf{MLP}_{2}^{e,t}([ \boldsymbol{q}_{j,f}^{t};\boldsymbol{q}_{j,l}^{t}]))}\] (3)where \(\textbf{MLP}_{1,2}^{e,t}:\mathbb{R}^{2d}\rightarrow\mathbb{R}^{d}\) are MLP networks, \([\cdot;\cdot]\) is concatenation. The first self-attention neural network will learn the hidden information from entity logic and leverage to entity feature, while the second one gathers logical information from time logic to time feature. Note that the computation of entity logic, and time logic obeys the law of fuzzy logic, without any extra learnable parameters. In this way, all dyadic operators can be generated from fuzzy logic in our framework. Due to space limitation, we present the union, exclusive or, implication operators and so on in Appendix A.3.

**Complement Operators:**\(\mathcal{C}_{e}\) and \(\mathcal{C}_{t}\). The aim of \(\mathcal{C}_{e}\) is to identify the complement of query set \(\llbracket q\rrbracket\) such that \(\llbracket-q\rrbracket=\mathcal{V}\backslash\llbracket q\rrbracket\), while \(\mathcal{C}_{t}\) aims to calculate the complement \(\llbracket-q\rrbracket=\mathcal{T}\backslash\llbracket q\rrbracket\) by the time parts. Suppose that \(\mathbf{V}_{q}=(\bm{q}_{f}^{e},\bm{q}_{f}^{e},\bm{q}_{f}^{t},\bm{q}_{f}^{t})\), we define the complement operator \(\mathcal{C}_{e}\) and \(\mathcal{C}_{t}\) as:

\[\mathcal{C}_{e}(\mathbf{V}_{q})=(f_{\text{not}}^{e}(\bm{q}_{f}^{e}),\textbf{ NOT}(\bm{q}_{l}^{e}),\bm{q}_{f}^{t},\bm{q}_{l}^{t}),\qquad\mathcal{C}_{t}( \mathbf{V}_{q})=(\bm{q}_{f}^{e},\bm{q}_{l}^{e},f_{\text{not}}^{t}(\bm{q}_{f}^{ t}),\textbf{NOT}(\bm{q}_{l}^{t}))\] (4)

where \(f_{\text{not}}^{e}(\bm{q}_{f})=\tanh(\textbf{MLP}_{3}([\bm{q}_{f}^{e};\bm{q}_{ f}^{e}])),f_{\text{not}}^{t}(\bm{q}_{f}^{t})=\tanh(\textbf{MLP}_{4}([\bm{q}_{f}^{t};\bm{q}_{l}^{t}]))\) are feature negation functions, two \(\textbf{MLP}_{3,4}:\mathbb{R}^{2d}\rightarrow\mathbb{R}^{d}\) are MLP networks, **NOT** is negation in fuzzy logic.

**Temporal Operators: After \(\mathcal{A}_{t}\), Before \(\mathcal{B}_{t}\) and Between \(\mathcal{D}_{t}\).** The operator After \(\mathcal{A}_{t}:\mathbf{V}_{q}\mapsto\mathbf{V}_{q}^{\prime}\) (Before \(\mathcal{B}_{t}:\mathbf{V}_{q}\mapsto\mathbf{V}_{q}^{\prime}\)) aims to deduce the timestamps after(before) a given fuzzy time set \(\llbracket q\rrbracket\). Let \(\mathbf{V}_{q}=(\bm{q}_{f}^{e},\bm{q}_{l}^{e},\bm{q}_{f}^{t},\bm{q}_{l}^{t})\), we define \(\mathcal{A}_{t}\) and \(\mathcal{B}_{t}\) as:

\[\mathcal{A}_{t}(\mathbf{V}_{q})=(\bm{q}_{f}^{e},\bm{q}_{l}^{e},\bm{q}_{f}^{t}+ \frac{1+\bm{q}_{l}^{t}}{2},\frac{1-\bm{q}_{l}^{t}}{2}),\qquad\mathcal{B}_{t}( \mathbf{V}_{q})=(\bm{q}_{f}^{e},\bm{q}_{l}^{e},\bm{q}_{f}^{t}-\frac{1+\bm{q}_{l }^{t}}{2},\frac{1-\bm{q}_{l}^{t}}{2})\] (5)

The entity part does not change after computation because temporal operator only affects the time part (time feature \(\bm{q}_{f}^{t}\) and time logic \(\bm{q}_{l}^{t}\)). The motivation of computation is illustrated in Figure 2. Since \(\bm{q}_{l}^{t}\) is the uncertainty of time feature \(\bm{q}_{f}^{t}\), the time part can be viewed as an interval \([\bm{q}_{f}^{t}-\bm{q}_{l}^{t},\bm{q}_{f}^{t}+\bm{q}_{l}^{t}]\) whose center is \(\bm{q}_{f}^{t}\) and half-length is \(\bm{q}_{l}^{t}\). The interval is covered by \([\bm{q}_{f}^{t}-1,\bm{q}_{f}^{t}+1]\) because the probability \(\bm{q}_{l}^{t}<1\). Then, after interval \([\bm{q}_{f}^{t}-\bm{q}_{l}^{t},\bm{q}_{f}^{t}+\bm{q}_{l}^{t}]\) is the interval \([\bm{q}_{f}^{t}+\bm{q}_{l}^{t},\bm{q}_{f}^{t}+1]\) whose center is \(\bm{q}_{f}^{t}+\frac{1+\bm{q}_{l}^{t}}{2}\) and half-length is \(\frac{1-\bm{q}_{l}^{t}}{2}\), which gives the time part of embedding \(\mathcal{A}_{t}(\mathbf{V}_{q})\). Similarly, the time part of embedding \(\mathcal{B}_{t}(\mathbf{V}_{q})\) is \(\bm{q}_{f}^{t}-\frac{1+\bm{q}_{l}^{t}}{2}\) (time feature) and \(\frac{1-\bm{q}_{l}^{t}}{2}\) (time logic), which are generated from \([\bm{q}_{f}^{t}-1,\bm{q}_{f}^{t}-\bm{q}_{l}^{t}]\) before \([\bm{q}_{f}^{t}-\bm{q}_{l}^{t},\bm{q}_{f}^{t}+\bm{q}_{l}^{t}]\). The operator Between \(\mathcal{D}_{t}:\mathbf{V}_{q_{1}},\mathbf{V}_{q_{2}}\mapsto\mathbf{V}_{q}^{\prime}\) inferences the time set after \(\llbracket q_{1}\rrbracket\) and before \(\llbracket q_{2}\rrbracket\). Therefore, we define Between \(\mathcal{D}_{t}\) as \(\mathcal{D}_{t}(\mathbf{V}_{q_{1}},\mathbf{V}_{q_{2}})=\mathcal{I}_{t}( \mathcal{A}_{t}(\mathbf{V}_{q_{1}}),\mathcal{B}_{t}(\mathbf{V}_{q_{2}}))\) to output the time between \(\llbracket q_{1}\rrbracket\) and \(\llbracket q_{2}\rrbracket\).

### Learning Temporal Feature-Logic Embeddings

We expect the model to achieve high scores for the answers to the given query \(q\), and low scores for \(v^{\prime}\notin\llbracket q\rrbracket\). Therefore, we firstly define a distance function to measure the distance between a given answer embedding and a query embedding, and then we train the model with negative sampling loss.

**Distance Function** Given an entity embedding \(\mathbf{v}=(\bm{v}_{f}^{e},\bm{0},\bm{0},\bm{0})\), a timestamp embedding \(\mathbf{t}=(\bm{0},\bm{0},\bm{t}_{f}^{t},\bm{0})\) and a query embedding \(\mathbf{V}_{q}=(\bm{q}_{f}^{e},\bm{q}_{f}^{e},\bm{q}_{f}^{t},\bm{q}_{f}^{t},\bm{q }_{l}^{t})\), we define the distance \(d\) between the answer and the query \(q\) as the sum of the feature distance (between the feature parts) and the logic part (to expect uncertainty to be \(0\)). If the query answers entities, the distance is \(d^{e}(\mathbf{v};\mathbf{V}_{q})=\|\bm{v}_{f}^{e}-\bm{q}_{f}^{e}\|_{1}+\bm{q}_{l}^{e}\). Otherwise, the distance is \(d^{t}(\mathbf{t};\mathbf{V}_{q})=\|\bm{t}_{f}^{t}-\bm{q}_{f}^{t}\|_{1}+\bm{q}_{l} ^{t}\) for queries answering timestamp set, where \(\|\cdot\|_{1}\) is the \(L_{1}\) norm and \(+\) is element-wise addition. The distance function aims to optimize two losses. One is to push the answers to the neighbor of query in the embedding

Figure 2: The computation of time part in temporal operators Before and After.

space. It corresponds to the term L1 distance between answer and query. The other is to reduce the uncertainty of the query (the probability interpretation of the logic part), to make the answers more accurate.

**Loss Function** Given a training set of queries, we optimize a negative sampling loss

\[L=-\log\sigma(\gamma-d(\mathbf{v};\mathbf{V}_{q}))-\frac{1}{k}\sum_{i=1}^{k} \log\sigma(d(\mathbf{v}_{i}^{\prime};\mathbf{V}_{q})-\gamma)\] (6)

where \(\gamma>0\) is a fixed margin, \(k\) is the number of negative entities, and \(\sigma(\cdot)\) is the sigmoid function. When query \(q\) is answering entities (timestamps), \(v\in\llbracket q\rrbracket\) is a positive entity (timestamp), \(v_{i}^{\prime}\notin\llbracket q\rrbracket\) is the \(i\)-th negative entity (timestamp).

## 5 Experiments

In this section, we evaluate the ability of TFLEX to reason over TKGs. We first introduce experimental settings in Section 5.1, and then present the experimental results in Section 5.2.

### Experimental Settings

Datasets and Query GenerationExperiments are performed on three new datasets generated from standard benchmarks for TKGC: ICEWS14 [37], ICEWS05-15 [37], and GDELT-500 [38] (with statistics in Appendix B.1). We predefined 40 kinds of complex queries for each dataset. The definition of the 40 kinds of complex queries and the query generation process details are described in Appendix B.2. We consider 27 kinds of queries for training and all 40 kinds for evaluation and testing. Please refer to Appendix B.3 for summaries of the final datasets.

To briefly summarize the results, we aggregate groups of queries that can be answered: entities (\(\text{avg}_{e}\)), timestamps (\(\text{avg}_{t}\)), entities with negation (\(\text{avg}_{e,\mathcal{C}_{e}}\)), timestamps with negation (\(\text{avg}_{t,\mathcal{C}_{t}}\)), entities with unseen union (\(\text{avg}_{\{\mathcal{U}_{e}\}}\)), timestamps with unseen union (\(\text{avg}_{\{\mathcal{U}_{t}\}}\)), and other hybrid unseen structures (\(\text{avg}_{x}\)). These groups are inspired by the experiment settings of existing static QEs [1, 2, 3, 4]. The detail that which query belongs to which group will be shown in Appendix B.7. Note that the training set only involves 4 groups of queries: \(\text{avg}_{e}\), \(\text{avg}_{t}\), \(\text{avg}_{e,\mathcal{C}_{e}}\), and \(\text{avg}_{t,\mathcal{C}_{t}}\).

EvaluationGiven a test query \(q\), for each non-trivial answer \(v\in\llbracket q\rrbracket_{\text{test}}-\llbracket q\rrbracket_{\text{ valid}}\) of the query \(q\), we rank it against non-answer entities \(\mathcal{V}-\llbracket q\rrbracket_{\text{test}}\) (or non-answer timestamps \(\mathcal{T}-\llbracket q\rrbracket_{\text{test}}\) if the query is answering timestamps). Then we calculate Mean Reciprocal Rank (MRR) based on the rank. The higher, the better. Please refer to Appendix B.5 for the definition of MRR.

### Main Results

For each group, we report the average MRR in Table 1. The raw MRR results on all query structures for each dataset in detail are presented in Appendix B.7.

**How well can TFLEX answer temporal complex queries?** We compare TFLEX with state-of-the-art query embeddings Query2box [2], BetaE [3] and ConE [4] on answering entities. Existing query embeddings only handle FOL on entity set, but unable to cope with temporal logic over timestamp set. Therefore, the results of these three methods have to be obtained by ignoring the timestamps, so that the \(\text{avg}_{t}\), \(\text{avg}_{t,\mathcal{C}_{t}}\), \(\text{avg}_{\{\mathcal{U}_{t}\}}\) and \(\text{avg}_{x}\) of three methods are zeros. Comparing the results of these methods in Table 1, we can see that TFLEX outperforms all the baselines on all the metrics. These results demonstrate that TFLEX can perform reasoning over TKGs well, at least better than the existing query embeddings.

**Ablation on entity part.** The variant **X(ConE)** replaces the entity part of TFLEX with ConE [4] to handle the logic over entity sets. In the entity part, ConE is geometric while TFLEX is fuzzy. The variant performs even worse than TFLEX and ConE. The dropping MRR indicates that the entity part plays an important role in the framework. Considering the performance of ConE, we think there is semantic conflict between the time part of TFLEX and the entity part of ConE. Simply combining static QEs with dynamic QEs is not a clever way to achieve the best performance.

**Ablation on time part**. The variant **FLEX** removes the time part of the temporal feature-logic embedding. Then, **FLEX** can only answer entities. The results show that **FLEX** slightly outperforms ConE. However, the performance of **FLEX** is worse than TFLEX with a large margin on all the datasets. Therefore, we conclude that the time part also plays an important role in the framework.

**Ablation on feature part**. If we remove the entity and timestamp feature, the embeddings of entities and timestamps will crash to zeros. Instead, we consider another way to explore the impact of the feature part. Noticing that some TKGC approaches [36, 39] embed entities and timestamps into the same semantic space, we propose **X-IF** to merge the entity and timestamp features into one feature. Compared with TFLEX, **X-IF** achieves higher scores on ICEWS14 and ICEWS05-15, but lower on GDELT. The results imply that unifying the feature of entity and timestamp is potentially beneficial in some datasets.

**Ablation on logic part**. The variant **X-logic** removes both entity logic and time logic. It achieves lower scores than TFLEX on all the datasets. This is because the logic part is responsible for reasoning over TKGs. Removing the logic part results in that neural logical operators completely rely on neural network to learn the logic, which is not enough to handle various temporal complex queries.

**Out-of-data reasoning**. The results on \(\operatorname{avg}_{\{U_{e}\}},\operatorname{avg}_{\{U_{t}\}},\operatorname{ avg}_{x}\) support that the framework can reason over unseen entity logic, unseen time logic as well as their hybrid. The entity union and time union operators are not included in the training set, but the framework can still handle them well.

**Sensitive analysis**. (1) The selection of hyperparameters (embedding dimension \(d\), the margin \(\gamma\)) has a substantial influence on the effectiveness of TFLEX. We train the model with embedding dimension \(d\in\{300,400,500,600,700,800,900,1000\}\), the margin \(\gamma\in\{5,10,15,20,25,30,35,40\}\). The best performance is achieved when \(d=800\) and \(\gamma=15\). Too small and too large \(d,\gamma\) both lead to worse results, reported in Appendix B.6. (2) Besides, we also investigate the stability of TFLEX. We train and test for five times with different random seeds and report the error bars in Appendix B.6. The small standard variances demonstrate that the performance of TFLEX is stable.

**Comparison between TFLEX and TKGC methods**. It's natural to compare TFLEX with SOTA TKGC methods, since all of them can answer one-hop temporal queries. We present the comparison results in Table 2. We can see that TFLEX is competitive with translation-based methods

\begin{table}
\begin{tabular}{l l r r r r r r r r} \hline \hline
**Dataset** & **Metrics** & **Query2box** & **BetaE** & **ConE** & **TFLEX** & **X(ConE)** & **FLEX** & **X-IF** & **X-logic** \\ \hline \multirow{6}{*}{ICEWS14} & avg\({}_{c}\) & 25.06 & 37.19 & 41.94 & 56.79 & 40.93 & 43.67 & 56.89 & 56.64 \\  & avg\({}_{c,c_{s}}\) & & 36.69 & 44.88 & 50.82 & 42.15 & 44.41 & 49.78 & 51.17 \\  & avg\({}_{t}\) & & & & 17.56 & 16.41 & & 18.77 & 18.03 \\  & avg\({}_{t,c_{t}}\) & & & & 36.37 & 35.24 & & 37.73 & 36.39 \\  & avg\({}_{\{U_{e}\}}\) & & & & 26.47 & 35.74 & 25.46 & 29.25 & 34.48 & 34.68 \\  & avg\({}_{\{U_{t}\}}\) & & & & 26.24 & 24.07 & & 28.04 & 26.36 \\  & avg\({}_{\{U_{t}\}}\) & & & & 28.03 & 26.65 & & 29.31 & 28.61 \\  & **AVG** & & & & 35.93 & 30.13 & & 36.43 & 35.98 \\ \hline \multirow{6}{*}{ICEWS05-15} & avg\({}_{c}\) & 24.00 & 31.33 & 40.93 & 48.99 & 36.29 & 38.96 & 49.90 & 44.80 \\  & avg\({}_{c,c_{s}}\) & & & 29.70 & 43.52 & 46.17 & 38.12 & 42.10 & 46.11 & 41.92 \\  & avg\({}_{t}\) & & & & 4.39 & 4.41 & & 4.43 & 3.29 \\  & avg\({}_{t,c_{t}}\) & & & & 30.16 & 29.49 & & 30.26 & 28.34 \\  & avg\({}_{\{U_{t}\}}\) & & & & 28.69 & 26.40 & & 27.70 & 23.39 \\  & avg\({}_{x}\) & & & & 24.26 & 21.69 & & 24.41 & 21.95 \\  & **AVG** & & & & 33.72 & 27.54 & & 33.98 & 29.86 \\ \hline \multirow{6}{*}{GDELT-500} & avg\({}_{c}\) & 9.67 & 14.75 & 18.44 & 19.60 & 17.83 & 19.07 & 17.92 & 17.36 \\  & avg\({}_{c,c_{s}}\) & & & & 11.15 & 12.67 & 13.52 & 12.34 & 13.35 & 12.13 & 12.11 \\  & avg\({}_{t}\) & & & & 5.38 & 3.16 & & 5.49 & 5.75 \\  & avg\({}_{\{U_{e}\}}\) & & & & 6.31 & 3.93 & & 6.50 & 6.86 \\  & avg\({}_{\{U_{e}\}}\) & & & & & 6.17 & 6.35 & & 6.59 & 6.80 \\  & avg\({}_{x}\) & & & & 6.17 & 6.17 & & 6.47 & 6.64 \\  & avg\({}_{\{U_{e}\}}\) & & & & 9.32 & 8.17 & & 8.86 & 8.92 \\ \hline \hline \end{tabular}
\end{table}
Table 1: Average MRR results for different groups of temporal complex queries. **X** denotes the variant of TFLEX. **X(ConE)** replaces the entity part with ConE [4]. **FLEX** ablates the time part. **X-1F** merges entity feature and timestamp feature into one feature. **X-logic** removes the logic part.

(ConT [43], TTransE [36], HyTE [44], etc.), but it doesn't outperform the SOTA TKGC methods like ChronoR [17] and TuckERT [39]. However, the result doesn't affect the novelty and contribution of this paper. Please note that the projection operator of TFLEX is as simple as TTransE, not further optimized for TKGC tasks only. Upgrading the projection operator to outperform SOTA TKGC methods remains a future work.

**Necessity of training on temporal complex queries**. Our experiments demonstrate that training on complex queries is necessary to achieve the best performance. We compare with translation-based \(\mathcal{P}_{e}\) operators (TTransE [36], HyTE [44] and TFLEX's variant **TFLEX-1p**) using only one-hop **Pe** queries for training. We choose TTransE and HyTE because our projection operator is also translation-based (\(\mathcal{P}_{e}(\mathbf{V}_{q},\mathbf{r},\mathbf{V}_{t})\propto\mathbf{V}_{q }+\mathbf{r}+\mathbf{V}_{t}\)). From the result table 3, we observe that TFLEX achieves the best performance when comparing with these translation-based baselines on all datasets. Besides, compared with **TFLEX-1p**, TFLEX achieves 7.9% relative improvement on average on MRR, which demonstrates that training on complex queries could improve the one-hop query-answering ability.

**Effectiveness of neural temporal operators**. We found that the temporal operators \(\mathcal{A}_{t}\) and \(\mathcal{B}_{t}\) change the semantic of predicted timestamp embedding logically. We randomly select an event \((s,r,o)\) from ICEWS14 and consider three temporal queries **Pt**, **bPt** and **aPt**. Then, **Pt**(\(=\mathcal{P}_{t}(s,r,o)\)) predicts the date \(t\) when this event happened. And **bPt**(\(=\mathcal{B}_{t}(\mathcal{P}_{t}(s,r,o))\)) should predict the date before \(t\), while **aPt**(\(=\mathcal{A}_{t}(\mathcal{P}_{t}(s,r,o))\)) is supposed to predict the time after \(t\). The output of three queries are time embeddings. Because the time embedding is fuzzy, we score it to all possible Timestamps, and visualize the normalized similarity score distribution over all days in a year, from 0 to 365 in ICEWS14. The higher the score, the more possible the predicted date is the day. We plot the three score distributions in Figure 3. For each distribution, we highlight the periods of the highest scores

\begin{table}
\begin{tabular}{l c c c c c c c c c c c c} \hline \hline \multirow{2}{*}{Model} & \multicolumn{4}{c}{ICEWS14} & \multicolumn{4}{c}{ICEWS05-15} & \multicolumn{4}{c}{GDELT} \\ \cline{2-13}  & MRR & Hit@1 & Hit@3 & Hit@10 & MRR & Hit@1 & Hit@3 & Hit@10 & MRR & Hit@1 & Hit@3 & Hit@10 \\ \hline TransE\({}^{*}\)[35] & 28.0 & 9.4 & - & 63.7 & 29.4 & 9.0 & - & 66.3 & 11.3 & 0.0 & 15.8 & 31.2 \\ DistMat\({}^{\text{\textdagger}}\)[41] & 43.9 & 32.3 & - & 67.2 & 45.6 & 33.7 & - & 69.1 & 19.6 & 11.7 & 20.8 & 34.8 \\ SimpleE\({}^{*}\)[42] & 45.8 & 34.1 & 51.6 & 68.7 & 47.8 & 35.9 & 53.9 & 70.8 & 20.6 & 12.4 & 22.0 & 36.6 \\ \hline ConT [43] & 18.5 & 11.7 & 20.5 & 31.5 & 16.3 & 10.5 & 18.9 & 27.2 & 14.4 & 8.0 & 15.6 & 26.5 \\ TTransE [36] & 25.5 & 7.4 & - & 60.1 & 27.1 & 8.4 & - & 61.6 & 11.5 & 0.0 & 16.0 & 31.8 \\ HyTE [44] & 29.7 & 10.8 & 41.6 & 65.5 & 31.6 & 11.6 & 44.5 & 68.1 & 11.8 & 0.0 & 16.5 & 32.6 \\ TA-DistMat [45] & 47.7 & 36.3 & - & 68.6 & 47.4 & 34.6 & - & 72.8 & 20.6 & 12.4 & 21.9 & 36.5 \\ DE-Transfer [46] & 32.6 & 12.4 & 46.7 & 68.6 & 31.4 & 10.8 & 45.3 & 68.5 & 12.6 & 0.0 & 18.1 & 35.0 \\ DE-DistMat [46] & 50.1 & 39.2 & 56.9 & 70.8 & 48.4 & 36.6 & 54.6 & 71.8 & 21.3 & 13.0 & 22.8 & 37.6 \\ DE-SimpleE [46] & 52.6 & 41.8 & 59.2 & 72.5 & 51.3 & 39.2 & 57.8 & 74.8 & 23.0 & 14.1 & 24.8 & 40.3 \\ ChronoR [17] & **62.5** & **54.7** & **66.9** & **77.3** & **67.5** & **59.6** & **72.3** & **82.0** & - & - & - & - \\ \hline TuckERT [39] & 59.4 & 51.8 & 64.0 & 73.1 & 62.7 & 55.0 & 67.4 & 76.9 & **41.1** & **31.0** & **45.3** & **61.4** \\ TuckERTN [39] & 60.4 & 52.1 & 65.5 & 75.3 & 63.8 & 55.9 & 68.6 & 78.3 & 38.1 & 28.3 & 41.8 & 57.6 \\ \hline RGCRN\({}^{\dagger}\)[47, 40] & 33.3 & 24.0 & 36.5 & 51.5 & 35.9 & 26.2 & 40.0 & 54.6 & 18.6 & 11.5 & 19.8 & 32.4 \\ CyGNet\({}^{\dagger}\)[48] & 34.6 & 25.3 & 38.8 & 53.1 & 35.4 & 25.4 & 40.2 & 54.4 & 18.0 & 11.1 & 19.1 & 31.5 \\ RE-NET\({}^{\dagger}\)[28] & 35.7 & 25.9 & 40.1 & 54.8 & 36.8 & 26.2 & 41.8 & 57.6 & 19.6 & 12.0 & 20.5 & 33.8 \\ RE-GCN\({}^{\dagger}\)[40] & 37.7 & 27.1 & 42.5 & 58.8 & 38.2 & 27.4 & 43.0 & 59.9 & 19.1 & 11.9 & 20.4 & 33.1 \\ \hline TFLEX-1p & 43.9 & 31.4 & 49.6 & 64.4 & 40.6 & 29.1 & 47.5 & 66.1 & 16.5 & 8.6 & 17.3 & 33.1 \\ TFLEX & 48.2 & 35.7 & 56.5 & 72.3 & 43.0 & 30.0 & 49.8 & 69.5 & 18.5 & 10.1 & 19.6 & 34.9 \\ \hline \hline \end{tabular}
\end{table}
Table 2: TKGC Results (%) on ICEWS14, ICEWS05-15, and GDELT. The results from top to bottom are organized as static KGEs, timestamp-based transformation TKGEs, tensor decomposition, autoregressive models and ours. Best results are in bold. \(\dagger\), \(\star\) indicate the results taken from [40, 17]. Other results are the best numbers reported in their respective paper.

Figure 3: Score distributions of **Pt**, **bPt** and **aPt**.

with a colored background. These colored blocks represent the most likely happening time interval of the event. We observe that the order of colored blocks (corresponding to the predictions of **bPt**, **Pt**, and **aPt**) matches the logical meanings of these operators (Before the event, On the event, After the event). The visualization shows that neural temporal operators perform the time transformation correctly. More examples are attached in Appendix D.

**Explaining answers with temporal feature-logic framework**. We take query **Pe2** for example. Given temporal query **Pe2**: \(q[V_{7}]=V_{7},\exists V_{a},r_{1}(e_{1},V_{a},t_{1})\wedge r_{2}(V_{a},V_{7},t _{2})\), let's try an example which can be written as: On 2014-04-04, who consulted the man who was appealed to or requested by the Head of Government (Latvia) on 2014-08-01? In this example, \(e_{1}\) is "Head of Government (Latvia)", \(r_{1}\) is "Make an appeal or request", \(t_{1}\) is "2014-08-01", \(r_{2}\) is "consult\({}^{-1}\)", and \(t_{2}\) is "2014-04-04". Then we use TFLEX to execute the query and get answers. We classify the answers into easy, hard and wrong ones. The easy answer is the correct answer that appears in the training set, while the hard answer is the correct answer that exists in the testing set instead of training set.

We present five most likely answers for interpretation in Figure 4. From the table we observe that TFLEX ranks easy answers "Francois Hollande", "Taavi Roivas" and hard answer "Andris Berzins" higher than wrong answers "Angela Merkel" and "Head of Government (Latvia)". This shows that TFLEX successfully finds the hard answer by performing complex reasoning, and distinguishes the right answers from the wrong ones.

We provide 36 examples in Appendix E, including the visualization and intermediate explanation of answers for each query structure.

## 6 Conclusion

In this paper, we firstly define a temporal multi-hop logical reasoning task on temporal knowledge graphs. Then we generate three new TKG datasets and propose the Temporal Feature-Logic embedding framework, TFLEX, to handle temporal complex queries in datasets. Fuzzy logic is used to guide all FOL transformations on the logic part of embeddings. We also further extended fuzzy logic to implement extra temporal operators (**Before**, **After** and **Between**). To the best of our knowledge, TFLEX is the first framework to support multi-hop complex reasoning on temporal knowledge graphs. Experiments on benchmark datasets demonstrate the efficacy of the proposed framework in handling different operations in complex queries.

## Acknowledgments and Disclosure of Funding

This work is supported by the National Science Foundation of China (Grant No. 62176026) and Beijing Natural Science Foundation (M22009); Engineering Research Center of Information Networks, Ministry of Education. We would like to express our sincere gratitude to our corresponding authors, Prof. Haihong E and Dr. Chengjin Xu, for their guidance, expertise, and unwavering support throughout the project. Furthermore, we would like to thank Fenglong Su, Gengxian Zhou, Tianyi Hu, Ningyuan Li, Mingzhi Sun, and Haoran Luo for their individual contributions and collaboration in various aspects of this project. Their expertise and dedication have significantly enriched the final outcome. Additionally, we extend our thanks to the anonymous reviewers for their time and efforts in reviewing our work. Their constructive feedback and comments have been instrumental in improving the overall clarity and rigor of this research.

Figure 4: Intermediate variable assignments and ranks for example Pe2 query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

## Broader Impact

Multi-hop reasoning makes the information stored in TKGs more valuable. With the help of multi-hop reasoning, we can digest more hidden and implicit information in TKGs. It will broaden and deepen KG applications in various fields, such as question answering, recommend systems, and information retrieval. It may also bring about risks exposing unexpected personal information on public data.

Finance temporal knowledge graph is a good example to illustrate the broader impact of multi-hop reasoning. In the financial field, the information stored in TKGs is very sensitive. The one-hop reasoning can complete the hidden financial transaction, while the multi-hop reasoning can help to detect the fraud. The After operator could also be used to predict the future financial transaction. People may take the advantages of logical reasoning to digest financial factor to obtain excess returns.

Military temporal knowledge graph is another example. With the help of multi-hop logical reasoning, we may predict the future military strategy of a country. Besides, with the fuzzy completion of the hidden military information, we can also detect the hidden militarily moves, which may save thousands of soldiers' lives.

The last example is social temporal knowledge graph. The behaviors of people are left and stored in TKGs. With the help of logical reasoning, we may predict a short future of a person. For example, the query may answer the evolution of user profiles: how long may a person transfer to another role, from student to worker, becoming a parent, or being a grandparent. Tracking the user's identity change can provide super benefits for merchants' advertising. Detecting the role of a person is also helpful to provide more personalized services.

However, we should agree that the multi-hop reasoning is still at an extremely early stage, though it may bring about risks. Therefore, we should pay more attention to the security of TKGs and the privacy of users at the mean time when we explore the technology of multi-hop reasoning over TKGs.

## Limitation & Future Work

In this section, we list 4 limitations and talk about the possible future work.

**Limitation 1: The temporal operators are not enough.**. We define three extra temporal operators (**Before**, **After** and **Between**) in query generation. However, there exists more temporal operators in the real world. For example, Allen [49] defined 13 types of temporal relations represented by two intervals, including before/after, during/contains, overlaps/overlapped-by, meets/met-by, starts/started-by, finishes/finished-by and equal. In the future we would like to promote these temporal operators to TKGs.

**Limitation 2: The temporal embedding could improve.**. In this paper, the embedding of the timestamp is randomly initialized and finally learned by the model via logical advantages. Such embedding ignores the order of different timestamps. The order property is learned by the After and Before operators, which may be not enough. We recall that in the field of NLP, positional embeddings also have order features, which may be used for the construction of timestamp embeddings.

**Limitation 3: The query generation is time-consuming.**. There are 40 predefined query structures in our query generation module. Each query structure has 10k+ queries for training. With the scale of TKGs increasing, the number of queries will also increase, even 40x faster. Therefore, we need to find a more efficient way to generate queries for large scale TKGs.

**Limitation 4: The MRR and Hits@k are weak.**. The MRR and Hits@k evaluation metric may not inflect the performance of multi-hop reasoning. We observe that some queries have lots of answers. When the number of answers is larger than k, the MRR and Hits@k will be low, even if all answers are correctly ranked at top. Because the right answers that ranked after k are labeled as false. The Hits@k decreases with the increase number of right answers, which is not reasonable. This disadvantage prevents us from comparing the performance across different datasets. In this paper, GDELT is much denser, and the count of right answers is larger than the other two datasets. Therefore, the MRR of GDELT is lower than the other two datasets. It can also be verified that on the average MRR, group avg\({}_{t}\) is lower than group avg\({}_{e}\). The reason is that the number of right answers of group avg\({}_{t}\) is larger than that of group avg\({}_{e}\), which can be seen from the statistic of average answer count of queries in Table 10. In the future, there should be a more reasonable evaluation metric for multi-hop reasoning.

## References

* [1] Will Hamilton, Payal Bajaj, Marinka Zitnik, Dan Jurafsky, and Jure Leskovec. Embedding logical queries on knowledge graphs. _Advances in Neural Information Processing Systems_, 31:2026-2037, 2018.
* [2] H Ren, W Hu, and J Leskovec. Query2box: Reasoning over knowledge graphs in vector space using box embeddings. In _International Conference on Learning Representations (ICLR)_, 2020.
* [3] Hongyu Ren and Jure Leskovec. Beta embeddings for multi-hop logical reasoning in knowledge graphs. _Neural Information Processing Systems (NeurIPS)_, 2020.
* [4] Zhanqiu Zhang, Jie Wang, Jiajun Chen, Shuiwang Ji, and Feng Wu. Cone: Cone embeddings for multi-hop reasoning over knowledge graphs. _Advances in Neural Information Processing Systems_, 34, 2021.
* [5] Nurendra Choudhary, Nikhil Rao, Sumeet Katariya, Karthik Subbian, and Chandan Reddy. Probabilistic entity representation model for reasoning over knowledge graphs. _Advances in Neural Information Processing Systems_, 34, 2021.
* [6] Nurendra Choudhary, Nikhil Rao, Sumeet Katariya, Karthik Subbian, and Chandan K Reddy. Self-supervised hyperboloid representations from logical queries over knowledge graphs. In _Proceedings of the Web Conference 2021_, pages 1373-1384, 2021.
* [7] Lihui Liu, Boxin Du, Heng Ji, ChengXiang Zhai, and Hanghang Tong. Neural-answering logical queries on knowledge graphs. In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_, pages 1087-1097, 2021.
* [8] Xueyuan Lin, Haihong E, Gengxian Zhou, Tianyi Hu, Li Ningyuan, Mingzhi Sun, and Haoran Luo. Flex: Feature-logic embedding framework for complex knowledge graph reasoning. _ArXiv_, abs/2205.11039, 2023. URL https://api.semanticscholar.org/CorpusID:248986747.
* [9] Erik Arakelyan, Daniel Daza, Pasquale Minervini, and Michael Cochez. Complex query answering with neural link predictors. _arXiv preprint arXiv:2011.03459_, 2020.
* [10] Francois P. S. Luus, Prithviraj Sen, Pavan Kapanipathi, Ryan Riegel, Ndivhuwo Makondo, Thabang Lebese, and Alexander G. Gray. Logic embeddings for complex query answering. _ArXiv_, abs/2103.00418, 2021.
* [11] Haitian Sun, Andrew Arnold, Tania Bedrax Weiss, Fernando Pereira, and William W Cohen. Faithful embeddings for knowledge base queries. _Advances in Neural Information Processing Systems_, 33, 2020.
* [12] Dinesh Garg, Shajith Ikbal, Santosh K Srivastava, Harit Vishwakarma, Hima Karanam, and L Venkata Subramaniam. Quantum embedding of knowledge for reasoning. _Advances in Neural Information Processing Systems_, 32:5594-5604, 2019.
* [13] Santosh Kumar Srivastava, Dinesh Khandelwal, Dhiraj Madan, Dinesh Garg, Hima Karanam, and L Venkata Subramaniam. Inductive quantum embedding. _Advances in Neural Information Processing Systems_, 33, 2020.
* [14] Lifan Lin and Kun She. Tensor decomposition-based temporal knowledge graph embedding. _2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)_, pages 969-975, 2020. URL https://api.semanticscholar.org/CorpusID:229701707.
* [15] Timothee Lacroix, Guillaume Obozinski, and Nicolas Usunier. Tensor decompositions for temporal knowledge base completion. _ArXiv_, abs/2004.04926, 2020. URL https://api.semanticscholar.org/CorpusID:214390104.
* [16] Pengpeng Shao, Guohua Yang, Dawei Zhang, Jianhua Tao, Feihu Che, and Tong Liu. Tucker decomposition-based temporal knowledge graph completion. _Knowl. Based Syst._, 238:107841, 2020. URL https://api.semanticscholar.org/CorpusID:226965423.
* [17] Ali Reza Sadeghian, Mohammadreza Armandpour, Anthony Colas, and Daisy Zhe Wang. Chronor: Rotation based temporal knowledge graph embedding. In _AAAI Conference on Artificial Intelligence_, 2021. URL https://api.semanticscholar.org/CorpusID:232269660.
* [18] Julien Leblay and Melisachew Wudage Chekol. Deriving validity time in knowledge graph. _Companion Proceedings of the The Web Conference 2018_, 2018. URL https://api.semanticscholar.org/CorpusID:13846713.

* Radstok and Chekol [2021] Wessel Radstok and Melisachew Wudage Chekol. Leveraging static models for link prediction in temporal knowledge graphs. _2021 IEEE 33rd International Conference on Tools with Artificial Intelligence (ICTAI)_, pages 1034-1041, 2021. URL https://api.semanticscholar.org/CorpusID:235670110.
* Xu et al. [2020] Chengjin Xu, M. Nayyeri, Fouad Alkhoury, Hamed Shariat Yazdi, and Jens Lehmann. Tero: A time-aware knowledge graph embedding via temporal rotation. In _International Conference on Computational Linguistics_, 2020. URL https://api.semanticscholar.org/CorpusID:222124934.
* Dasgupta et al. [2018] Shib Sankar Dasgupta, Swayambhu Nath Ray, and Partha Talukdar. Hyte: Hyperplane-based temporally aware knowledge graph embedding. In _Proceedings of the 2018 conference on empirical methods in natural language processing_, pages 2001-2011, 2018.
* Xu et al. [2019] Chengjin Xu, M. Nayyeri, Fouad Alkhoury, Hamed Shariat Yazdi, and Jens Lehmann. Temporal knowledge graph completion based on time series gaussian embedding. In _International Workshop on the Semantic Web_, 2019. URL https://api.semanticscholar.org/CorpusID:218900866.
* Han et al. [2020] Zhen Han, Peng Chen, Yunpu Ma, and Volker Tresp. Dyernie: Dynamic evolution of riemannian manifold embeddings for temporal knowledge graph completion. _ArXiv_, abs/2011.03984, 2020. URL https://api.semanticscholar.org/CorpusID:226262324.
* Trivedi et al. [2017] Rakshit S. Trivedi, Hanjun Dai, Yichen Wang, and Le Song. Know-evolve: Deep temporal reasoning for dynamic knowledge graphs. In _International Conference on Machine Learning_, 2017. URL https://api.semanticscholar.org/CorpusID:8040343.
* Wu et al. [2020] Jiapeng Wu, Mengyao Cao, Jackie Chi Kit Cheung, and William L. Hamilton. Temp: Temporal message passing for temporal knowledge graph completion. In _Conference on Empirical Methods in Natural Language Processing_, 2020. URL https://api.semanticscholar.org/CorpusID:222177069.
* Xu et al. [2020] Youri Xu, Haihong E, Meina Song, Wenyu Song, Xiaodong Lv, Wang Haotian, and Yang Jinrui. Rtfe: A recursive temporal fact embedding framework for temporal knowledge graph completion. In _North American Chapter of the Association for Computational Linguistics_, 2020. URL https://api.semanticscholar.org/CorpusID:222067007.
* Liao et al. [2021] Siyuan Liao, Shangsong Liang, Zaiqiao Meng, and Qiang Zhang. Learning dynamic embeddings for temporal knowledge graphs. _Proceedings of the 14th ACM International Conference on Web Search and Data Mining_, 2021. URL https://api.semanticscholar.org/CorpusID:232126110.
* Jin et al. [2019] Woojeong Jin, Meng Qu, Xisen Jin, and Xiang Ren. Recurrent event network: Autoregressive structure inference over temporal knowledge graphs. In _Conference on Empirical Methods in Natural Language Processing_, 2019. URL https://api.semanticscholar.org/CorpusID:222205878.
* Li et al. [2021] Zixuan Li, Xiaolong Jin, Wei Li, Saiping Guan, Jiafeng Guo, Huawei Shen, Yuanzhuo Wang, and Xueqi Cheng. Temporal knowledge graph reasoning based on evolutional representation learning. _Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval_, 2021. URL https://api.semanticscholar.org/CorpusID:233324265.
* Han et al. [2021] Zhen Han, Zifeng Ding, Yunpu Ma, Yujia Gu, and Volker Tresp. Learning neural ordinary equations for forecasting future links on temporal knowledge graphs. In _Conference on Empirical Methods in Natural Language Processing_, 2021. URL https://api.semanticscholar.org/CorpusID:237304520.
* Han et al. [2021] Zhen Han, Peng Chen, Yunpu Ma, and Volker Tresp. Explainable subgraph reasoning for forecasting on temporal knowledge graphs. In _International Conference on Learning Representations_, 2021. URL https://api.semanticscholar.org/CorpusID:235614395.
* Jung et al. [2021] Jaehun Jung, Jinhong Jung, and U Kang. Learning to walk across time for interpretable temporal knowledge graph completion. _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_, 2021. URL https://api.semanticscholar.org/CorpusID:236979995.
* Wang et al. [2022] Ruijie Wang, Zheng Li, Dachun Sun, Shengzhong Liu, Jinning Li, Bing Yin, and Tarek Abdelzaher. Learning to sample and aggregate: Few-shot reasoning over temporal knowledge graphs. _Advances in Neural Information Processing Systems_, 35:16863-16876, 2022.
* Dalvi and Suciu [2007] Nilesh Dalvi and Dan Suciu. Efficient query evaluation on probabilistic databases. _The VLDB Journal_, 16:523-544, 2007.

* Bordes et al. [2013] Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. Translating embeddings for modeling multi-relational data. In _NIPS 2013._, 2013.
* Jiang et al. [2016] Tingsong Jiang, Tianyu Liu, Tao Ge, Lei Sha, Baobao Chang, Sujian Li, and Zhifang Sui. Towards time-aware knowledge graph completion. In _Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers_, pages 1715-1724, Osaka, Japan, December 2016. The COLING 2016 Organizing Committee. URL https://aclanthology.org/C16-1161.
* Boschee et al. [2015] Elizabeth Boschee, Jennifer Lautenschlager, Sean O'Brien, Steve Shellman, James Starz, and Michael Ward. ICEWS Coded Event Data, 2015. URL https://doi.org/10.7910/DVN/28075.
* Leetaru and Schrodt [2013] Kalev Leetaru and Philip A. Schrodt. Gdelt: Global data on events, location, and tone. _ISA Annual Convention_, 2013.
* Shao et al. [2020] Pengpeng Shao, Guohua Yang, Dawei Zhang, Jianhua Tao, Feihu Che, and Tong Liu. Tucker decomposition-based temporal knowledge graph completion. _Knowl. Based Syst._, 238:107841, 2020.
* Li et al. [2021] Zixuan Li, Xiaolong Jin, Wei Li, Saiping Guan, Jiafeng Guo, Huawei Shen, Yuanzhuo Wang, and Xueqi Cheng. Temporal knowledge graph reasoning based on evolutional representation learning. _Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval_, 2021. URL https://api.semanticscholar.org/CorpusID:233324265.
* Yang et al. [2015] Bishan Yang, Scott Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and relations for learning and inference in knowledge bases. In _Proceedings of the International Conference on Learning Representations (ICLR) 2015_, May 2015.
* Kazemi and Poole [2018] Seyed Mehran Kazemi and David L. Poole. Simple embedding for link prediction in knowledge graphs. In _Neural Information Processing Systems_, 2018. URL https://api.semanticscholar.org/CorpusID:3674966.
* Ma et al. [2018] Yunpu Ma, Volker Tresp, and Erik A. Daxberger. Embedding models for episodic knowledge graphs. _J. Web Semant._, 59, 2018. URL https://api.semanticscholar.org/CorpusID:5444869.
* Dasgupta et al. [2018] Shib Sankar Dasgupta, Swayambhu Nath Ray, and Partha Talukdar. HyTE: Hyperplane-based temporally aware knowledge graph embedding. In _Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing_, pages 2001-2011, Brussels, Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1225. URL https://aclanthology.org/D18-1225.
* Garcia-Duran et al. [2018] Alberto Garcia-Duran, Sebastijan Dumancic, and Mathias Niepert. Learning sequence encoders for temporal knowledge graph completion. In _Conference on Empirical Methods in Natural Language Processing_, 2018. URL https://api.semanticscholar.org/CorpusID:52183483.
* Goel et al. [2020] Rishab Goel, Seyed Mehran Kazemi, Marcus Brubaker, and Pascal Poupart. Diachronic embedding for temporal knowledge graph completion. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 34, pages 3988-3995, 2020.
* Seo et al. [2016] Youngjoo Seo, Michael Defferrard, Pierre Vandergheynst, and Xavier Bresson. Structured sequence modeling with graph convolutional recurrent networks. In _International Conference on Neural Information Processing_, 2016. URL https://api.semanticscholar.org/CorpusID:2687749.
* Zhu et al. [2020] Cunchao Zhu, Muhao Chen, Changjun Fan, Guangquan Cheng, and Yan Zhan. Learning from history: Modeling temporal knowledge graphs with sequential copy-generation networks. In _AAAI Conference on Artificial Intelligence_, 2020. URL https://api.semanticscholar.org/CorpusID:229180723.
* Allen [1983] James F. Allen. Maintaining knowledge about temporal intervals. _Commun. ACM_, 26(11):832-843, nov 1983. ISSN 0001-0782. doi: 10.1145/182.358434. URL https://doi.org/10.1145/182.358434.
* Kingma and Ba [2015] Diederick P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In _Proceedings of the International Conference on Learning Representations (ICLR)_, 2015.

**Appendix**

## Appendix A More Details about Neural Operators

### Fuzzy Logic

**Fuzzy logic** is a generalization of Boolean logic, which is based on the idea that the truth of a statement can be expressed as a number between 0 and 1. It is a mathematical framework for reasoning with imprecise information. In fuzzy logic, there are also logical operators, such as conjunction, disjunction, negation, implication, equivalence, and exclusive or. Most popular fuzzy logic operators are defined as follows (\(a,b\in[0,1]\)):

(1) **conjunction**: \(a\wedge b=\min(a,b)\). **disjunction**: \(a\lor b=\max(a,b)\).

(2) **negation**: \(\neg a=1-a\). **exclusive or**: \(a\oplus b=\min(a,1-b)+\min(1-a,b)\).

(3) **implication**: \(a\to b=\max(1-a,b)\). **equivalence**: \(a\leftrightarrow b=\min(a,b)+\max(1-a,1-b)\).

However, the fuzzy logic operators are defined over real space, not suitable for reasoning over vector space. We expect that the fuzzy logic operators can be executed by matrix computation. Because the embedding space of knowledge graph is a vector space. In order to cope with tensor computation in neural networks, we introduce the fuzzy logic operators over vector space in the following, which is called vector logic.

### Vector Logic

Vector logic is an elementary logical model based on matrix algebra. In vector logic, true values are mapped to the vector, and logical operators are executed by matrix computation.

**Truth Value Vector Space**\(V_{2}\). A two-valued vector logic uses two \(d\)-dimensional (\(d\geq 2\)) column vectors \(\vec{s}\) and \(\vec{n}\) to represent true and false in the classic binary logic. The two vectors \(\vec{s}\) and \(\vec{n}\) are real-valued, normally orthogonal to each other, and normalized vectors, _i.e._, \(\|\vec{s}\|=1,\|\vec{n}\|=1\). Truth value vector space are generated by \(V_{2}=\{\vec{s},\vec{n}\}\), and operations on vectors in truth value space is based on scalar product.

**Operators**. The basic logical operators are associated with their own matrices by vectors in truth-value vector space. Two common types of operators are monadic and dyadic.

(1) **Monadic Operators** are functions: \(V_{2}\to V_{2}\). Two examples are Identity \(I=\vec{s}\vec{s}^{T}+\vec{n}\vec{n}^{T}\) and Negation \(N=\vec{n}\vec{s}^{T}+\vec{s}\vec{n}^{T}\) such that \(I\vec{s}=\vec{s},I\vec{n}=\vec{n},N\vec{n}=\vec{s},N\vec{s}=\vec{n}\). Note that the truth tables of \(I\) and \(N\) fulfill the real logical rules of identity and negation in classic boolean logic.

(2) **Dyadic operators** are functions: \(V_{2}\otimes V_{2}\to V_{2}\), where \(\otimes\) denotes Kronecker product. Dyadic operators include conjunction \(C\), disjunction \(D\), implication IMPL, equivalence \(E\), exclusive or XOR, etc. For example, the conjunction between two logical propositions \((p\wedge q)\) is performed by \(C(\vec{u}\otimes\vec{v})\), where \(C=\vec{s}(\vec{s}\otimes\vec{s})^{T}+\vec{n}(\vec{s}\otimes\vec{n})^{T}+\vec {n}(\vec{n}\otimes\vec{s})^{T}+\vec{n}(\vec{n}\otimes\vec{n})^{T}\). It can be verified that \(C(\vec{s}\otimes\vec{s})=\vec{s},C(\vec{s}\otimes\vec{n})=C(\vec{n}\otimes \vec{s})=C(\vec{n}\otimes\vec{n})=\vec{n}\). Dyadic operators which correspond to logical operations in classic binary logic are defined by its formulation to perform logical operations on truth value vectors. Their associated matrices has \(d^{2}\) rows and \(d\) columns.

**Many-valued Two-dimensional Logic**. Many-valued logic is introduced to include uncertainties in the logic vector. Weighting \(\vec{s}\) and \(\vec{n}\) by probabilities, uncertainties are introduced: \(\vec{f}=\epsilon\vec{s}+\delta\vec{n}\), where \(\epsilon,\delta\in[0,1],\ \epsilon+\delta=1\). Besides, operations on vectors can be simplified to computation on the scalar of these vectors. For example, given two vectors \(\vec{u}=\alpha\vec{s}+\beta\vec{n},\vec{v}=\alpha^{\prime}\vec{s}+\beta^{ \prime}\vec{n}\), we have:

\[\text{NOT}(\vec{u})= N\vec{u}=(1-\alpha)\vec{s}+\alpha\vec{n}\] \[\text{OR}(\vec{u},\vec{v})= D(\vec{u}\otimes\vec{v})\] \[\text{AND}(\vec{u},\vec{v})= C(\vec{u}\otimes\vec{v})\] \[\text{AND}(\alpha,\alpha^{\prime})= \vec{s}^{T}C(\vec{u}\otimes\vec{v})=\alpha\alpha^{\prime}\] (7) \[\text{IMPL}(\vec{u},\vec{v})= L(\vec{u}\otimes\vec{v})\] \[\text{XOR}(\vec{u},\vec{v})= X(\vec{u}\otimes\vec{v})\]

[MISSING_PAGE_FAIL:16]

Proof.: (Proposition 1) **Commutativity**:

For the intersection operations, as the calculations of \(\mathcal{I}_{e}\) and \(\mathcal{I}_{t}\) are identical, here, we only prove that \(\mathcal{I}_{e}\) complies with commutative law. The entity feature part and the time feature part of the result are computed as a weighted summation of each query's corresponding parts. Since addition is commutative and the attention weights do not concern the order of calculations, both feature parts' calculations are commutative.

Then, we discuss the logic parts. The logic parts only include the AND in fuzzy logic which, essentially, is just the multiplication of each element by the definition provided above. Because multiplication is surely commutative, the calculation of either entity logic part or time logic part is commutative. Thus the intersection operation \(\mathcal{I}_{e}(\mathcal{I}_{t})\) is commutative.

As for \(\mathcal{U}_{e}\) and \(\mathcal{U}_{t}\), their feature parts have the same form of weighted summation as the intersection operations do. Thus, the feature parts of both \(\mathcal{U}_{e}\) and \(\mathcal{U}_{t}\) comply to commutative law. Also, the _time logic part_ of \(\mathcal{U}_{e}\) and the _entity logic part_ of \(\mathcal{U}_{t}\) solely concern AND operator which has been proved commutative before. The OR operator, by definition, gives the aggregation of different accumulative parts each of which is commutative itself. Also, the multiplications in each of the summations are commutative. Hence, OR operation is invariant to the order of calculations, which finally gives the calculations of _entity logic part_ of \(\mathcal{U}_{e}\) and the _time logic part_ of \(\mathcal{U}_{t}\) are commutative. Then we can naturally affirm that \(\mathcal{U}_{e}\) and \(\mathcal{U}_{t}\) are commutative as well.

Proof.: Additionally, we prove that the cost of OR operator's implementation is not as expensive as it seems to be. The process of computation can be described as follows:

```
0: queries \(\{q_{1}...q_{n}\}\)
0: the union of queries
1: Let \(u=0\).
2: For \(q\)  In \(\{q_{1}...q_{n}\}\)
3: \(u=u+q-u*q\)
4: EndFor
5:return\(u\) ```

**Algorithm 1**OR

As we implement OR step by step on a series of \(n\) queries, the loop goes n-1 times in total. Assuming the embedding dimension of a query is \(d\), we can have the cost of OR is O(\(n\)*\(d\)). 

## Appendix B More Details about Experiments

In this section, we show more details about our experiments. Firstly, we introduce the origin datasets in Section B.1. Then, we describe the details on how we define the query structure and how to sample queries in Section B.2. With the generated queries, we construct three datasets and report their statistics in Section B.3. We also show the details of our model implementation in Section B.4 and evaluation protocol in Section B.5. Besides, we show more experimental data for sensitive analysis in Section B.6. Finally, we present the detail metrics of main results in Section B.7.

### Details of Origin Datasets

To construct the reasoning dataset, we use three datasets of temporal KGs that have become standard benchmarks for TKGC: ICEWS14 [37], ICEWS05-15 [37], and GDELT-500 [38]. The two subsets of ICEWS are generated by Boschee et al. [37]: ICEWS14 corresponding to the facts in 2014 and ICEWS05-15 corresponding to the facts between 2005 and 2015. GDELT-500 generated by Leetaru and Schrodt [38] corresponds to the facts from April 1, 2015, to March 31, 2016. The statistics of the dataset are shown in Table 8.

[MISSING_PAGE_FAIL:18]

\begin{table}
\begin{tabular}{l l l} \hline \hline
**Type** & **Query Name** & **Query Structure Definition** \\ \hline \multirow{4}{*}{entity multi-hop} & **Pe** & Pe(s, r, t) \\  & **Pe2** & Pe(Pe(s1, r1, t1), r2, t2) \\  & **Pe3** & Pe(Pe(Pe(s1, r1, t1), r2, t2), r3, t3) \\  & **e2i** & And(Pe(s1, r1, t1), Pe(s2, r2, t2)) \\  & **e3i** & And(Pe(s1, r1, t1), Pe(s2, r2, t2), Pe(e3, r3, t3)) \\ \cline{2-3}  & **e2i\_N** & And(Pe(s1, r1, t1), Not(Pe(s2, r2, t2))) \\  & **e3i\_N** & And(Pe(s1, r1, t1), Pe(s2, r2, t2), Not(Pe(s3, r3, t3))) \\ \cline{2-3} entity not & **Pe\_e2i\_N** & Pe(And(Pe(s1, r1, t1), Not(Pe(s2, r2, t2))), r3, t3) \\  & **e2i\_PeN** & And(Pe(Pe(s1, r1, t1), Not(Pe(s2, r2, t2))), r3, t3) \\  & **e2i\_PeN** & And(Pe(Pe(s1, r1, t1), r2, t2), Not(Pe(s2, r3, t3))) \\  & **e2i\_NPe** & And(Not(Pe(s1, r1, t1), r2, t2)), Pe(s2, r3, t3)) \\ \cline{2-3} entity union & **e2u** & Or(Pe(s1, r1, t1), Pe(s2, r2, t2)) \\  & **Pe\_e2u** & Pe(Or(Pe(s1, r1, t1), Pe(s2, r2, t2)), r3, t3) \\ \hline \multirow{4}{*}{time multi-hop} & **Pt** & Pt(s, r, o) \\  & **aPt** & after(Pt(s, r, o)) \\  & **bPt** & before(Pt(s, r, o)) \\  & **Pe\_Pt** & Pe(s1, r1, Pt(s2, r2, o1)) \\  & **Pt\_sPe\_Pt** & Pt(Pe(s1, r1, Pt(s2, r2, o1)), r3, o2) \\  & **Pt\_oPe\_Pt** & Pt(s1, r1, Pe(s2, r2, Pt(s3, r3, o1))) \\  & **t2i\_N** & TimeAnd(Pt(s1, r1, o1), Pt(s2, r2, o2), Pt(s3, r3, o3)) \\  & **t2i\_N** & TimeAnd(Pt(s1, r1, o1), TimeNot(Pt(s2, r2, o1), r3, o1), TimeNot(Pt(s3, r3, o2)))) \\  & **t2i\_NPt** & TimeAnd(TimeNot(Pt(Pe(s1, r1, t1), r2, o1)), Pt(s2, r3, o2)) \\  & **t2i\_PtN** & TimeAnd(Pt(Pe(s1, r1, t1, t2), o1), TimeNot(Pt(s2, r3, o2))) \\ \cline{2-3}  & **t2u** & TimeOr(Pt(s1, r1, o1), Pt(s2, r2, o2)) \\  & **Pe\_t2u** & Pe(s1, r1, TimeOr(Pt(s2, r2, o1), Pt(s3, r3, o2))) \\ \hline \multirow{4}{*}{
\begin{tabular}{l} hybrid multi-hop} & **between** & TimeAnd(after(Pt(s1, r1, o1)), before(Pt(s2, r2, o2))) \\  & **e2i\_Pe** & And(Pe(Pe(s1, r1, t1, t2, t2), Pe(s2, r3, t3)) \\  & **Pe\_e2i** & Pe(e2i(s1, r1, t1, s2, r2, t2), r3, t3) \\  & **t2i\_Pe** & TimeAnd(Pt(Pe(s1, r1, t1), r2, o1), Pt(s2, r3, o2)) \\  & **Pe\_t2i** & Pe(s1, r1, t2i(s2, r2, o1, s3, r3, o2)) \\  & **Pe\_aPt** & Pe(s1, r1, after(Pt(s2, r2, o1))) \\  & **Pe\_bPt** & Pe(s1, r1, before(Pt(s2, r2, o1))) \\  & **Pe\_at2i** & Pe(s1, r1, after(t2i(s2, r2, o1, s3, r3, o2))) \\  & **Pe\_bt2i** & Pe(s1, r1, before(t2i(s2, r2, o1, s3, r3, o2))) \\  & **Pt\_sPe** & Pt(Pe(s1, r1, t1), r2, o1) \\  & **Pt\_oPe** & Pt(s1, r1, Pe(s2, r2, t1)) \\  & **Pt\_se2i** & Pt(e2i(s1, r1, t1, s2, r2, t2), r3, o1) \\  & **Pt\_oe2i** & Pt(s1, r1, e2i(s2, r2, t1, s3, r3, t2)) \\ \hline \hline \end{tabular}
\end{table}
Table 6: Definition of query structures in temporal query embeddings. Operators on entity sets include Pe, And, Or, and Not. Operators on timestamp sets include Pt, TimeAnd, TimeOr, TimeNot, after, and before. The prefix “a” and “b” represent “after” and “before” respectively. The prefix “s” or “o” mean that the sub-query is a subject query or an object query respectively.

Figure 5: Visualization of temporal query structures answering entity sets. These structures are basic functions that can be used to construct more complex temporal query structures.

Figure 6: Visualization of temporal query structures answering timestamp sets. These structures are basic functions that can be used to construct more complex temporal query structures.

the functions are easy to be extended to support more complex query structures and reimplement the existing query embedding methods.

As is introduced in Section 4, we use the computation graph to represent the reasoning process. To get the computation graph of a CQF, we use the python interpreter to parse the function to Abstract Syntax Tree (AST), which is a more friendly readable subset of computation graph. In this way, executing the computation graph is equivalent to executing the CQF in python interpreter. Since we have the god privileged access to the AST, we can modify the interpreter to support various dynamic reasoning processes. Below we show how to unify (1) the reasoning of ground-truth, (2) the sampling of anchors, and (3) the reasoning of embedding-based methods by modifying the python interpreter.

**Ground-Truth Reasoning Interpreter**.

In the reasoning of ground-truth, we need to get all real answers of a query under a given TKG. To achieve this, the first we need to do is to implement the basic functions. We wrap the python built-in set to QuerySet class to store entities and timestamps. The basic functions are implemented as lambda function in python, with input and output as QuerySet. Then, the basic functions are registered as symbols to the python interpreter. When executing the CQF, the python interpreter will call the corresponding basic functions to get the final answer. The answers are finally generated from subgraph matching, which depends on the ground truth in TKG. We show the pseudocode of the ground-truth reasoning interpreter in Figure 7.

**Anchors Sampling Interpreter**.

The anchor, which may be entity, relation or timestamp, is the input argument of the CQF. The aim of the anchors sampling interpreter is to get the possible anchors and answers of a query under a given TKG. For the sampled anchors, we expect the answer set not empty. Since the answers could be obtained from the ground-truth reasoning interpreter, we only focus on the sampling of anchors in the anchors sampling interpreter.

Given the standard split of edges into training (\(\mathcal{F}_{\text{train}}\)), validation (\(\mathcal{F}_{\text{valid}}\)) and test (\(\mathcal{F}_{\text{test}}\)) sets, we append inverse relations and double the number of edges in the graph. Then we create three graph: \(\mathcal{G}_{\text{train}}=\{\mathcal{V},\mathcal{R},\mathcal{T},\mathcal{F}_ {\text{train}}\}\), \(\mathcal{G}_{\text{valid}}=\{\mathcal{V},\mathcal{R},\mathcal{T},\mathcal{F}_ {\text{train}}+\mathcal{F}_{\text{valid}}\}\),\(\mathcal{G}_{\text{test}}=\{\mathcal{V},\mathcal{R},\mathcal{T},\mathcal{F}_{\text{train}}+ \mathcal{F}_{\text{valid}}+\mathcal{F}_{\text{test}}\}\). Given a query \(q\), let \(\llbracket q\rrbracket_{\text{train}}\), \(\llbracket q\rrbracket_{\text{valid}}\), and \(\llbracket q\rrbracket_{\text{test}}\) denote a set of answers (entities or timestamps) obtained by subgraph matching of \(q\) on \(\mathcal{G}_{\text{train}}\), \(\mathcal{G}_{\text{valid}}\) and \(\mathcal{G}_{\text{test}}\). For each query \(q\), the reasoning process starts from anchor nodes and computes the final answer set via subgraph matching.

For the basic function **Pe** and **Pt**, we simply use all the triples and extract the entities and timestamps as the anchors. These anchors are supposed to have no empty answers under **Pe** and **Pt**. However, when it comes to some hard queries, such as **e2i** and **e3i**, the random sampled anchors may have empty answers. Because the TKG is sparse and incomplete, the intersection of two query sets has a high probability to be empty. The empty answers are meaningless for model-training and damage to

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline  & 1p & 2p & 3p & 2i & 3i \\ avg\({}_{e}\) & Pe & Pe2 & Pe3 & e2i & e3i \\ avg\({}_{t}\) & Pt, aPt, bPt & Pe\_Pt & Pt\_sPe\_Pt, Pt\_oPe\_Pt & t2i & t3i \\ \hline  & 2in & 3in & inp & pin & pni \\ avg\({}_{e,\mathcal{C}_{e}}\) & e2i\_N & e3i\_N & Pe\_e2i\_N & e2i\_PeN & e2i\_NPe \\ avg\({}_{t,\mathcal{C}_{i}}\) & t2i\_N & t3i\_N & Pe\_t2i\_N & t2i\_PtN & t2i\_NPt \\ \hline  & 2u & up & & & \\ avg\({}_{\{\mathcal{U}_{t}\}}\) & e2u & Pe\_e2u & & & \\ avg\({}_{\{\mathcal{U}_{t}\}}\) & t2u & Pe\_t2u & & & \\ \hline  & pi & ip & & & \\ avg\({}_{x}\) & e2i\_Pe & Pe\_e2i & & Pe\_aPt & Pe\_bPt \\  & t2i\_Pe & Pe\_t2i & & Pe\_at2i & Pe\_btzi \\  & & & & & Pt\_sPe & Pt\_oPe \\  & & & & between & Pt\_se2i & Pt\_oe2i \\ \hline \hline \end{tabular}
\end{table}
Table 7: The query structures are aggregated into groups. The groups are inspired by the experiment settings in static query embeddings [1, 2, 3, 4]. The groups avg\({}_{e}\), avg\({}_{\mathcal{E}_{e},\mathcal{C}_{e}}\), avg\({}_{\mathcal{E}_{i},\mathcal{C}_{i}}\) are for training and testing. Besides, extra groups avg\({}_{\{\mathcal{U}_{e}\}}\), avg\({}_{\{\mathcal{U}_{t}\}}\), avg\({}_{\{\mathcal{F}_{\text{train}}\}}\) are for evaluation and testing only.

the performance of data-sampling process. To solve this problem, we use the following two strategies to accelerate the sampling.

(1) **Inverse Sampling**: We randomly sample an entity as objective, denoted \(e_{o}\). Then we sample subjective entity \(e_{s_{1}},e_{s_{2}}\), relation \(r_{1},r_{2}\) and timestamp \(t_{1},t_{2}\), according to the fact \((e_{s_{1}},r_{1},e_{o},t_{1})\) and \((e_{s_{2}},r_{2},e_{o},t_{2})\). The sampled anchors are \((e_{s_{1}},r_{1},t_{1};e_{s_{2}},r_{2},t_{2})\). These anchors under **ezi** have the answer \(e_{o}\) at least, which asserts that the answer set is not empty. Such sampling method that samples the answer first and then samples the anchors is called **Inverse Sampling**.

(2) **Bi-directional Sampling**: For long multi-hop queries, such as **Pe2**, the complexity of random sampling is \(O(N^{2L})\), where \(N\) is the entity count and \(L\) is the length of the query. **Pe2** has \(L=2\). It contains an anchor-sampling complexity of \(O(N^{L})\) and a ground-truth reasoning (to get answers) complexity of \(O(N^{L})\). The origin sampling is to sample one subjective entity, get the objective as answers as next subjective anchors, again get the next objective answers. The final answers recursively depend on the initial subjective entity, leading to low performance. To accelerate, we sample an entity at the middle of AST, denoted \(e_{m}\). Then we sample in two directions. One is forward, \(e_{m}\) as the subjective entity, to sample relation \(r_{2}\) and timestamp \(t_{2}\). The other is backward, \(e_{m}\) as the objective entity, to sample subjective anchor \(e_{1}\), relation \(r_{1}\) and timestamp \(t_{1}\). The sampled anchors are \((e_{1},r_{1},t_{1};r_{2},t_{2})\). The final answer set is asserted not empty, because it at least contains all the answers of \(\text{Pe}(e_{m},r_{2},t_{2})\). Be aware that the two directions are independent, which can be sampled in parallel. Such sampling method that samples the answer in two directions is called **Bi-directional Sampling**, which can reduce the computation complexity to \(O(N^{L+\frac{k}{2}})\), composed of a sampling complexity of \(O(N^{\frac{k}{2}})\) and a ground-truth reasoning complexity of \(O(N^{L})\).

Figure 7: Python-style pseudocode of ground-truth reasoning interpreter.

#### Embedding Reasoning Interpreter

On the contrary of the ground-truth reasoning interpreter which has '**set**' as the input and output of the CQFs, in the embedding reasoning interpreter, the input and output of CQFs are '**embedding vectors**'. The embedding-based method for reasoning over TKG is called **Temporal Query Embedding**. The computation complexity of the embedding reasoning interpreter is \(O(L+N)\), where \(L\) is the length of the query and \(N\) is the entity count. The complexity consists of a query-embedding complexity of \(O(L)\) and a scoring-to-answer complexity of \(O(N)\). The embedding reasoning is much faster than the ground-truth reasoning, which has a computation complexity of \(O(N^{L})\).

To implement the embedding reasoning interpreter, we just need to replace the basic functions with neural networks. The symbols dict to pass to the interpreter is

\[\begin{array}{l}\{\\ \text{ ``Pe'': }\mathcal{P}_{e},\text{ ``Pt'': }\mathcal{P}_{t},\\ \text{ ``And'': }\mathcal{I}_{e},\text{ ``Or'': }\mathcal{U}_{e},\text{ ``Not'': }\mathcal{N}_{e},\\ \text{ ``TimeAnd'': }\mathcal{I}_{t},\text{ ``TimeOr'': }\mathcal{U}_{t},\text{ ``TimeNot'': }\mathcal{N}_{t},\\ \text{ ``TimeAfter'': }\mathcal{A}_{t},\text{ ``TimeBefore'': }\mathcal{B}_{t}\\ \}\}\end{array}\] (8)

The embedding vectors are learned as is introduced in Section 4. Unlike the ground-truth reasoning, the embedding reasoning is fuzzy. The output of the embedding reasoning interpreter is an embedding vector, which is a fuzzy set representation. To get the final answer set, we need to use the distance function (in Section 4.3) to score to candidate answers. In this way, the embedding vector is converted to the final answer set. The final answers are given in the ranking list, where each answer is followed by its distance to the query. Usually the top-k answers are accepted as the final answers.

Note that the interpreter is flexible, and easy to implement and extend. In order to reproduce static query embeddings [2; 3; 4] over dynamic knowledge graphs, the only thing to do is to implement the symbols dict and the distance function.

We hope that the design of interpreter is helpful for the future research of temporal query embedding.

#### Screenshot

Additionally, we show the screenshot of a real running interpreter in Figure 8. In the screenshot, we randomly select an example of **e2i** query. Then, we use the embedding reasoning interpreter to get the final answer set step by step. The final answer set is shown in the ranking list, where each answer is followed by its similarity score to the query. Finally, the bot correctly predicts the hard answer which only exists in the test set!

### Details of Generated Datasets

Finally, we generate three datasets for the task of temporal complex reasoning using the process in Section B.2. The statistics of the generated datasets are listed below. Table 9 show the count of query

Figure 8: The screenshot of a real running interpreter.

[MISSING_PAGE_FAIL:25]

\begin{table}
\begin{tabular}{l r r r r r r r r r} \hline \hline  & \multicolumn{3}{c}{**ICEWS14**} & \multicolumn{3}{c}{**ICEWS05-15**} & \multicolumn{3}{c}{**GDELT-500**} \\ \cline{2-10}
**Query Name** & **Train** & **Validate** & **Test** & **Train** & **Validate** & **Test** & **Train** & **Validate** & **Test** \\ \hline

[MISSING_PAGE_POST]

pt** & 8.14 & 25.96 & 26.23 & 66.99 & 154.01 & 147.34 & 17.58 & 35.60 & 32.22 \\ \hline
**e2u** & - & 3.12 & 3.17 & - & 2.38 & 2.40 & - & 5.04 & 5.41 \\
**Pe\_e2u** & - & 2.38 & 2.44 & - & 1.24 & 1.25 & - & 9.39 & 10.78 \\ \hline
**t2u** & - & 4.35 & 4.53 & - & 5.57 & 5.92 & - & 9.70 & 10.51 \\
**Pe\_t2u** & - & 2.72 & 2.83 & - & 1.24 & 1.28 & - & 9.90 & 11.27 \\ \hline
**between** & 122.61 & 120.94 & 120.27 & 1407.87 & 1410.39 & 1404.76 & 214.16 & 210.99 & 207.85 \\
**e2i\_Pe** & - & 1.00 & 1.00 & - & 1.00 & 1.00 & - & 1.07 & 1.10 \\
**Pe\_e2i** & - & 2.18 & 2.24 & - & 1.32 & 1.33 & - & 5.08 & 5.49 \\
**t2i\_Pe** & - & 1.03 & 1.03 & - & 1.01 & 1.02 & - & 1.34 & 1.44 \\
**Pe\_t2i** & - & 1.14 & 1.16 & - & 1.07 & 1.08 & - & 2.01 & 2.20 \\
**Pe\_aPt** & 4.67 & 16.73 & 16.50 & 18.68 & 43.80 & 46.23 & 49.31 & 66.21 & 68.88 \\
**Pe\_at2i** & 7.26 & 22.63 & 21.98 & 30.40 & 60.03 & 53.18 & 88.77 & 101.60 & 101.88 \\
**Pt\_sPe** & 8.65 & 28.86 & 29.22 & 71.51 & 162.36 & 155.46 & 27.55 & 45.83 & 43.73 \\
**Pt\_se2i** & 1.31 & 5.72 & 6.19 & 1.37 & 9.00 & 9.30 & 2.76 & 8.72 & 7.66 \\
**Pe\_bPt** & 4.53 & 17.07 & 16.80 & 18.70 & 45.81 & 48.23 & 67.67 & 84.79 & 83.00 \\
**Pe\_bt2i** & 7.27 & 21.92 & 21.23 & 30.31 & 61.59 & 64.98 & 88.80 & 100.64 & 100.67 \\
**Pt\_oPe** & 1.41 & 5.23 & 5.46 & 1.68 & 8.36 & 8.21 & 3.84 & 11.31 & 10.06 \\
**Pt\_oe2i** & 1.32 & 6.51 & 7.00 & 1.44 & 10.49 & 10.89 & 2.55 & 8.17 & 7.27 \\ \hline \hline \end{tabular}
\end{table}
Table 10: Average answers count for each dataset. All numbers are rounded to two decimal places.

found in sensitive analysis on ICEWS14 (Section B.6) for all datasets. Besides, the source code is available at Github2. We cite these projects 3, and thank them for their great contributions!

Footnote 3: TFLEX: https://github.com/LinXueyuanStdio/TFLEX

Footnote 4: GQE, Query2box, BetaE: https://github.com/snap-stanford/KGReasoning

### Evaluation

Given the standard split of edges into training (\(\mathcal{F}_{\text{train}}\)), validation (\(\mathcal{F}_{\text{valid}}\)) and test (\(\mathcal{F}_{\text{test}}\)) sets, we append inverse relations and double the number of edges in the graph. Then we create three graph: \(\mathcal{G}_{\text{train}}=\{\mathcal{V},\mathcal{R},\mathcal{T},\mathcal{F}_ {\text{train}}\},\mathcal{G}_{\text{valid}}=\{\mathcal{V},\mathcal{R},\mathcal{ T},\mathcal{F}_{\text{train}}+\mathcal{F}_{\text{valid}}\},\mathcal{G}_{\text{test}}=\{ \mathcal{V},\mathcal{R},\mathcal{T},\mathcal{F}_{\text{train}}+\mathcal{F}_{ \text{valid}}+\mathcal{F}_{\text{test}}\}\). Given a query \(q\), let \(\llbracket q\rrbracket_{\text{train}}\), \(\llbracket q\rrbracket_{\text{valid}}\), and \(\llbracket q\rrbracket_{\text{test}}\) denote a set of answers (entities or timestamps) obtained by subgraph matching of \(q\) on \(\mathcal{G}_{\text{train}}\), \(\mathcal{G}_{\text{valid}}\) and \(\mathcal{G}_{\text{test}}\). For a test query \(q\) and its non-trivial answer set \(v\in\llbracket q\rrbracket_{test}-\llbracket q\rrbracket_{valid}\), we denote the rank of each answer \(v_{i}\) as \(rank(v_{i})\). The mean reciprocal rank (MRR) is \(\text{MRR}(q)=\frac{1}{||v||}\sum_{v_{i}\in v}\frac{1}{rank(v_{i})}\) and Hits at K (Hits@K) is Hits@K(\(q)=\frac{1}{||v||}\sum_{v_{i}\in v}f(rank(v_{i}))\), where \(f(n)=\begin{cases}1,&n\leq K\\ 0,&n>K\end{cases}\).

### Experiment Data for Sensitive Analysis

We conduct experiments on ICEWS14 to analyze the impact of the embedding dimensionality \(d\) and the margin \(\gamma\) on the performance of TFLEX.

Impacts of Embedding DimensionalityOur experiments indicate that the selection of embedding dimension has a substantial influence on the effectiveness of TFLEX. We train TFLEX with embedding dimension \(d\in\{300,400,500,600,700,800,900,1000\}\) and plot results based on the validation set, as shown in Figure 8(a). With the increase of \(d\), the model performance (indicated by MRR) increases rapidly and reaches its top at \(d=800\). Therefore, we assign 800 as the best setting.

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline Dataset & \(d\) & \(b\) & \(n\) & \(\gamma\) & \(m\) & \(l\) \\ \hline ICEWS14 & 800 & 512 & 128 & 15 & 300k & \(1\times 10^{-4}\) \\ ICEWS05-15 & 800 & 512 & 128 & 30 & 300k & \(1\times 10^{-4}\) \\ GDELT-500 & 800 & 512 & 128 & 30 & 300k & \(1\times 10^{-4}\) \\ \hline \hline \end{tabular}
\end{table}
Table 12: Hyperparameters on each dataset. \(d\) is the embedding dimension, \(b\) is the batch size, \(n\) is the negative sampling size, \(\gamma\) is the parameter in the loss function, \(m\) is the maximum training step, and \(l\) is the learning rate.

Figure 9: The impact of embedding dimensionality \(d\) and the margin \(\gamma\) on MRR.

[MISSING_PAGE_FAIL:28]

\begin{table}
\begin{tabular}{l c c c c c c c} \hline \hline
**Model** & avg\({}_{c}\) & **Pe** & **Pe2** & **Pe3** & **e2i** & **e3i** & \\ \hline Query2box & 25.06 & 25.81 & 17.29 & 12.97 & 16.00 & 53.25 & \\ BetaE & 37.19 & 39.52 & 23.77 & 17.50 & 23.77 & 81.38 & \\ ConE & 41.94 & 42.55 & 30.90 & 24.78 & 26.52 & 84.93 & \\ ConE(temporal) & 42.23 & 41.21 & 31.83 & 24.99 & 28.98 & 84.17 & \\ FLEX & 43.67 & 45.25 & 33.07 & 27.22 & 27.62 & 85.18 & \\ TTLEX & 56.79 & 48.21 & 37.27 & 33.53 & 69.24 & 95.70 & \\ X(ConE) & 40.93 & 40.58 & 28.84 & 24.31 & 30.93 & 79.98 & \\ X-1F & 56.89 & 48.61 & 37.51 & 32.61 & 71.25 & 94.47 & \\ X-logic & 56.64 & 48.00 & 37.42 & 31.23 & 73.11 & 93.45 & \\ \hline \hline  & avg\({}_{d_{c}}\) & **Pt** & **aPt** & **bPt** & **Pe\_Pt** & **Pt\_sPe\_Pt** & **Pt\_oPe\_Pt** & **t2i** & **t3i** \\ \hline TFLEX & 17.56 & 20.87 & 3.00 & 2.96 & 14.27 & 9.57 & 9.46 & 27.49 & 52.84 \\ X(ConE) & 16.41 & 19.45 & 3.06 & 3.01 & 13.96 & 8.79 & 8.67 & 25.01 & 49.36 \\ X-1F & 18.77 & 21.94 & 3.04 & 2.99 & 16.69 & 10.73 & 10.44 & 29.66 & 54.71 \\ X-logic & 18.03 & 21.33 & 3.10 & 3.05 & 15.76 & 9.85 & 9.94 & 28.57 & 52.63 \\ \hline \hline  & avg\({}_{c,c_{e}}\) & **e2i\_N** & **e3i\_N** & **Pe\_e2i\_N** & **e2i\_PeN** & **e2i\_Npe** & & & \\ \hline BetaE & 36.69 & 30.44 & 87.93 & 19.94 & 22.80 & 22.36 & & \\ ConE & 44.88 & 40.98 & 99.12 & 29.22 & 29.84 & 25.22 & & \\ ConE(temporal) & 44.94 & 41.45 & 98.99 & 29.48 & 30.71 & 24.09 & & \\ FLEX & 44.41 & 38.30 & 99.22 & 31.18 & 30.49 & 22.84 & & \\ TFLEX & 50.82 & 45.55 & 99.56 & 34.74 & 35.63 & 38.61 & & \\ X(ConE) & 42.15 & 39.10 & 96.25 & 26.92 & 27.59 & 20.89 & & \\ X-1F & 49.78 & 42.31 & 99.31 & 34.89 & 34.77 & 37.61 & & \\ X-logic & 51.17 & 44.65 & 99.25 & 35.30 & 36.31 & 40.33 & & \\ \hline \hline  & avg\({}_{d_{c}}\) & **e2i\_N** & **e3i\_N** & **Pe\_t2i\_N** & **t2i\_Pt**N** & **t2i\_Npt** & \\ \hline TFLEX & 36.37 & 25.38 & 98.91 & 34.05 & 11.42 & 12.07 & & \\ X(ConE) & 35.24 & 26.90 & 98.82 & 30.30 & 9.44 & 10.75 & & \\ X-1F & 37.73 & 26.40 & 98.82 & 37.85 & 12.38 & 13.23 & & \\ X-logic & 36.39 & 25.68 & 98.69 & 33.30 & 11.34 & 12.93 & & \\ \hline \hline  & avg\({}_{\{d_{c}\}}\) & **e2u** & **Pe\_e2u** & & & & \\ \hline BetaE & 19.95 & 18.61 & 21.28 & & & & \\ ConE & 26.47 & 21.84 & 31.11 & & & & \\ ConE(temporal) & 27.63 & 23.01 & 32.26 & & & & \\ FLEX & 29.25 & 24.05 & 34.46 & & & & \\ TFLEX & 35.74 & 29.20 & 42.28 & & & & \\ X(ConE) & 25.46 & 20.26 & 30.67 & & & & \\ X-1F & 34.48 & 30.04 & 38.93 & & & & \\ X-logic & 34.68 & 29.44 & 39.92 & & & & \\ \hline \hline  & avg\({}_{\{d_{c}\}}\) & **t2u** & **Pe\_t2u** & & & & \\ \hline TFLEX & 26.24 & 30.73 & 21.74 & & & & \\ X(ConE) & 24.07 & 27.63 & 20.51 & & & & \\ X-1F & 28.04 & 33.91 & 22.16 & & & & \\ X-logic & 26.36 & 31.21 & 21.52 & & & & \\ \hline \hline  & avg\({}_{\{d_{c}\}}\) & **e2i\_Pe** & **Pe\_e2i** & **Pe\_aPt** & **Pe\_bPt** & **Pe\_at2i** & **Pe\_bt2i** & \\ \hline TFLEX & 28.03 & 98.86 & 36.77 & 8.66 & 9.74 & 7.90 & 7.78 & \\ X(ConE) & 26.65 & 87.31 & 28.72 & 11.01 & 10.40 & 11.21 & 11.27 & \\ X-1F & 29.31 & 98.87 & 36.00 & 10.04 & 10.21 & 8.30 & 8.06 \\ X-logic & 28.61 & 97.64 & 36.96 & 10.09 & 10.27 & 8.76 & 8.93 & \\ \hline \hline  & avg\({}_{\{d_{c}\}}\) & **t2i\_Pe** & **Pe\_t2i** & **Pt\_sPe** & **Pt\_oPe** & **Pt\_sPe2i** & **Pt\_oPe\_Pt** & **t2i** & **t3i** \\ \hline TFLEX & 35.93 & 96.62 & 64.50 & 4.32 & 10.58 & 8.20 & 7.95 & 2.57 \\ X(ConE) & 30.13 & 95.40 & 63.04 & 3.77 & 8.82 & 6.44 & 5.76 & 3.32 \\ X-1F & 36.43 & 97.24 & 70.32 & 4.88 & 10.73 & 12.24 & 11.55 &

\begin{table}
\begin{tabular}{l c c c c c c c} \hline \hline

\begin{table}
\begin{tabular}{l c c c c c c c} \hline \hline

**RQ1**: How about incorporating temporal information into the static query embedding, without considering time logic?

**RQ2**: Further, how about enhancing the static query embedding with temporal logic?

To address research question (**RQ1**), we propose a variant of ConE called **ConE(temporal)** that incorporates temporal information into the static query embedding. The only difference between ConE and ConE(temporal) is the projection operator used. In ConE(temporal), the projection operator incorporates temporal information through a technique called TTransE, which uses the temporal embedding of timestamps. In terms of formulation, the projection operator for ConE(temporal) is given by \(\mathcal{P}_{e}(\mathbf{V}_{q},\mathbf{r},\mathbf{V}_{t})=g(\textbf{ MLP}\ (\mathbf{V}_{q}+\mathbf{r}+\mathbf{V}_{t}))\), while for ConE it is given by \(\mathcal{P}_{e}(\mathbf{V}_{q},\mathbf{r},\mathbf{V}_{t})=g(\textbf{ MLP}\ (\mathbf{V}_{q}+\mathbf{r}))\). Note that \(\mathbf{V}_{q},\mathbf{r},\mathbf{V}_{t}\) are cone embeddings.

From Table 17, we observe that there is slightly improvement in terms of MRR when comparing ConE(temporal) with ConE. It shows that the temporal information can help to improve the performance of static query embedding on answering entities over TKGs. However, the improvement is not significant, which indicates that simply aware of the temporal information is not enough to promote the static query embedding to efficient temporal one.

Next, we wonder if it could help when we utilize more queries involving time logic, which provides more temporal information. Therefore, we address research question (**RQ2**) by proposing a variant of ConE and TFLEX, called **X(ConE)**, that enhances the static query embedding with temporal logic. **X(ConE)** replaces the entity part of temporal feature-logic embedding with ConE, as is introduced in Section 5.2. In the other view, **X(ConE)** is based on ConE, using cone embedding concatenated with the time part of temporal feature-logic embedding, which can handle temporal logic.

From Table 17, to our surprise, **X(ConE)** performs worse than ConE and TFLEX. The concatenation of cone embedding and feature-logic embedding does not help to improve the overall performance of temporal complex reasoning. This is because cone embedding is geometric, while temporal feature-logic embedding is fuzzy. We think there is a mismatch or semantic conflict between the two embeddings, which leads to the poor performance of **X(ConE)**.

Be aware that we do not deny the importance of temporal logic. In fact, temporal logic is very important for temporal complex reasoning (See **Ablation on time part** in Section 5.2). However, we think that it is not a good idea to promote the static query embedding to temporal one by simply concatenating the geometric embedding with the fuzzy embedding. The right way to promote remains an open question.

## Appendix D Visualization of Semantic Changes by Neural Temporal Operators

In this section, we present more visualization of the semantic changes of temporal operators in TFLEX. The examples are randomly selected in the test set of ICEWS14. The visualization is shown in Figure 10, Figure 11 and Figure 12. We attach the anchors and the ground-truth answers in the corresponding caption of figures. From the figures, we observe that the model correctly ranks the hard answers at top when answering query **Pt**. It can also be seen from the figure that the semantic changes of temporal operators **aPPt** and **bPt** are intuitive and reasonable.

\begin{table}
\begin{tabular}{l l l l l l l l l l} \hline \hline
**Dataset** & **Model** & avg\({}_{e}\) & avg\({}_{e,C_{e}}\) & avg\({}_{\mathcal{U}_{e}}\) & avg\({}_{t}\) & avg\({}_{t,\mathcal{L}_{e}}\) & avg\({}_{\mathcal{U}_{e}}\) & avg\({}_{x}\) & **AVG\({}_{e}\)** & **AVG** \\ \hline \multirow{4}{*}{ICEWS14} & ConE & 41.94 & 44.88 & 26.47 & & & & 37.76 & \\  & ConE(temporal) & 42.23 & 44.94 & 27.63 & & & & 38.27 & \\  & X(ConE) & 40.93 & 42.15 & 25.46 & 16.41 & 35.24 & 24.07 & 26.65 & 36.18 & 30.13 \\  & TFLEX & 56.79 & 50.82 & 35.74 & 17.56 & 36.37 & 26.24 & 28.03 & 47.78 & 35.93 \\ \hline \multirow{4}{*}{ICEWS05-15} & ConE & 40.93 & 43.52 & 43.02 & & & & 42.49 & \\  & ConE(temporal) & 40.74 & 43.34 & 43.14 & & & & 42.41 & \\  & X(ConE) & 36.29 & 38.12 & 36.37 & 4.41 & 29.49 & 26.40 & 21.69 & 36.93 & 27.54 \\  & TFLEX & 48.99 & 46.17 & 54.37 & 4.39 & 30.16 & 28.69 & 24.26 & 49.84 & 33.72 \\ \hline \multirow{4}{*}{GDELT-500} & ConE & 18.44 & 12.67 & 6.96 & & & & 12.69 & \\  & ConE(temporal) & 18.51 & 12.67 & 7.30 & & & & 12.83 & \\  & X(ConE) & 17.83 & 12.34 & 7.41 & 3.16 & 3.93 & 6.35 & 6.17 & 12.53 & 8.17 \\ \cline{1-1}  & TFLEX & 19.60 & 13.52 & 7.58 & 5.38 & 6.31 & 6.71 & 6.17 & 13.57 & 9.32 \\ \hline \hline \end{tabular}
\end{table}
Table 17: Average MRR results for TFLEX and the variants of ConE. \(\textbf{AVG}_{e}\) denotes average of avg\({}_{e}\), avg\({}_{e,\mathcal{C}_{e}}\) and avg\({}_{\mathcal{U}_{e}}\). **AVG** denotes average of all groups.

Figure 11: Score distributions of **Pt**, **bPt** and **aPt**, where \(s\) is **Citizen (India)**, \(r\) is **Use unconventional violence**, \(o\) is **Chief Secretary Chandra**, ground-truth answer of **Pt** is **2014-05-11**.

Figure 12: Score distributions of **Pt**, **bPt** and **aPt**, where \(s\) is **Mohammad Javad Zarif**, \(r\) is **Appeal for economic cooperation**, \(o\) is **United Arab Emirates**, ground-truth answer of **Pt** is **2014-04-14**.

Figure 10: Score distributions of **Pt**, **bPt** and **aPt**, where \(s\) is **Citizen (India)**, \(r\) is **Criticize or denounce**, \(o\) is **Sadhu (India)**, ground-truth answer of **Pt** is **2014-03-27**.

Explaining Answers with Temporal Feature-Logic Framework

In this section, we present the explanation of answers given by TFLEX. Below we take the query "**e2i**" as an example. The temporal query "**e2i**" is defined as follows: \(q[V_{j}]=V_{j},\exists V_{a},V_{b},r_{1}(e_{1},V_{a},t_{1})\wedge r_{2}(e_{2},V_{b },t_{2})\). Let's consider the specific query: "Who was consulted by Mohammad Javad Zarif on 2014-04-07 and consulted Mohammad Javad Zarif on 2014-04-07". In this example, \(e_{1}\) = "Mohammad Javad Zarif", \(r_{1}\) = "consulted by", \(t_{1}\) = "2014-04-07", \(r_{2}\) = "consulted", and \(t_{2}\) = "2014-04-07". We use TFLEX to execute the query and obtain the answers. The answers are categorized into easy, hard, and wrong ones. Table 18 presents the five most likely answers and their rankings for interpretation. From the table, we observe that TFLEX ranks the answers "Mohammad Javad Zarif", "Sebastian Kurz", "China" and "Catherine Ashton" high, while ranking the wrong answer "Iran" low. TFLEX even infers a hard answer "Catherine Ashton" with higher score than two easy answers "Sebastian Kurz" and "China". This demonstrates that TFLEX successfully identifies the correct answers using complex reasoning and distinguishes them from the wrong ones.

Figure 14: Intermediate variable assignments and ranks for example Pe query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 13: Intermediate variable assignments and ranks for example Pt query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 15: Intermediate variable assignments and ranks for example Pe2 query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 16: Intermediate variable assignments and ranks for example Pe3 query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 17: Intermediate variable assignments and ranks for example Pe_Pt query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 18: Intermediate variable assignments and ranks for example e2i query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 23: Intermediate variable assignments and ranks for example t2i query. Correctness whether the answer belongs to the ground-truth set of answers.

Figure 21: Intermediate variable assignments and ranks for example Pe_e2i query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 22: Intermediate variable assignments and ranks for example Pe_t2i query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

## Appendix A

Figure 27: Intermediate variable assignments and ranks for example Pt_oe2i query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 24: Intermediate variable assignments and ranks for example t3i query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 25: Intermediate variable assignments and ranks for example t2i_Pe query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 31: Intermediate variable assignments and ranks for example e2i_Npe query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 28: Intermediate variable assignments and ranks for example t2i_Npt query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 30: Intermediate variable assignments and ranks for example Pe_t2i_N query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 29: Intermediate variable assignments and ranks for example t2i_PtN query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 33: Intermediate variable assignments and ranks for example e2i_N query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 34: Intermediate variable assignments and ranks for example e2i_N query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 32: Intermediate variable assignments and ranks for example e2i_P8U query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 33: Intermediate variable assignments and ranks for example Pe_e2i_N query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 39: Intermediate variable assignments and ranks for example Pt_oPe query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 37: Intermediate variable assignments and ranks for example Pe_e2u query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 38: Intermediate variable assignments and ranks for example Pt_sPe query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 36: Intermediate variable assignments and ranks for example e2u query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 41: Intermediate variable assignments and ranks for example t3i_N query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 42: Intermediate variable assignments and ranks for example t2u query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 43: Intermediate variable assignments and ranks for example Pe_t2u query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 44: Intermediate variable assignments and ranks for example Pe_aPt query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 46: Intermediate variable assignments and ranks for example Pe_at2i query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

Figure 47: Intermediate variable assignments and ranks for example Pe_bti2i query. Correctness indicates whether the answer belongs to the ground-truth set of answers.

## Appendix A

Figure 48: Intermediate variable assignments and ranks for example between query. Correctness indicates whether the answer belongs to the ground-truth set of answers.