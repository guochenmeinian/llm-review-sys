# Trading off Consistency and Dimensionality of Convex Surrogates for Multiclass Classification

Enrique Nueve

Department of Computer Science

University of Colorado Boulder

enrique.nueveiv@colorado.edu

&Bo Waggoner

Department of Computer Science

University of Colorado Boulder

bwag@colorado.edu

&Dhamma Kimura

Department of Computer Science

University of Colorado Boulder

dhamma.kimpara@colorado.edu

&Jessie Finocchiaro

Department of Computer Science

Boston College

finocch@bc.edu

Most of this work was completed while author was at Harvard University CRCS

###### Abstract

In multiclass classification over \(n\) outcomes, we typically optimize some _surrogate loss_\(L:\mathbb{R}^{d}\times\mathcal{Y}\rightarrow\mathbb{R}\) assigning real-valued error to predictions in \(\mathbb{R}^{d}\). In this paradigm, outcomes must be embedded into the reals with dimension \(d\approx n\) in order to design a _consistent_ surrogate loss. Consistent losses are well-motivated theoretically, yet for large \(n\), such as in information retrieval and structured prediction tasks, their optimization may be computationally infeasible. In practice, outcomes are typically embedded into some \(\mathbb{R}^{d}\) for \(d\ll n\), with little known about their suitability for multiclass classification. We investigate two approaches for trading off consistency and dimensionality in multiclass classification while using a convex surrogate loss. We first formalize _partial consistency_ when the optimized surrogate has dimension \(d\ll n\). We then check if partial consistency holds under a given embedding and low-noise assumption, providing insight into when to use a particular embedding into \(\mathbb{R}^{d}\). Finally, we present a new method to construct (fully) consistent losses with \(d\ll n\) out of multiple problem instances. Our practical approach leverages parallelism to sidestep lower bounds on \(d\).

## 1 Introduction

Multiclass classification, due to its combinatorial and discontinuous nature, is intractable to optimize directly, which drives machine learners to optimize some nicer _surrogate loss_. To ensure these surrogates properly "correspond" to the discrete classification task, we seek to design _consistent_ surrogates. If one uses a consistent surrogate loss, in the limit of infinite data and model expressivity, one ends up with the same classifications as if one had solved the original intractable problem directly with probability \(1\).

Surrogate losses form the backbone of gradient-based optimization for classification tasks. Optimizing a surrogate is easier than direct optimization, but a large dimension \(d\) of the surrogate loss \(L:\mathbb{R}^{d}\times\mathcal{Y}\rightarrow\mathbb{R}\) can make gradient-based optimization intractable. Therefore, previous literature has operated under the premise that the prediction dimension \(d\) should be as low as possible, subject to consistency for the classification task [Ramaswamy and Agarwal, 2016, Finocchiaro et al., 2024, 2020]. For multi-class classification over \(n\) outcomes, the lower bound on \(d\) is \(n-1\)[Ramaswamy and Agarwal, 2016].

These previous works implicitly focus on a binary approach to consistency: a surrogate is either consistent for every possible label distribution, or it is not consistent. But there is a way out: lower bounds on the surrogate dimension \(d\) rely on edge-cases that rarely show up in reality (Ramaswamy and Agarwal, 2016). As a result, practitioners are often willing to trade-off the guarantee of consistency in order to improve the computational tractability of optimization. However, we currently lack rigorous analysis tools to analyze many of the partially-consistent surrogates commonly used in practice. Thus, _unlike previous works, our work focuses on this more realistic paradigm of partial consistency._ We apply our unique approach to rigorously analyze a popular surrogate construction that encompasses methods such as one-hot and binary encoding. Our approach allows for fine-grained control of the trade-off between consistency and dimension.

Prior works have informally brushed upon the proposed partial-consistency paradigm, without rigorous study. For example, Agarwal and Agarwal (2015) impose a low-noise assumption to construct a surrogate for classification with \(d=\log(n)\). However, their work does not provide any way to control the consistency-dimension trade-off. Similarly, Struminsky et al. (2018) characterize the excess risk bounds of inconsistent surrogates, which teaches us about the learning rates for inconsistent surrogates, but not _under which distributional assumptions_ we can recover consistency guarantees.

Using different techniques than both of these approaches, we seek to understand the tradeoffs of consistency, surrogate prediction dimension, and number of problem instances through the use of polytope embeddings which are common in the literature (Wainwright et al., 2008; Blondel et al., 2020). When embedding outcomes into \(d\ll n\) dimensions, we first show there always exists a set of distributions where _hallucinations_ occur: where the report minimizing the surrogate leads to a prediction \(\hat{y}\) such that the underlying true distribution has no weight on the prediction; that is, \(Pr[Y=\hat{y}]=0\) (Theorem 3). Following this, we show that every polytope embedding is partially consistent under strong enough low-noise assumptions (Theorem 5). Finally, we demonstrate through leveraging the embedding structure and multiple problem instances that the mode (in particular, a full rank ordering) over \(n\) outcomes embedded into a \(\frac{n}{2}\) dimensional surrogate space is elicitable over all distributions via \(O(n^{2})\) problem instances (Theorem 10). This alternative approach to recovering consistency is parallelizable, detangling the complexity of gradient computation of one high-dimensional surrogate.

## 2 Background and Notation

Let \(\mathcal{Y}\) be a finite label space, and throughout let \(n=|\mathcal{Y}|\). Define \(\mathbb{R}^{\mathcal{Y}}_{+}\) to be the nonnegative orthant. Let \(\Delta_{\mathcal{Y}}=\{p\in\mathbb{R}^{\mathcal{Y}}_{+}\mid\|p\|_{1}=1\}\) be the set of probability distributions on \(\mathcal{Y}\), represented as vectors. We denote the point mass distribution of an outcome \(y\in\mathcal{Y}\) by \(\delta_{y}\in\Delta_{\mathcal{Y}}\). Let \([d]:=\{1,\ldots,d\}\). In general, we denote a discrete loss by \(\ell:\mathcal{Y}\times\mathcal{Y}\rightarrow\mathbb{R}_{+}\) with outcomes denoted by \(y\in\mathcal{Y}\) and a surrogate loss by \(L:\mathbb{R}^{d}\times\mathcal{Y}\rightarrow\mathbb{R}\) with surrogate reports \(u\in\mathbb{R}^{d}\) and outcomes \(y\in\mathcal{Y}\). The surrogate must be accompanied by a link \(\psi:\mathbb{R}^{d}\rightarrow\mathcal{Y}\) mapping the convex surrogate model's predictions back into the discrete target space, and we discuss consistency of a _pair_\((L,\psi)\) with respect to the target \(\ell\).

For \(\epsilon>0\), we define an epsilon ball via \(B_{\epsilon}(u)=\{x\in\mathbb{R}^{d}\mid\|u-x\|_{2}<\epsilon\}\) and \(B_{\epsilon}:=B_{\epsilon}(\vec{0})\). Given a closed convex set \(\mathcal{C}\subset\mathbb{R}^{d}\), we define a projection operation onto \(\mathcal{C}\) via \(\text{Proj}_{\mathcal{C}}(u):=\arg\min_{x\in\mathcal{C}}\|u-x\|_{2}\). Given a closed convex set \(\mathcal{C}\subset\mathbb{R}^{d}\) and \(u\in\mathbb{R}^{d}\), we let the set-pointwise distance to be defined as \(\|u-\mathcal{C}\|_{2}:=\|u-\text{Proj}_{\mathcal{C}}(u)\|_{2}\). Full tables of notation are found in Appendix A.

### Property Elicitation, Consistency, and Prediction Dimension

Discrete label prediction requires optimization of a target loss function, \(\ell\), e.g. multi-class classification and 0-1 loss. When designing surrogate losses, consistency is the key notion of correspondence between surrogate and target loss. Intuitively, consistency implies that minimizing surrogate risk corresponds to solving the target problem. Finocchiaro et al. (2021) show that surrogate loss consistency is a necessary precursor to excess risk bounds and convergence rates.

Consistency is generally a difficult condition to work with directly. Hence, we will use the notion of _calibration_, which is equivalent to consistency in our setting with finite outcomes. Our approach follows from the property elicitation literature, which allows us to abstract away from the feature space \(\mathcal{X}\) and focus on the conditional distributions over the labels, \(p=\Pr[Y\mid X=x]\in\Delta_{\mathcal{Y}}\)[1, 2, 3, 4, 10]. In this approach, the central object of study is a _property_ which maps label distributions to reports that minimize the loss.

**Definition 1** (Property, Elicits, Level Set).: _Let \(\mathcal{R}\) be an arbitrary report set. For \(\mathcal{P}\subseteq\Delta_{\mathcal{Y}}\), a property is a set-valued function \(\Gamma:\mathcal{P}\to 2^{\mathcal{R}}\setminus\{\varnothing\}\), which we denote \(\Gamma:\mathcal{P}\rightrightarrows\mathcal{Y}\). A loss \(L:\mathcal{R}\times\mathcal{Y}\to\mathbb{R}\) elicits the property \(\Gamma\) on \(\mathcal{P}\) if_

\[\forall\;p\in\mathcal{P},\;\Gamma(p)=\operatorname*{arg\,min}_{u\in\mathcal{ R}}\mathbb{E}_{Y\sim p}[L(u,Y)]\;.\]

_If \(L\) elicits a property, it is unique and we denote it \(\operatorname{prop}[L]\). The level set of \(\Gamma\) for report \(r\) is the set \(\Gamma_{r}:=\{p\in\mathcal{P}\mid r=\Gamma(p)\}\). If \(\operatorname{prop}[L]=\Gamma\) and \(|\Gamma(p)|=1\) for all \(p\in\mathcal{P}\), we say that \(L\) is strictly proper for \(\Gamma\)._

In this work, \(\mathcal{R}=\mathcal{Y}\) for target losses and \(\mathcal{R}=\mathbb{R}^{d}\) for surrogate losses.

Once a model is optimized wrt. a surrogate \(L\), it predicts reports in the surrogate space, \(\mathbb{R}^{d}\). Then, to map surrogate reports to discrete labels, the surrogate loss must be paired with a link, \(\psi:\mathbb{R}^{d}\to\mathcal{Y}\). Intuitively, a surrogate and link pair \((L,\psi)\) are calibrated with respect to a target loss \(\ell\), if the optimal expected surrogate loss when making the _incorrect classification_ (by \(\psi\)) is strictly greater than the optimal surrogate loss.

**Definition 2** (\(\ell\)-Calibrated Loss).: _Given discrete loss \(\ell:\mathcal{Y}\times\mathcal{Y}\to\mathbb{R}_{+}\), surrogate loss \(L:\mathbb{R}^{d}\times\mathcal{Y}\to\mathbb{R}\), and link function \(\psi:\mathbb{R}^{d}\to\mathcal{Y}\). We say that \((L,\psi)\) is \(\ell\)-calibrated over \(\mathcal{P}\subseteq\Delta_{\mathcal{Y}}\) if, for all \(p\in\mathcal{P}\),_

\[\inf_{u\in\mathbb{R}^{d}:\psi(u)\notin\operatorname{prop}[\ell](p)}\mathbb{E} _{Y\sim p}[L(u,Y)]>\inf_{u\in\mathbb{R}^{d}}\mathbb{E}_{Y\sim p}[L(u,Y)]\;.\]

_If \(\mathcal{P}\) is not specified, then we are discussing calibration over \(\Delta_{\mathcal{Y}}\). In general, when \((L,\psi)\) is \(\ell\)-calibrated over \(\mathcal{P}\) such that \(\mathcal{P}\subset\Delta_{\mathcal{Y}}\), we say partial calibration holds with respect to \(\mathcal{P}\)._

Our analysis crucially relies on the ability to specify \(\mathcal{P}\) when invoking the definition of calibration. This is because the surrogates we analyze break the \(d=n-1\) lower bound on the dimension of any consistent surrogate loss. So the surrogates will not be calibrated over the whole simplex \(\Delta_{\mathcal{Y}}\). To aid in our analysis, we use a condition that shows that converging to a property value implies calibration for the target loss itself [1].

**Definition 3** (\(\ell\)-Calibrated Property).: _Let \(\mathcal{P}\subseteq\Delta_{\mathcal{Y}}\), \(\Gamma:\mathcal{P}\rightrightarrows\mathbb{R}^{d}\), discrete loss \(\ell:\mathcal{Y}\times\mathcal{Y}\to\mathbb{R}_{+}\), and \(\psi:\mathbb{R}^{d}\to\mathcal{Y}\). We will say \((\Gamma,\psi)\) is \(\ell\)-calibrated for all \(p\in\mathcal{P}\) and all sequences in \(\{u_{m}\}\) in \(\mathbb{R}^{d}\) if,_

\[u_{m}\to\Gamma(p)\Rightarrow\mathbb{E}_{Y\sim p}[\ell(\psi(u_{m}),Y)]\to \min_{r\in\mathcal{Y}}\mathbb{E}_{Y\sim p}[\ell(r,Y)]\;.\]

**Theorem 1** ([1, Theorem 3]).: _Let \(\ell:\mathcal{Y}\times\mathcal{Y}\to\mathbb{R}_{+}\) and \(\mathcal{P}\subseteq\Delta_{\mathcal{Y}}\). Let \(\Gamma:\mathcal{P}\rightrightarrows\mathbb{R}^{d}\) and \(\psi:\mathbb{R}^{d}\to\mathcal{Y}\) be such that \(\Gamma\) is elicitable and \((\Gamma,\psi)\) is an \(\ell\)-calibrated property over \(\mathcal{P}\). Let \(L:\mathbb{R}^{d}\times\mathcal{Y}\to\mathbb{R}\) be a convex function for all \(y\in\mathcal{Y}\) and strictly proper for \(\Gamma\) i.e. \(\operatorname{prop}[L]=\Gamma\) and \(|\Gamma(p)|=1\) for all \(p\in\mathcal{P}\). Then, \((L,\psi)\) is \(\ell\)-calibrated over \(\mathcal{P}\)._

Finally, we present the 0-1 loss that we analyze, which is the target loss for multiclass classification.

**Definition 4** (0-1 Loss).: _We denote the 0-1 loss by \(\ell_{0-1}:\mathcal{Y}\times\mathcal{Y}\to\{0,1\}\) such that \(\ell_{0-1}(y,\hat{y}):=\mathbbm{1}_{y\neq\hat{y}}\). Observe \(\gamma^{\operatorname{mode}}(p):=\operatorname{prop}[\ell_{0-1}](p)=\{y\in \mathcal{Y}|y\in\operatorname{arg\,max}_{y}p_{y}\}\)._

## 3 Polytope Embedding and Existence of Calibrated Regions

Often, discrete outcomes are embedded in continuous space onto the vertices of the simplex via one-hot encoding, or the vertices of the unit cube via binary encoding [10]. Generalizing, we introduce an approach to surrogate construction inspired by [10] and Blondel et al. [2] that encompasses the aforementioned embedding methods. This construction utilizes embeddings onto the vertices of arbitrary low-dimensional polytopes \(\varphi:\mathcal{Y}\to\mathbb{R}^{d}\). Then, an embedding scheme naturally induces a large class of loss functions \(L_{\varphi}^{G}\) defined by the embedding, any \(G\)-Bregman Divergence, and a link function \(\psi^{\varphi}\).

Our analysis begins by defining a condition stronger than inconsistency that arises when embedding into \(d<n-1\) dimensions for multiclass classification. To this end, we introduce the notion of _hallucination_ as a means to characterize the "worst case" behavior of a surrogate pair (SS 3.2). In a positive manner, we characterize the _calibration regions_ of various embeddings (SS 3.3), which are sets \(\mathcal{P}\subseteq\Delta_{\mathcal{Y}}\) such that our surrogate and link pair \((L^{G}_{\varphi},\psi^{\varphi})\) are \(\ell\)-calibrated over \(\mathcal{P}\). We refer the reader to the Appendix B for omitted full proofs.

### Polytope Embedding Construction

A Convex Polytope \(P\subset\mathbb{R}^{d}\), or simply a polytope, is the convex hull of a finite number of points \(u_{1},\dots,u_{n}\in\mathbb{R}^{d}\). An extreme point of a convex set \(A\), is a point \(u\in A\) such that if \(u=\lambda y+(1-\lambda)z\) with \(y,z\in A\) and \(\lambda\in[0,1]\), then \(y=u\) and/or \(z=u\). We shall denote by \(\mathrm{vert}(P)\) a polytope's set of extreme points. A polytope can be expressed by the convex hull of its extreme points, i.e. \(P=\mathrm{conv}\left(\mathrm{vert}(P)\right)\)(Bronsted, 2012, Theorem 7.2). Additional definitions pertaining to polytopes are used for proofs that are omitted to the appendix, we refer the reader to (SS B.1) for said definitions.

We propose the following embedding procedure that allows one to construct surrogate losses with almost _any_ polytope, and _any_ Bregman divergence.

**Construction 1** (Polytope Embedding).: _Given \(\mathcal{Y}\) outcomes, \(|\mathcal{Y}|=n\), choose a polytope \(P\subset\mathbb{R}^{d}\) such that \(|\mathrm{vert}(P)|=n\). Choose a bijection between \(\mathcal{Y}\) and \(\mathrm{vert}(P)\). According to this bijection, assign each vertex a unique outcome so that \(\{v_{y}\in\mathbb{R}^{d}|y\in\mathcal{Y}\}=\mathrm{vert}(P)\). Then the polytope embedding \(\varphi:\Delta_{\mathcal{Y}}\to P\) is \(\varphi(p):=\sum_{y\in\mathcal{Y}}p_{y}v_{y}\), which is the sum of \(p\)-scaled vectors_

Following the work of Blondel (2019) and their proposed Projection-based losses, we use the extremely general class of Bregman divergences (Definition 5) and a polytope embedding \(\varphi\) to define an induced loss \(L^{G}_{\varphi}\) (Definition 6).

**Definition 5** (Bregman Divergence).: _Given a strictly convex function \(G:\mathbb{R}^{d}\to\mathbb{R}\), \(D_{G}(u,v):=G(v)-[G(u)+\langle dG_{v},u-v\rangle]\) is a Bregman divergence where \(dG_{v}\) denotes a subgradient of \(G\) at \(v\). For this work, we shall always assume that \(\mathrm{dom}(G)=\mathbb{R}^{d}\)._

**Definition 6** (\((D_{G},\varphi)\) Induced Loss).: _Given a Bregman divergence \(D_{G}\) and a polytope embedding \(\varphi\), we say \((D_{G},\varphi)\) induces a loss \(L^{G}_{\varphi}:\mathbb{R}^{d}\times\mathcal{Y}\to\mathbb{R}_{+}\) defined as_

\[L^{G}_{\varphi}(u,y):=D_{G}(u,v_{y})=G(v_{y})-[G(u)+\langle dG_{v_{y}},u-v_{y} \rangle]\.\]

_Note, that for any fixed \(y\in\mathcal{Y}\), \(L^{G}_{\varphi}(u,y)\) is convex with respect to \(u\in\mathbb{R}^{d}\)._

We show that for any \(p\in\Delta_{\mathcal{Y}}\), the report that uniquely minimizes the expectation of the loss \(L^{G}_{\varphi}\) is \(\varphi(p)\), the embedding point of \(p\). Furthermore, the polytope \(P\) contains all of, and only the minimizing reports in expectation under \(L^{G}_{\varphi}\).

**Proposition 2**.: _For a given induced loss \(L^{G}_{\varphi}\), the unique report which minimizes the expected loss is \(u^{*}:=\operatorname*{arg\,min}_{u\in\mathbb{R}^{d}}\mathbb{E}_{\mathcal{Y} \sim p}[L^{G}_{\varphi}(u,Y)]=\varphi(p)\) such that \(u^{*}\in P\). Furthermore, every \(\hat{u}\in P\) is a minimizer of \(\mathbb{E}_{\mathcal{Y}\sim\hat{p}}[L^{G}_{\varphi}(u,Y)]\) for some \(\hat{p}\in\Delta_{\mathcal{Y}}\)._

We now define the maximum a posteriori (MAP) link, which will be used in conjunction with an induced loss \(L^{G}_{\varphi}\) to form a surrogate pair for the 0-1 loss. The MAP link projects surrogate predictions onto the polytope \(P\), then links to the nearest vertex of \(P\), and is commonly used in the literature (Tsochantaridis et al., 2005; Blondel, 2019; Xue et al., 2016). Since the MAP link performs a projection, one may ask if this is computationally challenging; fortunately this operation is computationally feasible due to the convexity of the polytope (Blondel, 2019).

**Definition 7** (MAP Link).: _Let \(\varphi\) be a polytope embedding from \(\Delta_{\mathcal{Y}}\) to \(P\). The MAP link \(\psi^{\varphi}:\mathbb{R}^{d}\to\mathcal{Y}\) is defined as \(\psi^{\varphi}(u)=\operatorname*{arg\,min}_{y\in\mathcal{Y}}\|\text{Proj}_{P}(u )-v_{y}\|_{2}\). The level set of the link for \(y\) is \(\psi^{\varphi}_{y}=\{u\in\mathbb{R}^{d}|y=\psi^{\varphi}(u)\}\). We break ties arbitrarily but deterministically._

### Hallucination Regions

Since our polytope embedding violates surrogate dimension bounds, calibration for 0-1 loss will not hold for all distributions. In particular, we show there always exists some distribution \(p\) such that \(p_{y}=0\) yet \(\mathbb{E}_{\mathcal{Y}\sim p}[L^{G}_{\varphi}(u,Y)]\) is minimized at some \(u\) such that \(\psi^{\varphi}(u)=y\). This implies a "worst case" inconsistency where the reported outcome could never actually occur with respect to our embedding of \(n\) events via \(\varphi\) into \(\mathrm{vert}(P)\).

**Definition 8** (Hallucination).: _Given \((L,\psi)\) such that \(L:\mathbb{R}^{d}\times\mathcal{Y}\to\mathbb{R}_{+}\), \(|\mathcal{Y}|=n\), \(d<n\), and \(\psi:\mathbb{R}^{d}\to\mathcal{Y}\), we say that a hallucination occurs at a surrogate report \(u\in\mathbb{R}^{d}\) if, for some \(p\in\Delta_{\mathcal{Y}}\), \(u\in\operatorname*{arg\,min}_{\tilde{u}\in\mathbb{R}^{d}}\mathbb{E}_{\mathcal{ Y}\sim p}[L(\tilde{u},Y)]\) and \(\psi(u):=y\) but \(p_{y}=0\). We denote by \(\mathcal{H}\subseteq P\subset\mathbb{R}^{d}\) as the hallucination region as the elements of \(P\) at which hallucinations can occur._

We express the subspace of the surrogate space where hallucinations can occur as the hallucination region denoted by \(\mathcal{H}\). In Theorem 3, we characterize the hallucination region for any polytope embedding while using the surrogate pair \((L^{G}_{\varphi},\psi^{\varphi})\) and show that \(\mathcal{H}\) is never empty.

**Theorem 3**.: _For any given pair \((L^{G}_{\varphi},\psi^{\varphi})\) and \(\ell_{0-1}\) with embedding dimension \(d<n-1\); it holds that \(\mathcal{H}=\cup_{y\in\mathcal{Y}}\mathrm{conv}\,(\mathrm{vert}(P)\setminus \{v_{y}\})\cap\psi^{\varphi}_{y}\) and furthermore \(\mathcal{H}\neq\varnothing\)._

_Sketch._ Fix \(y\in\mathcal{Y}\). We abuse notation and write \(\mathrm{vert}(P_{-y}):=\mathrm{vert}(P)\setminus\{v_{y}\}\). Observe \(\mathrm{conv}\,(\mathrm{vert}(P_{-y}))\cap\psi^{\varphi}_{y}\subseteq \mathcal{H}\) since any point in this set can be expressed as a convex combination without needing vertex \(v_{y}\) implying there is a distribution embedded by \(\varphi\) to said point which has no weight on \(y\). We seek to show that \(\mathcal{H}\subseteq\cup_{y\in\mathcal{Y}}\mathrm{conv}\,(\mathrm{vert}(P_{- y}))\cap\psi^{\varphi}_{y}\). Assume there exists a point \(u\notin\mathrm{conv}\,(\mathrm{vert}(P)\setminus v_{y})\cap\psi^{\varphi}_{y}\) such that there exists some \(p\in\Delta_{\mathcal{Y}}\) where \(\varphi(p)=u\), \(p_{y}=0\), and \(\psi^{\varphi}(u)=y\). Since \(\psi^{\varphi}(u)=y\) and \(u\notin\mathrm{conv}\,(\mathrm{vert}(P_{-y}))\cap\psi^{\varphi}_{y}\), it must be the case that \(u\notin\mathrm{conv}\,(\mathrm{vert}(P_{-y}))\). However, that implies that \(u\) is strictly in the vertex figure and thus must have weight on the coefficient for \(y\). Thus, forming a contradiction that \(p_{y}=0\) which implies that \(\mathcal{H}\subseteq\cup_{y\in\mathcal{Y}}\mathrm{conv}\,(\mathrm{vert}(P_{- y}))\cap\psi^{\varphi}_{y}\). Finally, using Helly's Theorem [14, Corollary 21.3.2] we show that \(\cap_{y\in\mathcal{Y}}\mathrm{conv}\,(\mathrm{vert}(P)\setminus v_{y})\neq\varnothing\), which implies the non-emptiness of \(\mathcal{H}\) as well. 

Theorem 3 suggests that using machine learning in high-risk settings such as medical and legal applications while violating the known \(n-1\) dimensional bound for surrogate losses in multiclass classification is inherently ill-advised without human intervention given the possibility for hallucinations. Furthermore, hallucinations may be forced by the target loss, as in the case of Hamming loss (see Appendix C). In these cases practitioners should carefully consider the choice of target loss. We conjecture that hallucinations are common for many structured prediction losses. However this is not a concern in our primary loss of study of multi-class classification.

### Calibration Regions

Ideally, we would like calibration to hold over the entire simplex since that would imply minimizing surrogate risk would always correspond to solving the target problem regardless of the true underlying

Figure 1: (Left) Mode level sets of \(\Delta_{\mathcal{Y}}\) where \(\mathcal{Y}=\{a,b,c,d\}\) embedded into a two dimensional unit cube. The center red point denotes the origin \((0,0)\) which is the hallucination region. (Right) An embedding of \(\Delta_{\mathcal{Y}}\) where \(\mathcal{Y}=\{a,b,c,d,e,f\}\) into a three-dimensional permutahedron: the beige region expresses strict calibration regions, the light pink regions expresses regions with inconsistency, and the auburn region expresses regions with hallucinations. For example, consider the report \(u=\vec{0}\). Since losses are convex, if \(p=(0,\frac{1}{2},0,0,\frac{1}{2},0)\), then \(\mathrm{conv}\,(\{b,e\})\) (dashed grey) is optimal, which includes \(u\). However, \(\vec{0}\) is also contained in \(\mathrm{conv}\,(\{a,d\})\) which is optimal for the distribution \(p^{\prime}=(\frac{1}{2},0,0,\frac{1}{2},0,0)\). Therefore, we cannot distinguish the optimal reports for a hallucination at \(\vec{0}\).

distribution. We observe that the mode's embedded level sets in the polytope overlap (see Figure 1L), which is unsurprising given that we are violating the lower bounds on surrogate prediction for the mode and hence calibration does not hold over the entire simplex. Since \(|2^{\mathcal{Y}}\setminus\{\varnothing\}|\) is a finite set, we know that the number of unique mode level sets is finite. Although every point in the polytope is a minimizing report for some distribution, if multiple distributions with non-intersecting mode sets are embedded to the same point, there is no way to define a link function that is correct in all cases. However, if the union of mode sets for the \(p\)'s mapped to any \(u\in P\) is a singleton, regardless of the underlying distribution+, a link \(\psi\) would be calibrated over the union if it mapped \(u\) to the mentioned singleton. Given \((L,\psi)\), \(\varphi\), and a target loss \(\ell\), we define strict calibrated regions as the points for which calibration holds regardless of the actual distribution realized, which are possible at said points.

Footnote †: We leave the more general case of linking \(u\) when \(\bigcap_{p\in\varphi^{-1}(u)}\gamma(p)\neq\varnothing\) to future work.

**Definition 9** (Strict Calibrated Region).: _Suppose we are given \((L,\psi)\), \(\varphi\), and a target loss \(\ell\). We say \(R\subseteq P\) is a strict calibrated region via \((L,\psi)\) with respect to \(\ell\) if \((L,\psi)\) is \(\ell\)-calibrated for all \(p\in\varphi^{-1}(R):=\{p\in\Delta_{\mathcal{Y}}:\varphi(p)\in R\}\)._

_For any \(y\in\mathcal{Y}\), we define \(R_{y}\coloneqq R\cap\psi_{y}\). We let \(R_{\mathcal{Y}}\coloneqq\cup_{y\in\mathcal{Y}}R_{y}\)._

By violating lower bounds, we are in a partially consistent paradigm where surrogate reports do not necessarily correspond to a unique distribution \(p\). However, strict calibration regions allow us to check whether or not the loss is calibrated for the distribution \(p\) generating the data -- even without explicit access to \(p\). One simply has to check whether the report \(u\) is in \(R_{\mathcal{Y}}\).

In Theorem 4, regardless of one's chosen \(P\), we show that there always exists a non-zero Lebesgue measurable strict calibration region and that \((L_{\varphi}^{G},\psi^{\varphi})\) is calibrated for the 0-1 loss overall distributions embedded into the strict calibration region. This result shows that our surrogate and link construction for _any_\(d\), always yields discernible calibration regions -- lending support to the practical use and study of these surrogates.

**Theorem 4**.: _Let \(D_{G}\) be a Bregman divergence, \(\varphi\) be any polytope embedding, \(\psi^{\varphi}\) be the MAP link, and \(L_{\varphi}^{G}\) be the loss induced by \((D_{G},\varphi)\). There exists a \(\mathcal{P}\subseteq\Delta_{\mathcal{Y}}\) with non-zero Lebesgue measure and \(\varphi(\mathcal{P})\subseteq R_{\mathcal{Y}}\) via \((L_{\varphi}^{G},\psi^{\varphi})\) with respect to \(\ell_{0-1}\)._

Although strict calibration regions \(R_{y}\) exist for each outcome \(y\in\mathcal{Y}\) via the polytope embedding, tightly characterizing strict calibration regions is non-trivial. Since the level sets of elicitable properties are convex within the underlying simplex, characterizing the strict calibration regions becomes a collision detection problem, which is often computationally hard.

## 4 Restoring Inconsistent Surrogates via Low-Noise Assumptions

Looking towards application, we refine our results on the existence of strict calibration regions by examining a low-noise assumption, which provides an interpretable calibration region (SS 4.1). We show which low-noise assumptions imply calibration when embedding \(2^{d}\) outcomes into \(d\) dimensions and \(d!\) outcomes into \(d\) dimensions (SS 4.2). We refer the reader to Appendix B for omitted proofs.

### Calibration via Low Noise Assumptions

We demonstrate that every polytope embedding leads to calibration under some low-noise assumption. Our results enable practictioners to choose the dimension \(d\), unlike in previous works. Following previous work [1], we define a low noise assumption to be a subset of the probability simplex on the label distribution parameterized by \(\hat{\alpha}\): \(\Theta_{\hat{\alpha}}=\{p\in\Delta_{\mathcal{Y}}\mid\max_{y\in\mathcal{Y}}p_{ y}\geq 1-\hat{\alpha}\}\) where \(\hat{\alpha}\in[0,1]\). This noise assumption can be understood as Massart noise [10] in the multiclass setting.

Given \(\alpha\in[0,1]\) and \(y\in\mathcal{Y}\), we define the set \(\Psi^{y}_{y}=\{(1-\alpha)\delta_{y}+\alpha\delta_{\hat{y}}\mid\hat{y}\in \mathcal{Y}\}\). With an embedding \(\varphi\) onto \(P\), we define the set \(P^{y}_{\alpha}:=\varphi(\operatorname{conv}\left(\Psi^{y}_{\alpha}\right))\), a scaled version of \(P\) anchored at \(v_{y}\), that moves vertices \((1-\alpha)\) proportionally towards \(y\), (Figure 2R).

**Theorem 5**.: _Let \(D_{G}\) be a Bregman divergence, \(\varphi\) be any polytope embedding, and \(L_{\varphi}^{G}\) be the loss induced by \((D_{G},\varphi)\). There exists an \(\alpha\in[0,.5)\) such that for the link \(\psi^{\varphi,\alpha}(u)=\operatorname*{arg\,min}_{y\in\mathcal{Y}}\|u-P^{y}_{ \alpha}\|_{2},\,(L_{\varphi}^{G},\psi^{\varphi,\alpha})\) is \(\ell_{0-1}\)-calibrated over the distributions \(\Theta_{\alpha}:=\{p\in\Delta_{\mathcal{Y}}\mid\max_{y\in\mathcal{Y}}p_{y}\geq 1- \alpha\}\)._Proof.: **Part 1 (Choosing \(\alpha\in[0,.5)\))**: By Theorem 4, there exists an \(\epsilon>0\) such that \(B_{\epsilon}(v_{y})\cap P\subseteq R_{y}\) for all \(y\in\mathcal{Y}\). Given that \(\operatorname{vert}(P)\) are unique points, there exists a sufficiently small \(\epsilon^{\prime}>0\) such that \(B_{\epsilon^{\prime}}(v)\cap B_{\epsilon^{\prime}}(\hat{v})=\varnothing\) for all \(v,\hat{v}\in\operatorname{vert}(P)\) where \(v\neq\hat{v}\). Let \(\epsilon^{\prime\prime}=\min\left(\epsilon,\epsilon^{\prime}\right)\). For any \(y\in\mathcal{Y}\), observe the set \(\operatorname{conv}\left(\Psi_{\alpha}^{y}\right)\), defined using any \(\alpha\in[0,.5)\), is a scaled-down translated unit simplex and that for all \(p\in\operatorname{conv}\left(\Psi_{\alpha}^{y}\right)\subset\Delta_{\mathcal{ Y}}\) it holds that \(y=\operatorname{mode}(p)\).

We shall show that for some sufficiently small \(\alpha\in[0,.5)\), \(P_{\alpha}^{y}\) is a scaled down version of \(P\) positioned at the respective vertex \(v_{y}\). Furthermore, we shall show that \(P_{\alpha}^{y}\subset B_{\epsilon^{\prime\prime}}(v_{y})\cap P\subseteq R_{y}\) for all \(y\in\mathcal{Y}\). Observe that by linearity of \(\varphi\),

\[P_{\alpha}^{y}:=\varphi(\operatorname{conv}\left(\Psi_{\alpha}^{y}\right))= \operatorname{conv}\left(\varphi(\{(1-\alpha)\delta_{y}+\alpha\delta_{\hat{y}} |\hat{y}\in\mathcal{Y}\})\right)=\operatorname{conv}\left(\{(1-\alpha)v_{y}+ \alpha v_{\hat{y}}|\hat{y}\in\mathcal{Y}\}\right)\]

and hence, \(P_{\alpha}^{y}\) is a scaled version of \(P\) positioned at \(v_{y}\). Hence for some sufficiently small \(\alpha\), \((1-\alpha)v_{y}+\alpha v_{\hat{y}}\in B_{\epsilon^{\prime\prime}}(v_{y})\) for all \(\hat{y}\) and hence \(P_{\alpha}^{y}\subseteq B_{\epsilon^{\prime\prime}}(v_{y})\subseteq R_{y}\). With said sufficiently small \(\alpha\), define \(\psi^{\varphi,\alpha}\) and the respective sets \(\operatorname{conv}\left(\Psi_{\alpha}^{y}\right)\) for each \(y\in\mathcal{Y}\). Using the previous \(\alpha\), define the set \(\Theta_{\alpha}\) as well.

**Part 2 (Showing Calibration)**: Recall, by Proposition 2, for any \(p\in\Delta_{\mathcal{Y}}\), \(u=\varphi(p)\) minimizes the expected surrogate loss \(\mathbb{E}_{\mathcal{Y}\sim p}[L_{\varphi}^{G}(u,Y)]\). For any fixed \(y\in\mathcal{Y}\), observe that \(\operatorname{conv}\left\{(1-\alpha)\delta_{y}+\alpha\delta_{\hat{y}}\mid \hat{y}\in\mathcal{Y}\right\}=\{p\in\Delta_{\mathcal{Y}}:p_{y}\geq 1-\alpha\} \subset\Delta_{\mathcal{Y}}\) and hence, by Proposition 2, \(\cup_{y\in\mathcal{Y}}P_{\alpha}^{y}\) contains all of the minimizing surrogate reports with respect to \(\Theta_{\alpha}\). By our choice of \(\alpha\) and the construction of \(\psi_{\alpha}^{P}\), every \(u\in\cup_{y\in\mathcal{Y}}P_{\alpha}^{y}\) is linked to the proper unique mode outcome since \(\cup_{y\in\mathcal{Y}}P_{\alpha}^{y}\subseteq R_{\mathcal{Y}}\). Assuming a low-noise condition where \(p\in\Theta_{\alpha}\), any \(u\notin\cup_{y\in\mathcal{Y}}P_{\alpha}^{y}\) is never optimal for any low-noise distribution. In such cases, we project the point to the nearest \(P_{\alpha}^{y}\) as a matter of convention. Given that calibration is a result pertaining to minimizing reports, this design choice is non-influential. Finally, since every \(\cup_{y\in\mathcal{Y}}P_{\alpha}^{y}\subseteq R_{\mathcal{Y}}\), by the definition of strict calibration region, it holds that \((L_{\varphi}^{G},\psi^{\varphi,\alpha})\) is \(\ell_{0-1}\)-calibrated for \(\Theta_{\alpha}\). 

### Embedding into the Unit Cube and Permutahedron under Low-Noise

In this section, we demonstrate embedding onto the unit cube and the permutahedron (Blondel et al., 2020; Seger, 2018). We show that by embedding \(2^{d}\) outcomes into a \(d\) dimensional unit cube \(P^{\square}\), \((L_{\varphi}^{G},\psi^{P^{\square},\alpha})\) is calibrated over \(\Theta_{\alpha}\) for all \(\alpha\in[0,\frac{1}{2})\). Furthermore, we found that by embedding \(d!\) outcomes into a \(d\) dimensional permutahedron \(P^{w}\), \((L_{\varphi}^{G},\psi^{P^{w},\alpha})\) is calibrated for \(\Theta_{\alpha}\) for \(\alpha\in[0,\frac{1}{d})\). Theorem 6 enables us to simultaneously study the aforementioned embeddings.

**Theorem 6**.: _Let \(D_{G}\) be a Bregman divergence, \(\varphi\) be any polytope embedding, and \(L_{\varphi}^{G}\) be the loss induced by \((D_{G},\varphi)\). Fix \(\alpha\in[0,.5)\) and with it define \(\Theta_{\alpha}\). If for all \(y,\hat{y}\in\mathcal{Y}\) such that \(y\neq\hat{y}\) it holds that \(P_{\alpha}^{y}\cap P_{\alpha}^{\hat{y}}=\varnothing\), then \((L_{\varphi}^{G},\psi^{\varphi,\alpha})\) is \(\ell_{0-1}\)-calibrated for \(\Theta_{\alpha}\) where \(\psi^{\varphi,\alpha}(u)=\operatorname*{arg\,min}_{y\in\mathcal{Y}}\|u-P_{ \alpha}^{y}\|_{2}\)._

Proof.: Pick an \(\alpha\) such that for all \(y,\hat{y}\in\mathcal{Y}\), \(P_{\alpha}^{y}\cap P_{\alpha}^{\hat{y}}=\varnothing\). Define \(\Theta_{\alpha}\) and \(\psi^{\varphi,\alpha}\) accordingly. For \(p\in\Theta_{\alpha}\) and some \(y\in\mathcal{Y}\), say a sequence \(\{u_{m}\}\) converges to \(\operatorname{prop}[L_{\varphi}^{G}](p)=\varphi(p)\in P_{\alpha}^{y}\), where the equality follows from Proposition 2. Given that each \(P_{\alpha}^{y}\) is closed and pairwise disjoint, there exists some \(\hat{\epsilon}>0\) such that for all \(y,\hat{y}\in\mathcal{Y}\) where \(y\neq\hat{y}\), it also holds that \((P_{\alpha}^{y}+B_{\hat{\epsilon}})\cap(P_{\alpha}^{\hat{y}}+B_{\hat{\epsilon}})=\varnothing\) where \(+\) denotes the Minkowski sum. Since \(\{u_{m}\}\) converges to \(\varphi(p)\), there exists some \(N\in\mathbb{N}\) such that for all \(n\geq N\), \(\|u_{n}-\varphi(p)\|_{2}<\hat{\epsilon}\). By the definition of \(\psi^{\varphi,\alpha}\), any \(u_{n}\) where \(n\geq N\) will be mapped to \(y\), the correct unique report given that \(\operatorname{prop}[L_{\varphi}^{G}](p)\in P_{\alpha}^{y}\). Hence, \((\operatorname{prop}[L_{\varphi}^{G}],\psi^{\varphi,\alpha})\) is \(\ell_{0-1}\)-calibrated property with respect to \(\Theta_{\alpha}\). Finally, since \(L_{\varphi}^{G}\) is strictly proper for \(\operatorname{prop}[L_{\varphi}^{G}]\), by Theorem 1, we have that \((L_{\varphi}^{G},\psi^{\varphi,\alpha})\) is \(\ell_{0-1}\)-calibrated for \(\Theta_{\alpha}\). 

Unit CubeDefine a unit cube in \(d\)-dimensions by \(P^{\square}:=\operatorname{conv}\left(\{-1,1\}^{d}\right)\). Binary encoding outcomes into the elements of \(\{-1,1\}^{d}\) (the vertices of a unit cube) is a commonly used method in practice (e.g., (Seger, 2018; Yu and Blaschko, 2018)). We show that calibration holds under a low noise assumption of \(\Theta_{\alpha}\) when \(\alpha<.5\).

**Corollary 7**.: _Let \(\varphi\) be an embedding from \(2^{d}\) outcomes into the vertices of \(P^{\square}\) in \(d\)-dimensions and define an induced loss \(L_{\varphi}^{G}\). Fix \(\alpha\in[0,.5)\) and define \(\Theta_{\alpha}\). \((L_{\varphi}^{G},\psi^{P^{\square},\alpha})\) is \(\ell_{0-1}\)-calibrated for \(\Theta_{\alpha}\)._Corollary 7 suggests that binary encoding is an appropriate methodology when one has a prior over the data that the mode of the label distribution \(\Pr[Y\mid X=x]\) is greater than half for all \(x\in\mathcal{X}\). Interestingly, the bound of \(\alpha\) is not dependent on the dimension of \(d\). We now present a result for embedding outcomes into a factorially lower dimension via the permutahedron. Intuitively, ranking can be recast as a multiclass classification problem, in which case the outcomes are orderings of the \(d\) possible labels.

PermutahedronLet \(\mathcal{S}_{d}\) express the set of permutations on \([d]\). The permutahedron associated with a vector \(w\in\mathbb{R}^{d}\) is defined to be the convex hull of the permutations of the indices of \(w\), i.e., \(P^{w}:=\operatorname{conv}\left(\{\pi(w)\mid\pi\in\mathcal{S}_{d}\}\right) \subset\mathbb{R}^{d}\). The permutahedron may serve as an embedding from \(d!\) outcomes into \(d\)-dimensions; it is a natural choice for embedding full rankings over \(d\) items.

**Corollary 8**.: _Let \(\varphi\) be an embedding from \(d!\) outcomes into the vertices of \(P^{w}\) in \(d\) dimensions such that \(w=(0,\frac{1}{\beta d},\frac{2}{\beta d},\ldots,\frac{d-1}{\beta d})\in\mathbb{ R}^{d}\) where \(\beta=\frac{d-1}{2}\). Fix \(\alpha\in[0,\frac{1}{d})\). Then \((L^{G}_{\varphi},\psi^{P^{w},\alpha})\) is \(\ell_{0-1}\)-calibrated over \(\Theta_{\alpha}\)._

The calibration region in Corollary 8 show that consistency in \(\Theta_{\alpha}\) shrinks exponentially in \(d\). Unless one has a prior that the data follows some form of a power distribution, Corollary 8 suggests not to factorially embed outcomes.

## 5 Elicitation in Low Dimensions with Multiple Problem Instances

The tools developed in previous sections now enable us to address the setting in which we require full consistency, \(\mathcal{P}=\Delta_{\mathcal{Y}}\), but also desire surrogate prediction dimension \(d\ll n-1\). We side-step the \(n-1\) lower bound by utilizing multiple problem instances and aggregation of the outputs. Although cumulatively we have a larger surrogate prediction dimension than \(n-1\), each individual problem instance has a less than \(n-1\) surrogate prediction dimension. This approach is well-motivated since it allows for distributed computing of separate, smaller models which leads to faster convergence overall since in general optimization is at least \(poly(d)\). Previous work such as Ramaswamy et al. (2014) has explored the consistency of multiclass problem reductions; however, we take a different, geometrically motivated, approach.

**Definition 10**.: _Extending Definition 1, we say a loss and link pair \((L,\psi)\), where \(L:\mathbb{R}^{d}\times\mathcal{Y}\to\mathbb{R}\) and \(\psi:\mathbb{R}^{d}\to\mathcal{Y}\), elicits a property \(\Gamma:\mathcal{P}\rightrightarrows\mathcal{Y}\) on \(\mathcal{P}\subseteq\Delta_{\mathcal{Y}}\) if \(\forall\ p\in\mathcal{P},\ \Gamma(p)=\psi(\arg\min_{u\in\mathbb{R}^{d}}\mathbb{E}_{Y\sim p}[L(u,Y)])\)._

**Definition 11** (\((n,d,m)\)-Polytope Elicitable).: _Suppose we are given a property \(\gamma:\mathcal{P}\rightrightarrows\mathcal{Y}\) such that \(\mathcal{P}\subseteq\Delta_{\mathcal{Y}}\) and \(|\mathcal{Y}|=n\) finite outcomes. Say we have \(m\) unique polytope embeddings \(\{\varphi_{j}:\Delta_{\mathcal{Y}}\to\mathbb{R}^{d}\}_{j=1}^{m}\) where \(d<n-1\), and a set of induced losses \(\{L^{G}_{\varphi_{j}}\}_{j=1}^{m}\) and links \(\psi_{j}:\mathbb{R}^{d}\to\mathcal{B}_{j}\) defined wrt. \(\varphi_{j}\), where \(\mathcal{B}_{j}\) is an arbitrary report set. For each \(j\in[m]\), assume the pair \((L^{G}_{\varphi_{j}},\psi_{j})\) elicits the property \(\Gamma_{j}:\mathcal{P}\rightrightarrows\mathcal{B}_{j}\). If there exists a function \(\Upsilon:\mathcal{B}_{1}\times\cdots\times\mathcal{B}_{m}\rightrightarrows \mathcal{Y}\) such that for any \(p\in\Delta_{\mathcal{Y}}\) it holds that \(\Upsilon(\Gamma_{1}(p),\ldots,\Gamma_{m}(p))=\gamma(p)\), we say that \(\gamma\) is \((n,d,m)\)-Polytope Elicitable over \(\mathcal{P}\)._Equivalently, we will also say that the pair \((\{(L^{G}_{\varphi_{j}},\psi_{j})\}_{j=1}^{m},\Upsilon)\)\((n,d,m)\)-Polytope elicits the property \(\gamma\) with respect to \(\mathcal{P}\).

We shall express a \(d\)-cross polytope by \(P^{\oplus}:=\operatorname{conv}\left(\{\pi((\pm 1,0,\dots,0))\mid\pi\in\mathcal{S }_{d}\}\right)\) where \((\pm 1,0,\dots,0)\in\mathbb{R}^{d}\). Observe that a \(d\)-cross polytope has \(2d\) vertices. For any vertex of a d-cross polytope \(v\in\operatorname{vert}(P^{\oplus})\), we shall say that \((v,-v)\) forms a diagonal vertex pair.

**Lemma 9**.: _Say we are given a cross-polytope embedding \(\varphi:\Delta_{2d}\to P^{\oplus}\) and induced loss \(L^{G}_{\varphi}\). Let \((v_{a_{i}},v_{b_{i}})\), be the \(i^{th}\) diagonal pair (i.e. \(\varphi(\delta_{a_{i}})=v_{a_{i}}\)). Define the property \(\Gamma^{\varphi}:\Delta_{2d}\to\mathcal{B}\) element-wise by_

\[\Gamma^{\varphi}(p)_{i}:=\left\{\begin{array}{ll}(<,a_{i},b_{i})&\text{if }p_{a_{i}}<p_{b_{i}}\\ (>,a_{i},b_{i})&\text{if }p_{a_{i}}>p_{b_{i}}\\ (=,a_{i},b_{i})&\text{if }p_{a_{i}}=p_{b_{i}}.\end{array}\right.\]

_Furthermore define the link \(\psi^{P^{\oplus}}:\mathbb{R}^{d}\to\mathcal{B}\) with respect to each diagonal pair as_

\[\psi(u;v_{a_{i}},v_{b_{i}})_{i}^{P^{\oplus}}:=\left\{\begin{array}{ll}(<,a_{ i},b_{i})&\text{if }||u-v_{a_{i}}||_{2}>||u-v_{b_{i}}||_{2}\\ (>,a_{i},b_{i})&\text{if }||u-v_{a_{i}}||_{2}<||u-v_{b_{i}}||_{2}\\ (=,a_{i},b_{i})&\text{o.w.}\end{array}\right.\]

_Then \((L^{G}_{\varphi},\psi^{P^{\oplus}})\) elicits \(\Gamma^{\varphi}\)._

The following theorem states that by using multiple problem instances, based on Lemma 9, we can Polytope-elicit the mode. Algorithm 1 outlines how to aggregate the individual solutions to infer the mode. We defer the proof to Appendix B.

**Theorem 10**.: _Let \(d\geq 2\). The mode is \((2d,d,m)\)-Polytope Elictable for some \(m\in[2d-1,d(2d-1)]\)._

**Require:**: \(M=\{(L^{G}_{\varphi_{j}},\psi^{P^{\oplus}}_{j})\}_{j=1}^{m}\)

Learn a model \(h_{j}:\mathcal{X}\to\mathbb{R}^{d}\) for each instance \((L^{G}_{\varphi_{j}},\psi^{P^{\oplus}}_{j})\in M\)

For some fixed \(x\in\mathcal{X}\), collect all \(B_{j}\leftarrow\psi^{P^{\oplus}}_{j}(h_{j}(x))\) where \(B_{j}\in\mathcal{B}_{j}\)

Report \(R\leftarrow\text{FindMaxes}^{\dagger}(B_{1},\dots,B_{m})\)

**Algorithm 1** Elicit mode via comparisons and the \(d\)-Cross Polytopes

Although Theorem 10 states that the mode is \((2d,d,m)\)-Polytope Elictable for some \(m\in[2d-1,d(2d-1)]\), it does not state how we select said \(\{(L^{G}_{\varphi_{j}},\psi^{P^{\oplus}}_{j})\}_{j=1}^{m}\) problem instances in an optimal manner. Unfortunately, selecting the min number of problem instances reduces to a a minimum set cover problem which is computationally hard. Even so, through a greedy approach, one can choose

Figure 3: Four outcomes embedded in \(\mathbb{R}^{2}\) in two different ways, with the minimizing reports \(\bullet\) for a distribution \(p\).” (Left) Configuration \(\varphi_{1}\) with \(\bullet\) at \((-.5,.3)\) implying \(p_{a}>p_{d}\) and \(p_{b}>p_{c}\). (Right) Configuration \(\varphi_{2}\) with \(\bullet\) at \((0,0)\) implying \(p_{a}=p_{b}\) and \(p_{c}=p_{d}\). This implies the true distribution is \(p=(0.4,0.4,0.1,0.1)\).”

problem instances that are log approximate optimal relative to the true best configuration. In practice using real data, given that these are asymptotic results, we may have conflicting logic for the provided individual reports. In Appendix D, we discuss an approach of how to address this in practice.

## 6 Discussion and Conclusion

This work examines various tradeoffs between surrogate loss dimension, restricting the region of consistency in the simplex when using the 0-1 loss, and number of problem instances. Since our analysis is based on an embedding approach commonly used in practice, our work provides theoretical guidance for practitioners choosing an embedding. We see several possible future directions. The first is a deeper investigation into hallucinations. Future work could investigate the size of the hallucination region in theory, and the frequency of reports in the hallucination region in practice. Another direction would be to construct a method that efficiently identifies the strict calibration regions and the distributions embedded into them. This would provide better guidance on whether or not a particular polytope embedding aligns with one's prior over the data. Another possible direction would be to explore whether concepts from this paper could be applied to the underlying problem of cost-sensitive multiclass classification. Finally, another direction is to identify other properties that can be elicited via multiple problem instances while also reducing the dimension of any one instance.

**Broader Impacts:** Our work broadly informs the selection of loss functions for machine learning. Thus our work may influence practitioners' choice of loss function. Of course, such loss functions can be used for ethical or unethical purposes. We do not know of particular risks of negative impacts of this work beyond risks of machine learning in general.

## Acknowledgments and Disclosure of Funding

We thank Rafael Frongillo for discussions about hallucinations, which led to the exploration of many of the ideas in this work and Amzi Jeffs for discussions regarding convex geometry. This material is based upon work supported by the National Science Foundation under Award No. 2202898 (JF).

## References

* Agarwal and Agarwal (2015) Arpit Agarwal and Shivani Agarwal. On consistent surrogate risk minimization and property elicitation. In _Conference on Learning Theory_, pages 4-22. PMLR, 2015.
* Banerjee et al. (2005) Arindam Banerjee, Xin Guo, and Hui Wang. On the optimality of conditional expectation as a bregman predictor. _IEEE Transactions on Information Theory_, 51(7):2664-2669, 2005.
* Bartlett et al. (2006) Peter L Bartlett, Michael I Jordan, and Jon D McAuliffe. Convexity, classification, and risk bounds. _Journal of the American Statistical Association_, 101(473):138-156, 2006.
* Blondel (2019) Mathieu Blondel. Structured prediction with projection oracles. _Advances in neural information processing systems_, 32, 2019.
* Blondel et al. (2020) Mathieu Blondel, Andre FT Martins, and Vlad Niculae. Learning with fenchel-young losses. _The Journal of Machine Learning Research_, 21(1):1314-1382, 2020.
* Brondsted (2012) Arne Brondsted. _An introduction to convex polytopes_, volume 90. Springer Science & Business Media, 2012.
* Finocchiaro et al. (2020) Jessie Finocchiaro, Rafael Frongillo, and Bo Waggoner. Embedding dimension of polyhedral losses. In _Conference on Learning Theory_, pages 1558-1585. PMLR, 2020.
* Finocchiaro et al. (2021) Jessie Finocchiaro, Rafael Frongillo, and Bo Waggoner. Unifying lower bounds on prediction dimension of consistent convex surrogates. _arXiv preprint arXiv:2102.08218_, 2021.
* Finocchiaro et al. (2024) Jessie Finocchiaro, Rafael M Frongillo, and Bo Waggoner. An embedding framework for the design and analysis of consistent polyhedral surrogates. _Journal of Machine Learning Research_, 25(63):1-60, 2024.
* Gruber (2007) Peter M Gruber. _Convex and discrete geometry_, volume 336. Springer, 2007.
* Hiriart-Urruty and Lemarechal (2004) Jean-Baptiste Hiriart-Urruty and Claude Lemarechal. _Fundamentals of convex analysis_. Springer Science & Business Media, 2004.
* Massart and Nedelec (2006) Pascal Massart and Elodie Nedelec. Risk bounds for statistical learning. 2006.
* Ramaswamy and Agarwal (2016) Harish G Ramaswamy and Shivani Agarwal. Convex calibration dimension for multiclass loss matrices. _The Journal of Machine Learning Research_, 17(1):397-441, 2016.
* Ramaswamy et al. (2014) Harish G Ramaswamy, Balaji Srinivasan Babu, Shivani Agarwal, and Robert C Williamson. On the consistency of output code based learning algorithms for multiclass learning problems. In _Conference on Learning Theory_, pages 885-902. PMLR, 2014.
* Rockafellar (1997) R Tyrrell Rockafellar. _Convex analysis_, volume 11. Princeton university press, 1997.
* Seger (2018) Cedric Seger. An investigation of categorical variable encoding techniques in machine learning: binary versus one-hot and feature hashing, 2018.
* Steinwart (2007) Ingo Steinwart. How to compare different loss functions and their risks. _Constructive Approximation_, 26(2):225-287, 2007.
* Struminsky et al. (2018) Kirill Struminsky, Simon Lacoste-Julien, and Anton Osokin. Quantifying learning guarantees for convex but inconsistent surrogates. _Advances in Neural Information Processing Systems_, 31, 2018.
* Tewari and Bartlett (2007) Ambuj Tewari and Peter L Bartlett. On the consistency of multiclass classification methods. _Journal of Machine Learning Research_, 8(5), 2007.
* Tsochantaridis et al. (2005) Ioannis Tsochantaridis, Thorsten Joachims, Thomas Hofmann, Yasemin Altun, and Yoram Singer. Large margin methods for structured and interdependent output variables. _Journal of machine learning research_, 6(9), 2005.
* Wainwright et al. (2008) Martin J Wainwright, Michael I Jordan, et al. Graphical models, exponential families, and variational inference. _Foundations and Trends(r) in Machine Learning_, 1(1-2):1-305, 2008.
* Wainwright et al. (2018)Yexiang Xue, Zhiyuan Li, Stefano Ermon, Carla P Gomes, and Bart Selman. Solving marginal map problems with np oracles and parity constraints. _Advances in Neural Information Processing Systems_, 29, 2016.
* Yu and Blaschko (2018) Jiaqian Yu and Matthew B Blaschko. The lovasz hinge: A novel convex surrogate for submodular losses. _IEEE transactions on pattern analysis and machine intelligence_, 42(3):735-748, 2018.
* Zhang (2004) Tong Zhang. Statistical analysis of some multi-category large margin classification methods. _Journal of Machine Learning Research_, 5(Oct):1225-1251, 2004.

[MISSING_PAGE_EMPTY:13]

Polytopes, Omitted Proofs, and Results

### Polytopes

A Convex Polytope \(P\subset\mathbb{R}^{d}\), or simply a polytope, is the convex hull of a finite number of points \(u_{1},\ldots,u_{n}\in\mathbb{R}^{d}\). An extreme point of a convex set \(A\), is a point \(u\in A\) such that if \(u=\lambda y+(1-\lambda)z\) with \(y,z\in A\) and \(\lambda\in[0,1]\), then \(y=u\) and/or \(z=u\). We shall denote by \(\operatorname{vert}(P)\) a polytope's set of extreme points. A polytope can be expressed by the convex hull of its extreme points, i.e. \(P=\operatorname{conv}\left(\operatorname{vert}(P)\right)\)[Brondsted, 2012, Theorem 7.2].

We define the dimension of \(P\) via \(\dim(P):=\dim(\operatorname{affhull}(P))\) where \(\operatorname{affhull}(P)\) denotes the smallest affine set containing \(P\). A set \(F\subseteq P\) is a face of \(P\) is there exists a hyperplane \(H(y,\alpha):=\{u\in\mathbb{R}^{d}\mid\langle u,y\rangle=\alpha\}\) such that \(F=P\cap H\) and \(P\subseteq H^{+}\) such that \(H^{+}(y,\alpha):=\{u\in\mathbb{R}^{d}\mid\langle u,y\rangle\leq\alpha\}\). Let \(F_{i}(P)\) where \(i\in[d-1]\) denote set of faces of dim \(i\) of a polytope \(P\). A face of dimension zero is called a vertex and a face of dimension one is called an edge. We define the edge set of a polytope \(P\) by \(E(P):=\{\operatorname{conv}\left((v_{i},v_{j})\right)\mid(v_{i},v_{j})\subseteq \binom{\operatorname{vert}(P)}{2},\operatorname{conv}\left((v_{i},v_{j}) \right)\in F_{1}(P)\}\). We define the neighbors of a vertex \(v\) by \(\operatorname{ne}(v;P):=\{\hat{v}\in\operatorname{vert}(P)\mid\ \operatorname{conv}\left((v,\hat{v})\right)\in E(P)\}\). We will denote \(\operatorname{conv}\left((v,\hat{v})\right)\in E(P)\) by as \(e_{v,\hat{v}}\) and \(\operatorname{ne}(v;P)\) by \(\operatorname{ne}(v)\) when clear from context.

### Omitted Proofs from SS 3

Proposition 2.: _For a given induced loss \(L^{G}_{\varphi}\), the unique report which minimizes the expected loss is \(u^{*}:=\operatorname{arg\,min}_{u\in\mathbb{R}^{d}}\mathbb{E}_{Y\sim p}[L^{G} _{\varphi}(u,Y)]=\varphi(p)\) such that \(u^{*}\in P\). Furthermore, every \(\hat{u}\in P\) is a minimizer of \(\mathbb{E}_{Y\sim\hat{p}}[L^{G}_{\varphi}(u,Y)]\) for some \(\hat{p}\in\Delta_{\mathcal{Y}}\)._

Proof.: By [Banerjee et al., 2005, Theorem 1], the minimizer of \(\mathbb{E}_{Y\sim p}[L^{G}_{\varphi}(u,Y)]\) is \(\sum_{y\in\mathcal{Y}}p_{y}v_{y}=\varphi(p)\). Thus, by the construction of the polytope embedding, it holds that \(u^{*}=\varphi(p)\). Since Bregman divergences are defined with respect to strictly convex functions, \(u^{*}\) uniquely minimizes \(\mathbb{E}_{Y\sim p}[L^{G}_{\varphi}(u,Y)]\).

Conversely, every \(\hat{u}\in P\) is expressible as a convex combination of vertices; hence, by the definition of \(\varphi\), for some distribution, say \(\hat{p}\in\Delta_{\mathcal{Y}}\), it holds \(\hat{u}=\varphi(\hat{p})\). Therefore, it holds that \(\hat{u}\) minimizes \(\mathbb{E}_{Y\sim\hat{p}}[L^{G}_{\varphi}(u,Y)]\). 

Theorem 3.: _For any given pair \((L^{G}_{\varphi},\psi^{\varphi})\) and \(\ell_{0-1}\) with embedding dimension \(d<n-1\); it holds that \(\mathcal{H}=\cup_{y\in\mathcal{Y}}\operatorname{conv}\left(\operatorname{vert} (P)\setminus\{v_{y}\}\right)\cap\psi^{\varphi}_{y}\) and furthermore \(\mathcal{H}\neq\varnothing\)._

Proof.: Choose a \(y\in\mathcal{Y}\). We abuse notation and write \(\operatorname{vert}(P)\setminus v_{y}:=\operatorname{vert}(P)\setminus\{v_{ y}\}\). Observe all \(u\in\operatorname{conv}\left(\operatorname{vert}(P)\setminus v_{y}\right)\cap \psi^{\varphi}_{y}\) can be expressed as a convex combination of vertices without needing vertex \(v_{y}\). The coefficients of said convex combination express a \(p\in\Delta_{\mathcal{Y}}\) that is embedded to the point \(u\in P\) where \(p_{y}=0\). Yet, by Proposition 2, said \(u\) is an expected minimizer of \(L^{G}_{\varphi}\) with respect to \(p\). Given the intersection with \(\psi^{\varphi}_{y}\) and by Definition 8, it holds that \(\cup_{y\in\mathcal{Y}}\operatorname{conv}\left(\operatorname{vert}(P)\setminus v _{y}\right)\cap\psi^{\varphi}_{y}\subseteq\mathcal{H}\).

We now shall show that \(\mathcal{H}\subseteq\cup_{y\in\mathcal{Y}}\operatorname{conv}\left( \operatorname{vert}(P)\setminus v_{y}\right)\cap\psi^{\varphi}_{y}\). Fix \(y\in\mathcal{Y}\). Assume there exists a point \(u\notin\operatorname{conv}\left(\operatorname{vert}(P)\setminus v_{y}\right) \cap\psi^{\varphi}_{y}\) such that there exists some \(p\in\Delta_{\mathcal{Y}}\) where \(\varphi(p)=u\), \(p_{y}=0\), and \(\psi^{\varphi}(u)=y\). Since \(\psi^{\varphi}(u)=y\) and \(u\notin\operatorname{conv}\left(\operatorname{vert}(P)\setminus v_{y}\right) \cap\psi^{\varphi}_{y}\), it must be the case that \(u\notin\operatorname{conv}\left(\operatorname{vert}(P)\setminus v_{y}\right)\). However, that implies that \(u\) is strictly in the vertex figure and thus must have weight on the coefficient for \(y\). Thus, forming a contradiction that \(p_{y}=0\) which implies that \(\mathcal{H}=\cup_{y\in\mathcal{Y}}\operatorname{conv}\left(\operatorname{vert} (P)\setminus v_{y}\right)\cap\psi^{\varphi}_{y}\).

To show non-emptiness of \(\mathcal{H}\), we shall use Helly's Theorem (Rockafellar [1997], Corollary 21.3.2). W.l.o.g, assign an index such that \(\mathcal{Y}=\{y_{1},\ldots,y_{d},y_{d+1},\ldots,y_{n}\}\). Observe the elements of the set \(\{\mathcal{Y}\setminus y_{i}\}_{i=1}^{n}\) each differ by one element. W.l.o.g, pick the first \(d+1\) elements of the previous set. Observe \(|\cap_{i=1}^{d+1}\mathcal{Y}\setminus y_{i}|=|\mathcal{Y}\setminus\{y_{1}, \ldots,y_{d},y_{d+1}\}|=n-(d+1)>0\). Hence, by Helly's theorem and uniqueness of \(y_{i}\)'s, \(\cap_{y\in\mathcal{Y}}\operatorname{conv}\left(\operatorname{vert}(P)\setminus v _{y}\right)\neq\varnothing\).

Pick a point \(u^{\prime}\in\cap_{y\in\mathcal{Y}}\operatorname{conv}\left(\operatorname{vert} (P)\setminus v_{y}\right)\). Since \(\psi^{\varphi}\) is well-defined, \(u^{\prime}\) will be linked to some outcome \(y^{\prime}\in\mathcal{Y}\) and thus \(u^{\prime}\in\operatorname{conv}\left(\operatorname{vert}(P)\setminus v_{y^{ \prime}}\right)\cap\psi^{\varphi}_{y^{\prime}}\subset\mathcal{H}\). Yet, \(u^{\prime}\) can be expressed as a convex combination which does not use \(v_{y^{\prime}}\) since it lies in \(\cap_{y\in\mathcal{Y}}\mathrm{conv}\left(\mathrm{vert}(P)\setminus v_{y}\right)\). Thus, by using Proposition 2 and by the definition of Hallucination (Def. 8), we have that \(\mathcal{H}\neq\varnothing\). 

**Lemma 1** (Proposition 1.2.4).: _[Hiriart-Urruty and Lemarechal, 2004] If \(\varphi\) is an affine transformation of \(\mathbb{R}^{n}\) and \(A\subset\mathbb{R}^{n}\) is convex, then then the image \(\varphi(A)\) is also convex. In particular, if the set \(A\) is a convex polytope, the image is also a convex polytope._

**Lemma 2**.: _Let \(D_{G}\) be a Bregman divergence, \(\varphi\) be any polytope embedding, \(\psi\) be the MAP link, and \(L_{\varphi}^{G}\) be the loss induced by \((D_{G},\varphi)\). Assume the target loss is \(\ell_{0-1}\). If a point is in a strict calibrated region such that \(u\in R_{y}\) for some \(y\in\mathcal{Y}\), it is necessary that \(u\in\mathrm{conv}\left(\{v_{y}\}\cup\mathrm{ne}(v_{y})\right)\setminus \mathrm{conv}\left(\mathrm{ne}(v_{y})\right)\)._

Proof.: If \(u\in R_{y}\) and \(u\in P\setminus\left(\mathrm{conv}\left(\{v_{y}\}\cup\mathrm{ne}(v_{y}) \right)\setminus\mathrm{conv}\left(\mathrm{ne}(v_{y})\right)\right)\), then \(u\) can be expressed as a convex combination which has no weight on the coefficient for \(v_{y}\). Hence, there exists a distribution embedded into \(u\) where \(y\) would not be the mode, thus violating the initial claim that \(u\in R_{y}\). 

**Lemma 3**.: _Let \(D_{G}\) be a Bregman divergence, \(\varphi\) be any polytope embedding, \(\psi\) be the MAP link, and \(L_{\varphi}^{G}\) be the loss induced by \((D_{G},\varphi)\). For any \(u\in e_{(v_{i},v_{j})}\in E(P)\), it holds that \(|\varphi^{-1}(u)|=1\)._

Proof.: Observe, the two vertices of an edge define the convex hull making up the edge and hence, by (Gruber [2007],Theorem 2.3) the two vertices are affinely independent. Therefore, all elements of the edge have a unique convex combination which are expressed by the convex combinations of the edge's vertices. Given the relation of the embedding \(\varphi\) and convex combinations of vertices expressing distributions, it holds that \(|\varphi^{-1}(u)|=1\). 

**Lemma 4**.: _Let \(D_{G}\) be a bregman divergence, \(\varphi\) be a polytope embedding, and \(L_{\varphi}^{G}\) be the induced loss by \((D_{G},\varphi)\). For all \(y\in\mathcal{Y}\), it holds that \(\dim(\varphi(\text{mode}_{y}))=\dim(P)\geq 2\)._

Proof.: By the construction of \(\varphi\), we know that \(\dim(P)\geq 2\). Fix \(y\in\mathcal{Y}\). By Lemma 3, we know that any edge connected from \(v_{y}\) and \(\hat{v}\in\mathrm{ne}(v_{y})\), the distributions embedded into the half of the line segment closer to \(v_{y}\), \(y\) is in the mode. By Lemma 1, we know that \(\varphi(\gamma_{y}^{\mathrm{mode}})\) is a convex set. Thus, the convex hull of the half line segments is part of \(\varphi(\gamma_{y}^{\mathrm{mode}})\). Since each vertex has at least \(\dim(P)\) neighbors, it holds that \(\dim(\varphi(\gamma_{y}^{\mathrm{mode}}))=\dim(P)\). 

**Theorem 4**.: _Let \(D_{G}\) be a Bregman divergence, \(\varphi\) be any polytope embedding, \(\psi^{\varphi}\) be the MAP link, and \(L_{\varphi}^{G}\) be the loss induced by \((D_{G},\varphi)\). There exists a \(\mathcal{P}\subseteq\Delta_{\mathcal{Y}}\) with non-zero Lebesgue measure and \(\varphi(\mathcal{P})\subseteq R_{\mathcal{Y}}\) via \((L_{\varphi}^{G},\psi^{\varphi})\) with respect to \(\ell_{0-1}\)._

Proof.: Recall that \(\gamma^{\mathrm{mode}}(p):=\mathrm{prop}[\ell_{0-1}](p)=\mathrm{mode}(p)\). Fix \(y\in\mathcal{Y}\). For contradiction, assume for any \(\hat{y}\in\mathcal{Y}\) where \(y\neq\hat{y}\), it holds that \(B_{\epsilon}(v_{y})\cap\varphi(\gamma_{y}^{\mathrm{mode}})\neq\varnothing\) for all \(\epsilon>0\). By Lemma 3, it holds that \(\mathrm{conv}\left(\{v_{y}\}\cup m_{v_{y},\alpha}\right)\subseteq\varphi(\gamma_ {y}^{\mathrm{mode}})\) where \(m_{v_{y},\alpha}:=\{(1-\alpha)v_{y}+\alpha\bar{v}\mid\bar{v}\in\mathrm{ne}(v_{y})\}\) defined by any \(\alpha\in(0,.5)\). Furthermore, the elements of \(\cup_{m\in m_{v_{y},\alpha}}\mathrm{conv}\left(\{v_{y}\}\cup\{m\}\right)\) have one distribution embedded onto it where \(y\) is the only valid mode thus, we know that \(\varphi(\mathrm{mode}_{\hat{y}})\cap\cup_{m\in m_{v_{y},\alpha}}\mathrm{conv} \left(\{v_{y}\}\cup\{m\}\right)=\varnothing\). Since \(\varphi(\gamma_{\hat{y}}^{\mathrm{mode}})\subset P\) is closed and convex, there must exist some non-negative min distance between \(\varphi(\gamma_{\hat{y}}^{\mathrm{mode}})\) and \(v_{y}\) which we shall denote by \(d_{v}\). For any \(\epsilon\in(0,d_{v_{y}})\), we can define \(B_{\epsilon}(v_{y})\) such that \(B_{\epsilon}(v_{y})\cap\varphi(\gamma_{\hat{y}}^{\mathrm{mode}})=\varnothing\), forming a contradiction.

For each \(v_{y}\in\mathrm{vert}(P)\) define a \(d_{v_{y}}\) and let \(\epsilon^{\prime}\in\cap_{v_{y}\in\mathrm{vert}(P)}(0,d_{v_{y}})\). By the construction of \(P\) and the definition of \(\psi^{\varphi}\), there exists a \(\epsilon^{\prime\prime}>0\) such that for all \(u\in B_{\epsilon^{\prime\prime}}(v_{y})\) it holds that \(\psi(u)=y\) and \(B_{\epsilon^{\prime\prime}}(v_{y})\subset\psi_{y}^{\varphi}\). For any \(y\in\mathcal{Y}\), we know that \(B_{\min\{\epsilon^{\prime},\epsilon^{\prime\prime}\}}(v_{y}))\cap P\subseteq R_{y}\) by the construction of our epsilon ball. We claim \(\varphi^{-1}(B_{\min\{\epsilon^{\prime},\epsilon^{\prime\prime}\}}(v_{y})\cap P)\) is a set of distributions for which calibration holds.

For \(p\in\Delta_{\mathcal{Y}}\) such that \(\varphi(p)\in B_{\min\{\epsilon^{\prime},\epsilon^{\prime\prime}\}}(v_{y})\cap P\) for some \(v_{y}\in\mathrm{vert}(P)\), suppose a sequence \(\{u_{m}\}\) converges to \(\mathrm{prop}[L_{\varphi}^{G}](p)=\varphi(p)\) (equality by Proposition 2). By construction of \(B_{\min\{\epsilon^{\prime},\epsilon^{\prime\prime}\}}(v_{y})\cap P\), \(\psi^{\varphi}(\varphi(p))=y\in\mathrm{mode}(p)\) and hence, a minimizing report for \(\ell_{0-1}(y;p)\). Furthermore, since \(B_{\min\{\epsilon^{\prime},\epsilon^{\prime\prime}\}}(v_{y})\subset\psi_{\varphi^{- 1}(v_{y})}^{\varphi}\), all elements within \(B_{\min\{\epsilon^{\prime},\epsilon^{\prime\prime}\}}(v_{y})\) link to \(y\). Since \(\{u_{m}\}\) converges to \(\mathrm{prop}[L_{\varphi}^{G}](p)\), there exists some \(N\in\mathbb{N}\) and \(n\geq N\), such that \(\min\{\epsilon^{\prime},\epsilon^{\prime\prime}\}\), meaning that \(\mathbb{E}_{\mathcal{Y}\sim p}[\ell_{0-1}(\psi^{\sigma}(u_{m}),Y)]\rightarrow\min_ {y\in\mathcal{Y}}\mathbb{E}_{\mathcal{Y}\sim p}[\ell_{0-1}(y,Y)]\). Hence, for any \(v_{y}\in\mathrm{vert}(P)\), \((\mathrm{prop}[L_{\varphi}^{\sigma}],\psi^{\sigma})\) is \(\ell_{0-1}\)-calibrated property with respect to \(\varphi^{-1}(B_{\min\{\epsilon^{\prime},\epsilon^{\prime\prime}\}}(v_{y}) \cap P)\). Furthermore, by the construction of \(B_{\min\epsilon^{\prime},\epsilon^{\prime\prime}}(v_{y})\) for each \(v_{y}\in\mathrm{vert}(P)\), we have that \(L_{\varphi}^{G}\) is strictly for \(\mathrm{prop}[L_{\varphi}^{G}]\). Thus, by Theorem 1, \((L_{\varphi}^{G},\psi^{\sigma})\) is \(\ell_{0-1}\)-calibrated for at least the distributions \(\mathcal{P}=\cup_{v_{y}\in\mathrm{vert}(P)}\varphi^{-1}(B_{\min\{\epsilon^{ \prime},\epsilon^{\prime\prime}\}}(v_{y})\cap P)\) as well as \(\varphi(\mathcal{P})\subseteq R_{\mathcal{Y}}\). Furthermore, since \(B_{\min\{\epsilon^{\prime},\epsilon^{\prime\prime}\}}\) for each \(v_{y}\in\mathrm{vert}(P)\) is non-empty, we have that \(\mathcal{P}\neq\varnothing\). 

### Omitted Proofs from SS 4

**Corollary 7**.: _Let \(\varphi\) be an embedding from \(2^{d}\) outcomes into the vertices of \(P^{\square}\) in \(d\)-dimensions and define an induced loss \(L_{\varphi}^{G}\). Fix \(\alpha\in[0,.5)\) and define \(\Theta_{\alpha}\). \((L_{\varphi}^{G},\psi^{P^{\square},\alpha})\) is \(\ell_{0-1}\)-calibrated for \(\Theta_{\alpha}\)._

Proof.: W.l.o.g, say the outcome \(y_{1}\in\mathcal{Y}\) is embedded into \(\mathbbm{1}_{[d]}\in\mathrm{vert}(P^{\square})\). Say \(\alpha=.5\). Observe that

\[\Psi_{\alpha}^{y_{1}}=\left\{\begin{pmatrix}1\\ 0\\ \vdots\\ 0\\ 0\end{pmatrix},\begin{pmatrix}1-\alpha\\ \alpha\\ \vdots\\ 0\\ \end{pmatrix},\begin{pmatrix}1-\alpha\\ 0\\ \vdots\\ 0\\ \end{pmatrix},\dots,\begin{pmatrix}1-\alpha\\ 0\\ \vdots\\ \alpha\\ 0\end{pmatrix},\begin{pmatrix}1-\alpha\\ 0\\ \vdots\\ 0\\ \end{pmatrix}\right\}\]

and that \(1\geq(1-\alpha)\pm\alpha\geq 0\) for any \(\alpha\in(0,.5)\). Hence, for any \(\alpha\in(0,.5)\) it holds that \(P_{0.5}^{y_{1}}=\mathrm{conv}\left(\{0,1\}^{d}\right)\) and furthermore \(P_{\alpha}^{y_{1}}\subset P_{0.5}^{y_{1}}\subset\mathbb{R}_{>0}^{d}\). By symmetry of \(P^{\square}\) and the linearity of \(\varphi\), for any \(\alpha\in(0,.5)\) and \(y\in\mathcal{Y}\), we have that \(P_{\alpha}^{y}\) is a strict subset of the orthant that contains \(v_{y}\). Hence, for all \(y,\hat{y}\in\mathcal{Y}\) such that \(y\neq\hat{y}\), it holds that \(P_{\alpha}^{y}\cap P_{\alpha}^{\hat{y}}=\varnothing\). Thus by Theorem 6, \((L_{\varphi}^{G},\psi^{P^{\square},\alpha})\) is \(\ell_{0-1}\)-calibrated for \(\Theta_{\alpha}\) where \(\alpha\in(0,.5)\). 

**Corollary 8**.: _Let \(\varphi\) be an embedding from \(d!\) outcomes into the vertices of \(P^{w}\) in \(d\) dimensions such that \(w=(0,\frac{1}{\beta d},\frac{2}{\beta d},\dots,\frac{d-1}{\beta d})\in\mathbb{ R}^{d}\) where \(\beta=\frac{d-1}{2}\). Fix \(\alpha\in[0,\frac{1}{d})\). Then \((L_{\varphi}^{G},\psi^{P^{w},\alpha})\) is \(\ell_{0-1}\)-calibrated over \(\Theta_{\alpha}\)._

Proof.: Let \(\Delta_{d}:=\mathrm{conv}\left(\{\mathbbm{1}_{i}\in\mathbb{R}^{d}\mid i\in[d] \right)\right)\) and observe \(P^{w}\subset\Delta_{d}\) since for all \(\pi\), \(\|\pi\cdot w\|_{1}=\|w\|_{1}=1\). Observe that \(P^{w}\) can be symmetrically partitioned into \(d!\) regions with disjoint interiors, one for each permutation \(\pi\in\mathcal{S}_{d}\) via \(\Delta_{d}^{\pi}:=\{u\in\Delta_{d}\mid u_{1}\leq\dots\leq u_{d}\}\). Fix \(\pi\in\mathcal{S}_{d}\) and w.l.o.g assume \(\pi\) is associated with the constraints \(\Delta_{w}^{\pi}:=\{u\in\Delta_{w}\mid u_{1}\leq\dots\leq u_{d}\}\) implying that \(\pi(w)=(\frac{0}{\beta d},\frac{1}{\beta d},\dots,\frac{d-1}{\beta d})\). Let \(\alpha=\frac{1}{d}\) and define \(\Theta_{\alpha}\). With respect to \(\Theta_{\alpha}\), let \(y:=\varphi^{-1}(\pi(w))\in\mathcal{Y}\) and \(\hat{y}:=\varphi^{-1}(\hat{\pi}(w))\in\mathcal{Y}\) such that \(\hat{\pi}\in\mathcal{S}_{d}\). Thus the set \(\Psi_{\alpha}^{y}:=\{(1-\frac{1}{d})\delta_{y}+(\frac{1}{d})\delta_{\hat{y}}\mid \hat{y}\in\mathcal{Y}\}\) is mapped via \(\varphi\) to the following points

\[\varphi(\Psi_{\alpha}^{y})=\{(1-\frac{1}{d})(\pi(w))+(\frac{1}{d})(\hat{\pi}(w ))\mid\hat{\pi}\in\mathcal{S}_{d}\}\]

within the permutahedron.

We shall show that \(P_{\alpha}^{y}\subseteq\Delta_{d}^{\pi}\). If this were not true, there would exists an element of \(w^{\pi,\hat{\pi}}\in\varphi(\Psi_{\alpha}^{y})\) such such that for some pair of adjacent indices, say \(i,i+1\in[d-1]\), \(w_{i}^{\pi,\hat{\pi}}>w_{i+1}^{\pi,\hat{\pi}}\). For sake of contradiction, fix \(i\in[d-1]\) and assume there exists a \(\hat{\pi}\in\mathcal{S}_{d}\) such that \(w_{i}^{\pi,\hat{\pi}}>w_{i+1}^{\pi,\hat{\pi}}\). Observe that 

[MISSING_PAGE_FAIL:17]

**Case 1**, \(\implies\): Assume for contradiction that \(p_{a}<p_{b}\) and \(||\varphi(p)-v_{a}||_{2}<||\varphi(p)-v_{b}||_{2}\). Then

\[\langle\varphi(p)-\mathbbm{1}_{1},\varphi(p)-\mathbbm{1}_{1}\rangle< \langle\varphi(p)+\mathbbm{1}_{1},\varphi(p)+\mathbbm{1}_{1}\rangle\] \[(u_{1}-1)^{2}+\sum_{i=1}u_{i}^{2}< (u_{1}+1)^{2}+\sum_{i=1}u_{i}^{2}\] \[-u_{1}< u_{1}\;.\]

By the definition of a \(d\)-cross polytope \(P^{\oplus}:=\operatorname{conv}\left(\{\pi((\pm 1,0,\dots,0))\mid\pi\in\mathcal{S}_{d} \}\right)\) and the orthogonal relation between vertices, to express a \(u\in P^{\oplus}\) as a convex combination of vertices, each diagonal pair of vertices coefficients solely influence the position along a single unit basis vector. Hence, due to the definition of \(\varphi\), we have \(u_{1}=1_{1}\cdot p_{a}-\mathbbm{1}_{1}\cdot p_{b}<0\) since we have assumed that \(p_{a}<p_{b}\). Hence \(-u_{1}<u_{1}<0\), a contradiction.

**Case 2**, \(\implies\): Assume \(p_{a}>p_{b}\) and \(||\varphi(p)-v_{a}||_{2}<||\varphi(p)-v_{b}||_{2}\). By symmetry with case 1, all the inequalities are reversed, leading to the contradiction that \(-u_{1}>u_{1}>0\).

**Case 3**: (\(p_{a}=p_{b}\)): Follows from the if and only ifs of cases 1 and 2.

Hence \((L_{\varphi}^{G},\psi_{\varphi})\) elicits \(\Gamma^{\varphi}\).

**Theorem 10**.: _Let \(d\geq 2\). The mode is \((2d,d,m)\)-Polytope Elicitable for some \(m\in[2d-1,d(2d-1)]\)._

Proof.: We will elicit the mode via the intermediate properties, \(\Gamma^{\varphi_{j}}\), defined in Lemma 9. First we construct a set of embeddings so that we guarantee that all the \(\varphi_{j}\)'s allow comparison between any pair of outcome probabilities. For example, for each unique pair \((a,b)_{j}\in\binom{\mathcal{Y}}{2}\) define an embedding: \(\varphi_{j}(\delta_{a})=1_{1}\) and \(\varphi_{j}(\delta_{b})=-\mathbbm{1}_{1}\), and embed every other remaining report \(r\in\mathcal{Y}\setminus\{a,b\}\) arbitrarily. Since \((L_{\varphi}^{G},\psi^{P^{\oplus}})\) elicits \(\Gamma^{\varphi}\), minimizing each \(L_{\varphi_{j}}^{G}\) with a separate model yields us comparisons via the link \(\psi^{P^{\oplus}}\). To find the set \(r\in\mathcal{Y}\) such that \(p_{r}\) is maximum, we use a sorting algorithm that uses pairwise comparisons, such as bubble sort. Hence with \(\Upsilon\) as Algorithm 1, we have that \(\Upsilon(\{L_{\varphi_{j}}^{G},\psi^{P^{\oplus}}\})=\text{mode}(p)\).

Assuming there exist \(\varphi_{j}\)s such that there is no redundancy in comparison pairs between each \(\Gamma^{\varphi_{j}}\), we would need only \(\frac{d(2d-1)}{d}=2d-1\) problem instances. Hence, we establish our lower bound on the needed number of problem instances. 

## Appendix C Hamming Loss Hallucination Example

Hamming loss \(\ell:\mathcal{Y}\times\mathcal{Y}\rightarrow\mathbb{R}_{+}\) is defined by \(\ell(y,\hat{y})=\sum_{i=1}^{d}\mathbbm{1}_{y_{i}\neq\hat{y}_{i}}\) where \(\mathcal{Y}=\{-1,1,\}^{d}\). Suppose \(d=3\) and we have the following indexing over outcomes

\[\mathcal{Y}:=\{y_{1}\equiv(1,1,1),y_{2}\equiv(1,1,-1),y_{3}\equiv( 1,-1,1),y_{4}\equiv(-1,1,1),\\ y_{5}\equiv(-1,-1,1),y_{6}\equiv(1,-1,-1),y_{7}\equiv(-1,1,-1 ),y_{8}\equiv(-1,-1,-1)\}\;.\]

Let us define the following distribution

\[p_{\epsilon}=(0,\frac{1}{3}-\epsilon,\frac{1}{3}-\epsilon,\frac{1}{3}- \epsilon,0,0,0,3\epsilon)\in\Delta_{\mathcal{Y}}\]

such that \(\epsilon>0\).

* \(\mathbb{E}_{Y\sim p_{\epsilon}}[\ell(y_{1},Y)]=1+6\epsilon\)
* \(\mathbb{E}_{Y\sim p_{\epsilon}}[\ell(y_{2},Y)]=\mathbb{E}_{Y\sim p_{\epsilon}}[ \ell(y_{3},Y)]=\mathbb{E}_{Y\sim p_{\epsilon}}[\ell(y_{4},Y)]=\frac{4}{3}+2\epsilon\)
* \(\mathbb{E}_{Y\sim p_{\epsilon}}[\ell(y_{5},Y)]=\mathbb{E}_{Y\sim p_{\epsilon}}[ \ell(y_{6},Y)]=\frac{7}{3}-4\epsilon\)
* \(\mathbb{E}_{Y\sim p_{\epsilon}}[\ell(y_{8},Y)]=2-6\epsilon\)

For all \(\epsilon\in[0,\frac{1}{12})\), the minimizing report in expectation is \(y_{1}=(1,1,1)\). However, \(p_{\epsilon,1}=0\) and thus, a hallucination would occur under a calibrated surrogate and link pair.

Linking under Multiple Problem Instances

As stated in SS 5, when using real data, given that these are asymptotic results, we may have conflicting logic for the provided individual reports. In this section, we provide an approach such that the algorithm still reports information in the aforementioned scenario and will reduce to Algorithm 1 asymptotically. We build a binary relation table \(M\in\{0,1\}^{n\times n}\) with the provided reports. Based on \(M\), we select a largest subset of \(S\subseteq\mathcal{Y}\) such that when \(M\) is restricted to rows and columns corresponding to the elements of \(S\), denoted by \(M_{S}\), we have that \(M_{S}\) is reflexive, antisymmetric, transitive, and strongly connected implying \(M_{S}\) has a total-order relation defined over its elements. Having a total-order relation infers the mode can be found via comparisons. The algorithm returns \((R,S)\), where \(R\) is the mode set with respect to the elements of \(S\).

```
0:\(M=\{(L^{G}_{\varphi_{j}},\psi^{P^{\oplus}}_{j})\}_{j=1}^{m}\)  Learn a model \(h_{j}:\mathcal{X}\rightarrow\mathbb{R}^{d}\) for each instance \((L^{G}_{\varphi_{j}},\psi^{P^{\oplus}}_{j})\in M\)  For some fixed \(x\in\mathcal{X}\), collect all \(B_{j}\leftarrow\psi^{P^{\oplus}}_{j}(h_{j}(x))\) where \(B_{j}\in\mathcal{B}_{j}\)  Build \(M\in\{0,1\}^{n\times n}\) binary relation table with provided \(\{B_{j}\}_{j=1}^{m}\) as such * Label rows top to bottom by \(y_{1},\ldots,y_{n}\) and columns left to right by \(y_{1},\ldots,y_{n}\). * For all \((\cdot,p_{y_{i}},p_{y_{k}})\in B_{j}\), if \(p_{y_{i}}\leq p_{y_{k}}\) set \(M[i,k]=1\) and \(0\) otherwise. Select largest subset \(S\subseteq\mathcal{Y}\) such that \(M_{S}\) is reflexive, antisymmetric, transitive, and strongly connected. Report \((R,S)\leftarrow\) FindMaxElements-of-\(S(M;S)\) ```

**Algorithm 2** Elicit mode via comparisons and the d-Cross Polytopes over well-defined partial orderings

### NeurIPS Paper Checklist

The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: **The papers not including the checklist will be desk rejected.** The checklist should follow the references and precede the (optional) supplemental material. The checklist does NOT count towards the page limit.

Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist:

* You should answer [Yes], [No], or [NA].
* [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.
* Please provide a short (1-2 sentence) justification right after your answer (even for NA).

**The checklist answers are an integral part of your paper submission.** They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper.

The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a proper justification is given (e.g., "error bars are not reported because it would be too computationally expensive" or "we were unable to find the license for the dataset we used"). In general, answering "[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found.

IMPORTANT, please:

* **Delete this instruction block, but keep the section heading "NeurIPS paper checklist"**,
* **Keep the checklist subsection headings, questions/answers and guidelines below.**
* **Do not modify the questions and only use the provided macros for your answers**.

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Any claimed result in the abstract is proved within this work. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Yes, our paper discuss how these results are asymptotic.

Guidelines:

* The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.
* The authors are encouraged to create a separate "Limitations" section in their paper.
* The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.
* The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.
* The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.
* The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.
* If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.
* While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: Yes, we thoroughly introduce every necessary definition and past result necessary to understand the assumptions that hold under our results. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The results of this work have rigorous proofs presented next to the results or referenced clearly in the appendix. Guidelines: * The answer NA means that the paper does not include experiments.

* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [NA] Justification:This paper does not include experiments requiring code. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). ** Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA] Justification: The paper does not include experiments Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: The paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: The paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.

* The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.
* The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: None of our conducted work for this paper violates the code of ethics presented. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: In the body of our paper, we provide a broader impact section. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The answer NA means that the paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks.

* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: The paper does not use existing assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release new assets. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects.

Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: the paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.