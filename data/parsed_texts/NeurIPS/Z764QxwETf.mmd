# PuzzleFusion: Unleashing the Power of

Diffusion Models for Spatial Puzzle Solving

Sepidehsadat Hosseini, Mohammad Amin Shabani, Saghar Irandoust, Yasutaka Furukawa

Simon Fraser University

{sepidh, mshabani, sirandou, furukawa}@sfu.ca

Work done while being student at SFU

###### Abstract

This paper presents an end-to-end neural architecture based on Diffusion Models for spatial puzzle solving, particularly jigsaw puzzle and room arrangement tasks. In the latter task, for instance, the proposed system takes a set of room layouts as polygonal curves in the top-down view and aligns the room layout pieces by estimating their 2D translations and rotations, akin to solving the jigsaw puzzle of room layouts. A surprising discovery of the paper is that the simple use of a Diffusion Model effectively solves these challenging spatial puzzle tasks as a conditional generation process. To enable learning of an end-to-end neural system, the paper introduces new datasets with ground-truth arrangements: 1) 2D Voronoi jigsaw dataset, a synthetic one where pieces are generated by Voronoi diagram of 2D pointset; and 2) MagicPlan dataset, a real one offered by MagicPlan from its production pipeline, where pieces are room layouts constructed by augmented reality App by real-estate consumers. The qualitative and quantitative evaluations demonstrate that our approach outperforms the competing methods by significant margins in all the tasks. We have provided code and data here.

## 1 Introduction

Spatial puzzle solving demands meticulous reasoning and arrangement of elements within a given space. The classic example of jigsaw puzzles, which many of us have enjoyed as a recreational activity, showcases the challenge and satisfaction of such tasks. Applications of jigsaw puzzles extend beyond mere entertainment, encompassing areas such as the restoration of shattered 2D artwork and documents Das et al. (2017); McBride and Kimia (2003), image stitching in computer vision Hammoudeh and Pollett (2017), and even DNA sequence assembly in genomics Pop (2009); Marande and Burger (2007). In real estate, room layout arrangement has emerged as a compelling spatial puzzle task, where consumers leverage mobile devices to scan individual rooms that are to be arranged into a floorplan.

Spatial puzzle solving poses a considerable challenge even for humans, making it an engaging mental exercise. Addressing this challenge for computational approaches is even more demanding, despite the emergence of deep learning. Current state-of-the-art techniques typically enumerate pairs of aligned pieces, evaluate their compatibility by learning, and employ optimization or search methods to identify the most likely global arrangement Harel and Ben-Shahar (2021); Hoff and Olver (2014); Shih and Lu (2018). However, these approaches struggle to scale as the complexity of global arrangement increases exponentially with the number of pieces.

This paper makes a breakthrough in spatial puzzle solving with an end-to-end neural architecture based on Diffusion Models Ho et al. (2020), named PuzzleFusion. The surprising discovery of this paper is that a Diffusion Model, typically regarded as a powerful generative model, is an effectivespatial puzzle solver. PuzzleFusion formulates the spatial puzzle as a conditional generation process where the piece information is the condition.

Concretely, each puzzle piece is a polygonal shape, represented by a sequence of 2D corner coordinates. A piece is associated with task-dependent properties, such as a texture image for pictorial jigsaw puzzles or the room types and door locations for Room Layout Arrangement. The output is a 2D position and an orientation for each piece. The forward diffusion process adds noise to a feature vector initialized with the ground truth position and orientation. The reverse denoising process learns to infer position and orientation subject to the piece shape and property information as a condition.

Qualitative and quantitative evaluations over the three tasks (Cross-cut jigsaw, Voronoi jigsaw, and room layout arrangement) demonstrate that PuzzleFusion outperforms the current state-of-the-art methods by significant margins. The paper also makes dataset contributions by introducing large-scale datasets with ground-truth labels for Voronoi jigsaw and room layout arrangement tasks. Specifically, the room layout arrangement dataset comes from a production pipeline by MagicPlan (https://www.magicplan.app/) consisting of room-layouts and floorplans for 98,780 houses, which we obtained permission to share with the research community.

In summary, this paper makes the following three key contributions: 1) An end-to-end neural architecture based on Diffusion Models for spatial puzzle solving; 2) State-of-the-art performance across three spatial puzzle tasks in terms of accuracy and speed; and 3) The new spatial puzzle datasets including room-layouts and floorplans for 98,780 houses from a production pipeline. We will make all our code and data public.

## 2 Related Work

Spatial puzzle solving is closely related to Structure from Motion (SfM), pose estimation, arrangement learning, and more. The section discusses the related techniques.

**Feature matching** has been successful for the SfM problem Snavely et al. (2006); Li et al. (2020); Lin et al. (2016). The rise of deep neural networks enables more robust feature matching by learning Yi et al. (2018); Sun et al. (2021); Sarlin et al. (2020). However, these techniques require visual overlaps. Our task has little to no visual overlaps between adjacent images.

**Geometry inference** estimates a relative pose between images or partial scans with minimal overlaps by registering inferred or hallucinated geometry. A popular approach learns the priors of room shapes and alternates pairwise alignment and scene completion Lin et al. (2019); Yang et al. (2019). Yang et al. (2020) combines global relative pose estimation and local pose refinement

Figure 1: Room layout arrangement is the task of taking a set of room layouts and their corresponding room types as the input and predicting the position and the orientation of each room. The biggest discovery and surprise of this paper is that conditional generation by a Diffusion Model solves this challenging problem.

with panoramas. These techniques learn priors of a single room, while our approach learns the arrangements of multiple rooms on a house scale.

**Arrangement learning** is the current state-of-the-art for indoor room layout arrangement. An early work uses windows to align indoor and outdoor reconstructions Cohen et al. (2016). Shabani _et al_. Shabani et al. (2021) use doors to enumerate room arrangements and learn to score each candidate. Their approach is exponential in the number of rooms with many heuristics. Lambert _et al_. Lambert et al. (2022) uses doors, windows, and openings to create room alignment hypotheses. They utilize depth maps to create top-down views and learn to verify the correctness, improving a run-time from exponential to polynomial. Our end-to-end approach does not enumerate arrangement candidates and makes significant performance improvements. Lastly, an annotated site map and SfM reconstructions are aligned to solve a challenging structure from motion problem Martin-Brualla et al. (2014); Hosseini and Furukawa (2022), which they coined as a "3D jigsaw puzzle".

**Puzzle Solving** has been an engaging research area for a long time Freeman and Garder (1964); Radack and Badler (1982); Markaki and Panagiotakis (2022), ranging from pictorial puzzles with image information Shih and Lu (2018); Le and Li (2019); Toler-Franklin et al. (2010) to apictorial puzzles with only geometry information Goldberg et al. (2002); Harel and Ben-Shahar (2020); Hoff and Olver (2014, 2013); Harel and Ben-Shahar (2021). In previous studies, heuristic-based methods, such as edge and color matching Wolfson et al. (1988); Nielsen et al. (2008); Chung et al. (1998), have been predominantly used for solving both methods. Recently, deep learning-based methods seek to learn high-level pictorial features Noroozi and Favaro (2016); Li et al. (2021). However, they suffer from poor geometric reasoning and are limited to simple square puzzles. Consequently, researchers combine learning-based models with heuristics to handle more complex puzzles Le and Li (2019). Nonetheless, these methods still require explicit pairwise comparison of pieces and lack data-driven high-level reasoning. Our method overcomes these limitations through an innovative end-to-end use of Diffusion Models which are usually regarded as powerful generative models.

**Diffusion models** (DMs) are emerging generative models, which slowly corrupt a sample by adding noise Ho et al. (2020); Dhariwal and Nichol (2021); Nichol and Dhariwal (2021); Shabani et al. (2022), learn to invert the process, and generate a diverse set of samples from noise signals. DMs have established SOTA performances in numerous tasks such as image colorization/inpainintg Song et al. (2020); Nichol et al. (2021), image to image translation Sasaki et al. (2021); Zhao et al. (2022), text to image Ramesh et al. (2022), super-resolution Rombach et al. (2021); Saharia et al. (2021); Li et al. (2021), image and semantic editing Avrahami et al. (2022); Meng et al. (2022), and denoising Kawar et al. (2022). Recent works use DMs as representation learners for discriminative tasks such as image segmentation Baranchuk et al. (2021); Wolleb et al. (2021). Diffusion inspired models have been used for human pose estimation Shan et al. (2023); Gong et al. (2023), and object placement Wei et al. (2023), however, both tasks do not require sophisticated shape comparisons. While in our case a more advanced and intricate approach is necessary to capture and exploit all details of the shapes.

Figure 2: Spatial puzzle datasets for Voronoi and Cross-cut puzzle solving (Left) and room layout arrangement (Right). We consider both pictorial and apictorial versions of the Cross-cut jigsaw puzzle. Note that colors in puzzle solving problems are random and just indicate different pieces.

Spatial Puzzle Solving Tasks

Spatial puzzle solving involves arranging puzzle pieces, each with its geometry and optional features such as images or categories. In real scenarios, puzzle pieces are affected by erosion, duplication, or loss. This paper investigates three distinct puzzle-solving tasks.

\(\bullet\) Cross-cut Jigsaw Puzzle (CJP) generates pieces by making random straight cuts through a larger polygonal shape Harel and Ben-Shahar (2021). Puzzle pieces are convex polygons, each with an arbitrary number of neighboring pieces. The sum of the two adjacent angles at any corner equals \(180^{\circ}\). The application of the technique could be the restoration of shattered artwork.

\(\bullet\) Voronoi Jigsaw Puzzle (VJP) generates pieces by randomly sampling points within a predetermined bounding box and extracting the cells of the Voronoi diagram as the pieces. With the lack of the "\(180^{\circ}\) constraint", VJP is significantly more challenging, where no effective solution has been presented in the literature to our knowledge. Voronoi diagrams play a role in biological systems like cell arrangements Bock et al. (2010), potentially useful in studying natural phenomena.

\(\bullet\) Room Layout Arrangement (RLA) determines the room arrangement and the corresponding floor-plan, offering a key application in real estate. Contrary to the prior tasks, a corner may align along the edge of another piece, expanding the solution space to be explored. Pieces come from the room layout estimation algorithms Shabani et al. (2021); Lambert et al. (2022) or interactive augmented reality apps used by consumers.

**Task input/output**: The input is a set of \(N\) polygons (puzzle pieces in CJP/VJP and room layouts in RLA), each of which is a sequence of corner coordinates forming a 1D polygonal loop. In RLA, a door piece is also given as a line segment with two corners, and a room piece is associated with a room type as a 20D one-hot vector. For a pictorial version of CJP, a piece is associated with a 128D image feature vector obtained from a pretrained auto-encoder. For simplicity, we mix room-corners and door-corners, and use \(C_{i}^{r}\) to denote the 2D coordinate of the \(i\)th corner in the \(r\)th polygon. \(\mathcal{T}^{r}\) denotes the image feature or the room type vector. Please refer to supplementary for details. The output is the position of the piece/room center and the rotation around it (an angle between 0 and \(2\pi\) for CJP/VJP and a 4-fold Manhattan rotation for RLA). The center is the average of the corners.

**Metrics**: For CJP and VJP, we adopt metrics used in previous work Harel and Ben-Shahar (2020), namely Overlap, Precision, and Recall. The overlap score is the average IoU of pieces with the ground truth. Precision and Recall are on the connectivity of neighboring pieces. For RLA, we consider two metrics. The first metric is the Mean Positional Error in pixels (MPE) over the rooms Shabani et al. (2021). 2 The second metric evaluates the correctness of the room connectivity in the reconstruction. We borrow a Graph Edit Distance (GED) by Nauata et al. (2021), which counts the number of user edits necessary to fix the connectivity graph. We declare that two rooms are connected if the door centers are within 5 pixels from the two rooms. Note that we have designed task-specific metrics, respecting the methodologies of existing literature while providing a thorough evaluation of our performance.

Footnote 2: Shabani et al. Shabani et al. (2021) used a permissive metric (the availability of the “correct” solution in the k results with a certain error-tolerance) as the task was challenging. We make great improvements and use a standard metric.

## 4 Spatial Puzzle Solving as Conditional Generation

Our idea is simple, using a Diffusion Model to "conditionally generate" the correct arrangement, where the input is the center and rotation of room layouts/puzzle pieces and their types and shapes are the conditions. This section explains the forward and the reverse processes.

### Forward process

The forward process adds a Gaussian noise to an arrangement. A compact representation would be per-polygon positions and rotations. Instead, we will use a redundant representation, where a center position and a rotation are stored at each corner.

There are a few reasons. Our reverse process is based on a Transformer architecture where each position/rotation estimation becomes a node. Our approach 1) enriches the capacity of the arrangement representation (also an adaptive capacity, where a complex polygon with more corners is given more capacity); 2) allows direct communications between corners/doors for which we will have a specific loss; and 3) makes it straightforward to combine with the condition (_i.e._, original corner coordinates and room types).

Concretely, we use \(x_{i,t}^{r}\) to denote the position/rotation of the \(r\)th room/piece stored at the \(i\)th corner at time \(t\) of the diffusion process, where \(t\) varies from 0 to 1,000 in our experiments:

\[x_{i,t}^{r} = \left(p_{i,t}^{r},o_{i,t}^{r}\right).\] (1)

\(p_{i,t}^{r}\) and \(o_{i,t}^{r}\) denote the polygon-center position (a 2D vector) and the rotation. We consider rotation as a 2D vector obtained from rotation matrix including \(\text{cos}(o_{i,t}^{r})\) and -\(\text{sin}(o_{i,t}^{r})\). The forward process adds a noise by sampling \(\delta_{i,t}^{r}\in\mathcal{N}(\mathbf{0},\mathbf{I})\) with a standard cosine noise scheduling with variance \((1-\alpha_{t})\)Nichol and Dhariwal (2021b):

\[x_{i,t}^{r}=\sqrt{\bar{\alpha}_{t}}x_{i,0}^{r}+\sqrt{1-\bar{\alpha}_{t}} \delta_{i,t}^{r},\quad\bar{\alpha}_{t}=\frac{f(t)}{f(0)},\quad f(t)=\cos\left( \frac{t/T+0.008}{1+0.008}\cdot\frac{\pi}{2}\right)^{2}\] (2)

### Reverse process

Figure 3 illustrates our reverse process for room layout arrangement, which takes the arrangement \(\{x_{i,t}^{r}\}\) at time \(t\) and infers the noise \(\delta_{i,t}^{r}\) under the condition of the original room shapes \(\{C_{i}^{r}\}\) (_i.e._, a corner position with respect to the room center) and the room types as a one-hot vector \(\{\mathcal{T}^{r}\}\).

**Feature embedding**: The reverse process is based on a Transformer architecture where every corner is a node. We initialize its feature embedding as

\[\hat{x}_{i,t}^{r}\leftarrow\text{Lin}(x_{i,t}^{r})+\text{Lin}([C_{i}^{r},r,i] )+\text{MLP}(t)+\text{Lin}(\mathcal{T}^{r}).\] (3)

The first term uses a linear layer to convert a 4D vector (_i.e._, 2 for the room center coordinate and 2 for the rotation vector) to a 256D embedding vector. The second term also uses a linear layer to convert a condition vector (_i.e._, 2 for the corner coordinate respecting to the center of the polygon

Figure 3: Illustration of our diffusion model architecture employed for the RLA task. Given the arrangement estimation \(x_{t}=\{x_{i,t}^{r}\}\), the reverse process infers the noise \(\{\delta_{i,t}^{r}\}\) and recovers \(x_{t-1}=\{x_{i,t-1}^{r}\}\), while injecting the original room shapes \(\{C_{i}^{r}\}\) and types \(\{\mathcal{T}^{r}\}\) as the condition. Each room corner holds the room position and rotation estimation. The reverse process starts from \(x_{T}\) and denoises towards \(x_{0}\).

in addition to 32 for polygon index which shows which polygon each corner belongs \(r\) and 32 to show the corner index in each polygon \(i\)), The third term uses a 2-layer MLP to convert a time step \(t\) to a 256D vector. The fourth term is extra information such as room/door type (20 types) for RLA which we extract it by applying a linear layer on 20D one-hot vector or 128D for image features in pictorial CJP)

**Attention modules**: Feature embeddings \(\{\tilde{x}^{r}_{i,t}\}\) go through six blocks of self-attention modules that have two different attention mechanisms: Polygon Self Attention (P-SA) and Global Self Attention (G-SA). P-SA limits pairwise interactions between corners in each polygon. P-SA is akin to a sparse self attention family Guo et al. (2019); Child et al. (2019); Li et al. (2019), which helps to generate consistent positions and rotations at different corners of a polygon. G-SA is a standard self-attention between all corners of a puzzle or a house. After the attention blocks, a linear layer converts 256D embedding back to a 4D representation \(\tilde{\delta}^{r}_{i,t}\), which is used for the following denoising formula Ho et al. (2020):

\[x^{r}_{i,t-1}=\frac{1}{\sqrt{\alpha_{t}}}\left(x^{r}_{i,t}-\frac{1-\alpha_{t} }{\sqrt{1-\bar{\alpha}_{t}}}\tilde{\delta}^{r}_{i,t}\right)+\sqrt{1-\alpha_{t }}z.\] (4)

\(z\sim\mathcal{N}(0,I)\) for \(t>1\) and otherwise 0. For the final result at time \(t=0\), we take the average polygon center position and the polygon rotation.

**Loss functions**: There are two loss functions. We first follow Ho et al. (2020); Dhariwal and Nichol (2021) and use a standard noise regression loss on \(\delta\):

\[L_{\text{simple}} =E_{t,x^{r}_{1,0},\delta^{r}_{i,t}}\left[\left\|\delta^{r}_{i,t}- \tilde{\delta}^{r}_{i,t}\right\|^{2}\right].\] (5)

To enhance the quality of supervision, we propose a "matching" loss, specifically aimed at the vertices where incident edges meet. These vertices are shared by two polygons. We denote the indices of these two polygons as \(r_{1}\) and \(r_{2}\), then the corresponding vertex indices within \(r_{1}\) and \(r_{2}\) as \(i_{1}\) and \(i_{2}\), respectively. The corresponding vertices must be at the same position, and as such, we calculate the loss as the Euclidean distance between their coordinates:

\[L_{\text{match}} = E_{t,x^{r}_{i,0},\delta^{r}_{i,t}}\left[\left\|\tilde{C}^{r_{1}} _{i_{1}}-\tilde{C}^{r_{2}}_{i_{2}}\right\|^{2}\right],\] (6) \[\hat{C}^{r}_{i} = \tilde{p}^{r}_{i,0}+R_{\tilde{\sigma}^{r}_{i,0}}C^{r}_{i}\,,\] (7) \[(\tilde{p}^{r}_{i,0},\tilde{\sigma}^{r}_{i,0}) = \tilde{x}^{r}_{i,0}=\left(x^{r}_{i,t}-\sqrt{1-\bar{\alpha}_{t}} \tilde{\delta}^{r}_{i,t}\right)/\sqrt{\bar{\alpha}_{t}}.\] (8)

\(R_{\tilde{\sigma}^{r}_{i,0}}\) denotes the rotation matrix corresponding to \(\tilde{\sigma}^{r}_{i,0}\). For the room layout arrangement task, we add the loss only to doors without walls, which yields superior results in our experiments. The total loss is defined as the sum of the above loss functions, \(L_{\text{total}}=L_{\text{simple}}+L_{\text{match}}\). In practice, we found that adding \(L_{\text{match}}\) only for \(t<500\) results in better performance.

## 5 Experimental Results and Discussions

We have implemented the system with PyTorch Paszke et al. (2019), using a workstation with a 3.70GHz Intel i9-10900X CPU (20 cores) and two NVIDIA RTX A6000 GPUs. We use the AdamW Loshchilov and Hutter (2017); Kingma and Ba (2014) optimizer with \(\beta_{1}=0.9\), \(\beta_{2}=0.999\), weight decay equal to 0.05, and the batch size of 512. The learning rate is initialized to 0.0005. It takes roughly 24 hours to train a model and 3 seconds to estimate the arrangement for one sample.

### Preprocessing and Datasets

We have carefully pre-processed and prepared datasets for fair evaluation, whose details are referred to supplementary. We here provide summary points for the three tasks (See Fig. 2).

**Cross-cut Jigsaw Puzzle (CJP)**: We have used code provided by Harel et al. (2021) to generate 100k/1k puzzles for training/testing. The code generates a convex polygon and cuts it by 3 to 5 lines. For the pictorial version, we have used images from COCO 2017 dataset Lin et al. (2014), that is, randomly selecting a training/testing image of the dataset for each training/testing CJP sample. Following Harel and Ben-Shahar (2021), to simulate real-world scenario, we perturb corner coordinates with noise with three different levels to create datasets under three different noise levels with thresholds equal to 0, 2, and 4.

**Voronoi Jigsaw Puzzle (VJP)**: We have generated 200k/1k puzzles for training/testing by randomly sampling 3 to 15 points inside a random rectangle and extracting their Voronoi cells as the pieces. We have created datasets with three different levels of noise. For each corner, we added a random number from a Gaussian distribution with \(\sigma^{2}\) equal to 0, 2, and 4 for noise levels 0, 1, and 2, respectively.

**Room Layout Arrangement (RLA)**: MagicPlan (https://www.magicplan.app), a mobile software company for real estate and construction, agrees to share production data with us and the research community, where the paper introduces the MagicPlan dataset, containing room shapes and their ground-truth arrangement for 98,780 single-story houses/apartments. We split the data into 93,780/5,000 training/testing samples. MagicPlan software reconstructs room shapes one by one by asking users to click room corners through an augmented reality app. Room shapes are Manhattan-rectified as an enforcement of the app, then manually arranged to form a floorplan, which we seek to automate. Each room is associated with a room type. The number of rooms (resp. corners) in a house ranges from 3 to 10 (resp. 12 to 182). We also use RPLAN Wu et al. (2019) for evaluation, containing 60k floorplans. We divide into 55k/5k training/testing, where the number of rooms (resp. corners) in a house ranges from 3 to 8 (resp. 14 to 98). Note that RICOH dataset Saharia et al. (2021) and ZIND dataset Lambert et al. (2022b) are too small for network training and are not used in our experiments.

### Competing methods

Harel _et al._Harel and Ben-Shahar (2021) and Shabani _et al._Shabani et al. (2021) are state-of-the-art methods for CJP and RLA, respectively. We have used their public implementations to compare in the corresponding tasks. Note that Harel _et al._ is not applicable to VJP or RLA, where neighboring angles may not add to \(180^{\circ}\) or corners may not meet. Shabani _et al._ is not applicable to CJP or BJP due to its poor scalability (i.e., exponential in the number of pieces). We have also prepared a third method based on the transformer network to be compared for RLA. The following provides more information, while the full details are in supplementary.

**Harel _et al._Harel and Ben-Shahar (2021) proposed a two-step algorithm for CJP: Enumerating pairs of compatible pieces by heuristics based on edge lengths or corner angles, then globally solving for the whole arrangement by a spring system.

**Shabani _et al._Shabani et al. (2021) enumerates arrangement candidates by heuristics and learns to regress the realism of an arrangement candidate by deep neural networks. Since the number of room/door types differs in our datasets, we made minor modifications to the data loader and the network architecture.

**TransVector** is a baseline Transformer network with a vector representation that directly estimates the pose parameters instead of iterative denoising. TransVector shares the same architecture as our denoising network at the core with the following changes: 1) Remove time-dependent features (\(x_{i,t}^{r}\) and \(t\)) from the embedding (3); 2) Change the supervision \(\delta_{i,t}^{r}\) from the noise to the position/rotation parameters; and We have also compared with the Transformer network with a raster representation, which is presented in the supplementary.

### Main results

Table 1 compares the proposed approach against Shabani _et al._Shabani et al. (2021) and TransVector. Shabani _et al._ runs exponentially in the number of pieces (i.e., rooms), taking hours or even days to process a single house with seven or more rooms. Therefore, we collect small houses (_i.e._, at most six rooms) to create "Small RPLAN" and "Small MagicPlan" datasets for its evaluations. For each experimental setting (_e.g._, Small MagicPlan), we train a network for each method.

[MISSING_PAGE_FAIL:8]

Our layout arrangement uses a redundant representation (i.e., all the corners store the position and the orientation estimates of a piece), enriching the capacity and enabling direct communications between room/door corners (Sect. 4.1). To assess the effects of this redundancy, we have created a variant of our system with a compact representation, that is, each room/door has only a single node estimating a single copy of the room position and the orientation. We aggregate corner coordinates into a single embedding vector and pass as a condition (See supplementary for the details). The MPE/GED metrics for Full MagicPlan change from \((41.23/3.16)\) to \((51.62/5.52)\), a significant performance drop showing the importance of our redundant representation.

\begin{table}
\begin{tabular}{c|c|c|c|c|c} \hline \hline \multicolumn{2}{c|}{Train} & \multicolumn{2}{c|}{Test} & \multicolumn{2}{c|}{MPE(\(\downarrow\))} & \multicolumn{1}{c}{GED (\(\downarrow\))} \\ \hline R-Type & Door & R-Type & Door & & & \\ \hline ✓ & ✓ & None & ✓ & 48.4 & 3.8 \\ None & ✓ & None & ✓ & 47.4 & 3.6 \\ ✓ & ✓ & Noisy & ✓ & 49.7 & 4.0 \\ Noisy & ✓ & Noisy & ✓ & 49.3 & 3.9 \\ ✓ & ✓ & ✓ & None & 46.9 & 5.2 \\ ✓ & None & ✓ & None & 45.5 & 5.2 \\ ✓ & ✓ & ✓ & ✓ & 40.8 & 3.1 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Effects of the room-type (R-type) and the Door information. Full MagicPlan is used. \(\diagdown\) indicates the information being used. When a room-type is not used, we set a zero vector as a room-type one-hot vector, when room type is noisy we assign each room with a random room type. When the door information is not used, we do not pass the door-corner nodes to the network.

\begin{table}
\begin{tabular}{l c c c c|c c c c|c c c c|c c c} \hline \hline \multicolumn{2}{c}{Dataset} & \multicolumn{6}{c}{Cross-cut Jigsaw Puzzle} & \multicolumn{6}{c}{Voronoi Jigsaw Puzzle} \\ \cline{2-13} Metric & \multicolumn{3}{c}{Overlap (\(\uparrow\))} & \multicolumn{3}{c}{Precision (\(\uparrow\))} & \multicolumn{3}{c}{Recall (\(\uparrow\))} & \multicolumn{3}{c}{Overlap (\(\uparrow\))} & \multicolumn{3}{c}{Precision (\(\uparrow\))} & \multicolumn{3}{c}{Recall (\(\uparrow\))} \\ \hline Noise Level & 0 & 1 & 2 & 0 & 1 & 2 & 0 & 1 & 2 & 0 & 1 & 2 & 0 & 1 & 2 \\ \hline Harel _et al_. & 0.91 & 0.70 & 0.30 & 0.95 & 0.77 & 0.33 & **0.99** & 0.78 & 0.30 & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\ Ours (w/o \(L_{\text{match}}\)) & 0.91 & 0.90 & 0.89 & 0.94 & 0.92 & 0.90 & 0.77 & 0.76 & 0.73 & 0.65 & 0.64 & 0.63 & 0.75 & 0.71 & 0.71 & 0.53 & 0.52 & 0.52 \\ Ours & **0.94** & **0.94** & **0.93** & **0.97** & **0.95** & **0.93** & 0.91 & **0.92** & **0.91** & **0.70** & **0.68** & **0.67** & **0.78** & **0.75** & **0.74** & **0.60** & **0.57** & **0.55** \\ \hline \hline \end{tabular}
\end{table}
Table 2: CJP and VJP quantitative results with three metrics. Our method consistently shows superior performance with significant margins under the presence of noise. The second row shows ours without the matching loss. Harel _et al_. is unable to handle VJP due to the assumptions (See 5.2).

\begin{table}
\begin{tabular}{l|c|c|c|c|c|c|c|c|c|c|c} \hline \hline \multicolumn{2}{c|}{P-SA} & G-SA & \multicolumn{2}{c|}{\(L_{\text{match}}\)} & \multicolumn{2}{c|}{MPE (\(\downarrow\))} & \multicolumn{2}{c}{GED (\(\downarrow\))} \\ \hline None & ✓ & None & 48.2 & 4.9 \\ ✓ & ✓ & None & 43.4 & 4.5 \\ ✓ & None & All corners & 55.3 & 9.4 \\ None & ✓ & All Corners & 45.1 & 4.6 \\ ✓ & ✓ & All corners & 41.8 & 3.6 \\ ✓ & None & Doors & 56.9 & 9.3 \\ None & ✓ & Doors & 45.2 & 4.3 \\ ✓ & ✓ & Doors & 40.8 & 3.1 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Contributions of our two attention mechanisms (P-SA, G-SA) and the door matching loss (\(L_{\text{match}}\)). Full MagicPlan is used. \(\diagdown\) indicates the feature being used. In case of \(L_{\text{match}}\) “Doors” means matching loss has been applied only on door corners and “All corners” means matching loss has been applied to all corners including door corners.

Figure 6: Apictorial CJP arrangement results. Both methods work well in a noise-free case (left), but only our method maintains the performance with the presence of noise (right).

A popular approach in the RLA literature is to align door detections/annotations to enumerate arrangement candidates Lambert et al. (2022); Shabani et al. (2021). Our approach directly learns to infer the arrangement without relying on such "hard" heuristics. To further demonstrate the power of our approach, we remove or alter the room type and the door information during training and testing, where the current state-of-the-art methods Lambert et al. (2022); Shabani et al. (2021) completely fail. Table 8 shows some performance drop, but the effects are marginal. Our numbers are still much better than TransVector with the full information (MPE=\(53.11\) and GED=\(6.41\) in Table 1), the only competing method capable of handling this most challenging setting. To evaluate the capacity of our network to handle overlaps, we conducted an experiment. In this experiment, we augmented our train/test dataset by randomly selecting up to two rooms per house. For each selected room, we employed one of the following strategies: 1) Duplicating the room with the ground truth (GT) room types. 2) Duplicating the room with random room types. 3) Enlarging the room by 20\(\%\) to create partial overlaps. The dataset used for this experiment is Full MagicPlan dataset. Our evaluation metrics, MPE/GED, resulted in 48.3/3.9, respectively. Please also see the supplementary document and the video for more results, more visualizations, and animations of the denoising process.

### Conclusion

This paper introduced an end-to-end neural architecture for spatial puzzle solving tasks. The proposed approach is faster, robust to data corruptions, end-to-end, and far superior to existing methods in all the metrics in the variety of tasks, namely Cross-cut jigsaw puzzle (pictorial and apictorial), Voronoi jigsaw puzzle, and room layout arrangement. Despite numerous advantages, our approach faces certain limitations. The primary challenge is its substantial need for training data, which limits our ability to process smaller datasets. For the room layout arrangement task, the utilization of raw image information could further enhance performance as discussed in Shabani et al. (2021); Lambert et al. (2022). However, this would significantly increase the amount of data transfer from a mobile device, where on-device processing would become desirable. One key future work is the development of data-efficient (at training) and computation-efficient (at testing) neural architectures Kitaev et al. (2020). To our knowledge, this paper is the first to demonstrate that Diffusion Models, generally regarded as powerful generative models, are also effective in solving various challenging spatial arrangement tasks. The paper has the potential to motivate other researchers to further expand the applicability of emerging Diffusion Models, moving beyond content generation and into a myriad of other tasks.

**Acknowledgment**: This research is partially supported by NSERC Discovery Grants with Accelerator Supplements and the DND/NSERC Discovery Grant Supplement, NSERC Alliance Grants, and the John R. Evans Leaders Fund (JELF). We are also thankful to Magicplan for sharing the datasets.

## References

* Avraham et al. (2022) Omri Avraham, Ohad Fried, and Dani Lischinski. 2022. Blended Latent Diffusion. _arXiv preprint arXiv:2206.02779_ (2022).

Figure 7: Pictorial CJP arrangement results. Figure 8: VJP arrangement results.

Dmitry Baranchuk, Ivan Rubachev, Andrey Voynov, Valentin Khrulkov, and Artem Babenko. 2021. Label-Efficient Semantic Segmentation with Diffusion Models. (2021). arXiv:cs.CV/2112.03126
* Bock et al. (2010) Martin Bock, Amit Kumar Tyagi, Jan-Ulrich Kreft, and Wolfgang Alt. 2010. Generalized voronoi tessellation as a model of two-dimensional cell tissue dynamics. _Bulletin of mathematical biology_ 72 (2010), 1696-1731.
* Child et al. (2019) Rewon Child, Scott Gray, Alec Radford, and Ilya Sutskever. 2019. Generating long sequences with sparse transformers. _arXiv preprint arXiv:1904.10509_ (2019).
* Chung et al. (1998) Min Gyo Chung, Margaret M Fleck, and David A Forsyth. 1998. Jigsaw puzzle solver using shape and color. In _ICSP'98. 1998 Fourth International Conference on Signal Processing (Cat. No. 98TH8344)_, Vol. 2. IEEE, 877-880.
* ECCV 2016_, Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling (Eds.). Springer International Publishing, Cham, 285-300.

* Dhariwal and Nichol (2021) Prafulla Dhariwal and Alex Nichol. 2021. Diffusion Models Beat GANs on Image Synthesis. _CoRR_ abs/2105.05233 (2021). arXiv:2105.05233 https://arxiv.org/abs/2105.05233
* Dosovitskiy et al. (2020) Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. 2020. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. _CoRR_ abs/2010.11929 (2020). arXiv:2010.11929 https://arxiv.org/abs/2010.11929
* Freeman and Garder (1964) Herbert Freeman and L Garder. 1964. Apictorial jigsaw puzzles: The computer solution of a problem in pattern recognition. _IEEE Transactions on Electronic Computers_ (1964), 118-127.
* Goldberg et al. (2002) David Goldberg, Christopher Malon, and Marshall Bern. 2002. A global approach to automatic solution of jigsaw puzzles. In _Proceedings of the eighteenth annual symposium on Computational geometry_. 82-87.
* Gong et al. (2023) Jia Gong, Lin Geng Foo, Zhipeng Fan, Qiuhong Ke, Hossein Rahmani, and Jun Liu. 2023. Diffuse: Toward More Reliable 3D Pose Estimation. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_.
* Guo et al. (2019) Qipeng Guo, Xipeng Qiu, Pengfei Liu, Yunfan Shao, Xiangyang Xue, and Zheng Zhang. 2019. Star-transformer. _arXiv preprint arXiv:1902.09113_ (2019).
* Hammoudeh and Pollett (2017) Zayd Hammoudeh and Chris Pollett. 2017. Clustering-Based, Fully Automated Mixed-Bag Jigsaw Puzzle Solving. In _Computer Analysis of Images and Patterns_, Michael Felsberg, Anders Heyden, and Norbert Kruger (Eds.). Springer International Publishing, Cham, 205-217.
* Harel and Ben-Shahar (2020) Peleg Harel and Ohad Ben-Shahar. 2020. Lazy caterer jigsaw puzzles: Models, properties, and a mechanical system-based solver. _arXiv preprint arXiv:2008.07644_ (2020).
* Harel and Ben-Shahar (2021) Peleg Harel and Ohad Ben-Shahar. 2021. Crossing cuts polygonal puzzles: Models and Solvers. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_. 3084-3093.
* Ho et al. (2020) Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising Diffusion Probabilistic Models. _arXiv preprint arxiv:2006.11239_ (2020).
* Hoff and Olver (2014a) Daniel Hoff and Peter Olver. 2014a. Automatic Solution of Jigsaw Puzzles. _Journal of Mathematical Imaging and Vision_ 49 (05 2014). https://doi.org/10.1007/s10851-013-0454-3Daniel J Hoff and Peter J Olver. 2013. Extensions of invariant signatures for object recognition. _Journal of mathematical imaging and vision_ 45, 2 (2013), 176-185.
* Hoff and Olver (2014b) Daniel J Hoff and Peter J Olver. 2014b. Automatic solution of jigsaw puzzles. _Journal of mathematical imaging and vision_ 49 (2014), 234-250.
* Hosseini and Furukawa (2022) Sepidehsadat Hosseini and Yasutaka Furukawa. 2022. Extreme Floorplan Reconstruction by Structure-Hallucinating Transformer Cascades. _arXiv preprint arXiv:2206.00645_ (2022).
* Kawar et al. (2022) Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. 2022. Denoising Diffusion Restoration Models. In _Advances in Neural Information Processing Systems_.
* Kingma and Ba (2014) Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_ (2014).
* Kitaev et al. (2020) Nikita Kitaev, Lukasz Kaiser, and Anselm Levskaya. 2020. Reformer: The Efficient Transformer. In _International Conference on Learning Representations_. https://openreview.net/forum?id=rkgNKkHtvB
* Lambert et al. (2022a) John Lambert, Yuguang Li, Ivaylo Boyadzhiev, Lambert Wixson, Manjunath Narayana, Will Hutchcroft, James Hays, Frank Dellaert, and Sing Bing Kang. 2022a. SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas. In _ECCV_.
* Lambert et al. (2022b) John Lambert, Yuguang Li, Ivaylo Boyadzhiev, Lambert Wixson, Manjunath Narayana, Will Hutchcroft, James Hays, Frank Dellaert, and Sing Bing Kang. 2022b. SALVe: Semantic Alignment Verification for Floorplan Reconstruction from Sparse Panoramas. In _ECCV_.
* Le and Li (2019) Canyu Le and Xin Li. 2019. JigsawNet: Shredded image reassembly using convolutional neural network and loop-based composition. _IEEE Transactions on Image Processing_ 28, 8 (2019), 4000-4015.
* Li et al. (2021b) Haoying Li, Yifan Yang, Meng Chang, Huajun Feng, Zhihai Xu, Qi Li, and Yue-ting Chen. 2021b. SRDiff: Single Image Super-Resolution with Diffusion Probabilistic Models. _CoRR_ abs/2104.14951 (2021). arXiv:2104.14951 https://arxiv.org/abs/2104.14951
* Li et al. (2021a) Ru Li, Shuaicheng Liu, Guangfu Wang, Guanghui Liu, and Bing Zeng. 2021a. Jigsawgan: Auxiliary learning for solving jigsaw puzzles with generative adversarial networks. _IEEE Transactions on Image Processing_ 31 (2021), 513-524.
* Li et al. (2019) Shiyang Li, Xiaoyong Jin, Yao Xuan, Xiyou Zhou, Wenhu Chen, Yu-Xiang Wang, and Xifeng Yan. 2019. Enhancing the locality and breaking the memory bottleneck of transformer on time series forecasting. _Advances in neural information processing systems_ 32 (2019).
* Li et al. (2020) Xinghui Li, Kai Han, Shuda Li, and Victor Prisacariu. 2020. Dual-Resolution Correspondence Networks. In _Conference on Neural Information Processing Systems (NeurIPS)_.
* Lin et al. (2019) Cheng Lin, Changjian Li, and Wenping Wang. 2019. Floorplan-jigsaw: Jointly estimating scene layout and aligning partial scans. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_. 5674-5683.
* ECCV 2014_, David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars (Eds.). Springer International Publishing, Cham, 740-755.
* Lin et al. (2016) Wen-Yan Lin, Siying Liu, Nianjuan Jiang, Minh N. Do, Ping Tan, and Jiangbo Lu. 2016. RepMatch: Robust Feature Matching and Pose for Reconstructing Modern Cities. In _ECCV_.
* Loshchilov and Hutter (2017) Ilya Loshchilov and Frank Hutter. 2017. Decoupled weight decay regularization. _arXiv preprint arXiv:1711.05101_ (2017).
* Marande and Burger (2007) William Marande and Gertraud Burger. 2007. Mitochondrial DNA as a Genomic Jigsaw Puzzle. _Science_ 318, 5849 (2007), 415-415. https://doi.org/10.1126/science.1148033 arXiv:https://www.science.org/doi/pdf/10.1126/science.1148033* Markaki and Panagiotakis (2022) Smaragda Markaki and Costas Panagiotakis. 2022. Jigsaw puzzle solving techniques and applications: a survey. _The Visual Computer_ (2022), 1-17.
* Martin-Brualla et al. (2014) Ricardo Martin-Brualla, Yanling He, Bryan C Russell, and Steven M Seitz. 2014. The 3d jigsaw puzzle: Mapping large indoor spaces. In _European Conference on Computer Vision_. Springer, 1-16.
* McBride and Kimia (2003) Jonah C. McBride and Benjamin B. Kimia. 2003. Archaeological Fragment Reconstruction Using Curve-Matching. In _2003 Conference on Computer Vision and Pattern Recognition Workshop_, Vol. 1. 3-3. https://doi.org/10.1109/CVPRW.2003.10008
* Meng et al. (2022) Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon. 2022. SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations. In _International Conference on Learning Representations_.
* Nauta et al. (2021) Nelson Nauta, Sepidehsadat Hosseini, Kai-Hung Chang, Hang Chu, Chin-Yi Cheng, and Yasutaka Furukawa. 2021. House-GAN++: Generative Adversarial Layout Refinement Network towards Intelligent Computational Agent for Professional Architects. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_. 13632-13641.
* Nichol and Dhariwal (2021a) Alex Nichol and Prafulla Dhariwal. 2021a. Improved Denoising Diffusion Probabilistic Models. _CoRR_ abs/2102.09672 (2021). arXiv:2102.09672 https://arxiv.org/abs/2102.09672
* Nichol et al. (2021) Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. 2021. GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models. _CoRR_ abs/2112.10741 (2021). arXiv:2112.10741 https://arxiv.org/abs/2112.10741
* Nichol and Dhariwal (2021b) Alexander Quinn Nichol and Prafulla Dhariwal. 2021b. Improved Denoising Diffusion Probabilistic Models. (2021). https://openreview.net/forum?id=-NEXDKK8gZ
* Nielsen et al. (2008) Ture R Nielsen, Peter Drewsen, and Klaus Hansen. 2008. Solving jigsaw puzzles using image features. _Pattern Recognition Letters_ 29, 14 (2008), 1924-1933.
* Noroozi and Favaro (2016) Mehdi Noroozi and Paolo Favaro. 2016. Unsupervised learning of visual representations by solving jigsaw puzzles. In _Computer Vision-ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part VI_. Springer, 69-84.
* Paszke et al. (2019) Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. 2019. Pytorch: An imperative style, high-performance deep learning library. _Advances in neural information processing systems_ 32 (2019).
* Pop (2009) Mihai Pop. 2009. Genome assembly reborn: recent computational challenges. _Briefings in Bioinformatics_ 10, 4 (05 2009), 354-366. https://doi.org/10.1093/bib/bbp026 arXiv:https://academic.oup.com/bib/article-pdf/10/4/354/847444/bbp026.pdf
* Radack and Badler (1982) Gerald M Radack and Norman I Badler. 1982. Jigsaw puzzle matching using a boundary-centered polar encoding. _Computer Graphics and Image Processing_ 19, 1 (1982), 1-17.
* Ramesh et al. (2022) Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. 2022. Hierarchical text-conditional image generation with clip latents. _arXiv preprint arXiv:2204.06125_ (2022).
* Rombach et al. (2021) Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. 2021. High-Resolution Image Synthesis with Latent Diffusion Models. (2021). arXiv:cs.CV/2112.10752
* Saharia et al. (2021) Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J Fleet, and Mohammad Norouzi. 2021. Image super-resolution via iterative refinement. _arXiv:2104.07636_ (2021).
* Sarlin et al. (2020) Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich. 2020. SuperGlue: Learning Feature Matching with Graph Neural Networks. In _CVPR_. https://arxiv.org/abs/1911.11763* Sasaki et al. (2021) Hiroshi Sasaki, Chris G. Willcocks, and Toby P. Breckon. 2021. UNIT-DDPM: UNpaired Image Translation with Denoising Diffusion Probabilistic Models. _CoRR_ abs/2104.05358 (2021). arXiv:2104.05358 https://arxiv.org/abs/2104.05358
* Shabani et al. (2022) Mohammad Amin Shabani, Sepidehsadat Hosseini, and Yasutaka Furukawa. 2022. HouseDiffusion: Vector Floorplan Generation via a Diffusion Model with Discrete and Continuous Denoising. _arXiv preprint arXiv:2211.13287_ (2022).
* Shabani et al. (2021) Mohammad Amin Shabani, Weilian Song, Makoto Odamaki, Hirochika Fujiki, and Yasutaka Furukawa. 2021. Extreme Structure from Motion for Indoor Panoramas without Visual Overlaps. In _Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)_. https://aminshabani.github.io/publications/extreme_sfm/pdfs/iccv2021_2088.pdf
* Shan et al. (2023) Wenkang Shan, Zhenhua Liu, Xinfeng Zhang, Zhao Wang, Kai Han, Shanshe Wang, Siwei Ma, and Wen Gao. 2023. Diffusion-Based 3D Human Pose Estimation with Multi-Hypothesis Aggregation. _arXiv preprint arXiv:2303.11579_ (2023).
* Shih and Lu (2018) Huang-Chia Shih and Chien-Liang Lu. 2018. Divide-and-conquer jigsaw puzzle solving. In _2018 IEEE Visual Communications and Image Processing (VCIP)_. IEEE, 1-2.
* Snavely et al. (2006) Noah Snavely, Steven M Seitz, and Richard Szeliski. 2006. Photo tourism: exploring photo collections in 3D. _ACM siggraph_ (2006), 835-846.
* Song et al. (2020) Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. 2020. Score-Based Generative Modeling through Stochastic Differential Equations. _CoRR_ abs/2011.13456 (2020). arXiv:2011.13456 https://arxiv.org/abs/2011.13456
* Sun et al. (2021) Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. 2021. LoFTR: Detector-Free Local Feature Matching with Transformers. _CVPR_ (2021).
* Toler-Franklin et al. (2010) Corey Toler-Franklin, Benedict Brown, Tim Weyrich, Thomas Funkhouser, and Szymon Rusinkiewicz. 2010. Multi-feature matching of fresco fragments. _ACM Transactions on Graphics (TOG)_ 29, 6 (2010), 1-12.
* Wei et al. (2023) Qiuhong Anna Wei, Sijie Ding, Jeong Joon Park, Rahul Sajnani, Adrien Poulenard, Srinath Sridhar, and Leonidas Guibas. 2023. LEGO-Net: Learning Regular Rearrangements of Objects in Rooms. _arXiv preprint arXiv:2301.09629_ (2023).
* Wolfson et al. (1988) Haim Wolfson, Edith Schonberg, Alan Kalvin, and Yehezkel Lamdan. 1988. Solving jigsaw puzzles by computer. _Annals of Operations Research_ 12, 1 (1988), 51-64.
* Wolleb et al. (2021) Julia Wolleb, Robin Sandkuhler, Florentin Bieder, Philippe Valmaggia, and Philippe C. Cattin. 2021. Diffusion Models for Implicit Image Segmentation Ensembles. (2021). arXiv:cs.CV/2112.03145
* Wu et al. (2019) Wenming Wu, Xiao-Ming Fu, Rui Tang, Yuhan Wang, Yu-Hao Qi, and Ligang Liu. 2019. Data-driven interior plan generation for residential buildings. _ACM Transactions on Graphics (TOG)_ 38, 6 (2019), 1-12.
* Yang et al. (2019) Zhenpei Yang, Jeffrey Z. Pan, Linjie Luo, Xiaowei Zhou, Kristen Grauman, and Qixing Huang. 2019. Extreme Relative Pose Estimation for RGB-D Scans via Scene Completion. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_.
* Yang et al. (2020) Zhenpei Yang, Siming Yan, and Qixing Huang. 2020. Extreme relative pose network under hybrid representations. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_. 2455-2464.
* Yi et al. (2018) Kwang Moo Yi, Eduard Trulls, Yuki Ono, Vincent Lepetit, Mathieu Salzmann, and Pascal Fua. 2018. Learning to find good correspondences. In _Proceedings of the IEEE conference on computer vision and pattern recognition_. 2666-2674.
* Zhao et al. (2022) Min Zhao, Fan Bao, Chongxuan Li, and Jun Zhu. 2022. Egsde: Unpaired image-to-image translation via energy-guided stochastic differential equations. _arXiv preprint arXiv:2207.06635_ (2022).
* Zhu et al. (2020)Methods details of our system and competing methods

We benefit from Transformers in our task in two ways. First, Transformers provide the capability of processing sequences with different lengths, which we use to process different number of room layouts/corners in the houses. Second, we utilize the self-attention module of Transformers to create optimal interaction and information-sharing among input tokens. These two features make Transformers an ideal backbone for our model. Our method uses six Transformer encoder blocks, and attention in each block has four heads. We also use an MLP For converting 256D Transformer output to rotation and position (4D). To keep the experiments fair, we use the same architecture for our transformer baselines as much as possible. In the following, we provide details corresponding to each of the baselines.

**Transformer with a raster representation** (TransRaster) uses the raster images to represent the input room layouts/types and the output room positions. Note that this baseline does not handle rotations as explained below. An input room layout is represented as a 20-channel \(256\times 256\) semantic segmentation image, where there are 20 room/door types. The room center is aligned with the center of an image. An output room position is represented as a \(256\times 256\) room occupancy image, which is ideally a translated version of the input room segmentation image at the correct room location. Given an output room occupancy image, we perform an exhaustive search over the possible room translations and find one with the most overlap between the occupancy image and the translated room segmentation image. 3 We use VisionTransformer Dosovitskiy et al. (2020) with a CNN decoder that takes a set of input room segmentation images and produces a set of room occupancy images.

Footnote 3: We could expand the search space with possible room rotations, but rooms are often symmetric. To be simple, we use this baseline only for experiments when ground-truth rotations are given.

In the other word TransRaster uses an encoder part of U-Net, which has 8 down-sampling blocks, converting each input room layout to a feature map of dimension 512. Each feature map (corresponding to a room layout) will become one input token for the Transformer. Input sequences length is equal to the number of rooms in a house, and information is shared among different rooms. We use six Transformer encoder blocks, and attention in each block has four heads. We pass the output of Transformer to a U-Net up-sampling model with eight Up-sampling blocks to change the dimension from 512 to \(256\times 256\).

**Transformer with a vector representation** uses the same backbone as our method; a linear layer converts the 28D input vector (i.e., 2 for the original corner coordinate and 20 for the room/door type one-hot vector) to the 256D feature map, six Transformer encoder blocks, and the attention in each block have four heads. We also use an MLP to convert 256D output embedding to 4D output.

**Diffusion model, one room per node** encodes each node as corresponding to a room instead of a corner in the room. To ease the implementation, we set the maximum number of nodes per room to 20 and we pad extra nodes when the room has less than 20 nodes with 0. We flatten the conditions per room and then use a linear layer to convert it to a 256D embedding vector. Each feature map represents a room and an input token for Transformer, we use the same Transformer as our method. After the Transformer blocks, a linear layer converts 256D output to 4D (i.e., 2 for the position and 2 for the rotation).

**Shabani et al.**Shabani et al. (2021) takes the input layout of each room with the resolution of \(256\times 256\) with the same number of channels as the number of room types to pass each pixel as a one-hot vector of the corresponding room type. We use the same model as Shabani et al. (2021) and change the number of input channels to 11 for RPLAN and 20 for MagicPlan. To generate the arrangement candidates, we use the given room layouts of our dataset to connect doors, while we also use overlap filtering to reduce the number of candidates. Note that our datasets is significantly larger than the one in Shabani et al. (2021), enabling us to randomly select a positive or a negative candidate in each iteration and therefore remove the class imbalance weight used in Shabani et al. (2021). During the training for each house, we randomly select a GT with the label 1 or a faulty candidate with the label [0, 1) based on the number of mismatched doors. During the test, we pass all the possible candidates of each house and select the candidate with the highest score as the final prediction.

Harel et al.2021 proposed a two-step algorithm for CJP. Their method considers two types of constraints to find plausible mates based on the length and angle of different pairs of connections. By estimating the matings hierarchically using these constraints, they approach the problem of finding positions as a multi-body spring-mass system. We utilize the authors' provided implementation4 for comparison with our method. With a test dataset of 1000 crossing-cut puzzles, we restrict the running time of the spring-system algorithm to 2 minutes per puzzle. Furthermore, unlike the provided implementation, we also consider failure cases in the metrics. Regarding the pictorial case, the authors score a candidate mating by extrapolating the images of puzzle pieces and considering the difference of the mean color value on the edges. We do not impose any time limit as we evaluate only on 20 samples.

Footnote 4: https://ficvl.cs.bgu.ac.il/polygonal-puzzle-solving/

## Appendix B Datasets Details and Preprocessing

We normalize the puzzles/floorpls for each task and dataset by scaling them to fit within a \(1\times 1\) square, and we also resize all corresponding images to dimensions of \(256\times 256\) in the case of pictorial CJP. While this normalization process does not introduce any essential additional information during testing in CJP and VJP, it could potentially enables the network to cheat in RLA, as the longer extent of arranged floorpls is always fixed to \(1\). To address this issue, during testing in RLA, we apply a random scaling factor in the range of [0.8, 1.0] to the room shapes of each house. In the subsequent sections, we provide a detailed description of each dataset. In the following, we provide additional statistics for our floorplan datasets.

The Voronoi Jigsaw Puzzle dataset consists of 200k training puzzles and 1k testing puzzles. These puzzles were created by randomly selecting 3 to 15 points, The individual pieces of the puzzles were obtained by extracting the Voronoi cells corresponding to these points. There are 1,066, 14,033, 23,715, 20,279, 16,073, 15,235, 16,428, 15,018, 16,318, 15,096, 16,487, 16,233, and 15,670 puzzles with 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, and 15 pieces respectively. Each piece has a minimum, maximum, and average of 3, 20, and 4.51 corners respectively. The minimum, maximum, and average number of corners per puzzle are 10, 93, and 42.24.

Cross-cut Jigsaw Puzzle (CJP) are consist of 100k training and 1k testing puzzles, where each one were generated using Harel and Ben-Shahar (2021) method which generate a convex polygon and cuts it by 3 to 5 lines. There are 1719, 6046, 15854, 14521, 6905, 10929, 12065, 8361, 6521, 8192, 7663, 4642, 1508, 73, and 1 puzzles with 3, to 18 pieces respectively. Each piece has a minimum,

\begin{table}
\begin{tabular}{l|c|c|c|c|c|c|c|c|c} \hline \hline Room Type & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & All \\ \hline Master bedroom & 0.20 & 0.26 & 0.29 & 0.32 & 0.39 & 0.49 & 0.49 & 0.53 & 0.34 \\ Living room & 0.52 & 0.56 & 0.59 & 0.65 & 0.71 & 0.75 & 0.79 & 0.79 & 0.65 \\ Kitchen & 0.42 & 0.47 & 0.52 & 0.59 & 0.68 & 0.71 & 0.76 & 0.79 & 0.59 \\ Bathroom & 0.54 & 0.70 & 0.85 & 0.96 & 1.12 & 1.28 & 1.33 & 1.47 & 0.96 \\ Toilet & 0.07 & 0.11 & 0.15 & 0.22 & 0.22 & 0.25 & 0.27 & 0.26 & 0.18 \\ Corridor & 0.07 & 0.12 & 0.15 & 0.19 & 0.25 & 0.32 & 0.37 & 0.45 & 0.21 \\ Closet & 0.13 & 0.18 & 0.22 & 0.32 & 0.48 & 0.68 & 0.92 & 1.22 & 0.41 \\ Hall & 0.35 & 0.55 & 0.68 & 0.77 & 0.85 & 0.91 & 0.98 & 1.08 & 0.73 \\ Laundry room & 0.05 & 0.05 & 0.05 & 0.07 & 0.10 & 0.13 & 0.18 & 0.23 & 0.09 \\ Bedroom & 0.34 & 0.69 & 1.08 & 1.32 & 1.51 & 1.74 & 1.93 & 2.10 & 1.23 \\ Balcony & 0.05 & 0.08 & 0.16 & 0.32 & 0.40 & 0.48 & 0.56 & 0.64 & 0.29 \\ Dining room & 0.13 & 0.12 & 0.12 & 0.14 & 0.17 & 0.19 & 0.22 & 0.25 & 0.15 \\ Private office & 0.00 & 0.01 & 0.02 & 0.05 & 0.05 & 0.07 & 0.08 & 0.10 & 0.05 \\ Den & 0.05 & 0.05 & 0.06 & 0.7 & 0.09 & 0.11 & 0.12 & 0.12 & 0.08 \\ Storage & 0.00 & 0.01 & 0.01 & 0.02 & 0.02 & 0.02 & 0.03 & 0.03 & 0.02 \\ Others & 0.00 & 0.01 & 0.01 & 0.02 & 0.03 & 0.04 & 0.04 & 0.07 & 0.03 \\ Doors & 2.84 & 3.82 & 4.82 & 5.43 & 6.92 & 8.02 & 6.10 & 10.18 & 5.90 \\ \hline \hline \end{tabular}
\end{table}
Table 5: MagicPlan dataset consists of floorpls with 3 to 10 rooms. The table shows average number of rooms with a specific room type based on the total number of rooms in the house.

maximum, and average of 3, 13, and 4.47 corners respectively. The minimum, maximum, and average number of corners per puzzle are 16, 76, and 41.99.

MagicPlan dataset consists of roughly 98K houses/apartments, which we divide into 93K training and 5K testing samples. The number of rooms in a house ranges from 3 to 10. Concretely, 11661, 16322, 19171, 17582, 13200, 9649, 6780, and 4415 houses contain 3, 4, 5, 6, 7, 8, 9, and 10 rooms, respectively. The minimum and maximum numbers of corners in a house are 12 and 182. Table 5 shows average number of rooms with a specific room type based on the total number of rooms in the house.

In the RPLAN dataset, we divide 60K samples in RPLAN to 55K train and 5K test. The number of rooms in a house ranges from 3 to 8. Concretely 99, 582, 5083, 19551, 21921, and 13235 houses contain 3, 4, 5, 6, 7, and 8 rooms, respectively.

## Appendix C Additional ablation studies

### Additional ablation studies on room layout arrangement

Figure 13 shows the raw estimated position information at each room/door corner before the room-wise averaging. Since the ground-truth has the same pose parameters for all corners in a room/door, the network learns to produce consistent parameters. Figure 14 shows five pose estimation results by our system while varying the initial noise \(x_{T}\). While there are minor differences, the overall room arrangements are similar and close to the ground-truth, indicating that the Diffusion model is capable of producing consistent results given enough constraints as a pose estimation system, as opposed to a generative model whose original goal is to create a diverse set of answers.

\begin{table}
\begin{tabular}{l|c|c|c|c|c|c|c|c} \hline \hline Dataset & \multicolumn{2}{c}{Small RPLAN} & \multicolumn{2}{c}{Full RPLAN} & \multicolumn{2}{c}{Small MagicPlan} & \multicolumn{2}{c}{Full JigsawPlan} \\ \hline Metric & MPE (\(\downarrow\)) & GED (\(\downarrow\)) & MPE (\(\downarrow\)) & GED (\(\downarrow\)) & MPE (\(\downarrow\)) & GED (\(\downarrow\)) & MPE (\(\downarrow\)) & GED (\(\downarrow\)) \\ \hline Shabani _et al_. & 17.6 & 1.0 & ✗ & ✗ & 32.2 & 1.1 & ✗ & ✗ \\ TransRaster & 13.9 & 1.2 & 15.7 & 2.1 & 36.1 & 2.1 & 41.9 & 4.1 \\ TransVector & 12.9 & 1.1 & 13.9 & 2.0 & 37.7 & 1.9 & 42.8 & 4.0 \\ Ours & **4.6\(\pm 0.7\)** & **0.4\(\pm 0.0\)** & **5.4\(\pm 0.7\)** & **0.6\(\pm 0.0\)** & **17.5\(\pm 0.8\)** & **1.0\(\pm 0.4\)** & **27.9\(\pm 0.7\)** & **2.7\(\pm 0.5\)** \\ \hline \hline \end{tabular}
\end{table}
Table 6: Main quantitative results with two metrics: Positional Error (MPE) and Graph Editing Distance (GED). This table show a case where the ground-truth rotations are given, as TransRaster baseline cannot handle rotations. Small RPLAN (resp. Small MagicPlan) is a subset of the corresponding full dataset, consisting of houses with at most 6 rooms. The small datasets are created for Shabani _et al_., which is not scalable to many rooms. Our method is stochastic and shows both the mean and the standard deviation.

Figure 9: Visualization of predicted layouts at step “t”s. At t=1000, position parameters at each corner are initialized by a Gaussian noise, and at t=0, there is the final predicted layout. The top row shows the predicted layout without averaging/voting, and the bottom row shows with averaging/voting. To make it more clear, we show doors by their corners.

#### c.1.1 Additional ablation on RPLAN

The main paper shows the ablation studies on the MagicPlan dataset in case of room layout arrangment task. This part of supplementary will present the same study results on RPLAN dataset. Table 7 shows the impact of our attention module and door matching loss on performance and Table 8 shows the impact of noise in the room type and door detection on our performance, although there is a performance drop, our method still works better than the competing methods.

\begin{table}
\begin{tabular}{c|c|c|c|c} \hline \hline P-SA & G-SA & \(L_{\text{match}}\) & MPE \((\downarrow)\) & GED \((\downarrow)\) \\ \hline  & ✓ & & 25.6 & 1.6 \\ ✓ & ✓ & & 24.2 & 1.5 \\ ✓ & & Doors & 36.9 & 2.4 \\  & ✓ & Doors & 22.1 & 1.1 \\ ✓ & ✓ & All Corners & 10.7 & 0.9 \\ ✓ & ✓ & Doors & 10.5 & 0.9 \\ \hline \hline \end{tabular}
\end{table}
Table 7: Co attention mechanisms (P-SA, G-SA) and the door matching loss (\(L_{\text{match}}\)). Full RPLAN is used. ✓ indicates the feature being used. In case of \(L_{\text{match}}\) “Doors” means matching loss has been applied only on door corners and “All corners” means matching loss has been applied to all corners including door corners.

Figure 10: Qualitative evaluations of our approach against the three competing methods. The top two rows are from Small MagicPlan. The bottom two rows is from Small RPLAN. The GT rotations are given for all the cases to enable comparisons with all the methods.

\begin{table}
\begin{tabular}{c|c|c|c|c|c} \hline \hline \multicolumn{2}{c}{Train} & \multicolumn{2}{c|}{Test} & \multirow{2}{*}{MPE\((\downarrow)\)} & \multirow{2}{*}{GED \((\downarrow)\)} \\ \cline{2-2} \cline{6-6} R-Type & & & & & \\ \hline ✓ & ✓ & & ✓ & 17.3 & 1.4 \\  & ✓ & & ✓ & 16.4 & 1.5 \\ ✓ & ✓ & ✓ & & 15.1 & 1.9 \\ ✓ & ✓ & ✓ & & 14.3 & 1.9 \\ ✓ & ✓ & ✓ & ✓ & 10.5 & 0.9 \\ \hline \hline \end{tabular}
\end{table}
Table 8: Effects of the room-type (R-type) and the Door information. Full RPLAN is used. ✓ indicates the information being used. When a room-type is not used, we set a zero vector as a room-type one-hot vector. When the door information is not used, we do not pass the door-corner nodes to the network.

### Additional ablation studies on puzzle solving

We have provided additional qualitative results of our method in Figure 15 and Figure 16 including noisy samples or samples with missing or duplicate pieces. In case of missing and duplicate experiment, we repeat (remove) each piece with a probability of \(10\%\). Table 9 presents the evaluation metrics of missing and duplicate experiments.

#### c.2.1 Pictorial Cross-cut Jigsaw Puzzle

To enhance the integration of image information into our pictorial puzzle diffusion models, we employed a two-step approach. Firstly, we pretrained an auto-encoder utilizing the puzzle pieces. This auto-encoder served as the image embedder for our diffusion model, enabling the conversion of each puzzle into a compact 128D feature vector.

The pretraining process involved training the model to downsample an input image of dimensions \(3\times 256\times 256\) to a compressed representation of size \(32\times 2\times 2\) within the encoder, and subsequently reconstructing the original image size in the decoder. We employed the mean squared error

Figure 11: Qualitative evaluations of our method for Full MagicPlan dataset without GT rotations top two rows, and Full RPLAN dataset without GT rotations bottom two rows. We show edges and corners here to show overlaps and noisy annotations more clear.

(MSE) loss function during training. However, to focus our model's attention on learning the texture features, given that the diffusion model already captured the geometry features, we applied the loss function exclusively to the pixels within the puzzle piece.

By adopting this selective application of the loss function, we prioritize the acquisition of texture-based details, as the geometric characteristics are already embedded within the diffusion model.

Quantitatively, we also evaluated our method on the full Cross-cut dataset to measure the effectiveness of the pictorial information compared to apictorial scenario. We found that the model converges faster when using pictorial information while it achieves slightly better overlap score of 0.9417 compared to 0.9398 in apictorial scenario. Figure 17 shows additional qualitative results of our method compared to Harel _et al_. Harel and Ben-Shahar (2021).

Figure 14: A diffusion model is stochastic and produces a different result every time. The middle rows show five different pose estimation results. The top (resp. bottom) is from Full RPLAN (resp. Full MagicPlan) dataset.

\begin{table}
\begin{tabular}{c c|c c c|c c c} \hline \hline  & & \multicolumn{3}{c}{Cross-cut} & \multicolumn{3}{c}{Voronoi} \\ \cline{3-8} Missing & Duplicate & Overlap (\(\uparrow\)) & Precision (\(\uparrow\)) & Recall (\(\uparrow\)) & Overlap (\(\uparrow\)) & Precision (\(\uparrow\)) & Recall (\(\uparrow\)) \\ \hline ✓ & - & 0.88 & 0.92 & 0.82 & 0.68 & 0.68 & 0.56 \\ - & ✓ & 0.92 & 0.97 & 0.88 & 0.67 & 0.71 & 0.57 \\ - & - & 0.94 & 0.97 & 0.91 & 0.70 & 0.78 & 0.60 \\ \hline \hline \end{tabular}
\end{table}
Table 9: Effects of the Missing or Duplicate pieces in puzzle solving problem. ✓ indicates it if missing or duplicate piece were presented during test time. In training time we do not have duplicate or missing piece presented to show our model robustness to unseen noise during test.

Figure 15: Additional qualitative results of Voronoi jigsaw puzzle are presented in four different setups: 1) No noise, 2) Noise level 2, 3) Missing piece, and 4) Duplicate piece (D indicates the duplicated pieces).

Figure 16: Additional qualitative results of Cross-cut jigsaw puzzle are presented in four different setups: 1) No noise, 2) Noise level 2, 3) Missing piece, and 4) Duplicate piece (D indicates the duplicated pieces).

Figure 17: Additional qualitative results of pictorial Cross-cut jigsaw puzzle compared to Harel _et al_. Harel and Ben-Shahar (2021).