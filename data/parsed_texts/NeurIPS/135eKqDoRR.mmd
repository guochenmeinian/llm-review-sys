[MISSING_PAGE_FAIL:1]

predicted pretrained labels of two images from downstream tasks: a 'Dog' image from CIFAR10 [30] and an 'Osteosperm' image from Flowers102 [41]. For the 'Dog' image, multiple pretrained labels like 'Chihuahua', 'Basenji'-_subclasses_ of dogs-receive high logits. Similarly, for the 'Osteosperm' image, pretrained labels such as 'Sea Urchin', 'Daisy', which _share similar features_, also score high. Despite these connections, the one-to-one LM retains only the label with the highest logit, suggesting the _probabilities of other related labels are ignored_. Figure 0(b) shows the frequency distribution of the predicted pretrained labels and the ground-truth downstream labels of downstream samples, with the diagonal representing the results derived from one-to-one LM. The 'Automobile' class from CIFAR10, for example, can no longer be paired with the optimal pretrained label 'Moving Van', which has already been greedily mapped to the label 'Truck', implying _suboptimal label assignments_.

The above observation motivates us to go beyond these binary mappings. In Section 3, we replace the one-to-one LM function with a probabilistic LM matrix. Each matrix element is a real number that quantifies the relationship between a pretrained label and a downstream label, updated iteratively during VR optimization. This allows predictions for each downstream sample to consider diverse contributions from all pretrained labels, enabling a flexible many-to-many mapping strategy.

Specifically, we present _Bayesian-guided label mapping_ (BLM) in Section 4, which assigns values to elements in the probabilistic LM matrix based on Bayesian conditional probabilities, derived from the joint distribution of the predicted pretrained labels on downstream tasks and the ground-truth downstream labels. We further extend BLM to BLM+, which aggregates _top-\(K\) predicted probabilities_ instead of using a single predicted label when estimating the joint distribution, accounting for uncertainty in the predictions. We also provide a theoretical analysis that justifies the potential of probabilistic many-to-many LM to outperform deterministic one-to-one LM.

To show the effectiveness of BLM, experiments are conducted on 12 widely used datasets, with BLM and BLM+ being applied to different input VR methods-padding and watermarking-on pretrained ResNet and ResNeXt (see Section 5). The ablation study and parameter analysis are also included, along with visualization results and discussions of why VR is effective. BLM and BLM+ are also applied to vision-language models (see Appendix L) to demonstrate their general applicability.

In summary, both theoretical analysis and empirical findings (Tables 1-2) provide compelling evidence that BLM and BLM+, grounded in Bayesian principles, facilitate VR to leverage pretrained knowledge for diverse downstream tasks. Beyond performance improvement, BLM and BLM+ offer insights into understanding the effectiveness of VR (Figures 3-4): revealing the relations between pretrained and downstream label spaces may guide future studies into more interpretable VR methods.

## 2 Related Works

**Model Reprogramming.** Among cutting-edge transfer learning methods (see Appendix B), model reprogramming introduces an efficient learning framework for adapting models pretrained on large

Figure 1: Drawbacks of one-to-one LM from the perspectives of (a) individual images and (b) the entire dataset. An ImageNet-pretrained classifier is reused in downstream tasks. In (a), images ‘Dog’ and ‘Osteosperm’ from downstream tasks are mapped into only one pretrained label, respectively, ignoring other probabilities. In (b), the distribution of [predicted pretrained label \(y^{\mathrm{S}}\), ground-truth downstream label \(y^{\mathrm{T}}\)] pairs reveals the existence of suboptimal solutions, where ‘Automobile’ cannot be paired with the optimal pretrained label ‘Moving Van’, which has already been mapped to ‘Truck’.

scale data to downstream tasks constrained by limited resources [7]. By changing the input or output interfaces (i.e., input or output space) purposefully, while preserving the integrity of the pretrained model, knowledge can be reused on new tasks, sidestepping exhaustive finetuning of the model.

Many recent studies focus on repurposing diverse pretrained models for downstream tasks, including pretrained vision models [1, 4, 38, 48, 49, 52] such as ResNet [17] and ViT [11], language models [15, 50] such as BERT [24], acoustic [60, 21, 61] and graph models [23]. Such repurposing encompasses several types: cross-modal (e.g., from voice to time-series [61], or vision to text [38]), different tasks within the same modality (e.g., from image classification to out-of-distribution detection [52]), and different domains within the same task (e.g., from ImageNet to medical images [48]).

**Prompting and Input VR.** Prompting incorporates meticulously designed prompts (additional parameters) into pretrained models with specific architectures to utilize pretrained models in downstream tasks. Leveraging ViT, VPT [22] integrates prompts alongside image embeddings, while EEVPT [16] further enhances VPT by embedding parameters within self-attention layers. TransHP [53] additionally learns prompt tokens to encode coarse image categories. In vision-language models such as CLIP [45], besides text-prompting methods such as CoOP [68] and CoCoOP [67], models like MaPLe [25] also learn layer-specific mapping functions that bridge vision and text.

Slightly different from prompt tuning, input VR offers a model-agnostic approach by introducing trainable noise to images in the input space before feeding those images into pretrained models. This process does not impact the visual effect of the images. Two prevalent techniques are padding-based VR and watermarking-based VR. Padding-based models [4, 12, 48, 49] preserve the integrity of images while introducing trainable noise patterns to the outer frames around images, whereas watermarking-based models [1, 3, 42, 52] train noise patterns that overlay the images.

**Output Mapping for VR.** Because pretrained labels and downstream labels are often different, relying solely on input VR may be insufficient for downstream tasks. To bridge this gap, output mapping methods are introduced to facilitate alignment between different label spaces. Mainstream approaches include deep learning-based and statistical inference-based (i.e., gradient-free) LM methods. Deep learning-based methods insert a learnable fully connected layer to connect pretrained and downstream labels [27, 49]. However, for tasks with large label spaces, the additional model layers would result in extra training costs, potentially canceling the efficiency advantages of VR.

As for gradient-free LM methods, _random label mapping_ (RLM) [12] establishes mappings between an equal number of randomly selected pretrained labels and downstream labels, masking out other unused ones. _Frequent label mapping_ (FLM) [48] selects optimal one-to-one mappings using a greedy approach based on the number of pairs between pretrained and downstream labels. _Iterative label mapping_ (ILM) [4] extends FLM by updating mappings at each epoch, refining the output label mapping as input VR patterns evolve. As depicted in Figure 1, these one-to-one mappings _overlook potential probabilities_ and lead to _suboptimal solutions_. We propose BLM to address these issues.

## 3 Problem Formulation

**Problem Setup**. Consider a pretrained task with input and output variables \(X^{\mathrm{S}}\) and \(Y^{\mathrm{S}}\), jointly defined over \(\mathcal{X}^{\mathrm{S}}\times\mathcal{Y}^{\mathrm{S}}\), where \(\mathcal{X}^{\mathrm{S}}\subseteq\mathbb{R}^{d_{\mathrm{S}}}\) has the input dimensionality \(d_{\mathrm{S}}\) and \(\mathcal{Y}^{\mathrm{S}}=\{1,\dots,k_{\mathrm{S}}\}\). We have a pretrained classifier \(f_{\mathrm{pre}}:\mathcal{X}^{\mathrm{S}}\mapsto\mathbb{R}^{k_{\mathrm{S}}}\) producing a logits vector \(f_{\mathrm{pre}}(x^{\mathrm{S}})\in\mathbb{R}^{k_{\mathrm{S}}}\) for each \(x^{\mathrm{S}}\in\mathcal{X}^{\mathrm{S}}\). For a downstream task with input and output variables \(X^{\mathrm{T}}\) and \(Y^{\mathrm{T}}\) defined over \(\mathcal{X}^{\mathrm{T}}\times\mathcal{Y}^{\mathrm{T}}\), where \(\mathcal{X}^{\mathrm{T}}\subseteq\mathbb{R}^{d_{\mathrm{T}}}\) has the input dimensionality \(d_{\mathrm{T}}\) and \(\mathcal{Y}^{\mathrm{T}}=\{1,\dots,k_{\mathrm{T}}\}\), VR seeks to adapt \(f_{\mathrm{pre}}\) to the downstream task without modifying its parameters. To achieve this, VR introduces two functions: 1) input VR function \(f_{\mathrm{in}}(\cdot|\theta):\mathcal{X}^{\mathrm{T}}\mapsto\mathcal{X}^{ \mathrm{S}}\) with learnable parameters \(\theta\) that converts downstream inputs for compatibility with \(f_{\mathrm{pre}}\); and 2) output LM function \(f_{\mathrm{out}}^{\omega}(\cdot):\mathbb{R}^{k_{\mathrm{S}}}\mapsto\mathbb{R}^ {k_{\mathrm{T}}}\) that aligns the output logits of \(f_{\mathrm{pre}}\) with the downstream label space by a transformation \(\omega\). Concretely, given a training dataset \(\mathcal{D}^{\mathrm{T}}=\{(x_{i}^{\mathrm{T}},y_{i}^{\mathrm{T}})\}_{i=1}^{n}\) with \(n\) training samples drawn from \(\mathcal{X}^{\mathrm{T}}\times\mathcal{Y}^{\mathrm{T}}\) for the downstream task, the training objective of VR can be formulated as:

\[\min_{\theta\in\Theta}\frac{1}{n}\sum_{i=1}^{n}\ell(y_{i}^{\mathrm{T}},(f_{ \mathrm{out}}^{\omega}\circ f_{\mathrm{pre}}\circ f_{\mathrm{in}})(x_{i}^{ \mathrm{T}};\theta)),\] (1)

where \(\ell\) is a loss function, and \(f_{\mathrm{out}}^{\omega}\circ f_{\mathrm{pre}}\circ f_{\mathrm{in}}\) denotes the composition of input VR, pretrained model and output LM. In this study, we focus on _gradient-free_ LM, where \(f_{\mathrm{out}}^{\omega}\) does not introduce additional trainable parameters but strategically leverages \(f_{\mathrm{in}}\) and \(f_{\mathrm{pre}}\) to determine \(\omega\).

**Modeling Existing LM.** As mentioned, \(f^{\omega}_{\rm out}\) serves to find a mapping between each \(y^{\rm S}\in\mathcal{Y}^{\rm S}\) and \(y^{\rm T}\in\mathcal{Y}^{\rm T}\). This can be achieved by constructing an output label transformation \(\omega\) such that for each downstream sample \(x_{i}^{\rm T}\), its label \(\hat{y}_{i}^{\rm T}\) is predicted by \(\arg\max\text{softmax}(\hat{y}_{i}^{\rm T})\), with:

\[\hat{y}_{i}^{\rm T}\equiv\begin{bmatrix}\hat{y}_{i}^{\rm 1}\\ \vdots\\ \hat{y}_{i}^{\rm k_{T}}\end{bmatrix}=f(x_{i}^{\rm T})^{\top}\cdot\omega=\begin{bmatrix} f(x_{i}^{\rm T})_{1}&\ldots&f(x_{i}^{\rm T})_{k_{\rm S}}\end{bmatrix} \begin{bmatrix}\omega_{1,1}&\ldots&\omega_{1,k_{\rm T}}\\ \vdots&\ddots&\vdots\\ \omega_{k_{\rm S},1}&\ldots&\omega_{k_{\rm S},k_{\rm T}}\end{bmatrix},\] (2)

where \(f(x_{i}^{\rm T})\) is shorthand for \((f_{\rm pre}\circ f_{\rm in})(x_{i}^{\rm T};\theta)\). \(\omega\) can be updated iteratively [4] with input VR. A deterministic one-to-one relation between \(\mathcal{Y}^{\rm S}\) and \(\mathcal{Y}^{\rm T}\) implies only a _single_ "correct" \(y^{\rm S}\in\mathcal{Y}^{\rm S}\) exists for each \(y^{\rm T}\in\mathcal{Y}^{\rm T}\). Formally, \(\omega\) in Eq. (2) is a binary matrix, where just a _single_ element \(\omega_{j,k}\) is set to 1 in each column of \(\omega\) (i.e., \(\omega\in\{0,1\}^{k_{\rm S}\times k_{\rm T}}\) satisfying \(\sum_{j=1}^{k_{\rm S}}\omega_{j,:}=1\)).

**Our Probabilistic LM.** Considering aforementioned drawbacks of one-to-one mappings, we propose a probabilistic LM for VR, assigning real values to all elements in \(\omega\) (i.e., \(\omega\in[0,1]^{k_{\rm S}\times k_{\rm T}}\) satisfying \(\sum_{j=1}^{k_{\rm S}}\omega_{j,:}=1\)). Each element \(\omega_{y^{\rm S},y^{\rm T}}\) quantifies the relationship between \(y^{\rm S}\in\mathcal{Y}^{\rm S}\) and \(y^{\rm T}\in\mathcal{Y}^{\rm T}\). This acknowledges contributions from all pretrained labels for the prediction of downstream samples. The flexible many-to-many LM implies the inherent complexity in label correspondence. In Section 4, we investigate how to assign values to our probabilistic LM based on Bayes' theorem.

## 4 Bayesian-guided Probabilistic Label Mapping (BLM)

### Method Demonstration

**Interpreting \(p(Y^{\rm T}|X^{\rm T})\)**. The objective of VR is to maximize \(p(Y^{\rm T}|X^{\rm T})\) defined over the downstream task space. By using the law of total probability, we can express \(p(Y^{\rm T}|X^{\rm T})\) as

\[p(Y^{\rm T}|X^{\rm T})=\sum\nolimits_{y^{\rm S}\in\mathcal{Y}^{\rm S}}p(Y^{\rm S }=y^{\rm S}|X^{\rm T})\,p(Y^{\rm T}|Y^{\rm S}=y^{\rm S},X^{\rm T}).\] (3)

Mirroring the structure of Eq. (2), Eq. (3) enables us to estimate \(p(Y^{\rm T}|X^{\rm T})\) using training data \(\mathcal{D}^{\rm T}\),2

Footnote 2: This estimation is similar to [40], see Appendix B for more discussion.

\[\hat{p}(Y^{\rm T}|X^{\rm T})=\frac{1}{n}\sum_{i=1}^{n}\left(\sum_{y^{\rm S} \in\mathcal{Y}^{\rm S}}\underbrace{p(Y^{\rm S}=y^{\rm S}|X^{\rm T}=x_{i}^{\rm T })}_{\boxed{\text{input VR}:(f_{\rm pre}\circ f_{\rm in})(x_{i}^{\rm T},\theta) }}\underbrace{p(Y^{\rm T}=y_{i}^{\rm T}|Y^{\rm S}=y^{\rm S},X^{\rm T}=x_{i}^{ \rm T})}_{\boxed{\text{output LM}:f^{\omega}_{\rm out}^{\rm S}}}\right),\] (4)

where \(\text{\textcircled{\text{\text{\text{\text{\textlbrack{\text{\textlbrack{ \text{\textlbrack{\textlbrack{\textlbracklbrack{\texttextlbracklbrack{ \For \(p(Y^{\rm S}=y^{\rm S}|X^{\rm T})\), in addition to summing up Eq. (6) for \(y^{\rm T}\in\mathcal{Y}^{\rm T}\), we add Laplace smoothing coefficient \(\lambda\) to ensure the denominator of Eq. (5) being non-zero, with \(k_{\rm S}\) being the size of \(\mathcal{Y}^{\rm S}\):

\[\hat{p}_{\rm BLM}(Y^{\rm S}=y^{\rm S}|X^{\rm T})=\frac{\sum_{y^{\rm T}\in \mathcal{Y}^{\rm T}}\sum_{i=1}^{n}\mathds{1}\{y^{\rm T}_{i}=y^{\rm T}\}\cdot \mathds{1}\{\hat{y}^{\rm S}_{i}=y^{\rm S}\}+\lambda}{n+k_{\rm S}\cdot\lambda}= \frac{\sum_{i=1}^{n}\mathds{1}\{\hat{y}^{\rm S}_{i}=y^{\rm S}\}+\lambda}{n+k_{ \rm S}\cdot\lambda}.\] (7)

Substituting Eq. (7) and Eq. (6) back to Eq. (5) yields the estimation of \(\hat{\omega}_{y^{\rm S},y^{\rm T}}\) to be \(\hat{p}_{\rm BLM}(Y^{\rm T}=y^{\rm T}|Y^{\rm S}=y^{\rm S},X^{\rm T})\). After column-wise sum normalization of \(\hat{\omega}_{y^{\rm S},y^{\rm T}}\) to satisfy \(\sum_{j=1}^{k_{\rm S}}\omega_{j,\cdot}=1\) (as formulated in Section 3), we obtain the final probabilistic LM, denoted as \(\omega_{\rm BLM}\).

**BLM+.** Recall that BLM estimates \(p(Y^{\rm T}=y^{\rm T},Y^{\rm S}=y^{\rm S}|X^{\rm T})\) by frequency-counting based on a single _most likely_ predicted label. However, this strategy disregards other high-ranking predictions that could offer valuable information. Thus, we introduce BLM+, an extension of BLM that considers top-\(K\)_predicted probabilities_ of the pretrained model for the estimation of \(p(Y^{\rm T}=y^{\rm T},Y^{\rm S}=y^{\rm S}|X^{\rm T})\). Rather than relying solely on the tally, BLM+ aggregates _probabilities_ for samples where \(y^{\rm S}\) ranks among the top-\(K\) predictions. In this way, BLM+ acknowledges the uncertainty in \(f(x^{\rm T}_{i})\) and exploits other potential predictions, providing more robust estimations.

Let \(\mathcal{Y}^{\rm S}_{K,i}\equiv\{y^{\prime}|\arg\max_{y_{1},\ldots,y_{K}}f(x^{ \rm T}_{i})_{y^{\prime}}\}\) denote the set of the top-\(K\) predicted pretrained labels for input \(x^{\rm T}_{i}\), and \(\hat{p}(y^{\rm S}|x^{\rm T}_{i})\equiv(\mathrm{softmax}\circ f)(x^{\rm T}_{i}) _{y^{\rm S}}\) denote the predicted probability for any \(y^{\rm S}\in\mathcal{Y}^{\rm S}\) given \(x^{\rm T}_{i}\). Then, within the BLM+ strategy, the joint density is approximated3 as:

Footnote 3: Note that this approximation is not normalized, and thus, is not strictly equivalent to the true probability.

\[\hat{p}_{\rm BLM_{+}}(Y^{\rm T}=y^{\rm T},Y^{\rm S}=y^{\rm S}|X^{\rm T})=\frac {\sum_{i=1}^{n}\mathds{1}\{y^{\rm T}_{i}=y^{\rm T}\}\cdot\hat{p}(y^{\rm S}|x^{ \rm T}_{i})\cdot\mathds{1}\{y^{\rm S}\in\mathcal{Y}^{\rm S}_{K,i}\}}{n}.\] (8)

Similar to BLM, with the Laplace smoothing coefficient being \(\lambda\) and the size of \(\mathcal{Y}^{\rm S}\) being \(k_{\rm S}\), \(p(Y^{\rm S}=y^{\rm S}|X^{\rm T})\) can be expressed by applying BLM+ as:

\[\hat{p}_{\rm BLM_{+}}(Y^{\rm S}=y^{\rm S}|X^{\rm T})=\frac{\sum_{i=1}^{n} \hat{p}(y^{\rm S}|x^{\rm T}_{i})\cdot\mathds{1}\{y^{\rm S}\in\mathcal{Y}^{\rm S }_{K,i}\}+\lambda}{n+k^{\rm S}\cdot\lambda}.\] (9)

Combining Eq. (9) and Eq. (8) with Eq. (5), and going through all \(y^{\rm T}\in\mathcal{Y}^{\rm T}\) and \(y^{\rm S}\in\mathcal{Y}^{\rm S}\), we obtain the full BLM+ estimation as \(\omega_{\rm BLM_{+}}\) after column-wise sum normalization of \(\hat{\omega}_{y^{\rm S},y^{\rm T}}\), similar to BLM. In practice, we set \(K=\lfloor\alpha\cdot k_{\rm T}\rfloor\), with ratio \(\alpha\) being a hyper-parameter that decides \(K\) based on the size of downstream label space \(k_{\rm T}\).

**Pipeline and Learning Strategy.** The learning of BLM and BLM+ allows for seamless integration into existing VR pipelines. It is model-agnostic (e.g., pretrained ResNet or ResNeXt) and compatible with all input VR methods (e.g., watermarking or padding). Figure 2 illustrates the learning strategy in detail. Besides, the learning pipeline of BLM is shown in Algorithm 1, while that of BLM+ is shown in Algorithm 2. The completed pseudocode for all LM methods (RLM, FLM, ILM, BLM, BLM+) and a more detailed discussion of involved matrix operations are in Appendix D.

Figure 2: Learning strategy of BLM and BLM+. First, input images, incorporated with VR watermarking or padding patterns, are fed into a fixed pretrained model to obtain logits and predicted labels. Then, the true labels (of \(y^{\rm T}\)) and predicted labels (of \(y^{\rm S}\)) are used to estimate \(\omega_{\rm BLM}\) or \(\omega_{\rm BLM_{+}}\). Next, using \(\omega_{\rm BLM}\) or \(\omega_{\rm BLM_{+}}\) that reweights output logits of pretrained models for the downstream labels, the predicted results can be derived. Finally, backpropagation is performed to update the input VR.

The iterative process of learning \(\omega_{\mathrm{BLM}},\omega_{\mathrm{BLM}+}\) comprises these four steps: 1) Input images, with VR patterns, are fed into the fixed pretrained model to obtain output logits and predicted pretrained labels. 2) BLM and BLM+ replace previous LM (e.g., RLM, FLM or ILM) to estimate \(\omega\). 3) The initial logits are reweighted using \(\omega_{\mathrm{BLM}}\) or \(\omega_{\mathrm{BLM}+}\), yielding refined predictions for downstream labels. 4) Loss functions (e.g., cross-entropy) and backpropagation are employed to update the input VR.

### Theoretical Analysis

Furthermore, we include a justification of why probabilistic many-to-many LM (e.g., BLM and BLM+) should be favored over deterministic one-to-one LM (e.g., RLM, FLM and ILM). Define the label spaces \(\mathcal{Y}^{\mathrm{S}}=\{0,1\}\) and \(\mathcal{Y}^{\mathrm{T}}=\{0,1\}\) as binary sets4. Consider the set of potential LM functions \(\mathcal{F}_{\mathrm{lm}}=\{f_{\mathrm{lm}}:\mathcal{Y}^{\mathrm{S}}\to \mathcal{Y}^{\mathrm{T}}\}\), including each function \(f_{\mathrm{lm}}(y^{\mathrm{S}})\in\{y^{\mathrm{T}},1-y^{\mathrm{T}}\}\). For any \(f_{\mathrm{lm}}\in\mathcal{F}_{\mathrm{lm}}\), the expected accuracy of \(f_{\mathrm{lm}}\) regarding the entire downstream label space is defined as5:

Footnote 4: This analysis focuses on the binary setting for simplicity.

\[\mathrm{Acc}(f_{\mathrm{lm}})=\mathbb{E}_{y^{\mathrm{T}}\in\mathcal{Y}^{ \mathrm{T}}}\left[\sum_{y^{\mathrm{S}}\in\mathcal{Y}^{\mathrm{S}}}p(y^{\mathrm{ S}})\cdot p\left(f_{\mathrm{lm}}(y^{\mathrm{S}})=y^{\mathrm{T}}|y^{\mathrm{S}} \right)\right],\] (10)

where \(p(y^{\mathrm{S}})\) is the marginal distribution of the pretrained labels and \(p\left(f_{\mathrm{lm}}(y^{\mathrm{S}})=y^{\mathrm{T}}|y^{\mathrm{S}}\right)\) is the conditional probability that \(f_{\mathrm{lm}}\) correctly predicts a downstream label \(y^{\mathrm{T}}\) from a pretrained label \(y^{\mathrm{S}}\). Let \(f_{\mathrm{plm}}\) and \(f_{\mathrm{dlm}}\) denote the probabilistic LM (Definition E.1) and deterministic LM (Definition E.2), respectively. We finally prove that \(\mathrm{Acc}(f_{\mathrm{plm}})\geq\mathrm{Acc}(f_{\mathrm{dlm}})\) (Corollary E.5) in Appendix E, which further verifies the effectiveness of our methods in the view of theoretical understanding.

```
1:Input: Pretrained label space \(\mathcal{Y}^{\mathrm{S}}\) with \(k_{\mathrm{S}}\) labels, downstream label space \(\mathcal{Y}^{\mathrm{T}}\) with \(k_{\mathrm{T}}\) labels, downstream training set \(\{(x_{i}^{\mathrm{T}},y_{i}^{\mathrm{T}})\}_{i=1}^{n}\), pretrained model \(f_{\mathrm{pre}}(\cdot)\), iterations \(E\), learning rate \(a\), \(\lambda\), \(K\)
2:Output: Probabilistic LM \(\omega_{\mathrm{BLM}+}\in[0,1]^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\)
3: Initialize \(\omega_{\mathrm{BLM}+}\leftarrow\{0\}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\), set \(\theta\leftarrow\mathbf{0}\)
4:for\(e=1...E\)do
5:# Step 1: Get Pretrained Model Outputs
6:\(f(x_{i}^{\mathrm{T}};\theta)=f_{\mathrm{pre}}(f_{\mathrm{in}}(x_{i}^{\mathrm{T }};\theta))\) for \(i=1...n\)
7:# Step 2: Compute (or Update) the LM Matrix
8:\(y_{i}^{\mathrm{S}}\leftarrow\mathrm{argmax}_{y_{i}\times y^{\mathrm{S}}}f(x_{i}^ {\mathrm{T}};\theta)_{y^{\mathrm{T}}}\) for \(i=1...n\)
9:if\(e\)=1then Compute \(\omega_{\mathrm{BLM}+}\) using Eq. (5,8,9)
10:else Update \(\omega_{\mathrm{BLM}+}\) using Eq. (5,8,9)
11:# Step 3: Predict Downstream Labels
12:\(\hat{y}_{i}^{\mathrm{T}}\leftarrow\mathrm{argmax}_{y_{i}}f_{\mathrm{out}}^{ \omega}(f(x_{i}^{\mathrm{T}};\theta))_{y}\) for \(i=1...n\)
13:# Step 4: Update VR Patterns
14:\(\theta\leftarrow\theta-a\triangledown\sum_{i=1}^{n}\ell(y_{i}^{\mathrm{T}},f_{ \mathrm{out}}^{\omega}(f(x_{i}^{\mathrm{T}};\theta)))\)
15:endfor
16:return\(\omega_{\mathrm{BLM}+}\) ```

**Algorithm 2** Training Pipeline of BLM+

## 5 Experiments

**Tasks and Baselines.** Following ILM [4], we employ ResNet-18 [17] pretrained on ImageNet-1K [46] and ResNeXt pretrained on Instagram [37] to test the performance of VR. The results are evaluated on twelve downstream datasets: Flowers102 [41], DTD [9], UCF101 [47], Food101 [2], GTSRB [19], EuroSAT [18], OxfordPets [44], StanfordCars [29], SUN397 [58], CIFAR10/100 [30] and SVHN [39]. Previous gradient-free LM methods RLM [12], FLM [48] and ILM [4] are used as the baselines. The results of deep learning-based LM will also be included for reference, where LM is treated as a single-layer linear neural network connected to the output of the pretrained model for training alongside VR. More dataset and implementation details are in Appendix F. Regarding hyper-parameters of BLM, \(\lambda\) is set as 1, and the top-\(K\) ratio \(\alpha\) is 0.15 (analyzed in Appendix G).

**Results for Padding-based VR.** Padding-based input VR adds trainable noise to the outer frames of centered images. Table 1 shows the performance of BLM and BLM+ applied with padding-based input VR. BLM and BLM+ yield the highest accuracy across all datasets except for SVHN. On ResNet-18, compared to the SOTA (i.e., ILM), BLM achieves an average improvement of 4.7% across the 12 datasets, whereas BLM+ achieves a 6.1% enhancement. On ResNeXt-101, BLM and BLM+ achieve accuracy improvements of 3.2% and 3.8% on average, respectively. The elevation in accuracy is particularly pronounced in tasks with a higher number of classes (e.g., UCF101, CIFAR100). On SVHN, ILM performs slightly better, which could be attributed to the minimal inter-class variation and the smaller number of classes (which is 10) in SVHN, resulting in similar mapping values for different downstream labels and thus reducing our method's advantage (discussed in Appendix H). However, compared to current gradient-free LM methods, the deep learning-based LM may still have an advantage in the performance of downstream tasks due to the learning capacity of the linear layer neural network. Our proposed BLM and BLM+ aim to bridge the gap between gradient-free LM and deep learning-based LM. Additionally, BLM and BLM+ have been observed to possess greater interpretability (see Appendix I for more experiments) and fewer parameters (see Appendix J for details) compared to deep learning-based LM.

**Results for Watermarking-based VR.** BLM and BLM+ can be applied to different input VR methods. For the watermarking-based VR method, which overlays trainable noise patterns on resized images, the results of BLM and BLM+ with ResNet-18 as the pretrained model are shown in Table 2. Since ILM is the best-performing baseline, we only include its results here for comparison. Our BLM and BLM+ methods again outperform ILM, achieving an average gain in accuracy of 6.1% and 7.5%, respectively. Therefore, in the case of watermarking-based VR, BLM and BLM+ also close the gap between current gradient-free and deep learning-based LM. Results in Tabel 2 underscore the applicability of our output LM methods with different input VR.

**Results for Vision-Language Models.** The application of our BLM and BLM+ on vision-language models (i.e., CLIP), along with the performance, and visualization results are dis

\begin{table}
\begin{tabular}{c|c c|c c|c c|c c|c c} \hline \hline  & \multicolumn{4}{c|}{ResNet-18 (ImageNet-1K)} & \multicolumn{4}{c|}{ResNeXt-101-32x8d (Instagram)} \\ \hline \multicolumn{1}{c|}{Padding} & \multicolumn{4}{c|}{Gradient-free} & \multicolumn{2}{c|}{Deep} & \multicolumn{4}{c|}{Gradient-free} & \multicolumn{2}{c|}{Deep} \\ \hline Methods & RLM & FLM & ILM & BLM+ & - & FLM & ILM & BLM & BLM+ & - \\ \hline Flowers102 & 11.0\({}_{\text{e.5}}\) & 20.0\({}_{\text{e.1}}\) & 27.9\({}_{\text{e.7}}\) & 44.4\({}_{\text{e.1}}\) & **50.1\({}_{\text{e.16}}\)** & 76.7\({}_{\text{e.2}}\) & 22.5\({}_{\text{e.5}}\) & 27.9\({}_{\text{e.3}}\) & **31.5\({}_{\text{e.3}}\)** & 30.1\({}_{\text{e.3}}\) & 85.2\({}_{\text{e.1}}\) \\ DTD & 16.3\({}_{\text{e.7}}\) & 32.4\({}_{\text{e.1}}\) & 35.3\({}_{\text{e.9}}\) & 42.0\({}_{\text{e.3}}\) & **43.9\({}_{\text{e.4}}\)** & 49.1\({}_{\text{e.3}}\) & 40.3\({}_{\text{e.4}}\) & 41.4\({}_{\text{e.0}}\) & 47.8\({}_{\text{e.4}}\) & **49.4\({}_{\text{e.0}}\)** & 64.0\({}_{\text{e.5}}\) \\ UCF101 & 6.6\({}_{\text{e.4}}\) & 18.9\({}_{\text{e.5}}\) & 23.9\({}_{\text{e.3}}\) & 30.9\({}_{\text{e.4}}\) & **32.0\({}_{\text{e.4}}\)** & 46.0\({}_{\text{e.4}}\) & 41.9\({}_{\text{e.4}}\) & 43.1\({}_{\text{e.3}}\) & 48.3\({}_{\text{e.3}}\) & **50.1\({}_{\text{e.6}}\)** & 68.3\({}_{\text{e.3}}\) \\ Food101 & 3.8\({}_{\text{e.3}}\) & 12.8\({}_{\text{e.1}}\) & 14.8\({}_{\text{e.2}}\) & 22.3\({}_{\text{e.2}}\) & **25.1\({}_{\text{e.3}}\)** & 34.1\({}_{\text{e.2}}\) & 20.5\({}_{\text{e.2}}\) & 23.0\({}_{\text{e.2}}\) & **96.2\({}_{\text{e.3}}\)** & **31.4\({}_{\text{e.2}}\)** & 58.7\({}_{\text{e.3}}\) \\ GTSRB & 46.1\({}_{\text{e.3}}\) & 45.5\({}_{\text{e.4}}\) & 52.0\({}_{\text{e.1}}\) & **54.8\({}_{\text{e.3}}\)** & **54.3\({}_{\text{e.3}}\)** & 53.4\({}_{\text{e.3}}\) & 56.2\({}_{\text{e.5}}\) & 59.9\({}_{\text{e.4}}\) & 62.9\({}_{\text{e.3}}\) & **63.0\({}_{\text{e.3}}\)** & 74.4\({}_{\text{e.4}}\) \\ EuroSAT & 82.4\({}_{\text{e.4}}\) & 83.8\({}_{\text{e.1}}\) & 85.2\({}_{\text{e.4}}\) & **86.7\({}_{\text{e.1}}\)** & **86.7\({}_{\text{e.1}}\)** & 92.4\({}_{\text{e.4}}\) & 87.8\({}_{\text{e.4}}\) & 86.2\({}_{\text{e.3}}\) & 87.6\({}_{\text{e.3}}\) & **88.3\({}_{\text{e.3}}\)** & 93.2\({}_{\text{e.2}}\) \\ OxfordPets & 9.3\({}_{\text{e.1}}\) & 62.9\({}_{\text{e.1}}\) & 65.4\({}_{\text{e.1}}\) & 69.8\({}_{\text{e.3}}\) & **70.6\({}_{\text{e.2}}\)** & 73.0\({}_{\text{e.3}}\) & 76.8\({}_{\text{e.9}}\) & 82.8\({}_{\text{e.3}}\) & 82.4\({}_{\text{e.3}}\) & **8

[MISSING_PAGE_FAIL:8]

labels in downstream tasks, taking ResNet-18 pretrained on ImageNet-1K as an example. Each column of \(\omega\) computed using BLM or BLM+ is a vector with length \(k_{\mathrm{S}}=1000\), representing the weights assigned to the 1,000 outputs-one for each \(y^{\mathrm{S}}\)-of the pretrained model corresponding to a downstream label \(y^{\mathrm{T}}\). The top-weighted labels (i.e., \(y^{\mathrm{S}}\) where \(\omega_{y^{\mathrm{S}},y^{\mathrm{T}}}\) is larger) for 'Edamame' correspond to organisms such as snakes and artichokes, which share similarities in color and shape. Similarly, the predominant labels associated with 'Fibrous' from the texture dataset include rough-textured items like 'Hay' and 'Komondor'. 'Dog' encompasses various sub-breed canines. These findings suggest that BLM and BLM+ establish an optimal probabilistic LM between label spaces, and handle similarity or inclusion relationship, addressing the drawbacks in Figure 1.

**Discussion of Why VR Is Effective.** From a visualization perspective, Figure 4 shows the top-weighted pretrained labels and input VR patterns \(\theta\) at different iteration stages using BLM+. The training loss for each iteration and changes in \(\omega\), measured by the Euclidean norm, are also plotted. During the update of \(\omega\) and \(\theta\), the pretrained labels with top \(\omega_{y^{\mathrm{S}},y^{\mathrm{T}}}\) for \(y^{\mathrm{T}}\) being 'Marigold' transition gradually from dissimilar labels such as 'Ref' and 'Teddy' to 'Cauliflower' and 'Pineapple' which share more similarities in color, shape and texture. Meanwhile, the training loss diminishes gradually, and \(\omega\) converges, demonstrating the effectiveness of VR and BLM+.

**Impact of Label Space Sizes \(k_{\mathrm{T}}\).** Figure 5 shows the relationship between different sizes of the downstream label space and the accuracy improvement achieved by BLM and BLM+. Tasks with larger label spaces report more pronounced performance improvements. While simpler tasks with smaller label spaces might not fully showcase the power of our approach, the strength of BLM and BLM+ lies in unraveling the complex many-to-many relationship that often arises in tasks with more numerous classes. In such scenarios, our probabilistic LM methods demonstrate their full potential.

**Impact of Training Dataset Sizes \(n\).** Figure 6 illustrates the impact of varying training dataset sizes for the downstream task on different LM methods. Regarding CIFAR100 as the downstream task, compared with RLM and ILM, BLM and BLM+ yield higher accuracy consistently. With approximately a 40% fraction of the downstream training data, BLM or BLM+ can achieve similar accuracy compared with training on the entire dataset.

**Other Experiments.** The parameter experiments and performance analysis regarding the impact of Laplace smoothing coefficient \(\lambda\) and top-\(K\) ratio \(\alpha\) for BLM and BLM+ are detailed in Appendix G. The visualization and analysis of LM matrices derived from gradient-free and deep learning-based methods can be found in Appendix I. Training cost analysis is discussed in Appendix J. Additional visualization results of LM methods applied to pretrained vision models are presented in Appendix K. Lastly, the application of BLM and BLM+ for vision-language models is explored in Appendix L.

Figure 4: Visualization of input VR and top-weighted pretrained labels applying BLM+. Training loss and weight changes (Euclidean norm) of probabilistic LM \(\omega_{\mathrm{BLM+}}\) per iteration are plotted below. Pretrained ResNet-18 is used, and the downstream label ‘Marigold’ is selected as an example.

## 6 Conclusion

We focus on output LM methods for VR and reveal the drawbacks in current gradient-free LM methods, which use one-to-one mappings that overly simplify the relationship between the pretrained and downstream label spaces. To address this issue, we propose BLM, which calculates probabilistic LM matrices guided by Bayes' theorem. Additionally, we aggregate the probability of top-\(K\) predicted pretrained labels instead of counting a single label during the estimation of probabilistic LM matrices, yielding an improved method BLM+. Both theoretical analysis and experimental results validate the effectiveness of BLM and BLM+ while offering insights into understanding the effectiveness of VR through a probabilistic lens.

## Acknowledgement

CYC, ZSY, and FL are supported by the Australian Research Council (ARC) with grant number DE240101089, and FL is also supported by ARC with grant number DP230101540 and the NSF&CSIRO Responsible AI program with grant number 2303037. JZQ is supported by ARC with grant number DP240101006. This research is also supported by The University of Melbourne's Research Computing Services and the Petascale Campus Initiative. We sincerely appreciate the time and dedication of the reviewers in carefully reviewing our manuscript.

## References

* [1] Hyojin Bahng, Ali Jahanian, Swami Sankaranarayanan, and Phillip Isola. Exploring visual prompts for adapting large-scale models. _arXiv preprint arXiv:2203.17274_, 2022.
* [2] Lukas Bossard, Matthieu Guillaumin, and Luc Van Gool. Food-101-mining discriminative components with random forests. In _ECCV_, 2014.
* [3] Chengyi Cai, Zesheng Ye, Lei Feng, Jianzhong Qi, and Feng Liu. Sample-specific masks for visual reprogramming-based prompting. In _ICML_, 2024.
* [4] Aochuan Chen, Yuguang Yao, Pin-Yu Chen, Yihua Zhang, and Sijia Liu. Understanding and improving visual prompting: A label-mapping perspective. In _CVPR_, 2023.

* [5] Hao Chen, Ran Tao, Han Zhang, Yidong Wang, Xiang Li, Wei Ye, Jindong Wang, Guosheng Hu, and Marios Savvides. Conv-adapter: Exploring parameter efficient transfer learning for convnets. In _CVPR_, 2024.
* [6] Hao Chen, Jindong Wang, Ankit Shah, Ran Tao, Hongxin Wei, Xing Xie, Masashi Sugiyama, and Bhiksha Raj. Understanding and mitigating the label noise in pre-training on downstream tasks. In _ICLR_, 2024.
* [7] Pin-Yu Chen. Model reprogramming: Resource-efficient cross-domain machine learning. In _AAAI_, 2024.
* [8] Haoang Chi, Feng Liu, Wenjing Yang, Long Lan, Tongliang Liu, Bo Han, William Cheung, and James Kwok. Tohan: A one-step approach towards few-shot hypothesis adaptation. _NeurIPS_, 2021.
* [9] Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea Vedaldi. Describing textures in the wild. In _CVPR_, 2014.
* [10] Ruijiang Dong, Feng Liu, Haoang Chi, Tongliang Liu, Mingming Gong, Gang Niu, Masashi Sugiyama, and Bo Han. Diversity-enhancing generative network for few-shot hypothesis adaptation. In _ICML_, 2023.
* [11] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. In _ICLR_, 2020.
* [12] Gamaleldin F Elsayed, Ian Goodfellow, and Jascha Sohl-Dickstein. Adversarial reprogramming of neural networks. In _ICLR_, 2018.
* [13] Zhen Fang, Jie Lu, Feng Liu, Junyu Xuan, and Guangquan Zhang. Open set domain adaptation: Theoretical bound and algorithm. _IEEE TNNLS_, 2020.
* [14] Zhen Fang, Jie Lu, Feng Liu, and Guangquan Zhang. Semi-supervised heterogeneous domain adaptation: Theory and algorithms. _IEEE TPAMI_, 2022.
* [15] Karen Hambardzumyan, Hrant Khachatrian, and Jonathan May. Warp: Word-level adversarial reprogramming. In _ACL-IJCNLP_, 2021.
* [16] Cheng Han, Qifan Wang, Yiming Cui, Zhiwen Cao, Wenguan Wang, Siyuan Qi, and Dongfang Liu. E 2 vpt: An effective and efficient approach for visual prompt tuning. In _ICCV_, 2023.
* [17] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In _CVPR_, 2016.
* [18] Patrick Helber, Benjamin Bischke, Andreas Dengel, and Damian Borth. Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification. _IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing_, 2019.
* [19] Sebastian Houben, Johannes Stallkamp, Jan Salmen, Marc Schlipsing, and Christian Igel. Detection of traffic signs in real-world images: The german traffic sign detection benchmark. In _IJCNN_, 2013.
* [20] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. _arXiv preprint arXiv:2106.09685_, 2021.
* [21] Yun-Ning Hung, Chao-Han Huck Yang, Pin-Yu Chen, and Alexander Lerch. Low-resource music genre classification with cross-modal neural model reprogramming. In _ICASSP_, 2023.
* [22] Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, Serge Belongie, Bharath Hariharan, and Ser-Nam Lim. Visual prompt tuning. In _ECCV_, 2022.
* [23] Yongcheng Jing, Chongbin Yuan, Li Ju, Yiding Yang, Xinchao Wang, and Dacheng Tao. Deep graph reprogramming. In _CVPR_, 2023.

* [24] Jacob Devlin Ming-Wei Chang Kenton and Lee Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In _NAACL-HLT_, 2019.
* [25] Muhammad Uzair Khattak, Hanoona Rasheed, Muhammad Maaz, Salman Khan, and Fahad Shahbaz Khan. Maple: Multi-modal prompt learning. In _CVPR_, 2023.
* [26] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_, 2014.
* [27] Eliska Kloberdanz, Jin Tian, and Wei Le. An improved (adversarial) reprogramming technique for neural networks. In _ICANN_, 2021.
* [28] Jannik Kossen, Mark Collier, Basil Mustafa, Xiao Wang, Xiaohua Zhai, Lucas Beyer, Andreas Steiner, Jesse Berent, Rodolphe Jenatton, and Effrosyni Kokiopoulou. Three towers: Flexible contrastive learning with pretrained image models. _NeurIPS_, 2023.
* [29] Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3d object representations for fine-grained categorization. In _ICCV workshops_, 2013.
* [30] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
* [31] Tao Lei, Junwen Bai, Siddhartha Brahma, Joshua Ainslie, Kenton Lee, Yanqi Zhou, Nan Du, Vincent Zhao, Yuexin Wu, Bo Li, et al. Conditional adapters: Parameter-efficient transfer learning with fast inference. _NeurIPS_, 2023.
* [32] Jian Liang, Dapeng Hu, and Jiashi Feng. Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation. In _ICML_, 2020.
* [33] Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. Conditional adversarial domain adaptation. _NeurIPS_, 2018.
* [34] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Unsupervised domain adaptation with residual transfer networks. _NeurIPS_, 2016.
* [35] Ilya Loshchilov and Frank Hutter. Sgdr: Stochastic gradient descent with warm restarts. _arXiv preprint arXiv:1608.03983_, 2016.
* [36] Yadan Luo, Zijian Wang, Zi Huang, and Mahsa Baktashmotlagh. Progressive graph learning for open-set domain adaptation. In _ICML_, 2020.
* [37] Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. Exploring the limits of weakly supervised pretraining. In _ECCV_, 2018.
* [38] Paarth Neekhara, Shehzeen Hussain, Jinglong Du, Shlomo Dubnov, Farinaz Koushanfar, and Julian McAuley. Cross-modal adversarial reprogramming. In _WACV_, 2022.
* [39] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Baolin Wu, Andrew Y Ng, et al. Reading digits in natural images with unsupervised feature learning. In _NeurIPS workshop_, 2011.
* [40] Cuong Nguyen, Tal Hassner, Matthias Seeger, and Cedric Archambeau. Leep: A new measure to evaluate transferability of learned representations. In _ICML_, 2020.
* [41] Maria-Elena Nilsback and Andrew Zisserman. Automated flower classification over a large number of classes. In _2008 Sixth Indian conference on computer vision, graphics & image processing_. IEEE, 2008.
* [42] Changdae Oh, Hyeji Hwang, Hee-young Lee, YongTaek Lim, Geunyoung Jung, Jiyoung Jung, Hosik Choi, and Kyungwoo Song. Blackvip: Black-box visual prompting for robust transfer learning. In _CVPR_, 2023.
* [43] Junting Pan, Ziyi Lin, Xiatian Zhu, Jing Shao, and Hongsheng Li. St-adapter: Parameter-efficient image-to-video transfer learning. _NeurIPS_, 2022.

* [44] Omkar M Parkhi, Andrea Vedaldi, Andrew Zisserman, and CV Jawahar. Cats and dogs. In _CVPR_, 2012.
* [45] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In _ICML_, 2021.
* [46] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. _IJCV_, 2015.
* [47] Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah. Ucf101: A dataset of 101 human actions classes from videos in the wild. _arXiv preprint arXiv:1212.0402_, 2012.
* [48] Yun-Yun Tsai, Pin-Yu Chen, and Tsung-Yi Ho. Transfer learning without knowing: Reprogramming black-box machine learning models with scarce data and limited resources. In _ICML_, 2020.
* [49] Hsi-Ai Tsao, Lei Hsiung, Pin-Yu Chen, Sijia Liu, and Tsung-Yi Ho. AutoVP: an automated visual prompting framework and benchmark. In _ICLR_, 2024.
* [50] Ria Vinod, Pin-Yu Chen, and Payel Das. Reprogramming language models for molecular representation learning. _NeurIPS_, 2020.
* [51] Boyu Wang, Jorge Mendez, Mingbo Cai, and Eric Eaton. Transfer learning via minimizing the performance gap between domains. _NeurIPS_, 2019.
* [52] Qizhou Wang, Feng Liu, Yonggang Zhang, Jing Zhang, Chen Gong, Tongliang Liu, and Bo Han. Watermarking for out-of-distribution detection. _NeurIPS_, 2022.
* [53] Wenhao Wang, Yifan Sun, Wei Li, and Yi Yang. Transhp: Image classification with hierarchical prompting. _NeurIPS_, 2023.
* [54] Zixin Wang, Yadan Luo, Zhi Chen, Sen Wang, and Zi Huang. Cal-sfda: Source-free domain-adaptive semantic segmentation with differentiable expected calibration error. In _ACM MM_, 2023.
* [55] Wei-Hung Weng, Jonathan Deaton, Vivek Natarajan, Gamaleldin F Elsayed, and Yuan Liu. Addressing the real-world class imbalance problem in dermatology. In _Machine learning for health_, 2020.
* [56] Wikipedia contributors. Cartesian product -- Wikipedia, the free encyclopedia. https://en.wikipedia.org/w/index.php?title=Cartesian_product&oldid=1219343305, 2024.
* [57] Wikipedia contributors. Cosine similarity -- Wikipedia, the free encyclopedia. https://en.wikipedia.org/w/index.php?title=Cosine_similarity&oldid=1224774490, 2024.
* [58] Jianxiong Xiao, James Hays, Krista A Ehinger, Aude Oliva, and Antonio Torralba. Sun database: Large-scale scene recognition from abbey to zoo. In _CVPR_, 2010.
* [59] Zhuoyan Xu, Zhenmei Shi, Junyi Wei, Fangzhou Mu, Yin Li, and Yingyu Liang. Towards few-shot adaptation of foundation models via multitask finetuning. In _ICLR_, 2024.
* [60] Chao-Han Huck Yang, Bo Li, Yu Zhang, Nanxin Chen, Rohit Prabhavalkar, Tara N Sainath, and Trevor Strohman. From english to more languages: Parameter-efficient model reprogramming for cross-lingual speech recognition. In _ICASSP_, 2023.
* [61] Chao-Han Huck Yang, Yun-Yun Tsai, and Pin-Yu Chen. Voice2series: Reprogramming acoustic models for time series classification. In _ICML_, 2021.
* [62] Li Yi, Gezheng Xu, Pengcheng Xu, Jiaqi Li, Ruizhi Pu, Charles Ling, A Ian McLeod, and Boyu Wang. When source-free domain adaptation meets learning with noisy labels. _arXiv preprint arXiv:2301.13381_, 2023.

* [63] Elad Ben Zaken, Shauli Ravfogel, and Yoav Goldberg. Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models. _arXiv preprint arXiv:2106.10199_, 2021.
* [64] Maxime Zanella and Ismail Ben Ayed. Low-rank few-shot adaptation of vision-language models. In _CVPR_, 2024.
* [65] Yichi Zhang, Yinpeng Dong, Siyuan Zhang, Tianzan Min, Hang Su, and Jun Zhu. Exploring the transferability of visual prompting for multimodal large language models. In _CVPR_, 2024.
* [66] Ziyi Zhang, Weikai Chen, Hui Cheng, Zhen Li, Siyuan Li, Liang Lin, and Guanbin Li. Divide and contrast: Source-free domain adaptation via adaptive contrastive learning. _NeurIPS_, 2022.
* [67] Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and Ziwei Liu. Conditional prompt learning for vision-language models. In _CVPR_, 2022.
* [68] Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and Ziwei Liu. Learning to prompt for vision-language models. _IJCV_, 2022.
* [69] Yitao Zhu, Zhenrong Shen, Zihao Zhao, Sheng Wang, Xin Wang, Xiangyu Zhao, Dinggang Shen, and Qian Wang. Melo: Low-rank adaptation is better than fine-tuning for medical image diagnosis. In _IEEE International Symposium on Biomedical Imaging_, 2024.

The task of VR reuses fixed pretrained models for downstream tasks. As illustrated in Figure 7, an input VR module operates before pretrained models, directly altering the input space of downstream tasks. Concurrently, an output LM function acts after pretrained models, taking the predicted pretrained labels as input and outputting those for downstream tasks. Hence, VR achieves the reusability of pretrained models for downstream tasks without adapting the model parameters, primarily through modifications to the input and output spaces.

## Appendix B Recent Work in Transfer Learning

Visual reprogramming is one type of methods that aim to obtain models on downstream tasks with the help of pretrained models. This process is similar to the aim of transfer learning which is used to leverage knowledge from a data-rich domain [13] or a pretrained model [51] to address tasks on other domains. The former is known as _domain adaptation_, and the latter is known as finetuning.

**Finetuning.** Given a pretrained model, finetuning uses trainable parameters to accommodate new task-specific information of the downstream tasks. As pretrained models grow in size, recent progresses in transfer learning have prioritized _parameter-efficient finetuning_ (PEFT) [20] to support resource-friendly adaptation. Regarding PEFT, the prevailing methods can be categorized as follows. The most widely adopted approach is selective finetuning [46, 63], which adjusts a subset of parameters from the pretrained model while keeping the remaining components fixed, thereby reducing the total number of trainable parameters for downstream tasks. Other methods may involve adding adapters [5, 31, 43], which introduce extra trainable layers or parameters to the pretrained model and finetune only these adapters during training. Moreover, low-rank adaptation methods [20, 64, 69] have also been proposed for pretrained Vision Transformers. They apply low-rank decomposition to the parameters during training, achieving remarkable performance on downstream tasks with a significantly reduced number of parameters. Additionally, Prompt Tuning methods [16, 22, 53], similarly directed at pretrained Vision Transformers, integrate trainable parameters parallel to the features at the input and intermediate layers. The primary distinction of these methods from VR [1, 3, 4, 48, 49, 65] lies in their necessity to be designed according to different pretrained model architectures and may also involve modifying the model weights. In contrast, VR is model-agnostic and does not require alterations to pretrained model parameters.

**Domain Adaptation.**_Domain adaptation_ (DA) aims to bridge the distributional gap by aligning feature spaces of the source task to the target domain with different data distributions [14, 36, 54]. Often, DA is achieved by learning invariant representations or transforming parameters to manage domain-specific shifts of the source and target data. CDAN [33] addresses this by introducing a conditional discriminator for class label-conditioned feature adaptation, while UDA [34] leverages residual layers to capture both domain-specific and domain-shared representations. More recently, source-free DA [62, 32, 66], which seeks adaptation without access to the source data, has gained

Figure 7: The problem setting of Visual Reprogramming. The left part shows the pretrained model and corresponding dataset, while the right part shows downstream tasks. The pretrained model is fixed, whereas the input VR and output LM modules are variable.

popularity due to growing concerns over data privacy and storage limitations, as well as the need for adaptation in scenarios where source data is inaccessible [8, 10].

**Pretrained Model Selection.** The BLM/BLM+ framework models \(p(Y^{\mathrm{T}}|X^{\mathrm{T}})\) by using the pre-trained model \(f_{\mathrm{pre}}\) and integrating over the pre-traiend label space \(\mathcal{Y}^{\mathrm{S}}\) (Eq. (3)), relying on \(n\) training examples for empirical estimation (Eq. (4)). Essentially, Eq. (4) can be seen as a score that assesses how a pre-trained model, whose output lies in \(\mathcal{Y}^{\mathrm{S}}\), performs on a downstream task \(\mathcal{X}^{\mathrm{T}}\times\mathcal{Y}^{\mathrm{T}}\), measured over \(n\) downstream samples. This finding resembles LEEP [40], a pre-trained model transferability metric, which shares the same empirical formulation with BLM. In this sense, BLM/BLM+ extends LEEP by incorporating top-\(K\) aggregation for more robust estimation, suggesting the potential as a more generalized framework for assessing pre-trained model transferability.

## Appendix C A Simple Probability Estimation Example

We aim to estimate \(p(Y^{\mathrm{T}}=y^{\mathrm{T}},Y^{\mathrm{S}}=y^{\mathrm{S}}\mid X^{\mathrm{T}})\) and \(p(Y^{\mathrm{S}}=y^{\mathrm{S}}\mid X^{\mathrm{T}})\) for BLM and BLM+ in this paper. Here, we employ a simple example (without Laplace smoothing) to help understand how to estimate these two probabilities.

The conditional probability \(p(Y^{\mathrm{T}}=y^{\mathrm{T}},Y^{\mathrm{S}}=y^{\mathrm{S}}\mid X^{\mathrm{ T}})\) represents the joint distribution of \(Y^{\mathrm{T}}\) and \(Y^{\mathrm{S}}\), given the input reprogramming \(f_{\mathrm{in}}(\cdot,\theta)\), the pretrained model \(f_{\mathrm{pre}}(\cdot)\), and the variable \(X^{\mathrm{T}}\) of the downstream task. Similarly, \(p(Y^{\mathrm{S}}=y^{\mathrm{S}}\mid X^{\mathrm{T}})\) represents the distribution of \(Y^{\mathrm{S}}\) under these conditions.

We consider the following example shown in Figure 8. It is assumed that \(\mathcal{Y}^{\mathrm{T}}=\{\mathtt{Cat},\mathtt{Dog}\}\) and \(\mathcal{Y}^{\mathrm{S}}=\{\mathtt{CockerSpaniel},\mathtt{EnglishSpringer}, \mathtt{EgyptianCat}\}\). The Downstream samples are

\[\{(x_{1},\mathtt{Dog}),(x_{2},\mathtt{Dog}),(x_{3},\mathtt{Dog}),(x_{4}, \mathtt{Cat})\}\in\mathcal{X}^{\mathrm{T}}\times\mathcal{Y}^{\mathrm{T}}.\]

If the reprogrammed predictions calculated by \(f_{\mathrm{pre}}(f_{\mathrm{in}}(x_{i};\theta))\) are

\[\{x_{1}:\mathtt{CockerSpaniel},x_{2}:\mathtt{CockerSpaniel},x_{3}:\mathtt{ EnglishSpringer},x_{4}:\mathtt{EgyptianCat}\},\]then the joint distribution \(p(Y^{\mathrm{T}}=y^{\mathrm{T}},Y^{\mathrm{S}}=y^{\mathrm{S}}\mid X^{\mathrm{T}})\) can be estimated as a matrix with the following nonzero values:

\[p(Y^{\mathrm{T}}=\texttt{Dog},Y^{\mathrm{S}}=\texttt{CockerSpaniel}\mid X^{ \mathrm{T}})=\frac{1}{2},\]

\[p(Y^{\mathrm{T}}=\texttt{Dog},Y^{\mathrm{S}}=\texttt{EnglishSpringer}\mid X^{ \mathrm{T}})=\frac{1}{4},\]

\[p(Y^{\mathrm{T}}=\texttt{Cat},Y^{\mathrm{S}}=\texttt{EgyptianCat}\mid X^{ \mathrm{T}})=\frac{1}{4},\]

as is shown in Figure 8. Similarly, \(p(Y^{\mathrm{S}}=y^{\mathrm{S}}\mid X^{\mathrm{T}})\) can also be estimated.

## Appendix D Detailed Procedures of Output LM Methods

This section provides a detailed exposition of gradient-free LM methods. Such methods, derived from data distributions, obviate the need for gradients in the output mapping phase. The pseudocode is presented below. Similar to Section 3, \(\omega\) represents the one-to-one LM or probabilistic LM.

### Random Label Mapping (RLM)

```
1:Input: Pretrained label space \(\mathcal{Y}^{\mathrm{S}}\) with \(k_{\mathrm{S}}\) labels, downstream label space \(\mathcal{Y}^{\mathrm{T}}\) with \(k_{\mathrm{T}}\) labels
2:Output: One-to-one LM \(\omega\in\{0,1\}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\)
3: Initialize \(\omega\leftarrow\{0\}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\), temp set \(T\leftarrow\{\}\) to store matched pretrained labels
4:# Computing output mapping \(\omega\)
5:for\(y^{\mathrm{T}}\in\mathcal{Y}^{\mathrm{T}}\)do
6: Randomly select \(y^{\mathrm{S}}\in\mathcal{Y}^{\mathrm{S}}-T\)
7:\(\omega_{y^{\mathrm{S}},y^{\mathrm{T}}}\gets 1\)
8:\(T\gets T\cup\{y^{\mathrm{S}}\}\)
9:endfor
10:return\(\omega\) ```

**Algorithm 3** Random Label Mapping for VR

The process of _random label mapping_ (RLM) is outlined in Algorithm 3., where the computation of \(\omega\) does not involve the downstream training set. The algorithm establishes a random one-to-one mapping between the pretrained and the downstream labels, ensuring that each \(y^{\mathrm{T}}\) corresponds to a unique \(y^{\mathrm{S}}\). RLM is computed once before learning the input VR \(f(\cdot;\theta)\).

### Frequent Label Mapping (FLM)

```
1:Input: Downstream training set \(\{(x_{i}^{\mathrm{T}},y_{i}^{\mathrm{T}})\}_{i=1}^{n}\), given input VR \(f_{\mathrm{in}}(\cdot;\theta)\) and pretrained model \(f_{\mathrm{pre}}(\cdot)\) with the \(j\)th dimension being \(f_{\mathrm{pre}}(\cdot)_{j}\)
2:Output: Frequency distribution matrix \(d\in\mathbb{Z}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\)
3: Initialize \(d\leftarrow\{0\}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\)
4:# Computing frequency distribution matrix \(d\)
5:for\(i=1...n\)do
6:\(\hat{y}_{i}^{\mathrm{S}}\leftarrow\arg\max_{j}(f_{\mathrm{pre}}(f_{\mathrm{ in}}(x_{i}^{\mathrm{T}};\theta))_{j})\)
7:\(d_{\hat{y}_{i}^{\mathrm{S}},y_{i},\mathrm{T}}\gets d_{\hat{y}_{i}^{\mathrm{ S}},y_{i},\mathrm{T}}+1\)
8:endfor
9:return\(d\) ```

**Algorithm 4** Computing Frequency Distribution Matrix of [predicted pretrained label, ground-truth downstream label]

The procedure of _frequent label mapping_ (FLM) is outlined in Algorithm 5. Initially, it utilizes the pretrained model to obtain predicted pretrained labels for samples of the downstream task. Subsequently, it computes a joint distribution matrix between the predicted pretrained labels and the ground-truth downstream labels. Finally, employing a greedy algorithm, it iteratively identifies the maximum value in the rows and columns corresponding to unmatched label pairs in the matrix to determine the one-to-one mappings. FLM is also computed prior to the training of \(f_{\mathrm{in}}(\cdot;\theta)\).

### Iterative Label Mapping (ILM)

```
1:Input: Pretrained label space \(\mathcal{Y}^{\mathrm{S}}\) with \(k_{\mathrm{S}}\) labels, downstream label space \(\mathcal{Y}^{\mathrm{T}}\) with \(k_{\mathrm{T}}\) labels, downstream training set \(\{(x_{i}^{\mathrm{T}},y_{i}^{\mathrm{T}})\}_{i=1}^{n}\), given pretrained model \(f_{\mathrm{pre}}(\cdot)\)
2:Output: One-to-one LM \(\omega\in\{0,1\}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\)
3: Initialize \(\omega\leftarrow\{0\}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\), temp set \(T\leftarrow\{\}\) to store matched pretrained labels, initialize \(f_{\mathrm{in}}(\cdot;\theta)\) (\(\theta\leftarrow\mathbf{0}\))
4:# Computing frequency distribution matrix \(d\)
5:Use Algorithm 4 to obtain \(d\)
6:# Computing output mapping \(\omega\)
7:while size of \(T\) is not \(k_{\mathrm{T}}\)do
8: Find the maximum \(d_{y^{\mathrm{S}},y^{\mathrm{T}}}\) in \(d\)
9:\(\omega_{y^{\mathrm{S}},y^{\mathrm{T}}}\gets 1\)
10:\(d_{y^{\mathrm{S}},t}\gets 0\) for \(t=1,2,...,k_{\mathrm{T}}\)
11:\(d_{s,y^{\mathrm{T}}}\gets 0\) for \(s=1,2,...,k_{\mathrm{S}}\)
12:\(T\gets T\cup\{y^{\mathrm{S}}\}\)
13:endwhile
14:return\(\omega\) ```

**Algorithm 5** Frequent Label Mapping for VR

In this paper, we propose a new approach to the problem of finding a _local_ mapping (ILM).

### Iterative Label Mapping (ILM)

```
1:Input: Pretrained label space \(\mathcal{Y}^{\mathrm{S}}\) with \(k_{\mathrm{S}}\) labels, downstream label space \(\mathcal{Y}^{\mathrm{T}}\) with \(k_{\mathrm{T}}\) labels, downstream training set \(\{(x_{i}^{\mathrm{T}},y_{i}^{\mathrm{T}})\}_{i=1}^{n}\), given pretrained model \(f_{\mathrm{pre}}(\cdot)\)
2:Output: One-to-one LM \(\omega\in\{0,1\}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\)
3: Initialize \(\omega\leftarrow\{0\}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\)
4:\(\omega\leftarrow\{0\}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\)
5:\(d_{y^{\mathrm{S}},y^{\mathrm{T}}}\gets 0\) for \(t=1,2,...,k_{\mathrm{T}}\)
6:\(d_{s,y^{\mathrm{T}}}\gets 0\) for \(s=1,2,...,k_{\mathrm{S}}\)
7:\(T\gets T\cup\{y^{\mathrm{S}}\}\)
8:endwhile
9:# Training \(f_{\mathrm{in}}(\cdot;\theta)\)
10:\(\theta\leftarrow\theta-a\cdot\nabla_{\theta}\sum_{i=1}^{n}\ell(y_{i}^{\mathrm{ T}},f_{\mathrm{out}}^{\omega}(f_{\mathrm{pre}}(f_{\mathrm{in}}(x_{i}^{\mathrm{T}}; \theta))))\)
11:endfor
12:return\(\omega\) ```

**Algorithm 6** Iterative Label Mapping for VR

In this paper, we propose a new approach to the problem of finding a _local mapping_ (ILM).

### Bayesian-guided Label Mapping (BLM)

The detailed procedure of _Bayesian-guided label mapping_ (BLM) proposed in this paper is shown in Algorithm 7. Compared to ILM, BLM replaces the previous one-to-one mapping \(\omega\in\{0,1\}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\)with probabilistic LM \(\omega\in[0,1]^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\), both satisfying \(\sum_{j=1}^{k_{\mathrm{S}}}\omega_{j,\cdot}=1\) as stated in Section 3. Meanwhile, the process of matrix computation for BLM is based on the Bayes' theorem (detailed in Section 4) to reflect the complex relationship among label spaces, rather than determining the optimal match through the oversimplified greedy algorithm.

```
1:Input: Pretrained label space \(\mathcal{Y}^{\mathrm{S}}\) with \(k_{\mathrm{S}}\) labels, downstream label space \(\mathcal{Y}^{\mathrm{T}}\) with \(k_{\mathrm{T}}\) labels, downstream training set \(\{(x_{i}^{\mathrm{T}},y_{i}^{\mathrm{T}})\}_{i=1}^{n}\), given pretrained model \(f_{\mathrm{pre}}(\cdot)\), total iteration number \(E\), learning rate \(a\), Laplace smoothing \(\lambda\)
2:Output: Probabilistic LM \(\omega\in[0,1]^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\)
3:Initialize \(\omega\leftarrow\{0\}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\), initialize \(f_{\mathrm{in}}(\cdot;\theta)\) (\(\theta\leftarrow\mathbf{0}\)), temp matrix \(P=[P_{1},...,P_{k_{\mathrm{S}}}]^{\top}\in\mathbb{R}^{k_{\mathrm{S}}}\)
4:for\(e=1...E\)do
5: # Computing frequency distribution matrix \(d\)
6:  Use Algorithm 4 to obtain \(d\)
7: # Computing output mapping \(\omega\)
8:\(P_{y^{\mathrm{S}}}\leftarrow\sum_{i=1}^{k_{\mathrm{T}}}d_{y^{\mathrm{S}},t}+\lambda\) for \(y^{\mathrm{S}}=1...k_{\mathrm{S}}\)
9:\(\omega_{y^{\mathrm{S}},y^{\mathrm{T}}}\gets d_{y^{\mathrm{S}},y^{\mathrm{T }}}/P_{y^{\mathrm{S}}}\) for \(y^{\mathrm{S}}=1...k_{\mathrm{S}},y^{\mathrm{T}}=1...k_{\mathrm{T}}\)
10: # Column normalization of \(\omega\)
11:\(\omega_{y^{\mathrm{S}},y^{\mathrm{T}}}\leftarrow\omega_{y^{\mathrm{S}},y^{ \mathrm{T}}}/\sum_{i=1}^{k_{\mathrm{S}}}\omega_{s,y^{\mathrm{T}}}\) for \(y^{\mathrm{S}}=1...k_{\mathrm{S}},y^{\mathrm{T}}=1...k_{\mathrm{T}}\)
12: # Training \(f_{\mathrm{in}}(\cdot;\theta)\)
13:\(\theta\leftarrow\theta-a\cdot\nabla_{\theta}\sum_{i=1}^{n}\ell(y_{i}^{\mathrm{ T}},f_{\mathrm{out}}^{\omega}(f_{\mathrm{pre}}(f_{\mathrm{in}}(x_{i}^{\mathrm{T}}; \theta))))\)
14:endfor
15:return\(\omega\) ```

**Algorithm 7** Bayesian-guided Label Mapping for VR

### Improved Bayesian-guided Label Mapping (BLM+)

As mentioned in Section 4, BLM+ extends BLM by incorporating the aggregation of top-\(K\) predicted probabilities, shown in Algorithm 9.

This divergence manifests in the computation process of the joint distribution matrix between predicted pretrained labels and ground-truth downstream labels. Previous methods (i.e., RLM, ILM, BLM) computed a non-negative integer matrix \(d\in\mathbb{Z}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\) based on the frequency of occurrence of samples (Algorithm 4).

In BLM+, the calculation entails replacing the deterministic frequencies with predicted probabilities from the top \(K\) pretrained labels to estimate the joint distribution matrix \(d\in\mathbb{R}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\), as is shown in Algorithm 8. In the procedure, the probability aggregation substitutes the binary frequency distribution \(\{0,1\}\) with a probability distribution within the range of \([0,1]\), while the top-\(K\) technique serves to retain the most probable \(k\) predicted labels rather than selecting only one (i.e., BLM) or all labels (denoted as '-Top-K' in ablation studies in Section 5).

### A Quick Version of ILM, BLM, and BLM+

The baseline method FLM calculates the mapping \(\omega\) once and keeps it fixed, while ILM and our methods update \(\omega\) at each step. However, updating \(\omega\) does not require running the model twice to obtain current predictions for each epoch. Instead, predictions from the most recent epoch can be reused. Therefore, only in the first epoch is it necessary to run the pretrained model an additional time to initialize the weights of LM, which is the same as FLM. In subsequent epochs, these methods do not require any extra runs. More details can be found in the quick version of our released code.

## Appendix E Detailed Theoretical Analysis

### Justification and Analysis

In this section, we investigate why probabilistic LM should be favored over deterministic one-to-one mapping. This analysis assumes the existence of true correspondences between labels in the pretrained and downstream domains. We establish that, under certain conditions, probabilistic LM (Definition. E.1) outperforms deterministic LM (Definition E.2) in estimating the distribution of true label correspondences, quantified by the expected accuracy of the LM function (Eq. (10)).

This analysis focuses on the comparisons of LM. Given that the pretrained model \(f_{\mathrm{pre}}\), input \(x\), and input transformations \(f_{\mathrm{in}}\) are the same across different LM methods, we will omit these notations below unless explicitly needed. We begin by introducing key definitions.

**Definition E.1** (_probabilistic label mapping_ (PLM)).: _Let \(\mathcal{F}_{\mathrm{plm}}\subset\mathcal{F}_{\mathrm{lm}}\) be a set of mapping functions such that for all \(f_{\mathrm{plm}}\in\mathcal{F}_{\mathrm{plm}}\), we have_

\[p(f_{\mathrm{plm}}(y^{\mathrm{S}})=y^{\mathrm{T}}|y^{\mathrm{S}})=\omega_{y^{ \mathrm{S}},y^{\mathrm{T}}},\text{ s.t.}\sum_{y^{\mathrm{S}}\in\mathcal{Y}^{ \mathrm{S}}}\omega_{y^{\mathrm{S}},y^{\mathrm{T}}}=1,\forall y^{\mathrm{T}} \in\mathcal{Y}^{\mathrm{T}}.\] (11)

_Here, \(p(f_{\mathrm{plm}}(y^{\mathrm{S}})=y^{\mathrm{T}}|y^{\mathrm{S}})\) is the conditional probability that a pretrained label \(y^{\mathrm{S}}\) is mapped to a downstream label \(y^{\mathrm{T}}\)._

**Definition E.2** (_deterministic label mapping_ (DLM)).: _Let \(\mathcal{F}_{\mathrm{dlm}}\subset\mathcal{F}_{\mathrm{lm}}\) be a set of mapping functions, defined by \(f_{\mathrm{dlm}}(y^{\mathrm{S}})=g(y^{\mathrm{S}})\) for all \(y^{\mathrm{S}}\in\mathcal{Y}^{\mathrm{S}}\), where \(g(y^{\mathrm{S}})\) specifies a deterministic rule, either \(g(y^{\mathrm{S}})=y^{\mathrm{S}}\) for identity mapping; or \(g(y^{\mathrm{S}})=1-y^{\mathrm{S}}\) for flip mapping, respectively. Then, deterministic label mapping is defined as: \(\forall f_{\mathrm{dlm}}\in\mathcal{F}_{\mathrm{dlm}}\),_

\[p(f_{\mathrm{dlm}}(y^{\mathrm{S}})=y^{\mathrm{T}}|y^{\mathrm{S}})=\delta_{y^{ \mathrm{S}},g(y^{\mathrm{S}})},\text{ with }\delta_{y^{\mathrm{S}},g(y^{\mathrm{S}})}= \begin{cases}1&\text{if }g(y^{\mathrm{S}})=y^{\mathrm{T}}\\ 0&\text{otherwise}\end{cases},\] (12)

_where \(\delta\) is the Kronecker delta function, ensuring \(y^{\mathrm{T}}\) is uniquely mapped from a pretrained label \(y^{\mathrm{S}}\)._Then, we demonstrate the conditions where \(\mathrm{Acc}(f_{\mathrm{plm}})\geq\mathrm{Acc}(f_{\mathrm{dlm}})\). Since DLM is defined by \(g\), following either identity mapping or flip mapping exclusively, each case will be discussed separately.

**Lemma E.3**.: _Given a collection of paired labels \(\{(y^{\mathrm{S}},y^{\mathrm{T}})\}_{i=1}^{n}\). If the aggregate conditional probabilities \(p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=0)\geq p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=0)\) and \(p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=1)\geq p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=1)\) hold true, and considering \(f_{\mathrm{dlm}}\) is defined by identity mapping as outlined in Definition E.2, then it follows that \(\mathrm{Acc}(f_{\mathrm{plm}})\geq\mathrm{Acc}(f_{\mathrm{dlm}})\)._

Lemma E.3 (proof in Appendix E.2) implies that PLM achieves at least as high expected accuracy as DLM defined by identity mapping, under the following conditions: for downstream samples with \(y^{\mathrm{T}}=0\), the inequality is satisfied when they are more likely to correspond to pretrained samples with \(y^{\mathrm{S}}=1\) than those with \(y^{\mathrm{S}}=0\); for downstream samples with \(y^{\mathrm{T}}=1\), the inequality is satisfied when the corresponding pretrained samples are more likely to have \(y^{\mathrm{S}}=0\) than \(y^{\mathrm{S}}=1\).

**Uncertainty in Label Inter-Dependencies**. Essentially, the conditions above reflect potential complex patterns of label correspondence that arise when inter-dependencies between the labels exist across domains. While this "label mismatch" problem has been discussed in binary settings, it can be generalized to multi-class settings without loss of generality. Unlike DLM, which merely relies on a static mapping rule and hence may fail when true label correspondence conflicts with this predefined rule, PLM captures the conditional probabilities of \(y^{\mathrm{T}}\) given \(y^{\mathrm{S}}\). By harnessing the inherent uncertainty encoded in the probabilistic form of \(\omega\), PLM is expected to achieve more robust label mapping predictions.

Next, we compare PLM with DLM using the flip mapping rule.

**Lemma E.4**.: _Given a collection of paired labels \(\{(y^{\mathrm{S}},y^{\mathrm{T}})\}_{i=1}^{n}\). If the aggregate conditional probabilities \(p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=0)\leq p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=0)\) and \(p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=1)\leq p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=1)\), and \(f_{\mathrm{dlm}}\) is defined by flip mapping as outlined in Definition E.2, then \(\mathrm{Acc}(f_{\mathrm{plm}})\geq\mathrm{Acc}(f_{\mathrm{dlm}})\)._

Lemma E.4 (proof in Appendix E.2) establishes another sufficient condition under which PLM could achieve an expected accuracy at least as high as DLM defined by flip mapping. The condition applies to all downstream samples, regardless of their labels (both \(y^{\mathrm{T}}=0\) or \(y^{\mathrm{T}}=1\)), stating that it is more likely that their corresponding pretrained label being \(y^{\mathrm{S}}=1\) rather than \(y^{\mathrm{S}}=0\).

**Bias in Label Correspondences**. The bias in Label correspondence refers to a phenomenon where a disproportionate number of downstream samples correspond to pretrained samples with a specific label. For example, consider a medical diagnosis task where both pretrained and downstream data come from populations with low disease prevalence, the label correspondences may exhibit this bias [55]. While this bias may be overlooked by DLM, it could be captured and even exploited by PLM, which flexibly adjusts the weighting schemes, e.g., assigning higher value to \(\omega_{1,0}\) than \(\omega_{0,0}\) for samples where \(y^{\mathrm{T}}=0\), and to \(\omega_{1,1}\) over \(\omega_{0,1}\) for samples where \(y^{\mathrm{T}}=1\).

**Corollary E.5**.: _Let \(f_{\mathrm{plm}}\) and \(f_{\mathrm{dlm}}\) denote the label mapping functions defined in Definition E.1 and Definition E.2, respectively. Given pretrained and downstream label spaces \(\mathcal{Y}^{\mathrm{S}}=\{0,1\}\) and \(\mathcal{Y}^{\mathrm{T}}=\{0,1\}\), if for any joint distribution over \(\mathcal{Y}^{\mathrm{S}}\times\mathcal{Y}^{\mathrm{T}}\),_

\[\exists\,a\in\{0,1\}\ s.t.\ p(y^{\mathrm{S}}=a|y^{\mathrm{T}}=\bar{a})\geq p( y^{\mathrm{S}}=\bar{a}|y^{\mathrm{T}}=\bar{a}),\] (13)

_where \(\bar{a}\) is the opposite label of \(a\), then we have \(\mathrm{Acc}(f_{\mathrm{plm}})\geq\mathrm{Acc}(f_{\mathrm{dlm}})\)._

_Remark E.6_.: Corollary E.5 implies a theoretical foundation for preferring PLM over DLM in scenarios where the label mapping relationship between two domains is uncertain, biased and potentially deviates from a deterministic one-to-one mapping assumption. This finding holds importance in label mappings for VR, as the label spaces may encompass multi-class settings. Furthermore, in VR settings, the pretrained labels derived from \(f_{\mathrm{pre}}\) predictions, are subject to increased uncertainties and biases influenced by the quality and distribution of the pretrained model and dataset6.

Footnote 6: For the analysis purpose, in this section we simplify the setting and operate with ground-truth \(\mathcal{Y}^{\mathrm{S}}\). In practice, VR does not have access to true \(y^{\mathrm{S}}\) but must rely on the predicted \(y^{\mathrm{S}}\) from the well-trained \(f_{\mathrm{pre}}\) instead.

### Completed Proof of Lemma E.3 and Lemma E.4

**Lemma E.7** (_cf._ Lemma E.3).: _Given a collection of paired labels \(\{(y^{\mathrm{S}},y^{\mathrm{T}})\}_{i=1}^{n}\). If the aggregate conditional probabilities \(p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=0)\geq p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=0)\) and \(p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=1)\geq p(y^{\mathrm{S}}=0)\)._\(1|y^{\mathrm{T}}=1\)) hold true, and \(f_{\mathrm{dlm}}\) is defined by identity mapping as outlined in Definition E.2, then \(\mathrm{Acc}(f_{\mathrm{plm}})\geq\mathrm{Acc}(f_{\mathrm{dlm}})\)._

Proof.: Expand Eq. (10) by taking all possibilities of \(y^{\mathrm{T}}\), we have:

\[\begin{split}\mathrm{Acc}(f_{\mathrm{lm}})&=\mathbb{ E}_{y^{\mathrm{T}}\in\mathcal{Y}^{\mathrm{T}}}\left[\sum_{y^{\mathrm{S}}\in \mathcal{Y}^{\mathrm{S}}}p(y^{\mathrm{S}})\cdot p\left(f_{\mathrm{lm}}(y^{ \mathrm{S}})=y^{\mathrm{T}}|y^{\mathrm{S}}\right)\right]\\ &=\sum_{y^{\mathrm{T}}\in\mathcal{Y}^{\mathrm{T}}}p(y^{\mathrm{T}} )\left[\sum_{y^{\mathrm{S}}\in\mathcal{Y}^{\mathrm{S}}}p(y^{\mathrm{S}}|y^{ \mathrm{T}})\cdot p\left(f_{\mathrm{lm}}(y^{\mathrm{S}})=y^{\mathrm{T}}|y^{ \mathrm{S}},y^{\mathrm{T}}\right)\right]\\ &=\sum_{y^{\mathrm{T}}\in\mathcal{Y}^{\mathrm{T}}}p(y^{\mathrm{T}} )\left[\sum_{y^{\mathrm{S}}\in\mathcal{Y}^{\mathrm{S}}}p(y^{\mathrm{S}}|y^{ \mathrm{T}})\cdot p\left(f_{\mathrm{lm}}(y^{\mathrm{S}})=y^{\mathrm{T}}|y^{ \mathrm{S}}\right)\right].\end{split}\] (14)

Note that the conditional independence holds since the output of \(f_{\mathrm{lm}}\) relies solely on the input \(y^{\mathrm{S}}\). For DLM defined by identity mapping, \(p(f_{\mathrm{dlm}}(y^{\mathrm{S}})=y^{\mathrm{T}}|y^{\mathrm{S}})=1\) if \(y^{\mathrm{S}}=y^{\mathrm{T}}\), and \(0\) otherwise. Taking into account all the samples, the expected accuracy \(\mathrm{Acc}(f_{\mathrm{dlm}})\) can then be expressed by

\[\begin{split}\mathrm{Acc}(f_{\mathrm{dlm}})&=\sum_{y^ {\mathrm{T}}\in\mathcal{Y}^{\mathrm{T}}}p(y^{\mathrm{T}})\,p(y^{\mathrm{S}}=y^ {\mathrm{T}}|y^{\mathrm{T}})\\ &=p(y^{\mathrm{T}}=0)p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=0)+p(y^{ \mathrm{T}}=1)p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=1).\end{split}\] (15)

As for PLM, the expected accuracy can be rewritten as

\[\begin{split}\mathrm{Acc}(f_{\mathrm{plm}})&=\sum_{y ^{\mathrm{T}}\in\mathcal{Y}^{\mathrm{T}}}p(y^{\mathrm{T}})\sum_{y^{\mathrm{S}} \in\mathcal{Y}^{\mathrm{S}}}\omega_{y^{\mathrm{S}},y^{\mathrm{T}}}\cdot p(y^{ \mathrm{S}}|y^{\mathrm{T}})\\ &=p(y^{\mathrm{T}}=0)\left[\omega_{0,0}\cdot p(y^{\mathrm{S}}=0|y^ {\mathrm{T}}=0)+\omega_{1,0}\cdot p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=0)\right]\\ &\quad+p(y^{\mathrm{T}}=1)\left[\omega_{0,1}\cdot p(y^{\mathrm{S}} =0|y^{\mathrm{T}}=1)+\omega_{1,1}\cdot p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=1) \right],\end{split}\] (16)

where \(\omega_{0,0}\) stands for \(\omega_{y^{\mathrm{S}}=0,y^{\mathrm{T}}=0}\), and similarly for the remaining \(\omega_{0,1},\omega_{1,0},\omega_{1,1}\).

To evaluate the expected accuracy of \(f_{\mathrm{plm}}\) and \(f_{\mathrm{dlm}}\), we look into the comparison separately for each \(y^{\mathrm{T}}\). Specifically, for the samples with \(y^{\mathrm{T}}=0\), we aim to show that

\[\begin{split} p(y^{\mathrm{T}}=0)&\left[\omega_{0,0} \cdot p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=0)+\omega_{1,0}\cdot p(y^{\mathrm{S}}= 1|y^{\mathrm{T}}=0)\right]\\ &\geq p(y^{\mathrm{T}}=0)p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=0). \end{split}\] (17)

Given the constraints \(\omega_{0,0}+\omega_{1,0}=1\) and \(p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=0)+p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=0)=1\), the LHS of Eq. (17) becomes

\[\begin{split}& p(y^{\mathrm{T}}=0)\left[\omega_{0,0}\cdot p(y^{ \mathrm{S}}=0|y^{\mathrm{T}}=0)+\omega_{1,0}\cdot p(y^{\mathrm{S}}=1|y^{ \mathrm{T}}=0)\right]\\ &=p(y^{\mathrm{T}}=0)\left[(\omega_{0,0}\cdot p(y^{\mathrm{S}}=0| y^{\mathrm{T}}=0)+\omega_{1,0}(1-p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=0)) \right]\\ &=p(y^{\mathrm{T}}=0)\left[(\omega_{0,0}-\omega_{1,0})\cdot p(y^{ \mathrm{S}}=0|y^{\mathrm{T}}=0)+\omega_{1,0}\right].\end{split}\] (18)

The inequality we need to show is then simplified to \(p(y^{\mathrm{T}}=0)[(\omega_{0,0}-\omega_{1,0})\cdot p(y^{\mathrm{S}}=0|y^{ \mathrm{T}}=0)+\omega_{1,0}]\geq p(y^{\mathrm{T}}=0)p(y^{\mathrm{S}}=0|y^{ \mathrm{T}}=0)\). This inequality holds if \(p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=0)\leq p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=0)\).

Similarly, for samples with \(y^{\mathrm{T}}=1\), the inequality of interest is

\[\begin{split} p(y^{\mathrm{T}}=1)&\left[\omega_{1,0} \cdot p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=0)+\omega_{1,1}\cdot p(y^{\mathrm{S}}=1| y^{\mathrm{T}}=1)\right]\\ &\geq p(y^{\mathrm{T}}=1)p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=1). \end{split}\] (19)

This holds if \(p(y^{\mathrm{S}}=1|y^{\mathrm{T}}=1)\leq p(y^{\mathrm{S}}=0|y^{\mathrm{T}}=1)\).

Both conditions can be satisfied without conflict. Thus, we can confirm Lemma E.3 by evaluating these conditions jointly.

**Lemma E.8** (_cf._ Lemma E.4).: _Given a collection of paired labels \(\{(y^{\rm S},y^{\rm T})\}_{i=1}^{n}\). If the aggregate conditional probabilities \(p(y^{\rm S}=0|y^{\rm T}=0)\leq p(y^{\rm S}=1|y^{\rm T}=0)\) and \(p(y^{\rm S}=0|y^{\rm T}=1)\leq p(y^{\rm S}=1|y^{\rm T}=1)\), and \(f_{\rm dlm}\) is defined by flip mapping as outlined in Definition E.2, then \(\mathrm{Acc}(f_{\rm plm})\geq\mathrm{Acc}(f_{\rm dlm})\)._

Proof.: When defined deterministically by flip mapping, DLM can be equivalently expressed as \(p(f_{\rm dlm}(y^{\rm S})=y^{\rm T}|y^{\rm S})=1\) if \(y^{\rm S}\neq y^{\rm T}\), and \(0\) otherwise. This allows the expected accuracy of DLM to be expanded as:

\[\mathrm{Acc}(f_{\rm dlm}) =\sum_{y^{\rm T}\in\mathcal{Y}^{\rm T}}p(y^{\rm T})\,p(y^{\rm S} \neq y^{\rm T}|y^{\rm T})\] \[=\sum_{y^{\rm T}\in\mathcal{Y}^{\rm T}}p(y^{\rm T})\,\left(1-p(y^ {\rm S}=y^{\rm T}|y^{\rm T})\right)\] (20) \[=p(y^{\rm T}=0)\left(1-p(y^{\rm S}=1|y^{\rm T}=0)\right)+p(y^{\rm T }=1)\left(1-p(y^{\rm S}=0|y^{\rm T}=1)\right).\]

Meanwhile, the expected accuracy of PLM remains consistent as in Eq.16. Again, to show that \(\mathrm{Acc}(f_{\rm plm})\geq\mathrm{Acc}(f_{\rm dlm})\) holds, we compare the expected accuracy with respect to different \(y^{\rm T}\) samples separately.

For samples with \(y^{\rm T}=0\), we need to show

\[\begin{split} p(y^{\rm T}=0)&\left[\omega_{0,0}\cdot p (y^{\rm S}=0|y^{\rm T}=0)+\omega_{1,0}\cdot p(y^{\rm S}=1|y^{\rm T}=0)\right]\\ &\geq p(y^{\rm T}=0)p(y^{\rm T}=0)\left(1-p(y^{\rm S}=1|y^{\rm T}= 0)\right).\end{split}\] (21)

Given the constraints that \(\omega_{0,0}+\omega_{1,0}=1\) and \(p(y^{\rm S}=1|y^{\rm T}=0)=1-p(y^{\rm S}=0|y^{\rm T}=0)\), the LHS of Eq.21 can be expressed by

\[\begin{split} p(y^{\rm T}=0)&\left[\omega_{0,0} \cdot p(y^{\rm S}=0|y^{\rm T}=0)+\omega_{1,0}\cdot p(y^{\rm S}=1|y^{\rm T}=0) \right]\\ =p(y^{\rm T}=0)&\left[(\omega_{0,0}-\omega_{1,0}) \cdot p(y^{\rm S}=0|y^{\rm T}=0)+\omega_{1,0}\right].\end{split}\] (22)

We rearrange the terms:

\[\begin{split} p(y^{\rm T}=0)&\left[(\omega_{0,0}- \omega_{1,0})\cdot p(y^{\rm S}=0|y^{\rm T}=0)+\omega_{1,0}\right]\geq p(y^{\rm T }=0)\left(1-p(y^{\rm S}=0|y^{\rm T}=0)\right)\\ &(\omega_{0,0}-\omega_{1,0})\cdot p(y^{\rm S}=0|y^{\rm T}=0)+ \omega_{1,0}\geq 1-p(y^{\rm S}=0|y^{\rm T}=0)\\ \frac{1-p(y^{\rm S}=0|y^{\rm T}=0)-\omega_{1,0}+\omega_{1,0}\cdot p (y^{\rm S}=0|y^{\rm T}=0)}{p(y^{\rm S}=0|y^{\rm T}=0)}\leq\omega_{0,0}\\ \frac{1-p(y^{\rm S}=0|y^{\rm T}=0)-\omega_{1,0}\cdot(1-p(y^{\rm S }=0|y^{\rm T}=0))}{p(y^{\rm S}=0|y^{\rm T}=0)}\leq\omega_{0,0}\\ \frac{(1-\omega_{1,0})\cdot(1-p(y^{\rm S}=0|y^{\rm T}=0))}{p(y^{ \rm S}=0|y^{\rm T}=0)}\leq\omega_{0,0}.\end{split}\] (23)

It is then concluded that Eq.23 holds if \(p(y^{\rm S}=0|y^{\rm T}=0)\leq p(y^{\rm S}=1|y^{\rm T}=0)\).

As with \(y^{\rm T}=1\) samples, a similar derivation is performed to satisfy the inequality

\[\begin{split}& p(y^{\rm T}=1)\left[\omega_{0,1}\cdot p(y^{\rm S}=0|y^{ \rm T}=1)+\omega_{1,1}\cdot p(y^{\rm S}=1|y^{\rm T}=1)\right]\\ &\geq p(y^{\rm T}=0)p(y^{\rm T}=0)\left(1-p(y^{\rm S}=1|y^{\rm T}= 0)\right).\end{split}\] (24)

Resembling \(y^{\rm T}=0\) samples, the derivation yields the condition \(p(y^{\rm S}=0|y^{\rm T}=1)\leq p(y^{\rm S}=1|y^{\rm T}=1)\).

Notably, the condition \(p(y^{\rm S}=0|y^{\rm T}=0)\leq p(y^{\rm S}=1|y^{\rm T}=0)\) does not conflict with \(p(y^{\rm S}=0|y^{\rm T}=1)\leq p(y^{\rm S}=1|y^{\rm T}=1)\), and both conditions can be jointly satisfied. 

## Appendix F Training Details

### Dataset Information

Additional dataset information is presented in Table4. For a fair comparison, we adhere to the data partitioning scheme employed by ILM [4] through all datasets. The batch size for Oxfordpets and DTD is set to be 64 while 256 for the remaining datasets.

### Parameter Information

Consistent training settings are maintained to ensure a fair comparison. For training input VR patterns, we apply the Adam optimizer [26] with an initial learning rate of 0.01. The number of epochs is 200, with the learning rate decay being 0.1, scheduled at epochs 100 and 145. All experiments are conducted on a single A100 GPU and the average accuracy of three distinct random seeds are reported.

## Appendix G Parameter Analysis

### Choosing Hyper-parameters

As described in Section 4, the ratio \(\alpha\) is used in calculating \(k=\lfloor\alpha\cdot k_{\mathrm{T}}\rfloor\). The experimental results to tune hyper-parameters \(\alpha\) and \(\lambda\) are reported in Table 5. \(\alpha\) is chosen among \([0.01,0.05,0.15,0.5,1]\), while \(\lambda\) is chosen among \([0.01,0.1,1,10,100,1000]\). The optimized \(\lambda\) is determined first to be 1 by the average accuracy of different \(\alpha\) values, followed by deriving an optimal \(\alpha=0.15\).

While the same hyper-parameters may not necessarily be optimal across different datasets, for the sake of consistency and fairness, this paper employs identical hyper-parameters for all datasets.

### Analyzing Hyper-parameters

Figures 9 and Figure 10 illustrate the impact of \(\lambda\) and \(\alpha\) on accuracy. It is observed that the optimal hyper-parameters vary across different datasets.

In general, as \(\lambda\) increases, the test accuracy initially rises and then declines. This parameter is used to balance the contributions of individual pretrained labels. An over-small \(\lambda\) might overly rely on the distribution of pretrained labels obtained from pretrained models, while a too-large one might overlook differences among pretrained labels. Meanwhile, with an increase in \(\alpha\), accuracy first increases, then plateaus or slightly decreases. This is because excessively small or large \(\alpha\) values may

\begin{table}
\begin{tabular}{c|c c c c} \hline \hline Dataset & Original Image Size & Training Set Size & Testing Set Size & Number of Classes \\ \hline Flowers102 & 128 \(\times\) 128 & 4,093 & 2,463 & 102 \\ DTD & 128 \(\times\) 128 & 2,820 & 1,692 & 47 \\ UCF101 & 128 \(\times\) 128 & 7,639 & 3,783 & 101 \\ Food101 & 128 \(\times\) 128 & 50,500 & 30,300 & 101 \\ GTSRB & 32 \(\times\) 32 & 39,209 & 12,630 & 43 \\ EuroSAT & 128 \(\times\) 128 & 13,500 & 8,100 & 10 \\ OxfordPets & 128 \(\times\) 128 & 2,944 & 3,669 & 37 \\ StanfordCars & 128 \(\times\) 128 & 6,509 & 8,041 & 196 \\ SUN397 & 128 \(\times\) 128 & 15,888 & 19,850 & 397 \\ CIFAR10 & 32 \(\times\) 32 & 50,000 & 10,000 & 10 \\ CIFAR100 & 32 \(\times\) 32 & 50,000 & 10,000 & 100 \\ SVHN & 32 \(\times\) 32 & 73,257 & 26,032 & 10 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Detailed dataset information

\begin{table}
\begin{tabular}{c|c c c c c c} \hline \hline \(\alpha|\lambda\) & 0.01 & 0.1 & 1 & 10 & 100 & 1000 \\ \hline
0.01 & 40.5\(\pm\)0.8 & 41.7\(\pm\)1.4 & 44.1\(\pm\)0.1 & 45.1\(\pm\)0.6 & 42.9\(\pm\)0.4 & 40.5\(\pm\)0.4 \\
0.05 & 46.2\(\pm\)0.4 & 45.8\(\pm\)0.8 & 48.9\(\pm\)0.2 & 47.2\(\pm\)0.4 & 45.2\(\pm\)0.8 & 43.0\(\pm\)0.1 \\
0.15 & 48.2\(\pm\)0.4 & 49.4\(\pm\)1.0 & 50.1\(\pm\)0.6 & 48.1\(\pm\)0.6 & 45.4\(\pm\)0.7 & 44.6\(\pm\)0.2 \\
0.1 & 48.6\(\pm\)0.8 & 50.0\(\pm\)1.0 & 48.4\(\pm\)0.4 & 48.4\(\pm\)0.6 & 45.8\(\pm\)0.9 & 45.6\(\pm\)0.5 \\
1 & 49.1\(\pm\)0.8 & 50.2\(\pm\)0.2 & 49.3\(\pm\)0.7 & 49.3\(\pm\)0.6 & 45.3\(\pm\)0.7 & 44.4\(\pm\)0.7 \\ \hline Average & 46.5\(\pm\)0.6 & 47.4\(\pm\)0.9 & 48.1\(\pm\)0.4 & 47.6\(\pm\)0.5 & 44.9\(\pm\)0.7 & 43.6\(\pm\)0.4 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Tuning ratio \(\alpha\) and Laplace \(\lambda\) (ResNet-18, Flowers102, average accuracy (%))lead to the neglect of certain crucial labels or the emphasis on redundant ones during the estimation of the probability aggregation matrix. Therefore, choosing moderate values for \(\lambda\) and \(\alpha\) appears to be more appropriate.

### Task-specific Hyper-parameters

We used universal hyper-parameters to show that BLM and BLM+'s performance gains over baselines are not sensitive to hyper-parameters. However, we assume that the dataset-specific tuning for hyper-parameters could yield more optimized results.

Additional experiments are conducted using a validation set and training set split of 30% and 70% to find optimal hyper-parameters for each dataset. Results are shown in Table 6. We observe that optimal hyper-parameters tailored for each dataset achieve better performance compared to using shared hyper-parameters, which matches our assumption.

## Appendix H Limitations of BLM and BLM+

**Less effective for tasks with very few classes.** As shown in Table 1, when the number of classes (i.e., size of the label space) in downstream tasks is smaller (10 classes in SVHN and 10 classes in EuroSAT) and the original task is relatively simple, the advantage of BLM and BLM+ is not very pronounced. This is because BLM and BLM+ replace the one-to-one mapping with a pairwise-connected probabilistic LM. While this optimization yields positive results in most tasks, for a

\begin{table}
\begin{tabular}{c|c c c c c} \hline \hline  & Flowers102 & UCF101 & DTD & OxfordPets & CIFAR10 \\ \hline Specific \(\alpha\) & 0.15 & 0.15 & 0.5 & 0.5 & 0.5 \\ Specific \(\lambda\) & 1 & 1 & 1 & 10 & 10 \\ Accuracy (Trained on 70\% Samples) & 45.82 & 31.84 & **43.75** & **72.27** & **66.54** \\ \hline Shared \(\alpha\) & 0.15 & 0.15 & 0.15 & 0.15 & 0.15 \\ Shared \(\lambda\) & 1 & 1 & 1 & 1 & 1 \\ Accuracy (Trained on 70\% Samples) & 45.82 & 31.84 & 42.31 & 70.52 & 66.04 \\ \hline \hline \end{tabular}
\end{table}
Table 6: Difference between task-specific parameters and shared parameterssmall subset of simple tasks, the one-to-one mapping may better reflect the relationship between the pretrained label space and the downstream label space. For such tasks, BLM and BLM+ no longer exhibit significant effects.

**Not solving the cases where VR is not applicable for downstream tasks.** For example, in the case of the StanfordCars dataset in vision models, as shown in Table 1 and Table 2, the accuracy of the downstream task remains consistently low (<10%) through learning using input VR. While applying BLM and BLM+ in such scenarios yields better results compared to using one-to-one mapping, it still cannot significantly enhance VR performance to the extent of being comparable to finetuning the entire model.

## Appendix I Visualization of Label Mapping Matrices

Based on the example of ResNet-18 pretrained on ImageNet-1K applying to the downstream task CIFAR10, Figure 11 depicts the visualization results of LM matrices. The first row in Figure 11 shows the results of gradient-free methods BLM and BLM+, while the second row shows deep learning-based methods which learn a linear neural network for \(f_{\mathrm{out}}^{\omega}\). 'Deep Learning' refers to a single-layer neural network without constraints (i.e., \(\omega\in\mathbb{R}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\)), while 'Deep Learning + Sigmoid' refers to applying the Sigmoid function to restrict \(\omega\in[0,1]^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\) aligning with the range of \(\omega_{\mathrm{BLM}}\) and \(\omega_{\mathrm{BLM+}}\). The right part of Figure 11 depicts the specific pretrained and downstream labels corresponding to these matrices.

It is observed that BLM and BLM+ are good at revealing similarities between pretrained and downstream labels. For example, for the downstream label 'Airplane', which visually resembles 'Great White Shark', 'Hammerhead' and 'Stingray', the weights in \(\omega_{\mathrm{BLM}}\) or \(\omega_{\mathrm{BLM+}}\) tend to be

Figure 11: The visualization results of the LM matrices. Using the example of ResNet-18 pretrained on ImageNet-1K applied to the downstream task CIFAR10, the left figure displays the first 10 rows and 10 columns of the LM matrices (including the result matrix of the first 10 pretrained and downstream labels), while the right figure presents specific labels. Compared to gradient-free LM methods (i.e., BLM and BLM+), deep learning-based methods (i.e., a single-layer unrestricted neural network \(\omega\in\mathbb{R}^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\) and a single-layer neural network with Sigmoid \(\omega\in[0,1]^{k_{\mathrm{S}}\times k_{\mathrm{T}}}\)) demonstrate less interpretability in revealing the relationship between labels.

higher. Conversely, for dissimilar labels like 'Truck' and 'Ostrich', the weights will be approaching 0. However, the weight matrices obtained from deep learning-based methods fail to capture such clear-label relationship. The results demonstrate the advantages of BLM and BLM+ in terms of interpretability.

## Appendix J Training Cost Analysis

**The Required Number of Epochs.** Different label mapping methods require varying numbers of epochs to converge. We initially used 200 epochs as with [4] to ensure a fair comparison with the baseline methods. Additional experiments are conducted to assess the impact of different epoch numbers from [60, 100, 150] on our BLM and BLM+ model, using ResNet-18 as the pretrained model. The results are shown in Table 7.

We found that running 100 epochs yields results comparable to those achieved with 200 epochs. This demonstrates that BLM and BLM+ require less convergence time, highlighting their efficiency.

**Overall Time Consumption.** Table 8 presents a comparison of different output mapping methods in terms of computational resources, utilizing the Flowers102 dataset as the downstream task. Gradient-free LM refers to estimating output mappings using statistical methods, while deep learning-based LM treats label mapping as a single linear layer neural network attached after the pretrained models. 'BLM*' and 'BLM+*' refer to training with only 100 epochs as is shown in Table 7. It should be noted that the running times for ILM, BLM, and BLM+ are measured using the quick version (see Appendix D.6 for details). Apart from VR methods, which fix the pretrained model, the time costs associated with directly finetuning pretrained models are also listed. Here, the term 'Linear' refers to finetuning the final layer of the pretrained model, while 'Fully' refers to finetuning the entire model.

Besides, regarding the performance of finetuning methods on downstream tasks compared with VR, please refer to [4] for more discussion. Since we mainly focus on LM methods for VR in this paper, which has a different problem setting with finetuning, the performance comparison of VR and finetuning will not be addressed here.

\begin{table}
\begin{tabular}{c|c c c c|c c c c|c c c} \hline \hline  & \multicolumn{4}{c|}{BLM} & \multicolumn{4}{c|}{BLM+} & \multicolumn{4}{c}{ILM} & FLM \\ \hline Epochs & 60 & 100 & 150 & 200 & 60 & 100 & 150 & 200 & 200 & 200 \\ Average Accuracy & \multirow{2}{*}{44.5} & \multirow{2}{*}{45.2} & \multirow{2}{*}{45.5} & \multirow{2}{*}{45.3} & \multirow{2}{*}{45.8} & \multirow{2}{*}{46.4} & \multirow{2}{*}{46.9} & \multirow{2}{*}{46.7} & \multirow{2}{*}{40.6} & \multirow{2}{*}{37.2} \\ on 12 Tasks (\%) & & & & & & & & & & & \\ \hline \hline \end{tabular}
\end{table}
Table 7: Impact of epoch numbers on different label mapping methods

\begin{table}
\begin{tabular}{c|c c c c c c|c c} \hline \hline  & \multicolumn{4}{c|}{Gradient-free LM} & \multicolumn{4}{c}{Deep Learning-} \\  & \multicolumn{4}{c|}{} & \multicolumn{4}{c|}{based LM} & \multicolumn{4}{c}{Finetuning} \\ \hline  & FLM & ILM & BLM & BLM+ & **BLM* & **BLM+* & - & Linear & Fully \\ \hline Back- & \multirow{2}{*}{No} & \multirow{2}{*}{No} & \multirow{2}{*}{No} & \multirow{2}{*}{No} & \multirow{2}{*}{No} & \multirow{2}{*}{No} & \multirow{2}{*}{Yes} & \multirow{2}{*}{-} & \multirow{2}{*}{-} \\  & \multicolumn{4}{c|}{} & \multicolumn{4}{c|}{} & \multicolumn{4}{c|}{ResNet-18} & \\ \hline Parameter & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.20} & \multirow{2}{*}{0.51} & \multirow{2}{*}{11.7} \\ Number (M) & & & & & & & & & & \\ Whole & \multirow{2}{*}{11.97} & \multirow{2}{*}{12.04} & \multirow{2}{*}{11.95} & \multirow{2}{*}{13.06} & \multirow{2}{*}{**6.03**} & \multirow{2}{*}{**6.52**} & \multirow{2}{*}{12.34} & \multirow{2}{*}{14.03} & \multirow{2}{*}{15.28} \\ Time (min) & & & & & & & & & & \\ \hline Parameter & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.10} & \multirow{2}{*}{0.20} & \multirow{2}{*}{2.0} & \multirow{2}{*}{88.8} \\ Number (M) & & & & & & & & & & \\ Whole & \multirow{2}{*}{24.68} & \multirow{2}{*}{24.81} & \multirow{2}{*}{24.51} & \multirow{2}{*}{24.71} & \multirow{2}{*}{**12.33**} & \multirow{2}{*}{**12.44**} & \multirow{2}{*}{24.80} & \multirow{2}{*}{24.49} & \multirow{2}{*}{35.07} \\ Time (min) & & & & & & & & & & \\ \hline \hline \end{tabular}
\end{table}
Table 8: Training cost analysis of LM & VR and none-VR finetuning (on Flowers102)We therefore analyze the efficiency of BLM and BLM+ from three perspectives:

* Extra Consumption of Calculating the Mapping Matrix Compared with One-to-One Mapping: Compared to the baseline method ILM, the additional cost for BLM and BLM+ primarily involves the gradient-free multiplication and division within the mapping matrix (which is sized according to the source and target label spaces, \(1000\times 102\) in this case). This additional cost is minimal, as shown in Table 8.
* Time Consumption of Updating the Mapping Matrix per Epoch: Compared with FLM, updating \(\omega\) in ILM, BLM, and BLM+ does not require running the model to obtain current predictions for each epoch. Instead, predictions from the most recent epoch can be reused (see Appendix D.6). As a result, there is no noticeable time overhead for updating \(\omega\) per epoch, as indicated by Table 8.
* Time Consumption of LM and VR Compared with Deep Learning-based Methods: It is observed that methods based on deep learning introduce a substantial number of extra parameters (which would further increase with larger downstream label space and higher pretrained model complexity) along with the necessity of backpropagation for gradient computation. Conversely, the gradient-free LM methods along with VR emphasized in this study do not encounter these challenges.

## Appendix K More Results on Visual Classification Tasks

Figures 12-16 illustrate the visualization results of label mapping using ILM (one-to-one mapping), BLM, and BLM+ for VR on various datasets with pretrained ResNet-18. For BLM and BLM+, the top three contributing pretrained labels corresponding to the downstream label are presented, along with their respective weights.

**Results when the pretrained and downstream labels exhibit appearance resemblance.** Figures 12 and 15 respectively depict the outcomes on Flowers102 and Food101 datasets, each about classification tasks of various flowers and food. BLM+ is adept at assigning higher weights to pretrained labels with a greater resemblance to the downstream label in terms of _color_, _shape_, and _intricate features_. In terms of _color_, as evidenced in Figure 15, the top-weighted labels for 'Edamame' comprise 'Green Snake', 'Artichoke', and 'Green Mamba', all sharing a green hue. Regarding _shape_, in Figure 12, the 'Gazania' with petal stripes corresponds to top weighted labels such as 'Banana' and 'Zucchini', which exhibit similar striping patterns. As for _intricate features_, in Figure 12, the 'Globe Thistle' with needle-like appearance aligns with top weighted labels including 'Sea Urchin', 'Porcupine', and 'Cardoon', which possess akin prickly characteristics.

**Results when the pretrained and downstream labels exhibit similarities in texture.** Figure 13 presents the results on the DTD dataset, which pertains to the classification of various textures. Both BLM+ and BLM assign higher weights to labels sharing akin textures. For example, 'Spiralled'

Figure 12: Label mapping results of ILM, BLM, BLM+ for VR on Flowers102 dataset.

corresponds to top-weighted labels embodying spiral-shaped entities such as 'Snail', 'Centipede', and 'Coil', while 'Fibrous' aligns with entities possessing a rough and fibrous texture, including 'Hay', 'Komodor', and 'Porcupine'.

**Results when the pretrained and downstream labels exhibit similarities in backgrounds.** Figure 14 illustrates the results on the UCF101 dataset, a dataset for action classification. In this task, both BLM and BLM+ tend to assign higher weights to pretrained labels with backgrounds or environments akin to the downstream labels. For example, the action 'Apply Lipstick' often involves the presence of a human face; hence, pretrained labels such as applying 'Lipstick', eating 'Ice Lolly', and spraying 'Hair Spray' contribute significantly. Likewise, labels closely associated with 'Baseball pitch' include 'Ballplayer' and 'Scoreboard', featuring backgrounds of vast grass fields.

**Results when pretrained and downstream labels exhibit inclusion relationship.** Figure 16 illustrates the results on the CIFAR10 dataset, which comprises images broadly categorized into ten main classes, with each category corresponding to several subcategories within the pretrained domain. It is noted that unlike the singular class selection of ILM, both BLM and BLM+ allocate similar weights to multiple subcategories. For example, 'Dog' corresponds to different breeds such as 'Cocker Spaniel', 'English Springer', and 'English Setter', while 'Bird' encompasses subcategories including 'Peacock', 'Albatross', and 'Little Blue Heron'. Hence, the learning framework of BLM and BLM+ demonstrates effective handling of the inclusion relationship between label spaces.

Figure 14: Label mapping results of ILM, BLM, BLM+ for VR on UCF101 dataset.

Figure 13: Label mapping results of ILM, BLM, BLM+ for VR on DTD dataset.

## Appendix L Applications on Vision-Language Models

### Learning Framework

The distinction between _Vision-Language Models_ (VLM) and vision models lies in (1) vision models take a single image as input, whereas VLMs take a pair of text and images as input; and (2) vision models have fixed pretrained labels, with model outputs being logits, while VLMs lack pretrained labels, with model outputs being the cosine similarity [57] between images and text embeddings. As a result, when applying BLM and BLM+ to VLM, it is necessary to design an input text set to replace the original pretrained labels in vision models.

In this paper, we follow a previous work [4] and construct the input texts set by taking the Cartesian product [56] of the downstream label set and the prompt set. BLM and BLM+ can be applied to compute the joint frequency distribution (for BLM) or aggregated predicted probability (for BLM+) between the input texts and the downstream ground-truth labels. This enables the mapping from candidate input texts to probable classification results.

The full process of learning \(\omega_{\mathrm{BLM}},\omega_{\mathrm{BLM+}}\) for vision models or VLMs is illustrated in Figure 17. Besides, the pipeline and algorithm details are the same as BLM and BLM+ for vision models shown in Figure 2, Algorithm 7 and 9.

Figure 16: Label mapping results of ILM, BLM, BLM+ for VR on CIFAR10 dataset.

Figure 15: Label mapping results of ILM, BLM, BLM+ for VR on Food101 dataset.

### Performance Results

Table 9 presents the performance of BLM and BLM+ applied to VLMs across 12 datasets. For a fair comparison, we follow the previous work [1] to employ CLIP as the pretrained model and a watermarking-based VR with an outer frame size of 30. We utilized an initial learning rate of 40 and a Cosine Annealing learning rate schedule [35], with a total of 200 epochs. An SGD optimizer with a momentum of 0.9 was employed for learning the Input VR. Results without label mapping (denoted by 'None') and one-to-one mapping served as the baseline, and the average accuracy was computed over three different random seeds.

From the performance results, it can be observed that except for the EuroSAT dataset, which has a small number of classes and simpler tasks (this limitation will be discussed in detail in Appendix H), BLM or BLM+ achieves improvements across all other tasks. They achieve the average accuracy of 79.1% and 79.3%, respectively, without increasing the number of model parameters to be trained. This empirical evidence demonstrates that BLM and BLM+ can also be effectively applied to VLMs.

Figure 17: The framework of learning \(\omega_{\mathrm{BLM}}\) or \(\omega_{\mathrm{BLM+}}\) for pretrained vision models (upper) or VLMs (lower). As described in Section 4, for vision models, \(\omega_{\mathrm{BLM}}\) or \(\omega_{\mathrm{BLM+}}\) is derived from the frequency distribution (in BLM) or probability aggregation matrix (in BLM+) where pairs of [predicted pretrained label, ground-truth downstream label] are calculated. Nevertheless, for VLMs, the predicted pretrained label is replaced by possible text inputs from the Cartesian product of the downstream label set, and the prompt set. The cosine similarities of images and text embedding are calculated in VLMs to replace the output logits in vision models.

### Visualization Results

Figures 18-22 show the visualization results of top-weighted input texts on different datasets applying BLM and BLM+. It is evident that, unlike the single optimal text input in one-to-one mapping, BLM and BLM+ assign different weights to many possible descriptions. For example, in CIFAR10, an image of a bird may be described as 'a low-resolution photo of a bird', 'a close-up photo of the bird', or 'this is a photo of a bird', among others. Such methods affirm different expressions instead of only one description using one-to-one LM.

These experiments further demonstrate that BLM and BLM+ can be used to enhance the performance of input VR in VLMs while providing reasonable explanations for why input VR in VLMs can effectively work.

\begin{table}
\begin{tabular}{c|c c|c c} \hline \hline CLIP (ViT-B32) & \multicolumn{2}{c|}{Baseline} & \multicolumn{2}{c}{Ours} \\ \hline Method & None & One-to-one & BLM & BLM+ \\  & & Mapping & & \\ \hline Flowers102 & 70.5\(\pm\)0.7 & 75.5\(\pm\)1.0 & **76.9\(\pm\)**1.9 & 76.4\(\pm\)1.5 \\ DTD & 61.4\(\pm\)0.6 & 59.5\(\pm\)1.1 & 60.9\(\pm\)0.9 & **61.5\(\pm\)**0.3 \\ UCF101 & 67.5\(\pm\)0.1 & 67.9\(\pm\)0.6 & 72.2\(\pm\)0.2 & **72.3\(\pm\)**0.4 \\ Food101 & 79.2\(\pm\)0.2 & 78.1\(\pm\)0.3 & 79.3\(\pm\)0.1 & **79.4\(\pm\)**0.1 \\ GTSRB & 91.4\(\pm\)0.4 & 91.3\(\pm\)0.2 & **91.5\(\pm\)**0.2 & 90.9\(\pm\)1.0 \\ EuroSAT & **96.6\(\pm\)**0.1 & 96.5\(\pm\)0.1 & 96.3\(\pm\)0.1 & 96.3\(\pm\)0.1 \\ OxfordPets & 88.4\(\pm\)0.1 & 86.8\(\pm\)0.6 & 88.6\(\pm\)0.5 & **89.0\(\pm\)**0.4 \\ StanfordCars & 57.9\(\pm\)0.1 & 55.8\(\pm\)0.1 & 59.8\(\pm\)0.7 & **60.3\(\pm\)**0.2 \\ SUN397 & 61.4\(\pm\)0.2 & 60.6\(\pm\)0.1 & 63.1\(\pm\)0.2 & **63.8\(\pm\)**0.2 \\ CIFAR10 & 94.0\(\pm\)0.2 & 94.1\(\pm\)0.1 & **94.2\(\pm\)**0.2 & 94.1\(\pm\)0.3 \\ CIFAR100 & 75.1\(\pm\)0.2 & 74.8\(\pm\)0.1 & 75.4\(\pm\)0.5 & **75.5\(\pm\)**0.3 \\ SVHN & 91.3\(\pm\)0.2 & 91.3\(\pm\)0.2 & 91.5\(\pm\)0.1 & **91.7\(\pm\)**0.1 \\ \hline Average & 77.9 & 77.7 & 79.1 & **79.3** \\ \hline \hline \end{tabular}
\end{table}
Table 9: Performance comparison on VLMs (mean % ± std %)

Figure 18: Results of ILM, BLM, BLM+ for VR on Flowers102 dataset.

Figure 19: Results of ILM, BLM, BLM+ for VR based on CLIP on DTD Dataset.

Figure 20: Results of ILM, BLM, BLM+ for VR based on CLIP on UCF101 dataset.

Figure 21: Results of ILM, BLM, BLM+ for VR based on CLIP on Food101 dataset.

Figure 22: Results of ILM, BLM, BLM+ for VR based on CLIP on CIFAR10 dataset.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The claims made in the abstract are detailed in the introduction part, and further discussed in each section. Each paragraph in the introduction is provided with a corresponding link to certain sections. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The limitations are discussed in Appendix H. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [Yes] Justification: All assumptions and proof are included in Appendix E. Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: All implementation details (described in Appendix F) have been included. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: The link to the code has been provided in the abstract. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Detailed dataset information is included in Section 5 and Appendix F. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Experiments are run on three seed with the standard divination being reported in Table 1, 2 and 9, and also shown in strip areas in Figure 9-10. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).

* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The computer resources have been discussed in Appendix F and detailed in Appendix J. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research conducted in the paper conform with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: Since methods proposed in this paper are used to improve the performance of VR in downstream classification tasks, there is no potential societal impact. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.

* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA]. Justification: The paper does not release data or models that have a high risk for misuse. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: Creators or original owners of code or data have been cited. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.

* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.