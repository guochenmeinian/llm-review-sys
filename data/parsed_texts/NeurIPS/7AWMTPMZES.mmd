# Discrete Modeling via Boundary Conditional Diffusion Processes

Yuxuan Gu\({}^{\dagger}\) Xiaocheng Feng\({}^{\dagger\ddagger}\) Lei Huang\({}^{\dagger}\) Yingsheng Wu\({}^{\dagger}\) Zekun Zhou\({}^{\dagger}\)

Weihong Zhong\({}^{\dagger}\) Kun Zhu\({}^{\dagger}\) Bing Qin\({}^{\dagger\ddagger}\)

\({}^{\dagger}\)Harbin Institute of Technology Peng Cheng Laboratory

{yxgu,xcfeng,lhuang,yswu,zkzhou,whzhong,kzhu,qinb}@ir.hit.edu.cn

###### Abstract

We present an novel framework for efficiently and effectively extending the powerful continuous diffusion processes to discrete modeling. Previous approaches have suffered from the discrepancy between discrete data and continuous modeling. Our study reveals that the absence of guidance from discrete boundaries in learning probability contours is one of the main reasons. To address this issue, we propose a two-step forward process that first estimates the boundary as a prior distribution and then rescales the forward trajectory to construct a boundary conditional diffusion model. The reverse process is proportionally adjusted to guarantee that the learned contours yield more precise discrete data. Experimental results indicate that our approach achieves strong performance in both language modeling and discrete image generation tasks. In language modeling, our approach surpasses previous state-of-the-art continuous diffusion language models in three translation tasks and a summarization task, while also demonstrating competitive performance compared to auto-regressive transformers. Moreover, our method achieves comparable results to continuous diffusion models when using discrete ordinal pixels and establishes a new state-of-the-art for categorical image generation on the Cifar-10 dataset.

## 1 Introduction

Discrete modeling is essential due to the natural prevalence of discreteness in numerous domains, including proteins (Madani et al., 2020, 2023), images (Parmar et al., 2018; Dosovitskiy et al., 2021), and natural language (Sutskever et al., 2014; Brown et al., 2020). Recent dominant framework for discrete modeling is the Transformer (Vaswani et al., 2017) with an autoregressive manner. While achieving impressive performance, it does suffer from a slow step-by-step generation process, especially for long sequences. Continuous Diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020), on the contrary, exhibit the ability to recover high-dimensional data from noise in parallel with limited iteration steps. Although proved to be effective in continuous data generation (Rombach et al., 2022; Kong et al., 2021), they continue to encounter challenges in discrete modeling (Austin et al., 2021; Chen et al., 2023; Li et al., 2022; Gong et al., 2023).

In this paper, we reveal a significant discrepancy pertaining to the modeling of discrete data using continuous diffusion models. Current approaches represent a discrete sample with a vector point in the continuous space. The diffusion process learns a neural network to model the probability distributions that recovers this continuous point from Gaussian noise. However, the discrete data actually corresponds to an area in the continuous space rather than a single point, where the oversimplified assumption leads to a mismatch between learned probability contours and the boundary of the discrete area. Take language generation as an example, a word is represented with an embedding vector in the embedding space. To generate this word, it is impractical to strictly enforce the predicted vector to be an exact match to the embedding. On the contrary, vectors around this embedding can also generatethe same word, thereby defining the collective area they encompass as a discrete area of this word. As illustrated in Figure 1A, suppose the learned probability density function is \(p_{\theta}(\mathbf{x})\) and two points \(\mathbf{x}^{i}\) and \(\mathbf{x}^{o}\) are sampled in the same density contour where \(p_{\theta}(\mathbf{x}^{i})=p_{\theta}(\mathbf{x}^{o})\). It is obvious that \(\mathbf{x}^{i}\) lies in the discrete area and is able to recover the discrete data while \(\mathbf{x}^{o}\) can not. This means that the diffusion model only learns a simplified scenario that does not match the real probability distribution.

To address the issues above, we proposed to take the boundaries of discrete areas as priors, as shown in Figure 1B, where boundary curves are regarded as oracle contours. As it gradually approaches the discrete boundary, the learned density contours of diffusion models are expected to transform from Gaussian distributions to the boundary distribution. Therefore, we propose to divide the forward process into two steps. First is the boundary estimation where we precisely calculate the stopping time \(t_{0}\) and position \(\mathbf{x}_{t_{0}}\) at which the forward trajectory cross the boundary. Then we rescale the trajectory for both training and inference stages to make the sampling probability of noisy point \(\mathbf{x}_{t}\) conditioned on the boundary. To make the boundary estimation tractable (appendix A) and eliminate randomness in conditional state transitions \(\mathbf{x}_{t_{0}}\rightarrow\mathbf{x}_{t}\), we utilize the Ordinary Differential Equations (ODEs) to describe the forward trajectory.

Our approach is experimented in both language modeling and discrete image generation. On three machine translation datasets (Iwslt14 de-en[2], Wmt14 en-de, Wmt16 en-ro) and a text summarization dataset (Gigaword[16]) for language modeling, our proposed approach not only significantly improves existing diffusion models to at most \(7.8\%\) but also achieves competitive performance to autoregressive transformers. For image generation on Cifar-10 [11], our model realizes a comparable result to continuous diffusion models with discrete ordinal pixels and establishes a new state-of-the-art for categorical pixels.

## 2 Preliminaries

Diffusion ModelsTo model a real distribution \(q(\mathbf{x}_{0})\), diffusion models utilize a forward process \(p_{t}(\mathbf{x}|\mathbf{x}_{0})\) with \(T\) steps to gradually add Gaussian noise \(\pi(\mathbf{x})=\mathcal{N}(\mathbf{0},\mathbf{I})\) into the data distribution, where \(p_{T}(\mathbf{x}|\mathbf{x}_{0})=\pi(\mathbf{x})\). There are different architectures for the forward process. A common approach [14] considers the forward process as the Markovian process, where \(p_{t}(\mathbf{x}|\mathbf{x}_{0})=\prod_{s=1}^{t}p_{s}(\mathbf{x}_{s}|\mathbf{ x}_{s-1})\) combines a series of Gaussian distributions. Thus the forward process follows a Gaussian distribution that \(p_{t}(\mathbf{x}|\mathbf{x}_{0})=\mathcal{N}(\sqrt{\bar{\alpha}_{t}}\mathbf{x }_{0},(1-\bar{\alpha}_{t})\mathbf{I})\) (Variance Preserving) or \(p_{t}(\mathbf{x}|\mathbf{x}_{0})=\mathcal{N}(\mathbf{x}_{0},\sigma_{t}^{2} \mathbf{I})\) (Variance Exploding) [21], where noise scheduler \(\bar{\alpha}_{t}\) monotonically decreases from 1 to 0 and \(\sigma_{t}\) increases from sufficiently small to the maximum pairwise distance between all training data points. To recover data from noise, diffusion processes train neural networks \(\mathbf{x}_{\theta}(\mathbf{x}_{t},t)\) to predict \(\mathbf{x}_{0}\) (other equivalent targets include \(\boldsymbol{\epsilon}\) and \(\nabla\log p(\mathbf{x}_{t})\)) from \(\mathbf{x}_{t}\sim p_{t}(\mathbf{x}|\mathbf{x}_{0})\):

\[\mathcal{L}_{\theta}=\mathbb{E}_{t\sim\mathcal{U}_{(1,T)},\mathbf{x}_{0}\sim q (\mathbf{x}_{0}),\mathbf{x}_{t}\sim p_{t}(\mathbf{x}|\mathbf{x}_{0})}\left[ \left\|\mathbf{x}_{0}-\mathbf{x}_{\theta}(\mathbf{x}_{t},t)\right\|^{2} \right].\] (1)

Samples are generated with a series of reverse state transition \(p(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{\theta}(\mathbf{x}_{t},t))\).

Flow MatchingAnother architecture [11] utilizes the ODEs and defines a time-dependent flow function \(\phi_{t}(\mathbf{x})=\sigma_{t}(\mathbf{x}_{0})\mathbf{x}+\mu_{t}(\mathbf{x}_{ 0})\) that maps \(p_{t}(\mathbf{x}|\mathbf{x}_{0})=[\phi_{t}]_{*}\pi(\mathbf{x})=\pi(\phi_{t}^{ -1}(\mathbf{x}))\left|\det\frac{\mathrm{d}\phi_{*}^{-1}(\mathbf{x})}{\mathrm{d }\mathbf{x}}\right|=\mathcal{N}(\mu_{t}(\mathbf{x}_{0}),\sigma_{t}^{2}(\mathbf{ x}_{0})\mathbf{I})\), where \(\mu_{t}\) and \(\sigma_{t}\) can be the same as in diffusion

Figure 1: (A) Blue and green curves are the learned probability density contours of the diffusion model for two data points. The red area is the discrete area of the blue data \(\mathbf{x}_{0}\) and the boundary of this area is naturally a density contour. The discrete boundary is a complex hypersurface in the high-dimensional continuous space and we simplify it into a red line for convenience of description. As observed in the magnified part, the learned contours deviate from the boundary contour, resulting in inconsistent probability densities and gradient directions. (B) We consider the discrete boundary as priors for the diffusion process to estimate a more appropriate probability distribution, where the learned contours are expected to follow the shape of the discrete boundary.

models or a more straightforward form that \(\mu_{t}=(1-\frac{t}{T})\mathbf{x}_{0}\) and \(\sigma_{t}=\frac{t}{T}\). Recovering data from noises relies on the vector field \(u_{t}(\mathbf{x}|\mathbf{x}_{0})\) that generates the probability path with the ODE \(\mathrm{d}\phi_{T-t}(\mathbf{x})=u_{T-t}(\phi_{T-t}(\mathbf{x})|\mathbf{x}_{0} )\mathrm{d}t,t:0\to T\). Neural networks \(u_{\theta}(\mathbf{x},t)\) are trained to estimate the vector field \(u_{t}(\mathbf{x}|\mathbf{x}_{0})\) via the following objective:

\[\mathcal{L}_{\theta}=\mathbb{E}_{t\sim\mathcal{U}_{(1,T)},\mathbf{x}_{0}\sim q (\mathbf{x}_{0}),\mathbf{x}_{T}\sim\mathbf{r}(\mathbf{x})}\left[\left\|u_{ \theta}(\phi_{t}(\mathbf{x}_{T}),t)-\frac{\mathrm{d}\phi_{t}(\mathbf{x}_{T})}{ \mathrm{d}t}\right\|^{2}\right].\] (2)

Besides, the vector field is proved to have the form:

\[u_{t}(\mathbf{x}|\mathbf{x}_{0})=\frac{\sigma_{t}^{\prime}(\mathbf{x}_{0})}{ \sigma_{t}(\mathbf{x}_{0})}\left(\mathbf{x}-\mu_{t}(\mathbf{x}_{0})\right)+ \mu_{t}^{\prime}(\mathbf{x}_{0}),\text{ where apostrophe indicates derivative to }t.\] (3)

## 3 Methodology

As illustrated in Figure 2, our objective is to refine the probability density contours of \(p_{t}(\mathbf{x}|\mathbf{x}_{0})\) so that they better fit the boundaries of discrete samples while still allowing for the ease of sampling. Let \(\mathbf{x}_{0}\) denote the samples from a real distribution \(q(\mathbf{x}_{0})\). Obtaining a boundary-aware corresponding noisy data \(\mathbf{x}\) at time \(t\in[1,T]\) is \(p_{t}(\mathbf{x}|\mathbf{x}_{0})=\int p_{t}(\mathbf{x},\mathbf{x}_{t_{0}},t_{ 0}|\mathbf{x}_{0})\mathrm{d}\mathbf{x}_{t_{0}}\mathrm{d}t_{0}\), where \(t_{0}\) is a random variable distributed according to when the diffusion trajectory and the discrete boundary intersect, and \(\mathbf{x}_{t_{0}}\) is the corresponding sample point at \(t_{0}\). Then the forward process is rescaled in two steps:

\[\tilde{p}_{t}(\mathbf{x}|\mathbf{x}_{0})=\int\frac{\tilde{p}_{t}(\mathbf{x}| \mathbf{x}_{t_{0}},t_{0},\mathbf{x}_{0})}{\text{Trajectory Rescaling}}\quad \frac{p(\mathbf{x}_{t_{0}},t_{0}|\mathbf{x}_{0})}{\text{Boundary Estimation}}\mathrm{d} \mathbf{x}_{t_{0}}\mathrm{d}t_{0},\] (4)

where the latter term is to calculate the discrete boundaries and the former term is to rescale the forward trajectory. In order to make the equation tractable and ensure that \(\mathbf{x}\) and \(\mathbf{x}_{t_{0}}\) are on the same trajectory, we model the forward process with flow functions \(\phi_{t}(\mathbf{x})\) and extend the notation as:

\[\psi_{t}(\mathbf{x})=\mathbf{u}(\mathbf{x}_{0},t)\;\mathbf{x}_{0}+\mathbf{v} (\mathbf{x}_{0},t)\;\mathbf{x},\quad p_{t}(\mathbf{x}|\mathbf{x}_{0})=[\psi_{ t}]_{*}\pi(\mathbf{x})\] (5)

where \(\mathbf{u}(\cdot)\) and \(\mathbf{v}(\cdot)\) are coefficient functions and sampling \(\mathbf{x}_{t}\) from \(p_{t}(\mathbf{x}|\mathbf{x}_{0})\) equals to

\[\mathbf{x}_{t}=\psi_{t}(\bm{\epsilon}),\quad\bm{\epsilon}\sim\pi(\mathbf{x}) =\mathcal{N}(\mathbf{0},\mathbf{I}).\] (6)

### Estimate Discrete Boundaries

Before figuring out the joint distribution \(p(\mathbf{x}_{t_{0}},t_{0}|\mathbf{x}_{0})\), let's start by discussing how to verify whether an arbitrary point \(\mathbf{x}\) in the continuous space belongs to the discrete area of \(\mathbf{x}_{0}\). Suppose \(\mathbf{x}_{0}\), which exists in the continuous space \(S\), is the representation vector of a discrete random variable \(\mathcal{I}\) in a discrete space with \(K\) states. Besides, \(\mathcal{J}\) is another discrete random variable _i.i.d._ with \(\mathcal{I}\). We define the discrete area of \(\mathbf{x}_{0}\) in the continuous space \(S\) as:

\[C_{\mathcal{I}}=\{\forall\mathbf{x}\in S|f(\mathbf{x},\mathcal{I})>f(\mathbf{x },\mathcal{J}),\forall\mathcal{J}\neq\mathcal{I}\},\] (7)

Figure 2: (A) Rescaled Probability Contours. The bold curve \(1\sigma\) is the density contour of one standard deviation. As the time \(t\) decreases from \(T\) to \(0\), the rescaled contours will gradually fit the discrete boundary and probability densities will also concentrate to this boundary. (B) Rescaled Forward Trajectory. Original forward trajectory \(\mathbf{x}_{0}\rightarrow\mathbf{x}_{t_{0}}\rightarrow\mathbf{x}_{\tau}\) is rescaled to be a boundary conditional trajectory \(\tilde{\mathbf{x}}_{1}\rightarrow\tilde{\mathbf{x}}_{t}\) that starts from \(\tilde{\mathbf{x}}_{1}=\mathbf{x}_{t_{0}}\). The rescaled forward distribution \(\tilde{p}_{t}(\tilde{\mathbf{x}}_{t}|\mathbf{x}_{0})\) is transformed from the discrete boundary to Gaussian distributions.

where \(f(\mathbf{x},\mathcal{I})\) is a function assessing the likelihood of an arbitrary continuous point \(\mathbf{x}\) inside the discrete area of \(\mathbf{x}_{0}\). For instance, in language modeling, \(K\) is the vocabulary size. \(\mathcal{I},\mathcal{J}\in K^{n}\) are two different sequences of \(n\) tokens and \(\mathbf{x}_{0}\in\mathbb{R}^{[n,m]}\) is a sequence of \(m\)-dimensional vector embeddings for \(\mathcal{I}\). \(f(\mathbf{x},\mathcal{I})\) is the dot similarity function. \(C_{\mathcal{I}}\) collects all vectors in the embedding space that will be decoded to generate \(\mathcal{I}\) and excludes vectors associated with any other token sequences \(\mathcal{J}\).

Given a noisy point \(\mathbf{x}_{t_{0}}\) locating at the boundary between \(C_{\mathcal{I}}\) and \(C_{\mathcal{J}}\), we can get \(|f(\mathbf{x}_{t_{0}},\mathcal{I})-f(\mathbf{x}_{t_{0}},\mathcal{J})|=0\) based on previous definition. Replacing \(\mathbf{x}_{t_{0}}\) with eqs. (5) and (6), there is:

\[f(\mathbf{u}_{t_{0}}\mathbf{x}_{0}+\mathbf{v}_{t_{0}}\boldsymbol{\epsilon}, \mathcal{I})=f(\mathbf{u}_{t_{0}}\mathbf{x}_{0}+\mathbf{v}_{t_{0}}\boldsymbol{ \epsilon},\mathcal{J}).\] (8)

In language modeling and categorical images, \(f(\cdot)\) is a linear projection function that:

\[\mathbf{u}_{t_{0}}(f(\mathbf{x}_{0},\mathcal{I})-f(\mathbf{x}_{0},\mathcal{J} ))=\mathbf{v}_{t_{0}}(f(\boldsymbol{\epsilon},\mathcal{J})-f(\boldsymbol{ \epsilon},\mathcal{I})).\] (9)

Further simplification of this equation can not be universally applied to all arbitrary forms of \(\mathbf{u}_{t_{0}}\) and \(\mathbf{v}_{t_{0}}\). Therefore, we calculate separately for several commonly occurring special cases.

Diffusion ProcessFor variance preserving, there is \(\mathbf{u}_{t}^{2}+\mathbf{v}_{t}^{2}=1\) and we have:

\[\mathbf{u}_{t_{0}}=1\bigg{/}\sqrt{1+\left(\frac{f(\mathbf{x}_{0},\mathcal{I}) -f(\mathbf{x}_{0},\mathcal{J})}{f(\boldsymbol{\epsilon},\mathcal{J})-f( \boldsymbol{\epsilon},\mathcal{I})}\right)^{2}}\text{ and }\mathbf{v}_{t_{0}}=1 \bigg{/}\sqrt{1+\left(\frac{f(\boldsymbol{\epsilon},\mathcal{J})-f( \boldsymbol{\epsilon},\mathcal{I})}{f(\mathbf{x}_{0},\mathcal{I})-f(\mathbf{x }_{0},\mathcal{J})}\right)^{2}}.\] (10)

For variance exploding, there are \(\mathbf{u}_{t}=1\) and \(\mathbf{v}_{t}=\sigma_{t}\). We can obtain:

\[\mathbf{u}_{t_{0}}=1\text{ and }\mathbf{v}_{t_{0}}=\left(f(\boldsymbol{ \epsilon},\mathcal{J})-f(\boldsymbol{\epsilon},\mathcal{I})\right)/\left(f( \mathbf{x}_{0},\mathcal{I})-f(\mathbf{x}_{0},\mathcal{J})\right).\] (11)

Flow MatchingFor optimal transport, there is \(\mathbf{u}_{t}+\mathbf{v}_{t}=1\) and similarly we get:

\[\mathbf{u}_{t_{0}}=1\bigg{/}\left(1+\frac{f(\mathbf{x}_{0},\mathcal{I})-f( \mathbf{x}_{0},\mathcal{J})}{f(\boldsymbol{\epsilon},\mathcal{J})-f( \boldsymbol{\epsilon},\mathcal{I})}\right)\text{ and }\mathbf{v}_{t_{0}}=1 \bigg{/}\left(1+\frac{f(\boldsymbol{\epsilon},\mathcal{J})-f(\boldsymbol{ \epsilon},\mathcal{I})}{f(\mathbf{x}_{0},\mathcal{I})-f(\mathbf{x}_{0}, \mathcal{J})}\right).\] (12)

As a result, \(t_{0}\) can be directly derived by inverting the coefficient function \(\mathbf{u}_{t}\) or \(\mathbf{v}_{t}\), which depends on the choice of noise scheduling strategies. Since their differences do not affect our results, we omit the detailed calculation (appendix E) and denote this process with a function \(G(\cdot)\):

\[t_{0}=G(\mathbf{x}_{0},\boldsymbol{\epsilon}),\text{ where }\mathbf{u}( \mathbf{x}_{0},G(\mathbf{x}_{0},\boldsymbol{\epsilon}))=\mathbf{u}_{t_{0}} \text{ and }\mathbf{v}(\mathbf{x}_{0},G(\mathbf{x}_{0},\boldsymbol{\epsilon}))= \mathbf{v}_{t_{0}}.\] (13)

It's worth noting that \(t_{0}\) is not a scalar but a vector, where the dimension is the number of elements in \(\mathbf{x}_{0}\). If \(\mathbf{x}_{0}\) is a sequence of \(n\) tokens, \(t_{0}\in[1,T]^{n}\). If \(\mathbf{x}_{0}\) is a RGB image with \(3\)-channel \(\times\)\(h\)-height \(\times\)\(w\)-width of pixels, \(t_{0}\in[1,T]^{3\times h\times w}\). Furthermore, the corresponding noisy sample \(\mathbf{x}_{t_{0}}\) is derived as:

\[\mathbf{x}_{t_{0}}=\mathbf{u}(\mathbf{x}_{0},G(\mathbf{x}_{0},\boldsymbol{ \epsilon}))\mathbf{x}_{0}+\mathbf{v}(\mathbf{x}_{0},G(\mathbf{x}_{0}, \boldsymbol{\epsilon}))\boldsymbol{\epsilon}=\psi_{G(\mathbf{x}_{0},\boldsymbol {\epsilon})}(\boldsymbol{\epsilon}),\] (14)

which is a time-independent function of the Gaussian noise \(\boldsymbol{\epsilon}\). It's worth mentioning that both \(p(t_{0}|\mathbf{x}_{0})\) and \(p(\mathbf{x}_{t_{0}}|\mathbf{x}_{0})\) are intractable, since \(G(\mathbf{x}_{0},\boldsymbol{\epsilon})\) and \(\psi_{G(\mathbf{x}_{0},\boldsymbol{\epsilon})}(\boldsymbol{\epsilon})\) are not invertible to \(\boldsymbol{\epsilon}\). Different \(\boldsymbol{\epsilon}\)s can be mapped to a same \(t_{0}\) or \(\mathbf{x}_{t_{0}}\). Fortunately, there is an one-to-one mapping between \(\boldsymbol{\epsilon}\) and the \([\mathbf{x}_{t_{0}};t_{0}]\) pair. We denote the boundary flow function and the corresponding inversion as

\[\Psi(\boldsymbol{\epsilon})=[\psi_{G(\mathbf{x}_{0},\boldsymbol{\epsilon})}( \boldsymbol{\epsilon});G(\mathbf{x}_{0},\boldsymbol{\epsilon})],\qquad\Psi^{ \text{-}1}([\mathbf{x}_{t_{0}};t_{0}])=(\mathbf{x}_{t_{0}}-\mathbf{u}(\mathbf{x }_{0},t_{0})\mathbf{x}_{0})/\mathbf{v}(\mathbf{x}_{0},t_{0}),\] (15)

and the joint boundary distribution is calculated as

\[p(\mathbf{x}_{t_{0}},t_{0}|\mathbf{x}_{0})=[\Psi]_{*}\pi([\mathbf{x}_{t_{0}};t_{ 0}]).\] (16)

The support set of \(\mathbf{x}_{t_{0}}\) is restricted to the boundary contour, while other regions in the space are assigned a probability of \(0\). To obtain the complete boundary, it is necessary to iterate over all possible choices of \(\mathcal{J}\) and perform pairwise comparisons with \(\mathcal{I}\). The complexity is \(O(n\times K)\), where \(n\) elements in \(\mathbf{x}_{0}\) is independently iterated. In practical implementation, obtaining the tightest boundary only requires one step of parallel calculation and an extra \(\min(\cdot)\) function over all \(t_{0}\) candidates.

Confidence FactorThe discrete area defined by eq. (7) represents an ideal scenario in which the confidence of the boundary is insufficiently reliable for practical application. Due to the intractability of obtaining the probability density function across the entire discrete area and calculating its confidence interval, we employ an empirical strategy. This approach involves utilizing a confidence factor, denoted as \(r\), ranging from \(0\) to \(1\), which is multiplied by \(t_{0}\) to strike a balance between confidence and discreteness. Therefore, \(r=0\) implies the exclusion of discrete priors, causing the discrete area to collapse into a single point, which is the original diffusion process. As the value of \(r\) increases, the modeling of discrete boundaries improves at the expense of reliability. Empirically, when the model is conditioned with good guidance, setting a larger value for \(r\) allows us to obtain better discrete priors. However, in the case of unconditional modeling, maintaining reliability becomes more crucial to prevent oscillations and even collapses during training.

### Rescale the Forward Trajectory

In this section, we introduce how to formulate the forward trajectory conditioned on discrete boundaries and derive the rescaled noisy sampling distribution. We start with the boundary-independent forward process \(p_{t}(\mathbf{x}|\mathbf{x}_{0})\). Let \(\mathbf{x}_{t}\) denote a noisy point at time \(t\) sampled from \(p_{t}(\mathbf{x}|\mathbf{x}_{0})\), there is \(\boldsymbol{\epsilon}_{t}=\left(\mathbf{x}_{t}-\mathbf{u}(\mathbf{x}_{0},t) \mathbf{x}_{0}\right)/\mathbf{v}(\mathbf{x}_{0},t)\) given eq. (5). Equations (13) and (14) provide the corresponding \(\left[\mathbf{x}_{t_{0}};t_{0}\right]\) pair on the same trajectory, which is deterministically calculated with no randomness:

\[\left[\mathbf{x}_{t_{0}};t_{0}\right]=\Psi(\boldsymbol{\epsilon}_{t}),\text{ where }\boldsymbol{\epsilon}_{t}=\left(\mathbf{x}_{t}-\mathbf{u}(\mathbf{x}_{0},t) \mathbf{x}_{0}\right)/\mathbf{v}(\mathbf{x}_{0},t).\] (17)

To model the transition probability \(p_{t}(\mathbf{x}_{t_{0}},t_{0}|\mathbf{x}_{t},\mathbf{x}_{0})\), we utilize the Dirac delta function \(\delta(\mathbf{x})\simeq\lim_{\sigma\to 0}\mathcal{N}(\mathbf{0}, \sigma^{2}\mathbf{I})\), which can be loosely thought of as aggregating all probability densities toward the origin, assigning an infinite density at the origin and zero densities elsewhere. Therefore, we have \(p_{t}(\mathbf{x}_{t_{0}},t_{0}|\mathbf{x}_{t},\mathbf{x}_{0})=\delta\left( \left[\mathbf{x}_{t_{0}};t_{0}\right]-\Psi(\boldsymbol{\epsilon}_{t})\right).\) Then the forward process, conditioned on the discrete boundary, is simply derived via Bayes' rule:

\[p_{t}(\mathbf{x}_{t}|\mathbf{x}_{t_{0}},t_{0},\mathbf{x}_{0})=p_{t}(\mathbf{x }_{t_{0}},t_{0}|\mathbf{x}_{t},\mathbf{x}_{0})\frac{p_{t}(\mathbf{x}_{t}| \mathbf{x}_{0})}{p(\mathbf{x}_{t_{0}},t_{0}|\mathbf{x}_{0})}=\begin{cases}0, \quad\left[\mathbf{x}_{t_{0}};t_{0}\right]\neq\Psi(\boldsymbol{\epsilon}_{t}) \\ +\infty\times\frac{p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})}{p(\mathbf{x}_{t_{0}},t _{0}|\mathbf{x}_{0})},\quad\text{otherwise}\end{cases}.\] (18)

Since \(p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})>0\) and \(p(\mathbf{x}_{t_{0}},t_{0}|\mathbf{x}_{0})>0\), \(p_{t}(\mathbf{x}_{t}|\mathbf{x}_{t_{0}},t_{0},\mathbf{x}_{0})\) is also a delta function that

\[p_{t}(\mathbf{x}_{t}|\mathbf{x}_{t_{0}},t_{0},\mathbf{x}_{0})=\delta\left( \mathbf{x}_{t}-\mathbf{u}(\mathbf{x}_{0},t)\mathbf{x}_{0}-\mathbf{v}(\mathbf{ x}_{0},t)\Psi^{\cdot 1}(\left[\mathbf{x}_{t_{0}};t_{0}\right])\right).\] (19)

Based on the translation property of the Dirac delta function, i.e. \(\int f(x)\delta(x-a)\mathrm{d}x=f(a)\), the original forward process \(p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})=[\psi_{t}\circ\Psi^{\cdot 1}\circ\Psi]_{ \ast}\pi(\mathbf{x}_{t})=[\psi_{t}]_{\ast}\pi(\mathbf{x}_{t})\) naturally ignores the influence of discrete boundaries, even if the boundary information is explicitly added as a condition.

To enable the discrete priors, we propose a simple and intuitive approach: rescale the forward trajectory. As shown in Figure 2B, the original forward process flows from \(\mathbf{x}_{0}\) to a random noise \(\boldsymbol{\epsilon}\), and we reset the starting point to \(\mathbf{x}_{t_{0}}\). Accordingly, the intermediate noisy points \(\mathbf{x}_{t},t\in[1,T]\) will be proportionally mapped on this new path, which is

\[\begin{split}\tilde{\mathbf{x}}_{t}&=\mathbf{x}_{ \tau},\quad\tau=\mathcal{T}(t,t_{0})=r\times t_{0}+t\times(T-r\times t_{0})/T \\ &=\mathbf{u}(\mathbf{x}_{0},\mathcal{T}(t,t_{0}))\mathbf{x}_{0}+ \mathbf{v}(\mathbf{x}_{0},\mathcal{T}(t,t_{0}))\Psi^{\cdot 1}\left(\left[ \mathbf{x}_{t_{0}};t_{0}\right]\right).\end{split}\] (20)

Similar to eq. (19), the rescaled conditional forward process is a Dirac delta function:

\[\tilde{p}_{t}(\tilde{\mathbf{x}}_{t}|\mathbf{x}_{t_{0}},t_{0},\mathbf{x}_{0}) =\delta\left(\tilde{\mathbf{x}}_{t}-\mathbf{u}(\mathbf{x}_{0},\mathcal{T}(t, t_{0}))\mathbf{x}_{0}-\mathbf{v}(\mathbf{x}_{0},\mathcal{T}(t,t_{0}))\Psi^{ \cdot 1}\left(\left[\mathbf{x}_{t_{0}};t_{0}\right]\right)\right).\] (21)

However, \(\tilde{p}_{t}(\tilde{\mathbf{x}}_{t}|\mathbf{x}_{0})\) faces the same problem of irreversibility as in eq. (14) and we derive it as:

\[\begin{split}\tilde{p}_{t}(\tilde{\mathbf{x}}_{t}|\mathbf{x}_{0})& =\int\tilde{p}_{t}(\tilde{\mathbf{x}}_{t},\tau|\mathbf{x}_{0}) \mathrm{d}\tau=\int\tilde{p}_{t}(\tilde{\mathbf{x}}_{t},\tau|\mathbf{x}_{t_ {0}},t_{0},\mathbf{x}_{0})p(\mathbf{x}_{t_{0}},t_{0}|\mathbf{x}_{t_{0}}) \mathrm{d}[\mathbf{x}_{t_{0}};t_{0}]\mathrm{d}\tau\\ &=\int[\psi_{\tau}\circ\Psi^{\cdot 1}\circ\Psi]_{\ast}\pi([ \tilde{\mathbf{x}}_{t};\tau])\mathrm{d}\tau=\int[\psi_{\tau}]_{\ast}\pi([ \tilde{\mathbf{x}}_{t};\tau])\mathrm{d}\tau.\end{split}\] (22)

Obtaining the probability density function requires gathering together the probability densities of the same location \(\tilde{\mathbf{x}}_{t}\) with different \(\tau\), which is intractable. Fortunately, we only need to sample noisy points from this probability distribution \(\tilde{\mathbf{x}}_{t}\sim\tilde{p}_{t}(\tilde{\mathbf{x}}_{t}|\mathbf{x}_{0})\), which is easy to implement:

\[\tilde{\mathbf{x}}_{t}=\mathbf{u}\left(\mathbf{x}_{0},\mathcal{T}(t,G(\mathbf{ x}_{0},\boldsymbol{\epsilon}))\right)\mathbf{x}_{0}+\mathbf{v}(\mathbf{x}_{0}, \mathcal{T}(t,G(\mathbf{x}_{0},\boldsymbol{\epsilon})))\boldsymbol{\epsilon}, \quad\boldsymbol{\epsilon}\sim\pi(\mathbf{x}).\] (23)
Training ObjectiveTheoretically, the diffusion neural networks can be trained as in eq.2, where the rescaled vector field is derived as \(\tilde{u}_{t}=\frac{\mathrm{d}\mathbf{x}_{0}}{\mathrm{d}t}=\frac{\mathrm{d} \mathbf{\tilde{x}}_{t}}{\mathrm{d}\mathbf{\tau}}\frac{\mathrm{d}\mathbf{\tau}}{ \mathrm{d}\mathbf{\tilde{\tau}}}\). However, since a low error estimation on \(\mathbf{x}_{0}\) is of significant importance to our trajectory rescaling method, according to eqs.10 to 13, we convert the objective to an upper bound of the eq.2 (See appendix F for more details) and train a neural network \(\mathbf{x}_{\theta}(\tilde{\mathbf{x}}_{t},t)\) to predict \(\mathbf{x}_{0}\) directly:

\[\mathcal{L}_{\theta}=\mathbb{E}_{\mathbf{x}_{0}\sim q(\mathbf{x}_{0}),t\sim \mathcal{U}_{(1,T)},\tilde{\mathbf{x}}_{t}\sim\tilde{p}_{t}(\mathbf{x}|\mathbf{ x}_{0})}\left[\|\mathbf{x}_{0}-\mathbf{x}_{\theta}(\tilde{\mathbf{x}}_{t},t)\|^{2} \right].\] (24)

The training procedure is demonstrated in algorithm1 and key steps are summarized in the line4.

```
1:repeat
2:\(\mathbf{x}_{0}\sim q(\mathbf{x}_{0})\), \(\boldsymbol{\epsilon}\sim\pi(\mathbf{x})=\mathcal{N}(\mathbf{0},\mathbf{I})\)
3:\(t\sim\text{Uniform}(\{1,\dots,T\})\)
4:\(\tau\coloneqq\mathcal{T}\left(t,G(\mathbf{x}_{0},\boldsymbol{\epsilon})\right)\)// eqs.13 and 20
5:\(\tilde{\mathbf{x}}_{t}\coloneqq\mathbf{u}(\mathbf{x}_{0},\tau)\mathbf{x}_{0}+ \mathbf{v}(\mathbf{x}_{0},\tau)\boldsymbol{\epsilon}\)// eq.23
6: Take gradient descent step on \(\nabla_{\theta}\|\mathbf{x}_{0}-\mathbf{x}_{\theta}(\tilde{\mathbf{x}}_{t},t) \|^{2}\)// eq.24
7:until converged ```

**Algorithm 1** Training

Reverse ProcessA direct approach that follows the flow matching is to solve the ODE of \(\mathrm{d}\psi_{T-t}(\mathbf{x})=\tilde{u}_{T-t}(\mathbf{\upsilon}_{T-t}( \mathbf{\upsilon})\mathbf{\chi}_{0})\mathrm{d}t,\psi_{T}(\mathbf{x})\sim\pi( \mathbf{x})\). This form of transformation is inefficient with \(\mathbf{x}_{0}\)-prediction during inference because we have to solve the equation of \(\tau=\mathcal{T}\left(t,G\left(\mathbf{x}_{\theta},\frac{\tilde{\mathbf{x}}_{t }-\mathbf{u}(\mathbf{x}_{\theta},\tau)\mathbf{x}_{\theta}}{\mathbf{v}(\mathbf{ x}_{\theta},\tau)}\right)\right)\) to get the \(\tau\) with respect to the change of \(\tilde{\mathbf{x}}_{t}\) and \(\mathbf{x}_{\theta}\) in real time. Therefore, we provide a deterministic reverse process as an alternative, which is a special case of DDIM [11] or the ODE with discrete timesteps. Given the time intervals \(\Delta t\in[\Delta t_{1},\dots\Delta t_{s}],\sum\Delta t=T\), we generalize the boundary conditions \([\mathbf{x}_{t_{0}};t_{0}]\) in \(\tilde{p}_{t}(\tilde{\mathbf{x}}_{t}|\mathbf{x}_{t_{0}},t_{0},\mathbf{x}_{0})\) of eq.21 and \(\Psi^{-1}([\mathbf{x}_{t_{0}};t_{0}])\) of eq.15 to any arbitrary condition pairs \([\tilde{\mathbf{x}}_{t};\tau]\) and obtain the reverse process:

\[\tilde{p}([\tilde{\mathbf{x}}_{t-\Delta t};\tau_{\Delta}][\tilde{ \mathbf{x}}_{t};\tau],\hat{\mathbf{x}}_{0})=\] (25) \[\delta\left(\left[\begin{matrix}\tilde{\mathbf{x}}_{t-\Delta t} \\ \tau_{\Delta}\end{matrix}\right]-\left[\begin{matrix}\mathbf{u}(\hat{\mathbf{x} }_{0},\tau_{\Delta})\hat{\mathbf{x}}_{0}+\mathbf{v}(\hat{\mathbf{x}}_{0},\tau _{\Delta})\hat{\boldsymbol{\epsilon}}\\ \mathcal{T}\left(t-\Delta t,G(\hat{\mathbf{x}}_{0},\hat{\boldsymbol{\epsilon}}) \right)\end{matrix}\right]\right),\]

where \(\hat{\mathbf{x}}_{0}=\mathbf{x}_{\theta}(\tilde{\mathbf{x}}_{t},t)\) and \(\tau_{\Delta}\) is the previous timestep of \(\tau\) on the same rescaled trajectory.

Sampling from the reverse process is illustrated in algorithm2. Similar to the sampling process of DDIM [11], it starts from the Gaussian noise, iteratively predicts the pseudo target \(\hat{\mathbf{x}}_{0}\), and updates the reverse trajectory. However, since the \(\tau\) and \(\hat{\boldsymbol{\epsilon}}\) are mutually conditioned, we have to keep track of the \(t\), \(\tau\), \(\tilde{\mathbf{x}}_{t}\), and \(\hat{\boldsymbol{\epsilon}}\) during each iteration and split the update of \(\hat{\boldsymbol{\epsilon}}\) into an asynchronous step (line8). Because reverse trajectory keeps changing due to different pseudo targets \(\tilde{\mathbf{x}}_{0}\) predicted by learned neural networks, which brings severe instability, sometimes simply fixing the initial path (removing the line8) exhibits better performance in experiments.

```
1:repeat
2:\(\mathbf{x}_{0}\sim q(\mathbf{x}_{0})\), \(\boldsymbol{\epsilon}\sim\pi(\mathbf{x})=\mathcal{N}(\mathbf{0},\mathbf{I})\)
3:\(t\sim\text{Uniform}(\{1,\dots,T\})\)
4:\(\tau\coloneqq\mathcal{T}\left(t,G(\mathbf{x}_{0},\boldsymbol{\epsilon})\right)\)// eqs.13 and 20
5:\(\tilde{\mathbf{x}}_{t}\coloneqq\mathbf{u}(\mathbf{x}_{0},\tau)\mathbf{x}_{0}+ \mathbf{v}(\mathbf{x}_{0},\tau)\boldsymbol{\epsilon}\)// eq.23
6: Take gradient descent step on \(\nabla_{\theta}\|\mathbf{x}_{0}-\mathbf{x}_{\theta}(\tilde{\mathbf{x}}_{t},t) \|^{2}\)// eq.24
7:until converged ```

**Algorithm 2** Sampling

## 4 Language Modeling

Recent diffusion language models [15, 16] inherit the embedding-rounding framework that a sentence with \(n\) discrete tokens \(W=[w_{1},\dots,w_{n}]\) is embedded to a continuous space via a trainable embedding layer \(\texttt{Emb}(W)=[\texttt{Emb}(w_{1}),\dots,\texttt{Emb}(w_{n})]\). The vocabulary set is \(K\) that \(\forall w_{n}\in K\). Besides, the token embeddings are used as the target points \(\mathbf{x}_{0}=[\mathbf{x}_{0}^{1},\dots,\mathbf{x}_{0}^{n}]\), \(\mathbf{x}_{0}^{n}=\texttt{Emb}(w_{n})\), for continuous diffusion trajectories. Hence, generating tokens from embeddings is:

\[p(W|\mathbf{x}_{0})=\sum\nolimits_{i=1}^{n}p(w_{i}|\mathbf{x}_{0}^{i})=\sum \nolimits_{i=1}^{n}\frac{\exp(f(\mathbf{x}_{0}^{i},w_{i}))}{\sum_{j\in K}\exp(f( \mathbf{x}_{0}^{i},j))},\] (26)

where \(f(\mathbf{x},j)=\texttt{Emb}(j)\cdot\mathbf{x}\) is the dot production distance. It's also the function assessing the likelihood of point \(\mathbf{x}\) inside the discrete area of \(j\). The coefficient functions follow the DDPM [16], which are \(\mathbf{u}(\mathbf{x}_{0},t)=\sqrt{\bar{\alpha}_{t}}\) and \(\mathbf{v}(\mathbf{x}_{0},t)=\sqrt{1-\bar{\alpha}_{t}}\). Besides, the objectives are

\[\mathcal{L}_{\theta}=\mathbb{E}_{W,t,\tilde{\mathbf{x}}_{t}}\left[\sum\nolimits_{ i=1}^{n}\lVert\texttt{Emb}(w_{i})-\mathbf{x}_{\theta}(\tilde{\mathbf{x}}_{t}^{i},t)\|^{2}/n\right]\] (27)

[MISSING_PAGE_FAIL:7]

length beam \(\times\)\(3\) sentence beams) of our model. The reranked performance can even outperform transformers on Iwslt14 de-en and Wnt16 en-ro.

AblationOur approach is a general framework applicable to almost all continuous diffusion models, providing them with discrete boundaries as priors. We choose Difformer [Gao et al., 2022] as the base model and follow the configurations. As proved in eq. (19), the original forward process will ignore the discrete priors although explicitly demonstrated. We conduct ablation experiments on the rescaling module. As illustrated in Table 2, our approach rescales the trajectory of both forward and reverse processes on Difformer. Only rescaling the forward trajectory is also effective but sub-optimal due to the inconsistent distribution during inference. Due to computational cost and fair comparison, our method leaves room for improvement. For example, replacing the forward trajectory with optimal transport in Flow Matching, \(\mathbf{u}(\mathbf{x}_{0},t)=1-t/T\) and \(\mathbf{v}(\mathbf{x}_{0},t)=t/T\), achieves better performance on Wnt16.

AnalysisOur training objective, eq. (24), is an upper bound of the eq. (2). We demonstrate the influence of this approximation in Table 3 on Iwslt14 de-en to reveal the thought of our formula. On the one hand, \(\mathcal{L}_{\mathbf{x}_{0}}\) brings theoretical errors at a constant scale. On the other hand, \(\mathcal{L}_{\mathbf{x}_{0}}\) mitigates some experimental errors from the neural networks. The first row \(\mathcal{L}_{\mathbf{x}_{0}}\) is the objective we used in eq. (24) and the second row \(\mathcal{L}_{\tilde{u}_{t}}=\mathbb{E}_{\{t,\mathbf{x}_{0},\tilde{\mathbf{x }}_{t}\}}\left[\|\tilde{u}_{t}(\tilde{\mathbf{x}}_{t}|\mathbf{x}_{\theta}( \tilde{\mathbf{x}}_{t},t))-\frac{\mathrm{d}\tilde{\mathbf{x}}_{t}}{\mathrm{d }t}\|^{2}\right]\) is directly derived from the eq. (2). The first two columns represent the error expectations of \(\mathbf{x}_{0}\) and \(\tilde{u}_{t}\) on the test set. It is easy to observe that, with the dynamic coefficient \(\frac{\mathrm{d}\tau}{\mathrm{d}\tilde{t}}=\frac{T-r\times G(\mathbf{x}_{0}, \mathbf{x}_{0})}{T}\) (appendix F), the value of \(\mathbf{x}_{0}\)'s error (\(8.44\)) is much larger than the \(\tilde{u}_{t}\)'s error (\(1.56\)). Therefore, \(\mathcal{L}_{\mathbf{x}_{0}}\) is beneficial for reducing the impact of the prediction error from the neural network. The third column in Table 3 illustrates the one-step accuracy of predicting \(\mathbf{x}_{0}\) and the fourth column is the Bleu score on the test set. Experimental results show that optimizing the upper bound has a negligible impact on the final performance (only a \(0.2\%\) drop of the Bleu score), while can improve the efficiency of the loss calculation during the training phase.

## 5 Discrete Image Generation

Image pixels are usually treated as real numbers in continuous space since adjacent pixel values exhibit linear continuity.They are essentially discrete and quantized data with a finite state space, such as \(256\) states in RGB format. We utilize two discrete image representations. One is binary coding provided by Bit Diffusion [Chen et al., 2023b] that converts a sub-pixel with 256 integers to a \(8\)-bit binary code. It is more efficient as it stores ordinal relationships, but the representation space it constructs will be sparse. Another is pixel embedding, which is a more discrete form of representation because the relationships between pixels are thoroughly broken down and reconstructed by learning the embedding representation. Each pixel is regarded as a one-hot vector and transformed with an embedding layer Emb as used in language. Furthermore, we design an intermediate state to demonstrate the correlation between discreteness and modeling difficulty, which is initializing a fixed embedding with binary coding. The optimization target for binary coding is the MSE loss, and pixel embeddings take the same objective as in language.

Experimental SetupWe use Cifar-10 [Krizhevsky et al., 2009] for discrete image generation. The evaluation metric is Fid [Heusel et al., 2017], which compares 50K generated samples with the training set. Our image generation model is constructed on Bit Diffusion [Chen et al., 2023b], where the architecture is U-Net [Ronneberger et al., 2015] with \(3\) stages, \(256\) channels and \(3\) residual blocks

\begin{table}
\begin{tabular}{l|c c} \hline
**Models** & **Iwslt14** & **Wmt16** \\ \hline \hline Base (Difformer) & 31.58 & 30.08 \\ + forward only & 33.02 & 32.86 \\ + forward \& reverse & **33.42** & 33.15 \\ \hline \hline Optimal Transport & 32.77 & **33.65** \\ \hline \end{tabular}
\end{table}
Table 2: Ablation studies.

\begin{table}
\begin{tabular}{l|c c c c} \hline
**Objectives** & \(\mathbb{E}_{\tilde{\mathbf{x}}_{t}}\|\mathbf{x}_{0}-\tilde{\mathbf{x}}_{0}\|^{2}\) & \(\mathbb{E}_{\tilde{\mathbf{x}}_{t}}\|\tilde{u}_{t}(\tilde{\mathbf{x}}_{t}| \mathbf{x}_{0})-\tilde{u}_{t}(\tilde{\mathbf{x}}_{t}|\tilde{\mathbf{x}}_{0})\|^{2 }\) & \(\mathbb{E}_{\tilde{\mathbf{x}}_{t}}\left[p(\tilde{\mathbf{x}}_{0}\in C_{\mathbf{x }_{0}})\right]\) & Bleu \\ \hline \hline \(\mathcal{L}_{\mathbf{x}_{0}}\) (eq. 24) & 8.44 & 1.56 & 51.81\% & 33.42 \\ \hline \hline \(\mathcal{L}_{\tilde{u}_{t}}\) & 8.41 & 1.55 & 52.34\% & 33.49 \\ \hline \end{tabular}
\end{table}
Table 3: Analysis on the training objectives.

[MISSING_PAGE_FAIL:9]

cost increases drastically as the size of sentence length or the image resolution increases. Diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020; Dhariwal and Nichol, 2021; Saharia et al., 2022) can generate data in parallel, but are tailored for continuous problems. To generalize diffusion models for discrete data, the most straightforward methods define discrete processes in discrete spaces (Sohl-Dickstein et al., 2015; Hoogeboom et al., 2021; Austin et al., 2021; Campbell et al., 2022; Zhang et al., 2023; Sun et al., 2023; Lou et al., 2023), which will be bothered by large number of discrete status. Besides, a simplified version of discrete diffusion processes is recently used in language modeling (He et al., 2023; Chen et al., 2023). Approaches in another line argue to located discrete data in continuous spaces, which is more flexible and efficient, with the mapping functions including binary bits (Chen et al., 2023) and embeddings (Li et al., 2022; Gong et al., 2023, 2023; Yuan et al., 2022; Gulrajani and Hashimoto, 2023; Han et al., 2023). Other generative models adapted for discrete modeling includes Variational Autoencoders (Kingma and Welling, 2014), Generative Adversarial Networks (Hjelm et al., 2018; Fedus et al., 2018), and Normalizing Flows (Lindt and Hoogeboom, 2021; Hoogeboom et al., 2021; Tan et al., 2022).

Diffusion Models with Deterministic TrajectoryDeterministic diffusion process is usually used in the inference stage to speed up sampling, where DDIM (Song et al., 2021) derives a serial of non-Markovian diffusion processes and the deterministic one is a special case from this implicit perspective. Additionally, deterministic diffusion processes can be converted to ordinary differential equations (Song et al., 2021), which is utilized by recent sampling acceleration approaches such as DEIS (Zhang and Chen, 2023) and DPM-Solvers (Lu et al., 2022, 2022; Zheng et al., 2023). Our approach requires a deterministic forward trajectory to eliminate the randomness between the boundary point and sampled point. Flow matching (Liu, 2022; Lipman et al., 2023; Albergo and Vanden-Eijnden, 2023; Liu et al., 2023) is a collection of generative models that employ ordinary differential equations to facilitate both forward and reverse processes. They can be regarded as generally equivalent to Diffusion models. Therefore, we extend the framework of flow matching for our method.

## 7 Conclusion

We studied the gap between discrete modeling and continuous spaces, focusing on the inconsistency between probability density contours learned by continuous diffusion models and discrete boundaries. We have proposed a novel and general approach to address this issue by enabling continuous diffusion models to be conditioned on discrete priors, which is achieved via discrete boundary estimation and trajectory rescaling. An important limitation is that our method is designed for continuous diffusion models, where discrete diffusion models constructed specially on the discrete state space would not encounter the problem. However, discrete diffusion models also possess their own shortcomings, and the practical applications of continuous diffusion models are more extensive. We believe that our method has the potential to advance the development of unified and general diffusion models. By bridging the gap between discrete and continuous modeling, we hope to inspire new possibilities for modeling complex systems and phenomena.

## Acknowledgements

Bing Qin is the corresponding author of this work, We thank the anonymous reviewers for their insightful comments. This work was supported by the National Natural Science Foundation of China (NSFC) (U22B2059, grant 62276078), the Key R&D Program of Heilongjiang via grant 2022ZX01A32, the International Cooperation Project of PCL, PCL2022D01 and the Fundamental Research Funds for the Central Universities (Grant No.HIT.OCEF.2023018).

## References

* Achiam et al. (2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. _arXiv preprint arXiv:2303.08774_, 2023.
* Albergo and Vanden-Eijnden (2023) Michael Samuel Albergo and Eric Vanden-Eijnden. Building normalizing flows with stochastic interpolants. In _The Eleventh International Conference on Learning Representations_, 2023. URL https://openreview.net/forum?id=li7qeBbCR1t.
* Albergo et al. (2021)Jacob Austin, Daniel D. Johnson, Jonathan Ho, Daniel Tarlow, and Rianne van den Berg. Structured denoising diffusion models in discrete state-spaces. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, _Advances in Neural Information Processing Systems_, 2021.
* Brown et al. (2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, _Advances in Neural Information Processing Systems_, volume 33, pages 1877-1901. Curran Associates, Inc., 2020.
* Campbell et al. (2022) Andrew Campbell, Joe Benton, Valentin De Bortoli, Tom Rainforth, George Deligiannidis, and Arnaud Doucet. A continuous time framework for discrete denoising models. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, _Advances in Neural Information Processing Systems_, 2022.
* Cettolo et al. (2012) Mauro Cettolo, Christian Girardi, and Marcello Federico. WIT3: Web inventory of transcribed and translated talks. In Mauro Cettolo, Marcello Federico, Lucia Specia, and Andy Way, editors, _Proceedings of the 16th Annual Conference of the European Association for Machine Translation_, pages 261-268, Trento, Italy, May 28-30 2012. European Association for Machine Translation.
* Chen et al. (2023a) Jiao Chen, Aston Zhang, Mu Li, Alex Smola, and Diyi Yang. A cheaper and better diffusion language model with soft-masked noise. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, pages 4765-4775, Singapore, December 2023a. Association for Computational Linguistics.
* Chen et al. (2023b) Ting Chen, Ruixiang Zhang, and Geoffrey Hinton. Analog bits: Generating discrete data using diffusion models with self-conditioning. In _The Eleventh International Conference on Learning Representations_, 2023b.
* Dhariwal and Nichol (2021) Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, _Advances in Neural Information Processing Systems_, volume 34, pages 8780-8794. Curran Associates, Inc., 2021.
* Dosovitskiy et al. (2021) Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In _International Conference on Learning Representations_, 2021. URL https://openreview.net/forum?id=YicbFdNTTy.
* Esser et al. (2021) Patrick Esser, Robin Rombach, and Bjorn Ommer. Taming transformers for high-resolution image synthesis. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 12873-12883, 2021.
* Fedus et al. (2018) William Fedus, Ian Goodfellow, and Andrew M. Dai. Maskgan: Better text generation via filling in the _. In _International Conference on Learning Representations_, 2018.
* Gao et al. (2022) Zhujin Gao, Junliang Guo, Xu Tan, Yongxin Zhu, Fang Zhang, Jiang Bian, and Linli Xu. Difformer: Empowering diffusion model on embedding space for text generation. _arXiv preprint arXiv:2212.09412_, 2022.
* Ghazvininejad et al. (2019) Marjan Ghazvininejad, Omer Levy, Yinhan Liu, and Luke Zettlemoyer. Mask-predict: Parallel decoding of conditional masked language models. In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan, editors, _Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)_, pages 6112-6121, Hong Kong, China, November 2019. Association for Computational Linguistics.
* Ghazvininejad et al. (2019)Shansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu, and Lingpeng Kong. DiffuSeq-v2: Bridging discrete and continuous text spaces for accelerated Seq2Seq diffusion models. In Houda Bouamor, Juan Pino, and Kalika Bali, editors, _Findings of the Association for Computational Linguistics: EMNLP 2023_, pages 9868-9875, Singapore, December 2023a. Association for Computational Linguistics.
* Gong et al. (2023b) Shansan Gong, Mukai Li, Jiangtao Feng, Zhiyong Wu, and Lingpeng Kong. Diffuseq: Sequence to sequence text generation with diffusion models. In _The Eleventh International Conference on Learning Representations_, 2023b.
* Gu et al. (2018) Jiatao Gu, James Bradbury, Caiming Xiong, Victor O.K. Li, and Richard Socher. Non-autoregressive neural machine translation. In _International Conference on Learning Representations_, 2018.
* Gu et al. (2019) Jiatao Gu, Changhan Wang, and Junbo Zhao. Levenshtein transformer. In H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlche-Buc, E. Fox, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 32. Curran Associates, Inc., 2019.
* Gulrajani and Hashimoto (2023) Ishaan Gulrajani and Tatsunori Hashimoto. Likelihood-based diffusion language models. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.
* Han et al. (2023) Xiaochuang Han, Sachin Kumar, and Yulia Tsvetkov. SSD-LM: Semi-autoregressive simplex-based diffusion language model for text generation and modular control. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 11575-11596, Toronto, Canada, July 2023. Association for Computational Linguistics.
* He et al. (2023) Zhengfu He, Tianxiang Sun, Qiong Tang, Kuanning Wang, Xuanjing Huang, and Xipeng Qiu. DiffusionBERT: Improving generative masked language models with diffusion models. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, _Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 4521-4534, Toronto, Canada, July 2023. Association for Computational Linguistics.
* Heusel et al. (2017) Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. _Advances in neural information processing systems_, 30, 2017.
* Heylm et al. (2018) R Devon Hjelm, Athul Paul Jacob, Adam Trischler, Gerry Che, Kyunghyun Cho, and Yoshua Bengio. Boundary seeking gans. In _International Conference on Learning Representations_, 2018.
* Ho et al. (2020) Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, _Advances in Neural Information Processing Systems_, volume 33, pages 6840-6851. Curran Associates, Inc., 2020.
* Hoogeboom et al. (2021a) Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forre, and Max Welling. Argmax flows and multinomial diffusion: Learning categorical distributions. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, _Advances in Neural Information Processing Systems_, volume 34, pages 12454-12465. Curran Associates, Inc., 2021a.
* Hoogeboom et al. (2021b) Emiel Hoogeboom, Didrik Nielsen, Priyank Jaini, Patrick Forre, and Max Welling. Argmax flows and multinomial diffusion: Learning categorical distributions. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, _Advances in Neural Information Processing Systems_, volume 34, pages 12454-12465. Curran Associates, Inc., 2021b.
* Kim and Rush (2016) Yoon Kim and Alexander M. Rush. Sequence-level knowledge distillation. In Jian Su, Kevin Duh, and Xavier Carreras, editors, _Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing_, pages 1317-1327, Austin, Texas, November 2016. Association for Computational Linguistics.
* Kingma and Welling (2014) Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. In _International Conference on Learning Representations_, 2014.
* Kong et al. (2021) Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro. Diffwave: A versatile diffusion model for audio synthesis. In _International Conference on Learning Representations_, 2021.
* Krizhevsky et al. (2014)Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
* Li et al. (2022) Xiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy Liang, and Tatsunori Hashimoto. Diffusion-LM improves controllable text generation. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, _Advances in Neural Information Processing Systems_, 2022.
* Lin (2004) Chin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In _Text Summarization Branches Out_, pages 74-81, Barcelona, Spain, July 2004. Association for Computational Linguistics.
* Lindt and Hoogeboom (2021) Alexandra Lindt and Emiel Hoogeboom. Discrete denoising flows. In _ICML Workshop on Invertible Neural Networks, Normalizing Flows, and Explicit Likelihood Models_, 2021.
* Lipman et al. (2023) Yaron Lipman, Ricky T. Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le. Flow matching for generative modeling. In _The Eleventh International Conference on Learning Representations_, 2023.
* Liu (2022) Qiang Liu. Rectified flow: A marginal preserving approach to optimal transport. _arXiv preprint arXiv:2209.14577_, 2022.
* Liu et al. (2023) Xingchao Liu, Chengyue Gong, and Qiang Liu. Flow straight and fast: Learning to generate and transfer data with rectified flow. In _International conference on learning representations (ICLR)_, 2023.
* Lou et al. (2023) Aaron Lou, Chenlin Meng, and Stefano Ermon. Discrete diffusion language modeling by estimating the ratios of the data distribution. _arXiv preprint arXiv:2310.16834_, 2023.
* Lu et al. (2022a) Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models. _arXiv preprint arXiv:2211.01095_, 2022a.
* Lu et al. (2022b) Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. DPM-solver: A fast ODE solver for diffusion probabilistic model sampling in around 10 steps. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, _Advances in Neural Information Processing Systems_, 2022b.
* Madani et al. (2020) Ali Madani, Bryan McCann, Nikhil Naik, Nitish Shirish Keskar, Namrata Anand, Raphael R Eguchi, Po-Ssu Huang, and Richard Socher. Progen: Language modeling for protein generation. _arXiv preprint arXiv:2004.03497_, 2020.
* Madani et al. (2023) Ali Madani, Ben Krause, Eric R Greene, Subu Subramanian, Benjamin P Mohr, James M Holton, Jose Luis Olmos, Caiming Xiong, Zachary Z Sun, Richard Socher, et al. Large language models generate functional protein sequences across diverse families. _Nature Biotechnology_, 41(8):1099-1106, 2023.
* Ott et al. (2019) Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. fairseq: A fast, extensible toolkit for sequence modeling. In _Proceedings of NAACL-HLT 2019: Demonstrations_, 2019.
* Papineni et al. (2002) Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. In Pierre Isabelle, Eugene Charniak, and Dekang Lin, editors, _Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics_, pages 311-318, Philadelphia, Pennsylvania, USA, July 2002. Association for Computational Linguistics.
* Parmar et al. (2018) Niki J. Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam Shazeer, Alexander Ku, and Dustin Tran. Image transformer. In _International Conference on Machine Learning (ICML)_, 2018. URL http://proceedings.mlr.press/v80/parmar18a.html.
* Rombach et al. (2022) Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolution image synthesis with latent diffusion models. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 10684-10695, June 2022.
* Rombach et al. (2020)Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In _Medical Image Computing and Computer-Assisted Intervention-MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18_, pages 234-241. Springer, 2015.
* Rush et al. (2015) Alexander M. Rush, Sumit Chopra, and Jason Weston. A neural attention model for abstractive sentence summarization. In Lluis Marquez, Chris Callison-Burch, and Jian Su, editors, _Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing_, pages 379-389, Lisbon, Portugal, September 2015. Association for Computational Linguistics.
* Saharia et al. (2022) Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, Jonathan Ho, David J Fleet, and Mohammad Norouzi. Photorealistic text-to-image diffusion models with deep language understanding. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, _Advances in Neural Information Processing Systems_, volume 35, pages 36479-36494. Curran Associates, Inc., 2022.
* Sennrich et al. (2016) Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words with subword units. In Katrin Erk and Noah A. Smith, editors, _Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 1715-1725, Berlin, Germany, August 2016. Association for Computational Linguistics.
* Sohl-Dickstein et al. (2015) Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In Francis Bach and David Blei, editors, _Proceedings of the 32nd International Conference on Machine Learning_, volume 37 of _Proceedings of Machine Learning Research_, pages 2256-2265, Lille, France, 07-09 Jul 2015. PMLR.
* Song et al. (2021a) Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In _International Conference on Learning Representations_, 2021a.
* Song et al. (2021b) Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In _International Conference on Learning Representations_, 2021b.
* Sun et al. (2023) Haoran Sun, Lijun Yu, Bo Dai, Dale Schuurmans, and Hanjun Dai. Score-based continuous-time discrete diffusion models. In _The Eleventh International Conference on Learning Representations_, 2023.
* Sutskever et al. (2014) Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks. _Advances in neural information processing systems_, 27, 2014.
* Tan et al. (2022) Shawn Tan, Chin-Wei Huang, Alessandro Sordoni, and Aaron Courville. Learning to dequantise with truncated flows. In _International Conference on Learning Representations_, 2022.
* Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, L ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 30. Curran Associates, Inc., 2017.
* Ye et al. (2023) Jiasheng Ye, Zaixiang Zheng, Yu Bao, Lihua Qian, and Mingxuan Wang. Dinoiser: Diffused conditional sequence learning by manipulating noises. _arXiv preprint arXiv:2302.10025_, 2023.
* Yuan et al. (2022) Hongyi Yuan, Zheng Yuan, Chuanqi Tan, Fei Huang, and Songfang Huang. Seqdiffuseq: Text diffusion with encoder-decoder transformers. _ArXiv_, abs/2212.10325, 2022.
* Zhang et al. (2023) Pengze Zhang, Hubery Yin, Chen Li, and Xiaohua Xie. Formulating discrete probability flow through optimal transport. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.
* Zhang and Chen (2023) Qinsheng Zhang and Yongxin Chen. Fast sampling of diffusion models with exponential integrator. In _The Eleventh International Conference on Learning Representations_, 2023.
* Zheng et al. (2023) Kaiwen Zheng, Cheng Lu, Jianfei Chen, and Jun Zhu. Dpm-solver-v3: Improved diffusion ode solver with empirical model statistics. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.

Stopping Time for Forward Process

The forward diffusion process \(\mathbf{X}=\left\{\mathbf{x}_{n},n\geq 0\right\}\) is a markovian stochastic process with a transition probability \(p(\mathbf{x}_{i}|\mathbf{x}_{i-1})=\mathcal{N}\left(\mathbf{x}_{i};\sqrt{ \alpha_{i}}\mathbf{x}_{i-1},(1-\alpha_{i})\,\mathbf{I}\right)\). And a stopping time \(t_{0}\) with respect to \(\mathbf{X}\) is a random time such that for each \(n\geq 0\), the event \(\{t_{0}=n\}\) is completely determined by the total information known up to time \(n\), \(\{\mathbf{x}_{0},\ldots,\mathbf{x}_{n}\}\). Suppose the random variables \(\{\mathbf{x}_{n}\}\) are in a one-dimensional space and the forward process starts with \(\mathbf{x}_{0}=0\). Besides, let \(A,\mathbf{x}_{0}\in A\) be the discrete area belonging to \(\mathbf{x}_{0}\) that for each points in area \(A\) will be regarded as \(\mathbf{x}_{0}\) during data generation. Our expected stopping time is defined as:

\[t_{0}=\min\{n\geq 0,\mathbf{x}_{n}\notin A\},\]

which represents the first time \(\mathbf{x}_{n}\) leaves area \(A\). We can write the probability of stopping time as:

\[P(t_{0}=0)=P(\mathbf{x}_{0}\notin A)=0\] \[P(t_{0}=1)=P(\mathbf{x}_{0}\in A,\mathbf{x}_{1}\notin A)\] \[\quad=\int_{\mathbf{x}_{1}\notin A}\mathcal{N}\left(\mathbf{x}_{1 };\sqrt{\alpha_{1}}\mathbf{x}_{0},(1-\alpha_{1})\,\mathbf{I}\right)\mathrm{d} \mathbf{x}_{1}\] \[P(t_{0}=2)=P(\mathbf{x}_{0}\in A,\mathbf{x}_{1}\in A,\mathbf{x}_ {2}\notin A)\] \[\quad=P(\mathbf{x}_{0}\in A,\mathbf{x}_{1}\in A)\times P( \mathbf{x}_{2}\notin A|\mathbf{x}_{1}\in A)\] \[\quad=\int_{\mathbf{x}_{n}\notin A}\Big{[}\int_{\mathbf{x}_{1} \in A}\mathcal{N}\left(\mathbf{x}_{1};\sqrt{\alpha_{1}}\mathbf{x}_{0},(1- \alpha_{1})\,\mathbf{I}\right)\times\] \[\quad\quad\quad\mathcal{N}\left(\mathbf{x}_{2};\sqrt{\alpha_{2}} \mathbf{x}_{1},(1-\alpha_{2})\,\mathbf{I}\right)\mathrm{d}\mathbf{x}_{1} \Big{]}\mathrm{d}\mathbf{x}_{2}\] \[\quad\quad\quad\quad\quad\cdots\cdots\] \[P(t_{0}=n)=P(\mathbf{x}_{0}\in A,\ldots,\mathbf{x}_{n-1}\in A, \mathbf{x}_{n}\notin A)\] \[=\int_{\mathbf{x}_{n}\notin A}\int_{\mathbf{x}_{\leq n}\in A} \prod_{i=1}^{n-1}\mathcal{N}\left(\mathbf{x}_{i};\sqrt{\alpha_{i}}\mathbf{x}_{ i-1},(1-\alpha_{i})\,\mathbf{I}\right)\mathrm{d}\mathbf{x}_{1:n}.\]

Since the diffusion process is established in continuous space, calculating the probability of the stopping time requires integrating over each intermediate state \(\mathbf{x}_{1:n-1}\), rather than a simple state transfer as in the discrete space. Hence, directly obtain the stopping time is intractable. Additionally, even if we are able to get probability of the stopping time, we can only get a distribution over the time dimension, without knowing the exact time of \(\mathbf{x}_{n}\) leaving area \(A\). Therefore, we need to eliminate randomness from the state transition \(\mathbf{x}_{i-1}\rightarrow\mathbf{x}_{i}\) and find a deterministic forward trajectory to estimate the stopping time.

## Appendix B Properties of Dirac Delta Function

There are several useful properties of Dirac delta function:

* **Symmetry Property:**\(\delta(-x)=\delta(x)\)
* **Scaling Property:**\(\delta(ax)=\frac{\delta(x)}{|a|}\)
* **Translation Property:**\(\int f(x)\delta(x-a)\mathrm{d}x=f(a)\)

## Appendix C Bridging Flow Matching and DDPM

In this work, we utilizes the framework of Flow Matching to model the diffusion processes, where the forward process is defined by flow functions in eq. (5). Although having different mathematical forms, it is essentially equivalent to traditional diffusion processes. Here, we provide an alternative form from the perspective of state transfer \(p_{t}(\mathbf{x}_{t}|\mathbf{x}_{t-1})\).

### Deterministic Forward Process

Equation (5) gives the definition \(p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})=[\psi_{t}]_{*}\pi(\mathbf{x})\), where \(\psi_{t}(\mathbf{x})=\mathbf{u}_{t}\mathbf{x}_{0}+\mathbf{v}_{t}\mathbf{x}\). Here we provide the equivalent derivation of \(p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})\) from the perspective of diffusion processes:

\[\begin{split} p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})& =\int p_{t}(\mathbf{x}_{1:t}|\mathbf{x}_{0})\mathrm{d}\mathbf{x}_{1:t-1}\\ &=\int p(\mathbf{x}_{1}|\mathbf{x}_{0})\prod_{s=2}^{t}p_{s}( \mathbf{x}_{s}|\mathbf{x}_{s-1},\mathbf{x}_{0})\mathrm{d}\mathbf{x}_{1:t-1}, \end{split}\] (29)

where \(p(\mathbf{x}_{1}|\mathbf{x}_{0})=\mathcal{N}(\mathbf{u}_{1}\mathbf{x}_{0}, \mathbf{v}_{1}^{2}\mathbf{I})\) is the first step of the forward process at which the global noise is introduced into the forward trajectory. The state transfer probability of forward process \(p_{s}(\mathbf{x}_{s}|\mathbf{x}_{s-1},\mathbf{x}_{0})=\delta(\mathbf{x}_{s}- \mathbf{u}_{s}\mathbf{x}_{0}-\mathbf{v}_{s}\psi_{s-1}^{-1}(\mathbf{x}_{s-1}))\) is a Dirac delta function. Therefore,

\[\begin{split} p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})& =\int\prod_{s=3}^{t}p_{s}(\mathbf{x}_{s}|\mathbf{x}_{s-1},\mathbf{x}_{0}) \mathrm{d}\mathbf{x}_{2:t-1}\\ &\times\underbrace{\int p_{2}(\mathbf{x}_{2}|\mathbf{x}_{1}, \mathbf{x}_{0})p(\mathbf{x}_{1}|\mathbf{x}_{0})\mathrm{d}\mathbf{x}_{1}}_{Q_{ 1}},\end{split}\] (30)

where we denote the integral of \(\mathbf{x}_{1}\) as \(Q_{1}\). Based on

\[\begin{split} Q_{0}&=q(\mathbf{x}_{1}|\mathbf{x}_{0} )=\mathcal{N}(\mathbf{u}_{1}\mathbf{x}_{0},\mathbf{v}_{1}^{2}\mathbf{I})\\ q_{2}(\mathbf{x}_{2}|\mathbf{x}_{1},\mathbf{x}_{0})& =\delta\left(\mathbf{x}_{2}-\mathbf{u}_{2}\mathbf{x}_{0}-\mathbf{v}_{2}\psi_ {1}^{-1}(\mathbf{x}_{1})\right)\\ &=\delta\Bigg{[}\mathbf{x}_{2}-\frac{\mathbf{v}_{2}}{\mathbf{v}_ {1}}\mathbf{x}_{1}-\left(\mathbf{u}_{2}-\frac{\mathbf{v}_{2}\mathbf{u}_{1}}{ \mathbf{v}_{1}}\right)\mathbf{x}_{0}\Bigg{]}\\ &=\delta\Bigg{[}\mathbf{x}_{1}-\frac{\mathbf{v}_{1}}{\mathbf{v}_ {2}}\mathbf{x}_{2}-\left(\mathbf{u}_{1}-\frac{\mathbf{v}_{1}\mathbf{u}_{2}}{ \mathbf{v}_{2}}\right)\mathbf{x}_{0}\Bigg{]}\end{split}\] (31)

and the **Translation Property** of the Dirac delta function, we can calculate \(Q_{1}\) as:

\[\begin{split} Q_{1}&=\int\underbrace{p_{2}(\mathbf{ x}_{2}|\mathbf{x}_{1},\mathbf{x}_{0})}_{\delta(x-a)}\underbrace{p(\mathbf{x}_{1}| \mathbf{x}_{0})}_{f(\mathbf{x})}\mathrm{d}\mathbf{x}_{1},\\ &\text{where }\begin{cases}x:\mathbf{x}_{1}\\ a:\frac{\mathbf{v}_{1}}{\mathbf{v}_{2}}\mathbf{x}_{2}+\left(\mathbf{u}_{1}- \frac{\mathbf{v}_{1}\mathbf{u}_{2}}{\mathbf{v}_{2}}\right)\mathbf{x}_{0}\\ \end{cases}\\ \implies Q_{1}&=\mathcal{N}(\mathbf{u}_{2}\mathbf{x}_{0}, \mathbf{v}_{2}^{2}\mathbf{I}.)\end{split}\] (32)

Then we can continue the deviation of \(p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})\) as:

\[\begin{split} p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})& =\int Q_{0}\prod_{s=2}^{t}p_{s}(\mathbf{x}_{s}|\mathbf{x}_{s-1}, \mathbf{x}_{0})\mathrm{d}\mathbf{x}_{1:t-1}\\ &=\int Q_{1}\prod_{s=3}^{t}p_{s}(\mathbf{x}_{s}|\mathbf{x}_{s-1}, \mathbf{x}_{0})\mathrm{d}\mathbf{x}_{2:t-1}\\ &=\cdots\cdots\\ &=\int p_{t}(\mathbf{x}_{t}|\mathbf{x}_{t-1})Q_{t-2}\mathrm{d} \mathbf{x}_{t-1}\\ &=Q_{t-1}=\mathcal{N}(\mathbf{u}_{t}\mathbf{x}_{0},\mathbf{v}_{t}^ {2}\mathbf{I})\end{split}\] (33)

Therefore, the probability distribution of \(\mathbf{x}_{t}\) conditioned on \(\mathbf{x}_{0}\) follows a Gaussian distribution \(\mathcal{N}(\mathbf{u}_{t}\mathbf{x}_{0},\mathbf{v}_{t}^{2}\mathbf{I})\), which is the same as in original DDPMs when the coefficient functions are defined as \(\mathbf{u}_{t}=\sqrt{\bar{\alpha}_{t}}\) and \(\mathbf{v}_{t}=\sqrt{1-\bar{\alpha}_{t}}\). This provides an important benefit that the Flow Matching and diffusion models share the same training procedure.

### Deterministic Reverse Process

The reverse tranfer probability follows Bayes' rule:

\[\begin{split} p(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})=p_{t }(\mathbf{x}_{t}|\mathbf{x}_{t-1},\mathbf{x}_{0})\frac{p_{t-1}(\mathbf{x}_{t-1} |\mathbf{x}_{0})}{p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})}\\ =\frac{p_{t-1}(\mathbf{x}_{t-1}|\mathbf{x}_{0})}{p_{t}(\mathbf{x} _{t}|\mathbf{x}_{0})}\times\delta\Bigg{[}\mathbf{x}_{t}-\frac{\mathbf{v}_{t}} {\mathbf{v}_{t-1}}\mathbf{x}_{t-1}-\left(\mathbf{u}_{t}-\frac{\mathbf{v}_{t} \mathbf{u}_{t-1}}{\mathbf{v}_{t-1}}\right)\mathbf{x}_{0}\Bigg{]}.\end{split}\] (34)

Since Dirac delta function has another form of

\[\delta(x)=\begin{cases}+\infty,x=0\\ 0,x\neq 0\end{cases},\] (35)

and \(p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})>0\), \(p_{t-1}(\mathbf{x}_{t-1}|\mathbf{x}_{t})>0\), we have

\[\begin{split} p(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})& =p_{t}(\mathbf{x}_{t}|\mathbf{x}_{t-1},\mathbf{x}_{0})\frac{p_{t-1 }(\mathbf{x}_{t-1}|\mathbf{x}_{0})}{p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})}\\ &=\left\{\begin{aligned} &+\infty\times\frac{\frac{>0}{p_{t-1}( \mathbf{x}_{t-1}|\mathbf{x}_{0})}}{p_{t}(\mathbf{x}_{t}|\mathbf{x}_{0})}, \quad\mathbf{x}_{t}=\left[\frac{\mathbf{v}_{t}}{\mathbf{v}_{t-1}}\mathbf{x}_{t -1}+\left(\mathbf{u}_{t}-\frac{\mathbf{v}_{t}\mathbf{u}_{t-1}}{\mathbf{v}_{t- 1}}\right)\mathbf{x}_{0}\right]\\ &\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad 0,\quad \mathbf{x}_{t}\neq\left[\frac{\mathbf{v}_{t}}{\mathbf{v}_{t-1}}\mathbf{x}_{t -1}+\left(\mathbf{u}_{t}-\frac{\mathbf{v}_{t}\mathbf{u}_{t-1}}{\mathbf{v}_{t- 1}}\right)\mathbf{x}_{0}\right]\\ &\simeq\left\{\begin{aligned} &+\infty,\,\mathbf{x}_{t-1}= \left[\frac{\mathbf{v}_{t-1}}{\mathbf{v}_{t}}\mathbf{x}_{t}+\left( \mathbf{u}_{t-1}-\frac{\mathbf{u}_{t}\mathbf{v}_{t-1}}{\mathbf{v}_{t}}\right) \mathbf{x}_{0}\right]\\ &\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad 0,\,\mathbf{x}_{t-1}\neq \left[\frac{\mathbf{v}_{t-1}}{\mathbf{v}_{t}}\mathbf{x}_{t}+\left(\mathbf{u}_{t -1}-\frac{\mathbf{u}_{t}\mathbf{v}_{t-1}}{\mathbf{v}_{t}}\right)\mathbf{x}_{0} \right]\\ &=\delta\Bigg{[}\mathbf{x}_{t-1}-\frac{\mathbf{v}_{t-1}}{\mathbf{v }_{t}}\mathbf{x}_{t}-\left(\mathbf{u}_{t-1}-\frac{\mathbf{u}_{t}\mathbf{v}_{t -1}}{\mathbf{v}_{t}}\right)\mathbf{x}_{0}\Bigg{]}\\ &=\lim_{\sigma\to 0}\mathcal{N}\left(\frac{\mathbf{v}_{t-1}}{ \mathbf{v}_{t}}\mathbf{x}_{t}+\left(\mathbf{u}_{t-1}-\frac{\mathbf{u}_{t} \mathbf{v}_{t-1}}{\mathbf{v}_{t}}\right)\mathbf{x}_{0},\sigma^{2}\mathbf{I} \right).\end{split}\right.\end{split}\] (36)

### Deterministic Optimization Objective

We first include the derivation of the variational bound for diffusion models provided by Sohl-Dickstein et al. (2015). The probability the generative model assigns to the data is:

\[\begin{split} p(\mathbf{x}_{0})&=\int p(\mathbf{x }_{0:T})\mathrm{d}\mathbf{x}_{1:T}\\ &=\int p(\mathbf{x}_{0:T})\frac{p_{T}(\mathbf{x}_{1:T}|\mathbf{x}_ {0})}{p_{T}(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\mathrm{d}\mathbf{x}_{1:T}\\ &=\int p_{T}(\mathbf{x}_{1:T}|\mathbf{x}_{0})\frac{p(\mathbf{x}_{0: T})}{p_{T}(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\mathrm{d}\mathbf{x}_{1:T}\\ &=\int p_{T}(\mathbf{x}_{1:T}|\mathbf{x}_{0})p(\mathbf{x}_{T}) \prod_{t=1}^{T}\frac{p(\mathbf{x}_{t-1}|\mathbf{x}_{t})}{p_{t}(\mathbf{x}_{t}| \mathbf{x}_{t-1})}\mathrm{d}\mathbf{x}_{1:T}.\end{split}\] (37)Training amounts to minimizing the negative log likelihood:

\[\mathcal{L} =-\int p(\mathbf{x}_{0})\log p(\mathbf{x}_{0})\mathrm{d}\mathbf{x} _{0}\] \[=-\int p(\mathbf{x}_{0})\log\Bigg{[}\int p_{T}(\mathbf{x}_{1:T}| \mathbf{x}_{0})p(\mathbf{x}_{T})\prod_{t=1}^{T}\frac{p(\mathbf{x}_{t-1}| \mathbf{x}_{t})}{p_{t}(\mathbf{x}_{t}|\mathbf{x}_{t-1})}\mathrm{d}\mathbf{x}_{ 1:T}\Bigg{]}\mathrm{d}\mathbf{x}_{0}\] \[\leq-\int p_{T}(\mathbf{x}_{0:T})\log\Bigg{[}p(\mathbf{x}_{T}) \prod_{t=1}^{T}\frac{p(\mathbf{x}_{t-1}|\mathbf{x}_{t})}{p_{t}(\mathbf{x}_{t}| \mathbf{x}_{t-1})}\Bigg{]}\mathrm{d}\mathbf{x}_{0:T}\] \[=\mathbb{E}_{p_{T}}\Bigg{[}\log\frac{p_{T}(\mathbf{x}_{T}| \mathbf{x}_{0})}{p(\mathbf{x}_{T})}-\log p(\mathbf{x}_{0}|\mathbf{x}_{1})+ \sum_{t=2}^{T}\log\frac{p(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})}{p( \mathbf{x}_{t-1}|\mathbf{x}_{t})}\Bigg{]}\] \[=\mathbb{E}_{p_{T}}\Bigg{[}\underbrace{D_{\text{KL}}(p_{T}( \mathbf{x}_{T}|\mathbf{x}_{0})||p(\mathbf{x}_{T}))}_{\mathcal{L}_{T}}\underbrace{ -\log p(\mathbf{x}_{0}|\mathbf{x}_{1})}_{\mathcal{L}_{0}}+\sum_{t=2}^{T} \underbrace{D_{\text{KL}}(p(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})||p (\mathbf{x}_{t-1}|\mathbf{x}_{t}))}_{\mathcal{L}_{t-1}}\Bigg{]}\]

where \(\mathcal{L}_{T}\) is usually ignored as a constant and \(p(\mathbf{x}_{t-1}|\mathbf{x}_{t})\) is parameterized with a neural network \(p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t})\) to approximate the conditioned probability distributions in the reverse process. Since \(p(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})=\lim\limits_{\sigma\to 0} \mathcal{N}\left(\frac{\mathbf{v}_{t-1}}{\mathbf{v}_{t}}\mathbf{x}_{t}+\left( \mathbf{u}_{t-1}-\frac{\mathbf{u}_{t}\mathbf{v}_{t-1}}{\mathbf{v}_{t}} \mathbf{x}_{0}\right),\sigma^{2}\mathbf{I}\right)\), the parameterized \(p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t})\) can take the same form \(\mathcal{N}(\bm{\mu}_{\theta}(\mathbf{x}_{t},t),\sigma_{t}^{2}\mathbf{I})\) because the Dirac delta function is a special case of Gaussian distribution and the KL divergence of two Gaussians can be simplified. Finally, the training objective for the deterministic diffusion process is divided as:

\[\mathcal{L}=\left\{\begin{aligned} \mathcal{L}_{T}&:\text{ a constant}\\ \mathcal{L}_{0}&:-\log\delta\left(\mathbf{x}_{0}- \mathbf{x}_{\theta}(\mathbf{x}_{1},1)\right)\\ \mathcal{L}_{t-1}&:c\|\mathbf{x}_{0}-\mathbf{x}_{ \theta}(\mathbf{x}_{t},t)\|^{2}+\lim\limits_{\sigma\to 0}\log\frac{\sigma_{t}}{ \sigma}\\ c&=\frac{1}{2\sigma_{t}^{2}}\left(\mathbf{u}_{t-1}- \frac{\mathbf{u}_{t}\mathbf{v}_{t-1}}{\mathbf{v}_{t-1}}\right)^{2},\end{aligned}\right.\] (38)

where the simplified version \(\|\mathbf{x}_{0}-\mathbf{x}_{\theta}(\mathbf{x}_{t},t)\|^{2}\) is the same as DDPMs but with different coefficients.

Figure 4: We demonstrate the trajectory differences among Markovian Diffusion Process, Deterministic Diffusion and Flow Matching.

Different Diffusion Trajectories

We illustrate the trajectories of different diffusion processes in Figure 4. The forward and reverse generation for the Markovian diffusion process is:

\[\left\{\begin{aligned} \mathbf{x}_{t}&=\sqrt{\bar{\alpha}_{t}} \mathbf{x}_{0}+\sqrt{1-\bar{\alpha}_{t}}\boldsymbol{\epsilon}_{t}\\ \mathbf{x}_{t-1}&=\frac{\sqrt{\bar{\alpha}_{t-1}}(1- \alpha_{t})}{1-\bar{\alpha}_{t}}\mathbf{x}_{0}+\frac{\sqrt{\bar{\alpha}_{t}}(1 -\bar{\alpha}_{t-1})}{1-\bar{\alpha}_{t}}\mathbf{x}_{t}\\ &\hskip 142.26378pt+\frac{\sqrt{(1-\bar{\alpha}_{t-1})(1- \alpha_{t})}}{\sqrt{1-\bar{\alpha}_{t}}}\boldsymbol{\epsilon}_{t-1}.\end{aligned}\right.\] (39)

The deterministic diffusion process:

\[\left\{\begin{aligned} \mathbf{x}_{t}&=\sqrt{\bar{ \alpha}_{t}}\mathbf{x}_{0}+\sqrt{1-\bar{\alpha}_{t}}\boldsymbol{\epsilon}\\ \mathbf{x}_{t-1}&=\left(\sqrt{\bar{\alpha}_{t-1}}- \frac{\sqrt{\bar{\alpha}_{t}(1-\bar{\alpha}_{t-1})}}{\sqrt{1-\bar{\alpha}_{t}} }\right)\mathbf{x}_{0}\\ &\hskip 142.26378pt+\frac{\sqrt{1-\bar{\alpha}_{t-1}}}{\sqrt{1- \bar{\alpha}_{t}}}\mathbf{x}_{t}.\end{aligned}\right.\] (40)

The deterministic flow matching with optimal transport:

\[\left\{\begin{aligned} \mathbf{x}_{t}&=(1-\frac{t}{T}) \mathbf{x}_{0}+\frac{t}{T}\boldsymbol{\epsilon}\\ \mathbf{x}_{t-1}&=\frac{1}{t}\mathbf{x}_{0}+\frac{t- 1}{t}\mathbf{x}_{t}.\end{aligned}\right.\] (41)

## Appendix E Details of the Function \(G\)

Equation (13) defines the function \(G(\mathbf{x},\boldsymbol{\epsilon})\) as the inversion of coefficient function.

Flow MatchingThe coefficient is \(\mathbf{u}_{t}=1-t/T\), where \(t=T\times(1-\mathbf{u}_{t})\). Therefore,

\[G(\mathbf{x}_{0},\boldsymbol{\epsilon})=t_{0}=T\times(1-\mathbf{u}_{t_{0}})=T \bigg{/}\left(1+\frac{f(\boldsymbol{\epsilon},\mathcal{J})-f(\boldsymbol{ \epsilon},\mathcal{I})}{f(\mathbf{x}_{0},\mathcal{I})-f(\mathbf{x}_{0}, \mathcal{J})}\right)\] (42)

DiffusionThe coefficient for Variance Exploding is \(\mathbf{v}_{T}=\sigma_{0}\left(\frac{\sigma_{T}}{\sigma_{0}}\right)^{\frac{t} {T}}\), where \(t=T\times\frac{\log\mathbf{v}_{t}-\log\sigma_{0}}{\log\sigma_{T}-\log\sigma_{ 0}}\).

\[G(\mathbf{x}_{0},\boldsymbol{\epsilon})=t_{0}=\mathbf{v}_{t_{0}}=T\times\frac{ \log\mathbf{v}_{t}-\log\sigma_{0}}{\log\sigma_{T}-\log\sigma_{0}}=T\times\frac {\log\frac{f(\boldsymbol{\epsilon},\mathcal{J})-f(\boldsymbol{\epsilon}, \mathcal{I})}{f(\mathbf{x}_{0},\mathcal{I})-f(\mathbf{x}_{0},\mathcal{J})}- \log\sigma_{0}}{\log\sigma_{T}-\log\sigma_{0}}.\] (43)

For Variance Preserving, the function \(G(\mathbf{x}_{0},\boldsymbol{\epsilon})\) is more difficult to calculate since \(\mathbf{u}_{t}=\sqrt{\bar{\alpha}_{t}}\), where \(\bar{\alpha}=\prod_{i=1}^{t}\alpha_{i}\), \(\alpha_{t}=1-\beta_{t}\), and \(\beta_{t}\) is also influenced by noise schedulers. This makes \(G(\mathbf{x}_{0},\boldsymbol{\epsilon})\) hard to calculate. Fortunately, we can bypass this function and provide the corresponding pseudo code.

## Appendix F Details of the Training Objective

The rescaled vector field is calculated as:

\[\tilde{u}_{t} =\frac{\mathrm{d}\tilde{\mathbf{x}}_{t}}{\mathrm{d}t}=\frac{ \mathrm{d}\tilde{\mathbf{x}}_{t}}{\mathrm{d}\tau}\frac{\mathrm{d}\tau}{\mathrm{ d}t}\] (44) \[=\left[\mathbf{u}^{\prime}\left(\mathbf{x}_{0},\tau\right)\mathbf{ x}_{0}+\mathbf{v}^{\prime}(\mathbf{x}_{0},\tau)\boldsymbol{\epsilon}\right]\frac{T-r \times G(\mathbf{x}_{0},\boldsymbol{\epsilon})}{T}\] \[=u_{\tau}\times\frac{T-r\times G(\mathbf{x}_{0},\boldsymbol{ \epsilon})}{T}.\]Considering the expectation form of \(\tilde{u}_{t}\), there is:

\[\begin{split}\mathbb{E}_{\tilde{\mathbf{x}}_{t}}\left[\tilde{u}_{t}( \tilde{\mathbf{x}}_{t}|\mathbf{x}_{0})\right]&=\sum p(\tilde{ \mathbf{x}}_{t}|\mathbf{x}_{0})\tilde{u}_{t}(\tilde{\mathbf{x}}_{t}|\mathbf{x }_{0})\\ &=\sum p(\tilde{\mathbf{x}}_{t}|\mathbf{x}_{0})\bigg{[}\mathbf{u} ^{\prime}\left(\mathbf{x}_{0},\tau\right)\mathbf{x}_{0}+\mathbf{v}^{\prime}( \mathbf{x}_{0},\tau)\boldsymbol{\epsilon}\bigg{]}\underbrace{\frac{T-r\times G (\mathbf{x}_{0},\boldsymbol{\epsilon})}{T}}_{0\leq\text{coefficient}\leq 1}\\ &\leq\sum p(\tilde{\mathbf{x}}_{t}|\mathbf{x}_{0})\bigg{[} \mathbf{u}^{\prime}\left(\mathbf{x}_{0},\tau\right)\mathbf{x}_{0}+\mathbf{v}^ {\prime}(\mathbf{x}_{0},\tau)\boldsymbol{\epsilon}\bigg{]}\\ &=\mathbf{u}^{\prime}\left(\mathbf{x}_{0},\tau\right)\bigg{[} \sum p(\tilde{\mathbf{x}}_{t}|\mathbf{x}_{0})\mathbf{x}_{0}\bigg{]}+\mathbf{v} ^{\prime}(\mathbf{x}_{0},\tau)\boldsymbol{\epsilon}\\ &=\tilde{u}_{t}(\tilde{\mathbf{x}}_{0}|\mathbb{E}_{\tilde{ \mathbf{x}}_{t}}|\mathbf{x}_{0})).\end{split}\] (45)

Therefore, the training objective \(\mathbb{E}\|\tilde{u}_{t}-\tilde{u}_{\theta}\|^{2}\leq c\,\mathbb{E}\| \mathbf{x}_{0}-\mathbf{x}_{\theta}\|^{2}\), where \(c\) is the coefficient.

## Appendix G Code Implementations

Our framework is a module constructed on current diffusion models. We demonstrate our kernel part _rescale diffusion trajectory_ with pseudo python code as below:

``` defrescale_diffusion_trajectory(x_0,epsilon,embedding,labels,alphas_cumprod,timesteps,mode): #embedding:embeddingmatrix,f(x,i)=(embedding*x)[i] #labels:I #alphas_cumprod:listofallu_t #timesteps:t #mode:noisingordenoising
#1.getf(x,i): self_dot=torch.sum(embedding*embedding,dim=-1) f_x_i=self_dot[labels][...,None] labels=labels[...,None]
#2.getf(x,j)andf(eps,j): embedding=embedding.permute(1,0) f_x_j=torch.matmul(x_0,embedding) f_eps_j=torch.matmul(epsilon,embedding)
#3.getf(x,i)-f(x,j):(usually>=0;smaller->closer) #filteroutf(x,i)-f(x,i)withalargepositivenumber100 fxi_minus_fxj=(f_x_i-f_x_j).scatter(-1,labels,100)
#4.getf(eps,i)andf(eps,j)-f(eps,i):(larger->morenoise) f_eps_i=torch.gather(f_eps_j,-1,labels) #filteroutf(eps,i)-f(eps,i)withalargenegativenumber-100 fepsj_minus_fepsi=(f_eps_j-f_eps_i).scatter(-1,labels,-100)
#5.getfractionandu_t_0 #maskresultsoutsidethesupportset info_mask=(fepsj_minus_fepsi<0)|(fxi_minus_fxj<0) fraction=fix_minus_fjfx/feps_minus_fieps fraction[info_mask]=100 min_frac,-=fraction.min(dim=-1)#minimum #DiffusionVariancePreservingeq.(9) u_t_0=torch.sqrt(1/(1+min_frac**2))[...,None]
#6.rescaletimesteps sqrt_alphas_cumprod=torch.sqrt(alphas_cumprod)

###!!important trick!!!!###
#We do not need to calculate the function G(x_0,t) (eq. (12)).
#Timesteps of diffusion processes are discrete and
# we just iterate over and compare with all coefficient functions.
#Besides, function G is easy to calculate for Flow Matching. index = torch.sum(u_t_0 < sqrt_alphas_cumprod, dim=-1)
#T is the maximum timestep, for example T=2000.
#onfactor is the confidency factor
#tau is therescaled timestep
#delta_tau is therescaled decoding velocity if mode == 'noising': tau = (timesteps + index - \ (((timesteps + 1) / T) * index)).long().clamp(0, T) tau = (confactor * tau.float() + \ (1.0 - confactor) * timesteps.float()).long().clamp(0, T) return tau elif mode == 'denoising': delta_tau = (T - index) / T delta_tau = (confactor * delta_tau + \ (1 - confactor) * 1.0).clamp(0, 1) return delta_tau

## Appendix H Analysis

Gaussian SamplingOur framework is compatible with the Gaussian sampling in DDPM, where random noises can be added into each iteration step. Algorithm 3 demonstrates the Gaussian sampling procedure. Compared with algorithm 2, a Gaussian noise \(\mathbf{z}\sim\mathcal{N}(\mathbf{0},\sigma_{t}^{2}\mathbf{I})\) with a decreasing variance \(\sigma_{t}\) is injected to the estimated next state \(\tilde{\mathbf{x}}_{t}\). This noise \(\mathbf{z}\) will be mapped as changing the initial sampling \(\tilde{\mathbf{x}}_{T}\) through the trajectory alteration step. We illustrate the deterministic and Gaussian sampling for our model on Cifar-10 in Table 6, where the deterministic sampling can achieve a much better performance of FiD. We assume this is because our coefficient functions \(\mathbf{u}(\mathbf{x}_{0},t)\) and \(\mathbf{v}(\mathbf{x}_{0},t)\) are dynamically calculated to rescale the deterministic trajectory in the training stage. In the inference stage, \(\mathbf{x}_{0}\) is replaced by \(\mathbf{x}_{\theta}(\mathbf{x}_{t},t)\), where errors will accumulate if the predicted pseudo target changes frequently. Moreover, Gaussian sampling will further introduce random noises at each reverse step, making our rescaled timestep \(\tau\) far away from the training situation. Therefore, errors in the calculations of trajectory scaling will explode over iterations.

## Appendix I Limitations

Our framework is proposed to migrate the powerful continuous diffusion models to discrete problems. There is another technical route that directly designs the diffusion process on the discrete state space and our method is not useful for this scenario. However, we believe the continuous diffusion models can be a general framework for generative modeling and our effort can advance this target.

We prefer \(\mathbf{x}_{0}\) as the training target because we highly depend on the reliability of the predicted \(\hat{\mathbf{x}}_{0}\) during inference. Although it is possible to use other targets, the modeling effect will decrease in practical use, which limits the flexibility of diffusion modeling. For example, predicting the \(\hat{\bm{\epsilon}}\) and recovering \(\hat{\mathbf{x}}_{0}\) with eq. (23) is inefficient, because a small error in predicting \(\hat{\bm{\epsilon}}\) will be amplified by eq. (23) and lead to the collapse of \(G(\hat{\mathbf{x}}_{0},\hat{\bm{\epsilon}})\).

Our approach requires extra computational cost. But they are acceptable since our rescaling process is a series of parallel matrix computations. Considering that our approach is compatible with the Self-Conditioning (Chen et al., 2023), our overhead is negligible when it is used.

## Appendix J Other Experimental Details

For language modeling, we utilize the model configuration _transformer-iwslt-de-en_ in Fairseq framework (Ott et al., 2019) for Iwslt14 de-en, which has \(6\) transformer layers, \(4\) attention heads, \(512\) hidden dimensions, and \(1024\) feed forward layer dimensions. For other datasets, the configuration is _transformer-base_, which has \(6\) transformer layers, \(8\) attention heads, \(512\) hidden dimensions, and \(2048\) feed forward layer dimensions. The embedding dimension is \(128\). The beam size is \(1\) length prediction beam \(\times 5\) generation beam, since the length prediction is unstable for diffusion language models. For reranking, we take \(7\) length prediction beam \(\times 3\) generation beam as Difforner to let the transformer choose the best one.

\begin{table}
\begin{tabular}{l|c c} \hline \hline  & **Gaussian** & **Deterministic** \\ \hline \hline Binary Coding & 13.39 & **3.86** \\ Fixed Embedding & 12.21 & **9.15** \\ Trainable Embedding & 22.24 & **10.99** \\ \hline \hline \end{tabular}
\end{table}
Table 6: FiD of difference sampling strategies.

[MISSING_PAGE_FAIL:23]

\begin{table}
\begin{tabular}{|p{113.8pt}||p{113.8pt}|p{113.8pt}|p{113.8pt}|} \hline \hline
**Source: German** & \multicolumn{3}{c|}{**Target: English**} \\  & **Difformer** & **Ours** & **Golden** \\ \hline \hline ich mchte ihnen erzhlen, wie wir das herausgefunden haben. & i want to tell you about this. & i want to tell you how we  ve figured that out. & i want to tell you how we found that out. \\ \hline da gingen ganz schn viele verrckte dinge vor sich. & lots of crazy things. & there were quite a lot of crazy things going on. & there was a whole lot of crazy going on in there. \\ \hline man mach etwas, das eigentlich ein wenig anders ist. & you do something a little different. & you  re doing something that  s actually a little bit different. & you do something that  s actually a little different. \\ \hline und die welt in der wir lebten sah so aus. & and the world we lived like this. & and the world we lived in looked like this. & and the world we used to live in looked like this. \\ \hline man erwartete eine zustzliche milliarde spieler im nchsten jahrzehnt. & you  ll expect an next billion players. & you expect an extra billion players in the next decade. & they expect one billion more gamers in the next decade. \\ \hline b hat diese vorteile und risiken. was wollen sie tun? & b has risks. what do you want to do? & b has these benefits and risks. what do you want to do? & b has these benefits, and these risks. what do you want to do? & b has these benefits, and these risks. what do you want to do  & and these risks. what do you want to do  \\ \hline wir haben also so eine situation, wo, je weit unsere wissenschaft fortschreitet, wir uns uns e mehr eingestehen mussen, dass diese kategorien, die wir fr stabile anatomische kategorien gehalten hatten welche sehr einfache zuordnungen herstellten um dauerhafte identitstkategorien zu schaffen wiel schaffen wielche sehr einfache zuordnungen herstellten um dauerhafte identitstkategorien zu schaffen wiel schaffen, als wir unschrfer sind, als wir angenommen haben. & so we have a situation where, as the further our science goes, to admit in terms, the more that these categories that we thought were stable anatomical categories, which made a very simple assa-combations to create permanent identity or are much unsharers unschrfer sind, als wir angenommen haben. & so what we have is a sort of situation where the farther our science goes, the more we have to admit to ourselves that these categories that we thought of as stable anatomical categories, which made a very simple assa-combations to create permanent identity or are much unsharers unschrfer sind, als wir angenommen haben. & so what we have is a sort of situation where the farther our science goes, the more we have to admit to ourselves that these categories that we thought of as stable anatomical categories, which made a very simple assa-combations to create permanent identity or are much more blanky than we thought. \\ \hline \end{tabular}
\end{table}
Table 7: Cases of translation on Iwslt14 de-en.

[MISSING_PAGE_FAIL:25]

## 6 Conclusion

Figure 7: Generated Trainable Embedding images of reproduced Bit Diffusion and Ours on Cifar-10.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Contributions and scope are in abstract and introduction. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Discussed in (7) Conclusion and (H) Limitations sections. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: From sections (A) to (E) in appendices. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We use algorithms 1 and 2 to demonstrate how to reproduce our algorithm. We provide a paragraph of Experimental Setup in (4) Language Modeling and (5) Discrete Image Generation sections. Other details are in section (I) and pseudo code of our kernel process is in (F). Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: The pseudo code of our kernel process is demonstrated in (F) and we will public our code on github.com. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We provide a paragraph of Experimental Setup in (4) Language Modeling and (5) Discrete Image Generation sections. Other details are in section (I). We provide ablation studies on the hyperparameters. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [No] Justification: Error bars are not reported because it would be too computationally expensive. Each result in the experiment table needs to be run on an 80G A100 for at least 2 days. The huge overhead required to obtain a statistically significant error bar makes it impossible for us to achieve it. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.

* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: Details are in section (I). Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: Discussed in section (J). Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.

* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Our approach is a framework involves algorithms but not pre-trained models. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We provide the link or citation of each asset, where licenses are in the link. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.

* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: No new assets introduced. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: No crowdsourcing. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: No crowdsourcing. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.