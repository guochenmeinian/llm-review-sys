# Blocked Collaborative Bandits: Online Collaborative Filtering with Per-Item Budget Constraints

 Soumyabrata Pal

Google Research

Bangalore, India

soumyabratapal13@gmail.com &Arun Sai Suggala

Google Research

Bangalore, India

arunss@google.com &Karthikeyan Shanmugam

Google Research

Bangalore, India

karthikeyanvs@google.com &Prateek Jain

Google Research

Bangalore, India

prajain@google.com

###### Abstract

We consider the problem of _blocked_ collaborative bandits where there are multiple users, each with an associated multi-armed bandit problem. These users are grouped into _latent_ clusters such that the mean reward vectors of users within the same cluster are identical. Our goal is to design algorithms that maximize the cumulative reward accrued by all the users over time, under the _constraint_ that no arm of a user is pulled more than \(\mathsf{B}\) times. This problem has been originally considered by [4], and designing regret-optimal algorithms for it has since remained an open problem. In this work, we propose an algorithm called \(\mathtt{B\text{-}LATTICE}\) (Blocked Latent bAndiTs via maTrIx ComplEtion) that collaborates across users, while simultaneously satisfying the budget constraints, to maximize their cumulative rewards. Theoretically, under certain reasonable assumptions on the latent structure, with \(\mathsf{M}\) users, \(\mathsf{N}\) arms, \(\mathsf{T}\) rounds per user, and \(\mathsf{C}=O(1)\) latent clusters, \(\mathtt{B\text{-}LATTICE}\) achieves a per-user regret of \(\widetilde{O}(\sqrt{\mathsf{T}(1+\mathsf{N}\mathsf{M}^{-1})}\) under a budget constraint of \(\mathsf{B}=\Theta(\log\mathsf{T})\). These are the first sub-linear regret bounds for this problem, and match the minimax regret bounds when \(\mathsf{B}=\mathsf{T}\). Empirically, we demonstrate that our algorithm has superior performance over baselines even when \(\mathsf{B}=1\). \(\mathtt{B\text{-}LATTICE}\) runs in phases where in each phase it clusters users into groups and collaborates across users within a group to quickly learn their reward models.

## 1 Introduction

Modern recommendation systems cater to millions of users and items [1] on a daily basis, typically in an online fashion. A critical feature of such systems is to quickly learn tastes of individual users from sequential actions and feedback, and suggest personalized products for each user. Furthermore, in practice, an item that has already been consumed by a user is recommended very few times to the same user (or _not_ recommended at all). This is because, in applications such as movie/book recommendations, a typical user will find little interest in consuming the same item multiple times.

This problem - that we rename as _Blocked Collaborative Bandits_ - was abstracted out by [4] with a modeling assumption that users have a latent clustering structure. That is, each user can belong to an unknown cluster and the expected reward for an item/movie is same for all users in a cluster. Formally, consider \(\mathsf{M}\) users, \(\mathsf{N}\) items and \(\mathsf{T}\) rounds with \(\mathsf{M},\mathsf{N}\gg\mathsf{T}\) (\(\mathsf{M},\mathsf{N}\approx 10^{6}\) in recommendation systems such as YouTube) and in each round, every user is recommended some item (potentially different for each user). On consuming the item, a noisy reward is assigned. As mentioned above,it is assumed that the users can be clustered in \(\mathsf{C}\) clusters, where \(\mathsf{C}\ll\mathsf{M},\mathsf{N}\), and users in the same cluster have identical reward distributions over items. Furthermore, any item can be recommended to a particular user at most \(\mathsf{B}\) times, after which the item is _blocked_ for the user.

[4] considered this problem for \(\mathsf{B}=1\) in the setting where a user in cluster \(c\) on being recommended item \(j\) provides a like (\(+1\)) with probability \(p_{cj}\) and a dislike (\(-1\)) with probability \(1-p_{cj}\). The authors studied a notion of pseudo-regret corresponding to minimizing the number of _un-likeable_ items for a user, _i.e.,_ items for which the probability of user giving a like (\(+1\)) is less than \(1/2\). To this end, the authors proposed the Collaborative-Greedy algorithm, an \(\epsilon\)-greedy style algorithm that performs random exploration in each round with certain probability. During exploitation it provides recommendations based on a neighborhood of similar users. However, maximizing the number of _likeable_ items is limiting as it does not prioritize items with large rewards and completely disregards the item ordering. Despite these theoretical limitations, variants of the collaborative algorithm designed in [4] have found applications in predicting Bitcoin price, [29], information retrieval [12] among others.

Recent works have studied this problem under a more practical notion of regret which involves maximizing the cumulative rewards accrued over time [2, 5]. However, these works assume a cluster structure among both users and items. This assumption entails that there are many copies of the highest rewarding item for any user; this voids the blocking constraint and makes the problem significantly easier. Moreover, the algorithms designed in [2] are greedy (they perform exploration first to cluster users, items, and then perform exploitation) and achieve significantly sub-optimal regret. These bounds, translated to the original blocked bandit problem where there are no item clusters, have sub-optimal dependence on the number of items \(\mathsf{N}\). The algorithms designed in [5] assumed a _noiseless_ binary feedback model which allowed for constant regret. However, these algorithms are not easily extendable to the more general noisy reward setting we consider in this work.

Another line of work has studied this problem when \(\mathsf{B}=\mathsf{T}\) (i.e., no budget constraints on arms) [24, 11, 25]. While some of these works have designed regret optimal algorithms [25], the \(\mathsf{B}=\mathsf{T}\) budget constraint is too lenient in many modern recommendation systems. To summarize, existing works have either attempted to solve the much harder setting of \(\mathsf{B}=1\) by imposing additional restrictions on the problem or the simpler \(\mathsf{B}=\mathsf{T}\) setting which is not very relevant in practice.

**This Work.** In this work, we make progress on this problem by considering the intermediate setting of \(\mathsf{B}=\Theta(\log\mathsf{T})\). We do not impose any cluster structure among items (as in [4]), and consider a general notion of regret which involves maximizing the cumulative rewards under the budget constraints. We propose B-LATTICE(Alg. 1), a phased algorithm which carefully balances exploration and exploitation. Our algorithm also performs on-the-fly clustering of users and collaborates across users within a cluster to quickly learn their preferences, while simultaneously satisfying the budget constraints. The key contribution of our work is that under certain standard incoherence assumptions (also used recently in [25]) and a budget constraint of \(\mathsf{B}=\Theta(\log\mathsf{T})\), we show that B-LATTICE achieves a per-user regret of \(\widetilde{O}(\sqrt{\mathsf{T}(1\sqrt{\mathsf{N}\mathsf{M}^{-1}})})\)1. Empirically, our algorithm can even handle a budget constraint of \(\mathsf{B}=1\) and perform better than baselines (Alg. 6). However, bounding its regret

\begin{table}
\begin{tabular}{c||c|c|c} \hline Paper & Setting & Metric & Guarantees (worst-Case) \\ \hline \hline Bresler et al., 2014 [4] & \begin{tabular}{c} \(\mathsf{B}=1\), \\ user clusters \\ \end{tabular} & \begin{tabular}{c} pseudo regret (maximize \\ likeable items) \\ \end{tabular} & \(O(T)\) \\ \hline Bresler et al., 2018 [5] & \begin{tabular}{c} \(\mathsf{B}=1\), \\ user, item clusters; \\ noiseless rewards \\ \end{tabular} & regret & \(\widetilde{O}(1)\) \\ \hline Ariu et al., 2020 [2] & \begin{tabular}{c} \(\mathsf{B}=1\), \\ user, item clusters \\ \end{tabular} & regret & \begin{tabular}{c} \(\widetilde{O}(\mathsf{T}^{2/3}(1+\mathsf{N}\mathsf{M}^{-1})^{1/3})\) \\ sub-optimal in \(\mathsf{N}\), \(\mathsf{T}\) \\ \end{tabular} \\ \hline Pal et al., 2023 [25] & \begin{tabular}{c} \(\mathsf{B}=\mathsf{T}\), \\ user clusters \\ \end{tabular} & regret & 
\begin{tabular}{c} \(\widetilde{O}(\sqrt{\mathsf{T}(1+\mathsf{N}\mathsf{M}^{-1})}\) \\ minimax optimal in \(\mathsf{N}\), \(\mathsf{M}\), \(\mathsf{T}\) \\ \end{tabular} \\ \hline
**This Work** & 
\begin{tabular}{c} \(\mathsf{B}=\Theta(\log\mathsf{T})\), \\ user clusters \\ \end{tabular} & regret & \(\widetilde{O}(\sqrt{\mathsf{T}(1+\mathsf{N}\mathsf{M}^{-1})}\) \\ \hline \end{tabular}
\end{table}
Table 1: Comparison of various approaches for blocked collaborative bandits. All the regret bounds stated here are worst-case bounds and assume \(\mathsf{C}=O(1)\). Moreover, the regret is averaged across users. The worst-case pseudo-regret in [5] is linear when the items have rewards close to \(0.5\). In [2], the authorsâ€™ proposed a greedy algorithm whose worst-case has \(\mathsf{T}^{2/3}\) dependence.

in this setting is much more challenging which we aim to address in a future work. That being said, under an additional cluster structure on the items, we show that our theoretical guarantees hold even for \(\mathsf{B}=1\) (Appendix F).

We also provide a non-trivial regret lower bound of \(\widetilde{\Omega}(\sqrt{\mathsf{NM}^{-1}}\bigvee\mathsf{TM}^{-1/2})\). Our proof involves a novel reduction to multi-hypothesis testing and relies on Fano's inequality for approximate recovery [28] (see Appendix E). Our techniques could be of independent interest even outside the context of this work. Our lower bound is tight in two regimes - when the number of rounds \(\mathsf{T}\) is very small or very large. However, we conjecture that our upper bounds are actually tight since they recover the same rates as in the \(\mathsf{B}=\mathsf{T}\) setting [25]; tightening the lower bound is left as a future work. Finally, we verify our theoretical results by simulations on synthetic data (see Appendix C). Here, we compare a more practical version of B-LATTICE(Algorithm 6) with Collaborative-Greedy [4]. We demonstrate that B-LATTICE not only has good regret but also other practically desirable properties such as a small cold-start period, and repeated high quality recommendations.

**Techniques.** Our algorithm is built on recent works that have studied this problem without the budget constraint [17; 25]. [17] developed a regret optimal algorithm called LATTICE that runs in phases. At any phase, the algorithm maintains a grouping of users which it refines over time (these groups are nothing but our current estimate of user clusters). Within each group, the algorithm relies on collaboration to quickly estimate the reward matrix. To be precise, the algorithm performs random exploration followed by low-rank matrix completion [8] to get a good estimate of the user-item reward matrix. Next, the algorithm uses the estimated reward matrix to eliminate sub-optimal arms for each user. Finally, it refines the user clusters by placing users with similar reward structure in the same group.

Extending the above algorithmic recipe to our setting poses a couple of challenges. First, observe that the _oracle_ optimal strategy in the budget constrained setting is to recommend each of the top \(\mathsf{T}/\mathsf{B}\) items \(\mathsf{B}\) times; we refer to these top times as _golden_ items in the sequel. To compete against such a policy, our algorithm needs to quickly identify the golden items for each user. The LATTICE algorithm described above doesn't perform this, as it aims to only identify the top item for every user. So, one of the key novelties in our algorithm is to design a test to quickly identify the golden items and recommend them to the users. The second challenge arises from the usage of low-rank matrix completion oracles in LATTICE. To be precise, LATTICE requires more accurate estimates of the user-item reward matrix in the later phases of the algorithm. To this end, it repeatedly recommends an item to a user to reduce the noise in its estimates. However, this is infeasible in our setting due to the budget constraints. So, the second novelty in our algorithm is to avoid repeated recommendations and design an alternate exploration strategy that adheres to the budget constraints.

**Other Related Work:**

_Item-Item Collaborative Filtering (CF)._ A complementary theoretical line of work proposes to exploit a clustering structure across the items instead of users [7; 23; 27; 22]. Under a similar blocking constraint, the authors have provided a sub-linear regret guarantee based on a certain measure of complexity called the doubling dimension. Since then, there have been several works in the literature that have attempted to exploit a cluster structure on both users and items [6; 2].

_Variants of User-User CF._[15] has looked into the problem of non-stationary user-user collaborative filtering where the preferences of users change over time. [13] studies a variant where the user only provides positive ratings i.e when the user has liked an item. [9] and [3] studies probabilistic models for user user CF in an online and offline model respectively.

_Cluster Structure across users._ In several problems related to multi-armed bandits, cluster structure across users have been explored. In particular, in [11; 20; 10; 21; 26], the authors have imposed a cluster-structure across users while each item has a \(d\)-dimensional context chosen uniformly at random at each round. The preferences of each user is a linear function of the context vector and the cluster id. Under these settings, the authors prove a strong regret bound. However, note that in our setting, the item contexts are hidden; hence, these techniques are not applicable to our setting.

## 2 Problem Setting and Background

**Notation.** We write \([m]\) to denote the set \(\{1,2,\ldots,m\}\). For a vector \(\mathbf{v}\in\mathbb{R}^{m}\), \(\mathbf{v}_{i}\) denotes the \(i^{\text{th}}\) element; for any set \(\mathcal{U}\subseteq[m]\), let \(\mathbf{v}_{\mathcal{U}}\) denote the vector \(\mathbf{v}\) restricted to the indices in \(\mathcal{U}\). Similarly,for \(\mathbf{A}\in\mathbb{R}^{m\times n}\), \(\mathbf{A}_{ij},\mathbf{A}_{i}\) denotes the \((i,j)\)-th element and the \(i^{\text{th}}\) row of \(\mathbf{A}\) respectively. For any set \(\mathcal{U}\subseteq[m],\mathcal{V}\subseteq[n]\), \(\mathbf{A}_{\mathcal{U},\mathcal{V}}\) denotes \(\mathbf{A}\) restricted to the rows in \(\mathcal{U}\) and columns in \(\mathcal{V}\). Let \(\|\mathbf{A}\|_{\infty}\) denote absolute value of the largest entry in matrix \(\mathbf{A}\). \(\mathcal{N}(0,\sigma^{2})\) denotes the Gaussian distribution with \(0\) mean and variance \(\sigma^{2}\). We write \(\mathbb{E}X\) to denote the expectation of a random variable \(X\). \(\left|\left|\mathbf{U}\right|\right|_{2,\infty}\) corresponds to the maximum euclidean norm of a row of the matrix \(\mathbf{U}\). More precisely, for a matrix \(\mathbf{U}\in\mathbb{R}^{\mathsf{M}\times r}\), the norm \(\left|\left|\mathbf{U}\right|\right|_{2,\infty}=\max_{i\in[\mathsf{M}]}\left| \left|\mathbf{U}_{i}\right|\right|_{2}\). Thus, if \(\left|\left|\mathbf{U}\right|\right|_{2,\infty}\) is small as in Lemma 1, then all rows of \(\mathbf{U}\) have a small \(\ell_{2}\) norm.

**Problem Setting.** Consider an online recommendation system with \(\mathsf{M}\) users, \(\mathsf{N}\) items and \(\mathsf{T}\) rounds. Let \(\mathbf{P}\in\mathbb{R}^{\mathsf{M}\times\mathsf{N}}\) be the reward matrix which is unknown. Here, we assume the set of \(\mathsf{M}\) users can be partitioned into \(\mathsf{C}\) disjoint but unknown clusters \(\mathcal{C}^{(1)},\mathcal{C}^{(2)},\ldots,\mathcal{C}^{(\mathsf{C})}\) such that any two users \(u,v\in[\mathsf{M}]\) belonging to the same cluster have identical reward vectors i.e. \(\mathbf{P}_{u}=\mathbf{P}_{v}\). In each round \(t\in[\mathsf{T}]\), every user is recommended an item (can be different for each user) by the system. In turn, the system receives feedback in the form of reward from each user. Let, \(\mathbf{R}^{(t)}_{u\rho_{u}(t)}\) be the observed reward for recommending item \(\rho_{u}(t)\in[\mathsf{N}]\) to user \(u\) at round \(t\) such that:

\[\mathbf{R}^{(t)}_{u\rho_{u}(t)}=\mathbf{P}_{u\rho_{u}(t)}+\mathbf{E}^{(t)}_{u \rho_{u}(t)}\] (1)

where \(\mathbf{E}^{(t)}_{u\rho_{u}(t)}\) denotes the unbiased additive noise. 2 We assume that elements of \(\{\mathbf{E}^{(t)}_{u\rho_{u}(t)}\}_{\begin{subarray}{c}u\in[\mathsf{M}]\\ t\in[\mathsf{T}]\end{subarray}}\) are i.i.d. zero mean sub-gaussian random variables with variance proxy \(\sigma^{2}\) i.e. for all \(u,t\in[\mathsf{M}]\times[\mathsf{T}]\), we have \(\mathbb{E}\mathbf{E}^{(t)}_{u\rho_{u}(t)}=0\) and for all \(s\in\mathbb{R}\), we have \(\mathbb{E}\exp(s\mathbf{E}^{(t)}_{u\rho_{u}(t)})\leq\exp(\sigma^{2}s^{2}/2)\). As in practical recommendation systems, we impose an additional constraint that the same item cannot be recommended more than \(\mathsf{B}\) times to a user, for some small \(\mathsf{B}=\Theta(\log\mathsf{T})\). For simplicity of presentation, we assume \(\mathsf{T}\) is a multiple of \(\mathsf{B}\). However, we would like to note that our results hold for general \(\mathsf{T}\). Without loss of generality, we assume \(\mathsf{N}\geq\mathsf{T}/\mathsf{B}\), since otherwise the budget constraints cannot be satisfied.

Footnote 2: This corresponds to the following analogue of multi-agent multi-armed bandits (MAB) - we have \(\mathsf{M}\) users each involved in a separate MAB problem with the same set of \(\mathsf{N}\) arms (corresponding to the \(\mathsf{N}\) items) and \(\mathsf{T}\) rounds. The mean reward of each arm is different for each user captured by the \(\mathsf{M}\times\mathsf{N}\) reward matrix \(\mathbf{P}\). In each round \(t\), every agent \(u\in[\mathsf{M}]\) simultaneously pulls an unblocked arm \(\rho_{u}(t)\) of their choice based on the feedback history of all users (including \(u\)) from previous rounds. Subsequently the noisy feedback for all \(\mathsf{M}\) users and their corresponding arm pulls at round \(t\) is revealed to everyone.

Our goal is to design a method that maximizes cumulative reward. Let \(\pi_{u}:[\mathsf{N}]\rightarrow[\mathsf{N}]\) denote the function that sorts the rewards of user \(u\in[\mathsf{M}]\) in descending order, i.e., for any \(i<j\), \(\mathbf{P}_{u\pi_{u}(i)}\geq\mathbf{P}_{u\pi_{u}(j)}\). The _oracle_ optimal strategy for this problem is to recommend \(\{\pi_{u}(s)\}_{\begin{subarray}{c}s=1\ldots\mathsf{T}/\mathsf{B}\end{subarray}}\), the top \(\mathsf{T}/\mathsf{B}\) items with the highest reward, \(\mathsf{B}\) times each. This leads us to the following notion of regret

\[\mathsf{Reg}(\mathsf{T})\triangleq\sum_{s\in[\mathsf{T}/\mathsf{B}],u\in[ \mathsf{M}]}\frac{\mathbb{B}\mathbf{P}_{u\pi_{u}(s)}}{\mathsf{M}}-\mathbb{E} \sum_{t\in[\mathsf{T}],u\in[\mathsf{M}]}\frac{\mathbf{P}_{u\rho_{u}(t)}}{ \mathsf{M}},\] (2)

where the expectation is over the randomness in the policy and the rewards, and \(\rho_{u}(t)\) is any policy that satisfies the budget constraints.

**Importance of collaboration.** Suppose we treat each user independently and try to minimize their regret. In this case, when \(\mathsf{B}\) is as small as \(O(\log\mathsf{T})\), we will incur a regret that is almost linear in \(\mathsf{T}\). This is because we will not have enough data for any item to know if it has a high or a low reward. This shows the importance of collaboration across users to achieve optimal regret. The latent cluster structure in our problem allows for collaboration and sharing information about items across users.

For ease of exposition of our ideas, we introduce a couple of definitions.

**Definition 1**.: _A subset of users \(\mathcal{S}\subseteq[\mathsf{M}]\) is called "nice" if \(\mathcal{S}\equiv\bigcup_{j\in\mathcal{A}}\mathcal{C}^{(j)}\) for some \(\mathcal{A}\subseteq[\mathsf{C}]\). In other words, \(\mathcal{S}\) can be represented as the union of some subset of clusters._

**Definition 2**.: _For any user \(u\in[\mathsf{M}]\), we call the set of items \(\{\pi_{u}(t)\}_{t=1}^{\mathsf{T}/\mathsf{B}}\) (i.e., the set of best \(\mathsf{T}/\mathsf{B}\) items) to be the golden items for user \(u\)._

### Low-Rank Matrix Completion

Additional Notation.For an estimate \(\widehat{\mathbf{P}}\) of reward matrix \(\mathbf{P}\), we will use \(\widetilde{\pi}_{u}:[\mathsf{N}]\rightarrow[\mathsf{N}]\) to denote the items ordered according to their estimated reward for the user \(u\) i.e., \(\widehat{\mathbf{P}}_{u\widetilde{\pi}_{u}(i)}\geq\widehat{\mathbf{P}}_{u \widetilde{\pi}_{u}(j)}\) when \(i<j\). For any user \(u\in[\mathsf{M}]\) and any subset of items \(\mathcal{A}\subseteq[\mathsf{N}]\), we will use \(\pi_{u}\mid\mathcal{A}:[|\mathcal{A}|]\rightarrow[\mathsf{N}]\) to denote the permutation \(\pi_{u}\) restricted to items in \(\mathcal{A}\subseteq[\mathsf{N}]\) i.e. for any user \(u\in[\mathsf{M}]\) and any \(i,j\in[|\mathcal{A}|]\) satisfying \(i<j\), we will have \(\mathbf{P}_{u\widetilde{\pi}_{u}(i)|\mathcal{A}}\geq\mathbf{P}_{u\widetilde{ \pi}_{u}(j)|\mathcal{A}}\). Here, \(\pi_{u}(i)\mid\mathcal{A}\) corresponds to the \(i^{\text{th}}\) item among items in \(\mathcal{A}\) sorted in descending order of expected reward for user \(u\).

An important workhorse of our algorithm is low-rank matrix completion, which is a well studied problem in the literature [16; 18; 8; 17]. Given a small set of entries that are randomly sampled from a matrix, these algorithms infer the missing values of the matrix. More precisely, consider a low-rank matrix \(\mathbf{Q}\in\mathbb{R}^{\mathsf{M}\times\mathsf{N}}\). Let \(\Omega\subseteq[\mathsf{M}]\times[\mathsf{N}]\) be a random set of indices obtained by picking each index in \([\mathsf{M}]\times[\mathsf{N}]\) independently with probability \(p>0\). Let \(\{\mathbf{Z}_{ij}\}_{(i,j)\in\Omega}\) be the corresponding noisy entries (sub-gaussian random variables with variance proxy \(\sigma^{2}>0\)) that we observe which satisfy \(\mathbb{E}\mathbf{Z}_{ij}=\mathbf{Q}_{ij}\forall(i,j)\in\Omega\). In this work we rely on nuclear norm minimization to estimate \(\mathbf{Q}\) (see Algorithm 4). Recent works have provided tight element-wise recovery guarantees for this algorithm [8; 17]. We state these guarantees in the following Lemma.

**Lemma 1** (Lemma 2 in [17]).: _Consider matrix \(\mathbf{Q}\in\mathbb{R}^{\mathsf{M}\times\mathsf{N}}\) with rank \(r\) and SVD decomposition \(\widetilde{\mathbf{U}}\boldsymbol{\Sigma}\widetilde{\mathbf{V}}^{\mathsf{T}}\) satisfying \(\|\widetilde{\mathbf{U}}\|_{2,\infty}\leq\sqrt{\mu r/\mathsf{M}},\|\widetilde{ \mathbf{V}}\|_{2,\infty}\leq\sqrt{\mu r/\mathsf{N}}\) and condition number \(\kappa=O(1)\). Let \(d_{1}=\max(\mathsf{M},\mathsf{N})\), \(d_{2}=\min(\mathsf{M},\mathsf{N})\), noise variance \(\sigma^{2}>0\), and let sampling probability \(p\) be such that \(p=\widetilde{\Omega}\Big{(}\frac{d_{2}^{2}}{\max\Big{(}1,\frac{\sigma^{2}\mu}{ \|\mathbf{P}\|^{2}}\Big{)}}\Big{)}\) (for some constant \(c>0\)). Suppose we sample a subset of indices \(\Omega\subseteq[\mathsf{M}]\times[\mathsf{N}]\) such that each tuple of indices \((i,j)\in[\mathsf{M}]\times[\mathsf{N}]\) is included in \(\Omega\) independently with probability \(p\). Let \(\{\mathbf{Z}_{ij}\}_{(i,j)\in\Omega}\) be the noisy observations corresponding to all indices in \(\Omega\). Then Algorithm 4, when run with inputs \((\mathsf{M},\mathsf{N},\sigma^{2},r,\Omega,\{\mathbf{Z}_{ij}\}_{(i,j)\in\Omega})\), returns an estimate \(\widetilde{\mathbf{Q}}\) of \(\mathbf{Q}\) which satisfies the following error bounds with probability at least \(1-O(\delta+d_{2}^{-12})\)_

\[\|\mathbf{Q}-\widetilde{\mathbf{Q}}\|_{\infty}=O\left(\frac{\sigma\sqrt{\mu^{ 3}\log d_{1}}}{\sqrt{pd_{2}}}\right).\] (3)

Lemma 1 provides guarantees on the estimate \(\widetilde{\mathbf{Q}}\) of \(\mathbf{Q}\) given the set of noisy observations corresponding to the entries in \(\Omega\). Equation 3 says that the quality of the estimate becomes better with the increase in sampling probability \(p\) that determines the number of entries in \(\Omega\). Note the detailed Algorithm Estimate (Alg. 4) designed in [17; 8] is provided in Appendix A.

**Remark 1** (Warm-up (Greedy Algorithm)).: _Using Lemma 1, it is easy to design a greedy algorithm (Alg. 5 in Appendix B) for \(\mathsf{B}=1\); for a fixed number of rounds \(m\), we recommend random unblocked items to every user. Since the reward matrix \(\mathbf{P}\) is a low-rank matrix, we use Algorithm 4 to estimate the entire matrix. Subsequently, we recommend the best estimated unblocked items for each user for the remaining rounds. We can prove that the regret suffered by such an algorithm is \(\widetilde{O}(\mathsf{T}^{2/3}(1\bigvee(\mathsf{N}/\mathsf{M}))^{1/3})\). The dependence on number of rounds \(\mathsf{T}\) is sub-optimal, but Alg. 5 does not require the knowledge of any gaps corresponding to the reward matrix \(\mathbf{P}\). See Appendix B for a detailed proof. We would like to note that the result can be generalized easily to \(\mathsf{B}=\Theta(\log\mathsf{T})\)._

## 3 Main Results

Let \(\mathbf{X}\in\mathbb{R}^{\mathsf{C}\times\mathsf{N}}\) be the sub-matrix of the expected reward matrix \(\mathbf{P}\) comprising \(\mathsf{C}\) distinct rows of \(\mathbf{P}\) corresponding to each of the \(\mathsf{C}\) true clusters. Also, let \(\tau:=\max_{i,j\in[r]}|\mathcal{C}^{(i)}|/|\mathcal{C}^{(j)}|\) denote the ratio of the maximum and minimum cluster size. To obtain regret bounds, we make the following assumptions on the matrix \(\mathbf{X}\):

**Assumption 1** (Assumptions on \(\mathbf{X}\)).: _Let \(\mathbf{X}=\mathbf{U}\boldsymbol{\Sigma}\mathbf{V}^{\mathsf{T}}\) be the SVD of \(\mathbf{X}\). Also, let \(\mathbf{X}\) satisfy the following: 1) Condition number: \(\mathbf{X}\) is full-rank and has non zero singular values \(\lambda_{1}>\cdots>\lambda_{\mathsf{C}}\) with condition number \(\lambda_{1}/\lambda_{\mathsf{C}}=O(1)\), 2) \(\mu\)-incoherence: \(\left\|\mathbf{V}\right\|_{2,\infty}\leq\sqrt{\mu\mathsf{C}/\mathsf{N}}\), 3) Subset Strong Convexity: For some \(\alpha\) satisfying \(\alpha\log\mathsf{M}=\Omega(1)\), \(\gamma=\widetilde{O}(1)\) for all subset of indices \(\mathcal{S}\subseteq[\mathsf{M}],|\mathcal{S}|\geq\gamma\mathsf{C}\), the minimum non zero singular value of \(\mathbf{V}_{\mathcal{S}}\) must be at least \(\sqrt{\alpha\left|\mathcal{S}\right|/\mathsf{M}}\)._

[MISSING_PAGE_FAIL:6]

difference in regret of at most \(\mathsf{B}\) in two separate instances constructed in standard measure change arguments [19]. However, we prove two regret lower bounds on this problem, out of which the latter is the technically more interesting one.

The first term in the lower bound in Thm. 2 follows from a simple reduction from standard multi-armed bandits. Intuitively, if we have \(\mathsf{T}/\mathsf{B}\) known identical copies of each item, then the blocking constraint is void - but with \(\mathsf{C}=1\), this is (almost) equivalent to a standard multi-armed bandit problem with \(\mathsf{MT}\) rounds, \(\mathsf{NBT}^{-1}\) distinct arms (up to normalization with \(\mathsf{M}\)). The lower bound follows from invoking standard results in MAB literature. For \(\mathsf{B}=\mathsf{T}\), we recover the matching regret lower bound in [25] without the blocking constraint. Furthermore, for \(\mathsf{B}=\Theta(\log\mathsf{T})\), the first term is tight up to log factors when number of rounds is small for example when \(\mathsf{T}=O(1)\). (Appendix E)

The second term in the lower bound is quite non-trivial. Note that the second term is tight up to log factors when the number of rounds \(\mathsf{T}=\Theta(\mathsf{N})\) is very large (close to the number of items) and \(\mathsf{B}=O(\log\mathsf{T})\) is small. We obtain this bound via reduction of the regret problem to a multiple hypothesis testing problem with exponentially many instances and applying Fano's inequality [28] (commonly used in proving statistical lower bounds in parameter estimation) for approximate recovery. Our approach might be of independent interest in other online problems as well. (Appendix E)

**Remark 4**.: _We leave the problem of extending our guarantees for \(\mathsf{B}=1\) as future work. However we make progress by assuming a cluster structure over items as well. More precisely, suppose both items and users can be grouped into a constant number of disjoint clusters as such that (user,item) pairs in same cluster have same expected reward. Then, we can sidestep the statistical dependency issues in analysis of Alg. 1 for \(\mathsf{B}=1\) and provide similar guarantees as in Thm. 1 (see Appendix F)._

## 4 \(\mathsf{B-Lattice}\) Algorithm

\(\mathsf{B-Lattice}\) is a recursive algorithm and runs in \(O(\log\mathsf{T})\) phases of exponentially increasing length. \(\mathsf{B-Lattice}\) assume the knowledge of the following quantities - users \(\mathsf{M}\), items \(\mathsf{N}\), clusters \(\mathsf{C}\), rounds \(\mathsf{T}\), blocking constraint \(\mathsf{B}\), maximum true reward \(\left\lVert\mathbf{P}\right\rVert_{\infty}\), incoherence factor \(\mu\), cluster size ratio \(\tau\), noise variance \(\sigma^{2}>0\) and other hyper-parameters in Assumption 1. At any phase, the algorithm maintains a partitioning of users into crude clusters, and a set of active items for each such crude cluster. Let \(\mathcal{M}^{(\ell)}\) be the partitioning of users in the \(\ell^{th}\) phase, and \(\mathcal{N}^{(\ell)}\) be the list containing the set of active items for each group of users in \(\mathcal{M}^{(\ell)}\). In the first phase, we place all users into a single group and keep all items active for every user; that is, \(\mathcal{M}^{(1)}=[[\mathsf{M}]]\), \(\mathcal{N}^{(1)}=[[\mathsf{N}]]\). There are three key components in each phase: (a) exploration, (b) exploitation, and (c) user clustering. In what follows, we explain these components in detail. For simplicity of exposition, suppose Assumption 2 is true namely the parameters \(\mu,\sigma,\tau,\left\lVert\mathbf{P}\right\rVert_{\infty},\mathsf{C}\) are constants.

**Exploration (Alg. 2).** The goal of the \(\mathtt{Explore}\) sub-routine is to gather enough data to obtain a better estimate of the reward matrix. To be precise, let \(\mathcal{M}^{(\ell,i)}\) be the users in the \(i^{th}\) group at phase \(\ell\), and \(\mathcal{N}^{(\ell,i)}\) be the set of active items for this group. Let \(\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\) be the sub-matrix of \(\mathbf{P}\) corresponding to rows \(\mathcal{M}^{(\ell,i)}\) and columns \(\mathcal{N}^{(\ell,i)}\) (recall, this sub-matrix has rank at most \(\mathsf{C}\)). Our goal is to get an estimate \(\widehat{\mathbf{P}}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\) of this matrix that is entry-wise \(O(2^{-\ell})\) close to the true matrix. To do this, for each user in \(\mathcal{M}^{(\ell,i)}\), we randomly recommend items from \(\mathcal{N}^{(\ell,i)}\) with probability \(p=O\Big{(}\frac{2^{2\ell}\log d_{1}}{d_{2}}\Big{)}\) (Line 6). Here, \(d_{1}=\max(|\mathcal{M}^{(\ell,i)}|,|\mathcal{N}^{(\ell,i)}|)\), \(d_{2}=\min(|\mathcal{M}^{(\ell,i)}|,|\mathcal{N}^{(\ell,i)}|)\). We then rely on low-rank matrix completion algorithm (Algorithm 4) to estimate the low rank sub-matrix. By relying on Lemma 1, we show that our estimate is entry-wise \(O(2^{-\ell})\) accurate. This also shows that our algorithm gets more accurate estimate of \(\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\) as we go to the later phases.

**User Clustering (lines 7-8 of Alg. 1).** After the _exploration_ phase, we refine the user partition to make it more fine-grained. An important property we always want to ensure in our algorithm is that \(\mathcal{M}^{(\ell,i)}\), the \(i^{th}\) group/crude cluster in phase \(\ell\), is a _nice_ subset for all \((\ell,i)\) (see Definition 1 for a definition of nice subset). To this end, we build a user-similarity graph whose nodes are users in \(\mathcal{M}^{(\ell,i)}\), and draw an edge between two users if they have similar rewards for all the arms in \(\mathcal{N}^{(\ell,i)}\) (Line 8 in Alg. 1). Next, we partition \(\mathcal{M}^{(\ell,i)}\) based on the connected components of the graph. That is, we group all the users in a connected component into a single cluster. In our analysis, we show that each connected component of the graph is a _nice subset_.

**Exploitation (Alg. 3).** The main goal in the Exploit sub-routine of our algorithm is to identify common golden items for a group of users jointly. Consider a group of users \(\mathcal{M}\) with active items \(\mathcal{N}\) at the beginning of _exploit_ sub-routine invoked in the \(\ell^{\text{th}}\) phase of Algorithm 1. We perform the following test in Line 1 of the Exploit sub-routine: for every user \(u\in\mathcal{M}\), we check if \(\widetilde{\mathbf{P}}_{u\widetilde{w}_{u}(1)|\mathcal{N}}-\widetilde{\mathbf{P }}_{u\widetilde{w}_{u}(|\mathcal{N}|)|\mathcal{N}}\geq c^{\prime}2^{-\ell}\) for some constant \(c^{\prime}>0\) - that is if the estimated highest rewarding and lowest rewarding items of the user \(u\) have a significant gap. For all the users that satisfy the above property, we take a union of the items close to the estimated highest rewarding item for each of them (Line 3). We can show that these identified items are actually golden items for all users in the nice subset \(\mathcal{M}\). Hence, we immediately recommend these identified golden items to every user in the nice subset \(\mathcal{B}\) times. In case a golden item is blocked for a user, we recommend an unblocked active item (Line 5). Subsequently we remove the golden items from the active set of items (Line 8) and prune it. We go on repeating the process with the pruned set of items until we can find no user that satisfy the above gap property between highest and lowest estimated rewarding items in the active set.

To summarize, in each phase of Algorithm 1, we perform the exploration, exploitation and user clustering steps described above. As the algorithm proceeds, we get more fine grained clustering of users, and more accurate estimates of the rewards of active items. Using this information, the algorithm tries to identify golden items and recommends the identified golden items to users.

**Implementation Details:** The actual implementation of the algorithm described above is a bit more involved due to the fact that every user has to be recommended an item at every time step (seeproblem setting in Section 2). To see this, consider the following scenario. Suppose, we identified item \(j\) as a golden item for users in the nice subset \(\mathcal{M}\) (crude cluster) in the Exploit sub-routine invoked in some phase of Alg. 1. Moreover, suppose there are two users \(u_{1},u_{2}\) in the cluster for whom the item has been recommended \(n_{1},n_{2}\) times respectively, for some \(n_{1}<n_{2}\). So, for the final \(n_{2}-n_{1}\) iterations during which the algorithm recommends item \(j\) to \(u_{1}\), it has to recommend some other item to \(u_{2}\). In our algorithm, we randomly recommend an item from the remaining active set of items for \(u_{2}\) during those \(n_{2}-n_{1}\) rounds. We store the rewards from these recommendations and use them in the exploration component of future phases. A similar phenomenon also occurs in the _Explore_ sub-routine where we sometimes need to recommend items outside the sub-sampled set of entries in \(\Omega\) (Line 7 and 10 in Alg. 2) To this end, we introduce matrices \(\mathbf{K},\mathbf{L}\in\mathbb{R}^{\mathbb{M}\times\mathbb{N}}\) which perform the necessary book-keeping for us.

\(\mathbf{K}\) tracks number of times an item has been recommended to a user and the corresponding observation has been already used in computing an estimate of some reward sub-matrix (Line 2 of Alg. 2). Since these estimates are used to cluster users and eliminate items (Lines 7-10 in Alg. 1), these observations are not reused in subsequent phases to avoid statistical dependencies. \(\mathbf{L}\) tracks the number of times an item has been recommended to a user and the corresponding observation has not been used in computing an estimate of reward sub-matrix so far. These observations can still be used once in Line 2 of Alg. 2. Observe that \(\mathbf{K}_{ij}+\mathbf{L}_{ij}\) is the total times user \(i\) has been recommended item \(j\). In practice, eliminating observations is unnecessary and we can reuse observations whenever required. Hence Alg. 1 can work even when \(\mathsf{B}=1\) (see Alg. 6 for a simplified and practical version).

**Handling very few active items (Line 5 in Alg. 1).** Recall, in the exploration step of phase \(\ell\), we randomly recommend active items with probability \(p=O\Big{(}\frac{2^{2\ell}\log d_{1}}{d_{2}}\Big{)}\). If \(p>1\), then we simply recommend all the remaining unblocked items for each user until the end. In our analysis, we can show that this happens only if the size of surviving items is too small, and when the number of remaining rounds is very small. Hence the regret is small if we follow this approach (Lemma 5). Similarly, when remaining rounds become smaller than \(\mathsf{T}^{1/3}\), we follow the same approach.

**Running Time:** Computationally speaking, the main bottleneck of our algorithm is the matrix completion function _Estimate_ invoked in Line 13 of the Explore Component (Algorithm 2). All the remaining steps have lower order run-times. Note that the _Estimate_ function is invoked at most \(O(\mathsf{C}\log\mathsf{T})\) times since there are can be at most \(\mathsf{C}\) disjoint nice subsets of users at a time and the number of phases is \(\log\mathsf{T}\). Moreover, note that the _Estimate_ function (Algorithm 4) solves a convex objective in Line 3 - this has a time complexity of \(O(\mathsf{M}^{2}\mathsf{N}+\mathsf{N}^{2}\mathsf{M})\) which is slightly limiting because of the quadratic dependence. However, a number of highly efficient techniques have been proposed for optimizing the aforementioned objective even when \(\mathsf{M}\), \(\mathsf{N}\) are in the order of millions (see [14]).

```
0: Phase index \(\ell\), nice subset of users \(\mathcal{M}\), active items \(\mathcal{N}\), round index \(t_{0}\), exploit rounds \(t_{\text{\tt{e}p}{\text{\tt{e}p}}}\), estimate \(\widetilde{\mathbf{P}}\) of \(\mathbf{P}\) and error guarantee \(\Delta_{\ell}\) such that \(\left|\widetilde{\mathbf{P}}_{\mathcal{M},\mathcal{N}}-\mathbf{P}_{\mathcal{ M},\mathcal{N}}\right|\right|_{\infty}\leq 8\mathsf{C}\Delta_{\ell}\) with high probability. //Takes a particular set of users (nice w.h.p.), their corresponding set of active items and an estimate of corresponding reward sub-matrix as input. Identifies common golden items for all aforementioned users in this module and recommends them jointly until exhausted - recommendations are kept track of in global variables \(\mathbf{K},\mathbf{L}\) and active items are pruned.
1:while there exists \(u\in\mathcal{M}\) such that \(\widetilde{\mathbf{P}}_{u\#_{u}(1)|\mathcal{N}}-\widetilde{\mathbf{P}}_{u\#_ {u}(1)|\mathcal{N}}\geq 64\mathsf{C}\Delta_{\ell}\)do
2: Compute \(\mathcal{R}_{u}=\{j\in\mathcal{N}\mid\widetilde{\mathbf{P}}_{u\geq\widetilde{ \mathbf{P}}_{u\#_{u}(1)|\mathcal{N}}}-2\Delta_{\ell+1}\}\) for every user \(u\in\mathcal{M}\). Compute \(\mathcal{S}=\cup_{u\in\mathcal{M}}\mathcal{R}_{u}\). // Find common set of golden items for all users in \(\mathcal{M}\)
3:for rounds \(t=t_{0}+1,t_{0}+2,\ldots,t_{0}+|\mathcal{S}|\mathsf{B}\)do
4:for each user \(u\in\mathcal{M}\)do
5: Denote by \(x\leftarrow\left[(t-t_{0}/\mathsf{B})\right]\) item in \(\mathcal{S}\). If \(\mathbf{K}_{ux}+\mathbf{L}_{ux}<\mathsf{B}\) (\(x\) is unblocked), then recommend \(x\) to user \(u\) and update \(\mathbf{L}_{ux}\leftarrow\mathbf{L}_{ux}+1\). If \(\mathbf{K}_{ux}+\mathbf{L}_{ux}=\mathsf{B}\) (\(x\) is blocked), recommend any unblocked item \(y\) in \(\mathcal{N}\) (i.e \(\mathbf{K}_{uy}+\mathbf{L}_{uy}<\mathsf{B}\)) for the user \(u\) and update \(\mathbf{L}_{uy}\leftarrow\mathbf{L}_{uy}+1\). // Recommend all identified golden items
6:endfor
7:endfor
8: Update \(\mathcal{N}\leftarrow\mathcal{N}\setminus\mathcal{S}\). // Remove golden items and prune active items \(\mathcal{N}\)
9: Update \(t_{0}\gets t_{0}+|\mathcal{S}|\,\mathsf{B}\) and \(t_{\text{e}p}{\text{\tt{e}p}}\gets t_{\text{e}p}+|\mathcal{S}|\,\mathsf{B}\).
10:endwhile
11: Return \(\mathcal{N},t_{0},t_{\text{e}p}\). ```

**Algorithm 3** Exploit (Exploit Component of a phase)

**Proof Sketch of Theorem 1** We condition on the high probability event that the low rank matrix completion estimation step is always successful (Lemma 17). Note that for a fixed user, the items chosen for recommendation in the _exploit_ component of any phase are _golden items_ and costs zero regret if they are unblocked and recommended. Even if it is blocked, we show a swapping argument to a similar effect. That is, with an appropriate permutation of the recommended items, we can ignore the regret incurred from golden-items altogether. Moreover, in the _explore_ component of the \(\ell^{\text{th}}\) phase, we can bound the sub-optimality gap of the surviving active items by some pre-determined \(\epsilon_{\ell}\). We prove that this holds even with the (chosen) permutation of the recommended items (Lemma 18). We choose \(\epsilon_{\ell}\) to be exponentially decreasing in \(\ell\) and the number of rounds in the _explore_ component of phase \(\ell\) is roughly \(1/\epsilon_{\ell}^{2}\). Putting these together, we obtain the regret guarantee in Theorem 1.

## 5 Conclusion and Future Work

We study the problem of Collaborative Bandits in the setting where each item can be recommended to a user a small number of times. Under some standard assumptions and a blocking constraint of \(\Theta(\log\mathsf{T})\), we show a phased algorithm \(\textsc{B-LATTICE}\) with regret guarantees that match the tight results with no blocking constraint [25]. To the best of our knowledge, this is the first regret guarantee for such a general problem with no assumption of item clusters. We also provide novel regret lower bounds that match the upper bound in several regimes. Relaxing the assumptions, extending guarantees to a blocking constraint of \(\mathsf{B}=1\) and tightening the gap between the regret upper and lower bounds are very interesting directions for future work.

## Acknowledgements

We would like to thank Sandeep Juneja for helpful discussions on understanding the information theoretic limits of the problem.

## References

* [1] Charu C Aggarwal et al. _Recommender systems_, volume 1. Springer, 2016.
* [2] Kaito Ariu, Narae Ryu, Se-Young Yun, and Alexandre Proutiere. Regret in online recommendation systems. _Advances in Neural Information Processing Systems_, 33:21141-21150, 2020.
* [3] Kishor Barman and Onkar Dabeer. Analysis of a collaborative filter based on popularity amongst neighbors. _IEEE Transactions on Information Theory_, 58(12):7110-7134, 2012.
* Volume 2_, NIPS'14, pages 3347-3355, 2014.
* [5] Guy Bresler and Mina Karzand. Regret bounds and regimes of optimality for user-user and item-item collaborative filtering. In _2018 Information Theory and Applications Workshop (ITA)_, pages 1-37. IEEE, 2018.
* [6] Guy Bresler and Mina Karzand. Regret bounds and regimes of optimality for user-user and item-item collaborative filtering. _IEEE Transactions on Information Theory_, 67(6):4197-4222, 2021.
* [7] Guy Bresler, Devavrat Shah, and Luis Filipe Voloch. Collaborative filtering with low regret. In _Proceedings of the 2016 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Science_, SIGMETRICS '16, pages 207-220, New York, NY, USA, 2016. ACM.
* [8] Yuxin Chen, Yuejie Chi, Jianqing Fan, Cong Ma, and Yuling Yan. Noisy matrix completion: Understanding statistical guarantees for convex relaxation via nonconvex optimization. _arXiv preprint arXiv:1902.07698_, 2019.
* [9] Onkar Dabeer. Adaptive collaborating filtering: The low noise regime. In _2013 IEEE International Symposium on Information Theory_, pages 1197-1201. IEEE, 2013.
* [10] Claudio Gentile, Shuai Li, Purushottam Kar, Alexandros Karatzoglou, Giovanni Zappella, and Evans Etrue. On context-dependent clustering of bandits. In _International Conference on Machine Learning_, pages 1253-1262. PMLR, 2017.
* [11] Claudio Gentile, Shuai Li, and Giovanni Zappella. Online clustering of bandits. In _International Conference on Machine Learning_, pages 757-765. PMLR, 2014.
* [12] Dorota Glowacka et al. Bandit algorithms in information retrieval. _Foundations and Trends(r) in Information Retrieval_, 13(4):299-424, 2019.
* [13] Reinhard Heckel and Kannan Ramchandran. The sample complexity of online one-class collaborative filtering. In _International Conference on Machine Learning_, pages 1452-1460. PMLR, 2017.
* [14] Cho-Jui Hsieh and Peder Olsen. Nuclear norm minimization via active subspace selection. In _International Conference on Machine Learning_, pages 575-583. PMLR, 2014.
* [15] Wasim Huleihel, Soumyabrata Pal, and Ofer Shayevitz. Learning user preferences in non-stationary environments. In _International Conference on Artificial Intelligence and Statistics_, pages 1432-1440. PMLR, 2021.
* [16] Prateek Jain, Praneeth Netrapalli, and Sujay Sanghavi. Low-rank matrix completion using alternating minimization. In _Proceedings of the forty-fifth annual ACM symposium on Theory of computing_, pages 665-674, 2013.

* [17] Prateek Jain and Soumyabrata Pal. Online low rank matrix completion. _arXiv preprint arXiv:2209.03997_, 2022.
* [18] Vladimir Koltchinskii, Karim Lounici, and Alexandre B Tsybakov. Nuclear-norm penalization and optimal rates for noisy low-rank matrix completion. 2011.
* [19] Tor Lattimore and Csaba Szepesvari. _Bandit algorithms_. Cambridge University Press, 2020.
* [20] Shuai Li, Wei Chen, and Kwong-Sak Leung. Improved algorithm on online clustering of bandits. _arXiv preprint arXiv:1902.09162_, 2019.
* [21] Shuai Li, Alexandros Karatzoglou, and Claudio Gentile. Collaborative filtering bandits. In _Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval_, pages 539-548, 2016.
* [22] Greg Linden, Brent Smith, and Jeremy York. Amazon. com recommendations: Item-to-item collaborative filtering. _IEEE Internet computing_, 7(1):76-80, 2003.
* [23] Gregory D Linden, Jennifer A Jacobi, and Eric A Benson. Collaborative recommendations using item-to-item similarity mappings, July 24 2001. US Patent 6,266,649.
* [24] Odalric-Ambrym Maillard and Shie Mannor. Latent bandits. In _International Conference on Machine Learning_, pages 136-144. PMLR, 2014.
* [25] Soumyabrata Pal, Arun Sai Suggala, Karthikeyan Shanmugam, and Prateek Jain. Optimal algorithms for latent bandits with cluster structure. _arXiv preprint arXiv:2301.07040_, 2023.
* [26] Yunzhe Qi, Tianxin Wei, Jingrui He, et al. Neural collaborative filtering bandits via meta learning. _arXiv preprint arXiv:2201.13395_, 2022.
* [27] Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. Item-based collaborative filtering recommendation algorithms. In _Proceedings of the 10th international conference on World Wide Web_, pages 285-295, 2001.
* [28] Jonathan Scarlett and Volkan Cevher. An introductory guide to fano's inequality with applications in statistical estimation. _arXiv preprint arXiv:1901.00555_, 2019.
* [29] Devavrat Shah and Kang Zhang. Bayesian regression and bitcoin. In _2014 52nd annual Allerton conference on communication, control, and computing (Allerton)_, pages 409-414. IEEE, 2014.

**Limitations:** The main contributions of our works are theoretical. From a theoretical point of view, the limitations of our paper are discussed in Sections 3 and 5. In particular, we believe that tightening the gap between the upper and lower bounds in regret will require novel and non-trivial algorithmic ideas - we leave this as an important direction of future work.

**Broader Impact:** Due to the theoretical nature of the work, we do not foresee any adverse societal impact.

## Appendix A Low rank matrix completion

Below, we describe the Estimate sub-routine to estimate a \(\mathsf{M}\times\mathsf{N}\) low rank matrix \(\mathbf{Q}\) of rank \(r\) given a partially observed set of noisy entries \(\{\mathbf{Z}_{ij}\}_{(i,j)\in\Omega}\) corresponding to a subset \(\Omega\subseteq[\mathsf{M}]\times[\mathsf{N}]\). Here \(\mathbb{E}\mathbf{Z}_{ij}=\mathbf{Q}_{ij}\) for all \((i,j)\in\Omega\) and furthermore, \(\{\mathbf{Z}_{ij}\}_{(i,j)\in\Omega}\) are independent sub-gaussian random variables with variance proxy at most \(\sigma^{2}\).

```
0: Matrix dimensions \((\mathsf{M},\mathsf{N})\), noise variance \(\sigma^{2}\), rank \(r\), subset of indices that are observed \(\Omega\subseteq[\mathsf{M}]\times[\mathsf{N}]\) and noisy observations \(\{\mathbf{Z}_{ij}\}_{(i,j)\in\Omega}\).
1: Partition the rectangular matrix into square matrices. Without loss of generality, assume \(\mathsf{M}\leq\mathsf{N}\). For each \(i\in[\mathsf{N}]\), randomly set \(\zeta_{i}\) to be a value in the set \([[\mathsf{N}/\mathsf{M}]]\) uniformly at random. Partition indices in \([\mathsf{N}]\) into \([\mathsf{N}]^{(1)},[\mathsf{N}^{(2)},\dots,[\mathsf{N}]^{(k)}\) where \(k=[\mathsf{N}/\mathsf{M}]\) and \([\mathsf{N}]^{(q)}=\{i\in[\mathsf{N}]\mid\zeta_{i}=q\}\) for each \(q\in[k]\). Set \(\Omega^{(q)}\leftarrow\Omega\cap([\mathsf{M}]\times[\mathsf{N}]^{(q)})\) for all \(q\in[k]\). {If \(\mathsf{M}\geq\mathsf{N}\), we partition the indices in \([\mathsf{M}]\).}
2:for\(q\in[k]\)do
3: Solve the following convex program with \(\lambda=C_{\lambda}\sigma\sqrt{|\Omega|\,/\max(\mathsf{M},\mathsf{N})}\), for some constant \(C_{\lambda}>0\) \[\min_{\widetilde{\mathbf{Q}}^{(q)}\in\mathbb{R}^{\mathsf{M}\times[\mathsf{N}] ^{(q)}}}\sum_{(i,j)\in\Omega^{(q)}}\frac{(\widetilde{\mathbf{Q}}^{(q)}_{i}( \widetilde{\mathbf{Q}}^{(q)}_{i})-\mathbf{Z}_{ij})^{2}}{2}+\lambda\|\widetilde {\mathbf{Q}}^{(q)}\|_{\star}\] where \(\|\widetilde{\mathbf{Q}}^{(q)}\|_{\star}\) denotes nuclear norm of matrix \(\widetilde{\mathbf{Q}}^{(q)}\) and \(\gamma_{\mathrm{u}}(j)\) is index of \(j\) in set \([\mathsf{N}]^{(q)}\).
4:endfor
5: Return \(\widetilde{\mathbf{Q}}\in\mathbb{R}^{\mathsf{M}\times\mathsf{N}}\) such that \(\widetilde{\mathbf{Q}}_{[\mathsf{M}],[\mathsf{N}^{(q)}}=\widetilde{\mathbf{Q} }^{(q)}\) for all \(q\in[k]\). ```

**Algorithm 4**Estimate (Low-rank matrix completion ) [17]

## Appendix B Explore-Then-Commit (ETC)

We first present a greedy algorithm in the blocked setting with \(\mathsf{B}=1\) (no repetition) that uses the Explore-Then-Commit (ETC) framework. Such an algorithm has two disjoint phases - _exploration and exploitation_. We will first jointly explore the set of items (without repeating same item for any user) for all users for a certain number of rounds and compute an estimate \(\widetilde{\mathbf{P}}\) of the reward matrix \(\mathbf{P}\). Subsequently, in the exploitation phase, for each user, we recommend the best estimated distinct items (that have not been recommended in the exploration phase to that user) inferred from the estimated reward matrix \(\widetilde{\mathbf{P}}\). Note that if we explore too less, then our estimate will be poor and hence we will suffer large regret once we commit in the exploitation phase. On the other hand, if we explore too much, then the exploration cost will be high. Our goal is to balance both the exploration length and the exploitation cost under the blocked setting. Thus, we obtain the following result:

**Theorem 3**.: _Consider the GBB setting with \(\mathsf{M}\) users, \(\mathsf{C}=O(1)\) clusters, \(\mathsf{N}\) items, \(\mathsf{T}\) recommendation rounds and blocking constraint \(\mathsf{B}=1\). Set \(d_{2}=\min(\mathsf{M},\mathsf{N})\). Let \(\mathbf{R}^{(t)}_{u\rho_{u}(t)}\) be the reward in each round, defined as in (1). Suppose \(d_{2}=\Omega(\mu r\log(rd_{2}))\). Let \(\mathbf{P}\in\mathbb{R}^{\mathsf{M}\times\mathsf{N}}\) be the expected reward matrix that satisfies the conditions stated in Lemma 1, and let \(\sigma^{2}\) be the noise variance in rewards. Then, Algorithm 5, applied to the online rank-\(r\) matrix completion problem under the blocked setting guarantees the regret defined as in eq. 2 to be:_

\[\mathsf{Reg}(\mathsf{T})=\widetilde{O}\Big{(}\mu\mathsf{T}^{2/3}||\mathbf{P} ||^{1/3}_{\infty}\max\Big{(}1,\frac{\mathsf{N}}{\mathsf{M}}\Big{)}^{1/3}+ \mu^{2}||\mathbf{P}||_{\infty}\max\Big{(}1,\frac{\mathsf{N}}{\mathsf{M}} \Big{)}+||\mathbf{P}||_{\infty}\mathsf{T}^{-2}\Big{)}.\] (6)

In order to understand the result, note that the second term in the regret bound stems from the fact that in our algorithmic framework, the low rank matrix completion module needs a certain number ofobserved indices and therefore a certain number of exploration rounds (note that \(p\geq C\mu^{2}d_{2}^{-1}\log^{3}d_{2}\) for some constant \(C>0\) in Lemma 1). Similarly, the third term stems from the failure of the estimation module; again, the term \(\mathsf{T}^{-2}\) can be replaced by \(\mathsf{T}^{-c}\) for any constant \(c>0\). The first term in the regret bound captures the dependence on the number of rounds \(\mathsf{T}\) - the scaling of \(\mathsf{T}^{2/3}\) is sub-optimal and our subsequent goal is to improve this dependence to the rate of \(\sqrt{\mathsf{T}}\).

Proof of Theorem 3.: Suppose we explore for a period of \(\mathsf{S}\) rounds such that the exploration period succeeds with a probability of \(1-\nu\). Conditioned on the event that the exploration period succeeds, we obtain an estimate \(\widetilde{\mathbf{P}}\) of the reward matrix \(\mathbf{P}\) satisfying \(\|\mathbf{P}-\widetilde{\mathbf{P}}\|_{\infty}\leq\rho\). Recall \(\pi_{u}:[\mathsf{N}]\to[\mathsf{N}]\) to be the permutation on \([\mathsf{N}]\) such that for any \(i,j\in[\mathsf{N}];i<j\), we have \(\mathbf{P}_{u\pi_{u}(i)}\geq\mathbf{P}_{u\pi_{u}(j)}\). Similarly, denote \(\widetilde{\pi}_{u}:[\mathsf{N}]\to[\mathsf{N}]\) such that for for any \(i,j\in[\mathsf{N}];i<j\), we have \(\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(i)}\geq\widetilde{\mathbf{P}}_{ u\widetilde{\pi}_{u}(j)}\). Now consider any index \(i\in[\mathsf{T}]\) for which we will analyze \(\mathbf{P}_{u\widetilde{\pi}_{u}(i)}-\mathbf{P}_{u\pi_{u}(i)}\) which is the error if we choose the \(i^{\text{th}}\) item according to the estimated matrix \(\widetilde{\mathbf{P}}\) (instead of \(\mathbf{P}\)). There are several cases that we need to consider. First, suppose \(\widetilde{\pi}_{u}(i)=\pi_{u}(j)\) where \(j\leq i\). In that case, we have \(\mathbf{P}_{u\widetilde{\pi}_{u}(i)}-\mathbf{P}_{u\pi_{u}(i)}\geq 0\). Now, consider the other case where \(j>i\) implying that the element in the \(j^{\text{th}}\) position in the permutation \(\pi_{u}\) has shifted to the left in \(\widetilde{\pi}_{u}\). In order for this to happen, there must exist an element \(i_{1}\leq i\leq i_{2}\) for which \(\widetilde{\pi}_{u}(i_{2})=\pi_{u}(i_{1})\) implying that an element \(i_{1}\) in the permutation \(\pi_{u}\) has shifted to the right in \(\widetilde{\pi}_{u}\). Therefore,

\[\mathbf{P}_{u\widetilde{\pi}_{u}(i)}-\mathbf{P}_{u\pi_{u}(i)} =\mathbf{P}_{u\widetilde{\pi}_{u}(i)}-\widetilde{\mathbf{P}}_{u \widetilde{\pi}_{u}(i)}+\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(i)}- \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(i_{2})}\] \[+\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(i_{2})}-\mathbf{P} _{u\widetilde{\pi}_{u}(i_{2})}+\mathbf{P}_{u\widetilde{\pi}_{u}(i_{2})}- \mathbf{P}_{u\pi_{u}(i)}\geq-2\rho\]

where we used the fact that \(\|\mathbf{P}-\widetilde{\mathbf{P}}\|_{\infty}\leq\rho\), \(\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(i)}-\widetilde{\mathbf{P}}_{u \widetilde{\pi}_{u}(i_{2})}\geq 0\) (since \(i\leq i_{2}\)), \(\mathbf{P}_{u\widetilde{\pi}_{u}(i_{2})}-\mathbf{P}_{u\pi_{u}(i)}=\mathbf{P}_ {u\pi_{u}(i_{1})}-\mathbf{P}_{u\pi_{u}(i)}\geq 0\) (since \(i_{1}\leq i\)). Therefore, at each step of the exploitation stage, for each user \(u\), we recommend one of the top \(\mathsf{T}-\mathsf{S}\) items (as inferred from \(\widetilde{\mathbf{P}}\)) with the highest reward that have not been recommended until that round to the user \(u\); in each such step, we will suffer a regret of at most \(2\rho\) if we compare with the item at the same index in \(\pi_{u}\). As before, conditioned on the event that the exploration fails (and in the exploration stage as well), the regret at each step can be bounded from above by \(2\|\mathbf{P}\|_{\infty}\). In that case, we have

\[\mathsf{Reg}_{\Pi}(\mathsf{T}) =\frac{1}{\mathsf{M}}\sum_{u\in[\mathsf{M}]}\sum_{t\in[\mathsf{T}]} \mathbf{P}_{u\pi_{u}(t)}-\sum_{t\in[\mathsf{T}]}\mathbf{P}_{u\rho_{u}(t)}\leq \max_{u\in[\mathsf{M}]}\Big{(}\sum_{t\in[\mathsf{T}]}\mathbf{P}_{u\pi_{u}(t)}- \sum_{t\in[\mathsf{T}]}\mathbf{P}_{u\widetilde{\pi}_{u}(t)}\Big{)}\] \[\leq 25\|\mathbf{P}\|_{\infty}+2(\mathsf{T}-\mathsf{S})\rho\Pr( \text{Exploration succeeds})+2(\mathsf{T}-\mathsf{S})\|\mathbf{P}\|_{\infty}\Pr( \text{Exploration fails})\] \[\leq 25\|\mathbf{P}\|_{\infty}+2\mathsf{T}\rho+2\mathsf{T}\delta\| \mathbf{P}\|_{\infty}.\]

We use Lemma 1 to set \(\mathsf{S}=O\Big{(}\mathsf{N}p+\sqrt{\mathsf{N}p\log\mathsf{M}\delta^{-1}} \Big{)}\) such that \(\rho=O\Big{(}\frac{\sigma r}{\sqrt{d_{2}}}\sqrt{\frac{\mu^{3}\log d_{2}}{p}} \Big{)}\) and \(\nu=1-\delta-O(d_{2}^{-3})\). We have

\[\mathsf{Reg}(\mathsf{T})\leq O\Big{(}\mathsf{N}p+\sqrt{\mathsf{N}p\log \mathsf{M}\delta^{-1}}\Big{)}\|\mathbf{P}\|_{\infty}+\mathsf{T}O\Big{(}\frac{ \sigma r}{\sqrt{d_{2}}}\sqrt{\frac{\mu^{3}\log d_{2}}{p}}\Big{)}+\mathsf{T}( \delta+d_{2}^{-3})\|\mathbf{P}\|_{\infty}.\]

For simplicity, we ignore the logarithmic and lower order terms and attempt to minimize \(\mathsf{N}p\|\mathbf{P}\|_{\infty}+\mathsf{T}\Big{(}\frac{\sigma r}{\sqrt{d_{ 2}}}\sqrt{\frac{\mu^{3}\log d_{2}}{p}}\Big{)}\) (_Simplified Expression_) by choosing \(p=(\mathsf{N}\|\mathbf{P}\|_{\infty})^{-2/3}\Big{(}\frac{\mathsf{T}\sigma r}{ \sqrt{d_{2}}}\sqrt{\mu^{3}\log d_{1}}\Big{)}^{2/3}\), \(\delta=\mathsf{T}^{-4}\). If \(p\geq C\mu^{2}d_{2}^{-1}\log^{3}d_{2}\), then notice that \(\mathsf{N}p\geq 1\) and therefore \(\mathsf{N}p+\sqrt{\mathsf{N}p\log\mathsf{M}\delta^{-1}}=O(\mathsf{N}p\sqrt{ \log\mathsf{M}\delta^{-1}})\). Subsequently, we have

\[\mathsf{Reg}(\mathsf{T})=O\Big{(}\mathsf{T}^{2/3}(\sigma^{2}r^{2}\|\mathbf{P} \|_{\infty})^{1/3}\Big{(}\frac{\mu^{3}\mathsf{N}\log d_{2}}{d_{2}}\Big{)}^{1/ 3}\log\sqrt{\mathsf{MT}}+\|\mathbf{P}\|_{\infty}\mathsf{T}^{-2}\Big{)}.\]

There exists an edge case when the value of \(p\) that minimizes the _simplified expression_ satisfies \(p\leq C\mu^{2}d_{2}^{-1}\log^{3}d_{2}\). Then we can substitute \(p=C\mu^{2}d_{2}^{-1}\log^{3}d_{2}\). In that case, the second term in the _simplified expression_ will still be bounded as before. On the other hand the first term in the _simplified expression_ will now be bounded by \(O(\frac{\mathsf{N}\mu^{2}}{d_{2}}\log^{3}d_{2}\log^{2}(\mathsf{MNT})||\mathbf{ P}||_{\infty})\). Hence, our regret will be bounded by

\[\mathsf{Reg}(\mathsf{T}) =O\Big{(}\mathsf{T}^{2/3}(\sigma^{2}r^{2}\|\mathbf{P}\|_{\infty} )^{1/3}\Big{(}\frac{\mu^{3}\mathsf{N}\log d_{2}}{d_{2}}\Big{)}^{1/3}\log\sqrt{ \mathsf{MT}}+\frac{\mathsf{N}\mu^{2}}{d_{2}}\log^{5}(\mathsf{MNT})||\mathbf{P} ||_{\infty}+\|\mathbf{P}\|_{\infty}\mathsf{T}^{-2}\Big{)}\] \[=\widetilde{O}\Big{(}\mu\mathsf{T}^{2/3}||\mathbf{P}||_{\infty}^{ 1/3}\max\Big{(}1,\frac{\mathsf{N}}{\mathsf{M}}\Big{)}^{1/3}+\mu^{2}||\mathbf{ P}||_{\infty}\max\Big{(}1,\frac{\mathsf{N}}{\mathsf{M}}\Big{)}+|| \mathbf{P}||_{\infty}\mathsf{T}^{-2}\Big{)}.\]

## Appendix C Experiments

We conduct detailed synthetic experiments in order to validate the theoretical guarantees/properties of our algorithm. For this purpose we use a simplified version of B-LATTICE described in Alg. 6 (all experiments have been performed on a Google Colab instance with 12GB RAM) :

In PB-LATTICE(Alg. 6), we do not use the _exploit_ component for simplicity. Intuitively, if the user is recommended a _golden item_ during the _explore_ component, it is a good event in any case. Furthermore, in Step 14, we use \(k\)-means to cluster the users. Since we obtain a significantly large embedding vector for each user in Step 13, \(k-\)means is quite practical.

We run PB-LATTICEon several synthetic datasets. There are two main baselines for us to consider 1) Greedy Algorithm namely Alg. 5 2) In the setting where the user \(u\), on being recommended item \(j\) provides a like (\(+1\)) with probablity \(\mathbf{P}_{uj}\) and a dislike (\(-1\)) with probability \(1-\mathbf{P}_{uj}\), we also compare with _Collaborative-Greedy_ in [4]. However, recall that [4], even in the restricted setting, only provides theoretical guarantees on the number of likeable items (items with probability of liking \(>0.5\)) recommended during the course of \(\mathsf{T}\) rounds.

We generate three synthetic datasets to validate our algorithms. For each of them, we take \(\mathsf{M}=150\) users, \(\mathsf{N}=150\) items and \(\mathsf{T}=60\) rounds (hence the total items recommended will be \(9000\)). The reward matrix \(\mathbf{P}=\mathbf{U}\mathbf{V}^{\mathsf{T}}\) (\(\mathbf{U}\in\mathbb{R}^{\mathsf{M}\times\mathsf{C}}\) and \(\mathbf{V}\in\mathbb{R}^{\mathsf{N}\times\mathsf{C}}\)) is generated as in [25] - in the \(i^{\text{th}}\) row of \(\mathbf{U}\), the \((i\%\mathsf{C})^{\text{th}}\) entry is set to be \(1\) while the other entries are \(0\); the entries of \(\mathbf{V}\) are sampled in the following way for the three datasets.

Figure 1: Cumulative Regret of the greedy algorithm (Alg. 5) and the Blocked LATTICE algorithm (simplified version in Alg. 6). In the setting where our observations are in \(\{+1,-1\}\) i.e. the user likes (\(+1\)) an item with probability \(p\) and dislikes with probability \(1-p\), we also compare with the algorithm provided in [4] named Collaborative-Greedy. In all our settings, we have \(\mathsf{M}=150\) users, \(\mathsf{N}=150\) items, \(\mathsf{C}=4\) clusters and \(\mathsf{T}=60\) rounds. The ground truth reward matrix \(\mathbf{P}=\mathbf{U}\mathbf{V}^{\mathsf{T}}\) is generated in the following way: each row of \(\mathbf{U}\) is a standard basis vector while each entry of \(\mathbf{V}\) is sampled independently from \(\mathcal{N}(0,25)\) in (a), each entry of \(\mathbf{V}\) is sampled independently from \(\mathcal{U}(0,5)\) in (b) and each entry of \(\mathbf{U}\) is sampled independently from \(\mathcal{U}(0,1)\) in (c). In (a) and (b), gaussian noise with variance \(0.25\) is added to the expected observation and in (c), we observe +1 (probability is expected reward) or -1. Notice that PB-LATTICE has 1) a small cold-start period 2) always makes good recommendations 3) better empirical rewards than other baselines.

1. (_D1:_) Each entry of \(\mathbf{V}\) is sampled from a gaussian distribution \(\mathcal{N}(0,25)\) with mean zero and variance \(25\). User \(u\) on being recommended item \(j\) provides a random feedback distributed according to \(\mathcal{N}(\mathbf{P}_{uj},0.25)\).
2. (_D2:_) Each entry of \(\mathbf{V}\) is sampled from a uniform distribution \(\mathcal{U}(0,5)\) with range in \([0,5]\). User \(u\) on being recommended item \(j\) provides a random feedback distributed according to \(\mathcal{N}(\mathbf{P}_{uj},0.25)\).
3. (_D3:_) Each entry of \(\mathbf{V}\) is sampled from a uniform distribution \([0.05,0.95]\) with equal probability. User \(u\) on being recommended item \(j\) provides a like \((+1)\) with probability \(\mathbf{P}_{uj}\) and a dislike \((-1)\) with probability \(1-\mathbf{P}_{uj}\).

For the PB-LATTICEalgorithm (Alg. 6), we choose the hyper-parameters on the phase lengths and gap parameters as \(m_{\ell}=10+2\ell\) and \(\nu_{\ell}={||\mathbf{P}||}_{\infty}/(8\cdot 2^{\ell})\). Since PB-LATTICEis a recursive algorithm, we initialize PB-LATTICEwith phase index \(1\), phase length \(12\), list of users \([[\mathsf{M}]]\), list of items \([[\mathsf{N}]]\), clusters C, rounds T, noise \(\sigma^{2}\), round index \(1\), gap factor \({||\mathbf{P}||}_{\infty}/16\). For the greedy algorithm (Alg. 5), we experiment with two exploration periods (\(m=10\) and \(m=30\)). Finally, for the Collaborative-Greedy algorithm in [4], we choose \(\theta=0.5\) and \(\alpha=0.5\).

[MISSING_PAGE_EMPTY:18]

the best \(\mathsf{T}/\mathsf{B}\) items _(golden items)_ not chosen for recommendation so far in the exploit phases for users in \(\mathcal{M}^{(\ell,i)}\) are contained in the set of surviving items i.e. if \(\mathcal{Z}=[\mathsf{N}]\setminus\mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{(\ell, \mathsf{t})}\), then it must happen that

\[\mathcal{N}^{(\ell,i)}\supseteq\bigcup_{u\in\mathcal{M}^{(\ell,i)}}\{\pi_{u}(t ^{\prime})\mid\mathcal{Z}\}_{t^{\prime}=1}^{\mathsf{T}/\mathsf{B}-\left| \mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{(\ell,i)}\right|}\text{ for all }i\in[a_{\ell}]\] (8)

Note that eq. 8 implies that for every user \(u\in\mathcal{M}^{(\ell,i)}\), there are **sufficient golden items in \(\mathcal{N}^{(\ell,i)}\) to be recommended for the remaining rounds**. To see this, note that there are \(\mathsf{T}/\mathsf{B}\) golden items at the beginning and no golden items which are unblocked are eliminated. Hence the number of remaining rounds at any point must be smaller than the number of possible allowed recommendations of golden items belonging to the surviving set of items.
3. Furthermore, for all \(i\in[a_{\ell}]\), the set \(\mathcal{N}^{(\ell,i)}\) must also satisfy the following: \[\left|\mathbf{P}_{u\pi_{u}(1)|\mathcal{N}^{(\ell,i)}}-\min_{j\in\mathcal{N} ^{(\ell,i)}}\mathbf{P}_{uj}\right|\leq\epsilon_{\ell}\text{ for all }u\in\mathcal{M}^{(\ell,i)}\] (9) where \(\epsilon_{\ell}\) is a fixed exponentially decreasing sequence in \(\ell\) (in particular, we choose \(\epsilon_{1}=\left|\left|\mathbf{P}\right|\right|_{\infty}\) and \(\epsilon_{\ell}=C^{\prime}2^{-\ell}\min\left(\left\|\mathbf{P}\right\|_{\infty },\frac{\sigma\sqrt{\mu}}{\log\mathsf{N}}\right)\) for \(\ell>1\) for some constant \(C^{\prime}>0\)).

Next, at the beginning of the _exploit_ component of phase \(\ell+1\), we will have the following set of desirable properties:

1. At every round \(t\) in the _exploit_ component of phase \(\ell+1\), we maintain a list of disjoint _nice subsets_ of users \(\mathcal{M}^{(\ell+1)}\equiv\{\mathcal{M}^{(\ell+1,1)},\ldots,\mathcal{M}^{( \ell+1,a_{\ell+1})}\}\) (where \(\cup_{i\in[a_{\ell+1}]}\mathcal{M}^{(\ell+1,i)}\subseteq[\mathsf{M}]\)) and corresponding sets of items \(\mathcal{N}^{(\ell+1,t)}\equiv\{\mathcal{N}^{(\ell+1,t,1)},\ldots,\mathcal{N}^ {(\ell+1,t,a_{\ell+1})}\}\) where \(a_{\ell+1}\leq\mathsf{C}\) and \(\cup_{i\in[a_{\ell+1}]}\mathcal{N}^{(\ell+1,t,i)}\subseteq[\mathsf{N}]\). Note that in the exploit component, we also use the round index in the superscript for item subsets as they can change during the _exploit_ component (unlike the _explore_ component).
2. We ensure that for any user \(u\in\mathcal{M}^{(\ell+1,i)}\), the set of items chosen for recommendation in the _exploit_ component of phase \(\ell+1\) belongs to the set of best \(\mathsf{T}\) items i.e. \(\{\pi_{u}(t)\}_{t=1}^{\mathsf{T}}\).

Since LATTICE is random, we will say that our algorithm is \((\epsilon_{\ell},\ell)-\)_good_ if at the beginning of the _explore_ component of the \(\ell^{\text{th}}\) phase the algorithm can maintain a list of users and items satisfying properties A-C. Let us also define the event \(\mathcal{E}_{2}^{(\ell)}\) to be true if properties (A-C) are satisfied at the beginning of the _explore_ component of phase \(\ell\) by the phased elimination algorithm. We can show that if our algorithm is \((\epsilon_{\ell},\ell)-\)_good_ then the low rank matrix completion step (denoted by the event \(\mathcal{E}_{3}^{(\ell)}\)) in the _explore_ component of phase \(\ell\) is successful (i.e. the event \(\mathcal{E}_{3}^{(\ell)}\) is true) with high probability.

Conditioned on the aforementioned two events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\), with probability \(1\), during all rounds \(t\) of the exploit component in phase \(\ell+1\), properties \(a-b\) are satisfied and the event \(\mathcal{E}_{2}^{(\ell+1)}\) is going to be true. We are going to prove inductively that our algorithm is \((\epsilon_{\ell},\ell)\)-good for all phases indexed by \(\ell\) for our choice of \(\{\epsilon_{\ell}\}_{\ell}\) with high probability.

Base Case:For \(\ell=1\) (the first phase), the number of rounds in the _exploit_ component is zero and we start with the _explore_ component. We initialize \(\mathcal{M}^{(1,1)}=[\mathsf{N}]\), \(\mathcal{N}^{(1,1)}=[\mathsf{M}]\) and therefore, we have

\[\left|\max_{j\in\mathcal{N}^{(\ell,1)}}\mathbf{P}_{uj}-\min_{j\in\mathcal{N}^ {(\ell,1)}}\mathbf{P}_{uj}\right|\leq\left|\left|\mathbf{P}\right|\right|_{\infty} \text{ for all }u\in[\mathsf{M}].\]

Clearly, \([\mathsf{M}]\) is a _nice subset_ of users and finally for every user \(u\in[\mathsf{M}]\), the best \(\mathsf{T}/\mathsf{B}\) items (_golden items_) \(\{\pi_{u}(t)\}_{t=1}^{\mathsf{T}/\mathsf{B}}\) belong to the entire set of items. Thus for \(\ell=1\), conditions A-C are satisfied at the beginning of the _explore_ component and therefore the event \(\mathcal{E}_{2}^{(1)}\) is true. Hence, our initialization makes the algorithm \((\left|\left|\mathbf{P}\right|\right|_{\infty},1)\)-good.

Inductive Argument:Suppose, at the beginning of the phase \(\ell\), we condition on the events \(\bigcap_{j=1}^{\ell}\mathcal{E}_{2}^{(j)}\) that Algorithm is \((\epsilon_{j},j)-\)_good_ for all \(j\leq\ell\). This means that conditions (A-C) are satisfied at the beginning of the _explore_ component of all phases up to and including that of \(\ell\) for each reward sub-matrix (indexed by \(i\in[a_{\ell}]\)) corresponding to the users in \(\mathcal{M}^{(\ell,i)}\) and items in \(\mathcal{N}^{(\ell,i)}\). Next, our goal is to run low rank matrix completion in order to estimate each of the sub-matrices corresponding to \(\{(\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)})\}_{i\in[a_{\ell}]}\).

Exploration Strategy:Consider a particular nice subset of users \(\mathcal{M}^{(\ell,i)}\) and corresponding active items \(\mathcal{N}^{(\ell,i)}\) (s.t. \(|\mathcal{N}^{(\ell,i)}|\geq\mathsf{T}^{1/3}\)) at the beginning of the _explore_ component of phase \(\ell\) for \(\mathcal{M}^{(\ell,i)}\). For each user \(u\in\mathcal{M}^{(\ell,i)}\), we are going to sample each item \(j\in\mathcal{N}^{(\ell,i)}\) with probability \(p\) (to be determined based on the desired error guarantee). Suppose the set of indices sampled in the explore component of phase \(\ell\) is denoted by \(\Omega^{(\ell)}\subseteq\mathcal{M}^{(\ell,i)}\times\mathcal{N}^{(\ell,i)}\). Now, for each user \(u\in\mathcal{M}^{(\ell,i)}\) we recommend all the unblocked items in the set \(\mathcal{A}_{u}^{(\ell)}\equiv\{j\in\mathcal{N}^{(\ell,i)}\mid(u,j)\mid\Omega^ {(\ell)}\}\) and obtain the corresponding noisy reward (note that for blocked items in the aforementioned set, we have already obtained the corresponding noisy rewards).

For simplicity, we intend to complete the _explore_ component at the same round for all users in \(\mathcal{M}^{(\ell,i)}\). If, for two users \(u,v\in\mathcal{M}^{(\ell,i)}\), it happens that recommendation of all items in \(\mathcal{A}_{u}^{(\ell)}\) is complete for user \(u\) but recommendation of all items in \(\mathcal{A}_{v}^{(\ell)}\) is incomplete for user \(v\), then for the remaining rounds we recommend to user \(u\) arbitrary unblocked items from \(\mathcal{N}^{(\ell,i)}\). Note that this is always possible since the set \(\mathcal{N}^{(\ell,i)}\) has sufficiently many unblocked items allowing recommendations in the remaining rounds at beginning of explore component of phase \(\ell\). We start with the following lemma to characterize the round complexity of estimating the sub-matrix \(\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\) up to entry-wise error \(\Delta_{\ell+1}\) with high probability using the noisy observations corresponding to the subset of indices \(\Omega^{(\ell)}\):

**Lemma 4**.: _Consider a particular subset of nice users \(\mathcal{M}^{(\ell,i)}\) and corresponding active items \(\mathcal{N}^{(\ell,i)}\) (such that \(\min\left(\mathsf{M}/(\tau\mathsf{C}),\left|\mathcal{N}^{(\ell,i)}\right| \right)\geq\mathsf{T}^{1/3}\)) at the beginning of the explore component of phase \(\ell\). Suppose \(d_{1}=\max(|\mathcal{M}^{(\ell,i)}|,|\mathcal{N}^{(\ell,i)}|)\) and \(d_{2}=\min(|\mathcal{M}^{(\ell,i)}|,|\mathcal{N}^{(\ell,i)}|)\). Let us fix \(\Delta_{\ell+1}=\Omega(\sigma\sqrt{\mu^{3}\log d_{1}}/\sqrt{d_{2}})\) and condition on the event \(\mathcal{E}_{2}^{(\ell)}\). Suppose Assumptions 1 and 2 are satisfied. In that case, in explore component of phase \(\ell\), by choosing \(1\geq p=c\Big{(}\frac{\sigma^{2}\widetilde{\mu}^{3}\log d_{1}}{\Delta_{\ell+ 1}^{2}d_{2}}\Big{)}\) (for some constant \(c>0\)) and using_

\[m_{\ell}=O\Big{(}\frac{\sigma^{2}\widetilde{\mu}^{3}\log(\mathsf{M}\bigvee \mathsf{N})}{\Delta_{\ell+1}^{2}}\max\Big{(}1,\frac{\mathsf{N}\tau}{\mathsf{M} }\Big{)}\log\mathsf{T}\Big{)}\Big{)}\]

_rounds under the blocked constraint, we can compute an estimate \(\widetilde{\mathbf{P}}^{(\ell)}\in\mathbb{R}^{\mathsf{M}\times\mathsf{N}}\) such that with probability \(1-O(\mathsf{T}^{-3})\), we have_

\[\Big{|}\bigg{|}\widetilde{\mathbf{P}}^{(\ell)}_{\mathcal{M}^{(\ell,i)}, \mathcal{N}^{(\ell,i)}}-\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{( \ell,i)}}\Big{|}\Big{|}_{\infty}\leq\Delta_{\ell+1}.\] (10)

_where \(\sigma^{2}\) is the noise variance, \(\mu\) is the incoherence of reward matrix \(\mathbf{P}\) and \(\widetilde{\mu}\) is the incoherence factor of reward sub-matrix \(\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\)._

Proof of Lemma 4.: We are going to use Lemma 1 in order to compute an estimate \(\widetilde{\mathbf{P}}^{(\ell)}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\) of the sub-matrix \(\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\) satisfying \(\Big{|}\bigg{|}\widetilde{\mathbf{P}}^{(\ell)}_{\mathcal{M}^{(\ell,i)},\mathcal{N }^{(\ell,i)}}-\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}} \Big{|}_{\infty}\leq\Delta_{\ell+1}\). Since \(\mathcal{M}^{(\ell,i)}\) is a _nice_ subset of users, the cardinality of \(\left|\mathcal{M}^{(\ell,i)}\right|\) must be larger than \(\mathsf{M}/(\tau\mathsf{C})\). Recall that \(\tau\) is the ratio of the maximum cluster size and the minimum cluster size; \(\mathsf{M}/\mathsf{C}\) being the average cluster size implies that the minimum cluster size is bounded from above by \(\mathsf{M}/(\tau\mathsf{C})\). From Lemma 1, we know that by using \(m_{\ell}=O\Big{(}p\left|\mathcal{N}^{(\ell,i)}\right|+\sqrt{\left|\mathcal{N} ^{(\ell,i)}\right|p\log(\left|\mathcal{M}^{(\ell,i)}\right|\delta^{-1})}\Big{)}\) rounds (see Lemma 1) restricted to users in \(\mathcal{M}^{(\ell,i)}\) such that with probability at least \(1-(\delta+d_{2}^{-12})\) (see Remark 5),

\[\Big{|}\bigg{|}\widetilde{\mathbf{P}}^{(\ell)}_{\mathcal{M}^{(\ell,i)}, \mathcal{N}^{(\ell,i)}}-\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i )}}\Big{|}_{\infty}=O\left(\frac{\sigma\sqrt{\widetilde{\mu}^{3}\log d_{1}}}{ \sqrt{pd_{2}}}\right).\]

where \(d_{1}=\max(|\mathcal{M}^{(\ell,i)}|,|\mathcal{N}^{(\ell,i)}|)\), \(d_{2}=\min(|\mathcal{M}^{(\ell,i)}|,|\mathcal{N}^{(\ell,i)}|)\) and \(\widetilde{\mu}\) is the incoherence factor of the matrix \(\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\). In order for the right hand side to be less than \(\Delta_{\ell+1}\), we can set \(p=c\Big{(}\frac{\sigma^{2}\widetilde{\mu}^{3}\log d_{1}}{\Delta_{\ell+1}^{2}d_{2}} \Big{)}\) for some appropriate constant \(c>0\). Since the event \(\mathcal{E}_{2}^{(\ell)}\) is true, we must have that \(\left|\mathcal{M}^{(\ell,i)}\right|\geq\mathsf{M}/(\tau\mathsf{C})\); hence \(d_{2}\geq\min\Big{(}\mathsf{M}/(\tau\mathsf{C}),\left|\mathcal{N}^{(\ell,i)} \right|\Big{)}\). Therefore, we must have that

\[m_{\ell}=O\Big{(}\frac{\sigma^{2}\widetilde{\mu}^{3}\log(\mathsf{M}\,\mathsf{ V})}{\Delta_{\ell+1}^{2}}\max\Big{(}1,\frac{\mathsf{N}\tau}{\mathsf{M}}\Big{)} \log\mathsf{T})\Big{)}\]

where we substitute \(\delta^{-1}=1/\mathsf{poly}(\mathsf{T})\) and furthermore, the condition of the Lemma statement implies that \(d_{2}^{-12}=O(\mathsf{T}^{-3})\). Hence, we complete the proof of the lemma.

**Remark 5** (Remark 1 in [8]).: _The error probability can be reduced from \(O(\delta+d_{2}^{-3})\) to \(O(\delta+d_{2}^{-c})\) for any constant \(c>0\) with only constant factor changes in the round complexity \(m\) and the estimation guarantees \(\left\|\mathbf{P}-\widetilde{\mathbf{P}}\right\|_{\infty}\). We will use \(c=12\) in rest of the paper._

Note that although \(\widetilde{\mu}\), the incoherence factor of the sub-matrix \(\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\) is unknown, from Lemma 3, we know that \(\widetilde{\mu}\) is bounded from above by \(O(\mu)\) (recall that \(C,\alpha,\tau=O(1)\)).

Exploration Strategy continued:In particular, we choose \(\Delta_{\ell+1}=\epsilon_{\ell}/176\mathsf{C}\) at the beginning of the _explore_ component of phase \(\ell\) for the set of users \(\mathcal{M}^{(\ell,i)}\) with active items \(\mathcal{N}^{(\ell,i)}\). One edge case scenario is when for a particular set of _nice_ users \(\mathcal{M}^{(\ell,i)}\), at the beginning of the explore component of phase \(\ell\), we have \(\left|\mathcal{N}^{(\ell,i)}\right|\leq\mathsf{T}^{1/3}\). In this case, **this set of _nice_ users \(\mathcal{M}^{(\ell,i)}\) do not progress to the next phase** and in the _explore_ component, we simply recommend arbitrary items in \(\mathcal{N}^{(\ell,i)}\) to users in \(\mathcal{M}^{(\ell,i)}\) for the remaining rounds. Another interesting edge case scenario is when \(d_{2}=\min(\left|\mathcal{M}^{(\ell,i)}\right|,\left|\mathcal{N}^{(\ell,i)} \right|,)\) is so small that the requisite error guarantee \(\Delta_{\ell+1}\) (eq. 10) cannot be achieved even by setting \(p=1\) i.e. we recommend all the items in the active set. Recall that by our induction assumption, \(\mathcal{N}^{(\ell,i)}\) is sufficiently large so that it is possible to recommend unblocked items for the number of remaining rounds (say \(\mathsf{T}-t_{\ell}\) with \(t_{\ell}\) being the round at which the _explore_ component of phase \(\ell\) starts). In that case, **the set of users \(\mathcal{M}^{(\ell,i)}\) do not progress to the subsequent phase**; we simply recommend arbitrary unblocked items in the set \(\mathcal{N}^{(\ell,i)}\) to the users in \(\mathcal{M}^{(\ell,i)}\) for the remaining rounds. In both the above edge case scenarios, the _explore_ component of phase \(\ell\) for users in \(\mathcal{M}^{(\ell,i)}\) would last for the remaining rounds from where it starts. We can now show the following lemma:

**Lemma 5**.: _Consider a particular subset of nice users \(\mathcal{M}^{(\ell,i)}\) and corresponding surviving items \(\mathcal{N}^{(\ell,i)}\) at the beginning of the explore component of phase \(\ell\). Suppose \(d_{1}=\max(|\mathcal{M}^{(\ell,i)}|,|\mathcal{N}^{(\ell,i)}|)\) and \(d_{2}=\min(|\mathcal{M}^{(\ell,i)}|,|\mathcal{N}^{(\ell,i)}|)\). Now \(\Delta_{\ell+1}=\epsilon_{\ell}/176\mathsf{C}\) is such that there does not exist any \(p\in[0,1]\) for which RHS in eq. 3 can be \(\Delta_{\ell+1}\) for estimation of matrix \(\mathbf{P}\) restricted to the rows in \(\mathcal{M}^{(\ell,i)}\) and columns in \(\mathcal{N}^{(\ell,i)}\). In that case, we must have for all users \(u\in\mathcal{M}^{(\ell,i)}\),_

\[(\mathsf{T}-t_{\ell})\max_{y\in\mathcal{N}^{(\ell,i)}}\Big{(}\mathbf{P}_{u\pi_ {u}(1)|\mathcal{N}^{(\ell,i)}}-\mathbf{P}_{uy}\Big{)}=\widetilde{O}\Big{(} \sigma\mathsf{C}\sqrt{\mu^{3}\log d_{1}}\max\Big{(}\sqrt{\mathsf{T}},\mathsf{T} \sqrt{\frac{\mathsf{C}}{\mathsf{M}\tau}}\Big{)}\Big{)}\]

_where \(t_{\ell}\) is the round at which the explore component of phase \(\ell\) starts._

Proof.: Note that by our induction hypothesis, we must have \(\mathsf{B}\left|\mathcal{N}^{(\ell,i)}\right|\geq\mathsf{T}-t_{\ell}\) because the set of surviving items must contain sufficient unblocked items (for recommendation in the remaining rounds) for every user \(u\in\mathcal{M}^{(\ell,i)}\). Hence, by setting \(p=1\) in eq. 3, with a certain number of rounds, we can obtain an estimate \(\mathbf{Q}\) of \(\mathbf{P}\) satisfying

\[\left|\left|\mathbf{Q}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}-\mathbf{P}_ {\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\right|\right|_{\infty}=O\Big{(} \frac{\sigma\sqrt{\mu^{3}\log d_{1}}}{\sqrt{d_{2}}}\Big{)}.\]

Hence, this implies that our choice of \(\Delta_{\ell+1}\) satisfies \(\Delta_{\ell+1}=O\Big{(}\frac{\sigma\sqrt{\mu^{3}\log d_{1}}}{\sqrt{d_{2}}} \Big{)}\) implying that \(\epsilon_{\ell}=O\Big{(}\frac{\sigma\mathsf{C}\sqrt{\mu^{3}\log d_{1}}}{\sqrt{d_{ 2}}}\Big{)}\). Now, there are two possibilities: 1) either \(d_{2}=\left|\mathcal{M}^{(\ell,i)}\right|\) implying that \(\mathsf{M}/(\tau\mathsf{C})\leq O\Big{(}\frac{\sigma\mathsf{C}\sqrt{\mu^{3}\log d _{1}}}{\sqrt{d_{2}}}\Big{)}\). Thus, we can conclude that \(\mathsf{P}\) is a contradiction. 
\(\big{|}\mathcal{M}^{(\ell,i)}\big{|}\leq\big{|}\mathcal{N}^{(\ell,i)}\big{|}\). In that case, we have that \(\epsilon_{\ell}=O\Big{(}\frac{\sigma\mathbb{C}^{1.5}\sqrt{\mu^{3}\log d_{1}}}{ \sqrt{\mathsf{M}\tau}}\Big{)}\). Now, because of our induction assumption, we will have

\[\max_{y\in\mathcal{N}^{(\ell,i)}}\Big{(}\mathbf{P}_{u\pi_{u}(1)|\mathcal{N}^{( \ell,i)}}-\mathbf{P}_{uy}\Big{)}\leq\epsilon_{\ell}=O\Big{(}\frac{\sigma \mathbb{C}^{1.5}\sqrt{\mu^{3}\log d_{1}}}{\sqrt{\mathsf{M}\tau}}\Big{)}.\]

Therefore, for any user \(u\in\mathcal{M}^{(\ell,i)}\), if we recommend arbitrary unblocked items in \(\mathcal{N}^{(\ell,i)}\) for the remaining rounds then we can bound the following quantity

\[(\mathsf{T}-t_{\ell})\max_{y\in\mathcal{N}^{(\ell,i)}}\Big{(}\mathbf{P}_{u\pi _{u}(1)|\mathcal{N}^{(\ell,i)}}-\mathbf{P}_{uy}\Big{)}=O\Big{(}\frac{\sigma \mathbb{T}\mathbb{C}^{1.5}\sqrt{\mu^{3}\log d_{1}}}{\sqrt{\mathsf{M}\tau}} \Big{)}.\]

2) The second possibility is the following: \(d_{2}=\big{|}\mathcal{N}^{(\ell,i)}\big{|}\geq\mathsf{B}^{-1}(\mathsf{T}-t_{ \ell})\). In that case, from our induction assumption, we have that (\(\mathsf{B}=\Theta(\log\mathsf{T})\))

\[\max_{y\in\mathcal{N}^{(\ell,i)}}\Big{(}\mathbf{P}_{u\pi_{u}(1)|\mathcal{N}^{ (\ell,i)}}-\mathbf{P}_{uy}\Big{)}\leq\epsilon_{\ell}=\widetilde{O}\Big{(} \frac{\sigma\mathbb{C}\sqrt{\mu^{3}\log d_{1}}}{\sqrt{\mathsf{T}-t_{\ell}}} \Big{)}.\]

and therefore

\[(\mathsf{T}-t_{\ell})\max_{y\in\mathcal{N}^{(\ell,i)}}\Big{(} \mathbf{P}_{u\pi_{u}(1)|\mathcal{N}^{(\ell,i)}}-\mathbf{P}_{uy}\Big{)}\leq \epsilon_{\ell}(\mathsf{T}-t_{\ell})=\widetilde{O}\Big{(}\frac{\sigma\mathbb{ C}\sqrt{\mu^{3}\log d_{1}}}{\sqrt{\mathsf{T}-t_{\ell}}}\cdot(\mathsf{T}-t_{ \ell})\Big{)}\] \[=\widetilde{O}\Big{(}\sigma\mathbb{C}\sqrt{\mu^{3}\mathsf{T}\log d _{1}}\Big{)}.\]

Consider \(\mathcal{M}^{\prime(\ell)}\subseteq\mathcal{M}^{(\ell)}\) to be the family of _nice_ subsets of users which do not fall into the edge case scenarios i.e. 1) there exists \(0\leq p\leq 1\) for which the theoretical bound in RHS in eq. 3 can be smaller than \(\Delta_{\ell+1}\) 2) we have \(\big{|}\mathcal{N}^{(\ell,i)}\big{|}\geq\mathsf{T}^{1/3}\). More precisely \(\mathcal{M}^{\prime(\ell)}\) corresponds to the set

\[\Big{\{}\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{(\ell)}\text{ with active items }\mathcal{N}^{(\ell,i)}\mid\Delta_{\ell+1}=\Omega\Big{(}\frac{\sigma\sqrt{\mu^{3} \log\max(\big{|}\mathcal{M}^{(\ell,i)}\big{|}\,\big{|}\mathcal{N}^{(\ell,i)} \big{|})}}{\sqrt{\min(\big{|}\mathcal{M}^{(\ell,i)}\big{|}\,\big{|}\mathcal{N} ^{(\ell,i)}\big{|})}}\Big{)}\] \[\text{ and }\big{|}\mathcal{N}^{(\ell,i)}\Big{|}\geq\mathsf{T}^{1/3}\Big{\}}\]

Suppose \(\mathsf{M}/(\tau\mathbb{C})=\Omega(\mathsf{T}^{1/3})\). As mentioned before, the event \(\mathcal{E}_{3}^{(\ell)}\) is true if the algorithm has successfully computed an estimate \(\widetilde{\mathbf{P}}^{(\ell)}\in\mathbb{R}^{\mathsf{M}\times\mathsf{N}}\) such that for all \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\)

\[\Big{|}\bigg{|}\widetilde{\mathbf{P}}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{( \ell,i)}}^{(\ell)}-\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}} \bigg{|}\bigg{|}_{\infty}\leq\Delta_{\ell+1}\text{ for all }\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime\ell}\] (11)

implying that for each of the distinct nice subsets \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\), after the _explore_ component of phase \(\ell\), the algorithm finds a good entry-wise estimate of the sub-matrix \(\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\). In the following part of the analysis, we will repeatedly condition on the events \(\mathcal{E}_{2}^{(\ell)}\) (conditions A-C are satisfied at the beginning of the _explore_ component of phase \(\ell\)) and the event \(\mathcal{E}_{3}^{(\ell)}\) (eq. 10 is true for all nice subsets \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) in the explore component of phase \(\ell\)). Note that the event \(\mathcal{E}_{2}^{(\ell)}\) is true due to the induction hypothesis and conditioned on the event \(\mathcal{E}_{2}^{(\ell)}\), the event \(\mathcal{E}_{3}^{(\ell)}\) is true with probability at least \(1-O(\mathsf{T}^{-3}\mathbb{C})\) (after taking a union bound over C clusters).

Fix any \(\mathcal{M}^{(\ell,i)}\subseteq\mathcal{M}^{\prime(\ell)}\) and condition on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\). For each user \(u\in\mathcal{M}^{(\ell,i)}\), once the algorithm has computed the estimate \(\widetilde{\mathbf{P}}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}^{(\ell)}\) in eq. 11, let us denote a set of good items for the user \(u\) by

\[\mathcal{T}_{u}^{(\ell)} \equiv\{j\in\mathcal{N}^{(\ell,i)}\mid\widetilde{\mathbf{P}}_{uj} \geq\widetilde{\mathbf{P}}_{u\widetilde{u}_{u}(\mathsf{T}\mathsf{B}^{-1}-\big{|} \mathcal{O}^{(\ell,i)}_{\mathcal{M}^{(\ell,i)}}\big{|}|\mathcal{N}^{(\ell,i)}}-2 \Delta_{\ell+1}\}\] (12) \[\mathcal{R}_{u}^{(\ell)} \equiv\{j\in\mathcal{N}^{(\ell,i)}\mid\widetilde{\mathbf{P}}_{uj} \geq\widetilde{\mathbf{P}}_{u\widetilde{u}_{u}(1)|\mathcal{N}^{(\ell,i)}}-2 \Delta_{\ell+1}\}\] (13)where \(t\) is the round index at the end of the _explore_ component of phase \(\ell\) and \(|\mathcal{O}^{(\ell,t)}_{\mathcal{M}^{(\ell,i)}}|\) is the number of rounds in _exploit_ components of phases that the user \(u\in\mathcal{M}^{(\ell,i)}\) has encountered so far. Note from our algorithm, that users in the same nice subset \(\mathcal{M}^{(\ell,i)}\) have encountered exactly the same number of rounds in _exploit_ components of phases until the end of phase \(\ell\). Recall that users in \(\mathcal{M}^{(\ell,i)}\) have been recommended the same set of items until blocked (unless blocked already for some user in which case the item in question has already been recommended B times) in the _exploit_ components of phases until the end of phase \(\ell\) (this set of items chosen for recommendation in the _exploit_ components up to end of phase \(\ell\) is denoted by \(\mathcal{O}^{(\ell,t)}_{\mathcal{M}^{(\ell,i)}}\)). If we condition on the event \(\mathcal{E}^{(\ell)}_{3}\), then we can show the following statement to be true (in the following lemma, we remove the superscript \(t\) in \(\mathcal{O}^{(\ell,t)}_{\mathcal{M}^{(\ell,i)}}\) for simplicity - the round index \(t\) corresponds to the end of phase \(\ell\) for users in \(\mathcal{M}^{(\ell,i)}\)):

**Lemma 6**.: _Condition on the events \(\mathcal{E}^{(\ell)}_{2},\mathcal{E}^{(\ell)}_{3}\) being true. Consider a nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{t(\ell)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell,i)}\) for which guarantees in eq. 11 holds. Let \(\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\) be the set of items that have been chosen for recommendation to users in \(\mathcal{M}^{(\ell,i)}\) in exploit components of the first \(\ell\) phases. Denote \(\mathcal{Z}=[\mathbb{N}]\setminus\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\). In that case, for every user \(u\in\mathcal{M}^{(\ell,i)}\), the items \(\pi_{u}(s)\mid\mathcal{Z}\) for all \(s\in[\mathsf{TB}^{-1}-\left|\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}} \right|]\) must belong to the set \(\mathcal{T}^{(\ell)}_{u}\)._

Proof.: Let us fix a user \(u\in\mathcal{M}^{(\ell,i)}\) with active set of arms \(\mathcal{N}^{(\ell,i)}\). Let us also fix an item \(a\equiv\pi_{u}(t)\mid\mathcal{Z}\) for \(t\in[\mathsf{TB}^{-1}-\left|\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}} \right|]\). Recall that \(\widetilde{\pi}\mid\mathcal{Z}\) is the permutation of the items sorted in descending order according to their estimated reward in \(\widetilde{\mathbf{P}}^{(\ell)}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\). Now there are two possibilities regarding the position of the arm \(a\) in the permutation \(\widetilde{\pi}\mid\mathcal{Z}\) - 1) \(\pi_{u}(t)\mid\mathcal{Z}\equiv\widetilde{\pi}_{u}(t_{1})\mid\mathcal{Z}\) for some \(t_{1}\leq t\) which implies that in the permutation \(\widetilde{\pi}\mid\mathcal{Z}\), the position of the arm \(a\) is \(t_{1}\). In that case, the arm \(a\) survives in the set \(\mathcal{T}^{(\ell)}_{u}\) by definition (see eq. 12) 2) Now, suppose that \(\pi_{u}(t)\mid\mathcal{Z}\equiv\widetilde{\pi}_{u}(t_{1})\mid\mathcal{Z}\) for some \(t_{1}\leq t\) which implies that in the permutation \(\widetilde{\pi}\mid\mathcal{Z}\), the arm \(a\) has been shifted to the right (from \(\pi\mid\mathcal{Z}\)). In that case, there must exist another item \(b\equiv\pi_{u}(t_{2})\mid\mathcal{Z}\) for \(t_{2}>t\) such that \(\pi_{u}(t_{2})\mid\mathcal{Z}\equiv\widetilde{\pi}_{u}(t_{3})\mid\mathcal{Z}\) for \(t_{3}\leq t\). Now, we will have

\[\widetilde{\mathbf{P}}^{(\ell)}_{ub}-\widetilde{\mathbf{P}}^{(\ell)}_{ua}= \widetilde{\mathbf{P}}^{(\ell)}_{ub}-\mathbf{P}_{ub}+\mathbf{P}_{ub}-\mathbf{P }_{ua}+\mathbf{P}_{ua}-\widetilde{\mathbf{P}}^{(\ell)}_{ua}\leq 2\Delta_{\ell+1}\]

where we used the following facts a) conditioned on the event \(\mathcal{E}^{(\ell)}_{3}\), we have \(\widetilde{\mathbf{P}}^{(\ell)}_{us}-\mathbf{P}_{us}\leq\Delta_{\ell+1}\) for all \(u\in\mathcal{M}^{(\ell,i)},s\in\mathcal{N}^{(\ell,i)}\) b) \(\mathbf{P}_{ub}-\mathbf{P}_{ua}\leq 0\) by definition. Hence, this implies that \(a\in\mathcal{T}^{(\ell)}_{u}\).

**Corollary 1**.: _Condition on the events \(\mathcal{E}^{(\ell)}_{2},\mathcal{E}^{(\ell)}_{3}\) being true. Consider a nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{t(\ell)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell,i)}\) for which guarantees in eq. 11 holds. Suppose \(t_{\ell}\) is the final round of the explore component of phase \(\ell\) for users in \(\mathcal{M}^{(\ell,i)}\). In that case, for user \(u\), the set \(\mathcal{T}^{(\ell)}_{u}\) contains sufficient items that are unblocked and can be recommended for the remaining \(\mathsf{T}-t_{\ell}\) rounds._

Proof.: From Lemma 11, we showed that \(\mathcal{T}^{(\ell)}_{u}\) comprises the set of items \(\pi_{u}(s)\mid\mathcal{Z}\) for all \(s\in[\mathsf{TB}^{-1}-\left|\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}} \right|]\) where \(\mathcal{Z}=[\mathbb{N}]\setminus\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\). Now, suppose the \(k^{\text{th}}\) item in the set \(\mathcal{H}_{u}\equiv\{\pi_{u}(t^{\prime})\mid\mathcal{Z}\}_{t^{\prime}=1}^{ \mathsf{T}-\left|\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}}\) has been recommended to user \(u\)\(b_{k}<\mathsf{B}\) times in previous phases. In that case, the number of allowed recommendations of items in \(\mathcal{T}^{(\ell)}_{u}\) is at least \(\mathsf{TB}^{-1}-\mathsf{B}\left|\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}} \right|-\sum_{k\in\mathcal{H}_{u}}b_{k}\) which is more than the remaining rounds that is at most \(\mathsf{TB}^{-1}-\mathsf{B}\left|\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}} \right|-\sum_{k\in\mathcal{H}_{u}}b_{k}\) (\(\mathsf{B}\left|\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\right|\) rounds have already been used up when the _golden items_ were identified and recommended). 

Consider a _nice_ subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) and its corresponding active set of items \(\mathcal{N}^{(\ell,i)}\) for which eq. 11 holds true. At the end of the _explore_ component of phase \(\ell\), based on the estimate \(\widetilde{\mathbf{P}}^{(\ell)}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\), we construct a graph \(\mathcal{G}^{(\ell,i)}\) whose nodes are given by the users in \(\mathcal{M}^{(\ell,i)}\). Now, we draw an edge between two users \(u,v\in\mathcal{M}^{(\ell,i)}\) if \(\left|\widetilde{\mathbf{P}}_{ux}^{(\ell)}-\widetilde{\mathbf{P}}_{vx}^{(\ell)} \right|\leq 2\Delta_{\ell+1}\) for all considered items \(x\in\mathcal{N}^{(\ell,i)}\).

**Lemma 7**.: _Condition on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\) being true. Consider a nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell,i)}\) for which guarantees in eq. 11 holds. Consider the graph \(\mathcal{G}^{(\ell,i)}\) formed by the users in \(\mathcal{M}^{(\ell,i)}\) such that an edge exists between two users \(u,v\in\mathcal{M}^{(\ell,i)}\) if \(\left|\widetilde{\mathbf{P}}_{ux}^{(\ell)}-\widetilde{\mathbf{P}}_{vx}^{( \ell)}\right|\leq 2\Delta_{\ell+1}\) for all considered items \(x\in\mathcal{N}^{(\ell,i)}\). Nodes in \(\mathcal{G}^{(\ell,i)}\) corresponding to users in the same cluster form a clique. Also, users in each connected component of the graph \(\mathcal{G}^{(\ell,i)}\) form a nice subset of users._

Proof.: For any two users \(u,v\in\mathcal{M}^{(\ell,i)}\) belonging to the same cluster, consider an arm \(x\in\mathcal{N}^{(\ell,i)}\). We must have

\[\widetilde{\mathbf{P}}_{ux}^{(\ell)}-\widetilde{\mathbf{P}}_{vx}^{(\ell)}= \widetilde{\mathbf{P}}_{ux}^{(\ell)}-\mathbf{P}_{ux}+\mathbf{P}_{ux}-\mathbf{ P}_{vx}+\mathbf{P}_{vx}-\widetilde{\mathbf{P}}_{vx}^{(\ell)}\leq 2\Delta_{\ell+1}.\]

Now, consider two users \(u,v\in\mathcal{M}^{(\ell,i)}\) that belongs to different clusters \(\mathcal{P},\mathcal{Q}\) respectively. Note that since the event \(\mathcal{E}^{(\ell)}\) is true, \(\mathcal{M}^{(\ell,i)}\) is a union of clusters comprising \(\mathcal{P},\mathcal{Q}\). Furthermore, we have already established that nodes in \(\mathcal{G}^{(\ell,i)}\) (users in \(\mathcal{M}^{(\ell,i)}\)) restricted to the same cluster form a clique. There every connected component of the graph \(\mathcal{G}^{(\ell,i)}\) can be represented as a union of a subset of clusters.

**Lemma 8**.: _Condition on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\) being true. Consider a nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell,i)}\) for which guarantees in eq. 11 holds. In that case, for any subset \(\mathcal{Y}\subseteq\mathcal{N}^{(\ell,i)}\) and any \(s\in[|\mathcal{Y}|]\), for every user \(u\in\mathcal{M}^{(\ell,i)}\), we must have_

\[\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}-\widetilde{ \mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}-6\Delta_{\ell+1}\leq\mathbf{ P}_{u\pi_{u}(1)|\mathcal{Y}}-\mathbf{P}_{u\pi_{u}(s)|\mathcal{Y}}\leq \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}-\widetilde{ \mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}+6\Delta_{\ell+1}.\]

Proof.: Since, we condition on the event \(\mathcal{E}_{3}^{(\ell)}\), we must have computed an estimate \(\widetilde{\mathbf{P}}^{(\ell)}\), an estimate of \(\mathbf{P}\) restricted to users in \(\mathcal{M}^{(\ell,i)}\) and items in \(\mathcal{N}^{(\ell,i)}\) such that

\[\left|\left|\widetilde{\mathbf{P}}_{\mathcal{M}^{(\ell,i)}\mathcal{N}^{(\ell,i)}}^{(\ell)}-\mathbf{P}_{\mathcal{M}^{(\ell,i)}\mathcal{N}^{(\ell,i)}} \right|\right|_{\infty}\leq\Delta_{\ell+1}.\]

We can decompose the term being studied in the following manner:

\[\widetilde{\mathbf{P}}_{u\pi_{u}(1)|\mathcal{Y}}^{(\ell)}- \widetilde{\mathbf{P}}_{u\pi_{u}(s)|\mathcal{Y}}^{(\ell)}\] \[=\widetilde{\mathbf{P}}_{u\pi_{u}(1)|\mathcal{Y}}^{(\ell)}- \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}^{(\ell)}+ \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}^{(\ell)}- \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{(\ell)}+ \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{(\ell)}- \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{(\ell)}- \widetilde{\mathbf{P}}_{u\pi_{u}(s)|\mathcal{Y}}^{(\ell)}.\]

Let us bound the quantity \(\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{(\ell)}- \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{(\ell)}\). In order to analyze this quantity, we will consider a few cases. In the first case, suppose that \(\pi_{u}(s)\mid\mathcal{Y}=\widetilde{\pi}_{u}(t_{1})\mid\mathcal{Y}\) for \(t_{1}\geq s\). In that case, we will have that \(\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{(\ell)}- \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{(\ell)}\geq 0\). In the second case, suppose \(\pi_{u}(s)\mid\mathcal{Y}=\widetilde{\pi}_{u}(t_{2})\mid\mathcal{Y}\) for \(t_{2}<s\) and \(\pi_{u}(t_{3})\mid\mathcal{Y}=\widetilde{\pi}_{u}(s)\mid\mathcal{Y}\) for \(t_{3}<s\). In that case, we have

\[\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{(\ell )}-\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{(\ell)}\] \[=\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{( \ell)}-\mathbf{P}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}+\mathbf{P}_{u\widetilde{ \pi}_{u}(s)|\mathcal{Y}}-\mathbf{P}_{u\pi_{u}(s)|\mathcal{Y}}+\mathbf{P}_{u\pi_{u} (s)|\mathcal{Y}}-\widetilde{\mathbf{P}}_{u\pi_{u}(s)|\mathcal{Y}}^{(\ell)}\] \[=\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{( \ell)}-\mathbf{P}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}+\mathbf{P}_{u\pi_{u}(s)| \mathcal{Y}}-\mathbf{P}_{u\pi_{u}(s)|\mathcal{Y}}+\mathbf{P}_{u\pi_{u}(s)| \mathcal{Y}}-\widetilde{\mathbf{P}}_{u\pi_{u}(s)|\mathcal{Y}}^{(\ell)}\geq-2 \Delta_{\ell+1}\]

where we used the fact \(\mathbf{P}_{u\pi_{u}(s)|\mathcal{Y}}-\mathbf{P}_{u\pi_{u}(s)|\mathcal{Y}}\geq 0\). In the final case, we assume that \(\pi_{u}(s)\mid\mathcal{Y}=\widetilde{\pi}_{u}(t_{2})\mid\mathcal{Y}\) for \(s>t_{2}\) and \(\pi_{u}(t_{3})\mid\mathcal{Y}=\widetilde{\pi}_{u}(s)\mid\mathcal{Y}\) for \(t_{3}>s\). This means that both the items \(\pi_{u}(s)\mid\mathcal{Y},\pi_{u}(t_{3})\mid\mathcal{Y}\) have been shifted to the left in the permutation \(\widetilde{\pi}_{u}\mid\mathcal{Y}\). Hence,

\[\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{(\ell)}- \widetilde{\mathbf{P}}_{u\pi_{u}(s)|\mathcal{Y}}^{(\ell)}\] \[=\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}^{( \ell)}-\mathbf{P}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}+\mathbf{P}_{u \widetilde{\pi}_{u}(s)|\mathcal{Y}}-\mathbf{P}_{u\pi_{u}(s)|\mathcal{Y}}\] \[+\mathbf{P}_{u\pi_{u}(s)|\mathcal{Y}}-\widetilde{\mathbf{P}}_{u \pi_{u}(s)|\mathcal{Y}}^{(\ell)}\geq-2\Delta_{\ell+1}+\mathbf{P}_{u\widetilde{ \pi}_{u}(s)|\mathcal{Y}}-\mathbf{P}_{u\pi_{u}(s)|\mathcal{Y}}=-2\Delta_{\ell+1 }+\mathbf{P}_{u\pi_{u}(t_{3})|\mathcal{Y}}-\mathbf{P}_{u\pi_{u}(s)|\mathcal{Y}}.\]Hence there must exist an element \(\pi_{u}(t_{4})\mid\mathcal{Y}\) such that \(t_{4}<s\) and \(\widetilde{\pi}_{u}(t_{5})\mid\mathcal{Y}=\pi_{u}(t_{4})\mid\mathcal{Y}\) for \(t_{5}>s\). In that case, we must have

\[\mathbf{P}_{u\pi_{u}(t_{3})|\mathcal{Y}}-\mathbf{P}_{u\pi_{u}(s)| \mathcal{Y}}\geq\mathbf{P}_{u\pi_{u}(t_{3})|\mathcal{Y}}-\mathbf{P}_{u\pi_{u}( t_{4})|\mathcal{Y}}\] \[=\mathbf{P}_{u\pi_{u}(t_{3})|\mathcal{Y}}-\widetilde{\mathbf{P}} _{u\pi_{u}(t_{3})|\mathcal{Y}}^{(\ell)}+\widetilde{\mathbf{P}}_{u\pi_{u}(t_{3} )|\mathcal{Y}}^{(\ell)}-\widetilde{\mathbf{P}}_{u\pi_{u}(t_{4})|\mathcal{Y}}^{ (\ell)}+\widetilde{\mathbf{P}}_{u\pi_{u}(t_{4})|\mathcal{Y}}^{(\ell)}-\mathbf{ P}_{u\pi_{u}(t_{4})|\mathcal{Y}}\] \[\geq-2\Delta_{\ell+1}+\widetilde{\mathbf{P}}_{u\pi_{u}(t_{3})| \mathcal{Y}}^{(\ell)}-\widetilde{\mathbf{P}}_{u\pi_{u}(t_{4})|\mathcal{Y}}^{ (\ell)}=-2\Delta_{\ell+1}+\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)| \mathcal{Y}}^{(\ell)}-\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(t_{5})| \mathcal{Y}}^{(\ell)}\geq-2\Delta_{\ell+1}.\]

Therefore, in this case, we get that \(\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)}^{(\ell)}-\widetilde{\mathbf{P }}_{u\pi_{u}(s)}^{(\ell)}\geq-4\Delta_{\ell+1}\). Again, we will have that

\[\widetilde{\mathbf{P}}_{u\pi_{u}(1)|\mathcal{Y}}^{(\ell)}- \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}^{(\ell)}= \widetilde{\mathbf{P}}_{u\pi_{u}(1)|\mathcal{Y}}^{(\ell)}-\mathbf{P}_{u\pi_{u} (1)|\mathcal{Y}}^{(\ell)}\] \[+\mathbf{P}_{u\pi_{u}(1)|\mathcal{Y}}^{(\ell)}-\mathbf{P}_{u \widetilde{\pi}_{u}(1)|\mathcal{Y}}^{(\ell)}+\mathbf{P}_{u\widetilde{\pi}_{u} (1)|\mathcal{Y}}^{(\ell)}-\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)| \mathcal{Y}}^{(\ell)}\geq-2\Delta_{\ell+1}.\]

By combining the above arguments, we have that

\[\widetilde{\mathbf{P}}_{u\pi_{u}(1)|\mathcal{Y}}^{(\ell)}-\widetilde{\mathbf{ P}}_{u\pi_{u}(s)|\mathcal{Y}}^{(\ell)}\geq\widetilde{\mathbf{P}}_{u\widetilde{ \pi}_{u}(1)|\mathcal{Y}}^{(\ell)}-\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u} (s)|\mathcal{Y}}^{(\ell)}-6\Delta_{\ell+1}.\]

By a similar set of arguments involving triangle inequalities, we will also have

\[\widetilde{\mathbf{P}}_{u\pi_{u}(1)|\mathcal{Y}}^{(\ell)}-\widetilde{\mathbf{ P}}_{u\pi_{u}(s)|\mathcal{Y}}^{(\ell)}\leq\widetilde{\mathbf{P}}_{u\pi_{u}(1)| \mathcal{Y}}^{(\ell)}-\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)| \mathcal{Y}}^{(\ell)}+6\Delta_{\ell+1}.\]

This completes the proof of the lemma. 

We now show the following lemma characterizing the union of good items for a connected component of the graph \(\mathcal{G}^{(\ell,i)}\). Recall that \(\mathsf{T}-\left|\mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{(\ell)}\right|\) counts the number of rounds excluding the ones used up in _exploit_ component so far up to the \(\ell^{\text{th}}\) phase.

**Lemma 9**.: _Condition on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\) being true. Consider a nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell,i)}\) for which guarantees in eq. 11 holds. Consider a subset of users \(\mathcal{G}\in\mathcal{M}^{(\ell,i)}\) forming a connected component. Fix any set \(\mathcal{Y}=\bigcup_{u\in\mathcal{G}}\mathcal{T}_{g}^{(\ell)}\setminus \mathcal{J}\) for some \(\mathcal{J}\) such that for every user \(u\in\mathcal{G}\), we have \(\widetilde{\pi}_{u}(s^{\prime})\mid\mathcal{N}^{(\ell,i)}\equiv\widetilde{ \pi}_{u}(s)\mid\mathcal{Y}\) for \(s^{\prime}=\mathsf{TB}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{(\ell)}\right|\) and some common index \(s\). In that case, we must have_

\[\max_{v\in\mathcal{G}}\Big{(}\max_{x,y\in\mathcal{Y}}\widetilde{\mathbf{P}}_{ vx}-\widetilde{\mathbf{P}}_{vy}\Big{)}\leq\max_{u\in\mathcal{G}}\Big{(} \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}-\widetilde{\mathbf{ P}}_{u\widetilde{\pi}_{u}(s^{\prime})|\mathcal{N}^{(\ell,i)}}\Big{)}+24 \mathsf{C}\Delta_{\ell+1}\]

Proof.: Let us fix a user \(v\in\mathcal{G}\). We have \(\max_{x,y\in\mathcal{Y}}\widetilde{\mathbf{P}}_{vx}-\widetilde{\mathbf{P}}_{vy} =\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(1)|\mathcal{Y}}-\min_{y\in \mathcal{Y}}\widetilde{\mathbf{P}}_{vy}\). Now, there are two possibilities for any \(y\in\mathcal{Y}\): first, suppose that \(y\in\mathcal{T}_{v}^{(\ell)}\). In that case, we have

\[\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(1)|\mathcal{Y}}-\widetilde{\mathbf{ P}}_{vy}=\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(1)|\mathcal{Y}}-\widetilde{ \mathbf{P}}_{v\widetilde{\pi}_{v}(s)|\mathcal{Y}}+\widetilde{\mathbf{P}}_{v \widetilde{\pi}_{v}(s)|\mathcal{Y}}-\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(s^ {\prime})|\mathcal{T}_{v}^{(\ell)}}+\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(s^ {\prime})|\mathcal{T}_{v}^{(\ell)}}-\widetilde{\mathbf{P}}_{vy}\]

Recall that the set \(\mathcal{T}_{v}^{(\ell)}\) was constructed as

\[\mathcal{T}_{v}^{(\ell)}\equiv\{j\in\mathcal{N}^{(\ell,i)}\mid\widetilde{ \mathbf{P}}_{vj}\geq\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(s^{\prime})| \mathcal{N}^{(\ell,i)}}-2\Delta_{\ell+1}\}\text{ where }s^{\prime}=\mathsf{TB}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{(\ell)}\right|\] (14)

Since \(y\in\mathcal{T}_{v}^{(\ell)}\), we can bound \(\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(s^{\prime})|\mathcal{T}_{v}^{(\ell)} }-\widetilde{\mathbf{P}}_{vy}\leq 2\Delta_{\ell+1}\). Also, from the construction of \(\mathcal{T}_{v}^{(\ell)}\), \(\{\widetilde{\pi}_{v}(r)\mid\mathcal{N}^{(\ell,i)}\}_{r=1}^{s}\) is present in the set \(\mathcal{T}_{v}^{(\ell)}\). Also, since \(\mathcal{T}_{u}^{(\ell)}\) is just a subset of \(\mathcal{N}^{(\ell,i)}\), the positions of the items \(\{\widetilde{\pi}_{v}(r)\mid\mathcal{N}^{(\ell,i)}\}_{r=1}^{s}\) do not change in the permutation corresponding to the items in \(\mathcal{T}_{v}^{(\ell)}\) sorted by estimated reward for \(v\) in decreasing order i.e. \(\widetilde{\pi}_{v}(r)\mid\mathcal{N}^{(\ell,i)}=\widetilde{\pi}_{v}(r)\mid \mathcal{T}_{v}^{(\ell)}\) for any \(r\in[s]\). Hence \(\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(s)|\mathcal{Y}}-\widetilde{\mathbf{P}}_{ v\widetilde{\pi}_{v}(s^{\prime})|\mathcal{T}_{v}^{(\ell)}}=0\). Hence, by combining the above, we have

\[\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(1)|\mathcal{Y}}-\widetilde{\mathbf{P}}_{ vy}\leq\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(1)|\mathcal{Y}}-\widetilde{\mathbf{P}}_{v \widetilde{\pi}_{v}(s)|\mathcal{Y}}+2\Delta_{\ell+1}.\]

Next, consider the case when \(y\not\in\mathcal{T}_{v}^{(\ell)}\). Hence,

[MISSING_PAGE_FAIL:26]

Therefore, in this case, we get that \(\widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(s)}-\widetilde{\mathbf{P}}^{( \ell)}_{v\widetilde{\pi}_{u}(s)}\geq-8\Delta_{\ell+1}\). Hence we get

\[\widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(1)|\mathcal{ Y}}-\widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(s)|\mathcal{Y}}= \widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(1)|\mathcal{Y}}- \widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(s)|\mathcal{Y}}\] \[+\widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(s)| \mathcal{Y}}-\widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{u}(s)| \mathcal{Y}}\geq\widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(1)| \mathcal{Y}}-\widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(s)| \mathcal{Y}}-8\Delta_{\ell+1}.\]

Also, we will have that

\[\widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{u}(1)|\mathcal{ Y}}-\widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{u}(1)|\mathcal{Y}}= \widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{u}(1)|\mathcal{Y}}- \mathbf{P}^{(\ell)}_{v\widetilde{\pi}_{u}(1)|\mathcal{Y}}\] \[+\widetilde{\mathbf{P}}^{(\ell)}_{u\widetilde{\pi}_{u}(1)| \mathcal{Y}}-\widetilde{\mathbf{P}}^{(\ell)}_{u\widetilde{\pi}_{v}(1)| \mathcal{Y}}+\mathbf{P}^{(\ell)}_{u\widetilde{\pi}_{v}(1)|\mathcal{Y}}- \widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(1)|\mathcal{Y}}\geq-4 \Delta_{\ell+1}.\]

By combining the above arguments, we have that

\[\widetilde{\mathbf{P}}^{(\ell)}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}- \widetilde{\mathbf{P}}^{(\ell)}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}\geq \widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{u}(1)|\mathcal{Y}}- \widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{u}(s)|\mathcal{Y}}-4\Delta _{\ell+1}\geq\widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(1)|\mathcal{ Y}}-\widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(s)|\mathcal{Y}}-12\Delta_{ \ell+1}.\]

By a similar set of arguments involving triangle inequalities, we will also have

\[\widetilde{\mathbf{P}}^{(\ell)}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}- \widetilde{\mathbf{P}}^{(\ell)}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}\leq \widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(1)|\mathcal{Y}}- \widetilde{\mathbf{P}}^{(\ell)}_{v\widetilde{\pi}_{v}(s)|\mathcal{Y}}+12 \Delta_{\ell+1}.\]

This completes the proof of the lemma. 

Now, for any fixed subset \(\mathcal{Y}\subseteq\mathcal{N}^{(\ell,i)}\), let us define the set \(\mathcal{R}^{(\ell)}_{u}\mid\mathcal{Y}\) for user \(u\) below:

\[\mathcal{R}^{(\ell)}_{u}\mid\mathcal{Y}=\{j\in\mathcal{Y}\mid \widetilde{\mathbf{P}}_{uj}\geq\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)| \mathcal{Y}}-2\Delta_{\ell+1}\}\]

Hence, \(\mathcal{R}^{(\ell)}_{u}\mid\mathcal{Y}\) corresponds to the set of items for user \(u\) that is close to the item with the highest estimated reward for user \(u\) restricted to the set \(\mathcal{Y}\) at the end of the _explore_ component of phase \(\ell\).

**Lemma 11**.: _Condition on the events \(\mathcal{E}^{(\ell)}_{2},\mathcal{E}^{(\ell)}_{3}\) being true. Consider a nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell,i)}\) for which guarantees in eq. 11 holds. Fix any subset \(\mathcal{Y}\subseteq\mathcal{N}^{(\ell,i)}\). In that case, for every user \(u\in\mathcal{M}^{(\ell,i)}\), the item with the highest reward \(\pi_{u}(1)\mid\mathcal{Y}\) in the set \(\mathcal{Y}\) must belong to the set \(\mathcal{R}^{(\ell)}_{u}\mid\mathcal{Y}\). Moreover, \(\max_{s,s^{\prime}\in\mathcal{R}^{(\ell)}_{u}\mid\mathcal{Y}}|\mathbf{P}_{us }-\mathbf{P}_{us^{\prime}}|\leq 4\Delta_{\ell+1}\)._

Proof.: Let us fix a user \(u\in\mathcal{M}^{(\ell,i)}\) with active set of arms \(\mathcal{N}^{(\ell,i)}\). Now, we will have

\[\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}- \widetilde{\mathbf{P}}^{(\ell)}_{u\pi_{u}(1)|\mathcal{Y}}=\widetilde{\mathbf{P }}^{(\ell)}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}\] \[-\mathbf{P}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}+\mathbf{P}_{u \widetilde{\pi}_{u}(1)|\mathcal{Y}}-\mathbf{P}_{u\pi_{u}(1)|\mathcal{Y}}+ \mathbf{P}_{u\pi_{u}(1)|\mathcal{Y}}-\widetilde{\mathbf{P}}^{(\ell)}_{u\pi_{u} (1)|\mathcal{Y}}\leq 2\Delta_{\ell+1}\]

which implies that \(\pi_{u}(1)\mid\mathcal{Y}\in\mathcal{R}^{(\ell)}_{u}\mid\mathcal{Y}\). Here we used the fact that \(\widetilde{\mathbf{P}}^{(\ell)}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}- \mathbf{P}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}\leq\Delta_{\ell+1}\), \(\mathbf{P}_{u|\mathcal{Y}}-\widetilde{\mathbf{P}}^{(\ell)}_{u\pi_{u}(1)|\mathcal{Y}} \leq\Delta_{\ell+1}\) and \(\mathbf{P}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}-\mathbf{P}_{u\pi_{u}(1)| \mathcal{Y}}\leq 0\). Next, notice that for any \(s,s^{\prime}\in\mathcal{R}^{(\ell)}_{u}\mid\mathcal{Y}\)

\[\mathbf{P}_{us}-\mathbf{P}_{us^{\prime}}=\mathbf{P}_{us}-\widetilde{\mathbf{P}}^{ (\ell)}_{us}+\widetilde{\mathbf{P}}^{(\ell)}_{us}-\widetilde{\mathbf{P}}^{( \ell)}_{ut_{1}}+\widetilde{\mathbf{P}}^{(\ell)}_{ut_{1}}-\widetilde{\mathbf{P}}^{( \ell)}_{us^{\prime}}+\widetilde{\mathbf{P}}^{(\ell)}_{us^{\prime}}-\mathbf{P}_{us^{ \prime}}\leq 4\Delta_{\ell+1}.\]

**Lemma 12**.: _Condition on the events \(\mathcal{E}^{(\ell)}_{2},\mathcal{E}^{(\ell)}_{3}\) being true. Consider a nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell,i)}\) for which guarantees in eq. 11 holds. Fix any subset \(\mathcal{Y}\subseteq\mathcal{N}^{(\ell,i)}\). Consider two users \(u,v\in\mathcal{M}^{(\ell,i)}\) having an edge in the graph \(\mathcal{G}^{(\ell,i)}\). Conditioned on the events \(\mathcal{E}^{(\ell)}_{2},\mathcal{E}^{(\ell)}_{3}\), we must have_

\[\max_{x\in\mathcal{R}^{(\ell)}_{u}\mid\mathcal{Y},y\in\mathcal{R}^{(\ell)}_{v} \mid\mathcal{Y}}|\mathbf{P}_{ux}-\mathbf{P}_{uy}|\leq 16\Delta_{\ell+1}\text{ and }\max_{x\in\mathcal{R}^{(\ell)}_{u}\mid\mathcal{Y},y\in\mathcal{R}^{(\ell)}_{v} \mid\mathcal{Y}}|\mathbf{P}_{vx}-\mathbf{P}_{vy}|\leq 16\Delta_{\ell+1}\]

Proof.: From the construction of \(\mathcal{G}^{(\ell,i)}\), we know that users \(u,v\in\mathcal{M}^{(\ell,i)}\) have an edge if \(\left|\widetilde{\mathbf{P}}^{(\ell)}_{ux}-\widetilde{\mathbf{P}}^{(\ell)}_{vx} \right|\leq 2\Delta_{\ell+1}\) (and therefore \(\left|\mathbf{P}_{ux}-\mathbf{P}_{vx}\right|\leq\left|\widetilde{\mathbf{P}}^{( \ell)}_{ux}-\mathbf{P}_{ux}\right|+\left|\mathbf{P}_{vx}-\widetilde{\mathbf{P}}^{( \ell)}_{vx}\right|+\left|\widetilde{\mathbf{P}}^{(\ell)}_{ux}-\widetilde{\mathbf{P}}^{( \ell)}_{vx}\right|\leq 4\Delta_{\ell+1}

be the set \(\mathcal{R}_{u}^{(\ell)}\mid\mathcal{Y}\). Suppose \(\mathbf{P}_{u\pi_{v}(1)\mid\mathcal{Y}}=a\) and \(\mathbf{P}_{v\pi_{v}(1)\mid\mathcal{Y}}=b\). Consider any pair of items \(x\in\mathcal{R}_{u},y\in\mathcal{R}_{v}\) respectively. Therefore, for \(x\in\mathcal{R}_{u}\) this must mean that \(\mathbf{P}_{ux}\geq a-4\Delta_{\ell+1}\) (note that \(\pi_{u}(1)\mid\mathcal{Y}\in\mathcal{R}_{u}\)). For \(y\in\mathcal{R}_{v}\), we must similarly have \(\mathbf{P}_{vy}\geq b-4\Delta_{\ell+1}\). Since \(u,v\) are connected by an edge, we must have \(\mathbf{P}_{vx}\geq a-8\Delta_{\ell+1}\) and \(\mathbf{P}_{uy}\geq b-8\Delta_{\ell+1}\). Now, we have \(\mathbf{P}_{v\pi_{v}(1)\mid\mathcal{Y}}\geq\mathbf{P}_{vx}\) implying that \(b\geq a-8\Delta_{\ell+1}\); hence

\[\mathbf{P}_{ux}-\mathbf{P}_{uy}\leq\mathbf{P}_{u\pi_{u}(1)\mid\mathcal{R}_{u} }-\mathbf{P}_{uy}\leq a-(b-8\Delta_{\ell+1})\leq 16\Delta_{\ell+1}.\]

A similar analysis for \(v\) shows that \(\mathbf{P}_{vy}-\mathbf{P}_{vx}\leq 16\Delta_{\ell+1}\). This completes the proof of the lemma. 

**Lemma 13**.: _Condition on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\) being true. Consider a nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell,i)}\) for which guarantees in eq. 11 holds. Fix any subset \(\mathcal{Y}\subseteq\mathcal{N}^{(\ell,i)}\). Consider two users \(u,v\in\mathcal{M}^{(\ell,i)}\) having a path of length \(\mathsf{L}\) in the graph \(\mathcal{G}^{(\ell,i)}\). Conditioned on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\), we must have_

\[\max_{x\in\mathcal{R}_{u}^{(\ell)}\mid\mathcal{Y},y\in\mathcal{R}_{v}^{(\ell )}\mid\mathcal{Y}}\mid\mathbf{P}_{ux}-\mathbf{P}_{uy}\rvert\leq 8(\mathsf{L}+1) \Delta_{\ell+1}\]

Proof.: Recall from the construction of \(\mathcal{G}^{(\ell,i)}\) that conditioned on \(\mathcal{E}_{3}^{(\ell)}\) users \(u,v\in\mathcal{M}^{(\ell,i)}\) have an edge if \(\left|\widetilde{\mathbf{P}}_{ux}^{(\ell)}-\widetilde{\mathbf{P}}_{vx}^{( \ell)}\right|\leq 2\Delta_{\ell+1}\) (and therefore \(\left|\mathbf{P}_{ux}-\mathbf{P}_{vx}\right|\leq 4\Delta_{\ell+1}\)) for all \(x\in\mathcal{N}^{(\ell,i)}\). Again, for simplicity of notation, let us denote \(\mathcal{R}_{u}\) to be the set \(\mathcal{R}_{u}^{(\ell)}\mid\mathcal{Y}\). Suppose \(\mathbf{P}_{u\pi_{v}(1)\mid\mathcal{Y}}=a\) and \(\mathbf{P}_{v\pi_{v}(1)\mid\mathcal{Y}}=b\). Consider any pair of items \(x\in\mathcal{R}_{u},y\in\mathcal{R}_{v}\) respectively. Therefore, for \(x\in\mathcal{R}_{u}\) this must mean that \(\mathbf{P}_{ux}\geq a-4\Delta_{\ell+1}\). For \(y\in\mathcal{R}_{v}\), we must similarly have \(\mathbf{P}_{vy}\geq b-4\Delta_{\ell+1}\). Since \(u,v\) are connected by an path of length \(\mathsf{L}\) (say \(a_{1},a_{2},\ldots,a_{(\mathsf{L}-1)}\)), we must have \(\mathbf{P}_{a_{1}x}\geq a-8\Delta_{\ell+1}\), \(\mathbf{P}_{a_{2}x}\geq a-12\Delta_{\ell+1}\) and finally \(\mathbf{P}_{vx}\geq a-4(\mathsf{L}+1)\Delta_{\ell+1}\). By a similar analysis \(\mathbf{P}_{uy}\geq b-4(\mathsf{L}+1)\Delta_{\ell+1}\). Now, we have \(\mathbf{P}_{v\pi_{v}(1)\mid\mathcal{Y}}\geq\mathbf{P}_{vx}\) implying that \(b\geq a-4(\mathsf{L}+1)\Delta_{\ell+1}\); hence

\[\mathbf{P}_{ux}-\mathbf{P}_{uy}\leq\mathbf{P}_{u\pi_{u}(1)\mid\mathcal{R}_{u} }-\mathbf{P}_{uy}\leq a-(b-4(\mathsf{L}+1)\Delta_{\ell+1})\leq 8(\mathsf{L}+1) \Delta_{\ell+1}.\]

Again, a similar analysis for \(v\) shows that \(\mathbf{P}_{vy}-\mathbf{P}_{vx}\leq 8(\mathsf{L}+1)\Delta_{\ell+1}\). This completes the proof of the lemma. 

**Corollary 2**.: _Condition on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\) being true. Consider a nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell,i)}\) for which guarantees in eq. 11 holds. Fix any subset \(\mathcal{Y}\subseteq\mathcal{N}^{(\ell,i)}\). Consider two users \(u,v\in\mathcal{M}^{(\ell,i)}\) having a path in the graph \(\mathcal{G}^{(\ell,i)}\). Conditioned on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\), we must have_

\[\max_{x\in\mathcal{R}_{u}^{(\ell)}\mid\mathcal{Y},y\in\mathcal{R}_{v}^{(\ell )}\mid\mathcal{Y}}\mid\mathbf{P}_{ux}-\mathbf{P}_{uy}\rvert\leq 16\mathsf{C}\Delta_{\ell+1}\text{ and }\max_{x\in\mathcal{R}_{u}^{(\ell)}\mid\mathcal{Y},y\in\mathcal{R}_{v}^{(\ell )}\mid\mathcal{Y}}\mid\mathbf{P}_{vx}-\mathbf{P}_{vy}\rvert\leq 16\mathsf{C}\Delta_{\ell+1}\]

Proof.: The proof follows from the fact that any two users \(u,v\in\mathcal{M}^{(\ell,i)}\) connected via a path must have a shortest path of length at most \(2\mathsf{C}-1\) conditioned on the events \(\mathcal{E}_{2}^{\ell},\mathcal{E}_{3}^{(\ell)}\). This is because, from Lemma 13, we know that users in the same cluster form a clique and since there are at most \(\mathsf{C}\) clusters, the shortest path must be of length at most \(2\mathsf{C}-1\). 

Hence, for a particular set of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\), consider the \(j^{\text{th}}\) connected component of \(\mathcal{G}^{(\ell,i)}\) comprising of users \(\mathcal{M}^{(\ell,i,j)}\). If we consider the union of items \(\mathcal{S}\equiv\cup_{u\in\mathcal{M}^{(\ell,i,j)}}\mathcal{R}_{u}^{(\ell)}\mid \mathcal{Y}\) for any subset \(\mathcal{Y}\mid\mathcal{N}^{(\ell,i)}\), then from Corollary 2, we must have that for any user \(u\in\mathcal{M}^{(\ell,i,j)}\),

\[\max_{x,y\in\mathcal{S}}\left|\mathbf{P}_{ux}-\mathbf{P}_{uy}\right|\leq 16 \mathsf{C}\Delta_{\ell+1}.\] (15)

This follows from the fact that every element \(s\in\mathcal{S}\) must exist in \(\mathcal{R}_{v}^{(\ell)}\mid\mathcal{Y}\) for some \(v\in\mathcal{M}^{(\ell,i,j)}\); moreover, \(v\) is connected to \(u\) and therefore the shortest path joining them must be of length at most \(2\mathsf{C}-1\). Finally we use Corollary 2 to conclude equation 15.

**Lemma 14**.: _Condition on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\) being true. Consider a nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell,i)}\) for which guarantees in eq. 11 holds. Consider the \(j^{\text{th}}\) connected component of the graph \(\mathcal{G}^{(\ell,i)}\) comprising of users \(\mathcal{M}^{(\ell,i,j)}\). Let \(\mathcal{N}^{(\ell,i,j)}\equiv\cup_{u\in\mathcal{M}^{(\ell,i,j)}}\mathcal{T}_{ u}^{(\ell)}\) denote the union of good items for users in \(\mathcal{M}^{(\ell,i,j)}\). In that case,_

1. _For every user_ \(u\in\mathcal{M}^{(\ell,i,j)}\)_, the items_ \(\pi_{u}(s)\mid[\mathbb{N}]\setminus\mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{( \ell)}\) _for_ \(s\in[\mathsf{T}\mathsf{B}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{( \ell)}\right|]\) _must belong to the set_ \(\mathcal{N}^{(\ell,i,j)}\) _i.e. the golden items that have not been chosen for recommendation to users in_ \(\mathcal{M}^{(\ell,i,j)}\) _in exploit components of previous phases must belong to the surviving set of items_ \(\mathcal{N}^{(\ell,i,j)}\)_._
2. _For any subset_ \(\mathcal{Y}\subseteq\mathcal{N}^{(\ell,i,j)}\) _and any_ \(s\leq|\mathcal{Y}|,\) _we must have the following for any_ \(\mathsf{A}>0\)_:_ \[\text{If }\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)| \mathcal{Y}}-\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}} \geq\mathsf{A}\text{ for some }u\in\mathcal{M}^{(\ell,i,j)}\] \[\text{then }\mathbf{P}_{v\widetilde{\pi}_{v}(1)|\mathcal{Y}}- \mathbf{P}_{v\widetilde{\pi}_{v}(s)|\mathcal{Y}}\] \[\geq\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(1)|\mathcal{Y}}- \widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(s)|\mathcal{Y}}-4\Delta_{\ell+1} \geq\mathsf{A}-(2\mathsf{C}-1)4\Delta_{\ell+1}\text{ for all }v\in\mathcal{M}^{(\ell,i,j)}.\]

Proof.: The proof of the first part follows directly from Lemma 11 where we showed that for a particular user \(u\in\mathcal{M}^{(\ell,i)}\), the items \(\mathbf{P}_{u\widetilde{\pi}_{u}(s)|[\mathbb{N}]\setminus\mathcal{O}_{ \mathcal{M}^{(\ell,i)}}^{(\ell)}}\) for \(s\in[\mathsf{T}\mathsf{B}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{( \ell)}\right|]\) must belong to the set \(\mathcal{T}_{u}^{(\ell)}\) (and the fact that \(\mathcal{N}^{(\ell,i,j)}\supseteq\mathcal{T}_{u}^{(\ell)}\)).

We move on to the proof of the second part of the lemma. Recall that any two users \(u,v\in\mathcal{M}^{(\ell,i)}\) have an edge in the graph \(\mathcal{G}^{(\ell,i)}\) if \(\left|\widetilde{\mathbf{P}}_{u\widetilde{\pi}}^{(\ell)}-\widetilde{\mathbf{P }}_{v\widetilde{\pi}}^{(\ell)}\right|\leq 2\Delta_{\ell+1}\) for all \(x\in\mathcal{N}^{(\ell,i)}\). In that case, we have

\[\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{u}(1)|\mathcal{Y}}- \widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(s)|\mathcal{Y}}\geq\widetilde{ \mathbf{P}}_{v\widetilde{\pi}_{u}(1)|\mathcal{Y}}-\widetilde{\mathbf{P}}_{v \widetilde{\pi}_{u}(s)|\mathcal{Y}}\] \[\geq\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}} -\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{Y}}-4\Delta_{\ell+1 }\geq\mathsf{A}-4\Delta_{\ell+1}.\]

We are going to prove the Lemma statement by induction on length of the shortest path joining the users \(u,v\). The base case (when the path length is \(1\) i.e. \(u,v\) are joined by an edge) is proved above. Suppose the statement is true when length of the shortest path is \(\mathsf{L}-1\). In that case, we have the following set of inequalities (suppose \(w\) is the neighbor of \(v\) and the length of the shortest path joining \(u,w\) is \(\mathsf{L}-1\))

\[\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(1)|\mathcal{Y}}- \widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(s)|\mathcal{Y}}\geq\widetilde{ \mathbf{P}}_{v\widetilde{\pi}_{u}(1)|\mathcal{Y}}-\widetilde{\mathbf{P}}_{v \widetilde{\pi}_{u}(s)|\mathcal{Y}}\] \[\geq\widetilde{\mathbf{P}}_{w\widetilde{\pi}_{u}(1)|\mathcal{Y}} -\widetilde{\mathbf{P}}_{w\widetilde{\pi}_{u}(s)|\mathcal{Y}}-4\Delta_{\ell+1 }\geq\mathsf{A}-4\Delta_{\ell+1}.\]

The lemma statement follows from the fact that the length of the shortest path between users \(u,v\) in the same connected component is at most \(2\mathsf{C}-1\). This completes the proof of the lemma. 

Partition of \(\mathcal{M}^{(\ell,i)}\) in phase \(\ell+1\) into nice subsets of users and their corresponding active subsets of items:Consider a nice set of users \(\mathcal{M}^{(\ell,i)}\) at the end of the _explore_ component of phase \(\ell\) i.e. the start of the subsequent phase \(\ell+1\) for the users in \(\mathcal{M}^{(\ell,i)}\). At this point, conditioned on events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\), our goal is to further partition the users in \(\mathcal{M}^{(\ell,i)}\) into more nuanced _nice_ subsets. Suppose the number of rounds is at least \(\mathsf{T}^{1/3}/\mathsf{B}=\widetilde{O}(\mathsf{T}^{1/3})\) implying that the active set of items \(\mathcal{N}^{(\ell,i)}\) is of size at least \(\widetilde{\Omega}(\mathsf{T}^{1/3})\) (induction assumption property B). Suppose, we index the connected components of the graph \(\mathcal{G}^{(\ell,i)}\) formed by the users in \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\). Now, for each index \(j\), the set of users corresponding to the \(j^{\text{th}}\) connected component of the graph \(\{\mathcal{G}^{(\ell,i)}\}\) forms the \(j^{\text{th}}\) nice subset of users (Lemma 7) stemming from users in \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) - let us denote this set of users by \(\mathcal{M}^{(\ell+1,z)}\) for some index \(s>0\). For this set of users \(\mathcal{M}^{(\ell+1,z)}\), at the start of the _exploit_ component of phase \(\ell+1\) (round \(t\)), we define the active set of items \(\mathcal{N}^{(\ell+1,t,z)}\) to be \(\bigcup_{u\in\mathcal{M}^{(\ell+1,z)}}\mathcal{T}_{u}^{(\ell)}\). Hence \(\{(\mathcal{M}^{(\ell+1,z)},\mathcal{N}^{(\ell+1,t,z)})_{z}\}_{z}\) forms the family of nice sets of users (that progress to the \((\ell+1)^{\text{th}}\) phase) and their corresponding active set of items at the beginning (_exploit_ component) of phase \(\ell+1\) for users stemming from \(\mathcal{M}^{\prime(\ell)}\). Next, we discuss our recommendation strategy for \(\mathcal{M}^{(\ell+1,z)}\) (a _nice_ subset of users) in the _exploit_ component of phase \(\ell+1\).

Strategy in exploit component of phase \(\ell+1\):Note that in the exploit component of phase \(\ell+1\) for users in \(\mathcal{M}^{(\ell,i,j)}\equiv\mathcal{M}^{(\ell+1,z)}\) (new notation indicating that \(\mathcal{M}^{(\ell,i,j)}\equiv\mathcal{M}^{(\ell+1,z)}\) is a _nice_ subset of users at phase \(\ell+1\)) for some indices \(i,j\) and \(z\), we follow a recursive approach to identify and recommend items in \(\{\pi_{u}(t)\}_{t=1}^{\mathsf{TB}^{-1}}\) for all users \(u\in\mathcal{M}^{(\ell+1,z)}\). At the beginning of the _exploit_ component of phase \(\ell+1\) (say round \(t\)), we will also initialize \(\mathcal{O}_{\mathcal{M}^{(\ell+1,i)}}^{(\ell+1,t)}\) to be the set of items \(\mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{(\ell)}\) (i.e. the _golden_ items that have been chosen for recommendation in the _exploit_ components of previous phases (\(1-\ell\)) to users in \(\mathcal{M}^{(\ell,i)}\) and recommended sufficiently enough number of times to be blocked). At start of the _exploit_ component of phase \(\ell+1\) (round \(t\)), recall that the active set of items is given by \(\mathcal{N}^{(\ell+1,t,z)}\equiv\bigcup_{u\in\mathcal{M}^{(\ell+1,z)}} \mathcal{T}_{u}^{(\ell)}\). We reiterate here that \(t\) corresponds to the index of the starting round in the _exploit_ component of phase \(\ell+1\) for users in the _nice subset_\(\mathcal{M}^{(\ell+1,z)}\).

Let us denote \(s=\mathsf{TB}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{(\ell+1,t)}\right|\) and \(\mathcal{Y}=\mathcal{N}^{(\ell+1,t,z)}\). First of all, note that from Lemma 14, for all users \(u\in\mathcal{M}^{(\ell+1,z)}\) the items \(\pi_{u}(r)\mid[\mathsf{N}]\setminus\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{( \ell+1,t)}\) for \(r\in[s]\) must belong to the set \(\mathcal{Y}\) i.e. the best \(s\) items among those that are not in the set \(\mathcal{O}_{\mathcal{M}^{(\ell+1,t)}}^{(\ell+1,t)}\) must survive in \(\mathcal{Y}\) (Lemma 14). Now, we look at two possibilities:

1. _(Possibility A):_ For all users \(u\in\mathcal{M}^{(\ell+1,z)}\), we have that \(\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)\mid\mathcal{Y}}-\widetilde{ \mathbf{P}}_{u\widetilde{\pi}_{u}(s)\mid\mathcal{Y}}\leq 64\mathsf{C}\Delta_{ \ell+1}\) In that case, we stop the _exploit_ component of phase \(\ell+1\) and move on to the _explore_ component of phase \(\ell+1\) for users in \(\mathcal{M}^{(\ell+1,z)}\) and active items \(\mathcal{Y}\). Conditioned on events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\), in Lemma 15, we show that the above condition implies for every user \(u\in\mathcal{M}^{(\ell+1,z)}\), we must have \[\max_{x,y\in\mathcal{Y}}\leq 88\mathsf{C}\Delta_{\ell+1}.\] Furthermore, for \(\mathcal{Z}=[\mathsf{N}]\setminus\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{( \ell+1)}\), it must happen that \(\mathcal{Y}\supseteq\{\pi_{u}(s)\mid\mathcal{Z}\}_{s=1}^{\mathsf{T}/\mathsf{B }-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{(\ell+1)}\right|}\) for every user \(u\in\mathcal{M}^{(\ell+1,z)}\). In other words, for each user \(u\in\mathcal{M}^{(\ell+1,z)}\), the set \(\mathcal{Y}\) must contain all the top \(\mathsf{TB}^{-1}\) golden items ( \(\{\pi_{u}(r)\}_{r=1}^{\mathsf{TB}^{-1}}\)) that were not recommended in the _exploit_ components so far.
2. _(Possibility B):_ For some user \(u\in\mathcal{M}^{(\ell+1,z)}\), we have that \(\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)\mid\mathcal{Y}}-\widetilde{ \mathbf{P}}_{u\widetilde{\pi}_{u}(s)\mid\mathcal{Y}}\geq 64\mathsf{C}\Delta_{\ell+1}\). In that case, from Lemma 14, we know that for every user \(v\in\mathcal{M}^{(\ell+1,z)}\), we must have \(\mathbf{P}_{v\widetilde{\pi}_{u}(1)\mid\mathcal{Y}}-\mathbf{P}_{v\widetilde{ \pi}_{v}(s)\mid\mathcal{Y}}\geq 56\mathsf{C}\Delta_{\ell+1}\). In that case, if we consider the set of items \(\mathcal{S}\equiv\cup_{u\in\mathcal{M}^{(\ell+1,z)}}\mathcal{R}_{u}^{(\ell)} \mid\mathcal{Y}\), then from Lemma 13 (or see eq. 15), we must have that for every user \(u\in\mathcal{M}^{(\ell+1,z)}\), \[\max_{x,y\in\mathcal{S}}|\mathbf{P}_{ux}-\mathbf{P}_{uy}|\leq 16\mathsf{C} \Delta_{\ell+1}\] (16) For every user \(u\in\mathcal{M}^{(\ell+1,z)}\), recall that in Lemma 11, we showed that \(\pi_{u}(1)\mid\mathcal{Y}\in\mathcal{R}_{u}^{(\ell)}\mid\mathcal{Y}\) and in Lemma 14, we showed that \(\pi_{u}(1)\mid\mathcal{Y}=\pi_{u}(1)\mid[\mathsf{N}\setminus\left|\mathcal{O}_ {\mathcal{M}^{(\ell+1,t)}}^{(\ell+1,t)}\right|]\). Hence, \(\pi_{u}(1)\mid\mathcal{Y}=\pi_{u}(1)\mid[\mathsf{N}\setminus\left|\mathcal{O} _{\mathcal{M}^{(\ell+1,z)}}^{(\ell+1,t)}\right|]\) belongs to the set \(\mathcal{S}\) for every user \(u\in\mathcal{M}^{(\ell+1,z)}\). Hence we must have that the items \(\mathcal{S}\) is a subset of \(\{\pi_{u}(r)\mid[\mathsf{N}]\setminus\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{( \ell+1,t)}\}_{r=1}^{s}\). Suppose we index the items in \(\mathcal{S}\). For each of the subsequent \(\mathsf{B}\left|\mathcal{S}\right|\) rounds (indexed by \(b\in[\mathsf{B}\mathcal{S}]\)), for every user \(u\in\mathcal{M}^{(\ell+1,z)}\), we go to the \(\lceil(b/\mathsf{B})\rceil^{\mathsf{th}}\) item in \(\mathcal{S}\) and recommend it to user \(u\) if unblocked. On the other hand, if the \(\lceil(b/\mathsf{B})\rceil^{\mathsf{th}}\) item in \(\mathcal{S}\) is blocked (or becomes blocked) for the user \(u\in\mathcal{M}^{(\ell+1,z)}\), then we simply recommend any unblocked item in \(\mathcal{N}^{(\ell+1,t,z)}\). This is always possible because we will prove via induction (see Lemma 15 and in particular eq. 23) that at every round in the _exploit_ component of phase \(\ell+1\), the number of unblocked items for any user \(u\in\mathcal{M}^{(\ell+1,z)}\) in the set \(\mathcal{N}^{(\ell+1,t,z)}\) (where \(t\) is the previous decision round for \(\mathcal{M}^{(\ell+1,z)}\) on whether possibility A or B is true) is always larger than the number of remaining rounds. We make the following updates: \[\mathcal{O}_{\mathcal{M}^{(\ell+1,1,\varepsilon)}}^{(\ell+1,t+| \mathcal{S}|)}\leftarrow\mathcal{O}_{\mathcal{M}^{(\ell+1,\varepsilon)}}^{( \ell+1,t)}\cup\mathcal{S}\] (17) \[\mathcal{N}^{(\ell+1,t+|\mathcal{S}|,z)}\leftarrow\mathcal{N}^{( \ell+1,t,z)}\setminus\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{(\ell+1,t+| \mathcal{S}|)}\] (18) \[t\gets t+|\mathcal{S}|\text{ and }\mathcal{Y}\leftarrow\mathcal{N}^{( \ell+1,t,s)}\] (19) i.e we update the set \(\mathcal{O}_{\mathcal{M}^{(\ell+1,t)}}^{(\ell+1,t)}\) by taking union with the set of \(|\mathcal{S}|\) identified items in \(\{\pi_{u}(t)\}_{t=1}^{\mathsf{T}}\) for all users \(u\in\mathcal{M}^{(\ell+1,z)}\). After these \(|\mathcal{S}|\) rounds, for the set of users \(\mathcal{M}^{(\ell+1,z)}\), the set of active items \(\mathcal{N}^{(\ell+1,t,z)}\) is pruned by removing the items in \(\mathcal{S}\) and the time index is increased from \(t\) to \(t+|\mathcal{S}|\). At this point, we repeat the same process again for users in \(\mathcal{M}^{(\ell+1,z)}\) with the pruned set of active items \(\mathcal{N}^{(\ell+1,t,s)}\) i.e. we check for _possibility \(A\) or possibility \(B\)_. If we encounter possibility \(B\), then we again find the set of items \(\mathcal{S}\equiv\cup_{u\in\mathcal{M}^{(\ell+1,z)}}\mathcal{R}_{u}^{(\ell)} \mid\mathcal{Y}\) and recommended it to all users in \(\mathcal{M}\) in \(|\mathcal{S}|\operatorname{\mathsf{B}}\) steps as outlined above. We do this step recursively until we encounter Step A for the users in \(\mathcal{M}^{(\ell+1,z)}\) and at that point we exit the _exploit_ component of phase \(\ell+1\) and enter the _explore_ component of phase \(\ell+1\).

As before, at the beginning of the _explore_ component of phase \(\ell+1\) for the _nice_ subset of users \(\mathcal{M}^{(\ell+1,z)}\), let us denote the set of active items by \(\mathcal{N}^{(\ell+1,z)}\) and the set of items considered for recommendation in the _exploit_ phases including the \((\ell+1)^{\text{th}}\) one by \(\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{(\ell+1)}\) (i.e. we remove the \(t\) in the superscript for simplicity). Therefore, at the end of the _explore_ component of phase \(\ell+1\) for the _nice_ subset of users \(\mathcal{M}^{(\ell+1,z)}\), the set of active items \(\mathcal{N}^{(\ell+1,z)}\) satisfy the following:

**Lemma 15**.: _Consider a nice subset of users \(\mathcal{M}^{(\ell+1,z)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell+1,z)}\) at the end of the exploit stage of phase \(\ell+1\) i.e. for all users \(u\in\mathcal{M}^{(\ell+1,z)}\), we have \(\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)|\mathcal{N}^{(\ell+1,z)}}- \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{N}^{(\ell+1,z)}} \leq 64\mathsf{C}\Delta_{\ell+1}\) for \(s=\mathsf{TB}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{(\ell+1)}\right|\). Suppose \(\mathcal{M}^{(\ell+1,z)}\) is comprised of the users in a connected component of the graph \(\mathcal{G}^{(\ell,i)}\) which in turn is formed by the users in \(\mathcal{M}^{(\ell,i)}\) for which guarantees in eq. 11 holds true i.e. we condition on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\) being true. In that case, we must have that_

1. _for all users_ \(u\in\mathcal{M}^{(\ell+1,z)}\)_,_ \[\max_{x,y\in\mathcal{N}^{(\ell+1,z)}}|\mathbf{P}_{ux}-\mathbf{P}_{uy}|\leq 8 8\mathsf{C}\Delta_{\ell+1}\] _i.e. the best and worst items in the set_ \(\mathcal{N}^{(\ell+1,z)}\) _for any user_ \(u\in\mathcal{M}^{(\ell+1,z)}\) _has close rewards._
2. _Denote_ \(\mathcal{Z}=[\mathsf{N}]\setminus\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{( \ell+1)}\) _to be set of items not chosen for recommendation to users in_ \(\mathcal{M}^{(\ell+1,z)}\) _in the exploit component of phases until (and including) phase_ \(\ell+1\)_. Then it must happen that_ \[\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{(\ell+1)}\subseteq\{\pi_{u }(t)\}_{t=1}^{\mathsf{TB}^{-1}}\] (20) \[\mathcal{N}^{(\ell+1,z)}\supseteq\bigcup_{u\in\mathcal{M}^{( \ell+1,z)}}\{\pi_{u}(t^{\prime})\mid\mathcal{Z}\}_{t^{\prime}=1}^{\mathsf{TB} ^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{(\ell+1)}\right|.\] (21)

Proof.: Suppose at the end of the _explore_ component of phase \(\ell\), \(\mathcal{M}^{(\ell+1,z)}\subseteq\mathcal{M}^{(\ell,i)}\). We will prove a more general statement. Consider the rounds \(t_{1},t_{2},\dots\) at which we check for _possibility A or possibility B_ (this includes the starting and ending rounds of the _exploit_ component of phase \(\ell+1\)). At any such round \(t_{r}\), for all users \(u\in\mathcal{M}^{(\ell+1,z)}\), we must have that \(\widetilde{\pi}_{u}(\mathsf{TB}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell,t_{r} )}}^{(\ell,t_{r})}\right|)\mid\mathcal{N}^{(\ell,i)}\in\mathcal{N}^{(\ell+1,t_{ r},z)}\) and

\[\max_{x,y\in\mathcal{N}^{(\ell+1,t_{r},z)}}|\mathbf{P}_{ux}- \mathbf{P}_{uy}|\leq\max_{v\in\mathcal{M}^{(\ell+1,z)}}\left(\widetilde{ \mathbf{P}}_{u\widetilde{\pi}_{u}(1)|\mathcal{N}^{(\ell+1,t_{r},z)}}- \widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)|\mathcal{N}^{(\ell+1,t_{r},z)}} \right)+24\mathsf{C}\Delta_{\ell+1}\] (22) \[\mathcal{N}^{(\ell+1,t_{r},z)}\supseteq\bigcup_{u\in\mathcal{M}^{( \ell+1,z)}}\{\pi_{u}(t^{\prime})\mid\mathcal{Z}\}_{t^{\prime}=1}^{s}\text{ where }\mathcal{Z}\equiv[\mathsf{N}]\setminus\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{r})}}^{(\ell+1,t_{r})}\] (23) \[\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{r})}}^{(\ell+1,t_{r})}\subseteq\{ \pi_{u}(t)\}_{t=1}^{\mathsf{TB}^{-1}}\] (24)for \(s=\mathsf{T}-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{s})}}^{(\ell+1,t_{s})}\right|\) We will prove the statement above via induction on the recursions performed in the _exploit_ component of the phase \(\ell+1\). For the base case, we consider the round \(t_{1}\) which corresponds to the beginning of the _exploit_ component of phase \(\ell+1\). At this round, recall that \(\mathcal{N}^{(\ell+1,t_{1},z)}=\cup_{u\in\mathcal{M}^{(\ell+1,z)}}\mathcal{T} _{u}^{(\ell)}\). Of course, with \(s=\mathsf{T}-\left|\mathcal{O}_{\mathcal{M}^{(\ell,z)}}^{(\ell)}\right|\), for every user \(u\in\mathcal{M}^{(\ell+1,z)}\), we must have \(\{\widetilde{\pi}_{u}(r)\mid\mathcal{N}^{(\ell,z)}\}_{r=1}^{s}\in\mathcal{T} _{u}^{(\ell)}\) (Lemma 11) and since \(\mathcal{N}^{(\ell+1,z)}\) is a union of the sets \(\mathcal{T}_{u}^{(\ell)}\), \(\widetilde{\pi}_{u}(r)\mid\mathcal{N}^{(\ell,z)}=\widetilde{\pi}_{u}(r)\mid \mathcal{N}^{(\ell+1,z)}\) for all \(r\in[s]\). Hence by invoking Lemma 9 (in the statement of Lemma 9, we have \(\mathcal{J}=\phi\) i.e. \(\mathcal{Y}=\mathcal{N}^{(\ell+1,z)}\) and \(\widetilde{\pi}_{u}(s)\mid\mathcal{N}^{(\ell,z)}=\widetilde{\pi}_{u}(s)\mid \mathcal{N}^{(\ell+1,z)}\) for \(s=\mathsf{T}-\left|\mathcal{O}_{\mathcal{M}^{(\ell,z)}}^{(\ell,t_{s})}\right|\)), we obtain the statement of the Lemma for round \(t_{1}\).

Suppose the induction statement is true for round \(t_{a}\) and the second possibility i.e. possibility \(B\) became true. In that case, we do not exit the recursion and our goal is to show that the lemma statement is true at the next decision round \(t_{a+1}\). The induction hypothesis implies that for every user \(u\in\mathcal{M}^{(\ell+1,z)}\), we have that \(\widetilde{\pi}_{u}(\mathsf{T}\mathsf{B}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{ (\ell,z)}}^{(\ell)}\right|)\) survives in the set of items \(\mathcal{N}^{(\ell+1,t_{a},z)}\) and furthermore, we have \(\widetilde{\pi}_{u}(\mathsf{T}\mathsf{B}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{ (\ell,z)}}^{(\ell)}\right|)\mid\mathcal{N}^{(\ell,z)}=\widetilde{\pi}_{u}(s) \mid\mathcal{N}^{(\ell+1,t_{a},z)}\) for \(s=\mathsf{T}\mathsf{B}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{a})}}^ {(\ell+1,t_{a})}\right|\) (note that \(s\) is common for all users in \(\mathcal{M}^{(\ell+1,z)}\)). The induction hypothesis also implies that

\[\mathcal{N}^{(\ell+1,t_{r},z)}\supseteq\bigcup_{u\in\mathcal{M}^{(\ell+1,z)}} \{\pi_{u}(t^{\prime})\mid\mathcal{Z}\}_{t^{\prime}=1}^{s}\text{ where }\mathcal{Z}\equiv[\mathsf{N}]\setminus\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{a})}}^{( \ell+1,t_{a})}\text{ and }s=\mathsf{T}-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{a})}}^{( \ell+1,t_{a})}\right|\] (25)

\[\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{r})}}^{(\ell+1,t_{r})}\subseteq\{\pi_{u}( t)\}_{t=1}^{\mathsf{T}\mathsf{B}^{-1}}\] (26)

Again, at the decision round \(t_{a}\), since the possibility \(B\) was true, for one of the users \(u\in\mathcal{M}^{(\ell+1,z)}\), we must have for \(s=\mathsf{T}-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{a})}}^{(\ell+1,t_{a}+1)}\right|\),

\[\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(1)\mid\mathcal{N}^{(\ell+1,t_{a},z )}}-\widetilde{\mathbf{P}}_{u\widetilde{\pi}_{u}(s)\mid\mathcal{N}^{(\ell+1,t_{ a},z)}}\geq 64\mathsf{C}\Delta_{\ell+1}\]

implying that for every user \(v\in\mathcal{M}^{(\ell+1,z)}\), we have

\[\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(1)\mid\mathcal{N}^{(\ell+1,t_{a}, z)}}-\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(s)\mid\mathcal{N}^{(\ell+1,t_{a},z )}}\geq 56\mathsf{C}\Delta_{\ell+1}.\]

The above equation further implies that (Lemma 8), for every user \(v\in\mathcal{M}^{(\ell+1,z)}\), we will have

\[\mathbf{P}_{v\pi_{v}(1)\mid\mathcal{N}^{(\ell+1,t_{a},z)}}-\mathbf{P}_{v\pi_{v} (s)\mid\mathcal{N}^{(\ell+1,t_{a},z)}}\geq 50\mathsf{C}\Delta_{\ell+1}.\]

Hence, as mentioned before, if we consider the set of items \(\mathcal{S}\equiv\cup_{u\in\mathcal{M}^{(\ell+1,z)}}\mathcal{R}_{u}^{(\ell)}\mid \mathcal{N}^{(\ell+1,t_{a},z)}\), then from Lemma 13 (or see eq. 15), we must have that for every user \(u\in\mathcal{M}^{(\ell+1,z)}\), \(\pi_{u}(1)\mid\mathcal{N}^{(\ell+1,t_{a},z)}\in\mathcal{S}\) and

\[\max_{y\in\mathcal{S}}\left|\mathbf{P}_{u\pi_{u}(1)\mid\mathcal{N}^{(\ell+1,t_{ a},z)}}-\mathbf{P}_{uy}\right|\leq 16\mathsf{C}\Delta_{\ell+1}.\] (27)

Hence, if we remove the set \(\mathcal{S}\) to update \(\mathcal{N}^{(\ell+1,t_{a},z)}\) i.e. \(\mathcal{N}^{(\ell+1,t_{a}+1,z)}\leftarrow\mathcal{N}^{(\ell+1,t_{a},z)}\setminus \mathcal{S}\), for every user \(u\in\mathcal{M}^{(\ell+1,z)}\), we must have

\[\widetilde{\pi}_{u}(\mathsf{T}\mathsf{B}^{-1}-\left|\mathcal{O}_{ \mathcal{M}^{(\ell,z)}}^{(\ell)}\right|)\mid\mathcal{N}^{(\ell,z)}= \widetilde{\pi}_{u}(\mathsf{T}\mathsf{B}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{( \ell+1,t_{a})}}^{(\ell+1,t_{a})}\right|)\mid\mathcal{N}^{(\ell+1,t_{a},z)}\] \[=\widetilde{\pi}_{u}(\mathsf{T}\mathsf{B}^{-1}-\left|\mathcal{O}_{ \mathcal{M}^{(\ell+1,t_{a}+1)}}^{(\ell+1,t_{a}+1)}\right|)\mid\mathcal{N}^{( \ell+1,t_{a}+1,z)}.\]

This is because for each user \(u\), only elements which have larger rewards than \(\widetilde{\pi}_{u}(\mathsf{T}\mathsf{B}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{( \ell+1,t_{a})}}^{(\ell+1,t_{a})}\right|)\mid\mathcal{N}^{(\ell+1,t_{a},z)}\) are removed which makes the aforementioned item survive in \(\mathcal{N}^{(\ell+1,t_{a}+1,z)}\) and also moves its position up (recall that \(\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{a})}}^{(\ell+1,t_{a})}\leftarrow\mathcal{O}_{ \mathcal{M}^{(\ell+1,t_{a})}}^{(\ell+1,t_{a})}\cup\mathcal{S}\)) in the list of surviving items sorted in decreasing order by expected reward. Hence, we can apply Lemma9 to conclude the first part of the induction proof. In order to show the final statement, with \(s=\mathsf{TB}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,s)}}^{(\ell+1,t_{r})}\right|\), we can simply substitute that

\[\max_{v\in\mathcal{M}^{(\ell+1,s)}}\left(\widetilde{\mathbf{P}}_{u\widetilde{ \overline{\pi}}_{u}(1)|\mathcal{N}^{(\ell+1,t_{r,s})}}-\widetilde{\mathbf{P}} _{u\widetilde{\overline{\pi}}_{u}(s)|\mathcal{N}^{(\ell+1,t_{r,s})}}\right) \leq 64\mathsf{C}\Delta_{\ell+1}\]

when possibility \(A\) became true at a decision round \(t_{r}\) and we exit the _exploit_ component to enter the _explore_ component of phase \(\ell+1\) for users in \(\mathcal{M}^{(\ell+1,z)}\).

Moreover, we will also have that

\[\mathcal{S}\subseteq\{\pi_{u}(r)\mid\mathcal{N}^{(\ell+1,t_{a},z )}\}_{r=1}^{s}\text{ where }s=\mathsf{TB}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{a})}}^{(\ell+1,t_{a})}\right|\] (28) \[\implies\mathcal{S}\subseteq\{\pi_{u}(r)\mid\mathcal{Z}\}_{r=1}^ {s}\text{ where }\mathcal{Z}\equiv[\mathsf{N}]\setminus\mathcal{O}_{\mathcal{M}^{(\ell+1,s)}}^ {(\ell+1,t_{a})}\text{ and }s=\mathsf{T}-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{a})}}^{(\ell+1,t_{ a})}\right|\] (29) \[\implies\mathcal{S}\subseteq\{\pi_{u}(t)\}_{t=1}^{\mathsf{TB}^{-1}}\] (30) \[\implies\mathcal{N}^{(\ell+1,t_{a+1},z)}\supseteq\bigcup_{u\in \mathcal{M}^{(\ell+1,z)}}\{\pi_{u}(t^{\prime})\mid\mathcal{Z}\}_{t^{\prime}= 1}^{\mathsf{TB}^{-1}-s}\] (31) \[\text{ where }\mathcal{Z}\equiv[\mathsf{N}]\setminus\mathcal{O}_{ \mathcal{M}^{(\ell+1,t_{a+1})}}^{(\ell+1,t_{a+1})}\text{ and }s=\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{a})}}^{(\ell+1,t_{a})}\right|\] (32)

This first implication is due to our induction hypothesis (see eq.25) which implies that the best \(s\) items in the smaller set \(\mathcal{N}^{(\ell+1,t_{a},z)}\) is same as the best \(s=\mathsf{TB}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{(\ell+1,t_{ a})}\right|\) items in the larger set \([\mathsf{N}]\setminus\mathcal{O}_{\mathcal{M}^{(\ell+1,z)}}^{(\ell+1,t_{a})}\). Hence, it is evident that the set \(\mathcal{S}\) must also be a subset of the best \(\mathsf{TB}^{-1}\) items (_golden items_) for user \(u\) namely \(\{\pi_{u}(t)\}_{t\in[\mathsf{TB}^{-1}]}\). Since the above facts are true for all users \(u\in\mathcal{M}^{(\ell+1,z)}\), we can also conclude that the new pruned set of items \(\mathcal{N}^{(\ell+1,t_{a+1},z)}\) at the next decision round \(t_{a+1}\) is a superset of the best \(\mathsf{TB}^{-1}-\left|\mathcal{O}_{\mathcal{M}^{(\ell+1,t_{a+1})}}^{(\ell+1,t _{a+1})}\right|\) items for every user \(u\). This completes the second part of the induction proof. 

**Lemma 16**.: _Conditioned on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\), with choice of \(\Delta_{\ell+1}=\epsilon_{\ell+1}/88\mathsf{C}\), conditions A-C will be satisfied at the beginning of the explore component of phase \(\ell\) for the different nice subsets \(\{\mathcal{M}^{(\ell+1,z)}\}_{z}\) and their corresponding set of active arms \(\{\mathcal{N}^{(\ell+1,z)}\}_{z}\) implying that the event \(\mathcal{E}_{2}^{(\ell+1)}\) will be true._

Proof.:
1. _Proof of condition A:_ Due to our induction hypothesis, condition A is true for the _explore_ component of phase \(\ell\). Hence, the _explore_ component of phase \(\ell\) is implemented separately and asynchronously for each disjoint _nice_ subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\subseteq\mathcal{M}^{( \ell)}\) (recall that \(\mathcal{M}^{\prime(\ell)}\) corresponds to the nice subsets of users which do not fall into the edge case scenarios). Let us fix one such nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\). After the successful low rank matrix completion step (event \(\mathcal{E}_{3}^{(\ell)}\) is true), we find the connected components of a graph \(\mathcal{G}^{(\ell,i)}\) which in turn correspond to nice subsets of users as well (see Lemma 7). Since the above facts are true for all nice subsets of users in \(\mathcal{M}^{\prime(\ell)}\), the _nice_ subsets of users that progress to the \((\ell+1)^{\text{th}}\) phase are disjoint. Since these set of users are not modified during the _exploit_ component of phase \(\ell+1\), condition A is true at the beginning of the _explore_ component of phase \(\ell+1\).
2. _Proof of conditions B and C:_ Again, let us fix a subset of nice users \(\mathcal{M}^{(\ell+1,z)}\) that has progressed to phase \(\ell+1\) and was in turn a part of the _nice_ subset of users \(\mathcal{M}^{(\ell,i)}\) in phase \(\ell\). In other words, the set of users \(\mathcal{M}^{(\ell+1,z)}\) corresponds to a connected component of the graph \(\mathcal{G}^{(\ell,i)}\). From Lemma 15, we can conclude that conditions B and C are true at the beginning of the _explore_ component of phase \(\ell+1\) for users in \(\mathcal{M}^{(\ell+1,z)}\) with choice of \(\Delta_{\ell+1}=\epsilon_{\ell+1}/88\mathsf{C}\) where \(\epsilon_{\ell+1}\) was pre-determined. Therefore, the conditions B and C hold for all nice subsets of users \(\{\mathcal{M}^{(\ell+1,z)}\}_{z}\) that have progressed to phase \(\ell+1\).

Hence, conditioned on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\), with choice of \(\Delta_{\ell+1}=\epsilon_{\ell+1}/88\mathsf{C}\), the algorithm will be \((\epsilon_{\ell+1},\ell+1)-\)good and the event \(\mathcal{E}_{2}^{(\ell+1)}\) will be true.

### Analyzing the regret guarantee

**Lemma 17**.: _Consider a fixed decreasing sequence \(\{\epsilon_{\ell}\}_{\ell\geq 1}\) where \(\epsilon_{1}=\left|\left|\mathbf{P}\right|\right|_{\infty}\) and \(\epsilon_{\ell}=C^{\prime}2^{-\ell}\min\left(\left|\mathbf{P}\right|\right|_{ \infty},\frac{\sigma\sqrt{\mu}}{\log\mathbf{N}}\right)\) for \(\ell>1\) for some constant \(C^{\prime}>0\). Let us denote the event \(\mathcal{E}=\bigcap_{\ell}\mathcal{E}_{2}^{(\ell)}\bigcap_{\ell}\mathcal{E}_{3 }^{(\ell)}\) to imply that our algorithm is \((\epsilon_{\ell},\ell)-\)good at all phases indexed by \(\ell\) and the explore components of all phases are successful with the length of the explore component of phase \(\ell\) being_

\[m_{\ell}=O\Big{(}\frac{\sigma^{2}\widetilde{\mu}^{3}\log(\mathsf{M}\bigvee \mathsf{N})}{\Delta_{\ell+1}^{2}}\max\Big{(}1,\frac{\mathsf{N}\tau}{\mathsf{M }}\Big{)}\log\mathsf{T}\Big{)}\Big{)}.\]

_The above statement implies that for any nice subset of users \(\mathcal{M}^{(\ell,i)}\) that has progressed to the \(\ell^{\text{th}}\) phase with active items \(\mathcal{N}^{(\ell,i)}\) at the beginning of the explore components, with \(m_{\ell}\) rounds, we can compute an estimate \(\widetilde{\mathbf{P}}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\) of \(\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\) satisfying_

\[\left|\left|\widetilde{\mathbf{P}}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}^{(\ell)}-\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}} \right|\right|_{\infty}\leq\Delta_{\ell+1}.\]

_In that case, the event \(\mathcal{E}\) is true with probability at least \(1-\mathsf{CT}^{-2}\)._

Proof.: Notice that

\[\Pr(\mathcal{E}^{c})=1-\Pr(\bigcup_{\ell}\mathcal{E}_{2}^{(\ell)c }\bigcup_{\ell}\mathcal{E}_{3}^{(\ell)c})\] \[\geq 1-(\Pr(\mathcal{E}_{2}^{(1)c})+\Pr(\mathcal{E}_{3}^{(1)c} \mid\mathcal{E}_{2}^{(1)}))\] \[-\sum_{\ell>1}\Big{(}\Pr(\mathcal{E}_{2}^{(\ell)c}\mid\bigcap_{ \ell^{\prime}<\ell}(\mathcal{E}_{2}^{(\ell^{\prime})}\cap\mathcal{E}_{3}^{( \ell)}))+\Pr(\mathcal{E}_{3}^{(\ell)c}\mid\mathcal{E}_{2}^{(\ell)c},\bigcap_ {\ell^{\prime}<\ell}(\mathcal{E}_{2}^{(\ell^{\prime})}\cap\mathcal{E}_{3}^{( \ell)}))\Big{)}\] \[\geq 1-(\Pr(\mathcal{E}_{2}^{(1)c})+\Pr(\mathcal{E}_{3}^{(1)c} \mid\mathcal{E}_{2}^{(1)}))\] \[-\sum_{\ell>1}\Big{(}\Pr(\mathcal{E}_{2}^{(\ell)c}\mid\mathcal{E} _{2}^{(\ell-1)},\mathcal{E}_{3}^{(\ell-1)})+\Pr(\mathcal{E}_{3}^{(\ell)c}\mid \mathcal{E}_{2}^{(\ell)})\Big{)}\geq 1-\mathsf{CT}^{-2}\]

where we used the following facts 1) \(\Pr(\mathcal{E}_{2}^{(1)c})=0\) and \(\Pr(\mathcal{E}_{2}^{(\ell)c}\mid\mathcal{E}_{2}^{(\ell-1)},\mathcal{E}_{3}^{( \ell-1)})=0\) for all \(\ell\) (Lemma 16) 2) \(\Pr(\mathcal{E}_{3}^{(\ell)c}\mid\mathcal{E}_{2}^{(\ell)})\leq\mathsf{CT}^{-2}\) implied from Lemma 4 with additional union bounds over the number of phases (at most the number of rounds \(\mathsf{T}\)) and the number of disjoint nice subsets of users that have progressed in each phase (at most the number of clusters \(\mathsf{C}\)). An important fact to keep in mind is that the above analysis is possible since the observations used to compute estimates are never repeated in Alg. 2 and we are able to avoid complex dependencies. 

Now, we are ready to prove our main regret bound. Suppose we condition on the event \(\mathcal{E}\) as defined in Lemma 17. Conditioned on the event \(\mathcal{E}\), let us denote by \(\rho_{u}\) to be some sequence of items recommended to the user \(u\in[\mathsf{M}]\) by our algorithm. The probability of this sequence of items being recommended is \(\Pr(\cap_{u\in[\mathsf{M}]}\rho_{u}\mid\mathcal{E})\).

#### d.2.1 Swapping argument

Let us fix a particular user \(u\in[\mathsf{M}]\) and a sequence of recommended items \(\rho_{u}\) such that \(\rho_{u}(t)\in[\mathsf{N}]\) is the item recommended to user \(u\) at round \(t\). For sake of analysis, we will construct a permutation \(\theta_{u}:[\mathsf{T}]\rightarrow\{\rho_{u}(t)\}_{t\in[\mathsf{T}]}\) of the items \(\{\rho_{u}(t)\}_{t\in[\mathsf{T}]}\) with sequential modifications (\(\theta_{u}\) is initialized with \(\rho_{u}\)). For any phase indexed by \(\ell\), consider the _exploit_ and _explore_ components for a _nice_ subset of users \(\mathcal{M}^{(\ell,i)}\). The sequence of items recommended to user \(u\) during the _explore_ component remain unchanged i.e. for any phase \(\ell\), \(\theta_{u}(t)=\rho_{u}(t)\) for all rounds \(t\in[t]\) such that \(t\) corresponds to the _explore_ component of phase \(\ell\) for the user \(u\).

Now, for the exploit component in phase \(\ell\), recall that \(\mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{(\ell)}\setminus\mathcal{O}_{\mathcal{M} ^{(\ell,i)}}^{(\ell-1)}\) is the set of items chosen for recommendation particularly in the _exploit_ component of phase \(\ell\) (we remove the super-script \(t\) since we refer to the end of the _exploit_ components in phase \(\ell\) and phase \(\ell-1\) respectively). Suppose at round \(t\) in the _explore_ component of phase \(\ell\), the \(b^{\text{th}}\) item in the set \(\mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{(\ell)}\setminus\mathcal{O}_{\mathcal{M} ^{(\ell,i)}}^{(\ell-1)}\) was chosento be recommended to all users in \(\mathcal{M}^{(\ell,i)}\) but was found to be blocked for user \(u\in\mathcal{M}^{(\ell,i)}\) before it could be recommended \(\mathsf{B}\) times. Let us also denote \(\mathcal{N}^{(\ell,t_{a},i)}\) to be set of active items for users in \(\mathcal{M}^{(\ell,i)}\) at round \(t\) (i.e. \(t_{a}\) was the previous decision round where it was decided whether possibility A or possibility B was true). Since the \(b^{\text{th}}\) item in the set \(\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\setminus\mathcal{O}^{(\ell-1)}_ {\mathcal{M}^{(\ell,i)}}\) was blocked for user \(u\), instead we recommend any unblocked item for user \(u\) from the current set of active items \(\mathcal{N}^{(\ell,t_{a},i)}\). This is always possible; we showed in Lemma 15 (see eq. 23) that the active set of items always contain sufficient unblocked items for possible recommendations for remaining rounds for any user in the corresponding _nice_ subset of users during the exploit component. Now there are two possibilities:

1. (\(b^{\text{th}}\) _item in the set \(\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\setminus\mathcal{O}^{(\ell-1)}_ {\mathcal{M}^{(\ell,i)}}\) was recommended in round \(t^{\prime}\) in the explore component of previous phase \(\ell^{\prime}\))_ We consider the active set of items \(\mathcal{N}^{(\ell^{\prime},h)}\) (such that \(u\in\mathcal{M}^{(\ell^{\prime},h)}\) in phase \(\ell^{\prime}\)) where \(\ell^{\prime}<\ell\) is the phase index (and \(t^{\prime}\) is the round index) when the \(b^{\text{th}}\) item in \(\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\setminus\mathcal{O}^{(\ell-1)}_ {\mathcal{M}^{(\ell,i)}}\) (say \(a\)) was recommended to the user \(u\) during the _explore_ component. Let us denote the item that we have recommended as replacement to user \(u\) at round \(t\) by \(a^{\prime}\). Note that since \(a^{\prime}\in\mathcal{N}^{(\ell,t_{a},i)}\), it must happen that \(a^{\prime}\in\mathcal{N}^{(\ell^{\prime},h)}\) since \(\mathcal{N}^{(\ell,t_{a},i)}\subseteq\mathcal{N}^{(\ell^{\prime},h)}\). In that case, we have \[\rho_{u}(t)=a^{\prime}\text{ and }\rho_{u}(t^{\prime})=a\] We swap the above items so that in the modified sequence, we have \[\theta_{u}(t)=a\text{ and }\theta_{u}(t^{\prime})=a^{\prime}\] The goal of the swapping operation at round \(t\) in the _exploit_ component is to modify the sequence of items such that 1) the item \(a\) chosen for recommendation at round \(t\) is assigned to round \(t\) in the _exploit_ component 2) the item \(a\) actually recommended in round \(t^{\prime}<t\) and phase \(\ell^{\prime}<\ell\) is replaced by another item \(a^{\prime}\) (actually recommended at round \(t>t^{\prime}\) in phase \(\ell>\ell^{\prime}\)) such that both \(a,a^{\prime}\) belongs to the same set of active items \(\mathcal{N}^{(\ell^{\prime},h)}\) (\(u\in\mathcal{M}^{(\ell^{\prime},h)}\) for some \(h\)). We will also say that the item \(a\)_chosen for recommendation is replaced by a swapping operation of length \(1\)_. This is because the chosen element for recommendation \(a\) was recommended in the _explore_ component of a previous phase. A more precise definition of the _length of a swapping operation_ is provided below.
2. (\(b^{\text{th}}\) _item in the set \(\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\setminus\mathcal{O}^{(\ell-1)}_ {\mathcal{M}^{(\ell,i)}}\) was recommended in the exploit component of previous phase):_ This is the more difficult case. As before, let us denote the \(b^{\text{th}}\) item in the set \(\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\setminus\mathcal{O}^{(\ell-1)}_ {\mathcal{M}^{(\ell,i)}}\) by \(a\). Of course, the item \(a\) could not have been chosen for recommendation in the _exploit_ component of a previous phase (i.e. \(a\) cannot belong in the set \(\mathcal{O}^{(\ell^{\prime})}_{\mathcal{M}^{(\ell^{\prime},j)}}\setminus \mathcal{O}^{(\ell^{\prime}-1)}_{\mathcal{M}^{(\ell^{\prime},j)}}\) for any \(\ell^{\prime}<\ell\) with \(u\in\mathcal{M}^{(\ell^{\prime},j)}\) in phase \(\ell^{\prime}\).) In that case, the item \(a\) was recommended in the _exploit_ component of phase \(\ell\)_as part of a swapping operation_. With this intuition in mind, let us define _length of a swapping operation_ precisely:

**Definition 3** (Length of swapping operation).: _For a user \(u\), suppose \(a_{1}\in\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\setminus\mathcal{O}^{( \ell-1)}_{\mathcal{M}^{(\ell,i)}}\) is an item chosen for recommendation in the exploit component of phase \(\ell\) but found to be blocked. In that case, we will say that \(a_{1}\) is replaced by a swapping operation of length \(\mathsf{L}+1\) if there exists \(\mathsf{L}+1\) items \(a_{1},a_{2},\ldots,a_{\mathsf{L}},a_{\mathsf{L}+1}\), \(\mathsf{L}+1\) phases \(p_{1}>p_{2}>\cdots>p_{\mathsf{L}}>p_{\mathsf{L}+1}\) and respective rounds \(t_{1},t_{2},\ldots,t_{\mathsf{L}},t_{\mathsf{L}+1}\) such that 1) \(a_{1}\) is chosen for recommendation in exploit component of phase \(p_{1}\) at round \(t_{1}\)_) _for each \(2\leq i<\mathsf{L}\), \(a_{i-1}\) has been recommended in the exploit component of phase \(p_{i}\) at round \(t_{i}\) when the intended item chosen for recommendation was \(a_{i}\) 3) \(a_{\mathsf{L}}\) has been recommended in the explore component of phase \(p_{\mathsf{L}+1}\) at round \(t_{\mathsf{L}+1}\) 3) \(a_{\mathsf{L}+1}\) is the item recommended to user \(u\) in place of \(a_{1}\) in phase \(p_{1}\) at round \(t_{1}\)._

As before, \(a_{\mathsf{L}+1}\) belongs to current set of active items \(\mathcal{N}^{(\ell,t_{a},i)}\) at round \(t_{1}\) for users in \(\mathcal{M}^{(\ell,i)}\) (recall that \(t_{a}\) is the decision round just prior to \(t_{1}\)). In the above definition, note that \(\mathsf{L}\) must be finite since there are a finite number of components and the first phase only has an _explore_ component (recall that _exploit_ component in the first phase has zero rounds).

For a user \(u\in\mathcal{M}^{(\ell,i)}\), suppose \(a_{1}\in\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\setminus\mathcal{O}^{( \ell-1)}_{\mathcal{M}^{(\ell,i)}}\) is an item chosen for recommendation in the _exploit_ component of phase \(\ell\) but found to be blocked. Moreover suppose \(a_{1}\) must be _replaced by a swapping operation of length \(\mathsf{L}\)_ (see Definition 3 for notations). In that case, we make the following modifications to the permutation \(\theta_{u}\):

\[\theta_{u}(t_{i})=a_{i}\text{ for all }1\leq i\leq\mathsf{L}+1\]

**Lemma 18**.: _Condition on the event \(\mathcal{E}\). Consider the modified sequence of distinct items \(\{\theta_{u}(t)\}_{t\in[\mathcal{T}]}\) for a certain fixed user \(u\). For any phase \(\ell\) to which the user \(u\) has progressed as part of the nice subset \(\mathcal{M}^{(\ell,i)}\), consider the exploit component starting from round index \(t_{\mathsf{exploit,start},\ell}\) to \(t_{\mathsf{exploit,end},\ell}\). In that case, the set of elements \(\{\theta_{u}(t)\mid t\in[t_{\mathsf{exploit,start},\ell},t_{\mathsf{exploit,end},\ell}]\}\) is equivalent to the set of elements \(\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\setminus\mathcal{O}^{(\ell-1)}_ {\mathcal{M}^{(\ell,i)}}\) repeated \(\mathsf{B}\) times i.e. the golden items **chosen for recommendation** in the exploit component of phase \(\ell\) to users in \(\mathcal{M}^{(\ell,i)}\). Similarly, consider the explore component starting from round index \(t_{\mathsf{exploit,start},\ell}\) to \(t_{\mathsf{exploit,end},\ell}\). In that case, for any \(t\in[t_{\mathsf{exploit,start},\ell},t_{\mathsf{exploit,end},\ell}]\), it must happen that \(\theta_{u}(t)\in\mathcal{N}^{(\ell,i)}\) i.e. the set of active items for \(\mathcal{M}^{(\ell,i)}\) during the explore component of phase \(\ell\)._

Proof.: We start with the following claim.

**Claim 1**.: _For a user \(u\in\mathcal{M}^{(\ell,i)}\), suppose \(a_{1}\in\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\setminus\mathcal{O}^{( \ell-1)}_{\mathcal{M}^{(\ell,i)}}\) is an item chosen for recommendation in the exploit component of phase \(\ell\) at round \(t_{1}\) but found to be blocked for user \(u\). Moreover suppose \(a_{1}\) has been replaced by a swapping operation of length \(\mathsf{L}+1\) (see Definition 3 for notations). In that case, we already have \(\theta_{u}(t_{i})=a_{i}\) for all \(2\leq i\leq\mathsf{L}\). We only need to modify the sequence by making the following two changes: 1) \(\theta_{u}(t_{1})=a_{1}\) 2) \(\theta_{u}(t_{\mathsf{L}+1})=a_{\mathsf{L}+1}\). Note that in the true sequence, \(a_{\mathsf{L}+1}\) has been recommended in the round \(t_{1}\) replacing the intended item \(a_{1}\)._

Proof.: We will prove the claim via induction. Notation-wise, suppose for any \(\ell^{\prime}\leq\ell\), the user \(u\) belongs to the set \(\mathcal{M}^{(\ell^{\prime},i)}\) and the set of active items at round \(t_{1}\) for users in \(\mathcal{M}^{(\ell,i)}\) is denote by \(\mathcal{N}\) (for simplicity, we remove the superscripts). The base case for \(\mathsf{L}=0\) is true by construction - here the item \(a_{1}\) is recommended in the _explore_ component of phase \(p_{2}\) at round \(t_{2}\). We find an unblocked item \(a_{2}\) in the set \(\mathcal{N}\subseteq\mathcal{N}^{(\ell,i)}\) (note that items are never added to the active set across phases and only pruned), recommend it at round \(t_{1}\) according to our algorithm. For analysis, we modify

\[\theta_{u}(t_{1})=a_{1}\text{ and }\theta_{u}(t_{2})=a_{2}\]

Now, suppose our claim is true for some \(\mathsf{L}=l\). Now, for \(\mathsf{L}=l+1\), note that \(a_{1}\) was recommended in the _exploit_ component of phase \(p_{2}\) at round \(t_{2}\); this implies that \(a_{1}\) must have been used to replace another item \(a_{2}\) via a swapping operation of length \(l\). By our induction hypothesis, we must have \(\theta_{u}(t_{i})=a_{i}\) for all \(2\leq i\leq\mathsf{L}\) (as a matter of fact, we will have \(\theta_{u}(t_{\mathsf{L}+1})=a_{1}\)). Therefore, only the pair of modifications \(\theta_{u}(t_{1})=a_{1}\) and \(\theta_{u}(t_{\mathsf{L}+1})=a_{\mathsf{L}+1}\) suffice to bring the desired changes in \(\theta_{u}\). 

We can also conclude from Claim 1 that 1) at any round \(t\) in the _exploit_ component of some phase for user \(u\), if the chosen item to be recommended is found to be blocked, then that chosen item is brought to the \(t^{\text{th}}\) position in the sequence \(\theta_{u}\) 2) Once the chosen item is brought to its correct position in \(\theta_{u}\), it will not be modified/moved in any future round. 3) All chosen items for recommendation to user \(u\) corresponding to _exploit_ components are moved to their correct position (i.e. the intended round for their recommendation) in the sequence \(\theta_{u}\). Next we make the following claim:

**Claim 2**.: _Consider the setting in Claim 1. It must happen that all the items \(a_{1},a_{2},\ldots,a_{\mathsf{L}+1}\) must belong to the set \(\mathcal{N}^{(p_{\mathsf{L}+1},i)}\) - the set of active items in the phase \(p_{\mathsf{L}+1}\) for users in the nice subset \(\mathcal{M}^{\{p_{\mathsf{L}+1},i\}}\) to which \(u\) belongs and \(a_{\mathsf{L}}\) was recommended in its explore component._

Proof.: Again, note that items are never added to the active set across phases and only pruned. If an item \(a_{1}\) is replaced by \(a_{\mathsf{L}+1}\) via a swapping operation of length \(\mathsf{L}+1\), it implies that \(a_{1}\) was used to replace item \(a_{2}\) (via a swapping operation of length \(\mathsf{L}\)), \(a_{2}\) was used to replace \(a_{3}\) (via a swapping operation of length \(\mathsf{L}-1\)) and so on. The final golden item for user \(u\) in this sequence \(a_{\mathsf{L}}\) was recommended in phase \(p_{\mathsf{L}+1}\) in the explore component and belonged to the set of active items \(\mathcal{N}^{(p_{\mathsf{L}+1},i)}\). Hence, this implies that all the subsequent surviving items \(a_{1},a_{2},a_{3},\ldots,a_{\mathsf{L}-1},a_{\mathsf{L}+1}\) must have belonged to the set of active items \(\mathcal{N}^{(p_{\mathsf{L}+1},i)}\) as well. 

From Claim 2, we can conclude that for any round \(t\) in the _explore_ component of some phase \(\ell\) for user \(u\), if \(\rho_{u}(t)\) is replaced in the sequence \(\theta_{u}\) at round \(t\), then \(\rho_{u}(t),\theta_{u}(t)\) belong to the same set of active items \(\mathcal{N}^{(\ell,i)}\). With both these arguments, we complete the proof of the lemma.

#### d.2.2 Final Regret analysis

Let us condition on the event \(\mathcal{E}\). Consider any user \(u\in[\mathsf{M}]\) - recall that \(\{\rho_{u}(t)\}_{t\in[\mathsf{T}]}\) is the random variable denoting the sequence of \(\mathsf{T}\) items recommended to the user \(u\), \(\rho_{u}(t)\) is a realization of \(\{\rho_{u}(t)\}_{t\in[\mathsf{T}]}\) conditioned on the event \(\mathcal{E}\). Furthermore, \(\theta_{u}\) is the modified sequence - a permutation of the \(\mathsf{T}\) items \(\{\rho_{u}(t)\}\) recommended for user \(u\). For simplicity of notation, we will assume that \(u\in\mathcal{M}^{(\ell,i)}\) for every phase \(\ell\). Hence the active set of items during the _explore_ component of phase \(\ell\) for the _nice_ subset of users \(\mathcal{M}^{(\ell,i)}\) is denoted by \(\mathcal{N}^{(\ell,i)}\). Also, in line with our previous usage of notations, let us denote \(\mathcal{O}^{(\ell)}_{\mathcal{M}^{(\ell,i)}}\setminus\mathcal{O}^{(\ell-1)}_ {\mathcal{M}^{(\ell,i)}}\) to be the set of items chosen for recommendation particularly in the _exploit_ component of phase \(\ell\). Moreover, \(\mathcal{O}\) denotes the entire set of items chosen for recommendation in all the _exploit_ components to user \(u\). In other words, if \(\ell_{u}\) is the final phase to which user \(u\) has progressed then \(\mathcal{O}_{u}=\mathcal{O}^{(\ell_{u})}_{\mathcal{M}^{(\ell_{u})}}\). We denote the regret for the user \(u\) by

\[\mathsf{Reg}_{u}(\mathsf{T})\mid\mathcal{E}\hat{=}\mathbb{E}\Big{[}\Big{(} \sum_{t\in[\mathsf{T}]}\mathbf{P}_{u\pi_{u}(t)}-\mathbf{P}_{u\rho_{u}(t)} \Big{)}\mid\mathcal{E}\Big{]}\]

where the expectation is over the randomness in the algorithm and the noise in the observations. Note that with this notation, we have \(\mathsf{Reg}(\mathsf{T})\mid\mathcal{E}=\mathsf{M}^{-1}\sum_{u\in[\mathsf{M}] }\mathsf{Reg}_{u}(\mathsf{T})\mid\mathcal{E}\). We now have the following set of inequalities for regret of user \(u\):

\[\mathsf{Reg}_{u}(\mathsf{T})\mid\mathcal{E} \hat{=}\mathbb{E}\Big{[}\Big{(}\sum_{t\in[\mathsf{T}]}\mathbf{P} _{u\pi_{u}(t)}-\mathbf{P}_{u\rho_{u}(t)}\Big{)}\mid\mathcal{E}\Big{]}=\mathbb{ E}\Big{[}\Big{(}\sum_{t\in[\mathsf{T}]}\mathbf{P}_{u\pi_{u}(t)}-\mathbf{P}_{u \rho_{u}(t)}\Big{)}\mid\mathcal{E}\Big{]}\] \[=\sum_{\rho_{u}(t)}\Pr(\rho_{u}(t)=\rho_{u}(t)\mid\mathcal{E}) \Big{(}\sum_{t\in[\mathsf{T}]}\mathbf{P}_{u\pi_{u}(t)}-\mathbf{P}_{u\widetilde {\theta}_{u}(t)}\Big{)}.\]

Let us denote the set of rounds in the _exploit_ component of \(\ell^{\text{th}}\) phase by \(\mathsf{exploit}(\ell,\mathcal{M}^{(\ell,i)})\) and the _explore_ component of \(\ell^{\text{th}}\) phase by \(\mathsf{explore}(\ell,\mathcal{M}^{(\ell,i)})\). Therefore we can further decompose the regret for user \(u\) as follows:

\[\mathsf{Reg}_{u}(\mathsf{T})\mid\mathcal{E} =\sum_{\rho_{u}(t)}\Pr(\rho_{u}(t)=\rho_{u}(t)\mid\mathcal{E}) \Big{(}\sum_{t\in[\ell_{u}]}\sum_{t\in\mathsf{exploit}(\ell,\mathcal{M}^{( \ell,i)})}\Big{(}\mathbf{P}_{u\pi_{u}(t)}-\mathbf{P}_{u\widetilde{\theta}_{u}( t)}\Big{)}\] \[+\sum_{\ell\in[\ell_{u}]}\sum_{t\in\mathsf{explore}(\ell,\mathcal{ M}^{(\ell,i)})}\Big{(}\mathbf{P}_{u\pi_{u}(t)}-\mathbf{P}_{u\widetilde{ \theta}_{u}(t)}\Big{)}\Big{)}.\]

Next, our arguments are conditioned on the event \(\mathcal{E}\) and any sequence \(\rho_{u}(t)\) having a non-zero probability of appearing conditioned on event \(\mathcal{E}\). Recall in Lemma 15, we proved by induction that \(\mathcal{O}_{u}\subseteq\{\pi_{u}(t)\}_{t=1}^{T}\). Moreover, in Lemma 18, we proved that items chosen for recommendation in the _exploit_ components for user \(u\) are in their correct positions (i.e. the round when they were intended to be recommended but might have been found to be blocked) in the sequence \(\theta_{u}\). Consider a permutation of the best \(\mathsf{T}\) items for user \(u\)\(\sigma_{u}:[\mathsf{T}]\rightarrow\{\pi_{u}(t)\}_{t=1}^{\mathsf{T}}\) such that

\[\sigma_{u}(t)=\theta_{u}(t)\text{ for all }t\in\cup_{\ell}\mathsf{exploit}(\ell, \mathcal{M}^{(\ell,i)})\] \[\{\sigma_{u}(t)\}_{t\in\cup_{\ell}\mathsf{explore}(\ell,\mathcal{ M}^{(\ell,i)})}\equiv\{\pi_{u}(t^{\prime})\}_{t^{\prime}\in[\mathsf{T}]} \setminus\mathcal{O}_{u}\]

where in a round in any _exploit_ component, the permutation \(\sigma\) maps the item chosen for recommendation (which we know to be among the best \(\mathsf{T}\) items) for user \(u\) to that round. For any round belonging to the _explore_ component, the permutation \(\sigma\) arbitrarily maps the remaining items among the best \(\mathsf{T}\) items (namely the set \(\{\pi_{u}(t^{\prime})\}_{t^{\prime}\in[\mathsf{T}]}\setminus\mathcal{O}_{u}\)). Notice that \(\sum_{t\in[\mathsf{T}]}\mathbf{P}_{u\pi_{u}(t)}=\sum_{t\in[\mathsf{T}]} \mathbf{P}_{u\sigma_{u}(t)}\). Therefore, we can further decompose the regret as

\[\mathsf{Reg}_{u}(\mathsf{T})\mid\mathcal{E} =\sum_{\rho_{u}(t)}\Pr(\rho_{u}(t)=\rho_{u}(t)\mid\mathcal{E}) \Big{(}\sum_{t\in[\ell_{u}]}\sum_{t\in\mathsf{exploit}(\ell,\mathcal{M}^{(\ell,i )})}\Big{(}\mathbf{P}_{u\sigma_{u}(t)}-\mathbf{P}_{u\widetilde{\theta}_{u}(t)} \Big{)}\] \[+\sum_{\ell\in[\ell_{u}]}\sum_{t\in\mathsf{explore}(\ell,\mathcal{ M}^{(\ell,i)})}\Big{(}\mathbf{P}_{u\sigma_{u}(t)}-\mathbf{P}_{u\widetilde{ \theta}_{u}(t)}\Big{)}\Big{)}\] \[=\sum_{\rho_{u}(t)}\Pr(\rho_{u}(t)=\rho_{u}(t)\mid\mathcal{E}) \Big{(}\sum_{t\in[\ell_{u}]}\sum_{t\in\mathsf{explore}(\ell,\mathcal{M}^{(\ell,i )})}\Big{(}\mathbf{P}_{u\sigma_{u}(t)}-\mathbf{P}_{u\widetilde{\theta}_{u}(t)} \Big{)}\Big{)}\]For the explore component in the phase indexed by \(\ell\), we have proved in Lemma 14 that the active set of items \(\mathcal{N}^{(\ell,i)}\) is a superset of \(\{\pi_{u}(t^{\prime})\}_{t^{\prime}\in[\mathsf{T}]}\setminus\mathcal{O}_{u}\). Therefore, we can bound (using Lemma 4 and condition C stated at beginning of sec. D.1) for any \(\ell\neq\ell_{u}\) (\(\ell_{u}\) denotes index of the final phase that user \(u\) was part of)

\[\sum_{t\in\mathsf{explore}(\ell,\mathcal{M}^{(\ell,i)})}\Big{(}\mathbf{P}_{u \sigma_{u}(t)}-\mathbf{P}_{u\widetilde{\theta}_{u}(t)}\Big{)}\leq m_{\ell} \cdot\epsilon_{\ell}=O\Big{(}\frac{\sigma^{2}\widetilde{\mu}^{3}\log(\mathsf{M }\bigvee\mathsf{N})}{\Delta_{\ell+1}^{2}}\max\Big{(}1,\frac{\mathsf{N}\tau}{ \mathsf{M}}\big{)}\log\mathsf{T}\Big{)}\Big{)}\Big{)}\cdot\epsilon_{\ell}.\]

where \(\widetilde{\mu}\) is the incoherence factor of the sub-matrix \(\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\). Next, using the facts that \(\Delta_{\ell+1}=\epsilon_{\ell+1}/88\mathsf{C}\), \(2\epsilon_{\ell}=\epsilon_{\ell+1}\), \(\mathsf{C},\tau=O(1)\), we get that (after hiding log factors for simplicity)

\[\sum_{t\in\mathsf{explore}(\ell,\mathcal{M}^{(\ell,i)})}\Big{(}\mathbf{P}_{u \sigma_{u}(t)}-\mathbf{P}_{u\widetilde{\theta}_{u}(t)}\Big{)}=\widetilde{O} \Big{(}\frac{\sigma^{2}\widetilde{\mu}^{3}}{\epsilon_{\ell}}\max\Big{(}1,\frac{ \mathsf{N}}{\mathsf{M}}\Big{)}\Big{)}=\widetilde{O}\Big{(}\frac{\sigma^{2} \mu^{3}}{\epsilon_{\ell}}\max\Big{(}1,\frac{\mathsf{N}}{\mathsf{M}}\Big{)} \Big{)}.\]

In the above statement, from Lemmas 2 and 3, we also used the fact that \(\widetilde{\mu}=O(\mu)\) and the condition number of the sub-matrix \(\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\) is \(O(1)\). Finally, for the _explore_ component of the final phase \(\ell_{u}\), from Lemma 11, we will also have (in the final phase, one of the edge case scenarios might appear)

\[\sum_{t\in\mathsf{explore}(\ell,\mathcal{M}^{(\ell,i)})}\Big{(}\mathbf{P}_{u \sigma_{u}(t)}-\mathbf{P}_{u\widetilde{\theta}_{u}(t)}\Big{)}=\widetilde{O} \Big{(}\sigma\mu^{3/2}\max\Big{(}\sqrt{\mathsf{T}},\sqrt{\frac{\mathsf{T}^{2} }{\mathsf{M}}}\Big{)}\Big{)}+\widetilde{O}\Big{(}\frac{\sigma^{2}\mu^{3}}{ \epsilon_{\ell_{u}}}\max\Big{(}1,\frac{\mathsf{N}}{\mathsf{M}}\Big{)}\Big{)}\]

Hence, we can put together everything to conclude that

\[\sum_{\ell\in[\ell_{u}]}\sum_{t\in\mathsf{explore}(\ell,\mathcal{ M}^{(\ell,i)})}\Big{(}\mathbf{P}_{u\sigma_{u}(t)}-\mathbf{P}_{u\widetilde{ \theta}_{u}(t)}\Big{)}\] \[=\sum_{\ell}\widetilde{O}\Big{(}\frac{\sigma^{2}\mu^{3}}{\epsilon _{\ell}}\max\Big{(}1,\frac{\mathsf{N}}{\mathsf{M}}\Big{)}\Big{)}+\widetilde{O }\Big{(}\sigma\mu^{3/2}\max\Big{(}\sqrt{\mathsf{T}},\sqrt{\frac{\mathsf{T}^{2} }{\mathsf{M}}}\Big{)}\Big{)}\] \[\leq\sum_{\ell:\epsilon_{\ell}\leq\Phi}m_{\ell}\Phi+\sum_{\ell: \epsilon_{\ell}\geq\Phi}\widetilde{O}\Big{(}\frac{\sigma^{2}\mu^{3}}{\Phi} \max\Big{(}1,\frac{\mathsf{N}}{\mathsf{M}}\Big{)}\Big{)}+\widetilde{O}\Big{(} \sigma\mu^{3/2}\max\Big{(}\sqrt{\mathsf{T}},\sqrt{\frac{\mathsf{T}^{2}}{ \mathsf{M}}}\Big{)}\Big{)}\] \[\leq\mathsf{T}\Phi+\mathsf{J}\cdot\widetilde{O}\Big{(}\frac{ \sigma^{2}\mu^{3}}{\Phi}\max\Big{(}1,\frac{\mathsf{N}}{\mathsf{M}}\Big{)}\Big{)} +\widetilde{O}\Big{(}\sigma\mu^{3/2}\max\Big{(}\sqrt{\mathsf{T}},\sqrt{\frac{ \mathsf{T}^{2}}{\mathsf{M}}}\Big{)}\Big{)}\]

where \(\mathsf{J}\) is the number of phases with \(\epsilon_{\ell}\geq\Phi\). By choosing \(\Phi=\sqrt{\frac{\sigma^{2}\mu^{3}}{\mathsf{T}}\max\Big{(}1,\frac{\mathsf{N}} {\mathsf{M}}\Big{)}}\), we can bound

\[\sum_{\ell\in[\ell_{u}]}\sum_{t\in\mathsf{explore}(\ell,\mathcal{M}^{(\ell,i)}) }\Big{(}\mathbf{P}_{u\sigma_{u}(t)}-\mathbf{P}_{u\widetilde{\theta}_{u}(t)} \Big{)}=\widetilde{O}\Big{(}\mathsf{J}\sigma\mu^{3/2}\sqrt{\mathsf{T}\max\Big{(} 1,\frac{\mathsf{N}}{\mathsf{M}}\Big{)}}\Big{)}\]

where we used the fact that \(\mathsf{N}\gg\mathsf{T}\) and therefore the last term in the previous equation is a lower order term compared to the first two ones. Next, recall that we choose \(\epsilon_{\ell}=C^{\prime}2^{-\ell}\min\Big{(}\|\mathbf{P}\|_{\infty},\frac{ \sigma_{\sqrt{\mathsf{T}^{2}}}}{\log\mathsf{N}}\Big{)}\) (so that the condition on \(\sigma>0\) in Lemma 1 is automatically satisfied for all \(\ell\)) for some constant \(C^{\prime}>0\), the maximum number of phases \(\ell\) for which \(\epsilon_{\ell}>\Phi\) can be bounded from above by \(\mathsf{J}=O\Big{(}\log\Big{(}\frac{1}{\Phi}\min\Big{(}\|\mathbf{P}\|_{\infty}, \frac{\sigma_{\sqrt{\mathsf{T}^{2}}}}{\log\mathsf{N}}\Big{)}\Big{)}\Big{)}\). Therefore, we can hide \(\mathsf{J}\) inside \(\widetilde{O}\) and obtain

\[\sum_{\ell\in[\ell_{u}]}\sum_{t\in\mathsf{explore}(\ell,\mathcal{M}^{(\ell,i)}) }\Big{(}\mathbf{P}_{u\sigma_{u}(t)}-\mathbf{P}_{u\widetilde{\theta}_{u}(t)} \Big{)}=\widetilde{O}\Big{(}\sigma\mu^{3/2}\sqrt{\mathsf{T}\max\Big{(}1,\frac{ \mathsf{N}}{\mathsf{M}}\Big{)}}\Big{)}.\]

Therefore, we must have that

\[\mathsf{Reg}_{u}(\mathsf{T})\mid\mathcal{E}=\widetilde{O}\Big{(}\sigma\mu^{3/2} \sqrt{\mathsf{T}\max\Big{(}1,\frac{\mathsf{N}}{\mathsf{M}}\Big{)}}\Big{)}\implies \mathsf{Reg}(\mathsf{T})\mid\mathcal{E}=\widetilde{O}\Big{(}\sigma\mu^{3/2} \sqrt{\mathsf{T}\max\Big{(}1,\frac{\mathsf{N}}{\mathsf{M}}\Big{)}}\Big{)}.\]

Finally, we use the fact that

\[\mathsf{Reg}(\mathsf{T})\leq\mathsf{Reg}(\mathsf{T})\mid\mathcal{E}+\Pr( \mathcal{E}^{c})(\mathsf{Reg}(\mathsf{T})\mid\mathcal{E}^{c}).\]

From Lemma 17, we know that \(\Pr(\mathcal{E}^{c})\leq\mathsf{CT}^{-2}\), \(\mathsf{Reg}(\mathsf{T})\mid\mathcal{E}^{c}\leq\mathsf{T}||\mathbf{P}||_{\infty}\) therefore,

\[\mathsf{Reg}(\mathsf{T})\leq\mathsf{Reg}(\mathsf{T})\mid\mathcal{E}+\Pr( \mathcal{E}^{c})(\mathsf{Reg}(\mathsf{T})\mid\mathcal{E}^{c})=\widetilde{O} \Big{(}\sigma\mu^{3/2}\sqrt{\mathsf{T}\max\Big{(}1,\frac{\mathsf{N}}{\mathsf{M}} \Big{)}}+\mathsf{T}^{-1}||\mathbf{P}||_{\infty}\Big{)}\]

which completes the proof of our main result.

Proof of Lower Bound (Theorem 2)

Consider our problem setting with \(\mathsf{M}\) users, \(\mathsf{N}\) items and \(\mathsf{T}\) rounds, blocking constraint \(\mathsf{B}\), noise variance proxy \(\sigma^{2}=1\) and all expected rewards in \([0,1]\). Here we consider \(\mathsf{C}=1\) i.e. all users belong to the same cluster. Let us denote a particular policy chosen by the recommendation system as \(\pi\) that belongs to the class of polices \(\Pi\). Moreover, let us also denote by \(\mathcal{E}\) the set of possible environments corresponding to the expected reward matrices that has all rows to be same (satisfies cluster structure for \(\mathsf{C}=1\)). In that case, the minimax regret is given by

\[\inf_{\pi\in\Pi}\sup_{\nu\in\mathcal{E}}\mathsf{Reg}(\mathsf{T};\mathcal{E})\]

### Lower Bound via reduction

We can ease the problem by assuming that at each round \(t=1,2,\ldots,\mathsf{T}\), the users come in a sequential fashion - the \(j^{\text{th}}\) user is recommended an item based on all previous history of observations including the feedback obtained from recommending items from users \(1,2,\ldots,j-1\) at round \(t\). Furthermore, we also assume that the \(\mathsf{N}\) items can be partitioned into \(\mathsf{NB}/\mathsf{T}\) known groups where each group has identical items - hence we have a simple multi-armed bandit problem (MAB) with \(\mathsf{NB}/\mathsf{T}\) arms and \(\mathsf{MT}\) rounds with a single user. A lower bound on this simplified MAB problem will imply a lower bound on our setting i.e by appropriately normalizing, we have

\[\inf_{\pi\in\Pi}\sup_{\nu\in\mathcal{E}}\mathsf{Reg}(\mathsf{T};\mathcal{E}) \geq\frac{1}{\mathsf{M}}\inf_{\pi\in\Pi}\sup_{\nu\in\mathcal{E}}\mathsf{Reg} _{\mathsf{MAB}}(\mathsf{MT};\mathcal{E})=\Omega\Big{(}\frac{1}{\mathsf{M}} \sqrt{\frac{\mathsf{NB}}{\mathsf{T}}}\cdot\mathsf{MT}\Big{)}=\Omega\Big{(} \sqrt{\frac{\mathsf{NB}}{\mathsf{M}}}\Big{)}\]

where we simply used the standard regret lower bound in multi-armed bandits with \(\mathsf{K}\) arms and \(\mathsf{T}\) rounds which is \(\Omega(\sqrt{\mathsf{KT}})\)[19].

### Lower Bound via application of Fano's inequality

As before, we can ease the original problem by assuming that at each round \(t=1,2,\ldots,\mathsf{T}\), the users come in a sequential fashion - the \(j^{\text{th}}\) user is recommended an item based on all previous history of observations including the feedback obtained from recommending items from users \(1,2,\ldots,j-1\) at round \(t\). Clearly, a lower bound on the simplified problem will imply a lower bound on our setting i.e by appropriately normalizing, we have

\[\inf_{\pi\in\Pi}\sup_{\nu\in\mathcal{E}}\mathsf{Reg}(\mathsf{T};\mathcal{E}) \geq\frac{1}{\mathsf{M}}\inf_{\pi\in\Pi}\sup_{\nu\in\mathcal{E}}\mathsf{Reg} _{\mathsf{MAB}}(\mathsf{MT};\mathcal{E}).\]

Furthermore, ignoring the normalizing factor by \(\mathsf{M}\), for \(\mathsf{C}=1\), the simplified problem is equivalent to a standard Multi-armed bandit (MAB) problem with a single agent with \(\mathsf{MT}\) rounds and an additional hard constraint that each item can be pulled at most \(\mathsf{MB}\) times. We will construct \(\binom{\mathsf{N}}{\mathsf{TB}^{-1}}\) environments in the following way: let \(\mathcal{T}\equiv\{\mathcal{S}\subseteq[\mathsf{N}]\mid|\mathcal{S}|=\mathsf{ TB}^{-1}\}\) be the set of all subsets of \([\mathsf{N}]\) of size \(\mathsf{TB}^{-1}\). Now for each subset \(\mathcal{S}\in\mathcal{T}\), we construct an environment by assuming that the agent on pulling any arm in the set \(\mathcal{S}\) observes a random reward distributed according to \(\mathcal{N}(\Delta,1)\) and on pulling any arm outside the set \(\mathcal{S}\) observes a random reward distributed according to \(\mathcal{N}(0,1)\). This corresponds to the the reward matrix \(\mathbf{P}\) (in our original problem) having an entry \(\Delta\) in the \(\mathsf{TB}^{-1}\) columns indexed in \(\mathcal{S}\) and \(0\) in the remaining columns. Let \(\mathbb{E}_{\mathcal{S}},\mathbb{P}_{\mathcal{S}},\mathcal{E}_{\mathcal{S}}\) denote the expectation, probability measure and the environment if \(\mathcal{S}\in\mathcal{T}\) is the set of chosen columns for constructing the environment.

Next we assume that the set \(\mathcal{S}\) is chosen uniformly at random from \(\mathcal{T}\). Hence we must have

\[\inf_{\pi\in\Pi}\sup_{\nu\in\mathcal{E}}\mathsf{Reg}_{\mathsf{MAB}}(\mathsf{ MT};\mathcal{E})\geq\inf_{\pi\in\Pi}\mathbb{E}_{\mathcal{S}\sim\mathcal{T}} \mathsf{Reg}_{\mathsf{MAB}}(\mathsf{T};\mathcal{E}_{\mathcal{S}})\]

Fix any policy \(\pi\in\Pi\). Condition on the set \(\mathcal{S}\) being selected from \(\mathcal{T}\). Let \(\mathsf{R}(\mathcal{S})\) be the number of times arms indexed in the set \(\mathcal{S}\) are pulled in the \(\mathsf{MT}\) rounds. In that case we must have

\[\mathsf{Reg}_{\mathsf{MAB}}(\mathsf{T};\mathcal{E}_{\mathcal{S}})\geq\mathbb{ P}_{\mathcal{S}}(\mathsf{R}(\mathcal{S})\leq\frac{3\mathsf{MT}}{4})\frac{ \mathsf{MT}\Delta}{4}.\]

Now, consider the estimation problem of which set \(\mathcal{S}\) was selected from \(\mathcal{T}\). Let \(\widehat{X}\) be an estimator that takes as input the observations in the \(\mathsf{MT}\) rounds and returns a set \(\widehat{\mathcal{S}}\) in the following way: it finds \(\widehat{\mathcal{S}}\) as the set of \(\mathsf{T}\) arms that have been pulled the most number of times jointly and returns \(\widehat{\mathcal{S}}\) if \(\mathsf{R}(\widehat{\mathcal{S}})\geq 3\mathsf{MT}/4\) and the null set \(\emptyset\) otherwise. We consider the estimator \(\widehat{X}\) to make an error if it returns a set \(\widehat{\mathcal{S}}\) such that \(\widehat{\mathcal{S}}\cap\mathcal{S}\leq\mathsf{T}/4\mathsf{B}\). If the estimator \(\widehat{X}\) makes an error, note that \(\mathsf{R}(\widehat{\mathcal{S}})\geq 3\mathsf{MT}/4\) implies that \(\mathsf{R}(\widehat{\mathcal{S}}\setminus\mathcal{S})\geq\mathsf{MT}/2\) (since each arm can be pulled at most \(\mathsf{M}\) times) - hence, it implies that \(\mathsf{R}(\mathcal{S})\leq\mathsf{MT}/2\). Therefore, if we denote \(\mathsf{Error}\) as the error event, then we must have

\[\mathsf{Reg}_{\mathsf{MAB}}(\mathsf{T};\mathcal{E}_{\mathcal{S}}) \geq\mathbb{P}_{\mathcal{S}}(\mathsf{R}(\mathcal{S})\leq\frac{3\mathsf{MT}}{ 4})\frac{\mathsf{MT}\Delta}{4}\geq\mathbb{P}_{\mathcal{S}}(\mathsf{Error}) \frac{\mathsf{MT}\Delta}{4}\] \[\implies\inf_{\pi\in\Pi}\sup_{\nu\in\mathcal{E}}\mathsf{Reg}_{ \mathsf{MAB}}(\mathsf{MT};\mathcal{E})\geq\mathbb{P}(\mathsf{Error})\frac{ \mathsf{MT}\Delta}{4}=\mathbb{E}_{\mathcal{S}\sim\mathcal{T}}\mathbb{P}_{ \mathcal{S}}(\mathsf{Error})\frac{\mathsf{MT}\Delta}{4}\]

Therefore, our goal is to bound the quantity \(\mathbb{E}_{\mathcal{S}\sim\mathcal{T}}\mathbb{P}_{\mathcal{S}}(\mathsf{Error})\). At this point we have reduced our problem to a multiple hypothesis testing problem. Therefore, in order to lower bound the probability of the event \(\mathsf{Error}\), we use Fano's inequality for approximate recovery:

**Lemma** (Fano's inequality with approximate recovery [28]).: _For any random variables \(V,\widehat{V}\) on alphabets \(\mathcal{V},\widehat{V}\), consider an error when \(d(V,\widehat{V})\geq t\) for some \(t>0\) and distance function \(d:\mathcal{V}\times\widehat{\mathcal{V}}\to\mathbb{R}\). In that case, if we denote the error event by \(\mathsf{Error}\), we must have_

\[\mathbb{P}(\mathsf{Error})\geq 1-\frac{I(V;\widehat{V})+\log 2}{\log\frac{| \mathcal{V}|}{\mathsf{G}_{\max}}}\]

_where \(\mathsf{G}_{\max}=\max_{\widehat{v}\in\widehat{\mathcal{V}}}\sum_{v\in \mathcal{V}}1[d(v,\hat{v})\leq t]\) and \(I(V;\widehat{V})\) is the mutual information between the random variables \(V\) and \(\widehat{V}\)._

In the special case when the random variable \(V\) is uniform, then we can upper bound the mutual information by \(I(V;\widehat{V})\leq\max_{v,\widehat{v}\in\mathcal{V}}\mathsf{KL}(P_{\widehat {V}|V=v}||P_{\widehat{V}|V=v^{\prime}})\leq\max_{v,\widehat{v}\in\mathcal{V} }\mathsf{KL}(P_{v}||P_{v^{\prime}})\) where the second inequality follows from Data-processing inequality (\(P_{v}=P(\cdot\mid v)\) corresponds to the probability of the observations given \(V=v\)).

Next, we apply it to our setting to prove an estimation error lower bound for our designed estimator \(\widehat{X}\). In our setting, \(\mathsf{G}_{\max}\) corresponds to the maximum possible number of sets in \(\mathcal{T}\) that have intersection of size more than \(\mathsf{T}/4\mathsf{B}\) with some fixed set \(\mathcal{S}\in\mathcal{T}\). Clearly we have

\[\mathsf{G}_{\max}\leq\sum_{t=\mathsf{T}/4\mathsf{B}+1}^{\mathsf{T}}\binom{ \mathsf{N}-\mathsf{T}}{\mathsf{T}-t}\binom{\mathsf{T}}{t}\leq\mathsf{T}\binom{ \mathsf{N}-\mathsf{T}}{\mathsf{T}-\mathsf{T}/4\mathsf{B}}\binom{\mathsf{T}}{ \mathsf{T}/4}\leq\mathsf{T}\Big{(}\frac{2\mathsf{N}e}{\mathsf{T}}\Big{)}^{ \mathsf{T}-\mathsf{T}/4\mathsf{B}}\Big{(}4e\Big{)}^{\mathsf{T}/4\mathsf{B}}.\]

Furthermore, in our setting, we also have that

\[\max_{\mathcal{S},\mathcal{S}^{\prime}\in\mathcal{T}}\mathsf{KL} (P_{\mathcal{S}}||P_{\mathcal{S}^{\prime}})\] \[\leq\sum_{i\in\mathcal{S}\cup\mathcal{S}^{\prime}}\mathbb{E}_{ \mathcal{S}}\mathsf{R}(\{i\})\max(\mathsf{KL}(\mathcal{N}(0,1)||\mathcal{N}( \Delta,1)),\mathsf{KL}(\mathcal{N}(\Delta,1)||\mathcal{N}(0,1)))\leq 2\mathsf{MBT}\Delta^{2}\]

- this follows from the fact that the distributions \(P_{\mathcal{S}},P_{\mathcal{S}^{\prime}}\) are most separated in \(\mathsf{KL}\)-Divergence if \(\mathcal{S}\cap\mathcal{S}^{\prime}=\emptyset\) and by using the fact that each arm can be pulled at most \(\mathsf{MB}\) times. Therefore, we must have (provided \(\mathsf{N}=c\mathsf{T}\) for some large enough constant \(c>0\), and \(\mathsf{T}\) is large enough) for some constant \(c^{\prime}>0\)

\[\mathbb{P}(\mathsf{Error}) \geq 1-\frac{I(\mathcal{S};\widehat{S})+\log 2}{\log\frac{| \mathcal{T}|}{\mathsf{G}_{\max}}}\geq 1-\frac{2\mathsf{MBT}\Delta^{2}+\log 2}{\log\Big{(}\frac{( \mathsf{N}/\mathsf{T})^{\mathsf{T}}}{\mathsf{T}-\mathsf{T}/4\mathsf{B}}\Big{(}4e \Big{)}^{\mathsf{T}/4\mathsf{B}}\Big{)}}\] \[\geq 1-\frac{2\mathsf{MB}^{2}\mathsf{T}\Delta^{2}+\mathsf{B}\log 2}{c^{ \prime}\log(\mathsf{N}/\mathsf{T})}\geq 0.9-\frac{2\mathsf{MB}\Delta^{2}}{c^{ \prime}\log(\mathsf{N}/\mathsf{T})}.\]

Therefore, substituting \(\Delta=\frac{c^{\prime}\sqrt{\log(\mathsf{N}/\mathsf{T})}}{\mathsf{B}\sqrt{ \mathsf{M}}}\), we have that for some constant \(c^{\prime\prime}\geq 0\)

\[\inf_{\pi\in\Pi}\sup_{\nu\in\mathcal{E}}\mathsf{Reg}_{\mathsf{MAB}}(\mathsf{MT}; \mathcal{E})\geq c^{\prime\prime}\mathsf{TB}^{-1}\sqrt{\mathsf{M}\log(\mathsf{N}/ \mathsf{T})}\]

and therefore

\[\inf_{\pi\in\Pi}\sup_{\nu\in\mathcal{E}}\mathsf{Reg}(\mathsf{T};\mathcal{E}) \geq\frac{1}{\mathsf{M}}\inf_{\pi\in\Pi}\sup_{\nu\in\mathcal{E}}\mathsf{Reg}_{ \mathsf{MAB}}(\mathsf{MT};\mathcal{E})=\Omega\Big{(}\frac{\mathsf{T}\sqrt{\log( \mathsf{N}/\mathsf{T})}}{\mathsf{B}\sqrt{\mathsf{M}}}\Big{)}.\]```
0: Phase index \(\ell\), List of disjoint nice subsets of users \(\mathcal{M}^{(\ell)}\), list of corresponding subsets of active items \(\mathcal{N}^{(\ell)}\), clusters \(\mathsf{C}\), rounds \(\mathsf{T}\), noise \(\sigma^{2}>0\), round index \(t_{0}\), exploit rounds \(t_{\text{exploit}}\), estimate \(\widetilde{\mathbf{P}}\) of \(\mathbf{P}\), incoherence \(\mu\), entry-wise error guarantee \(\epsilon_{\ell}\) of \(\widetilde{\mathbf{P}}\) restricted to all users in \(\mathcal{M}^{(\ell)}\) and all items in \(\mathcal{N}^{(\ell)}\), count matrix \(\mathbf{K}\in\mathbb{N}^{\mathsf{M}\times\mathsf{N}}\).
1:for\(i^{\text{th}}\) nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{(\ell)}\) with active items \(\mathcal{N}^{(\ell,i)}\) (\(i^{\text{th}}\) set in list \(\mathcal{N}^{(\ell)}\)) do
2: Set \(t=t_{0}\). Set \(\epsilon_{\ell+1}=\epsilon_{\ell}/2\), \(\Delta_{\ell}=\epsilon_{\ell}/88\mathsf{C}\) and \(\Delta_{\ell+1}=\epsilon_{\ell+1}/88\mathsf{C}\).
3: Run exploit component for users in \(\mathcal{M}^{(\ell,i)}\) with active items \(\mathcal{N}^{(\ell,i)}\). Obtain updated active set of items, round index and exploit rounds \(\mathcal{N}^{(\ell,i)},t,t_{\text{exploit}}\leftarrow\text{Exploit\_Item\_Cluster}( \mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)},t,t_{\text{exploit}},\widetilde{ \mathbf{P}}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}},\Delta_{\ell})\).
4: Set \(d_{1}=\max(|\mathcal{M}^{(\ell,i)}|,|\mathcal{N}^{(\ell,i)}|)\), \(d_{2}=\min(|\mathcal{M}^{(\ell,i)}|,|\mathcal{N}^{(\ell,i)}|)\) and \(p=c\Big{(}\frac{\sigma^{2}\mu^{3}\log d_{1}}{\Delta_{\ell+1}^{2}d_{2}}\Big{)}\) for some appropriate fixed constant \(c>0\).
5:if\(|\mathcal{N}^{(\ell,i)}|\geq\mathsf{T}^{1/3}\) and \(p<1\)then
6: Run explorement for users in \(\mathcal{M}^{(\ell,i)}\) with active items \(\mathcal{N}^{(\ell,i)}\). Obtain updated estimate and round index \(\widetilde{\mathbf{P}},t\leftarrow\text{Explo\_Item\_Cluster}( \mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)},t,p)\) such that \(\Big{|}\bigg{|}\widetilde{\mathbf{P}}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{( \ell,i)}}-\mathbf{P}_{\mathcal{M}^{(\ell,i)},\mathcal{N}^{(\ell,i)}}\Big{|} \bigg{|}_{\infty}\leq\Delta_{\ell+1}\) w.h.p.
7: For every user \(u\in\mathcal{M}^{(\ell,i)}\), compute \(\mathcal{T}_{u}^{(\ell)}\equiv\{j\in\mathcal{N}^{(\ell,i)}\mid\widetilde{ \mathbf{P}}_{u\pi_{u}(\mathsf{T}-t_{\text{exploit}})}-\widetilde{\mathbf{P}}_ {uj}\leq 2\Delta_{\ell+1}\}\).
8: Construct graph \(\mathcal{G}^{(\ell,i)}\) whose nodes are users in \(\mathcal{M}^{(\ell,i)}\) and an edge exists between two users \(u,v\in\mathcal{M}^{(\ell,i)}\) if \(\left|\widetilde{\mathbf{P}}_{ux}^{(\ell)}-\widetilde{\mathbf{P}}_{v}^{(\ell) }\right|\leq 2\Delta_{\ell+1}\) for all arms \(x\in\mathcal{N}^{(\ell,i)}\).
9: Initialize lists \(\mathcal{M}_{i}^{(\ell+1)}=[]\) and \(\mathcal{N}_{i}^{(\ell+1)}=[]\).
10: For each connected component \(\mathcal{M}^{(\ell,i,j)}\) (\(\cup_{j}\mathcal{M}^{(\ell,i,j)}\equiv\mathcal{M}^{(\ell,i)}\)), compute \(\mathcal{N}^{(\ell,i,j)}\equiv\cup_{u\in\mathcal{M}^{(\ell,i)}}\mathcal{T}_{u}^ {(\ell)}\).
11: For each connected component \(\mathcal{M}^{(\ell,i,j)}\), construct graph \(\mathcal{G}_{\text{item}}^{(\ell,i,j)}\) whose nodes are items in \(\mathcal{N}^{(\ell,i)}\) and an edge exists between two items \(u,v\in\mathcal{N}^{(\ell,i)}\) if \(\left|\widetilde{\mathbf{P}}_{xu}^{(\ell)}-\widetilde{\mathbf{P}}_{xv}^{( \ell)}\right|\leq 16\mathsf{C}\Delta_{\ell+1}\) for all users \(x\in\mathcal{M}^{(\ell,i,j)}\). Update \(\mathcal{N}^{(\ell,i,j)}\) to be the set of items \(\mathcal{N}^{(\ell,i,j)}\equiv\{x\in\mathcal{N}^{(\ell,i)}\mid x\text{ is connected with some node in}\mathcal{N}^{(\ell,i,j)}\}\).
12: Invoke B-LATTICE(\(\ell+1,\mathcal{M}_{i}^{(\ell+1)},\mathcal{N}_{i}^{(\ell+1)}\), \(\mathsf{C}\), \(\mathsf{T}.\sigma^{2},t,t_{\text{exploit}},\widetilde{\mathbf{P}},\epsilon_{ \ell+1},\mathbf{K},\mathcal{G}_{\text{item}}^{(\ell,i,j)}\)).
13:else
14: For each user \(u\in\mathcal{M}^{(\ell,i)}\), recommend \(\mathsf{T}-t\) unblocked items in \(\mathcal{N}^{(\ell,i)}\) until end of rounds.
15:endif
16:endfor ```

**Algorithm 7** BBUIC (Blocked Latent Bandits with User and Item Clusters)

## Appendix F Blocked Bandits having User and Item Clusters with blocking constraint \(\mathsf{B}=1\)

Recall that in this setting, the \(\mathsf{N}\) items can be grouped into \(\mathsf{C}^{\prime}\) disjoint clusters \(\mathsf{D}^{(1)},\mathsf{D}^{(2)},\ldots,\mathsf{D}^{(\mathsf{C}^{\prime})}\) that are unknown. The expected reward for user \(u\) (belonging to cluster \(a\in[\mathsf{C}]\)) on being recommended item \(j\) (belonging to cluster \(b\in[\mathsf{C}^{\prime}]\)) is \(\mathbf{P}_{ij}=\mathbf{Q}_{ab}\) where \(\mathbf{Q}\in\mathbb{R}^{\mathsf{C}\times\mathsf{C}^{\prime}}\) is the small core reward matrix (unknown). In this setting, we provide our theoretical guarantees with \(\mathsf{B}=1\) i.e. any item can be recommended to a user only once under the blocking constraint.

Recall that the main reason our theoretical analysis required \(\mathsf{B}=\Theta(\log\mathsf{T})\) for Thm. 1 setting is that if the observations that were used to compute estimates of some reward sub-matrix in a certain phase with certain guarantees that hold with some probability, then conditioning on such estimates with the said guarantees make the aforementioned observations dependent in analysis of future phases. In the \(\mathsf{B}\mathsf{B}\mathsf{B}\mathsf{C}\) setting, we show that in each phase, the possibility of the nice subsets of users and their corresponding active items is actually bounded and small. On the other hand, the possibilities were exponentially large in the number of items in the \(\mathsf{G}\mathsf{B}\mathsf{B}\) setting. Therefore, we can use a _for all_ argument here implying that for a set of already used observations, we can show that for all possible nice subsets of users and their active items, they can be used again to compute acceptable estimates. Such an analysis allows us to provide theoretical guarantees even with \(\mathsf{B}=1\) for the \(\mathsf{B}\mathsf{B}\mathsf{B}\mathsf{C}\) setting.

```
0: Phase index \(\ell\), nice subset of users \(\mathcal{M}\), active items \(\mathcal{N}\), round index \(t_{0}\), sampling probability \(p\).
1: For each tuple of indices \((i,j)\in\mathcal{M}\times\mathcal{N}\), independently set \(\delta_{ij}=1\) with probability \(p\) and \(\delta_{ij}=0\) with probability \(1-p\).
2: Denote \(\Omega=\{(i,j)\in\mathcal{M}\times\mathcal{N}\mid\delta_{ij}=1\}\) and \(m=\max_{i\in\mathcal{M}}\mid|j\in\mathcal{N}\mid(i,j)\in\Omega|\) to be the maximum number of index tuples in a particular row. Initialize observations corresponding to indices in \(\Omega\) to be \(\mathcal{A}=\phi\).
3:for rounds \(t=t_{0}+1,t_{0}+2,\ldots,t_{0}+m\)do
4:for each user \(u\in\mathcal{M}\)do
5: Find an item \(z\) in \(\{j\in\mathcal{N}\mid(u,j)\in\Omega,\delta_{uj}=1\}\). If \(\mathbf{K}_{uz}==0\) (\(z\) is unblocked), set \(\rho_{u}(t)=z\) and recommend \(z\) to user \(u\). Observe \(\mathbf{R}^{(t)}_{u\rho_{u}(t)}\) and update \(\mathcal{A}=\mathcal{A}\cup\{\mathbf{R}^{(t)}_{u\rho_{u}(t)}\}\), \(\mathbf{K}_{uz}\gets 1\).
6: If \(\mathbf{K}_{uz}==1\) (\(z\) is blocked), recommend any unblocked item \(\rho_{u}(t)\) in \(\mathcal{N}\) s.t. \((u,\rho_{u}(t))\not\in\Omega\). Update \(\mathbf{K}_{u\rho_{u}(t)}\gets 1\). Set \(\mathcal{A}=\mathcal{A}\cup\{\mathbf{R}^{(t^{\prime})}_{u\rho_{u}(t^{\prime})}\}\) where \(t^{\prime}<t\) is the round when \(\rho_{u}(t^{\prime})=z\) was recommended to user \(u\).
7:endfor
8:endfor
9: Compute the estimate \(\widetilde{\mathbf{P}}=\texttt{Estimate}(\mathcal{M},\mathcal{N},\sigma^{2}, \mathsf{C},\Omega,\mathcal{A})\) and return \(\widetilde{\mathbf{P}},t_{0}+m\). ```

**Algorithm 8** Exploit_Item_Cluster(Exploit Component of a phase)

Therefore in Algorithm 7 for the \(\mathsf{B\ddot{B}IC}\) setting, we only have a single counter matrix \(\mathbf{K}\in\{0,1\}^{\mathsf{M}\times\mathsf{N}}\) which is binary. The matrix \(\mathbf{K}\) is initialized to be a zero matrix. Whenever an item \(j\) is recommended to user \(i\), we set \(\mathbf{K}_{ij}=1\). If, in a future phase, we need to recommend item \(j\) to user \(i\) again, due to the blocking constraint, we simply reuse the observation (see Step 6 in Alg. 9).

### Algorithm and Discussion

We start with a definition for _nice subsets of items_ analogous to the _nice subset of users_ (see Definition 1).

**Definition 4**.: _A subset of items \(\mathcal{S}\subseteq[\mathsf{N}]\) will be called "nice" if \(\mathcal{S}\equiv\bigcup_{j\in\mathcal{A}}\mathcal{D}^{(j)}\) for some \(\mathcal{A}\subseteq[\mathsf{C}^{\prime}]\). In other words, \(\mathcal{S}\) can be represented as the union of some subset of clusters of items._

As in the analysis of \(\mathsf{\mathsf{GBB}}\) setting, we will have the desirable properties A-C that should be satisfied with high probability at the beginning of the _explore_ component of phase \(\ell\). Recall that we defined the event \(\mathcal{E}^{(\ell)}_{2}\) to be true if properties (A-C) are satisfied at the beginning of the _explore_ component of phase \(\ell\) by the phased elimination algorithm. Here, we stipulate a further property D that the corresponding surviving set of items for each nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{(\ell)}\) is also a _nice subset of items_.

Furthermore, we defined the event \(\mathcal{E}_{3}^{(\ell)}\) when eq. 10 is true for all nice subsets \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) in the explore component of phase \(\ell\). Algorithm 7 is a similar recursive algorithm as Algorithm 1 and the only modification is the addition of Step 11. As in Alg. 1, we instantiate Alg. 7 with phase index \(1\), list of _nice subsets_ of users having a single element comprising all users i.e. \(\mathcal{M}^{(1)}=[[\mathsf{M}]]\) and corresponding list of active items \(\mathcal{N}^{(1)}=[[\mathsf{N}]]\), clusters \(\mathsf{C}\), rounds \(\mathsf{T}\), blocking constraint \(\mathsf{B}\), noise \(\sigma^{2}\), round index \(1\), exploit rounds \(0\), estimate \(\widetilde{\mathbf{P}}\) to be \(\mathsf{O}^{\mathsf{M}\times\mathsf{N}}\), incoherence \(\mu\) and \(\epsilon_{1}=O\Big{(}\big{\|}\mathbf{P}\|_{\infty},\frac{\sigma\sqrt{\mu}}{\log M }\Big{)}\). Here, we will have a single count matrix \(\mathbf{K}\) which is binary and is initialized to be an all zero matrix. We are going to show recursively that conditioned on \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\), properties A-D will be satisfied at the beginning of phase \(\ell+1\).

**Base Case:** For \(\ell=1\) (the first phase), the number of rounds in the _exploit_ component is zero and we start with the _explore_ component. We initialize \(\mathcal{M}^{(1,1)}=[\mathsf{N}]\), \(\mathcal{N}^{(1,1)}=[\mathsf{M}]\) and therefore, we have

\[\Big{|}\max_{j\in\mathcal{N}^{(\ell,1)}}\mathbf{P}_{uj}-\min_{j\in\mathcal{N}^ {(\ell,1)}}\mathbf{P}_{uj}\Big{|}\leq\left|\left|\mathbf{P}\right|\right|_{ \infty}\text{ for all }u\in[\mathsf{M}].\]

Clearly, \([\mathsf{M}]\) is a _nice subset_ of users, \([\mathsf{N}]\) is a _nice subset_ of items and finally for every user \(u\in[\mathsf{M}]\), the best \(\mathsf{T}/\mathsf{B}\) items (_golden items_) \(\{\pi_{u}(t)\}_{t=1}^{\mathsf{T}/\mathsf{B}}\) belong to the entire set of items. Thus for \(\ell=1\), conditions A-D are satisfied at the beginning of the _explore_ component and therefore the event \(\mathcal{E}_{4}^{(1)}\) is true. Furthermore, from Lemma 4, eq. 10 is true for the first phase with probability \(1-o(\mathsf{T}^{-12})\) implying that the event \(\mathcal{E}_{3}^{(1)}\) is true with high probability.

**Inductive Argument:** Suppose, at the beginning of the phase \(\ell\), we condition on the events \(\bigcap_{j=1}^{\ell}\mathcal{E}_{2}^{(j)}\bigcap_{j=1}^{\ell}\mathcal{E}_{2}^ {(j)}\) that Algorithm is \((\epsilon_{j},j)-\)_good_ for all \(j\leq\ell\). This means that conditions (A-D) are satisfied at the beginning of the _explore_ component of all phases up to and including that of \(\ell\) for each reward sub-matrix (indexed by \(i\in[a_{\ell}]\)) corresponding to the users in \(\mathcal{M}^{(\ell,i)}\) and items in \(\mathcal{N}^{(\ell,i)}\). Furthermore, we also condition on the event eq. 10 is true for all nice subsets of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{(\ell)}\) and their corresponding set of items \(\mathcal{N}^{(\ell,i)}\) - implying that the event \(\mathcal{E}_{3}^{(\ell)}\) is true. Recall that for a user \(v\), the set \(\mathcal{T}_{v}^{(\ell)}\) was constructed as

\[\mathcal{T}_{v}^{(\ell)}\equiv\{j\in\mathcal{N}^{(\ell,i)}\mid\widetilde{ \mathbf{P}}_{vj}\geq\widetilde{\mathbf{P}}_{v\widetilde{\pi}_{v}(s^{\prime})| \mathcal{N}^{(\ell,i)}}-2\Delta_{\ell+1}\}\text{ where }s^{\prime}=\mathsf{TB}^{-1}-\Big{|} \mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{(\ell)}\Big{|}\] (33)

which implies that every item in \(\mathcal{T}_{v}^{(\ell)}\) is close to one of the _golden items_ in \(\mathcal{N}^{(\ell,i)}\). At the end of Step 10 in Alg. 7, we can still show that Lemma 9 holds for each set of users \(\mathcal{M}^{(\ell,i,j)}\) as they form a connected component. Notice that in Step 11 in Lemma 9, for each set of users \(\mathcal{M}^{(\ell,i,j)}\), we construct a graph \(\mathsf{G}_{\mathsf{item}}^{(\ell,i,j)}\) whose nodes correspond to the items in \(\mathcal{N}^{(\ell,i)}\) and an edge exists between two items \(u,v\in\mathcal{N}^{(\ell,i)}\) if \(\left|\widetilde{\mathbf{P}}_{xu}^{(\ell)}-\widetilde{\mathbf{P}}_{xv}^{(\ell)} \right|\leq 16\mathsf{C}\Delta_{\ell+1}\) for all users \(x\in\mathcal{M}^{(\ell,i,j)}\). Analogous to the proof of Lemma 7, we can conclude here as well that items in the same _item cluster_ form a clique. Therefore, any connected component in the graph \(\mathsf{G}_{\mathsf{item}}^{(\ell,i,j)}\) must correspond to a _nice_ subset of items since condition D is true and \(\mathcal{N}^{(\ell,i)}\) is already a nice subset of items. Hence the set of modified items \(\mathcal{N}^{(\ell,i,j)}\) constructed at the end of Step 11 in Alg. 7 is a _nice_ subset of items. Furthermore, we can also prove the corresponding version of Lemma 9:

**Lemma 19**.: _Condition on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\) being true. Consider a nice subset of users \(\mathcal{M}^{(\ell,i,j)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell,i,j)}\) for which guarantees in eq. 11 holds. Fix any set \(\mathcal{Y}=\mathcal{N}^{(\ell,i,j)}\setminus\mathcal{J}\) for some \(\mathcal{J}\) such that for every user \(u\in\mathcal{G}\), we have \(\widetilde{\pi}_{u}(s^{\prime})\mid\mathcal{N}^{(\ell,i,j)}\equiv\widetilde{ \pi}_{u}(s)\mid\mathcal{Y}\) for \(s^{\prime}=\mathsf{TB}^{-1}-\Big{|}\mathcal{O}_{\mathcal{M}^{(\ell,i)}}^{(\ell)}\) and some common index \(s\). In that case, we must have_

\[\max_{v\in\mathcal{G}}\Big{(}\max_{x,y\in\mathcal{Y}}\widetilde{\mathbf{P}}_{vx }-\widetilde{\mathbf{P}}_{vy}\Big{)}\leq\max_{u\in\mathcal{G}}\Big{(}\widetilde{ \mathbf{P}}_{u\widetilde{\pi}_{u}(1)|\mathcal{Y}}-\widetilde{\mathbf{P}}_{u \widetilde{\pi}_{u}(s^{\prime})|\mathcal{N}^{(\ell,i)}}\Big{)}+24(\mathsf{C}+ \mathsf{C}^{\prime})\Delta_{\ell+1}\]

Proof.: Note that with the analysis of Lemma 9, the conclusion was true for the constructed \(\mathcal{N}^{(\ell,i,j)}\) at the end of Step 10 in Alg. 7. However, in the modified set of items \(\mathcal{N}^{(\ell,i,j)}\), we are only addingitems in \(\mathcal{N}^{(\ell,i)}\) that either belong to the same cluster (in which case there is no added gap) or if we are adding items belonging to a different cluster, then the added gap on the RHS can be at most \(\mathsf{C}^{\prime}\Delta_{\ell+1}\). The above statement follows from a similar argument as in Lemma 13 where we showed that gap in expected reward between two users in \(\mathcal{M}^{(\ell,i,j)}\) (or rather two users connected by a path in \(\mathcal{G}^{(\ell,i)}\)) for the same item is at most \(O(\mathsf{C}\Delta_{\ell+1})\). 

Hence, we have shown that each subset of users \(\mathcal{M}^{(\ell,i,j)}\) is a _nice subset of users_ and furthermore, the corresponding subset of items constructed at the end of Step 11 is _nice subset of items_. Next, we move on to the _exploit_ component of phase \(\ell+1\) where we use a similar trick (See Step 3 in Alg. 8) to ensure that at the end, we are left with a _nice subset of items_. As before, we can show that the constructed set of items \(\mathcal{S}\) is itself a _nice subset of items_. We can again prove the following modified version of Corollary 2

**Corollary 3**.: _Condition on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\) being true. Consider a nice subset of users \(\mathcal{M}^{(\ell,i)}\in\mathcal{M}^{\prime(\ell)}\) and their corresponding set of active items \(\mathcal{N}^{(\ell,i)}\) for which guarantees in eq. 11 holds. Fix any subset \(\mathcal{Y}\subseteq\mathcal{N}^{(\ell,i)}\). Consider two users \(u,v\in\mathcal{M}^{(\ell,i)}\) having a path in the graph \(\mathcal{G}^{(\ell,i)}\). Conditioned on the events \(\mathcal{E}_{2}^{(\ell)},\mathcal{E}_{3}^{(\ell)}\), we must have_

\[\max_{x,y\in\mathcal{S}}|\mathbf{P}_{ux}-\mathbf{P}_{uy}|\leq 16(\mathsf{C}+ \mathsf{C}^{\prime})\Delta_{\ell+1}\text{ and }\max_{x,y\in\mathcal{S}}|\mathbf{P}_{vx}- \mathbf{P}_{vy}|\leq 16(\mathsf{C}+\mathsf{C}^{\prime})\Delta_{\ell+1}\]

_where \(\mathcal{S}\equiv\{z\in\mathcal{N}^{(\ell,i,j)}\mid z\text{ is connected with }\mathcal{R}_{u}^{(\ell)}\cup\mathcal{R}_{v}^{(\ell)}\}\)._

Proof.: The proof again follows from the fact that adding items belonging to a different cluster but connected via a path to the original items in \(\mathcal{R}_{u}^{(\ell)}\cup\mathcal{R}_{V}^{(\ell)}\) can only add a term of at most \(16\mathsf{C}^{\prime}\Delta_{\ell+1}\) in the RHS. 

Therefore, at the beginning of the _explore_ component of phase \(\ell+1\) for a particular _nice_ subset of users \(\mathcal{M}^{(\ell+1,z)}\), the corresponding set of items \(\mathcal{N}^{(\ell+1,z)}\) must be a _nice_ subset of items as well. Most importantly, what this implies is that for the low rank matrix completion step in the _explore_ component of phase \(\ell+1\), we can re-use observations from previous phases and provide theoretical guarantees as well. This is because, in eq. 10 in Lemma 4, we can take a union bound over all possible _nice subsets of users_ and _all possible nice subsets of items_. Since the number of clusters \(\mathsf{C},\mathsf{C}^{\prime}=O(1)\), the total possibilities is \(O(1)\) as well (although exponential in the number of clusters). Hence, the complex dependencies of the previously made observations used to compute prior estimates resulted by the conditioning on surviving items and users is no longer a problem - we have simply made a _for all_ argument. The rest of the analysis follows as in the GBB setting and we can arrive at a similar result as in Theorem 1 but with \(\mathsf{B}=1\) when the set of items can be clustered into \(\mathsf{C}^{\prime}=O(1)\) disjoint clusters.