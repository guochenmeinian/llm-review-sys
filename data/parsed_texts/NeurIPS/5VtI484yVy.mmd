# A Neuro-Symbolic Benchmark Suite for Concept Quality and Reasoning Shortcuts

 Samuele Bortolotti\({}^{1}\)1 Emanuele Marconato\({}^{2,1}\)1 Tommaso Carraro\({}^{3,6}\) Paolo Morettin\({}^{1}\)

**Emile van Krieken\({}^{4}\) Antonio Vergari\({}^{4}\) Stefano Teso\({}^{5,1}\) Andrea Passerini\({}^{1}\)**

\({}^{1}\) DISI, University of Trento \({}^{2}\)DI, University of Pisa \({}^{3}\)Fondazione Bruno Kessler

\({}^{4}\)University of Edinburgh \({}^{5}\)CIMeC, University of Trento

\({}^{6}\)University of Padova

{name.surname}@unitn.it

tcarraro@fbk.eu

{Emile.van.Krieken, avergari}@ed.ac.uk

Equal contribution.

Footnote 1: footnotemark:

###### Abstract

The advent of powerful neural classifiers has increased interest in problems that require both learning and reasoning. These problems are critical for understanding important properties of models, such as trustworthiness, generalization, interpretability, and compliance to safety and structural constraints. However, recent research observed that tasks requiring both learning and reasoning on background knowledge often suffer from _reasoning shortcuts_ (RSs): predictors can solve the downstream reasoning task without associating the correct concepts to the high-dimensional data. To address this issue, we introduce rsbench, a comprehensive benchmark suite designed to systematically evaluate the impact of RSs on models by providing easy access to highly customizable tasks affected by RSs. Furthermore, rsbench implements common metrics for evaluating concept quality and introduces novel formal verification procedures for assessing the presence of RSs in learning tasks. Using rsbench, we highlight that obtaining high quality concepts in both purely neural and neuro-symbolic models is a far-from-solved problem. rsbench is available at: https://unitn-sml.github.io/rsbench.

## 1 Introduction

Although the field of deep learning has made significant progress in developing accurate neural classifiers, end-to-end neural networks struggle with tasks that also require symbolic reasoning on low-level inputs like visual objects [1; 2]. Instead, Neuro-symbolic (NeSy) AI [2; 3; 4; 5] promises to improve the trustworthiness of AI systems by integrating perception with symbolic reasoning [6; 7]. This involves extracting high-level _concepts_ from the input and reasoning over them with some prior knowledge, _e.g._, safety constraints, to obtain a prediction. This setup can encourage [8; 9; 10; 11; 12; 13] or even ensure [14; 15; 16] the output complies with the knowledge.

Recent evidence suggests that, in some problems, NeSy models can achieve high accuracy on the reasoning task by _learning concepts with incorrect semantics_. Such _reasoning shortcuts_ (RSs) [17] occur when the knowledge, which acts as a bridge between the given output labels and the concepts [18], allows for inferring the right label using unintended concepts. This can seriously undermine the original purpose of NeSy AI systems, especially in high-stakes scenarios. For instance, in the BDD-OIA dataset [19], a model is given a set of traffic laws, and must predict what actions an autonomous vehicle is allowed to perform (_e.g._, "go" or "stop"). It will believe it obeys these laws by confusing pedestrians for red lights, as both entail the correct action ("stop"). Yet, if - when usedin an out-of-distribution (OOD) task - the vehicle is allowed to cross over red lights in case of an emergency, its preexisting confusion can lead to unfortunate scenarios [20]. RSs impact learnability [18], interpretability of the learned concepts [21; 22; 23; 24], and reliability in down-stream tasks [25; 26; 27; 28; 20]. At the same time, they can affect most NeSy architectures, regardless of how they are implemented, including approaches based on probabilistic logic [12; 13; 14; 16; 29; 30; 31; 32; 33], fuzzy logic [8; 34], reasoning in embedding space [35], and abduction [36; 37]. Given their impact, researchers have proposed several mitigation strategies [17; 25; 20; 38; 39; 40; 41; 42; 43], yet how to deal with RSs remains an open problem.

Unfortunately, suitable data sets with known RSs are scarce and scattered throughout the literature, hindering research on this challenging problem. Current benchmark suites for learning and reasoning neglect RSs altogether [44] and lack OOD data suitable for investigating their impact, while others are restricted to larger models [45; 46; 47]. Simultaneously, available data sets annotated with concept supervision (_e.g._, CUB200 [48]), which is essential for evaluating concept quality, do not require logical reasoning and do not supply prior knowledge.

**Contributions**. We fill this gap by introducing rsbench, an integrated benchmark suite providing all the ingredients needed for systematic evaluation of the impact of RSs and the efficacy of mitigation strategies. rsbench comprises: 1) A curated collection of _tasks_ that require learning and reasoning that are provably affected by RSs. rsbench comprises entirely new and already established tasks with different flavors - arithmetical, logical, and high-stakes - along with associated _data sets_ and _data generators_ for evaluating OOD scenarios.2 2) Python implementations of _quality metrics_ useful for assessing the impact of RSs on NeSy models and more generally the reliability of concepts learned (explicitly or implicitly) by other concept-based architectures and end-to-end neural networks. 3) a novel algorithm, countrss, that exploits automated reasoning techniques [49] to _verify a priori_ whether a task is affected by RSs and to count them. We showcase rsbench by assessing the impact of RSs on the quality of concepts acquired by several deep learning architectures, illustrated in Fig. 1.

Footnote 2: In Appendix C.6, we provide a **how-to** guide to the usage of rsbench.

## 2 Reasoning Shortcuts: Causes, Consequences, and Scope

We study tasks where models require both learning and reasoning (in short: _L&R tasks_) to accurately predict a (vector) output \(\mathbf{y}\) from low-level inputs \(\mathbf{x}\)[20]. First, we assume there is a set of \(k\) high-level concepts \(\mathbf{c}^{*}\) associated to the inputs \(\mathbf{x}\). Then, we assume the concepts \(\mathbf{c}^{*}\) and prior knowledge \(\mathsf{K}\) together infer the correct output \(\mathbf{y}^{*}\). The prior knowledge can encode known structural [11] or safety constraints [15] in some formal language (_e.g._, logical connectives).

**Example 1**.: _The_ SDD-OIA _dataset (detailed in Section 3.3) is a L&R task that contains images \(\mathbf{x}\) of 3D traffic scenes, and the goal is to predict one or more allowed actions \(\{\texttt{stop},\texttt{go},\texttt{left},\texttt{right}\}\). We assume the correct output depends on binary concepts \(c_{\texttt{grn}},c_{\texttt{red}},c_{\texttt{ped}}\) encoding whether green lights, red lights, and pedestrians are visible, respectively. The knowledge specifies that if the latter are detected, the vehicle must stop: \(\mathsf{K}=(c_{\texttt{ped}}\lor c_{\texttt{red}}\Rightarrow y_{\texttt{stop}})\)._

Figure 1: **Role of concepts in deep learning models.** (a) NeSy architectures like DeepProbLog (DPL) and Logic Tensor Networks (LTN) map the input \(\mathbf{x}\) to concepts \(\mathbf{c}\) and reason over these according to prior knowledge to obtain a label \(\mathbf{y}\). (b) CBMs are similar, except the prediction is computed by a learned linear layer, making it easy to obtain concept-level explanations of all predictions. (c) Black-box neural networks infer a label \(\mathbf{y}\) directly from the input \(\mathbf{x}\); concepts \(\mathbf{c}\) can be extracted from their latent representation by applying techniques like TCAV [50]. Lighting bolts indicate what variables are usually supervised.

[MISSING_PAGE_FAIL:3]

## 3 The rsbench Benchmark Suite

In the following, we outline the L&R tasks and metrics provided by rsbench. By construction, RSs do not compromise in-distribution performance, and their worst effects are seen on OOD data. rsbench facilitates _constructing novel OOD data sets_ by providing a configurable _data generator_ for each of its tasks (except BDD-OIA, cf. Section 3.3). These enable fine-grained control over all details of the training, validation and test splits (like number of examples and percentage allocated to each split, in addition to task-specific settings discussed in the relevant subsection) and the creation of OOD splits, all through a simple YAML configuration file. All tasks are available as Python classes and their knowledge K is supplied in the widely used DIMACS CNF format [57], to support interoperability with model implementations and reasoning packages. In Sections 3.1 to 3.3, for each task, we illustrate a possible reasoning shortcut and its impact on an OOD input.

Table 1 provides an overview of the rsbench L&R tasks, breaking them down into relevant properties, namely whether they: include a _data generator_ (Gen); allow users to create () or provide ready-made () _out-of-distribution_ splits (OOD); allow users to create () or provide ready-made () data suitable for _continual learning_ (ConL) [17]; have complex inputs, making it difficult to extract concepts (, of different objects) separately (Cplx x); require complex reasoning when using the default knowledge (Cplx K); by default use knowledge that is intrinsically _ambiguous_, _i.e._, it yields RSs even if the training set contains all possible combinations of concepts and labels (Amb K). A task involves complex inputs (Cplx x) when it requires processing semi-realistic visual scenes with multiple objects for concept extraction (,, and ). It involves complex reasoning (Cplx K) when inference requires handling interrelated concepts or multi-step reasoning. For instance, BDD-OIA and SDD-OIA require inferring \(4\) actions from \(20\) interrelated concepts (, traffic lights of different colors, presence of pedestrians), where some concepts are mutually exclusive (, traffic lights can't be green and red simultaneously).

Fig. 2 illustrates how a NeSy architecture (DPL) operates on a rsbench L&R task (BDD-OIA).

### Arithmetical Tasks and Data Sets

MNAdd[14] is the quintessential benchmark for evaluating reasoning in NeSy AI [7; 12; 58; 59; 60; 61; 62]. The goal is to infer the sum of \(k\geq 2\) MNIST [63] digits, provided knowledge encoding the rule of summation, that is,._.g._, the model should predict \(y=7\). Despite its simplicity, MNAdd highlights a clear performance gap between pure neural baselines and NeSy architectures [14; 38]. RSs arise when we can infer the correct sum using the wrong digits. This can occur due to commutativity (, and both sum to \(4\)) or incomplete training data (, in absence of other training examples, knowing that sum to \(5\) is insufficient to discriminate

Figure 2: This figure illustrates inference and training in regular NeSy architectures for one BDD-OIA example [19]. The input \(\mathbf{x}\) is a dashcam image. The model first extracts concepts from the image using a neural backbone (NN) and then uses a (differentiable) reasoning layer to infer a vector label \(\mathbf{y}=(y_{\mathsf{go}},y_{\mathsf{stoop}},y_{\mathsf{left}},y_{\mathsf{ right}})\). While the model includes a neural component, the labels depend solely on the extracted concepts. The reasoning layer is aware of prior knowledge K, which encodes constraints like “if a pedestrian or a red light is detected, the prediction must be stop.”

[MISSING_PAGE_FAIL:5]

**Task:**Kand-Logic[25] is a task - inspired by Wassily Kandinsky's paintings and [64] - that requires simple (but non-trivial) perceptual processing and relatively complex reasoning. In the simplest case, each input \(x=(x_{1},x_{2})\) consists of two \(64\times 64\) images, each depicting three geometric primitives with different shapes (\(\square\), \(\triangle\), \(\Circle\)) and colors (**red**, **blue**, **yellow**). The goal is to predict whether \(x_{1}\) and \(x_{2}\) fit the same predefined _logical pattern_ or not. Let each \(x_{i}\) contain three primitives \(x_{i,1}\), \(x_{i,2}\), \(x_{i,3}\) with two concepts each: shape \(\mathtt{sha}(x_{ij})\) and color \(\mathtt{col}(x_{ij})\). The pattern is built out of predicates like "all primitives in the image have a different color", "all primitives have the same color", and "exactly two primitives have the same shape", formally:

\[\mathtt{diffcol}(x_{i})=\bigwedge_{j\neq j^{\prime}}(\mathtt{col}(x_{ij})\neq \mathtt{col}(x_{ij^{\prime}})),\quad\mathtt{samecolor}(x_{i})=\bigwedge_{j\neq j ^{\prime}}(\mathtt{col}(x_{ij})=\mathtt{col}(x_{ij^{\prime}})),\]

and \(\mathtt{twosha}(x_{i})=\neg\mathtt{samesha}(x_{i})\wedge\neg\mathtt{diffsha }(x_{i})\). For instance, the default pattern [25]\(\mathtt{patt}(x_{i})\) is "all images include either the same number of primitives with the same color, or the same number of primitives with the same shape", or equivalently:

\[(\mathtt{diffcol}(x_{1})\wedge\mathtt{diffcol}(x_{2}))\vee( \mathtt{twocol}(x_{1})\wedge\mathtt{twocol}(x_{2}))\vee(\mathtt{samecolor}(x_ {1})\wedge\mathtt{samecolor}(x_{2}))\] \[\vee(\mathtt{diffsha}(x_{1})\wedge\mathtt{diffsha}(x_{2}))\vee( \mathtt{twosha}(x_{1})\wedge\mathtt{twosha}(x_{2}))\vee(\mathtt{samesha}(x_{1}) \wedge\mathtt{samesha}(x_{2}))\]

An input \(x\) is positive if and only if it satisfies the pattern, _i.e._, \(\mathsf{K}=(Y\Leftrightarrow\mathtt{patt}(x_{1},x_{2}))\). Unlike MNLogic, in Kand-Logic each primitive has multiple attributes that cannot easily be processed separately. This means that RSs can easily, _e.g._, confuse shape with color when either is sufficient to entail the right prediction, as in the example above. rsbench provides the data set used in [25] (\(3\) images per input with \(3\) primitives each) and a generator that allows configuring the number of images and primitives per input and the pattern itself.

**Task:**CLE4EVR[17] focuses on logical reasoning over three-dimensional scenes, inspired by CLEVR[65] and CLEVR-HANS[66]. Among these, CLEVR is tailored for visual-question answering and CLEVR-HANS to contain confounding factors at the input level, to make _shortcuts_ arise [67]. Both of them typically provide models with exhaustive concept-level supervision, obscuring whether RSs are present without it. Our CLE4EVR constitutes a simplified version where RSs can be easily determined. Each input image \(x\), of size \(240\times 320\), contains a variable number of objects differing in size (\(3\) possible values), shape (\(10\)), color (\(10\)), material (\(2\)), position (real), and rotation (real), and the goal is to determine whether the objects satisfy a pre-specified condition \(\varphi\) that depends on all discrete attributes of the objects in the scene. The default knowledge \(\mathsf{K}\) is designed to induce RSs [17]: it asserts that an image \(x\) is positive iff at least two objects \(x_{i}\) and \(x_{j}\) have the same color and shape, _i.e._, \(\exists i\neq j\,.\,(\mathtt{sha}(x_{i})=\mathtt{sha}(x_{j}))\wedge(\mathtt{ col}(x_{i})=\mathtt{col}(x_{j}))\). When all possible colors and shapes are observed, the only RSs CLE4EVR is affected by are those in which the attributes of first object are attributed to the second one. However, if the training set includes only _some_ combinations - _e.g._, pink rings and gray spheres are never observed together - the model can collapse different shapes and colors [17]. Hence, even when objects are processed separately (_e.g._, via Faster-RCNN embeddings), the model can confuse colors and shapes with one another, _e.g._, it can mistake blue cones for red pyramids and vice versa. Occlusion further complicates the picture, complicating both perception and reasoning. As above, the generator allows to customize the number of objects per image, the knowledge, and whether occlusion is allowed.

### High-stakes Tasks and Data Sets

**Task:**BDD-OIA[19] is a multi-label autonomous driving task for studying RSs in real-world, _high-stakes_ scenarios. The goal is to infer what actions out of \(\{\mathtt{forward},\mathtt{stop},\mathtt{left},\mathtt{right}\}\) are safedepending on what objects (_e.g._, cars, traffic signs) are present in an input dashcam image. The knowledge \(\mathsf{K}\) establishes that, _e.g._, it is not safe to move forward if there are pedestrians on the road, based on a set of \(21\) binary concepts indicating the presence of different obstacles on the road. The constraints specify conditions for being able to proceed (\(\mathsf{green\_light}\vee\mathsf{follow}\vee\mathsf{clear}\Rightarrow\mathsf{ forward}\)), stop (\(\mathsf{red\_light}\vee\mathsf{stop\_sign}\vee\mathsf{obstacle}\Rightarrow \mathsf{stop}\)), and for turning left and right, as well as relationships between actions (_e.g._, \(\mathsf{stop}\Rightarrow\neg\mathsf{forward}\)). Input images, of size \(720\times 1280\), come with concept-level annotations, making it possible to assess the quality of the learned concepts. The dataset comprises \(16,082\) training examples, \(2,270\) validation examples and \(4,572\) test examples. Common RSs allow to, _e.g._, confuse pedestrians with red_lights, as they both imply the correct (\(\mathsf{stop}\)) action for all training examples [20].

**Task: SDD-OIA. BDD-OIA** is not suitable for systematically evaluating RSs out-of-distribution, where they show the highest impact. With rsbench, we fill this gap by introducing SDD-OIA, a synthetic replacement for BDD-OIA that comes with a fully configurable _data generator_, enabling fine-grained control over what labels, concepts, and images are observed and the creation of OOD splits. In short, SDD-OIA shares the same classes, concepts and (by default) knowledge as BDD-OIA, but the images are 3D traffic scenes modelled and rendered using Blender [68] as \(469\times 387\) RGB images. Images are generated by first sampling a desired label \(\mathbf{y}\), then picking concepts \(\mathbf{c}\) that yield that label, and then rendering an image \(\mathbf{x}\) displaying those concepts. This allows to easily control what concepts and labels should appear in all data splits, which in turn determine what kinds of RSs can be learned. The complete data generation process is described in Appendix C.11.

In Section 4, we showcase SDD-OIA by implementing an OOD autonomous ambulance scenario [20] in which the vehicle is allowed to cross red lights in case of an emergency. Formally, this requires altering the prior knowledge by introducing a new emergency variable that conditions the traffic rules, that is, (\(\neg\)emergency\(\implies\) original rule for \(\mathsf{stop}\)) \(\land\) (\(\neg\)emergency\(\implies\) alternative rule for \(\mathsf{stop}\)), and similarly for turn_left and turn_right. We specifically test this scenario in Section 4. Naturally, other challenging OOD scenarios can be created.

### Metrics for Reasoning Shortcuts

**Model-level metrics.** rsbench facilitates assessing learned models by implementing several metrics for label and concept predictions - including accuracy and \(F_{1}\) score - as well as metrics for RSs. First, rsbench provides concept-level confusion matrices, which show how well the predicted concepts \(\mathbf{c}=(c_{1},\ldots,c_{k})\) recover the annotations \(\mathbf{c}^{*}=(c_{1}^{*},\ldots,c_{k}^{*})\) and are essential for visualizing and spotting RSs, as can be seen in Table 3. Second, it implements _concept collapse_\(\mathsf{Cls}(C)\), which measures to what extent the learned concepts mix distinct ground-truth concepts. Given a concept confusion matrix \(C\in[0,1]^{m\times m}\), where \(m\) is the size of the confusion matrix (_e.g._, \(m=2^{k}\) when all ground-truth concepts are observed), it is defined as \(\mathsf{Cls}(C)=1-p/m\), where \(p=\sum_{j=1}^{m}1\{\exists i\.\ C_{ij}>0\}\). High collapse shows that the model tends to use fewer concepts to solve the task, making it useful for diagnostics. Vice versa, a lower concept collapse may indicate that the RS is densely activating all concepts. Concept collapse is not trivial to implement because not all \(2^{k}\) ground-truth concept combinations may appear in the test set (especially when \(k\) is large, see Appendix A for details), so rsbench provides ready-made implementations for all its tasks.

**Task-level metrics.** RSs arise due to a complex interaction between prior knowledge and training data (cf. Section 2) making it difficult to assess _a priori_ which L&R tasks they affect. Fortunately, it is possible to count how many optimal (deterministic) RSs affect a L&R task [20; 25], as long as this satisfies two technical assumptions.3 They also provide a closed-form expression for the count that works only when the training set is _exhaustive_ (that is, comprises all possible combinations of concepts, like MNAdd) and the concepts are extracted jointly. This makes it possible to _formally verify_ whether a L&R task can be solved via RSs by checking that the count is larger than \(1\). This is crucial for anticipating the occurrence of RSs in novel tasks and for iteratively improving task specifications in the design stage. In practice, however, the training set is seldom exhaustive and concepts are often processed separately. While the former issue can be overcome - and in fact, we provide a closed-form solution in Appendix A.3 - the latter is more challenging.

Footnote 3: Specifically, _invertibility_ (**A1**) and _determinism_ (**A2**), meaning that it is always possible to recover the unique ground-truth concept vector underlying any input and that the knowledge \(\mathsf{K}\) maps any concept configuration to a unique label, respectively; see [20] for an in-depth discussion.

rsbench addresses it by implementing a practical counting algorithm, named countrss, that leverages _automated reasoning_[49] techniques. In a nutshell, each optimal RS can be viewed as a linear mapping \(\mathbf{c}=A\mathbf{c}^{*}\) that maps ground-truth to predicted concepts under the _constraint_ that these yield the correct label \(\mathbf{y}^{*}\) for all training examples. The problem thus boils down to counting how many matrices \(A\in\{0,1\}^{k\times k}\), where \(k\) is the number of concepts,4 satisfy this constraint. Given the exponential (in \(k\)) number of candidates, countrss relies on state-of-the-art _model counting_ solvers [49, 69] for efficiency. That is, we encode the above _constraint_ as a propositional logic formula (see Appendix A for the exact encoding), such that each model (solution) represents a distinct RS. countrss, based on PyEda[70], works for all L&R tasks that satisfy the necessary technical assumptions, including all those in rsbench except BDD-OIA, and supports both exact [71] and, for the more complex tasks, approximate counting [72].

Footnote 4: More precisely, \(k\) is the number of bits required for the one-hot encoding of the concept vector \(\mathbf{c}\).

We showcase countrss by evaluating the impact of the amount of training examples on the RS count for two instances of MMLogic: AND (with \(\mathsf{K}=(y\Leftrightarrow c_{1}\wedge c_{2}\wedge c_{2})\)) and XOR (\(\mathsf{K}=(y\Leftrightarrow c_{1}\oplus c_{2}\oplus c_{3})\)). When the training set is exhaustive, AND admits \(6\) RSs and XOR \(24\), proving that symmetries in the XOR function make it latter more ambiguous in this case, as stated in Section 3.2. The number of RSs grows drastically when we only provide a single example, as it becomes easier to predict all labels correctly while confusing concepts, with the XOR presenting \(192\) RSs. For the AND, the count depends on whether the single ground truth label is positive or negative, the number of RSs growing to \(48\) and \(336\), respectively. This highlights how even simple formulas can be affected by RSs and that these depend crucially on the available data, as expected, and that countrss can anticipate the occurrence of RSs in L&R tasks without the need for training any model.

## 4 Evaluating RSs and Concept Quality with rsbench

rsbench is meant to be a general framework for evaluating the impact of RSs and concept quality in _any_ machine learning model. We showcase this by evaluating _five_ different architectures on three L&R tasks, one per "flavor", namely MlAdd-EvenOdd, Kand-Logic, and SDD-OIA.

We consider two state-of-the-art NeSy models: DeepProbLog (DPL) [14] and Logic Tensor Networks (LTN) [34]. Both comprise a neural network module to extract concepts \(\mathbf{c}\) for every input \(\mathbf{x}\), which are later used to predict labels \(\mathbf{y}\) according to the knowledge \(\mathsf{K}\) (Fig. 1(a)). These predictions are done according to a probabilistic logic semantic in DPL and by using fuzzy logic in LTN. As stated in Section 2, we also experiment with purely neural models, evaluating the quality of the concepts they learn on rsbench. Specifically, we employ CBMs (Fig. 1(b)), black-box NNs and CLIP (Fig. 1(c)). In our analysis, we investigate directly the bottleneck layer for CBM, where concepts are expected to be learned, and adopt TCAV for NN and CLIP.

\begin{table}
\begin{tabular}{l c c c} \hline \hline  & \(\mathsf{F}_{1}(Y)(\uparrow)\) & \(\mathsf{F}_{1}(C)(\uparrow)\) & \(\mathsf{Cls}(C)(\downarrow)\) \\ \hline DPL & \(0.87\pm 0.15\) & \(0.25\pm 0.09\) & \(0.69\pm 0.04\) \\ LTN & \(0.77\pm 0.09\) & \(0.35\pm 0.04\) & \(0.00\pm 0.01\) \\ CMN\({}^{\dagger}\) & \(0.36\pm 0.04\) & \(0.59\pm 0.01\) & \(0.00\pm 0.01\) \\ NN & \(0.72\pm 0.08\) & \(0.33\pm 0.01\) & \(0.17\pm 0.01\) \\ CLP\({}^{\star}\) & \(0.99\pm 0.01\) & \(0.32\pm 0.01\) & \(0.00\pm 0.01\) \\ \hline \hline \end{tabular}
\end{table}
Table 4: Results on Kand-Logic

\begin{table}
\begin{tabular}{l c c c c} \hline \hline  & \(\mathsf{F}_{1}(Y)(\uparrow)\) & \(\mathsf{F}_{1}(C)(\uparrow)\) & \(\mathsf{Cls}(C)(\downarrow)\) \\ \hline DPL & \(0.94\pm 0.04\) & \(0.06\pm 0.08\) & \(0.61\pm 0.08\) \\ LTN & \(0.66\pm 0.10\) & \(0.05\pm 0.06\) & \(0.70\pm 0.01\) \\ \(\mathsf{CN}^{\dagger}\) & \(0.89\pm 0.13\) & \(0.44\pm 0.07\) & \(0.09\pm 0.09\) \\ NM\({}^{\star}\) & \(0.57\pm 0.38\) & \(0.07\pm 0.03\) & \(0.29\pm 0.34\) \\ CLP\({}^{\star}\) & \(0.62\pm 0.14\) & \(0.04\pm 0.01\) & \(0.48\pm 0.17\) \\ \hline \hline \end{tabular}
\end{table}
Table 2: Results on MNAdd-EvenOdd

\begin{table}
\begin{tabular}{l c c c c} \hline \hline  & \(\mathsf{mF}_{1}(Y)(\uparrow)\) & \(\mathsf{mF}_{1}(C)(\uparrow)\) & \(\mathsf{mC}_{1}(C)(\downarrow)\) & \(\mathsf{OD}\)-\(\mathsf{mF}_{1}(Y)(\uparrow)\) \\ \hline DPL & \(0.80\pm 0.01\) & \(0.49\pm 0.03\) & \(0.86\pm 0.04\) & \(0.62\pm 0.09\) \\ LTN & \(0.82\pm 0.04\) & \(0.46\pm 0.04\) & \(0.81\pm 0.02\) & \(0.72\pm 0.06\) \\ CRN\({}^{\dagger}\) & \(0.60\pm 0.12\) & \(0.61\pm 0.04\) & \(0.68\pm 0.06\) & \(0.45\pm 0.05\) \\ NN\({}^{\star}\) & \(0.93\pm 0.18\) & \(0.44\pm 0.02\) & \(0.43\pm 0.28\) & \(0.47\pm 0.19\) \\ CLIP\({}^{\star}\) & \(0.90\pm 0.09\) & \(0.43\pm 0.04\) & \(0.23\pm 0.02\) & \(0.81\pm 0.06\) \\ \hline \hline \end{tabular}
\end{table}
Table 5: Performance on SDD-OIAWe evaluate macro \(F_{1}\) for predicted labels and concepts, denoted as \(\mathrm{F}_{1}(Y)\) and \(\mathrm{F}_{1}(C)\), respectively, and concept collapse \(\mathsf{Cls}(C)\) (see Appendix A for the exact definition). We report the mean and standard deviation over \(10\) random seeds. We train all models by maximum likelihood on the labels, as customary in NeSy and for neural baselines. Notice that, CBM without annotated concepts would be equivalent to NN, therefore we supervise a handful of concepts, as customary [55; 22; 73; 23]. Specifically, we supervise a total of \(100\) examples for MNAdd-EvenOdd (only for the digits \(3\), \(4\), \(8\) and \(9\)); \(20\) examples for Kand-Logic (for red, \(\square\), and \(\bigcirc\)); and \(\sim 700\) examples for SDD-OIA on the high-stakes concepts red_light, green_light, car, person, rider, other_obstacle, stop_sign, right_green_light, and left_green_light. All details about the losses, architectures, metrics, and model selection procedure we use are reported in Appendix B.

**All tasks succeed in inducing RSs across all models**. The results in Tables 2, 4 and 5 show that all models attain medium-to-high \(\mathrm{F}_{1}(Y)\) on the three benchmarks, meaning the labels _can_ be predicted accurately, with the following exceptions: On MNAdd-EvenOdd LTN, NN, and CLIP show medium-to-high variance (\(10\%\), \(38\%\), and \(14\%\), respectively); On Kand-Logic, LTN, CBM, and NN reach suboptimal performance on (around \(77\%\), \(36\%\), and \(72\%\), respectively); On SDD-OIA, CBM scores only \(60\%\)\(\mathrm{F}_{1}(Y)\). We attribute the subbar \(\mathrm{F}_{1}(Y)\) score of CBM to the fact that their top linear layer is not expressive enough to accurately infer the label from the concept bottleneck in more complex tasks like Kand-Logic and SDD-OIA. Despite these variations in prediction performance, _all models show overall low concept quality_, as measured by \(\mathrm{F}_{1}(C)\). Even CBM, despite receiving concept supervision, fare below \(60\%\).

**Understanding concept quality with rsbench.** The high rate of \(\mathsf{Cls}(C)\) in all tasks (except for LTN in Kand-Logic) suggests that NeSy models tend mix concepts together [40]. The left-most confusion matrix in Table 3 shows that in MNAdd-EvenOdd, DPL uses roughly half of the available digits to solve the task with high \(\mathrm{F}_{1}(Y)\). In contrast, CBM experiences less collapse due to concept supervision. NN and CLIP also yield overall low collapse (an exception being CLIP in MNAdd-EvenOdd), and in fact the right-most confusion matrix in Table 3 shows that NN in MNAdd-EvenOdd activates densely most concepts. We point out that, however, lower collapse for INI and CLIP stems also from TCAV, which can introduce noise in the extracted concepts. Due to space constraints, we report a detailed analysis of this phenomenon in the supplementary material.

**Generators enable measuring the OOD impact of RSs.** For SDD-OIA we leverage the generator to evaluate an ood setting where the same concepts are used with a different knowledge \(\mathsf{K}_{000}\) (reported in Section 3.3). _We observe that all models suffer a visible drop in OOD \(\mathrm{m}\mathrm{F}_{1}(Y)\) performance_, as expected: DPL drops by \(18\%\), LTN by \(10\%\), and CBM by \(\sim 15\%\). NN is the most affected, with average \(46\%\) difference, while CLIP is the most resilient with only \(9\%\) drop.

## 5 Discussion and Conclusion

We introduced rsbench, an integrated benchmark suite for systematic evaluation of RSs and concept quality in tasks requiring learning and reasoning. While existing benchmark suites [44] neglect RSs altogether, rsbench supplies datasets for various RS-heavy tasks and corresponding ready-made data generators for evaluating OOD and continual learning scenarios. At the same time, rsbench provides formal verification and evaluation routines for assessing how much RSs and concept quality affect each task. Our experiments showcase how rsbench enables practitioners to easily investigate the impact of RSs on several existing or future deep learning architectures.

RSs are also connected to the more general problem of learning high-level concepts from data, _aka_ symbol grounding [74; 75]. Interpretable concepts play an increasingly central role as a _lingua franca_ in explainable AI (XAI) [21; 76] for both _post-hoc_[77; 50; 78; 79] and _ante-hoc_[55; 73; 22; 80; 81; 24] explanations of model decisions. As with RSs, a central question is whether the concepts encode the intended semantics [82; 83]. rsbench can be used to benchmark precisely whether learned concepts satisfy this condition. Furthermore, it can also benefit new research in mechanistic interpretability [84; 85; 86; 87; 88], specifically for studying challenging scenarios in which deriving a high-level explanation of neural networks behavior is complicated by poor concept semantics.

Another related topic is _identifiability_ of latent concepts, which is studied in independent component analysis [89] and causal representation learning [90; 53; 91]. rsbench can be readily used to empirically assess identification of latent concepts with only label supervision [92; 93; 94].

**Broader Impact.** Concepts confused by RSs can lead to poor down-stream decision making. With rsbench, we hope to enable research on mitigation strategies for RSs to avoid such consequences. At the same time, rsbench might be used to design adversarial attack that exploit or promote RSs and therefore undermine the trustworthyness of ML systems.

**Limitations and Future Work.** While rsbench already provides a variety tasks offering different learning and reasoning challenges, we plan to extend it to include variants of other popular reasoning datasets such as Visual Sudoku [95], Raven matrices [96], KANDY [97], CLEVR-HANS [66], and ROAD-R [98] which in their current status do not allow a systematic study of RSs. Implementations of NeSy architectures make use of distinct formisms and file formats, making it especially challenging to ensure data interoperability. rsbench partially addresses this by supplying both Python APIs and CNF specifications - the standard file format for logic formulas in formal verification - for all L&R tasks. In the future, we will build on initiatives like ULLER [99], which promise to provide a unified interface for NeSy architectures. We also plan to improve the scalability of the formal verification algorithm to larger L&R tasks and to leverage as a guide for active learning-based mitigation strategies.

### Acknowledgements

The authors are grateful to Alice Plebe for her valuable guidance on Blender, as well as to the authors of the assets used in SDD-OIA, see Appendix C.11.1 for the full list. Funded by the European Union. The views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union, the European Health and Digital Executive Agency (HaDEA) or the European Research Executive Agency. Neither the European Union nor the granting authority can be held responsible for them. Grant Agreement no. 101120763 - TANGO. PM is supported by the MSCA project GA nF101110960 Probabilistic Formal Verification for Provably Trustworthy AI - PFV-4-PTAI. AV is supported by the "UNREAL: Unified Reasoning Layer for Trustworthy ML" project (EP/Y023838/1) selected by the ERC and funded by UKRI EPSRC. Emile van Krieken was funded by ELIAI (The Edinburgh Laboratory for Integrated Artificial Intelligence), EPSRC (grant no. EP/W002876/1).

## References

* [1] Luc De Raedt and Angelika Kimmig. Probabilistic (logic) programming concepts. _Machine Learning_, 2015.
* [2] Luc De Raedt, Sebastijan Dumancic, Robin Manhaeve, and Giuseppe Marra. From statistical relational to neural-symbolic artificial intelligence. In _Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence_, pages 4943-4950, 2021.
* [3] Artur dAvila Garcez, Sebastian Bader, Howard Bowman, Luis C Lamb, Leo de Penning, BV Illuminoo, Hoifung Poon, and COPPE Gerson Zaverucha. Neural-symbolic learning and reasoning: A survey and interpretation. _Neuro-Symbolic Artificial Intelligence: The State of the Art_, 342:1, 2022.
* [4] Tirtharaj Dash, Sharad Chitlangia, Aditya Ahuja, and Ashwin Srinivasan. A review of some techniques for inclusion of domain-knowledge into deep neural networks. _Scientific Reports_, 12(1):1-15, 2022.
* [5] Eleonora Giunchiglia, Mihaela Catalina Stoian, and Thomas Lukasiewicz. Deep learning with logical constraints. _arXiv preprint arXiv:2205.00523_, 2022.
* [6] Didac Suris, Sachit Menon, and Carl Vondrick. Vipergpt: Visual inference via python execution for reasoning. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 11888-11898, 2023.
* [7] Daniel Cunningham, Mark Law, Jorge Lobo, and Alessandra Russo. The role of foundation models in neuro-symbolic learning and reasoning. _arXiv preprint arXiv:2402.01889_, 2024.
* [8] Michelangelo Diligenti, Marco Gori, and Claudio Sacca. Semantic-based regularization for learning and inference. _Artificial Intelligence_, 2017.
* [9] Jingyi Xu, Zulu Zhang, Tal Friedman, Yitao Liang, and Guy Broeck. A semantic loss function for deep learning with symbolic knowledge. In _ICML_, 2018.
* [10] Yaqi Xie, Ziwei Xu, Mohan S Kankanhalli, Kuldeep S Meel, and Harold Soh. Embedding symbolic knowledge into deep networks. _Advances in neural information processing systems_, 32, 2019.
* [11] Luca Di Liello, Pierfrancesco Ardino, Jacopo Gobbi, Paolo Morettin, Stefano Teso, and Andrea Passerini. Efficient generation of structured objects with constrained adversarial networks. _Advances in neural information processing systems_, 33:14663-14674, 2020.
* [12] Emile van Krieken, Thiviyan Thanapalasingam, Jakub M Tomczak, Frank van Harmelen, and Annette ten Teije. A-nesi: A scalable approximate method for probabilistic neurosymbolic inference. _arXiv preprint arXiv:2212.12393_, 2022.
* [13] Connor Pryor, Charles Dickens, Eriq Augustine, Alon Albalak, William Wang, and Lise Getoor. Neupsl: Neural probabilistic soft logic. _arXiv preprint arXiv:2205.14268_, 2022.
* [14] Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc De Raedt. DeepProbLog: Neural Probabilistic Logic Programming. _NeurIPS_, 2018.
* [15] Nick Hoernle, Rafael Michael Karampatsis, Vaishak Belle, and Kobi Gal. MultiplexNet: Towards fully satisfied logical constraints in neural networks. In _AAAI_, 2022.
* [16] Kareem Ahmed, Stefano Teso, Kai-Wei Chang, Guy Van den Broeck, and Antonio Vergari. Semantic Probabilistic Layers for Neuro-Symbolic Learning. In _NeurIPS_, 2022.
* [17] Emanuele Marconato, Gianpaolo Bontempo, Elisa Ficarra, Simone Calderara, Andrea Passerini, and Stefano Teso. Neuro symbolic continual learning: Knowledge, reasoning shortcuts and concept rehearsal. In _ICML_, 2023.
* [18] Kaifu Wang, Efi Tsamoura, and Dan Roth. On learning latent models with multi-instance weak supervision. In _NeurIPS_, 2023.

* [19] Yiran Xu, Xiaoyin Yang, Lihang Gong, Hsuan-Chu Lin, Tz-Ying Wu, Yunsheng Li, and Nuno Vasconcelos. Explainable object-induced action decision for autonomous vehicles. In _CVPR_, pages 9523-9532, 2020.
* [20] Emanuele Marconato, Stefano Teso, Antonio Vergari, and Andrea Passerini. Not all neuro-symbolic concepts are created equal: Analysis and mitigation of reasoning shortcuts. In _NeurIPS_, 2023.
* [21] Cynthia Rudin. Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead. _Nature Machine Intelligence_, 1(5):206-215, 2019.
* [22] Zhi Chen, Yijie Bei, and Cynthia Rudin. Concept whitening for interpretable image recognition. _Nature Machine Intelligence_, 2020.
* [23] Emanuele Marconato, Andrea Passerini, and Stefano Teso. Glancenets: Interpretabile, leak-proof concept-based models. _NeurIPS_, 2022.
* [24] Eleonora Poeta, Gabriele Ciravegna, Eliana Pastor, Tania Cerquitelli, and Elena Baralis. Concept-based explainable artificial intelligence: A survey. _arXiv preprint arXiv:2312.12936_, 2023.
* [25] Emanuele Marconato, Samuele Bortolotti, Emile van Krieken, Antonio Vergari, Andrea Passerini, and Stefano Teso. BEARS Make Neuro-Symbolic Models Aware of their Reasoning Shortcuts. _arXiv preprint arXiv:2402.12240_, 2024.
* [26] Xuan Xie, Kristian Kersting, and Daniel Neider. Neuro-symbolic verification of deep neural networks. In _IJCAI_, 2022.
* [27] Faried Abu Zaid, Dennis Diekmann, and Daniel Neider. Distribution-aware neuro-symbolic verification. _AISoLA_, pages 445-447, 2023.
* [28] Andrea Bontempelli, Stefano Teso, Fausto Giunchiglia, and Andrea Passerini. Concept-level debugging of part-prototype networks. In _International Conference on Learning Representations_, 2023.
* [29] Marco Lippi and Paolo Frasconi. Prediction of protein \(\beta\)-residue contacts by markov logic networks with grounding-specific weights. _Bioinformatics_, 2009.
* [30] Zhun Yang, Adam Ishay, and Joohyung Lee. NeurASP: Embracing neural networks into answer set programming. In _IJCAI_, 2020.
* [31] Jiani Huang, Ziyang Li, Binghong Chen, Karan Samel, Mayur Naik, Le Song, and Xujie Si. Scallop: From probabilistic deductive databases to scalable differentiable reasoning. _NeurIPS_, 2021.
* [32] Giuseppe Marra and Ondrej Kuzelka. Neural markov logic networks. In _Uncertainty in Artificial Intelligence_, 2021.
* [33] Arseny Skryagin, Wolfgang Stammer, Daniel Ochs, Devendra Singh Dhami, and Kristian Kersting. Neural-probabilistic answer set programming. In _Proceedings of the International Conference on Principles of Knowledge Representation and Reasoning_, volume 19, pages 463-473, 2022.
* [34] Ivan Donadello, Luciano Serafini, and Artur D'Avila Garcez. Logic tensor networks for semantic image interpretation. In _IJCAI_, 2017.
* [35] Tim Rocktaschel and Sebastian Riedel. Learning knowledge base inference with neural theorem provers. In _Proceedings of the 5th workshop on automated knowledge base construction_, pages 45-50, 2016.
* [36] Wang-Zhou Dai and Stephen H Muggleton. Abductive knowledge induction from raw data. _arXiv preprint arXiv:2010.03514_, 2020.
* [37] Zhi-Hua Zhou. Abductive learning: towards bridging machine learning and logical reasoning. _Science China. Information Sciences_, 62(7):76101, 2019.

* [38] Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc De Raedt. Neural probabilistic logic programming in deepproblog. _Artificial Intelligence_, 298:103504, 2021.
* [39] Zeman Li, Zehua Liu, Yuan Yao, Jingwei Xu, Taolue Chen, Xiaoxing Ma, L Jian, et al. Learning with logical constraints but without shortcut satisfaction. In _ICLR_, 2023.
* [40] Emanuele Sansone and Robin Manhaeve. Learning symbolic representations through joint generative and discriminative training. In _International Joint Conference on Artificial Intelligence 2023 Workshop on Knowledge-Based Compositional Generalization_, 2023.
* [41] Hao-Yuan He, Hui Sun, Zheng Xie, and Ming Li. Ambiguity-aware abductive learning. In _Proceedings of the 41st International Conference on Machine Learning_, Vienna, Austria, 2024.
* [42] Lauren Nicole DeLong, Yojana Gadiya, Paola Galdi, Jacques D Fleuriot, and Daniel Domingo-Fernandez. Mars: A neurosymbolic approach for interpretable drug discovery. _arXiv preprint arXiv:2410.05289_, 2024.
* [43] Elena Umili, Francesco Argenziano, and Roberto Capobianco. Neural reward machines. _arXiv preprint arXiv:2408.08677_, 2024.
* [44] Arne Vermeulen, Robin Manhaeve, and Giuseppe Marra. An experimental overview of neural-symbolic systems. In _International Conference on Inductive Logic Programming_, pages 124-138. Springer, 2023.
* [45] Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. Metamath: Bootstrap your own mathematical questions for large language models. _arXiv preprint arXiv:2309.12284_, 2023.
* [46] Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. Mammoth: Building math generalist models through hybrid instruction tuning. _arXiv preprint arXiv:2309.05653_, 2023.
* [47] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. _arXiv preprint arXiv:2103.03874_, 2021.
* [48] Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie. The caltech-ucsd birds-200-2011 dataset. 2011.
* [49] Armin Biere, Marijn Heule, and Hans van Maaren. _Handbook of satisfiability_, volume 185. IOS press, 2009.
* [50] Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas, et al. Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav). In _International conference on machine learning_, pages 2668-2677. PMLR, 2018.
* [51] Rich Caruana. Multitask learning. _Machine learning_, 28:41-75, 1997.
* [52] Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and Aapo Hyvarinen. Variational autoencoders and nonlinear ica: A unifying framework. In _International Conference on Artificial Intelligence and Statistics_, pages 2207-2217, 2020.
* [53] Bernhard Scholkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner, Anirudh Goyal, and Yoshua Bengio. Toward causal representation learning. _Proceedings of the IEEE_, 2021.
* [54] Jaron Maene and Luc De Raedt. Soft-unification in deep probabilistic logic. _Advances in Neural Information Processing Systems_, 36, 2024.
* [55] Pang Wei Koh, Thao Nguyen, Yew Siang Tang, Stephen Mussmann, Emma Pierson, Been Kim, and Percy Liang. Concept bottleneck models. In _International Conference on Machine Learning_, pages 5338-5348. PMLR, 2020.

* [56] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In _ICML_, 2021.
* [57] Holger H Hoos and Thomas Stutzle. Satlib: An online resource for research on sat. _Sat_, 2000:283-292, 2000.
* [58] Jaron Maene and Luc De Raedt. Soft-unification in deep probabilistic logic. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.
* [59] Samy Badreddine, Artur d'Avila Garcez, Luciano Serafini, and Michael Spranger. Logic tensor networks. _Artificial Intelligence_, 303:103649, 2022.
* [60] Alessandro Daniele, Tommaso Campari, Sagar Malhotra, and Luciano Serafini. Deep symbolic learning: Discovering symbols and rules from perceptions. _arXiv preprint arXiv:2208.11561_, 2022.
* [61] Eleonora Misino, Giuseppe Marra, and Emanuele Sansone. VAEL: Bridging Variational Autoencoders and Probabilistic Logic Programming. _NeurIPS_, 2022.
* [62] Lennert De Smet, Pedro Zuidberg Dos Martires, Robin Manhaeve, Giuseppe Marra, Angelika Kimmig, and Luc De Readt. Neural probabilistic logic programming in discrete-continuous domains. In _Uncertainty in Artificial Intelligence_, pages 529-538. PMLR, 2023.
* [63] Yann LeCun. The mnist database of handwritten digits. _http://yann. lecun. com/exdb/mnist/_, 1998.
* [64] Heimo Muller and Andreas Holzinger. Kandinsky patterns. _Artificial Intelligence_, 2021.
* [65] Justin Johnson, Bharath Hariharan, Laurens Van Der Maaten, Li Fei-Fei, C Lawrence Zitnick, and Ross Girshick. CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning. In _CVPR_, 2017.
* [66] Wolfgang Stammer, Patrick Schramowski, and Kristian Kersting. Right for the right concept: Revising neuro-symbolic concepts by interacting with their explanations. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 3619-3629, 2021.
* [67] Robert Geirhos, Jorn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and Felix A Wichmann. Shortcut learning in deep neural networks. _Nature Machine Intelligence_, 2(11):665-673, 2020.
* a 3D modelling and rendering package_. Blender Foundation, Stichting Blender Foundation, Amsterdam, 2018.
* [69] Carla P Gomes, Ashish Sabharwal, and Bart Selman. Model counting. In _Handbook of satisfiability_, pages 993-1014. IOS press, 2021.
* [70] Chris Drake. Pyeda: Data structures and algorithms for electronic design automation. In _SciPy_, pages 25-30, 2015.
* [71] Adnan Darwiche. Sdd: A new canonical representation of propositional knowledge bases. In _Twenty-Second International Joint Conference on Artificial Intelligence_, 2011.
* [72] Supratik Chakraborty, Kuldeep S. Meel, and Moshe Y. Vardi. Algorithmic improvements in approximate counting for probabilistic inference: From linear to logarithmic sat calls. In _Proceedings of International Joint Conference on Artificial Intelligence (IJCAI)_, 7 2016.
* [73] Mateo Espinosa Zarlenga, Pietro Barbiero, Gabriele Ciravegna, Giuseppe Marra, Francesco Giannini, Michelangelo Diligenti, Zohreh Shams, Frederic Precioso, Stefano Melacci, Adrian Weller, et al. Concept embedding models. _arXiv preprint arXiv:2209.09056_, 2022.
* [74] Stevan Harnad. The symbol grounding problem. _Physica D: Nonlinear Phenomena_, 42(13):335346, June 1990.

* [75] Elena Umili, Roberto Capobianco, and Giuseppe De Giacomo. Grounding ltlf specifications in image sequences. In _Proceedings of the International Conference on Principles of Knowledge Representation and Reasoning_, volume 19, pages 668-678, 2023.
* [76] Subbarao Kambhampati, Sarath Sreedharan, Mudit Verma, Yantian Zha, and Lin Guan. Symbols as a lingua franca for bridging human-ai chasm for explainable and advisable ai systems. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 36, pages 12262-12267, 2022.
* [77] Mingjie Li and Quanshi Zhang. Does a neural network really encode symbolic concepts? In _International Conference on Machine Learning_, pages 20452-20469. PMLR, 2023.
* [78] Atticus Geiger, Hanson Lu, Thomas Icard, and Christopher Potts. Causal abstractions of neural networks. _Advances in Neural Information Processing Systems_, 34:9574-9586, 2021.
* [79] Gesina Schwalbe. Concept embedding analysis: A review. _arXiv preprint arXiv:2203.13909_, 2022.
* [80] Eunji Kim, Dahuin Jung, Sangha Park, Siwon Kim, and Sungroh Yoon. Probabilistic concept bottleneck models. _arXiv preprint arXiv:2306.01574_, 2023.
* [81] Pietro Barbiero, Gabriele Ciravegna, Francesco Giannini, Mateo Espinosa Zarlenga, Lucie Charlotte Magister, Alberto Tonda, Pietro Lio, Frederic Precioso, Mateja Jamnik, and Giuseppe Marra. Interpretable neural-symbolic concept reasoning. In _International Conference on Machine Learning_, pages 1801-1825. PMLR, 2023.
* [82] Anita Mahinpei, Justin Clark, Isaac Lage, Finale Doshi-Velez, and Weiwei Pan. Promises and pitfalls of black-box concept learning models. _arXiv preprint arXiv:2106.13314_, 2021.
* [83] Emanuele Marconato, Andrea Passerini, and Stefano Teso. Interpretability is in the mind of the beholder: A causal framework for human-interpretable representation learning. _Entropy_, 25(12):1574, 2023.
* [84] Chris Olah. Mechanistic interpretability, variables, and the importance of interpretable bases. 2022.
* [85] Arthur Conmy, Augustine Mavor-Parker, Aengus Lynch, Stefan Heimersheim, and Adria Garriga-Alonso. Towards automated circuit discovery for mechanistic interpretability. _Advances in Neural Information Processing Systems_, 36:16318-16352, 2023.
* [86] Atticus Geiger, Chris Potts, and Thomas Icard. Causal abstraction for faithful model interpretation. _arXiv preprint arXiv:2301.04709_, 2023.
* [87] Ziqian Zhong, Ziming Liu, Max Tegmark, and Jacob Andreas. The clock and the pizza: Two stories in mechanistic explanation of neural networks. _Advances in Neural Information Processing Systems_, 36, 2024.
* [88] Leonard Bereska and Efstratios Gavves. Mechanistic interpretability for ai safety-a review. _arXiv preprint arXiv:2404.14082_, 2024.
* [89] Aapo Hyvarinen and Erkki Oja. Independent component analysis: algorithms and applications. _Neural networks_, 13(4-5):411-430, 2000.
* [90] Luigi Gresele, Julius Von Kugelgen, Vincent Stimper, Bernhard Scholkopf, and Michel Besserve. Independent mechanism analysis, a new concept? _Advances in neural information processing systems_, 34:28233-28248, 2021.
* [91] Liang Wendong, Armin Kekic, Julius von Kugelgen, Simon Buchholz, Michel Besserve, Luigi Gresele, and Bernhard Scholkopf. Causal component analysis. _Advances in Neural Information Processing Systems_, 36, 2024.

* [92] Sebastien Lachapelle, Tristan Deleu, Divyat Mahajan, Ioannis Mitliagkas, Yoshua Bengio, Simon Lacoste-Julien, and Quentin Bertrand. Synergies between disentanglement and sparsity: Generalization and identifiability in multi-task learning. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, _Proceedings of the 40th International Conference on Machine Learning_, volume 202 of _Proceedings of Machine Learning Research_, pages 18171-18206. PMLR, 23-29 Jul 2023.
* [93] Marco Fumero, Florian Wenzel, Luca Zancato, Alessandro Achille, Emanuele Rodola, Stefano Soatto, Bernhard Scholkopf, and Francesco Locatello. Leveraging sparse and shared feature activations for disentangled representation learning, 2023.
* [94] Armeen Taeb, Nicolo Ruggeri, Carina Schnuck, and Fanny Yang. Provable concept learning for interpretable predictions using variational autoencoders, 2022.
* [95] Eriq Augustine, Connor Pryor, Charles Dickens, Jay Pujara, William Wang, and Lise Getoor. Visual sudoku puzzle classification: A suite of collective neuro-symbolic tasks. In _International Workshop on Neural-Symbolic Learning and Reasoning (NeSy)_, 2022.
* [96] Fan Shi, Bin Li, and Xiangyang Xue. Towards generative abstract reasoning: Completing raven's progressive matrix via rule abstraction and selection. _arXiv preprint arXiv:2401.09966_, 2024.
* [97] Luca Salvatore Lorello, Marco Lippi, and Stefano Melacci. The kandy benchmark: Incremental neuro-symbolic learning and reasoning with kandinsky patterns. _arXiv preprint arXiv:2402.17431_, 2024.
* [98] Eleonora Giunchiglia, Mihaela Catalina Stoian, Salman Khan, Fabio Cuzzolin, and Thomas Lukasiewicz. Road-r: The autonomous driving dataset with logical requirements. _Machine Learning_, pages 1-31, 2023.
* [99] Emile van Krieken, Samy Badreddine, Robin Manhaeve, and Eleonora Giunchiglia. Uller: A unified language for learning and reasoning. _arXiv preprint arXiv:2405.00532_, 2024.
* [100] Yoshihide Sawada and Keigo Nakamura. Concept bottleneck model with additional unsupervised concepts. _IEEE Access_, 10:41758-41765, 2022.
* [101] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. _Journal of Machine Learning Research_, 12:2825-2830, 2011.
* [102] Cian Eastwood and Christopher KI Williams. A framework for the quantitative evaluation of disentangled representations. In _International conference on learning representations_, 2018.
* [103] Tommaso Carraro. LTNtorch: PyTorch implementation of Logic Tensor Networks, mar 2022.
* [104] Tuomas Oikarinen, Subhro Das, Lam M Nguyen, and Tsui-Wei Weng. Label-free concept bottleneck models. _arXiv preprint arXiv:2304.06129_, 2023.
* [105] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua Bengio and Yann LeCun, editors, _3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings_, 2015.
* [106] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition, 2015.
* [107] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In _CVPR_, pages 248-255. Ieee, 2009.
* [108] Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, Yingying Chen, Fangchen Liu, Vashishht Madhavan, and Trevor Darrell. Bdd100k: A diverse driving dataset for heterogeneous multi-task learning. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 2636-2645, 2020.

* [109] Daphne Koller and Nir Friedman. _Probabilistic graphical models: principles and techniques_. MIT press, 2009.
* [110] Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daume III au2, and Kate Crawford. Datasheets for datasets, 2021.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Our key claims are stated in the abstract and introduction, see the contributions paragraph. Summarizing, the main claim is that existing benchmark for learning and reasoning are insufficient to evaluate reasoning shortcuts and mitigation strategies, and we aim to fill this gap.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discuss the key limitations of rsbench in Section 5 and potential issues with TCAV-based concept extraction in Appendix A.2.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [N/A] Justification: We make no theoretical claims.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The data and code of rsbench, as well as the code used for our evaluation, are readily available at the link provided in the abstract. All experimental details are supplied in the appendix.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: The full benchmark suite, available at the provided URL, comes with documentation.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: See Section 4 and Appendix B. Additional details can be found in the source code.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: All tables come with error bars reporting the standard deviations.
8. **Experiments Compute Resources**Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: In. In short, the experiments were conducted on an A5000 GPU, and Blender rendering on a K40 GPU.
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: All authors read and followed the code of conduct. Our work does rely on experiments with human subjects or crowd-workers. All data sets we provide are freely available for research purposes and suitable for evaluating the impact reasoning shortcuts. The BDD-OIA data set is also available for research under its own license, see C.1. We believe our tasks and data sets pose no immediate harmful consequences. We discuss potential issues in Section 5.
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: We briefly discuss broader impact in Section 5.
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [N/A] Justification: We believe our tasks and data sets pose no such risk.
12. **License for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: All assets are properly credited, see C.11.1 and C.1.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: All new assets - tasks, data sets, data generators, code - are documented on the online website.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [N/A] Justification: The paper does not involve crowdsourcing nor research with human subjects.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects**Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?

Answer: [N/A]

Justification: The paper does not involve crowdsourcing nor research with human subjects.

Metrics: Additional Details

### Model-level Metrics

Label and Concept Evaluation.For all datasets, we evaluate the predictions on the labels by measuring the \(F_{1}\)-score with macro average. We followed these specifics for MNAdd-Even0dd and Kand-Logic.

In BDD-OIA and SDD-OIA, there are \(4\) labels and \(21\) concepts, and to measure the \(F_{1}\) score we adopt a softened metric [19; 100], namely, the mean-\(F_{1}\) score and a mean accuracy. Specifically, we first compute the binary \(F_{1}\)-score and accuracy for each concept \(C_{i}\) and then average them:

\[\mathrm{mF}_{1}(Y)=\frac{F_{1}(\text{forward})+F_{1}(\text{stop})+F_{1}(\text{ left})+F_{1}(\text{right})}{4}\] (1)

Similarly, for the concepts, we perform the following:

\[\mathrm{mF}_{1}(C)=\frac{F_{1}(\text{green\_light})+\dots+F_{1}(\text{right\_ follow})}{21}\] (2)

Concept Collapse.For all datasets, to measure the _Concept collapse_\(\mathsf{Cls}(C)\), we first compute the confusion matrix. Here, we provide additional details when not all ground-truth concepts \(\mathbf{C}^{*}\) appear in the test set. To this end, it is desirable to mention how the confusion matrix is extracted.

Let \(\mathcal{C}^{*}\subseteq\{0,1\}^{k}\) be the subset of concepts vectors appearing in the test set, and \(\mathcal{C}\) be the subset of concepts vectors predicted by the model for inputs in the test set, _e.g._, taking the MAP estimate. Notice that both \(|\mathcal{C}|\) and \(|\mathcal{C}^{*}|\) are below or equal to \(2^{k}\). To evaluate the confusion matrix in this multilabel setting, the set of labels is determined by first converting each binary string to its integer value, _e.g._, \((0,1,1)\mapsto 3\). Let \(\mathcal{F}(\mathcal{C})\) and \(\mathcal{F}(\mathcal{C}^{*})\) be the two subsets converted to categorical values from \(\mathcal{C}\) and \(\mathcal{C}^{*}\), respectively. From \(\mathcal{F}(\mathcal{C})\) and \(\mathcal{F}(\mathcal{C}^{*})\) we obtain the confusion matrix \(C\) using the scikit-learn library [101]. In this case, the output would be a matrix \(C\in[0,1]^{m\times m}\), where \(m=|\mathcal{F}(\mathcal{C})\cup\mathcal{F}(\mathcal{C}^{*})|\), where categorical values not appearing in \(\mathcal{F}(\mathcal{C}^{*})\) will give empty rows, _i.e._, \(C_{i,:}=(0,\dots,0)^{\top}\), for all \(i\not\in\mathcal{F}(\mathcal{C}^{*})\). Following the previous definition, we obtain that:

\[p=\sum_{j=1}^{m}\mathbbm{1}\{\exists i\:.\:C_{ij}>0\}=|\mathcal{F}(\mathcal{C })|\] (3)

Then, collapse can be evaluated as before:

\[\mathsf{Cls}(C)=1-\frac{p}{m}\] (4)

Notice that when \(m=2^{k}\) the form reduces to the one discussed in the main text.

For Kand-Logic, we took the concept for each geometric figure, using a 6-dimensional one-hot encoding for shape (3) and color (3), and computed the collapse after converting this base 3 representation to a base 10 integer. rsbench provides a way to compute the collapse for shape and color separately. In this case, we compute the confusion matrix as is without the need for a conversion. We threat the digits predictions in MNAdd-Even0dd, in the same way.

To compute the \(\mathsf{Cls}(C)\) for BDD-OIA and SDD-OIA, we convert the binary 21-concept prediction to an integer and compute the collapse. rsbench also allows computing the collapse for each concept associated with corresponding categories (e.g., move_forward, stop, turn_left, turn_right) in the same manner.

### The Impact of TCAV

We extract concepts from neural networks by leveraging the TCAV post-hoc explainer [50]. In essence, TCAV acts as a linear probe: for each concept, it trains a binary linear classifier using the network's embeddings (typically from the second-to-last layer) as inputs and the concept's annotations as targets, distinguishing between when a concept is present (\(x_{c}\)) and when it is absent (\(x_{\neg c}\)). Fromthis classifier, we extract the Concept Activation Vector (CAV), which corresponds to the weights of the linear decision boundary, denoted as \(\mathbf{v}_{\text{CAV}}\).

To assess whether a concept is present, we use the TCAV score, which checks whether the model's prediction aligns positively with the CAV by computing:

\[\frac{\partial f(x_{i})}{\partial h(x_{i})}\cdot\mathbf{v}_{\text{CAV}},\] (5)

where \(\frac{\partial f(x_{i})}{\partial h(x_{i})}\) represents the gradient of the model's output with respect to the embedding space \(h(x_{i})\), and \(\cdot\) denotes the dot product. A positive score suggests that the concept is contributing to the model's prediction.

We employed the TCAV score to determine the presence of concepts in both NN and CLIP, as discussed in Section4.

One issue is that TCAV is not always reliable, depending on the task at hand, meaning that it might mis-predict the concepts learned by the model, simply because these concepts may not be linearly separable in the embedding space. This occurs even when the linear classifiers perform well on held-out data.

This can lead to overestimating concept collapse, as noted in Section4, and to underestimating the quality of implicitly learned concepts. Possible remedies, which we plan to implement as we develop rsbench further, include replacing TCAV with more advanced techniques from mechanistic interpretability [78, 85].

### Task-level Metrics

To properly understand how the countrss works and how it is possible to count the number of RSs we need to introduce technical details on what assumptions and conditions are required. We report in this section an overview of the theoretical material in [20, 25], precisely meant to explain comprehensively the counting of RSs. Additional details about derivations and proofs for RSs characterization can be found in the references above.

To this end, we need to (_i_) introduce the functional form of NeSy predictors along with their training objective and the optimality condition, and (_ii_) the data generation process and the notion of intended semantics. (_iii_) By leveraging two simplifying assumptions, it is possible to derive a formula for counting the number of optimal solutions (including RSs).

Neuro-Symbolic models and Learning Objective.Without loss of generality, we analyze Neuro-Symbolic models leveraging Probabilistic Logic approaches [16, 14, 9] of the form:

\[p_{\theta}(\mathbf{y}\mid\mathbf{x};\mathsf{K})=\sum_{\mathbf{c}\in\{0,1\}^ {k}}p(\mathbf{y}\mid\mathbf{c};\mathsf{K})p_{\theta}(\mathbf{c}\mid\mathbf{x})\] (6)

The _perception_ step is performed via \(p_{\theta}(\mathbf{c}\mid\mathbf{x})\), computing a high-level conceptual description of a low-level input, usually implemented as a neural network; and the _reasoning_ step is performed by \(p(\mathbf{y}\mid\mathbf{c};\mathsf{K})\), which infers a prediction \(\mathbf{y}\) based on the high-level description \(\mathbf{c}\) and prior knowledge \(\mathsf{K}\).

The learning objective for models of this form is given by the maximization of the likelihood on data a set \(\mathcal{D}=\{(\mathbf{x},\mathbf{y})\}\). We denote with (**D1**) the condition to which NeSy models attain the optimum of likelihood that is \(\theta^{*}\in\operatorname*{argmax}_{\theta}\sum_{(\mathbf{x},\mathbf{y})\in \mathcal{D}}\log p_{\theta}(\mathbf{y}\mid\mathbf{x};\mathsf{K})\).

Data Generation Process and Intended Semantics.Similar to [20], we assume data are distributed according to a ground-truth distribution \(p^{*}(\mathbf{x},\mathbf{y};\mathsf{K})\). There exist \(k\) latent, _ground-truth concepts_\(\mathbf{c}^{*}\in\{0,1\}^{k}\) drawn from an unobserved distribution \(p(\mathbf{c}^{*})\), where input variables \(\mathbf{x}\in\mathbb{R}^{n}\) are distributed according to the conditional \(p(\mathbf{x}\mid\mathbf{c}^{*})\). Latent concepts also generate the label \(\mathbf{y}\) according to distributions \(p(\mathbf{x}\mid\mathbf{c}^{*};\mathsf{K})\). The overall distribution on the observed inputs and output labels is given by \(p(\mathbf{x},\mathbf{y};\mathsf{K})=\mathbb{E}_{\mathbf{c}^{*}\sim p^{*}( \mathbf{c}^{*})}p(\mathbf{x}\mid\mathbf{c}^{*})p(\mathbf{y}\mid\mathbf{c}; \mathsf{K})\). The conditional distribution \(p(\mathbf{c}^{*}\mid\mathbf{x})\) describes how concepts are distributed according to the input.

Based on this, we denote with (**D2**) the condition for which the learned concepts possess the intended semantics, that is \(p_{\theta}(\mathbf{c}\mid\mathbf{x})\equiv p(\mathbf{c}^{*}\mid\mathbf{x})\).

Reasoning Shortcuts are Optimal Solutions with Unintended Semantics.Having specified the meaning of intended concepts (**D2**) and the optimality condition for NeSy models (**D1**), does **D1**\(\implies\)**D2**, even in the limit of infinite data? Attaining optimality with NeSy models is insufficient to learn concepts with the intended semantics [20], making the implication not to hold in general.

It is possible to detect the presence of RSs before-hand, leveraging two technical assumptions:

* **Invertibility**, the ground-truth map from input to concept is given by a function \(f^{*}:\mathbf{x}\mapsto\mathbf{c}^{*}\), _i.e._, \(p(\mathbf{c}^{*}\mid\mathbf{x})=\mathbbm{1}\{\mathbf{c}^{*}=f^{*}(\mathbf{x})\}\);
* **Determinism**, the labels are uniquely determined by the knowledge \(\mathsf{K}\) and concepts by a function \(\beta_{\mathsf{K}}:\mathbf{c}\mapsto\mathbf{y}\) underlying the knowledge, _i.e._, \(p(\mathbf{y}\mid\mathbf{c},\mathsf{K})=\mathbbm{1}\{\mathbf{y}=\beta_{\mathsf{ K}}(\mathbf{c})\}\).

Intuitively, **A1** indicates that ground-truth concepts are determined uniquely from the input, _i.e._, ground-truth concepts can be read from the input variables. This means that **D2** reduces to obtain the function \(f^{*}\) via the model \(p_{\theta}(\mathbf{c}\mid\cdot)\). On the other hand, **A2** subtends the fact that for knowledge \(\mathsf{K}\) there is only one \(\mathbf{y}\) that complies with concepts \(\mathbf{c}\), that is \((\mathbf{c},\mathbf{y})\models\mathsf{K}\) and \((\mathbf{c},\mathbf{y}^{\prime})\models\mathsf{K}\), _if and only if_\(\mathbf{y}^{\prime}=\mathbf{y}\). This also means that given the concepts and the knowledge, only one label vector is associated with them.

We indicate with \(\mathsf{supp}(\mathbf{c}^{*})\) the support of the ground-truth concepts distribution \(p(\mathbf{c}^{*})\) and with \(\mathcal{A}\) the space of all maps \(\alpha:\{0,1\}^{k}\rightarrow\{0,1\}^{k}\), mapping one concept vector to another. Based on this, we can derive a count for optimal NeSy models of a particular form:

**Theorem 1** (Misspecification of NeSy models [20]).: _Under **A1** and **A2**, the number of models of the form \(p_{\theta}(\mathbf{c}\mid\mathbf{x})=\mathbbm{1}\{\mathbf{c}=f_{\theta}( \mathbf{x})\}\), with \(f_{\theta}=(\alpha\circ f^{*})\), attaining maximum likelihood amounts to:_

\[\sum_{\alpha\in\mathcal{A}}\mathbbm{1}\Big{\{}\bigwedge_{\mathbf{c}\in \mathsf{supp}(\mathbf{c}^{*})}(\beta_{\mathsf{K}}\circ\alpha)(\mathbf{c})= \beta_{\mathsf{K}}(\mathbf{c})\Big{\}}\] (7)

In a nutshell, the theorem proves that the number of alternative solutions to the ground-truth one \(f^{*}\) is given by those maps \(\alpha\in\mathcal{A}\) that _map ground-truth concepts to valid alternatives for label predictions_. When the number is above \(1\), RSs are present in the learning problem. The formula offers a principled way to count RSs in practice and allows to design tasks where RSs are present and we show a practical implementation with \(\mathtt{countrss}\).

Explicit count of optimal solutions.Marconato _et al._[20] showed that it is possible to derive an analytical expression for the total number of optimal solutions appearing in Eq. (7). This requires making assumptions on how the count is performed:

* All possible maps \(\alpha:\{0,1\}^{k}\rightarrow\{0,1\}^{k}\) can be learned by the neural model, that is \(\mathcal{A}\) is complete and of cardinality \(|\mathcal{A}|=(2^{k})^{2^{k}}\)
* The support of \(p(\mathbf{c}^{*})\) is complete, that is \(\mathrm{supp}(\mathbf{c}^{*})=2^{k}\)

Here, assumption (**C1**) allows to count the total number of maps by considering the limit case where each \(\alpha(\mathbf{c})\) can be predicted independently from \(\alpha(\mathbf{c}^{\prime})\), for \(\mathbf{c}\neq\mathbf{c}^{\prime}\). It is possible to derive the total count of possible optimal \(\alpha\)'s [20], given by:

\[\#\text{opt-}\alpha\text{'s}(\textbf{C1},\textbf{C2})=\prod_{\mathbf{c}\in\{0,1\}^{k}}|\mathcal{E}(\mathbf{c},\mathsf{K})|^{|\mathcal{E}(\mathbf{c},\mathsf{ K})|}\] (8)

where the set \(\mathcal{E}(\mathbf{c},\mathsf{K})\subset\{0,1\}^{k}\) contains all concepts \(\mathbf{C}\) that yield the same result under \(\beta_{\mathsf{K}}\), and it is defined as \(\mathcal{E}(\mathbf{c},\mathsf{K}):=\{\mathbf{c}^{\prime}:\beta_{\mathsf{K}}( \mathbf{c}^{\prime})=\beta_{\mathsf{K}}(\mathbf{c})\}\). In other terms, \(\mathcal{E}(\mathbf{c},\mathsf{K})\subset\{0,1\}^{k}\) is the equivalence class for \(\mathbf{c}\) and logic \(\mathsf{K}\). It is possible to relax **C2** by capturing a more general case and showing that RSs can be even more. The underlying idea is that for all \(\mathbf{c}^{\prime\prime}\not\in\mathrm{supp}(\mathbf{c}^{*})\), _i.e._, not appearing in the training set, a map \(\alpha\) can predict whatever element in \(\{0,1\}^{k}\) without affecting the training likelihood. This gives an even bigger number of solutions provided by:

\[\#\text{opt-}\alpha\text{'s}(\textbf{C1})=\prod_{\mathbf{c}\in \mathrm{supp}(\mathbf{C}^{*})}|\mathcal{E}(\mathbf{c},\mathsf{K})|^{|\mathcal{E }(\mathbf{c},\mathsf{K})|}\prod_{\mathbf{c}\not\in\mathrm{supp}(\mathbf{C}^{* })}2^{k}\] (9)

However, relaxing **C1** makes finding an explicit expression for counting optimal solutions more complicated. We then resort to formal methods to show that this can be done algorithmically.

Algorithmic implementation with countrs.We detail the encoding of maps \(\alpha\) and their counting in propositional logic, under the previous assumptions **A1** and **A2**. We denote with \(\mathbb{B}=\{0,1\}\) and matrix element \(\mathbf{L}_{i,j}\) as \(\mathbf{L}[i,j]\). For ease of exposition, we additionally assume that all concepts \(c_{i}\), for \(i\in\{1,\ldots,k\}\), have the same number of values \(b\in\mathbb{N}^{+}\).

We introduce \(\mathbf{O}\in\mathbb{B}^{k\times k}\) the boolean matrix encoding the mapping between the ground-truth concepts \(\mathbf{c}^{*}\) and the predicted concepts \(\mathbf{c}\), where \(k\in\mathbb{N}^{+}\) is the number of concepts. Intuitively, \(\mathbf{O}\) determines what learned concepts depend on the ground truth ones. For example, it may be the case that in Kand-Logic, the concept \(c_{\texttt{shape}}\) depends on \(c_{\texttt{color}}^{*}\) and \(c_{\texttt{color}}\) depends on \(c_{\texttt{shape}}^{*}\).

The full mapping from ground truth to predicted concept values is defined by the block matrix \(\mathbf{A}\in\mathbb{B}^{(k\cdot b)\times(k\cdot b)}\). This mapping encodes how the values of the ground truth concepts are mapped to the values of the predicted predicted. For example, in Kand-Logic it may be the case that \(\alpha:red\mapsto\square\) and \(\alpha:\square\mapsto red\), and so on for other colors and shapes. We require that this assignment of \(\mathbf{A}\) is consistent with the assignment of \(\mathbf{O}\). This means that the \(i,j\)-block of \(\mathbf{A}\) has non-zero entries if and only if the \(i\)-th ground truth concept is mapped onto the \(j\)-th predicted concept:

\[\bigwedge_{i=1}^{k}\bigwedge_{j=1}^{k}\left[\mathbf{O}[i,j]\Leftrightarrow \left(\bigvee_{x=ib}^{i(b+1)-1}\bigvee_{y=jb}^{j(b+1)-1}\mathbf{A}[x,y]\right) \right].\] (10)

\(\mathbf{A}\) also must have exactly one positive entry for each column, encoding the fact that a single ground-truth value cannot be mapped to two or more values by the model. Again, multiple ground-truth values can still end up collapsing into the same predicted value:

\[\bigwedge_{j=1}^{k\cdot b}\mathsf{OHE}(\mathbf{A}[1,j],...,\mathbf{A}[k\cdot b,j]).\] (11)

Out of every assignment to \(\mathbf{A}\) satisfying the constraints above, only those that are consistent with the supervision can achieve optimal predictive performance and therefore be potential RSs. Let \(\mathbf{c}^{*}\in\mathbb{B}^{k\cdot b}\) denote the boolean vector encoding the ground truth concept values appearing in the support of \(p(\mathbf{c}^{*})\), and let \(\hat{\mathbf{c}}\in\mathbb{B}^{k\cdot b}\) denote the predicted concepts for the ground-truth concept, which is defined as the boolean dot product (denoted as \(\otimes\)) of \(\mathbf{c}^{*}\) with \(\mathbf{A}\):

\[\bigwedge_{\mathbf{c}^{*}\in\texttt{supp}(\mathbf{c}^{*})}\left(\hat{\mathbf{ c}}\Leftrightarrow\mathbf{A}\otimes\mathbf{c}^{*}\right).\] (12)

Finally, by denoting with \(\mathsf{K}\) and \(\mathbf{y}^{*}\) the logical encoding of the task and the ground-truth label for the \(\mathbf{c}^{*}\) (corresponding to \(\mathbf{y}^{*}=\beta_{\mathsf{K}}(\mathbf{c}^{*})\)) respectively, we constrain the model predictions to be correct, which in turn forces the values of \(\mathbf{A}\) to comply with condition (**D1**):

\[\bigwedge_{\mathbf{c}^{*}\in\texttt{supp}(\mathbf{c}^{*})}\left(\mathsf{K}( \mathbf{c}_{d})\Leftrightarrow\mathbf{y}^{*}\right).\] (13)

The full encoding is the conjunction of Eq. (10), Eq. (11), Eq. (12), and Eq. (13). This is fed to a model counter, whose output equals the number of possible assignments to \(\mathbf{A}\) that satisfy the formula. When this number is above \(1\), RSs are present in the learning problem. This number indicates the optimal maps \(\alpha\)'s (according to the specifics of the constraints) that can be learned by the NeSy model.

Notice that, without any additional constraint on \(\mathbf{O}\), the count would enumerate all RSs as done in Eq. (9). We instead search for more specific RSs that relax condition **C1**. In our setup, we constrain each ground-truth concept \(c_{i}^{*}\) to be mapped to a single extracted concept \(c_{i}\). This condition is typically referred to as _completeness_[102], that is there are no copies or repetitions of ground-truth concepts in the learned ones. For example, we avoid counting solutions where the map \(\alpha\) predicts two concepts, say \(c_{1}\) and \(c_{2}\), only depending on one ground-truth concept, say \(c_{1}^{*}\). Notice that, however, multiple concepts \(c_{i}^{*}\) can still affect a single concept in \(c_{j}\). Formally, we achieve this by enforcing exactly one (OHE) positive value in each column of \(\mathbf{O}\):

\[\bigwedge_{j=1}^{k}\mathsf{OHE}(\mathbf{O}[1,j],...,\mathbf{O}[k,j])\] (14)where \(\mathsf{OHE}(a_{1},\ldots,a_{k})\) is one _if and only if_ there is only one \(a_{i}=1\) and the remaining are zero, otherwise zero. Basically, the matrix \(\mathbf{O}\) encodes all maps of concept indices, a necessary element whenever there is no clear notion of ordering among concepts (Cplx x).

Then, this additional constraint can be added to the previous conjunction and used to evaluate the number of RSs. One perk of \(\mathtt{countrss}\) is that many additional constraints can be added to the conjunction of Eq.10, Eq.11, Eq.12, and Eq.13 and evaluate different situations depending on the expected model architectural biases. By adding

\[\bigwedge_{j=1}^{k}\mathsf{OHE}(\mathbf{O}[j,1],...,\mathbf{O}[j,k])\] (15)

to Eq.14, we then require that only permutation maps are considered, that is one \(\mathbf{c}_{i}\) only depends on one \(\mathbf{c}_{\pi(i)}^{*}\), where \(\pi\) is a permutation of \(k\) elements. Further constraints can also be added to include concept supervision.

## Appendix B Experiments: Additional Details

All experiments were conducted using Python 3.8 and PyTorch 1.13, executed on a single A5000 GPU. The implementation of DPL was taken from [25]. For LTN, NN, CBM, and CLIP, new implementations were developed from scratch. LTN models were developed employing LTNtorch[103]. As for CLIP, we leveraged the implementation of [104]. For all the datasets, we used the pre-trained (with contrastive learning for image-caption matching, see [56]) visual transformer ViT-B/32 to this end, passing all input images to first a rescaling transformation of the image to \(224\times 224\times 3\) to comply with the backbone layer. Visual embeddings are then saved and made available in our supplementary material for successive fine-tuning of neural predictors.

For the dataset generation process of rsbench, we utilized Python 3.7 along with Blender 2.91, leveraging the bpy Python package set to version 2.91a0. The methodology for generating CLE4EVR variants and SDD-OIA was inspired by the work of Johnson et al. [65]. The images, which require Blender rendering, were generated using a Tesla K40c GPU.

SDD-OIA was generated using seed \(0\), with random splits of \(0.7\) for train, \(0.15\) for validation, and \(0.15\) for test. The configuration was \(0.9\) in-distribution and \(0.1\) out-of-distribution. The dataset comprises \(6820\) training examples, \(1464\) validation examples, \(1464\) test examples, and \(1000\) OOD examples. Kand-Logic and MNAdd-EvenOdd are the same datasets used in [25]. MNMath was generated using seed \(0\) with random splits, maintaining an \(80/20\) ratio for in-distribution and out-of-distribution data. It contains \(1,000\) training samples, \(200\) validation samples, \(300\) test samples, and \(200\) OOD samples. MNLogic was also generated using seed \(0\) and random splits, with an \(80/20\) ID/OOD ratio. It consists of \(1,000\) training samples, \(200\) validation samples, \(300\) test samples, and \(300\) OOD samples.

All models were trained using end-to-end training, providing supervision on the ground truth labels and not on the concept labels, except for CBM where few concept supervision has been provided.

### Additional experiments: Mnnath and MNLogic

In this section, we discuss additional experiments conducted on MNMath and MNLogic datasets.

For MNMath, we chose a task involving two equations with 8 digits (4 per equation), where \(\mathbf{x}=(\mathbf{x}_{1},\mathbf{x}_{2},\mathbf{x}_{3},\mathbf{x}_{4}, \mathbf{x}_{5},\mathbf{x}_{6},\mathbf{x}_{7},\mathbf{x}_{8})\). We designed a multi-task setup: one task predicts whether \(y_{1}=\mathbbm{1}\{\mathbf{x}_{1}+\mathbf{x}_{2}=\mathbf{x}_{3}+\mathbf{x}_{4}\}\), and the other checks if \(y_{2}=\mathbbm{1}\{\mathbf{x}_{5}\cdot\mathbf{x}_{6}=\mathbf{x}_{7}\cdot \mathbf{x}_{8}\}\) holds.

This version of MNMath includes all possible digit values (0 to 9). We chose this setup because it is particularly prone to reasoning shortcuts. Specifically, if all digits are mapped to a fixed value, _e.g._, \(\raisebox{-0.5pt}{\includegraphics[height=14.226378pt]{./}}\ldots,\raisebox{-0.5pt}{ \includegraphics[height=14.226378pt]{./}}\to 4\), they solve the MNMath task.

We evaluated three models (DPL, NN, and CBM) on this benchmark. The setup mirrors previous experiments (Section4), where each model receives supervision only on the final labels so that the concepts are treated as latent variables. As CBM require concept supervision, we gave supervision on few concepts, specifically \(0,5\) and \(9\). In this case the model predicts the concept (the digit value) for each digit independently. Following that, the model produces two labels, representing whether the two formulas are true, respectively.

The results in Table 6 summarize the performance of all models, averaged across five different seeds. The table highlights that all models struggle with reasoning shortcuts (RSs), reflected in the low concept accuracy (\(\mathrm{Acc}_{C}\)) and concept fidelity (\(\mathrm{F}_{1}(C)\)) scores, particularly for NN and CBM. However, despite these issues, the models still manage to achieve moderate to high performance on label prediction metrics (\(\mathrm{Acc}_{Y}\) and \(\mathrm{F}_{1}(Y)\)).

For MLLogic, we focused on evaluating the XOR operation on 4 bits. In this case, the input is \(\mathbf{x}=(\mathbf{x}_{1},\mathbf{x}_{2},\mathbf{x}_{3},\mathbf{x}_{4})\), and the task is to compute the output \(y=\mathbf{x}_{1}\oplus\mathbf{x}_{2}\oplus\mathbf{x}_{3}\oplus\mathbf{x}_{4}\).

We chose the XOR operation for its inherent ambiguity, which can lead to reasoning shortcuts, as discussed in previous work [20].

We evaluated the DPL, NN, and CBM models under the same setup as in MNMath, with the sole exception that there is no weight sharing among the components processing each digit, which makes the task more challenging. Unlike in MNMath, the CBM model did not receive concept supervision, as supervision for either 0 or 1 would suffice for learning the concept correctly.

The results in Table 7 reflect averages across five seeds. While all models demonstrated high performance on the task (as indicated by \(\mathrm{Acc}_{Y}\) and \(\mathrm{F}_{1}(Y)\)), they exploited unintended concepts, evident from the \(\mathrm{Acc}_{C}\) and \(\mathrm{F}_{1}(C)\) metrics. Interestingly, the 50% concept accuracy achieved by all models indicates that there is no inherent preference for any model to favor one solution over another, whether it be the identity or the reasoning shortcut ( illustrated in Fig. 3).

### Loss Functions

For NN, CBM, DPL and CLIP, the loss function corresponding to log-likelihood maximization is given by the cross-entropy loss, defined as:

\[\mathcal{L}_{\mathrm{CE}}(\mathbf{x})=-\sum_{i=1}^{\ell}y_{i}\log(\hat{y}_{i})\] (16)

\begin{table}
\begin{tabular}{l c c c c c} \hline \hline  & \(\mathrm{Acc}_{Y}(\uparrow)\) & \(\mathrm{F}_{1}(Y)(\uparrow)\) & \(\mathrm{Acc}_{C}(\uparrow)\) & \(\mathrm{F}_{1}(C)(\uparrow)\) & \(\mathsf{Cls}(C)(\downarrow)\) \\ \hline DPL & \(0.99\pm 0.01\) & \(0.99\pm 0.01\) & \(0.51\pm 0.06\) & \(0.47\pm 0.05\) & \(0.01\pm 0.01\) \\ CBM\({}^{\dagger}\) & \(0.95\pm 0.10\) & \(0.89\pm 0.23\) & \(0.50\pm 0.05\) & \(0.48\pm 0.05\) & \(0.01\pm 0.01\) \\ NN\({}^{\dagger}\) & \(0.98\pm 0.01\) & \(0.60\pm 0.20\) & \(0.46\pm 0.05\) & \(0.41\pm 0.10\) & \(0.10\pm 0.20\) \\ \hline \hline \end{tabular}
\end{table}
Table 7: Results on MNLogic

Figure 3: MNLogic reasoning shortcut

where \(y_{i}=1\) if \(i\) is the ground-truth label for input \(\mathbf{x}\), and \(\hat{y}_{i}\) is the predicted probability for class \(i\) by the model when passed the input example \(\mathbf{x}\).

LTN is the only one that differs and utilizes the Logic Tensor Network loss [59]. In LTN, the neural networks represent First-Order Logic predicates (_e.g._, the predicate \(\mathrm{Digit}\) in the MMAdd task). Formulas are constructed recursively by using fuzzy logic operators (_e.g._, fuzzy quantifiers and logical connectives). The LTN loss imposes on learning the parameters of such predicates in such a way the satisfaction of the knowledge base is maximized. Given a First-Order Logic knowledge base \(\mathsf{K}\), the loss can be defined as:

\[\mathcal{L}_{\text{{\sc{ltn}}}}(\mathbf{x})=1-\mathrm{SatAgg}_{\phi\in\mathsf{ K}}\,\mathcal{G}_{\theta}(\mathbf{x};\phi)\] (17)

where \(\phi\) is a formula contained in \(\mathsf{K}\) (like the addition for MNAdd), \(\mathrm{SatAgg}\) is an aggregator function that measures overall satisfaction of \(\mathsf{K}\), and \(\mathcal{G}_{\theta}(\mathbf{x};\phi)\) is the LTN-_grounding_ (i.e., evaluation) of \(\phi\) given \(\mathbf{x}\). This special operator is meant to map symbols from the logical domain (_e.g._, the symbolic representation of the addition with "\(+\)") to the real domain (_e.g._, its computational graph performing the addition). Hence, \(\mathcal{G}_{\theta}(\mathbf{x};\phi)\) can be seen as a fuzzy truth value resulting from the evaluation of logical formula \(\phi\) on input \(\mathbf{x}\). \(\theta\) are the parameters of the learnable predicates contained in \(\phi\). In the case of multi-label predictions, parameters \(\theta\) of the neural network are shared among different formulas \(\phi\in\mathsf{K}\) (_e.g._, like in MNAth where different equations appear in the system). Learning is then performed by differentiating the above expression.

The value of the loss depends on the semantics of the fuzzy logic operators used to approximate each logical connective (_e.g._, and, or, implication) and quantifier (_e.g._, exists, forall).

For CBM, we provided partial supervision by selecting only a few concept classes for supervision, rather than supervising all concepts. The concept supervision was also implemented using cross-entropy loss, specifically applied to the concepts. The cross-entropy loss for concepts is given by:

\[\mathcal{L}_{\text{{\sc{concept}}}}(\mathbf{x})=-\frac{1}{k}\sum_{i=1}^{k}m_ {i}\sum_{b=1}^{B_{i}}c_{ib}\log(\hat{c}_{ib})\] (18)

where \(c_{ib}=1\) if \(i\)-th ground-truth concept has value \(b\) for input \(\mathbf{x}\), and \(\hat{c}_{ib}\) is the predicted probability for concept \(i\) with value \(b\). Here, \(B_{i}\) denotes the cardinality of the \(i\)-th concept, and \(m_{i}=1\) if the concept \(i\) is supervised, otherwise being zero.

**Entropy.** To further explore the concept space, for LTN and DPL in MNAdd-EvenOdd, we applied an entropy loss on the bottleneck of the concepts. The entropy loss encourages diversity in the concept representations and is defined as:

\[\mathcal{L}_{\text{{\sc{entropy}}}}=-\sum_{i=1}^{k}\frac{\hat{c}_{i}\log(\hat{ c}_{i})}{\log(k)}\] (19)

where \(\hat{c}_{i}\) is the average probability, evaluated over the batch elements.

**Combined losses.** In scenarios where both ground truth labels and concept labels were used, the total loss is a weighted sum of the cross-entropy loss and the concept loss:

\[\mathcal{L}_{\text{{\sc{total}}}}(\mathbf{x})=\mathcal{L}_{\text{{\sc{CE}}}}( \mathbf{x})+w_{c}\mathcal{L}_{\text{{\sc{concept}}}}(\mathbf{x})+w_{h} \mathcal{L}_{\text{{\sc{entropy}}}}\] (20)

where \(w_{c}\) and \(w_{h}\) are hyperparameters that controls the trade-off between the two losses. For LTN the equivalent can be obtained by substituting \(\mathcal{L}_{\text{{\sc{CE}}}}(\mathbf{x})\) with \(\mathcal{L}_{\text{{\sc{ltn}}}}(\mathbf{x})\).

### Model Selection

All experiments rely on the Adam optimizer [105]. Hyperparameters were selected through a comprehensive grid search over predefined ranges, considering the macro \(f_{1}\) performance metric on a validation set. All experiments were run for \(40\) epochs employing early stopping, by saving the model which performs best in f1 score on the validation set. The experiments, aside from MNMath and MNL Logic, were conducted using 10 different seeds: 123, 456, 789, 1011, 1213, 1415, 1617, 1819, 2021, and 2122. In contrast, MNMath and MNL Logic were tested across 5 different seeds: 1415, 1617, 1819, 2021, and 2223.

For all experiments, the learning rate \(\gamma\) was fine-tuned within the range of \(10^{-4}\) to \(10^{-2}\). We found that the best performing models tended to have learning rates around \(10^{-3}\), striking a balance between convergence speed and stability.

The batch size \(\nu\) varied between \(32\) and \(512\), while the weight decay \(\omega\) spanned from \(10^{-4}\) to \(0\). We observed that smaller batch sizes generally resulted in more stable training dynamics, particularly for complex models, while moderate weight decay values helped prevent overfitting.

For CBM, since it requires concept supervision, we tuned the weight of the concept supervision \(w_{c}\) among \(1\), \(2\), and \(5\).

When entropy was required to make the model converge, we tuned the weight of the entropy \(w_{h}\) loss among \(0.2\), \(0.5\), \(0.8\), \(1\), and \(2\).

Additionally, for LTN, the hyper-parameter p for quantifiers was adjusted within the range of \(2\) to \(10\) with a step size of \(2\). Moreover, we tuned different fuzzy logic semantics for the fuzzy operators, specifically for and, or and implication, such as Godel, Product and ukasiewicz for and and or, while Godel, Product, ukasiewicz, Goguen and Kleene-Dienes for implication.

We set the exponential decay rate \(\beta\) to \(0.99\) for all experiments, as we empirically observed that it provides the best performance for our tasks.

Below, you find all the hyperparameters which performed the best on our datasets.

**Hyperparameters for** SDD-OIA**:

* DPL, \(\gamma=10^{-2}\), \(\nu=128\), and \(\omega=10^{-4}\);
* LTN, \(\gamma=10^{-3}\), \(\nu=32\), \(\omega=0\), and p \(=2\), and, or, implication set to Product;
* NN, \(\gamma=10^{-3}\), \(\nu=32\), and \(\omega=10^{-4}\);
* CBM, \(\gamma=10^{-2}\), \(\nu=512\), \(\omega=10^{-4}\), and \(w_{c}=2\);
* CLIP, \(\gamma=10^{-3}\), \(\nu=32\), and \(\omega=10^{-2}\).

**Hyperparameters for** Kand-Logic**:

* DPL, \(\gamma=10^{-4}\), \(\nu=32\), and \(\omega=0\);
* LTN, \(\gamma=10^{-3}\), \(\nu=128\), \(\omega=10^{-3}\), p \(=8\), and \(w_{h}=0.8\) and set to Godel, or and implication set to Product;
* NN, \(\gamma=10^{-3}\), \(\nu=256\), and \(\omega=10^{-1}\);
* CBM, \(\gamma=10^{-4}\), \(\nu=128\), \(\omega=10^{-2}\), and \(w_{c}=2\);
* CLIP, \(\gamma=10^{-3}\), \(\nu=256\), and \(\omega=10^{-1}\).

**Hyperparameters for** MNAdd-EvenOdd**:

* DPL, \(\gamma=10^{-3}\), \(\nu=32\), \(\omega=10^{-4}\) and \(w_{h}=1\);
* LTN, \(\gamma=10^{-3}\), \(\nu=64\), \(\omega=10^{-4}\), p \(=6\), \(w_{h}=10\), and set to Godel, or and implication set to Product;
* NN, \(\gamma=10^{-3}\), \(\nu=32\), and \(\omega=10^{-1}\);
* CBM, \(\gamma=10^{-3}\), \(\nu=32\), \(\omega=0\), and \(w_{c}=2\);
* CLIP, \(\gamma=10^{-2}\), \(\nu=128\), and \(\omega=10^{-2}\).

**Hyperparameters for** MNMath**:

* DPL, \(\gamma=10^{-3}\), \(\nu=64\), \(\omega=10^{-4}\) and \(w_{h}=0\);
* NN, \(\gamma=10^{-4}\), \(\nu=64\), and \(\omega=10^{-4}\);
* CBM, \(\gamma=10^{-3}\), \(\nu=64\), \(\omega=10^{-4}\), and \(w_{c}=1\);

**Hyperparameters for** MNLogic**:

* DPL, \(\gamma=10^{-3}\), \(\nu=64\), \(\omega=10^{-4}\) and \(w_{h}=0\);
* NN, \(\gamma=10^{-3}\), \(\nu=64\), and \(\omega=10^{-4}\);
* CBM, \(\gamma=10^{-4}\), \(\nu=64\), \(\omega=10^{-4}\), and \(w_{c}=1\);

[MISSING_PAGE_FAIL:29]

\begin{table}
\begin{tabular}{c c c c} \hline \hline Input & Layer Type & Parameter & Activation \\ \hline \((1,28,56)\) & Convolution & depth=32, kernel=4, stride=2, padding=1 & ReLU \\ \((32,14,28)\) & Dropout & \(p=0.5\) & \\ \((32,14,28)\) & Convolution & depth=64, kernel=4, stride=2, padding=1 & ReLU \\ \((64,7,14)\) & Dropout & \(p=0.5\) & \\ \((64,7,14)\) & Dropout & \(p=0.5\) & \\ \((64,7,14)\) & Dropout & \(p=128, kernel=4, stride=2, padding=1 & ReLU \\ \((2688)\) & Linear & dim=20, bias = True & ReLU \\ \((2688)\) & Linear & dim=19, bias = True & \\ \hline \hline \end{tabular}
\end{table}
Table 13: CBM architecture for MNAdd-EvenOdd

\begin{table}
\begin{tabular}{c c c c} \hline \hline Input & Layer Type & Parameter & Activation \\ \hline \((1,28,56)\) & Convolution & depth=32, kernel=4, stride=2, padding=1 & ReLU \\ \((32,14,28)\) & Dropout & \(p=0.5\) & \\ \((32,14,28)\) & Convolution & depth=64, kernel=4, stride=2, padding=1 & ReLU \\ \((64,7,14)\) & Dropout & \(p=0.5\) & \\ \((64,7,14)\) & Dropout & \(p=0.5\) & \\ \((64,7,14)\) & Dropout & \(p=0.5\) & \\ \((64,7,14)\) & Dropout & \(p=0.5\) & \\ \((64,7,14)\) & Convolution & \(p=0.5\) & \\ \((64,7,14)\) & Convolution & \(p=0.5\) & \\ \((2688)\) & Linear & dim=20, bias = True & \\ \((2688)\) & Linear & dim=20, bias = True & \\ \((20)\) & Linear & dim=19, bias = True & \\ \hline \hline \end{tabular}
\end{table}
Table 14: NN architecture for MNAdd-EvenOdd

\begin{table}
\begin{tabular}{c c c c} \hline \hline Input & Layer Type & Parameter & Activation \\ \hline \((1024,1)\) & Linear & dim=256, bias=True & ReLU \\ \((256)\) & Linear & dim=64, bias=True & ReLU \\ \((64)\) & Linear & dim=19, bias=True & \\ \hline \hline \end{tabular}
\end{table}
Table 15: CLIP architecture for MNAdd-EvenOdd

\begin{table}
\begin{tabular}{c c c c} \hline \hline Input & Layer Type & Parameter & Activation \\ \hline \((1,28,56)\) & Convolution & depth=16, kernel=3, stride=1, padding=1 & ReLU \\ \((16,28,56)\) & MaxPool2d & kernel=2, stride=2 & \\ \((16,14,28)\) & Convolution & depth=32, kernel=3, stride=1, padding=1 & ReLU \\ \((32,14,28)\) & MaxPool2d & kernel=2, stride=2 & \\ \((32,7,14)\) & Flatten & & \\ \((3136)\) & Linear & dim=128, bias=True & ReLU \\ \((128)\) & Linear & dim=64, bias=True & ReLU \\ \((64)\) & Linear & dim=19, bias=True & \\ \hline \hline \end{tabular}
\end{table}
Table 10: CBM architecture for SDD-OIA

\begin{table}
\begin{tabular}{c c c c} \hline \hline Input & Layer Type & Parameter & Activation \\ \hline \((1024,1)\) & Linear & dim=256, bias=True & ReLU \\ \((256)\) & Linear & dim=64, bias=True & ReLU \\ \((64)\) & Linear & dim=19, bias=True & \\ \hline \hline \end{tabular}
\end{table}
Table 15: CLIP architecture for MNAdd-EvenOdd

\begin{table}
\begin{tabular}{c c c c} \hline \hline Input & Layer Type & Parameter & Activation \\ \hline \((3,28,28)\) & Flatten & & \\ \((2352)\) & Linear & dim=256, bias=True & ReLU \\ \((256)\) & Linear & dim=128, bias=True & ReLU \\ \((128)\) & Linear & dim=8, bias = True & ReLU \\ \hline \hline \end{tabular}
\end{table}
Table 16: DPL and LTN architecture for Kand-Logic

\begin{table}
\begin{tabular}{c c c c} \hline \hline Input & Layer Type & Parameter & Activation \\ \hline \((1,28,112)\) & Convolution & depth=16, kernel=3, padding=1 & ReLU \\ \((16,28,112)\) & MaxPool2d & kernel=2, stride=2 & ReLU \\ \((16,14,56)\) & Convolution & depth=32, kernels=3, padding=1 & ReLU \\ \((32,14,56)\) & MaxPool2d & kernel=2, stride=2 & ReLU \\ \((32,7,28)\) & Convolution & depth=64, kernel=3, padding=1 & ReLU \\ \((64,7,28)\) & Flatten & & \\ \((12544)\) & Linear & dim=128, bias=True & ReLU \\ \((128)\) & Linear & dim=64, bias=True & ReLU \\ \((128,4,14)\) & MaxPool2d & kernel=2, stride=2 & \\ \((64,7,7)\) & Flatten & & \\ \((3136)\) & Linear & dim=128, bias=True & ReLU \\ \((128)\) & Linear & dim=2, bias=True & \\ \hline \hline \end{tabular}
\end{table}
Table 20: NN architecture for MNLogic

\begin{table}
\begin{tabular}{c c c c} \hline \hline Input & Layer Type & Parameter & Activation \\ \hline \((1,28,28)\) & Convolution & depth=32, kernel=3, padding=1, stride=1 & ReLU \\ \((32,28,28)\) & MaxPool2d & kernel=2, stride=2 & ReLU \\ \((32,14,14)\) & Convolution & depth=64, kernel=3, padding=1 & ReLU \\ \((64,14,14)\) & MaxPool2d & kernel=2, stride=2 & \\ \((64,7,7)\) & Flatten & & \\ \((3136)\) & Linear & dim=128, bias=True & ReLU \\ \((128)\) & Linear & dim=2, bias=True & \\ \hline \hline \end{tabular}
\end{table}
Table 21: CBM and DPL architecture for MNLogic

\begin{table}
\begin{tabular}{c c c c} \hline \hline Input & Layer Type & Parameter & Activation \\ \hline \((3,64,192)\) & Convolution & depth=16, kernel=3, stride=1, padding=1 & ReLU \\ \((16,64,192)\) & MaxPool2d & kernel=2, stride=2 & ReLU \\ \((16,32,96)\) & Convolution & depth=32, kernel=3, stride=1, padding=1 & ReLU \\ \((32,32,96)\) & MaxPool2d & kernel=2, stride=2 & \\ \((32,16,48)\) & Convolution & depth=64, kernel=3, stride=1, padding=1 & ReLU \\ \((64,16,48)\) & MaxPool2d & kernel=2, stride=2 & \\ \((64,8,24)\) & Convolution & depth=128, kernel=3, stride=1, padding=1 & ReLU \\ \((128,8,24)\) & MaxPool2d & kernel=2, stride=2 & \\ \((128,4,12)\) & Convolution & depth=256, kernel=3, stride=1, padding=1 & ReLU \\ \((256,4,12)\) & MaxPool2d & kernel=2, stride=2 & \\ \((256,2,6)\) & Flatten & & \\ \((3072)\) & Linear & dim=512, bias=True & ReLU \\ \((512)\) & Linear & dim=64, bias=True & ReLU \\ \((64)\) & Linear & dim=1, bias=True & \\ \hline \hline \end{tabular}
\end{table}
Table 17: NN architecture for Kand-Logic

\begin{table}
\begin{tabular}{c c c c} \hline \hline Input & Layer Type & Parameter & Activation \\ \hline \((3,28,28)\) & Flatten & & \\ \((2352)\) & Linear & dim=128, bias=True & ReLU \\ \((256)\) & Linear & dim=128, bias=True & ReLU \\ \((128)\) & Linear & dim=8, bias = True & \\ \((8)\) & Linear & dim=6, bias = True & \\ \((6)\) & Linear & dim=22, bias = True & \\ \hline \hline \end{tabular}
\end{table}
Table 18: CBM architecture for Kand-Logic

\begin{table}
\begin{tabular}{c c c c} \hline \hline Input & Layer Type & Parameter & Activation \\ \hline \((1,28,224)\) & Convolution & depth=16, kernel=3, padding=1 & ReLU \\ \((16,28,224)\) & MaxPool2d & kernel=2, stride=2 & \\ \((16,14,112)\) & Convolution & depth=32, kernel=3, padding=1 & ReLU \\ \((32,14,112)\) & MaxPool2d & kernel=2, stride=2 & \\ \((32,7,56)\) & Convolution & depth=64, kernel=3, padding=1 & ReLU \\ \((64,7,56)\) & Flatten & & \\ \((25088)\) & Linear & dim=128, bias=True & ReLU \\ \((128)\) & Linear & dim=64, bias=True & ReLU \\ \((64)\) & Linear & dim=2, bias=True & \\ \hline \hline \end{tabular}
\end{table}
Table 22: NN architecture for MNMathCode, Data Sets and Generators

In the following, we discuss: 1) code and data licensing Appendix C.1, 2) how the data was collected and organised Appendix C.4, 3) what kind of information it contains Appendix C.5, 4) how it should be used ethically and responsibly Appendix C.2, 5) how it will be made available and maintained Appendix C.3. All data, generators, metadata, and experimental code for reproducing the results are available at: https://unitn-sml.github.io/rsbench.

Detailed statistics for each data set using the default configuration are reported in Table 23.

### Licensing

**Code**. Most of our code is available under the BSD 3-Clause license. The CLE4EVR and SDD-OIA generators are derived from the CLEVR code base, which is available under the BSD license. The Kand-Logic generator is derived from the Kandinsky-patterns code base, which is available under the GPL-3.0 license, and so is our generator.

**Data**. MMMath, MNAdd-Half, MNAdd-EvenOdd and MNLogic are derived from MNIST[63], which is distributed under CC-BY-SA 3.0, and so are our data sets and generated data. BDD-OIA is derived from BDD-100k[108], which is distributed under a BSD 3-Clause license, and so is our data set. Data sets and generated data for Kand-Logic and SDD-OIA are available under a CC-BY-SA 4.0 license.

### Ethical Statement

rsbench is a collection of datasets aimed at exploring challenges related to concept quality, particularly focusing on identifying reasoning shortcuts. It also includes a formal verification tool to assess how often these shortcuts occur in specific configurations. Essentially, rsbench aims to help investigating concept quality in neural, neuro-symbolic and foundation models. Although this is not its intended purpose, such a benchmark may inadvertently used to improve models designed for harmful applications. However, to our knowledge, our work does not directly threaten individuals or society. Additionally, since most datasets are synthetically generated, they do not cause harm during creation. BDD-OIA, just like BDD-100k, could in principle be used to train models that aim to cause harm. We expressly disapprove of this usage.

### Hosting and Maintenance Plan

The data is openly available on Zenodo at https://zenodo.org/doi/10.5281/zenodo.11612555. The data set generators are freely available on Github. The repository is linked in our website: https://github.com/unitn-sml/rsbench.

\begin{table}
\begin{tabular}{r r r r r r r r} \hline Task & Inv x & Info c & Info y & Train & Val & Test & OOD \\ \hline MNMath & \(28k\times 28\) & \(k\) digits, 10 values each & cat multilabel & custom & custom & custom & custom \\ MNAdd-Half & \(56\times 28\) & \(2\) digits, 10 values each & cat (19 values) & \(2,940\) & \(840\) & \(420\) & \(1,080\) \\ MNAdd-EventOdd & \(56\times 28\) & \(2\) digits, 10 values each & cat (19 values) & \(6,720\) & \(1,920\) & \(960\) & \(5,040\) \\ MNLogic & \(28k\times 28\) & \(k\) digits, 2 values each & binary & custom & custom & custom & custom \\  & & & & & & & \\ Kand-Logic & \(3\times 192\times 64\) & \(3\) objects per image & & & & & \\  & & & 3 shapes & binary & \(4,000\) & \(1,000\) & \(1,000\) & – \\  & & & 3 colors & & & & & \\  & & \(n\) to \(m\) objects per image & & & & & \\ CLE4EVR & \(320\times 240\) & \(10\) shapes & & & & & & \\  & & \(2\) materials & & & & & \\  & & & 3 sizes & & & & & \\ BDD-OIA & \(1280\times 720\) & \(21\) binary concepts & bin multilabel, 4 labels & \(16,082\) & \(2,270\) & \(4,572\) & – \\  & & \(469\times 387\) & \(21\) binary concepts & bin multilabel, 4 labels & \(6,820\) & \(1,464\) & \(1,464\) & \(1,000\) \\ \hline \end{tabular}
\end{table}
Table 23: **Detailed statistics about the _default_ data sets in rsbench. For generators, the number of concepts \(k\) is configurable; in CLE4EVR, \(n\) and \(m\) are the minimum and maximum number of objects.**

### Data Collection

rsbench makes uses of two pre-existing data collections, namely MNIST and BDD-OIA. In this section, we briefly describe this data and how it is collected.

MNIST: The MNIST[63] dataset is a well known collection of handwritten digits, consisting of \(60,000\) training images and \(10,000\) test images. Each image is a \(28\times 28\) grayscale image of a numerical digit ranging from \(0\) to \(9\). The dataset was created by Yann LeCun, Corinna Cortes and Christopher J.C. Burges. MNAdd-EvenOdd and MNAdd-Half build on the MNIST dataset [20, 25]. MNLogic and MNMath, two datasets that can be generated from rsbench, make use of MNIST images.

BDD-OIA: BDD-OIA[19] is a dataset based on BDD-100K[108] dataset. BDD-100K is a large collection consisting of driving video data, developed by researchers at the University of California, Berkeley. The dataset is suitable for multitask learning, ranging from object detection to semantic segmentation and object tracking. It contains \(100,000\) videos and images, collected under diverse driving conditions, times of day, and geographic locations. The data is annotated with labels including bounding boxes, lane marking, and drivable area segmentation. For further information, please refer to the original paper [108].

### Data Generators

Each rsbench data generator comprises two Python components: the _generator_ proper samples new data, and the associated _parser_ reads the configuration from a YAML file. The latter also validates the configuration, _i.e._, check for required fields and ensure the logical formulas work as intended. Users can also configure the generators through the command line. Generated images are stored in PNG format, and ground-truth annotations as J0BLIB metadata.

**Shared configuration options**. All generators support a set of basic command line settings: config: path to the YAML configuration file; output_dir: path to the output directory; n_samples: number of samples to be generated; log_level: verbosity level; seed: RNG seed, for reproducibility;

They all comply with the following YAML settings: symbols: names of the logic symbols (concepts) that appear in the knowledge; the order is managed internally by rsbench; logic: formal specification of the knowledge as a sympy formula, used for computing the ground truth labels; prop_in_distribution: proportion of examples to put in the in-distribution sets (train, validation, and test), up to \(100\%\); combinations_in_distribution: what combinations of concept values should be included in the in-distribution sets. val_prop: proportion of examples to put in the validation set; test_prop: proportion of examples to put in the test set;

**Non-Blender generators**: MNMath, MNLogic, and Kand-Logic. The generator first parses the YAML configuration file, then proceeds to randomly sample the required number of examples. It generates a series of label and concept assignments that comply with the combinations combinations specified by the config file, if any. The ground-truth label is computed using the knowledge \(\mathsf{K}\). For MNMath, which is multi-class and multi-label, this involves splitting the configurations between classes or random sampling. Before the generation of the dataset, rsbench automatically checks whether the sampled configurations produce labels that are either all false or all true, and returns an error to the user if such a condition is found.

If the prop_in_distribution flag is set, the specified ratio is assigned to the in-distribution datasets (training, validation, and test), while the remaining settings are allocated to the out-of-distribution datasets. An equal number of examples are then assigned to both positive and negative configurations chosen for training, testing, and validation. This is achieved by sampling configurations alternately from positive and negative sides, with replacement. Depending on the dataset, examples are generated, and information such as labels and concepts are stored as J0BLIB metadata.

Finally, rsbench provides the option to specify a compression type (_e.g._, zip) for storing the dataset, ensuring efficient storage and easy distribution.

**Blender-based generators**. Generating 3D images involves running scripts from within Blender, which requires a different setup. These scripts read all configuration from the command line and specified configuration files. Options include the positions of shapes (shape_dir) and materials (material_dir), the output directories (output_image_dir for the examples and output_scene_dir for metadata), the image resolution (width, height), and details bout the rendering step (like render_tile_size, render_num_samples, camera_jitter, light_jitter). The rendering engine used for CLE4EVR is CYCLES, while SDD-OIA uses the EEVEE rendering engine to speed up rendering, although this can be easily changed by the user.

The generators build on the implementation of [65]. The images are stored as PNGs, while the metadata, in JSON format, contains information about concepts, ground truth labels, object bounding boxes, object positions, and relationships between objects (_e.g._, that one object is behind another). Unlike the synthetic data generation case, these scripts currently do not offer an option to compress the dataset, though this is a future contribution under consideration.

### Example usage

rsbench provides functionality for loading, training, and evaluating both the data and models discussed in this paper. This ready-to-use toolkit is available at https://github.com/unitn-sml/rsbench-code/tree/main/rsseval. Alternatively, the data from rsbench can be loaded with minimal code, as demonstrated in the following example:

```
1fromrs.datasets.xorimportMNLOGIC
2
3classrequired_args:
4def__init__(self):
5self.c_sup=0#specifies%supervisionavailableonconcepts
6self.which_c=-1#specifieswhichconceptstosupervise,-1=all
7self.batch_size=64#batchsizeoftheloaders
8
9args=required_args()
10
11dataset=MNLOGIC(args)
12train_loader,val_loader,test_loader=dataset.get_loaders()
13
14model=#defineyourmodelhere
15optimizer=#defineoptimizerhere
16criterion=#definelossfunctionhere
17
18forepochinrange(30):
19forimages,labels,conceptsintrain_loader:
20optimizer.zero_grad()
21outputs=model(images)
22loss=criterion(outputs,labels,concepts)
23loss.backward()
24optimizer.step() ```

Listing 1: Code snippet showcasing the training of a neural network on MNLogic using the default configuration.

```
1fromrs.datasets.xorimportMNLOGIC
2
3classrequired_args:
4def__init__(self):
5self.c_sup=0#specifies%supervisionavailableonconcepts
6self.which_c=-1#specifieswhichconceptstosupervise,-1=all
7self.batch_size=64#batchsizeoftheloaders
8
9args=required_args()
10
11dataset=MNLOGIC(args)
12train_loader,val_loader,test_loader=dataset.get_loaders()
13
14model=#defineyourmodelhere
15optimizer=#defineoptimizerhere
16criterion=#definelossfunctionhere
17
18forepochinrange(30):
19forimages,labels,conceptsintrain_loader:
20optimizer.zero_grad()
21outputs=model(images)
22loss=criterion(outputs,labels,concepts)
23loss.backward()
24optimizer.step() ```

Listing 1: Code snippet showcasing the training of a neural network on MNLogic using the default configuration.

Listing 1 illustrates a typical procedure for training a neural network on MNLogic, following standard PyTorch practices and default configurations.

Additionally, various models and datasets can be employed by providing a script with the appropriate arguments, as shown below:

```
1pythonmain.py--datasetmnmathpl--modelmnmathnn--n_epochs5--lr0.001--seed8--batch_size=64--exp_decay=1--c_sup0--taskmnmath ```

Customization of the data and splits is supported, allowing users to explore different experimental settings and corner cases. This customization involves modifying a short JSON or YAML file. Further details and examples can be found in Appendix C.

For formal verification of RSs, rsbench offers a dedicated code base available at https://github.com/unitn-sml/rsbench-code/tree/main/rsscount.

To generate a DIMACS encoding for counting tasks, use the command:

```
1pythongen-rss-count.py

[MISSING_PAGE_FAIL:36]

The user can specify which data combination to generate in-distribution by setting combinations_in_distribution (_e.g._, specifying "red, square" "blue, square" "blue, square" means the in-distribution data contains an image made of a red square and two blue squares).

### Cle4evr Data Generator

The data generation process for CLE4EVR closely resembles that of previous datasets. To generate the datasets, the program samples various configurations, specifically the number of objects, shapes,

\begin{table}
\begin{tabular}{l l} \hline \hline
**YAML config** & **JOBLIB metadata** & **PNG data** \\ \hline colors: & - red \\ - yellow & - blue \\ shapes: & - circle & \{ \\ - square & ’label’: True, \\ - triangle & ’meta’: \{ \\ symbols: & ’concepts’: [ \\ - shape\_1 & [6, 2, \\ - color\_1 & 5, 1, \\ - shape\_3 & 6, 2], \\ - color\_3 & [6, 1, \\ logic: & (Eq(color\_1, color\_2) \& 6, 1], \\  Eq(shape\_1, shape\_2) \& \\  No(shape\_1, shape\_3)) \& [ 5, 2, \\ ... & 5, 2, \\  # two equal one diff & 4, 1] \\ aggregator\symbols: & ] \\  - pattern\_1 & \} \\  - pattern\_2 & \} \\  - pattern\_3 & aggregator\logic: \\  pattern\_1 \& \\  pattern\_2 \& \\  pattern\_3 & \\ \hline \hline \end{tabular}
\end{table}
Table 26: Example of Kand-Logic data

\begin{table}
\begin{tabular}{l l} \hline \hline
**YAML config** & **JOBLIB metadata** & **PNG data** \\ \hline n\_digits: 3 & \{ \\ xor\_rule: False & ’label’: True, \\ symbols: & ’meta’: \{ \\ - a & ’concepts’: [ \\ - b & True, \\ - c & False \\ logic: & ] \\ Or(And(a, b), Not(c)) & ] \\ use\_mnist: True & \} \\ \hline \hline \end{tabular}
\end{table}
Table 25: Example of MNLogic data colors, and sizes. These configurations are then divided into positive and negative sets based on the whether they satisfy the knowledge logic. The sets are used to generate images while maintaining a balanced ratio of positive and negative ground-truth samples.

rsbench allows users to customize various aspects of data generation, including the number of objects, whether occlusion is permitted, and the dimensions of the image. The occlusion check, which uses Blender rendering, can be slow for many objects due to rejection sampling.

rsbench by default includes two materials (rubber and metal), nine shapes, and eight predefined colors, with options to create custom blend files and specify RGB values. Default object sizes are large, medium, and small, but users can fully customize these settings in a configuration file.

The symbols for each object, are be defined in the following the order: color, shape, material, and size.

### Sdd-Oia Data Generator

Regarding SDD-OIA, rsbench allows users to specify parameters such as the number of samples, number of configurations to be generated, and image size.

For SDD-OIA, the data generation approach differs from other datasets in rsbench and follows a Bayesian network [109]. The process involves first (\(i\)) sampling the actions \(\mathbf{y}\) from \(p(\mathbf{y})\), ensuring that the overall dataset is balanced in the labels, _i.e._, \(p(\mathbf{y})\) is the uniform distribution. (\(ii\)) Second, we sample the ground-truth concepts \(\mathbf{c}^{*}\) from the conditional \(p(\mathbf{c}^{*}\mid\mathbf{y})\). Then, (\(iii\)) the concepts \(\mathbf{c}^{*}\) specify a fine-grained distribution of objects in the scene, denoted as \(\mathbf{c}_{FG}\), which are sampled through \(p(\mathbf{c}_{FG}|\mathbf{c}^{*})\). Next, the fine-grained objects are used to generate the scene. This step is deterministic and yields the final image \(\mathbf{x}\). The crossroads scene is essentially a grid where objects' positions are specified by the fine-grained variables \(\mathbf{c}_{FC}\). This ensures the concepts \(\mathbf{c}^{*}\) are visible from the car's camera. The scene is then rendered with blender. The process is shown in Fig. 4. All steps in the sampling procedure ensure that all concepts can be retrieved from the image (respecting

Figure 4: Illustration of the sampling process of SDD-OIA

\begin{table}
\begin{tabular}{l l l} \hline \hline
**YAML config** & **JSON metadata** & **PNG data** \\ \hline symbols: & \(\quad\) - color\_1 & \(\quad\) \\  - shape\_1 & \(\quad\) “label”: 0, \\  - mat\_1 & \(\quad\) “concepts”: [ \\  - size\_1 & \(\quad\) [ \\  - color\_2 & \(\quad\) [ \\  - shape\_2 & \(\quad\) 0, \\  - mat\_2 & \(\quad\) 1, \\  - size\_2 & \(\quad\) 0, \\ logic: ] & \(\quad\) 0, \\   And( & \(\quad\) 0, \\   Eq(color\_1, color\_2), & \(\quad\) 0, \\   Eq(shape\_1, shape\_2), & \(\quad\) 0 \\   Eq(mat\_1, mat\_2), & \(\quad\) ], \\   Eq(size\_1, size\_2) & \(\quad\) ] \\ \hline \hline \end{tabular}
\end{table}
Table 27: Example of CLE4EVR data assumption **A1** in Appendix A.3) and that labels can be predicted uniquely from concepts \(\mathbf{c}^{*}\) (respecting assumption **A2** in Appendix A.3).

A key aspect of SDD-OIA is its customizable data generation process, which involves sampling the concepts and constructing the scene. This necessitates a hard-coded compositional framework to correctly position the camera and objects, ensuring visibility from the car's perspective. This approach enables the creation of a high-quality synthetic neuro-symbolic dataset, where objects, sample quantities, and distribution ratios are fully customizable. Like other datasets, SDD-OIA maintains a balanced distribution across all actions. Users can configure model selection, object dimensions, and the probabilities for sampling different objects by adjusting the categorical distribution weights or the hard-coded matrix configuration.

#### c.11.1 Assets used in SDD-OIA

All assets are made available under permissive licenses that allow reuse for non-commercial purposes.

* Author: stunts. Speed Limit Signs [3D model]. Retrieved from https://free3d.com/3d-model/speed-limit-signs-172903.html;
* Author: corrobrocz. Concrete street barrier [3D model]. Retrieved from https://free3d.com/3d-model/concrete-street-barrier-917223.html;
* Author: paulsendesign. Cartoon low poly trees [3D model]. Retrieved from https://free3d.com/3d-model/cartoon-low-poly-trees-895299.html;

\begin{table}
\begin{tabular}{l l} \hline \hline
**JSON metadata** & **PNG data** \\ \hline \{ & “label”: [ \\  & 0, \\  & 1, \\  & 0, \\  & 1 \\  & ], \\  & "concepts": \{ \\  & "red\_light": false, \\  & "green\_light": true, \\  & "car": false, \\  & "person": false, \\  & "rider": false, \\  & "other\_obstacle": false, \\  & "follow": false, \\  & "stop\_sign": false, \\  & "left\_lane": false, \\  & "left\_green\_light": true, \\  & "left\_follow": false, \\  & "no\_left\_lane": false, \\  & "left\_obstacle": false, \\  & "left\_obstacle": false, \\  & "clear": true \\  & \} \\ \hline \hline \end{tabular}
\end{table}
Table 28: Example of SDD-OIA data * Author: roxas. Low Poly Car [3D model]. Retrieved from https://free3d.com/3d-model/low-poly-car-14842.html;
* Author: RokoTheAwesome. Traffic Light [3D model]. Retrieved from https://www.turbosquid.com/3d-models/traffic-light-547022

All the models from free3d are under the Personal Use License, meaning the models are available for free but only for personal or non-commercial use. In contrast, the models from TurboSquid are under the Standard 3D Model License, which permits the use of TurboSquid models in various commercial projects, such as games and movies. This license allows the creation and distribution of your end-products without reproduction limitations to any target market or audience indefinitely. However, the license prohibits making the models themselves directly available to end-users, so rsbench redirects to the asset URL.

### BDD-OIA Data

Data for BDD-OIA are those previously published in [19]. BDD-OIA images are selected from BDD-100k only including frames with complicated scenes where multiple actions {forward,stop,left,right} are possible. This includes situations with multiple objects present. Following [19], all images are manually annotated for ground-truth actions and \(21\) associated binary concepts. The dataset contains \(16\)k frames for training, (with annotated labels and concepts); 2k frames for validation, and \(4.5\)k frames for testing. The table below reports the overall proportion of labels and concepts.

Concept classes in BDD-OIA

\begin{tabular}{l l c} \multicolumn{3}{c}{Concept classes in BDD-OIA} \\ \hline \hline
**Action Category** & **Concepts** & **Count** \\ \hline  & green\_light & 7805 \\ move\_forward & follow & 3489 \\  & road\_clear & 4838 \\ \hline  & red\_light & 5381 \\  & traffic\_sign & 1539 \\ stop & car & 233 \\  & person & 163 \\  & rider & 5255 \\  & other\_obstacle & 455 \\ \hline  & left\_lane & 154 \\  & left\_green\_light & 885 \\ turn\_left & left\_follow & 365 \\  & no\_left\_lane & 150 \\  & left\_obstacle & 666 \\  & left\_solid\_line & 316 \\ \hline  & right\_lane & 6081 \\  & right\_green\_light & 4022 \\ turn\_right & right\_follow & 2161 \\ \hline  & no\_right\_lane & 4503 \\  & right\_obstacle & 4514 \\  & right\_solid\_line & 3660 \\ \hline \hline \end{tabular}

[MISSING_PAGE_EMPTY:41]

Dataset Documentation: Datasheets for Datasets

Here, we answer the questions posed in the datasheets for datasets paper by Gebru et al [110].

### Motivation

For what purpose was the dataset created?rsbench was created to study the phenomenon of reasoning shortcuts (RSs) and concept quality in neuro-symbolic and neural architectures. rsbench offers several datasets where RSs occur, as well as a formal verification tool that enables users to verify how many RSs appear in the desired settings.

Who created the dataset _(e.g.,_ which team, research group) and on behalf of which entity _(e.g.,_ company, institution, organisation)?_The datasets have been created by the "Structured Machine Learning" research group at the department of Information Engineering and Computer Science of the University of Trento in collaboration with the april Lab at School of Informatics, University of Edinburgh.

Who funded the creation of the dataset?The datasets have been created for research purposes. Funded by the European Union. The views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union, the European Health and Digital Executive Agency (HaDEA) or the European Research Executive Agency. Neither the European Union nor the granting authority can be held responsible for them. Grant Agreement no. 101120763 - TANGO. PM is supported by the MSCA project GA nF101110960 Probabilistic Formal Verification for Provably Trustworthy AI - PFV-4-PTAI. AV is supported by the "UNREAL: Unified Reasoning Layer for Trustworthy ML" project (EP/Y023838/1) selected by the ERC and funded by UKRI EPSRC. Emile van Kriken was funded by ELIAI (The Edinburgh Laboratory for Integrated Artificial Intelligence), EPSRC (grant no. EP/W002876/1).

### Composition

What do the instances that comprise the dataset represent (_e.g.,_ documents, photos, people, countries)?All datasets contain annotations regarding concepts and labels. SDD-OIA comprises synthetically generated images depicting autonomous driving scenarios, such that if they were captured from a car's dashcam, and includes additional information about the scene structure, such as bounding boxes, 2D and 3D coordinates, and spatial relationships among objects. MNMath, MNAdd-Half, MNAdd-EvenOdd and MNLogic contain synthetic images of handwritten digits, derived from the MNIST dataset. Kand-Logic consists of synthetic data showcasing patterns of geometric shapes with various colors. CLE4EVR features synthetically generated images representing 3D objects of different shapes, colors, materials, and dimensions; similar to SDD-OIA, they include additional scene information. BDD-OIA is a real-world, high-stakes dataset comprising images captured from a car's dashcam. For a comprehensive description, please refer to [19].

How many instances are there in total (of each type, if appropriate)?Please refer to Table 23.

Does the dataset contain all possible instances or is it a sample (not necessarily random) of instances from a larger set?The datasets represent samples from configurations that can be randomly generated according to a grammar. Using the generators, one can filter through various combinations and determine the level of exhaustiveness for generating examples. For a comprehensive overview of each dataset generation process, please consult Appendix C.5 and subsequent sections.

What data does each instance consist of?Alongside the images, each dataset sample is annotated with concepts and labels. However, for SDD-OIA and CLE4EVR, detailed scene information is included, encompassing individual 2D and 3D coordinates, bounding boxes, and spatial relationships between objects. For an complete overview refer to Table 23.

Is there a label or target associated with each instance?Yes, the concept annotations are derived from the data generation process, while the labels are symbolically derived from the knowledge provided to the dataset.

Is any information missing from individual instances?No.

Are relationships between individual instances made explicit (_e.g._, users' movie ratings, social network links)?No, there are no connections between different instances.

Are there recommended data splits (_e.g._, training, development/validation, testing)?Information about the data splits we employed is reported in Appendix B. The user has the freedom to choose the data splits they prefer during the data generation process.

Are there any errors, sources of noise, or redundancies in the dataset?No.

Is the dataset self-contained, or does it link to or otherwise rely on external resources (_e.g._, websites, tweets, other datasets)?Some of our data sets build on top of established and stable data, namely MNIST and (the last frames provided by) BDD-100k, for which we provide download links. SDD-OIA makes use of external assets, listed in Appendix C.11.1. The ready-made SDD-OIA data set does not require these assets, but in order to use the generator these have to be obtained separately.

Does the dataset contain data that might be considered confidential (e.g., data that is protected by legal privilege or by doctor-patient confidentiality, data that includes the content of individuals' non-public communications)?No.

Does the dataset contain data that, if viewed directly, might be offensive, insulting, threatening, or might otherwise cause anxiety?No.

Does the dataset relate to people?If not, you may skip the remaining questions in this section. BDD-OIA contains images depicting pedestrians and bicycle riders. Identifiable information in these images, including anonymization, rights, and risks, is managed by the original BDD-100k authors.

Does the dataset identify any subpopulations (_e.g._, by age, gender)?Please refer to E.2.

Is it possible to identify individuals (_i.e._, one or more natural persons), either directly or indirectly (_i.e._, in combination with other data) from the dataset?Please refer to E.2.

Does the dataset contain data that might be considered sensitive in any way (e.g., data that reveals racial or ethnic origins, sexual orientations, religious beliefs, political opinions or union memberships, or locations; financial or health data; biometric or genetic data; forms of government identification, such as social security numbers; criminal history)?Please refer to E.2.

### Collection Process

How was the data associated with each instance acquired?MNIST and BDD-100k have been obtained from their official repositories, http://yann.lecun.com/exdb/mnist/ and https://dl.cv.ethz.ch/bdd100k/data/, respectively. All other data is synthetically generated.

What mechanisms or procedures were used to collect the data (_e.g._, hardware apparatus or sensor, manual human curation, software program, software API)?Details about data generations and software programs are discussed in Appendix B.

If the dataset is a sample from a larger set, what was the sampling strategy (_e.g._, deterministic, probabilistic with specific sampling probabilities)?Please refer to the similar question in Appendix E.2.

Who was involved in the data collection process (_e.g._, students, crowdworkers, contractors) and how were they compensated (_e.g._, how much were crowdworkers paid)?The authors were involved in the process of generating these datasets.

Over what timeframe was the data collected?The datasets were generated over a span of several days.

Were any ethical review processes conducted (_e.g._, by an institutional review board)?No.

Does the dataset relate to people? If not, you may skip the remainder of the questions in this section.BDD-OIA is the only dataset relating to people, please refer to Appendix E.2.

### Preprocessing/Cleaning/Labeling

Was any preprocessing/cleaning/labeling of the data done (_e.g._, discretization or bucketing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of instances, processing of missing values)?No, the datasets were generated along with labels and concept annotations.

Was the "raw" data saved in addition to the preprocessed/cleaned/labeled data (_e.g._, to support unanticipated future uses)?NA

Is the software used to preprocess/clean/label the instances available?NA

### Uses

Has the dataset been used for any tasks already?In the paper, we demonstrate and benchmark the intended use of these datasets for evaluating concept quality and exploring RSs. MNAdd-EvenOdd, MNAdd-Half, and CLE4EVR have been utilized in previous studies [25, 20, 17] to investigate RSs and concept quality.

Is there a repository that links to any or all papers or systems that use the dataset?Yes, https://unitn-sml.github.io/rsbench/.

What (other) tasks could the dataset be used for?SDD-OIA and CLE4EVR offer additional information regarding the scene, including the 3D and 2D coordinates of objects, their bounding boxes, and the relationships between objects within the scene. This spatial data enables various applications such as object discovery, object detection, and reasoning over the scene's structure.

Is there anything about the composition of the dataset or the way it was collected and preprocessed/cleaned/labeled that might impact future usesNo.

Are there tasks for which the dataset should not be used?These datasets are meant for research purposes only.

### Distribution

Will the dataset be distributed to third parties outside of the entity (_e.g._, company, institution, organization) on behalf of which the dataset was created?No.

How will the dataset will be distributed (_e.g._, tarball on website, API, GitHub)?The datasets, data generators, and related evaluation code are available on the website, enabling users to generate, download, and test their model on the data. Each dataset is provided in zip format and can be downloaded from the Zenodo link on the website.

When will the dataset be distributed?The datasets employed in the paper are available now on the website.

Will the dataset be distributed under a copyright or other intellectual property (IP) license, and/or under applicable terms of use (ToU)?Please refer to Appendix C.1.

Have any third parties imposed IP-based or other restrictions on the data associated with the instances?SDD-OIA makes use of assets taken from https://free3d.com and https://www.turbosquid.com. See Appendix C.11.1 for the full list and associated licenses. Other instances of datasets themselves do not have IP-based restrictions.

Do any export controls or other regulatory restrictions apply to the dataset or to individual instances?Not that we are are of.

### Maintenance

Who is supporting/hosting/maintaining the dataset?The datasets are supported by the authors and will be actively maintained by the "Structured Machine Learning" research group in the future. For the hosting and maintenance plan, please refer to Appendix C.3.

How can the owner/curator/manager of the dataset be contacted (e.g., email address)?The authors of rsbench can be contacted via their email addresses: samuele.bortolotti@unitn.it, emanuele.marconato@unitn.it.

Is there an erratum?If errors are found, an erratum will be added to the website.

Will the dataset be updated (_e.g.,_ to correct labeling errors, add new instances, delete instances)?Any potential future updates or extensions will be communicated via the website. The datasets will be versioned.

If the dataset relates to people, are there applicable limits on the retention of the data associated with the instances (_e.g.,_ were individuals in question told that their data would be retained for a fixed period of time and then deleted)?The only dataset involving people is BDD-OIA, place refer to Appendix E.2.

Will older versions of the dataset continue to be supported/hosted/maintained?We plan to continue hosting older versions of the dataset.

If others want to extend/augment/build on/contribute to the dataset, is there a mechanism for them to do so?Yes, the dataset generation code is available on our website.

### Other Questions

Is your dataset free of biases?Our data sets are designed to induce a particular type of bias, namely reasoning shortcuts, in models, for the purpose of studying them. The data itself however is not biased towards human factors such as gender, ethnicity, age, etc.

Can you guarantee compliance to GDPR?No, we are unable to comment on legal matters.

### Author Statement of Responsibility

The authors assume full responsibility for any rights violations and confirm the license associated with the datasets and their images.