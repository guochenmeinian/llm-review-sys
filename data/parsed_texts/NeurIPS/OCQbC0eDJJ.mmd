# Honor Among Bandits:

No-Regret Learning for Online Fair Division

 Ariel D. Procaccia

Paulson School of Engineering and Applied Sciences, Harvard University | _E-mail_: arielpro@seas.harvard.edu.

Benjamin Schiffer

Department of Statistics, Harvard University | _E-mail_: bschiffer1@g.harvard.edu.

Shirley Zhang

Paulson School of Engineering and Applied Sciences, Harvard University | _E-mail_: szhang2@g.harvard.edu.

###### Abstract

We consider the problem of online fair division of indivisible goods to players when there are a finite number of types of goods and player values are drawn from distributions with unknown means. Our goal is to maximize social welfare subject to allocating the goods fairly in expectation. When a player's value for an item is unknown at the time of allocation, we show that this problem reduces to a variant of (stochastic) multi-armed bandits, where there exists an arm for each player's value for each type of good. At each time step, we choose a distribution over arms which determines how the next item is allocated. We consider two sets of fairness constraints for this problem: envy-freeness in expectation and proportionality in expectation. Our main result is the design of an explore-then-commit algorithm that achieves \(\tilde{O}(T^{2/3})\) regret while maintaining either fairness constraint. This result relies on unique properties fundamental to fair-division constraints that allow faster rates of learning, despite the restricted action space. We also prove a lower bound of \(\tilde{\Omega}(T^{2/3})\) regret for our setting, showing that our results are tight.

## 1 Introduction

Fair allocation of indivisible goods is a fundamental problem with a wide range of applications; implemented algorithms for this task have been widely used in practice [14]. We consider the online fair division setting, which introduces additional complexities as items arrive one by one and each item must be immediately and irrevocably allocated at its time of arrival. Crucially, this allocation must be done without knowledge of future items [5]. One motivating example for this setting is a food bank that receives donations for a region and then allocates these donations among many different food pantries and soup kitchens in that region. Donations are often perishable, and therefore must be immediately allocated. Furthermore, donations can be unpredictable, and hence knowledge of future items is limited.

Two standard notions of fairness are _envy-freeness_ and _proportionality_. Envy-freeness implies that every player is at least as happy with their own allocation as with any other player's allocation. Intuitively, envy-freeness guarantees that no player will want to trade their allocation for that of another player. Proportionality is a slightly weaker notion, which requires only that each of the \(n\) players receive at least a \(1/n\) fraction of their total value for all items. Finding a solution which is envy-free or proportional is often interesting in and of itself, as can be seen from many previous results in fair division [7, 30, 12, 3]. In cases where there may exist multiple envy-free or proportional allocations, however, a natural goal is then to find the best solution among such allocations [13]. In our work, we evaluate the quality of a fair solution by its (utilitarian) _social welfare_, which is defined as the sum over all players of each player's value for their own allocation.

We take a probabilistic approach to analyzing online fair division. In particular, we assume that there are a finite number of item types, and each player's value for each type of item is drawn froma random distribution. In practice, these distributions would not be known in advance and must be learned as items are allocated. For example, consider again the food bank. When a new food pantry opens, the values of that food pantry for different types of products are unknown. After items have been allocated to the food pantry, however, the food bank can easily collect information on the demand for various item types at the food pantry. Therefore, we primarily consider the setting where the player distributions are unknown in advance, and a player's true value for an item is observed if and only if that player receives the item. This problem can be viewed as a variant of the multi-armed bandits problem, as the goal is to learn unknown distributions (player values) while maintaining high reward (social welfare), subject to fairness constraints; with a finite number of types of items, pulling an arm represents allocating a specific item type to a specific player.

As is standard in the multi-armed bandits literature, we use the notion of _regret_ to measure the difference between our algorithm's performance and that of the optimal policy that knows the value distributions and is subject to the same fairness constraints. Our overarching challenge is this: _design online allocation algorithms that achieve low regret while maintaining fairness in the form of emvy-freeness or proportionality._

### Our Results

Our main result is that there exists a simple optimization-based explore-then-commit algorithm that achieves \(\tilde{O}(T^{2/3})\) regret and maintains envy-freeness in expectation (Algorithm 1 and Theorem 1). A variant of the same algorithm achieves \(\tilde{O}(T^{2/3})\) regret while maintaining proportionality in expectation. The key step of the algorithm is a linear program-based optimization that guarantees that the constraints are satisfied without significantly decreasing social welfare.

The main difficulty in this learning problem is that the envy-freeness and proportionality constraints depend on the unknown value distributions and may be tight constraints without any slack. We therefore develop novel machinery that relies on fundamental properties of these fairness notions. One observation is that our fairness constraints are always satisfied when players are treated equally. Another crucial property is that when players have unequal values, these fairness notions can be satisfied with slack (Property 2). The latter property is especially challenging to show for envy-freeness, and the combinatorial algorithm that achieves it (Lemma 1) should be of independent interest to researchers in fair division.

### Related Work

**Online Fair Division.** Work in online fair division generally deals with dividing goods when there is uncertainty about the future. Early work in the area focused on axiomatic questions [31; 1].

Our paper is most closely related to work by Benade et al. [5]. Like us, they consider a setting where indivisible items arrive online and must be allocated immediately and irrevocably to players. They study several models for how the values of items are determined, ranging from a model where values are drawn i.i.d. from a distribution common to all players and items to, at the other extreme, and adversarial model with worst-case values. There are two fundamental differences between their work and ours. First, Benade et al. [5] do not optimize social welfare; rather, they seek to either just minimize envy, or do so while (approximately) satisfying the axiomatic notion of Pareto efficiency. Second, and more crucially, they assume that the values of all players for an item are known at the time of its arrival, whereas in our model the values are unknown. It is precisely this modeling choice that induces a learning problem and underlies the connection between our setting and multi-armed bandits, which is absent in prior work in online fair division.

Like us, Yamada et al. [35] also study online fair division through the lens of bandit learning. Their setting is similar to ours in that they consider a finite number of item types where player values for item types are initially unknown. However, [35] do not guarantee fairness through constraints - instead, they incorporate fairness through their objective function of Nash social welfare. [35] also make an additional assumption that player values are normalized, which we do not require for our results.

**Fairness in Multi-armed Bandits.** The other main body of literature related to our paper is multi-armed bandits with constraints. One notion of fairness in multi-armed bandits is the idea that similar individuals and/or groups should be treated similarly [9; 18; 23]. The fairness constraint of Joseph et al. [17] is that a worse arm is not pulled with higher probability than a better arm. Their definition of fairness is actually incompatible with maintaining envy-freeness (or proportionality), because maintaining envy-freeness may require allocating an item to a player with lower value to prevent envy. Another common fairness constraint in multi-armed bandits is that every arm receives a minimum fraction of pulls [10; 11; 20; 28]. This notion of fairness is also not compatible with envy-freeness because the optimal envy-free allocation may never give a player a specific item type. There also exist many other fairness notions in contextual bandits that are farther from our setting [15; 29; 32; 34]. Wei et al. [33] analyze a form of envy-freeness in contextual bandits, but their envy-freeness notion depends only on the treatment probabilities instead of the values.

Our paper is also closely related to work on multi-armed bandits subject to general linear constraints. Multiple works in linear bandits study "safety" with respect to a linear constraint that depends on the unknown true mean values [2; 8; 26]. Amani et al. [2] focus on a single constraint and specifically show that if there is positive slack in the optimal solution, then \(\tilde{O}(T^{1/2})\) regret is possible. If there is zero slack, however, their algorithm only achieves \(\tilde{O}(T^{2/3})\) regret. This differs from our work because envy-freeness and proportionality involve multiple constraints that can have zero slack. Note that our setting is similar but not equivalent to linear bandits, as a single arm is pulled in each step in our setting. There also exist many results for cumulative constraints in bandits [21; 22]. These are less closely related to our model as we consider constraints that must hold at every time step. Finally, there is a branch of multi-armed bandits that studies constraints in expectation at each step as in our paper. However, these works are also in the linear bandits setting and again require a safety gap that fairness constraints such as envy-freeness may not guarantee [27].

**Practical Motivation.** Mertzanidis et al. [25] apply online fair division algorithms through a partnership with a program in Indiana that redistributes rejected truckloads of food. The program, known as Food Drop, allocates 10,000+ pounds of rejected food per month to food banks. In this application, the available food arrives in an online and unpredictable way, and the trucks must be allocated immediately. More generally, the specific food donations depend on what items grocery stores or restaurants have remaining at the end of the day. Therefore, donations are unpredictable, which we model through randomness.

In practice, utilities for food donations such as in the Food Drop program may not be additive. However, if the deliveries are sufficiently infrequent, then additive player utilities are likely to be a good approximation. For example, in the food allocation data of [19], there were a total of 1760 donations from 169 donors over the course of five months and 277 organizations that received donations. Therefore, the organizations receive donations every 3-4 weeks on average, suggesting that donations can be largely regarded as independent.

## 2 Model

In this section we introduce our basic setting and terminology.

### Online Allocation With Unknown Values

Suppose we have a set of players \(N=[n]\) and a set of object types \(M=[m]\). Given a set of \(T\) indivisible items, an _allocation_\(A=(A_{1},...,A_{n})\) is a partition of the \(T\) items among the \(n\) players, where player \(i\) receives the items in \(A_{i}\). In our model, we assume that every item \(j\) has a type \(k(j)\in[m]\), and that there exists a (possibly unknown) matrix \(\mu^{*}\) such that each player \(i\)'s value for an item of type \(k\in[m]\) is independently drawn from a sub-Gaussian distribution with mean \(\mu^{*}_{ik}\). Player values are assumed to be independent across both players and items. We will often refer to \(\mu^{*}_{i}\) as the vector of mean values for player \(i\). For a specific item \(j\), we denote player \(i\)'s value for item \(j\) as \(V_{i}(j)\), and similarly, player \(i\)'s value for their allocation \(A_{i}\) as \(V_{i}(A_{i})=\sum_{j\in A_{i}}V_{i}(j)\). The (utilitarian) _social welfare_ of an allocation \(A\) is \(\operatorname{sw}(A)=\sum_{i=1}^{n}V_{i}(A_{i})\).

We consider algorithms in the following online setting. At each time step \(t\in[T]\), an item \(j_{t}\) of type \(k_{t}\) arrives, where \(k_{t}\sim\mathcal{D}\), for some known distribution \(\mathcal{D}\) supported on \([m]\). We will assume that \(\mathcal{D}=\operatorname{Unif}([m])\), or in other words that every item has an equal probability of being type \(1,...,m\). We make this choice purely for ease of exposition, in order to simplify notation; our results and techniques extend seamlessly to arbitrary distributions \(\mathcal{D}\) that do not depend on \(T\), as we explain in Appendix C.1. The algorithm observes the item type \(k_{t}\), and must then immediately allocate the item \(j_{t}\) to a player \(i_{t}\), at which time the algorithm observes that player's value \(V_{i_{t}}(j_{t})\). Note that the algorithm does not observe any other player's value for item \(j_{t}\). The high-level goal is to allocate these items in a manner that maximizes the social welfare of the final allocation of all \(T\) items.

We denote \(X\in\mathbb{R}^{n\times m}\) as a valid fractional allocation if \(\sum_{i}X_{ik}=1\) for every \(k\in[m]\). One valid fractional allocation we will often refer to is the _uniform at random_ allocation (UAR), where every entry is \(\frac{1}{n}\). At every time-step \(t\), before observing \(k_{t}\), the allocation algorithm \(\mathrm{ALG}\) takes as input the history \(H_{t}=\{(k_{t^{\prime}},i_{t^{\prime}},\dot{V}_{i^{\prime}},(j_{t^{\prime}})) :t^{\prime}<t\}\) and returns a fractional allocation \(X_{t}=\mathrm{ALG}(H_{t})\), where \((X_{t})_{ik}\) represents the probability of allocating the item to player \(i\) if the item is of type \(k\). If the next item is of type \(k_{t}\), then the algorithm allocates the item randomly among the \(n\) players according to the distribution induced by the \(k_{t}^{\mathrm{th}}\) column of \(X_{t}\), i.e. \((X_{t}^{\top})_{k_{t}}\). Therefore, the \(t^{\mathrm{th}}\) item is allocated to player \(i\) with probability \((X_{t})_{ik_{t}}\). We denote the final realized allocation that \(\mathrm{ALG}\) returns as \(A(\mathrm{ALG})\), and the corresponding partial allocation up to time \(\tau\) as \(A^{\tau}(\mathrm{ALG})\). This online process is summarized in pseudo-code in Appendix A.

We will also assume (explicitly in our theorem statements) that for all \(i,k\), there exist known constants \(a,b>0\) such that \(a\leq\mu_{ik}^{*}\leq b\). This assumption is necessary because if we allow the means of values to be arbitrary close to zero, then it can be impossible to achieve regret of \(o(T)\). This is formalized in Theorem 11 in Appendix C.2.

### Fairness Notions

We will primarily use two metrics of fairness to evaluate an online allocation algorithm \(\mathrm{ALG}\): envy-freeness in expectation and proportionality in expectation. Both are defined below. For two vectors \(x,y\in\mathbb{R}^{n}\), we use \(\langle x,y\rangle=x\cdot y\) to represent the dot product of the two vectors.

**Definition 1**.: Let \(X_{t}=\mathrm{ALG}(H_{t})\) be the fractional allocation used by algorithm \(\mathrm{ALG}\) at time \(t\) given history \(H_{t}\). Then \(\mathrm{ALG}\) satisfies _envy-freeness in expectation (_EFE_) if for all \(t\) and all \(H_{t}\), \((X_{t})_{i}\cdot\mu_{i}^{*}\geq\max_{i^{\prime}\in[n]}\;(X_{t})_{i^{\prime}} \cdot\mu_{i}^{*}\) for all \(i\).

**Definition 2**.: Let \(X_{t}=\mathrm{ALG}(H_{t})\) be the fractional allocation used by algorithm \(\mathrm{ALG}\) at time \(t\) given history \(H_{t}\). Then \(\mathrm{ALG}\) satisfies _proportionality in expectation (_PE_) if for all \(t\) and all histories \(H_{t}\), \((X_{t})_{i}\cdot\mu_{i}^{*}\geq\frac{1}{n}\sum_{i^{\prime}\in[n]}\;(X_{t})_{i ^{\prime}}\cdot\mu_{i}^{*}\) for all \(i\)._

Intuitively, envy-freeness in expectation is equivalent to maintaining that at every time step \(t\) and before observing the item type \(k_{t}\), no player prefers the fractional allocation of any other player in \(X_{t}\). Similarly, proportionality in expectation is equivalent to maintaining that at every time step \(t\) and before observing the item type \(k_{t}\), the expected value of every player for their fractional allocation is at least \(1/n\) times that player's value if they received the item with probability \(1\).

In Appendix B, we justify some of the implicit choices behind these definitions. Specifically, we discuss why we consider envy-freeness in expectation rather than its realization, and also why we require envy-freeness in expectation to hold at every individual time step. Analogous results for proportionality can be found in Appendix B.1. For the former question, Theorem 3 shows that in our setting, no algorithm can with high probability output an allocation \(A(\mathrm{ALG})\) with realized envy less than \(\sqrt{T}\). Note that Benade et al. [5] show that in the adversarial setting, no algorithm can guarantee \(o(\sqrt{T})\) realized envy. Conversely, they also show that when values are generated randomly and observed before allocation, there exists an algorithm that _can_ guarantee \(o(1)\) realized envy with high probability. Theorem 3 shows that when values are still generated randomly but are _unknown_ at the time of allocation (as in our setting), no algorithm can guarantee \(o(\sqrt{T})\) realized envy with high probability. We complement Theorem 3 with Theorem 4, which shows that any algorithm \(\mathrm{ALG}\) that satisfies envy-freeness in expectation will output a final allocation \(A(\mathrm{ALG})\) with realized envy of at most \(\sqrt{T}\log(T)\) with high probability. Therefore, envy-free in expectation algorithms are within a \(\log(T)\) factor of being "optimal" in terms of final realized envy.

We also show that requiring envy-freeness in expectation at every time step does not lead to any social welfare loss compared to requiring envy-freeness in expectation only at the end of \(T\) rounds. More specifically, Theorem 5 (again in Appendix B) implies that requiring that no player is envious in expectation of any other player at the end of all \(T\) rounds is equivalent to maintaining envy-freeness in expectation at all times \(t\in[T]\) when maximizing social welfare. A key step of our proof of Theorem 5 is showing that for every time- or history-dependent algorithm \(\mathrm{ALG}\) which achieves envy-freeness in expectation at the end of \(T\) rounds, there exists another algorithm \(\mathrm{ALG}^{\prime}\) that is time- and history-independent, envy-free in expectation at every time step, and achieves the same social welfare. Therefore, maximizing social welfare only over algorithms which are envy-free in expectation at every time step is sufficient even if envy-freeness in expectation at the end of \(T\) rounds is all that is desired.

We can formulate our fairness notions as linear constraints, in the spirit of prior work in fair division [4]. Formally, define \(\langle A,B\rangle_{F}\) as the Frobenius inner product of matrices \(A\) and \(B\). For \(B\in\mathbb{R}^{n\times m},c\in\mathbb{R}\), and a fractional allocation \(X\), we represent the linear constraint \(\langle B,X\rangle_{F}\geq c\) as the tuple \((B,c)\). A fractional allocation \(X\) satisfies a set of \(L\) linear constraints \(\{(B_{\ell},c_{\ell})\}_{\ell=1}^{L}\) if for all \(\ell\in[L]\), \(\langle B_{\ell},X\rangle_{F}\geq c_{\ell}\). Because the constraints represent "fairness in expectation" relative to the mean values, we will explicitly let the constraint matrix \(B_{\ell}(\mu^{*})\) be a function of the mean value matrix \(\mu^{*}\). Therefore, we will consider sets of constraints of the form \(\{(B_{\ell}(\mu^{*}),c_{\ell})\}_{\ell=1}^{L}\). Because these constraints are functions of \(\mu\), we will also refer to families of constraints \(\left\{\{(B_{\ell}(\mu),c_{\ell})\}_{\ell=1}^{L}\right\}_{\mu}\).

The following two remarks show how envy-freeness in expectation and proportionality in expectation can be represented within this framework.

**Remark 1**.: For every \(\ell\in[n^{2}]\), construct \(B_{\ell}^{\text{ee}}(\mu^{*})\) as follows. Define \(i=\lceil\frac{\ell}{n}\rceil\) and \(i^{\prime}=(\ell\mod n)+1\). For every \(k\in[K]\), let \((B_{\ell}^{\text{ee}}(\mu^{*}))_{ik}=\mu_{ik}^{*}\) and \((B_{\ell}^{\text{ee}}(\mu^{*}))_{i^{\prime}k}=-\mu_{ik}^{*}\). For all \(i^{\prime\prime}\not\in\{i,i^{\prime}\}\), let \((B_{\ell}^{\text{ee}}(\mu^{*}))_{i^{\prime\prime}}=0\). Then the envy-freeness in expectation constraints for mean \(\mu^{*}\) as defined in section 1 correspond to \(\operatorname{ee}(\mu^{*}):=\{(B_{\ell}^{\text{ee}}(\mu^{*}),0)\}_{\ell=1}^{n^ {2}}\).

**Remark 2**.: For every \(\ell\in[n]\), construct \(B_{\ell}^{\text{ee}}(\mu^{*})\) as follows. For every \(k\in[m]\), \((B_{\ell}^{pe}(\mu^{*}))_{\ell k}=\frac{(n-1)}{n}\cdot\mu_{tk}^{*}\) and \((B_{\ell}^{pe}(\mu^{*}))_{ik}=-\frac{1}{n}\cdot\mu_{tk}^{*}\) for every \(i\neq\ell\). Then the proportionality in expectation constraints for mean \(\mu^{*}\) as defined in Definition 2 correspond to \(\operatorname{pe}(\mu^{*})=\{(B_{\ell}^{pe}(\mu^{*}),0)\}_{\ell=1}^{n}\).

### Regret and Problem Formulation

An algorithm \(\operatorname{ALG}\) satisfies constraints \(\{(B_{\ell}(\mu^{*}),c_{\ell})\}_{\ell=1}^{L}\) if for all \(t\in[T]\), the fractional allocation \(X_{t}\) used by \(\operatorname{ALG}\) at time \(t\) satisfies the constraints \(\{(B_{\ell}(\mu^{*}),c_{\ell})\}_{\ell=1}^{L}\). When \(\mu^{*}\) is known, the expected social welfare can be directly optimized over all algorithms \(\operatorname{ALG}\) that satisfy constraints \(\{(B_{\ell}(\mu^{*}),c_{\ell})\}_{\ell=1}^{L}\). This problem is equivalent to solving LP (1) with \(\mu=\mu^{*}\) and using the solution \(Y^{\mu^{*}}\) as the fractional allocation for all time steps.

\[Y^{\mu}:=\arg\max\ \langle X,\mu\rangle_{F}\] \[\text{s.t.}\ \langle B_{\ell}(\mu),X\rangle_{F}\geq c_{\ell} \quad\forall\ell\] \[\sum_{i}X_{ik}=1\quad\forall k\] (1)

When \(\mu^{*}\) is unknown, we define the regret of an algorithm \(\operatorname{ALG}\) as follows. Note that the baseline algorithm in this definition of regret is the optimal allocation algorithm under the constraints when \(\mu^{*}\) is known.

**Definition 3**.: Let \(Y^{\mu^{*}}\) be the solution to LP (1) for \(\mu=\mu^{*}\). Let \(X_{t}=\operatorname{ALG}(H_{t})\) be the fractional allocation used by algorithm \(\operatorname{ALG}\) at time \(t\) given history \(H_{t}\). Then the \(T\)-step regret of \(\operatorname{ALG}\) for constraints \(\{(B_{\ell}(\mu^{*}),c_{\ell})\}_{\ell=1}^{L}\) is \(T\cdot\langle Y^{\mu^{*}},\mu^{*}\rangle_{F}-\sum_{t=0}^{T-1}\langle X_{t},\mu^ {*}\rangle_{F}\).

We are now ready to present the formal problem statement. Because the constraints depend on the unknown values that are being learned, we only require constraint satisfaction with high probability.

**Problem 1**.: _Suppose we are given \(n,m,T,a,b\) such that \(0<a\leq\mu_{ik}^{*}\leq b\) for all \(i\in[n]\), \(k\in[m]\). Given a family of fairness constraints \(\left\{\{(B_{\ell}(\mu),c_{\ell})\}_{\ell=1}^{L}\right\}_{\mu}\) representing either envy-freeness in expectation or proportionality in expectation, the goal is to construct an algorithm \(\operatorname{ALG}\) such that with probability \(1-1/T\), \(X_{t}=\operatorname{ALG}(H_{t})\) satisfies the constraints \((B_{\ell}(\mu^{*}),c_{\ell})\}_{\ell=1}^{L}\) for all \(t\in[T]\) and the regret of \(\operatorname{ALG}\) for constraints \((B_{\ell}(\mu^{*}),c_{\ell})\}_{\ell=1}^{L}\) is \(o(T)\)._

Note that the \(o(T)\) regret in Problem 1 will be \(\tilde{O}(T^{2/3})\) for our results. We use the standard \(O()\) and \(\tilde{O}()\) notation with respect to the number of time steps \(T\), and therefore the constants represented by this notation may depend on other problem parameters such as \(n\) and \(m\).

## 3 Fairness Machinery

Our goal in this section is to establish novel, fundamental properties of envy-freeness and proportionality in expectation, which will serve as a crucial part of the machinery underlying our regret bounds.

In the context of fairness, a natural assumption is that if a group of individuals are treated equally, then that group is considered to be treated fairly. In that spirit, our first key property is as follows.

**Property 1**.: _For any \(\ell\in[L]\), suppose that a fractional allocation \(X\in\mathbb{R}^{n\times m}\) satisfies \(X_{i_{1}}=X_{i_{2}},\;\forall i_{1},i_{2}\in\{i:B_{\ell}(\mu)_{i}\neq\bm{\theta}\}\). Then \(\langle B_{\ell}(\mu),X\rangle_{F}\geq c_{\ell}\)._

Informally, a set of constraints satisfies Property 1 if for any constraint in the set, the constraint is always satisfied when all players involved in the constraint have the same fractional allocation. An important consequence of Property 1 is that the uniform at random allocation satisfies every constraint. This implies that even with no information about the players' mean values, the uniform at random allocation will always be fair.

Note that envy-freeness in expectation satisfies Property 1 because any two players with equal allocations are never envious of each other. Proportionality in expectation also satisfies Property 1, because if every player has the same allocation, then every player is receiving exactly their proportional allocation.

**Observation 1**.: _The envy-freeness in expectation and proportionality in expectation constraints satisfy Property 1._

Our second key property is more technical and novel. Intuitively, the property requires the existence of a fractional allocation \(X^{\prime}\) that is only slightly worse than the optimal constrained allocation \(Y^{\mu}\), but unlike the latter allocation, in \(X^{\prime}\) the constraints either hold with slack or all players involved in the constraint are treated equally. Interestingly, this property does not hold for arbitrary sets of linear constraints, but relies on structure inherent to the envy-freeness in expectation and proportionality in expectation constraints. The bulk of the theoretical work of this paper is proving that the envy-freeness in expectation and proportionality in expectation constraints satisfy this property.

**Property 2**.: _Let \(Y^{\mu}\) be the solution to LP (1). Then there exists constants (relative to \(T\)) \(\gamma_{0}\) and \(C_{\mathrm{P}2}>0\) such that for any \(\gamma<\gamma_{0}\) and any \(\mu\), there exists a fractional allocation \(X^{\prime}\) such that \(\langle X^{\prime},\mu\rangle_{F}\geq\langle Y^{\mu},\mu\rangle_{F}-C_{\mathrm{ P}2}\gamma\), and such that for each \(\ell\in[L]\), either_

1. \(\langle B_{\ell}(\mu),X^{\prime}\rangle_{F}\geq c_{\ell}+\gamma\) _or_
2. \(\forall i_{1},i_{2}\in\{i:B_{\ell}(\mu)_{i}\neq\bm{\theta}\}\)_,_ \(X^{\prime}_{i_{1}}=X^{\prime}_{i_{2}}\)_._

**Lemma 1**.: _The family of envy-freeness in expectation constraints satisfies Property 2._

Proof sketch.: We will informally argue that we can transform \(Y^{\mu}\) into a fractional allocation \(X^{\prime}\) which satisfies Property 2 through Algorithm 3. Algorithm 3 iterates over 'envy-with-slack-\(\alpha\)' graphs, which track whether a player prefers their allocation by at least \(\alpha\) over another player's allocation. More specifically, given parameters \(\mu,X,\) and \(\alpha\), the corresponding 'envy-with-slack' graph has vertices \(N\) and edge set \(E\) such that a directed edge from \(i\) to \(i^{\prime}\) exists if and only if \(X_{i}\cdot\mu_{i}-X_{i^{\prime}}\cdot\mu_{i}<\alpha\). The weight of each such edge is \(X_{i}\cdot\mu_{i}-X_{i^{\prime}}\cdot\mu_{i}\). At a high level, Algorithm 3 constructs 'envy-with-slack-\(\alpha\)' graphs with progressively smaller \(\alpha\), with \(\alpha\geq\gamma\) for all iterations. The algorithm operates on sets of nodes called _equivalence classes_, where every pair of nodes in an equivalence class has the same allocation. Algorithm 3 makes progress in every iteration by either 1) merging two equivalence classes, or 2) removing an edge from the graph.

An overview of the algorithm is as follows. In each iteration, Algorithm 3 generally performs one of three operations and decreases \(\alpha\). First, if there exists an equivalence class \(S\) with at least one incoming edge but no outgoing edges, then operation remove-incoming-edge transfers allocation probability from nodes in \(S\) to all other nodes. This will remove all incoming edges to \(S\). If such an equivalence class does not exist, then Algorithm 3 finds a special type of directed cycle in the 'envy-with-slack' graph. The directed cycle is chosen so that the outgoing edge of each node \(i\) in the cycle is among \(i\)'s outgoing edges with minimal weight. Therefore, each node \(i\) in the cycle is pointing to an \(i^{\prime}\in N\) for whom \(i\) has the least slack. If there exists some node \(i^{*}\in N\) which has an edge to some but not all of the nodes in the cycle, then operation cycle-shift gives each node in the cycle half of its current allocation and half of the next node's allocation. This will remove an outgoing edge from \(i^{*}\). If such a node does not exist, then Algorithm 3 either decreases \(\alpha\) to remove an edge or creates a new equivalence class by merging all equivalence classes that the nodes in the cycle belong to via operation average-clique.

However, such a merge may lead to envy, which is removed by Algorithm 4. Each call to Algorithm 4 removes envy from at least one edge. Algorithm 4 does so by first carefully redistributing allocation among the nodes until there exists a cycle where each node has non-negative envy (which is equivalent to a cycle with non-positive slack). Each node in the cycle is then given the allocation of the nextnode in the cycle. We prove that each call to Algorithm 4 decreases the number of edges with envy, while not increasing the number of edges in the 'envy-with-slack' graph. Furthermore, Algorithm 4 does not significantly decrease the social welfare of the allocation.

The three operations and Algorithm 4 each take as input an allocation \(X\) and returns a new allocation \(X^{\prime}\) which is close in social welfare to \(X\). Furthermore, each iteration begins with an envy-free allocation, and the size of the edge set of the 'envy-with-slack' graphs never increases throughout the algorithm. The maximum size of an equivalence class is \(n\), so an edge must be removed from the 'envy-with-slack' graph every \(n\) iterations. There are at most \(n^{2}\) edges, and the algorithm therefore terminates in at most \(n^{3}\) iterations with an allocation which satisfies Property 2. For the numerous details, see Appendix F. 

**Lemma 2**.: _The family of proportionality in expectation constraints satisfies Property 2._

Proof sketch.: Define the slack \(S_{i}\) of a player \(i\) for an allocation as the amount by which that player's value for their allocation is greater than their proportional value. In other words, the slack is the amount of welfare a player can lose and still satisfy the proportionality constraint. We construct the fractional allocation \(X^{\prime}\) in one of two different ways depending on the amount of total slack for the allocation \(Y^{\mu}\) across all \(n\) players.

If the amount of total slack across all \(n\) players is less than \(\frac{bn\gamma}{a}\), then we take \(X^{\prime}=\mathrm{UAR}\). Note that the total slack is equivalent to the change in social welfare between \(Y^{\mu}\) and UAR. Therefore, because the total slack was less than \(\frac{bn\gamma}{a}\), the difference in social welfare between \(Y^{\mu}\) and UAR is at most \(\frac{bn\gamma}{a}\) which is \(O(\gamma)\). Furthermore, by definition the UAR allocation satisfies option 2 of Property 2 for all constraints \(\ell\).

If the amount of total slack is greater than \(\frac{bn\gamma}{a}\), then we construct \(X^{\prime}\) from \(Y^{\mu}\) by transferring allocation away from players with slack greater than the required \(\gamma\) and redistributing this allocation so that every player has slack of at least \(\gamma\). Specifically, each player \(i\) loses \(\Delta_{ik}\) of their allocation for item \(k\), where

\[\Delta_{ik}:=\frac{Y^{\mu}_{ik}}{\sum_{k^{\prime}=1}^{m}Y^{\mu}_{ik^{\prime}} }\cdot\frac{S_{i}}{\sum_{i^{\prime}=1}^{n}S_{i^{\prime}}}\cdot\frac{n\gamma} {a}.\]

The allocation \(X^{\prime}\) is then constructed as

\[X^{\prime}_{ik}:=Y^{\mu}_{ik}-\Delta_{ik}+\frac{1}{n}\sum_{i^{\prime}=1}^{n} \Delta_{i^{\prime}k}.\] (2)

Intuitively, this can be viewed as each player putting a part of their allocation (proportional to \(S_{i}\cdot\gamma\)) into a communal "pot." The pot, consisting of \(\sum_{i^{\prime}=1}^{n}\Delta_{i^{\prime}k}\) for item \(k\), is then divided evenly among all \(n\) players to form \(X^{\prime}\). By construction, no player loses more than \(S_{i}\) social welfare when the pot is created, and every player receives at least \(\gamma\) additional social welfare when the pot is redistributed. Therefore, in the resulting allocation \(X^{\prime}\), every player prefers their allocation to their proportional value by at least \(\gamma\), i.e. each player has a slack of at least \(\gamma\) for \(X^{\prime}\). Furthermore, the total difference in social welfare between \(Y^{\mu}\) and \(X^{\prime}\) is at most \(O(\gamma)\). We have thus shown that in both cases, \(X^{\prime}\) will satisfy all of the desired conditions. The full proof is relegated to Appendix E. 

It will be useful to introduce two further properties that are immediately satisfied by the definitions of envy-freeness in expectation and proportionality in expectation. Property 3 guarantees a form of Lipschitz continuity in \(\mu\) for the constraints. This is unsurprising, as the entries in the matrices \(B_{\ell}(\mu)\) for both envy-freeness in expectation and proportionality in expectation are linear in the entries of \(\mu\). Property 4 guarantees that the non-zero entries in the constraint matrices stay the same for all values of \(\mu\), which follows directly from Remarks 1 and 2 and the fact that \(\mu_{ik}\) is bounded away from \(0\).

**Property 3**.: _There exists a \(K>0\) such that \(\forall\mu^{1},\mu^{2}\in[a,b]^{n\times m}\) and \(\forall\epsilon>0\), if \(\|\mu^{1}-\mu^{2}\|_{1}\leq\epsilon\) then \(\|B_{\ell}(\mu^{1})-B_{\ell}(\mu^{2})\|_{1}\leq K\epsilon\)._

**Observation 2**.: _The envy-freeness in expectation and proportionality in expectation constraints satisfy Property 3._

**Property 4**.: _For all \(\mu,\mu^{\prime}\in[a,b]^{n\times m}\), \(\{i:B_{\ell}(\mu)_{i}\neq\bm{\theta}\}=\{i:B_{\ell}(\mu^{\prime})_{i}\neq\bm{ \theta}\}\)._

**Observation 3**.: _The envy-freeness in expectation and proportionality in expectation constraints satisfy Property 4._

Recall that Property 2 implies that for every constraint \(\ell\), either the constraint \(\ell\) has a slack of at least \(\gamma\) for \(X^{\prime}\) or every player involved in constraint \(\ell\) is treated equally under allocation \(X^{\prime}\). A slack of \(\gamma\) in the constraint guarantees constraint satisfaction for all \(\mu^{\prime}\) close to \(\mu\) if the constraints are continuous in \(\mu\). Treating every player equally for a given constraint also guarantees that the constraints are satisfied for all \(\mu^{\prime}\) by Property 1. Therefore, Properties 1 and 2 together with continuity (Property 3) imply that there exists a fractional allocation \(X^{\prime}\) such that the social welfare of \(X^{\prime}\) is close to the social welfare of \(Y^{\mu}\) and such that \(X^{\prime}\) not only satisfies the constraints for \(\mu\), but also satisfies the constraints for any \(\mu^{\prime}\) close to \(\mu\).

## 4 Algorithm and Regret Bounds

In this section, we present our main result, an explore-then-commit algorithm which achieves \(\tilde{O}(T^{2/3})\) regret while maintaining either proportionality in expectation or envy-freeness in expectation. The key step in Algorithm 1 is the optimization in LP (3) to guarantee that the fairness constraints are satisfied with high probability. For \(\mu\in\mathbb{R}_{+}^{n\times m}\) and \(\epsilon\in\mathbb{R}_{+}^{n\times m}\), we define the confidence region \(\mu\pm\epsilon=\{\mu^{\prime}\in\mathbb{R}^{n\times m}:\mu_{ik}-\epsilon_{ik} \leq\mu^{\prime}_{ik}\leq\mu_{ik}+\epsilon_{ik}\:\forall i,k\}\). Note that Algorithm 1 requires solving LPs with an infinite number of constraints, which we discuss further in Section 6.

```
0:\(n,m,T,\{(\{B_{\ell}(\mu),c_{\ell}\})_{\ell=1}^{L}\}_{\mu}\) for\(t\gets 1\) to \(T^{2/3}-1\)do  At time \(t\), use fractional allocation \(X^{t}=\mathrm{UAR}\). endfor \(N_{ik}\leftarrow\sum_{\tau=0}^{T^{2/3}-1}\mathbbm{1}_{k_{\tau}=k,i_{\tau}=i}\) \(\hat{\mu}_{ik}\leftarrow\frac{1}{N_{ik}}\sum_{\tau=0}^{T^{2/3}-1}\mathbbm{1}_{k _{\tau}=k,i_{\tau}=i}V_{i_{\tau}}(j_{\tau})\) \(\epsilon_{ik}=\sqrt{\log^{2}(4Tnm)/(2N_{ik})}\) \(\hat{X}\leftarrow\) Solution to the following LP: \[\max_{X} \langle X,\hat{\mu}\rangle_{F}\] s.t. \[\langle B_{\ell}(\mu),X\rangle_{F}\geq c_{\ell}\quad\forall\ell \in[L],\forall\mu\in\hat{\mu}\pm\epsilon\] \[\sum_{i=1}^{n}X_{ik}=1\quad\forall k\] (3) for\(t\gets T^{2/3}\) to \(T-1\)do  At time \(t\), use fractional allocation \(X^{t}=\hat{X}\). endfor ```

**Algorithm 1** Fair Explore-Then-Commit

**Theorem 1**.: _Suppose we are given \(n,m,T,a,b\) such that \(0<a\leq\mu^{*}_{ik}\leq b\) for all \(i\in[n]\), \(k\in[m]\). If \(\{\{(B_{\ell}(\mu),c_{\ell})\}_{\ell=1}^{L}\}_{\mu}=\{\mathrm{efe}(\mu)\}_{\mu}\) or \(\{\{(B_{\ell}(\mu),c_{\ell})\}_{\ell=1}^{L}\}_{\mu}=\{\mathrm{pe}(\mu)\}_{\mu}\), then Algorithm 1 with probability \(1-1/T\) satisfies the constraints \(\{(B_{\ell}(\mu^{*}),c_{\ell})\}_{\ell=1}^{L}\) and achieves regret of \(\tilde{O}(T^{2/3})\) for constraints \(\{(B_{\ell}(\mu^{*}),c_{\ell})\}_{\ell=1}^{L}\)._

Proof sketch.: We have already shown in Section 3 that both envy-freeness in expectation and proportionality in expectation satisfy Properties 1, 2, 3, and 4. Therefore, it suffices to show that Algorithm 1 achieves \(\tilde{O}(T^{2/3})\) regret for any family of constraints \(\{\{(B_{\ell}(\mu),c_{\ell})\}_{\ell=1}^{L}\}_{\mu}\) that satisfies Properties 1, 2, 3, and 4.

The allocations used during the warm-up steps of Algorithm 1 are uniform at random, and therefore these allocations satisfy the constraints \(\{(B_{\ell}(\mu),c_{\ell})\}_{\ell=1}^{L}\) for all \(\mu\) by Property 1. Because the fractional allocations used in the first \(T^{2/3}\) steps are all \(\mathrm{UAR}\), each arm, or (player, item) pair, will be sampled with probability \(\frac{1}{nm}\) at each step. This implies by Hoeffding's inequality that with high probability, \(N_{ik}=\tilde{\Omega}(T^{2/3})\) for all \(i,k\). The \(i,k\) entry in the \(\epsilon\) matrix is proportional to \(\frac{1}{\sqrt{N_{ik}}}\), andtherefore \(\|\epsilon\|_{1}=\tilde{O}(T^{-1/3})\) with high probability. Because the value distributions are sub-Gaussian, a standard application of Hoeffding's inequality also gives that with high probability, the true mean matrix will be within our confidence region, i.e. \(\mu^{*}\in\hat{\mu}\pm\epsilon\). To summarize, because we used \(\mathrm{UAR}\) for the first \(T^{2/3}\) steps, we have that

\[\Pr\left(\|\epsilon\|_{1}\leq\tilde{O}(T^{-1/3}),\mu^{*}\in\hat{\mu}\pm \epsilon\right)\geq 1-\frac{1}{T}.\]

For the rest of the proof we will assume that the high probability event in the equation above holds. The next step is to show that \(\hat{X}\) has \(\|\epsilon\|_{1}\) per-step regret compared to \(Y^{\mu^{*}}\). Let \(K\) be the Lipschitz constant of Property 3. Using Property 2 with \(\mu=\mu^{*}\) and \(\gamma=2K\|\epsilon\|_{1}=\tilde{O}(T^{-1/3})\) gives that there exists an allocation \(X^{\prime}\) such that the social welfare of \(X^{\prime}\) is only \(O(\|\epsilon\|_{1})\) less than the social welfare of the optimal allocation \(Y^{\mu^{*}}\) and such that every constraint \(\ell\) either has slack of at least \(2K\|\epsilon\|_{1}\) (option 1 of Property 2) or every player is treated equally in constraint \(\ell\) (option 2 of Property 2). We will now show that \(X^{\prime}\) is a solution to LP (3). If option 1 holds for constraint \(\ell\in[L]\), then by Property 3, \(X^{\prime}\) will satisfy the constraint \((B_{\ell}(\mu),c_{\ell})\) for every \(\mu\in\hat{\mu}\pm\epsilon\). Formally, if option 1 holds for constraint \(\ell\), then for any \(\mu\in\hat{\mu}\pm\epsilon\),

\[\langle B_{\ell}(\mu),X^{\prime}\rangle_{F} =\langle B_{\ell}(\mu),X^{\prime}\rangle_{F}-\langle B_{\ell}( \mu^{*}),X^{\prime}\rangle_{F}+\langle B_{\ell}(\mu^{*}),X^{\prime}\rangle_{F}\] \[=\langle B_{\ell}(\mu)-B_{\ell}(\mu^{*}),X^{\prime}\rangle_{F}+ \langle B_{\ell}(\mu^{*}),X^{\prime}\rangle_{F}\] \[\geq\langle B_{\ell}(\mu^{*}),X^{\prime}\rangle_{F}-\|B_{\ell}( \mu)-B_{\ell}(\mu^{*})\|_{1} \text{[$0\leq X^{\prime}_{ik}\leq 1,\;\forall i,k$]}\] \[\geq\langle B_{\ell}(\mu^{*}),X^{\prime}\rangle_{F}-2K\|\epsilon \|_{1} \text{[Property 3]}\] \[\geq c_{\ell}.\] [Property 2: option 1]

If option 2 holds for constraint \(\ell\in[L]\), then Properties 1 and 4 together guarantee that \(X^{\prime}\) will satisfy the constraint \((B_{\ell}(\mu),c_{\ell})\) for every \(\mu\in\hat{\mu}\pm\epsilon\). Therefore, \(X^{\prime}\) will satisfy all of the constraints \(\{B_{\ell}(\mu),c_{\ell}\}_{\ell=1}^{L}\) for every \(\mu\in\hat{\mu}\pm\epsilon\), which implies that \(X^{\prime}\) is a solution to LP (3).

Finally, because \(\hat{X}\) is the optimal solution to LP (3), \(\hat{X}\) must have higher social welfare than \(X^{\prime}\) under means \(\hat{\mu}\). Because \(\|\mu^{*}-\hat{\mu}\|_{1}\leq\|\epsilon\|_{1}\), this implies that \(\hat{X}\) must have at most \(O(\|\epsilon\|_{1})\) less social welfare than \(X^{\prime}\) under the true means \(\mu^{*}\). An application of the triangle inequality gives that,

\[\langle Y^{\mu^{*}},\mu^{*}\rangle_{F}-\langle\hat{X},\mu^{*} \rangle_{F} =\langle Y^{\mu^{*}},\mu^{*}\rangle_{F}-\langle X^{\prime},\mu^{* }\rangle_{F}+\langle X^{\prime},\mu^{*}\rangle_{F}-\langle\hat{X},\mu^{*} \rangle_{F}\] \[=\tilde{O}\left(\|\epsilon\|_{1}+\|\epsilon\|_{1}\right)\] \[=\tilde{O}(T^{-1/3}).\]

Thus, the total regret for the steps after the warm-up period is \(\tilde{O}(T^{2/3})\). The regret of the warm-up period is at most \((b-a)T^{2/3}\) due to the assumption that the mean values are bounded. We can therefore conclude that the total regret is \(\tilde{O}(T^{2/3})\), and this completes the proof of regret. Finally, we note that by construction of LP (3), if \(\mu^{*}\in\hat{\mu}\pm\epsilon\) then the chosen fractional allocations \(\hat{X}\) must also satisfy the constraints \(\{(B_{\ell}(\mu^{*}),c_{\ell})\}_{\ell=1}^{L}\) as desired. See Appendix D for the full proof. 

## 5 Lower bounds

The following lower bound shows that Theorem 1 is tight up to \(\log\) factors. An equivalent result holds for proportionality, with the same proof.

**Theorem 2**.: _There exists \(a,b,n,m\) such that no algorithm can, for all \(\mu^{*}\in[a,b]^{n\times m}\), both satisfy the envy-freeness constraints and achieve regret of less than \(\frac{T^{2/3}}{\log(T)}\) with probability at least \(1-1/T\). The same is true for the proportionality constraints._

Proof sketch.: We defer the formal proof to Appendix G and provide brief intuition here.

Suppose there are two item types and two players. In this case envy-freeness and proportionality are equivalent, and therefore we will focus on the former. Consider the following two mean value matrices.

\[\mu_{1} =\begin{bmatrix}2&3\\ 1&1\end{bmatrix} \mu_{2} =\begin{bmatrix}2&3\\ 1&1+T^{-1/3}\end{bmatrix}\]We will show that no algorithm can with probability \(1-1/T\) achieve regret of less than \(\tilde{\Omega}(T^{2/3})\) and satisfy envy-freeness in expectation for both of these distributions. First, note that the expected social welfare maximizing allocation for \(\mu_{1}\) is to give all items of type 1 to player 2 and all items of type 2 to player 1. On the other hand, any envy-free allocation for \(\mu_{2}\) must give \(\tilde{\Omega}(T^{-1/3})\) fraction of items of type 2 to player 2. This implies that if an algorithm is unable to distinguish between \(\mu_{1}\) and \(\mu_{2}\), then either the regret will be \(\tilde{\Omega}(T^{2/3})\) for \(\mu_{1}\) or the algorithm will not be envy-free for \(\mu_{2}\).

Therefore, any algorithm that has regret of less than \(\tilde{\Omega}(T^{2/3})\) and satisfies envy-freeness for both \(\mu_{1}\) and \(\mu_{2}\) must distinguish between \(\mu_{1}\) and \(\mu_{2}\). The only way to do this is to allocate at least \(\tilde{\Omega}(T^{2/3})\) items of type \(2\) to player 2. However, this will result in regret under \(\mu_{1}\) of \(\tilde{\Omega}(T^{2/3})\). 

## 6 Discussion

We conclude by discussing some limitations and open questions. First, Algorithm 1 involves solving a linear program with an infinite number of linear constraints. Linear programs with an infinite number of constraints (called semi-infinite programs) are well-studied and occur in many applications [16; 24]. We also note that a finite number of (exponentially many) constraints suffices for envy-freeness in expectation and proportionality in expectation by bounding all of the possible extreme values of \(\epsilon\). Nevertheless, we opted to avoid this representation because it significantly complicates the presentation of the algorithm. Furthermore, there also exists a polynomial time separation oracle for determining whether an allocation satisfies the infinitely many constraints, which would allow techniques such as the Ellipsoid Method [6] to solve the linear program in polynomial time.

Second, while the regret coefficients for proportionality are polynomial in \(n\), a practical limitation of Algorithm 1 for envy-freeness is that the \(\tilde{O}\) term is exponential in \(n\). We expect, however, that the worst-case bound we present in Lemma 1 is far from tight. Whether there exists a bound on the regret that is polynomial in \(n\) for learning under envy-freeness in expectation constraints is an open question for future work.

The other natural question that remains open for future work is whether we can achieve \(\tilde{O}(\sqrt{T})\) regret while maintaining envy-freeness in expectation or proportionality in expectation. If the optimal solution \(Y^{\mu^{*}}\) has a positive slack in every constraint, then an upper confidence bound (UCB) approach would be likely to work. Unfortunately, the fairness constraints for envy-freeness in expectation and proportionality in expectation are often tight for the optimal allocation. Furthermore, the constraints have a constant (greater than \(1/n\)) dependence on every unknown value in the \(\mu^{*}\) matrix. Therefore, every mean value \(\mu^{*}_{ik}\) might need to be learned with high accuracy even if the optimal allocation does not allocate item type \(k\) to player \(i\).

We also note that there exist additional (albeit less prominent) fairness notions for the problem of online fair division, such as equitability, which may satisfy additional properties that allow for lower regret. We leave the question of studying more fairness notions for future work.

Finally, a broader question is whether the connection we have established between multi-armed bandits and online fair division might be leveraged to give a fresh perspective on additional problems in this area, such as online cake cutting [31].

## Acknowledgments and Disclosure of Funding

Procaccia gratefully acknowledges research support by the National Science Foundation under grants IIS-2147187, IIS-2229881 and CCF-2007080; and by the Office of Naval Research under grant N00014-20-1-2488. Schiffer was supported by an NSF Graduate Research Fellowship. Zhang was supported by an NSF Graduate Research Fellowship.

## References

* [1] M. Aleksandrov, H. Aziz, S. Gaspers, and T. Walsh. Online fair division: Analysing a food bank problem. In _Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)_, pages 2540-2546, 2015.
* [2] S. Amani, M. Alizadeh, and C. Thrampoulidis. Linear stochastic bandits under safety constraints. _Advances in Neural Information Processing Systems_, 32, 2019.
* [3] H. Aziz and S. Mackenzie. A discrete and bounded envy-free cake cutting protocol for any number of agents. In _Proceedings of the 57th Symposium on Foundations of Computer Science (FOCS)_, pages 416-427, 2016.
* [4] E. Balkanski, S. Branzei, D. Kurokawa, and A. D. Procaccia. Simultaneous cake cutting. In _Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI)_, pages 566-572, 2014.
* [5] G. Benade, A. M. Kazachkov, A. D. Procaccia, A. Psomas, and D. Zeng. Fair and efficient online allocations. _Operations Research_, 2024. Forthcoming.
* [6] R. G. Bland, D. Goldfarb, and M. J. Todd. The ellipsoid method: A survey. _Operations Research_, 29(6):1039-1091, 1981.
* [7] S. J. Brams and A. D. Taylor. An envy-free cake division protocol. _American Mathematical Monthly_, 102(1):9-18, 1995.
* [8] E. Carlsson, D. Basu, F. Johansson, and D. Dubhashi. Pure exploration in bandits with linear constraints. In _International Conference on Artificial Intelligence and Statistics_, pages 334-342. PMLR, 2024.
* [9] G. Chen, X. Li, and Y. Ye. Fairer lp-based online allocation via analytic center. _arXiv preprint arXiv:2110.14621_, 2021.
* [10] Y. Chen, A. Cuellar, H. Luo, J. Modi, H. Nemlekar, and S. Nikolaidis. Fair contextual multi-armed bandits: Theory and experiments. In _Conference on Uncertainty in Artificial Intelligence_, pages 181-190. PMLR, 2020.
* [11] H. Claure, Y. Chen, J. Modi, M. Jung, and S. Nikolaidis. Multi-armed bandits with fairness constraints for distributing resources to human teammates. In _Proceedings of the 2020 ACM/IEEE International Conference on Human-Robot Interaction_, pages 299-308, 2020.
* [12] J. Edmonds and K. Pruhs. Cake cutting really is not a piece of cake. In _Proceedings of the 17th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA)_, pages 271-278, 2006.
* [13] Y. Gal, M. Mash, A. D. Procaccia, and Y. Zick. Which is the fairest (rent division) of them all? _Journal of the ACM_, 64(6): article 39, 2017.
* [14] J. Goldman and A. D. Procaccia. Spliddit: Unleashing fair division algorithms. _SIGecom Exchanges_, 13(2):41-46, 2014.
* [15] R. Grazzi, A. Akhavan, J. Falk, L. Cella, and M. Pontil. Group meritocratic fairness in linear contextual bandits. _Advances in Neural Information Processing Systems_, 35:24392-24404, 2022.
* [16] R. Hettich and K. Kortanek. Semi-infinite programming: theory, methods, and applications. _SIAM review_, 35(3):380-429, 1993.
* [17] M. Joseph, M. Kearns, J. Morgenstern, S. Neel, and A. Roth. Fair algorithms for infinite and contextual bandits. _arXiv:1610.09559_, 2016.
* [18] M. Joseph, M. Kearns, J. H. Morgenstern, and A. Roth. Fairness in learning: Classic and contextual bandits. _Advances in Neural Information Processing Systems_, 29, 2016.

* [19] Min Kyung Lee, Daniel Kusbit, Anson Kahng, Ji Tae Kim, Xinran Yuan, Allissa Chan, Daniel See, Ritesh Noothigattu, Siheon Lee, Alexandros Psomas, et al. Webildai: Participatory framework for algorithmic governance. _Proceedings of the ACM on human-computer interaction_, 3(CSCW):1-35, 2019.
* [20] F. Li, J. Liu, and B. Ji. Combinatorial sleeping bandits with fairness constraints. _IEEE Transactions on Network Science and Engineering_, 7(3):1799-1813, 2019.
* [21] Q. Liu, W. Xu, S. Wang, and Z. Fang. Combinatorial bandits with linear constraints: Beyond knapsacks and fairness. _Advances in Neural Information Processing Systems_, 35:2997-3010, 2022.
* [22] X. Liu, B. Li, P. Shi, and L. Ying. An efficient pessimistic-optimistic algorithm for stochastic linear bandits with general constraints. _Advances in Neural Information Processing Systems_, 34:24075-24086, 2021.
* [23] Y. Liu, G. Radanovic, C. Dimitrakakis, D. Mandal, and D. C. Parkes. Calibrated fairness in bandits. _arXiv preprint arXiv:1707.01875_, 2017.
* [24] M. Lopez and G. Still. Semi-infinite programming. _European Journal of Operational Research_, 180(2):491-518, 2007.
* [25] Marios Mertzanidis, Alexandros Psomas, and Paritosh Verma. Automating food drop: The power of two choices for dynamic and fair food allocation. _arXiv preprint arXiv:2406.06363_, 2024.
* [26] A. Moradipari, M. Alizadeh, and C. Thrampoulidis. Linear thompson sampling under unknown linear constraints. In _ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)_, pages 3392-3396. IEEE, 2020.
* [27] A. Pacchiano, M. Ghavamzadeh, P. Bartlett, and H. Jiang. Stochastic bandits with linear constraints. In _International Conference on Artificial Intelligence and Statistics_, pages 2827-2835. PMLR, 2021.
* [28] V. Patil, G. Ghalme, V. Nair, and Y. Narahari. Achieving fairness in the stochastic multi-armed bandit problem. _Journal of Machine Learning Research_, 22(174):1-31, 2021.
* [29] C. Schumann, Z. Lang, N. Mattei, and J. P. Dickerson. Group fairness in bandit arm selection. _arXiv preprint arXiv:1912.03802_, 2019.
* [30] F. E. Su. Rental harmony: Sperner's lemma in fair division. _American Mathematical Monthly_, 106(10):930-942, 1999.
* [31] T. Walsh. Online cake cutting. In _Proceedings of the 3rd International Conference on Algorithmic Decision Theory (ADT)_, pages 292-305, 2011.
* [32] L. Wang, Y. Bai, W. Sun, and T. Joachims. Fairness of exposure in stochastic bandits. In _International Conference on Machine Learning_, pages 10686-10696. PMLR, 2021.
* [33] W. Wei, X. Ma, and J. Wang. Fair adaptive experiments. _Advances in Neural Information Processing Systems_, 36, 2024.
* [34] Y. Wu, Z. Zheng, and T. Zhu. Best arm identification with fairness constraints on subpopulations. In _2023 Winter Simulation Conference (WSC)_, pages 540-551. IEEE, 2023.
* [35] Hakuei Yamada, Junpei Komiyama, Kenshi Abe, and Atsushi Iwasaki. Learning fair division from bandit feedback. In _International Conference on Artificial Intelligence and Statistics_, pages 3106-3114. PMLR, 2024.

## Appendix A Algorithmic Representation of Model

```
1:\(\mathrm{ALG}\)
2:\(\forall i,\ A_{i}^{0}\leftarrow\{\},H_{0}\leftarrow\{\}\)
3:for\(t\gets 1\) to \(T\)do
4:\(X_{t}\leftarrow\mathrm{ALG}(H_{t})\)
5:\(k_{t}\sim\mathcal{D}\)
6: Generate item \(j_{t}\) of type \(k_{t}\) (i.e. \(V_{i}(j_{t})\sim N(\mu_{ik_{t}}^{*},1),\ \forall i\in N\) )
7:\(i_{t}\leftarrow\) Sample from \(\left(X_{t}\right)_{k_{t}}^{\top}\)
8:\(A_{i_{t}}^{t}=A_{i_{t}}^{t-1}+\{j_{t}\}\)
9:\(H_{t}\gets H_{t-1}+(k_{t},i_{t},V_{i_{t}}(j_{t}))\)
10:endfor
11:return\(A=(A_{1}^{T},A_{2}^{T},...,A_{n}^{T})\) ```

**Algorithm 2** [Online Item Allocation]

## Appendix B Motivating Fairness in Expectation

In this section, we will explore the relationship between envy-freeness in expectation and realized envy, as well as the relationship between requiring envy-freeness in expectation at every time step and only requiring envy-freeness in expectation at the end of round \(T\). For this section, we will use the following notation. For any algorithm \(\mathrm{ALG}\), we denote \(X_{t}=\mathrm{ALG}(H_{t})\) as the fractional allocation used at time \(t\), and \(\mathrm{Pr}_{\mathrm{ALG}}(i,k,H_{t}):=(X_{t})_{ik}\).

Previous works on fair online allocation of indivisible goods have focused on the fairness of the final, realized allocation instead of studying fairness in expectation as in Definitions 1 and 2[5]. We define the realized envy of an allocation below.

**Definition 4**.: The realized envy of allocation \(A\) at time \(\tau\) is \(\max_{i,i^{\prime}}V_{i}(A_{i^{\prime}}^{\tau})-V_{i}(A_{i}^{\tau})\).

We show in the following theorems that algorithms which are envy-free in expectation are within a \(\log(T)\) factor of being "optimal" in terms of final realized envy. Informally, Theorem 3 shows that in our setting, no algorithm can with high probability output an allocation \(A(\mathrm{ALG})\) with realized envy less than \(\sqrt{t}\). Conversely, Theorem 4 shows that any algorithm \(\mathrm{ALG}\) that satisfies envy-freeness in expectation will output a final allocation \(A(\mathrm{ALG})\) with realized envy of at most \(\sqrt{T}\log(T)\) with high probability.

**Theorem 3**.: _Suppose \(\mu^{*}\) is known. For any algorithm \(\mathrm{ALG}\) and for any \(\tau\in[T]\), with probability at least \(1/16\) the allocation \(A^{\tau}(\mathrm{ALG})\) has realized envy of more than \(\sqrt{\tau}\)._

Proof.: Assume there are two players and only one item type, and assume that all values are drawn from \(\mathcal{N}(\mu,1)\). Fix \(\tau\geq\log^{2}(T)\). As in Algorithm 2, define \(i_{t}\in\{1,2\}\) as the player allocated the item at time \(t\). The realized envy of the two players can be written as:

\[\text{Realized Envy of Player $1$ at time $\tau=\left(\sum_{t=0}^{\tau} \mathbbm{1}_{i_{t}=1}\cdot V_{1}(j_{t})\right)-\left(\sum_{t=0}^{\tau} \mathbbm{1}_{i_{t}=2}\cdot V_{1}(j_{t})\right)$}\] (4) \[\text{Realized Envy of Player $2$ at time $\tau=\left(\sum_{t=0}^{\tau} \mathbbm{1}_{i_{t}=2}\cdot V_{2}(j_{t})\right)-\left(\sum_{t=0}^{\tau} \mathbbm{1}_{i_{t}=1}\cdot V_{2}(j_{t})\right)$}\,.\] (5)

Let \(v_{i}^{a}\) be the value of the assigned player for item \(i\), and \(v_{i}^{a}\) be the value of the unassigned player for item \(i\). Note that \(v_{i}^{a},v_{i}^{u}\sim N(\mu,1)\), because at the time of allocation, \(\mathrm{ALG}\) does not know either player's value for the item, and player values are therefore independent of the assignment.

By this coupling argument, Equations (4) and (5) can be rewritten as:

\[\text{Realized Envy of Player $1$ at time $\tau=\left(\sum_{t=0}^{\tau} 1_{i_{t}=1}\cdot v_{i}^{a}\right)-\left(\sum_{i=0}^{\tau}1_{i_{t}=2}\cdot v_{ i}^{u}\right)$}\] (6)(7)

By the Central Limit Theorem, \(\sum_{i=0}^{\tau}v_{i}^{a}\) and \(\sum_{i=0}^{\tau}v_{i}^{u}\) are both \(N(\tau\cdot\mu,\tau)\). Therefore, for any \(\tau\), with probability at least \(1/16\), we have that

\[\sum_{t=0}^{\tau}v_{t}^{a}\leq\tau\mu-\sqrt{\tau}\quad\text{and}\]

\[\sum_{t=0}^{\tau}v_{t}^{u}\geq\tau\mu+\sqrt{\tau}.\]

Putting these equations together, we have that

\[\sum_{t=0}^{\tau}v_{t}^{a}+2\sqrt{\tau}\leq\sum_{t=0}^{\tau}v_{t}^{u}.\]

However, this result with Equations (6) and (7) implies that the envy must be at least \(\sqrt{\tau}\) for any choice of \(\{i_{t}\}\). Therefore, we have shown that with probability at least \(1/16\), the envy at time \(\tau\) will be at least \(\sqrt{\tau}\) for any possible algorithm. 

**Theorem 4**.: _Suppose \(\mu^{*}\) is known. Also assume that all of the value distributions are bounded by a constant \(B\). If \(\mathrm{ALG}\) is deterministic (i.e. \(\mathrm{ALG}(H_{t})\) is a deterministic function of \(H_{t}\)) and satisfies envy-freeness in expectation, then with probability \(1-o(1/T)\), the realized envy of \(A^{\tau}(\mathrm{ALG})\) at every time \(\tau\in[T]\) is at most \(\sqrt{\tau}\log(T)\)._

Proof.: We will bound the realized envy of \(A(\mathrm{ALG})\) between any two specific players \(i,i^{\prime}\), which will then imply a bound on the realized envy of \(A(\mathrm{ALG})\) by a union bound. The key observation is that each round of Algorithm 2 consists of first a random draw from \(\mathcal{D}\) to determine the item type \(k_{t}\) and then a draw from \(\xi_{t}\sim\mathrm{Unif}([0,1])\) which determines the player to which the item is allocated based on \(X_{t}=\mathrm{ALG}(H_{t})\). Formally, the \(t^{\mathrm{th}}\) item is allocated to player \(i\) if

\[\xi_{t}\in\left[\sum_{i^{\prime\prime}=1}^{i-1}(X_{t})_{i^{\prime\prime}k_{t} }\,\ \sum_{i^{\prime\prime}=1}^{i}(X_{t})_{i^{\prime\prime}k_{t}}\right].\]

Define \(\{v_{ti^{\prime\prime}}\}_{i^{\prime\prime}=1}^{n}\) as the values of the players for the item at time \(t\). This is the final source of randomness in round \(t\). Therefore, the allocation of any player at time \(\tau\) is a function of the random variable sequence \(\{(k_{t},\xi_{t},\{v_{ti^{\prime\prime}}\}_{i^{\prime\prime}=1}^{n})\}_{t=0}^ {\tau-1}\).

Let \(E_{\tau}\) represent the envy accrued by player \(i\) for player \(i^{\prime}\) up until but not including time \(\tau\). Then

\[E_{\tau} =\sum_{t=0}^{\tau-1}v_{ti}\cdot\sum_{k=1}^{m}\mathbbm{1}_{k_{t}=k }\cdot\left(\mathbbm{1}_{\xi_{t}\in[\sum_{s=1}^{i^{\prime}-1}(X_{t})_{sk_{t}},\sum_{s=1}^{i^{\prime}}(X_{t})_{sk_{t}}]}-\mathbbm{1}_{\xi_{t}\in[\sum_{s=1} ^{i-1}(X_{t})_{sk_{t}},\sum_{s=1}^{i}(X_{t})_{sk_{t}}]}\right)\] \[:=f\left(\{(k_{t},\xi_{t},\{v_{ti^{\prime\prime}}\}_{i^{\prime \prime}=1}^{n})\}_{t=0}^{\tau-1}\right).\]

Now we will apply McDiarmid's inequality to the function \(f\left(\{(k_{t},\xi_{t},\{v_{ti^{\prime\prime}}\}_{i^{\prime\prime}=1}^{n})\}_ {t=0}^{\tau-1}\right)\). First, we show that the bounded condition is satisfied. If \(\{(k_{t},\xi_{t},\{v_{ti^{\prime\prime}}\}_{i^{\prime\prime}=1}^{n})\}_{t=0}^ {\tau-1}\) and \(\{(k^{\prime}_{t},\xi^{\prime}_{t},\{v^{\prime}_{ti^{\prime\prime}}\}_{i^{ \prime\prime}=1}^{n})\}_{t=0}^{\tau-1}\) differ only at the \(s^{\mathrm{th}}\) element for any \(s\in[0,\tau-1]\), then

\[\left|f\left(\{(k_{t},\xi_{t},\{v_{ti^{\prime\prime}}\}_{i^{\prime\prime}=1}^{n}) \}_{t=0}^{\tau-1}\right)-f\left(\{(k^{\prime}_{t},\xi^{\prime}_{t},\{v_{ti^{ \prime\prime}}\}_{i^{\prime\prime}=1}^{n})\}_{t=0}^{\tau-1}\right)\right|\leq B.\]

Therefore, we can apply McDiarmid's inequality to get that

\[\Pr\left(\left|f\left(\{(k_{t},\xi_{t},\{v_{ti^{\prime\prime}}\}_{i^{\prime \prime}=1}^{n})\}_{t=0}^{\tau-1}\right)-\mathbb{E}\left[f\left(\{(k_{t},\xi_{t },\{v_{ti^{\prime\prime}}\}_{i^{\prime\prime}=1}^{n})\}_{t=0}^{\tau-1}\right) \right]\right|\geq\sqrt{\tau}\log(T)\right) \leq e^{-\log^{2}(T)/(2B^{2})}\] \[\leq T^{-\log(T)/(2B^{2})}.\]Since \(\mathrm{ALG}\) is envy-free in expectation, we know that \(\mathbb{E}\left[f\left(\{(k_{t},\xi_{t},\{v_{ti^{\prime\prime}}\}_{i^{\prime}=1}^{ n})\}_{t=0}^{\tau-1}\right)\right]\leq 0\). Therefore, we must have that

\[\Pr\left(f\left(\{(k_{t},\xi_{t},\{v_{ti^{\prime\prime}}\}_{i^{\prime\prime}=1}^ {n})\}_{t=0}^{\tau-1}\right)\geq\sqrt{\tau}\log(T)\right)\leq T^{-\log(T)/(2B^ {2})}.\]

Taking a union bound over all pairs \(i,i^{\prime}\) and all \(\tau\in[T]\), we have that

\[\Pr(\exists\tau:\text{Realized envy at time }\tau\text{ is }\geq\sqrt{\tau}\log(T)\ )\leq n^{2}T\cdot T^{-2\log(T)/b^{2}}=o(1/T).\]

Therefore, with probability \(1-o(1/T)\), the realized envy at ever time \(\tau\) is at most \(\sqrt{\tau}\log(T)\). 

Note that Theorem 3 does not contradict the results of Benade et al. [5], who achieve envy-freeness of the realized allocation with high probability when the true player values for the items are known at time of allocation (as opposed to our model which only knows the item type). When player values for item \(j_{t}\) are known before assignment, Theorem 3 does not apply.

We also defined envy-freeness in expectation as a constraint which needs to hold at every time step \(t\). In some fair division applications, we may only care about "fairness" of the total allocation at the end of the process. Therefore, we could instead only require that no player is envious in expectation of any other player at the end of all \(T\) rounds. However, Theorem 5 shows that this is equivalent to maintaining envy-freeness in expectation at all times \(t\in[T]\) when maximizing social welfare.

**Theorem 5**.: _Suppose \(\mu^{*}\) is known. Let \(\mathcal{E}\) be the class of all algorithms that are envy-free in expectation and let \(\mathcal{F}\) be the class of all algorithms which satisfy \(\mathbb{E}[V_{i}(A_{i}^{T})]\geq\max_{i^{\prime}\in[n]}\mathbb{E}[V_{i}(A_{i^ {\prime}}^{T})]\) for all \(i\). Then_

\[\max_{\mathrm{ALG}\in\mathcal{F}}\mathbb{E}[\mathrm{sw}(A(\mathrm{ALG}))]= \max_{\mathrm{ALG}\in\mathcal{E}}\mathbb{E}[\mathrm{sw}(A(\mathrm{ALG}))].\]

Proof.: By definition, \(\mathcal{E}\subseteq\mathcal{F}\), which proves one direction of the desired equality. We will now show that for any \(\mathrm{ALG}\in\mathcal{F}\), there exists an algorithm \(\mathrm{ALG}^{\prime}\in\mathcal{E}\) such that

\[\mathbb{E}[\mathrm{sw}(A(\mathrm{ALG}^{\prime}))]=\mathbb{E}[\mathrm{sw}(A( \mathrm{ALG}))].\]

First, observe that by the definition of \(\mathcal{F}\), we have that for all \(i,i^{\prime}\),

\[\frac{1}{T}\,\mathbb{E}\left[\sum_{t\in[T]}\sum_{k}\Pr_{\mathrm{ ALG}}(i,k,H_{t})\mu_{ik}\Pr_{\mathcal{D}}(k)\right]\geq\frac{1}{T}\,\mathbb{E} \left[\sum_{t\in[T]}\sum_{k}\Pr_{\mathrm{ALG}}(i^{\prime},k,H_{t})\mu_{ik} \Pr_{\mathcal{D}}(k)\right].\] (8)

By linearity of expectation, Equation (8) is equivalent to

\[\frac{1}{T}\sum_{t\in[T]}\sum_{k}\int_{H_{t}}\Pr_{\mathrm{ ALG}}(i,k,H_{t})dH_{t}\cdot\mu_{ik}\Pr_{\mathcal{D}}(k)\geq\frac{1}{T}\sum_{t\in[T]} \sum_{k}\int_{H_{t}}\Pr_{\mathrm{ALG}}(i^{\prime},k,H_{t})dH_{t}\cdot\mu_{ik} \Pr_{\mathcal{D}}(k).\] (9)

Furthermore, by definition

\[\mathbb{E}[\mathrm{sw}(\mathrm{ALG})] =\mathbb{E}\left[\sum_{i=1}^{n}\sum_{t\in[T]}\sum_{k}\Pr_{ \mathrm{ALG}}(i,k,H_{t})\mu_{ik}\Pr_{\mathcal{D}}(k)\right]\] \[=\sum_{i=1}^{n}\sum_{t\in[T]}\sum_{k}\int_{H_{t}}\Pr_{\mathrm{ ALG}}(i,k,H_{t})dH_{t}\cdot\mu_{ik}\cdot\Pr_{\mathcal{D}}(k)\] \[=\sum_{i=1}^{n}\sum_{k}\left(\sum_{t\in[T]}\int_{H_{t}}\Pr_{ \mathrm{ALG}}(i,k,H_{t})dH_{t}\right)\cdot\mu_{ik}\cdot\Pr_{\mathcal{D}}(k).\]

We will construct the algorithm \(\mathrm{ALG}^{\prime}\) as follows. Suppose \(\mathrm{ALG}^{\prime}\) is time-independent and history-independent, such that for all \(t,H_{t}\),

\[\Pr_{\mathrm{ALG}^{\prime}_{t}}(i,k,H_{t})=\frac{1}{T}\sum_{s\in[T]}\int_{ \mathrm{ALG}_{s}}(i,k,H_{s})dH_{s}.\]

[MISSING_PAGE_FAIL:16]

Proof.: As in the proof of Theorem 3, assume there are two players and only one item type, and assume that all values are drawn from \(\mathcal{N}(\mu,1)\). Then the realized proportionality gap of the two players can be written as:

\[\text{Realized proportionality gap of Player }1\text{ at time }\tau=\frac{1}{2}\left(\sum_{t=0}^{\tau} \mathbbm{1}_{i_{t}=1}\cdot V_{1}(j_{t})\right)-\frac{1}{2}\left(\sum_{t=0}^{ \tau}\mathbbm{1}_{i_{t}=2}\cdot V_{1}(j_{t})\right)\] (10) \[\text{Realized proportionality gap of Player }2\text{ at time }\tau=\frac{1}{2}\left(\sum_{t=0}^{\tau} \mathbbm{1}_{i_{t}=2}\cdot V_{2}(j_{t})\right)-\frac{1}{2}\left(\sum_{t=0}^{ \tau}\mathbbm{1}_{i_{t}=1}\cdot V_{2}(j_{t})\right)\] (11)

These equations only differ from those of realized envy by a scalar factor, and therefore the rest of the proof follows exactly as in Theorem 3. 

**Theorem 8**.: _Suppose \(\mu^{*}\) is known. Also assume that all of the value distributions are bounded by a constant \(B\). If \(\mathrm{ALG}\) is deterministic (i.e. \(\mathrm{ALG}(H_{t})\) is a deterministic function of \(H_{t}\)) and satisfies proportionality in expectation, then with probability \(1-o(1/T)\), the realized proportionality gap of \(A^{\tau}(\mathrm{ALG})\) at every time \(\tau\in[T]\) is at most \(\sqrt{\tau}\log(T)\)._

Proof.: In this proof, we can let \(E_{t}\) be the accrued "proportionality gap" of any player \(i\). Then as in Theorem 4, an application of McDiarmid's inequality allows us to bound the realized proportionality gap with high probability for all \(\tau\). 

The following two theorems are analogs of Theorem 5 and Theorem 6 for envy-freeness in expectation. Together, these theorems imply that maximizing social welfare subject to proportionality in expectation at every time step is equivalent to maximizing social welfare subject to proportionality in expectation only at the end of round \(T\).

**Theorem 9**.: _Suppose \(\mu^{*}\) is known. Let \(\mathcal{E}\) be the class of all algorithms that are proportional in expectation and let \(\mathcal{F}\) be the class of all algorithms which satisfy \(\mathbb{E}[V_{i}(A_{i}^{T})]\geq\frac{1}{n}\sum_{i^{\prime}\in[n]}\mathbb{E}[V _{i}(A_{i^{\prime}}^{T})]\) for all \(i\). Then_

\[\max_{\mathrm{ALG}\in\mathcal{F}}\mathbb{E}[\mathrm{sw}(A(\mathrm{ALG}))]= \max_{\mathrm{ALG}\in\mathcal{E}}\mathbb{E}[\mathrm{sw}(A(\mathrm{ALG}))].\]

Proof.: Suppose \(\mathrm{ALG}\in\mathcal{F}\). We will define \(\mathrm{ALG}^{\prime}\) as in Theorem 5 to be

\[\Pr_{\mathrm{ALG}^{\prime}_{t}}(i,k,H_{t})=\frac{1}{T}\sum_{s\in[T]}\int\Pr_{ \mathrm{ALG}_{s}}(i,k,H_{s})dH_{s}.\]

By this construction, \(\mathrm{ALG}^{\prime}\in\mathcal{E}\) because

\[\sum_{k}\Pr_{\mathrm{ALG}^{\prime}_{t}}(i,k,H_{t})\mu_{ik}\Pr_{ \mathcal{D}}(k)\] \[=\sum_{k}\frac{1}{T}\sum_{s\in[T]}\int\Pr_{\mathrm{ALG}_{s}}(i,k, H_{s})dH_{s}\mu_{ik}\Pr_{\mathcal{D}}(k)\] \[=\frac{1}{T}\sum_{k}\sum_{s\in[T]}\int\Pr_{\mathrm{ALG}_{s}}(i,k, H_{s})dH_{s}\mu_{ik}\Pr_{\mathcal{D}}(k)\] \[\geq\frac{1}{Tn}\sum_{i^{\prime}=1}^{n}\sum_{k}\sum_{s\in[T]}\int \Pr_{\mathrm{ALG}_{s}}(i^{\prime},k,H_{s})dH_{s}\mu_{ik}\Pr_{\mathcal{D}}(k) \text{[ALG}\in\mathcal{F}]\] \[=\sum_{i^{\prime}=1}^{n}\sum_{k}\frac{1}{Tn}\sum_{s\in[T]}\int \Pr_{\mathrm{ALG}_{s}}(i^{\prime},k,H_{s})dH_{s}\mu_{ik}\Pr_{\mathcal{D}}(k)\] \[=\frac{1}{n}\sum_{i^{\prime}=1}^{n}\sum_{k}\Pr_{\mathrm{ALG}^{ \prime}_{t}}(i^{\prime},k,H_{t})\mu_{ik}\Pr_{\mathcal{D}}(k).\]Because \(\mathcal{E}\subseteq\mathcal{F}\) and because we showed in Theorem 5 that \(\mathrm{ALG}^{\prime}\) and \(\mathrm{ALG}\) have the same expected social welfare, the desired result follows. 

**Theorem 10**.: _The algorithm which maximizes expected social welfare subject to \(\mathrm{PE}\) up to time \(T\) is time-independent, history-independent, and can be calculated in polynomial time._

Proof.: By Theorem 9, there exists an optimal algorithm that satisfies proportionality in expectation that is time-independent and history-independent. To find the best such fractional allocation, all we must do is solve LP (1) with the proportionality in expectation constraints. 

## Appendix C Additional Model Notes

### Choice of \(\mathcal{D}\)

In the body of the paper, we focus on the case when \(\mathcal{D}\) is the uniform distribution over item types. However, our results generalize to any distribution \(\mathcal{D}\) which does not depend on \(T\). In this case, the social welfare of a fractional allocation \(X\) becomes \(\sum_{i,k}X_{ik}\Pr_{\mathcal{D}}(k)\mu_{ik}\). For a matrix \(\nu\in\mathbb{R}^{n\times m}\), define \(f_{\mathcal{D}}(\nu)=\nu^{\prime}\in\mathbb{R}^{n\times m}\), where \(\nu^{\prime}_{ik}=n\cdot\Pr_{\mathcal{D}}(k)\cdot\mu_{ik}\). For mean values \(\mu^{*}\), define \(\mu^{\prime}=f_{\mathcal{D}}(\mu^{*})\). Then social welfare of a fractional allocation \(X\) with means \(\mu^{*}\) and distribution \(\mathcal{D}\) is then simply \(\frac{1}{n}\langle X,\mu^{\prime}\rangle_{F}\) as in the uniform \(\mathcal{D}\) case. Similarly, the envy-freeness in expectation or proportionality in expectation constraints on \(X\) with means \(\mu^{*}\) and item distribution \(\mathcal{D}\) can be represented as \(\langle B_{\ell}(\mu^{\prime}),X\rangle_{F}\geq c_{\ell}\), which is an equivalent form to the constraints when \(\mathcal{D}\) is uniform. Therefore, for arbitrary \(\mathcal{D}\) we can use Algorithm 1 with only two slight modifications. The first is we must transform the \(\hat{\mu},\mu\), and other components of the linear programs using the function \(f_{\mathcal{D}}\). The second modification is that we potentially need more exploration steps (larger \(T\)) in the warm-up period to guarantee the same level of estimation of \(\mu^{*}\), depending on the value of \(\min_{i,k}\Pr_{\mathcal{D}}(k)\). However, since we require that \(\mathcal{D}\) does not depend on \(T\), this will not change the overall regret of the algorithm.

### Lower Bound on Means

In this section, we show that if the means of player values can be arbitrarily close to zero, then it can be impossible to achieve a regret of \(o(T)\).

**Theorem 11**.: _For \(\epsilon>0\), there does not exist an algorithm \(\mathrm{ALG}\) such that for any possible \(\mu^{*}\in[0,\epsilon]^{n\times m}\), for every \(t\) the fractional allocation \(X_{t}\) chosen by \(\mathrm{ALG}\) satisfies envy-freeness in expectation with probability greater than \(1/2\) and the regret of \(\mathrm{ALG}\) is \(o(T)\). The same result also holds for proportionality in expectation._

Proof.: W.l.o.g. assume that \(\epsilon=1\). The proof also holds for any other constant \(\epsilon\). Suppose the underlying value distributions are Bernoulli, that we have two players and two item types, and assume \(T\geq 2\). We will consider two cases for \(\mu^{*}\) and show that no algorithm can with probability greater than \(1/2\) satisfy the constraints and have regret of \(o(T)\) for both of these cases of \(\mu^{*}\).

First, let

\[\mu^{1}=\begin{bmatrix}1/T^{2}&0\\ 1&0.5\end{bmatrix}\quad\text{and}\]

\[\mu^{2}=\begin{bmatrix}0&1/T^{2}\\ 1&0.5\end{bmatrix}.\]

If \(\mu^{*}=\mu^{1}\) or \(\mu^{*}=\mu^{2}\), then player \(1\) will not have a realized value of \(1\) for any of the \(T\) items with probability at least \(1/2\). Therefore, no algorithm can differentiate between \(\mu^{*}=\mu^{1}\) and \(\mu^{*}=\mu^{2}\) with probability at least \(1/2\). The only fractional allocation that is envy-free for both \(\mu^{*}=\mu^{1}\) and \(\mu^{*}=\mu^{2}\) is the uniform at random allocation. However, this allocation has regret of \(\Omega(T)\) for \(\mu^{*}=\mu^{2}\), as the best fractional allocation when \(\mu^{*}=\mu^{2}\) is the fractional allocation

\[Y^{\mu^{2}}=\begin{bmatrix}0&0.5\\ 1&0.5\end{bmatrix}.\]

This proves the desired result that no algorithm can be envy-free for \(\mu^{*}\) and have \(o(T)\) regret for both possible realizations of \(\mu^{*}\). Similarly, the uniform at random allocation is the only proportional allocation in this example, and therefore the same result holds.

Proof of Theorem 1

Observations 1, 2, and 3 give that the proportionality in expectation constraints and the envy-freeness in expectation constraints satisfy Properties 1, 3, and 4 respectively. Lemmas 1 and 2 respectively give that the proportionality in expectation constraints and the envy-freeness in expectation constraints satisfy Property 2. These results combined with Lemma 3 directly prove Theorem 1.

**Lemma 3**.: _Let \(\left\{\{(B_{\ell}(\mu),c_{\ell})\}_{\ell=1}^{L}\right\}_{\mu\in[a,b]^{n\times m}}\) be a family of constraints that satisfy Properties 1, 3, 4, and 2. Then with probability \(1-1/T\), Algorithm 1 satisfies constraints \(\{(B_{\ell}(\mu^{*}),c_{\ell})\}_{\ell=1}^{L}\) and has regret of \(\tilde{O}(T^{2/3})\) for constraints \(\{(B_{\ell}(\mu^{*}),c_{\ell})\}_{\ell=1}^{L}\)._

Proof.: First, we note that the regret of the first \(T^{2/3}\) steps can be bounded by

\[\sum_{t=0}^{T^{2/3}-1}\langle Y^{\mu^{*}},\mu^{*}\rangle_{F}-\langle X_{t},\mu ^{*}\rangle_{F}\leq T^{2/3}(b-a)=O(T^{2/3}).\] (12)

By Property 1, the uniform at random allocation satisfies constraints \(\{(B_{\ell}(\mu),c_{\ell})\}_{\ell=1}^{L}\). Therefore, \(X_{t}\) satisfies the constraints for all \(t<T^{2/3}\). Furthermore, because the fractional allocation was uniform at random for the first \(T^{2/3}\) steps, we have that for sufficiently large \(T\),

\[\Pr\left(\|\epsilon\|_{1}\leq nm\sqrt{nm\log^{2}(4nmT)}\cdot T^{- 1/3}\right)\] \[\geq\Pr\left(\forall i\in[n],k\in[m],\epsilon_{ik}\leq\sqrt{nm \log^{2}(4nmT)}\cdot T^{-1/3}\right)\] \[=\Pr\left(\forall i\in[n],k\in[m],N_{ik}\geq\frac{T^{2/3}}{nm}\right)\] \[=\Pr\left(\forall i\in[n],k\in[m],N_{ik}\geq\frac{T^{2/3}}{nm}- \frac{T^{2/3}}{2nm}\right)\] \[\geq\Pr\left(\forall i\in[n],k\in[m],N_{ik}\geq\frac{T^{2/3}}{nm}- \sqrt{\log(4nmT)}\cdot T^{1/3}\right)\] \[\geq 1-nme^{-2\log(4nmT)}\] \[\geq 1-\frac{1}{2T},\] (13)

where the second to last inequality is by Hoeffding's Inequality and a union bound. This implies that with probability \(1-\frac{1}{2T}\), \(\|\epsilon\|_{1}=\tilde{O}(T^{-1/3})\). Because the values are drawn from a Sub-Gaussian distribution, there exists a constant \(c>0\) (which depends on the distribution of the values) such that by Hoeffding's inequality,

\[\Pr\left(\forall i\in[n],k\in[m],|\hat{\mu}_{ik}-\mu^{*}_{ik}| \leq\epsilon_{ik}\right) \geq 1-2nme^{-c\log^{2}(4nmT)}\] \[\geq 1-2nm\left(\frac{1}{4nmT}\right)^{c\log(4nmT)}\] \[\geq 1-\frac{1}{2T}.\] [For sufficiently large \[T\] ] (14)

For the rest of this proof, we will assume that

\[\|\epsilon\|_{1}\leq\tilde{O}(T^{-1/3})\] (15)

and

\[\forall i\in[n],k\in[m],|\hat{\mu}_{ik}-\mu^{*}_{ik}|\leq\epsilon_{ik},\] (16)

which by Equations (13) and (14) happens with probability \(1-1/T\).

If \(K\) is the Lipschitz constant for this family of constraints, then by Equation (15), \(2K\|\epsilon\|_{1}\leq\tilde{O}(T^{-1/3})\leq\gamma_{0}\) for sufficiently large \(T\), where \(\gamma_{0}\) is from Property 2. Therefore, taking \(\gamma=2K\|\epsilon\|_{1}\) in Property 2 gives that there exists some fractional allocation \(X^{\prime}\) such that

\[\left|\langle\mu^{*},Y^{\mu^{*}}\rangle_{F}-\langle\mu^{*},X^{\prime}\rangle_ {F}\right|\leq O(\|\epsilon\|_{1}),\] (17)

[MISSING_PAGE_EMPTY:20]

1. \(X^{\prime}\) decreases the social welfare relative to \(Y^{\mu}\) by \(O(\gamma)\) and
2. For every constraint \(i\in[n]\), either \(X^{\prime}=\mathrm{UAR}\) or \[X^{\prime}_{i}\cdot\mu_{i}-\frac{1}{n}\|\mu_{i}\|_{1}\geq\gamma.\] (23)

LP (22) has \(n\) constraints, one corresponding to each player. Define

\[S_{i}=Y^{\mu}_{i}\cdot\mu_{i}-\frac{1}{n}\|\mu_{i}\|_{1}.\] (24)

\(S_{i}\) is the slack on the \(i\)th constraint when using the optimal solution \(Y^{\mu}\). Now we have two cases depending on \(\sum_{i=1}^{n}S_{i}\), the total amount of slack across all \(n\) players.

**Case 1:**\(\sum_{i=1}^{n}S_{i}\leq\frac{b}{a}n\gamma\)

Let \(X^{\prime}=\mathrm{UAR}\). This will result in an decrease of social welfare of at most \(\frac{b}{a}n\gamma\) compared to \(Y^{\mu}\). To see why, note that the slack of constraint \(i\) is equivalent to how much player \(i\) prefers their fractional allocation in \(Y^{\mu}\) to \(\mathrm{UAR}\). Therefore, switching to \(\mathrm{UAR}\) from \(Y^{\mu}\) decreases the total social welfare by \(S_{i}\) per player, and therefore decreases the total social welfare by \(\sum_{i=1}^{n}S_{i}\leq\frac{b}{a}n\gamma=O(\gamma)\). Furthermore, \(X^{\prime}=\mathrm{UAR}\) clearly satisfies the other condition because every player is treated equally.

**Case 2:**\(\sum_{i=1}^{n}S_{i}>\frac{b}{a}n\gamma\)

Intuitively, in this case we want to redistribute the slack from the constraints with a lot of slack to the constraints without much slack. To do this, construct \(X^{\prime}\) as follows. Define

\[\Delta_{ik}:=\frac{Y^{\mu}_{ik}}{\sum_{k^{\prime}=1}^{m}Y^{\mu}_{ik^{\prime}}} \cdot\frac{S_{i}}{\sum_{i^{\prime}=1}^{n}S_{i^{\prime}}}\cdot\frac{n\gamma}{a}.\] (25)

By construction, we have that

\[\sum_{i=1}^{n}\sum_{k=1}^{m}\Delta_{ik}=\frac{n\gamma}{a}.\] (26)

Because \(\sum_{i=1}^{n}S_{i}\geq\frac{b}{a}n\gamma\), we also have that

\[\frac{S_{i}}{\sum_{i^{\prime}}S_{i^{\prime}}}\cdot\frac{n\gamma}{a}\leq\frac{ S_{i}}{b}.\] (27)

Furthermore, for every \(i\), \(S_{i}\leq Y^{\mu}_{i}\cdot\mu_{i}\) by definition of \(S_{i}\). Because \(\mu_{ik}\leq b\), this implies that \(\frac{S_{i}}{b}\leq\sum_{k=1}^{m}Y^{\mu}_{ik}\). With Equation (27), this implies that \(\frac{S_{i}}{\sum_{i^{\prime}}S_{i^{\prime}}}\cdot\frac{n\gamma}{a}\leq\sum_ {k=1}^{m}Y^{\mu}_{ik}\). With Equation (25), this implies that \(\Delta_{ik}\leq Y^{\mu}_{ik}\). Finally, we note that

\[\Delta_{i}\cdot\mu_{i} =\frac{Y^{\mu}_{i}\cdot\mu_{i}}{\sum_{k^{\prime}=1}^{m}Y^{\mu}_{ ik^{\prime}}}\cdot\frac{S_{i}}{\sum_{i^{\prime}=1}^{n}S_{i^{\prime}}}\cdot \frac{n\gamma}{a}\] [Equation (25)] \[\leq\left(\frac{\sum_{k=1}^{m}Y^{\mu}_{ik}\mu_{ik}}{b\sum_{k^{ \prime}=1}^{m}Y^{\mu}_{ik^{\prime}}}\right)S_{i}\] [Equation (27)] \[\leq\left(\frac{\sum_{k=1}^{m}Y^{\mu}_{ik}}{\sum_{k^{\prime}=1}^{ m}Y^{\mu}_{ik^{\prime}}}\right)S_{i}\] [\[\mu_{ik}\leq b\] ] \[=S_{i}.\] (28)

Now we are ready to construct \(X^{\prime}\). Let

\[X^{\prime}_{ik}:=Y^{\mu}_{ik}-\Delta_{ik}+\frac{1}{n}\sum_{i^{\prime}=1}^{n} \Delta_{i^{\prime}k}.\] (29)

In order for this to be a valid allocation, we need that \(X^{\prime}_{ik}\geq 0\), which is true because we showed above that \(\Delta_{ik}\leq Y^{\mu}_{ik}\). We also need that \(\sum_{i=1}^{n}X^{\prime}_{ik}=1\), which follows from

\[\sum_{i=1}^{n}X^{\prime}_{ik}=\sum_{i=1}^{n}\left(Y^{\mu}_{ik}-\Delta_{ik}+ \frac{1}{n}\sum_{i^{\prime}=1}^{n}\Delta_{i^{\prime}k}\right)=1-\sum_{i=1}^{n} \Delta_{ik}+\sum_{i^{\prime}=1}^{n}\Delta_{i^{\prime}k}=1.\]Next, we will show that Equation (23) is satisfied for all \(i\) for fractional allocation \(X^{\prime}\). Starting with the left hand side of Equation (23), we have

\[X^{\prime}_{i}\cdot\mu_{i}-\frac{1}{n}\|\mu_{i}\|_{1}\] \[=Y^{\mu}_{i}\cdot\mu_{i}-\Delta_{i}\cdot\mu_{i}+\sum_{k=1}^{m} \frac{1}{n}\sum_{i^{\prime}=1}^{n}\Delta_{i^{\prime}k}\mu_{ik}-\frac{1}{n}\|\mu _{i}\|_{1}\] [Eq (29)] \[=S_{i}-\Delta_{i}\cdot\mu_{i}+\frac{1}{n}\sum_{i^{\prime}=1}^{n} \Delta_{i^{\prime}}\cdot\mu_{i}\] [Eq (24)] \[\geq\frac{1}{n}\sum_{i^{\prime}=1}^{n}\Delta_{i^{\prime}}\cdot \mu_{i}\] [Eq (28)] \[\geq\frac{a}{n}\sum_{i^{\prime}=1}^{n}\sum_{k=1}^{m}\Delta_{i^{ \prime}k}\] [\(\mu_{ik}\geq a\)] \[=\gamma.\] [Eq (26)]

Furthermore, we can bound the decrease in social welfare between fractional allocation \(X^{\prime}\) and \(Y^{\mu}\) by

\[\langle Y^{\mu},\mu\rangle_{F}-\langle X^{\prime},\mu\rangle_{F} =\langle Y^{\mu}-X^{\prime},\mu\rangle_{F}\] \[\leq\sum_{i=1}^{n}\Delta_{i}\cdot\mu_{i}\] [Equation (29)] \[\leq b\sum_{i=1}^{n}\sum_{k=1}^{m}\Delta_{ik}\] [\(\mu_{ik}\leq b\)] \[\leq\frac{b}{a}n\gamma.\] [Equation (26)]

Therefore, we have shown that \(X^{\prime}\) has the desired properties, and thus the proportionality constraints satisfy Property 2. 

## Appendix F Proof of Lemma 1

For Section F only, we will assume w.l.o.g. that \(a=1\) and that \(b\geq 1\). This is without loss of generality because envy-freeness in expectation constraints and social welfare are both scale invariant. Therefore, scaling every player's values (and mean values) by \(1/a\) will give an equivalent problem where \(a=1\).

To prove Lemma 1, will show that we can transform \(Y^{\mu}\) into a fractional allocation \(X^{\prime}\) which satisfies Property 2 through Algorithm 3. Algorithm 3 iterates over the following types of 'envy-with-slack' graphs, which track whether a player prefers their allocation by at least \(\alpha\) over another player's allocation.

**Definition 6**.: Let \(\mathsf{create\mbox{-}slack\mbox{-}graph}(\mu,X,\alpha)\) be the subroutine which returns the directed graph with vertices \(N\) and edges generated as follows. Suppose \(G=\mathsf{create\mbox{-}slack\mbox{-}graph}(\mu,X,\alpha)\). Then a directed edge from \(i\) to \(i^{\prime}\) exists in \(G\) if and only if

\[\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle<\alpha.\]

At a high level, Algorithm 3 constructs 'envy-with-slack' graphs with progressively smaller \(\alpha\), with \(\alpha\geq\gamma\) for all iterations. The algorithm operates on sets of nodes called _equivalence classes_, where every pair of nodes in an equivalence class has the same allocation. We represent the set of equivalence classes in a fractional allocation \(X\) as \(\mathcal{S}(X)\).

**Definition 7**.: Let \(\mathcal{S}(X)\) be the set of equivalence classes of fractional allocation \(X\), where two nodes \(i,i^{\prime}\) are part of the same equivalence class \(S\in\mathcal{S}(X)\) if and only if \(X_{i}=X_{i^{\prime}}\).

Algorithm 3 generally makes progress by either 1) merging two equivalence classes, or 2) removing an edge from the graph. We formalize this model below.

Each iteration \(r\) begins with some allocation \(X^{r}\) and a slack value \(\alpha^{r}\). Algorithm 3 then generates from these parameters a directed graph \(G^{r}=\textsf{create-slack-graph}(\mu,X^{r},\alpha^{r})\), which is the 'envy-with-slack' graph for allocation \(X^{r}\) given means \(\mu\). As in standard graph notation, for a graph \(G\) we define \(V(G)\) as the vertices of \(G\) and \(E(G)\) as the edges of \(G\). Each edge \(e=(i,i^{\prime})\in E(G^{r})\) has a weight \(w_{e}=\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle\). For a set of vertices \(S\), we use \(\delta^{+}(S)\) to represent the edges with head in \(S\) and tail in \(N\backslash S\), and similarly, we use \(\delta^{-}(S)\) to represent the edges with tail in \(S\) and head in \(N\backslash S\). For notational convenience, we let \(\delta^{\cdot}(i)=\delta^{\cdot}(\{i\})\), and \(\delta^{+}(i)=\delta^{+}(\{i\})\). Throughout this section, we will use the notation \(\operatorname{sw}(X,\mu)=\langle X,\mu\rangle_{F}\).

An overview of the algorithm is as follows. In each iteration, Algorithm 3 generally performs one of three operations and removes an edge by decreasing \(\alpha\). First, if there exists an equivalence class \(S\) with at least one incoming edge but no outgoing edges, then operation remove-incoming-edge transfers allocation probability from nodes in \(S\) to all other nodes. If such an equivalence class does not exist, then Algorithm 3 finds a specific type of cycle in the 'envy-with-slack' graph. If there exists some node which has an edge to some but not all of the nodes in the cycle, then operation cycle-shift gives each node in the cycle half of its current allocation and half of the next node's allocation. If such a node does not exist and all edges in the graph have low enough weight, then operation average-clique instead creates a new equivalence class by merging all equivalence classes that the nodes in the cycle belong to. Such a merge may lead to envy, which is removed by a call to Algorithm 4. We define each of the three operations formally below, where each operation returns a new allocation \(X^{\prime}\).

**Definition 8**.: Let \(S\in\mathcal{S}(X)\). Define \(X_{Sk}=X_{ik}\) for every \(i\in S\). Let

\[\textsf{remove-incoming-edge}(S,\alpha,X)\]

 be the subroutine which returns \(X^{\prime}\), where

\[X^{\prime}_{ik}=X_{ik}-\frac{(n-|S|)\alpha X_{Sk}}{2bn\sum_{k^{ \prime}}X_{Sk^{\prime}}}\quad\;\forall\;i\in S\] and \[X^{\prime}_{ik}=X_{ik}+\frac{|S|\alpha X_{Sk}}{2bn\sum_{k^{ \prime}}X_{Sk^{\prime}}}\quad\;\;\;\forall\;i\in N\backslash S\]

**Definition 9**.: Let \(C\) be a cycle in a graph \(G=\textsf{create-slack-graph}(\mu,X,\alpha)\) and \(\textsf{next}(i)\) be the node which \(i\) points to in \(C\). Then the subroutine \(\textsf{cycle-shift}(C,X)\) returns \(X^{\prime}\), where

\[X^{\prime}_{ik} =\frac{X_{ik}+X_{\textsf{next}(i)k}}{2}\quad\;\forall\;i\in V(C)\] \[X^{\prime}_{ik} =X_{ik}\quad\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\forall\;i\in N \backslash V(C)\]

**Definition 10**.: Let \(Q\) be a clique in a graph \(G=\textsf{create-slack-graph}(\mu,X,\alpha)\). Then the subroutine \(\textsf{average-clique}(Q,X)\) returns \(X^{\prime}\), where

\[X^{\prime}_{ik} =\frac{\sum_{i^{\prime}\in Q}X_{i^{\prime}k}}{|Q|}\quad\;\;\forall \;i\in Q\] \[X^{\prime}_{ik} =X_{ik}\quad\;\;\;\;\;\;\;\;\;\;\;\;\forall\;i\in N\backslash Q\]

We also define two intermediary operations. Note that the \(\arg\min\) function may return the empty set, a singleton, or a set with multiple elements.

**Definition 11**.: Let \(G=\textsf{create-slack-graph}(\mu,X,\alpha)\) with edge set \(E\). For each equivalence class \(S\in\mathcal{S}(X)\), let \(E_{S}=\arg\min_{e\in\delta^{+}(S)}w_{e}\), where the size of \(E_{S}\) may be \(0,1\), or \(>1\). Let \(E^{\prime}=\sum_{S}E_{S}\), and let \(G^{\prime}=(N,E^{\prime})\). Then the subroutine \(\textsf{find-special-cycle}(G,\mathcal{S}(X))\) returns a cycle \(C\) of \(G^{\prime}\) where \(V(C)\) contains at most one member of each equivalence class \(S\in\mathcal{S}(X)\) (and returns \(\emptyset\) if no such cycle exists).

**Definition 12**.: Let \(G=\text{create-slack-graph}(\mu,X,\alpha)\) and let \(U\subset N\). Let \(\text{distribute-equally}(U,\beta,X)\) be the subroutine which returns \(X^{\prime}\), where

\[X^{\prime}_{ik} =(1-|N\backslash U|\cdot\beta)\cdot X_{ik}\quad\forall\;i\in U\] \[X^{\prime}_{ik} =X_{ik}+\beta\cdot\sum_{i^{\prime}\in U}X_{i^{\prime}k}\quad\quad \forall\;i\in N\backslash U\]

We are now ready to present Algorithm \(3\).

``` Require \(Y^{\mu},\mu\) Let \(\alpha^{0}\leftarrow\gamma\cdot(e^{n^{2}\log(4bn^{4})+n^{3}\log(2n)},X^{0} \gets Y^{\mu},G^{0}\leftarrow\text{create-slack-graph}(\mu,X^{0},\alpha^{0 }),r\gets 0\). while\(\exists(u,v)\in E(G^{r})\) s.t. \(u,v\) are in different equivalence classes do if\(\exists\;S\in\mathcal{S}(X^{r})\) s.t. \(\delta^{\cdot}(S)\neq\emptyset\) and \(\delta^{+}(S)=\emptyset\)then \(\triangleright\;X^{r+1}=\text{remove-incoming-edge}(S,\alpha^{r},X^{r})\) \(\triangleright\;\alpha^{r+1}=\frac{\alpha^{r}}{2b}\) else \(\triangleright\;C=\text{find-special-cycle}(G^{r},\mathcal{S}(X^{r}))\) if\(\exists\;u\in N\) and \(\exists i,i^{\prime}\in V(C)\) such that \((u,i)\in E\) and \((u,i^{\prime})\notin E\)then \(\triangleright\;X^{r+1}=\text{cycle-shift}(C,X^{r})\) \(\triangleright\;\alpha^{r+1}=\frac{\alpha^{r}}{2}\) else if\(\exists\;e\in E(G^{r})\) s.t. \(w_{e}\geq\frac{\alpha^{r}}{4bn^{4}}\)then \(\triangleright\;X^{r+1}=X^{r}\) \(\triangleright\;\alpha^{r+1}=\frac{\alpha^{r}}{4bn^{4}}\) else \(\triangleright\;\mathcal{S}^{\prime}=\{S\in\mathcal{S}(X^{r}):S\cap V(C)\neq\emptyset\}\) \(\triangleright\;Q=\bigcup_{S\in\mathcal{S}^{\prime}}S\) \(\triangleright\;X^{\mathsf{avg}}=\text{average-clique}(Q,X^{r})\) \(\triangleright\;\alpha^{\mathsf{avg}}=\frac{\alpha^{r}}{n}\) \(\triangleright\;G^{\mathsf{avg}}=\text{create-slack-graph}(\mu,X^{\mathsf{ avg}},\alpha^{\mathsf{avg}})\) // \(G^{\mathsf{avg}}\) defined for analysis only. \(\triangleright\;X^{\prime}=X^{\mathsf{avg}}\) \(\triangleright\;G^{\prime}=\text{create-slack-graph}(\mu,X^{\prime},0)\) while\(\exists e\in E(G^{\prime})\)do \(\triangleright\;X^{\prime}=\text{remove-envy}(\mu,X^{\prime})\) \(\triangleright\;G^{\prime}=\text{create-slack-graph}(\mu,X^{\prime},0)\) endwhile \(\triangleright\;X^{r+1}=X^{\prime}\) \(\triangleright\;\alpha^{r+1}=\frac{\alpha^{\mathsf{avg}}}{2}\) endif endif \(\triangleright\;G^{r+1}\leftarrow\text{create-slack-graph}(\mu,X^{r+1}, \alpha^{r+1})\) \(\triangleright\;r=r+1\) endwhile return\(X^{r}\) ```

**Algorithm 3** Achieving Envy with Slack

Algorithm 3 calls remove-envy, which is equivalent to calling Algorithm 4. Algorithm 4 will require the following definition.

**Definition 13**.: Let \(\text{create-non-negative-envy-graph}(\mu,X)\) be the subroutine which returns the directed graph with vertices \(N\) and edges generated as follows. Suppose \(G=\text{create-non-negative-envy-graph}(\mu,X)\). Then a directed edge from \(i\) to \(i^{\prime}\) exists in \(G\) if and only if

\[\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle\leq 0.\]

Note that this definition is exactly the same as that of \(\text{create-slack-graph}(\mu,X,0)\), except with a weak instead of a strict inequality. We now present Algorithm 4.

We begin by proving some helpful lemmas. It will be convenient to define the following term.

**Definition 14**.: Let \(X\) be an **envy-free** fractional allocation for \(\mu\) if for all \(i,i^{\prime}\in N\),

\[\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle\geq 0.\]

**Lemma 4**.: _Let \(X\) be an envy-free fractional allocation for \(\mu\), and let \(G=\mathsf{create\_slack\_graph}(\mu,X,\alpha)\) with edge set \(E\). Suppose that there exists some equivalence class \(S\in\mathcal{S}(X)\) such that \(\delta^{\cdot}(S)\neq\emptyset\) and \(\delta^{+}(S)=\emptyset\) in \(G\), and let \(X^{\prime}=\mathsf{remove\_incoming\_edge}(S,\alpha,X)\). Let \(G^{\prime}=\mathsf{create\_slack\_graph}(\mu,X^{\prime},\alpha/2b)\) with edge set \(E^{\prime}\). Then \(|E^{\prime}|<|E|\)._

Proof.: We first show that if an edge \(e\notin E\), then \(e\notin E^{\prime}\). Note that for any \(i,i^{\prime}\) such that \((i,i^{\prime})\notin E\),

\[\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle\geq \alpha>\frac{\alpha}{2b}.\]

Therefore, to show that an edge \((i,i^{\prime})\) not in \(E\) is also not in \(E^{\prime}\), it suffices to show that \(\langle X^{\prime}_{i},\mu_{i}\rangle-\langle X^{\prime}_{i^{\prime}},\mu_{i}\rangle \geq\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle\).

The subroutine \(\mathsf{remove\_incoming\_edge}(S,\alpha,X)\) only transfers weight from \(S\) to \(N\backslash S\), which implies that no node in \(N\backslash S\) will gain an edge to a node in \(S\). Formally,

\[\langle X^{\prime}_{i^{\prime}},\mu_{i^{\prime}}\rangle-\langle X^{\prime}_{i ^{\prime}},\mu_{i^{\prime}}\rangle>\langle X_{i^{\prime}},\mu_{i^{\prime}} \rangle-\langle X_{i},\mu_{i^{\prime}}\rangle\quad\forall\,i\in S,i^{\prime} \in N\backslash S.\] (30)

Every pair of nodes \(i,i^{\prime}\in S\) has their fractional allocation reduced by the same amount, so

\[\langle X^{\prime}_{i},\mu_{i}\rangle-\langle X^{\prime}_{i^{\prime}},\mu_{i} \rangle=\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle \quad\forall\,i,i^{\prime}\in S.\] (31)

Similarly, every pair of nodes \(i,i^{\prime}\in N\backslash S\) has their fractional allocation increased by the same amount, so

\[\langle X^{\prime}_{i},\mu_{i}\rangle-\langle X^{\prime}_{i^{\prime}},\mu_{i }\rangle=\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle \quad\forall\,i,i^{\prime}\in N\backslash S.\] (32)

Finally, we observe that for any \(i\in S\) and \(i^{\prime}\in N\backslash S\),

\[\langle X^{\prime}_{i},\mu_{i}\rangle-\langle X^{\prime}_{i^{\prime}},\mu_{i }\rangle=\left(\langle X_{i},\mu_{i}\rangle-\sum_{k\in[m]}\frac{(n-|S|)\alpha X_{Sk}\mu_{ik}}{2bn\sum_{k^{\prime}}X_{Sk^{\prime}}} \right)-\left(\langle X_{i^{\prime}},\mu_{i}\rangle+\sum_{k\in[m]}\frac{|S| \alpha X_{Sk}\mu_{ik}}{2bn\sum_{k^{\prime}}X_{Sk^{\prime}}}\right)\]\[=\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle- \sum_{k\in[m]}\frac{n\alpha X_{Sk}\mu_{ik}}{2bn\sum_{k^{\prime}}X_{Sk^{\prime}}}\] \[\geq\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i} \rangle-\sum_{k\in[m]}\frac{n\alpha X_{Sk}}{2n\sum_{k^{\prime}}X_{Sk^{\prime}}}\] \[=\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i} \rangle-\frac{\alpha}{2}\] \[\geq\alpha-\frac{\alpha}{2}\] \[\geq\frac{\alpha}{2b}.\]

where the second inequality is because \((i,i^{\prime})\not\in E\). Therefore, by definition of \(G^{\prime},(i,i^{\prime})\notin E^{\prime}\).

Recall that \(\delta^{\cdot}(S)\neq\emptyset\) in \(G\). We will now show that \(\delta^{\cdot}(S)=\emptyset\) in \(G^{\prime}\). Observe that for \(i\in S\) and \(i^{\prime}\in N\backslash S\),

\[\langle X_{i^{\prime}}^{\prime},\mu_{i^{\prime}}\rangle- \langle X_{i}^{\prime},\mu_{i^{\prime}}\rangle =\left(\langle X_{i^{\prime}},\mu_{i^{\prime}}\rangle+\sum_{k\in[ m]}\frac{|S|\alpha X_{Sk}\mu_{i^{\prime}k}}{2bn\sum_{k^{\prime}}X_{Sk^{\prime}}} \right)-\left(\langle X_{i},\mu_{i^{\prime}}\rangle-\sum_{k\in[m]}\frac{(n-|S| )\alpha X_{Sk}\mu_{i^{\prime}k}}{2bn\sum_{k^{\prime}}X_{Sk^{\prime}}}\right)\] \[=\langle X_{i^{\prime}},\mu_{i^{\prime}}\rangle-\langle X_{i},\mu _{i^{\prime}}\rangle+\sum_{k\in[m]}\frac{n\alpha X_{Sk}\mu_{i^{\prime}k}}{2 bn\sum_{k^{\prime}}X_{Sk^{\prime}}}\] \[\geq\langle X_{i^{\prime}},\mu_{i^{\prime}}\rangle-\langle X_{i},\mu_{i^{\prime}}\rangle+\frac{\alpha}{2b}\] \[\geq\frac{\alpha}{2b}.\]

Therefore, \((i^{\prime},i)\notin E\), which implies \(\delta^{\cdot}(S)=\emptyset\) in \(G^{\prime}\). We conclude that all edges in \(E^{\prime}\) exist in \(E\), and at least one edge in \(E\) does not exist in \(E^{\prime}\), which implies that \(|E^{\prime}|<|E|\). 

**Lemma 5**.: _Let \(X\) be an envy-free fractional allocation for \(\mu\), and let \(G=\mathsf{create\text{-}slack\text{-}graph}(\mu,X,\alpha)\) with edge set \(E\). Suppose that there exists some equivalence class \(S\in\mathcal{S}(X)\) such that \(\delta^{\cdot}(S)\neq\emptyset\) and \(\delta^{+}(S)=\emptyset\) in \(G\), and let \(X^{\prime}=\mathsf{remove\text{-}incoming\text{-}edge}(S,\alpha,X)\). Then \(X^{\prime}\) is an envy-free allocation for \(\mu\)._

Proof.: Let \(G^{\prime}=\mathsf{create\text{-}slack\text{-}graph}(\mu,X^{\prime},\alpha/2b)\) with edge set \(E^{\prime}\). It suffices to show that \(w_{e}\geq 0\lor e\in E^{\prime}\). By Lemma 4, if an edge \((i,i^{\prime})\notin E\), then

\[\langle X_{i}^{\prime},\mu_{i}\rangle-\langle X_{i^{\prime}}^{\prime},\mu_{i} \rangle\geq\tfrac{\alpha}{2b}\geq 0.\]

Consider any \(i\in S\) and \(i^{\prime}\in N\backslash S\). Then there must not exist an edge \((i,i^{\prime})\in E\) by assumption. Also by assumption, for any \(i,i^{\prime}\) such that \((i,i^{\prime})\in E\), we have that \(\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle\geq 0\). By a direct application of Equations (30), (31), and (32), we can conclude that \(\langle X_{i}^{\prime},\mu_{i}\rangle-\langle X_{i^{\prime}}^{\prime},\mu_{i} \rangle\geq 0\) as well. 

**Lemma 6**.: _Let \(G=\mathsf{create\text{-}slack\text{-}graph}(\mu,X,\alpha)\) with edge set \(E\). Suppose that there exists some equivalence class \(S\in\mathcal{S}(X)\) such that \(\delta^{\cdot}(S)\neq\emptyset\) and \(\delta^{+}(S)=\emptyset\) in \(G\), and let \(X^{\prime}=\mathsf{remove\text{-}incoming\text{-}edge}(S,\alpha,X)\). Then_

\[\operatorname{sw}(X,\mu)-\operatorname{sw}(X^{\prime},\mu)\leq\frac{\alpha n}{2}.\]

Proof.: Observe that

\[\operatorname{sw}(X^{\prime},\mu) =\sum_{i\in S}\langle X_{i}^{\prime},\mu_{i}\rangle+\sum_{i\in N \backslash S}\langle X_{i}^{\prime},\mu_{i}\rangle\] \[\geq\sum_{i\in S}\left(1-\frac{(n-|S|)\alpha}{2bn\sum_{k^{\prime} }X_{Sk^{\prime}}}\right)\cdot\langle X_{i},\mu_{i}\rangle+\sum_{i\in N \backslash S}\langle X_{i},\mu_{i}\rangle\]\[\begin{split}\langle X_{i}^{\prime},\mu_{i}\rangle-\langle X_{i}^{ \prime},\mu_{i}\rangle&=\langle X_{i},\mu_{i}\rangle-\frac{1}{2} \langle X_{i},\mu_{i}\rangle-\frac{1}{2}\langle X_{\mathsf{next}(i)},\mu_{i ^{\prime}}\rangle\\ &=\frac{1}{2}(\langle X_{i^{\prime}},\mu_{i^{\prime}}\rangle- \langle X_{i},\mu_{i^{\prime}}\rangle)+\frac{1}{2}(\langle X_{i^{\prime}}, \mu_{i^{\prime}}\rangle-\langle X_{\mathsf{next}(i)},\mu_{i^{\prime}}\rangle) \\ &\geq\frac{1}{2}(\alpha)+\frac{1}{2}(0)\\ &=\frac{\alpha}{2}.\end{split}\] (35)

We have shown that if \(e\in E^{\prime}\), then \(e\in E\). Now we will show that there exists at least one edge \(e\) such that \(e\in E\), but \(e\notin E^{\prime}\). Consider the node \(u\) described in the lemma statement, and let \(i\in V(C)\) be some node such that \((u,i)\in E\) but \((u,\mathsf{next}(i))\notin E\). Suppose that \(u\notin V(C)\). Then

\[\begin{split}\langle X_{u}^{\prime},\mu_{u}\rangle-\langle X_{i} ^{\prime},\mu_{u}\rangle&=\langle X_{u},\mu_{u}\rangle-\frac{1}{2} \langle X_{i},\mu_{u}\rangle-\frac{1}{2}\langle X_{\mathsf{next}(i)},\mu_{u}\rangle \\ &=\frac{1}{2}(\langle X_{u},\mu_{u}\rangle-\langle X_{i},\mu_{u} \rangle)+\frac{1}{2}(\langle X_{u},\mu_{u}\rangle-\langle X_{\mathsf{next}(i )},\mu_{u}\rangle)\end{split}\]\[\geq\frac{1}{2}(\alpha)+\frac{1}{2}(0)\] \[=\frac{\alpha}{2}.\]

Suppose that \(u\in V(C)\). Then

\[\langle X_{u}^{\prime},\mu_{u}\rangle-\langle X_{i}^{\prime},\mu_{ u}\rangle =\frac{1}{2}\langle X_{u},\mu_{u}\rangle+\frac{1}{2}\langle X_{ \mathsf{net}(u)},\mu_{u}\rangle-\frac{1}{2}\langle X_{i},\mu_{u}\rangle- \frac{1}{2}\langle X_{\mathsf{next}(i)},\mu_{u}\rangle\] \[=\frac{1}{2}(\langle X_{u},\mu_{u}\rangle-\langle X_{i},\mu_{u} \rangle)+\frac{1}{2}(\langle X_{\mathsf{next}(u)},\mu_{u}\rangle-\langle X_{ \mathsf{next}(i)},\mu_{u}\rangle)\] \[\geq\frac{1}{2}(\alpha)+\frac{1}{2}(0)\] \[=\frac{\alpha}{2}.\]

This implies that \((u,i)\notin E^{\prime}\), as desired. 

**Lemma 8**.: _Let \(X\) be an empy-free fractional allocation for \(\mu\) and let \(G=\mathsf{create\text{-}slack\text{-}graph}(\mu,X,\alpha)\) with edge set \(E\). Let \(C=\mathsf{find\text{-}special\text{-}cycle}(G,\mathcal{S}(X))\) and let \(X^{\prime}=\mathsf{cycle\text{-}shift}(C,X)\). Then \(X^{\prime}\) is an empy-free allocation for \(\mu\)._

Proof.: Let \(G^{\prime}=\mathsf{create\text{-}slack\text{-}graph}(\mu,X^{\prime},\alpha/2)\) with edge set \(E^{\prime}\). It suffices to show that \(w_{e}\geq 0\) for all \(e\in E^{\prime}\). By Lemma 7, if an edge \((i,i^{\prime})\notin E\), then

\[\langle X_{i}^{\prime},\mu_{i}\rangle-\langle X_{i^{\prime}}^{\prime},\mu_{ i}\rangle\geq\tfrac{\alpha}{2}\geq 0.\]

Recall that by assumption, for any \(i,i^{\prime}\) such that \((i,i^{\prime})\in E\), \(\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle\geq 0\). Suppose that \(i\in V(C),i^{\prime}\in N\), and \((i,i^{\prime})\in E\). Then by Equation (33),

\[\langle X_{i}^{\prime},\mu_{i}\rangle-\langle X_{i^{\prime}}^{\prime},\mu_{ i}\rangle\geq\frac{1}{2}(\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}}, \mu_{i}\rangle)\geq 0.\]

Suppose instead that \(i,i^{\prime}\notin V(C)\) and edge \((i,i^{\prime})\in E\). Then by Equation (34),

\[\langle X_{i}^{\prime},\mu_{i}\rangle-\langle X_{i^{\prime}}^{\prime},\mu_{ i}\rangle=\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle\geq 0.\]

Finally, suppose that \(i\in V(C),i^{\prime}\in N\backslash V(C)\), and edge \((i^{\prime},i)\in E\). Then by Equation (35),

\[\langle X_{i^{\prime}}^{\prime},\mu_{i^{\prime}}\rangle-\langle X _{i}^{\prime},\mu_{i^{\prime}}\rangle =\frac{1}{2}(\langle X_{i^{\prime}},\mu_{i^{\prime}}\rangle- \langle X_{i},\mu_{i^{\prime}}\rangle)+\frac{1}{2}(\langle X_{i^{\prime}},\mu_ {i^{\prime}}\rangle-\langle X_{\mathsf{next}(i)},\mu_{i^{\prime}}\rangle)\] \[\geq\frac{1}{2}(0)+\frac{1}{2}(0)\] \[=0.\]

**Lemma 9**.: _Let \(X\) be an empy-free fractional allocation for \(\mu\) and let \(G=\mathsf{create\text{-}slack\text{-}graph}(\mu,X,\alpha)\) with edge set \(E\). Let \(C=\mathsf{find\text{-}special\text{-}cycle}(G,\mathcal{S}(X))\) and let \(X^{\prime}=\mathsf{cycle\text{-}shift}(C,X)\). Then_

\[\operatorname{sw}(X,\mu)-\operatorname{sw}(X^{\prime},\mu)\leq\frac{n\alpha}{2}.\]

Proof.: Observe that

\[\operatorname{sw}(X^{\prime},\mu) =\sum_{i\in V(C)}\langle X_{i}^{\prime},\mu_{i}\rangle+\sum_{i \in N\backslash V(C)}\langle X_{i}^{\prime},\mu_{i}\rangle\] \[=\frac{1}{2}\cdot\sum_{i\in V(C)}(\langle X_{i},\mu_{i}\rangle+ \langle X_{\mathsf{net}(i)},\mu_{i}\rangle)+\sum_{i\in N\backslash V(C)} \langle X_{i},\mu_{i}\rangle\] \[\geq\frac{1}{2}\cdot\sum_{i\in V(C)}(\langle X_{i},\mu_{i}\rangle+ \langle X_{i},\mu_{i}\rangle-\alpha)+\sum_{i\in N\backslash V(C)}\langle X_{i}, \mu_{i}\rangle\]\[=\sum_{i\in V(C)}\left(\langle X_{i},\mu_{i}\rangle-\frac{\alpha}{2} \right)+\sum_{i\in N\setminus V(C)}\langle X_{i},\mu_{i}\rangle\] \[\geq\sum_{i\in V(C)}\left(\langle X_{i},\mu_{i}\rangle-\frac{ \alpha}{2}\right)+\sum_{i\in N\setminus V(C)}\left(\langle X_{i},\mu_{i} \rangle-\frac{\alpha}{2}\right)\] \[=\sum_{i\in N}\langle X_{i},\mu_{i}\rangle-\frac{n\alpha}{2}\]

This implies that

\[\operatorname{sw}(X,\mu)-\operatorname{sw}(X^{\prime},\mu)\leq\frac{n\alpha }{2}.\]

**Lemma 10**.: _Let \(X\) be an envy-free fractional allocation for \(\mu\). Let \(G=\mathsf{create\text{-}slack\text{-}graph}(\mu,X,\alpha)\) with edge set \(E\), and let \(Q\) be a clique in \(G\). Let \(X^{\prime}=\mathsf{average\text{-}clique}(Q,X)\) and \(G^{\prime}=\mathsf{create\text{-}slack\text{-}graph}(\mu,X^{\prime},\alpha/n)\), with \(E^{\prime}\) the edge set of \(G^{\prime}\). Then \(|E^{\prime}|\leq|E|\)._

Proof.: It suffices to show that if an edge \(e\notin E\), then \(e\notin|E^{\prime}|\). If \(i,i^{\prime}\in Q\), then edge \((i,i^{\prime})\) must be in \(E\), as \(Q\) is a clique. Suppose that \(i,i^{\prime}\in N\backslash Q\) and \((i,i^{\prime})\notin E\). Then

\[\langle X^{\prime}_{i},\mu_{i}\rangle-\langle X^{\prime}_{i^{\prime}},\mu_{i} \rangle=\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime}},\mu_{i}\rangle\geq\alpha.\]

Now, suppose that \(i\in Q,i^{\prime}\in N\backslash Q\), and \((i,i^{\prime})\notin E\). Then

\[\langle X^{\prime}_{i},\mu_{i}\rangle-\langle X^{\prime}_{i^{ \prime}},\mu_{i}\rangle =\frac{1}{|Q|}\left(\sum_{i^{\prime\prime}\in Q}\langle X_{i^{ \prime\prime}},\mu_{i}\rangle\right)-\langle X_{i^{\prime}},\mu_{i}\rangle\] \[\geq\langle X_{i},\mu_{i}\rangle-\alpha\left(\frac{|Q|-1}{|Q|} \right)-\langle X_{i^{\prime}},\mu_{i}\rangle\] \[\geq\alpha-\alpha\left(\frac{|Q|-1}{|Q|}\right)\] \[\geq\frac{\alpha}{n}.\]

Finally, suppose that \(i\in Q,i^{\prime}\in N\backslash Q\), and \((i^{\prime},i)\notin E\). Then

\[\langle X^{\prime}_{i^{\prime}},\mu_{i^{\prime}}\rangle-\langle X ^{\prime}_{i},\mu_{i^{\prime}}\rangle =\langle X_{i^{\prime}},\mu_{i^{\prime}}\rangle-\frac{1}{|Q|} \left(\sum_{i^{\prime\prime}\in Q}\langle X_{i^{\prime\prime}},\mu_{i^{\prime} }\rangle\right)\] \[=\frac{1}{|Q|}\left(\sum_{i^{\prime\prime}\in Q}\langle X_{i^{ \prime}},\mu_{i^{\prime}}\rangle-\langle X_{i^{\prime\prime}},\mu_{i^{\prime} }\rangle\right)\] \[=\frac{1}{|Q|}\left(\langle X_{i^{\prime}},\mu_{i^{\prime}}\rangle- \langle X_{i},\mu_{i^{\prime}}\rangle+\sum_{\{i^{\prime\prime}\in Q:i^{\prime \prime}\neq i\}}\langle X_{i^{\prime}},\mu_{i^{\prime}}\rangle-\langle X_{i^{ \prime\prime}},\mu_{i^{\prime}}\rangle\right)\] \[\geq\frac{1}{n}(\alpha+0)\] \[\geq\frac{\alpha}{n}.\]

**Lemma 11**.: _Let \(X\) be an envy-free fractional allocation for \(\mu\). Let \(G=\mathsf{create\text{-}slack\text{-}graph}(\mu,X,\alpha)\) with edge set \(E\), and let \(Q\) be a clique in \(G\). Let \(X^{\prime}=\mathsf{average\text{-}clique}(Q,X)\). Then_

\[\langle X^{\prime}_{i},\mu_{i}\rangle-\langle X^{\prime}_{i^{\prime}},\mu_{i} \rangle\geq-\alpha\quad\forall i,i^{\prime}\in N.\]Proof.: First, suppose \(i^{\prime}\in N\backslash Q\) and \(i\in N\). Then

\[\langle X^{\prime}_{i^{\prime}},\mu_{i^{\prime}}\rangle-\langle X^{\prime}_{i}, \mu_{i^{\prime}}\rangle\geq\min_{i^{\prime\prime}\in N}\langle X_{i^{\prime}}, \mu_{i^{\prime}}\rangle-\langle X_{i^{\prime\prime}},\mu_{i^{\prime}}\rangle \geq 0.\]

Suppose instead that \(i,i^{\prime}\in Q\). Then

\[\langle X^{\prime}_{i^{\prime}},\mu_{i^{\prime}}\rangle-\langle X^{\prime}_{i},\mu_{i^{\prime}}\rangle=0.\]

Finally, suppose that \(i\in Q,i^{\prime}\in N\backslash Q\). Then

\[\langle X^{\prime}_{i},\mu_{i}\rangle-\langle X^{\prime}_{i^{ \prime}},\mu_{i}\rangle =\frac{1}{|Q|}\left(\sum_{i^{\prime\prime}\in Q}\langle X_{i^{ \prime\prime}},\mu_{i}\rangle\right)-\langle X_{i^{\prime}},\mu_{i}\rangle\] \[\geq\langle X_{i},\mu_{i}\rangle-\alpha\left(\frac{|Q|-1}{|Q|} \right)-\langle X_{i^{\prime}},\mu_{i}\rangle\] \[\geq 0-\alpha\left(\frac{|Q|-1}{|Q|}\right)\] \[\geq-\alpha.\]

**Lemma 12**.: _Let \(G=\mathsf{create\text{-}slack\text{-}graph}(\mu,X,\alpha)\) with edge set \(E\), and let \(Q\) be a clique in \(G\). Let \(X^{\prime}=\mathsf{average\text{-}clique}(Q,X)\). Then_

\[\operatorname{sw}(X,\mu)-\operatorname{sw}(X^{\prime},\mu)\leq n\cdot\alpha.\]

Proof.: Observe that

\[\operatorname{sw}(X^{\prime},\mu) =\sum_{i\in Q}\langle X^{\prime}_{i},\mu_{i}\rangle+\sum_{i\in N \backslash Q}\langle X^{\prime}_{i},\mu_{i}\rangle\] \[\geq\sum_{i\in Q}(\langle X_{i},\mu_{i}\rangle-\alpha)+\sum_{i \in N\backslash Q}\langle X_{i},\mu_{i}\rangle\] \[\geq\sum_{i\in N}(\langle X_{i},\mu_{i}\rangle-\alpha)\] \[\geq\operatorname{sw}(X,\mu)-n\cdot\alpha.\]

Rearranging, this implies that

\[\operatorname{sw}(X,\mu)-\operatorname{sw}(X^{\prime},\mu)\leq n\cdot\alpha.\]

**Lemma 13**.: _Let \(G=\mathsf{create\text{-}slack\text{-}graph}(\mu,X,0)\) with edge set \(E\), and let \(X^{\prime}=\mathsf{remove\text{-}envy}(\mu,X)\). Further let \(G^{\prime}=\mathsf{create\text{-}slack\text{-}graph}(\mu,X^{\prime},0)\) with edge set \(E^{\prime}\). Then \(|E^{\prime}|<|E|\)._

Proof.: First, we show that if an edge \(e\notin E\), then \(e\notin E^{\prime}\). In other words, we will show that no new edges with positive envy (negative weight) are added. Observe that within the while loop, \(\mathsf{remove\text{-}envy}\) distributes \(\beta_{i^{*}}\) from a set \(U\) to \(N\backslash U\). If at the beginning of the while loop \(\exists i\in U\) such that \(w_{i,i^{\prime}}<0\) for some \(i^{\prime}\in N\backslash U\), then \(\beta_{i^{*}}=0\) and \(i^{\prime}\) is added to \(U\). Otherwise, by definition \(\beta_{i^{*}}\) is at most the minimum fraction that the set \(U\) needs to give away in order to create a new \(0\) envy edge between any node in \(U\) and a node \(i^{\prime}\in N\backslash U\). Therefore, \(\mathsf{distribute\text{-}equally}\) cannot create a new edge with positive envy by our choice of \(\beta_{i^{*}}\), which implies that no new edge with positive envy could have been created by the end of the while loop. Now, suppose that \(w_{(u,v)}<0\) at the end of the while loop. Then there is a cycle \(C\) in \(G^{r}\) containing \((u,v)\). Then for every \(i\), \(\langle X^{\prime}_{i},\mu_{i}\rangle\geq\langle X^{r}_{i},\mu_{i}\rangle\). The total set of allocations has not changed, so no positive envy is introduced.

Now, we show that there exists an edge \(e\in E\) such that \(e\notin E^{\prime}\). That is, we show that we have removed some edge with positive envy. If \(w_{(u,v)}=0\) at the end of the while loop, then \((u,v)\in E\)and \((u,v)\not\in E^{\prime}\) so we are done. Otherwise, there is a cycle in \(G^{r}\) containing \((u,v)\). As the overall set of allocations has not changed and \(\langle X_{v},\mu_{u}\rangle-\langle X_{u},\mu_{u}\rangle>0\), we must have

\[\big{|}i\in V(C)\text{ s.t. }\langle X_{i}^{\prime},\mu_{u}\rangle-\langle X_{u}^{ \prime},\mu_{u}\rangle<0\big{|}<\big{|}i\in V(C)\text{ s.t. }\langle X_{i},\mu_{u}\rangle-\langle X_{u},\mu_{u}\rangle<0\big{|}.\]

Therefore, there exists some edge \(e=(u,i)\) for \(i\in V(C)\) such that \(e\in E\) but \(e\notin E^{\prime}\). 

**Lemma 14**.: _Let \(G=\mathsf{create\_slack\_graph}(\mu,X,0)\) with edge set \(E\). Suppose that_

\[-\tfrac{\alpha}{4bn^{3}}\leq\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime }},\mu_{i}\rangle\quad\forall i,i^{\prime}\in N.\]

_Let \(X^{0}=X\) and define \(X^{\ell}=\mathsf{remove\_envy}(\mu,X^{\ell-1})\). Then for all \(i,i^{\prime},\ell\),_

\[-\tfrac{\alpha}{4bn^{2}}\leq\langle X_{i}^{\ell},\mu_{i^{\prime}}\rangle- \langle X_{i}^{\ell-1},\mu_{i^{\prime}}\rangle\leq\tfrac{\alpha}{4n^{3}}.\]

Proof.: We first prove by induction on \(\ell\) that for all \(\ell\),

\[-\tfrac{\alpha}{4bn^{3}}\leq\langle X_{i}^{\ell},\mu_{i}\rangle-\langle X_{i^ {\prime}}^{\ell},\mu_{i}\rangle\quad\forall i,i^{\prime}\in N.\]

The base case is true by assumption. Now consider any \(\ell\). By the inductive hypothesis, we have that for all \(i,i^{\prime}\in N\), \(-\tfrac{\alpha}{4bn^{3}}\leq\langle X_{i}^{\ell-1},\mu_{i}\rangle-\langle X_{ i^{\prime}}^{\ell-1},\mu_{i}\rangle\). Suppose for contradiction that there exists some \(i,i^{\prime}\in N\) such that \(-\tfrac{\alpha}{4bn^{3}}>\langle X_{i}^{\ell},\mu_{i}\rangle-\langle X_{i^{ \prime}}^{\ell},\mu_{i}\rangle\). This means that the envy of \(i\) for \(i^{\prime}\) must have increased to more than during \(\tfrac{\alpha}{4bn^{3}}\) in the \(\ell^{th}\) call to \(\mathsf{remove\_envy}\). The only way for the envy of \(i\) for \(i^{\prime}\) to increase in \(\mathsf{remove\_envy}\) is if \(i\in U\), \(i^{\prime}\in N\backslash U\), and \(\beta_{i^{*}}>0\). If \(\langle X_{i}^{\ell-1},\mu_{i}\rangle-\langle X_{i^{\prime}}^{\ell-1},\mu_{i} \rangle\leq 0\), then \(\beta_{i^{*}}=0\). Therefore, we must have \(\langle X_{i}^{\ell-1},\mu_{i}\rangle-\langle X_{i^{\prime}}^{\ell-1},\mu_{i} \rangle>0\). However, by our choice of \(\beta_{i^{*}}\), \(i^{\prime}\) must then be added to \(U\) before \(i\) becomes envious of \(i^{\prime}\). Therefore, it is not possible for the envy of \(i\) for \(i^{\prime}\) to have increased to more than \(\tfrac{\alpha}{4bn^{3}}\) in the \(\ell^{th}\) call to \(\mathsf{remove\_envy}\).

We now prove the main lemma. Consider any \(\ell\). One stopping condition of the while loop in \(\mathsf{remove\_envy}\) is when \(w_{(u,v)}=\langle X_{u}^{r},\mu_{u}\rangle-\langle X_{v}^{r},\mu_{u}\rangle=0\). Observe that \(v\in U\) and \(u\in N\backslash U\) for all iterations \(r\) in the while loop. This implies that \(u\)'s allocation is always increasing, while \(v\)'s allocation is always decreasing. The increase in \(u\)'s utility is therefore at most \(u\)'s current envy towards \(v\)'s allocation in \(X_{i}^{\ell-1}\), which is upper bounded by \(\tfrac{\alpha}{4bn^{3}}\) by the induction proof above. Formally,

\[\langle X_{u}^{\ell},\mu_{u}\rangle-\langle X_{u}^{\ell-1},\mu_{u}\rangle\leq \langle X_{v}^{\ell-1},\mu_{u}\rangle-\langle X_{u}^{\ell-1},\mu_{u}\rangle\leq \frac{\alpha}{4bn^{3}}.\] (36)

Furthermore, over the course of \(\mathsf{remove\_envy}\), the allocation of node \(u\) is increased at least as much as that of any other node \(i\), i.e.

\[(X_{uk}^{\ell}-X_{uk}^{\ell-1})\geq(X_{ik}^{\ell}-X_{ik}^{\ell-1})\quad\forall i \in N,k\in[m].\]

This is because \(u\) is always a member of \(N\backslash U\). Therefore, for any \(i,i^{\prime}\in N\),

\[\langle X_{i}^{\ell},\mu_{i^{\prime}}\rangle-\langle X_{i}^{\ell-1},\mu_{i^{ \prime}}\rangle\leq b\cdot\frac{\alpha}{4bn^{3}}=\frac{\alpha}{4bn^{3}},\]

as \(b\) is the largest possible utility ratio between two nodes.

Again by applying Equation (36) and because \(b\) is the largest possible utility ratio between two nodes, for any \(i,i^{\prime}\in[N]\), the utility of \(i^{\prime}\) for the allocation transferred from \(i\) to \(u\) is at most \(b\cdot\tfrac{\alpha}{4bn^{3}}=\tfrac{\alpha}{4n^{3}}\). Node \(i\) could have transferred to at most \(n\) nodes during \(\mathsf{remove\_envy}\), which implies that node \(i^{\prime}\) has utility of at most \(n\cdot\tfrac{\alpha}{4bn^{3}}=\tfrac{\alpha}{4n^{2}}\) for all of the allocation transferred away from node \(i\) during \(\mathsf{remove\_envy}\). Therefore,

\[\langle X_{i}^{\ell},\mu_{i^{\prime}}\rangle-\langle X_{i}^{\ell-1},\mu_{i^{ \prime}}\rangle\geq-\frac{\alpha}{4n^{2}}\quad\forall\,i\in N.\]

**Lemma 15**.: _Let \(G=\mathsf{create\_slack\_graph}(\mu,X,0)\) with edge set \(E\). Suppose that_

\[-\tfrac{\alpha}{4bn^{3}}\leq\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime }},\mu_{i}\rangle\quad\forall i,i^{\prime}\in N.\]

_Let \(X^{0}=X\) and define \(X^{\ell}=\mathsf{remove\_envy}(\mu,X^{\ell-1})\). Then for all \(i,i^{\prime}\) and for all \(\ell\leq n^{2}\),_

\[\operatorname{sw}(X^{0},\mu)-\operatorname{sw}(X^{\ell},\mu)\leq\tfrac{n \alpha}{4}.\]Proof.: Consider some \(\ell\). By Lemma 14 we know that

\[\langle X_{i}^{\ell},\mu_{i}\rangle-\langle X_{i}^{\ell-1},\mu_{i}\rangle\geq- \frac{\alpha}{4n^{2}}\quad\forall\,i\in N.\]

Applying the above once for each node, we obtain

\[\operatorname{sw}(X^{\ell},\mu) =\sum_{i\in N}\langle X_{i}^{\ell},\mu_{i}\rangle\] \[\geq\sum_{i\in N}\left(\langle X_{i}^{\ell},\mu_{i}\rangle-\frac {\alpha}{4n^{2}}\right)\] \[\geq\operatorname{sw}(X^{\ell-1},\mu)-n\cdot\frac{\alpha}{4n^{2 }}.\]

Rearranging, this implies that

\[\operatorname{sw}(X^{\ell-1},\mu)-\operatorname{sw}(X^{\ell},\mu)\leq\frac{ \alpha}{4n}.\]

Because \(\ell\leq n^{2}\), we therefore must have

\[\operatorname{sw}(X^{0},\mu)-\operatorname{sw}(X^{\ell},\mu)\leq\frac{n \alpha}{4}.\]

**Lemma 16**.: _Let \(G=\mathsf{create\text{-}slack\text{-}graph}(\mu,X,\alpha)\) with edge set \(E\). Suppose that for \(S\in\mathcal{S}(X)\), if \(\delta^{\cdot}(S)\notin\emptyset\), then \(\delta^{+}(S)\notin\emptyset\). Further suppose that_

\[-\tfrac{\alpha}{4bn^{3}}\leq\langle X_{i},\mu_{i}\rangle-\langle X_{i^{\prime }},\mu_{i}\rangle\quad\forall i,i^{\prime}\in N\]

_Let \(X^{0}=X\) and define \(X^{\ell}=\mathsf{remove\text{-}envy}(\mu,X^{\ell-1})\). Finally, for \(\ell\leq n^{2}\) let \(G^{\prime}=\mathsf{create\text{-}slack\text{-}graph}(\mu,X^{\ell},\tfrac{ \alpha}{2})\) with edge set \(E^{\prime}\). Then \(|E^{\prime}|\leq|E|\)._

Proof.: It suffices to show that if an edge \((i,i^{\prime})\notin E\), then \((i,i^{\prime})\notin E^{\prime}\). By Lemma 14, in each call to remove-envy, the utility of \(i\) for the allocation of \(i\) decreases by at most \(\tfrac{\alpha}{4n^{2}}\). Therefore,

\[\langle X_{i}^{\ell},\mu_{i}\rangle-\langle X_{i}^{0},\mu_{i}\rangle\geq\ell \cdot-\frac{\alpha}{4n^{2}}\geq-\frac{\alpha}{4}.\]

Again by Lemma 14, in each call to remove-envy, the utility of \(i\) for the allocation of \(i^{\prime}\) increases by at most \(\tfrac{\alpha}{4n^{3}}\). Therefore,

\[\langle X_{i^{\prime}}^{\ell},\mu_{i}\rangle-\langle X_{i^{\prime}}^{0},\mu_ {i}\rangle\leq\ell\cdot\frac{\alpha}{4n^{3}}\leq\frac{\alpha}{4n}.\]

Putting both equations together, we have

\[\langle X_{i}^{\ell},\mu_{i}\rangle-\langle X_{i^{\prime}}^{\ell },\mu_{i}\rangle \geq\langle X_{i}^{0},\mu_{i}\rangle-\frac{\alpha}{4}-\left( \langle X_{i^{\prime}}^{0},\mu_{i}\rangle+\frac{\alpha}{4n}\right)\] \[=\langle X_{i}^{0},\mu_{i}\rangle-\langle X_{i^{\prime}}^{0},\mu_ {i}\rangle-\frac{\alpha}{4}-\frac{\alpha}{4n}\] \[\geq\alpha-\frac{\alpha}{2}\] \[=\frac{\alpha}{2}\]

as desired. 

**Lemma 17**.: _Let \(X^{\prime}=\mathsf{remove\text{-}envy}(\mu,X)\). Then \(|\mathcal{S}(X^{\prime})|\leq|\mathcal{S}(X)|\)._

Proof.: It suffices to show that no equivalence class \(S\in S(X)\) becomes smaller (i.e. strictly loses members) during \(\mathsf{remove\text{-}envy}\). First, suppose for contradiction that \(S\) first becomes smaller during the while loop during iteration \(r\). Then in iteration \(r\), it must be the case that \(S\cap U\neq\emptyset\) and \(S\cap(N\backslash U)\neq\emptyset\), otherwise the allocation of each member of \(S\) would have changed by the same amount. Furthermore, it must be the case that in iteration \(r\), \(\beta_{i^{*}}>0\), otherwise no allocation would have been transferred. In iteration \(r\), consider some \(i\in(S\cap U)\) and \(i^{\prime}\in(S\cap(N\backslash U))\). Then \(\beta_{i}=0\)as \(i\) begins iteration \(r\) with zero envy towards \(i^{\prime}\). Because \(\beta_{i^{*}}\leq\min_{i}\beta_{i}\), this means \(\beta_{i^{*}}\leq 0\), which is a contradiction. Therefore, no equivalence class \(S\) becomes smaller during the while loop. To conclude the proof, we observe that in the cycle elimination step after the while loop, the total set of allocations remains the same, which implies that the set of equivalence classes remains the same as well. 

We are finally ready to prove Lemma 1.

Proof of Lemma 1.: We first prove by induction that every iteration \(r\) starts with an envy-free allocation \(X^{r}\). The base case is satisfied because \(X^{0}=Y^{\mu}\), and \(Y^{\mu}\) is envy-free by definition. Now, suppose that the inductive hypothesis holds for all iterations up to and including \(r\). We will show that iteration \(r+1\) starts with an envy-free allocation. If \(X^{r+1}=X^{r}\), then we can directly invoke the inductive hypothesis for iteration \(r\). Otherwise, suppose that remove-incoming-edge was called in iteration \(r\) of Algorithm 3. Then by Lemma 5, iteration \(r+1\) starts with an envy-free allocation. Suppose instead that cycle-shift was called in iteration \(r\). Then by Lemma 8, iteration \(r+1\) starts with an envy-free allocation. Finally, suppose that average-clique was called in iteration \(r\). Then the remove-envy is called repeatedly as long as there exists an edge with negative weight in \(E(G^{\prime})\). By Lemma 13, each call to remove-envy removes an edge with negative weight from \(E(G^{\prime})\), and adds no new edges with negative weight. There are a finite number of edges in \(E(G^{\prime})\), so this loop terminates. Therefore, iteration \(r+1\) starts with an envy-free allocation.

Next, we prove that in every iteration, either an edge is removed from the envy-with-slack graph, or the number of equivalence classes decreases. Formally, for two iterations \(r\) and \(r+1\), we prove that either

1. \(|E(G^{r})|>|E(G^{r+1})|\) or
2. \(|E(G^{r})|\geq|E(G^{r+1})|\) and \(|\mathcal{S}(X^{r})|>|\mathcal{S}(X^{r+1})|\).

If remove-incoming-edge is called in iteration \(r\) of Algorithm 3, then by Lemma 4 we have \(|E(G^{r})|>|E(G^{r+1})|\). If cycle-shift is called in iteration \(r\), then by Lemma 7 we have \(|E(G^{r})|>|E(G^{r+1})|\). If \(\exists\in E(G^{r})\) s.t. \(w_{e}\geq\frac{\alpha}{4bn^{4}}\), then \(e\in E(G^{r})\) but \(e\notin E(G^{r+1})\). Furthermore, if \(e^{\prime}\notin E(G^{r})\), then \(e^{\prime}\notin E(G^{r+1})\) as \(X^{r}=X^{r+1}\). Therefore, we have \(|E(G^{r})|>|E(G^{r+1})|\).

Finally, suppose average-clique is called in iteration \(r\) on clique \(Q\). Recall that \(G^{\mathsf{avg}}=\mathsf{create-slack-graph}(\mu,\mathsf{average-clique}(Q,X^{r }),\alpha^{\mathsf{avg}})\). By Lemma 10, we know that \(|E(G^{r})|\geq|E(G^{\mathsf{avg}})|\). The number of edges in \(E(G^{\mathsf{avg}})\) is at most \(n^{2}\), so remove-envy will be called at most \(n^{2}\) times by Lemma 13. Because average-clique was called, we know that \(w_{e}<\frac{\alpha^{r}}{4bn^{4}}\quad\forall e\in E(G^{r})\). By Lemma 11 with \(\alpha=\frac{\alpha^{r}}{4bn^{4}}\),

\[\langle X_{i}^{\mathsf{avg}},\mu_{i}\rangle-\langle X_{i^{\prime}}^{\mathsf{ avg}},\mu_{i}\rangle\geq-\frac{\alpha^{r}}{4bn^{4}}=-\frac{\alpha^{\mathsf{ avg}}}{4bn^{3}}\quad\forall i,i^{\prime}\in N.\]

Therefore, we can apply Lemma 16 with \(\alpha=\alpha^{\mathsf{avg}}\) to conclude that \(|E(G^{r+1})|\leq|E(G^{\mathsf{avg}})|\leq|E(G^{r})|\). Finally, observe that because \(C\) included members of at least two equivalence classes, the operation average-clique strictly decreased the number of equivalence classes. By Lemma 17, operation remove-envy does not increase the number of equivalence classes. Therefore, \(|\mathcal{S}(X^{r})|>|\mathcal{S}(X^{r+1})|\).

We now prove that the algorithm terminates with an \(X^{r}\) which satisfies Proposition 2. Each iteration either removes an edge or merges two equivalence classes. Because the maximum number of edges is \(n^{2}\) and the number of equivalence classes is \(n\), Algorithm 3 terminates in at most \(n^{3}\) iterations. We need to show that Algorithm 3 terminates with \(\alpha^{r}\geq\gamma\). If an iteration \(r\) does not call remove-envy, then an edge is removed and \(\alpha^{r+1}\geq\frac{\alpha^{r}}{4bn^{4}}\). There can be at most \(n^{2}\) such iterations. If an iteration \(r\) does call remove-envy, then \(\alpha^{r+1}=\frac{\alpha^{r}}{2n}\). There can be at most \(n\) such iterations which call remove-envy between every iteration which does not call remove-envy, for a total of at most \(n^{3}\) iterations. Therefore,

\[\alpha^{r}\geq\frac{\alpha_{0}}{(4bn^{4})^{n^{2}}\cdot(2n)^{n^{3}}}=\frac{ \alpha_{0}}{e^{n^{2}\log(4bn^{4})+n^{3}\log(2n)}}.\]

Choosing \(\alpha_{0}=\gamma\cdot(e^{n^{2}\log(4bn^{4})+n^{3}\log(2n)})\) thus implies that \(\alpha_{r}\geq\gamma\) for every iteration \(r\) if \(\gamma\cdot(e^{n^{2}\log(4bn^{4})+n^{3}\log(2n)})\leq 1\). Therefore, we set \(\gamma_{0}=e^{-n^{2}\log(4bn^{4})-n^{3}\log(2n)}\).

Finally, we need to show that Algorithm 3 does not significantly decrease the social welfare. By Lemmas 6, 9 and 12, we know that each of the operations remove-incoming-edge, cycle-shift, and average-clique change the social welfare by at most \(O(\gamma)\). Each of these operations is called at most \(n^{3}\) times. Each of remove-incoming-edge and cycle-shift are called at most once for each edge, or at most \(n^{2}\) times. Operation average-clique is called at most \(n\) times for each edge, or at most \(n^{3}\) times. Finally, Lemma 15 bounds the total social welfare loss from all calls to remove-envy between any two calls to average-clique by \(O(\gamma)\). Therefore, \(\operatorname{sw}(Y^{\mu},\mu)-\operatorname{sw}(X^{r},\mu)=O(\gamma)\), as desired.

Proof of Theorem 2

Proof.: Let \(a=1\), \(b=3\), \(n=2\), and \(m=2\), and assume that the distributions of values are all normal distributions with variance \(1\). For \(n=2\), envy-freeness and proportionality are equivalent, and therefore we will focus on the former. Define \(\epsilon=T^{-1/3}\). We will prove the desired result by contradiction. Assume there exists an algorithm \(\mathrm{ALG}\) such that for any \(\mu^{*}\in[a,b]^{2\times 2}\), the probability that the algorithm satisfies the envy-freeness constraints and has regret of less than \(\frac{T^{2/3}}{\log(T)}\) is at least \(1-1/T\).

Consider the following two matrices.

\[\mu_{1} =\begin{bmatrix}2&3\\ 1&1\end{bmatrix} \mu_{2} =\begin{bmatrix}2&3\\ 1&1+\epsilon\end{bmatrix}\]

Define \(P_{1}\) as the distribution of the full history \(H_{T}\) when using algorithm \(\mathrm{ALG}\) when \(\mu^{*}=\mu_{1}\). Define \(P_{2}\) as the equivalent distribution when \(\mu^{*}=\mu_{2}\).

We will proceed according to the following proof sketch. First, we will show that if \(\mu^{*}=\mu_{1}\), then \(\mathrm{ALG}\) with constant probability allocates \(\tilde{O}(T^{2/3})\) items of type 2 to player 2 (Lemma 18). We next upper bound the total variation distance between \(P_{1}\) and \(P_{2}\). When two distributions are sufficiently close in total variation distance, then an event that has constant probability under one distribution also has constant probability under the other distribution. Therefore, Lemma 18 and the closeness in TV distance of \(P_{1}\) and \(P_{2}\) together imply that if \(\mu^{*}=\mu_{2}\), then \(\mathrm{ALG}\) with constant probability allocates \(\tilde{O}(T^{2/3})\) items of type 2 to player 2. When \(\mathrm{ALG}\) allocates \(\tilde{O}(T^{2/3})\) items of type 2 to player 2, then \(\mathrm{ALG}\) cannot satisfy the envy-freeness constraints for \(\mu_{2}\). Therefore, the previous two sentences together imply that with constant probability, \(\mathrm{ALG}\) will not satisfy the envy-freeness constraints for all \(t\) when \(\mu^{*}=\mu_{2}\), which is a contradiction.

**Lemma 18**.: _Using the notation defined above,_

\[\mathbb{E}_{P_{1}}[N_{22}^{T}]\leq T^{2/3}\]

_and_

\[\Pr_{P_{1}}\left(\sum_{t=0}^{T-1}X_{22}^{t}>\frac{T^{2/3}}{\log(T)}\right)<1/8.\] (37)

Intuitively, both equations in Lemma 18 bound how many times an item of type \(2\) is allocated to player 2. The first equation bounds in expectation while the second equation bounds elements of the fractional allocations \(X^{t}\). The proof of Lemma 18 is given in Appendix G.1.

**Lemma 19**.: _Using the notation from above,_

\[\mathrm{KL}(P_{1},P_{2})=\mathbb{E}_{P_{1}}[N_{22}^{T}]\cdot\mathrm{KL}\Big{(} \mathcal{N}(1,1),\mathcal{N}(1+\epsilon,1)\Big{)}\]

Proof.: Define \(f^{1}_{ik}\) as the probability density function (pdf) of \(\mathcal{N}((\mu_{1})_{ik},1)\) and \(f^{2}_{ik}\) as the pdf of \(\mathcal{N}((\mu_{2})_{ik},1)\). We let \(f_{\mathcal{N}(\mu,\sigma^{2})}\) be the pdf of a normal distribution with mean \(\mu\) and variance \(\sigma^{2}\).

For any history \(H_{T}=\{(k_{t},i_{t},v_{t})\}_{t=0}^{T-1}\), recall that \(X^{t}\) is the fractional allocation chosen by \(\mathrm{ALG}\) at time \(t\) given history \(H_{t}\). Then we have that for any \(H_{T}\)

\[P_{1}(H_{T})=\prod_{t=0}^{T-1}\left(\frac{1}{m}X_{i_{t}k_{t}}^{t}f^{1}_{i_{t} k_{t}}(v_{t})\right),\]

The \(1/m\) term comes from item \(t\) having a \(1/m\) probability of being of type \(k_{t}\). The \(X_{i_{t}k_{t}}^{t}\) is the probability that \(\mathrm{ALG}\) allocates the item of type \(k_{t}\) to player \(i_{t}\) at time \(t\), and finally \(f^{1}_{i_{t}k_{t}}(v_{t})\) is the probability of seeing value \(v_{t}\) given that the item of type \(k_{t}\) was allocated to player \(i_{t}\). Similarly, we have that

\[P_{2}(H_{T})=\prod_{t=0}^{T-1}\left(\frac{1}{m}X_{i_{t}k_{t}}^{t}f^{2}_{i_{t}k_ {t}}(v_{t})\right).\]Therefore, we have that

\[KL(P_{1},P_{2}) =\mathbb{E}_{H_{T}\sim P_{1}}\left[\log\left(\frac{P_{1}(H_{T})}{P_{2 }(H_{T})}\right)\right]\] \[=\mathbb{E}_{H_{T}\sim P_{1}}\left[\log\left(\frac{\prod_{t=0}^{T-1 }\left(\frac{1}{m}X_{i_{t}k_{t}}^{t}f_{i_{t}k_{t}}^{1}(v_{t})\right)}{\prod_{t= 0}^{T-1}\left(\frac{1}{m}X_{i_{t}k_{t}}^{t}f_{i_{t}k_{t}}^{2}(v_{t})\right)} \right)\right]\] \[=\mathbb{E}_{H_{T}\sim P_{1}}\left[\log\left(\frac{\prod_{t=0}^{T-1 }\left(f_{i_{t}k_{t}}(v_{t})\right)}{\prod_{t=0}^{T-1}\left(f_{i_{t}k_{t}}^{2} (v_{t})\right)}\right)\right]\] \[=\mathbb{E}_{H_{T}\sim P_{1}}\left[\log\left(\prod_{t=0}^{T-1} \frac{f_{i_{t}k_{t}}^{1}(v_{t})}{f_{i_{t}k_{t}}^{2}(v_{t})}\right)\right]\] \[=\mathbb{E}_{H_{T}\sim P_{1}}\left[\log\left(\prod_{t:(i_{t},k_{t })=(2,2)}\frac{f_{\mathcal{N}(1,1)}(v_{t})}{f_{\mathcal{N}(1+\epsilon,1)}(v_{ t})}\right)\right]\] \[=\mathbb{E}_{H_{T}\sim P_{1}}\left[\sum_{t:(i_{t},k_{t})=(2,2)} \log\left(\frac{f_{\mathcal{N}(1,1)}(v_{t})}{f_{\mathcal{N}(1+\epsilon,1)}(v_ {t})}\right)\right]\] \[=\sum_{t=0}^{T-1}\mathbb{E}_{H_{T}\sim P_{1}}\left[\mathbbm{1}_{( i_{t},k_{t})=(2,2)}\left(\frac{f_{\mathcal{N}(1,1)}(v_{t})}{f_{\mathcal{N}(1+ \epsilon,1)}(v_{t})}\right)\right]\] \[=\sum_{t=0}^{T-1}\mathbb{E}_{H_{T}\sim P_{1}}\left[\mathbbm{1}_{( i_{t},k_{t})=(2,2)}\left(\frac{f_{\mathcal{N}(1,1)}(v_{t})}{f_{\mathcal{N}(1+ \epsilon,1)}(v_{t})}\right)\right]\] \[=\sum_{t=0}^{T-1}\mathbb{E}_{H_{T}\sim P_{1}}\left[\mathbbm{1}_{( i_{t},k_{t})=(2,2)}\cdot KL\left(\mathcal{N}(1,1),\mathcal{N}(1+\epsilon,1) \right)\right]\] \[=KL\left(\mathcal{N}(1,1),\mathcal{N}(1+\epsilon,1)\right)\mathbb{ E}_{H_{T}\sim P_{1}}\left[\sum_{t=0}^{T-1}\mathbbm{1}_{(i_{t},k_{t})=(2,2)}\right]\] \[=KL\left(\mathcal{N}(1,1),\mathcal{N}(1+\epsilon,1)\right)\mathbb{ E}_{H_{T}\sim P_{1}}\left[N_{22}^{T}\right].\]

We can use Lemma 18 and Lemma 19 to bound the KL-divergence between \(P_{1}\) and \(P_{2}\) by

\[\mathrm{KL}(P_{1},P_{2})=\mathbb{E}_{P_{1}}[N_{22}^{T}]\cdot\mathrm{KL}\Big{(} \mathcal{N}(1,1),\mathcal{N}(1+\epsilon,1)\Big{)}=\frac{\mathbb{E}_{P_{1}}[N_{ 22}^{T}]\epsilon^{2}}{2}\leq\frac{1}{2}.\] (38)

We next need the following result from probability theory that is a consequence of the Bretagnolle-Huber inequality.

**Lemma 20**.: _For any two probability distributions \(p\) and \(q\) defined on the same space and for any measurable event \(F\) in this space,_

\[p(F^{C})+q(F)\geq\frac{1}{2}e^{-\mathrm{KL}(p,q)}.\]

Proof.: For any probability distributions \(p\) and \(q\), we have by the Bretagnolle-Huber inequality that

\[d_{\mathrm{TV}}(p,q)\leq 1-\frac{1}{2}e^{-\mathrm{KL}(p,q)}.\]For any event \(F\),

\[d_{\mathrm{TV}}(p,q)\geq|p(F)-q(F)|\geq p(F)-q(F)=1-p(F^{C})-q(F).\]

Combining the above equations gives that

\[p(F^{C})+q(F)\geq\frac{1}{2}e^{-\mathrm{KL}(p,q)}.\] (39)

Taking \(p=P_{1}\), \(q=P_{2}\) and \(F=\left\{\sum_{t=0}^{T-1}X_{22}^{t}\leq\frac{T^{2/3}}{\log(T)}\right\}\) in Lemma 20, we have by Equation (38) that

\[\Pr_{P_{1}}\left(\sum_{t=0}^{T-1}X_{22}^{t}>\frac{T^{2/3}}{\log(T)}\right)+ \Pr_{P_{2}}\left(\sum_{t=0}^{T-1}X_{22}^{t}\leq\frac{T^{2/3}}{\log(T)}\right) \geq\frac{1}{2}e^{-\mathrm{KL}(P_{1},P_{2})}\geq 1/4.\] (40)

Combining Equation (37) with Equation (40) gives

\[\Pr_{P_{2}}\left(\sum_{t=0}^{T-1}X_{22}^{t}\leq\frac{T^{2/3}}{\log(T)}\right) \geq 1/8.\] (41)

If \(\sum_{t=0}^{T-1}X_{22}^{t}\leq\frac{T^{2/3}}{\log(T)}\), then there must exist some time \(t\) such that \(X_{22}^{t}\leq\frac{T^{-1/3}}{\log(T)}\). If \(X_{22}^{t}\leq\frac{T^{-1/3}}{\log(T)}\), then player 2's envy in expectation at time \(t\) for player 1 under \(\mu_{2}\) (for sufficiently large \(T\)) is

\[X_{11}^{t}\cdot 1+X_{12}^{t}(1+\epsilon)-X_{21}^{t}\cdot 1-X_{2 2}^{t}(1+\epsilon) =(1-X_{21}^{t})\cdot 1+(1-X_{22}^{t})(1+\epsilon)-X_{21}^{t} \cdot 1-X_{22}^{t}(1+\epsilon)\] \[=2+\epsilon-2X_{21}^{t}-2X_{22}^{t}(1+\epsilon)\] \[\geq\epsilon-2X_{22}^{t}(1+\epsilon)\] \[\geq\epsilon-\frac{2T^{-1/3}(1+\epsilon)}{\log(T)}\] \[=T^{-1/3}-\frac

[MISSING_PAGE_FAIL:38]

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Our main claim is a explore-then-commit algorithm which achieves \(\tilde{O}(T^{2/3})\) regret while maintaining envy-freeness or proportionality in expectation. In our body, we provide an algorithm that does so and a proof sketch, with the full proof in Appendix D. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The limitations of our results are discussed in the discussion section of the paper. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best

[MISSING_PAGE_FAIL:40]

2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [NA] Justification: This paper does not include any experiments requiring code. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA] Justification: This paper does not include any experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.

* The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: This paper does not include any experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: This paper does not include any experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?Answer: [Yes] Justification: All conditions in the code of ethics are met. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: The paper discusses positive societal impacts in applications like food allocation. There are no (plausible) negative societal impacts. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This paper does not include any datasets or trained models that can be misused. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiringthat users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: This paper does not use any existing assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This paper does not release any new assets. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects**Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing or human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve crowdsourcing or human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. * We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. * For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.