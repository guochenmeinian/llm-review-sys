# On Learning Necessary and Sufficient Causal Graphs

Hengrui Cai

University of California, Irvine

hengrc1@uci.edu

&Yixin Wang

University of Michigan

yixinw@umich.edu

&Michael I. Jordan

University of California, Berkeley

jordan@cs.berkeley.edu

&Rui Song

North Carolina State University

songray@gmail.com

###### Abstract

The causal revolution has stimulated interest in understanding complex relationships in various fields. Most of the existing methods aim to discover causal relationships among all variables within a complex large-scale graph. However, in practice, only a small subset of variables in the graph are relevant to the outcomes of interest. Consequently, causal estimation with the full causal graph--particularly given limited data--could lead to numerous _falsely discovered, spurious_ variables that exhibit high correlation with, but exert no causal impact on, the target outcome. In this paper, we propose learning a class of _necessary and sufficient causal graphs (NSCG)_ that exclusively comprises causally relevant variables for an outcome of interest, which we term _causal features_. The key idea is to employ _probabilities of causation_ to systematically evaluate the importance of features in the causal graph, allowing us to identify a subgraph relevant to the outcome of interest. To learn NSCG from data, we develop a _necessary and sufficient causal structural learning (NSCSL)_ algorithm, by establishing theoretical properties and relationships between probabilities of causation and natural causal effects of features. Across empirical studies of simulated and real data, we demonstrate that NSCSL outperforms existing algorithms and can reveal crucial yeast genes for target heritable traits of interest.

## 1 Introduction

Causal discovery has gained significant attention in recent years for disentangling complex causal relationships in various fields. Building upon the causal graphical model (see e.g., [23]), many causal structural learning algorithms have been developed (see e.g., [35; 7; 34; 14; 4; 27; 46; 44; 48; 5] to infer the causal knowledge (e.g., causal graphs) from observed data. These algorithms are based on the assumption of causal sufficiency (the absence of unmeasured confounders). In real-world applications, to satisfy such an assumption, we strive to learn large-scale causal graphs (see e.g., [20; 6; 38; 21], in the hope of **sufficiently** describing how an outcome of interest depends on its relevant variables.

In addition to sufficiency, it is also crucial to account for the concept of **necessity** by excluding redundant variables in explaining the outcome of interest. Failure to do so can result in the inclusion of spurious variables in the learned causal graphs, which are highly correlated but have no causal impact on the outcome. These variables can impede causal estimation with limited data and lead to falsely discovered spurious relationships, leading to poor generalization performance for downstream prediction [31]. For example, it might be observed that men aged 30 to 40 who buy diapers are also likely to buy beer. However, beer purchase is a spurious feature for diaper purchases: their correlation is not necessarily causal, as both purchases might be confounded by a shared cause, such as newfathers buying diapers for childcare while also buying beer to alleviate stress. Therefore, simply increasing the availability of diapers or beer will not causally improve the demand for the other (see also Fig. 1(left)).

Furthermore, the number of variables causally relevant to the outcome of interest is often considerably smaller than the number of variables included in estimating a causal graph (see Fig. 1(right)). For example, while an individual's genome may encompass 4 to 5 million single nucleotide polymorphisms (SNPs), only a limited number of non-spurious genes or proteins are found to systematically regulate the expression of the phenotype of interest [e.g., 6]. Similarly, in natural language processing tasks, excluding spurious embeddings such as writing style and dialect can enhance model accuracy and downstream prediction performance [e.g., 10]. Thus, a more parsimonious causal graph is required to unveil the necessary and sufficient causal dependencies.

In this work, we focus on learning _necessary and sufficient causal graphs_ (NSCG) that only contain causally relevant variables (which we term _causal features_) for an outcome of interest, offering a compact representation of causal graphs for a target outcome. Our **contributions** are three-fold.

\(\bullet\) We propose the notion of NSCG (see an illustration inside the green solid square in the right panel of Fig. 1). The key idea is to leverage the marginal and conditional probabilities of causation (POC) to systematically characterize the importance of variables (a.k.a. features).

\(\bullet\) We establish theoretical properties and relationships between POC and the natural causal effects of features, and derive the conditions under which they are equivalent, with lower bounds provided for identification. The natural causal effects of features have explicit forms under parametric models such as the linear structural equation model, enabling convenient estimation of the POC from observed data.

\(\bullet\) To select necessary and sufficient features in causal graphs, we propose a necessary and sufficient causal structural learning algorithm (NSCSL) to learn an NSCG containing all necessary and sufficient causes without unnecessary spurious features. This enables feature selection for causal discovery.

The proposed method provides concise explanations of causal relationships with high-dimensional data (i.e., with a large number of variables). Empirical studies in simulated datasets show that NSCSL outperforms existing algorithms in distilling relevant subgraphs for outcomes of interest; NSCSL can also identify important quantitative trait loci for the yeast and the causal protein signaling network for single cell data, as demonstrated in real data analyses.

### Related Works

The literature on _causal structural learning_ can be broadly classified into three classes. The first class of methods focuses on using local conditional independence tests to identify the causal skeleton and determine the direction of the edges, such as the PC algorithm [35; 14; 36]. The second class of methods uses functional causal models with additional assumptions about the data distribution, including ICA-LiNGAM [34] and the causal additive model (CAM) [4]. The third class, the score-based methods, includes greedy equivalence search (GES) [7; 27; 11] and acyclicity optimization methods [46]. Refer to [44; 48; 17; 5; 47; 41] for additional cutting-edge causal structural learning methods. Yet, these works do not consider the necessity of the variables incorporated in the causal graph, i.e., whether the variables are causally relevant to the outcome. Consequently, such algorithms can often produce a redundant or potentially misleading graph, as depicted in Fig. 1 (right).

Figure 1: **Left**: Illustration of the causal relationship between the customer being a new father or not, beer purchasing, and diaper purchasing, where solid lines represent the true model, and the dashed line corresponds to the spurious correlation between beer purchasing and diaper purchasing. **Right**: Relationship between various causal structures. The nodes \(A\), \(B\), and \(C\) belong to the necessary and sufficient causal graph for the desired result \(Y\) and are represented within the solid green square. Among them, nodes \(B\) and \(C\) are members of the Markov blanket of \(Y\), enclosed by the blue square. The node \(S\) is the spurious variable for \(Y\), while the nodes \(N\) and \(M\) are not related to the target.

Our work also links to _feature selections_ [see an overview in [16]]. Despite the extensive literature, only a few studies have examined variable selection in causal graphs. One notable exception is Aliferis et al. [1], which uses the concept of the Markov blanket to construct a local causal graph for the target variable of interest. In this context, a Markov blanket of a variable \(Y\) is the minimal variable subset conditioned upon which all other variables become probabilistically independent of \(Y\). Consequently, their algorithm uncovers only direct parents or children in the identified causal graph (such as the blue dotted square in the right panel of Fig. 1) and thereby overlooks the ancestors that contain atavistic information and indirectly influence the outcome. Recent works [18; 19] consider a minimal sufficient action set in bandits. Yet, these methods [also see 12; 13] rely on a true or known graph. We instead propose to simultaneously learn the causal graph and select the causal features.

Lastly, our work is connected to the body of research on _probability of causation_ [e.g., 22; 39; 45], which delineates the necessity and sufficiency of features for the outcome of interest. Recently, Wang & Jordan [42] introduced this concept into representation learning, formulating the non-spuriousness and efficiency of representations by generalizing the probabilities of causation to accommodate low-dimensional representations of high-dimensional data. However, these works primarily concentrate on the identification of probabilities of causation, assuming that the causal graph among the variables under consideration is known with causally independent features. We address this gap in our work by incorporating the notion of probabilities of causation into learning complex causal graphs.

## 2 Framework

**Graph terminology.** Consider a graph \(\mathcal{G}=(\bm{X},\bm{D}_{\bm{X}})\) with a node set \(\bm{X}\) and an edge set \(\bm{D}_{\bm{X}}\) that encompasses all edges in \(\mathcal{G}\) for nodes \(\bm{X}\). A node \(X_{i}\) is said to be a parent of \(X_{j}\) if there is a directed edge from \(X_{i}\) to \(X_{j}\), i.e., \(X_{i}\) is a direct cause of \(X_{j}\). A node \(X_{k}\) is said to be an ancestor of \(X_{j}\) if there is a directed path from \(X_{k}\) to \(X_{j}\) regulated by at least one additional node \(X_{i}\) for \(i\neq k\) and \(i\neq j\), i.e., \(X_{k}\) is an indirect cause of \(X_{j}\). Let the set of all parents/ancestors of node \(X_{j}\) in \(\mathcal{G}\) as \(\text{PA}_{X_{j}}(\mathcal{G})\). A directed graph \(\mathcal{G}\) that does not contain directed cycles is called a directed acyclic graph (DAG). The structural causal model (SCM) characterizes the causal relationship among \(|\bm{X}|=d\) nodes via a DAG \(\mathcal{G}\) and noises \(\bm{e}_{\bm{X}}=[e_{X_{1}},\cdots,e_{X_{d}}]^{\top}\) such that \(X_{i}:=h_{i}\{\text{PA}_{X_{i}}(\mathcal{G}),e_{X_{i}}\}\) for some unknown \(h_{i}\) and \(i=1,\cdots,d\).

**Notations and assumptions.** Denote \(\bm{O}=(\bm{Z},Y)\) as a collection of nodes that contains features \(\bm{Z}=[Z_{1},\cdots,Z_{p}]^{\top}\in\mathcal{Z}\subset\mathbb{R}^{p}\) and a discrete outcome of interest as \(Y\in\mathcal{L}=\{y_{1},\cdots,y_{l}\}\) for \(l\) different values. Here, the features can be intervened, such as treatment and mediators. Let \(Y(\bm{Z}=\bm{z})\) be the potential value of \(Y\) that would be observed after setting variable \(\bm{Z}\) as \(\bm{z}\). This is equivalent to the value of \(Y\) by imposing a 'do-operator' of \(do(\bm{Z}=\bm{z})\) as in Pearl et al. [23]. Similarly, one can define the potential outcome, \(Y(Z_{i}=z_{i})\), by setting an individual variable \(Z_{i}\) as \(z_{i}\), while keeping the rest of the model unchanged. Suppose there exists an SCM that characterizes the causal relationship among \(\bm{O}\), with its DAG as \(\mathcal{G}_{\bm{O}}\). A notation and abbreviation table is provided in App. A. Following the causal inference literature [see e.g., 29; 22; 23; 42], we assume:

(A1). **Consistency**: \(\bm{Z}=\bm{z}\leftrightarrow Y(\bm{Z}=\bm{z})=Y,\forall\bm{z}\in\mathcal{Z}\).

(A2). **Ignorability**: (i) \(Y(\bm{Z}=\bm{z})\perp\bm{Z},\forall\bm{z}\in\mathcal{Z};\) (ii) \(Y(Z_{i}=z_{i})\perp Z_{i}|\text{PA}_{Z_{i}\cup Y}(\mathcal{G}_{\bm{O}}), \forall z_{i}\in\mathcal{Z}_{i}.\)

Here, (A1) implies that the outcome observed for each unit under study with features as \(\bm{z}\) is identical to the outcome we would have observed had that unit been set with features \(\bm{Z}=\bm{z}\). In addition, since we include as many confounders as possible, the ignorability assumption in (A2), also known as the no unmeasured confounderness assumption, is satisfied.

## 3 Necessary and Sufficient Causal Graphs

We care about a subset or a function of \(\bm{Z}\), denoted as \(\bm{X}=[X_{1},\cdots,X_{d}]^{\top}\) (of \(d\) dimension with possibly \(d\ll p\)), which indeed captures the causal relationship between \(\bm{Z}\) and \(Y\). To be specific, let an SCM for causal nodes \(\bm{V}=(\bm{X},Y)\) with its DAG as \(\mathcal{G}_{\bm{V}}=(\bm{V},\bm{D}_{\bm{V}})\) and \(e_{\bm{V}}\) as a \(d+1\) dimensional independent noise, to characterize the causal relationship between \(\bm{X}\) and \(Y\). Let \(\mathbb{P}_{\mathcal{G}}\) be the mass/density function for an SCM with its DAG \(\mathcal{G}\). Following the causal (or disentangled) factorization in the causal graphical model [23], we define the _sufficient_ causal graph as follows.

**Definition 3.1**.: (Sufficient Graph) The graph \(\mathcal{G}_{\bm{V}}\) is a _sufficient_ causal graph to capture the causal relationship among \(\bm{Z}\) and \(Y\) with \(\bm{X}\subset\bm{Z}\) or \(\bm{X}=f(\bm{Z})\) (where \(f\) is within a countable or Vapnik-Chervonenkis (VC) class) if \(\mathbb{P}_{\mathcal{G}_{\bm{V}}}\{Y|\text{PA}_{Y}(\mathcal{G}_{\bm{V}})\}\prod_{X _{i}\in\text{PA}_{\bm{Y}}(\mathcal{G}_{\bm{V}})}\mathbb{P}_{\mathcal{G}_{\bm{V}}} \{X_{i}|\text{PA}_{X_{i}}(\mathcal{G}_{\bm{V}})\}\)\(=\mathbb{P}_{\mathcal{G}_{\bm{O}}}\{Y|\text{PA}_{Y}( \mathcal{G}_{\bm{O}})\}\prod_{Z_{i}\in\text{PA}_{Y}(\mathcal{G}_{\bm{O}})\} \mathbb{P}_{\mathcal{G}_{\bm{O}}}\{Z_{i}|\text{PA}_{Z_{i}}(\mathcal{G}_{\bm{O}})\}\).

Here, Def. 3.1 refers to a sub-structure \(\mathcal{G}_{\bm{V}}\) (from the whole graph \(\mathcal{G}_{\bm{O}}\)) containing all directed edges or paths towards \(Y\), making it sufficient to describe how \(Y\) depends on all its ancestors. Then, the causal graph \(\mathcal{G}_{\bm{V}}\) is said to be _necessary_ and _sufficient_ if it satisfies the following definition.

**Definition 3.2**.: (Necessary and Sufficient Graph) Suppose \(\mathcal{G}_{\bm{V}}\) satisfies Def. 3.1, then \(\mathcal{G}_{\bm{V}}\) is a _necessary_ and _sufficient_ causal graph to capture the causal relationship among \(\bm{Z}\) and \(Y\) if for any true subset \(\bm{W}\) of \(\bm{X}\), i.e., \(\bm{W}\subset\bm{X}\) or \(\bm{W}=g(\bm{X})\) (where \(g\) is within a countable or VC class), with \(\bm{U}=(\bm{W},Y)\), we have \(\mathbb{P}_{\mathcal{G}_{\bm{V}}}\{Y|\mathrm{PA}_{Y}(\mathcal{G}_{\bm{V}})\} \prod_{X_{i}\in\mathrm{PA}_{Y}(\mathcal{G}_{\bm{V}})}\mathbb{P}_{\mathcal{G} _{\bm{V}}}\{X_{i}|\mathrm{PA}_{X_{i}}(\mathcal{G}_{\bm{V}})\}\neq\mathbb{P}_{ \mathcal{G}_{\bm{U}}}\{Y|\mathrm{PA}_{Y}(\mathcal{G}_{\bm{U}})\}\prod_{W_{i} \in\mathrm{PA}_{Y}(\mathcal{G}_{\bm{U}})}\mathbb{P}_{\mathcal{G}_{\bm{U}}}\{W_ {i}|\mathrm{PA}_{W_{i}}(\mathcal{G}_{\bm{U}})\},\) where \(\mathcal{G}_{\bm{U}}\) is the causal graph for \(\bm{U}\).

Therefore, by Def. 3.2, we can further identify the _minimal sub-structure_\(\mathcal{G}_{\bm{V}}\) which includes only all directed edges or paths leading to \(Y\). The goal is to learn such a necessary and sufficient causal graph (NSCG) \(\mathcal{G}_{\bm{V}}\) from the observed data denoted as \(\{\bm{o}^{(j)}=(\bm{z}^{(j)},y^{(j)})\}_{1\leq j\leq n}\) with sample size \(n\), by identifying the latent causal features \(\bm{X}\). Denote the resulting estimated graph as \(\widehat{\mathcal{G}}_{\bm{V}}\).

## 4 Probability of Causation and Causal Effects

Obtaining an NSCG \(\mathcal{G}_{\bm{V}}\) directly based on Def. 3.2 poses several challenges, as the latent causal features \(\bm{X}\) driving the causal graph remain unknown. A naive approach is to search all different combinations of \(\bm{Z}\) for a candidate of \(\bm{X}\) such that Def. 3.2 holds, which yields a complexity of \(\mathcal{O}(p^{p})\). This motivates us to assess the necessity and sufficiency of features in determining the outcome by introducing the concepts of probabilities of causation and causal effects, which will be elaborated on and interconnected in this section.

### Probabilities of Causation and Lower Bounds

The probabilities of a feature being necessary and sufficient, known as the probability of causation (POC), have been proposed and studied [see 22; 39; 42]. Specifically, the probability of necessity and sufficiency (PNS) of feature \(\bm{Z}\) is first defined in Tian & Pearl [39] as follows.

**Definition 4.1**.: PNS in Tian & Pearl [39] with a univariate binary feature \(Z\):

\[PNS\equiv\mathbb{P}\{Y(Z\neq z)\neq y,Y(Z=z)=y\}\underset{by(A1)}{=}\mathbb{P} (Z=z,Y=y)\cdot PN+\mathbb{P}(Z\neq z,Y\neq y)\cdot PS,\]

where the probability of necessity (PN) is \(PN=\mathbb{P}\{Y(Z\neq z)\neq y|Z=z,Y=y\},\) and the probability of sufficiency (PS) is \(PS=\mathbb{P}\{Y(Z=z)=y|Z\neq z,Y\neq y\}.\)

The second equation in Def. 4.1 holds under (A1) [see details in 22; 39]. The PN score reflects the necessity of \(Z\) by evaluating the probability of the outcome becoming worse if revising the features given the good outcome observed. Similarly, the PS score indicates the sufficiency of \(Z\) by evaluating the probability of the outcome becoming better if changing the features given the bad outcome observed. Therefore, the PNS score shows the causal importance of the features by combining necessary and sufficient properties. The above definition can be generalized to multivariate cases for nonbinary features [see e.g., 42] to quantify the POC of an individual feature \(Z_{i}\). Let \(\bm{Z}_{-i}\equiv\bm{Z}\setminus Z_{i}\) be the set of complementary variables of \(Z_{i}\). In the following, we consider two different POCs for \(Z_{i}\) by extending the work of Wang & Jordan [42].

**Definition 4.2**.: Marginal POC (M-POC) for \(Z_{i}\):

\[\text{M-POC}_{i}(y)\equiv\mathbb{P}\{Y(Z_{i}\neq z_{i})\neq y,Y(Z_{i}=z_{i}) =y\}.\]

**Definition 4.3**.: Conditional POC (C-POC) for \(Z_{i}\):

\[\text{C-POC}_{i}(y)\equiv\mathbb{P}\{Y(Z_{i}\neq z_{i},\bm{Z}_{-i}=\bm{z}_{-i} )\neq y,Y(Z_{i}=z_{i},\bm{Z}_{-i}=\bm{z}_{-i})=y\}.\]

We introduce the marginal POC (M-POC) as a novel quantity in the literature to summarize the overall causal importance of an individual feature in determining the outcome's value. The conditional POC (C-POC) in Def. 4.3 corresponds to the conditional PNS in Wang & Jordan [42], which quantifies the likelihood of an individual feature being a direct and significant cause of the outcome while holding other features constant. As per Section 9.2.3 in Pearl et al. [22], the PNS in Def. 4.1 is not estimable unless additional conditions (monotonicity) are specified. To alleviate such a condition for identifying Defs. 4.2 and 4.3, we derive the lower bounds for the proposed POCs as follows.

**Theorem 4.4**.: _(Lower Bound of Probabilities of Causation) Suppose (A1) and (A2) hold. Then_

\[\text{M-POC}_{i}(y) \geq\mathbb{P}(Y=y|Z_{i}=z_{i})-\mathbb{P}(Y=y|Z_{i}\neq z_{i}),\] \[\text{C-POC}_{i}(y) \geq\mathbb{P}(Y=y|Z_{i}=z_{i},\bm{Z}_{-i}=\bm{z}_{-i})-\mathbb{P}(Y= y|Z_{i}\neq z_{i},\bm{Z}_{-i}=\bm{z}_{-i}).\]The proofs of Thm. 4.4 are in App. D. The lower bound equality holds when an additional monotonicity condition is imposed, with details in App. D. The results in Thm. 4.4 allow us to estimate the lower bound of POC from observed data by learning the conditional probability of \(Y\) given various combinations of confounders. This, in turn, aids in evaluating the significance of features, with details provided in App. B. Yet, estimating these conditional probabilities of \(Y\) based on high-dimensional features is very challenging [e.g., 32; 42], which motivates us to consider the corresponding expected mean outcome given different combinations of the confounders.

### Causal Effects and Connection to POCs

To connect the proposed POCs and facilitate the empirical estimation, we introduce the natural total effect (TE) and natural direct effect (DE) for \(Z_{i}\) by extending definitions in Pearl et al. [22].

**Definition 4.5**.: Natural Causal Effects for \(Z_{i}\):

\[TE_{i} =\mathbb{E}\{Y(Z_{i}=z_{i}+1)\}-\mathbb{E}\{Y(Z_{i}=z_{i})\},\] \[DE_{i} =\mathbb{E}\{Y(Z_{i}=z_{i}+1,\bm{Z}_{-i}=\bm{z}_{-i}^{(z_{i})})\} -\mathbb{E}\{Y(Z_{i}=z_{i})\},\]

where \(\bm{z}_{-i}^{(z_{i})}\) is the value of \(\bm{Z}_{-i}\) if setting \(do(Z_{i}=z_{i})\).

The natural total effect (\(TE_{i}\)) can be understood as the marginal change in the outcome when increasing \(Z_{i}\) by one unit. Similarly, the natural direct effect (\(DE_{i}\)) represents the conditional change in the outcome when \(Z_{i}\) is increased by one unit, with all other features held constant. Indeed, the natural total and direct causal effects delineated in Pearl et al. [22] emerge as particular instances of Def. 4.5 when examining a solitary treatment subject to intervention. By comparing Def. 4.5 with Defs. 4.2 and 4.3, it is natural to establish the relationship between POCs and causal effects below.

**Theorem 4.6**.: _(Relation between POCs and Causal Effects) Define \(\delta_{M}(z_{i})\equiv\mathbb{E}\{Y|Z_{i}=z_{i}\}-\mathbb{E}\{Y|Z_{i}\neq z_{ i}\}\) and \(\delta_{C}(z_{i})\equiv\mathbb{E}\{Y|Z_{i}=z_{i},\bm{Z}_{-i}=\bm{z}_{-i}\}- \mathbb{E}\{Y|Z_{i}\neq z_{i},\bm{Z}_{-i}=\bm{z}_{-i}\}\). Suppose (A1)-(A2) hold, then_

\[\sum_{y\in\mathcal{L}}\text{yM-POC}_{i}(y)\geq\delta_{M}(z_{i}),\qquad\sum_{y \in\mathcal{L}}\text{yC-POC}_{i}(y)\geq\delta_{C}(z_{i}),\]

_if \(Y\) is nonnegative. Further, if \(Z_{i}\) is binary, we have_

\[\min\{\sum_{y\in\mathcal{L}}\text{yM-POC}_{i}(y),|TE_{i}|\}\geq\delta_{M}(z_{ i}),\qquad\min\{\sum_{y\in\mathcal{L}}\text{yC-POC}_{i}(y),|DE_{i}|\}\geq \delta_{C}(z_{i}).\]

The proofs of Thm. 4.6 can be found in App. D, with the lower bound equality holds when an additional monotonicity condition is imposed. We can summarize the findings of Thms. 4.4 and 4.6 in two key aspects. First, the marginal and conditional POCs assess the _likelihood_ of a feature being spurious, while the absolute values of natural causal effects quantify the _size_ of such a spurious effect based on the magnitude of the outcome of interest. Both are lower bounded by the same quantity, that is, the differences in expectations based on the corresponding POC, given non-negative outcomes and binary features. With appropriate data processing, we can transform the outcome to be nonnegative, and thus causal effects become a suitable substitute for POCs. Second, these two approaches exhibit consistency under the monotonicity condition. The natural causal effects of features have explicit forms under parametric models (see details in SS 5.1), such as the linear structural equation model, enabling convenient estimation of the necessity and sufficiency of features from observed data. This section concludes with a toy example illustrating the identification of spurious features through the proposed causal effects and the distinction between total and direct causal effects.

**Example 4.7**.: _(Recall: Beer and Diaper) Given the causal graph in Fig. 1(left), consider a linear SCM for the customer being a new father or not (\(X_{F}\)), diaper purchasing (\(X_{D}\)), and beer purchasing (\(X_{B}\)): \(X_{D}=X_{F}+e_{D}\) and \(X_{B}=X_{F}+e_{B}\), where \(e_{D}\) and \(e_{B}\) are independent mean zero noises.__Since the true SCM is unknown, fitting a linear model \(X_{B}\sim\omega_{1}X_{F}+\omega_{2}X_{D}\) would result in ambiguous coefficients \(\omega_{1},\omega_{2}\in[0,1]\) with \(\omega_{1}+\omega_{2}=1\). By fitting \(X_{D}\sim cX_{F}\) and obtaining \(c\) close to 1, we have the estimated causal graph as \(X_{F}\xrightarrow{\omega_{1}}X_{B}\), and \(X_{F}\xrightarrow{c}X_{D}\xrightarrow{\omega_{2}}X_{B}\). Based on Def. 4.5, we estimate the corresponding causal effects in Table 1. It can be observed that the total effect of \(X_{F}\) on \(X_{B}\) surpasses the total effect from \(X_{D}\), indicating the spurious nature of the diaper purchasing, which should be removed to form the desired NSCG. Yet, using the direct effect may not be able to distinguish their differences due to the high correlation between \(X_{F}\) and \(X_{D}\) if \(\omega_{1}<\omega_{2}\)._

## 5 Necessary and Sufficient Causal Structural Learning

In this section, we formally present how to learn NSCG. Based on Thms. 4.4 and 4.6, a simple solution is to first use a pre-screening process to find necessary and sufficient features from \(\bm{Z}\) that achieve high scores of causation, and then estimate the causal graph among the selected nodes and \(Y\) to approximate \(\mathcal{G}_{\bm{V}}\). This approach works for general SCMs while may suffer from overfitting. Instead of using such a two-step learning, we propose to learn necessary and sufficient features and the causal graph simultaneously through a single-step optimization. To this end, in SS 5.1, we first introduce the structural equation model in order to provide the closed-form expressions of the proposed causal quantities. The main algorithm based on causal effects is presented in SS 5.2 for the _linear_ model, with the POC-based version available in App. B for the _nonlinear_ model.

### Structural Equation Model and Close Form of Causal Effects

**Structural equation model.** We define a selection function \(g\) that maps the feature set \(\bm{Z}\) to a subset, aiming to maintain good interpretability. That is, \(g:\bm{Z}\in\mathbb{R}^{p}\to g(\bm{Z})\in\mathbb{R}^{d}\) where \(d\ll p\), and we denote the \(i\)-th dimension of \(g(\bm{Z})\) as \(g_{i}(\bm{Z})\). Following the causal structure learning literature [35; 25; 46; 44; 48; 5], we assume the Markov and faithfulness conditions and consider a linear structural equation model (LSEM) such that \(\{g(\bm{Z}),Y\}\) is characterized by the pair (\(\bm{B},\bm{\epsilon}\)) as

\[\begin{bmatrix}g(\bm{Z})\\ Y\end{bmatrix}\leftarrow\bm{B}\begin{bmatrix}g(\bm{Z})\\ Y\end{bmatrix}+\bm{\epsilon}\equiv\begin{bmatrix}\bm{B}_{g}&0\\ \bm{\theta}&0\end{bmatrix}\begin{bmatrix}g(\bm{Z})\\ Y\end{bmatrix}+\begin{bmatrix}\bm{\epsilon}_{\bm{Z}}\\ \epsilon_{Y}\end{bmatrix},\] (1)

where \(\bm{B}\) is a \((d+1)\times(d+1)\) weighted adjacent matrix that characterizes the causal relationship among \(\{g(\bm{Z}),Y\}\), and \(\bm{\epsilon}\equiv[\bm{\epsilon}_{\bm{Z}}^{\top},\epsilon_{Y}]^{\top}\) is a \(d+1\) dimensional random vector of jointly independent errors. Here, \(\bm{B}\) consists of three components: (1). a \(d\times d\) matrix \(\bm{B}_{g}=\{b_{i,j}\}_{1\leq i\leq d,1\leq j\leq d}\) with \(b_{i,j}\) as the weight of the edge \(g_{i}(\bm{Z}_{i})\to g_{j}(\bm{Z}_{i})\) if exists and \(b_{i,j}=0\) otherwise; (2) a \(1\times d\) vector \(\bm{\theta}=[\theta_{1},\cdots,\theta_{p}]\) for \(\theta_{i}\) presenting the weight of the direct edge \(g_{i}(\bm{Z})\to Y\); and (3). a \((d+1)\times 1\) zero vector indicating the outcome of interest \(Y\) cannot be any part of the features. Without further assumptions, the model in (1) given a particular selector \(g\) can be identified only up to a Markov equivalence class (MEC) [35; 25]. In the following, we focus on cases where the DAG can be uniquely identifiable, such as LSEM with Gaussian noises of equal variance [35; 26; 24], and linear model with non-Gaussian noise [34; 47]. See more details and extensions to MEC in App. C.1.

**Close form and estimation of causal effects.** We next provide the close forms of the causal effects in Def. 4.5 under the model in (1). Recall that \(\theta_{i}\) presents the weight of the direct edge \(g(\bm{Z})_{i}\to Y\). According to (1) and Def. 4.5, we have

\[DE_{i}(\bm{B};g)=\theta_{i}.\]

The total causal effect can be quantified by the path method [see e.g., 43; 20]. Specifically, the causal effect of \(g_{i}(\bm{Z})\) on \(g_{j}(\bm{Z})\) along a directed path from \(g_{i}(\bm{Z})\to g_{j}(\bm{Z})\) in \(\mathcal{G}\) can be calculated by multiplying all edge weights along the path, under LSEM. Denote the set of directed paths that starts with \(g_{i}(\bm{Z})\) and ends with \(Y\) as \(\pi_{i}=\{g_{i}(\bm{Z})\rightarrow\cdots\to Y\}\) with the size as \(m_{i}\). Then the causal effect of \(g_{i}(\bm{Z})\) on \(Y\) through the directed path \(\pi_{i}^{(k)}=\{i,l_{1},\cdots,l_{\tau_{k}},d+1\}\in\pi_{i}\) with length \(\tau_{k}+1\) is \(PE\{\pi_{i}^{(k)}\}=b_{i,l_{1}}\cdots b_{l_{\tau_{k}},(d+1)}\), by the path method, where \(b_{i,j}\) is the weight of the edge \(g_{i}(\bm{Z})\to g_{j}(\bm{Z})\) if it exists, and \(b_{i,j}=0\) otherwise, for \(i,j\in\{1,\cdots,d\}\), and \(b_{l_{\tau_{k}},(d+1)}=\theta_{l_{\tau_{k}}}\) as the direct edge from \(g_{l_{\tau_{k}}}(\bm{Z})\) to \(Y\). Thus,

\[TE_{i}(\bm{B};g)=\sum_{k=1}^{m_{i}}PE\{\pi_{i}^{(k)}\}.\]

Both \(TE_{i}\) and \(DE_{i}\) can be explicitly calculated given a matrix \(\bm{B}\) under a selector \(g\). We denote their estimates as \(\widetilde{TE}_{i}\) and \(\widetilde{DE}_{i}\) given the estimated matrix \(\widehat{\bm{B}}\) and \(g\).

### Learning Algorithm based on Causal Effects

The primary algorithm based on causal effects comprises three steps that quantify two sources of loss and learn the causal graph, specifically: loss of causal structural learning, loss of discovering causal features, and minimizing the overall loss to learn NSCG based on data \(\{\boldsymbol{o}^{(j)}=(\boldsymbol{z}^{(j)},y^{(j)})\}_{1\leq j\leq n}\).

**Step 1: Form the loss from causal structural learning.** To estimate the matrix \(\boldsymbol{B}\) in (1), we adopt the acyclicity constraint [44; 46] as \(h_{1}(\boldsymbol{B})\equiv\text{tr}[(I_{d+1}+t\boldsymbol{B}\circ\boldsymbol {B})^{d+1}]-(d+1)=0,\) where \(I_{d+1}\) is a \(d+1\)-dimensional identity matrix, and \(\text{tr}(\cdot)\) is the trace of a matrix and \(t\) is a hyperparameter that depends on the estimated largest eigenvalue of \(\boldsymbol{B}\). The first loss by the augmented Lagrangian is

\[L_{1}(\boldsymbol{B},g,\theta,\lambda_{1}|\{\boldsymbol{o}^{(j)}\})=f( \boldsymbol{B},g,\theta|\{\boldsymbol{o}^{(j)}\})+\lambda_{1}h_{1}( \boldsymbol{B}),\] (2)

where \(f(\boldsymbol{B},g,\theta|\{\boldsymbol{o}^{(j)}\})\) is some loss such as the least square error in NOTEARS [46] or the Kullback-Leibler divergence in DAG-GNN [44] with parameters \(\theta\), and \(\lambda_{1}\) is the Lagrange multiplier. Other causal structural leaning algorithms [see e.g., 35; 7; 34; 14; 4; 27; 48] can also be applied by formulating the corresponding score or loss function.

**Step 2: Constraints for causal relevance and causal identifiability.** We next measure the causal relevance of the selection function \(g\) by the natural causal effects. We convert the outcome \(Y\) to be nonnegative. According to Thm. 4.6, we can avoid the estimation of POCs by using the related causal effects in Def. 4.5 with their explicit expressions. This part of loss thus becomes

\[L_{2}^{CE}(\boldsymbol{B},g,\gamma|\{\boldsymbol{o}^{(j)}\})=-\sum_{i=1}^{d}| \widehat{CE}_{i}(\boldsymbol{B};g)|+\sum_{i=1}^{d+1}|b_{i,d+1}|+\gamma|g|.\] (3)

Here, \(\widehat{CE}_{i}\) can either take the estimated \(DE_{i}\) or the estimated \(TE_{i}\) given the matrix \(\boldsymbol{B}\) and \(g\), as detailed in SS 5.1. The second term corresponds to the causal identification constraint on the last column of \(\boldsymbol{B}\), requiring all elements to be zeros as in (1). This constraint restricts the causal structural learning to a smaller class of DAGs. Finally, \(|g|\) denotes the number of selected nodes in \(g\), with a penalty \(\gamma\) to control the complexity of the selector.

**Step 3: Necessary and sufficient causal structural learning.** Combining two sources of loss functions in (2) with (3), leads to the objective as

\[\min_{\boldsymbol{B},g}\left[L_{1}(\boldsymbol{B},g,\theta,\lambda_{1}|\{ \boldsymbol{o}^{(j)}\})+\alpha L_{2}^{CE}(\boldsymbol{B},g,\gamma|\{\boldsymbol {o}^{(j)}\})\right],\] (4)

where \(\alpha\) can be reviewed as a trade-off parameter between two loss functions. Next, we provide a solution for (4) _without_ tuning \(\alpha\). Specifically, based on no unmeasured confounders in (A2), we can calculate the highest causal effects that could be achieved given all variables without any penalty. Denote the estimated highest absolute causal effects in data as \(\delta^{*}\). The goal is to find a subset of \(\boldsymbol{Z}\) such that \(g(\boldsymbol{Z})\) achieves a similar level of necessity and sufficiency, i.e., the resulting score is close to \(\delta^{*}\). Hence, we set the second loss as a constraint by comparing the overall causal effects of the selected nodes with the highest reference over the entire observed feature space, i.e.,

\[h_{2}(\boldsymbol{B};g)=\delta^{*}-\sum_{i=1}^{d}|\widehat{CE}_{i}(\boldsymbol {B};g)|+\sum_{i=1}^{d+1}|b_{i,d+1}|,\]

should be approaching 0 given a good selector \(g\). This yields a new objective function as

\[\min_{\boldsymbol{B},g}f(\boldsymbol{B},g,\theta|\{\boldsymbol{o}^{(j)}\})+ \lambda_{1}h_{1}(\boldsymbol{B})+\lambda_{2}h_{2}(\boldsymbol{B};g)+c|h_{1}( \boldsymbol{B})|^{2}+d|h_{2}(\boldsymbol{B};g)|^{2}+\gamma|g|,\] (5)

where \(\lambda_{2}\) is the Lagrange multiplier for the new constraint, and \(c\) and \(d\) are penalty terms. To minimize the loss in (5) and satisfy both \(h_{1}(B)\to 0\) and \(h_{2}(\boldsymbol{B};g)\to 0\), we simultaneously update \(\lambda_{1}\) and \(\lambda_{2}\) and increase \(c\) and \(d\) to infinity, by modifying the updating technique [see e.g., 46; 44] for multiple constraints, with the class of functions \(g\) specified as the subset of \(\boldsymbol{Z}\) and its penalty \(\gamma\) as the size of selected nodes in \(g\). Here, the minimization can be solved using a black-box stochastic optimization such as 'Adam' [15]. Denote the estimated matrix as \(\widehat{\boldsymbol{B}}\), based on which we can obtain the estimated causal graph as \(\widehat{\mathcal{G}}_{V}\) consisting of nodes \(\widehat{g}(\boldsymbol{Z})\). Finally, we name this proposed algorithm as necessary and sufficient causal structural learning (NSCSL). The computational complexity of NSCSL is provided in App. B.3. We next establish the consistency of estimated causal graphs below.

**Theorem 5.1**.: _Assume Model (1) holds with independent Gaussian error and equal variance. Suppose the topological ordering of the true bounded matrix \(\boldsymbol{B}\) is consistently estimated. Then the estimated matrix \(\widehat{\boldsymbol{B}}\) minimizing the loss in (5) converges to \(\boldsymbol{B}\) with the probability going to 1 as \(n\rightarrow\infty\)._The proof and detailed conditions for Thm. 5.1 are provided in App. D, which align with those commonly imposed in causal structural learning (e.g., [33]). Our proof follows similar strategies but accounts for the extra penalty term from causal effects. Notice that the explicit forms of causal effects under LSEM are linear combinations of elements of \(\bm{B}\). This implies our new regulation can similarly vanish away as \(n\) goes to infinity.

## 6 Experiments

**Experiment design.** Scenarios are generated as follows. We consider the dimension of variables in the graph as \(p=5\) in Scenarios 1 to 3 (S1 to S3), \(p=20\) in Scenario 4 (S4), and \(p=50\) in Scenario 5 (S5), to examine the scalability of NSCSL. For each scenario, the DAG that characterizes the causal relationship among variables \(\bm{\hat{O}}=(\bm{Z},Y)\) is generated from the Erdos-Renyi (ER) model with an expected degree as 2 for S1 to S3 and degree as 5 for S4 to S5. We also generate the graph from the scale-free (SF) model for S5 with the degree of 5 to examine the robustness of the proposed method under diverse synthetic graphs. Each edge is assigned positive weights. We set the last variable as the outcome of interest \(Y\), and generate the data based on LSEM by \(\bm{Z}=\bm{B}^{\top}\bm{Z}+\bm{\epsilon}\), where \(\bm{\epsilon}\) is a random vector of jointly independent binary variables with equal probability taking value one or zero. Thus, the outcome is nonnegative and discrete. In addition, we also include a nonlinear structural equation model for S4 where \(O_{i}:=\psi_{i}\{\text{PA}_{O_{i}}(\mathcal{G})\}+e_{O_{i}}\) and \(\psi_{i}(x)=\lfloor 2\log(x+1)\rceil\) where \(\lfloor x\rceil\) rounds to nearest integer for \(x\). In S1, the true causal graph contains one spurious node (indexed by 0) and three non-spurious nodes (indexed by 1, 2, and 3), as shown in sub-figures (a) of Fig. E.7, with the associated true NSCG in sub-figures (b) of Fig. E.7. Moreover, we design a balanced setting with half spurious variables and half non-spurious variables in S2, as depicted in Fig. E.8, and a baseline setting without any spurious variables in S3, shown in Fig. E.9. Finally, S4 contains 2 non-spurious variables with 17 spurious variables in Fig. E.10. The experiments are conducted on a Google Cloud Platform virtual machine with 8 processor cores and 32GB memory.

**Methods and benchmark specification.** We apply the proposed NSCSL based on TE and DE as the criteria of necessity and sufficiency, respectively, to capture the marginal and conditional causal effect of the confounders. Note that we consider fully identifiable models in the experiments so that it is meaningful to evaluate causal effects from the estimated graph. The underlying causal structure learning algorithm is set to NOTEARS [46]. We also compare the proposed method against other methods, including PC [35] and LiNGAM [34] for S1 to S5; DAG-GNN [44], GES with generalized score [GSGES, 11], fast causal inference [FCI, 36], and the causal additive model [CAM, 4], for all high-dimensional settings in S4 and S5. Here, we use a graph threshold of 0.3 (commonly used in the literature [46; 44; 48; 5]) to prune the noise edges for a fair comparison. The training details are provided in Table E.1. The true and estimated graphs with the associated matrix under different approaches are illustrated in Figs. E.2 to E.6 and Figs. E.7 to E.11 in App. E for S1 to S4. The comparison results across different sample sizes (\(n\)) are presented in Table 2 for S1 to S3, in Table 3 for S4 to S5 with linear ER model, in Table 4 for S4 with nonlinear ER model, and in Table 5 for S5 with linear SF model. All the results are evaluated by false discovery rate (FDR), true positive

\begin{table}
\begin{tabular}{l l l l l l l l l} \hline \hline  & & \multicolumn{3}{c}{FDR\(\pm\)SE} & \multicolumn{3}{c}{TPR\(\pm\)SE} & \multicolumn{3}{c}{SHD\(\pm\)SE} \\ Scenario & Method & \(n_{1}\) (small) & \(n_{2}\) (large) & \(n_{1}\) (small) & \(n_{2}\) (large) & \(n_{1}\) (small) & \(n_{2}\) (large) & \(n_{1}\) (small) & \(n_{2}\) (large) \\ \hline S1 & NSCSL-TE & 0.09\(\pm\)0.03 & 0.02\(\pm\)0.01 & 0.95\(\pm\)0.02 & 1.00\(\pm\)0.00 & 0.64\(\pm\)0.20 & 0.14\(\pm\)0.06 \\ \(p=5\) & NSCSL-DE & 0.08\(\pm\)0.03 & 0.02\(\pm\)0.01 & 0.95\(\pm\)0.03 & 1.00\(\pm\)0.00 & 0.72\(\pm\)0.20 & 0.14\(\pm\)0.06 \\ \(n_{1}=30\) & NOTEARS & 0.39\(\pm\)0.01 & 0.34\(\pm\)0.00 & 0.96\(\pm\)0.02 & 1.00\(\pm\)0.00 & 2.56\(\pm\)0.14 & 2.02\(\pm\)0.01 \\ \(n_{2}=100\) & PC & 0.53\(\pm\)0.02 & 0.53\(\pm\)0.01 & 0.47\(\pm\)0.05 & 0.41\(\pm\)0.01 & 3.12\(\pm\)0.11 & 3.20\(\pm\)0.07 \\ ER Model & LiNGAM & 0.31\(\pm\)0.02 & 0.33\(\pm\)0.00 & 0.78\(\pm\)0.02 & 0.98\(\pm\)0.01 & 2.30\(\pm\)0.10 & 2.00\(\pm\)0.00 \\ \hline S2 & NSCSL-TE & 0.10\(\pm\)0.03 & 0.02\(\pm\)0.01 & 1.00\(\pm\)0.00 & 0.99\(\pm\)0.01 & 0.38\(\pm\)0.14 & 0.12\(\pm\)0.06 \\ \(p=5\) & NSCSL-DE & 0.12\(\pm\)0.04 & 0.01\(\pm\)0.01 & 0.67\(\pm\)0.04 & 0.50\(\pm\)0.00 & 1.00\(\pm\)0.12 & 1.02\(\pm\)0.01 \\ \(n_{1}=30\) & NOTEARS & 0.63\(\pm\)0.01 & 0.60\(\pm\)0.00 & 1.00\(\pm\)0.00 & 1.00\(\pm\)0.00 & 3.46\(\pm\)0.13 & 3.02\(\pm\)0.01 \\ \(n_{2}=100\) & PC & 0.73\(\pm\)0.02 & 0.79\(\pm\)0.00 & 0.50\(\pm\)0.00 & 0.50\(\pm\)0.00 & 3.62\(\pm\)0.15 & 3.88\(\pm\)0.03 \\ ER Model & LiNGAM & 0.62\(\pm\)0.01 & 0.60\(\pm\)0.00 & 0.98\(\pm\)0.02 & 1.00\(\pm\)0.00 & 3.18\(\pm\)0.09 & 3.00\(\pm\)0.00 \\ \hline S3 & NSCSL-TE & 0.10\(\pm\)0.02 & 0.01\(\pm\)0.00 & 0.94\(\pm\)0.02 & 1.00\(\pm\)0.00 & 0.84\(\pm\)0.16 & 0.06\(\pm\)0.02 \\ \(p=5\) & NSCSL-DE & 0.08\(\pm\)0.02 & 0.01\(\pm\)0.00 & 0.84\(\pm\)0.03 & 0.81\(\pm\)0.00 & 1.30\(\pm\)0.14 & 1.00\(\pm\)0.00 \\ \(n_{1}=30\) & NOTEARS & 0.11\(\pm\)0.02 & 0.01\(\pm\)0.00 & 0.96\(\pm\)0.02 & 1.00\(\pm\)0.00 & 0.76\(\pm\)0.16 & 0.06\(\pm\)0.02 \\ \(n_{2}=100\) & PC & 0.00\(\pm\)0.00 & 0.00\(\pm\)0.00 & 0.66\(\pm\)0.02 & 0.80\(\pm\)0.00 & 1.68\(\pm\)0.12 & 1.00\(\pm\)0.00 \\ ER Model & LiNGAM & 0.03\(\pm\)0.01 & 0.00\(\pm\)0.00 & 0.98\(\pm\)0.01 & 1.00\(\pm\)0.00 & 0.24\(\pm\)0.09 & 0.02\(\pm\)0.01 \\ \hline \hline \end{tabular}
\end{table}
Table 2: Comparison results across S1 to S3 under different sample sizes (\(n\)). Methods are evaluated by FDR, TPR, and SHD, with the standard error (SE) reported for each metric, over 50 replications.

rate (TPR), and the structural Hamming distance (SHD) to the true causal graph, with their standard errors, over 50 replications. The average running time of these methods is also reported in Table 2 to Table 5 to reflect the computational complexities. In addition, the sensitivity analyses concerning all hyperparameters in Table E.1 are conducted using S4, as presented in Fig. 2.

**Results and conclusion.** NSCSL performs the best in discovering NSCG in S1, S2, S4, and S5, and shows comparably best results in S3 (a setting without any spurious variables). To be specific, the benchmark methods for causal structural learning aim to reveal causal relationships in the whole graph (i.e., sub-figures (a) in Figs. E.2 to E.6), which contains spurious effects on the target outcome \(\hat{Y}\). The proposed algorithm overcomes this drawback by purely identifying the true important causal relationships (i.e., sub-figures (b) in Figs. E.2 to E.6). By comparing the sub-figures (c) and (d) in Figs. E.2 to E.6 as well as Table 5, NSCSL-TE detects all necessary and sufficient causal paths towards the outcome, while NSCSL-DE only extracts direct causal relationships between the features and the outcome, resulting in a slightly lower TPR and slightly higher SHD than NSCSL-TE. Furthermore, from Table 2 to Table 5, the results under the proposed algorithm approach the truth more closely as the sample size increases in all scenarios, regardless of the underlying graph models and data-generating process. In contrast, the benchmark methods all fail to discover NSCG in the high-dimensional setting, exhibiting extremely high FDRs and SHDs. In addition, Table 3 to Table 5 reveal that NSCSL is as fast as the quickest benchmarks such as PC, LiNGAM, and FCI, and significantly faster than others like DAGGNN, GSGES, and CAM. Our method's integration of treatment effects into the optimization adds efficiency and restricts the searching space, making it practical and even beating NOTEARS in computation. The sensitivity analyses in Fig. 2 indicate that our method remains robust to these parameters set within a reasonable range.

**Real data analysis - Sachs et al. [30].** We conduct real data analysis using the benchmark data from Sachs et al. [30]. To validate our method's capacity to find the NSCG and align with Def. 3.2, we designated the protein Akt as the target outcome. This designation ensures that NSCG exists (see Fig. 3) and that finding an NSCG is meaningful. Our method (NSCSL-TE) and seven baseline methods were applied and evaluated against the true NSCG associated with the protein Akt. Table 6 shows that our method achieves the best performance in finding the NSCG concerning the protein Akt.

**Real data analysis - Brem & Kruglyak [2].** Furthermore, we apply NSCSL to gene expression traits in yeast [2] using a dataset of 104 yeast segregants with diverse genotypes. The goal is to identify genes, known as quantitative trait loci (QTLs), influencing the expression level (nonnegative) of the genetic variant YER124C, a daughter cell-specific protein involved in cell wall metabolism. Following a similar approach as in Chakraborty et al. [6], we include 492 QTLs by filtering out genes with missing or low variability in expression levels. The total sample size is 262. Given the high-dimensional QTLs, constructing an NSCG with only causally relevant variables for the outcome of interest is essential. We apply NSCSL-TE and compare it with all baseline methods. The summarized results in Table 7 highlight our method's ability to identify relevant genetic influencers

\begin{table}
\begin{tabular}{l l l l l l l l l l} \hline \hline  & & \multicolumn{2}{c}{FDR\(\pm\)SE} & \multicolumn{2}{c}{TPR\(\pm\)SE} & \multicolumn{2}{c}{SHD\(\pm\)SE} & \multicolumn{2}{c}{Time\(\pm\)SE} \\ Scenario & Method & \(n_{1}\) (small) & \(n_{2}\) (large) & \(n_{1}\) (small) & \(n_{2}\) (large) & \(n_{1}\) (small) & \(n_{2}\) (large) & \(n_{1}\) (small) & \(n_{1}\) (small) & \(n_{2}\) (large) \\ \hline S4 & NSCSL-TE & 0.11\(\pm\)0.02 & 0.00\(\pm\)0.01 & 1.00\(\pm\)0.00 & 1.00\(\pm\)0.00 & 3.66\(\pm\)0.24 & 0.40\(\pm\)0.01 & 10.8\(\pm\)0.3 & 56.2\(\pm\)1.1 \\ \(p=20\) & NSCSL-DE & 0.11\(\pm\)0.02 & 0.00\(\pm\)0.01 & 0.69\(\pm\)0.01 & 0.67\(\pm\)0.00 & 1.34\(\pm\)0.08 & 1.00\(\pm\)0.01 & 12.4\(\pm\)0.8 & 54.5\(\pm\)1.3 \\ \(n_{1}=100\) & NOTEARS & 0.93\(\pm\)0.00 & 0.92\(\pm\)0.00 & 1.00\(\pm\)0.00 & 1.00\(\pm\)0.00 & 40.80\(\pm\)0.20 & 36.40\(\pm\)0.04 & 22.9\(\pm\)6.4 & 69.8\(\pm\)8.7 \\ \(n_{2}=100\) & PC & 0.92\(\pm\)0.00 & 0.95\(\pm\)0.00 & 0.51\(\pm\)0.02 & 0.67\(\pm\)0.00 & 19.08\(\pm\)0.17 & 33.4\(\pm\)0.03 & 6.9\(\pm\)0.5 & 16.3\(\pm\)0.8 \\ ER Model & LiNGAM & 0.92\(\pm\)0.00 & 0.93\(\pm\)0.00 & 0.99\(\pm\)0.00 & 0.99\(\pm\)0.01 & 1.00\(\pm\)0.00 & 33.00\(\pm\)0.20 & 3.71\(\pm\)0.02 & 8.1\(\pm\)0.5 & 24.6\(\pm\)4.6 \\ Degree-5 & DAGGNN & 0.93\(\pm\)0.00 & 0.93\(\pm\)0.00 & 0.97\(\pm\)0.01 & 0.97\(\pm\)0.00 & 41.34\(\pm\)0.19 & 40.10\(\pm\)0.06 & 28.3\(\pm\)2.4 & 39.1\({}^{2}\)\(\pm\)7.2 \\  & GSGES & 0.98\(\pm\)0.01 & 0.98\(\pm\)0.00 & 0.22\(\pm\)0.02 & 0.20\(\pm\)0.01 & 43.20\(\pm\)0.26 & 45.70\(\pm\)0.34 & 39.4\({}^{2}\)\(\pm\)7.5 & 26.3\({}^{2}\)\(\pm\)9.1 \\  & FCI & 0.98\(\pm\)0.01 & 0.99\(\pm\)0.00 & 0.10\(\pm\)0.01 & 0.67\(\pm\)0.00 & 27.20\(\pm\)0.17 & 32.9\(\pm\)0.02 & 6.6\(\pm\)0.3 & 12.7\(\pm\)0.2 \\  & CAM & 0.93\(\pm\)0.00 & 0.94\(\pm\)0.00 & 0.63\(\pm\)0.02 & 1.00\(\pm\)0.00 & 29.80\(\pm\)0.38 & 43.0\(\pm\)0.07 & 19.6\({}^{2}\)\(\pm\)18.3 & 25.6\({}^{2}\)\(\pm\)23.2 \\ \hline S5 & NSCSL-TE & 0.03\(\pm\)0.01 & 0.02\(\pm\)0.01 & 0.86\(\pm\)0.03 & 0.93\(\pm\)0.01 & 2.18\(\pm\)0.13 & 1.58\(\pm\)0.07 & 11.1\(\pm\)3.9 & 21.1\({}^{2}\)\(\pm\)1.2 \\ \(p=50\) & NSCSL-DE & 0.02\(\pm\)0.02 & 0.01\(\pm\)0.01 & 0.29\(\pm\)0.02 & 0.28\(\pm\)0.01 & 10.08\(\pm\)0.21 & 9.66\(\pm\)0.13 & 11.9\(\pm\)0.5 & 25.3\({}^{2}\)\(\pm\)10.9 \\ \(n_{1}=1000\) & NOTEARS & 0.86\(\pm\)0.04 & 0.85\(\pm\)0.01 & 0.93\(\pm\)0.03 & 0.92\(\pm\)0.17 & 7.20\(\pm\)1.40 & 7.71\(\pm\)0.53 & 128.3\(\pm\)3.8 & 26.2 & 9.6\({}^{2}\)\(\pm\)15.1 \\ \(n_{2}=3000\) & PC & 0.96\(\pm\)0.03 & 0.97\(\pm\)0.02 & 0.07\(\pm\)0.02 & 0.06\(\pm\)0.01 & 82.12\(\pm\)1.21 & 82.88\(\pm\)1.63 & 20.9\(\pm\)0.5 & 35.9\(\pm\)3.2 \\ Eff Model & LiNGAM & 0.86\(\pm\)0.02 & 0.86\(\pm\)0.01 & 0.97\(\pm\)0.02 & 0.99\(\pm\)0.01 & 86.12\(\pm\)1.20 & 85.70\(\pm\)0.84 & 43.1\({}^{2}\)\(\pm\)6.3 & 14.5\(\pm\)37.9 \\  & DAGGNN & 0.87\(\pm\)0.02 & 0.88\(\pm\)0.01 & 0.93\(\pm\)0.02 & 0.94\(\pm\)0.01 & 87.50\(\pm\)1.10 & 85.62\(\pm\)0.96 & 49.3\({}^{2}\)\(\pm\)7.5 & 81.1\({}^{2}\)\(\pm\)87.6 \\  & GSGES & 0.89\(\pm\)0.03 & 0.93\(\pm\)0.01 & 0.19\(\pm\)0.03 & 0.12\(\pm\)0.01 & 93.54\(\pm\)1.46 &for the variant YER124C without contamination by irrelevant genes. The estimated causal graph and causal effects as well as more detailed analyses are provided in App. E.2. These observations align with findings from our simulation studies, further supporting NSCSL's superiority in revealing important causal features.

## 7 Limitations and Future Research

In this work, we introduced NSCSL that leverages causal effects/POCs to systematically assess feature importance while learning a causal graph. By identifying a subgraph closely related to the outcome, our method filters irrelevant variables, presenting a significant advancement in the field. Extensive empirical evaluations on simulated and real-world data underscore NSCSL's superior performance over existing algorithms, including important findings on yeast genes and the protein signaling network. However, this promising advancement is not without limitations. First, NSCSL, like most existing causal structural learning methods, assumes no unmeasured confounders (A2) and the causal Markov condition. These assumptions may not hold in practice, leading to biased causal effect estimates and potential errors in the causal graph. Second, NSCSL employs absolute causal effects as a substitute for POCs to facilitate estimation in high-dimensional settings. Although theoretically consistent under certain conditions, examining the differences between these two methods in general feature and outcome spaces is an area for future research.

\begin{table}
\begin{tabular}{l l l l l l l l} \hline \hline Scenario & Method & FDR\(\pm\)SE & TPR\(\pm\)SE & SHD\(\pm\)SE & Time\(\pm\)SE \\ \hline S5 & NSCSL-TE & 0.02\(\pm\)0.02 & 0.78\(\pm\)0.03 & 5.08\(\pm\)0.11 & 135.7\(\pm\)5.6 \\ \(p=50\) & NSCSL-DE & 0.02\(\pm\)0.02 & 0.51\(\pm\)0.02 & 17.20\(\pm\)0.35 & 147.0\(\pm\)6.3 \\ \(n=1000\) & NOTEARS & 0.88\(\pm\)0.04 & 0.75\(\pm\)0.03 & 123.10\(\pm\)1.50 & 160.5\(\pm\)8.1 \\ SF Model & PC & 0.97\(\pm\)0.03 & 0.06\(\pm\)0.02 & 79.34\(\pm\)1.17 & 321.20\(\pm\)0.8 \\ Degree=5 & LiNGAM & 0.91\(\pm\)0.02 & 0.98\(\pm\)0.01 & 212.00\(\pm\)5.12 & 117.7\(\pm\)6.3 \\  & DAGGNN & 0.92\(\pm\)0.02 & 0.85\(\pm\)0.02 & 203.50\(\pm\)7.80 & 57.3\(\pm\)13.6 \\  & GSGES & 0.96\(\pm\)0.03 & 0.10\(\pm\)0.03 & 98.34\(\pm\)2.15 & 35.9\(\pm\)13.5 \\  & FCI & 0.97\(\pm\)0.02 & 0.07\(\pm\)0.01 & 81.70\(\pm\)1.40 & 15.7\(\pm\)1.1 \\  & CAM & 0.98\(\pm\)0.04 & 0.24\(\pm\)0.03 & 218.00\(\pm\)8.15 & 37.1\({}^{\pm}\)53.6 \\ \hline \hline \end{tabular}
\end{table}
Table 6: Real data results for the single-cell data by Sachs et al. [30], evaluated by total edges, correct edges, and SHD, based on the true NSCG with respect to the protein Akt.

\begin{table}
\begin{tabular}{l l l l l l l l} \hline \hline Scenario & Method & FDR\(\pm\)SE & TPR\(\pm\)SE & SHD\(\pm\)SE & Time\(\pm\)SE \\ \hline S4 & NSCSL-TE & 0.03\(\pm\)0.01 & 0.83\(\pm\)0.01 & 0.60\(\pm\)0.02 & 55.8\(\pm\)0.3 \\ \(p=20\) & NSCSL-DE & 0.03\(\pm\)0.01 & 0.50\(\pm\)0.01 & 1.60\(\pm\)0.02 & 56.8\(\pm\)0.2 \\ \(n=1000\) & NOTEARS & 0.91\(\pm\)0.01 & 0.83\(\pm\)0.01 & 35.90\(\pm\)0.04 & 56.5\(\pm\)0.7 \\ ER Model & PC & 0.99\(\pm\)0.01 & 0.12\(\pm\)0.01 & 44.12\(\pm\)0.03 & 15.7\(\pm\)0.2 \\ Degree=5 & LiNGAM & 0.93\(\pm\)0.01 & 0.70\(\pm\)0.00 & 37.30\(\pm\)0.03 & 11.6\(\pm\)0.1 \\  & DAGGNN & 0.94\(\pm\)0.01 & 0.86\(\pm\)0.01 & 34.80\(\pm\)0.06 & 41.3\({}^{\pm}\)9.8 \\  & GSGES & 0.98\(\pm\)0.01 & 0.23\(\pm\)0.01 & 52.40\(\pm\)0.38 & 22.1\(\pm\)7.5 \\  & FCI & 0.97\(\pm\)0.01 & 0.13\(\pm\)0.01 & 33.80\(\pm\)0.06 & 12.6\(\pm\)0.3 \\  & CAM & 0.95\(\pm\)0.01 & 1.00\(\pm\)0.01 & 31.60\(\pm\)0.08 & 27.9\({}^{\pm}\)33.7 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Comparison studies under the nonlinear structural equation model for S4 over 50 replications.

\begin{table}
\begin{tabular}{l l l l l l l l l} \hline \hline Method & NSCSL & NOTEARS & PC & LinNGAM & DAGGNN & GSGES & FCI & CAM \\ \hline Total Edges & 8 & 20 & 25 & 6 & 33 & 28 & 24 & 7 \\ Correct Edges & 4 & 2 & 2 & 1 & 4 & 2 & 2 & 1 \\ SHD & 8 & 21 & 28 & 11 & 30 & 32 & 27 & 10 \\ \hline \hline \end{tabular}
\end{table}
Table 7: Real data results for the yeast gene data, evaluated by total edges, the identified parents/ancestors of the variant YER124C, and the edges towards YER124C.

Figure 3: The causal signaling network in Sachs et al. [30], where the blue-colored sub-graph is the true NSCG for protein Akt (purple).

Figure 2: Sensitivity analyses.

## Acknowledgments and Disclosure of Funding

Research reported in this publication was supported in part by the Amazon Web Services (AWS) Cloud Research program, the Office of Naval Research under grant N00014-23-1-2590, and the National Science Foundation under grant No. 2231174 and No. 2310831. The authors thank the area chair and the reviewers for their constructive comments which have led to a significant improvement of the earlier version of this article.

## References

* [1] Aliferis, C. F., Statnikov, A., Tsamardinos, I., Mani, S., and Koutsoukos, X. D. Local causal and markov blanket induction for causal discovery and feature selection for classification part i: algorithms and empirical evaluation. _Journal of Machine Learning Research_, 11(1), 2010.
* [2] Brem, R. B. and Kruglyak, L. The landscape of genetic complexity across 5,700 gene expression traits in yeast. _Proceedings of the National Academy of Sciences_, 102(5):1572-1577, 2005.
* [3] Brzywczyk, J. and Paszewski, A. Role of o-acetylhomoserine sulfhydrylylase in sulfur amino acid synthesis in various yeasts. _Yeast_, 9(12):1335-1342, 1993.
* [4] Buhlmann, P., Peters, J., Ernest, J., et al. Cam: Causal additive models, high-dimensional order search and penalized regression. _The Annals of Statistics_, 42(6):2526-2556, 2014.
* [5] Cai, H., Song, R., and Lu, W. Anoce: Analysis of causal effects with multiple mediators via constrained structural learning. In _International Conference on Learning Representations_, 2020.
* [6] Chakraborty, A., Nandy, P., and Li, H. Inference for individual mediation effects and interventional effects in sparse high-dimensional causal graphical models. _arXiv preprint arXiv:1809.10652_, 2018.
* [7] Chickering, D. M. Optimal structure identification with greedy search. _Journal of machine learning research_, 3(Nov):507-554, 2002.
* [8] Colman-Lerner, A., Chin, T. E., and Brent, R. Yeast ckb1 and mob2 activate daughter-specific genetic programs to induce asymmetric cell fates. _Cell_, 107(6):739-750, 2001.
* [9] de Melo, A. T., Martho, K. F., Roberto, T. N., Nishiduka, E. S., Machado Jr, J., Brustolini, O. J., Tashima, A. K., Vasconcelos, A. T., Vallim, M. A., and Pascon, R. C. The regulation of the sulfur amino acid biosynthetic pathway in cryptococcus neoformans: the relationship of cys3, calcineurin, and gpp2 phosphatases. _Scientific Reports_, 9(1):11923, 2019.
* [10] Feder, A., Keith, K. A., Manzoor, E., Pryzant, R., Sridhar, D., Wood-Doughty, Z., Eisenstein, J., Grimmer, J., Reichart, R., Roberts, M. E., et al. Causal inference in natural language processing: Estimation, prediction, interpretation and beyond. _arXiv preprint arXiv:2109.00725_, 2021.
* [11] Huang, B., Zhang, K., Lin, Y., Scholkopf, B., and Glymour, C. Generalized score functions for causal discovery. In _Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining_, pp. 1551-1560, 2018.
* [12] Janzing, D., Balduzzi, D., Grosse-Wentrup, M., and Scholkopf, B. Quantifying causal influences. 2013.
* [13] Janzing, D., Minorics, L., and Blobaum, P. Feature relevance quantification in explainable ai: A causal problem. In _International Conference on artificial intelligence and statistics_, pp. 2907-2916. PMLR, 2020.
* [14] Kalisch, M. and Buhlmann, P. Estimating high-dimensional directed acyclic graphs with the pc-algorithm. _Journal of Machine Learning Research_, 8(Mar):613-636, 2007.
* [15] Kingma, D. P. and Ba, J. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_, 2014.
* [16] Kumar, V. and Minz, S. Feature selection: a literature review. _SmartCR_, 4(3):211-229, 2014.

* [17] Lachapelle, S., Brouillard, P., Deleu, T., and Lacoste-Julien, S. Gradient-based neural dag learning. _arXiv preprint arXiv:1906.02226_, 2019.
* [18] Lee, S. and Bareinboim, E. Structural causal bandits: Where to intervene? _Advances in neural information processing systems_, 31, 2018.
* [19] Lee, S. and Bareinboim, E. Characterizing optimal mixed policies: Where to intervene and what to observe. _Advances in neural information processing systems_, 33:8565-8576, 2020.
* [20] Nandy, P., Maathuis, M. H., Richardson, T. S., et al. Estimating the effect of joint interventions from observational data in sparse high-dimensional settings. _The Annals of Statistics_, 45(2):647-674, 2017.
* [21] Niu, Y., Tang, K., Zhang, H., Lu, Z., Hua, X.-S., and Wen, J.-R. Counterfactual vqa: A cause-effect look at language bias. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pp. 12700-12710, 2021.
* [22] Pearl, J. et al. Models, reasoning and inference. _Cambridge, UK: CambridgeUniversityPress_, 19, 2000.
* [23] Pearl, J. et al. Causal inference in statistics: An overview. _Statistics surveys_, 3:96-146, 2009.
* [24] Peters, J. and Buhlmann, P. Identifiability of gaussian structural equation models with equal error variances. _Biometrika_, 101(1):219-228, 2014.
* [25] Peters, J., Mooij, J. M., Janzing, D., and Scholkopf, B. Causal discovery with continuous additive noise models. 2014.
* [26] Peters, J., Janzing, D., and Scholkopf, B. _Elements of causal inference: foundations and learning algorithms_. The MIT Press, 2017.
* [27] Ramsey, J., Glymour, M., Sanchez-Romero, R., and Glymour, C. A million variables and more: the fast greedy equivalence search algorithm for learning high-dimensional graphical causal models, with an application to functional magnetic resonance images. _International journal of data science and analytics_, 3(2):121-129, 2017.
* [28] Rolland, P., Cevher, V., Kleindessner, M., Russell, C., Janzing, D., Scholkopf, B., and Locatello, F. Score matching enables causal discovery of nonlinear additive noise models. In _International Conference on Machine Learning_, pp. 18741-18753. PMLR, 2022.
* [29] Rosenbaum, P. R. and Rubin, D. B. The central role of the propensity score in observational studies for causal effects. _Biometrika_, 70(1):41-55, 1983.
* [30] Sachs, K., Perez, O., Pe'er, D., Lauffenburger, D. A., and Nolan, G. P. Causal protein-signaling networks derived from multiparameter single-cell data. _Science_, 308(5721):523-529, 2005.
* [31] Scholkopf, B., Locatello, F., Bauer, S., Ke, N. R., Kalchbrenner, N., Goyal, A., and Bengio, Y. Toward causal representation learning. _Proceedings of the IEEE_, 109(5):612-634, 2021.
* [32] Shah, R. D. and Peters, J. The hardness of conditional independence testing and the generalised covariance measure. _arXiv preprint arXiv:1804.07203_, 2018.
* [33] Shi, C. and Li, L. Testing mediation effects using logic of boolean matrices. _Journal of the American Statistical Association_, pp. 1-14, 2021.
* [34] Shimizu, S., Hoyer, P. O., Hyvarinen, A., and Kerminen, A. A linear non-gaussian acyclic model for causal discovery. _Journal of Machine Learning Research_, 7(Oct):2003-2030, 2006.
* [35] Spirtes, P., Glymour, C., Scheines, R., Kauffman, S., Aimale, V., and Wimberly, F. Constructing bayesian network models of gene expression networks from microarray data. 2000.
* [36] Spirtes, P. L., Meek, C., and Richardson, T. S. Causal inference in the presence of latent variables and selection bias. _arXiv preprint arXiv:1302.4983_, 2013.

* [37] Takahashi, H., Braby, C. E., and Grossman, A. R. Sulfur economy and cell wall biosynthesis during sulfur limitation of chlamomonas reinhardtii. _Plant physiology_, 127(2):665-673, 2001.
* [38] Tang, K., Huang, J., and Zhang, H. Long-tailed classification by keeping the good and removing the bad momentum causal effect. _arXiv preprint arXiv:2009.12991_, 2020.
* [39] Tian, J. and Pearl, J. Probabilities of causation: Bounds and identification. _Annals of Mathematics and Artificial Intelligence_, 28(1):287-313, 2000.
* [40] Van de Geer, S. and Buhlmann, P. \(\ell_{0}\)-penalized maximum likelihood for sparse directed acyclic graphs. 2013.
* [41] Vowels, M. J., Camgoz, N. C., and Bowden, R. D'ya like dags? a survey on structure learning and causal discovery. _ACM Computing Surveys (CSUR)_, 2021.
* [42] Wang, Y. and Jordan, M. I. Desiderata for representation learning: A causal perspective. _arXiv preprint arXiv:2109.03795_, 2021.
* [43] Wright, S. Correlation and causation. _Journal of agricultural research_, 20(7):557-585, 1921.
* [44] Yu, Y., Chen, J., Gao, T., and Yu, M. Dag-gnn: Dag structure learning with graph neural networks. In _International Conference on Machine Learning_, pp. 7154-7163. PMLR, 2019.
* [45] Zhang, W., Wu, T., Wang, Y., Cai, Y., and Cai, H. Towards trustworthy explanation: On causal rationalization. In _Proceedings of the 40th International Conference on Machine Learning_, volume 202, pp. 41715-41736. PMLR, 2023.
* [46] Zheng, X., Aragam, B., Ravikumar, P. K., and Xing, E. P. Dags with no tears: Continuous optimization for structure learning. In _Advances in Neural Information Processing Systems_, pp. 9472-9483, 2018.
* [47] Zheng, X., Dan, C., Aragam, B., Ravikumar, P., and Xing, E. Learning sparse nonparametric dags. In _International Conference on Artificial Intelligence and Statistics_, pp. 3414-3425. PMLR, 2020.
* [48] Zhu, S., Ng, I., and Chen, Z. Causal discovery with reinforcement learning. In _International Conference on Learning Representations_, 2019.