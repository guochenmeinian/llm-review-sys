# Data Debugging is NP-hard for Classifiers Trained with SGD

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Data debugging is to find a subset of the training data such that the model obtained by retraining on the subset has a better accuracy. A bunch of heuristic approaches are proposed, however, none of them are guaranteed to solve this problem effectively. This leaves an open issue whether there exists an efficient algorithm to find the subset such that the model obtained by retraining on it has a better accuracy. To answer this open question and provide theoretical basis for further study on developing better algorithms for data debugging, we investigate the computational complexity of the problem named Debuggable. Given a machine learning model \(\mathcal{M}\) obtained by training on dataset \(D\) and a test instance \((\mathbf{x}_{\text{test}},y_{\text{test}})\) where \(\mathcal{M}(\mathbf{x}_{\text{test}})\neq y_{\text{test}}\), Debuggable is to determine whether there exists a subset \(D^{\prime}\) of \(D\) such that the model \(\mathcal{M}^{\prime}\) obtained by retraining on \(D^{\prime}\) satisfies \(\mathcal{M}^{\prime}(\mathbf{x}_{\text{test}})=y_{\text{test}}\). To cover a wide range of commonly used models, we take SGD-trained linear classifier as the model and derive the following main results. (1) If the loss function and the dimension of the model are not fixed, Debuggable is NP-complete regardless of the training order in which all the training samples are processed during SGD. (2) For hinge-like loss functions, a comprehensive analysis on the computational complexity of Debuggable is provided; (3) If the loss function is a linear function, Debuggable can be solved in linear time, that is, data debugging can be solved easily in this case. These results not only highlight the limitations of current approaches but also offer new insights into data debugging.

## 1 Introduction

Given a machine learning model, data debugging is to find a subset of the training data such that the model will have a better accuracy if retrained on that subset [1]. Data debugging serves as a popular method of both data cleaning and machine learning interpretation. In the context of data cleaning, data debugging (_a.k.a._ training data debugging [2] or data cleansing [1]) can be used to improve the quality of the training data by removing the flaws leading to mispredictions [3; 4; 5]. When it comes to ML interpretation, data debugging locates the part of the training data responsible for unexpected predictions of an ML model. Therefore it is also studied as a training data-based (_a.k.a._ instance-based [6]) interpretation, which is crucial for helping system developers and ML practitioners to debug ML system by reporting the harmful part of training data [7].

To solve the data debugging problem, existing researches adopt a two-phase score-based heuristic approach [2]. In the first phase, a score representing the estimated impact on the model accuracy is assigned to each training sample in the training data. It is hoped that the harmful part of training data gets a lower score than the other part. In the second phase, training samples with lower scores are removed greedily and the model is retrained on the modified training data. The two phases are carried out iteratively until a well-trained model is obtained. Most of the related works focus ondeveloping algorithms to estimate the scores efficiently in the first phase [8; 9; 10; 11; 12; 13; 14; 15; 16], but rarely study the effectiveness of the entire two-phase approach.

Since it is computationally intractable to estimate the score for all possible subsets of the training data, it is often assumed that the score representing the impact of a subset is approximately equal to the sum of the scores of each individual training samples from the subset. However, Koh et. al. [10] showed this is not always the case. For a bunch of subsets sampled from the training data, they empirically studied the difference between the estimated impact and the actual impact of each subset by taking influence functions as the scoring method. The estimated impact is calculated by summing up the score by influence function of each training samples in the subset, and the actual impact is measured by the improvement of accuracy of the model retrained after removing the subset from training data. They found that the estimated impact tends to underestimate the actual impact. Removing a large number of training samples could result in a large deviation between estimated and actual impacts. Although an upper bound of the deviation under certain assumptions has been derived, it is still unknown whether the deviation can be reduced or eliminated efficiently.

The above deviation also poses challenges to the effectiveness of the entire approach. Suppose the influence function is adopted as the scoring method, the accuracy of the model is not guaranteed to improve due to the deviation reported in [10] if a large group of training samples are removed during each iteration. Moreover, there is no theoretical analysis for the effectiveness of the greedy approach in the second phase. Even if only one training sample is removed during each iteration of the two-phase approach, the accuracy of the model is still not guaranteed to be improved. The effectiveness of the entire two-phase approach is therefore not assured. This leaves the following open problem:

**Problem 1.1**.: Is there an efficient algorithm to find the subset of the training data, such that the model obtained by retraining on it has a better accuracy?

The computational complexity results presented in this paper demonstrate that it is unlikely to solve the data debugging problem efficiently in polynomial time. To figure out its hardness, we study the problem Debuggable which is the decision version of data debugging when the test set consists of only one instance. Formally, Debuggable is defined as follows:

**Problem 1.2** (Debuggable).: Given a classifier \(\mathcal{M}\), its training data \(T\), a test instance \((\mathbf{x},y)\). Is there a \(T^{\prime}\subseteq T\), such that \(\mathcal{M}\) predicts \(y\) on \(\mathbf{x}\) if retrained on \(T^{\prime}\)?

Basically, we prove that Debuggable is NP-complete, which means data debugging is unlikely to be solved in polynomial time. This result answers the open question mentioned above directly, this is, the large deviation of estimated impacts [10] cannot be reduced or eliminated efficiently. This is because if the impact of a subset of the training data could be accurately estimated as the sum of the impact of each training sample in the subset, data debugging can be solved in polynomial time, which is impossible unless P=NP.

Although Debuggable is generally intractable, we still hope to develop efficient algorithms tailored to specific cases. Thus it is necessary to figure out the root cause of the hardness for Debuggable. Previous research are always conducted based on the belief that the complexity of data debugging is due to the chosen model architecture is complicated. However, we show that at least for models trained by stochastic gradient descent (SGD), the hardness stems from the hyper-parameter configuration selected for the SGD training, which was not yet aware of by previous work. To cover a wide range of commonly used machine learning models, we take linear classifiers as the model and show that even for linear classifiers, Debuggable is NP-hard as long as they are trained by SGD. Moreover, we provided a comprehensive analysis on hyper-parameter configurations that affect the computational complexity of Debuggable, including the loss function, the model dimension and the training order. Training order, _a.k.a._ training data order [17] or order of training samples [18], refers to the order in which each training sample is considered during the SGD. Detailed complexity results are shown in Table 1.

Our contribution can be concluded as follows:

* We studied the computational complexity of data debugging and showed that data debugging is NP-hard for linear classifiers in the general setting for _all possible training orders_.
* We studied the complexity of Debuggable when the loss is fixed as the hinge-like function. For 2 or higher dimension, Debuggable is NP-complete when the training order is adversarially chosen; For one-dimensional cases, Debuggable can be NP-hard when the interception \(\beta<0\), and is solvable in linear time when \(\beta\geq 0\).
* We proved that Debuggable is solvable in linear time when the loss function is linear.

Moreover, we have a discussion on the implications of these complexity results for machine learning interpretability and data quality, as well as limitations of score-based greedy methods. Our results suggest the further study as follows. (1) It is better to characterize the training sample and find the criterion which can be used to decide the existence of efficient algorithms; (2) Designing algorithms with CSP-solver is a potential way to solve data debugging more efficiently than the brute-force one; (3) Developing random algorithms is a potential way to solve data debugging successfully with high probability.

### Related Works

The solution of data debugging has applications in database query results reliability enhancement [2; 19], training data cleaning [1] and machine learning interpretation[9; 8; 10; 20; 21]. Existing works on data debugging mainly adopt a two-phase approach, which scores the training samples in the first phase and greedily deletes training samples with lower scores in the second phase. Most of the research focus on the first phase. There are mainly two ways of scoring adopted for data debugging in practice. Leave-one-out (LOO) retraining is a widely studied way, which evaluates the contribution of a training sample through the difference in the model's accuracy trained without that training sample. To avoid the cost of model retraining, Koh and Liang took influence functions as an approximation of LOO [8]. After that, various extensions and improvements of the influence function based method are proposed, such as Fisher kernel [9], influence function for group impacts [10], second-order approximations [11] and scalable influence functions [12]. Another way is Shapley-based scoring, where the impact of a training sample is measured by its average marginal contribution to all subsets of the training data [13]. Since Shapley-base scoring suffers from expensive computational cost [22], recent works focus on techniques that efficiently estimate the Shapley value, including Monte-Carlo sampling [13], group testing [14; 15] and using proxy models such as \(k\)-NN [16; 3]. However, those methods do not admit any theoretical guarantee on the effectiveness. This paper discusses the limitations of the above methods and suggests some future directions on data debugging.

## 2 Preliminaries and Problem Definition

**Linear classifiers.** Formally, a (binary) linear classifier is a function \(\lambda_{\mathbf{w}}:\mathbb{R}^{d}\rightarrow\{-1,1\}\), where \(d\) is called its _dimension_ and \(\mathbf{w}\in\mathbb{R}^{d}\) its parameter. Without loss of generality, the bias term of a linear classifier is set as zero in this paper. All vectors in this paper are assumed to be _column_ vectors. For an input \(\mathbf{x}\), the value of \(\lambda_{\mathbf{w}}\) is defined as

\[\lambda_{\mathbf{w}}(\mathbf{x})=\begin{cases}1&\text{if }\mathbf{w}^{\top} \mathbf{x}\geq 0\\ -1&\text{otherwise.}\end{cases}\]

We denote the class of linear models as \(\Lambda\).

**Training data.** A _training sample_ is a pair \((\mathbf{x},y)\) in which \(\mathbf{x}\in\mathbb{R}^{d}\) is the input and \(y\in\{-1,1\}\) is the label of \(\mathbf{x}\). The _training data_ is a multiset of training samples. We employ \(\mathbf{w}\xrightarrow{T}\mathbf{w}^{\prime}\) to denote that the parameter \(\mathbf{w}^{\prime}\) is obtained by training the parameter \(\mathbf{w}\) on the training data \(T\), and employ \(\mathbf{w}\xrightarrow{(\mathbf{x},y)}\mathbf{w}^{\prime}\) to denote that \(\mathbf{w}^{\prime}\) is obtained by training \(\mathbf{w}\) on the training sample \((\mathbf{x},y)\).

\begin{table}
\begin{tabular}{c c c c} \hline \hline Loss Function & Dimension & Training Order & Complexity \\ \hline Not Fixed & Not Fixed & - & NP-hard \\ Hinge-like & \(\geq 2\) & Adversarially Chosen & NP-hard \\ Hinge-like, \(\beta<0\) & \(1\) & Adversarially Chosen & NP-hard \\ Hinge-like, \(\beta\geq 0\) & \(1\) & - & Linear Time \\ Linear & - & - & Linear Time \\ \hline \hline \end{tabular}
\end{table}
Table 1: Computational complexity of the data debugging problem 

**Loss functions and learning rates.** Binary linear classifiers typically use unary functions on \(y\mathbf{w}^{\top}\mathbf{x}\) as their loss functions [23]. Therefore we only consider loss functions of the form \(\mathcal{L}:y\mathbf{w}^{\top}\mathbf{x}\mapsto\mathbb{R}\) for the rest of the paper.

The _linear_ loss is in the form of

\[\mathcal{L}_{\mathtt{lin}}(y\mathbf{w}^{\top}\mathbf{x})=-\alpha(y\mathbf{w}^{ \top}\mathbf{x}+\beta).\]

The _hinge-like_ loss function is defined as the following form

\[\mathcal{L}_{\mathtt{hinge}}(y\mathbf{w}^{\top}\mathbf{x})=\begin{cases}- \alpha(y\mathbf{w}^{\top}\mathbf{x}+\beta),&y\mathbf{w}^{\top}\mathbf{x}<\beta \\ 0,&\text{otherwise}.\end{cases}\]

We call \(\beta\) as the _interception_ of \(\mathcal{L}_{\mathtt{hinge}}\). We represent the learning rate of a model using a vector \(\boldsymbol{\eta}=(\eta_{1},\dots,\eta_{d})\), where \(\eta_{i}\geq 0\) and each parameter \(w_{i}\) can be updated with the corresponding learning rate \(\eta_{i}\).

**Stochastic gradient descent.** The stochastic gradient descent (SGD) method updates parameter \(\mathbf{w}\) from its initial value \(\mathbf{w}^{(0)}\) through several epochs. During each epoch, the SGD goes through the entire set of training samples in some training order through several iterations. The training order is defined as a sequence of training samples, in the form of \((\mathbf{x}_{1},y_{1})\dots(\mathbf{x}_{n},y_{n})\). For \(1\leq i<j\leq n\), \((\mathbf{x}_{i},y_{i})\) is considered before \((\mathbf{x}_{j},y_{j})\) during the SGD. We use \(w_{i}\) to denote the \(i\)-th coordinate of \(\mathbf{w}\). We also use \(\mathbf{w}^{(e,k)}\) to denote the value of \(\mathbf{w}\) at the end of \(k\)-th iteration of epoch \(e\) and use \(\mathbf{w}^{(e)}\) to denote the value of \(\mathbf{w}\) after the end of epoch \(e\). Assuming \((\mathbf{x},y)\) to be the training sample considered at iteration \(k\), the stochastic gradient descent (SGD) method updates parameter \(w_{i}\) for each \(i\) by

\[w_{i}^{(e,k)}\gets w_{i}^{(e,k-1)}-\eta_{i}\cdot\frac{\partial\mathcal{L}( y(\mathbf{w}^{(e,k-1)})^{\top}\mathbf{x})}{\partial w_{i}}\] (1)

In other words, we have

\[\mathbf{w}^{(e,k)}\leftarrow\mathbf{w}^{(e,k-1)}-\boldsymbol{\eta}\otimes \nabla\mathcal{L}(y(\mathbf{w}^{(e,k-1)})^{\top}\mathbf{x})\]

where \(\boldsymbol{\eta}\otimes\nabla\mathcal{L}=(\eta_{1}\frac{\partial\mathcal{L}} {\partial w_{1}},\dots,\eta_{d}\frac{\partial\mathcal{L}}{\partial w_{d}})\) is the Hadamard product. We say a training sample \(\mathbf{x}\) is _activated_ at iteration \(k\) during epoch \(e\) if \(\nabla\mathcal{L}(y(\mathbf{w}^{(e,k-1)})^{\top}\mathbf{x})\neq 0\). The SGD terminates at the end of epoch \(e\) if \(\|\mathbf{w}^{(e-1)}-\mathbf{w}^{(e)}\|<\varepsilon\) for threshold \(\varepsilon\) or \(e\) reached some predetermined value. We denote \(\mathbf{w}^{*}=\mathbf{w}^{(e)}\). A linear classifier trained by SGD with the meta-parameters mentioned above is denoted as \(\texttt{SGD}_{\Lambda}(\mathcal{L},\boldsymbol{\eta},\varepsilon,T)=\lambda_{ \mathbf{w}^{*}}\). With a slight abuse of notation, we define \(\texttt{SGD}_{\Lambda}(\mathcal{L},\boldsymbol{\eta},\varepsilon,T,\mathbf{x} )=\lambda_{\mathbf{w}^{*}}(\mathbf{x})\). We also use \(\texttt{SGD}_{\Lambda}(T,\mathbf{x})\) to avoid cluttering when the context is clear.

**Problem definition.** With the above definitions, Debuggable for SGD-trained linear classifiers can be formalized as follows:

\begin{tabular}{|c|} \hline Debuggable-Lin \\
**Input:** Training data \(T\), loss function \(\mathcal{L}\), initial parameter \(\mathbf{w}^{(0)}\), learning rate \(\boldsymbol{\eta}\), threshold \(\varepsilon\) and instance \((\mathbf{x}_{\text{test}},y_{\text{test}})\). \\
**Output:** "Yes": if \(\exists\Delta\subseteq T\) such that \(\texttt{SGD}_{\Lambda}(\mathcal{L},\boldsymbol{\eta},\varepsilon,T\setminus \Delta,\mathbf{x}_{\text{test}})=y_{\text{test}}\); \\ "No": otherwise. \\ \hline \end{tabular}

We say \(\texttt{SGD}_{\Lambda}(\mathcal{L},\boldsymbol{\eta},\varepsilon,T)\) is _debuggable_ on \((\mathbf{x}_{\text{test}},y_{\text{test}})\) if \((\mathcal{L},\mathbf{w}^{(0)},\boldsymbol{\eta},\varepsilon,T,\mathbf{x}_{ \text{test}},y_{\text{test}})\) is a yes-instance of Debuggable-Lin, and not _debuggable_ on \((\mathbf{x}_{\text{test}},y_{\text{test}})\) otherwise.

## 3 Results for Unfixed Loss Functions

In this section, we prove the NP-hardness of Debuggable-Lin. Intuitively, Debuggable-Lin is to determine whether there exists a subset \(T^{\prime}\subseteq T\) where activated training samples within \(T^{\prime}\) drive the parameter \(\mathbf{w}\) toward the region defined by \(y_{\text{test}}\mathbf{w}^{\top}\mathbf{x}_{\text{test}}>0\). The activation of training samples depends on the complex interaction between the training data and the model.

**Theorem 3.1**.: Debuggable-Lin is NP-hard for all training orders.

We only show the proof sketch and leave the details in the appendix.

Proof Sketch.: We build a reduction from an NP-hard problem Monotone 1-in-3 SAT [24]:

Monotone 1-in-3 SAT

**Input:** A 3-CNF formula \(\varphi\) with no negation signs.

**Output:**"Yes": if \(\varphi\) has a 1-in-3 assignment, under which each clause contains exactly one true literal;

"No": otherwise.

For example, \(\varphi_{1}=(x_{1}\lor x_{2}\lor x_{3})\wedge(x_{2}\lor x_{3}\lor x_{4})\) is a yes-instance because \((x_{1},x_{2},x_{3},x_{4})=(\text{T,F,F,T})\) is an 1-in-3 assignment; \(\varphi_{2}=(x_{1}\lor x_{2}\lor x_{3})\wedge(x_{2}\lor x_{3}\lor x_{4})\wedge (x_{1}\lor x_{2}\lor x_{4})\wedge(x_{1}\lor x_{3}\lor x_{4})\) is a no-instance.

Given a 3-CNF formula \(\varphi\), our goal is to construct a configuration of the training process, such that the resulting model outputs the correct answer if and only if its training data \(T^{\prime}\) encodes an 1-in-3 assignment \(\nu\) of \(\varphi\). This can be done by carefully designing the encoding so that for each \(x_{i}\in\varphi\), \(\nu(x_{i})=\text{True}\) if and only if \(\mathbf{t}_{x_{i}}\in T^{\prime}\). Finally, we can construct some \(T\) with \(T\supseteq T^{\prime}\cup\{\mathbf{t}_{x_{i}}|x_{i}\in\varphi\}\), such that some classifier trained on \(T\) is a yes-instance of Debuggable-Lin if and only if \(\varphi\) is a yes-instance of Monotone 1-in-3 SAT, thereby finishing our proof.

**The reduction.** Suppose \(\varphi\) has \(m\) clauses and \(n\) variables, let \(N=n+2m+1\). We set the dimension of the linear classifier to \(N\).

The input. Each coordinate of the input is named as

\[\mathbf{x}=(x_{c_{1}},\ldots,x_{c_{m}},x_{x_{1}},\ldots,x_{x_{n}},x_{b_{1}}, \ldots,x_{b_{m}},x_{\text{dummy}})^{\top}\]

We also use \(x_{i}\) to denote the \(i\)-th coordinate of \(\mathbf{x}\).

The parameters. Each coordinate of the parameter is named as

\[\mathbf{w}=(w_{c_{1}},\ldots,w_{c_{m}},w_{x_{1}},\ldots,w_{x_{n}},w_{b_{1}}, \ldots,w_{b_{m}},w_{\text{dummy}})^{\top}\]

We also use \(w_{i}\) to denote the \(i\)-th coordinate of \(\mathbf{w}\). Each \(w_{x_{j}}\) represents the truth value of variable \(x_{j}\), where 1 represents True and -1 represents False. Similarly, each \(w_{c_{j}}\) represents the truth value of clause \(c_{j}\) based on the value of its variables. \(w_{b_{j}}\) and \(w_{\text{dummy}}\) are used for convenience of proof.

The initial value of the parameter is set to

\[\mathbf{w}^{(0)}=(\overbrace{\frac{1}{2},\ldots,\frac{1}{2}}^{m},\overbrace{- 1,\ldots,-1}^{n},\overbrace{-1,\ldots,-1}^{m},1)^{\top}\]

Loss function. We denote \(U(x_{0},\delta):=\{x|x_{0}-\delta<x<x_{0}+\delta\}\) as the \(\delta\)-neighborhood of \(x_{0}\) and define \(U(\pm x_{0},\delta)=U(x_{0},\delta)\cup U(-x_{0},\delta)\). We define the _local ramp function_ as

\[r_{x_{0},\delta}(x)=\begin{cases}0&,x\leq x_{0}-\delta;\\ x-x_{0}+\delta&,x\in U(x_{0},\delta);\\ 2\delta&,x\geq x_{0}+\delta.\end{cases}\]

The loss function is defined as

\[\mathcal{L}=-\frac{12N}{5}r_{-5,0.01}(y\mathbf{w}^{\top}\mathbf{x})-r_{-\frac {1}{2},0.26}(y\mathbf{w}^{\top}\mathbf{x})-\frac{1}{1000N}\sum_{x_{0}\in\{\pm 1,\pm 3\}}r_{x_{0},0.01}(y\mathbf{w}^{\top}\mathbf{x}).\]

\(\mathcal{L}\) is monotonically decreasing with derivatives

\[\frac{\partial\mathcal{L}}{\partial w_{i}}=\begin{cases}-\frac{12N}{5}\cdot yx _{i}&,y\mathbf{w}^{\top}\mathbf{x}\in U(-5,0.01);\\ -yx_{i}&,y\mathbf{w}^{\top}\mathbf{x}\in U(-\frac{1}{2},0.26);\\ -\frac{1}{1000N}yx_{i}&,y\mathbf{w}^{\top}\mathbf{x}\in\bigcup_{x_{0}\in\{\pm 1,\pm 3\}}U(x_{0},0.01);\\ 0&,\text{otherwise.}\end{cases}\] (2)Learning rate. The learning rate for SGD is set to be

\[\bm{\eta}=(\overbrace{5,\ldots,5}^{m},\overbrace{\frac{1}{6N},\ldots,\frac{1}{6N }}^{n},\overbrace{2000N,\ldots,2000N}^{m},1)^{\top}.\]

Training data. We define two gadgets, \(\texttt{var}\left(i\right)\) and \(\texttt{clause}\left(i,i_{1},i_{2},i_{3}\right)\), as illustrated in Table 2 and 3. All the unspecified coordinates are set to zero. We use \(T_{0}\) to denote the training data. \(\texttt{var}\left(i\right)\) is contained in \(T_{0}\) if and only if \(x_{i}\in\varphi\), and \(\texttt{clause}\left(i,i_{1},i_{2},i_{3}\right)\) is contained in \(T_{0}\) if and only if \(c_{i}=(x_{i_{1}}\lor x_{i_{2}}\lor x_{i_{3}})\in\varphi\).

Threshold and instance. The threshold \(\varepsilon\) can be any fixed value in \(\mathbb{R}_{+}\). The instance is defined as \((\mathbf{x}_{\text{test}},y_{\text{test}})\), where \(y_{\text{test}}=1\) and

\[\mathbf{x}_{\text{test}}=(\overbrace{1,\ldots,1}^{m},\overbrace{0,\ldots,0}^ {n+m},\frac{-11m+5}{2})^{\top}.\]

The following reduction works for all possible training orders. Intuitively, during the training process, each \(\texttt{var}\left(i\right)\) in the training data will set \(w_{x_{i}}\) to around \(1\) (that is, mark \(x_{i}\) as True) in the first epoch, and each \(\texttt{clause}\left(i,i_{1},i_{2},i_{3}\right)\) will set \(w_{c_{i}}\) to near \(\frac{11}{2}\) in the second epoch, if and only if exactly one of \(w_{x_{i_{1}}},w_{x_{i_{2}}},w_{x_{i_{3}}}\) is near \(1\) and the others near \(-1\) (that is, mark \(c_{i}\) as satisfied if exactly one of its literals is True and the others False). The training process terminates at the end of the second epoch. 

## 4 Results for Fixed Loss Functions

We have proved the NP-hardness for Debuggable-Lin when the loss function is not fixed. In this section, we study the complexity when the loss function is fixed as linear and hinge-like functions. Assuming that SGD terminates after only one epoch with a fixed order, we will show that Debuggable-Lin is solvable in linear time for linear loss. For hinge-like loss functions, Debuggable-Lin can be solved in linear time only when the dimension \(d=1\) and the interception \(\beta\geq 0\). For the rest cases, Debuggable-Lin becomes NP-hard.

### The Easy Case

We start with the linear loss function \(\mathcal{L}=-\alpha(y\mathbf{w}^{\top}\mathbf{x}+\beta)\), with which all the training data are activated and \(\mathbf{w}^{*}=\mathbf{w}^{*}(T)=\mathbf{w}^{(0)}+\sum_{(\mathbf{x},y)\in T} \alpha y\bm{\eta}\otimes\mathbf{x}\). Since \(y_{\text{test}}\in\{-1,1\}\), Debuggable-Lin is equivalent to deciding whether

\[\max_{T^{\prime}\subseteq T}\{y_{\text{test}}(\mathbf{w}^{*}(T^{\prime}))^{ \top}\mathbf{x}_{\text{test}}\}>0.\]

A training sample \((\mathbf{x},y)\) is "good" if \(y_{\text{test}}(\alpha y\bm{\eta}\otimes\mathbf{x})^{\top}\mathbf{x}_{\text{ test}}>0\) and "bad" otherwise. The _good training-sample assessment_ (GTA) algorithm, as shown in Algorithm 1, deals with this situation by greedily picking all "good" training samples.

Denoting \(T^{*}\) as the set of all good data in \(T\), it follows that

\[y_{\text{test}}(\mathbf{w}^{*}(T^{*}))^{\top}\mathbf{x}_{\text{ test}} =y_{\text{test}}(\mathbf{w}^{(0)})^{\top}\mathbf{x}_{\text{test}}+ \sum_{(\mathbf{x},y)\in T^{*}}y_{\text{test}}(\alpha y\bm{\eta}\otimes \mathbf{x})^{\top}\mathbf{x}_{\text{test}}\] \[\geq y_{\text{test}}(\mathbf{w}^{(0)})^{\top}\mathbf{x}_{\text{ test}}+\sum_{(\mathbf{x},y)\in T^{\prime}}y_{\text{test}}(\alpha y\bm{\eta} \otimes\mathbf{x})^{\top}\mathbf{x}_{\text{test}}\]

for all \(T^{\prime}\subseteq T\). Hence \(\max_{T^{\prime}\subseteq T}\{y_{\text{test}}(\mathbf{w}^{*}(T^{\prime}))^{ \top}\mathbf{x}_{\text{test}}\}=y_{\text{test}}(\mathbf{w}^{*}(T^{*}))^{\top} \mathbf{x}_{\text{test}}\) and Debuggable-Lin can be solved by GTA in linear time. The following theorem is straightforward.

**Theorem 4.1**.: Debuggable-Lin is linear time solvable for linear loss functions.

```
0: Training data \(T\), loss function \(\mathcal{L}\), initial parameter \(\mathbf{w}^{(0)}\), learning rate \(\boldsymbol{\eta}\), threshold \(\varepsilon\) and test instance \((\mathbf{x}_{\text{test}},y_{\text{test}})\).
0: TRUE, iff \(\texttt{SGD}_{\Lambda}(\mathcal{L},\boldsymbol{\eta},\varepsilon,T)\) is debuggable on \((\mathbf{x}_{\text{test}}y_{\text{test}})\).
1\(\mathbf{w}\leftarrow\mathbf{w}^{(0)}\);
2for\((\mathbf{x},y)\in T\)do
3if\(y_{\text{test}}(\alpha y\boldsymbol{\eta}\otimes\mathbf{x})^{\top}\mathbf{x}_ {\text{test}}>0\)then
4\(\mathbf{w}\leftarrow\mathbf{w}+\alpha y\boldsymbol{\eta}\otimes\mathbf{x}\);
5
6 end if
7if\(y_{\text{test}}\mathbf{w}^{\top}\mathbf{x}_{\text{test}}\geq 0\)then
8 return TRUE;
9
10 end if
11return FALSE; ```

**Algorithm 1**Good Training-sample Assessment (GTA)

GTA is still effective for one-dimensional classifiers trained with hinge-like losses when \(\beta\geq 0\).

**Theorem 4.2**.: Debuggable-Lin is linear time solvable for hinge-like loss functions, when \(d=1\) and \(\beta\geq 0\).

Proof.: It suffices to prove that if \(\exists T^{\prime}\subseteq T\) such that \(\texttt{SGD}_{\Lambda}(T^{\prime},x_{\text{test}})=y_{\text{test}}\), \(\texttt{SGD}_{\Lambda}(T^{*},x_{\text{test}})=y_{\text{test}}\).

a) Suppose all the data in \(T^{*}\) are activated, we have

\[y_{\text{test}}w^{*}(T^{*})x_{\text{test}} =y_{\text{test}}w^{(0)}x_{\text{test}}+\sum_{(x,y)\in T^{*}}y_{ \text{test}}\alpha y\eta xx_{\text{test}}\] \[\geq y_{\text{test}}w^{(0)}x_{\text{test}}+\sum_{(x,y)\in T^{ \prime}\cap T^{*}}y_{\text{test}}\alpha y\eta xx_{\text{test}}+\sum_{(x,y)\in T ^{\prime}\setminus T^{*}}y_{\text{test}}\alpha y\eta xx_{\text{test}}\] \[=y_{\text{test}}w^{*}(T^{\prime})x_{\text{test}}\geq 0\]

b) Suppose \((x,y)\in T^{*}\) is the first inactivated data during the training phase, and \(w\) is the current parameter, we have \(ywx>\beta\). Since \(\alpha\eta\cdot(xy)\cdot(x_{\text{test}}y_{\text{test}})\geq 0\), we have \((x_{\text{test}}y_{\text{test}})\cdot w\geq 0\). Let \(T^{\prime\prime}\) be the set of training data appeared before \((x,y)\), we have \(y_{\text{test}}w^{*}(T^{*})x_{\text{test}}\geq y_{\text{test}}w^{*}(T^{\prime \prime})x_{\text{test}}\geq 0\). 

### The Hard Case

The gradient of training data may not always be activated and could be affected by the training order. When the training order is adversarially chosen, the following theorem shows that Debuggable-Lin is NP-hard for all \(d\geq 2\) and \(\beta\in\mathbb{R}\).

**Theorem 4.3**.: If the training order is adversarially chosen and \(d\geq 2\), Debuggable-Lin is NP-hard for _each_ hinge-like loss function at _every_ constant learning rate.

Proof sketch.: Since the result can be easily extended for all \(d>2\) by padding the other \(d-2\) dimensions with zeros, we only prove for the case of \(d=2\). We assume \(\beta\geq-1\) and leave the \(\beta<-1\) case to the appendix. To avoid cluttering, we further assume \(\boldsymbol{\eta}=\mathbf{1}\) and \(\alpha=1\). The proof can be easily generalized by appropriately re-scaling the constructed vectors.

We build a reduction from the subset sum problem, which is well-known to be NP-hard:

```
0: Subset Sum Input: A set of positive integer \(S\), and a positive integer \(t\). Output: "Yes": if \(\exists S^{\prime}\subseteq S\) such that \(\sum_{a\in S^{\prime}}a=t\); "No": otherwise. ```

**Algorithm 2**The Hard Case

[MISSING_PAGE_EMPTY:8]

which contradicts to the fact that \(y_{\text{test}}\mathbf{w}^{\top}\mathbf{x}_{\text{test}}\geq 0\).

Let \(S^{\prime}=\{a_{i}|(\mathbf{x}_{i},y_{i})\in T^{*}\}\) and \(t^{\prime}=\sum_{a\in S^{\prime}}a_{i}\), it suffices to prove \(t^{\prime}=t\). Notice that

\[\mathbf{w}^{(0)}\xrightarrow{T^{*}\cap\{(\mathbf{x}_{i},y_{i})|1 \leq j\leq i\}}\mathbf{w}_{c} =(\sqrt{\gamma}(-18n^{2}m^{2}+\frac{|T^{*}|}{n+1}),3\sqrt{\gamma} \sum_{a_{i}\in S^{\prime}}a_{i})\] \[=(\sqrt{\gamma}(-18n^{2}m^{2}+\frac{|T^{*}|}{n+1}),3\sqrt{\gamma} t^{\prime})\]

Hence \(y_{c}\mathbf{w}_{c}^{\top}\mathbf{x}_{c}=\gamma(-18n^{2}m^{2}+\frac{|T^{*}|}{n +1})(18n^{2}m^{2}-2)-9\gamma tt^{\prime}<-1\leq\beta\), thus

\[\mathbf{w}_{c}\xrightarrow{(\mathbf{x}_{c},y_{c})}\mathbf{w}_{b}=\mathbf{w}_{ c}+\mathbf{x}_{c}y_{c}=(\sqrt{\gamma}(\frac{|T^{*}|}{n+1}-2),3\sqrt{\gamma}(t^{ \prime}-t))\]

(1) If \(t^{\prime}\leq t-1\), we have \(y_{b}\mathbf{w}_{b}^{\top}\mathbf{x}_{b}=\gamma\left(\frac{|T^{*}|}{n+1}-2+3( t-t^{\prime})\right)>\gamma\geq\beta\), a contradiction. (2) If \(t^{\prime}\geq t+1\), we have \(y_{a}\mathbf{w}_{a}^{\top}\mathbf{x}_{a}=\gamma\left(\frac{|T^{*}|}{n+1}-2+3( t^{\prime}-t)\right)>\gamma\geq\beta\), another contradiction.

Therefore \(t^{\prime}=t\), and this completes the proof. 

Moreover, Debuggable-Lin is NP-hard even when \(d=1\) and \(\beta<0\).

**Theorem 4.4**.: If the training order is adversarially chosen and \(d=1\), Debuggable-Lin remains NP-hard for _each_ hinge-like loss function with \(\beta<0\) at _every_ constant learning rate.

**Remarks.** The training order in this section can be arbitrary as long as the last three training samples are \((\mathbf{x}_{c},y_{c}),(\mathbf{x}_{b},y_{b}),(\mathbf{x}_{a},y_{a})\), respectively. All the training samples are "good" since for each \((\mathbf{x},y)\in T\) we have \(\mathbf{x}^{\top}\mathbf{x}_{\text{test}}y_{\text{test}}>0\). This implies that Debuggable-Lin is NP-hard even if all the training data are "good" training samples, and exemplifies why the GTA algorithm fails for higher dimensions.

## 5 Discussion and Conclusion

In this paper, we provided a comprehensive analysis on the complexity of Debuggable. We focus on the linear classifier that is trained using SGD, as it is a key component in the majority of popular models.

Since Debuggable is a special case of data debugging, the above results proved the intractability of data debugging and therefore gives a negative answer to Problem 1.1 declared in the introduction. The complexity results also demonstrated that it is not accurate to estimate the impact of subset of training data by summing up the score of each training samples in the subset, _as long as the scores can be calculated in polynomial time_.

In Section 4, a training sample is said to be "good" if it can help the resulting model to predict correctly on the test instance. That is, it can increase \(y_{\text{test}}(\mathbf{w}^{*})^{\top}\mathbf{x}_{\text{test}}\). However, in our proof we showed that Debuggable remains NP-hard even if all training samples are "good". This suggests that the quality of a training sample does not depend only on some properties of itself but also on the interaction between the rest of the training data, which should be taken into consideration when developing data cleaning approaches.

Moreover, the NP-hardness of Debuggable implies that, it is in general intractable to figure out the causality between even the prediction of a linear classifier and its training data. This may be seem surprising since linear classifiers have long been considered "inherently interpretable". As warned in [25], _a method being "inherently interpretable" needs to be verified before it can be trusted_, the concept of interpretability must be _rigorously defined_, or at least its boundaries specified.

Our results suggests the following directions for future research. Firstly, characterizing the training sample may be helpful in designing efficient algorithms for data debugging; Secondly, designing algorithms using CSP-solver is a potential way to solve data debugging more efficiently than the brute-force algorithms; Finally, developing random algorithms is a potential way to solve data debugging successfully with high probability.

## References

* Hara et al. [2019] Satoshi Hara, Atsushi Nitanda, and Takanori Maehara. _Data Cleansing for Models Trained with SGD_. Curran Associates Inc., Red Hook, NY, USA, 2019.
* Wu et al. [2020] Weiyuan Wu, Lamproos Flokas, Eugene Wu, and Jiannan Wang. Complaint-driven training data debugging for query 2.0. pages 1317-1334, 06 2020. doi: 10.1145/3318464.3389696.
* Karlas et al. [2022] Bojan Karlas, David Dao, Matteo Interlandi, Bo Li, Sebastian Schelter, Wentao Wu, and Ce Zhang. Data debugging with shapley importance over end-to-end machine learning pipelines, 2022.
* Neutatz et al. [2021] Felix Neutatz, Binger Chen, Ziawasch Abedjan, and Eugene Wu. From cleaning before ml to cleaning for ml. _IEEE Data Eng. Bull._, 44:24-41, 2021. URL https://api.semanticscholar.org/CorpusID:237542697.
* Li et al. [2021] Peng Li, Xi Rao, Jennifer Blase, Yue Zhang, Xu Chu, and Ce Zhang. Cleanml: A study for evaluating the impact of data cleaning on ml classification tasks. In _2021 IEEE 37th International Conference on Data Engineering (ICDE)_, pages 13-24, 2021. doi: 10.1109/ICDE51399.2021.00009.
* Bae et al. [2024] Juhan Bae, Nathan Ng, Alston Lo, Marzyeh Ghassemi, and Roger Grosse. If influence functions are the answer, then what is the question? In _Proceedings of the 36th International Conference on Neural Information Processing Systems_, NIPS '22, Red Hook, NY, USA, 2024. Curran Associates Inc. ISBN 9781713871088.
* Pradhan et al. [2022] Romila Pradhan, Jiongli Zhu, Boris Glavic, and Babak Salimi. Interpretable data-based explanations for fairness debugging. In _Proceedings of the 2022 International Conference on Management of Data_, SIGMOD '22, page 247-261, New York, NY, USA, 2022. Association for Computing Machinery. ISBN 9781450392495. doi: 10.1145/3514221.3517886. URL https://doi.org/10.1145/3514221.3517886.
* Volume 70_, ICML'17, page 1885-1894. JMLR.org, 2017.
* Khanna et al. [2018] Rajiv Khanna, Been Kim, Joydeep Ghosh, and Oluwasanmi Koyejo. Interpreting black box predictions using fisher kernels. In _International Conference on Artificial Intelligence and Statistics_, 2018. URL https://api.semanticscholar.org/CorpusID:53085397.
* Koh et al. [2019] Pang Wei Koh, Kai-Siang Ang, Hubert Hua Kian Teo, and Percy Liang. On the accuracy of influence functions for measuring group effects. In _Neural Information Processing Systems_, 2019. URL https://api.semanticscholar.org/CorpusID:173188850.
* Basu et al. [2020] Samyadeep Basu, Xuchen You, and Soheil Feizi. On second-order group influence functions for black-box predictions. In _Proceedings of the 37th International Conference on Machine Learning_, ICML'20. JMLR.org, 2020.
* Guo et al. [2018] Han Guo, Nazneen Rajani, Peter Hase, Mohit Bansal, and Caiming Xiong. FastIF: Scalable influence functions for efficient model interpretation and debugging. In Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih, editors, _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_, pages 10333-10350, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.808. URL https://aclanthology.org/2021.emnlp-main.808.
* Ghorbani and Zou [2019] Amirata Ghorbani and James Y. Zou. Data shapley: Equitable valuation of data for machine learning. _ArXiv_, abs/1904.02868, 2019. URL https://api.semanticscholar.org/CorpusID:102350503.
* Jia et al. [2019] R. Jia, David Dao, Boxin Wang, Frances Ann Hubis, Nicholas Hynes, Nezihre Merve Gurel, Bo Li, Ce Zhang, Dawn Xiaodong Song, and Costas J. Spanos. Towards efficient data valuation based on the shapley value. _ArXiv_, abs/1902.10275, 2019. URL https://api.semanticscholar.org/CorpusID:67855573.
* Jia et al. [2021] Ruoxi Jia, Fan Wu, Xuehui Sun, Jiacen Xu, David Dao, Bhavya Kailkhura, Ce Zhang, Bo Li, and Dawn Song. Scalability vs. utility: Do we have to sacrifice one for the other in data importance quantification? In _2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 8235-8243, 2021. doi: 10.1109/CVPR46437.2021.00814.
* Jia et al. [2019] Ruoxi Jia, David Dao, Boxin Wang, Frances Ann Hubis, Nezihre Merve Gurel, Bo Li, Ce Zhang, Costas Spanos, and Dawn Song. Efficient task-specific data valuation for nearest neighbor algorithms. _Proc. VLDB Endow._, 12(11):1610-1623, jul 2019. ISSN 2150-8097. doi: 10.14778/3342263.3342637. URL https://doi.org/10.14778/3342263.3342637.

* Mange [2019] Jeremy Mange. Effect of training data order for machine learning. In _2019 International Conference on Computational Science and Computational Intelligence (CSCI)_, pages 406-407, 2019. doi: 10.1109/CSCI49370.2019.00078.
* Chang et al. [2021] Ernie Chang, Hui-Syuan Yeh, and Vera Demberg. Does the order of training samples matter? improving neural data-to-text generation with curriculum learning. _ArXiv_, abs/2102.03554, 2021. URL https://api.semanticscholar.org/CorpusID:231846815.
* Liu et al. [2022] Yejia Liu, Weiyuan Wu, Lampros Flokas, Jiannan Wang, and Eugene Wu. Enabling sql-based training data debugging for federated learning. _Proceedings of the VLDB Endowment_, 15:388-400, 02 2022. doi: 10.14778/3494124.3494125.
* Brunet et al. [2019] Marc-Etienne Brunet, Colleen Alkalay-Houlihan, Ashton Anderson, and Richard Zemel. Understanding the origins of bias in word embeddings, 2019.
* Wang et al. [2019] Hao Wang, Berk Ustun, and Flavio P. Calmon. Repairing without retraining: Avoiding disparate impact with counterfactual distributions, 2019.
* Deng and Papadimitriou [1994] Xiaotie Deng and Christos H. Papadimitriou. On the complexity of cooperative solution concepts. _Math. Oper. Res._, 19:257-266, 1994. URL https://api.semanticscholar.org/CorpusID:12946448.
* Wang et al. [2022] Qi Wang, Yue Ma, Kun Zhao, and Yingjie Tian. A comprehensive survey of loss functions in machine learning. _Annals of Data Science_, 9, 04 2022. doi: 10.1007/s40745-020-00253-5.
* Demaine et al. [2024] Erik D. Demaine, William Gasarch, and Mohammad Hajiaghayi. _Computational Intractability: A Guide to Algorithmic Lower Bounds_. MIT Press, 2024.
* Jacovi and Goldberg [2020] Alon Jacovi and Yoav Goldberg. Towards faithfully interpretable nlp systems: How should we define and evaluate faithfulness? In _Annual Meeting of the Association for Computational Linguistics_, 2020. URL https://api.semanticscholar.org/CorpusID:215416110.
* Parque [2021] Victor Parque. Tackling the subset sum problem with fixed size using an integer representation scheme. In _2021 IEEE Congress on Evolutionary Computation (CEC)_, pages 1447-1453, 2021. doi: 10.1109/CEC45853.2021.9504889.

Detailed Proofs for Section 3

**Notations.** Given some orderings \(\{o_{e}\}\) of training data, where \(o_{\mathbf{t}}^{e}\) as the order of \(\mathbf{t}\) in epoch \(e\). We use \(w_{x_{i}}^{(e,l)}\) to denote the value of \(w_{x_{i}}\) after the \(l\)-th iteration in epoch \(e\). We also denote \(\mathbf{x_{t}}\) and \(y_{\mathbf{t}}\) as the feature and the label of training data \(\mathbf{t}\), respectively. We denote \(\mathbf{t}^{(e,l)}\) as the training sample being considered during epoch \(e\), iteration \(l\).

**Lemma A.1**.: Suppose \(T\subseteq T_{0}\) is the training data and let \(T_{l,r}^{e}=\{\mathbf{t}^{(e,l)},\mathbf{t}^{(e,l+1)},\ldots,\mathbf{t}^{(e,r)}\}\) be the set of consecutive training samples considered during epoch \(e\) from iteration \(l\) to \(r\). For \(1\leq l\leq r\leq|T|\), if clause(\(\gamma,i_{1},i_{2},i_{3}\))\(\not\in T_{l,r}^{e}\), then \(w_{c_{\gamma}}^{(e,l-1)}=w_{c_{\gamma}}^{(e,r)}\).

Proof.: For each \(\mathbf{t}\in T_{l,r}^{e}\), we have \((x_{\mathbf{t}})_{c_{\gamma}}=0\). Therefore

\[\left|\left.\frac{\partial\mathcal{L}}{\partial c_{\gamma}}\right|_{\mathbf{t }}\right|\leq\max\left\{\left|-\frac{12N}{5}yx_{c_{\gamma}}\right|,\left|-yx_{c _{\gamma}}\right|,\left|-\frac{1}{1000N}yx_{c_{\gamma}}\right|,0\right\}=0\]

Hence \(\left.\frac{\partial\mathcal{L}}{\partial c_{\gamma}}\right|_{\mathbf{t}}=0\), and

\[w_{c_{\gamma}}^{(e,r)}=w_{c_{\gamma}}^{(e,l-1)}-\eta_{c_{\gamma}}\sum_{ \mathbf{t}\in T_{l,r}^{e}}\left.\frac{\partial\mathcal{L}}{\partial c_{\gamma }}\right|_{\mathbf{t}}=w_{c_{\gamma}}^{(e,l-1)}\]

Similarly, \((x_{\mathbf{t}})_{b_{\gamma}}=0\), and

\[\left|\left.\frac{\partial\mathcal{L}}{\partial b_{\gamma}}\right|_{\mathbf{t }}\right|\leq\max\left\{\left|-\frac{12N}{5}yx_{b_{\gamma}}\right|,\left|-yx_{b _{\gamma}}\right|,\left|-\frac{1}{1000N}yx_{b_{\gamma}}\right|,0\right\}=0\]

Hence \(\left.\frac{\partial\mathcal{L}}{\partial b_{\gamma}}\right|_{\mathbf{t}}=0\), and

\[w_{b_{\gamma}}^{(e,r)}=w_{b_{\gamma}}^{(e,l-1)}-\eta_{b_{\gamma}}\sum_{ \mathbf{t}\in T_{l,r}^{e}}\left.\frac{\partial\mathcal{L}}{\partial b_{\gamma }}\right|_{\mathbf{t}}=w_{b_{\gamma}}^{(e,l-1)}\]

**Lemma A.2**.: Suppose \(T\subseteq T_{0}\) is the training data and \(T_{l}:=\{\mathbf{t}^{(1,1)},\ldots,\mathbf{t}^{(1,l)}\}\). \(\forall 1\leq i\leq n,1\leq l\leq|T|\), \(w_{x_{i}}^{(1,l)}\in U(1,\frac{l+1}{6000N^{2}})\) if var (\(i\)) \(\in T_{l}\); Otherwise \(w_{x_{i}}^{(1,l)}\in U(-1,\frac{l+1}{6000N^{2}})\).

Proof.: We prove this lemma by induction.

Basic Case: Note that for all \(1\leq i\leq n\), \(w_{x_{i}}^{(0)}=-1\), and for all \(1\leq\gamma\leq m,w_{c_{\gamma}}^{(0)}=1/2,w_{b_{\gamma}}^{(0)}=-1\). We denote \(\mathbf{t}=\mathbf{t}^{(1,1)}\) to avoid cluttering. For any fixed \(i\):

(1) If \(\mathbf{t}=\)var (\(i\)). We have \(y_{\mathbf{t}}(\mathbf{w}^{(0)})^{\top}\mathbf{x}_{\mathbf{t}}^{\prime}=5w_{x_{ i}}^{(0)}=-5\), hence

\[\left.\frac{\partial\mathcal{L}}{\partial w_{x_{i}}}\right|_{\mathbf{t}}=-\frac{ 12N}{5}y_{\mathbf{t}}(x_{\mathbf{t}})_{i}=-12N\]

and

\[w_{x_{i}}^{(1,1)}=w_{x_{i}}^{(0)}-\eta_{x_{i}}\left.\frac{\partial\mathcal{L}} {\partial w_{x_{i}}}\right|_{\mathbf{t}}=-1-\frac{1}{6N}\left(-\frac{12N}{5} \right)=1\in U(1,\frac{2}{6000N^{2}})\]

(2) If \(\mathbf{t}=\)clause (\(\gamma,i,i^{\prime},i^{\prime\prime}\)). We have

\[y_{\mathbf{t}}(\mathbf{w}^{(0)})^{\top}\mathbf{x}_{\mathbf{t}}^{\prime}=w_{x_{ i}}^{(0)}+w_{x_{i^{\prime}}}^{(0)}+w_{x_{i^{\prime\prime}}}^{(0)}+w_{c_{\gamma}}^{(0)}+ \frac{1}{2}w_{b_{\gamma}}^{(0)}=-3\]

hence

\[\left.\frac{\partial\mathcal{L}}{\partial w_{x_{i}}}\right|_{\mathbf{t}}=-\frac {1}{1000N}y_{\mathbf{t}}(x_{\mathbf{t}})_{x_{i}}=-\frac{1}{1000N}\]and

\[w_{x_{i}}^{(1,1)} =w_{x_{i}}^{(0)}-\eta_{x_{i}}\left.\frac{\partial\mathcal{L}}{ \partial w_{x_{i}}}\right|_{\mathbf{t}}=-1-\frac{1}{6N}\left(-\frac{1}{1000N}\right)\] \[=-1+\frac{1}{6000N^{2}}\in U(-1,\frac{2}{6000N^{2}})\]

(3) Otherwise, \(w_{x_{i}}\) will not be updated. Therefore \(w_{x_{i}}^{(1,1)}=w_{x_{i}}^{(0)}=-1\in U(-1,\frac{2}{6000N^{2}})\).

Hence this lemma is true for \(l=1\).

Induction Step: Suppose the lemma is true for \(l<|T|\). We prove that this lemma remains true for \(l+1\). We denote \(\mathbf{t}=\mathbf{t}^{(1,l+1)}\) to avoid cluttering. This makes sense since \(l+1\leq|T|\) and thus \(\mathbf{t}\in T\). For any fixed \(i\):

(1) If \(\mathbf{t}=\)var(_i_), then var(_i_)\(\not\in T_{l}\) because there are at most one var(_i_) in \(T\) for each \(i\).

Therefore \(w_{x_{i}}^{(1,l)}\in U(-1,\frac{l+1}{6000N^{2}})\). We have \(y_{\mathbf{t}}(\mathbf{w}^{(1,l)})^{\top}\mathbf{x}_{\mathbf{t}}^{\prime}=5w_ {x_{i}}^{(1,l)}\in U(-5,0.01)\), and \(\left.\frac{\partial\mathcal{L}}{\partial w_{x_{i}}}\right|_{\mathbf{t}}=- \frac{12N}{5}y_{\mathbf{t}}(x_{\mathbf{t}})_{i}=-12N\). Hence

\[w_{x_{i}}^{(1,l+1)} =w_{x_{i}}^{(1,l)}-\eta_{x_{i}}\left.\frac{\partial\mathcal{L}} {\partial w_{x_{i}}}\right|_{\mathbf{t}}=w_{x_{i}}^{(1,l)}-\frac{1}{6N}\left( -\frac{12N}{5}\right)\] \[=w_{x_{i}}^{(1,l)}+2\in U(1,\frac{l+2}{6000N^{2}})\]

(2) If \(\mathbf{t}=\)clause(\(\gamma,i,i^{\prime},i^{\prime\prime}\)). In this case, clause(\(\gamma,\cdot,\cdot,\cdot\))\(\not\in T_{1,l}^{1}\) and by Lemma A.1 we have \(w_{c_{\gamma}}^{(1,l)}=w_{c_{\gamma}}^{(0)},w_{b_{\gamma}}^{(1,l)}=w_{b_{ \gamma}}^{(0)}\). From the induction hypothesis we have

\[w_{x_{i}}^{(1,l)},w_{x_{i^{\prime}}}^{(1,l)},w_{x_{i^{\prime\prime}}}^{(1,l)} \in U(\pm 1,\frac{l+1}{6000N^{2}})\]

and thus

\[y_{\mathbf{t}}(\mathbf{w}^{(1,l)})^{\top}\mathbf{x}_{\mathbf{t}}^{\prime} =w_{x_{i}}^{(1,l)}+w_{x_{i^{\prime}}}^{(1,l)}+w_{x_{i^{\prime \prime}}}^{(1,l)}+w_{c_{\gamma}}^{(1,l)}+\frac{1}{2}w_{b_{\gamma}}^{(1,l)}\] \[=w_{x_{i}}^{(1,l)}+w_{x_{i^{\prime}}}^{(1,l)}+w_{x_{i^{\prime \prime}}}^{(1,l)}\] \[\in\bigcup_{x_{0}\in\{\pm 1,\pm 3\}}U(x_{0},\frac{3(l+1)}{6000N^{2}}) \subseteq\bigcup_{x_{0}\in\{\pm 1,\pm 3\}}U(x_{0},0.01)\]

We have \(\left.\frac{\partial\mathcal{L}}{\partial w_{x_{i}}}\right|_{\mathbf{t}}=-\frac {1}{1000N}\) and \(w_{x_{i}}^{(1,l+1)}=w_{x_{i}}^{(1,l)}-\eta_{x_{i}}\left.\frac{\partial\mathcal{ L}}{\partial w_{x_{i}}}\right|_{\mathbf{t}}=w_{x_{i}}^{(1,l)}+\frac{1}{6000N^{2}}\). Consider the following cases:

* If var(_i_)\(\in T_{l}\), then var(_i_)\(\in T_{l+1}\) and \(w_{x_{i}}^{(1,l)}\in U(1,\frac{l+1}{6000N^{2}})\). Therefore \(w_{x_{i}}^{(1,l+1)}\in U(1,\frac{l+2}{6000N^{2}})\).
* If var(_i_)\(\not\in T_{l}\), then var(_i_)\(\not\in T_{l+1}\) and \(w_{x_{i}}^{(1,l)}\in U(-1,\frac{l+1}{6000N^{2}})\). Therefore \(w_{x_{i}}^{(1,l+1)}\in U(-1,\frac{l+2}{6000N^{2}})\).

(3) Otherwise, \(w_{x_{i}}\) will not be updated, and \(w_{x_{i}}^{(1,l+1)}=w_{x_{i}}^{(1,l)}\). If var(_i_)\(\in T_{l}\) then var(_i_)\(\in T_{l+1}\) and \(w_{x_{i}}^{(1,l+1)}\in U(1,\frac{l+2}{6000N^{2}})\); Otherwise var(_i_)\(\not\in T_{l+1}\) and \(w_{x_{i}}^{(1,l+1)}\in U(-1,\frac{l+2}{6000N^{2}})\).

Hence if the lemma is true for \(l<|T|\), it is also true for \(l+1\). Therefore, the lemma is true for all \(1\leq l\leq|T|\). 

**Corollary A.1**.: Suppose \(T\subseteq T_{0}\) is the training data. \(\forall 1\leq i\leq n,1\leq l\leq|T|\), if var(_i_)\(\in T\), then \(w_{x_{i}}^{(1)}\in U(1,\frac{1}{6000N})\). Otherwise \(w_{x_{i}}^{(1)}\in U(-1,\frac{1}{6000N})\).

Proof.: Note that \(w^{(1)}_{x_{i}}=w^{(1,|T|)}_{x_{i}}\) and \(N=2m+n+1\). By Lemma A.2, if var (\(i\))\(\in T\) we have

\[w^{(1,|T|)}_{x_{i}}\in U(1,\frac{|T|+1}{6000N^{2}})\subseteq U(1,\frac{m+n+1}{60 00N^{2}})\subseteq U(1,\frac{1}{6000N})\]

If var (\(i\))\(\not\in T\), we have

\[w^{(1,|T|)}_{x_{i}}\in U(-1,\frac{|T|+1}{6000N^{2}})\subseteq U(-1,\frac{m+n+1} {6000N^{2}})\subseteq U(-1,\frac{1}{6000N})\]

**Lemma A.3**.: Suppose \(T\subseteq T_{0}\) is the training data. \(\forall 1\leq\gamma\leq m\), if \(\exists 1\leq i_{1},i_{2},i_{3}\leq n\) such that clause(\(\gamma,i_{1},i_{2},i_{3}\)) \(\in T\), then \(w^{(1)}_{b_{\gamma}}=0,w^{(1)}_{c_{\gamma}}=\frac{1}{2}+\frac{1}{200N}\); Otherwise, \(w^{(1)}_{b_{\gamma}}=-1,w^{(1)}_{c_{\gamma}}=\frac{1}{2}\).

Proof.: (1) If such \(\mathbf{t}_{\gamma}=\)clause(\(\gamma,i_{1},i_{2},i_{3}\)) exists in \(T\), by Lemma A.2 we have

\[w^{(1,o^{1}_{\mathbf{t}_{\gamma}})}_{x_{i_{1}}}+w^{(1,o^{1}_{\mathbf{t}_{ \gamma}})}_{x_{i_{2}}}+w^{(1,o^{1}_{\mathbf{t}_{\gamma}})}_{x_{i_{3}}}\in \bigcup_{x_{0}\in\{\pm 1,\pm 3\}}U(x_{0},\frac{3(o^{1}_{\mathbf{t}_{\gamma}}+1)}{6000 N^{2}})\subseteq\bigcup_{x_{0}\in\{\pm 1,\pm 3\}}U(x_{0},0.01)\]

By Lemma A.1 we have \(w^{(1,o^{1}_{\mathbf{t}_{\gamma}}-1)}_{c_{\gamma}}=w^{(0)}_{c_{\gamma}}\) and \(w^{(1,o^{1}_{\mathbf{t}_{\gamma}}-1)}_{b_{\gamma}}=w^{(0)}_{b_{\gamma}}\) because clause(\(\gamma,\cdot,\cdot,\cdot\))\(\not\in T^{1}_{1,o_{\mathbf{t}_{\gamma}}-1}\). Hence

\[y_{\mathbf{t}_{\gamma}}(\mathbf{w}^{(1,o^{1}_{\mathbf{t}_{\gamma }}-1)})^{\top}\mathbf{x}^{\prime}_{\mathbf{t}_{\gamma}} =w^{(1,o^{1}_{\mathbf{t}_{\gamma}})}_{x_{i_{1}}}+w^{(1,o^{1}_{ \mathbf{t}_{\gamma}})}_{x_{i_{2}}}+w^{(1,o^{1}_{\mathbf{t}_{\gamma}})}_{x_{i_{ 3}}}+w^{(1,o^{1}_{\mathbf{t}_{\gamma}}-1)}_{c_{\gamma}}+\frac{1}{2}w^{(1,o^{1 }_{\mathbf{t}_{\gamma}}-1)}_{b_{\gamma}}\] \[=w^{(1,o^{1}_{\mathbf{t}_{\gamma}})}_{x_{i_{1}}}+w^{(1,o^{1}_{ \mathbf{t}_{\gamma}})}_{x_{i_{2}}}+w^{(1,o^{1}_{\mathbf{t}_{\gamma}})}_{x_{i_{ 3}}}+w^{(1,o^{1}_{\mathbf{t}_{\gamma}}-1)}_{c_{\gamma}}\] \[\in\bigcup_{x_{0}\in\{\pm 1,\pm 3\}}U(x_{0},0.01)\]

We have \(\left.\frac{\partial\mathcal{L}}{\partial w_{c_{\gamma}}}\right|_{\mathbf{t} _{\gamma}}=-\frac{1}{1000N}\), and

\[w^{(1,o^{1}_{\mathbf{t}_{\gamma}})}_{c_{\gamma}}=w^{(1,o^{1}_{\mathbf{t}_{ \gamma}}-1)}_{c_{\gamma}}-\eta_{c_{\gamma}}\left.\frac{\partial\mathcal{L}}{ \partial w_{c_{\gamma}}}\right|_{\mathbf{t}_{\gamma}}=\frac{1}{2}+5\times \frac{1}{1000N}=\frac{1}{2}+\frac{1}{200N}\]

Similarly, \(\left.\frac{\partial\mathcal{L}}{\partial w_{b_{\gamma}}}\right|_{\mathbf{t} _{\gamma}}=-\frac{1}{2000N}\) and

\[w^{(1,o^{1}_{\mathbf{t}_{\gamma}})}_{b_{\gamma}}=w^{(1,o^{1}_{\mathbf{t}_{ \gamma}}-1)}_{b_{\gamma}}-\eta_{b_{\gamma}}\left.\frac{\partial\mathcal{L}}{ \partial w_{c_{\gamma}}}\right|_{\mathbf{t}_{\gamma}}=-1-2000N\times(-\frac{1} {2000N})=0\]

Note also that clause(\(\gamma,\cdot,\cdot,\cdot\))\(\not\in T^{1}_{o_{\mathbf{t}_{\gamma}},|T|}\), by Lemma A.1 we have

\(w^{(1)}_{c_{\gamma}}=w^{(1,|T|)}_{c_{\gamma}}=w^{(1,o^{1}_{\mathbf{t}_{\gamma}})}_{c_{ \gamma}}=\frac{1}{2}+\frac{1}{200N}\) and \(w^{(1)}_{b_{\gamma}}=w^{(1,|T|)}_{b_{\gamma}}=w^{(1,o^{1}_{\mathbf{t}_{\gamma}}) }_{b_{\gamma}}=0\).

(2) If such \(\mathbf{t}_{\gamma}=\)clause(\(\gamma,i_{1},i_{2},i_{3}\)) does not exist in \(T\), by Lemma A.1 we have \(w^{(1)}_{c_{\gamma}}=w^{(0)}_{c_{\gamma}}=\frac{1}{2}\) and \(w^{(1)}_{b_{\gamma}}=w^{(0)}_{b_{\gamma}}=-1\). 

**Lemma A.4**.: Suppose \(T\subseteq T_{0}\) and \(C_{l}\) be the number of clause() in \(T^{2}_{1,l}\). \(\forall 1\leq i\leq n,1\leq l\leq|T|\), \(w^{(2,l)}_{x_{i}}\in U(1,\frac{C_{l}+1/2}{6N})\) if var(\(i\))\(\in T\); Otherwise \(w^{(2,l)}_{x_{i}}\in U(-1,\frac{C_{l}+1/2}{6N})\).

Proof.: Similar to the proof of A.2, we prove this lemma by induction.

Basic Case: Note that for all \(1\leq i\leq n\), \(w^{(1)}_{x_{i}}=U(\pm 1,\frac{1}{6000N})\), and for all \(1\leq\gamma\leq m,w^{(1)}_{c_{\gamma}}\in\{\frac{1}{2},\frac{1}{2}+\frac{1}{200 N}\},w^{(1)}_{b_{\gamma}}\in\{-1,0\}\). We denote \(\mathbf{t}=\mathbf{t}^{(2,1)}\) to avoid cluttering. For any fixed \(i\):

(1) If \(\mathbf{t}=\)var(\(i\)), \(C_{1}=0\). By Corollary A.1, \(w^{(1)}_{x_{i}}=U(1,\frac{1}{6000N})\). We have

\[y_{\mathbf{t}}(\mathbf{w}^{(1)})^{\top}\mathbf{x}^{\prime}_{\mathbf{t}}=5w^{(1)} _{x_{i}}\in U(5,\frac{1}{1200N})\]hence \(\left.\frac{\partial\mathcal{L}}{\partial w_{x_{i}}}\right|_{\mathbf{t}}=0\), and

\[w_{x_{i}}^{(2,1)}=w_{x_{i}}^{(1)}\in U(1,\frac{1}{6N})=U(1,\frac{C_{l}+1/2}{6N})\]

(2) If \(\mathbf{t=}\)clause(\(\gamma,i,i^{\prime},i^{\prime\prime}\)), \(C_{1}=1\). By Lemma A.3, we have \(w_{c_{\gamma}}^{(1)}=\frac{1}{2}+\frac{1}{200N}\) and \(w_{b_{\gamma}}^{(1)}=0\). Therefore,

\[y_{\mathbf{t}}(\mathbf{w}^{(1)})^{\top}\mathbf{x^{\prime}_{t}} =w_{x_{i}}^{(1)}+w_{x_{i^{\prime}}}^{(1)}+w_{x_{i^{\prime\prime}} }^{(1)}+w_{c_{\gamma}}^{(1)}+\frac{1}{2}w_{b_{\gamma}}^{(1)}\] \[=w_{x_{i}}^{(1)}+w_{x_{i^{\prime}}}^{(1)}+w_{x_{i^{\prime\prime}} }^{(1)}+\frac{1}{2}-\frac{1}{200N}\] \[\in\bigcup_{x_{0}\in\{\frac{1}{2}\pm 1,\frac{1}{2}\pm 3\}}U(x_{0},0.01)\]

hence \(\left.\frac{\partial\mathcal{L}}{\partial w_{x_{i}}}\right|_{\mathbf{t}}\in\{0,-yx_{x_{i}}\}=\{-1,0\}\), and \(\eta_{x_{i}}\left.\frac{\partial\mathcal{L}}{\partial w_{x_{i}}}\right|_{ \mathbf{t}}\in\{-\frac{1}{6N},0\}\).

By Corollary A.1, if \(\mathtt{var}(i)\)\(\in T\), we have

\[w_{x_{i}}^{(2,1)}=w_{x_{i}}^{(1)}-\eta_{x_{i}}\left.\frac{\partial\mathcal{L}} {\partial w_{x_{i}}}\right|_{\mathbf{t}}\in U(1,\frac{3/2}{6N})=U(1,\frac{C_{ l}+1/2}{6N})\]

If \(\mathtt{var}(i)\)\(\not\in T\), we have

\[w_{x_{i}}^{(2,1)}=w_{x_{i}}^{(1)}-\eta_{x_{i}}\left.\frac{\partial\mathcal{L}} {\partial w_{x_{i}}}\right|_{\mathbf{t}}\in U(-1,\frac{3/2}{6N})=U(-1,\frac{C _{l}+1/2}{6N})\]

(3) Otherwise, \(w_{x_{i}}\) will not be updated and \(C_{1}\leq 1\). Therefore if \(\mathtt{var}(i)\)\(\in T\),

\[w_{x_{i}}^{(2,1)}=w_{x_{i}}^{(1)}\in U(1,\frac{3/2}{6N})\subseteq U(1,\frac{C _{l}+1/2}{6N})\]

If \(\mathtt{var}(i)\)\(\not\in T\),

\[w_{x_{i}}^{(2,1)}=w_{x_{i}}^{(1)}\in U(-1,\frac{3/2}{6N})\subseteq U(-1,\frac{C _{l}+1/2}{6N})\]

Hence this lemma is true for \(l=1\).

Induction Step: Suppose the lemma is true for \(l<|T|\). We prove that this lemma remains true for \(l+1\). We denote \(\mathbf{t}=\mathbf{t}^{(2,l+1)}\) to avoid cluttering. This makes sense since \(l+1\leq|T|\) and thus \(\mathbf{t}\in T\). For any fixed \(i\):

(1) If \(\mathbf{t=}\)var(\(i\)), \(C_{l+1}=C_{l}\). By Corollary A.1, \(w_{x_{i}}^{(2,l)}\in U(1,\frac{C_{l}+1/2}{6N})\).

We have \(y_{\mathbf{t}}(\mathbf{w}^{(2,l)})^{\top}\mathbf{x^{\prime}_{t}}=5w_{x_{i}}^{ (2,l)}\in U(5,1/6)\) and \(\left.\frac{\partial\mathcal{L}}{\partial w_{x_{i}}}\right|_{\mathbf{t}}=0\).Hence \(w_{x_{i}}^{(2,l+1)}=w_{x_{i}}^{(2,l)}\in U(1,\frac{C_{l+1}+1/2}{6N})\).

(2) If \(\mathbf{t=}\)clause(\(\gamma,i,i^{\prime},i^{\prime\prime}\)), \(C_{l+1}=C_{l}+1\). In this case, \(\mathtt{clause}(\gamma,\cdot,\cdot,\cdot)\not\in T_{1,l}^{2}\) and by Lemma A.1 and Lemma A.3 we have \(w_{c_{\gamma}}^{(2,l)}=w_{c_{\gamma}}^{(1)}=\frac{1}{2}+\frac{1}{200N},w_{b_{ \gamma}}^{(2,l)}=w_{b_{\gamma}}^{(1)}=0\). From the induction hypothesis we have \(w_{x_{i}}^{(2,l)},w_{x_{i^{\prime}}}^{(2,l)},w_{x_{i^{\prime\prime}}}^{(2,l)}\in U (\pm 1,\frac{C_{l}+1/2}{6N})\). Noting that

\[\frac{C_{l}+1/2}{6N}\leq\frac{m+1/2}{6N}=\frac{m+1/2}{(n+2(m+1/2))}\leq\frac{1 }{12}\]

we have

\[y_{\mathbf{t}}(\mathbf{w}^{(2,l)})^{\top}\mathbf{x^{\prime}_{t}} =w_{x_{i}}^{(2,l)}+w_{x_{i^{\prime}}}^{(2,l)}+w_{x_{i^{\prime \prime}}}^{(2,l)}+w_{c_{\gamma}}^{(2,l)}+\frac{1}{2}w_{b_{\gamma}}^{(2,l)}\] \[=w_{x_{i}}^{(2,l)}+w_{x_{i^{\prime}}}^{(2,l)}+w_{x_{i^{\prime \prime}}}^{(2,l)}+\frac{1}{2}+\frac{1}{200N}\] \[\in\bigcup_{x_{0}\in\{\frac{1}{2}\pm 1,\frac{1}{2}\pm 3\}}U\left(x_{0}, \frac{3(C_{l}+1/2)}{6N}+\frac{1}{200N}\right)\] \[\subseteq\bigcup_{x_{0}\in\{\frac{1}{2}\pm 1,\frac{1}{2}\pm 3\}}U(x_{0},0.26)\]And thus \(\left.\frac{\partial\mathcal{L}}{\partial w_{x_{i}}}\right|_{\mathbf{t}}\in\{0,-yx _{x_{i}}\}=\{-1,0\}\), and \(\eta_{x_{i}}\left.\frac{\partial\mathcal{L}}{\partial w_{x_{i}}}\right|_{ \mathbf{t}}\in\{-\frac{1}{6N},0\}\).

By Corollary A.1, if \(\mathsf{var}(i)\in T\), \(w_{x_{i}}^{(2,l+1)}=w_{x_{i}}^{(l)}-\eta_{x_{i}}\left.\frac{\partial\mathcal{ L}}{\partial w_{x_{i}}}\right|_{\mathbf{t}}\in U(1,\frac{C_{l}+3/2}{6N})=U(1, \frac{C_{l+1}+1/2}{6N})\); if \(\mathsf{var}(i)\not\in T\), \(w_{x_{i}}^{(2,l+1)}=w_{x_{i}}^{(l)}-\eta_{x_{i}}\left.\frac{\partial\mathcal{ L}}{\partial w_{x_{i}}}\right|_{\mathbf{t}}\in U(-1,\frac{C_{l}+3/2}{6N})=U(-1, \frac{C_{l+1}+1/2}{6N})\).

(3) Otherwise, \(w_{x_{i}}\) will not be updated. We have \(C_{l+1}\leq C_{l}+1\)\(w_{x_{i}}^{(2,l+1)}=w_{x_{i}}^{(2,l)}\). If \(\mathsf{var}(i)\in T\) then \(w_{x_{i}}^{(2,l+1)}\in U(1,\frac{C_{l+1}+1/2}{6N})\); If \(\mathsf{var}(i)\not\in T\) then \(w_{x_{i}}^{(2,l+1)}\in U(-1,\frac{C_{l+1}+1/2}{6N})\).

Hence if the lemma is true for \(l<|T|\), it is also true for \(l+1\). Therefore, the lemma is true for all \(1\leq l\leq|T|\). 

**Corollary A.2**.: Suppose \(T\subseteq T_{0}\) is the training data. \(\forall 1\leq i\leq n\), if \(\mathsf{var}(i)\in T\), then \(w_{x_{i}}^{(2)}\in U(1,0.1)\). Otherwise \(w_{x_{i}}^{(2)}\in U(-1,0.1)\).

Proof.: Note that \(w_{x_{i}}^{(2)}=w_{x_{i}}^{(2,|T|)}\) and \(C_{|T|}\leq m\). By Lemma A.4, if \(\mathsf{var}\left(i\right)\in T\) we have

\[w_{x_{i}}^{(2,|T|)}\in U(1,\frac{C_{|T|}+1/2}{6N})\subseteq U(1,\frac{m+1/2}{ 6N})\subseteq U(1,\frac{1}{12})\subseteq U(1,0.1)\]

If \(\mathsf{var}\left(i\right)\not\in T\), we have

\[w_{x_{i}}^{(1,|T|)}\in U(-1,\frac{C_{|T|}+1/2}{6N})\subseteq U(-1,\frac{m+1/2} {6N})\subseteq U(-1,\frac{1}{12})\subseteq U(-1,0.1)\]

**Lemma A.5**.: Suppose \(T\subseteq T_{0}\) is the training data. \(\forall 1\leq i\leq m\), if \(\exists 1\leq i_{1},i_{2},i_{3}\leq n\) such that \(\mathsf{clause}(i,i_{1},i_{2},i_{3})\in T\), then

1. \(w_{b_{j}}^{(2)}=1000N\);
2. \(w_{c_{j}}^{(2)}=\frac{11}{2}+\frac{1}{200N}\) if exactly one of \(\mathsf{var}(i_{1})\), \(\mathsf{var}(i_{2})\), \(\mathsf{var}(i_{3})\) is in \(T\). Otherwise \(w_{c_{j}}^{(2)}=\frac{1}{2}+\frac{1}{200N}\).

Otherwise, \(w_{b_{i}}^{(2)}=-1,w_{c_{i}}^{(2)}=\frac{1}{2}\).

Proof.: (1) If such \(\mathbf{t}_{\gamma}=\mathsf{clause}(\gamma,i_{1},i_{2},i_{3})\) exists in \(T\), by Lemma A.4 we have

\[w_{x_{i_{1}}}^{(2,o_{\gamma}^{1})},w_{x_{i_{2}}}^{(2,o_{\gamma}^{1})},w_{x_{i_ {3}}}^{(2,o_{\gamma}^{1})}\in U(\pm 1,\frac{m+1/2}{6N})\subseteq U(\pm 1,\frac{1}{12N})\]

By Lemma A.1 we have \(w_{c_{\gamma}}^{(2,o_{\gamma}^{1}-1)}=w_{c_{\gamma}}^{(1)}=\frac{1}{2}+\frac{ 1}{200N}\) and \(w_{b_{\gamma}}^{(2,o_{\gamma}^{1}-1)}=w_{b_{\gamma}}^{(1)}=0\) because \(\mathsf{clause}(\gamma,\cdot,\cdot,\cdot)\not\in T_{1,o_{\gamma}-1}^{1}\). Consider the following two cases:

(a) If exactly one of \(\mathsf{var}(i_{1})\), \(\mathsf{var}(i_{2})\), \(\mathsf{var}(i_{3})\) is in \(T\), by Corollary A.2 we have

\[y_{\mathbf{t}_{\gamma}}(\mathbf{w}^{(2,o_{\gamma}^{1}-1)})^{ \top}\mathbf{x}_{\mathbf{t}_{\gamma}}^{\prime} =w_{x_{i_{1}}}^{(2,o_{\gamma}^{1},-1)}+w_{x_{i_{2}}}^{(2,o_{\gamma }^{1},-1)}+w_{x_{i_{3}}}^{(2,o_{\gamma}^{1},-1)}+w_{c_{\gamma}}^{(2,o_{\gamma }^{1},-1)}+\frac{1}{2}w_{b_{\gamma}}^{(2,o_{\gamma}^{1},-1)}\] \[=w_{x_{i_{1}}}^{(2,o_{\gamma}^{1},-1)}+w_{x_{i_{2}}}^{(2,o_{\gamma }^{1},-1)}+w_{x_{i_{3}}}^{(2,o_{\gamma}^{1},-1)}+\frac{1}{2}+\frac{1}{200N}\] \[\in U(-\frac{1}{2},\frac{3}{12N}+\frac{1}{200N})\subseteq U(-\frac{ 1}{2},0.26)\]

Hence \(\left.\frac{\partial\mathcal{L}}{\partial w_{c_{\gamma}}}\right|_{\mathbf{t}_{ \gamma}}=-1\), and

\[w_{c_{\gamma}}^{(2,o_{\gamma}^{1})}=w_{c_{\gamma}}^{(2,o_{\gamma}^{1}-1)}-\eta_{ c_{\gamma}}\left.\frac{\partial\mathcal{L}}{\partial w_{c_{\gamma}}}\right|_{\mathbf{t}_{ \gamma}}=\frac{1}{2}+\frac{1}{200N}+5=\frac{11}{2}+\frac{1}{200N}\]Similarly,

\[w_{b_{\gamma}}^{(2,o_{\tau_{\gamma}}^{1})}=w_{b_{\gamma}}^{(2,o_{\tau_{\gamma}}^{ 1}-1)}-\eta_{b_{\gamma}}\left.\frac{\partial\mathcal{L}}{\partial w_{b_{\gamma}} }\right|_{\mathbf{t}_{\gamma}}=1000N\]

Note also that \(\mathtt{clause}(\gamma,\cdot,\cdot,\cdot)\not\in T^{1}_{o_{\mathbf{t}_{\gamma}},|T|}\), by Lemma A.1 we have \(w_{c_{\gamma}}^{(2)}=w_{c_{\gamma}}^{(2,|T|)}=w_{c_{\gamma}}^{(2,o_{\tau_{ \gamma}}^{1})}=\frac{11}{2}-\frac{1}{200N}\) and \(w_{b_{\gamma}}^{(2)}=w_{b_{\gamma}}^{(2,|T|)}=w_{b_{\gamma}}^{(2,o_{\tau_{ \gamma}}^{1})}=1000N\).

(b) Otherwise, we have

\[y_{\mathbf{t}_{\gamma}}(\mathbf{w}^{(2,o_{\tau_{\gamma}}^{1}-1)})^{\top} \mathbf{x}_{\mathbf{t}_{\gamma}}^{\prime} =w_{x_{i_{1}}}^{(2,o_{\tau_{\gamma}}^{1}-1)}+w_{x_{i_{2}}}^{(2,o_ {\tau_{\gamma}}^{1}-1)}+w_{x_{i_{3}}}^{(2,o_{\tau_{\gamma}}^{1}-1)}+w_{c_{ \gamma}}^{(2,o_{\tau_{\gamma}}^{1}-1)}+\frac{1}{2}w_{b_{\gamma}}^{(2,o_{\tau_ {\gamma}}^{1}-1)}\] \[=w_{x_{i_{1}}}^{(2,o_{\tau_{\gamma}}^{1}-1)}+w_{x_{i_{2}}}^{(2,o_ {\tau_{\gamma}}^{1}-1)}+w_{x_{i_{3}}}^{(2,o_{\tau_{\gamma}}^{1}-1)}+\frac{1}{2 }+\frac{1}{200N}\] \[\in\bigcup_{x_{0}\in\{-\frac{7}{2},\frac{1}{2},\frac{5}{2}\}}U(x_ {0},\frac{3}{12N}+\frac{1}{200N})\subseteq\bigcup_{x_{0}\in\{-\frac{7}{2}, \frac{1}{2},\frac{5}{2}\}}U(x_{0},0.26)\]

Hence \(\left.\frac{\partial\mathcal{L}}{\partial w_{c_{\gamma}}}\right|_{\mathbf{t}_ {\gamma}}=\left.\frac{\partial\mathcal{L}}{\partial w_{b_{\gamma}}}\right|_{ \mathbf{t}_{\gamma}}=0\), so \(w_{c_{\gamma}}^{(2,o_{\tau_{\gamma}}^{1})}=w_{c_{\gamma}}^{(2,o_{\tau_{\gamma} }^{1}-1)}=\frac{1}{2}+\frac{1}{200N},w_{b_{\gamma}}^{(2,o_{\tau_{\gamma}}^{1 })}=w_{b_{\gamma}}^{(2,o_{\tau_{\gamma}}^{1}-1)}=0\).

Note also that \(\mathtt{clause}(\gamma,\cdot,\cdot,\cdot)\not\in T^{1}_{o_{\mathbf{t}_{\gamma}},|T|}\), by Lemma A.1 we have \(w_{c_{\gamma}}^{(2)}=w_{c_{\gamma}}^{(2,|T|)}=w_{c_{\gamma}}^{(2,o_{\tau_{ \gamma}}^{1})}=\frac{1}{2}+\frac{1}{200N}\) and \(w_{b_{\gamma}}^{(2)}=w_{b_{\gamma}}^{(2,|T|)}=w_{b_{\gamma}}^{(2,o_{\tau_{ \gamma}}^{1})}=0\).

(2) If such \(\mathbf{t}_{\gamma}=\mathtt{clause}(\gamma,i_{1},i_{2},i_{3})\) does not exist in \(T\), by Lemma A.1 and Lemma A.3 we have \(w_{c_{\gamma}}^{(2)}=w_{c_{\gamma}}^{(1)}=\frac{1}{2}\) and \(w_{b_{\gamma}}^{(2)}=w_{b_{\gamma}}^{(1)}=-1\). 

Moreover, \(\mathbf{w}\) reaches its fixpoint at the end of the second epoch and will no longer be updated.

**Lemma A.6**.: \(\mathbf{w}^{(2)}=\mathbf{w}^{(3)}\)_._

Proof.: Suppose \(\mathbf{w}^{(2)}\neq\mathbf{w}^{(3)}\), then there exists \(1\leq i\leq N\) such that \(w_{i}^{(2)}\neq w_{i}^{(3)}\), and there are some training sample \(\mathbf{t}\) in the training data such that \(\left.\frac{\partial\mathcal{L}}{\partial w_{i}^{(2)}}\right|_{\mathbf{t}}\neq 0\). Let \(\mathbf{t}=(\mathbf{x_{t}},y_{\mathbf{t}})\) and \(\mathbb{I}=U(-5,0.01)\cup U(-\frac{1}{2},0.26)\cup\left(\bigcup_{x_{0}\in\{ \pm 1,\pm 3\}}U(x_{0},0.01)\right)\). By (2) we have \(y_{\mathbf{t}}(\mathbf{w}^{(2)})^{\top}\mathbf{x_{t}}^{\prime}\in\mathbb{I}\). At least one of the following is true:

1. \(\exists 1\leq i\leq n,\mathbf{t}=\mathtt{var}(i)\). According to lemma A.2, \(y_{\mathbf{t}}(\mathbf{w}^{(2)})^{\top}\mathbf{x_{t}}^{\prime}=yw_{x_{i}}^{(2)} x_{i}\in U(5,0.5)\subseteq\mathbb{R}\setminus\mathbb{I}\), contradicting to \(y_{\mathbf{t}}(\mathbf{w}^{(2)})^{\top}\mathbf{x_{t}}^{\prime}\in\mathbb{I}\).
2. \(\exists 1\leq i\leq m\) and \(1\leq i_{1},i_{2},i_{3}\leq n\), such that \(\mathbf{t}=\mathtt{clause}(i,i_{1},i_{2},i_{3})\). According to lemma A.5, we have \[y_{\mathbf{t}}(\mathbf{w}^{(2)})^{\top}\mathbf{x_{t}}^{\prime} =w_{b_{i}}^{(2)}+w_{c_{i}}^{(2)}+w_{x_{i_{1}}}^{(2)}+w_{x_{i_{2}}} ^{(2)}+w_{x_{i_{3}}}^{(2)}\] \[\geq 1000N+\frac{1}{2}+\frac{1}{200N}+3\times(-1-0.1)\] \[\geq 1000-3.3\geq 996\] We have \(y_{\mathbf{t}}(w^{(2)})^{\top}\mathbf{x_{t}}^{\prime}\not\in\mathbb{I}\), another contradiction.

Therefore \(\mathbf{w}^{(2)}=\mathbf{w}^{(3)}\), \(\mathbf{w}\) reaches its fixpoint at the end of the second epoch. In other words, \(\mathbf{w}^{*}=\mathbf{w}^{(2)}\). 

We are now ready to give a rigorous proof of theorem 3.1.

Proof of theorem 3.1.: It only suffices to prove the correctness of the reduction in section 3.

If. Suppose \(\varphi\in\)Monotone 1-in-3 SAT, then there is a truth assignment \(\nu(\cdot)\) that assigns exactly one variable in each clause of \(\varphi\) is true. Let \(\Delta=\{\mathtt{var}(i)|\nu(x_{i})=\mathtt{False}\}\). Let \(\mathbf{w}^{\prime}\) be the parameter of \(\mathtt{SGD}_{\Lambda}(T_{0}\setminus\Delta)\). By Lemma A.5, \((w^{\prime})_{c_{\gamma}}=\frac{11}{2}+\frac{1}{200N}\) for all \(1\leq\gamma\leq m\), hence

\[(\mathbf{w}^{\prime})^{\top}\mathbf{x}_{\text{test}}=\sum_{\gamma=1}^{m}w^{ \prime}_{c_{\gamma}}\geq\frac{11m}{2}+\frac{-11m+5}{2}=\frac{5}{2}>0\]

and \(\lambda_{\mathbf{w}^{\prime}}(\mathbf{x}_{\text{test}})=1\), thus \(\mathtt{SGD}_{\Lambda}(T_{0})\) is thus debuggable.

Only if. Suppose \(\mathtt{SGD}_{\Lambda}(T_{0})\) is debuggable, there will be a \(\Delta\) such that \(\mathtt{SGD}_{\Lambda}(T_{0},\mathbf{x}_{\text{test}})=y_{\text{test}}\). We denote \(\mathbf{w}^{\prime}\) as the parameter trained by SGD on \(T_{0}\setminus\Delta\). We have \(\lambda_{\mathbf{w}^{\prime}}(\mathbf{x}_{\text{test}})=1\) and \((\mathbf{w}^{\prime})^{\top}\mathbf{x}_{\text{test}}\geq 0\). By Lemma A.5, \(w^{\prime}_{c_{\gamma}}=\{\frac{1}{2}+\frac{1}{200N},\frac{\Gamma 1}{2}+\frac{1}{200N}\}\). Suppose \(w_{c^{*}}=\frac{1}{2}+\frac{1}{200N}\), then

\[(\mathbf{w}^{\prime})^{\top}\mathbf{x}_{\text{test}} =w_{c^{*}}+\sum_{c_{\gamma}\neq c^{*}}w_{c_{\gamma}}\] \[\leq\frac{11}{2}(m-1)+\frac{1}{2}+\frac{m}{200N}-\frac{11m}{2}+ \frac{5}{2}\] \[=-\frac{5}{2}+\frac{m}{200N}\] \[\leq-\frac{5}{2}+\frac{1}{200}=-2.495<0\]

leading to a contradiction.

As a consequence, \(w^{\prime}_{c_{\gamma}}=\frac{11}{2}+\frac{1}{200N}\) for all \(1\leq\gamma\leq m\). By Lemma A.5, exactly one of \(\mathtt{var}(i_{1})\),\(\mathtt{var}(i_{2})\),\(\mathtt{var}(i_{3})\) is in \(T_{0}\setminus\Delta\) for each \(c_{\gamma}=(x_{i_{1}}\lor x_{i_{2}}\lor x_{i_{3}})\). Consider a truth assignment \(\nu\) that maps every \(x_{i}\) to False where \(\mathtt{var}(i)\in\Delta\), and maps the rest to True. Then \(\nu\) assigns exactly one variable true in each \(c_{\gamma}=(x_{i_{1}}\lor x_{i_{2}}\lor x_{i_{3}})\) if and only if exactly one of \(\mathtt{var}(i_{1})\),\(\mathtt{var}(i_{2})\),\(\mathtt{var}(i_{3})\) is in \(T_{0}\setminus\Delta\). Hence \(\nu\) is a truth assignment that assigns true to exactly one variable in each clause of \(\varphi\), and thus \(\varphi\) is a yes-instance of Monotone 1-in-3 SAT. 

## Appendix B Detailed Proofs for Section 4

### Proof of Theorem 4.4

Proof.: We build a reduction from the Subset Sum problem with a fixed size, which is NP-hard as a particular case of the class of knapsack problems [26]. Formally, it is defined as:

Subset Sum with a fixed size

**Input:** A set of positive integer \(S\), and two positive integers \(t,k\).

**Output:** "Yes": if \(\exists S^{\prime}\subseteq S\) of size \(k\) such that \(\sum_{a\in S^{\prime}}a=t\);

"No": otherwise.

The ordered training data \(T\) is constructed as

\[T=\{(x_{1},y_{1}),(x_{2},y_{2}),\ldots,(x_{n},y_{n})\}\cup\{(x_{a},y_{a})\}\]

where \(x_{i}y_{i}=\frac{2}{3}+\frac{a_{i}}{3\sum_{a\in S}a}\) for all \(1\leq i\leq n\) and \(x_{a}y_{a}=1+\frac{1}{6\sum_{a\in S}a}\). Let \(\eta=1,\alpha=1,\beta=-1\), \(w^{(0)}=-1-\frac{2}{3}k-\frac{1}{3\sum_{a\in S}a}\) and let the test instance \((x_{\text{test}},y_{\text{test}})\) satisfy \(x_{\text{test}}y_{\text{test}}=1\). It now suffices to prove that \(\exists S^{\prime}\subseteq S\) such that \(|S^{\prime}|=k\) and \(\sum_{a\in S^{\prime}}a=t\) if and only if \(\exists T^{\prime}\subseteq T\) such that \(w:w^{(0)}\xrightarrow{r^{\prime}}w\) satisfies \(y_{\text{test}}wx_{\text{test}}>0\).

If: Suppose \(\exists S^{\prime}\subseteq S\) such that \(|S^{\prime}|=k\) and \(\sum_{a\in S}a=t\). Let \(T^{*}=\{(x_{i},y_{i})|a_{i}\in S^{\prime}\}\), we prove that \(y_{\text{test}}w^{*}x_{\text{test}}>0\) for \(w^{*}\) satisfying \(w^{(0)}\xrightarrow{T^{\prime}=T^{*}\cup\{(x_{a},y_{a})\}}w^{*}\).

Since

\[w^{(0)}+\sum_{a_{i}\in S^{\prime}}x_{i}y_{i} =-1-\frac{2}{3}k-\frac{t}{3\sum_{a\in S}a}+\sum_{a_{i}\in S^{\prime }}\left(\frac{2}{3}+\frac{a_{i}}{3\sum_{a\in S}a}\right)\] \[=-1-\frac{2}{3}k-\frac{t}{3\sum_{a\in S}a}+\sum_{a_{i}\in S^{ \prime}}\frac{2}{3}+\frac{\sum_{a\in S^{\prime}}a}{3\sum_{a\in S}a}=-1\]

and \(\forall 1\leq i\leq n,x_{i}y_{i}>\frac{2}{3}\), for each \(1\leq i<n\), suppose \(w^{(0)}\xrightarrow{T^{*}\cap\{(x_{i},y_{i})|1\leq j\leq i\}}w_{i}\), we have

\[w_{i}x_{i+1}y_{i+1}<\left(w^{(0)}+\sum_{a_{j}\in S^{\prime}}x_{j}y_{j}-\frac{2 }{3}\right)\cdot\frac{2}{3}<-\frac{10}{9}<\beta.\]

That is, each training sample in \(T^{*}\) is activated. Then for \(w^{(0)}\xrightarrow{T^{*}}w_{a}\), we have \(w_{a}=-1\). Then, since \(y_{a}w_{a}x_{a}=-(1+\frac{1}{6\sum_{a\in S}a})<\beta\) and \(w_{a}\xrightarrow{(x_{a},y_{a})}w^{*}\) we have \(w^{*}=w_{a}+x_{a}y_{a}=\frac{1}{6\sum_{a\in S}a}\). Therefore, \(y_{\text{test}}w^{*}x_{\text{test}}=\frac{1}{6\sum_{a\in S}a}>0\).

Only if: For each \(T^{\prime}\subseteq T\), let \(T^{*}=T^{\prime}\setminus\{(x_{a},y_{a})\}\) and \(c(T^{*})\) be the set of training samples in \(T^{*}\) that are activated. If \(y_{\text{test}}w^{*}x_{\text{test}}\geq 0\) for \(w^{*}\) satisfying \(w^{(0)}\xrightarrow{T^{\prime}}w^{*}\), we prove that the set \(S^{\prime}=\{a_{i}|(x_{i},y_{i})\in c(T^{*})\}\) satisfies \(|S^{\prime}|=k\) and \(\sum_{a\in S^{\prime}}a=t\).

We first show that \(y_{\text{test}}w_{a}x_{\text{test}}<0\) for \(w^{(0)}\xrightarrow{c(T^{*})}w_{a}\). Otherwise, suppose \(y_{\text{test}}w_{a}x_{\text{test}}\geq 0\) we have \(w_{a}\geq 0\). Let \((x,y)\) be the last training sample of \(c(T^{\prime})\), since \(\frac{2}{3}<xy\leq 1\), we have \(w^{\prime}\geq w_{a}-xy\geq-1\) for \(w^{\prime}\xrightarrow{(x,y)}w_{a}\). Thus \(yw^{\prime}x\geq\beta\), which contradicts to the definition of \(c(T^{*})\). We next show that \(|S^{\prime}|=k\). Suppose \(|S^{\prime}|\leq k-1\), we have

\[w_{a}=w^{(0)}+\sum_{(x_{i},y_{i})\in c(T^{*})}x_{i}y_{i} =-1-\frac{2}{3}k-\frac{t}{3\sum_{a\in S}a}+\sum_{a_{i}\in S^{ \prime}}\frac{2}{3}+\frac{\sum_{a\in S^{\prime}}a}{3\sum_{a\in S}a}\] \[<-1-\frac{2}{3}k+\frac{2}{3}(k-1)+\frac{1}{3}=-\frac{4}{3}\]

Thus \(w^{*}\leq w_{a}+x_{a}y_{a}<-\frac{4}{3}+(1+\frac{1}{6\sum_{a\in S}a})<0\) and then \(y_{\text{test}}w^{*}x_{\text{test}}<0\), which contradicts to the fact that \(y_{\text{test}}w^{*}x_{\text{test}}\geq 0\). Therefore \(|S^{\prime}|\geq k\).

Suppose \(|S^{\prime}|\geq k+1\), we have

\[w_{a}=w^{(0)}+\sum_{(x_{i},y_{i})\in c(T^{*})}x_{i}y_{i} \geq-1-\frac{2}{3}k-\frac{1}{3}+\frac{2}{3}(k+1)=-\frac{2}{3}\]

Then \(y_{a}w_{a}x_{a}\geq(-\frac{2}{3})\cdot(1+\frac{1}{6\sum_{a\in S}a})\geq-\frac {7}{9}\geq\beta\), that is, \((x_{a},y_{a})\) is not activated and \(w^{*}=w_{a}\). Then since \(y_{\text{test}}w_{a}x_{\text{test}}<0\), we have \(y_{\text{test}}w^{*}x_{\text{test}}=y_{\text{test}}w_{a}x_{\text{test}}<0\), which contradicts to the fact that \(y_{\text{test}}w^{*}x_{\text{test}}\geq 0\). Therefore \(|S^{\prime}|=k\).

It remains to prove that \(\sum_{a\in S^{\prime}}a=t\). Otherwise, suppose \(\sum_{a\in S^{\prime}}a\leq t-1\), we have

\[w_{a}=w^{(0)}+\sum_{(x_{i},y_{i})\in c(T^{*})}x_{i}y_{i} \leq-1-\frac{2}{3}k-\frac{t}{3\sum_{a\in S}a}+\frac{2}{3}k+\frac{t -1}{3\sum_{a\in S}a}\] \[=-1-\frac{1}{3\sum_{a\in S}a}\]

Thus \(y_{\text{test}}w^{*}x_{\text{test}}\leq y_{\text{test}}(w_{a}+x_{a}y_{a})x_{ \text{test}}\leq-\frac{1}{6\sum_{a\in S}a}<0\), which contradicts to the fact that \(y_{\text{test}}w^{*}x_{\text{test}}\geq 0\). Therefore \(\sum_{a\in S^{\prime}}a\geq t\).

Suppose \(\sum_{a\in S^{\prime}}a\geq t+1\) we have

\[w_{a}=w^{(0)}+\sum_{(x_{i},y_{i})\in c(T^{*})}x_{i}y_{i} \geq-1-\frac{2}{3}k-\frac{t}{3\sum_{a\in S}a}+\frac{2}{3}k+\frac{t +1}{3\sum_{a\in S}a}\] \[=-1+\frac{1}{3\sum_{a\in S}a}\]Thus

\[y_{a}w_{a}x_{a} \geq(-1+\frac{1}{3\sum_{a\in S}a})\cdot(1+\frac{1}{6\sum_{a\in S}a})\] \[\geq-1+\frac{1}{6\sum_{a\in S}a}+\frac{1}{18(\sum_{a\in S}a)^{2}} \geq\beta.\]

That is, \((x_{a},y_{a})\) is not activated and \(w^{*}=w_{a}\). Then since \(y_{\text{test}}w_{a}x_{\text{test}}<0\), we have \(y_{\text{test}}w^{*}x_{\text{test}}=y_{\text{test}}w_{a}x_{\text{test}}<0\), which contradicts to the fact that \(y_{\text{test}}w^{*}x_{\text{test}}\geq 0\). Therefore \(\sum_{a\in S^{\prime}}a=t\). 

### Proof of Theorem 4.3 for \(\beta<-1\)

Proof.: To avoid cluttering, we still assume \(\bm{\eta}=\mathbf{1}\) and \(\alpha=1\). The proof can be generalized by appropriately re-scaling the constructed vectors.

Let \(M=-\beta(n+2)+9\beta nm^{2}(n+1)+3\). Suppose \(n=|S|>1\), \(m=\max_{a\in S}\{a\}\) and \(S=\{a_{1},a_{2},\ldots,a_{n}\}\). We further assume \(n>1\). Let the ordered set of training samples be

\[T=\{(\mathbf{x}_{1},y_{1}),(\mathbf{x}_{2},y_{2}),\ldots,(\mathbf{x}_{n},y_{ n})\}\cup\{(\mathbf{x}_{c},y_{c}),(\mathbf{x}_{b},y_{b}),(\mathbf{x}_{a},y_{a})\}\]

where \(\mathbf{x}_{i}y_{i}=(\frac{1}{n+1},-3\beta a_{i})\) for all \(1\leq i\leq n,\mathbf{x}_{c}y_{c}=(M+\frac{3}{2}\beta-1,\beta(3t-\frac{1}{2})),\mathbf{x}_{b}y_{b}=(1,-1),\mathbf{x}_{a}y_{a}=(-\frac{3}{2}\beta,-\frac{3}{2 }\beta)\). Let \(\mathbf{w}^{(0)}=(-M,0)\). Let the test instance \((\mathbf{x}_{\text{test}},y_{\text{test}})\) satisfy \(\mathbf{x}_{\text{test}}y_{\text{test}}=(1,0)\).

For each \(1\leq i<n\), suppose \(\mathbf{w}^{(0)}\xrightarrow{T\cap\{(\mathbf{x}_{i},y_{i})|1\leq j\leq i\}} \mathbf{w}_{i}\), we have

\[y_{i+1}\mathbf{w}_{i}^{\top}\mathbf{x}_{i+1} \leq-M\cdot\frac{1}{n+1}+\frac{i}{(n+1)^{2}}+9\beta^{2}a_{i+1} \sum_{j=1}^{i}a_{j}\] \[\leq-M\cdot\frac{1}{n+1}+\frac{n}{(n+1)^{2}}+9\beta^{2}nm^{2}<\beta\]

This means all the \((\mathbf{x}_{i},y_{i})\in T\setminus\{(\mathbf{x}_{c},y_{c}),(\mathbf{x}_{b}, y_{b}),(\mathbf{x}_{a},y_{a})\}\) can be activated and thus the resulting parameter trained by \(T\setminus\{(\mathbf{x}_{c},y_{c}),(\mathbf{x}_{b},y_{b}),(\mathbf{x}_{a},y_{ a})\}\) is

\[\mathbf{w}_{c}=\mathbf{w}^{(0)}+\sum_{i=1}^{n}\mathbf{x}_{i}y_{i}=\left(-M+ \frac{|T^{*}|}{n+1},-3\beta\sum_{i=1}^{n}a_{i}\right)\]

It now suffices to prove that for all \(S^{\prime}\subseteq S\), \(\sum_{a\in S^{\prime}}a=t\) if and only if \(\exists T^{\prime}\subseteq T\) such that \(\mathbf{w}:\mathbf{w}^{(0)}\xrightarrow{T^{\prime}}\mathbf{w}\) such that \(y_{\text{test}}\mathbf{w}^{\top}\mathbf{x}_{\text{test}}>0\).

If. Suppose \(\exists S^{\prime}\subseteq S\) such that \(\sum_{a\in S}a=t\), we prove that \(\exists T^{\prime}\subseteq T\) such that \(y_{\text{test}}(\mathbf{w}^{*})^{\top}\mathbf{x}_{\text{test}}>0\) for \(\mathbf{w}^{*}\) satisfying \(\mathbf{w}^{(0)}\xrightarrow{T^{*}}\mathbf{w}^{*}\).

Let \(T^{*}=\{(\mathbf{x}_{i},y_{i})|a_{i}\in S^{\prime}\}\), \(T^{\prime}=T^{*}\cup\{(\mathbf{x}_{c},y_{c}),(\mathbf{x}_{b},y_{b}),(\mathbf{ x}_{a},y_{a})\}\). We have

\[\mathbf{w}_{c}=(-M+\frac{|T^{*}|}{n+1},-3\beta\sum_{a_{i}\in S^{\prime}}a_{i} )=(-M+\frac{|T^{*}|}{n+1},-3\beta t)\]

And \(y_{c}\mathbf{w}_{c}^{\top}\mathbf{x}_{c}=(-M+\frac{|T^{*}|}{n+1})(M+\frac{3} {2}\beta-1)-3t\beta^{2}(3t-\frac{1}{2})<\beta\), so

\[\mathbf{w}_{c}\xrightarrow{(\mathbf{x}_{c},y_{c})}\mathbf{w}_{b}=\mathbf{w}_{ c}+\mathbf{x}_{c}y_{c}=(\frac{|T^{*}|}{n+1}+\frac{3}{2}\beta-1,-\frac{1}{2}\beta)\]

Note that \(\beta<-1\), we have \(y_{b}\mathbf{w}_{b}^{\top}\mathbf{x}_{b}=\frac{|T^{*}|}{n+1}+2\beta<(\beta+ \frac{|T^{*}|}{n+1})+\beta<\beta\), and

\[\mathbf{w}_{b}\xrightarrow{(\mathbf{x}_{b},y_{b})}\mathbf{w}_{a}=\mathbf{w}_{ b}+\mathbf{x}_{a}y_{a}=(\frac{|T^{*}|}{n+1}+\frac{3}{2}\beta,-\frac{1}{2}\beta-1)\]

Note also that \(y_{a}\mathbf{w}_{a}^{\top}\mathbf{x}_{a}=\frac{3}{2}(-\beta)(\frac{|T^{*}|}{n+1 }-1+\beta)<\beta\), we have

\[\mathbf{w}_{a}\xrightarrow{(\mathbf{x}_{a},y_{a})}\mathbf{w}^{*}=\mathbf{w}_ {a}+\mathbf{x}_{a}y_{a}=(\frac{|T^{*}|}{n+1},-2\beta-1)\]Therefore, \(y_{\text{test}}(\mathbf{w}^{*})^{\top}\mathbf{x}_{\text{test}}=\frac{|T^{*}|}{n+1}\geq 0\).

Only if: For each \(T^{\prime}\subseteq T\), let \(T^{*}=T^{\prime}\setminus\{(\mathbf{x}_{c},y_{c}),(\mathbf{x}_{b},y_{b}),( \mathbf{x}_{a},y_{a})\}\), if \(y_{\text{test}}(\mathbf{w}^{*})^{\top}\mathbf{x}_{\text{test}}\) for \(\mathbf{w}^{*}\) satisfying \(\mathbf{w}^{(0)}\xrightarrow{T^{\prime}}\mathbf{w}^{*}\), we prove that \(\exists S^{\prime}\subseteq S\) such that \(\sum_{a\in S^{\prime}}a=t\). We first show that for each \(T^{\prime}\subseteq T\), if \(\mathbf{w}(\mathbf{w}^{(0)}\xrightarrow{T^{\prime}}\mathbf{w})\) satisfying \(y_{\text{test}}\mathbf{w}^{\top}\mathbf{x}_{\text{test}}\geq 0\), we have \(\forall k\in\{a,b,c\},(\mathbf{x}_{k},y_{k})\in T^{\prime},y_{k}\mathbf{w}_{k} ^{\top}\mathbf{x}_{k}<\beta\), where \(\mathbf{w}^{(0)}\xrightarrow{T^{\prime}}\mathbf{w}_{c}\xrightarrow{(\mathbf{ x}_{c},y_{c})}\mathbf{w}_{b}\xrightarrow{(\mathbf{x}_{b},y_{b})}\mathbf{w}_{a}\). Otherwise, suppose \(\exists k\in\{a,b,c\}\) such that \((\mathbf{x}_{k},y_{k})\not\in T^{\prime}\) or \(y_{k}\mathbf{w}_{k}^{\top}\mathbf{x}_{k}\geq\beta\), we have

\[y_{\text{test}}\mathbf{w}^{\top}\mathbf{x}_{\text{test}} \leq-M+\frac{|T^{*}|}{n+1}+M+\frac{3}{2}\beta-1+1-\frac{3}{2} \beta-\min\left\{1,M+\frac{3}{2}\beta-1,-\frac{3}{2}\beta\right\}\] \[=\frac{|T^{*}|}{n+1}-1<0\]

which contradicts to the fact that \(y_{\text{test}}\mathbf{w}^{\top}\mathbf{x}_{\text{test}}\geq 0\).

Let \(S^{\prime}=\{a_{i}|(\mathbf{x}_{i},y_{i})\in T^{*}\}\) and \(t^{\prime}=\sum_{a\in S^{\prime}}a_{i}\), it suffices to prove \(t^{\prime}=t\). Notice that

\[\mathbf{w}^{(0)}\xrightarrow{T^{*}}\mathbf{w}_{c} =(-M+\frac{|T^{*}|}{n+1},-3\beta\sum_{a_{i}\in S^{\prime}}a_{i})\] \[=(-M+\frac{|T^{*}|}{n+1},-3\beta t^{\prime})\]

Hence \(y_{c}\mathbf{w}_{c}^{\top}\mathbf{x}_{c}=(-M+\frac{|T^{*}|}{n+1})(M+\frac{3}{ 2}\beta-1)-3t^{\prime}\beta^{2}(3t-\frac{1}{2})<\beta\), thus

\[\mathbf{w}_{c}\xrightarrow{(\mathbf{x}_{c},y_{c})}\mathbf{w}_{b}=\mathbf{w}_{ c}+\mathbf{x}_{c}y_{c}=(\frac{|T^{*}|}{n+1}+\frac{3}{2}\beta-1,-3\beta(t^{ \prime}-t)-\frac{1}{2}\beta)\]

(1) If \(t^{\prime}\leq t-1\), we have

\[y_{b}\mathbf{w}_{b}^{\top}\mathbf{x}_{b} =\frac{|T^{*}|}{n+1}-1+2\beta+3\beta(t^{\prime}-t)\] \[\geq\frac{|T^{*}|}{n+1}-(1+\beta)>0>\beta\]

a contradiction. Hence \(\mathbf{w}_{a}=\mathbf{w}_{b}\xrightarrow{(\mathbf{x}_{b},y_{b})}\mathbf{w} _{a}=(\frac{|T^{*}|}{n+1}+\frac{3}{2}\beta,-3\beta(t^{\prime}-t)-\frac{1}{2} \beta-1)\).

(2) If \(t^{\prime}\geq t+1\), we have

\[y_{a}\mathbf{w}_{a}^{\top}\mathbf{x}_{a} =-\frac{3\beta}{2}\left(\frac{|T^{*}|}{n+1}-1+\beta-3\beta(t^{ \prime}-t)\right)\] \[\geq-\frac{3\beta}{2}\left(\frac{|T^{*}|}{n+1}-1-2\beta\right)\] \[>-\frac{3\beta}{2}\left(\frac{|T^{*}|}{n+1}+1\right)>0>\beta\]

another contradiction. Therefore \(t^{\prime}=t\), and this completes the proof.

## Appendix C Limitations

It is important to emphasize that the complexity results in section 4 requires the training order to be adversarially chosen. The complexity of Debuggable for randomly chosen training order is unclear and needs to be figured out in the future research.

NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The main results are discussed in section 3 and section 4. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: See section C in the appendix. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: The proof of theorem 3.1 is available in section A; The proof of theorem 4.1 and theorem 4.2 are available in section 4; The proof of theorem 4.3 is available in section 4 and section B; The proof of theorem 4.4 is available in section B.

Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [NA] Justification: This paper does not include experiments. Guidelines:

* The answer NA means that the paper does not include experiments.
* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?

Answer: [NA]

Justification: This paper does not include experiments requiring code.

Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.

6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?

Answer: [NA]

Justification: This paper does not include experiments.

Guidelines:

* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.

7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?

Answer: [NA]

Justification: This paper does not include experiments.

Guidelines:

* The answer NA means that the paper does not include experiments.

* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: This paper does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: They authors have made sure that the research conducted in the paper conform with the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: The impacts are discussed in section 5 Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This paper only provides theoretical results and poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: This paper does not use existing assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.