# Macro Placement

by Wire-Mask-Guided Black-Box Optimization

 Yunqi Shi, Ke Xue, Lei Song, Chao Qian

National Key Laboratory for Novel Software Technology, Nanjing University, China

School of Artificial Intelligence, Nanjing University, China

{shiyq, xuek, songl, qianc}@lamda.nju.edu.cn

Corresponding Author

###### Abstract

The development of very large-scale integration (VLSI) technology has posed new challenges for electronic design automation (EDA) techniques in chip floorplanning. During this process, macro placement is an important subproblem, which tries to determine the positions of all macros with the aim of minimizing half-perimeter wirelength (HPWL) and avoiding overlapping. Previous methods include packing-based, analytical and reinforcement learning methods. In this paper, we propose a new black-box optimization (BBO) framework (called WireMask-BBO) for macro placement, by using a wire-mask-guided greedy procedure for objective evaluation. Equipped with different BBO algorithms, WireMask-BBO empirically achieves significant improvements over previous methods, i.e., achieves significantly shorter HPWL by using much less time. Furthermore, it can fine-tune existing placements by treating them as initial solutions, which can bring up to 50% improvement in HPWL. WireMask-BBO has the potential to significantly improve the quality and efficiency of chip floorplanning, which makes it appealing to researchers and practitioners in EDA and will also promote the application of BBO. Our code is available at https://github.com/lamda-bbo/WireMask-BBO.

## 1 Introduction

EDA techniques have been widely employed to assist engineers in designing chips [30, 31], while the rapid advancement of VLSI technology has led to an exponential growth in chip scale, posing significant challenges. Particularly, for the important chip floorplanning stage in EDA, which strives to optimize power, performance, and area metrics while adhering to constraints such as congestion and density [45], the number of cells to be placed on the chip canvas increases rapidly and their routing relationships also become more complex, requiring innovative and efficient methods.

During the floorplanning placement stage, the position of each cell on the chip canvas is established. A modern chip typically comprises thousands of macros (i.e., individual building blocks such as memories) and millions of standard cells (i.e., smaller basic components like logic gates). The designer provides a netlist, which outlines the design requirements and serves as a large-scale hypergraph containing numerous hyper-edges (also called nets) that represent the routing relationships among macros and standard cells. Traditionally, the placement problem is divided into two successive stages [4]: macro placement, which is usually addressed by heuristic or learning methods [42, 44], and standard cell placement, which is usually addressed by analytical solvers [13, 28]. After placing all the cells (including macros and standard cells), a routing stage is performed. The general flow of chip floorplanning and routing is illustrated in Figure 1. In this work, we concentrate on macro placement due to its greater impact on placement quality: Macros are often larger and more crucial for achieving optimal placement [4, 47].

arlier methods often formulate macro placement as a rectangular packing problem, where solutions are represented by sequence pair (SP) [33], B\({}^{*}\)-tree [11], corner block list (CBL) [19] or other data structures [34; 27], and solve it by simulated annealing (SA) [1; 18; 24; 40]. This kind of method suffers from the poor scalability due to the quadratic complexity of decoding a genotype solution to a phenotype placement. Analytical methods [12; 13; 28; 29] place macros and standard cells simultaneously, and relax the task to a mathematical programming problem, which can be solved efficiently. However, they cannot guarantee the non-overlapping between cells, which is a hard constraint of cell placement. More recently, by dividing the chip canvas into discrete grids and formulating the task of placing macros onto grids step by step as a Markov decision process (MDP), reinforcement learning (RL) methods have been applied, showing promising performance [14; 15; 26; 32]. But their fast convergence (after only a few hundred evaluations) observed in experiments may imply that the huge search space of placement is still underexplored, and further improvement is expected. A detailed review of these existing methods is provided in Section 2.

In this paper, we propose a new BBO framework for macro placement. To allow better exploration, a solution is directly represented by the coordinates of all macros on the chip canvas. HPWL is used as the minimization objective function. The key of our framework is that in order to improve efficiency, we use an elaborate evaluation procedure, which greedily improves a solution (with the goal of minimizing HPWL while avoiding overlapping) before evaluation. Concretely, using the wire mask [26] to record the increment of HPWL by moving a macro to each candidate grid on the chip canvas, the macros in the solution are sequentially adjusted to the nearest best grid. This framework is briefly called WireMask-BBO, which can use any BBO algorithm to solve the resulting problem.

Experimental results on multiple popular benchmarks demonstrate that WireMask-BBO, when equipped with different BBO algorithms such as random search (RS), Bayesian optimization (BO), and evolutionary algorithms (EA), significantly outperforms the compared representative methods, including traditional BBO methods based on packing formulation, analytical methods, and RL methods. Especially, WireMask-EA (i.e., WireMask-BBO equipped with EA) generates the highest-quality placement in 6 out of 7 different chip benchmarks, and surpasses the state-of-the-art MaskPlace [26] in 8 minutes on average. Besides, as an optimization-based method, WireMask-BBO can fine-tune any existing placement, regardless of how it was generated. That is, WireMask-BBO can be combined with any existing macro placement method as post-processing. Our experiments show that such fine-tuning can lead to an improvement of up to 50% in the objective HPWL.

Our main contribution is introducing the general framework WireMask-BBO, while not developing new BBO algorithms. In fact, our experiments show that even employing simple BBO techniques has led to superior performance over previous methods. We will open-source WireMask-BBO and use it as an optimization benchmark to encourage the invention of more efficient BBO algorithms for solving macro placement problems, as well as broaden the application scenario of BBO.

## 2 Background

In this section, we introduce the macro placement problem, and the existing methods which can be generally categorized into packing-based, analytical, and grid-based RL methods.

Figure 1: General flow of chip floorplanning and routing, where the routing stage basically relies on the placement result. We focus on the macro placement task in this paper.

### Macro Placement

The input for a macro placement problem constitutes a netlist \(H=(V,E)\), where \(V\) denotes the information (i.e., height and width) about all cells designated for placement on the chip, and \(E\) is a hyper-graph comprised of hyper-edges \(e_{i}\in E\), which encompasses multiple cells (including both macros and standard cells) and signifies their interconnectivity during the routing phase. A macro placement solution consists of the positions of all macros \(\{v_{i}\}_{i=1}^{k}\) with the coordinates of each macro \(v_{i}\in V\) on the chip canvas expressed as \((x_{i},y_{i})\), where \(k\) denotes the total number of marcros. To facilitate a comprehensive understanding of the macro placement problem, we present several key metrics for evaluating placement outcomes.

**HPWL** is the predominant metric for gauging placement quality, as it offers a precise estimation of the wirelength necessary for routing [9; 22; 38]. A shorter wirelength decreases delay and power consumption, enhancing overall performance [36]. To calculate HPWL of a macro placement solution \(\bm{s}\), each hyper-edge \(e_{j}\in E\) corresponds to a rectangle area characterized by its lower-left endpoint, with coordinates (\(\min_{v_{i}\in e_{j}}x_{i},\min_{v_{i}\in e_{j}}y_{i}\)), and its upper-right endpoint, with coordinates (\(\max_{v_{i}\in e_{j}}x_{i},\max_{v_{i}\in e_{j}}y_{i}\)). That is, the rectangle is the smallest one bounding all cells within \(e_{j}\). Let \(w_{j}=\max_{v_{i}\in e_{j}}x_{i}-\min_{v_{i}\in e_{j}}x_{i}\) and \(h_{j}=\max_{v_{i}\in e_{j}}y_{i}-\min_{v_{i}\in e_{j}}y_{i}\) denote the width and height of the rectangle, respectively. Then,

\[\text{HPWL}(\bm{s},H)=\sum\nolimits_{e_{j}\in E}(w_{j}+h_{j}).\] (1)

**Congestion** serves as a vital metric in determining the routability of a given placement, exerting a direct influence on the manufacturing process. A widely-adopted approach for approximating congestion is rectangular uniform wire density (RUDY) [41]. The congestion of a grid on the canvas can be represented as the cumulative impact of all hyper-edge rectangle areas encompassing the grid. By selecting the top \(10\%\) congested grids (denoted as \(G^{\star}\)) and computing the mean of their congestion, the RUDY value of a macro placement solution is calculated as \(\frac{1}{|G^{\star}|}\sum_{g_{i}\in G^{\star}}\sum_{e_{j}\in E(g_{i})}\frac{w_ {j}+h_{j}}{w_{j}\cdot h_{j}}\), where \(|G^{\star}|\) is the size of \(G^{\star}\), \(E(g_{i})\) denotes the set of hyper-edges whose rectangle areas cover \(g_{i}\), and \((w_{j}+h_{j})/(w_{j}\cdot h_{j})\) measures the impact of the rectangle area of hyper-edge \(e_{j}\).

**Density** measures the overlap degree between cells by employing an electrostatic analogy [29]. It is often treated as a penalty to diminish overlap, yielding a more uniform distribution of cells across the chip area [4; 13; 28; 29]. Further discussion will not be provided here, as our formulation ensures non-overlapping, which is a hard constraint of macro placement.

**Area** denotes the area of the minimum bounding rectangle that encloses all the macros. It was prevalent when the focus was on tightly packing macros and minimizing the area they occupied [10; 42]. However, when considering fixed-area chips as in [15; 26; 28; 32] and our work, the placement of cells optimized is to reduce wirelength and congestion rather than minimize the area.

### Packing-based Methods

As the focus was once on minimizing the bounding area of given macros, which can lead to a higher chip area utilization ratio [31], the packing formulation emerged as a natural and straightforward approach for the macro placement problem. Each macro, represented as a rectangle, has to be packed within a specified chip canvas, with the objective being to optimize the weighted sum of the area metric and HPWL metric. Several solution representation methods have been proposed, such as SP [33], B\({}^{*}\)-tree [11], CBL [19], etc. These genotype solutions will be mapped to concrete macro placement (phenotype) solutions for evaluation. SA is often employed [1; 18; 24; 40] to solve such BBO problems by perturbing the genotype to generate new offspring solutions and evaluating the corresponding phenotype to determine whether to accept the perturbation.

To handle both macros and standard cells, a divide-and-conquer idea is introduced [39; 43]. The standard cells are first clustered into blocks using either the logical hierarchy or min-cut-based partitioning algorithms [23; 37]. Placement is then performed on the mix of macro blocks and clustered standard cell blocks, often by SA using packing formulation [1; 2]. Finally, the standard cells are re-allocated by detailed placement. While reducing the problem size, clustering standard cells into rectangular blocks may cut some connections and hinder finding an optimal solution.

Recently, RL has been introduced to decide which perturbation operator should be selected and which macro should be perturbed by SA [46]. Moreover, [5] formulates the CBL establishment as aMDP and constructs a CBL genotype step by step. These advancements continue to grapple with the drawbacks of packing, such as poor scalability, which cannot be solved fundamentally because the drawbacks come from the quadratic complexity of mapping from genotype to phenotype [33]. Besides, at least one edge of each macro under the packing setting must be attached to another macro or the canvas's edge, making the placement quite congested, as visualized in Figure 2(a). Note that the congested macro placement will limit the space for subsequent standard cell placement, and lead to the bad performance of full placement, which will be shown in Table 3.

### Analytical Methods

Analytical methods [12; 13; 28; 29] place macros and standard cells simultaneously, and relax the full placement task to a mathematical programming problem, which can be solved efficiently. For example, DREAMPlace [28], a state-of-the-art and highly efficient analytical placement method, recasts the full placement task as \(\min\) WA\((\bm{s},H)+\lambda\cdot\text{Density}(\bm{s},H)\), where WA represents the smooth weighted-average wirelength (originally proposed by [20]) for approximating HPWL, Density denotes a differentiable density metric for penalizing overlapping, and \(\lambda\) is a trade-off factor. This problem is then solved numerically using classical mathematical optimization techniques (e.g., gradient descent), to rapidly generate high-quality full placement. Figure 2(b) shows a macro placement generated by DREAMPlace, which is better than that generated by packing in Figure 2(a). However, analytical methods cannot guarantee the non-overlapping between cells. Even employing macro placement legalization techniques, numerous overlaps may persist [4].

### Grid-based RL Methods

As the number of macros increases, packing-based methods encounter scalability challenges, while analytical methods may produce overlapping placements that are impractical for manufacturing [4]. To meet the demands of modern chip design and fully leverage RL, the Graph placement published in _Nature_[32] divides the chip canvas into discrete grids, with each macro assigned discrete coordinates of grids, and formulates the placement problem as a MDP, wherein the agent decides the placement of the next macro at each step. Notably, no reward is given until the final step, when all macros are placed. The ultimate reward is the weighted sum of HPWL and congestion. Compared with packing-based methods, the grid-based design eliminates edge attachment and provides room for standard cell placement while offering improved scalability. The length of the MDP grows linearly with the number of macros, as opposed to the quadratic complexity of packing formulation [33]. DeepPR [15] integrates convolutional and graph neural networks during the embedding stage, and introduces an intrinsic reward to promote exploration. However, DeepPR brings overlaps. Though PRNet [14] incorporates the overlap area into the reward function as a penalty, the non-overlapping issue still exists as observed in their experiments.

A key limitation of the above-mentioned methods is the absence of extrinsic rewards until the final step, leading to sub-optimal performance for a long MDP with over one thousand steps. To

Figure 2: Visualization of macro placement on the circuit benchmark _adaptec3_ using the proposed WireMask-EA and three representative methods. The macros are represented by yellow rectangles. The performance is evaluated in terms of HPWL and congestion; the lower the value, the better.

address this issue, MaskPlace [26] introduces a dense reward RL pipeline, incorporating a view mask for gathering global information, a position mask to ensure non-overlapping, and a wire mask to evaluate the placement of the current macro. Notably, the wire mask offers an immediate reward, calculated as the increase in HPWL after placing the current macro. These three masks are processed by a convolutional neural network and serve as input features for both the value and policy networks. MaskPlace can generate high-quality non-overlapping placement results in an affordable time. Figure 2(c) gives a placement example, which is better than that generated by packing and analytical methods as shown in Figures 2(a) and 2(b). From the experiments in [26], we can also observe that MaskPlace converges after only a few hundred evaluations, implying that the huge search space of placement may be still underexplored. The experimental results in Section 4 will confirm this conjecture, showing that our proposed framework will bring significant improvement.

## 3 Proposed Framework WireMask-BBO

This section is devoted to our proposed WireMask-BBO, where Section 3.1 introduces the problem formulation and Section 3.2 is concerned with optimization methods to solve the resulting problem.

### Wire-Mask-Guided Problem Formulation

**Solution representation.** To allow better exploration, a macro placement solution \(\bm{s}\) is directly represented by the coordinates of all macros \(\{v_{i}\}_{i=1}^{k}\), i.e., \(\bm{s}=(x_{1},y_{1},\ldots,x_{k},y_{k})\), where \((x_{i},y_{i})\) denotes the coordinates of the macro \(v_{i}\) on the chip canvas. For example, there are three macros A, B and C for the placement task in Figure 3, and thus a solution \(\bm{s}\) is represented by \((x_{1},y_{1},x_{2},y_{2},x_{3},y_{3})\).

**Objective evaluation.** The metric HPWL in Eq. (1) is used as the objective function to be minimized. But if optimizing in the solution space directly, it is difficult to efficiently find a solution that has a small HPWL value and satisfies the non-overlapping constraint. To improve the efficiency, a greedy improvement strategy is applied to a solution before evaluating it.

As in [32], the chip canvas is first divided into discrete grids. In the process of improving a solution greedily, each macro is moved to a grid by letting the macro's bottom-left corner situate at the bottom-left corner of the grid. The order of adjusting the position of a macro \(v_{i}\) is determined by the area of all the cells connected with \(v_{i}\), i.e., all the cells in the hyper-edges containing \(v_{i}\). Note that each hyper-edge contains a set of connected cells. The positions of all macros will be adjusted sequentially in the decreasing order of their corresponding computed areas, because a macro with a larger computed area implies connecting with more large cells and thus is intuitively more important.

Let \(v_{1}^{*},\ldots,v_{k}^{*}\) denote the ordered macros. Assume that the positions of \(v_{1}^{*},\ldots,v_{i-1}^{*}\) have been adjusted. When considering \(v_{i}^{*}\), a wire mask \(W_{i}\) introduced in [26] is first computed, which records the increase of HPWL by placing \(v_{i}^{*}\) to each candidate grid, given \(v_{1}^{*},\ldots,v_{i-1}^{*}\) already adjusted. Note that those grids that will lead to overlap or exceeding the canvas boundary after placing \(v_{i}^{*}\) are excluded. Then, \(v_{i}^{*}\) is moved to the grid with the least increment of HPWL. If such a grid is not unique, \(v_{i}^{*}\) is moved to the nearest one among them. This is actually a greedy step that moves \(v_{i}^{*}\) to the grid with the least increment on HPWL given the placement of \(v_{1}^{*},\ldots,v_{i-1}^{*}\). This process is repeated until the positions of all the macros have been adjusted. The HPWL of the resulting solution with all the adjusted macros is treated as the objective value of the original solution. Thus, a solution and its improved version in objective evaluation can be viewed as the genotype and phenotype representation of a macro placement. The detailed process of objective evalution is presented in Algorithm 1.

Figure 3 gives an example illustration of objective evaluation. For the input netlist \(H=(V,E)\), \(V\) contains three macros A, B and C, and the hyper-graph \(E\) contains two hyper-edges: one encompasses macros A and B, and the other encompasses A and C. Each hyper-edge signifies the interconnectivity of the macros contained by it. The chip canvas is partitioned into \(5\times 5\) grids. Assume that the width and height of each grid is both 1. The solution to be evaluated (as shown in Figure 3(a)) consists of the positions of macros A, B and C. According to the hyper-graph \(E\), we know that during the routing phase, macro A is connected with B and C, while macro B and C are both connected with only A. Thus, the corresponding areas computed in line 1 of Algorithm 1 are decreasingly ordered as A, B and C, which is just the order in line 2 to adjust the positions of macros sequentially.

When trying to adjust the position of macro A, a wire mask is first computed as in line 5 of Algorithm 1, which is shown in Figure 3(b), where the number in each grid is the increment of HPWLled by placing macro A in that grid. For example, if placing macro A in the center grid as shown in Figure 3(c), both the two hyper-edges correspond to the smallest rectangle bounding macro A (i.e., the red and black dotted square in Figure 3(c)) for computing HPWL in Eq. (1), and thus the corresponding HPWL is 6, which is the sum of half perimeters of these two rectangles. As the initial HPWL before placing macro A is 0, the increment of HPWL is 6. Note that when adjusting the position of a macro, its bottom-left corner must be situated at the bottom-left corner of a grid, and grids without numbers in the wire mask indicate that the current macro should not be placed there due to overlap or exceeding the canvas boundary. The underlined italic number in the wire mask denotes the least HPWL increment, representing the locally optimal choice, i.e., the set \(Q\) in line 6 of Algorithm 1. Then, as shown in lines 7-8 of Algorithm 1, macro A is placed at the local optimal grid, which has the smallest Euclidean distance to it. The coordinate of macro A in the original placement is denoted by the red star in Figure 3(b), and thus it is adjusted to be situated at the grid closest to it, as shown in Figure 3(c).

Figure 3: An example illustration of objective evaluation of WireMask-BBO.

The positions of macros B and C are adjusted similarly. Figure 3(c) shows the adjusted placement of macro A, and also the wire mask when trying to place macro B. Figure 3(d) shows the adjusted placement of macros A and B, and also the wire mask when trying to place macro C. Figure 3(e) gives the final improved placement after adjusting the positions of all macros. As HPWL is the sum of all hyper-edges' bounding rectangles' half perimeters, these rectangles can be updated each time a macro is placed, as shown by the red and black dotted squares in Figure 3. That is, for any individual macro, it is only necessary to update the bounding rectangles of its associated hyper-edges and compute the increase in their half perimeters. Thus, the calculation of HPWL can be performed incrementally, as in line 9 of Algorithm 1. In Figure 3, the increment of HPWL after placing macros A, B and C is 6, 3 and 2, respectively, leading to the HPWL value 11 of the final improved placement. Note that the red and black dotted bounding rectangles in Figure 3 are shown for illustrative purposes, while the actual HPWL calculation in our experiments is based on pin information.

Therefore, we have formulated macro placement as a black-box optimization problem, where the genotype-phenotype mapping is greedily guided by wire mask. Figures 3(a) and (e) give an example of genotype and phenotype representation. An algorithm for solving this problem will search in the genotype space, where the goodness of a genotype solution is estimated by the objective value of its corresponding phenotype. When an algorithm terminates, the corresponding phenotype of the generated genotype solution will be output as the final macro placement. Note that by the wire-mask-guided mapping process, the phenotype solution is guaranteed to have no overlap, and thus an algorithm can search in the genotype space without considering constraints.

### Black-Box Optimization

The above formulated problem can be solved by any BBO algorithm. In our experiments, we employ three simple ones, random search (RS), Bayesian optimization (BO) [17] and evolutionary algorithm (EA) [7]. RS randomly allocates all macros in a solution and evaluates it, recording the historical best. For BO, we adopt the efficient TuRBO approach [16] to directly optimize the continuous coordinates \((x_{1},y_{1},\ldots,x_{k},y_{k})\) of all macros, resulting in a dimension of \(2k\), where \(k\) is the number of macros. For EA, we choose the simple (1+1)-EA [6; 49], which maintains only one solution and iteratively improves it by mutation. We design the mutation operator by randomly selecting two macros and exchanging their coordinates in a solution. Our experiments will show that using these three simple BBO algorithms has been sufficient for the superior performance over previous methods. It is expected to design better BBO algorithms for the proposed formulation of macro placement.

By adopting the grid-based discretization and designing the wire-mask-guided greedy genotype-phenotype mapping, the proposed framework WireMask-BBO can efficiently generate a non-overlapping high-quality placement, addressing the poor scalability issue of packing-based methods as well as the overlapping issue of analytical methods. The use of black-box optimization enhances the exploration ability, making WireMask-BBO able to surpass the state-of-the-art RL-based method MaskPlace [26]. Figure 2(d) visualizes a placement generated by WireMask-BBO equipped with EA, which is better than that by SP-SA (a representative packing-based method) [33], DREAMPlace (a representative analytical method) [28] and MaskPlace [26], as shown in Figures 2(a), 2(b) and 2(c).

## 4 Experiments

We mainly empirically test our method on the ISPD2005 benchmark [35], which was originally proposed as a standard cell placement benchmark with fixed macros. Following conventional practice [15; 14; 26], we modify all macros to be movable for the macro placement problem. The ISPD2005 benchmark contains eight chips, i.e., _adapter1-4_ and _bigblue1-4_. Note that for the _bigblue2_ chip, which has over 20,000 macros and 30,000 macro-related hyper-edges, a single objective evaluation by step-by-step placement costs more than an hour. Thus, we do not include this chip in our experiments as [26]. For each chip, the canvas is partitioned into approximately 150\(\times\)150 grids heuristically. The detailed statistics (e.g., the number of macros, partitions, etc.) of the chips are provided in Appendix A.

We compare WireMask-BBO with several representative macro placement methods, including the packing-based SP-SA [33], three analytical methods NTUPlace3 [12], RePlace [13], DREAMPlace [28], and three RL-based methods Graph placement [32], DeepPR [15], MaskPlace [26]. As introduced in Section 3.2, we equip the proposed WireMask-BBO framework with RS, BO and EA,denoted as WireMask-RS, WireMask-BO and WireMask-EA, respectively. For the employed method TuRBO [16] for BO, we use the common hyper-parameters. For the EA, its initial solution is set as the best among 100 random solutions. All experiments are run on two Intel Xeon Platinum 8171M CPUs, each with 26 cores and 52 threads.

**Main results.** Table 1 gives the detailed results of running each method using five random seeds. The runtime for each run of WireMask-BBO is set as 1,000 minutes. The results of analytical and RL-based methods are directly from [26]. Note that the analytical method NTUPlace3 is deterministic, and thus has no standard deviation. We compute the rank of each method on each chip as in [21], which are averaged in the last column of Table 1. WireMask-RS, WireMask-BO and WireMask-EA achieve the three highest ranks, disclosing the effectiveness of the proposed general framework WireMask-BBO. Among these three variants, WireMask-EA performs the best, which has the highest rank 1.43 and achieves the smallest HPWL value on 5 out of the 7 chips. RS relies solely on random sampling without leveraging any search history. BO performs well in many low-dimensional tasks (typically when the dimension \(d\leq 20\)[17]), but suffers from the curse of dimensionality due to the time-consuming cost of updating the Gaussian process surrogate model and optimizing the acquisition function [8]. For example, in our experiments where \(d\) (i.e., 2 times the number of macros) is always larger than 1000, EA can sample much more solutions (about 2-7 times as shown in Table 9 of Appendix B) than BO during the 1000-minutes running. Compared with any previous method, WireMask-EA is significantly better on at least 6 out of the 7 chips, by the Wilcoxon rank-sum test with significance level 0.05. It is outperformed by RePlace and DREAMPlace on the chip _adapter4_, implying the suitability of analytical methods for this particular problem.

**Running time analysis.** As shown in Table 1, any variant of WireMask-BBO always performs better than the state-of-the-art MaskPlace [26], which ranks the highest among the compared previous methods. While [26] did not offer explicit training time details, the authors state a 200-minute convergence time in response to our inquiry. Next, we examine the efficiency of WireMask-BBO when compared with MaskPlace. Taking MaskPlace as the baseline, we plot the curve of HPWL over the wall clock time for WireMask-BBO in Figure 4. Each variant of WireMask-BBO surpasses MaskPlace very quickly. Particularly, WireMask-EA requires only 39, 8, 0.37, 0.62, 0.15, and 3 minutes, respectively, with an average of 8 minutes to surpass MaskPlace across six benchmark chips. This is notably faster than the 200-minute convergence time reported for MaskPlace. We have excluded the _bigblue4_ chip in Figure 4, because the 1,000-minute search for WireMask-EA only completes its initialization on this large-scale chip. On the chips _adapter3_ and _adapter4_, WireMask-EA actually outperforms MaskPlace after only a single greedy placement guided by wire mask, implying that MaskPlace fails to balance exploration and exploitation.

**Performance on congestion metric.** Aside from HPWL, congestion and density are also vital metrics as introduced in Section 2.1. As our framework WireMask-BBO maintains the non-overlapping property, density constraint does not need to be considered. Here, we evaluate placement congestion and compare it to the results of MaskPlace [26] and SP-SA [33] in Table 2. We normalize the congestion values by setting WireMask-EA's congestion to 1.00. The MaskPlace placements are provided by its authors2, while the SP-SA and WireMask-BBO placement results are obtained from a

\begin{table}
\begin{tabular}{c c c c c c c c c c c} \hline \hline Method & Type & adopted & adapted & adapted & adapted & adapted & labeled & bibble & bibble(\(\cdot 10^{7}\)) & \(+/-/-\) & Avg. Rank \\ \hline SP-SA[33] & Praking & 188.844\(\pm\)42.17 & 179.86\(\pm\)8.75 & 113.54\(\pm\)7.56 & 1200(\pm\)4.25 & 5.12\(\pm\)143 & 164.70\(\pm\)9.53 & 5.29\(\pm\)2.73 & 0/70 & 6.86 \\ NTUPlace3 [12] & Analytical & 26.62 & 321.7 & 328.44 & 462.93 & 2.28 & 485.53 & 48.38 & 0/70 & 9.00 \\ RePlace [16] & Analytical & 16.99 \(\pm\)1.20 & 113.52\(\pm\)2.90 & 111.21 & 11.69 & 7.641\(\pm\)0.55 & 2.486 & 119.84\(\pm\)3.43 & 11.00\(\pm\)0.73 & 1/60 & 5.28 \\ DREAMFilter [28] & Analytical & 158.81 \(\pm\)1.64 & 170.94\(\pm\)2.72 & 129.14 & 5.055 & **37.41\(\pm\)0.87** & 4.24\(\pm\)0.46 & 1019.29\(\pm\)2.91 & 125.21\(\pm\)6.14 & 1/60 & 4.86 \\ Graph [32] & RL & 30.10\(\pm\)2.98 & 351.71\(\pm\)3.20 & 38.38 & 18.35 & 131.54\(\pm\)2.97 & 2.058\(\pm\)1.29 & 35.78\(\pm\)4.73 & 53.55\(\pm\)4.06 & 0/70 & 9.00 \\ DeepF [18] & RL & 1.991 \(\pm\)1.98 & 351.67\(\pm\)2.30 & 38.16 & 131.86\(\pm\)2.57 & 2.38\(\pm\)5.65 & 34.08\(\pm\)2.18 & 63.00\(\pm\)4.44 & 0/70 & 8.86 \\ MaxMaxPlace [26] & RL & 6.38\(\pm\)0.55 & 73.75\(\pm\)6.53 & 64.44\(\pm\)3.60 & 32.11\(\pm\)0.65 & 2.91\(\pm\)0.65 & 91.11\(\pm\)7.83 & 10.17\(\pm\)0.99 & 0/70 & 4.28 \\ WireMask-RS & Ours & 6.13\(\pm\)0.05 & 59.28 \(\pm\)1.60 & 60.04\(\pm\)2.06 & 62.06 & 2.292 & 10.60\(\pm\)0.52 & **5.26\(\pm\)0.17** & **5.02\(\pm\)0.17** & **0.52\(\pm\)** & 2.57 \\ WireMask-BO & Ours & 6.07\(\pm\)0.14 & 59.71\(\pm\)3.34 & 61.00\(\pm\)2.08 & 63.86\(\pm\)1.01 & 2.14\(\pm\)0.03 & 67.58\(\pm\)6.49 & 6.52\(\pm\)0.18 & 0/3/4 & 2.86 \\ WireMask-AA & Ours & **5.14\(\pm\)0.07** & **52.43\(\pm\)2.23** & **57.78\(\pm\)1.16** & **53.79\(\pm\)1.02** & **2.12\(\pm\)0.01** & **59.87\(\pm\)3.40** & **5.28\(\pm\)** & 0.25 & **1.43** \\ \hline \hline \end{tabular}
\end{table}
Table 1: HPWL values (\(\times 10^{5}\)) obtained by ten compared methods on seven chips. Each result consists of the mean and standard deviation of five runs. The best (smallest) mean value on each chip is bolded. The symbols ‘\(+\)’, ‘\(-\)’ and ‘\(\approx\)’ indicate the number of chips where the result is significantly superior to, inferior to, and almost equal to WireMask-EA, respectively, according to the Wilcoxon rank-sum test with significance level 0.05.

1,000-minute search using the same random seed. The results show that though optimizing HPWL, WireMask-BBO can also achieve smaller congestion. The reason is that the RUDY approximation of congestion is sometimes positively related to the HPWL metric. Given a macro placement solution, the HPWL in Eq. (1) is computed as the sum of the rectangle's half-perimeter of hyper-edge, i.e., \(\sum_{e_{j}\in E}(w_{j}+h_{j})\), where \(e_{j}\) denotes a hyper-edge, \(E\) denotes the hyper-graph comprised of all hyper-edges, \(w_{j}\) and \(h_{j}\) denote the width and height of the rectangle corresponding to \(e_{j}\), respectively. The RUDY measures the overall congestion on the canvas, and the congestion of each grid \(g_{i}\) on the canvas is calculated by the cumulative impact of all hyper-edges encompassing the grid. Note that a hyper-edge \(e_{j}\) will add an impact to each of its covered grids by \(\frac{1}{w_{j}}+\frac{1}{h_{j}}\). Then, the overall congestion of all grids is \(\sum_{g_{i}}\sum_{e_{j}\in E(g_{i})}\frac{1}{w_{j}}+\frac{1}{h_{j}}=\sum_{e_{j }\in E}w_{j}\cdot h_{j}\cdot(\frac{1}{w_{j}}+\frac{1}{h_{j}})=\sum_{e_{j}\in E }(w_{j}+h_{j})=\mathrm{HPWL}\), where \(E(g_{i})\) denotes the set of hyper-edges whose corresponding rectangle covers the grid \(g_{i}\). The first equality holds because the number of times of a hyper-edge \(e_{j}\in E\) enumerated in LHS is equal to the number of grids covered by it, which is \(w_{j}\cdot h_{j}\). Thus, we can observe a positive relation between RUDY and HPWL. Besides our results, Table 4 in MaskPlace [26] and Table 4 in ChiPFormer [25] have also shown that the best HPWL can lead to the best congestion. However, a lower HPWL does not necessarily lead to a lower RUDY, because RUDY only considers the top-10% congested grids as introduced in Section 2.1.

**Full placement results.** Table 3 shows the results of different methods on the full placement task involving both macros and standard cells. We utilize PRNet [14] and DREAMPlace [28] as baselines, because both of them are designed to handle mixed-size placement tasks. The other five macro placement methods first optimize the macro placement, fix the macro positions, and then employ DREAMPlace to optimize the standard cell placement exclusively. The mean\(\pm\)std values are derived from DREAMPlace standard cell placement using five different random seeds. The results of PRNet are directly from [14]. Although WireMask-EA achieves the best performance on only one chip, i.e., _adapter4_, it attains the highest average rank. Compared with the mixed-size placement optimization methods PRNet and DREAMPlace, WireMask-EA does not explicitly optimize the full

\begin{table}
\begin{tabular}{l c c c c c c c c c c c c c c} \hline Benchmark & \multicolumn{2}{c}{adaptec1} & \multicolumn{2}{c}{adaptec2} & \multicolumn{2}{c}{adaptec3} & \multicolumn{2}{c}{adaptec4} & \multicolumn{2}{c}{highlet1} & \multicolumn{2}{c}{highlet3} & \multicolumn{2}{c}{highlet4} & \multicolumn{2}{c}{Avg. Rank} \\ Mattes & HPWL & Coog. & HPWL & Coog. & HPWL & Coog. & HPWL & Coog. & HPWL & Cong. & HPWL & Cong. & HPWL & Cong. & HPWL & Cong. \\ \hline Sp-SA [31] & 18.77 & 4.21 & 117.63 & 1.34 & 123.02 & 2.03 & 102.94 & 1.54 & 5.30 & 2.09 & 136.16 & 1.50 & 190.00 & 2.72 & 4.86 & 4.71 \\ MgOTrace [26] & 6.56 & 1.22 & 79.98 & 1.63 & 79.32 & 1.25 & 75.75 & 1.37 & 2.42 & 1.63 & 2.61 & **6.64** & **8.9** & / & / & 4.40 & 3.67 \\ WireMask-RB & 6.09 & 1.01 & 57.31 & 1.04 & 60.91 & 1.04 & 60.02 & **0.98** & 2.18 & 1.09 & 63.86 & 1.01 & **8.21** & 1.10 & 2.29 & 2.43 \\ WireMask-BO & 6.14 & 1.02 & 55.31 & **6.99** & 58.67 & 1.06 & 61.67 & 1.06 & **2.10** & **0.94** & 68.85 & 1.19 & 8.39 & 1.07 & 2.29 & 2.43 \\ WireMask-EA & **5.81** & **1.00** & **49.32** & 1.00 & **56.56** & **1.00** & **58.79** & 1.00 & 2.12 & 1.00 & **64.85** & 1.00 & 8.45 & **1.00** & **1.43** & **1.57** \\ \hline \end{tabular}
\end{table}
Table 2: Comparison on HPWL (\(\times 10^{5}\)) and Congestion (Cong.).

Figure 4: HPWL (\(\times 10^{5}\)) vs. wall clock time of WireMask-BBO, where the shaded region represents the standard error derived from 5 independent runs.

placement wirelength; thus, its best overall performance confirms the contribution of high-quality macro placement to an overall superior final placement.

**Fine-tuning results.** In fact, WireMask-BBO can be combined with any existing macro placement method for post-processing. The placement generated by any existing method can be treated as the initial solution of WireMask-BBO and then further improved. Table 4 shows the HPWL results of SP-SA and MaskPlace before and after 1,000 minutes of fine-tuning by WireMask-EA, with the average improvement ratio of \(53.93\%\) and \(17.06\%\), respectively. Compared to Table 1, fine-tuning the placement of MaskPlace leads to the best HPWL value on the two chips _adapted1_ and _bigblue1_.

**Additional results.** We propose a post local search procedure to further improve final placement results. We investigate the influence of the two hyper-parameters of WireMask-BBO, i.e., number of partitions in chip canvas discretization, and adjustment order of macros in objective evaluation. For WireMask-EA, the best-performed variant of WireMask-BBO, the influence of different mutation operators is also examined. We compare the number of evaluations of WireMask-BBO methods in 1000 minutes. Furthermore, we test on the _ariane_ RISC-V CPU design benchmark [48], still showing the clear superiority of WireMask-BBO over previous methods. We finally include comparisons with two concurrent advanced methods, i.e., ChiPFormer [25] and AutoDMP [4], and our WireMask-EA still maintains the superior performance. These results are provided in Appendix B.

## 5 Conclusion

This paper proposes the general framework WireMask-BBO for macro placement, which adopts a wire-mask-guided greedy genotype-phenotype mapping and can be equipped with any BBO algorithm. Extensive experimental results show that WireMask-BBO is clearly superior to previous packing-based, analytical, and RL-based methods. Furthermore, it can be combined with any existing macro placement method to further improve the final placement. Though showing significant potential, WireMask-BBO also has some limitations. First, it can only deal with macro placement, leaving standard cells for analytical placers. Second, its performance is limited for chips with a large number of macros due to the expensive objective evaluation. This, however, can be alleviated by equipping with high-dimensional BBO algorithms [8] or designing specific efficient BBO algorithms for macro placement, which is a very interesting future work. Our method does not have negative social impacts.

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline Method & adapted1 & adapted2 & adapted3 & adapted4 & bigblue1 & bigblue3 & Avg. Imp. \\ \hline SP-SA [33] & 18.84 & 117.36 & 115.48 & 120.03 & 5.12 & 164.70 & \multirow{2}{*}{\(53.93\%\)} \\ +WireMask-EA (1000min) & \(6.02\pm 0.11\) & \(60.35\pm 4.41\) & \(57.88\pm 0.62\) & \(59.50\pm 0.92\) & \(2.21\pm 0.02\) & \(82.68\pm 18.17\) & \\ \hline MaskPlace [26] & 6.56 & 79.98 & 79.32 & 75.75 & 2.42 & 82.61 & \multirow{2}{*}{\(17.06\%\)} \\ +WireMask-EA (1000min) & \(5.84\pm 0.10\) & \(61.43\pm 1.23\) & \(59.24\pm 2.71\) & \(60.35\pm 1.38\) & \(2.10\pm 0.01\) & \(74.93\pm 7.79\) & \\ \hline \hline \end{tabular}
\end{table}
Table 4: HPWL \((\times 10^{5})\) values obtained after fine-tuning existing placements by running WireMask-EA for 1,000 minutes. The last column, Avg. Imp., denotes the average improvement ratio across six chips, obtained by comparing the HPWL values before and after fine-tuning.

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline \hline benchmark & adapted1 & adapted2 & adapted2 & adapted3 & adapted4 & bigblue1 & bigblue3 & \(+j-r\) & Avg. Rank \\ \hline PBNet [4] & **8.28** & 12.33 & 23.24 & 23.49 & 14.10 & 46.86 & **1000.3** & 22.5/0 & 5.29 \\ DREAMMPC [28] & 11.10 \(\pm\)1.31 & 138.41 \(\pm\)1.74 & **173.63.09** & **237.37** & **11.33** & **106.48** & **23.651** & **23.655** & **17.85** & **23.23** & 2/4/1 & 3.57 \\ SP-SA [31]-BreaMP [26]-BreaMP & 10.86 \(\pm\)0.18 & 14.80 \(\pm\)0.01 & 30.63 \(\pm\)0.82 & 28.89 \(\pm\)0.02 & 10.70 \(\pm\)0.01 & 65.01 \(\pm\)0.12 & 20.79 \(\pm\)0.36 & 0/7/0 & 6.29 \\ MapPLPL [26]-BreaMP & 10.86 \(\pm\)0.10 & 12.98 \(\pm\)0.28 & 21.64 \(\pm\)0.07 & 25.24 \(\pm\)0.01 & 10.64 \(\pm\)0.01 & 54.98 \(\pm\)0.06 & 1/6 & 0/6/0 & 5.00 \\ WireMask-ES-BBMEMP & 10.94 \(\pm\)0.02 & **0.97** & **0.02** & 22.76 \(\pm\)0.01 & 22.09 \(\pm\)0.01 & 10.41 \(\pm\)0.03 & 42.58 \(\pm\)0.20 & 20.62 \(\pm\)0.08 & 2/4/1 & 3.00 \\ WireMask-BBO-BRMEMPC & 9.19 \(\pm\)0.26 & 12.87 \(\pm\)0.01 & 26.16 \(\pm\)0.04 & 26.76 \(\pm\)0.01 & 10.56 \(\pm\)0.01 & 56.08 \(\pm\)0.32 & 12.28 \(\pm\)0.06 & 1/6/0 & 4.43 \\ WireMask-EA+DEREAMMPC & 8.93 \(\pm\)0.01 & 9.20 \(\pm\)0.05 & 21.72 \(\pm\)0.01 & **20.51\(\pm\)0.01** & 10.35 \(\pm\)0.02 & 42.52 \(\pm\)0.11 & 171.23 \(\pm\)0.48 & **2.14** \\ \hline \hline \end{tabular}
\end{table}
Table 3: Comparison of HPWL values \((\times 10^{7})\) on the full placement task involving both macros and standard cells. The best (smallest) mean value on each chip is bolded. The symbols ‘+’, ‘-’ and ‘\(\approx\)’ indicate the number of chips where the result is significantly superior to inferior to, and almost equivalent to WireMask-EA+DREAMMPC, respectively, according to the Wilcoxon rank-sum test with significance level 0.05.

## Acknowledgement

We would like to thank Yao Lai from The University of Hong Kong for his generous help and valuable discussions, and the anonymous reviewers for their helpful comments. This work was supported by the National Key R&D Program of China (2022ZD0116600) and National Science Foundation of China (62022039). Chao Qian is the corresponding author.

## References

* [1] Saurabh N Adya and Igor L Markov. Fixed-outline floorplanning through better local search. In _Proceedings of the 19th IEEE International Conference on Computer Design: VLSI in Computers and Processors_, pages 328-334, Austin, TX, 2001.
* [2] Saurabh N Adya and Igor L Markov. Fixed-outline floorplanning: Enabling hierarchical design. _IEEE Transactions on Very Large Scale Integration Systems_, 11(6):1120-1135, 2003.
* [3] SN Adya, S Chaturvedi, JA Roy, D Papa, and IL Markov. Unification of partitioning, floorplanning and placement. In _Proceedings of the 17th International Conference on Computer-Aided Design_, pages 550-557, San Jose, CA, 2004.
* [4] Anthony Agnesina, Puranjay Rajvanshi, Tian Yang, Geraldo Pradipta, Austin Jiao, Ben Keller, Brucek Khailany, and Haoxing Ren. AutoDMP: Automated DREAMPlace-based macro placement. In _Proceedings of the 27th International Symposium on Physical Design_, pages 149-157, Virtual, 2023.
* [5] Mohammad Amini, Zhanguang Zhang, Surya Penmetsa, Yingxue Zhang, Jianye Hao, and Wulong Liu. Generalizable floorplanner through corner block list representation and hypergraph embedding. In _Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_, pages 2692-2702, Washington, DC, 2022.
* [6] Auger Anne and Benjamin Doerr. _Theory of Randomized Search Heuristics: Foundations and Recent Developments_. World Scientific, 2011.
* [7] Thomas Back. _Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms_. Oxford University Press, 1996.
* [8] Mickael Binois and Nathan Wycoff. A survey on high-dimensional Gaussian process modeling with application to Bayesian optimization. _ACM Transactions on Evolutionary Learning and Optimization_, 2(2):1-26, 2022.
* [9] Andrew E Caldwell, Andrew B Kahng, Stefanus Mantik, Igor L Markov, and Alexander Zelikovsky. On wirelength estimations for row-based placement. _IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems_, 18(9):1265-1278, 1999.
* [10] Heming Chan, Pinaki Mazumder, and Khushro Shahookar. Macro-cell and module placement by genetic adaptive search with bitmap-represented chromosome. _Integration_, 12(1):49-77, 1991.
* [11] Yun-Chih Chang, Yao-Wen Chang, Guang-Ming Wu, and Shu-Wei Wu. B*-trees: A new representation for non-slicing floorplans. In _Proceedings of the 37th Annual Design Automation Conference_, pages 458-463, Los Angeles, CA, 2000.
* [12] Tung-Chieh Chen, Zhe-Wei Jiang, Tien-Chang Hsu, Hsin-Chen Chen, and Yao-Wen Chang. Ntuplace3: An analytical placer for large-scale mixed-size designs with preplaced blocks and density constraints. _IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems_, 27(7):1228-1240, 2008.
* [13] Chung-Kuan Cheng, Andrew B Kahng, Ilgweon Kang, and Lutong Wang. Replace: Advancing solution quality and routability validation in global placement. _IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems_, 38(9):1717-1730, 2018.

* Cheng et al. [2022] Ruoyu Cheng, Xianglong Lyu, Yang Li, Junjie Ye, Jianye Hao, and Junchi Yan. The policy-gradient placement and generative routing neural networks for chip design. In _Advances in Neural Information Processing Systems 35_, New Orleans, LA, 2022.
* Cheng and Yan [2021] Ruoyu Cheng and Junchi Yan. On joint learning for solving placement and routing in chip design. In _Advances in Neural Information Processing Systems 34_, pages 16508-16519, Virtual, 2021.
* Eriksson et al. [2019] David Eriksson, Michael Pearce, Jacob Gardner, Ryan D Turner, and Matthias Poloczek. Scalable global optimization via local Bayesian optimization. In _Advances in neural information processing systems 32_, Vancouver, Canada, 2019.
* Frazier [2018] Peter I Frazier. A tutorial on Bayesian optimization. _arXiv preprint arXiv:1807.02811_, 2018.
* Ho et al. [2004] Shinn-Ying Ho, Shinn-Jang Ho, Yi-Kuang Lin, and WC-C Chu. An orthogonal simulated annealing algorithm for large floorplanning problems. _IEEE Transactions on Very Large Scale Integration Systems_, 12(8):874-877, 2004.
* Hong et al. [2000] Xianlong Hong, Gang Huang, Yici Cai, Jiangchun Gu, Sheqin Dong, Chung-Kuan Cheng, and Jun Gu. Corner block list: An effective and efficient topological representation of non-slicing floorplan. In _Proceedings of the 13th IEEE/ACM International Conference on Computer Aided Design_, pages 8-12, San Jose, CA, 2000.
* Hsu et al. [2011] Meng-Kai Hsu, Yao-Wen Chang, and Valeriy Balabanov. TSV-aware analytical placement for 3D IC designs. In _Proceedings of the 48th Design Automation Conference_, pages 664-669, San Diego, CA, 2011.
* Janez [2006] Demsar Janez. Statistical comparisons of classifiers over multiple data sets. _Journal of Machine Learning Research_, 7:1-30, 2006.
* Kahng and Reda [2006] Andrew B Kahng and Sherief Reda. A tale of two nets: Studies of wirelength progression in physical design. In _Proceedings of the 7th International Workshop on System-level Interconnect Prediction_, pages 17-24, Munich, Germany, 2006.
* Karypis et al. [1997] George Karypis, Rajat Aggarwal, Vipin Kumar, and Shashi Shekhar. Multilevel hypergraph partitioning: Application in VLSI domain. In _Proceedings of the 34th annual Design Automation Conference_, pages 526-529, Anaheim, CA, 1997.
* Kirkpatrick et al. [1983] Scott Kirkpatrick, C Daniel Gelatt Jr, and Mario P Vecchi. Optimization by simulated annealing. _Science_, 220(4598):671-680, 1983.
* Lai et al. [2023] Yao Lai, Jinxin Liu, Zhentao Tang, Bin Wang, Jianye Hao, and Ping Luo. Chipformer: Transferable chip placement via offline decision transformer. In _Proceedings of the 40th International Conference on Machine Learning_, pages 18346-18364, Honolulu, HA, 2023.
* Lai et al. [2022] Yao Lai, Yao Mu, and Ping Luo. Maskplace: Fast chip placement via reinforced visual representation learning. In _Advances in Neural Information Processing Systems 35_, New Orleans, LA, 2022.
* Lin and Chang [2002] Jai-Ming Lin and Yao-Wen Chang. TCG-S: Orthogonal coupling of P*-admissible representations for general floorplans. In _Proceedings of the 39th Annual Design Automation Conference_, page 842-847, New Orleans, LA, 2002.
* Lin et al. [2020] Yibo Lin, Zixuan Jiang, Jiaqi Gu, Wuxi Li, Shounak Dhar, Haoxing Ren, Brucek Khailany, and David Z Pan. DREAMPlace: Deep learning toolkit-enabled gpu acceleration for modern VLSI placement. _IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems_, 40(4):748-761, 2020.
* Lu et al. [2015] Jingwei Lu, Pengwen Chen, Chin-Chih Chang, Lu Sha, Dennis Jen-Hsin Huang, Chin-Chi Teng, and Chung-Kuan Cheng. ePlace: Electrostatics-based placement using fast Fourier transform and Nesterov's method. _ACM Transactions on Design Automation of Electronic Systems_, 20(2):1-34, 2015.

* [30] Done MacMillen, Raul Camposano, D. Hill, and Thomas W. Williams. An industrial view of electronic design automation. _IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems_, 19(12):1428-1448, 2000.
* [31] Igor L Markov, Jin Hu, and Myung-Chul Kim. Progress and challenges in VLSI placement research. In _Proceedings of the 25th International Conference on Computer-Aided Design_, pages 275-282, San Jose, CA, 2012.
* [32] Azalia Mirhoseini, Anna Goldie, Mustafa Yazgan, Joe Wenjie Jiang, Ebrahim Songhori, Shen Wang, Young-Joon Lee, Eric Johnson, Omkar Pathak, Azade Nazi, et al. A graph placement methodology for fast chip design. _Nature_, 594(7862):207-212, 2021.
* [33] Hiroshi Murata, Kunihiro Fujiyoshi, Shigetoshi Nakatake, and Yoji Kajitani. VLSI module placement based on rectangle-packing by the sequence-pair. _IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems_, 15(12):1518-1524, 1996.
* [34] Shigetoshi Nakatake, Kunihiro Fujiyoshi, Hiroshi Murata, and Yoji Kajitani. Module packing based on the BSG-structure and IC layout applications. _IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems_, 17(6):519-530, 1998.
* [35] Gi-Joon Nam, Charles J Alpert, Paul Villarrubia, Bruce Winter, and Mehmet Yildiz. The ISPD2005 placement contest and benchmark suite. In _Proceedings of the 9th International Symposium on Physical Design_, pages 216-220, San Francisco, CA, 2005.
* [36] Jan M Rabaey, Anantha P Chandrakasan, and Borivoje Nikolic. _Digital Integrated Circuits_. Pearson, 2002.
* [37] Jarrod A Roy, Saurabh N Adya, David A Papa, and Igor L Markov. Min-cut floorplacement. _IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems_, 25(7):1313-1326, 2006.
* [38] Khushro Shahookar and Pinaki Mazumder. VLSI cell placement techniques. _ACM Computing Surveys_, 23(2):143-220, 1991.
* [39] Arun Shanbhag, S Danda, and Naveed Sherwani. Floorplanning for mixed macro block and standard cell designs. In _Proceedings of 4th Great Lakes Symposium on VLSI_, pages 26-29, Notre Dame, IN, 1994.
* [40] M Shunmugathammal, C Christopher Columbus, and S Anand. A novel b*-tree crossover-based simulated annealing algorithm for combinatorial optimization in VLSI fixed-outline floorplans. _Circuits, Systems, and Signal Processing_, 39(2):900-918, 2020.
* [41] Peter Spindler and Frank M Johannes. Fast and accurate routing demand estimation for efficient routability-driven placement. In _Proceedings of the 14th Conference on Design, Automation & Test in Europe_, pages 1-6, Nice, France, 2007.
* [42] Maolin Tang and Xin Yao. A memetic algorithm for VLSI floorplanning. _IEEE Transactions on Systems, Man, and Cybernetics_, 37(1):62-69, 2007.
* [43] Michael Upton, Khosrow Samii, and Stephen Sugiyama. Integrated placement for mixed macro cell and standard cell designs. In _Proceedings of the 27th ACM/IEEE Design Automation Conference_, pages 32-35, San Francisco, CA, 1991.
* [44] Dhruv Vashisht, Harshit Rampal, Haiguang Liao, Yang Lu, Devika Shanbhag, Elias Fallon, and Levent Burak Kara. Placement in integrated circuits using cyclic reinforcement learning and simulated annealing. _arXiv preprint arXiv:2011.07577_, 2020.
* [45] Laung-Terng Wang, Yao-Wen Chang, and Kwang-Ting Tim Cheng. _Electronic Design Automation: Synthesis, Verification, and Test_. Morgan Kaufmann, 2009.
* [46] Qi Xu, Hao Geng, Song Chen, Bo Yuan, Cheng Zhuo, Yi Kang, and Xiaoqing Wen. Good-floorplan: Graph convolutional network and reinforcement learning-based floorplanning. _IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems_, 41(10):3492-3502, 2021.

* [47] Junchi Yan, Xianglong Lyu, Ruoyu Cheng, and Yibo Lin. Towards machine learning for placement and routing in chip design: A methodological overview. _arXiv preprint arXiv:2202.13564_, 2022.
* [48] Florian Zaruba and Luca Benini. The cost of application-class processing: Energy and performance analysis of a linux-ready 1.7-ghz 64-bit RISC-V core in 22-nm FDSOI technology. _IEEE Transactions on Very Large Scale Integration Systems_, 27(11):2629-2640, 2019.
* [49] Zhi-Hua Zhou, Yang Yu, and Chao Qian. _Evolutionary Learning: Advances in Theories and Algorithms_. Springer, 2019.

Experimental Settings

The detailed statistics of benchmarks are in Table 5. Each column in the table represents the following:

* #Macros: the number of macros.
* #Standard cells: the number of standard cells.
* #Hyper-edges: the number of hyper-edges.
* #Macro-related Hyper-edges: the number of hyper-edges that are related to Marco, which is used in the objective evaluation process of WireMask-BBO.
* Area Utilization Ratio: the proportion of the total area of the chip canvas that is occupied by the macros, calculated by dividing the area of the macros by the total area of the chip canvas. A higher Area Utilization Ratio to some extent indicates a harder placement problem, because we have to maintain the non-overlapping property.
* #Partitions: the number of partitions when discretizing the chip canvas into grids.

All columns, except for #Partitions, are predetermined and unalterable in the benchmark.3 The #Partitions, however, constitutes a crucial hyperparameter, which is determined heuristically based on the heights and widths of the macros and the canvas. To elaborate, in the case where multiple macros of identical size, e.g., \(30\times 20\), are present on a given chip, with the canvas size \(9000\times 9000\), the value of #Partitions would be set to \(300\), thereby resulting in a grid size of \(30\times 30\) for each grid. The influence of #Partitions is discussed in Table 7 of Appendix B.2.

Footnote 3: Note that for the _bigblue2_ chip, which has over 20,000 macros and 30,000 macro-related hyper-edges, a single objective evaluation by step-by-step placement costs more than an hour. Thus, we do not include this chip in our experiments as [26], and its #Partitions is denoted as /.

## Appendix B Additional Results

### Post local search

As the genotype-phenotype mapping in the objective evaluation of WireMask-BBO is performed greedily, guided by wire mask, we propose a post local search procedure to modify the final generated macro placement, which will probably bring further improvement. For a final generated macro placement, the positions of all macros are sequentially adjusted; the position of each macro is adjusted to the best grid (ties are broken randomly) which reduces the current HPWL value most. Note that when adjusting the position of one macro, all the other macros are fixed, which is different from that in the objective evaluation of WireMask-BBO, which is only based on the positions of those macros that have been adjusted. We have applied this post local search procedure to the final placements generated by SP-SA [33], MaskPlace [26] and WireMask-BBO. The macros are adjusted sequentially according to the order employed by WireMask-BBO (i.e., lines 1-2 in Algorithm 1); this process is performed twice. Note that the adjustment order of macros can be arbitrary when applying this post local search process. The results in Table 6 show that the final placements can be further improved, which is expected because both MaskPlace and WireMask involve (probabilistically) greedy incremental placement guided by wire mask.

\begin{table}
\begin{tabular}{l r r r r r r} \hline \hline Benchmark & \#Macros & \#Standard cells & \#Hyper-edges & \#Macro-related Hyper-edges & Area Utilization Ratio & \#Partitions \\ \hline adapter1 & 543 & 210,904 & 3,709 & 693 & 0.48 & 160 \\ adapter5 & 566 & 254,457 & 266,009 & 4,201 & 0.63 & 158 \\ adaptec3 & 723 & 459,927 & 466,758 & 3,259 & 0.55 & 113 \\ adapter4 & 1,329 & 494,716 & 515,951 & 2,949 & 0.48 & 108 \\ bigbine1 & 560 & 277,604 & 284,479 & 409 & 0.27 & 160 \\ bigbine2 & 23,084 & 534,782 & 577,235 & 33,223 & 0.38 & / \\ bigbine3 & 1,298 & 1,095,514 & 1,123,170 & 3,937 & 0.66 & 234 \\ bigbine4 & 8,170 & 2,196,183 & 2,229,886 & 22,223 & 0.37 & 273 \\ ariane & 932 & 0 & 12,404 & 12,404 & 0.78 & 357 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Detailed statistics of different benchmarks.

### Hyper-parameter analysis

We empirically investigate the influence of the the hyper-parameters of WireMask-EA, i.e., the number of partitions when discretizing the chip canvas into grids, the order of adjusting the positions of macros in objective evaluation, and the mutation operator.

Number of partitions.In our main experiments, the number of partitions is heuristically determined based on detailed macro statistics and varies across different chips, ranging from 108 for _adaptec4_ to 273 for _bigblue4_, as shown in Table 5. The first two rows of Table 7 show the results of WireMask-EA after increasing and decreasing the number of partitions by 100, respectively. The last row gives the results of the default WireMask-EA, achieving the highest average rank.

By increasing the grid partition number, more fine-grained genotype-phenotype mapping guided by wire mask can be achieved, but the computational overhead is also increased. If the grid partition number is too small, the mapping may even not lead to non-overlapping placements, as observed on the chips _adaptec2_, _adaptec3_ and _adaptec4_ after decreasing the grid partition number by \(100\). Thus, a good balance needs to be considered, when determining the grid partition number in practice.

Order of adjusting the positions of macros.In the objective evaluation of WireMask-BBO, the positions of macros are adjusted sequentially, in the decreasing order of the sum of area of each macro's connected cells, as shown in lines 1-2 of Algorithm 1. Here, we also test the random adjustment order and the order only considering the area of each macro itself, the results of which are shown in the first two rows, respectively, of Table 8.

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \hline benchmark & \multicolumn{1}{c}{adaptec1} & \multicolumn{1}{c}{adaptec2} & \multicolumn{1}{c}{adaptec3} & \multicolumn{1}{c}{adiptec4} & \multicolumn{1}{c}{bigblue1} & \multicolumn{1}{c}{bigblue3} & \multicolumn{1}{c}{bigblue4} & \multicolumn{1}{c}{\(+/-/\approx\)} & Avg. Rank \\ \hline SP-SA [33] & \(18.84\pm 4.62\) & \(117.36\pm 8.73\) & \(115.48\pm 7.56\) & \(120.03\pm 4.25\) & \(5.12\pm 1.43\) & \(164.70\pm 19.55\) & \(25.49\pm 2.73\) & \\ after\_local\_search & \(12.52\pm 1.59\) & \(97.22\pm 8.34\) & \(104.46\pm 7.73\) & \(102.17\pm 5.50\) & \(2.70\pm 0.17\) & \(138.85\pm 14.53\) & \(14.94\pm 0.84\) & \\ \hline MaxPlace [26] & \(6.56\) & \(79.98\) & \(79.33\) & \(75.75\) & \(2.42\) & \(82.61\) & / & \(9.69\) \\ after\_local\_search & \(6.15\pm 0.05\) & \(72.46\pm 3.69\) & \(74.18\pm 0.68\) & \(67.99\pm 1.13\) & \(2.22\pm 0.02\) & \(77.87\pm 1.54\) & / & \\ \hline WireMask-RS & \(6.13\pm 0.05\) & \(59.28\pm 1.48\) & \(60.60\pm 0.45\) & \(62.06\pm 0.22\) & \(2.19\pm 0.01\) & \(62.58\pm 2.07\) & \(8.20\pm 0.17\) & \(3.57\) \\ after\_local\_search & \(5.99\pm 0.06\) & \(57.23\pm 1.75\) & \(59.22\pm 0.40\) & \(60.99\pm 0.82\) & \(2.17\pm 0.01\) & \(58.32\pm 3.57\) & \(7.64\pm 0.24\) & \\ \hline WireMask-BO & \(6.07\pm 0.14\) & \(59.17\pm 3.94\) & \(61.00\pm 2.08\) & \(63.86\pm 1.01\) & \(2.14\pm 0.03\) & \(67.48\pm 6.49\) & \(8.62\pm 0.18\) & \\ after\_local\_search & \(6.04\pm 0.12\) & \(54.24\pm 2.92\) & \(60.29\pm 2.29\) & \(62.96\pm 1.16\) & \(2.13\pm 0.01\) & \(63.87\pm 8.26\) & \(7.86\pm 0.21\) & \\ \hline WireMask-EA & \(5.91\pm 0.07\) & \(52.63\pm 2.23\) & \(57.75\pm 1.16\) & \(58.79\pm 1.02\) & \(2.12\pm 0.01\) & \(59.87\pm 3.40\) & \(8.28\pm 0.25\) & \\ after\_local\_search & \(5.89\pm 0.07\) & \(49.04\pm 2.35\) & \(57.41\pm 1.04\) & \(57.72\pm 0.76\) & \(2.11\pm 0.01\) & \(56.29\pm 5.23\) & \(7.66\pm 0.26\) & \\ \hline \hline \end{tabular}
\end{table}
Table 6: HPWL values (\(\times 10^{5}\)) obtained by post local search on existing placements. The last column, Avg. Imp., denotes the average improvement ratio across seven chips, obtained by comparing the HPWL values before and after post local search.

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline \hline Method & \multicolumn{1}{c}{adaptec1} & \multicolumn{1}{c}{adaptec2} & \multicolumn{1}{c}{adaptec3} & \multicolumn{1}{c}{adipec4} & \multicolumn{1}{c}{bigblue1} & \multicolumn{1}{c}{bigblue3} & \multicolumn{1}{c}{bigblue4} & \(+/-/\approx\) & Avg. Rank \\ \hline \(+100\)\_grid\_num & \(\bm{5.88\pm 0.69}\) & \(56.97\pm 2.16\) & \(\bm{57.74\pm 0.98}\) & \(59.36\pm 1.10\) & \(2.30\pm 0.02\) & \(62.93\pm 3.36\) & \(8.32\pm 0.24\) & \(0.3/4\) & 1.71 \\ \(-100\)\_grid\_num & \(7.07\pm 0.18\) & \(\times\) & \(\times\) & \(\times\) & \(\times\) & \(3.06\pm 0.07\) & \(84.37\pm 4.14\) & \(10.14\pm 0.30\) & \(0/4/0\) & 3.00 \\ default setting & \(5.91\pm 0.07\) & \(\bm{52.63\pm 2.23}\) & \(57.75\pm 1.16\) & \(\bm{58.79\pm 1.02}\) & \(\bm{2.12\pm 0.01}\) & \(\bm{59.87\pm 3.40}\) & \(\bm{5.28\pm 0.25}\) & & \(\bm{1.28}\) \\ \hline \hline \end{tabular}
\end{table}
Table 7: HPWL values (\(\times 10^{5}\)) obtained by WireMask-EA under different grid partition numbers. The symbol \(\times\) denotes that the method fails to generate non-overlapping placements. The best (smallest) mean value on each chip is bolded. The symbols ‘\(+\)’, ‘\(-\)’, and ‘\(\approx\)’ indicate that the number of chips where the result is significantly superior to, inferior to, and almost equivalent to the default setting, respectively, according to the Wilcoxon rank-sum test with significance level 0.05.

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline \hline Benchmark & \multicolumn{1}{c}{adaptec1} & \multicolumn{1}{c}{adaptec2} & \multicolumn{1}{c}{adaptec3} & \multicolumn{1}{c}{adipec4} & \multicolumn{1}{c}{bigblue1} & \multicolumn{1}{c}{bigblue3} & \multicolumn{1}{c}{bigblue4} & \(+/-/\approx\) & Avg. Rank \\ \hline random\_order & \(12.65\pm 0.68\) & \(\times\) & \(\times\) & \(93.25\pm 4.66\) & \(3.40\pm 0.09\) & \(\times\) & \(\times\) & \(0/3/0\) & 3.00 \\ size\_only\_order & \(6.32\pm 0.13\) & \(\bm{47.39\pm 1.02}\) & \(61.18\pm 1.03\) & \(\bm{54.57\pm 1.69}\) & \(2.16\pm 0.01\) & \(102.99\pm 7.69\) & \(10.80\pm 0.24\) & \(2/5/0\) & 1.71 \\ default setting & \(\bm{5.91\pm 0.07}\) & \(52.63\pm 2.23\) & \(\bm{57.75\pm 1.16}\) & \(\bm{58.79\pm 1.02}\) & \(\bm{2.12\pm 0.01}\) & \(\bm{59.87\pm 3.40}\) & \(\bm{5.28\pm 0.25}\) & & \(\bm{1.28}\) \\ \hline \hline \end{tabular} \end{The random order always leads to the worst result, and may even fail to generate non-overlapping placements. Compared with using the order only considering each macro's area, the original WireMask-EA performs significantly better on five chips, and worse on the other two chips. Its best overall performance is expected, because the order considering the sum of area of each macro's connected cells is more closely related to the performance metric HPWL.

Mutation operator.For WireMask-EA, which performs the best among the three variants of WireMask-BBO, we also examine the influence of its mutation operator. We employed the swap mutation operator in our experiments, which randomly selects two macros and interchanges their coordinates. To further investigate, we implement the uniform mutation operator as well, which selects a macro at random and uniformly reallocates it on the chip canvas. Moreover, we combine these two mutation operators, with each being executed with a probability of 1/2. As shown in Figure 5, the utilization of the swap mutation operator alone (i.e., Swap_only) performs better than using the uniform mutation operator alone (i.e., Uniform_only) or their combination (i.e., Mix).

### Number of evaluations

Table 9 lists the number of evaluations used by WireMask-RS, WireMask-BO and WireMask-EA in Table 1, each of which runs for 1000 minutes. The number of evaluations of RS and EA is rather close, indicating that our EA operator is quite efficient. Besides, BO uses fewer evaluations than RS and EA, owing to the time-consuming cost of updating the Gaussian process model and optimizing the acquisition function.

Figure 5: HPWL \((\times 10^{5})\) vs. wall clock time of WireMask-EA using different mutation operators, where the shaded region represents the standard error derived from 5 independent runs.

\begin{table}
\begin{tabular}{l c c c c c c c} \hline \hline
1000 min & adaptec1 & adaptec2 & adaptec3 & adaptec4 & bigblue1 & bigblue3 & bigblue4 \\ \hline WireMask-RS & 3610 & 3689 & 5257 & 2791 & 7367 & 976 & 106 \\ WireMask-BO & 820 & 655 & 810 & 600 & 1580 & 540 & 59 \\ WireMask-EA & 3526 & 3540 & 5179 & 2685 & 7217 & 877 & 97 \\ \hline \hline \end{tabular}
\end{table}
Table 9: Number of evaluations of WireMask-RS, WireMask-BO and WireMask-EA in Table 1.

### Results on the _ariane_ benchmark

We evaluate the performance of our WireMask-BBO framework on another benchmark, the _ariane_ RISC-V CPU design [48], which has been previously studied in works such as [32, 26]. Our evaluation involves a comparison with three analytical methods and three RL methods, and the results are summarized in Table 10. The results of analytical and RL methods are directly from [26]. The analytical methods all fail to generate non-overlapping placement results on _ariane_, likely due to its high macro area utilization ratio of 0.78, which is the largest among all the benchmarks in Table 5. The overlapping issue is consistent with our discussion presented in Section 2.3. The RL-based methods show significantly worse performance compared to our proposed WireMask-BBO methods. The three different variants of WireMask-BBO are comparable based on the statistical test, with WireMask-EA demonstrating the lowest mean HPWL value.

### Comparison with concurrent works

Recently, ChiPFormer [25] and AutoDMP [4] are proposed as new state-of-the-art methods in macro placement. For a comprehensive comparison, we also conduct experiments with these two concurrent works here.

ChiPFormer.ChiPFormer [25] incorporates an offline learning decision transformer to improve the generalizability. The pre-trained model provides placement results with acceptable quality within minutes, and converges to better results than MaskPlace [26] using fewer evaluations. We have compared our proposed WireMask-EA with ChiPFormer on ten chips, as outlined in Table 11. The experimental results show that our WireMask-EA clearly outperforms ChiPFormer on 9 circuits out of 10, no matter the number of evaluations is 1, 300 or 2k.

AutoDMP.AutoDMP [4] improves the efficient DREAMIPace [28], using Bayesian optimization to explore the configuration space and showing potential in real EDA application. We have included running time comparison between the state-of-the-art method AutoDMP [4] and our proposed WireMask-EA as shown in Figure 6. The results of MaskPlace (3k evaluations) and ChiPFormer (2k evaluations) are ploted by dotted lines in the figure. We can observe that on the two chip benchmarks, _adaptec1_ and _bigblue1_, AutoDMP and WireMask-EA can surpass MaskPlace and ChiPFormer quickly, and WireMask-EA performs the best.

\begin{table}
\begin{tabular}{c c c c} \hline \hline Method & Type & ariane & \(+/-/\approx\) \\ \hline NTUPlace3 [12] & Analytical & \(\times\) & \\ RePlace [13] & Analytical & \(\times\) & \\ DREAMIPace [28] & Analytical & \(\times\) & \\ Graph [32] & RL & \(16.89\pm 0.60\) & \(-\) \\ DeepPR [15] & RL & \(52.20\pm 0.89\) & \(-\) \\ MaskPlace [26] & RL & \(14.63\pm 0.20\) & \(-\) \\ WireMask-RS & Ours & \(9.90\pm 0.18\) & \(\approx\) \\ WireMask-BO & Ours & \(9.71\pm 0.46\) & \(\approx\) \\ WireMask-EA & Ours & \(\mathbf{9.68\pm 0.61}\) & \\ \hline \hline \end{tabular}
\end{table}
Table 10: Comparison of HPWL values \((\times 10^{5})\) on the _ariane_ benchmark [48]. A ‘\(\times\)’ symbol means that the method fails the legalization and thus cannot generate non-overlapping placement results.The best (smallest) mean value is bolded. The symbols ‘\(+\)’, ‘\(-\)’ and ‘\(\approx\)’ indicate that the result is significantly superior to, inferior to, and almost equivalent to WireMask-EA, respectively, according to the Wilcoxon rank-sum test with significance level 0.05.

\begin{table}
\begin{tabular}{l|c c|c c|c c} \hline \hline Benchmark & ChiPFormer (1) & WireMask-EA (1) & ChiPFormer (0.3k) & WireMask-EA (0.3k) & ChiPFormer (2k) & WireMask-EA (\(\Sigma\)k) \\ \hline adapted1 & \(8.87\pm 0.98\) & \(\bm{7.20\pm 0.34}\) & \(7.02\pm 0.11\) & \(\bm{6.29\pm 0.07}\) & \(6.62\pm 0.05\) & \(\bm{5.96\pm 0.08}\) \\ adgtpc2 & \(123.7\pm 22.61\) & \(\bm{11.04\pm 2.009}\) & \(70.42\pm 2.67\) & \(\bm{61.25\pm 4.10}\) & \(67.10\pm 5.46\) & \(\bm{53.88\pm 2.53}\) \\ adgtpc3 & \(107.11\pm 8.84\) & \(\bm{75.37\pm 2.93}\) & \(78.32\pm 2.03\) & \(\bm{64.49\pm 1.69}\) & \(76.70\pm 1.15\) & \(\bm{59.26\pm 1.30}\) \\ adgtpc4 & \(85.63\pm 7.52\) & \(75.63\pm 1.30\) & \(69.42\pm 0.54\) & \(\bm{64.52\pm 1.81}\) & \(68.80\pm 1.59\) & \(\bm{59.52\pm 1.71}\) \\ bigblue1 & \(3.11\pm 0.03\) & \(\bm{2.31\pm 0.06}\) & \(2.96\pm 0.04\) & \(\bm{2.18\pm 0.01}\) & \(2.95\pm 0.04\) & \(\bm{2.14\pm 0.01}\) \\ bigblue3 & \(131.78\pm 17.36\) & \(\bm{99.20\pm 24.69}\) & \(81.48\pm 4.83\) & \(\bm{64.51\pm 4.15}\) & \(72.92\pm 2.56\) & \(\bm{56.65\pm 2.81}\) \\ ibm01 & \(4.57\pm 0.27\) & \(\bm{3.76\pm 0.36}\) & \(3.61\pm 0.08\) & \(\bm{2.92\pm 0.07}\) & \(3.05\pm 0.11\) & \(\bm{2.39\pm 0.07}\) \\ ibm02 & \(6.01\pm 0.41\) & \(\bm{5.13\pm 0.16}\) & \(4.84\pm 0.17\) & \(\bm{3.86\pm 0.03}\) & \(4.24\pm 0.25\) & \(\bm{3.56\pm 0.05}\) \\ ibm03 & \(\bm{2.15\pm 0.17}\) & \(3.10\pm 0.12\) & \(\bm{1.75\pm 0.07}\) & \(2.20\pm 0.11\) & \(\bm{1.64\pm 0.06}\) & \(1.69\pm 0.11\) \\ ibm04 & \(5.00\pm 0.14\) & \(\bm{3.60\pm 0.17}\) & \(4.19\pm 0.11\) & \(\bm{2.93\pm 0.11}\) & \(4.06\pm 0.13\) & \(\bm{2.62\pm 0.04}\) \\ \hline \hline \end{tabular}
\end{table}
Table 11: HPWL values (\(\times 10^{5}\)) obtained by the recent proposed state-of-the-art method ChiPFormer [25] and our proposed WireMask-EA on ten chips, including _adapter_ and _bigblue_ from ISPD2005 benchmark [35] and _ibm_ from ICCAD2004 benchmark [3]. The number in \(()\) denotes the number of evaluations used. Each result consists of the mean and standard deviation of five runs. The best (smallest) mean value on each chip is bolded.

Figure 6: HPWL \((\times 10^{5}\)) vs. wall clock time of WireMask-EA and AutoDMP [4], where the shaded region represents the standard error derived from 5 independent runs.