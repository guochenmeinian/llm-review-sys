# Variational Inference for Interacting Particle Systems

with Discrete Latent States

 Giosue Migliorini

Department of Statistics

University of California, Irvine &Padhraic Smyth

Department of Statistics and Computer Science

University of California, Irvine

###### Abstract

We present a novel Bayesian learning framework for interacting particle systems with discrete latent states, addressing the challenge of inferring dynamics from partial, noisy observations. Our approach learns a variational posterior path measure by parameterizing the generator of the underlying continuous-time Markov chain. We formulate the problem as a multi-marginal Schrodinger bridge with aligned samples, employing a two-stage learning procedure. Our method incorporates an emission distribution for decoding latent states and uses a scalable variational approximation.

## 1 Introduction

Many real-world phenomena, from epidemics to wildfires, can be modeled as systems of interacting components evolving in continuous time, where the underlying dynamics are governed by discrete latent states. This paradigm extends the concept of hidden Markov models (Baum and Petrie, 1966; Kouemou and Dymarski, 2011) to spatially structured, continuous-time processes. Interacting particle systems (IPSs) (Liggett, 1985; Lanchier, 2024) offer a powerful mathematical framework for describing local propagation dynamics. However, inferring the rules governing these systems from partial, noisy observations remains a significant challenge. We propose a novel Bayesian approach that addresses this challenge by learning a variational posterior path measure on the space of IPS trajectories. Our approach parameterizes the rate matrix of the continuous-time Markov chain (CTMC) of the latent IPS using neural networks and incorporates an emission model that can decode internal discrete states to continuous data and noisy observations. Key contributions of our approach include:

* Framing the problem as a multi-marginal discrete Schrodinger bridge, solved by a two-stage procedure: learning an endpoint-conditioned process for trajectory reconstruction, followed by distillation to an unconditional process for prediction.
* A scalable variational approximation using site-wise factorization of time-marginals and assuming independent particle evolution in infinitesimal time intervals conditionally on the present global configuration, enabling efficient learning for high-dimensional spatio-temporal processes.
* Flexibility in incorporating domain knowledge through informative priors on rate matrix entries and neural architectures with desirable inductive biases.

We demonstrate preliminary results of our approach on two simulated datasets for the following tasks: reconstructing the trajectory of an epidemic on a network and predicting wildfire spread on a lattice. For a description of the notation, see Appendix A. An overview of the relevant literature is presented in Appendix B, while proofs and other derivations are provided in Appendix C.

## 2 Background

Interacting particle systemsConsider a graph \(\mathcal{G}=(V,E)\), and denote \(i\sim j\) if there is an edge between the vertices \(i,j\), i.e., \(\{i,j\}\in E\). Following Liggett (1985), we refer to vertices \(i\in V\) as sites. For a countable local state space \(S\), consider the configuration space \(\mathcal{Z}:=\{\boldsymbol{z}\mid\boldsymbol{z}:V\to S\}\). For our analysis, we assume both \(V\) and \(S\) to be finite. An IPS adds a continuous-time dimension to this setting. Specifically, we obtain a CTMC \(\boldsymbol{z}(t)\) on \(\mathcal{Z}\) restricted to a time interval \([0,T]\), whose path space we denote \(\Omega_{[0,T]}\). We define \(z^{i}(t)\in S\) as the state of site \(i\) at time \(t\). We consider a scenario where the dynamics of each site are described by local transition rates that depend on the graph's connectivity (Lanchier, 2017), corresponding to

\[\lambda_{t}^{s\to\tilde{s}}(i,\boldsymbol{z}(t))\coloneqq\lim_{\Delta t\to 0 }\frac{1}{\Delta t}\mathbb{P}\left(z^{i}(t+\Delta t)=\tilde{s}\mid z^{i}(t)=s, \,z^{j}(t):\,i\sim j\right),\]

for \(s\) to \(s^{\prime}\neq s\) at site \(i\) and time \(t\in[0,T]\), and set \(\lambda_{t}^{s\to s}(i,\boldsymbol{z}(t))\coloneqq-\sum_{s^{\prime}\neq s} \lambda_{t}^{s\to s^{\prime}}(i,\boldsymbol{z}(t))\). The local transition rates for each site can be compactly represented as matrices \(\boldsymbol{\lambda}_{t}(i,\boldsymbol{z}(t))\).

**Definition 1** (Local generator).: _A mapping \(\mathbf{\Lambda}_{t}:\mathcal{Z}\times[0,T]\to\mathbb{R}^{|V|\times|S|\times|S|}\) assigning to each configuration \(\boldsymbol{z}(t)\) a three-dimensional array containing the local transition rate matrices \(\boldsymbol{\lambda}_{t}(i,\boldsymbol{z}(t))\) for all sites \(i\in V\)._

One can characterize the CTMC on the space of configurations by making the additional assumption that updates at each site happen independently from one another. Then, for an arbitrarily small \(\Delta t\) and \(\tilde{\boldsymbol{z}}\in\mathcal{Z}\),

\[p_{t+\Delta t|t}(\tilde{\boldsymbol{z}}|\boldsymbol{z})\approx\delta_{ \boldsymbol{z},\tilde{\boldsymbol{z}}}+\Delta t\sum_{i\in V}\lambda_{t}^{z^{i} \to\tilde{z}^{i}}(i,\boldsymbol{z}(t))\prod_{j\neq i}\delta_{z^{j},\tilde{z}^ {j}}+o(\Delta t).\] (1)

For brevity, we denote these transition rates as \(\Lambda_{t}(\tilde{\boldsymbol{z}}\mid\boldsymbol{z})\coloneqq\sum_{i\in V} \lambda_{t}^{z^{i}\to\tilde{z}^{i}}(i,\boldsymbol{z}(t))\prod_{j\neq i} \delta_{z^{j},\tilde{z}^{j}}\). A detailed derivation can be found in Appendix C.3. We refer to endpoint-conditioned processes as Markov bridges, and we provide a quick overview in Appendix C.1 for noisy data.

## 3 Variational Discrete Interacting Particle Systems

We consider a dataset of sequences of observations in a space \(\mathcal{X}\) and observation times \(\{\boldsymbol{x}_{1:K_{j}}^{(j)},t_{1:K_{j}}^{(j)}\}_{j=1:N}\). We assume these are noisy observations of a latent IPS \((\boldsymbol{z}^{(j)}(t))_{t\in[t_{1}^{(j)},t_{K_{j}}^{(j)}]}\in\Omega_{[t_{1}^ {(j)},t_{K}^{(j)}]}\). Pairwise conditional independence is assumed for any couple of observations in a sequence, i.e. \(\boldsymbol{x}_{k}^{(j)}\perp\boldsymbol{x}_{k}^{(j)}\mid\boldsymbol{z}^{(j)}(t)\) for \(t\in[t_{k}^{(j)},t_{k}^{(j)}]\) and \(t_{k}^{(j)}<t_{k}^{(j)}\). The discrete set of measurement times \(t_{1}^{(j)}<\cdots<t_{K_{j}}^{(j)}\) is allowed to be arbitrarily defined for each sequence, e.g., at random or regularly spaced. For ease of illustration, we present our results for a fixed set of observation times \(t_{1},\ldots,t_{K}\), but the extension to irregularly sampled time series is straightforward and presented in Appendix C.2. We assume that the graph determining the particles' dependence structure is fixed for each realization and directly deducible from the observed sequences.

Consider an emission distribution \(p_{t}(\boldsymbol{x}\mid\boldsymbol{z})\in\mathcal{P}(\mathcal{X})\) and a prior path measure \(P\in\mathcal{P}(\Omega_{[t_{1},t_{K}]})\) for the latent IPS. This can be specified directly on the entries of a prior local generator, encoding possible constraints in the latent dynamics, and by an initial prior distribution. Let \(\mathrm{P}\in\mathcal{P}(\mathcal{X}^{K}\times\Omega_{[t_{1},t_{K}]})\)

Figure 1: An illustration of our methodology on a simulated noiseless dataset of wildfire propagation. The first model approximates a Markov bridge interpolating between the observations, enabling to reconstruct the unobserved trajectory. The second model, approximating the unconditional process, can predict beyond the last observation. Results shown for a held-out example.

denote the reference measure constructed by gluing the prior and emission probabilities at each observed timestep, i.e. \(\mathrm{P}(d\bm{x}_{1:K},(d\bm{z}(t))_{t\in[t_{1},t_{K}]})=\prod_{k=1}^{K}p_{t_{k}} (d\bm{x}_{k}\mid\bm{z}(t_{k}))P((d\bm{z}(t))_{t\in[t_{1},t_{K}]})\). The marginal distribution of the data at an observation time \(t_{k}\) is denoted as \(\pi_{k}\in\mathcal{P}(\mathcal{X})\), for \(k=1,\ldots,K\). For a given sequence of distributions \(\{\pi_{k}\}_{k=1:K}\), we can express a multi-marginal discrete Schrodinger bridge problem with noisy observations as

\[\mathrm{Q}^{*}\coloneqq\operatorname*{arg\,min}_{\mathrm{Q}\in\mathcal{P}( \mathcal{X}^{K}\times\Omega_{[t_{1},t_{K}]})}\{D_{\mathrm{KL}}(\mathrm{Q}\,|| \,\mathrm{P})\,|\,q_{t_{k}}=\pi_{k},\,k=1,\ldots,K\},\] (2)

where \(q_{t_{k}}\in\mathcal{P}(\mathcal{X})\) correspond to marginalizations of \(\mathrm{Q}\) at each observed timepoint in the space of observations \(\mathcal{X}\).

Our goal is twofold:

* **Trajectory reconstruction**, by learning the conditional local generator \(\bm{\Lambda}_{t}(\cdot\mid\bm{x}_{1:K})\) of the Markov bridge \(Q^{*}_{\cdot\mid\bm{x}_{1:K}}\in\mathcal{P}(\Omega_{[t_{1},t_{K}]})\);
* **Prediction**, by learning the local generator \(\bm{\Lambda}_{t}\) of the Markov process \(Q^{*}\in\mathcal{P}(\Omega_{[t_{1},t_{K}]})\), enabling extrapolation beyond an observed time window or with no past observations at all for a given graph.

We show that the second goal can be achieved by distilling knowledge from a model trained for the first goal into a model that does not glance at future observations.

### Trajectory reconstruction

Let \(\pi_{1:K}\) denote the coupling solving the static version of (2), that is

\[\pi_{1:K}=\operatorname*{arg\,min}_{q_{1:K}\in\mathcal{P}(\mathcal{X}^{K})}\{ D_{\mathrm{KL}}(q_{t_{1:K}}\mid\mid p_{t_{1:K}})\,|\,q_{k}=\pi_{k},\,k=1,\ldots,K\},\] (3)

where \(p_{1:K}\in\mathcal{P}(\mathcal{X}^{K})\) is the marginal of the observed trajectories obtained from the reference measure \(\mathrm{P}\). Similarly to the setting considered in Sommath et al. (2023), we assume that our dataset is comprised of trajectories of _aligned_ samples, in the sense that each observed trajectory \(\bm{x}_{1:K}\) is sampled from the coupling \(\pi_{1:K}\). By the additive property of the Kullback-Leibler divergence (Leonard, 2013), the dynamic problem in equation 2 can be rewritten as

\[\operatorname*{arg\,min}_{Q\in\mathcal{P}(\Omega_{[t_{1},t_{K}]})}\mathbb{E} _{\pi_{1:K}}\left[D_{\mathrm{KL}}(Q_{\cdot\mid\bm{x}_{1:K}}\mid\mid P_{\cdot \mid\bm{x}_{1:K}})\right].\] (4)

As samples from \(\pi_{1:K}\) are available, we can treat this stage as a _smoothing_ problem, and perform approximate posterior inference.

#### 3.1.1 Noiseless data

In the special case where observations are noiseless snapshots of the IPS, i.e. \(\bm{x}_{k}=\bm{z}(t_{k})\), the latent variables in the model correspond to the unobserved portions of the stochastic process of the form \((\bm{z}(t))_{t\in(t_{k},t_{k+1})}\). The emission distribution corresponds to the transition probability \(p_{t_{k}}(\bm{x}\mid\bm{z})=\lim_{t\to t_{k+1}^{-}}\mathbb{P}(\bm{z}(t_{k})= \bm{x}\mid\bm{z}(t)=\bm{z})\), obtained from the prior rates using equation 1. We learn a variational posterior \(Q^{\theta}\in\mathcal{P}(\Omega_{[t_{1},t_{K}]})\) through amortization (Amos et al., 2023), by parameterizing the local generator of the approximate Markov bridge with a neural model \(\Lambda^{\theta}\), having parameters \(\theta\in\Theta\).

**Proposition 2**.: _Let (3) admit a solution \(\pi_{1:K}\). Moreover, let \(\bm{x}_{1:K}\) be noiseless observations of \((\bm{z}(t))\in\Omega_{[0,T]}\), and let \(P\in\mathcal{P}(\Omega_{[0,T]})\). Then, the amortized version of the problem in equation 2 reduces to_

\[\operatorname*{arg\,min}_{\theta\in\Theta}\sum_{k=1}^{K-1}\mathbb{E}_{\pi_{k,k+ 1}}\left[D_{\mathrm{KL}}(Q^{\theta}_{\cdot\mid\bm{x}_{k},\bm{x}_{k+1}}||\,P)- \mathbb{E}_{Q^{\theta}_{\cdot\mid\bm{x}_{k},\bm{x}_{k+1}}}[\log p_{t_{k+1}}( \bm{x}_{k+1}\mid\bm{z}(t_{k+1}^{-}))]\right],\] (5)

_where \(\pi_{k,k+1}\in\mathcal{P}(\mathcal{X}^{2})\) is obtained by marginalizing \(\pi_{1:K}\), and \(\bm{z}(t_{k+1}^{-})=\lim_{t\to t_{k+1}^{-}}\bm{z}(t)\)._

Notice that this parameterization is highly scalable as it allows mini-batching across segments of time. The KL divergence of two CTMCs can be estimated using Monte Carlo integration, using the analytic form derived in Opper and Sanguinetti (2007), see Appendix C.4 for a derivation.

#### 3.1.2 Noisy data

In order to learn a conditional model with noisy data, we propose to parameterize our variational posterior in an autoregressive fashion, extending the method proposed in Seifner and Sanchez (2023). The authors propose to compute a single hidden representation of the entire sequence via an ODE-RNN model (Rubanova et al., 2019), and then condition the inference model at every time step using that variable. We extend their approach by letting the conditioning variable change through time, only capturing dependence on future observations. Note that the option to drop conditioning on past observations follows naturally from the conditional independence assumption. We do not need to train multiple models to accomplish this, as it is enough to checkpoint the ODE-RNN model at the observation times. We can express the variational posterior as

\[q^{\theta}_{t_{1}}(d\bm{z}(t_{1})\,|\,h_{t_{1}}(\bm{x}_{1:K}))\prod_{k=1}^{K-1 }dQ^{\theta}((d\bm{z}(t))_{t\in(t_{k},t_{k+1})}\,|\,\bm{z}(t_{k}),h^{\theta}_{t _{k}}(\bm{x}_{k+1:K})),\] (6)

where \(q^{\theta}_{t_{1}}\) is a Categorical distribution parameterized by an encoder. The model can be learned by minimizing the negative evidence lower bound

\[\mathcal{L}^{\text{AR}}(\theta)\coloneqq\mathbb{E}_{\pi_{1:K}}\left[D_{\text {KL}}(Q^{\theta}_{:|\bm{x}_{1:K}}\,||\,P)-\mathbb{E}_{Q^{\theta}_{:|\bm{x}_{1 :K}}}\left[\sum_{k=1}^{K}\log p_{t_{k}}(\bm{x}_{k}\,\mid\bm{z}(t_{k}))\right] \right].\] (7)

#### 3.1.3 Simulation

While at sampling time any exact stochastic simulation algorithm (e.g. Gillespie, 2001) can be employed, at training time we are limited to differentiable approximations. We propose two options, trading off assumptions on the variational family for scalability.

Forward simulationThis approach involves fixing a time-discretization grid \(t_{k}<t_{k}+\Delta t<\dots<t_{k+1}-\Delta t<t_{k+1}\) and sampling iteratively from a Gumbell-softmax approximation (Jang et al., 2017) to equation 1, updating the latent state \(\bm{z}(t+\Delta t)=\bm{z}(t)+N_{t}^{\theta}(\Delta t,\bm{z}(t))\), where \(N_{t}^{\theta}\) is the jump process describing the latent CTMC. While this method is exact in the limit \(\Delta t\to 0\) and requires no additional restrictions to the variational family, its cost scales linearly with respect to the number of jumps (Jia and Benson, 2019). However, we are not required to compute inflow rates (of the form \(\lambda^{s\to z^{i}}\)), but only outflow rates (like \(\lambda^{z^{i}\to s}\)), making the output of our local rates model scale linearly with respect to \(|S|\).

Neural master equationTechniques from the literature on neural ODEs (Chen et al., 2021) can be applied if we consider a factorized posterior \(q_{t}(\bm{z}\,\mid\bm{x}_{1:K})=\prod_{i\in V}q_{t}^{i}(z^{i}\mid\bm{x}_{1:K})\). Note that spatial dependence is still propagated through time, as the local rates model depends on the global configuration (or a neighborhood restriction). For notational simplicity we omit conditioning on \(\bm{x}_{1:K}\), but note that this applies to conditional and unconditional settings alike. We can then simulate from the system of marginal master equations given initial conditions \(q_{1}^{i}(z_{1}^{i}),\,i\in V,\) as

\[\partial_{t}q_{t}^{i}(z^{i}(t))=\sum_{s\neq z^{i}(t)}\Bigl{(}\mathbb{E}_{q_{i }^{-i}}\bigl{[}\lambda_{t}^{s\to z^{i}(t)}(i,\bm{z}(t))\bigr{]}q_{t}^{i}(s)- \mathbb{E}_{q_{t}^{-i}}\bigl{[}\lambda_{t}^{z^{i}(t)\to s}(i,\bm{z}(t)) \bigr{]}q_{t}^{i}(z^{i}(t))\Bigr{)}\,,\,\,i\in V.\] (8)

This variational approximation was introduced for continuous-time Bayesian networks in Linzner and Koeppl (2018) under the name of _star_-approximation. This is to be distinguished from the _mean-field_ approach, where the approximation entails either a fixed rate for each site or compartmental models directly describing the mean-field behaviour of the system (Seifner and Sanchez, 2023; Opper and Sanguinetti, 2007; Cohn et al., 2010). As the solution to equation 8 is a continuous function, one can use the memory-efficient adjoint method (Chen et al., 2021; Seifner and Sanchez, 2023) at training time, making this approach extremely scalable.

### Prediction

The trajectory reconstruction model learned in Section 3.1 approximates the Schrodinger bridge \(\mathrm{Q}^{\star}\) through an endpoint-conditioned scheme for the latent trajectories, leveraging the factorization \(Q^{\theta}_{:|\bm{x}_{1:K}}((dz(t))_{t\in[t_{1},t_{K})})\pi_{1:K}(d\bm{x}_{1:K})\). However, for many applications, we require the ability togenerate predictions beyond observed time intervals. Given an initial observation \(\bm{x}_{1}\) at time \(t_{1}\), we aim to predict observations at arbitrary times \(\tilde{t}\in(t_{1},t_{K}]\). This prediction task leverages an alternative factorization of \(\mathrm{Q}^{\star}\):

\[q_{\tilde{t}}^{\star}(d\bm{x}_{\tilde{t}}\mid\bm{z}(\tilde{t}\,))Q^{\star}_{ \mid\bm{x}_{1}}((d\bm{z}(t))_{t\in[t_{1},t_{K}]})\pi_{1}(d\bm{x}_{1}).\]

While it can be shown that \(q_{\tilde{t}}^{\star}(\bm{x}_{\tilde{t}}\mid\bm{z}(\tilde{t}\,))=p_{\tilde{t}} (\bm{x}_{\tilde{t}}\mid\bm{z}(\tilde{t}\,))\) using the additive property of the KL, the models developed thus far are constrained by their dependence on endpoint conditions. To overcome this limitation, we propose learning an unconditional amortized posterior \(Q^{\phi}\) by minimizing the KL divergence

\[\mathcal{L}_{\text{KL}}(\phi)\coloneqq D_{\text{KL}}(Q^{\star}\,||\,Q^{\phi}) \propto\mathbb{E}_{\pi_{1:K}}\left[D_{\text{KL}}(Q^{\star}_{\mid\bm{x}_{1:K}},||,Q^{\phi})\right].\] (9)

A direct computation of this loss is intractable due to the unavailability of \(Q^{\star}\) and \(Q^{\star}_{\mid\bm{x}_{1:K}}\), hence we employ the surrogate loss function

\[\hat{\mathcal{L}}_{\text{KL}}^{\theta}(\phi)\coloneqq\mathbb{E}_{\pi_{1:K}} \left[D_{\text{KL}}(Q^{\theta}_{\mid\bm{x}_{1:K}},||,Q^{\phi})\right].\] (10)

The absolute difference between these quantities can be upper bounded in terms of the total variation distance between the solution to equation 2 and our conditional approximation. We provide a detailed analysis of the bound in Appendix C.6.

## 4 Experiments

We demonstrate our methodology on two simulated scenarios: epidemic trajectory inference on networks and wildfire spread prediction on lattices. We parameterize the neural models for the local generators with a novel architecture, detailed in Appendix D. Results and details of the simulations are reported in Appendix E.

## 5 Conclusion

We introduce a variational inference method to fit partially observed trajectories whose dynamics can be modeled by a continuous-time latent process, parameterized as an interacting particle system. Our solution is an approximation to a multi-marginal Schrodinger bridge, that we obtain by first fitting an endpoint-conditioned model and then distilling it into an unconditional one. This methodology enables both trajectory reconstruction and prediction of future states. In future work we aim at testing our models on real data, comparing with state-of-the-art methods.

## References

* Albergo and Vanden-Eijnden [2022] Michael Samuel Albergo and Eric Vanden-Eijnden. Building normalizing flows with stochastic interpolants. _The Eleventh International Conference on Learning Representations_, 2022.
* Aldous [2013] David Aldous. Interacting particle systems as stochastic social dynamics. _Bernoulli_, pages 1122-1149, 2013.
* Alt and Koeppl [2023] Bastian Alt and Heinz Koeppl. Entropic matching for expectation propagation of markov jump processes. _arXiv preprint arXiv:2309.15604_, 2023.
* Amos et al. [2023] Brandon Amos et al. Tutorial on amortized optimization. _Foundations and Trends in Machine Learning_, 16(5):592-732, 2023.
* Baum and Petrie [1966] Leonard E Baum and Ted Petrie. Statistical inference for probabilistic functions of finite state markov chains. _The annals of mathematical statistics_, 37(6):1554-1563, 1966.
* Berghaus et al. [2024] David Berghaus, Kostadin Cvejoski, Patrick Seifner, Cesar Ojeda, and Ramses J Sanchez. Foundation inference models for markov jump processes. _arXiv preprint arXiv:2406.06419_, 2024.
* Bladt and Sorensen [2005] Mogens Bladt and Michael Sorensen. Statistical inference for discretely observed markov jump processes. _Journal of the Royal Statistical Society Series B: Statistical Methodology_, 67(3):395-410, 2005.
* Bladt et al. [2014]Nicholas M Boffi and Eric Vanden-Eijnden. Deep learning probability flows and entropy production rates in active matter. _Proceedings of the National Academy of Sciences_, 121(25):e2318106121, 2024.
* Bongini et al. (2017) Mattia Bongini, Massimo Fornasier, Markus Hansen, and Mauro Maggioni. Inferring interaction rules from observations of evolutive systems i: The variational approach. _Mathematical Models and Methods in Applied Sciences_, 27(05):909-951, 2017.
* Boys et al. (2008) Richard J Boys, Darren J Wilkinson, and Thomas BL Kirkwood. Bayesian inference for a discretely observed stochastic kinetic model. _Statistics and Computing_, 18:125-135, 2008.
* Bramson and Griffeath (1980) Maury Bramson and David Griffeath. Asymptotics for interacting particle systems on z d. _Zeitschrift fur Wahrscheinlichkeitstheorie und verwandte Gebiete_, 53(2):183-196, 1980.
* Campbell et al. (2022) Andrew Campbell, Joe Benton, Valentin De Bortoli, Thomas Rainforth, George Deligiannidis, and Arnaud Doucet. A continuous time framework for discrete denoising models. _Advances in Neural Information Processing Systems_, 35:28266-28279, 2022.
* Campbell et al. (2024) Andrew Campbell, Jason Yim, Regina Barzilay, Tom Rainforth, and Tommi Jaakkola. Generative flows on discrete state-spaces: Enabling multimodal flows with applications to protein co-design. In _Forty-first International Conference on Machine Learning_, 2024.
* Chen et al. (2021) Ricky TQ Chen, Brandon Amos, and Maximilian Nickel. Neural spatio-temporal point processes. In _International Conference on Learning Representations_, 2021.
* Chen et al. (2024) Yifan Chen, Mark Goldstein, Mengjian Hua, Michael S Albergo, Nicholas M Boffi, and Eric Vanden-Eijnden. Probabilistic forecasting with stochastic interpolants and f\(\backslash\)"ollmer processes. _arXiv preprint arXiv:2403.13724_, 2024.
* Chen et al. (2019) Yongxin Chen, Giovanni Conforti, Tryphon T Georgiou, and Luigia Ripani. Multi-marginal schrodinger bridges. In _International Conference on Geometric Science of Information_, pages 725-732. Springer, 2019.
* Cohn et al. (2010) Ido Cohn, Tal El-Hay, Nir Friedman, and Raz Kupferman. Mean field variational approximation for continuous-time bayesian networks. _The Journal of Machine Learning Research_, 11:2745-2783, 2010.
* Comas et al. (2023) Armand Comas, Yilun Du, Christian Fernandez Lopez, Sandesh Ghimire, Mario Sznaier, Joshua B Tenenbaum, and Octavia Camps. Inferring relational potentials in interacting systems. In _International Conference on Machine Learning_, pages 6364-6383. PMLR, 2023.
* Corstanje and van der Meulen (2023) Marc Corstanje and Frank van der Meulen. Guided simulation of conditioned chemical reaction networks. _arXiv preprint arXiv:2312.04457_, 2023.
* Corstanje et al. (2023) Marc Corstanje, Frank van der Meulen, and Moritz Schauer. Conditioning continuous-time markov processes by guiding. _Stochastics_, 95(6):963-996, 2023.
* De Bortoli et al. (2021) Valentin De Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet. Diffusion schrodinger bridge with applications to score-based generative modeling. _Advances in Neural Information Processing Systems_, 34:17695-17709, 2021.
* Dolgov and Savostyanov (2024) Sergey Dolgov and Dmitry Savostyanov. Tensor product approach to modelling epidemics on networks. _Applied Mathematics and Computation_, 460:128290, 2024.
* Durrett (2006) Rick Durrett. Ten lectures on particle systems. _Lectures on Probability Theory: Ecole d'Ete de Probabilites de Saint-Flour XXIII--1993_, pages 97-201, 2006.
* Feng et al. (2022) Jinchao Feng, Mauro Maggioni, Patrick Martin, and Ming Zhong. Learning interaction variables and kernels from observations of agent-based systems. _IFAC-PapersOnLine_, 55(30):162-167, 2022.
* Fitzsimmons et al. (1992) Pat Fitzsimmons, Jim Pitman, and Marc Yor. Markovian bridges: construction, palm interpretation, and splicing. In _Seminar on Stochastic Processes, 1992_, pages 101-134. Springer, 1992.
* Fitzsimmons et al. (2019)Andrew Gelman, Aki Vehtari, Daniel Simpson, Charles C Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian Burkner, and Martin Modrak. Bayesian workflow. _arXiv preprint arXiv:2011.01808_, 2020.
* Gillespie [2001] Daniel T Gillespie. Approximate accelerated stochastic simulation of chemically reacting systems. _The Journal of chemical physics_, 115(4):1716-1733, 2001.
* Golightly and Sherlock [2019] Andrew Golightly and Chris Sherlock. Efficient sampling of conditioned markov jump processes. _Statistics and Computing_, 29:1149-1163, 2019.
* Grattarola et al. [2021] Daniele Grattarola, Lorenzo Livi, and Cesare Alippi. Learning graph cellular automata. _Advances in Neural Information Processing Systems_, 34:20983-20994, 2021.
* Grinstein et al. [1985] Grinstein, C Jayaprakash, and Yu He. Statistical mechanics of probabilistic cellular automata. _Physical review letters_, 55(23):2527, 1985.
* Hobolth and Stone [2009] Asger Hobolth and Eric A Stone. Simulation from endpoint-conditioned, continuous-time markov chains on a finite state space, with applications to molecular evolution. _The annals of applied statistics_, 3(3):1204, 2009.
* Igashov et al. [2023] Ilia Igashov, Arne Schneuing, Marwin Segler, Michael Bronstein, and Bruno Correia. Retrobridge: Modeling retrosynthesis with markov bridges. _arXiv preprint arXiv:2308.16212_, 2023.
* Jackson [2011] Christopher Jackson. Multi-state models for panel data: the msm package for r. _Journal of statistical software_, 38:1-28, 2011.
* Jang et al. [2017] Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparametrization with gumble-softmax. In _International Conference on Learning Representations (ICLR 2017)_, 2017.
* Jia and Benson [2019] Junteng Jia and Austin R Benson. Neural jump stochastic differential equations. _Advances in Neural Information Processing Systems_, 32, 2019.
* Kalkhof et al. [2024] John Kalkhof, Arlene Kuhn, Yannik Frisch, and Anirban Mukhopadhyay. Frequency-time diffusion with neural cellular automata. _arXiv preprint arXiv:2401.06291_, 2024.
* Kang et al. [2024] Beomseok Kang, Harshit Kumar, Minah Lee, Biswadeep Chakraborty, and Saibal Mukhopadhyay. Learning locally interacting discrete dynamical systems: Towards data-efficient and scalable prediction. In _Proceedings of the 6th Annual Learning for Dynamics and Control Conference_, volume 242, pages 1357-1369, 2024.
* Keeling and Eames [2005] Matt J Keeling and Ken TD Eames. Networks and epidemic models. _Journal of the Royal Society Interface_, 2(4):295-307, 2005.
* Kidger [2021] P Kidger. _On neural differential equations_. PhD thesis, University of Oxford, 2021.
* Kim et al. [2024] Jun Hyeong Kim, Seonghwan Kim, Seokhyun Moon, Hyeongwoo Kim, Jeheon Woo, and Woo Youn Kim. Discrete diffusion schr\"'odinger bridge matching for graph transformation. _arXiv preprint arXiv:2410.01500_, 2024.
* Kohs et al. [2021] Lukas Kohs, Bastian Alt, and Heinz Koeppl. Variational inference for continuous-time switching dynamical systems. _Advances in Neural Information Processing Systems_, 34:20545-20557, 2021.
* Kouemou and Dymarski [2011] Guy Leonard Kouemou and Dr Przemyslaw Dymarski. History and theoretical basics of hidden markov models. _Hidden Markov models, theory and applications_, 1, 2011.
* Kummerle et al. [2024] Christian Kummerle, Mauro Maggioni, and Sui Tang. Learning transition operators from sparse space-time samples. _IEEE Transactions on Information Theory_, 2024.
* Lanchier [2017] Nicolas Lanchier. _Stochastic modeling_. Springer, 2017.
* Lanchier [2024] Nicolas Lanchier. _Stochastic interacting systems in life and social sciences_, volume 5. Walter de Gruyter GmbH & Co KG, 2024.
* Lang et al. [2024] Quanjun Lang, Xiong Wang, Fei Lu, and Mauro Maggioni. Interacting particle systems on networks: joint inference of the network and the interaction kernel. _arXiv preprint arXiv:2402.08412_, 2024.
* Lanchier et al. [2021]Hugo Lavenant, Stephen Zhang, Young-Heon Kim, and Geoffrey Schiebinger. Towards a mathematical theory of trajectory inference. _arXiv preprint arXiv:2102.09204_, 2021.
* Leonard [2013] Christian Leonard. A survey of the schr\(\backslash\)"' odinger problem and some of its connections with optimal transport. _arXiv preprint arXiv:1308.0215_, 2013.
* Li et al. [2021] Zhongyang Li, Fei Lu, Mauro Maggioni, Sui Tang, and Cheng Zhang. On the identifiability of interaction functions in systems of interacting particles. _Stochastic Processes and their Applications_, 132:135-163, 2021.
* Liggett [1985] Thomas Milton Liggett. _Interacting particle systems_, volume 2. Springer, 1985.
* Linzner [2021] Dominik Linzner. _Scalable Inference in Graph-coupled Continuous-time Markov Chains_. PhD thesis, Technische Universitat Darmstadt, 2021.
* Linzner and Koeppl [2018] Dominik Linzner and Heinz Koeppl. Cluster variational approximations for structure learning of continuous-time bayesian networks from incomplete data. In _Advances in Neural Information Processing Systems_, volume 31, 2018.
* Lipman et al. [2022] Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le. Flow matching for generative modeling. In _The Eleventh International Conference on Learning Representations_, 2022.
* Liu et al. [2022] Xingchao Liu, Chengyue Gong, and Qiang Liu. Flow straight and fast: Learning to generate and transfer data with rectified flow. _arXiv preprint arXiv:2209.03003_, 2022.
* Liu et al. [2015] Yu-Ying Liu, Shuang Li, Fuxin Li, Le Song, and James M Rehg. Efficient learning of continuous-time hidden markov models for disease progression. _Advances in neural information processing systems_, 28, 2015.
* Liu et al. [2023] Yuxuan Liu, Scott G McCalla, and Hayden Schaeffer. Random feature models for learning interacting dynamical systems. _Proceedings of the Royal Society A_, 479(2275):20220835, 2023.
* Lou et al. [2023] Aaron Lou, Chenlin Meng, and Stefano Ermon. Discrete diffusion language modeling by estimating the ratios of the data distribution. _arXiv preprint arXiv:2310.16834_, 2023.
* Lu et al. [2021] Fei Lu, Mauro Maggioni, and Sui Tang. Learning interaction kernels in heterogeneous systems of agents from multiple trajectories. _Journal of Machine Learning Research_, 22(32):1-67, 2021.
* McGibbon and Pande [2015] Robert T McGibbon and Vijay S Pande. Efficient maximum likelihood parameterization of continuous-time markov processes. _The Journal of chemical physics_, 143(3), 2015.
* Mordvintsev et al. [2020] Alexander Mordvintsev, Ettore Randazzo, Eyvind Niklasson, and Michael Levin. Growing neural cellular automata. _Distill_, 2020. URL https://distill.pub/2020/growing-ca/.
* Nodelman et al. [2002] Uri Nodelman, Christian R Shelton, and Daphne Koller. Continuous time bayesian networks. In _Proceedings of the Eighteenth conference on Uncertainty in artificial intelligence_, pages 378-387, 2002.
* Norris [1998] James R Norris. _Markov chains_. Number 2. Cambridge university press, 1998.
* Opper and Sanguinetti [2007] Manfred Opper and Guido Sanguinetti. Variational inference for markov jump processes. _Advances in neural information processing systems_, 20, 2007.
* Palm et al. [2022] Rasmus Berg Palm, Miguel Gonzalez Duque, Shyam Sudhakaran, and Sebastian Risi. Variational neural cellular automata. In _International Conference on Learning Representations_, 2022.
* Pare et al. [2020] Philip E Pare, Carolyn L Beck, and Tamer Basar. Modeling, estimation, and analysis of epidemics over networks: An overview. _Annual Reviews in Control_, 50:345-360, 2020.
* Peluchetti [2023] Stefano Peluchetti. Diffusion bridge mixture transports, schrodinger bridge problems and generative modeling. _Journal of Machine Learning Research_, 24(374):1-51, 2023.
* Rao and Teh [2013] Vinayak Rao and Yee Whye Teh. Fast mcmc sampling for markov jump processes and extensions. _Journal of Machine Learning Research_, 14:3295-3320, 2013.
* Rao et al. [2015]Yulia Rubanova, Ricky TQ Chen, and David K Duvenaud. Latent ordinary differential equations for irregularly-sampled time series. _Advances in neural information processing systems_, 32, 2019.
* Cachay et al. (2024) Salva Ruhling Cachay, Bo Zhao, Hailey Joren, and Rose Yu. Dyffusion: A dynamics-informed diffusion model for spatiotemporal forecasting. _Advances in Neural Information Processing Systems_, 36, 2024.
* Seifner and Sanchez (2023) Patrick Seifner and Ramses J Sanchez. Neural markov jump processes. In _International Conference on Machine Learning_, pages 30523-30552. PMLR, 2023.
* Shen et al. (2024) Yunyi Shen, Renato Berlinghieri, and Tamara Broderick. Multi-marginal schr\(\backslash\)" odinger bridges with iterative reference. _arXiv preprint arXiv:2408.06277_, 2024.
* Shi et al. (2024) Yuyang Shi, Valentin De Bortoli, Andrew Campbell, and Arnaud Doucet. Diffusion schrodinger bridge matching. _Advances in Neural Information Processing Systems_, 36, 2024.
* Somnath et al. (2023) Vignesh Ram Somnath, Matteo Pariset, Ya-Ping Hsieh, Maria Rodriguez Martinez, Andreas Krause, and Charlotte Bunne. Aligned diffusion schrodinger bridges. In _Uncertainty in Artificial Intelligence_, pages 1985-1995. PMLR, 2023.
* Sun et al. (2022) Haoran Sun, Lijun Yu, Bo Dai, Dale Schuurmans, and Hanjun Dai. Score-based continuous-time discrete diffusion models. _arXiv preprint arXiv:2211.16750_, 2022.
* Tamir et al. (2023) Ella Tamir, Martin Trapp, and Arno Solin. Transport with support: Data-conditional diffusion bridges. _Transactions on Machine Learning Research_, 2023.
* Tesfaldet et al. (2022) Mattie Tesfaldet, Derek Nowrouzezahrai, and Chris Pal. Attention-based neural cellular automata. _Advances in Neural Information Processing Systems_, 35:8174-8186, 2022.
* Tong et al. (2023) Alexander Tong, Nikolay Malkin, Guillaume Huguet, Yanlei Zhang, Jarrid Rector-Brooks, Kilian Fatras, Guy Wolf, and Yoshua Bengio. Improving and generalizing flow-based generative models with minibatch optimal transport. In _ICML Workshop on New Frontiers in Learning, Control, and Dynamical Systems_, 2023.
* Vargas et al. (2021) Francisco Vargas, Pierre Thodoroff, Austen Lamacraft, and Neil Lawrence. Solving schrodinger bridges via maximum likelihood. _Entropy_, 23(9):1134, 2021.
* Wang (2021) Qingcan Wang. _Selected Topics in Deep Learning Theory and Continuous-Time Hidden Markov Models_. Princeton University, 2021.
* Wildner and Koeppl (2019) Christian Wildner and Heinz Koeppl. Moment-based variational inference for markov jump processes. In _International Conference on Machine Learning_, pages 6766-6775. PMLR, 2019.
* Wolfram (1986) Stephen Wolfram. Theory and applications of cellular automata. _World Scientific_, 1986.
* Wulff and Hertz (1992) N Wulff and J A Hertz. Learning cellular automaton dynamics with neural networks. _Advances in Neural Information Processing Systems_, 5, 1992.
* Yang et al. (2022) Liu Yang, Constantinos Daskalakis, and George E Karniadakis. Generative ensemble regression: Learning particle dynamics from observations of ensembles with physics-informed deep generative models. _SIAM Journal on Scientific Computing_, 44(1):B80-B99, 2022.
* Zhang et al. (2017) Boqian Zhang, Jiangwei Pan, and Vinayak A Rao. Collapsed variational bayes for markov jump processes. _Advances in Neural Information Processing Systems_, 30, 2017.

## Appendix A Notation

Let \(\Omega_{[0,T]}\) be the space of \(\mathcal{Z}\)-valued cadlag functions over a time interval \([0,T]\), and denote by \(\mathcal{P}(\Omega_{[0,T]})\) the space of probability measure on the path space. We denote by \(\Omega_{[t,t^{\prime}]}\) time restrictions of \(\Omega_{[0,T]}\) to \([t,t^{\prime}]\), for \(0\leq t<t^{\prime}\leq T\). We denote the cartesian product \(\times_{k\in[K]}\mathcal{X}\) of observations at \(K\) times as \(\mathcal{X}^{K}\). Consider the Polish space \(\mathcal{Q}\coloneqq\mathcal{X}^{K}\times\Omega_{[0,T]}\) and probability measures \(\mathrm{Q},\mathrm{P}\in\mathcal{P}(\mathcal{Q})\). We introduce the following notation:

* The marginal probability measures over observations, given by the canonical projection \(\phi:\mathcal{Q}\rightarrow\mathcal{X}^{K}\) and denoted as \(q_{1:K}\coloneqq\phi_{\#}\mathrm{Q}\), \(p_{1:K}\coloneqq\phi_{\#}\mathrm{P}\).
* The marginal path measures over latent trajectories, given by the canonical projection \(\varphi:\mathcal{Q}\rightarrow\Omega_{[0,T]}\) and denoted as \(Q\coloneqq\varphi_{\#}\mathrm{Q}\), \(P\coloneqq\varphi_{\#}\mathrm{P}\).
* The conditional path measures over latent trajectories, given by measurable mappings \(\bm{x}_{1:K}\in\mathcal{X}^{K}\mapsto\mathcal{Q}_{\cdot|\bm{x}_{1:K}}\in \mathcal{P}(\Omega_{[0,T]})\) and \(\bm{x}_{1:K}\in\mathcal{X}^{K}\mapsto\mathcal{P}_{\cdot|\bm{x}_{1:K}}\in \mathcal{P}(\Omega_{[0,T]})\)

For a path measure \(Q\in\mathcal{P}(\Omega_{[0,T]})\), we assume that the time-marginal and transition probability measures are absolutely continuous w.r.t. the counting measure. Their Radon-Nikodym derivative can then be expressed by the probability mass function \(q_{t}(\bm{z})\) and the transition probability \(q_{t^{\prime}|t}(\tilde{\bm{z}}\mid\bm{z})\) for timesteps \(0\leq t<t^{\prime}\leq T\) and configurations \(\bm{z},\ \tilde{\bm{z}}\in\mathcal{Z}\).

## Appendix B Related work

### Learning interacting particle systems

The dynamics of many physical systems can be described through the local interaction laws of their constituent components. This principle has inspired computational frameworks that directly parameterize these governing interactions, both deterministically and stochastically. A prime example is cellular automata (Wolfram, 1986; Grinstein et al., 1985). Early developments focused on studying the emergence of global patterns from a fixed set of rules on the evolution of individual cells. The inverse problem --inferring such rules from observations-- has been of historical interest in the machine learning community (Wulff and Hertz, 1992; Mordvintsev et al., 2020), with recent developments incorporating attention-based architectures, graph neural networks, and black-box variational inference (Tesfaldet et al., 2022; Kang et al., 2024; Grattarola et al., 2021; Palm et al., 2022). Models that learn interaction rules find applications across many domains, including physical simulators, multi-agent dynamics, dynamic graphs, as well as deep generative modeling (Kalkhof et al., 2024).

Within this context, most existing methods have proposed iterative updating schemes by parameterizing transition rules in discrete time. Interacting particle systems (IPSs) offer an alternative mathematical formalism that extends cellular automata to continuous time. Interacting particle systems are structured CTMCs whose states evolve with dependence on neighbors within a topology, typically established by a graph. Lanchier (2017) provides a modern introduction to this field. Classical literature focused on systems with finite states and often countably many sites (Bramson and Griffeath, 1980; Liggett, 1985; Durrett, 2006), while more recent work has focused on systems with finitely many sites (Aldous, 2013). These systems have found applications in multi-agent modeling (Comas et al., 2023) and have been extended to systems of stochastic differential equations (SDEs) in Euclidean space. This extension has seen increased attention recently (Lu et al., 2021; Yang et al., 2022; Feng et al., 2022; Liu et al., 2023; Lang et al., 2024; Kummerle et al., 2024; Boffi and Vanden-Eijnden, 2024). The learnability and identifiability of interaction rules in these systems have also been explored (Bongini et al., 2017; Li et al., 2021).

### Inference for CTMCs

Inference methods for Markov jump processes (MJPs) have been extensively studied. Maximum likelihood estimation for time-homogeneous MJPs is discussed in Jackson (2011); Bladt and Sorensen (2005); McGibbon and Pande (2015). Expectation-maximization techniques for continuous-time hidden Markov models have been developed in Liu et al. (2015), and an overview of the topic can be found in Wang (2021). Bayesian approaches include Markov chain Monte Carlomethods (Boys et al., 2008; Hoboth and Stone, 2009; Rao and Teh, 2013) and variational methods. The latter include mean-field (Opper and Sanguinetti, 2007; Cohn et al., 2010), moment-based methods (Wildner and Koeppl, 2019), combinations with MCMC (Zhang et al., 2017), and extensions to hybrid processes (Kohs et al., 2021). Novel methods include black-box variational inference with neural networks (Seifner and Sanchez, 2023), foundation models (Berghaus et al., 2024), and expectation propagation (Alt and Koeppl, 2023). Another directly related line of research focuses on simulation methods for Markov bridges, notably Corstanje et al. (2023), Corstanje and van der Meulen (2023) and Golightly and Sherlock (2019). While less directly related, it's worth noting recent work discrete flow matching and diffusion methods (Campbell et al., 2022; Igashov et al., 2023; Lou et al., 2023; Campbell et al., 2024). Concurrently to our work, a similar formulation of discrete Schrodinger bridges as CTMCs for two endpoint marginals contraints has been proposed in the context of discrete generative modelling by Kim et al. (2024).

### Trajectory Inference

Trajectory inference is a crucial component of our work, with connections to several recent developments. The Schrodinger bridge (SB) problem with multi-marginal constraints has been explored by Chen et al. (2019), Lavenant et al. (2021). Recent advances in SB methods with a source and a target are presented in Vargas et al. (2021) and De Bortoli et al. (2021), with extensions to the multi-marginal setting by Shen et al. (2024). Our approach shares similarities with Somnath et al. (2023), Shi et al. (2024), and Peluchetti (2023) in that it relies on samples from couplings solving the static SB problem. However, our methodology differs in that we learn the Markovian bridge and recover the unconditional path measure by distillation, rather than relying on closed-form endpoint-conditioned diffusions. The concept of Markov bridge by interpolation with a fictitious dynamic, as proposed by Igashov et al. (2023), is related to stochastic interpolants (Albergo and Vanden-Eijnden, 2022; Tong et al., 2023; Lipman et al., 2022; Liu et al., 2022) for probabilistic forecasting (Chen et al., 2024). Ad-hoc variants for dynamical systems have also been developed (Ruhling Cachay et al., 2024). Our methodology also shares connections with flow matching using Gaussian process and Kalman filter interpolants (Tamir et al., 2023), in the fact that we are interested in _model-based_ interpolants in a Bayesian framework.

## Appendix C Proofs

### Markov bridges

Consider a sequence of observations \(\{\bm{x}_{k}\}_{k\in[K]}\in\mathcal{X}^{K}\) recorded at times \(\{t_{k}\}_{k\in[K]}\in\mathbb{R}^{K}\), and assume conditional independence with respect to a Markov process \((\bm{z}(t))_{t\in[0,T]}\). For \(t\in[t_{0},t_{K-1}]\), let \(\bm{x}_{>t}=\{\bm{x}_{k}\,|\,t_{k}>t,\,k=1,\ldots,K\}\) and \(\bm{x}_{\leq t}=\{\bm{x}_{k}\,|\,t_{k}\leq t,\,k=1,\ldots,K\}\). The next observation after \(t\) is at time \(t^{\prime}\coloneqq\min\{t_{k}:t_{k}>t,\,k=1,\ldots,K\}\), and we assume \(t+\Delta t<t^{\prime}\) for \(\Delta t\approx 0\), by right-continuity of the transition probabilities. We can then denote the conditional transition rates for \(\tilde{\bm{z}}\neq\bm{z}\) as

\[\Lambda_{t}(\tilde{\bm{z}}\mid\bm{z},\,\bm{x}_{0:K}) =\lim_{\Delta t\downarrow 0}\left(\Delta t\right)^{-1}\left[ \mathbb{P}(\bm{z}(t+\Delta t)=\tilde{\bm{z}}\mid\bm{z}(t)=\bm{z},\bm{x}_{0:K})\right]\] \[=\lim_{\Delta t\downarrow 0}\left(\Delta t\right)^{-1}\left[\frac{ \mathbb{P}(\bm{z}(t+\Delta t)=\tilde{\bm{z}},\bm{z}(t)=\bm{z},\bm{x}_{>t}\mid \bm{x}_{\leq t})}{\mathbb{P}(\bm{z}(t)=\bm{z},\bm{x}_{>t}\mid\bm{x}_{\leq t}) }\right]\] \[=\lim_{\Delta t\downarrow 0}\left(\Delta t\right)^{-1}\left[\frac{ \mathbb{P}(\bm{x}_{>t+\Delta t}\mid\bm{z}(t+\Delta t)=\tilde{\bm{z}})\mathbb{ P}(\bm{z}(t+\Delta t)=\tilde{\bm{z}}\mid\bm{z}(t)=\bm{z})}{\mathbb{P}(\bm{x}_{>t} \mid\bm{z}(t)=\bm{z})}\right]\] \[=\Lambda_{t}(\tilde{\bm{z}}\mid\bm{z})\frac{\mathbb{P}(\bm{x}_{>t }\mid\bm{z}(t)=\tilde{\bm{z}})}{\mathbb{P}(\bm{x}_{>t}\mid\bm{z}(t)=\bm{z})},\]

and similarly

\[\Lambda_{t}(\bm{z}\mid\bm{z},\,\bm{x}_{0:K})=-\sum_{\tilde{\bm{z}}\neq\bm{z}} \Lambda_{t}(\tilde{\bm{z}}\mid\bm{z})\frac{\mathbb{P}(\bm{x}_{>t}\mid\bm{z}(t)= \tilde{\bm{z}})}{\mathbb{P}(\bm{x}_{>t}\mid\bm{z}(t)=\bm{z})}.\] (11)

We refer the reader to Fitzsimmons et al. (1992) for a detailed construction.

### Irregularly sampled time series

The problem in equation 2 considers a fixed number of time steps \(K\) and a set of observation times \(t_{1},\ldots,t_{K}\). In this section, we provide an extension to irregular an arbitrary observation times.

We assume that the number of timesteps is i.i.d. for each trajectory, and drawn from \(K\sim p(K)\). The same goes for observation times, that are in turn drawn from \(t_{1:K}\mid K\sim p(t_{1:K}\mid K),\) and \(\bm{x}_{1:K}|t_{1:K}\sim\pi_{1:K}\). We do not model these probabilities, and instead express equation 2 as a solution in expectation, i.e.

\[\mathrm{Q}^{*}_{\cdot|t_{1:K}}\coloneqq\operatorname*{arg\,min}_{\mathrm{Q} \in\mathcal{P}(\mathcal{X}^{K}\times\Omega_{[t_{1},t_{K}]})}\{D_{\mathrm{KL}}( \mathrm{Q}\,||\,\mathrm{P})\,|\,q_{t_{k}}=\pi_{k},\,k=1,\ldots,K\},\quad\mathrm{ Q}^{*}=\mathbb{E}_{K,t_{1:K}}\left[\mathrm{Q}^{*}_{\cdot|t_{1:K}}\right].\] (12)

The amortized problem can be written as

\[\operatorname*{arg\,min}_{\theta\in\Theta}\mathbb{E}_{K,t_{1:K}}\{D_{\mathrm{ KL}}(\mathrm{Q}^{\theta}\,||\,\mathrm{P})\,|\,q_{t_{k}}=\pi_{k},\,k=1,\ldots,K\},\] (13)

where \(\mathrm{Q}^{\theta},\mathrm{P}\in\mathcal{P}(\mathcal{X}^{K}\times\Omega_{[ t_{1},t_{K}]})\).

### From local interactions to a global dynamics

Consider a stochastic process \((\bm{z}(t))\in\Omega_{[0,T]}\), whose dynamics at each site are driven by a system of CTMCs \(\left(z^{i}(t)\right)\), for \(i\in V\). In this section we illustrate that, under an independence assumption of jumps in infinitesimal time intervals, a global description of the dynamics can be deduced. This corresponds to an CTMC on the global state space \(\mathcal{Z}\coloneqq S^{V}\), hence a global master equation (ME) can be derived. This equivalence is well-known in the literature on continuous-time Bayesian networks (Nodelman et al., 2002; Linzner, 2021).

Local dynamics.Let \(\tilde{\bm{z}}^{i,s}\in\mathcal{Z}\) be \(\bm{z}\in\mathcal{Z}\) where we substitute site \(i\in V\) to be \(s\in S\), and denote

\[p_{t}^{i|-i}(s\mid\bm{z}) \coloneqq p_{t}^{i}\left(z^{i}(t)=s\mid\{\bm{z}_{t}(j)=\bm{z}(j),j\neq i \}\right),\] \[p_{t+\Delta t|t}^{i}(s\mid\bm{z}) \coloneqq p_{t}^{i}\left(\bm{z}_{t+\Delta t}(i)=s\mid\{\bm{z}_{t}=\bm{z}\} \right),\] \[p_{t}^{-i}(\bm{z}) \coloneqq\sum_{s\in S}p_{t}(\tilde{\bm{z}}^{i,s}).\]

Let the initial distribution of \(\bm{z}_{0}\) be \(p_{0}\in\mathcal{P}(\mathcal{Z})\), and let each one-dimensional CTMC \((z^{i}(t))\) have a local generator \(\bm{\lambda}_{t}(i,\bm{z})\coloneqq[\lambda_{t}^{s\to s^{\prime}}(i, \tilde{\bm{z}}^{i,s})]_{s,s^{\prime}\in S}\), that is a mapping \(\bm{\lambda}:[0,T]\times V\times\mathcal{Z}\to\mathbb{R}^{|S|\times|S|}\). Local transition rates are defined as

\[\lambda_{t}^{z^{i}\to s}(i,\bm{z})=\begin{cases}\lim_{\Delta t\downarrow 0}p_{t+ \Delta t|t}^{i}(s\mid\bm{z}),&s\neq z^{i},\\ -\sum_{s^{\prime}\neq z^{i}}\lambda_{t}^{z^{i}\to s^{\prime}}(i,\bm{z}),&s=z^{ i}.\end{cases}\]

As we are interested in working with non-homogeneous Markov chains, recovering the Markov kernels from the rate matrix is non-trivial and requires commutativity assumptions of the rate matrix (Norris, 1998). For simplicity, we only consider arbitrarily small time intervals \(0<\Delta t\ll 1\) and adopt a "piece-wise" approximation to the rate matrix, such that it is constant for the interval \([t,t+\Delta t)\). A similar approximation is adopted in the context of generative modelling, by both discrete diffusion (Sun et al., 2022) and flow matching (Campbell et al., 2024). We can then express each site-marginal Markov transition kernel as

\[q_{t+\Delta t|t}^{i}(s\mid\bm{z})\approx\delta_{s,z^{i}}+\Delta t\lambda_{t}^{ z^{i}\to s}(i,\bm{z})+o(\Delta t),\quad i\in V.\] (14)The dynamics at each site \(i\in V\) can be described by _full conditional_ master equations, i.e. defined conditionally on a global configuration fixed at all sites but \(i\). These correspond to

\[\partial_{t}q_{t}^{i|-i}(z^{i}\mid\bm{z})\] \[=\lim_{\Delta t\to 0}\Delta t^{-1}\left[q_{t+\Delta t}^{i|-i}(z^{i} \mid\bm{z})-q_{t}^{i|-i}(z^{i}\mid\bm{z})\right]\] \[=\lim_{\Delta t\to 0}\Delta t^{-1}\left[\sum_{s\in S}q_{t+ \Delta t|t}^{i}(z^{i}\mid\tilde{\bm{z}}^{i,s})q_{t}^{i|-i}(s\mid\bm{z})-q_{t}^ {i|-i}(z^{i}\mid\bm{z})\right]\] \[=\lim_{\Delta t\to 0}\Delta t^{-1}\sum_{s\neq z^{i}}\left[q_{t+ \Delta t|t}^{i}(z^{i}\mid\tilde{\bm{z}}^{i,s})q_{t}^{i|-i}(s\mid\bm{z})-q_{t+ \Delta t|t}^{i}(s\mid\bm{z})q_{t}^{i|-i}(z^{i}\mid\bm{z})\right]\] \[=\sum_{s\neq z^{i}}\left[\lambda_{t}^{s\to z^{i}}(i,\tilde{\bm{z}}^{i,s})q_{t}^{i|-i}(s\mid\bm{z})-\lambda_{t}^{z^{i}\to s}(i,\bm{z})q_{t}^{i|-i}(z ^{i}\mid\bm{z})\right].\] (15)

In matrix form, this can be written as \(\partial_{t}q_{t}^{i|-i}(-\mid\bm{z})=\bm{\lambda}_{t}(i,\bm{z})^{\top}q_{t}^{ i|-i}(-\mid\bm{z})\) for the probability vector \(q_{t}^{i|-i}(-\mid\bm{z})\in\Delta^{|S|}\).

Independent infinitesimal transitions.Consider two global configurations \(\tilde{\bm{z}}\), \(\bm{z}\in\mathcal{Z}\), such that \(\tilde{\bm{z}}\neq\bm{z}\). At time \(t\in[0,1]\) and for \(0<\Delta t\ll 1\), we assume independent transitions along each coordinate and adopt the approximation in (14), so that

\[q_{t+\Delta t|t}(\tilde{\bm{z}}\mid\bm{z}) =\prod_{i\in V}q_{t+\Delta t|t}^{i}(\tilde{z}^{i}\mid\bm{z})\] \[\approx\prod_{i\in V}\left[\delta_{z^{i},\tilde{z}^{i}}+\Delta t \lambda_{t}^{z^{i}\to\tilde{z}^{i}}(i,\bm{z})+o(\Delta t)\right]\] \[=\delta_{\bm{z},\tilde{\bm{z}}}+\Delta t\sum_{i\in V}\lambda_{t}^ {z^{i}\to\tilde{z}^{i}}(i,\bm{z})\prod_{j\neq i}\delta_{\tilde{z}^{j},z^{j}}+o (\Delta t).\] (16)

Notice that the appropriateness of this assumption is highly dependent on the process we are modeling. It is probably a safe assumption for models of propagation on a graph, but it might not be for scenarios where sites are strongly coupled, such as object tracking. In this latter case, a site switching to a state of occupancy would imply that a neighboring site has switched to a state of inoccupancy at the exact same time, which couldn't be captured by the dependence structured described by (16).

Global master equation.We can characterize the generator of a CTMC \(\bm{\Lambda}_{t}=[\Lambda_{t}(\tilde{\bm{z}}\mid\bm{z})]_{\tilde{\bm{z}},\bm {z}\in\mathcal{Z}}\) by populating it with asynchronous site-wise transitions

\[\Lambda_{t}(\tilde{\bm{z}}\mid\bm{z})=\sum_{i\in V}\lambda_{t}^{z^{i}\to \tilde{z}^{i}}(i,\bm{z})\prod_{j\neq i}\delta_{\tilde{z}^{j},z^{j}}\] (17)

and letting \(\Lambda_{t}(\bm{z}\mid\bm{z})=-\sum_{\tilde{\bm{z}}\neq\bm{z}}\Lambda_{t}( \tilde{\bm{z}}\mid\bm{z})\). In other words, the only non-zero entries of the generator are those representing transitions at a single site, and there are at most \(|V|\times|S|\times|S|\) of those, as compared to the \(|S|^{|V|}\times|S|^{|V|}\) entries of the matrix. The ME can then be expressed as

\[\partial_{t}q_{t}(\bm{z}) =\sum_{\tilde{\bm{z}}\neq\bm{z}}\left[\Lambda_{t}(\bm{z}\mid\tilde {\bm{z}})q_{t}(\tilde{\bm{z}})-\Lambda_{t}(\tilde{\bm{z}}\mid\bm{z})q_{t}(\bm{ z})\right]\] \[=\sum_{i\in V}\sum_{s\neq z^{i}}\left[\lambda_{t}^{s\to z^{i}}(i, \tilde{\bm{z}}^{i,s})q_{t}^{i|-i}(s\mid\bm{z})-\lambda_{t}^{z^{i}\to s}(i,\bm{z} )q_{t}^{i|-i}(z^{i}\mid\bm{z})\right]q_{t}^{-i}(\bm{z})\] \[=\sum_{i\in V}\partial_{t}q_{t}^{i|-i}(z^{i}\mid\bm{z})q_{t}^{-i} (\bm{z}).\] (18)

### Derivation of \(D_{\mathrm{KL}}(Q\,||\,P)\)

Consider two CTMCs with path measures \(Q,\,P\in\mathcal{P}(\Omega_{[0,T]})\), and denote their respective rate matrices with \(\Lambda_{t}(\tilde{\bm{z}}\mid\bm{z})\) and \(\Psi_{t}(\tilde{\bm{z}}\mid\bm{z})\) for \(\bm{z},\,\tilde{\bm{z}}\in\mathcal{Z}\). Their KL divergence, as discussed in Opperand Sanguinetti (2007); Seifner and Sanchez (2023), can be derived from the limit of discrete-time transitions with step size \(h\coloneqq T/K\) as

\[\begin{split}& D_{\mathrm{KL}}(Q||P)\\ &=\lim_{K\to\infty}\sum_{\bm{z}_{0:K}}q_{0}(\bm{z}_{0})\prod_{k=0} ^{K-1}q_{k+h|k}(\bm{z}_{k+h}\mid\bm{z}(t_{k}))\log\frac{q_{0}(\bm{z}_{0})\prod_{k =0}^{K-1}q_{k+h|k}(\bm{z}_{k+h}\mid\bm{z}(t_{k}))}{p_{0}(\bm{z}_{0})\prod_{k=0} ^{K-1}p_{k+h|k}(\bm{z}_{k+h}\mid\bm{z}(t_{k}))}\\ &=\sum_{\bm{z}_{0}}q_{0}(\bm{z}_{0})\log\frac{q_{0}(\bm{z}_{0})}{ p_{0}(\bm{z}_{0})}+\lim_{K\to\infty}\sum_{k=0}^{K-1}\mathbb{E}_{q_{k}(\bm{z})} \left[\sum_{\bm{z}_{k+h}}q_{k+h|k}(\bm{z}_{k+h}\mid\bm{z})\log\frac{q_{k+h|k}( \bm{z}_{k+h}\mid\bm{z})}{p_{k+h|k}(\bm{z}_{k+h}\mid\bm{z})}\right]\\ &=D_{\mathrm{KL}}(q_{0}||p_{0})+\int_{0}^{T}\mathbb{E}_{q_{k}( \bm{z})}\sum_{\tilde{\bm{z}}\neq\bm{z}}\bigg{\{}\Psi_{t}(\tilde{\bm{z}}\mid\bm {z})+\Lambda_{t}(\tilde{\bm{z}}\mid\bm{z})\left(\log\frac{\Lambda_{t}(\tilde{ \bm{z}}\mid\bm{z})}{\Psi_{t}(\tilde{\bm{z}}\mid\bm{z})}-1\right)\bigg{\}}dt, \end{split}\] (20)

where the last line follows from dividing and multiplying each summand in (20) by \(h\), and substituting the transition probabilities with rates,

\[\begin{split}\frac{q_{k+h|k}(\bm{z}_{k+h}\mid\bm{z})}{h}\log \frac{q_{k+h|k}(\bm{z}_{k+h}\mid\bm{z})}{p_{k+h|k}(\bm{z}_{k+h}\mid\bm{z})} \xrightarrow[]{h\to 0}\begin{cases}\Lambda_{t}(\bm{z}_{k+h}\mid\bm{z})\log \frac{\Lambda_{t}(\bm{z}_{k+h}\mid\bm{z})}{\Psi_{t}(\bm{z}_{k+h}\mid\bm{z})} &\bm{z}_{k+h}\neq\bm{z},\\ \sum_{\tilde{\bm{z}}\neq\bm{z}}\left[\Psi_{t}(\tilde{\bm{z}}\mid\bm{z})-\Lambda _{t}(\tilde{\bm{z}}\mid\bm{z})\right]&\bm{z}_{k+h}=\bm{z}.\end{cases}\end{split}\]

By assuming transition probabilities of the form \(q_{t+h|t}(\tilde{\bm{z}}\mid\bm{z})=\prod_{i\in V}q_{t+h|t}(\tilde{\bm{z}}(i) \mid\mathcal{N}_{i}(\bm{z}))\) where we define a neighborhood \(\mathcal{N}_{i}(\bm{z})\coloneqq\{z^{i},\bm{z}(j):i\sim j\}\), we can rewrite each summand in (20) as

\[\begin{split}&\mathbb{E}_{q_{k}(\bm{z})}\left[\sum_{\bm{z}_{k+h} }q_{k+h|k}(\bm{z}_{k+h}\mid\bm{z})\log\frac{q_{k+h|k}(\bm{z}_{k+h}\mid\bm{z})} {p_{k+h|k}(\bm{z}_{k+h}\mid\bm{z})}\right]\\ &=\mathbb{E}_{q_{k}(\bm{z})}\left[\sum_{i\in V}\sum_{s\in S}q_{k+h,\,k}^{i}(s\mid\mathcal{N}_{i}(\bm{z}))\log\frac{q_{k+h,\,k}^{i}(s\mid \mathcal{N}_{i}(\bm{z}))}{p_{k+h,\,k}^{i}(s\mid\mathcal{N}_{i}(\bm{z}))} \right].\end{split}\]

Letting \(K\to\infty\) and plugging (8), we get

\[\begin{split}& D_{\mathrm{KL}}(Q||P)\\ &=D_{\mathrm{KL}}(q_{0}||p_{0})+\int_{0}^{T}\mathbb{E}_{q_{t}(\bm{z })}\sum_{i\in V}\sum_{s\neq z^{i}}\bigg{\{}\psi_{t}^{z^{i}\to s}(i,\bm{z})- \lambda_{t}^{z^{i}\to s}(i,\bm{z})\\ &\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad+ \lambda_{t}^{z^{i}\to s}(i,\bm{z})\left(\log\frac{\lambda_{t}^{z^{i}\to s}(i, \bm{z})}{\psi_{t}^{z^{i}\to s}(i,\bm{z})}\right)\bigg{\}}dt.\end{split}\] (21)

### Derivation of the evidence lower bound

We start by proving a simple but fundamental property of the solution to equation 2, by showing that the optimal paths in latent space are Markovian, provided our reference process \(P\in\mathcal{P}(\Omega_{[0,T]})\) is Markovian. This motivates our parameterization of such process as a CTMC.

**Lemma 3** (\(Q^{\star}\) is Markov).: _If \(P\in\mathcal{P}(\Omega_{[0,T]})\) is Markov, then \(Q^{\star}\coloneqq\varphi_{\#}Q^{\star}\) solving equation 2 with reference measure \(\mathrm{P}((d\bm{z}(t))_{t\in[0,T]},d\bm{x}_{1:K})\coloneqq\prod_{k\in[K]}p( d\bm{x}_{k}\mid\bm{z}(t_{k}))P((d\bm{z}(t))_{t\in[0,T]})\) is Markov._

Proof.: The proof is a simple extension of Leonard (2013, Prop. 2.10) to the case where the process is latent, and we restate it here for completeness.

We consider an arbitrary time \(t\in[0,T]\). When it is an observation time, i.e. \(t=t_{k}\) for some \(k=1,\dots,K\), we consider a fixed time-marginal at \(t_{k}\) in observation space, denoted \(\hat{q}_{k}\in\mathcal{P}(\mathcal{X})\), a conditional measure at \(t_{k}\) in latent space \(\hat{q}_{t_{k}}(\cdot|\bm{x}_{k})\in\mathcal{P}(\mathcal{Z})\), and conditional path measures on both latent trajectories and observations, before and after \(t\). These can be denotedas \(\hat{\mathrm{Q}}^{<}_{|\bm{z}(t_{k})}\coloneqq\hat{\mathrm{Q}}^{[0,t_{k})}_{|\bm{z}(t _{k})}\in\mathcal{P}(\Omega_{[0,t_{k})}\times\mathcal{X}_{[0,t_{k})})\) and \(\hat{\mathrm{Q}}^{>}_{|\bm{z}(t_{k})}\coloneqq\hat{\mathrm{Q}}^{(t_{k},T]}_{| \bm{z}(t_{k})}\in\mathcal{P}(\Omega_{(t_{k},T]}\times\mathcal{X}_{(t_{k},T]})\), where we denote, with a slight abuse of notation, \(\mathcal{X}_{[0,t_{k})}\) and \(\mathcal{X}_{(t_{k},T]}\) to be the product space of observations happening before and after \(t_{k}\). When \(t\) is not an observation time, we simply consider a prescribed time-marginal in latent space \(\hat{q}_{t}\in\mathcal{P}(\mathcal{Z})\) and the conditional path measures \(\hat{\mathrm{Q}}^{<}_{|\bm{z}(t)}\coloneqq\hat{\mathrm{Q}}^{[0,t)}_{|\bm{z}(t )}\in\mathcal{P}(\Omega_{[0,t)}\times\mathcal{X}_{[0,t)})\) and \(\hat{\mathrm{Q}}^{>}_{|\bm{z}(t)}\coloneqq\hat{\mathrm{Q}}^{(t,T)}_{|\bm{z}( t)}\in\mathcal{P}(\Omega_{(t_{k},T]}\times\mathcal{X}_{(t_{k},T]})\). As the proof in this case naturally follows from that of Leonard (2013, Prop. 2.10), we focus our attention to the case where \(t\) is an observation time \(t_{k}\).

We want to prove that, among all the joint measures \(\mathrm{Q}\) that satisfy \(q_{k}=\hat{q}_{k}\), \(q_{t_{k}}(\cdot|\bm{x}_{k})=\hat{q}_{t_{k}}(\cdot|\bm{x}_{k})\), \(Q^{<}_{|\bm{z}(t_{k})}=\hat{\mathrm{Q}}^{<}_{|\bm{z}(t_{k})}\) and \(Q^{>}_{|\bm{z}(t_{k})}=\hat{\mathrm{Q}}^{>}_{|\bm{z}(t_{k})}\), a minimum in the KL divergence is attained by

\[\int_{\mathcal{X}}\int_{\mathcal{Z}}\hat{\mathrm{Q}}^{<}_{|\bm{z}(t_{k})} \otimes\hat{\mathrm{Q}}^{>}_{|\bm{z}(t_{k})}\hat{q}_{t_{k}}(d\bm{z}(t_{k})| \bm{x}_{k})\hat{q}_{k}(d\bm{x}_{k}),\] (22)

i.e. the latent process is Markov (Leonard, 2013). By arbitrariness of \(t_{k}\) and of the measures we fix, this is also true for the solution to equation 2. This can be shown by applying the additive property of the KL divergence twice, conditioning on a \(\bm{x}_{k}\) and \(\bm{z}(t_{k})\) first,

\[D_{\mathrm{KL}}(\mathrm{Q}\,||\,\mathrm{P})=D_{\mathrm{KL}}(\hat{q}_{t_{k}}( \cdot|\bm{x}_{k})\hat{q}_{k}\,||\,p_{t_{k}}(\cdot|\bm{x}_{k})p_{k})+\int_{ \mathcal{X}}\int_{\mathcal{Z}}D_{\mathrm{KL}}(\mathrm{Q}_{\cdot|\bm{z}_{k}} \,||\,P_{|\bm{z}_{k})}\hat{q}_{t_{k}}(d\bm{z}(t_{k})|\bm{x}_{k})\hat{q}_{k}(d \bm{x}_{k}),\]

and then on the prescribed half path \(\hat{\mathrm{Q}}^{<}_{|\bm{z}(t_{k})}\), obtaining

\[D_{\mathrm{KL}}(\mathrm{Q}_{\cdot|\bm{z}_{k}}\,||\,P_{\cdot|\bm{z}_{k})}=D_{ \mathrm{KL}}(\hat{\mathrm{Q}}^{<}_{|\bm{z}(t_{k})}\,||\,P^{<}_{\cdot|\bm{z}(t _{k})})+\int_{\Omega_{(t_{k},T]}}D_{\mathrm{KL}}\left(\mathrm{Q}^{[t_{k},T]}_{ \cdot|(\bm{z}(t))_{t\in[0,t_{k}]}}\,||\,P^{>}_{\cdot|\bm{z}(t_{k})}\right)d \hat{\mathrm{Q}}^{<}_{|\bm{z}(t_{k})}.\]

By Jensen's inequality, we get

\[D_{\mathrm{KL}}(\mathrm{Q}^{>}_{|\bm{z}(t_{k})}\,||\,P^{>}_{\cdot |\bm{z}(t_{k})}) =D_{\mathrm{KL}}\left(\int_{\Omega_{(t_{k},T]}}Q^{[t_{k},T]}_{ \cdot|(\bm{z}(t))_{t\in[0,t_{k}]}}d\hat{\mathrm{Q}}^{<}_{|\bm{z}(t_{k})}\,|| \,P^{>}_{\cdot|\bm{z}(t_{k})}\right)\] \[\leq\int_{\Omega_{(t_{k},T]}}D_{\mathrm{KL}}\left(\mathrm{Q}^{[t _{k},T]}_{\cdot|(\bm{z}(t))_{t\in[0,t_{k}]}}\,||\,P^{>}_{\cdot|\bm{z}(t_{k})} \right)d\hat{\mathrm{Q}}^{<}_{|\bm{z}(t_{k})},\]

and equality is achieved if and only if the process is Markov, i.e. \(\mathrm{Q}^{[t_{k},T]}_{\cdot|(\bm{z}(t))_{t\in[0,t_{k}]}}=\hat{\mathrm{Q}}^{>} _{\cdot|\bm{z}(t_{k})}\). This proves that a minimum satisfying the prescribed marginals is achieved by a Markov process, i.e. satisfying equation 22. 

Next, we derive the evidence lower bound for noiseless data, as presented in Proposition 2, and for noisy data. Alternative derivations for the latter can be found in Opper and Sanguinetti (2007); Wildner and Koeppl (2019).

Our derivation follows by analyzing the limit of discretized processes, following an approach analogous to the derivation of the KL divergence between two CTMCs in Opper and Sanguinetti (2007). Specifically, we consider probability mass functions corresponding to marginal and conditionals of a discretized CTMC \((\bm{z}(t))_{t\in[t_{1},t_{K}]}\) on a uniform grid \(t_{k}=\tau_{k}^{0}<\tau_{k}^{1}<\cdots<\tau_{k}^{T_{k}-1}<\tau_{k}^{T_{k}}=t_{k+1}\), where \(T_{k}=(t_{k+1}-t_{k})/\Delta t,\) for \(k=1,\ldots,K-1\). We then let \(\Delta t\to 0\), and simultaneously \(T_{k}\to\infty\). We denote the latent process at a discrete time \(\tau\) as \(\bm{z}_{\tau}\coloneqq\bm{z}(\tau)\).

#### c.5.1 Noiseless data - Proof of Proposition 2

When \(\bm{x}_{1:K}\) is a noiseless observation of a Markov process \((\bm{z}(t))_{t\in[t_{1},t_{K}]}\) at times \(t_{1:K}\), we can leverage the Markov property and obtain at any time \(\tau_{k}^{j}\), for \(j=1,\ldots,T_{k}-2\) and \(k=1,\ldots,K-1\)

\[\bar{p}_{\tau_{k}^{j}}(\bm{z}) \coloneqq p_{\tau_{k}^{j}}(\bm{z}\,|\,\bm{x}_{1:K})\] \[=p_{\tau_{k}^{j}}(\bm{z}\,|\,\bm{x}_{k},\bm{x}_{k+1})\] \[=p_{\tau_{k}^{j}\,|\,t_{k}}(\bm{z}\,|\,\bm{x}_{k})\frac{p_{t_{k+1 }\,|\,\tau_{k}^{j}}(\bm{x}_{k+1}\,|\,\bm{z})}{p_{t_{k+1}\,|\,t_{k}}(\bm{x}_{k+1 }\,|\,\bm{x}_{k})},\] \[\bar{p}_{\tau_{k}^{j+1}\,|\,\tau_{k}^{j}}(\tilde{\bm{z}}\,|\,\bm{z}) \coloneqq p_{\tau_{k}^{j+1}\,|\,\tau_{k}^{j}}(\tilde{\bm{z}}\,|\,\bm{z}, \bm{x}_{1:K})\] \[=p_{\tau_{k}^{j+1}\,|\,\tau_{k}^{j}}(\tilde{\bm{z}}\,|\,\bm{z}, \bm{x}_{k+1})\] \[=p_{\tau_{k}^{j+1}\,|\,\tau_{k}^{j}}(\tilde{\bm{z}}\,|\,\bm{z}) \frac{p_{t_{k+1}\,|\,\tau_{k}^{j+1}}(\bm{x}_{k+1}\,|\,\tilde{\bm{z}})}{p_{t_{k+ 1}\,|\,\tau_{k}^{j}}(\bm{x}_{k+1}\,|\,\bm{z})}.\]

Hence,

\[p(\bm{z}_{\tau_{k}^{1},\tau_{k}^{T_{k}-1}}\mid\bm{x}_{1:K}) =\bar{p}_{\tau_{k}^{1}}(\bm{z}_{\tau_{k}^{1}})\prod_{j=1}^{T_{k}-2 }\bar{p}_{\tau_{k}^{j+1}\,|\,\tau_{k}^{j}}(\bm{z}_{\tau_{k}^{j+1}}\,|\,\bm{z}_{ \tau_{k}^{j}})\] \[=p_{\tau_{k}^{1}\,|\,t_{k}}(\bm{z}_{\tau_{k}^{1}}\mid\bm{x}_{k}) \prod_{j=1}^{T_{k}-2}p_{\tau_{k}^{j+1}\,|\,\tau_{k}^{j}}(\bm{z}_{\tau_{k}^{j+1 }}\mid\bm{z}_{\tau_{k}^{j}})\frac{p_{t_{k+1}\,|\,\tau_{k}^{T_{k}-1}}(\bm{x}_{k +1}\,|\,\bm{z}_{\tau_{k}^{T_{k}-1}})}{p_{t_{k+1}\,|\,t_{k}}(\bm{x}_{k+1}\,|\, \bm{x}_{k})}.\]

It follows that

\[D_{\mathrm{KL}}\left(Q^{\theta}_{\cdot|\bm{x}_{1:K}}\,||\,P_{\cdot |\bm{x}_{1:K}}\right)\] \[=\sum_{k=1}^{K-1}\mathbb{E}_{q_{\tau_{k}^{1},\tau_{k}^{T_{k}-1}}^{ \theta}(\cdot\mid\bm{x}_{k},\bm{x}_{k+1})}\left[\log\frac{q_{\tau_{k}^{1},\tau _{k}^{T_{k}-1}}^{\theta}(\bm{z}_{\tau_{k}^{1},\tau_{k}^{T_{k}-1}}\,|\,\bm{x}_{k },\bm{x}_{k+1})}{p_{\tau_{k}^{1}}(\bm{z}_{\tau_{k}^{1}})\prod_{j=1}^{T_{k}-2} \bar{p}_{\tau_{k}^{j+1}\,|\,\tau_{k}^{j}}(\bm{z}_{\tau_{k}^{j+1}}\,|\,\bm{z}_{ \tau_{k}^{j}})}\right]\] \[=\sum_{k=1}^{K-1}\mathbb{E}_{q_{\tau_{k}^{1},\tau_{k}^{1}}^{ \theta}(\cdot\mid\bm{x}_{k},\bm{x}_{k+1})}\left[\log\frac{q_{\tau_{k}^{1},\tau _{k}^{T_{k}-1}}^{\theta}(\bm{z}_{\tau_{k}^{1},\tau_{k}^{T_{k}-1}}\,|\,\bm{x}_{k },\bm{x}_{k+1})}{p_{\tau_{k}^{1}\,|\,t_{k}}(\bm{z}_{\tau_{k}^{1}}\mid\bm{x}_{k })\prod_{j=1}^{T_{k}-2}p_{\tau_{k}^{j+1}\,|\,\tau_{k}^{j}}(\bm{z}_{\tau_{k}^{j+ 1}}\,|\,\bm{z}_{\tau_{k}^{j}})}\right]\] \[\qquad\quad-\mathbb{E}_{q_{\tau_{k}^{2},\tau_{k}^{-1}}^{ \theta}(\cdot\mid\bm{x}_{k},\bm{x}_{k+1})}\left[\log p_{t_{k+1}\,|\,\tau_{k}^{ T_{k}-1}}(\bm{x}_{k+1}\,|\,\bm{z}_{\tau_{k}^{T_{k}-1}})\right]+\log p_{t_{k+1}\,|\,t_{k}}( \bm{x}_{k+1}\,|\,\bm{x}_{k})\]

Denoting \(\log Z=\sum_{k=1}^{K-1}\log p_{t_{k+1}\,|\,t_{k}}(\bm{x}_{k+1}\,|\,\bm{x}_{k})\) and as \(\Delta t\to 0\) and \(T_{k}\to\infty\), we get

\[=\log Z+\sum_{k=1}^{K-1}D_{\mathrm{KL}}\left(Q^{\theta}_{\cdot|\bm{x}_{k},\bm{x }_{k+1}}\,||\,P_{\cdot|\bm{x}_{k}}\right)-\mathbb{E}_{q_{\tau_{k+1}^{-}}^{ \theta}(\cdot\mid\bm{x}_{k},\bm{x}_{k+1})}\left[\log p_{t_{k+1}\,|\,t_{k+1}^{-}}( \bm{x}_{k+1}\,|\,\bm{z}(t_{k+1}^{-}))\right],\]

where each KL term is restricted to the time interval \((t_{k},t_{k+1})\) and \(\bm{z}(t_{k+1}^{-})=\lim_{t\to t_{k}^{-}}\bm{z}(t)\).

#### c.5.2 Noisy data

When \(\bm{x}_{1:K}\) is a noisy observation of \((\bm{z}(t))_{t\in[t_{1},t_{K}]}\) at times \(t_{1:K}\), at any time \(\tau_{k}^{j}\) for \(j=1,\ldots,T_{k}-1\) and \(k=1,\ldots,K-1\),

\[\bar{p}_{\tau_{k}^{j}}(\bm{z}_{\tau_{k}^{j}}) \coloneqq p_{\tau_{k}^{j}}(\bm{z}_{\tau_{k}^{j}}\mid\bm{x}_{1:K})\] (23) \[=p_{\tau_{k}^{j}}(\bm{z}_{\tau_{k}^{j}})\frac{p_{\leq\tau_{k}^{j} \mid\tau_{k}^{j}}(\bm{z}_{\leq\tau_{k}^{j}}\mid\bm{z}_{\tau_{k}^{j}})p_{>\tau_{k }^{j}\mid\tau_{k}^{j}}(\bm{x}_{>\tau_{k}^{j}}\mid\bm{z}_{\tau_{k}^{j}})}{p_{< \tau_{k}^{j}\mid\bm{z}_{\tau_{k}^{j}}}(\bm{x}_{>\tau_{k}^{j}}\mid\bm{z}_{\tau_{k}^ {j}})},\] (24) \[\bar{p}_{\tau_{k}^{j+1}\mid\tau_{k}^{j}}(\bm{z}_{\tau_{k}^{j+1}}\mid \bm{z}_{\tau_{k}^{j}}) \coloneqq p_{\tau_{k}^{j+1}\mid\tau_{k}^{j}}(\bm{z}_{\tau_{k}^{j+1 }}\mid\bm{z}_{\tau_{k}^{j}},\,\bm{x}_{1:K})\] (25) \[=p_{\tau_{k}^{j+1}\mid\tau_{k}^{j}}(\bm{z}_{\tau_{k}^{j+1}}\mid \bm{z}_{\tau_{k}^{j}})\frac{p_{>\tau_{k}^{j}\mid\tau_{k}^{j+1}}(\bm{x}_{> \tau_{k}^{j}}\mid\bm{z}_{\tau_{k}^{j+1}})}{p_{>\tau_{k}^{j}\mid\tau_{k}^{j}}(\bm{x}_{> \tau_{k}^{j}}\mid\bm{z}_{\tauAt the last step before an observation time, we can further decompose

\[\begin{split} p_{>\tau_{k}^{T_{k}-1}|\tau_{k}^{T_{k}}}(\bm{x}_{>\tau_ {k}^{T_{k}-1}}\mid\bm{z}_{\tau_{k}^{T_{k}}})&=p_{\geq t_{k+1}|t _{k+1}}(\bm{x}_{\geq t_{k+1}}\mid\bm{z}_{t_{k+1}})\\ &=p_{t_{k+1}}(\bm{x}_{k+1}\mid\bm{z}_{t_{k+1}})p_{>t_{k+1}|t_{k+1 }}(\bm{x}_{>t_{k+1}}\mid\bm{z}_{t_{k+1}}).\end{split}\]

Hence, denoting \(t_{1}:t_{k}=\{t_{1},\tau_{1}^{1},\ldots,\tau_{K-1}^{T_{K-1}-1},t_{K}\}\), we get

\[\begin{split} p_{t_{1}:t_{k}}(\bm{z}_{t_{1}:t_{k}}\mid\bm{x}_{1:K} )&=\bar{p}_{t_{1}}(\bm{z}_{t_{1}})\prod_{k=1}^{K-1}\prod_{j=0}^{T _{k}-1}\bar{p}_{\tau_{k}^{j+1}\mid\tau_{j}^{j}}(\bm{z}_{\tau_{k}^{j+1}}\,|\, \bm{z}_{\tau_{k}^{j}})\\ &=\frac{p_{t_{1}}(\bm{z}_{t_{1}})p_{t_{1}}(\bm{x}_{1}\mid\bm{z}_{ t_{1}})}{p_{1:K}(\bm{x}_{1:K})}\prod_{k=1}^{K-1}p_{t_{k+1}}(\bm{x}_{k+1}\mid\bm{z}_{ t_{k+1}})\prod_{j=0}^{T_{k}-1}p_{\tau_{k}^{j+1}\mid\tau_{k}^{j}}(\bm{z}_{\tau_{k}^{j+ 1}}\,|\,\bm{z}_{\tau_{k}^{j}}).\end{split}\]

and

\[q_{t_{1}:t_{K}}^{\theta}(\bm{z}_{t_{1}:t_{K}}\mid\bm{x}_{1:K})=q_{t_{1}}^{ \theta}(\bm{z}_{t_{1}}\mid\bm{x}_{1:K})\prod_{k=1}^{K-1}q_{\tau_{k}^{j}:t_{k+1 }}^{\theta}(\bm{z}_{\tau_{k}^{1}:t_{k+1}}\mid\bm{z}_{t_{k}},\bm{x}_{>t_{k}}).\]

Denoting \(\log Z=\log p_{1:K}(\bm{x}_{1:K})\), the KL can be expressed as

\[\begin{split}& D_{\mathrm{KL}}\left(Q_{:|\bm{x}_{1:K}}^{\theta} \left|\,\middle|P_{:|\bm{x}_{1:K}}\right.\right)\\ &=\mathbb{E}_{q_{t_{1}:t_{K}}^{\theta}(\cdot\mid\bm{z}_{1:K})} \left[\log\frac{q_{t_{1}:t_{K}}^{\theta}(\bm{z}_{t_{1}:t_{K}}\mid\bm{x}_{1:K}) }{p_{t_{1}:t_{k}}(\bm{z}_{t_{1}:t_{k}}\mid\bm{x}_{1:K})}\right]\\ &=\log Z+\mathbb{E}_{q_{t_{1}:t_{K}}^{\theta}(\cdot\mid\bm{z}_{1: K})}\left[\log\frac{q_{t_{1}:t_{K}}^{\theta}(\bm{z}_{t_{1}:t_{K}}\mid\bm{x}_{1:K}) }{p_{t_{1}:t_{k}}(\bm{z}_{t_{1}:t_{k}})}\right]-\mathbb{E}_{q_{t_{1}:t_{K}}^{ \theta}(\cdot\mid\bm{x}_{1:K})}\left[\sum_{k=1}^{K}\log p_{t_{k}}(\bm{x}_{k} \mid\bm{z}_{t_{k}})\right].\end{split}\]

As \(\Delta t\to 0\) and \(T_{k}\to\infty\), we get

\[=\log Z+D_{\mathrm{KL}}(Q_{:|\bm{x}_{1:K}}^{\theta}\left|\,\middle|P\right)- \mathbb{E}_{Q_{:|\bm{x}_{1:K}}^{\theta}}\left[\sum_{k=1}^{K}\log p_{t_{k}}(\bm{ x}_{k}\mid\bm{z}_{t_{k}})\right]\]

### Unconditional loss

In this section, we aim at justifying the choice of the surrogate loss in Section 3.2. We do so by bounding its distance to the ideal loss, with respect to the Markov process \(Q^{\star}\in\mathcal{P}(\Omega_{[t_{1},t_{K}]})\) that is unavailable.

**Definition 4**.: _For a given time \(t\), we define:_

* _The total variation distance:_ \[\left\|q_{t}^{\star}-q_{t}^{\theta}\right\|_{\text{TV}}=\mathbb{E}_{\tau_{1:K}( \bm{x}_{1:K})}\bigg{[}\sum_{\bm{z}\in\mathcal{Z}}\left|q_{t}^{\star}(\bm{z} \mid\bm{x}_{1:K})-q_{t}^{\theta}(\bm{z}\mid\bm{x}_{1:K})\right|\bigg{]},\]
* _The expected Lambda difference:_ \[\varepsilon_{t}^{\Lambda}(\theta)\coloneqq\mathbb{E}_{q_{t}^{\theta}(\bm{z}, \bm{x}_{>t})}\sum_{\tilde{\bm{z}}\neq\bm{z}}\left|\Lambda_{t}^{\star}(\tilde{ \bm{z}}|\bm{z},\bm{x}_{>t})-\Lambda_{t}^{\theta}(\tilde{\bm{z}}|\bm{z},\bm{x}_ {>t})\right|.\]

**Theorem 5**.: _The following bound holds:_

\[\left|\mathcal{L}_{\text{KL}}(\phi)-\hat{\mathcal{L}}_{\text{KL}}^{\theta}(\phi )\right|\leq\int_{t_{1}}^{t_{K}}\left\|q_{t}^{\star}-q_{t}^{\theta}\right\|_{ \text{TV}}\cdot A_{t}(\theta,\phi)\,dt,\]

_where_

\[A_{t}(\theta,\phi)=\mathbb{E}_{q_{t}^{\theta}(\bm{z},\bm{x}_{1:K})}\left[ \varepsilon_{t}^{\Lambda}(\theta)\max_{\tilde{\bm{z}}\neq\bm{z}}\left|\log \Lambda_{t}^{\phi}(\tilde{\bm{z}}|\bm{z})\right|-\Lambda_{t}^{\phi}(\bm{z}|\bm{ z})\right].\]

Proof.:

**Lemma 6**.: \[D_{\mathrm{KL}}(Q^{\star}\,|\,Q^{\phi})\propto\mathbb{E}_{\pi_{1:K}}\left[D_{ \mathrm{KL}}(Q^{\star}_{:|\bm{x}_{1:K}}\,|\,Q^{\phi})\right].\] (27)

Proof.: Let \(Q^{\phi}\) have rates \(\Lambda^{\phi}_{t}(-|-)\), \(Q^{\star}_{:|\bm{x}_{1:K}}\) have rates \(\Lambda^{\star}_{t}(-|-)\), and \(Q^{\star}_{:|\bm{x}_{1:K}}\) have rates \(\Lambda^{\star}_{t}(-|-,\bm{x}_{>t})\), where we use the shorthand \(\bm{x}_{>t}\coloneqq\{\bm{x}_{k}:t_{k}>t,\,k\in 1,\ldots,K\}\). Then,

\[\mathbb{E}_{\pi_{1:K}}\left[D_{\mathrm{KL}}(Q^{\star}_{:|\bm{x}_ {1:K}}\,|\,Q^{\phi})\right]\] \[\propto\mathbb{E}_{\pi_{1:K}}\left[\int_{t_{1}}^{t_{K}}\mathbb{E }_{q^{\star}_{t}(\bm{z}|\bm{x}_{1:K})}\sum_{\tilde{\bm{z}}\neq\bm{z}}\bigg{\{} \Lambda^{\phi}_{t}(\tilde{\bm{z}}\mid\bm{z})-\Lambda^{\star}_{t}(\tilde{\bm{z} }\mid\bm{z},\bm{x}_{>t})\log\Lambda^{\phi}_{t}(\tilde{\bm{z}}\mid\bm{z}) \bigg{\}}dt\right]\] \[=\mathbb{E}_{\pi_{1:K}}\left[\int_{t_{1}}^{t_{K}}\mathbb{E}_{q^{ \star}_{t}(\bm{z}|\bm{x}_{1:K})}\sum_{\tilde{\bm{z}}\neq\bm{z}}\bigg{\{} \Lambda^{\phi}_{t}(\tilde{\bm{z}}\mid\bm{z})-\Lambda^{\star}_{t}(\tilde{\bm{z} }\mid\bm{z})\frac{q^{\star}_{>t|t}(\bm{x}_{>t}\mid\tilde{\bm{z}})}{q^{\star}_{ >t|t}(\bm{x}_{>t}\mid\bm{z})}\log\Lambda^{\phi}_{t}(\tilde{\bm{z}}\mid\bm{z}) \bigg{\}}dt\right]\] \[=\int_{t_{1}}^{t_{K}}\mathbb{E}_{\pi_{1:K}}\mathbb{E}_{q^{\star}_ {t}(\bm{z}|\bm{x}_{1:K})}\sum_{\tilde{\bm{z}}\neq\bm{z}}\bigg{\{}\Lambda^{\phi }_{t}(\tilde{\bm{z}}\mid\bm{z})-\Lambda^{\star}_{t}(\tilde{\bm{z}}\mid\bm{z}) \frac{q^{\star}_{>t|t}(\bm{x}_{>t}\mid\tilde{\bm{z}})}{q^{\star}_{>t|t}(\bm{x }_{>t}\mid\bm{z})}\log\Lambda^{\phi}_{t}(\tilde{\bm{z}}\mid\bm{z})\bigg{\}}dt.\]

Applying Fubini's theorem for interchanging integrals,

\[=\int_{t_{1}}^{t_{K}}\mathbb{E}_{q^{\star}_{t}(\bm{z})}\mathbb{E }_{q^{\star}_{1:K|t}(\bm{z}_{1:K}|\bm{z})}\sum_{\tilde{\bm{z}}\neq\bm{z}} \bigg{\{}\Lambda^{\phi}_{t}(\tilde{\bm{z}}\mid\bm{z})-\Lambda^{\star}_{t}( \tilde{\bm{z}}\mid\bm{z})\frac{q^{\star}_{>t|t}(\bm{x}_{>t}\mid\tilde{\bm{z}}) }{q^{\star}_{>t|t}(\bm{x}_{>t}\mid\bm{z})}\log\Lambda^{\phi}_{t}(\tilde{\bm{z} }\mid\bm{z})\bigg{\}}dt\] \[=\int_{t_{1}}^{t_{K}}\mathbb{E}_{q^{\star}_{t}(\bm{z})}\sum_{ \tilde{\bm{z}}\neq\bm{z}}\bigg{\{}\Lambda^{\phi}_{t}(\tilde{\bm{z}}\mid\bm{z}) -\mathbb{E}_{q^{\star}_{1:K|t}(\bm{x}_{1:K}|\bm{z})}\left[\frac{q^{\star}_{>t|t }(\bm{x}_{>t}\mid\tilde{\bm{z}})}{q^{\star}_{>t|t}(\bm{x}_{>t}\mid\bm{z})} \right]\Lambda^{\star}_{t}(\tilde{\bm{z}}\mid\bm{z})\log\Lambda^{\phi}_{t}( \tilde{\bm{z}}\mid\bm{z})\bigg{\}}dt\] \[=\int_{t_{1}}^{t_{K}}\mathbb{E}_{q^{\star}_{t}(\bm{z})}\sum_{ \tilde{\bm{z}}\neq\bm{z}}\bigg{\{}\Lambda^{\phi}_{t}(\tilde{\bm{z}}\mid\bm{z}) -\Lambda^{\star}_{t}(\tilde{\bm{z}}\mid\bm{z})\log\Lambda^{\phi}_{t}(\tilde{\bm {z}}\mid\bm{z})\bigg{\}}\,dt\] \[\propto D_{\mathrm{KL}}(Q^{\star}\,||\,Q^{\phi}).\]

However, we do not have access to \(\Lambda^{\star}(-|-,\bm{x}_{>t})\) and \(q^{\star}_{t}(-|\bm{x}_{1:K})\), but to their approximations \(\Lambda^{\theta}(-|-,\bm{x}_{>t})\) and \(q^{\theta}_{t}(-|\bm{x}_{1:K})\). Let \(q^{\star}_{t}(\bm{z},\bm{x}_{1:K})\coloneqq q^{\star}_{t}(\bm{z}|\bm{x}_{1:K} )\pi(\bm{x}_{1:K})\). For simplicity, we break down each KL term into parts, so to get

\[\mathbb{E}_{\pi_{1:K}}\left[D_{\mathrm{KL}}(Q^{\star}_{:|\bm{x}_ {1:K}}\,|\,Q^{\phi})\right]=\int_{t_{1}}^{t_{K}}\] \[\qquad\qquad\qquad\qquad\qquad\qquad-\underbrace{\mathbb{E}_{q^{ \star}_{t}(\bm{z},\bm{x}_{1:K})}\sum_{\tilde{\bm{z}}\neq\bm{z}}\Lambda^{\star}_{t} (\tilde{\bm{z}}\mid\bm{z},\bm{x}_{>t})\log\Lambda^{\phi}_{t}(\tilde{\bm{z}}\mid \bm{z})}_{-L^{(3)}_{t}(\bm{x}_{1:K})}dt,\] \[\mathbb{E}_{\pi_{1:K}}\left[D_{\mathrm{KL}}(Q^{\theta}_{:|\bm{x}_ {1:K}}\,|\,Q^{\phi})\right]=\int_{t_{1}}^{t_{K}}\] \[\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad- \underbrace{\mathbb{E}_{q^{\theta}_{t}(\bm{z},\bm{x}_{1:K})}\sum_{\tilde{\bm{z}} \neq\bm{z}}\Lambda^{\phi}_{t}(\tilde{\bm{z}}\mid\bm{z})}_{-L^{(3)}_{t}(\bm{x}_ {1:K})}dt.\]

Finally, we let

\[\mathbb{E}_{\pi_{1:K}}\left[D_{\mathrm{KL}}(Q^{\star}_{:|\bm{x}_{1:K}}\,|\,Q^{ \phi})-D_{\mathrm{KL}}(Q^{\theta}_{:|\bm{x}_{1:K}}\,|\,Q^{\phi})\right]=\int_{t _{1}}^{t_{K}}\sum_{i=1}^{3}\underbrace{L^{(i)}_{t}(\bm{x}_{1:K})-\hat{L}^{(i)}_{t }(\bm{x}_{1:K})}_{D^{(i)}(\bm{x}_{1:K})}dt.\]We quantify the error in terms of total variation distance and expected absolute error of the generator at each time \(t\in[t_{1},t_{K}]\),

\[\left\|q_{t}^{\star}-q_{t}^{\theta}\right\|_{TV} \coloneqq\mathbb{E}_{\pi_{1:K}(\bm{x}_{1:K})}\bigg{[}\sum_{\bm{z} \in\mathcal{Z}}\left|q_{t}^{\star}(\bm{z}\mid\bm{x}_{1:K})-q_{t}^{\theta}(\bm{ z}\mid\bm{x}_{1:K})\right|\bigg{]}\] \[=\mathbb{E}_{q_{t}^{\theta}(\bm{z},\bm{x}_{1:K})}\left|\frac{q_{ t}^{\star}(\bm{z},\bm{x}_{1:K})}{q_{t}^{\theta}(\bm{z},\bm{x}_{1:K})}-1 \right|,\] \[\varepsilon_{t}^{\Lambda}(\theta) \coloneqq\mathbb{E}_{q_{t}^{\theta}(\bm{z},\bm{x}_{>t})}\sum_{ \tilde{\bm{z}}\neq\bm{z}}\left|\Lambda_{t}^{\ast}(\tilde{\bm{z}}|\bm{z},\bm{x} _{>t})-\Lambda_{t}^{\theta}(\tilde{\bm{z}}|\bm{z},\bm{x}_{>t})\right|.\]

Then, we are interested in isolating the terms in \(\left|\mathcal{L}_{\text{KL}}(\phi)-\hat{\mathcal{L}}_{\text{KL}}^{\theta}( \phi)\right|\) that depend on \(\phi\),

\[\left|\,\mathbb{E}_{\pi_{1:K}}\left[D_{\text{KL}}(Q_{:|\bm{x}_{1:K}}^{\star} \mid Q^{\phi})-D_{\text{KL}}(Q_{:|\bm{x}_{1:K}}^{\theta}\mid Q^{\phi})\right] \right|\leq\int_{t_{1}}^{t_{K}}\left|D^{(1)}(\bm{x}_{1:K})\right|+\left|D^{(3) }(\bm{x}_{1:K})\right|dt.\]

By applying Jensen's inequality and the Cauchy-Schwarz inequality, we can further bound these quantities as

\[\left|D^{(1)}(\bm{x}_{1:K})\right| =\left|\mathbb{E}_{q_{t}^{\theta}(\bm{z},\bm{x}_{1:K})}\right| \bigg{[}\left(\frac{q_{t}^{\star}(\bm{z},\bm{x}_{1:K})}{q_{t}^{\theta}(\bm{z}, \bm{x}_{1:K})}-1\right)\sum_{\tilde{\bm{z}}\neq\bm{z}}\Lambda_{t}^{\phi}( \tilde{\bm{z}}\mid\bm{z})\bigg{]}\right|\] \[\leq\left\|q_{t}^{\star}-q_{t}^{\theta}\right\|_{TV}\mathbb{E}_{q _{t}^{\theta}(\bm{z},\bm{x}_{1:K})}\left|-\Lambda_{t}^{\phi}(\bm{z}\mid\bm{z}) \right|,\]

\[\left|D^{(3)}(\bm{x}_{1:K})\right|\] \[=\left|\mathbb{E}_{q_{t}^{\theta}(\bm{z},\bm{x}_{1:K})}\bigg{[} \left(1-\frac{q_{t}^{\star}(\bm{z},\bm{x}_{1:K})}{q_{t}^{\theta}(\bm{z},\bm{x}_ {1:K})}\right)\sum_{\tilde{\bm{z}}\neq\bm{z}}\left(\Lambda_{t}^{\ast}(\tilde{ \bm{z}}|\bm{z},\bm{x}_{>t})-\Lambda_{t}^{\theta}(\tilde{\bm{z}}|\bm{z},\bm{x}_{ >t})\right)\log\Lambda_{t}^{\phi}(\tilde{\bm{z}}\mid\bm{z})\bigg{]}\right|\] \[\leq\varepsilon_{t}^{\Lambda}(\theta)\left\|q_{t}^{\star}-q_{t}^{ \theta}\right\|_{TV}\mathbb{E}_{q_{t}^{\theta}(\bm{z},\bm{x}_{1:K})}\left[\max _{\tilde{\bm{z}}\neq\bm{z}}\left|\log\Lambda_{t}^{\phi}(\tilde{\bm{z}}\mid\bm{z })\right|\right].\]

Hence,

\[\left|\mathcal{L}_{\text{KL}}(\phi)-\hat{\mathcal{L}}_{\text{KL}} ^{\theta}(\phi)\right|\] \[\leq\int_{t_{1}}^{t_{K}}\left\|q_{t}^{\star}-q_{t}^{\theta} \right\|_{TV}\left(\varepsilon_{t}^{\Lambda}(\theta)\mathbb{E}_{q_{t}^{\theta }(\bm{z},\bm{x}_{1:K})}\left[\max_{\tilde{\bm{z}}\neq\bm{z}}\left|\log\Lambda _{t}^{\phi}(\tilde{\bm{z}}\mid\bm{z})\right|\right]-\mathbb{E}_{q_{t}^{\theta} (\bm{z},\bm{x}_{1:K})}\left[\Lambda_{t}^{\phi}(\bm{z}\mid\bm{z})\right]\right)dt\]

## Appendix D Implementation details

#### 0.d.1 Architecture

Self-Omitted AttentionGiven a configuration \(\bm{z}\in\mathcal{Z}\), observation and next observation times \(t,t_{\text{next}}\in\mathbb{R}\), a representation of future observations \(\bm{x}_{\text{next}}\), and context \(\bm{c}\), we parameterize conditional local generators of the form \((t,t_{\text{next}},\bm{z},\bm{x}_{\text{next}},\bm{c})\mapsto\bm{\Lambda}_{t,t _{\text{next}}}(\bm{z},\bm{x}_{\text{next}},\bm{c})\in\mathbb{R}^{|V|\times|S| \times|S|}\). We denote the output at a specific site \(i\in V\) as \(\lambda_{t,t_{\text{next}}}^{s\to\tilde{s},\theta}(i,\bm{z},\bm{x}_{\text{next }},\bm{c})\). For a given hidden dimension \(d\), we use multi-layer perceptrons to compute site-wise representations \(\bm{e}^{i}=f\big{(}x_{\text{next}}^{i},c^{i}\big{)}\in\mathbb{R}^{d}\) and \(\tilde{\bm{e}}^{i}=f\big{(}z^{i},x_{\text{next}}^{i},c^{i}\big{)}\in\mathbb{R} ^{d}\), that we collect in matrices \(\mathbf{E},\mathbf{\tilde{E}}\in\mathbb{R}^{|V|\times d}\). The unconditional setting reflects that of the conditional model, but without the \(t_{\text{next}}\) and \(\bm{x}_{\text{next}}\) terms. We group the columns of each matrix into \(H\) attention heads \(\mathbf{E}_{1},\ldots,\mathbf{E}_{H}\) and \(\mathbf{\tilde{E}}_{1},\ldots,\mathbf{\tilde{E}}_{H}\) (such that \(d\mod H=0\)), and denote the representations of site \(i\) in head \(h\) as \(\bm{e}_{h}^{i}\), \(\tilde{\bm{e}}_{h}^{i}\). Moreover, we let \(\tau=h(t,t_{\text{next}})\) be a time embedding.

We modify the attention mechanism so that the output at each site \(i\in V\) is invariant to the input state \(z^{i}\) at that site. This naturally follows from the fact that we are trying to parameterize transition rates for each site from any given (local) state to any other, while capturing neighborhood interactions. We do so by considering the usual query-key weight matrices \(\mathbf{W}_{\mathbf{Q}_{h}},\mathbf{W}_{\mathbf{K}_{h}}\in\mathbb{R}^{d\times d /H}\), the value matrix \(\mathbf{W}_{\mathbf{V}}\in\mathbb{R}^{d\times d}\), and an additional matrix \(\mathbf{W}_{\tilde{\mathbf{K}}_{h}}\in\mathbb{R}^{d\times d/H}\). We denote the site-specific queries and keys as \(\bm{q}_{h}^{i}=\bm{e}_{h}^{i}\mathbf{W}_{\mathbf{Q}_{h}}\), \(\bm{k}_{h}^{i}=\bm{e}_{h}^{i}\mathbf{W}_{\mathbf{K}_{h}}\) in \(\mathbb{R}^{d/H}\), and an additional term \(\tilde{\bm{k}}_{h}^{i}=\tilde{\bm{e}}_{h}^{i}\mathbf{W}_{\tilde{\mathbf{K}}_ {h}}\in\mathbb{R}^{d/H}\) that includes state information, for \(i\in V\) and \(h=1,\dots,H\). We then compute the matrix \(\mathbf{A}_{h}\in\mathbb{R}^{|V|\times|V|}\) by letting each element be

\[a_{h}^{ij}=\operatorname{softmax}\big{(}\big{\{}\hat{a}_{h}^{il}/\sqrt{d/H},\, l\in V\big{\}}\big{)},\quad\hat{a}_{h}^{ij}=\begin{cases}\langle\bm{q}_{h}^{i}, \tilde{\bm{k}}_{h}^{j}\rangle,&i\sim j,\\ \langle\bm{q}_{h}^{i},\bm{k}_{h}^{j}\rangle,&i=j,\\ 0,&\text{otherwise.}\end{cases}\]

When the neighborhood structure is that of a lattice (and denoting \(M=|\mathcal{N}_{i}|\) for any \(i\)), we use the method proposed in the Vision Transformer Cellular Automata (Tesfaldet et al., 2022) to localize attention, reducing computations from \(\mathcal{O}(|V|^{2})\) to \(\mathcal{O}(|V|M)\). For graphs with an arbitrary neighborhood structure, we perform element-wise masking of \(\mathbf{A}\) with the adjacency matrix.

Considering the values \(\mathbf{V}_{h}=\mathbf{E}_{h}\mathbf{W}_{\mathbf{V}_{h}}\in\mathbb{R}^{|V| \times d/H}\), the self-omitted attention output \(\mathtt{SOA}_{h}\in\mathbb{R}^{|V|\times d/H}\) is then computed and information across heads is combined by concatenating them, as

\[\mathbf{O}=\operatorname{concat}\big{[}\mathtt{SOA}_{1},\dots,\mathtt{SOA}_{H }\big{]}\in\mathbb{R}^{|V|\times d},\quad\mathtt{SOA}_{h}=\mathbf{A}_{h} \mathbf{V}_{h}\in\mathbb{R}^{|V|\times d/H}.\]

The off-diagonal elements of the rate matrix for each site are then computed by passing each \(\bm{o}^{i}\) through an MLP mapping to \(\mathbb{R}^{|S|\times(|S|-1)}\). Filling the diagonals with the row-wise sum and concatenating the matrices yields the local generator in \(\mathbb{R}^{|V|\times|S|\times|S|}\).

### Training

The simulation algorithms that can be used at training time for trajectory reconstruction are reported in Algorithm 1 and Algorithm 2. Notice that it is also possible to learn the unconditional generator at the same time as the unconditional one, by freezing the gradients of \(\theta\) before updating the \(\hat{\mathcal{L}}_{\text{KL}}^{\theta}\) loss. While all datapoints in a batch are processed in parallel, we might need to evolve the solver through different time points for each batch. This is feasible by applying the tricks for parallel solving of neural ODEs with varying time-intervals presented in Chen et al. (2021).

While training the conditional generator, we often observed the model converge to a local minima where the next observed state is reached in a very short time right after the previous observation, and rates are then zeroed until the next observation time. This biases the distribution of samples seen at training time by the unconditional model, that might then experience "mode collapse" and predict all of the transition rates to be zero. This reflects the insight given by Theorem 5. We found that choosing priors that bias the conditional model towards performing fewer transitions helps addressing this issue, as they tend to regularize the path.

### Computational considerations

Our method is not simulation-free, in the sense that learning is made possible by backpropagating through a solver. In doing so, a practitioner can incur in two fundamental problems, inaccurate gradients and memory-intensive training steps. The choice of a backpropagation technique can trade off one disadvantage for the other. In our experiments we use continuous adjoint methods, that provide memory-efficient numerical solutions (constant w.r.t. the time discretization grid) at the cost of incurring numerical errors that accumulate into potentially inaccurate gradient estimates. An overview of other possible approaches is presented in (Kidger, 2021).

```
0: Observations \(\bm{x}_{1},\dots,\bm{x}_{K}\) at times \(t_{1},\dots,t_{K}\), step size \(\Delta t\), future encoder \(h_{t}\), initial encoder \(q_{1}\), conditional local generator \(\bm{\Lambda}_{t}\), prior \(p_{0},P\). Optional: context \(\bm{c}_{1},\dots,\bm{c}_{K}\).
0: Latent states \(\bm{z}(t_{1}),\dots,\bm{z}(t_{K})\), KL of the path
1: Sample \(\bm{z}(t_{1})\sim q_{1}(\cdot|\bm{x}_{1},h_{t_{1}}(\bm{x}_{>t_{1}}),\bm{c})\)
2:\(t_{\text{last}}\gets t_{1}\)
3: KL \(\gets D_{\text{KL}}(q_{1}\,||\,p_{0})\)
4:for\(t\in(t_{1},t_{K}]\)do
5: Sample \(\bm{z}\) from \(q_{t+\Delta t|t}\), approximating equation 1 using \(\bm{\Lambda}_{t}(\bm{z}\mid h_{t}(\bm{x}_{>t}),\bm{c}_{t_{\text{last}}})\)
6: Compute contribution \(d\text{KL}_{t}\) to equation 21 at time \(t\), using \(\bm{\Lambda}_{t}(\bm{z}\mid h_{t}(\bm{x}_{>t}),\bm{c}_{t_{\text{last}}})\)
7: KL \(\leftarrow\) KL + \(d\text{KL}_{t}\Delta t\)
8:if\(t=t_{k}\) for \(k=1,\dots,K\)then
9:\(\bm{z}(t_{k})\leftarrow\bm{z}\)
10:\(t_{\text{last}}\gets t\)
11:endif
12:endfor ```

**Algorithm 1** Forward simulation, conditional

```
0: Observations \(\bm{x}_{1},\dots,\bm{x}_{K}\) at times \(t_{1},\dots,t_{K}\), step size \(\Delta t\), future encoder \(h_{t}\), initial encoder \(q_{1}\), conditional local generator \(\bm{\Lambda}_{t}\), prior \(p_{0},P\). Optional: context \(\bm{c}_{1},\dots,\bm{c}_{K}\).
0: Latent states \(\bm{z}(t_{1}),\dots,\bm{z}(t_{K})\), KL of the path
1: Sample \(\bm{z}(t_{1})\sim q_{1}(\cdot|\bm{x}_{1},h_{t_{1}}(\bm{x}_{>t_{1}}),\bm{c})\)
2:\(t_{\text{last}}\gets t_{1}\)
3: KL \(\gets D_{\text{KL}}(q_{1}\,||\,p_{0})\)
4:for\(t\in(t_{1},t_{K}]\)do
5: Sample \(\bm{z}\sim q_{t}=\prod_{i}q_{i}^{i}\) using the Gumbell-Softmax trick
6: Compute \(d_{t}^{i}\) for all \(i\in V\), using \(\bm{\Lambda}_{t}(\bm{z}\mid h_{t}(\bm{x}_{>t}),\bm{c}_{t_{\text{last}}})\) and \(q_{t}^{i}\)
7: Compute contribution \(d\text{KL}_{t}\) to equation 21 at time \(t\), using \(\bm{\Lambda}_{t}(\bm{z}\mid h_{t}(\bm{x}_{>t}),\bm{c}_{t_{\text{last}}})\)
8: KL \(\leftarrow\) KL + \(d\text{KL}_{t}\Delta t\)
9:if\(t=t_{k}\) for \(k=1,\dots,K\)then
10:\(\bm{z}(t_{k})\leftarrow\bm{z}\)
11:\(t_{\text{last}}\gets t\)
12:endif
13:endfor ```

**Algorithm 2** Neural master equation

## Appendix E Experiments

### Datasets

EpidemicsThe dataset is comprised of a collection of 250 random graphs with 128 nodes each and a given expected degree of 3, where edges are generated at random. Two covariates \(\bm{c}_{1}^{i}\), \(\bm{c}_{2}^{i}\) are generated for each node \(i\in V\) by sampling from a standard normal distribution. An epidemic is then spread according to a Susceptible-Infected-Recovered (SIR) model [11, 12, 13]. Initially, all nodes are set to be susceptible (\(S\)) with the exception of \(p_{0}\) nodes set to be infected (\(I\)) at random. Each graph in the dataset is evolved in the continuous-time interval \([0,19]\), where a time-homogeneous functional form for the local transition

Figure 2: First 5 observations in time of a sequence from the wildfires dataset, with the corresponding covariates.

[MISSING_PAGE_FAIL:22]

Figure 5: Evolution of an epidemic on an held-out graph. Endpoint-conditioned generation (left), unconditional generation (center), trajectory observed only at the endpoints (right).

Figure 6: Initial conditions (top) and generated trajectories from the conditional (left) and unconditional (center) models, and true sequence observed only at the endpoints(right). Results shown for an held-out example.

### Model

Since there is no observation noise, all we need to parameterize in our experiments are the conditional and unconditional generators. Both can be thought of as mappings \(\mathcal{X}\to\mathbb{R}_{\geq 0}^{|V|\times|S|\times|S|}\), i.e. the output shall be a local transition rate matrix at each site \(i\in V\). For the wildfires experiment we simply consider a \(3\times 3\) Moore neighborhood, whereas for the epidemics we mask the attention matrix with the adjacency matrix of each observation. We constrain the output to be positive by applying a softmax function. We specify the prior path measure by a prior rate matrix, where we set to zero physically impossible transitions (e.g. \(U\to E\) for wildfires, or \(S\to R\) for epidemics) and the remaining off-diagonal elements to a constant value \(c\). More complex functional forms are possible, and shall be chosen for example by simulating from the prior predictive distribution (Gelman et al., 2020).

### Results

We provide a qualitative overview of the results we have obtained so far. These shall be considered preliminary, and a quantitative comparison with other baselines (e.g. the mean-field approximation from Seifner and Sanchez (2023)) will be carried out in future work. For the epidemics dataset, we display generated trajectories on an held-out graph in Figure 5, as well as the aggregated SIR curves for the same example in Figure 4. Notice how the conditional model tends to converge quickly to the end solution, while the unconditional model mirrors the true unobserved trajectory more closely. For the wildfires experiments, we display results on held-out examples in Figure 6 and Figure 7. Despite the lack of information at the initial time, the unconditional model can still predict an evolution very close to the ground truth final configuration.

Figure 7: Same as Figure 6 but at a different stage of the simulated wildfire propagation, results shown for an held-out example.