[MISSING_PAGE_FAIL:1]

to unveil the subsequent assortment in the cascade. This cycle continues until either an assortment receives a click from the user or the agent depletes the pre-selected assortments.

The cascading assortment bandit problem is the strict generalization of both the cascading bandits model and the assortment bandits model. It is also a generalization of the simple multi-armed bandit problem. That is, if \(K=1\) and \(M=1\), the problem is the simple multi-armed bandit. If \(K>1\) and \(M=1\), the problem corresponds to the cascading bandit. If \(K=1\) and \(M>1\), we recover the assortment bandit problem. The illustrations on comparisons between the cascading assortment bandit and the other combinatorial bandits are presented in Figure [1]

In order to accommodate the generalization of the interactive model across items and assortments, we also incorporate the feature information of items and parametrization of a click model in the cascading assortment bandit model. Hence, we name the model as **cascading contextual assortment bandit** (see Section 2.2 for the formal definition of the problem setting).1 Under this newly proposed combinatorial bandit model, we posit the following question:

Footnote 1: Note that a non-contextual version of the cascading assortment bandit is a special case of the cascading contextual assortment bandit with a one-hot encoded feature vector for each item. Hence, when we aim to provide efficient algorithms for cascading contextual assortment bandit, we also address the non-contextual cascading assortment bandit which has not been studied previously.

_Can we design a provably efficient algorithm for cascading contextual assortment bandits?_

To address the question at hand, we first have to overcome the technical challenges inherent in each special case of our problem setting: the cascading contextual bandit and the contextual assortment bandit. Firstly, in the cascading contextual bandit [13, 25], a longstanding issue has been the suboptimal dependence on the cascade length, \(K\). Intuitively, one would expect that as \(K\) increases in the cascading model, the regret should either diminish or at least remain constant; performance deterioration should not occur. However, all existing regret bounds for cascading contextual bandits scale proportionally to \(K\)[13, 29, 17, 28, 25]. This finding is not just counter-intuitive, but also suboptimal (for further discussions, refer to Section 2.4). As a result, (i) **eradicating the suboptimal dependence on cascade length**\(K\) has been recognized as an open problem, even within the cascading contextual bandit setting [1]

Further, in the context of assortment bandits, there is a widely recognized suboptimal dependence on the problem-specific constant \(\kappa\), as demonstrated in the existing assortment bandit literature [22, 23, 24, 25]. This problem-specific constant \(\kappa\) (in Assumption 4.2) represents the curvature of the multinomial logit (MNL) function. Recent studies [24, 25] have demonstrated an improved dependence on \(\kappa\), albeit only multiplied by logarithmic factors. However, this improvement comes at the expense of an increased dependence on the assortment size \(M\), a conclusion that is both counter-intuitive and suboptimal. Thus, (ii) **decreasing the \(\kappa\) dependence without escalating the dependence on \(M\)** still poses an unresolved issue. While addressing either of the two challenges (i) and (ii) can be daunting individually, tackling both issues simultaneously poses an even greater challenge in both our algorithm design and regret analysis.

Figure 1: Comparisons between the cascading assortment bandit and the other combinatorial bandits. The cascading assortment bandit subsumes the multi-armed bandit (\(K=1,M=1\)), the cascading bandit (\(K>1,M=1\)), and the assortment bandit (\(K=1,M>1\)).

To this end, we design novel upper confidence bound (UCB) algorithms for contextual cascading assortment bandits, tackling both technical challenges. We show that our proposed algorithms achieve provable guarantees on regret performances overcoming the longstanding technical challenges. Our regret bounds show sharper results than those of the existing contextual cascading bandits or assortment bandits. We corroborate our theoretical claims through numerical experiments, thus ensuring that both our newly proposed bandit framework and the proposed algorithms establish provable efficiency and practical applicability.

Our main contributions are summarized as follows.

* We formulate a general combinatorial bandit model, named _cascading contextual assortment bandit_ that encompasses the existing cascading bandits and assortment bandits. This novel problem setting is observed in many practical applications.
* We first propose a UCB bandit algorithm UCB-CCA for the cascading contextual assortment bandit and establish the \(T\)-step regret upper-bound of \(\tilde{\mathcal{O}}(\frac{1}{\kappa}d\sqrt{T})\) (in Theorem 4.3). This regret bound is tighter than the existing bounds for cascading contextual bandits, where we not only remove the longstanding, unnecessary dependence on \(K\) but also establish the result without dependence on \(M\).
* While UCB-CCA is an efficient algorithm achieving both the statistical efficiency and practical performances (shown in Section 7), its regret bound includes dependence on the inverse of a problem-dependent constant \(\kappa\), which can be potentially large in the worst case. To improve the dependence on \(\kappa\), we propose our second algorithm UCB-CCA+, which exploits a new Bernstein-type concentration result, taking into account the effects of the local curvature of the MNL model. We prove that UCB-CCA+ achieves \(\tilde{\mathcal{O}}(d\sqrt{T})\) without the dependence on \(\kappa\) in the leading term (only scaling with logarithmic factors), hence significantly improving the regret of UCB-CCA without increasing the other dependencies. Hence, we successfully solve the two technical challenges (i) and (ii) mentioned above.
* As an independent contribution, we prove that a greedy algorithm for the cascading assortment optimization problem gives a 0.5 approximation of the optimal solution (discussed in Section 8). To our best knowledge, this is the first rigorous result showing the approximation guarantee even for the contextual cascading bandit problem, instead of simply assuming access to an approximation optimization oracle.
* We evaluate our proposed methods in numerical experiments and show that the practical performances support our theoretical claims. Hence, our proposed algorithms along with our newly proposed bandit model establish provable efficiency and practical applicability.

\begin{table}
\begin{tabular}{l c c c c c} \hline \hline Algorithm & Context & Cascade & Assortment & Click Model & Regret Bound \\ \hline CombCascade [1] & \(\times\) & \(\bigcirc\) & \(\times\) & \(\times\) & \(\tilde{\mathcal{O}}(\sqrt{KNT})\) \\ C\({}^{3}\)-UCB [1] & \(\bigcirc\) & \(\bigcirc\) & \(\times\) & Linear & \(\tilde{\mathcal{O}}(d\sqrt{KT})\) \\ EE-MNL [5] & \(\times\) & \(\times\) & \(\bigcirc\) & MNL & \(\tilde{\mathcal{O}}(\sqrt{NT})\) \\ TS-MNL [2] & \(\bigcirc\) & \(\times\) & \(\bigcirc\) & MNL & \(\tilde{\mathcal{O}}(\frac{1}{\kappa}d^{3/2}\sqrt{T})\) \\ UCB-MNL [2] & \(\bigcirc\) & \(\times\) & \(\bigcirc\) & MNL & \(\tilde{\mathcal{O}}(\frac{1}{\kappa}d\sqrt{T})\) \\ LinTS-Cascade [2] & \(\bigcirc\) & \(\bigcirc\) & \(\times\) & Linear & \(\tilde{\mathcal{O}}(d^{3/2}K\sqrt{T})\) \\ CascadeWOFUL [2] & \(\bigcirc\) & \(\bigcirc\) & \(\times\) & Linear & \(\tilde{\mathcal{O}}(\sqrt{d^{2}T+dTK})\) \\ VAC\({}^{2}\)-UCB [2] & \(\bigcirc\) & \(\bigcirc\) & \(\times\) & Linear & \(\tilde{\mathcal{O}}(d\sqrt{T})\) \\ \hline UCB-CCA (Algorithm [1] & \(\bigcirc\) & \(\bigcirc\) & \(\bigcirc\) & MNL & \(\tilde{\mathcal{O}}(\frac{1}{\kappa}d\sqrt{T})\) \\ UCB-CCA+ (Algorithm [2] & \(\bigcirc\) & \(\bigcirc\) & MNL & \(\tilde{\mathcal{O}}(d\sqrt{T})\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Comparisons of algorithms for contextual cascade and assortment bandits as well as for cascading contextual assortment bandits. \(N\) is the number of ground items, \(K\) is a length of cascade, \(d\) is a dimension of feature vectors and \(T\) is total rounds. \(\kappa\) is a problem-dependent parameter for the MNL model. See Appendix 0.A for more discussions.

Preliminaries

### Notation

Define \([n]\) as a set of positive integers from \(1\) to \(n\). Let \(|\cdot|\) be the length of a sequence or the cardinality of a set. For a vector \(x\in\mathbb{R}^{d}\), we denote the \(\ell_{2}\)-norm of \(x\) as \(||x||_{2}\) and the \(V\)-weighted norm of \(x\) for a positive-definite matrix \(V\) as \(||x||_{V}=\sqrt{x^{\top}Vx}\). The determinant and trace of a matrix \(V\) are \(\det(V)\) and \(\text{trace}(V)\), respectively. \(\lambda_{\min}(V)\) denotes the minimum eigenvalue of a matrix \(V\).

### Cascading Contextual Assortment Bandit Problem

Consider \([N]\), a set of \(N\) items. Let \(\mathcal{A}\) be a set of candidate assortments of items with size \(M\), i.e., \(\mathcal{A}:=\{A\subseteq[N]:|A|=M\}\). A cascade \(S\) is an ordered sequence of \(K\) assortments chosen from \(\mathcal{A}\) where all the items in these \(K\) assortments are distinct. Then, the set of all feasible cascades \(\mathcal{S}\) can be defined as follows.

\[\mathcal{S}:=\big{\{}S\!=\!\big{(}A_{1},...,A_{K}\big{)}\mid A_{k}\in \mathcal{A}\text{ for all }k\in[K],\cap_{k=1}^{K}A_{k}=\emptyset\big{\}}\]

At round \(t\), feature vectors \(\{x_{ti}\in\mathbb{R}^{d},i\in[N]\}\) for every item are revealed to the decision-making agent. Each feature vector \(x_{ti}\) may contain the contextual information of the user at round \(t\) and the item \(i\). After observing this contextual information, at round \(t\), the agent recommends a cascade \(S_{t}=(A_{tk})_{k\in[K]}\) to the user, where \(A_{tk}\in\mathcal{A}\) represents the \(k\)-th assortment of the cascade at round \(t\). The user scans the assortments in \(S_{t}\) one by one. If the items in \(A_{tk}\) do not attract the user, the user moves on to the next assortment \(A_{t,k+1}\). The user stops at the \(O_{t}\)-th assortment when the user is attracted by an item in the \(O_{t}\)-th assortment and clicks on the item.

After the user clicks on the item, the agent observes a sequence of user choices \(y_{t}=(y_{tk})_{k\in[O_{t}]}\) where a binary vector \(y_{tk}=(y_{tk0},y_{tk1},...,y_{tkM})\) represents user choices on assortment \(A_{tk}\). Let \(y_{tkm}=1\) if the \(m\)-th item \(i_{m}\) in \(A_{tk}\) is clicked by the user, and \(y_{tkm}=0\) for items that are not clicked on. For each assortment, there is an _outside option_. That is, there is a probability that the user may not click any of the items in \(A_{tk}\). If the user does not choose any items, \(y_{tk0}=1\) and \(y_{tkm}=0\) for all \(m\in[M]\). The user choice for each assortment is given by the multinomial logit (MNL) choice model [2]. For this MNL model, there is an _unknown_ time-invariant parameter \(\theta^{*}\in\mathbb{R}^{d}\). We define the true weight of item \(i\) in round \(t\) as \(w_{ti}^{*}\coloneqq x_{ti}^{\top}\theta^{*}\). Also, we let the vector representation of the weights be defined as \(w_{t}^{*}\coloneqq(w_{ti}^{*})_{i\in[N]}\) for convenience.

Under this model, the user's click probability of the \(m\)-th item in \(A_{tk}\) and the probability of the outside option in \(A_{tk}\) is given respectively by

\[p_{t}(i_{m}|A_{tk},w_{t}^{*})=\frac{\exp(w_{ti_{m}}^{*})}{1+\sum_{j\in A_{tk}} \exp(w_{tj}^{*})}\quad\text{and}\quad p_{t}(i_{0}|A_{tk},w_{t}^{*})=\frac{1} {1+\sum_{j\in A_{tk}}\exp(w_{tj}^{*})}\]

where item \(i_{0}\) represents the outside option. The user choice \(y_{tk}\) is sampled from the multinomial distribution, \(y_{tk}\sim\text{MNL}\big{\{}1,\big{(}p_{t}(i_{m}|A_{tk},w_{t}^{*})\big{)}_{m=0 }^{M}\big{\}}\), where the argument \(1\) indicates that \(y_{tk}\) is a single-trial sample. Hence, \(\sum_{m=1}^{M}y_{tkm}\) is always 1. Also, we denote measurement noise as \(\epsilon_{tkm}\coloneqq y_{tkm}-p_{t}(i_{m}|A_{tk},w_{t}^{*})\). Since \(\epsilon_{tkm}\) is bounded in \([0,1]\), \(\epsilon_{tkm}\) is \(\sigma^{2}\)-sub-Gaussian with \(\sigma^{2}=1/4\). It is important to note that \(\epsilon_{tkm}\) across items in the same assortment is not independent due to the substitution effect in the MNL model.

The expected reward function of a combinatorial action \(S_{t}\) based on \(w_{t}^{*}\) is given by

\[f(S_{t},w_{t}^{*})=\sum_{k=1}^{K}\left\{\prod_{k=1}^{k-1}p_{t}(i_{0}|A_{tk},w_ {t}^{*})\right\}\sum_{i\in A_{tk}}p_{t}(i|A_{tk},w_{t}^{*})=1-\prod_{k=1}^{|S_ {t}|}p_{t}(i_{0}|A_{tk},w_{t}^{*}).\]

The formulation above is also known as the cascade model with disjunctive objective, where the user stops at the _first attractive_ item [13][14][18].

### \(\alpha\)-Approximation Oracle and \(\alpha\)-Regret

The exact combinatorial optimization to compute an optimal cascade of assortments can be computationally expensive. Therefore, we allow for approximate optimization. We assume that the 

[MISSING_PAGE_FAIL:5]

```
0: confidence radius \(\beta_{t}\) and ridge penalty parameter \(\lambda\geq 1\)
1:for\(t=1,\dots,T\)do
2: Observe \(x_{ti}\) for all \(i\in[N]\)
3: Compute \(u_{ti}=x_{ti}^{\top}\hat{\theta}_{t-1}+\beta_{t-1}||x_{ti}||_{V_{t-1}^{-1}}\) for all \(i\in[N]\)
4: Compute a candidate cascade \(S_{t}^{\prime}\leftarrow(A_{tk}^{\prime})_{k\in[K]}=\mathbb{O}^{\alpha}\left(u_ {t}\right)\)
5: Find optimistic exposure assortment index \(k^{*}\) in \((k^{*},i^{*})=\underset{k\in[K],i\in A_{tk}}{\operatorname{argmax}}\left| \left|x_{ti}\right|\right|_{V_{t-1}^{-1}}\)
6: Optimistic exposure swap \(S_{t}\leftarrow\left(A_{tk}\right)_{k\in[K]}\) where \(A_{tk}:=\begin{cases}A_{tk}^{\prime}&\text{if}\quad k=1\\ A_{t1}^{\prime}&\text{if}\quad k=k^{*}\\ A_{tk}^{\prime}&\text{otherwise}\end{cases}\)
7: Offer \(S_{t}\), and observe user feedback \(O_{t}\) and \(y_{t}=(y_{tk})_{k\in[O_{t}]}\)
8: Update \(V_{t}\gets V_{t-1}+\sum_{k=1}^{O_{t}}\sum_{i\in A_{tk}}x_{ti}x_{ti}^{\top}\)
9: Compute the regularized MLE \(\hat{\theta}_{t}\) by solving \(\nabla_{\theta}\left[\ell_{t}(\theta)+\frac{\lambda}{2}||\theta||_{2}^{2} \right]=\mathbf{0}\)
10:endfor
```

**Algorithm 1**UCB-CCA

## 3 Algorithm: Ucb-Cca

### Upper Confidence Bounds and Confidence Set

UCB-CCA utilizes the upper confidence bounds (UCB) technique [11] to compute an optimistic action based on optimistic estimates of each item's weight, \(u_{ti}=x_{ti}^{\top}\hat{\theta}_{t-1}+\beta_{t-1}(\delta)||x_{ti}||_{V_{t-1} ^{-1}}\) for all \(i\in[N]\). The confidence radius \(\beta_{t}(\delta)\) is specified to maintain a high-probability confidence set \(C_{t}(\delta)\) for the unknown parameter \(\theta^{*}\), although the algorithm does not explicitly compute \(C_{t}(\delta)\).

\[C_{t}(\delta):=\left\{\theta\in\mathbb{R}^{d}:||\hat{\theta}_{t}-\theta||_{V_ {t}}\leq\beta_{t}(\delta)\right\}.\]

Setting a proper confidence radius \(\beta_{t}(\delta)\) can guarantee that \(\theta^{*}\) lies within the confidence set with probability \(1-\delta\). On the event that \(\theta^{*}\in C_{t}(\delta)\), the UCB weight \(u_{ti}\) serves as an upper bound of a true weight \(w_{ti}^{*}:=x_{ti}^{\top}\theta^{*}\) for every item \(i\in[N]\). We denote the UCB weight vector as \(u_{t}=\left(u_{ti}\right)_{i\in[N]}\) for convenience.

### Optimistic Exposure Swapping

A distinctive element of UCB-CCA is what we call _optimistic exposure swapping_, a procedure crucial for eliminating dependence on the worst-case scanning probability, as elaborated in Section 2.4.2. This technique strategically positions the assortment containing the item with the highest uncertainty among the top \(MK\) items in the first slot of the cascade of assortments.

In each round \(t\), the \(\alpha\)-approximate oracle \(\mathbb{O}^{\alpha}(u_{t})\) outputs a _candidate_ cascade \(S_{t}^{\prime}\), determined by the UCB weights \(u_{t}\). It is important to note that \(S_{t}^{\prime}\) is not immediately presented to the user. Instead, after \(S_{t}^{\prime}\) is derived using the optimization oracle \(\mathbb{O}^{\alpha}(u_{t})\), the algorithm identifies the index \(k^{*}\) of an assortment that includes the item with the largest \(\left|\left|x_{ti}\right|\right|_{V_{t-1}^{-1}}^{\prime}\) in \(S_{t}^{\prime}\).

Subsequently, the algorithm swaps the positions: the assortment \(A_{tk^{*}}^{\prime}\) is moved to the top of \(S_{t}\), becoming \(A_{t1}\), and the initially top assortment \(A_{t1}^{\prime}\) in \(S_{t}^{\prime}\) is relocated to the \(k^{*}\)-th position of \(S_{t}\), now \(A_{tk^{*}}\). The positions of the other assortments remain the same, that is, \(A_{tk}=A_{tk}^{\prime}\) for all \(k\in[K]\setminus\{1,k^{*}\}\bigrb\). This procedure is viable as the expected reward is unaffected by the display order of assortments in the cascade, as shown in Lemma 4.5

### Regularized Maximum Likelihood Estimation

UCB-CCA computes a regularized maximum likelihood estimate of the unknown parameter \(\theta^{*}\). The negative log-likelihood is given by \(\ell_{t}(\theta)=-\sum_{\tau=1}^{t-1}\sum_{k=1}^{O_{\tau}}\sum_{m=0}^{M}y_{\tau km }\log p_{\tau}(i_{m}|A_{\tau k},w_{\tau})\), where 

[MISSING_PAGE_FAIL:7]

Eliminating the dependence on \(p^{*}\) is another key element of our analysis. To this end, we first show that the order of assortments in the cascade model with the disjunctive objective does not affect the expected reward. We formalize this property in the following lemma.

**Lemma 4.5**.: _Let \(p_{k}\) be the probability that the user clicks on any item in \(A_{k}\). Given a collection of assortments \(\{A_{1},\cdots,A_{K}\}\) with probabilities \(\{p_{1},\cdots,p_{K}\}\), their order of display does not matter. Further, for every permutation \(\rho:[K]\rightarrow[K]\), we have_

\[\sum_{k\in[K]}p_{k}\prod_{\hat{k}<k}(1-p_{\hat{k}})=1-\prod_{k\in[K]}(1-p_{k}) =\sum_{k\in[K]}p_{\rho^{-1}(k)}\prod_{\hat{k}<k}\left(1-p_{\rho^{-1}(\hat{k})} \right).\]

Consolidating these key results, we proceed to bound the cumulative regret. We begin by leveraging the monotonicity of the expected reward function and the definition of the \(\alpha\)-approximate optimization oracle to bound the cumulative regret.

\[\mathcal{R}^{\alpha}(T)\leq\mathbb{E}\left[\sum_{t=1}^{T}f(S_{t}, u_{t})-f(S_{t},w_{t}^{*})\right]\leq C_{K}\mathbb{E}\left[\sum_{t=1}^{T}\max_{A _{tk}\in S_{t}}\max_{i\in A_{tk}}(u_{ti}-w_{ti}^{*})\right]\] \[\leq 2C_{K}\mathbb{E}\left[\beta_{T}\sum_{t=1}^{T}\max_{A_{tk} \in S_{t}}\max_{i\in A_{tk}}||x_{ti}||_{V_{t-1}^{-1}}\right]=2C_{K}\mathbb{E} \left[\beta_{T}\sum_{t=1}^{T}\max_{k\in[O_{t}]}\max_{i\in A_{tk}}||x_{ti}||_{V _{t-1}^{-1}}\right]. \tag{4}\]

The second inequality is from Lemma4.4 letting \(C_{K}:=(K/(K+1))^{K+1}\). The third inequality is given by the concentration of the UCB weights (see LemmaB.3). Note that the assortment including the item with the largest value of \(||x_{ti}||_{V_{t}^{-1}}\) is always examined by the user since it is included in the first assortment of \(S_{t}\) by the optimistic exposure swapping technique as described in Section3.2. Note that a change in the order of assortments incurred by the optimistic exposure swapping does not affect the expected reward which is shown in Lemma4.5. Hence, for every round \(t\in[T]\), we obtain

\[\max_{A_{tk}\in S_{t}}\max_{i\in A_{tk}}||x_{ti}||_{V_{t-1}^{-1}}=\max_{k\in[O _{t}]}\max_{i\in A_{tk}}||x_{ti}||_{V_{t-1}^{-1}}. \tag{5}\]

Therefore, the last equality in Eq.4 is given by Eq.5. Then, we can apply the maximal version of elliptical potential lemma (see LemmaB.8) to bound the cumulative regret.

## 5 Improved Dependence on \(\kappa\)

While UCB-CCA achieves the regret bound of \(\tilde{\mathcal{O}}(\frac{1}{\kappa}d\sqrt{T})\) improving dependence on \(K\), the bound includes the problem-dependent constant \(\kappa\). This implies a potential risk of the regret bound becoming large when \(\kappa\) becomes very small. In order to circumvent this challenge, we propose a new _optimism in the face of uncertainty (OFU)_ algorithm, UCB-CCA+, which exhibits a regret bound that is independent of \(\kappa\) in the leading term. The pseudocode of UCB-CCA+ is detailed in Algorithm2.

### Algorithm: Ucb-CCA+

#### 5.1.1 Confidence Set

UCB-CCA+ computes a regularized MLE \(\hat{\theta}_{t}\), following the same procedure described in Section3.3. Then, the algorithm constructs a new confidence set centered around \(\hat{\theta}_{t}\) utilizing a Bernstein-type tail inequality for self-normalized martingales [11, 12]. Nevertheless, a simple adaptation of the previous approaches may incur increased dependence on \(M\). Hence, a more intricate analysis and refined algorithmic strategy are imperative to effectively address this challenge.

First, we define \(g_{t}(\theta)\coloneqq\sum_{\tau=1}^{t}\sum_{k\in[O_{\tau}]}\sum_{i\in A_{\tau k }}p_{\tau}(i|A_{\tau k},w_{\tau})x_{\tau i}+\lambda_{t}\theta\) where \(w_{t}=(w_{ti})_{i\in[N]}\) and \(w_{ti}=x_{ti}^{\top}\theta\). We also denote the partial derivative of \(p_{t}(i|A_{tk},w_{t})\) with respect to \(w_{ti}\) as \(\dot{p}_{t}(i|A_{\tau k},w_{\tau})\coloneqq p_{t}(i|A_{tk},w_{t})p_{t}(i_{0}|A _{tk},w_{t})\). Additionally, we define the new design matrix containing local information, denoted as \(H_{t}(\theta)\coloneqq\sum_{\tau=1}^{t}\sum_{k\in[O_{\tau}]}\sum_{i\in A_{ \tau k}}\dot{p}_{\tau}(i|A_{\tau k},w_{\tau})x_{\tau i}x_{\tau i}^{\top}+ \lambda_{t}I_{d}\), and, for convenience, \(H_{t}\coloneqq\sum_{\tau=1}^{t}\sum_{k\in[O_{\tau}]}\sum_{i\in A_{\tau k}} \dot{p}_{\tau}(i|A_{\tau k},w_{\tau}^{*})x_{\tau i}x_{\tau i}^{\top}+\lambda_ {t}I_{d}\). Then, the algorithm constructs a confidence set as below:

\[B_{t}(\delta):=\left\{\theta\in\mathbb{R}^{d}:||g_{t}(\hat{\theta}_{t})-g_{t}( \theta)||_{H_{t}^{-1}(\theta)}\leq\gamma_{t}(\delta)\right\} \tag{6}\]where the confidence radius \(\gamma_{t}(\delta)\) is suitably specified to ensure that the true parameter \(\theta^{*}\) lies in the confidence set \(B_{t}(\delta)\) with high probability. On the event of \(\theta^{*}\in B_{t}(\delta)\), The following lemma bounds the weighted \(\ell_{2}\)-norm of the difference between \(\theta\) and \(\theta^{*}\).

**Lemma 5.1**.: _Suppose \(\theta^{*}\in B_{t}(\delta)\). Then, for any \(\theta\in B_{t}(\delta)\), we have \(||\theta-\theta^{*}||_{H_{t}}\leq 6\gamma_{t}(\delta)\)._

#### 5.1.2 Doubly Optimistic Exposure Swapping

UCB-CCA+ still faces the challenge outlined in Section 2.4.2. The complication is exacerbated for UCB-CCA+ as the algorithm concurrently updates two gram matrices, \(H_{t}\) and \(V_{t}\), which only contain the information of the observed items. Building upon the technique of optimistic exposure swapping detailed in Section 3.2 in each round \(t\), UCB-CCA+ assigns the assortment \(L_{t,H}\) -- containing the item with the largest uncertainty with respect to \(H_{t-1}\) among the top \(KM\) items -- to the first slot of cascade \(S_{t}\). Similarly, the algorithm places \(L_{t,V}\) -- with the item that has the largest uncertainty with respect to \(V_{t-1}\) -- in the second slot of \(S_{t}\).

### Regret Analysis of Ucb-CCA+

**Theorem 5.2** (Regret upper bound of Ucb-CCA+).: _Suppose Assumptions [_4.1_]and[_4.2_]hold, and we run UCB-CCA+ for total \(T\) rounds with \(\lambda\geq 1\) and \(\gamma_{t}(\delta)\coloneqq\frac{3\sqrt{\lambda_{t}}}{2}+\frac{2}{\sqrt{ \lambda_{t}}}\log\biggl{(}\frac{(\lambda_{t}+KM_{t}/d)^{d/2}\lambda_{t}^{-d/2} }{\delta}\biggr{)}+\frac{2d}{\sqrt{\lambda_{t}}}\log 2\) with \(\delta=\frac{1}{t^{2}}\). Then, the regret of UCB-CCA+ is upper-bounded by_

\[\mathcal{R}^{\alpha}(T)\leq C_{1}\gamma_{T}(\delta)\sqrt{2dT\log\left(1+\frac{ KMT}{d\lambda}\right)}+\frac{C_{2}}{\kappa}\gamma_{T}(\delta)^{2}d\log\left(1+ \frac{KMT}{d\lambda}\right)\]

_where \(C_{1}=36\) and \(C_{2}=216(1+Me)\)._

**Discussion of Theorem 5.2**. Theorem 5.2 establishes the regret bound of \(\tilde{\mathcal{O}}\bigl{(}d\sqrt{T}\bigr{)}\). The leading term of the regret bound is independent of \(\kappa\). Although the second term exhibits dependence on \(\kappa\), the term only scales logarithmically in \(T\), whose comparative effect diminishes as \(t\) increases compared to the leading term. Hence, the worst-case regret guarantee of UCB-CCA+ improves from that of UCB-CCA. The comprehensive proof of Theorem 5.2 is provided in the appendix.

## 6 Approximation Algorithm for Optimal Combinatorial Action

In this section, we show that computing the optimal cascade is, in general, a weakly NP-hard problem and give a (fast) polynomial time algorithm that the agent can use to compute a \(0.5\)-approximation to the optimal cascade for any weight \(w\). We assume that the MNL weights are given and consider the problem of finding the cascade that maximizes the expected reward. This is an optimization problem on selecting a sequence of \(K\) assortments with size \(M\) each from a ground set of \(N\) items. The number of feasible cascades is \(O\Big{(}\binom{N}{M}^{K}\Big{)}\). In fact, we establish the following hardness result.

**Lemma 6.1**.: _For general \(M\), the optimization problem is weakly NP-hard even for \(K=2\)._

The hardness of our problem follows from the hardness result of [19] for a related setting of unconstrained cascade optimization where the size of each assortment can be arbitrary. In light of this hardness, we turn our attention to finding fast approximation algorithms for the problem. While there has been a lot of recent work on the unconstrained cascade optimization problem (see [19, 12, 10] and the references therein), none of the previous algorithms apply to our constrained setting (where the size of each assortment is \(M\)).

We consider the following greedy approach for the problem. Consider arbitrary weights at round \(t\), i.e. \(w_{t}=(w_{tt})_{i\in[N]}\), is given. We order the items in \([N]\) in decreasing order of given weights and consider the following cascade of assortments.

\[D_{1}=\{1,2,...,M\},D_{2}=\{M+1,M+2,...,2M\},\cdots,D_{K}=\{(K-1)M+1,\cdots,KM\}\]

We call these assortments "decreasing order assortments". Let \(\mathrm{OPT}\) denote the value of the optimal solution to the problem. We establish that showing these assortments in any possible sequences gives a good approximation to the problem.

**Lemma 6.2**.: _Let \(\mathrm{OPT}\) denote the overall click probability in the optimal solution. The decreasing order assortments \(D_{1},...,D_{K}\), shown in any order, have overall click probability at least \(0.5\,\mathrm{OPT}\)._

We present the proof in Appendix E. We also show that our algorithm is optimal for \(M=1\), which captures the classic cascade optimization problem.

## 7 Numerical Experiments

In this section, we evaluate the performances of our proposed algorithms \(\mathsf{UCB-CCA}\) and \(\mathsf{UCB-CCA}\) in numerical experiments and compare their performances with the existing combinatorial bandit algorithms \(\mathsf{CombCascade}\) and \(\mathsf{C}^{3}\)-\(\mathsf{UCB}\). For simulations, we generate a random sample of the unknown time-invariant parameter \(\theta^{*}\) from \(\mathcal{N}(0,1)\) at the beginning of the simulation. We sample \(N\) feature vectors from \(\mathcal{N}(0,1)\) in each round \(t\). At each round \(t\), the oracle computes a sequence of assortments in decreasing order, forming a cascade \(S_{t}\) based on given \(w_{t}\). We assess the cumulative regret of \(\mathsf{UCB-CCA}\), \(\mathsf{UCB-CCA+}\), \(\mathsf{CombCascade}\), and \(\mathsf{C}^{3}\)-\(\mathsf{UCB}\). Note that a user's choice for \(\mathsf{UCB-CCA}\) and \(\mathsf{UCB-CCA+}\) is determined by the MNL logit choice model, whereas \(\mathsf{C}^{3}\)-\(\mathsf{UCB}\) utilizes a linear model and \(\mathsf{CombCascade}\) is a non-contextual model. Figure 2 and Figure 2 indicate that both \(\mathsf{UCB-CCA}\) and \(\mathsf{UCB-CCA+}\) significantly outperform \(\mathsf{C}^{3}\)-\(\mathsf{UCB}\) and \(\mathsf{CombCascade}\). We also observe that \(\mathsf{UCB-CCA+}\) shows a slight performance advantage over \(\mathsf{UCB-CCA}\), although the difference is not statistically significant. While \(\mathsf{UCB-CCA+}\) has a sharper worst-case regret guarantee, \(\mathsf{UCB-CCA}\) can provide favorable practical performances, with simpler implementation and computational efficiency.

## Acknowledgments and Disclosure of Funding

This work was supported by the National Research Foundation of Korea(NRF) grant funded by the Korea government(MSIT) (RS-2023-00222663, No. 2022R1C1C1006859, No. 2022R1A4A103057912, No. 2021M3E5D2A01024795) and by Creative-Pioneering Researchers Program through Seoul National University and by Naver.

## References

* Abbasi-Yadkori et al. [2011] Yasin Abbasi-Yadkori, David Pal, and Csaba Szepesvari. Improved algorithms for linear stochastic bandits. _Advances in neural information processing systems_, 24, 2011.
* Abeille et al. [2021] Marc Abeille, Louis Faury, and Clement Calauzenes. Instance-wise minimax-optimal algorithms for logistic bandits. In _International Conference on Artificial Intelligence and Statistics_, pages 3691-3699. PMLR, 2021.
* Agrawal et al. [2023] Priyank Agrawal, Theja Tulabandhula, and Vashist Avadhanula. A tractable online learning algorithm for the multinomial logit contextual bandit. _European Journal of Operational Research_, 2023.
* Agrawal et al. [2017] Shipra Agrawal, Vashist Avadhanula, Vineet Goyal, and Assaf Zeevi. Thompson sampling for the mnl-bandit. In _Conference on Learning Theory_, pages 76-78. PMLR, 2017.
* Agrawal et al. [2019] Shipra Agrawal, Vashist Avadhanula, Vineet Goyal, and Assaf Zeevi. Mnl-bandit: A dynamic learning approach to assortment selection. _Operations Research_, 67(5):1453-1485, 2019.
* Auer [2002] Peter Auer. Using confidence bounds for exploitation-exploration trade-offs. _Journal of Machine Learning Research_, 3(Nov):397-422, 2002.
* Chen et al. [2020] Xi Chen, Yining Wang, and Yuan Zhou. Dynamic assortment optimization with changing contextual information. _Journal of machine learning research_, 2020.
* Cheung and Simchi-Levi [2017] Wang Chi Cheung and David Simchi-Levi. Assortment optimization under unknown multinomial logit choice models. _arXiv preprint arXiv:1704.00108_, 2017.
* Cheung and Simchi-Levi [2017] Wang Chi Cheung and David Simchi-Levi. Thompson sampling for online personalized assortment optimization problems with multinomial logit choice models. _Available at SSRN 3075658_, 2017.
* Fata et al. [2019] Elaheh Fata, Will Ma, and David Simchi-Levi. Multi-stage and multi-customer assortment optimization with inventory constraints. _arXiv preprint arXiv:1908.09808_, 2019.
* Faury et al. [2020] Louis Faury, Marc Abeille, Clement Calauzenes, and Olivier Fercoq. Improved optimistic algorithms for logistic bandits. In _International Conference on Machine Learning_, pages 3052-3060. PMLR, 2020.
* Gao et al. [2021] Pin Gao, Yuhang Ma, Ningyuan Chen, Guillermo Gallego, Anran Li, Paat Rusmevichientong, and Huseyin Topaloglu. Assortment optimization and pricing under the multinomial logit model with impatient customers: Sequential recommendation and selection. _Operations research_, 69(5):1509-1532, 2021.
* Kveton et al. [2015] Branislav Kveton, Csaba Szepesvari, Zheng Wen, and Azin Ashkan. Cascading bandits: Learning to rank in the cascade model. In _International conference on machine learning_, pages 767-776. PMLR, 2015.
* Kveton et al. [2015] Branislav Kveton, Zheng Wen, Azin Ashkan, and Csaba Szepesvari. Combinatorial cascading bandits. _Advances in Neural Information Processing Systems_, 28, 2015.
* Lattimore and Szepesvari [2020] Tor Lattimore and Csaba Szepesvari. _Bandit algorithms_. Cambridge University Press, 2020.
* Li et al. [2017] Lihong Li, Yu Lu, and Dengyong Zhou. Provably optimal algorithms for generalized linear contextual bandits. In _International Conference on Machine Learning_, pages 2071-2080. PMLR, 2017.
* Li and Zhang [2018] Shuai Li and Shengyu Zhang. Online clustering of contextual cascading bandits. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 32, 2018.
* Li et al. [2016] Shuai Li, Baoxiang Wang, Shengyu Zhang, and Wei Chen. Contextual combinatorial cascading bandits. In _International conference on machine learning_, pages 1245-1253. PMLR, 2016.
* Liu et al. [2020] Nan Liu, Yuhang Ma, and Huseyin Topaloglu. Assortment optimization under the multinomial logit model with sequential offerings. _INFORMS Journal on Computing_, 32(3):835-853, 2020.

* [20] Xutong Liu, Jinhang Zuo, Siwei Wang, John CS Lui, Mohammad Hajiesmaili, Adam Wierman, and Wei Chen. Contextual combinatorial bandits with probabilistically triggered arms. In _International Conference on Machine Learning_, pages 22559-22593. PMLR, 2023.
* [21] Daniel McFadden. Modeling the choice of residential location. _Transportation Research Record_, (673), 1978.
* [22] Min-hwan Oh and Garud Iyengar. Thompson sampling for multinomial logit contextual bandits. _Advances in Neural Information Processing Systems_, 32, 2019.
* [23] Min-hwan Oh and Garud Iyengar. Multinomial logit contextual bandits: Provable optimality and practicality. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 35, pages 9205-9213, 2021.
* [24] Noemie Perivier and Vineet Goyal. Dynamic pricing and assortment under a contextual mnl demand. _Advances in Neural Information Processing Systems_, 35:3461-3474, 2022.
* [25] Daniel Vial, Sujay Sanghavi, Sanjay Shakkottai, and R Srikant. Minimax regret for cascading bandits. _arXiv preprint arXiv:2203.12577_, 2022.
* [26] Kun Wang. Conservative contextual combinatorial cascading bandit. _IEEE Access_, 9:151434-151443, 2021.
* [27] Xue Wang, Mike Mingcheng Wei, and Tao Yao. Online assortment optimization with high-dimensional data. _Available at SSRN 3521843_, 2019.
* [28] Zixin Zhong, Wang Chi Chueng, and Vincent YF Tan. Thompson sampling algorithms for cascading bandits. _The Journal of Machine Learning Research_, 22(1):9915-9980, 2021.
* [29] Shi Zong, Hao Ni, Kenny Sung, Nan Rosemary Ke, Zheng Wen, and Branislav Kveton. Cascading bandits for large-scale recommendation problems. In _Proceedings of the 32nd Conference on Uncertainty in Artificial Intelligence_, 2016.