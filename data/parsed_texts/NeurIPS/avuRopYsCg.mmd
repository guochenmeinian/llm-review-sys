# Discovering Intrinsic Spatial-Temporal Logic Rules to Explain Human Actions

 Chengzhi Cao\({}^{1,2}\), Chao Yang\({}^{1}\), Ruimao Zhang\({}^{1}\), Shuang Li\({}^{1}\)

\({}^{1}\)The Chinese University of Hong Kong (Shenzhen)

\({}^{2}\)University of Science and Technology of China

chengzhicao@mail.ustc.edu.cn, 222043011@link.cuhk.edu.cn,

zhangruimao@cuhk.edu.cn, lishuang@cuhk.edu.cn

Work done as a graduate research assistant at The Chinese University of Hong Kong (Shenzhen)

###### Abstract

We propose a _logic-informed_ knowledge-driven modeling framework for human movements by analyzing their trajectories. Our approach is inspired by the fact that human actions are usually driven by their intentions or desires, and are influenced by environmental factors such as the spatial relationships with surrounding objects. In this paper, we introduce a set of _spatial-temporal logic rules_ as knowledge to explain human actions. These rules will be automatically discovered from observational data. To learn the model parameters and the rule content, we design an expectation-maximization (EM) algorithm, which treats the rule content as latent variables. The EM algorithm alternates between the E-step and M-step: in the E-step, the posterior distribution over the latent rule content is evaluated; in the M-step, the rule generator and model parameters are jointly optimized by maximizing the current expected log-likelihood. Our model may have a wide range of applications in areas such as sports analytics, robotics, and autonomous cars, where understanding human movements are essential. We demonstrate the model's superior _interpretability_ and _prediction_ performance on pedestrian and NBA basketball player datasets, both achieving promising results.

## 1 Introduction

For a human, although the exhibited movements can be complex, the logic behind the actions is usually simple, clear, and can be generalized [17]. The _logic rules_ present a compact and high-level _knowledge representation_, defining what actions tend to be executed under what conditions. It emphasizes reasoning, and encourages structuring the world in terms of objects, properties, and relations [22]. There has been a great interest and business value in unveiling the human logic from the observational movements and actions [18]. We provide two motivating examples below.

In _sports analytics_, understanding each player's behavior preferences or tendencies under various scenarios will provide coaches with valuable information [1]. Usually, coaches need to watch the game or training videos for hundreds of hours before they can summarize the discoveries into compact principles. _Could we design an algorithm to synthesize these principles from the raw action data automatically_? One can imagine, such a tool will significantly reduce the workload of coaches, providing more granular insight into each player's capabilities and strategies, and aiding in personalized training and match strategy design [15].

In _self-driving car_, it's essential to enable the self-driving cars to "read human's mind" like humans. This requires the self-driving cars to automatically _understand human intentions and reasoning_ whenthey are running on the same roads with human drivers [2]. If self-driving cars can automatically distill logic rules from their observed _low-level noisy_ human actions and movement trajectories, it will increase the technical reliability and accelerate the widespread use of self-driving cars.

For human actions, lots of the governing rules would be regarding the _spatial-temporal relation_ with the surrounding environments and their intentions [9]. For example, when a basketball player with a ball is within the scoring range, his/her action, such as shoot, pass, or triple threat, is influenced by historical and current surrounding factors, such as the current locations of the player and the defenders, the time elapses of the game, the success shooting rate of the player in today's game, and so on. The quick decision made by the player is actually reflecting a composition of all these factors, which can be described as a collection of spatial-temporal logic rules in our model.

Formally, in our introduced spatial-temporal logic rules, the logic variable (i.e., predicate) set will include spatial-temporal relation predicates, in addition to the commonly defined object property and relation predicates. The rule content will _capture the spatial relation of the object with surrounding objects, as well as the temporal ordering constraints of the events_.

Our methods have the following distinct features:

_From the modeling perspective:_ (_i_) Our human action model is a rule-based _probabilistic_ model, which treats each hidden rule as a "soft" constraint. We assume each rule will be executed by humans with probabilities, and this _tolerates the uncertainties_ in data. (_ii_) Our model directly uses low-level, fine-grained, and (may) irregularly-spaced action times and locations (i.e., original _3d coordinates_) as inputs, as opposed to other rule-based models, where one needs to first extract relational data as inputs. (_iii_) Our spatial and temporal predicates are also probabilistic. For predicates such as "left of" or "before", we model them as kernel functions with learnable variables. In this way, our introduced spatial-temporal predicates are _smooth functions_ of the input locations and times, which increases model flexibility.

_From the learning perspective:_ We propose a _tractable_ and _differentiable_ algorithm that can jointly learn the _rule content_ and _model parameters_ from observational data. The learning framework is designed to maximize the likelihood of the human action trajectories. Specifically, we propose to use a neural rule generator to generate the spatial-temporal logic rule set. Our continuous rule generator parameters will be optimized in a differentiable way. The overall learning procedure is an expectation-maximization (EM) algorithm, where we treat the rule set as latent variables. In the E-step, the posterior distribution over the latent rule set is evaluated. In the M-step, both the rule generator parameters and the model parameters are optimized by maximizing the expected log-likelihood with respect to the current posterior. We demonstrated the promising performance of our model in terms of human action _prediction_ and _explanation_ on two interesting real datasets.

## 2 Related Work

Logic Rule Learning.Learning logic rules from raw data has been widely studied for various downstream tasks, such as motion inference [4] and healthcare analysis [11]. Learning rules via an exact search requires enumerating all combinations of the logic predicates and is intractable in most problems. One has to design heuristic searching algorithms by leveraging some structural properties of the problems. For example, Dash et al. [5] formulated a convex rule learning problem and proposed a column generation algorithm to expand the rule set gradually. Wang et al. [25] designed a Bayesian framework for learning rule classifiers and derived bounds on the support of rules in a MAP solution. Recently, Yang et al. [28] proposed an interesting end-to-end differentiable approach (Neural LP) to learn the parameters and structure of logical rules. Qu et al. [19], and Sadeghian et al. [22] proposed an efficient logic rule mining algorithm based on the knowledge graph data. _However, none of these advanced rule mining methods can directly work on spatial-temporal human action data when the inputs are raw event 3d coordinates and types._

Spatio-Temporal Dynamics for Event Data.Since the human actions are irregular spatial-temporal event data, we also briefly discuss _probabilistic_ models for such _event sequences_. Modeling the spatial-temporal dynamics of discrete events is foundational in many scientific fields and applications [20]. Shen et al. [23] proposed a novel deep learning model for spatial-temporal events such as taxi data and achieved promising prediction accuracy. Zhou et al. [31] integrated deep learning methods with spatiotemporal point processes and modeled the intensity function as a latent stochastic process. Chen et al. [3] deployed two novel architectures, including jump and attentive continuous-time normalizing flows, to learn the dynamics of the spatiotemporal event data. Repe et al.

[21] learned canonical spatiotemporal point cloud representation using a latent ODE and continuous normalizing flows to generate shapes continuously in spacetime. _However, these spatial-temporal event models are governed by hard-to-interpret dynamic functions and cannot be generalized to model human action events. Could we propose a model with logic-informed dynamic functions to explain the spatial-temporal human action events?_

## 3 Our Model

### Data: Human Actions Recorded as Spatial-Temporal Event Sequences

Consider a set of objects, denoted as \(\mathcal{C}\). For the object \(c\in\mathcal{C}\), its trajectories and the key actions observed up to \(t\) can be summarized as a sequence of temporally ordered events:

\[\mathcal{H}^{c}_{t-}=\{e^{c}_{1}=(t^{c}_{1},s^{c}_{1},\kappa^{c}_{1}),\dots,e ^{c}_{n}=(t^{c}_{n},s^{c}_{n},\kappa^{c}_{n})\mid t^{c}_{n}<t\},\] (1)

where \(t\in R^{+}\) is the time, \(s\in R^{2}\) is the location, and \(\kappa\in\mathcal{K}\) is the event (i.e., action) type.

### Definition of Spatial-Temporal Predicates

Static PredicateGiven the object set \(\mathcal{C}\), the _predicate_ is defined as the _property_ or _relation_ of objects, which is a _logic function_ as follows:

\[X(\cdot):\mathcal{C}\times\mathcal{C}\cdots\times\mathcal{C}\mapsto\left\{0,1 \right\}.\] (2)

For example, \(Smokes(c)\) is a property predicate and \(Friend(c,c^{\prime})\) is a relation predicate.

Temporal relation predicatesThey can be used to define the temporal relations of two action events. We consider three types of temporal relation predicates {before, equal, after} as:

\[\begin{array}{l}R_{\text{Before}}(t_{1},t_{2})=\mathbbm{1}\{t_{1}-t_{2}<0 \},\\ R_{\text{After}}(t_{1},t_{2})=\mathbbm{1}\{t_{1}-t_{2}>0\},\\ R_{\text{Equal}}(t_{1},t_{2})=\mathbbm{1}\{t_{1}=t_{2}\}.\end{array}\] (3)

We will treat the temporal relation predicate as either a boolean variable or a real-valued function. If the time information is imprecisely recorded, we can parameterize the temporal relation predicates as temporal kernel functions that map to \([0,1]\), which is a function of \(t_{1},t_{2}\) with learnable parameters.

Spatial-Temporal PredicateIn our paper, we extend the above static predicates to spatial-temporal predicates, which include spatial-temporal _property_ predicates and spatial-temporal _relation_ predicates.

Specifically, the spatial-temporal _property_ predicates are defined as:

\[X(\cdot):\mathcal{C}\times\cdots\times\mathcal{C}\times\mathcal{T}\times \mathcal{S}\mapsto\left\{0,1\right\}.\] (4)

For example, \(PickupKey\left(c,t,s\right)\) is a spatial-temporal property predicate. Suppose an entity \(c_{1}\) picked up the key at time \(t_{1}\) in location \(s_{1}\), then the predicate will be grounded as True (1) at \((c_{1},t_{1},s_{1})\), i.e., \(PickupKey(c_{1},t_{1},s_{1})=1\); otherwise it is false.

Given the observational human action data, the grounded predicate \(\{PickupKey\left(c,t,s\right)\}_{t=1,2,\dots}\) can be modeled as a sequence of discrete events - when the predicate becomes True, an event happens. In general, the grounded spatial-temporal property predicate is a discrete event sequence, where the event occurrence times and locations are irregular.

The spatial-temporal _relation_ predicates are introduced to define the spatial and temporal relations of two entities. Specifically, they are defined as:

\[R(\cdot,\cdot):(\mathcal{C}\times\mathcal{T}\times\mathcal{S})\times(\mathcal{ C}\times\mathcal{T}\times\mathcal{S})\mapsto\left\{0,1\right\}.\] (5)

Spatial-temporal relation predicates are logic variables indicating the spatial-temporal relations of two objects, where we further divide them into _temporal relation_ predicates, _static spatial relation_ predicates, and _dynamic spatial relation_ predicates. More details can be found in Appendix.

It is noteworthy that all these boolean predicates can be converted to probabilistic ones. We can soften these logic functions by kernel functions with learnable parameters to tolerate uncertainties in data.

### Definition of Spatial-Temporal Logic Rules

We will consider spatial-temporal logic rules where the body part contain spatial-temporal predicates as relation constraints. For example, a sensible rule will look like:

\[\begin{array}{l}f:& Y_{\text{TurnAcom}}(c,t,s)\gets X_{\text{PickUpKey}}(c,t,s) \bigwedge\\ & R_{\text{InForto}}((c^{\prime},t,s^{\prime}),(c,t,s))\bigwedge R_{\text{ behind}}((c^{\prime\prime},t,s^{\prime\prime}),(c,t,s)),\end{array}\] (6)where \(c\in\mathcal{C}_{\text{person}}\), \(c^{\prime}\in\mathcal{C}_{\text{block}}\), and \(c^{\prime\prime}\in\mathcal{C}_{\text{key}}\). "person", "block" and "key" are the specific instances in the object set \(\mathcal{C}\), and this rule represents that a person wants to pick up a key, while one block is in front of him and the key is behind him, so the turns around. We utilize this example to manifest the meaning of logic rules. In general, the _spatial-temporal logic rule_ in our paper is defined as a logical connectives of predicates, including property predicates and spatial-temporal relation predicates:

\[f:Y(v)\leftarrow\bigwedge_{X_{\text{groups}}\in\mathcal{X}_{f}}X_{\text{ property}}(v)\bigwedge_{R_{\text{spatial-temporal}}\in\mathcal{R}_{f}}R_{\text{spatial-temporal}}(v^{\prime},v),\] (7)

where \(Y(v)\) is the _head predicate_ evaluated at the entity-time-location triplet \(v\), \(\mathcal{X}_{f}\) is the set of property predicates defined in rule \(f\), and \(\mathcal{R}_{f}\) denotes the set of spatial-temporal relation predicates defined in rule \(f\).

### Logic-Informed Action Event Models

We consider a setting where we can fully observe the trajectories of all the moving objects, including their real-time locations and key actions (i.e., events), denoted as \(\mathcal{H}_{t}\). We aim to propose a logic-informed spatial-temporal model to predict and explain the action type given the entity-time-location triplet \(v=(c,t,s)\) (i.e., query) and \(\mathcal{H}_{t}\). The main idea is to construct the model features using spatial-temporal logic rules, as defined in Eq. (7). Intuitively, given the entire trajectories \(\mathcal{H}_{t}\) and the query \(v=(c,t,s)\), the body part of the rule defines the evidence to be selectively gathered from _history_ to deduce the event type for query entity \(v=(c,t,s)\). Assume that for each possible event type \(\kappa\in\mathcal{K}\), there exist multiple rules such as Eq. (7) to explain its occurrence, with \(\kappa\) being the _head predicate_. Given an individual rule as Eq. (7), we propose to build the _feature_ that is conditional on history and query as

\[\phi_{f}(\kappa\left|v,\mathcal{H}_{t}\right)=\text{sign}(\kappa\in f)\cdot \sum_{\text{path}(\mathcal{H}_{t},v)}g_{f}\left(\text{path}\right),\] (8)

where we introduce a function \(g_{f}(\cdot)\) to check the body conditions of \(f\) given a "path". We use a simple example to explain how to compute features, as shown in Figure 1. As illustrated, the feature computes the valid total number of "paths" given the data and query. Suppose there is a rule set \(\mathcal{F}_{\kappa}\), where the event \(\kappa\) is the head predicate. All the rules will play together to reason about the occurrence of \(\kappa\). For each \(f\in\mathcal{F}_{\kappa}\), one can compute the features as above. Given the rule set \(\mathcal{F}_{\kappa}\), we model the probability of the event \(\kappa\) as a log-linear function of the features, i.e.,

\[p(\kappa|v,\mathcal{H}_{t})\propto\exp\left(\sum_{f\in\mathcal{F}_{\kappa}}w_ {f}\cdot\phi_{f}(\kappa|v,\mathcal{H}_{t})\right),\] (9)

where \(w=[w_{f}]_{f\in\mathcal{F}}\geq 0\) are the learnable weight parameters associated with each rule. All the model parameters can be learned by maximizing the likelihood, which can be computed using the above Eq. (9). We intend to train a rule generator \(p_{\theta}\) and an evaluator \(p_{w}\) to maximize the likelihood of training data as:

\[\max_{\theta,w}\mathcal{O}(\theta,w)=\mathbb{E}_{(\kappa,v,\mathcal{H}_{t})} [\log\mathbb{E}_{p_{\theta}}[p_{w}(\kappa|v,\mathcal{H}_{t})]].\] (10)

More details can be found as follows.

## 4 Our Learning Algorithm

Our goal is to jointly learn the set of spatial-temporal logic rules \(\{\mathcal{F}_{\kappa}\}_{\kappa\in\mathcal{K}}\) and their weights by the maximum likelihood method, where each rule has a general form as Eq. (7).

To discover each rule, the algorithm needs to navigate through the combinatorial space considering all the combinations of the property predicates and their spatial and temporal relations. To address this computational challenge, we propose a tractable (functional) EM algorithm that treats the rule set as latent variable \(z\). The rules will be generated by a hidden neural rule generator. The overall learning framework alternates between an E-step, where the posterior distribution of the latent rule space is evaluated (rule generation), and the M-step, where the model parameters and rule generator parameters are optimized. Please refer to Figure. 2 for an illustration.

Figure 1: Illustration of feature construction using a simple logic formula with temporal relation predicate (\(t_{1}<t_{2}\)), \(f:Y\leftarrow A\wedge B\wedge C\wedge(A\) Before \(B\)). The rule defines the template to gather combinations of the body predicate history events. Here predicate A has 2 events and predicate B has 1 event, the temporal relation constraint would lead to valid combinations (also called “paths”). This type of feature construction can be extended to spatial-temporal cases, where we count the valid paths as the feature.

Our goal is to maximize the likelihood of the observed human action events \(\{\kappa^{(i)}\}_{i=1,\dots,n}\). Using the chain rule, we have

\[\log p_{w}(\{\kappa^{(i)}\}_{i=1,\dots,n})=\sum_{i=1}^{n}\log p_{w}(\kappa^{(i)} \mid v^{(i)},\mathcal{H}_{t^{(i-1)}}).\] (11)

To simplify the notation, we will use \(p_{w}(\kappa^{(i)})\) to stand for \(p_{w}(\kappa^{(i)}\mid v^{(i)},\mathcal{H}_{t^{(i-1)}})\) in the following. Given a latent rule set \(z\), we have to marginalize the posterior of \(z\) to get the above log-likelihood. However, the exact inference of \(z\) is intractable. We will introduce an amortized recognition network \(p_{\theta}(z|\kappa^{(i)})\) to approximate the true posterior. We have

\[\log p_{w}(\kappa^{(i)})=D_{KL}(p_{\theta}(z|\kappa^{(i)})||p_{w}(z|\kappa^{( i)}))+\mathcal{L}(\theta,w;\kappa^{(i)}),\] (12)

where the first term is the KL divergence of the approximate from the true posterior, and the second term \(\mathcal{L}(\theta,w;\kappa^{(i)})\) is the variational lower bound (ELBO). It can be represented as:

\[\mathcal{L}(\theta,w;\kappa^{(i)})=-D_{KL}(p_{\theta}(z|\kappa^{(i)})||p_{w}( z))+\mathbb{E}_{p_{\theta}(z|\kappa^{(i)})}[\log p_{w}(\kappa^{(i)}|z)].\] (13)

And \(\log p_{w}(\kappa^{(i)})\geq\mathcal{L}(\theta,w;\kappa^{(i)})\). The bound becomes tight when the approximate posterior matches the true one. Our goal is to optimize the variational parameters \(\theta\) and model parameters \(w\) from the ELBO lower bound.

### Rule Generator

We deploy Transformer-based framework to model the rule generator \(p_{\theta}\). We define the distribution of a set of rules as follows:

\[p_{\theta}(z\mid v,\mathcal{H}_{t})=\Psi(z|N,\text{Trans}_{\theta}(v,\mathcal{ H}_{t})),\] (14)

where \(\Psi(\cdot)\) is multinomial distributions, \(N\) is the number of the top rules, and \(\text{Trans}_{\theta}(v,\mathcal{H}_{t})\) defines a distribution over compositional rules with spatial-temporal states. The generative process of the rule set is quite intuitive, where we simply generate \(N\) rules to form \(z\). In fact, this \(p_{\theta}(z\mid v,\mathcal{H}_{t})\) is a flexible posterior approximation function, which will be optimized by the EM type algorithm.

We choose transformer over graph neural network (GNN) as our baseline because transformer architectures are based on a self-attention mechanism that is able to capture long-range relationships, as opposed to recurrent neural networks that process sequence elements recursively and can only take into account short-term context. Note that the graph operations in GNN are designed to learn node representations on the fixed and homogeneous graphs. The limitations especially become problematic when learning representations on a changeable graph that consists of various types of nodes and edges.

Figure 2: The overview of our proposed framework. It contains two important processes: rule generating and logic reasoning. Given the past motion of each entity on a scene over the last few seconds, the rule generator generates logic rules for the reasoning predictor. The reasoning predictor takes the generated rules as input, and predict the intention of each entity. It is optimized by EM algorithm. In the E-step, a set of top K rules are selected from all generated rules via posterior inference. Finally in the M-step, the rule generator is updated to be consistent with the high-quality rules identified in E-step.

### Rule Evaluator

Eq. (9) is our rule evaluator (suppose we know the rule content). Here we assume the rule content is latent, and the rule evaluator is given as

\[p_{w}(\kappa|v,z,\mathcal{H}_{t})=\frac{\exp\left(\sum_{f\in z_{\kappa}}w_{f} \cdot\phi_{f}(\kappa|v,\mathcal{H}_{t})\right)}{\sum_{\kappa^{\prime}}\exp \left(\sum_{f\in z_{\kappa^{\prime}}}w_{f}\cdot\phi_{f}(\kappa^{\prime}|v, \mathcal{H}_{t})\right)}.\] (15)

### Optimization

We optimize the rule generator \(p_{\theta}\) and reasoning evaluator \(p_{w}\) to maximize the objective in Eq. (10). At each training iteration, we first update the reasoning predictor \(p_{w}\) according to some rules generated by the generator, and then update the rule generator \(p_{\theta}\).

In our network, the latent rule set will be automatically discovered. The best set of logic rules is approximately obtained by sampling and preserving the top-K rules according to their posterior probabilities. Specifically, as shown in Eq. (14), the posterior probabilities of the latent rule \(z\) is obtained by a Transformer type of encoder, which maps the input observed action trajectories to a latent explanatory rule space. Each candidate rule is generated in the latent rule space token-by-token (token means logic variable/predicate in our setting) in a sequential manner and meanwhile the posterior probability of each rule sequence can be evaluated. When optimizing the evaluator, we draw several rules \(\hat{z}\) for each query and let the evaluator uses \(\hat{z}\) to predict \(\kappa\). For each query, we try to identify top-K rules \(z_{I}\) from all generated rules \(\hat{z}\). It is accomplished by taking into account the posterior probabilities of each subset of logic rules \(z_{I}\) with prior from the rule generator \(p_{\theta}\) and likelihood from the reasoning predictor \(p_{w}\). Specifically, when a series of rules produced from the rule generator \(p_{\theta}\), we calculate the weights of each rule \(z^{(i)}\) as follows:

\[J(z^{(i)})=\{p_{w}(\kappa|z^{(i)})-\frac{1}{|\mathcal{A}|}\}+\log\text{Trans}_{ \theta}(z^{(i)}|v,\mathcal{H}_{t}),\] (16)

where \(\mathcal{A}\) is the set of all candidate event type inferred by logic rules. \(\text{Trans}_{\theta}(z^{(i)}|v,\mathcal{H}_{t})\) is the probability of rule computed by the generator. For a subset of rules \(z_{I}\subset\hat{z}\), the log-probability can be approximated as: \(\log p_{\theta,w}(z_{I}|v,\mathcal{H}_{t})\approx\sum_{z^{(i)}\in z_{I}}J(z^{( i)})+\log\Psi(z_{I}|N,\text{Trans}_{\theta}(v,\mathcal{H}_{t}))+\text{const}\). This equation inspired us to use the distribution \(q(z_{I})\propto\exp(\sum_{z^{(i)}\in z_{I}}J(z^{(i)})+\log\Psi(z_{I}|N,\text{ Trans}_{\theta}(v,\mathcal{H}_{t})))\) as approximation of the posterior. Each rule \(z^{(i)}\) sampled from \(q(z_{I})\) independently can be formed with \(N\) logic rules.

Clearly, \(J(z^{(i)})\) can be regarded as the quality of candidate rules, with consideration of the evaluator \(p_{w}\). It is calculated as the contribution of a rule to the correct event type minus the average contribution of this rule to the other candidate responses. A rule is more significant if it obtains a higher score to the correct event type and a lower score to other potential predictions.

After getting several high-quality rules from training data, we further utilize these rules to update the parameters of rule generator \(p_{\theta}\). Concretely, we regard the generated high-quality rules as part of training data, and update the rule generator by maximizing the log-likelihood as follows:

\[\mathcal{O}(\theta)=\log p_{\theta}(z_{I}|v,\mathcal{H}_{t})=\sum_{z^{(i)}\in z _{I}}\log\text{Trans}_{\theta}(v,\mathcal{H}_{t})+\text{const}.\] (17)

By learning to generate high-quality rules, the rule generator will reduce the search area and produce better empirical results for the reasoning predictor.

## 5 Experiments

In this section, we provide some implementation details and show ablation studies as well as visualization to evaluate the performance of our framework. We compare our model with several state-of-the-art approaches, including PECNet [14], NMMP [7], STGAT [8], SOPHIE [22], STAR [29], Y-Net [13], MID [6], Social-SSL [24], Social-VAE [26], Social-Implicit [16], and NSP-SFM [30].

### Implementation

We follow the same data prepossessing strategy as PECNet [14] for our method. All models were trained and tested on the same split of the dataset, as suggested by the benchmark. We train the network using Adam optimizer with a learning rate of 0.001 and batch size 16 for 500 epochs.

#### 5.1.1 Datasets

Stanford Drone Dataset.This dataset consists of more than 11,000 persons in 20 scenes captured from the campus of Stanford University in bird's eye view. We follow the [27] standard train-test split, and predict the future 4.8s (12 frames) using past 3.2s (8 frames). Note that SDD dataset does not provide explicit pedestrian's action. Instead, we record them as an abstract encoding of the pedestrian's speed and location. The action contains [left, right, straight, turn around].

NBA SportVU Dataset.It is collected by NBA using the SportVU tracking system, which reports the trajectories of the ten players and the ball in real basketball games. Each trajectory contains the 2D positions and velocities of the offensive team, consisting of 5 players. We predict the future 10 timestamps (4.0s) based on the historical 5 timestamps (2.0s). Each player's action contains [left, right, straight, turn around, pass, shoot].

#### 5.1.2 Metrics

Here, we adopt two metrics for evaluation: Average Displacement Error (\(ADE\)) and Final Displacement Error (\(FDE\)). Specifically, \(ADE_{N}\) is defined as the minimum average distance between N predicted trajectories and the ground truth over all the involved entities within the prediction horizon. \(FDE_{N}\) is defined as the minimum deviated distance of N predicted trajectories at the last predicted time step. Moreover, we also calculate the accuracy and F1 score of event-types predicted from each network.

### Synthetic Experiment

We follow [10] to verify our model's rule discovery ability on synthetic datasets with a known set of ground-truth rules and weights. The synthetic events are generated from TLPPs [12] with a known set of rules and weights. We prepared 4 synthetic datasets, and each setting corresponds to different rule weights, rule length and number, type of temporal relation, and intensity of free predicates. Note that it was originally utilized for the temporal point process, so we modify it by adding spatial variables (such as "left, right, front, and behind") to fit in our settings. The weight learning results on 4 synthetic datasets are shown in the Figure 3, where 2400 sequences are used for evaluation. Each plot at the bottom compares the genuine rule weights to the learned rule weights and reports the Mean

\begin{table}
\begin{tabular}{c|c c c c c c c} \hline Times & Y-Net & MID & NSP-SFM & Social-SSL & \begin{tabular}{c} Social \\ Implicit \\ \end{tabular} & 
\begin{tabular}{c} Social \\ VAE \\ \end{tabular} & Ours \\ \hline
1.0s & 0.38/0.48 & 0.45/0.59 & 0.41/0.52 & 0.48/0.61 & 0.45/0.53 & 0.49/0.66 & **0.30/0.40** \\
2.0s & 0.63/0.93 & 0.76/1.06 & 0.67/0.94 & 0.76/1.08 & 0.72/0.96 & 0.77/1.11 & **0.58/0.88** \\
3.0s & 0.94/1.34 & 1.06/1.40 & 0.98/1.35 & 1.06/1.43 & 1.00/1.39 & 1.11/1.46 & **0.87/1.31** \\
4.0s & 1.17/1.61 & 1.32/1.74 & 1.18/1.63 & 1.35/1.78 & 1.19/1.66 & 1.37/1.79 & **1.13/1.60** \\ \hline Acc. & 0.69 & 0.65 & 0.70 & 0.68 & 0.69 & 0.64 & **0.73** \\ \hline \end{tabular}
\end{table}
Table 1: Quantitative results (\(ADE_{20}/FDE_{20}\), and accuracy) of trajectory prediction in NBA dataset. The bold/underlined font represent the best/second best result.

Figure 3: Rule discovery and weight learning results on 4 synthetic datasets (2.4K seqs).

Absolute Error (MAE). As we can see, almost all truth rule weights are learned correctly. It shows an accurate performance of our algorithm in terms of both the rule discovery and parameter learning.

### Analysis

We compare our method with several state-of-the-art approaches, and Table 2 presents the qualitative results on the SDD dataset. The proposed model achieved the best performance in ADE, FDE and accuracy. We observe that our method significantly outperforms all baselines measured by ADE and FDE. It achieves an ADE of 6.41 and FDE of 10.23 at \(K=20\) in SDD datset, which exceeds the previous state-of-the-art performance of Y-Net [13] by 18.3% on ADE and 13.6% on FDE. In Table 1, our method also achieve higher performance than Y-Net in NBA dataset. This is because Y-Net firstly assume that the waypoint lies on a straight line segment connecting the sampled goal and the past trajectory, then use a multivariate Gaussian prior centered at the assumed location. This assumption can not well suit in other complex conditions, such as the trajectory of players in the NBA dataset.

Compared with MID [6], we also obtain 15.7% ADE and 28.4% FDE improvement. Note that they carefully design a Transformer-based architecture to model the temporal dependencies in trajectories, but ignore the spatial correlation of agents. Our transformer-based network aims at generating high-quality logic rules based on spatial-temporal relation under the principle to maximize the likelihood of the observational human actions. For NSP-SFM [30], it obtains high performance in SDD dataset but can not achieve the same level in NBA dataset. It combines physics with deep learning for trajectory prediction and accommodates arbitrary physics models. The limitation of it lies in specific physics models, such as pedestrians, and is deterministic. So it can not deal with some strategy-based conditions, including basketball and football games. But our logic-learning method tries to use a set of spatial-temporal logic rules with intention variables involved as principles to model the dynamics of human actions, not restrained into specific conditions.

Further, The proposed model achieved the best scores in F1 score, which is an balanced metric considering both recall and precision. This is because the rule generator and evaluator can collaborate with each other to reduce search space and learn better rules. More experiments and ablation studies can be found in Supplementary Material.

\begin{table}
\begin{tabular}{l|c c c c c c c c c} \hline Metrics & PECNet & Y-Net & MID & NMMP & STGAT & SOPHIE & 
\begin{tabular}{c} Social \\ SSL \\ \end{tabular} & NSP-SFM & STAR & Ours \\ \hline \(ADE_{20}\) & 20.03 & 7.85 & 7.61 & 14.12 & 14.43 & 15.56 & 6.63 & 6.52 & 10.76 & **6.41** \\ \(FDE_{20}\) & 33.86 & 11.85 & 14.30 & 20.68 & 22.59 & 24.32 & 12.23 & 10.61 & 17.03 & **10.23** \\ \hline F1 score & 0.37 & 0.54 & 0.49 & 0.41 & 0.33 & 0.39 & 0.53 & 0.58 & 0.56 & **0.59** \\ \hline \end{tabular}
\end{table}
Table 2: Quantitative results (\(ADE_{20}\), \(FDE_{20}\) and F1 score) of trajectory prediction in SDD dataset. The bold/underlined font represent the best/second best result.

Figure 4: Visual results on the NBA dataset. We plot the predicted trajectories from the state-of-the-art method NMMP (b), Ours (c) and ground truth (a). The red/blue color represents players of two teams and the green color represents the basketball. Light color represents the past trajectory.

To evaluate the robustness of our method, We added some noise and randomly removed several tracks in the NBA dataset, then evaluated all methods in Table 3 ("Ours*" is the original results without noises or missing tracks). As we can see, our method still achieves the best performance. Moreover, by comparing "Ours" and "Ours*", we can see that the quality of tracks has less influence on our method, which demonstrates the robustness of our method.

Our method not only outperforms all the above comparative methods in quantitative evaluations, but also produces visually pleasing results among them. Figure 4 compares the predicted trajectories of NMMP, ground-truth (GT) and our methods on NBA dataset. It is obvious that our method produces more precise predictions than state-of-the art method NMMP. This is because our proposed spatial-temporal logic rules can actually captures the spatial relation of the players with surrounding players, as well as the temporal ordering constraints of the events.

### Generated Logic Rules

We add visualization and explanation about the logic rule and corresponding actions from NBA dataset in Figure 5. Note that the static spatial relation {Left(B,A)} represents that the player B is on the left of player A. And the dynamic spatial relation {Away(A,E)} means that player A is getting away from player E. We can see that these logic rules are meaningful and diverse. In this picture, player A is defended by two players and then passes the ball to player B. Player B goes front and crossover to bypass three defenders and shoot at the basket. Our rule can actually represent their offensive strategy. In fact, our framework can actually adapt to some complex motions, such as cutting toward the ball, because these spatial-temporal predicates are fed into the rule generator and evaluator to obtain high-quality rules to explain the intention of players.

Figure 5: Visualization and explanation of logic rules in NBA dataset.

## 6 Limitation

It's challenging to define some complex predicates with richer meanings for different datasets. Given a more informative dataset, our method can discover more principles-like complex rules. Our motivation is to consider the spatial-temporal relation between pedestrians and generate some high-quality logic rules to explain their behaviors. Although we only choose some simple actions in our experiments, they can bring some benefits for understanding the principles of biological agents' behaviors. Our framework is suitable for more complex conditions, supposing more sophisticated action predicates can be obtained from the data.

## 7 Conclusion

We proposed a framework for learning intrinsic spatial-temporal logic rules for explaining human actions. We regard logic rules as latent variables, and the rule generator as well as the rule evaluator are jointly learned with EM-based algorithm. In the experiments, our method can analyze the biological movement sequence of pedestrians and players, and obtained novel insights from generated logic rules. In the future, we plan to incorporate other physical laws into the models, such as conservation of energy and momentum to enhance robustness of our model.

## 8 Acknowledgement

Shuang Li's research was in part supported by the NSFC under grant No. 62206236, Shenzhen Science and Technology Program JCYJ20210324120011032, National Key R&D Program of China under grant No. 2022ZD0116004, and Guangdong Key Lab of Mathematical Foundations for Artificial Intelligence.

## References

* [1] David Adam. Science and the world cup: how big data is transforming football. _Nature_, 611(7936):444-446, 2022.
* [2] Claudine Badue, Ranik Guidolini, Raphael Vivacqua Carneiro, Pedro Azevedo, Vinicius B Cardoso, Avelino Forechi, Luan Jesus, Rodrigo Berriel, Thiago M Paixao, Filipe Mutz, et al. Self-driving cars: A survey. _Expert Systems with Applications_, 165:113816, 2021.
* [3] Ricky TQ Chen, Brandon Amos, and Maximilian Nickel. Neural spatio-temporal point processes. In _International Conference on Learning Representations_, 2021.
* [4] Chang Choi, Junho Choi, Eunji Lee, Ilsun You, and Pankoo Kim. Probabilistic spatio-temporal inference for motion event understanding. _Neurocomputing_, 122:24-32, 2013.
* [5] Sanjeeb Dash, Oktay Gunluk, and Dennis Wei. Boolean decision rules via column generation. _Advances in neural information processing systems_, 31, 2018.
* [6] Tianpei Gu, Guangyi Chen, Junlong Li, Chunze Lin, Yongming Rao, Jie Zhou, and Jiwen Lu. Stochastic trajectory prediction via motion indeterminacy diffusion. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 17113-17122, 2022.

\begin{table}
\begin{tabular}{l|c c c c c c c c} \hline \multirow{2}{*}{Methods} & \multicolumn{2}{c}{1.0} & \multicolumn{2}{c}{2.0} & \multicolumn{2}{c}{3.0} & \multicolumn{2}{c}{4.0} \\ \cline{2-9}  & ADE & FDE & ADE & FDE & ADE & FDE & ADE & FDE \\ \hline Y-Net & 0.51 & 0.62 & 0.81 & 1.11 & 1.08 & 1.49 & 1.37 & 1.86 \\ NSP-SFM & 0.48 & 0.63 & 0.82 & 1.13 & 1.06 & 1.46 & 1.36 & 1.82 \\ Ours & 0.31 & 0.48 & 0.67 & 0.91 & 0.93 & 1.39 & 1.18 & 1.66 \\ Ours* & 0.30 & 0.40 & 0.58 & 0.88 & 0.87 & 1.31 & 1.13 & 1.60 \\ \hline \end{tabular}
\end{table}
Table 3: Robustness of our method in NBA dataset in some noise.

* [7] Yue Hu, Siheng Chen, Ya Zhang, and Xiao Gu. Collaborative motion prediction via neural motion message passing. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_, pages 6319-6328, 2020.
* [8] Yingfan Huang, Huikun Bi, Zhaoxin Li, Tianlu Mao, and Zhaoqi Wang. Stgat: Modeling spatial-temporal interactions for human trajectory prediction. In _Proceedings of the IEEE/CVF international conference on computer vision_, pages 6272-6281, 2019.
* [9] Rainer Kartmann, You Zhou, Danqing Liu, Fabian Paus, and Tamim Asfour. Representing spatial object relations as parametric polar distribution for scene manipulation based on verbal commands. In _2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)_, pages 8373-8380. IEEE, 2020.
* [10] Shuang Li, Mingquan Feng, Lu Wang, Abdelmajid Essofi, Yufeng Cao, Junchi Yan, and Le Song. Explaining point processes by learning interpretable temporal logic rules. In _International Conference on Learning Representations_, 2021.
* [11] Shuang Li, Mingquan Feng, Lu Wang, Abdelmajid Essofi, Yufeng Cao, Junchi Yan, and Le Song. Explaining point processes by learning interpretable temporal logic rules. In _International Conference on Learning Representations_, 2022.
* [12] Shuang Li, Lu Wang, Ruizhi Zhang, Xiaofu Chang, Xuqin Liu, Yao Xie, Yuan Qi, and Le Song. Temporal logic point processes. pages 5990-6000, 2020.
* [13] Karttikeya Mangalam, Yang An, Harshayu Girase, and Jitendra Malik. From goals, waypoints & paths to long term human trajectory forecasting. In _Proceedings of the IEEE/CVF International Conference on Computer Vision_, pages 15233-15242, 2021.
* [14] Karttikeya Mangalam, Harshayu Girase, Shreyas Agarwal, Kuan-Hui Lee, Ehsan Adeli, Jitendra Malik, and Adrien Gaidon. It is not the journey but the destination: Endpoint conditioned trajectory prediction. In _Computer Vision-ECCV 2020: 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part II 16_, pages 759-776. Springer, 2020.
* [15] Andrew Miller, Luke Bornn, Ryan Adams, and Kirk Goldsberry. Factorized point process intensities: A spatial analysis of professional basketball. In _International conference on machine learning_, pages 235-243. PMLR, 2014.
* [16] Abduallah Mohamed, Deyao Zhu, Warren Vu, Mohamed Elhoseiny, and Christian Claudel. Social-implicit: Rethinking trajectory prediction evaluation and the effectiveness of implicit maximum likelihood estimation. In _European Conference on Computer Vision_, pages 463-479. Springer, 2022.
* [17] Filmer Stuart Cuckow Northrop. The logic of the sciences and the humanities. 1947.
* [18] Clayton Peterson. A logic for human actions. _Applications of Formal Philosophy: The Road Less Travelled_, pages 73-112, 2017.
* [19] Meng Qu, Junkun Chen, Louis-Pascal Xhonneux, Yoshua Bengio, and Jian Tang. Rnnlogic: Learning logic rules for reasoning on knowledge graphs. In _International Conference on Learning Representations_, 2021.
* [20] Alex Reinhart. A review of self-exciting spatio-temporal point processes and their applications. _Statistical Science_, 33(3):299-318, 2018.
* [21] Davis Rempe, Tolga Birdal, Yongheng Zhao, Zan Gojcic, Srinath Sridhar, and Leonidas J Guibas. Caspr: Learning canonical spatiotemporal point cloud representations. _Advances in neural information processing systems_, 33:13688-13701, 2020.
* [22] Ali Sadeghian, Mohammadreza Armandpour, Patrick Ding, and Daisy Zhe Wang. Drum: End-to-end differentiable rule mining on knowledge graphs. _Advances in Neural Information Processing Systems_, 32, 2019.

* [23] Bilong Shen, Xiaodan Liang, Yufeng Ouyang, Miaofeng Liu, Weimin Zheng, and Kathleen M Carley. Stepdeep: A novel spatial-temporal mobility event prediction framework based on deep neural network. In _Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining_, pages 724-733, 2018.
* [24] Li-Wu Tsao, Yan-Kai Wang, Hao-Siang Lin, Hong-Han Shuai, Lai-Kuan Wong, and Wen-Huang Cheng. Social-ssl: Self-supervised cross-sequence representation learning based on transformers for multi-agent trajectory prediction. In _Computer Vision-ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23-27, 2022, Proceedings, Part XXII_, pages 234-250. Springer, 2022.
* [25] Tong Wang, Cynthia Rudin, Finale Doshi-Velez, Yimin Liu, Erica Klampfl, and Perry MacNeille. A bayesian framework for learning rule sets for interpretable classification. _The Journal of Machine Learning Research_, 18(1):2357-2393, 2017.
* [26] Baowen Xu, Xuelei Wang, Shuo Li, Jingwei Li, and Chengbao Liu. Social-cvae: Pedestrian trajectory prediction using conditional variational auto-encoder. In _International Conference on Neural Information Processing_, pages 476-489. Springer, 2023.
* [27] Chenxin Xu, Maosen Li, Zhenyang Ni, Ya Zhang, and Siheng Chen. Groupnet: Multiscale hypergraph neural networks for trajectory prediction with relational reasoning. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 6498-6507, 2022.
* [28] Fan Yang, Zhilin Yang, and William W Cohen. Differentiable learning of logical rules for knowledge base reasoning. _Advances in neural information processing systems_, 30, 2017.
* [29] Cunjun Yu, Xiao Ma, Jiawei Ren, Haiyu Zhao, and Shuai Yi. Spatio-temporal graph transformer networks for pedestrian trajectory prediction. In _Computer Vision-ECCV 2020: 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part XII 16_, pages 507-523. Springer, 2020.
* [30] Jiangbei Yue, Dinesh Manocha, and He Wang. Human trajectory prediction via neural social physics. In _Computer Vision-ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23-27, 2022, Proceedings, Part XXXIV_, pages 376-394. Springer, 2022.
* [31] Zihao Zhou, Xingyi Yang, Ryan Rossi, Handong Zhao, and Rose Yu. Neural point process for learning spatiotemporal event dynamics. In _Learning for Dynamics and Control Conference_, pages 777-789. PMLR, 2022.