# An exactly solvable model for emergence and scaling laws in the multitask sparse parity problem

Yoonsoo Nam*

Rudolf Peierls Centre for Theoretical Physics, University of Oxford

Nayara Fonseca*

Rudolf Peierls Centre for Theoretical Physics, University of Oxford

Seok Hyeong Lee

Center for Quantum Structures in Modules and Spaces, Seoul National University

Chris Mingard

Rudolf Peierls Centre for Theoretical Physics, University of Oxford

Ard A. Louis

Rudolf Peierls Centre for Theoretical Physics, University of Oxford

###### Abstract

Deep learning models can exhibit what appears to be a sudden ability to solve a new problem as training time, training data, or model size increases, a phenomenon known as emergence. In this paper, we present a framework where each new ability (a skill) is represented as a basis function. We solve a simple multi-linear model in this skill-basis, finding analytic expressions for the emergence of new skills, as well as for scaling laws of the loss with training time, data size, model size, and optimal compute. We compare our detailed calculations to direct simulations of a two-layer neural network trained on multitask sparse parity, where the tasks in the dataset are distributed according to a power-law. Our simple model captures, using a single fit parameter, the sigmoidal emergence of multiple new skills as training time, data size or model size increases in the neural network.

## 1 Introduction

_Emergence_ in large language models (LLMs) has attracted a lot of recent attention [1, 2, 3, 4]. It motivates the costly drive to train ever larger models on ever larger datasets, in the hope that new skills will emerge. While the concept of emergence has been critiqued on the grounds that the sharpness of the transition to acquiring a new skill may be sensitive to the measure being used [5], the observation that important new skills are learned for larger models raises many challenging questions: when the skills emerge and what drives the emergence. These questions are complicated by difficulties in formally defining skills or capabilities [6], and by our general limited understanding of the internal representations of deep neural networks [7].

Another widely observed property of deep learning models is that the loss improves predictably as a power-law in the number of data points or the number of model parameters or simply in the amount of compute thrown at a problem. These neural scaling laws [8, 9] have been widely observed across different architectures and datasets [10, 11, 12, 13, 14, 15, 16]. While the scaling exponents can depend on these factors, the general phenomena of scaling appear to be remarkably robust. This raises many interesting questions such as: What causes the near-universal scaling behavior? How does the continuous scaling of the loss relate to the discontinuous emergence of new skills?

A challenge in answering the questions raised by the phenomena of emergence and scaling laws arises from the enormous scale and expense of training cutting-edge modern LLMs, which are optimized for commercial applications, and not for answering scientific questions about how they work. One way that progress can be made is to study simpler dataset/architecture combinations that are more tractable. The current paper is inspired in part by recent work in this direction that proposed studying emergence in learning the sparse parity problem [17, 18], which is easy to define, but known to becomputationally hard. In particular, Michaud et al. [18] introduce the multiple unique sparse parity problem - where tasks are distributed in the data through a power-law distribution of frequencies - as a proxy for studying emergence and neural scaling in LLMs. For this data set, the authors empirically measure the scaling laws of a 2-layer multilayer perceptron (MLP) as a function of training steps (\(T\)), parameters (\(N\)), and training samples (\(D\)). Based on their quanta model of abrupt skill acquisition, they schematically derive neural scaling laws as a sum of emergences of new skills. However, no link was established between the neural network dynamics and the quanta model.

In this paper, we introduce an analytically tractable model by defining a basis of orthogonal functions for the multitask sparse parity problem. Each basis function corresponds to a skill that can be learned, and their respective frequencies are distributed following a power-law with exponent \(\alpha+1\). We then propose a simple multilinear expansion in these orthogonal functions that introduces a layered structure reminiscent of neural networks (NNs) and gives rise to the stage-like training dynamics [19]. With our simple model, we can analytically calculate full scaling laws, including pre-factors, as a function of data exponents \(\alpha\), \(T,D,N\), and optimal compute \(C\). Our simple model can, with just one parameter calibrated to the emergence of the first skill, predict the ordered emergence of multiple skills in a 2-layer MLP. We summarize our contributions as follows:

1. _Skills as basis functions._ We establish a framework for investigating emergence by representing skills as orthogonal functions that form a basis in function space (Section 2). We apply our methods to controlled experiments on the multitask sparse parity dataset.
2. _Multilinear model._ We propose an analytically tractable model that is expanded in the basis of skill functions, and is multilinear with respect to its parameters so that it possesses a layerwise structure (Section 3). The multilinear nature of the model produces non-linear dynamics, and the orthogonal basis decouples the dynamics of each skill.
3. _Scaling laws._ We derive scaling laws for our multilinear model, including the prefactor constants, which relate the model's performance to training time (\(T\)), dataset size (\(D\)), number of parameters (\(N\)), and optimal compute (\(C=N\times T\)), see Section 4. We show that the scaling exponents for these factors are \(-\alpha/(\alpha+1)\), \(-\alpha/(\alpha+1)\), \(-\alpha\), \(-\alpha/(\alpha+2)\), respectively, where \(\alpha+1\) is the exponent of the power-law input data.
4. _Predicting emergence._ We demonstrate that our multilinear model captures the skill emergence of an MLP with 2 layers for varying training time, dataset size, and number of trainable parameters. Our results show that the multilinear model, calibrated only on the first skill, can predict the emergence of subsequent skills in the 2-layer MLP, see Fig. 1 and Section 5. We obtain an equivalent result on the time emergence for a transformer architecture (Fig. 4).

Figure 1: **Predicting emergence.** The skill strength \(\mathcal{R}_{k}\), defined as the \(k^{th}\) coefficient if a model is expanded in the basis of the skill functions (\(g_{k}\)), measures how well the \(k^{\text{th}}\) skill is learned, and is plotted against (a) time \(T\), (b) data set size \(D\), and (c) number of parameters \(N\) (width of the hidden layer). \(\mathcal{R}_{k}\) is normalized by the target scale \(S\) such that \(\mathcal{R}_{k}/S=1\) means zero skill loss. The dashed lines show the abrupt growth – emergence – of \(5\) skills for a 2-layer MLP (Appendix K) trained on the multitask sparse parity problem with data power-law exponent \(\alpha=0.6\) (shaded area indicate 1-standard deviation over at least \(10\) runs). Solid lines are the predictions (Eqs. (14), (17) and (21), respectively) from our multilinear model calibrated on the first skill (blue) only.

## 2 Setup

In this section, we define the multitask sparse parity problem under the mean-squared error (MSE) loss. We represent skills as orthogonal functions and measure their strength in a model by calculating the linear correlation between the model output and the skill basis functions. For a comprehensive list of notations, refer to the **glossary** in Appendix A. Our code is also available online.1

Footnote 1: https://github.com/yoonsoonam119/Skill_Eigenmode.git

Multitask sparse parity problem.In the sparse parity problem, \(n_{b}\) skill bits are presented to the model. The target function is a parity function applied to a fixed subset of the input bits. The model must detect the relevant \(m<n_{b}\) sparse bits and return the parity function on this subset (\(M(i,x)\), see Table 1). Michaud et al. [18] introduced the **multitask** sparse parity problem by introducing \(n_{*}\) unique sparse parity variants - or skills - with different sparse bits (for a representation, see Table 1). Each skill is represented in the \(n_{s}\) control bits as a one-hot string, and the model must solve the specific sparse parity task indicated by the control bits (for more details, see Appendix B.1).

The \(n_{s}\) skills (random variable \(I\in\{1,2,\ldots,n_{s}\}\)) follow a power law distribution \(\mathcal{P}_{s}\), and the skill bits (random variable \(X\in\{0,1\}^{n_{b}}\)) are uniformly distributed. Because \(\mathcal{P}_{s}\) and \(\mathcal{P}_{b}\) are independent, the input distribution \(\mathcal{P}(I,X)\) follows a product of two distributions:

\[\mathcal{P}_{s}(I=i):=\frac{i^{-(\alpha+1)}}{\sum_{j}^{n_{s}}j^{-(\alpha+1)}}, \qquad\mathcal{P}_{b}(X=x):=2^{-n_{b}},\qquad\mathcal{P}(I,X):=\mathcal{P}_{s }(I)\mathcal{P}_{b}(X).\] (1)

We denote \(A=\left(\sum_{j=1}^{n_{s}}j^{-(\alpha+1)}\right)^{-1}\) so that \(\mathcal{P}_{s}(i):=Ai^{-(\alpha+1)}\).

Skill basis functions.We represent the \(k^{th}\) skill as a function \(g_{k}:\{0,1\}^{n_{s}+n_{b}}\rightarrow\{-1,0,1\}\) that returns the parity (\(\{-1,1\}\)) on the \(k^{th}\) skill's sparse bits if \(i=k\), but returns \(0\) if the control bit mismatches that of the \(k^{th}\) skill (\(i\neq k\)):

\[g_{k}(i,x):=\left\{\begin{matrix}(-1)^{\sum_{j}M_{j}(i,x)}&\text{ if }i=k\\ 0&\text{ otherwise }\end{matrix}\right.,\] (2)

where \(M:\{0,1\}^{n_{s}+n_{b}}\rightarrow\{0,1\}^{m}\) is the map that selects the relevant sparse bits for the \(i^{th}\) skill (Table 1) and \(M_{j}(i,x)\) is the \(j^{\text{th}}\) entry of \(M(i,x)\). Note that different skill functions have \(0\) correlation as the supports of skills functions are **mutually exclusive**:

\[g_{k}(i,x)g_{k^{\prime}}(i,x)=\delta_{i,k}\delta_{k,k^{\prime}}.\] (3)

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \hline Skill idx \((I)\) & Control bits & Skill bits \((X)\) & \(y\) & \(M(i,x)\) & \(g_{1}(i,x)\) & \(g_{2}(i,x)\) & \(\ldots\) & \(g_{n_{s}}(i,x)\) \\ \hline
1 & 1000000 & 11011000100 & \(S\) & [1,1,0] & 1 & 0 & \(\ldots\) & 0 \\
1 & 100000 & 100101010001 & \(-S\) & [0,1,0] & \(-1\) & 0 & \(\ldots\) & 0 \\ \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) \\
2 & 0100000 & 00100101101 & \(-S\) & [0,0,1] & 0 & \(-1\) & \(\ldots\) & 0 \\ \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) & \(\vdots\) \\ \(n_{s}\) & 0000001 & 0010100110 & \(-S\) & [1,1,1] & 0 & 0 & \(\ldots\) & \(-1\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: **Multitask sparse parity dataset and skill basis functions.** The control bits are \(n_{s}\)-dimensional one-hot vectors encoding specific parity tasks, indexed in the first column. The frequency of the distinct parity tasks follows a rank-frequency distribution with an inverse power law relation (Eq. (1)). The skill bits are binary strings with \(m=3\) relevant sparse bits (highlighted in colors) with their locations varying by skill. The \(y\) column shows the target scale \(S\) multiplied by the parity computed from the relevant bit set \(M(i,x)\). The last columns show the values of the skill basis functions \(g_{k}(i,x)\), defined in Eq. (2).

The target function.The target function is a sum over \(n_{s}\) skill functions multiplied by a target scale \(S\):

\[f^{*}(i,x):=S\sum_{k=1}^{n_{s}}g_{k}(i,x).\] (4)

The target scale \(S\) is the norm of the target function (\(\mathbf{E}_{I,X}\left[f^{*}(I,X)f^{*}(I,X)\right]=S^{2}\)). Note that the skill functions serve as 'features' or countable basis for describing the target function as in Hutter [20].

MSE loss.We use MSE loss for analytic tractability:

\[\mathcal{L}:=\frac{1}{2}\mathbf{E}_{X,I}\left[\left(f^{*}(I,X)-f(I,X)\right)^{ 2}\right],\] (5)

where \(f\) is the function expressed by a given model. We define the skill loss \(\mathcal{L}_{k}\) as the loss when only the \(k^{th}\) skill is given, which can be weighted by their skill frequencies to express the total loss:

\[\mathcal{L}_{k}:=\frac{1}{2}\mathbf{E}_{X}\left[\left(f^{*}(I=k,X)-f(I=k,X) \right)^{2}\right],\qquad\mathcal{L}=\sum_{k=1}^{n_{s}}\mathcal{P}_{s}(I=k) \mathcal{L}_{k}.\] (6)

Skill strength.The skill strength or the linear correlation between the \(k^{th}\) skill (\(g_{k}\)) and a function expressed by the model at time \(T\) (\(f_{T}\)) is

\[\mathcal{R}_{k}(T):=\mathbf{E}_{X}\left[g_{k}(I=k,X)f_{T}(I=k,X)\right].\] (7)

The skill strength \(\mathcal{R}_{k}\) is the \(k^{th}\) coefficient if a model is expanded in the basis of the skill functions (\(g_{k}\)). The skill strength, like the test loss, can be accurately approximated by a sum (see Appendix K.3). The skill loss \(\mathcal{L}_{k}\) (Eq. (6)) can be expressed by the skill strength and the norm of the learned function for \(I=k\):

\[\mathcal{L}_{k}(T)=\frac{1}{2}\left(S^{2}+\mathbf{E}_{X}\left[f_{T}(I=k,X)^{2 }\right]-2S\mathcal{R}_{k}(f_{T})\right).\] (8)

The skill loss becomes \(0\) if and only if \(f_{T}(I=k,X)=Sg_{k}(I=k,X)\).

Experimental setting.We use a 2-layer MLP that receives the \(n_{s}+n_{b}\) bits as inputs and outputs a scalar (\(\{0,1\}^{n_{s}+n_{b}}\rightarrow\mathbb{R}\)). In most of the experiments, the NN is trained with stochastic gradient descent (SGD) with width \(1000\), using \(n_{s}=5\), \(m=3\), and \(n_{b}=32\), unless otherwise stated. A decoder transformer is also used for the time emergent experiments. See Appendix K for details.

## 3 Multilinear model

We propose a simple multilinear model - multilinear with respect to the parameters - with the first \(N\) most frequent skill functions \(g_{k}(i,x)\) as the basis functions (features):

\[f_{T}(i,x;a,b)=\sum_{k=1}^{N}a_{k}(T)b_{k}(T)g_{k}(i,x),\] (9)

where \(a,b\in\mathbb{R}^{N}\) are the parameters. The model has built-in skill functions \(g_{k}\) - which transform control bits and skill bits into the parity outputs of each skill - so the model only needs to scale the parameters to \(a_{k}b_{k}=S\).

The multilinear structure (product of \(a_{k},b_{k}\)) is analogous to the layered structure of NNs and results in emergent dynamics (Fig. 1(a)) different from a linear model with the same basis functions (Appendix H). A similar model has been studied by Saxe et al. [19] in the context of linear neural networks (Appendix B.2).

For the multilinear model, note that \(a_{k}(T)b_{k}(T)\) is the skill strength \(\mathcal{R}_{k}\) (Eq. (7)) and the skill loss (Eq. (6)) is a function of \(S\) and \(\mathcal{R}_{k}\) only:

\[a_{k}(T)b_{k}(T)=\mathcal{R}_{k}(T),\qquad\mathcal{L}_{k}(T)=\frac{1}{2}(S- \mathcal{R}_{k}(T))^{2}\,.\] (10)Assuming that we are training the model on \(D\) samples from \(\mathcal{P}(I,X)\), the empirical loss decomposes into a sum of empirical skill losses because \(g_{k}\)'s supports are mutually exclusive. This **decouples** the dynamics of each skill (\(\mathcal{R}_{k}(T)\)), which is analytically solvable under gradient flow (Appendix C.1).

\[\boxed{\mathcal{L}^{(D)}(T)=\frac{1}{2D}\sum_{k=1}^{n_{s}}d_{k}(S-\mathcal{R}_{ k}(T))^{2},\qquad\frac{\mathcal{R}_{k}(T)}{S}=\frac{1}{1+\left(\frac{S}{ \mathcal{R}_{k}(0)}-1\right)e^{-2\eta\frac{d_{k}}{D}ST}},}\] (11)

where \(d_{k}\) is the number of samples of the \(k^{th}\) skill (i.e., number of samples \((i,x)\) with \(g_{k}(i,x)\neq 0\)), \(\eta\) is the learning rate, and \(0<\mathcal{R}_{k}(0)<S\) is the skill strength at initialization.

## 4 Scaling laws

Recent literature has extensively explored scaling laws; see Section 7 for an overview. In this section, we derive the scaling laws of our multilinear model (Section 3) for time (\(T\)), data (\(D\)), parameters (\(N\)) and optimal compute (\(C\)). We define compute as \(C:=T\times N\)[21].

Table 2 shows our analytical scaling laws including their prefactor constants (Appendix J) and Fig. 2 compares the simulation of our model with our scaling law predictions. For the scaling law exponents, we achieve the same exponent as in Hutter [20] for \(D\) and in Michaud et al. [18] for \(T,D,\) and \(N\). Assuming \(0<\alpha<1\), the exponents are consistent with the small power-law exponents reported in large-scale experiments, see, e.g., [9; 14; 22].

Using Eqs. (6), (10) and (11), we derive the loss as a function of time (\(T\)), data (\(D\)), parameters (\(N\)), and the number of observations for each skill \([d_{1},\cdots,d_{n_{s}}]\):

\[\mathcal{L}=\frac{S^{2}}{2}\sum_{k=1}^{N}\mathcal{P}_{s}(k)\frac{1}{\left(1+ \left(\frac{S}{\mathcal{R}_{k}(0)}-1\right)^{-1}e^{2\eta\frac{d_{k}}{D}ST} \right)^{2}}+\frac{S^{2}}{2}\sum_{k=N+1}^{n_{s}}\mathcal{P}_{s}(k).\] (12)

Under suitable assumptions (e.g., for the \(T\) scaling law, we take \(D,N\rightarrow\infty\) and \(d_{k}/D\rightarrow\mathcal{P}_{s}(k)\)), we can use Eq. (12) to derive the scaling laws. For \(T,D\), and \(N\), we used Eq. (11) - decoupled dynamics induced the basis functions \(g_{k}\) - to decouple the evolution of each skill loss:

1. For the time scaling law, each \(\mathcal{L}_{k}\) shares the same dynamics with \(T\) scaled by \(\mathcal{P}_{s}(k)\).
2. For the data scaling law, each \(\mathcal{L}_{k}\) depends only on the observation the \(k^{th}\) skill (\(d_{k}>0\)).
3. For the parameter scaling law, each \(\mathcal{L}_{k}\) depends on whether the model has \(g_{k}\) as a basis function.

For the optimal compute scaling law, we show in Corollary 4 (Appendix J) that the optimal tradeoff between \(T\) and \(N\) for given \(C\) is when \(T\) is large enough to fit the \(N^{th}\) skill (Fig. 3). In Appendix J, we show **rigorous** derivations of all scaling laws, including the prefactors, error bounds, and conditions (e.g., how large \(N\) must be compared to \(T\) to be treated as infinity). For simplified derivations for the exponents only, see Appendix E. For an intuitive derivation (stage-like training) and connection to Michaud et al. [18], see Appendix D.

## 5 Predicting emergence

The literature on emergence has rapidly expanded lately; for a review of these developments, see Section 7. In this section, we analyze the emergence of a 2-layer NN (Section 2) and discuss to what degree the emergence in NNs can be described with our model. At initialization, NNs **lack** the information about the data and must 'discover' each \(g_{k}\). To take this effect into account in our model, we add an extra parameter which we calibrate (fit) on an NN trained on one skill (\(n_{s}=1\)) system and use it to predict the emergence of subsequent skills for the \(n_{s}=5\) setup (Fig. 1).

### Time emergence

In our multilinear model, the layerwise structure - the product of parameters \(a_{k}b_{k}\) - leads to a sigmoidal saturation where an update of one layer hastens the update of the other layer. Feature

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline Bottleneck & Condition 1 & Condition 2 & Exponent & Prefactor & Scaling law \\ \hline Time (\(T\)) & \(D\gg NT^{2},T^{3}\) & \(N^{\alpha+1}\gg T\) & \(-\alpha/(\alpha+1)\) & Thm.4 & Thms.2,3 \\ Data (\(D\)) & \(T\gg D(\log D)^{1+\epsilon}\) & \(N^{\alpha+1}\gg D\) & \(-\alpha/(\alpha+1)\) & Thm.5 & Thm.5 \\ Parameter (\(N\)) & \(D\gg T^{3}\) & \(N^{\alpha+1}=o(T)\) & \(-\alpha\) & Thm.1 & Thm.1 \\ Compute (\(C\)) & \(D\gg T^{3}\) & \(N^{\alpha+1}\approx T\) & \(-\alpha/(\alpha+2)\) & Cor. 5 & Cor. 4 \\ \hline \hline \end{tabular}
\end{table}
Table 2: **Summary of the scaling laws for the multilinear model.** The leftmost column indicates the bottleneck resource while the next two columns are the conditions for the ‘large resources’ – large enough to be treated as infinity. The fourth column is the bottleneck resource’s scaling law exponent for the loss. The last two columns show the statement for the prefactor constant and the scaling law (with the assumptions and explicit error terms) in Appendix J.

Figure 3: **Scaling law for optimal compute.** The solid lines are the learning curves of the multilinear model as a function of compute \(C=T\times N\) with varying parameters \(N\) from \(10^{1}\) (top plateau) to \(10^{4}\) (bottom plateau). The dotted lines are optimal compute scaling laws with exponent \(-\alpha/(\alpha+2)\) (Appendix E.4) and calculated prefactor constants (Appendix J). See Appendix K.4 for details of the experiment. For a given \(C\), we achieve the optimal tradeoff when \(T\) is large enough to fit all \(N\) skills (i.e. when the solid lines plateau). For the case \(\alpha=0.3\), the optimal \(C\) for the model decays faster than the power-law, see Appendix E.1.

Figure 2: **Scaling laws.** The learning curve (\(\mathcal{L}\) is the MSE loss) of the multilinear model (solid) and the theoretical power-law (dotted) for (a) time \(T\), (b) data \(D\), and (c) parameters \(N\). Lower left legends show the condition (top) and the scaling law (bottom) where \(\alpha+1\) is the exponent of the power-law input data (Eq. (1)). See the appendices for 1) rigorous derivations of the theoretical scaling laws including the exponents, prefactors (e.g., \(\mathcal{A}_{N}\) for \(\mathcal{L}=\mathcal{A}_{N}N^{-\alpha}\)), and conditions (Appendix J); 2) simplified derivations of the exponent only (Appendix E); 3) details of the experiment (Appendix K.4).

learning dynamics in a 2-layer MLP shares the positive feedback between the layers but require a non-trivial update of parameters to express \(g_{k}\).

Extended model.Given that feature learning, though nonlinear, involves parameter updates, we compensate for the additional delay in feature-learning by multiplying \(g_{k}\) by a calibration constant \(0<\mathcal{B}<1\):

\[f_{T}(i,x;a,b)=\sum_{k=1}^{N}a_{k}(T)b_{k}(T)\mathcal{B}g_{k}(i,x),\qquad 0< \mathcal{B}<1.\] (13)

The calibration constant \(\mathcal{B}\) rescales the dynamics in \(T\) (Eq. (11)):

\[\frac{\mathcal{R}_{k}(T)}{S}=\frac{1}{1+\left(\frac{S}{\mathcal{R}_{k}(0)}-1 \right)e^{-2\eta\mathcal{P}_{s}(k)\mathcal{B}^{2}ST}},\] (14)

where \(d_{k}/D\to\mathcal{P}_{s}(k)\) because we assume \(D\to\infty\). We observe that \(\mathcal{B}^{2}=1/22\) fits the NN trained on one skill (see Fig. 11 in Appendix I), and the calibrated model predicts emergence in the \(n_{s}=5\) system (Fig. 1(a)): suggesting that the dynamics of feature-learning \(g_{k}\) in 2-layers NNs is similar to that of parameter learning (\(a_{k}b_{k}\)) in a simple multilinear model. For further intuition of the extended model, see an example of time emergence in an NN in Appendix G.

### Data point emergence

Our multilinear model can learn the \(k^{th}\) skill with a single observation of the skill because the skill functions \(g_{k}\) are built in (see Corollary 1 in Appendix C.2). NNs, without the fixed basis functions, must 'discover' each \(g_{k}\), which requires multiple samples from the \(k^{th}\) skill.

Extended model.To make our model a \(D_{c}\)-shot learner, we extend it by replacing \(g_{k}\) with the \(e_{k,l}\) basis:

\[f_{T}(i,x;a,B)=\sum_{k=1}^{N}a_{k}(T)\sum_{l=1}^{D_{c}}B_{k,l}(T)e_{k,l}(i,x),\] (15)

where the matrix \(B\in\mathbb{R}^{N\times D_{c}}\) is an extension of \(b\in\mathbb{R}^{N}\) in Eq. (9), \(D_{c}\) is a fixed scalar, and \(e_{k,l}(i,x):\{0,1\}^{n_{s}+n_{b}}\to\mathbb{R}\) are functions with the following properties:

\[\mathbf{E}_{X|I=k}\left[e_{k,l}e_{k,l^{\prime}}\right]=\delta_{ll^{\prime}}, \hskip 14.226378pte_{k,l}(I\neq k,x)=0,\quad\sum_{l=1}^{D_{c}}\frac{1}{\sqrt{D _{c}}}e_{k,l}=g_{k}.\] (16)

The first property states that \(e_{k}\)'s, when \(I=k\), are orthonormal in \(X\). The second property asserts that, similar to \(g_{k}\) (Eq. (2)), \(e_{k,l}\) is non-zero only when \(I=k\), and fitting of the \(k^{th}\) skill only occurs among \(e_{k,l}\)'s, keeping the skills _decoupled_. The third property states that \(g_{k}\) can be expressed using \(e_{k,l}\).

For the \(k^{th}\) skill, the extended model overfits \(g_{k}\) when there are fewer observations (\(d_{k}\)) than the dimension of the \(e_{k,l}\) basis (\(D_{c}\)), and fits \(g_{k}\) when \(d_{k}\geq D_{c}\), making our model a \(D_{c}\) shot learner.

\(D_{c}\) shot learner._If we initialize the extended model in Eq. (15) with sufficiently small initialization and if the conditions in Eq. (16) are satisfied, then the skill strength after training (\(T\to\infty\)) on \(D\) datapoints is_

\[\mathcal{R}_{k}(\infty)=\begin{cases}S\left(1-\sqrt{1-d_{k}/D_{c}}\right)&:d _{k}<D_{c}\\ S&:d_{k}\geq D_{c}.\end{cases}\] (17)

_The number \(d_{k}\) is the number of samples in the training set for the \(k^{th}\) skill (i.e., datapoints with \(g_{k}(i,x)\neq 0\))._

* See Appendix F.3. \(\blacksquare\)

Using Eq. (17), we can calculate the emergence of \(\mathcal{R}_{k}/S\) as a function of \(D\). Note that Eq. (17) is similar to the model in Michaud et al. [18] in that, to learn a skill, the model requires a certain number of samples from the skill.

The derivation of Eq. (17) follows trivially from the dynamics of the extended model (Eq. (15)) and well-known results in linear/kernel regression [23; 24; 25; 26; 27]. To be more specific, the model finds the minimum norm solution as if we performed ridgeless regression on \(g_{k}\) with basis functions \([e_{k,1},\cdots e_{k,D_{c}}]\). See Appendix F.3 for details.

We observe that \(D_{c}=800\) approximates the data emergence for the \(n_{s}=1\) system (see Fig. 11 in Appendix I) and also the emergence for \(n_{s}=5\) system (Fig. 1(b)), suggesting that the NN discovers \(g_{k}\) when it observes \(D_{c}\) samples from the \(k^{th}\) skill.

### Parameter emergence

Since our multilinear model has \(g_{k}\)'s as the basis functions, it requires only one basis function (\(2\) parameters) to express a skill (see Corollary 2 in Appendix C.3). A 2-layer NN cannot express a skill with a single hidden node (i.e., a hidden layer with width \(1\)); it requires multiple hidden nodes to express a single skill.

Extended model.To compensate for the need for multiple hidden nodes in expressing one skill, we extend our model similarly to Eq. (15). Because the number of parameters is now a bottleneck, we ensure the model has \(N\) basis functions (\(e_{k,l}\)'s):

\[f_{T}(i,x;a,B)=\sum_{k=1}^{q-1}\sum_{l=1}^{N_{c}}a_{k}(T)B_{k,l}(T)e_{k,l}(i,x )+\sum_{l^{\prime}=1}^{r}a_{q}(T)B_{q,l^{\prime}}(T)e_{q,l^{\prime}}(i,x),\] (18)

where \(N_{c}\) is the number of basis functions needed to express a skill, quotient \(q\) is \(\lfloor(N-1)/N_{c}\rfloor+1\) and remainder \(r\) is such that \((q-1)N_{c}+r=N\). In short, the \(N\) basis functions are

\[[e_{1,1},\cdots,e_{1,N_{c}},\quad e_{2,1},\cdots,e_{2,N_{c}}\quad\cdots\quad e _{q,1},\cdots,e_{q,r}].\] (19)

Similar to Eq. (16), the basis functions satisfy the following properties

\[\mathbf{E}_{X|I=k}\,[e_{k,l}e_{k,l^{\prime}}]=\delta_{ll^{\prime}},\quad\ e_{k,l}(I \neq k,x)=0,\quad\sum_{l=1}^{N_{c}}\frac{1}{\sqrt{N_{c}}}e_{k,l}=g_{k}.\] (20)

\(N_{c}\) basis functions for a skill._For the extended model in Eq. (18), the skill strength at \(T,D\to\infty\) for a given \(N\) becomes_

\[\mathcal{R}_{k}(\infty)=\begin{cases}0&:k>q\\ S\frac{r}{N_{c}}&:k=q\\ S&:k<q\,.\end{cases}\] (21)

See Appendix F.4.

The model can express the \(k^{\rm th}\) skill based on the number of available basis functions for the given skill (Eq. (21)). For example, skills with \(k<q\) have all \(N_{c}\) basis functions \([e_{k,1},\cdots,e_{k,N_{c}}]\) to express the \(k^{\rm th}\) skill (Eq. (20)), while for \(k=q\), only \(r\) of the \(N_{c}\) basis functions are available.

We observe that \(N_{c}=4\) fits the parameter emergence for the \(n_{s}=1\) system (see Fig. 11 in Appendix I) and also the emergence for the \(n_{s}=5\) system (Fig. 1(c)), suggesting that the NN requires \(4\) nodes in expressing \(g_{k}\). The results also suggest that an NN, while lacking the ordering of basis functions (Eq. (19)), prefers to use the hidden neuron in fitting more frequent skills. The 'preference' toward frequent skills agrees with Fig. 1(a) where the NN learns more frequent skills first. Note that for the parameter emergence experiment, Adam [28] was used, instead of SGD, to increase the chance of escaping the near-flat saddle points induced by an insufficient number of parameters.

### Time emergence in a transformer

To test whether our conceptual framework extends to other architectures, we perform a time emergence experiment with a transformer (Fig. 4). Note that the emergent time \(\tau_{emerge}\) - when the skill strength is sufficiently larger than \(0\) - follows the same power-law relationship as Eq. (11): \(\tau_{emerge}(k)\propto k^{\alpha+1}\) (see Fig. 6 in Appendix D for a discussion on emergent time). This suggests that, in the multitask sparse parity setup, other architectures may follow similar decoupled dynamics (Eq. (11)) and the consequent scaling laws (Section 4) and emergence (Section 5). An in-depth study of these findings across different architectures is left for future work.

### Limitations of the multilinear model

The strength of our extended multilinear model comes from the decoupled dynamics for each skill: leading to the prediction of the time, data, and parameter emergence with a single calibration. The weakness of our model is that it simplifies the more complex dynamics of NNs.

Time emergence.We note that the NN and the multilinear model emerge at similar instances, but the NN takes longer to saturate fully. This is because, for a given skill, the dynamics of the NN is not one sigmoidal saturation but a sum of **multiple** sigmoidal dynamics with different saturation times. To express the parity function, the NN must use multiple hidden neurons, and the skill strength can be divided into the skill strength from each neuron whose dynamics follow a sigmoidal saturation. Because of the non-linearity and the function it expresses, each neuron is updated at different rates, and the slowly saturating neurons result in a longer tail compared to our multilinear model. For an example, see Fig. 8 in Appendix G.

Data point emergence.Our extended model (Eq. (17)) deviates from NNs when \(d_{k}\ll D_{c}\) and NNs show a more abrupt change in \(\mathcal{R}_{k}\) as a function of \(D\). This is because our model asserts strict decoupling among the skills: even a few \(d_{k}\) will contribute to learning \(g_{k}\) from \(e_{k,l}\). This differs from the NN, which lacks strict decoupling among the samples from different skills. We speculate that because NNs can perform benign [29] or tempered [30] overfitting, they treat a few data points from less frequent skills as 'noise' from more frequent skills: requiring more samples to learn the infrequent skills.

Parameter emergence.Note that Fig. 1(c) has high variance compared to other emergence plots in Fig. 1; this is because the NN sparsely, over many repeated trials, uses the hidden neurons to learn less frequent skills over more frequent ones (see Table 5 in Appendix I for an example of such outliers). Because NNs are less strictly biased toward frequent skills than our model, we speculate that initial conditions favoring less frequent skills may contribute to the outliers.

## 6 Discussion and conclusion

This work demonstrated scaling laws and predicted emergence in a 2-layer MLP using a tractable multilinear model. We found that representing skills as mutually exclusive functions leads to the decoupled dynamics, resulting in the scaling laws observed in a 2-layer MLP. The layerwise structure leads to emergent (sigmoidal) saturation of the skill strength, similar to what is observed in 2-layer MLPs.

Despite lacking explicit skill functions, NNs exhibit similar emergence patterns. We speculate that the model's layerwise structure and power-law frequencies of the skills induce **stage-like** dynamics

Figure 4: **Transformer on multitask sparse parity task. We trained a transformer on the multitask sparse parity task with \(\alpha=0.9\); see Appendix K for details. Left: An example of the time emergence (measured in steps) for the transformer in the \(n_{s}=5\) setup. See Appendix I for enlarged plots showing the saturation of each skill in linear scale. Right: The \(k^{th}\) skill’s emergent time \(\tau_{emerge}(k)\) (i.e. \(\mathcal{R}_{k}(\tau_{emerge}(k))/S=0.05\)) as a function of \(k\) (error bars indicate 1-standard deviation over \(5\) runs). The emergent times follow a power law of \(k^{\alpha+1}\), following the same relationship in the multilinear model (Eq. (11)).**(Appendix D) in NNs. The parameters relevant for expressing more frequent skills are updated significantly faster than those for less frequent skills. When skill 'discovery' operates on different time scales with minimal interaction, the skill dynamics effectively become **decoupled**, justifying our model setup.

Our results suggest a link between feature learning and emergence [6] driven by decoupled, stage-like dynamics. The layerwise dynamics leading to sigmoidal saturation may also disentangle the problem into skills (features) of varying importance (frequencies). Then feature learning, or discovering the basis functions that describe the target function [31; 32] (for recent studies, see [33; 34; 35; 36; 37; 38]), likely occurs in stages. Investigating this connection through layerwise dynamics is left for future work.

Similar to many prior works (see, e.g., [20; 18]), we studied a simple model on an idealized power-law distributed dataset. Also, our model cannot capture the complex non-linear interactions among multiple skills but can express any linear superposition of skills. In future work, we will explore 'complex skills' in language as a superposition of linearly independent skills. By validating our findings in language tasks, we aim to contribute to a broader understanding of how neural networks acquire and exhibit complex behaviors.

## 7 Related works

In this section, we review the literature on scaling laws and emergence in NNs. Focusing on data scaling, Hutter [20] develops a model with a discrete set of features. Under the assumption of a power-law distribution of features, this model demonstrates that the error decreases as a power law with increasing data size. In a related vein, Michaud et al. [18] propose a model of neural scaling laws in which the loss is decomposed into a sum over 'quanta'. Their model aims to reconcile the apparent discrepancy between loss metrics' regular power-law scaling and the abrupt development of novel capabilities in large-scale models. Various other models for neural scaling laws have been proposed in recent research, including connecting neural scaling exponents to the data manifold's dimension [39] and their relation with kernels [40], proposing solvable random-feature models [41; 21], and developing data scaling models using kernel methods [42; 43; 25].

Closely related to the study of neural scaling laws is the understanding of emergent abilities in large language models. Several studies [1; 2; 3; 4] document examples of such emergent abilities. Arora and Goyal [44] propose a framework for the emergence of tuples of skills in language models, in which the task of predicting text requires combining different skills from an underlying set of language abilities. Okawa et al. [45] demonstrate that a capability composed of smoothly scaling skills will exhibit emergent scaling due to the multiplicative effect of the underlying skills' performance. Other works related to the skill acquisition include Yu et al. [46], who introduce a new evaluation to measure the ability to combine skills and develop a methodology for grading such evaluations, and Chen et al. [47], who formalize the notion of skills and their natural acquisition order in language models.

## Acknowledgements

NF acknowledges the UKRI support through the Horizon Europe guarantee Marie Sklodowska-Curie grant (EP/X036820/1). SL was supported by the National Research Foundation of Korea (NRF) grant funded by the Korean government (MSIT) (No.2020R1A5A1016126). We thank Charles London, Eric Michaud, Zohar Ringel, and Shuofeng Zhang for their helpful comments.

## References

* [1] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. _Advances in neural information processing systems_, 33:1877-1901, 2020.
* [2] Deep Ganguli, Danny Hernandez, Liane Lovitt, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Nova Dassarma, Dawn Drain, Nelson Elhage, et al. Predictability and surprise in large generative models. In _Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency_, pages 1747-1764, 2022.
* [3] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adria Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. _arXiv preprint:2206.04615_, 2022.
* [4] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. _arXiv preprint: 2206.07682_, 2022.
* [5] Rylan Schaeffer, Brando Miranda, and Sanmi Koyejo. Are emergent abilities of large language models a mirage? _Advances in Neural Information Processing Systems_, 36, 2023.
* [6] Usman Anwar, Abulhair Saparov, Javier Rando, Daniel Paleka, Miles Turpin, Peter Hase, Ekdeep Singh Lubana, Erik Jenner, Stephen Casper, Oliver Sourbut, Benjamin L. Edelman, Zhaowei Zhang, Mario Gunther, Anton Korinek, Jose Hernandez-Orallo, Lewis Hammond, Eric Bigelow, Alexander Pan, Lauro Langosco, Tomasz Korbak, Heidi Zhang, Ruiqi Zhong, Sean O hEigeartaigh, Gabriel Recchia, Giulio Corsi, Alan Chan, Markus Anderljung, Lilian Edwards, Yoshua Bengio, Danqi Chen, Samuel Albanie, Tegan Maharaj, Jakob Foerster, Florian Tramer, He He, Atoosa Kasirzadeh, Yejin Choi, and David Krueger. Foundational challenges in assuring alignment and safety of large language models. _arXiv preprint: 2404.09932_, 2024.
* [7] Trenton Bricken, Adly Templeton, Joshua Batson, Brian Chen, Adam Jermyn, Tom Conerly, Nick Turner, Cem Anil, Carson Denison, Amanda Askell, Robert Lasenby, Yifan Wu, Shauna Kravec, Nicholas Schiefer, Tim Maxwell, Nicholas Joseph, Zac Hatfield-Dodds, Alex Tamkin, Karina Nguyen, Brayden McLean, Josiah E Burke, Tristan Hume, Shan Carter, Tom Henighan, and Christopher Olah. Towards monosemanticity: Decomposing language models with dictionary learning. _Transformer Circuits Thread_, 2023. https://transformercircuits.pub/2023/monosemantic-features/index.html.
* [8] Joel Hestness, Sharan Narang, Newsha Ardalani, Gregory Diamos, Heewoo Jun, Hassan Kianinejad, Md Mostofa Ali Patwary, Yang Yang, and Yanqi Zhou. Deep learning scaling is predictable, empirically. _arXiv preprint:1712.00409_, 2017.
* [9] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. _arXiv preprint:2001.08361_, 2020.
* [10] Jonathan S Rosenfeld, Amir Rosenfeld, Yonatan Belinkov, and Nir Shavit. A constructive prediction of the generalization error across scales. _arXiv preprint: 1909.12673_, 2019.
* [11] Tom Henighan, Jared Kaplan, Mor Katz, Mark Chen, Christopher Hesse, Jacob Jackson, Heewoo Jun, Tom B Brown, Prafulla Dhariwal, Scott Gray, et al. Scaling laws for autoregressive generative modeling. _arXiv preprint:2010.14701_, 2020.

* Gordon et al. [2021] Mitchell A Gordon, Kevin Duh, and Jared Kaplan. Data and parameter scaling laws for neural machine translation. In Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih, editors, _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_, pages 5915-5922, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics.
* Zhai et al. [2022] Xiaohua Zhai, Alexander Kolesnikov, Neil Houlsby, and Lucas Beyer. Scaling vision transformers. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 12104-12113, 2022.
* Hoffmann et al. [2022] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal large language models. _arXiv preprint:2203.15556_, 2022.
* Cabannes et al. [2023] Vivien Cabannes, Elvis Dohmatob, and Alberto Bietti. Scaling laws for associative memories. _arXiv preprint arXiv:2310.02984_, 2023.
* Bachmann et al. [2024] Gregor Bachmann, Sotiris Anagnostidis, and Thomas Hofmann. Scaling mlps: A tale of inductive bias. _Advances in Neural Information Processing Systems_, 36, 2024.
* Barak et al. [2022] Boaz Barak, Benjamin Edelman, Surbhi Goel, Sham Kakade, Eran Malach, and Cyril Zhang. Hidden progress in deep learning: Sgd learns parities near the computational limit. _Advances in Neural Information Processing Systems_, 35:21750-21764, 2022.
* Michaud et al. [2023] Eric Michaud, Ziming Liu, Uzay Girit, and Max Tegmark. The quantization model of neural scaling. _Advances in Neural Information Processing Systems_, 36, 2023.
* Saxe et al. [2014] Andrew M Saxe, James L McClelland, and Surya Ganguli. Exact solutions to the nonlinear dynamics of learning in deep linear neural networks. _Proceedings of the International Conference on Learning Representations 2014_, 2014. arXiv:1312.6120.
* Hutter [2021] Marcus Hutter. Learning curve theory. _arXiv preprint:2102.04074_, 2021.
* Bordelon et al. [2024] Blake Bordelon, Alexander Atanasov, and Cengiz Pehlevan. A dynamical model of neural scaling laws. _arXiv preprint:2402.01092_, 2024.
* Besiroglu et al. [2024] Tamay Besiroglu, Ege Erdil, Matthew Barnett, and Josh You. Chinchilla scaling: A replication attempt. _arXiv preprint:2404.10102_, 2024.
* Canatar et al. [2021] Abdulkadir Canatar, Blake Bordelon, and Cengiz Pehlevan. Spectral bias and task-model alignment explain generalization in kernel regression and infinitely wide neural networks. _Nature communications_, 12(1):2914, 2021.
* Jacot et al. [2020] Arthur Jacot, Berlin Simsek, Francesco Spadaro, Clement Hongler, and Franck Gabriel. Kernel alignment risk estimator: Risk prediction from training data. _Advances in Neural Information Processing Systems_, 33:15568-15578, 2020.
* Cui et al. [2021] Hugo Cui, Bruno Loureiro, Florent Krzakala, and Lenka Zdeborova. Generalization error rates in kernel regression: The crossover from the noiseless to noisy regime. _Advances in Neural Information Processing Systems_, 34:10131-10143, 2021.
* Harzli et al. [2024] Ouns El Harzli, Bernardo Cuenca Grau, Guillermo Valle-Perez, and Ard A Louis. Double-descent curves in neural networks: a new perspective using gaussian processes. In _Proceedings of the AAAI Conference on Artificial Intelligence_, pages 11856-11864, 2024.
* Simon et al. [2023] James B Simon, Madeline Dickens, Dhruva Karkada, and Michael R DeWeese. The eigenlearning framework: A conservation law perspective on kernel regression and wide neural networks. _Transactions on Machine Learning Research_, 2023. arXiv:2110.03922.
* Kingma and Ba [2014] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _arXiv preprint:1412.6980_, 2014.
* Bartlett et al. [2020] Peter L Bartlett, Philip M Long, Gabor Lugosi, and Alexander Tsigler. Benign overfitting in linear regression. _Proceedings of the National Academy of Sciences_, 117(48):30063-30070, 2020.

* [30] Neil Mallinar, James Simon, Amirhesam Abedsoltan, Parthe Pandit, Misha Belkin, and Preetum Nakkiran. Benign, tempered, or catastrophic: Toward a refined taxonomy of overfitting. _Advances in Neural Information Processing Systems_, 35:1182-1195, 2022.
* [31] Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new perspectives. _IEEE transactions on pattern analysis and machine intelligence_, 35(8):1798-1828, 2013.
* [32] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. _Nature_, 521(7553):436, 2015.
* [33] Greg Yang and Edward J Hu. Tensor programs iv: Feature learning in infinite-width neural networks. In _International Conference on Machine Learning_, pages 11727-11737. PMLR, 2021.
* [34] Alexander Atanasov, Blake Bordelon, and Cengiz Pehlevan. Neural networks as kernel learners: The silent alignment effect. _arXiv preprint arXiv:2111.00034_, 2021.
* [35] Arthur Jacot, Eugene Golikov, Clement Hongler, and Franck Gabriel. Feature learning in \(l\_2\)-regularized dnns: Attraction/repulsion and sparsity. _Advances in Neural Information Processing Systems_, 35:6763-6774, 2022.
* [36] Blake Bordelon and Cengiz Pehlevan. Self-consistent dynamical field theory of kernel evolution in wide neural networks. _Advances in Neural Information Processing Systems_, 35:32240-32256, 2022.
* [37] Inbar Seroussi, Gadi Naveh, and Zohar Ringel. Separation of scales and a thermodynamic description of feature learning in some cnns. _Nature Communications_, 14(1):908, 2023.
* [38] Hugo Cui, Luca Pesce, Yatin Dandi, Florent Krzakala, Yue M Lu, Lenka Zdeborova, and Bruno Loureiro. Asymptotics of feature learning in two-layer networks after one gradient-step. _arXiv preprint arXiv:2402.04980_, 2024.
* [39] Utkarsh Sharma and Jared Kaplan. Scaling laws from the data manifold dimension. _Journal of Machine Learning Research_, 23(9):1-34, 2022. arXiv:2004.10802.
* [40] Yasaman Bahri, Ethan Dyer, Jared Kaplan, Jaehoon Lee, and Utkarsh Sharma. Explaining neural scaling laws. _arXiv preprint:2102.06701_, 2021.
* [41] Alexander Maloney, Daniel A Roberts, and James Sully. A solvable model of neural scaling laws. _arXiv preprint:2210.16859_, 2022.
* [42] Stefano Spigler, Mario Geiger, and Matthieu Wyart. Asymptotic learning curves of kernel methods: empirical data versus teacher-student paradigm. _Journal of Statistical Mechanics: Theory and Experiment_, 2020(12):124001, 2020.
* [43] Blake Bordelon, Abdulkadir Canatar, and Cengiz Pehlevan. Spectrum dependent learning curves in kernel regression and wide neural networks. In _International Conference on Machine Learning_, pages 1024-1034. PMLR, 2020.
* [44] Sanjeev Arora and Anirudh Goyal. A theory for emergence of complex skills in language models. _arXiv preprint:2307.15936_, 2023.
* [45] Maya Okawa, Ekdeep S Lubana, Robert Dick, and Hidenori Tanaka. Compositional abilities emerge multiplicatively: Exploring diffusion models on a synthetic task. _Advances in Neural Information Processing Systems_, 36, 2024.
* [46] Dingli Yu, Simran Kaur, Arushi Gupta, Jonah Brown-Cohen, Anirudh Goyal, and Sanjeev Arora. Skill-mix: A flexible and expandable family of evaluations for ai models. _arXiv preprint:2310.17567_, 2023.
* [47] Mayee Chen, Nicholas Roberts, Kush Bhatia, Jue Wang, Ce Zhang, Frederic Sala, and Christopher Re. Skill-it! a data-driven skills framework for understanding and training language models. _Advances in Neural Information Processing Systems_, 36, 2023.

* [48] Alethea Power, Yuri Burda, Harri Edwards, Igor Babuschkin, and Vedant Misra. Grokking: Generalization beyond overfitting on small algorithmic datasets. _arXiv:2201.02177_, 2022.
* [49] Irina Gennad'evna Shevtsova. Sharpening of the upper bound of the absolute constant in the berry-esseen inequality. _Theory of Probability and Its Applications_, 51(3):549-553, 2007.
* [50] Hugh L Montgomery and Robert C Vaughan. _Multiplicative Number Theory I: Classical Theory_. Cambridge Studies in Advanced Mathematics. Cambridge University Press, 2007.

## Appendix A Glossary

\begin{tabular}{l l} \(A\) & Normalization constant for \(\mathcal{P}_{s}\) such that \(\mathcal{P}_{s}(k)=Ak^{-(\alpha+1)}\) \\ \(T\) & Time or step \\ \(D\) & Number of data points \\ \(N\) & Number of parameters (skill basis functions in the model for the \\  & multilinear model; the width of hidden layer for MLP) \\ \(C\) & The computation cost \(T\times N\) \\ \(n_{s}\) & The number of skills in the multitask sparse parity problem \\ \(I\) & Random variable of the control bits \\ \(X\) & Random variable of the skill bits \\ \(\mathcal{P}_{s}\) & Probability of skills (control bits) \\ \(P_{b}\) & Probability of skill bits \\ \(S\) & The target scale or the norm of the target function \\ \(\mathcal{R}_{k}\) & Skill strength of the \(k^{th}\) skill (Eq. (7)) \\ \(\mathcal{L}\) & Total (generalization) loss \\ \(\mathcal{L}^{(D)}\) & Empirical loss for \(D\) samples \\ \(\mathcal{L}_{k}\) & Skill loss of the \(k^{th}\) skill (Eq. (6)) \\ \(d_{k}\) & Number of observation of the \(k^{th}\) skill (i.e. number of training points \\  & \((i,x)\) with \(g_{k}(i,x)\neq 0\)) \\ \(f^{*}\) & Target function \(f^{*}:\{0,1\}^{n_{s}+n_{b}}\rightarrow\{-S,S\}\) (Eq. (4)) \\ \(g_{k}\) & The \(k^{th}\) skill basis function \(g_{k}:\{0,1\}^{n_{s}+n_{b}}\rightarrow\{-1,0,1\}\) (Eq. (2)) \\ \end{tabular}

## Appendix B Background

In this section, we review the multitask sparse parity dataset, as described by Michaud et al. [18] and discuss the nonlinear dynamics of two-layer linear networks, following the work of Saxe et al. [19].

### Multitask sparse parity

The sparse parity task can be stated as follows: for a bit string of length \(n_{b}\), the goal is to determine the parity (sum mod 2) of a predetermined subset of \(m\) bits within that string. The **multitask** sparse parity [18] extends this problem by introducing \(n_{s}\) unique sparse parity variants in the dataset. The input bit strings have a length of \(n_{s}+n_{b}\). The first \(n_{s}\) bits function as indicators by assigning a specific task. The frequency of the distinct parity tasks follows a rank-frequency distribution with an inverse power law relation (power-law distribution). The last \(n_{b}\) bits are uniformly distributed. This sets a binary classification problem \(\{0,1\}^{n_{s}+n_{b}}\rightarrow\{0,1\}\) where only a single bit of the initial \(n_{s}\) bits is nonzero. In Table 3, the many distinct parity tasks represent different skills. 2

Footnote 2: Note that here we follow the even/odd parity convention used in [18], i.e., \(\{0,1\}\), instead of \(\{1,-1\}\) as used in the main text.

The proposal in [18] aims to reconcile the regularity of scaling laws with the emergence of abilities with scale using three key hypotheses: (i) skills, represented as a finite set of computations, are distinct and separate; (ii) these skills differ in their effectiveness, leading to a ranking based on their utility to reduce the loss; and (iii) the pattern of how frequently these skills are used in prediction follows a power-law distribution. Interestingly, the multitask problem has a consistent pattern across scaling curves: each parity displays a distinct transition, characterized by a sharp decrease in loss at a specific scale of parameters, data, or training step. Such a sudden shift occurs after an initial phase of no noticeable improvement, leading to reverse sigmoid-shaped learning curves. Michaud et al. [18] empirically show that for a one-hidden-layer neural network with ReLU activation, trained using cross-entropy loss and the Adam optimizer, these transitions happen at different scales for distinct tasks. This results in a smooth decrease in the overall loss as the number of skill levels increases.

### Nonlinear dynamics of linear neural network

Saxe et al. [19] have solved the exact dynamics for two-layer linear neural networks with gradient descent under MSE loss (Fig. 5(a)).3 The dynamics decompose into independent modes that show sigmoidal growth at different timescales (Fig. 5(c)). The setup assumes orthogonal input features \(X\in\mathbb{R}^{d_{1}}\) and input-output correlation matrix \(\Sigma\in\mathbb{R}^{d_{1}\times d_{3}}\) for target output \(f^{*}(X)\in\mathbb{R}^{d_{3}}\):

Footnote 3: To be specific, it is under gradient flow or the continuous limit of full batch gradient descent.

\[\mathbf{E}_{X}\left[X_{i}X_{j}\right]=\delta_{ij},\qquad\Sigma=\mathbf{E}_{X} \left[X{f^{*}}^{T}(X)\right]\] (22)

\begin{table}
\begin{tabular}{c c c} \hline \hline Control bits & Skill bits & \(y\) \\ \hline
10000000000 & 11000100001010 & 1 \\
01000000000 & 010100100001000 & 0 \\
00100000000 & 0011010101101 & 1 \\ \(\vdots\) & \(\vdots\) & \(\vdots\) \\
00000000001 & 1000100100100 & 1 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Representation of the multitask sparse parity as presented in [18]. The control bits are one-hot vectors encoding a specific parity task. The frequency of the different tasks follows a power-law distribution. In this example, there are \(n_{s}=10\) tasks, and skill bits are length \(n_{b}=15\). The \(y\) column is the resulting parity computed from \(m=3\) bits (highlighted in colors). The multitask dataset provides a controlled experimental setting designed to investigate skills.

By performing SVD (singular value decomposition) on input-output correlation matrix \(\Sigma=U\Lambda V\), the target function \(f^{*}:\mathbb{R}^{d_{1}}\rightarrow\mathbb{R}^{d_{3}}\) becomes:

\[f^{*}(x)=\sum_{k=1}^{d_{2}}v_{k}\lambda_{k}u_{k}^{T}x,\qquad U^{T}\Lambda V= \mathbf{E}_{X}\left[Xf^{*}(X)^{T}\right]\] (23)

where \(u_{k}\in\mathbb{R}^{d_{1}}\),\(v_{k}\in\mathbb{R}^{d_{3}}\) are the row vectors of \(U,V\) and \(\lambda_{k}\in\mathbb{R}\) are the singular values of \(\Lambda\).

Saxe et al. [19] have shown that the dynamics of a two-layer (one-hidden-layer) undercomplete (the width of the hidden layer is smaller than the width of the input and output) linear neural network decomposes into that of the following'modes':

\[v_{k}^{T}f(x;a,b)=a_{k}b_{k}u_{k}^{T}x\qquad k\in\{1,2,\cdots,d_{2}\}.\] (24)

where \(a_{k},b_{k}\in\mathbb{R}\) are the parameters. Note that Eq. (24) are \(d_{2}\) decoupled functions \(v_{k}^{T}f(x):\mathbb{R}^{d_{1}}\rightarrow\mathbb{R}\) (Fig. 5(b)). Assuming small and positive initialization (\(0<a_{k}(0)b_{k}(0)\ll\lambda_{k}\)), the dynamics of Eq. (24) under gradient descent with learning rate \(\eta\) can be solved analytically; the product of parameters \(a_{k}b_{k}\) grows sigmoidally with saturation time proportional to \(\lambda_{k}^{-1}\) (Fig. 5(c)):

\[\frac{a_{k}(T)b_{k}(T)}{\lambda_{k}}=\frac{1}{1+\left(\frac{\lambda_{k}}{a_{i} (0)b_{i}(0)}-1\right)e^{-2\eta\lambda_{k}t}}\,.\] (25)

Using the analytic equation of the multilinear model, Saxe et al. [19] have empirically demonstrated that the dynamics of both linear and **nonlinear** neural networks closely resemble that of the multilinear model (Eq. (25)).

Figure 5: **Nonlinear dynamics of linear neural networks.****(a):** A two-layer undercomplete linear neural network, which is a multiplication of two matrices, where \(d_{2}<d_{1}\) and \(d_{2}<d_{3}\). **(b):** The \(d_{2}\) independent modes of dynamics for linear neural network (Eq. (24)). The product of parameters \(a_{k}b_{k}\) are learnable parameters and vectors \(u_{k},v_{k}\) are obtained from SVD of the input-output correlation matrix \(\Sigma\) (Eq. (22)). **(c):** The temporal evolution of \(a_{k}b_{k}\) under gradient descent, which follows a sigmoidal growth (Eq. (25)). Note that smaller \(\lambda_{k}-\) the singular value of \(\Sigma\) – results in a more delayed saturation of \(a_{k}b_{k}\).

Derivation of the multilinear model

In this section, we provide derivations of how the skill loss of our multilinear model evolves with a given resource: time (Lemma 1), data (Corollary 1), and parameters (Corollary 2). Note that two corollaries for data and parameters (Corollaries 1 and 2) follow from the decoupled dynamics (Lemma 1).

### Decoupled dynamics of the multilinear model

**Lemma 1**.: _Let the multilinear model Eq. (9) be trained with gradient flow on \(D\) i.i.d samples for the setup in Section 2 (input distribution: Eq. (1), target function: Eq. (4), and MSE loss: Eq. (5)). Let \(k\leq N\) be a skill index in the multilinear model and the input distribution (\(k\leq n_{s}\)). Then assuming the following initialization \(a_{k}(0)=b_{k}(0)\) and \(0<a_{k}(0)b_{k}(0)<S\), the dynamics of the \(k^{th}\) skill strength (\(\mathcal{R}_{k}\)) is_

\[\mathcal{R}_{k}(T)=\frac{S}{1+\left(\frac{S}{\mathcal{R}_{k}(0)}-1\right)e^{-2 \eta S\frac{d_{k}}{D}T}}\] (26)

_and the skill loss is_

\[\mathcal{L}_{k}(T)=\frac{S^{2}}{2\left(1+\left(\frac{S}{\mathcal{R}_{k}(0)}-1 \right)^{-1}e^{2\eta S\frac{d_{k}}{D}T}\right)^{2}},\] (27)

_where \(\eta\) is the learning rate and \(d_{k}\) is the number of observations with \(g_{k}(I=k,x^{(j_{k})})\neq 0\)._

**Proof** For \(j=1,\cdots,D\), denote \((i^{(j)},x^{(j)})\) be the \(j^{th}\) data point in the training set. Then the empirical loss for \(D\) datapoints is given as

\[\mathcal{L}^{(D)}=\frac{1}{2D}\sum_{j=1}^{D}\left(f^{*}(i^{(j)},x^{(j)})-f(i^{ (j)},x^{(j)})\right)^{2}.\] (28)

We note that

\[\left(f^{*}(i^{(j)},x^{(j)})-f(i^{(j)},x^{(j)})\right)^{2} =\left(\sum_{k=1}^{n_{s}}(S-a_{k}b_{k})g_{k}(i^{(j)},x^{(j)}) \right)^{2}\] \[=(S-a_{i^{(j)}}b_{i^{(j)}})^{2}g_{i^{(j)}}(i^{(j)},x^{(j)})^{2}\] \[=(S-a_{i^{(j)}}b_{i^{(j)}})^{2},\]

as \(g_{i}(i,j)\in\{1,-1\}\) and \(g_{k}(i,j)=0\) for \(i\neq k\). So if we denote \(d_{k}\) the number of data points with \(i^{(j)}=k\), then we can conclude

\[\mathcal{L}^{(D)}=\frac{1}{2D}\sum_{j=1}^{D}(S-a_{i^{(j)}}b_{i^{(j)}})^{2}= \frac{1}{2D}\sum_{k=1}^{n_{s}}d_{k}(S-a_{k}b_{k})^{2},\] (29)

which is the decoupled loss in the main text (Eq. (11)). Using the gradient descent equation and Eq. (29), we obtain

\[\frac{da_{k}}{dt} =-\eta\frac{d\mathcal{L}_{D}}{da_{k}}\] (30) \[=-\eta\frac{d_{k}}{D}b_{k}(a_{k}b_{k}-S).\] (31)

Likewise, we can obtain the equation for \(b_{k}\) as

\[\frac{db_{k}}{dt}=-\eta\frac{d_{k}}{D}a_{k}(a_{k}b_{k}-S).\] (32)Because of symmetry between \(a\) and \(b\) (See Appendix B.2 or [19]), assuming \(a_{k}(0)=b_{k}(0)\), and \(a_{k}(0)b_{k}(0)>0\) results in \(a_{k}(T)=b_{k}(T)\) for all \(T\). The equation for \(\mathcal{R}_{k}=a_{k}b_{k}\) is

\[\frac{d\mathcal{R}_{k}}{dt} =-\eta\frac{da_{k}}{dt}b_{k}+a_{k}\frac{db_{k}}{dt}=-\eta\frac{d _{k}}{D}(b_{k}^{2}+a_{k}^{2})(a_{k}b_{k}-S)\] (33) \[=-2\eta\frac{d_{k}}{D}\mathcal{R}_{k}(\mathcal{R}_{k}-S).\] (34)

Assuming \(a_{k}(0)b_{k}(0)<S\), we can solve the differential equation to obtain

\[\mathcal{R}_{k}(T)=\frac{S}{1+\left(\frac{S}{\mathcal{R}_{k}(0)}-1\right)e^{- 2\eta S\frac{d_{k}}{D}T}}.\] (35)

The equation for \(\mathcal{L}_{k}\) follows from Eq. (10). 

### One-shot learner

**Corollary 1**.: _For the setup in Lemma 1, the \(k^{th}\) skill loss (\(\mathcal{L}_{k}\)) at \(T,N\to\infty\) is_

\[\mathcal{L}_{k}(\infty)=\begin{cases}0&:d_{k}>0\\ (S-\mathcal{R}_{k}(0))^{2}/2\approx S^{2}/2&:d_{k}=0,\end{cases}\] (36)

_where \(d_{k}\) is the number of \(k^{th}\) skill's observations._

* The corollary follows directly from Lemma 1. By taking \(T,N\to\infty\), \[\mathcal{R}_{k}(\infty)=\begin{cases}S&:d_{k}>0\\ \mathcal{R}_{k}(0)&:d_{k}=0\end{cases}\] (37) We obtain the result by using the relationship between \(\mathcal{R}_{k}\) and \(\mathcal{L}_{k}\) in Eq. (10). 

### Equivalence between a basis function and a skill

**Corollary 2**.: _Let the multilinear model Eq. (9) be trained with gradient flow on \(D\) i.i.d samples for the setup in Section 3 (input distribution: Eq. (1), target function: Eq. (4), and MSE loss: Eq. (5)). Assume \(a_{k}(0)=b_{k}(0)\), \(0<a_{k}(0)b_{k}(0)<S\), and that the model has the \(N\) most frequent skills as basis functions. Then \(\mathcal{R}_{k}\) for the \(k^{th}\leq n_{s}\) skill at \(T,D\to\infty\) is_

\[\mathcal{L}_{k}(\infty)=\begin{cases}0&:k\leq N\\ S^{2}/2&:k>N\end{cases}\] (38)

* The corollary follows directly from Lemma 1. By taking \(T,D\to\infty\), \[\mathcal{R}_{k}(\infty)=\begin{cases}S&:k\leq N\\ \mathcal{R}_{k}(0)&:k>N\end{cases}\] (39) We obtain the result by using the relationship between \(\mathcal{R}_{k}\) and \(\mathcal{L}_{k}\) in Eq. (10) and \(\mathcal{R}_{k}(0)\ll S\). 
Stage-like training: intuitive derivation of the scaling laws

Even though we provide more detailed (Appendix E) and rigorous (Appendix J) derivation of the scaling laws, a less general yet more intuitive solution aids in understanding the scaling laws of our model and NNs. In this section, we define stage-like training - one skill is completely learned before the next skill initiates learning (Fig. 6(a)) - and state the conditions for it to occur. We provide an example of how stage-like training results in the time scaling law and explain how the model in Michaud et al. [18] may arise from the NN dynamics. Finally, we discuss the stage-like training's role in emergence in NNs.

### Stage-like training

When a model exhibits an emergence behavior - when saturation of skill occurs abruptly after a delay - and the intervals between each emergence are sufficiently large, the model admits stage-like training. The multilinear model (sigmoidal saturation of skills strength, Eq. (11)) in the multitask sparse parity dataset (power-law decay of skill frequencies, Eq. (1)) can satisfy such conditions: In Fig. 6(a), we observe the stage-like training in time in which one skill saturates (reaches \(\mathcal{R}_{k}/S\approx 1\)) before the next skill initiates its emergence. To quantify this behavior, we define two intervals for each skill (see Fig. 6(a)):

* The emergent time \(\tau_{k}^{(e)}(\epsilon)\): the time for \(\mathcal{R}_{k}/S\) to reach \(\epsilon\);
* The saturation time \(\tau_{k}^{(s)}(\epsilon)\): the time for \(\mathcal{R}_{k}/S\) to saturate from \(\epsilon\) to \(1-\epsilon\).

Using the dynamics equation (Eq. (11)) and that \(d_{k}/D\to\mathcal{P}_{s}(k)\), the emergent time and saturation time of the \(k^{th}\) skill becomes

\[\tau_{k}^{(e)}(\epsilon)=\frac{1}{2\eta\mathcal{P}_{s}(k)S}\ln\left(\frac{S}{ \frac{\mathcal{R}_{k}(0)}{\frac{1}{\epsilon}-1}}\right)\propto k^{\alpha+1}, \qquad\tau_{k}^{(s)}(\epsilon)=\frac{1}{\eta\mathcal{P}_{s}(k)S}\ln\left( \frac{1}{\epsilon}-1\right)\propto k^{\alpha+1}.\] (40)

For sufficiently small initialization (\(\mathcal{R}_{k}(0)\ll S\)), we get a **stage-like** training:

\[\tau_{k}^{(s)}(\epsilon)<\tau_{k+1}^{(e)}(\epsilon)-\tau_{k}^{(e)}(\epsilon), \qquad\epsilon\ll 1.\] (41)

where the model finishes learning (saturating) the \(k^{th}\) skill before starting to learn (emerging) the next skill.

Figure 6: **Stage-like training. The multilinear model is trained on the multitask sparse parity problem with \(\alpha=0.6\) and \(S=5\). (a):** Skill strength of the model as a function of time. The emergent time \(\tau_{k}^{(e)}(\epsilon)\) is the time required for the \(k^{th}\) skill to reach \(\mathcal{R}_{k}/S=\epsilon\). The saturation time \(\tau_{k}^{(s)}(\epsilon)\) is the time required for \(\mathcal{R}_{k}/S\) to saturate from \(\epsilon\) to \(1-\epsilon\). The model shows stage-like training if the emergent time interval \(\tau_{k+1}^{(e)}(\epsilon)-\tau_{k}^{(e)}(\epsilon)\) is larger than the saturation time \(\tau_{k}^{(s)}(\epsilon)\) for sufficiently small \(\epsilon\) (\(0.05\) in the figure). (b): The loss as a function of time for the same system as (a). For stage-like training, the change in the loss for the \(k^{th}\) emergence is \(\mathcal{P}_{s}(k)\mathcal{L}_{k}+\mathcal{O}(\epsilon)\) and the interval for the next emergence is \(\Delta\tau^{(e)}(\epsilon)=\tau_{k+1}^{(e)}(\epsilon)-\tau_{k}^{(e)}(\epsilon)\).**

### Time scaling law from stage-like training

Assuming our model satisfies the stage-like training for all \(k\) of interest, we can derive the time scaling law from the stage-like training.

At \(\tau_{k}^{(e)}(\epsilon)\), because of stage-like training, all skills with index up to but not including \(k\) have saturated (\(\mathcal{R}_{i<k}\approx S\)), or equivalently \(\mathcal{L}_{i<k}\approx 0\) (Eq. (10)). The total loss, the sum of \(\mathcal{L}_{j}\) weighted by \(\mathcal{P}_{s}(j)\propto j^{-(\alpha+1)}\) (Eq. (6)), becomes \(\sum_{j=k}^{\infty}\mathcal{P}_{s}(I=j)S^{2}/2\) (Fig. 6(b)). The saturation of the \(k^{th}\) skill results in a loss difference of \(\mathcal{P}_{s}(I=k)S^{2}/2\). Thus, we obtain

\[\frac{\Delta\mathcal{L}}{\mathcal{L}} \approx\frac{\mathcal{P}_{s}(I=k)}{\sum_{j=k}^{\infty}\mathcal{P} _{s}(I=j)}=-\frac{k^{-(\alpha+1)}}{\sum_{j=k}^{\infty}j^{-(\alpha+1)}}\approx- \frac{k^{-(\alpha+1)}}{\int_{k}^{\infty}j^{-(\alpha+1)}dj}\] (42) \[=-\alpha k^{-1}+\mathcal{O}(k^{-2}).\] (43)

Accordingly, the emergent interval between the \(k\) and \(k+1\) skills relative to the \(\tau_{k}^{(e)}(\epsilon)\) is

\[\frac{\Delta T}{T} =\frac{\tau_{k+1}^{(e)}(\epsilon)-\tau_{k}^{(e)}(\epsilon)}{\tau_ {k}^{(e)}(\epsilon)}=\frac{(k+1)^{\alpha+1}-k^{\alpha+1}}{k^{\alpha+1}}\] (44) \[=(\alpha+1)k^{-1}+\mathcal{O}(k^{-2}).\] (45)

Assuming \(k\gg 1\) and combining Eq. (43) and Eq. (45) to the largest order, we have the equation for the power-law with exponent \(-\alpha/(\alpha+1)\) in Fig. 2(a):

\[\frac{\Delta\mathcal{L}}{\mathcal{L}}=-\frac{\alpha}{\alpha+1}\frac{\Delta T} {T}.\] (46)

If the stage-like training holds for any resource (e.g., time, data, or parameters), the scaling law can be derived using the ratio of change in loss per skill (Eq. (43)) and the ratio of change with respect to the resource (given by the emergent time in Eq. (45)). The quanta model in Michaud et al. [18] is an example where the stage-like training holds for all resources.

### Discussion on the effective decoupling of skills in neural networks

In Section 5, we have empirically demonstrated that the multilinear model predicts the emergence of a 2-layer NN (Fig. 1). In Section 6, we briefly discussed why NNs, despite their **lack** of the decoupling among the skills, behave similarly to the decoupled model with \(g_{k}\)s as fixed basis functions: the **stage-like training** in NNs - induced by the model's layerwise structure and power-law frequencies of the skills - effectively decouples the skills. In this subsection, we extend the discussion in more detail.

In NNs, even though \(g_{k}\)s are 'discovered' (feature learned) by non-tractable dynamics, we speculate that similar stage-like dynamics also hold in 'discovering' (feature learning) \(g_{k}\)s: parameters 'useful' for expressing more frequent skills will be updated significantly faster than parameters useful for expressing less frequent skills.

If skill discovery and saturation dynamics operate at different time scales (stages), with negligible interaction among the skills, the skill dynamics become effectively **decoupled**. Because the dynamics are decoupled in stages, NNs repeat the feature learning process - using the limited resource (time, data, parameters) to express the skill - for all skills with each iteration varying only in the scale of the resource (e.g. training time, number of observations, and number of hidden layer neurons): resulting in a similar emergence to our multilinear model.

A more concrete understanding of our speculation that feature learning also occurs in stages due to a layerwise structure is left for future work.

## Appendix E Derivation of the scaling law exponents

This section provides a detailed derivation of the scaling laws up to a rigor common in physics and engineering. For example, we approximate the Riemann sum as integral or treat \(k\), the number ofskills, as a differentiable parameter. For more general and rigorous derivations including the prefactor constants, see Appendix J. Instead, for more intuition and the relationship to the quanta model in Michaud et al. [18], see Appendix D.

### Time scaling law exponent

To derive the time scaling law exponent, we assume the time as the bottleneck and take \(N,D\to\infty\). By using the decoupled dynamics of each skill loss (Lemma 1),

\[\mathcal{L}_{k}=\frac{S^{2}}{2\left(1+\left(\frac{S}{\mathcal{R}_{k}(0)}-1 \right)^{-1}e^{2\eta\frac{d_{k}}{D}ST}\right)^{2}}.\] (47)

Noting that \(d_{k}/D\to\mathcal{P}_{s}(k)\) as \(D\to\infty\), where \(\mathcal{P}_{s}(k)=Ak^{-(\alpha+1)}\), we have

\[\mathcal{L}_{k}=\frac{S^{2}}{2\left(1+\left(\frac{S}{\mathcal{R}_{k}(0)}-1 \right)^{-1}e^{2\eta Ak^{-(\alpha+1)}ST}\right)^{2}}.\] (48)

This is a function of \(k^{-(\alpha+1)}T\) only, suggesting the **decoupling** dynamics for each skill. Thus,

\[\frac{d\mathcal{L}_{k}}{dT}=-\frac{k}{(\alpha+1)T}\frac{d\mathcal{L}_{k}}{dk}.\] (49)

Using Eq. (6) and taking \(N,n_{s}\to\infty\) at the same rate,4 we can approximate the loss as an integral instead of a sum over \(k\):

Footnote 4: We take \(N\) and \(n_{s}\) to \(\infty\) at the same rate since we do not want the number of parameters to be a bottleneck in this setup.

\[\mathcal{L}\approx\lim_{N\to\infty}\int_{1}^{N}Ak^{-(\alpha+1)} \mathcal{L}_{k}dk,\] (50)

where \(A\) is the normalization constant for \(\mathcal{P}_{s}\). We can differentiate the loss and use Eq. (49) to express the equation in terms of \(k\):

\[\frac{d\mathcal{L}}{dT}=\lim_{N\to\infty}\int_{1}^{N}Ak^{-(\alpha+1)}\frac{d \mathcal{L}_{k}}{dT}dk=-\lim_{N\to\infty}\frac{1}{(\alpha+1)T}\int_{1}^{N}Ak^{ -\alpha}\frac{d\mathcal{L}_{k}}{dk}dk.\] (51)

Integrating by parts, we obtain

\[\frac{d\mathcal{L}}{dT} =-\lim_{N\to\infty}\frac{1}{(\alpha+1)T}\left[Ak^{-\alpha} \mathcal{L}_{k}\right]_{1}^{N}-\lim_{N\to\infty}\frac{\alpha}{(\alpha+1)T} \int_{1}^{N}Ak^{-(\alpha+1)}\mathcal{L}_{k}dk\] (52) \[=-\lim_{N\to\infty}\mathcal{O}\left(N^{-\alpha}\frac{1}{T}\right) +\mathcal{O}\left(\frac{1}{Te^{T}}\right)-\frac{\alpha}{(\alpha+1)T}\mathcal{ L}.\] (53)

The first term goes to \(0\) as \(N\to\infty\) and the second term goes to \(0\) exponentially faster compared to the last term for \(T\gg 1\), which leads to the scaling law with exponent \(-\alpha/(\alpha+1)\):

\[\frac{d\mathcal{L}(T)}{\mathcal{L}(T)}=-\frac{\alpha}{\alpha+1}\frac{dT}{T}.\] (54)

\begin{table}
\begin{tabular}{c c c c c} \hline \hline Bottleneck & Time & Data & Parameter & Exponent \\ \hline Time (\(T\)) & \(T\) & \(\infty\) & \(\infty\) & \(-\alpha/(\alpha+1)\) \\ Data (\(D\)) & \(\infty\) & \(D\) & \(\infty\) & \(-\alpha/(\alpha+1)\) \\ Parameter (\(N\)) & \(\infty\) & \(\infty\) & \(N\) & \(-\alpha\) \\ Compute (\(C\)) & \(C^{(\alpha+1)/(\alpha+2)}\) & \(\infty\) & \(C^{1/(\alpha+2)}\) & \(-\alpha/(\alpha+2)\) \\ \hline \hline \end{tabular}
\end{table}
Table 4: **Summary of the scaling laws.** The leftmost column shows the bottleneck of the scaling law. The middle three columns show the resource values in terms of the bottleneck (either taken to infinity or proportional to the bottleneck). The last column shows the scaling exponent for the loss as power-law of the bottleneck where \(\alpha+1\) is the exponent of the Zipfian input data (Eq. (1)).

Finite \(N\) correction for small \(\alpha\).In Fig. 7, we observe that our model with \(\alpha=0.1\) deviates from the expected power-law with exponent \(-\alpha/(\alpha+1)\). The deviation can be explained by the antiderivative term in Eq. (52):

The second term (\(k=1\)) goes to \(0\) faster than \(\mathcal{O}(T^{-1})\) for sufficiently larger \(T\) but the first term (\(k=N\)) may not decay fast enough for finite \(N\) and sufficiently small \(\alpha\). For example, \(N=50,000\) and \(\alpha=0.1\) leads to \(N^{-\alpha}\approx 0.3\), which is not negligibly small.

Assuming finite \(N\) and small \(\alpha\) such that the first term in Eq. (55) is non-negligible, we can rewrite Eq. (52) as

\[\frac{d\mathcal{L}}{dT}\approx-\frac{\alpha}{(\alpha+1)}\frac{ \mathcal{L}+\mathcal{L}_{C}}{T},\qquad\mathcal{L}_{C}\approx S^{2}AN^{-\alpha} /2\alpha,\] (56)

where we assumed a small initialization \(S/\mathcal{R}_{k}(0)\gg 1\) and sufficiently large number of parameters \(N^{\alpha+1}\gg T\) to approximate \(\mathcal{L}_{C}\). Because the total loss at initialization is \(\mathcal{L}(0)=S^{2}/2\), \(\mathcal{L}_{C}\) is non-negligible compared to the loss for sufficiently small \(\alpha\). Thus considering \(\mathcal{L}_{C}\), we obtain the corrected power-law which better approximates the time scaling law (dashed lines in Fig. 7). For a rigorous and comprehensive analysis of the time scaling law, see Theorem 2 and Theorem 3 in Appendix J.

### Data scaling law exponent

In this section, we derive the data scaling law exponent. The data scaling law assumes \(T\to\infty\) and \(N\to\infty\) with data as the bottleneck. From the decoupled dynamics of the multilinear model (Lemma 1), we can show that our model is a one-shot learner (Corollary 1):

**One shot learner.**_Given that \(N>k\), \(T\to\infty\), and \(d_{k}\) is the number of samples from the training set with \(g_{k}(i,x)\neq 0\), the \(k^{th}\) skill loss after training is_

\[\mathcal{L}_{k}(\infty)=\begin{cases}0&:d_{k}>0\\ (S-\mathcal{R}_{k}(0))^{2}/2\approx S^{2}/2&:d_{k}=0.\end{cases}\] (57)

**Proof** See Appendix C.2.

Figure 7: **Scaling law and corrected predictions. A simulation of our multilinear model with \(N=50,000\) (solid), a scaling law with exponent \(-\alpha/(\alpha+1)\) (dotted), and a corrected scaling law considering finite \(N\) (dashed, Eq. (56)). The finite \(N\) corrected scaling law better predicts the dynamics, especially for smaller \(\alpha\).**

Our model requires only one sample from the \(k^{th}\) skill to learn such a skill, similar to how language models are few-shot learners at inference.5 The model can one-shot learn a skill since it has \(g_{k}\) as the basis functions, and the dynamics among different skills are decoupled. A similar one-shot learner has been studied in Hutter [20] where the error depends on a single 'observation' of a feature.

Footnote 5: Few-shot learning is typically discussed in the context of models that have undergone pre-training (see, e.g. [1]). We speculate that expanding in the basis \(g_{k}\) in our framework can model aspects of the pre-training process.

Because the \(k^{th}\) skill loss **only depends** on \(d_{k}\) (number of observations for the \(k^{th}\) skill), we can calculate the expectation of the skill loss for \(D\) data points from \(P_{observed}(k|D)\) or the probability that \(d_{k}>0\):

\[P_{observed}(k|D)=1-(1-\mathcal{P}_{s}(k))^{D}\,.\] (58)

Using the one-shot learning property (Eq. (57)), the probability of observing the \(k^{th}\) skill (Eq. (58)), and the decomposition of the loss into skill losses (Eq. (6)), the expected loss for \(D\) datapoints is

\[\mathbf{E}_{D}\left[\mathcal{L}\right] =\frac{1}{2}\sum_{k=1}^{\infty}S^{2}\mathcal{P}_{s}(k)(1-P_{observed }(k))\] (59) \[=\frac{1}{2}S^{2}A\sum_{k=1}^{\infty}k^{-(\alpha+1)}\left(1- \mathcal{P}_{s}(k)\right)^{D}\] (60) \[\approx\frac{1}{2}S^{2}A\int_{1}^{\infty}k^{-(\alpha+1)}\left(1- Ak^{-(\alpha+1)}\right)^{D}dk,\] (61)

where the expectation \(\mathbf{E}_{D}\) is over all possible training sets of size \(D\), and \(A\) is the normalization constant such that \(\mathcal{P}(k)=Ak^{-(\alpha+1)}\). The difference in the loss \(\Delta\mathcal{L}=\mathbf{E}_{D+1}\left[\mathcal{L}\right]-\mathbf{E}_{D} \left[\mathcal{L}\right]\) is

\[\Delta\mathcal{L} =\frac{1}{2}S^{2}A\int_{1}^{\infty}k^{-(\alpha+1)}\left(1-Ak^{-( \alpha+1)}\right)^{D}\left(\left(1-Ak^{-(\alpha+1)}\right)-1\right)dk\] (62) \[=-\frac{1}{2}S^{2}A^{2}\int_{1}^{\infty}k^{-2(\alpha+1)}\left(1- Ak^{-(\alpha+1)}\right)^{D}dk.\] (63)

We can integrate \(\Delta\mathcal{L}\) by parts.

\[\Delta\mathcal{L} =\frac{1}{2}\left[-\frac{S^{2}Ak^{-\alpha}}{(\alpha+1)(D+1)} \left(1-Ak^{-(\alpha+1)}\right)^{D+1}\right]_{1}^{\infty}\] \[\qquad\qquad-\frac{S^{2}A\alpha}{2(\alpha+1)(D+1)}\int_{1}^{ \infty}k^{-(\alpha+1)}\left(1-Ak^{-(\alpha+1)}\right)^{D+1}dk\] \[\approx-\frac{\alpha}{(\alpha+1)(D+1)}\mathbf{E}_{D}\left[ \mathcal{L}\right]+\frac{\alpha}{(\alpha+1)(D+1)}\Delta\mathcal{L}.\]

In the second line, the first term goes to \(0\) for \(D\gg 1\). In the last line, we used the expression for \(\Delta\mathcal{L}\) (Eq. (62)) and \(\mathbf{E}_{D}\left[\mathcal{L}\right]\) (Eq. (59)). Rearranging the equation above and using that \(D\gg 1\), we obtain the scaling law with exponent \(-\alpha/(\alpha+1)\):

\[\frac{\Delta\mathcal{L}}{\mathbf{E}_{D}\left[\mathcal{L}\right]} =-\frac{\alpha}{1+(\alpha+1)D}\approx-\frac{\alpha}{(\alpha+1)} \frac{1}{D}\] (64) \[=-\frac{\alpha}{(\alpha+1)}\frac{\Delta D}{D}.\] (65)

where in the last line, \(\Delta D/D=1/D\) as the change in the number of data points relative to \(D\) is one.

### Parameter scaling law exponent

The parameter scaling law assumes \(T\to\infty\) and \(D\to\infty\), with the parameters \(N<n_{s}\) as the bottleneck. Because our model is a one-shot learner (Eq. (57)), learning of the \(k^{th}\) skill **only depends** on the existence of \(g_{k}\) in the model; the model with \([g_{1},\cdots,g_{N}]\) will learn all \(k\leq N\) skills with \(\mathcal{L}_{k}=0\).

The \(\mathcal{L}_{k}\) dependence on \(g_{k}\) is formalized in Corollary 2, which we repeat here.

Equivalence between a basis function and a skill._Given \(T,D\to\infty\) and if the multilinear model has the \(N\) most frequent skill functions as a basis,_

\[\mathcal{L}_{k}(\infty)=\begin{cases}0&:k\leq N\\ S^{2}/2&:k>N.\end{cases}\] (66)

* See Appendix C.3. \(\blacksquare\)

Using Eq. (66) and Eq. (6), we can express the total loss as function of \(N\): \[\mathcal{L}\approx\frac{S^{2}}{2}\int_{N+1}^{\infty}Ak^{-(\alpha+1)}dk\propto (N+1)^{-\alpha}.\] (67) By approximating \(N\approx N+1\) for \(N\gg 1\), we obtain the power-law with exponent \(-\alpha\).

### Optimal compute scaling law

For analytical tractability, we define compute as \(C:=T\times N\). We start from Eq. (12) with \(D\to\infty\)

\[\mathcal{L}\approx\int_{1}^{N}Ak^{-(\alpha+1)}\mathcal{L}_{k}dk+\lim_{n_{s}\to \infty}\frac{S^{2}}{2}\int_{N}^{n_{s}}Ak^{-(\alpha+1)}dk.\] (68)

We can use Eq. (56) to calculate the first term and integrate the last term to get

\[\mathcal{L} \approx(\mathcal{L}(0)+\mathcal{L}_{C})T^{-\alpha/(\alpha+1)}- \mathcal{L}_{c}+\frac{S^{2}A}{2\alpha}N^{-\alpha}\] (69) \[\approx\mathcal{O}(T^{-\alpha/(\alpha+1)})+\mathcal{O}(N^{- \alpha}),\] (70)

where we used that \(\mathcal{L}(0)\gg\mathcal{L}_{C}\) and \(S^{2}A/(2\alpha)-\mathcal{L}_{C}>0\). Intuitively, the approximation shows the tradeoff between \(T\) - when increased, decreases the loss of the first \(N\) skills - and \(N\) - when increased, decreases the loss at sufficiently large \(T\) - for fixed compute \(C\). For a comprehensive analysis of the approximation above, see Appendix J.

Removing the irrelevant constant terms,

\[\mathcal{L}=T^{-\alpha/(\alpha+1)}+N^{-\alpha}.\] (71)

We can use the method of Lagrangian multiplier to obtain

\[-\frac{\alpha}{\alpha+1}T^{-\alpha/(\alpha+1)-1}+\lambda N =0,\] (72) \[-\alpha N^{-(\alpha+1)}+\lambda T =0,\] (73) \[NT-C =0,\] (74)

where \(\lambda\) is the Lagrange multiplier and \(C\) is compute. We can solve the above set of equations to obtain \(T^{\alpha+1}\propto N\) or equivalently

\[T\propto C^{(\alpha+1)/(\alpha+2)},\quad N\propto C^{1/(\alpha+2)}.\] (75)

We can plug it in Eq. (71) to get

\[\mathcal{L}\propto C^{-\alpha/(\alpha+2)}.\] (76)

This derivation is similar to that of Bordelon et al. [21] (see Appendix N: Compute Optimal Scaling from Sum of Power-Laws in [21]). For a rigorous derivation of the optimal compute scaling law, see Corollary 4 and Appendix J.

Derivation of the extended multilinear model

In this section, we show the derivation for the extended multilinear model.

### Gradient flow in the extended multilinear model

**Lemma 2**.: _Let the extended multilinear model Eq. (15) be trained with gradient flow on \(D\) i.i.d samples for the setup in Section 2 (input distribution: Eq. (1), target function: Eq. (4), and MSE loss: Eq. (5)). For the skill index \(k\leq N\) be a skill index in the multilinear model, let the feature matrix \(\Phi\in\mathbb{R}^{D_{c}\times d_{k}}\) for the \(k^{th}\) skill be_

\[\Phi_{lj}=e_{k,l}(i^{(j)}=k,x^{(j)}),\] (77)

_and SVD on \(\Phi=USV\). Assuming that the system is overparametrized (\(d_{k}<D_{c}\)), the gradient on \(\vec{B}_{k}\in\mathbb{R}^{D_{c}}\) (\([B_{k,1},\cdots,B_{k,D_{c}}]\)) is contained in the column space of semi-orthogonal matrix \(U\in\mathbb{R}^{D_{c}\times d_{k}}\):_

\[UU^{T}\frac{d\vec{B}_{k}}{dt}=\frac{d\vec{B}_{k}}{dt}.\] (78)

Proof.: Similar to Lemma 1, the total loss can be decomposed into each skill such that the dynamics of \(B_{k,l}\) relies only on \(d_{k}\) observations of the \(k^{th}\) skill:

\[\mathcal{L}_{D} =\frac{1}{2D}\sum_{k=1}^{n_{s}}\sum_{j=1}^{D}\left(f^{*}(i^{(j)}, x^{(j)})-f(i^{(j)},x^{(j)})\right)^{2}\] (79) \[=\frac{1}{2D}\sum_{k=1}^{n_{s}}\sum_{j_{k}=1}^{d_{k}}\left(Sg_{k} (k,x^{(j_{k})})-\sum_{l=1}^{D_{c}}a_{k}B_{k,l}e_{k,l}(k,x^{(j_{k})})\right)^{2}\] (80) \[=\frac{1}{2D}\sum_{k=1}^{n_{s}}\sum_{j_{k}=1}^{d_{k}}\left(\sum_{ l=1}^{D_{c}}(\frac{S}{\sqrt{D_{c}}}-a_{k}B_{k,l})e_{k,l}(k,x^{(j_{k})})\right)^{2}.\] (81)

In the second line, we used Eq. (16) that \(e_{k,l}(I\neq k,x)=0\) and the orthogonality of \(g_{k}\) (Eq. (3)). In the last line, we used Eq. (16) that \(g_{k}={D_{c}}^{-1/2}\sum_{l}e_{k,l}\). We can find the gradient descent equation of \(B_{k,l}\) from Eq. (81):

\[\frac{dB_{k,l}}{dt}=-\eta\sum_{j=1}^{d_{k}}\frac{1}{D}\left[a_{k}e_{k,l}(k,x^{ (j)})\sum_{l^{\prime}=1}^{D_{c}}(a_{k}B_{k,l^{\prime}}-\frac{S}{\sqrt{D_{c}}}) e_{k,l^{\prime}}(k,x^{(j)})\right],\] (82)

which in the matrix form is

\[\frac{d\vec{B}_{k}}{dt}=-\frac{\eta a_{k}}{D}\Phi\Phi^{T}\left(B_{k}a_{k}- \frac{\vec{S}}{\sqrt{D_{c}}}\right),\] (83)

where \(D_{c}\) dimensional vectors \(\vec{B_{k}}\) and \(\vec{S}\) are \([B_{k,1},\cdots,B_{k,D_{c}}]\) and \([S,\cdots,S]\) respectively. It illustrates that \(\frac{dB_{k}}{dt}\) is contained in \(\mathrm{im}(\Phi)\), which is contained in \(\mathrm{im}(U)\) (immediate from \(\Phi=USV\)). As \(UU^{T}(Uz)=U(U^{T}U)z=Uz\), \(UU^{T}\) acts as identity on image of \(U\), showing that \(UU^{T}\frac{d\vec{B}_{k}}{dt}=\frac{d\vec{B}_{k}}{dt}\).

### Conserved quantity of extended multilinear model

**Lemma 3**.: _In the setup of Lemma 2, \(a_{k}^{2}-|\vec{B}_{k}|^{2}\) is conserved over time._

Proof.: We can use Eq. (81) to find the equation for \(a_{k}\):

\[\frac{da_{k}}{dt}=-\eta\sum_{j=1}^{d_{k}}\frac{1}{D}\left[\sum_{l=1}B_{k,l}e_{ k,l}(k,x^{(j)})\sum_{l^{\prime}=1}^{D_{c}}(a_{k}B_{k,l^{\prime}}-\frac{S}{ \sqrt{D_{c}}})e_{k,l^{\prime}}(k,x^{(j)})\right],\] (84)which in the matrix form is

\[\frac{da_{k}}{dt}=-\frac{\eta}{D}\vec{B}_{k}^{T}\Phi\Phi^{T}\left(\vec{B}_{k}a_{k }-\frac{\vec{S}}{\sqrt{D_{c}}}\right).\] (85)

Then

\[a_{k}\frac{da_{k}}{dt} =-\frac{\eta a_{k}}{D}\vec{B}_{k}^{T}\Phi\Phi^{T}\left(\vec{B}_{k} a_{k}-\frac{\vec{S}}{\sqrt{D_{c}}}\right)\] (86) \[=\vec{B}_{k}^{T}\frac{d\vec{B}_{k}}{dt},\] (87)

where we used Eq. (83) in the last line. Thus, \(a_{k}^{2}-|\vec{B}_{k}|^{2}\) is conserved during the dynamics. 

### \(\boldsymbol{D_{c}}\) shot learner

**Proposition 1**.: _Let the setup be as that in Lemma 2. Suppose that \(a_{k}(T)\) is eventually bounded away from zero, i.e. there exists \(\delta>0\) and \(M>0\) such that \(T>M\Rightarrow|a_{k}(T)|\geq\delta\). Also assume that \(U^{\perp}\)-component of \(\vec{B}_{k}(0)a_{k}(0)\) and \(\vec{B}_{k}(0)S\) is negligible. Then the skill strength \(\mathcal{R}_{k}\) is_

\[\mathcal{R}_{k}(\infty)=\begin{cases}d_{k}<D_{c}:&S\left(1-\sqrt{1-d_{k}/D_{c }}\right)\\ d_{k}\geq D_{c}:&S\end{cases}\] (88)

* First, we show that \(\frac{d\mathcal{L}_{k}}{dt}\leq 0\) with equality only holding when the gradient is 0. \[\frac{d\mathcal{L}_{k}}{dt} =\frac{d\mathcal{L}_{k}}{da_{k}}\frac{da_{k}}{dt}+\sum_{i}^{D_{c}} \frac{d\mathcal{L}_{k}}{dB_{k,i}}\frac{dB_{k,i}}{dt}\] (89) \[=-\eta\frac{d_{k}}{D}\left(\frac{d\mathcal{L}_{k}}{da_{k}}\frac{ d\mathcal{L}_{k}}{da_{k}}+\sum_{i}^{D_{c}}\frac{d\mathcal{L}_{k}}{dB_{k,i}}\frac{d \mathcal{L}_{k}}{dB_{k,i}}\right)\leq 0.\] (90) The equality holds only when \[\frac{d\mathcal{L}_{k}}{da_{k}}=\frac{da_{k}}{dt}=0\quad\text{and}\quad\frac{ d\mathcal{L}_{k}}{dB_{k,i}}=\frac{dB_{k,i}}{dt}=0\,.\] (91) We show that both \(a_{k}\) and \(\vec{B}_{k}\) are bounded throughout whole dynamics. As \[\mathcal{L}_{k}=\left|\Phi\left(\vec{B}_{k}a_{k}-\frac{\vec{S}}{\sqrt{D_{c}}} \right)\right|^{2}\geq\sigma^{2}\left|UU^{T}\left(\vec{B}_{k}a_{k}-\frac{\vec {S}}{\sqrt{D_{c}}}\right)\right|^{2}\] (92) for \(\sigma^{2}\) the smallest nonzero eigenvalue of \(\Phi\Phi^{T}\), where \(\Phi=USV\). This shows that \[UU^{T}\left(\vec{B}_{k}a_{k}-\frac{\vec{S}}{\sqrt{D_{c}}}\right)\] (93) is bounded, so \(UU^{T}\vec{B}_{k}a_{k}\) is bounded. Meanwhile, in Lemma 2, we showed that \((1-UU^{T})\frac{d\vec{B}_{k}}{dt}=0\), so \((1-UU^{T})\vec{B}_{k}a_{k}\) is bounded. This shows that \(\vec{B}_{k}a_{k}\) is bounded. As \(a_{k}^{2}-|\vec{B}_{k}|^{2}\) is constant (Lemma 3) and \(|\vec{B}_{k}a_{k}|=|a_{k}||\vec{B}_{k}|\) is bounded, this shows that both \(a_{k}\) and \(|\vec{B}_{k}|\) are bounded. The dynamics moving in some bounded region always has at least one accumulation point, which we denote as \(p\). We will show that \(\frac{d\mathcal{L}_{k}}{dt}=0\) at \(p\). The function \(\mathcal{L}_{k}(t)\) in \(t\) is a decreasing differential function which is positive. We also note that \(\frac{d^{2}\mathcal{L}_{k}(t)}{dt^{2}}\) is globally bounded, as it can be expressed in polynomial expression in \((a_{k},\vec{B}_{k})\) and we showed that \((a_{k}(t),\vec{B}_{k}(t))\) is bounded. From Taylor's theorem, one can obtain

\[\inf\mathcal{L}_{k}(t)\leq\mathcal{L}_{k}(t_{1}+t_{2})\leq\mathcal{L}_{k}(t_{1 })+t_{2}\frac{d\mathcal{L}_{k}}{dt}(t_{1})+\frac{t_{2}^{2}}{2}M\] (94)for \(M=\sup|\frac{d^{2}\mathcal{L}_{k}(t)}{dt^{2}}|\). Choosing \(t_{2}=-\frac{d\mathcal{L}_{k}}{dt}(t_{1})M^{-1}\) shows that

\[\mathcal{L}_{k}(t_{1})-\frac{1}{2M}\left(\frac{d\mathcal{L}_{k}}{dt}(t_{1}) \right)^{2}\geq\inf\mathcal{L}_{k}(t)\] (95)

and letting \(t_{1}\to\infty\) here gives

\[\lim_{t_{1}\to\infty}\frac{1}{2M}\left(\frac{d\mathcal{L}_{k}}{dt}(t_{1}) \right)^{2}\leq\lim_{t_{1}\to\infty}(\mathcal{L}_{k}(t_{1})-\inf\mathcal{L}_{ k}(t))=0\] (96)

so \(\frac{d\mathcal{L}_{k}}{dt}\to 0\) as \(t\to\infty\). Meanwhile, as \(p\) is accumulation point of \((a_{k},B_{k})\), \(\frac{d\mathcal{L}_{k}}{dt}(p)\) is accumulation point of \(\frac{d\mathcal{L}_{k}}{dt}(a_{k}(t),\vec{B}_{k}(t))\). As \(\lim_{t\to\infty}\frac{d\mathcal{L}_{k}}{dt}(t)=0\), the only accumulation point of \(\frac{d\mathcal{L}_{k}}{dt}(t)\) is zero, which shows that \(\frac{d\mathcal{L}_{k}}{dt}(p)=0\).

We have seen that \(a_{k}^{2}-|\vec{B}_{k}|^{2}\) and \((I-UU^{T})\vec{B}_{k}\) are conserved in our dynamics. A quantity conserved in dynamics should also be conserved at \(p\), so \(p=(a,\vec{B})\) should satisfy the following conditions:

* \(a^{2}-|\vec{B}|^{2}=a_{k}(0)^{2}-|\vec{B}_{k}(0)|^{2}\) (Lemma 3);
* \((I-UU^{T})\vec{B}=(I-UU^{T})\vec{B}_{k}(0)\) (Lemma 2);
* \(\frac{d\mathcal{L}_{k}}{dt}(a,\vec{B})=0\), or equivalently the gradient is \(0\) at \(p\).

We will solve for \(p\) satisfying those three conditions. The third condition is equivalent to that

\[aUU^{T}\left(\vec{B}a-\frac{\vec{S}}{\sqrt{D_{c}}}\right)=0.\] (97)

As \(a_{k}(T)\) is eventually bounded away from zero, we have \(a\neq 0\), so

\[UU^{T}\left(\vec{B}a-\frac{\vec{S}}{\sqrt{D_{c}}}\right)=0.\] (98)

It follows that

\[\vec{B}=UU^{T}\vec{B}+(I-UU^{T})\vec{B}=UU^{T}\frac{\vec{S}}{\sqrt{D_{c}}}a^{ -1}+(I-UU^{T})\vec{B}_{k}(0)\] (99)

and substituting to first condition gives

\[a^{2}-\frac{1}{a^{2}}\left|UU^{T}\frac{\vec{S}}{\sqrt{D_{c}}}\right|^{2}- \left|(I-UU^{T})\vec{B}_{k}(0)\right|^{2}=a_{k}(0)^{2}-|\vec{B}_{k}(0)|^{2}.\] (100)

This is equivalent to a quadratic equation in \(a^{2}\), and has a following solution of

\[a^{2}=\sqrt{\left|UU^{T}\frac{\vec{S}}{\sqrt{D_{c}}}\right|^{2}+\frac{(a_{k}( 0)^{2}-|UU^{T}\vec{B}_{k}(0)|^{2})^{2}}{4}}+\frac{a_{k}(0)^{2}-|UU^{T}\vec{B} _{k}(0)|^{2}}{2}.\] (101)

This shows that there are two candidates for \(p\), with \(a\) given as two square roots of Eq. (101) and \(B\) determined from \(a\) by Eq. (99). It is impossible for \(\mathcal{L}_{k}(t)\) to have accumulation points both in regions \(a>0\) and \(a<0\), as it would imply \(a_{k}(t)=0\) happens infinitely many often, contradicting that \(a_{k}\) is eventually bounded away from zero. Thus it follows that \(\mathcal{L}_{k}(t)\) can only have one accumulation point. As dynamics having unique accumulation point should converge, it follows that

\[(a,\vec{B})=(a_{k}(\infty),\vec{B}_{k}(\infty)).\] (102)

One can check that the \(U^{\perp}\)-component of \(\vec{B}_{k}(\infty)a_{k}(\infty)\) is given as

\[(I-UU^{T})\vec{B}_{k}(\infty)a_{k}(\infty)=(I-UU^{T})\vec{B}_{k}(0)a_{k}(0)\] (103)

and this is bounded by \(|(1-UU^{T})B_{k}(0)|(S+a_{k}(0))\), so by our assumption this is negligible. Thus, we find that \(\vec{B}_{k}(\infty)a_{k}(\infty)\) is the pseudo-inverse solution, which is also found by the linear model with \(e_{k,l}\) as basis functions. We can calculate \(\mathcal{L}_{k}(\infty)\) using the result from kernel (linear) regression [23, 24, 25, 26, 27] (for a summary, see tables 1 and 2 in appendix A of [27]). Using the terminology in table 1 of [27], the sample size is \(d_{k}\); the number of parameters is \(D_{c}\); ridge and noise are absent; the eigenfunctions are \([e_{k,1},\cdots,e_{k,D_{c}}]\); the eigen coefficients are \(\mathbf{E}_{X}[e_{k,i}(x)Sg_{k}(x)]=SD_{c}^{-1/2}\) (Eq. (16)); eigenvalues are uniform; the learnability is \(d_{k}/D_{c}\) for all \(i\); and the overfitting coefficient is \((1-d_{k}/D_{c})^{-1}\). Taking into account that we have halved the MSE loss (Eq. (5)), the test loss is

\[\mathcal{L}_{k}(\infty)=\frac{S^{2}}{2}\left(1-\frac{d_{k}}{D_{c}}\right).\] (104)

We obtain the result by using Eq. (10).

### \(\boldsymbol{N_{c}}\) basis functions for a skill

**Proposition 2**.: _Let the extended multilinear model Eq. (18) be trained with gradient flow on \(D\to\infty\) i.i.d samples for the setup in Section 3 with \(n_{s}\to\infty\) (input distribution: Eq. (1), target function: Eq. (4), and MSE loss: Eq. (5), initialization: that of Proposition 1). For a model with the following finite \(N\) basis functions_

\[[e_{1,1},\ \cdots,\ e_{1,N_{c}},\ e_{2,1},\ \cdots,\ e_{q,r}],\] (105)

_where quotient \(q=\lfloor(N-1)/N_{c}\rfloor+1\) and remainder \(r\) is such that \((q-1)N_{c}+r=N\). The skill strength at \(T\to\infty\) becomes_

\[\mathcal{R}_{k}(\infty)=\begin{cases}k>q:&0\\ k=q:&S\frac{r}{N_{c}}\\ k<q:&S.\end{cases}\] (106)

* Because we have \(D\to\infty\) and because \([e_{k,1},\cdots e_{k,N_{c}}]\) can express \(g_{k}\) (Eq. (20)), it is trivial to show that \(\mathcal{R}_{k}(\infty)=S\) for \(k<q\). For \(k=q\), the gradient descent dynamics (Eq. (83)) leads to \[\frac{d\vec{B}_{k}}{dt}=-\frac{\eta a_{k}}{D}\Phi\Phi^{T}\left(\vec{B}_{k}a_{ k}-\frac{\vec{S}}{\sqrt{N_{c}}}\right)\] (107) where the matrix \(\Phi\in\mathbb{R}^{r\times d_{k}}\) and vector \(\vec{B}_{k}\in\mathbb{R}^{r}\) are the feature matrix(Eq. (77)) and parameters for the \(k^{th}\) skill respectively. As \(D\to\infty\), the matrix \(\Phi\Phi^{T}\) becomes a rank \(r\) identity matrix scaled by the frequency of the skill: \[\lim_{D\to\infty}\frac{1}{D}(\Phi\Phi^{T})_{ll^{\prime}}=\mathbf{E}_{I,X}\left[ e_{k,l}(k,X)e_{k,l^{\prime}}(k,X)\right]=\mathcal{P}(k)\delta_{l,l^{\prime}}.\] (108) Plugging in \(\Phi\Phi^{T}\), \[\frac{dB_{k,l}}{dt}=-\eta\mathcal{P}(k)a_{k}\left(B_{k,l}a_{k}-\frac{S}{\sqrt{ N_{c}}}\right).\] (109) Assuming the initialization in Proposition 1, we can show that \(a_{k}(\infty)B_{k,l}(\infty)=S/\sqrt{N_{c}}\) for \(l\leq r\). From Eq. (7), the skill strength \(\mathcal{R}_{k}(\infty)\) is \[\mathcal{R}_{k}(\infty) =\sum_{l=1}^{r}\frac{S}{\sqrt{N_{c}}}\mathbf{E}_{X}\left[e_{k,l}(k,X)g_{k}(k,X)\right]\] (110) \[=S\frac{r}{N_{c}},\] (111) where we used Eq. (20) for the linear correlation between \(e_{k,l}\) and \(g_{k}\).

Time emergence example in NN

In this section, we discuss an example for the time emergence case (Fig. 1(a)) in which the saturation of skill in an NN consists of multiple saturating'modes' as in Fig. 8.

Task.We assume an input \(X\in\mathbb{R}^{3\times 8}\) (note that we are not using \(X\) as a random variable) that is all \(8\) possible inputs for bits with dimension \(3\). The target \(Y\) is the parity function scaled by \(S\).

\[X=\begin{pmatrix}\begin{smallmatrix}0&0&0&0&1&1&1&1\\ 0&0&1&1&0&0&1&1\\ 0&1&0&1&0&1&0&1\end{smallmatrix}\end{pmatrix},\qquad Y=\begin{pmatrix} \begin{smallmatrix}S&-S&-S&S&-S&S&S&-S\end{smallmatrix}\end{pmatrix}\] (112)

NN.We assume a 2-layer width 3 NN with ReLU activation with the input dimension 3 (Fig. 8(a)). The NN has 16 parameters, but to simplify the argument, we use weight sharing so NN has only \(4\) parameters:

\[f(x;\alpha,\beta,\gamma,c)=w^{T}\sigma(Wx+b)+c\] (113)

where \(\sigma\) is the ReLU activation and \(W,b,w\) are

\[W=\begin{pmatrix}\begin{smallmatrix}-\alpha&\alpha&-\alpha\\ -\beta&\beta&-\beta\\ \gamma&-\gamma&\gamma\end{smallmatrix}\end{pmatrix},\qquad b=\begin{pmatrix} \begin{smallmatrix}0\\ \beta\\ -\gamma\end{smallmatrix}\end{pmatrix},\qquad w=\begin{pmatrix}\begin{smallmatrix} -2\alpha\\ \beta\\ \gamma\end{smallmatrix}\end{pmatrix}.\] (114)

Modes.It is easy to see that \(\alpha=\beta=\gamma=\sqrt{2S}\) and \(c=-S\) leads to the target parity function. We note that one parameter except \(c\) (i.e. \(\alpha,\beta,\gamma\)) maps to one neuron or a mode (colors in Fig. 8(a)). We define the first mode \(f^{(1)}\) as

\[f^{(1)}(x) =w_{1}\sigma(W_{1}^{T}x+b_{1})=-2\alpha^{2}\sigma(x_{2}-x_{1}-x_{ 3})\] (115) \[=-2\alpha^{2}h_{1}(x),\qquad h_{1}(x):=\sigma(x_{2}-x_{1}-x_{3}),\] (116)

where \(w_{1},b_{1}\) are the first entry of \(w,b\) respectively and \(W_{1}\) is the first row of \(W\). Note that \(f^{(1)}(x)\) takes a form similar to the multilinear model (Eq. (9)) but with \(h_{1}\) as the respective basis. We define \(f^{(2)},f^{(3)}\) similarly, and the sum of modes becomes the NN:

\[f(x)=\sum_{q=1}^{3}f^{(i)}(x)+c,\] (117)

which resembles the multilinear model with different skills.

Figure 8: **Modes in NN.** A 2-layer MLP with ReLU activations with a width of 3 and weight sharing (Eq. (114)) is trained to fit the parity function. **(a):** The skill strength \(\mathcal{R}\), because of the last layer’s linearity, can be decomposed into skill strength from each hidden neuron or each ‘mode’ (shown in different colors, Eq. (119)). **(b):** The skill strength for each mode follows a near-sigmoidal curve with different emergent/saturation times (colors) whose sum results in the total skill strength (solid black). Note that different saturation times of each mode result in a deviation from the prediction of the multilinear model with \(\mathcal{B}^{2}=1/3\) (dashed black).

Mode strength.Analogous to the skill strength in Eq. (7), we define mode \(q\)'s strength \(\mathcal{R}^{(q)}\) as

\[\mathcal{R}^{(q)}=\frac{1}{8S^{2}}Y^{T}f^{(q)}(X),\] (118)

where \(f^{(q)}(X)=[f^{(q)}(X_{1}),\cdots,f^{(q)}(X_{8})]\) and \(X_{j}\) are the \(j^{th}\) column of \(X\). By the linearity of the expectation,

\[\mathcal{R}=\sum_{q=1}^{3}\mathcal{R}^{(q)}.\] (119)

Note that constant \(c\) always has zero correlation (inner product) to the target (\(Y\)).

Analysis.The dynamics of each mode \(\mathcal{R}^{(q)}(x)\) differs from that of the multilinear model (Eq. (11)) because \(h_{q}(x)\) often depends on the parameter, and the dynamics are no longer decoupled among each mode. Nevertheless, each mode follows a sigmoid-like growth (Fig. 8(b)). We note that each mode has a different saturation time scale or is updated at different frequencies. A mode with a longer time scale leads to a longer 'tail' of saturation as discussed in the main text.

Update frequency.Because of the non-linearity, each mode differs in the gradients it receives. We can explicitly calculate the gradient for each parameter as:

\[\frac{d\alpha^{2}}{dt} =2\eta\alpha^{2}(-S-(-2\alpha^{2}+2\beta^{2}+c))\] (120) \[\frac{d\beta^{2}}{dt} =-\eta\beta^{2}(S-(-2\alpha^{2}+5\beta^{2}+5c))\] (121) \[\frac{d\gamma^{2}}{dt} =-\eta\gamma^{2}(S-(\gamma^{2}+c))\] (122) \[\frac{dc}{dt} =-\eta(2\alpha^{2}-5\beta^{2}-\gamma^{2}-8c).\] (123)

We immediately notice that \(c\) will grow the fastest for small initialization (\(\alpha,\beta,\gamma,c\ll 1\)) because it saturates exponentially while other parameters saturate sigmoidally. Considering that \(S\) is always the largest term and \(c\) saturate to \(S\) quickly, we notice that the saturation is in the order of \(\alpha^{2}\) (\(\approx 2S+2c\approx 4S\)), \(\beta^{2}\) (\(\approx-S+5c\approx 4S\)), and \(\gamma^{2}\)(\(\approx 2S\)). We observe that our crude approximation holds in Fig. 8(b): the first (\(\alpha\)) and the second (\(\beta\)) modes saturate at similar timescale, while the third mode (\(\gamma\)) requires approximately twice the time for saturation.

Details of the multilinear model

The multilinear model (Fig. 9(a)) has two identifying properties: 1) the layerwise structure and 2) \(g_{k}\) as the basis functions. In this section, we discuss the role of each property in more detail.

Multilinearity.The product of two parameters (\(a_{k}b_{k}\)) creates the layerwise structure (Fig. 9(a)) that gives rise to the emerging dynamics (sudden saturation or sigmoidal growth) in Fig. 9(b). The time emergence of NN is well-described by the sigmoidal dynamics (Fig. 1(a)); a non-sigmoidal saturation dynamics, for example, that of linear models (Fig. 10(a)), would inadequately describe the time emergence. Such dynamics have first been studied by Saxe et al. [19] (See Appendix B.2 for an overview).

Assuming a sufficiently fast decay of \(d_{k}\) for the skills, the sigmoidal growth results in a stage-like training (Appendix D) where one skill fully saturates before the next skill emerges. In Appendix D, we discuss how the stage-like training can describe the quanta model [18] and how NNs, without explicit \(g_{k}\)s, decouple each skill.

Finally, note that even though sigmoidal saturation has a resemblance to the test accuracy in grokking [48], our model is irrelevant to grokking because \(\mathcal{R}_{k}\) - which is defined over the expectation over the \(k^{th}\) skill (Eq. (7)) - appears both in the empirical loss (Eq. (11)) and the test loss: failing to describe the discrepancy between train and test accuracy in grokking.

Connection to linear models.In Section 4 and Appendix E, we have shown how the scaling laws follow from the basis functions \(g_{k}\) that decouples the loss. To analyze the role of \(g_{k}\), we can ask whether a simpler linear model with \(g_{k}\) as basis functions (Eq. (124)) also recovers the scaling laws. The answer is yes and we outline how a linear model can recover all scaling laws. In addition, we also outline how extended linear models - extended similar to Section 5 such that skills are decoupled - can recover all emergence behaviors shown in Appendix F except the time emergence.

By replacing \(a_{k}b_{k}\) with \(w_{k}\), we obtain the linear model with skill basis functions:

\[f_{T}(i,x;w)=\sum_{k=1}^{N}w_{k}(T)g_{k}(i,x).\] (124)

The dynamics of the linear model under gradient flow is

\[\mathcal{R}_{k}(T)=w_{k}(T)=S(1-e^{-\eta\frac{d_{k}}{D}T}),\] (125)

where we assumed \(w_{k}(0)=0\). The linear model follows an exponential saturation of the skill strength in contrast to the sigmoidal saturation of the multilinear model (Fig. 10).

Figure 9: **Multilinear model.****(a):** An illustration of the multilinear model which is multilinear in terms of parameters, generating a layerwise structure. The model also has the skill functions \(g_{k}\)s as basis functions. **(b):** The dynamics of the multilinear model are decoupled and each skill strength (\(\mathcal{R}_{k}\)) shows a sigmoidal growth in time. Note that less frequent skills have a more delayed growth.

Nevertheless, the linear model Eq. (125) results in the same scaling laws in Section 4. For the time scaling law, we recover the relationship between \(d\mathcal{L}_{k}/dT\) and \(d\mathcal{L}_{k}/dk\) in Appendix E.1 because \(\mathcal{R}_{k}(T)\) is a function of \(\frac{d_{k}}{D}T\) only (where \(d_{k}/D=\mathcal{P}_{s}(k)\) for \(D\to\infty\)). For the data scaling law, we recover Corollary 1 because each \(w_{k}\) (i.e. \(\mathcal{R}_{k}\)) is decoupled. For the parameter scaling law, we recover Corollary 2 trivially as the linear model shares the same basis functions.

The data and parameter emergence in Section 5 can be obtained from the linear model in Eq. (124) if we extend the model analogous to Eqs. (15) and (18). For example, we can extend the model for data emergence as

\[f_{T}(i,x;W)=\sum_{k=1}^{N}\sum_{l=1}^{D_{c}}W_{k,l}(T)e_{k,l}(i,x),\] (126)

where the matrix \(W\in\mathbb{R}^{N\times D_{c}}\) is an extension of \(w\in\mathbb{R}^{N}\) in Eq. (124), \(D_{c}\) is a fixed scalar, and \(e_{k,l}(i,x):\{0,1\}^{n_{s}+n_{b}}\to\mathbb{R}\) are functions with the following properties:

\[\mathbf{E}_{X|I=k}\left[e_{k,l}e_{k,l^{\prime}}\right]=\delta_{ll^{\prime}}, \hskip 14.226378pte_{k,l}(I\neq k,x)=0,\hskip 14.226378pt\sum_{l=1}^{D_{c}} \frac{1}{\sqrt{D_{c}}}e_{k,l}=g_{k}.\] (127)

The equivalence can be shown by Lemma 2 which states that the multilinear model finds the minimum norm solution: the solution that the linear model finds in a ridgeless regression setup.

Thus, for our setup, the basis functions play a critical role in the scaling laws and data/parameter emergences. The choice of basis functions, also known as the task-model alignment (see [23, 27]), determines the linear model's scaling laws and emergence behaviors. See Bordelon et al. [21] for a study of the scaling laws in linear models.

Figure 10: **Dynamics of linear and multilinear model.****(a):** Skill strength dynamics of the linear model (Eq. (125)) **(b):** Skill strength dynamics of the multilinear model (Eq. (11)). For the linear model, \(\mathcal{R}_{k}\) emerges from \(T=0\) for all \(d_{k}/D>0\): obstructing the stage-like training. For the multilinear model, \(\mathcal{R}_{k}\) shows a delayed emergence depending on \(d_{k}/D\): allowing the stage-like training and describing the sigmoidal time emergence in Fig. 1(a).

[MISSING_PAGE_EMPTY:34]

Rigorous derivation of the scaling laws

In Appendix E, we discussed the scaling laws in simplified settings, favoring intuition over mathematical rigor. Building upon the intuitive understanding developed in Appendix E, we now turn our attention to a rigorous analysis of the scaling laws. In this section, we will derive general scaling laws by considering a comprehensive set of parameters and variables. Our goal is to establish the conditions under which these scaling laws hold and to quantify the associated error terms. By explicitly analyzing the error terms, this section aims to provide a rigorous assessment of the validity and limitations of our scaling law estimates.

### General set up, repeated

We go back to the most general settings possible. Our starting point is Eq. (27), which describes the dynamics of \(\mathcal{R}_{k}\) and \(\mathcal{L}_{k}\) valid for \(k\leq N\):

\[\mathcal{L}_{k}=\frac{S^{2}}{2\left(1+\left(\frac{S}{\mathcal{R}_{k}(0)}-1 \right)^{-1}e^{2\eta\frac{d_{k}}{D}ST}\right)^{2}}\] (27)

We do not use skills for indices \(k>N\) in our model, but we can still denote

\[\mathcal{R}_{k}=0\quad\text{and}\quad\mathcal{L}_{k}=\frac{S^{2}}{2}.\] (128)

For \(\mathcal{P}_{s}(k)=Ak^{-\alpha-1}\), the total loss is given as

\[\mathcal{L}=\sum_{k=1}^{n_{s}}\mathcal{P}_{s}(k)\mathcal{L}_{k}=\sum_{k=1}^{N }\mathcal{P}_{s}(k)\mathcal{L}_{k}+\sum_{k=N+1}^{n_{s}}\mathcal{P}_{s}(k) \frac{S^{2}}{2}.\] (129)

When \(n_{s},N,T\) are all set, their dependency with the data is only determined by the statistics \(d_{k}\), the number of data with \(i^{(j)}=k\). We assumed that \((i,x)\in I\times\{0,1\}^{n_{d}}\) was collected as random samples with \(i\) following the Zipfian distribution of size \(n_{s}\) and exponent \(\alpha+1\), or equivalently \(P(i=k)=\mathcal{P}_{s}(k)=Ak^{-\alpha-1}\) for \(1\leq k\leq n_{s}\). Then \((d_{1},\cdots,d_{n_{s}})\) is a vector denoting the number of occurrences in \(D\) independent sampling from that distribution. It follows that \(d_{i}\) follows binomial distribution \(B(D,\mathcal{P}_{s}(k))\).

In this complete perspective, our loss is dependent on all of those parameters and variables

\[\mathcal{L}=\mathcal{L}(n_{S},\mathcal{D},\mathcal{R}_{init},N,T)\] (130)

where \(\mathcal{R}_{init}=(\mathcal{R}_{1}(0),\cdots,\mathcal{R}_{N}(0))\) denotes the vector representing initial condition. We will also simply denote \(r_{k}=\mathcal{R}_{k}(0)\). We will not assume much on \(r_{k}\), but we absolutely need \(0<r_{k}<S\) for dynamics to hold, and we also should have

\[\sum_{k=1}^{n_{s}}\mathcal{P}_{s}(k)r_{k}^{2}=\mathbf{E}[f(0)^{2}]\ll S^{2}.\] (131)

\begin{table}
\begin{tabular}{c c c c c} \hline \hline Large resource & Condition & Scaling law & Constant & Statement \\ \hline \(D\gg T^{3}\) & \(N^{\alpha+1}=o(T)\) & \(\mathcal{L}=\mathcal{A}_{N}N^{-\alpha}\) & Theorem 1 & Theorem 1 \\ \(D\gg NT^{2},T^{3}\) & \(N^{\alpha+1}\gg T\) & \(\mathcal{L}=\mathcal{A}_{T}T^{-\alpha/(\alpha+1)}\) & Theorem 4 & Theorems 2 and 3 \\ \(D\gg T^{3}\) & \(N^{\alpha+1}\approx T\) & \(\mathcal{L}=\mathcal{A}_{C}C^{-\alpha/(\alpha+2)}\) & Corollary 5 & Corollary 4 \\ \(T\gg D(\log D)^{1+\epsilon}\) & \(N^{\alpha+1}=o(D)\) & \(\mathcal{L}=\mathcal{A}_{N}N^{-\alpha}\) & Theorem 5 & Theorem 5 \\ \(T\gg D(\log D)^{1+\epsilon}\) & \(N^{\alpha+1}\gg D\) & \(\mathcal{L}=\mathcal{A}_{D}D^{-\alpha/(\alpha+1)}\) & Theorem 5 & Theorem 5 \\ \hline \hline \end{tabular}
\end{table}
Table 6: **Scaling laws and their conditions.** The leftmost column indicates the condition for the ‘large resource’ – large enough to be treated as infinity, while the second column is the condition between the other two resources for the scaling law (third column). The last two columns show where the statement for the prefactor constant (e.g. \(\mathcal{A}_{N}\) for scaling law \(\mathcal{L}=\mathcal{A}_{N}N^{-\alpha}\)) and the scaling law (with the assumptions and explicit error terms) are given. Note that whenever \(T\) appears in theorems and corollaries, \(\eta S\) is multiplied to make it dimensionless.

We will not impose any particular distribution on \(\mathcal{R}_{init}\). Instead, we will try to identify sufficient conditions on \(r_{k}\) for our desired result to hold, and those conditions will differ by the situation we are considering. For example, in Theorems 2 and 3 where we prove time scaling law \(\mathcal{L}=\Theta(T^{-\alpha/(\alpha+1)})\) for large enough \(D\) and bottleneck \(T\), we only require \(\epsilon<r_{k}<S/2\) for some \(\epsilon>0\). However, the exact constant depends on the distribution of \(r_{k}\), and figuring out the explicit constant seems to be only feasible when we fix \(r_{k}=r\) as in Theorem 4.

### Estimates for large \(D\)

We will first consider the situation where \(D\) becomes the 'large resource' so that its effect on the loss function is negligible. The number of data \(d_{k}\) follows binomial distribution \(B(D,\mathcal{P}_{s}(k))\), so \(d_{k}/D\) converges to \(\mathcal{P}_{s}(k)\) for large enough \(D\). So taking the limit of \(\mathcal{L}\) when we let \(D\to\infty\) has the effect of replacing \(d_{k}/D\) by \(\mathcal{P}_{s}(k)\) in the expression of \(\mathcal{L}\). We will establish an explicit inequality comparing the difference between \(\mathcal{L}\) and this limit.

**Lemma 4**.: _For a function \(F:\mathbb{R}\to\mathbb{R}\) with its total variation \(V(F)\) bounded, we have_

\[\left|\mathbf{E}_{\mathcal{D}}\left[F(\frac{d_{k}}{D})\right]-\mathbf{E}_{z \sim\mathcal{N}(\mathcal{P}_{s}(k),\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))/D )}\left[F(z)\right]\right|<\frac{V(F)}{\sqrt{D}\sqrt{\mathcal{P}_{s}(k)(1- \mathcal{P}_{s}(k))}}\] (132)

_where \(\mathcal{N}(\mu,\sigma^{2})\) denotes normal distribution of mean \(\mu\) and variance \(\sigma^{2}\)._

* This is just an application of the Berry-Esseen inequality (with constant \(1\), see [49] for modern treatment) applied to \(d_{k}\) following binomial distribution \(B(D,\mathcal{P}_{s}(k))\). \(\blacksquare\)

**Lemma 5**.: _Let \(F:\mathbb{R}\to\mathbb{R}\) be a \(C^{2}\) function such that \(F^{\prime\prime}\) is bounded. Then we have_

\[\left|\mathbf{E}_{z\sim\mathcal{N}(\mathcal{P}_{s}(k),\mathcal{P}_{s}(k)(1- \mathcal{P}_{s}(k))/D)}\left[F(z)\right]-F(\mathcal{P}_{s}(k))\right|\leq \frac{\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))}{2D}\mathrm{sup}|F^{\prime \prime}|.\] (133)

* First, we apply Taylor's theorem to show that \[|F(z)-F(\mathcal{P}_{s}(k))-F^{\prime}(\mathcal{P}_{s}(k))(z-\mathcal{P}_{s}( k))|\leq\frac{(z-\mathcal{P}_{s}(k))^{2}}{2}\sup|F^{\prime\prime}|.\] (134) Taking expectation when \(z\) follows normal distribution \(\mathcal{N}(\mathcal{P}_{s}(k),\frac{\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k)) }{D})\) gives \[|\mathbf{E}_{z}\left[F(z)-F(\mathcal{P}_{s}(k))\right]|= |\mathbf{E}_{z}\left[F(z)-F(\mathcal{P}_{s}(k))-F^{\prime}( \mathcal{P}_{s}(k))(z-\mathcal{P}_{s}(k))\right]|\] (135) \[\leq \mathbf{E}_{z}\left[|F(z)-F(\mathcal{P}_{s}(k))-F^{\prime}( \mathcal{P}_{s}(k))(z-\mathcal{P}_{s}(k))|\right]\] (136) \[\leq \mathbf{E}_{z}\left[\frac{(z-\mathcal{P}_{s}(k))^{2}}{2}\sup|F^{ \prime\prime}|\right]\] (137) \[= \frac{\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))}{2D}\mathrm{sup}|F ^{\prime\prime}|.\] (138)

\(\blacksquare\)

**Proposition 3**.: _We have_

\[\left|\mathbf{E}_{\mathcal{D}}\left[\mathcal{L}_{k}\right]-\frac{S^{2}}{2 \left(1+\left(\frac{S}{r_{k}}-1\right)^{-1}e^{2\eta\mathcal{P}_{s}(k)ST} \right)^{2}}\right|<\frac{2^{\alpha}S^{2}}{\sqrt{D\mathcal{P}_{s}(k)}}+\frac{4S ^{4}\eta^{2}T^{2}\mathcal{P}_{s}(k)}{D}.\] (139)

* Consider the function \(F:\mathbb{R}\to\mathbb{R}\) given as \[F(z)=\frac{S^{2}}{2\left(1+\left(\frac{S}{r_{k}}-1\right)^{-1}e^{2\eta STz} \right)^{2}}.\] (140) This function is monotone decreasing and \(C^{2}\) on the whole domain, and its supremum and infimum are given as \[\sup F=\lim_{z\to-\infty}F(z)=\frac{S^{2}}{2}\quad\text{and}\quad\inf F=\lim_ {z\to\infty}F(z)=0.\] (141)This implies that

\[V(F)=\sup F-\inf F=\frac{S^{2}}{2}.\] (142)

Also, we will show that \(F^{\prime\prime}\) is globally bounded. We first calculate

\[F^{\prime\prime}(z)=-4S^{3}r_{k}(1-\frac{r_{k}}{S})^{2}\eta^{2}T^{2}\frac{e^{2 \eta STz}(1-\frac{r_{k}}{S}-\frac{2r_{k}}{S}e^{2\eta STz})}{\left(1-\frac{r_{k} }{S}+\frac{r_{k}}{S}e^{2\eta STz}\right)^{4}}.\] (143)

We consider the following inequalities

\[e^{2\eta STz} \leq\frac{S}{r_{k}}\left(1-\frac{r_{k}}{S}+\frac{r_{k}}{S}e^{2 \eta STz}\right)\] (144) \[\left|1-\frac{r_{k}}{S}-\frac{2r_{k}}{S}e^{2\eta STz}\right| \leq\left|1-\frac{r_{k}}{S}\right|+\frac{2r_{k}}{S}e^{2\eta STz}<2 \left(1+\frac{r_{k}}{S}(e^{2\eta STz}-1)\right)\] (145)

to show that

\[|F^{\prime\prime}(z)|<4S^{3}r_{k}(1-\frac{r_{k}}{S})^{2}\eta^{2}T^{2}\frac{ \frac{2S}{r_{k}}\left(1-\frac{r_{k}}{S}+\frac{r_{k}}{S}e^{2\eta STz}\right)^ {2}}{\left(1-\frac{r_{k}}{S}+\frac{r_{k}}{S}e^{2\eta STz}\right)^{4}}<8S^{4} \eta^{2}T^{2}\] (146)

for all \(z\). Thus we can apply both Lemma 4 and Lemma 5 to this function \(F\) and we have

\[\left|\mathbf{E}_{\mathcal{D}}\left[F(\frac{d_{k}}{D})\right]-F( \mathcal{P}_{s}(k))\right|< \frac{V(F)}{\sqrt{D}\sqrt{\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k) )}}+\frac{\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))}{2D}\mathrm{sup}|F^{ \prime\prime}|\] \[< \frac{S^{2}}{2\sqrt{D}\sqrt{\mathcal{P}_{s}(k)(1-\mathcal{P}_{s} (k))}}+\frac{4\mathcal{P}_{s}(k)S^{4}\eta^{2}T^{2}}{D}\] \[< \frac{2^{\alpha}S^{2}}{\sqrt{D\mathcal{P}_{s}(k)}}+\frac{4 \mathcal{P}_{s}(k)S^{4}\eta^{2}T^{2}}{D}\] (147)

where the last line follows from that we always have

\[1-\mathcal{P}_{s}(k)\geq 1-\mathcal{P}_{s}(1)=\frac{2^{-(\alpha+1)}+\cdots +n_{s}^{-(\alpha+1)}}{1+2^{-(\alpha+1)}+\cdots+n_{s}^{-(\alpha+1)}}>\frac{2^{- (\alpha+1)}}{1+2^{-(\alpha+1)}}>\frac{1}{2^{2(\alpha+1)}}.\] (148)

**Lemma 6**.: _For any integer \(N\) and \(\sigma\geq 1/2\) and \(\sigma\neq 1\), we have_

\[\sum_{k=1}^{N}k^{-\sigma}=\zeta(\sigma)+\frac{N^{1-\sigma}}{1-\sigma}+O(N^{- \sigma})\] (149)

_where \(\zeta\) is the Riemann zeta function (defined over the whole complex plane except \(1\) via analytic continuation). In addition,_

\[\sum_{k=1}^{N}k^{-1}=\log N+\gamma+O(N^{-1})\] (150)

_where \(\gamma=0.5772156649...\) is Euler's constant._

Proof.: See Corollary 1.15 of [50], or other analytic number theory textbooks. 

**Proposition 4**.: _(Large \(D\) approximation) We have_

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}]-\sum_{k=1}^{N}\mathcal{P}_ {s}(k)\frac{S^{2}}{2\left(1+\left(\frac{S}{r_{k}}-1\right)^{-1}e^{2\eta \mathcal{P}_{s}(k)ST}\right)^{2}}-\sum_{k=N+1}^{n_{s}}\mathcal{P}_{s}(k)\frac{ S^{2}}{2}\] (151) \[= O\left(S^{2}D^{-1/2}f_{\alpha}(N)+S^{4}\eta^{2}T^{2}D^{-1}\right)\] (152)

_where_

\[f_{\alpha}(N)=\begin{cases}1&\text{if }\alpha>1\\ \log N&\text{if }\alpha=1\\ N^{(1-\alpha)/2}&\text{if }\alpha<1.\end{cases}\] (153)

_The constant on the \(O\) term only depends on \(\alpha\)._

**Proof** From the description of \(\mathcal{L}\) in Eq. (129), we have

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}]-\sum_{k=1}^{N}\mathcal{P}_{s}(k) \frac{S^{2}}{2\left(1+\left(\frac{S}{r_{k}}-1\right)^{-1}e^{2\eta \mathcal{P}_{s}(k)ST}\right)^{2}}-\sum_{k=N+1}^{n_{s}}\mathcal{P}_{s}(k)\frac{S ^{2}}{2}\] (154) \[= \sum_{k=1}^{N}\mathcal{P}_{s}(k)\left(\mathbf{E}_{\mathcal{D}}[ \mathcal{L}_{k}]-\frac{S^{2}}{2\left(1+\left(\frac{S}{r_{k}}-1\right)^{-1}e^{ 2\eta\mathcal{P}_{s}(k)ST}\right)^{2}}\right).\] (155)

We apply Proposition 3 to give

\[\sum_{k=1}^{N}\mathcal{P}_{s}(k)\left(\mathbf{E}_{\mathcal{D}}[\mathcal{L}_{k} ]-\frac{S^{2}}{2\left(1+\left(\frac{S}{r_{k}}-1\right)^{-1}e^{2\eta\mathcal{P} _{s}(k)ST}\right)^{2}}\right)<\sum_{k=1}^{N}\mathcal{P}_{s}(k)\left(\frac{2^{ \alpha}S^{2}}{\sqrt{D\mathcal{P}_{s}(k)}}+\frac{4S^{4}\eta^{2}T^{2}\mathcal{P} _{s}(k)}{D}\right).\] (156)

Each of these sum involving \(\mathcal{P}_{s}(k)\) is bounded as

\[\sum_{k=1}^{N}\mathcal{P}_{s}(k)^{2}<\left(\sum_{k=1}^{N}\mathcal{P}_{s}(k) \right)^{2}<1\] (157)

and

\[\sum_{k=1}^{N}\sqrt{\mathcal{P}_{s}(k)}<\sum_{k=1}^{N}k^{-(\alpha+1)/2}=O(f_{ \alpha}(N))\] (158)

which follows from Lemma 6. Combining those two gives

\[\sum_{k=1}^{N}\mathcal{P}_{s}(k)\left(\frac{2^{\alpha}S^{2}}{\sqrt{D\mathcal{ P}_{s}(k)}}+\frac{S^{4}\eta^{2}T^{2}\mathcal{P}_{s}(k)}{D}\right)=O\left(S^{2}D^{- 1/2}f_{\alpha}(N)+S^{4}\eta^{2}T^{2}D^{-1}\right).\] (159)

While Proposition 4 holds for any \(D\), it becomes only meaningful if the resulting error terms are less than the main term we desire. We will revisit this when the exact main term is found, and determine the sufficient size of \(D\) for error terms to become small enough.

### Estimates for not too small \(n_{s}\)

We next discuss the effect of \(n_{s}\). When \(n_{s}\to\infty\) heuristically, then intuitively we have \(\mathcal{P}_{s}(k)\to k^{-(\alpha+1)}/\zeta(\alpha+1)\). We will discuss the difference between when we regard \(n_{s}\) as \(\infty\) and when we do not.

**Proposition 5**.: _The following equations hold:_

\[A^{-1}=\sum_{k=1}^{n_{s}}k^{-(\alpha+1)}=\zeta(\alpha+1)-\frac{n_{s}^{-\alpha} }{\alpha}+O(n_{s}^{-\alpha-1})\] (160)

\[\mathcal{P}_{s}(k)=\frac{k^{-\alpha-1}}{\zeta(\alpha+1)}\left(1+\frac{n_{s}^{- \alpha}}{\alpha\zeta(\alpha+1)}O(n_{s}^{-\alpha-1})\right)\] (161)

\[\sum_{k=N+1}^{n_{s}}\mathcal{P}_{s}(k)=\frac{N^{-\alpha}-n_{s}^{-\alpha}}{ \alpha\zeta(\alpha+1)}+O(N^{-\min(\alpha+1,2\alpha)})\] (162)

_All implied constants on \(O\) only depend on \(\alpha\)._

**Proof** The first statement Eq. (160) follows from substituting \(\sigma=\alpha+1\) in Lemma 6. As \(\mathcal{P}_{s}(k)=Ak^{-(\alpha+1)}\), the second statement Eq. (161) immediately follows. If we substitute \(n_{s}=N\) into Eq. (160) and calculate differences between them, we obtain

\[\sum_{k=N+1}^{n_{s}}k^{-\alpha-1}=\frac{N^{-\alpha}-n_{s}^{-\alpha}}{\alpha}+O( N^{-\alpha-1}).\] (163)

Thus we have

\[\sum_{k=N+1}^{n_{s}}\mathcal{P}_{s}(k)=A\sum_{k=N+1}^{n_{s}}k^{-(\alpha+1)}= \frac{N^{-\alpha}-n_{s}^{-\alpha}}{\alpha\zeta(\alpha+1)}+O\left(N^{-\alpha-1 }+(N^{-\alpha}-n_{s}^{-\alpha})n_{s}^{-\alpha}\right).\] (164)

Regardless of the size of \(n_{s}\), We always have

\[(N^{-\alpha}-n_{s}^{-\alpha})n_{s}^{-\alpha}\leq\left(\frac{N^{-\alpha}}{2} \right)^{2}=\frac{N^{-2\alpha}}{4}\] (165)

so the third statement Eq. (162) follows.

We go back to the description of total loss given in Eq. (129) as

\[\mathcal{L}=\sum_{k=1}^{N}\mathcal{P}_{s}(k)\mathcal{L}_{k}+\sum_{k=N+1}^{n_{ s}}\mathcal{P}_{s}(k)\frac{S^{2}}{2}\] (129)

and we take its expectation in \(\mathcal{D}\). Proposition 4 suggests that its limit when \(D\to\infty\) is given as

\[\lim_{D\to\infty}\mathbf{E}_{\mathcal{D}}[\mathcal{L}]=\sum_{k=1}^{N}\mathcal{ P}_{s}(k)\frac{S^{2}}{2\left(1+\left(\frac{S}{r_{k}}-1\right)^{-1}e^{2\eta \mathcal{P}_{s}(k)ST}\right)^{2}}+\sum_{k=N+1}^{n_{s}}\mathcal{P}_{s}(k)\frac{ S^{2}}{2}.\] (166)

Denote

\[\mathscr{L}_{1}=\sum_{k=1}^{N}\mathcal{P}_{s}(k)\frac{S^{2}}{2 \left(1+\left(\frac{S}{r_{k}}-1\right)^{-1}e^{2\eta\mathcal{P}_{s}(k)ST} \right)^{2}}\] (167) \[\mathscr{L}_{2}=\sum_{k=N+1}^{n_{s}}\mathcal{P}_{s}(k)\frac{S^{2 }}{2}.\] (168)

We discuss the effect of \(n_{s}\) in \(\mathscr{L}_{1}\) and \(\mathscr{L}_{2}\), by comparing limit of \(\mathscr{L}_{1}\) and \(\mathscr{L}_{2}\) when \(n_{s}\to\infty\) and their original values.

* For the term \(\mathscr{L}_{1}\), the change of letting \(n_{s}\) as finite value from \(n_{s}\to\infty\) has effect of multiplying \(T\) by \(1+n_{s}^{-\alpha}/(\alpha\zeta(\alpha+1))\), and multiplying whole \(\mathscr{L}_{1}\) by \(1+n_{s}^{-\alpha}/(\alpha\zeta(\alpha+1))\). It can be equivalently put as \[\mathscr{L}_{1}(n_{s},N,T)=\left(1+\frac{n_{s}^{-\alpha}}{\alpha\zeta(\alpha+ 1)}+O(n_{s}^{-\alpha-1})\right)\mathscr{L}_{1}\left(\infty,N,T\left(1+\frac{n_ {s}^{-\alpha}}{\alpha\zeta(\alpha+1)}+O(n_{s}^{-\alpha-1})\right)\right).\] (169) We always have \(n_{s}>N\) and \(N\to\infty\) eventually, so if dependency of \(\mathscr{L}_{1}\) with respect to \(T\) is at most polynomial order, then change of main term of \(\mathscr{L}_{1}\) is negligible. We can't establish exact statements yet without the descriptions of size of \(\mathcal{L}_{1}\).
* The term \(\mathscr{L}_{2}\) only depends on \(N\) and \(n_{s}\), not on \(T\). Applying Proposition 5 (especially Eq. (162)) gives \[\mathscr{L}_{2}(n_{s},N,T)=\frac{N^{-\alpha}-n_{s}^{-\alpha}}{\alpha\zeta(\alpha +1)}\frac{S^{2}}{2}+O(N^{-\min(\alpha+1,2\alpha)}S^{2})\] (170) When \(n_{s}\) grows faster than \(N\) then \(n_{s}^{-\alpha}\) part is totally negligible, and when \(n_{s}\) has same order as \(N\) then \(n_{s}^{-\alpha}\) affects the constant for main term of \(\mathscr{L}_{2}\). Things might get little complicated when \(n_{s}=N+o(N)\), where \(N^{-\alpha}-n_{s}^{-\alpha}=o(N^{-\alpha})\) can happen then.

* Comparing size of \(\mathscr{L}_{1}\) and \(\mathscr{L}_{2}\) mainly depends on time. The term \(\mathscr{L}_{2}\) is fixed, and \(\mathscr{L}_{1}\) decreases as \(T\) increases. For \(T=\infty\) we have \(\mathscr{L}_{1}=0\), so \(\mathscr{L}_{2}\) having order \(N^{-\alpha}\) dominates (this proves scaling law for \(N\) of exponent \(\alpha\)), so restriction on \(n_{s}\) becomes quite substantial. For small \(T\) and large \(N\) where the size of \(\mathscr{L}_{2}\) is small, we can expect the restriction on \(n_{s}\) to be less substantial. For example, in the extreme case \(N=\infty\), we have \(\mathscr{L}_{2}=0\), and \(n_{s}\) does not matter at all (except that, of course, it should satisfy \(n_{s}\geq N\)).

For such reasons, it is hard to quantify exact conditions for \(n_{s}\) such that error terms are controlled, unless we specify relative growth of \((N,T)\). However, \(n_{s}=\omega(N)\) suffices to assure that setting \(n_{s}=\infty\) has zero effect on the main term. We will not worry about \(n_{s}\) in this setting anymore too, and come back to this at the very end to determine enough \(n_{s}\).

### Estimating main terms

We assume \(D=\infty\) and \(n_{s}=\infty\) - virtually implying that \(d_{k}/D=\mathcal{P}_{s}(k)\) and \(\mathcal{P}_{s}(k)=k^{-\alpha-1}/\zeta(\alpha+1)\) (calculated by rule of \(n_{s}=\infty\)). We decomposed our main term into

\[\lim_{n_{s}\to\infty}\lim_{D\to\infty}\mathbf{E}_{\mathcal{D}}[\mathcal{L}]= \mathscr{L}_{1}+\mathscr{L}_{2}\] (171)

where

\[\mathscr{L}_{1}=\sum_{k=1}^{N}\mathcal{P}_{s}(k)\frac{S^{2}}{2\left(1+\left( \frac{S}{r_{k}}-1\right)^{-1}e^{2\eta\mathcal{P}_{s}(k)ST}\right)^{2}}\] (172)

and

\[\mathscr{L}_{2}=\sum_{k=N+1}^{\infty}\mathcal{P}_{s}(k)\frac{S^{2}}{2}.\] (173)

By Proposition 5, \(\mathcal{L}_{2}\) is determined almost completely as

\[\mathscr{L}_{2}=\frac{S^{2}N^{-\alpha}}{2\alpha\zeta(\alpha+1)}+O(N^{-\alpha-1 }).\] (174)

Now focus on \(\mathscr{L}_{1}\). For

\[F(z)=\frac{S^{2}}{2\left(1+\left(\frac{S}{r_{k}}-1\right)^{-1}e^{2\eta STz} \right)^{2}}\] (175)

(note: it really depends on \(r_{k}\) so it is correct to write \(F_{k}\), but for convenience we will keep using \(F\).) one can express \(\mathscr{L}_{1}\) as

\[\mathscr{L}_{1}=\sum_{k=1}^{N}\mathcal{P}_{s}(k)F(\mathcal{P}_{s}(k)).\] (176)

**Lemma 7**.: _Let \(F(z)\) be defined as Eq. (175)._

1. _(Estimate for large_ \(z\)_) We have_ \[0\leq F(z)\leq\frac{(S-r_{k})^{2}}{2}{\rm min}\left(1,\frac{S^{2}}{r_{k}^{2}}e ^{-4\eta STz}\right).\] (177)
2. _(Estimate for small_ \(z\)_) For_ \(z\geq 0\)_, we have_ \[\frac{(S-r_{k})^{2}}{2}-\frac{8\eta S^{3}T}{27}z\leq F(z)\leq\frac{(S-r_{k})^{ 2}}{2}.\] (178)

**Proof**

1. The left side is obvious. For the right side, \(F(z)\leq(S-r_{k})^{2}/2\) follows from noting that \(F(0)=\frac{(S-r_{k})^{2}}{2}\) and proving \(F^{\prime}(z)\leq 0\), and \(F(z)\leq\frac{(S-r_{k})^{2}}{2}\frac{S^{2}}{r_{k}^{2}}e^{-4\eta STz}\) follows from just replacing \(1+\left(\frac{S}{r_{k}}-1\right)^{-1}e^{2\eta STz}\) in the denominator of \(F\) by \(\left(\frac{S}{r_{k}}-1\right)^{-1}e^{2\eta STz}\).

2. For the left side, it suffices to show \(-F^{\prime}(z)\leq\frac{8nS^{3}T}{27}\). One can calculate \[F^{\prime}(z)=-2S^{2}r_{k}(1-\frac{r_{k}}{S})^{2}\eta T\frac{e^{2\eta STz}}{\left( 1+\frac{r_{k}}{S}(e^{2\eta STz}-1)\right)^{3}}\] (179) and \[F^{\prime\prime}(z)=-4S^{3}r_{k}(1-\frac{r_{k}}{S})^{2}\eta^{2}T^{2}\frac{e^{2 \eta STz}(1-\frac{r_{k}}{S}-\frac{2r_{k}}{S}e^{2\eta STz})}{\left(1+\frac{r_{ k}}{S}(e^{2\eta STz}-1)\right)^{4}}\] (180) so \(F\) has unique inflection point at \[1-\frac{r_{k}}{S}-\frac{2r_{k}}{S}e^{2\eta STz}=0\quad\Rightarrow\quad e^{2 \eta STZ}=\frac{1}{2}\left(\frac{S}{r_{k}}-1\right)\] (181) and this point is where \(-F^{\prime}(z)\) obtains maximum. Substituting this to the expression of \(F^{\prime}(z)\) gives \(-F^{\prime}(z)=\frac{8nS^{3}T}{27}\).

Our threshold for distinguishing two approximation methods will be set as \(z=z_{0}=(\zeta(\alpha+1)\eta ST)^{-1}\), where both two error terms are bounded by \(O(S^{2})\). The constant \(\zeta(\alpha+1)\) is set to make later calculations much easier. Applying Lemma 7 gives

\[\mathscr{L}_{1} =\sum_{k=1}^{N}\mathcal{P}_{s}(k)F(\mathcal{P}_{s}(k))\] (182) \[=\sum_{1\leq k\leq N,\mathcal{P}_{s}(k)<z_{0}}\frac{(S-r_{k})^{2} }{2}\mathcal{P}_{s}(k)\] \[\quad+O\left(\eta S^{3}T\sum_{1\leq k\leq N,\mathcal{P}_{s}(k)<z_ {0}}\mathcal{P}_{s}(k)^{2}+S^{2}\sum_{1\leq k\leq N,\mathcal{P}_{s}(k)>z_{0}} \mathcal{P}_{s}(k){\rm min}\left(1,\frac{S^{2}}{r_{k}^{2}}e^{-4\eta ST \mathcal{P}_{s}(k)}\right)\right).\] (183)

Denote

\[\mathscr{M} =\sum_{1\leq k\leq N,\mathcal{P}_{s}(k)<z_{0}}\frac{(S-r_{k})^{2 }}{2}\mathcal{P}_{s}(k)\] (184) \[\mathscr{E}_{1} =\eta S^{3}T\sum_{1\leq k\leq N,\mathcal{P}_{s}(k)<z_{0}}\mathcal{ P}_{s}(k)^{2}\] (185) \[\mathscr{E}_{2} =S^{2}\sum_{1\leq k\leq N,\mathcal{P}_{s}(k)>z_{0}}\mathcal{P}_{ s}(k){\rm min}\left(1,\frac{S^{2}}{r_{k}^{2}}e^{-4\eta ST\mathcal{P}_{s}(k)} \right).\] (186)

**Proposition 6**.: _Suppose that there exists \(0<r<\sqrt{S}\) such that \(r\leq r_{k}<S/2\) for all \(k\). In the decomposition of_

\[\lim_{n_{s}\to\infty}\lim_{D\to\infty}\mathbf{E}_{\mathcal{D}}[\mathcal{L}]= \mathscr{M}+\mathscr{L}_{2}+O(\mathscr{E}_{1}+\mathscr{E}_{2})\] (187)

_given as above, we have the following bound._

1. _If_ \((\eta ST)^{1/(\alpha+1)}>N\)_, then_ \[\mathscr{L}_{2} =\frac{S^{2}N^{-\alpha}}{2\alpha\zeta(\alpha+1)}+O(S^{2}N^{-\alpha -1})\] (188) \[\mathscr{M} =\mathscr{E}_{1}=0\] (189) \[\mathscr{E}_{2} =O\left(S^{2}(\log(S/r))^{\alpha/(\alpha+1)}(\eta ST)^{-\alpha/( \alpha+1)}\right)\] (190)2. _If_ \((\eta ST)^{1/(\alpha+1)}<N\)_, then_ \[\mathscr{L}_{2}+\mathscr{M} =\Theta\left(S^{2}\sum_{k>(\eta ST)^{1/(\alpha+1)}}\mathcal{P}_{s}( k)\right)=\Theta(S^{2}(\eta ST)^{-\alpha/(\alpha+1)})\] (191) \[\mathscr{E}_{1} =O\left(S^{2}(\eta ST)^{-\alpha/(\alpha+1)}\right)\] (192) \[\mathscr{E}_{2} =O\left(S^{2}(\log(S/r))^{\alpha/(\alpha+1)}(\eta ST)^{-\alpha/ (\alpha+1)}\right)\] (193)

_Here all constants in \(O\) and \(\Theta\) terms are absolute with respect to \(\eta,S,T,N\). (They may depend on \(\alpha\).)_

* We first note that the condition \(\mathcal{P}_{s}(k)<z_{0}=(\zeta(\alpha+1)\eta ST)^{-1}\) is equivalent to \[\mathcal{P}_{s}(k)<z_{0}=(\zeta(\alpha+1)\eta ST)^{-1}\,\Leftrightarrow\,k ^{-\alpha-1}<\frac{1}{\eta ST}\,\Leftrightarrow\,k>(\eta ST)^{1/(\alpha+1)}.\] (194) Thus we can rephrase the descriptions of terms as \[\mathscr{M} =\sum_{(\eta ST)^{1/(\alpha+1)}<k\leq N}\frac{(S-r_{k})^{2}}{2} \mathcal{P}_{s}(k)\] (195) \[\mathscr{E}_{1} =\eta S^{3}T\sum_{(\eta ST)^{1/(\alpha+1)}<k\leq N}\mathcal{P}_{ s}(k)^{2}\] (196) \[\mathscr{E}_{2} =S^{2}\sum_{k\leq\min((\eta ST)^{1/(\alpha+1)},N)}\mathcal{P}_{ s}(k)\min\left(1,\frac{S^{2}}{r_{k}^{2}}e^{-4\eta ST\mathcal{P}_{s}(k)} \right).\] (197) Applying Proposition 5 easily shows that \[\mathscr{L}_{2}=\frac{S^{2}N^{-\alpha}}{2\alpha\zeta(\alpha+1)}+O(S^{2}N^{- \alpha-1}).\] (198) For \(\mathscr{M}\) and \(\mathscr{E}_{1}\), we will consider them by dividing two cases depending on whether \((\eta ST)^{1/(\alpha+1)}>N\) or \((\eta ST)^{1/(\alpha+1)}<N\). If \((\eta ST)^{1/(\alpha+1)}>N\), then the condition \((\eta ST)^{1/(\alpha+1)}<k\leq N\) is never satisfied, so \(\mathscr{M}=\mathscr{E}_{1}=0\). Now suppose \((\eta ST)^{1/(\alpha+1)}<N\). We first note that \[\mathscr{L}_{2}+\mathscr{M}=\sum_{(\eta ST)^{1/(\alpha+1)}<k\leq N}\frac{(S-r _{k})^{2}}{2}\mathcal{P}_{s}(k)+\sum_{k>N}\frac{S^{2}}{2}\mathcal{P}_{s}(k).\] (199) As \((S-r_{k})^{2}=\Theta(S^{2})\), we can let \[\mathscr{L}_{2}+\mathscr{M}=\Theta\left(S^{2}\sum_{k>(\eta ST)^{1/(\alpha+1)}} \mathcal{P}_{s}(k)\right)\] (200) and using Proposition 5 gives the desired estimate \(\mathscr{L}_{2}+\mathscr{M}=\Theta(S^{2}(\eta ST)^{-\alpha/(\alpha+1)})\). For \(\mathscr{E}_{1}\), estimating sum of \(\mathcal{P}_{s}(k)^{2}\) using Lemma 6 gives \[\mathscr{E}_{1}=O\left(\eta S^{3}T\sum_{k>(\eta ST)^{1/(\alpha+1)}}k^{-2(\alpha +1)}\right)=O\left(S^{2}(\eta ST)^{-\alpha/(\alpha+1)}\right).\] (201) For \(\mathscr{E}_{2}\) we always have \[\mathscr{E}_{2}\leq S^{2}\sum_{k\leq(\eta ST)^{1/(\alpha+1)}}\mathcal{P}_{s}( k)\text{min}\left(1,\frac{S^{2}}{r^{2}}e^{-4\eta ST\mathcal{P}_{s}(k)}\right)\] (202) regardless of the size of \(N\), so it suffices to bound this sum. If we denote \(l=(\eta ST)^{1/(\alpha+1)}\) and define \[F_{2}(z)=\min\left(1,\frac{S^{2}}{r^{2}}e^{-4\eta STz}\right),\] (203)it suffices to show the bound

\[\sum_{k\leq l}\mathcal{P}_{s}(k)F_{2}(\mathcal{P}_{s}(k))=O\left(\left(\log(S/r) \right)^{\alpha/(\alpha+1)}(\eta ST)^{-\alpha/(\alpha+1)}\right).\] (204)

We will approximate this sum as

\[\sum_{k\leq l}\mathcal{P}_{s}(k)F_{2}(\mathcal{P}_{s}(k))= \sum_{k\leq l}(\mathcal{P}_{s}(k)-\mathcal{P}_{s}(k+1))\frac{ \mathcal{P}_{s}(k)}{\mathcal{P}_{s}(k+1)-\mathcal{P}_{s}(k)}F_{2}(\mathcal{P} _{s}(k))\] (205) \[= \sum_{k\leq l}(\mathcal{P}_{s}(k)-\mathcal{P}_{s}(k+1))\frac{k^{- \alpha-1}}{(\alpha+1)k^{-\alpha-2}(1+O(k^{-1}))}F_{2}(\mathcal{P}_{s}(k))\] (206) \[= O\left(\sum_{k\leq l}(\mathcal{P}_{s}(k)-\mathcal{P}_{s}(k+1)) \mathcal{P}_{s}(k)^{-1/(\alpha+1)}F_{2}(\mathcal{P}_{s}(k))\right).\] (207)

to obtain the form of Riemann sum approximation for the integral of

\[\int_{z=\mathcal{P}_{s}(l)}^{\infty}z^{-1/(\alpha+1)}F_{2}(z)dz\] (208)

at \(\mathcal{P}_{s}(l)<\mathcal{P}_{s}(l-1)<\cdots<\mathcal{P}_{s}(1)\). As \(F_{2}(z)\) is decreasing function, this Riemann sum is always less than the integral, so we obtain

\[\sum_{k\leq l}\mathcal{P}_{s}(k)F_{2}(\mathcal{P}_{s}(k))=O\left(\int_{z= \mathcal{P}_{s}(l)}^{\infty}z^{-1/(\alpha+1)}F_{2}(z)dz\right).\] (209)

We note that \(\mathcal{P}_{s}(l)=(\zeta(\alpha+1)\eta ST)^{-1}\). The threshold for \(F_{2}(z)\) to become \(1\) is given at

\[\frac{S^{2}}{r^{2}}e^{-4\eta STz}=1\quad\Leftrightarrow\quad z=\frac{1}{2\eta ST }\log\frac{S}{r}.\] (210)

As \(r<\sqrt{S}\), this value is always greater than \(\mathcal{P}_{s}(l)\). Thus we can divide our integral as

\[\int_{(\zeta(\alpha+1)\eta ST)^{-1}}^{\infty}z^{-1/(\alpha+1)}F_ {2}(z)dz\] (211) \[= \int_{(\zeta(\alpha+1)\eta ST)^{-1}}^{(2\eta ST)^{-1}\log(S/r)}z^ {-1/(\alpha+1)}dz+\int_{(2\eta ST)^{-1}\log(S/r)}^{\infty}z^{-1/(\alpha+1)} \frac{S^{2}}{r^{2}}e^{-4\eta STz}dz.\] (212)

The first part is bounded by

\[\int_{(\zeta(\alpha+1)\eta ST)^{-1}}^{(2\eta ST)^{-1}\log(S/r)}z^{-1/(\alpha+ 1)}dz=O\left(\left((2\eta ST)^{-1}\log(S/r)\right)^{\alpha/(\alpha+1)}\right)\] (213)

which can be shown to be \(O\left(\left(\log(S/r)\right)^{\alpha/(\alpha+1)}(\eta ST)^{-\alpha/(\alpha+ 1)}\right)\). For the second part, we apply substitution of \(w=4\eta STz\) to show

\[\int_{(2\eta ST)^{-1}\log(S/r)}^{\infty}z^{-1/(\alpha+1)}\frac{S ^{2}}{r^{2}}e^{-4\eta STz}dz= \frac{S^{2}}{r^{2}}(4\eta ST)^{-\alpha/(\alpha+1)}\int_{2\log(S/r )}^{\infty}w^{-1/(\alpha+1)}e^{-w}dw\] (214) \[= \frac{S^{2}}{r^{2}}(4\eta ST)^{-\alpha/(\alpha+1)}\Gamma\left( \frac{\alpha}{\alpha+1},2\log\frac{S}{r}\right)\] (215)

and applying the asymptotic \(\Gamma(s,x)=O(x^{s-1}e^{-x})\) suggests that this is bounded by

\[\ll\frac{S^{2}}{r^{2}}(4\eta ST)^{-\alpha/(\alpha+1)}\left(\log\frac{S}{r} \right)^{-1/(\alpha+1)}e^{-2\log(S/r)}=O\left((\eta ST)^{-\alpha/(\alpha+1)} \right).\] (216)

**Theorem 1**.: _(Parameter scaling law) Assume the following conditions: \(n_{s}>N\) with \(\lim(N/n_{s})=\gamma<1\) (\(\gamma\) can be zero), and there exists \(0<r<\sqrt{S}\) such that \(r<\mathcal{R}_{k}(0)<S/2\) for all \(k\). If \(N,T\to\infty\) while satisfying \(N^{\alpha+1}=o(T)\), the expected loss \(\mathbf{E}_{\mathcal{D}}[\mathcal{L}]\) for all datasets \(\mathcal{D}\) of size \(D\) satisfies_

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}] =\frac{S^{2}(1-\gamma^{\alpha})}{2\alpha\zeta(\alpha+1)}N^{-\alpha}\] \[\quad+O\left(S^{2}N^{-\min(\alpha+1,2\alpha)}+S^{2}\left(\log(S/ r)\right)^{\alpha/(\alpha+1)}(\eta ST)^{-\alpha/(\alpha+1)}\right)\] \[\quad+O\left(S^{2}D^{-1/2}f_{\alpha}(N)+S^{4}\eta^{2}T^{2}D^{-1} \right),\] (217)

_where_

\[f_{\alpha}(N)=\begin{cases}1&\text{if }\alpha>1\\ \log N&\text{if }\alpha=1\\ N^{(1-\alpha)/2}&\text{if }\alpha<1.\end{cases}\] (218)

_The constant on the \(O\) term only depends on \(\alpha\). When \(D\gg T^{3}\), then all the error terms involving \(D\) are negligible._

**Proof** In the situation \(n_{s}=\infty\) and \(D=\infty\), Proposition 6 shows that

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}]=\frac{S^{2}}{2\alpha\zeta(\alpha+1)}N^{ -\alpha}+O\left(S^{2}N^{-(\alpha+1)}+S^{2}\left(\log(S/r)\right)^{\alpha/( \alpha+1)}(\eta ST)^{-\alpha/(\alpha+1)}\right).\] (219)

We consider the effect of \(n_{s}\) first. As \(\mathscr{L}_{1}\) becomes an error term in this estimation, letting \(n_{s}\) as a finite value has no effect on overall estimation. The term \(\mathscr{L}_{2}\) accounts for the main term, and letting \(n_{s}\) as finite value changes it to

\[\frac{N^{-\alpha}-n_{s}^{-\alpha}}{\alpha\zeta(\alpha+1)}\frac{S^{2}}{2}+O(N^ {-\min(\alpha+1,2\alpha)}S^{2}).\] (220)

This accounts for the factor \((1-\gamma^{\alpha})\) on the main term and \(O(N^{-\min(\alpha+1,2\alpha)}S^{2})\) added to the error term. The effect of \(D\) is exactly described in Proposition 4, contributing the error term of \(O\left(S^{2}D^{-1/2}f_{\alpha}(N)+S^{4}\eta^{2}T^{2}D^{-1}\right)\). Regarding the sufficient condition for \(D\), if \(D\gg T^{3}\) then we have

\[S^{4}\eta T^{2}D^{-1}\ll T^{-\alpha/(\alpha+1)},\quad S^{2}D^{-1/2}f_{\alpha}( N)\ll T^{-3/2}N^{1/2}\ll T^{-1}\] (221)

so all error terms involving \(D\) are less than \(O(T^{-\alpha/(\alpha+1)})\). \(\blacksquare\)

For the situation \(T=O(N^{\alpha+1})\) however, the error terms \(\mathscr{E}_{1}\) and \(\mathscr{E}_{2}\) are of same size, so we can only say that the main term is of \(O(S^{2}(\eta ST)^{-\alpha/(\alpha+1)})\).

**Theorem 2**.: _(Upper bound for the time scaling law) Assume the following conditions: \(n_{s}>N\), and there exists there exists \(0<r<\sqrt{S}\) such that \(r<\mathcal{R}_{k}(0)<S/2\) for all \(k\). If \(N,T\to\infty\) while satisfying \(\eta ST=O(N^{\alpha+1})\), the expected loss \(\mathbf{E}_{\mathcal{D}}[\mathcal{L}]\) is_

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}]=O\left(S^{2}\left(\log(S/r)\right)^{ \alpha/(\alpha+1)}(\eta ST)^{-\alpha/(\alpha+1)}+S^{2}D^{-1/2}f_{\alpha}(N)+S ^{4}\eta^{2}T^{2}D^{-1}\right)\] (222)

_with constant on \(O\) only depending on \(\alpha\) and \(\limsup((\eta ST)^{1/(\alpha+1)}/N)\), with \(f_{\alpha}\) defined as in Theorem 1. If \(D\gg NT^{2}\) and \(D\gg T^{3}\), then all the error terms involving \(D\) are negligible._

**Proof** The error term regarding \(D\) can be obtained in the same way as Theorem 1, so we will let \(D=\infty\) for the rest of the proof. Also, we can let \(n_{s}=\infty\), as we observed that it contributes at most to the constant factor of the upper bound and does not change the scaling.

In the decomposition of Proposition 6, we always have

\[\mathscr{E}_{2}=O\left(S^{2}\left(\log(S/r)\right)^{\alpha/(\alpha+1)}\left( \eta ST\right)^{-\alpha/(\alpha+1)}\right)\] (223)

and

\[\mathscr{E}_{1}=O\left(S^{2}(\eta ST)^{-\alpha/(\alpha+1)}\right)\] (224)

holding regardless of \(N\), so it only remains to consider \(\mathscr{L}_{2}+\mathscr{M}\). If \((\eta ST)^{1/(\alpha+1)}<N\), then \(\mathscr{L}_{2}+\mathscr{M}\) is of size \(O\left(S^{2}(\eta ST)^{-\alpha/(\alpha+1)}\right)\). If \((\eta ST)^{1/(\alpha+1)}\geq N\), then \(N\) and \((\eta ST)^{1/(\alpha+1)}\) has same order, so \(\mathscr{L}_{2}+\mathscr{M}=\mathscr{L}_{2}=\Theta(S^{2}N^{-\alpha})\) is \(O\left(S^{2}(\eta ST)^{-\alpha/(\alpha+1)}\right)\). Thus in either cases we have the desired bound. \(\blacksquare\)

**Theorem 3**.: _(Lower bound for the time scaling law) Assume the following conditions: \(n_{s}>N\) and \(0<\mathcal{R}_{k}(0)<S/2\). If \(N,T\to\infty\) while satisfying \((8\zeta(\alpha+1)^{-1}\eta ST)^{1/(\alpha+1)}<N\), the expected loss \(\mathbf{E}_{\mathcal{D}}[\mathcal{L}]\) is_

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}]\geq\kappa S^{2}(\eta ST)^{-\alpha/( \alpha+1)}+O\left(\eta^{-1}ST^{-1}+S^{2}D^{-1/2}f_{\alpha}(N)+S^{4}\eta^{2}T^{ 2}D^{-1}\right)\] (225)

_for \(\kappa\) and constant on \(O\) only depending on \(\alpha\), with \(f_{\alpha}\) defined as in Theorem 1. If \(D\gg NT^{2}\) and \(D\gg T^{3}\), then all the error terms involving \(D\) are negligible._

**Proof** The error term regarding \(D\) can be obtained in the same way as Theorem 1, so we will let \(D=\infty\) for the rest of the proof. We only show the lower bound for \(\mathscr{L}_{1}\), holding regardless of \(N\) and \(n_{s}\). In Lemma 7 (Eq. (178)) we have

\[F(z)\geq\frac{(S-r_{k})^{2}}{2}-\frac{8\eta S^{3}T}{27}z\geq\frac{S^{2}}{8}- \frac{8\eta S^{3}T}{27}z\] (226)

for \(z\geq 0\), so if \(z\leq(4\eta ST)^{-1}\) then \(F(z)\geq S^{2}/8-2S^{2}/27>S^{2}/20\). The condition \(\mathcal{P}_{s}(k)\leq(4\eta ST)^{-1}\) is equivalent to that \(k\geq(4\zeta(\alpha+1)^{-1}\eta ST)^{1/(\alpha+1)}\). In evaluating \(\mathscr{L}_{1}=\sum_{k=1}^{N}\mathcal{P}_{s}(k)F(\mathcal{P}_{s}(k))\), we will only add over \(k\) in range of

\[(4\zeta(\alpha+1)^{-1}\eta ST)^{1/(\alpha+1)}<k<(8\zeta(\alpha+1)^{-1}\eta ST )^{1/(\alpha+1)}.\] (227)

From the assumption, this interval sits inside \(1<k<N\). For such \(k\) we use upper bound of \(F(\mathcal{P}_{s}(k))>S^{2}/20\). Then by using Proposition 5 we can obtain

\[\mathscr{L}_{1} \geq\frac{S^{2}}{20}\sum_{(4\zeta(\alpha+1)^{-1}\eta ST)^{1/( \alpha+1)}<k<(8\zeta(\alpha+1)^{-1}\eta ST)^{1/(\alpha+1)}}\mathcal{P}_{s}(k)\] (228) \[=\frac{S^{2}}{20}\left(\frac{(\zeta(\alpha+1)^{-1}\eta ST)^{- \alpha/(\alpha+1)}}{\alpha\zeta(\alpha+1)}(4^{-\alpha/(\alpha+1)}-8^{-\alpha/ (\alpha+1)})+O\left((\eta ST)^{-1}\right)\right).\] (229)

The possible effect of \(n_{s}\) on the main term is to multiply both the main term by and \(T\) by \((1+n_{s}^{-\alpha})\), so it increases the bound.

The condition \((8\zeta(\alpha+1)^{-1}\eta ST)^{1/(\alpha+1)}<N\) is not absolutely necessary for lower bound. The condition \((\eta ST)^{1/(\alpha+1)}=\Theta(N)\) and \(n_{s}\geq 2N\) would suffice and one can formulate a similar theorem, although the constant of lower bound might be much smaller if \((\eta ST)^{1/(\alpha+1)}/N\) is small.

Lastly, we provide a simpler version of those results combined and discuss the special case where the optimal compute \(C=NT\), or the given engineering budget, is specified.

**Corollary 3**.: _(Summary of the large data estimation) Assuming \(D\gg NT^{2},T^{3}\) and \(n_{s}\gg N^{1+\epsilon}\) such that effects of \(n_{s}\) and \(D\) are negligible, then for \(N,T\to\infty\) we have_

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}]=\Theta_{\eta,S,r}\left(\max(N^{-\alpha}, T^{-\alpha/(\alpha+1)})\right),\] (230)

_where \(\Theta_{\eta,S,r}\) denotes that the implied constant depends on \(\eta,S,\alpha\) and \(r=\min\mathcal{R}_{k}(0)>0\). In particular, we have_

\[N^{\alpha+1}=O(T)\quad\Rightarrow\quad\mathbf{E}_{\mathcal{D}}[\mathcal{L}]= \Theta_{\eta,S,r}(N^{-\alpha})\] (231)

_and_

\[T=O(N^{\alpha+1})\quad\Rightarrow\quad\mathbf{E}_{\mathcal{D}}[\mathcal{L}]= \Theta_{\eta,S,r}(T^{-\alpha/(\alpha+1)}).\] (232)

**Proof** Apply Theorem 1 if \(N^{\alpha+1}=o(T)\) and Theorem 2 and Theorem 3 if \(N^{\alpha+1}\gg T\).

**Corollary 4**.: _(The 'computationally optimal' case) Denote \(C=NT\) and assume the conditions in Corollary 3. Then we have_

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}]\gg C^{-\alpha/(\alpha+2)}.\] (233)

_When \(N=\Theta(C^{1/(\alpha+2)})\) and \(T=\Theta(C^{(\alpha+1)/(\alpha+2)})\), we achieve \(\mathbf{E}_{\mathcal{D}}[\mathcal{L}]=\Theta(C^{-\alpha/(\alpha+2)})\). (Its implied constant may depend on implied constant for growth of \(N\) and \(T\).)_

**Proof** The first part follows from

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}]\gg\max(N^{-\alpha},T^{-\alpha/(\alpha+1)})\] (234)

and

\[\max(N^{-\alpha},T^{-\alpha/(\alpha+1)})\geq(N^{-\alpha})^{1/(\alpha+2)}(T^{- \alpha/(\alpha+1)})^{(\alpha+1)/(\alpha+2)}=(NT)^{-\alpha/(\alpha+2)}.\] (235)

The second part can be checked by substituting \((N,T)=(C^{1/(\alpha+2)},C^{(\alpha+1)/(\alpha+2)})\) (or their constant multiples) to Corollary 3.

### Computing the constant for time scaling law

While we have found the time scaling law \(\mathbf{E}[\mathcal{L}]=O(T^{-\alpha/(\alpha+1)})\) holding for \(T=O(N^{\alpha+1})\), bounds in Theorem 2 and Theorem 3 were chosen rather lazily and do not depict the correct picture. We will find the constant using a more refined estimation, but we require additional assumptions on parameters. We will focus on the setting where \(D\) and \(n_{s}\) are large enough to be negligible, \(\mathcal{R}_{k}(0)=r\) is fixed, and \(T=O(N^{\alpha+1})\) with fixed constant such that time scaling law holds.

**Theorem 4**.: _(Constant for time scaling law) Denote \(\mathcal{L}^{\infty}\) as the loss when \(D,n_{s}\to\infty\) so that their effect is negligible:_

\[\mathcal{L}^{\infty}=\mathcal{L}^{\infty}(T,N)=\sum_{k=1}^{N}\mathcal{P}_{s}( k)\frac{S^{2}}{2\left(1+\left(\frac{S}{r}-1\right)^{-1}e^{2\eta\mathcal{P}_{s}(k) ST}\right)^{2}}+\frac{S^{2}N^{-\alpha}}{2\alpha\zeta(\alpha+1)}.\] (236)

_When \(T,N\to\infty\) and \(\lim N/(\eta ST)^{1/(\alpha+1)}=\lambda\) for a fixed constant \(\lambda\in(0,\infty]\), the following limit exists:_

\[\mathcal{A}(\lambda)=\lim_{T,N\to\infty}(\eta ST)^{\alpha/(\alpha+1)}\mathcal{ L}^{\infty}(T,N).\] (237)

_The prefactor constant \(\mathcal{A}\) as the a function of \(\lambda\) (when \(\lambda=\infty\) then let \(\lambda^{-\alpha}=\lambda^{-(\alpha+1)}=0\)) is_

\[\mathcal{A}(\lambda)=\frac{\zeta(\alpha+1)^{-1/(\alpha+1)}}{\alpha+1}\int_{ \lambda^{-(\alpha+1)}/\zeta(\alpha+1)}^{\infty}u^{-1/(\alpha+1)}\Phi_{S,r}(u) du+\frac{S^{2}}{2\alpha\zeta(\alpha+1)}\lambda^{-\alpha},\] (238)

_where_

\[\Phi_{S,r}(u)=\frac{S^{2}}{2\left(1+\left(\frac{S}{r}-1\right)^{-1}e^{2u} \right)^{2}}.\] (239)

* We first observe \[\mathcal{L}^{\infty}=\sum_{k=1}^{N}\mathcal{P}_{s}(k)\Phi_{S,r}(\eta ST \mathcal{P}_{s}(k))+\frac{S^{2}N^{-\alpha}}{\alpha\zeta(\alpha+1)}.\] (240) We will seek to convert it into Riemann sum form of certain integral. We start by noting that \[\mathcal{P}_{s}(k) =(\mathcal{P}_{s}(k)-\mathcal{P}_{s}(k+1))\frac{k}{\alpha+1}(1+O (k^{-1}))\] (241) \[=\frac{\zeta(\alpha+1)^{-1/(\alpha+1)}}{\alpha+1}(\mathcal{P}_{s }(k)-\mathcal{P}_{s}(k+1))\mathcal{P}_{s}(k)^{-1/(\alpha+1)}(1+O(k^{-1}))\] (242) Denote \(u_{k}=\eta ST\mathcal{P}_{s}(k)\), then the sum can be approximated to \[\sum_{k}\mathcal{P}_{s}(k)\Phi_{S,r}(\eta ST\mathcal{P}_{s}(k))\] (243) \[\approx \sum_{k}(\mathcal{P}_{s}(k)-\mathcal{P}_{s}(k+1))\mathcal{P}_{s}( k)^{-1/(\alpha+1)}\Phi_{S,r}(\eta ST\mathcal{P}_{s}(k))\] (244) \[= (\eta ST)^{-\alpha/(\alpha+1)}\sum_{k}(u_{k}-u_{k+1})u_{k}^{-1/( \alpha+1)}\Phi_{S,r}(u_{k})\] (245) if we ignore small \(k\). As \(\Phi_{S,r}\) is decreasing, this corresponds to Riemann sum taking minimum in the interval \([u_{k+1},u_{k}]\). So integral provides an upper bound for this sum. Similarly, we can approximate it with Riemann sum taking maximum in \([u_{k},u_{k-1}]\) if we use \[\mathcal{P}_{s}(k)=\frac{\zeta(\alpha+1)^{-1/(\alpha+1)}}{\alpha+1}(\mathcal{P }_{s}(k-1)-\mathcal{P}_{s}(k))\mathcal{P}_{s}(k-1)^{-1/(\alpha+1)}(1+O(k^{-1}))\] (246) instead. As \(\Phi_{S,r}\) shows exponential decay, we can ignore values at small \(k\), so this shows \[(\eta ST)^{-\alpha/(\alpha+1)}\sum_{k}(u_{k}-u_{k+1})u_{k}^{-1/(\alpha+1)}\Phi _{S,r}(u_{k})\approx\int_{u_{N}}^{\infty}u^{-1/(\alpha+1)}\Phi_{S,r}(u)du\] (247)and from that

\[u_{N}=\eta STN^{-(\alpha+1)}\zeta(\alpha+1)^{-1}=\lambda^{-(\alpha+1)}\zeta( \alpha+1)^{-1}\] (248)

we obtain our desired result. 

Theorem 4 basically tells that for \(N=\lambda(\eta ST)^{1/(\alpha+1)}\) and \(D,n_{s}\) large enough, we have

\[\mathcal{L}\sim\mathcal{A}(\lambda)(\eta ST)^{-\alpha/(\alpha+1)}\] (249)

with \(\mathcal{A}(\lambda)\) given as Eq. (238), thus specifying the constant for time scaling law. For finite \(\lambda\), this theorem covers the computationally optimal case of \((N,T)=(\lambda_{1}C^{1/(\alpha+2)},\lambda_{2}C^{(\alpha+1)/(\alpha+2)})\) for some nonzero constant \(\lambda_{1},\lambda_{2}\). For \(\lambda=\infty\), it describes the case \(T=o(N^{\alpha+1})\) where effect of \(N\) is negligible.

**Corollary 5**.: _Denote \(\mathcal{L}^{\infty}\) as \(\mathcal{L}^{\infty}\) as the loss when \(D,n_{s}\to\infty\) same as Eq. (236). Denote \(C=NT\) and suppose that_

\[(N,\eta ST)=(\lambda(\eta SC)^{1/(\alpha+2)},\lambda^{-1}(\eta SC)^{(\alpha+1 )/(\alpha+2)})\] (250)

_for a fixed constant \(0<\lambda<\infty\). Then as \(C\to\infty\), we have_

\[\mathcal{L}^{\infty}=\mathcal{A}\left(\lambda^{(\alpha+2)/(\alpha+1)}\right) \lambda^{\alpha/(\alpha+1)}\left(\eta SC\right)^{-\alpha/(\alpha+2)}(1+o(1))\] (251)

_where \(\mathcal{A}\) is given as Eq. (238) of Theorem 4._

* As \(\lim N/(\eta ST)^{1/(\alpha+1)}=\lambda^{(\alpha+2)/(\alpha+1)}\) under above conditions, we can apply Theorem 4 and substituting Eq. (250) into Eq. (249) gives the desired result. 

Technically we can optimize \(\mathcal{L}^{\infty}\) for a given fixed value of \(C=NT\) by letting \(\lambda\) as argument of minimum of \(\mathcal{A}\left(\lambda^{(\alpha+2)/(\alpha+1)}\right)\lambda^{-\alpha/( \alpha+1)}\), although it seems almost impossible to obtain any form of formula for such \(\lambda\).

Lastly, we provide the following estimate for the time scale constant (\(\mathcal{A}(\lambda)\)) when \(r\) is small, especially the first term in Eq. (238).

**Proposition 7**.: _As \(r\to 0\), we have (\(\Lambda>0\) fixed)_

\[\int_{\Lambda}^{\infty}u^{-1/(\alpha+1)}\Phi_{S,r}(u)du\approx\left(\log \frac{S-r}{r}\right)^{\alpha/(\alpha+1)}\frac{2^{1/(\alpha+1)}S^{2}(\alpha+1)} {4\alpha}.\] (252)

* Denote \(M=(\frac{S}{r}-1)\), and replace \(u\) by \((\log M)v\). Then we have \[\int_{\Lambda}^{\infty}u^{-1/(\alpha+1)}\Phi_{S,r}(u)du =(\log M)^{\alpha/(\alpha+1)}\frac{S^{2}}{2}\int_{\Lambda/\log M }^{\infty}\frac{v^{-1/(\alpha+1)}dv}{(1+M^{2v-1})^{2}}\] (253) \[=(\log M)^{\alpha/(\alpha+1)}\frac{S^{2}}{2}\int_{0}^{\infty}1_{ v\geq\Lambda/\log M}\frac{v^{-1/(\alpha+1)}dv}{(1+M^{2v-1})^{2}}.\] (254) As \(M\to\infty\), the integrand converges to \[\lim_{M\to\infty}1_{v\geq\Lambda/\log M}\frac{v^{-1/(\alpha+1)}dv}{(1+M^{2v-1 })^{2}}=\begin{cases}v^{-1/(\alpha+1)}&\text{if }v\leq 1/2\\ 0&\text{if }v>1/2.\end{cases}\] (255) The integrand is bounded by \(v^{-1/(\alpha+1)}\) if \(v\leq 1/2\) and \(v^{-1/(\alpha+1)}e^{-2(2v-1)}\) if \(v>1/2\), those of which are all integrable. So we can apply Lebesgue's dominated convergence theorem to show \[\lim_{M\to\infty}\int_{\Lambda/\log M}^{\infty}\frac{v^{-1/( \alpha+1)}dv}{(1+M^{2v-1})^{2}} =\int_{0}^{\infty}\left(\lim_{M\to\infty}1_{v\geq\Lambda/\log M} \frac{v^{-1/(\alpha+1)}dv}{(1+M^{2v-1})^{2}}\right)\] (256) \[=\int_{0}^{1/2}v^{-1/(\alpha+1)}dv.\] (257) Thus we have \[\lim_{r\to 0}\left(\log\frac{S-r}{r}\right)^{-\alpha/(\alpha+1)}\int_{ \Lambda}^{\infty}u^{-1/(\alpha+1)}\Phi_{S,r}(u)du =\frac{S^{2}}{2}\int_{0}^{1/2}v^{-1/(\alpha+1)}dv\] (258) \[=\frac{2^{1/(\alpha+1)}S^{2}(\alpha+1)}{4\alpha}\] (259) which can be observed to be equivalent to the desired expression of Eq. (252). 

### Estimates for large \(T\) and threshold between data/parameter scaling

The estimates for small \(D\) require different techniques from estimates for large \(D\). We will consider the situation \(T\) grows much faster than \(D\) and \(N\), and discuss when data scaling law of \(\mathcal{L}=\Theta(D^{-\alpha/(\alpha+1)})\) happens. We will consider a simpler setting of '\(n_{s}=\infty\)' or equivalently that effects of \(n_{s}\) are negligible (\(n_{s}=\omega(N)\) seems to suffice) and \(\mathcal{R}_{k}(0)=r<S\) is fixed, although it won't be impossible to discuss their subtle effects.

First we single out effect of \(T\) by comparing \(\mathcal{L}(T)\) and \(\mathcal{L}(\infty)\). We remind

\[\mathcal{L}_{k}(T)=\frac{S^{2}}{2\left(1+\left(\frac{S}{r}-1\right)^{-1}e^{2 \eta d_{k}ST/D}\right)^{2}}\] (27)

and its limit when \(T\to\infty\) is given as

\[\mathcal{L}_{k}(\infty)=\lim_{T\to\infty}\mathcal{L}_{k}(T)=\begin{cases} \frac{(S-r)^{2}}{2}&\text{if }d_{k}=0\\ 0&\text{if }d_{k}>0.\end{cases}\] (280)

**Proposition 8**.: _Suppose that \(\mathcal{R}_{k}(0)=r<S\) is fixed. For large \(T\), we have_

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}(T)]-\mathbf{E}_{\mathcal{D}}[\mathcal{L }(\infty)]=O\left(S^{4}r^{-2}De^{-4\eta ST/D}\right).\] (281)

* As \(\mathcal{L}_{k}(T)\) is decreasing in \(T\), we always have \(\mathcal{L}_{k}(T)\geq\mathcal{L}_{k}(\infty)\) so therefore \[\mathbf{E}_{\mathcal{D}}[\mathcal{L}(T)]-\mathbf{E}_{\mathcal{D}}[\mathcal{L }(\infty)]\geq 0.\] (282) So we only need to establish an upper bound for \(\mathcal{L}_{k}(T)-\mathcal{L}_{k}(\infty)\). We note that \(\mathcal{L}_{k}(T)-\mathcal{L}_{k}(\infty)\) when \(d_{k}=0\), so one can write \[\mathcal{L}_{k}(T)-\mathcal{L}_{k}(\infty)=1_{d_{k}>0}\mathcal{L}_{k}(T)\] (283) where \(1_{d_{k}>0}\) denotes the characteristic function \[1_{d_{k}>0}=\begin{cases}1&\text{if }d_{k}>0\\ 0&\text{if }d_{k}=0.\end{cases}\] (284) We use simple bound of \[\mathcal{L}_{k}(T)<\frac{S^{2}}{2\left(\left(\frac{S}{r}-1\right)^{-1}e^{2 \eta d_{k}ST/D}\right)^{2}}<\frac{S^{4}}{2}r^{-2}e^{-4\eta d_{k}ST/D}.\] (285) As \(d_{k}\) follows binomial distribution \(B(D,\mathcal{P}_{s}(k))\), considering its moment generating function gives \[\mathbf{E}_{d_{k}}[e^{-4\eta d_{k}ST/D}]=\left(1-\mathcal{P}_{s}(k)+\mathcal{ P}_{s}(k)e^{-4\eta ST/D}\right)^{D}\] (286) so thus \[\mathbf{E}_{d_{k}}[1_{d_{k}>0}e^{-4\eta d_{k}ST/D}]=\left(1-\mathcal{P}_{s}(k) +\mathcal{P}_{s}(k)e^{-4\eta ST/D}\right)^{D}-(1-\mathcal{P}_{s}(k))^{D}.\] (287) Meanwhile, for \[0\leq u,v\leq 1\] real numbers, we have \[|u^{D}-v^{D}|=|u-v||u^{D-1}+u^{D-2}v+\cdots+v^{D-1}|\leq D|u-v|\] (288) so, applying this inequality to above gives \[\mathbf{E}_{d_{k}}[1_{d_{k}>0}e^{-4\eta d_{k}ST/D}]\leq D\mathcal{P}_{s}(k)e^ {-4\eta ST/D}.\] (289) Thus, we can deduce \[\mathbf{E}_{d_{k}}[\mathcal{L}_{k}(T)]-\mathbf{E}_{d_{k}}[\mathcal{ L}_{k}(\infty)] =\mathbf{E}_{d_{k}}[1_{d_{k}>0}\mathcal{L}_{k}(T)]\] (290) \[<\frac{S^{4}r^{-2}}{2}\mathbf{E}_{d_{k}}[1_{d_{k}>0}e^{-4\eta d _{k}ST/D}]\] (291) \[\leq\frac{S^{4}r^{-2}}{2}De^{-4\eta ST/D}\mathcal{P}_{s}(k)\] (292)and thus

\[0\leq\mathbf{E}_{\mathcal{D}}[\mathcal{L}(T)]-\mathbf{E}_{\mathcal{D}}[ \mathcal{L}(\infty)]<\frac{S^{4}r^{-2}}{2}De^{-4\eta ST/D}\sum_{k=1}^{\infty} \mathcal{P}_{s}(k)^{2}=O\left(S^{4}r^{-2}De^{-4\eta ST/D}\right).\] (273)

This provides an almost complete account for the effect of very large \(T\). We will let \(T=\infty\) from this point. We have

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}(\infty)]=\frac{(S-r)^{2}}{2}\sum_{k=1}^{N }\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))^{D}+\frac{S^{2}}{2}\sum_{k=N+1}^{ \infty}\mathcal{P}_{s}(k).\] (274)

Applying Lemma 6 gives

\[\sum_{k=N+1}^{\infty}\mathcal{P}_{s}(k)=\frac{N^{-\alpha}}{\alpha\zeta(\alpha +1)}+O(N^{-\alpha-1})\] (275)

so it suffices to focus on the first sum. We will divide the range of \(k\) into two \(1\leq k\leq M\) and \(M<k\leq N\). For the sum over \(1\leq k\leq M\), we will apply the following simple bound (in the last part, we used \(1-x\leq e^{-x}\))

\[0\leq\sum_{k=1}^{M}\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))^{D}\leq(1- \mathcal{P}_{s}(M))^{D}\leq e^{-\mathcal{P}_{s}(M)D}.\] (276)

For the sum over \(M<k\leq N\), we will approximate the sum into some integral, which happens to be incomplete gamma function.

**Proposition 9**.: _For \(2<M<N\) integers, we have_

\[\sum_{k=M+1}^{N}\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))^{D}\] (277) \[= D^{-\alpha/(\alpha+1)}\frac{\zeta(\alpha+1)^{-1/(\alpha+1)}}{ \alpha+1}\left(\Gamma\left(\frac{\alpha}{\alpha+1},D\mathcal{P}_{s}(N)\right) -\Gamma\left(\frac{\alpha}{\alpha+1},D\mathcal{P}_{s}(M)\right)\right)\] (278) \[+O\left(D^{-(2\alpha+1)/(\alpha+1)}+D^{-\alpha/(\alpha+1)}M^{-1} \right).\] (279)

_Here \(\Gamma\) denotes the incomplete gamma function_

\[\Gamma\left(s,x\right)=\int_{x}^{\infty}y^{s-1}e^{-y}dy.\] (280)

**Proof** Consider the interval \([\mathcal{P}_{s}(N),\mathcal{P}_{s}(M)]\) and its partition \(\mathscr{P}=\{\mathcal{P}_{s}(N)<\mathcal{P}_{s}(N-1)<\cdots<\mathcal{P}_{s}( M)\}\). For a function \(f(x)=x^{-1/(\alpha+1)}(1-x)^{D}\), we will consider its upper and lower Darboux sums with respect to \(\mathcal{P}\). As \(f\) is decreasing in \((0,1]\), its upper and lower Darboux sums are given respectively as

\[U(f,\mathscr{P}) =\sum_{k=M}^{N-1}(\mathcal{P}_{s}(k)-\mathcal{P}_{s}(k+1)) \mathcal{P}_{s}(k+1)^{-1/(\alpha+1)}(1-\mathcal{P}_{s}(k+1))^{D}\] (281) \[L(f,\mathscr{P}) =\sum_{k=M}^{N-1}(\mathcal{P}_{s}(k)-\mathcal{P}_{s}(k+1)) \mathcal{P}_{s}(k)^{-1/(\alpha+1)}(1-\mathcal{P}_{s}(k))^{D}.\] (282)

and those give bound of the integral of \(f\) as

\[L(f,\mathscr{P})\leq\int_{\mathcal{P}_{s}(N)}^{\mathcal{P}_{s}(M)}f(x)dx\leq U (f,\mathscr{P}).\] (283)

Meanwhile, by noting that

\[\mathcal{P}_{s}(k)=\frac{\zeta(\alpha+1)^{-1/(\alpha+1)}}{\alpha+1}(\mathcal{ P}_{s}(k)-\mathcal{P}_{s}(k+1))\mathcal{P}_{s}(k)^{-1/(\alpha+1)}(1+O(k^{-1}))\] (284)one can show

\[\sum_{k=M}^{N}\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))^{D}\] (285) \[= \frac{\zeta(\alpha+1)^{-1/(\alpha+1)}}{\alpha+1}\left(\sum_{k=M}^{N -1}(\mathcal{P}_{s}(k)-\mathcal{P}_{s}(k+1))\mathcal{P}_{s}(k)^{-1/(\alpha+1) }(1-\mathcal{P}_{s}(k))^{D}\right)(1+O(M^{-1}))\] (286) \[= \frac{\zeta(\alpha+1)^{-1/(\alpha+1)}}{\alpha+1}L(f,\mathscr{P})( 1+O(M^{-1})).\] (287)

Applying a similar argument for upper Darboux sum gives

\[\sum_{k=M}^{N}\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))^{D}=\frac{\zeta(\alpha+ 1)^{-1/(\alpha+1)}}{\alpha+1}U(f,\mathscr{P})(1+O(M^{-1}))\] (288)

and from Eq. (283) it follows

\[\sum_{k=M}^{N}\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))^{D}=\frac{\zeta(\alpha +1)^{-1/(\alpha+1)}}{\alpha+1}\left(\int_{\mathcal{P}_{s}(N)}^{\mathcal{P}_{s }(M)}x^{-1/(\alpha+1)}(1-x)^{D}dx\right)(1+O(M^{-1})).\] (289)

From now we will estimate the integral

\[\int_{\mathcal{P}_{s}(N)}^{\mathcal{P}_{s}(M)}x^{-1/(\alpha+1)}(1-x)^{D}dx.\] (290)

We replace \(x=y/D\) in the integral inside, then it becomes

\[\int_{\mathcal{P}_{s}(N)}^{\mathcal{P}_{s}(M)}x^{-1/(\alpha+1)}(1-x)^{D}dx=D^ {-\alpha/(\alpha+1)}\int_{D\mathcal{P}_{s}(N)}^{DP_{s}(M)}y^{-1/(\alpha+1)} \left(1-\frac{y}{D}\right)^{D}dy.\] (291)

We want to approximate \(\left(1-\frac{y}{D}\right)^{D}\) by \(e^{-y}\), so we will estimate difference between them. We have

\[D\log(1-y/D)=-y-\sum_{k=2}^{\infty}\frac{y^{k}}{kD^{k-1}}\] (292)

so if \(D>2y\) then

\[-y>D\log(1-y/D)=-y-\frac{1}{D}\sum_{k=2}^{\infty}\frac{y^{k}}{kD^{k-2}}>-y- \frac{1}{D}\sum_{k=2}^{\infty}\frac{y^{k}}{2(2y)^{k-2}}=-y-\frac{y^{2}}{D}\] (293)

so

\[e^{-y}\left(1-\frac{y^{2}}{D}\right)<e^{-y}e^{-y^{2}/D}<\left(1-\frac{y}{D} \right)^{D}<e^{-y},\] (294)

where we used the inequality \(1-x\leq e^{-x}\). As \(\mathcal{P}_{s}(M)<1/2\) if \(M>2\) (obvious from \(\mathcal{P}_{s}(M)<(\mathcal{P}_{s}(1)+\mathcal{P}_{s}(2))/2<1/2\)), any \(y\) in the interval \([D\mathcal{P}_{s}(N),D\mathcal{P}_{s}(M)]\) satisfies \(D>2y\). So, we can apply this approximation in every \(y\). It follows that

\[\int_{D\mathcal{P}_{s}(N)}^{D\mathcal{P}_{s}(M)}y^{-1/(\alpha+1)} \left(1-\frac{y}{D}\right)^{D}dy\] (295) \[= \int_{D\mathcal{P}_{s}(N)}^{D\mathcal{P}_{s}(M)}y^{-1/(\alpha+1) }e^{-y}dy+O\left(\int_{D\mathcal{P}_{s}(N)}^{D\mathcal{P}_{s}(M)}y^{-1/( \alpha+1)}e^{-y}\frac{y^{2}}{D}dy\right)\] (296) \[= \int_{D\mathcal{P}_{s}(N)}^{D\mathcal{P}_{s}(M)}y^{-1/(\alpha+1) }e^{-y}dy+O\left(D^{-1}\int_{0}^{\infty}y^{-1/(\alpha+1)}e^{-y}y^{2}dy\right)\] (297) \[= \Gamma\left(\frac{\alpha}{\alpha+1},D\mathcal{P}_{s}(N)\right)- \Gamma\left(\frac{\alpha}{\alpha+1},D\mathcal{P}_{s}(M)\right)+O(D^{-1}).\] (298)

Combining this with Eq. (289) and Eq. (291) gives the desired result. 

We combine Proposition 8 and Proposition 9 together to obtain this final estimation result.

**Theorem 5**.: _(Scaling laws for large time estimation) Suppose that \(N,D\rightarrow\infty\) and \(n_{s}\gg N^{1+\epsilon}\) for some \(\epsilon>0\) so that effect of \(n_{s}\) is negligible. Suppose that \(\mathcal{R}_{k}(0)=r\) for all \(1\leq k\leq N\)._

1. _(Parameter scaling law) If_ \(N=o(D^{1/(\alpha+1)})\)_, then we have_ \[\mathbf{E}_{\mathcal{D}}[\mathcal{L}]=\frac{S^{2}}{2\alpha\zeta(\alpha+1)}N^{ -\alpha}+O\left(S^{2}D^{-\alpha/(\alpha+1)}+S^{2}N^{-\alpha-1}+S^{4}r^{-2}De^{ -4\eta ST/D}\right).\] (299)
2. _(Data scaling law) If_ \(D=O(N^{\alpha+1})\) _and_ \(\mu=\lim(D/N^{\alpha+1})\) _exists (it can be zero), then_ \[\mathbf{E}_{\mathcal{D}}[\mathcal{L}] =D^{-\alpha/(\alpha+1)}\left(\frac{(S-r)^{2}\zeta(\alpha+1)^{-1/ (\alpha+1)}}{2(\alpha+1)}\Gamma\left(\frac{\alpha}{\alpha+1},\frac{D}{N^{ \alpha+1}\zeta(\alpha+1)}\right)+\frac{S^{2}(D/N^{\alpha+1})^{\alpha/(\alpha+ 1)}}{2\alpha\zeta(\alpha+1)}\right)\] \[\quad+O\left(S^{2}D^{-(2\alpha+1)/(2\alpha+2)}+S^{4}r^{-2}De^{-4 \eta ST/D}\right)\] (300) _Here_ \(\Gamma\) _denotes the incomplete gamma function_ \[\Gamma\left(s,x\right)=\int_{x}^{\infty}y^{s-1}e^{-y}dy.\] (301) _In particular, if_ \(D=o(N^{\alpha+1})\) _such that_ \(\mu=0\)_, we have_ \[\mathbf{E}_{\mathcal{D}}[\mathcal{L}] =D^{-\alpha/(\alpha+1)}\frac{(S-r)^{2}\zeta(\alpha+1)^{-1/(\alpha +1)}}{2(\alpha+1)}\Gamma\left(\frac{\alpha}{\alpha+1}\right)(1+o(1))\] \[\quad\quad+O\left(S^{4}r^{-2}De^{-4\eta ST/D}\right).\] (302)

_In either case, \(T\gg D(\log D)^{1+\epsilon}\) for some \(\epsilon>0\) implies that error terms involving \(T\) are negligible._

**Proof** Proposition 8 states

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}(T)]-\mathbf{E}_{\mathcal{D}}[\mathcal{L} (\infty)]=O\left(S^{4}r^{-2}De^{-4\eta ST/D}\right)\] (261)

and we showed

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}(\infty)]=\frac{(S-r)^{2}}{2}\sum_{k=1}^{ N}\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))^{D}+\frac{S^{2}}{2}\sum_{k=N+1}^{ \infty}\mathcal{P}_{s}(k)\] (274)

and

\[\sum_{k=N+1}^{\infty}\mathcal{P}_{s}(k)=\frac{N^{-\alpha}}{\alpha\zeta(\alpha+ 1)}+O(N^{-\alpha-1}).\] (275)

For the sum of \(\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))^{D}\) over \(1\leq k\leq N\), we use the estimate (see Eq. (276)) of

\[\sum_{k=1}^{M}\mathcal{P}_{s}(k)(1-\mathcal{P}_{s}(k))^{D}=O\left(e^{-\mathcal{ P}_{s}(M)D}\right)\] (303)

and the estimate of Proposition 9. Combining all those gives

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}]\] (304) \[= \frac{S^{2}N^{-\alpha}}{2\alpha\zeta(\alpha+1)}\] (305) \[+D^{-\alpha/(\alpha+1)}\frac{(S-r)^{2}\zeta(\alpha+1)^{-1/(\alpha +1)}}{2(\alpha+1)}\left(\Gamma\left(\frac{\alpha}{\alpha+1},D\mathcal{P}_{s}( N)\right)-\Gamma\left(\frac{\alpha}{\alpha+1},D\mathcal{P}_{s}(M)\right)\right)\] (306) \[+O\left(S^{2}(D^{-(2\alpha+1)/(\alpha+1)}+D^{-\alpha/(\alpha+1)} M^{-1}+N^{-\alpha-1}+e^{-\mathcal{P}_{s}(M)D})+S^{4}r^{-2}e^{-4\eta ST/D}\right).\] (307)

We will prove our main statement by choosing appropriate \(M\) depending on size comparison between \(D\) and \(N\).

1. If \(N=o(D^{1/(\alpha+1)})\), then we let \(M=3\), and also regard all incomplete gamma function values as \(O(1)\). Then it follows \[\mathbf{E}_{\mathcal{D}}[\mathcal{L}]=\frac{S^{2}N^{-\alpha}}{2\alpha\zeta( \alpha+1)}+O\left(S^{2}D^{-\alpha/(\alpha+1)}+S^{2}N^{-\alpha-1}+S^{4}r^{-2}e^ {-4\eta ST/D}\right)\] (308) and thus obtaining the parameter scaling law.
2. Suppose \(D=O(N^{\alpha+1})\) and \(\mu=\lim(D/N^{\alpha+1})\) exists. We want \[D^{-\alpha/(\alpha+1)}\frac{(S-r)^{2}\zeta(\alpha+1)^{-1/(\alpha+1)}}{2(\alpha +1)}\Gamma\left(\frac{\alpha}{\alpha+1},D\mathcal{P}_{s}(N)\right)+\frac{S^{2 }N^{-\alpha}}{2\alpha\zeta(\alpha+1)}\] (309) to be our main term, and set \(M<N\) such that the term \[S^{2}D^{-\alpha/(\alpha+1)}\Gamma\left(\frac{\alpha}{\alpha+1},D\mathcal{P}_{ s}(M)\right)\] (310) and error terms not depending on \(T\) given as \[O\left(S^{2}(D^{-(2\alpha+1)/(\alpha+1)}+D^{-\alpha/(\alpha+1)}M^{-1}+N^{- \alpha-1}+e^{-\mathcal{P}_{s}(M)D})\right)\] (311) are all bounded by \(O(D^{-(2\alpha+1)/(2\alpha+2)})\). Set \(M=D^{1/(2\alpha+2)}\). Then \(\mathcal{P}_{s}(M)=D^{-1/2}/\zeta(\alpha+1)\), so applying the asymptotic \(\Gamma(s,x)=O(x^{s-1}e^{-x})\) gives \[\Gamma\left(\frac{\alpha}{\alpha+1},D\mathcal{P}_{s}(M)\right)=O\left(D^{-1/ 2(\alpha+1)}e^{-\sqrt{D}/\zeta(\alpha+1)}\right).\] (312) This term and \(e^{-\mathcal{P}_{s}(M)D}=e^{-\sqrt{D}/\zeta(\alpha+1)}\) are less than \(D^{-\alpha/(\alpha+1)}M^{-1}=O(D^{-(2\alpha+1)/(2\alpha+2)})\), and obviously \(D^{-(2\alpha+1)/(\alpha+1)}\) is less than \(D^{-(2\alpha+1)/(2\alpha+2)}\). Thus it follows that \[\mathbf{E}_{\mathcal{D}}[\mathcal{L}] =D^{-\alpha/(\alpha+1)}\frac{(S-r)^{2}\zeta(\alpha+1)^{-1/(\alpha +1)}}{2(\alpha+1)}\Gamma\left(\frac{\alpha}{\alpha+1},\frac{D}{N^{\alpha+1} \zeta(\alpha+1)}\right)+\frac{S^{2}N^{-\alpha}}{2\alpha\zeta(\alpha+1)}\] \[\quad+O\left(S^{2}D^{-(2\alpha+1)/(2\alpha+2)}+S^{4}r^{-2}De^{-4 \eta ST/D}\right).\] (313) Regarding the final statement regarding sufficient condition for large \(T\), \(T\gg D(\log D)^{1+\epsilon}\) implies \[De^{-4\eta ST/D}<De^{-4\eta S(\log D)^{1+\epsilon}}<D\cdot D^{-4\eta S(\log D )^{\epsilon}}\ll D^{-K}\] (314) for any \(K>0\), showing that the error term \(O\left(S^{4}r^{-2}De^{-4\eta ST/D}\right)\) is negligible compared to all other error terms of Eq. (299) and Eq. (300). \(\blacksquare\)

We also provide a summary of all large time estimation results.

**Corollary 6**.: _(Summary of large time estimation) Assuming \(T\gg D(\log D)^{1+\epsilon}\) and \(n_{s}\gg N^{1+\epsilon}\) such that effects of \(n_{s}\) and \(T\) are negligible, and \(\mathcal{R}_{k}(0)=r\) for all \(1\leq k\leq N\). Then for \(D,N\to\infty\), we have_

\[\mathbf{E}_{\mathcal{D}}[\mathcal{L}]=\Theta_{\eta,S,r}\left(\max(N^{-\alpha}, D^{-\alpha/(\alpha+1)})\right),\] (315)

_where \(\Theta_{\eta,S,r}\) denotes that the implied constant depends on \(\eta,S,r\) and \(\alpha\). In particular, we have_

\[N^{\alpha+1}=O(D)\quad\Rightarrow\quad\mathbf{E}_{\mathcal{D}}[\mathcal{L}]= \Theta_{\eta,S,r}(N^{-\alpha})\] (316)

_and_

\[D=O(N^{\alpha+1})\quad\Rightarrow\quad\mathbf{E}_{\mathcal{D}}[\mathcal{L}]= \Theta_{\eta,S,r}(D^{-\alpha/(\alpha+1)}).\] (317)

**Proof** Just summarize the results of Theorem 5. \(\blacksquare\)Methods

In this section, we present the methods used in our experiments.

### 2-layer MLP

We trained a 2-layer fully connected neural network (MLP) with ReLU activations. All parameters of the MLP were initialized with a Gaussian distribution with a standard deviation of \(0.001\). The input dimension of the model was \(n_{s}+n_{b}=5+32\) where \(n_{s}\) is the length of control bits (number of skills) and \(n_{b}\) is the length of the skill bits. Each skill has \(m=3\) mutually exclusive sparse bits that are used to express the skill function. The target scale was \(S=5\). The model was trained with SGD without momentum and no weight decay (the exception is the parameter emergence experiment where Adam with learning rate \(0.001\) and weight decay of \(5\times 10^{-5}\) was used to escape the local minima).6 For the data emergence experiment, the learning rate was halved every \(50,000\) step.

Footnote 6: We are free to choose any optimizer as long as it preserves the order in which the skills are learned. Additionally, the parameter emergence experiment uses infinite data; we expect the same solution for Adam and SGD.

The skill strength \(\mathcal{R}_{k}(T)\) (Eq. (7)) was measured using \(20,000\) i.i.d samples from the \(k^{th}\) skill.7 For the time emergence, the skill strengths were measured every 50 steps, while for other experiments, they were measured after training. To mimic the infinite parameter \(N\rightarrow\infty\), we used the model of width \(1000\) (for the hidden layer). To mimic the infinite time \(T\rightarrow\infty\), we trained for \(5\times 10^{5}\) steps (\(3\times 10^{4}\) steps for time emergence) where each step had the batch size of \(4000\) (\(2000\) for the data emergence experiment). To mimic \(D\rightarrow\infty\), we sampled new data points for every batch. The details are given in the following table.

Footnote 7: Note that except the data scaling law experiment, the training set size is infinite.

### Transformer

This section outlines the transformer architecture used in Fig. 4. Data is encoded as for the 2-layer MLP, but with one-hot positional encoding appended to the data. We use a basic decoder transformer with 1 block, an initial embedding layer with output dimension 512, and a final linear layer. For the attention mechanism, we used 4 attention heads. For non-linearity, we used ReLU. A batch size of 5000 was used with a target scale \(S=1\) and default Pytorch initialization. The model was trained with SGD with a learning rate of \(5\times 10^{-5}\), weight decay of \(10^{-5}\), and momentum with \(\beta=0.9\). At every 100 steps, the skill strength \(\mathcal{R}_{k}(T)\) (Eq. (7)) was measured using \(20,000\) i.i.d samples from the \(k^{th}\) skill.

### Measurement of skill strength

The skill strength \(\mathcal{R}_{k}\) is a simple linear correlation between the learned function \(f\) - function expressed by NN - and \(g_{k}\) for \(\mathcal{P}_{b}\) given \(I=k\). We approximate the expectation over \(X\) by taking the mean over \(20,000\) i.i.d samples from \(\mathcal{P}_{b}\) for the \(k^{th}\) skill:

\[\mathcal{R}_{k}=\mathbf{E}_{X}[f(k,X)g_{k}(k,X)]\approx\frac{1}{20000}\sum_{j =1}^{20000}f(k,x^{(j)})g_{k}(k,x^{(j)}),\] (318)where the notation \(x^{(j)}\) denotes the \(j^{th}\) sample.

### Details of the scaling law experiment

For the loss of the model (solid lines) in Fig. 2, we used the analytic equation for the model (Eq. (12)) under suitable assumptions such as sufficiently large \(n_{s}\) (Table 2). For the scaling laws (dotted lines) in Fig. 2, we used the exponents from Appendix E or Appendix J and the prefactor constants from Theorem 4 (time scaling law), Theorem 5 (data scaling law), and Theorem 1 (parameter scaling law). For the hyperparameters of the simulation, we used \(n_{s}=10^{5}\) such that \(n_{s}\) is large compared to other resources; \(S=1\) and \(\mathcal{R}_{k}(0)=0.01\) such that \(S-\mathcal{R}_{k}(0)\approx S\); and \(\eta=1\).

Time scaling law.The total loss as a function of \(T\) for \(D,N\to\infty\) (Fig. 2(a), solid) is

\[\mathcal{L}=\frac{S^{2}}{2}\sum_{k=1}^{n_{s}}\mathcal{P}_{s}(k)\frac{1}{\left( 1+\left(\frac{S}{\mathcal{R}_{k}(0)}-1\right)^{-1}e^{2\eta\mathcal{P}_{s}(k) ST}\right)^{2}},\] (319)

which follows by taking \(D\to\infty\) and \(N=n_{s}\) on Eq. (12). The scaling law (Fig. 2(a), dotted) is

\[\mathcal{L}=\mathcal{A}_{T}T^{-\alpha/(\alpha+1)},\] (320)

where the exponent is derived in Appendix E.1 or Theorems 2 and 3. The prefactor constant is

\[\mathcal{A}_{t}=\frac{S^{2}}{2}\frac{\zeta(\alpha+1)^{-1/(\alpha+1)}}{(\alpha +1)(\eta S)^{\alpha/(\alpha+1)}}\int_{0}^{\infty}\frac{u^{-1/(\alpha+1)}}{ \left(1+\left(\frac{S}{r}-1\right)^{-1}e^{2u}\right)^{2}}du,\] (321)

which we obtained by taking \(D\to\infty\) on Eq. (238).

Data scaling law.The total loss as a function of \(D\) when \(N,T\to\infty\) (Fig. 2(b), solid) is

\[\mathbf{E}_{D}\left[\mathcal{L}\right]=\frac{S^{2}}{2}\sum_{k=1}^{n_{s}}\left( 1-\mathcal{P}_{s}(k)\right)^{D}\mathcal{P}_{s}(k),\] (322)

which follows from Eq. (58). The scaling law (Fig. 2(b), dotted) is

\[\mathcal{L}=\mathcal{A}_{D}D^{-\alpha/(\alpha+1)},\] (323)

where the exponent follows from Appendix E.2 or Theorem 5. The prefactor constant is

\[\mathcal{A}_{D}=\frac{S^{2}}{2}\frac{\zeta(\alpha+1)^{-1/(\alpha+1)}}{\alpha +1}\Gamma\left(\frac{\alpha}{\alpha+1}\right)\] (324)

which we obtained by taking \(N\to\infty\) in Eq. (302).

Parameter scaling law.The total loss as a function of \(N\) when \(T,D\to\infty\) (Fig. 2(c), solid) is

\[\mathcal{L}=\frac{S^{2}}{2}\sum_{k=N+1}^{n_{s}}\mathcal{P}_{s}(k),\] (325)

which follows from taking \(T,D\to\infty\) on Eq. (12). The scaling law (Fig. 2(c), dotted) is

\[\mathcal{L}=\mathcal{A}_{N}N^{-\alpha},\] (326)

where the exponent follows from Theorem 1. The prefactor constant is

\[\mathcal{A}_{N}=\frac{S^{2}}{2},\] (327)

which we obtained by taking \(D,T\to\infty\), \(N/n_{s}\to 0\), and \(\zeta(\alpha+1)\approx\alpha^{-1}\) in Eq. (217).

Compute scaling law.The total loss as a function of \(T\) and \(N\) for \(D\to\infty\) (Fig. 3, solid) is

\[\mathcal{L}=\frac{S^{2}}{2}\sum_{k=1}^{N}\mathcal{P}_{s}(k)\frac{1}{\left(1+ \left(\frac{S}{\mathcal{R}_{k}(0)}-1\right)^{-1}e^{2\eta\mathcal{P}_{s}(k)ST} \right)^{2}}+\sum_{k=N+1}^{n_{s}}\mathcal{P}_{s}(k),\] (328)

which follows by taking \(D\to\infty\) in Eq. (12). In Fig. 3, we plotted for \(N\in\{10,20,50,70,100,200,500,700,1000,2000,5000,10000\}\) and \(T\in[1,1000]\) as examples of different tradeoff between \(T\) and \(N\) for fixed \(C\).

The scaling law (Fig. 3, dotted) is

\[\mathcal{L}=\mathcal{A}_{c}C^{-\alpha/(\alpha+2)},\] (329)

where the exponent is derived in Appendix E.4 or Corollary 4. Using Corollary 5, the prefactor constant is

\[\mathcal{A}_{c}=\mathcal{A}\left(\lambda^{(\alpha+2)/(\alpha+1)}\right)\lambda ^{\alpha/(\alpha+1)}\left(\eta S\right)^{-\alpha/(\alpha+2)}\] (330)

where \(\mathcal{A}:\mathbb{R}\to\mathbb{R}\) is defined in Eq. (238). We used the minimum value of \(\mathcal{A}_{c}\) for \(\lambda\in(0,\infty]\).

### Estimates of the compute use

On CPU, our emergence experiments on the 2-layer MLP (Fig. 1) take \(2\sim 5\) hours for a single run of time emergence experiments and \(20\sim 40\) hours for a single run of other experiments depending on the CPU. All experiments were repeated \(10\) times (except for parameter emergence where we repeated the experiment \(50\) times). Each experiment requires memory of at most \(5\)GB. The CPU cluster in which we experimented contained the following CPUs: Intel(R) Core(TM) i5-7500, i7-9700K, i7-8700; and Intel(R) Xeon(R) Silver 4214R, Gold 5220R, Silver 4310, Gold 6226R, E5-2650 v2, E5-2660 v3, E5-2640 v4, Gold 5120, Gold 6132. The transformer experiment (Fig. 4) takes \(48\sim 72\) hours for each run; we used an RTX4090 with 24GB RAM, with 1 CPU from the list above.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The claims in the abstract and introduction accurately reflect the paper's contributions, as evidenced by the contribution list in the introduction section, which references the sections presenting each result. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: The paper discusses the limitations of the multilinear model in Section 5.5 and the general limitations regarding the assumptions about the framework in Section 6 (Discussion and Conclusion). These sections address the robustness of the results and the scope of the claims made. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs**Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: All theoretical results are accompanied by intuitive explanations in the main text, with detailed derivations (Appendices C and E) and rigorous proofs (Appendix J) in the supplemental material. In addition, an alternative derivation of the scaling laws via stage-like training is given in Appendix D. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We have provided details - architecture, initialization, learning setup, and measurements - of our experiments in Appendix K including the details of NN for emergence experiment (Fig. 1) in Appendix K.1, the details of scaling law experiment (Figs. 2 and 3) in Appendix K.4, the details of the transformer experiment (Fig. 4) in Appendix K.2. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).

* We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
* **Open access to data and code*
* Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: We provide a link to our source code in the main text. Guidelines:
* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
* **Experimental Setting/Details*
* Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: We specify the details in Appendix K.1 (2-layer NN) and Fig. 4 (transformer). Guidelines:
* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.
* **Experiment Statistical Significance*
* Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: Yes, all our figures in the main text, which are not simulations (Figs. 1 and 4), have 1-standard deviation error bars. Guidelines:
* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We provide the compute resource details in Appendix K.5. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: The research conducted in this paper adheres to the principles outlined in the NeurIPS Code of Ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA]Justification: This research aims to deepen the fundamental understanding of emergence phenomena and scaling laws in deep learning. As our theoretical and empirical investigations are conducted in a carefully controlled, idealized environment, we do not anticipate any immediate societal consequences arising directly from the findings of this particular study. Guidelines:

* The answer NA means that there is no societal impact of the work performed.
* If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.
* Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.
* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The research presented in this paper does not involve the release of data or models that pose a risk for misuse. Guidelines:

* The answer NA means that the paper poses no such risks.
* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.

12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: This paper does not use any existing assets from other sources. Guidelines: * The answer NA means that the paper does not use existing assets.

* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.
* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release new assets. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve any crowdsourcing experiments or research with human subjects. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: No IRB approvals or equivalent reviews were required.

Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.