# QuinNet: Efficiently Incorporating Quintuple Interactions into Geometric Deep Learning Force Fields

Zun Wang

Microsoft Research AI4Science

Beijing, China, 100084

zunwang@microsoft.com

&Guoqing Liu

Microsoft Research AI4Science

Beijing, China, 100084

&Yichi Zhou

Microsoft Research AI4Science

Beijing, China, 100084

&Tong Wang

Microsoft Research AI4Science

Beijing, China, 100084

&Bin Shao

Microsoft Research AI4Science

Beijing, China, 100084

binshao@microsoft.com

###### Abstract

Machine learning force fields (MLFFs) have instigated a groundbreaking shift in molecular dynamics (MD) simulations across a wide range of fields, such as physics, chemistry, biology, and materials science. Incorporating higher order many-body interactions can enhance the expressiveness and accuracy of models. Recent models have achieved this by explicitly including up to four-body interactions. However, five-body interactions, which have relevance in various fields, are still challenging to incorporate efficiently into MLFFs. In this work, we propose the quintuple network (QuinNet), an end-to-end graph neural network that efficiently expresses many-body interactions up to five-body interactions with _ab initio_ accuracy. By analyzing the topology of diverse many-body interactions, we design the model architecture to efficiently and explicitly represent these interactions. We evaluate QuinNet on public datasets of small molecules, such as MD17 and its revised version, and show that it is compatible with other state-of-the-art models on these benchmarks. Moreover, QuinNet surpasses many leading models on larger and more complex molecular systems, such as MD22 and Chignolin, without increasing the computational complexity. We also use QuinNet as a force field for molecular dynamics (MD) simulations to demonstrate its accuracy and stability, and conduct an ablation study to elucidate the significance of five-body interactions. We open source our implementation at [https://github.com/Zun-Wang/QuinNet](https://github.com/Zun-Wang/QuinNet).

## 1 Introduction

Machine learning force fields (MLFFs) [1, 2, 3, 4, 5, 6] have brought about a transformative shift in molecular dynamics (MD) simulations across diverse fields, including physics, chemistry, biology, and material science. MLFFs enable superior accuracy and reliability by leveraging _ab initio_ and experimental data to learn interatomic interactions, while simultaneously keeping the low cost of empirical force fields. As a result, MLFFs provide a powerful tool for accurately modeling molecularinteractions, and have the potential to revolutionize our understanding of complex systems at both the atomistic and macroscopic scales.

Recent geometric deep learning potentials, represent atoms in a system as nodes and chemical bonds as edges in a graph while incorporating physical symmetries. These methods have been proven to be data-efficient and effective in modeling many-body interactions [7]. The development track of geometric deep learning potentials is similar to that of empirical force fields, which follow the many-body expansion theory [8; 9; 10]. Previous studies [11; 12; 13; 14; 15; 16; 17; 18; 19; 20] have primarily adopted a hierarchical approach to model truncated energy correction terms, enabling the incorporation of higher-order interactions. As higher-order many-body interactions play a critical role in accurately modeling complex molecular systems, this approach has shown promise in leveraging graph neural networks (GNNs) [21] to construct more expressive and accurate models.

Nowadays, GNN models have incorporated many-body interactions up to four-body interactions explicitly [17; 18; 19; 20] and incorporating higher order many-body interactions is still a challenge. The neglect of higher-order many-body interactions may result in incomplete molecular representations [22] and limited accuracy in certain cases [23; 24]. For example, five-body interactions play an important role in various fields such as coarse-grained protein force field [25], organic molecules [26], crystal vibrations [27; 28], electrostatic interaction potentials [29], and so on.

In this paper, we develop a MLFF based on GNNs, called quintuple network (QuinNet), to address the challenge of incorporating higher order many-body interactions, up to quintuple, into molecular representations without introducing more computational complexity. To achieve this, we analyze the topology of diverse many-body interactions and design QuinNet to explicitly represent these interactions efficiently. Our approach outperforms existing methods in terms of accuracy on several large molecular systems (e.g., MD22 and Chignolin dataset) while remaining comparable on small molecules (e.g., MD17 and revised MD17 dataset). Additionally, computational complexity analysis demonstrates the efficiency of our model. Our work has the potential to advance the field of MLFFs by providing methods to incorporate higher order many-body interactions.

## 2 Related Work

The field of MLFFs has witnessed significant progress since the introduction of the first neural network-based framework by Behler and Parrinello [30]. However, the inherent indistinguishability of atoms has posed a challenge in ordering them, which has limited the success of this approach. To overcome this challenge, GNNs have emerged as a promising solution, leveraging the power of graph formalism to focus on relationships among entities rather than individual node properties.

Currently, two mainstream GNN-based methods have been developed for constructing force fields: group theory-based methods and direction-based methods. Group theory-based methods preserve physical symmetries by imposing trainable weights as the representation of related groups [22; 31]. These equivariant models, including Tensor Field Networks [32], Cormorant [33], SE(3)-Transformers [34], NequIP [7], Equiformer [35], and Allegro [36], have demonstrated high performance across diverse tasks. Furthermore, the MACE [37], which was developed hierarchically using a body order expansion manner, has been proposed as a unifying framework of E(3)-equivariant atom-centered interatomic potentials, extending the ACE [38] framework to include methods built on equivariant message passing neural networks (MPNNs).

On the other hand, direction-based methods, such as SchNet [11; 12], DimeNet (DimeNet++) [13; 14], PaiNN [15], ET [16], GemNet [17], SphereNet [18], ComENet [19], and ViSNet [20], explicitly model interatomic interactions by incorporating more geometric information. This progress has motivated us to investigate the potential performance enhancements of explicitly incorporating higher-order interactions into GNN-based force fields.

## 3 Preliminary

### GNN-based force fields

The key idea of graph neural networks boils down to a message-passing framework [39], wherein each node iteratively updates its embedding by aggregating messages from its neighboring nodes.

With \(h_{v}\) and \(e_{vw}\) denoting node features and edge features respectively, the message-passing layer is defined as

\[\begin{split} m_{v}^{t+1}&=\sum_{w\in\mathcal{N}(v)}M_{ t}(h_{v}^{t},h_{w}^{t},e_{vw}^{t}),\\ h_{v}^{t+1}&=U_{t}(h_{v}^{t},m_{v}^{t+1}),\end{split} \tag{1}\]

where \(M_{t}\) and \(U_{t}\) are a message function and an update function, respectively. In the realm of GNN-based force field, physical symmetries such as translation, rotation, and permutation symmetries have been demonstrated to be intrinsic and highly effective for model design.

Group equivarianceLet \(\mathcal{L}:\mathcal{X}\rightarrow\mathcal{Y}\) be a function that maps from input space \(\mathcal{X}\) to output space \(\mathcal{Y}\). We say that \(\mathcal{L}\) is equivariant with respect to a group \(G\) if for all group element \(g\in G\),

\[\mathcal{L}\circ D^{\mathcal{X}}(g)=D^{\mathcal{Y}}(g)\circ\mathcal{L}, \tag{2}\]

where \(D^{\mathcal{X}}\) is the representation of group \(G\) in the input vector space \(\mathcal{X}\).

Group equivariant convolutional layerIn recent years, there has been a growing interest in designing group equivariant neural networks due to the importance of respecting relevant symmetries as an inductive bias. Specifically, the group equivariant convolutional layer is defined as follows:

\[\mathcal{L}^{(l_{o})}_{acm_{o}}(\vec{r}_{a},V^{l_{i}}_{acm_{i}})\coloneqq\sum _{m_{f},m_{i}}C^{(l_{o},m_{o})}_{(l_{f},m_{f})(l_{i},m_{i})}\sum_{b\in S}F^{(l_ {f},l_{i})}_{cm_{f}}(\vec{r}_{ab})V^{l_{i}}_{bcm_{i}}, \tag{3}\]

where the node features are denoted by \(V\), and \(\vec{r}_{ab}\) represents the relative position vector between point \(a\) and point \(b\). The subscripts \(c\), \(i\), \(f\), and \(o\) denote channel, input, filter, and output, respectively. Additionally, \(l\) and \(m\) correspond to the orbital quantum number and magnetic quantum number, respectively. This definition of the group equivariant convolutional layer is an important contribution to the development of neural networks that can effectively handle physical symmetries.

### Empirical force fields

In classical molecular dynamics simulations, force fields play a crucial role in describing the potential energy \(\mathcal{V}(\mathbf{r}^{N})\) of a system, where \(\mathbf{r}^{N}\) represents the positions of \(N\) particles. A common functional form for force fields is \(\mathcal{V}(\mathbf{r}^{N})=E_{\text{bonded}}+E_{\text{non-bonded}}\). The bonded energy term captures the deviation of bonds and angles from their equilibrium values, while the non-bonded interactions include long-range forces, such as electrostatic and van der Waals interactions. To represent the bonded interactions hierarchically, bond stretching, angle bending, bond rotation, and other factors can be taken into account.

Improvement of torsion potentialThe torsion potential is a crucial aspect of molecular modeling, representing the energy associated with the rotation of dihedral angles between bonded atoms. While many of the torsion terms are comprised of only one term from the cosine series expansion [40], it has been discovered that including more than one term is necessary for certain bonds, such as gauche conformations [41; 42]. This involves the use of higher order cosine series, represented by \(\sum_{n=0}^{N}\frac{V_{n}}{2}\left[1+\cos(n\omega-\gamma)\right]\), where \(\omega\) denotes the torsion angle and \(V_{n}\) is the barrier height.

Improper torsions and out-of-plane bending motionsExperimental observations have shown that in certain molecular systems, the atom connected to a ring tends to remain in the same plane due to the \(\pi\)-bonding energy. However, the force field discussed in the previous section predicts an equilibrium structure with the atom out of plane. In order to correct this discrepancy, an additional term or terms need to be incorporated into the force field to ensure that the sp\({}^{2}\) carbon and its three bonded atoms remain in the same plane. One simple approach is to include an "out-of-plane"

Figure 1: Two methods to represent out-of-plane bending terms: (a) calculating the angle between a bond from the central atom and the plane defined by the central atom and the other two atoms and (b) calculating the height of the central atom above a plane defined by the other three atoms.

bending term [43]. Fig. 1 illustrates two methods that can be used to model the out-of-plane bending contributions. The first method involves calculating the angle between a bond from the central atom and the plane defined by the central atom and the other two atoms, as shown in Fig. 1 (a). The second method calculates the height of the central atom above a plane defined by the other three atoms, as shown in Fig. 1 (b).

### Challenge of incorporating higher order many-body interactions into GNNs explicitly

Higher-order many-body interactions could be learned implicitly by stacking more MPNN layers, while incorporating these interactions explicitly into GNNs would improve the performance significantly. Incorporating many-body interactions explicitly into GNN models heavily relies on the selection of appropriate physical quantities, such as bond lengths, bond angles, and dihedral angles. However, for higher order many-body interactions, finding a suitable quantity poses a significant challenge. Moreover, calculating such a physical quantity increases the computational complexity as the order of interactions increases. Therefore, solving this problem while simultaneously reducing computational complexity is of utmost importance.

## 4 Methods

To explicitly incorporate five-body interactions into GNNs, we first analyze the topology of three-, four-, and five-body interactions to identify the key physical quantities required to describe these many-body interactions. Based on this analysis, we design the model architecture to effectively capture and represent these interactions.

### Topology of five-body interactions

Five-body interactions have been shown to play a critical role in various cases, such as reproducing specific phenomena in protein systems [25]. While three-body and four-body interactions can be effectively captured by incorporating angular and dihedral angular information, which physical quantity is suitable for representing the five-body interactions explicitly is still a question.

In this work, we propose to use dihedral angles as a unified physical quantity to describe five-body interactions. Fig. 2 illustrates the topology of three-body, four-body, and five-body interactions, respectively. Fig. 2 (a) and (c) show that three-body interactions and improper torsion in four-body interactions could be represented as angles; and Fig. 2 (b) implies that torsion in four-body interactions could be represented as dihedral angles. There are only three different topologies for five-body interactions (Fig. 2 (d)-(f)) and all of them could be represented as dihedral angles. To calculate dihedral angles, we first compute the cosine of the angle between two planes formed by vectors connecting neighboring atoms. For instance, in Fig. 2 (d), atoms \(j_{1}\), \(j_{2}\), \(j_{3}\), and \(j_{4}\) form a neighborhood around atom \(i\), and the normal vector of the plane composed of vectors \(\vec{r}_{ij_{1}}\) and \(\vec{r}_{ij_{2}}\) can be computed using their outer product, i.e. \((\vec{r}_{ij_{1}}\times\vec{r}_{ij_{2}})\cdot(\vec{r}_{ij_{3}}\times\vec{r}_{ ij_{4}})\). The dihedral angle

Figure 2: A schematic diagram that describes the topology of (a) three-body interaction (angles), (b) four-body interaction (torsions), (c) four-body interaction (improper torsions), and (d-f) five-body interactions. The marker \(\bigcirc\) on a plane represents the normal vector of this plane.

between these two planes can be easily determined as the supplementary angle to the angle between their normal vectors, which can be calculated by taking their inner product. Further details on the relationships between different many-body interactions refer to the Supplementary Materials.

### Architecture of QuinNet

Inspired by the topology analysis of many-body interactions, we design the model architecture of QuinNet. The overall schematic diagram of QuinNet is shown in Fig. 3 (a), which explicitly incorporates many-body interactions and reduces computational complexity simultaneously. In particular, we design the QuinNet module, as shown in Fig. 3 (b), where different many-body (i.e., from 3-body to 5-body) interactions are handled separately and linearly combined as the output of the module.

Three-body interactionsThe three-body interaction, which is related to angular information as depicted in Fig. 2 (a), is handled using the PaiNN [15] approach (refer to Fig. 3 (c)). The equation for the three-body interaction is expressed as:

\[\left\|\sum_{j\in\mathcal{N}_{i}}\hat{r}_{ij}\right\|^{2}=\sum_{j,k\in \mathcal{N}_{i}}\langle\hat{r}_{ij},\hat{r}_{ij}\rangle=\sum_{j,k\in\mathcal{ N}_{i}}\cos\alpha_{jik}, \tag{4}\]

where \(\hat{r}_{ij}\) denotes the normalized vector of relative position bewteen atom \(i\) and \(j\), \(\vec{r}_{ij}\), and \(\langle\cdot,\cdot\rangle\) is inner product. This approach incorporates the representation of bond angular information into node \(i\).

Four-body interactions (torsion)The incorporation of torsion interactions in force fields necessitates the use of dihedral angular terms, as depicted in Fig. 2 (b). To address this, we adopt the ViSNet [20] model, which explicitly accounts for torsion energy, as shown in Fig. 3 (b). This is achieved through vector rejection of the direction unit of node \(i\), \(\vec{v}_{i}\), which is equivalent to Gram-Schmidt normalization. In 3-dimensional space, the process reduces to calculating the cross product of the normal vector of two planes, as what we summarized in the last section. The torsion angles are then represented via

\[\left(\sum_{j\in\mathcal{N}_{i}}\hat{r}_{ij}\times\hat{r}_{ij_{1}}\right)\cdot \left(\sum_{k\in\mathcal{N}_{j_{1}}}\hat{r}_{jk}\times(-\hat{r}_{ij_{1}}) \right)=\sum_{\begin{subarray}{c}j\in\mathcal{N}_{i},\\ k\in\mathcal{N}_{j_{1}}\end{subarray}}\langle\vec{n}_{ij_{1}j_{2}},\vec{n}_{ ij_{1}k}\rangle, \tag{5}\]

where \(\vec{n}_{ijk_{1}}\) is the normal vector of the plane composed of nodes \(i\), \(j\), and \(k_{1}\) (\(i\), \(j\), and \(k_{1}\) are non-colinear). This approach constructs hidden states with dihedral angular information for edge \(e_{ij}\).

Four-body interactions (improper torsion)As ViSNet does not incorporate improper torsion term, the QuinNet module incorporates the out-of-plane bending term by computing it in the same manner as Fig. 2 (c), as depicted in Fig. 3 (e). Specifically, the term is computed using the equation

\[\sum_{j\in\mathcal{N}_{i}}\hat{r}_{ij}\cdot\left[\left(\sum_{j\in\mathcal{N}_ {i}}\alpha_{j}\hat{r}_{ij}\right)\times\left(\sum_{j\in\mathcal{N}_{i}}\beta_ {j}\hat{r}_{ij}\right)\right]=\sum_{j_{1},j_{2},j_{3}\in\mathcal{N}_{i}}\gamma _{ij_{1}j_{2}}\langle\vec{r}_{ij_{3}},\vec{n}_{ij_{1}j_{2}}\rangle. \tag{6}\]

where the different coefficients \(\alpha_{j}\) and \(\beta_{j}\) are introduced to prevent the term from being zero due to the properties of the cross product and the \(\gamma\) is the coefficient from the product of \(\alpha\) and \(\beta\). The out-of-plane bending term is an essential component of nodes' embedding.

Five-body interactions@1The evaluation the five-body@1 term could be represented as dihedral angles (depicted in Fig. 2 (d) and Fig. 3 (f)):

\[\left\|\left(\sum_{j\in\mathcal{N}_{i}}\alpha_{j}\hat{r}_{ij}\right)\times \left(\sum_{j\in\mathcal{N}_{i}}\beta_{j}\hat{r}_{ij}\right)\right\|^{2}=\sum _{j_{1},j_{2},j_{3},j_{4}\in\mathcal{N}_{i}}\gamma_{ij_{1}j_{2}j_{3}j_{4}} \langle\vec{n}_{ij_{1}j_{2}},\vec{n}_{ij_{3}j_{4}}\rangle. \tag{7}\]

As noted before, different coefficients \(\alpha_{j}\) and \(\beta_{j}\) are assigned to avoid the term becoming zero and the term provides a node embedding. Moreover, the term encompasses a portion of the description for improper interactions, and further details can be found in the Supplementary Materials.

Figure 3: A schematic diagram of QuinNet. (a) The overall architecture of QuinNet, where \(\{Z\}\) represents the set of atomic numbers. The initial node features are zero vectors of a fixed dimension. The QuinNet module inputs scalar and vectorial node features \(s_{i}\) and \(\vec{v}_{i}\), radial basis function (RBF) as scalar edge feature \(e_{ij}\), and relative position vector \(\vec{r}_{ij}\) as vectorial edge feature, and then outputs an updated scalar and vectorial node feature and scalar edge feature for the next layer. The set of spherical harmonic functions, \(Y_{i}m\), is denoted as \(Y_{l}\). The final scalar node features are summed to form the graph feature, and the target prediction is obtained. (b) The QuinNet module consists of six modules that handle (c) 3-body interactions, (d) torsion terms in 4-body interactions, (e) improper terms in 4-body interactions, and (f)-(h) five-body interactions, respectively. The normal vector corresponding to node \(j\) is represented by \(\vec{n}_{j}\). In a linear layer, the weights are referred to as \(W\), while the term \(b\) signifies the bias.

Five-body interactions@IITo compute the five-body interaction@II term (refer to Fig. 2 (e) and Fig. 3 (g)), we use the following equation to construct hidden states on edges:

\[\left\|\left(\sum_{k_{\in\mathcal{N}_{j_{1}}}}\alpha_{k}\hat{r}_{kj_{1}}\times \sum_{k\in\mathcal{N}_{j_{1}}}\beta_{k}\hat{r}_{kj_{1}}\right)\Bigg{|}_{j_{1} \in\mathcal{N}_{i}}\right\|^{2}=\sum_{\begin{subarray}{c}k_{1}\in\mathcal{N}_{j _{1}}\\ k_{2}\in\mathcal{N}_{j_{2}}\end{subarray}}\gamma_{j_{1}j_{2}k_{1}k_{2}}(\vec{n }_{ij_{1}k_{1}},\vec{n}_{ij_{2}k_{2}})_{j_{1},j_{2}\in\mathcal{N}_{i}}\,, \tag{8}\]

where \(\big{|}_{j}\in\mathcal{N}_{i}\) indicates that the values should be chosen according to the source nodes of node \(i\).

Five-body interactions@IIIThe five-body interaction@III term, as illustrated in Fig. 2 (f) and Fig. 3 (h), is computed as follows,

\[\left(\sum_{j\in\mathcal{N}_{i}}\alpha_{j}\hat{r}_{ij}\times\sum_{j\in \mathcal{N}_{i}}\beta_{j}\hat{r}_{ij}\right)\!\cdot\left(\sum_{k\in\mathcal{N} _{j}}\alpha_{k}\hat{r}_{jk}\times\sum_{k\in\mathcal{N}_{j}}\beta_{k}\hat{r}_{ jk}\right)\Bigg{|}_{j\in\mathcal{N}_{i}}=\sum_{\begin{subarray}{c}j_{1},j_{2} \in\mathcal{N}_{j}\\ k_{1},k_{2}\in\mathcal{N}_{j}\end{subarray}}\gamma_{ij_{1}j_{2}k_{1}k_{2}}(\vec{ n}_{ij_{1}j_{2}},\vec{n}_{jk_{1}k_{2}})\Bigg{|}_{j\in\mathcal{N}_{i}}\,, \tag{9}\]

which constructs the representation of edges.

Higher order cosine seriesSince it is beneficial to include higher order cosine series terms in the force field [41; 42], we utilize the vector addition theorem of spherical harmonic functions. Although all the angular calculations in Eq. 4 - Eq. 9 only consider one order of cosine terms, the higher-order cosine terms could be incorporated easily by using the following equation:

\[P_{l}(\cos\theta)=\frac{4\pi}{2l+1}\sum_{m=-l}^{l}Y_{lm}^{*}(\hat{u})Y_{lm}( \hat{v}), \tag{10}\]

where \(\theta\) denotes the angle between two unit vectors \(\hat{u}\) and \(\hat{v}\), and \(P_{l}\) and \(Y_{l}\) represent Legendre polynomials and spherical harmonic functions of \(l\)-th order, respectively. \(Y_{l}^{*}\) is the complex conjugate of \(Y_{l}\). As \(l\) increases, higher-order cosine terms are incorporated into the calculation, enabling us to improve the accuracy of our model and make it suitable for a broader range of applications. Additional proof can be found in the Supplementary Materials.

### Complexity analysis

Inspired by the design of PaiNN [15], QuinNet incorporates many-body interactions by calculating relevant physical quantities during the message passing layer, eliminating the need for calculations beforehand. The operations within the QuinNet module can be decomposed into cross product and inner product, which are independent of the number of nodes' neighbors. As a result, the computational complexity of each many-body interaction is significantly reduced to \(\mathcal{O}(|\mathcal{N}|)\), where \(|\mathcal{N}|\) represents the number of neighbors for each node. This approach allows QuinNet to efficiently model complex interactions, enhancing its overall performance. A more comprehensive analysis refers to the Supplementary Materials.

## 5 Results

We conduct comprehensive evaluations on different datasets to demonstrate the effectiveness of the QuinNet model. First, we benchmark our model on the public MD17 [2] and revised MD17 [44] small molecular datasets, where the impact of five-body interactions is relatively weak. Despite this, we show that the QuinNet model shows comparable accuracy with the state-of-the-art models in these datasets. Moreover, QuinNet has also been benchmarked on the QM9 dataset [45; 46], the details of which can be found in the Supplementary Materials. Furthermore, we evaluate the performance of QuinNet on the larger molecular systems of MD22 [47] and Chignolin datasets [48]. These complex systems are known to exhibit a more pronounced influence of five-body interactions. Our evaluation demonstrates that QuinNet accurately models these interactions and achieves higher accuracy in energy and force prediction compared to other models.

### MD17 Dataset and MD Simulation

The MD17 dataset [2] contains a diverse range of sizes, spanning from 150k to nearly 1M conformational geometries. Each trajectory was computed at a temperature of 500 K with a resolution of 0.5 fs. The total energy and force labels for each dataset were computed using the PBE+vdW-TS electronic structure method [49, 50]. In Table 1, we present the mean absolute errors (MAEs) of QuinNet for 7 molecules in the MD17 dataset, along with comparisons to nine other models. QuinNet outperforms other tested models in nearly 57.14% of tasks, especially the performance on forces. Additionally, we perform MD simulations using trained QuinNets as force fields and plot the distribution of interatomic distances \(h(r)\) for these 7 molecules in Fig. 4. Further details regarding additional settings can be found in the Supplementary Materials.

### Revised MD17 Dataset

Christensen and von Lilienfeld discovered that the energy of the original MD17 dataset was noisy [44]. Therefore, 100,000 structures of each molecule were selected from the original dataset to create the revised MD17 dataset, and the energies and forces were recalculated at the PBE/def2-SVP level of theory using a very tight SCF convergence and a very dense DFT integration grid [49, 53, 54]. As shown in Table 2, QuinNet matches the performance of popular test models on the revised MD17 dataset. Supplementary Materials provide additional information on the relevant settings.

### MD22 Dataset

The MD22 dataset [47] is a recently introduced collection of MD trajectories, which encompasses four major classes of biomolecules and supramolecules, ranging from a small peptide consisting

\begin{table}
\begin{tabular}{l l l l l l l l l l l l} \hline \hline  & & SalNet [11, 22] & Diastolic [13] & PaNorm [15] & SparsorbNet [51] & ET [16] & GunNe [17] & Neupli [50, 3] & SONGRATES [52] & VMSNet [20] & QuinNet \\ \hline \multirow{2}{*}{Aeptin} & Energy & 0.37 & 0.204 & 0.167 & 0.151 & 0.123 & 0.131 & 0.139 & **0.116** & 0.119 \\  & Error & 1.35 & 0.499 & 0.338 & 0.258 & 0.253 & 0.217 & 0.184 & 0.226 & 0.155 & **0.145** \\ \hline \multirow{2}{*}{Ethanol} & Energy & 0.08 & 0.084 & 0.064 & 0.082 & 0.052 & - & 0.051 & 0.052 & 0.051 & **0.080** \\  & Force & 0.39 & 0.230 & 0.224 & 0.094 & 0.109 & 0.085 & 0.071 & 0.096 & **0.080** & **0.080** \\ \hline \multirow{2}{*}{Multimaldehyde} & Energy & 0.13 & 0.104 & 0.091 & 0.079 & 0.077 & 0.076 & 0.072 & **0.075** & 0.075 & 0.075 \\  & Force & 0.66 & 0.383 & 0.319 & 0.167 & 0.169 & 0.155 & 0.129 & 0.147 & 0.160 & **0.097** \\ \hline \multirow{2}{*}{Nephthalene} & Energy & 0.16 & 0.212 & 0.116 & 0.116 & **0.088** & - & 0.113 & 0.115 & **0.085** & 0.101 \\  & Force & 0.58 & 0.215 & 0.077 & 0.089 & 0.081 & 0.051 & **0.09** & 0.074 & **0.039** & **0.039** \\ \hline \multirow{2}{*}{Salicylic acid} & Energy & 0.20 & 0.134 & 0.116 & 0.114 & 0.093 & - & 0.106 & 0.016 & **0.092** & 0.101 \\  & Force & 0.85 & 0.314 & 0.105 & 0.129 & 0.125 & 0.090 & 0.145 & 0.046 & **0.080** \\ \hline \multirow{2}{*}{Toluene} & Energy & 0.12 & 0.026 & 0.095 & 0.094 & **0.074** & - & 0.092 & 0.095 & **0.075** & 0.080 \\  & Force & 0.57 & 0.216 & 0.094 & 0.087 & 0.067 & 0.060 & 0.066 & 0.073 & **0.039** & **0.039** \\ \hline \multirow{2}{*}{Unacil} & Energy & 0.14 & 0.115 & 0.106 & 0.105 & **0.095** & - & 0.104 & 0.103 & **0.095** & 0.096 \\  & Force & 0.56 & 0.301 & 0.139 & 0.119 & 0.095 & 0.097 & 0.076 & 0.111 & **0.082** & **0.082** \\ \hline \hline \end{tabular}
\end{table}
Table 1: Comparison of the MAEs between several benchmarked models and QuinNet trained on MD17 dataset using 950 training samples and 50 validation samples (energies in kcal/mol and forces in kcal/mol-Å). The lowest values are highlighted in bold.

Figure 4: The distribution of interatomic distances \(h(r)\) for (a) aspirin, (b) ethanol, (c) malonaldehyde, (d) naphthalene, (e) salicylic acid, (f) toluene, and (g) uracil in MD17 dataset. The insets display the ball-and-stick representations of these molecules.

of 42 atoms to a double-walled nanotube containing 370 atoms. The trajectories were sampled at temperatures between 400 and 500 K at a resolution of 1 fs, and the corresponding potential energy and atomic forces were calculated using the PBE+MBD [49; 50] level of theory. Table 3 presents the MAEs of the QuinNet model for seven systems within the MD22 dataset, along with a comparison to six benchmark models. Our results show that QuinNet outperforms the vast majority of benchmark models in predicting atomic forces, and since the MD22 dataset claims that long-range interactions are crucial, this could be the reason why the ViSNet-LSRM model that incorporates long-range interactions and the models with chosen cutoff radius have more accurate energy predictions. Further details on the relevant settings refer to the Supplementary Materials.

### Ablation study on Chignolin Dataset

The Chignolin, consisting of 166 atoms, serves as the simplest artificial protein for folding and unfolding studies. The dataset includes a diverse set of folding and unfolding states of Chignolin, comprising a total of 9,543 representative conformations [48]. As Wang et al.[25] noted that incorporating five-body interactions could enhance the performance of models on Chignolin, we performed an ablation study to evaluate the impact of various many-body interactions. As shown in Fig. 5, the explicit inclusion of five-body interactions up to part II led to a significant decrease in MAEs. It is worth noting that the energy errors exhibit some fluctuations when introducing five-body interactions up to part I. Considering that the five-body interactions up to part I to some extent describe the four-body improper terms, as demonstrated in the Supplementary Materials, we speculate that these two different representations of the same interaction may cause antagonism. To test this, we

\begin{table}
\begin{tabular}{l l l l l l l l l l} \hline \hline  & \multicolumn{2}{c}{UNITE [55]} & GenNet (TO) [17] & NcapIP (\(\mu\)=3) [7] & MacE [37] & Allegro [36] & BOTNet & ViSNet [20] & QuinNet \\ \hline \multirow{2}{*}{Aspirin} & Energy & 0.055 & - & 0.0530 & 0.0507 & 0.0530 & 0.0530 & **0.0445** & 0.0486 \\  & Force & 0.175 & 0.2191 & 0.1891 & 0.1522 & 0.1684 & 0.1960 & 0.1520 & **0.1429** \\ \hline \multirow{2}{*}{Azobenzene} & Energy & 0.025 & - & 0.0161 & 0.0277 & 0.0277 & 0.0161 & **0.0156** & 0.0394 \\  & Force & 0.097 & - & 0.0669 & 0.0692 & 0.0600 & 0.0761 & 0.0585 & **0.0513** \\ \hline \multirow{2}{*}{Benzene} & Energy & 0.002 & - & 0.0009 & 0.0002 & 0.0069 & **0.0007** & **0.0007** & 0.0096 \\  & Force & 0.017 & 0.0115 & 0.0069 & 0.0069 & **0.0046** & 0.0069 & 0.0066 & 0.00047 \\ \hline \multirow{2}{*}{Ethanol} & Energy & 0.014 & - & 0.0092 & **0.0032** & 0.0092 & 0.0092 & 0.0078 & 0.0096 \\  & Force & 0.085 & 0.083 & 0.06-6 & **0.0484** & **0.0484** & 0.0738 & 0.0522 & 0.0516 \\ \hline \multirow{2}{*}{Malondialdehyde} & Energy & 0.025 & - & 0.0184 & 0.0185 & 0.0138 & 0.0185 & **0.0132** & 0.0168 \\  & Force & 0.152 & 0.1522 & 0.0176 & 0.0946 & **0.0830** & 0.1338 & 0.0893 & 0.0875 \\ \hline \multirow{2}{*}{Naphthalene} & Energy & 0.011 & - & **0.0046** & 0.1153 & **0.0046** & **0.0046** & 0.0057 & 0.0174 \\  & Force & 0.060 & 0.0438 & 0.0300 & 0.0369 & **0.0208** & 0.0415 & 0.0291 & 0.0242 \\ \hline \multirow{2}{*}{Paracetamol} & Energy & 0.044 & - & 0.0323 & 0.0300 & 0.0346 & 0.0300 & **0.0258** & 0.0362 \\  & Force & 0.164 & - & 0.1361 & 0.1107 & 0.1130 & 0.1338 & 0.1029 & **0.0979** \\ \hline \multirow{2}{*}{Salicylic acid} & Energy & 0.017 & - & **0.0161** & 0.0208 & 0.0208 & 0.0185 & **0.0161** & 0.033 \\  & Force & 0.088 & 0.1222 & 0.0922 & 0.0715 & **0.0669** & 0.0992 & 0.0795 & 0.0771 \\ \hline \multirow{2}{*}{Toluene} & Energy & 0.010 & - & 0.0069 & 0.0115 & 0.0092 & 0.0699 & **0.0509** & 0.139 \\  & Force & 0.058 & 0.0507 & 0.0369 & 0.0350 & 0.0415 & 0.0438 & 0.0264 & **0.0244** \\ \hline \multirow{2}{*}{Unacil} & Energy & 0.013 & - & 0.0092 & 0.0115 & 0.0138 & 0.0092 & **0.0069** & 0.0149 \\  & Force & 0.088 & 0.0876 & 0.0669 & 0.0484 & **0.0415** & 0.0738 & 0.0495 & 0.0487 \\ \hline \hline \end{tabular}
\end{table}
Table 2: Comparison of the MAEs between several benchmarked models and QuinNet trained on revised MD17 dataset using 950 training samples and 50 validation samples (energies in kcal/mol and forces in kcal/(mol·A)). The lowest values are shown in bold.

\begin{table}
\begin{tabular}{l l l l l l l l l l} \hline \hline  & \multicolumn{2}{c}{\# TrainVal} & \multicolumn{2}{c}{\#dominal [47]} & ViSNet-LSRM [56] & ViSNet [20; 56] & MacE (\(\mu\)=3) [7] & MacE (\(\mu\)=3) [7] & MacE (\(\mu\)=3) [7] & QuinNet \\ \hline \multirow{2}{*}{Ac-Ala-NSMMe} & Energy & 0.0093 & **0.0018** & 0.0019 & 0.0140 & 0.0080 & 0.0015 & 0.0200 \\  & Force & 0.29 & 0.0942 & 0.0972 & 0.1753 & 0.3920 & 0.0768 & **0.0031** \\ \hline \multirow{2}{*}{DHA (disonotherapeutic acid)} & Energy & 0.023 & **0.0016** & 0.0027 & 0.0033 & 0.0029 & 0.0034 & 0.0021 \\  & Force & 0.25 & 0.0598 & 0.0668 & 0.1430 & 0.5419 & 0.0648 & **0.0483** \\ \hline \multirow{2}{*}{Stadyuse} & Energy & 0.046 & **0.0012** & 0.0015 & 0.0058 & 0.0082 & 0.0014 & 0.0052 \\  & Force & 0.08 & 0.0707 & 0.0869 & 0.1568 & 0.0526 & 0.0767 & **0.0540** \\ \hline \multirow{2}{*}{AT-AT} & \multirow{2}{*}{2500500} & Energy & 0.012 & **0.0013** & 0.0028 & 0.0038 & 0.0036 & 0.0018 & 0.0024 \\  & Force & 0.09 & 0.0751 & 0.1010 & 0.3067 & 0.3436 & 0.0072 & **0.0087** \\ \hline \multirow{2}{*}{AT-AT-CO-CO} & Energy & 0.012 & **0.0019** & 0.0017 & 0.0159 & 0.0038 & 0.0013 & 0.0032 \\  & Force & 0.70 & **0.1664** & 0.1563 & 0.3759 & 0.4635 & 0.1153 & 0.1273 \\ \hline \multirow{2}{*}{Badyball attacker} & \multirow{2}{*}{550500} & Energy & 0.0079 & **0.0029** & 0.0030 & 0.0010 & 0.0039 & 0.0033 & 0.0038 \\  & Force & 0.68 & 1.0035 & 0.1335 & 0.3021 & 0.5120 & **0.0035** & 0.1001 \\ \hline \multirow{2}{*}{Double-walled smoke} & \multirow{2}{*}{750500} & Energy & 0.0108 & **0.0039** & **0.0028** & 0.0035 & 0.0035 & 0.0035 & **0.0039** \\  & Force & 0.502 & 0.591 & 0.3959 & 0.3959 & 0.4128 & 0.9352 & 0.2764 & **0.0343** \\ \hline \hline \end{tabular}
\end{table}
Table 3: Comparison of the MAEs between several benchmarked models and the lowest values are marked in bold (energies in kcal/mol per atom and forces in kcal/(mol·A)). Furthermore, the data splitting of the training set and validation set for training QuinNet on MD22 dataset is shown.

removed the four-body (improper) terms and retained only the five-body interactions up to part I for training on the Chignolin dataset. The resulting energy MAE is 1.2906 \(\pm\) 0.0267 kcal/mol, and the force MAE is 0.2974 \(\pm\) 0.002417 kcal/(mol\(\cdot\)A). These values are lower than the case where both four-body (improper) and five-body interactions up to part I coexist, thus confirming our hypothesis. These results demonstrate the importance of incorporating five-body interactions for accurately modeling the folding and unfolding conformations of Chignolin. Comparisons of the MAEs between different models and the detailed values of the ablation study refer to the Supplementary Materials.

## 6 Conclusion

In this work, we propose the QuinNet architecture, which efficiently incorporates many-body interactions up to whole five-body in graph neural networks for molecular dynamics simulations. Our experiments on several public datasets, including MD17, revised MD17, MD22, and Chignolin, demonstrate that QuinNet achieves high accuracy without significantly increasing computational complexity. Notably, our ablation study on Chignolin highlights the significance of five-body interactions in accurately modeling complex bio-molecular systems.

## References

* [1] Albert P Bartok, Mike C Payne, Risi Kondor, and Gabor Csanyi. Gaussian approximation potentials: The accuracy of quantum mechanics, without the electrons. _Phys. Rev. Lett._, 104(13):136403, 2010.
* [2] Stefan Chmiela, Alexandre Tkatchenko, Huziel E Sauceda, Igor Poltavsky, Kristof T Schutt, and Klaus-Robert Muller. Machine learning of accurate energy-conserving molecular force fields. _Sci. Adv._, 3(5):e1603015, 2017.
* [3] Stefan Chmiela, Huziel E Sauceda, Klaus-Robert Muller, and Alexandre Tkatchenko. Towards exact molecular dynamics simulations with machine-learned force fields. _Nat. Commun._, 9(1):3887, 2018.
* [4] Linfeng Zhang, Jiequn Han, Han Wang, Roberto Car, and Weinan E. Deep potential molecular dynamics: a scalable model with the accuracy of quantum mechanics. _Phys. Rev. Lett._, 120(14):143001, 2018.
* [5] Jonathan P Mailoa, Mordechai Kornbluth, Simon Batzner, Georgy Samsonidze, Stephen T Lam, Jonathan Vandermause, Chris Ablitt, Nicola Molinari, and Boris Kozinsky. A fast neural network approach for direct covariant forces prediction in complex multi-element extended systems. _Nat. Mach. Intell._, 1(10):471-479, 2019.
* [6] Yu Xie, Jonathan Vandermause, Lixin Sun, Andrea Cepellotti, and Boris Kozinsky. Bayesian force fields from active learning for simulation of inter-dimensional transformation of stanene. _Npj Comput. Mater._, 7(1):40, 2021.

Figure 5: The ablation study on Chignolin dataset.

* [7] Simon Batzner, Albert Musaelian, Lixin Sun, Mario Geiger, Jonathan P Mailoa, Mordechai Kornbluth, Nicola Molinari, Tess E Smidt, and Boris Kozinsky. E (3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials. _Nat. Commun._, 13(1):2453, 2022.
* [8] RK Nesbet. Atomic Bethe-Goldstone equations. III. correlation energies of ground states of Be, B, C, N, O, F, and Ne. _Phys. Rev._, 175(1):2, 1968.
* [9] D Hankins, JW Moskowitz, and FH Stillinger. Water molecule interactions. _J. Chem. Phys._, 53(12):4544-4554, 1970.
* [10] Mark S Gordon, Dmitri G Fedorov, Spencer R Pruitt, and Lyudmila V Slipchenko. Fragmentation methods: A route to accurate calculations on large systems. _Chem. Rev._, 112(1):632-672, 2012.
* [11] Kristof Schutt, Pieter-Jan Kindermans, Huziel Enoc Sauceda Felix, Stefan Chmiela, Alexandre Tkatchenko, and Klaus-Robert Muller. SchNet: A continuous-filter convolutional neural network for modeling quantum interactions. _Advances in neural information processing systems_, 30, 2017.
* [12] Kristof T Schutt, Huziel E Sauceda, P-J Kindermans, Alexandre Tkatchenko, and K-R Muller. SchNet-a deep learning architecture for molecules and materials. _J. Chem. Phys._, 148(24):241722, 2018.
* [13] Johannes Gasteiger, Janek Gross, and Stephan Gunnemann. Directional message passing for molecular graphs. In _International Conference on Learning Representations_, 2019.
* [14] Johannes Gasteiger, Shankari Giri, Johannes T Margraf, and Stephan Gunnemann. Fast and uncertainty-aware directional message passing for non-equilibrium molecules. _Preprint at [http://arxiv.org/abs/2011.14115_](http://arxiv.org/abs/2011.14115_), 2020.
* [15] Kristof Schutt, Oliver Unke, and Michael Gastegger. Equivariant message passing for the prediction of tensorial properties and molecular spectra. In _International Conference on Machine Learning_, pages 9377-9388. PMLR, 2021.
* [16] Philipp Tholke and Gianni De Fabritiis. Equivariant transformers for neural network based molecular potentials. In _International Conference on Learning Representations_, 2022.
* [17] Johannes Gasteiger, Florian Becker, and Stephan Gunnemann. GemNet: Universal directional graph neural networks for molecules. _Advances in Neural Information Processing Systems_, 34:6790-6802, 2021.
* [18] Benjamin Coors, Alexandru Paul Condurache, and Andreas Geiger. SphereNet: Learning spherical representations for detection and classification in omnidirectional images. In _Proceedings of the European conference on computer vision (ECCV)_, pages 518-533, 2018.
* [19] Limei Wang, Yi Liu, Yuchao Lin, Haoran Liu, and Shiwang Ji. ComENet: Towards complete and efficient message passing for 3D molecular graphs. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, _Advances in Neural Information Processing Systems_, 2022.
* [20] Yusong Wang, Shaoning Li, Xinheng He, Mingyu Li, Zun Wang, Nanning Zheng, Bin Shao, Tong Wang, and Tie-Yan Liu. ViSNet: a scalable and accurate geometric deep learning potential for molecular dynamics simulation. _Preprint at [http://arxiv.org/abs/2210.16518_](http://arxiv.org/abs/2210.16518_), 2022.
* [21] Chaitanya K Joshi, Cristian Bodnar, Simon V Mathis, Taco Cohen, and Pietro Lio. On the expressive power of geometric graph neural networks. _Preprint at [http://arxiv.org/abs/2301.09308_](http://arxiv.org/abs/2301.09308_), 2023.
* [22] Albert P Bartok, Risi Kondor, and Gabor Csanyi. On representing chemical environments. _Phys. Rev. B_, 87(18):184115, 2013.

* [23] Roberto Rivelino, Puspitapallab Chaudhuri, and Sylvio Canuto. Quantifying multiple-body interaction terms in H-bonded HCN chains with many-body perturbation/coupled-cluster theories. _J. Chem. Phys._, 118(23):10593-10601, 2003.
* [24] Patricia RP Barreto, Alessandra F Albernaz, Federico Palazzetti, Andrea Lombardi, Gaia Grossi, and Vincenzo Aquilanti. Hyperspherical representation of potential energy surfaces: intermolecular interactions in tetra-atomic and penta-atomic systems. _Phys. Scr._, 84(2):028111, 2011.
* [25] Jiang Wang, Nicholas Charron, Brooke Husic, Simon Olsson, Frank Noe, and Cecilia Clementi. Multi-body effects in a coarse-grained protein force field. _J. Chem. Phys._, 154(16):164113, 2021.
* [26] David Peter Kovacs, Cas van der Oord, Jiri Kucera, Alice EA Allen, Daniel J Cole, Christoph Ortner, and Gabor Csanyi. Linear atomic cluster expansion force fields for organic molecules: beyond RMSE. _J. Chem. Theory Comput._, 17(12):7696-7711, 2021.
* [27] AW Solbrig Jr. Valence force potentials for calculating crystal vibrations in silicon. _J. Phys. Chem. Solids_, 32(8):1761-1768, 1971.
* [28] SL Altmann, A Lapiccirella, KW Lodge, and N Tomassini. A valence force field for the silicon crystal. _J. Phys. C: Solid State Phys._, 15(27):5581, 1982.
* [29] Clifford E Dykstra. Electrostatic interaction potentials in molecular force fields. _Chem. Rev._, 93(7):2339-2353, 1993.
* [30] Jorg Behler and Michele Parrinello. Generalized neural-network representation of high-dimensional potential-energy surfaces. _Phys. Rev. Lett._, 98(14):146401, 2007.
* [31] Risi Kondor, Zhen Lin, and Shubhendu Trivedi. Clebsch-Gordan Nets: a fully fourier space spherical convolutional neural network. _Advances in Neural Information Processing Systems_, 31, 2018.
* [32] Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li Li, Kai Kohlhoff, and Patrick Riley. Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds. _Preprint at [http://arxiv.org/abs/1802.08219_](http://arxiv.org/abs/1802.08219_), 2018.
* [33] Brandon Anderson, Truong Son Hy, and Risi Kondor. Cormorant: Covariant molecular neural networks. _Advances in neural information processing systems_, 32, 2019.
* [34] Fabian Fuchs, Daniel Worrall, Volker Fischer, and Max Welling. SE (3)-transformers: 3D Roto-translation equivariant attention networks. _Advances in Neural Information Processing Systems_, 33:1970-1981, 2020.
* [35] Yi-Lun Liao and Tess Smidt. Equiformer: Equivariant graph attention transformer for 3D atomistic graphs. In _The Eleventh International Conference on Learning Representations_, 2023.
* [36] Albert Musaelian, Simon Batzner, Anders Johansson, Lixin Sun, Cameron J Owen, Mordechai Kornbluth, and Boris Kozinsky. Learning local equivariant representations for large-scale atomistic dynamics. _Nat. Commun._, 14(1):579, 2023.
* [37] Ilyes Batatia, David P Kovacs, Gregor Simm, Christoph Ortner, and Gabor Csanyi. MACE: Higher order equivariant message passing neural networks for fast and accurate force fields. _Advances in Neural Information Processing Systems_, 35:11423-11436, 2022.
* [38] Ralf Drautz. Atomic cluster expansion for accurate and transferable interatomic potentials. _Phys. Rev. B_, 99(1):014104, 2019.
* [39] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In _International conference on machine learning_, pages 1263-1272. PMLR, 2017.
* [40] Junmei Wang, Romain M Wolf, James W Caldwell, Peter A Kollman, and David A Case. Development and testing of a general amber force field. _J. Comput. Chem._, 25(9):1157-1174, 2004.

* [41] Charles W Bock, Philip George, Mendel Trachtman, and Murray Zanger. A reappraisal of the structure of the second stable conformer of buta-1, 3-diene. _J. Chem. Soc., Perkin trans._, (1):26-34, 1979.
* [42] Andrew R Leach and Andrew R Leach. _Molecular modelling: principles and applications_. Pearson education, 2001.
* [43] Thomas A Halgren. Merck molecular force field. III. molecular geometries and vibrational frequencies for MMFF94. _J. Comput. Chem._, 17(5-6):553-586, 1996.
* [44] Anders S Christensen and O Anatole Von Lilienfeld. On the role of gradients for machine learning of molecular energies and forces. _Mach. Learn.: Sci. Technol._, 1(4):045018, 2020.
* [45] Lars Ruddigkeit, Ruud Van Deursen, Lorenz C Blum, and Jean-Louis Reymond. Enumeration of 166 billion organic small molecules in the chemical universe database GDB-17. _J. Chem. Inf. Model._, 52(11):2864-2875, 2012.
* [46] Raghunathan Ramakrishnan, Pavlo O Dral, Matthias Rupp, and O Anatole Von Lilienfeld. Quantum chemistry structures and properties of 134 kilo molecules. _Sci. Data_, 1(1):1-7, 2014.
* [47] Stefan Chmiela, Valentin Vassilev-Galindo, Oliver T Unke, Adil Kabylda, Huziel E Sauceda, Alexandre Tkatchenko, and Klaus-Robert Muller. Accurate global machine learning force fields for molecules with hundreds of atoms. _Sci. Adv._, 9(2):eadf0873, 2023.
* [48] Zun Wang, Hongfei Wu, Lixin Sun, Xinheng He, Zhirong Liu, Bin Shao, Tong Wang, and Tie-Yan Liu. Improving machine learning force fields for molecular dynamics simulations with fine-grained force metrics. _J. Chem. Phys._, 159(3), 2023.
* [49] John P Perdew, Kieron Burke, and Matthias Ernzerhof. Generalized gradient approximation made simple. _Phys. Rev. Lett._, 77(18):3865, 1996.
* [50] Alexandre Tkatchenko, Robert A DiStasio Jr, Roberto Car, and Matthias Scheffler. Accurate and efficient method for many-body van der Waals interactions. _Phys. Rev. Lett._, 108(23):236402, 2012.
* [51] Oliver T Unke, Stefan Chmiela, Michael Gastegger, Kristof T Schutt, Huziel E Sauceda, and Klaus-Robert Muller. Spookynet: Learning force fields with electronic degrees of freedom and nonlocal effects. _Nat. Commun._, 12(1):7273, 2021.
* [52] Thorben Frank, Oliver Unke, and Klaus-Robert Muller. So3krates: Equivariant attention for interactions on arbitrary length-scales in molecular systems. _Advances in Neural Information Processing Systems_, 35:29400-29413, 2022.
* [53] Frank Neese. Software update: the orca program system, version 4.0. _Wiley Interdiscip. Rev. Comput. Mol. Sci._, 8(1):e1327, 2018.
* [54] Florian Weigend and Reinhart Ahlrichs. Balanced basis sets of split valence, triple zeta valence and quadruple zeta valence quality for H to Rn: Design and assessment of accuracy. _Phys. Chem. Chem. Phys._, 7(18):3297-3305, 2005.
* [55] Zhuoran Qiao, Anders S Christensen, Matthew Welborn, Frederick R Manby, Anima Anandkumar, and Thomas F Miller III. Informing geometric deep learning with electronic interactions to accelerate quantum chemistry. _Proc. Natl. Acad. Sci. U.S.A._, 119(31):e2205221119, 2022.
* [56] Yunyang Li, Yusong Wang, Lin Huang, Han Yang, Xinran Wei, Jia Zhang, Tong Wang, Zun Wang, Bin Shao, and Tie-Yan Liu. Long-short-range message-passing: A physics-informed framework to capture non-local interaction for scalable molecular dynamics simulation. _Preprint at [http://arxiv.org/abs/2304.13542_](http://arxiv.org/abs/2304.13542_), 2023.
* [57] David Peter Kovacs, Ilyes Batatia, Eszter Sara Arany, and Gabor Csanyi. Evaluation of the mace force field architecture: from medicinal chemistry to materials science. _Preprint at [http://arxiv.org/abs/2305.14247_](http://arxiv.org/abs/2305.14247_), 2023.