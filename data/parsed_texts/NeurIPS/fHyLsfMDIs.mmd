# Entropic Neural Optimal Transport

via Diffusion Processes

 Nikita Gushchin

Sokoltech

_Moscow, Russia_

n.gushchin@skoltech.ru

&Alexander Kolesov

Skoltech1

_Moscow, Russia_

a.kolesov@skoltech.ru

&Alexander Korotin

Skoltech1

_Moscow, Russia_

a.korotin@skoltech.ru

&Dmitry Vetrov

HSE University,1 AIRI2

_Moscow, Russia_

vetrovd@yandex.ru

&Evgeny Burnaev

Skoltech1

_Moscow, Russia_

e.burnaev@skoltech.ru

Footnote 1: Skolkovo Institute of Science and Technology

###### Abstract

We propose a novel neural algorithm for the fundamental problem of computing the entropic optimal transport (EOT) plan between continuous probability distributions which are accessible by samples. Our algorithm is based on the saddle point reformulation of the dynamic version of EOT which is known as the Schrodinger Bridge problem. In contrast to the prior methods for large-scale EOT, our algorithm is end-to-end and consists of a single learning step, has fast inference procedure, and allows handling small values of the entropy regularization coefficient which is of particular importance in some applied problems. Empirically, we show the performance of the method on several large-scale EOT tasks. The code for the ENOT solver can be found at https://github.com/ngushchin/EntropicNeuralOptimalTransport.

## 1 Introduction

Optimal transport (OT) plans are a fundamental family of alignments between probability distributions. The majority of scalable neural algorithms to compute OT are based on the dual formulations of OT, see [28] for a survey. Despite the success of such formulations in generative modeling [42, 31], these dual form approaches can hardly be generalized to the popular **entropic OT**[12]. This is due to the numerical instability of the dual entropic OT problem [14] which appears for small entropy

Figure 1: Trajectories of samples learned by our Algorithm 1 for Celeba deblurring with \(\epsilon=0,1,10\).

regularization values which are suitable for downstream generative modeling tasks. At the same time, entropic OT is useful as it allows to learn one-to-many stochastic mappings with tunable level of sample diversity. This is particularly important for ill-posed problems such as super-resolution [37].

**Contributions**. We propose a saddle-point reformulation of the Entropic OT problem via using its dynamic counterpart known as the Schrodinger Bridge problem (SS4.1). Based on our new reformulation, we propose a novel end-to-end neural algorithm to solve the related entropic OT problem for a pair of continuous distributions accessible by samples (SS4.2). Unlike many predecessors, our method allows handling small entropy coefficients. This enables practical applications to \(\textit{data}\rightarrow\textit{data}\) mapping tasks that require slight variability in the learned maps. Furthermore, we provide an error analysis for solving the suggested saddle point optimization problem through duality gaps which are the errors of solving the inner and outer optimization problems (SS4.3). Empirically, we illustrate the performance of the method on several toy and large-scale EOT tasks (SS5).

## 2 Background

Optimal Transport (OT) and Schrodinger Bridge (SB) problems imply finding an efficient way to transform some initial distribution \(\mathbb{P}_{0}\) to target distribution \(\mathbb{P}_{1}\). While the solution of OT only gives the information about which part of \(\mathbb{P}_{0}\) is transformed to which part of \(\mathbb{P}_{1}\), SB implies finding a stochastic process that describes the entire evolution from \(\mathbb{P}_{0}\) to \(\mathbb{P}_{1}\). Below we give an introduction to OT and SB problems and show how they are related. For a detailed overview of OT, we refer to [49; 41] and of SB - to [32; 11].

### Optimal Transport (OT)

**Kantorovich's OT formulation** (with the quadratic cost). We consider \(D\)-dimensional Euclidean spaces \(\mathcal{X}\), \(\mathcal{Y}\) and use \(\mathcal{P}_{2}(\mathcal{X})=\mathcal{P}_{2}(\mathcal{Y})\) to denote the respective sets of Borel probability distributions on them which have finite second moment. For two distributions \(\mathbb{P}_{0}\in\mathcal{P}_{2}(\mathcal{X})\), \(\mathbb{P}_{1}\in\mathcal{P}_{2}(\mathcal{Y})\), consider the following minimization problem:

\[\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\int_{\mathcal{X}\times \mathcal{Y}}\frac{||x-y||^{2}}{2}d\pi(x,y),\] (1)

where \(\Pi(\mathbb{P}_{0},\mathbb{P}_{1})\subset\mathcal{P}_{2}(\mathcal{X}\times \mathcal{Y})\) is the set of probability distributions on \(\mathcal{X}\times\mathcal{Y}\) with marginals \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\). Such distributions \(\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})\) are called the transport plans between \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\). The set \(\Pi(\mathbb{P}_{0},\mathbb{P}_{1})\) is non-empty as it always contains the trivial plan \(\mathbb{P}_{0}\times\mathbb{P}_{1}\). A minimizer \(\pi^{*}\) of (1) always exists and is called an OT plan. If \(\mathbb{P}_{0}\) is absolutely continuous, then \(\pi^{*}\) is deterministic: its conditional distributions are degenerate, i.e., \(\pi^{*}(\cdot|x)=\delta_{T^{*}(x)}\) for some \(T^{*}:\mathcal{X}\rightarrow\mathcal{Y}\) (OT map).

**Entropic OT formulation.** We use \(H(\pi)\) to denote the differential entropy of distribution \(\pi\) and \(\text{KL}(\pi||\pi^{\prime})\) to denote the Kullback-Leibler divergence between distributions \(\pi\) and \(\pi^{\prime}\). Two most popular entropic OT formulations regularize (1) with the entropy \(H(\pi)\) or KL-divergence between plan \(\pi\) and the trivial plan \(\mathbb{P}_{0}\times\mathbb{P}_{1}\), respectively (\(\epsilon>0\)):

\[\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\int_{\mathcal{X}\times \mathcal{Y}}\frac{||x-y||^{2}}{2}d\pi(x,y)-\epsilon H(\pi),\] (2)

\[\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\int_{\mathcal{X}\times \mathcal{Y}}\frac{||x-y||^{2}}{2}d\pi(x,y)+\epsilon\text{KL}(\pi||\mathbb{P}_{ 0}\times\mathbb{P}_{1}).\] (3)

Since \(\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})\), it holds that \(\text{KL}(\pi||\mathbb{P}_{0}\times\mathbb{P}_{1})\!=\!-H(\pi)\!+\!H(\mathbb{P} _{0})\!+\!H(\mathbb{P}_{1})\), i.e., both formulations are equal up to an additive constant when \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\) are absolutely continuous. The minimizer of (2) is **unique** since the functional is strictly convex in \(\pi\) thanks to the strict convexity of \(H(\pi)\). This unique minimizer \(\pi^{*}\) is called the entropic OT plan.

### Schrodinger Bridge (SB)

**SB with the Wiener prior.** Let \(\Omega\) be the space of \(\mathbb{R}^{D}\) valued functions of time \(t\in[0,1]\) describing some trajectories in \(\mathbb{R}^{D}\), which start at time \(t=0\) and end at time \(t=1\). We use \(\mathcal{P}(\Omega)\) to denote the set of probability distributions on \(\Omega\). We use \(dW_{t}\) to denote the differential of the standard Wiener process. Let \(W^{\epsilon}\in\mathcal{P}(\Omega)\) be the Wiener process with the variance \(\epsilon\) which starts at \(\mathbb{P}_{0}\). This diffusion process can be represented via the following stochastic differential equation (SDE):

\[W^{\epsilon}:dX_{t}=\sqrt{\epsilon}dW_{t},\quad X_{0}\sim\mathbb{P}_{0}.\] (4)We use \(\text{KL}(T||Q)\) to denote the Kullback-Leibler divergence between stochastic processes \(T\) and \(Q\). The Schrodinger Bridge problem was initially proposed in 1931/1932 by Erwin Schrodinger [44]. It can be formulated as follows [11, Problem 4.1]:

\[\inf_{T\in\mathcal{F}(\mathbb{P}_{0},\mathbb{P}_{1})}\text{KL}(T||W^{\epsilon}),\] (5)

where \(\mathcal{F}(\mathbb{P}_{0},\mathbb{P}_{1})\subset\mathcal{P}(\Omega)\) is the set of probability distributions on \(\Omega\) having marginal distributions \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\) at \(t=0\) and \(t=1\), respectively. Thus, the Schrodinger Bridge problem implies finding a stochastic process \(T\) with marginal distributions \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\) at times \(t=0\) and \(t=1\), respectively, which has minimal KL divergence with the prior process \(W^{\epsilon}\).

**Link to OT problem.** Here we recall how Scrodinger Bridge problem (5) relates to entropic OT problem (2). _This relation is well known (see, e.g., [32] or [11, Problem 4.2]), and we discuss it in detail because our proposed approach (S4) is based on it._ Let \(\pi^{T}\) denote the joint distribution of a stochastic process \(T\) at time moments \(t=0,1\) and \(\pi_{0}^{T}\), \(\pi_{1}^{T}\) denote its marginal distributions at time moments \(t=0,1\), respectively. Let \(T_{|x,y}\) denote the stochastic processes \(T\) conditioned on values \(x,y\) at times \(t=0,1\), respectively. One may decompose \(\text{KL}(T||W^{\epsilon})\) as [48, Appendix C]:

\[\text{KL}(T||W^{\epsilon})=\text{KL}(\pi^{T}||\pi^{W^{\epsilon}})+\int_{ \mathcal{X}\times\mathcal{Y}}\text{KL}(T_{|x,y}||W^{\epsilon}_{|x,y})d\pi^{T} (x,y),\] (6)

i.e., KL divergence between \(T\) and \(W^{\epsilon}\) is a sum of two terms: the first represents the similarity of the processes at start and finish times \(t=0\) and \(t=1\), while the second term represents the similarity of the processes for intermediate times \(t\in(0,1)\) conditioned on the values at \(t=0,1\). For the first term, it holds (see Appendix A or [11, Eqs 4.7-4.9]):

\[\text{KL}(\pi^{T}||\pi^{W^{\epsilon}})=\int_{\mathcal{X}\times\mathcal{Y}} \frac{||x-y||^{2}}{2\epsilon}d\pi^{T}(x,y)-H(\pi^{T})+C,\] (7)

where \(C\) is a constant which depends only on \(\mathbb{P}_{0}\) and \(\epsilon\). In [32, Proposition 2.3], the authors show that if \(T^{*}\) is the solution to (5), then \(T^{*}_{|x,y}=W^{\epsilon}_{|x,y}\). Hence, one may optimize (5) over processes \(T\) for which \(T_{|x,y}=W^{\epsilon}_{|x,y}\) for every \(x,y\) and set the last term in (6) to zero. In this case:

\[\inf_{T\in\mathcal{F}(\mathbb{P}_{0},\mathbb{P}_{1})}\text{KL}(T||W^{\epsilon })=\inf_{T\in\mathcal{F}(\mathbb{P}_{0},\mathbb{P}_{1})}\text{KL}(\pi^{T}|| \pi^{W^{\epsilon}})=\inf_{\pi^{T}\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\text{ KL}(\pi^{T}||\pi^{W^{\epsilon}}).\] (8)

i.e., it suffices to optimize only over joint distributions \(\pi^{T}\) at time moments \(t=0,1\). _Hence, minimizing (8) is equivalent (up to an additive constant C) to solving EOT (2) divided by \(\epsilon\), and their respective solutions \(\pi^{T^{*}}\) and \(\pi^{*}\) coincide._ Thus, SB problem (5) can be simplified to the entropic OT problem (2) with entropy coefficient \(\epsilon\).

**Dual form of EOT**. Entropic OT problem (8) has several dual formulations. Here we recall the one which is particularly useful to derive our algorithm. The dual formulation follows from the weak OT theory [7, Theorem 1.3] and we explain it in detail in the proof of Lemma B.3:

\[\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\text{KL}(\pi||\pi^{W^{ \epsilon}})=\sup_{\beta}\big{\{}\int_{\mathcal{X}}\beta^{C}(x)d\mathbb{P}_{0}( x)+\int_{\mathcal{Y}}\beta(y)d\mathbb{P}_{1}(y)\big{\}},\]

where \(\beta^{C}(x)\stackrel{{\text{def}}}{{=}}\inf_{\nu\in\mathcal{P}_{ 2}(\mathcal{Y})}\big{\{}\text{KL}\big{(}\nu||\pi^{W^{\epsilon}}(\cdot|x) \big{)}-\int_{\mathcal{Y}}\beta(y)d\nu(y)\big{\}}\). The \(\sup\) here is taken over \(\beta\) belonging to the set of functions

\[\mathcal{C}_{b,2}(\mathcal{Y})\stackrel{{\text{def}}}{{=}}\{ \beta:\mathcal{Y}\to\mathbb{R}\text{ continuous s.t. }\exists u,v,w\in\mathbb{R}:\,u\|\cdot\|^{2}+v\leq\beta(\cdot)\leq w\},\]

i.e., \(\beta\) should be continuous with mild boundness assumptions.

**Dynamic SB problem (DSB)**. It is known that the solution to the SB problem (5) belongs to the class \(\mathcal{D}(\mathbb{P}_{0})\) of finite-energy diffusions \(T_{f}\)[32, Proposition 4.1] which are given by:

\[T_{f}:dX_{t}=f(X_{t},t)dt+\sqrt{\epsilon}dW_{t},\quad X_{0}\sim\mathbb{P}_{0}, \quad\mathbb{E}_{T_{f}}[\int_{0}^{1}||f(X_{t},t)||^{2}dt]<\infty,\] (9)

where \(f:\mathbb{R}^{D}\times[0,1]\to\mathbb{R}^{D}\) is the drift function. The last inequality in (9) means that \(T_{f}\) is a finite-energy diffusion. Hence, optimizing only over finite-energy diffusions rather than all possible processes is enough to solve SB problem (5). For finite-energy diffusions, it is possible to rewrite the optimization objective. One can show that \(\text{KL}(T_{f}||W^{\epsilon})\) between processes \(T_{f}\) and \(W^{\epsilon}\) is [40]:

\[\text{KL}(T_{f}||W^{\epsilon})=\frac{1}{2\epsilon}\mathbb{E}_{T_{f}}[\int_{0}^ {1}||f(X_{t},t)||^{2}dt].\] (10)

By substituting (10) in (5), SB problem reduces to the following problem [11, Problem 4.3]:

\[\inf_{T_{f}\in\mathcal{D}(\mathbb{P}_{0},\mathbb{P}_{1})}\text{KL}(T_{f}||W^{ \epsilon})=\inf_{T_{f}\in\mathcal{D}(\mathbb{P}_{0},\mathbb{P}_{1})}\frac{1}{ 2\epsilon}\mathbb{E}_{T_{f}}[\int_{0}^{1}||f(X_{t},t)||^{2}dt],\] (11)

where \(\mathcal{D}(\mathbb{P}_{0},\mathbb{P}_{1})\subset\mathcal{P}(\Omega)\) is the set of finite-energy diffusion on \(\Omega\) having marginal distributions \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\) at \(t=0\) and \(t=1\), respectively. Note that \(\mathcal{D}(\mathbb{P}_{0},\mathbb{P}_{1})\subset\mathcal{F}(\mathbb{P}_{0}, \mathbb{P}_{1})\). Since the problem (11) is the equivalent reformulation of (5), its optimal value also equals (8). However, solving this problem, as well as (8) is challenging as it is still hard to satisfy the boundary constraints.

## 3 Related Work

In this section, we overview the existing methods to compute the OT plan or map. To avoid any confusion, we emphasize that popular Wasserstein GANs [5] compute only the OT cost but not the OT plan and, consequently, are out of scope of the discussion.

**Discrete OT.** The majority of algorithms in computational OT are designed for the discrete setting where the inputs \(\mathbb{P}_{0},\mathbb{P}_{1}\) have finite supports. In particular, the usage of entropic regularization (2) allows to establish efficient methods [13] to compute the entropic OT plan between discrete distributions with the support size up to \(10^{5}\)-\(10^{6}\) points, see [41] for a survey. For larger support sizes, such methods are typically computationally intractable.

**Continuous OT.** Continuous methods imply computing the OT plan between distributions \(\mathbb{P}_{0}\), \(\mathbb{P}_{1}\) which are accessible by empirical samples. Discrete methods "as-is" are not applicable to the continuous setup in high dimensions because they only do a stochastic _matching_ between the train samples and do not provide out-of-sample estimation. In contrast, continuous methods employ neural networks to explicitly or implicitly _learn_ the OT plan or map. As a result, these methods can map unseen samples from \(\mathbb{P}_{0}\) to \(\mathbb{P}_{1}\) according to the learned OT plan or map.

There exists many methods to compute OT plans [51; 36; 38; 26; 28; 27; 42; 16; 19; 18] but they consider only unregularized OT (1) rather than the entropic one (2). In particular, they mostly focus on computing the deterministic OT plan (map) which may not exist. Recent works [31; 30] design algorithms to compute OT plans for weak OT [20; 7]. Although weak OT technically subsumes entropic OT, these works do not cover the entropic OT (2) because there is no simple way to estimate the entropy from samples. Below we discuss methods specifically for **EOT** (2) and **DSB** (11).

### Continuous Entropic OT

In LSOT [45], the authors solve the dual problem to entropic OT (2). The dual potentials are then used to compute the _barycentric projection_\(x\mapsto\int_{\mathcal{Y}}y\,d\pi^{*}(y|x)\), i.e., the first conditional moment of the entropic OT plan. This strategy may yield a deterministic approximation of \(\pi^{*}\) for small \(\epsilon\) but does not recover the entire plan itself.

In [14, Figure 3], the authors show that the barycentric projection leads to the averaging artifacts which make it impractical in downstream tasks such as the unpaired image super-resolution. To solve these issues, the authors propose a method called SCONES. It recovers the entire conditional distribution \(\pi^{*}(y|x)\) of the OT plan \(\pi^{*}\) from the dual potentials. Unfortunately, this is costly. During the training phase, the method requires learning a score-based model for the distribution \(\mathbb{P}_{1}\). More importantly, during the inference phase, one has to run the Langevin dynamic to sample from \(\pi^{*}(y|x)\).

The optimization of the above-mentioned entropic approaches requires evaluating the exponent of large values which are proportional to \(\epsilon^{-1}\)[45, Eq. 7]. Due to this fact, those methods are **unstable** for small values \(\epsilon\) in (2). In contrast, our proposed method (SS4) resolves this issue: technically, it works even for \(\epsilon=0\).

### Approaches to Compute Schrodinger Bridges

Existing approaches to solve DSB mainly focus on generative modeling applications (_noise \(\rightarrow\) data_). For example, FB-SDE [10] utilizes data likelihood maximization to optimize the parameters of 

[MISSING_PAGE_FAIL:5]

in EOT. This term is replaced by the energy of the process \(\mathbb{E}_{T_{f}}\big{[}\int_{0}^{1}||f(X_{t},t)||^{2}dt\big{]}\) which can be straightforwardly estimated from the samples of \(T_{f}\), allowing to establish a computational algorithm.

### Practical Optimization Procedure

To solve (12), we parametrize drift function \(f(x,t)\) of the process \(T_{f}\) and potential \(\beta(y)\)4 by neural nets \(f_{\theta}:\mathbb{R}^{D}\times[0,1]\to\mathbb{R}^{D}\) and \(\beta_{\phi}:\mathbb{R}^{D}\to\mathbb{R}\). We consider the following maximin problem:

Footnote 4: In practice, \(\beta_{\phi}\in\mathcal{C}_{b,2}(\mathcal{Y})\) since we can choose \(u=0\), \(v=\min(\texttt{float32})\), \(w=\max(\texttt{float32})\).

\[\sup_{\beta}\inf_{T_{f_{\theta}}}\Big{\{}\frac{1}{2\epsilon}\mathbb{E}_{T_{f_ {\theta}}}[\int_{0}^{1}||f_{\theta}(X_{t},t)||^{2}dt]+\int_{\mathcal{Y}}\beta_ {\phi}(y)d\mathbb{P}_{1}(y)-\int_{\mathcal{Y}}\beta_{\phi}(y)d\pi_{1}^{T_{f_{ \theta}}}(y)\Big{\}}.\] (14)

We use standard Euler-Maruyama (Eul-Mar) simulation (Algorithm 2 in Appendix C) for sampling from the stochastic process \(T_{f}\) by solving its SDE (9). To estimate the value of \(\mathbb{E}_{T_{f}}[\int_{0}^{1}||f(X_{t},t)||^{2}dt]\) in (14), we utilize the mean value of \(||f(x,t)||^{2}\) over time \(t\) of trajectory \(X_{t}\) that is obtained during the simulation by Euler-Maruyama algorithm (Appendix C). We train \(f_{\theta}\) and \(\beta_{\phi}\) by optimizing (12) with the stochastic gradient ascent-descent by sampling random batches from \(\mathbb{P}_{0}\), \(\mathbb{P}_{1}\). The optimization procedure is detailed in Algorithm 1. We use \(f_{n,m}\) to denote the drift at time step \(n\) for the \(m\)-th object of the input sample batch. We use the averaged of the drifts as an estimate of \(\int_{0}^{1}||f(X_{t},t)||^{2}dt\) in the training objective.

**Remark.** For the image tasks (SS5.3, SS5.4), we find out that using a slightly different parametrization of \(T_{f}\) considerably improves the quality of our Algorithm, see Appendix F.

It should be noted that the term \(\mathbb{E}_{T_{f}}[\int_{0}^{1}||f(X_{t},t)||^{2}dt]\) is not multiplied by \(\frac{1}{2\epsilon}\) in the algorithm since this does not affect the optimal \(T_{f^{*}}\) solving the inner optimization problem, see Appendix D.

**Relation to GANs.** At the first glance, our method might look like a typical GAN as it solves a maximin problem with the "discriminator" \(\beta_{\phi}\) and SDE "generator" with the drift \(f_{\theta}\). Unlike GANs, in our saddle point objective (12), optimization of "generator" \(T_{f}\) and "discriminator" \(\beta\) are swapped, i.e., "generator" is adversarial to "discriminator", not vise versa, as in GANs. For further discussion of differences between saddle point objectives of neural OT/GANs, see [31, SS4.3], [42, SS4.3], [16].

### Error Bounds via Duality Gaps

Our algorithm solves a maximin optimization problem and recovers some _approximate_ solution \((\hat{\beta},T_{f})\). Given such a pair, it is natural to wonder how close is the recovered \(T_{f}\) to the optimal \(T_{f^{*}}\). Our next result sheds light on this question via bounding the error with the _duality gaps_.

**Theorem 4.3** (Error analysis via duality gaps).: _Consider a pair (\(\hat{\beta}\), \(T_{f}\)). Define the duality gaps, i.e., errors of solving inner and outer optimization problems by:_

\[\epsilon_{1}\stackrel{{\text{\tiny{def}}}}{{=}}\mathcal{L}(\hat{ \beta},T_{f})-\inf_{T_{f}}\mathcal{L}(\hat{\beta},T_{f}),\qquad\text{and}\qquad \epsilon_{2}\stackrel{{\text{\tiny{def}}}}{{=}}\sup_{\beta}\inf_{T _{f}\in\mathcal{D}(\mathbb{P}_{0})}\mathcal{L}(\beta,T_{f})-\inf_{T_{f}} \mathcal{L}(\hat{\beta},T_{f}).\] (15)

_Then it holds that_

\[\rho_{\text{TV}}(T_{f},T_{f^{*}})\leq\sqrt{\epsilon_{1}+\epsilon_{2}},\qquad \text{and}\qquad\rho_{\text{TV}}(\pi^{T_{f}},\pi^{T_{f^{*}}})\leq\sqrt{ \epsilon_{1}+\epsilon_{2}},\] (16)

_where we use \(\rho_{\text{TV}}(\cdot,\cdot)\) to denote the total variation norm (between the processes or plans)._

**Relation to prior works**. There exist deceptively similar results, see [38, Theorem 3.6], [42, Theorem 4.3], [16, Theorem 4], [6, Theorem 3]. _None of them are relevant to our EOT/DSB case._

In [38], [42], [16], the authors consider maximin reformulations of unregularized OT (1), i.e., non-entropic. Their result requires the potential \(\beta\) (\(f,\psi\) in their notation) to be a convex function which in practice means that one has to employ ICNNs [4] which have poor expressiveness [29, 17, 26]. Our result is free from such assumptions on \(\beta\). In [6], the authors consider general OT problem [39] and require the general cost functional to be strongly convex (in some norm). Their results also do not apply to our case as the (negative) entropy which we consider is not strongly convex.

## 5 Experimental Illustrations

In this section, we qualitatively and quantitatively illustrate the performance of our algorithm in several entropic OT tasks. Our proofs apply only to EOT (\(\epsilon>0\)), but for completeness, we also present results \(\epsilon=0\), i.e., unregularized case (1). Furthermore, we test our algorithm with \(\epsilon=0\) on the Wasserstein-2 Benchmark [28], see Appendix J. We also demonstrate the extension of our algorithm to costs other than the squared Euclidean distance in Appendix I. The implementation details are given in Appendices E, F and G. The code is written in PyTorch and is publicly available at

https://github.com/ngushchin/EntropicNeuralOptimalTransport

### Toy 2D experiments

Here we give qualitative examples of our algorithm's performance on toy 2D pairs of distributions. We consider two pairs \(\mathbb{P}_{0},\mathbb{P}_{1}\): _Gaussian \(\rightarrow\) Swiss Roll, Gaussian \(\rightarrow\) Mixture of 8 Gaussians_. We provide qualitative results in Figure 2 and Figure 5 (Appendix E), respectively. In both cases, we provide solutions of the problem for \(\epsilon=0,0.01,0.1\) and sample trajectories. For \(\epsilon=0\), all the trajectories are straight lines as they represent solutions for non-regularized OT (1), see [43, SS5.4]. For bigger \(\epsilon\), trajectories, as expected, become more noisy and less straight.

### High-dimensional Gaussians

For general continuous distributions \(\mathbb{P}_{0},\mathbb{P}_{1}\), the ground truth solution of entropic OT (2) and DSB (11) is unknown. This makes it challenging to assess how well does our algorithm solve these problems. Fortunately, when \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\) are Gaussians, there exist _closed form solutions_ of these related problems, see [25] and [9]. Thus, to quantify the performance of our algorithm, we consider entropic OT problems in dimensions \(D\in\{2,16,64,128\}\) with \(\epsilon=1\) for Gaussian \(\mathbb{P}_{0}=\mathcal{N}(0,\Sigma_{0})\), \(\mathbb{P}_{1}=\mathcal{N}(0,\Sigma_{1})\). We pick \(\Sigma_{0}\), \(\Sigma_{1}\) at random: their eigenvectors are uniformly distributed on the unit sphere and eigenvalues are sampled from the loguniform distribution on \([-\log 2,\log 2]\).

Figure 2: _Gaussian \(\rightarrow\)Mix of 8 Gaussians_. The process learned with ENOT **(ours)** for \(\epsilon\!=\!0,0.01,0.1\).

**Metrics**. We evaluate **(a)** how precisely our algorithm fits the target distribution \(\mathbb{P}_{1}\) on \(\mathbb{R}^{D}\); **(b)** how well it recovers the entropic OT plan \(\pi^{*}\) which is a Gaussian distribution on \(\mathbb{R}^{D}\times\mathbb{R}^{D}\); **(c)** how accurate are the learned marginal distributions at intermediate times \(t=0,\frac{1}{10},\ldots,1\).

In each of the above-mentioned cases, we compute the BW\({}_{2}^{2}\)-UVP [29, SS5] between the learned and the ground truth distributions. For two distributions \(\widehat{\chi}\) and \(\chi\), it is the Wasserstein-2 distance between their Gaussian approximations which is further normalized by the variance of the distribution \(\chi\):

\[\text{B}\mathbb{W}_{2}^{2}\text{-UVP}\big{(}\widehat{\chi},\chi\big{)}=\frac{ 100\%}{\frac{1}{2}\text{Var}(\chi)}\mathbb{W}_{2}^{2}(\mathcal{N}(\mu_{ \widehat{\chi}},\Sigma_{\widehat{\chi}}),\mathcal{N}(\mu_{\chi},\Sigma_{\chi}) ).\] (17)

We estimate the metric by using \(10^{5}\) samples.

**Baselines**. We compare our method ENOT with LSOT [45], SCONES [14], MLE-SB [48], DiffSB[15], FB-SDE [10] (two algorithms, A and J). Results are given in Tables 1, 2 and 3. LSOT and SCONES solve EOT without solving SB, hence there are no results in Table 3 for these methods. Our method achieves low BW\({}_{2}^{2}\)-UVP values indicating that it recovers the ground truth process and entropic plan fairly well. The competitive methods have good results in low dimensions, however they perform worse in high dimensions. Importantly, our methods scores the best results in recovering the OT plan (Table 2) and the marginal distributions of the Schrodinger bridge (Table 3). To illustrate the stable convergence of ENOT, we provide the plot of BW\({}_{2}^{2}\)-UVP between the learned plan and the ground truth plan for ENOT during training in Figure 6 (Appendix E).

### Colored MNIST

In this section, we test how the entropy parameter \(\epsilon\) affects the stochasticity of the learned plan in higher dimensions. For this, we consider the entropic OT problem between colorized MNIST digits of classes "2" (\(\mathbb{P}_{0}\)) and "3" (\(\mathbb{P}_{1}\)).

**Effect of parameter \(\epsilon\).** For \(\epsilon=0,1,10\), we learn our Algorithm 1 on the _train_ sets of digits "2" and "3". We show the translated _test_ images in Figures 2(a), 2(b) and 2(c), respectively. When \(\epsilon=0\), there is no diversity in generated "3" samples (Figure 2(a)), the color remains since the map tried to minimally change the image in the RGB pixel space. When \(\epsilon=1\), some slight diversity in the shape of "3" appears but the color of the input "2" is still roughly preserved (Figure 2(c)). For higher \(\epsilon\), the diversity of generated samples becomes clear (Figure 2(c)). In particular, the color of "3" starts to slightly deviate from the input "2". That is, increasing the value \(\epsilon\) of the entropy term in (2) expectedly leads to bigger stochasticity in the plan. We add the conditional LPIPS variance [24, Table 1] of generated samples for test datasets by ENOT to show how diversity changes for different \(\epsilon\) (Table 4). We provide examples of trajectories learned by ENOT in Figure 7 (Appendix F).

**Metrics and baselines.** We compare our method ENOT with SCONES [14], and DiffSB [15] as these are the only methods which the respective authors applied for _data\(\rightarrow\)data_ tasks. To evaluate the results, we use the FID metric [23] which is the Bures-Wasserstein (Freschet) distance between thedistributions after extracting features using the InceptionV3 model [47]. We measure test FID for every method and present the results and qualitative examples in Figure 3. There are no results for SCONES with \(\epsilon=0,1,10\), since it **is not applicable** for such reasonably small \(\epsilon\) due to computational instabilities, see [14, SS5.1]. DiffSB [15] can be applied for small regularization \(\epsilon\), so we test \(\epsilon=1,10\). By the construction, this algorithm is not suitable for \(\epsilon=0\).

Our ENOT method outperforms the baselines in FID. DiffSB [15] yield very high FID. This is presumably due to instabilities of DiffSB which the authors report in their sequel paper [46]. SCONES yields reasonable quality but due to high \(\epsilon=25,100\) the shape and color of the generated images "3" starts to deviate from those of their respective inputs "2".

For completeness, we provide the results of the stochastic _matching_ of the **test parts** of the datasets by the discrete OT for \(\epsilon=0\) and EOT [12] for \(\epsilon=1,10\) (Figures 2(f), 2(g), 2(h)). This is not the out-of-sample estimation, obtained samples "3" are just **test** samples of "3" (this setup is _unfair_). Discrete OT is _not a competitor_ here as it does not generate new samples and uses _target_ test samples. Still it gives a rough estimate what to expect from the learned plans for increasing \(\epsilon\).

### Unpaired Super-resolution of Celeba Faces

For the large-scale evaluation, we adopt the experimental setup of SCONES [14]. We consider the problem of unpaired image super-resolution for the \(64\times 64\) aligned faces of CelebA dataset [35].

We do the _unpaired_ train-test split as follows: we split the dataset into 3 parts: 90k (train A1), 90k (train B1), 20k (test C1) samples. For each part we do \(2\times\) bilinear downsample and then \(2\times\) bilinear upsample to degrade images but keep the original size. As a result, we obtain degraded parts A0, B0, C0. For training in the unpaired setup, we use parts A0 (degraded faces, \(\mathbb{P}_{0}\)) and B1 (clean faces, \(\mathbb{P}_{1}\)). For testing, we use the hold-out part C0 (unseen samples) with C1 considered as the reference.

We train our model with \(\epsilon{=}0,1,10\) to and test how it restores C1 (Figure 3(a)) from C0 images (Figure 3(b)) and present the qualitative results in Figures 3(f), 3(g), 3(h). We provide examples of trajectories learned by ENOT in Figure 1.

**Metrics and baselines.** To quantify the results, as in [14], we compute the FID score [23] between the sets of mapped C0 images and C1 images (Table 5). The FID of ENOT is better than FID values of the other methods, but increases with \(\epsilon\) probably due to the increasing variance of gradients during training. As in SS5.1 and SS5.3, the diversity of samples increases with \(\epsilon\). Our method works with small values of \(\epsilon\) and provides **reasonable** amount of diversity in the mapped samples which grows with \(\epsilon\) (Table 4). As the baseline among other methods for EOT we consider only SCONES, as it is the only EOT/DSB algorithm which has been applied to _data\(\rightarrow\)data_ task at \(64\times 64\) resolution. At the same time, we emphasize that SCONES **is not applicable** for small \(\epsilon\) due to instabilities, see [14, SS5.1]. This makes it **impractical**, as due to high \(\epsilon\), its produces up-scaled images (Figures 3(c)) are

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline \(\epsilon\) & **0** & **1** & **10** \\ \hline
**Colored MNIST** & \(0\) & \(5.3\cdot 10^{-3}\) & \(2.0\cdot 10^{-2}\) \\ \hline
**Celeba** & \(0\) & \(3.4\cdot 10^{-2}\) & \(5.1\cdot 10^{-2}\) \\ \hline \end{tabular}
\end{table}
Table 4: LPIPS variability of ENOT samples.

Figure 3: Samples of colored MNIST obtained by ENOT **(ours)** and DOT for different \(\epsilon\).

nearly random and do not reflect the attributes of the input images (Figure 3(a)). We do not provide results for DiffSB [15] since it already performs bad on Colored MNIST (SS5.3) and the authors also did not consider any image-to-image apart of grayscale 28x28 images.

For completeness, we present results on this setup for other methods, which do not solve EOT: ICNN-based OT [38] and AugCycleGAN [2]. ICNN (4d) learns a deterministic map. AugCycleGAN (4e) learns a stochastic map, but the generated samples differ only by brightness.

## 6 Discussion

**Potential impact.** There is a lack of scalable algorithms for learning continuous entropic OT plans which may be used in _data\(\rightarrow\)data_ practical tasks requiring control of the diversity of generated samples. We hope that our results provide a new direction for research towards establishing scalable and efficient methods for entropic OT by using its connection with SB.

**Potential social impact.** Like other popular methods for generating images, our method can be used to simplify the work of designers with digital images and create new products based on it. At the same time, our method may be used for creating fake images just like the other generative models.

**Limitations.** To simulate the trajectories following SDE (9), we use the Euler-Maruyama scheme. It is straightforward but may be imprecise when the number of steps is small or the noise variance \(\epsilon\) is high. As a result, for large \(\epsilon\), our Algorithm 1 may be computationally heavy due to the necessity to backpropagate through a large computational graph obtained via the simulation. Employing time and memory efficient SDE integration schemes is a promising avenue for the future work.

Acknowledgements. This work was partially supported by Skoltech NGP program (SkoltechMIT joint project).

Figure 3: Faces produced by ENOT **(ours)** and SCONEs for various \(\epsilon\).

Figure 3(a) shows test degraded images (C0), 4b – their original high-resolution counterparts (C1).

\begin{table}
\begin{tabular}{|c|c|c|c|c|c|c|} \hline
**Method** & **ENOT**\(\epsilon=0\) & **ENOT**\(\epsilon=1\) & **ENOT**\(\epsilon=10\) & SCONES [14], \(\epsilon=100\) & AugCycleGAN [2] & ICNN [38] \\ \hline
**FID** & **3.78** & **7.63** & **14.8** & 18.88 & 15.2 & 22.2 \\ \hline \end{tabular}
\end{table}
Table 5: Test FID values of various methods in unpaired super-resolution of faces experiment.

## References

* [1] Yves Achdou, Pierre Cardaliaguet, Francois Delarue, Alessio Porretta, and Filippo Santambrogio. _Mean Field Games: Cetraro, Italy 2019_, volume 2281. Springer Nature, 2021.
* [2] Amjad Almahairi, Sai Rajeshwar, Alessandro Sordoni, Philip Bachman, and Aaron Courville. Augmented cyclegan: Learning many-to-many mappings from unpaired data. In _International Conference on Machine Learning_, pages 195-204. PMLR, 2018.
* [3] Brandon Amos. On amortizing convex conjugates for optimal transport. In _The Eleventh International Conference on Learning Representations_, 2022.
* [4] Brandon Amos, Lei Xu, and J Zico Kolter. Input convex neural networks. In _Proceedings of the 34th International Conference on Machine Learning-Volume 70_, pages 146-155. JMLR. org, 2017.
* [5] Martin Arjovsky and Leon Bottou. Towards principled methods for training generative adversarial networks. In _International Conference on Learning Representations_, 2017.
* [6] Arip Asadulaev, Alexander Korotin, Vage Egiazarian, and Evgeny Burnaev. Neural optimal transport with general cost functionals. _arXiv preprint arXiv:2205.15403_, 2022.
* [7] Julio Backhoff-Verguas, Mathias Beiglbock, and Gudmun Pammer. Existence, duality, and cyclical monotonicity for weak transport costs. _Calculus of Variations and Partial Differential Equations_, 58(6):1-28, 2019.
* [8] Jean-David Benamou and Yann Brenier. A computational fluid mechanics solution to the monge-kantorovich mass transfer problem. _Numerische Mathematik_, 84(3):375-393, 2000.
* [9] Charlotte Bunne, Ya-Ping Hsieh, Marco Cuturi, and Andreas Krause. The schrodinger bridge between gaussian measures has a closed form. In _International Conference on Artificial Intelligence and Statistics_, pages 5802-5833. PMLR, 2023.
* [10] Tianrong Chen, Guan-Horng Liu, and Evangelos Theodorou. Likelihood training of schrodinger bridge using forward-backward sdes theory. In _International Conference on Learning Representations_, 2021.
* [11] Yongxin Chen, Tryphon T Georgiou, and Michele Pavon. Stochastic control liaisons: Richard sinkhorn meets gaspard monge on a schrodinger bridge. _SIAM Review_, 63(2):249-313, 2021.
* [12] Marco Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. _Advances in neural information processing systems_, 26, 2013.
* [13] Marco Cuturi and Arnaud Doucet. Fast computation of wasserstein barycenters. In _International conference on machine learning_, pages 685-693. PMLR, 2014.
* [14] Max Daniels, Tyler Maunu, and Paul Hand. Score-based generative neural networks for large-scale optimal transport. _Advances in neural information processing systems_, 34:12955-12965, 2021.
* [15] Valentin De Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet. Diffusion schrodinger bridge with applications to score-based generative modeling. _Advances in Neural Information Processing Systems_, 34:17695-17709, 2021.
* [16] Jiaojiao Fan, Shu Liu, Shaojun Ma, Hao-Min Zhou, and Yongxin Chen. Neural monge map estimation and its applications. _Transactions on Machine Learning Research_, 2023. Featured Certification.
* [17] Jiaojiao Fan, Qinsheng Zhang, Amirhossein Taghvaei, and Yongxin Chen. Variational wasserstein gradient flow. In _International Conference on Machine Learning_, pages 6185-6215. PMLR, 2022.
* [18] Milena Gazdieva, Alexander Korotin, Daniil Selikhanovych, and Evgeny Burnaev. Extremal domain translation with neural optimal transport. In _Advances in Neural Information Processing Systems_, 2023.
* [19] Milena Gazdieva, Litu Rout, Alexander Korotin, Alexander Filippov, and Evgeny Burnaev. Unpaired image super-resolution with optimal transport maps. _arXiv preprint arXiv:2202.01116_, 2022.

* [20] Nathael Gozlan, Cyril Roberto, Paul-Marie Samson, and Prasad Tetali. Kantorovich duality for general transport costs and applications. _Journal of Functional Analysis_, 273(11):3327-3405, 2017.
* [21] A Hitchhiker's Guide. _Infinite dimensional analysis_. Springer, 2006.
* [22] Pierre Henry-Labordere. (martingale) optimal transport and anomaly detection with neural networks: A primal-dual algorithm. _arXiv preprint arXiv:1904.04546_, 2019.
* [23] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. GANs trained by a two time-scale update rule converge to a local nash equilibrium. In _Advances in neural information processing systems_, pages 6626-6637, 2017.
* [24] Xun Huang, Ming-Yu Liu, Serge Belongie, and Jan Kautz. Multimodal unsupervised image-to-image translation. In _Proceedings of the European conference on computer vision (ECCV)_, pages 172-189, 2018.
* [25] Hicham Janati, Boris Muzellec, Gabriel Peyre, and Marco Cuturi. Entropic optimal transport between unbalanced gaussian measures has a closed form. _Advances in neural information processing systems_, 33:10468-10479, 2020.
* [26] Alexander Korotin, Vage Egiazarian, Arip Asadulaev, Alexander Safin, and Evgeny Burnaev. Wasserstein-2 generative networks. In _International Conference on Learning Representations_, 2021.
* [27] Alexander Korotin, Alexander Kolesov, and Evgeny Burnaev. Kantorovich strikes back! wasserstein GANs are not optimal transport? In _Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track_, 2022.
* [28] Alexander Korotin, Lingxiao Li, Aude Genevay, Justin M Solomon, Alexander Filippov, and Evgeny Burnaev. Do neural optimal transport solvers work? a continuous wasserstein-2 benchmark. _Advances in Neural Information Processing Systems_, 34:14593-14605, 2021.
* [29] Alexander Korotin, Lingxiao Li, Justin Solomon, and Evgeny Burnaev. Continuous wasserstein-2 barycenter estimation without minimax optimization. In _International Conference on Learning Representations_, 2021.
* [30] Alexander Korotin, Daniil Selikhanovych, and Evgeny Burnaev. Kernel neural optimal transport. In _The Eleventh International Conference on Learning Representations_, 2023.
* [31] Alexander Korotin, Daniil Selikhanovych, and Evgeny Burnaev. Neural optimal transport. In _The Eleventh International Conference on Learning Representations_, 2023.
* [32] Christian Leonard. A survey of the schrodinger problem and some of its connections with optimal transport. _arXiv preprint arXiv:1308.0215_, 2013.
* [33] Alex Tong Lin, Samy Wu Fung, Wuchen Li, Levon Nurbekyan, and Stanley J Osher. Alternating the population and control neural networks to solve high-dimensional stochastic mean-field games. _Proceedings of the National Academy of Sciences_, 118(31):e2024713118, 2021.
* [34] Guan-Horng Liu, Tianrong Chen, Oswin So, and Evangelos Theodorou. Deep generalized schrodinger bridge. _Advances in Neural Information Processing Systems_, 35:9374-9388, 2022.
* [35] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In _Proceedings of International Conference on Computer Vision (ICCV)_, December 2015.
* [36] Guansong Lu, Zhiming Zhou, Jian Shen, Cheng Chen, Weinan Zhang, and Yong Yu. Large-scale optimal transport via adversarial training with cycle-consistency. _arXiv preprint arXiv:2003.06635_, 2020.
* [37] Andreas Lugmayr, Martin Danelljan, and Radu Timofte. Ntire 2021 learning the super-resolution space challenge. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_, pages 596-612, 2021.
* [38] Ashok Makkuva, Amirhossein Taghvaei, Sewoong Oh, and Jason Lee. Optimal transport mapping via input convex neural networks. In _International Conference on Machine Learning_, pages 6672-6681. PMLR, 2020.
* [39] Francois-Pierre Paty, Alexandre d'Aspremont, and Marco Cuturi. Regularity as regularization: Smooth and strongly convex brenier potentials in optimal transport. In _International Conference on Artificial Intelligence and Statistics_, pages 1222-1232. PMLR, 2020.

* [40] Michele Pavon and Anton Wakolbinger. On free energy, stochastic control, and schrodinger processes. In _Modeling, Estimation and Control of Systems with Uncertainty: Proceedings of a Conference held in Sopron, Hungary, September 1990_, pages 334-348. Springer, 1991.
* [41] Gabriel Peyre, Marco Cuturi, et al. Computational optimal transport. _Foundations and Trends(r) in Machine Learning_, 11(5-6):355-607, 2019.
* [42] Litu Rout, Alexander Korotin, and Evgeny Burnaev. Generative modeling with optimal transport maps. In _International Conference on Learning Representations_, 2022.
* [43] Filippo Santambrogio. Optimal transport for applied mathematicians. _Birkauser, NY_, 55(58-63):94, 2015.
* [44] Erwin Schrodinger. _Uber die umkehrung der naturgesetze_. Verlag der Akademie der Wissenschaften in Kommission bei Walter De Gruyter u. Company., 1931.
* [45] Vivien Seguy, Bharath Bhushan Damodaran, Remi Flamary, Nicolas Courty, Antoine Rolet, and Mathieu Blondel. Large scale optimal transport and mapping estimation. In _International Conference on Learning Representations_, 2018.
* [46] Yuyang Shi, Valentin De Bortoli, Andrew Campbell, and Arnaud Doucet. Diffusion schrodinger bridge matching. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.
* [47] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 1-9, 2015.
* [48] Francisco Vargas, Pierre Thodoroff, Austen Lamacraft, and Neil Lawrence. Solving schrodinger bridges via maximum likelihood. _Entropy_, 23(9):1134, 2021.
* [49] Cedric Villani. _Optimal transport: old and new_, volume 338. Springer Science & Business Media, 2008.
* [50] Gefei Wang, Yuling Jiao, Qian Xu, Yang Wang, and Can Yang. Deep generative learning via schrodinger bridge. In _International Conference on Machine Learning_, pages 10794-10804. PMLR, 2021.
* [51] Yujia Xie, Minshuo Chen, Haoming Jiang, Tuo Zhao, and Hongyuan Zha. On scalable and efficient computation of large scale optimal transport. volume 97 of _Proceedings of Machine Learning Research_, pages 6882-6892, Long Beach, California, USA, 09-15 Jun 2019. PMLR.

Extended background: KL divergence with the Wiener process plan

This section illustrates that (7) holds. Consider a process \(T\in\mathcal{F}(\mathbb{P}_{0})\), i.e., \(T\) is a probability distribution on \(\Omega\) with the marginal \(\mathbb{P}_{0}\) at \(t=0\).

Let \(W^{*}\) be the Wiener process with variance \(\epsilon\) starting at \(\mathbb{P}_{0}\), i.e., it satisfies \(dX_{t}=\sqrt{\epsilon}dW_{t}\) with \(X_{0}\sim\mathbb{P}_{0}\). Hence, \(\pi^{W^{*}}(y|x)\) is the normal distribution \(\frac{d\pi^{W^{*}}(y|x)}{dy}=\mathcal{N}(y|x,\epsilon I)\). Then \(\text{KL}(\pi^{T}||\pi^{W^{*}})\) between joint distributions at times \(t=0\) and \(t=1\) of these processes is given by:

\[\text{KL}(\pi^{T}||\pi^{W^{*}})=-\int_{\mathcal{X}\times\mathcal{Y}}\log\frac{ d\pi^{W^{*}}(x,y)}{d[x,y]}d\pi^{T}(x,y)+\underbrace{\int_{\mathcal{X}\times \mathcal{Y}}\log\frac{d\pi^{T}(x,y)}{d[x,y]}d\pi^{T}(x,y)}_{=-H(\pi^{T})},\] (18)

where \(\frac{d\pi(x,y)}{d[x,y]}\) denotes the joint density of distribution \(\pi\). We derive

\[-\int_{\mathcal{X}\times\mathcal{Y}}\log\frac{d\pi^{W^{*}}(x,y)}{ d[x,y]}d\pi^{T}(x,y)=-\int_{\mathcal{X}\times\mathcal{Y}}\log\frac{d\pi^{W^{*}}(y |x)}{dy}\frac{d\pi^{W^{*}}(x)}{dx}d\pi^{T}(x,y)=\] \[-\int_{\mathcal{X}\times\mathcal{Y}}\log\frac{d\pi^{W^{*}}(y|x)}{ dy}d\pi^{T}(x,y)-\int_{\mathcal{X}}\int_{\mathcal{Y}}\log\frac{d\pi^{W^{*}}(x)}{ dx}d\pi^{T}(y|x)\overbrace{d\mathbb{P}_{0}(x)}^{d\pi^{T}(x)}=\] \[-\int_{\mathcal{X}\times\mathcal{Y}}\log\frac{d\pi^{W^{*}}(y|x)}{ dy}d\pi^{T}(x,y)-\int_{\mathcal{X}}\log\frac{d\pi^{W^{*}}(x)}{dx}\big{[}\int_{ \mathcal{Y}}1d\pi^{T}(y|x)\big{]}d\mathbb{P}_{0}(x)=\] \[-\int_{\mathcal{X}}\int_{\mathcal{Y}}\log\frac{d\pi^{W^{*}}(y|x)} {dy}d\pi^{T}(x,y)-\int_{\mathcal{X}}\log\frac{d\pi^{W^{*}}(x)}{dx}d\mathbb{P}_ {0}(x)=\] \[-\int_{\mathcal{X}\times\mathcal{Y}}\log\frac{d\pi^{W^{*}}(y|x)}{ dy}d\pi^{T}(x,y)-\int_{\mathcal{X}}\log\frac{d\mathbb{P}_{0}(x)}{dx}d\mathbb{P}_ {0}(x)=\] \[-\int_{\mathcal{X}\times\mathcal{Y}}\log\frac{d\pi^{W^{*}}(y|x)}{ dy}d\pi^{T}(x,y)+H(\mathbb{P}_{0})=\] \[-\int_{\mathcal{X}\times\mathcal{Y}}\log\biggl{(}(2\pi\epsilon)^{ \frac{-D}{2}}\exp\biggl{(}-\frac{||x-y||^{2}}{2\epsilon}\biggr{)}\biggr{)}d \pi^{T}(x,y)+H(\mathbb{P}_{0})=\] \[+\frac{D}{2}\log(2\pi\epsilon)+\int_{\mathcal{X}\times\mathcal{Y}} \frac{||x-y||^{2}}{2\epsilon}d\pi^{T}(x,y)+H(\mathbb{P}_{0}).\]

After substituting this result into (18), one obtains:

\[\text{KL}(\pi^{T}||\pi^{W^{*}})=\int_{\mathcal{X}\times\mathcal{Y}}\frac{||x- y||^{2}}{2\epsilon}d\pi^{T}(x,y)-H(\pi^{T})+\underbrace{\frac{D}{2}\log(2\pi \epsilon)+H(\mathbb{P}_{0})}_{=C\text{ in }(\ref{eq:1})}.\] (19)

## Appendix B Proofs

In this section, we provide the proof for our main theoretical results (Theorems 4.1 and 4.3). The proofs require several auxiliary results which we formulate and prove in SSB.1 and SSB.2.

In SSB.1, we show that entropic OT can be reformulated as a maximin problem. This is a technical intermediate result needed to derive our main maximin reformulation of SB (Theorem 4.1). More precisely, in SSB.2, we show that these maximin problems for entropic OT and SB are actually equivalent. By using this observation and related facts, in SSB.3, we prove our Theorems 4.1 and 4.3.

### Relaxation of entropic OT

To begin with, we recall some facts regarding EOT and SB. Recall the definition of EOT (2):

\[\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\int_{\mathcal{X}\times \mathcal{Y}}\frac{||x-y||^{2}}{2}d\pi(x,y)-\epsilon H(\pi).\] (20)Henceforth, we assume that \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\) are _absolutely continuous_. The situation when \(\mathbb{P}_{0}\) or \(\mathbb{P}_{1}\) is not absolutely continuous is not of any practical interest: there is no \(\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})\) for which the differential entropy \(H(\pi)\) is finite which means that (20) equals to \(+\infty\) for every \(\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})\), i.e., every plan is optimal. In turn, when \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\) are absolutely continuous, the OT plan is unique thanks to the strict convexity of entropy (on the set of absolutely continuous plans).

Recall equation (19) for \(\text{KL}(\pi||\pi^{W^{*}})\):

\[\text{KL}(\pi||\pi^{W^{*}})=\int_{\mathcal{X}\times\mathcal{Y}}\frac{||x-y||^{ 2}}{2\epsilon}d\pi(x,y)-H(\pi)+C.\] (21)

We again note that

\[\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\text{KL}(\pi||\pi^{W^{*}})= \frac{1}{\epsilon}\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\Big{\{} \int_{\mathcal{X}\times\mathcal{Y}}\frac{||x-y||^{2}}{2}d\pi(x,y)-\epsilon H (\pi)\Big{\}}+C,\]

i.e., problems (20) and (21) can be viewed as equivalent as their minimizers are the same. For convenience, we proceed with \(\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\text{KL}(\pi||\pi^{W^{*}})\) and denote its optimal value by \(\mathcal{L}^{*}\), i.e.,

\[\mathcal{L}^{*}\stackrel{{\text{def}}}{{=}}\inf_{\pi\in\Pi( \mathbb{P}_{0},\mathbb{P}_{1})}\text{KL}(\pi||\pi^{W^{*}}).\]

For a given \(\beta\in\mathcal{C}_{b,2}(\mathcal{Y})\), we define an auxiliary joint distribution \(d\pi^{\beta}(x,y)=d\pi^{\beta}(y|x)d\mathbb{P}_{0}(x)\), where \(d\pi^{\beta}(y|x)\) is given by

\[d\pi^{\beta}(y|x)=\frac{1}{C_{\beta}^{x}}\exp(\beta(y))d\pi^{W^{*}}(y|x),\]

where \(C_{\beta}^{x}(x)\stackrel{{\text{def}}}{{=}}\int_{\mathcal{Y}} \exp(\beta(y))d\pi^{W^{*}}(y|x)\). Note that \(C_{\beta}^{x}<\infty\) since \(\beta\in\mathcal{C}_{b,2}(\mathcal{Y})\) is upper bounded. Before going further, we need to introduce several technical auxiliary results.

**Proposition B.1**.: _For \(\nu\in\mathcal{P}_{2}(\mathcal{Y})\) and \(x\in\mathcal{X}\) it holds that_

\[\text{KL}(\nu||\pi^{W^{*}}(\cdot|x))-\int_{\mathcal{Y}}\beta(y)d\nu(y)=\text{ KL}(\nu||\pi^{\beta}(\cdot|x))-\log C_{\beta}^{x}.\] (22)

Proof of Proposition B.1.: We derive

\[\text{KL}(\nu||\pi^{W^{*}}(\cdot|x))-\int_{\mathcal{Y}}\beta(y)d \nu(y)=\int_{\mathcal{Y}}\log\frac{d\nu(y)}{d\pi^{W^{*}}(y|x)}d\nu(y)-\int_{ \mathcal{Y}}\beta(y)d\nu(y)=\] \[\int_{\mathcal{Y}}\log\frac{d\nu(y)}{\exp(\beta(y))d\pi^{W^{*}}(y |x)}d\nu(y)=\int_{\mathcal{Y}}\log\frac{C_{\beta}^{x}d\nu(y)}{C_{\beta}^{x} \exp(\beta(y))d\pi^{W^{*}}(y|x)}d\nu(y)=\] \[\int_{\mathcal{Y}}\log\frac{d\nu(y)}{d\pi^{\beta}(y|x)}d\nu(y)- \log C_{\beta}^{x}=\text{KL}(\nu||\pi^{\beta}(\cdot|x))-\log C_{\beta}^{x}.\]

**Lemma B.2**.: _For \(\pi\in\Pi(\mathbb{P}_{0})\), i.e., probability distributions \(\pi\in\mathcal{P}_{2}(\mathcal{X}\times\mathcal{Y})\) whose projection to \(\mathcal{X}\) equals \(\mathbb{P}_{0}\), we have_

\[\text{KL}(\pi||\pi^{W^{*}})-\int_{\mathcal{Y}}\beta(y)d\pi(y)=\text{KL}(\pi|| \pi^{\beta})-\int_{\mathcal{X}}\log C_{\beta}^{x}d\mathbb{P}_{0}(x).\] (23)

Proof of Lemma b.2.: For each \(x\in\mathcal{X}\), we substitute \(\nu=\pi(\cdot|x)\) to (22) and integrate over \(x\sim\mathbb{P}_{0}\). For the left part, we obtain the following:

\[\int_{\mathcal{X}}\Big{(}\text{KL}(\pi(\cdot|x)||\pi^{W^{*}}( \cdot|x))-\int_{\mathcal{Y}}\beta(y)d\pi(y|x)\Big{)}d\mathbb{P}_{0}(x)=\] \[\int_{\mathcal{X}}\text{KL}(\pi(\cdot|x)||\pi^{W^{*}}(\cdot|x))d \mathbb{P}_{0}(x)-\int_{\mathcal{X}\times\mathcal{Y}}\beta(y)d\pi(y|x)d \mathbb{P}_{0}(x)=\]\[\int_{\mathcal{X}}\int_{\mathcal{Y}}\log\frac{d\pi(y|x)}{d\pi^{W^{ \epsilon}}(y|x)}d\pi(y|x)d\mathbb{P}_{0}(x)-\int_{\mathcal{Y}}\beta(y)d\pi_{1}( y)=\] \[\int_{\mathcal{X}}\int_{\mathcal{Y}}\log\frac{d\pi(y|x)d\mathbb{P} _{0}(x)}{d\pi^{W^{\epsilon}}(y|x)d\mathbb{P}_{0}(x)}d\pi(y|x)d\mathbb{P}_{0}(x) -\int_{\mathcal{Y}}\beta(y)d\pi_{1}(y)=\] \[\int_{\mathcal{X}\times\mathcal{Y}}\log\frac{d\pi(x,y)}{d\pi^{W^ {\epsilon}}(x,y)}d\pi(x,y)-\int_{\mathcal{Y}}\beta(y)d\pi_{1}(y)=\] \[\text{KL}(\pi||\pi^{W^{\epsilon}})-\int_{\mathcal{Y}}\beta(y)d\pi _{1}(y).\]

For the right part, we obtain:

\[\int_{\mathcal{X}}\Big{\{}\text{KL}(\pi(\cdot|x)||\pi^{\beta}( \cdot|x))-\log C_{\beta}^{x}\Big{\}}d\mathbb{P}_{0}(x)=\] \[\int_{\mathcal{X}}\text{KL}(\pi(\cdot|x)||\pi^{\beta}(\cdot|x))d \mathbb{P}_{0}(x)-\int_{\mathcal{X}}\log C_{\beta}^{x}d\mathbb{P}_{0}(x)=\] \[\int_{\mathcal{X}}\int_{\mathcal{Y}}\log\frac{d\pi(y|x)}{d\pi^{ \beta}(y|x)}d\pi(y|x)d\mathbb{P}_{0}(x)-\int_{\mathcal{X}}\log C_{\beta}^{x}d \mathbb{P}_{0}(x)=\] \[\int_{\mathcal{X}}\int_{\mathcal{Y}}\log\frac{d\pi(y|x)d\mathbb{P }_{0}(x)}{d\pi^{\beta}(y|x)d\mathbb{P}_{0}(x)}d\pi(y|x)d\mathbb{P}_{0}(x)-\int _{\mathcal{X}}\log C_{\beta}^{x}d\mathbb{P}_{0}(x)=\] \[\int_{\mathcal{X}\times\mathcal{Y}}\log\frac{d\pi(x,y)}{d\pi^{ \beta}(x,y)}d\pi(x,y)-\int_{\mathcal{X}}\log C_{\beta}^{x}d\mathbb{P}_{0}(x)=\] \[\text{KL}(\pi||\pi^{\beta})-\int_{\mathcal{X}}\log C_{\beta}^{x}d \mathbb{P}_{0}(x).\]

Hence, the equality (23) holds. 

Now we introduce the following auxiliary functional \(\widetilde{\mathcal{L}}\):

\[\widetilde{\mathcal{L}}(\beta,\pi)\stackrel{{\text{def}}}{{=}} \text{KL}(\pi||\pi^{W^{\epsilon}})-\int_{\mathcal{Y}}\beta(y)d\pi_{1}(y)+\int_ {\mathcal{Y}}\beta(y)d\mathbb{P}_{1}(y).\]

Recall that \(\pi_{1}\) denotes the second marginal distribution of \(\pi\). We use this functional to derive the saddle point reformulation of EOT.

**Lemma B.3** (Relaxation of entropic optimal transport).: _It holds that_

\[\mathcal{L}^{*}=\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\text{KL}(\pi|| \pi^{W^{*}})\!=\!\sup_{\beta}\inf_{\pi\in\Pi(\mathbb{P}_{0})}\widetilde{ \mathcal{L}}(\beta,\pi),\] (24)

_where \(\sup\) is taken over potentials \(\beta\in\mathcal{C}_{b,2}(\mathcal{Y})\) and \(\inf\) over \(\pi\in\Pi(\mathbb{P}_{0})\)._

Proof of Lemma b.3.: We obtain

\[\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\text{KL}\big{(} \pi||\pi^{W^{\epsilon}}\big{)}=\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1}) }\Big{\{}\int_{\mathcal{X}}\text{KL}\big{(}\pi(y|x)||\pi^{W^{\epsilon}}(y|x) \big{)}d\mathbb{P}_{0}(x)\Big{\}}=\] \[\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\int_{\mathcal{X}}C \big{(}x,\pi(y|x)\big{)}d\mathbb{P}_{0}(x),\] (25)

where \(C\big{(}x,\nu\big{)}\stackrel{{\text{def}}}{{=}}\text{KL}\big{(} \nu||\pi^{W^{*}}(y|x)\big{)}\). The last problem in (25) is known as weak OT [7, 20] with a weak OT cost \(C\). For a given \(\beta\in\mathcal{C}_{b,2}(\mathcal{Y})\), consider its weak \(C\)-transform given by:

\[\beta^{C}(x)\stackrel{{\text{def}}}{{=}}\inf_{\nu\in\mathcal{P}_{2 }(\mathcal{Y})}\big{\{}C(x,\nu)-\int_{\mathcal{Y}}\beta(y)d\nu(y)\big{\}}.\] (26)

Since \(C:\mathcal{X}\times\mathcal{P}_{2}(\mathcal{Y})\to\mathbb{R}\) is lower bounded (by zero), convex in the second argument and jointly lower semi-continuous, the following equality holds [7, Theorem 1.3]:

\[\mathcal{L}^{*}=\inf_{\pi\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})}\int_{\mathcal{X }}C\big{(}x,\pi(y|x)\big{)}d\mathbb{P}_{0}(x)=\sup_{\beta}\big{\{}\int_{ \mathcal{X}}\beta^{C}(x)d\mathbb{P}_{0}(x)+\int_{\mathcal{Y}}\beta(y)d\mathbb{ P}_{1}(y)\big{\}},\] (27)where \(\sup\) is taken over \(\beta\in\mathcal{C}_{b,2}(\mathcal{Y})\). We use our Proposition B.1 to note that

\[\beta^{C}(x) =\inf_{\nu\in\mathbb{P}_{2}(\mathcal{Y})}\left\{\text{KL}\big{(}\nu ||\pi^{W^{*}}(y|x)\big{)}-\int_{\mathcal{Y}}\beta(y)d\nu(y)\right\}=\] \[\inf_{\nu\in\mathbb{P}_{2}(\mathcal{Y})}\left\{\text{KL}(\nu|| \pi^{\beta}(\cdot|x))-\log C_{\beta}^{x}\right\}=-\log C_{\beta}^{x}.\]

This allows us to derive

\[\int_{\mathcal{X}}\beta^{C}(x)d\mathbb{P}_{0}(x)+\int_{\mathcal{Y }}\beta(y)d\mathbb{P}_{1}(y)=\] (28) \[-\int_{\mathcal{X}}\log C_{\beta}^{x}d\mathbb{P}_{0}(x)+\int_{ \mathcal{Y}}\beta(y)d\mathbb{P}_{1}(y)=\] \[\overbrace{\left\{\inf_{\pi\in\Pi(\mathbb{P}_{0})}\text{KL}(\pi ||\pi^{\beta})\right\}}^{=0}-\int_{\mathcal{X}}\log C_{\beta}^{x}d\mathbb{P}_{ 0}(x)+\int_{\mathcal{Y}}\beta(y)d\mathbb{P}_{1}(y)=\] \[\inf_{\pi\in\Pi(\mathbb{P}_{0})}\left\{\text{KL}(\pi||\pi^{\beta })-\overbrace{\int_{\mathcal{X}}\log C_{\beta}^{x}d\mathbb{P}_{0}(x)+\int_{ \mathcal{Y}}\beta(y)d\mathbb{P}_{1}(y)}^{\text{Do not depend on $\pi$}}\right\}=\] \[\inf_{\pi\in\Pi(\mathbb{P}_{0})}\left\{\text{KL}(\pi||\pi^{\beta })-\int_{\mathcal{Y}}\beta(y)d\pi(y)+\int_{\mathcal{Y}}\beta(y)d\mathbb{P}_{1 }(y)\right\}=\inf_{\pi\in\Pi(\mathbb{P}_{0})}\widetilde{\mathcal{L}}(\beta,\pi).\] (29)

Here in transition to line (29), we use our Lemma B.2. It remains to take \(\sup_{\beta}\) in equality between (28) and (29) and then recall (27) to finish the proof and obtain desired (24). 

Thus, we can obtain the value \(\mathcal{L}^{*}\) (8) by solving maximin problem (24) with only one constraint \(\pi\in\Pi(\mathbb{P}_{0})\). Moreover, our following lemma shows that in all optimal pairs (\(\beta^{*}\), \(\pi^{*}\)) which solve maximin problem (24), \(\pi^{*}\) is necessary the unique entropic OT plan between \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\).

**Lemma B.4** (Entropic OT plan solves the relaxed entropic OT problem).: _Let \(\pi^{*}\) be the entropic OT plan between \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\). For every optimal \(\beta^{*}\in\operatorname*{argsup}_{\beta}\inf_{\pi\in\Pi(\mathbb{P}_{0})} \mathcal{L}(\beta,\pi)\), we have_

\[\pi^{*}=\operatorname*{arginf}_{\pi\in\Pi(\mathbb{P}_{0})}\widetilde{\mathcal{ L}}(\beta^{*},\pi).\] (30)

Proof of Lemma b.4.: Since \(\beta^{*}\) is optimal, we know from Lemma B.3 that \(\inf_{\pi\in\Pi(\mathbb{P}_{0})}\mathcal{L}(\beta^{*},\pi)=\mathcal{L}^{*}\). Thanks to \(\pi^{*}\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})\), we have \(\pi_{1}^{*}=\mathbb{P}_{1}\). We substitute \(\pi^{*}\) to \(\mathcal{L}(\beta^{*},\pi)\) and obtain

\[\mathcal{L}(\beta^{*},\pi^{*})=\text{KL}(\pi^{*}||\pi^{W^{*}})+\int_{\mathcal{ Y}}\!\!\beta(y)d\mathbb{P}_{1}(y)-\int_{\mathcal{Y}}\beta(y)\overbrace{d\pi_{1}^{*} (y)}^{=d\mathbb{P}_{1}(y)}=\text{KL}(\pi^{*}||\pi^{W^{*}})=\mathcal{L}^{*}.\] (31)

The functional \(\pi\mapsto\mathcal{L}(\beta^{*},\pi)\) is strictly convex (in the convex subset of \(\Pi(\mathbb{P}_{0})\) of distributions \(\pi\) for which \(\text{KL}(\pi||\pi^{W^{*}})<\infty\)). Thus, it has a unique minimizer, which is \(\pi^{*}\). 

From our Lemmas B.3 and B.4 it follows that to get the OT plan \(\pi^{*}\) one may solve the maximin problem (24) to obtain an optimal saddle point \((\beta^{*},\pi^{*})\). Unfortunately, it is challenging to estimate \(\text{KL}(\pi||\pi^{W^{*}})\) from samples, which limits the usage of this objective in practice.

### Equivalence of EOT and DSB relaxed problems

Below we show how to relax SB problem (11) and link its solution to the relaxed entropic OT (24).

For a given \(\beta\in\mathcal{C}_{b,2}(\mathcal{Y})\), we define an auxiliary process \(T^{\beta}\) such that its conditional distributions are \(T^{\beta}_{|x,y}=W^{\epsilon}_{|x,y}\) and its joint distribution \(\pi^{T^{\beta}}\) at \(t=0,1\) is given by \(\pi^{\beta}\).

To simplify many of upcoming formulas, we introduce \(C_{\beta}\stackrel{{\text{def}}}{{=}}\int_{\mathcal{X}}\log C_{ \beta}^{x}d\mathbb{P}_{0}(x)\). Also, we introduce \(\mathcal{F}(\mathbb{P}_{0})\) to denote the set of processes starting at \(\mathbb{P}_{0}\) at time \(t=0\).

**Lemma B.5** (Inner objectives of relaxed EOT and SB are KL with \(T^{\beta}\) and \(\pi^{T^{\beta}}\)).: _For \(\pi\in\Pi(\mathbb{P}_{0})\) and \(T\in\mathcal{F}(\mathbb{P}_{0})\), the following equations hold:_

\[\widetilde{\mathcal{L}}(\beta,\pi)=\text{\rm KL}(\pi||\pi^{T^{\beta}})-C_{\beta }+\int_{\mathcal{Y}}\beta(y)d\mathbb{P}_{1}(y),\] (32)

\[\mathcal{L}(\beta,T)=\text{\rm KL}(T||T^{\beta})-C_{\beta}+\int_{\mathcal{Y} }\beta(y)d\mathbb{P}_{1}(y).\] (33)

_Note that the last two terms in each line depend only on \(\beta\) but not on \(\pi\) or \(T\)._

Proof of Lemma b.5.: The first equation (32) directly follows from Lemma B.2. Now we prove (33):

\[\mathcal{L}(\beta,T)-\int_{\mathcal{Y}}\beta(y)d\mathbb{P}_{1}(y)=\text{\rm KL }(T||W^{\epsilon})-\int\beta(y)d\pi_{1}^{T}(y)=\]

\[\text{\rm KL}(\pi^{T}||\pi^{W^{\epsilon}})+\int_{\mathcal{X}\times\mathcal{Y }}\text{\rm KL}(T_{|x,y}||W^{\epsilon}_{|x,y})d\pi^{T}(x,y)-\int\beta(y)d\pi_ {1}^{T}(y)=\] (34)

\[\text{\rm KL}(\pi^{T}||\pi^{T^{\beta}})-C_{\beta}+\int_{\mathcal{X}\times \mathcal{Y}}\text{\rm KL}(T_{|x,y}||W^{\epsilon}_{|x,y})d\pi^{T}(x,y)=\]

\[\text{\rm KL}(\pi^{T}||\pi^{T^{\beta}})-C_{\beta}+\int_{\mathcal{X}\times \mathcal{Y}}\text{\rm KL}(T_{|x,y}||T^{\beta}_{|x,y})d\pi^{T}(x,y)=\text{\rm KL }(T||T^{\beta})-C_{\beta}.\] (35)

In the transition to line (34), we use the disintegration formula (6). In line (35), we use the definition of \(T^{\beta}\), i.e., we exploit the fact that \(T^{\beta}_{|x,y}=W^{\epsilon}_{|x,y}\) and again use (6). 

As a result of Lemma B.5, we obtain the following important corollary.

**Corollary B.6** (The solution to the inner problem of relaxed SB is a diffusion).: _Consider the problem_

\[\inf_{T\in\mathcal{F}(\mathbb{P}_{0})}\mathcal{L}(\beta,T).\] (36)

_Then \(T^{\beta}\) is the unique optimizer of (36) and it holds that \(T^{\beta}\in\mathcal{D}(\mathbb{P}_{0})\), i.e., it is a diffusion process:_

\[T^{\beta}=\operatorname*{arginf}_{T\in\mathcal{F}(\mathbb{P}_{0})}\mathcal{L} (\beta,T)=\operatorname*{arginf}_{T_{f}\in\mathcal{D}(\mathbb{P}_{0})}\mathcal{ L}(\beta,T_{f}).\] (37)

Proof.: Thanks to (33), we see that \(T^{\beta}\) is the unique minimizer of (36). Now let \(\mathbb{Q}\stackrel{{\text{\rm def}}}{{=}}\pi_{1}^{T^{\beta}}\). Then

\[T^{\beta}=\operatorname*{arginf}_{T\in\mathcal{F}(\mathbb{P}_{0})} \mathcal{L}(\beta,T)=\operatorname*{arginf}_{T\in\mathcal{F}(\mathbb{P}_{0})} \Big{[}\text{\rm KL}(T||W^{\epsilon})-\int_{\mathcal{Y}}\beta(y)d\pi_{1}^{T}( y)\Big{]}=\] \[\operatorname*{arginf}_{T\in\mathcal{F}(\mathbb{P}_{0},\mathbb{Q} )}\Big{[}\text{\rm KL}(T||W^{\epsilon})-\underbrace{\int_{\mathcal{Y}}\beta(y) d\pi_{1}^{T}(y)}_{=\text{\rm Const, since }\pi_{1}^{T}=\pi_{1}^{T^{\beta}}=\mathbb{Q}}\text{\rm KL}(T||W^{\epsilon})=\] \[\operatorname*{arginf}_{T_{f}\in\mathcal{D}(\mathbb{P}_{0}, \mathbb{Q})}\text{\rm KL}(T_{f}||W^{\epsilon})=\operatorname*{arginf}_{T_{f} \in\mathcal{D}(\mathbb{P}_{0},\mathbb{Q})}\frac{1}{2\epsilon}\mathbb{E}_{T_{f}} [\int_{0}^{1}||f(X_{t},t)||^{2}dt].\] (38)

In transition to (38), we use the fact that the process solving the Schrodinger Bridge (this time between \(\mathbb{P}_{0}\) and \(\mathbb{Q}\)) with the Wiener Prior is a diffusion process (see Dynamic SB problem in SS2.2 for details). As a result, we obtain \(T^{\beta}\in\mathcal{D}(\mathbb{P}_{0},\mathbb{Q})\subset\mathcal{D}(\mathbb{P} _{0})\) and finish the proof. 

Below we show that for a given \(\beta\), minimization of the SB relaxed functional \(\mathcal{L}(\beta,T_{f})\) over \(T_{f}\) is equivalent to the minimization of relaxed EOT functional \(\widetilde{\mathcal{L}}(\beta,\pi)\) (24) with the same \(\beta\).

**Lemma B.7** (Equivalence of the \(\inf\) values of the relaxed functionals).: _It holds that_

\[\inf_{T_{f}\in\mathcal{D}(\mathbb{P}_{0})}\mathcal{L}(\beta,T_{f})=\inf_{\pi\in \Pi(\mathbb{P}_{0})}\widetilde{\mathcal{L}}(\beta,\pi)=-C_{\beta}+\int\beta(y)d \mathbb{P}_{1}(y).\] (39)

_Moreover, the unique minimizers are given by \(T^{\beta}\in\mathcal{D}(\mathbb{P}_{0})\) and \(\pi^{T^{\beta}}\in\Pi(\mathbb{P}_{0})\), respectively._Proof of Lemma b.7.: Follows from Lemma B.5 and Corollary B.6. 

Finally, we see that both the maximin problems are equivalent.

**Corollary B.8** (Equivalence of EOT and DSB maximin problems).: _It holds that_

\[\mathcal{L}^{*}=\sup_{\beta}\inf_{T_{f}\in\mathcal{D}(\mathbb{P}_{0})}\mathcal{ L}(\beta,T_{f})=\sup_{\beta}\inf_{\pi\in\Pi(\mathbb{P}_{0})}\widetilde{\mathcal{L}}( \beta,\pi)\] (40)

Proof of Corollary b.8.: We take \(\sup_{\beta}\) of both parts in equation (39). 

Also, it follows that the maximization of \(\inf_{T_{f}\in\mathcal{D}(\mathbb{P}_{0})}\mathcal{L}(\beta,T_{f})\) over \(\beta\) allows to solve entropic OT.

### Proofs of main results

Finally, after long preparations, we prove our main Theorem 4.1.

Proof of Theorem 4.1 and Corollary 4.2.: From our Lemma B.7 and Corollary B.8 it follows that

\[\beta^{*}\!\in\!\operatorname*{argsup}_{\beta}\!\!\inf_{T_{f}\in\mathcal{D}( \mathbb{P}_{0})}\!\!\mathcal{L}(\beta,T_{f})\Leftrightarrow\beta^{*}\!\in \!\operatorname*{argsup}_{\beta}\inf_{\pi\in\Pi(\mathbb{P}_{0})}\!\!\widetilde {\mathcal{L}}(\beta,\pi),\]

i.e., both maximin problems share the same optimal \(\beta^{*}\). Thanks to our Lemma B.7, we already know that the process \(T^{\beta^{*}}\in\mathcal{D}(\mathbb{P}_{0})\) and the plan \(\pi^{T^{\beta^{*}}}\in\Pi(\mathbb{P}_{0})\) are the unique minimizers of problems

\[\inf_{T_{f}\in\mathcal{D}(\mathbb{P}_{0})}\!\!\mathcal{L}(\beta^{*},T_{f})= \inf_{\pi\in\Pi(\mathbb{P}_{0})}\!\!\widetilde{\mathcal{L}}(\beta^{*},\pi),\]

respectively. Therefore, \(T_{f^{*}}=T^{\beta^{*}}\) and, in particular, \(\pi^{T_{f^{*}}}=\pi^{T^{\beta^{*}}}\). Moreover, since \((\beta^{*},\pi^{T_{f^{*}}})\) is an optimal saddle point for \(\widetilde{\mathcal{L}}\), from Lemma B.4 we conclude that \(\pi^{T_{f^{*}}}=\pi^{*}\), i.e., \(\pi^{T_{f^{*}}}\) is the **EOT plan** between \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\). In particular, \(\pi^{T_{f^{*}}}\in\Pi(\mathbb{P}_{0},\mathbb{P}_{1})\) which also implies that \(T_{f^{*}}\in\mathcal{D}(\mathbb{P}_{0},\mathbb{P}_{1})\). The last step is to derive

\[\mathcal{L}^{*}=\mathcal{L}(\beta^{*},T_{f^{*}})=\text{KL}(T_{f^{*}}||W^{ \epsilon})+\underbrace{\int_{\mathcal{Y}}\beta^{*}(y)d\mathbb{P}_{1}(y)-\int_{ \mathcal{Y}}\beta^{*}(y)\overbrace{d\pi_{1}^{T_{f^{*}}}(y)}^{=d\mathbb{P}_{1}( y)}}_{=0\text{ since }T_{f^{*}}\in\mathcal{D}(\mathbb{P}_{0},\mathbb{P}_{1})}=\text{KL}(T_{f^{*}}||W^{ \epsilon}).\]

which concludes that \(T_{f^{*}}\) is the **solution to SB** (5). 

Proof of Theorem 4.3.: Part 1. From Lemma B.5 and Corollary B.6 it follows that that \(\inf_{T_{f}}\mathcal{L}(\hat{\beta},T_{f})\) has the unique minimizer \(T^{\widehat{\beta}}\) whose conditional distributions are \(T^{\widehat{\beta}}_{|x,y}=W^{\epsilon}_{|x,y}\). Therefore,

\[\epsilon_{1}=\mathcal{L}(\hat{\beta},T_{f})-\inf_{T_{f}}\mathcal{L}(\hat{\beta },T_{f})=\]

\[\left[\text{KL}(T_{f}||T^{\widehat{\beta}})-C_{\hat{\beta}}+\int_{\mathcal{Y}} \widehat{\beta}(y)d\mathbb{P}_{1}(y)\right]-\big{[}-C_{\widehat{\beta}}+\int_{ \mathcal{Y}}\widehat{\beta}(y)d\mathbb{P}_{1}(y)\big{]}=\text{KL}(T_{f}||T^{ \widehat{\beta}}).\] (41)

Part 2. Now we consider \(\epsilon_{2}\). We know that

\[\mathcal{L}^{*}=\text{KL}(T_{f^{*}}||W^{\epsilon})=\]

\[\text{KL}(\pi^{T_{f^{*}}}||\pi^{W^{\epsilon}})+\int_{\mathcal{X}\times \mathcal{Y}}\text{KL}(T_{f^{*}|x,y}||W^{\epsilon}_{|x,y})d\pi^{T_{f^{*}}}(x,y) =\text{KL}(\pi^{T_{f^{*}}}||\pi^{W^{\epsilon}}).\]

From Lemma B.5 and Corollary B.6, we also know that

\[\inf_{T_{f}}\mathcal{L}(\hat{\beta},T_{f})=-C_{\hat{\beta}}+\int\hat{\beta}(y)d \mathbb{P}_{1}(y).\]

Therefore:

\[\epsilon_{2}=\mathcal{L}^{*}-\inf_{T_{f}}\mathcal{L}(\hat{\beta},T_{f^{*}})= \text{KL}(\pi^{T_{f^{*}}}||\pi^{W^{\epsilon}})+C_{\hat{\beta}}-\int\hat{\beta}( y)d\mathbb{P}_{1}(y)=\]\[\text{KL}(\pi^{T_{f^{*}}}||\pi^{W_{*}})+\int_{\mathcal{X}}\log C_{\beta}^{x}d \mathbb{P}_{0}(x)-\int\hat{\beta}(y)d\mathbb{P}_{1}(y)=\]

\[\int_{\mathcal{X}}\text{KL}(\pi^{T_{f^{*}}}(\cdot|x)||\pi^{W^{*}}(\cdot|x))d \mathbb{P}_{0}(x)+\int_{\mathcal{X}}\log C_{\beta}^{x}d\mathbb{P}_{0}(x)-\int \hat{\beta}(y)d\mathbb{P}_{1}(y)=\]

\[\int_{\mathcal{X}}\text{KL}(\pi^{T_{f^{*}}}(\cdot|x)||\pi^{W^{*}}(\cdot|x))d \mathbb{P}_{0}(x)+\int_{\mathcal{X}}\log C_{\beta}^{x}d\mathbb{P}_{0}(x)-\int \hat{\beta}(y)d\pi^{T_{f^{*}}}(y|x)d\mathbb{P}_{0}(x)=\]

\[\int_{\mathcal{X}}\Big{\{}\text{KL}(\pi^{T_{f^{*}}}(\cdot|x)||\pi^{W^{*}}( \cdot|x))+\log C_{\beta}^{x}-\int_{\mathcal{Y}}\hat{\beta}(y)d\pi^{T_{f^{*}}} (y|x)\Big{\}}d\mathbb{P}_{0}(x)=\]

\[\int_{\mathcal{X}}\Big{\{}\text{KL}(\pi^{T_{f^{*}}}(\cdot|x)||\pi^{T^{\hat{ \beta}}}(\cdot|x))-\log C_{\beta}^{x}+\log C_{\beta}^{x}\Big{\}}d\mathbb{P}_{0 }(x)=\]

\[\int_{\mathcal{X}}\text{KL}(\pi^{T_{f^{*}}}(\cdot|x)||\pi^{T^{\hat{\beta}}}( \cdot|x))d\mathbb{P}_{0}(x)=\text{KL}(\pi^{T_{f^{*}}}||\pi^{T^{\hat{\beta}}})=\]

\[\text{KL}(\pi^{T_{f^{*}}}||\pi^{T^{\hat{\beta}}})+\underbrace{\int_{\mathcal{X }\times\mathcal{Y}}\text{KL}(T_{f^{*}|x,y}||T_{|x,y}^{\hat{\beta}})d\pi^{T_{f^ {*}}}(x,y)}_{=0,\text{ since }T_{f^{*}|x,y}=T_{|x,y}^{\hat{\beta}}=W_{|x,y}^{ \hat{\beta}}}=\text{KL}(T_{f^{*}}||T^{\hat{\beta}}).\] (42)

Thus, we obtain \(\epsilon_{2}=\text{KL}(T_{f^{*}}||T^{\hat{\beta}})\).

Part 3. By summing (41) and (42) and using the Pinsker inequality, we obtain

\[\epsilon_{1}+\epsilon_{2}=\text{KL}(T_{\hat{f}}||T^{\hat{\beta}})+ \text{KL}(T_{f^{*}}||T^{\hat{\beta}})\geq 2\rho_{\text{TV}}^{2}(T_{f},T^{ \widehat{\beta}})+2\rho_{\text{TV}}^{2}(T_{f^{*}},T^{\widehat{\beta}})\geq\]

\[\big{[}\rho_{\text{TV}}(T_{\hat{f}},T^{\widehat{\beta}})+\rho_{\text{TV}}(T_{ f^{*}},T^{\widehat{\beta}})\big{]}^{2}\geq\rho_{\text{TV}}^{2}(T_{\hat{f}},T_{f^{*}}).\] (43)

Here we use the triangle inequality in line (43). Therefore, \(\rho_{\text{TV}}(T_{\hat{f}},T_{f^{*}})\leq\sqrt{\epsilon_{1}+\epsilon_{2}}\).

Part 4. By summing (41) and (42) and using the Pinsker inequality, we obtain

\[\epsilon_{1}+\epsilon_{2}=\text{KL}(T_{f}||T^{\widehat{\beta}})+ \text{KL}(T_{f^{*}}||T^{\widehat{\beta}})=\]

\[\text{KL}(\pi^{T_{f}}||\pi^{T^{\widehat{\beta}}})+\int_{\mathcal{X}\times \mathcal{Y}}\text{KL}(T_{f|x,y}||T_{|x,y}^{\widehat{\beta}})d\pi^{T_{f}}(x,y)+\]

\[\text{KL}(\pi^{T_{f^{*}}}||\pi^{T^{\widehat{\beta}}})+\int_{\mathcal{X}\times \mathcal{Y}}\text{KL}(T_{f^{*}|x,y}||T_{|x,y}^{\widehat{\beta}})d\pi^{T_{f^{*} }}(x,y)\geq\]

\[\text{KL}(\pi^{T_{f}}||\pi^{T^{\widehat{\beta}}})+\text{KL}(\pi^{T_{f^{*}}}|| \pi^{T^{\widehat{\beta}}})\geq 2\rho_{\text{TV}}^{2}(\pi^{T_{f}},\pi^{T^{ \widehat{\beta}}})+2\rho_{\text{TV}}^{2}(\pi^{T_{f^{*}}},\pi^{T^{\widehat{\beta }}})\geq\]

\[\big{[}\rho_{\text{TV}}(\pi^{T_{f}},\pi^{T^{\widehat{\beta}}})+\rho_{\text{TV}} (\pi^{T_{f^{*}}},\pi^{T^{\widehat{\beta}}})\big{]}^{2}\geq\rho_{\text{TV}}^{2} (\pi^{T_{f}},\pi^{T_{f^{*}}}).\]

Thus, \(\rho_{\text{TV}}(\pi^{T_{f^{*}}},\pi^{T^{\widehat{\beta}}})\leq\sqrt{\epsilon_ {1}+\epsilon_{2}}\). 

## Appendix C Euler-Maruyama

In our Algorithm 1, at both the training and the inference stages, we use the Euler-Maruyama Algorithm 2 to solve SDE.

## Appendix D Drift Norm Constant Multiplication Invariance

Our Algorithm 1 aims to solve the following optimization problem:

\[\sup_{\beta}\inf_{T_{f}\in\mathcal{D}(\mathbb{P}_{0})}\underbrace{\Big{\{} \mathbb{E}_{T_{f}}(\int_{0}^{1}C||f(X_{t},t)||^{2}dt]+\int_{\mathcal{Y}}\beta(y )d\mathbb{P}_{1}(y)-\int_{\mathcal{Y}}\beta(y)d\mathbb{P}_{1}^{T_{f}}(y)\Big{\}}} _{\stackrel{{\text{def}}}{{=}}\mathcal{L}^{C}(\beta,T_{f})},\]

with \(C=1\). At the same time, we use \(C=\frac{1}{2\epsilon}\) in our theoretical derivations (12). We emphasize that the actual value of \(C>0\)**does not affect** the optimal solution \(T_{f^{*}}\) to this problem. Specifically, if \((\beta^{*},T_{f^{*}})\) is the optimal point for the problem with \(C=1\), then \((\widetilde{C}\beta^{*},T_{f^{*}})\) is the optimal point for \(C=\widetilde{C}\). Indeed, for a pair \((\beta,T_{f})\) it holds that

\[\mathcal{L}^{1}(\beta,T_{f})=\mathbb{E}_{T_{f}}[\int_{0}^{1}||f(X_ {t},t)||^{2}dt]+\int_{\mathcal{Y}}\beta(y)d\mathbb{P}_{1}(y)-\int_{\mathcal{Y} }\beta(y)d\mathbb{P}_{1}^{T_{f}}(y)=\] \[\frac{1}{\widetilde{C}}\bigg{\{}\mathbb{E}_{T_{f}}[\int_{0}^{1} \widetilde{C}||f(X_{t},t)||^{2}dt]+\int_{\mathcal{Y}}\widetilde{C}\beta(y)d \mathbb{P}_{1}(y)-\int_{\mathcal{Y}}\widetilde{C}\beta(y)d\mathbb{P}_{1}^{T_{ f}}(y)\bigg{\}}=\] \[\frac{1}{\widetilde{C}}\bigg{\{}\mathbb{E}_{T_{f}}[\int_{0}^{1} \widetilde{C}||f(X_{t},t)||^{2}dt]+\int_{\mathcal{Y}}\widetilde{\beta}(y)d \mathbb{P}_{1}(y)-\int_{\mathcal{Y}}\widetilde{\beta}(y)d\mathbb{P}_{1}^{T_{ f}}(y)\bigg{\}}=\frac{1}{\widetilde{C}}\mathcal{L}^{\widetilde{C}}(\widetilde{ \beta},T_{f}),\] (44)

where we use \(\widetilde{\beta}\stackrel{{\mathrm{def}}}{{=}}\widetilde{C}\beta\). Hence problems \(\sup_{\beta}\inf_{T_{f}}\mathcal{L}^{1}(\beta,T_{f})\) and \(\sup_{\widetilde{\beta}}\inf_{T_{f}}\mathcal{L}^{\widetilde{C}}(\widetilde{ \beta},T_{f})\) can be viewed as **equivalent** in the sense that one can be derived one from the other via the change of variables and multiplication by \(\widetilde{C}>0\). For completeness, we also note that the change of variables \(\beta\leftrightarrow\widetilde{\beta}\) actually preserves the functional class of \(\beta\), i.e., \(\beta\in\mathcal{C}_{b,2}(\mathcal{Y})\Longleftrightarrow\widetilde{\beta} \in\mathcal{C}_{b,2}(\mathcal{Y})\).

For convenience, we get rid of dependence on \(\epsilon\) in the objective (12) and consider \(\mathcal{L}^{1}\) for optimization, i.e., use \(C=1\) in Algorithm 1. Still the dependence on \(\epsilon\) remains in \(\sup_{\beta}\inf_{T_{f}}\mathcal{L}^{1}(\beta,T_{f})\) as \(T_{f}\in\mathcal{D}(\mathbb{P}_{0})\) is a diffusion process with volatility \(\epsilon\). Interestingly, this point of view (optimizing \(\mathcal{L}^{1}\) instead of \(\mathcal{L}^{\frac{2\epsilon}{2\epsilon}}\)) **technically** allows to consider even \(\epsilon=0\). In this case, the optimization is performed over _deterministic_ trajectories \(T_{f}\) determined by the velocity field \(f(X_{t},t)\). The problem \(\sup_{\beta}\inf_{T_{f}}\mathcal{L}^{1}(\beta,T_{f})\) may be viewed as a saddle point reformulation of the **unregularized** OT with the quadratic cost in the _dynamic_ form, also known as the Benamou-Brenier formula [43, SS6.1]. This particular case is out of scope of our paper (it is not EOT/SB) and we do not study the properties of \(\mathcal{L}^{1}\) in this case. However, for completeness, we provide experimental results for \(\epsilon=0\).

## Appendix E ENOT for Toy Experiments and High-dimensional Gaussians

In 2D toy experiments, we consider 2 tasks: _Gaussian \(\to\) 8 gaussians_ and _Gaussian \(\to\) Swiss roll_. Results for the last one (Figure 5) are qualitatively similar to results of the first one (Figure 2), which we discussed earlier (SS5.1). For both tasks, we parametrize the SDE drift function in Algorithm 1 by a feedforward neural network \(f_{\theta}\) with 3 inputs, 3 linear layers (100 hidden neurons and ReLU activations) and 2 outputs. As inputs, we use 2 coordinates and time value \(t\) (as is). Analogically, we parametrize the potential by a feedforward neural network \(\beta_{\phi}\) with 2 inputs, 3 linear layers (100 hidden neural and ReLU activations) and 2 outputs. In all the cases, we use \(N=10\) discretization steps for solving SDE by Euler-Maruyama Algorithm 2, Adam with lr \(=10^{-4}\), batch size 512. We train the model for \(20000\) total iterations of \(\beta_{\phi}\), and on each of them, we do \(K_{f}=10\) updates for the SDE drift function \(f_{\theta}\).

In the experiments with high-dimensional Gaussians, we use exactly the same setup as for toy 2D experiments but chose \(N=200\) discretization steps for SDE, all hidden sizes in neural networks are 512, and we train our model for 10000 iterations. To illustrate the stability of the algorithm, we provide the plot of BW\({}_{2}^{2}\)-UVP (%) between the ground truth EOT plan \(\pi^{*}\) and the learned plan \(\pi\) of ENOT during training for \(DIM=128\) in Figure 6.

## Appendix F ENOT for Colored MNIST and Unpaired Super-resolution of Celeba Faces

For the image tasks (SS5.3, SS5.4), we find out that using the following reparametrization of Euler-Maruyama Algorithm 2 considerably improves the quality of our Algorithm 1. In the Euler-Maruyama Algorithm 2, instead of using a neural network to parametrize drift function \(f(X_{t},t)\) and calculating the next state as \(X_{t+1}=X_{t}+f(X_{t},t)\Delta t+\sqrt{\epsilon\Delta t}\), we parametrize \(g(X_{t},t)=X_{t}+f(X_{t},t)\Delta t\) by a neural network \(g_{\theta}\), and calculate the next state as \(X_{t+1}=g_{\theta}(X_{t},t)+\sqrt{\epsilon\Delta t}\). In turn, the drift function is given by \(f(X_{t},t)=\frac{1}{\Delta t}g(X_{t},t)-X_{t}\). Also, we do not add noise at the last step of the Euler-Maruyama simulation because we find out that it provides better empirical performance.

Figure 5: Gaussian \(\rightarrow\) Swiss roll, learned stochastic process with ENOT **(ours)**.

Figure 6: BW\({}_{2}^{2}\)-UVP \(\downarrow\) (%) between the the EOT plan \(\pi^{*}\) and the learned plan \(\pi\) of ENOT and MLE-SB during the training (DIM = 128).

We use WGAN-QC discriminator's ResNet architecture 5 for the potential \(\beta\). We use UNet 6 as \(g_{\theta}(X_{t},t)\) of SDE in our model. To condition it on \(t\), we first obtain the embedding of \(t\) by using the positional embedding 7. Then we add conditional instance normalization (CondIN) layers after each UNet's upscaling block 8. We use Adam with \(\text{lr}=10^{-4}\), batch size 64 and 10:1 update ratio for \(f_{\theta}/\beta_{\phi}\). For \(\epsilon=0\) and \(\epsilon=1\) our model converges in \(\approx 20000\) iterations, while for \(\epsilon=10\) it takes \(\approx 70000\) iteration to convergence. The last setup takes more iterations to converge because adding noise with higher variance during solving SDE by Euler-Maruyama Algorithm 2 increases the variance of stochastic gradients.

Footnote 5: github.com/harryliev/WGAN-QC

Footnote 6: github.com/milesial/Pytorch-UNet

Footnote 7: github.com/rosinality/denoising-diffusion-pytorch

Footnote 8: github.com/kgkgzrtk/cUNet-Pytorch

In the unpaired super-resolution of Celeba faces, we use the same experimental setup as for the colored MNIST experiment. It takes \(\approx 40000\) iterations for \(\epsilon=0\) and \(\approx 70000\) iterations for \(\epsilon=1\) and \(\epsilon=10\) to converge. In Figures 7, 1 we present trajectories provided by our algorithm for Colored MNIST and Celeba experiments.

**Computational complexity.** In the most challenging task (SS5.4), ENOT converges in one week on \(2\times\) A100 GPUs.

## Appendix G Details of the baseline methods

In this section, we discuss details of the baseline methods with which we compare our method.

### Gaussian case (SS5.2).

**SCONES**[14]. We use the code from the authors' repository

https://github.com/mdnls/scones-synthetic

for their evaluation in the Gaussian case. We employ their configuration blob/main/config.py.

**LSOT**[45]. We use the part of the code of SCONES corresponding to learning dual OT potentials blob/main/cpat.py and the barycentric projection blob/main/bproj.py in the Gaussian case with configuration blob/main/config.py.

**FB-SDE-J**[10]. We utilize the official code from

https://github.com/ghliu/SB-FBSDE

with their configuration blob/main/configs/default_checkerboard_config.py for the checkerboard-to-noise toy experiment, changing the number of steps of dynamics from 100 to 200 steps. Since their hyper-parameters are developed for their 2-dimensional experiments, we increase the number of iterations for dimensions 16, 64 and 128 to 15 000.

**FB-SDE-A**[10]. We also take the code from the same repository as above. We base our configuration on the authors' one (blob/main/configs/default_moon_to_spiral_config.py) for the moon-to-spiral experiment. As earlier, we increase the number of steps of dynamics up to 200. Also, we change the number of training epochs for dimensions 16, 64 and 128 to 2,4 and 8 correspondingly.

Figure 7: Trajectories from our learned ENOT (**ours**) for colored MNIST for different \(\epsilon\).

**DiffSB [15]**. We utilize the official code from

https://github.com/JTT94/diffusion_schrodinger_bridge

with their configuration blob/main/conf/dataset/2d.yaml for toy problems. We increase the amount of steps of dynamics to 200 and the number of steps of IPF procedure for dimensions 16, 64 and 128 to 30, 40 and 60, respectively.

**MLE-SB [48]**. We use the official code from

https://github.com/fraciscovargas/GP_Sinkhorn

with hyper-parameters from blob/main/notebooks/2D Toy Data/2d_examples.ipynb. We set the number of steps to 200. As earlier, we increase the number of steps of IPF procedure for dimensions 16, 64 and 128 to 1000, 3500 and 5000, respectively.

### Colored MNIST (SS5.3)

**SCONES [14]**. In order to prepare a score-based model, we use the code from

https://github.com/ermongroup/ncsnv2

with their configuration blob/master/configs/cifar10.yml. Next, we utilize the code of SCONES from the official repository for their unpaired Celeba super-resolution experiment (blob/main/scones/configs/superres_KL_0.005.yml). We adapt it for 32\(\times\)32 ColorMNIST images instead of 64\(\times\)64 celebrity faces.

**DiffSB [15]**. We use the official code with their configuration blob/main/conf/mnist.yaml adopting it for three-channel ColorMNIST images instead of one-channel MNIST digits.

### CelebA (SS5.4)

**SCONES [14]**. For the SCONES, we use their exact code and configuration from blob/main/scones/configs/superres_KL_0.005.yml. As for the score-based model for celebrity faces, we pick the pre-trained model from

https://github.com/ermongroup/ncsnv2

It is the one used by the authors of SCONES in their paper.

**Augmented Cycle GAN [2]**. We use the official code from

https://github.com/NathanDeMaria/AugmentedCycleGAN

with their default hyper-parameters.

**ICNN [38]**. We utilize the reworked implementation by

https://github.com/iamalexkorotin/Wasserstein2Benchmark.

which is a non-minimax version [26] of ICNN-based approach [38]. That is, we use blob/main/notebooks/W2_test_images_benchmark.ipynb and only change the dataloaders.

## Appendix H Mean-Field Games

This appendix discusses the relation between the Mean-Field Game problem and Schrodinger Brdiges.

### Intro to the Mean-Field game.

Consider a game with infinitely many small players. At time moment \(t=0\), they are distributed according to \(X_{0}\sim\rho_{0}\). Every player controls its behavior through drift \(\alpha\) of the SDE:

\[dX_{t}=\alpha(X_{t},t,\rho_{t})dt+\sqrt{2\nu}dW_{t}\]Here \(\rho_{t}\) is the distribution of all the players at the time moment \(t\). When we consider a specific player, we consider \(\rho_{t}\) as a parameter. Each player aims to minimize the quantity:

\[\mathbb{E}[\int_{0}^{T}(L(X_{t},\alpha_{t},\rho_{t})+f(X_{t},\rho_{t}))dt+g(X_{T},\rho_{T})].\]

Here \(L(x,\alpha,\rho)\) is similar to the Lagrange function in physics and describes the cost of moving in some direction given the current position and the other players' distribution. The additional function \(f(X_{t},\rho_{t})\) is interpreted as the cost of the player's interaction at coordinate \(x\) with all the others. Now we can introduce the value function \(\phi(x,t)\), which for position \(x\) and start time \(t\) returns the cost in case of the optimal control:

\[\phi(x,t)\stackrel{{\text{def}}}{{=}}\inf_{\alpha}\mathbb{E}[ \int_{t}^{T}(L(X_{t},\alpha_{t},\rho_{t})+f(X_{t},\rho_{t}))dt+g(X_{T},\rho_{T} )].\]

Before considering the Mean-Field game, we need to define an additional function \(H(x,p,\rho)\). It is similar to the Hamilton function and is defined as the Legendre transform of Lagrange function \(L\):

\[H(x,p,\rho)\stackrel{{\text{def}}}{{=}}\sup_{\alpha}[-\alpha p- L(x,\alpha,\rho)].\]

_Mean-Field game implies finding the Nash equilibrium for all players of such the game._ It is known [1] that the Nash equilibrium is the solution of the system of Hamilton-Jacobi-Bellman (HJB) and Fokker-Planck (FP) PDE equations. For two functions \(H(x,p,\rho)\) and \(f(x,\rho)\), Mean-Field game formulates as a system of two PDE with two constraints:

\[-\partial_{t}\phi-\nu\Delta\phi+H(x,\nabla\phi,\rho)=f(x,\rho)\text{ (HJB)}\]

\[-\partial_{t}\rho-\nu\Delta\rho-\textbf{div}(\rho\nabla_{p}H(x,\nabla\phi))=0 \text{ (FP)}\]

\[\text{ s.t. }\rho(x,0)=\rho_{0}\text{, }\phi(x,T)=g(x,\rho(\cdot,T))\]

The solution of this system is two functions \(\rho(x,t)\) and \(\phi(x,t)\), which describe all players' dynamics. Also, in Nash equilibrium, the specific player's behavior is described by the following SDE:

\[dX_{t}=-\nabla_{p}H(X_{t},\nabla\phi(X_{t},t),\rho)dt+\sqrt{2\nu}dW_{t}.\]

### Relation to our work.

In recent work [34], the authors show that the Schrodinger Bridger problem could be formulated as a Mean-Field game with hard constraints on distribution \(\rho(\cdot,T)=\rho_{target}(\cdot,T)\) via choosing proper function \(g(x,\rho(\cdot,T))\) such as:

\[g(x,\rho(\cdot,T))=\begin{cases}\infty,&\text{if }\rho(\cdot,T)\neq\rho_{target}( \cdot,T)\\ 0,&\rho(\cdot,T)=\rho_{target}(\cdot,T)\end{cases}\]

Also, the authors proposed an extension of DiffSB [34] algorithm for the Mean-Field game problem.

In [33], the authors in their experiments **consider only soft constraints** on the target density. More precisely, they consider only simple constraints such as \(g(x,\rho)=||x-x_{target}||_{2}\), where \(x_{target}\) is a given shared target point for every player, and every player is penalized for being far from this. Such soft constraint force players to have delta distribution at point \(x_{target}\).

To solve the Mean-Field problem, the authors parameterize value function \(\phi(x,t)\) by a neural network and use different neural network \(N_{\theta}\) to sample from \(\rho_{t}\). The authors penalize the violation of Mean-Field game PDEs for optimizing these networks. After the convergence, one can sample from the distribution \(\rho_{t}\) by using neural network \(N_{\theta}\). _Approach_[33]_ _has the advantage that authors do not need to use SDE solvers, which require more steps with growing parameter \(\nu\) of diffusion operator_. However, computation of Laplacian and divergence for high-dimensional spaces (e.g., space 12228-dimensional space of 3x64x64 images) at each iteration of the training step may be computationally hard, restricting the applicability of their method to large-scale setups.

**In our approach**, we initially work with the SDE:

\[dX_{t}=\alpha(X_{t},t,\rho_{t})dt+\sqrt{2\nu}dW_{t},\]

which describes the player's behavior and use a neural network to parametrize the drift \(\alpha\). We consider only **hard constraints** on the target distribution, \(f(X_{t},\rho_{t})=0\) and \(L(X_{t},\alpha_{t},\rho_{t})=\frac{1}{2}||\alpha_{t}||^{2}\) since this variant of Mean-Field game is also the particular case of Schrodinger Bridge problem and is equivalent to the entropic optimal transport. _Since we do not need to compute Laplacian or divergence, our approach scales better with the dimension_. However, for high values of diffusion parameter \(\nu\) (which is equal to the \(\frac{1}{2}\epsilon\) in our notation, where \(\epsilon\) is the entropic regularization strength), our approach needs more steps for accurate solving of the SDE to provide samples, as we mentioned in limitations.

## Appendix I Extending ENOT to other costs

In the main text, we focus only on EOT with the quadratic cost \(c(x,y)=\frac{1}{2}\|x-y\|^{2}\) which coincides with SB with the Wiener prior \(W^{\epsilon}\). However, one could use a different prior \(Q_{v}\) instead of \(W^{\epsilon}\) in (5):

\[Q_{v}:dX_{t}=v(X_{t},t)dt+\sqrt{\epsilon}dW_{t},\]

and solve the problem

\[\inf_{T_{f}\in\mathcal{D}(\mathbb{P}_{0},\mathbb{P}_{1})}\text{KL}(T_{f}||Q_{v })=\inf_{T_{f}\in\mathcal{D}(\mathbb{P}_{0},\mathbb{P}_{1})}\frac{1}{2 \epsilon}\mathbb{E}_{T_{f}}[\int_{0}^{1}||f(X_{t},t)-v(X_{t},t)||^{2}dt].\]

Here we just use the known expression (6) for \(\text{KL}(T_{f}||Q_{v})\) between two diffusion processes through their drift functions. Using the same derivation as in the main text SS2.2, it can be shown that this new problem is equivalent to solving the EOT with cost \(c(x,y)=-\log\pi^{Q_{v}}(y|x)\), where \(\pi^{Q_{v}}(y|x)\) is a conditional distribution of the stochastic process \(Q_{v}\) at time \(t=1\) given the starting point \(x\) at time \(t=0\). For example, for \(W^{\epsilon}\) (which we consider in the main text) we have

\[c(x,y)=-\log\pi^{W^{\epsilon}}(y|x)=\frac{1}{2\epsilon}(y-x)^{T}(y-x)+\text{ Const},\]

i.e., we get the quadratic cost. Thus, using different priors for the Schrodinger bridge problem makes it possible to solve Entropic OT for other costs. We conjecture that most of our proofs and derivations can be extended to arbitrary prior process \(Q_{v}\) just by slightly changing the minimax functional (12):

\[\sup_{\beta}\inf_{T_{f}}\left(\frac{1}{2\epsilon}\mathbb{E}_{T_{f}}[\int_{0}^ {1}||f(X_{t},t)-v(X_{t},t)||^{2}dt]+\int_{\mathcal{Y}}\beta_{\phi}(y)d\mathbb{ P}_{1}(y)-\int_{\mathcal{Y}}\beta_{\phi}(y)d\pi_{1}^{T_{f}}(y)\right).\]

We conduct a toy experiment to support this claim and consider \(Q_{v}\) with \(\epsilon=0.01\) and \(v(x,t)=\nabla\log p(x)\), where \(\log p(x)\) is a 2D distribution with a wave shape, see Figure 8. Intuitively, it means that trajectories should be concentrated in the regions with a high density of \(p\). In Figure e 8, there the grey-scale color map represents the density of \(p\), start points (\(\mathbb{P}_{0}\)) are green, target points (\(\mathbb{P}_{1}\)) are red, obtained trajectories are pink and mapped points are blue.

## Appendix J ENOT for the unregularized OT (\(\epsilon=0\))

Our proposed algorithm is designed to solve entropic OT and the equivalent SB problem. This implies that \(\epsilon>0\). Nevertheless, our algorithm _technically_ allows using even \(\epsilon=0\), in which case it presumably computes the unegularized OT map for the quadratic cost. Here we present some empirical evidence supporting this claim as well some theoretical insights.

Empirical evidence. We consider the experimental setup with images from the continuous Wasserstein-2 benchmark [28, SS4.4]. The images benchmark provides 3 pairs of distributions (Early, Mid, Late) for which the ground truth unregularized OT map for the quadratic cost is known by the construction. Hence, we may compare the map learned with our method (\(\epsilon=0\)) with the true one.

We train our method with \(\epsilon=0\) on each of 3 benchmark pairs and present the quantitative results in Table 6. We use the same \(\mathcal{L}^{2}\)-UVP metric [28, SS4.2] as the authors of the benchmark. As the baselines, we include the results of MM:R method from [28] and the method from [3]. Both methods are minimax and have some similarities with our approach. As we can see, ENOT with \(\epsilon=0\)works better than the MM:R solver but slightly underperforms compared to [3]. This evaluation demonstrates that our method recovers the unregularized OT map for the quadratic cost with the comparable quality to the existing saddle point OT methods.

Theoretical insights. We see that empirically our method with \(\epsilon=0\) recovers the unregularized OT map. At the same time, this is not supported by our theoretical results as they work exclusively for \(\epsilon>0\) and rely on the properties of the KL divergence.

Overall, it seems like for \(\epsilon=0\) our method yields a saddle point reformulation of the Benamou-Brenier (BB) [8] problem which is also known as the dynamic version of the unregularized OT (\(\epsilon=0\)) with the quadratic cost. This problem can be formulated as follows:

\[\inf_{T_{f}}\left\{\frac{1}{2}\mathbb{E}_{T_{f}}[\int_{0}^{1}||f(X_{t},t)||^{2 }dt]\right\}\quad\text{s.t.}\quad T_{f}:dX_{t}=f(X_{t},t)dt,\quad X_{0}\sim \mathbb{P}_{0},X_{1}\sim\mathbb{P}_{1},\] (45)

i.e., the goal is to find the process \(T_{f}\) of the minimal energy which moves the probability mass of \(\mathbb{P}_{0}\) to \(\mathbb{P}_{1}\). BB (45) is very similar to DSB (11) but there is no multiplier \(\frac{1}{\epsilon}\), and the stochastic process \(T_{f}\) is restricted to be deterministic (\(\epsilon=0\)). It is governed by a vector field \(f\). Just like the DSB (11) is equivalent to EOT (2), it is known that BB (45) is **equivalent** to unregularized OT with the quadratic cost (\(\epsilon=0\)). Namely, the distribution \(\pi^{T_{f^{\star}}}\) is the unregularized OT plan between \(\mathbb{P}_{0}\) and \(\mathbb{P}_{1}\).

In turn, our Algorithm 1 for \(\epsilon=0\) optimizes the following saddle point objective:

\[\sup_{\beta}\inf_{T_{f}}\mathcal{L}(\beta,T_{f})\stackrel{{\text {def}}}{{=}}\sup_{\beta}\inf_{T_{f}}\bigg{\{}\frac{1}{2}\mathbb{E}_{T_{f}}[\int _{0}^{1}||f(X_{t},t)||^{2}dt]+\int_{\mathcal{Y}}\beta(y)d\mathbb{P}_{1}(y)- \int_{\mathcal{Y}}\beta(y)d\mathbb{P}_{1}^{T_{f}}(y)\bigg{\}},\] (46)

where \(T_{f}:dX_{t}=f(X_{t},t)dt\) with \(X_{0}\sim\mathbb{P}_{0}\) (the constraint \(X_{1}\sim\mathbb{P}_{1}\) here is lifted) and \(\beta\in\mathcal{C}_{2,b}(\mathcal{Y})\). Just like in the Entropic case, functional \(\mathcal{L}\) can be viewed as the Lagrangian for BB (45) with \(\beta\) playing the role of the Lagrange multiplier for the constraint \(d\pi_{1}^{T_{f}}(y)=d\mathbb{P}_{1}(y)\). Naturally, it is expected that the value (45) coincides with (46), and we provide a _sketch of the proof_ of this fact.

Overall, the proof logic is analogous to the Entropic case but the actual proof is much more technical as we can not use the \(KL\)-divergence machinery which helps to avoid non-uniqueness, etc.

**Step 1 (Auxiliary functional, analog of Lemma B.3).** We introduce an auxiliary functional

\[\widetilde{\mathcal{L}}(\beta,H)\stackrel{{\text{def}}}{{=}} \int_{\mathcal{X}}\frac{1}{2}\|x-H(x)\|^{2}d\mathbb{P}_{0}(x)-\int_{\mathcal{X} }\beta(H(x))d\mathbb{P}_{0}(x)+\int_{\mathcal{Y}}\beta(y)d\mathbb{P}_{1}(y),\]

\begin{table}
\begin{tabular}{|c|c|c|c|} \hline Benchmark & Early & Mid & Late \\ \hline
[28]* & \(1.4\) & \(0.4\) & \(0.22\) \\ \hline
[3]* & \(0.61\) & \(0.20\) & \(0.09\) \\ \hline ENOT (**ours**) & \(0.77\) & \(0.21\) & \(0.09\) \\ \hline \end{tabular}
\end{table}
Table 6: Comparison on W2 benchmark. *Results are taken from [3, Table 2].

where \(\beta\) is a potential and \(H:\mathbb{R}^{D}\to\mathbb{R}^{D}\) is a measurable map. This functional is nothing but the well-known max-min reformulation of static OT problem (in Monge's form) with the quadratic cost [3, Eq. 4], [28, Eq.9]. Hence,

\[\sup_{\beta}\inf_{H}\widetilde{\mathcal{L}}(\beta,H)=\underbrace{\inf_{H \mathbb{P}_{0}=\mathbb{P}_{1}}\int_{\mathcal{X}}\frac{1}{2}||x-H(x)||^{2}d \mathbb{P}_{0}(x)}_{\stackrel{{\text{def}}}{{\leftarrow}} \mathcal{L}^{*}}.\]

**Step 2 (Solution of the inner problem is always an OT map).** An existence of some minimizer \(H=H^{\beta}\) in \(\inf_{H}\widetilde{L}(\beta,H)\) can be deduced from the measurable argmin selection theorem, e.g., [21, Theorem 18.19]. For this \(H^{\beta}\) we consider \(\mathbb{P}^{\prime}\stackrel{{ def}}{{=}}H^{\beta}\sharp \mathbb{P}_{0}\). Recall that

\[H^{\beta}\in\operatorname*{arginf}_{H}\widetilde{L}(\beta,H)=\operatorname*{ arginf}_{H}\int_{\mathcal{X}}\big{\{}\frac{\|x-H(x)\|^{2}}{2}-\beta(H(x))\big{\}}d \mathbb{P}_{0}(x).\]

Here we may add the fictive constraint \(H\sharp\mathbb{P}_{0}=\mathbb{P}^{\prime}\) which is anyway satisfied by \(H^{\beta}\) and get

\[H^{\beta}\in\operatorname*{arginf}_{H\sharp\mathbb{P}_{0}=\mathbb{P}^{\prime }}\int_{\mathcal{X}}\big{\{}\frac{\|x-H(x)\|^{2}}{2}-\beta(H(x))\big{\}}d \mathbb{P}_{0}(x)=\operatorname*{arginf}_{H\sharp\mathbb{P}_{0}=\mathbb{P}^{ \prime}}\int_{\mathcal{X}}\frac{\|x-H(x)\|^{2}}{2}d\mathbb{P}_{0}(x).\]

The last equality holds since \(\int\beta(H(x))d\mathbb{P}_{0}(x)=\int\beta(y)d\mathbb{P}^{\prime}(y)\) does not depend on the choice of \(H\) due to the constraint \(H\sharp\mathbb{P}_{0}=\mathbb{P}^{\prime}\). The latter is the OT problem between \(\mathbb{P}\) and \(\mathbb{P}^{\prime}\) and we see that \(H^{\beta}\) is its solution.

**Step 3 (Equivalence for inner objective values).** Since \(H^{\beta}\) is the OT map between \(\mathbb{P}_{0},\mathbb{P}^{\prime}\) (it is unique as \(\mathbb{P}_{0}\) is absolutely continuous [43]), it can be represented as an ODE solution \(T_{f^{\beta}}\) to the Benamour Brenier problem between \(\mathbb{P}_{0},\mathbb{P}^{\prime}\), i.e., \(T_{f^{\beta}}:dX_{t}=f^{\beta}(X_{t},t)dt\) and \(H^{\beta}(X_{0})=X_{0}+\int_{0}^{1}f^{\beta}(X_{t},t)dt\). Furthermore, in this case, \(\|X_{0}-H^{\beta}(X_{0})\|^{2}=\int_{0}^{1}\|f^{\beta}(X_{t},t)\|^{2}dt\). Hence, it can be derived that

\[\inf_{H}\widetilde{\mathcal{L}}(\beta,H)=\inf_{T_{f}}\mathcal{L}(\beta,T_{f}).\]

**Step 4 (Equivalence of the saddle point objective).** Take \(\sup\) over \(\beta\in\mathcal{C}_{b,2}(\mathcal{Y})\) and get the final equivalence:

\[\sup_{\beta}\inf_{H}\widetilde{\mathcal{L}}(\beta,H)=\sup_{\beta}\inf_{H} \mathcal{L}(\beta,T_{f})=\mathcal{L}^{*}.\]

**Step 5 (Dynamic OT solutions are contained in optimal saddle points).** Pick any optimal \(\beta^{*}\in\operatorname*{argsup}_{\beta}\inf_{H}\mathcal{L}(\beta,T_{f^{*}})\) and let \(T_{f^{*}}\) be any solution to the Benamou-Brenier problem. Checking that \(T^{*}\in\inf_{H}\mathcal{L}(\beta^{*},T_{f})\) can be done analogously to [31, Lemma 4], [42, Lemma 4.1]. 

The derivation above shows the equivalence of objective values of dynamic unregularized OT (45) and our saddle point reformulation of BB (45). Additionally, it shows that solutions \(T_{f^{*}}\) can be recovered from _some_ optimal saddle points \((\beta^{*},T_{f^{*}})\) of our problem. At the same time, _unlike the EOT case_ (\(\epsilon>0\)), it is not guaranteed that for all the optimal saddle points \((\beta^{*},T_{f^{*}})\) it holds that \(T_{f^{*}}\) is the solution to the BB problem. This aspect seems to be closely related to the _fake solutions_ issue in the saddle point methods of OT [30] and may require further studies.