# Is Score Matching Suitable for Estimating Point Processes?

 Haoqun Cao\({}^{1}\), Zizhuo Meng\({}^{2}\), Tianjun Ke\({}^{1}\), Feng Zhou\({}^{1,3}\)

\({}^{1}\)Center for Applied Statistics and School of Statistics, Renmin University of China

\({}^{2}\)Data Science Institute, University of Technology Sydney

\({}^{3}\)Beijing Advanced Innovation Center for Future Blockchain and Privacy Computing

hcao65@wisc.edu, feng.zhou@ruc.edu.cn

Corresponding author.

###### Abstract

Score matching estimators have gained widespread attention in recent years partly because they are free from calculating the integral of normalizing constant, thereby addressing the computational challenges in maximum likelihood estimation (MLE). Some existing works have proposed score matching estimators for point processes. However, this work demonstrates that the incompleteness of the estimators proposed in those works renders them applicable only to specific problems, and they fail for more general point processes. To address this issue, this work introduces the weighted score matching estimator to point processes. Theoretically, we prove the consistency of our estimator and establish its rate of convergence. Experimental results indicate that our estimator accurately estimates model parameters on synthetic data and yields results consistent with MLE on real data. In contrast, existing score matching estimators fail to perform effectively. Codes are publicly available at https://github.com/KenCao2007/WSM_TPP.

## 1 Introduction

Point processes are a class of statistical models used to characterize event occurrences. Typical models include Poisson processes [9] and Hawkes processes [3]. Their applications span various fields such as seismology [16; 17], finance [1; 4], criminology [15], and neuroscience [11; 26]. In the field of point processes, maximum likelihood estimation (MLE) has been a conventional estimator. However, MLE has an inherent limitation: it requires the computation of the normalizing constant, which corresponds to the intensity integral term in the likelihood. Except for simple cases, calculating the intensity integral analytically is generally infeasible. This necessitates the use of numerical integration methods like Monte Carlo or quadrature for approximating the computation. This introduces approximation errors, and more importantly, for high-dimensional problems, numerical integration encounters the curse of dimensionality, rendering training infeasible.

To address this issue, prior research has introduced the concept of score matching (SM) [5] to the field of point processes. For instance, [18] derived the application of SM to the estimation of traditional statistical Poisson processes. Furthermore, [24] extended the use of SM to the estimation of deep covariate spatio-temporal point processes. [10] also generalized the application of SM to Hawkes processes. These works have greatly advanced the utilization of SM for point processes. However, in practical applications, we have found that these estimators only work for specific point processes. For more general cases, these estimators cannot accurately estimate model parameters, even for some simple statistical point processes. One of the core contribution of this work is to _theoretically_ demonstrate the incompleteness of the estimators proposed in the aforementioned studies.

The incompleteness of the estimators in the aforementioned studies stems from the transition from explicit SM to implicit SM. The explicit SM estimates model parameters by minimizing the expected distance between the gradient of the log-density of the model and the gradient of the log-density of the data. However, we cannot directly minimize the above objective function since it depends on the unknown data distribution. To facilitate solving, we need to convert the above explicit SM to implicit SM by using a trick of integration by parts, provided that some regularity conditions are satisfied [5]. In [18; 24; 10], they assume that the required regularity conditions are satisfied in their point process models and directly employ the implicit SM objective. However, as demonstrated in Section 3, the required regularity conditions cannot be met for general point processes. This implies that the concise implicit SM objectives (Equation (2) in [18], Equation (10) in [24], Equation (4) in [10]) are incomplete, and they cannot accurately estimate parameters for general point processes.

To address this issue, this work introduces a (autoregressive) weighted score matching (WSM) estimator that can be applied to more general point processes. WSM eliminates the intractable terms in SM objective by adding a weight function that takes zero at the boundary of the integration region. Compared to previous work on WSM [6; 22; 12], we are the first work to apply WSM on a stochastic process where the dimension \(N_{T}\) is also random. This stochasticity in dimensionality poses greater challenges to the derivation, requiring special treatment to address this issue.

Specifically, we make following contributions: **(1)** We theoretically demonstrate that implicit (autoregressive) SM estimators in [18; 24; 10] are incomplete because the required regularity conditions cannot be satisfied for general point processes. **(2)** To address this issue, we propose a (autoregressive) WSM estimator that is applicable to general point processes. Theoretically, we establish its consistency and convergence rate. **(3)** In experiments, we confirm that on synthetic data, (autoregressive) WSM successfully recovers the ground-truth parameters; on real data, (autoregressive) WSM estimates results consistent with MLE; while existing (autoregressive) SM estimator fails in both scenarios.

## 2 Preliminaries

Now we provide knowledge on Poisson and Hawkes processes and (autoregressive) score matching.

### Poisson Process and Hawkes Process

The Poisson process [9] is a stochastic point process that models the occurrence of events over a time window \([0,T]\). A trajectory from Poisson process can be represented as an ordered sequence \(\mathcal{T}=(t_{1},\ldots,t_{N_{T}})\) where \(N_{t}=\max\{n:t_{n}\leq t,t\in[0,T]\}\) is the corresponding counting process and thus \(N_{T}\) is the random number of events in \([0,T]\). The inhomogeneous Poisson process has a time-varying intensity \(\lambda(t)\) representing the instantaneous rate of event occurrence at \(t\). Mathematically, the intensity function is defined as \(\lambda(t)=\lim_{\delta_{t}\to 0}\mathbb{E}[N_{t+\delta_{t}}-N_{t}]/\delta_{t}\). The probability density function of Poisson process is:

\[p(\mathcal{T})=\prod_{n=1}^{N_{T}}\lambda(t_{n})\exp\left(-\int_{0}^{T}\lambda (t)dt\right).\] (1)

The Hawkes process [3] is a self-excitation point process where the occurrence of an event increases the likelihood of more events in the future. A trajectory from Hawkes process is similarly represented as \(\mathcal{T}=(t_{1},\ldots,t_{N_{T}})\) on \([0,T]\). The conditional intensity function of Hawkes process, representing the instantaneous rate of event occurrence at \(t\) given the history up to but not including \(t\), is:

\[\lambda^{*}(t)=\lambda(t|\mathcal{F}_{t^{-}})=\mu(t)+\sum_{t_{j}<t}g(t-t_{j}),\] (2)

where \(\mu(t)\) is the baseline intensity, \(g(\cdot)\) is the triggering kernel representing the self-excitation effect, the summation expresses the accumulative excitation from all past events, \(\mathcal{F}_{t^{-}}\) is the historical information up to but not including \(t\). \(\lambda^{*}(t)\) means the intensity is dependent on the history.

Poisson process assumes the independence of event occurrences, while Hawkes process extends it by introducing an autoregressive structure, making subsequent events dependent on prior events. Giventhe history \(\mathcal{F}_{t_{n}}=(t_{1},\ldots,t_{n})\), the conditional probability density of \((n+1)\)-th event at \(t>t_{n}\) is:

\[p(t|\mathcal{F}_{t_{n}})=\lambda^{*}(t)\exp\left(-\int_{t_{n}}^{t}\lambda^{*}( \tau)d\tau\right).\] (3)

Here, we introduce the definition of the univariate Hawkes process. However, multivariate Hawkes processes also exist. For ease of notation, we use the univariate case for illustration, but we also provide solutions for the multivariate case.

### Score Matching

MLE is a classic estimator that minimizes Kullback-Leibler divergence between a model distribution and data distribution. However, a drawback is the intractable computation of the normalizing constant. Approximating it through numerical integration can be computationally demanding. In contrast, SM [5] offers an alternative by minimizing Fisher divergence between model and data distributions:

\[\mathcal{L}_{\text{SM}}(\theta)=\frac{1}{2}\mathbb{E}_{p(\mathbf{x})}\|\nabla _{\mathbf{x}}\log p(\mathbf{x})-\nabla_{\mathbf{x}}\log p_{\theta}(\mathbf{x} )\|^{2},\]

where \(p(\mathbf{x})\) represents the data distribution, \(p_{\theta}(\mathbf{x})\) is the parameterized model distribution, the gradient of the log-density is called the score, and \(\|\cdot\|\) represents a suitable norm, such as the \(\ell^{2}\) norm. Minimizing the Fisher divergence above provides the parameter estimate. The advantage of SM lies in its ability to bypass the computation of the normalizing constant since the score no longer contains this constant: \(p_{\theta}(\mathbf{x})=\frac{1}{Z(\theta)}\tilde{p}_{\theta}(\mathbf{x})\) where \(Z(\theta)=\int\tilde{p}_{\theta}(\mathbf{x})d\mathbf{x}\), \(\nabla_{\mathbf{x}}\log p_{\theta}(\mathbf{x})=\nabla_{\mathbf{x}}\log\tilde {p}_{\theta}(\mathbf{x})\).

Under certain conditions, we can use integration by parts to replace the explicit SM objective, which involves an unknown distribution \(p(\mathbf{x})\), with an equivalent implicit one,

\[\mathcal{J}_{\text{SM}}(\theta)=\mathbb{E}_{p(\mathbf{x})}\left[\frac{1}{2} \|\nabla_{\mathbf{x}}\log p_{\theta}(\mathbf{x})\|^{2}+\text{Tr}\left(\nabla_ {\mathbf{x}}^{2}\log p_{\theta}(\mathbf{x})\right)\right].\] (4)

### Autoregressive Score Matching

An autoregressive model defines a probability density \(p(\mathbf{x})\) as a product of conditionals using the chain rule: \(p(\mathbf{x})=\prod_{n=1}^{N}p(x_{n}|\mathbf{x}_{<n})\), where \(x_{n}\) is the \(n\)-th entry and \(\mathbf{x}_{<n}\) denotes the entries with indices smaller than \(n\). The original SM is not suitable for autoregressive models because the autoregressive structure introduces challenges in gradient computation in Equation (4). To address this issue, [13] proposed autoregressive score matching (ASM). Unlike SM, which minimizes the Fisher divergence between the joint distributions of the model \(p_{\theta}(\mathbf{x})\) and the data \(p(\mathbf{x})\), ASM minimizes the Fisher divergence between the conditionals of the model \(p_{\theta}(x_{n}|\mathbf{x}_{<n})\) and the data \(p(x_{n}|\mathbf{x}_{<n})\):

\[\mathcal{L}_{\text{ASM}}(\theta)=\frac{1}{2}\sum_{n=1}^{N}\mathbb{E}_{p( \mathbf{x}_{\leq n})}\left(\frac{\partial\log p(x_{n}|\mathbf{x}_{<n})}{ \partial x_{n}}-\frac{\partial\log p_{\theta}(x_{n}|\mathbf{x}_{<n})}{ \partial x_{n}}\right)^{2}.\]

Similarly, the above explicit ASM objective involves an unknown distribution \(p(x_{n}|\mathbf{x}_{<n})\). Under specific regularity conditions, we can apply integration by parts to derive an implicit ASM objective:

\[\mathcal{J}_{\text{ASM}}(\theta)=\sum_{n=1}^{N}\mathbb{E}_{p(\mathbf{x}_{ \leq n})}\left[\frac{1}{2}\left(\frac{\partial\log p_{\theta}(x_{n}|\mathbf{x} _{<n})}{\partial x_{n}}\right)^{2}+\frac{\partial^{2}\log p_{\theta}(x_{n}| \mathbf{x}_{<n})}{\partial x_{n}^{2}}\right].\] (5)

## 3 Score Matching for Poisson Process

We analyze the application of SM for Poisson process and its failure in achieving consistent estimation. Subsequently, we propose a provably consistent WSM estimator.

### Failure of Score Matching for Poisson Process

Consider a Poisson process \(\mathcal{T}=(t_{1},\ldots,t_{N_{T}})\) on \([0,T]\). Let \(p(\mathcal{T})\) represent the data distribution, which is uniquely associated with an intensity function \(\lambda(t)\). Let \(p_{\theta}(\mathcal{T})\) represent the parameterizedmodel distribution, which is uniquely associated with a parameterized intensity function \(\lambda_{\theta}(t)\). In the following, we denote the score as \(\psi(t_{n})=\frac{\partial}{\partial t_{n}}\log p(\mathcal{T})\).

Previous works [18; 24] have both attempted to apply SM to the Poisson process:

\[\mathcal{L}_{\text{SM}}(\theta)=\frac{1}{2}\mathbb{E}_{p(\mathcal{T})}\left[ \sum_{n=1}^{N_{T}}\left(\psi(t_{n})-\psi_{\theta}(t_{n})\right)^{2}\right].\] (6)

In order for SM to be practical, [18; 24] assumed that specific regularity conditions are satisfied. Therefore, they employed an implicit SM objective similar to Equation (4):

\[\mathcal{J}_{\text{SM}}(\theta)=\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^{ N_{T}}\frac{1}{2}\psi_{\theta}^{2}(t_{n})+\frac{\partial\psi(t_{n})}{\partial t _{n}}\right].\] (7)

In practical applications, we have found that the above estimator works only for specific Poisson processes and fails for more general Poisson processes. The reason for its failure lies in the fact that, for more general Poisson processes, the specific regularity conditions cannot be satisfied.

Such conditions require the probability density function of the random variable is zero when it approaches infinity in any of its dimensions. However, for point processes, such requirement is not satisfied, because the random variable in point process \(\mathcal{T}=(t_{1},\ldots,t_{N_{T}})\) is not of fixed dimension and takes values in a subset of \(\mathbb{R}_{+}^{N_{T}}\). Therefore, for general Poisson processes, we cannot derive the implicit SM in Equation (7) based on the explicit SM in Equation (6).

**Proposition 3.1**.: _Assume that all functions and expectations in \(\mathcal{L}_{\text{SM}}(\theta)\) and \(\mathcal{J}_{\text{SM}}(\theta)\) are well defined, we have,_

\[\mathcal{L}_{\text{SM}}(\theta)= \mathcal{J}_{\text{SM}}(\theta)+\text{const}-\sum_{N=1}^{\infty} \int p(t_{1},\ldots,t_{N})\frac{\partial\log p_{\theta}(t_{1},\ldots,t_{N})}{ \partial t_{1}}\Big{|}_{t_{1}=0}d\mathcal{T}_{2:N}\] (8) \[+\sum_{N=1}^{\infty}\int p(t_{1},\ldots,t_{N})\frac{\partial\log p _{\theta}(t_{1},\ldots,t_{N})}{\partial t_{N}}\Big{|}_{t_{N}=T}d\mathcal{T}_{ 1:N-1}.\]

_Therefore, \(\mathcal{L}_{\text{SM}}(\theta)\) is equivalent to \(\mathcal{J}_{\text{SM}}(\theta)\) if and only if the sum of the last two terms is a constant not containing \(\theta\)._

For specific Poisson processes, the sum of the last two terms can be zero. However, for more general cases, this sum contains \(\theta\). This implies that \(\mathcal{J}_{\text{SM}}\) fails for general Poisson processes.

### Weighted Score Matching

To address the situation where SM fails, inspired by [6; 22], we introduce the WSM for Poisson process. The core idea of WSM is to eliminate the two intractable terms by adding a weight function that takes zero at the boundary of the integration region. The weight function is designed to be a vector-valued function \(\mathbf{h}:\mathbb{R}_{+}^{N_{T}}\rightarrow\mathbb{R}_{+}^{N_{T}}\) with the \(n\)-th element denoted as \(h_{n}(\mathcal{T})\). Here, we present the conditions that a valid weight function should satisfy:

\[\begin{split}\lim_{t_{n}\to t_{n+1}}p(\mathcal{T})\psi_{ \theta}(t_{n})h_{n}(\mathcal{T})=0,\ \lim_{t_{n}\to t_{n-1}}p(\mathcal{T})\psi_{\theta}(t_{n})h_{n}(\mathcal{T})=0,\ \forall n\in[N_{T}],\\ \mathbb{E}[\psi_{\theta}^{2}(t_{n})h_{n}(\mathcal{T})]<\infty,\ \mathbb{E}[\psi_{ \theta}(t_{n})\frac{\partial h_{n}(\mathcal{T})}{\partial t_{n}}]<\infty, \forall n\in[N_{T}].\end{split}\] (9)

One can verify that such weight functions are easy to find for most \(p(\mathcal{T})\) and \(\psi_{\theta}(t_{n})\). With a valid weight function \(\mathbf{h}\), the explicit WSM objective can be defined as:

\[\mathcal{L}_{\text{WSM}}(\theta)=\frac{1}{2}\mathbb{E}_{p(\mathcal{T})}\left[ \sum_{n=1}^{N_{T}}(\psi(t_{n})-\psi_{\theta}(t_{n}))^{2}h_{n}(\mathcal{T}) \right].\] (10)

The introduction of the weight function allows control over the values of the integrand at the boundaries of the integration domain, thereby eliminating the last two terms in Equation (8).

**Theorem 3.2**.: _Assume the true intensity is in the family of the model intensity, denoted as \(\lambda(t)=\lambda_{\theta^{*}}(t)\), where \(\theta^{*}\in\Theta\). We further assume that \(\frac{\partial\log\lambda_{\theta_{1}}(t)}{\partial t}=\frac{\partial\log\lambda _{\theta_{2}}(t)}{\partial t}\ a.s.\) gives \(\theta_{1}=\theta_{2}\). Then the unique minimizer of \(\mathcal{L}_{\text{WSM}}(\theta)\) is \(\theta^{*}\)._

The explicit WSM objective is not practical as it depends on the unknown data distribution \(p(\mathcal{T})\), so we further derive the implicit WSM objective which is tractable.

**Theorem 3.3**.: _Assume that all functions and expectations in \(\mathcal{L}_{\text{WSM}}(\theta)\) and \(\mathcal{J}_{\text{WSM}}(\theta)\) are well defined, Equation (9) is satisfied, we have,_

\[\mathcal{L}_{\text{WSM}}(\theta)=\mathcal{J}_{\text{WSM}}(\theta)+\text{const},\]

\[\mathcal{J}_{\text{WSM}}(\theta)=\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^ {N_{T}}\frac{1}{2}\psi_{\theta}^{2}(t_{n})h_{n}(\mathcal{T})+\frac{\partial \psi_{\theta}(t_{n})}{\partial t_{n}}h_{n}(\mathcal{T})+\psi_{\theta}(t_{n}) \frac{\partial h_{n}(\mathcal{T})}{\partial t_{n}}\right].\] (11)

For general Poisson processes, Equation (11) is always valid with a suitable weight function. Thus, we do not need to worry about the issues of failure that may arise when using Equation (7).

## 4 Autoregressive Score Matching for Hawkes Processes

Similarly, we analyze the usage of ASM for Hawkes processes and its failure in achieving consistent estimation. Subsequently, we propose a provably consistent autoregressive WSM (AWSM) estimator.

### Failure of Autoregressive Score Matching for Hawkes Process

The original SM, even when adjusted by a weight function, is not suitable for point processes with autoregressive structures, such as Hawkes process. Because in such cases, directly calculating the score still includes the intensity integral, which is precisely what the use of SM aims to avoid. Therefore, an ASM method is proposed for parameter estimation for Hawkes process in [10].

Consider a Hawkes process \(\mathcal{T}=(t_{1},\dots,t_{N_{T}})\) on \([0,T]\) with the underlying conditional probability density of \(t_{n}\) denoted as \(p(t_{n}|\mathcal{F}_{t_{n-1}})\). The parameterized conditional probability density model of \(t_{n}\) is \(p_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})\). We denote the conditional score as \(\psi(t_{n}|\mathcal{F}_{t_{n-1}})=\frac{\partial}{\partial t_{n}}\log p(t_{n} |\mathcal{F}_{t_{n-1}})=\frac{\partial}{\partial t_{n}}\log\lambda(t_{n}| \mathcal{F}_{t_{n-1}})-\lambda(t_{n}|\mathcal{F}_{t_{n-1}}),n=1,\dots N_{T}\). An explicit ASM objective is defined as:

\[\mathcal{L}_{\text{ASM}}(\theta)=\frac{1}{2}\mathbb{E}_{p(\mathcal{T})}\left[ \sum_{n=1}^{N_{T}}(\psi(t_{n}|\mathcal{F}_{t_{n-1}})-\psi_{\theta}(t_{n}| \mathcal{F}_{t_{n-1}}))^{2}\right].\] (12)

Similarly, to make ASM practical, [10] assumed that specific regularity conditions are satisfied. Therefore, an implicit ASM is proposed accordingly:

\[\mathcal{J}_{\text{ASM}}(\theta)=\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^ {N_{T}}\frac{1}{2}\psi_{\theta}^{2}(t_{n}|\mathcal{F}_{t_{n-1}})+\frac{\partial \psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})}{\partial t_{n}}\right].\] (13)

However, the same issue as in the Poisson process arises here. The regularity conditions required to eliminate the unknown data distribution do not hold. Therefore, we cannot derive the implicit ASM in Equation (13) based on the explicit ASM in Equation (12).

**Proposition 4.1**.: _Assume that all functions and expectations in \(\mathcal{L}_{\text{ASM}}(\theta)\) and \(\mathcal{J}_{\text{ASM}}(\theta)\) are well defined, we have,_

\[\mathcal{L}_{\text{ASM}}(\theta)= \mathcal{J}_{\text{ASM}}(\theta)+\text{const}+\sum_{n=1}^{\infty }\int p(\mathcal{T}_{:n-1})p(t_{n}|\mathcal{F}_{t_{n-1}})\psi_{\theta}(t_{n}| \mathcal{F}_{t_{n-1}})\Big{|}_{t_{n}=T}d\mathcal{T}_{:n-1}\] (14) \[-\sum_{n=1}^{\infty}\int p(\mathcal{T}_{:n-1})p(t_{n}|\mathcal{F} _{t_{n-1}})\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})\Big{|}_{t_{n}=t_{n-1}}d \mathcal{T}_{:n-1}.\]

_Therefore, \(\mathcal{L}_{\text{ASM}}(\theta)\) is equivalent to \(\mathcal{J}_{\text{ASM}}(\theta)\) if and only if the sum of last two terms is a constant not containing \(\theta\)._

Generally speaking, for most Hawkes processes, the sum of the last two terms in Equation (14) still contains \(\theta\), even for a common Hawkes process with an exponential decay triggering kernel. We illustrate this example in Section 6.2. This implies that \(\mathcal{J}_{\text{ASM}}\) fails for general Hawkes processes.

### Autoregressive Weighted Score Matching

Similarly, to address the situation where ASM fails, we introduce the AWSM for Hawkes process. We present the conditions that a valid weight function \(\mathbf{h}\) should satisfy :

\[\lim_{t_{n}\to T}p(\mathcal{T}_{1:n})\psi_{\theta}(t_{n}| \mathcal{F}_{t_{n-1}})h_{n}(\mathcal{T})=0,\lim_{t_{n}\to t_{n-1}}p( \mathcal{T}_{1:n})\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})h_{n}(\mathcal{T} )=0,\;\forall n\in[N_{T}],\] \[\mathbb{E}[\psi_{\theta}^{2}(t_{n}|\mathcal{F}_{t_{n-1}})h_{n}( \mathcal{T})]<\infty,\;\mathbb{E}[\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}}) \frac{\partial h_{n}(\mathcal{T})}{\partial t_{n}}]<\infty,\forall n\in[N_{T}].\] (15)

With a valid weight function \(\mathbf{h}\), the explicit AWSM objective can be defined as:

\[\mathcal{L}_{\text{AWSM}}(\theta)=\frac{1}{2}\mathbb{E}_{p( \mathcal{T})}\left[\sum_{n=1}^{N_{T}}(\psi(t_{n}|\mathcal{F}_{t_{n-1}})-\psi_ {\theta}(t_{n}|\mathcal{F}_{t_{n-1}}))^{2}h_{n}(\mathcal{T})\right].\] (16)

**Theorem 4.2**.: _Assume the true conditional density is in the family of the model conditional density, denoted as \(p(t_{n}|\mathcal{F}_{t_{n-1}})=p_{\theta^{*}}(t_{n}|\mathcal{F}_{t_{n-1}})\), where \(\theta^{*}\in\Theta\). We further assume that \(p_{\theta_{1}}(t_{n}|\mathcal{F}_{t_{n-1}})=p_{\theta_{2}}(t_{n}|\mathcal{F}_ {t_{n-1}})\;a.e.\) gives \(\theta_{1}=\theta_{2}\). Then the unique minimizer of \(\mathcal{L}_{\text{AWSM}}(\theta)\) is \(\theta^{*}\)._

The explicit AWSM objective is not practical as it depends on the unknown data distribution \(p(t_{n}|\mathcal{F}_{t_{n-1}})\), so we further derive the implicit AWSM objective which is tractable.

**Theorem 4.3**.: _Assume that all functions and expectations in \(\mathcal{L}_{\text{AWSM}}(\theta)\) and \(\mathcal{J}_{\text{AWSM}}(\theta)\) are well defined, Equation (15) are satisfied, we have,_

\[\mathcal{L}_{\text{AWSM}}(\theta)=\mathcal{J}_{\text{AWSM}}( \theta)+\text{const},\] \[\mathcal{J}_{\text{AWSM}}(\theta)=\mathbb{E}_{p(\mathcal{T})} \left[\sum_{n=1}^{N_{T}}\frac{1}{2}\psi_{\theta}^{2}(t_{n}|\mathcal{F}_{t_{n- 1}})h_{n}(\mathcal{T})+\frac{\partial\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}} )}{\partial t_{n}}h_{n}(\mathcal{T})+\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}} )\frac{\partial h_{n}(\mathcal{T})}{\partial t_{n}}\right].\] (17)

For general Hawkes processes, Equation (17) is always valid with a suitable weight function. Thus, we do not need to worry about the issues of failure that may arise when using Equation (13).

Multivariate Hawkes ProcessesFor the multivariate case, events are \(\{(t_{1},k_{1}),\ldots,(t_{N_{T}},k_{N_{T}})\}\) with \(k_{n}\in 1,\ldots,K\) denoting the event type of the \(n\)-th event. The history up to the \((n-1)\)-th event is denoted by \(\mathcal{F}_{t_{n-1}}\). We need to consider both the distributions of event times and event types. For the temporal distribution, we use the AWSM objective with the temporal score \(\psi(t_{n}|\mathcal{F}_{t_{n-1}})=\frac{\partial}{\partial t_{n}}\log p(t_{n}| \mathcal{F}_{t_{n-1}})\) as before. For the type distribution, since we do not need to compute the intensity integral, we directly use the cross-entropy objective:

\[\mathcal{J}_{\text{CE}}(\theta)=\mathbb{E}_{p(\mathcal{T})}\left[ \sum_{n=1}^{N_{T}}\log p_{\theta}(k_{n}|\mathcal{F}_{t_{n-1}},t_{n})\right]= \mathbb{E}\left[\sum_{n=1}^{N_{T}}\log\lambda_{k_{n}}(t_{n}|\mathcal{F}_{t_{n -1}};\theta)-\log\lambda(t_{n}|\mathcal{F}_{t_{n-1}};\theta)\right],\] (18)

where \(\lambda=\sum_{k=1}^{K}\lambda_{k}\). The final loss is \(\mathcal{J}(\theta)=\mathcal{J}_{\text{AWSM}}(\theta)+\alpha\mathcal{J}_{\text {CE}}(\theta)\); \(\alpha\) is a balancing coefficient.

## 5 Theoretical Analysis

In this section, we analyze the statistical properties of AWSM estimator of univariate Hawkes process. Similar conclusions also hold for the WSM estimator of Poisson process, as discussed in Appendix C.5. We consider \(M\) i.i.d. sequences \(\{t_{1}^{(m)},\ldots,t_{N_{m}}^{(m)}\}_{m=1}^{M}\) from \(p(\mathcal{T})\) of a Hawkes process. We assume the true density is in the family of the model density, denoted as \(p(\mathcal{T})=p_{\theta^{*}}(\mathcal{T})\), where \(\theta^{*}\in\Theta\subset\mathbb{R}^{r}\). The estimate \(\hat{\theta}\) is obtained by \(\hat{\theta}=\arg\min_{\theta\in\Theta}\hat{\mathcal{J}}_{\text{AWSM}}(\theta)\) where \(\hat{\mathcal{J}}_{\text{AWSM}}\) represents the empirical loss. Below we omit the subscript AWSM as it does not cause any ambiguity.

### Asymptotic Property

We first establish the consistency of \(\hat{\theta}\) for a Hawkes process.

**Theorem 5.1**.: _Under mild regularity Assumptions C.1 to C.3, we have \(\hat{\theta}\xrightarrow{p}\theta^{*}\) as \(M\rightarrow\infty\)._

### Non-asymptotic Error Bound

Then, we establish a non-asymptotic error bound for \(\hat{\theta}\). We define

\[\mathcal{J}_{\mathrm{h}}(\theta)=\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^{N_ {T}}\big{[}\underbrace{\frac{1}{2}\psi_{\theta}^{2}(t_{n}|\mathcal{F}_{t_{n-1}} )+\frac{\partial\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})}{\partial t_{n}}}_{A _{n}(\mathcal{T},\theta)}\big{]}h_{n}(\mathcal{T})+\underbrace{\psi_{\theta}(t _{n}|\mathcal{F}_{t_{n-1}})}_{B_{n}(\mathcal{T},\theta)}\frac{\partial h_{n}( \mathcal{T})}{\partial t_{n}}\right].\]

**Assumption 5.2**.: Assume there exists \(\alpha>1\) such that,

\[\inf_{\theta:||\theta-\theta^{*}||\geq\delta}\mathcal{J}_{\mathbf{h}}(\theta) -\mathcal{J}_{\mathbf{h}}(\theta^{*})\geq C_{\mathbf{h}}\delta^{\alpha}\]

holds for any small \(\delta\). Here, \(C_{\mathbf{h}}\) is a positive constant that depends on the weight function \(\mathbf{h}\) such that \(C_{a\mathbf{h}}=aC_{\mathbf{h}}\) for any positive constant \(a\). \(\|\cdot\|\) is the euclidean norm.

**Assumption 5.3**.: For \(\forall n\in\mathbb{N}^{+}\), there exists \(\hat{A_{n}}(\mathcal{T}),\dot{B_{n}}(\mathcal{T})\) such that,

\[|A_{n}(\mathcal{T},\theta_{1})-A_{n}(\mathcal{T},\theta_{2})|\leq\dot{A_{n}}( \mathcal{T})||\theta_{1}-\theta_{2}||,\quad|B_{n}(\mathcal{T},\theta_{1})-B_{ n}(\mathcal{T},\theta_{2})|\leq\dot{B_{n}}(\mathcal{T})||\theta_{1}-\theta_{2}||.\]

**Theorem 5.4**.: _Given that \(\hat{\theta}\) converges to \(\theta^{*}\) in probability, combined with Assumptions 5.2 and 5.3, for \(\delta<CK_{\alpha}\frac{\sqrt{r}}{2^{\alpha-1}}\frac{\Gamma(\mathbf{h},A,B)}{C_ {\mathbf{h}}}\), we have_

\[\text{Pr}\left[||\hat{\theta}-\theta^{*}||\leq\left(CK_{\alpha}\frac{\Gamma( \mathbf{h},A,B)}{\delta C_{\mathbf{h}}}\sqrt{\frac{r}{M}}^{1/(\alpha-1)} \right)\right]\geq 1-\delta,\] (19)

_where \(\Gamma(\mathbf{h},A,B)=\sqrt{\mathbb{E}_{p(\mathcal{T})}\left\{\sum_{n=1}^{N_ {T}}\left[(\dot{A}_{n}(\mathcal{T})h_{n}(\mathcal{T}))+(\dot{B}_{n}(\mathcal{ T})\frac{\partial h_{n}(\mathcal{T})}{\partial t_{n}})\right]\right\}^{2}}\), \(C\) is a universal constant, \(K_{\alpha}=\frac{2^{2\alpha}}{2^{\alpha-1}-1}\), and \(r\) is the number of dimensions of \(\theta\)._

### Discussion on Optimal Weight Function

In Sections 3 and 4, we only provide the conditions that the weight function needs to satisfy. In fact, there are many weight functions that satisfy these conditions. The optimal weight function should minimize the error bound in Equation (19), which is equivalent to minimizing the coefficient \(\frac{\Gamma(\mathbf{h},A,B)}{C_{\mathbf{h}}}\). The numerator cannot be analytically computed as it involves an unknown distribution \(p(\mathcal{T})\), but we can maximize the denominator \(C_{\mathbf{h}}\) in a predefined function family.

**Theorem 5.5**.: _Define \(\mathbf{h}^{0}\) to be a weight function with its \(n\)-th element defined as the distance between \(t_{n}\) and the boundary of its support \([t_{n-1},T]\):_

\[h_{n}^{0}(t_{n})=\frac{T-t_{n-1}}{2}-|t_{n}-(T+t_{n-1})/2|.\]

_We have,_

\[\boldsymbol{h}^{0}\in\operatorname*{arg\,max}_{\boldsymbol{h}\in\mathcal{H}} \underset{\theta:||\theta-\theta^{*}||\geq\delta}{\text{inf}}\mathcal{J}_{ \mathbf{h}}(\theta)-\mathcal{J}_{\mathbf{h}}(\theta^{*})\]

_where \(\mathcal{H}\) is a family of functions that is rigorously defined in Equation (27)._

Combined with Assumption 5.2, it can be observed that \(\mathbf{h}^{0}\) maximizes \(C_{\mathbf{h}}\) in \(\mathcal{H}\). Though it does not necessarily optimize \(\frac{\Gamma(\mathbf{h},A,B)}{C_{\mathbf{h}}}\), it is an adequate choice without using any information on \(p(\mathcal{T})\). We also discuss it heuristically in Appendix C.4. It is worth noting that \(h_{n}^{0}\) is not continuously differentiable; however, it is weakly differentiable. Its weak derivative is continuous, allowing both integration by parts and statistical theory to hold. In subsequent experiments, we consistently employ this optimal weight function when \(T\) is available or can be approximated for the dataset.

## 6 Experiments

In this section, we validate our proposed (A)WSM on parametric or deep point process models. For parametric models, we focus on verifying whether (A)WSM can accurately recover the ground-truth parameters. For deep point process models, we confirm that our new training method is also applicable to deep neural network models. 2

### Baselines and Metrics

We consider three baseline parameter estimators: (1) **MLE** (2) implicit **(A)SM**[18; 24; 10] (3) Denoising Score Matching (**DSM**) [10]. We briefly introduce DSM in deep point process models.

For deep Hawkes process training, DSM is employed as follows. For observed timestamps \(t_{n}^{(m)}\) in \(m\)-th sequence, we sample \(L\) noise samples \(\tilde{t}_{n,l}^{(m)}=t_{n}^{(m)}+\epsilon_{n,l}^{(m)},l=1,\ldots,L,\) where \(\text{Var}(\varepsilon_{n,L}^{(m)})=\sigma^{2}\) and get the DSM objective:

\[\hat{\mathcal{J}}(\theta)=\frac{1}{M}\sum_{m=1}^{M}\sum_{n=1}^{N_{m}}\sum_{l=1 }^{L}\frac{1}{2L}\big{[}\psi_{\theta}(\tilde{t}_{n,l}^{(m)}|\mathcal{F}_{t_{n -1}^{(m)}})+\frac{\varepsilon_{n,l}^{(m)}}{\sigma^{2}}\big{]}+\alpha\hat{ \mathcal{J}}_{\text{CE}}(\theta),\]

where \(\mathcal{J}_{\text{CE}}(\theta)\) is the cross-entropy loss defined in Equation (18).

To compare the performance of different methods, for parametric models on synthetic data, we use the mean absolute error (**MAE**, \(|\hat{\theta}-\theta|\)) between the ground-truth parameters and the estimates as a metric since the ground-truth parameters are known. For deep point process models, we use the test log-likelihood (**TLL**) and the event type prediction accuracy (**ACC**) on the test data as metrics.

### Parametric Models

DatasetsWe validate the effectiveness of (A)WSM using three sets of synthetic data. (1) **Poisson Process**: This dataset is simulated from an inhomogeneous Poisson process with an intensity function \(\lambda(t)=\exp(\theta\sin(t))\) with \(T=2\), \(\theta=2\). (2) **Exponential Hawkes Processes**: This dataset is simulated from \(2\)-variate Hawkes processes with exponential decay triggering kernels \(g_{ij}(\tau)=\alpha_{ij}\exp(-5\tau),\;\tau>0\) with \(T=10\), \(\mu_{1}=\mu_{2}=1\), \(\alpha_{11}=1.6,\alpha_{12}=0.2\), \(\alpha_{21}=\alpha_{22}=1\). (3) **Gaussian Hawkes Processes**: This dataset is simulated from \(2\)-variate Hawkes processes with Gaussian decay triggering kernels \(g_{ij}(\tau)=\frac{\alpha_{ij}}{\sqrt{2\pi\sigma}}\exp(-\frac{\tau^{2}}{2\sigma ^{2}}),\;\tau>0\) with \(T=10\), \(\mu_{1}=\mu_{2}=1\), \(\alpha_{11}=1.6,\alpha_{12}=0.2\), \(\alpha_{21}=\alpha_{22}=1\), \(\sigma=1\).

Training ProtocolWe assume that we know the ground-truth model but do not know its parameters. Therefore, we use the ground-truth model as the training model. The purpose is to verify whether the estimator can recover the ground-truth parameters. For each dataset, we collect a total of \(1000\) sequences. We run \(500\) iterations of gradient descent using Adam [8] as the optimizer for all scenarios. For MLE, the intensity integral is computed through numerical integration, with the number of integration nodes set to \(100\) to achieve a considerable level of accuracy. We change the random seed \(3\) times to compute the mean and standard deviation of MAE.

ResultsIn Table 1, we report the MAE of parameter estimates for three models trained by MLE, (A)SM, and (A)WSM on the synthetic dataset. We can see that both MLE and (A)WSM achieve small MAE on three types of data. However, the MAE of (A)SM is large. As we have theoretically demonstrated earlier, this is because MLE and (A)WSM estimators are consistent. In contrast, (A)SM, due to the absence of the required regularity conditions in the three cases, has an incomplete objective and cannot accurately estimate parameters. In Figure 1, we showcase the learned intensity functions. Both MLE and (A)WSM successfully captured the ground truth, while (A)SM fails.

\begin{table}
\begin{tabular}{c|c|c c c|c c c} \hline \hline Estimator & \multicolumn{2}{c|}{Poisson} & \multicolumn{2}{c|}{Exp-Hawkes} & \multicolumn{2}{c}{Gaussian-Hawkes} \\ \cline{2-9}  & \(\phi\) & \(\alpha_{11}\) & \(\alpha_{12}\) & \(\mu_{1}\) & \(\alpha_{11}\) & \(\mu_{1}\) & \(\sigma\) \\ \hline (A)WSM & \(0.07\pm 0.14\) & \(0.041\pm 0.041\) & \(0.026\pm 0.001\) & \(\mathbf{0.011\pm 0.040}\) & \(0.153\pm 0.162\) & \(0.022\pm 0.023\) & \(0.060\pm 0.066\) \\ \hline (A)SM & \(1.56\pm 0.01\) & \(1.600\pm 0.001\) & \(0.200\pm 14.30\) & \(0.700\pm 0.272\) & \(1.413\pm 0.263\) & \(0.696\pm 0.267\) & \(2.507\pm 1.957\) \\ \hline MLE & \(\mathbf{-0.02\pm 0.10}\) & \(\mathbf{0.028\pm 0.015}\) & \(\mathbf{0.014\pm 0.002}\) & \(0.012\pm 0.006\) & \(\mathbf{0.098\pm 0.107}\) & \(\mathbf{0.017\pm 0.019}\) & \(\mathbf{0.051\pm 0.049}\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: The MAE of three models trained by MLE, (A)SM, and (A)WSM on the synthetic dataset. For the 2-variate processes, we only present the estimation results for some parameters here. The results for other parameters can be found in Table 3.

### Deep Point Processes Models

DatasetsWe consider four real datasets. (1) **Half-Sin Hawkes Process**: This is a synthetic 2-variate Hawkes process with trigerring kernel \(g_{ij}=\alpha_{ij}sin(\tau),\tau\in(0,\pi)\), \(K=2\). (2) **StackOverflow**[7]: This dataset has two years of user awards on StackOverflow. Each user received a sequence of badges and there are \(K=22\) kinds of badges. (3) **Retweet**[25]: This dataset includes sequences indicating how each novel tweets are forwarded by other users. Retweeter categories serve as event types \(K=3\). (4) **Taobao**[21]: This dataset comprises user activities on Taobao (in total \(K=17\) event types). For each dataset, we follow the default training/dev/testing split in the repository.

Training ProtocolIn recent years, many deep point process models have been proposed. Here, we focus on two of the most popular attention-based Hawkes process models: **SAHP**[23] and **THP**[27]. We deploy AWSM and ASM on THP and SAHP. For each dataset, we train 3 seeds with the same epochs and report the mean and standard deviation of the best TLL and ACC. When using MLE, we adopt numerical integration to calculate the intensity integral. To ensure model accuracy, the number of integration nodes is set to be large enough as we sample 10 nodes between every two adjacent events. When using DSM, we tune the variance of noise for better results. When using AWSM, since for real datasets, the true observation endpoint \(T\) is unknown. We choose the maximum event time of each batch as the observation endpoint for weight function \(\bm{h}^{0}\). This may lead to unsatisfying results since real datasets may not be sampled during a unified time window. We provide a remedy for this as discussed in Appendix D.1. Details of training and testing hyperparameters are provided in Appendix D.2.

ResultsIn Table 2, we report the performance of SAHP and THP trained using three different methods, namely MLE, AWSM, and DSM, on four datasets. It is evident from the results that models trained with MLE and AWSM exhibit very similar performance in terms of both TLL and ACC on the test data. This indicates consistency between MLE and AWSM, as they yield comparable model parameters. For DSM, it is significantly inferior to the performance of MLE and AWSM. This may result from the fact that the DSM objective is a biased estimation of the original SM objective and fails to produce consistent estimation when \(\sigma>0\) as discussed in [20]. For ASM, it completely fails in the scenarios mentioned above. It is unable to estimate the correct parameters, and its results are not reported. Generally, for complex point process models such as deep Hawkes processes, the necessary regularity conditions are not satisfied, meaning that ASM's objective is incomplete.

### Advantage of (A)WSM over MLE

The key advantage of (A)WSM over MLE is its avoidance of computing intensity integrals, which can be computationally intensive for complex point process models and impact MLE accuracy. We evaluate the test log-likelihood of MLE and AWSM on the Exp-Hawkes dataset as the number of integration nodes varies. As shown in Figure 1d, with a limited number of nodes, MLE is faster but exhibits substantial estimation errors. Increasing the number of nodes reduces the error but significantly increases computation time. In this scenario, AWSM is much faster than MLE with the same accuracy, thus offering better computational efficiency.

Figure 1: The learned intensity functions from MLE, (A)SM, and (A)WSM on (a) Poisson, (b) Exp-Hawkes and (c) Gaussian-Hawkes. We present the results for the 1-st dimension. The 2-nd dimension are in Appendix D. The ground truth, MLE, and (A)WSM nearly overlap, while (A)SM differs. (d) The TLL and runtime of (A)WSM and MLE w.r.t. the number of integration nodes.

### Comparison Between Weights

Though we provide theoretical insight into the choice of an optimal weight function for AWSM, its validity still needs to be testified by experiments. Here, we compare the near-optimal weight \(\bm{h}^{0}\) with natural weight \(\bm{h}^{1}\) and squareroot weight \(\bm{h}^{2}\) satisfying Equation (15),

\[h^{1}_{n}(t_{n})=(t_{n}-t_{n-1})(T-t_{n}),h^{2}_{n}(t_{n})=\sqrt{(t_{n}-t_{n-1} )(T-t_{n})}.\]

All three weight functions can be applied in AWSM to recover ground-truth parameters, however with different convergence rates. We carry out experiments on synthetic data for exponential-decay model with the same setting as Section 6.2 in our paper. We measure their MAE for different sample sizes in Figure 2 and find that \(\mathbf{h^{0}}\) does achieve the best results among the three weight functions.

## 7 Limitations

The current limitation of the methodology is that some real data are collected from multiple time intervals \([0,T_{1}],\ldots,[0,T_{L}]\) or collated in a fixed time interval \([0,T]\) with unknown \(T\). However, for a score matching to be valid, the required weight function must involve knowledge of \(T\). Currently, our remedy including approximate \(T\) or performing data truncation as discussed in Appendix D.1.

## 8 Conclusions

In conclusion, the SM estimator for point processes can overcome the challenges associated with intensity integrals in MLE. While existing works have proposed SM estimators for point processes, our investigation reveals that they prove effective only for specific problems and fall short in more general cases. To address this issue, our work introduces a novel approach: the (A)WSM estimator for point processes, offering both theoretical soundness and empirical success.

\begin{table}
\begin{tabular}{c|c c c|c c} \hline \multirow{2}{*}{Dataset} & \multicolumn{3}{c}{SAHP (TLL!)} & \multicolumn{3}{c}{THP (TLL!)} \\ \cline{2-7}  & MLE & AWSM & DSM & MLE & AWSM & DSM \\ \hline Half-Sin & \(1.542_{\pm 0.038}\) & \(\bm{1.703_{\pm 0.014}}\) & \(0.804_{\pm 0.353}\) & \(1.161_{\pm 0.011}\) & \(\bm{1.271_{\pm 0.036}}\) & \(-0.385_{\pm 0.033}\) \\ \hline Stackoverflow & \(\bm{-2.428_{\pm 0.14}}\) & \(-2.541_{\pm 0.661}\) & \(-2.629_{\pm 0.068}\) & \(\bm{-2.368_{\pm 0.003}}\) & \(-2.508_{\pm 0.007}\) & \(-2.782_{\pm 0.034}\) \\ \hline Tabao & \(\bm{-1.050_{\pm 0.100}}\) & \(-1.373_{\pm 0.091}\) & \(-1.911_{\pm 0.049}\) & \(-1.052_{\pm 0.012}\) & \(\bm{-0.948_{\pm 0.004}}\) & \(-1.791_{\pm 0.040}\) \\ \hline \multirow{2}{*}{Refuets} & \(\bm{0.454_{\pm 0.009}}\) & \(0.411_{\pm 0.077}\) & \(0.110_{\pm 0.186}\) & \(\bm{0.421_{\pm 0.012}}\) & \(0.419_{\pm 0.009}\) & \(-0.183_{\pm 0.197}\) \\ \hline \multirow{2}{*}{Dataset} & \multicolumn{3}{c}{SAHP (ACC!)} & \multicolumn{3}{c}{THP (ACC!)} \\ \cline{2-7}  & MLE & AWSM & DSM & MLE & AWSM & DSM \\ \hline Half-Sin & \(0.502_{\pm 0.001}\) & \(\bm{0.505_{\pm 0.001}}\) & \(0.501_{\pm 0.001}\) & \(0.508_{\pm 0.016}\) & \(\bm{0.523_{\pm 0.010}}\) & \(0.503_{\pm 0.001}\) \\ \hline Stackoverflow & \(0.461_{\pm 0.001}\) & \(\bm{0.462_{\pm 0.01}}\) & \(0.421_{\pm 0.062}\) & \(0.461_{\pm 0.001}\) & \(\bm{0.462_{\pm 0.001}}\) & \(0.445_{\pm 0.0016}\) \\ \hline Tabao & \(\bm{0.572_{\pm 0.022}}\) & \(0.455_{\pm 0.011}\) & \(0.421_{\pm 0.017}\) & \(\bm{0.594_{\pm 0.001}}\) & \(0.592_{\pm 0.002}\) & \(0.435_{\pm 0.010}\) \\ \hline Refuets & \(\bm{0.454_{\pm 0.009}}\) & \(0.411_{\pm 0.077}\) & \(0.590_{\pm 0.009}\) & \(\bm{0.594_{\pm 0.001}}\) & \(0.592_{\pm 0.002}\) & \(0.556_{\pm 0.001}\) \\ \hline \end{tabular}
\end{table}
Table 2: The TLL and ACC of two attention-based deep Hawkes process models trained by MLE and AWSM on four datasets. Because ASM estimator completely fails, we do not report its results.

Figure 2: MAE of parameter estimation versus sample size for three different weight functions on Exponential-Hawkes Model. Our near-optimal weight function outperforms the rest two valid weight functions in all sample sizes. We only show results for three parameters. The rest parameters have almost the same paradigm.

## Acknowledgments and Disclosure of Funding

This work was supported by NSFC Project (No. 62106121), the MOE Project of Key Research Institute of Humanities and Social Sciences (22JJD110001), the fundamental research funds for the central universities, and the research funds of Renmin University of China (24XNKJ13).

## References

* [1] Emmanuel Bacry and Jean-Francois Muzy. Hawkes model for price and trades high-frequency dynamics. _Quantitative Finance_, 14(7):1147-1166, 2014.
* [2] Feng Chen and Peter Hall. Inference for a nonstationary self-exciting point process with an application in ultra-high frequency financial data modeling. _Journal of Applied Probability_, 50(4):1006-1024, 2013.
* [3] Alan G Hawkes. Spectra of some self-exciting and mutually exciting point processes. _Biometrika_, 58(1):83-90, 1971.
* [4] Alan G Hawkes. Hawkes processes and their applications to finance: a review. _Quantitative Finance_, 18(2):193-198, 2018.
* [5] Aapo Hyvarinen. Estimation of non-normalized statistical models by score matching. _J. Mach. Learn. Res._, 6:695-709, 2005.
* [6] Aapo Hyvarinen. Some extensions of score matching. _Computational statistics & data analysis_, 51(5):2499-2512, 2007.
* [7] Leskovec Jure. Snap datasets: Stanford large network dataset collection. _Retrieved December 2021 from http://snap. starford. edu/data_, 2014.
* [8] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6980_, 2014.
* [9] John Frank Charles Kingman. _Poisson processes_, volume 3. Clarendon Press, 1992.
* [10] Zichong Li, Yanbo Xu, Simiao Zuo, Haoming Jiang, Chao Zhang, Tuo Zhao, and Hongyuan Zha. Smurf-thp: Score matching-based uncertainty quantification for transformer hawkes process. 2023.
* [11] Scott Warren Linderman. _Bayesian Methods for Discovering Structure in Neural Spike Trains_. PhD thesis, Harvard University, 2016.
* [12] Song Liu, Takafumi Kanamori, and Daniel J Williams. Estimating density models with truncation boundaries using score matching. _The Journal of Machine Learning Research_, 23(1):8448-8485, 2022.
* [13] Chenlin Meng, Lantao Yu, Yang Song, Jiaming Song, and Stefano Ermon. Autoregressive score matching. _Advances in Neural Information Processing Systems_, 33:6673-6683, 2020.
* [14] Paul Milgrom and Ilya Segal. Envelope theorems for arbitrary choice sets. _Econometrica_, 70(2):583-601, 2002.
* [15] George Mohler. Modeling and estimation of multi-source clustering in crime and security data. _The Annals of Applied Statistics_, pages 1525-1539, 2013.
* [16] Yosihiko Ogata. Space-time point-process models for earthquake occurrences. _Annals of the Institute of Statistical Mathematics_, 50(2):379-402, 1998.
* [17] Yosihiko Ogata. Seismicity analysis through point-process modeling: A review. In _Seismicity patterns, their statistical significance and physical meaning_, pages 471-507. Springer, 1999.

* [18] Maneesh Sahani, Gergo Bohner, and Arne Meyer. Score-matching estimators for continuous-time point-process regression models. In Francesco A. N. Palmieri, Aurelio Uncini, Kostas I. Diamantaras, and Jan Larsen, editors, _26th IEEE International Workshop on Machine Learning for Signal Processing, MLSP 2016, Vietri sul Mare, Salerno, Italy, September 13-16, 2016_, pages 1-5. IEEE, 2016.
* [19] Aad W Van der Vaart. _Asymptotic statistics_, volume 3. Cambridge university press, 2000.
* [20] Pascal Vincent. A connection between score matching and denoising autoencoders. _Neural computation_, 23(7):1661-1674, 2011.
* [21] Siqiao Xue, Xiaoming Shi, James Zhang, and Hongyuan Mei. Hypro: A hybridly normalized probabilistic model for long-horizon prediction of event sequences. _Advances in Neural Information Processing Systems_, 35:34641-34650, 2022.
* [22] Shiqing Yu, Mathias Drton, and Ali Shojaie. Generalized score matching for non-negative data. _The Journal of Machine Learning Research_, 20(1):2779-2848, 2019.
* [23] Qiang Zhang, Aldo Lipani, Omer Kirnap, and Emine Yilmaz. Self-attentive Hawkes process. In _Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event_, volume 119 of _Proceedings of Machine Learning Research_, pages 11183-11193. PMLR, 2020.
* [24] Yixuan Zhang, Quyu Kong, and Feng Zhou. Integration-free training for spatio-temporal multimodal covariate deep kernel point processes. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.
* [25] Qingyuan Zhao, Murat A Erdogdu, Hera Y He, Anand Rajaraman, and Jure Leskovec. Seismic: A self-exciting point process model for predicting tweet popularity. In _Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining_, pages 1513-1522, 2015.
* [26] Feng Zhou, Quyu Kong, Zhijie Deng, Jichao Kan, Yixuan Zhang, Cheng Feng, and Jun Zhu. Efficient inference for dynamic flexible interactions of neural populations. _Journal of Machine Learning Research_, 23(211):1-49, 2022.
* [27] Simiao Zuo, Haoming Jiang, Zichong Li, Tuo Zhao, and Hongyuan Zha. Transformer Hawkes process. In _Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event_, volume 119 of _Proceedings of Machine Learning Research_, pages 11692-11702. PMLR, 2020.

Proof of Results in Section 3

### Proof of Proposition 3.1

Proof.: First consider the cross term in \(\mathcal{L}_{\text{SM}}(\theta)\) and expand the expectation,

\[\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^{N_{T}}\frac{\partial \log p(\mathcal{T})}{\partial t_{n}}\frac{\partial\log p_{\theta}(\mathcal{T})} {\partial t_{n}}\right]\] \[= \sum_{N=1}^{\infty}\int p(t_{1},\ldots,t_{N})\sum_{n=1}^{N}\frac {\partial\log p(t_{1},\ldots,t_{N})}{\partial t_{n}}\frac{\partial\log p_{ \theta}(t_{1},\ldots,t_{N})}{\partial t_{n}}d\mathcal{T}_{1:N}\] (20) \[= \sum_{N=1}^{\infty}\left\{\int\sum_{n=1}^{N}[p(t_{1},\ldots,t_{N} )\frac{\partial\log p_{\theta}(t_{1},\ldots,t_{N})}{\partial t_{n}}]|_{t_{n}=t _{n-1}}^{t_{n}=t_{n+1}}d\mathcal{T}_{-n}\right.\] \[\left.-\int\sum_{n=1}^{N}p(t_{1},\ldots,t_{N})\frac{\partial^{2} \log p_{\theta}(t_{1},\ldots,t_{N})}{\partial t_{n}^{2}}d\mathcal{T}_{1:N} \right\}.\]

The third equation uses an integral-by-part trick. All integrations above are taken within the area of \(\{0\leq t_{1}\leq\ldots\leq t_{N}\leq T\}\) or \(\{0\leq t_{1}\leq\ldots\leq t_{n-1}\leq t_{n+1}\leq\ldots\leq t_{N}\leq T\}\) when \(t_{n}\) has been integrated. For the first term in the right side of the last equation, notice that,

\[\frac{\partial\log p_{\theta}(t_{1},\ldots,t_{N})}{\partial t_{N}}=\frac{ \partial}{\partial t_{n}}\log\lambda_{\theta}(t_{n}),\quad\frac{\partial}{ \partial t_{n}}\log\lambda_{\theta}(t_{n})\big{|}_{t_{n}=t_{n-1}}=\frac{ \partial}{\partial t_{n-1}}\log\lambda_{\theta}(t_{n-1})|_{t_{n-1}=t_{n}}.\] (21)

Therefore, we can see that, for \(n\in\{2,\ldots,n\}\),

\[\int[p(t_{1},\ldots,t_{N})\frac{\partial\log p_{\theta}(t_{1}, \ldots,t_{N})}{\partial t_{n-1}}]|_{t_{n-1}=t_{n}}d\mathcal{T}_{-(n-1)}\] \[= \int[p(t_{1},\ldots,t_{N})\frac{\partial\log p_{\theta}(t_{1}, \ldots,t_{N})}{\partial t_{n}}]|_{t_{n}=t_{n-1}}d\mathcal{T}_{-n}.\]

Using the above equation, we manage to cancel out most of the terms being summed in the right side of the thrid equation in Equation (20) and only leave the first and last term, which completes the proof.

### Proof of Theorem 3.2

Proof.: First, since \(\mathcal{L}_{\text{WSM}}(\theta)\geq 0\) and \(\mathcal{L}_{\text{WSM}}(\theta^{*})=0\), we see \(\theta^{*}\) is a minimizer. If there exists another minimizer \(\theta_{1}\), then we have

\[\mathcal{L}_{\text{WSM}}(\theta)=\sum_{N=1}^{\infty}\int\sum_{n=1}^{N}\left[ \frac{\partial}{\partial t_{n}}\log\lambda_{\theta^{*}}(t_{n})-\frac{ \partial}{\partial t_{n}}\log\lambda_{\theta_{1}}(t_{n})\right]^{2}h_{n}( \mathcal{T})d\mathcal{T}.\]

By the definition of \(\mathbf{h}(\mathcal{T})\), for any \(N\), since \(\mathbf{h}(\mathcal{T})>0\)\(a.s.\) elementwisely on \(\{0\leq t_{1}\leq\ldots\leq t_{N}\leq T\}\). So \(\mathcal{L}_{\text{WSM}}(\theta)=0\) implies \(\frac{\partial\log\lambda_{\theta^{*}}(t)}{\partial t}\) = \(\frac{\partial\log\lambda_{\theta_{1}}(t)}{\partial t}\)\(a.e.\) on \([0,T]\). By assumption, this implies \(\theta_{1}=\theta^{*}\), which completes the proof.

### Proof of Theorem 3.3

Proof.: The proof is basically the same as the proof of Proposition 3.1. We first expand the expectation and consider the cross-term in \(\mathcal{L}_{\text{WSM}}(\theta)\),

\[\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^{N_{T}}\frac{\partial \log p(\mathcal{T})}{\partial t_{n}}\frac{\partial\log p_{\theta}(\mathcal{T}) }{\partial t_{n}}h_{n}(\mathcal{T})\right]=\sum_{N=1}^{\infty}\int\sum_{n=1}^{N }\frac{\partial p(\mathcal{T})}{\partial t_{n}}\frac{\partial\log p_{\theta}( \mathcal{T})}{\partial t_{n}}h_{n}(\mathcal{T})d\mathcal{T}_{1:N}\] \[=\sum_{N=1}^{\infty}\left\{\int\sum_{n=1}^{N}p(t_{1},\ldots,t_{N} )\frac{\partial\log p_{\theta}(\mathcal{T})}{\partial t_{n}}h_{n}(\mathcal{T })\Big{|}_{t_{n}=t_{n-1}}^{t_{n}=t_{n+1}}d\mathcal{T}_{-n}\right.\] (22) \[\left.-\int p(t_{1},\ldots,t_{N})\sum_{n=1}^{N}\left[\frac{ \partial^{2}\log p_{\theta}(\mathcal{T})}{\partial t_{n}^{2}}h_{n}(\mathcal{ T})+\frac{\partial\log p_{\theta}(\mathcal{T})}{\partial t_{n}}\frac{ \partial h_{n}(\mathcal{T})}{\partial t_{n}}\right]d\mathcal{T}_{1:N}\right\}.\]

We denote \(t_{N+1}=T\) and \(t_{0}=0\) here. Using the first two equations in Equation (9), we have:

\[\int[p(t_{1},\ldots,t_{N})\frac{\partial\log p_{\theta}(t_{1}, \ldots,t_{N})}{\partial t_{n}}h_{n}(\mathcal{T})]\big{|}_{t_{n}=t_{n+1}}d \mathcal{T}_{-n}=0,\forall n\in[N],\] \[\int[p(t_{1},\ldots,t_{N})\frac{\partial\log p_{\theta}(t_{1}, \ldots,t_{N})}{\partial t_{n}}h_{n}(\mathcal{T})]\big{|}_{t_{n}=t_{n-1}}d \mathcal{T}_{-n}=0,\forall n\in[N].\]

Therefore, the first intractable summation term in Equation (22) will disappear, and the second term equals \(-\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^{N_{T}}\frac{\partial}{\partial t _{n}}\psi_{\theta}(t_{n})h_{n}(\mathcal{T})+\psi_{\theta}(t_{n})\frac{ \partial}{\partial t_{n}}h_{n}(\mathcal{T})\right]\). The existence of such an expectation is due to the last two equations in Equation (9). Therefore, we complete the proof.

We can see from the proof that, in Equation (9), the first two equations ensure that the integration by parts trick does not produce an intractable term, and the last two equations are simply regularity conditions that ensure all terms are well-defined.

## Appendix B Proof of Results in Section 4

**Lemma B.1**.: _Let \(f(t_{n},\mathcal{F}_{t_{n-1}})\) be a function of \(t_{n},\mathcal{F}_{t_{n-1}}\), where \(n\in\{1,\ldots,N_{T}\}\). Then we have_

\[\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^{N_{T}}f(t_{n},\mathcal{F}_{t_{n-1} })\right]=\sum_{n=1}^{\infty}\int p(t_{1},\ldots,t_{n})f(t_{n},\mathcal{F}_{t_ {n-1}})d\mathcal{T}_{1:n},\]

_where \(p(t_{1},\ldots,t_{n})\) is the density of observing these timestamps, the integration is taken over \(\{0\leq t_{1}\leq\ldots\leq t_{n}\leq T\}\)._

Proof.: We first expand the expectation and obtain,

\[\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^{N_{T}}f(t_{n}, \mathcal{F}_{t_{n-1}})\right]=\sum_{N=1}^{\infty}\int p(t_{1},\ldots,t_{N}) \sum_{n=1}^{N}f(t_{n},\mathcal{F}_{t_{n-1}})d\mathcal{T}\] \[=\sum_{N=1}^{\infty}\Big{\{}\int\int\sum_{n=1}^{N-1}p(t_{1}, \ldots,t_{n})p(t_{n+1},\ldots,t_{N}|\mathcal{F}_{t_{n}})f(t_{n},\mathcal{F}_{t _{n-1}})d\mathcal{T}_{n+1:N}d\mathcal{T}_{1:n}\] \[\quad+\int p(t_{1},\ldots,t_{N})p(N_{T}=N|\mathcal{F}_{t_{N}})f(t _{N},\mathcal{F}_{t_{N-1}})d\mathcal{T}\Big{\}}.\]

At this point, we need to first integrate out \(t_{n+1},\ldots,t_{N}\), which uses

\[\int p(t_{n+1},\ldots,t_{N}|\mathcal{F}_{t_{n}})d\mathcal{T}_{n+1:N}=p(N_{T}=N| \mathcal{F}_{t_{n}}).\]Plug this in and we obtain,

\[\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^{N_{T}}f(t_{n},\mathcal{F }_{t_{n-1}})\right] =\sum_{N=1}^{\infty}\int\sum_{n=1}^{N}p(t_{1},\dots,t_{n})p(N_{T}=N |\mathcal{F}_{t_{n}})f(t_{n},\mathcal{F}_{t_{n-1}})d\mathcal{T}_{1:n}\] \[=\sum_{N=1}^{\infty}\sum_{n=1}^{N}\int p(t_{1},\dots,t_{n})p(N_{T} =N|\mathcal{F}_{t_{n}})f(t_{n},\mathcal{F}_{t_{n-1}})d\mathcal{T}_{1:n}\] \[=\sum_{n=1}^{\infty}\int p(t_{1},\dots,t_{n})f(t_{n},\mathcal{F}_ {t_{n-1}})\sum_{N=n}^{\infty}p(N_{T}=N|\mathcal{F}_{t_{n}})d\mathcal{T}_{1:n}\] \[=\sum_{n=1}^{\infty}\int p(t_{1},\dots,t_{n})f(t_{n},\mathcal{F}_ {t_{n-1}})d\mathcal{T}_{1:n}.\]

The thrid equation adopts the exchange of summation. The feasibility is ensured by the assumption that the expectation in the left side of the equation exists and Fubini's theorem. The fourth equation use the fact that \(\sum_{N=n}^{\infty}p(N_{T}=N|\mathcal{F}_{t_{n}})=1\).

### Proof of Proposition 4.1

Proof.: We use Lemma B.1 to the cross term of \(\mathcal{L}_{\text{ASM}}(\theta)\) and obtain,

\[\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^{N_{T}}\psi(t_{n}| \mathcal{F}_{t_{n-1}})\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})\right]\] \[=\sum_{n=1}^{\infty}\int p(t_{1},\dots t_{n})\psi(t_{n}|\mathcal{ F}_{t_{n-1}})\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})d\mathcal{T}_{1:n}\] \[=\int_{t_{0}}^{T}p(t_{1}|\mathcal{F}_{t_{0}})\frac{\partial\log p (t_{1}|\mathcal{F}_{t_{0}})}{\partial t_{1}}\psi_{\theta}(t_{1}|\mathcal{F}_{t _{0}})dt_{1}\] \[+\sum_{n=2}^{\infty}\int p(t_{1},\dots,t_{n-1})p(t_{n}|\mathcal{F }_{t_{n-1}})\frac{\partial\log p(t_{n}|\mathcal{F}_{t_{n-1}})}{\partial t_{n}} \psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})d\mathcal{T}_{1:n}\] \[=\int_{t_{0}}^{T}\frac{\partial p(t_{1}|\mathcal{F}_{t_{0}})}{ \partial t_{1}}\psi_{\theta}(t_{1}|\mathcal{F}_{t_{0}})dt_{1}+\sum_{n=2}^{ \infty}\int\int_{t_{n-1}}^{T}p(t_{1},\dots,t_{n-1})\frac{\partial p(t_{n}| \mathcal{F}_{t_{n-1}})}{\partial t_{n}}\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n- 1}})dt_{n}d\mathcal{T}_{1:n-1}\] \[=p(t_{1}|\mathcal{F}_{t_{0}})\psi_{\theta}(t_{1}|\mathcal{F}_{t_{ 0}})\big{|}_{t_{1}=t_{0}}^{t_{1}=T}-\int_{t_{0}}^{T}p(t_{1}|\mathcal{F}_{t_{0}}) \frac{\partial\psi_{\theta}(t_{1}|\mathcal{F}_{t_{0}})}{\partial t_{1}}dt_{1}\] \[+\sum_{n=2}^{\infty}\int p(t_{1},\dots,t_{n-1})p(t_{n}|\mathcal{F}_ {t_{n-1}})\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})\big{|}_{t_{n}=t_{n-1}}^{t _{n}=T}d\mathcal{T}_{1:n-1}\] \[-\sum_{n=2}^{\infty}\int p(t_{1},\dots,t_{n})\frac{\partial\psi_{ \theta}(t_{n}|\mathcal{F}_{t_{n-1}})}{\partial t_{n}}d\mathcal{T}_{1:n}\] \[=\sum_{n=1}^{\infty}\int p(\mathcal{T}_{:n-1})p(t_{n}|\mathcal{F} _{t_{n-1}})\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})\big{|}_{t_{n}=t_{n-1}}^{t _{n}=T}d\mathcal{T}_{:n-1}-\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^{N_{T}} \frac{\partial\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})}{\partial t_{n}} \right].\]

For the fifth equation, we simply rearrange the terms. We recall that the notation \(p(\mathcal{T}_{:0})\) equals one. For the last equation, we use Lemma B.1 again. This will be sufficient to complete the proof.

### Proof of Theorem 4.2

Proof.: First, since \(\mathcal{L}_{\text{AWSM}}(\theta)\geq 0\) and \(\mathcal{L}_{\text{AWSM}}(\theta^{*})=0\), we see \(\theta^{*}\) is a minimizer. If there exists another minimizer \(\theta_{1}\), then we have

\[\mathcal{L}_{\text{AWSM}}(\theta_{1})=\frac{1}{2}\sum_{N=1}^{\infty}\int\sum_{ n=1}^{N}[\psi_{\theta^{*}}(t_{n}|\mathcal{F}_{t_{n-1}})-\psi_{\theta_{1}}(t_{n}| \mathcal{F}_{t_{n-1}})]^{2}h_{n}(\mathcal{T})d\mathcal{T}=0.\]

By the definition of \(h_{n}(\mathcal{T})\), we have \(h_{n}(\mathcal{T})>0,\ a.s.\) on \(0\leq t_{1}\leq\ldots,\leq t_{N}\leq T\) for any \(n\leq N\) and \(N\in\mathbb{N}_{+}\). This implies, for any \(n\leq N\) and \(N\in\mathbb{N}_{+}\), \(\psi_{\theta^{*}}(t_{n}|\mathcal{F}_{t_{n-1}})=\psi_{\theta_{1}}(t_{n}| \mathcal{F}_{t_{n-1}}),\ a.e.\) on \(\{0\leq t_{n-1}\leq t_{n}\leq T\}\). Therefore we have

\[\log p_{\theta^{*}}(t_{n}|\mathcal{F}_{t_{n-1}})=\log p_{\theta_{1}}(t_{n}| \mathcal{F}_{t_{n-1}})+C,a.e.,\]

And we conclude that \(C=0\) since \(\int_{t_{n-1}}^{T}p_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})dt_{n}=1\). Then by assumption, we have \(p_{\theta^{*}}(t_{n}|\mathcal{F}_{t_{n-1}})=p_{\theta_{1}}(t_{n}|\mathcal{F}_{ t_{n-1}})\ a.e.\Rightarrow\theta_{1}=\theta^{*}\). 

### Proof of Theorem 4.3

The proof is basically the same as the proof of Proposition 4.1. We first use the Lemma B.1 to the cross term of \(\mathcal{L}_{\text{AWSM}}(\theta)\),

\[\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^{N_{T}}\psi(t_{n}| \mathcal{F}_{t_{n-1}})\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})h_{n}( \mathcal{T})\right]\] \[=\sum_{n=1}^{\infty}\int p(t_{1},\ldots t_{n})\psi(t_{n}| \mathcal{F}_{t_{n-1}})\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})h_{n}( \mathcal{T})d\mathcal{T}_{1:n}\] \[=\sum_{n=1}^{\infty}\int p(\mathcal{T}_{:n-1})p(t_{n}|\mathcal{F} _{t_{n-1}})\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})h_{n}(\mathcal{T})\Big{|} _{t_{n}=t_{n-1}}^{t_{n}=T}d\mathcal{T}_{:n-1}\] \[-\sum_{n=1}^{\infty}\int p(t_{1},\ldots,t_{n})\left[\frac{\partial \psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})}{\partial t_{n}}h_{n}(\mathcal{T})+ \psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})\frac{\partial h_{n}(\mathcal{T})}{ \partial t_{n}}\right]d\mathcal{T}_{1:n}.\]

Between the second and the third line above, we omit the steps used in the derivation of Proposition 4.1 to make it concise. For the term in the third line above, it will be eliminated using Equation (15). For the term in the fourth line above, using Lemma B.1, we have:

\[-\sum_{n=1}^{\infty}\int p(t_{1},\ldots,t_{n})\left[\frac{\partial \psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})}{\partial t_{n}}h_{n}(\mathcal{T}) +\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})\frac{\partial h_{n}(\mathcal{T})}{ \partial t_{n}}\right]d\mathcal{T}_{1:n}=\] \[-\mathbb{E}_{p(\mathcal{T})}\left[\sum_{n=1}^{N_{T}}\frac{ \partial\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})}{\partial t_{n}}h_{n}( \mathcal{T})+\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})\frac{\partial h_{n}( \mathcal{T})}{\partial t_{n}}\right].\]

The existence of the expectation is ensured by the last two terms in Equation (15).

## Appendix C Proof of Results in Section 5

We present all the regularity condition needed for establishing the consistency of our estimator:

**Assumption C.1**.: The parameter space \(\Theta\) is a compact set in \(\mathbb{R}^{d}\) and contains an open set which contains \(\theta^{*}\).

**Assumption C.2**.: Both the \(\mu_{\theta}(t)\) and \(g_{\theta}(t)\) are twice continuously differentiable w.r.t. \(t\) for all \(\theta\in\Theta\) and those derivatives are continuous w.r.t. \(\theta\).

We remind readers that \(\mu_{\theta}(t)\) and \(g_{\theta}(t)\) are the mean intensity function and the triggering kernel for a Hawkes process, first defined in Equation (2).

**Assumption C.3**.: If both \(\mu_{\theta_{1}}(t)=\mu_{\theta_{2}}(t)\ a.s.\) and \(g_{\theta_{1}}(t)=g_{\theta_{2}}(t)\ a.s.\) on \([0,T]\), then \(\theta_{1}=\theta_{2}\).

### Proof of Theorem 5.1

Proof.: As shown in Theorem 5.7 in [19], if we can prove a uniform in probability convergence for \(\hat{\mathcal{J}}_{\text{AWSM}}(\theta)\) to \(\mathcal{J}_{\text{AWSM}}(\theta)\), then using the fact that \(\theta^{*}\) is a unique minimizer of \(\mathcal{J}_{\text{WSM}}(\theta)\) in a compact set in \(\mathbb{R}^{d}\), the consistency is proved. Therefore, we only prove the uniform in probability convergence.

For any \(\theta\in\Theta\), for each sampled sequence \((t_{1}^{(m)},\dots,t_{N_{m}}^{(m)})\), we perceive the following value as a random variable,

\[\xi_{m}=\sum_{n=1}^{N_{m}}\left[\frac{1}{2}\psi_{\theta}(t_{n}^{(m )}|\mathcal{F}_{t_{n-1}^{(m)}})h_{n}(\mathcal{T}^{(m)})+\frac{\partial}{ \partial t_{n}}\psi_{\theta}(t_{n}^{(m)}|\mathcal{F}_{t_{n-1}^{(m)}})h_{n}( \mathcal{T}^{(m)})\right.\] \[\qquad\qquad+\left.\psi_{\theta}(t_{n}^{(m)}|\mathcal{F}_{t_{n-1 }^{(m)}})\frac{\partial}{\partial t_{n}}h_{n}(\mathcal{T}^{(m)})\right].\]

One can verify that it is a measurable map from the sample space to the real line, therefore indeed a random variable. And its expectation is \(\mathcal{J}_{\text{AWSM}}(\theta)\), which is finite by assumption. Since different sequences are i.i.d. samples with finite expectation, using the weak law of large numbers, we have:

\[\hat{\mathcal{J}}_{\text{AWSM}}(\theta)=\frac{1}{M}\sum_{m=1}^{M}\xi_{m} \xrightarrow{p}\mathcal{J}_{\text{AWSM}}(\theta),\forall\theta\in\Theta.\] (23)

Now we prove that this convergence is uniform in \(\Theta\). Similar to [2], we first prove that

\[\forall\varepsilon>0,\exists\delta>0,s.t.\forall\|\theta_{1}-\theta_{2}\|< \delta,\mathbb{P}(|\hat{\mathcal{J}}_{\text{AWSM}}(\theta_{1})-\hat{ \mathcal{J}}_{\text{AWSM}}(\theta_{2})|>\frac{1}{3}\varepsilon)\to 0,M\to\infty.\] (24)

First, by Assumption C.2, we know \(\lambda_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}}\) and \(\frac{\partial}{\partial t_{n}}\lambda_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}}\) are continuous w.r.t \(\theta\). Therefore \(\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})=\frac{\partial}{\partial t_{n}} \log\lambda_{\theta}(t_{n}|\mathcal{F}_{t-1})-\lambda_{\theta}(t_{n}|\mathcal{ F}_{t_{n-1}})\) and \(\frac{\partial}{\partial t_{n}}\psi_{\theta}(t_{n}|\mathcal{F}_{t_{n-1}})= \frac{\partial^{2}}{\partial t_{n}^{2}}\log\lambda_{\theta}(t_{n}|\mathcal{F}_ {t_{n-1}})-\frac{\partial}{\partial t_{n}}\lambda_{\theta}(t_{n}|\mathcal{F}_ {t_{n-1}})\) are both continuous w.r.t. \(\theta\), therefore the \(\mathcal{J}_{\text{AWSM}}(\theta)\) is a continuous function of \(\theta\). Since \(\Theta\) is a compact set in \(\mathbb{R}^{d}\), we know \(\mathcal{J}_{\text{AWSM}}(\theta)\) is uniform continuous.

Therefore, we can bound \(|\mathcal{J}_{\text{AWSM}}(\theta_{1})-\mathcal{J}_{\text{AWSM}}(\theta_{2})|\) using \(\|\theta_{1}-\theta_{2}\|\). Using the result in Equation (23), we know that for any \(\varepsilon>0\), we can find a uniform \(\delta\) so that \(|\mathcal{J}_{\text{AWSM}}(\theta_{1})-\mathcal{J}_{\text{AWSM}}(\theta_{2})| <\frac{1}{6}\varepsilon,\forall\|\theta_{1}-\theta_{2}\|<\delta\). So that,

\[\mathbb{P}(|\hat{\mathcal{J}}_{\text{AWSM}}(\theta_{1})-\hat{ \mathcal{J}}_{\text{AWSM}}(\theta_{2})|>\frac{1}{3}\varepsilon)\] \[<\mathbb{P}(|\hat{\mathcal{J}}_{\text{AWSM}}(\theta_{1})- \mathcal{J}_{\text{AWSM}}(\theta_{1})|+|\hat{\mathcal{J}}_{\text{AWSM}}( \theta_{2})-\mathcal{J}_{\text{AWSM}}(\theta_{2})|>\frac{1}{6}\varepsilon)\] \[<\mathbb{P}(|\hat{\mathcal{J}}_{\text{AWSM}}(\theta_{1})- \mathcal{J}_{\text{AWSM}}(\theta_{1})|>\frac{1}{12}\varepsilon)\to 0,M\to\infty.\]

Now we follow exactly the same steps as [2] for the uniform in probability convergence. Since Equation (24) hold, for such a \(\delta\) in that equation, since \(\Theta\) is a compact set in \(\mathbb{R}^{d}\), there exists a finite number of open balls with radius \(\delta\) whose union covers \(\Theta\). Let \(\vartheta_{1},\dots,\vartheta_{i},\dots,\vartheta_{L}\) denote the centers of these balls. We denote \(\vartheta_{i(\theta)}\) the center of a ball which contains \(\theta\). Since we have

\[\mathbb{P}(\sup_{\theta}|\hat{\mathcal{J}}_{\text{AWSM}}(\theta)- \mathcal{J}_{\text{AWSM}}(\theta)|>\varepsilon)\leq\mathbb{P}(\sup_{\theta}| \hat{\mathcal{J}}_{\text{AWSM}}(\theta)-\hat{\mathcal{J}}_{\text{AWSM}}( \vartheta_{i(\theta)})|>\frac{\varepsilon}{3})\] \[+\mathbb{P}(\sup_{\theta}|\hat{\mathcal{J}}_{\text{AWSM}}( \vartheta_{i(\theta)})-\mathcal{J}_{\text{AWSM}}(\vartheta_{i(\theta)})|>\frac{ \varepsilon}{3})+\mathbb{P}(\sup_{\theta}|\mathcal{J}_{\text{AWSM}}(\theta) -\mathcal{J}_{\text{AWSM}}(\vartheta_{i(\theta)})|>\frac{\varepsilon}{3}).\]

The third term on the right equals \(0\) because of its definition and the uniform continuous of \(\mathcal{J}_{\text{AWSM}}(\theta)\). The first term converges to \(0,M\to\infty\) by Equation (24). For the second term, we write

\[\mathbb{P}(\sup_{\theta}|\hat{\mathcal{J}}_{\text{AWSM}}(\theta)-\mathcal{J}_{ \text{AWSM}}(\vartheta_{i(\theta)})|>\frac{\varepsilon}{3})<\sum_{i=1}^{L} \mathbb{P}(|\hat{\mathcal{J}}_{\text{AWSM}}(\theta_{i})-\mathcal{J}_{\text{ AWSM}}(\theta_{i})|>\frac{\varepsilon}{3})\to 0.\]Finally we obtain \(\sup_{\theta\in\Theta}|\hat{\mathcal{J}}_{\text{AWSM}}(\theta)-\mathcal{J}_{\text{ AWSM}}(\theta)|\xrightarrow{p}0\), which completes the proof.

### Proof of Theorem 5.4

First we restate the technical assumptions needed for the proof.

**Assumption 5.2**.: _Assume there exists \(\alpha>1\) such that,_

\[\inf_{\theta:||\theta-\theta^{*}||\geq\delta}\mathcal{J}_{\mathbf{h}}(\theta)- \mathcal{J}_{\mathbf{h}}(\theta^{*})\geq C_{\mathbf{h}}\delta^{\alpha}\]

_holds for any small \(\delta\). Here, \(C_{\mathbf{h}}\) is a positive constant that depends on the weight function \(\mathbf{h}\) such that \(C_{a\mathbf{h}}=aC_{\mathbf{h}}\) for any positive constant \(a\)._

For this assumption, we assume that the optimal parameter \(\theta^{*}\) is well-separated from other neighbouring parameters in terms of the population objective values. This is a standard assumption for Theorem 5.52 in [19]. This assumption will satisfy if \(\nabla_{\theta}^{2}\mathcal{J}_{\mathbf{h}}(\theta)\) is positive definite at \(\theta^{*}\).

**Assumption 5.3**.: _For \(\forall n\in\mathbb{N}^{+}\), there exists \(\dot{A_{n}}(\mathcal{T}),\dot{B_{n}}(\mathcal{T})\) such that,_

\[|A_{n}(\mathcal{T},\theta_{1})-A_{n}(\mathcal{T},\theta_{2})|\leq\dot{A_{n}}( \mathcal{T})||\theta_{1}-\theta_{2}||,\quad|B_{n}(\mathcal{T},\theta_{1})-B_{ n}(\mathcal{T},\theta_{2})|\leq\dot{B_{n}}(\mathcal{T})||\theta_{1}-\theta_{2}||.\]

For this assumption, we assume the objective function has certain level of continuity. This assumption will realize if \(sup_{\theta\in\Theta}||\nabla_{\theta}A_{n}(\mathcal{T},\theta)||\) exisits for any \(n\) and the same condition also applies to \(B_{n}(\mathcal{T},\theta)\).

We also define,

\[J_{\mathbf{h}}(\mathcal{T};\theta)=\sum_{n=1}^{N_{T}}\left[[A_{n}(\mathcal{T}, \theta)h_{n}(\mathcal{T})+B_{n}(\mathcal{T},\theta)\frac{\partial h_{n}( \mathcal{T})}{\partial t_{n}}\right],\]

we see \(\mathbb{E}[J_{\mathbf{h}}(\mathcal{T};\theta)]=\mathcal{J}_{h}(\theta)\).

Now we begin the proof of Theorem 5.4.

Proof.: First define

\[\dot{J}_{\mathbf{h}}(\mathcal{T})=\sum_{n=1}^{N_{T}}\left[\dot{A_{n}}( \mathcal{T})h_{n}(\mathcal{T})+\dot{B_{n}}(\mathcal{T})\frac{\partial h_{n}( \mathcal{T})}{\partial t_{n}}\right].\]

Next we evaluate the bracketing number of such function class,

\[\mathcal{F}_{\delta}:=\{J_{\mathbf{h}}(\mathcal{T};\theta)-J_{\mathbf{h}}( \mathcal{T};\theta^{*})|\theta\in\Theta,||\theta-\theta^{*}||\leq\delta\}.\]

a

Denote \(\mathcal{N}_{[}](\varepsilon,\mathcal{F},L^{2}(P))\) as the bracketing number of \(\mathcal{F}\) with the radius \(\varepsilon\) under the norm of \(L^{2}(P)\). \(P\) is the underlying probability measure induced by \(\mathcal{T}\). Use Example 19.6 in [19] we have,

\[\mathcal{N}_{[}](\varepsilon||J||_{L^{2}(P)},\mathcal{F}_{\delta},L^{2}(P)) \leq(1+\frac{4\delta}{\varepsilon})^{r}\]

Since

\[|J_{\mathbf{h}}(\mathcal{T};\theta)-J_{\mathbf{h}}(\mathcal{T};\theta^{*})| \leq\dot{J}_{\mathbf{h}}(\mathcal{T})||\theta-\theta^{*}||\leq\dot{J}_{ \mathbf{h}}(\mathcal{T})\delta,\] (25)

therefore \(\dot{J}_{\mathbf{h}}(\mathcal{T})\delta\) is the envelope of \(\mathcal{F}_{\delta}\), we denote it as \(F_{\delta}\). Therefore we obtain,

\[\mathcal{N}_{[}](\varepsilon||F_{\delta}||_{L^{2}(P)},\mathcal{F}_{\delta},L^ {2}(P))=\mathcal{N}_{[}](\varepsilon\delta||\dot{J}_{\mathbf{h}}||_{L^{2}(P)},\mathcal{F}_{\delta},L^{2}(P))\leq(1+\frac{4}{\varepsilon})^{r}.\]

After obtaining this quantity, the next step is to upper bound the empirical process defined as,

\[\mathbb{G}_{M}\big{(}J_{\mathbf{h}}(;\theta)-J_{\mathbf{h}}(;\theta^{*})\big{)} :=\frac{1}{\sqrt{M}}\sum_{m=1}^{M}\left[J_{\mathbf{h}}(\mathcal{T}_{m};\theta)- J_{\mathbf{h}}(\mathcal{T}_{m};\theta^{*})-\mathbb{E}_{p(\mathcal{T})}[J_{ \mathbf{h}}(\mathcal{T};\theta)-J_{\mathbf{h}}(\mathcal{T};\theta^{*})]\right]\]Using Corollary 19.35 in [19], since we have \(||\hat{J}_{\mathbf{h}}||_{L^{2}(P)}=\Gamma(\mathbf{h},A,B)<\infty\), then,

\[\begin{split}\mathbb{E}\left[\underset{f\in\mathcal{F}_{\delta}}{ sup}\ \mathbb{G}_{n}(f)\right]&\leq CJ_{\parallel}(||F||_{L^{2}(P)}, \mathcal{F}_{\delta},L^{2}(P))\\ &=C||F||_{L^{2}(P)}\int_{0}^{1}\sqrt{\log N_{\parallel}(\varepsilon ||F||_{L^{2}(P)},\mathcal{F}_{\delta},L^{2}(P))}d\varepsilon\\ &\leq C\delta||\dot{m}||_{L(P)}\sqrt{r}\int_{0}^{1}\sqrt{\log(1+ \frac{4}{\varepsilon})}d\varepsilon\\ &\leq C^{\prime}\sqrt{r}\delta\Gamma(\mathbf{h},A,B),\end{split}\] (26)

where \(C\) and \(C^{\prime}\) are universal constant and \(J_{\parallel}(\cdot,\cdot,\cdot)\) is the entropy integral.

Finally, given that \(\hat{\theta}\) converges to \(\theta^{*}\) in probability, combined with Assumption 5.2 and Equation (26), using Theorem 5.52 in [19] we have, for \(\delta<CK_{\alpha}\frac{\sqrt{r}}{2^{\alpha-1}}\frac{\Gamma(\mathbf{h},A,B)}{ C_{\mathbf{h}}}\), we have,

\[\text{Pr}\left[||\hat{\theta}-\theta^{*}||\leq\left(CK_{\alpha}\frac{\Gamma( \mathbf{h},A,B)}{\delta C_{\mathbf{h}}}\sqrt{\frac{r}{n}^{-1/(\alpha-1)}} \right)\right]\geq 1-\delta,\]

where \(C\) is a universal constant and \(K_{\alpha}=\frac{2^{2\alpha}}{2^{\alpha-1}-1}\).

### Proof of Theorem 5.5

First we give a rigorous definition of \(\mathcal{H}\),

\[\begin{split}\mathcal{H}:=&\left\{\mathbf{h}( \mathcal{T})\mid\mathbf{h}:\mathbb{R}_{+}^{N_{T}}\rightarrow\mathbb{R}_{+}^{N_ {T}},\ h_{n}(\mathcal{T})=h_{n}(t_{n},\ldots,t_{1}),h_{n}(\mathcal{T})|_{t_{n} =t_{n-1}}=h_{n}(\mathcal{T})|_{t_{n}=T}=0\\ &|h_{n}(t_{n}^{1},t_{1},\ldots,t_{n-1})-h_{n}(t_{n}^{2},t_{1}, \ldots,t_{n-1})|\leq|t_{n}^{1}-t_{n}^{2}|,\forall n,t_{n}^{1},t_{n}^{2}\right\}. \end{split}\] (27)

In other words, \(\mathcal{H}\) contains functions whose component function \(h_{n}\) is \(1\)-Lipschitz continuous w.r.t. its last dimension \(t_{n}\). It's easy to verify \(\mathbf{h}^{0}\in\mathcal{H}\).

Proof.: First we prove that,

\[\underset{\mathbf{h}\in\mathcal{H}}{max}\ \mathcal{L}_{\mathbf{h}}(\theta)= \mathcal{L}_{\mathbf{h}^{0}}(\theta)\] (28)

Notice that,

\[\mathcal{L}_{\mathbf{h}}(\theta)=\frac{1}{2}\mathbb{E}_{p(\mathcal{T})}\left[ \sum_{n=1}^{N_{T}}(\psi(t_{n}|\mathcal{F}_{t_{n-1}})-\psi_{\theta}(t_{n}| \mathcal{F}_{t_{n-1}}))^{2}h_{n}(\mathcal{T})\right]\]

Notice that, in \(\mathcal{H}\), for any \(z=t-n-1\) or \(z=T\),

\[|h_{n}(\mathcal{T})|=|h_{n}(t_{n},\ldots,t_{1})|=|h_{n}(t_{n},\ldots,t_{1})-h _{n}(z,\ldots,t_{1})|\leq|t_{n}^{1}-z|=h_{n}^{0}(\mathcal{T})\]

Therefore,

\[\mathcal{L}_{\mathbf{h}}(\theta)\leq\frac{1}{2}\mathbb{E}_{p(\mathcal{T})} \left[\sum_{n=1}^{N_{T}}(\psi(t_{n}|\mathcal{F}_{t_{n-1}})-\psi_{\theta}(t_{n}| \mathcal{F}_{t_{n-1}}))^{2}h_{n}^{0}(\mathcal{T})\right]=\mathcal{L}_{\mathbf{ h}^{0}}(\theta),\forall\mathbf{h}\in\mathcal{H}\]

and equation 28 is proved.

Finally, we have,

\[\begin{split}&\inf_{\theta:||\theta-\theta^{*}||\geq\delta} \mathcal{J}_{\mathbf{h}^{0}}(\theta)-\mathcal{J}_{\mathbf{h}^{0}}(\theta^{*})\\ =&\inf_{\theta:||\theta-\theta^{*}||\geq\delta} \mathcal{L}_{\mathbf{h}^{0}}(\theta)-\mathcal{L}_{\mathbf{h}^{0}}(\theta^{*}) \\ =&\inf_{\theta:||\theta-\theta^{*}||\geq\delta} \sup_{\mathbf{h}\in\mathcal{H}}[\mathcal{L}_{\mathbf{h}}(\theta)-\mathcal{L}_ {\mathbf{h}}(\theta^{*})]\\ =&\inf_{\theta:||\theta-\theta^{*}||\geq\delta} \sup_{\mathbf{h}\in\mathcal{H}}[\mathcal{J}_{\mathbf{h}}(\theta)-\mathcal{J}_ {\mathbf{h}}(\theta^{*})]\\ \geq&\sup_{h\in\mathcal{H}}\inf_{\theta:||\theta- \theta^{*}||\geq\delta}[\mathcal{J}_{\mathbf{h}}(\theta)-\mathcal{J}_{ \mathbf{h}}(\theta^{*})].\end{split}\]The second equality is due to Equation (28) and \(\mathcal{L}_{\mathbf{h}}(\theta^{*})=0\). The inequality is due to max-min inequality. 

### Continued Discussion on Optimal Weight Function

Given \(\bm{h}^{0}\) maximizes \(C_{\bm{h}}\), it is still unclear whether it is still preferable considering \(\Gamma(\mathbf{h},A,B)\). This is indeed a tough question that we do not yet have a satisfying answer. For specific parametric models, \(\hat{A}_{n}(\mathcal{T}),\hat{B}_{n}(\mathcal{T})\) can be computed analytically (see line 478-480) and then \(\Gamma(\mathbf{h},A,B)\) can be computed via Monte Carlo. Then we can study how sensitive \(\Gamma(\mathbf{h},A,B)\) is to \(\mathbf{h}\). For general models, especially when \(\psi_{\theta}\) is a deep neural network like THP or SAHP, \(\Gamma(\mathbf{h},A,B)\) is intractable to compute.

However, heuristically speaking, our choice of near-optimal weight function \(\mathbf{h^{0}}\) should be a good choice even concerning \(\Gamma(\mathbf{h},A,B)\). To make \(\Gamma(\mathbf{h},A,B)\) small, a natural idea is to make \(|h_{n}(\mathcal{T})|\) and \(|\frac{\partial}{\partial t_{n}}h_{n}(\mathcal{T})|\) small. The weight function we chose and its derivative have relatively positive low powers with respect to \(t_{n}\), therefore making \(|h_{n}^{0}(\mathcal{T})|\) and \(|\frac{\partial}{\partial t_{n}}h_{n}^{0}(\mathcal{T})|\) small. For weight functions \(h_{n}^{1}(\mathcal{T})=(T-t_{n})(t_{n}-t_{n-1})\), the power w.r.t. \(t_{n}\) is two. And for \(h_{n}^{2}(\mathcal{T})=\sqrt{(T-t_{n})(t_{n}-t_{n-1})}\), its derivative is \(\frac{\partial}{\partial t_{n}}h_{n}^{2}(\mathcal{T})=\frac{T-t_{n}-(t_{n}-t_ {n-1})}{\sqrt{(T-t_{n})(t_{n}-t_{n-1})}}\), the numerator is usually a bounded quantity and the denominator may be close to zero, making its derivative large. In conclusion, \(\mathbf{h^{0}}\) is a better choice compared with \(\mathbf{h^{1}}\) or \(\mathbf{h^{2}}\) concerning \(\Gamma(\mathbf{h},A,B)\).

### Discussion on Poisson Process

For Poisson process, results in Section 5 also holds, including the consistency and the convergence rate. For the choice of weight function, a reasonable choice is still the distance function presented below.

Consider a Poisson process, since the support of \(\mathcal{T}\) is \(V=\{\mathcal{T}\in N^{T},0\leq t_{1}\leq\ldots\leq t_{N_{T}}\leq T\}\). Define \(A\in\mathbb{R}^{(N_{T}+1)\times N_{T}}\) to be a coefficient matrix used below as,

\[A=\begin{bmatrix}-1&0&0&\ldots&0\\ 1&-1&0&\ldots&0\\ 0&1&-1&\ldots&0\\ \vdots&\vdots&\vdots&\ddots&0\\ 0&0&0&1&-1\\ 0&0&0&0&1\end{bmatrix}.\]

Denote \(\mathbf{a}_{n}\in\mathbb{R}^{N_{t}}\) as the \(n\)-th row vector of \(A\). Let \(b_{n}=0,n\in[N_{T}],b_{N_{T}+1}=-T\). Then \(V\) is a convex Polytope which can be rewritten as,

\[V=\{\mathcal{T}\in\mathbb{R}^{N_{T}}|\langle\mathbf{a}_{n},\mathcal{T}\rangle +b_{n}\leq 0,n=1,2,\ldots,N_{T}+1\}.\]

Therefore, the distance between \(\mathcal{T}\) and \(\partial V\) is,

\[dist(\mathcal{T},\partial V)=\min_{\mathbf{z}}\{\|\mathcal{T}-\mathbf{z}\| |\max_{n\in[N_{T}+1]}[\langle\mathbf{a}_{n},\mathbf{z}\rangle+b_{n}]=0\}= \min_{n\in[N_{T}+1]}\frac{|\langle\mathbf{a}_{n},\mathbf{z}\rangle+b_{n}|}{\| \mathbf{a}_{n}\|}.\] (29)

Let \(h_{n}^{0}(\mathcal{T})=dist(\mathcal{T},\partial V),\mathbf{h}^{0}(\mathcal{T })=(h_{n}^{0}(\mathcal{T}),h_{n}^{0}(\mathcal{T}),\ldots,h_{n}^{0}(\mathcal{T }))^{T}\). Again, \(\mathbf{h}^{0}(\mathcal{T})\) is only weak derivative. The envelope theorem in [14] yields,

\[\nabla_{\mathcal{T}}\mathbf{h}^{0}(\mathcal{T})=-\frac{\mathbf{a}_{n^{*}}}{\| \mathbf{a}_{n^{*}}\|},\]

wehre \(n^{*}\) is the is the minimizer of the last minimization in Equation (29).

Similar arguments as in Section 5.3 also applies to Poisson process, with the distance weight function defined above. Such a weight function also maximizes the denominator for the convergence rate of the Poisson process. However, in the experiment, we addops another weight function for easier implementation defined as \(\mathbf{h}^{1}(\mathcal{T})\) with its \(n\)-th component \(h_{n}^{1}(\mathcal{T})=(T-t_{n})(t_{n}-t_{n-1})\).

## Appendix D Additional Experimental Details

In this section, we present some experimental details. First we discuss our modification to the original AWSM for when \(T\) for a dataset is not accessible. Then we provide addtional estimation results for the parametric model and hyperparameters for results in Table 2.

### Weight for Equal Length Sequences

In this paper, we consider the setting of the temporal point process in a fixed time interval \([0,T]\) consistently. Technically speaking, this poses extra difficulty since the dimension(number of events) would also be random. Therefore, the realized point processes should have a random length in this setting, which is the case for our dataset. However, in real data collection, different sequences may be sampled from different lengths of time interval lengths, and our proposed weight may fail under such a case, resulting in inconsistent estimation. In such a case, we propose to truncate the sequences to be of same length, and introduce the weight function for fixed-length temporal point processes.

We focus on AWSM for Hawkes process. A fixed \(N\)-length Hawkes process could be considered as a \(N\) dimensional random variable with density function as,

\[p(t_{1},\ldots,t_{N})=\prod_{n=1}^{N}\lambda^{*}(t_{n})\int_{0}^{t_{N}}\lambda ^{*}(t)dt.\]

Since the number of observations is fixed, we could simply treat it as an \(N\) dimensional random variable and perform autoregressive weighted score matching. The valid weight function in this case should satisfy \(h_{n}(\mathcal{T})|_{t_{n}=t_{n-1}}=h_{n}(\mathcal{T})|_{t_{n}=t_{n+1}}=0\). Similar nonasymptotic bounds could be derived here and a near optimal weight function would be the Euclidean distance between \(t_{n}\) and the boundary of \(t_{n}\)'s support, which would be \(\{t_{n-1},t_{n+1}\}\). Therefore, the near-optimal weight function would be \(h_{n}^{0}(\mathcal{T})=\min\{t_{n}-t_{n-1},t_{n+1}-t_{n}\}\).

During experiments, when \(T\) is unknown and cannot be approximated well, we perform a data truncation for each batch. We naively drop all timestamps beyond the length of the shortest sequence to make length consistent within a batch. Then we perform an AWSM for the fixed-length Hawkes process. We specify the results with this modification when we show our hyperparameters.

### Additional Results and Hyperparameters

For parametric models, Table 3 provide the estimation results for some parameters and Figure 3 shows the learned intensity functions on the 2-nd dimension for the 2-variate Hawkes processes.

For deep point process experiments, we run 4 datasets with 3 methods deployed on 2 models. We show the hyperparameters of those experiments in Table 4. **Epochs** column represents the number

\begin{table}
\begin{tabular}{l|c c|c c|c c|c c|c c} \hline \hline \multirow{2}{*}{Dataset} & \multicolumn{2}{c}{Epochs} & \multicolumn{2}{c}{\(\alpha_{\text{AWSM}}\)} & \multicolumn{2}{c}{Trunc} & \multicolumn{2}{c}{\(\alpha_{\text{DSM}}\)} & \multicolumn{2}{c}{\(\sigma_{\text{DSM}}\)} \\ \cline{2-11}  & SAHP & THP & SAHP & THP & SAHP & THP & SAHP & THP & SAHP & THP \\ \hline Half-Sin & \(100\) & \(100\) & \(20\) & \(20\) & F & F & \(20\) & \(10\) & \(0.01\) & \(0.01\) \\ STACKOVERFLOW & \(100\) & \(500\) & \(20\) & \(20\) & T & F & \(10\) & \(10\) & \(0.1\) & \(0.1\) \\ TAOBAD & \(500\) & \(300\) & \(50\) & \(20\) & T & T & \(20\) & \(20\) & \(0.01\) & \(5\)e-3 \\ RETweETS & \(100\) & \(100\) & \(20\) & \(10\) & F & F & \(2000\) & \(10\) & \(0.01\) & \(5\)e-4 \\ \hline \hline \end{tabular}
\end{table}
Table 4: The hyperparameters for experiments in Table 2.

\begin{table}
\begin{tabular}{c|c c c|c c c} \hline \hline \multirow{2}{*}{Estimator} & \multicolumn{3}{c|}{Exp-Hawkes} & \multicolumn{3}{c}{Gaussian-Hawkes} \\ \cline{2-7}  & \(\alpha_{21}\) & \(\alpha_{22}\) & \(\mu_{2}\) & \(\alpha_{12}\) & \(\alpha_{21}\) & \(\alpha_{22}\) & \(\mu_{2}\) \\ \hline (A)WSM & \(\mathbf{0.052\pm 0.054}\) & \(\mathbf{0.022\pm 0.005}\) & \(\mathbf{0.011\pm 0.012}\) & \(0.037\pm 0.043\) & \(0.082\pm 0.080\) & \(0.012\pm 0.010\) & \(0.060\pm 0.006\) \\ \hline (A)SM & \(0.769\pm 0.001\) & \(0.769\pm 0.001\) & \(0.680\pm 0.279\) & \(0.126\pm 0.108\) & \(0.971\pm 0.00\) & \(0.717\pm 2.85\) & \(2.507\pm 1.957\) \\ \hline MLE & \(0.065\pm 0.032\) & \(0.034\pm 0.015\) & \(\mathbf{0.014\pm 0.002}\) & \(\mathbf{0.025\pm 0.032}\) & \(\mathbf{0.045\pm 0.041}\) & \(\mathbf{0.006\pm 1.06}\) & \(\mathbf{0.051\pm 0.049}\) \\ \hline \hline \end{tabular}
\end{table}
Table 3: The MAE of 2-variate Hawkes processes trained by MLE, (A)SM, and (A)WSM on the synthetic dataset.

of epochs for the experiments of a model (THP or SAHP) on a dataset. We train same epochs for three training methods (MLE, AWSM or DSM) and validate every 10 epochs to report the best result. When training MLE, the hyperparameter is the number of integral nodes, which is always 10 for all experiments. When training AWSM, we have two hyperparameters, the value of balancing coefficient for CE loss, shown in column \(\alpha_{\text{AWSM}}\) and whether data truncation is performed as shown in column **Trunc**. T represents performing data truncation and F represents no data truncation. For DSM, the hyperparameters are balancing coefficient denoted as \(\alpha_{\text{DSM}}\) and variance of noise denoted as \(\sigma_{\text{DSM}}\).

Figure 3: The learned intensity functions from MLE, (A)SM, and (A)WSM on (a) Exp-Hawkes and (b) Gaussian-Hawkes for the 2-nd dimension.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Please refer to abstract and introduction of this paper, where we list main contributions verified in following theory and experiments. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discuss the limitation of our proposed method in the Limitations section. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: We provide comprehensive proof in the appendix. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We disclose all the information needed to reproduce the main experimental results. Please refer to the Experiments section. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: The code and data is attached in the supplemental material. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: The brief instruction of train/test, hyperparameters, and the related training details are provided in the Experiments section. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: All experimental results reported in the tables includes the mean and standard deviation for multiple runs. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors).

* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: We list the necessary information about computer resource in the Experiments section. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We have received NeurIPS Code of Ethics and conform with it in every respect. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [No] Justification: This paper presents work whose goal is to advance the field of machine learning. There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We cite the original paper about assets, such as dataset, baseline and so on. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [Yes] Justification: Please refer to supplementation material, where we provide the details of code. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.