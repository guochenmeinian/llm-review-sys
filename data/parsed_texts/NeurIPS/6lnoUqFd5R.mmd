# Learning the Efficient Frontier

Philippe Chatigny

Riskfuel

Toronto

pc@riskfuel.com

&Ivan Sergienko

Beacon Platform

New York

ivan.sergienko@beacon.io

&Ryan Ferguson

Riskfuel

Toronto

rf@riskfuel.com

&Jordan Weir

Riskfuel

Toronto

jw@riskfuel.com

&Maxime Bergeron

Riskfuel

Toronto

mb@riskfuel.com

Corresponding authorContribution was made when working at Riskfuel

###### Abstract

The efficient frontier (EF) is a fundamental resource allocation problem where one has to find an optimal portfolio maximizing a reward at a given level of risk. This optimal solution is traditionally found by solving a convex optimization problem. In this paper, we introduce NeuralEF: a fast neural approximation framework that robustly forecasts the result of the EF convex optimization problem with respect to heterogeneous linear constraints and variable number of optimization inputs. By reformulating an optimization problem as a sequence to sequence problem, we show that NeuralEF is a viable solution to accelerate large-scale simulation while handling discontinuous behavior.

## 1 Introduction

Making the least risky decision to maximize a cumulative reward over time is a central problem in machine learning and at the core of resource allocation optimization problems [26]. In modern portfolio theory [16], this problem is commonly referred to as the efficient frontier (EF) [36]. It involves distributing resources among \(n\) risky assets to maximize return on investment while respecting various constraints. These constraints (e.g., maximum allocation allowable for an asset) are set to prevent aggressive or unrealistic allocations in practice. Finding the optimal solution to this optimization problem given the expected risk and return of each asset under a set of constraints can be done by solving a convex optimization problem of quadratic programs (QP) and second-order cone programs (SOCP). Although a single optimization problem is not time-consuming to solve, its current computational cost remains the most significant bottleneck when performing the simulations necessary for financial applications [22, 7].

Indeed, inputs to the EF problem such as future expectations of asset returns, co-variances, and even simulated client preferences on asset allocation are stochastic (c.f. Table 1). Thus, one needs to repeatedly solve the optimal allocation problem under a large number of different scenarios and Monte Carlo (MC) simulations [39] are commonly used to estimate the expected reward over time. Given an allocation function \(g\) and stochastic input \(Z\), we need to compute \(\mathbb{E}(g(Z))=\int g(z)f_{Z}(z)\,dz\) where \(f_{Z}\) is the density function of \(Z\). Sampling the empiric mean of \(g(Z)\) approximates \(\mathbb{E}(g(Z))\) with a convergence rate of \(\mathcal{O}(1/\sqrt{N})\) where \(N\) denotesthe number of samples. The computational cost of this simulation is therefore influenced by the size of \(N\) and the cost of computing \(g\). In spite of the vast literature of variance reduction techniques [5; 17] and the use of low-discrepancy sampling methods [10; 21] that aim to reduce \(N\), the results of the simulation will be misleading if the assumptions are not valid, leaving the cost of running \(g(z)\) as the principal bottleneck. This makes it practically impossible to run multiple MC simulations on different candidate assumptions in real time unless significant computational resources are available. Applications that heavily depend on MC simulations of the EF problem like basket option derivatives pricing face this bottleneck because their valuation depends on accurate estimates of the expected returns \(\mathbb{E}(R)\), portfolio volatility \(\mathbb{E}(V)\) and/or allocations \(\mathbb{E}(X)\). The roll-out of new regulatory frameworks for financial applications of the EF problem (e.g. portfolio management) requiring more rigorous testing of \(\mathbb{E}(g(Z))\) further increases the minimal acceptable \(N\), exacerbating the need for speed [37; 3].

The core problem then becomes finding a way reduce the computational cost of \(g\), making it possible to run a large number of MC simulations in a few seconds [27; 25]. Accelerating the optimization on highly-parallel hardware like graphical processing units (GPUs) can accelerate some convex optimization problems [13; 44; 11; 12], but not enough to run MC simulation in real-time effectively. Instead of only exploiting hardware, others have proposed to approximate the optimization step using deep neural networks (DNNs) and infer the result directly [18; 28; 48; 19]. However, proposed approaches fall short since they fail to simultaneously satisfy the following key requirements: (**1**) they do not provide theoretical guarantees that their forecast is within the domain set by constraints, (**2**) they do not show that their results can be applied at large scale faster than the optimization itself, (**3**) they can't handle a variable amount of heterogeneous inequality constraints and optimization inputs, and, (**4**) they are not robust to discontinuous behavior of optimization problems.

This work addresses all the shortcoming of DNN-based approaches mentioned above. We propose NeuralEF, a DNN-based model to approximate the computation of the EF problem robustly. Our model is up to 615X times faster than the baseline convex optimization when used with hardware acceleration. It is able to handle a variable number of assets and inequality constraints with consistent accuracy. In particular, we introduce a dynamic greedy allocation module to respect the constraints robustly that is agnostic to the DNN architecture. The remainder of this paper is organized as follows. Section 2 describes the EF problem and presents related works on convex optimization acceleration. Section 3 introduces NeuralEF and its training methodology. Section 4 outlines our empirical evaluations on the EF optimization problem. Finally, section 5 presents our conclusions.

## 2 Background and Related Work

### The Efficient Frontier

We seek an optimal allocation \(\bm{x}=[x_{1},\cdots x_{n}]\) over \(n\)_risky_ assets given a soft volatility target \(\mathcal{V}_{\text{target}}\). This means a portfolio with higher achieved volatility than \(\mathcal{V}_{\text{target}}\) is valid only if the resulting allocation has the minimum volatility that can be achieved on the feasible domain. Finding the optimal allocation maximizing portfolio return at a given volatility target is conditional on the assets' expected returns \(\bm{R}=[r_{1},\cdots,r_{n}]\), volatilities \(\bm{V}=[v_{1},\cdots,v_{n}]\), and correlations \(\bm{P}=[[\rho_{1,1},\cdots,\rho_{1,n}],\cdots,[\rho_{n,1},\cdots\rho_{n,n}]]\). Constraints that must be satisfied include upper and lower bounds on total allocation of _risky_ assets \(\alpha_{\text{max}},\alpha_{\text{min}}\)

Figure 1: Illustration of the EF problem. The optimal allocations are at the frontier of the plot where the expected returns is maximized for a level of volatility. The yellow dot denotes the best allocation for eq. 2 for \(\mathcal{V}_{\text{target}}=0.06\). The location of the yellow dot will vary under different conditions, which can be approximated under different scenarios (\(Z\)) using MC simulations.

and a minimum and maximum asset allocation limit per asset \(\bm{X}_{\textsc{mix}}=[x_{1}^{\textsc{mix}},\cdots,x_{n}^{\textsc{mix}}]\), \(\bm{X}_{\textsc{max}}=[x_{1}^{\textsc{max}},\cdots,x_{n}^{\textsc{max}}]\). As is typical in finance, assets can belong to a set of \(m\) classes \(\bm{C}=[c_{1},\cdots,c_{n}];c_{i}\in[1,\cdots,m]\), and allocations are subject to a class maximum \(\bm{\zeta}_{\textsc{max}}=[\zeta_{c_{1}},\cdots\zeta_{c_{m}}];\sum_{x\in c_{ j}}x_{i}\leq\zeta_{c_{j}}\). We denote the set of convex optimization inputs by \(\bm{Z}_{\text{input}}=[\bm{R},\bm{V},\bm{P},\bm{X}_{\textsc{max}},\bm{X}_{ \textsc{mix}},\bm{C},\bm{\zeta}_{\textsc{max}},\alpha_{\textsc{mix}},\alpha_{ \textsc{mix}},\alpha_{\textsc{max}},\mathcal{V}_{\text{target}}]\) and the resulting allocation by \(\bm{Z}_{\text{output}}=\text{EF}(\bm{Z}_{\text{input}})\).

This problem is illustrated in fig. 1 using random allocations where the EF is located at the left-most frontier of the plots. We can find this frontier along a range of volatility targets by solving a two-step conditional convex optimization problem where we first find the optimal weights that minimizes risk in a portfolio of \(n\) assets subject to linear weight constraints and then maximize the return if the risk of the portfolio is below \(\mathcal{V}_{\text{target}}\).

Finding this minimum variance portfolio is equivalent to solving a QP problem of the form

\[\bm{\psi}:=\text{minimize }\frac{1}{2}\bm{x}^{\top}\bm{Q}\bm{x}\text{ subject to }\bm{a}_{i}^{\top}\leq\bm{b}_{i}\;\;\forall i\in 1, \cdots,w,\] (1)

where \(\bm{x}\in\mathbb{R}^{n}\) is a column vector of weights representing the allocation, \(\bm{Q}\) is the covariance matrix of the portfolio's assets, \(\bm{a}_{i}\) is a row vector representing the \(i\)-th linear constraint (obtained from \(\alpha_{\textsc{mix}},\alpha_{\textsc{max}},\bm{X}_{\textsc{max}},\bm{X}_{ \textsc{min}},\bm{\zeta}_{\textsc{max}}\)) and \(\bm{b}_{i}\) is the maximum required value for the \(i\)-th constraint. The result of eq. 1 allows us to calculate the minimum volatility \(\mathcal{V}_{\text{min}}=\bm{x}^{\top}\bm{Q}\bm{x}\) that can be achieved on the feasible domain.

If the resulting portfolio risk \(\mathcal{V}_{\text{min}}<\mathcal{V}_{\text{target}}\), then we can afford to maximize portfolio return. In this case, the objective function of the first problem becomes one of the constraints of a SOCP problem of the form

\[\bm{\phi}:=\text{minimize }-\bm{R}^{\top}\bm{x}\text{ subject to }\frac{1}{2}\bm{x}^{\top}\bm{Q}\bm{x}\leq \mathcal{V}_{\text{target}}\text{ and }\bm{a}_{i}^{\top}\leq\bm{b}_{i}\forall i\in 1, \cdots,w.\] (2)

Thus, the efficient frontier can be summarized by

\[\bm{Z}_{\text{output}}=\text{EF}(\bm{Z}_{\text{input}})=\bm{\psi}\text{ if }\mathcal{V}_{\text{min}}>\mathcal{V}_{\text{target}}\text{ else }\bm{\phi}.\] (3)

The EF optimization is sensitive at inflection points where one asset becomes more attractive than another. All else held equal, an infinitesimal difference in expected returns can cause a jump in optimal allocation for all assets. Modeling the EF problem is challenging due to the presence of such discontinuities, which grows factorially (\(\mathcal{O}(N!)\)) as the number of assets increases.

### Accelerating Convex Optimizations

The simplest way to speed up eq. 3 is to implement the solver for direct use with highly parallelizable hardware. This has been done using GPUs for various convex optimizations, particularly for large problems with numerous unknowns [13, 44, 12]. In particular, [11] showed that solving numerous optimizations simultaneously in a single batch leads to significant speedup. We replicated this experiment by writing a vectorized implementation of the optimization of eq. 3 in Pytorch to solve multiple EF problems at once. We observed accelerations which are consistent with the order of magnitude achieved in these works, but not sufficient to allow the completion of a full simulation in a matter of few seconds unless the GPU used has high memory capacity (e.g. 40 GB).

Several works [4, 1, 20] embed differentiable optimization problems in DNNs, offering a solution to robustly approximate the EF problem including the handling of the inequality constraints in eq. 1 and eq. 2. Their approaches aim to solve a parameterized optimization problem ensuring a constrained layer's output to align with homogeneous linear inequality constraints established by \(\bm{Z}_{\text{input}}\). This is done either by solving the optimization problem during training [4, 1], or when initializating the model [20]. To support a heterogenous set of constraints, one would need to specify a set of linear inequality constraints ahead of time. This approach is impractical as it cannot generalize to unspecified sets of constraints.

Other existing supervised learning (SL) approaches to approximate convex optimization with DNNs do not provide the desired flexibility and robustness for large-scale generalization [48, 2, 18, 28]. They use a DNN that takes \(\bm{Z}_{\text{input}}\) as input and outputs \(\bm{Z}_{\text{output}}\), treating inequality constraints as soft during training. Reinforcement learning (RL) approaches like POMO [31] and PPO [35] have also been applied variable length input combinatorial optimization problems with high label retrieval complexity where their learned policy tries to reduce an optimally gap by measuring the regrets from the optimal allocation. These DNN approaches do not guarantee that predicted values remain within the feasible domain and are often unable to handle the changing dimensionality of \(\bm{Z}_{\text{input}}\) and \(\bm{Z}_{\text{output}}\) based on \(n\) and the set of constraints selected. Our proposed method addresses these issues, resulting in a fast and accurate approximation of the convex optimizer that respects constraints.

## 3 Neural Approximation of the Efficient Frontier

To approximate the computation of the QP and conditional SOCP optimization described in sec. 2.1, we use a stacked transformer encoder architecture [46, 29] as shown in fig. 2. The principal idea behind NeuralEF is to consider the optimization problem as a sequence-to-sequence (SEQ2SEQ) problem [45] and use the self attention mechanism to consider the relationships between the optimization inputs when approximating eq. 3. Contrary to large language models (LLMs) that solve quantitative mathematical problem by parsing the problem using a mix of natural language and mathematical notation where a forecast is built using the same notation [33, 15], our SEQ2SEQ formulation explicitly parse the whole optimization problem by considering the optimization input directly and forecasts the output in the solution domain. We setup the SEQ2SEQ problem such that the inputs are a set of tokens, each representing a single asset, and the outputs are a one dimensional sequence of the optimal allocation. To convert the optimization problem in eq. 3 to a sequence representation, we divide the optimization input parameters in two types of features: global optimization inputs (\(\bm{P},\bm{\zeta}_{\text{\tiny MAX}},\alpha_{\text{\tiny MIN}},\alpha_{\text{ \tiny MAX}},\,\mathcal{V}_{\text{target}}\)) and asset specific inputs (\(\bm{R},\bm{V},\bm{\Upsilon}_{\text{\tiny MAX}},\bm{X}_{\text{\tiny MIN}},\bm {C}\)). These features along with a sequence of asset identifier (\(n\) values evenly spaced within \([0,1]\)) are used to rearrange the optimization input parameters into a set of vectors and are linearly projected into higher dimensional

Figure 3: Illustration with two assets of the domain output space that the dynamic greedy allocation rebalancing module will enforce. The output domain is highlighted by the cross hatch patterns and the constraints are highlighted by the red lines.

Figure 2: Illustration of the Transformer Encoder architecture of NeuralEF. On the left side the projection to a sequence representation from the optimization inputs considering 3 assets is shown as an example.

[MISSING_PAGE_FAIL:5]

We generated two test datasets \(\mathcal{D}_{\text{test}}\), \(\mathcal{D}_{\text{validation}}\) of 1 million samples each on the the same domain as the training set described in table 1. All synthetic datasets mimic real-life distributions for the volatility and correlation inputs, encompassing area of the optimization domain around the discontinuity areas. Around 84% of the test samples feature at least two optimization inputs within \(\epsilon\) proximity of each other to target discontinuity areas of eq. 3. This synthetic data allows for precise control over optimization inputs and encompasses a broad spectrum of scenarios, ranging from extreme to real-world cases targeting mainly the discontinuity regions. Consequently, it facilitates a comprehensive evaluation of the model's performance across various settings. All datasets have varying numbers of assets and asset classes, and include two allocation scenarios: full allocation (\(\alpha_{\text{MAX}}=\alpha_{\text{MIN}}=1\)) and partial allocation (\(\alpha_{\text{MAX}}>\alpha_{\text{MIN}}\)) where there is no obligation to allocate the full budget. Only valid optimization inputs \(\bm{Z}_{\text{input}}\), i.e. where \(\text{EF}(\bm{Z}_{\text{input}})\) does not fail because of numerical difficulties in the solver or that no solution exists, where considered.

NeuralEF is a 7.9M parameter DNN and was trained on a single NVIDIA A100 GPU with stochastic gradient descent using the AdamW optimizer [34] and the \(L^{2}\) loss. We also used an annealing learning rate decay starting from \(5.5e^{-5}\) to \(1.0e^{-6}\). As stated in sec. 2, we also implemented a baseline EF optimization in PyTorch that we used solely for comparing the evaluation throughput (evaluations/seconds) between NeuralEF over the base pricer which was implemented using CVXOPT [14]. The hyperparameters of NeuralEF are described in table. 2 and were selected by estimated guesses from the accuracy measured on \(\mathcal{D}_{\text{validation}}\).

### In-domain Interpolation

\begin{table}
\begin{tabular}{l r|l r} \hline \hline
**Feature** & **Range** & **Feature** & **Range** \\ \hline (\(\mathcal{V}_{\text{target}}\)) volatility target & \([0.05,0.15]\) & (\(\bm{V}\)) volatility & \([0,2]\) \\ (\(\bm{P}\)) Correlation matrix & [-1, 1] & (\(\bm{R}\)) returns & [-1,2] \\ (\(\bm{\zeta}_{\text{MAX}}\)) maximum class allocation & [ 0.2, 1.0] & (\(wt_{\text{MAX}}\)) maximum asset allocations & [0.01, 1.0] \\ (\(\alpha_{\text{MIN}}\)) Allocation lower bound & [0.6, 1.0] & (\(\alpha_{\text{MAX}}\)) Allocation upper bound & 1.0 \\ (\(n\)) Number of asset sampled & [2,12] & (\(m\)) Possible class & [0,1,2] \\ \hline \hline \end{tabular}
\end{table}
Table 1: Input Domain of optimization input used for training.

\begin{table}
\begin{tabular}{l r|l r} \hline \hline
**Name** & **Value** & **Name** & **Value** \\ \hline Token dimension & 320 & (D) Transformer depth & 8 \\ Transformer \# heads & 8 & Transformer heads dimension & 32 \\ Feed forward projection & 1024 & Output activation & Sigmoid \\ Embedding method & [30, 24] & Hidden activation & Swish [42] \\ \hline \hline \end{tabular}
\end{table}
Table 2: HyperParameters of NeuralEF. Adjusting accuracy at the expense of throughput can be easily done by increasing the token dimension.

Figure 4: Cumulative distributions of the sum of absolute allocation error of allocations and portfolio returns per number of assets

We assess NeuralEF's accuracy by measuring its ability to predict portfolio weights, returns and volatility on \(\mathcal{D}_{\text{test}}\). We use Mean square error (MSE), mean absolute error (MAE), and quantiles to evaluate the error distribution for portfolios with varying numbers of assets. Additionally, we test NeuralEF's precision in ranking asset importance in the allocation, check the precision of our model to forecast volatility (\(\mathcal{V}_{\text{target}}=\bm{Z}_{output}^{\top}\bm{Q}\bm{Z}_{output}\leq max (\mathcal{V}_{\text{target}},\mathcal{V}_{\text{min}})\)), and check for feasibility of violating constraints. Table 3 summarizes the accuracy results for different numbers of assets considered. Overall, NeuralEF shows accurate performance on portfolio weight prediction with slight deviations only in the higher upper quantiles for all asset cases. The model also demonstrates a high level of accuracy on returns and volatility. The ability to rank assets in order of importance correlates with the ability to respect constraints not captured by DGAR. The optimality gap metrics (ranking precision, \(\bm{\zeta}_{\text{MAX}}\) and \(\mathcal{V}_{\text{target}}\)) are by design highly sensitive to a slight \(\epsilon\) deviation, which in practice wouldn't necessarily be impactful. However, this limitation is to be considered when considering NeuralEF in safety-critical scenarios. NeuralEF can easily be applied within MC simulations that targets \(\mathbb{E}(R)\), \(\mathbb{E}(V)\), and/or \(\mathbb{E}(x)\) as failure to respect the unsupported constraints does not necessarily lead to large error on the allocation. With a sufficiently large \(N\), these errors do not impact the derived distributional features of \(\mathbb{E}(g(Z))\).

We plot the error distribution per asset by displaying the cumulative distribution of the sum error for all \(x_{1},\cdots,x_{n}\), the absolute error on the expected return and the portfolio volatility in Fig. 4. The total weight allocation error does not exceed 1% total deviation in around 98% of cases, but the impact on the resulting returns and volatility is only noticeable in 1% of cases. From the remaining tail exceeding the 1% total deviation, we measured no case violating the volatility constraint and only 8% exceeded the class constraint. The source of these errors was mainly found in regions with abrupt changes in the allocation due to the nature of the optimization.

NeuralEF accurately captures the qualitative behavior of the optimization in discontinuous regions, but instability in these areas exposes a weakness of approximating function with discontinuous behavior using DNNs. We illustrate this behavior using one example from the 99.997th quantile worst predictions of \(\mathcal{D}_{\text{test}}\), where we vary a single input parameter (\(r_{10}\in[-1.0,2.0]\)) while keeping the others constant, in Fig. 5. NeuralEF approximates discontinuities for most assets accurately, and errors on the portfolio returns are often attributed to ranking failure when NeuralEF transitions through these discontinuities. At the expense of always respecting constraints, DGAR can spread forecast errors to other assets with a poor \(\mathcal{K}\) ordering leading to a larger absolute error in the resulting forecast than not using DGAR. Despite some assets not being modeled properly, we observe often that for practical purposes, this doesn't impact the resulting portfolio return or the portfolio

\begin{table}
\begin{tabular}{c|c c c c c c c} \hline \hline Asset case & Vertofolio weights & MSE & Vertofolio weights & MAE & 95 & quadratic & 99.997 quantile & Ranking precision \\ \hline
1 & 2.56-0.06 & 1.10-0.01 & 1.20-0.01 & 1.30-0.02 & 1.40-0.01 & 9.11-0.01 & 9.11-0.01 \\
2 & 2.56-0.06 & 3.57-0.06 & 1.50-0.02 & 1.30-0.02 & 1.30-0.01 & 9.96-0.01 \\
3 & 8.80-0.07 & 6.00-0.01 & 1.46-0.02 & 4.75-0.02 & 1.30-0.01 & 9.42-1.7 \\
4 & 2.56-0.06 & 1.38-0.01 & 1.40-0.02 & 4.56-0.02 & 1.50-0.01 & 9.56-1.57 \\
5 & 1.56-0.02 & 1.20-0.01 & 1.46-0.02 & 4.18-0.01 & 1.50-0.01 & 9.56-0.02 \\
6 & 1.56-0.02 & 1.20-0.01 & 1.46-0.02 & 4.48-0.02 & 1.50-0.01 & 9.56-0.02 \\
7 & 1.56-0.02 & 1.20-0.01 & 1.46-0.02 & 4.48-0.02 & 1.50-0.01 & 9.56-0.01 \\
8 & 1.56-0.02 & 1.20-0.01 & 1.46-0.02 & 4.48-0.02 & 1.50-0.01 & 9.56-0.01 \\
9 & 1.56-0.02 & 1.20-0.01 & 1.46-0.02 & 4.77-0.02 & 1.50-0.01 & 84.56-0.02 \\
10 & 1.17-0.02 & 1.20-0.02 & 5.20-0.02 & 5.20-0.01 & 1.10-0.01 & 3.51-0.01 \\
11 & 1.21-0.01 & 1.70-0.02 & 1.20-0.02 & 5.34-0.02 & 2.30-0.01 & 80.00-0.03 \\
12 & 1.66-0.08 & 1.00-0.01 & 1.36-0.02 & 4.30-0.02 & 1.40-0.01 & 7.56-0.01 \\ \hline \hline \multicolumn{10}{c}{Periods return MAE} & \multicolumn{1}{c}{**Vertofolio weights MAE**} & \multicolumn{1}{c}{**Spearto 99.995 quantile**} & \multicolumn{1}{c}{**Quarto 99.997 quantile**} & \multicolumn{1}{c}{**Ranking precision**} \\ \hline
2 & 2.56-0.06 & 1.00-0.02 & 1.20-0.01 & 1.20-0.01 & 1.50-0.01 & 10.00-0.01 \\
1 & 8.56-0.06 & 2.00-0.01 & 1.20-0.01 & 1.20-0.01 & 1.20-0.01 & 9.15-0.01 \\
4 & 5.26-0.06 & 1.70-0.01 & 1.45-0.02 & 4.00-0.02 & 1.20-0.

volatility, as illustrated in fig. 6 (a-b). An ablation study motivating the different NeuralEF's components is presented in sec. C.2

### Throughput Evaluation and Carbon Footprint Impact

We report a significant acceleration in the performance of NeuralEF compared to the single-tread baseline optimizer, with a 623X time improvement on a CPU (AMD 5950X achieving 559 eval./s). The main factors contributing to this improvement are running multiple optimizations in batches, the smaller computational cost of inferring the result compared to numerically solving the optimization using an interior-point solver, and the use of half-precision floating-point format4. We demonstrate the scalability of NeuralEF on fig. 7 for

Figure 5: Illustration of the behavior NeuralEF at discontinuous points of the optimization. The unstable regions on the allocation occurs where \(r_{10}\in[0,0.5]\). All assets change allocation either smoothly through that region or suddenly by a jump discontinuity.

Figure 6: Impact of the inflection point prediction failure using the same prediction shown in fig. 5 on the estimated return and volatility respectively (a,b). EF numerical calculation throughput per concurrent process and its emissions in kgCO\({}_{2}\)e/kWh (c). Emissions presented are for computing 1000 evaluations per concurrent process and are scaled by a factor of 1e3.

Figure 7: Throughput of the vectorized EF version on GPU (left), NeuralEF in FP16-precision (middle) and NeuralEF in FP32 precision (right) by batch size compared to the single-thread and multi-thread pricer.

both GPUs and CPUs as well as the impact of the different components. The highest achieved throughput are presented on table. 4.

Parallelizing the execution on CPU through concurrent processes of the base pricer can increase throughput, but the scaling ability of this approach is inferior to NeuralEF. Fig. 7 (c) shows that the throughput scales linearly with the number of cores until the concurrent processes saturate the CPU usage and prevent further speedup. Considering the AMD 5950X CPU as an example, we achieved a maximum throughput of 10377.80 eval./sec. 5. It would take 26.77 hours to generate a billion evaluations, whereas it would only take 41 minutes or 1.25 hours with NeuralEF respectively on a A100 or on two ISR chips. When accelerated on GPU, impractical large batch sizes are needed to compete with a concurrent CPU setup. Pytorch-EF needs batches of 1.2 million request to reach a maximum throughput of 111479 eval./sec. In comparison, NeuralEF can achieves 343760 eval./sec. using batch size of 80k request. From an ease of use standpoint, the accelerated throughput of NeuralEF on a few devices is more running multiple machines to achieve the same throughput on CPU or having to deal with large batch size in practice. The scaling advantage of NeuralEF also offer an avenue to reduce the carbon footprint of large-scale simulations.

Footnote 5: CPUs of newer generations and with higher number of core are expected to perform better.

NeuralEF is less environmentally impactful than running the same optimization on CPU. For a single AMD Ryzen 9, if we consider the total time to generate our training dataset of 1 billion EF optimizations, the total simulation on CPU would approximate to 1.39 kgCO\({}_{2}\)e. Increasing the throughput by running concurrent processes increases the CO\({}_{2}\) emission on the chip as it requires more energy as show in fig. 6 (c). Training NeuralEF is more environmentally expensive due to a cumulative 336 hours of computation on a single A100 GPU with an AMD server-grade CPU server resulting in approximately 5.71 kgCO\({}_{2}\)e. At inference, the total emissions for forecasting a billion EF optimization using NeuralEF is estimated to be 0.03 kgCO\({}_{2}\)e6. Hence, we can offset the total cost of training NeuralEF by running approximately 4.20 billions evaluations. Since MC error converges as \(\mathcal{O}(1/\sqrt{N})\), one could get a 4x more precise approximation to \(\mathbb{E}(g(Z))\) with NeuralEF in the time it would takes to obtain \(N\) simulations on a single CPU. Given that the EF problem is a cornerstone

\begin{table}
\begin{tabular}{l c|l c} \hline
**A100:** & **Throughput (eval./sec.)** & **2080T:** & **Throughput (eval./sec.)** \\ Pytorch-EF & 11479.39 & Pytorch-EF & (26452.06 \\ NeuralEF (f932) & 12950.36 & NeuralEF (f912) & 3781.05 \\ NeuralEF (f916) & 34750.77 & NeuralEF (f916) & 107259.29 \\ NeuralEF (f916) clean-only & 36982.09 & NeuralEF (f916) clean-only & 114106.05 \\ NeuralEF (f916) no preprocessing & 401641.81 & NeuralEF (f916) no preprocessing & 118711.91 \\
**Intel Xeon Platinum 8480+ (ISR)** & **3090:** & **Throughput (eval./sec.)** \\ NeuralEF (f932) & 56930.39 & Pytorch-EF & 41052.53 \\ NeuralEF (f916 + AMX) & 221787.48 & NeuralEF (f912) & 77859.95 \\
**AMD 5950X (reference)** & **NeuralEF (f916) clean-only** & 167934.15 \\ single-addX & 559:15 & NeuralEF (f916) clean-only & 173388.66 \\ Concurrent processes (23) & 10377.80 & NeuralEF (f916) no preprocessing & 170650.62 \\ \hline \end{tabular}
\end{table}
Table 4: Maximum average throughput achieved. Note that two Intel Xeon Platinum 8480 CPUs were used simultaneously on a dual-socket machine to achieve the best throughput.

Figure 8: Scalability of DGAR throughput by number of assets and batch size.

of multiple applications in finance, 4.20 billions evaluations is easily offset in less than a week by a single organization.

### Out-of-domain Generalization

The generalization ability of our model was measured by testing it on a larger input domain on a new dataset \(\mathcal{D}_{\text{ood}}\) of 1 million samples using the same domain as in \(\mathcal{D}_{\text{test}}\), but instead considering \(\mathcal{V}_{\text{target}}\in[0.01,0.3]\), \(\bm{R}\in[0,4]\), \(\alpha_{\text{MIN}}\in[0.2,1.0]\). The accuracy of the model degrades significantly on the tail of the distribution, especially for larger asset cases, indicating that it is not recommended to use NeuralEF outside the training domain. However, scale invariance in eq. 3 when all returns have the same sign (e.g., \(\bm{R}=[0.3,0.4,0.5]\approx[3.3,3.4,3.5]\)), allows the model to accurately estimate optimization even with returns outside the training domain by rescaling \(\bm{R}\) by \(\lambda\) such that they fit within the training domain. One can revert to the base optimization in the rare cases that it goes out of the domain, e.g. where assets go above 200% returns or the 200% volatilities, both being highly unlikely cases. Otherwise, one can always train NeuralEF on a bigger domain than table. 1 with most likely more data. Because NeuralEF has been trained on synthetic data, we haven't observed behavior bias that arises directly from certain regime aside in cases where assets would oscillate in the inflection area of the optimization, i.e. when two "attractive" assets have returns/volatilities \(\epsilon\) close to each other and/or near 0 across a prolonged period of time.

## 5 Conclusion and Broader Impacts

In this work we introduce NeuralEF, a fast DNN-based model that approximates the solution of a convex optimization problem by treating it as a SEQ2SEQ problem. Using the Efficient Frontier, a highly discontinuous resource allocation problem, we demonstrate NeuralEF's accuracy and its ability to handle variable-length input optimization parameters while robustly respecting linear constraints by means of a novel dynamic greedy allocation rebalancing module. This positions NeuralEF as an attractive solution to reduce the computational footprint of running large scale simulations and offers a practical means to accelerate convex optimization problems in application that rely on MC simulation such as securities pricing, portfolio management and valuation of unit-linked insurance policies [6, 38].

More importantly, our reformulation of convex optimization as SEQ2SEQ offers a tangible step towards solving quantitative mathematical problems efficiently with DNNs [33, 15]. Whether it is easier to expedite optimization problems with heterogeneous constraints though a RL training paradigm [31, 35] or a SL paradigm like done with NeuralEF hinges on additional experimental insights. However, we know that current LLMs struggle to solve hard mathematical tasks [33] and simply scaling them is impractical for achieving strong mathematical reasoning [23]. Converting a quantitative mathematical problem into a sequence representation and then forecasting the results presents a more practical approach than solving it directly. This conceptually separate reasoning, i.e. how to formulate a mathematical problem given some inputs using a LLM, and solving it as two independent learning tasks that can be combined at inference.

Figure 9: Cumulative distributions of the sum of absolute allocation error of allocations and portfolio returns per number of assets for \(\mathcal{D}_{\text{ood}}\)

## References

* [1] A. Agrawal, B. Amos, S. Barratt, S. Boyd, S. Diamond, and J. Z. Kolter. Differentiable convex optimization layers. _Advances in neural information processing systems_, 32, 2019.
* [2] A. Agrawal, S. Barratt, and S. Boyd. Learning convex optimization models. _IEEE/CAA Journal of Automatica Sinica_, 8(8):1355-1364, 2021.
* [3] I. Akkizidis and L. Kalyvas. _Final based III modelling: Implementation, impact and implications_. Springer, 2018.
* [4] B. Amos and J. Z. Kolter. Optnet: Differentiable optimization as a layer in neural networks. In _International Conference on Machine Learning_, pages 136-145. PMLR, 2017.
* [5] D. F. Anderson, D. J. Higham, and Y. Sun. Computational complexity analysis for monte carlo approximations of classically scaled population processes. _Multiscale Modeling & Simulation_, 16(3):1206-1226, 2018.
* [6] P. Boyle, M. Broadie, and P. Glasserman. Monte carlo methods for security pricing. _Journal of economic dynamics and control_, 21(8-9):1267-1321, 1997.
* [7] P. Brandimarte. _Handbook in Monte Carlo simulation: applications in financial engineering, risk management, and economics_. John Wiley & Sons, 2014.
* [8] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners. _Advances in neural information processing systems_, 33:1877-1901, 2020.
* [9] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners. _Advances in neural information processing systems_, 33:1877-1901, 2020.
* [10] R. E. Caflisch. Monte carlo and quasi-monte carlo methods. _Acta numerica_, 7:1-49, 1998.
* [11] J. Charlton, S. Maddock, and P. Richmond. Two-dimensional batch linear programming on the gpu. _Journal of Parallel and Distributed Computing_, 126:152-160, 2019.
* [12] P. Charoenphaibul and N. Juneam. Gpu-accelerated method for simulating efficient portfolios in the mean-variance analysis. In _2020 17th International Joint Conference on Computer Science and Software Engineering (JCSSE)_, pages 171-176. IEEE, 2020.
* [13] D. Cole, S. Shin, F. Pacaud, V. M. Zavala, and M. Anitescu. Exploiting gpu/simd architectures for solving linear-quadratic mpc problems. _arXiv preprint arXiv:2209.13049_, 2022.
* [14] S. Diamond and S. Boyd. Cvxpy: A python-embedded modeling language for convex optimization. _The Journal of Machine Learning Research_, 17(1):2909-2913, 2016.
* [15] I. Drori, S. Zhang, R. Shuttleworth, L. Tang, A. Lu, E. Ke, K. Liu, L. Chen, S. Tran, N. Cheng, R. Wang, N. Singh, T. L. Patti, J. Lynch, A. Shporer, N. Verma, E. Wu, and G. Strang. A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level. _Proceedings of the National Academy of Sciences_, 119(32):e2123433119, 2022.
* [16] E. J. Elton and M. J. Gruber. Modern portfolio theory, 1950 to date. _Journal of banking & finance_, 21(11-12):1743-1759, 1997.
* [17] M. Estecahandy, L. Bordes, S. Collas, and C. Paroissin. Some acceleration methods for monte carlo simulation of rare events. _Reliability Engineering & System Safety_, 144:296-310, 2015.

* [18] Z. Feinstein and B. Rudloff. Deep learning the efficient frontier of convex vector optimization problems. _arXiv preprint arXiv:2205.07077_, 2022.
* [19] A. Fernandez and S. Gomez. Portfolio selection using neural networks. _Computers & operations research_, 34(4):1177-1191, 2007.
* [20] T. Frerix, M. Niessner, and D. Cremers. Homogeneous linear inequality constraints for neural network activations. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops_, pages 748-749, 2020.
* [21] M. Giles, F. Y. Kuo, I. H. Sloan, and B. J. Waterhouse. Quasi-monte carlo for finance applications. _ANZIAM Journal_, 50:C308-C323, 2008.
* [22] P. Glasserman. _Monte Carlo methods in financial engineering_, volume 53. Springer, 2004.
* [23] D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song, and J. Steinhardt. Measuring mathematical problem solving with the MATH dataset. In _Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, Neurips Datasets and Benchmarks 2021, December 2021, virtual_, 2021.
* [24] J. Ho, N. Kalchbrenner, D. Weissenborn, and T. Salimans. Axial attention in multidimensional transformers. _arXiv preprint arXiv:1912.12180_, 2019.
* [25] J. C. Hull. _Options futures and other derivatives_. Pearson Education India, 2003.
* [26] T. Ibaraki and N. Katoh. _Resource allocation problems: algorithmic approaches_. MIT press, 1988.
* [27] P. Jackel. _Monte Carlo methods in finance_, volume 2. J. Wiley, 2002.
* [28] R. Kannan and J. R. Luedtke. A stochastic approximation method for approximating the efficient frontier of chance-constrained nonlinear programs. _Mathematical Programming Computation_, 13(4):705-751, 2021.
* [29] J. D. M.-W. C. Kenton and L. K. Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In _Proceedings of NAACL-HLT_, pages 4171-4186, 2019.
* [30] N. Kitaev, L. Kaiser, and A. Levskaya. Reformer: The efficient transformer. In _International Conference on Learning Representations_, 2020.
* [31] Y.-D. Kwon, J. Choo, B. Kim, I. Yoon, Y. Gwon, and S. Min. Pomo: Policy optimization with multiple optima for reinforcement learning. _Advances in Neural Information Processing Systems_, 33:21188-21198, 2020.
* [32] A. Lacoste, A. Luccioni, V. Schmidt, and T. Dandres. Quantifying the carbon emissions of machine learning. _arXiv preprint arXiv:1910.09700_, 2019.
* [33] A. Lewkowycz, A. J. Andreassen, D. Dohan, E. Dyer, H. Michalewski, V. V. Ramasesh, A. Slone, C. Anil, I. Schlag, T. Gutman-Solo, et al. Solving quantitative reasoning problems with language models. In _Advances in Neural Information Processing Systems_, 2022.
* [34] I. Loshchilov and F. Hutter. Decoupled weight decay regularization. In _7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019_, 2019.
* [35] Y. Ma, J. Li, Z. Cao, W. Song, L. Zhang, Z. Chen, and J. Tang. Learning to iteratively solve routing problems with dual-aspect collaborative transformer. _Advances in Neural Information Processing Systems_, 34:11096-11107, 2021.
* [36] Y. Markovits, A. J. Davis, and R. Van Dick. Organizational commitment profiles and job satisfaction among greek private and public sector employees. _International journal of cross cultural management_, 7(1):77-99, 2007.

* [37] O. McCullagh, M. Cummins, and S. Killian. The fundamental review of the trading book: implications for portfolio and risk management in the banking sector. _Journal of Money, Credit and Banking_, 2022.
* [38] D. L. McLeish. _Monte Carlo simulation and finance_, volume 276. John Wiley & Sons, 2011.
* [39] N. Metropolis and S. Ulam. The monte carlo method. _Journal of the American statistical association_, 44(247):335-341, 1949.
* [40] H. Pan and R. Kondor. Permutation equivariant layers for higher order interactions. In _International Conference on Artificial Intelligence and Statistics_, pages 5987-6001. PMLR, 2022.
* [41] C. R. Qi, H. Su, K. Mo, and L. J. Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 652-660, 2017.
* May 3, 2018, Workshop Track Proceedings_, 2018.
* [43] V. Schmidt, K. Goyal, A. Joshi, B. Feld, L. Conell, N. Laskaris, D. Blank, J. Wilson, S. Friedler, and S. Luccioni. Codecarbon: estimate and track carbon emissions from machine learning computing. _Cited on_, page 20, 2021.
* [44] M. Schubiger, G. Banjac, and J. Lygeros. Gpu acceleration of admm for large-scale quadratic programming. _Journal of Parallel and Distributed Computing_, 144:55-67, 2020.
* [45] I. Sutskever, O. Vinyals, and Q. V. Le. Sequence to sequence learning with neural networks. _Advances in neural information processing systems_, 27, 2014.
* [46] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. Attention is all you need. _Advances in neural information processing systems_, 30, 2017.
* [47] O. Vinyals, S. Bengio, and M. Kudlur. Order matters: Sequence to sequence for sets. _arXiv preprint arXiv:1511.06391_, 2015.
* [48] X. Warin. Deep learning for efficient frontier calculation in finance. _Journal of Computational Finance_, 26(1), 2022.
* [49] M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. R. Salakhutdinov, and A. J. Smola. Deep sets. _Advances in neural information processing systems_, 30, 2017.

[MISSING_PAGE_FAIL:14]

variance = np.matmul(np.matmul(vtid.T, cov), wtd)[0, 0] if variance < v.t.:  ret = np.array(ret)  chol = np.linalg.cbolesky(cov).T  gq = np.vstack(kp.zeros(n,assets), chol)  hq = np.zeros(n,assets + 1)  hq[0] = np.sqrt(v,t)  wt = cvxp_solve_socp(-ret, Gl-G, h1-H, Gq-Gq, hq-hq) #eq 2  vt = np.mininum(list(np.maximum(list(wt), min_weights)), max_weights)  return wt

## Appendix B Preprocessing

We encounter ambiguity in optimization problems due to various combinations of inputs representing the same problem. To address this, we provide three examples where we discuss the ambiguity and propose a standardized solution for processing inputs in an optimized manner prior to token projection.

When the \(i\)-th asset belongs to the \(j\)-th asset class and \(x_{i}^{\text{\tiny MAX}}>\zeta_{c_{j}}\), the constraint \(x_{i}^{\text{\tiny MAX}}\) is overridden by \(\zeta_{c_{j}}\). This means that there is no combination of assets where the allocation of the \(i\)-th asset can be higher than \(\zeta_{c_{j}}\). To address this constraint, we clip \(x_{i}^{\text{\tiny MAX}}\) to \(\zeta_{c_{j}}\) by using the formula: \(x_{i}^{\text{\tiny MAX}}=\min(\max(x_{i}^{\text{\tiny MAX}},\zeta_{c_{j}}),0)\) for all \(i\)-th assets belonging to the \(j\)-th class.

The remaining two cases are additional edge cases related to the previous condition. If only one asset is assigned to the \(j\)-th class, \(\zeta_{c_{j}}\) and \(x_{j}^{\text{\tiny MAX}}\) should be equal because it is equivalent to having no class constraint for that class. Also, if a class constraint is set but no assets belong to that class, it is equivalent to setting \(\zeta_{c_{j}}=0\). By processing the optimization inputs in this manner, we ensure that any ambiguity on the class constraints are standardized, allowing for equivalent linear projections into token before the transformer encoder part of the network.

## Appendix C Experimental Section

### Dataset

The size and description of the dataset we used are presented in table. 5. We used an asymmetric weighting scheme to generate all datasets, favoring more complex optimizations (see Table 6). As the number of assets increases, the number of unstable regions also increases, where allocation can significantly change. To ensure training and evaluation encompass these unstable regions, we generated a higher proportion of optimization inputs with more assets.

### Ablation study

NeuralEF comprises three parts. First, the preprocesses step (1.1) sort requests by asset returns, (1.2) reduce optimization input ambiguity (Appendix B), and (1.3) project them into tokens for a SEQ2SEQ representation. Secondly there is a bidirectional encoder transformer that solve EF as SEQ2SEQ. Finally, there is DGAR to enforce constraints. The preprocessing and DGAR help accurate forecasting. (1.1) and (1.2) are optional for training if accounted in the training data but help at inference to ensure the sorting requirement of NeuralEF and clean request of some optimization input ambiguities.

To show the effectiveness of DGAR, we've trained two NeuralEF models (w/ and w/o DGAR) trained for 5 days with a fixed learning rate of \(5.5e-5\) and present the distributional error an

\begin{table}
\begin{tabular}{l r l} \hline \hline
**Dataset name** & **Size** & **Description** \\ \hline \(\mathcal{D}_{\text{train}}\) & 1.2B samples & Sampled at random over the domain in table. 1 \\ \(\mathcal{D}_{\text{test}}\) & 990K samples & Sampled at random over the domain in table. 1 \\ \(\mathcal{D}_{\text{ood}}\) & 990K samples & Sampled following the indication of sec. 4.3 \\ \hline \hline \end{tabular}
\end{table}
Table 5: Description of the dataset used optimality gap of the metrics that are not respected on fig. 10-11 highlighting that model with DGAR achieves better MAE. Also, DGAR exhibits a reduced optimally gap of constraint adherence, further motivating the use of DGAR.

The cleaning module of NeuralEF were attached before the transformer part of the model to address the possible ambiguities provided in the optimization inputs. Using the same example of fig. 5 where the 10-th asset is associated to class \(C_{2}\), which is its only member, we changed the value of the constraints to be ambiguous relative to another and show in fig. 12 how accuracy deteriorates when the model encounter request that are ambiguous.

### Accuracy with half-precision floating-point format

The results obtained using single-precision floating-point (FP32) and the model quantized to half-precision floating-point (FP16) are on the same order of accuracy as shown in table 7 and fig. 13. The quantization process to FP16 maintains the necessary precision for the calculations, resulting in equivalent outcomes as the FP32 counterpart. While a degradation

\begin{table}
\begin{tabular}{c|c} \hline
**Asset case** & **Proportion (\%)** \\ \hline
2 & 2.517 \\
3 & 2.551 \\
4 & 2.559 \\
5 & 2.603 \\
6 & 6.834 \\
7 & 6.879 \\
8 & 10.346 \\
9 & 10.377 \\
10 & 13.826 \\
11 & 13.850 \\
12 & 27.658 \\ \hline \end{tabular}
\end{table}
Table 6: Proportion of assets in each datasets.

Figure 11: Optimiality gap W/ DGAR vs W/O DGAR

Figure 10: Accuracy W/ DGAR vs W/O DGAR

in the ability to rank assets7 and respect the volatility and class constraint occurs, we observe that this does not impact the overall distributional properties and the downstream applications that would benefit from it. As such, there is no discrepancy in the results between the two representations, demonstrating the viability of using the lower-precision FP16 for computational efficiency.

Footnote 7: The ranking of the results has been computed with a tolerance of \(1e-4\), where a slight deviations are permissible and don’t hurt the accuracy. This was made such that negligible allocation made by NeuralEF which can be disregarded for practical purpose are neglected.

Figure 12: Issue of semantically equivalent requests with perturbation \(x_{10}^{\text{\tiny MAX}}\in[0.5,1]\) and \(\zeta_{\text{\tiny c}_{2}}\in[0.5,1]\)

Figure 13: Cumulative distributions of the sum of absolute allocation error of allocations and portfolio returns per number of assets for the FP16 quantized NeuralEF.

\begin{table}
\begin{tabular}{c|c c c c c c} \hline
**Amont case** & **Portfolio weights MSE** & **Portfolio weights MAE** & **95 quantile** & **93-865 quantile** & **90.397 quantile** & **Ranking precision** \\

[MISSING_PAGE_POST]

 \hline  & 1.29e-06 & 1.13e-03 & 2.49e-02 & 5.75e-02 & 1.84e-01 & 79.517 \% \\ \hline \end{tabular}
\end{table}
Table 7: Accuracy of portfolio weights, implied return and resulting volatility for the FP16 quantized NeuralEF.