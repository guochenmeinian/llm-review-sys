# Universal Rates for Active Learning

 Steve Hanneke

Purdue University

steve.hanneke@gmail.com

&Amin Karbasi

Yale University

amin.karbasi@yale.edu

&Shay Moran

Technion, Google Research

smoran@technion.ac.il

&Grigoris Velegkas

Yale University

grigoris.velegkas@yale.edu

###### Abstract

In this work we study the problem of _actively_ learning binary classifiers from a given concept class, i.e., learning by utilizing _unlabeled_ data and submitting targeted _queries_ about their labels to a domain expert. We evaluate the quality of our solutions by considering the _learning curves_ they induce, i.e., the rate of decrease of the misclassification probability as the number of label queries increases. The majority of the literature on active learning has focused on obtaining _uniform_ guarantees on the error rate which are only able to explain the upper envelope of the learning curves over families of different data-generating distributions. We diverge from this line of work and we focus on the _distribution-dependent_ framework of universal learning whose goal is to obtain guarantees that hold for any fixed distribution, but do not apply uniformly over all the distributions. We provide a complete characterization of the optimal learning rates that are achievable by algorithms that have to specify the number of _unlabeled_ examples they use ahead of their execution. Moreover, we identify combinatorial complexity measures that give rise to each case of our tetrachotomic characterization. This resolves an open question that was posed by Balcan et al. (2010). As a byproduct of our main result, we develop an active learning algorithm for _partial_ concept classes that achieves exponential learning rates in the uniform setting.

## 1 Introduction

The most prototypical type of learning is that of _supervised_ learning, where an algorithm is given as input \(n\)_labeled_ data points sampled i.i.d. from some unknown distribution and the goal is to output a function that has low probability of misclassifying new data from the same distribution. One caveat with this passive model of learning is that it fails to capture the settings in which _unlabeled_ data is easily accessible, but obtaining their labels is costly. A natural example that fits this description is that of webpage classification. It is easy for any web crawler to collect information about billions of different webpages in a very short amount of time, however understanding which category a webpage belongs to usually requires human feedback. Perhaps the most commonly used way to model this problem is through the _active_ learning framework in which the learner is given access to a large stream of unlabeled data and a budget of \(n\) queries that it can submit to a domain expert in order to obtain the label of some datapoint. The learner's goal is to submit queries for the labels of the most informative examples, and, as a result, eliminate some redundancy in the information content of labeled data.

In this paper we study the optimal learning rates that are achievable by an active learning algorithm. In the passive learning setting, it is common to measure the quality of an algorithm by its _learning curve_, i.e., plotting the decay of its error rate as the number of training examples increases. In contrast, in theactive learning setting, the resource we are interested in is the number of label queries the algorithm requests, so it is natural to consider the rate of decay of the misclassification probability as the number of queries \(n\) increases. Most of the prior works on active learning have focused on obtaining _uniform_ guarantees on the error rate, i.e., guarantees that hold uniformly over the data-generating distributions. In this work we follow a different path and we view the problem through the lens of _universal_ rates that was recently introduced by Bousquet et al. (2021). In this framework we are aiming for guarantees that hold for all distributions, but they do not hold uniformly over them. In other words, we allow for _distribution-dependent_ constants in the error rate. To make the distinction between uniform and universal rates clear, we first recall what uniform learnability of a hypothesis class \(\mathbb{H}\) means. We say that \(\mathbb{H}\) is uniformly learnable at rate \(R(n)\) if there exists a learning rule \(\hat{h}_{n}\) such that

\[\big{(}\exists C,c>0\big{)}\big{(}\forall\mathbb{P}\in\textsc{RE}(\mathbb{H}) \big{)}\text{ it holds that }\mathbb{E}[\mathrm{er}_{\mathrm{P}}(\hat{h}_{n})]\leq C\cdot R(c \cdot n),\forall n\in\mathbb{N}\,.\]

The above expression states that there exists a learning rule \(\hat{h}_{n}\) and _distribution-independent_ constants such that for all realizable distributions the expected error rate of the classifier is at most \(C\cdot R(c\cdot n)\). The difference in the definition of universal learnability is that we swap the order of the quantifiers. To be more precise, we say that a class \(\mathbb{H}\) is universally learnable at rate \(R(n)\) if there exists a learning rule \(\hat{h}_{n}\) such that

\[\big{(}\forall\mathbb{P}\in\textsc{RE}(\mathbb{H})\big{)}\big{(}\exists C,c> 0\big{)}\text{ such that }\mathbb{E}[\mathrm{er}_{\mathrm{P}}(\hat{h}_{n})]\leq C\cdot R(c\cdot n), \forall n\in\mathbb{N}\,.\]

Note that in the above definition the constants \(c,C\) are _distribution-dependent_. As is evident from our main result and from prior results in universal learning (Bousquet et al., 2021; Hanneke et al., 2022; Kalavasis et al., 2022; Bousquet et al., 2022; Hanneke et al., 2023) this change in the definition affects the landscape of the optimal learning rates significantly.

### Related Work

Active Learning.There has been a very long line of work deriving theoretical guarantees for active learning, both in the realizable and the agnostic setting (Cohn et al., 1994; Dasgupta, 2005; Balcan et al., 2006; Hanneke, 2007b, a; Dasgupta et al., 2007; Hanneke, 2009; Balcan et al., 2009, 2010; Hanneke, 2012, 2014; Wiener et al., 2015; Hanneke and Yang, 2015; Beygelzimer et al., 2016). As we alluded to before, most of these works focus on obtaining _minmax_ guarantees, i.e., the bounds they provide hold in the worst case over a family of distributions. To be more precise, while many of these results have distribution-dependent guarantees, they are typically expressed in a way that aims to match a lower bound on the minmax performance over a family o distributions, with respect to some parameter, like the disagreement coefficient. For these reasons the results in these works do not capture the full spectrum of universal rates. We also remark that there are a few works that do study universal rates, e.g. Balcan et al. (2010); Hanneke (2012); Yang and Hanneke (2013), but none of them have derived a complete characterization of the optimal rates.

Universal Rates.The study of universal learning rates was put forth in the seminal work of Bousquet et al. (2021) who derived a complete characterization of the optimal rates in the supervised learning setting. Later, Kalavasis et al. (2022) extended these result to the multiclass setting, with a bounded number of classes, and Hanneke et al. (2023) improved upon this result by characterizing multiclass classification with an infinite number of labels. Subsequently, the work of Bousquet et al. (2022) derived more fine-grained results for binary classification compared to Bousquet et al. (2021). The work that is most closely related to ours is Hanneke et al. (2022) which derives a complete characterization of the optimal learning rates in a very general interactive learning setting. In that setting, the learner is allowed to submit arbitrary binary valued queries about the unlabeled data. We provide a detailed comparison between our results and theirs in Section 1.5. Very recently, Attias et al. (2024) studied universal rates in the context of regression.

Partial Concept Classes.The vast majority of the literature in learning theory has focused on _total_ concept classes, i.e., classes that consist of functions that are defined everywhere on the instance domain. Recently, Alon et al. (2021) proposed a learning theory of _partial_ concept classes, i.e., classes that consist of functions that can be _undefined_ on some parts of the instance domain. Later, Kalavasis et al. (2022) extended some of the results to the multiclass setting, with a finite number of labels. Recently, Cheung et al. (2023) studied partial concept classes in the context of online learning and they showed that there are such classes that are online learnable but none of their "extensions" to total concept classes is online learnable. The advantage of partial concepts is that they provide a convenient way to express _data-dependent_ constraints. En route of obtaining our main result, we design active learning algorithms for partial concept classes. For a more detailed discussion about partial concepts we refer the reader to Appendix A.2.

### Formal Setting

Learning Model.We now present formally the learning setting that we consider in this work. There is a _domain_\(\mathcal{X}\), which we assume to be a Polish space, and a concept class \(\mathbb{H}\subseteq\{0,1\}^{\mathcal{X}}\), which satisfies standard measurability assumptions (see Definition A.1). We define a _classifier_\(h:\mathcal{X}\to\{0,1\}\) to be a universally measurable function and its _error rate_ is defined as \(\operatorname{er}_{\mathrm{P}}(h):=\operatorname{P}\left[(x,y):h(x)\neq y\right]\), where \(\mathrm{P}\) is the data-generating distribution over \(\mathcal{X}\times\{0,1\}\). When \(\mathrm{P}\) is clear from the context we might drop the subscript \(\mathrm{P}\) in \(\operatorname{er}_{\mathrm{P}}(h)\). We call \(\mathrm{P}\)_realizable_ with respect to the hypothesis class \(\mathbb{H}\) if \(\inf_{h\in\mathbb{H}}\operatorname{er}_{\mathrm{P}}(h)=0\). We denote by \(\mathrm{P}_{\mathcal{X}}\) be the marginal distribution of \(\mathrm{P}\) on \(\mathcal{X}\).

Active Learning Model.We define an _active learning algorithm_ to be a sequence of universally measurable functions which, given access to a stream of _unlabeled_ data points from \(\mathcal{X}\) that are drawn i.i.d. from \(\mathrm{P}_{\mathcal{X}}\) and a label query budget \(n\), output a classifier \(\hat{h}_{n}:\mathcal{X}\times\{0,1\}\). In this work we consider a _non-adaptive_ active learning model, with respect to the _unlabeled_ data. In particular, the learning algorithm needs to specify a function \(u:\mathbb{N}\to\mathbb{N}\) so that \(u(n)\) is the number of _unlabeled_ points it observes and \(n\) is the number of points for which it can request the label. The number \(u(n)\) is specified _before_ the execution of the algorithm and cannot be modified based on the realization of the unlabeled sequence or the answers that it gets for the labels of the points it queries. We place no bound whatsoever on the function \(u(\cdot)\). Also, the algorithm can only request the labels of points it has observed and not arbitrary points from \(\mathcal{X}\). We emphasize that the label requests that the algorithm makes can be adaptive, and can depend on answers to previous label queries. To the best of our knowledge, the active learning algorithms that have been proposed in the literature either fit into this model or they can be modified to satisfy the non-adaptivity restriction with negligible performance loss.

Learning Rates.We now define formally what it means for an algorithm to achieve a learning rate \(R(n)\) in the _universal learning_ model. We adopt the definition of Bousquet et al. (2021).

**Definition 1.1** (Learning Rates (Bousquet et al., 2021)).: _Fix a concept class \(\mathbb{H}\), and let \(R:\mathbb{N}\to[0,1],R(n)\stackrel{{ n\to\infty}}{{\longrightarrow}}0\) be a rate function, where \(n\) is the label query budget of the learner._

* \(\mathbb{H}\) _is learnable at rate_ \(R\) _if there is a learning algorithm_ \(\hat{h}_{n}\) _such that for every realizable distribution_ \(\mathrm{P}\)_, there exist_ \(c,C\) _for which_ \(\mathbb{E}[\operatorname{er}(\hat{h}_{n})]\leq CR(cn),\forall n\in\mathbb{N}\)_._
* \(\mathbb{H}\) _is not learnable at rate faster than_ \(R\) _if for all learning algorithms_ \(\hat{h}_{n}\) _there exists a realizable distribution_ \(\mathrm{P}\) _and_ \(c,C\) _for which_ \(\mathbb{E}[\operatorname{er}(\hat{h}_{n})]\geq CR(cn)\)_, for infinitely many_ \(n\in\mathbb{N}\)_._
* \(\mathbb{H}\) _is learnable with optimal rate_ \(R\) _if it is learnable at rate_ \(R\) _and it is not learnable at rate faster than_ \(R\)_._
* \(\mathbb{H}\) _admits arbitrarily fast rates if for all rate functions_ \(R\)_, it is learnable at rate_ \(R\)_._
* \(\mathbb{H}\) _requires arbitrarily slow rates if for all rate functions_ \(R\)_, it is not learnable at rate faster than_ \(R\)_._

Combinatorial Measures.We now define some combinatorial complexity measures that our characterization relies on. To make the presentation easier to follow, we provide informal definitions. For the formal ones, we refer the reader to Appendix A.3. We first describe the _Littlestone tree_ that was introduced by Bousquet et al. (2021).

**Definition 1.2** (Littlestone Tree, Informal (see Definition A.8) (Bousquet et al., 2021)).: _A Littlestone tree for \(\mathbb{H}\subseteq\{0,1\}^{\mathcal{X}}\) is a complete binary tree of depth \(d\leq\infty\) whose nodes are labeled by elements of \(\mathcal{X}\) and the edges to the left, right child are labeled by \(0,1\). We require that for every level \(0\leq n<d\)and every path from the root to a node at level \(n\) there is some \(h\in\mathbb{H}\) that realizes this path. We say that \(\mathbb{H}\) has an infinite Littlestone tree if it has a Littlestone tree of depth \(d=\infty\)._

We underline that this notion can be thought of as an infinite extension of the _Littlestone dimension_(Littlestone, 1988) of \(\mathbb{H}\). Recall that the Littlestone dimension is defined to be the largest \(d\in\mathbb{N}\) for which \(\mathbb{H}\) has a Littlestone tree of such depth and it is \(\infty\) if one can construct Littlestone trees of arbitrary depth. Crucially, this is not the same as having a _single_ tree whose depth is infinite, so one can see that infinite Littlestone dimension is _not_ the same as having an infinite Littlestone tree.

We next give the definition of the _Vapnik-Chervonenkis-Littlestone tree_ (VCL) that was introduced by Bousquet et al. (2021).

**Definition 1.3** (VCL Tree, Informal (see Definition A.10)(Bousquet et al., 2021)).: _A VCL tree for \(\mathbb{H}\subseteq\{0,1\}^{\mathcal{X}}\) is a complete tree of depth \(d\leq\infty\) such that every level \(0\leq n<d\) has nodes that are labeled by \(\mathcal{X}^{n+1}\) with branching factor \(2^{n+1}\) and whose \(2^{n+1}\) edges connecting a node to its children are labeled by the elements of \(\{0,1\}^{n+1}\). We require that for every node at any level \(0\leq n<d,\) the path from the root to this node is realized by some \(h\in\mathbb{H}\). We say that \(\mathbb{H}\) has an infinite VCL tree if it has a VCL tree of depth \(d=\infty\)._

Intuitively, the VCL tree combines the notions of the Littlestone tree and the VC dimension (Vapnik and Chervonenkis, 1971; Blumer et al., 1989). The differences between the Littlestone tree and the VCL tree are that in the latter the size of the nodes increases linearly with the level and the branching factor increases exponentially, whereas in the former all the nodes are singletons and the branching factor is always two.

We are now ready to introduce a new combinatorial measure which we call the _star tree_.

**Definition 1.4** (Star Tree, Informal (see Definition A.9)).: _A star tree for \(\mathbb{H}\subseteq\{0,1\}^{\mathcal{X}}\) is a complete tree of depth \(d\leq\infty\) such that every level \(0\leq n<d\) has nodes that are labeled by \((\mathcal{X}\times\{0,1\})^{n+1}\) with branching factor \(n+1\) and whose \(n+1\) edges connecting a node to its children are labeled by \(\{0,\ldots,n\}.\) The label of the edge indicates the element of the node whose label along the path is flipped. We require that for every node at level \(0\leq n<d\), the path from the root to this node is realized by \(\mathbb{H}.\) We say that \(\mathbb{H}\) has an infinite star star tree if it has a star tree of depth \(d=\infty\)._

Essentially, this definition combines the structure of a Littlestone tree with the notion of the _star number_(Hanneke and Yang, 2015). Every node at level \(n\) consists of \(n+1\)_labeled_ points and there are \(n+1\) edges attached to it. Each edge indicates which of the \(n+1\) points of the labeled node has its label flipped along every path that this edge is part of.

### Main Results

We are now ready to state the main results of this work. Our first main result is a complete characterization of the optimal learning rates that a class \(\mathbb{H}\) admits in the active learning setting.

**Theorem 1.5**.: _For every concept class \(\mathbb{H}\) exactly one of the following cases holds._

* \(\mathbb{H}\) _is actively learnable at arbitrarily fast rates._
* \(\mathbb{H}\) _is actively learnable at an optimal rate_ \(e^{-n}.\)__
* \(\mathbb{H}\) _is actively learnable at_ \(o(1/n)\) _rates, but requires rates arbitrarily close to_ \(1/n.\)__
* \(\mathbb{H}\) _requires arbitrarily slow rates for active learning._

Our next result characterizes exactly when these rates occur by specifying combinatorial complexity measures of \(\mathbb{H}\) that determine which case of the tetrachtotomy it falls into.

**Theorem 1.6**.: _For every concept class \(\mathbb{H}\) the following hold._

* _If_ \(\mathbb{H}\) _does not have an infinite Littlestone tree, then it is learnable at arbitrarily fast rates._
* _If_ \(\mathbb{H}\) _has an infinite Littlestone tree but does not have an infinite star tree, then it is learnable at optimal rate_ \(e^{-n}.\)__
* _If_ \(\mathbb{H}\) _has an infinite star tree but does not have an infinite VCL tree, then it is learnable at optimal rate_ \(o(1/n),\) _but requires rates arbitrarily close to_ \(1/n.\)__* _If_ \(\mathbb{H}\) _has an infinite VCL tree, then it requires arbitrarily slow rates._

We remark that the landscape of the optimal rates looks significantly different compared to the passive setting (Bousquet et al., 2021) and the general interactive learning setting (Hanneke et al., 2022). Our main result answers an open question that was posed in Balcan et al. (2010), which asks for necessary and sufficient conditions for learnability at an exponential rate in the active learning setting.

### Examples

We now present examples of classes that witness each case of our tetrachotomic characterization.

Arbitrarily-fast rates: Bousquet et al. (2021) give examples with no infinite Littlestone tree (e.g., thresholds on the integers, and positive halfspaces on \(\mathbb{N}^{d}\)), hence learnable at arbitrarily fast rates.

Exponential rates: Famously, threshold classifiers \([a,\infty)\) over \(\mathbb{R}\) have an infinite Littlestone tree and are actively learnable at exponential rate (even uniformly). A more interesting example is the class of interval classifiers \([a,b]\) on \(\mathbb{R}\), which (also famously) has uniform rate \(1/n\) for active learning (it has infinite star number), and has an infinite Littlestone tree, but it _has no infinite star tree_: for any choice of \(x\) in the root node, the edge labeling \(x\) as 1 has a version space with star number equal 4 (it is effectively 2 disjoint threshold problems), so the depth of that subtree is bounded. Therefore, by our theory, it is actively learnable at \(e^{-n}\) universal rate (in stark contrast to the uniform rate \(1/n\)).

Sublinear rates: Halfspaces on \(\mathbb{R}^{d}\) have an infinite star tree but no infinite VCL tree. To construct that star tree, the key observation is that any set in convex position is a star set (Balcan et al., 2010).

Arbitrarily slow rates: Bousquet et al. (2021) provide examples of classes with an infinite VCL tree, such as the class of all clarfisifiers, so these require arbitrarily slow rates in our setting as well.

### Comparison to Supervised Learning and General Interactive Learning Setting

We now compare our characterization to the results of Bousquet et al. (2021) that prove an analogous result in the supervised learning setting. Let us first recall their main result which shows that in this learning model a class is universally learnable at:

* Exponential rate \(e^{-n}\) if and only if it does not have an infinite Littlestone tree.
* Linear rate \(1/n\) if and only if it has an infinite Littlestone tree but does not have an infinite VCL tree.
* Arbitrarily slow rates if and only if it has an infinite VCL tree.

As one can see, our results illustrate the advantage that active learning algorithms have over their supervised counterparts. We underline that the only case where active learning does not offer an improvement compared to the passive setting is when \(\mathbb{H}\) has an infinite VCL tree.

Let us now discuss the interactive learning model that was considered by Hanneke et al. (2022). In this general model of interaction, the learner is allowed to ask _arbitrary binary queries_ about any subset of the unlabeled data. In particular, these queries include, but are not limited to, label queries, comparison queries, and general membership queries. They show that the optimal rates that any class \(\mathbb{H}\) admits are the following:

* Arbitrarily fast if and only if it does not have an infinite Littlestone tree.
* Exponential if and only if it has an infinite Littlestone tree but not an infinite VCL tree.
* Arbitrarily slow if and only if it has an infinite VCL tree.

We underline that the algorithm by Hanneke et al. (2022) that achieves arbitrarily fast rates uses only label queries and the number of unlabeled data \(u(n)\) that it uses can be chosen statically prior to the execution of the algorithm. Therefore, this result applies to the setting we consider in our work. Moreover, the lower bounds they provide also apply to our setting since (i) the queries that Hanneke et al. (2022) consider are more general, and (ii) their lower bounds hold even when the learner knows the marginal distribution \(\mathrm{P}_{\mathcal{X}}\). As is evident from our main result, the active learning setting provides a richer landscape of optimal rates compared to the general interactive learning setting of Hanneke et al. (2022). In particular, just the absence of an infinite VCL tree for \(\mathbb{H}\) does not necessarily imply that we can achieve (at least) exponential rates. To get this result, Hanneke et al. (2022) make strong use of these general queries in order to provide an algorithm that has a binary-search flavor and can learn _partial_ concept classes with finite VC dimension at an exponential rate. Our main result shows that such guarantees are not achievable by using only label queries.

### Technical Challenges

The most technically innovative part of our work is the \(o(1/n)\) algorithm. Let us set up some terminology to facilitate our discussion. The _version space_ of a concept class, given a labeled dataset \(S\), is the set of concepts that classify all the elements of \(S\) correctly. Moreover, the _VCL game_ is a Gale-Stewart game defined by Bousquet et al. (2021) that was used in their passive learning algorithm that achieves \(1/n\) universal rate. The original (passive) learner from Bousquet et al. (2021) partitions a portion of the data into some number \(B(n)\) of batches, from which they construct partial concept classes of finite VC dimension by using the batches to play the VCL game against the player's winning strategy, and for each resulting partial concept class they run a separate learner on another portion of data and return a majority vote of their resulting classifiers. The latter part of this strategy _could never work_ in the active learning setting, since the number of batches \(B(n)\) must be an increasing function of \(n\), and applying an active learner for each partial concept class separately would require each to use (nearly) \(\Omega(n)\) queries (to get the \(o(1/n)\) guarantee there), so the total number of queries would be (nearly) \(\Omega(B(n)n)\gg n\), violating the label budget \(n\). To resolve this, we ended up completely re-imagining how to use these partial concept classes. Rather than running a separate algorithm for each class, we run a _single_ active learning algorithm, where individual decisions of whether to query involve voting over the partial concept classes. We first extend an algorithm of Hanneke (2012) (for total concepts) to achieve \(o(1/n)\) rate for partial concept VC classes (this required completely re-formulating Hanneke's analysis). The resulting algorithm involves estimating the probability that a random \(k\)-tuple is VC shattered by certain constrained version spaces. We replace this with an estimated average (over a select subset of partial concept classes) of this shattering probability, which we show composes appropriately with the analysis of the algorithm to obtain the \(o(1/n)\) rate. Comparing our work to the general interactive learning setting considered by Hanneke et al. (2022), the main differences are (i) we design a new algorithm that uses only label queries and achieves exponential rates when \(\mathbb{H}\) does not have an infinite star tree, a combinatorial measure we introduce in our work, (ii) we prove a \(o(1/n)\) lower bound in the setting where \(\mathbb{H}\) has an infinite star tree, and (iii) we propose a novel active learning algorithm that achieves sublinear rates when \(\mathbb{H}\) does not have an infinite VCL tree.

## 2 Arbitrarily Fast Rates

As we explained before, the first case of the tetrachotomy in our characterization is a direct implication of the results by Hanneke et al. (2022). To be more precise, they design an algorithm which achieves arbitrarily fast rates using only label queries. In order to do that, they need the number of _unlabeled_ points \(u(n)\) to be an arbitrarily fast increasing function, that, nevertheless, can be specified in a non-adaptive manner prior to the execution of the algorithm. The result is summarized in Theorem 2.1.

**Theorem 2.1** (Hanneke et al. (2022)).: _If \(\mathbb{H}\) does not have an infinite Littlestone tree it is actively learnable with arbitrarily fast rates._

For completeness, we present their algorithm in Figure 1.

Similarly with the upper bound, the lower bound is an immediate consequence of a result from Hanneke et al. (2022), since the learner can submit more informative queries in their model.

**Theorem 2.2** (Hanneke et al. (2022)).: _If \(\mathbb{H}\) has an infinite Littlestone tree, then \(\mathbb{H}\) is not actively learnable at rate faster than exponential \(e^{-n}\). This holds even if \(\mathrm{P}_{\mathcal{X}}\) is known to the learner._

## 3 Exponentially Fast Rates

In this section, we prove the second case in the tetrachotomy we have stated, i.e., that \(\mathbb{H}\) is learnable at an exponential rate if and only if it has an infinite Littlestone tree and it does not have an infinite star tree. Our proof consists of two parts. First, we show that if \(\mathbb{H}\) does not have an infinite star tree it is learnable at an exponentially fast rate. Then, we show that whenever \(\mathbb{H}\) has an infinite star tree, the best achievable rate cannot exceed \(o(1/n)\). The omitted details can be found in Appendix C.

### Exponential Rates Algorithm: High-Level Overview

The high-level approach to get the exponential rates algorithm follows the same spirit of the approaches from Bousquet et al. (2021); Hanneke et al. (2022). First, we design an appropriate Gale-Stewart game (cf. Appendix A.2), i.e., a game between a learner and an adversary, that is associated with \(\mathbb{H}\) in which the learner has a winning strategy if and only if \(\mathbb{H}\) does not have an infinite star tree. The next step is to show that, in the limit, the winning strategy of the learner gives rise to a _partial_ concept class \(\mathcal{F}\) that has _finite_ star number (see Definition A.7). Since this result is asymptotic, our approach is to consider several instances of this game, execute them for a finite number of steps, and obtain a partial concept class from each one. Then, we aggregate these classes into a _majority_ class. The intuition is that, with high probability, most of the games will have induced classes whose star number is bounded by a distribution-dependent constant, so then we can show that the majority class will also have bounded star number, and this bound is distribution-dependent. Thus, our task boils down to actively learning a partial concept class whose star number is finite. In order to do that, we extend the approach that Hanneke and Yang (2015) used for total concept classes to the regime of partial classes. We believe that this result could be of independent interest.

### The Star Tree Game

We first outline the Gale-Stewart game we use. Recall that every node of a star tree at depth \(n\) consists of \(n+1\) points along with their labels. There are \(n+1\) edges that connect the node with its children and the label of every edge indicates the point whose label is flipped along any path that uses this edge. Let us now describe the game \(\mathfrak{G}\) that we use in this setting. In every round \(\tau\geq 1\) we have the following interaction between the learner \(\text{P}_{\text{L}}\) and the adversary \(\text{P}_{\text{A}}\):

* Player \(\text{P}_{\text{A}}\) chooses points \((\vec{\xi}_{\tau},\vec{\zeta}_{\tau})=(\xi_{\tau}^{0},\ldots,\xi_{\tau}^{\tau- 1},\zeta_{\tau}^{0},\ldots,\zeta_{\tau}^{\tau-1})\in\mathcal{X}^{\tau}\times \{0,1\}^{\tau}\).
* Player \(\text{P}_{\text{L}}\) chooses \(\eta_{\tau}\in\{0,\ldots,\tau-1\}\).
* Player \(\text{P}_{\text{L}}\) wins the game in round \(\tau\) if \[\mathbb{H}_{\vec{\xi}_{1},\vec{\zeta}_{1},\eta_{1},\ldots,\vec{\xi}_{\tau}, \vec{\zeta}_{\tau},\eta_{\tau}}:=\left\{h\in\mathbb{H}:\begin{array}{ll}h( \xi_{s}^{i})=\zeta_{s}^{i},&\text{if }\eta_{s}\neq i\\ h(\xi_{s}^{i})=1-\zeta_{s}^{i},&\text{if }\eta_{s}=i\end{array},1\leq s \leq\tau,0\leq i<s\right\}=\emptyset.\] (1)

It is easy to see that the winning condition for \(\text{P}_{\text{L}}\) is finitely decidable (cf. Appendix A.2), hence \(\mathfrak{G}\) is a Gale-Stewart game. Recall that this means exactly one player between the adversary and the learner has a winning strategy. Using a result regarding the measurability of winning strategies in Gale-Stewart games that was shown by Bousquet et al. (2021) (see Theorem A.3) we can prove the following connection between \(\mathfrak{G}\) and the existence of infinite star trees ( see Appendix C.1 for the proof).

**Lemma 3.1**.: _The class \(\mathbb{H}\) does not have an infinite star tree if and only if \(\text{P}_{\text{L}}\) has a universally measurable winning strategy in \(\mathfrak{G}\)._

The first step in our approach, is to make use of some \(\Theta(n)\) label queries in order to obtain the labels of \(\Theta(n)\) many points. The idea these labeled points in order to simulate the Gale-Stewart game we described above (see Appendix C.3 for the details). The main technical issue we need to handle is that we have no control over the number of rounds the game needs in order to terminate. Using ideas that have appeared in the universal learning literature, we use a portion of these labeled points to estimate some number \(\hat{t}_{n}\) so that, with at least some constant probability over the dataset, the game will terminate within \(\hat{t}_{n}\) many rounds. Then, we split the remaining of the labeled dataset into batches of size \(\hat{t}_{n}\) and we run the game on each batch. The outcome of each game gives us a _pattern-avoidance_ function, i.e., a function that takes an input tuples of arbitrarily _labeled_ points and changes the label of one of them so that the resulting labeled tuple is not consistent with the data-generating distribution \(\mathrm{P}\). In other words, the output of this function could not have been generated by the \(\mathrm{P}\). A technical complication we need to handle is that we obtain multiple such pattern avoidance functions, some of which are incorrect, but to make the presentation cleaner we explain the idea using a single pattern avoidance function \(\widetilde{g}_{t^{*}}\) that produces inconsistent labels. The formal setting is handled in Appendix C.4. One way to think about this function is that it provides _data-dependent_ constraints. Thus, it is natural to express such a constraint through a _partial_ concept class. We define

\[\mathcal{F}=\left\{f:\mathcal{X}\rightarrow\{0,1,\star\}:(x_{1},f(x_{1})),(x_{2 },f(x_{2})),\ldots,(x_{t^{*}},f(x_{t^{*}}))\notin\mathrm{image}(\widetilde{g}_ {t^{*}}),\forall x_{1},\ldots,x_{t^{*}}\in\mathcal{X}^{t^{*}}\right\}.\]Notice that the constraint we have placed on \(\mathcal{F}\) is satisfied if \(f(x_{i})=\star\), for some \(i\in[t^{*}]\). We consider the natural extension of the notion of star sets to the case of partial concept classes, i.e., we say that a labeled set \(S\) with labels in \(\{0,1\}\) is a star set if \(S\) and its adjacent sets \(S^{\prime}\), whose labels are still restricted to be in \(\{0,1\}\), are obtainable using functions from \(\mathcal{F}\) (see Definition A.7). A key observation is that the star number of \(\mathcal{F}\) is bounded by \(t^{*}-1\). Another difficulty we need to overcome is that we do not know \(t^{*}\), since it is a random variable that depends on the realized sequence and its distribution might have heavy tails. To make our approach easier to follow, let us first assume that we do know \(t^{*}\)1. Then, our task boils down to actively learning a partial concept class.

Footnote 1: In Appendix C.4 we show how to obtain an etimate.

### Active Learning of Partial Concept Classes with Finite Star Number

We now present an algorithm that achieves exponential rates when actively learning a partial concept class \(\mathcal{F}\) that star number \(\mathfrak{s}<\infty\). The idea of our approach is to reduce the problem of actively learning a partial concept to the well-studied problem of actively learning a total concept class. The algorithm is presented in Figure 2. Let us explain the high-level ideas of the algorithm. First, we consider a large enough set of unlabeled data. Our goal is to find their labels using _logarithmically_ many queries. To do that, we consider the uniform distribution over these unlabeled examples. Then, we use an algorithm from Hanneke and Yang (2015) (see Theorem C.1) which guarantees exponential rates when applied to a class with finite star number. Because the underlying distribution on the sample is uniform, with high probability, the algorithm will find the correct labels of all the points. Finally, we feed these labeled examples to the one-inclusion graph algorithm (Theorem A.5) to get the desired result. We are now ready to state our theorem. The proof is postponed to Appendix C.2.

**Theorem 3.2**.: _There exists an active learning algorithm \(\mathcal{A}\) for a partial concept class \(\mathcal{F}\) which given a label budget \(n\) and access to unlabeled samples from a realizable distribution \(\mathrm{P}^{*}\) returns a classifier \(\hat{h}_{n}\) such that \(\mathbb{E}_{\mathrm{P}^{*}}[\mathrm{er}(\hat{h}_{n})]\leq c_{1}\mathrm{d}e^{- c_{2}n/\mathfrak{s}}\), where \(c_{1},c_{2}\) are absolute numerical constants, and \(\mathfrak{s},\mathrm{d}\) is the star number, VC dimension of \(\mathcal{F}\)._

### Slower than Exponential is Sublinear

The next step in the characterization is to show that if \(\mathbb{H}\) has an infinite star tree, then it does not admit rates faster than sublinear. The proof starts by picking a random path on the infinite star tree. The target distribution is supported only on nodes of the selected path. Then, given some algorithm \(\hat{h}_{n}\), we distribute the mass of the target probability distribution across the path, potentially skipping some nodes of it, in a way that creates an infinite sequence \(n_{i_{1}},n_{i_{2}},\ldots\), so that when the learner has label budget \(n_{i_{j}}\), with some constant probability, it will only observe unlabeled points up to level \(k_{i_{j}}\). Moreover, with at least some constant probability, it will not query the point of that level whose label is flipped along the target path. On that event, it makes a mistake with probability at least \(C\cdot p_{i_{j}}/k_{i_{j}}\), where \(C\) is some absolute constant. Our choice of \(p_{i_{j}},k_{i_{j}}\) guarantees that \(R(n_{j})>p_{i_{j}}/k_{i_{j}},\) where \(R(\cdot)\) is the target sublinear rate function. Finally, we apply Fatou's lemma to get the desired result. For the full proof and the formal theorem statement, we refer the reader to Appendix C.5

## 4 Sublinear Rates

Our approach to achieve sublinear rates in the setting where \(\mathbb{H}\) does not have an infinite VCL tree shares some high-level ideas with the one in Section 3, but many technical challenges make it significantly more involved. The main obstacle is that there is no active learning algorithm that achieves sublinear rates for VC classes _uniformly_ over all realizable distributions. Recall that in the exponential rates setting, such an algorithm does exist (Hanneke and Yang, 2015). Instead, the sublinear rates algorithm for VC classes from Hanneke (2012) depends on distribution-dependent constants in the sample complexity. The omitted details from this section can be found in Appendix D.

Instead of the star tree Gale-Stewart game that was used to get the exponential rates guarantee, we use the VCL Gale-Stewart game Bousquet et al. (2021) (cf. Figure 6). To be more precise, we use \(\lfloor n/5\rfloor\) of the label budget to get the labels of \(\lfloor n/5\rfloor\) unlabeled points that come i.i.d. from \(\mathrm{P}_{\mathcal{X}}\). Then, we execute the VCL game on \(\Theta(\sqrt{n})\) different batches of size \(\Theta(\sqrt{n})\). Each of these games induces a _partial_ concept class. We show how to obtain a \(\mathrm{P}\)-dependent bound on the VC dimension that holds for most of these classes. Moreover, we show that for most of these classes the data-generating distribution \(\mathrm{P}\) is _realizable_. Finally, we design a single active learning algorithm that combines information from all these classes and achieves sublinear learning rates. This algorithm builds upon Hanneke (2012) but is modified to work with partial concept classes instead of total concept classes. This requires a very different analysis and is the most technically involved part of our work.

Let us now explain the main ideas of this algorithm and the challenges behind it. As we mentioned before, the number of queries that the algorithm from Hanneke (2012) needs to achieve the sublinear error rate depends on the underlying data-generating distribution. Thus, we cannot just get a large enough number of unlabeled samples, consider the uniform distribution over them and use the algorithm on this distribution. This is because the learning rate for \(\mathbb{H}\) would depend on the uniform distribution \(U_{S}\) over the sample \(S\) and not on the data-generating distribution \(\mathrm{P}\). To illustrate the ideas of the algorithm, we consider five different streams of i.i.d. (unlabeled) data \(S_{1},S_{2},S_{3},S_{4},S_{5}\). For the purposes of the subsequent discussion, we can imagine that these streams have infinite size, but as explained in description of the algorithm, we only need \(\mathrm{poly}(n)\) unlabeled points. Let us first explain the use of \(S_{5}\). We use \(n/5\) of our query budget to obtain the labels of the first \(n/5\) points and then we use them to train a _supervised_ learning algorithm from Bousquet et al. (2021) that achieves linear rate \(O(1/n)\). This is used for technical reasons in our analysis and in order to ensure that the classifier we output has, at most, linear error rate no matter how the active learning component of our algorithm behaves. Next, we use \(n/5\) of the query budget to obtain the labels of the first \(n/5\) points from \(S_{1}\). Then, we run the VCL game on these labeled datasets of size \(\sqrt{n}/5\) and obtain \(\sqrt{n}\) different pattern avoidance functions \(\widehat{y}_{\sqrt{n}/5}^{i}\) that take as input \(\ell_{\sqrt{n}/5}^{i}\) points (cf. Appendix D.2), where \(i\in[\sqrt{n}]\). Let

\[\mathcal{F}_{\sqrt{n}/5}^{i}:=\left\{f:\mathcal{X}\to\{0,1,\star\}:(f(x_{1}), \ldots,f(x_{\ell_{\sqrt{n}/5}^{i}}))\neq\widehat{y}_{\sqrt{n}/5}^{i}(x_{1}, \ldots,x_{\ell_{\sqrt{n}/5}^{i}})\right\},i\in[\sqrt{n}]\,.\]

First, we show that for a \((1-o(1))\)-fraction of these partial concept classes \(\mathrm{P}\) is a realizable distribution. Intuitively, this means that the partial concept class we obtain by running the VCL game on \(\sqrt{n}\) many points is the same as the class we would have obtained if we were to run the game on infinitely many points (cf. Lemma D.4). Next, we need to estimate some number \(\widehat{\mathrm{d}}_{n}\in\mathbb{N}\) which, as \(n\to\infty\), converges to the \(9/10\)-quantile \(\mathrm{d}^{*}\) of the distribution of the VC dimension of the partial concept classes that are obtained by running the VCL game on _infinitely_ many samples. We let

\[\widehat{\mathrm{d}}_{n}:=\min_{d\in\mathbb{N}}\left\{\exists i_{1},i_{2}, \ldots,i_{9/10\cdot\sqrt{n}}\in[\sqrt{n}]:i_{1}<i_{2}<\ldots<i_{9/10\cdot\sqrt {n}},\mathrm{d}\left(\mathcal{F}_{\sqrt{n}/5}^{i_{j}}\right)\leq d,\forall j \in[9/10\sqrt{n}]\right\}\,,\]

where \(\mathrm{d}(\mathcal{F})\) denotes the VC dimension of class \(\mathcal{F}\). Lemma D.5 shows that, for large enough \(n\), \(\widehat{\mathrm{d}}_{n}=\mathrm{d}^{*}\), with high probability, where \(\mathrm{d}^{*}\in\mathbb{N}\) is such that with probability at least \(9/10\) over the random draw2 of the partial class, its VC dimension is at most \(\mathrm{d}^{*}\). One technical complication we need to handle is that the concept classes we have obtained are estimated from a game on \(\sqrt{n}\) many points instead of infinitely many points, so a \(o(1)\)-fraction of them do not correspond to samples from the correct distribution. To do that we use a robust version of the well-known Dvoretzky-Kiefer-Wolfowitz (DKW) inequality (cf. Theorem D.1) for estimating the CDF.

Footnote 2: This random draw is induced by an execution of the VCL game on infinitely many i.i.d. points from \(\mathrm{P}\).

Next, we use another \(n/5\) of the query budget to obtain the labels of the first \(n/5\) points of \(S_{2}\). We will make two distinctions regarding this stream. For the purposes of the analysis, we consider a fixed stream of infinitely many i.i.d. samples from \(\mathrm{P}\) and we denote it by \(S_{2}^{\infty}\), but in the actual algorithm we use a dataset of size \(\Theta(n)\) and we denote it by \(S_{2}^{n}\). We define

\[V_{n/5}^{i}:=\left\{f\in\mathcal{F}_{\sqrt{n/5}}^{i}:f(x)=y\text{ for the first $n/5$ points in $S_{2}^{\infty}$}\right\}\,,\]

to be the version space of \(\mathcal{F}_{\sqrt{n/5}}^{i}\) defined on the first \(n/5\) examples of \(S_{2}^{\infty}\). Moreover, we let \(V_{\mathrm{d}^{*},n/5}\) be a random version space that is sampled from the following process: we run the VCL game on an infinite stream of labeled data from \(\mathrm{P}\) to get a pattern avoidance function \(\widetilde{y}\) and then we define the partial concept class \(\widetilde{\mathcal{F}}\) in the same way as before. If the VC dimension of this class is greater than \(\mathrm{d}^{*}\) we discard it and restart the process. Otherwise, we let \(V_{\mathrm{d}^{*},n/5}\) be the version space of \(\widetilde{\mathcal{F}}\) on the first \(n/5\) labeled points of \(S_{2}^{\infty}\). We take \(\mathrm{d}^{*}\) to be the \(9/10-\)quantile of \(\widetilde{\mathrm{P}}\) as described before (cf. Lemma D.5). Given some \(k\in\mathbb{N}\), let \(p_{n,k}:=\mathbb{E}[\mathrm{P}^{k}(x_{1},\ldots,x_{k}\text{ VC shattered by }V_{\mathrm{d}^{*},n/5})|S_{2}^{\infty}]\) where the expectation is over the draw of \(V_{\mathrm{d}^{*},n/5}\), given the fixed \(S_{2}^{\infty}\). Let \(k^{*}\in\mathbb{N}\) be the largest number such that \(\lim_{n\to\infty}p_{n,k^{*}}\neq 0.\) Notice that since, by definition, the VC dimension is bounded by \(\mathrm{d}^{*}\) such a number \(k^{*}\) exists. From here on, we will only consider the version spaces \(V^{i}_{n/5}\) that are obtained from some partial class with VC dimension at most \(\widehat{\mathrm{d}}_{n}.\) Let \(p_{n,k,i}:=\mathrm{P}^{k}(x_{1},\ldots,x_{k}\) VC shattered by \(V^{i}_{n/5}).\) Notice that for every \(k\leq\widehat{\mathrm{d}}_{n}\) and every \(i\in[\sqrt{n}]\) we can estimate this quantity to arbitrary precision using only _unlabeled_ examples. We denote by \(\widehat{p}_{n,k,i}\) these estimates.

We now consider the first \(n^{2}\) unlabeled points of the third data stream \(S_{3}.\) For each such point \(X\), let \(p^{X}_{n,k}:=\mathbb{E}[\mathrm{P}^{k}(x_{1},\ldots,x_{k},X\text{ VC shattered by }V_{\mathrm{d}^{*},n/5})|S_{2}^{\infty},X].\) Moreover, for each \(y\in\{0,1\}\) let

\[V^{(X,y)}_{\mathrm{d}^{*},n/5}:=\left\{f\in V_{\mathrm{d}^{*},n/5}:f(X)=y\right\},\;\;p^{(X,y)}_{n,k}:=\mathbb{E}[\mathrm{P}^{k}(x_{1},\ldots,x_{k}\text{ VC shattered by }V^{(X,y)}_{\mathrm{d}^{*},n/5})|S_{2}^{\infty},X],y\in\{0,1\}\,.\]

We define the quantities \(p^{X}_{n,k,i},p^{(X,y)}_{n,k,i}\) in the same way for the realized version spaces. Again, by Hoeffding's bound, we can estimate these quantities to arbitrary precision using unlabeled data. Similarly as before, we denote these estimates by \(\widehat{p}^{X}_{n,k,i},\widehat{p}^{(X,y)}_{n,k,i}.\) The idea is to make use of Lemma D.4 and show that the classes which have been obtained by a VCL game that has not converged will only affect our estimates by some \(o(1)\). This is formalized in Proposition D.6. Thus, we can use \(\widehat{p}_{n,k,i},\widehat{p}^{X}_{n,k,i},\widehat{p}^{(X,y)}_{n,k,i},\) in order to estimate \(p_{n,k,},p^{X}_{n,k},p^{(X,y)}_{n,k}.\) We denote these estimates by \(\widehat{p}_{n,k,},\widehat{p}^{X}_{n,k},\)\(\widehat{p}^{(X,y)}_{n,k}.\) These are the key quantities we use to _infer_ the labels of unlabeled points.

Our algorithm tries to infer the label of each unlabeled point \(X\in S_{3}\) (cf. Figure 7) in the following way: if \(\widehat{p}^{X}_{n,k}\geq\frac{\widehat{p}_{n,k}}{2}\) then we query the label of \(X,\) otherwise we infer the label to be \(\arg\max_{y\in\{0,1\}}\widehat{p}^{(X,y)}_{n,k}.\) Lemma D.7 shows that the inferences are correct, when \(n\) is large enough.

The main ingredient of the proof that remains to be handled is to show that the number of label queries we submit is _sublinear_ in \(n.\) For that, it is sufficient to show that the probability that we query the label of a point is \(o(1).\) Lemma D.8 shows that when \(k=k^{*},\) this is indeed the case.

Finally, since we do not know the true value of \(k^{*},\) we run the algorithm for every \(k\leq\widehat{\mathrm{d}}_{n}.\) The active learning component of the algorithm gives us \(\widehat{\mathrm{d}}_{n}+1\) different labeled datasets, which we use to train \(\widehat{\mathrm{d}}_{n}+1\) instances of a supervised learning algorithm, such as the one from Bousquet et al. (2021). Our analysis so far has shown that for sufficiently large \(n,\) at least one of these datasets will be correctly labeled with size \(\omega(n).\) Thus, since the supervised learning algorithm has error linear in the size of its training set, at least one of these executions will give a classifier that has error \(o(1/n).\) The last step is to run a tournament among the \(\mathrm{d}_{n}+2\) different classifiers3 to choose the best one. This is handled by Lemma D.9(Hanneke, 2012). The main result of this section (cf. Theorem D.10), follows as a corollary of the results we have discussed. All the steps are summarized in Figure 7.

Footnote 3: Recall that we have one more classifier from \(S_{5}.\)

Lastly, a lower bound from Hanneke et al. (2022) completes our characterization (cf. Theorem D.11).

## 5 Conclusion

In this work we have provided a complete characterization of the optimal learning rates in active learning. It is an open question if it also holds when the learner knows the distribution \(\mathrm{P}_{\mathcal{X}}.\)

## Acknowledgments

Amin Karbasi acknowledges funding in direct support of this work from NSF (IIS-1845032), ONR (N00014- 19-1-2406), and the AI Institute for Learning-Enabled Optimization at Scale (TILOS). Shay Moran is a Robert J. Shillman Fellow; he acknowledges support by ISF grant 1225/20, by BSF grant 2018385, by Israel PBC-VATAT, by the Technion Center for Machine Learning and Intelligent Systems (MLIS), and by the the European Union (ERC, GENERALIZATION, 101039692). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council Executive Agency. Neither the European Union nor the granting authority can be held responsible for them. Grigoris Velegkas was supported in part by the AI Institute for Learning-Enabled Optimization at Scale (TILOS).

## References

* Alon et al. (2021) N. Alon, S. Hanneke, R. Holzman, and S. Moran. 2021. A Theory of PAC Learnability of Partial Concept Classes. In _Proceedings of the \(62^{\mathrm{nd}}\) Annual Symposium on Foundations of Computer Science_.
* Attias et al. (2024) Idan Attias, Steve Hanneke, Alkis Kalavasis, Amin Karbasi, and Grigoris Velegkas. 2024. Universal Rates for Regression: Separations between Cut-Off and Absolute Loss. In _The Thirty Seventh Annual Conference on Learning Theory_. PMLR, 359-405.
* Balcan et al. (2006) M.-F. Balcan, A. Beygelzimer, and J. Langford. 2006. Agnostic Active Learning. In _Proceedings of the \(23^{\mathrm{rd}}\) International Conference on Machine Learning_.
* Balcan et al. (2009) M.-F. Balcan, A. Beygelzimer, and J. Langford. 2009. Agnostic Active Learning. _J. Comput. System Sci._ 75, 1 (2009), 78-89.
* Balcan et al. (2010) M.-F. Balcan, S. Hanneke, and J. Wortman Vaughan. 2010. The True Sample Complexity of Active Learning. _Machine Learning_ 80, 2-3 (2010), 111-139.
* Beygelzimer et al. (2016) A. Beygelzimer, D. J. Hsu, J. Langford, and C. Zhang. 2016. Search improves label for active learning. In _Advances in Neural Information Processing Systems 29_.
* Blumer et al. (1989) A. Blumer, A. Ehrenfeucht, D. Haussler, and M. Warmuth. 1989. Learnability and the Vapnik-Chervonenkis Dimension. _Journal of the Association for Computing Machinery_ 36, 4 (1989), 929-965.
* Bousquet et al. (2022) Olivier Bousquet, Steve Hanneke, Shay Moran, Jonathan Shafer, and Ilya Tolstikhin. 2022. Fine-Grained Distribution-Dependent Learning Curves. _arXiv preprint arXiv:2208.14615_ (2022).
* Bousquet et al. (2021) O. Bousquet, S. Hanneke, S. Moran, R. van Handel, and A. Yehudayoff. 2021. A Theory of Universal Learning. In _Proceedings of the \(53^{\mathrm{rd}}\) Annual ACM Symposium on the Theory of Computing_.
* Cheung et al. (2023) Tsun-Ming Cheung, Hamed Hatami, Pooya Hatami, and Kaave Hosseini. 2023. Online Learning and Disambiguations of Partial Concept Classes. _arXiv preprint arXiv:2303.17578_ (2023).
* Cohn et al. (1994) D. Cohn, L. Atlas, and R. Ladner. 1994. Improving Generalization with Active Learning. _Machine Learning_ 15, 2 (1994), 201-221.
* Cohn (2013) Donald L Cohn. 2013. _Measure theory_. Vol. 1. Springer.
* Dasgupta (2005) S. Dasgupta. 2005. Coarse Sample Complexity Bounds for Active Learning. In _Advances in Neural Information Processing Systems \(18\)_.
* Dasgupta et al. (2007) S. Dasgupta, D. Hsu, and C. Monteleoni. 2007. A General Agnostic Active Learning Algorithm. In _Advances in Neural Information Processing Systems \(20\)_.
* Gale and Stewart (1953) David Gale and Frank M Stewart. 1953. Infinite games with perfect information. _Contributions to the Theory of Games 2_, 245-266 (1953), 2-16.
* Hanneke (2007a) S. Hanneke. 2007a. A Bound on the Label Complexity of Agnostic Active Learning. In _Proceedings of the \(24^{\mathrm{th}}\) International Conference on Machine Learning_.
* Hanneke (2007b) S. Hanneke. 2007b. Teaching Dimension and the Complexity of Active Learning. In _Proceedings of the \(20^{\mathrm{th}}\) Conference on Learning Theory_.
* Hanneke (2009) S. Hanneke. 2009. _Theoretical Foundations of Active Learning_. Ph. D. Dissertation. Machine Learning Department, School of Computer Science, Carnegie Mellon University.
* Hanneke (2012) S. Hanneke. 2012. Activized Learning: Transforming Passive to Active with Improved Label Complexity. _Journal of Machine Learning Research_ 13, 5 (2012), 1469-1587.
* Hanneke (2014) S. Hanneke. 2014. Theory of Disagreement-Based Active Learning. _Foundations and Trends in Machine Learning_ 7, 2-3 (2014), 131-309.
* Hanneke et al. (2022) Steve Hanneke, Amin Karbasi, Shay Moran, and Grigoris Velegkas. 2022. Universal Rates for Interactive Learning. In _Advances in Neural Information Processing Systems_.
* Hanneke et al. (2014)Steve Hanneke, Shay Moran, and Qian Zhang. 2023. Universal Rates for Multiclass Learning. In _The Thirty Sixth Annual Conference on Learning Theory_. PMLR, 5615-5681.
* Hanneke and Yang (2015) S. Hanneke and L. Yang. 2015. Minimax Analysis of Active Learning. _Journal of Machine Learning Research_ 16, 12 (2015), 3487-3602.
* Haussler et al. (1994) D. Haussler, N. Littlestone, and M. Warmuth. 1994. Predicting \(\{0,1\}\)-Functions on Randomly Drawn Points. _Information and Computation_ 115, 2 (1994), 248-292.
* Hodges et al. (1993) Wilfrid Hodges, Hodges Wilfrid, et al. 1993. _Model theory_. Cambridge University Press.
* Kalavasis et al. (2022) Alkis Kalavasis, Grigoris Velegkas, and Amin Karbasi. 2022. Multiclass Learnability Beyond the PAC Framework: Universal Rates and Partial Concept Classes. _arXiv preprint arXiv:2210.02297_ (2022).
* Kechris (2012) Alexander Kechris. 2012. _Classical descriptive set theory_. Vol. 156. Springer Science & Business Media.
* Littlestone (1988) N. Littlestone. 1988. Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. _Machine Learning_ 2 (1988), 285-318.
* Vapnik and Chervonenkis (1971) V. Vapnik and A. Chervonenkis. 1971. On the uniform convergence of relative frequencies of events to their probabilities. _Theory of Probability and its Applications_ 16, 2 (1971), 264-280.
* Wiener et al. (2015) Y. Wiener, S. Hanneke, and R. El-Yaniv. 2015. A Compression Technique for Analyzing Disagreement-Based Active Learning. _Journal of Machine Learning Research_ 16, 4 (2015), 713-745.
* Yang and Hanneke (2013) L. Yang and S. Hanneke. 2013. Activized Learning with Uniform Classification Noise. In _Proceedings of the 30\({}^{\rm th}\) International Conference on Machine Learning_.

Omitted Details from Section 1

### Formal Definition of Learning Setting

We recall some basic notions of measures and probabilities on Polish spaces. For a detailed treatment the reader is referred to Kechris (2012); Cohn (2013). Our presentation follows Bousquet et al. (2021).

Polish Spaces.A _Polish space_ is a separable topological space that admits a complete metric. For example, this category includes \(\mathbb{R}^{n}\), any compact metric space, any separable Banach space, etc.

Universally Measurable Functions.Let \(\mathfrak{F}\) be the Borel \(\sigma\)-field on some Polish space \(\mathcal{X}\) and let \(\mu\) be a probability measure. We denote by \(\mathfrak{F}_{\mu}\) the completion of \(\mathfrak{F}\) under \(\mu\), i.e., the collections of all subsets of \(\mathcal{X}\) that differ from a Borel set on a set of zero measure. A set \(B\subseteq\mathcal{X}\) is called _universally measurable_ if \(B\in\mathfrak{F}_{\mu}\) for every probability measure \(\mu\). Moreover, a function \(f:\mathcal{X}\rightarrow\mathcal{Y}\) is called universally measurable if \(f^{-1}(B)\) is universally measurable, for any universally measurable set \(B\). An important property is that universally measurable sets and functions on Polish spaces are the same as Borel sets, from a probabilistic point of view.

We are now ready to provide the definition of measurability of a concept class \(\mathbb{H}\).

**Definition A.1** (Measurability of \(\mathbb{H}\)).: _Let \(\mathcal{X}\) be a Polish space. We say that a concept class \(\mathbb{H}\subseteq\{0,1\}^{\mathcal{X}}\), is measurable if there is a Polish space \(\Theta\) and a Borel-measurable map \(h:\mathcal{X}\times\Theta\rightarrow\{0,1\}\) so that \(\mathbb{H}=\{h(\theta,\cdot):\theta\in\Theta\}\)._

We underline that Definition A.1 is very general and its only requirement is that \(\mathbb{H}\) can be parameterized in some reasonable way.

### Omitted Preliminaries

Gale-Stewart Games.We briefly discuss some basic and useful facts about Gale-Stewart games, a concept that was recently introduced to the learning theory community by Bousquet et al. (2021). Our discussion follows Bousquet et al. (2021); Hanneke et al. (2022). We refer to Bousquet et al. (2021) and references therein for a more detailed presentation. Let us fix sequences of sets \(\mathcal{X}_{t},\mathcal{Y}_{t}\) for \(t\geq 1\). We consider infinite games between two players, a learner \(\text{P}_{\text{L}}\) and an adversary \(\text{P}_{\text{A}}\), where in each round \(t\geq 1\), \(\text{P}_{\text{A}}\) selects an element \(x_{t}\in\mathcal{X}_{t}\), and then \(\text{P}_{\text{L}}\) selects an element \(y_{t}\in\mathcal{Y}_{t}\). The rules of the game are defined by a set \(\mathcal{W}\subseteq\prod_{t\geq 1}(\mathcal{X}_{t}\times\mathcal{Y}_{t})\) of winning sequences for \(\text{P}_{\text{L}}\). This means that after an infinite sequence of consecutive plays \(x_{1},y_{1},x_{2},y_{2},\ldots\), we say that \(\text{P}_{\text{L}}\) wins if \((x_{1},y_{1},x_{2},y_{2},\ldots)\in\mathcal{W}\); otherwise the winner is \(\text{P}_{\text{A}}\).

A _strategy_ is a rule used by each of the players to determine their next move, given the current state and the history of the game. Formally, a strategy for \(\text{P}_{\text{A}}\) is a sequence of functions \(f_{t}:\prod_{s<t}(\mathcal{X}_{s}\times\mathcal{Y}_{s})\rightarrow\mathcal{X}_ {t}\) for \(t\geq 1\), so that \(\text{P}_{\text{A}}\) plays \(x_{t}=f_{t}(x_{1},y_{1},\ldots,x_{t-1},y_{t-1})\) in round \(t\). Similarly, a strategy for \(\text{P}_{\text{L}}\) is a sequence of \(g_{t}:\prod_{s<t}(\mathcal{X}_{s}\times\mathcal{Y}_{s})\times\mathcal{X}_{t} \rightarrow\mathcal{Y}_{t}\) for \(t\geq 1\), so that \(\text{P}_{\text{L}}\) plays \(y_{t}=g_{t}(x_{1},y_{1},\ldots,x_{t-1},y_{t-1},x_{t})\) in round \(t\). We say that a strategy for \(\text{P}_{\text{A}}\) is _winning_ if playing that strategy always makes \(\text{P}_{\text{A}}\) win the game no matter what \(\text{P}_{\text{L}}\) plays; a winning strategy for \(\text{P}_{\text{L}}\) is defined similarly. The main question in these infinite games is determine conditions under which one of the two players has a winning strategy in the game. We remark that when the game is finite it is not hard to easy that exactly one of the two players has such a strategy. In the context of infinite games, such a condition was introduced by Gale and Stewart (1953): a \(\mathcal{W}\) is _finitely decidable_ if for every sequence of plays \((x_{1},y_{1},x_{2},y_{2},\ldots)\in\mathcal{W}\), there exists some \(n<\infty\) so that

\[(x_{1},y_{1},\ldots,x_{n},y_{n},x^{\prime}_{n+1},y^{\prime}_{n+1},x^{\prime}_{n +2},y^{\prime}_{n+2},\ldots)\in\mathcal{W}\]

for all choices of \(x^{\prime}_{n+1},y^{\prime}_{n+1},x^{\prime}_{n+2},y^{\prime}_{n+2},\ldots\) In words, the condition that "\(\mathcal{W}\) is finitely decidable" means that if \(\text{P}_{\text{L}}\) wins the game, then she knows that after playing a _finite_ number of rounds. Conversely, \(\text{P}_{\text{A}}\) wins the game when \(\text{P}_{\text{L}}\) does not win after any finite number of rounds.

Such a game whose set \(\mathcal{W}\) is finitely decidable is called a _Gale-Stewart game_. We use the following important result about Gale-Stewart games.

**Remark A.2** (Gale and Stewart (1953); Hodges et al. (1993); Kechris (2012)).: _In any Gale-Stewart game exactly one between \(P_{\text{A}}\) and \(P_{\text{L}}\) has a winning strategy._The above result is purely existential and provides no information about the complexity of the winning strategies. Importantly, it is unclear whether winning strategies can be chosen to be measurable. The next result from Bousquet et al. (2021) addresses this concern.

**Theorem A.3** (Theorem B.1 from Bousquet et al. (2021)).: _Let \(\{X_{t}\}_{t\geq 1}\) be Polish spaces and \(\{Y_{t}\}_{t\geq 1}\) be countable sets. Consider a Gale-Stewart game whose set \(\mathcal{W}\subseteq\prod_{t\geq 1}(X_{t}\times Y_{t})\) of winning strategies for \(P_{L}\) is finitely decidable and coanalytic. Then there is a universally measurable winning strategy._

The following remark shows that we can, equivalently, let the strategy of the the learner \(\text{P}_{\text{L}}\) and the adversary \(\text{P}_{\text{A}}\) depend only on the choices of their opponent in the previous rounds.

**Remark A.4** (Bousquet et al. (2021)).: _The strategy of \(P_{L}\) is defined to be a sequence of functions \(y_{t}=f_{t}(x_{1},y_{1},\ldots,x_{t-1},y_{t-1})\) of the history of the game, where \(y_{1},\ldots,y_{t-1}\) are defined similarly. Thus, we can equivalently let \(y_{t}=f_{t}(x_{1},\ldots,x_{t-1})\). The same holds for the strategy of \(P_{A}\)._

Partial Concept Classes.The traditional PAC learning framework studies (mainly) _total_ concept classes, i.e., classes of functions \(h:\mathcal{X}\to\{0,1\}\) that are defined on _every_ point \(x\in\mathcal{X}\). The caveat with total functions is that they do not provide a direct way to express _data-dependent_ constraints. For example, if the space \(\mathcal{X}\) is high-dimensional but the data that the leaner has to classify lie in a low-dimensional space, it is not clear how to encode this restriction through total concepts. This is very relevant to practical application of machine learning such as classification of images; the space \(\mathcal{X}\) is the set of all possible values of the pixels of the image but most of these configurations of the pixels do not even correspond to an image of an object of interest. Alon et al. (2021) proposed and studied an extension of the PAC framework that allows one to capture such assumptions using _partial_ concept classes, i.e., sets of functions \(f:\mathcal{X}\to\{0,1,\star\}\), where \(f(x)=\star\) means that \(f\) is undefined at \(x\). In the context of classification of images, when a classifier returns \(\star\) it means that \(x\) does not belong to the space of valid images. Alon et al. (2021) extend a lot of notions, such as PAC learnability and the VC dimension, from the setting of total concept classes to the setting of partial concept classes (see, e.g., Definition A.6). To show how one can use partial classes, to express data-dependent constraints, we remark that Alon et al. (2021) illustrated how the class of \(d\)-dimensional linear classifiers with margin \(\gamma>0\) can be formulated as a partial class: we say that a sample \((x_{1},y_{1}),\ldots,(x_{n},y_{n})\in\mathbb{R}^{d}\times\{0,1\}\) is \((R,\gamma)\)-separable if all the points \(x_{1},\ldots,x_{n}\) lie in a (euclidean) ball of radius \(R\), the \(0\)-labeled examples and the \(1\)-labeled examples are linearly separable, and the (euclidean) distance between the \(0\)-labeled examples and \(1\)-labeled examples is at least \(2\gamma\). Then, the class

\[\mathcal{F}_{R,\gamma}=\big{\{}f:\mathbb{R}^{d}\to\{0,1\star\}: (\forall x_{1},\ldots,x_{n})\in\mathrm{supp}(f):\] \[(x_{1},(f(x_{1})),\ldots,(x_{n},(f(x_{n}))\text{ is }(R,\gamma)- \text{separable}\big{\}},\]

where \(\mathrm{supp}(f)\) is the set of all points where \(f(x)\neq\star\), expresses the set of functions that satisfy these constraints. Remarkably, the VC dimension of \(\mathcal{F}\) is bounded by \(O\left(\frac{R^{2}}{\gamma^{2}}\right)\)(Alon et al., 2021). Perhaps surprisingly, even though the PAC learnability of partial classes is characterized by the VC dimension (as it is the case with total classes), the ERM algorithm provably fails to learn partial classes. Thus, the algorithmic landscape is much richer and complicated compared to total classes. Moreover, there is no algorithmic way to extend a partial concept class to a total concept class without significantly increasing its VC dimension. For details, we refer to (Alon et al., 2021).

One-Inclusion Graph Algorithm.We state formally the guarantees of the one-inclusion graph algorithm (Haussler et al., 1994).

**Theorem A.5** (One-Inclusion Graph Algorithm (Haussler et al., 1994)).: _For any (total) concept class \(\mathbb{H}\) whose VC dimension is bounded by \(\mathrm{d}<\infty\), there is an algorithm \(\mathbb{A}:(\mathcal{X}\times\{0,1\})^{*}\times\mathcal{X}\to\{0,1\}\) such that for any \(n\in\mathbb{N}\) and any sequence \(\{(x_{1},y_{1}),\ldots,(x_{n},y_{n})\}\in(\mathcal{X}\times\{0,1\})^{n}\) that is realizable w.r.t. \(\mathbb{H}\),_

\[\frac{1}{n!}\sum_{\sigma\in\mathrm{Sym}(n)}\mathbb{1}\{\mathbb{A}(x_{\sigma(1 )},y_{\sigma(1)},\ldots,x_{\sigma(n-1)},y_{\sigma(n-1)},x_{\sigma(n)})\neq y_{ \sigma(n)}\}\leq\frac{\mathrm{d}}{n},\]

_where \(\mathrm{Sym}(n)\) denotes the symmetric group of permutations of \(\{1,\ldots,n\}\)._In particular, Theorem A.5 implies immediately that if \((x_{1},y_{1}),\ldots,(x_{n},y_{n})\) are i.i.d. from \(\mathrm{P}\) then the classifier \(\tilde{h}_{n}(\cdot):=\mathbb{A}(x_{1},y_{1},\ldots,x_{n},y_{n},\cdot)\) has \(\mathbb{E}[\mathrm{er}(\tilde{h}_{n})]\leq\frac{\mathrm{d}}{n+1}\). We remark that Alon et al. (2021) showed that this result also holds for partial concept classes.

### Omitted Definitions

**Definition A.6** (VC Dimension of Partial Concept Classes (Alon et al., 2021)).: _For a partial concept class \(\mathcal{F}\subseteq\{0,1,\star\}^{\mathcal{X}}\), the VC dimension of \(\mathcal{F}\) is defined to be the largest number \(\mathrm{d}\in\mathbb{N}\) such that \(\exists(x_{1},\ldots,x_{\mathrm{d}})\in\mathcal{X}^{\mathrm{d}}\) such that \(\{(f(x_{1}),\ldots,f(x_{\mathrm{d}})):f\in\mathcal{F}\}=\{0,1\}^{d}\). Such a sequence \((x_{1},\ldots,x_{\mathrm{d}})\) is said to be shattered by \(\mathcal{F}\). If there is no bound on \(\mathrm{d}\) we say that the VC dimension is \(\infty\)._

The following definition of the star number is an adaptation of the definition in (Hanneke and Yang, 2015).

**Definition A.7** (Star Number of Partial Concept Classes).: _For a partial concept class \(\mathcal{F}\subseteq\{0,1,\star\}^{\mathcal{X}}\), the star number of \(\mathcal{F}\) is defined to be the largest number \(\mathfrak{s}\in\mathbb{N}\) such that \(\exists(x_{1},\ldots,x_{\mathrm{s}})\in\mathcal{X}^{\mathfrak{s}}\) such that \(\exists f_{0}\in\mathcal{F}\) and \(\forall i\in[\mathfrak{s}],\exists f_{i}\in\mathcal{F}:f_{i}(x_{i})=1-f_{0}(x _{i}),f_{i}(x_{j})=f_{0}(x_{j})\neq\star,\forall j\in[\mathfrak{s}]\setminus \{i\}\). If there is no bound on \(\mathfrak{s}\) we say that the star number is \(\infty\)._

**Definition A.8** (Littlestone Tree (Bousquet et al., 2021)).: _A Littlestone tree for \(\mathbb{H}\subseteq\{0,1\}^{\mathcal{X}}\) is a complete binary tree of depth \(d\leq\infty\) whose internal nodes are labeled by \(\mathcal{X}\), and whose two edges connecting a node to its children are labeled by \(\{0,1\}\), such that every path of length at most \(d\) emanating from the root is consistent with a concept \(h\in\mathbb{H}\). Formally, a Littlestone tree is a collection_

\[\bigcup_{0\leq\ell<d}\big{\{}x_{\vec{u}}:\vec{u}\in\{0,1\}^{\ell}\big{\}}=\{x _{\emptyset}\}\cup\{x_{0},x_{1}\}\cup\{x_{00},x_{01},x_{10},x_{11}\}\cup\ldots\]

_such that for every path \(\vec{y}\in\{0,1\}^{d}\) and \(n<d\), there exists \(h\in\mathbb{H}\) so that \(h(x_{\vec{y}_{\leq\ell}})=y_{\ell+1}\) for \(0\leq\ell\leq n\). We say that \(\mathbb{H}\) has an infinite Littlestone tree if there is a Littlestone tree for \(\mathbb{H}\) of depth \(d=\infty\)._

**Definition A.9** (Star Tree).: _A Star tree for \(\mathbb{H}\subseteq\{0,1\}^{\mathcal{X}}\) of consists of a collection_

\[\bigcup_{0\leq\ell<d}\big{\{}(x_{\vec{u}},z_{\vec{u}})\in\big{(}\mathcal{X}^{ \ell+1},\{0,1\}^{\ell+1}\big{)}:\vec{u}\in\{0\}\times\{0,1\}\times\ldots\times \{0,1,\ldots,\ell\}\big{\}}\]

_such that for every level \(n<d\), and \(\vec{y}\in\{0\}\times\{0,1\}\times...\times\{0,1,\ldots,n-1\}\), there exists some \(h\in\mathbb{H}\) such that \(h(x^{i}_{\vec{y}_{\leq k}})=f(z^{i}_{\vec{y}_{\leq k}},y_{k+1})\) for all \(0\leq i\leq k\) and \(0\leq k\leq n\), where we denote_

\[\vec{y}_{\leq k}=(y_{1},y_{2},\ldots,y_{k}),\,\,\,x_{\vec{y}_{\leq k}}=(x^{0} _{\vec{y}_{\leq k}},\ldots,x^{k}_{\vec{y}_{\leq k}}),\,\,\,z_{\vec{y}_{\leq k} }=(z^{0}_{\vec{y}_{\leq k}},\ldots,z^{k}_{\vec{y}_{\leq k}}),\]

\[f(z^{i}_{\vec{y}_{\leq k}},y_{k+1})=\begin{cases}z^{i}_{\vec{y}_{\leq k}},& \text{if }y_{k+1}\neq i\\ 1-z^{i}_{\vec{y}_{\leq k}},&\text{otherwise}\end{cases}.\]

_We say that \(\mathbb{H}\) has an infinite star tree if it has a star tree of depth \(d=\infty\)._

**Definition A.10** (VCL Tree Bousquet et al. (2021)).: _A Vapnik-Chervonenkis-Littlestone (VCL) tree for \(\mathbb{H}\subseteq\{0,1\}^{\mathcal{X}}\) of depth \(d\leq\infty\) consists of a collection_

\[\bigcup_{0\leq\ell<d}\{x_{\vec{u}}\in\mathcal{X}^{\ell+1},\vec{u}\in\{0,1\} \times\{0,1\}^{2}\times...\times\{0,1\}^{\ell}\}\]

_such that for every level \(n<d\), and \(\vec{y}\in\{0,1\}\times\{0,1\}^{2}\times\{0,1\}^{n+1}\), there exists some \(h\in\mathbb{H}\) such that \(h(x^{i}_{\vec{y}_{\leq k}})=y^{i}_{k+1}\) for all \(0\leq i\leq k\) and \(0\leq k\leq n\), where we denote_

\[\vec{y}_{\leq k}=(y^{0}_{1},(y^{0}_{2},y^{1}_{2}),\ldots,(y^{0}_{k},\ldots,y^{k-1 }_{k})),\,\,\,x_{\vec{y}_{\leq k}}=(x^{0}_{\vec{y}_{\leq k}},\ldots,x^{k}_{ \vec{y}_{\leq k}}).\]

_We say that \(\mathbb{H}\) has an infinite VCL tree if it has a VCL tree of depth \(d=\infty\)._
**Arbitrarily Fast Rates (Hanneke et al., 2022):** Input is a label budget \(N\) and a rate function \(R(n)\).

1. \(m_{1}\leftarrow\left\lceil 2\ln(1/R(n))\right\rceil\).
2. \(m_{2}\leftarrow\left\lceil\frac{\ln\left(m_{1}2^{2}\lfloor\sqrt{m_{1}}\rfloor+ ^{2}/R(n)\right)}{R(n)}\right\rceil.\)
3. Create sets \(S_{1}=x_{1},\ldots,x_{m_{1}},S_{2}=x_{m_{1}+1},\ldots,x_{m_{2}}\).
4. Split \(S_{1}\) into \(\lfloor\sqrt{m_{1}}\rfloor\) batches of size \(\lfloor\sqrt{m_{1}}\rfloor\) and consider all the labeled prefixes of the batches in lexicographical order: \(b_{i,j}\) denotes the \(i\)-th batch with the labeled prefix \(j,1\leq j\leq 2^{\lfloor\sqrt{m_{1}}\rfloor+1}\).
5. Let \(\mathbb{A}_{0}(\cdot;b_{i,j})\) be the output of the ordinal SOA trained on \(b_{i,j}\) and denote \(g_{i,j}(x)=\mathbb{A}_{0}(x;b_{i,j})\). See (Bousquet et al., 2021).
6. Evaluate the classifiers \(g_{i,j}(\cdot)\) on the points in \(S_{2}\).
7. Define a set \(\mathbb{F}\) of equivalence classes: \(g_{i,j}\) and \(g_{i^{\prime},j^{\prime}}\) are in the same class iff they classify \(S_{2}\) the same.
8. For each \(F\in\mathbb{F}\), define \[\mathrm{rank}(F)=\min\bigg{\{}r:\exists\;1\leq i_{1}<i_{2}\ldots<i_ {\lfloor\sqrt{m_{1}}\rfloor/3}\leq\lfloor\sqrt{m_{1}}\rfloor,k_{1},\ldots,k_ {\lfloor\sqrt{m_{1}}\rfloor/3}\in[2^{r+1}]\] such that \(g_{i_{j},k_{j}}\in F,1\leq j\leq\lfloor\sqrt{m_{1}}\rfloor/3\bigg{\}}\), or \(\mathrm{rank}(F)=\infty\) if no such \(r\) exists.
9. Enumerate \(\mathbb{F}=\{\mathcal{F}_{1},\mathcal{F}_{2},\ldots\}\) so that \(\mathrm{rank}(\mathcal{F}_{\ell})\) is non-decreasing in \(\ell\), and pick any \(f_{\ell}\in\mathcal{F}_{\ell}\) for each \(\ell\).
10. For each distinct \(i,j\leq\lfloor\sqrt{n}\rfloor\) query the label of any point in \(S_{2}\) on which \(f_{i},f_{j}\) disagree.
11. If there is some \(f_{\hat{\ell}}\) which is correct on all the points we queried, return \(f_{\hat{\ell}}\).
12. Otherwise, return any \(f_{\ell}\).

## Appendix B Omitted Details from Section 2

### Omitted Details from Section 3

### Proof of Lemma 3.1

Before we prove our main result of this section, we present an omitted proof from the main body.

Proof.: Assume that \(\mathbb{H}\) has an infinite star tree. Then, the adversary can start from the root of the tree and play \((\vec{\xi}_{1},\vec{\zeta}_{1})=(\vec{x}_{\varnothing},\vec{z}_{\varnothing})\) and for every strategy \(\{\eta_{\tau}\}_{\tau\geq 1}\) of the learner, \(\mathrm{P}_{\mathrm{A}}\) can follow the path \(\vec{y}_{\leq\tau}=(\eta_{1},\eta_{2},\ldots,\eta_{\tau})\) and play \((\vec{x}_{\vec{y}_{\leq\tau}},\vec{z}_{\vec{y}_{\leq\tau}})\) in round \(\tau+1\). Since the tree is infinite, there is no \(\tau^{*}\in\mathbb{N}\) such that \(\mathbb{H}_{\vec{\xi}_{1},\vec{\zeta}_{1}\eta_{1},\ldots,\vec{\xi}_{\tau^{*}},\vec{\zeta}_{\tau^{*}},\eta_{\tau^{*}}}=\varnothing\).

For the other direction, assume that the adversary has a winning strategy. Then, we can define the tree

\[\mathcal{T}=\bigcup_{0\leq\ell<\infty}\big{\{}(\vec{x}_{\vec{q}},\vec{z}_{ \vec{q}})\in\big{(}\mathcal{X}^{\ell+1},\{0,1\}^{\ell+1}\big{)}:\vec{\eta}_{i} \in\{0,1,\ldots,i-1\},1\leq i\leq\ell\big{\}}\]

where \((\vec{x}_{\eta_{1},\ldots,\eta_{\tau-1}},\vec{z}_{\eta_{1},\ldots,\eta_{\tau-1 }})=(\vec{\xi}_{\tau}(\eta_{1},\ldots,\eta_{\tau-1}),\vec{\zeta}_{\tau}(\eta _{1},\ldots,\eta_{\tau-1}))\). The tree \(\mathcal{T}\) is infinite by the definition of the winning strategy in \(\mathfrak{G}\) for \(\mathrm{P}_{\mathrm{A}}\). To prove the universal measurability of the winning strategy of \(\mathrm{P}_{\mathrm{L}}\), using Lemma A.3 it suffices to show that the set of winning strategies \(\mathcal{W}\) of the learner

Figure 1: Arbitrarily Fast Rates Algorithm (Hanneke et al., 2022)

is coanalytic. To this end, we consider its complement

\[\mathcal{W}^{c} =\left\{(\vec{\xi},\vec{\zeta},\vec{\eta})\in\bigcup_{t=1}^{\infty} \left(\mathcal{X}^{t}\times\{0,1\}^{t}\times\{0,\ldots,t-1\}\right):\mathbb{H} _{\vec{\xi}_{1},\vec{\zeta}_{1},\eta_{1},\ldots,\vec{\xi}_{t},\vec{\zeta}_{t}, \eta_{t}}\neq\varnothing\right\}\] \[=\bigcap_{t=1}^{\infty}\bigcup_{\theta\in\Theta}\bigcap_{s=1}^{t} \left\{(\vec{\xi},\vec{\zeta},\vec{\eta}):\begin{array}{ll}h(\theta,\vec{\xi} _{s}^{i})=\vec{\zeta}_{s}^{i},&\text{if }\eta_{s}\neq i\\ h(\theta,\vec{\xi}_{s}^{i})=1-\vec{\zeta}_{s}^{i},&\text{if }\eta_{s}=i\end{array} \right.,0\leq i<s\right\}\]

Notice that the set \(\left\{\begin{array}{ll}h(\theta,\vec{\xi}_{s}^{i})=\vec{\zeta}_{s}^{i},& \text{if }\eta_{s}\neq i\\ h(\theta,\vec{\xi}_{s}^{i})=1-\vec{\zeta}_{s}^{i},&\text{if }\eta_{s}=i\end{array} \right.,0\leq i<s\right\}\) is Borel by the measurability assumption. Also, the intersection in the above expression are countable and the union is a projection of a Borel set. Hence, \(\mathcal{W}^{c}\) is analytic, so we have proven the claim. 

### Active Learning of Partial Classes with Finite Star Number: Exponential Uniform Rate

We now explain the approach to actively learn a partial concept class with finite star number at a _uniform_ exponential rate. We first state a result from Hanneke and Yang (2015) about active learning of _total_ concept classes with finite star dimension that we utilize in our construction.

**Theorem C.1** (Hanneke and Yang (2015)).: _There exists an active learning algorithm \(\mathcal{A}\) for a total concept class \(\mathbb{H}\) which given a label budget \(n=c\cdot\mathfrak{s}\log(1/\varepsilon)\), where \(c\) is an absolute numerical constant and \(\mathfrak{s}\) is the star number of the class, and access to samples from a realizable distribution \(\mathrm{P}^{*}\) returns a classifier \(\hat{h}_{n}\) such that, with probability arbitrarily close to one, \(\mathrm{P}^{*}[\hat{h}_{n}(x)\neq y]\leq\varepsilon\)._

We underline that the success probability of this algorithm does not depend on the query budget.

Our algorithm for partial classes can be found in Figure 2. We now prove the main result in this setting that we described in Theorem 3.2.

Proof of Theorem 3.2.: Let \(\mathcal{F}\) be a partial concept class whose star number \(\mathfrak{s}\) is finite. Notice that since \(\mathrm{d}\leq\mathfrak{s}\), its VC dimension is also finite. Let \(S=(X_{1},\ldots,X_{m})\) be \(m\) samples of the stream that \(\mathcal{A}\) has access to, where \(m\) is some value to be determined. We also let

\[\widehat{\mathbb{H}}=\left\{h:S\rightarrow\{0,1\}:\exists f\in\mathcal{F}\text { s.t. }h(X_{i})=f(X_{i}),\forall i\in[m]\right\}\,.\]

Now notice that \(\widehat{\mathbb{H}}\) is, by definition, a total concept class and its star number, VC dimension is also at most \(\mathfrak{s}\), \(d\), respectively. Moreover, since \(\mathrm{P}^{*}\) is realizable with respect to \(\mathcal{F}\) we have that, except for a measure-zero event, \(\widehat{\mathbb{H}}\neq\emptyset\). This can be seen as follows. Since the distribution \(\mathrm{P}^{*}\) is realizable, there exists a sequence of functions \(f_{k}\in\mathcal{F}\) so that

\[\mathrm{P}^{*}[f_{k}(x)\neq y]<\frac{1}{2^{k}}\,.\]

Let us fix \(m\geq 1\). We have that

\[\sum_{k=1}^{\infty}\Pr[\exists s\leq m:f_{k}(x_{s})\neq y_{s}]\leq m\sum_{k=1 }^{\infty}\mathrm{P}^{*}[f_{k}(x)\neq y]<\infty\,,\]

where the first inequality is due to union bound. By Borel-Cantelli, with probability one, there exists for every \(m\geq 1\) a hypothesis \(f\in\mathcal{F}\) so that \(f(x_{s})=y_{s}\) for all \(s\leq m\). For the rest of the proof, we condition on this probability one event \(E_{0}\). We definite \(\widehat{\mathrm{P}}^{*}\) to be the uniform distribution on the (labeled) sample. Our previous discussion shows that \(\widehat{\mathrm{P}}^{*}\) is realizable with respect to \(\widehat{\mathbb{H}}\). Now let us run algorithm \(\mathcal{A}^{\prime}\) from Theorem C.1 with \(\varepsilon=1/(2m)\) and success probability \(1/(2m)\). Let \(E_{1}\) be the event that the error of the output \(\hat{h}\) of \(\mathcal{A}^{\prime}\) is at most \(1/(2m)\). We condition on this event for the rest of the proof. Notice that in this case, the algorithm will have figured out the correct label of every \(X_{i},1\leq i\leq m\). Indeed, if for some \(i\in[m]\) we have that \(\hat{h}(X_{i})\neq Y_{i}\), then \(\mathrm{er}(\hat{h})\geq 1/m\). Notice that, by the definition of \(\widehat{\mathbb{H}}\), we have that \(\mathfrak{s}(\widehat{\mathbb{H}})\leq\mathfrak{s}(\mathcal{F}).\) Moreover, the number of labels that \(\mathcal{A}^{\prime}\) requests is at most \(c\cdot\mathfrak{s}\log(2m)\), where \(c\) is some absolute numerical constant.

Since we have \(m\)_labeled_ samples, we can use them as input to the one-inclusion graph algorithm (see Theorem A.5). This algorithm guarantees that

\[\mathbb{E}[\mathrm{er}(\hat{h}_{m})|E_{0},E_{1}]\leq\frac{\mathrm{d}(\mathcal{F })}{m+1}\,.\]Thus, we get that

\[\mathbb{E}[\mathrm{er}(\hat{h}_{m})]\leq\frac{\mathrm{d}(\mathcal{F})}{m+1}+\frac{ 1}{m}<\frac{\mathrm{d}(\mathcal{F})+1}{m}\,.\]

It follows immediately from the definitions that \(\mathrm{d}(\mathcal{F})\leq\mathfrak{s}(\mathcal{F}).\) The result follows by picking \(m=\frac{e^{c\cdot n/\mathfrak{s}}}{2}.\) 

**Star Tree Gale-Stewart Game with Finite Sequence and Estimation:** Input is a labeled sequence \(\{(x_{1},y_{1}),\ldots,(x_{N},y_{N})\}\)

Use \(\lfloor N/2\rfloor\) of the data to estimate \(\hat{t}_{N}\) (cf. Lemma C.5.). Let \(\hat{N}=\lfloor N/2\hat{t}_{N}\rfloor.\)

Use the remaining \(\lfloor N/2\rfloor\) of the data to run the star tree game (cf. Figure 5) and obtain \(\widetilde{g}_{\hat{t}_{N}}^{i},1\leq i\leq\hat{N}.\)

Estimate for \(1\leq i\leq\hat{N}\)

\[\mathcal{F}_{i}=\bigg{\{}f\!:\!\mathcal{X}\!\rightarrow\!\{0,1,\star\}:\forall (x_{1},\ldots,x_{\tau_{\hat{t}_{N}}})\in\mathcal{X}^{\tau_{\hat{t}_{N}}}, \left(x_{1},f(x_{1}),\ldots,x_{\tau_{\hat{t}_{N}}},f(x_{\tau_{\hat{t}_{N}}}) \right)\notin\mathrm{image}\left(\widetilde{g}_{\hat{t}_{N}}^{i}\right) \bigg{\}}.\]

Estimate the \(9/16-\)majority class

\[\mathcal{F}_{m}^{\hat{N}}=\bigg{\{}f:\mathcal{X}\rightarrow\{0,1,\star\}: \forall\ell\in\mathbb{N},\forall(x_{1},\ldots,x_{\ell})\in\mathcal{X}^{\ell}, \exists\text{ at least }(9/16)\hat{N}\text{ classes }\mathcal{F}_{j},1\leq j\leq\hat{N}\text{ s.t. }\]

\[\exists\hat{f}\in\mathcal{F}_{j}\text{ with }(\hat{f}(x_{1}),\ldots,\hat{f}(x_{ \ell}))=(f(x_{1}),\ldots,f(x_{\ell}))\bigg{\}}.\]

Return \(\big{\{}G_{\ell}:(\mathcal{X}\times\{0,1\})^{\ell}\rightarrow\{0,1\}\big{\}}_ {\ell\in\mathbb{N}}\) where

\[G_{\ell}(x_{1},y_{1},\ldots,x_{\ell},y_{\ell})=\mathbb{1}\left\{\exists f\in \mathcal{F}_{m}^{\hat{N}}:(f(x_{1}),\ldots,f(x_{\ell}))=(y_{1},\ldots,y_{\ell })\right\}.\]

Figure 3: Majority Class Estimation Through Star Games.

Figure 2: Exponential Rates Algorithm for Partial Classes.

### The Online Setting

To build some intuition, we first show how to use the game between the learner and the adversary discussed in Section 3 to get an asymptotic result. We call this the online setting. Assume that there is an infinite labeled sequence \(S=(x_{1},y_{1},x_{2},y_{2},\ldots)\) that is consistent with \(\mathbb{H}\), i.e., for any \(t<\infty\), there exists \(h\in\mathbb{H}:h(x_{t})=y_{t}\). We use \(S\) to simulate the game \(\mathfrak{G}\) between \(\text{P}_{\text{A}}\) and \(\text{P}_{\text{L}}\) which gives rise to a partial concept class \(\mathcal{F}\) with finite star number. This approach is shown in Figure 5.

We first show as \(t\to\infty\) the game converges, i.e., there are no more realizable \(\tau_{t^{*}}\)-tuples \((x_{1},y_{1},\ldots,x_{\tau_{t^{*}}},y_{\tau_{t^{*}}})\) that belong to the image of \(\widetilde{g}_{\tau_{t^{*}}}\), for some finite number \(t^{*}\). To simplify the notation, we define \(\widetilde{g}_{t^{*}}=\widetilde{g}_{\tau_{t^{*}}}\). Recall that this function is defined in Figure 5.

**Lemma C.2**.: _If \(\mathbb{H}\) does not have an infinite star tree, for any sequence \(x_{1},y_{1},x_{2},y_{2},\ldots,\) that is consistent with \(\mathbb{H}\), there exists some finite number \(t^{*}\in\mathbb{N}\), such that for all \(t>t^{*}\)_

\[(x_{t-\tau_{t-1}+1},y_{t-\tau_{t-1}+1}\ldots,x_{t},\ldots,y_{t})\notin\operatorname {image}(\widetilde{g}_{t-1}),\tau_{t}=\tau_{t-1},\widetilde{g}_{t}=\widetilde{ g}_{t-1}\,.\]

Proof.: Suppose that \((x_{t-\tau_{t-1}+1},\ldots,x_{t},y_{t-\tau_{t-1}+1},\ldots,y_{t})\in \operatorname{image}(\widetilde{g}_{t-1})\) happens an infinite sequence of times \(t_{1},t_{2},\ldots\). Since \(\eta_{\tau_{t}}\) is a winning strategy for the learner in \(\mathfrak{G}\), we have that for some finite \(t^{*}\) it holds that \(\mathbb{H}_{\vec{\xi}_{1},\vec{\zeta}_{1},\ldots,\vec{\zeta}_{t^{*}},\vec{ \zeta}_{t^{*}},\eta_{t^{*}}}=\varnothing\) (see Equation (1)), where \(\vec{\xi}_{i},\vec{\zeta}_{i},\eta_{i}\) are defined in Figure 5. Hence, we have arrived in a contradiction.

Figure 4: Exponential Rates Algorithm.

Figure 5: Star Gale-Stewart Game on Infinite Sequences.

[MISSING_PAGE_FAIL:20]

Lemma C.4 guarantees that for some \(t^{*}\in\mathbb{N}\), the Gale-Stewart game played on a set of \(t^{*}\) points will have converged with probability at least \(7/8\), i.e., \(\Pr\left[\mathrm{per}(\widetilde{g}_{t^{*}})>0\right]\leq 1/8\). This number \(t^{*}\) depends on the distribution and is unknown to the learner. We first show how the learner can estimate a similar \(\hat{t}_{n}\) from the data. Our approach is an adaptation of Lemma 5.10 in Bousquet et al. (2021), but we present the proof for completeness.

**Lemma C.5** (Adaptation of Lemma 5.10 in (Bousquet et al., 2021)).: _For any \(N\in\mathbb{N}\), there exists a universally measurable \(\hat{t}_{N}=\hat{t}_{N}(X_{1},Y_{1},...,X_{\lfloor N/2\rfloor},Y_{\lfloor N/2 \rfloor})\) whose definition does not depend on \(\mathrm{P}\) so that the following holds. Set the critical time \(t^{*}\in\mathbb{N}\) be such that_

\[\Pr\left[\mathrm{per}(\widetilde{g}_{t^{*}})>0\right]\leq 1/8\,,\]

_where the probability is over the training set of the algorithm. There exist \(C,c>0\) that depend on \(\mathrm{P},t^{*}\) but not \(N\) so that_

\[\Pr[\hat{t}_{N}\in T^{\star}]\geq 1-Ce^{-cN}\,,\]

_where the probability is over the training of the estimator \(\hat{t}_{N}\) and \(T^{*}\) is the set_

\[T^{*}=\{1\leq t\leq t^{*}:\Pr\left[\mathrm{per}(\widetilde{g}_{t})>0\right] \leq 3/8\}\.\]

Proof.: We split this labeled set into two parts. The idea is to use the first one to run the Gale-Stewart game and the other one to estimate whether it has converged or not. For each \(1\leq t\leq\lfloor\frac{N}{4}\rfloor\) and \(1\leq i\leq\lfloor\frac{N}{4t}\rfloor\), we let

\[\tau_{t}^{i} :=T_{t}(X_{(i-1)t+1},Y_{(i-1)t+1},\ldots,X_{it},Y_{it})\] \[\widetilde{g}_{t}^{i}(w_{1},z_{1},\ldots,w_{\tau_{i}^{i}},z_{\tau _{i}^{i}}) :=\widetilde{G}_{t}(X_{(i-1)t+1},Y_{(i-1)t+1},\ldots,X_{it},Y_{it},w_{1},z_{1},\ldots,w_{\tau_{i}^{i}},z_{\tau_{i}^{i}})\,.\]

be the estimated quantities when we run Figure 5 on the \(i\)-th batch of the data. Next, for each \(t\) we estimate \(\Pr[\mathrm{per}(\widetilde{g}_{t})>0]\) by the fraction of the \(\widetilde{g}_{t}^{i}\) for which there is a tuple on the second quarter of the data that belongs to the image of \(\widetilde{g}_{t}^{i}\). For every fixed \(t\), the data that the functions \(\left\{\widetilde{g}_{t}^{i}\right\}_{i\leq\lfloor N/2t\rfloor}\) are trained on are independent of each other and of the second half of the training set. This means that we can view every \(\left\{\widetilde{g}_{t}^{i}\right\}_{i\leq\lfloor N/2t\rfloor}\) as an independent draw of the distribution of \(\widetilde{g}_{t}\). To estimate the error of the algorithm we use the second quarter of the training set. We let

\[\hat{e}_{t}=\frac{1}{\lfloor N/4t\rfloor}\sum_{i=1}^{\lfloor N/4t\rfloor} \mathbb{1}_{\left\{\exists s:\lfloor N/4\rfloor+1\leq s\leq\lfloor N/2\rfloor -\tau_{i}^{i},\left(X_{s+1},Y_{s+1},\ldots,X_{s+\hat{\tau}^{i}},Y_{s+\hat{ \tau}^{i}}\right)\in\mathrm{image}(\widetilde{g}_{t}^{i})\right\}}\,.\]

Now observe that

\[\hat{e}_{t}\leq e_{t}=\frac{1}{\lfloor N/4t\rfloor}\sum_{i=1}^{\lfloor N/4t \rfloor}\mathbb{1}_{\left\{\mathrm{per}(\widetilde{g}_{t})>0\right\}}\,,\]

with probability one. We define

\[\hat{t}_{N}=\inf\{t\leq\lfloor N/4\rfloor:\hat{e}_{t}<1/4\}\,,\]

where we assume that \(\inf\emptyset=\infty\).

We now want to bound the probability that \(\hat{t}_{N}>t^{*}\). Using Hoeffding's inequality we get that

\[\Pr\left[\hat{t}_{N}>t^{*}\right]\leq\Pr\left[\hat{e}_{t^{*}}\geq\frac{1}{4} \right]\leq\Pr\left[e_{t^{*}}\geq\frac{1}{4}\right]=\Pr\left[e_{t^{*}}-\frac{ 1}{8}\geq\frac{1}{8}\right]=\Pr\left[e_{t^{*}}-\mathbb{E}[e_{t^{*}}]\geq\frac{ 1}{8}\right]\leq e^{-\lfloor N/4t^{*}\rfloor/32}\,.\]

This implies that \(\hat{t}_{N}\leq t^{*}\) except for an event with exponentially small probability. Moreover, for all \(1\leq t\leq t^{*}\) that \(\Pr\left[\mathrm{per}(\widetilde{g}_{t})>0\right]>\frac{3}{8}\), there is some \(\varepsilon>0\) such that \(\Pr\left[\mathrm{per}(\widetilde{g}_{t})>\varepsilon\right]>\frac{1}{4}+\frac {1}{16}\) (this holds by continuity). Now fix some \(1\leq t\leq t^{*}\) such that \(\Pr\left[\mathrm{per}(\widetilde{g}_{t})>0\right]>\frac{3}{8}\) (if it exists). Then, using Hoeffding's inequality again we get that

\[\Pr\left[\frac{1}{\lfloor N/4t\rfloor}\sum_{i=1}^{\lfloor N/4t\rfloor} \mathbb{1}_{\left\{\mathrm{per}(\widetilde{g}_{t}^{i})>\varepsilon\right\}}< \frac{1}{4}\right]\leq e^{-\lfloor N/4t^{*}\rfloor/128}\,.\]

Whenever \(g\) is a function such that \(\mathrm{per}(g)>\varepsilon\), then

\[\Pr\left[\{\exists s:\lfloor N/4\rfloor+1\leq s\leq\lfloor N/2\rfloor-\tau,(X _{s+1},Y_{s+1},\ldots,X_{s+\tau},Y_{s+\tau})\in\mathrm{image}(g)\}\right] \geq 1-(1-\varepsilon)^{\lfloor(N-4)/4\tau\rfloor}\,\]since there are \(\lfloor(N-4)/4\tau\rfloor\) disjoint intervals of length \(\tau\). As we mentioned before, \(\{\widetilde{g}_{t}^{i}\}_{i\leq\lfloor N/4t\rfloor}\) are independent of \((X_{s},Y_{s})_{s>\lfloor n/4\rfloor}\). Thus, applying a union bound we get that the probability that all \(\widetilde{g}_{t}^{i}\) that have \(\operatorname{per}^{\tau^{i}_{t}}(\widetilde{g}_{t}^{i})>\varepsilon\) make at least one error on the second half of the training set is

\[\operatorname{Pr}\left[\mathbb{1}_{\left\{\operatorname{per}^{ \tau^{i}}(\widetilde{g}_{t}^{i})>\varepsilon\right\}}\leq\mathbb{1}_{\left\{ \frac{\mathbb{Z}s:\lfloor N/4\rfloor+1\leq s\leq\lfloor N/2\rfloor-\tau_{t}^{i},(X_{s+1},Y_{s+1},\ldots,X_{s+\tau_{t}^{i}},Y_{s+\tau_{t}^{i}})\in\operatorname {image}(\widetilde{g}_{t}^{i})\right\}}\right]\] \[\geq 1-\left\lfloor\frac{N}{4t}\right\rfloor(1-\varepsilon)^{ \lfloor(N-4)/4t^{*}\rfloor}\,,\]

where the last inequality holds since \(\tau_{t}^{i}\leq t^{*}\). Thus, we get that

\[\operatorname{Pr}[\hat{t}_{N}=t]\leq\operatorname{Pr}\left[\hat{e}_{t}<\frac {1}{4}\right]\leq\left\lfloor\frac{N}{4}\right\rfloor(1-\varepsilon)^{\lfloor (N-4)/4t^{*}\rfloor}+e^{-\left\lfloor\frac{N}{4t^{*}}\right\rfloor/128}\,.\]

Using the previous estimates and applying a union bound, we get that

\[\operatorname{Pr}[\hat{t}_{N}\notin T^{\star}]\leq e^{-\lfloor N/4t^{*} \rfloor/32}+t^{\star}\left\lfloor\frac{N}{4}\right\rfloor(1-\varepsilon)^{ \lfloor(N-4)/4t^{*}\rfloor}+t^{\star}e^{-\lfloor N/4t^{*}\rfloor/128}\leq Ce^ {-cn}\,,\]

for some constants \(C,c>0\). 

Essentially, Lemma C.5 tells us that we can estimate a batch size \(\hat{t}_{n}\), using only information from the data, so that, with probability \(1-Ce^{-cn}\), the star tree game will have converged when we run it on \(\hat{t}\) labeled points. Following the approach of Hanneke et al. (2022), the idea is to run the game multiple times, then create the partial concept classes that are induced by each execution, and, finally, aggregate them into a _majority_ class (see Figure 3). We show that if most of the games have converged, then the majority class has bounded star number. This is made formal in Lemma C.6. We remark that Hanneke et al. (2022) showed a similar result regarding the VC dimension of the majority class.

**Lemma C.6**.: _The majority class \(\mathcal{F}_{m}^{\tilde{N}}\) defined in Figure 3 has star number that is bounded by some distribution-dependent constant \(\hat{\mathfrak{s}}\), with probability at least \(1-e^{-c\tilde{N}}\), for some absolute constant \(c>0\)._

Proof.: We know that there exists some \(\mathfrak{s}^{*}\) such that, with probability at least \(9/10\), the star of any partial concept class \(\mathcal{F}_{i}\) is at most \(\mathfrak{s}^{*}\). We let \(X_{i}=\mathbb{1}_{\left\{\text{star number of $\mathcal{F}_{i}> \mathfrak{s}^{*}$}\right\}}\). Notice the all the \(X_{i}\)'s are i.i.d. Bernoulli random variables with \(p\leq 1/10\), since the data that induce the classes \(\mathcal{F}_{i}\) are i.i.d.. Thus, we can use Hoeffding's inequality to bound the probability that more than \(2/10\) of them have star number greater than \(\mathfrak{s}^{*}\) as follows

\[\operatorname{Pr}\left[\sum_{i=1}^{\tilde{N}}X_{i}\geq(2/10)\hat{N}\right]= \operatorname{Pr}\left[\sum_{i=1}^{\tilde{N}}X_{i}-(1/10)\hat{N}\geq(15/72) \hat{N}\right]\leq e^{-\tilde{N}/50}\,.\]

We let \(\mathcal{E}_{1}\) be the complement of the event above and we condition on it for the rest of the proof. So, we know that at least \(8/10\hat{N}\) of the partial concept classes \(\mathcal{F}_{i}\) have star number bounded by \(\mathfrak{s}^{*}\). We will bound the size \(\ell\) of the star set of \(\mathcal{F}_{m}^{\tilde{N}}\). For any star sequence \(S=(x_{1},y_{1},\ldots,x_{\ell},y_{\ell})\in(\mathcal{X}\times\{0,1\})^{\ell}\) of \(\mathcal{F}_{m}^{\tilde{N}}\) it holds that

\[\frac{1}{\ell}\sum_{j=1}^{\ell}\mathbb{1}\Bigg{\{}\frac{1}{\tilde{N}}\sum_{i=1 }^{\tilde{N}}\mathbb{1}\left\{\exists f\in\mathcal{F}_{i}:f(x_{j})=1-y_{j},f(x _{p})=y_{p},\forall p\in[\ell]\setminus\{j\}\right\}>9/16\Bigg{\}}=1\,.\]

Using Markov's inequality, we get that

\[\frac{1}{\ell}\sum_{j=1}^{\ell}\frac{1}{\tilde{N}}\sum_{i=1}^{\tilde{N}} \mathbb{1}\left\{\exists f\in\mathcal{F}_{i}:f(x_{j})=1-y_{j},f(x_{p})=y_{p}, \forall p\in[\ell]\setminus\{j\}\right\}>\frac{9}{16}\,.\]Swapping the summation gives us

\[\frac{1}{\hat{N}}\sum_{i=1}^{\hat{N}}\frac{1}{\ell}\sum_{j=1}^{\ell }\mathbb{1}\left\{\exists f\in\mathcal{F}_{i}:f(x_{j})=1-y_{j},f(x_{p})=y_{p}, \forall p\in[\ell]\setminus\{j\}\right\}>\frac{9}{16}\iff\] \[\frac{1}{\hat{N}}\sum_{i=1}^{\hat{N}}\frac{1}{\ell}\sum_{j=1}^{ \ell}\mathbb{1}\left\{\nexists f\in\mathcal{F}_{i}:f(x_{j})=1-y_{j},f(x_{p})= y_{p},\forall p\in[\ell]\setminus\{j\}\right\}\leq\frac{7}{16}\,.\]

Using Markov's inequality again, we get that

\[\frac{1}{\hat{N}}\sum_{i=1}^{\hat{N}}\mathbb{1}\left\{\frac{1}{ \ell}\sum_{j=1}^{\ell}\mathbb{1}\left\{\nexists f\in\mathcal{F}_{i}:f(x_{j})= 1-y_{j},f(x_{p})=y_{p},\forall p\in[\ell]\setminus\{j\}\right\}>9/16\right\}\leq\] \[\frac{16}{9}\cdot\frac{1}{\hat{N}}\sum_{i=1}^{\hat{N}}\frac{1}{ \ell}\sum_{j=1}^{\ell}\mathbb{1}\left\{\nexists f\in\mathcal{F}_{i}:f(x_{j})= 1-y_{j},f(x_{p})=y_{p},\forall p\in[\ell]\setminus\{j\}\right\}\,.\]

This implies that

\[\frac{1}{\hat{N}}\sum_{i=1}^{\hat{N}}\mathbb{1}\left\{\frac{1}{ \ell}\sum_{j=1}^{\ell}\mathbb{1}\left\{\nexists f\in\mathcal{F}_{i}:f(x_{j})= 1-y_{j},f(x_{p})=y_{p},\forall p\in[\ell]\setminus\{j\}\right\}>9/16\right\} <7/9\iff\] \[\frac{1}{\hat{N}}\sum_{i=1}^{\hat{N}}\mathbb{1}\left\{\frac{1}{ \ell}\sum_{j=1}^{\ell}\mathbb{1}\left\{\exists f\in\mathcal{F}_{i}:f(x_{j})= 1-y_{j},f(x_{p})=y_{p},\forall p\in[\ell]\setminus\{j\}\right\}\geq 7/16 \right\}\geq 2/9\,.\]

Thus, we have shown that at least \(2/9\) of the partial concept classes witness at least \(7/16\) of the star patterns. By the definition of the star number, this means that all these classes have star number at least \(7/16\cdot m-1\). This is because we can drop all the points from \(S\) that correspond to star patterns that the class does not realize and the remaining set of labeled points is a star set. Since at least one these classes' star number is at most \(\mathfrak{s}^{*}\) we have that \(7/16\cdot m-1\leq\mathfrak{s}^{*}\), which means that \(m\leq 16/7(\mathfrak{s}^{*}+1)\). Thus, we have shown that the star number of \(\mathcal{F}_{m}^{\hat{N}}\) is at most \(16/7(\mathfrak{s}^{*}+1)=\hat{\mathfrak{s}}\), with probability at least \(1-e^{-c\hat{N}}\). 

Similarly as in Hanneke et al. (2022), we define a sequence of universally measurable functions \(\left\{G_{\ell}:(\mathcal{X}\times\{0,1\})^{\ell}\to\{0,1\}\right\}_{\ell\in \mathbb{N}}\) where

\[G_{\ell}(x_{1},y_{1},\ldots,x_{\ell},y_{\ell})=\mathbb{1}\left\{\exists f\in \mathcal{F}_{m}^{\hat{N}}:(f(x_{1}),\ldots,f(x_{\ell}))=(y_{1},\ldots,y_{\ell })\right\}\,.\]

An equivalent interpretation of the previous lemma is that the star number of the partial class on which \(\{G_{\ell}\}_{\ell\in\mathbb{N}}\) returns \(1\) has a distribution-dependent bound, with high probability. Lemma C.7 is an important component in the derivation of our result and it shows that \(\{G_{\ell}\}_{\ell\in\mathbb{N}}\) return \(1\) on all finite subsets of the correctly labeled data sequence, with high probability. This result follows similarly as Lemma 7 in Hanneke et al. (2022).

**Lemma C.7**.: _The \(\left\{G_{\ell}\right\}_{\ell\in\mathbb{N}}\) as defined above are universally measurable functions, and with probability at least \(1-Ce^{-cN},C,c>0\), the following hold:_

* _The star number of the class_ \[\mathcal{F}_{G}=\left\{f\!:\!\mathcal{X}\!\to\!\{0,1,\star\}:\forall\ell\!\in \!\mathbb{N},\forall(x_{1},\ldots,x_{\ell})\!\in\!\mathcal{X}^{\ell}:G_{\ell}(x _{1},f(x_{1}),\ldots,x_{\ell},f(x_{\ell}))=1\right\}\] _has a finite distribution-dependent upper bound_ \(\hat{\mathfrak{s}}\)_._
* \(\forall\ell\in\mathbb{N}\)_, for_ \((x_{1},y_{1},\ldots,x_{\ell},y_{\ell})\sim\mathrm{P}^{\ell}\)_,_ \(G_{\ell}(x_{1},y_{1},\ldots,x_{\ell},y_{\ell})=1\) _with conditional probability one (given_ \(G_{\ell}\)_)._

Proof.: We condition on the event \(\mathcal{E}_{0}\) described in Lemma C.6. Notice that, by definition, a labeled sequence \(S=\left(x_{1},y_{1}\ldots,x_{\ell},y_{\ell}\right)\in\left(\mathcal{X}\times \{0,1\}\right)^{\ell}\) is a star set of the class \(\mathcal{F}_{G}\) if and only if \(S\) is a star set of \(\mathcal{F}_{m}^{N}\). Hence, the bound on the star number follows immediately from Lemma C.6. We also condition on the event \(\mathcal{E}_{1}\) described in Lemma C.5. We now bound the probability that at least \((13/32)\hat{N}\) of the functions \(\widetilde{g}_{\hat{t}_{N}}^{i}\) have \(\operatorname{per}\left(\widetilde{g}_{\hat{t}_{N}}^{i}\right)>0\). For any \(t\in T^{*}\), using Hoeffding's inequality we get that

\[\Pr\left[\frac{1}{\hat{N}}\sum_{i=1}^{\hat{N}}\mathbb{1}\Big{\{} \operatorname{per}\left(\widetilde{g}_{\hat{t}_{N}}^{i}\right)>0\Big{\}}> \frac{13}{32}\right]=\Pr\left[\frac{1}{\hat{N}}\sum_{i=1}^{\hat{N}}\mathbb{1} \Big{\{}\operatorname{per}\left(\widetilde{g}_{\hat{t}_{N}}^{i}\right)>0 \Big{\}}-\frac{3}{8}>\frac{1}{32}\right]\leq\exp\left(-\hat{N}/512\right),\]

Since we know that \(\hat{t}_{n}\leq t^{*},\) taking a union bound over all \(1\leq t\leq t^{*}\) we get that

\[\Pr\left[\frac{1}{\hat{N}}\sum_{i=1}^{\hat{N}}\mathbb{1}\Big{\{} \operatorname{per}\left(\widetilde{g}_{\hat{t}_{N}}^{i}\right)>0\Big{\}}> \frac{13}{32},\hat{t}_{n}\in T^{*}\right] \leq\sum_{t\in T^{*}}\Pr\left[\frac{1}{\hat{N}}\sum_{i=1}^{\hat {N}}\mathbb{1}\Big{\{}\operatorname{per}\left(\widetilde{g}_{\hat{t}_{N}}^{i }\right)>0\Big{\}}>\frac{13}{32}\right]\] \[\leq t^{*}\exp\left(-\hat{N}/512\right)\,.\]

Thus, except for an event with exponentially small probability, at least \(19/32\) of the functions \(\widetilde{g}_{\hat{t}_{N}}^{i}\) have \(\operatorname{per}\left(\widetilde{g}_{\hat{t}_{N}}^{i}\right)\), with probability one. Notice that, by definition, if the partial class \(\mathcal{F}_{i}\) that corresponds to such a function cannot produce a labeling \(\widetilde{y}_{\ell}\in\{0,1\}^{\ell}\) of some tuple \(\vec{x}_{\ell}\in\mathcal{X}^{\ell}\) where \(\vec{x}_{\ell}\sim\mathrm{P}_{X}^{\ell}\), we can infer that this \(\widetilde{y}_{\ell}\) is not the correct labeling, and this inference will be valid with probability one over the draw of \(\vec{x}_{\ell}\). Thus, with probability one, if the \(9/16\)-majority cannot produce some labeling we have that at least one such partial class \(\mathcal{F}_{j}\) that corresponds to a correct \(\widetilde{g}_{\hat{t}_{N}}^{j}\) cannot produce this labeling, so it is not the correct one. As a result, with probability one, if \(\mathcal{F}_{m}^{N}\) cannot produce \(\widetilde{y}_{\ell}\) for \(\vec{x}_{\ell}\) we know that this is not the correct labeling. The measurability of \(\{G_{\ell}\}_{t\in\mathbb{N}}\) follows by the measurability of all the \(\left\{\widetilde{g}_{\hat{t}_{N}}^{i}\right\}_{i\in\hat{N}}.\) The proof of the lemma follows by noticing that the probability of all the events we have conditioned on can be bounded by \(1-C^{\prime}e^{-c^{\prime}\hat{N}}\) and that \(\hat{N}=\lfloor N/2\hat{t}_{N}\rfloor\geq\lfloor N/2t^{*}\rfloor.\) 

We are now ready to prove the result about active learning at exponential universal rates. Our approach is summarized in Figure 4.

**Theorem C.8**.: _Assume that \(\mathbb{H}\subseteq\{0,1\}^{\mathcal{X}}\) does not have an infinite star tree. Then, \(\mathbb{H}\) admits an active learning algorithm that achieves exponential rates._

Proof.: First, notice that the Gale-Stewart subroutine Figure 3 uses \(\lfloor n/2\rfloor\) points and the exponential rates algorithm for partial classes uses at most \(\lfloor e^{c\cdot n}\rfloor\) points. This is because we define a uniform distribution over these points during its execution. To prove the learning rate guarantees, we first condition on the event \(\mathcal{E}_{0}\) described in Lemma C.7. Then, we have some partial concept class \(\mathcal{F}_{G}\) whose star number is finite by some distribution-dependent number \(\hat{\mathfrak{s}}\) and has the property that \(\forall\ell\in\mathbb{N}\), for \((x_{1},y_{1},\ldots,x_{\ell},y_{\ell})\sim\mathrm{P}^{\ell}\), \(f(x_{1})=y_{1},\ldots,f(x_{\ell})=y_{\ell}\) for some \(f\in\mathcal{F}_{G}.\) Thus, the conditions of Theorem C.1 are satisfied and the conditional error rate of the output of our algorithm is \(\mathbb{E}[\operatorname{er}(\hat{h}_{n})|\mathcal{E}_{0}]\leq c_{1}\mathrm{d} e^{-c_{2n}/\hat{\mathfrak{s}}}\). Since \(\mathcal{E}_{0}\) happens with probability at least \(1-\tilde{C}e^{-\hat{c}n}\), we see that the unconditional error of the output is \(\mathbb{E}[\operatorname{er}(\hat{h}_{n})]\leq c_{1}\mathrm{d}e^{-C_{2}n/\hat {\mathfrak{s}}}+\tilde{C}e^{-\hat{c}n}\leq Ce^{-cn},\) for some distribution-dependent constants \(c,C>0\). 

### Sublinear Rates Lower Bound

**Theorem C.9**.: _Assume that \(\mathbb{H}\subseteq\{0,1\}^{\mathcal{X}}\) has an infinite star tree and let \(R(n)\) be a rate function with \(R(n)=o(1/n)\). Then, \(\mathbb{H}\) requires rate \(R(n)\)._

Proof.: Let

\[\vec{t}=\bigcup_{0\leq\ell<\infty}\left\{(x_{\vec{u}},z_{\vec{u}})\in\left( \mathcal{X}^{\ell+1},\{0,1\}^{\ell+1}\right):\vec{u}\in\{0\}\times\{0,1\} \times\ldots\times\{0,1,\ldots,\ell\}\right\}\,,\]be an infinite star tree. We also fix the learning algorithm \(\hat{h}_{n}\). Recall that \(\left\{u(n)\right\}_{n\in\mathbb{N}}\) denotes the number of unlabeled samples that \(\hat{h}_{n}\) uses.

We first pick a path on the tree uniformly at random. To be more precise, let \(\vec{y}=(y_{1},y_{2},\ldots)\) be a sequence of independent random variables where \(y_{i}\) is uniformly distributed in \(\{0,\ldots,i-1\}\). The idea is that \(\vec{y}\) specifies a random path on the tree. We define the target distribution \(\mathrm{P}_{\vec{y}}\) in an inductive way by specifying sequences \(\{k_{i},p_{i},n_{i}\}_{i\geq 1}\) and putting mass \(p_{i}\) on the node of the random path at level \(k_{i}\). Conditional on the given node, we distribute the mass among its points uniformly. Let us now be formal. For the base of the induction, we let \(p_{2}=1/2\) and \(k_{1}=1\). We will specify the value of \(p_{1}\) later. For the inductive step, for any \(i\geq 2\), given the value of \(p_{i},k_{i-1}\), we will specify \(k_{i},p_{i+1}\). We let \(k_{i}\) be the smallest integer so that \(k_{i}>k_{i-1}\) and \(R(\lfloor k_{i}/8\rfloor)<p_{i}/k_{i}\). Notice that since \(R(n)=o(1/n)\), \(k_{i}<\infty\). We let \(n_{i}=\lfloor k_{i}/8\rfloor\) and

\[p_{i+1}=\min\left\{\frac{1}{4u_{n_{i}}},\frac{p_{i}}{4}\right\}\,.\]

Notice that since \(\{p_{i}>0\}_{i\geq 2},\sum_{i\geq 2}p_{i}<1\)4, by setting \(p_{1}=1-\sum_{i\geq 2}p_{i}\) the sequence \(\{p_{i}\}_{i\geq 1}\) can be used as a probability distribution. We are now ready to define \(\mathrm{P}_{\vec{y}}\) on \(\mathcal{X}\times\{0,1\}\). To make the notation simpler, for any \(\vec{y}\) and for \(k\geq 1\)

Footnote 4: This is because \(p_{i+1}\leq p_{i}/4\).

\[w^{j}_{\vec{y}\leq k-1}=\begin{cases}1-z^{j}_{\vec{y}\leq k-1},&\text{if }j=y_{k}\\ z^{j}_{\vec{y}\leq k-1},&\text{otherwise}\end{cases}\,.\]

For \(i\geq 1\), let

\[\mathrm{P}_{\vec{y}}\left(x^{j}_{\vec{y}\leq k_{i}-1},w^{j}_{\vec{y}\leq k_{i }-1}\right)=\frac{p_{i}}{k_{i}},1\leq j\leq k_{i}-1\,.\]

Notice that, by the definition of \(p_{i}\), this is indeed a probability distribution. We now show that \(\mathrm{P}_{\vec{y}}\) is realizable. Since \(\vec{t}\) is a star tree, there exists some \(h\in\mathbb{H}\) such that

\[h\left(x^{j}_{\vec{y}\leq k}\right)=w^{j}_{\vec{y}\leq k-1}\,,\]

for all \(0\leq j\leq k,\) and \(1\leq k\leq n\). Thus, for the probability of error of \(h\) we have that

\[\mathrm{er}_{\vec{y}}(h):=\mathrm{P}_{\vec{y}}\left[(x,y)\in\mathcal{X}\times \{0,1\}:h(x)\neq y\right]\leq\sum_{k>n}p_{k}\,,\]

so by taking \(n\to\infty\) we see that \(\mathrm{P}_{\vec{y}}\) is realizable for every \(\vec{y}\). Moreover, we note that the mapping \(\vec{y}\to\mathrm{P}_{\vec{y}}\) is measurable.

We now let \((X,Y),(X_{1},Y_{1}),(X_{2},Y_{2}),\ldots\) be i.i.d. samples drawn from \(\mathrm{P}_{\vec{y}}\). We can draw them as

\[X=x^{J}_{\vec{y}\leq T-1},\quad Y=w^{J}_{\vec{y}\leq T-1},\quad X_{j}=x^{J_{j }}_{\vec{y}\leq T_{j}-1},\quad Y_{j}=w^{J_{j}}_{\vec{y}\leq T_{j}-1}\,,\]

where \((T,J),(T_{1},J_{1}),(T_{2},J_{2}),\ldots\) are i.i.d. random variables, independent of the path \(\vec{y}\), with

\[\mathrm{Pr}[T=k_{i},J=j]=\frac{p_{i}}{k_{i}}\,,\]

for all \(i\geq 1,0\leq j\leq k_{i}-1\).

For all \(i\in\mathbb{N}\), let us define the event \(E^{i}_{0}=\left\{T_{1}\leq k_{i},T_{2}\leq k_{i},\ldots,T_{u_{n_{i}}}\leq k_{i}\right\}\) under which the algorithm has not received any unlabeled points from any level \(k_{j},j>i\). Let us also call \(E^{i}_{1}\) the event that \(\hat{h}_{n_{i}}\) does not query the point whose label is flipped, i.e., the point \(x^{y_{i}}_{\vec{y}\leq k_{i}-1}\). Also, we denote \(E^{i}_{2}\) the event that the learner classifies at least one point of level \(k_{i}\) incorrectly. Then, we have that

\[\mathrm{Pr}[E^{i}_{2}|E^{i}_{1},E^{i}_{0}]\geq\left(1-\frac{1}{(7/8\cdot k_{i}) }\right)\geq\frac{6}{7}\,,\]

since there are at least \((7/8)\cdot k_{i}\) points on this level that the learner has not queried, and under the events we have conditioned on the flipped point along the path is chosen uniformly at random among these points. We now bound \(\mathrm{Pr}[E^{i}_{0}]\). Notice that

\[\sum_{j\geq i+1}p_{j}\leq\frac{4}{3}p_{i+1}\leq\frac{p_{i}}{3}\leq\frac{1}{12 \cdot u_{n_{i}}}\,.\]Thus,

\[\Pr[E_{0}^{i}]\geq\left(1-\sum_{j\geq i+1}p_{j}\right)^{u_{n_{i}}}\geq\left(1- \frac{1}{12\cdot u_{n_{i}}}\right)^{u_{n_{i}}}\geq\frac{9}{10}\,.\]

Finally, we need to bound \(\Pr[E_{1}^{i}|E_{0}^{i}]\). Notice that

\[\Pr[E_{1}^{i}|E_{0}^{i}]\geq\frac{7}{8}\,,\]

since the learner has \(n\) label queries and there are at least \(8n\) points. Putting it together, we can bound

\[\Pr[E_{2}^{i}] =\Pr[E_{2}^{i}|E_{1}^{i},E_{0}^{i}]\cdot\Pr[E_{1}^{i}|E_{0}^{i}] \cdot\Pr[E_{0}^{i}]\] \[\geq\frac{6}{7}\cdot\frac{7}{8}\cdot\frac{9}{10}\] \[=\frac{27}{40}\,,\]

which using reverse Markov's inequality implies that

\[\Pr_{\vec{y}}\left[\Pr[E_{2}^{i}|\vec{y}]\geq\frac{9}{40}\right]\geq\frac{18 }{31}\,.\]

Moreover, notice that

\[\Pr[\hat{h}_{n_{i}}(X)\neq Y|\vec{y}]\geq\frac{p_{i}}{k_{i}}\cdot\Pr[E_{2}^{i} |\vec{y}]\geq R(n_{i})\cdot\Pr[E_{2}^{i}|\vec{y}]\,.\]

Thus, we can see that

\[\Pr_{\vec{y}}\left[\Pr[\hat{h}_{n_{i}}\neq Y|\vec{y}]\geq\frac{9}{40}\cdot R (n_{i})\right]\geq\frac{18}{31}\,.\]

Using Fatou's lemma, we have that

\[\mathbb{E}\left[\limsup_{i\to\infty}\frac{1}{R(n_{i})}\Pr[\hat{h }_{n_{i}}(X)\neq Y|\vec{y}]\right] \geq\mathbb{E}\left[\limsup_{i\to\infty}\frac{1}{R(n_{i})}\cdot \min\left\{\Pr[\hat{h}_{n_{i}}(X)\neq Y|\vec{y}],9/40\cdot R(n_{i})\right\}\right]\] \[\geq\limsup_{i\to\infty}\frac{1}{R(n_{i})}\,\mathbb{E}\left[\min \left\{\Pr[\hat{h}_{n_{i}}(X)\neq Y|\vec{y}],9/40\cdot R(n_{i})\right\}\right]\] \[\geq\limsup_{i\to\infty}\frac{1}{R(n_{i})}\Pr_{\vec{y}}\left[\Pr[ \hat{h}_{n_{i}}(X)\neq Y|\vec{y}]\geq 9/40\cdot R(n_{i})\right]\cdot\frac{9}{40} \cdot R(n_{i})\] \[\geq\frac{9}{40}\cdot\frac{18}{31}\] \[=\frac{81}{620}\,,\]

where the first inequality is by the definition of \(\min\), the second inequality follows from Fatou's lemma, and the third inequality follows from Markov's inequality. We remark that Fatou's lemma can be applied here since

\[\frac{1}{R(n_{i})}\min\left\{\Pr\left[\hat{h}_{n_{i}}(X)\neq Y|\vec{y}\right], 9/40\cdot R(n_{i})\right\}\leq 9/40\,.\]

Thus, there must exist a realization of \(\vec{y}\) such that

\[\mathbb{E}[\mathrm{er}_{\vec{y}}(\hat{h}_{n})|\vec{y}]\geq C\cdot R(n)\,,\]

infinitely often, where \(C\) is some absolute constant. Choosing \(\mathrm{P}=\mathrm{P}_{\vec{y}}\) for this realization of \(\vec{y}\) concludes the proof. 

## Appendix D Omitted Details from Section 4

### Useful Tools

**Theorem D.1** (Dvoretzky-Kiefer-Wolfowitz (DKW) Inequality).: _Let \(F\) be the CDF of some distribution \(\mathcal{D}\) supported on \(\mathbb{R}\), \(n\in\mathbb{N}\) and \(F_{n}\) be the empirical CDF obtained from \(n\) i.i.d. samples from \(\mathcal{D}\). Then, \(\forall\varepsilon>0\) we have that_

\[\Pr\left[\sup_{x\in\mathbb{R}}|F_{n}(x)-F(x)|>\varepsilon\right]\leq 2e^{-2n \varepsilon^{2}}\,.\]

### The VCL Game

For completeness, we provide various algorithms and results that appeared in Bousquet et al. (2021); Hanneke et al. (2022), which we utilize in our approach to get sublinear learning rates. It is instructive to start with an informal description of a pattern avoidance function \(g:\mathcal{X}^{k}\rightarrow\{0,1\}^{k}\). Intuitively, this function takes as input a \(k\)-tuple of unlabeled data generated by a realizable distribution \(\mathrm{P}_{\mathcal{X}}\) and it returns a labeling of these data that is not the true labeling by \(\mathrm{P}\). They define

\[\mathrm{per}(g)=\mathrm{P}^{k}[x_{1},\ldots,x_{k}:g(x_{1},\ldots,x_{k})=(y_{1},\ldots,y_{k})]\,.\]

Bousquet et al. (2021) provide a way to obtain such a pattern avoidance function for any realizable distribution. This is obtained by a VCL game in Figure 6 which returns a function \(\tilde{y}_{\tau_{t}}\). Their following result shows that as the number of points \(N\) used in the VCL game grows, the probability that we obtain a pattern avoidance function that is incorrect goes to zero.

**Lemma D.2** (Correct Pattern Avoidance Function (Restatement of Lemma 5.7 (Bousquet et al., 2021))).: _Consider the VCL game in Figure 6. Then, \(\mathrm{Pr}[\mathrm{per}(\hat{\tilde{y}}_{\tau_{t}})>0]\to 0,\) as \(N\rightarrow\infty.\)_

Finally, we remark that Bousquet et al. (2021) showed the following result.

**Theorem D.3** (Supervised Learning Linear Rates (Bousquet et al., 2021)).: _If \(\mathbb{H}\) does not have an infinite VCL tree there exists a supervised learning algorithm that can learn \(\mathbb{H}\) at linear rate._

### Omitted Details of the Sublinear Rates Algorithm

**Lemma D.4**.: _Let \(\mathcal{F}_{\sqrt{n}/5}^{i},i\in[\sqrt{n}]\) be the partial concept classes that are obtained by playing the VCL game on \(\sqrt{n}/5\) examples that are generated i.i.d. from \(\mathrm{P}\). Then, with probability at least \(1-e^{-C\cdot n^{1/4}},\) where \(C>0\) is some absolute constant, \(\mathrm{P}\) is a realizable distribution for a \((1-o(1))-\)fraction of these classes._

Proof.: Let \(\hat{\tilde{y}}_{\sqrt{n}/5}^{i}\) be the pattern avoidance function that is obtained from the \(i-\)th batch of \(\sqrt{n}/5\) i.i.d. samples from \(\mathrm{P}.\) Since we know that \(\mathrm{Pr}[\mathrm{per}(\hat{\tilde{y}}_{\sqrt{n}/5}^{i})>0]\to 0\) as \(n\rightarrow\infty\) (cf. Lemma D.2), for any \(\varepsilon>0\) there is some \(b_{\varepsilon}\) such that if the batch size \(b=\sqrt{n}/5\) is at least \(b_{\varepsilon}\), then \(\mathrm{Pr}[\mathrm{per}(\hat{\tilde{y}}_{\sqrt{n}/5}^{i})>0]<\varepsilon.\) Hence, for every \(n\) there is some \(\varepsilon_{n}=o(1)\) so that when the batch size is \(\sqrt{n}/5\) we have that \(\mathrm{Pr}[\mathrm{per}(\hat{\tilde{y}}_{\sqrt{n}/5}^{i})>0]<\varepsilon_{n}.\) Notice that whenever \(\mathrm{per}(\hat{\tilde{y}}_{\sqrt{n}/5}^{i})=0\) the distribution \(\mathrm{P}\) is realizable with respect to the corresponding class \(\mathcal{F}_{\sqrt{n}/5}^{i}\). Let us set \(\delta_{n}=n^{-1/8}.\) Using Hoeffding's inequality we have that with probability at least \(1-e^{-C\cdot\delta_{n}^{2}\cdot\sqrt{n}}=1-e^{C\cdot n^{1/4}},\) where \(C\) is some absolute constant, at least \((1-\varepsilon_{n}-\delta_{n})-\)fraction of the \(\hat{\tilde{y}}_{\sqrt{n}/5}^{i}\) will have \(\mathrm{per}(\hat{\tilde{y}}_{\sqrt{n}/5}^{i})=0.\) Since \(\delta_{n}+\varepsilon_{n}=o(1)\) we have shown the claim. 

**Lemma D.5**.: _Let \(\mathrm{\widetilde{P}}\) be the distribution of the VC dimension of the partial concept classes that are obtained by playing the VCL game on infinitely many i.i.d. samples from \(\mathrm{P}\). Let \(\mathrm{d}^{*}\) be the \(9/10\)-quantile of \(\mathrm{\widetilde{P}}\). Then, for \(n\geq n_{\mathrm{P}}\), where \(n_{\mathrm{P}}\) is some \(\mathrm{P}\)-dependent constant we have that \(\widehat{\mathrm{d}}_{n}=\mathrm{d}^{*}\), with probability at least \(1-3e^{-C_{\mathrm{P}}\cdot n^{1/4}}\), where \(C_{\mathrm{P}}\) is a constant the depends on the data-generating distribution \(\mathrm{P}\)._

Figure 6: The VCL Game (Bousquet et al., 2021).

Proof.: Consider the following experiment. We sample an infinite sequence of labeled points from \(\mathrm{P}\) and we run the VCL game (cf. Figure 6) on this sequence. Let \(\widehat{y}\) be the pattern avoidance function that is obtained from that game defined over \(\widehat{\ell}\) many points and let

\[\widehat{\mathcal{F}}:=\left\{f:\mathcal{X}\to\{0,1,\star\}:(f(x_{1}),\ldots,f (x_{\widehat{\ell}}))\neq\widehat{y}(x_{1},\ldots,x_{\widehat{\ell}})\right\}\,.\]

Let \(d^{*}\in\mathbb{N}\) be the smallest number such that

\[\Pr[\mathrm{d}(\widehat{\mathcal{F}})\leq d^{*}]>9/10\,.\]

Let \(F\) be the CDF of the distribution of the VC dimension of \(\mathcal{F}\), let \(d_{1}<d^{*}<d_{2}\) be the largest, smallest number5 such that \(F(d_{1})\neq F(d^{*}),F(d_{2})\neq F(d^{*})\) and let \(C_{\mathrm{P}}=\min\{F(d^{*})-F(d_{1}),F(d_{2})-F(d^{*})\}/4\). Let \(F_{\sqrt{n}}\) be the empirical CDF of the distribution obtained on \(\sqrt{n}\) i.i.d. samples. Notice that whenever we estimate \(F\) with accuracy \(C_{\mathrm{P}}\) the empirical \(9/10\)-quantile will the same as the true \(9/10\)-quantile. The DKW inequality (Theorem D.1) shows that this happens with probability \(1-2e^{-2C_{\mathrm{P}}^{2}k}\). Let us call this even \(E_{1}\) and condition on it.

Footnote 5: If only one these number exists, then we ignore the one that does not exist in the definition of \(C_{\mathrm{P}}\). If none of these numbers exist then the estimation task is trivial.

Next, we need to handle the fact that we do not obtain samples from partial concept classes that are generated from VCL games on infinitely many i.i.d. samples from \(\mathrm{P}\) but merely on \(\sqrt{n}\) many such samples. Let us consider the following experiment. We run the VCL game on \(k\) streams of infinitely many i.i.d. samples from \(\mathrm{P}\) and if the game has not terminated within the first \(\sqrt{n}\) rounds, we rewind the pattern avoidance function to the one that is obtained in that round. Then, Lemma D.4 shows that, with probability at least \(1-e^{-C\cdot n^{1/4}}\), we will only rewind the pattern avoidance function of a \(o(1)-\)fraction of these games will have converged. We call this event \(E_{2}\) and we condition on it. Let us denote by \(\widehat{F}_{k}\) the empirical CDF of the VC dimension of the partial concept classes obtained by this experiment. Under \(E_{2}\), we have that \(\sup_{x\in\mathbb{N}}|F_{k}(x)-\widehat{F}_{k}(x)|=o(1)\). Thus, by taking \(n\) large enough so that the \(o(1)<<C_{\mathrm{P}}\), we see that the estimation of \(\widehat{\mathrm{d}}_{n}\) using the samples that are obtained from the truncated VCL game also converges to \(\mathrm{d}^{*}\). The bound on the probability of error follows from a union bound over \(E_{1},E_{2}\). 

**Proposition D.6**.: _For \(n>n_{\mathrm{P}},\) where \(n_{\mathrm{P}}\) is some distribution-dependent constant, given \(m=O(n^{3})\) unlabeled samples we can estimate \(p_{n,k},p_{n,k}^{X},p_{n,k}^{(X,y)}\) with accuracy \(o(1)\), with probability at least \(1-C_{\mathrm{P}}\cdot e^{-C_{\mathrm{P}}^{\prime}n^{1/4}},\) where \(C_{\mathrm{P}},C_{\mathrm{P}}^{\prime}>0,\) are distribution-dependent constants._

Proof.: As we alluded to before, using \(O(n^{3})\) unlabeled samples in total we can estimate the quantities \(p_{n,k,i},p_{n,k,i}^{X},p_{n,k,i}^{(X,y)}\) with accuracy \(1/n\) for each version space \(V_{n/5}^{i}\), with probability at least \(1-C_{1}\sqrt{n}e^{-C_{2}\sqrt{n}}\), where \(C_{1},C_{2}>0,\) are absolute constants. Let us denote these estimates \(\widehat{p}_{n,k,i},\widehat{p}_{n,k,i}^{X},\widehat{p}_{n,k,i}^{(X,y)}\) We condition on this event for the rest of the proof.

Assume that \(n\) is large enough and condition on the events of Lemma D.4, Lemma D.5. Let us denote by \(i_{1},\ldots,i_{k}\) the indices of the partial concept classes whose VC dimension is bounded by \(\widehat{\mathrm{d}}_{n}=\mathrm{d}^{*}\). By definition, \(k\geq 9/10\sqrt{n}\). Consider the following statistical experiment. We run the VCL game on infinitely many i.i.d. samples from \(\mathrm{P}\), we define the partial concept class obtained from the pattern avoidance function of the game, if the class has VC dimension at most \(\mathrm{d}^{*}\) we keep the sample, otherwise we discard it. Then, we define its version space on the first \(n/5\) samples of \(S_{2}^{2}\). Let us call \(\widetilde{V}^{i}\) the version space obtained by the \(i\)-th sample of this experiment. Then, \(\mathrm{P}^{k}(x_{1},\ldots,x_{k}\) VC shattered by \(\widetilde{V}^{i}\)) is an unbiased sample from the distribution whose expected value \(p_{n,k}\) we are trying to estimate. Similarly for the rest of the quantities we have defined. Let us call these samples \(\widetilde{p}_{n,k,i},\widetilde{p}_{n,k,i}^{X},\widehat{p}_{n,k,i}^{(X,y)}\) and denote by \(\widetilde{S}_{n},\widetilde{S}_{n}^{X},\widetilde{S}_{n}^{(X,y)}\) their empirical estimates over \(9/10\sqrt{n}\) many samples. Hoeffding's inequality gives us that \(|\widetilde{S}_{n}-p_{n,k}|=o(1),|\widetilde{S}_{n}^{X}-p_{n,k}^{X}|=o(1),| \widetilde{S}_{n}^{(X,y)}-p_{n,k}^{(X,y)}|=o(1),\) with probability at least \(1-Ce^{-C^{\prime}\cdot n^{1/4}}\), for some absolute constants \(C,C^{\prime}>0\). We condition on this event.

Notice that, under the events we have conditioned on, the samples \(p_{n,k,i},p_{n,k,i}^{X},p_{n,k,i}^{(X,y)}\) we obtain from running the VCL game on \(O(\sqrt{n})\) many samples, differ from the samples \(\widetilde{p}_{n,k,i},\widetilde{p}_{n,k,i}^{X},\widetilde{p}_{n,k,i}^{(X,y)}\)on a sublinear number of terms. Moreover, the absolute difference on the terms they disagree on is bounded by 1. Thus, if we denote by \(S_{n},S_{n}^{X},S_{n}^{(X,y)}\) the average of these values we have that \(|\widehat{S}_{n}-S_{n}|=o(1),|\widehat{S}_{n}^{X}-S_{n}^{X}|=o(1),|\widehat{S}_ {n}^{(X,y)}-S_{n}^{X}|=o(1).\) Finally, let \(\widehat{S}_{n},\widehat{S}_{n}^{X},\widehat{S}_{n}^{(X,y)}\) be the averages of \(\widehat{p}_{n,k,i},\widehat{p}_{n,k,i}^{X},\widehat{p}_{n,k,i}^{(X,y)}\). Since \(|\widehat{p}_{n,k,i}-p_{n,k,i}|=o(1),|\widehat{p}_{n,k,i}^{X}-p_{n,k,i}^{X}|=o( 1),|\widehat{p}_{n,k,i}^{(X,y)}-p_{n,k,i}^{(X,y)}|=o(1),\) using the triangle inequality on all the previous estimations we see that \(|\widehat{S}_{n}-p_{n,k}|=o(1),|\widehat{S}_{n}^{X}-p_{n,k}^{X}|=o(1),|\widehat {S}_{n}^{X}(x,y)-p_{n,k}^{(X,y)}|=o(1),\) with probability at least \(1-C_{\mathrm{P}}\cdot e^{-C_{\mathrm{P}}^{\prime}n^{1/4}}\). 

**Lemma D.7**.: _Let \(n>C_{S_{2}^{\infty}},\) where \(C_{S_{2}^{\infty}}\) is some constant that depends on \(S_{2}^{\infty},\mathrm{P}\). Then, with probability at least \(1-C_{\mathrm{P}}\cdot e^{-C_{\mathrm{P}}^{\prime}n^{1/4}}\), for every \(k\leq k^{*}\), if \(\widehat{p}_{n,k}^{X}-\frac{\widehat{p}_{n,k}}{2}\) then \(y=\operatorname*{argmax}_{y\in\{0,1\}}\widehat{p}_{n,k}^{(X,y)}\) is the correct label of \(X\)._

Proof.: Let \(n>C_{S_{2}^{\infty}}\) be large enough so that for all \(k\leq k^{*}\) we have that:

* \[p_{n,k}\leq 100/99\cdot\lim_{n\to\infty}p_{n,k}\,,\]
* the guarantee from Proposition D.6 gives us that \[\widehat{p}_{n,k}^{X}<\frac{\widehat{p}_{n,k}}{2}\implies p_{n,k}^{X}<\frac{3 }{4}\cdot p_{n,k}\,,\]
* and \[p_{n,k}^{(X,y)}\geq\frac{99}{100}p_{n,k} \implies\widehat{p}_{n,k}^{(X,y)}\geq\frac{95}{100}\widehat{p}_ {n,k}\] \[p_{n,k}^{(X,y)}<\frac{80}{100}p_{n,k} \implies\widehat{p}_{n,k}^{(X,y)}<\frac{90}{100}\widehat{p}_ {n,k}\,.\]

We condition on these events for the rest of the proof. Since \(p_{n,k}\leq 100/99\cdot\lim_{n\to\infty}p_{n,k}\) for the correct label \(y^{*}\) we have that \(p_{n,k}^{(X,y^{*})}\geq 99/100\cdot p_{n,k}\). Moreover, since \(p_{n,k}^{X}<3/4\cdot p_{n,k}\) for the other label \(\bar{y}=1-y^{*}\) it holds that \(p_{n,k}^{(X,\bar{y})}<80/100\cdot p_{n,k}\). Thus, under the event we have conditioned on we have that \(\operatorname*{argmax}_{y\in\{0,1\}}\widehat{p}_{n,k}^{(X,y)}\) will indeed be the correct label. The correctness probability follows directly from Proposition D.6. 

**Lemma D.8**.: _For \(k=k^{*}\) we have that \(\Pr\left[\widehat{p}_{n,k^{*}}^{X}\geq\frac{\widehat{p}_{n,k^{*}}}{2}\right]= o(1).\)_

Proof.: Essentially, the proof of this result follows by Markov's inequality. Let us consider some large enough \(n\) and condition on the event described in Proposition D.6. Then, \(\widehat{p}_{n,k^{*}}^{X}\geq\frac{\widehat{p}_{n,k^{*}}}{2}\implies p_{n,k^ {*}}^{X}\geq\frac{p_{n,k^{*}}}{4}\), so it suffices to bound

\[\Pr\left[p_{n,k^{*}}^{X}\geq\frac{p_{n,k^{*}}}{4}\right]\,.\]

Using Markov's inequality, we have that

\[\Pr\left[p_{n,k^{*}}^{X}\geq\frac{p_{n,k^{*}}}{4}\right] \leq\frac{4\,\mathbb{E}[p_{n,k^{*}}^{X}]}{p_{n,k^{*}}}\] \[=\frac{4p_{n,k^{*}+1}}{p_{n,k^{*}}}\] \[=o(1)\,.\]

where we have used the fact that \(\mathbb{E}[p_{n,k^{*}}^{X}]=p_{n,k^{*}+1}\) and that \(p_{n,k^{*}}\) is bounded below by a constant.

We now state the guarantees of ActiveSelect (Hanneke, 2012). We note that the original statement of the result did not specify the size of the unlabeled dataset that the algorithm uses, but a straightforward adaptation of it shows that with \(O(n^{3})\) many unlabeled data its error guarantee changes increases by \(O(1/n^{2})\).

**Lemma D.9** (Hanneke (2012)).: _A call to ActiveSelect (cf Figure 8) with \(N\) classifiers \(\{h_{1},\dots,h_{N}\}\), a query budget of \(m\), and \(O(N^{2}/n^{3})\) unlabeled points makes at most \(m\) label queries and if \(h_{\widehat{k}}\) is the classifier it returns, then with probability at least \(1-C_{1}\cdot Ne^{-C_{2}\cdot m/(N^{2}\log(N))},\) we have \(\operatorname{er}(h_{\widehat{k}})\leq 2\min_{k\in[N]}\operatorname{er}(h_{k})+O(1 /n^{2}).\)_

We are now ready to prove the main result in this section. The algorithm is summarized in Figure 7.

**Theorem D.10**.: _Assume that \(\mathbb{H}\subseteq\{0,1\}^{\mathcal{X}}\) does not have an infinite VCL tree. Then, \(\mathbb{H}\) admits an active learning algorithm that achieves sublinear rates._

Proof.: We have all the main ingredients we need to prove our result. Let us fix some \(S_{2}^{\infty}\) whose elements are i.i.d. from \(\mathrm{P}\). Conditioning on the results of Lemma D.7, Lemma D.8, we have that for large enough \(n\), which depends on \(S_{2}^{\infty},\) we can obtain a labeled dataset \(L_{n}\) whose size is \(\omega(n)\). Feeding this dataset into the supervised learning algorithm from Bousquet et al. (2021) gives as a classifier \(\widetilde{h}_{n}\) that, conditioned on \(S_{2}^{\infty}\) and the events \(E\) we have described, has error

\[\mathbb{E}[\operatorname{er}(\widetilde{h}_{n})|S_{2}^{\infty},E]=o(1/n)\,.\]

Moreover, the probability of \(E\) is also \(o(1/n)\), so we get

\[\mathbb{E}[\operatorname{er}(\widetilde{h}_{n})|S_{2}^{\infty}]=o(1/n)\,.\]

Similarly, for the output \(\widehat{h}_{n}\) of ActiveSelect, we have that

\[\mathbb{E}[\operatorname{er}(\widehat{h}_{n})|S_{2}^{\infty}] =o(1/n)\] \[\mathbb{E}[\operatorname{er}(\widehat{h}_{n})] =O(1/n)\,,\]

where the second bound comes from the fact that we feed into ActiveSelect the output of the passive learning algorithm \(\widehat{h}_{n}^{p}\) from Bousquet et al. (2021) (cf. Theorem D.3), whose bound does not not depend on \(S_{2}^{\infty}\).

Let us call \(R(n)\) the error rate of our algorithm. To show that \(\mathbb{E}[R(n)]=o(1/n)\) it suffices to prove that \(\limsup_{n\to\infty}\mathbb{E}[n\cdot R(n)]=0\). Fatou's lemma gives us that

\[\limsup_{n\to\infty}n\cdot\mathbb{E}[\cdot R(n)] =\limsup_{n\to\infty}n\cdot\mathbb{E}[\cdot R(n)]\] \[=\limsup_{n\to\infty}\mathop{\mathbb{E}}_{S_{2}^{\infty}}[ \mathbb{E}[n\cdot R(n)|S_{2}^{\infty}]]\] \[\leq\mathop{\mathbb{E}}_{S_{2}^{\infty}}[\limsup_{n\to\infty}n \cdot\mathbb{E}[R(n)|S_{2}^{\infty}]]\] \[=0\,,\]

where Fatou's lemma applies since \(\mathbb{E}[n\cdot R(n)|S_{2}^{\infty}]\leq C_{\mathrm{P}}\) where \(C_{\mathrm{P}}\) is some \(\mathrm{P}-\)dependent constant. This is because, almost surely over \(S_{2}^{\infty}\), the expected error of \(\widehat{h}_{n}^{p}\) is bounded by \(C_{\mathrm{P}}^{\prime}/n\).

### Arbitrarily Slow Rates Lower Bound

**Theorem D.11** (Hanneke et al. (2022)).: _If \(\mathbb{H}\) has an infinite VCL tree, no active learning algorithm can achieve rates that are faster than arbitrarily slow._
a passive learning algorithm \(A_{p}\)

1. Let \(S_{1},S_{2},S_{3},S_{4},S_{5},U\) be sets of \(O(N^{3})\) unlabeled points that are i.i.d. from \(\mathrm{P}_{\mathcal{X}}\).
2. Request the labels of the first \(N/5\) points of \(S_{5}\) and run \(A_{p}\) on this set. Let \(\widehat{h}_{N}^{p}\) be its output.
3. Request the labels of the first \(N/5\) points of \(S_{1}\), split them into batches of size \(O(\sqrt{N})\) and run the VCL game on them (cf. Figure 6).
4. Let \(\widehat{y}_{\sqrt{N}/t}^{i},i\in[\sqrt{N}],\) be the pattern avoidance functions from the previous step and for every \(i\in[\sqrt{N}]\) define \[\mathcal{F}_{\sqrt{N}/5}^{i}:=\left\{f:\mathcal{X}\to\{0,1,\star \}:(f(x_{1}),\ldots,f(x_{\ell_{\sqrt{N}/5}^{i}}))\neq\right.\] \[\left.\widehat{y}_{\sqrt{N}/5}^{i}(x_{1},\ldots,x_{\ell_{\sqrt{N}/5 }^{i}})\right\}.\]
5. Let \[\widehat{\mathrm{d}}_{N}:=\min_{d\in\mathbb{N}}\left\{\exists i_{1},i_{2}, \ldots,i_{9/10\cdot\sqrt{N}}\in[\sqrt{N}]:\right.\] \[\left.i_{1}<i_{2}<\ldots<i_{9/10\cdot\sqrt{N}},\mathrm{d}(\mathcal{F}_{ \sqrt{N}/5}^{i_{j}})\leq d,\forall j\in[9/10\sqrt{N}]\right\}.\]
6. Request the labels of the first \(N/5\) points of \(S_{2}\) and let \[V_{N/5}^{i}:=\left\{f\in\mathcal{F}_{\sqrt{N}/5}^{i}:f(x)=y\text{ for these }N/5\text{ point}\right\}.\]
7. For \(k=0,\ldots,\widehat{\mathrm{d}}_{N}\): 1. Let \(\widetilde{S}_{3}\) be the next \(n^{2}\) examples in \(S_{3}\) and \(\widetilde{m}_{N}=N/(5(\widehat{d}_{N}+1))\) be the label budget. 2. Let \(\widehat{S}=\{\}\) 3. For each point \(X\in\widetilde{S}_{3},y\in\{0,1\}\): 1. Estimate \(\widehat{p}_{N,k},\widehat{p}_{N,k}^{X},\widehat{p}_{N,k}^{(X,y)}\) using \(V_{N/5}^{i}\) and fresh unlabeled points from \(U\) as described in Proposition D.6. 2. If \(\widehat{p}_{N,k}^{X}\leq\widehat{p}_{N,k}/2\) infer \(y^{*}=\operatorname*{argmax}_{y\in\{0,1\}}\widehat{p}_{N,k}^{(X,y)}\), otherwise request the label \(y^{*}\) of \(X\). 3. Append \((X,y^{*})\) to \(\widehat{S}\) and update the label budget \(\widetilde{m}_{N}\). If \(\widetilde{m}_{N}=0\) jump to Step (d). 4. Run \(A_{p}\) on \(\widehat{S}\) and let \(\widehat{h}_{k}\) be its output.
8. Return (cf. Figure 8).

Figure 7: Sublinear Rates Algorithm.

**ActiveSelect**(Hanneke, 2012) Input is a set of classifiers \(\{h_{1},\ldots,h_{L}\}\), label budget \(m\), sequence of unlabeled examples \(\mathcal{U}\).

1. For each \(j,k\in\{1,\ldots,N\}\) s.t. \(j<k\): 1. Let \(R_{jk}\) be the first \(\left\lfloor\frac{m}{j(L-j)\ln(eL)}\right\rfloor\) points in \(\mathcal{U}\cap\{x:h_{j}(x)\neq h_{k}(x)\}\) (if such value exists). 2. Request the labels for \(R_{jk}\) and let \(Q_{jk}\) be the set of labeled examples. 3. Let \(m_{kj}=\operatorname{er}_{Q_{jk}}(h_{k})\).
2. Return \(h_{\hat{k}}\), where \(\hat{k}=\max\left\{k\in\{1,\ldots,L\}:\max_{j<k}m_{kj}\leq 7/12\right\}.\)

Figure 8: ActiveSelect Algorithm (Hanneke, 2012).

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The main body and supplementary material of the submission provide proofs for all the claims. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We formally define the mathematical model our results hold for. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: We present full proofs in the main body and the supplementary material. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [NA] Justification: Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA] Justification: Guidelines:

* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: Guidelines:

* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.

* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: The work is primarily theoretical and does not have any immediate societal impact. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.