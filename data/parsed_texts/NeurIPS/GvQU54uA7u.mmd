# Preference-based Pure Exploration

 Apurv Shukla

Department of ECE, Texas A&M University

College Station, TX 77840

apurv.shukla@umich.edu &Debabrota Basu

Equipe School, Univ. Lille, Inria, CNRS

Centrale Lille, UMR-9189 - CRIStAL, France

debabrota.basu@inria.fr

This work was done when the author was at Texas A& M University. The author is currently at the University of Michigan, Ann Arbor.

###### Abstract

We study the preference-based pure exploration problem for bandits with vector-valued rewards. The rewards are ordered using a (given) preference cone \(\mathcal{C}\) and our goal is to identify the set of Pareto optimal arms. First, to quantify the impact of preferences, we derive a novel lower bound on sample complexity for identifying the most preferred policy with a confidence level \(1-\delta\). Our lower bound elicits the role played by the geometry of the preference cone and punctuates the difference in hardness compared to existing best-arm identification variants of the problem. We further explicate this geometry when the rewards follow Gaussian distributions. We then provide a convex relaxation of the lower bound and leverage it to design the Preference-based Track and Stop (PreTS) algorithm that identifies the most preferred policy. Finally, we show that the sample complexity of PreTS is asymptotically tight by deriving a new concentration inequality for vector-valued rewards.

## 1 Introduction

Following COVID-19, the importance of reliable clinical trials and corresponding data acquisition to design effective drugs has gained wider recognition. However, conducting large-scale clinical trials is cost and time intensive as it requires working with large number of patients and following up their medical conditions over time. In the past two decades, this has led to doubling in the cost to bring a drug to the market, i.e., to \(\$2.6\) billion with a 12-year drug development horizon and 90% failure rate during the clinical trial (Mullard, 2014; Sun et al., 2022). However, due to the rise of systematic data acquisition about biological systems, pharmaceutical firms are interested in harvesting the collected data for drug discovery (Gaulton et al., 2012; Reker and Schneider, 2015). Thus, machine learning-based methods are increasingly studied and deployed as a promising avenue for identifying potentially successful drugs with less patient involvement, increasing the "hit rate", and speeding up the development process (Jayatunga et al., 2022; Smer-Barreto et al., 2023; Sadybekov and Katritch, 2023; Hasselgren and Oprea, 2024). But deciding whether a drug is successful depends on multiple and often conflicting objectives regarding safety, efficacy, and pharmacokinetic constraints (Lizotte and Laber, 2016). For example, COV-BOOST (Munro et al., 2021) demonstrates a phase II vaccine clinical trial conducted on 2883 participants to measure the immunogenicity indicators (e.g. cellular response, anti-spike IgG and NT\({}_{50}\)) of different Covid-19 vaccines as a booster (third dose). Experts decide how different indicators are preferred over one another, and above different thresholds (Jayatunga et al., 2022). This motivates us to study a sequential decision-making problem, where we aim to conduct minimum number of experiments to acquire informative data, and to reliably validate a hypothesis with multiple objectives by imposing preferences over them.

Problems of such nature can be modeled as a multi-armed bandit (in brief, bandits), which is an established framework for sequential decision-making under uncertainty (Lattimore and Szepesvari, 2020). In bandits, a learner has access to an instance of \(K\) decisions (or arms). Each arm \(k\in\{1,\ldots,K\}\) corresponds to a probability distribution \(P_{k}\) of feedback (rewards) with unknown mean \(\mu_{k}\). At each step \(t\in\mathbb{N}\), the learner interacts with the instance by taking a decision \(k_{t}\) (analogously pulling an arm), and observes a noisy reward \(R_{t}\) from the corresponding distribution of rewards \(P_{k_{t}}\). The goal of the learner is to identify the arm with the highest expected reward over a certain confidence level through minimum number of interactions with the instance. This is popularly known as a fixed-confidence Best Arm Identification (BAI) in bandit literature (Jamieson and Nowak, 2014; Garivier and Kaufmann, 2016; Soare et al., 2014), which is a special case of pure exploration problems (Even-Dar et al., 2006; Bubeck et al., 2009; Auer et al., 2016).

The bandit literature spanning over a century mostly focuses on a scalar reward, i.e., a single objective. In our problem, each reward \(R_{t}\) is a real-valued vector of \(L\in\mathbb{N}\) objectives, and thus, the unknown mean vector of each arm \(M_{k}\in\mathbb{R}^{L}\). Since the objectives can be often conflicting, there might not exist a single best arm. Rather, there exists a Pareto Optimal Set of arms (Drugan and Nowe, 2013; Auer et al., 2016). Given a set of preferences over the objectives, the Pareto Optimal Set consists of arms whose mean vectors dominate the mean vectors of any other arm outside the set. Keeping generality, we assume that preferences are defined by a cone of vectors \(\mathcal{C}\subseteq\mathbb{R}^{L}\). Every \(\mathcal{C}\) induces a set of partial or incomplete orders over the \(L\) objectives (Jahn et al., 2009; Lohne, 2011). Given the preference cone \(\mathcal{C}\), we aim to _exactly_ identify the complete Pareto Optimal Set with a confidence level \((1-\delta)\in[0,1)\) using as few interactions as possible. We refer to this problem Preference-based Pure Exploration (**PrePEx**). Recently, Auer et al. (2016); Kone et al. (2023a,b); crepon et al. (2024) consider a special case of PrePEx, where the preference is known. To the best of our knowledge, Ararat and Tekin (2023) and Korkmaz et al. (2023) are the only studies of PrePEx from frequentist and Bayesian angles, respectively. Here, we consider a frequentist approach as in (Ararat and Tekin, 2023). However, their goal is to identify points that are in the Pareto Optimal Set or very close to it. In contrast, we focus on exactly identifying the Pareto Optimal Set. Additionally, Ararat and Tekin (2023) propose a gap-based elimination algorithm to solve the problem that generalises the algorithm of Even-Dar et al. (2006). But in BAI, there is another paradigm of designing efficient algorithms that solves and tracks the exact lower bound on the expected time to identify the best arm \((1-\delta)\) correctly (Garivier and Kaufmann, 2016; Degenne and Koolen, 2019). We explore this paradigm for PrePEx and ask two questions:

_What is the exact lower bound of_ PrePEx _for identifying the Pareto Optimal Set, and how to design a computationally tractable algorithm matching this bound?_

We address them affirmatively in our contributions:

**1. Lower Bound for PrePEx.** In Theorem 3.1, we study hardness of PrePEx problems by deriving the novel lower bound on the expected sample complexity of any algorithm to yield the exact Pareto Optimal Set with confidence \((1-\delta)\). The challenge here is to extend the classical BAI lower bound (Garivier and Kaufmann, 2016) to a set of confusing instances given \(\mathcal{C}\). We observe that unlike BAI, distinguishability of two arms in PrePEx depends on their projections on the cone polar to \(\mathcal{C}\). We also show that our lower bound generalises the lower bound for pure exploration under known constraints (Carlsson et al., 2024). Additionally, we provide an exact characterization the lower bound further for Gaussian reward distributions in Theorem 3.2. It shows that the hardness depends on the bilinear projection of the mean matrix of arms onto the boundary of a normal cone of policies and the preferences. This is novel w.r.t. the existing gap-dependent lower bounds that hold either for a narrow range of \(\mu_{a}\)'s (Ararat and Tekin, 2023), or fixed preference (Kone et al., 2023a).

**2. Algorithm Design.** First, we observe that the optimisation problem in our lower bound involves minimisation over a non-convex set. We provide a convex relaxation of the problem based on ideas from disjunctive programming (Theorem 4.1 and 4.2). We then leverage this lower bound to propose a novel Track-and-Stop (Garivier and Kaufmann, 2016) style algorithm, called PreTS (Preference-based Track-and-Stop). In Theorem 4.3, we devise a new stopping rule that can handle the preference-aligned suboptimality gaps between the arms.

**3. Sample Complexity Analysis.** Finally, we provide an upper bound on sample complexity of PreTS. This requires us to define a distance metric between two pareto sets of arms, and proving a concentration bound with respect to this metric (Theorem 5.1). In Theorem 5.2, we prove that sample complexity of PreTS matches the convexified lower bound up to constants.

### Related Works

In the past decade, works on multi-armed bandits also focuses on pure-exploration in addition to regret minimization. Regret minimization and pure-exploration differ in the sense when arms in pure-exploration are immediately discarded upon being deemed as sub-optimal, whereas, in the regret minimization setting, sub-optimal arms may still be played since they provide additional information about other arms. Pure-exploration problems have been considered in two settings: fixed-budget and fixed-confidence. The fixed-budget setting aims at bounding the probability of underestimating the best arm given a budget of samples. Audibert and Bubeck (2010) propose the first algorithm for the fixed budget setting. Here, the budget is divided into \(K-1\) rounds and at the end of every round, the arms with the lowest empirical mean are discarded. On the other hand, best-arm identification is a version of the pure-exploration problem with scalar rewards (Even-Dar et al., 2006). In this setting, we are given a \(\delta\in(0,1)\) and the goal is to identify the best-arm with probability at least \(1-\delta\). Several strategies such as those based on elimination, adaptivity, racing, upper-confidence bounds have been proposed to minimize the number of expected pulls of an arm in the fixed confidence setting by (Kalyanakrishnan et al., 2012; Gabillon et al., 2012; Jamieson et al., 2014; Garivier and Kaufmann, 2016; Jedra and Proutiere, 2020). Arm rewards can be modeled as a vector with Gaussian Process (Zuluaga et al., 2016), linear rewards (Drugan and Nowe, 2013; Lu et al., 2019), and non-parametric rewards (Turgay et al., 2018), which can include contextual bandit formulations (Tekin and Turgay, 2017; Shukla, 2022). In recent past, the pure exploration techniques have been successfully applied in hyperparameter tuning (Li et al., 2018) and black-box optimization problems (Contal et al., 2013; Wang et al., 2021, 2022) demonstrating considerable performance gains.

In a marked deviation, given an instance of the bandit problem, the goal of this paper is to identify the entire Pareto front. A key observation in this regard is that there might be arms, which are sub-optimal for almost every objective but still lie on the Pareto front. Further, since sampling an arm returns a vector of rewards determining an arm-strategy that reduces the uncertainty in the estimate of every reward function is challenging. An immediate consequence of these differences is the fact that the complexity of identifying the Pareto front is different from that of best arm identification. Auer et al. (2016) consider the Pareto front identification problem in the multi-armed bandit model and establish sample complexity bounds for the problem in terms of relevant problem parameters in the fixed-confidence setting. The multi-armed bandit problem is further studied under cone-based preferences by Ararat and Tekin (2023). The main contribution of (Ararat and Tekin, 2023) are bounds on the sample complexity of the problem in terms of gap-based notions that depend on the cone. Karagozlu et al. (2024) builds upon this work to introduce adaptive elimination based algorithms for learning the Pareto front under incomplete preferences. When the reward vectors are Gaussian processes Korkmaz et al. (2023) propose an elimination based algorithm based for identifying the Pareto front. The goal in these works is to identify the set of arms that are \(\epsilon\) close to the Pareto front as the sample complexity to identify the exact Pareto set can be very large. Kone et al. (2023) consider the problem of identifying a relevant subset of the Pareto set using a single sampling strategy Adaptive Pareto Exploration, along with different stopping rules to consider variations of the Pareto Set Identification problem. crepon et al. (2024) consider the exact Pareto front identification problem in the multi-armed bandit setting but with fixed and known preference cone. They propose a lower bound and a computationally efficient gradient-based algorithm to implement a track-and-stop based strategy. To the best of our knowledge, ours is the first work to consider _the exact Pareto front identification problem from a pure-exploration perspective_. Therefore, our proposed framework can be used for identifying the Pareto front given a preference cone for several variants of the bandit problem including the standard multi-armed bandit problem, linear bandits, etc.

## 2 Preference-based Pure Exploration Problem

In this section, we formalise the fixed-confidence setting of preference-based pure exploration and introduce the notations.

**Notations.** For \(n\in\mathbb{N}\), let \([n]\) denote the set \(\{1,2,\ldots,n\}\). We use \(\|\cdot\|_{1},\|\cdot\|_{2},\|\cdot\|_{\infty}\) to denote the \(\ell_{1}\)-norm, \(\ell_{2}\)-norm and \(\ell_{\infty}\)-norm, respectively. For a vector \(z,\ z^{(\ell)}\) denotes its \(\ell^{th}\) component. Let \(e_{\ell}\) denote the vector with \(1\) in the \(\ell^{th}\) position and zero otherwise. \(\Delta_{K}\) denotes the simplex on \([K]\). \(d_{\text{KL}}\left(P,Q\right)\) measures the KL-divergence between distributions \(P\) and \(Q\). \(\operatorname{vect}(A)\) is the vectorized version of matrix \(A\). \(\mathbf{1}\) is the vector of all \(1\)'s. Further details of notations are deferred to Appendix A.

**PrePEx: Problem Formulation.** In PrePEx, a learner can access a bandit instance with \(K\) arms. Each arm \(k\in[K]\) corresponds to a reward distribution \(P_{k}\) over \(\mathbb{R}^{L}\) with unknown mean \(M_{k}\in\mathbb{R}^{L}\) and known covariance \(\Sigma=\mathrm{Diag}(\sigma_{1}^{2},\ldots,\sigma_{L}^{2})\). Here, \(L\) denotes the number of objectives corresponding to each arm. Thus, a bandit instance can be specified with the vector of mean rewards \(\{M_{k}\}_{k=1}^{K}\). For brevity, we represent them with a matrix \(M\in\mathbb{R}^{L\times K}\) such that its \(k^{\mathrm{th}}\) column is \(M_{k}\). At each time \(t\in\mathbb{N}\), the learner pulls an arm \(k_{t}\in[K]\) and observes the corresponding reward vector \(R_{t}\) sampled from \(\nu_{k_{t}}\). In pure exploration, the learner typically focuses on finding the best arm, i.e. the arm with highest mean (Garivier and Kaufmann, 2016). In pure exploration, a more general setting of BAI, the learner aims to find a policy \(\pi\in\Delta_{K}\) that dictates the arm-proportion to choose to maximize the expected reward from the instance.

Following the vector optimization literature (Jahn et al., 2009; Ararat and Tekin, 2023), we assume that the learner has additionally access to an ordering cone \(\mathcal{C}\).

**Definition 2.1** (Ordering Cone).: _A set \(\mathcal{C}\subseteq\mathbb{R}^{L}\) is called a cone if \(v\in\mathcal{C}\) implies that \(\alpha v\in\mathcal{C}\) for all \(\alpha\geq 0\). A solid cone has a non-empty interior, i.e., \(\mathrm{int}(\mathcal{C})\neq\emptyset\). A pointed cone contains the origin. A closed convex, pointed and solid cone is called an ordering cone._

An ordering cone can be both polyhedral and non-polyhedral. Following the literature (Ararat and Tekin, 2023; Karagozlu et al., 2024), we consider access to a polyhedral ordering cone.

**Definition 2.2** (Polyhedral Ordering Cone).: _An ordering cone \(\mathcal{C}\) is a polyhedral cone if \(\mathcal{C}\triangleq\{x\in\mathbb{R}^{L}\mid Ax\geq 0\}\), where \(A\in\mathbb{R}^{K\times L}\) with rows \(a_{i}^{\top}\). \(A\) is called the half-space representation of \(\mathcal{C}\)._

Each polyhedral ordering cone induces a set of partial order on the reward vectors in \(\mathbb{R}^{L}\). To ignore the redundancies and to focus on the bandit problem, we further assume that \(A\) is full row-rank and \(\|A_{i}\|_{2}=1\)(Ararat and Tekin, 2023). Hereafter, we call them _preference cones_, and the vectors in the cone as the _preferences_. We refer to (Jahn et al., 2009; Lohne, 2011) for further details on cones.

**Example 2.1** (Preference cones).: _The positive orthant \(\mathbb{R}^{L}_{+}\) is a polyhedral ordering cone. This is the one used in the pareto-set identification literature (Auer et al., 2016; Kone et al., 2023b; crepon et al., 2024). The cones with all non-negative entries are called solvency cones and used in finance (Kabanov, 2009). Another simple example is \(\mathcal{C}_{\pi/3}\triangleq\{(r\cos\theta,r\sin\theta)\in\mathbb{R}^{2} \mid r\geq 0\wedge\theta\in[0,\pi/3]\}\), i.e.,all the 2-dimensional vectors that make an angle less than \(\pi/3\) with the \(x\)-axis._

**Definition 2.3** (Partial Order).: _For every \(\mu,\mu^{\prime}\in\mathbb{R}^{L},\mu\preceq_{\mathcal{C}}\mu^{\prime}\) if \(\mu\in\mu^{\prime}+\mathcal{C}\) and \(\mu\prec_{\mathcal{C}}\mu\) if \(\mu\in\mu^{\prime}+\mathrm{int}(\mathcal{C})\). Alternatively, \(\mu\preceq_{\mathcal{C}}\mu^{\prime}\) is equivalent to \(z^{\top}(\mu-\mu^{\prime})\leq 0,\forall z\in\mathcal{C}\)._

The partial order induced by \(\mathcal{C}\) induces further order over the set of arms \([K]\).

**Definition 2.4** (Order over arms).: _Consider two arms \(i,j\in[K]\). (i) Arm \(i\) is weakly dominated by arm \(j\) iff \(M_{i}\preceq_{\mathcal{C}}M_{j}\). (ii) Arm \(i\) dominates arm \(j\) iff \(M_{j}\prec_{\mathcal{C}\setminus\{0\}}M_{i}\). (iii) Arm \(i\) strongly dominates arm \(j\) iff \(M_{j}\prec_{\mathcal{C}}M_{i}\)._

**Definition 2.5** (Pareto Optimal Set).: _An arm \(i\in[K]\) is Pareto Optimal if it is not dominated by any other arm w.r.t. the cone \(\mathcal{C}\). The Pareto Optimal Set \(\mathcal{P}^{*}\) is defined as the set of all Pareto Optimal arms._

Given a preference cone, a learner aims to identify exactly the Pareto Optimal Set from a finite set of arms \([K]\) whose mean rewards belong to the Pareto Optimal Set w.r.t. \(\mathcal{C}\). Alternatively, this vector optimization problem can be represented in the policy space as finding a policy \(\pi\in\Delta_{K}\) supported on the Pareto Optimal Set of arms. The following vector optimization problem yields this:

\[V(M)\triangleq\max_{\pi\in\Delta_{K}}\ M\pi\text{ over }\mathcal{C}.\] (1)

In this context, we denote the set of Pareto optimal policies as \(\Pi^{*}(M)\triangleq\arg\max_{\pi\in\Delta_{K}}\ M\pi\) over \(\mathcal{C}\). We assume that \(\Pi^{*}(M)\) is non-empty.

**Example 2.2** (Pareto Optimal Sets for different cones).: _Figure 1 illustrates the Pareto Optimal Sets among \(2\)-dimensional mean vectors of \(200\) randomly selected arms under preference cones \(\mathcal{C}_{\pi/2}\)

Figure 1: Effect of cone selection on size of Pareto optimal setand \(\mathcal{C}_{\pi/3}\). We observe that the Pareto Optimal Sets for them (in pink and blue respectively), are completely different for the same set of arms. Thus, we have to adapt to the available preferences to solve the aforementioned problem. As noted later, the geometry of this cone plays a crucial role in determining the Pareto front._

In PrePEx, we consider the problem of Equation (1), when the mean matrix \(M\) is unknown a priori but bounded, i.e., the entries of \(M,\ M_{ij}\in[M_{\min},M_{\max}]\). We denote all such mean matrices by \(\mathcal{M}\). Identifying the policy will lead us to identify the true Pareto front \(\mathcal{P}^{*}\). In the noisy feedback setting, the reward at time \(t\) is \(R_{t}=M_{k_{t}}+\eta_{t}\), where \(\eta_{t}\in\mathbb{R}^{L}\) is the noise vector. We assume that the noise vectors \(\eta_{t}\) are independent of \(M_{k_{t}}\) and also across time. Further, they are sub-Gaussian with parameter \(\sigma\) and adapted to the filtration \(\mathcal{F}_{t}\), which is a standard assumption in the literature. A policy \(\pi\in\Pi\subset\Delta^{K}\) is a randomized mapping from the history \(\mathcal{H}_{t}\) to the probability simplex over the set of arms \([K]\). _In Preference-based Pure EXploration (PrePEX) problem, the goal of the learner is to identify a Pareto optimal policy in \(\Pi^{*}\) (Equation (1)) given an instance \(M\) and a preference cone \(\mathcal{C}\) while observing only noisy rewards from the arms, and also using as few observations as possible._

**Definition 2.6** (\((1-\delta)\)-correct PrePEX).: _An algorithm for Preference-based Pure Exploration (PrePEx) is said to be \((1-\delta)\) correct if with probability \(1-\delta\), it recommends a Pareto optimal policy \(\pi\in\Pi^{*}\)._

For example, a pareto optimal policy for \(\mathcal{C}_{\pi/2}\) would be a distribution in \(\Delta_{K}\) with support on the arms corresponding to the pink reward vectors (Figure 1). For \(\mathcal{C}_{\pi/3}\), it would be one with support on blue points. Finally, we make the standard assumption on the mean rewards.

**Assumption 2.1** (Single Parameter Exponential Family).: _Let \(X=(X_{1},,X_{d})\) be a \(d\)-dimensional random vector with a distribution \(P_{\theta},\theta\in\Theta\). Suppose \(X_{1},\ldots,X_{d}\) are jointly continuous. The family of distributions \(\{P_{\theta},\theta\in\Theta\}\) is said to belong to the one parameter Exponential family if the density of \(X\) may be represented in the form \(f(x|\theta)\triangleq h(x)\exp\left(\eta(\theta)T(x)-\psi(\theta)\right)\). We assume that the mean reward for each vector belongs to a single-parameter exponential family with variance bounded by \(1\)._

## 3 Lower Bound on Sample Complexity

We begin by deriving a KL-divergence based lower bound for PrePEx using techniques from (Garivier and Kaufmann, 2016). Our lower bound is based on establishing a change-of-measure argument in the spirit of (Graves and Lai, 1997; Kaufmann et al., 2016). The lower bounds are derived first by defining a set of alternating instances \(\Lambda\) for a given bandit instance and then by trying to compute an optimal allocation policy \(w\in\Delta_{K}\) that maximises the sum of minimum KL-divergence between any instance in \(\Lambda\) and the bandit instance under interaction. _The key insight of our work is to formulate the identification of Pareto Set problem in the policy space rather than in the arm space as done in antecedent literature._ This formulation helps us to derive the KL-based lower bound, which is more general than the existing suboptimality gap-based lower bounds (Auer et al., 2016; Ararat and Tekin, 2023; crepon et al., 2024).

**The Alternating Instances with respect to Pareto Fronts.** The learner needs to distinguish between all instance \(\tilde{M}\in\mathcal{M}\setminus\{M\}\) for which the Pareto front associated with \(\tilde{M}\) is different from the one associated with \(M\). At first, given an optimal policy of \(M\), say \(\pi^{*}\), it would appear that the set of confusing instances is \(\Lambda_{\pi^{*}}\left(M\right)^{\mathrm{naive}}\triangleq\left\{\tilde{M} \in\mathcal{M}:\tilde{M}\pi^{*}\preceq_{\mathcal{C}}\max_{\pi\in\Pi}\tilde{M} \pi\right\}\). However, this is fallacious since the instances whose rewards dominate \(M\) can also confuse a policy \(\pi\). Given a \(\pi^{\star}\), the correct alternating set is the set of instances in \(\mathcal{M}\) whose Pareto optimal set is not dominated by \(\pi^{\star}\) corresponding to \(M\).

\[\Lambda_{\pi^{*}}\left(M\right) \triangleq\left\{\tilde{M}\in\mathcal{M}\setminus\{M\}:\max_{\pi \in\Pi}\tilde{M}\pi\not\preceq_{\mathcal{C}}\tilde{M}\pi^{*}\right\}\] \[=\left\{\tilde{M}\in\mathcal{M}\setminus\{M\}:\exists z\in \mathcal{C}\ \mathrm{s.t.}\ \max_{\pi\in\Pi}z^{\top}\tilde{M}\pi>z^{\top}\tilde{M}\pi^{*}\right\}\,.\]

With this new alternate set defined, we now establish lower bounds on the performance of any PrePEX algorithm.

**Theorem 3.1** (Lower Bound).: _Given a bandit model \(M\in\mathcal{M}\), a preference cone \(\mathcal{C}\), and a confidence level \(\delta\in[0,1)\), the expected stopping time of any \((1-\delta)\)-correct PrePEx algorithm, to identify the _Pareto Optimal Set is_

\[\mathbb{E}[\tau]\geq\mathcal{T}_{M,\mathcal{C}}\log\left(\frac{1}{2.4\delta} \right),\] (2)

_where, the expectation is taken over the stochasticity of both the algorithm and the bandit instance. Here, \(\mathcal{T}_{M,\mathcal{C}}\) is called the characteristic time of the PrePEx instance \((\mathcal{M},\mathcal{C})\) and is expressed as_

\[(\mathcal{T}_{M,\mathcal{C}})^{-1}\triangleq\sup_{w\in\Delta}\inf_{\begin{subarray} {c}\pi\in\Pi\setminus\{\pi^{*}\}\\ \pi^{*}\in\Pi^{*}(M)\end{subarray}}\inf_{\tilde{M}\in\partial\Lambda_{\pi^{*} }(M)}\inf_{z\in\mathcal{C}}\sum_{k=1}^{K}w_{k}d_{\text{KL}}\left(z^{\top}M_{k},z^{\top}\tilde{M}_{k}\right)\,,\] (3)

_such that \(\partial\Lambda_{\pi^{*}}\left(M\right)\triangleq\cup_{\Pi\setminus\{\pi^{*} \}}\left\{\tilde{M}\in\mathcal{M}:\exists\;z\in\mathcal{C},\;\langle\operatorname{ vect}\left(z(\pi-\pi^{*})^{\top}\right),\operatorname{vect}\bigl{(}\tilde{M} \bigr{)}\rangle=0\right\}.\)_

_Proof_ _Intuition._ First, we observe that an instance \(\tilde{M}\) is in alternating set if there exists a \(\pi\in\Pi\setminus\{\pi^{*}\}\) and \(z\in\mathcal{C}\), such that \(z^{\top}\tilde{M}(\pi-\pi^{*})>0\). If \(\pi\) and \(\pi^{*}\) were pure strategies, it would have been exactly \(\inf_{z\in\mathcal{C}\setminus\{0\}}z^{\top}(\tilde{M}_{a}-\tilde{M}_{a^{*}})>0\). Let us denote the \(z\) achieving the \(\inf\) as \(z_{\inf}\), i.e., the preference for which \(\tilde{M}_{a}\) and \(\tilde{M}_{a^{*}}\) are least distinguishable. Thus, we observe that \(z_{\inf}^{\top}\tilde{M}_{a}\) exactly functions as the mean of the arm \(a\) in an instance \(\tilde{M}\), whereas \(z_{\inf}^{\top}(\tilde{M}_{a^{*}}-M_{a})\) acts as the suboptimality gap. Now, we extend this idea in the classical lower bound scheme to get a nested optimization problem with \(\inf\) over \(z\in\mathcal{C}\) and \(\tilde{M}\) in the alternating set, and a sup over allocations \(w\in\Delta_{K}\). We further show that the \(\inf\) for \(\tilde{M}\) appears at the boundary of the alternating set defined as \(\partial\Lambda(M)\).

**Discussions.** (i) Novelty: In the best of our knowledge, this is the first lower bound for PrePEx with fixed confidence with an explicit KL-based dependence. All the existing lower bounds are gap dependent, and valid for a narrow range on mean vectors or known preference cone, i.e. the right orthant. Our proof does not need such assumptions. The gap-dependent bounds are special case of ours (cf. Theorem 3.2 for the case of Gaussian rewards).

(ii) Geometric Insights. Theorem 3.1 provides multiple geometric insights into the affect of the ordering cone \(\mathcal{C}\) on the characteristic time. _First_, the alternating set \(\Lambda_{\pi^{*}}\left(M\right)\) is piece-wise polyhedral and non-convex. We address consequent issues in Section 4.1. _Second_, there is an additional minimization over the vectors lying in the cone \(\mathcal{C}\). We interpret the minimization over vectors in the cone as a _instance- and preference-dependent scalarization of the distance between the given instance \(M\) and the corresponding most-confusing instance in \(\Lambda_{\pi^{*}}\left(M\right)\). Third_, in the proof, we show that the reward gap using the best policy \(\pi^{*}\) and a given policy \(\pi\) for the most confusing instance belongs to the polar cone \(\mathcal{C}^{\circ}\) of the preference cone \(\mathcal{C}\). The most confusing lies on the boundary of this polar cone and its projection the policy gaps \((\pi^{*}-\pi)\). Further insights can be obtained by imagining the polar cone to be orthogonal to the cone \(\mathcal{C}\). Then, the vector of reward-gaps for the most confusing instance for every objective is orthogonal to the generating rays of \(\mathcal{C}\). These novel geometric insights are complementary to the existing algebraic and statistical insights available in the lower bound literature (Kone et al., 2023; Ararat and Tekin, 2023).

### Characteraization of Lower Bounds for Gaussians

To understand our lower bound better and to compare it with the literature, we present a reduction for Gaussian bandits. In Gaussian bandits, we assume that the reward vectors of arm \(a\in[K]\) are generated from a multivariate Gaussian distribution \(\mathcal{N}(\mu_{a},\Sigma)\), where the covariance is a diagonal matrix: \(\Sigma\triangleq\mathrm{Diag}(\sigma_{1}^{2},\ldots,\sigma_{L}^{2})\).

**Theorem 3.2** (Lower Bound for Gaussian Bandits).: _1. Given any \(\pi^{\star}\in\Pi^{*}(M)\) and \(N(\pi^{*})\) being the set of neighbouring policies of \(\pi^{*}\), the most confusing instance of \(M\) belongs to the set_

\[\left\{\tilde{M}\in\mathcal{M}\setminus\{M\}:\tilde{M}_{k,\ell}=M_{k,\ell}- \beta\frac{\sigma_{\ell}^{2}}{z^{\ell}}\frac{(\pi^{*}-\pi)_{k}}{w_{k}},\;\; \forall\pi\in N(\pi^{*}),z\in\mathcal{C}\setminus\{0\},k\in[K],\ell\in[L] \right\},\]

_where \(\beta\triangleq\frac{z^{\top}M(\pi^{*}-\pi)}{\mathrm{Tr}(\Sigma)\|\pi^{*}-\pi \|_{\mathrm{Diag}(1/w)}^{2}}\)._

_2. The inverse of characteristic time, i.e. \((\mathcal{T}_{M,\mathcal{C}}^{\mathrm{Gauss}})^{-1}\), for an instance \((M,\mathcal{C})\) is_

\[\inf_{\begin{subarray}{c}\pi\in N(\pi^{*})\\ \pi^{*}\in\Pi^{*}(M)\end{subarray}}\min_{z\in\mathcal{C}\setminus\{0\}}\frac{(z ^{\top}M(\pi^{*}-\pi))^{2}}{2\mathrm{Tr}(\Sigma)\|\pi^{*}-\pi\|_{2}^{2}}\,.\]

**Consequences.**_First_, we observe an interesting phenomenon that a bilinear projection of mean matrix \(M\) on the preferences and policy gaps operates as an extension of suboptimality gap in classical BAI. This is a reminiscent of the lower bound for pure exploration under known linear constraints as in Carlsson et al. (2024) who show that the hardness of the problem depends only on the projection of the mean vector on the policy gap. In addition to similar projection structure, preferences introduce a novel bilinearity here. _Second_, we show how the lower bound inflates with the covariance matrix for each objective. This shows the richness of our KL-divergence based lower bound as opposed to gap-based bounds which have difficulty accommodating variance related terms directly.

_Connection to existing results._ Our result generalizes several existing lower bounds for BAI.

1. _BAI lower bound._ Our lower bound is able to recover that of Kaufmann et al. (2016) for the standard BAI problem with fixed confidence. In the case of the standard BAI problem, the ordering cone is given by \(\mathcal{C}\triangleq\mathbb{R}_{+}\) and therefore the minimization over \(\mathcal{C}\) in (3) becomes redundant. The definition of the alternating set is then given by the set of instances which have a different optimal arm than \(\mu\) which is exactly the set considered in (Kaufmann et al., 2016).

2. _Pure exploration under known constraints._ Our lower bound is able to recover the lower bound of Carlsson et al. (2023) for the BAI problem with fixed confidence and linear constraints. This is the case with \(L=1\) and the ordering cone being \(\mathcal{C}\triangleq\mathbb{R}_{+}\) making the minimization over \(z\in\mathcal{C}\) in (3) redundant. \(\Lambda_{\pi^{*}}\left(M\right)\) becomes \(\Lambda_{\pi^{*}}\left(M\right)=\{\tilde{\mu}:\max_{\pi\in\Pi}\tilde{\mu}^{ \top}\pi\geq\mu^{\top}\pi^{*}\}\) and we retrieve exactly their Corollary 1.

## 4 Algorithm Design: PreTS

In this section, we propose an algorithm that tracks the lower bound. However, this is not straightforward since the alternating set is non-convex. We first propose a convex relaxation for this set and then, design a Track and Stop style algorithm, called PreTS.

### Convex Relaxation of the Lower Bound

One of the major differences regarding the structure of lower bounds compared to a standard BAI problem is that \(\Lambda_{\pi^{*}}\left(M\right)\) is a piece-wise polyhedron, i.e., a union of hyperplanes. Each hyperplane corresponds to a policy \(\pi\in\Pi\setminus\{\pi^{*}\}\). To make the optimization problem tractable and obtain a convex program, we relax \(\Lambda_{\pi^{*}}\left(M\right)\) using its convex closure, denoted by \(\text{ch}\left(\Lambda_{\pi^{*}}\left(M\right)\right)\). We note that the construction of such a convex relaxation for track-and-stop (when the lower bound problem is non-convex) has been done in the MDP setting AI Marjani and Proutiere (2021). We define \(\text{ch}\left(\Lambda_{\pi^{*}}\left(M\right)\right)\) in Theorem 4.1 by formulating it as a disjunctive program, which we can reformulate further as a linear program (Balas, 1985).

**Theorem 4.1**.: _Let \(\mathcal{F}\triangleq\cup_{\Pi\setminus\pi^{*}}\left\{\tilde{M}\in\mathcal{M }:\;\exists\;z\in\mathcal{C},\langle\text{vect}\left(z^{\top}(\pi-\pi^{*}) \right),\text{vect}\big{(}\tilde{M}\big{)}\rangle=0\right\}\). Fix \(z\in\mathcal{C}\) such that \(z=\sum_{i}\alpha_{i}v_{i}\). Then, we have \(\text{ch}\left(\mathcal{F}\right)=\mathcal{I}\), where \(\mathcal{I}\) is defined as_

\[\mathcal{I}\triangleq\{\tilde{M}\in\mathcal{M}:\gamma^{\top}\text{vect}( \tilde{M})\geq\gamma_{0},\gamma=\sum\nolimits_{i}u_{i}\alpha_{i}\text{vect}(v _{i}^{\top}(\pi-\pi^{*})),\gamma_{0}\leq u_{i}\sum\nolimits_{i}\alpha_{i}v_{i} ^{\top}\pi^{*}\}.\] (4)

Using the convex hull (Eq. (4)), we quantify the optimal value for a given allocation \(w\) as

\[\overline{\mathcal{V}}_{\mathcal{C}}(w,M)\triangleq\min_{\tilde{M}\in\text{ch }\left(\partial\Lambda_{\pi^{*}}\left(M\right)\right)}\inf_{z\in\mathcal{C}} \sum_{k=1}^{K}w_{k}d_{\text{KL}}\left(z^{\top}M,z^{\top}\tilde{M}\right)\,.\]

The corresponding optimal allocation is

\[\overline{w}^{*}(M)=\arg\max_{w\in\Delta^{K}}\inf_{\begin{subarray}{c}\pi\in \Pi\setminus\pi^{*}\\ \pi^{*}\in\Pi^{*}(M)\end{subarray}}\min_{\tilde{M}\in\text{ch}\left(\partial \Lambda_{\pi^{*}}\left(M\right)\right)}\inf_{z\in\mathcal{C}}\sum_{k=1}^{K}w_{k }d_{\text{KL}}\left(z^{\top}M,z^{\top}\tilde{M}\right)\,.\] (5)

Hereafter, we consider Equation (5) as the optimization problem to be tracked. To compute \(\overline{\mathcal{V}}_{\mathcal{C}}(w,M)\), we need access to the true instance \(M\) which is not available to us. Our Track-and-Stop strategy is based on repeatedly sampling an arm to construct an estimate of \(M\), i.e. \(M_{t}\), and exploiting continuity properties of \(\overline{\mathcal{V}}_{\mathcal{C}}(w,M)\) to show that \(\overline{\mathcal{V}}_{\mathcal{C}}(w,M_{t})\rightarrow\overline{\mathcal{V }}_{\mathcal{C}}(w,M)\) and the cumulative number of arm plays \(N_{t,k}\to w_{k},\ w_{k}\in\overline{w}^{*}(M)\). These properties ensure that it makes sense to design a Track and Stop style algorithm for this problem.

**Theorem 4.2** (Analytical Properties).: _For all \(M\in\mathbb{R}^{L\times K}\) and all preference cones \(\mathcal{C}\), we get 1. The mapping \((w,M)\rightarrow\overline{\mathcal{V}}_{\mathcal{C}}(w,M)\) is continuous. 2. The characteristic time mapping \(M\rightarrow\overline{\mathcal{T}_{M,\mathcal{C}}}\) is continuous. 3. The set valued function \(M\rightarrow\overline{w}^{*}(M)\) is upper-hemicontinuous. 4. The set \(\overline{w}^{*}(M)\) is convex._

_Discussion: Cost of Convexification._ For Gaussian bandits, as we can get the analytical form of the most confusing instance \(\tilde{M}\) (Theorem 3.2), we do not pay any extra cost of convexification. In the non-Gaussian settings, where we cannot find such analytical forms for the most confusing instances, the minimum value of the inner minimisation problem under the convex hull (Equation (5)) can go lower than the minimum value found in the original non-convex set of instances (Equation (3)). Thus, the characteristic time attained by solving the convex relaxation might be higher than that of the original lower bound. Hence, an algorithm solving the convex relaxation has a higher stopping time. However, convexification is essential for the computational feasibility of a lower bound-tracking algorithm for PrePEx. This computational-statistical trade-off will be interesting to study in the future.

### Algorithm: Preference-based Track-and-Stop (PreTS)

We now construct a general recipe to design a PrePEx algorithm when we do not have access to the true instance \(M\). The fundamental element of any such recipe is constructing an estimate of \(M\). For a given set of observed rewards \(\{R_{t}\}_{t=1}^{T}\), we obtain a column-wise empirical average of the observed rewards and use it as our estimator of \(M\). Now, we elaborate the three key components of our PrePEx algorithm Preference-based Track and Stop (PreTS, Algorithm 1).

1. **Sampling Rule:** For the sampling rule, we consider a Track-and-Stop strategy (Garivier and Kaufmann, 2016). It tracks the optimal proportion of arm sampling by plugging in the empirical estimates of means and empirical count \(N_{k,t}\) in the convexified lower bound. This leads to an allocation policy with improved information acquisition.

2. **Stopping Rule:** Our ultimate stopping goal is to identify arms that are on the Pareto front. Based on this, we define the confidence set as:

\[c(t,\delta)\triangleq\left\{\tilde{M}\in\mathcal{M}:\,\min_{z\in\mathcal{C}} \sum_{k}N_{k,t}d_{\text{KL}}(z^{\top}\hat{M}_{t}^{(k)},z^{\top}\tilde{M}^{(k )})\leq\beta(t,\delta)\right\}\,,\] (6)

where \(\beta(t,\delta)\triangleq\sum_{a\in S}3\ln\left(1+\ln\left(N_{k,t}\right) \right)+K\mathcal{T}\left(\frac{\ln\left(\frac{1}{\delta}\right)}{K}\right)\) and \(\mathcal{T}\) is defined in Equation (17). Our first claim is to show that the true instance belongs to the confidence ellipsoid with high probability.

**Lemma 4.1** (Confidence Ball).: _For any \(t\in\mathbb{N}\) and \(c(t,\delta)\) is defined in Equation (6), we have \(\mathbb{P}\left(M\notin c(t,\delta)\right)\leq\delta\)._

Thus, we can now formalise the corresponding Chernoff-stopping rule as

\[\min_{\tilde{M}\in\text{ch}\left(\partial\Lambda_{x^{*}}\left(\hat{M}_{t} \right)\right)}\min_{z\in\mathcal{C}}\sum_{k}N_{k,t}d_{\text{KL}}\left(z^{\top }\hat{M}_{t}^{(k)},z^{\top}\tilde{M}^{(k)}\right)\geq\beta(t,\delta)\] (7)

Given the estimates \(\hat{M}_{t}\), the problem in Equation (7) can be solved efficiently. Next, we show that upon stopping with Equation (7), PreTS returns the true Pareto Front \(\mathcal{P}^{*}\) with probability \(1-\delta\). Let\(\hat{\mathcal{P}}_{t}\) denote the estimated Pareto Front at time \(t\), which is constructed using estimates \(\hat{M}_{t}\). Then at stopping time \(\tau\), we have

\[\mathbb{P}\left(\mathcal{P}^{*}\neq\hat{\mathcal{P}}_{t}\right) \leq \mathbb{P}\left(\exists\;t\in\mathbb{N}:\sum_{k,\ell}N_{k,t}d_{ \text{KL}}\left(z^{\top}\hat{M}_{t}^{(k)},z^{\top}M^{(k)}\right)\geq\beta(t, \delta)\right)\] \[\leq \sum_{t=1}^{\infty}\mathbb{P}\left(\sum_{k,\ell}N_{k,t}d_{\text{ KL}}\left(z^{\top}\hat{M}_{t}^{(k)},z^{\top}M^{(k)}\right)\geq\beta(t,\delta) \right)\leq\delta\]

where, the last inequality is true due to Theorem 4.3, a concentration result on the KL-divergence with preference projected mean rewards.

**Theorem 4.3**.: _For all \(\rho\geq(K+1)\), \(z\in\mathcal{C}\) and \(t\in\mathbb{N}\), we have that:_

\[\mathbb{P}\left[\sum_{k\in[K]}N_{k,t}d_{\text{KL}}\left(z^{\top}\hat{M}_{t}^{( k)},z^{\top}M^{(k)}\right)\geq\rho\right]\leq\exp\left(-\rho\right)\left(\frac{ \left\lceil\rho\log(t)\right\rceil}{K}\right)^{K}\exp\left(K+1\right)\]

3. **Recommendation Rule:** At the end of stopping time \(\tau\), the algorithm returns an estimate of the Pareto Front \(\hat{\mathcal{P}}_{\tau}\).

## 5 Upper Bound on Sample Complexity

Now, we prove upper bound on the expected sample complexity of PreTS. This requires us to the Track-an-Stop proof technique. But the challenge is to show concentration of the pareto fronts under a suitable metric.

**Concentrating to the Pareto Front.** To show that upon stopping the algorithm returns the true Pareto Frontier, we need to establish a valid metric to show such convergence. Usually, the distance between sets is measured using the Hausdorff metric (Costantini and Vitolo, 1995), i.e. \(d_{H}(\hat{\mathcal{P}}_{\tau},\mathcal{P})\triangleq\max\left\{\sup_{k\in \hat{\mathcal{P}}_{\tau}}\inf_{k^{\prime}\in\mathcal{P}}\|M_{k}-M_{k^{\prime}} \|_{\infty},\;\sup_{k\in\mathcal{P}}\inf_{k^{\prime}\in\hat{\mathcal{P}}_{ \tau}}\|M_{k}-M_{k^{\prime}}\|_{\infty}\right\}\). But the Hausdorff distance only defines a pseudo-distance between sets and \(\mathcal{Z}\) may not be closed under this metric. To circumvent this issue, we build upon the notion of a gap-based metric considered in the antecedent literature (Auer et al., 2016) to measure the distance between the mean reward of an arm and a given Pareto Front. We extend it to a distance metric between elements in the space of Pareto Fronts \(\mathcal{Z}\).

**Definition 5.1** (Distance from Pareto Front).: _The distance of the mean of arm \(k\) from the Pareto Front \(\mathcal{P}^{*}\) is \(d(k,\mathcal{P}^{*})\triangleq\inf_{\varepsilon\geq 0}\varepsilon\), such that \(M_{k}+\varepsilon\mathbf{1}\nsubseteq_{\mathcal{C}}M_{k^{\prime}},\;k^{\prime} \in\mathcal{P}^{*}\). Equivalently,_

\[d(k,\mathcal{P}^{*})\triangleq\inf_{k^{\prime}\in\mathcal{P}^{*}}\max\left\{0, \sup_{z\in\mathcal{C}\cap\mathbb{B}(1)}z^{\top}\left(M_{k^{\prime}}-M_{k} \right)\right\}.\] (8)

**Definition 5.2** (Distance between Pareto Fronts).: _We define the metric between Pareto Fronts \(d_{\text{P}}\left((\cdot,\cdot)\,,\cdot\right):\mathcal{Z}\times\mathcal{Z} \rightarrow\mathbb{R}_{\geq 0}\) as \(d_{\text{P}}\left(\hat{P},\mathcal{P}^{*}\right)\triangleq\max\left\{\sup_{k\in \hat{P}}d(k,\mathcal{P}^{*}),\sup_{k\in\mathcal{P}^{*}}d(k,\hat{P})\right\}\)._

In the appendix, we establish that (i) \(d(\cdot,\cdot)\) is a valid metric on \(\mathcal{Z}\), and (ii) \(\mathcal{Z}\) is compact and complete under \(d(\cdot,\cdot)\). Now, we leverage this metric to show that the Pareto Front defined by the arm-wise constructed estimator \(\hat{M}_{t}\) concentrates towards the true Pareto Front.

**Theorem 5.1** (Concentration of mean estimates).: _For any pair \((i,j)\in[K]\times[K]\) and \(z\in\mathcal{C}\), we have_

\[\left|z^{\top}\left(M_{i}-M_{j}\right)-z^{\top}\left(\hat{M}_{i,t}-\hat{M}_{j,t }\right)\right|\leq\beta_{ij}(t)\,,\]

_where \(\beta_{ij}^{2}(t)\triangleq 4\|z\|_{1}^{2}\bigg{(}h\left(\frac{\log(\frac{K_{1}}{2})}{2} \right)+\sum_{a\in\{i,j\}}\log\left(4+\log(N_{a}(t))\right)\bigg{)}\left(\sum_ {a\in\{i,j\}}\frac{1}{N_{a}(t)}\right)\), \(K_{1}\triangleq\frac{K(K-1)}{2}\), and \(h(x)\approx x+\log(x)\)._Proof Sketch.: This is a consequence of jointly applying a vectorial concentration result for multiple-objectives of each arm (Kaufmann and Koolen, 2021), and pairwise time-uniform concentration bounds (Kone et al., 2023a). A key observation here is that the confidence radii depends on the magnitude of the preference vector \(z\) and scales with different objectives accordingly.

**Sample Complexity of PreTS.** Using this new concentration result for the Pareto Front and the stopping rule in Equation 7, we derive an upper bound on the expected stopping time of PreTS.

**Theorem 5.2** (Upper Bound on Sample Complexity).: _For any \(\alpha>0\) and \(c(t,\delta)\) defined in (7), we have that the stopping time satisfies_

\[\lim_{\delta\to 0}\frac{\mathbb{E}[\tau]}{\log\left(\frac{1}{\delta}\right)} \leq\overline{\mathcal{T}_{M,\mathcal{C}}}\ \forall\ M\in\mathbb{R}^{L\times K}\]

The basic outline of the proof follows a general strategy to prove Track-and-Stop result. However, the new arguments lie in establishing that the Pareto fronts converge under a suitable metric sufficiently fast. Our proof implies that PreTS matches the convex relaxation of the lower bound asymptotically at the corresponding risk level \(\delta\). Strictly, speaking this is not _asymptotically optimal_ since, we do not track the exact lower-bound.

## 6 Conclusion and Future Works

We study the fixed-confidence version of preference-based pure exploration problem under linear stochastic bandit feedback, where each arm corresponds to a reward vector ordered according to a preference cone. We derive a novel lower bound for this problem. We leverage the lower bound further to derive a track-and-stop based algorithm for PrePEx problem. As future work, it would be interesting to verify our results on a real-world datasets.

Additionally, it would be interesting and challenging to study how other asymptotically optimal pure exploration strategies, e.g. gamified explorers (Degenne and Koolen, 2019), top-two algorithms (Jourdan et al., 2022), can be adapted to this setting. In general, improving the computational efficiency and studying the optimality gap with respect to the non-convex lower-bound problem would be of fundamental interest.

## References

* Al Marjani and Proutiere (2021) Al Marjani, A. and Proutiere, A. (2021). Adaptive sampling for best policy identification in markov decision processes. In _International Conference on Machine Learning_, pages 7459-7468. PMLR.
* Ararat and Tekin (2023) Ararat, C. and Tekin, C. (2023). Vector optimization with stochastic bandit feedback. In _International Conference on Artificial Intelligence and Statistics_, pages 2165-2190. PMLR.
* Audibert and Bubeck (2010) Audibert, J.-Y. and Bubeck, S. (2010). Best arm identification in multi-armed bandits.
* Auer et al. (2016) Auer, P., Chiang, C.-K., Ortner, R., and Drugan, M. (2016). Pareto front identification from stochastic bandit feedback. In _Artificial intelligence and statistics_, pages 939-947. PMLR.
* Balas (1985) Balas, E. (1985). Disjunctive programming and a hierarchy of relaxations for discrete optimization problems. _SIAM Journal on Algebraic Discrete Methods_, 6(3):466-486.
* Berge (1877) Berge, C. (1877). _Topological spaces: Including a treatment of multi-valued functions, vector spaces and convexity_. Oliver & Boyd.
* Bubeck et al. (2009) Bubeck, S., Munos, R., and Stoltz, G. (2009). Pure exploration in multi-armed bandits problems. In _Algorithmic Learning Theory: 20th International Conference, ALT 2009, Porto, Portugal, October 3-5, 2009. Proceedings 20_, pages 23-37. Springer.
* Carlsson et al. (2024) Carlsson, E., Basu, D., Johansson, F., and Dubhashi, D. (2024). Pure exploration in bandits with linear constraints. In _International Conference on Artificial Intelligence and Statistics_, pages 334-342. PMLR.
* Carlsson et al. (2023) Carlsson, E., Basu, D., Johansson, F. D., and Dubhashi, D. (2023). Pure exploration in bandits with linear constraints. _arXiv preprint arXiv:2306.12774_.
* Carlsson et al. (2021)C., Buffoni, D., Robicquet, A., and Vayatis, N. (2013). Parallel gaussian process optimization with upper confidence bound and pure exploration. In _Joint European Conference on Machine Learning and Knowledge Discovery in Databases_, pages 225-240. Springer.
* Costantini and Vitolo (1995) Costantini, C. and Vitolo, P. (1995). On the infimum of the hausdorff metric topologies. _Proceedings of the London Mathematical Society_, 3(2):441-480.
* crepon et al. (2024) crepon, e., Garivier, A., and M Koolen, W. (2024). Sequential learning of the Pareto front for multi-objective bandits. In Dasgupta, S., Mandt, S., and Li, Y., editors, _Proceedings of The 27th International Conference on Artificial Intelligence and Statistics_, volume 238 of _Proceedings of Machine Learning Research_, pages 3583-3591. PMLR.
* Degenne and Koolen (2019) Degenne, R. and Koolen, W. M. (2019). Pure exploration with multiple correct answers. In _Neural Information Processing Systems_.
* Donsker and Varadhan (1975) Donsker, M. D. and Varadhan, S. S. (1975). Asymptotic evaluation of certain markov process expectations for large time, i. _Communications on pure and applied mathematics_, 28(1):1-47.
* Drugan and Nowe (2013) Drugan, M. M. and Nowe, A. (2013). Designing multi-objective multi-armed bandits algorithms: A study. In _The 2013 international joint conference on neural networks (IJCNN)_, pages 1-8. IEEE.
* Even-Dar et al. (2006) Even-Dar, E., Mannor, S., and Mansour, Y. (2006). Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems. _Journal of machine learning research_, 7(Jun):1079-1105.
* Gabillon et al. (2012) Gabillon, V., Ghavamzadeh, M., and Lazaric, A. (2012). Best arm identification: A unified approach to fixed budget and fixed confidence. In _Advances in Neural Information Processing Systems_, pages 3212-3220.
* Garivier and Kaufmann (2016) Garivier, A. and Kaufmann, E. (2016). Optimal best arm identification with fixed confidence. In _Conference on Learning Theory_, pages 998-1027.
* Gaulton et al. (2012) Gaulton, A., Bellis, L. J., Bento, A. P., Chambers, J., Davies, M., Hersey, A., Light, Y., McGlinchey, S., Michalovich, D., Al-Lazikani, B., et al. (2012). Chembl: a large-scale bioactivity database for drug discovery. _Nucleic acids research_, 40(D1):D1100-D1107.
* Graves and Lai (1997) Graves, T. L. and Lai, T. L. (1997). Asymptotically efficient adaptive choice of control laws incontrolled markov chains. _SIAM journal on control and optimization_, 35(3):715-743.
* Hasselgren and Oprea (2024) Hasselgren, C. and Oprea, T. I. (2024). Artificial intelligence for drug discovery: Are we there yet? _Annual Review of Pharmacology and Toxicology_, 64:527-550.
* Jahn et al. (2009) Jahn, J. et al. (2009). _Vector optimization_. Springer.
* Jamieson et al. (2014) Jamieson, K., Malloy, M., Nowak, R., and Bubeck, S. (2014). lil'ucb: An optimal exploration algorithm for multi-armed bandits. In _Conference on Learning Theory_, pages 423-439.
* Jamieson and Nowak (2014) Jamieson, K. and Nowak, R. (2014). Best-arm identification algorithms for multi-armed bandits in the fixed confidence setting. In _2014 48th Annual Conference on Information Sciences and Systems (CISS)_, pages 1-6. IEEE.
* Jayatunga et al. (2022) Jayatunga, M. K., Xie, W., Ruder, L., Schulze, U., and Meier, C. (2022). Ai in small-molecule drug discovery: a coming wave. _Nat. Rev. Drug Discov_, 21(3):175-176.
* Jedra and Proutiere (2020) Jedra, Y. and Proutiere, A. (2020). Optimal best-arm identification in linear bandits. _Advances in Neural Information Processing Systems_, 33:10007-10017.
* Jourdan et al. (2022) Jourdan, M., Degenne, R., Baudry, D., de Heide, R., and Kaufmann, E. (2022). Top two algorithms revisited. _Advances in Neural Information Processing Systems_, 35:26791-26803.
* Kabanov (2009) Kabanov, Y. (2009). _Markets with Transaction Costs Mathematical Theory_. Springer.
* Kalyanakrishnan et al. (2012) Kalyanakrishnan, S., Tewari, A., Auer, P., and Stone, P. (2012). Pac subset selection in stochastic multi-armed bandits. In _ICML_, volume 12, pages 655-662.
* Kalyanakrishnan et al. (2013)Karagozlu, E. M., Yildirim, Y. C., Ararat, C., and Tekin, C. (2024). Learning the pareto set under incomplete preferences: Pure exploration in vector bandits. In _International Conference on Artificial Intelligence and Statistics_, pages 3070-3078. PMLR.
* Kaufmann et al. (2016) Kaufmann, E., Cappe, O., and Garivier, A. (2016). On the complexity of best arm identification in multi-armed bandit models. _Journal of Machine Learning Research_, 17:1-42.
* Kaufmann and Koolen (2021) Kaufmann, E. and Koolen, W. M. (2021). Mixture martingales revisited with applications to sequential tests and confidence intervals. _Journal of Machine Learning Research_, 22(246):1-44.
* Kone et al. (2023a) Kone, C., Kaufmann, E., and Richert, L. (2023a). Adaptive algorithms for relaxed pareto set identification. _Advances in Neural Information Processing Systems_, 36:35190-35201.
* Kone et al. (2023b) Kone, C., Kaufmann, E., and Richert, L. (2023b). Bandit pareto set identification: the fixed budget setting. _arXiv preprint arXiv:2311.03992_.
* Korkmaz et al. (2023) Korkmaz, I. O., Ararat, C., and Tekin, C. (2023). Bayesian vector optimization with gaussian processes.
* Lattimore and Szepesvari (2020) Lattimore, T. and Szepesvari, C. (2020). _Bandit Algorithms_. Cambridge University Press.
* Li et al. (2018) Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., and Talwalkar, A. (2018). Hyperband: A novel bandit-based approach to hyperparameter optimization. _Journal of Machine Learning Research_, 18(185):1-52.
* Lizotte and Laber (2016) Lizotte, D. J. and Laber, E. B. (2016). Multi-objective markov decision processes for data-driven decision support. _Journal of Machine Learning Research_, 17(210):1-28.
* Lohne (2011) Lohne, A. (2011). _Vector optimization with infimum and supremum_. Springer Science & Business Media.
* Lu et al. (2019) Lu, S., Wang, G., Hu, Y., and Zhang, L. (2019). Multi-objective generalized linear bandits. _arXiv preprint arXiv:1905.12879_.
* Magureanu et al. (2014) Magureanu, S., Combes, R., and Proutiere, A. (2014). Lipschitz bandits: Regret lower bound and optimal algorithms. In _Conference on Learning Theory_, pages 975-999. PMLR.
* Mullard (2014) Mullard, A. (2014). New drugs cost us \(\$2.6\) billion to develop. _Nature reviews drug discovery_, 13(12).
* Munro et al. (2021) Munro, A. P., Janani, L., Cornelius, V., Aley, P. K., Babbage, G., Baxter, D., Bula, M., Cathie, K., Chatterjee, K., Dodd, K., et al. (2021). Safety and immunogenicity of seven covid-19 vaccines as a third dose (booster) following two doses of chadox1 ncov-19 or bnt162b2 in the uk (cov-boost): a blinded, multicentre, randomised, controlled, phase 2 trial. _The Lancet_, 398(10318):2258-2276.
* Peskun (1973) Peskun, P. H. (1973). Optimum monte-carlo sampling using markov chains. _Biometrika_, 60(3):607-612.
* Reker and Schneider (2015) Reker, D. and Schneider, G. (2015). Active-learning strategies in computer-assisted drug discovery. _Drug discovery today_, 20(4):458-465.
* Sadybekov and Katritch (2023) Sadybekov, A. V. and Katritch, V. (2023). Computational approaches streamlining drug discovery. _Nature_, 616(7958):673-685.
* Shukla (2022) Shukla, A. (2022). _Optimization and Learning in Dynamic Environments: Models and Algorithms_. Columbia University.
* Smer-Barreto et al. (2023) Smer-Barreto, V., Quintanilla, A., Elliott, R. J., Dawson, J. C., Sun, J., Campa, V. M., Lorente-Macias, A., Unciti-Broceta, A., Carragher, N. O., Acosta, J. C., et al. (2023). Discovery of sensolvics using machine learning. _Nature communications_, 14(1):3445.
* Soare et al. (2014) Soare, M., Lazaric, A., and Munos, R. (2014). Best-arm identification in linear bandits. In _Advances in Neural Information Processing Systems_, pages 828-836.
* Sorensen et al. (2016)Sun, D., Gao, W., Hu, H., and Zhou, S. (2022). Why 90_Acta Pharmaceutica Sinica B_, 12(7):3049-3062.
* Tekin and Turgay (2017) Tekin, C. and Turgay, E. (2017). Multi-objective contextual bandits with a dominant objective. In _2017 IEEE 27th International Workshop on Machine Learning for Signal Processing (MLSP)_, pages 1-6. IEEE.
* Turgay et al. (2018) Turgay, E., Oner, D., and Tekin, C. (2018). Multi-objective contextual bandit problem with similarity information. In _International Conference on Artificial Intelligence and Statistics_, pages 1673-1681. PMLR.
* Wang et al. (2022) Wang, J., Basu, D., and Trummer, I. (2022). Procrastinated tree search: Black-box optimization with delayed, noisy, and multi-fidelity feedback. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 36, pages 10381-10390.
* Wang et al. (2021) Wang, J., Trummer, I., and Basu, D. (2021). Demonstrating udo: A unified approach for optimizing transaction code, physical design, and system parameters via reinforcement learning. In _Proceedings of the 2021 International Conference on Management of Data_, pages 2794-2797.
* Zuluaga et al. (2016) Zuluaga, M., Krause, A., et al. (2016). e-pal: An active learning approach to the multi-objective optimization problem. _Journal of Machine Learning Research_, 17(104):1-32.

## Appendix

**Table of Contents**

* 1 Notations
* 2 Proofs of Lower Bounds
	* 2.1 Generic Lower Bound: Proof of Theorem 3.1
	* 2.2 Lower Bound for Gaussians: Proof of Theorem 3.2
	* 2.3 Proof of Theorem 4.1
	* 2.4 Proof of Theorem 4.2
* 3 Proof of the Stopping Time
	* 3.1 Proof of Lemma 4.1
	* 3.2 Proof of Theorem 4.3
* 4 Proofs for Sample Complexity Upper Bound
	* 4.1 Pairwise Concentration Bounds
	* 4.2 Concentration to the Pareto Front
	* 4.3 Proof of Theorem 5.2
* 5 Reduction to Best-arm Identification
* 6 Useful Existing Results

[MISSING_PAGE_EMPTY:15]

Proofs of Lower Bounds

### Generic Lower Bound: Proof of Theorem 3.1

Proof.: The proof follows the basic structure of constructing a lower bound as in Kaufmann et al. (2016). Recall that their inverse of characteristic time is given by

\[\mathcal{T} =\sup_{w\in\Pi}\inf_{\tilde{M}\in\Lambda_{\pi^{*}}(M)}\sum_{k}w_{k} d_{\text{KL}}\left(M_{k},\tilde{M}_{k}\right)\] (9)

The main challenge for our setting is describing the alternating set \(\Lambda_{\pi^{*}}\left(M\right)\) and scalarization of the given instance \(M\in\mathcal{M}\). Given a matrix of arm-objective mean-rewards \(M\), ordering cone \(\mathcal{C}\) and a family of policies \(\Pi\), the Pareto front is the set of optimal values (ordered wrt \(\mathcal{C}\)) of

\[\max_{\pi\in\Pi}\ M\pi\,.\] (10)

* **Step 1: Constructing set of alternative instances** Let \(\pi^{*}\in\arg\max_{\pi\in\Pi}M\pi\). The set of confusing instances given \(\Pi\) and \(\mathcal{C}\) is the set of all matrices \(\tilde{M}\) which have a different Pareto front than \(M\) when using the policy \(\pi^{*}\). Therefore, the optimal values of (10) with instance \(M\) are not-dominated by those of instance \(\tilde{M}\). Hence, the set of alternative instances, \(\Lambda_{\pi^{*}}\left(M\right)\) is given by: \[\Lambda_{\pi^{*}}\left(M\right):=\left\{\tilde{M}\in\mathcal{M}:\max_{\pi\in \Pi}\tilde{M}\pi\not\leq_{C}\tilde{M}\pi^{*}\right\}\] Let \(\pi^{\prime}\in\arg\max_{\pi\in\Pi}\tilde{M}\pi\) over \(\mathcal{C}\) which implies \(\tilde{M}\pi^{\prime}\not\leq_{C}\tilde{M}\pi^{*}\) or equivalently: \[\exists\,z\in\mathcal{C},\ \pi\in\Pi\setminus\{\pi^{*}\}\text{ s.t. }z^{\top}\tilde{M}\pi>z^{\top}\tilde{M}\pi^{*}\] Therefore, the alternative set can be written as: \[\Lambda_{\pi^{*}}\left(M\right) \triangleq\cup_{\pi\in\Pi\setminus\{\pi^{*}\}}\left\{\tilde{M} \in\mathcal{M}:\ \exists\,z\in\mathcal{C},z^{\top}\tilde{M}\pi>z^{\top}\tilde{M}\pi^{*}\right\}\] \[=\cup_{\pi\in\Pi\setminus\{\pi^{*}\}}\left\{\tilde{M}\in \mathcal{M}:\exists\,z\in\mathcal{C}:z^{\top}\tilde{M}\cdot(\pi-\pi^{*})>0\right\}\] where, \(\cdot\) represents a bilinear product and, its complement is given by: \[\overline{\Lambda_{\pi^{*}}\left(M\right)} \triangleq\cap_{\pi\in\Pi\setminus\{\pi^{*}\}}\left\{\tilde{M} \in\mathcal{M}:\forall\ z\in\mathcal{C}:z^{\top}\tilde{M}\cdot(\pi-\pi^{*}) \leq 0\right\}\] \[=\cap_{\pi\in\Pi\setminus\{\pi^{*}\}}\left\{\tilde{M}\in \mathcal{M}:\tilde{M}\cdot(\pi-\pi^{*})\in\mathcal{C}^{\circ}\right\}\] where, \(\text{ri}(\mathcal{C}^{\circ})\) denotes the relative interior of the polar cone to \(\mathcal{C}\). Since \(\mathcal{C}\) is a polyhedral cone, it is closed and convex and therefore, its polar cone is non-empty, closed and convex. Therefore, \(\overline{\Lambda_{\pi^{*}}\left(M\right)}\) is non-empty.
* **Step 2: Hardest instance lies on the boundary** We now show that given \(\pi^{*},\text{ and }\pi\), the hardest instances \(\tilde{M}\in\mathcal{M}\) are such that: \[\tilde{M}\cdot(\pi-\pi^{*})\in\text{bd}(C^{\circ}).\] Fix \(\pi^{\prime}\in\Pi\setminus\{\pi^{*}\}\) and let \(M^{\prime}\in\left\{\tilde{M}\in\mathcal{M}:\tilde{M}\cdot(\pi^{\prime}-\pi^{ *})\in\text{ri}(\mathcal{C}^{\circ})\right\}\). Then, by convexity of \(\left\{\tilde{M}\in\mathcal{M}:\exists\,z\in\mathcal{C}:z^{\top}\tilde{M} \cdot(\pi-\pi^{*})>0\right\}\) there exists \(M^{\prime\prime}\in\left\{\tilde{M}\in\mathcal{M}:\tilde{M}\cdot(\pi^{\prime}- \pi^{*})\in\text{bd}(\mathcal{C}^{\circ})\right\}\) such that \(\left|z^{\top}M_{k}-z^{\top}M^{\prime}_{k}\right|\geq\left|z^{\top}M_{k}-z^{ \top}M^{\prime\prime}_{k}\right|\), \(\forall\,z\in\mathcal{C}\). Since \(d_{\text{KL}}\left(z^{\top}M_{k},z^{\top}M^{\prime}_{k}\right)\geq d_{\text{KL }}\left(z^{\top}M_{k},z^{\top}M^{\prime\prime}_{k}\right)\). Using the above arguments we see that the minimum argument of \(\sum_{k}w_{k}d_{\text{KL}}\left(z^{\top}M^{\prime},z^{\top}M^{\prime\prime}\right)\) is such that \(M^{\prime\prime}\in\left\{\tilde{M}\in\mathcal{M}:\tilde{M}\cdot(\pi-\pi^{*}) \in\text{bd}(\mathcal{C}^{\circ})\right\}\).

The optimization problem now becomes:

\[\sup_{w\in\Pi}\inf_{\tilde{M}\in\Lambda_{\pi^{*}}(M)}\inf_{z\in \mathcal{C}}\sum_{k}w_{k}d_{\text{KL}}\left(z^{\top}M_{k},z^{\top}\tilde{M_{k}}\right)\] \[=\sup_{w\in\Delta^{K}}\inf_{\pi\in\Pi\setminus\pi^{*}}\min_{\tilde{ M}\in\partial\Lambda_{\pi^{*}}(M)}\inf_{z\in\mathcal{C}}\sum_{k=1}^{K}w_{k}d_{ \text{KL}}\left(z^{\top}M_{k},z^{\top}\tilde{M_{k}}\right)\,,\]

where

\[\partial\Lambda_{\pi^{*}}\left(M\right) \triangleq\cup_{\Pi\setminus\pi^{*}}\left\{\tilde{M}\in\mathcal{ M}:\exists\,z\in\mathcal{C},\,z^{\top}\tilde{M}(\pi-\pi^{*})=0\right\}\] \[=\cup_{\Pi\setminus\pi^{*}}\left\{\tilde{M}\in\mathcal{M}:\, \exists\,z\in\mathcal{C},\,\left\langle\text{vect}\left(z^{\top}(\pi-\pi^{*} )\right),\text{vect}(\tilde{M})\right\rangle=0\right\}\,.\] (11)

Finally, to accommodate for multiple optimal policies \(\pi^{*}\), the inner minimisation problem becomes

\[\sup_{w\in\Delta^{K}}\inf_{\begin{subarray}{c}\pi\in\Pi\setminus\pi^{*}\\ \pi^{*}\in\Pi^{*}(M)\end{subarray}}\min_{\tilde{M}\in\partial\Lambda_{\pi^{*}} (M)}\inf_{z\in\mathcal{C}}\sum_{k=1}^{K}w_{k}d_{\text{KL}}\left(z^{\top}M_{k}, z^{\top}\tilde{M_{k}}\right)\]

This concludes the proof.

### Lower Bound for Gaussians: Proof of Theorem 3.2

Proof.: **Step 1.** Simplifying the KL-divergence for a Gaussian bandit instance with identical variance across all objectives yields

\[\mathcal{V}_{\mathcal{C}}(w,M)=\min_{\tilde{M}\in\partial\Lambda_{\pi^{*}}(M) }\min_{z\in C}\sum_{k=1}^{K}w_{k}\sum_{\ell=1}^{L}(z^{(\ell)})^{2}\frac{\left( \mu_{k}^{(\ell)}-\tilde{M}_{k}^{(\ell)}\right)^{2}}{2\sigma_{\ell}^{2}}\,.\] (12)

Recalling that due to the projection lemma, the \(\tilde{M}\) achieving the minimum satisfies

\[z^{\top}\sum_{k=1}^{K}\tilde{M}_{k}^{\top}\left(\pi_{k}^{*}-\pi_{k}\right)=0, \;\forall z\in\mathcal{C}\] (13)

Now, we formulate the Lagrangian of (12) with dual variables \(\beta\) for (13) as

\[\mathcal{L}\left(w,M,\tilde{M},\gamma,\beta\right)\] \[=\sum_{k=1}^{K}w_{k}\sum_{\ell=1}^{L}(z^{(\ell)})^{2}\left(\frac{ \mu_{k}^{(\ell)}-\tilde{M}_{k}^{(\ell)}}{\sqrt{2}\sigma_{\ell}}\right)^{2}+ \beta z^{\top}\tilde{M}\left(\pi^{*}-\pi\right)\] \[=\sum_{k=1}^{K}w_{k}\sum_{\ell=1}^{L}(z^{(\ell)})^{2}\left(\frac{ \mu_{k}^{(\ell)}-\tilde{M}_{k}^{(\ell)}}{\sqrt{2}\sigma_{\ell}}\right)^{2}+ \beta z^{\top}\tilde{M}\left(\pi^{*}-\pi\right)\] (14)

**Step 2.** Taking the derivative w.r.t. \(\tilde{M}\), we have

\[\frac{\partial\mathcal{L}}{\partial\tilde{M}_{k}^{(\ell)}}=w_{k}\left(z^{( \ell)}\right)^{2}\left(\frac{-2}{2\sigma_{\ell}^{2}}\right)\left(\mu_{k}^{( \ell)}-\tilde{M}_{k}^{(\ell)}\right)+\beta z^{(\ell)}\left(\pi^{*}-\pi\right) _{k}\,,\]

and setting it to zero, we get

\[w_{k}\left(z^{(\ell)}\right)^{2}\left(\frac{2}{2\sigma_{\ell}^{2 }}\right)\left(\mu_{k}^{(\ell)}-\tilde{M}_{k}^{(\ell)}\right)=\beta z^{(\ell)} \left(\pi^{*}-\pi\right)_{k}\] \[\implies\tilde{M}_{k}^{(\ell)}=\mu_{k}^{(\ell)}-\frac{2\sigma_{\ell }^{2}\beta\left(z^{(\ell)}\left(\pi^{*}-\pi\right)_{k}\right)}{2w_{k}\left(z^{ (\ell)}\right)^{2}}=\mu_{k}^{(\ell)}-\frac{\sigma_{\ell}^{2}\beta\left(\pi^{*} -\pi\right)_{k}}{w_{k}z^{(\ell)}}\,.\] (15)The last equality holds for any \(z^{(\ell)}\neq 0\). Therefore, the Lagrangian now becomes

\[\mathcal{L}(w,M,\beta)\] \[=\sum_{k=1}^{K}w_{k}\sum_{\ell=1}^{L}(z^{(\ell)})^{2}\left(\frac{ \mu_{k}^{(\ell)}-\tilde{M}_{k}^{(\ell)}}{\sqrt{2}\sigma_{\ell}}\right)^{2}+ \beta\sum_{i=1}^{L}\lambda_{i}\sum_{\ell=1}^{L}v_{i}^{(\ell)}\sum_{k=1}^{K} \tilde{M}_{k}^{(\ell)}\left(\pi^{*}-\pi\right)_{k}\] \[=\sum_{k=1}^{K}w_{k}\sum_{\ell=1}^{L}(z^{(\ell)})^{2}\frac{(\pi^{ *}-\pi)_{k}^{2}}{(z^{(\ell)})^{2}w_{k}^{2}}\frac{\beta^{2}\sigma_{\ell}^{2}}{2} +\beta\sum_{\ell=1}^{L}z^{(\ell)}\sum_{k=1}^{K}\left(\pi^{*}-\pi\right)_{k} \left(\mu_{k}^{(\ell)}-\beta\sigma_{\ell}^{2}\frac{(\pi^{*}-\pi)_{k}}{z^{(\ell )}w_{k}}\right)\] \[=-\frac{\beta^{2}}{2}\sum_{k=1}^{K}\sum_{\ell=1}^{L}\sigma_{\ell} ^{2}\frac{(\pi^{*}-\pi)_{k}^{2}}{w_{k}}+\beta\sum_{\ell=1}^{L}\sum_{k=1}^{K}z ^{(\ell)}\left(\pi^{*}-\pi\right)_{k}\mu_{k}^{(\ell)}\]

**Step 3.** By taking the derivative with respect to \(\beta\), we have

\[\frac{\partial\mathcal{L}}{\partial\beta}=-\beta\sum_{k=1}^{K}\sum_{\ell=1}^{ L}\sigma_{\ell}^{2}\frac{(\pi^{*}-\pi)_{k}^{2}}{w_{k}}+\sum_{\ell=1}^{L}\sum_{k=1}^{ K}z^{(\ell)}\left(\pi^{*}-\pi\right)_{k}\mu_{k}^{(\ell)}\,,\]

and setting it to zero, leads to:

\[\beta=\frac{\sum_{\ell=1}^{L}\sum_{k=1}^{K}z^{(\ell)}\left(\pi^{*}-\pi\right)_ {k}\mu_{k}^{(\ell)}}{\sum_{k=1}^{K}\sum_{\ell=1}^{L}\sigma_{\ell}^{2}\frac{( \pi^{*}-\pi)_{k}^{2}}{w_{k}}}=\frac{z^{\top}M\Delta}{\sigma_{o}^{2}\|\Delta\| _{\text{Diag}(1/w)}^{2}}\,,\] (16)

where \(\sigma_{o}^{2}\triangleq\sum_{\ell=1}^{L}\sigma_{\ell}^{2}\), and \(\Delta\triangleq\pi^{*}-\pi\).

From (15), excluding for the origin lying within the cone, we get:

\[\tilde{M}_{k}^{(\ell)} =\mu_{k}^{(\ell)}-\beta\sigma_{\ell}^{2}\frac{(\pi^{*}-\pi)_{k}}{ z^{\ell}w_{k}}\] \[=\mu_{k}^{(\ell)}-\frac{\sigma_{\ell}^{2}}{z^{\ell}}\frac{\Delta_ {k}}{w_{k}}\frac{z^{\top}M\Delta}{\sigma_{o}^{2}\|\Delta\|_{\text{Diag}(1/w)} ^{2}}\]

Finally, the Lagrangian from (14) leads to

\[\mathcal{L}(w,M)\] \[=-\frac{1}{2}\left(\frac{z^{\top}M\Delta}{\sigma_{o}^{2}\|\Delta\| _{\text{Diag}(1/w)}^{2}}\right)^{2}\sigma_{o}^{2}\|\Delta\|_{\text{Diag}(1/w) }^{2}+\frac{(z^{\top}M\Delta)^{2}}{\sigma_{o}^{2}\|\Delta\|_{\text{Diag}(1/w)} ^{2}}\] \[=\frac{(z^{\top}M\Delta)^{2}}{2\sigma_{o}^{2}\|\Delta\|_{\text{ Diag}(1/w)}^{2}}\,.\]

Thus, the characteristic time inverse is given by,

\[\max_{w\in\Delta^{K}}\inf_{\begin{subarray}{c}\pi\in N(\pi^{*})\\ \pi^{*}\in\Pi^{*}(M)\end{subarray}}\min_{z\in\mathcal{C}\setminus\{0\}}\frac{ (z^{\top}M\Delta)^{2}}{2\sigma_{o}^{2}\|\Delta\|_{\text{Diag}(1/w)}^{2}}=\inf_ {\begin{subarray}{c}\pi\in N(\pi^{*})\\ \pi^{*}\in\Pi^{*}(M)\end{subarray}}\min_{z\in\mathcal{C}\setminus\{0\}}\frac{ (z^{\top}M\Delta)^{2}}{2\sigma_{o}^{2}\|\Delta\|_{2}^{2}}\,.\]

### Proof of Theorem 4.1

This proof follows directly from Theorem 3.1 in Balas (1985). Recall that the set \(\mathcal{F}\) is given by:

\[\mathcal{F}\triangleq\cup_{\Pi\setminus\{\pi^{*}\}}\left\{\tilde{M}\in \mathcal{M}:\langle\text{vect}(z^{\top}(\pi-\pi^{*})),\text{vect}(\tilde{M}) \rangle=0\right\}\]

Any \(z\in\mathcal{C}\), we have \(z=\sum_{i}\alpha_{i}v_{i}\). Rewriting, every hyperplane in \(\mathcal{F}\) as \(P_{\pi}=\left\{\tilde{M}\in\mathcal{M}\big{|}\langle\text{vect}\left(\sum_{i} \alpha_{i}v_{i}^{\top}\pi\right),\text{vect}(\tilde{M})\rangle=\sum_{i}\alpha_ {i}v_{i}^{\top}\pi^{*}\right\}\). Then, by Theorem 3.1 in Balas (1985), \(\mathcal{C}(\mathcal{F})\) is given by:

\[\mathcal{C}(\mathcal{F})=\begin{cases}\gamma^{\top}\text{vect}(\tilde{M})\geq \gamma_{0},\,\gamma=\sum_{i}u_{i}\alpha_{i}\text{vect}(v_{i}^{\top}(\pi-\pi^{*})) \\ \gamma_{0}\leq u_{i}\sum_{i}\alpha_{i}v_{i}^{\top}\pi^{*},\tilde{M}\in\mathcal{M} \end{cases}\]

### Proof of Theorem 4.2

Recall that:

\[\bar{\mathcal{V}}_{\mathcal{C}}(w,M) \triangleq\min_{\tilde{M}\in\text{ch}(\partial\Lambda_{\pi^{*}}(M) )}\inf_{z\in\mathcal{C}}\sum_{k=1}^{K}w_{k}d_{\text{KL}}\left(z^{\top}M,z^{\top} \tilde{M}\right)\] \[\bar{w}^{*}(M) \triangleq\arg\max_{w\in\Delta^{\mathcal{K}}}\inf_{\begin{subarray} {c}\pi\in\Pi\setminus\pi^{*}\\ \pi^{*}\in\Pi^{*}(M)\end{subarray}}\min_{\tilde{M}\in\text{ch}(\partial \Lambda_{\pi^{*}}(M))}\min_{z\in\mathcal{C}}\sum_{k=1}^{K}w_{k}d_{\text{KL}} \left(z^{\top}M,z^{\top}\tilde{M}\right)\]
* For \((1)\) and \((2)\) observe that \((z,M)\to z^{\top}M\) and \((z,M,\tilde{M})\to d_{\text{KL}}\left(z^{\top}M,z^{\top}\tilde{M}\right)\) are continuous maps for all \((z,M)\in\mathcal{C}\times\mathcal{M}\) and \((z,M,\tilde{M})\in\mathcal{C}\times\mathcal{M}\times\text{ch}\left(\partial \Lambda_{\pi^{*}}\left(M\right)\right)\). Further, \(\sum_{k}w_{k}d_{\text{KL}}\left(z^{\top}M,z^{\top}\tilde{M}\right)\) is continuous in all its elements. Fix a sequence \((w_{t},,z_{t},M_{t})\in\Pi\times\mathcal{C}\times\mathcal{M}\) such that \((w_{t},z_{t},M_{t})\rightarrow(w,z,M)\). For any \(\epsilon,\;\exists\;t^{\prime}\geq 1\) such that \(\|(w_{t},z_{t},M_{t})-(w,z,M)\|\leq\epsilon\;\forall\;t\geq t^{\prime}\). Further, \(\text{ch}\left(\Lambda_{\pi^{*}}\left(M_{t}\right)\right)\rightarrow\text{ch} \left(\Lambda_{\pi^{*}}\left(M\right)\right)\). Therefore, for every \(\epsilon^{\prime},\;\exists\;t^{\prime\prime}\geq 1\) such that \(\forall\;t\geq t^{\prime\prime}\) we \[\Big{|}\sum_{k}w_{k,t}d_{\text{KL}}\left(z_{t}^{\top}M_{t},z_{t}^{\top}\tilde {M}_{t}\right)-\sum_{k}w_{k}d_{\text{KL}}\left(z^{\top}M,z_{t}^{\top}\tilde{ M}_{t}\right)\Big{|}\leq\epsilon^{\prime}\;\forall\;\tilde{M}_{t}\in\mathbb{R}^{K \times L}\] Taking \(t\geq\max\{t^{\prime},t^{\prime\prime}\}\), we have: \[\Big{|}\inf_{\tilde{M}\in\partial\Lambda_{\pi^{*}}(M)}\inf_{z\in \mathcal{C}}\sum_{k}w_{k,t}d_{\text{KL}}\left(z_{t}^{\top}M_{t},z_{t}^{\top} \tilde{M}_{t}\right)-\inf_{\tilde{M}\in\partial\Lambda_{\pi^{*}}(M)}\inf_{z \in\mathcal{C}}\sum_{k}w_{k}d_{\text{KL}}\left(z^{\top}M,z_{t}^{\top}\tilde{ M}_{t}\right)\Big{|}\] \[\leq\Big{|}\inf_{\tilde{M}\in\partial\Lambda_{\pi^{*}}(M)}\inf_{z \in\mathcal{C}}\sum_{k}w_{k,t}d_{\text{KL}}\left(z_{t}^{\top}M_{t},z_{t}^{ \top}\tilde{M}_{t}\right)-\sum_{k}w_{k}d_{\text{KL}}\left(z^{\top}M,z_{t}^{ \top}\tilde{M}_{t}\right)\Big{|}\] \[\leq\epsilon^{\prime}\]
* For \((3)\), we define \(f(w,M)=\inf_{\tilde{M}\in\text{ch}(\partial\Lambda_{\pi^{*}}(M))}\inf_{z\in \mathcal{C}}\sum_{k}w_{k}d_{\text{KL}}\left(z^{\top}M,z^{\top}\tilde{M}\right)\) and \(C(w)=\text{II}\). Then, from Berge's Theorem (Theorem F.1 in Appendix), we get \(w^{*}(M)\) is upper-hemicontinuous.
* For \((4)\), the convexity of \(w^{*}(M)\) follows since the optimal solution \[\max_{w\in\Pi}\inf_{\tilde{M}\in\text{ch}(\partial\Lambda_{\pi^{*}}(M))}\inf_{z \in\mathcal{C}}\sum_{k}w_{k}d_{\text{KL}}\left(z^{\top}M,z^{\top}\tilde{M}\right)\] is concave for any given \(\pi\) and \(\pi^{*}\).

Proof of the Stopping Time

### Proof of Lemma 4.1

The proof follows by showing that \(\inf_{z\in\mathcal{C}}\sum_{k}N_{k,t}d_{\text{KL}}\left(z^{\top}\hat{M}_{k,t},z^{ \top}M_{k}\right)\) is an appropriate stochastic process and can be bounded using the mixture of martingales technique of Kaufmann and Koolen (2021).

To this end, given a \(z\in\mathcal{C}\), we define the random variable as

\[X_{k}(t)\triangleq\sum_{k}\max\{0,N_{k,t}d_{\text{KL}}\left(z_{\inf}^{\top}\hat {M}_{k,t},z_{\inf}^{\top}M_{k}\right)-3\ln(1+\ln N_{k,t})\}\,,\]

where \(z_{\inf}\triangleq\arg\inf_{z\in\mathcal{C}}\sum_{k}N_{k,t}d_{\text{KL}}\left( z^{\top}\hat{M}_{k,t},z^{\top}M_{k}\right)\)

Since we assume \(M_{k,\ell}\) belongs to exponential family of distributions, for any given \(z_{\inf}\neq\mathbf{0}\), \(z_{\inf}^{\top}M_{k}\) being a non-degenerate linear transform also belongs to the exponential family.

Now, plugging in \(X_{k}(t)\) in Theorem 7 of Kaufmann and Koolen (2021) yields

\[\mathbb{P}\left[\exists t\in\mathbb{N}:\sum_{k\in[K]}N_{k,t}d_{ \text{KL}}\left(z_{\inf}^{\top}\hat{M}_{k,t},z_{\inf}^{\top}M_{k}\right) \geq\sum_{k\in[K]}3\ln\left(1+\ln\left(N_{k,t}\right)\right)+K\mathcal{T} \left(\frac{\ln\left(\frac{1}{\delta}\right)}{K}\right)\right]\] \[\leq\ \delta\.\]

Here, \(\mathcal{T}:\mathbb{R}^{+}\rightarrow\mathbb{R}^{+}\) is such that

\[\mathcal{T}(x)\triangleq 2\tilde{h}_{3/2}\left(\frac{h^{-1}(1+x)+\ln\left(2 \zeta(2)\right)}{2}\right)\] (17)

with

\[\forall u\geq 1,\quad h(u) =u-\ln(u)\] (18) \[\forall z\in[1,e],\forall x\geq 0,\quad\tilde{h}_{z}(x) =\begin{cases}\exp\left(\frac{1}{h^{-1}(x)}\right)h^{-1}(x)&\text{ if }x\geq h^{-1}\left(\frac{1}{\ln(z)}\right)\\ z(x-\ln(\ln(z)))&\text{ else}\end{cases}\,\] (19)

and \(\zeta(2)=\sum_{n=1}^{\infty}n^{-2}\).

### Proof of Theorem 4.3

First, we prove the following lemma required to proceed with Theorem 4.3.

**Lemma C.1**.: _For any \(k=1,2,\ldots,K\), let \(1\leq t_{k}\leq t\). Let \(\eta>0\) and define the event:_

\[C\triangleq\cap_{k\in[K]}C_{k}\triangleq\cap_{k\in[K]}\{t_{k}\leq N_{k,t}\leq (1+\eta)t_{k}\}\]

_and let \(\mathbbm{1}_{C}\) indicate whether the event holds. For \(\rho\geq(1+\eta)K\), for all \(z\in\mathcal{C}\) we have:_

\[\mathbb{P}\left[\mathbbm{1}_{C}\sum_{k\in[K]}N_{k,t}d_{\text{KL}}\left(z^{\top }\hat{M}_{k,t},z^{\top}M_{k}\right)\geq\rho\right]\leq\left(\frac{\rho e}{K} \right)^{K}\exp\left(\frac{-\rho}{1+\eta}\right)\,.\]

Proof.: Fix \(\zeta\in\mathbb{R}_{+}^{K}\) and \(t\geq 0\). Define \(m_{k,t}\) such that:

\[m_{k,t} = \begin{cases}m,\text{ if }\exists\,0\leq m\leq z^{\top}M_{k}, \text{ s.t. }td_{\text{KL}}\left(m,z^{\top}M_{k}\right)=\zeta_{k}\\ 0,\text{ otherwise}\end{cases}\]

By monotonicity of \(td_{\text{KL}}\left(.\right),\ t\to m_{k,t}\) is increasing. With \(t=N_{k,t}\), we have that

\[N_{k,t}d_{\text{KL}}\left(m_{k,N_{k,t}},z^{\top}M_{k}\right)=\zeta_{k}\leq N _{k,t}d_{\text{KL}}\left(z^{\top}\hat{M}_{k,t},z^{\top}M_{k}\right),\implies z ^{\top}\hat{M}_{k,t}\overset{(a)}{\leq}m_{k,N_{k,t}}\overset{(b)}{\leq}m_{k, (1+\eta)t_{k}}.\]where \((a)\) follows from monotonicity of \(d_{\text{KL}}\left(\cdot,\cdot\right)\) and \((b)\) follows from monotonicity of \(m_{k,t}^{(\ell)}\).

With \(t_{k}d_{\text{KL}}\left(z^{\top}\hat{M}_{k,t_{k}\left(1+\eta\right)},z^{\top}M_{ k}\right)=\frac{\zeta_{k}}{1+\eta}\) and non-negativity of \(d_{\text{KL}}\left(\cdot,\cdot\right)\) we have:

\[\mathbb{P}\left(\cap_{k\in[K]}\left\{\mathbbm{1}_{C_{k}}N_{k,t}d_ {\text{KL}}\left(z^{\top}\hat{M}_{k,t},z^{\top}M_{k}\right)\geq\zeta_{k}\right\}\right)\] \[\leq \mathbb{P}\left(\cap_{k\in[K]}\left\{z^{\top}\hat{M}_{k,t}\leq m_ {k,N_{k,t}},C_{k}\right\}\right)\] \[\leq \mathbb{P}\left(\cap_{k\in[K]}\left\{z^{\top}\hat{M}_{k,t}\leq m_ {k,\left(1+\eta\right)t_{k}},C_{k}\right\}\right)\] \[\overset{(a)}{\leq} \exp\left(-\sum_{k\in[K]}t_{k}d_{\text{KL}}\left(m_{k,\left(1+\eta \right)t_{k}},z^{\top}M_{k}\right)\right)\] \[= \exp\left(-\sum_{k\in[K]}\frac{\zeta_{k}}{1+\eta}\right)\,,\]

where \((a)\) follows from Lemma F.2.

Using Lemma F.3, with \(Z_{k}=N_{k,t}d_{\text{KL}}\left(z^{\top}\hat{M}_{k,t},z^{\top}M_{k}\right)\) and \(a=\frac{1}{(1+\eta)}\), we have that:

\[\mathbb{P}\left[\mathbbm{1}_{C}\sum_{k\in[K]}N_{k,t}d_{\text{KL}}\left(z^{\top }\hat{M}_{k,t},z^{\top}M_{k}\right)\geq\rho\right]\leq\left(\frac{\rho e}{K} \right)^{K}\exp\left(\frac{-\rho}{1+\eta}\right)\]

This concludes the proof. 

**Now, we provide the proof of Theorem 4.3.**

Proof.: Let us define \(D=\lceil\frac{\log(t)}{\log(1+\eta)}\rceil\) and set \(\mathcal{D}=\{1,2,\ldots,D\}^{K}\). Let us define

\[A=\left\{\sum_{k\in[K]}N_{k,t}d_{\text{KL}}\left(z^{\top}\hat{M}_{k,t},z^{\top }M_{k}\right)\geq\rho\right\}\]

\[B_{d}=\cap_{k=1}^{K}\left\{\left(1+\xi\right)^{d_{k}-1}\leq N_{k,t}\leq(1+\xi )^{d_{k}}\right\}\]

We have \(A=\cup_{d\in\mathcal{D}}(A\cap B_{d})\), hence \(\mathbb{P}(A)\leq\sum_{d\in\mathcal{D}}\mathbb{P}(A\cap B_{d})\).

For \(\eta=\frac{1}{\rho-1}\) and \(\rho\geq(1+\eta)K\), we get \(\rho\geq K+1\).

Now, we use Lemma C.1 with \(\eta=\frac{1}{\rho-1}\) and \(\bar{t}_{k}=\left(1+\eta\right)^{d_{k}-1}\) to obtain for all \(d\in\mathcal{D}\):

\[\mathbb{P}\left(A\cap B_{d}\right)\leq\left(\frac{\rho e}{K}\right)^{K}\exp \left(\frac{-\rho}{(1+\eta)}\right)\]

By a union bound on \(\mathcal{D}\), we have:

\[\mathbb{P}\left(A\right)\leq\left(\frac{D\rho e}{K}\right)^{K}\exp\left(\frac {-\rho}{1+\eta}\right)\]

Noting that \(D=\lceil\frac{\log(t)}{\log(1+\eta)}\rceil\) and \(\eta=\frac{1}{\rho-1}\), we get:

\[\mathbb{P}\left(A\right)\leq\exp\left(-\rho\right)\left(\frac{\rho\lceil\rho \log(t)\rceil}{K}\right)^{K}e^{K+1}\,.\]Proofs for Sample Complexity Upper Bound

### Pairwise Concentration Bounds

**Lemma D.1** (Pairwise concentration (Proof of Theorem 5.1)).: _Consider the event:_

\[\mathcal{E}_{t}\triangleq\cap_{i\in[K]}\cap_{j\neq i}\left\{L_{i,j}(t)\leq z^{ \top}\mu_{i}-z^{\top}\mu_{j}\leq U_{i,j}(t)\right\}\] (20)

_where \(L_{ij}(t)=z^{\top}(\hat{\mu}_{i,t}-\hat{\mu}_{j,t})-\beta_{ij}(t)\) and \(U_{ij}(t)=z^{\top}(\hat{\mu}_{i,t}-\hat{\mu}_{j,t})+\beta_{ij}(t)\), and \(\beta_{ij}(t)\) is defined as_

\[\beta_{ij}^{2}(t)\triangleq 4\|z\|_{1}^{2}\!\left(h\left(\frac{\log(\frac{K_{ 1}}{\delta})}{2}\right)+\sum_{a\in\{i,j\}}\log\left(4+\log(N_{a}(t))\right) \right)\left(\sum_{a\in\{i,j\}}\frac{1}{N_{a}(t)}\right).\]

_Here, \(K_{1}\triangleq\frac{K(K-1)}{2},\;h(\cdot)\approx x+\log(1+x)\). Then, we get_

\[\mathbb{P}\left(\cap_{t=1}^{\infty}\mathcal{E}_{t}\right)\geq 1-\delta\,.\]

Proof.: We have the following:

\[\mathcal{E}_{t} = \cap_{(i,j)}\left\{L_{i,j}\leq z^{\top}\mu_{i}-z^{\top}\mu_{j} \leq U_{i,j}\right\}\] \[= \cap_{(i,j)}\left\{\left|z^{\top}\left(\hat{\mu}_{i,t}-\hat{\mu}_ {j,t}\right)-z^{\top}\left(\mu_{i}-\mu_{j}\right)\big{|}\leq\beta_{ij}(t)\right\}\right.\]

where, \((i,j)\in[K]\times[K]\) is the set of arm pairs. By a union bound, we have the following:

\[\mathbb{P}\left(\overline{\mathcal{E}}_{t}\right) = \mathbb{P}\left(\exists\,t\geq 1:\overline{\mathcal{E}}_{t} \text{ holds }\right)\] \[= \mathbb{P}\left(\exists\,t\geq 1:\left|z^{\top}\left(\hat{\mu}_{i,t}- \hat{\mu}_{j,t}\right)-z^{\top}\left(\mu_{i}-\mu_{j}\right)\big{|}\geq\beta_{ ij}(t)\right)\] \[\leq \mathbb{P}\left(\exists\,t\geq 1:\left|z^{\top}(\hat{\mu}_{i,t}- \mu_{i})-z^{\top}(\hat{\mu}_{j,t}-\mu_{j})\right|\geq\beta_{ij}(t)\right)\] \[\stackrel{{(a)}}{{\leq}} \sum_{(i,j)}\frac{\delta}{K(K-1)}\] \[= \delta\]

\((a)\) follows from

1. \(z^{\top}(\hat{\mu}_{i,t}-\mu_{i})\) is a \(\|z\|_{1}\) sub-Gaussian as \(\hat{\mu}_{i,t}-\mu_{i}\) is 1-sub-Gaussian, and
2. Lemma 7 of (Kone et al., 2023a) that states that for two 1-sub-Gaussian and centred random variables \(X\) and \(Y\), the following holds true with probability \(1-\delta\). \[\left|\frac{1}{p}\sum_{i}X_{i}-\frac{1}{q}\sum_{i}Y_{i}\right|\leq 2 \sqrt{\left(h\left(\frac{\log(\frac{1}{2})}{2}\right)+\log\log(e^{4}p)+\log \log(e^{4}q)\right)\left(\frac{1}{p}+\frac{1}{q}\right)}\,,\] given \(h(x)\approx x+\ln x\).

We now show that the Pareto fronts under the metric \(d_{p}\).

**Lemma D.2**.: \((\mathcal{Z},d_{p})\) _is a complete metric space._

Proof.: From Definition 5.2, for two Pareto fronts \(\mathcal{P}_{1},\mathcal{P}_{2}\in\mathcal{Z}\), we have that:

\[d_{p}(\mathcal{P}_{1},\mathcal{P}_{2})\triangleq\max\left\{\sup_{k\in \mathcal{P}_{1}}d(k,\mathcal{P}_{1}),\sup_{k\in\mathcal{P}_{2}}d(k,\mathcal{P} _{1})\right\}\]

where,

\[d(k,\mathcal{P})=\inf_{k^{\prime}\in\mathcal{P}}\max\left\{0,\sup_{z\in C\cap \mathbb{B}(1)}z^{\top}\left(\mu_{k^{\prime}}-\mu_{k}\right)\right\}\]1. We first show that \(d_{p}(\mathcal{P}_{1},\mathcal{P}_{2})\) is a metric. Let \(\mathcal{P}_{1},\mathcal{P}_{2}\in\mathcal{Z}\). To show that \(d_{p}\) is a metric, we show that: 1. Symmetry: \(d_{p}(\mathcal{P}_{1},\mathcal{P}_{2})\) is symmetric by definition 2. Triangle Inequality: We show that \(d_{p}(\mathcal{P}_{1},\mathcal{P}_{3})\leq d_{p}(\mathcal{P}_{1},\mathcal{P}_{ 2})+d_{p}(\mathcal{P}_{2},\mathcal{P}_{3})\). \[d_{p}\left(\mathcal{P}_{1},\mathcal{P}_{3}\right) = \max\left\{\max_{k\in\mathcal{P}_{1}}\min_{k^{\prime}\in\mathcal{ P}_{3}}\mu_{k^{\prime}}(X_{3})-\mu_{k}(X_{1}),\max_{k\in\mathcal{P}_{3}}\min_{k ^{\prime}\in\mathcal{P}_{1}}\mu_{k^{\prime}}(X_{1})-\mu_{k}(X_{3})\right\}\] We have that: \[\max_{k\in\mathcal{P}_{1}}\min_{k^{\prime}\in\mathcal{P}_{3}}\mu_ {k^{\prime}}(X_{3})-\mu_{k}(X_{1})\] \[\leq \max_{k\in\mathcal{P}_{1}}\min_{k^{\prime}\in\mathcal{P}_{3}}\mu _{k^{\prime}}(X_{3})+\min_{k^{\prime\prime}\in\mathcal{P}_{2}}\mu_{k^{\prime \prime}}(X_{2})-\max_{k^{\prime\prime}\in\mathcal{P}_{2}}\mu_{k^{\prime\prime }}(X_{2})-\mu_{k}(X_{1})\] \[\leq \max_{k^{\prime\prime}\in\mathcal{P}(X_{2})}\min_{k^{\prime}\in \mathcal{P}_{3}}\mu_{k^{\prime}}(X_{3})-\mu_{k^{\prime\prime}}(X_{2})+\max_{k \in\mathcal{P}_{1}}\min_{k^{\prime\prime}\in\mathcal{P}(X_{2})}\mu_{k^{\prime \prime}}(X_{2})-\mu_{k}(X_{1})\] Using a similar argument: \[\max_{k\in\mathcal{P}_{3}}\min_{k^{\prime}\in\mathcal{P}_{1}}\mu_ {k^{\prime}}(X_{1})-\mu_{k}(X_{2})\leq\max_{k^{\prime\prime}\in\mathcal{P}(X_ {2})}\min_{k^{\prime}\in\mathcal{P}_{1}}\mu_{k^{\prime}}(X_{1})-\mu_{k^{\prime \prime}}(X_{2})+\max_{k\in\mathcal{P}_{3}}\min_{k^{\prime\prime}\in\mathcal{P} (X_{2})}\mu_{k^{\prime\prime}}(X_{2})-\mu_{k}(X_{3})\] Noting that for any positive numbers \(a,b,c,d,\ \max\{a+b,c+d\}=\max\{a+c,b+d\}\), we have: \[d_{p}(\mathcal{P}_{1},\mathcal{P}_{3})\leq \max\Big{\{}\max_{k^{\prime\prime}\in\mathcal{P}(X_{2})}\min_{k^{ \prime}\in\mathcal{P}_{3}}\mu_{k^{\prime}}(X_{3})-\mu_{k^{\prime\prime}}(X_{2} )+\max_{k\in\mathcal{P}_{1}}\min_{k^{\prime\prime}\in\mathcal{P}(X_{2})}\mu_{ k^{\prime\prime}}(X_{2})-\mu_{k}(X_{1}),\] \[\max_{k^{\prime\prime}\in\mathcal{P}(X_{2})}\min_{k^{\prime}\in \mathcal{P}_{1}}\mu_{k^{\prime}}(X_{1})-\mu_{k^{\prime\prime}}(X_{2})+\max_{k \in\mathcal{P}_{3}}\min_{k^{\prime\prime}\in\mathcal{P}(X_{2})}\mu_{k^{\prime \prime}}(X_{2})-\mu_{k}(X_{3})\Big{\}}\] \[= \max\Big{\{}\max_{k^{\prime\prime}\in\mathcal{P}(X_{2})}\min_{k^{ \prime}\in\mathcal{P}_{1}}\mu_{k^{\prime}}(X_{1})-\mu_{k^{\prime\prime}}(X_{2} )+\max_{k^{\prime}\in\mathcal{P}_{1}}\min_{k^{\prime\prime}\in\mathcal{P}(X_{2 })}\mu_{k^{\prime\prime}}(X_{2})-\mu_{k^{\prime}}(X_{1}),\] \[\max_{k^{\prime\prime}\in\mathcal{P}(X_{2})}\min_{k^{\prime}\in \mathcal{P}_{3}}\mu_{k^{\prime}}(X_{3})-\mu_{k^{\prime\prime}}(X_{2})+\max_{k \in\mathcal{P}_{3}}\min_{k^{\prime\prime}\in\mathcal{P}(X_{2})}\mu_{k^{\prime \prime}}(X_{2})-\mu_{k}(X_{3})\Big{\}}\] \[= d_{p}(\mathcal{P}_{1},\mathcal{P}_{2})+d_{p}(\mathcal{P}_{2}, \mathcal{P}_{3})\]
3. We now show that \(d_{p}(\mathcal{P}_{1},\mathcal{P}_{2})=0\iff\mathcal{P}_{1}=\mathcal{P}_{2}\). The implication \(\mathcal{P}_{1}=\mathcal{P}_{2}\implies d_{p}(\mathcal{P}_{1},\mathcal{P}_{2})=0\) is immediate. For the other side, note that by Definition 5.2, we have: \[d_{p}\left(\mathcal{P}_{1},\mathcal{P}_{2}\right) =0\] \[\implies\sup_{k\in\mathcal{P}_{1}}\Delta(k,\mathcal{P}_{2})=0\text{ and }\sup_{k\in\mathcal{P}_{2}}\Delta(k,\mathcal{P}_{1})=0\] Further, \(\sup_{k\in\mathcal{P}_{1}}\Delta(k,\mathcal{P}_{2})=0\) implies: \[\forall\ k\in\mathcal{P}_{1},k\not\preceq_{\mathcal{C}}k^{\prime},\ k^{\prime}\in\mathcal{P}_{2}\iff\forall\ k\in\mathcal{P}_{1},\ k\in\mathcal{P}_{2}\] A similar agrument using \(\sup_{k\in\mathcal{P}_{1}}\Delta(k,\mathcal{P}_{1})=0\) implies that \(\forall\ k\in\mathcal{P}_{2},\ k\not\preceq_{\mathcal{C}}k^{\prime},k^{\prime} \in\mathcal{P}_{1}\).
2. We now show that \(\mathcal{Z}\) is compact under the metric \(d_{p}\). Consider a sequence of Pareto fronts \(\mathcal{P}_{1},\mathcal{P}_{2},\ldots,\mathcal{P}_{n}\in\mathcal{Z}\) and \(\mathcal{P}\) be the candidate for limiting Pareto front. * Boundedness of \(\mathcal{P}\) is immediate. * \(\mathcal{P}_{n}\rightarrow\mathcal{P}\), therefore, \(\forall\ \epsilon>0,\exists\ N(\epsilon)\) s.t. \(\forall\ n>N(\epsilon)\) and \(d_{p}(P_{n},P)<\epsilon\). Let \(\mu_{k}\) be a limit point of \(\mathcal{P}\), i.e., \(\exists\) a sequence \(\mu_{k,n}\in\mathcal{P}\) such that \(\mu_{k,n}\rightarrow\mu_{k}\). Since \(d_{p}\left(\mathcal{P}_{n},\mathcal{P}\right)\to 0\) for each \(\mu_{k,n}\in\mathcal{P}\) there exists \(\mu_{k,n,m}\in\mathcal{P}_{n}\) s.t. \(\mu_{k,n,m}\rightarrow\mu_{k,n}\). Using a diagonalization argument, we can obtain a subsequence \(\mu_{k,n,m}\rightarrow\mu_{k}\). * Since \(\mathcal{P}_{n}\) is compact, \(\mu_{k}\) must lie in \(\mathcal{P}\) and therefore, \(\mathcal{P}\) is closed.

### Concentration to the Pareto Front

**Lemma D.3**.: _There exists constants \(C>0\) such that:_

\[\mathbb{P}\left(\tilde{\mathcal{G}}_{T}\right)\leq 2K^{2}\frac{1}{1-\exp(-C)}T\exp \left(-CT^{1/8}\right)\,,\]

_where \(\mathcal{G}_{T}=\cap_{t=h(T)}^{T}\left\{d_{\mathbb{P}}\left(\hat{\mathcal{P}}_{t}, \mathcal{P}^{*}\right)\leq\epsilon\right\}\)._Proof.: We then have that:

\[\mathbb{P}\left(d_{\mathrm{P}}\left(\hat{\mathcal{P}}_{t},\mathcal{P }^{*}\right)\geq\epsilon\right) = \mathbb{P}\left(\max\left\{d_{\mathrm{P}}\left(\hat{\mathcal{P}}_{t },\mathcal{P}^{*}\right),d_{\mathrm{P}}\left(\mathcal{P}^{*},\hat{\mathcal{P}}_ {t}\right)\right\}\geq\epsilon\right)\] \[\leq \mathbb{P}\left(d_{\mathrm{P}}\left(\hat{\mathcal{P}}_{t}, \mathcal{P}^{*}\right)\geq\epsilon\right)+\mathbb{P}\left(d_{\mathrm{P}}\left( \mathcal{P}^{*},\hat{\mathcal{P}}_{t}\right)\geq\epsilon\right)\]

Focusing on the first term we have:

\[d_{\mathrm{P}}\left(\hat{\mathcal{P}}_{t},\mathcal{P}^{*}\right) =\inf_{k\in\hat{\mathcal{P}}_{t}}\sup_{k^{\prime}\in\mathcal{P}^ {*}}\max\left\{0,\max_{z\in C\cap\mathbb{B}(1)}z^{\top}\left(M_{k^{\prime}}- \hat{M}_{k,t}\right)\right\}\] \[\stackrel{{(a)}}{{=}}\max_{k^{\prime}\in\hat{ \mathcal{P}}_{t}}\max_{k^{\prime}\in\mathcal{P}^{*}}\max\left\{0,\max_{z\in C \cap\mathbb{B}(1)}z^{\top}\left(M_{k^{\prime}}-\hat{M}_{k^{\prime},t}+\hat{M} _{k^{\prime},t}-\hat{M}_{k,t}\right)\right\}\] \[\stackrel{{(b)}}{{\leq}}\max_{k^{\prime}\in\mathcal{ P}^{*}}\max\left\{0,\max_{z\in C\cap\mathbb{B}(1)}z^{\top}\left(M_{k^{\prime}}- \hat{M}_{k^{\prime},t}\right)\right\}\] \[\quad+\max_{k^{\prime}\in\mathcal{P}^{*}}\max\left\{0,\max_{z\in C \cap\mathbb{B}(1)}z^{\top}\left(\hat{M}_{k^{\prime},t}-\hat{M}_{k,t}\right)\right\}\]

Recall that \(\bar{\mathcal{G}}_{T}=\cup_{t=h(T)}^{T}\left\{d_{\mathrm{P}}\left(\hat{ \mathcal{P}}_{t},\mathcal{P}^{*}\right)\geq\epsilon\right\}\), then using a union bound, we have:

\[\mathbb{P}\left(\bar{\mathcal{G}}_{T}\right)\] \[\leq \sum_{t=h(T)}^{T}\mathbb{P}\left(d_{\mathrm{P}}\left(\hat{ \mathcal{P}}_{t},\mathcal{P}^{*}\right)\geq\epsilon\right)\] \[\leq \sum_{t=h(T)}^{T}\left[\sum_{(k,k^{\prime})}\mathbb{P}\left(z^{ \top}\left(\hat{M}_{k,t}-\hat{M}_{k^{\prime},t}\right)\leq z^{\top}\left(M_{k} -M_{k^{\prime}}\right)-\xi\right)\right.\] \[\qquad\qquad\left.+\mathbb{P}\left(z^{\top}\left(\hat{M}_{k,t}- \hat{M}_{k^{\prime},t}\right)\geq z^{\top}\left(M_{k}-M_{k^{\prime}}\right)+ \xi\right)\right].\]

Let \(T\) be such that \(h(T)\geq K^{2}\). Since \(t\geq h(T)\), one has that \(N_{k,t}\geq\sqrt{t}-K\).

Then using a union bound on each pair and number of arms, as well as a Chernoff bound, we have that each of the terms in the above inequality are bounded as

\[\mathbb{P}\left(z^{\top}\left(\hat{M}_{k,t}-\hat{M}_{k^{\prime},t }\right)\leq z^{\top}\left(M_{k}-M_{k^{\prime}}\right)-\xi\right)\] \[= \mathbb{P}\left(z^{\top}\left(\hat{M}_{k,t}-\hat{M}_{k^{\prime}, t}\right)\leq z^{\top}\left(M_{k}-M_{k^{\prime}}\right)-\xi,N_{k,t}\geq\sqrt{t}\right)\] \[\leq \sum_{s=\sqrt{t}-K}^{t}\mathbb{P}\left(z^{\top}\left(\hat{M}_{k, s}-\hat{M}_{k^{\prime},s}\right)\leq z^{\top}\left(M_{k}-M_{k^{\prime}}\right)-\xi\right)\] \[\leq \sum_{s=\sqrt{t}-K}^{t}\mathbb{P}\left(z^{\top}\left(\hat{M}_{k, s}-M_{k}\right)-z^{\top}\left(\hat{M}_{k^{\prime},s}-M_{k^{\prime}}\right)\leq- \xi/2-\xi/2\right)\] \[\leq \sum_{s=\sqrt{t}-K}^{t}\left(\mathbb{P}\left(z^{\top}\left(\hat{ M}_{k,s}-M_{k}\right)\leq-\xi/2\right)+\mathbb{P}\left(z^{\top}\left(\hat{M}_{k^{ \prime},s}-M_{k^{\prime}}\right)\geq\xi/2\right)\right)\] \[\leq \sum_{s=\sqrt{t}-K}^{t}\left(\exp\left(-sd_{\text{KL}}\left(z^{ \top}M_{k}-\xi/2,z^{\top}M_{k}\right)\right)+\exp\left(-sd_{\text{KL}}\left(z^{ \top}M_{k^{\prime}}+\xi/2,z^{\top}M_{k^{\prime}}\right)\right)\right)\] \[\leq \frac{\exp\left(-(\sqrt{t}-K)d_{\text{KL}}\left(z^{\top}M_{k}-\xi /2,z^{\top}M_{k}\right)\right)}{1-\exp\left(-d_{\text{KL}}\left(z^{\top}M_{k}- \xi/2,z^{\top}M_{k}\right)\right)}+\frac{\exp\left(-(\sqrt{t}-K)d_{\text{KL}} \left(z^{\top}M_{k^{\prime}}+\xi/2,z^{\top}M_{k^{\prime}}\right)\right)}{1-\exp \left(-d_{\text{KL}}\left(z^{\top}M_{k^{\prime}}+\xi/2,z^{\top}M_{k^{\prime}} \right)\right)}\] \[\leq \left(\frac{1}{1-\exp\left(-d_{\text{KL}}\left(z^{\top}M_{k}-\xi/2,z^{\top}M_{k}\right)\right)}+\frac{1}{1-\exp\left(-d_{\text{KL}}\left(z^{\top} M_{k^{\prime}}+\xi/2,z^{\top}M_{k^{\prime}}\right)\right)}\right)\] \[\quad\times\exp\left(-(\sqrt{t}-K)\min_{k,k^{\prime}}\{d_{\text{KL}} \left(z^{\top}M_{k}-\xi/2,z^{\top}M_{k}\right),d_{\text{KL}}\left(z^{\top}M_{k^{ \prime}}+\xi/2,z^{\top}M_{k^{\prime}}\right)\}\right)\]Similarly, we have:

\[\mathbb{P}\left(z^{\top}\left(\hat{M}_{k,t}-\hat{M}_{k^{\prime},t} \right)\geq z^{\top}\left(M_{k}-M_{k^{\prime}}\right)+\xi\right)\] \[\leq \left(\frac{1}{1-\exp\left(-d_{\text{KL}}\left(z^{\top}M_{k}+\xi/2, z^{\top}M_{k}\right)\right)}+\frac{1}{1-\exp\left(-d_{\text{KL}}\left(z^{\top}M_{k^{ \prime}}-\xi/2,z^{\top}M_{k^{\prime}}\right)\right)}\right)\] \[\quad\times\exp\left(-(\sqrt{t}-K)\min_{k,k^{\prime}}\{d_{\text{ KL}}\left(z^{\top}M_{k}+\xi/2,z^{\top}M_{k}\right),d_{\text{KL}}\left(z^{\top}M_{k^{ \prime}}-\xi/2,z^{\top}M_{k^{\prime}}\right)\}\right)\]

Now, we set

\[C\triangleq\min_{k}\left\{d_{\text{KL}}\left(z^{\top}M_{k}+\xi/2,z^{\top}M_{k }\right),d_{\text{KL}}\left(z^{\top}M_{k}-\xi/2,z^{\top}M_{k}\right)\right\}\]

and

\[B\triangleq\sum_{\left(k,k^{\prime}\right)} \left(\frac{1}{1-\exp\left(-d_{\text{KL}}\left(z^{\top}M_{k}-\xi/2,z^{\top}M_{k}\right)\right)}+\frac{1}{1-\exp\left(-d_{\text{KL}}\left(z^{ \top}M_{k^{\prime}}+\xi/2,z^{\top}M_{k^{\prime}}\right)\right)}\right.\] \[\quad+\frac{1}{1-\exp\left(-d_{\text{KL}}\left(z^{\top}M_{k}+\xi/ 2,z^{\top}M_{k}\right)\right)}+\frac{1}{1-\exp\left(-d_{\text{KL}}\left(z^{ \top}M_{k^{\prime}}-\xi/2,z^{\top}M_{k^{\prime}}\right)\right)}\right).\]

We observe that \(B\leq 2K^{2}\frac{1}{1-\exp(-C)}\). Now, we get that

\[\mathbb{P}\left(\bar{\mathcal{G}}_{T}\right)\leq\sum_{t=h(T)}^{T}B\exp-C\sqrt{ t}\leq 2K^{2}\frac{1}{1-\exp(-C)}T\exp\left(-CT^{1/8}\right)\,.\]

### Proof of Theorem 5.2

**Theorem D.1** (Restating Theorem 5.2).: _For any \(\alpha>0\) and \(c(t,\delta)\) defined in (7), we have that the stopping time satisfies :_

\[\lim_{\delta\to 0}\frac{\mathbb{E}[\tau]}{\log\left(\frac{1}{\delta}\right)} \leq\alpha\bar{\mathcal{T}}_{\mathcal{F}}(M)\;\forall\;M\in\mathbb{R}^{K\times L}\]

Proof.: **Step 1: Good Event** Let \(T\in\mathbb{N},\text{ and }h(T)=\sqrt{T}\), define the good event:

\[\mathcal{G}_{T}=\cap_{t=h(T)}^{T}\left\{d_{p}(\hat{\mathcal{P}}_{t},\mathcal{ P}^{*})\leq f(\epsilon)\right\}\] (21)

where, \(f(\epsilon)\) is such that:

\[d_{p}(\hat{\mathcal{P}}_{t},\mathcal{P}^{*})\leq f(\epsilon)\implies\sup_{w^{ \prime}\in w^{*}(\hat{\mathcal{P}}_{\tau})}\sup_{w\in w^{*}(\mathcal{P}^{*})} \|w^{\prime}-w\|\leq\epsilon\]

**Step 2: Concentration of Good Event** In Lemma D.3, we show that:

\[\mathbb{P}\left(\bar{\mathcal{G}}_{T}\right)\leq 2K^{2}\frac{1}{1-\exp(-C)}T\exp \left(-CT^{\frac{1}{8}}\right)\]

**Step 3: Tracking Lemma** We have:

\[\left|N_{k,t}-w_{k}^{*}(M)\right| \leq \left|\frac{N_{k,t}}{t}-\frac{1}{t}\sum_{s=1}^{t-1}w_{k}^{*}(\hat {M}_{s})\right|+\left|\frac{1}{t}\sum_{s=1}^{t-1}w_{k}^{*}(\hat{M}_{s})-w_{k}^ {*}(M)\right|\] \[\leq \frac{N_{k,t}}{t}+\frac{h(T)}{t}+\left|\frac{1}{t}\sum_{s=1}^{t -1}w_{k}^{*}(\hat{M}_{s})-w_{k}^{*}(M)\right|\] \[\leq \frac{K(\sqrt{t}+1)}{t}+\frac{h(T)}{t}+\left|\frac{1}{t}\sum_{s=1 }^{t}w_{k}^{*}(\hat{M}_{s})-w_{k}^{*}(M)\right|\]From (Garivier and Kaufmann, 2016), we have that:

\[\max_{k}\left|N_{k,t}-\sum_{t}w_{k,t}\right|\leq K\left(1+\sqrt{t}\right)\]

#### Step 4: Complexity of the good event

Assume \(t\geq T_{\epsilon}\), and let:

\[C_{\epsilon}\left(M\right)\triangleq\inf_{w^{\prime},M^{\prime}}\overline{ \mathcal{V}}_{\mathcal{C}}\left(w,M\right),\;\forall(w,M)\text{ s.t. }\|w^{\prime}-w\|\leq 3\epsilon,\;d_{ \mathrm{P}}\left(\hat{P}_{t},\mathcal{P}^{*}\right)\leq f(\epsilon)\]

Then, we have that:

\[\overline{\mathcal{V}}_{\mathcal{C}}\left(N_{t},\hat{M}_{t}\right)\geq tC_{ \epsilon}(M)\]

#### Step 5: Bounding the stopping time for good and bad events

Let \(\tau_{\delta}\) be the stopping time, then:

\[\min\{\tau_{\delta},T\}\leq\sqrt{T}+\sum_{t=T_{\epsilon}}^{T}\mathbbm{1}_{\tau _{\delta}\geq t}\]

From the stopping rule (Equation (7)), we get that:

\[T_{\epsilon}+\sum_{t=T_{\epsilon}}^{T}\mathbbm{1}_{\overline{ \mathcal{V}}_{\mathcal{C}}\left(N_{t},\hat{M}_{t}\right)\leq\beta(t,\delta)} \leq \sqrt{T}+\sum_{t=T_{\epsilon}}^{T}\mathbbm{1}_{tC_{\epsilon}(M) \leq\beta(t,\delta)}\] \[\leq \sqrt{T}+\frac{\beta(t,\delta)}{C_{\epsilon}(M)}\]

where, \(\beta(t,\delta)\) is defined in Equation (6).

Define \(T_{\delta}=\inf\left\{T\in\mathbb{N}:\sqrt{T}+\frac{c(t,\delta)}{C_{\epsilon}( M)}\leq T\right\}\). Hence, we have:

\[\mathbb{E}\left[\tau_{\delta}\right]\leq T_{\epsilon}+T_{\delta}+\sum_{T=1}^{ \infty}2K^{2}\frac{1}{1-\exp(-C)}T\exp\left(-CT^{-1/8}\right)\leq T_{\epsilon }+T_{\delta}+T^{\prime}\]

Let \(C(\eta)=\inf\{T:T-\sqrt{T}\geq\frac{T}{(1+\eta)}\}\). Then:

\[T_{\delta}\leq C(\eta)+\inf\left\{T\in\mathbb{N}:\frac{TC_{\epsilon}(M)}{(1+ \eta)}\geq\beta(t,\delta)\right\}\]

#### Step 6: Obtaining the asymptotic bounds

Taking limits:

\[\lim_{\delta\to 0}\inf\frac{\mathbb{E}\left[\tau_{\delta}\right]}{\log\left( \frac{1}{\delta}\right)}\leq\alpha\mathcal{T}(M)\;\forall\;\alpha\geq 1\]Reduction to Best-arm Identification

We briefly discuss how the metric \(d_{\mathrm{P}}\left(\cdot,\cdot\right)\) extends existing notions of gap in best-arm and Pareto-front identification literature. Specifically, we proceed with the three following observations.

1. Observe that \(d_{\mathrm{P}}\left(\mathcal{P}^{*},\mathcal{P}^{*}\right)=0\).
2. Further, iff \(\mathcal{C}\) represents the component-wise ordering as in Pareto-front identification (Auer et al., 2016; Kone et al., 2023a), then \(z^{(\ell)}=1,\ \forall\ \ell\in[L]\). \[d_{\mathrm{P}}\left(\left[K\right]\setminus\mathcal{P}^{*}, \mathcal{P}^{*}\right)\right)\] \[=\max\left\{\sup_{k\in[K]\setminus\mathcal{P}^{*}}d\left(k, \mathcal{P}^{*}\right),\sup_{k\in\mathcal{P}^{*}}d\left(\left[K\right] \setminus\mathcal{P}^{*},k\right)\right\}\] \[=\max\left\{\sup_{k\in[K]\setminus\mathcal{P}^{*}}\inf_{k^{\prime} \in\mathcal{P}^{*}}\max\left\{0,\min_{\ell\in[L]}\left(M_{\ell}k-M_{\ell}k^{ \prime}\right)\right\},\right.\] \[\left.\qquad\qquad\sup_{k\in\mathcal{P}^{*}}\inf_{k^{\prime} \in[K]\setminus\mathcal{P}^{*}}\max\left\{0,\min_{\ell\in[L]}\left(M_{\ell}k -M_{\ell}k^{\prime}\right)\right\}\right\}\] \[=\max\left\{\sup_{k\in[K]\setminus\mathcal{P}^{*}}\inf_{k^{\prime} \in\mathcal{P}^{*}}\max\left\{0,m(k^{\prime},k)\right\},\right.\] \[\left.\qquad\qquad\sup_{k\in\mathcal{P}^{*}}\inf_{k^{\prime} \in[K]\setminus\mathcal{P}^{*}}\max\left\{0,M(k,k^{\prime})\right\}\right\}\] \[=\sup_{k\in\mathcal{P}^{*}}\inf_{k^{\prime}\in[K]\setminus \mathcal{P}^{*}}\max\left\{0,M(k,k^{\prime})\right\}\,.\]
3. Finally, when there is only a single objective, i.e., \(\left|L\right|=1\) and assuming an unique optimal arm (fairly common assumption in BAI literature), we have: \[d_{\mathrm{P}}\left(\left[K\right]\setminus\mathcal{P}^{*}, \mathcal{P}^{*}\right)\right) =\max\left\{\sup_{k\in[K]\setminus\mathcal{P}^{*}}d\left(k, \mathcal{P}^{*}\right),\sup_{k\in\mathcal{P}^{*}}d\left(\left[K\right] \setminus\mathcal{P}^{*},k\right)\right\}\] \[=\max\left\{\sup_{k\in[K]\setminus k^{*}}\max\left\{0,(\mu_{k}- \mu_{k^{*}})\right\},\right.\] \[\left.\qquad\qquad\sup_{k^{\prime}\in[K]\setminus k^{*}}\max \left\{0,(\mu_{k^{*}}-\mu_{k^{\prime}})\right\}\right\}\] \[=\min_{k^{\prime}\neq k^{*}}\Delta_{k^{\prime}}\,,\] which is exactly the gap for one-dimensional bandit.

Useful Existing Results

**Theorem F.1** (Berge's Maximum Theorem (Berge, 1877)).: _Let \(\mathcal{U}\) and \(\mathcal{V}\) be topological spaces, \(f:\mathcal{U}\times\mathcal{V}\to\mathbb{R}\) and \(C:\mathcal{U}\to\mathcal{V}\) be non-empty compact set for all \(u\in\mathcal{U}\). Then, if \(C\) is continuous at \(u\), \(f^{*}(u)=\max_{v\in C(u)}f(u,v)\) is continuous and \(C^{*}(u)=\{v\in C(u):f^{*}(u)=f(u,v)\}\) is upper-hemicontinuous._

**Theorem F.2** (Donsker-Vardhan Variational Formula (Donsker and Varadhan, 1975)).: _For mutual information \(d_{\text{KL}}\left(P,Q\right)\), we have that:_

\[d_{\text{KL}}\left(P,Q\right)=\sup_{f}\mathbb{E}_{P}\left[f\right]-\ln\mathbb{ E}_{Q}\left[\exp(f)\right]\]

**Lemma F.1** (Peskun Ordering (Peskun, 1973)).: _For any two random variables \(X,Y\) on \(\mathbb{R}^{K}\) the following are equivalent:_

1. \(X\leq_{s}Y\)__
2. _For all_ \(x\in\mathbb{R}^{K},\;\mathbb{P}\left[X\geq x\right]\leq\mathbb{P}\left[Y\geq x\right]\)__
3. _For all non-negative functions_ \(f_{1},f_{2},\ldots,f_{K}\)_, we have that:_ \(\mathbb{E}[\Pi_{i=1}^{K}f_{i}]\leq\mathbb{E}[\Pi_{i=1}^{K}f_{i}]\)__

**Lemma F.2** (Magureanu et al. (2014)).: _For any \(k=1,2,\ldots,K\), let us define \(1\leq t_{k}\leq t\). Then for all \(0\leq C_{k}\leq M_{k}\), we have_

\[\mathbb{P}\left(\cap_{k\in[K]}\left\{\hat{M}_{k,t}\leq C_{k},\;t_{k}\leq N_{k, t}\right\}\right)\leq\exp\left(-\sum_{k\in[K]}t_{k}d_{\text{KL}}\left(C_{k},M_{ k}\right)\right)\,.\]

**Lemma F.3** (Magureanu et al. (2014)).: _Let \(a>0\) and \(K\geq 2\) and \(Z\in\mathbb{R}^{K}\) such that for all \(\xi\in\mathbb{R}_{+}^{K}\) we have:_

\[\mathbb{P}\left(Z\geq\zeta\right)\leq\exp\left(-a\sum_{k\in[K]}\zeta_{k}\right)\,.\]

_Then, for all \(\rho\geq\frac{K}{a}\in\mathbb{R}_{+}\), we have_

\[\mathbb{P}\left(\sum_{k\in[K]}Z_{k}\geq\rho\right)\leq

### NeurIPS Paper Checklist

The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: **The papers not including the checklist will be desk rejected.** The checklist should follow the references and precede the (optional) supplemental material. The checklist does NOT count towards the page limit.

Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist:

* You should answer [Yes], [No], or [NA].
* [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.
* Please provide a short (1-2 sentence) justification right after your answer (even for NA).

**The checklist answers are an integral part of your paper submission.** They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper.

The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a proper justification is given (e.g., "error bars are not reported because it would be too computationally expensive" or "we were unable to find the license for the dataset we used"). In general, answering "[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found.

IMPORTANT, please:

* **Delete this instruction block, but keep the section heading "NeurIPS paper checklist",**
* **Keep the checklist subsection headings, questions/answers and guidelines below.**
* **Do not modify the questions and only use the provided macros for your answers**.

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification:Guidelines:

* The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.
* The authors are encouraged to create a separate "Limitations" section in their paper.
* The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.
* The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.
* The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.
* The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.
* If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.
* While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes] Justification: Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: Guidelines: * The answer NA means that the paper does not include experiments.

* If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.
* If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.
* Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.
* While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] Justification: Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). ** Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors). * It should be clear whether the error bar is the standard deviation or the standard error of the mean. * It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. * For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). * If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. ** The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.
* The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. * The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. * The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. * If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper poses no such risks.

* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. * If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification:Guidelines:

* The answer NA means that the paper does not involve crowdsourcing nor research with humansubjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.