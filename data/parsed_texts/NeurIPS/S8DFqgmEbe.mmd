# Learning nonparametric latent causal graphs

with unknown interventions

Yibo Jiang

University of Chicago

yiboj@uchicago.edu

&Bryon Aragam

University of Chicago

bryon@chicagobooth.edu

###### Abstract

We establish conditions under which latent causal graphs are nonparametrically identifiable and can be reconstructed from unknown interventions in the latent space. Our primary focus is the identification of the latent structure in measurement models without parametric assumptions such as linearity or Gaussianity. Moreover, we do not assume the number of hidden variables is known, and we show that at most one unknown intervention per hidden variable is needed. This extends a recent line of work on learning causal representations from observations and interventions. The proofs are constructive and introduce two new graphical concepts--_imaginary subsets_ and _isolated edges_--that may be useful in their own right. As a matter of independent interest, the proofs also involve a novel characterization of the limits of edge orientations within the equivalence class of DAGs induced by _unknown_ interventions. These are the first results to characterize the conditions under which causal representations are identifiable without making any parametric assumptions in a general setting with unknown interventions and without faithfulness.

## 1 Introduction

Among the many challenges in modern machine learning and artificial intelligence, learning and reasoning about causes and effects from data remains a key challenge. In practice, one of the hurdles that must be overcome is that we often do not have direct access to measurements on causally meaningful variables, and instead can only measure primitive, indirect measurements such as pixel intensities in vision, gene expression values in biology, letters and words in language, or frequency signals in audio. In these applications, it is necessary to first learn representations with meaningful causal signals, a problem known as causal representation learning [52]. Besides learning representations or features of data, we are also interested in understanding what happens when we intervene on these learned features, which is essential for causal reasoning. As such, broadly speaking, causal representation learning can be broken down into two steps: (1) learning high-level features from raw data and (2) learning causal relations between these features.

Given the proliferation of recent work of identifying latent representations in the observational setting [2, 13, 26, 29, 30, 32, 38, 40, 43, 44, 45, 51, 55, 63, 70, 71, 73, 43, 46, 70, 71, 73], in this paper we consider the case of interventions. Data arising from interventions opens the door for a causal interpretation of the learned representations, which is often described by a directed acyclic graph (DAG). This setting raises new challenges, namely that the interventions are both _latent_ and _unknown_. Moreover, in practical applications, flexible deep neural networks are used to learn nonlinear representations of the data, which necessitates the consideration of nonparametric assumptions. Motivated by these challenges, we seek to answer the following important question:

_Given a list of latent, unknown interventions, when is it possible to identify the underlying (latent) causal relationships without making parametric assumptions?_In particular, we focus on the problem of learning structure [47; 56], and leave the problem of learning the representations themselves to existing work, since one can then use deep latent variable models to infer the latent distributions from the latent structure, which is well-studied [e.g. 20; 28; 35; 46; 64; 65]. We adopt the measurement model [36; 43; 54] where there are no direct causal edges between observed covariates. This model has been used extensively to model causal representations [e.g. 1; 25; 32; 57; 61; 66; 67; 68]. Surprisingly, we show that it is possible to learn latent causal structure without learning the distributions of latent representations, unlike [1; 32; 57; 61]. Furthermore, unlike [1; 57; 61], we do not impose any parametric assumptions: We allow for general noisy, nonlinear transformations between latents and observed as well as arbitrary nonlinear relationships between the latents, which makes the problem significantly harder. Part of our motivation is to better understand the _minimal_ assumptions for learning causal structure from unknown interventions.

### Contributions

Our main contribution is a set of nonparametric assumptions under which the entire latent causal graph is identifiable given unknown interventions in the latent space, up to edges that we show cannot be oriented without additional assumptions (in a similar sense to reversible edges in a Markov equivalence class). To the best of our knowledge, structure identification in a nonparametric setting given _unknown_ and _latent_ interventions has not been considered in-depth in the literature.

More specifically, we make the following contributions:

1. We introduce two new graphical concepts--_imaginary subsets_ (Definition 3.2) and _isolated edges_ (Definition 3.3)--that are key to identifiability and orientability of edges in the true causal graph. These are illustrated in Figure 1 and discussed in detail in Sections 4-5.
2. We combine these concepts with nonparametric, graphical assumptions to show that the causal graph is identifiable up to isolated edges (Theorem 3.4).
3. We show the limitation of edge orientations using CI relations alone under unknown interventions even when there are no latent variables (Theorem 5.3).

The implications of these results are twofold: 1) It _is_ possible to learn the entire DAG without making parametric assumptions, albeit at the cost of nontrivial graphical assumptions, and 2) If we wish to relax these graphical conditions, alternative assumptions are needed. That is, in Appendix C (Examples 3-6), we prove that our assumptions are nearly necessary in the sense that if any individual assumption is relaxed, then identifiability fails. Figure 1 illustrates our graphical conditions in a simple example that will be referred back to throughout the paper. Finally, we verify our theoretical results in a simulation study.

### Related work

Learning the Markov equivalence class of causal graphs from observational distributions is a well-researched area [56]. Although our focus is on learning measurement models with interventions, we note that the observational case has been extensively studied [25; 32; 36; 43; 54; 66; 67; 68].

Figure 1: Illustration of the main concepts used in this paper. \(G=G_{B}\cup G_{H}\) is a measurement model with bipartite DAG \(G_{B}\) (blue edges) and latent DAG \(G_{H}\) (red edges), \(\{X_{5},X_{6}\}\) is an imaginary subset, \(\{X_{1},X_{2}\}\) is a replaceable subset while \(\{X_{1},X_{2},X_{5}\}\) is a non-replaceable subset, and \(H_{2}\to H_{4}\) is an isolated edge. In fact, \(\{X_{5},X_{6}\}\) is a non-replaceable imaginary subset. This is also not a maximal measurement model although it still illustrates the main concepts. For completeness, the undirected dependency graphs under different interventional targets are provided in Figure 2.

Intervention design.In the classical setting of known interventions on observables, Eberhardt et al. [16] show that for causal graphs with more than \(n>2\) variables, \(n-1\) single node interventions are sufficient, and in the worst case, they are also necessary. Kocaoglu et al. [34] consider intervention design in the presence of latents, and propose efficient algorithms. Hauser and Buhlmann [24] derive a notion of interventional equivalence for hard/structural interventions, while Tian and Pearl [60] and Yang et al. [69] do the same for soft/parametric interventions.

Unknown interventions.There has been growing literature on learning under unknown interventions recently as well. A recent line of work studies soft interventions where the unknown interventional targets are observed [7; 15; 19; 21; 27; 33; 49; 58]. In particular, Jaber et al. [27] consider the case where the causal graph consists of measured and unmeasured latent variables, but the intervention targets, though unknown, are from measured variables. Squires et al. [58] assume no hidden variables and use direct \(\mathcal{I}\)-faithfulness to identify the unknown intervention targets. Perry et al. [49] utilize independent causal mechanisms as a key assumption and measure the number of mechanism changes to identify the true DAG. Castelletti and Peluso [7], Eaton and Murphy [15], and Faria et al. [19] propose Bayesian methods to learn DAGs under unknown interventions.

Latent interventions.A very different setting arises when the interventions are both unknown _and_ latent. Perhaps the earliest approach to this general setting is _causal feature learning_, introduced in [8; 9]. More closely related to our paper are Liu et al. [42], Squires et al. [57], and Varici et al. [61], which consider unknown interventions on latent variables under parametric assumptions. Squires et al. [57] assume hard interventions on latent variables under a linear model. Varici et al. [61] allow nonlinearities in the latent space with a linear map between hidden and observed, using the score function for identification. Liu et al. [42] assume the existence of an auxiliary observed variable \(u\) that modulates the variant weights among latent causal variables where the setup is similar to that of iVAE [31]. Ahuja et al. [1] assume a polynomial decoder and the intervention target on the latent is known. Brehmer et al. [4] consider the weakly supervised setting with paired pre- and post-intervention samples, where the interventions are random and unknown. Lippe et al. [41], on the other hand, work with latent interventions on temporal sequences.

While our work was under review, we were made aware of several concurrent works that study the same problem under different assumptions [5; 37; 72].

## 2 Preliminaries

Our basic setup is a standard graphical model with both observed and latent variables. Appendix A contains a comprehensive overview of all the necessary formal graphical concepts; we briefly outline the basics here. Let \(G=(V,E)\) be a directed acyclic graph (DAG) with \(V=(X,H)\) where \(X\) denotes the observed part and \(H\) denotes the hidden or latent part. Define \(n:=|X|\) and \(m:=|H|\). For a given node \(v\), we use standard notation such as \(\mathrm{pa}(v)\), \(\mathrm{ch}(v)\), \(\mathrm{an}(v)\) and \(\mathrm{de}(v)\) for parents, children, ancestors, and descendants respectively. Given a subset \(V^{\prime}\subseteq V\), \(\mathrm{pa}(V^{\prime})\coloneqq\cup_{v\in V^{\prime}}\mathrm{pa}(v)\), given two subsets \(A,B\subseteq V\), \(\mathrm{pa}_{B}(A)=\mathrm{pa}(A)\cap B\) and given a subgraph \(G^{\prime}\subseteq G\), \(\mathrm{pa}_{G^{\prime}}(V^{\prime})\coloneqq\mathrm{pa}(V^{\prime})\cap G^{\prime}\). Similar notation can be defined for children, ancestors, and descendants. For disjoint subsets \(A,B,C\subseteq V\), define \(\mathrm{d}\text{-}\mathrm{sep}_{G}(AB\,|\,C)\) to mean that \(A,B\) are \(d\)-separated by \(C\) in the graph \(G\). A DAG encodes a set of \(d\)-separation relations, defined by

\[\mathcal{T}_{V^{\prime}}(G)=\{\langle A,B,C\rangle:\mathrm{d}\text{-}\mathrm{ sep}_{G}(AB\,|\,C)\text{ for disjoint subsets }A,B,C\subseteq V^{\prime}\}\]

where \(V^{\prime}\subseteq V\). For simplicity, we write \(\mathcal{T}(G)=\mathcal{T}_{V}(G)\). Recall that two DAGs \(G_{1}\) and \(G_{2}\) are Markov equivalent if \(\mathcal{T}(G_{1})=\mathcal{T}(G_{2})\). The Markov equivalence relations define a set of equivalence classes of DAGs called the Markov equivalence class (MEC).

Every distribution \(P\) on \(V\) defines a collection of conditional independence (CI) relations:

\[\mathcal{T}_{V^{\prime}}(P)=\{\langle A,B,C\rangle:A\perp\!\!\!\perp B\,|\,C \text{ in }P\text{ for disjoint subsets }A,B,C\subseteq V^{\prime}\}\]

where \(V^{\prime}\subseteq V\), and as before \(\mathcal{T}(P)=\mathcal{T}_{V}(P)\). We denote the marginal of \(V^{\prime}\) by \(P_{V^{\prime}}\).

_Remark 2.1_.: Throughout the paper, _unconditional_ (i.e. marginal) independence and \(d\)-separation will play a prominent role. Thus, unless otherwise stated, when we say \(A\) and \(B\) are dependent or \(d\)-connected, or that there is an active path between \(A\) and \(B\), without explicit mention of the separating set \(C\), we consider it implies that \(C=\emptyset\).

Interventions.For background, Eberhardt and Scheines [17] provides a detailed account of the different types of interventions in causal systems. In this paper, we consider _hard_ (or _structural_) interventions on a _single node_. Let \(I\subseteq V\) be a set of intervention targets. The **intervention graph** of \(G\) is the DAG \(G^{(I)}=(V,E^{(I)})\), where \(E^{I}\coloneqq\{(a,b)|(a,b)\in E,b\notin I\}\). Similarly, let \(P^{(I)}\) be the interventional distribution. We further restrict intervention targets to be latent variables in this paper (\(I\subseteq H\)), which necessitates considering _unknown_ intervention targets. Thus, we have access to a family of intervention targets \(\mathcal{I}=\{I_{0},...,I_{k}\}\) with \(|I_{j}|\leq 1\). By convention, we let \(I_{0}=\emptyset\) so that \(G^{(I_{0})}=G\) and \(P^{(I_{0})}=P\) is the observational distribution.

A subtle but important point is that different interventional distributions may be the same, i.e. \(P^{(I)}_{X}=P^{(I^{\prime})}_{X}\) but \(I\neq I^{\prime}\). This implies, in particular, that the number of latent variables is unknown (see Remark C.1).

**Example 1**.: Known and unknown interventions have different implications in terms of edge orientations. To see this, consider the unoriented edge between two variables \(X_{1}\) and \(X_{2}\). If we know the intervention target is \(\{X_{1}\}\) and we observe that \(X_{1}\) and \(X_{2}\) become independent under this intervention, then we know \(X_{1}\gets X_{2}\). However, if we do not know the intervention target is \(X_{1}\) and we observe the same independence between \(X_{1}\) and \(X_{2}\), then it is possible the true DAG is \(X_{1}\gets X_{2}\) with intervention target \(X_{1}\) or the true DAG is \(X_{1}\to X_{2}\) and the intervention target \(X_{2}\).

Measurement models.Our main results apply to so-called _measurement models_[54, 36] in which every observed variable only has incoming edges and no outgoing edges (i.e. \(\mathrm{ch}(X)=\emptyset\)). This assumption cleanly encapsulates the problem of reconstructing latent causal structure and captures relevant applications where the relationships between raw observations are less relevant than causal features and is a standard model adopted in prior work [e.g. 25, 66, 67, 68, 43].

For any measurement model, \(G\) decomposes as the union of two subgraphs \(G=G_{B}\cup G_{H}\) where \(G_{B}\) is a directed, bipartite graph pointing from \(H\) to \(X\), and \(G_{H}\) is a DAG over the latent variables \(H\). See Figure 1.

Following Markham and Grosse-Wentrup [43], for any distribution \(P\) over \(V\), define the undirected dependency graph (UDG), denoted \(D(P)\), to be the undirected graph over \(X\) in which there is an edge between \(X_{i}\) and \(X_{j}\) if and only if they are marginally dependent (i.e. given the empty set, cf. Remark 2.1). Clearly, \(D(P)\) is easily constructed from \(\mathcal{T}_{X}(P)\) by checking if each pair of observed variables is marginally independent or not.

Figure 2: UDG under different intervention targets for Figure 1.

Main result

We can now state our goal formally as follows:

_Given a set of interventional distributions \(\{P_{X}^{(I)}\}_{I\in\mathcal{I}}\), can we recover \(G_{B}\) and \(G_{H}\)?_

Here, \(\{P_{X}^{(I)}\}_{I\in\mathcal{I}}\) is a _set_ and not a tuple: If two different interventions lead to the same interventional distributions, then we only observe one copy of \(P_{X}^{(I)}\) in this set. As a result, we do not know the number of latent variables (see Remark C.1); we show how this is learned in the proof. Of course, in practice, we only have sample access to \(P_{X}^{(I)}\). In this paper, we focus on identifiability and leave estimation from finite samples to future work.

_Remark 3.1_.: Learning from the tuple \((P_{X}^{(I)})_{I\in\mathcal{I}}\) is easier than learning from the set \(\{P_{X}^{(I)}\}_{I\in\mathcal{I}}\), since one can trivially reduce the tuple problem to a set problem by removing duplicates. Thus, there is no loss of generality in our setting.

### Assumptions

To solve this problem, we make the following assumptions:

**Assumption 1** (Graphical conditions).: The DAG \(G\) satisfies the following conditions for every \(I\in\mathcal{I}\) and pair of hidden variables \(H_{i}\neq H_{j}\):

* \(P^{(I)}\) is Markov with respect to \(G^{(I)}\), i.e. \(\mathcal{T}(G^{(I)})\subseteq\mathcal{T}(P^{(I)})\).
* \(X_{i}\perp_{P^{(I)}}X_{j}\implies\mathrm{d}\mathrm{-sep}_{G^{(I)}}\{X_{j} \}\,|\,\emptyset\rangle\), i.e. marginal independence in \(X\) implies \(d\)-separation.
* \(\mathrm{d}\mathrm{-sep}_{G^{(I)}}\{\{H_{i}\}\{H_{j}\}\,|\,\emptyset\rangle\implies\text{ there exists }X_{i}\in\mathrm{ch}_{X}(H_{i})\text{ and }X_{j}\in\mathrm{ch}_{X}(H_{j})\text{ such that } \mathrm{d}\mathrm{-sep}_{G^{(I)}}\{\{X_{i}\}\{X_{j}\}\,|\,\emptyset\rangle.\]

**Assumption 2** (Complete family of targets).: \(\mathcal{I}=\{\emptyset,\{H_{1}\},\ldots,\{H_{m}\}\}\).

Intuitively, the graphical conditions in Assumption 1 ensure that hidden variables and their dependencies have detectable signatures in observed distributions. Of course, Assumption 1(a) is just the usual Markov assumption that relates the graph \(G\) to the distribution \(P\). Assumption 1(b) requires that marginal dependencies of observed variables are reflected in the underlying graph, and is much weaker than similar conditions in the graphical modeling literature. Assumption 2 ensures that the effect of each hidden variable is measured. Furthermore, with the exception of Assumption 1(c), which arises from our fully nonparametric setup, each of these assumptions has appeared previously in the literature [1, 14, 18, 32, 43, 48, 53, 59, 61]. See also Remark 4.3. A detailed discussion of these assumptions is deferred to Appendix C. In particular, with the exception of the Markov property Assumption 1(a), we give counterexamples to show that when any _one_ of these assumptions is violated (but the rest continue to hold), there are two graphs that have the same set of observed distributions under different interventions.

_Remark 3.2_.: It is worth noting that the well-known subset condition [18, 32, 48] is implied by Assumption 1 and Assumption 2 (Lemma C.1 in Appendix C.4). However, this arises from the fact that Assumption 2 is needed for _exact_ recovery. If the main objective is instead partial recovery and Assumption 2 is relaxed, then one needs to additionally assume the subset condition. See Appendix C.4 for details.

_Remark 3.3_.: Assumption 1 and Assumption 2 also generalize the well-known _pure child_ condition, which is widely used and has applications in NLP and topic modeling [e.g. 3, 6, 45, 66]; see also Section 4.3. It is easy to see that the existence of pure children for each latent implies Assumption 1(c).

### Maximal measurement model

Under Assumptions 1-2, two different measurement models can still induce exactly the same interventional distributions of observed variables. Even without interventions, there may be ambiguities, an observation that dates back to [50] in the definition of a maximal ancestral graph and was more recently used in [32]. Example 6 in Appendix C.5 gives a concrete example where two measurement models share the same set of observed distributions under interventions. Fortunately, the ambiguity is limited: There is always a _maximal_ measurement model that encodes as many non-redundant dependencies as possible, as defined below:1

Footnote 1: Here, non-redundant means that the edge encodes a genuine dependence. In other words, adding any more edges would change the underlying model.

**Definition 3.1** (Maximal measurement model).: A measurement model \(G\) is called **maximal** if it satisfies Assumption 1 and the following two conditions:

1. \(\mathrm{pa}(X_{i})\neq\emptyset\) for all \(i\in[n]\),
2. There is no DAG \(G^{\prime}=(V,E^{\prime})\) also satisfying Assumption 1 such that, \(\{\mathcal{T}_{X}(G^{(I)})\}_{I\in\mathcal{I}}=\{\mathcal{T}_{X}(G^{\prime(I) })\}_{I\in\mathcal{I}}\), and \(E\subsetneq E^{\prime}\).

Our definition of maximality here mirrors the concept of maximality introduced in [50], extended to include interventions. Throughout the paper, if not mentioned explicitly, the measurement model is considered to be maximal. More discussion on maximality is provided in Appendix C.5.

### Imaginary subsets and isolated edges

To identify \(G\), we will break the problem into two phases: First, we learn the bipartite graph \(G_{B}\), and then we use this to learn the latent DAG \(G_{H}\). Each of these phases introduces a new graphical concept, which are defined here.

#### 3.3.1 Imaginary subsets

Latent variables induce cliques in the UDG \(D(P_{X}^{(I)})\), which provide a way to identify the existence of a latent [43]. Unfortunately, the identification of \(G_{B}\) is complicated by _imaginary subsets_: Intuitively, imaginary subsets are ambiguous subsets of observed variables that may not be the children of a single latent. Given \(D(P_{X}^{(I)})\), let \(\Omega_{P}^{(I)}\) be the set of maximal cliques in \(D(P_{X}^{(I)})\). We also let \(\Omega=\cup_{I\in\mathcal{I}}\Omega_{P}^{(I)}\).

**Definition 3.2** (Imaginary subsets).: A subset \(X^{\prime}\subseteq X\) is a **valid subset** if for all \(I\in\mathcal{I}\), there exists a maximal clique \(C\in\Omega_{P}^{(I)}\) such that \(X^{\prime}\subseteq C\). A valid subset is **maximal** if there is no other valid subset \(X^{\prime\prime}\) such that \(X^{\prime}\subsetneq X^{\prime\prime}\subseteq C\) for every maximal clique \(C\in\Omega\) containing \(X^{\prime}\). A maximal valid subset \(X^{\prime}\subseteq X\) is **imaginary** if there is no hidden variable \(H_{i}\) such that \(X^{\prime}\subseteq\mathrm{ch}_{X}(H_{i})\).

Imaginary subsets (more precisely, the lack thereof) are crucial to the identification of \(G_{B}\), although at first glance they may seem a bit abstract. Indeed, handling imaginary subsets turns out to be a nontrivial issue, so we defer further discussion of this concept to Section 4, where several examples and intuitions are given.

#### 3.3.2 Isolated edges

Once we identify \(G_{B}\), we'd like to identify \(G_{H}\). Unfortunately, Example 1 gave an example where unknown interventions are incapable of orienting an edge using CI information only. This type of edge can be identified more broadly as follows:

**Definition 3.3** (Isolated edge).: We say an edge \(x\to y\) is **isolated** if \(x\) does not have any parent (\(\mathrm{pa}(x)=\emptyset\)) and \(y\) only has \(x\) as its parent (\(\mathrm{pa}(y)=\{x\}\)).

The importance of isolated edges is that these are precisely the edges that cannot be oriented using CI information only (see Section 5.2).

### Identifiability of causal graph

We can now state the main result of this paper:

**Theorem 3.4**.: _Let \(G\) be a maximal measurement model satisfying Assumption 1. Then, given a complete family of interventions (Assumption 2), the following statements are true:_

1. _If there are no imaginary subsets (Definition_ 3.2_), then_ \(G\) _is identifiable from_ \(\{P^{(I)}\}_{I\in\mathcal{I}}\) _up to isolated edges (Definition_ 3.3_) in_ \(G_{H}\)2. Isolated edges in \(G_{H}\) cannot be oriented using CI information only.

In particular, the unknown number of latents \(m\) is also identified.

In other words, \(G\) can be maximally identified in the sense that any edge in the latent space that isn't oriented cannot be oriented from the given list of interventions using CI information only: Additional assumptions are needed (e.g. conditional invariances and direct \(\mathcal{I}\)-faithfulness as in [58]).

We devote a significant effort in the sequel to interpreting and understanding the assumption of no imaginary subsets, which turns out to be subtle and complicated. Thus, in Section 4, we provide several additional sufficient conditions as well as examples of imaginary subsets to help build intuition for this condition.

The proof of this result is broken down into two main steps:

1. Identifying the bipartite graph \(G_{B}\) (See Section 4);
2. Identifying the skeleton of the latent DAG \(G_{H}\) and orienting the edges in \(G_{H}\) (See Section 5);

Sections 4-5 outline the basic ideas behind these constructions. As the ideas are independently interesting and may be more broadly useful beyond just proving Theorem 3.4, we treat these independently.

## 4 Imaginary subsets and the bipartite graph

Theorem 3.4 indicates that as long as there are no imaginary subsets, \(G_{B}\) can be identified. In this section, we show how identifiability of \(G_{B}\) is related to the absence of imaginary subsets (Definition 3.2), and provide several different conditions for this to hold. Throughout this section, we assume as in Theorem 3.4 that \(G=G_{B}\cup G_{H}\) is a maximal measurement model satisfying Assumption 1, and that Assumption 2 also holds.

### Identifying \(G_{b}\) with no imaginary subsets

The following proposition explains why maximal valid subsets (Definition 3.2) are useful:

**Proposition 4.1**.: _For any hidden variable \(H_{i}\), \(\mathrm{ch}_{X}(H_{i})\) is a maximal valid subset._

Proposition 4.1 suggests that we assign a latent variable to each maximal valid subset. However, not every maximal valid subset corresponds to a single latent variable: For example, in Figure 1, \(\{X_{5},X_{6}\}\) is a maximal valid subset that does not correspond to any hidden variable, and hence is an imaginary subset. Unfortunately, these examples are not pathological; this turns out to be endemic and must be resolved carefully.

The first issue is that a maximal valid subset can be contained in another maximal valid subset. An example is \(\{X_{1},X_{2}\}\subset\{X_{1},X_{2},X_{5}\}\) in Figure 1 (see also Example 7 in Appendix D). This typically happens when two such subsets appear in different cliques, which does not violate our definition of maximal valid subsets:

**Definition 4.2** (Replaceable subset).: A maximal valid subset \(X^{\prime}\subseteq X\) is **replaceable** if there exists another maximal valid subset \(X^{\prime\prime}\) such that \(X^{\prime}\subsetneq X^{\prime\prime}\).

An example of a replaceable subset is in Figure 1. The advantage of replaceable subsets is that they can be identified and ignored. In particular, any replaceable imaginary subset is a non-issue. Thus, we have the following important result, which is proved in Appendix D.1:

**Theorem 4.3**.: _If there are no non-replaceable imaginary subsets, then a subset \(X^{\prime}\) is a non-replaceable maximal valid subset if and only if there exists a hidden variable \(H_{i}\) such that \(\mathrm{ch}_{X}(H_{i})=X^{\prime}\). In particular, it follows that \(G_{B}\) is identifiable._

Since one can check if \(X^{\prime}\) is replaceable, one might hope that simply eliminating replaceable subsets fixes the problem. Unfortunately, this is not enough: The devil is _non-replaceable imaginary subsets_; i.e. imaginary subsets that cannot be identified from the data. Moreover, non-replaceable imaginary subsets are a genuine phenomenon (\(\{X_{5},X_{6}\}\) in Figure 1). Thus, as stated, Theorem 4.3 has two drawbacks:1. Checking if non-replaceable imaginary subsets exist and getting rid of them is not easy; and
2. Even when there are imaginary subsets, \(G_{B}\) may still be identifiable.

Given the difficulties with non-replaceable imaginary subsets, we will provide two sufficient conditions to guarantee there are no imaginary subsets (Section 4.2) and also show how one can identify \(G_{B}\) even when there are imaginary subsets (Section 4.3).

### Sufficient conditions for no imaginary subsets

In this section, we provide two additional sufficient conditions to guarantee there are no imaginary subsets: The first--single source node--is intuitive and interpretable, but cannot always be checked. The second--no fractured subsets--is less intuitive but can be explicitly checked.

Single latent source.A latent source is any latent variable such that \(\mathrm{pa}(H_{i})=\emptyset\). We can show that imaginary subsets do not exist if there is only one latent source. This still allows for arbitrarily many hidden variables \(m=|H|>1\) (i.e. the descendants of the latent source in \(G_{H}\)).

**Theorem 4.4**.: _Under Assumptions 1-2, if \(G_{H}\) has one latent source, there are no imaginary subsets._

Therefore, with only one latent source node, we can recover the bipartite graph by Theorem 4.3.

Fractured subset condition.A necessary condition for an imaginary subset is that the subset is _fractured_. The definition is somewhat complicated, but worth it since fractured subsets can be identified and checked in practice:

**Definition 4.5** (Fractured subset).: Given a collection of maximal valid subsets \(\mathcal{S}\), a clique \(C\) is called **shattered** by \(\mathcal{S}\) if there exists a subset \(\mathcal{S}^{\prime}\subseteq\mathcal{S}\) such that \(\cup\mathcal{S}^{\prime}=C\). A collection of maximal valid subsets \(\{S_{i}\}_{i=1}^{k}\) is **complete** if for every intervention target \(I\in\mathcal{I}\), all shattered cliques in \(D(P^{(I)})\) form an edge cover of \(D(P^{I})\). A maximal valid subset \(X^{\prime}\subseteq X\) is **fractured** if there exists a complete collection \(\{S_{i}\}_{i=1}^{k}\) such that \(S_{i}\not\subseteq X^{\prime}\) for all \(S_{i}\).

Intuitively, a fractured subset provides redundant information as every connection between nodes in the fractured subset can be explained by other maximal valid subsets. The aforementioned necessity is shown by the following lemma:

**Lemma 4.6**.: _If a subset \(X^{\prime}\subseteq X\) is imaginary, then \(X^{\prime}\) is also fractured._

Therefore, we have the following identifiability corollary:

**Corollary 4.7**.: _Under Assumptions 1-2 and if there are no fractured subsets, then \(G_{B}\) is identifiable. Furthermore, the absence of fractured subsets can be checked and verified, and if it fails, a certificate is provided._

_Remark 4.1_.: Technically, we only need the condition that there are no _non-replaceable_ fractured subsets.

_Remark 4.2_.: One might suggest getting rid of all fractured subsets, however, even a non-imaginary subset can be a fractured subset (Example 9 in Appendix D). The no fractured subset condition naively captures such ambiguities of imaginary subsets, but is overkill. In fact, it is still possible to have identifiability with fractured subsets under different assumptions (Theorem 4.4, Theorem 4.8).

### Identifying \(G_{b}\) when there are imaginary subsets

Finally, we show that under the well-known pure child assumption, \(G_{B}\) can be identified even when there are imaginary subsets. The pure child assumption has been made in many existing works [e.g. 3, 6, 45, 66], typically along with additional parametric assumptions.

**Assumption 3** (Pure child).: For every \(H_{i}\in H,\) there exists at least one \(X_{i}\in X\) with \(\mathrm{pa}(X_{i})=\{H_{i}\}\), i.e. \(X_{i}\) only has one parent and that parent is \(H_{i}\).

_Remark 4.3_.: Assumption 1(c) is a much weaker assumption than Assumption 3. In particular, if a measurement model satisfies Assumption 3, it also satisfies Assumption 1(c).

**Theorem 4.8**.: _Under Assumptions 1-3, the complete collection (cf. Definition 4.5) with the smallest cardinality is exactly \(\{\mathrm{ch}_{X}(H_{i})\}_{i=1}^{m}\) and thus \(G_{B}\) can be identified._

_Remark 4.4_.: Under Assumption 3, there still could be imaginary subsets (Example 11 in Appendix D).

Identifying the latent DAG

Once we have learned the bipartite graph \(G_{B}\), the next step is to learn the DAG \(G_{H}\) over the latent variables \(H\). Learning the skeleton of \(G_{H}\) turns out to be straightforward: Assumption 1(b-c) suggest that two hidden variables \(H_{i}\) and \(H_{j}\) are \(d\)-separated if and only if \(\operatorname{ch}_{X}(H_{i})\) and \(\operatorname{ch}_{X}(H_{j})\) are in different cliques (Lemma E.2). Therefore, the idea is to use unconditional \(d\)-separations of latent variables under interventions for identification which is harder than having access to all conditional \(d\)-separations in the fully observational case (see Appendix E for details).

_Remark 5.1_.: In fact, we do not have access to full conditional \(d\)-separation statements of latents because observed variables are descendants of latent nodes.

The more interesting question is how to orient the edges with _unknown_ interventions. Unlike known interventions, edge orientation might not always be possible even when there are no latent variables as shown in Example 1. At the same time, it is sometimes possible as demonstrated by Example 13 in Appendix F. This raises the question of which edges provably _cannot_ be oriented under our assumptions: It turns out these are precisely the _isolated_ edges (Definition 3.3).

**Theorem 5.1**.: _Let \(G\) be a maximal measurement model satisfying Assumption 1 and assume we are given a complete family of interventions (Assumption 2) as well as the bipartite DAG \(G_{B}\). Then the true latent DAG \(G_{H}\) is identifiable up to isolated edges. Moreover, isolated edges cannot be oriented without making additional assumptions._

Thus, as long as we identify \(G_{B}\) (cf. Section 4), we can identify \(G_{H}\) up to isolated edges.

_Remark 5.2_.: The proof of Theorem 5.1 in Appendix G provides a constructive algorithm. Pseudocode for the overall approach can be found in Algorithm 2 in Appendix G.

In fact, the non-orientability of isolated edges is not restricted to latent edges or even the measurement model; this fact applies to general, fully (or partially) observed DAGs.

### Isolated equivalence

We now introduce an equivalence relation on DAGs that refines the notion of Markov equivalence to account for the extra information conveyed by unknown interventions. Unlike known interventions, which suffice to identify the entire DAG, Example 1 shows that unknown interventions carry strictly less information vs. known interventions. _These definitions are purely graphical_ and can be studied in their own right.

For this result, we do not need the measurement model assumptions nor Assumption 1-2. So, for now, consider the case of an arbitrary, fully observed DAG (i.e. \(H=\emptyset\)). By the transformational properties of MEC [12], we know that two Markov equivalent DAGs can be transformed into one another by a sequence of covered edge reversals (Definition B.3). Similarly, let's define the following:

**Definition 5.2**.: (Isolated equivalence class) Two DAGs \(G_{1}\) and \(G_{2}\) are isolated equivalent, denoted \(G_{1}\sim_{E}G_{2}\), if there exists a sequence of isolated edge reversals to transform one into another.

An example of two isolated-equivalent DAGs can be obtained from Figure 1: Since the latent edge \(H_{2}\to H_{4}\) is isolated, reversing it yields a DAG that is isolated equivalent to \(G\).

_Remark 5.3_.: Despite what the name might suggest, an isolated edge \(X\to Y\) does not mean that \(X\) and \(Y\) are disconnected from all other nodes. In fact, \(X\) and \(Y\) can still have outgoing edges (Definition 3.3) and \(X\to Y\) is not just an isolated connected component. Therefore, the IEC is not just a union of disjoint edges.

_Remark 5.4_.: Since an isolated edge is covered by definition, \(G_{1}\) and \(G_{2}\) are Markov equivalent if they are isolated equivalent. It is easy to check that isolated equivalence is an equivalence relation. _Therefore, the isolated equivalence class (IEC) is a finer partition of the Markov equivalence class (MEC)_. An IEC can and often will be a singleton (i.e. a DAG that is not isolated equivalent to any other DAG in the MEC).

_Remark 5.5_.: This is also different from the interventional Markov equivalence class where the intervention target is known [69].

### (Non-)Orientability of isolated edges

The value of isolated equivalence is that it identifies which DAGs cannot be distinguished (from CI information alone) using unknown interventions. This is formalized in the following theorem:

**Theorem 5.3**.: _Suppose \(G_{1}\) and \(G_{2}\) are in the same IEC. If the tuple \((G_{1},\mathcal{I}_{1})\) induces \(\{\mathcal{T}(G_{1}^{(I)})\}_{I\in\mathcal{I}_{1}}\), then there exists a family of interventional targets \(\mathcal{I}_{2}\) (possibly the same as \(\mathcal{I}_{1}\)) such that the tuple \((G_{2},\mathcal{I}_{2})\) also induces \(\{\mathcal{T}(G_{1}^{(I)})\}_{I\in\mathcal{I}_{1}}\)._

Theorem 5.3 shows that it is impossible to distinguish DAGs in the same IEC by looking at \(d\)-separations only. While it is impossible to distinguish within an IEC, it is possible to do so between different IECs (see Theorem F.7 in the appendix). Together, Theorems 5.3 and F.7 establish that isolated edges are precisely those edges that cannot be oriented by unknown interventions under our assumptions. This does not imply, of course, that this is impossible in practice: We simply need to impose additional assumptions. For example, one could use conditional invariances to improve the identifiability of edge orientations under additional assumptions like direct \(\mathcal{I}\)-faithfulness [58], which we have not assumed in this paper.

## 6 Experiments

We test the theoretical results on simulated datasets under two settings: pure child and single latent source. Because this paper is primarily theoretical, the purpose of experiments is simply to verify the theory. In particular, for single latent source experiments, we still adopt the pure child structure but we explicitly test our identification strategy - no imaginary subset (Theorem 4.4). We generate random causal graphs under different settings of \(m\), \(n\). _We do not enforce Assumption 1 (b) nor maximality (Definition 3.1)_. For each variable \(V_{i}\) in the causal graph, the structural equation is simply \(V_{i}\leftarrow\sum_{V_{j}\in\text{pa}(V_{i})}f(V_{j})+\epsilon\), where \(\epsilon\) is Gaussian noise, and \(f\) is a nonlinear function. We set \(f\) to be a quadratic function. To test independence, we adopt Chatterjee's coefficient [10]. The metric we use is the Structural Hamming Distance (SHD) between the estimated DAG and the true DAG. The results show that even without the graphical assumptions, our method can be effective in recovering the DAG for nonlinear models.

## 7 Conclusion

Using unknown, latent interventions, we have provided nonparametric identifiability results for a class of graphical measurement models that are commonly used to learn causal representations. For this, we introduced two important graphical concepts: _Imaginary subsets_ and _isolated edges_. Our proofs are constructive and can be implemented on finite samples. Obvious relaxations of interest include finding better sufficient conditions for identifying bipartite graphs and extensions to multi-node and/or soft interventions.

## 8 Acknowledgments

The authors would like to acknowledge the support of the NSF via IIS-1956330, the NIH via R01GM140467, and the Robert H. Topel Faculty Research Fund at the University of Chicago Booth School of Business. This work was done in part while B.A. was visiting the Simons Institute for the Theory of Computing.

\begin{table}
\begin{tabular}{l c c c c} \hline (m,n) & (2, 5) & (3, 8) & (4, 7) & (4, 8) \\ \hline Pure Child & 0.01\(\pm\)0.01 & 0.54\(\pm\)0.13 & 1.35\(\pm\)0.17 & 2.35\(\pm\)0.30 \\ Single Source & 0.02\(\pm\)0.02 & 0.92\(\pm\)0.18 & 1.52\(\pm\)0.21 & 2.81\(\pm\)0.30 \\ \hline \end{tabular}
\end{table}
Table 1: Experiments on simulated data show the effectiveness of our identification theory. The table shows SHD and standard errors are over \(100\) runs.

## References

* [1] K. Ahuja, Y. Wang, D. Mahajan, and Y. Bengio. "Interventional causal representation learning". In: _arXiv preprint arXiv:2209.11924_ (2022).
* [2] A. Anandkumar, D. Hsu, A. Javanmard, and S. Kakade. "Learning linear Bayesian networks with latent variables". In: _Proceedings of The 30th International Conference on Machine Learning_. 2013.
* [3] S. Arora, R. Ge, and A. Moitra. "Learning topic models-going beyond svd". In: _2012 IEEE 53rd annual symposium on foundations of computer science_. IEEE. 2012.
* [4] J. Brehmer, P. De Haan, P. Lippe, and T. Cohen. "Weakly supervised causal representation learning". In: _arXiv preprint arXiv:2203.16437_ (2022).
* [5] S. Buchholz, G. Rajendran, E. Rosenfeld, B. Aragam, B. Scholkopf, and P. Ravikumar. _Learning Linear Causal Representations from Interventions under General Nonlinear Mixing_. 2023.
* [6] R. Cai, F. Xie, C. Glymour, Z. Hao, and K. Zhang. "Triad constraints for learning causal structure of latent variables". In: _Advances in Neural Information Processing Systems_. 2019.
* [7] F. Castelletti and S. Peluso. "Network structure learning under uncertain interventions". In: _Journal of the American Statistical Association_ (2022).
* [8] K. Chalupka, F. Eberhardt, and P. Perona. "Causal feature learning: an overview". In: _Behaviormetrika_ 1 (2017).
* [9] K. Chalupka, P. Perona, and F. Eberhardt. "Visual causal feature learning". In: _arXiv preprint arXiv:1412.2309_ (2014).
* [10] S. Chatterjee. _A new coefficient of correlation_. 2020.
* [11] D. M. Chickering. "Optimal structure identification with greedy search". In: _Journal of machine learning research_ Nov (2002).
* [12] D. M. Chickering. "A transformational characterization of equivalent bayesian network structures". In: _arXiv preprint arXiv:1302.4938_ (2013).
* [13] M. J. Choi, V. Y. Tan, A. Anandkumar, and A. S. Willsky. "Learning latent tree graphical models". In: _Journal of Machine Learning Research_ (2011).
* [14] D. Deligeorgaki, A. Markham, P. Misra, and L. Solus. "Combinatorial and algebraic perspectives on the marginal independence structure of bayesian networks". In: _arXiv preprint arXiv:2210.00822_ (2022).
* [15] D. Eaton and K. Murphy. "Exact bayesian structure learning from uncertain interventions". In: _Artificial intelligence and statistics_. PMLR. 2007.
* [16] F. Eberhardt, C. Glymour, and R. Scheines. "N-1 experiments suffice to determine the causal relations among n variables". In: _Innovations in machine learning_. 2006.
* [17] F. Eberhardt and R. Scheines. "Interventions and causal inference". In: _Philosophy of science_ 5 (2007).
* [18] R. J. Evans. "Graphs for margins of bayesian networks". In: _Scandinavian Journal of Statistics_ 3 (2016).
* [19] G. R. A. Faria, A. Martins, and M. A. Figueiredo. "Differentiable causal discovery under latent interventions". In: _Conference on Causal Learning and Reasoning_. PMLR. 2022.
* [20] M. Germain, K. Gregor, I. Murray, and H. Larochelle. "Made: masked autoencoder for distribution estimation". In: _International conference on machine learning_. PMLR. 2015.
* [21] A. Hagele, J. Rothfuss, L. Lorch, V. R. Somnath, B. Scholkopf, and A. Krause. "Bacadi: bayesian causal discovery with unknown interventions". In: _arXiv preprint arXiv:2206.01665_ (2022).
* [22] Y. Halpern, S. Horng, and D. Sontag. "Anchored discrete factor analysis". In: _arXiv preprint arXiv:1511.03299_ (2015).
* [23] H. Halva, S. L. Corff, L. Lehericy, J. So, Y. Zhu, E. Gassiat, and A. Hyvarinen. "Disentangling identifiable features from noisy data with structured nonlinear ica". In: _arXiv preprint arXiv:2106.09620_ (2021).
* [24] A. Hauser and P. Buhlmann. "Characterization and greedy learning of interventional markov equivalence classes of directed acyclic graphs". In: _The Journal of Machine Learning Research_ 1 (2012).

* [25] B. Huang, C. J. H. Low, F. Xie, C. Glymour, and K. Zhang. "Latent hierarchical causal structure discovery with rank constraints". In: _arXiv preprint arXiv:2210.01798_ (2022).
* [26] A. Hyvarinen and H. Morioka. "Unsupervised feature extraction by time-contrastive learning and nonlinear ica". In: _Advances in Neural Information Processing Systems_ (2016).
* [27] A. Jaber, M. Kocaoglu, K. Shanmugam, and E. Bareinboim. "Causal discovery from soft interventions with unknown targets: characterization and learning". In: _Advances in Neural Information Processing Systems_. 2020.
* [28] M. J. Johnson, D. K. Duvenaud, A. Wiltschko, R. P. Adams, and S. R. Datta. "Composing graphical models with neural networks for structured representations and fast inference". In: _Advances in neural information processing systems_ (2016).
* [29] I. Khemakhem, D. Kingma, R. Monti, and A. Hyvarinen. "Variational autoencoders and nonlinear ica: a unifying framework". In: _International Conference on Artificial Intelligence and Statistics_. PMLR. 2020.
* [30] I. Khemakhem, D. P. Kingma, R. P. Monti, and A. Hyvarinen. "Ice-beem: identifiable conditional energy-based deep models". In: _NeurIPS2020_ (2020).
* [31] I. Khemakhem, D. P. Kingma, R. P. Monti, and A. Hyvarinen. "Variational autoencoders and nonlinear ica: a unifying framework". In: (2019).
* [32] B. Kivva, G. Rajendran, P. Ravikumar, and B. Aragam. "Learning latent causal graphs via mixture oracles". In: _Advances in Neural Information Processing Systems_ (2021).
* [33] M. Kocaoglu, A. Jaber, K. Shanmugam, and E. Bareinboim. "Characterization and learning of causal graphs with latent variables from soft interventions". In: _Advances in Neural Information Processing Systems_ (2019).
* [34] M. Kocaoglu, K. Shanmugam, and E. Bareinboim. "Experimental design for learning causal graphs with latent variables". In: _Advances in Neural Information Processing Systems_ (2017).
* [35] M. Kocaoglu, C. Snyder, A. G. Dimakis, and S. Vishwanath. "Causalgan: learning causal implicit generative models with adversarial training". In: _arXiv preprint arXiv:1709.02023_ (2017).
* [36] E. Kummerfeld and J. Ramsey. "Causal clustering for 1-factor measurement models". In: _Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining_. 2016.
* [37] J. von Kugelgen, M. Besserve, W. Liang, L. Gresele, A. Kekic, E. Bareinboim, D. M. Blei, and B. Scholkopf. _Nonparametric Identifiability of Causal Representations from Unknown Interventions_. 2023.
* [38] S. Lachapelle, P. Rodriguez, Y. Sharma, K. E. Everett, R. Le Priol, A. Lacoste, and S. Lacoste-Julien. "Disentanglement via mechanism sparsity regularization: a new principle for nonlinear ica". In: _First Conference on Causal Learning and Reasoning_. 2021.
* [39] S. L. Lauritzen. _Graphical models_. 1996.
* [40] S. Li, B. Hooi, and G. H. Lee. "Identifying through flows for recovering latent representations". In: _arXiv preprint arXiv:1909.12555_ (2019).
* [41] P. Lippe, S. Magliacane, S. Lowe, Y. M. Asano, T. Cohen, and S. Gavves. "Citris: causal identifiability from temporal intervened sequences". In: _International Conference on Machine Learning_. PMLR. 2022.
* [42] Y. Liu, Z. Zhang, D. Gong, M. Gong, B. Huang, A. v. d. Hengel, K. Zhang, and J. Q. Shi. _Identifying Weight-Variant Latent Causal Models_. 2022.
* [43] A. Markham and M. Grosse-Wentrup. "Measurement dependence inducing latent causal models". In: _Conference on Uncertainty in Artificial Intelligence_. PMLR. 2020.
* [44] G. Mita, M. Filippone, and P. Michiardi. "An identifiable double vae for disentangled representations". In: _Proceedings of the 38th International Conference on Machine Learning_. 2021.
* [45] G. E. Moran, D. Sridhar, Y. Wang, and D. M. Blei. "Identifiable variational autoencoders via sparse decoding". In: _arXiv preprint arXiv:2110.10804_ (2021).
* [46] J. Mouton and R. S. Kroon. "Integrating bayesian network structure into residual flows and variational autoencoders". In: _Transactions on Machine Learning Research_ ().
* [47] J. Pearl. _Causality_. 2009.
* [48] J. Pearl and T. S. Verma. "A statistical semantics for causation". In: _Statistics and Computing_ 2 (1992).

* [49] R. Perry, J. von Kugelgen, and B. Scholkopf. _Causal Discovery in Heterogeneous Environments Under the Sparse Mechanism Shift Hypothesis_. 2022.
* [50] T. Richardson and P. Spirtes. "Ancestral graph markov models". In: _The Annals of Statistics_ 4 (2002).
* [51] G. Roeder, L. Metz, and D. Kingma. "On linear identifiability of learned representations". In: _Proceedings of the 38th International Conference on Machine Learning_. 2021.
* [52] B. Scholkopf, F. Locatello, S. Bauer, N. R. Ke, N. Kalchbrenner, A. Goyal, and Y. Bengio. "Toward causal representation learning". In: _Proceedings of the IEEE_ 5 (2021).
* [53] A. Seigal, C. Squires, and C. Uhler. "Linear causal disentanglement via interventions". In: _arXiv preprint arXiv:2211.16467_ (2022).
* [54] R. Silva, R. Scheine, C. Glymour, and P. Spirtes. "Learning the structure of linear latent variable models". In: _Journal of Machine Learning Research_ Feb (2006).
* [55] P. Sorrenson, C. Rother, and U. Kothe. "Disentanglement by nonlinear ica with general incompressible-flow networks (GIN)". In: _International Conference on Learning Representations_. 2019.
* [56] P. Spirtes, C. N. Glymour, R. Scheines, and D. Heckerman. _Causation, prediction, and search_. 2000.
* [57] C. Squires, A. Seigal, S. Bhate, and C. Uhler. _Linear Causal Disentanglement via Interventions_. 2023.
* [58] C. Squires, Y. Wang, and C. Uhler. "Permutation-based causal structure learning with unknown intervention targets". In: _Conference on Uncertainty in Artificial Intelligence_. PMLR. 2020.
* [59] J. Textor, A. Idelberger, and M. Liskiewicz. "Learning from pairwise marginal independencies". In: _arXiv preprint arXiv:1508.00280_ (2015).
* [60] J. Tian and J. Pearl. "Causal discovery from changes". In: _arXiv preprint arXiv:1301.2312_ (2013).
* [61] B. Varici, E. Acarturk, K. Shanmugam, A. Kumar, and A. Tajer. "Score-based causal representation learning with interventions". In: _arXiv preprint arXiv:2301.08230_ (2023).
* [62] T. Verma and J. Pearl. "Equivalence and synthesis of causal models". In: _UAI '90: Proceedings of the Sixth Annual Conference on Uncertainty in Artificial Intelligence, MIT, Cambridge, MA, USA, July 27-29, 1990_. 1990.
* [63] Y. Wang, D. Blei, and J. P. Cunningham. "Posterior collapse and latent variable non-identifiability". In: _Advances in Neural Information Processing Systems_ (2021).
* [64] S. Webb, A. Golinski, R. Zinkov, T. Rainforth, Y. W. Teh, F. Wood, et al. "Faithful inversion of generative models for effective amortized inference". In: _Advances in Neural Information Processing Systems_ (2018).
* [65] C. Weilbach, B. Beronov, F. Wood, and W. Harvey. "Structured conditional continuous normalizing flows for efficient amortized inference in graphical models". In: _International Conference on Artificial Intelligence and Statistics_. PMLR. 2020.
* [66] F. Xie, R. Cai, B. Huang, C. Glymour, Z. Hao, and K. Zhang. "Generalized independent noise condition for estimating latent variable causal graphs". In: _Advances in Neural Information Processing Systems_ (2020).
* [67] F. Xie, B. Huang, Z. Chen, Y. He, Z. Geng, and K. Zhang. "Identification of linear non-gaussian latent hierarchical structure". In: _International Conference on Machine Learning_. PMLR. 2022.
* [68] F. Xie, Y. Zeng, Z. Chen, Y. He, Z. Geng, and K. Zhang. "Causal discovery of 1-factor measurement models in linear latent variable models with arbitrary noise distributions". In: _Neurocomputing_ (2023).
* [69] K. Yang, A. Katcoff, and C. Uhler. "Characterizing and learning equivalence classes of causal dags under interventions". In: _International Conference on Machine Learning_. PMLR. 2018.
* [70] M. Yang, F. Liu, Z. Chen, X. Shen, J. Hao, and J. Wang. "Causalvae: disentangled representation learning via neural structural causal models". In: _arXiv preprint arXiv:2004.08697_ (2020).
* [71] X. Yang, Y. Wang, J. Sun, X. Zhang, S. Zhang, Z. Li, and J. Yan. "Nonlinear ica using volume-preserving transformations". In: _International Conference on Learning Representations_. 2021.
* [72] J. Zhang, C. Squires, K. Greenewald, A. Srivastava, K. Shanmugam, and C. Uhler. "Identifiability guarantees for causal disentanglement from soft interventions". In: _arXiv preprint arXiv:2307.06250_ (2023).

* [73] R. S. Zimmermann, Y. Sharma, S. Schneider, M. Bethge, and W. Brendel. "Contrastive learning inverts the data generating process". In: _International Conference on Machine Learning_. PMLR. 2021.

Definitions

Let \(G=(V,E)\) be a DAG with \(V=(X,H)\) where \(X\) denotes the observed part and \(H\) denotes the hidden or latent part. In the measurement model, \(G\) decomposes as the union of two subgraphs \(G=G_{\!B}\cup G_{\!H}\) where \(G_{\!B}\) is a directed, bipartite graph of edges pointing from \(H\) to \(X\), and \(G_{\!H}\) is a DAG over the latent variables \(H\). We let \(E^{B}\) be the set of edges in \(G_{\!B}\) and let \(E^{H}\) be the set of edges in \(G_{\!H}\). See Figure 1.

For a given node \(v\), we use standard notation such as \(\mathrm{pa}(v)\), \(\mathrm{ch}(v)\), \(\mathrm{an}(v)\), \(\mathrm{de}(v)\) for parents, children, ancestors, descendants respectively. A node \(w\) is a parent of \(v\) if there exists an edge \(w\to v\). A node \(w\) is a child of \(v\) if there exists an edge \(v\to w\). A node \(w\) is an ancestor of \(v\) if there exists a directed path from \(w\) to \(v\). A node \(w\) is a descendent of \(v\) if there exists a directed path from \(v\) to \(w\). We also define \(\overline{\mathrm{pa}}(v)=\mathrm{pa}(v)\cup\{v\}\), \(\overline{\mathrm{ch}}(v)=\mathrm{ch}(v)\cup\{v\}\), \(\overline{\mathrm{an}}(v)=\mathrm{an}(v)\cup\{v\}\) and \(\overline{\mathrm{de}}(v)=\mathrm{de}(v)\cup\{v\}\). Given a subset \(V^{\prime}\subseteq V\), \(\mathrm{pa}(V^{\prime}):=\cup_{v\in V^{\prime}}\mathrm{pa}(v)\), given two subsets \(A,B\subseteq V\), \(\mathrm{pa}_{B}(A)=\mathrm{pa}(A)\cap B\) and given a subgraph \(G^{\prime}\subseteq G\), \(\mathrm{pa}_{G^{\prime}}(V^{\prime}):=\mathrm{pa}(V^{\prime})\cap G^{\prime}\). Similar notation can be defined for children, ancestors, and descendants. We use \(\mathrm{so}(G^{\prime})\) to denote the source nodes of \(G^{\prime}\) which are the nodes in \(G^{\prime}\) that do not have incoming edges. We also adopt the convention that \(H\) is identified with the indices \([m]=\{1,...,m\}\), and similarly \(X\) is identified with \([n]=\{1,...,n\}\). In particular, we use \(\mathrm{pa}(i)\) and \(\mathrm{pa}(H_{i})\) interchangeably when the context is clear.

Recall that a node \(V_{1}\) is called a collider if it is in the form

\[V_{2}\to V_{1}\gets V_{3}.\]

For disjoint subsets, \(A,B,C\subseteq V\), define \(\mathrm{d-sep}_{G}(AB\,|\,C)\) to mean that \(A,B\) are \(d\)-separated by \(C\) in the graph \(G\) which means that are no active path between \(A\) and \(B\) given by \(C\).

A path between \(A\) and \(B\) is active given \(C\) if the following hold:

1. For every collider in the path, either the collider or one of its descendants is in \(C\).
2. \(C\) does not include any non-colliders in the path

Recall the definitions of \(\mathcal{T}_{V^{\prime}}(G)\) and \(\mathcal{T}_{V^{\prime}}(P)\) as follows:

\[\mathcal{T}_{V^{\prime}}(G)=\{\langle A,B,C\rangle:\mathrm{d-sep}_{G}(AB\,|\,C) \text{ for disjoint subsets }A,B,C\subseteq V^{\prime}\}\]

\[\mathcal{T}_{V^{\prime}}(P)=\{\langle A,B,C\rangle:A\perp\!\!\!\perp B\,|\,C \text{ in $P$ for disjoint subsets }A,B,C\subseteq V^{\prime}\}\]

where \(V^{\prime}\subseteq V\).

## Appendix B Preliminaries

Markov equivalence class.Usually, there is more than one DAG that encodes the same set of \(d\)-separations. To formalize this, Markov equivalence can be defined as follows [39]:

**Definition B.1**.: Two DAGs \(G_{1}\) and \(G_{2}\) are called Markov equivalent if \(\mathcal{T}(G_{1})=\mathcal{T}(G_{2})\).

In particular, we use \(\mathcal{E}(G)\) to denote the Markov equivalence class (MEC) that \(G\) belongs to. Fortunately, MEC has a convenient graphical characterization. Recall that the skeleton of a DAG is the undirected graph of the DAG by ignoring its edge orientations. And a \(v\)-structure in a DAG \(G\) is ordered triple of variables \((V_{1},V_{2},V_{3})\) such that (1) \(G\) contains edges \(V_{1}\to V_{2}\) and \(V_{3}\to V_{2}\) and (2) \(V_{1}\) and \(V_{3}\) are not adjacent in \(G\).

**Theorem B.2** (Verma and Pearl [62]).: _Two DAGs are Markov equivalent if and only if they have the same skeletons and the same \(v\) structures._

There is also another transformational characterization of Markov equivalent DAGs [12].

**Definition B.3** (Covered Edge).: We say an edge \(x\to y\) is covered if \(x\) and \(y\) share the same parent excluding \(x\) (i.e. \(\mathrm{pa}(x)\cup\{x\}=\mathrm{pa}(y)\)).

**Theorem B.4** (Chickering [12]).: _If \(G_{1}\) and \(G_{2}\) are Markov equivalent, then \(G_{1}\) and \(G_{2}\) can be transformed into one another by a sequence of covered edge reversals._PDAGs and CPDAGs.A PDAG is a partially directed acyclic graph that contains both directed and undirected edges [11]. If a DAG \(G\) and a PDAG \(P\) have the same skeleton and \(v\)-structures and if every directed edge in \(P\) has the same orientations in \(G\), then \(G\) is called a consistent extension of \(P\).

We use completed PDAGs (CPDAG) to represent Markov equivalence classes of DAGs [11]. We define an edge to be compelled if, for every DAG of the Markov equivalence class, this edge has the same orientation. A reversible edge is an edge that is not compelled. Therefore, the completed PDAG of a MEC is a PDAG that has a directed edge for every compelled edge and an undirected edge for every reversible edge. A CPDAG uniquely represents an equivalence class of DAGs and every DAG in the equivalence class is a consistent extension of this CPDAG.

Measurement models and UDG.Recall that throughout the paper, we consider a specific type of latent causal graph called the _measurement model_[36, 54] in which there are no direct edges connecting the observed variables.

For any distribution \(P\) over \(V\), recall the definition of the undirected dependency graph (UDG), denoted \(D(P)\), to be the undirected graph over \(X\) in which there is an edge between \(X_{i}\) and \(X_{j}\) if and only if they are marginally dependent (i.e. given the empty set, cf. Remark 2.1). Similarly, we can also define UDG for a measurement model \(G\), denoted \(D(G)\), to be the undirected graph over \(X\) in which there is an edge between two \(X_{i}\) and \(X_{j}\) if and only if they are \(d\)-connected (i.e. by the empty set, cf. Remark 2.1) in \(G\). Parallel to the definiton of \(\Omega_{P}^{(I)}\) which is the set of maximal cliques in \(D(P_{X}^{(I)})\), we can also define \(\Omega_{G}^{(I)}\) to the set of maximal cliques in \(D(G^{(I)})\). We also let \(\Omega=\cup_{I\in\mathcal{I}}\Omega_{P}^{(I)}\).

Although it is always possible (i.e. by ignoring independencies and allowing for degenerate edges) to represent any latent variable model with densely connected, independent latents, this ignores precisely the latent (causal) structure that we seek to capture. We aim to uncover latent structures that can best capture the observed (in)dependencies. Markham and Grosse-Wentrup [43] show that, with only access to the observational distribution, we only need a minimal measurement model, where every latent variable corresponds to a clique of a minimum clique cover set of \(D(G)\) and there is no edge between latent variables, to represent all the dependencies of the observed variables \(X\). With interventions, however, such a minimal measurement model may not capture all of the observable dependencies, as illustrated by Example 2.

**Example 2**.: Without interventions, the graphs in Figure 3(a) and Figure 3(b) share the same CI statements over \(X\), and the first graph would be the one returned as the minimal measurement model. But they do not share the same CI statements under interventions. Specifically, we can intervene on \(H_{2}\) in Figure 3(b) which makes \(X_{1}\) and \(X_{2}\) independent, and this is not possible to achieve in Figure 3(a).

## Appendix C Discussion of assumptions

In this section, we discuss the main assumptions made in this paper (Assumption 1 and Assumption 2). With the exception of the Markov property (Assumption 1(a)), which is standard, we will also show why each assumption is needed by providing a counterexample showing that if each of the other assumptions hold but the assumption of interest fails, there exist two sets of measurement models and interventional targets \((G_{1},\mathcal{I}_{1})\) and \((G_{2},\mathcal{I}_{2})\), which can generate identical sets of observational distributions under unknown interventions. This implies, in particular, that none of our assumptions

Figure 3: Distinguishable measurement models under latent interventions.

can be removed without imposing additional assumptions. It is an interesting direction for future work to explore possible alternative assumptions more carefully.

We use the following notation in the examples:

* \(\sigma(p)\) is a Bernoulli random variable such that \[\sigma(p)=\begin{cases}1&\text{with probability }p\\ 0&\text{otherwise}\end{cases}\]
* \(\tau(p)\) is a random variable such that \[\tau(p)=\begin{cases}1&\text{with probability }p\\ -1&\text{otherwise}\end{cases}\]
* \(\oplus\) means XOR;
* \(\wedge\) means AND.

For ease of reference, we recall our two main assumptions here:

**Assumption 1** (Graphical conditions).: The DAG \(G\) satisfies the following conditions for every \(I\in\mathcal{I}\) and pair of hidden variables \(H_{i}\neq H_{j}\):

1. \(P^{(I)}\) is Markov with respect to \(G^{(I)}\), i.e. \(\mathcal{T}(G^{(I)})\subseteq\mathcal{T}(P^{(I)})\).
2. \(X_{i}\operatorname{\perp\!\!\!\perp}_{P^{(I)}}X_{j}\implies\operatorname{d- sep}_{G^{(I)}}(\{X_{i}\}\{X_{j}\}\,|\,\emptyset)\), i.e. marginal independence in \(X\) implies \(d\)-separation.
3. \(\operatorname{d-sep}_{G^{(I)}}(\{H_{i}\}\{H_{j}\}\,|\,\emptyset)\Longrightarrow\) there exists \(X_{i}\in\operatorname{ch}_{X}(H_{i})\) and \(X_{j}\in\operatorname{ch}_{X}(H_{j})\) such that \(\operatorname{d-sep}_{G^{(I)}}(\{X_{i}\}\{X_{j}\}\,|\,\emptyset)\).

**Assumption 2** (Complete family of targets).: \(\mathcal{I}=\{\emptyset,\{H_{1}\},\ldots,\{H_{m}\}\}\).

**Remark C.1**.: Although we know the set of intervention targets, we do not know the mapping from targets to distribution. In fact, it is possible that for two intervention targets \(I_{1}\) and \(I_{2}\), we have \(P_{X}^{(I_{1})}=P_{X}^{(I_{2})}\). For instance, if the measurement model has multiple source nodes, then intervening on these source nodes would not change the structures of the DAG. And it is not hard to have parametric examples where the distributions are also kept the same (for instance, see Example 4). So the number of elements in the set \(\{P_{X}^{(I)}\}_{I\in\mathcal{I}}\) could be less than \(m+1\). Therefore, we do not even know the number of hidden variables.

In particular, by Assumption 1(a) and (b), \(D(P^{(I)})\) is the same as \(D(G^{(I)})\) and thus \(\Omega_{P}^{(I)}\) equals \(\Omega_{G}^{(I)}\). We use these concepts interchangeably in this paper.

It is important to highlight that two distributions \(P_{1}\) and \(P_{2}\) over two measurement models \(G_{1}\) and \(G_{2}\) share the same UDG (i.e. \(D(P_{1})\) = \(D(P_{2})\)) if and only if \(\mathcal{T}_{X}(G_{1})\) = \(\mathcal{T}_{X}(G_{2})\) (Lemma D.12). Therefore, for Assumption 1(b), (c), and Assumption 2, we in addition show that the two measurement models in counterexamples are also _structurally equivalent_ in terms of observed variables, which means that \(\{\mathcal{T}_{X}(G_{1}^{(I)})\}_{I\in\mathcal{I}_{1}}\) is the same as \(\{\mathcal{T}_{X}(G_{2}^{(I)})\}_{I\in\mathcal{I}_{2}}\).

### Assumption 1(b)

Assumption 1(b) requires that the UDG \(D(P^{(I)})\) correctly encodes the marginal independence structure of \(P^{(I)}\). It is a type of "marginal faithfulness" assumption, however, this is a significantly weaker assumption than faithfulness and should not be confused with ordinary faithfulness, which requires that _all_ conditional independence statements in \(P^{(I)}\) are encoded in the DAG \(G^{(I)}\). To appreciate the sizable, difference, note that Assumption 1(b) imposes \(O(n^{2})\) constraints whereas faithfulness imposes \(O(4^{n})\) constraints. Similar "marginal"-type assumptions have been invoked previously; see [43, 59] and the references therein. Example 3 shows why Assumption 1(b) is needed. Specifically, because we allow nonlinear functions between observed and latent, without any restrictions, the observed distributions (i.e. over \(X\), both observational and interventional) can be arbitrary.

**Example 3** (Counterexamples for Assumption 1(b)).: Consider the two measurement models \(G_{(a)}\) and \(G_{(b)}\) in Figure 4. We will construct structural causal models for \(G_{(a)}\) and \(G_{(b)}\) such that they both satisfy Assumption 1(a), and (c). With the complete family of interventional targets (Assumption 2), the interventional distributions of observed variables for both DAGs are the same. Thus, without Assumption 1(b), there are ambiguities.

Specifically, for \(G_{(a)}\), we have the following structural equations:

\[H_{1} \leftarrow\sigma(0.5)\] \[X_{1} \gets H_{1}\oplus\epsilon_{1}^{a} \epsilon_{1}^{a} \leftarrow\sigma(0.5)\] \[X_{2} \gets H_{1}\oplus\epsilon_{2}^{a} \epsilon_{2}^{a} \leftarrow\sigma(0.5)\]

For \(G_{(b)}\), we have the following structural equations:

\[H_{1} \leftarrow\sigma(0.5)\] \[H_{2} \gets H_{1}\oplus\epsilon_{1}^{b} \epsilon_{1}^{b} \leftarrow\sigma(0.5)\] \[X_{1} \gets H_{1}\oplus\epsilon_{2}^{b} \epsilon_{2}^{b} \leftarrow\sigma(0.5)\] \[X_{2} \gets H_{2}\oplus\epsilon_{3}^{b} \epsilon_{3}^{b} \leftarrow\sigma(0.5)\]

Assumption 1(b) is violated because \(X_{1}\) and \(X_{2}\) are independent in both cases.

Let \(P_{X}^{*}(X_{1},X_{2})\) be the joint distribution over \(X_{1},X_{2}\) where \(X_{1}\) and \(X_{2}\) are independent bernoulli variables with parameter \(0.5\).

For \(G_{(a)}\), if the intervention target \(I\) is \(\emptyset\), then \(P_{X}^{(I)}=P_{X}^{*}\). If the intervention target \(I\) is \(\{H_{1}\}\) but the interventional marginal distribution of \(H_{1}\) is still a Bernoulli distribution, then \(P_{X}^{(I)}=P_{X}^{*}\).

For \(G_{(b)}\), if the intervention target \(I\) is \(\emptyset\), then \(P_{X}^{(I)}=P_{X}^{*}\). If the intervention target \(I\) is \(\{H_{1}\}\) but the interventional marginal distribution of \(H_{1}\) is still a Bernoulli distribution, then \(P_{X}^{(I)}=P_{X}^{*}\). If the intervention target \(I\) is \(\{H_{2}\}\) and we have \(H_{2}\leftarrow\sigma(0.5)\), then \(P_{X}^{(I)}=P_{X}^{*}\).

Therefore, both \(G_{(a)}\) and \(G_{(b)}\) can induce \(\{P_{X}^{(I)}\}_{I\in\mathcal{I}}=\{P_{X}^{*}\}\).

### Assumption 1(c)

Assumption 1(c) ensures the relationships between the hidden variables leave observable signatures in the observed data. Of all the assumptions, this one is new to the best of our knowledge and arises due to the fact that (a) We allow for dependencies between the latents, and (b) We make no parametric assumptions. The latter is what crucially distinguishes our approach from previous work that inevitably leverages parametric assumptions to either implicitly guarantee Assumption 1(c) or sidestep it altogether. In the fully nonparametric setting, this cannot be avoided, as shown by Example 4.

**Example 4** (Counterexample for Assumption 1(c)).: Consider the two measurement models \(G_{(a)}\) and \(G_{(b)}\) in Figure 5. We will construct structural causal models for both \(G_{(a)}\) and \(G_{(b)}\) such that they satisfy Assumption 1(a), (b), and (c). With the complete family of interventional targets (Assumption 2), the interventional distributions of observed variables for both DAGs are the same. In

Figure 4: Counterexample for Assumption 1(b)particular, these two DAGs have the same set of \(d\)-separation statements of observed variables under interventions. Therefore, Assumption 1(c) is needed to avoid ambiguities.

First of all, let us examine the structure of these two measurement models. For \(G_{(a)}\), if the intervention target \(I\) is either \(\emptyset\), \(\{H_{1}\}\), \(\{H_{2}\}\) or \(\{H_{3}\}\), \(X_{1}\), \(X_{2}\) and \(X_{3}\) always stays \(d\)-connected. For \(G_{(b)}\), if the intervention target \(I\) is \(\emptyset\) or \(\{H_{1}\}\), \(X_{1}\), \(X_{2}\) and \(X_{3}\) also stays \(d\)-connected. Therefore, by Lemma D.10, for the complete family of interventional targets \(\mathcal{I}_{(a)}\) of \(G_{(a)}\) and \(\mathcal{I}_{(b)}\) of \(G_{(b)}\), \(\{\mathcal{T}_{X}(G_{(a)}^{(I)})\}_{I\in\mathcal{I}_{(a)}}\) is the same as \(\{\mathcal{T}_{X}(G_{(b)}^{(I)})\}_{I\in\mathcal{I}_{(b)}}\).

Now let's consider this parametric example. Specifically, for \(G_{(a)}\), we have the following structural equations:

\[H_{1} \leftarrow\sigma(0.5)\] \[H_{2} \gets H_{1}\oplus\epsilon_{1}^{a}\quad\epsilon_{1}^{a} \leftarrow\sigma(0.5)\] \[H_{3} \gets H_{2}\oplus\epsilon_{2}^{a}\quad\epsilon_{1}^{a} \leftarrow\sigma(0.5)\] \[X_{1} \gets H_{1}+H_{2}\] \[X_{2} \gets H_{2}+H_{3}\] \[X_{3} \gets H_{1}+H_{3}\]

And for \(G_{(b)}\), we have the following structural equations:

\[\epsilon_{1}^{b} \leftarrow\sigma(0.5)\quad\epsilon_{2}^{b}\leftarrow\sigma(0.5) \quad\epsilon_{3}^{b}\leftarrow\sigma(0.5)\] \[H_{1} \leftarrow(\epsilon_{1}^{b},\epsilon_{2}^{b},\epsilon_{3}^{b})\] \[X_{1} \leftarrow\langle(1,1,0),H_{1}\rangle\] \[X_{2} \leftarrow\langle(0,1,1),H_{1}\rangle\] \[X_{3} \leftarrow\langle(1,0,1),H_{1}\rangle\]

For \(G_{(a)}\), if the intervention target \(I\) is \(\emptyset\), denote \(P_{X}^{(I)}=P_{X}^{1}\). If the intervention target \(I\) is \(\{H_{1}\}\) and \(H_{1}\leftarrow\sigma(0.6)\), denote \(P_{X}^{(I)}=P_{X}^{2}\). If the intervention target \(I\) is \(\{H_{2}\}\) and \(H_{2}\leftarrow\sigma(0.5)\) or the intervention target \(I\) is \(\{H_{3}\}\) and \(H_{3}\leftarrow\sigma(0.5)\), we have that \(P_{X}^{(I)}=P_{X}^{1}\).

For \(G_{(a)}\), if the intervention target \(I\) is \(\emptyset\), let \(P_{X}^{(I)}=P_{X}^{1}\). And if if the intervention target \(I\) is \(\{H_{1}\}\) and we set the distribution of \(\epsilon_{1}^{b}\) to be \(\sigma(0.6)\), we also have that \(P_{X}^{(I)}=P_{X}^{2}\).

Therefore, both \(G_{(a)}\) and \(G_{(b)}\) can induce \(\{P_{X}^{(I)}\}_{I\in\mathcal{I}}=\{P_{X}^{1},P_{X}^{2}\}\). And one can check that all the other assumptions still hold.

### Assumption 2

Assumption 2 ensures that the effect of each hidden variable is measured. Example 5 shows why Assumption 2 is needed. This assumption is also made in recent work on causal representation learning [1, 53].

**Example 5** (Counterexample for Assumption 2).: Consider the two measurement models \(G_{(a)}\) and \(G_{(b)}\) in Figure 6. Consider the family of _incomplete_ interventional targets \(\{\emptyset,\{H_{2}\}\}\), and assume

Figure 5: Counterexample for Assumption 1(c)

that \(\mathcal{I}_{(a)}=\mathcal{I}_{(b)}=\{\emptyset,\{H_{2}\}\}\). We will construct structural causal models for both \(G_{(a)}\) and \(G_{(b)}\) such that they satisfy Assumption 1 and the interventional distributions of observed variables for both DAGs are the same. In particular, these two DAGs have the same set of \(d\)-separation statements of observed variables under interventions. Therefore, Assumption 2 is needed to avoid ambiguities.

Let us examine the structure of these two measurement models. For \(G_{(a)}\), if the intervention target \(I\) is \(\emptyset\), \(X_{1}\), \(X_{2}\) and \(X_{3}\) are \(d\)-connected. If the intervention target \(I\) is \(\{H_{2}\}\), then only \(X_{2}\) and \(X_{3}\) are \(d\)-connected. Similarly, for \(G_{(b)}\), if the intervention target \(I\) is \(\emptyset\), \(X_{1}\), \(X_{2}\) and \(X_{3}\) also stays \(d\)-connected. And if the intervention target \(I\) is \(\{H_{2}\}\), then only \(X_{2}\) and \(X_{3}\) are \(d\)-connected. Therefore, by Lemma D.10, \(\{\mathcal{T}_{X}(G_{(a)}^{(I)})\}_{I\in\mathcal{I}_{(a)}}\) is the same as \(\{\mathcal{T}_{X}(G_{(b)}^{(I)})\}_{I\in\mathcal{I}_{(b)}}\).

Now let's consider this parametric example. Specifically, for \(G_{(a)}\), we have the following structural equations:

\[H_{1} \leftarrow\mathcal{N}(0,1)\] \[H_{2} \gets H_{1}+\epsilon_{1}^{a}\quad\epsilon_{1}^{a}\leftarrow \mathcal{N}(0,1)\] \[H_{3} \gets H_{2}+\epsilon_{2}^{a}\quad\epsilon_{2}^{a}\leftarrow \mathcal{N}(0,1)\] \[X_{1} \gets H_{1}\] \[X_{2} \gets H_{2}\] \[X_{3} \gets H_{3}\]

And for \(G_{(b)}\), we have the following structural equations:

\[H_{1} \leftarrow\mathcal{N}(0,1)\] \[H_{2} \gets H_{1}+\epsilon_{1}^{b}\quad\epsilon_{1}^{b}\leftarrow \mathcal{N}(0,1)\] \[X_{1} \gets H_{1}\] \[X_{2} \gets H_{2}\] \[X_{3} \gets H_{2}+\epsilon_{2}^{b}\quad\epsilon_{2}^{b}\leftarrow \mathcal{N}(0,1)\]

For \(G_{(a)}\), if the intervention target \(I\) is \(\emptyset\), \(P_{X}^{(I)}=\mathcal{N}(0,\Sigma_{1})\) and \(\Sigma_{1}=\begin{pmatrix}1&1&1\\ 1&2&2\\ 1&2&3\end{pmatrix}\). If the intervention target \(I\) is \(\{H_{2}\}\), and \(H_{2}\leftarrow\mathcal{N}(0,\alpha)\), then \(P_{X}^{(I)}=\mathcal{N}(0,\Sigma_{2})\) where \(\Sigma_{2}=\begin{pmatrix}1&0&0\\ 0&\alpha&\alpha\\ 0&\alpha&\alpha+1\end{pmatrix}\)

On the other hand, for \(G_{(b)}\), if the intervention target \(I\) is \(\emptyset\), \(P_{X}^{(I)}=\mathcal{N}(0,\Sigma_{1})\). And If the intervention target \(I\) is \(\{H_{2}\}\), and \(H_{2}\leftarrow\mathcal{N}(0,\alpha)\), then \(P_{X}^{(I)}=\mathcal{N}(0,\Sigma_{2})\).

Therefore, both \(G_{(a)}\) and \(G_{(b)}\) can induce \(\{P_{X}^{(I)}\}_{I\in\mathcal{I}}=\{\mathcal{N}(0,\Sigma_{1}),\mathcal{N}(0, \Sigma_{2})\}\). And one can check that all the other assumptions still hold.

### Discussion of subset condition

Subset condition is a common assumption used for latent graph identification that dates back to Pearl and Verma [48] (see also [18; 32]. It is defined as follows:

Figure 6: Counterexample for Assumption 2

**Assumption** (Subset condition).: For any \(H_{i}\neq H_{j}\), \(\mathrm{ch}_{X}(H_{i})\) is not a subset of \(\mathrm{ch}_{X}(H_{j})\) and vice versa.

The subset condition ensures that latent variables have observable signatures (i.e. in the observed marginal \(P(X)\)) and dates back to the 1990s [48], where it was used to study graphical latent variable models, and has more recently been applied on similar problems [18, 32].

It turns out that the subset condition is implied by Assumption 1 and Assumption 2.

**Lemma C.1**.: _Under Assumption 1 and Assumption 2, the subset condition always holds._

Proof.: Suppose the subset condition is violated, then without loss of generality, there exist two hidden variables \(H_{i}\) and \(H_{j}\) such that \(\mathrm{ch}_{X}(H_{i})\subseteq\mathrm{ch}_{X}(H_{j})\). Then by Lemma E.4, there exists an interventional target such that \(H_{i}\) and \(H_{j}\) are \(d\)-seperated. But this would violate Assumption 1(c). 

It is, however, worth noting that the subset section is implied because of Assumption 2. If the complete family of intervention targets is not assumed to be given, one might need to assume the subset condition. This is because Assumption 1(c) relies on the international targets provided. For example, if the latent graph is complete and the one and only interventional target is the empty set, then Assumption 1(c) is not violated for any graph.

### Maximal measurement models

Recall the definition of the maximal measurement model:

**Definition 3.1** (Maximal measurement model).: A measurement model \(G\) is called **maximal** if it satisfies Assumption 1 and the following two conditions:

* \(\mathrm{pa}(X_{i})\neq\emptyset\) for all \(i\in[n]\),
* There is no DAG \(G^{\prime}=(V,E^{\prime})\) also satisfying Assumption 1 such that, \(\{\mathcal{T}_{X}(G^{(I)})\}_{I\in\mathcal{I}}=\{\mathcal{T}_{X}(G^{\prime(I)} )\}_{I\in\mathcal{I}}\), and \(E\subseteq E^{\prime}\).

Example 6 shows why the maximality condition is needed.

**Example 6** (Maximal measurement model).: Consider the two measurement models \(G_{(a)}\) and \(G_{(b)}\) in Figure 7. We will construct structural causal models for both \(G_{(a)}\) and \(G_{(b)}\) such that they satisfy Assumption 1 and with a complete family of interventional targets (Assumption 2), the interventional distributions of observed variables for both DAGs are the same. In particular, the CI relations of observed variables are the same under different interventions. Furthermore, \(G_{(b)}\) encodes strictly more dependencies than \(G_{(a)}\) and is a maximal measurement model. Since these two graphs cannot be distinguished from the set of interventional distributions \(\{P_{X}^{(I)}\}_{I\in\mathcal{I}}\) alone, and one encodes more information than the other, this motivates why we consider maximal measurement models.

Let's first examine the structure of these two measurement models and show that \(G_{(b)}\) is maximal.

For \(G_{(a)}\), if the intervention target \(I\) is \(\emptyset\), \(X_{1}\), \(X_{2}\), \(X_{3}\) and \(X_{4}\) are \(d\)-connected. If the intervention target \(I\) is \(\{H_{1}\}\), then only \(X_{2}\), \(X_{3}\), \(X_{4}\) are \(d\)-connected. If the intervention target \(I\) is \(\{H_{2}\}\), then

Figure 7: An Example of maximal measurement model\(X_{1}\), \(X_{2}\), \(X_{3}\) and \(X_{4}\) are \(d\)-connected. If the intervention target \(I\) is \(\{H_{3}\}\), then \(X_{1}\), \(X_{3}\), \(X_{4}\) are \(d\)-connected and \(X_{2}\) is only \(d\)-connected to \(X_{1}\). If the intervention target \(I\) is \(\{H_{4}\}\), then \(X_{1}\), \(X_{2}\), \(X_{3}\) are \(d\)-connected and \(X_{4}\) is only \(d\)-connected to \(X_{1}\).

Similarly, for \(G_{(b)}\), if the intervention target \(I\) is \(\emptyset\), if the intervention target \(I\) is \(\emptyset\), \(X_{1}\), \(X_{2}\), \(X_{3}\) and \(X_{4}\) are \(d\)-connected. If the intervention target \(I\) is \(\{H_{1}\}\), then only \(X_{2}\), \(X_{3}\), \(X_{4}\) are \(d\)-connected. If the intervention target \(I\) is \(\{H_{2}\}\), then \(X_{1}\), \(X_{2}\), \(X_{3}\) and \(X_{4}\) are \(d\)-connected. If the intervention target \(I\) is \(\{H_{3}\}\), then \(X_{1}\), \(X_{3}\), \(X_{4}\) are \(d\)-connected and \(X_{2}\) is only conncoted to \(X_{1}\). If the intervention target \(I\) is \(\{H_{4}\}\), then \(X_{1}\), \(X_{2}\), \(X_{3}\) are \(d\)-connected and \(X_{4}\) is only connected to \(X_{1}\).

Therefore, by Lemma D.10, for the complete family of interventional targets \(\mathcal{I}_{(a)}\) of \(G_{(a)}\) and \(\mathcal{I}_{(b)}\) of \(G_{(b)}\), \(\{\mathcal{T}_{X}(G_{(a)}^{(I)})\}_{I\in\mathcal{I}_{(a)}}\) is the same as \(\{\mathcal{T}_{X}(G_{(b)}^{(I)})\}_{I\in\mathcal{I}_{(b)}}\).

One can also check \(G_{(b)}\) is maximal because adding additional edges to \(G_{(b)}\) would lead to different \(d\)-separation statements of observed variables under interventions.

Now we construct structural causal models for each DAG. Specifically, for \(G_{(a)}\), we have the following structural equations:

\[H_{2}\gets\epsilon_{1}^{a}\quad\epsilon_{1}^{a}\leftarrow \sigma(0.5)\] \[H_{3}\gets H_{2}\epsilon_{2}^{a}\quad\epsilon_{2}^{a} \leftarrow\tau(0.5)\] \[H_{4}\gets H_{3}\epsilon_{3}^{a}\quad\epsilon_{3}^{a} \leftarrow\sigma(0.5)\] \[H_{1}\gets H_{2}H_{4}\epsilon_{4}^{a}\quad\epsilon_{4}^{a} \leftarrow\sigma(0.5)\] \[X_{1}\gets H_{1}\] \[X_{2}\gets H_{2}\] \[X_{3}\gets H_{3}\] \[X_{4}\gets H_{4}\]

And for \(G_{(b)}\), we have the following structural equations:

\[H_{2}\leftarrow\epsilon_{1}^{b}\quad\epsilon_{1}^{b}\leftarrow \sigma(0.5)\] \[H_{3}\gets H_{2}\epsilon_{2}^{b}\quad\epsilon_{2}^{b} \leftarrow\tau(0.5)\] \[H_{4}\gets H_{3}\epsilon_{3}^{b}\quad\epsilon_{3}^{b} \leftarrow\sigma(0.5)\] \[H_{1}\gets H_{2}H_{3}^{2}H_{4}\epsilon_{4}^{b}\quad\epsilon_{4 }^{b}\leftarrow\sigma(0.5)\] \[X_{1}\gets H_{1}\] \[X_{2}\gets H_{2}\] \[X_{3}\gets H_{3}\] \[X_{4}\gets H_{4}\]

For \(G_{(a)}\), if the intervention target \(I\) is \(\emptyset\), then \(X_{2}=\epsilon_{1}^{a}\), \(X_{3}=\epsilon_{1}^{a}\epsilon_{2}^{a}\), \(X_{4}=\epsilon_{1}^{a}\epsilon_{2}^{a}\epsilon_{3}^{a}\) and \(X_{1}=\epsilon_{1}^{a}\epsilon_{2}^{a}\epsilon_{3}^{a}\epsilon_{4}^{a}\).

For \(G_{(b)}\), if the intervention target \(I\) is \(\emptyset\), then \(X_{2}=\epsilon_{1}^{b}\), \(X_{3}=\epsilon_{1}^{b}\epsilon_{2}^{b}\), \(X_{4}=\epsilon_{1}^{b}\epsilon_{2}^{b}\epsilon_{3}^{b}\) and \(X_{1}=\epsilon_{1}^{b}\epsilon_{2}^{b}\epsilon_{3}^{b}\epsilon_{4}^{b}\).

For \(G_{(a)}\), if the intervention target is \(\{H_{2}\}\) and \(H_{2}\leftarrow\epsilon_{1}^{\prime}\) where \(\epsilon_{1}^{\prime}\) is another Bernoulli random variable, then \(X_{2}=\epsilon_{1}^{\prime}\), \(X_{3}=\epsilon_{1}^{\prime}\epsilon_{2}^{a}\), \(X_{4}=\epsilon_{1}^{\prime}\epsilon_{2}^{a}\epsilon_{3}^{a}\) and \(X_{1}=\epsilon_{1}^{\prime}\epsilon_{2}^{a}\epsilon_{3}^{a}\epsilon_{4}^{a}\).

For \(G_{(b)}\), if the intervention target is \(\{H_{2}\}\) and \(H_{2}\leftarrow\epsilon_{1}^{\prime}\) where \(\epsilon_{1}^{\prime}\) is another Bernoulli random variable, then \(X_{2}=\epsilon_{1}^{\prime}\), \(X_{3}=\epsilon_{1}^{\prime}\epsilon_{2}^{b}\), \(X_{4}=\epsilon_{1}^{\prime}\epsilon_{2}^{b}\epsilon_{3}^{b}\) and \(X_{1}=\epsilon_{1}^{\prime}\epsilon_{2}^{b}\epsilon_{3}^{b}\epsilon_{4}^{b}\).

For \(G_{(a)}\), if the intervention target is \(\{H_{3}\}\) and \(H_{3}\leftarrow\epsilon_{2}^{\prime}\) where \(\epsilon_{2}^{\prime}\) is another Bernoulli random variable, then \(X_{2}=\epsilon_{1}^{a}\), \(X_{3}=\epsilon_{2}^{\prime}\), \(X_{4}=\epsilon_{2}^{\prime}\epsilon_{3}^{a}\) and \(X_{1}=\epsilon_{1}^{a}\epsilon_{2}^{a}\epsilon_{3}^{a}\epsilon_{4}^{a}\).

For \(G_{(b)}\), if the intervention target is \(\{H_{3}\}\) and \(H_{3}\leftarrow\epsilon_{2}^{\prime}\) where \(\epsilon_{2}^{\prime}\) is another Bernoulli random variable, then \(X_{2}=\epsilon_{1}^{b}\), \(X_{For \(G_{(b)}\), if the intervention target is \(\{H_{4}\}\) and \(H_{4}\leftarrow\epsilon^{\prime}_{3}\) where \(\epsilon^{\prime}_{3}\) is another Bernoulli random variable, then \(X_{2}=\epsilon^{b}_{1}\), \(X_{3}=\epsilon^{b}_{1}\epsilon^{b}_{2}\), \(X_{4}=\epsilon^{\prime}_{3}\) and \(X_{1}=\epsilon^{b}_{1}\epsilon^{\prime}_{3}\epsilon^{b}_{4}\).

For \(G_{(a)}\), if the intervention target \(I\) is \(\{H_{1}\}\) and \(H_{1}\leftarrow\epsilon^{\prime}_{4}\), then \(X_{2}=\epsilon^{a}_{1}\), \(X_{3}=\epsilon^{a}_{1}\epsilon^{a}_{2}\), \(X_{4}=\epsilon^{a}_{1}\epsilon^{a}_{2}\epsilon^{a}_{3}\) and \(X_{1}=\epsilon^{\prime}_{4}\).

For \(G_{(b)}\), if the intervention target \(I\) is \(\{H_{1}\}\) and \(H_{1}\leftarrow\epsilon^{\prime}_{4}\), then \(X_{2}=\epsilon^{b}_{1}\), \(X_{3}=\epsilon^{b}_{1}\epsilon^{b}_{2}\), \(X_{4}=\epsilon^{b}_{1}\epsilon^{b}_{2}\epsilon^{b}_{3}\) and \(X_{1}=\epsilon^{\prime}_{4}\).

Note that the four pairs of \((\epsilon^{a}_{1},\epsilon^{b}_{1})\), \((\epsilon^{a}_{2},\epsilon^{b}_{2})\), \((\epsilon^{a}_{3},\epsilon^{b}_{3})\) and \((\epsilon^{a}_{4},\epsilon^{b}_{4})\) have the same distributions.

Therefore, both \(G_{(a)}\) and \(G_{(b)}\) can induce the same \(\{P_{X}^{(I)}\}_{I\in\mathcal{I}}\). And one can check that Assumption 1 still hold.

In general, there are multiple DAGs that are Markov to a given distribution, and the question is how do we decide on the correct "minimal" representation. Without latents, there is no ambiguity: We can always test all possible CI relations and obtain a complete picture to obtain a minimal I-map. With latents, we must be careful:

* If we can check CI relations over all of \((X,H)\), then the usual notion of a minimal I-map prevails. But in practice, we cannot access \(P(X,H)\) since H is unobserved.
* Thus, in practice, we should restrict our attention to information about \(P(X)\) only. In this case, we argue that we should only remove an edge if its removal can be justified on the basis of information about \(P(X)\) only. This is the essence of maximality: We only remove an edge if it follows from the observed data \(X\). Otherwise, we remain agnostic: We do not want to remove an edge that may in fact reflect a "real" dependence over H.

This encapsulates the concept of maximality, and the underlying intuition is akin to that of maximal ancestral graphs. As a result, our characterization of the maximal measurement model aligns with the core principles of the maximal ancestral graph. Measurement models have latent variables and we only have access to partial information (ie., observed variables). Since two measurement models can encode the same set of conditional independencies over \(X\) and the absence of edges encodes nontrivial information, the removal of an edge should be justified carefully on the data we have available.

## Appendix D Proofs for Section 4

In this section, we provide all proofs that were left out in Section 4. Recall that we assume that \(G\) is a maximal measurement model (Definition 3.1) satisfying Assumption 1, and that Assumption 2 also holds.

This first proposition shows that maximal valid subsets can be used to identify bipartite graphs.

**Proposition 4.1**.: _For any hidden variable \(H_{i}\), \(\operatorname{ch}_{X}(H_{i})\) is a maximal valid subset._

Proof.: By Assumption 1(a) and Assumption 1(b), two observed variables \(X_{i}\) and \(X_{j}\) are dependent if and only if \(X_{i}\) and \(X_{j}\) are \(d\)-connected. Therefore, \(D(G^{(I)})=D(P^{(I)})\) under any intervention target \(I\).

Any two variables in \(\operatorname{ch}_{X}(H_{i})\) would stay \(d\)-connected under any unknown intervention on latent variables via the common parent \(H_{i}\). So \(\operatorname{ch}_{X}(H_{i})\) are always in the same clique for any \(D(G^{(I)})\) and thus \(\operatorname{ch}_{X}(H_{i})\) must be a valid subset.

Suppose \(\operatorname{ch}_{X}(H_{i})\) is not maximal. Then there exists a valid subset \(X^{\prime}\subseteq X\) such that \(\operatorname{ch}_{X}(H_{i})\subseteq X^{\prime}\), and by definition, for any intervention target \(I\) and any maximal clique \(C\in\Omega_{G}^{(I)}\) such that \(\operatorname{ch}_{X}(H_{i})\subseteq C\), we have \(\operatorname{ch}_{X}(H_{i})\subsetneq X^{\prime}\subseteq C\). Let \(e\) be an element in \(X^{\prime}\setminus\operatorname{ch}_{X}(H_{i})\). Consider the following new graph \(G^{\prime}\) with added edge \(H_{i}\to e\). We know that for any maximal clique \(C\) such that \(\operatorname{ch}_{X}(H_{i})\subseteq C\), we have \(\operatorname{ch}_{X}(H_{i})\subseteq\operatorname{ch}_{X}(H_{i})\cup\{e\} \subseteq X^{\prime}\subseteq C\).

To get a contradiction, we need to show that \(D(G^{(I)})=D(G^{\prime(I)})\), for any intervention target \(I\). Because we are adding an additional edge to \(G^{\prime}\), existing active paths between any observed variablesin \(G\) still exist in \(G^{\prime}\). Therefore, \(D(G^{\prime(I)})\) can only have more edges, and any potential additional edges in \(D(G^{\prime(I)})\) must be between \(e\) and some observed node \(X_{i}\). There are two cases. (a) Suppose \(X_{i}\in\mathrm{ch}_{X}(H_{i})\), then because \(e\) is always in the same clique as \(\mathrm{ch}_{X}(H_{i})\), the edge \(X_{i}-e\) must already exist in \(D(G^{(I)})\). (b) Suppose \(X_{i}\in\mathrm{ch}_{X}(H_{j})\) where \(H_{i}\neq H_{j}\). Then \(X_{i}\) and \(e\) are \(d\)-connected because there is an active path between \(H_{i}\) and \(H_{j}\) under intervention target \(I\). By Lemma D.13, there exists a maximal clique \(C\in\Omega_{G}^{(I)}\), where \(\mathrm{ch}_{X}(H_{i})\cup\mathrm{ch}_{X}(H_{j})\subseteq C\). However, we also know that \(\mathrm{ch}_{X}(H_{i})\subseteq\mathrm{ch}_{X}(H_{i})\cup\{e\}\subseteq X^{ \prime}\subseteq C\). Therefore, the edge \(X_{i}-e\) must already exist in \(D(G^{(I)})\). Then, \(\{\Omega_{G}^{(I)}\}_{I\in\mathcal{I}}\) is the same as \(\{\Omega_{G^{\prime}}^{(I)}\}_{I\in\mathcal{I}}\). And by Lemma D.10, \(\{\mathcal{T}_{X}(G^{(I)})\}_{I\in\mathcal{I}}\) is the same as \(\{\mathcal{T}_{X}(G^{\prime(I)})\}_{I\in\mathcal{I}}\). By Lemma D.17, this is not possible because \(G\) is maximal. 

### Replaceable and imaginary subsets

Somewhat unintuitively, it is possible that a maximal valid subset can be contained in another maximal valid subset. The reason is that \(X^{\prime\prime}\) in Definition 3.2 is not allowed to depend on the clique \(C\).

**Example 7**.: Consider \(G\) defined in Figure 8. When \(I=\{H_{1}\}\) or \(I=\emptyset\), there is one maximal clique \(C=\{X_{1},X_{2},X_{3}\}\in\Omega_{G}^{(I)}\). When \(I=\{H_{2}\}\), then there are two maximal cliques in \(\Omega_{G}^{(I)}\): \(\{X_{1},X_{2}\}\) and \(\{X_{2},X_{3}\}\). Thus,

\[\Omega=\{\{X_{1},X_{2}\},\{X_{2},X_{3}\},\{X_{1},X_{2},X_{3}\}\},\]

and the valid subsets are \(\{X_{1}\}\), \(\{X_{2}\}\), \(\{X_{3}\}\), \(\{X_{1},X_{2}\}\), and \(\{X_{2},X_{3}\}\). It is clear that \(\{X_{1},X_{2}\}\) is a maximal valid subset by the definition. But it turns out that \(\{X_{2}\}\) is also maximal: Even though there are valid sets between \(\{X_{2}\}\) and each clique in \(\Omega\), there is not a _single_ valid subset with this property.

**Theorem 4.3**.: _If there are no non-replaceable imaginary subsets, then a subset \(X^{\prime}\) is a non-replaceable maximal valid subset if and only if there exists a hidden variable \(H_{i}\) such that \(\mathrm{ch}_{X}(H_{i})=X^{\prime}\). In particular, it follows that \(G_{B}\) is identifiable._

Proof.: \((\Rightarrow)\) Suppose there exists a non-replaceable maximal valid subset \(X^{\prime}\) such that there is no hidden variable \(H_{i}\) with \(\mathrm{ch}_{X}(H_{i})=X^{\prime}\). Then \(X^{\prime}\) is imaginary, which is a contradiction. Note that \(X^{\prime}\) cannot be a proper set of any \(\mathrm{ch}_{X}(H_{i})\) either, because it is non-replaceable and all \(\mathrm{ch}_{X}(H_{i})\) are maximal valid subsets by Proposition 4.1.

\((\Leftarrow)\) On the other hand, there exists a hidden variable \(H_{i}\) such that \(\mathrm{ch}_{X}(H_{i})=X^{\prime}\). Then it must be non-replaceable. Suppose it is replaceable, then, by definition, there exists another maximal valid subset \(X^{\prime\prime}\) such that \(X^{\prime}\subseteq X^{\prime\prime}\). Then by the subset condition (Lemma C.1), \(X^{\prime\prime}\) must be imaginary. Suppose \(X^{\prime\prime}\) is replaceable, then there must exist another non-replaceable imaginary subset that contains both \(X^{\prime}\) and \(X^{\prime\prime}\), which is also a contradiction. 

There might exist a hidden variable \(H_{i}\) such that \(\mathrm{ch}_{X}(H_{i})\) is replaceable (Example 8).

**Example 8** (Non-imaginary set can be replaceable).: Consider Figure 9 below. When the intervention target \(I\) is \(\emptyset\), \(\{H_{4}\}\) or \(\{H_{1}\}\), then there are two maximal cliques: \(\{X_{1},X_{2},X_{3},X_{5}\}\) and \(\{X_{2},X_{3},X_{4},X_{5}\}\). When the intervention target \(I\) is \(\{H_{2}\}\), then there are three maximal cliques: \(\{X_{1},X_{5}\}\), \(\{X_{4}\}\) and \(\{X_{2},X_{3},X_{5}\}\). When the intervention target is \(\{H_{3}\}\), then there are three maximal cliques: \(\{X_{2},X_{4}\}\), \(\{X_{3},X_{5}\}\) and \(\{X_{1},X_{2},X_{5}\}\). Both \(\{X_{2}\}\) and \(\{X_{2},X_{5}\}\) are maximal valid subsets. But \(\{X_{2},X_{5}\}\) is imaginary. One might be tempted to add another edge \(H_{2}\to X_{5}\) which would create a clique of \(\{X_{2},X_{4},X_{5}\}\) when intervening on \(H_{3}\).

Figure 8: In this example, \(\{X_{2}\}\) is a maximal valid subset and is contained in another maximal valid subset \(\{X_{1},X_{2}\}\)

### Single source node

It can be shown that imaginary subsets do not exist if there is only one single hidden source node, i.e. a hidden variable such that \(\operatorname{pa}(H_{i})=\emptyset\). Note that this still allows for arbitrarily many hidden variables \(|H|>1\).

For any two observed variables \(X_{a}\) and \(X_{b}\). Let \(P^{(a,b)}\) be the set of all active paths between \(X_{a}\) and \(X_{b}\) in \(G^{(\emptyset)}\).

**Definition D.1** (Dominated path).: An active path \(P\) between \(X_{a}\) and \(X_{b}\) is called a \((X_{a},X_{b})\)-dominated path if either of the followings is true:

1. \(P\) is a common parent path (i.e., \(P\) is \(X_{a}\gets H_{k}\to X_{b}\) for some hidden variable \(H_{k}\)) and every directed path to \(\operatorname{so}(P)\) has at least one node \(H_{i}\neq H_{k}\) such that such that \(\{X_{a},X_{b}\}\subseteq\operatorname{ch}_{X}(H_{i})\).
2. \(P\) is not a common parent path and (a) every directed path to \(\operatorname{so}(P)\) has at least one node \(H_{i}\) such that \(\{X_{a},X_{b}\}\subseteq\operatorname{ch}_{X}(H_{i})\) or (b) there exists a hidden node \(H_{j}\) in \(P\) such that \(X_{a}\gets H_{j}\to X_{b}\) is a non-\((X_{a},X_{b})\)-dominated path (see (1)).

_Remark D.1_.: We consider the empty path from \(H_{i}\) to \(H_{i}\) as a directed path.

_Remark D.2_.: To slightly abuse notation, when \(\operatorname{so}(P)\) only has one element, we also use \(\operatorname{so}(P)\) to mean that element.

Appendix D.2.1 gives some lemmas to characterize dominated paths.

**Theorem 4.4**.: _Under Assumptions 1-2, if \(G_{H}\) has one latent source, there are no imaginary subsets._

Proof.: Suppose there is an imaginary subset \(X^{\prime}\). Then it must have at least three elements in it. If \(|X^{\prime}|=1\), then it must be a subset of \(\operatorname{ch}_{X}(H_{i})\) for some \(H_{i}\). If \(|X^{\prime}|=2\), then these two nodes do not share the same parent. Thus, there must exist at least two active paths between them in \(G^{(\emptyset)}\) because of Lemma E.4. By definition, these two active paths are non-dominated. But because there is only one single source node in the latent DAG, by Proposition D.5, this is not possible.

For every pair of nodes in \(X^{\prime}\), there could only be one non-dominated path between them because the necessary conditions in Proposition D.5 cannot be satisfied when there is only one single source node and Lemma D.1 shows that there is at least one non-dominated path.

By Proposition D.6, \(X^{\prime}\) cannot be imaginary. 

#### d.2.1 Key lemmas and propositions for proving Theorem 4.4

The following two lemmas characterize dominated paths.

**Lemma D.1**.: _If \(X_{a}\) and \(X_{b}\) are \(d\)-connected in \(G^{(\emptyset)}\), then \(P^{(a,b)}\) has at least one non-\((X_{a},X_{b})\)-dominated path._

Proof.: Because \(X_{a}\) and \(X_{b}\) are \(d\)-connected in \(G^{(\emptyset)}\), by definition, \(P^{(a,b)}\) is not empty.

Now let's consider two cases:

Figure 9: In this example, \(\{X_{2}\}\) is a maximal valid subset and is contained in another maximal valid subset \(\{X_{2},X_{5}\}\) even though \(\{X_{2}\}\) is the child set of \(H_{2}\).

1. There exists at least one hidden node that is a common parent of \(X_{a}\) and \(X_{b}\). Without loss of generality, let \(H_{1}\) be a common parent of \(X_{a}\) and \(X_{b}\). Because there is no circle and there is only a finite number of hidden variables, there exists a hidden variable \(H_{2}\) that could be \(H_{1}\) or an ancestor of \(H_{1}\) such that \(\{X_{a},X_{b}\}\subseteq\mathrm{ch}_{X}(H_{2})\) and \(H_{2}\) does not have an ancestor such that both \(X_{a}\) and \(X_{b}\) are its children. By definition, \(X_{a}\gets H_{2}\to X_{b}\) is non-\((X_{a},X_{b})\)-dominated.
2. There is no hidden node that is a common parent of \(X_{a}\) and \(X_{b}\). Then every path in \(P^{(a,b)}\) is non-\((X_{a},X_{b})\)-dominated. Because \(P^{(a,b)}\) is not empty, \(P^{(a,b)}\) has at least one non-\((X_{a},X_{b})\)-dominated path.

**Lemma D.2**.: _If \(\{X_{a},X_{b}\}\) is a valid subset and \(P^{a,b}\) has only one non-\((X_{a},X_{b})\)-dominated path, then the non-\((X_{a},X_{b})\)-dominated path must be a common parent path._

Proof.: Let's consider two cases:

1. There is no hidden node that is a common parent of \(X_{a}\) and \(X_{b}\). Because \(\{X_{a},X_{b}\}\) is a valid subset, there must exist at least two active paths between \(X_{a}\) and \(X_{b}\) in \(G^{\emptyset}\). Otherwise, by Lemma E.4, \(X_{a}\) and \(X_{b}\) must be \(d\)-separated for an intervention target. By definition, any active paths between \(X_{a}\) and \(X_{b}\) are non-\((X_{a},X_{b})\)-dominated paths. So, this case is not possible.
2. There exists at least one hidden node that is a common parent of \(X_{a}\) and \(X_{b}\). Without loss of generality, let \(H_{1}\) be a common parent of \(X_{a}\) and \(X_{b}\). If the active path \(X_{a}\gets H_{1}\to X_{b}\) is \((X_{a},X_{b})\)-dominated, we can find an ancestor of \(H_{1}\) called \(H_{2}\) such that \(\{X_{a},X_{b}\}\subseteq\mathrm{ch}_{X}(H_{2})\). Because there is only a finite number of hidden variables and there is no circle, we can eventually find a common parent \(H^{\prime}\) of \(X_{a}\) and \(X_{b}\) such that \(X_{a}\gets H^{\prime}\to X_{b}\) is a non-\((X_{a},X_{b})\)-dominated path. Therefore at least one of the non-\((X_{a},X_{b})\)-dominated paths is a common parent path. And if there is only one non-\((X_{a},X_{b})\)-dominated path, it must be a common parent path.

**Lemma D.3**.: _For any two nodes \(X_{a}\) and \(X_{b}\) where \(P^{a,b}\) has only one non-\((X_{a},X_{b})\)-dominated path \(P_{*}\), then there does not exist a directed path from \(H_{1}\) to \(H_{2}\) with either \(H_{1}\to X_{a},H_{2}\to X_{b}\) or \(H_{2}\to X_{a},H_{1}\to X_{b}\) such that \(\mathrm{so}(P)\in\mathrm{de}(H_{2})\)._

Proof.: By Lemma D.2, \(P_{*}\) is a common parent path. Let \(H_{*}\) be the common parent. Now here are two cases:

1. \(H_{1}=H_{2}\). In this case, \(P_{*}\) would not be a non-dominated path by definition. So this is not possible.
2. \(H_{1}\neq H_{2}\). Because this path is dominated, then either (a) \(H_{*}\) must be on this path or (b) there exists a common parent of \(X_{a},X_{b}\): \(H^{\prime}\) such that \(H^{\prime}\in\overline{\mathrm{an}}(H_{1})\). Case (a) is not possible because \(H_{*}\in\mathrm{de}(H_{2})\). Case (b) is also not possible by Lemma D.4.

**Lemma D.4**.: _For any two nodes \(X_{a}\) and \(X_{b}\) where \(P^{a,b}\) has only one non-\((X_{a},X_{b})\)-dominated path \(P_{*}\), for any hidden node \(H^{\prime}\) that is a common parent of \(X_{a},X_{b}\) and not the same as \(\mathrm{so}(P_{*})\), \(\mathrm{so}(P_{*})\) is an ancestor of \(H^{\prime}\)._

Proof.: Suppose \(\mathrm{so}(P_{*})\) is not an ancestor of \(H^{\prime}\). Then because \(X_{a}\gets H^{\prime}\gets X_{b}\) is a \((X_{a},X_{b})\)-dominated path, and there is only a finite number of hidden variables, we can eventually find a common parent \(H^{\prime\prime}\) of \(X_{a}\) and \(X_{b}\) such that \(X_{a}\gets H^{\prime\prime}\to X_{b}\) is a non-\((X_{a},X_{b})\)-dominated path. But \(\mathrm{so}(P_{*})\) is not an ancestor of \(H^{\prime}\). So it cannot be \(H^{\prime\prime}\). This is a contradiction to the fact that \(P^{a,b}\) has only one non-\((X_{a},X_{b})\)-dominated path.

**Proposition D.5**.: _If \(\{X_{a},X_{b}\}\subseteq X^{\prime}\) where \(X^{\prime}\) is an imaginary subset and \(P^{(a,b)}\) has at least two non-\((X_{a},X_{b})\)-dominated paths, then the following two conditions hold:_

1. _There exists a pair of non-_ \((X_{a},X_{b})\)_-dominated paths_ \((P_{1},P_{2})\) _such that given any intervention target_ \(I\in\mathcal{I}\)_, at least one of_ \(P_{1}\) _and_ \(P_{2}\) _is active in_ \(G^{(I)}\)__
2. _For any pair of non-_ \((X_{a},X_{b})\)_-dominated paths_ \((P_{1},P_{2})\) _that satisfies (a), there does not exist a single hidden node_ \(H_{\#}\) _that is shared by all directed path to_ \(\operatorname{so}(P_{1})\) _and_ \(\operatorname{so}(P_{2})\) _in_ \(G^{(\emptyset)}\)_._

Proof.: First, let's prove the first condition. We consider two conditions:

1. There is no hidden node that is a common parent of \(X_{a}\) and \(X_{b}\). Because \(\{X_{a},X_{b}\}\) is a valid subset, there must exist at least two active paths between \(X_{a}\) and \(X_{b}\) in \(G^{(\emptyset)}\). Otherwise, by Lemma E.4, \(X_{a}\) and \(X_{b}\) must be \(d\)-separated for an intervention target. By definition, any active paths between \(X_{a}\) and \(X_{b}\) are non-\((X_{a},X_{b})\)-dominated paths.
2. There exists at least one hidden node that is a common parent of \(X_{a}\) and \(X_{b}\). Without loss of generality, let \(H_{1}\) be a common parent of \(X_{a}\) and \(X_{b}\). If the active path \(X_{a}\gets H_{1}\to X_{b}\) is \((X_{a},X_{b})\)-dominated, we can find an ancestor of \(H_{1}\) called \(H_{2}\) such that \(\{X_{a},X_{b}\}\subseteq\operatorname{ch}_{X}(H_{2})\). Because there is only a finite number of hidden variables and there is no circle, we can eventually find a common parent \(H^{\prime}\) of \(X_{a}\) and \(X_{b}\) such that \(X_{a}\gets H^{\prime}\to X_{b}\) is a non-\((X_{a},X_{b})\)-dominated path. Therefore at least one of the non-\((X_{a},X_{b})\)-dominated paths is a common parent path. Because \(P^{(a,b)}\) has at least two non-\((X_{a},X_{b})\)-dominated paths, and given any intervention target, the common parent path will not be destroyed, the first condition is true.

Let's denote \(P_{1}\) to be a non-\((X_{a},X_{b})\)-dominated active path with hidden variables \(H_{a,1}\) and \(H_{b,1}\) such that \(X_{a}\gets H_{a,1}\) and \(X_{b}\gets H_{b,1}\) are in \(P_{1}\). Let \(P_{2}\) to be an a non-\((X_{a},X_{b})\)-dominated active path with hidden variables \(H_{a,2}\) and \(H_{b,2}\) such that \(X_{a}\gets H_{a,2}\) and \(X_{b}\gets H_{b,2}\) are in \(P_{2}\).

Now let's prove the second condition. Suppose, on the contrary, there exists such a hidden node \(H_{\#}\). Because \(P_{1}\) and \(P_{2}\) are non-\((X_{a},X_{b})\)-dominated, there must exist one directed path to \(P_{1}\) and one directed path to \(P_{2}\) such that these two directed paths do not have any hidden node \(H_{i}\) with \(\{X_{a},X_{b}\}\subseteq\operatorname{ch}_{X}(H_{i})\), except for maybe \(\operatorname{so}(P_{1})\) and \(\operatorname{so}(P_{2})\). On the other hand, these two directed paths share at least one common node \(H_{\#}\). Let \(H_{*}\) be the common nodes with the lowest ranking in topological ordering. Then \(H_{*}\) has the property that, under any intervention target \(I\), one of the two directed paths \(P_{1,*}\) and \(P_{2,*}\), where \(P_{1,*}\) is the directed path from \(H_{*}\) to \(\operatorname{so}(P_{1})\) and \(P_{2,*}\) is the directed path from \(H_{*}\) to \(\operatorname{so}(P_{2})\), still exists. If this is not true, then there is one intervention target \(I_{*}\) such that intervening on this node would break \(P_{1,*}\) and \(P_{2,*}\). Then \(I_{*}\) would be a common node on \(P_{1,*}\) and \(P_{2,*}\) other than \(H_{*}\). This violates the assumption \(H_{*}\) has the lowest ranking in the topological ordering. Note that \(\operatorname{so}(P_{1})\) or \(\operatorname{so}(P_{2})\) only has one element in it by Lemma E.3.

We now have four paths \(P_{1}\), \(P_{2}\)\(P_{1,*}\) and \(P_{2,*}\). Under any intervention target \(I\), one of \(P_{1}\), \(P_{2}\) is active and one of \(P_{1,*}\) and \(P_{2,*}\) is still active. Let's consider the following three cases:

1. \(P_{1,*}\) has no shared hidden node with \(P_{2}\) and \(P_{2,*}\) has no shared hidden node with \(P_{1}\). First of all, \(H_{*}\) cannot be a common parent of \(X_{a}\) and \(X_{b}\). Suppose \(H_{*}\) is a common parent of \(X_{a}\) and \(X_{b}\). Then by our construction, it is only possible if \(H_{*}=\operatorname{so}(P_{1})\) and \(H_{*}=\operatorname{so}(P_{2})\). Because \(P_{1}\) and \(P_{2}\) are both non-dominated paths, they must both be common parent paths in this case. This would imply they are the same path, which is a contradiction. Note that by Lemma E.3, an active path between hidden nodes \(H_{1}\) and \(H_{2}\) can only be a common ancestor path or a directed path. Either way, there is only one source node of the path and every other node in the path is a descendant of that source node. Therefore, \(P_{1,*}\) cannot have a shared hidden node with \(P_{1}\) except for \(\operatorname{so}(P_{1})\), otherwise there will be a directed circle. Similarly, \(P_{2,*}\) cannot have a shared hidden node with \(P_{2}\) except for \(\operatorname{so}(P_{2})\). For any intervention target \(I\), there are three cases:1. None of \(P_{1}\), \(P_{2}\)\(P_{1,*}\) and \(P_{2,*}\) are affected by \(I\). Then all of \(H_{a,1},H_{a,2}\), \(H_{b,1},H_{b,2}\) are descendents of \(H_{*}\).
2. One of \(P_{1,*}\) and \(P_{2,*}\) is destroyed. Without loss of generality, suppose \(P_{2,*}\) no longer exists. The intervention target \(I\) must be a part of the path \(P_{2,*}\) and it cannot be \(H_{*}\). Because \(P_{2,*}\) has no shared hidden node with \(P_{1}\), intervening on \(I\) means that \(P_{1}\) is still intact. Therefore, \(H_{a,1},H_{b,1}\) are descendents of \(H_{*}\).
3. One of \(P_{1}\) and \(P_{2}\) is destroyed. Without loss of generality, suppose \(P_{2}\) no longer exists. The intervention target \(I\) must be a part of the path \(P_{2}\) and it cannot be \(\operatorname{so}(P_{2})\). Therefore, \(P_{1,*}\) is still intact. \(H_{a,1},H_{b,1}\) are descendents of \(H_{*}\).

Finally, in all three cases, at least one pair of \((H_{a,1},H_{b,1})\) and \((H_{a,2},H_{b,2})\) is a set of descendants of \(H_{*}\). Now consider graph \(G^{\prime}=(V,E^{\prime})\) with \(E^{\prime}=E\cup\{H_{*}\to X_{a}\}\cup\{H_{*}\to X_{b}\}\). Note that \(E^{\prime}\) is not the same as \(E\) because at least one of \(\{H_{*}\to X_{a}\}\) and \(\{H_{*}\to X_{b}\}\) is missing. Otherwise, \(H_{*}\) would be a common parent of \(X_{a}\) and \(X_{b}\). By Lemma D.15, \(G^{\prime}\) violates the maximality.
2. Without loss of generality, \(P_{1,*}\) has shared hidden nodes with \(P_{2}\) and \(P_{1}\) is not a common parent path.

Note that in this case, \(P_{2,*}\) cannot have a shared hidden node with \(P_{1}\) except for one special case. Suppose the opposite is true. Let the shared node between \(P_{1,*}\) and \(P_{2}\) be \(H_{1}\). Let the shared node between \(P_{2,*}\) and \(P_{1}\) be \(H_{2}\). There must be a circle between \(H_{1}\) and \(H_{2}\) if \(H_{1}\neq H_{2}\) which is a contradiction. If \(H_{1}=H_{2}\), then \(H_{1}=H_{2}=\operatorname{so}(P_{1})=\operatorname{so}(P_{2})\). In this case, there is always at least one pair of \((H_{a,1},H_{b,1})\) and \((H_{a,2},H_{b,2})\) that is a set of descendants of \(\operatorname{so}(P_{1})\) and \(\operatorname{so}(P_{2})\) under any intervention target. In this case, adding \(\{X_{a},X_{b}\}\) to \(\operatorname{ch}_{X}(\operatorname{so}(P_{1}))\) would not change \(\Omega_{G}^{(I)}\) by the proof of Lemma D.15. By Lemma D.17, this is not possible. So we will ignore this special case.

Now let's consider the following cases under any intervention target \(I\) for when \(P_{2,*}\) does not have a shared hidden node with \(P_{1}\):

1. None of \(P_{1}\), \(P_{2}\)\(P_{1,*}\) and \(P_{2,*}\) are affected by \(I\). Then \(H_{a,1},H_{b,1}\) are descendents of \(\operatorname{so}(P_{1})\).
2. \(P_{1,*}\) is destroyed. Then \(P_{1}\) must be intact because the intervention target is in \(P_{1,*}\). \(H_{a,1},H_{b,1}\) are descendents of \(\operatorname{so}(P_{1})\).
3. \(P_{2,*}\) is destroyed. Because \(P_{2,*}\) does not have a shared hidden node with \(P_{1}\), \(H_{a,1},H_{b,1}\) are descendents of \(\operatorname{so}(P_{1})\).
4. \(P_{2}\) is destroyed. Then \(P_{1}\) must be intact. Then \(H_{a,1},H_{b,1}\) are descendents of \(\operatorname{so}(P_{1})\).
5. \(P_{1}\) is destroyed. Then \(P_{2}\) must be intact. \(P_{1,*}\) must also be intact because the intervention target is in \(P_{1}\) and it is not \(\operatorname{so}(P_{1})\). Because \(P_{2,*}\) cannot have a shared hidden node with \(P_{1}\), \(P_{2,*}\) is also active. Therefore, \(H_{a,2},H_{b,2}\) are connected to \(\operatorname{so}(P_{1})\) via the common ancestor \(H_{*}\).

Let's consider graph \(G^{\prime}=(V,E^{\prime})\) with \(E^{\prime}=E\cup\{\operatorname{so}(P_{1})\to X_{a}\}\cup\{\operatorname{so}(P_ {1})\to X_{b}\}\). Note that \(E^{\prime}\) is not the same as \(E\) because at least one of \(\{\operatorname{so}(P_{1})\to X_{a}\}\) and \(\{\operatorname{so}(P_{1})\to X_{b}\}\) is missing because \(P_{1}\) is not a common parent path and \(P_{1}\) is also non-\((X_{a},X_{b})\)-dominated.

For any intervention target \(I\) that induces \((a),(b),(c),(d)\), adding \(\{X_{a},X_{b}\}\) to \(\operatorname{ch}_{X}(\operatorname{so}(P_{1}))\) would not change \(\Omega_{G}^{(I)}\) by the proof of Lemma D.15.

For any intervention target \(I\) that induces \((e)\), \(D(G^{\prime I})\) does not have more edges than \(D(G^{I})\). If the opposite is true, then the new edge in \(D(G^{\prime I})\) must involve the added node \(X_{a}\) or \(X_{b}\). Without loss of generality, suppose the new edge is between \(X_{a}\) and \(X_{k}\), it must be that a parent of \(X_{k}\) is \(d\)-connected to \(\operatorname{so}(P_{1})\). Suppose that the parent of \(X_{k}\) is \(H_{k}\). By Lemma E.3, there are 2 cases. If \(\operatorname{so}(P_{1})\) has a directed path to \(H_{k}\), then \(H_{k}\) is connected to \(X_{a}\) and \(X_{b}\) via the common ancestor \(H_{*}\). If \(H_{k}\) has a directed path to \(\operatorname{so}(P_{1})\) or \(H_{k}\) and \(\operatorname{so}(P_{1})\) share a common ancestor, by our assumption, \(H_{k}\) and \(\{X_{a},X_{b}\}\) are connected by common ancestor \(H_{\#}\). Therefore, \(X_{k}\) and \(X_{a}\) are \(d\)-connected in \(D(G^{I})\).

So adding \(\{X_{a},X_{b}\}\) to \(\operatorname{ch}_{X}(\operatorname{so}(P_{1}))\) would not change \(\Omega_{G}^{(I)}\).

Finally, by Lemma D.17, this is not possible.

3. Without loss of generality, \(P_{1,*}\) has shared hidden nodes with \(P_{2}\) and \(P_{1}\) is a common parent path. Let \(H_{!}\) be the shared node between \(P_{1,*}\) and \(P_{2}\) that has the lowest topological ranking. Therefore, for any intervention target \(I\), at least one of \(P_{2}\) and the directed path from \(H_{!}\) to \(\operatorname{so}(P_{1})\) is intact. Otherwise, \(H_{!}\) is not the shared node between \(P_{1,*}\) and \(P_{2}\) that has the lowest topological ranking. First, let's consider two scenarios. 1. Both \(P_{1}\) and \(P_{2}\) are common parent paths. First of all, \(\operatorname{so}(P_{1})\) is not the same as \(\operatorname{so}(P_{2})\). Otherwise, \(P_{1}\) and \(P_{2}\) would be the same path. On the other hand, if \(\operatorname{so}(P_{2})\) appears in \(P_{1,*}\) because there is the only possible node that can be shared and is not \(\operatorname{so}(P_{1})\), it would violate how \(P_{1,*}\) is chosen. So this scenario is not possible. 2. \(P_{1}\) is a common parent path and \(P_{2}\) is not. First, \(H_{!}\) is not the same as \(\operatorname{so}(P_{1})\) because \(H_{!}\) is also on \(P_{2}\) which is a non-\((X_{a},X_{b})\)-dominated path. By definition, this is not possible. On the other hand, \(H_{!}\) is not a common parent of \(X_{a}\) and \(X_{b}\) because it would violate how \(P_{1,*}\) is chosen. We'll study this scenario next. Similar to the previous case, \(P_{2,*}\) cannot have a shared hidden node with \(P_{1}\). Now let's consider the following cases under any intervention target \(I\): 1. None of \(P_{1}\), \(P_{2}\)\(P_{1,*}\) and \(P_{2,*}\) are affected by \(I\). Then \(H_{a,1},H_{b,1}\) are descendents of \(H_{!}\). 2. \(P_{2,*}\) is destroyed. Because \(P_{2,*}\) does not have a shared hidden node with \(P_{1}\), \(H_{a,1},H_{b,1}\) are descendents of \(H_{!}\). 3. \(P_{2}\) is destroyed. Then the directed path from \(H_{!}\) to \(\operatorname{so}(P_{1})\) is still intact. Then \(H_{a,1},H_{b,1}\) are descendents of \(H_{!}\). 4. \(P_{1,*}\) is destroyed but the directed path from \(H_{!}\) to \(\operatorname{so}(P_{1})\) is still intact. Then \(P_{1}\) must be intact because the intervention target is in \(P_{1,*}\). \(H_{a,1},H_{b,1}\) are descendents of \(H_{!}\). 5. \(P_{1}\) is destroyed or the the directed path from \(H_{!}\) to \(\operatorname{so}(P_{1})\) is destroyed. In either case, \(P_{2}\) must be intact. The directed path from \(H_{*}\) to \(H_{!}\) must also be intact. Because \(P_{2,*}\) cannot have a shared hidden node with \(P_{1}\) or \(P_{1,*}\), \(P_{2,*}\) is also active. Therefore, \(H_{a,2},H_{b,2}\) are connected to \(H_{!}\) via the common ancestor \(H_{*}\). Now consider graph \(G^{\prime}=(V,E^{\prime})\) with \(E^{\prime}=E\cup\{H_{!}\to X_{a}\}\cup\{H_{!}\to X_{b}\}\). Note that \(E^{\prime}\) is not the same as \(E\) because at least one of \(\{H_{!}\to X_{a}\}\) and \(\{H_{!}\to X_{b}\}\) is missing. By the same argument as fore, \(G^{\prime}\) also violates the maximality assumption by Lemma D.17.

Finally, we have a contradiction. So the second condition is also necessary. 

**Proposition D.6**.: _Suppose \(X^{\prime}\subseteq X\) is a valid subset with \(|X^{\prime}|\geq 2\) and every pair of nodes in \(X^{\prime}\) has only one non-dominated path. And the latent DAG only has one source node. Then the followings are true:_

1. _there exists a hidden node_ \(H^{\prime}\) _with_ \(X^{\prime}\subseteq\operatorname{ch}_{X}(H^{\prime})\)__
2. _for any node_ \(X_{i}\in X^{\prime}\)_, one can find at least another node_ \(X_{j}\in X^{\prime}\) _such that_ \(X_{i}\gets H^{\prime}\to X_{j}\) _is a non-_\((X_{i},X_{j})\)_-dominated path._

Proof.: We'll show this by induction.

Base step:This is true because of Lemma D.2.

Inductive Hypothesis:Suppose the statement is true for all \(X^{\prime}\) with \(|X^{\prime}|=k\).

Inductive Step:We will show the statement is true for \(|X^{\prime}|=k+1\). Without loss of generality, let's suppose \(X^{\prime}=\{X_{1},...,X_{k+1}\}\). Consider the subset \(X^{\prime\prime}=\{X_{1},...,X_{k}\}\). By the inductive hypothesis, there exists a hidden node \(H^{\prime}\) with \(X^{\prime}\subseteq\operatorname{ch}_{X}(H^{\prime})\) and again without loss of generality, two nodes \(X_{1}\) and \(X_{2}\), such that \(X_{1}\gets H^{\prime}\to X_{2}\) is a non-\((X_{1},X_{2})\)-dominated path.

Now consider another subset \(X_{1,k+1}=\{X_{1},X_{k+1}\}\). By our assumption and Lemma D.2, there exists a hidden node \(H_{1,k+1}\) such that \(X_{1}\gets H_{1,k+1}\to X_{k+1}\) is a non-\((X_{1},X_{k+1})\)-dominated path. We can define \(H_{2,k+1}\) in a similar way.

If \(H_{1,k+1}=H^{\prime}\), then we are done.

Let's now consider the cases when \(H_{1,k+1}\neq H^{\prime}\). Because there is only one single source node, there must exist at least one common ancestor of \(H_{1,k+1}\) and \(H^{\prime}\): \(H_{*}\). Now let's consider three cases:

1. \(H_{1,k+1}\) is an ancestor of \(H^{\prime}\). Then there is a directed path \(P\) from \(H_{1,k+1}\) to \(H^{\prime}\). Now we have an active path between \(X_{2}\) and \(X_{k+1}\) via \(P\). Because this path is \((X_{2},X_{k+1})\)-dominated, we have a few cases. 1. There exists a common parent of \(X_{2}\), \(X_{k+1}\) that is in \(\overline{\mathrm{an}}(H_{1,k+1})\), which means that \(H_{2,k+1}\) is an ancestor of \(H_{1,k+1}\) by Lemma D.4 (case (c) covers when \(H_{2,k+1}=H_{1,k+1}\)). By Lemma D.3, this is not possible because we have a path between \(X_{1}\) and \(X_{2}\) via the directed path from \(H_{2,k+1}\) to \(H_{1,k+1}\) but \(H^{\prime}\) is a descendent of \(H_{1,k+1}\). 2. \(H_{2,k+1}\) is on \(P\) but it is not the same as \(H_{1,k+1}\) nor \(H^{\prime}\). By the same argument as the case (a), this is also not possible because of Lemma D.3. 3. \(H_{2,k+1}=H_{1,k+1}\). This means that \(H_{1,k+1}\) is a common parent of \(X_{1},X_{2}\). So it cannot be an ancestor of \(H^{\prime}\). This is a contradiction. 4. When \(H_{2,k+1}=H^{\prime}\), then \(H^{\prime}\) is the hidden node we are looking for because \(X^{\prime}\subseteq\mathrm{ch}_{X}(H^{\prime})\) and for any node \(X_{i}\in X^{\prime}\), there exists another node \(X_{j}\in X^{\prime}\) such that \(X_{i}\gets H^{\prime}\to X_{j}\) is a non-\((X_{i},X_{j})\)-dominated path (for \(X_{k+1}\), one can choose \(X_{2}\) such that \(X_{2}\gets H^{\prime}\to X_{k+1}\) is a non-dominated path).
2. \(H^{\prime}\) is an ancestor of \(H_{1,k+1}\). Then there is a directed path \(P\) from \(H^{\prime}\) to \(H_{1,k+1}\). Let \(X_{q}\) be an arbitrary node in \(X^{\prime\prime}\) that is not \(X_{1}\). Then we can define hidden node \(H_{q,k+1}\) such that \(X_{q}\gets H_{q,k+1}\to X_{k+1}\) is a non-\((X_{q},X_{k+1})\)-dominated path. Now we have an active path between \(X_{q}\) and \(X_{k+1}\) via \(P\). Because this path is \((X_{q},X_{k+1})\)-dominated, we have a few cases. 1. There exists a common parent of \(X_{q}\), \(X_{k+1}\) that is in \(\overline{\mathrm{an}}(H^{\prime})\), which means that \(H_{q,k+1}\) is an ancestor of \(H^{\prime}\) by Lemma D.4 (case (c) covers when \(H_{q,k+1}=H^{\prime}\)). By Lemma D.3. This is not possible because we have a path between \(X_{1}\) and \(X_{k+1}\) via the directed path from \(H_{q,k+1}\) to \(H^{\prime}\) but \(H_{1,k+1}\) is a descendent of \(H^{\prime}\). 2. \(H_{q,k+1}\) is on \(P\) but it is not the same as \(H_{1,k+1}\) nor \(H^{\prime}\). By the same argument as the case (a), this is also not possible because of Lemma D.3. 3. \(H_{q,k+1}=H^{\prime}\). This means \(H^{\prime}\) is a common parent of \(X_{1},X_{k+1}\). So it cannot be an ancestor of \(H_{1,k+1}\). This is a contradiction. 4. \(H_{q,k+1}=H_{1,k+1}\). This is possible. But because \(X_{q}\) is chosen arbitrarily. We have \(H_{q,k+1}=H_{1,k+1}\) for \(q=2,...,k\). Therefore \(X^{\prime}\subseteq\mathrm{ch}_{X}(H_{1,k+1})\). And for any node \(X_{i}\neq X_{k+1}\), we have that \(X_{i}\gets H_{1,k+1}\to X_{k+1}\) is a non-dominated path.
3. There exist a common ancestor \(H_{*}\) that is neither \(H_{1,k+1}\) nor \(H^{\prime}\), \(H^{\prime}\) is not an ancestor of \(H_{1,k+1}\) and \(H_{1,k+1}\) is not an ancestor of \(H^{\prime}\). \(H_{*}\) is a common ancestor of \(X_{2}\) and \(X_{k+1}\). Therefore, there is a common ancestor path between \(X_{2}\) and \(X_{k+1}\). But this path is a \((X_{2},X_{k+1})\)-dominated path. There are two cases: (a) \(H_{2,k+1}\in\overline{\mathrm{an}}(H_{1,k+1})\) when \(H_{2,k+1}\) is on the directed path from \(H_{*}\) to \(H_{1,k+1}\) or there is another common parent of \(X_{2}\), \(X_{k+1}\) that is in \(\overline{\mathrm{an}}(H_{*})\) (Lemma D.4), (b) \(H_{2,k+1}\in\overline{\mathrm{an}}(H^{\prime})\) when \(H_{2,k+1}\) is on the directed path from \(H_{*}\) to \(H^{\prime}\) or there is another common parent of \(X_{2},X_{k+1}\) that is in \(\overline{\mathrm{an}}(H_{*})\) (Lemma D.4). For case (a), we have a \((X_{1},X_{2})\)-dominated path cased by the path from \(H_{2,k+1}\) to \(H_{1,k+1}\). In this case, because \(X_{1}\gets H^{\prime}\to X_{2}\) is a non-\((X_{1},X_{2})\)-dominated path. \(H^{\prime}\) must be an ancestor for \(H_{1,k+1}\), which is a contradiction. By a similar argument, case (b) is also not possible.

### Fractured subset condition

A necessary condition for a non-replaceable imaginary subset is that the subset is fractured. The definition is restated below. Intuitively, a fractured subset provides redundant information as every connection between nodes in the fractured subset can be explained by other maximal valid subsets.

**Definition 4.5** (Fractured subset).: Given a collection of maximal valid subsets \(\mathcal{S}\), a clique \(C\) is called **shattered by \(\mathcal{S}\)** if there exists a subset \(\mathcal{S}^{\prime}\subseteq\mathcal{S}\) such that \(\cup\mathcal{S}^{\prime}=C\). A collection of maximal valid subsets \(\{S_{i}\}_{i=1}^{\mathcal{S}}\) is **complete** if for every intervention target \(I\in\mathcal{I}\), all shattered cliques in \(D(P^{(I)})\) form an edge cover of \(D(P^{I})\). A maximal valid subset \(X^{\prime}\subseteq X\) is **fractured** if there exists a complete collection \(\{S_{i}\}_{i=1}^{k}\) such that \(S_{i}\not\subseteq X^{\prime}\) for all \(S_{i}\).

The aforementioned necessity is shown by the following:

**Lemma 4.6**.: _If a subset \(X^{\prime}\subseteq X\) is imaginary, then \(X^{\prime}\) is also fractured._

Proof.: By Lemma D.16, we know that \(\{\operatorname{ch}_{X}(H_{i})\}_{i=1}^{m}\) is a complete cover. And because \(X^{\prime}\) is an imaginary subset, \(X^{\prime}\not\subseteq\operatorname{ch}_{X}(H_{i})\) for any \(H_{i}\). 

One might suggest getting rid of all fractured subsets. However, even a non-imaginary subset can be a fractured subset (Example 9).

**Example 9** (Non-imaginary set can be fractured).: Consider Figure 10. If the intervention target \(I\) is \(\{H_{1}\}\), \(\{H_{2}\}\), \(\emptyset\), then we have two maximal cliques: \(\{X_{1},X_{3},X_{4},X_{5},X_{6},X_{7}\}\), \(\{X_{2},X_{3},X_{4},X_{5},X_{6},X_{7}\}\). If the intervention target \(I\) is \(\{H_{3}\}\), then there are three maximal cliques: \(\{X_{3},X_{5},X_{7}\}\), \(\{X_{2},X_{4},X_{5},X_{6},X_{7}\}\), \(\{X_{1},X_{4},X_{5},X_{6},X_{7}\}\). If the intervention target \(I\) is \(\{H_{4}\}\), then there are three maximal cliques: \(\{X_{4},X_{6},X_{7}\}\), \(\{X_{2},X_{3},X_{5},X_{6},X_{7}\}\), \(\{X_{1},X_{3},X_{5},X_{6},X_{7}\}\). When the intervention target is \(\{H_{5}\}\), there are three maximal cliques: \(\{X_{1},X_{5},X_{6}\}\), \(\{X_{2},X_{5},X_{6}\}\), \(\{X_{3},X_{4},X_{5},X_{6},X_{7}\}\). By Proposition 4.1, all these five valid subsets are maximal: \(\{X_{1},X_{5},X_{6}\}\), \(\{X_{2},X_{5},X_{6}\}\), \(\{X_{3},X_{5},X_{7}\}\), \(\{X_{4},X_{6},X_{7}\}\) and \(\{X_{5},X_{6},X_{7}\}\). But \(\{X_{5},X_{6},X_{7}\}\) is fractured. In fact, \(\{X_{1},X_{5},X_{6}\}\), \(\{X_{2},X_{5},X_{6}\}\), \(\{X_{3},X_{5},X_{7}\}\), \(\{X_{4},X_{6},X_{7}\}\) constitutes a complete collection of maximal valid subsets.

Even under the maximality condition, it is still possible that two DAGs can share the same UDG (Example 10). The no fractured subset condition captures such ambiguities but is overkill.

Figure 11: An example where two maximal measurement models share the same UDG

Figure 10: In this example, the non-imaginary subset \(\{X_{5},X_{6},X_{7}\}\) is fractured

**Example 10**.: Consider Figure 11. For both \(G_{(a)}\) and \(G_{(b)}\), under any intervention target, there are four maximal cliques: \(\{X_{1},X_{4},X_{5}\}\), \(\{X_{2},X_{5},X_{6}\}\), \(\{X_{3},X_{4},X_{6}\}\), \(\{X_{4},X_{5},X_{6}\}\). And one can check that both \(G_{(a)}\) and \(G_{(b)}\) satisfy the maximality condition.

### Pure child assumption

We can also use the pure child assumption (Assumption 3) to get identifiability. The pure child assumption has been made in many existing works [6, 22, 66] with additional parametric assumptions to get identifiability.

**Assumption 3** (Pure child).: For every \(H_{i}\in H\), there exists at least one \(X_{i}\in X\) with \(\mathrm{pa}(X_{i})=\{H_{i}\}\), i.e. \(X_{i}\) only has one parent and that parent is \(H_{i}\).

Note that under Assumption 3, there still could be imaginary subsets.

**Example 11**.: Figure 12 satisfies Assumption 3 but there is an imaginary subset \(\{X_{5},X_{6}\}\).

**Theorem 4.8**.: _Under Assumptions 1-3, the complete collection (cf. Definition 4.5) with the smallest cardinality is exactly \(\{\mathrm{ch}_{X}(H_{i})\}_{i=1}^{m}\) and thus \(G_{B}\) can be identified._

Proof.: By Assumption 1(a) and Assumption 1(b), two observed variables \(X_{i}\) and \(X_{j}\) are dependent if and only if \(X_{i}\) and \(X_{j}\) are \(d\)-connected. Therefore, \(D(G^{(I)})\) is the same as \(D(P^{(I)})\) under any intervention target \(I\).

By Assumption 3, let's associate each hidden node \(H_{i}\) with one pure child \(X_{i}\).

First of all, there does not exist an imaginary subset with two pure children \(X_{i}\) and \(X_{j}\) of different hidden parents. If the opposite is true, then \(\{X_{i},X_{j}\}\) must be valid which is impossible by Lemma D.14. Therefore, every complete collection must have at least \(m\) maximal subsets.

By Lemma D.16, \(\{\mathrm{ch}_{X}(H_{i})\}_{i=1}^{m}\) is a complete collection with \(m\) maximal subsets.

In fact, \(\{\mathrm{ch}_{X}(H_{i})\}_{i=1}^{m}\) is the only complete collection with \(m\) maximal subsets. Suppose there exists a complete collection with imaginary subsets. There are two cases:

1. None of the imaginary subsets contains a pure child. Then we still need at least \(m\) non-imaginary subsets to cover pure children.
2. At least one of the imaginary subsets contains a pure child. Suppose one such imaginary subset is \(S_{i}\) and it contains \(X_{i}\). Then there must exist another maximal subset from the collection that contains \(X_{i}\). Suppose the opposite is true. Because \(S_{i}\) is an imaginary subset, there exists \(X_{k}\in S_{i}\) such that \(X_{k}\) and \(X_{i}\) do not share the same parent. And for any intervention target \(I\), if there is any edge between \(X_{i}\) and \(X_{j}\) in \(D(G^{(I)})\), by definition, there exists a shattered clique \(C\in D(G^{(I)})\) such that \(\{X_{i},X_{j}\}\subseteq C\) and \(S_{i}\subseteq C\). Therefore, there is an edge between \(X_{j}\) and \(X_{k}\) as well. Now consider graph \(G^{\prime}=(V,E^{\prime})\) where \(E^{\prime}=E\cup\{H_{i}\to X_{k}\}\). Under any intervention target \(I\), \(D(G^{\prime(I)})\) can only have more edges than \(D(G^{(I)})\) and if there exists a new edge, these edges must involve \(X_{k}\). Suppose one of these newly added edges is between \(X_{k}\) and \(X_{j}\). Then it must be that a parent of \(X_{j}\) is \(d\)-connected to \(H_{i}\). This would mean that \(X_{i}\) is \(d\)-connected to \(X_{j}\) in \(D(G^{(I)})\). By the previous argument, \(X_{k}\) is also \(d\)-connected to \(X_{j}\) in \(D(G^{(I)})\). Thus, \(G^{\prime}\) would violate the maximality condition by Lemma D.10 and Lemma D.17 which is a contradiction. Therefore, if there is one

Figure 12: In this example, the graph satisfies pure child but \(\{X_{5},X_{6}\}\) is an imaginary subset.

imaginary subset in the complete collection that contains a pure child, there must be at least two imaginary subsets that contain such a pure child. This means that to cover all \(m\) pure children, we need more than \(m\) maximal subsets.

On the other hand, suppose there exists a complete collection with at least one maximal subset \(X^{\prime}\) such that \(X^{\prime}\subseteq\operatorname{ch}_{X}(H_{i})\). Then \(X^{\prime}\) must not include the pure child of \(H_{i}\): \(X_{i}\). This is because, if \(X_{i}\in X^{\prime}\), then for any maximal clique \(C\in\Omega\) such that \(X^{\prime}\subseteq C\), we have that \(\{X_{i}\}\subseteq X^{\prime}\subseteq\operatorname{ch}_{X}(H_{i})\subseteq C\) because any node in \(C\setminus\{X_{i}\}\) is \(d\)-connected by \(X_{i}\) via \(H_{i}\) since \(X_{i}\) is a pure child. Therefore, \(X^{\prime}\) is not maximal which is a contradiction. Because \(X^{\prime}\) does not contain a pure child of \(H_{i}\), we still need to cover all \(m\) pure children. We need more than \(m\) maximal subsets. 

For algorithmic purposes, under the pure child assumption, one only needs to check if shattered maximal cliques form an edge cover.

**Lemma D.7**.: _Under Assumptions 1-3, for any intervention target \(I\), all maximal cliques \(C\in\Omega_{P}^{(I)}\) that is shattered by \(\{\operatorname{ch}_{X}(H_{i})\}_{i=1}^{m}\) is an edge cover of \(D(P^{(I)})\)._

Proof.: By Assumption 1(a) and Assumption 1(b), two observed variables \(X_{i}\) and \(X_{j}\) are dependent if and only if \(X_{i}\) and \(X_{j}\) are \(d\)-connected. Therefore, \(D(G^{(I)})\) is the same as \(D(P^{(I)})\) under any intervention target \(I\). By Assumption 3, let's associate each hidden node \(H_{i}\) with one pure child \(X_{i}\). Suppose the statement is not true. Then for some intervention target \(I\in\mathcal{I}\), there exists one clique \(C\) in \(\Omega_{G}^{(I)}\) that is not shattered and that clique contains one edge that is not covered by other shattered cliques in \(\Omega_{G}^{(I)}\). Suppose that edge is between \(X_{1}\) and \(X_{2}\), then there exist \(H_{1}\) and \(H_{2}\) with \(X_{1}\in\operatorname{ch}_{X}(H_{1})\) and \(X_{2}\in\operatorname{ch}_{X}(H_{2})\) and \(H_{1}\) is \(d\)-connected to \(H_{2}\). Let one such active path between \(H_{1}\) and \(H_{2}\) be \(P_{1,2}\). By Lemma E.3, there exists one source node \(\operatorname{so}(P_{1,2})\) (If \(H_{1}=H_{2}\), then \(\operatorname{so}(P_{1,2})\) is just \(H_{1}\)). Note that we can always find one node \(H_{*}\) in \(\overline{\operatorname{an}}(\operatorname{so}(P_{1,2})\) that has no incoming edge. Let's denote that the pure child of \(H_{*}\) is \(X_{*}\).

Then \(C_{*}=\cup_{H_{i}\in\overline{\operatorname{dec}}(H_{*})}\operatorname{ch}_{X} (H_{i})\) must be a shattered maximal clique in \(\Omega_{G}^{(I)}\). Suppose \(C_{*}\) is not a maximal clique. Then the maximal clique that contains \(C_{*}\) must contain another element \(X_{3}\) not in \(C_{*}\). There must exist another hidden variable \(H_{3}\) with \(X_{3}\in\operatorname{ch}_{X}(H_{3})\) that \(H_{*}\) is \(d\)-connected to because \(X_{3}\) is connected to the pure child of \(H_{*}\). But this is not possible by Lemma E.3 and the fact that \(H_{*}\) is a source node while \(X_{3}\) is not a descendant of \(H_{*}\).

### Examples of measurement model with no non-replaceable fractured subsets

Lemma 4.6 shows that an imaginary subset is a fractured subset. Because a replaceable imaginary subset can be found, our concern should focus solely on the non-replaceable ones (Theorem 4.3). In fact, Corollary 4.7 can be strengthed to say that as long as there are no non-replaceable fractured subsets, then the bipartite graph can be identified. In this section, we will show a class of measurement models with no non-replaceable fractured subsets (see Remark 4.1).

Let's first present a simple example where there are multiple source nodes and the pure child assumption is violated, and there is still no non-replaceable fractured subset.

**Example 12**.: Consider Figure 13. If the intervention target \(I\) is \(\emptyset\), \(H_{1}\) or \(H_{3}\), then two maximal cliques are \(\{X_{1},X_{2},X_{3}\}\) and \(\{X_{2},X_{3},X_{4}\}\). If the intervention target is \(H_{2}\), then there are three maximal clique: \(\{X_{1},X_{2}\}\), \(\{X_{2},X_{3}\}\) and \(\{X_{3},X_{4}\}\). One can easily check that there is no non-replaceable fractured subset.

Figure 13: In this example, there is no fractured set.

In fact, we can extend Figure 13 to a family of measurement models as follows:

**Definition D.2** (Sparse Measurement Model).: For a given measurement model \(G=(V,E)\) and \(V=X\cup H\), if \(X_{1},X_{2}\in X\) is \(d\)-connected, then it must be that

1. There exists at most one hidden node \(H_{i}\) such that \(\{X_{1},X_{2}\}\subseteq\mathrm{ch}_{X}(H_{i})\) (Type-1 path).
2. There exists at most one active path \(P\) between \(X_{1}\) and \(X_{2}\) such that \(\mathrm{pa}_{P}(X_{1})\neq\mathrm{pa}_{P}(X_{2})\) (Type-2 path).

And for any tuple \((X_{1},X_{2},X_{3})\subseteq X\) such that \(\{X_{1},X_{2}\}\subseteq\mathrm{ch}_{X}(H_{2})\) and \(\{X_{1},X_{3}\}\subseteq\mathrm{ch}_{X}(H_{3})\) with \(H_{2}\neq H_{3}\), \(X_{2}\) and \(X_{3}\) can only be \(d\)-connected via type-2 path \(P\) with the property that \(\mathrm{pa}_{P}(X_{2})=H_{2}\) and \(\mathrm{pa}_{P}(X_{3})=H_{3}\).

**Theorem D.8**.: _Under Assumptions 1-2 and with maximal sparse measurement model, there is no imaginary subset._

Proof.: Suppose there is an imaginary subset \(X^{\prime}\). Then \(|X^{\prime}|\geq 3\). If \(X^{\prime}\) has only one element, then it must be a subset of \(\mathrm{ch}_{X}(H^{\prime})\) for some hidden node \(H^{\prime}\). If \(X^{\prime}\) has two nodes, by the definition of sparse measurement, there could only be one active path between them and there exists an intervention target that can break this path. So \(X^{\prime}\) would not be valid.

Next, we'll use induction to show that for any valid subset \(X^{\prime}\) with \(|X^{\prime}|\geq 3\), there exists a hidden node \(H^{\prime}\) such that \(X^{\prime}\subseteq\mathrm{ch}_{X}(H^{\prime})\). In other words, \(X^{\prime}\) cannot be imaginary.

Base Step:If \(|X^{\prime}|=3\), then let \(X^{\prime}=\{X_{1},X_{2},X_{3}\}\). Suppose \(X^{\prime}\) is imaginary. Then every pair of nodes in \(X^{\prime}\) must have a type-1 path and a type-2 path because there exists an intervention target that can destroy the type-2 path but every pair of nodes is valid. Therefore, we have \(H_{1,2}\) as the common parent of \(X_{1},X_{2}\), \(H_{2,3}\) as the common parent of \(X_{2},X_{3}\) and \(H_{1,3}\) as the common parent of \(X_{1},X_{3}\). Note that these three hidden nodes are distinct, otherwise, \(X^{\prime}\) would not be imaginary. This is also not possible by the definition of the sparse measurement model.

Inductive Hypothesis:For any valid subset \(X^{\prime}\) with \(|X^{\prime}|=k\geq 3\), there exists a hidden node \(H^{\prime}\) such that \(X^{\prime}\subseteq\mathrm{ch}_{X}(H^{\prime})\).

Inductive Step:We'll show this is true for \(|X^{\prime}|=k+1\). Without loss of generality, suppose \(X^{\prime}=\{X_{1},...,X_{k+1}\}\). By the inductive hypothesis, \(X^{\prime\prime}=\{X_{1},...,X_{k}\}\) and \(X^{\prime\prime\prime}=\{X_{2},...,X_{k+1}\}\) are both non-imaginary. In other words, there exist \(H^{\prime\prime}\) and \(H^{\prime\prime\prime}\) such that \(X^{\prime\prime}\subseteq\mathrm{ch}_{X}(H^{\prime\prime})\) and \(X^{\prime\prime\prime}\subseteq\mathrm{ch}_{X}(H^{\prime\prime\prime})\). Because \(|X^{\prime}|\geq 4\), both \(H^{\prime\prime}\) and \(H^{\prime\prime\prime}\) are common parent of \(X_{2}\) and \(X_{3}\). By the definition of the sparse measurement model, \(H^{\prime\prime}=H^{\prime\prime\prime}\). 

**Theorem D.9**.: _Under Assumptions 1-2 and with maximal sparse measurement model, there is no non-replaceable fractured subset._

Proof.: By Theorem D.8, there is no imaginary subset. Therefore, if \(X^{\prime}\) is a maximal valid subset, then \(X^{\prime}\subseteq\mathrm{ch}_{X}(H_{i})\) for some hidden variable \(H_{i}\). By definition, if \(X^{\prime}\) is non-replaceable, there must exist a hidden variable \(H_{i}\) such that \(X^{\prime}=\mathrm{ch}_{X}(H_{i})\).

In addition, if \(X^{\prime}\) is fractured, there exists a complete collection \(\mathcal{S}=\{S_{j}\}_{j=1}^{k}\) such that \(S_{j}\not\subseteq X^{\prime}\) for all \(S_{j}\). Note for any \(S_{j}\), there exists a hidden node \(H_{j}\) such that \(S_{j}\subseteq\mathrm{ch}_{X}(H_{j})\) because there is no imaginary subset.

First of all, \(X^{\prime}\) must have at least two elements in it. If \(|X^{\prime}|=1\), then by the subset condition (Lemma C.1), no other hidden variable can be a parent of the single node in \(X^{\prime}\) and the aforementioned complete collection does not exist.

Let \(X_{1},X_{2}\) be two elements in \(X^{\prime}\). Because the measurement model is sparse, by Lemma E.4, there exists an intervention target \(I\) (could be the empty set) such that, the type-2 path between \(X_{1},X_{2}\) is destroyed. Under this intervention target, there must exist a \(C\in D(G^{(I)})\) that is shattered by \(\mathcal{S}\) and contains \(\{X_{1},X_{2}\}\). Therefore, there exists a subset of \(\mathcal{S}\): \(\{S^{\prime}_{j}\}_{j=1}^{k^{\prime}}\) with \(\{X_{1},X_{2}\}\subseteq C=\cup S^{\prime}_{j}\).

Because \(S^{\prime}_{j}\not\subseteq X^{\prime}\), there exist two maximal subsets \(S^{\prime}_{1}\) and \(S^{\prime}_{2}\) such that \(X_{1}\in S^{\prime}_{1}\) and \(X_{2}\in S^{\prime}_{2}\). This also means that there exist \(H_{1}\) and \(H_{2}\) with \(X_{1}\in S^{\prime}_{1}\subseteq\mathrm{ch}_{X}(H_{1})\) and \(X_{2}\in S^{\prime}_{1}\subseteq\mathrm{ch}_{X}(H_{2})\).

and \(H_{2}\) must be two different nodes other than \(H_{i}\) by the definition of the sparse measurement model. In addition, because \(S^{\prime}_{1}\not\subseteq X^{\prime}\), there exists \(X_{3}\in S^{\prime}_{1}\) where \(X_{3}\not\in X^{\prime}\).

Because \(\{X_{1},X_{2}\}\subseteq\mathrm{ch}_{X}(H_{i})\) and \(\{X_{1},X_{3}\}\subseteq\mathrm{ch}_{X}(H_{1})\) and \(X_{2},X_{3}\) are \(d\)-connected under the intervention target \(I\), by the definition of the sparse measurement model, \(X_{2}\) and \(X_{3}\) are \(d\)-connected via the path between \(H_{i}\) and \(H_{1}\). This is not possible because this path creates another type-2 path between \(X_{1}\) and \(X_{2}\).

### Useful lemmas

The first two lemmas show that we only need to care about maximal cliques of undirected dependency graphs.

**Lemma D.10**.: _For two measurement model \(G_{1}\) and \(G_{2}\) and two intervention targets \(I_{1}\) and \(I_{2}\), we have that \(\Omega^{(I_{1})}_{G_{1}}=\Omega^{(I_{2})}_{G_{2}}\) if and only if \(\mathcal{T}_{X}(G^{(I_{1})}_{1})=\mathcal{T}_{X}(G^{(I_{2})}_{2})\)._

Proof.: If \(\mathcal{T}_{X}(G^{(I_{1})}_{1})=\mathcal{T}_{X}(G^{(I_{2})}_{2})\), then \(D(G^{(I_{1})}_{1})\) is the same as \(D(G^{(I_{2})}_{2})\) by our construction of undirected dependency graphs. The obviously \(\Omega^{(I_{1})}_{G_{1}}=\Omega^{(I_{2})}_{G_{2}}\). On the other hand, if \(\Omega^{(I_{1})}_{G_{1}}=\Omega^{(I_{2})}_{G_{2}}\), then \(D(G^{(I_{1})}_{1})\) is the same as \(D(G^{(I_{2})}_{2})\) by Lemma D.11. By Proposition 6 of [43], \(\mathcal{T}_{X}(G^{(I_{1})}_{1})=\mathcal{T}_{X}(G^{(I_{2})}_{2})\). 

**Lemma D.11**.: _If \(G_{1}=(V,E_{1})\) and \(G_{2}=(V,E_{2})\) share the same maximal cliques, then \(E_{1}=E_{2}\)._

Proof.: Let's first show \(E_{1}\subseteq E_{2}\). Suppose \((A\to B)\in E_{2}\) and \((A\to B)\notin E_{1}\). Then there exists a maximal clique that contains \(A,B\) for \(G_{2}\). But there is no clique that contains \(A,B\) at the same time for \(G_{1}\). Therefore \(E_{1}\subseteq E_{2}\). Similarly, \(E_{2}\subseteq E_{1}\). 

**Lemma D.12**.: _Under Assumption 1(a) and (b), two distributions \(P_{1}\) and \(P_{2}\) over two measurement models \(G_{1}\) and \(G_{2}\) share the same UDG if and only if \(\mathcal{T}_{X}(G_{1})\) = \(\mathcal{T}_{X}(G_{2})\)._

Proof.: Because of Assumption 1(a) and (b), \(D(P_{1})=D(G_{1})\) and \(D(P_{2})=D(G_{2})\). By Lemma D.10 and Lemma D.11, the statement is true. 

**Lemma D.13**.: _If two hidden nodes \(H_{i}\) and \(H_{j}\) are \(d\)-connected in \(G^{(I)}\) under intervention target \(I\), then there exists a maximal clique \(C\in\Omega^{(I)}_{G}\) such that \(\mathrm{ch}_{X}(H_{i})\cup\mathrm{ch}_{X}(H_{j})\subseteq C\)_

Proof.: Because \(H_{i}\) and \(H_{j}\) are \(d\)-connected, \(\mathrm{ch}_{X}(H_{i})\) and \(\mathrm{ch}_{X}(H_{j})\) form a clique. Therefore, there exists a maximal clique that is a superset of \(\mathrm{ch}_{X}(H_{i})\cup\mathrm{ch}_{X}(H_{j})\). 

**Lemma D.14**.: _If a set of two observed elements \(\{X_{a},X_{b}\}\) is valid and \(X_{a},X_{b}\) do not share the same parent, then one of \(X_{a}\) and \(X_{b}\) must have at least two parents._

Proof.: \(X_{a}\) and \(X_{b}\) do not share the same parent. Therefore, there must exist at least two hidden nodes \(H_{a,1}\) and \(H_{b,1}\) such that \(X_{a}\in H_{a,1}\) and \(X_{b}\in H_{b,1}\). However, if there are only two such hidden nodes, Lemma E.4 suggests there exists an intervention target \(I\) that makes \(X_{a}\) and \(X_{b}\)\(d\)-separated and thus \(X_{a}\) and \(X_{b}\)\(d\)-separated. This is a violation of the fact that \(\{X_{a},X_{b}\}\) is a valid subset. 

**Lemma D.15**.: _For a hidden variable \(H_{i}\), there does not exist an observed node \(X_{i}\) such that \(X_{i}\not\in\mathrm{ch}_{X}(H_{i})\) but under any intervention target \(I\in\mathcal{I}\), \(X_{i}\) is a descendant of \(H_{i}\)._

Proof.: This violates maximality.

Consider \(G^{\prime}=(V,E^{\prime})\) with \(E^{\prime}=E\cup\{H_{i}\to X_{i}\}\). For any intervention target \(I\), \(D(G^{\prime(I)})\) does not have more edges than \(D(G^{\prime})\). If the opposite is true, then the new edge in \(D(G^{\prime(I)})\) must involve \(X_{i}\). Suppose the new edge is between \(X_{i}\) and \(X_{j}\), it must be that a parent of \(X_{j}\) is \(d\)-connected to \(H_{i}\). However, because \(X_{i}\) is a descendant of \(H_{i}\), by Lemma E.3, \(X_{i}\) must be \(d\)-connected to \(X_{j}\) in \(D(G^{I})\). Therefore, by Lemma D.10, \(\{\mathcal{T}_{X}(G^{(I)})\}_{I\in\mathcal{I}}\) is the same as \(\{\mathcal{T}_{X}(G^{(I)})\}_{I\in\mathcal{I}}\).

By Lemma D.17, the existence of \(G^{\prime}\) violates the maximality condition.

**Lemma D.16**.: \(\{\mathrm{ch}_{X}(H_{i})\}_{i=1}^{m}\) _is a complete cover._

Proof.: By Assumption 1(a) and Assumption 1(b), two observed variables \(X_{i}\) and \(X_{j}\) are dependent if and only if \(X_{i}\) and \(X_{j}\) are \(d\)-connected. Suppose \(\{\mathrm{ch}_{X}(H_{i})\}_{i=1}^{m}\) is not a complete cover. Then for some intervention target \(I\in\mathcal{I}\), there exists one clique \(C\) in \(D(G^{(I)})\) that is not shattered and that clique contains one edge that is not covered by other shattered cliques in \(D(G^{(I)})\). Suppose that edge is between \(X_{1}\) and \(X_{2}\), then there exist \(H_{1}\) and \(H_{2}\) with \(X_{1}\in\mathrm{ch}_{X}(H_{1})\) and \(X_{2}\in\mathrm{ch}_{X}(H_{2})\) and \(H_{1}\) is \(d\)-connected to \(H_{2}\). By Lemma D.13, this is not possible. 

**Lemma D.17**.: _If \(G=(X\cup H,E)\) is a maximal measurement model, then there does not exist a measurement model \(G^{\prime}=(X\cup H,E^{\prime})\) with \(E^{\prime}=E\cup\{H_{i}\to X_{i}\}\) for some hidden variable \(H_{i}\) and observed variable \(X_{i}\) such that for any intervention target \(I\in\mathcal{I}\), where \(\mathcal{I}\) is the complete family of intervention targets,_

\[\mathcal{T}_{X}(G^{(I)})=\mathcal{T}_{X}(G^{\prime(I)})\]

Proof.: By the definition of the maximal measurement model, we just need to show that \(G^{\prime}\) also satisfies Assumption 1. If \(G^{\prime}\) satisfies Assumption 1, then the existence of \(G^{\prime}\) would mean that \(G\) is not a maximal measurement model. Before delaying into the graphical assumptions, one first notices that because for any intervention target \(I\in\mathcal{I}\), \(\mathcal{T}_{X}(G^{(I)})=\mathcal{T}_{X}(G^{\prime(I)})\), then \(X_{i}\) must always be \(d\)-connected to \(\mathrm{ch}_{X}(H_{i})\) in both \(G^{(I)}\) and \(G^{\prime(I)}\) under any intervention target.

For Assumption 1(a), if a distribution \(P\) is Markov to \(G\), then it must be Markov to \(G^{\prime}\). This is because \(G^{\prime}\) has one more edge than \(G\), any active path in \(G\) would remain active in \(G^{\prime}\) as well. Thus \(\mathcal{T}(G^{\prime})\subseteq\mathcal{T}(G)\subseteq\mathcal{T}(P)\). A similar argument can be made for the interventional case.

For Assumption 1(b), we know that for any intervention target \(I\), \(X_{i}\mathrel{\mathop{\kern 0.0pt\perp}\limits_{P^{(I)}}}X_{j}\mathrel{ \mathop{\kern 0.0pt\implies}\limits_{\mathrm{d-sep}_{G^{(I)}}}}\!\!\left(\{X_{i}\} \middle\{X_{j}\}\,\middle|\,\emptyset\right)\). Because \(\mathcal{T}_{X}(G^{(I)})=\mathcal{T}_{X}(G^{\prime(I)})\), Assumption 1(b) is true for \(G^{\prime}\) as well.

For Assumption 1(c), because \(\mathcal{T}_{X}(G^{(I)})=\mathcal{T}_{X}(G^{\prime(I)})\) for any intervention target and \(G^{\prime},G\) only differs in bipartite graph. If Assumption 1(c) is satisfied by \(G\), it must be satisfied by \(G^{\prime}\) as well.

Therefore, \(G^{\prime}\) satisfies Assumption 1 and \(G\) is not maximal, which is a contradiction. 

## Appendix E Learning the skeleton of latent structures

Once we have learned the bipartite graph \(G_{B}\), the next step is to learn the DAG \(G_{H}\) over the latent variables \(H\). This turns out to be straightforward: Assumption 1(c) suggests that two hidden variables \(H_{i}\) and \(H_{j}\) are \(d\)-separated if and only if \(\mathrm{ch}_{X}(H_{i})\) and \(\mathrm{ch}_{X}(H_{j})\) are in different cliques (Lemma E.2). Therefore, the idea is to learn causal graphs using unconditional \(d\)-separations of latent variables under interventions.

Define \(\mathcal{M}_{H}\) as follows:

\[\mathcal{M}_{H}(G)\mathrel{\mathop{\kern 0.0pt\perp}\limits_{\mathrm{}}}(\{ \langle A,B\rangle:\mathrm{d-sep}_{G}(AB\,|\,\emptyset)\text{ for disjoint subsets }A,B\subseteq H\}).\]

Note that \(\mathcal{M}_{H}(G)\subseteq\mathcal{T}_{H}(G)\) because \(\mathcal{M}_{H}(G)\) only stores unconditional \(d\)-separations. Therefore, to learn the latent DAG, we would like to answer the following question:

_Given \(\{\mathcal{M}_{H}(G^{(I)}))\}_{I\in\mathcal{I}}\), can we recover \(G_{H}\)?_

_Remark E.1_.: This is harder than the fully observational case where we have access to all _conditional_\(d\)-separations.

The answer to the previous question is affirmative as shown by the next theorem (see Appendix E.2).

**Theorem E.1**.: _Under Assumptions 1-2 and suppose the bipartite graph \(G_{B}\) is correct, the skeleton of \(G_{H}\) is identifiable._

### Identifying unconditional \(d\)-separations of the latents

Given the bipartite graph \(G_{B}\) and \(\{\mathcal{T}_{X}(P^{(I)})\}_{I\in\mathcal{I}}\), we can easily construct \(\{\mathcal{M}_{H}(G^{(I)}))\}_{I\in\mathcal{I}}\) by the following lemma.

**Lemma E.2**.: _Given intervention target \(I\), two hidden variables \(H_{i}\) and \(H_{j}\) are \(d\)-separated in \(G^{(I)}\) if and only if there does not exist a clique \(C\in\Omega_{P}^{(I)}\) such that \(\operatorname{ch}_{X}(H_{i})\cup\operatorname{ch}_{X}(H_{j})\subseteq C\)._

Proof.: By Assumption 1(a) and Assumption 1(b), two observed variables \(X_{i}\) and \(X_{j}\) are dependent if and only if \(X_{i}\) and \(X_{j}\) are \(d\)-connected.

If \(H_{i}\) and \(H_{j}\) are \(d\)-separated in \(G^{(I)}\), then, by Assumption 1(c), there exists \(X_{i},X_{j}\in X\) where \(X_{i}\in\operatorname{ch}_{X}(H_{i})\), \(X_{j}\in\operatorname{ch}_{X}(H_{j})\), such that \(X_{i}\) and \(X_{j}\) are independent. Therefore, \(\operatorname{ch}_{X}(H_{i})\cup\operatorname{ch}_{X}(H_{j})\) is not a clique.

On the other hand, if there exist a clique \(C\in\Omega_{P}^{(I)}\) such that \(\operatorname{ch}_{X}(H_{i})\cup\operatorname{ch}_{X}(H_{j})\subseteq C\). This means that \(\operatorname{ch}_{X}(H_{i})\cup\operatorname{ch}_{X}(H_{j})\) is a clique. Then \(H_{i}\) and \(H_{j}\) must be \(d\)-connected, which is a contradiction. 

### Algorithm

Now we have Algorithm 1 to find the skeleton.

``` Input:\(\{\mathcal{M}_{H}(G^{(I)}))\}_{I\in\mathcal{I}}\)
1\(E\leftarrow\emptyset\) // Set of unoriented edges /* Step 0 */
2if\(\{\mathcal{M}_{H}(G^{(I)}))\}_{I\in\mathcal{I}}\) only has one distinct elementthen Output:\(E\) /* Step 1: Remove any pair of hidden variables that appears twice */
3for\(\mathcal{M}_{H}(G^{(I)}))\in\{\mathcal{M}_{H}(G^{(I)}))\}_{I\in\mathcal{I}}\)do
4for\(\langle H_{1},H_{2}\rangle\in\mathcal{M}_{H}(G^{(I)}))\)do
5 If\(\langle H_{1},H_{2}\rangle\) appears twice with at least two different intervention targets, delete \(\langle H_{1},H_{2}\rangle\) from \(\{\mathcal{M}_{H}(G^{(I)}))\}_{I\in\mathcal{I}}\). /* Step 2: Add unoriented edges */
6for\(\mathcal{M}_{H}(G^{(I)}))\in\{\mathcal{M}_{H}(G^{(I)}))\}_{I\in\mathcal{I}}\)do
7for\(\langle H_{1},H_{2}\rangle\in\mathcal{M}_{H}(G^{(I)}))\)do
8\(E\gets E\cup\{\langle H_{1},H_{2}\rangle\}\) ```

**Output:\(E\)**

**Algorithm 1** Learning Skeleton of \(G_{H}\)

**Theorem E.1**.: _Under Assumptions 1-2 and suppose the bipartite graph \(G_{B}\) is correct, the skeleton of \(G_{H}\) is identifiable._

Proof.: The proof relies on the correctness of Algorithm 1 which we show here.

First, suppose \(\{\mathcal{M}_{H}(G^{(I)}))\}_{I\in\mathcal{I}}\) only has one distinct element. Then there is no edge between latent variables in \(G_{H}\). Suppose, on the contrary, there is an edge \(H_{1}\to H_{2}\) between two hidden variables \(H_{1}\) and \(H_{2}\) in \(G_{H}\), then by Lemma E.2, \(\operatorname{ch}_{X}(H_{1})\cup\operatorname{ch}_{X}(H_{2})\) must be a clique in \(D(G^{(\emptyset)})\). But by Lemma E.3, when the intervention target \(I\) is \(H_{2}\), \(H_{1}\) and \(H_{2}\) would be \(d\)-separated, and by Lemma E.2, \(\operatorname{ch}_{X}(H_{1})\cup\operatorname{ch}_{X}(H_{2})\) must not be a clique in \(D(G^{(I)})\). Therefore, there must be at least two distinct elements in \(\{\mathcal{M}_{H}(G^{(I)}))\}_{I\in\mathcal{I}}\).

Now, let's consider the case after step 0. Let's denote the unoriented edge set returned by Algorithm 1 as \(E_{1}\) and the true unoriented edge set of \(G_{H}\) as \(E_{2}\).

1. [label=.]
2. \(E_{2}\subseteq E_{1}\). By Lemma E.3, \(\{\mathcal{M}_{H}(G^{(I)}))\}_{I\in\mathcal{I}}\) has all pairs of hidden variables. And we removed all the pair that does not have an edge in \(E_{2}\) by Lemma E.5.
3. \(E_{1}\subseteq E_{2}\). Suppose \(\exists\langle H_{1},H_{2}\rangle\in E_{1}\) such that \(\langle H_{1},H_{2}\rangle\notin E_{2}\). Note that \(\langle H_{1},H_{2}\rangle\) only appears with one intervention target and by Lemma E.5, this is not possible.

### Useful Lemmas

**Lemma E.3**.: _Given a DAG \(G=(V,E)\). If two nodes \(A,B\in V\) are d-connected by the empty set, then at least one of the following must be true_

1. _[label=.]_
2. _They share a common ancestor (common ancestor path)_
3. _There are directed paths between the two nodes and all the directed paths must have the same direction (directed path)_

Proof.: Because \(A,B\) are d-connected, there must exist active paths between the two nodes. There are four possibilities of active path

1. [label=.]
2. \(A\to...\to B\). This could be a direct path if every edge points to the same direction. If one of the intermediate edges points in the opposite direction. Then we would have a collider which makes the path inactive.
3. \(A\leftarrow...\gets B\). The same as the first case.
4. \(A\to...\gets B\). This is not possible because there must exist a collider on the path.
5. \(A\leftarrow...\to B\). \(A\) and \(B\) must share a common ancestor in this path unless there is a collider which is not possible.

Obviously, we cannot have two directed paths pointing in opposite directions because that would create a circle. 

**Lemma E.4**.: _For any two hidden variables \(H_{1}\) and \(H_{2}\), there exists at least one intervention target \(I\in\mathcal{I}\), such that \(\langle H_{1},H_{2}\rangle\in\mathcal{M}_{H}(G^{(I)})\)._

Proof.: If \(H_{1}\) and \(H_{2}\) are \(d\)-separated in \(G^{(\emptyset)}\), then we can just choose \(I=\emptyset\).

If \(H_{1}\) and \(H_{2}\) are d-connected in \(G^{(\emptyset)}\) and assume, without loss of generality, the directed paths between \(H_{1}\) and \(H_{2}\), if exist, point to \(H_{2}\), then based on Lemma E.3, if we intervene on \(H_{2}\), all the active paths between \(H_{1}\) and \(H_{2}\) would disappear. 

**Lemma E.5**.: _If \(\{\mathcal{M}_{H}(G^{(I)})\}_{I\in\mathcal{I}}\) has at least two distinct elements, then for any two hidden variables \(H_{1}\) and \(H_{2}\), there is no direct edge between \(H_{1}\) and \(H_{2}\) if and only if there exists at least two intervention targets \(I_{1},I_{2}\in\mathcal{I}\), such that \(\langle H_{1},H_{2}\rangle\in\mathcal{M}_{H}(G^{(I_{1})})\) and \(\langle H_{1},H_{2}\rangle\in\mathcal{M}_{H}(G^{(I_{2})})\)._

Proof.: If there is no direct edge between \(H_{1}\) and \(H_{2}\) and there exists only one intervention target \(I_{1}\in\mathcal{I}\), such that \(\langle H_{1},H_{2}\rangle\in\mathcal{M}_{H}(G^{(I_{1})})\), then \(I_{1}\neq\emptyset\). There is because if \(I_{1}=\emptyset\) and \(\langle H_{1},H_{2}\rangle\in\mathcal{M}_{H}(G^{(\emptyset)})\). Then there are no active paths between \(H_{1}\) and \(H_{2}\) and deleting edges via interventions would not create active paths. Because \(\{\mathcal{M}_{H}(G^{(I)})\}_{I\in\mathcal{I}}\) has at least two distinct elements, there must exist another intervention target such that \(\langle H_{1},H_{2}\rangle\) appears. By the proof of Lemma E.6, one of \(H_{1}\) and \(H_{2}\) is the intervention target \(I_{1}\). Without loss of generality, suppose \(I_{1}=\{H_{1}\}\), we can add \(H_{1}\gets H_{2}\) to the graph and it would violate the maximality condition. Thus, if there is no direct edge between \(H_{1}\) and \(H_{2}\), then there exists at least two intervention targets \(I_{1},I_{2}\in\mathcal{I}\), such that \(\langle H_{1},H_{2}\rangle\in\mathcal{M}_{H}(G^{(I_{1})})\) and \(\langle H_{1},H_{2}\rangle\in\mathcal{M}_{H}(G^{(I_{2})})\).

If there exists at least two intervention targets \(I_{1},I_{2}\in\mathcal{I}\), such that \(\langle H_{1},H_{2}\rangle\in\mathcal{M}_{H}(G^{(I_{1})})\) and \(\langle H_{1},H_{2}\rangle\in\mathcal{M}_{H}(G^{(I_{2})})\), then suppose there is a direct edge between \(H_{1}\) and \(H_{2}\). Without loss of generality, let's assume \(H_{1}\to H_{2}\). Then two variables would _only_ be \(d\)-separated when intervening on \(H_{2}\) which is a contradiction. 

**Lemma E.6**.: _In Algorithm 1, after step 1, for any intervention target \(I\) such that \(\mathcal{M}_{H}(G^{(I)})\neq\mathcal{M}_{H}(G^{(\emptyset)})\), then there exist a hidden variable \(H_{1}\) such that \(H_{1}\in\langle H_{i},H_{j}\rangle\) for all \(\langle H_{i},H_{j}\rangle\in\mathcal{M}_{H}(G^{(I)})\) and \(H_{1}\) is the intervention target \(I\)._Proof.: We just need to show that if \(\langle H_{i},H_{j}\rangle\in\mathcal{M}_{H}(G^{(I)})\) and \(\langle H_{i},H_{j}\rangle\notin\mathcal{M}_{H}(G^{(I^{\prime})})\) for \(I^{\prime}\neq I\), then one of \(H_{i}\) or \(H_{j}\) must be the intervention target \(I\). This is because, after step 1, every pair of hidden variables only appear once.

Suppose the opposite is true, then neither \(H_{i}\) nor \(H_{j}\) is being intervened on. So there is no direct edge between \(H_{i}\) and \(H_{j}\) since otherwise \(H_{i}\) and \(H_{j}\) would be \(d\)-connected. On the other hand, \(\langle H_{i},H_{j}\rangle\notin\mathcal{M}_{H}(G^{(I^{\prime})})\) for \(I^{\prime}\neq I\), implies that \(H_{i}\) and \(H_{j}\) are \(d\)-connected in the observational distribution because \(\mathcal{M}_{H}(G^{(I)})\neq\mathcal{M}_{H}(G^{(\emptyset)})\). Then by Lemma E.3, we can find another intervention target \(H_{i}\) or \(H_{j}\) such that \(\langle H_{i},H_{j}\rangle\) would appear again which would be a contradiction. 

## Appendix F Limitations of edge orientations

Unlike known interventions, with only access to CI information, edge orientation might not always be possible even when there are no latent variables as shown in Example 1. But it is also possible as demonstrated by Example 13. This raises the question of which edges provably _cannot_ be oriented.

In this section, we attempt to answer this question by studying equivalence relations between DAGs under unknown interventions. Such equivalence relations are finer partitions of the Markov equivalence class. _The results are purely graphical_ and can be studied in their own right. If assuming Markov and faithfulness, it also shows the limitations of edge orientations with access to CI information only. In addition, one could use conditional invariances to improve the identifiability of edge orientations. But it might require additional assumptions like direct \(\mathcal{I}\)-faithfulness[58] which we do not make in this paper.

**Example 13**.: Consider the CPDAG \(G\) shown in Figure 14. Let \(G_{1}\) be a consistent extension of \(G\) such that \(X_{1}\to X_{2}\) and \(I_{1}=X_{2}\). Then \(\{(X_{1},X_{2},\emptyset),(X_{3},X_{2},\emptyset)\}\subseteq\mathcal{T}(G_{1} ^{(I_{1})})\). \(G_{2}\) is another consistent extension of \(G\) where \(X_{2}\to X_{1}\) but there does not exist an intervention target that can induce \(\mathcal{T}(G_{1}^{(I_{1})})\). Therefore, if we observe \(\mathcal{T}(G_{1}^{(I_{1})})\), then we know that \(X_{1}\to X_{2}\).

In this section, we consider the _general case of an arbitrary, fully observed DAG (i.e. \(H=\emptyset\))_ instead of the measurement model. Given the skeleton of the DAG, all the compelled edges in the MEC can already be identified without access to interventional distributions. Therefore, without loss of generality, we assume the CPDAG is given and study if unknown hard interventions on single nodes can help orient reversible edges. Furthermore, because isolated edges are covered, they must be reversible in the MEC as well (cf. Lemma G.1), there is no loss of generality in focusing on reversible edges.

To state the problem formally:

_Given a CPDAG \(G\), we want to orient its reversible edges given a list \(\{\mathcal{T}(G_{*}^{(I)})\}_{I\in\mathcal{I}}\) for a family of intervention targets \(\mathcal{I}\) and \(G_{*}\), which is the true consistent extension of \(G\). In other words, is the tuple \(\langle G_{*},\mathcal{I}\rangle\) the unique one that can induce \(\{\mathcal{T}(G_{*}^{(I)})\}_{I\in\mathcal{I}}\)?_

Let's start with some definitions. Recall the definition of _covered edges[12]_:

**Definition B.3** (Covered Edge).: We say an edge \(x\to y\) is covered if \(x\) and \(y\) share the same parent excluding \(x\) (i.e. \(\mathrm{pa}(x)\cup\{x\}=\mathrm{pa}(y)\)).

In particular, an _isolated edge_ is a special covered edge.

**Definition 3.3** (Isolated edge).: We say an edge \(x\to y\) is **isolated** if \(x\) does not have any parent (\(\mathrm{pa}(x)=\emptyset\)) and \(y\) only has \(x\) as its parent (\(\mathrm{pa}(y)=\{x\}\)).

_Remark F.1_.: Isolated edges are trivially covered.

Figure 14: CPDAG of three variables with no latent variables.

### Isolated equivalence class

Chickering [12] show that two Markov equivalent DAGs can be transformed into one another by a sequence of covered edge reversals. The isolated equivalence class is also defined in a transformational fashion. We restate the definition below.

**Definition F.1**.: (Isolated equivalence class) Two DAGS \(G_{1}\) and \(G_{2}\) are isolated equivalent, denoted \(G_{1}\sim_{E}G_{2}\), if there exists a sequence of isolated edge reversals.

The next two theorems show that it is impossible to distinguish DAGs in an IEC by looking at \(d\)-separations only.

**Theorem F.2**.: _Let \(G_{1}\) and \(G_{2}\) be two consistent extensions of CPDAG \(G=(V,E)\). Suppose_

1. \(G_{1}\) _and_ \(G_{2}\) _only differs in one isolated edge_
2. _All the interventional targets are single nodes and the intervention is hard._

_Suppose the tuple \((G_{1},\mathcal{I}_{1})\) induces \(\{\mathcal{T}(G_{1}^{(I)})\}_{I\in\mathcal{I}_{1}}\)._

_Then there exists a family of interventional targets \(\mathcal{I}_{2}\) such that the tuple \((G_{2},\mathcal{I}_{2})\) also induces \(\{\mathcal{T}(G_{1}^{(I)})\}_{I\in\mathcal{I}_{1}}\)._

**Theorem 5.3**.: _Suppose \(G_{1}\) and \(G_{2}\) are in the same IEC. If the tuple \((G_{1},\mathcal{I}_{1})\) induces \(\{\mathcal{T}(G_{1}^{(I)})\}_{I\in\mathcal{I}_{1}}\), then there exists a family of interventional targets \(\mathcal{I}_{2}\) (possibly the same as \(\mathcal{I}_{1}\)) such that the tuple \((G_{2},\mathcal{I}_{2})\) also induces \(\{\mathcal{T}(G_{1}^{(I)})\}_{I\in\mathcal{I}_{1}}\)._

Proof.: Because \(G_{1}\) and \(G_{2}\) are in the same IEC, then, by definition, there exists a sequence of isolated edge reversals. Then we can prove by applying Theorem F.2 repeatedly. 

#### f.1.1 Proof of Theorem F.2

**Definition F.3**.: (Augmented Active Subgraph) Let \(G=(V,E)\) be a DAG and let path \(P:V_{1}\to...\to V_{k}\) be an active path given \(C\) where \(C\subseteq V\). Suppose \(H_{i}\) is a collider, then there must exist at least a node \(V_{d}\) in \(\overline{\mathrm{de}}(V_{i})\) where \(V_{d}\in C\). We define an **active descendent path** of \(V_{i}\) to be a directed path from \(V_{i}\) to \(V_{d}\). An **augmented active subgraph** of \(P\) is a subgraph including the active path \(P\) and all the active descendent paths of colliders in the original active path.

_Remark F.2_.: Our definition also considers the special case where \(V_{i}=V_{d}\) and the directed path is just \(V_{i}\to V_{i}\).

**Lemma F.4**.: _Let \(G=(V,E)\) be a DAG. Let \(I\) be a single node hard intervention target, then,_

\[\mathcal{T}(G)\subseteq\mathcal{T}(G^{I})\]

Proof.: Doing a hard intervention on any node \(V_{i}\in V\) removes all incoming edges to \(H_{i}\).

Suppose the statement is not true, then there exists \((A,B,C)\in\mathcal{T}(G)\) such that \((A,B,C)\notin\mathcal{T}(G^{I})\). This means that intervening on \(V_{i}\) creates an active path between \(A,B\) given \(C\). But deleting edges would not create a new path. The only way an active path can emerge is if a previously blocked path becomes unblocked after an intervention.

A path is blocked if either:

1. any non-collider is being conditioned on.
2. no descendants of collider (including itself) is being conditioned on

For the first condition, we know that deleting edges would not make non-colliders colliders. On the other hand, deleting edges would also not make non-descendants descendants (intervening on the collider itself would destroy the path). Therefore, hard intervening on a single node would not create new active paths. 

**Lemma F.5**.: _Let \(G\) be a DAG. Suppose there is an active path \(P\) in \(G\), and the hard intervention target \(I\) is not on the augmented active subgraph of the active path. Then this path stays active._Proof.: Because the intervened node is not on the path nor on the directed path going out from one of the colliders on the active path. Deleting its incoming edges would not change these paths. 

**Lemma F.6**.: _Let \(G_{1}\) and \(G_{2}\) be two DAGs that share the same augmented active subgraph of active path \(P\) given conditioning set \(C\). If there is a single node hard intervention on one of the nodes of that augmented active subgraph in both \(G_{1}\) and \(G_{2}\), then either the path is active in both \(G_{1}\) and \(G_{2}\) or it is not active in either \(G_{1}\) or \(G_{2}\)._

Proof.: Intervening on any node on the active path would destroy (if the intervened node has incoming edges) or sustain (if the intervened node has no incoming edges) the path in both \(G_{1}\) and \(G_{2}\).

Suppose we intervene on a descendant of a collider on the active path that is not the collider itself. Any active descendant path that has the intervened node on it would get destroyed. The path would stay active if there exists an alternative active descendant path that does not involve the intervened node, which is shared between \(G_{1}\) and \(G_{2}\) because they share the same augmented active subgraph. Note that intervening on a node would not create a new descendant path. 

Proof of Theorem F.2.: For notation, let's suppose the isolated edge is \(V_{i}\to V_{j}\) in \(G_{1}\).

To prove this, we just need to show that for any \(I_{i}\in\mathcal{I}_{1}\), there exists \(I_{j}\) such that

\[\mathcal{T}(G_{1}^{(I_{i})})=\mathcal{T}(G_{2}^{(I_{j})})\]

In particular, we will show that we can choose \(I_{j}=\{I_{i}\}\) when \(I_{i}\neq\{V_{i}\}\) and \(I_{j}=\{V_{j}\}\) when \(I_{i}=\{V_{i}\}\).

By the definition of Markov equivalence, we know that

\[\mathcal{T}(G_{1})=\mathcal{T}(G_{2})\]

First of all, note that an augmented active subgraph given conditioning set \(C\) in \(G_{1}\) must exist and be active given conditioning set \(C\) in \(G_{2}\) and vice versa. We know that two DAGs in the same Markov equivalence class share the same skeleton and v-structures. Therefore, for any augmented active subgraph given conditioning set \(C\) in \(G_{1}\), there is a subgraph with the same skeleton in \(G_{2}\). If the edges of the augmented active subgraph in \(G_{1}\) have the same orientations in \(G_{2}\), then it is active in \(G_{2}\). If some edges of the augmented active subgraph in \(G_{1}\) have different orientations than that of \(G_{2}\). Then the subgraph can only differ in one isolated edge. Because the endpoints of isolated edge cannot have other parents, the isolated edge cannot be in the descendant paths. The isolated edge can be in the active path itself, with edges going out from endpoints of isolated edge. When that edge is reversed, the path is still active.

To show that \(\mathcal{T}(G_{1}^{(I_{i})})=\mathcal{T}(G_{2}^{(I_{j})})\), we first need to show that for any \((A,B,C)\in\mathcal{T}(G_{1}^{(I_{i})})\), \((A,B,C)\in\mathcal{T}(G_{2}^{(I_{j})})\). By Lemma F.4, \(\mathcal{T}(G_{1})\subseteq\mathcal{T}(G_{1}^{(I_{i})})\) and \(\mathcal{T}(G_{2})\subseteq\mathcal{T}(G_{2}^{(I_{j})})\). We can only consider tuple \((A,B,C)\) where \((A,B,C)\notin\mathcal{T}(G_{1})\).

If \((A,B,C)\notin\mathcal{T}(G_{1})\), but \((A,B,C)\in\mathcal{T}(G_{1}^{(I_{i})})\), then all the active paths between \(A\) and \(B\) given \(C\) must be blocked or deleted after intervention on \(I_{i}\). Let's consider the following two cases:

1. Suppose an active path has the same augmented subgraph in both \(G_{1}\) and \(G_{2}\), then it will get blocked in \(G_{2}\) when intervened on \(I_{j}=I_{i}\). Note that \(I_{i}\) is neither \(V_{i}\) nor \(V_{j}\). Because \(V_{i}\to V_{j}\) is isolated, they do not have other parents. Intervening on them will not block/delete that path.
2. Suppose an augmented subgraphs in \(G_{1}\) and an augmented subgraphs in \(G_{2}\) differ in one isolated edge. If the intervention target \(I_{i}\) is \(V_{i}\), then we can choose \(I_{j}\) to be \(V_{j}\) (intervening on \(V_{j}\) in \(G_{2}\) will not delete that path). If the intervention target is neither \(V_{i}\) nor \(V_{j}\), then we can keep \(I_{j}\) to be the same as \(I_{i}\). Because \(V_{i}\to V_{j}\) is an isolated edge, this edge must be on the active path itself and not on the active descendant paths. Suppose the active path \(P\) is \(V_{1}\rightarrow...\to V_{k}\), then the subpath \(P_{1}:V_{1}\rightarrow...\to V_{i}\) and \(P_{2}:V_{j}\rightarrow...\to V_{k}\) have the same augmented subgraphs in both \(G_{1}\) and \(G_{2}\). By Lemma F.6, the intervention would have the same effect on them.

Therefore, if \(I_{j}=\{I_{i}\}\) when \(I_{i}\neq\{V_{i}\}\) and \(I_{j}=\{V_{j}\}\) when \(I_{i}=\{V_{i}\}\). By similar argument, \(\mathcal{T}(G_{2}^{(I_{j})})\subseteq\mathcal{T}(G_{1}^{(I_{i})})\). 

#### f.1.2 Orienting Non-isolated Edges

While it is impossible to distinguish within an IEC, it is possible to do so between IECs.

**Theorem F.7**.: _Let \(G_{1}\) and \(G_{2}\) be two DAGs. Suppose_

1. \(G_{1}\) _and_ \(G_{2}\) _are Markov equivalent._
2. \(G_{1}\) _and_ \(G_{2}\) _are not isolated equivalent._

_Then there exists a single-node hard intervention target \(I_{1}\) such that_

\[\mathcal{T}(G_{1}^{(I_{1})})\neq\mathcal{T}(G_{2}^{(I_{2})})\quad\forall I_{2}\]

_where \(I_{2}\) is also a single-node hard intervention target._

Proof.: Let \(\Delta(G_{1},G_{2})\) denote the set of edges in \(G_{1}\) that have opposite orientations in \(G_{2}\).

By theorem 2 of [12], we know that there exists a sequence of \(|\Delta(G_{1},G_{2})|\) distinct covered edge reversals that can transform \(G_{1}\) to \(G_{2}\). And each covered edge reversal creates a DAG in the same Markov equivalence class.

Because \(G_{1}\) and \(G_{2}\) are not isolated equivalent, there exist DAGs \(G_{m}\) and \(G_{n}\) in the sequence such that \(G_{m}\) and \(G_{n}\) differ by a covered edge where endpoints of the edge share at least one additional parent node. Without loss of generality, let \(G_{m}\) and \(G_{n}\) be the first pair in the sequence to have covered but not isolated edge reversal. In particular, the sequence is \(G_{1}\rightarrow...\to G_{m}\to G_{n}\rightarrow...\to G_{2}\).

For simplicity, suppose the covered edge in \(G_{m}\) is \(A\to B\) and the common parent is \(C\). Obviously, in \(G_{n}\), the covered edge is reversed (\(A\gets B\)). Suppose there is an intervention target \(I_{1}^{\prime}\) on \(G_{m}\) that is \(\{B\}\), then edges \(C\to B\) and \(A\to B\) get removed. Therefore, there exist subsets of vertices \(S_{1}\) and \(S_{2}\) such that \(C\) and \(B\) are d separated by \(S_{1}\), and \(A\) and \(B\) are d separated by \(S_{1}\).

However, for all DAGs in the subsequence after \(G_{m}\) including \(G_{n}\) and \(G_{2}\). The edge is reversed to be \(A\gets B\) (Note that the sequence has \(|\Delta(G_{1},G_{2})|\) distinct covered edge reversals that can transform \(G_{1}\) to \(G_{2}\). A reversed edge cannot be reversed again). There does not exist a single node intervention target that can remove both edges between \(A\), \(B\), and \(B\), \(C\).

Therefore,

\[\mathcal{T}(G_{m}^{(I_{1}^{\prime})})\neq\mathcal{T}(G_{2}^{(I_{2})})\quad \forall I_{2}\]

By our construction, \(G_{m}\) and \(G_{1}\) are in the same IEC. By Theorem F.2, there exists an intervention target \(I_{1}\) such that,

\[\mathcal{T}(G_{1}^{(I_{1})})\neq\mathcal{T}(G_{2}^{(I_{2})})\quad\forall I_{2}.\qed\]

#### f.1.3 Useful Lemmas

The first lemma characterizes the uncovered reversible edges.

**Lemma F.8**.: _Let \(G_{1}\) be a consistent extension of a CPDAG \(G\). Suppose there is an uncovered edge \(e:A\to B\) in \(G_{1}\) and the edge is unoriented in the CPDAG, then there must exist a node \(C\) in \(G_{1}\) such that \(C\to B\) and \(C\gets A\)._

Proof.: Because \(e\) is uncovered, there are two cases.

1. There is a node \(C\) in \(G_{1}\) that is a parent of \(B\) but not a parent of \(A\). Suppose there is no edge between \(C\) and \(A\). Then because \(e_{1}\) is unoriented, changing its direction would destroy a \(v\)-structure. Therefore there must be an edge between \(C\) and \(A\) and because \(C\) is not a parent \(A\), we have \(C\gets A\).

2. There is a node \(C\) in \(G_{1}\) that is a parent of \(A\) but not a parent of \(B\). By a similar argument, Therefore there must be an edge between \(C\) and \(B\). Because \(C\) is not a parent of \(B\), we have \(C\gets B\). In this case, we have a circle. Therefore, this is not a valid case. 

The next lemma characterizes reversible edges in an IEC.

**Lemma F.9**.: _Let \(G_{1}\) and \(G_{2}\) be two DAGs in the same IEC. Let \(e_{1}\) be a reversible edge in \(G_{1}\) that has the opposite orientation in \(G_{2}\). Then, \(e_{1}\) must be isolated._

Proof.: Let's denote \(e_{1}\) in \(G_{1}\) as \(A\gets B\). We can consider two cases.

1. \(e_{1}\) is a covered edge in \(G_{1}\). Suppose, on the contrary, \(e_{1}\) is non-isolated. By definition, there exists a common parent \(C\). Because \(e_{1}\) has the opposite orientation in \(G_{2}\), we have \(A\gets B\) in \(G_{2}\). \(G_{1}\) and \(G_{2}\) are isolated equivalent and thus Markov equivalent. They must share the same skeleton. So there must be edges connecting \(C\), \(A\), and \(C\), \(B\) in \(G_{2}\). By definition, there exists a sequence of isolated edge reversals from \(G_{2}\) to \(G_{1}\). There are only three valid possibilities (the fourth one is ignored because it creates a circle) in \(G_{2}\): 1. \(C\to A\), \(C\gets B\). Out of all the three edges among \(A,B,C\), the first edge that might be reversed in the sequence is \(C\gets B\). But regardless of the orientation of the edge between \(B\) and \(C\), one cannot reverse \(A\gets B\) in the sequence as it cannot be an isolated edge. 2. \(C\to A\), \(C\to B\). Out of all the three edges among \(A,B,C\), the first edge that might be reversed in the sequence is \(C\to A\). But regardless of the orientation of the edge between \(B\) and \(C\), one cannot reverse \(A\gets B\) in the sequence as it cannot be an isolated edge. 3. \(C\gets A\), \(C\gets B\). Because \(G_{1}\) and \(G_{2}\) are in the same IEC. The first edge to be reversed must be \(B\to A\). But then, we cannot reverse \(B\to C\) because it is not covered and we cannot reverse \(A\to C\) because it is covered but not isolated. So this case is also not possible.
2. \(e_{1}\) is not a covered edge in \(G_{1}\). By Lemma F.8, there must exist a node \(C\) in \(G_{1}\) such that \(C\to B\) and \(C\gets A\). Note that in \(G_{2}\), we have \(A\gets B\). By definition, there exists a sequence of isolated edge reversals from \(G_{2}\) to \(G_{1}\). There are only three valid possibilities (the fourth one is ignored because it creates circles) in \(G_{2}\): 1. \(C\to A\), \(C\to B\). Both \(C\to A\) and \(A\gets B\) have to be reversed. Out of all the three edges among \(A,B,C\), the first edge that might be reversed in the sequence is \(C\gets B\). But regardless of the orientation of the edge between \(B\) and \(C\), one cannot reverse \(A\gets B\) in the sequence as it cannot be an isolated edge. 2. \(C\gets A\), \(C\gets B\). Because \(G_{1}\) and \(G_{2}\) are in the same IEC. The first edge to be reversed must be \(B\to A\). But then, we cannot reverse \(B\to C\) because it is not covered. 3. \(C\to A\), \(C\gets B\). All the edges must be reversed. Because \(G_{1}\) and \(G_{2}\) are in the same IEC. The first edge to be reversed must be \(B\to C\). But then, we cannot reverse \(B\to A\) because it is covered but not isolated and we cannot reverse \(C\to A\) because it is not covered. So this case is also not possible. 

## Appendix G Edge orientations for measurement model

Up to this point, we have used unknown interventions to learn the skeleton of the underlying DAG \(G\) (Appendix D, Appendix E). For causal interpretation, we must go one step further and orient these edges. Now, orienting the edges in the bipartite graph is easy: In a measurement model, the observed \(X\) cannot have any children, so the only possibility is to orient the edges from hidden to observed. Orienting edges in the latent space is a different matter: Since the intervention targets are additionally unknown, this raises additional complications.

We extend Algorithm 1 to Algorithm 2 to orient edges in \(G_{H}\) up to isolated edges which cannot be oriented using CI information only in general (Appendix F).

**Theorem 5.1**.: _Let \(G\) be a maximal measurement model satisfying Assumption 1 and assume we are given a complete family of interventions (Assumption 2) as well as the bipartite DAG \(G_{B}\). Then the true latent DAG \(G_{H}\) is identifiable up to isolated edges. Moreover, isolated edges cannot be oriented without making additional assumptions._

Proof.: The identification is given by Algorithm 2.

Suppose the returned PDAG is \(G_{H}^{\#}\). First, by Theorem E.1, \(G_{H}^{\#}\) and \(G_{H}\) share the same skeleton. By Lemma G.2, all the unoriented edges are the reversible edges of the Markov equivalence class \(\mathcal{E}(G_{H})\). If a reversible edge \(H_{1}\to H_{2}\) is not covered or covered but non-isolated in \(G_{H}\), then \(H_{2}\) has at least two incoming edges by definition and Lemma F.8. Then \(H_{1}\to H_{2}\) will be correctly oriented because \(\mathcal{M}_{H}(G^{(H_{2})})\) has at least two members. Therefore, the only reversible edge that cannot be oriented is the isolated one.

By Lemma F.9, the only reversible edges in the IEC of \(G_{H}\) are isolated in \(G_{H}\). And by Theorem 5.3, we cannot distinguish DAGs in IEC with unknown single-node hard interventions. 

### Useful Lemmas

**Lemma G.1**.: _Let \(G\) be a DAG and suppose \(X\to Y\) is a covered edge in \(G\), then \(X\to Y\) is not compelled in \(\mathcal{E}(G)\)._

Proof.: By Lemma 1 of [12], we can reverse this edge to get \(G^{\prime}\) and \(G^{\prime}\) is Markov equivalent to \(G\). By definition of compelled edge, it is not a compelled edge. 

**Lemma G.2**.: _Every unoriented edge returned by Algorithm 2 is a reversible edge of the Markov equivalence class \(\mathcal{E}(G_{H})\)._

Proof.: Recall that an edge is reversible if there exist two members of the equivalence class that have two different orientations of this edge.

Without loss of generality, suppose one of the unoriented edges returned by Algorithm 2 is \(H_{1}\gets H_{2}\) in \(G_{H}\). Let's consider the following cases:

1. In \(G_{H}\), \(H_{1}\) has incoming edges other than \(H_{1}\gets H_{2}\). In this case, when the unknown intervention target \(I\) is \(\{H_{1}\}\), there are at least two elements in \(\mathcal{M}_{H}(G^{(I)})\) after step 1 of the algorithm. By Lemma E.6, we can thus orient the edge \(H_{1}\gets H_{2}\) in step 2.
2. In \(G_{H}\), \(H_{1}\) has no incoming edge other than \(H_{1}\gets H_{2}\) and \(H_{2}\) has at least two incoming edges. In this case, when the unknown intervention target \(I\) is \(H_{2}\), there are at least two elements in \(\mathcal{M}_{H}(G^{(I)})\) after step 1 of the algorithm. By Lemma E.6, we can thus orient the incoming edge of \(H_{2}\) in step 2 and orient \(H_{1}\gets H_{2}\) in step 3.
3. In \(G_{H}\), \(H_{1}\) has no incoming edge other than \(H_{1}\gets H_{2}\) and \(H_{2}\) has only one incoming edge. Suppose the other edge is \(H_{2}\gets H_{3}\) in \(G_{H}\). Then this edge must also be unoriented the Algorithm 2. Because if this edge is oriented, then \(H_{2}\) must be in \(\widehat{\mathcal{I}}\) by step 3 which implies that \(H_{1}\gets H_{2}\) must also be oriented as well. Therefore, we can reverse \(H_{1}\gets H_{2}\) and \(H_{2}\gets H_{3}\). Because \(H_{2}\gets H_{3}\) is unoriented, \(H_{3}\) must have at most one incoming edge since the other cases have been ruled out by the previous argument. If it has one incoming edge, we can reserve that edge as well. The process continues until we reach one node that does not have any incoming edge. The whole process does not create any new \(v\)-structures. So we have two Markov equivalent graphs with different orientations of \(H_{1}\gets H_{2}\).
4. In \(G_{H}\), \(H_{1}\) has no incoming edge other than \(H_{1}\gets H_{2}\) and \(H_{2}\) has no incoming edge.

Consider \(G^{{}^{\prime}}_{H}\) where \(G^{{}^{\prime}}_{H}\) has the same edges as \(G_{H}\) except that \(G_{H}\) has \(H_{1}\to H_{2}\). Because no \(v\)-structure is created or destroyed with this edge reversal, \(G^{{}^{\prime}}_{H}\) and \(G_{H}\) are Markov equivalent.

If an edge is unoriented, it must fall in the last two cases and be reversible.

[MISSING_PAGE_EMPTY:46]