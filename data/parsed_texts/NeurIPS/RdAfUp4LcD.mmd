# Linear Mode Connectivity in

Differentiable Tree Ensembles

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

_Linear Mode Connectivity_ (LMC) refers to the phenomenon that performance remains consistent for linearly interpolated models in the parameter space. For independently optimized model pairs from different random initializations, achieving LMC is considered crucial for validating the stable success of the non-convex optimization in modern machine learning models and for facilitating practical parameter-based operations such as model merging. While LMC has been achieved for neural networks by considering the permutation invariance of neurons in each hidden layer, its attainment for other models remains an open question. In this paper, we first achieve LMC for _soft tree ensembles_, which are tree-based differentiable models extensively used in practice. We show the necessity of incorporating two invariances: _subtree flip invariance_ and _splitting order invariance_, which do not exist in neural networks but are inherent to tree architectures, in addition to permutation invariance of trees. Moreover, we demonstrate that it is even possible to exclude such additional invariances while keeping LMC by designing _decision list_-based tree architectures, where such invariances do not exist by definition. Our findings indicate the significance of accounting for architecture-specific invariances in achieving LMC.

## 1 Introduction

A non-trivial empirical characteristic of modern machine learning models trained using gradient methods is that models trained from different random initializations could become functionally almost equivalent, even though their parameter representations differ. If the outcomes of all training sessions converge to the same local minima, this empirical phenomenon can be understood. However, considering the complex non-convex nature of the loss surface, the optimization results are unlikely to converge to the same local minima. In recent years, particularly within the context of neural networks, the transformation of model parameters while preserving functional equivalence has been explored by considering the _permutation invariance_ of neurons in each hidden layer [1; 2]. Notably, only a slight performance degradation has been observed when using weights derived through linear interpolation between permuted parameters obtained from different training processes [3; 4]. This demonstrates that the trained models reside in different, yet functionally equivalent, local minima. This situation is referred to as _Linear Mode Connectivity_ (LMC) [5]. From a theoretical perspective, LMC is crucial for supporting the stable and successful application of non-convex optimization. In addition, LMC also holds significant practical importance, enabling techniques such as model merging [6; 7] by weight-space parameter averaging.

Although neural networks are most extensively studied among the models trained using gradient methods, other models also thrive in real-world applications. A representative is tree ensemble models, such as random forests [8]. While they are originally trained by not gradient but greedy algorithms, differentiable _soft tree ensembles_, which learn parameters of the entire model through gradient-basedoptimization, have recently been actively studied. Not only empirical studies regarding accuracy and interpretability [9; 10; 11], but also theoretical analyses have been performed [12; 13]. Moreover, the differentiability of soft trees allows for integration with various deep learning methodologies, including fine-tuning [14], dropout [15], and various stochastic gradient descent methods [16; 17]. Furthermore, the soft tree represents the most elementary form of a hierarchical mixture of experts [18; 19; 20]. Investigating soft tree models not only advances our understanding of this particular structure but also contributes to broader research into essential technological components critical for the development of large-scale language models [21].

A research question that we tackle in this paper is: "Can LMC be achieved for soft tree ensembles?". Our empirical results, which are highlighted with a green line in the top left panel of Figure 1, clearly show that the answer is "Yes". This plot shows the variation in test accuracy when interpolating weights of soft oblivious trees, perfect binary soft trees with shared parameters at each depth, trained from different random initializations. The green line is obtained by our method introduced in this paper, where there is almost zero performance degradation. Furthermore, as shown in the bottom left panel of Figure 1, the performance can even improve when interpolating between models trained on split datasets.

The key insight is that, when performing interpolation between two model parameters, considering only tree permutation invariance, which corresponds to the permutation invariance of neural networks, is _not sufficient_ to achieve LMC, as shown in the orange lines in the plots. An intuitive understanding of this situation is also illustrated in the right panel of Figure 1. To achieve LMC, that is, the green lines, we show that two additional invariances beyond tree permutation, _subtree flip invariance_ and _splitting order invariance_, which inherently exist for tree architectures, should be accounted for.

Moreover, we demonstrate that it is possible to exclude such additional invariances while preserving LMC by modifying tree architectures. We realize such an architecture based on _a decision list_, a binary tree structure where branches extend in only one direction. By designating one of the terminal leaves as an empty node, we introduce a customized decision list that omits both subtree flip invariance and splitting order invariance, and empirically show that this can achieve LMC by considering only tree permutation invariance. Since incorporating additional invariances is computationally expensive, we can efficiently perform weight-space averaging in model merging on our customized decision lists.

Our contributions are summarized as follows:

* First achievement of LMC for tree ensembles with accounting for additional invariances beyond tree permutation.
* Development of a decision list-based tree architecture that does not involve the additional invariances.
* A thorough empirical investigation of LMC across various tree architectures, invariances, and real-world datasets.

## 2 Preliminary

We prepare the basic concepts of LMC and soft tree ensembles.

### Linear Mode Connectivity

Let us consider two models, \(A\) and \(B\), that have the same architecture. In the context of evaluating LMC, the concept of a "barrier" is frequently used [4; 23]. Let \(\bm{\Theta}_{A},\bm{\Theta}_{B}\in\mathbb{R}^{P}\) be vectorized parameters of models \(A\) and \(B\), respectively, for \(P\) parameters. Assume that \(\mathcal{C}:\mathbb{R}^{P}\rightarrow\mathbb{R}\) measures the performance of the model, such as accuracy, given its parameter vector. If higher values of \(\mathcal{C}(\cdot)\)

Figure 1: A representative experimental result on the MiniBooNE [22] dataset (left) and conceptual diagram of the LMC for tree ensembles (right).

mean better performance, the barrier between two parameter vectors \(\bm{\Theta}_{A}\) and \(\bm{\Theta}_{B}\) is defined as:

\[\mathcal{B}(\bm{\Theta}_{A},\bm{\Theta}_{B})=\sup_{\lambda\in[0,1]} \left[\,\lambda\mathcal{C}(\bm{\Theta}_{A})+(1-\lambda)\mathcal{C}(\bm{\Theta}_ {B})-\mathcal{C}(\lambda\bm{\Theta}_{A}+(1-\lambda)\bm{\Theta}_{B})\,\right].\] (1)

We can simply reverse the subtraction order if lower values of \(\mathcal{C}(\cdot)\) mean better performance like loss.

Several techniques have been developed to reduce barriers by transforming parameters while preserving functional equivalence. Two main approaches are _activation matching_ (AM) and _weight matching_ (WM). AM takes the behavior of model inference into account, while WM simply compares two models using their parameters. The validity of both AM and WM has been theoretically supported [24]. Numerous algorithms are available for implementing AM and WM. For instance, [4] uses a formulation based on the Linear Assignment Problem (LAP) to find suitable permutations, while [23] employs a differentiable formulation that allows for the optimization of permutations using gradient-based methods.

Existing research has focused exclusively on neural network architectures such as multi-layer perceptrons (MLP) and convolutional neural networks (CNN). No study has been conducted from the perspective of linear mode connectivity for soft tree ensembles.

### Soft Tree Ensemble

Unlike typical hard decision trees, which explicitly determine the data flow to the right or left at each splitting node, soft trees represent the proportion of data flowing to the right or left as continuous values between 0 and 1. This approach enables a differentiable formulation.

We use a \(\mathrm{sigmoid}\) function, \(\sigma:\mathbb{R}\rightarrow(0,1)\) to formulate a function \(\mu_{m,\ell}(\bm{x}_{i},\bm{w}_{m},\bm{b}_{m}):\mathbb{R}^{F}\times\mathbb{R} ^{F\times\mathcal{N}}\times\mathbb{R}^{1\times\mathcal{N}}\rightarrow(0,1)\) that represents the proportion of the \(i\)th data point \(\bm{x}_{i}\) flowing to the \(\ell\)th leaf of the \(m\)th tree as a result of soft splittings:

\[\mu_{m,\ell}(\bm{x}_{i},\bm{w}_{m},\bm{b}_{m}) =\prod_{n=1}^{\mathcal{N}}\underbrace{\sigma(\bm{w}_{m,n}^{\top} \bm{x}_{i}+b_{m,n})}_{\text{flow to the left}}\bm{\mathrm{1}}^{\bm{\mathrm{1}}_{ \ell^{\prime}\sim n}}(\underbrace{1-\sigma(\bm{w}_{m,n}^{\top}\bm{x}_{i}+b_{m,n })}_{\text{flow to the right}})^{\bm{\mathrm{1}}_{n}\smallsetminus\ell},\] (2)

where \(\mathcal{N}\) denotes the number of splitting nodes in each tree. The parameters \(\bm{w}_{m,n}\in\mathbb{R}^{F}\) and \(b_{m,n}\in\mathbb{R}\) correspond to the feature selection mask and splitting threshold value for \(n\)th node in a \(m\)th tree, respectively. The expression \(\mathds{1}_{\ell^{\prime}\sim n}\) (resp. \(\mathds{1}_{n\smallsetminus\ell}\)) is an indicator function that returns 1 if the \(\ell\)th leaf is positioned to the left (resp. right) of a node \(n\), and 0 otherwise.

If parameters are shared across all splitting nodes at the same depth, such perfect binary trees are called _oblivious trees_. Mathematically, \(\bm{w}_{m,n}=\bm{w}_{m,n^{\prime}}\) and \(b_{m,n}=b_{m,n^{\prime}}\) for any nodes \(n\) and \(n^{\prime}\) at the same depth in an oblivious tree. Oblivious trees can significantly reduce the number of parameters from an exponential to a linear order of the tree depth, and they are actively used in practice [9; 11].

To classify \(C\) categories, the output of the \(m\)th tree is computed by the function \(f_{m}:\mathbb{R}^{F}\times\mathbb{R}^{F\times\mathcal{N}}\times\mathbb{R}^{1 \times\mathcal{N}}\times\mathbb{R}^{C\times\mathcal{L}}\rightarrow\mathbb{R}^{C}\) as sum of the leaf parameters \(\bm{\pi}_{m,\ell}\) weighted by the outputs of \(\mu_{m,\ell}(\bm{x}_{i},\bm{w}_{m},\bm{b}_{m})\):

\[f_{m}(\bm{x}_{i},\bm{w}_{m},\bm{b}_{m},\bm{\pi}_{m})=\sum_{\ell= 1}^{\mathcal{L}}\bm{\pi}_{m,\ell}\mu_{m,\ell}(\bm{x}_{i},\bm{w}_{m},\bm{b}_{m}),\] (3)

where \(\mathcal{L}\) is the number of leaves in a tree. By combining this function for \(M\) trees, we realize the function \(f:\mathbb{R}^{F}\times\mathbb{R}^{M\times F\times\mathcal{N}}\times\mathbb{R} ^{M\times 1\times\mathcal{N}}\times\mathbb{R}^{M\times C\times\mathcal{L}} \rightarrow\mathbb{R}^{C}\) as an ensemble model consisting of \(M\) trees:

\[f(\bm{x}_{i},\bm{w},\bm{b},\bm{\pi})=\sum_{m=1}^{M}f_{m}(\bm{x}_ {i},\bm{w}_{m},\bm{b}_{m},\bm{\pi}_{m}),\] (4)

with the parameters \(\bm{w}=(\bm{w}_{1},\ldots,\bm{w}_{M})\), \(\bm{b}=(\bm{b}_{1},\ldots,\bm{b}_{M})\), and \(\bm{\pi}=(\bm{\pi}_{1},\ldots,\bm{\pi}_{M})\) being randomly initialized.

Despite the apparent differences, there are correspondences between MLPs and soft tree ensemble models. The formulation of a soft tree ensemble with \(D=1\) is:

\[f(\bm{x}_{i},\bm{w},\bm{b},\bm{\pi}) =\sum_{m=1}^{M}\Big{(}\,\sigma(\bm{w}_{m,1}^{\top}\bm{x}_{i}+b_{m,1 })\bm{\pi}_{m,1}+(1-\sigma(\bm{w}_{m,1}^{\top}\bm{x}_{i}+b_{m,1}))\bm{\pi}_{m,2 }\,\Big{)}\] \[=\sum_{m=1}^{M}\Big{(}\,(\bm{\pi}_{m,1}-\bm{\pi}_{m,2})\sigma(\bm {w}_{m,1}^{\top}\bm{x}_{i}+b_{m,1})+\bm{\pi}_{m,2}\,\Big{)}.\] (5)

When we consider the correspondence between \(\bm{\pi}_{m,1}-\bm{\pi}_{m,2}\) in tree ensembles and second layer weights in the two-layer perceptron, the tree ensembles model matches to the two-layer perceptron. It is clear from the formulation that the permutation of hidden neurons in a neural network corresponds to the rearrangement of trees in a tree ensemble.

## 3 Invariances Inherent to Tree Ensembles

In this section, we discuss additional invariances inherent to trees (Section 3.1) and introduce a matching strategy specifically for tree ensembles (Section 3.2). We also show that the presence of additional invariances varies depending on the tree structure, and we present tree structures where no additional invariances beyond tree permutation exist (Section 3.3).

### Parameter modification processes that maintains functional equivalence in tree ensembles

First, we clarify what invariances should be considered for tree ensembles, which are expected to reduce the barrier significantly if taken into account. When we consider perfect binary trees, there are three types of invariance:

* **Tree permutation invariance.** In Equation (4), the behavior of the function does not change even if the order of the \(M\) trees is altered. This corresponds to the permutation of internal nodes in neural networks, which has been a subject of active interest in previous studies on LMC.
* **Subtree flip invariance.** When the left and right subtrees are swapped simultaneously with the inversion of the inequality sign at the split, the functional behavior remains unchanged, which we refer to _subtree flip invariance_. Figure 2(a) presents a schematic diagram of this invariance, which is not found in neural networks but is unique to binary tree-based models. Since \(\sigma(-c)=1-\sigma(c)\) for \(c\in\mathbb{R}\) due to the symmetry of \(\mathrm{sigmoid}\), the inversion of the inequality is achieved by inverting the signs of \(\bm{w}_{m,n}\) and \(b_{m,n}\). [25] also focused on the sign of weights, but in a different way from ours. They pay attention to the amount of change from the parameters at the start of fine-tuning, rather than discussing the sign of the parameters.
* **Splitting order invariance.** Oblivious trees share parameters at the same depth, which means that the decision boundaries are straight lines without any bends. With this characteristic, even if the splitting rules at different depths are swapped, functional equivalence can be achieved if the positions of leaves are also swapped appropriately as shown in Figure 2(b). This invariance does not exist for non-oblivious perfect binary trees without parameter sharing, as the behavior of the decision boundary varies depending on the splitting order.

Figure 2: (a) Subtree flip invariance. (b) Splitting order invariance for an oblivious tree.

Note that MLPs also have an additional invariance beyond just permutation. Particularly in MLPs that employ ReLU as an activation function, the output of each layer changes linearly with a zero crossover. Therefore, it is possible to modify parameters without changing functional behavior by multiplying the weights in one layer by a constant and dividing the weights in the previous layer by the same constant. However, since the soft tree is based on the sigmoid function, this invariance does not apply. Previous studies [3; 4; 23] have consistently achieved significant reductions in barriers without accounting for this scale invariance. One potential reason is that changes in parameter scale are unlikely due to the nature of optimization via gradient descent. Conversely, when we consider additional invariances inherent to trees, the scale is equivalent to the original parameters.

### Matching Strategy

Here, we propose a matching strategy for binary trees. When considering invariances, it is necessary to compare multiple functionally equivalent trees and select the most suitable one for achieving LMC. Although comparing tree parameters is a straightforward approach, since the contribution of all the parameters in a tree is not equal, we apply weighting for each node for better matching. By interpreting a tree as a rule set with shared parameters as shown in Figure 3, we determine the weight of each splitting node by counting the number of leaves to which the node affects. For example, in the case of the left example in Figure 3, the root node affects eight leaves, nodes at depth \(2\) affect four leaves, and nodes at depth \(3\) affect two leaves. This strategy can apply to even trees other than perfect binary trees. For example, in the right example of Figure 3, the root node affects four leaves, a node at depth \(2\) affects three leaves, and a node at depth \(3\) affects two leaves.

In this paper, we employ the LAP, which is used as a standard benchmark [4] for matching algorithms. The procedures for AM and WM are as follows. Detailed algorithms (Algorithms 1 and 2) are described in Section A in the supplementary material.

* **Activation Matching (Algorithm 1).** In trees, there is nothing that directly corresponds to the activations in neural networks. However, by treating the output of each individual tree as an activation value of a neural network, it is possible to optimize the permutation of trees while examining their output similarities. Regarding subtree flip and splitting order invariances, it is possible to find the optimal pattern from all the possible patterns of flips and changes in the splitting order. Since the tree-wise output remains unchanged, the similarity between each tree, generated by considering additional invariances, and the target tree is evaluated based on the inner product of parameters while applying node-wise weighting.
* **Weight Matching (Algorithm 2).** Similar to AM, WM also involves applying weighting while extracting the optimal pattern by exploring possible flipping and ordering patterns. Although it is necessary to solve the LAP multiple times for each layer in MLPs [4], tree ensembles require only a single run of the LAP since there are no layers.

The time complexity of solving the LAP is \(\mathcal{O}(M^{3})\) using a modified Jonker-Volgenant algorithm without initialization [26], implemented in SciPy [27], where \(M\) is the number of trees. If only considering tree permutation, this process needs to be performed only once in both WM and AM. However, when considering additional invariances, we need to solve the LAP for each pattern generated by considering these additional invariances. In a non-oblivious perfect binary tree with depth \(D\), there are \(2^{D}-1\) splitting nodes, leading to \(2^{2^{D}-1}\) possible combinations of sign flips. Additionally, in the case of oblivious trees, there are \(D!\) different patterns of splitting order invariance. Therefore, for large values of \(D\), conducting a brute-force search becomes impractical.

In Section 3.3, we will discuss methods to eliminate additional invariance by adjusting the tree structure. This enables efficient matching even for deep models. Additionally, in Section 4.2, we will present numerical experiment results and discuss that the practical motivation to apply these algorithms is limited when targeting deep perfect binary trees.

Figure 3: Weighting strategy.

### Architecture-dependency of the Invariances

In previous subsections, tree architectures are fixed to perfect binary trees as they are most commonly and practically used in soft trees. However, tree architectures can be flexible as we have shown in the right example in Figure 3, and here we show that we can specifically design tree architecture that has neither the subtree flip nor splitting order invariances. This allows efficient matching as considering such two invariances is computationally expensive.

Our idea is to modify a _decision list_ shown on the left side of Figure 4, which is a tree structure where branches extend in only one direction. Due to this asymmetric structure, the number of parameters does not increase exponentially with the depth, and the splitting order invariance does not exist. Moreover, subtree flip invariance also does not exist for any internal nodes except for the terminal splitting node, as shown in the left side of Figure 4. To completely remove this invariance, we virtually eliminate one of the terminal leaves by leaving the node empty, that is, a fixed prediction value of zero, as shown on the right side of Figure 4. Therefore only permutation invariance exists for our proposed architecture. We summarize invariances inherent to each model architecture in Table 1.

## 4 Experiment

We empirically evaluate barriers in soft tree ensembles to examine LMC.

### Setup

Datasets.In our experiments, we employed Tabular-Benchmark [28], a collection of tabular datasets suitable for evaluating tree ensembles. Details of datasets are provided in Section B in the supplementary material. As proposed in [28], we randomly sampled \(10,000\) instances for train and test data from each dataset. If the dataset contains fewer than \(20,000\) instances, they are randomly divided into halves for train and test data. We applied quantile transformation to each feature and standardized it to follow a normal distribution.

Hyperparameters.We used three different learning rates \(\eta\in\{0.01,0.001,0.0001\}\) and adopted the one that yields the highest training accuracy for each dataset. The batch size is set at \(512\). It is known that the optimal settings for the learning rate and batch size are interdependent [29]. Therefore, it is reasonable to fix the batch size while adjusting the learning rate. During AM, we set the amount of data used for random sampling to be the same as the batch size, thus using \(512\) samples to measure the similarity of the tree outputs. As the number of trees \(M\) and their depths \(D\) vary for each experiment, these details will be specified in the experimental results section. During training, we minimized cross-entropy using Adam [16] with its default hyperparameters1. Training is conducted for \(50\) epochs. To measure the barrier using Equation (1), experiments were conducted by interpolating between two models with \(\lambda\in\{0,1/24,\dots,23/24,1\}\), which has the same granularity as in [4].

Footnote 1: https://pytorch.org/docs/stable/generated/torch.optim.Adam.html

Randomness.We conducted experiments with five different random seed pairs: \(r_{A}\in\{1,3,5,7,9\}\) and \(r_{B}\in\{2,4,6,8,10\}\). As a result, the initial parameters and the contents of the data mini-batches during training are different in each training. In contrast to spawning [5] that branches off from the exact same model pathway through, we used more challenging practical conditions. The parameters \(\bm{w}\), \(\bm{b}\), and \(\bm{\pi}\) were randomly initialized using a uniform distribution, identical to the procedure for a fully connected layer in the MLP2.

\begin{table}
\begin{tabular}{c c c c} \hline \hline  & **Perm** & **Flip** & **Order** \\ \hline Non-Oblivious Tree & ✓ & ✓ & \(\times\) \\ Oblivious Tree & ✓ & ✓ & ✓ \\ Decision List & ✓ & (✓) & \(\times\) \\ Decision List (Modified) & ✓ & \(\times\) & \(\times\) \\ \hline \hline \end{tabular}
\end{table}
Table 1: Invariances inherent to each model architecture.

Figure 4: Tree architecture where neither subtree flip invariance nor splitting order invariance exists.

**Resources.** All experiments were conducted on a system equipped with an Intel Xeon E5-2698 CPU at 2.20 GHz, 252 GB of memory, and Tesla V100-DGXS-32GB GPU, running Ubuntu Linux (version 4.15.0-117-generic). The reproducible PyTorch [30] implementation is provided in the supplementary material.

### Results for Perfect Binary Trees

Figure 5 shows how the barrier between two perfect binary tree model pairs changes in each operation. The vertical axis of each plot in Figure 5 shows the averaged barrier over datasets for each considered invariance. The results for both the oblivious and non-oblivious trees are plotted separately in a vertical layout. The panels on the left display the results when the depth \(D\) of the tree varies, keeping \(M=256\) constant. The panels on the right show the results when the number of trees \(M\) varies, with \(D\) fixed at \(2\). For both oblivious and non-oblivious trees, we observed that the barrier significantly decreases as the considered invariances increase. Focusing on the test data results, after accounting for various invariances, the barrier is nearly zero, indicating that LMC has been achieved. In particular, the difference between the case of only permutation and the case where additional invariances are considered tends to be larger in the case of AM. This is because parameter values are not used during the rearrangement of the tree in AM. Additionally, it has been observed that the barrier increases as trees become deeper, and the barrier decreases as the number of trees increases. These behaviors correspond to the changes observed in neural networks when the depth varies or when the width of hidden layers increases [3, 4]. Figure 6 shows interpolation curves when using AM in oblivious trees

Figure 5: Barriers averaged across 16 datasets with respect to considered invariances for non-oblivious (top row) and oblivious (bottom row) trees. The error bars show the standard deviations of 5 executions.

Figure 6: Interpolation curves of test accuracy for oblivious trees on 16 datasets from Tabular-Benchmark [28]. Two model pairs are trained with on the same dataset. The error bars show the standard deviations of \(5\) executions. We used \(M=256\) trees with a depth \(D=2\).

with \(D=2\) and \(M=256\). Other detailed results, such as performance for each dataset, are provided in Section C in the supplementary material.

Furthermore, we conducted experiments with split data following the protocol in [4, 31], where the initial split consists of randomly sampled 80% negative and 20% positive instances, and the second split inverts these ratios. There is no overlap between the two split datasets. We trained two model pairs using these separately split datasets and observed an improvement in performance by interpolating their parameters. Figure 7 illustrates the interpolation curves under AM in oblivious trees with parameters \(D=2\) and \(M=256\). We can observe that considering additional invariances improves performance after interpolation. Note that the data split is configured to remain consistent even when the training random seeds differ. Detailed results for each dataset using WM or AM are provided in Section C of the supplementary material.

Table 2 compares the average test barriers of an MLP with a ReLU activation function, whose width is equal to the number of trees, \(M=256\). The procedure for MLPs follows that described in Section 4.1. The permutation for MLPs is optimized using the method described in [4]. Since [4] indicated that WM outperforms AM in neural networks, WM was used for the comparison. Overall, tree models exhibit smaller barriers compared to MLPs while keeping similar accuracy levels. It is important to note that MLPs with \(D>1\) tend to have more parameters at the same depth compared to trees, leading to more complex optimization landscapes. Nevertheless, the barrier for the non-oblivious tree at \(D=3\) is smaller than that for the MLP at \(D=2\), even with more parameters. Furthermore, at the same depth of \(D=1\), tree models have a smaller barrier. Here, the model size is evaluated using \(F=44\), the average input feature size of 16 datasets used in the experiments.

In Section 3.2, we have shown that considering additional invariances for deep perfect binary trees is computationally challenging, which may suggest developing heuristic algorithms for deep trees. However, we consider it is rather a low priority, supported by our observations that the barrier tends to increase as trees deepen even if we consider invariances. This trend indicates that deep models are fundamentally less important for model merging considerations. Furthermore, deep perfect binary trees are rarely used in practical scenarios. [12] have demonstrated that generalization performance degrades with increasing depth in perfect binary trees due to the degeneracy of the Neural Tangent Kernel (NTK) [32]. This evidence further supports the preference for shallow perfect binary trees, and increasing the number of trees can enhance the expressive power while reducing barriers.

\begin{table}
\begin{tabular}{c c c c c c} \hline \hline  & \multicolumn{4}{c}{**MLP**} \\ \cline{2-6}
**Depth** & \multicolumn{3}{c}{**Barrier**} & \multicolumn{1}{c}{**Accuracy**} & **Size** \\ \cline{2-6}  & **NaNa** & **Perm** [4] & **Accuracy** & **Size** \\ \hline
1 & 8.955 \(\pm\) 0.877 & 0.491 \(\pm\) 0.062 & 76.286 \(\pm\) 0.094 & 12034 \\
2 & 15.341 \(\pm\) 1.125 & 2.997 \(\pm\) 0.709 & 75.981 \(\pm\) 0.139 & 77826 \\
3 & 15.915 \(\pm\) 2.479 & 5.940 \(\pm\) 2.153 & 75.935 \(\pm\) 0.117 & 143618 \\ \hline \hline \end{tabular} 
\begin{tabular}{c c c c c c} \hline \hline  & \multicolumn{4}{c}{**Non-Oblivious Tree**} \\ \cline{2-6}
**Depth** & \multicolumn{3}{c}{**Barrier**} & \multicolumn{1}{c}{**Accuracy**} & **Size** \\ \cline{2-6}  & **NaNa** & **Perm** & **Ours** & & & \\ \hline
1 & 8.965 \(\pm\) 0.963 & 0.449 \(\pm\) 0.235 & 0.181 \(\pm\) 0.078 & 76.464 \(\pm\) 0.167 & 12544 \\
2 & 6.801 \(\pm\) 0.464 & 0.811 \(\pm\) 0.333 & 0.455 \(\pm\) 0.105 & 76.631 \(\pm\) 0.052 & 36688 \\
3 & 5.602 \(\pm\) 0.926 & 16.85 \(\pm\) 0.334 & 0.740 \(\pm\) 0.158 & 76.339 \(\pm\) 0.115 & 84736 \\ \hline \hline \end{tabular} 
\begin{tabular}{c c c c c c} \hline \hline  & \multicolumn{4}{c}{**Oblivious Tree**} \\ \cline{2-6}
**Depth** & \multicolumn{3}{c}{**Barrier**} & \multicolumn{1}{c}{**Accuracy**} & **Size** \\ \cline{2-6}  & **NaNa** & **Perm** & **Ours** & & & \\ \hline
1 & 8.965 \(\pm\) 0.963 & 0.449 \(\pm\) 0.235 & 0.181 \(\pm\) 0.078 & 76.464 \(\pm\) 0.167 & 12544 \\
2 & 7.831 \(\pm\) 0.886 & 0.918 \(\pm\) 0.092 & 0.348 \(\pm\) 0.172 & 76.623 \(\pm\) 0.042 & 25088 \\
3 & 7.096 \(\pm\) 0.856 & 1.283 \(\pm\) 0.139 & 0.484 \(\pm\) 0.092 & 76.535 \(\pm\) 0.063 & 38656 \\ \hline \hline \end{tabular}
\end{table}
Table 2: Barriers, accuracies, and model sizes for MLP, non-oblivious trees, and oblivious trees.

Figure 7: Interpolation curves of test accuracy for oblivious trees on 16 datasets from Tabular-Benchmark [28]. Two model pairs are trained on split datasets with different class ratios. The error bars show the standard deviations of \(5\) executions. We used \(M=256\) trees with a depth \(D=2\).

### Results for Decision Lists

We present empirical results of the original decision lists and our modified decision lists, as shown in Figure 4. As we have shown in Table 1, they have fewer invariances.

Figure 8 illustrates barriers as a function of depth, considering only permutation invariance, with \(M\) fixed at \(256\). In this experiment, we have excluded non-oblivious trees from comparison as the number of their parameters exponentially increases as trees deepen, making them infeasible computation. Our proposed modified decision lists reduce the barrier more effectively than both oblivious trees and the original decision lists. However, barriers of the modified decision lists are still larger than those obtained by considering additional invariances with perfect binary trees. Tables 3 and 4 show the averaged barriers for 16 datasets, with \(D=2\) and \(M=256\). Although barriers of modified decision lists are small when considering only permutations (Perm), perfect binary trees such as oblivious trees with additional invariances (Ours) exhibit smaller barriers, which supports the validity of using oblivious trees as in [9; 11]. To summarize, when considering the practical use of model merging, if the goal is to prioritize efficient computation, we recommend using our proposed decision list. Conversely, if the goal is to prioritize barriers, it would be preferable to use perfect binary trees, which have a greater number of invariant operations that maintain the functional behavior.

## 5 Conclusion

We have presented the first investigation of LMC for soft tree ensembles. We have identified additional invariances inherent in tree architectures and empirically demonstrated the importance of considering these factors. Achieving LMC is crucial not only for understanding the behavior of non-convex optimization from a learning theory perspective but also for implementing practical techniques such as model merging. By arithmetically combining parameters of differently trained models, a wide range of applications such as task-arithmetic [33], including unlearning [34] and continual-learning [35], have been explored. Our research extends these techniques to soft tree ensembles that began training from entirely different initial conditions. We will leave these empirical investigations for future work.

This study provides a fundamental analysis of ensemble learning, and we believe that our discussion will not have any negative societal impacts.

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \hline \multirow{2}{*}{**Architecture**} & \multicolumn{4}{c}{**Train**} & \multicolumn{4}{c}{**Test**} \\ \cline{2-9}  & \multicolumn{3}{c}{**Barrier**} & \multirow{2}{*}{**Accuracy**} & \multicolumn{2}{c}{**Baririer**} & \multirow{2}{*}{**Accuracy**} \\ \cline{2-9} \cline{5-9}  & **Naïve** & & & & & & & & & \\ \cline{2-9}  & **Naïve** & **Perm** & **Ours** & & & & & & \\ \hline Non-Oblivious Tree & 13.079 \(\pm\) 0.755 & 14.963 \(\pm\) 1.520 & 4.500 \(\pm\) 0.527 & 85.646 \(\pm\) 0.090 & 6.801 \(\pm\) 0.464 & 8.631 \(\pm\) 1.444 & 0.943 \(\pm\) 0.435 & 76.631 \(\pm\) 0.052 \\ Oblivious Tree & 14.580 \(\pm\) 1.008 & 17.380 \(\pm\) 0.590 & 3.557 \(\pm\) 0.201 & 85.088 \(\pm\) 0.146 & 7.831 \(\pm\) 0.086 & 1.349 \(\pm\) 0.476 & 0.395 \(\pm\) 0.185 & 76.623 \(\pm\) 0.042 \\ Decision List & 13.853 \(\pm\) 0.788 & 12.85 \(\pm\) 1.942 & — & 85.337 \(\pm\) 0.147 & 7.513 \(\pm\) 0.944 & 7.25 \(\pm\) 1.840 & — & 76.7629 \(\pm\) 0.119 \\ Decision List (Modified) & 12.922 \(\pm\) 1.131 & 3.328 \(\pm\) 0.204 & — & 85.563 \(\pm\) 0.141 & 6.734 \(\pm\) 1.096 & 2.114 \(\pm\) 0.243 & — & 76.773 \(\pm\) 0.051 \\ \hline \hline \end{tabular}
\end{table}
Table 4: Barriers averaged for 16 datasets under AM with \(D=2\) and \(M=256\).

Figure 8: Averaged barrier for 16 datasets as a function of tree depth. The error bars show the standard deviations of 5 executions. The solid line represents the barrier in train accuracy, while the dashed line represents the barrier in test accuracy.

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \hline \multirow{2}{*}{**Architecture**} & \multicolumn{4}{c}{**Train**} & \multicolumn{4}{c}{**Test**} \\ \cline{2-9}  & \multicolumn{3}{c}{**Barrier**} & \multirow{2}{*}{**Accuracy**} & \multicolumn{2}{c}{**Barrier**} & \multirow{2}{*}{**Accuracy**} \\ \cline{2-9} \cline{5-9}  & **Naïve** & & & & & & & & \\ \hline Non-Oblivious Tree & 13.079 \(\pm\) 0.755 & 4.707 \(\pm\) 0.332 & 3.303 \(\pm\) 0.104 & 85.646 \(\pm\) 0.059 & 6.801 \(\pm\) 0.464 & 0.811 \(\pm\) 0.333 & 0.455 \(\pm\) 0.105 & 76.631 \(\pm\) 0.052 \\ Oblivious Tree & 13.079 \(\pm\) 1.058 & 4.534 \(\pm\) 0.176 & 2.874 \(\pm\) 0.108 & 85.908 \(\pm\) 0.106 & 7.831 \(\pm\) 0.066 & 0.919 \(\pm\) 0.093 & 0.348 \(\pm\) 0.172 & 76.632 \(\pm\) 0.042 \\ Decision List & 13.835 \(\pm\) 0.788 & 8.678 \(\pm\) 0.230 & — & 85.337 \(\pm\) 0.147 & 7.513 \(\pm\) 0.944 & 0.462 \(\pm\) 0.120 & — & 76.629 \(\pm\) 0.119 \\ Decision List (Modified) & 12.922 \(\pm\) 1.131 & 3.328 \(\pm\) 0.204 & — & 85.563 \(\pm\) 0.141 & 6.734 \(\pm\) 1.096 & 0.468 \(\pm\) 0.150 & — & 76.773 \(\pm\) 0.051 \\ \hline \hline \end{tabular}
\end{table}
Table 3: Barriers averaged for 16 datasets under WM with \(D=2\) and \(M=256\).

## References

* Hecht-Nielsen [1990] Robert Hecht-Nielsen. On the algebraic structure of feedforward network weight spaces. In _Advanced Neural Computers_. 1990.
* Chen et al. [1993] An Mei Chen, Haw-minu Lu, and Robert Hecht-Nielsen. On the Geometry of Feedforward Neural Network Error Surfaces. _Neural Computation_, 1993.
* Entezari et al. [2022] Rahim Entezari, Hanie Sedghi, Olga Saukh, and Behnam Neyshabur. The Role of Permutation Invariance in Linear Mode Connectivity of Neural Networks. In _International Conference on Learning Representations_, 2022.
* Ainsworth et al. [2023] Samuel Ainsworth, Jonathan Hayase, and Siddhartha Srinivasa. Git Re-Basin: Merging Models modulo Permutation Symmetries. In _The Eleventh International Conference on Learning Representations_, 2023.
* Frankle et al. [2020] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel Roy, and Michael Carbin. Linear Mode Connectivity and the Lottery Ticket Hypothesis. In _Proceedings of the 37th International Conference on Machine Learning_, 2020.
* Wortsman et al. [2022] Mitchell Wortsman, Gabriel Ilharco, Samir Ya Gadre, Rebecca Roelofs, Raphael Gontijo-Lopes, Ari S Morcos, Hongseok Namkoong, Ali Farhadi, Yair Carmon, Simon Kornblith, and Ludwig Schmidt. Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time. In _Proceedings of the 39th International Conference on Machine Learning_, 2022.
* Ortiz-Jimenez et al. [2023] Guillermo Ortiz-Jimenez, Alessandro Favero, and Pascal Frossard. Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained Models. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.
* Breiman [2001] Leo Breiman. Random Forests. In _Machine Learning_, 2001.
* Popov et al. [2020] Sergei Popov, Stanislav Morozov, and Artem Babenko. Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data. In _International Conference on Learning Representations_, 2020.
* Hazimeh et al. [2020] Hussein Hazimeh, Natalia Ponomareva, Petros Mol, Zhenyu Tan, and Rahul Mazumder. The Tree Ensemble Layer: Differentiability meets Conditional Computation. In _Proceedings of the 37th International Conference on Machine Learning_, 2020.
* Chang et al. [2022] Chun-Hao Chang, Rich Caruana, and Anna Goldenberg. NODE-GAM: Neural generalized additive model for interpretable deep learning. In _International Conference on Learning Representations_, 2022.
* Kanoh and Sugiyama [2022] Ryuichi Kanoh and Mahito Sugiyama. A Neural Tangent Kernel Perspective of Infinite Tree Ensembles. In _International Conference on Learning Representations_, 2022.
* Kanoh and Sugiyama [2023] Ryuichi Kanoh and Mahito Sugiyama. Analyzing Tree Architectures in Ensembles via Neural Tangent Kernel. In _International Conference on Learning Representations_, 2023.
* Ke et al. [2019] Guolin Ke, Zhenhui Xu, Jia Zhang, Jiang Bian, and Tie-Yan Liu. DeepGBM: A Deep Learning Framework Distilled by GBDT for Online Prediction Tasks. In _Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_, 2019.
* Srivastava et al. [2014] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. _Journal of Machine Learning Research_, 2014.
* Kingma and Ba [2015] Diederik Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. In _International Conference on Learning Representations_, 2015.
* Foret et al. [2021] Pierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur. Sharpness-aware Minimization for Efficiently Improving Generalization. In _International Conference on Learning Representations_, 2021.

* [18] M.I. Jordan and R.A. Jacobs. Hierarchical mixtures of experts and the EM algorithm. In _Proceedings of International Conference on Neural Networks_, 1993.
* [19] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc V. Le, Geoffrey E. Hinton, and Jeff Dean. Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer. In _International Conference on Learning Representations_, 2017.
* [20] Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding. In _International Conference on Learning Representations_, 2021.
* [21] Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lelio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothee Lacroix, and William El Sayed. Mistral 7B, 2023.
* [22] Byron Roe. MiniBooNE particle identification. UCI Machine Learning Repository, 2010.
* [23] Fidel A. Guerrero Pena, Heitor Rapela Medeiros, Thomas Dubail, Masih Aminbeidokhti, Eric Granger, and Marco Pedersoli. Re-basin via implicit Sinkhorn differentiation. In _IEEE/CVF Conference on Computer Vision and Pattern Recognition_, 2023.
* [24] Zhanpeng Zhou, Yongyi Yang, Xiaojiang Yang, Junchi Yan, and Wei Hu. Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature Connectivity. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.
* [25] Prateek Yadav, Derek Tam, Leshem Choshen, Colin Raffel, and Mohit Bansal. TIES-merging: Resolving interference when merging models. In _Thirty-seventh Conference on Neural Information Processing Systems_, 2023.
* [26] David F. Crouse. On implementing 2D rectangular assignment algorithms. _IEEE Transactions on Aerospace and Electronic Systems_, 2016.
* [27] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stefan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, C J Carey, Ilhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R. Harris, Anne M. Archibald, Antonio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. _Nature Methods_, 2020.
* [28] Leo Grinsztajn, Edouard Oyallon, and Gael Varoquaux. Why do tree-based models still outperform deep learning on typical tabular data? In _Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track_, 2022.
* [29] Samuel L. Smith, Pieter-Jan Kindermans, and Quoc V. Le. Don't Decay the Learning Rate, Increase the Batch Size. In _International Conference on Learning Representations_, 2018.
* [30] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style, High-Performance Deep Learning Library. In _Advances in Neural Information Processing Systems_, 2019.
* [31] Keller Jordan, Hanie Sedghi, Olga Saukh, Rahim Entezari, and Behnam Neyshabur. REPAIR: REnormalizing permuted activations for interpolation repair. In _The Eleventh International Conference on Learning Representations_, 2023.
* [32] Arthur Jacot, Franck Gabriel, and Clement Hongler. Neural Tangent Kernel: Convergence and Generalization in Neural Networks. In _Advances in Neural Information Processing Systems_, 2018.

* [33] Gabriel Ilharco, Marco Tulio Ribeiro, Mitchell Wortsman, Ludwig Schmidt, Hannaneh Hajishirzi, and Ali Farhadi. Editing models with task arithmetic. In _The Eleventh International Conference on Learning Representations_, 2023.
* [34] Ximing Lu, Sean Welleck, Jack Hessel, Liwei Jiang, Lianhui Qin, Peter West, Prithviraj Ammanabrolu, and Yejin Choi. QUARK: Controllable text generation with reinforced unlearning. In _Advances in Neural Information Processing Systems_, 2022.
* [35] Seyed Iman Mirzadeh, Mehrdad Farajtabar, Dilan Gorur, Razvan Pascanu, and Hassan Ghasemzadeh. Linear Mode Connectivity in Multitask and Continual Learning. In _International Conference on Learning Representations_, 2021.

Detailed Algorithms

We present pseudo-code of algorithms for activation matching (Algorithm 1) and weight matching (Algorithm 2). In these algorithms, if there is only one possible pattern for \(U\in\mathbb{N}\), which represents the number of possible operations, and the corresponding operation does nothing in particular, it becomes equivalent to simply considering tree permutations.

```
1ActivationMatching(\(\bm{\Theta}_{A}\in\mathbb{R}^{M\times P_{\text{tree}}}\), \(\bm{\Theta}_{B}\in\mathbb{R}^{M\times P_{\text{tree}}}\), \(\bm{x}_{\text{sampled}}\in\mathbb{R}^{F\times N_{\text{sampled}}}\)) Initialize \(\bm{O}_{A}\in\mathbb{R}^{M\times N_{\text{sampled}}\times C}\) and \(\bm{O}_{B}\in\mathbb{R}^{M\times N_{\text{sampled}}\times C}\) to store outputs for\(m=1\)to\(M\)do
2for\(i=1\)to\(N_{\text{sampled}}\)do
3 Set the output of the \(m\)th tree with \(\bm{\Theta}_{A}[m]\) using \(\bm{x}_{\text{sampled}}[:,i]\) to \(\bm{O}_{A}[m,i]\). Set the output of the \(m\)th tree with \(\bm{\Theta}_{B}[m]\) using \(\bm{x}_{\text{sampled}}[:,i]\) to \(\bm{O}_{B}[m,i]\).
4 Initialize similarity matrix \(\bm{S}\in\mathbb{R}^{M\times M}\)for\(m_{A}=1\)to\(M\)do
5for\(m_{B}=1\)to\(M\)do
6\(\bm{S}[m_{A},m_{B}]\leftarrow\textsc{Flatten}(\bm{O}_{A}[m_{A}])\cdot\textsc{ Flatten}(\bm{O}_{B}[m_{B}])\)
7\(\bm{p}\leftarrow\textsc{LinearSumAssignment}(\bm{S})\)// \(\bm{p}\in\mathbb{N}^{M}\): Optimal assignments \(\bm{\Theta}_{A},\bm{\Theta}_{B}\leftarrow\textsc{Weighting}(\bm{\Theta}_{A}, \bm{\Theta}_{B})\) Initialize operation indices \(\bm{q}\in\mathbb{N}^{M}\)for\(m=1\)to\(M\)do
8for\(u=1\)to\(U\)do// \(U\in\mathbb{N}\): Number of possible operations
9\(u^{\prime}\leftarrow\textsc{UpdateBestOperation}(\textsc{AdjustTree}(\bm{\Theta}_{A}[m],u) \cdot\bm{\Theta}_{B}[m],u)\) Append \(u^{\prime}\) to \(\bm{q}\)// \(\bm{q}\in\mathbb{N}^{M}\): Optimal operations
10return\(\bm{p},\bm{q}\) ```

**Algorithm 1**Activation matching for soft trees

Here, we describe the specifications of the notations and functions used in Algorithms 1 and 2. In Section 2.1, \(\bm{\Theta}_{A}\) and \(\bm{\Theta}_{B}\) are initially defined as vectors. However, for ease of use, in Algorithms 1 and 2, \(\bm{\Theta}_{A}\) and \(\bm{\Theta}_{B}\) are represented as matrices of size \(\mathbb{R}^{M\times P_{\text{tree}}}\), where \(P_{\text{Tree}}\) denotes the number of parameters in a single tree. Multidimensional array elements are accessed using square brackets [\(\cdot\)]. For example, for \(\bm{G}\in\mathbb{R}^{I\times J}\), \(\bm{G}[i]\) refers to the \(i\)th slice along the first dimension, and \(\bm{G}[:,j]\) refers to the \(j\)th slice along the second dimension, with sizes \(\mathbb{R}^{J}\) and \(\mathbb{R}^{I}\), respectively. Furthermore, it can also accept a vector \(\bm{v}\in\mathbb{N}^{l}\) as an input. In this case, \(\bm{G}[\bm{v}]\in\mathbb{R}^{l\times J}\). The Flatten function converts multidimensional input into a one-dimensional vector format. As the LinearSumAssignment

[MISSING_PAGE_FAIL:14]

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline \multirow{2}{*}{**Dataset**} & \multicolumn{4}{c}{**Train**} & \multicolumn{4}{c}{**Test**} \\ \cline{2-7}  & **Naive** & **Pern** & **Perm&**\&**\&**Flip** & **Naive** & **Perm** & **Perm\&**\&Flip** \\ \hline Bioresponse & 18.944 \(\pm\) 1.0076 & 5.876 \(\pm\) 1.477 & 4.132 \(\pm\) 0.893 & 8.235 \(\pm\) 6.456 & 1.265 \(\pm\) 0.635 & 0.314 \(\pm\) 0.432 \\ Diabetes130US & 2.148 \(\pm\) 0.601 & 1.388 \(\pm\) 1.599 & 0.947 \(\pm\) 0.883 & 1.044 \(\pm\) 0.959 & 0.540 \(\pm\) 0.999 & 0.784 \(\pm\) 0.840 \\ Higs & 27.578 \(\pm\) 1.742 & 8.187 \(\pm\) 0.769 & 1.477 \(\pm\) 1.423 & 4.045 \(\pm\) 0.889 & 0.662 \(\pm\) 0.590 & 0.292 \(\pm\) 0.421 \\ MagicTelescope & 2.995 \(\pm\) 1.139 & 3.057 \(\pm\) 0.365 & 3.027 \(\pm\) 0.346 & 2.006 \(\pm\) 1.055 & 0.361 \(\pm\) 0.618 & 0.229 \(\pm\) 0.438 \\ MiniBowCE & 18.283 \(\pm\) 4.700 & 1.402 \(\pm\) 3.398 & 1.256 \(\pm\) 0.211 & 1.259 \(\pm\) 4.190 & 2.031 \(\pm\) 0.314 & 0.000 \(\pm\) 0.000 \\ bank-marketing & 13.999 \(\pm\) 4.110 & 2.711 \(\pm\) 1.183 & 1.521 \(\pm\) 0.463 & 1.359 \(\pm\) 4.567 & 1.843 \(\pm\) 1.001 & 0.953 \(\pm\) 0.688 \\ coiffusion & 6.396 \(\pm\) 2.472 & 8.073 \(\pm\) 0.591 & 0.503 \(\pm\) 0.317 & 5.226 \(\pm\) 3.977 & 0.224 \(\pm\) 0.428 & 0.206 \(\pm\) 0.131 \\ covertype & 16.832 \(\pm\) 4.159 & 1.839 \(\pm\) 0.336 & 0.914 \(\pm\) 0.546 & 14.900 \(\pm\) 4.016 & 1.035 \(\pm\) 0.106 & 0.776 \(\pm\) 0.333 \\ credit & 7.317 \(\pm\) 2.425 & 3.172 \(\pm\) 2.636 & 2.615 \(\pm\) 0.831 & 5.861 \(\pm\) 2.064 & 2.202 \(\pm\) 3.103 & 1.830 \(\pm\) 0.588 \\ default-of-cerd-calents & 14.381 \(\pm\) 4.509 & 1.318 \(\pm\) 1.325 \(\pm\) 0.739 & 2.272 \(\pm\) 4.285 & 0.937 \(\pm\) 1.316 & 0.245 \(\pm\) 0.1172 \\ electricity & 10.000 \(\pm\) 2.930 & 1.035 \(\pm\) 0.543 & 0.221 \(\pm\) 0.192 & 9.422 \(\pm\) 2.795 & 0.771 \(\pm\) 0.478 & 0.120 \(\pm\) 0.071 \\ eye, movements & 18.743 \(\pm\) 1.994 & 1.605 \(\pm\) 1.927 & 3.786 \(\pm\) 1.301 & 1.495 \(\pm\) 0.467 & 0.463 \(\pm\) 0.183 & 0.180 \(\pm\) 0.206 \\ belce & 4.434 \(\pm\) 1.611 & 1.652 \(\pm\) 0.475 & 1.012 \(\pm\) 0.481 & 0.830 \(\pm\) 0.727 & 0.475 \(\pm\) 0.447 & 0.322 \(\pm\) 0.338 \\ house\_16H & 8.935 \(\pm\) 2.504 & 3.362 \(\pm\) 0.482 & 2.660 \(\pm\) 1.206 & 4.209 \(\pm\) 2.189 & 0.219 \(\pm\) 0.222 & 0.404 \(\pm\) 0.782 \\ jams & 17.756 \(\pm\) 3.322 & 1.042 \(\pm\) 1.040 & 1.736 \(\pm\) 0.219 & 3.205 \(\pm\) 2.849 & 0.029 \(\pm\) 0.064 & 0.007 \(\pm\) 0.016 \\ pol & 20.542 \(\pm\) 2.873 & 4.612 \(\pm\) 0.914 & 2.325 \(\pm\) 1.080 & 15.830 \(\pm\) 2.562 & 1.708 \(\pm\) 0.599 & 1.017 \(\pm\) 0.859 \\ \hline \hline \end{tabular}
\end{table}
Table 6: Accuracy barrier for non-oblivious trees with WM.

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline \multirow{2}{*}{**Dataset**} & \multicolumn{4}{c}{**Train**} & \multicolumn{4}{c}{**Test**} \\ \cline{2-7}  & **Naive** & **Pern** & **Perm&**\&**\&Flip** & **Naive** & **Perm** & **Perm\&Flip** \\ \hline Bioresponse & 18.944 \(\pm\) 1.0076 & 14.066 \(\pm\) 7.045 & 5.210 \(\pm\) 0.915 & 8.235 \(\pm\) 6.456 & 5.037 \(\pm\) 3.141 & 0.966 \(\pm\) 0.316 \\ Diabetes130US & 2.148 \(\pm\) 0.601 & 3.086 \(\pm\) 2.566 & 0.574 \(\pm\) 0.365 & 1.041 \(\pm\) 0.959 & 1.936 \(\pm\) 2.878 & 0.105 \(\pm\) 0.152 \\ Higs & 27.578 \(\pm\) 1.742 & 3.074 \(\pm\) 2.899 & 1.345 \(\pm\) 1.599 & 4.055 \(\pm\) 0.889 & 7.722 \(\pm\) 1.089 & 1.046 \(\pm\) 0.433 \\ MagicTelescope & 2.995 \(\pm\) 1.139 & 3.090 \(\pm\) 1.486 & 2.778 \(\pm\) 0.715 & 0.206 \(\pm\) 1.055 & 2.693 \(\pm\) 1.190 & 2.428 \(\pm\) 0.327 \\ MiniBowCE & 18.28 \(\pm\) 4.570 & 3.944 \(\pm\) 1.537 & 3.272 \(\pm\) 0.323 & 1.259 \(\pm\) 4.190 & 2.871 \(\pm\) 7.696 & 0.074 \(\pm\) 0.081 \\ bank-marketing & 1.3999 \(\pm\) 4.110 & 13.598 \(\pm\) 6.733 & 3.098 \(\pm\) 0.539 & 1.359 \(\pm\) 4.567 & 1.8210 \(\pm\) 7.605 & 2.643 \(\pm\) 0.704 \\ California & 6.369 \(\pm\) 2.472 & 5.080 \(\pm\) 2.036 & 2.035 \(\pm\) 0.255 & 5.266 \(\pm\) 3.277 & 4.858 \(\pm\) 4.027 & 0.261 \(\pm\) 0.285 \\ covertype & 16.823 \(\pm\) 4.159 & 19.708 \(\pm\) 6.392 & 1.420 \(\pm\) 0.619 & 14.900 \(\pm\) 4.016 & 17.765 \(\pm\) 6.400 & 0.758 \(\pm\) 0.540 \\ credit & 7.317 \(\pm\) 2.425 & 3.156 \(\pm\) 0.586 & 7.853 \(\pm\) 1.604 & 5.861 \(\pm\) 2.

\begin{table}
\begin{tabular}{c c c c c c c c c c} \hline \hline \multicolumn{1}{c}{\multirow{2}{*}{**Dataset**}} & \multicolumn{4}{c}{**Train**} & \multicolumn{4}{c}{**Test**} \\ \cline{2-10}  & **Noise** & **Pern** & **Naive (Modified)** & **Pern (Modified)** & **Naive** & **Pern** & **Naive (Modified)** & **Pern (Modified)** \\ \hline Bioresponse & 21,323 \(\pm\) 6.563 & 13.349 \(\pm\) 5.943 & 14.578 \(\pm\) 3.930 & 10.361 \(\pm\) 7.256 & 9.125 \(\pm\) 3.988 & 4.817 \(\pm\) 2.252 & 7.346 \(\pm\) 4.261 & 1.309 \(\pm\) 0.827 \\ Diabetes130US & 3.886 \(\pm\) 2.566 (0.686) & 1.120 \(\pm\) 1.123 (0.867) & 1.088 \(\pm\) 1.068 & 1.028 \(\pm\) 1.058 & 1.028 \(\pm\) 1.052 & 1.088 \(\pm\) 0.063 & 1.028 \(\pm\) 1.056 & 0.948 \(\pm\) 0.058 \\ Higgs & 30.704 \(\pm\) 2.899 (97.232) & 35.24 \(\pm\) 3.164 (97.616) & 28.910 \(\pm\) 1.232 (0.5838) & 20.131 \(\pm\) 1.693 & 9.020 \(\pm\) 2.019 & 3.544 \(\pm\) 2.885 & 0.157 \(\pm\) 0.162 \\ Magic/FaceFace & 3.909 \(\pm\) 1.498 (86.945) & 3.902 \(\pm\) 1.931 & 14.916 \(\pm\) 3.166 & 1.580 \(\pm\) 1.78 & 1.128 \(\pm\) 1.683 & 1.692 \(\pm\) 0.099 & 3.544 \(\pm\) 2.885 & 0.035 \(\pm\) 0.042 \\ MiniBowNE & 23.059 \(\pm\) 1.479 & 1.919 \(\pm\) 1.491 & 1.496 \(\pm\) 3.166 & 1.580 \(\pm\) 1.78 & 1.478 \(\pm\) 1.683 & 1.656 \(\pm\) 0.722 & 0.504 \(\pm\) 2.067 & 0.349 \(\pm\) 0.348 \\ bank-marketing & 1.1952 \(\pm\) 3.949 & 9.979 \(\pm\) 4.783 & 1.589 \(\pm\) 2.167 & 1.037 \(\pm\) 0.448 & 1.187 \(\pm\) 3.156 & 0.862 \(\pm\) 0.146 & 6.844 \(\pm\) 3.087 & 0.151 \(\pm\) 0.147 \\ California & 5.622 \(\pm\) 3.195 & 6.210 \(\pm\) 1.038 & 3.685 \(\pm\) 3.273 & 2.157 \(\pm\) 0.904 & 11.62 \(\pm\) 3.602 & 0.472 \(\pm\) 0.140 & 8.356 \(\pm\) 2.729 & 0.477 \(\pm\) 0.889 \\ covertype & 13.408 \(\pm\) 3.859 & 1.341 \(\pm\) 0.433 & 11.114 \(\pm\) 2.699 & 1.257 \(\pm\) 0.904 & 11.60 \(\pm\) 3.620 & 0.472 \(\pm\) 0.140 & 8.356 \(\pm\) 2.729 & 0.477 \(\pm\) 0.889 \\ credit & 12.138 \(\pm\) 1.155 & 1.968 \(\pm\) 0.950 & 14.626 \(\pm\) 5.484 & 1.309 \(\pm\) 0.422 & 1.080 \(\pm\) 0.909 & 1.421 \(\pm\) 1.046 & 1.367 \(\pm\) 0.591 & 0.940 \(\pm\) 0.662 \\ default-of-cerd-class & 12.815 \(\pm\) 1.116 & 1.047 \(\pm\) 1.138 & 1.378 \(\pm\) 2.133 & 1.793 \(\pm\) 0.881 & 1.614 \(\pm\) 3.038 & 0.512 \(\pm\) 1.397 & 1.916 \(\pm\) 0.666 \(\pm\) 0.651 \\ electricity & 6.524 \(\pm\) 1.863 & 0.725 \(\pm\) 0.451 & 0.21 \(\pm\) 2.685 & 0.944 \(\pm\) 0.557 & 5.843 \(\pm\) 0.482 & 0.254 \(\pm\) 0.347 & 8.457 \(\pm\) 2.460 & 0.543 \(\pm\) 0.511 \\ eye\_movements & 19.125 \(\pm\) 1.791 & 9.493 \(\pm\) 1.385 & 1.978 \(\pm\) 1.490 & 2.875 \(\pm\) 1.391 & 1.990 \(\pm\) 1.623 & 0.329 \(\pm\) 0.101 & 1.916 \(\pm\) 1.492 & 0.277 \(\pm\) 0.302 \\ heke & 4.513 \(\pm\) 1.876 & 1.554 \(\pm\) 0.617 & 5.116 \(\pm\) 0.793 & 1.574 \(\pm\) 0.154 & 0.725 \(\pm\) 0.598 & 0.155 \(\pm\) 0.190 & 1.263 \(\pm\) 0.711 & 0.359 \(\pm\) 0.346 \\ house\_16H & 9.195 \(\pm\) 2.408 & 2.530 \(\pm\) 0.446 & 8.993 \(\pm\) 1.302 & 2.232 \(\pm\) 0.320 & 1.459 \(\pm\) 2.413 & 0.052 \(\pm\) 0.129 & 4.192 \(\pm\) 1.517 & 0.158 \(\pm\) 0.296 \\ jamis & 20.766 \(\pm\) 2.097 & 2.409 \(\pm\) 2.050 & 2.170 \(\pm\) 2.017 & 4.009 \(\pm\) 0.324 & 3.497 \(\pm\) 2.605 & 4.999 \(\pm\) 2.018 & 0.451 \(\pm\) 1.300 & 0.004 \(\pm\) 0.009 \\ pol & 23.401 \(\pm\) 5.448 & 1.317 \(\pm\) 1.028 & 20.137 \(\pm\) 4.200 & 3.433 \(\pm\) 0.675 & 18.933 \(\pm\) 5.249 & 0.952 \(\pm\) 0.925 & 16.522 \(\pm\) 3.502 & 1.143 \(\pm\) 0.555 \\ \hline \hline \end{tabular}
\end{table}
Table 11: Accuracy barrier for decision lists with ARM. The numbers in parentheses

\begin{table}
\begin{tabular}{c c c c c c c c c} \hline \hline \multicolumn{1}{c}{\multirow{2}{*}{**Dataset**}} & \multicolumn{4}{c}{**Train**} & \multicolumn{4}{c}{**Test**} \\ \cline{2-10}  & **Noise** & **Pern** & **Naive (Modified)** & **Pern (Modified)** & **Naive** & **Pern** & **Naive (Modified)** & **Pern (Modified)** \\ \hline Bioresponse & 21,323 \(\pm\) 6.563 & 13.349 \(\pm\) 5.943 & 14.578 \(\pm\) 3.930 & 10.361 \(\pm\) 7.256 & 9.125 \(\pm\) 3.988 & 4.817 \(\pm\) 2.825 & 7.346 \(\pm\) 2.621 & 3.871 \(\pm\) 4.608 \\ Diabetes130US & 1,388 \(\pm\) 1.159 (60.686) & 1.120 \(\pm\) 1.125 (0.657) & 1.371 \(\pm\) 0.507 & 4.910 \(\pm\) 2.444 & 2.658 \(\pm\) 3.766 & 1.476 \(\pm\) 1.308 & 0.694 \(\pm\) 0.669 \\ Higgs & 27.785 \Figure 11: Interpolation curves of train accuracy for oblivious trees with WM.

Figure 12: Interpolation curves of test accuracy for oblivious trees with WM.

Figure 10: Interpolation curves of test accuracy for oblivious trees with AM.

Figure 9: Interpolation curves of train accuracy for oblivious trees with AM.

Figure 16: Interpolation curves of test accuracy for oblivious trees with WM by use of split dataset.

Figure 14: Interpolation curves of test accuracy for oblivious trees with AM by use of split dataset.

Figure 13: Interpolation curves of train accuracy for oblivious trees with AM by use of split dataset.

Figure 15: Interpolation curves of train accuracy for oblivious trees with WM by use of split dataset.

Figure 19: Interpolation curves of train accuracy for non-oblivious trees with WM.

Figure 17: Interpolation curves of train accuracy for non-oblivious trees with AM.

Figure 20: Interpolation curves of test accuracy for non-oblivious trees with WM.

Figure 18: Interpolation curves of test accuracy for non-oblivious trees with AM.

Figure 23: Interpolation curves of train accuracy for non-oblivious trees with WM by use of split dataset.

Figure 21: Interpolation curves of train accuracy for non-oblivious trees with AM by use of split dataset.

Figure 22: Interpolation curves of test accuracy for non-oblivious trees with AM by use of split dataset.

Figure 23: Interpolation curves of train accuracy for non-oblivious trees with WM by use of split dataset.

NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The abstract and introduction consistently present our research on tree ensembles from LMC perspectives. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: In Section 3.2, we have discussed the limitations. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [NA]Justification: We do not provide theoretical results in this paper. Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: The experimental setup is detailed in Section 4.1. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: Reproducible source code is provided in the supplementary material. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: The experimental setup is detailed in Section 4.1. Guidelines:

* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We conducted experiments multiple times with different random seeds and have reported the results, including the variability. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors).

* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: The computational resources used in our experiment is described in Section 4.1. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We reviewed the NeurIPS Code of Ethics and conducted our research in accordance with it. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [Yes] Justification: We have addressed societal impact in Section 5. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).

11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: We provide the source code as supplementary material; however, since the experiments concern the fundamental nature of machine learning models, we believe there are no risks involved. Guidelines:

* The answer NA means that the paper poses no such risks.
* Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.
* Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.
* We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.

12. **Licensees for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: We have used open datasets, citing them in accordance with their license information. Guidelines:

* The answer NA means that the paper does not use existing assets.
* The authors should cite the original paper that produced the code package or dataset.
* The authors should state which version of the asset is used and, if possible, include a URL.
* The name of the license (e.g., CC-BY 4.0) should be included for each asset.
* For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.
* If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.

* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: We do not provide any new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper neither engages in crowdsourcing nor research involving human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper neither engages in crowdsourcing nor research involving human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.