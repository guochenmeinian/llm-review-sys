A Best-of-both-worlds Algorithm for Bandits with Delayed Feedback with Robustness to Excessive Delays

 Saeed Masoudian

Churney ApS, Denmark

saeed@churney.io

&Julian Zimmert

Google Research

zimmert@google.com

&Yevgeny Seldin

University of Copenhagen

seldin@di.ku.dk

The work was done during SM's employment at the University of Copenhagen.

###### Abstract

We propose a new best-of-both-worlds algorithm for bandits with variably delayed feedback. In contrast to prior work, which required prior knowledge of the maximal delay \(d_{\max}\) and had a linear dependence of the regret on it, our algorithm can tolerate arbitrary excessive delays up to order \(T\) (where \(T\) is the time horizon). The algorithm is based on three technical innovations, which may all be of independent interest: (1) We introduce the first implicit exploration scheme that works in best-of-both-worlds setting. (2) We introduce the first control of distribution drift that does not rely on boundedness of delays. The control is based on the implicit exploration scheme and adaptive skipping of observations with excessive delays. (3) We introduce a procedure relating standard regret with drifted regret that does not rely on boundedness of delays. At the conceptual level, we demonstrate that complexity of best-of-both-worlds bandits with delayed feedback is characterized by the amount of information missing at the time of decision making (measured by the number of outstanding observations) rather than the time that the information is missing (measured by the delays).

## 1 Introduction

Delayed feedback is an ubiquitous challenge in real-world applications. Study of multi-armed bandits with delayed feedback has started at least four decades ago in the context of adaptive clinical trials (Simon, 1977, Eick, 1988), the same problem that has earlier motivated introduction of the bandit model itself (Thompson, 1933). We focus on robustness to delay outliers and to the loss generation mechanism. In practice occasional delay outliers are common (e.g., observations that never arrive). Robustness to the loss generation mechanism implies that the algorithm does not need to know whether the losses are stochastic or adversarial, but still provides regret bounds that match the optimal stochastic rates if the losses happen to be stochastic, while guaranteeing the adversarial rates if they are not (so-called best-of-both-worlds regret bounds). Such algorithms are important from a practical viewpoint, because the loss generation mechanism can rarely assumed to be stochastic, but it is still desirable to have tighter regret bounds if it happens to be. From the theoretical perspective both forms of robustness are interesting and challenging, requiring novel analysis tools and yielding better understanding of the problems.

Joulani et al. (2013) have studied multi-armed bandits with delayed feedback under the assumption that the rewards are stochastic and the delays are sampled from a fixed distribution.

They provided a modification of the UCB1 algorithm for stochastic bandits with non-delayed feedback (Auer et al., 2002). They have shown that the regret of the modified algorithm is \(O\left(\sum_{i:\Delta_{i}>0}\left(\frac{\log T}{\Delta_{i}}+\sigma_{\max}\Delta_ {i}\right)\right)\), where \(i\) indexes the arms, \(\Delta_{i}\) is the suboptimality gap of arm \(i\), \(T\) is the time horizon (unknown to the algorithm), and \(\sigma_{\max}\) is the maximal number of outstanding observations. (An observation is counted as outstanding at round \(t\) if it originates from round \(t\) or earlier, but due to delay it was not revealed to the algorithm by the end of round \(t\). The number of outstanding observations \(\sigma_{t}\) at round \(t\) is the number of actions that have already been played, but their outcome was not observed yet. We also call \(\sigma_{t}\) the [running] count of outstanding observations. The maximal number of outstanding observations \(\sigma_{\max}\) is the maximal value that \(\sigma_{t}\) takes and is unknown to the algorithm.) The result implies that in the stochastic setting the delays introduce an additive term in the regret bound, proportional to the maximal number of outstanding observation.

In the adversarial setting, multi-armed bandits with delayed feedback were first analyzed under the assumption of uniform delays (Neu et al., 2010, 2014). For this setting Cesa-Bianchi et al. (2019) have shown an \(\Omega(\sqrt{KT}+\sqrt{dT\log K})\) lower bound and an almost matching upper bound, where \(K\) is the number of arms and \(d\) is a fixed delay. The algorithm of Cesa-Bianchi et al. is a modification of the EXP3 algorithm of Auer et al. (2002b). Cesa-Bianchi et al. used a fixed learning rate that is tuned based on the knowledge of \(d\). The analysis is based on control of the drift of the distribution over arms played by the algorithm from round \(t\) to round \(t+d\). Thune et al. (2019) and Bistritz et al. (2019) provided algorithms for variable adversarial delays, but under the assumption that the delays are known "at action time", meaning that the delay \(d_{t}\) is known at time \(t\), when the action is taken, rather that at time \(t+d_{t}\), when the observation arrives. The advanced knowledge of delays was used to tune the learning rate and control the drift of played distribution from round \(t\), when an action is played, to round \(t+d_{t}\), when the observation arrives. Alternatively, an advance knowledge of the cumulative delay up to the end of the game could be used for the same purpose. Finally, Zimmert and Seldin (2020) derived an algorithm for the adversarial setting that required no advance knowledge of delays and matched the lower bound of Cesa-Bianchi et al. (2019) within constants. The algorithm and analysis of Zimmert and Seldin avoid explicit control of the distribution drift and are parameterized

\begin{table}
\begin{tabular}{l l} \hline Paper & Key results \\ \hline Joulani et al. (2013) & Stochastic bound: \(\mathcal{O}\left(\sum_{i:\Delta_{i}>0}\left(\frac{\log T}{\Delta_{i}}+\sigma_{ \max}\Delta_{i}\right)\right)\) \\ \hline Zimmert and Seldin (2020) & Adversarial bound \\  & without skipping: \(\mathcal{O}\left(\sqrt{KT}+\sqrt{D\log K}\right)\) \\  & with skipping: \(\mathcal{O}\left(\sqrt{KT}+\min_{\mathcal{S}}\left(|\mathcal{S}|+\sqrt{D_{ \mathcal{S}}\log K}\right)\right)\) \\  & (Masoudian et al. (2022) provide a matching lower bound) \\ \hline Masoudian et al. (2022) & Best-of-both-worlds bound, stochastic part \\  & \(\mathcal{O}\left(\sum_{i\neq i^{*}}\left(\frac{\log T}{\Delta_{i}}+\frac{\sigma_ {\max}}{\Delta_{i}\log K}\right)+d_{\max}K^{1/3}\log K\right)\) \\ The results assume oracle & Best-of-both-worlds bound, adversarial part \\  & \(\mathcal{O}\left(\sqrt{TK}+\sqrt{D\log K}+d_{\max}K^{1/3}\log K\right)\) \\ \hline Our paper & Best-of-both-worlds bound, stochastic part \\  & \(\mathcal{O}\left(\sum_{i\neq i^{*}}\left(\frac{\log T}{\Delta_{i}}+\frac{\sigma_ {\max}}{\Delta_{i}\log K}\right)+K\sigma_{\max}+S^{*}\right)\), where \\  & \(S^{*}=\mathcal{O}\left(\min\left(d_{\max}K^{\frac{2}{3}}\log K,\min_{\mathcal{S}} \left\{|\mathcal{S}|+\sqrt{D_{\mathcal{S}}K^{\frac{2}{3}}\log K}\right\} \right)\right)\) \\  & Best-of-both-worlds bound, adversarial part \\  & \(\mathcal{O}\left(\sqrt{KT}+\min_{\mathcal{S}}\left\{|\mathcal{S}|+\sqrt{D_{ \mathcal{S}}\log K}\right\}+S^{*}+K\sigma_{\max}\right)\) \\ \hline \end{tabular}
\end{table}
Table 1: Comparison to state-of-the-art. The following notation is used: \(T\) is the time horizon, \(K\) is the number of arms, \(i\) indexes the arms, \(\Delta_{i}\) is the suboptimality gap or arm \(i\), \(\sigma_{\max}\) is the maximal number of outstanding observations, \(D=\sum_{t=1}^{T}d_{t}\) is the total delay, \(\mathcal{S}\subseteq[T]\) is a set of skipped rounds, \(\mathcal{S}=[T]\setminus\mathcal{S}\) is the set of non-skipped rounds, \(D_{\mathcal{S}}=\sum_{t\in\mathcal{S}}d_{t}\) is the total delay in the _non_-skipped rounds, and \(d_{\max}\) is the maximal delay. We have \(\min_{\mathcal{S}}\left(|\mathcal{S}|+\sqrt{D_{\mathcal{S}}}\right)\leq\sqrt{D}\) and \(\sigma_{\max}\leq d_{\max}\), and in some cases \(\min_{\mathcal{S}}\left(|\mathcal{S}|+\sqrt{D_{\mathcal{S}}}\right)\ll\sqrt{D}\) and \(\sigma_{\max}\ll d_{\max}\).

by running counts of the number of outstanding observations \(\sigma_{t}\), which is an empirical quantity that is observed at time \(t\) ("at the time of action").

Masoudian et al. (2022) attempted to extend the algorithm of Zimmert and Seldin (2020) to the best-of-both-worlds setting. The stochastic part of the analysis of Masoudian et al. is based on a direct control of the distribution drift. The control is achieved by damping the learning rate to make sure that the played distribution on arms is not changing too much from round \(t\), when an action is played, to round \(t+d_{t}\), when the loss is observed. Highly varying delays cannot be treated with this approach, because fast learning rates limit the range \(d_{t}\) for which the drift is under control, while slow learning rates prevent learning. Therefore, Masoudian et al. had to reintroduce the assumption that that the maximal delay \(d_{\max}\) is known, and used it to tune the learning rate. Unfortunately, damping of the learning rate to control the drift over \(d_{\max}\) rounds made \(d_{\max}\) show up additively in the bound, meaning that potential presence of even a single delay of order \(T\) made both the stochastic and the adversarial bounds linear in the time horizon. We emphasise that the linear dependence of the regret on \(d_{\max}\) is real and not an artefact of the analysis, because it comes from damped learning rate.

We introduce a different best-of-both-worlds modification of the algorithm of Zimmert and Seldin (2020) that is fully parameterized by the running count of outstanding observations and requires no advance knowledge of delays or the maximal delay \(d_{\max}\). Our algorithm is based on a careful augmentation of the algorithm of Zimmert and Seldin with implicit exploration (described below), followed by application of a skipping technique (also described below) as a tool to limit the time span over which we need to control the distribution shift.

Implicit exploration was introduced by Neu (2015) to control the variance of importance-weighted loss estimates in adversarial bandits. But the exploration parameters add up linearly to the regret bound, making it highly challenging to design a scheme for best-of-both-worlds setting. The implicit exploration schedule of Neu leads to \(\Omega(\sqrt{T})\) regret bound and, therefore, unsuitable for that. Jin et al. (2022) introduced a different schedule for adversarial Markov decision processes with delayed feedback. However, it is unknown whether their schedule can work in a stochastic analysis. We introduce a novel schedule and show that it works in best-of-both-worlds setting.

Skipping was introduced by Thune et al. (2019) as a way to limit the dependence of an algorithm on a small number of excessively large delays. The idea is that it is "cheaper" to skip a round with an excessively large delay and bound the regret in the corresponding round by 1, than to include it in the core analysis. Thune et al. have assumed prior knowledge of delays, but Zimmert and Seldin (2020) have perfected the technique by basing it on a running count of outstanding observations. In both works skipping was an optional add-on aimed to improve regret bounds in case of highly unbalanced delays. In our work skipping becomes an indispensable part of the algorithm, because, apart from making the algorithm robust to a few excessively large delays, it also limits the time span over which the control of distribution drift is needed.

In Table 1 we compare our results to state of the art. In a nutshell, we replace terms dependent on \(d_{\max}\) by terms dependent on \(\sigma_{\max}\), and terms dependent on the square root of the total cumulative delay \(D=\sum_{t=1}^{T}d_{t}\), by terms dependent on the number of skipped rounds \(|\mathcal{S}|\) and a square root of the cumulative delay \(D_{\bar{\mathcal{S}}}=\sum_{t\in\bar{\mathcal{S}}}d_{t}\) in the non-skipped rounds \(\bar{\mathcal{S}}\) (those with the smaller delay). This yields robustness to excessive delays, because neither \(\sigma_{\max}\) nor \(\min_{\mathcal{S}}\left(|\mathcal{S}|+\sqrt{D_{\bar{\mathcal{S}}}}\right)\) depend on the magnitude of delay outliers. By contrast, both the stochastic and the adversarial regret bounds of Masoudian et al. (2022) become linear in \(T\) in presence of a single delay of order \(T\).

There are also additional benefits. It has been shown that \(\sigma_{\max}\leq d_{\max}\), and in some cases \(\sigma_{\max}\ll d_{\max}\)(Joulani et al., 2013, Masoudian et al., 2022). For example, if the first observation has delay \(T\), and the remaining observations have zero delay, then \(d_{\max}=T\), but \(\sigma_{\max}=1\). We also have that \(\min_{\mathcal{S}}\left(|\mathcal{S}|+\sqrt{D_{\mathcal{S}}}\right)\leq\sqrt{D}\), because \(\mathcal{S}=\varnothing\) is part of the minimization on the left, and in some cases \(\min_{\mathcal{S}}\left(|\mathcal{S}|+\sqrt{D_{\mathcal{S}}}\right)\ll\sqrt{D}\). For example, if the delays in the first \(\sqrt{T}\) rounds are of order \(T\), and the delays in the remaining rounds are zero, then \(\min_{\mathcal{S}}\left(|\mathcal{S}|+\sqrt{D_{\bar{\mathcal{S}}}}\right)= \mathcal{O}\left(\sqrt{T}\right)\), but \(\sqrt{D}=\Omega\left(T^{3/4}\right)\)(Thune et al., 2019). Therefore, bounds that exploit skipping are preferable over bounds that do not, and for some problem instances the improvement is significant. In Appendix F we show that bounds with an additive term \(d_{\max}\), including the results of Masoudian et al. (2022), cannot benefit from skipping, in contrast to ours.

The following list highlights our main contributions.

1. We provide the first best-of-both-worlds algorithm for bandits with delayed feedback that is robust to delay outliers. It improves both the stochastic and the adversarial regret bounds relative to the work of Masoudian et al. (2022), which lacks such robustness. For some problem instances the improvement is dramatic, e.g., in presence of a single delay of order \(T\) both the stochastic and the adversarial regret bounds of Masoudian et al. are of order \(T\), whereas our bounds are unaffected.
2. We provide an efficient technique to control the distribution drift under highly varying delays.
3. We provide the first implicit exploration scheme that works in best-of-both-worlds setting.
4. We provide a procedure relating drifted regret to normal regret in presence of delay outliers.
5. At the conceptual level, we show that best-of-both-worlds regret depends on the amount of information missing at the time of decision making (the number of outstanding observations) rather than the time that the information is missing (the delays). It was shown to be the case for the stochastic and adversarial regimes in isolation (Joulani et al., 2013; Zimmert and Seldin, 2020), but we are the first to show that it is also the case for best-of-both-worlds.

## 2 Problem setting

We study the problem of multi-armed bandit with variable delays. In each round \(t=1,2,\ldots\), the learner picks an action \(I_{t}\) from a set of \(K\) arms and immediately incurs a loss \(\ell_{t,I_{t}}\) from a loss vector \(\ell_{t}\in[0,1]^{K}\). However, the incurred loss is observed by the learner only after a delay of \(d_{t}\), at the end of round \(t+d_{t}\). The delays are arbitrary and chosen by the environment. We use \(\sigma_{t}\) to denote the number of outstanding observations at time \(t\) defined as \(\sigma_{t}=\sum_{s\leq t}\mathds{1}(s+d_{s}>t)\) and \(\sigma_{\max}=\max_{\ell\in[T]}\sigma_{t}\) to be the maximal number of outstanding observations. We consider two regimes for generation of losses by the environment: oblivious adversarial and stochastic.

We use pseudo-regret to compare the expected total loss of the learner's strategy to that of the best fixed action in hindsight. Specifically, the pseudo-regret is defined as:

\[\overline{Reg}_{T}=\mathbb{E}\left[\sum_{t=1}^{T}\ell_{t,I_{t}}\right]-\min_{ i\in[K]}\mathbb{E}\left[\sum_{t=1}^{T}\ell_{t,i}\right]=\mathbb{E}\left[\sum_{t=1} ^{T}\left(\ell_{t,I_{t}}-\ell_{t,i^{*}_{T}}\right)\right],\]

where \(i^{*}_{T}=\min_{i\in[K]}\mathbb{E}\left[\sum_{t=1}^{T}\ell_{t,i}\right]\) is the best action in hindsight. In the oblivious adversarial setting, the losses are assumed to be deterministic and independent of the actions taken by the algorithm. As a result, the expectation in the definition of \(i^{*}_{T}\) can be omitted and the pseudo-regret definition coincides with the expected regret. Throughout the paper we assume that \(i^{*}_{T}\) is unique. This is a common simplifying assumption in best-of-both-worlds analysis (Zimmert and Seldin, 2021). Tools for elimination of this assumption can be found in Ito (2021).

## 3 Algorithm

The algorithm is a best-of-both-worlds modification of the adversarial FTRL algorithm with hybrid regularizer by Zimmert and Seldin (2020). It is provided in Algorithm 1 display. The modification includes biased loss estimators (implicit exploration) and adjusted skipping threshold. The algorithm maintains a set of skipped rounds \(\mathcal{S}_{t}\) (initially empty), a cumulative count of "active" outstanding observations (those that have not been skipped yet), and a vector of cumulative observed loss estimates \(\widehat{L}_{t}^{obs}\) from non-skipped rounds. At round \(t\) the algorithm constructs an FTRL distribution \(x_{t}\) over arms using regularizer \(F_{t}\) defined in equation (2) below, and samples an arm according to \(x_{t}\). Then it receives the observations that arrive at round \(t\), except those that come from the skipped rounds, and updates the vector \(\widehat{L}_{t}^{obs}\) of cumulative loss estimates. The loss estimates \(\widehat{\ell}_{t}\) are defined below in equation (1). Then it counts the number of "active" outstanding observations \(\widehat{\sigma}_{t}\) (those that belong to non-skipped rounds), updates the cumulative count of outstanding observations \(\mathcal{D}_{t}\), and computes the skipping threshold \(d_{\max}^{t}=\sqrt{\frac{\mathcal{D}_{t}}{49K^{2/3}\log K}}\). Finally, it adds rounds \(s\) for which the observation has not arrived yet and the waiting time \((t-s)\) exceeds the skipping threshold \(d_{\max}^{t}\) to the set of skipped rounds \(\mathcal{S}_{t}\). Lemma 20, which is an adaptation of Zimmert and Seldin (2020, Lemma 5) to our skipping rule, shows that at most one round \(s\) is skipped at a time (at most one index \(s\) satisfies the if-condition for skipping in Line 15 of the algorithm for a given \(t\)).

We use implicit exploration to control importance-weighted loss estimates. The idea of using implicit exploration is inspired by the works of Neu (2015) and Jin et al. (2022), but its parametrization and purpose are different from prior work. To the best of our knowledge, it is the first time implicit exploration is used for best-of-both-worlds bounds. For any \(s,t\in[T]\) with \(s\leq t\) we define implicit exploration terms \(\lambda_{s,t}=e^{-\frac{\mathcal{D}_{t}}{\mathcal{D}_{t}-\mathcal{D}_{s}}}\). Our biased importance-weighted loss estimators are defined by

\[\widehat{\ell}_{t,i}=\frac{\ell_{t,i}\mathds{1}(I_{t}=i)}{\max\left\{x_{t,i}, \lambda_{t,t+\widehat{d}_{t}}\right\}},\] (1)

where \(\widehat{d}_{s}=\min\left(d_{s},\min\left\{(t-s):t-s\geq d_{\max}^{t}\right\}\right)\) denotes the time that the algorithm waits for the observation from round \(s\). It is the minimum of the delay \(d_{s}\), and the time \((t-s)\) to the first round when the waiting time exceeds the skipping threshold \(d_{\max}^{t}\).

We use a hybrid regularizer based on a combination of the negative Tsallis entropy and the negative entropy, with separate learning rates,

\[F_{t}(x)=-2\eta_{t}^{-1}\left(\sum_{i=1}^{K}\sqrt{x_{i}}\right)+\gamma_{t}^{ -1}\left(\sum_{i=1}^{K}x_{i}\log x_{i}\right),\] (2)

where the learning rates are \(\eta_{t}^{-1}=\sqrt{t}\) and \(\gamma_{t}^{-1}=\sqrt{\frac{49\mathcal{D}_{t}}{\log K}}\). The regularizer is the same as the one used by Zimmert and Seldin (2020). By inheriting their regularizer we inherit their adversarial regret bound, which is minimax optimal, with just a minor adjustment due to introduction of implicit exploration and a slight change in the learning rates and skipping threshold. The main contribution of our work is carrying out the stochastic analysis while staying within the algorithmic framework of Zimmert and Seldin and keeping the adversarial regret bound almost unscathed.

The update rule for \(x_{t}\) is

\[x_{t}=\nabla\bar{F}_{t}^{*}(-\widehat{L}_{t}^{obs})=\arg\min_{x\in\Delta^{K -1}}\langle\widehat{L}_{t}^{obs},x\rangle+F_{t}(x),\] (3)where \(\widehat{L}_{t}^{obs}=\sum_{s=1}^{t-1}\widehat{\ell}_{s}\mathds{1}(s+d_{s}<t) \mathds{1}(s\notin\mathcal{S}_{t-1})\) is the cumulative importance-weighted loss estimate of observations that have arrived by time \(t\) and have not been skipped. We use \(\mathcal{S}^{*}=\mathcal{S}_{T}\) to denote the final set of skipped rounds at time \(T\).

## 4 Regret Bounds

The following theorem provides best-of-both-worlds regret bounds for Algorithm 1. A proof is provided in Section 5 and a bound on \(S^{*}\) can be found in Appendix H.

**Theorem 1**.: _The pseudo-regret of Algorithm 1 for any sequence of delays and losses satisfies_

\[\overline{Reg}_{T}=\mathcal{O}\bigg{(}\sqrt{KT}+\min_{\mathcal{S}\subseteq[ T]}\Big{\{}|\mathcal{S}|+\sqrt{\mathcal{D}_{\bar{\mathcal{S}}}\log K}\Big{\}}+S^{* }+K\widehat{\sigma}_{\max}\bigg{)},\]

_where \(\widehat{\sigma}_{\max}=\max_{t\in[T]}\{\widehat{\sigma}_{t}\}\) is the maximal number of outstanding observations after skipping and_

\[S^{*}=\mathcal{O}\left(\min\left(d_{\max}K^{1/3}\log K\,\min_{\mathcal{S} \subseteq[T]}\bigg{\{}|\mathcal{S}|+\sqrt{\mathcal{D}_{\bar{\mathcal{S}}}K^{ \frac{2}{3}}\log K}\bigg{\}}\right)\right).\]

_Furthermore, if the losses are stochastic, the pseudo-regret also satisfies_

\[\overline{Reg}_{T}=\mathcal{O}\left(\sum_{i\neq i^{*}}\left(\frac{\log T}{ \Delta_{i}}+\frac{\widehat{\sigma}_{\max}}{\Delta_{i}\log K}\right)+K\widehat{ \sigma}_{\max}+S^{*}\right).\]

Masoudian et al. (2022) provide an \(\Omega\left(\sqrt{KT}+\min_{\mathcal{S}\subset[T]}\big{\{}|\mathcal{S}|+\sqrt{ \mathcal{D}_{\bar{\mathcal{S}}}\log K}\big{\}}\right)\) regret lower bound for adversarial environments with variable delays, which is matched within constants by the algorithm of (Zimmert and Seldin, 2020) for adversarial environments. Our algorithm matches the lower bound within a multiplicative factor of \(K^{\frac{1}{3}}\) on the delay-dependent term, which is the price we pay for obtaining a best-of-both-worlds guarantee. The price comes from a reduction of the skipping threshold of Zimmert and Seldin (2020) that we had to make to control the distribution drift that is due to the loss shift (see Appendix B.2). It is an open question whether this factor can be reduced.

In the stochastic regime, assuming that the delays in the first \(\sigma_{\max}\) rounds are of order \(T\), and that the losses come from Bernoulli distributions with bias close to \(\frac{1}{2}\), a trivial regret lower bound is \(\Omega\left(\sigma_{\max}\frac{\sum_{i\neq i^{*}}\Delta_{i}}{K}+\sum_{i\neq i ^{*}}\frac{\log T}{\Delta_{i}}\right)\). This bound is almost matched by the algorithm of Joulani et al. (2013) for the stochastic regime only. Our bound has some extra terms, most notably \(\sum_{i\neq i^{*}}\frac{\widehat{\sigma}_{\max}}{\Delta_{i}\log K}\) and \(S^{*}\). It is an open question whether these terms are inevitable or can be reduced.

Theorem 1 provides three major improvements relative to the results of Masoudian et al. (2022): (1) it requires no advance knowledge of \(d_{\max}\); (2) it replaces terms dependent on \(d_{\max}\) by terms dependent on \(\widehat{\sigma}_{\max}\), which never exceeds \(d_{\max}\), and in some cases may be significantly smaller; and (3) it makes skipping possible and beneficial, making the algorithm robust to a small number of excessively large delays and replacing \(\sqrt{D\log K}\) term with \(\min_{S\subseteq[T]}\bigg{\{}|\mathcal{S}|+\sqrt{\mathcal{D}_{\bar{\mathcal{ S}}}K^{\frac{2}{3}}\log K}\bigg{\}}\), which is never much larger, but in some cases significantly smaller.

## 5 Analysis

In this section, we present a proof of Theorem 1. We begin with the stochastic part of the bound in Section 5.1, followed by the adversarial part in Section 5.2.

### Stochastic Analysis

We start by defining the drifted regret \(\overline{Reg}_{T}^{drift}=\mathbb{E}\left[\sum_{t=1}^{T}\left(\langle x_{t}, \widehat{\ell}_{t}^{obs}\rangle-\widehat{\ell}_{t,z_{t}^{*}}^{obs}\right) \right],\) where \(\widehat{\ell}_{t}^{obs}=\sum_{s=1}^{t}\widehat{\ell}_{s}\mathds{1}(s+ \widehat{d}_{s}=t)\mathds{1}(s\notin\mathcal{S}_{t})\) is the cumulative vector of losses received at time \(t\). Lemma 2 is the first major contribution establishing a relationship between \(\overline{Reg}_{T}^{drift}\) and the actual regret \(\overline{Reg}_{T}\).

**Lemma 2** (Drift of the Drifted Regret).: _Let \(\sigma_{\max}^{t}=\max_{s\in[t]}\{\widehat{\sigma}_{s}\}\). Then_

\[\overline{Reg}_{T}^{drift}\geq\frac{1}{4}\overline{Reg}_{T}-2K\sum_{t=1}^{T} \left(\lambda_{t,t+\widehat{d}_{t}}+\lambda_{t,t+\widehat{d}_{t}+\sigma_{\max }^{t}}\right)-\frac{\sigma_{\max}}{4}-S^{*},\]

_where \(S^{*}\) is the total number of rounds skipped by the algorithm._

The core of Lemma 2 is based on controlling the distribution drift using implicit exploration and skipping. In prior work on bounded delays the relation between \(\overline{Reg}_{T}^{drift}\) and \(\overline{Reg}_{T}\) was achieved by shifting all the arrivals by \(d_{\max}\), leading to an additive term of order \(d_{\max}\). This approach fails for unbounded delays, because a single delay of order \(T\) prevents shifting and leads to linear regret. We address the challenge by introducing a procedure to rearrange the arrivals (Algorithm 2 below) and advanced control of the drift (Lemma 3 below). A proof of Lemma 2 is provided at the end of the section.

```
1Initialize\(\upsilon_{t}^{new}=0\) for all \(t=1,\ldots,T+d_{\max}^{T}\)for\(t=1,\ldots,T\)do
2for\(s=1,\ldots,t:s+\widehat{d}_{s}=t\)do
3 Find the first round \(\pi(s)\in[t,t+d_{\max}^{t}]\) such that \(\upsilon_{\pi(s)}^{new}=0\)
4 Move the arrival from round \(s\) to round \(\pi(s)\) and update \(\upsilon_{\pi(s)}^{new}=1\) ```

**Algorithm 2**Greedy Rearrangement

The drift control lemma (Lemma 3) is the second major contribution of the paper. Prior work on bounded delays controlled the drift by slowing the learning rate in accordance with \(d_{\max}\). This does not work for highly varying delays, because slow learning rates prevent learning, whereas fast learning rates fail to control the drift. Lemma 3 relies on implicit exploration terms in the loss estimators in equation (1) and on skipping of excessive delays, leaving the learning rates intact.

**Lemma 3** (Drift Control Lemma).: _Let \(d_{\max}^{t}\) be the skipping threshold at time \(t\). Then, for any \(i\in[K]\) and \(s,t\in[T]\), where \(s\leq t\) and \(t-s\leq d_{\max}^{t}\), we have_

\[x_{t,i}\leq 4\max(x_{s,i},\lambda_{s,t}).\]

The proof is based on introduction of an intermediate variable \(\widetilde{x}_{s}=\nabla\bar{F}_{s}^{*}(-\widehat{L}_{t-1}^{obs})\), which is based on the regularizer from round \(s\) and the loss estimate from round \(t\). It exploits the implicit exploration term \(\lambda_{s,t}\) to show that \(\frac{x_{t,i}}{\max(\widetilde{x}_{i},\lambda_{s,t})}\leq 2\) and skipping to show that \(\frac{\widetilde{x}_{i}}{x_{s,i}}\leq 2\). The latter implies that \(\frac{\max(\widetilde{x}_{i},\lambda_{s,t})}{\max(x_{s,i},\lambda_{s,t})}\leq 2\), and in combination with the former completes the proof. The details of the two steps are provided in Appendix B.

Given Lemmas 2 and Lemma 3, we apply standard FTRL analysis, similar to Masoudian et al. (2022), to obtain an upper bound for \(\overline{Reg}_{T}^{drift}\). Specifically, in Appendix A we show that

\[\overline{Reg}_{T}^{drift} \leq\mathbb{E}\bigg{[}a\sum_{t=1}^{T}\sum_{i\neq i^{*}}\eta_{t}x_{ t,i}^{1/2}+b\sum_{t=1}^{T}\sum_{i\neq i^{*}}\gamma_{t+\widehat{d}_{t}}( \upsilon_{t+\widehat{d}_{t}}-1)x_{t,i}\Delta_{i}+c\sum_{t=2}^{T}\sum_{i=1}^{K} \frac{\widehat{\sigma}_{t}\gamma_{i}x_{t,i}\log(1/x_{t,i})}{\log K}\bigg{]}\] \[\quad+\mathcal{O}\left(K\sum_{t=1}^{T}\lambda_{t,t+\widehat{d}_{ t}}\right),\] (4)

where \(a,b,c\geq 0\) are constants and \(\upsilon_{t}=\sum_{s=1}^{t}\mathds{1}\left(s+\widehat{d}_{s}=t\right)\) is the number of arrivals at time \(t\) (if a round \(s\) is skipped at time \(t\) it counts as an "empty" arrival with loss estimate set to zero). By combining (4) with Lemma 2, we obtain

\[\overline{Reg}_{T} \leq\mathbb{E}\bigg{[}2a\sum_{t=1}^{T}\sum_{i\neq i}\eta_{t}x_{ t,i}^{1/2}+2b\sum_{t=1}^{T}\sum_{i\neq i^{*}}\gamma_{t+\widehat{d}_{t}}( \upsilon_{t+\widehat{d}_{t}}-1)x_{t,i}\Delta_{i}+2c\sum_{t=2}^{T}\sum_{i=1}^{ K}\frac{\widehat{\sigma}_{t}\gamma_{t}x_{t,i}\log(1/x_{t,i})}{\log K}\bigg{]}\] \[\quad+\mathcal{O}\left(K\sum_{t=1}^{T}\left(\lambda_{t,t+ \widehat{d}_{t}}+\lambda_{t,t+\widehat{d}_{t}+\sigma_{\max}^{t}}\right)+ \sigma_{\max}+S^{*}\right).\] (5)Then we apply a self-bounding analysis, similar to Masoudian et al. (2022), and get

\[\overline{Reg}_{T}=\mathcal{O}\Bigg{(}\sum_{i\neq i^{*}}\left(\frac{1}{\Delta_{ i}}\log(T)+\frac{\sigma_{\max}}{\Delta_{i}\log K}\right)+\sigma_{\max}+K\sum_{t=1}^{T} \left(\lambda_{t,t+\widehat{d}_{t}}+\lambda_{t,t+\widehat{d}_{t}+\sigma_{\max }^{t}}\right)+S^{*}\Bigg{)}.\]

The details of the self-bounding analysis are provided in Appendix C.

The stochastic analysis is completed by the following lemma, which bounds the sum of implicit exploration terms above. It constitutes the third key result of the paper and shows that the bias from implicit exploration does not deteriorate neither the stochastic nor the adversarial bound. The proof is based on a careful study of the evolution of \(\mathcal{D}_{t}\) throughout the game, and is deferred to Appendix D.

**Lemma 4** (Summation Bound).: _For all \(s\in[T]\), let \(\mathcal{D}_{s}=\sum_{r=1}^{s}\widehat{\sigma}_{r}\) and \(\lambda_{s,t}=e^{-\frac{\mathcal{D}_{t}}{\mathcal{D}_{s}}}\), then_

\[\sum_{t=1}^{T}\left(\lambda_{t,t+\widehat{d}_{t}}+\lambda_{t,t+\widehat{d}_{t }+\sigma_{\max}^{t}}\right)=\mathcal{O}(\widehat{\sigma}_{\max}).\]

#### Proof of Lemma 2 (Drift of the Drifted Regret)

We start with the definition of the drifted regret.

\[\overline{Reg}_{T}^{drift}=\mathbb{E}\left[\sum_{t=1}^{T}\left( \langle x_{t},\widehat{\ell}_{t}^{obs}\rangle-\widehat{\ell}_{t,i_{T}^{*}}^{ obs}\right)\right] =\sum_{t=1}^{T}\sum_{\begin{subarray}{c}s+\widehat{d}_{s}=t\\ s\notin\mathcal{S}_{t}\end{subarray}}\sum_{i=1}^{K}\mathbb{E}\left[\frac{ \ell_{s,i}x_{s,i}x_{t,i}}{\max\left\{x_{s,i},\lambda_{s,t}\right\}}-\frac{ \ell_{s,i_{T}^{*}}x_{s,i_{T}^{*}}x_{t,i}}{\max\left\{x_{s,i_{T}^{*}},\lambda_{ s,t}\right\}}\right]\] \[\geq\sum_{t=1}^{T}\sum_{\begin{subarray}{c}s+\widehat{d}_{s}=t \\ s\notin\mathcal{S}_{t}\end{subarray}}\sum_{i=1}^{K}\mathbb{E}\left[\frac{ \ell_{s,i}x_{s,i}x_{t,i}}{\max\left\{x_{s,i},\lambda_{s,t}\right\}}-\ell_{s,i _{T}^{*}}x_{t,i}\right]\] \[\geq\sum_{t=1}^{T}\sum_{s+\widehat{d}_{s}=t}\sum_{i=1}^{K} \mathbb{E}\Big{[}\underbrace{\frac{\ell_{s,i}x_{s,i}x_{t,i}}{\max\left\{x_{s, i},\lambda_{s,t}\right\}}}_{\star}-\ell_{s,i_{T}^{*}}x_{t,i}\Big{]}-\mathcal{S}^{*}.\] (6)

Note that when taking the expectation, we rely on the fact that \(\widehat{\ell}_{s}\) with \(s+\widehat{d}_{s}=t\) does not affect \(x_{t}\). If \(\max\left\{x_{s,i},\lambda_{s,t}\right\}=x_{s,i}\), then \(\star=\ell_{s,i}x_{t,i}\), otherwise

\[\star=\ell_{s,i}x_{t,i}-\frac{\ell_{s,i}x_{t,i}\left(\lambda_{s,t}-x_{s,i} \right)}{\lambda_{s,t}}\geq\ell_{s,i}x_{t,i}-\frac{4\lambda_{s,t}(\lambda_{s, t}-x_{s,i})}{\lambda_{s,t}}\geq\ell_{s,i}x_{t,i}-4\lambda_{s,t},\] (7)

where the first inequality uses \(x_{t,i}\leq 4\max(x_{s,i},\lambda_{s,t})=4\lambda_{s,t}\) by Lemma 3, and \(\ell_{s,i}\geq 1\), and the second inequality follows by \(x_{s,i}\geq 0\). Plugging (7) into (6) gives

\[\overline{Reg}_{T}^{drift} \geq\sum_{t=1}^{T}\sum_{s+\widehat{d}_{s}=t}\sum_{i=1}^{K} \mathbb{E}\left[\left(\ell_{s,i}x_{t,i}-4\lambda_{s,t}-\ell_{s,i_{T}^{*}}x_{t,i}\right)\right]-S^{*}\] \[\geq\underbrace{\mathbb{E}\left[\sum_{t=1}^{T}\sum_{s+\widehat{ d}_{s}=t}\sum_{i=1}^{K}\Delta_{i}x_{t,i}\right]}_{\text{$R_{T}$}}-4K\sum_{t=1}^{T} \sum_{s+\widehat{d}_{s}=t}\mathbb{E}\left[\lambda_{s,t}\right]-S^{*}.\] (8)

It suffices to give a lower bound for \(R_{T}\) in terms of the actual regret \(\overline{Reg}_{T}\). The difference between \(R_{T}\) and \(\overline{Reg}_{T}\) is that \(\overline{Reg}_{T}=\mathbb{E}\left[\sum_{t=1}^{T}\sum_{i=1}^{K}\Delta_{i}x_{t,i}\right]\), whereas in \(R_{T}\) the sum \(\sum_{i=1}^{K}\Delta_{i}x_{t,i}\) is multiplied by the number of arrivals \(\upsilon_{t}=\sum_{s=1}^{t}\mathds{1}\left(s+\widehat{d}_{s}=t\right)\) at time \(t\), and \(\upsilon_{t}\) might be larger than one or zero due to delays.

Our main idea here is to leverage the drift control lemma to provide a lower bound for \(R_{T}\) in terms of \(\overline{Reg}_{T}\). Specifically, by Lemma 3 for all \(r\in[0,d_{\max}^{t}]\), we have \(\max(x_{t,i},\lambda_{t,t+r})\geq\frac{1}{4}x_{t+r,i}\), which implies \(x_{t,i}\geq\frac{1}{4}x_{t+r,i}-\lambda_{t,t+r}\). Thus, we obtain the following bound for any \(r\in[0,d_{\max}^{t}]\)

\[\sum_{i=1}^{K}\Delta_{i}x_{t,i}\geq\frac{1}{4}\sum_{i=1}^{K}\Delta_{i}x_{t+r, i}-K\lambda_{t,t+r}.\] (9)

In Algorithm 2 we provide a greedy procedure to rearrange the arrivals by postponing some arrivals to future rounds to create a _hypothetical_ rearranged sequence with at most one arrival at each round. Colliding arrivals are postponed to the first available (unoccupied) slot in the future. In Lemma 5 below we show that arrival originally received at time \(t\) stays in the \([t,t+\sigma_{\max}^{t}]\) interval (note that \(\sigma_{\max}^{t}\leq d_{\max}^{t}\)). When an observation from round \(s\) is postponed from arriving at round \(t\) to arriving at round \(t+r\) for \(r\in[0,d_{\max}^{t}]\), by (9) it is equivalent to replacing \(\sum_{i=1}^{K}\Delta_{i}x_{t,i}\) by \(\frac{1}{4}\sum_{i=1}^{K}\Delta_{i}x_{t+r,i}-K\lambda_{t,t+r}\) in \(R_{T}\). Note that Algorithm 2 may push an arrival to a round larger than \(T\), which is equivalent to replacing \(\sum_{i=1}^{K}\Delta_{i}x_{t,i}\) by zero.

Let \(v_{t}^{new}\) for all \(t\in[T+d_{\max}^{T}]\) be the total arrivals at time \(t\) after the rearrangement, and let \(\pi(t)\) be the round to which we have mapped round \(t\) for all \(t\in[T]\). Then for any rearrangement

\[R_{T}=\mathbb{E}\left[\sum_{t=1}^{T}v_{t}\sum_{i=1}^{K}\Delta_{i}x_{t,i} \right]\geq\mathbb{E}\left[\sum_{t=1}^{T}\frac{1}{4}\upsilon_{t}^{new}\sum_{i =1}^{K}\Delta_{i}x_{t,i}-K\sum_{t=1}^{T}\lambda_{t,\pi(t)}\right].\] (10)

The following lemma provides properties of the rearrangement procedure.

**Lemma 5**.: _Let \(\sigma_{\max}^{t}=\max_{s\in[t]}\left\{\widehat{\sigma}_{s}\right\}\). Then Algorithm 2 ensures for any \(t\in[T+d_{\max}^{T}]\) that \(\upsilon_{t}^{new}\in\{0,1\}\). Furthermore, for any round \(t\in[T]\) it keeps all the arrivals at time \(t\) in the interval \([t,t+\sigma_{\max}^{t}]\), such that \(\forall s\leq t:s+\widehat{d}_{s}=t\Rightarrow\pi(s)-t\leq\sigma_{\max}^{t}\)._

We provide a proof of the lemma in Appendix E. As a corollary, after the Greedy Rearrangement (Algorithm 2) the number of rounds with zero arrivals is at most \(\sigma_{\max}^{T}\). This is because there will be no arrivals after \(T+\sigma_{\max}^{T}\) and \(\sum_{t=1}^{T+\sigma_{\max}^{T}}\upsilon_{t}^{new}=\sum_{t=1}^{T}v_{t}=T\), which implies there are at most \(\sigma_{\max}^{T}\) zero arrivals as each round receives at most one arrival. Therefore

\[\mathbb{E}\bigg{[}\sum_{t=1}^{T}\upsilon_{t}^{new}\sum_{i=1}^{K} \Delta_{i}x_{t,i}\bigg{]} =\overline{Reg}_{T}-\mathbb{E}\left[\sum_{t=1}^{T}\mathds{1}(v_ {t}^{new}=0)\sum_{i=1}^{K}\Delta_{i}x_{t,i}\right]\] (11) \[\leq\overline{Reg}_{T}-\mathbb{E}\left[\sum_{t=1}^{T}\mathds{1}( \upsilon_{t}^{new}=0)\right]\leq\overline{Reg}_{T}-\mathbb{E}\left[\sigma_{ \max}^{T}\right]\leq\overline{Reg}_{T}-\sigma_{\max},\]

where the first equality uses the definition of \(\overline{Reg}_{T}=\mathbb{E}[\sum_{t=1}^{T}\sum_{i=1}^{K}\Delta_{i}x_{t,i}]\) and that \(\forall t\in[T]:\upsilon_{t}^{new}\in\{0,1\}\).

Since \(\forall t\in[T]:\pi(t)\leq t+\widehat{d}_{t}+\sigma_{\max}^{t}\), we have \(\lambda_{t,\pi(t)}\leq\lambda_{t,t+\widehat{d}_{t}+\sigma_{\max}^{t}}\). Together with (11), (10), and (8) it completes the proof.

### Adversarial Analysis

The adversarial analysis is similar to the analysis of Zimmert and Seldin (2020, Theorem 2). In Appendix G we show that

\[\overline{Reg}_{T}=\mathcal{O}\left(\sqrt{KT}+\min_{\mathcal{S}\subseteq[T]} \left\{|\mathcal{S}|+\sqrt{\mathcal{D}_{\mathcal{S}}\log K}\right\}+S^{*}+K \sum_{t=1}^{T}\lambda_{t,t+\widehat{d}_{t}}\right),\]

where the first two terms originate from the analysis of Zimmert and Seldin due to structural similarity of the algorithm, \(S^{*}\) is due to adjusted skipping threshold, and \(K\sum_{t=1}^{T}\lambda_{t,t+\widehat{d}_{t}}\) is due to implicit exploration bias and is bounded by Lemma 4. The proof is completed by the following bound on \(S^{*}\), which is shown in Appendix H.

**Lemma 6**.: _We have \(S^{*}=\mathcal{O}\left(\min\left(d_{\max}K^{\frac{2}{3}}\log K\;,\min_{ \mathcal{S}\subseteq[T]}\left\{|\mathcal{S}|+\sqrt{\mathcal{D}_{\mathcal{S}}K^{ \frac{2}{3}}\log K}\right\}\right)\right).\)_Discussion

We have successfully addressed the challenge of handling varying and potentially unbounded delays in best-of-both-worlds setting. The success was based on three technical innovations, which may be interesting in their own right: (1) A relation between the drifted and the standard regret under unbounded delays (given by Lemma 2, Algorithm 2, and Lemma 5); (2) A novel control of distribution drift based on implicit exploration and skipping that does not alter the learning rates and exhibits efficiency under highly varying delays (Lemma 3); and (3) An implicit exploration scheme applicable in best-of-both-worlds setting (Lemma 4).

The work leads to several directions for future research. One question is whether the best-of-both-worlds bounds could be improved further. In particular, whether the \(K^{\frac{1}{3}}\) term in the adversarial regret bound could be reduced or eliminated. The term arose due to the need to decrease the skipping threshold of Zimmert and Seldin (2020) to control the distribution drift. It would also be valuable to explore whether it is possible to reduce the \(S^{*}\) term and reduce or eliminate the \(\sum_{i\neq i^{*}}\frac{\bar{\sigma}_{\max}}{\Delta_{i}\log K}\) term in the stochastic bound, or to derive lower bounds showing that these terms are unavoidable. Another interesting direction is to find more applications for implicit exploration and skipping in the context of best-of-both-worlds bounds.

## Acknowledgments and Disclosure of Funding

SM and YS acknowledge partial support by the Independent Research Fund Denmark, grant number 9040-00361B.

## References

* Abernethy et al. (2015) Jacob D Abernethy, Chansoo Lee, and Ambuj Tewari. Fighting bandits with a new kind of smoothness. In _Advances in Neural Information Processing Systems (NeurIPS)_, 2015.
* Auer et al. (2002) Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. _Machine Learning_, 47, 2002.
* Auer et al. (2002) Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, and Robert E. Schapire. The nonstochastic multiarmed bandit problem. _SIAM Journal on Computing_, 32, 2002b.
* Bistritz et al. (2019) Ilai Bistritz, Zhengyuan Zhou, Xi Chen, Nicholas Bambos, and Jose Blanchet. Online exp3 learning in adversarial bandits with delayed feedback. In _Advances in Neural Information Processing Systems (NeurIPS)_, 2019.
* Cesa-Bianchi et al. (2019) Nicolo Cesa-Bianchi, Claudio Gentile, and Yishay Mansour. Delay and cooperation in nonstochastic bandits. _Journal of Machine Learning Research_, 20:1-38, 2019.
* Eick (1988) Stephen G. Eick. The two-armed bandit with delayed responses. _The Annals of Statistics_, 1988.
* Ito (2021) Shinji Ito. Parameter-free multi-armed bandit algorithms with hybrid data-dependent regret bounds. In _Proceedings of the Conference on Learning Theory (COLT)_, 2021.
* Jin et al. (2022) Tiancheng Jin, Tal Lancewicki, Haipeng Luo, Yishay Mansour, and Aviv Rosenberg. Near-optimal regret for adversarial MDP with delayed bandit feedback. In _Advances in Neural Information Processing Systems (NeurIPS)_, 2022.
* Joulani et al. (2013) Pooria Joulani, Andras Gyorgy, and Csaba Szepesvari. Online learning under delayed feedback. In _Proceedings of the International Conference on Machine Learning (ICML)_, 2013.
* Masoudian et al. (2022) Saeed Masoudian, Julian Zimmert, and Yevgeny Seldin. A best-of-both-worlds algorithm for bandits with delayed feedback. In _Advances in Neural Information Processing Systems (NeurIPS)_, 2022.
* Neu (2015) Gergely Neu. Explore no more: Improved high-probability regret bounds for non-stochastic bandits. In _Advances in Neural Information Processing Systems_, 2015.
* Neu et al. (2010) Gergely Neu, Andras Gyorgy, Csaba Szepesvari, and Andras Antos. Online markov decision processes under bandit feedback. In _Advances in Neural Information Processing Systems_, 2010.
* Neu et al. (2011)Gergely Neu, Andras Gyorgy, Csaba Szepesvari, and Andras Antos. Online markov decision processes under bandit feedback. _IEEE Transactions on Automatic Control_, 59:676-691, 2014.
* Orabona (2022) Francesco Orabona. A modern introduction to online learning, 2022. https://arxiv.org/abs/1912.13213.
* Simon (1977) Richard Simon. Adaptive treatment assignment methods and clinical trials. _Biometrics_, 33, 1977.
* Thompson (1933) William R. Thompson. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. _Biometrika_, 25, 1933.
* Thune et al. (2019) Tobias Sommer Thune, Nicolo Cesa-Bianchi, and Yevgeny Seldin. Nonstochastic multiarmed bandits with unrestricted delays. In _Advances in Neural Information Processing Systems (NeurIPS)_, 2019.
* Zimmert & Seldin (2020) Julian Zimmert and Yevgeny Seldin. An optimal algorithm for adversarial bandits with arbitrary delays. In _Proceedings on the International Conference on Artificial Intelligence and Statistics (AISTATS)_, 2020.
* Zimmert & Seldin (2021) Julian Zimmert and Yevgeny Seldin. Tsallis-INF: An optimal algorithm for stochastic and adversarial bandits. _Journal of Machine Learning Research_, 2021.

Details of the Drifted Regret Analysis

In this section we prove the bound on drifted regret in equation (4). The derivation is same as the one by Masoudian et al. (2022), however, for the sake of completeness we reproduce it here. The analysis follows the standard FTRL approach, decomposing the drifted pseudo-regret into _penalty_ and _stability_ terms as

\[\overline{Reg}_{T}^{drift}=\mathbb{E}\left[\underbrace{\sum_{t=1}^{T}\left\langle x _{t},\widehat{\ell}_{t}^{obs}\right\rangle+\bar{F}_{t}^{*}(-\widehat{L}_{t+1} ^{obs})-\bar{F}_{t}^{*}(-\widehat{L}_{t}^{obs})}_{stability}\right]+\mathbb{E} \left[\underbrace{\sum_{t=1}^{T}\bar{F}_{t}^{*}(-\widehat{L}_{t}^{obs})-\bar{F }_{t}^{*}(-\widehat{L}_{t+1}^{obs})-\widehat{\ell}_{t,i_{\widetilde{T}}}}_{penalty }\right].\]

The penalty term is bounded by the following inequality, derived by Abernethy et al. (2015)

\[penalty\leq\sum_{t=2}^{T}\left(F_{t-1}(x_{t})-F_{t}(x_{t})\right)+F_{T}( \mathrm{e}_{i_{T}^{*}})-F_{1}(x_{1}),\] (12)

where \(\mathrm{e}_{i_{T}^{*}}\) represents the unit vector in \(\mathbb{R}^{K}\) with the \(i_{T}^{*}\)-th element being one and zero elsewhere. This leads to the following bound for penalty term

\[penalty\leq\mathcal{O}\left(\sum_{t=2}^{T}\sum_{i\neq i^{*}}\eta_{t}x_{t,i}^ {\frac{1}{2}}+\sum_{t=2}^{T}\sum_{i=1}^{K}\frac{\sigma_{t}\gamma_{t}x_{t,i} \log(1/x_{t,i})}{\log K}\right),\] (13)

where we substitute the explicit form of the regularizer into (12) and exploit the properties \(\eta_{t}^{-1}-\eta_{t-1}^{-1}=\mathcal{O}(\eta_{t})\), \(\gamma_{t}^{-1}-\gamma_{t-1}^{-1}=\mathcal{O}(\sigma_{t}\gamma_{t}/\log K)\), and \(x_{t,i_{T}^{*}}^{\frac{1}{2}}-1\leq 0\).

For the stability term, following a similar analysis as presented by Masoudian et al. (2022, Lemma 5), but incorporating implicit exploration terms, for any \(\alpha_{t}\leq\gamma_{t}^{-1}\) we obtain

\[stability\leq\sum_{t=1}^{T}\sum_{i=1}^{K}2f_{t}^{{}^{\prime\prime}}(x_{t,i})^{- 1}(\widehat{\ell}_{t,i}^{obs}-\alpha_{t})^{2}.\]

Let \(A_{t}=\left\{s\leq t:s+\widehat{d}_{s}=t\right\}\), then due to the choice of skipping threshold, \(\alpha_{t}=\sum_{s\in A_{t}}\bar{\ell}_{s,t}\) satisfies the condition \(\alpha_{t}\leq\gamma_{t}^{-1}\), where \(\bar{\ell}_{s,t}=\frac{\sum_{i=1}^{K}f_{t}^{{}^{\prime\prime}}(x_{t,i})^{-1} \widehat{\ell}_{s,i}}{\sum_{i=1}^{K}f_{t}^{{}^{\prime\prime}}(x_{t,i})^{-1}}= \frac{f_{t}^{{}^{\prime\prime}}(x_{t,I_{s}})^{-1}\widehat{\ell}_{s,I_{s}}}{ \sum_{i=1}^{K}f_{t}^{{}^{\prime\prime}}(x_{t,i})^{-1}}\). Thus we have

\[stability\leq\sum_{t=1}^{T}\sum_{i=1}^{K}2f_{t}^{{}^{\prime\prime} }(x_{t,i})^{-1}\left(\sum_{s\in A_{t}}\widehat{\ell}_{s,i}-\bar{\ell}_{s,t} \right)^{2}\] \[=\underbrace{\sum_{t=1}^{T}\sum_{i=1}^{K}\sum_{s\in A_{t}}2f_{t}^ {{}^{\prime\prime}}(x_{t,i})^{-1}\left(\widehat{\ell}_{s,i}-\bar{\ell}_{s,t} \right)^{2}}_{S_{1}}\] \[+\underbrace{\sum_{t=1}^{T}\sum_{i=1}^{K}\sum_{r,s\in A_{t},r\neq s }2f_{t}^{{}^{\prime\prime}}(x_{t,i})^{-1}\left(\widehat{\ell}_{s,i}-\bar{\ell }_{s,t}\right)\left(\widehat{\ell}_{r,i}-\bar{\ell}_{r}\right)}_{S_{2}}\]For brevity we define \(z_{t,i}=f_{t}^{{}^{\prime}}\left(x_{t,i}\right)^{-1}\) and \(m_{s,i}^{t}=\max\left\{x_{s,i},\lambda_{s,t}\right\}\) for any \(s\leq t\) and \(i\in[K]\). We begin bounding \(S_{1}\) by replacing definition of loss estimators from (1) and get

\[\mathbb{E}[S_{1}] =\sum_{t=1}^{T}\sum_{i=1}^{K}\sum_{s\in A_{t}}2\mathbb{E}\left[z_ {t,i}\left(\frac{\mathds{1}(I_{s}=i)}{m_{s,i}^{t}}-\frac{z_{t,I_{s}}\mathds{1 }(I_{s}=i)}{m_{s,I_{s}}^{t}\sum_{j=1}^{K}z_{t,j}}\right)^{2}\right]\] \[\leq\sum_{t=1}^{T}\sum_{i=1}^{K}\sum_{s\in A_{t}}2\mathbb{E}\left[ z_{t,i}\left(\frac{\mathds{1}(I_{s}=i)}{m_{s,i}^{t}}-\frac{z_{t,I_{s}}}{m_{s,I_{s} }^{t}\sum_{j=1}^{K}z_{t,j}}\right)^{2}\right]\] \[=\sum_{t=1}^{T}\sum_{s\in A_{t}}2\underbrace{\sum_{i=1}^{K} \mathbb{E}\left[z_{t,i}\left(\frac{\mathds{1}(I_{s}=i)}{m_{s,i}^{t}}-\frac{z_{ t,I_{s}}\mathds{1}(I_{s}=i)}{m_{s,i}^{t}m_{s,I_{s}}^{t}\sum_{j=1}^{K}z_{t,j}} \right)\right]}_{S_{1}^{1}}\] \[+\sum_{t=1}^{T}\sum_{s\in A_{t}}\underbrace{2\mathbb{E}\left[ \left(\frac{z_{t,I_{s}}^{2}}{m_{s,I_{s}}^{t}{}^{2}(\sum_{j=1}^{K}z_{t,j})}- \sum_{i=1}^{K}\frac{z_{t,I_{s}}z_{t,i}\mathds{1}(I_{s}=i)}{m_{s,i}^{t}m_{s,I_{ s}}^{t}\sum_{j=1}^{K}z_{t,j}}\right)\right]}_{S_{1}^{1}}\]

Where the first inequality uses \(\ell_{s,I_{s}}\leq 1\). We show that \(S_{1}^{2}\) has negative contribution to \(S_{1}\) by taking expectation w.r.t. \(I_{s}\) as the following

\[S_{1}^{2}=\sum_{t=1}^{T}\sum_{s\in A_{t}}\mathbb{E}\left[\sum_{i=1}^{K}\frac{ z_{t,i}^{2}x_{s,i}}{m_{s,i}^{t}{}^{2}(\sum_{j=1}^{K}z_{t,j})}-\sum_{i=1}^{K} \frac{z_{t,i}^{2}x_{s,i}}{m_{s,i}^{t}{}^{2}\sum_{j=1}^{K}z_{t,j}}\right]=0\]

Thus we only need to bound \(S_{1}^{1}\), for which we take expectation w.r.t. \(I_{s}\) and separate \(i^{*}\) from the other arms to get

\[S_{1}^{1} =\sum_{i=1}^{K}\mathbb{E}\left[z_{t,i}\left(\frac{\mathds{1}(I_{s }=i)}{m_{s,i}^{t}{}^{2}}-\frac{z_{t,I_{s}}\mathds{1}(I_{s}=i)}{m_{s,i}^{t}{}^ {2}}\sum_{j=1}^{K}z_{t,j}\right)\right]\] \[\leq\sum_{i\neq i^{*}}\mathbb{E}\left[\frac{z_{t,i}x_{s,i}}{m_{s,i}^{t}{}^{2}}\right]+\mathbb{E}\left[\frac{z_{t,i^{*}}x_{s,i^{*}}}{m_{s,i}^{t }{}^{2}}-\frac{z_{t,i^{*}}^{2}x_{s,i^{*}}}{m_{s,i}^{t}{}^{2}\sum_{j=1}^{K}z_{t,j}}\right]\] \[\leq\sum_{i\neq i^{*}}\mathbb{E}\left[4\eta_{t}x_{s,i}^{1/2} \right]+\mathbb{E}\left[\frac{x_{s,i^{*}}}{m_{s,i^{*}}^{t}{}^{2}}\times z_{t,i^ {*}}\left(1-\frac{z_{t,i^{*}}}{\sum_{j=1}^{K}z_{t,j}}\right)\right]\] \[\leq\sum_{i\neq i^{*}}4\mathbb{E}\left[\eta_{t}x_{s,i}^{1/2} \right]+\mathbb{E}\left[\frac{x_{s,i^{*}}}{m_{s,i^{*}}^{t}}\times\eta_{t}x_{t,i ^{*}}^{3/2}\left(1-\frac{x_{t,i^{*}}^{3/2}}{(1-x_{t,i^{*}})^{3/2}+x_{t,i^{*}} ^{3/2}}\right)\right]\] \[\leq\sum_{i\neq i^{*}}4\mathbb{E}\left[\eta_{t}x_{s,i}^{1/2} \right]+\mathbb{E}\left[\frac{\eta_{t}x_{s,i^{*}}x_{t,i^{*}}^{3/2}}{m_{s,i^{*} }^{t}{}^{2}}\times\left(\frac{(1-x_{t,i^{*}})^{3/2}}{2^{-1/2}}\right)\right]\] \[\leq\sum_{i\neq i^{*}}4\mathbb{E}\left[\eta_{t}x_{s,i}^{1/2} \right]+\mathbb{E}\left[4\sqrt{2}\eta_{t}\sum_{i\neq i^{*}}x_{t,i}\right]\] \[\leq\sum_{i\neq i^{*}}4\mathbb{E}\left[\eta_{t}x_{s,i}^{1/2} \right]+\mathbb{E}\left[16\sqrt{2}\eta_{t}\sum_{i\neq i^{*}}(x_{s,i}+\lambda_{ s,t})\right]\] \[\leq\mathcal{O}\left(\mathbb{E}\left[\eta_{s}\sum_{i\neq i^{*}}x _{s,i}^{1/2}\right]+\mathbb{E}\left[K\lambda_{s,t}\right]\right),\]

where the second inequality uses \(z_{t,i}=f_{t}^{{}^{\prime\prime}}(x_{t,i})^{-1}\leq\eta_{t}x_{t,i}^{3/2}\) along \(x_{t,i}\leq m_{s,i}^{t}\) from Lemma 3, the third inequality is due the fact that \(z_{t,i^{*}}\left(1-\frac{z_{t,i^{*}}}{\sum_{j=1}^{K}z_{t,j}}\right)\) is an increasing function in termsof both \(z_{t,i^{*}}\) and \(\sum_{i\neq i^{*}}z_{t,i}\) and we substitute \(z_{t,i^{*}}\leq\eta_{t}x_{t,i^{*}}^{3/2}\) and \(\sum_{j\neq i^{*}}z_{t,j}\leq\sum_{j\neq i^{*}}\eta_{t}x_{t,j}^{3/2}\leq\eta_{t}( 1-x_{t,i^{*}})^{3/2}\), the fourth inequality is due to \((1-a)^{3/2}+a^{3/2}\leq 2^{-1/2}\), the fifth and the sixth inequalities rely on Lemma 3, and finally the last inequality is followed by \(\forall i:x_{s,i}\leq x_{s,i}^{1/2}\) and that \(\eta_{t}\leq\eta_{s}\). Combining bounds for \(S_{1}^{1}\) and \(S_{1}^{2}\) gives the following bound for \(S_{1}\)

\[\mathbb{E}[S_{1}]\leq\mathcal{O}\left(\sum_{t=1}^{T}\sum_{i\neq i^{*}}\eta_{t }\mathbb{E}[x_{t,i}^{1/2}]+\sum_{t=1}^{T}K\lambda_{t,t+\widehat{d}_{t}}\right)\] (14)

For \(S_{2}\), we take expectation with respect to \(I_{s}\), \(I_{r}\), and randomness of losses, all separately to get

\[\mathbb{E}[S_{2}] =\sum_{t=1}^{T}\sum_{i=1}^{K}\sum_{r,s\in A_{t},r\neq s}2\mathbb{ E}\left[z_{t,i}\left(\widehat{\ell}_{s,i}-\bar{\ell}_{s}\right)\left(\widehat{ \ell}_{r,i}-\bar{\ell}_{s}\right)\right]\] \[=\sum_{t=1}^{T}\sum_{i=1}^{K}\sum_{r,s\in A_{t},r\neq s}2\mathbb{ E}\left[z_{t,i}\left(\frac{\mu_{i}x_{s,i}}{m_{s,i}^{t}}-\frac{\sum_{j=1}^{K}z_{t, j}\mu_{j}x_{s,j}/m_{s,j}^{t}}{\sum_{j=1}^{K}z_{t,j}}\right)\left(\frac{\mu_{i}x_{r,i} }{m_{r,i}^{t}}-\frac{\sum_{j=1}^{K}z_{t,j}\mu_{j}x_{r,j}/m_{r,j}^{t}}{\sum_{j =1}^{K}z_{t,j}}\right)\right].\] (15)

For simplicity we define \(\epsilon_{s,i}^{t}=\mu_{i}-\frac{\mu_{i}x_{s,i}}{m_{s,i}^{t}}\) for any \(s\leq t\) and any \(i\in[K]\), for which we have the following bounds

\[0\leq\epsilon_{s,i}^{t}\leq\frac{\lambda_{s,t}}{m_{s,i}^{t}}.\]

We then continue from 15 and bound it as the following

\[\mathbb{E}[S_{2}]\] \[=\sum_{t=1}^{T}\sum_{\begin{subarray}{c}r\neq s\\ r,s\in A_{t}\end{subarray}}\sum_{i=1}^{K}2\mathbb{E}\left[z_{t,i}\left(\mu_{i} -\frac{\sum_{j=1}^{K}z_{t,j}\mu_{j}}{\sum_{j=1}^{K}z_{t,j}}-\epsilon_{s,i}^{t} +\frac{\sum_{j=1}^{K}z_{t,j}\epsilon_{s,j}^{t}}{\sum_{j=1}^{K}z_{t,j}}\right) \left(\mu_{i}-\frac{\sum_{j=1}^{K}z_{t,j}\mu_{j}}{\sum_{j=1}^{K}z_{t,j}}- \epsilon_{r,i}^{t}+\frac{\sum_{j=1}^{K}z_{t,j}\epsilon_{r,j}^{t}}{\sum_{j=1}^ {K}z_{t,j}}\right)\right]\] \[\leq\sum_{t=1}^{T}\sum_{\begin{subarray}{c}r\neq s\\ r,s\in A_{t}\end{subarray}}2\mathbb{E}\left[\underbrace{\sum_{i=1}^{K}z_{t,i} \left(\mu_{i}-\frac{\sum_{j=1}^{K}z_{t,j}\mu_{j}}{\sum_{j=1}^{K}z_{t,j}} \right)^{2}}_{S_{2}^{1}}+\underbrace{\sum_{i=1}^{K}z_{t,i}\epsilon_{s,i}^{t} \epsilon_{r,i}^{t}+2z_{t,i}(\epsilon_{s,i}^{t}+\epsilon_{r,i}^{t})}_{S_{2}^{2} }+\underbrace{\frac{(\sum_{i=1}^{K}z_{t,i}\epsilon_{s,i}^{t})(\sum_{i=1}^{K}z_{ t,i}\epsilon_{r,i}^{t})}{\sum_{i=1}^{K}z_{t,i}}}_{S_{2}^{3}}\right],\] (16)

where the inequality holds because we ignore the negative terms after multiplication and that \(|(\mu_{i}-\frac{\sum_{j=1}^{K}z_{t,j}\mu_{j}}{\sum_{j=1}^{K}z_{t,j}})|\leq 1\). We need to bound each part from (16). We start with \(S_{2}^{1}\),

\[S_{2}^{1} =\sum_{i=1}^{K}z_{t,i}\left(\mu_{i}-\frac{\sum_{j=1}^{K}z_{t,j} \mu_{j}}{\sum_{j=1}^{K}z_{t,j}}\right)^{2}\] \[=\sum_{i=1}^{K}z_{t,i}\mu_{i}^{2}-\frac{\left(\sum_{i=1}^{K}z_{t, i}\mu_{i}\right)^{2}}{\sum_{i=1}^{K}z_{t,i}}\] \[\leq\sum_{i=1}^{K}z_{t,i}\mu_{i}^{2}-\frac{\left(\sum_{i=1}^{K}z_{t,i}\mu_{i^{*}}\right)^{2}}{\sum_{i=1}^{K}z_{t,i}}\] \[\leq\sum_{i=1}^{K}z_{t,i}(\mu_{i}^{2}-\mu_{i^{*}}^{2})\] \[\leq\sum_{i\neq i^{*}}2\gamma_{t}x_{t,i}\Delta_{i}\] (17)We bound \(S_{2}^{2}\) as

\[S_{2}^{2} =\sum_{i=1}^{K}z_{t,i}\epsilon_{s,i}^{t}\epsilon_{r,i}^{t}+2z_{t,i}( \epsilon_{s,i}^{t}+\epsilon_{r,i}^{t})\] \[\leq\sum_{i=1}^{K}z_{t,i}\frac{\epsilon_{s,i}^{t}+\epsilon_{r,i}^{ t}}{2}+2z_{t,i}(\epsilon_{s,i}^{t}+\epsilon_{r,i}^{t})\] \[\leq\frac{5}{2}\sum_{i=1}^{K}\frac{z_{t,i}\lambda_{s,t}}{m_{s,i}^ {t}}+\frac{z_{t,i}\lambda_{r,t}}{m_{r,i}^{t}}\] \[\leq\frac{5}{2}K\gamma_{t}(\lambda_{s,t}+\lambda_{r,t}),\] (18)

where the last inequality holds because \(z_{t,i}\leq\gamma_{t}x_{t,i}\) and that \(x_{t,i}\leq 4m_{s,i}^{t},4m_{r,i}^{t}\) from Lemma 3.

It remains to give upper bound for \(S_{2}^{3}\) as

\[S_{2}^{3} =\frac{(\sum_{i=1}^{K}z_{t,i}\epsilon_{s,i}^{t})(\sum_{i=1}^{K}z _{t,i}\epsilon_{r,i}^{t})}{\sum_{i=1}^{K}z_{t,i}}\] \[\leq\frac{(\sum_{i=1}^{K}z_{t,i}\lambda_{s,t}/m_{s,i}^{t})(\sum_{ i=1}^{K}z_{t,i}\lambda_{r,t}/m_{r,i}^{t})}{\sum_{i=1}^{K}z_{t,i}}\] \[\leq\frac{1}{2}K\gamma_{t}(\lambda_{s,t}+\lambda_{r,t}),\] (19)

where the second inequality rely on \(z_{t,i}\leq\gamma_{t}x_{t,i}\), \(\lambda_{s,t}\leq m_{s,i}^{t}\), \(\lambda_{r,t}\leq m_{r,i}^{t}\), and \(x_{t,i}\leq 4m_{s,i}^{t},x_{t,i}\leq 4m_{r,i}^{t}\) from Lemma 3. It is suffices to plug bounds in (17), (18), and (19) to obtain

\[\mathbb{E}[S_{2}] \leq\sum_{t=1}^{T}\sum_{i\neq i^{*}}4\Delta_{i}\gamma_{t}\mathbb{ E}[x_{t,i}]\upsilon_{t}(v_{t}-1)+6\sum_{t=1}^{T}K\gamma_{t+\widehat{d}_{t}}( \upsilon_{t+\widehat{d}_{t}}-1)\lambda_{t,t+\widehat{d}_{t}}\] \[\leq\sum_{t=1}^{T}\sum_{i\neq i^{*}}\sum_{s\in A_{t}}4\Delta_{i} \gamma_{t}\mathbb{E}[x_{s,i}](\upsilon_{t}-1)+10\sum_{t=1}^{T}K\gamma_{t+ \widehat{d}_{t}}(\upsilon_{t+\widehat{d}_{t}}-1)\lambda_{t,t+\widehat{d}_{t}}\] \[\leq\mathcal{O}\left(\sum_{t=1}^{T}\sum_{i\neq i^{*}}\gamma_{t+ \widehat{d}_{t}}\Delta_{i}\mathbb{E}[x_{t,i}](\upsilon_{t+\widehat{d}_{t}}-1)+ K\sum_{t=1}^{T}\lambda_{t,t+\widehat{d}_{t}}\right),\] (20)

where the third inequality uses Lemma 3 and the last inequality holds because of the skipping that ensures \(\gamma_{t+\widehat{d}_{t}}(\upsilon_{t+\widehat{d}_{t}}-1)\leq 1\). Now, it is sufficient to combine the bounds for \(S_{1}\) and \(S_{2}\) in (14) and (20) and get

\[\mathbb{E}[stability]\leq\mathcal{O}\left(\sum_{t=1}^{T}\sum_{i\neq i^{*}} \eta_{t}\mathbb{E}[x_{t,i}^{1/2}]+\sum_{t=1}^{T}\sum_{i\neq i^{*}}\gamma_{t+ \widehat{d}_{t}}\mathbb{E}[x_{t,i}](\upsilon_{t+\widehat{d}_{t}}-1)+K\sum_{t =1}^{T}\lambda_{t,t+\widehat{d}_{t}}\right).\] (21)

Combining the stability bound from (21) and the penalty bound from (13) concludes the proof.

## Appendix B Proof of the Drift Control Lemma

In this section we provide a proof of Lemma 3. We start with a few auxiliary results, and then prove the lemma.

### Auxiliary results for the proof of the key lemma

For the proof we use two facts and a lemma from Masoudian et al. (2022), and a new lemma. Recall that \(f_{t}(x)=-2\eta_{t}^{-1}\sqrt{x}+\gamma_{t}^{-1}x\log x\).

**Fact 7**.: _(_Masoudian et al._,_ 2022, Fact 15_)_ \(f^{{}^{\prime}}_{t}(x)\) _is a concave function._

**Fact 8**.: _(_Masoudian et al._,_ 2022, Fact 16_)_ \(f^{{}^{\prime\prime}}_{t}(x)^{-1}\) _is a convex function._

**Lemma 9**.: _(_Masoudian et al._,_ 2022_, Lemma 17)_ _Fix \(t\) and \(s\) with \(t\geq s\), and assume that there exists \(\alpha\), such that \(x_{t,i}\leq\alpha\max(x_{s,i},\lambda_{s,t})\) for all \(i\in[K]\), and let \(f(x)=\left(-2\eta_{t}^{-1}\sqrt{x}+\gamma_{t}^{-1}x\log x\right)\), then we have the following inequality_

\[\frac{\sum_{j=1}^{K}f^{{}^{\prime\prime}}(x_{t,j})^{-1}\widehat{ \ell}_{s,j}}{\sum_{j=1}^{K}f^{{}^{\prime\prime}}(x_{t,j})^{-1}}\leq 2\alpha(K-1 )^{\frac{1}{3}}.\]

**Lemma 10**.: _If \(t>s\) and \((t-s)\leq d_{\max}^{t}\), then_

\[d_{\max}^{t}\leq\sqrt{2}d_{\max}^{s},\]

_which is equivalent to \(\mathcal{D}_{t}\leq 2\mathcal{D}_{s}\)._

Proof.: It suffices to prove that \(\mathcal{D}_{t}\leq 2\mathcal{D}_{s}\), which is equivalent to proving that \((\mathcal{D}_{t}-\mathcal{D}_{s})\leq\frac{1}{2}\mathcal{D}_{t}\). We have:

\[\mathcal{D}_{t}-\mathcal{D}_{s}=\sum_{r=s+1}^{t}\widehat{\sigma}_ {r}\leq(t-s)d_{\max}^{t}\leq\left(d_{\max}^{t}\right)^{2}=\frac{\mathcal{D}_{ t}}{49K^{\frac{1}{3}}\log K}\leq\frac{\mathcal{D}_{t}}{2},\]

where the first inequality holds because due to skipping, for all \(r\leq t\) we have \(\widehat{\sigma}_{r}\leq d_{\max}^{t}\), and \((t-s)\leq d_{\max}^{t}\). 

### Proof of the Drift Control Lemma

Now we are ready to provide a proof of Lemma 3. Similar to the analysis of Masoudian et al. (2022), the proof relies on induction on _valid_ pairs \((t,s)\), where a pair \((t,s)\) is considered valid if \(s\leq t\) and \((t-s)\leq d_{\max}^{t}\). The induction step for pair \((t,s)\) involves proving that \(x_{t,i}\leq 4\max(x_{s,i},\lambda_{s,t})\) for all \(i\in[K]\). To establish this, we use the induction assumption for all valid pairs \((t^{\prime},s^{\prime})\) such that \(s^{\prime},t^{\prime}<t\), as well as all valid pairs \((t^{\prime},s^{\prime})\), such that \(t^{\prime}=t\) and \(s<s^{\prime}\leq t\). The induction base encompasses all pairs \((t^{\prime},t^{\prime})\) for all \(t^{\prime}\in[T]\), where the statement \(x_{t^{\prime},i}\leq 4x_{t^{\prime},i}\) holds trivially.

To control \(\frac{x_{t,i}}{\max(x_{s,i},\lambda_{s,t})}\) we first introduce an auxiliary variable \(\widetilde{x}=\bar{F}_{s}^{*}(-\widehat{L}_{t-1}^{obs})\). We then address the problem of drift control by breaking it down into two sub-problems:

1. \(\frac{x_{t,i}}{\max(\widetilde{x}_{i},\lambda_{s,t})}\leq 2\): the drift due to change of regularizer,
2. \(\frac{\widetilde{x}_{i}}{x_{s,i}}\leq 2\): the drift due to loss shift.

#### Deviation induced by the change of regularizer

The regularizer at round \(r\) is defined as

\[F_{r}(x)=\sum_{i=1}^{K}f_{r}(x_{i})=\sum_{i=1}^{K}\left(-2\eta_{ r}^{-1}\sqrt{x_{i}}+\gamma_{r}^{-1}x_{i}\log x_{i}\right).\]

We have \(x_{t}=\nabla\bar{F}_{t}^{*}(-\widehat{L}_{t-1}^{obs})\) and \(\widetilde{x}=\nabla\bar{F}_{s}^{*}(-\widehat{L}_{t-1}^{obs})\). According to the KKT conditions, there exist Lagrange multipliers \(\mu\) and \(\widetilde{\mu}\), such that for all \(i\):

\[f^{{}^{\prime}}_{s}(\widetilde{x}_{i}) =-\widehat{L}_{t-1,i}^{obs}+\widetilde{\mu},\] \[f^{{}^{\prime}}_{t}(x_{t,i}) =-\widehat{L}_{t-1,i}^{obs}+\mu.\]

We also know that there exists an index \(j\), such that \(\widetilde{x}_{j}\geq x_{t,j}\). This leads to the following inequality:

\[-\widehat{L}_{t-1,j}^{obs}+\mu=f^{{}^{\prime}}_{t}(x_{t,j})\leq f^{{}^{\prime }}_{s}(x_{t,j})\leq f^{{}^{\prime}}_{s}(\widetilde{x}_{j})=-\widehat{L}_{t-1,j }^{obs}+\widetilde{\mu},\]where the first inequality holds because the learning rates are decreasing, and the second inequality is due to the fact that \(f_{s}^{{}^{\prime}}(x)\) is increasing. This implies that \(\mu\leq\widetilde{\mu}\), which gives us the following inequality for all \(i\):

\[f_{t}^{{}^{\prime}}(x_{t,i})=-\frac{1}{\eta_{t}\sqrt{x_{t,i}}}+\frac{\log(x_{t, i})}{\gamma_{t}}\leq-\frac{1}{\eta_{s}\sqrt{x_{i}}}+\frac{\log(\widetilde{x}_{i}) }{\gamma_{s}}=f_{s}^{{}^{\prime}}(\widetilde{x}_{i}).\]

Thus, we have two cases, either \(-\frac{1}{\eta_{t}\sqrt{x_{t,i}}}\leq-\frac{1}{\eta_{s}\sqrt{x_{i}}}\) or \(\frac{\log(x_{t,i})}{\gamma_{t}}\leq\frac{\log(\widetilde{x}_{i})}{\gamma_{s}}\).

**Case i:** If \(-\frac{1}{\eta_{t}\sqrt{x_{t,i}}}\leq-\frac{1}{\eta_{s}\sqrt{x_{i}}}\) holds, then we have \(\frac{x_{t,i}}{\widetilde{x}_{i}}\leq\frac{\eta_{t}^{2}}{\eta_{t}^{2}}=\frac{ t}{s}\). On the other hand, we have

\[t-s\leq d_{\max}^{t}=\sqrt{\frac{\sum_{r=1}^{t}\widehat{\sigma}_{r}}{K^{3/2} \log K}}\leq\sqrt{\frac{t^{2}/2}{K^{3/2}\log K}}\leq\frac{t}{2},\]

where the second inequality holds because trivially \(\widehat{\sigma}_{r}\leq r\). This implies that \(\frac{x_{t,i}}{\widetilde{x}_{i}}\leq 2\).

**Case ii:** If \(\frac{\log(x_{t,i})}{\gamma_{t}}\leq\frac{\log(\widetilde{x}_{i})}{\gamma_{s}}\), it implies that \(x_{t,i}\leq\widetilde{x}_{i}^{\frac{\gamma_{t}}{\gamma_{s}}}\). Using \(\widetilde{x}_{i}\leq\max(\widetilde{x}_{i},\lambda_{s,t})\), we get

\[x_{t,i} \leq\max(\widetilde{x}_{i},\lambda_{s,t})^{\frac{\gamma_{t}}{ \gamma_{s}}}\] \[=\max(\widetilde{x}_{i},\lambda_{s,t})\times\max(\widetilde{x}_{i },\lambda_{s,t})^{\frac{\gamma_{t}}{\gamma_{s}}-1}\] \[\leq\max(\widetilde{x}_{i},\lambda_{s,t})\times\lambda_{s,t}^{ \frac{\gamma_{t}}{\gamma_{s}}-1}\] \[=\max(\widetilde{x}_{i},\lambda_{s,t})\times\lambda_{s,t}^{- \frac{\sqrt{\mathcal{D}_{t}}-\sqrt{\mathcal{D}_{s}}}{\sqrt{\mathcal{D}_{t}}}}\] \[=\max(\widetilde{x}_{i},\lambda_{s,t})\times e^{\frac{\mathcal{D} _{t}}{\widetilde{\sigma}_{t}-\mathcal{D}_{s}}\times\frac{\sqrt{\mathcal{D}_{t }}-\sqrt{\mathcal{D}_{s}}}{\sqrt{\mathcal{D}_{t}}}}\] \[=\max(\widetilde{x}_{i},\lambda_{s,t})\times e^{\frac{\sqrt{ \mathcal{D}_{t}}}{(\sqrt{\mathcal{D}_{t}}+\sqrt{\mathcal{D}_{s}})}}\leq\max( \widetilde{x}_{i},\lambda_{s,t})\times e^{\frac{-1}{1+\sqrt{\frac{1}{2}}}} \leq\max(\widetilde{x}_{i},\lambda_{s,t})\times 2.\]

Therefore, in both cases we obtain

\[x_{t,i}\leq 2\max(\widetilde{x}_{i},\lambda_{s,t}).\] (22)

#### Deviation Induced by the Loss Shift

The initial steps of the proof of this part are the same as in Masoudian et al. (2022). However, for the sake of completeness, we restate them here.

Since we have \(x_{s}=\nabla\bar{F}_{s}^{*}(-\widehat{L}_{s-1}^{obs})\) and \(\widetilde{x}=\nabla\bar{F}_{s}^{*}(-\widehat{L}_{t-1}^{obs})\), they both share the same regularizer \(F_{s}(x)=\sum_{i=1}^{K}f_{s}(x_{i})\). For brevity, we drop \(s\) from \(f_{s}(x)\). By the KKT conditions \(\exists\mu,\widetilde{\mu}\) s.t. \(\forall i\):

\[f^{{}^{\prime}}(x_{s,i}) =-\widehat{L}_{s-1,i}^{obs}+\mu,\] \[f^{{}^{\prime}}(\widetilde{x}_{i}) =-\widehat{L}_{t-1,i}^{obs}+\widetilde{\mu}.\]

Let \(\widetilde{\ell}=\widehat{L}_{t-1}^{obs}-\widehat{L}_{s-1}^{obs}\), then by the concavity of \(f^{{}^{\prime}}(x)\) from Fact 7, we have

\[(x_{s,i}-\widetilde{x}_{i})f^{{}^{\prime\prime}}(x_{s,i})\leq \underbrace{f^{{}^{\prime}}(x_{s,i})-f^{{}^{\prime}}(\widetilde{x}_{i})}_{\mu -\widetilde{\mu}+\widetilde{\ell}_{i}}\leq(x_{s,i}-\widetilde{x}_{i})f^{{}^{ \prime\prime}}(\widetilde{x}_{i}).\] (23)

Since \(f^{{}^{\prime\prime}}(x_{s,i})\geq 0\), from the left side of (23) we get \(x_{s,i}-\widetilde{x}_{i}\leq f^{{}^{\prime\prime}}(x_{s,i})^{-1}\left(\mu- \widetilde{\mu}+\widetilde{\ell}_{i}\right)\). Taking summation over all \(i\) and using the fact that both vectors \(x_{s}\) and \(\widetilde{x}\) are probability vectors, we have

\[0=\sum_{i=1}^{K}\left(x_{s,i}-\widetilde{x}_{i}\right) \leq\sum_{i=1}^{K}f^{{}^{\prime\prime}}(x_{s,i})^{-1}\left(\mu- \widetilde{\mu}+\widetilde{\ell}_{i}\right),\] \[\Rightarrow\widetilde{\mu}-\mu \leq\frac{\sum_{i=1}^{K}f^{{}^{\prime\prime}}(x_{s,i})^{-1} \widetilde{\ell}_{i}}{\sum_{i=1}^{K}f^{{}^{\prime\prime}}(x_{s,i})^{-1}}.\] (24)Combining the right hand sides of (23) and (24) gives

\[(\widetilde{x}_{i}-x_{s,i})^{f^{{}^{\prime\prime}}}(\widetilde{x}_{i})\leq \widetilde{\mu}-\mu-\widetilde{\ell}_{i}\leq\frac{\sum_{j=1}^{K}f^{{}^{\prime \prime}}(x_{s,j})^{-1}\widetilde{\ell}_{j}}{\sum_{j=1}^{K}f^{{}^{\prime\prime}}( x_{s,j})^{-1}},\]

and by rearrangement we get

\[\widetilde{x}_{i} \leq x_{s,i}+f^{{}^{\prime\prime}}(\widetilde{x}_{i})^{-1}\times \frac{\sum_{j=1}^{K}f^{{}^{\prime\prime}}(x_{s,j})^{-1}\widetilde{\ell}_{j}}{ \sum_{j=1}^{K}f^{{}^{\prime\prime}}(x_{s,j})^{-1}}\] \[\leq x_{s,i}+\gamma_{s}\widetilde{x}_{i}\times\frac{\sum_{j=1}^{K }f^{{}^{\prime\prime}}(x_{s,j})^{-1}\widetilde{\ell}_{j}}{\sum_{j=1}^{K}f^{{} ^{\prime\prime}}(x_{s,j})^{-1}},\] (25)

where the last inequality holds because \(f^{{}^{\prime\prime}}(\widetilde{x}_{i})^{-1}=\left(\eta_{s}^{-1}\frac{1}{2} \widetilde{x}_{i}^{-3/2}+\gamma_{s}^{-1}\widetilde{x}_{i}^{-1}\right)^{-1}\). The next step for bounding \(\widetilde{x}_{i}\) is to bound \(\frac{\sum_{j=1}^{K}f^{{}^{\prime\prime}}(x_{s,j})^{-1}\widetilde{\ell}_{j}} {\sum_{j=1}^{K}f^{{}^{\prime\prime}}(x_{s,j})^{-1}}\) in (25), where \(\widetilde{\ell}_{j}=\sum_{r\in A}\widehat{\ell}_{r,j}\) and \(A=\left\{r:s\leq r+\widehat{d}_{r}<t\right\}\).

If there exists \(r\in A\), such that \(r>s\) and \(4\max(x_{r,i},\lambda_{r,r+\widehat{d}_{r}})\leq x_{s,i}\), then combining it with the induction assumption for \((r+\widehat{d}_{r},r)\), where we have \(x_{r+\widehat{d}_{r},i}\leq 4\max(x_{r,i},\lambda_{r,r+\widehat{d}_{r}})\), leads to \(x_{r+\widehat{d}_{r},i}\leq x_{s,i}\). On the other hand, by the induction assumption for pair \((r+\widehat{d}_{r},t)\), we have

\[x_{t,i}\leq 4\max(x_{r+\widehat{d}_{r},i},\lambda_{r+\widehat{d}_{r},t}).\]

So using \(x_{r+\widehat{d}_{r},i}\leq x_{s,i}\) and \(\lambda_{r+\widehat{d}_{r},t}\leq\lambda_{s,t}\) we can derive \(x_{t,i}\leq 4\max(x_{s,i},\lambda_{s,t})\). This inequality satisfies the condition we wanted to prove in the drift lemma. Therefore, we assume that for all \(r\in A\) we have either \(r\leq s\) or \(x_{s,i}\leq 4\max(x_{r,i},\lambda_{r,r+\widehat{d}_{r}})\). If \(r\leq s\), using the the induction assumption for \((s,r)\) together with the fact that \(\lambda_{r,s}\leq\lambda_{r,r+\widehat{d}_{r}}\), results in \(x_{s,i}\leq 4\max(x_{r,i},\lambda_{r,s})\). Consequently, in either case, the following inequality holds for all \(r\in A\)

\[x_{s,i}\leq 4\max(x_{r,i},\lambda_{r,r+\widehat{d}_{r}}).\] (26)

Thus, inequality in (26) satisfies the condition of Lemma 9, and for all \(r\in A\) we get:

\[\frac{\sum_{j=1}^{K}f^{{}^{\prime\prime}}(x_{s,j})^{-1}\widehat{\ell}_{r,j}}{ \sum_{j=1}^{K}f^{{}^{\prime\prime}}(x_{s,j})^{-1}}\leq 8(K-1)^{\frac{1}{3}}.\] (27)

We proceed by summing both sides of the inequality (27) over all \(r\in A\) and obtain \(\frac{\sum_{j=1}^{K}f^{{}^{\prime\prime}}(x_{s,j})^{-1}\widetilde{\ell}_{j}}{ \sum_{j=1}^{K}f^{{}^{\prime\prime}}(x_{s,j})^{-1}}\leq 4|A|(K-1)^{\frac{1}{3}}\). Now it suffices to plug this result into (25):

\[\widetilde{x}_{i} \leq x_{s,i}+8|A|\gamma_{s}\widetilde{x}_{i}(K-1)^{\frac{1}{3}}\Rightarrow\] \[\widetilde{x}_{i} \leq x_{s,i}\times\left(\frac{1}{1-8|A|\gamma_{s}(K-1)^{1/3}}\right)\] (28) \[\leq x_{s,i}\times\left(\frac{1}{1-24\gamma_{s}d_{\max}^{s}(K-1) ^{1/3}}\right)\] \[\leq x_{s,i}\times\left(\frac{1}{1-1/2}\right)=2x_{s,i},\] (29)

where the third inequality uses \(|A|\leq d_{\max}^{s}+t-s\leq d_{\max}^{t}+d_{\max}^{s}\), and that \(d_{\max}^{t}\leq 2d_{\max}^{s}\) by Lemma 10, and for the last inequality we use the definitions of \(\gamma_{s}\) and \(d_{\max}^{s}\).

Combining (29) and (22) completes the induction step.

Self-Bounding Analysis

In this section we show the details of how to apply self-bounding analysis to bound the right hand side of (5).

We start from (5) and decompose it as follows

\[\overline{Reg}_{T} \leq\mathbb{E}\left[a\underbrace{\sum_{t=1}^{T}\sum_{i\neq i^{*}} \eta_{t}x_{t,i}^{1/2}}_{A}+b\underbrace{\sum_{t=1}^{T}\sum_{i\neq i^{*}}\gamma_ {t+d_{t}}(\upsilon_{t+d_{t}}-1)x_{t,i}\Delta_{i}}_{B}+c\underbrace{\sum_{t=2}^ {T}\sum_{i=1}^{K}\frac{\widehat{\sigma}_{t}\gamma_{i}x_{t,i}\log(1/x_{t,i})}{ \log K}}_{C}\right]\] \[+\underbrace{\mathcal{O}\left(K\sum_{t=1}^{T}\left(\lambda_{t,t+ \widehat{d}_{t}}+\lambda_{t,t+\widehat{d}_{t}+\sigma_{\max}^{t}}\right)+ \sigma_{\max}+S^{*}\right)}_{\mathcal{D}}.\]

We rewrite the pseudo-regret as \(\overline{Reg}_{T}=4\overline{Reg}_{T}-3\overline{Reg}_{T}\), and then based on the decomposition above we have

\[\overline{Reg}_{T}\leq\mathbb{E}\left[4aA-\overline{Reg}_{T}\right]+\mathbb{ E}\left[4bB-\overline{Reg}_{T}\right]+\mathbb{E}\left[4cC-\overline{Reg}_{T} \right]+4D.\] (30)

Masoudian et al. (2022) provide the following three lemmas that give the bounds for the first three terms in (30). Although the algorithm of Masoudian et al. differs from ours, their bounds remain applicable, because they are based on the worst-case choice of \(x_{t,i}\), which is algorithm-independent.

**Lemma 11**.: _(Masoudian et al., 2022, Lemma 6) For any \(a\geq 0\), we have:_

\[4aA-\overline{Reg}_{T}\leq\sum_{i\neq i^{*}}\frac{4a^{2}}{\Delta_{i}}\log(T+1 )+1.\] (31)

**Lemma 12**.: _(Masoudian et al., 2022, Lemma 7) Let \(\upsilon_{max}=\max_{t\in[T]}\upsilon_{t}\), then for any \(b\geq 0\):_

\[4bB-\overline{Reg}_{T}\leq 64b^{2}\upsilon_{max}\log K.\] (32)

It is evident that \(\upsilon_{max}\leq\sigma_{\max}\), so the bound in Lemma 12 is dominated by \(\mathcal{O}(K\sigma_{\max})\) term in the regret bound.

**Lemma 13**.: _(Masoudian et al., 2022, Lemma 8) For any \(c\geq 0\):_

\[4cC-\overline{Reg}_{T}\leq\sum_{i\neq i^{*}}\frac{128c^{2}\sigma_{\max}}{ \Delta_{i}\log K}.\] (33)

By plugging (31),(32),(33) into (30) we get the desired bound.

## Appendix D A Proof of Lemma 4

First we provide two facts and two auxiliary lemmas.

**Lemma 14**.: _For any \(t\) we have_

\[2\mathcal{D}_{t}\geq\sum_{s=1}^{t}\widehat{d}_{s}.\]

Proof.: We show that for any \(t\in[T]\) we have \(\sum_{s=1}^{t}\widehat{d}_{s}-\mathcal{D}_{t}\leq\mathcal{D}_{t}\):

\[\sum_{s=1}^{t}\widehat{d}_{s}-\mathcal{D}_{t} =\sum_{(s\leq t)\wedge(s+\widehat{d}_{s}>t)}(\widehat{d}_{s}- \widehat{\sigma}_{s})\] \[\leq\sum_{(s\leq t)\wedge(s+\widehat{d}_{s}>t)}\widehat{d}_{s}\] \[\leq\left(d_{\max}^{t}\right)^{2}=\frac{\mathcal{D}_{t}}{49K^{ \frac{2}{3}}\log K}\leq\mathcal{D}_{t},\]where the second inequality holds because \(\widehat{d}_{s}\leq d_{\max}^{t}\), and the total number of steps that satisfy \((s\leq t)\wedge(s+\widehat{d}_{s}>t)\) is less than the skipping threshold at time \(t\), which is again \(d_{\max}^{t}\). Rearranging the inequality completes the proof.

**Lemma 15** ((Orabona, 2022, Lemma 4.13)).: _Let \(a_{0}\geq 0\) and \(f:[0;+\infty)\to[0;+\infty)\) be a nonincreasing function. Then_

\[\sum_{t=1}^{T}a_{t}f\left(a_{0}+\sum_{i=1}^{t}a_{i}\right)\leq\int_{a_{0}}^{ \sum_{t=0}^{T}a_{t}}f(x)dx.\]

**Fact 16**.: _For any \(x\geq 0\), we have \(e^{-x}\leq\frac{1}{x}\)._

**Fact 17**.: _For any \(x\geq 1\), we have \(e^{-x}\leq\frac{1}{x\log^{2}(x)}\)._

Proof of Lemma 4.: We have two summations as

\[\sum_{t=1}^{T}e^{-\frac{\mathcal{D}_{t+\widehat{d}_{t}}}{\mathcal{D}_{t+ \widehat{d}_{t}}-\mathcal{D}_{t}}}+\sum_{t=1}^{T}e^{-\frac{\mathcal{D}_{t+ \widehat{d}_{t}}}{\mathcal{D}_{t+\widehat{d}_{t}}+\widehat{d}_{t}}},\]

where we show an upper bound of \(\mathcal{O}(\widehat{\sigma}_{\max})\) for each of them.

**Bounding the First Summation:** Let \(T_{0}\) be the time satisfying \(\sqrt{\mathcal{D}_{T_{0}}}=\frac{\widehat{\sigma}_{\max}}{K^{1/3}\log(K)}\), then using Facts 16 and 17 we have

\[\sum_{t=1}^{T}e^{-\frac{\mathcal{D}_{t+\widehat{d}_{t}}}{\mathcal{D}_{t+ \widehat{d}_{t}}-\mathcal{D}_{t}}}\leq\underbrace{\sum_{t=1}^{T_{0}}\frac{ \mathcal{D}_{t+\widehat{d}_{t}}-\mathcal{D}_{t}}{\mathcal{D}_{t+\widehat{d}_{ t}}}}_{\mathcal{A}}+\underbrace{\sum_{t=T_{0}+1}^{T}\frac{\mathcal{D}_{t+ \widehat{d}_{t}}-\mathcal{D}_{t}}{\mathcal{D}_{t+\widehat{d}_{t}}\log^{2}\left( \frac{\mathcal{D}_{t+\widehat{d}_{t}}}{\mathcal{D}_{t+\widehat{d}_{t}}- \mathcal{D}_{t}}\right)}}_{B}.\]

For \(A\) we give the following bound

\[A=\sum_{t=1}^{T_{0}}\sum_{s=t+1}^{t+\widehat{d}_{t}}\frac{ \widehat{\sigma}_{s}}{\mathcal{D}_{t+\widehat{d}_{t}}} =\sum_{s=1}^{T_{0}}\sum_{t=0}^{s-1}\frac{\widehat{\sigma}_{s} \mathds{1}(t+\widehat{d}_{t}\geq s)}{\mathcal{D}_{t+\widehat{d}_{t}}}\] \[\leq\sum_{s=1}^{T_{0}}\frac{\widehat{\sigma}_{s}^{2}}{\mathcal{D} _{s}}\] \[\leq\sum_{s=1}^{T_{0}}\frac{\widehat{\sigma}_{s}\sqrt{\mathcal{D} _{s}}}{K^{1/3}\log(K)\mathcal{D}_{s}}\] \[=\sum_{s=1}^{T_{0}}\frac{\widehat{\sigma}_{s}}{K^{1/3}\log(K) \sqrt{\mathcal{D}_{s}}}\] \[\leq\mathcal{O}\left(\frac{\sqrt{D_{T_{0}}}}{K^{1/3}\log(K)} \right)=\mathcal{O}\left(\frac{\widehat{\sigma}_{\max}}{K^{2/3}\log^{2}(K)} \right),\]

where the second equality is by swapping the summations, the first inequality holds because \(\mathcal{D}_{t+\widehat{d}_{t}}\geq\mathcal{D}_{s}\), the third inequality uses \(\widehat{\sigma}_{s}\leq d_{\max}^{s}\leq\frac{\sqrt{\mathcal{D}_{s}^{*}}}{K^ {1/3}\log K}\), and the last inequality uses Lemma 15.

The bound for \(B\) is as follows

\[B=\sum_{t=T_{0}+1}^{T}\sum_{s=t+1}^{t+\widehat{d_{t}}}\frac{\widehat {\sigma}_{s}}{\mathcal{D}_{t+\widehat{d_{t}}}\log^{2}\left(\frac{\mathcal{D}_{t +\widehat{d_{t}}}}{\mathcal{D}_{t+\widehat{d_{t}}}-\mathcal{D}_{t}}\right)} \leq\sum_{t=T_{0}+1}^{T}\sum_{s=t+1}^{t+\widehat{d_{t}}}\frac{ \widehat{\sigma}_{s}}{\mathcal{D}_{t+\widehat{d_{t}}}\log^{2}\left(\frac{7K^{1 /3}\log(K)\mathcal{D}_{t+\widehat{d_{t}}}}{\widehat{\sigma}_{\max}\sqrt{ \mathcal{D}_{t+\widehat{d_{t}}}}}\right)}\] \[=\sum_{s=T_{0}+1}^{T}\sum_{t=T_{0}+1}^{s-1}\frac{\widehat{\sigma} _{s}\mathds{1}(t+\widehat{d_{t}}\geq s)}{\mathcal{D}_{t+\widehat{d_{t}}}\log^ {2}\left(\frac{49K^{2/3}\log^{2}(K)\mathcal{D}_{t+\widehat{d_{t}}}}{\widehat{ \sigma}_{\max}^{2}}\right)}\] \[\leq\sum_{s=T_{0}+1}^{T}\frac{\widehat{\sigma}_{s}^{2}}{4 \mathcal{D}_{s}\log^{2}\left(49K^{2/3}\log^{2}(K)\frac{\mathcal{D}_{s}}{ \widehat{\sigma}_{\max}^{2}}\right)}\] \[\leq\widehat{\sigma}_{\max}\sum_{s=T_{0}+1}^{T}\frac{\widehat{ \sigma}_{s}}{4\mathcal{D}_{s}\log^{2}\left(\frac{49K^{2/3}\log^{2}(K)\mathcal{ D}_{s}}{\widehat{\sigma}_{\max}^{2}}\right)}\] \[\leq\widehat{\sigma}_{\max}\int_{\mathcal{D}_{T_{0}}}^{\mathcal{D }_{T}}\frac{1}{4x\log^{2}(\frac{49K^{2/3}\log^{2}(K)x}{\widehat{\sigma}_{\max }^{2}})}\] \[=\widehat{\sigma}_{\max}\frac{-1}{4\log(\frac{49K^{2/3}\log^{2}( K)x}{\widehat{\sigma}_{\max}^{2}})}\bigg{|}_{\mathcal{D}_{T_{0}}}^{\mathcal{D}_{T}}= \mathcal{O}(\widehat{\sigma}_{\max}),\]

where the first inequality follows by \(\widehat{\sigma}_{s}\leq\widehat{\sigma}_{\max}\) and our skipping procedure that ensures \(\widehat{d_{t}}\leq d_{\max}^{t}\leq\frac{\sqrt{\mathcal{D}_{t+\widehat{d_{t} }}}}{K^{1/3}\log K}\), the second equality is by swapping the summations, the second inequality follows by \(\mathcal{D}_{t+\widehat{d_{t}}}\geq\mathcal{D}_{s}\) and \(\sum_{t=1}^{s-1}\mathds{1}(t+\widehat{d_{t}}\geq s)=\widehat{\sigma}_{s}\), the last inequality follows by Lemma 15, and the last equality uses \(\int\frac{1}{x\log^{2}(x/\widehat{\sigma}_{\max}^{2})}dx=\frac{-1}{\log(x/ \widehat{\sigma}_{\max}^{2})}\).

**Bound the Second Summation:** The bound for the second summation follows the same approach, but it requires additional care due to existence of \(\sigma_{\max}^{t}\) in it. Let \(T_{0}\) to be the time satisfying \(\sqrt{\mathcal{D}_{T_{0}}}=\frac{\widehat{\sigma}_{\max}}{K^{1/3}\log(K)}\), then using Facts 16 and 17 we have

\[\sum_{t=1}^{T}e^{-\frac{\mathcal{D}_{t+\sigma_{\max}^{t}+\widehat{d_{t}}}}{ \mathcal{D}_{t+\widehat{\sigma}_{\max}^{2}+\widehat{d_{t}}}-\mathcal{D}_{t}}} \leq\underbrace{\sum_{t=1}^{T_{0}}\frac{\mathcal{D}_{t+\sigma_{\max}^{t}+ \widehat{d_{t}}}-\mathcal{D}_{t}}{\mathcal{D}_{t+\sigma_{\max}^{t}+\widehat{d _{t}}}}}_{B}+\underbrace{\sum_{t=T_{0}+1}^{T}\frac{\mathcal{D}_{t+\sigma_{ \max}^{t}+\widehat{d_{t}}}-\mathcal{D}_{t}}{\mathcal{D}_{t+\sigma_{\max}^{t}+ \widehat{d_{t}}}\log^{2}\left(\frac{\mathcal{D}_{t+\sigma_{\max}^{t}+\widehat{ d_{t}}}}{\mathcal{D}_{t+\sigma_{\max}^{t}+\widehat{d_{t}}}-\mathcal{D}_{t}} \right)}}_{B}.\]

For \(A\) we give the following bound \[A=\sum_{t=1}^{T_{0}}e^{-\frac{\mathcal{D}_{t+\sigma_{\max}^{t}+ \widehat{d}_{t}}}{\mathcal{D}_{t+\sigma_{\max}^{t}+\widehat{d}_{t}-\mathcal{D}_ {t}}}} \leq\sum_{t=1}^{T_{0}}\frac{\mathcal{D}_{t+\sigma_{\max}^{t}+ \widehat{d}_{t}}-\mathcal{D}_{t}}{\mathcal{D}_{t+\sigma_{\max}^{t}+\widehat{d} _{t}}}\] \[=\sum_{t=1}^{T_{0}}\sum_{s=t+1}^{t+\sigma_{\max}^{t}+\widehat{d} _{t}}\frac{\widehat{\sigma}_{s}}{\mathcal{D}_{t+\sigma_{\max}^{t}+\widehat{d} _{t}}}\] \[\leq\sum_{s=1}^{T_{0}}\sum_{t=0}^{s-1}\frac{\widehat{\sigma}_{s} \mathds{1}(t+\sigma_{\max}^{t}+\widehat{d}_{t}\geq s)}{\mathcal{D}_{s}}\] \[\leq\sum_{s=1}^{T_{0}}\frac{(2\sigma_{\max}^{s}+\widehat{\sigma} _{s-\sigma_{\max}^{s}})\widehat{\sigma}_{s}}{\mathcal{D}_{s}}\] \[\leq\sum_{s=1}^{T_{0}}\frac{3\sqrt{\mathcal{D}_{s}}\widehat{ \sigma}_{s}}{K^{1/3}\log(K)\mathcal{D}_{s}}\] \[=\sum_{s=1}^{T_{0}}\frac{3\widehat{\sigma}_{s}}{K^{1/3}\log(K) \sqrt{\mathcal{D}_{s}}}\] \[\leq\mathcal{O}\left(\frac{\sqrt{\mathcal{D}_{T_{0}}}}{K^{1/3} \log(K)}\right)=\mathcal{O}(\frac{\widehat{\sigma}_{\max}}{K^{2/3}\log^{2}(K)}),\]

where the first inequality is by Fact 16, the second inequality holds by swapping the summations and that \(\mathcal{D}_{t+\sigma_{\max}^{t}+\widehat{d}_{t}}\geq\mathcal{D}_{s}\), third inequality use the following derivation

\[\mathds{1}(t+\sigma_{\max}^{t}+\widehat{d}_{t}\geq s) \leq\mathds{1}(t+\widehat{d}_{t}\geq s)+\mathds{1}(s>t+\widehat{d }_{t}\geq s-\sigma_{\max}^{t})\] (34) \[\leq\mathds{1}(t+\widehat{d}_{t}\geq s)+\mathds{1}(t\in[s-\sigma _{\max}^{t},s-1])+\mathds{1}(t<s-\sigma_{\max}^{t}\wedge t+\widehat{d}_{t} \geq s-\sigma_{\max}^{t}),\]

the third equality is by swapping the summations, the third inequality uses \(\widehat{\sigma}_{s}\leq d_{\max}^{s}\leq\frac{\sqrt{\mathcal{D}_{s}}}{K^{1/3} \log K}\), and finally the last inequality uses Lemma 15.

The bound for \(B\) is as follows

\[B =\sum_{t=T_{0}+1}^{T}\frac{\sum_{s=t+1}^{t+\sigma_{\max}^{t}+\widehat {d}_{t}}\widehat{\sigma}_{s}}{\mathcal{D}_{t+\sigma_{\max}^{t}+\widehat{d}_{t}} \log^{2}\left(\frac{T_{t+\sigma_{\max}^{t}+\widehat{d}_{t}}}{\sum_{s=t+1}^{t+ \sigma_{\max}^{t}+\widehat{d}_{t}}\widehat{\sigma}_{s}}\right)}\] \[\leq\sum_{t=T_{0}+1}^{T}\sum_{s=t+1}^{t+\sigma_{\max}^{t}+\widehat {d}_{t}}\frac{\widehat{\sigma}_{s}}{\mathcal{D}_{t+\sigma_{\max}^{t}+\widehat {d}_{t}}\log^{2}\left(\frac{7K^{1/3}\log(K)\mathcal{D}_{t+\sigma_{\max}^{t}+ \widehat{d}_{t}}}{2\widehat{\sigma}_{\max}\sqrt{\mathcal{D}_{t+\sigma_{\max}^{t }+\widehat{d}_{t}}}}\right)}\] \[=\sum_{s=T_{0}+1}^{T}\sum_{t=T_{0}+1}^{s-1}\frac{\widehat{\sigma }_{s}\mathds{1}(t+\sigma_{\max}^{t}+\widehat{d}_{t}\geq s)}{\mathcal{D}_{t+ \sigma_{\max}^{t}+\widehat{d}_{t}}\log^{2}\left(\frac{3K^{1/3}\log(K)\widehat {\mathcal{D}_{t+\sigma_{\max}^{t}+\widehat{d}_{t}}}}{\widehat{\sigma}_{\max}^ {t}}\right)}\] \[=\sum_{s=T_{0}+1}^{T}\sum_{t=T_{0}+1}^{s-1}\frac{4\widehat{\sigma }_{s}\mathds{1}(t+\sigma_{\max}^{t}+\widehat{d}_{t}\geq s)}{\mathcal{D}_{t+ \sigma_{\max}^{t}+\widehat{d}_{t}}\log^{2}\left(\frac{9K^{2/3}\log^{2}(K) \mathcal{D}_{t+\sigma_{\max}^{t}+\widehat{d}_{t}}}{\widehat{\sigma}_{\max}^{t }}\right)}\] \[\leq\sum_{s=T_{0}+1}^{T}\frac{4(2\sigma_{\max}^{s}+\widehat{\sigma }_{s-\sigma_{\max}^{s}})\widehat{\sigma}_{s}}{\mathcal{D}_{s}\log^{2}\left( \frac{\mathcal{D}_{s}}{4\widehat{\sigma}_{\max}^{t}}\right)}\] \[\leq\widehat{\sigma}_{\max}\sum_{s=T_{0}+1}^{T}\frac{12\widehat{ \sigma}_{s}}{\mathcal{D}_{s}\log^{2}\left(\frac{9K^{2/3}\log^{2}(K)\mathcal{D} _{s}}{\widehat{\sigma}_{\max}^{t}}\right)}\] \[\leq\widehat{\sigma}_{\max}\int_{\mathcal{D}_{T_{0}}}^{\mathcal{D }_{T}}\frac{12}{x\log^{2}(\frac{9K^{2/3}\log^{2}(K)x}{\widehat{\sigma}_{\max} ^{2}})}\] \[=\widehat{\sigma}_{\max}\frac{-12}{\log(\frac{9K^{2/3}\log^{2}(K) x}{\widehat{\sigma}_{\max}^{2}})}\Big{|}_{\mathcal{D}_{T_{0}}}^{\mathcal{D}_{T}}= \mathcal{O}(\widehat{\sigma}_{\max}),\]

where the first inequality is due to our skipping procedure that ensures \(\max\left\{\sigma_{\max}^{t},\widehat{d}_{t}\right\}\leq d_{\max}^{t}\leq \sqrt{\mathcal{D}_{t+\sigma_{\max}^{t}+\widehat{d}_{t}}}\), the second equality is by swapping the summations, the second inequality follows by \(\mathcal{D}_{t+\widehat{d}_{t}}\geq\mathcal{D}_{s}\) and (34), the last inequality follows by Lemma 15, and the last equality uses \(\int\frac{1}{x\log^{2}(x/\widehat{\sigma}_{\max}^{2})}dx=\frac{-1}{\log(x/ \widehat{\sigma}_{\max}^{2})}\). 

## Appendix E A proof of Lemma 5

Proof.: We use the term _free round_ to refer to a round \(r\) such that \(\upsilon_{r}^{new}\) is zero. By applying induction on the time step \(t\), we show that if the algorithm is currently at time \(t\) and intends to rearrange the \(\upsilon_{t}\) arrivals, there exist \(\upsilon_{t}\) free rounds in the interval \([t,t+\sigma_{\max}^{t}-\widehat{\sigma}_{t}+\upsilon_{t}]\) to which the algorithm can push the arrivals. This ensures that the arrival from round \(s\), will be rearranged to round \(\pi(s)\geq s+\widehat{d}_{s}\), such that \(\pi(s)-(s+\widehat{d}_{s})\leq\sigma_{\max}^{t}\). To this end, we assume the induction assumption holds for all \(r<t\), and then proceed with induction step for \(t\).

**Induction Base:**

The induction base corresponds to the first arrival time, denoted as \(t_{0}\). At this time step, all \(\upsilon_{t_{0}}\) arrivals can be rearranged to the free rounds in the interval \([t_{0},t_{0}+\upsilon_{t_{0}}-1]\), which is a subset of \([t_{0},t_{0}+\sigma_{\max}^{t_{0}}-\widehat{\sigma}_{t_{0}}+\upsilon_{t_{0}}-1]\). Therefore, the induction base holds.

**Induction step:**

Assume that we are at round \(t\), and our aim is to rearrange the arrivals of round \(t\). We define \(t_{1}\) as the last occupied round, where \(t_{1}\geq t\). So it suffices to prove \(t_{1}-t\leq\sigma_{\max}^{t}-\widehat{\sigma}_{t}\). We first note that since the algorithm is greedy, all rounds \(t,t+1,\ldots,t_{1}-1\) must also be occupied by some arrivals from the past.

Let \(t_{0}<t\) be the first round where one of its arrivals has been rearranged to \(t\), and let \(v^{{}^{\prime}}_{t_{0}}\) be the number of arrivals at time \(t_{0}\) that are rearranged to some rounds before \(t\). Then by induction assumption we know

\[t-t_{0}\leq\sigma^{t_{0}}_{\max}-\widehat{\sigma}_{t_{0}}+v^{{}^{\prime}}_{t_{0 }}+1=\sigma^{t_{0}}_{\max}-\sum_{r=1}^{t_{0}-1}\mathds{1}(r+\widehat{d}_{r}\geq t _{0})+v^{{}^{\prime}}_{t_{0}}+1.\] (35)

On the other hand, by the choice of \(t_{0}\), each occupied round \(t,t+1,\ldots,t_{1}\) must be occupied by exactly one arrival among the arrivals of rounds \(t_{0},\ldots,t-1\), except for the \(v^{{}^{\prime}}_{t}\) arrivals of \(t_{0}\) that are rearranged to some rounds before \(t\). So we have

\[t_{1}-t+1 \leq\sum_{r=1}^{t-1}\mathds{1}(t_{0}\leq r+\widehat{d}_{r}\leq t -1)-v^{{}^{\prime}}_{t_{0}}\] \[=\sum_{r=1}^{t_{0}-1}\mathds{1}(t_{0}\leq r+\widehat{d}_{r}\leq t -1)+\sum_{r=t_{0}}^{t-1}\mathds{1}(t_{0}\leq r+\widehat{d}_{r}\leq t-1)-v^{{} ^{\prime}}_{t_{0}}\] \[=\sum_{r=1}^{t_{0}-1}\mathds{1}(t_{0}\leq r+\widehat{d}_{r}\leq t -1)+t-t_{0}-\sum_{r=t_{0}}^{t-1}\mathds{1}(r+\widehat{d}_{r}\geq t)-v^{{}^{ \prime}}_{t_{0}},\]

where the second equality holds because \(\sum_{r=t_{0}}^{t-1}\mathds{1}(r+\widehat{d}_{r}\geq t_{0})=t-t_{0}\). We use (35) to bound \(t-t_{0}\) in the above inequality and get

\[t_{1}-t \leq\sigma^{t_{0}}_{\max}+\sum_{r=1}^{t_{0}-1}\mathds{1}(t_{0} \leq r+\widehat{d}_{r}\leq t-1)-\sum_{r=1}^{t_{0}-1}\mathds{1}(r+\widehat{d}_ {r}\geq t_{0})-\sum_{r=t_{0}}^{t-1}\mathds{1}(r+\widehat{d}_{r}\geq t)\] \[=\sigma^{t_{0}}_{\max}-\sum_{r=1}^{t_{0}-1}\mathds{1}(r+\widehat{d }_{r}\geq t)-\sum_{r=t_{0}}^{t-1}\mathds{1}(r+\widehat{d}_{r}\geq t)\] \[=\sigma^{t_{0}}_{\max}-\sum_{r=1}^{t-1}\mathds{1}(r+\widehat{d}_{ r}\geq t)\leq\sigma^{t}_{\max}-\widehat{\sigma}_{t},\] (36)

where the last inequality follows by the fact that \(\{\sigma^{r}_{\max}\}_{r\in[T]}\) is a non-decreasing sequence. So if the algorithm rearranges the \(v_{t}\) arrivals at round \(t\) to rounds \(t_{1}+1,\ldots,t_{1}+v_{t}\), then, using the inequality (36), we can conclude that these rounds fall within the interval \([t,t+\sigma^{t}_{\max}-\widehat{\sigma}_{t}+v_{t}]\). 

## Appendix F Adversarial bounds with \(d_{\max}\) cannot benefit from skipping

In this section we show that adversarial regret bounds that involve terms that are linear in \(d_{\max}\), such as the bounds of Masoudian et al. (2022), cannot benefit from skipping. We prove the following lemma.

**Lemma 18**.: \[\sqrt{D}\leq\min_{\bar{\mathcal{S}}}\left(|\mathcal{S}|+\sqrt{D_{\bar{ \mathcal{S}}}}\right)+d_{\max}.\]

Proof.: For any split of the rounds \([T]\) into \(\mathcal{S}\) and \(\bar{\mathcal{S}}\) we have

\[D=D_{\bar{\mathcal{S}}}+D_{\mathcal{S}}\leq D_{\bar{\mathcal{S}}}+|\mathcal{S} |d_{\max}\leq D_{\bar{\mathcal{S}}}+|\mathcal{S}|^{2}+d_{\max}^{2}.\]

Thus

\[\sqrt{D}\leq\sqrt{D_{\bar{\mathcal{S}}}+|\mathcal{S}|^{2}+d_{\max}^{2}}\leq| \mathcal{S}|+\sqrt{D_{\bar{\mathcal{S}}}}+d_{\max},\]

and since the above holds for any \(\bar{\mathcal{S}}\), we obtain the statement of the lemma. 

We remind that skipping allows to replace a term of order \(\sqrt{D}\) by a term of order \(\min_{\bar{\mathcal{S}}}\left(|\mathcal{S}|+\sqrt{D_{\bar{\mathcal{S}}}}\right)\) (for simplicity we ignore factors dependent on \(K\)). Thus, it may potentially replace a bound of order \(\sqrt{D}+d_{\max}\) by a bound of order \(\min_{\bar{\mathcal{S}}}\left(|\mathcal{S}|+\sqrt{D_{\bar{\mathcal{S}}}} \right)+d_{\max}\), but since by the lemma \(\min_{\bar{\mathcal{S}}}\left(|\mathcal{S}|+\sqrt{D_{\bar{\mathcal{S}}}} \right)+d_{\max}=\Omega(\sqrt{D})\), this would not improve the order of the bound.

Details of the Adversarial Analysis

The only difference between our algorithm and the algorithm of Zimmert and Seldin (2020) is the implicit exploration and the slightly modified skipping rule. Let \(\ell_{t}\) be the original loss sequence, then the adversary can create an adaptive sequence \(\widetilde{\ell}_{t}\) that forces the player to play according to the implicit exploration rule by simply down-scaling all the losses by

\[\widetilde{\ell}_{ti}=\frac{x_{ti}\ell_{ti}}{\max\left\{x_{t,i},\lambda_{t,t+ \widehat{d}_{t}}\right\}}\,.\]

Our regret bound decomposes now into

\[\overline{Reg}_{T} =\max_{i_{T}^{*}}\mathbb{E}\left[\sum_{t=1}^{T}\left\langle x_{t},\ell_{t}\right\rangle-\ell_{t,i_{T}^{*}}\right]\] \[\leq\max_{i_{T}^{*}}\mathbb{E}\left[\sum_{t=1}^{T}\left\langle x_ {t},\widetilde{\ell}_{t}\right\rangle-\widetilde{\ell}_{t,i_{T}^{*}}\right]+ \mathbb{E}\left[\sum_{t=1}^{T}\left\langle x_{t},\ell_{t}-\widetilde{\ell}_{ t}\right\rangle\right]\,.\]

For the second term we have

\[\sum_{t=1}^{T}\left\langle x_{t},\ell_{t}-\widetilde{\ell}_{t}\right\rangle \leq\sum_{i=1}^{K}\sum_{t=1}^{T}(1-\frac{x_{ti}}{x_{ti}+\lambda_{t,t+ \widehat{d}_{t}}})x_{ti}\leq K\sum_{t=1}^{T}\lambda_{t,t+\widehat{d}_{t}}\,,\]

which can be controlled via Lemma 4.

The first term is bounded by Zimmert and Seldin (2020, Theorem 3) (since the player plays their algorithm on the modified loss sequence) by

\[\max_{i_{T}^{*}}\mathbb{E}\left[\sum_{t=1}^{T}\left\langle x_{t},\ell_{t}\right\rangle-\ell_{t,i_{T}^{*}}\right] \leq 4\sqrt{KT}+\sum_{t=1}^{T}\gamma_{t}\widehat{\sigma}_{t}+ \gamma_{T}^{-1}\log K+S^{*}\] \[\leq 4\sqrt{KT}+\sum_{t=1}^{T}\frac{\widehat{\sigma}_{t}\sqrt{ \mathcal{D}_{t}}}{7\sqrt{\mathcal{D}_{t}}}+7\sqrt{\mathcal{D}_{T}\log K}+S^{*}\] \[=4\sqrt{KT}+\sqrt{\log K}\sum_{t=1}^{T}\frac{\mathcal{D}_{t}- \mathcal{D}_{t-1}}{7\sqrt{\mathcal{D}_{t}}}+7\sqrt{\mathcal{D}_{T}\log K}+S^{*}\] \[\leq 4\sqrt{KT}+\frac{2\sqrt{\log K}}{7}\sum_{t=1}^{T}\sqrt{ \mathcal{D}_{t}}-\sqrt{D_{t-1}}+7\sqrt{\mathcal{D}_{T}\log K}+S^{*}\] \[=4\sqrt{KT}+\frac{51}{7}\sqrt{\mathcal{D}_{T}\log K}+S^{*}\] \[\leq 4\sqrt{KT}+\frac{51}{7}\min_{\mathcal{S}\subseteq[T]}\left\{ \left|\mathcal{S}\right|+\sqrt{\mathcal{D}_{\mathcal{S}}\log K}\right\}+S^{*},\]

where the first equality uses the definition of \(\gamma_{t}\), the third inequality follows by \(\forall a,b>0:\frac{a-b}{\sqrt{a}}\leq 2(\sqrt{a}-\sqrt{b})\), and the last inequality uses the following lemma

**Lemma 19**.: _The skipping technique guarantees the following bound_

\[\sqrt{\mathcal{D}_{T}K^{\frac{2}{3}}\log K}\leq\min_{\mathcal{S}\subseteq[T]} \left\{\left|\mathcal{S}\right|+\sqrt{\mathcal{D}_{\bar{S}}K^{\frac{2}{3}} \log K}\right\}.\]

Combining the bounds on the first and the second terms provides the regret bound in Section 5.2. It only remains to provide a proof for Lemma 19.

Proof of Lemma 19.: For any \(t\in[T]\) we have \(\widehat{d}_{t}\leq\sqrt{\mathcal{D}_{T}/(49K^{\frac{2}{3}}\log(K))}\), therefore for any \(R\subset[T]\):

\[\sum_{t\in[T]\setminus R}d_{t}\geq\sum_{t\in[T]\setminus R}\widehat{d}_{t} \geq\mathcal{D}_{T}-|R|\sqrt{\mathcal{D}_{T}/(49K^{\frac{2}{3}}\log(K))}\]Hence we can derive the following lower bound,

\[\min_{R\subseteq[T]}|R|+\sqrt{\sum_{s\in[T]\setminus R}d_{s}K^{\frac{2 }{3}}\log(K)} \geq\min_{r\in\left[0,\sqrt{49\mathcal{D}_{T}K^{\frac{2}{3}}\log(K)} \right]}r+\sqrt{\mathcal{D}_{T}K^{\frac{2}{3}}\log(K)-\frac{1}{7}r\sqrt{ \mathcal{D}_{T}K^{\frac{2}{3}}\log(K)}}\] \[\geq\sqrt{\mathcal{D}_{T}K^{\frac{2}{3}}\log(K)},\]

where the second inequality uses the concavity in \(r\).

## Appendix H A Bound on \(S^{*}\)

Next, we reason about the nature of skips. The following lemma is an adaptation of Zimmert and Seldin (2020, Lemma 5) to our skipping threshold. To this end we provide two lemmas and then conclude then proof.

**Lemma 20**.: _Algorithm 1 will not skip more than 1 point at a time._

Proof.: We prove the lemma by contradiction. Assume that \(s_{1},s_{2}\) are both deactivated at time \(t\). W.l.o.g. let \(s_{2}\leq s_{1}-1\). Skipping of \(s_{1}\) at time \(t\) means \(t-s_{1}\geq\sqrt{\mathcal{D}_{t}/(K^{\frac{2}{3}}\log(K))}\geq\sqrt{ \mathcal{D}_{t-1}/(K^{\frac{2}{3}}\log(K))}\). At the same time we assumed \(t-1-s_{2}\geq t-s_{1}\), which means that \(s_{2}\) would have been deactivated at round \(t-1\) or earlier. 

Recall that \(\widehat{d}_{t}\) is the contribution of a timestep \(t\) to the sum \(\mathcal{D}_{T}\). Let \((t_{1},\dots,t_{S^{*}})\) be an indexing of \(\mathcal{S}\) and \(c=49K^{\frac{2}{3}}\log(K)\). We bound the number of skips by

\[S^{*}\leq 2c\widehat{d}_{t_{5}^{*}}.\] (37)

The above bound together with the fact that incurred delay \(\widehat{d}_{t_{5}^{*}}\) must be less than the the skipping threshold and the maximal delay \(d_{\max}\) give us

\[S^{*} \leq\mathcal{O}\left(K^{\frac{2}{3}}\log K\widehat{d}_{t_{5}^{*}}\right)\] \[\leq\mathcal{O}\left(\min\left\{d_{\max}K^{\frac{2}{3}}\log K, \sqrt{\mathcal{D}_{T}K^{\frac{2}{3}}\log K}\right\}\right)\] \[\leq\mathcal{O}\left(\min\left\{d_{\max}K^{\frac{2}{3}}\log K, \min_{\mathcal{S}_{\subseteq[T]}^{\infty}}\left\{|\mathcal{S}|+\sqrt{ \mathcal{D}_{\bar{\mathcal{S}}}K^{\frac{2}{3}}\log K}\right\}\right\}\right),\]

where the last inequality follows by Lemma 19. 

Proof of bound (37).: By Lemma 20 we skip at most one outstanding observation per round. Thus, we have that

\[\widehat{d}_{t_{m}}\geq\sqrt{\mathcal{D}_{t_{m}+\widehat{d}_{t_{m}}}/c}\geq \sqrt{\sum_{i=1}^{m}\widehat{d}_{t_{i}}/c}=\frac{\sqrt{\widehat{d}_{t_{m}}+ \sum_{i=1}^{m-1}\widehat{d}_{t_{i}}}}{\sqrt{c}}\,.\]

By solving the quadratic inequality in \(\widehat{d}_{t_{m}}\) we obtain

\[\widehat{d}_{t_{m}}\geq\frac{1+\sqrt{1+4c\sum_{i=1}^{m-1}\widehat{d}_{t_{i}}} }{2c}\,.\]

Now we prove by induction that \(\widehat{d}_{t_{m}}\geq\frac{m}{2c}\). The induction base holds since \(\widehat{d}_{t_{1}}=1\). For the inductive step we have

\[\widehat{d}_{t_{m}}\geq\frac{1+\sqrt{1+4c\sum_{i=1}^{m-1}\widehat{d}_{t_{i}}} }{2c}\geq\frac{1+\sqrt{1+m(m-1)}}{2c}\geq\frac{m}{2c}\,.\]

Then the induction step is satisfied.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: We list all our contributions in the abstract and introduction, and included a 548 literature review in the introduction to reflect the scope Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We present all our bounds in Table 1 and discuss about the gap between our results and existing lower and upper bounds in the introduction section. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?Answer: [Yes] Justification: Theorems state their assumptions explicitly. Proofs are provided concisely within the main body, with full details in the appendix. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [NA] Justification: This work is based on theoretical analysis. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code**Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [NA] Justification: This work does not include experiments. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA] Justification: This work does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: This work does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)* The assumptions made should be given (e.g., Normally distributed errors).
* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: This work does not include experiments. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: We confirm that we adhere to ethical standards where applicable, and we note that no experiments were conducted as part of this research. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [NA] Justification: This paper focuses on theoretical foundations, and discussing potential societal impacts, positive or negative, is beyond its scope. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This paper poses no such risks. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: This paper does not use existing assets. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. * For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.

* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper does not involve research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.