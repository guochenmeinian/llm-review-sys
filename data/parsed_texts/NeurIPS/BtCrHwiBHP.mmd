# Fully Unconstrained Online Learning

 Ashok Cutkosky

Boston University

ashok@cutkosky.com

&Zakaria Mhammedi

Google Research

mhammedi@google.com

###### Abstract

We provide a technique for online convex optimization that obtains regret \(G\|w_{\star}\|\sqrt{T\log(\|w_{\star}\|G\sqrt{T})}+\|w_{\star}\|^{2}+G^{2}\) on \(G\)-Lipschitz losses for any comparison point \(w_{\star}\) without knowing either \(G\) or \(\|w_{\star}\|\). Importantly, this matches the optimal bound \(G\|w_{\star}\|\sqrt{T}\) available _with_ such knowledge (up to logarithmic factors), unless either \(\|w_{\star}\|\) or \(G\) is so large that even \(G\|w_{\star}\|\sqrt{T}\) is roughly linear in \(T\). Thus, at a high level it matches the optimal bound in all cases in which one can achieve sublinear regret.

## 1 Unconstrained Online Learning

This paper provides new algorithms for _online learning_, which is a standard framework for the design and analysis of iterative first-order optimization algorithms used throughout machine learning. Specifically, we consider a variant of online learning often called "online convex optimization" [1, 2]. Formally, an online learning algorithm is designed to play a kind of "game" between the learning algorithm and the environment, which we can describe using the following protocol:

**Protocol 1.** Online Learning/Online Convex Optimization.

**Input:** Convex domain \(\mathcal{W}\subseteq\mathbb{R}^{d}\), number of rounds \(T\).

For \(t=1,\ldots,T\):

1. Learner outputs \(w_{t}\in\mathcal{W}\).
2. Nature reveals loss vector \(g_{t}\in\partial\ell_{t}\) for some convex function \(\ell_{t}:\mathcal{W}\rightarrow\mathbb{R}\) to the learner.
3. Learner suffers loss \((g_{t},w_{t})\).

The learner is evaluated with the _regret_\(\sum_{t=1}^{T}(\ell_{t}(w_{t})-\ell_{t}(w_{\star}))\) against comparators \(w_{\star}\in\mathcal{W}\). By convexity, the regret is bounded by the _linearized_ regret \(\sum_{t=1}^{T}(g_{t},w_{t}-w_{\star})\). Our goal is to ensure that for all \(w_{\star}\in\mathcal{W}\) simultaneously:

\[\text{Regret}_{T}(w_{\star})\coloneqq\sum_{t=1}^{T}(g_{t},w_{t}-w_{\star}) \underset{\text{goal}}{\leq}\widetilde{\mathcal{O}}\left(\|w_{\star}\|\sqrt{ \sum_{t=1}^{T}g_{t}\|^{2}}\right). \tag{1}\]

Qualitatively, we consider a learner to be performing well if \(\frac{1}{T}\sum_{t=1}^{T}(\ell_{t}(w_{t})-\ell_{t}(w_{\star}))\) is very small, usually going to zero as \(T\rightarrow\infty\). This indicates that the average loss of the learner is close to the average loss of any chosen comparison point \(w_{\star}\in\mathcal{W}\). This property is called "sublinear regret". The bound (1) is unimprovable in general [3, 4, 5], and clearly implies sublinear regret.

Algorithms that achieve low regret are used in a variety of machine learning applications. Perhaps the most famous such application is in the analysis of stochastic gradient descent, which achieves (1) for appropriately tuned learning rate [6]. More generally, stochastic convex optimization can be reducedto online learning via the _online to batch conversion_[7]. Roughly speaking, this result says that an online learning algorithm that guarantees low regret can be immediately converted into a stochastic convex optimization algorithm that converges at a rate of \(\frac{\mathbb{E}[\mathrm{Regret}_{\tau}(w_{\star})]}{T}\), where \(w_{\star}\) is the minimizer of the objective. Online learning can also be used to solve non-convex optimization problems [8] and can even be used to prove concentration inequalities [9, 10, 11, 12]. In all of these cases, achieving the bound (1) produces methods that are optimal for their respective tasks. Thus, it is desirable to be able to achieve (1) in as robust a manner as possible.

Our goal is to come as close as possible to achieving the bound (1) while requiring minimal prior user knowledge about the loss sequence \(g_{1},\ldots,g_{t}\) and \(w_{\star}\). In the past, several prior works have achieved the bound (1) when given prior knowledge of either \(\left\|w_{\star}\right\|\) or \(\max_{t}\left\|g_{t}\right\|\)[13, 14, 15, 16, 17, 18, 19, 20, 21]. However, such knowledge is frequently unavailable. Instead, many problems are "fully unconstrained" in the sense that we do not have any reasonable upper bounds on either \(\left\|w_{\star}\right\|\) or \(\max_{t}\left\|g_{t}\right\|\). In particular, when considering the application to stochastic convex optimization, the values for \(\left\|w_{\star}\right\|\) and \(\max_{t}\left\|g_{t}\right\|\) can be interpreted as knowledge of the correct learning rate for stochastic gradient descent [6]. Thus, achieving the bound (1) with less prior knowledge roughly corresponds to building algorithms that are able to achieve optimal convergence guarantees without requiring manual hyperparameter tuning. For this reason, it is common to refer to such algorithms as "parameter-free". This paper focuses on this difficult but realistic setting.

Our new upper bound.Unfortunately, the bound (1) is actually unobtainable in general without prior knowledge of either the magnitude \(\left\|w_{\star}\right\|\) or the value of \(\max_{t}\left\|g_{t}\right\|\)[18, 22]. Nevertheless, we will obtain a new compromise bound. For any user-specified \(\gamma>0\), our method will achieve:

\[\sum_{t=1}^{T}(g_{t},w_{t}-w_{\star})\leq\widetilde{O}\left(\max_{t\in[T]} \left\|g_{t}\right\|^{2}/\gamma+\gamma\left\|w_{\star}\right\|^{2}+\left\|w_{ \star}\right\|\sqrt{\sum_{t=1}^{T}\left\|g_{t}\right\|^{2}}\right). \tag{2}\]

To dissect this compromise, let us consider the case \(\left\|g_{t}\right\|=G\) for all \(t\) and \(\gamma=1\). In this situation, our bound (2) is roughly \(G^{2}+\left\|w_{\star}\right\|^{2}+\left\|w_{\star}\right\|G\sqrt{T}\), while the "ideal" bound (1) is merely \(\left\|w_{\star}\right\|G\sqrt{T}\). However, for our bound to be significantly worse than (1), we must have either \(G\geq\left\|w_{\star}\right\|\sqrt{T}\) or \(\left\|w_{\star}\right\|\geq G\sqrt{T}\). In either case, we might expect that \(\left\|w_{\star}\right\|G\sqrt{T}\) is roughly \(\Omega(T)\) (assuming that neither \(G\) nor \(\left\|w_{\star}\right\|\) is very small). So, intuitively the only cases in which our bound is worse than the ideal bound are those for which the ideal bound is already rather large--the problem is in some sense "too hard".

Comparison with previous boundsOur bound (2) is not the first attempted compromise in our fully unconstrained setting. Prior work [18, 23] instead provides the bound:

\[\sum_{t=1}^{T}(g_{t},w_{t}-w_{\star})\leq\widetilde{O}\left(\frac{1}{\gamma} \sqrt{\max_{t^{\prime}\in[T]}\left\|g_{t^{\prime}}\right\|\cdot\frac{T}{t=1} \left\|g_{t}\right\|+\gamma^{2}\max_{t\in[T]}\left\|g_{t}\right\|\left\|w_{ \star}\right\|^{3}+\left\|w_{\star}\right\|\sqrt{\sum_{t=1}^{T}\left\|g_{t} \right"second-order" bound and is known to imply _constant_ regret in certain settings [1; 24] (so-called "fast rates").
4. Consider the case that both bounds are tuned with their respective "optimal" values for \(\gamma\). Our new bound would then reduce to \(\tilde{O}\left(\|w_{\star}\|\sqrt{\sum_{t=1}^{T}\|g_{t}\|^{2}}+\|w_{\star}\|G\right)\), while the previous bound would instead become \(\tilde{O}\left(\|w_{\star}\|\sqrt{\sum_{t=1}^{T}\|g_{t}\|^{2}}+\|w_{\star}\|G^ {2/3}\left(\sum_{t=1}^{T}\|g_{t}\|\right)^{1/3}\right)\). Thus, our new bound appears more desirable even with individually optimal tuning.
5. Our bound ensures that when \(w_{\star}=0\), the dependence on \(T\) is \(O(1)\). This has a number of useful consequences. For example, by running a separate instance of our algorithm for each dimension of a \(d\)-dimensional problem, we can achieve: Attempting this with the bound (3) would incur a more significant dependence on the dimension \(d\). More generally, this property means that our bound fits into the framework for "combining" regret bounds of [25].

## 2 Notation

Throughout this paper, we use \(\mathcal{W}\) to refer to a convex domain contained in \(\mathbb{R}^{d}\). Our results can in fact be extended to Banach spaces relatively easily using the reduction techniques of [16], but we focus on \(\mathbb{R}^{d}\) here to keep things more familiar. We use \(\|\cdot\|\) to indicate the Euclidean norm. Occasionally we also make use of other norms--these will always be indicated by some subscript (e.g. \(\|\cdot\|_{t}\)). We use \(\mathbb{R}_{\geq 0}\) to indicate the set of non-negative reals. For a convex function \(F\) over \(\mathbb{R}^{d}\), the Fenchel conjugate of \(F\) is \(F^{\star}(\theta)=\sup_{x\in\mathbb{R}^{d}}(\theta,x)-F(x)\). We occasionally make use of a "compressed sum" notation: \(g_{\alpha\geq}\coloneqq\sum_{t=a}^{b}g_{t}\). We use \(O\) to hide constant factors and \(\tilde{O}\) to hide both constant and logarithmic factors. All proofs not present in the main paper may be found in the appendix.

We will refer to the values \(g_{t}\) provided to an online learning algorithm interchangeably as "gradients", "feedback" and "loss" values. We will refer to online learning algorithms occasionally as either "learners" or just "algorithms".

## 3 Overview of Approach

Our overall approach to achieve (2) is a sequence of reductions. As a first step, we observe that it suffices to achieve our goal in the special case \(\mathcal{W}=\mathbb{R}\). Specifically, [16] Theorems 2 and 3 reduce the general \(\mathcal{W}\) case to \(\mathcal{W}=\mathbb{R}\) case. We provide an explicit description of how to apply these reductions in Section C. So, we focus our analysis on the case \(\mathcal{W}=\mathbb{R}\). Next, we reduce the problem to a variant of the online learning protocol in which we also must contend with some potentially non-Lipschitz regularization function (Section 3.1). Finally, we show how to achieve low regret in this special regularized setting (Section 3.3).

### Hints and Regularization

Our bound is achieved via a reduction to a variant of Protocol 1 with two changes. First, the learner is provided with prior access to _magnitude hints_\(h_{t}\in\mathbb{R}\) that satisfy \(\|g_{t}\|\leq h_{t}\). This notion of magnitude hints is also a key ingredient in the previous bound (3). Our second change is that the loss is not only the linear loss \((g_{t},w)\), but a _regularized_ non-linear loss \((g_{t},w)+a_{t}\psi(w)\) for some fixed function \(\psi:\mathcal{W}\to\mathbb{R}_{\geq 0}\) that we call a "regularizer". Formally, this protocol variant is specified in Protocol 2.

**Protocol 2**.: Regularized Online Learning with Magnitude Hints.

**Input:** Convex function \(\psi:\mathcal{W}\rightarrow\mathbb{R}_{\geq 0}\).

For \(t=1,\ldots,T\):

1. Nature reveals magnitude hint \(h_{t}\geq h_{t-1}\geq 0\) to the learner.
2. Learner outputs \(w_{t}\in\mathcal{W}\).
3. Nature reveals loss \(\tilde{g}_{t}\) with \(\|\tilde{g}_{t}\|\leq h_{t}\) and \(a_{t}\in[0,\gamma]\) to the learner.
4. Learner suffers loss \((\tilde{g}_{t},w_{t})+a_{t}\psi(w_{t})\).

The learner is evaluated with the _regularized regret_\(\sum_{t=1}^{T}(\tilde{g}_{t},w_{t}-w_{\star})+a_{t}\psi(w_{t})-a_{t}\psi(w_{ \star})\). The goal is to obtain:

\[\sum_{t=1}^{T}(\tilde{g}_{t},w_{t}-w_{\star})+a_{t}\psi(w_{t})-a_{t}\psi(w_{ \star})\underset{\text{goal}}{\leq}\widetilde{\mathcal{O}}\left(\|w_{\star}\| \sqrt{h_{T}^{2}+\sum_{t=1}^{T}\|\tilde{g}_{t}\|^{2}+\psi(w_{\star})\sqrt{ \gamma^{2}+\sum_{t=1}^{T}a_{t}^{2}}}\right). \tag{4}\]

In the special case that \(\psi(w)=0\) (i.e. the \(a_{t}\) are irrelevant, or all \(0\)), then various algorithms achieving the desired bound (4) are available in the literature [18, 21, 23, 26]. We provide in Algorithm 3 a new algorithm for this situation that achieves the optimal logarithmic factors--there is in fact a pareto-frontier of incomparable bounds that differ in the logarithmic factors. [26] provides the first algorithm to reach this frontier, while our method can achieve all points on the frontier1. We include this result because it is of some independent interest, but it not the major focus of our contributions. Any of the prior work in this area would roughly suffice for our broader purposes; the difference is only in the logarithmic terms.

Footnote 1: It is likely that the approach of [26] in concert with the varying potentials of [20] would achieve all points on the frontier as well, although our analysis takes a different direction using the centered mirror descent method of [21].

Challenge of achieving (4).Achieving the bound (4) is challenging when \(\|w_{\star}\|\) is not known ahead of time. To see why, let us briefly consider two potential solutions.

The most immediate approach might be to reduce Protocol 2 to the case in which \(a_{t}=0\) for all \(t\) by replacing \(\tilde{g}_{t}\) with \(\tilde{g}_{t}+a_{t}\nabla\psi(w_{t})\), and then possibly modifying the magnitude hint \(h_{t}\) in some way to now be a bound on \(|\tilde{g}_{t}\|\). However, this approach is problematic because the expected bound would now depend on \(\sum_{t=1}^{T}\|\tilde{g}_{t}+a_{t}\nabla\psi(w_{t})\|^{2}\) rather than \(\sum_{t=1}^{T}\|\tilde{g}_{t}\|^{2}\) and \(\sum_{t=1}^{T}a_{t}^{2}\). This means that the naive regret bound would be very hard to interpret as \(w_{t}\) would appear on both the left and right hand sides of the inequality.

Another possibility is a follow-the-regularized leader/potential-based algorithm, making updates:

\[w_{t+1}=\operatorname*{argmin}_{w\in\mathcal{W}}P_{t}(w)+\sum_{i=1}^{t}(\tilde {g}_{i},w)+a_{i}\psi(w), \tag{5}\]

for some sequence of "potential functions" \(P_{t}:\mathcal{W}\rightarrow\mathbb{R}\). In fact, this approach can be very effective; this is roughly the method employed by [27] for a similar problem. However, deriving the correct potential \(P_{t}\) and proving the desired regret bound can be very difficult, and could easily require separate analysis for each different possible \(\psi\) function. For example, [27]'s analysis specifically applies to \(\psi(w)=\|w\|^{2}\). There is other work on similar protocols using approximately this method, such as [28, 29], that also requires particular analysis for each setting. Finally, even if the bound can be achieved in general using this scheme, solving the optimization problem (5) may incur some undesirable computational overhead, even for intuitively "simple" regularizers such as \(\psi(w)=\|w\|^{2}\). In fact, the method of [27] suffers from exactly this issue, which is why we provide an alternative approach in Section 3.3, for the special case of interest that \(\mathcal{W}=\mathbb{R}\).

Re-parametrizing to achieve (4).In order to achieve the bound (4) in the special case \(\mathcal{W}=\mathbb{R}\), we will employ a standard trick in convex optimization: re-parametrizing the objective as a convex constraint using the fact that the epigraph of a convex function is convex. Instead of having our learner output \(w_{t}\in\mathcal{W}\), we will output \((x_{t},y_{t})\in\mathcal{W}\times\mathbb{R}\), but subject to the constraint that \(y_{t}\geq\psi(x_{t})\). We provide details of this approach in Section 3.3.

With all of these technicalities introduced, we are ready to provide an outline of our method. The key idea is to show that for a very peculiar choice of coefficients \(a_{1},\ldots,a_{T}\) and some simple clipping of the gradients \(g_{t}\), we are able to achieve the following result.

**Theorem 1**.: _There exists an online learning algorithm that requires \(O(d)\) space and takes \(O(d)\) time per update, takes as input scalar values \(\gamma\), \(h_{1}\), and \(\epsilon\) and ensures that for any sequence \(g_{1},g_{2},\cdots\subset\mathbb{R}^{d}\), the outputs \(w_{1},w_{1},\cdots\subset\mathbb{R}^{d}\) satisfy for all \(w_{\star}\) and \(T\):_

\[\sum_{t=1}^{T} \big{(}g_{t},w_{t}-w_{\star}\big{)}\leq O\left[\epsilon G+\epsilon ^{2}\gamma+\frac{G^{2}}{\gamma}\log\left(e+\frac{G}{h_{1}}\right)+\|w_{\star} \|\sqrt{V\log\left(e+\frac{|w_{\star}|\sqrt{V}\log^{2}(T)}{h_{1}\epsilon}\right) }\right.\] \[\left.+\|w_{\star}\|G\log\left(e+\frac{\|w_{\star}\|\sqrt{V}\log^{ 2}(T)}{h_{1}\epsilon}\right)+\gamma\|w_{\star}\|^{2}\log\left(e+\frac{\|w_{ \star}\|^{2}}{\epsilon^{2}}\log\left(e+\frac{G}{h_{1}}\right)\right)\right],\]

_where \(G=\max(h_{1},\max_{t\in[T]}\|g_{t}\|)\) and \(V=G^{2}+\sum_{t=1}^{T}\|g_{t}\|^{2}\)._

Before proving this result, let us briefly unpack the algebra in the statement to see how it relates to our originally stated bound (2). Notice that if we drop all the logarithmic terms, the bound becomes:

\[\sum_{t=1}^{T}\langle g_{t},w_{t}-w_{\star}\rangle\leq\tilde{O}\left[\epsilon G+ \epsilon^{2}\gamma+\frac{G^{2}}{\gamma}+\|w_{\star}\|\sqrt{\sum_{t=1}^{T}\|g_{ t}\|^{2}+\|w_{\star}\|G+\gamma\|w_{\star}\|^{2}}\right]\]

Here if we should think of \(h_{1}\) and \(\epsilon\) as conservative under-estimates of \(\max_{t}\|g_{t}\|\) and \(\|w_{\star}\|\). Notice that decreasing \(h_{1}\) and \(\epsilon\) only increases the terms inside the logarithms, so that in some sense the algorithm is very robust to even extremely conservative under-estimation. When it holds that \(h_{1}\leq\max_{t}\|g_{t}\|\) and \(\epsilon\leq\|w_{\star}\|\), then the above bound is exactly the previously stated equation (2).

### Proof Sketch of Theorem 1

Let us suppose for now that we have access to an algorithm that achieves the bound (4) under Protocol 2. Let us call it Reg. In this section, we will detail how to use Reg to achieve our desired goal (2) under Protocol 1 with \(\mathcal{W}=\mathbb{R}\): in this sketch, we treat all values as _scalars_, and never vectors. Recall that it suffices to consider \(\mathcal{W}=\mathbb{R}\) to achieve the result in general. Given an output \(w_{t}\) from Reg, we play \(w_{t}\) and observe the gradient \(g_{t}\). We will then produce a modified gradient \(\tilde{g}_{t}\), a scalar \(a_{t}\), and a magnitude hint \(h_{t+1}\) to provide to Reg such that \(\tilde{g}_{t}\) and \(a_{t}\) satisfy the constraints of Protocol 2. We will set \(\psi(w)=w^{2}\), and then by careful choice of \(\tilde{g}_{t}\), \(a_{t}\), and \(h_{t+1}\), we will be able to establish Theorem 1.

There are two key steps in our reduction. The first step is now a standard trick originally used by [18, 23, 30] to reduce the original Protocol 1 to Protocol 2. The idea is as follows: let us set \(h_{t}=\max(h_{1},|g_{1}|,\ldots,|g_{t-1}|)\) for some given "initial value" \(h_{1}\geq 0\). Notice that \(h_{t}\) may be computed before \(g_{t}\) is revealed and that the value \(G\) specified in the theorem satisfies \(G=h_{T+1}\). Then, upon receiving a gradient \(g_{t}\), we replace \(g_{t}\) with the "clipped" gradient \(\tilde{g}_{t}=\{1\wedge\frac{h_{t}}{|g_{t}|}\}\cdot g_{t}\). The clipped gradient \(\tilde{g}_{t}\) satisfies \(|\tilde{g}_{t}|\leq h_{t}\) by definition. We then pass \(\tilde{g}_{t}\) in place of \(g_{t}\) to an algorithm that interacts with Protocol 2. It is then relatively straightforward to see that for all \(w_{\star}\in\mathcal{W}\):

\[\sum_{t=1}^{T}g_{t}(w_{t}-w_{\star}) \leq\sum_{t=1}^{T}\tilde{g}_{t}(w_{t}-w_{\star})+\sum_{t=1}^{T}| \tilde{g}_{t}-g_{t}\|w_{\star}|+\sum_{t=1}^{T}|\tilde{g}_{t}-g_{t}||w_{t}|,\] \[\leq\sum_{t=1}^{T}\tilde{g}_{t}(w_{t}-w_{\star})+h_{T+1}|w_{\star }|+\sum_{t=1}^{T}(h_{t+1}-h_{t})|w_{t}|.\]

At this point, prior work [18, 23] observed that if we could constrain \(|w_{t}|\) to have some chosen maximum value \(D\), then the final summation above is at most \(h_{T+1}D\). By carefully choosing \(D\) in tandem with an algorithm that achieve (4) in the case \(\psi(w)=0\), one can achieve the previous "compromise" bound (3).

This is where our _second_ key step (which is our main technical innovation) comes in. Instead of explicitly enforcing \(|w_{t}|\leq D\), we will apply a "soft constraint" by adding a regularizer. Surprisingly, we will add a very tiny amount of regularization and yet still achieve meaningful regret bounds.

[MISSING_PAGE_EMPTY:6]

to envision exactly what constraint is being enforced; notice that to make \(\sum_{t=1}^{T}(h_{t+1}-h_{t})|w_{t}|=\widetilde{O}(G^{2}/\gamma)\) by applying some constraint \(|w_{t}|\leq D\), we would need to set \(D=\widetilde{O}(G/\gamma)\). However, such an aggresive constraint would surely prevent us from achieving low regret for even relatively moderate \(\|w_{\star}\|\geq G/\gamma\). So, our regularization seems to be doing something more subtle than simply applying a global constraint to the \(w_{t}\)'s. Indeed, notice that in the case \(|g_{t}|\leq h_{1}\) for all \(t\), we actually have \(a_{t}=0\) and so no constraint effect at all is enforced!

The final step we need to check is bounding \(\sum_{t=1}^{T}\tilde{g}_{t}(w_{t}-w_{\star})+a_{t}\psi(w_{t})-a_{t}\psi(w_{ \star})\). To this end, we provide in Section 3.3 an algorithm that achieves the following bound, which is slightly weaker than (4):

\[\sum_{t=1}^{T}\big{(}\tilde{g}_{t} (w_{t}-w_{\star})+a_{t}\psi(w_{t})-a_{t}\psi(w_{\star})\big{)}\] \[\leq O\left[\epsilon h_{T}+|w_{\star}|\sqrt{V\log\left(e+\frac{|w_ {\star}|\sqrt{V}\log^{2}(T)}{h_{1}\epsilon}\right)}+|w_{\star}|h_{T}\log\left( e+\frac{|w_{\star}|\sqrt{V}\log^{2}(T)}{h_{1}\epsilon}\right)\right.\] \[\qquad\left.+\epsilon^{2}\gamma+w_{\star}^{2}\sqrt{S\log\left(e+ \frac{|w_{\star}|^{2}\sqrt{S}\log^{2}(T)}{\gamma\epsilon^{2}}\right)}+\|w_{ \star}\|^{2}\gamma\log\left(e+\frac{|w_{\star}|^{2}\sqrt{S}\log^{2}(T)}{\gamma \epsilon^{2}}\right)\right],\]

where \(S=\gamma^{2}+\gamma\sum_{t=1}^{T}a_{t}\). This bound is weaker than (4) due to the presence of \(S\) rather than \(\gamma^{2}+\sum_{t=1}^{T}a_{t}^{2}\). Nevertheless, by our bound on \(\sum_{t=1}^{T}a_{t}\), we have:

\[S\leq\gamma^{2}+\gamma^{2}\log\left(1+\log\left(G/h_{1}\right)\right)\]

so that combining all of the above calculations we establish Theorem 1.

Thus, it remains to establish how we can achieve (4), or the slightly weaker (but sufficient) statement above. We accomplish this next in Section 3.3.

### Regularized Online Learning via Epigraph Constraints

Recall that our approach to obtaining (4) is to replace the regularization terms in the loss with constraints. Formally, consider the following protocol:

**Protocol 3.** Epigraph-based Regularized Online Learning for \(\mathcal{W}=\mathbb{R}\).

**Input:** Convex function \(\psi:\mathbb{R}\rightarrow\mathbb{R}\).

For \(t=1,\ldots,T\):

1. Nature reveals magnitude hint \(h_{t}\geq h_{t-1}\) to the learner.
2. Learner outputs \((x_{t},y_{t})\in\mathbb{R}\times\mathbb{R}\) with \(y_{t}\geq\psi(x_{t})\).
3. Nature reveals \(\tilde{g}_{t}\in[-h_{t},h_{t}]\) and \(a_{t}\in[0,\gamma]\) to the learner.
4. Learner suffers loss \(\tilde{g}_{t}x_{t}+a_{t}y_{t}\).

The learner is evaluated with the _linear regret_\(\sum_{t=1}^{T}g_{t}(x_{t}-w_{\star})+a_{t}(y_{t}-\psi(w_{\star}))\). The goal is to obtain:

\[\sum_{t=1}^{T}\big{(}\tilde{g}_{t}(x_{t}-w_{\star})+a_{t}(y_{t}-\psi(w_{\star} ))\big{)}\underset{\text{goal}}{\leq}\widetilde{O}\left(\|w_{\star}\|\sqrt{h _{T}^{2}+\sum_{t=1}^{T}\tilde{g}_{t}^{2}}+\psi(w_{\star})\sqrt{\gamma^{2}+ \sum_{t=1}^{T}a_{t}^{2}}\right). \tag{6}\]

The key fact about this protocol is the observation that by setting \(w_{t}=x_{t}\), the bound (6) immediately implies (4). To see this, recall that \(\psi(w)\geq 0\), \(a_{t}\geq 0\), and \(y_{t}\geq\psi(x_{t})=\psi(w_{t})\) so that:

\[\sum_{t=1}^{T}\left((g_{t},w_{t}-w_{\star})+a_{t}\psi(w_{t})-a_{t}\psi(w_{ \star})\right)\leq\sum_{t=1}^{T}\left((g_{t},x_{t}-w_{\star})+a_{t}y_{t}-a_{t} \psi(w_{\star})\right).\]

So, to achieve (4) under Protocol 2, it suffices to achieve the bound (6) under Protocol 3.

There is one tempting approach that _almost, but not quite_, achieves this goal. One could employ the "constraint-set reduction" developed in [16] that converts an algorithm that operates on the "unconstrained" domain \(\mathbb{R}^{d}\times\mathbb{R}\) to one respecting the constraint \(y\geq\psi(x)\). In particular, it is relatively straightforward to build an algorithm that achieves (6) without requiring \(y_{t}\geq\psi(x_{t})\). This unconstrained setting can be handled by the classic "coordinate-wise updates" trick in which we run two instances of an algorithm achieving (4) in the special case that \(\psi(x)=0\), one of which will output \(x_{t}\) and receive feedback \(g_{t}\), and the other will output \(y_{t}\) and receive feedback \(a_{t}\). Then, by the individual regret bounds on both coordinates, we would have:

\[\sum_{t=1}^{T}\left(g_{t}\big{(}x_{t}-w_{\star}\big{)}+a_{t}\big{(} y_{t}-\psi(w_{\star})\big{)}\right) =\sum_{t=1}^{T}g_{t}\big{(}x_{t}-w_{\star}\big{)}+\sum_{t=1}^{T}a _{t}\big{(}y_{t}-\psi(w_{\star})\big{)},\] \[\leq\widetilde{O}\left(\|w_{\star}\|\sqrt{h_{T}^{2}+\sum_{t=1} \tilde{g}_{t}^{2}}+\psi(w_{\star})\sqrt{\gamma^{2}+\sum_{T=1}^{T}a_{t}^{2}} \right).\]

Then, one might hope that applying the constraint-set reduction of [16] would allow us to apply the constraint \(\mathcal{W}\) without damaging the regret bound. Unfortunately, this reduction will modify the feedback \(g_{t}\) and \(a_{t}\) in such a way that \(\sum_{t=1}^{T}a_{t}^{2}\) could become much larger, which makes this approach untenable in general.

Fortunately, it turns out that our particular usage will enforce some favorable conditions on \(a_{t}\) that make the above strategy viable. Specifically, the choices of \(\tilde{g}_{t}\), \(h_{t}\) and \(a_{t}\) described in Section 3.2 satisfy the condition that \(a_{t}=0\) unless \(\|\tilde{g}_{t}\|=h_{t}\). By careful inspection of the constraint-set reduction, it is possible to show that the above strategy achieves a slightly weaker version of (6):

\[\sum_{t=1}^{T}\tilde{g}_{t}\big{(}x_{t}-w_{\star}\big{)}+a_{t}\big{(}y_{t}- \psi(w_{\star})\big{)}\leq\widetilde{O}\left(\|w_{\star}\|\sqrt{h_{T}^{2}+\sum _{t=1}\tilde{g}_{t}^{2}}+\psi(w_{\star})\sqrt{\gamma^{2}+\gamma\sum_{T=1}^{T}a _{t}}\right). \tag{7}\]

As detailed in Section 3.2, this weaker bound suffices for our eventual purposes. Nevertheless, for the reader interested in a fully general solution, in Appendix H, we provide a method for achieving (6) without restrictions. We do not employ it in our main development because it involves solving a convex subproblem at each iteration and so may be less efficient in some settings. This technique does however involve a small improvement to so-called "full-matrix" regret bounds [31], and so may be of some independent interest.

## 4 Lower Bounds

In this section, we show that the result of Theorem 1 is tight. In fact, we show a stronger result that generalizes our extra penalty term from \(G^{2}/\gamma+\gamma\|w_{\star}\|^{2}\) to \(\gamma\psi(\|w_{\star}\|)+\gamma\psi^{\star}(G/\gamma)\) for any symmetric convex function \(\psi\), where \(\psi^{\star}(x)=\sup_{x}xz-\psi(z)\) is the Fenchel conjugate of \(\psi\). That is, we provide a Pareto frontier of different lower bounds and Theorem 1 is but one point on this frontier. In Appendix A we extend our upper-bound results to match any desired point on this frontier (up to a logarithmic factor).. We also provide matching upper bounds (up to a logarithmic factor) in Theorem 16, as well as more simplified

**Theorem 2**.: _Suppose \(\psi:\mathbb{R}\to\mathbb{R}\) is convex, symmetric, differentiable, non-negative, achieves its minimum at \(\psi(0)=0\), and \(\psi(x)\) is strictly increasing for non-negative \(x\). Further suppose that for any \(X,Y,Z>0\), there is some \(\tau\) such that for all \(T\geq\tau\),_

\[\exp(T)-1 \geq X\sqrt{T}\psi^{\star}(YT)\] \[X\psi^{\star}(YTZ) \geq TZ\]

_where \(\psi^{\star}(z)=\sup zx-\psi(x)\) is the Fenchel conjugate of \(\psi\). Let \(h_{1}>0\), \(\gamma>0\) and \(\epsilon>0\) be given._

_For any online learning algorithm \(\mathcal{A}\) interacting with Protocol 1 with \(\mathcal{W}=\mathbb{R}\), there is a \(T_{0}\) such that for any \(T\geq T_{0}\), there is a sequence of gradients \(g_{1},\dots,g_{T}\) and a \(w_{\star}\) such that the outputs \(w_{1},\dots,w_{T}\) of \(\mathcal{A}\) satisfy:_

\[\sum_{t=1}^{T}g_{t}\big{(}w_{t}-w_{\star}\big{)}\geq\epsilon G+\frac{\gamma}{8 }\psi^{\star}(G/\gamma)+\frac{\gamma}{4}\psi(w_{\star})+\frac{G|w_{\star}|}{4 }\sqrt{T\log\left(1+\frac{G|w_{\star}|\sqrt{T}}{h_{1}\epsilon}\right)},\]_where \(G=\max(h_{1},g_{1},\ldots,g_{T})\). In particular, with \(\psi(x)=x^{1+q}\) for any \(q>0\), we can ensure:_

\[\sum_{t=1}^{T}g_{t}(w_{t}-w_{\star})\geq\Omega\left[\epsilon G+\frac{G^{1+1/q}}{ \gamma^{1/q}}+\gamma|w_{\star}|^{1+q}+G|w_{\star}|\sqrt{T\log\left(1+\frac{G|w_{ \star}|\sqrt{T}}{h_{1}\epsilon}\right)}\right].\]

The conditions on \(\psi^{\star}\) in this bound are relatively mild. The first condition says that the gradient \(\nabla\psi^{\star}\) should not grow exponentially fast. The second condition says that \(\psi^{\star}\) should grow faster than some linear function. So, any polynomial of degree greater than 1 satisfies these conditions.

We note that this lower bound leaves something to be desired in terms of the quantification of the terms. Here, the value of \(G\) and \(\|w_{\star}\|\) depends on the algorithm \(\mathcal{A}\). This is a critical factor in the proof; roughly speaking, the proof operates by providing the algorithm with a constant gradient \(g_{t}=h_{1}\) at every round. Then, if the iterates \(w_{t}\) grow in some sense "quickly", we "punish" the algorithm with a very large negative gradient, which causes high regret if \(w_{\star}=0\). Alternatively, if the iterates do not grow quickly, then we show that the regret is large for some \(w_{\star}\gg 1\). This approach is a common idiom for lower bounds in the fully unconstrained setting [18; 22].

However, a much better bound might be possible; ideally, it would hold that for _any_\(G\) and \(\|w_{\star}\|\) and algorithm \(\mathcal{A}\), we can find a sequence of gradients \(g_{t}\) that enforces our desired regret. Indeed, when either \(\|w_{\star}\|\) or \(\max_{t}\|g_{t}\|\) is provided to the algorithm, the lower bounds available do take this form [3; 5]. We leave as an open question whether it is possible to do so in our setting.

## 5 Discussion

We have provided a new online learning algorithm that achieves a near-optimal regret bound (2). Our algorithm is "fully unconstrained", or "fully parameter-free", in the sense that we achieve a near-optimal regret bound without requiring bounds on the gradients \(g_{t}\) or the comparison point \(w_{\star}\). Prior work in this setting [18; 21; 22; 23; 26] achieve bounds that are technically incomparable, but may be aesthetically less desirable, as detailed in the discussion following (3). Nevertheless, ideally we would have a unified algorithm framework capturing both our old and new bounds. It is an open question whether more careful choice of regularization in our approach could achieve this goal.

Our algorithm takes as input parameters \(\epsilon\), \(h_{1}\) and \(\gamma\). All of these have a pleasingly small impact on the regret bound. \(\epsilon\) and \(h_{1}\) can be interpreted as very rough estimates of \(\|w_{\star}\|\) and \(G\). As these quantities go to zero, the regret bound increases only logarithmically. Moreover, these estimates can be too high by a factor of \(\sqrt{T}\) while still maintaining \(\tilde{O}(\|w_{\star}\|G\sqrt{T})\) regret. The quantity \(\gamma\) represents an estimate of \(G/\|w_{\star}\|\). As discussed in Section 1, this value does not appear in any term that has a \(T\)-dependence in the regret bound and so also has a very mild impact on the regret.

While our bound has several intuitively desirable characteristics, it is missing one important property: our bound suffers from an issue highlighted by [18] called the "range-ratio" problem. That is, the bound depends on the ratio \(G/h_{1}\), which could be very large if the losses are rescaled by some arbitrary large number without rescaling \(h_{1}\). This issue is at the heart of how we are able to sidestep the lower-bound of [18], which appears to apply to all algorithms that do not suffer from the range-ratio problem.

### Other forms of Unconstrained Online Learning

Our results focus on the case that we have no prior bounds on the value of \(\|w_{\star}\|\) or \(\|g_{t}\|\), and our bounds eventually depend on \(\max_{t}\|g_{t}\|\). One might worry that this is too conservative in some settings. For example, it might be that \(g_{t}\) is known to be a random variable with bounded mean \(\|\mathbb{E}[g_{t}]\|\leq G\) and variance \(\text{Var}(g_{t})\leq\sigma^{2}\) for some known \(G\) and \(\sigma\). In this case, \(\max_{t}\|g_{t}\|\) might become large even though intuitively our regret should still depend only on \(G+\sigma\). This is the setting considered by several prior work on online learning with unconstrained domains [9; 17; 32]. Under various assumptions, these results all achieve an in-expectation regret bound of \(\mathbb{E}[\text{Regret}_{T}(w_{\star})]\leq\widetilde{O}(\|w_{\star}\|(G+ \sigma)\sqrt{T})\).

In fact, our results come close to this ideal even without knowledge of \(G\). For example, [9; 17] study the case of sub-exponential \(g_{t}\) that satisfy \(\sup_{|a|\leq 1}\mathbb{E}[\exp(\beta(g_{t}-\mathbb{E}[g_{t}],a))]\leq\exp( \beta^{2}\sigma^{2}/2)\) for all \(|\beta|\leq 1/b\) for some \(b>0\). In this case, for 1-dimensional \(g_{t}\), we have \(\mathbb{E}[\max_{t}g_{t}^{2}]\leq\widetilde{O}(G^{2}+\sigma^{2})\), and so in expectation we achieve \(\widetilde{O}(\|w_{\star}\|(G+\sigma)\sqrt{T}+G^{2}+\sigma^{2}+\|w_{\star}\|^{2})\) (the extension from 1-d to arbitrary dimensions can then be achieved via the black-box reduction of [16]). However, in the case that \(g_{t}\) has some heavy-tailed distribution such as studied by [32], it is less clear that our bounds achieve the desired result out-of-the box. Discovering how to achieve this is an interesting direction for future study.

### Parameter-free Algorithms and Stochastic Convex Optimization

As discussed in the introduction, a common motivation for the study of online learning is its immediate application to stochastic convex optimization through various online-to-batch conversions. The classic conversion of [7], as well as a few more recent results [33; 34; 35; 36] all show that if \(g_{t}\) is the output of a stochastic gradient oracle for a convex function \(F\), then for any \(w_{\star}\in\text{argmin}\ F\):2

Footnote 2: The difference between these conversions lies in where the stochastic gradients \(g_{t}\) are computed.

\[\mathbb{E}\left[F\left(\tfrac{\sum_{t=1}^{T}w_{\star}}{T}\right)-F(w_{\star}) \right]\leq\frac{\mathbb{E}[\text{Regret}_{T}(w_{\star})]}{T}\]

If \(\|g_{t}\|\leq G\) with probability 1 (for an unknown \(G\)), our Theorem 1 immediately implies \(\mathbb{E}\left[F\left(\tfrac{\sum_{t=1}^{T}w_{\star}}{T}\right)-F(w_{\star}) \right]\leq\widetilde{O}\left(\tfrac{\|w_{\star}\|G}{\sqrt{T}}+\tfrac{G^{2}/ \gamma+\gamma\|w_{\star}\|^{2}}{T}\right)\). The first term is the optimal rate for stochastic convex optimization that can be achieved via SGD with learning rate \(\eta=\frac{\|w_{\star}\|}{G\sqrt{T}}\) if \(G\) and \(\|w_{\star}\|\) are known ahead of time, and the second term is a lower-order "penalty" for not having up-front knowledge of these quantities.

Convergence results that match that of optimally tuned SGD are often called "parameter-free" (the parameter in question is the learning rate). As mentioned in the introduction, there has been a long line of works that attempt to achieve this goal by matching the regret bound (1), which can then be applied to the stochastic setting via an online-to-batch conversion. More recent work on parameter-free optimization has considered the stochastic case [37; 38], or deterministic case [39] directly without passing through a general regret bound. Many of these algorithms have shown significant empirical promise, even for non-convex deep learning tasks [38; 39; 40; 41; 42]. Almost all of these results require apriori knowledge of the value \(G\)3

Footnote 3: A few exceptions achieve the prior bound (3) [18; 21; 23; 43].

To place our results in this context, let us focus on the case of a known \(G\) value. In this case, [37] show that by eschewing regret analysis and focusing specifically on the stochastic setting, it is possible to achieve a high-probability guarantee that improves upon the logarithmic factors achieved by our result, and so there seems to be something lost by focusing on regret bounds. However, in a surprising counterpoint, [44] shows that if one is interested in an _in-expectation_ result, then there is actually no way to improve upon the logarithmic factors achieved via online-to-batch conversion when applied to parameter-free regret bounds. Thus, our in-expectation stochastic convergence rate is optimal even up to logarithmic factors, while we also do not require prior knowledge of \(G\).

Finally, let us evaluate the optimality of our bound in the stochastic setting while accounting for the fact that our methods do not get to know either \(G\) or \(\|w_{\star}\|\). Here, we can again make use of the lower bounds developed by [44]. Consider the class of stochastic convex optimization objectives with Lipschitz constant \(G\) between \(1\) and \(L\) and \(\|w_{\star}\|\in[1,R]\). The "price of adaptivity" as defined by [44] is the maximum over this class of the ratio between the convergence guarantee of an algorithm that does not know \(\|w_{\star}\|\) and \(G\) with respect to the minimax optimal convergence guarantee for an algorithm that does know these values (which is \(RG/\sqrt{T}\)). We achieve a price of adaptivity of \(\widetilde{O}(1+\max(L,R)/\sqrt{T})\). The best-known lower bound for this class is \(\Omega(1+\min(L,R)/\sqrt{T})\)[44]. Thus, there is a gap here--although we provide matching homer bounds for the _online_ setting, it is possible that in the _stochastic_ setting, one can improve our bounds. That said, the stochastic lower bound is derived for algorithms that are given the ranges \([1,L]\) and \([1,R]\). Our algorithm does not use this information and it is also plausible that without such knowledge the lower bound itself would improve.

**Acknowledgements**

AC is supported by NSF grant number CCF-2211718.

## References

* [1] Francesco Orabona. "A modern introduction to online learning". In: _arXiv preprint arXiv:1912.13213_ (2019).
* [2] Elad Hazan. "Introduction to online convex optimization". In: _arXiv preprint arXiv:1909.05207_ (2019).
* [3] Jacob Abernethy, Peter L Bartlett, Alexander Rakhlin, and Ambuj Tewari. "Optimal strategies and minimax lower bounds for online convex games". In: _Proceedings of the nineteenth annual conference on computational learning theory_. 2008, pp. 415-424.
* [4] Brendan Mcmahan and Matthew Streeter. "No-regret algorithms for unconstrained online convex optimization". In: _Advances in neural information processing systems_. 2012, pp. 2402-2410.
* [5] Francesco Orabona. "Dimension-free exponentiated gradient". In: _Advances in Neural Information Processing Systems_. 2013, pp. 1806-1814.
* [6] Martin Zinkevich. "Online Convex Programming and Generalized Infinitesimal Gradient Ascent". In: _Proceedings of the 20th International Conference on Machine Learning (ICML-03)_. 2003, pp. 928-936.
* [7] Nicolo Cesa-Bianchi, Alex Conconi, and Claudio Gentile. "On the generalization ability of on-line learning algorithms". In: _Information Theory, IEEE Transactions on_ 50.9 (2004), pp. 2050-2057.
* [8] Ashok Cutkosky, Harsh Mehta, and Francesco Orabona. "Optimal Stochastic Non-smooth Non-convex Optimization through Online-to-Non-convex Conversion". In: _International Conference on Machine Learning (ICML)_. 2023.
* [9] Kwang-Sung Jun and Francesco Orabona. "Parameter-free online convex optimization with sub-exponential noise". In: _Conference on Learning Theory_. PMLR. 2019, pp. 1802-1823.
* [10] Zakaria Mhammedi. "Risk monotonicity in statistical learning". In: _Advances in Neural Information Processing Systems_ 34 (2021), pp. 10732-10744.
* [11] Francesco Orabona and Kwang-Sung Jun. "Tight concentrations and confidence sequences from the regret of universal portfolio". In: _IEEE Transactions on Information Theory_ (2023).
* [12] Gabor Lugosi and Gergely Neu. "Online-to-PAC conversions: Generalization bounds via regret analysis". In: _arXiv preprint arXiv:2305.19674_ (2023).
* [13] Elad Hazan, Alexander Rakhlin, and Peter L Bartlett. "Adaptive online gradient descent". In: _Advances in Neural Information Processing Systems_. 2008, pp. 65-72.
* [14] J. Duchi, E. Hazan, and Y. Singer. "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization". In: _Conference on Learning Theory (COLT)_. 2010, pp. 257-269.
* [15] H. Brendan McMahan and Matthew Streeter. "Adaptive Bound Optimization for Online Convex Optimization". In: _Proceedings of the 23rd Annual Conference on Learning Theory (COLT)_. 2010, pp. 244-256.
* [16] Ashok Cutkosky and Francesco Orabona. "Black-Box Reductions for Parameter-free Online Learning in Banach Spaces". In: _Conference On Learning Theory_. 2018, pp. 1493-1529.
* [17] Dirk van der Hoeven. "User-specified local differential privacy in unconstrained adaptive online learning". In: _Advances in Neural Information Processing Systems_. 2019, pp. 14103-14112.
* [18] Zakaria Mhammedi and Wouter M Koolen. "Lipschitz and Comparator-Norm Adaptivity in Online Learning". In: _Conference on Learning Theory_ (2020), pp. 2858-2887.
* [19] Liyu Chen, Haipeng Luo, and Chen-Yu Wei. "Impossible tuning made possible: A new expert algorithm and its applications". In: _Conference on Learning Theory_. PMLR. 2021, pp. 1216-1259.
* [20] Zhiyu Zhang, Ashok Cutkosky, and Ioannis Paschalidis. "Pde-based optimal strategy for unconstrained online learning". In: _International Conference on Machine Learning_. PMLR. 2022, pp. 26085-26115.
* [21] Andrew Jacobsen and Ashok Cutkosky. "Parameter-free Mirror Descent". In: _Proceedings of Thirty Fifth Conference on Learning Theory_. Ed. by Po-Ling Loh and Maxim Raginsky. Vol. 178. Proceedings of Machine Learning Research. PMLR, 2022, pp. 4160-4211.
* [22] Ashok Cutkosky and Kwabena Boahen. "Online Learning Without Prior Information". In: _Conference on Learning Theory_. 2017, pp. 643-677.

* [23] Ashok Cutkosky. "Artificial Constraints and Hints for Unbounded Online Learning". In: _Proceedings of the Thirty-Second Conference on Learning Theory_. 2019, pp. 874-894.
* [24] Nathan Srebro, Karthik Sridharan, and Ambuj Tewari. "Smoothness, low noise and fast rates". In: _Advances in neural information processing systems_. 2010, pp. 2199-2207.
* [25] Ashok Cutkosky. "Combining Online Learning Guarantees". In: _Proceedings of the Thirty-Second Conference on Learning Theory_. 2019, pp. 895-913.
* [26] Zhiyu Zhang, Heng Yang, Ashok Cutkosky, and Ioannis Ch Paschalidis. "Improving Adaptive Online Learning Using Refined Discretization". In: _arXiv preprint arXiv:2309.16044_ (2023).
* [27] Andrew Jacobsen and Ashok Cutkosky. "Unconstrained online learning with unbounded losses". In: _International Conference on Machine Learning_. PMLR. 2023, pp. 14590-14630.
* [28] Jack J Mayo, Hedi Hadiji, and Tim van Erven. "Scale-free unconstrained online learning for curved losses". In: _Conference on Learning Theory_. PMLR. 2022, pp. 4464-4497.
* [29] Gergely Neu and Nneka Okolo. "Dealing With Unbounded Gradients in Stochastic Saddle-point Optimization". In: _Proceedings of the 41st International Conference on Machine Learning_. PMLR. 2024, pp. 37508-37530.
* [30] Zakaria Mhammedi, Wouter M Koolen, and Tim Van Erven. "Lipschitz adaptivity with multiple learning rates in online learning". In: _Conference on Learning Theory_. PMLR. 2019, pp. 2490-2511.
* [31] Ashok Cutkosky. "Better full-matrix regret via parameter-free online learning". In: _Advances in Neural Information Processing Systems_ 33 (2020), pp. 8836-8846.
* [32] Jiujia Zhang and Ashok Cutkosky. "Parameter-free regret in high probability with heavy tails". In: _Advances in Neural Information Processing Systems_ 35 (2022), pp. 8000-8012.
* [33] Ashok Cutkosky. "Anytime Online-to-Batch, Optimism and Acceleration". In: _International Conference on Machine Learning_. 2019, pp. 1446-1454.
* [34] Ali Kavis, Kfir Y Levy, Francis Bach, and Volkan Cevher. "UniXGrad: A Universal, Adaptive Algorithm with Optimal Guarantees for Constrained Optimization." In: _NeurIPS_. 2019, pp. 6257-6266.
* [35] Aaron Defazio, Ashok Cutkosky, Harsh Mehta, and Konstantin Mishchenko. "When, Why and How Much? Adaptive Learning Rate Scheduling by Refinement". In: _arXiv preprint arXiv:2310.07831_ (2023).
* [36] Aaron Defazio, Harsh Mehta, Konstantin Mishchenko, Ahmed Khaled, Ashok Cutkosky, et al. "The Road Less Scheduled". In: _arXiv preprint arXiv:2405.15682_ (2024).
* [37] Yair Carmon and Oliver Hinder. "Making SGD Parameter-Free". In: _Conference on Learning Theory_ (2022).
* [38] Maor Iygi, Oliver Hinder, and Yair Carmon. "Dog is sgd's best friend: A parameter-free dynamic step size schedule". In: _International Conference on Machine Learning_. PMLR. 2023, pp. 14465-14499.
* [39] Aaron Defazio and Konstantin Mishchenko. "Learning-rate-free learning by d-adaptation". In: _International Conference on Machine Learning_. PMLR. 2023, pp. 7449-7479.
* [40] Francesco Orabona and Tatiana Tommasi. "Training Deep Networks without Learning Rates Through Coin Betting". In: _Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, 4-9 December 2017, Long Beach, CA, USA_. 2017, pp. 2157-2167.
* [41] Konstantin Mishchenko and Aaron Defazio. "Prodigy: An expeditiously adaptive parameter-free learner". In: _arXiv preprint arXiv:2306.06101_ (2023).
* [42] Ashok Cutkosky, Aaron Defazio, and Harsh Mehta. "Mechanic: A Learning Rate Tuner". In: _Advances in neural information processing systems_ 36 (2023).
* [43] Zhiyu Zhang, Heng Yang, Ashok Cutkosky, and Ioannis C Paschalidis. "Improving adaptive online learning using refined discretization". In: _International Conference on Algorithmic Learning Theory_. PMLR. 2024, pp. 1208-1233.
* [44] Yair Carmon and Oliver Hinder. "The Price of Adaptivity in Stochastic Convex Optimization". In: _arXiv preprint arXiv:2402.10898_ (2024).
* [45] Jean-Baptiste Hiriart-Urruty and Claude Lemarechal. _Fundamentals of convex analysis_. Springer Science & Business Media, 2004.
* [46] Ashok Cutkosky and Tamas Sarlos. "Matrix-Free Preconditioning in Online Learning". In: _International Conference on Machine Learning_. 2019, pp. 1455-1464.

* [47] Zakaria Mhammedi and Alexander Rakhlin. "Damped online Newton step for portfolio selection". In: _Conference on Learning Theory_. PMLR. 2022, pp. 5561-5595.
* [48] Zakaria Mhammedi and Khashayar Gatmiry. "Quasi-newton steps for efficient online expconcave optimization". In: _The Thirty Sixth Annual Conference on Learning Theory_. PMLR. 2023, pp. 4473-4503.
* [49] Khashayar Gatmiry and Zak Mhammedi. "Projection-Free Online Convex Optimization via Efficient Newton Iterations". In: _Advances in Neural Information Processing Systems_ 36 (2024).
* [50] Francesco Orabona and David Pal. "Coin Betting and Parameter-Free Online Learning". In: _Advances in Neural Information Processing Systems 29_. Ed. by D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett. Curran Associates, Inc., 2016, pp. 577-585.

[MISSING_PAGE_EMPTY:14]

[MISSING_PAGE_FAIL:15]

5. Set \(t\gets t+1\) and go to Item 2.

Suppose that the condition in Item 3 has not been triggered for the first \(\tau\) iterations. Then, we have:

\[\sum_{t=1}^{\tau}w_{t}\cdot g_{t} \geq-2\epsilon\tau h_{1}-\frac{1}{2}\sum_{t=1}^{\tau}\nabla\psi_{ \gamma}^{*}(2(t-1)h_{1})\cdot 2h_{1},\] \[\geq-2\epsilon\tau h_{1}-\frac{1}{2}\sum_{t=1}^{\tau}(\psi_{ \gamma}^{*}(2th_{1})-\psi_{\gamma}^{*}(2(t-1)h_{1})),\quad\text{(by convexity of $\psi_{\gamma}^{*}$)}\] \[=-2\epsilon\tau h_{1}-\frac{1}{2}\psi_{\gamma}^{*}(2\tau h_{1}). \tag{12}\]

Now, suppose that the condition in Item 3 is triggered at some iteration \(\tau+1\geq 1\). Then \(G=2\tau h_{1}\) and with \(w_{*}=0\), we have:

\[\sum_{t=1}^{T}g_{t}\cdot(w_{t}-w_{\centerdot}) =\sum_{t=1}^{\tau+1}g_{t}\cdot w_{t},\] \[=g_{\tau+1}\cdot w_{\tau+1}+\sum_{t=1}^{\tau}w_{t}\cdot g_{t},\] \[\geq 4\epsilon\tau h_{1}+\nabla\psi_{\gamma}^{*}(2\tau h_{1}) \cdot 2\tau h_{1}-2\epsilon\tau h_{1}-\frac{1}{2}\psi_{\gamma}^{*}(2\tau h _{1}),\quad\text{(by (\ref{eq:2}))}\] \[=2\epsilon\tau h_{1}+\nabla\psi_{\gamma}^{*}(2\tau h_{1})\cdot 2 \tau h_{1}-\psi_{\gamma}(\nabla\psi_{\gamma}^{*}(2\tau h_{1}))+\psi_{\gamma}( \nabla\psi_{\gamma}^{*}(2\tau h_{1}))-\frac{1}{2}\psi_{\gamma}^{*}(2\tau h_{1}),\] \[=2\epsilon\tau h_{1}+\psi_{\gamma}^{*}(2\tau h_{1})+\psi_{\gamma} (\nabla\psi_{\gamma}^{*}(2\tau h_{1}))-\frac{1}{2}\psi_{\gamma}^{*}(2\tau h_{1 }),\] \[\geq 2\epsilon\tau h_{1}+\frac{1}{2}\psi_{\gamma}^{*}(2\tau h_{1}), \tag{13}\] \[=\epsilon G+\frac{1}{2}\psi_{\gamma}^{*}(G).\]

Therefore, overall we have for \(w_{*}=0\):

\[\sum_{t=1}^{T}g_{t}\cdot(w_{t}-w_{\centerdot})\geq\epsilon G+\frac{\gamma}{2} \psi^{*}(G/\gamma)+\gamma\psi(|w_{*}|)+|w_{*}|G\sqrt{T\log\left(1+\frac{|w_{*} |G\sqrt{T}}{h_{1}\epsilon}\right)}.\]

Alternatively, suppose the condition in Item 3 is never triggered. In this case, let us set \(w_{*}=-2\nabla\psi_{\gamma}^{*}(2Th_{1})\). Then, \(G=h_{1}\) and by (12) we have:

\[\sum_{t=1}^{T}g_{t}\cdot(w_{t}-w_{*})\geq\nabla\psi_{\gamma}^{*}(2Th_{1})\cdot 2 Th_{1}-\frac{1}{2}\psi_{\gamma}^{*}(2Th_{1})-2\epsilon Th_{1}.\]

Using that \(\nabla\psi_{\gamma}^{*}(x)\cdot x\geq\psi_{\gamma}^{*}(x)\) by convexity of \(\psi_{\gamma}^{*}\) and \(\phi_{\gamma}^{*}(0)=0\), the right-hand side of the previous display can be bounded below by \(0\):

\[\nabla\psi_{\gamma}^{*}(2Th_{1})\cdot 2Th_{1}-\frac{1}{2}\psi_{ \gamma}^{*}(2Th_{1})-2\epsilon Th_{1} \geq\frac{1}{2}\psi_{\gamma}^{*}(2Th_{1}),\] \[\geq\frac{1}{4}\psi_{\gamma}^{*}(G)+\frac{1}{4}\psi_{\gamma}^{*}(2 Th_{1})-2\epsilon Th_{1}.\]

Applying Eq. (11):

\[\geq\frac{1}{4}\psi_{\gamma}^{*}(G)+8\epsilon Th_{1}-2\epsilon Th _{1},\] \[\geq\frac{\gamma}{4}\psi^{*}(G/\gamma)+6\epsilon Th_{1}. \tag{14}\]Further, since \(\psi_{\gamma}^{\star\star}=\psi_{\gamma}\), we have:

\[\nabla\psi_{\gamma}^{\star}(2Th_{1})\cdot 2Th_{1}-\frac{1}{2}\psi_{ \gamma}^{\star}(2Th_{1}) =\nabla\psi_{\gamma}^{\star}(2Th_{1})\cdot Th_{1}+\frac{1}{2} \left(\nabla\psi_{\gamma}^{\star}(2Th_{1})\cdot 2Th_{1}-\psi_{\gamma}^{\star}(2Th_{1}) \right),\] \[=\nabla\psi_{\gamma}^{\star}(2Th_{1})\cdot Th_{1}+\frac{1}{2}\psi _{\gamma}(\nabla\psi_{\gamma}^{\star}(2Th_{1})),\] \[=\nabla\psi_{\gamma}^{\star}(2Th_{1})\cdot Th_{1}+\frac{1}{2}\psi _{\gamma}(-w_{\star}),\] \[=\frac{1}{2}|w_{\star}|\cdot Th_{1}+\frac{\gamma}{2}\psi(w_{\star}).\]

Finally, let us bound \(\frac{1}{2}|w_{\star}|\cdot g_{1:T}\) using our choice of \(w_{\star}\). By definition, we have:

\[h_{1}T =h_{1}\sqrt{T\cdot T},\] \[=h_{1}\sqrt{T\log(1+(\exp(T)-1))},\]

applying Eq. (10):

\[\geq h_{1}\sqrt{T\log\left(1+\frac{2\sqrt{T}\nabla\psi_{\gamma}^{ \star}(2Th_{1})}{\epsilon}\right)},\] \[=h_{1}\sqrt{T\log\left(1+\frac{|w_{\star}|\sqrt{T}}{\epsilon} \right)},\] \[=G\sqrt{T\log\left(1+\frac{G|w_{\star}|\sqrt{T}}{h_{1}\epsilon} \right)}. \tag{15}\]

Therefore, combining Eq. (14) with Eq. (15):

\[\nabla\psi_{\gamma}^{\star}(2Th_{1})\cdot 2Th_{1}-\frac{1}{2}\psi_{ \gamma}^{\star}(2Th_{1})-2\epsilon Th_{1}\] \[\geq\frac{1}{2}\left(\frac{\gamma}{4}\psi^{\star}(G/\gamma)+6 \epsilon Th_{1}\right)+\frac{1}{2}\left(\frac{\gamma}{2}\psi(w_{\star})+\frac{ G|w_{\star}|}{2}\sqrt{T\log\left(1+\frac{G|w_{\star}|\sqrt{T}}{h_{1}\epsilon} \right)}-4\epsilon Th_{1}\right),\] \[\geq 3\epsilon Th_{1}+\frac{\gamma}{8}\psi^{\star}(G/\gamma)+ \frac{\gamma}{4}\psi(w_{\star})+\frac{G|w_{\star}|}{4}\sqrt{T\log\left(1+\frac {G|w_{\star}|\sqrt{T}}{h_{1}\epsilon}\right)},\] \[\geq\epsilon G+\frac{\gamma}{8}\psi^{\star}(G/\gamma)+\frac{ \gamma}{4}\psi(w_{\star})+\frac{G|w_{\star}|}{4}\sqrt{T\log\left(1+\frac{G|w_{ \star}|\sqrt{T}}{h_{1}\epsilon}\right)}.\]

## Appendix C Reduction to \(\mathcal{W}=\mathbb{R}\)

As a first step in our algorithm design, we observe that the application of some known reductions from [16] can significantly simplify our task. [16] show that to build an algorithm whose regret bound depends on \(g_{t}\) only through the norms \(\|g_{t}\|\), it suffices to consider exclusively the case \(\mathcal{W}=\mathbb{R}\). We provide the formal reduction in Algorithm 1, which ensures the following regret bound.

**Theorem 5** ([16]).: _Algorithm 1 ensures that \(|g_{t}^{\text{magnitude}}|\leq 2\|g_{t}\|\), and also for all \(w_{\star}\in\mathcal{W}\):_

\[\sum_{t=1}^{T}\langle g_{t},w_{t}-w_{\star}\rangle\leq 4\|w_{\star}\|\sqrt{2 \sum_{t=1}^{T}\|g_{t}\|^{2}}+\sum_{t=1}^{T}g_{t}^{magnitude}\big{(}w_{t}^{ \text{magnitude}}-\|w_{\star}\|\big{)}.\]From Theorem 5, it is clear that to achieve low regret on \(\mathcal{W}\), we need only bound \(\sum_{t=1}^{T}g_{t}^{\text{magnitude}}(w_{t}^{\text{magnitude}}-\|w_{*}\|)\), which is exactly the regret of a 1-dimensional learner. So, our final results will be established by considering the case of \(\mathcal{W}=\mathbb{R}\), although we will define many intermediate problems for general \(\mathcal{W}\) as they may have other applications for which the general setting is of interest.

## Appendix D An Efficient Algorithm for Protocol 2 With Restricted (But Sufficient) Assumptions

In this section, we describe our algorithm for Protocol 2 in the special case that \(\mathcal{W}=\mathbb{R}\) and \(a_{t}=0\) whenever \(|\tilde{g}_{t}|\neq h_{t}\), where \(\tilde{g}_{t}=(1\wedge\frac{h_{t}}{|g_{t}|})\cdot g_{t}\). Our algorithm is in fact a reduction to the special case that \(a_{t}=0\) for all \(t\). This is an important special case that has actually also been previously considered in the literature (see e.g. the discussion in Section 3.1), so we provide it as a separate Protocol below:

```
\(\mathbf{Protocol}\) 4. Online Learning with Magnitude Hints. Input: Convex domain \(\mathcal{W}\) (recall that we focus on \(\mathcal{W}=\mathbb{R}\)).  For \(t=1,\ldots,T\): 1. Nature reveals magnitude hint \(h_{t}\geq h_{t-1}\) to the learner. 2. Learner outputs \(w_{t}\in\mathcal{W}\). 3. Nature reveals loss scalar \(g_{t}\) with \(\|g_{t}\|\leq h_{t}\) to the learner. 4. Learner suffers loss \((g_{t},w_{t})\). The learner is evaluated with the _regret_\(\sum_{t=1}^{T}g_{t}(w_{t}-w_{*})\). The goal is to obtain: \[\sum_{t=1}^{T}(g_{t},w_{t}-w_{*})\underset{\text{goal}}{\leq}\widetilde{O} \left(\|w_{*}\|\sqrt{h_{T}^{2}+\sum_{t=1}^{T}\|g_{t}\|^{2}}\right).\] (16)
```

**Algorithm 1** Reduction From General \(\mathcal{W}\) to \(\mathbb{R}\)

In Section E, we provide an explicit algorithm (Algorithm 3) for Protocol 4 that suffices for our purposes and achieves the bound (16). In the rest of this section, we take the existence of such an algorithm as given, and use it to build our method for Protocol 2.

Our algorithm for Protocol 2 is given in Algorithm 2. The full regret bound is provided by Theorem 10. However, before providing the general bound, which is somewhat technical, we provide two more interpretable corollaries in order to provide a preview of what the method is capable of.

**Corollary 6**.: _For any \(\epsilon\) with \(\psi(\epsilon)>0\), there exists an algorithm for Protocol 2 such that for all \(t\), the outputs \(x_{1},\ldots,x_{T}\) satisfy:_

\[\sum_{t=1}^{T}g_{t}\big{(}x_{t}-x_{\star}\big{)}+a_{t}\big{(}\psi( x_{t})-\psi(x_{\star})\big{)}\] \[\leq O\left[\epsilon h_{T}+\psi(\epsilon)\gamma+|x_{\star}|\sqrt{ V_{g}\log\left(e+\frac{|x_{\star}|\sqrt{V_{g}\log^{2}(T)}}{h_{1}\epsilon}\right)}+|x_{ \star}|h_{T}\log\left(e+\frac{|x_{\star}|\sqrt{V_{g}}\log^{2}(T)}{h_{1}\epsilon }\right)\right.\] \[\left.+\psi(x_{\star})\sqrt{S_{a}\log\left(e+\frac{\psi(x_{\star} )\sqrt{S_{a}}\log^{2}(T)}{\gamma\psi(\epsilon)}\right)}+\psi(x_{\star})\gamma \log\left(e+\frac{\psi(x_{\star})\sqrt{S_{a}}\log^{2}(T)}{\gamma\psi(\epsilon) }\right)\right]\]

_Where \(V_{g}=h_{T}^{2}+\sum_{t=1}^{T}g_{t}^{2}\) and \(S_{a}=\gamma^{2}+\gamma\sum_{t=1}^{T}a_{t}\)._

Proof.: Apply Algorithm 2 with the Base set to Algorithm 3 using \(p=1/2\). Then, in the notation of Theorem 10, the regret bound of Theorem 11 shows that \(A,B,C\) are all \(O(1)\) while \(D\) is \(O(\log^{2}(T))\) and \(p=1/2\). Set \(\epsilon_{x}=\epsilon\) and \(\epsilon_{\psi}=\psi(\epsilon)\). The result immediately follows. 

**Corollary 7**.: _For any \(\epsilon\) with \(\psi(\epsilon)>0\), there exists an algorithm for Protocol 2 such that for all \(t\), the outputs \(x_{1},\ldots,x_{T}\) satisfy:_

\[\sum_{t=1}^{T}g_{t}\big{(}x_{t}-x_{\star}\big{)}+a_{t}\big{(}\psi( x_{t})-\psi(x_{\star})\big{)}\] \[\leq O\left[\epsilon\sqrt{V_{g}}+\psi(\epsilon)\sqrt{S_{a}}+|x_{ \star}|\sqrt{V_{g}\log\left(e+\frac{|x_{\star}|}{\epsilon}\right)}+|x_{\star}|h _{T}\log\left(e+\frac{|x_{\star}|}{\epsilon}\right)\right.\] \[\left.+\psi(x_{\star})\sqrt{S_{a}\log\left(e+\frac{\psi(x_{\star} )}{\psi(\epsilon)}\right)}+\psi(x_{\star})\gamma\log\left(e+\frac{\psi(x_{ \star})}{\psi(\epsilon)}\right)\right],\]

_where \(V_{g}=h_{T}^{2}+\sum_{t=1}^{T}g_{t}^{2}\) and \(S_{a}=\gamma^{2}+\gamma\sum_{t=1}^{T}a_{t}\)._

Proof.: Apply Algorithm 2 with the Base set to Algorithm 3 using \(p=0\). Then, in the notation of Theorem 10, the regret bound of Theorem 11 shows that \(A,B,C\) and \(D\) are all \(O(1)\) while \(p=0\). Set \(\epsilon_{x}=\epsilon\) and \(\epsilon_{\psi}=\psi(\epsilon)\). The result immediately follows. 

**Lemma 8**.: _Suppose \(\psi:\mathbb{R}\to\mathbb{R}\) is a convex function that achieves its minimum at 0. Let \(h>0\) and \(\gamma>0\) be given and define the norm \(\|(x,y)\|=h^{2}x^{2}+\gamma^{2}y^{2}\) and the distance function \(S(\hat{x},\hat{y})=\inf_{y\in\psi(x)}\|(x,y)-(\hat{x},\hat{y})\|\). For any \((\hat{x},\hat{y})\), let \((\delta^{x},\delta^{y})\) be an arbitrary subgradient of \(S\) at \((\hat{x},\hat{y})\). Then, \(\delta^{y}\leq 0\)._

Proof.: Throughout this proof, we will assume \(\hat{x}>0\). The proof is completely symmetric in the sign of \(\hat{x}\).

First, we dispense with the case in which there is no projection: suppose \(\hat{y}\geq\psi(\hat{x})\). Then we must have \(\hat{y}=y\) and \(\hat{x}=x\) and \(S(\hat{x},\hat{y})=0\). Further, for any \(\hat{y}>\hat{y}\), \(S(\hat{x},\hat{y})=0\). However, if \(\delta_{y}>0\), then by definition of subgradient, we must have \(0=S(\hat{x},\hat{y})\geq S(\hat{x},\hat{y})+\delta_{y}(\hat{y}-\hat{y})>0\), which cannot be. Therefore \(\delta_{y}\leq 0\). So, it remains to consider the case \(\hat{y}<\psi(\hat{x})\).

Define \((x,y)=\text{argmin}_{y\geq\psi(x)}\|(x,y)-(\hat{x},\hat{y})\|\). Further, by [16, Theorem 4], we have:

\[\big{(}\delta^{x},\delta^{y}\big{)}=\left(\frac{h^{2}(\hat{x}-x)}{\sqrt{h^{2}(x -\hat{x})^{2}+\gamma^{2}(\hat{y}-y)^{2}}},\frac{\gamma^{2}(\hat{y}-y)}{\sqrt{h ^{2}(x-\hat{x})^{2}+\gamma^{2}(\hat{y}-y)^{2}}}\right).\]

Therefore, it suffices to show that \(\hat{y}\leq y\).

To start, consider the case \(\psi(0)>\hat{y}\). Then, we have \(\hat{y}<\psi(0)\leq\psi(x)\leq y\) as desired. So, in the following we consider the remaining case \(\psi(0)\leq\hat{y}<\psi(\hat{x})\).

Observe that since \(\psi\) is convex, it must be continuous. Therefore, by intermediate value theorem there must be some \(\tilde{x}\geq 0\) with \(\psi(\tilde{x})=\hat{y}\). Further, we have \(\psi(\tilde{x})=\hat{y}<\psi(\tilde{x})\), so that \(\tilde{x}<\hat{x}\).

Now, by convexity, if \(x\geq\tilde{x}\), we must \(\psi(x)\geq\psi(\tilde{x})\) because \(\psi\) must be non-decreasing for positive \(x\) since it achieves its minimum at \(0\). Therefore, \(y\geq\psi(x)\geq\psi(\tilde{x})=\hat{y}\) and so we are done. So, let us suppose \(x<\tilde{x}\).

Further, suppose that \(\hat{y}>y\). Then, observe that:

\[h^{2}(\tilde{x}-\hat{x})^{2}+\gamma^{2}(\max(y,\psi(\tilde{x}))-\hat{y})^{2}<h ^{2}(x-\hat{x})^{2}+\gamma^{2}(y-\hat{y})^{2},\]

so that the point \((\tilde{x},\max(y,\psi(\tilde{x})))\) would contradict the optimality of \((x,y)\). Thus, it also cannot be that \(\hat{y}>y\) and so we are done. 

**Lemma 9**.: _Let \(h>0\) and \(\gamma>0\) be given and define the norm \(\|(x,y)\|=h^{2}x^{2}+\gamma^{2}y^{2}\) with corresponding dual norm \(\|\cdot\|_{\star}\). Let \((g,a)\) be any point satisfying \(|g|\leq h\), \(a\in[0,\gamma]\), and \(a=0\) unless \(|g|=h\). Let \((\delta^{x},\delta^{y})\) be any points satisfying \(\|(\delta^{x},\delta^{y})\|_{\star}=\|(g,a)\|_{\star}\). Then,_

\[|\delta^{x}| \leq|g|\sqrt{2},\] \[|\delta^{y}| \leq\gamma\sqrt{2}.\]

Proof.: The dual norm \(\|\cdot\|_{\star}\) is \(\|(g,a)\|_{\star}=\frac{g^{2}}{h^{2}}+\frac{a^{2}}{\gamma^{2}}\). So, we have:

\[\frac{(\delta^{x})^{2}}{h^{2}}+\frac{(\delta^{y})^{2}}{\gamma^{2}}=\frac{g^{2} }{h^{2}}+\frac{a^{2}}{\gamma^{2}}\leq 2.\]

This immediately implies \(|\delta^{y}|\leq\gamma\sqrt{2}\). We also have

\[(\delta^{x})^{2}\leq g^{2}+\frac{h^{2}a^{2}}{\gamma^{2}}.\]

Now, since \(a=0\) unless \(g^{2}=h^{2}\), this yields either \(|\delta^{x}|\leq|g|\) if \(|g|<h\) or \(|\delta^{x}|\leq\sqrt{g^{2}+h^{2}a^{2}/\gamma^{2}}=h\sqrt{2}\) if \(|g|=h\), so either way \(|\delta^{x}|\leq|g|\sqrt{2}\). 

**Theorem 10**.: _Let \(A,B,CD,\epsilon>0\), and \(p\geq 1\), be given. Suppose that for any sequence \(z_{1},\ldots,z_{T}\) and magnitude hints \(m_{1}\leq\cdots\leq m_{T}\) satisfying \(|z_{t}|\leq m_{t}\), Base outputs \(w_{1},\ldots,w_{T}\) and guarantees regret:_

\[\sum_{t=1}^{T}z_{t}(w_{t}-u)\leq\epsilon_{\textsc{Base}}Cm_{T}^{2p}Z^{1/2-p}+ A|u|\sqrt{Z\log\left(e+\frac{D|u|Z^{p}}{m_{1}^{2p}\epsilon_{\textsc{Base}}} \right)}+B|u|h_{T}\log\left(e+\frac{D|u|Z^{p}}{m_{1}^{2p}\epsilon_{\textsc{ Base}}}\right)\]_for any \(u\in\mathbb{R}\), where \(Z=m_{T}^{2}+\sum_{t=1}^{T}z_{t}^{2}\)._

_Let \(\epsilon_{x}\), \(\epsilon_{\psi}\) and \(\gamma\) be given non-negative inputs to Algorithm 2. Then, for any \(T\), with \(V_{g}=h_{T}^{2}+\sum_{t=1}^{T}g_{t}^{2}\) and \(S_{a}=\gamma^{2}+\gamma\sum_{t=1}^{T}a_{t}\), Algorithm 2's output sequence \(\hat{x}_{1},\ldots,\hat{x}_{T}\) guarantees:_

\[\sum_{t=1}^{T}g_{t}(\hat{x}_{t}-x_{\star})+a_{t}(\psi(\hat{x}_{t}) -\psi(x_{\star}))\leq\] \[\mathcal{C}_{x}\epsilon_{x}h_{T}^{2p}V_{g}^{1/2-p}+\mathcal{A}_{x }|x_{\star}|\sqrt{V_{g}\log\left(e+\frac{\mathcal{D}_{x}|x_{\star}|V_{g}^{p}}{ \epsilon_{x}h_{1}^{2p}}\right)+\mathcal{B}_{x}|x_{\star}|\log\left(e+\frac{ \mathcal{D}_{x}|x_{\star}|V_{g}^{p}}{\epsilon_{x}h_{1}^{2p}}\right)}\] \[\quad+\mathcal{C}_{\psi}\epsilon_{\psi}\gamma^{2p}S_{a}^{1/2-p}+ \mathcal{A}_{\psi}\psi(x_{\star})\sqrt{S_{a}\log\left(e+\frac{\mathcal{D}_{\psi }\psi(x_{\star})S_{a}^{p}}{\epsilon_{\psi}\gamma^{2p}}\right)+\mathcal{B}_{ \psi}\psi(x_{\star})\log\left(e+\frac{\mathcal{D}_{\psi}\psi(x_{\star})S_{a}^{p }}{\epsilon_{\psi}\gamma^{2p}}\right)},\]

_for any \(x_{\star}\in\mathbb{R}\), where the constants in the above expression are given by:_

\[\mathcal{A}_{x} =3A,\] \[\mathcal{B}_{x} =3B,\] \[\mathcal{C}_{x} =3C,\] \[\mathcal{D}_{x} =D,\] \[\mathcal{A}_{\psi} =\frac{1}{2}+144A^{2},\] \[\mathcal{B}_{\psi} =144A^{2}+24B,\] \[\mathcal{C}_{\psi} =3C\left[\left(144A^{2}+24B\right)\log\left(e+12CD\big{(}1152pA^{ 2}+48pb\big{)}^{p}\right)+\frac{1}{2}+\frac{(2p+1)\big{(}2-4p\big{)}^{\frac{1 -2p}{1+2p}}}{2}\right],\] \[\mathcal{D}_{\psi} =4D\left[1152A^{2}p+48pB\right]^{p}.\]

Proof.: First, observe that since \((x_{t},y_{t})\) is the result of a projection to the domain \(y\geq\psi(x)\), it must hold that \(y_{t}\geq\psi(x_{t})\) for all \(t\). Thus, since \(a_{t}>0\) and \(\psi\) is non-negative, we have for any \(x_{\star}\):

\[g_{t}(x_{t}-x_{\star})+a_{t}(\psi(x)-\psi(x_{\star}))\leq g_{t}(x_{t}-x_{\star })+a_{t}(y_{t}-x_{\star}).\]

Therefore, it suffices to bound \(\sum_{t=1}^{T}g_{t}(x_{t}-x_{\star})+a_{t}(y_{t}-x_{\star})\), which we will now accomplish.

By [16, Theorem 3], we have for any \(x_{\star}\in\mathbb{R}\)

\[\sum_{t=1}^{T}g_{t}(x_{t}-x_{\star})+a_{t}(y_{t}-\psi(x_{\star}))\leq\sum_{t=1 }^{T}(g_{t}+\delta_{t}^{x})(\hat{x}_{t}-x_{\star})+\sum_{t=1}^{T}(a_{t}+\delta _{t}^{y})(\hat{y}_{t}-\psi(x_{\star})),\]

and also \(\|(\delta_{t}^{x},\delta_{t}^{y})\|_{t_{\star}}=\|(g_{t},a_{t})\|_{t_{\star}}\) by [16, Proposition 1]. Therefore, by Lemma 9, we have \(|g_{t}+\delta_{t}^{x}|\leq 3|g_{t}|\leq 3h_{t}\). Defining \(V_{g}=h_{T}^{2}+\sum_{t=1}^{T}(g_{t}+\delta_{t}^{x})^{2}\), and by the guarantee of Base, we have for any \(x_{\star}\):

\[\sum_{t=1}^{T}(g_{t}+\delta_{t}^{x})(\hat{x}_{t}-x_{\star})\] \[\leq C(3h_{T})^{2p}\left[9h_{T}^{2}+\sum_{t=1}^{T}(g_{t}+\delta _{t}^{x})^{2}\right]^{1/2-p}\epsilon_{x}\] \[\quad+A|x_{\star}|\sqrt{\left[9h_{T}^{2}+\sum_{t=1}^{T}(g_{t}+ \delta_{t}^{x})^{2}\right]\log\left(e+\frac{D|x_{\star}|\left[9h_{T}^{2}+ \sum_{t=1}^{T}(g_{t}+\delta_{t}^{x})^{2}\right]^{p}}{(3h_{1})^{2p}\epsilon_{ x}}\right)}\] \[\quad+3Bh_{T}|x_{\star}|\log\left(e+\frac{D|x_{\star}|\left[9h _{T}^{2}+\sum_{t=1}^{T}(g_{t}+\delta_{t}^{x})^{2}\right]^{p}}{(3h_{1})^{p} \epsilon_{x}}\right)\] \[\leq 3Ch_{T}^{2p}V_{g}^{1/2-p}\epsilon_{x}+3A|x_{\star}|\sqrt{V_{ g}\log\left(e+\frac{D|x_{\star}|V_{g}^{p}}{h_{1}^{2p}\epsilon_{x}}\right)}+3Bh_{T}|x_{ \star}|\log\left(e+\frac{D|x_{\star}|V_{g}^{p}}{h_{1}^{2p}\epsilon_{x}}\right)\]Next, observe that by Lemma 9, \(|a_{t}+\delta_{t}^{y}|\leq 3\gamma\). We also have for any \(x_{\star}\in\mathbb{R}\):

\[\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})(\hat{y}_{t}-\psi(x_{\star})) =\frac{1}{2}\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})(y_{t}-2\psi(x_{ \star}))+\frac{1}{2}\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})y_{t}\] \[=\frac{1}{2}\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})(y_{t}-2\psi(x_{ \star}))+\frac{1}{2}\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})(y_{t}-2y_{\star})+y_{ \star}\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})\]

Now, define \(V_{a}=\gamma^{2}+\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})^{2}\). By the guarantee of Base applied twice, we have that for any \(x_{\star}\in\mathbb{R}\) (\(\psi(x_{\star})\geq 0\) below represents the comparator for the regret of Base):

\[\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})(\hat{y}_{t}-\psi(x_{\star}))\] \[\leq C(3\gamma)^{2p}\bigg{[}9\gamma^{2}+\sum_{t=1}^{T}(a_{t}+ \delta_{t}^{y})^{2}\bigg{]}^{1/2-p}\epsilon_{\psi}\] \[\quad\quad+A\psi(x_{\star})\sqrt{\bigg{(}9\gamma^{2}+\sum_{t=1}^ {T}(a_{t}+\delta_{t}^{y})^{2}\bigg{)}\log\bigg{(}e+\frac{2D\psi(x_{\star})\left[ 9\gamma^{2}+\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})^{2}\right]^{p}}{3^{2p}\gamma^ {2p}\epsilon_{\psi}}}\bigg{)}\] \[\quad\quad+3\gamma B\psi(x_{\star})\log\left(e+\frac{2D\psi(x_{ \star})\left[9\gamma^{2}+\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})^{2}\right]^{p}}{ 3^{2p}\gamma^{2p}\epsilon_{\psi}}\right)\] \[\quad\quad+Ay_{\star}\sqrt{\bigg{(}9\gamma^{2}+\sum_{t=1}^{T}(a_ {t}+\delta_{t}^{y})^{2}\bigg{)}\log\bigg{(}e+\frac{2Dy_{\star}\left[9\gamma^{2 }+\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})^{2}\right]^{p}}{3^{2p}\gamma^{2p} \epsilon_{\psi}}}\bigg{)}\] \[\quad\quad+3\gamma B|y_{\star}|\log\bigg{(}e+\frac{2Dy_{\star} \left[9\gamma^{2}+\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})^{2}\right]^{p}}{3^{2p} \gamma^{2p}\epsilon_{\psi}}\bigg{)}\] \[\quad\quad+y_{\star}\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})\] \[\leq 3C\gamma^{2p}V_{a}^{1/2-p}\epsilon_{\psi}+3A\psi(x_{\star}) \sqrt{V_{a}\log\bigg{(}e+\frac{2D\psi(x_{\star})V_{a}^{p}}{\gamma^{2p}\epsilon _{\psi}}\bigg{)}}+3B\psi(x_{\star})\log\bigg{(}e+\frac{2D\psi(x_{\star})V_{a }^{p}}{\gamma^{2p}\epsilon_{\psi}}\bigg{)}\] \[\quad\quad+3Ay_{\star}\sqrt{V_{a}\log\bigg{(}e+\frac{2Dy_{\star} V_{a}^{p}}{\epsilon_{\psi}}\bigg{)}}+3\gamma By_{\star}\log\bigg{(}e+\frac{2Dy_{ \star}V_{a}^{p}}{\gamma^{2p}\epsilon_{\psi}}\bigg{)}\] \[\quad\quad+y_{\star}\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})\]

Now, we observe:

\[\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y}) =\frac{1}{2\gamma}\sum_{t=1}^{T}\big{[}(a_{t}+\delta_{t}^{y}+ \gamma)^{2}-\gamma^{2}\big{]}-\frac{1}{2\gamma}\sum_{t=1}^{T}(a_{t}+\delta_{t }^{y})^{2},\] \[=\frac{1}{2\gamma}\sum_{t=1}^{T}\big{[}(a_{t}+\delta_{t}^{y}+ \gamma)^{2}-\gamma^{2}\big{]}+\frac{\gamma}{2}-\frac{1}{2\gamma}V_{a}.\]

Next, we bound \((a_{t}+\delta_{t}^{y}+\gamma)^{2}-\gamma^{2}\):

\[\big{(}a_{t}+\delta_{t}^{y}+\gamma\big{)}^{2}-\gamma=a_{t}^{2}+(\delta_{t}^{y} )^{2}+2a_{t}\delta_{t}^{y}+2\gamma a_{t}+2\gamma\delta_{t}^{y},\]using \(\delta_{t}^{y}\leq 0\) (from Lemma 8) amd \(|\delta_{t}^{y}|\leq\gamma\sqrt{2}\leq 2\gamma\) (from Lemma 9):

\[\leq a_{t}^{2}+2a_{t}\delta_{t}^{y}+2\gamma a_{t}\]

using \(0\leq a_{t}\leq\gamma\):

\[\leq 3\gamma a_{t},\]

so that we have (recalling that \(S_{a}=\gamma^{2}+\gamma\sum_{t=1}^{T}a_{t}\):

\[y_{*}\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})\leq-\frac{y_{*}}{2\gamma}V_{a}+\frac {3y_{*}}{2\gamma}S_{a}.\]

So, overall we have:

\[\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})(\hat{y}_{t}-\psi(x_{*}))\]

\[\leq 3C\gamma^{2p}V_{a}^{1/2-p}\epsilon_{\psi}+3A(\psi(x_{*})+y_{*})\sqrt{V_{a} \log\left(e+\frac{2D(\psi(x_{*})+y_{*})V_{a}^{p}}{\gamma^{2p}\epsilon_{\psi}} \right)}\]

\[+3B(\psi(x_{*})+y_{*})\log\left(e+\frac{2D\psi(x_{*})V_{a}^{p}}{\gamma^{2p} \epsilon_{\psi}}\right)-\frac{y_{*}}{2\gamma}V_{a}+\frac{3y_{*}}{2\gamma}S_{a}.\]

Since the above holds for _any_\(y_{*}\geq 0\), we may write:

\[\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})(\hat{y}_{t}-\psi(x_{*}))\]

\[\leq\inf_{y_{*}}\sup_{V_{a}}\left[3C\gamma^{2p}V_{a}^{1/2-p}\epsilon_{\psi}+3A (\psi(x_{*})+y_{*})\sqrt{V_{a}\log\left(e+\frac{2D(\psi(x_{*})+y_{*})V_{a}^{p}} {\gamma^{2p}\epsilon_{\psi}}\right)}\right.\]

\[\left.+3B(\psi(x_{*})+y_{*})\log\left(e+\frac{2D\psi(x_{*})V_{a}^{p}}{\gamma^{ 2p}\epsilon_{\psi}}\right)-\frac{y_{*}}{2\gamma}V_{a}+\frac{3y_{*}}{2\gamma}S_ {a}\right]\]

Now, applying Lemma 20 to bound the minimax expression above, we have:

\[\sum_{t=1}^{T}(a_{t}+\delta_{t}^{y})(\hat{y}_{t}-\psi(x_{*}))\leq \left(\frac{1}{2}+144A^{2}\right)\psi(x_{*})\sqrt{S_{a}\log\left(e+\frac{4D \psi(x_{*})S_{a}^{p}}{\epsilon_{\psi}\gamma^{2p}}\left[1152A^{2}p+48pB\right] ^{p}\right)}\]

\[+\gamma\psi(x_{*})(144A^{2}+24B)\log\left(e+\frac{4D\psi(x_{*})S_{a}^{p}}{ \epsilon_{\psi}\gamma^{2p}}\left[1152A^{2}p+48pB\right]^{p}\right)\]

\[+3C\gamma^{2p}S^{1/2-p}\epsilon_{\psi}\left[(144A^{2}+24B)\log\left(e+12CD(11 52pA^{2}+48pb)^{p}\right)+\frac{1}{2}+\frac{(2p+1)(2-4p)^{\frac{1-2p}{1+2p}}} {2}\right]\]

So, overall we achieve:

\[\sum_{t=1}^{T}g_{t}(x_{t}-x_{*})+a_{t}(y_{t}-\psi(x_{*}))\]

\[\leq 3Ch_{T}^{2p}V_{g}^{1/2-p}\epsilon_{x}+3A|x_{*}|\sqrt{V_{g}\log\left(e+ \frac{D|x_{*}|V_{g}^{p}}{h_{1}^{2p}\epsilon_{x}}\right)}+3Bh_{T}|x_{*}|\log \left(e+\frac{D|x_{*}|V_{g}^{p}}{h_{1}^{2p}\epsilon_{x}}\right)\]

\[+\left(\frac{1}{2}+144A^{2}\right)\psi(x_{*})\sqrt{S_{a}\log\left(e+\frac{4D \psi(x_{*})S_{a}^{p}}{\epsilon_{\psi}\gamma^{2p}}\left[1152A^{2}p+48pB\right] ^{p}\right)}\]

\[+\gamma\psi(x_{*})(144A^{2}+24B)\log\left(e+\frac{4D\psi(x_{*})S_{a}^{p}}{ \epsilon_{\psi}\gamma^{2p}}\left[1152A^{2}p+48pB\right]So, with:

\[\mathcal{A}_{x}=3A,\] \[\mathcal{B}_{x}=3B,\] \[\mathcal{C}_{x}=3C,\] \[\mathcal{D}_{x}=D,\] \[\mathcal{A}_{\psi}=\frac{1}{2}+144A^{2},\] \[\mathcal{B}_{\psi}=144A^{2}+24B,\] \[\mathcal{C}_{\psi}=3C\left[\left(144A^{2}+24B\right)\log\left(e+12 CD(1152pA^{2}+48pb)^{p}\right)+\frac{1}{2}+\frac{\left(2p+1\right)\left(2-4p \right)^{\frac{1-2p}{1+2p}}}{2}\right],\] \[\mathcal{D}_{\psi}=4D\left[1152A^{2}p+48pB\right]^{p},\]

we have

\[\sum_{t=1}^{T}g_{t}(x_{t}-x_{\star})+a_{t}(y_{t}-\psi(x_{\star}))\] \[\leq\mathcal{C}_{x}\epsilon_{x}h_{T}^{2p}V_{g}^{1/2-p}+\mathcal{A }_{x}|x_{\star}|\sqrt{V_{g}\log\left(e+\frac{\mathcal{D}_{x}|x_{\star}|V_{g}^ {p}}{\epsilon_{x}h_{1}^{2p}}\right)}+\mathcal{B}_{x}|x_{\star}|\log\left(e+ \frac{\mathcal{D}_{x}|x_{\star}|V_{g}^{p}}{\epsilon_{x}h_{1}^{2p}}\right),\] \[\qquad+\mathcal{C}_{\psi}\epsilon_{\psi}\gamma^{2p}S_{a}^{1/2-p} +\mathcal{A}_{\psi}\psi(x_{\star})\sqrt{S_{a}\log\left(e+\frac{\mathcal{D}_{ \psi}\psi(x_{\star})S_{a}^{p}}{\epsilon_{\psi}\gamma^{2p}}\right)}\] \[\qquad+\mathcal{B}_{\psi}\psi(x_{\star})\log\left(e+\frac{ \mathcal{D}_{\psi}\psi(x_{\star})S_{a}^{p}}{\epsilon_{\psi}\gamma^{2p}}\right).\]

from which the conclusion follows.

## Appendix E A Parameter-Free Algorithm With Optimal Log Factors for Protocol 4

In this section we quote an algorithm that obtains a performance guarantee suitable for use as Base in Theorem 10. We emphasize that the development in this section is only a very mild improvement (affecting only logarithmic factors) on previous work: our key contribution is how to use this algorithm to obtain better adaptivity to unknown Lipschitz constants.

In fact, algorithms satisfying the requirements of Theorem 10 up to logarithmic factors have been described by several previous authors: see [18, 21, 23, 26]. Here, we provide a slightly improved analysis of the algorithm of [21] which achieves tighter (and in fact optimal) logarithmic terms.

,

**Theorem 11**.: _Suppose \(g_{1},\ldots,g_{T}\) is any sequence of real numbers and \(0<h_{1}\leq\cdots\leq h_{T}\) is another sequence of real numbers satisfying \(|g_{t}|\leq h_{t}\). Then, if \(p=1/2\), Algorithm 3 guarantees for all \(u\)_

\[\sum_{t=1}^{T}g_{t}(w_{t}-u)\leq 8h_{T}\epsilon+6|u|\sqrt{\left(h_{T}^{2}+\sum_{t=1}^{T}g_{t}^{2} \right)\log\left(\frac{|u|\sqrt{3+\sum_{t=1}^{T}g_{t}^{2}/h_{t}^{2}}\log^{2} \left(3+\sum_{t=1}^{T}g_{t}^{2}/h_{t}^{2}\right)}{\epsilon}+1\right)}\] \[\qquad+6|u|h_{T}\log\left(\frac{|u|\sqrt{3+\sum_{t=1}^{T}g_{t}^{2 }/h_{t}^{2}}\log^{2}\left(3+\sum_{t=1}^{T}g_{t}^{2}/h_{t}^{2}\right)}{\epsilon} +1\right),\]_while if \(p<1/2\) Algorithm 3 guarantees instead:_

\[\sum_{t=1}^{T}g_{t}(w_{t}-u) \leq\frac{4h_{T}^{2p}e\left(\sum_{t=1}^{T}g_{t}^{2}\right)^{1/2-p}}{ 1-2p}\] \[\qquad+6|u|h_{T}\log\left(\frac{|u|\left(1+\sum_{t=1}^{T}g_{t}^{2}/h _{t}^{2}\right)^{p}}{e}+1\right).\]

Notice that the term \(\log^{2}\left(3+\sum_{t=1}^{T}g_{t}^{2}/h_{t}^{2}\right)\leq\log^{2}(3+T)\), and so we upper bound this term with a constant for the purposes of use in Theorem 10. Further, the term \(\sum_{t=1}^{T}g_{t}^{2}/h_{t}^{2}\leq\sum_{t=1}^{T}g_{t}^{2}/h_{1}^{2}\), and so the logarithmic terms always fit into the framework of Theorem 10.

Proof.: Observe that Algorithm 3 is an instance of FTRL with regularizer:

\[\psi_{t}(w)=k\int_{0}^{|w|}\min_{\eta\leq 1/h_{t}}\left[\frac{\log(x/ \alpha_{t}+1)}{\eta}+\eta V_{t}\right]dx.\]

That is,

\[w_{t}=\operatorname*{\arg\!\min}_{w}\psi_{t+1}(w)+\sum_{i=1}^{t-1}g_{i}w.\]

In the "centered mirror descent" framework of [21] (their Algorithm 1), this corresponds to setting \(\varphi(w)=0\). Further, [21] provides an analysis of this update for the particular family of regularizer functions \(\psi_{t}\) we consider above in their Theorem 6. Although formally speaking, their Theorem 6 specifies a particular equation for \(\alpha_{t}\), inspection of the proof shows that most of their argument applies so long as \(\alpha_{t}\) is non-increasing. We reproduce this verification in Lemma 12, which yields:

\[\sum_{t=1}^{T}g_{t}(w_{t}-u)\leq\psi_{T}(u)+\sum_{t=1}^{T}\frac{2 \alpha_{t}}{\sqrt{V_{t}}}.\]Next, define \(h_{T+1}=0\) and \(g_{T+1}=0\) in order to define \(\alpha_{T+1}\) and \(\psi_{T+1}\geq\psi_{T}\). So, we can replace \(\psi_{T}(u)\) with \(\psi_{T+1}(u)\) in the above expression. Next, to bound \(\psi_{T+1}(u)\), we observe that:

\[\psi_{T+1}(u) =k\int_{0}^{|u|}\min_{\eta 51/h_{T+1}}\left[\frac{\log(x/\alpha_{T+1} +1)}{\eta}+\eta V_{T+1}\right]\,dx,\] \[\leq k|u|\min_{\eta 51/h_{T+1}}\left[\frac{\log(u/\alpha_{T+1}+1)}{ \eta}+\eta V_{T+1}\right].\]

Now, notice that if the minimizing \(\eta\) of \(\min_{\eta 51/h_{T+1}}\left[\frac{\log(u/\alpha_{T+1}+1)}{\eta}+\eta V_{T+1}\right]\) occurs on the boundary \(\eta=1/h_{T+1}\), then it must be that \(\frac{\log(u/\alpha_{T+1}+1)}{\eta}>\eta V_{T+1}\), since \(\frac{\log(u/\alpha_{T+1}+1)}{\eta}\) is decreasing in \(\eta\) and \(\eta V_{T+1}\) is increasing in \(\eta\). Thus in this case \(\min_{\eta 51/h_{T+1}}\left[\frac{\log(u/\alpha_{T+1}+1)}{\eta}+\eta V_{T+1} \right]\leq 2h_{T}\log(u/\alpha_{T+1}+1)\). Alternatively, when the minimizing \(\eta\) is not on the boundary we have \(\min_{\eta 51/h_{T+1}}\left[\frac{\log(u/\alpha_{T+1}+1)}{\eta}+\eta V_{T+1} \right]=2\sqrt{V_{T+1}\log(u/\alpha_{T+1}+1)}\). So, in general we have:

\[\psi_{T+1}(u)\leq 2k|u|\sqrt{V_{T+1}\log(|u|/\alpha_{T+1}+1)}+2k|u|h_{T}\log(|u |/\alpha_{T+1}+1).\]

So far this analysis is identical to that of [21], and has been agnostic to the value of \(\alpha_{t}\), so long as \(\alpha_{t}\) is non-increasing. Now, however, we come to the place at which we diverge in analysis: our choice of \(\alpha_{t}\) is slightly larger and so results in better logarithmic factors in \(\psi\). The trade-off is that we need to provide a fresh analysis of \(\sum_{t=1}^{T}\frac{2\alpha_{t}g_{t}^{2}}{\sqrt{V_{t}}}\) to show that this term is still controlled. We accomplish this in Lemma 21 (for \(p=1/2\)) and Lemma 22 (for \(p<1/2\)). For \(p=1/2\), we then obtain:

\[\sum_{t=1}^{T}g_{t}(w_{t}-u) \leq 8h_{T}\epsilon+2k|u|\sqrt{\left(h_{T}^{2}+\sum_{t=1}^{T}g_{t}^ {2}\right)\log\left(\frac{|u|\sqrt{3+\sum_{t=1}^{T}g_{t}^{2}/h_{t}^{2}}\log^{ 2}\left(3+\sum_{t=1}^{T}g_{t}^{2}/h_{t}^{2}\right)}{\epsilon}+1\right)}\] \[\quad+2k|u|h_{T}\log\left(\frac{|u|\sqrt{3+\sum_{t=1}^{T}g_{t}^ {2}/h_{t}^{2}}\log^{2}\left(3+\sum_{t=1}^{T}g_{t}^{2}/h_{t}^{2}\right)}{ \epsilon}+1\right),\]

while for \(p<1/2\) we obtain:

\[\sum_{t=1}^{T}g_{t}(w_{t}-u) \leq\frac{4h_{T}^{2p}\epsilon\left(\sum_{t=1}^{T}g_{t}^{2}\right)^ {1/2-p}}{1-2p}\] \[\quad+2k|u|\sqrt{\left(h_{T}^{2}+\sum_{t=1}^{T}g_{t}^{2}\right) \log\left(\frac{|u|\left(1+\sum_{t=1}^{T}g_{t}^{2}/h_{t}^{2}\right)^{p}}{ \epsilon}+1\right)}\] \[\quad+2k|u|h_{T}\log\left(\frac{|u|\left(1+\sum_{t=1}^{T}g_{t}^{ 2}/h_{t}^{2}\right)^{p}}{\epsilon}+1\right).\]

The conclusion now follows by substituting in \(k=3\). 

The following technical Lemma is lifted almost entirely from [21]. Unfortunately, this result was not explicitly declared as a separate Lemma in the prior literature and is instead merely a subset of the proof of a larger Theorem (specifically, Theorem 6 of [21]). So, we include the argument here for completeness. The steps are nearly identical to the prior literature, with only very mild improvement to some constants.

**Lemma 12**.: _Let \(g_{1},\ldots,g_{T}\) be an arbitrary sequence of scalars. Suppose \(0<h_{1}\leq\cdots\leq h_{T}\) is non-decreasing sequence with \(|g_{t}|\leq h_{t}\) for all \(t\), and let \(\alpha_{1}\geq\cdots\geq\alpha_{T},\) be a non-increasing sequence. Let \(k\geq 3\). Set \(V_{t}=h_{t}^{2}+\sum_{i=1}^{t-1}g_{i}^{2}\) and define_

\[\psi_{t}(w) =k\int_{0}^{|w|}\min_{\eta\leq 1/h_{t}}\left[\frac{\log(x/ \alpha_{t}+1)}{\eta}+\eta V_{t}\right]\,dx\] \[w_{t} =\underset{w}{\text{argmin}}\,\psi_{t}(w)+\sum_{i=1}^{t-1}g_{i}w.\]_Then for all \(u\in\mathbb{R}\):_

\[\sum_{t=1}^{T}g_{t}(w_{t}-u)\leq\psi_{T}(u)+\sum_{t=1}^{T}\frac{2\alpha_{t}g_{t}^{ 2}}{\sqrt{V_{t}}}.\]

Proof.: Define \(\psi_{T+1}=\psi_{T}\) and let \(D_{f}(a|b)\) indicate the Bregman divergence \(D_{f}(a|b)=f(a)-f(b)-f^{\prime}(b)(a-b)\). Define \(\Delta_{t}(w)=D_{\psi_{t+1}}(w|w_{1})\). Then, by [21] Lemma 1, we have:

\[\sum_{t=1}^{T}g_{t}(w_{t}-u)\leq\psi_{T}(u)+\sum_{t=1}^{T}g_{t}(w_{t}-w_{t+1})- D_{\psi_{t}}(w_{t+1}|w_{t})-\Delta_{t}(w_{t+1})\]

So, it suffices to establish that:

\[g_{t}(w_{t}-w_{t+1})-D_{\psi_{t}}(w_{t+1}|w_{t})-\Delta_{t}(w_{t+1})\leq\frac{ 2\alpha_{t}g_{t}}{\sqrt{V_{t}}} \tag{17}\]

Following the notation and argument of [21], define \(F_{t}(w)=\log(w/\alpha_{t}+1)\) and

\[\Psi_{t}(x)=k\int_{0}^{x}\min_{\eta\leq 1/h_{t}}\left[\frac{F_{t}(x)}{\eta}+ \eta V_{t}\right]dx\]

Then we have \(\psi(w)=\Psi_{t}(\|w\|)\) and elementary calculation yields:

\[\Psi_{t}^{\prime}(x) =\left\{\begin{array}{ll}2k\sqrt{V_{t}F_{t}(x)}&\text{if }h_{t} \sqrt{F_{t}(x)}\leq\sqrt{V_{t}}\\ kh_{t}F_{t}(x)+\frac{kV_{t}}{h_{t}}&\text{otherwise}\end{array}\right.\] \[\Psi_{t}^{\prime\prime}(x) =\left\{\begin{array}{ll}\frac{k\sqrt{V_{t}}}{(x+\alpha_{t}) \sqrt{F_{t}(x)}}&\text{if }h_{t}\sqrt{F_{t}(x)}\leq\sqrt{V_{t}}\\ \frac{kh_{t}}{x+\alpha_{t}}&\text{otherwise}\end{array}\right.\] \[\Psi_{t}^{\prime\prime\prime}(x) =\left\{\begin{array}{ll}\frac{-k\sqrt{V_{t}}(1+2F_{t}(x))}{2(x +\alpha_{t})^{2}F_{t}(x)^{3/2}}&\text{if }h_{t}\sqrt{F_{t}(x)}\leq\sqrt{V_{t}}\\ \frac{-kh_{t}}{(x+\alpha_{t})^{2}}&\text{otherwise}\end{array}\right.\]

Therefore, \(\Psi_{t}(x)\geq 0\), \(\Psi_{t}^{\prime}(x)\geq 0\), \(\Psi_{t}^{\prime\prime}(x)\geq 0\) and \(\Psi_{t}^{\prime\prime\prime}(x)\leq 0\). Further, if we define \(x_{0}=\alpha_{t}(e-1)\), then for any \(>x_{0}\) we have \(\sqrt{F_{t}(x)}\geq\frac{1}{\sqrt{F_{t}(x)}}\) and:

\[-\frac{\Psi_{t}^{\prime\prime\prime}(x)}{\Psi_{t}^{\prime\prime}(x )^{2}} \leq\left\{\begin{array}{ll}\frac{1}{2k\sqrt{V_{t}}}\left(\frac{1 }{\sqrt{F_{t}(x)}}+2\sqrt{F_{t}(x)}\right)&\text{if }h_{t}\sqrt{F_{t}(x)} \leq\sqrt{V_{t}}\\ \frac{1}{kh_{t}}&\text{otherwise}\end{array}\right.\] \[\leq\left\{\begin{array}{ll}\frac{3\sqrt{F_{t}(x)}}{2k\sqrt{V_{ t}}}&\text{if }h_{t}\sqrt{F_{t}(x)}\leq\sqrt{V_{t}}\\ \frac{kh_{t}}{kh_{t}}&\text{otherwise}\end{array}\right.\]

using \(k\geq 3\):

\[\leq\frac{1}{2}\min\left(\sqrt{\frac{F_{t}(x)}{V_{t}}},\frac{1}{h_{t}}\right)\]

Now, if we define \(Z_{t}(x)=\int_{0}^{x}\min\left(\sqrt{\frac{F_{t}(\overline{x})}{V_{t}}},\frac {1}{h_{t}}\right)\,d\overline{x}\), then we have

\[-\frac{\Psi_{t}^{\prime\prime\prime}(x)}{\Psi_{t}^{\prime\prime}(x)^{2}}\leq \frac{1}{2}Z_{t}^{\prime}(x)\]

Clearly \(Z_{t}\) is convex, \(1/h_{t}\) Lipschitz, and achieves its minimum value of \(0\) at \(0\). Therefore, by [21] Lemma 2, we have:

\[g_{t}(w_{t}-w_{t+1})-D_{\psi_{t}}(w_{t+1}|w_{t})-Z_{t}(|w_{t+1}|)g _{t}^{2} \leq\frac{2g_{t}^{2}}{\Psi^{\prime\prime}(x_{0})},\] \[\leq\frac{2g_{t}^{2}(x_{0}+\alpha_{t})}{k\sqrt{V_{t}}},\] \[=\frac{2g_{t}^{2}\alpha_{t}e}{k\sqrt{V_{t}}},\] \[\leq\frac{2g_{t}^{2}\alpha_{t}}{\sqrt{V_{t}}}.\]So, now if we could show that \(\Delta_{t}(w)\geq Z_{t}(|w|)g_{t}^{2}\), this would establish (17). In turn, since \(\Delta_{t}(w)=\Psi_{t+1}(|w|)-\Psi_{t}(|w|)\), it suffices to establish:

\[\Psi_{t+1}^{\prime}(x)-\Psi_{t}^{\prime}(x)\geq Z^{\prime}(x)g_{t}^{2}=g_{t}^{ 2}\min\left(\sqrt{\frac{F_{t}(x)}{V_{t}}},\frac{1}{h_{t}}\right).\]

To this end, we compute:

\[\Psi_{t+1}^{\prime}(x)-\Psi_{t}^{\prime}(x) =k\min_{\eta\leq 1/h_{t+1}}\left[\frac{F_{t+1}(x)}{\eta}+\eta V_{t +1}\right]-k\min_{\eta\leq 1/h_{t}}\left[\frac{F_{t}(x)}{\eta}+\eta V_{t}\right],\] \[\geq k\min_{\eta\leq 1/h_{t}}\left[\frac{F_{t+1}(x)}{\eta}+\eta V_{ t+1}\right]-k\min_{\eta\leq 1/h_{t}}\left[\frac{F_{t}(x)}{\eta}+\eta V_{t}\right].\]

Next, let us define \(\delta_{m}=h_{t+1}^{2}-h_{t}^{2}\) so that \(V_{t+1}=V_{t}+\delta_{m}+g_{t}^{2}\). Then we have \(\frac{F_{t+1}(x)}{\eta}+\eta V_{t+1}\geq\min_{\eta^{\prime}}\left[\frac{F_{t+1 }(x)}{\eta^{\prime}}+\eta^{\prime}V_{t}\right]+\eta(\delta_{m}+g_{t}^{2})\). Armed with this calculation, we proceed:

\[\Psi_{t+1}^{\prime}(x)-\Psi_{t}^{\prime}(x)\geq k(\delta_{m}+g_{t}^{2})\min \left[\sqrt{\frac{F_{t+1}(x)}{V_{t+1}}},\frac{1}{h_{t}}\right]+k\min_{\eta\leq 1 /h_{t}}\left[\frac{F_{t+1}(x)}{\eta}+\eta V_{t}\right]-k\min_{\eta\leq 1/h_{t}} \left[\frac{F_{t}(x)}{\eta}+\eta V_{t}\right],\]

now, since \(\alpha_{t}\geq\alpha_{t+1}\), we have \(F_{t+1}\geq F_{t}\) so that:

\[\geq k(\delta_{m}+g_{t}^{2})\min\left[\sqrt{\frac{F_{t+1}(x)}{V_{t+1}}},\frac{ 1}{h_{t}}\right].\]

Next, observe that

\[\frac{d}{d\delta_{m}}\frac{\delta_{m}+g_{t}^{2}}{\sqrt{V_{t}+\delta_{m}+g_{t}^ {2}}}=\frac{\delta_{m}^{2}+2V_{t}+g_{t}^{2}}{2(V_{t}+\delta_{m}+g_{t}^{2})^{3/ 2}}\geq 0.\]

Therefore

\[\frac{\delta_{m}+g_{t}^{2}}{\sqrt{V_{t+1}}} =\frac{\delta_{m}+g_{t}^{2}}{\sqrt{V_{t}+\delta_{m}+g_{t}^{2}}},\] \[\geq\frac{g_{t}^{2}}{\sqrt{V_{t}}+g_{t}^{2}},\] \[\geq\frac{g_{t}^{2}}{\sqrt{V_{t}}}\sqrt{\frac{V_{t}}{V_{t}+g_{t}^ {2}}},\] \[\geq\frac{g_{t}^{2}}{\sqrt{V_{t}}}\sqrt{\frac{h_{t}^{2}}{h_{t}^{2 }+g_{t}^{2}}},\] \[\geq\frac{g_{t}^{2}}{\sqrt{2V_{t}}}.\]

This implies that

\[(\delta_{m}+g_{t}^{2})\sqrt{\frac{F_{t}(x)}{V_{t+1}}}\geq\frac{g_{t}^{2}}{ \sqrt{2}}\sqrt{\frac{F_{t}(x)}{V_{t}}}.\]

So, altogether we have:

\[\Psi_{t+1}^{\prime}(x)-\Psi_{t}^{\prime}(x) \geq\frac{kg_{t}^{2}}{\sqrt{2}}\min\left[\sqrt{\frac{F_{t+1}(x)}{ V_{t}}},\frac{1}{h_{t}}\right],\] \[\geq g_{t}^{2}\min\left[\sqrt{\frac{F_{t+1}(x)}{V_{t}}},\frac{1}{ h_{t}}\right],\] \[=Z_{t}^{\prime}(x)g_{t}^{2},\]

as desired. \(\Box\)

[MISSING_PAGE_FAIL:29]

**Theorem 14**.: _There exists an online learning algorithm that requires \(O(d)\) space and takes \(O(d)\) time per update, takes as input scalar values \(\gamma\), \(h_{1}\), and \(\epsilon\) and a symmetric convex function \(\psi\) and ensures that for any sequence \(g_{1},g_{2},\cdots\subset\mathbb{R}^{d}\), the outputs \(w_{1},w_{1},\cdots\subset\mathbb{R}^{d}\) satisfy for all \(w_{\star}\) and \(T\):_

\[\sum_{t=1}^{T} \big{\{}g_{t},w_{t}-w_{\star}\big{\}}\leq O\left[\epsilon G+\|w_{ \star}\|\sqrt{V\log\left(e+\frac{\|w_{\star}\|\sqrt{V}\log^{2}(T)}{h_{1} \epsilon}\right)}+\|w_{\star}\|G\log\left(e+\frac{\|w_{\star}\|\sqrt{V}\log^{2} (T)}{h_{1}\epsilon}\right)\right.\] \[\left.+\psi(\epsilon)\gamma+\gamma\psi(\|w_{\star}\|)\log\left(e+ \frac{\psi(\|w_{\star}\|)}{\psi(\epsilon)}\log\left(e+\frac{G}{h_{1}}\right) \right)+\gamma\log\left(1+\log\left(\frac{G}{h_{1}}\right)\right)\psi^{\star} \left(\frac{G}{\gamma}\left[1+\log\left(\frac{G}{h_{1}}\right)\right]\right) \right],\]

_where \(\psi^{\star}(\theta)=\sup_{w}\theta w-\psi(w)\) is the Fenchel conjugate of \(\psi\), \(G=\max(h_{1},\max_{t}\|g_{t}\|)\) and \(V=G^{2}+\sum_{t=1}^{T}\|g_{t}\|^{2}\)._

Proof.: Apply Algorithm 5 with Reg set to Algorithm 2 using Algorithm 3 with \(p=1/2\) as Base. The result in 1 dimension then follows from Theorem 16 and Corollary 6. Then by the reduction from \(d\)-dimensional online learning to 1-dimensional online learning ([16] Theorem 2), the result in high dimensions also follows. 

**Theorem 15**.: _Suppose \(\psi\) is a symmetric convex function. Suppose that so long as \(h_{t}\geq|\tilde{g}_{t}|\), Reg ensures for some \(A,B,C,D,p,\epsilon\):_

\[\sum_{t=1}^{T}\tilde{g}_{t}(w_{t}-w_{\star})+a_{t}(\psi(w_{t})- \psi(w_{\star}))\] \[\leq C\epsilon h_{T}^{2p}V_{g}^{1/2-p}+C\psi(\epsilon)\gamma^{2p }S_{a}^{1/2-p}+A|w_{\star}|\sqrt{V_{g}\log\left(e+\frac{D|x_{\star}|V_{g}^{p} }{h_{1}^{2p}\epsilon}\right)}\] \[+Bh_{T}|w_{\star}|\log\left(e+\frac{D|w_{\star}|V_{g}^{p}}{h_{1}^ {2p}\epsilon}\right)\] \[+A\psi(w_{\star})\sqrt{S_{a}\log\left[e+\frac{D\psi(w_{\star})}{ \gamma^{2p}\psi(\epsilon)}S_{a}^{p}\right]}\] \[+\gamma B\psi(w_{\star})\log\left[e+\frac{D\psi(w_{\star})}{ \gamma^{2p}\psi(\epsilon)}S_{a}^{p}\right],\]

_where \(V_{g}=h_{T}^{2}+\sum_{t=1}^{T}\tilde{g}_{t}^{2}\) and \(S_{a}=\gamma^{2}+\gamma\sum_{t=1}^{T}a_{t}\). Then Algorithm 4 ensures:_

\[S_{a} \leq\gamma^{2}+\gamma^{2}\log\left(1+\min\left[\log\left(\frac{h _{T}}{h_{1}}\right),T\right]\right),\] \[V_{g} \leq h_{T}^{2}+\sum_{t=1}^{T}g_{t}^{2},\]_and:_

\[\sum_{t=1}^{T}g_{t}(w_{t}-w_{*}) \leq Ceh_{T}^{2p}V_{g}^{1/2-p}+C\psi(\epsilon)\gamma^{2p}S_{a}^{1/2- p}+A|w_{*}|\sqrt{V_{g}\log\left(e+\frac{D|w_{*}|V_{g}^{p}}{h_{1}^{2p}\epsilon} \right)}\] \[+Bh_{T}|w_{*}|\log\left(e+\frac{D|w_{*}|V_{g}^{p}}{h_{1}^{2p} \epsilon}\right)\] \[+A\psi(w_{*})\sqrt{S_{a}\log\left[e+\frac{D\psi(w_{*})}{\gamma^{2p }\psi(\epsilon)}S_{a}^{p}\right]}\] \[+\gamma B\psi(w_{*})\log\left[e+\frac{D\psi(w_{*})}{\gamma^{2p} \psi(\epsilon)}S_{a}^{p}\right]\] \[+h_{T}|u|+\psi(w_{*})S_{a}\] \[+\gamma\log\left(1+\min\left[\log\left(\frac{h_{T}}{h_{1}}\right),T\right]\right)\psi^{*}\left(\frac{h_{T}}{\gamma}\left[1+\log\left(\frac{h_{ T}}{h_{1}}\right)\right]\right)\]

_In the special case that \(\psi(x)=\frac{|x|^{1+q}}{1+q}\), we can replace the final term \(\gamma\log\left(1+\min\left[\log\left(\frac{h_{T}}{h_{1}}\right),T\right]\right) \psi^{*}\left(h_{T}\left[1+\log\left(\frac{h_{T}}{h_{1}}\right)\right]\right)\) in the above expression by:_

\[\frac{h_{T}^{1+1/q}\left[1+\log\left(\frac{h_{T}}{h_{1}}\right)\right]^{1/q}}{ (1+1/q)\gamma^{1/q}}.\]

Proof.: We have:

\[\sum_{t=1}^{T}g_{t}(w_{t}-u)\] \[=\sum_{t=1}^{T}\tilde{g}_{t}(w_{t}-u)+a_{t}(\psi(w_{t})-\psi(u))+a _{t}\psi(u)+(g_{t}-\tilde{g}_{t})(w_{t}-u)-a_{t}\psi(w_{t}),\] \[\leq\psi(u)\sum_{t=1}^{T}a_{t}+|u|\sum_{t=1}^{T}|g_{t}-\tilde{g}_ {t}|+\sum_{t=1}^{T}\tilde{g}_{t}(w_{t}-u)+a_{t}(\psi(w_{t})-\psi(u)),\] \[\quad+\sum_{t=1}^{T}|g_{t}-\tilde{g}_{t}||w_{t}|-a_{t}\psi(w_{t})\]

Observing that \(|g_{t}-\tilde{g}_{t}|=h_{t+1}-h_{t}\):

\[=\psi(u)\sum_{t=1}^{T}a_{t}+|u|\sum_{t=1}^{T}[h_{t+1}-h_{t}]+\sum_{t=1}^{T}(h_ {t+1}-h_{t})|w_{t}|-a_{t}\psi(w_{t})+\sum_{t=1}^{T}\tilde{g}_{t}(w_{t}-u)+a_{ t}(\psi(w_{t})-\psi(u)).\]

Next, we will bound the terms \(\sum_{t=1}^{T}a_{t}\psi(u)\) and \(|u|\sum_{t=1}^{T}[[g_{t}|-h_{t}]_{+}\). Moreover, \(h_{t}=h_{t-1}+[|g_{t}|-h_{t}]_{+}\), so that \(|u|\sum_{t=1}^{T}|g_{t}-\tilde{g}_{t}|\leq|u|h_{T}\).

Further, notice that for any \(s_{0},s_{1},\ldots,s_{T}\), \(\sum_{t=1}^{T}\log\left(\frac{s_{t}}{\sum_{t=0}^{T}s_{t}}\right)\leq\log(s_{T}/ s_{0})\), so that:

\[\sum_{t=1}^{T}a_{t}\leq\gamma\log\left(1+\sum_{t=1}^{T}\frac{h_{t+1}-h_{t}}{h_ {t+1}}\right)\]

Notice that \([|g_{t}|-h_{t}]_{+}/h_{t+1}\leq 1\), so we also have:

\[\sum_{t=1}^{T}\frac{h_{t+1}-h_{t}}{h_{t+1}}\leq\min\left[\log\left(\frac{h_{T}} {h_{1}}\right),T\right]\]

so that overall:

\[S_{a}=\gamma^{2}+\gamma\sum_{t=1}^{T}a_{t}\leq\gamma^{2}+\gamma^{2}\log\left( 1+\min\left[\log\left(\frac{h_{T}}{h_{1}}\right),T\right]\right)\]Next, we bound the terms \((h_{t+1}-h_{t})|w_{t}|-a_{t}\psi(w_{t})\). Let \(\psi^{*}(w)\) be the Fenchel conjugate of \(\psi\). Recall that \(\psi\) is symmetric so that \(\psi(w_{t})=\psi(|w_{t}|)\). This also implies that \(\psi^{*}\) is symmetric and is minimized at zero. Thus:

\[(h_{t+1}-h_{t})|w_{t}|-a_{t}\psi(w_{t}) =(h_{t+1}-h_{t})|w_{t}|-a_{t}\psi(|w_{t}|),\] \[=a_{t}\psi^{*}\left(\frac{h_{t+1}-h_{t}}{a_{t}}\right),\] \[=a_{t}\psi^{*}\left(\frac{h_{t+1}}{\gamma}\left[1+\sum_{i=1}^{t} \frac{h_{i+1}-h_{i}}{h_{i+1}}\right]\right).\]

So, in general we have:

\[\sum_{t=1}^{T}(h_{t+1}-h_{t})|w_{t}|-a_{t}\psi(w_{t}) \leq\sum_{t=1}^{T}a_{t}\psi^{*}\left(\frac{h_{t+1}}{\gamma}\left[ 1+\sum_{i=1}^{t}\frac{h_{i+1}-h_{i}}{h_{i+1}}\right]\right),\] \[\leq\sum_{t=1}^{T}a_{t}\psi^{*}\left(\frac{h_{T}}{\gamma}\left[1 +\log\left(\frac{h_{T}}{h_{1}}\right)\right]\right),\] \[\leq\gamma\log\left(1+\min\left[\log\left(\frac{h_{T}}{h_{1}} \right),T\right]\right)\psi^{*}\left(\frac{h_{T}}{\gamma}\left[1+\log\left( \frac{h_{T}}{h_{1}}\right)\right]\right).\]

In the special case that \(\psi(w)=\frac{|w|^{1+q}}{1+q}\), we have \(\psi^{*}(h)=\frac{h^{1+1/q}}{1+1/q}\) so that we can improve the logarithmic factors and simplify the calculation:

\[a_{t}\psi^{*}\left(h_{t+1}\left[1+\sum_{i=1}^{t}\frac{h_{i+1}-h_{ i}}{h_{i+1}}\right]\right) =\frac{a_{t}h_{t+1}^{1+1/q}\left[1+\sum_{i=1}^{t}\frac{h_{i+1}-h_ {i}}{h_{i+1}}\right]^{1+1/q}}{(1+1/q)\gamma^{1+1/q}},\] \[=\frac{(h_{t+1}-h_{t})h_{t+1}^{1/q}\left[1+\sum_{i=1}^{t}\frac{h_ {i+1}-h_{i}}{h_{i+1}}\right]^{1/q}}{(1+1/q)\gamma^{1/q}},\] \[\leq\frac{(h_{t+1}-h_{t})h_{T}^{1/q}\left[1+\log\left(\frac{h_{T} }{h_{1}}\right)\right]^{1/q}}{(1+1/q)\gamma^{1/q}}\] \[\sum_{t=1}^{T}(h_{t+1}-h_{t})|w_{t}|-a_{t}\psi(w_{t}) \leq\frac{h_{T}^{1+1/q}\left[1+\log\left(\frac{h_{T}}{h_{1}}\right) \right]^{1/q}}{(1+1/q)\gamma^{1/q}}.\]

Finally, it is clear that \(|\tilde{g}_{t}|\leq h_{t}\) so the summation \(\sum_{t=1}^{T}\tilde{g}_{t}(w_{t}-u)+a_{t}(\psi(w_{t})-\psi(u))\) is controlled by the regret bound of REG:

\[\sum_{t=1}^{T}\tilde{g}_{t}\big{(}w_{t}-u\big{)}+a_{t}(\psi(w_{t })-\psi(u)\big{)} \leq C\epsilon h_{T}^{2p}V_{g}^{1/2-p}+C\psi(\epsilon)\gamma^{2p} S_{a}^{1/2-p}+A|x_{*}|\sqrt{V_{g}\log\left(e+\frac{D|x_{*}|V_{g}^{p}}{h_{1}^{2p} \epsilon}\right)}\] \[+Bh_{T}|x_{*}|\log\left(e+\frac{D|x_{*}|V_{g}^{p}}{h_{1}^{2p} \epsilon}\right)\] \[+A\psi(x_{*})\sqrt{S_{a}\log\left[e+\frac{D\psi(x_{*})}{\gamma^{2 p}\psi(\epsilon)}S_{a}^{p}\right]}\] \[+\gamma B\psi(x_{*})\log\left[e+\frac{D\psi(x_{*})}{\gamma^{2p} \psi(\epsilon)}S_{a}^{p}\right].\]Finally, we also have:

\[V_{g} =h_{T}^{2}+\sum_{t=1}^{T}\tilde{g}_{t}^{2},\] \[\leq h_{T}^{2}+\sum_{t=1}^{T}g_{t}^{2}.\]

### Full Statement of Main Result in High Dimensions

Throughout this paper, we have considered the special case that \(\mathcal{W}=\mathbb{R}\). This suffices due to the reductions of [16] as discussed in Section C. However, here we provide a more complete theorem and algorithm for the case \(\mathcal{W}=\mathbb{R}^{d}\). The pseudocode is provided in Algorithm 5, and the regret bound is stated in Theorem 16. Note that the regret bound follows essentially immediately from Theorem 15.

**Theorem 16**.: _There exists universal constants \(A\), \(B\), \(C\), such that Algorithm 5 guarantees for all \(T\):_

\[\sum_{t=1}^{T}(g_{t},w_{t}-w_{\star}) \leq C\epsilon h_{T}^{2p}V_{g}^{1/2-p}+C\psi(\epsilon)\gamma^{2p} S_{a}^{1/2-p}+A\|w_{\star}\|\sqrt{V_{g}\log\left(e+\frac{\|w_{\star}\|V_{g}^{ p}}{h_{1}^{2p}\epsilon}\right)}\] \[+Bh_{T}\|w_{\star}\|\log\left(e+\frac{\|w_{\star}\|V_{g}^{p}}{h_{1 }^{2}\epsilon}\right)\] \[+A\psi(\|w_{\star}\|)\sqrt{S_{a}\log\left[e+\frac{\psi(\|w_{\star }\|)}{\gamma^{2p}\psi(\epsilon)}S_{a}^{p}\right]}\] \[+\gamma B\psi(\|w_{\star}\|)\log\left[e+\frac{\psi(\|w_{\star}\|) }{\gamma^{2p}\psi(\epsilon)}S_{a}^{p}\right]\] \[+h_{T}|u|+\psi(\|w_{\star}\|)S_{a}\] \[+\gamma\log\left(1+\min\left[\log\left(\frac{h_{T}}{h_{1}}\right),T\right]\right)\psi^{\star}\left(\frac{h_{T}}{\gamma}\left[1+\log\left(\frac{h _{T}}{h_{1}}\right)\right]\right)\]_where_

\[S_{a}\leq\gamma^{2}+\gamma^{2}\log\left(1+\min\left[\log\left(\frac{h_{T}}{h_{1}} \right),T\right]\right)\]

\[V_{g}\leq h_{T}^{2}+\sum_{t=1}^{T}g_{t}^{2}\]

_In the special case that \(\psi(x)=\frac{\left\lfloor x\right\rfloor^{1+q}}{1+q}\), we can replace the final term \(\gamma\log\left(1+\min\left[\log\left(\frac{h_{T}}{h_{1}}\right),T\right] \right)\psi^{*}\left(h_{T}\left[1+\log\left(\frac{h_{T}}{h_{1}}\right)\right]\right)\) in the above expression by:_

\[\frac{h_{T}^{1+1/q}\left[1+\log\left(\frac{h_{T}}{h_{1}}\right)\right]^{1/q}}{ \left(1+1/q\right)\gamma^{1/q}}.\]

Proof.: Algorithm 5 is applying the dimension-free-to-one-dimension reduction provided by Theorem 2 of [16]. So overall the reduction tells us that the regret is bounded by

\[\sum_{t=1}^{T}\langle g_{t},w_{t}-w_{*}\rangle\leq\sum_{t=1}^{T}\langle g_{t} ^{1d},w_{t}^{magnitude}-\left\|w_{*}\right\|\rangle+\left\|w_{*}\right\|\sum_{ t=1}^{T}\langle g_{t},w_{t}^{direction}-w_{*}/\left\|w_{*}\right\|\rangle\]

In this case, the "direction" learner's iterates \(w_{t}^{direction}\) are generated by standard adaptive gradient descent [13], which guarantees the regret bound: \(\sum_{t=1}^{T}\langle g_{t},w_{t}^{direction}-w_{*}/\left\|w_{*}\right\|\rangle \leq 2\sqrt{2\sum_{t=1}^{T}\left\|g_{t}\right\|^{2}}\).

For the first sum \(\sum_{t=1}^{T}\langle g_{t}^{1d},w_{t}^{magnitude}-\left\|w_{*}\right\|\rangle\), notice that \(w^{magnitude}\) is simply an application of Algorithm 4 using an instance of Algorithm 6 The first sum is bounded by application of Theorem 15, noticing that \(|g_{t}^{1d}|\leq\left\|g_{t}\right\|\). So, putting the two bounds together we have the stated result. 

## Appendix G Technical Lemmas

**Lemma 17**.: _Let \(A\), \(B\), \(C\), \(D\), \(E\) be positive numbers and let \(e\) be the base of the natural logarithm. Then:_

\[\sup_{M}A\sqrt{M\log(e+DM^{C})}+B\log(e+DM^{C})-EM\leq\left(\frac{A^{2}}{E}+B \right)\log\left(e+D\left(\frac{2CA^{2}}{E^{2}}+\frac{2CB}{E}\right)^{C}\right)\]

Proof.: First, by Young inequality \(xy\leq\inf_{\lambda}x^{2}/2\lambda+\lambda y^{2}/2\), we have for all \(M\):

\[M\log(e+DM^{C})\leq\frac{M^{2}E^{2}}{4A^{2}}+\frac{A^{2}\log^{2}(e+DM^{2})}{E^ {2}}\]

Then using the identity \(\sqrt{x+y}\leq\sqrt{x}+\sqrt{y}\):

\[\sup_{M}A\sqrt{M\log(e+DM^{C})}+B\log(e+DM^{C})-EM\leq\sup_{M}\left(\frac{A^{2 }}{E}+B\right)\log(e+DM^{C})-\frac{EM}{2}\]

Now, from first order optimality conditions we are looking for a solution to:

\[\frac{\left(\frac{A^{2}}{E}+B\right)DCM^{C-1}}{e+DM^{C}} =\frac{E}{2}\] \[\frac{\left(\frac{A^{2}}{E}+B\right)DCM^{C-1}}{E} =\frac{E}{2}e+\frac{E}{2}DM^{C}\]

Notice that for any \(M\geq\frac{2CA^{2}}{E^{2}}+\frac{2CB}{E}\) we have:

\[\left(\frac{A^{2}}{E}+B\right)CD \leq\frac{E}{2}DM\] \[\left(\frac{A^{2}}{E}+B\right)DCM^{C-1} \leq\frac{E}{2}DM^{C}\] \[\left(\frac{A^{2}}{E}+B\right)DCM^{C-1} <\frac{E}{2}e+\frac{E}{2}DM^{C}\]Therefore, the optimal value for \(M\) can be at most \(\frac{2CA^{2}}{E^{2}}+\frac{2CB}{E}\). Now, notice that \(\left(\frac{A^{2}}{E}+B\right)\log(e+DM^{C})\) is strictly increasing in \(M\). Thus, our quantity of interest is upper-bounded by substituting in \(M=\frac{2CA^{2}}{E^{2}}+\frac{2CB}{E}\) into this increasing term:

\[\sup_{M}\left(\frac{A^{2}}{E}+B\right)\log(e+DM^{C})-EM\leq\left(\frac{A^{2}}{ E}+B\right)\log\left(e+D\left(\frac{2CA^{2}}{E^{2}}+\frac{2CB}{E}\right)^{C}\right)\]

**Lemma 18**.: _Let \(A\), \(B<1\), \(C\) be positive numbers. Then:_

\[\sup_{M}AM^{B}-CM=\left(\frac{BA}{C^{B}}\right)^{1/(1-B)}\left(\frac{1-B}{B}\right)\]

Proof.: We differentiate with respect to \(M\):

\[ABM^{B-1} =C\] \[M =\left(\frac{C}{AB}\right)^{1/(B-1)}\]

So, plugging in this optimal \(M\) value we have: \(\sup_{M}AM^{B}-CM=\left(\frac{C^{B}}{BA}\right)^{1/(B-1)}\left(\frac{1}{B}-1\right)\) 

**Lemma 19**.: _Let \(A\), \(B\), \(C\), \(D\), \(E\), \(F\), \(G<1\) be positive numbers and let \(e\) be the base of the natural logarithm. Then:_

\[\sup_{M}A\sqrt{M\log\left(e+DM^{C}\right)}+B\log\left(e+DM^{C} \right)+FM^{G}-\frac{EM}{2}\] \[\leq \left(\frac{4A^{2}}{E}+B\right)\log\left(e+D\left(\frac{32CA^{2}} {E^{2}}+\frac{8CB}{E}\right)^{C}\right)+\left(\frac{4^{G}GF}{E^{G}}\right)^{1/ (1-G)}\left(\frac{1-G}{G}\right)\]

_When \(G=0\), the last term \(\left(\frac{4^{G}GF}{E^{G}}\right)^{1/(1-G)}\left(\frac{1}{G}-1\right)\) should be replaced with the limiting value \(F\)._

Proof.: Notice that

\[\sup_{M}A\sqrt{M\log\left(e+DM^{C}\right)}+Blog\left(e+DM^{C} \right)+FM^{G}-\frac{EM}{2}\] \[\leq \sup_{M}A\sqrt{M\log\left(e+DM^{C}\right)}+B\log\left(e+DM^{C} \right)-\frac{EM}{4}+\sup_{M}FM^{G}-\frac{EM}{4}\]

The result now follows from Lemmas 17 and 18. Alternatively, if \(G=0\), clearly \(\sup_{M}FM^{G}-\frac{EM}{4}=F\). 

**Lemma 20**.: _Let \(\psi\), \(A\), \(B\), \(C\), \(D\), \(F\), \(S\), \(\gamma\), and \(p\leq 1/2\) be positive numbers with \(S\geq\gamma^{2}\), and let \(e\) be the base of the natural logarithm. Then:_

\[\inf_{E}\sup_{V}A(\psi+E)\sqrt{V\log\left(e+\frac{D(\psi+E)}{ \gamma^{2p}}V^{p}\right)}+B\gamma(\psi+E)\log\left(e+\frac{D(\psi+E)}{\gamma^ {2p}}V^{p}\right)+F\gamma^{2p}V^{1/2-p}-\frac{EV}{2\gamma}+\frac{ES}{2\gamma}\] \[\leq (1/2+16A^{2})\psi\sqrt{S\log\left(e+\frac{2D\psi S^{p}}{\gamma^ {2p}}(128pA^{2}\psi+16pB)^{p}\right)}\] \[\qquad\qquad+\gamma\psi\left(16A^{2}+2B\right)\log\left(e+\frac{2 D\psi S^{p}}{\gamma^{2p}}(128pA^{2}\psi+16pB)^{p}\right)\] \[\qquad\qquad+\left(\left(16A^{2}+2B\right)\log\left(e+2DF\left(1 28pA^{2}+16pB\right)^{p}\right)+\frac{1}{2}+\frac{(2p+1)(2-4p)^{\frac{1-2p}{1 +2p}}}{2}\right)\gamma^{2p}FS^{1/2-p}\]Proof.: By Lemma 19, we have:

\[\sup_{V}A(\psi+E)\sqrt{V\log\left(e+\frac{D(\psi+E)}{\gamma^{2p}}M^{p }\right)}+B\gamma(\psi+E)\log\left(e+\frac{D(\psi+E)}{\gamma^{2p}}M^{p}\right)+F \gamma^{2p}V^{1/2-p}-\frac{EV}{2\gamma}\] \[\leq\left(\frac{4A^{2}(\psi+E)^{2}\gamma}{E}+B\gamma(\psi+E) \right)\log\left(e+\frac{D(\psi+E)}{\gamma^{2p}}\left(\frac{32p\gamma^{2}A^{2}( \psi+E)^{2}}{E^{2}}+\frac{8p\gamma^{2}B(\psi+E)}{E}\right)^{p}\right)\] \[\qquad+\left(\frac{4^{1/2-p}(1/2-p)F\gamma^{2p}}{(E/\gamma)^{1/2- p}}\right)^{\frac{2}{1+2p}}\frac{2p+1}{1-2p}\] \[=\underbrace{\left(\frac{4A^{2}(\psi+E)^{2}\gamma}{E}+B\gamma( \psi+E)\right)\log\left(e+D(\psi+E)\left(\frac{32pA^{2}(\psi+E)^{2}}{E^{2}}+ \frac{8pB(\psi+E)}{E}\right)^{p}\right)}_{(**)}\] \[\qquad+\underbrace{\gamma\frac{(2p+1)(2-4p)^{\frac{1-2p}{1+2p}}}{ 2}\left(\frac{F}{E^{1/2-p}}\right)^{\frac{2}{1+2p}}}_{(**)}\]

Now, set:

\[E=\max\left[\min\left[\psi,\frac{\gamma\psi}{\sqrt{S}}\sqrt{\log\left(e+\frac{2 D\psi S^{p}}{\gamma^{2p}}\left(128pA^{2}+16pB\right)^{p}\right)}\right],\frac{ \gamma^{1+2p}F}{S^{\frac{1+2p}{2}}}\right]\]

We will bound the above expression by first considering \((*)\) and then \((**)\). Now, if \(E=\psi\), we have:

\[(*)=\gamma\psi\left(16A^{2}+2B\right)\log\left(e+2D\psi\left(128pA^{2}+16pB \right)^{p}\right)\]

recalling that \(S\geq\gamma^{2}\):

\[\leq\gamma\psi\left(16A^{2}+2B\right)\log\left(e+\frac{2D\psi S^{p}}{\gamma^{2 p}}(128pA^{2}+16pB)^{p}\right)\]

Alternatively, if \(E=\frac{\gamma\psi}{\sqrt{S}}\sqrt{\log\left(e+\frac{2D\psi S^{p}}{\gamma^{2p} }\left(128pA^{2}+16pB\right)^{p}\right)}\), then we have \(E+\psi\leq 2\psi\) and so:

\[(*)\leq\left(\frac{16A^{2}\psi^{2}\gamma}{E}+2B\gamma\psi\right)\log\left(e+2D \psi\left(\frac{128pA^{2}\psi^{2}}{E^{2}}+\frac{16pB\psi}{E}\right)^{p}\right) \tag{19}\]

Before we bound this expression, let us consider just the value inside the logarithm:

\[\frac{128pA^{2}\psi^{2}}{E^{2}}+\frac{16pB\psi}{E}\leq 128pA^{2}\psi\frac{S}{ \gamma^{2}}+16pB\frac{\sqrt{S}}{\gamma}\]

now, since \(S\geq\gamma^{2}\):

\[\leq\left(128pA^{2}\psi+16pB\right)\frac{S}{\gamma^{2}}\]

So, putting this back in the previous expression:

\[\log\left(e+2D\psi\left(\frac{128pA^{2}\psi^{2}}{E^{2}}+\frac{16pB\psi}{E} \right)^{p}\right)\leq\log\left(e+\frac{2D\psi S^{p}}{\gamma^{2p}}(128pA^{2} \psi+16pB)^{p}\right)\]

from which we conclude:

\[(*)\leq 16A^{2}\psi\sqrt{S\log\left(e+\frac{2D\psi S^{p}}{\gamma^{2 p}}(128pA^{2}\psi+16pB)^{p}\right)}\] \[\qquad\qquad\qquad+2B\gamma\psi\log\left(e+\frac{2D\psi S^{p}}{ \gamma^{2p}}(128pA^{2}\psi+16pB)^{p}\right)\]Finally, let us consider the case \(E=\frac{\gamma^{1+2p}F}{S^{\frac{1+2p}{1+2p}}}\). To handle this situation, we will work with two more subcases: either \(E\leq\psi\) or not. If \(E\leq\psi\), then \(E+\psi\leq 2\psi\). Therefore:

\[(*)\leq\left(\frac{16A^{2}\psi^{2}\gamma}{E}+2B\gamma\psi\right)\log\left(e+2D \psi\left(\frac{128pA^{2}\psi^{2}}{E^{2}}+\frac{16pB\psi}{E}\right)^{p}\right)\]

However, if \(E\leq\psi\), then it must be that \(E\geq\frac{2\psi}{\sqrt{S}}\sqrt{\log\left(e+\frac{2D\psi S\rho}{\gamma^{2p}} \left(128pA^{2}+16pB\right)^{p}\right)}\). Thus by the exact same analysis following equation (19), we again have

\[(*)\leq 16A^{2}\psi\sqrt{S\log\left(e+\frac{2D\psi S^{p}}{\gamma^{2 p}}(128pA^{2}\psi+16pB)^{p}\right)}\] \[\qquad\qquad\qquad+2B\gamma\psi\log\left(e+\frac{2D\psi S^{p}}{ \gamma^{2p}}(128pA^{2}\psi+16pB)^{p}\right)\]

So, for our final subcase we consider \(E=\frac{\gamma^{1+2p}F}{S^{\frac{1+2p}{2}}}\) and also \(E\geq\psi\). Then \(E+\psi\leq 2E\), which yields:

\[(*)\leq\gamma E(16A^{2}+2B)\log\left(e+2DE\left(128pA^{2}+16pB\right)^{p}\right)\]

Since \(S\geq\gamma^{2}\), \(E\leq F\) and so:

\[\leq\gamma F(16A^{2}+2B)\log\left(e+2DF\left(128pA^{2}+16pB\right)^{p}\right)\]

So, in all cases we have:

\[(*)\leq 16A^{2}\psi\sqrt{S\log\left(e+\frac{2D\psi S^{p}}{\gamma^{2 p}}(128pA^{2}\psi+16pB)^{p}\right)}\] \[\qquad\qquad\qquad+\gamma\psi\left(16A^{2}+2B\right)\log\left(e+ \frac{2D\psi S^{p}}{\gamma^{2p}}(128pA^{2}\psi+16pB)^{p}\right)\] \[\qquad\qquad\qquad+\gamma F(16A^{2}+2B)\log\left(e+2DF\left(128pA ^{2}+16pB\right)^{p}\right)\]

Where the last term \(\gamma F(16A^{2}+2B)\log\left(e+2DF\left(128pA^{2}+16pB\right)^{p}\right)\) is only present if \(p\neq 1/2\). Notice that we must have \(E\geq\frac{\gamma^{1+2p}F}{S^{\frac{1+2p}{1+2p}}}\). Therefore:

\[\gamma\frac{F^{\frac{1+2p}{1+2p}}}{E^{\frac{1+2p}{1+2p}}}\leq \gamma^{2p}FS^{1/2-p}\] \[(**)\leq\frac{(2p+1)(2-4p)^{\frac{1+2p}{1+2p}}}{2}\gamma^{2p}FS^{1 /2-p}\]

So, overall it holds that:

\[(*)+(**)\leq 16A^{2}\psi\sqrt{S\log\left(e+\frac{2D\psi S^{p}}{ \gamma^{2p}}(128pA^{2}\psi+16pB)^{p}\right)}\] \[\qquad\qquad\qquad+\gamma\psi\left(16A^{2}+2B\right)\log\left(e+ \frac{2D\psi S^{p}}{\gamma^{2p}}(128pA^{2}\psi+16pB)^{p}\right)\] \[\qquad\qquad\qquad+\gamma F(16A^{2}+2B)\log\left(e+2DF\left(128pA ^{2}+16pB\right)^{p}\right)\] \[\qquad\qquad\qquad+\frac{(2p+1)(2-4p)^{\frac{1-2p}{1+2p}}}{2} \gamma^{2p}FS^{1/2-p}\]

To conclude, let us bound \(\frac{ES}{2\gamma}\). If \(E\neq\frac{\gamma^{1+2p}F}{S^{\frac{1+2p}{2}}}\), then it must be that \(E\leq\frac{\gamma\psi}{\sqrt{S}}\sqrt{\log\left(e+\frac{2D\psi S^{p}}{\gamma^{ 2p}}\left(128pA^{2}+16pB\right)^{p}\right)}\). Therefore:

\[\frac{ES}{2\gamma}\leq\frac{\psi}{2}\sqrt{S\log\left(e+\frac{2D\psi S^{p}}{ \gamma^{2p}}\left(128pA^{2}+16pB\right)^{p}\right)}\]Alternatively, if \(E=\frac{\gamma^{14_{2}p}F}{S^{\frac{14_{2}p}{2}}}\). In this case:

\[\frac{ES}{2\gamma}=\frac{\gamma^{2p}FS^{1/2-p}}{2}\]

So, combining all these facts, we have when \(p<1/2\):

\[\inf_{E}\sup_{V}A(\psi+E)\sqrt{V\log\left(e+\frac{D(\psi+E)}{ \gamma^{2p}}M^{p}\right)}+B\gamma(\psi+E)\log\left(e+\frac{D(\psi+E)}{\gamma^{ 2p}}M^{p}\right)+F\gamma^{2p}V^{1/2-p}-\frac{EV}{2\gamma}+\frac{ES}{2\gamma}\] \[\leq\inf_{E}\left(*\right)+\left(**\right)+\frac{ES}{2\gamma}\] \[\leq 16A^{2}\psi\sqrt{S\log\left(e+\frac{2D\psi Sp}{\gamma^{2p}}( 128pA^{2}\psi+16pB)^{p}\right)}\] \[\qquad+\gamma\psi\left(16A^{2}+2B\right)\log\left(e+\frac{2D\psi Sp ^{p}}{\gamma^{2p}}(128pA^{2}\psi+16pB)^{p}\right)\] \[\qquad+\gamma F(16A^{2}+2B)\log\left(e+2DF\left(128pA^{2}+16pB \right)^{p}\right)\] \[\qquad+\frac{(2p+1)(2-4p)^{\frac{1-2p}{142p}}}{2}\gamma^{2p}FS^{ 1/2-p}\] \[\qquad+\frac{\gamma^{2p}FS^{1/2-p}}{2}+\frac{\psi}{2}\sqrt{S\log \left(e+\frac{2D\psi Sp^{p}}{\gamma^{2p}}\left(128pA^{2}+16pB\right)^{p}\right)}\]

grouping terms, and using \(\gamma\leq\gamma^{2p}S^{1/2-p}\):

\[\leq(1/2+16A^{2})\psi\sqrt{S\log\left(e+\frac{2D\psi Sp^{p}}{\gamma ^{2p}}(128pA^{2}\psi+16pB)^{p}\right)}\] \[\qquad+\gamma\psi\left(16A^{2}+2B\right)\log\left(e+\frac{2D\psi Sp ^{p}}{\gamma^{2p}}(128pA^{2}\psi+16pB)^{p}\right)\] \[\qquad+\left(\left(16A^{2}+2B\right)\log\left(e+2DF\left(128pA^{2 }+16pB\right)^{p}\right)+\frac{1}{2}+\frac{(2p+1)(2-4p)^{\frac{1-2p}{142p}}}{2 }\right)\gamma^{2p}FS^{1/2-p}\]

**Lemma 21**.: _Suppose \(g_{1},\ldots,g_{t}\) and \(0<h_{1}\underset{e}{\leq}h_{2}\leq\cdots\leq h_{T}\) are such that \(|g_{t}|\leq h_{t}\) for all \(t\). Define \(V_{t}=ch_{t}^{2}+g_{1:t-1}^{2}\). Define \(\alpha_{t}=\frac{\gamma^{c}\sum_{i=1}^{t-1}g_{i}^{2}/h_{i}^{2}\log^{2}\left(c+ \sum_{i=1}^{t-1}g_{i}^{2}/h_{i}^{2}\right)}{\sqrt{c+\sum_{i=1}^{t-1}g_{i}^{2}/ h_{i}^{2}}}\) for some \(c\geq 3\). Then:_

\[\sum_{t=1}^{T}\frac{\alpha_{t}g_{t}^{2}}{\sqrt{V_{t}}}\leq=4eh_{T}\]

Proof.: Let \(1=\tau_{1},\ldots,\tau_{k}\leq T\) be the set of indices such that \(h_{\tau_{i+1}}>2h_{\tau_{i}}\) and \(h_{\tau_{i+1}-1}\leq 2h_{\tau_{i}}\), with \(\tau_{k+1}\) defined equal to \(T+1\) for convenience. Note that this implies \(h_{\tau_{k-i}}<h_{\tau_{k}}/2^{i}\). Further, \(h_{\tau_{k}}\leq h_{T}\), so overall we have for all \(i\)\(h_{\tau_{k-i}}\leq h_{T}/2^{i}\). We will show that

\[\sum_{t=\tau_{i}}^{\tau_{i+1}-1}\frac{\alpha_{t}g_{t}^{2}}{\sqrt{V_{t}}}\leq 2 \epsilon h_{\tau_{i}} \tag{20}\]

[MISSING_PAGE_EMPTY:39]

**Lemma 22**.: _Suppose \(g_{1},\ldots,g_{t}\) and \(0<h_{1}\leq h_{2}\leq\cdots\leq h_{T}\) are such that \(|g_{t}|\leq h_{t}\) for all \(t\). Define \(V_{t}=ch_{t}^{2}+g_{1:t-1}^{2}\). Define \(\alpha_{t}=\frac{e}{\left(e+\sum_{i=1}^{t-1}g_{i}^{2}/h_{i}^{2}\right)^{p}}\) for some \(c\geq 1\) and \(p\in[0,1/2)\). Then:_

\[\sum_{t=1}^{T}\frac{\alpha_{t}g_{t}^{2}}{\sqrt{V_{t}}}\leq\frac{2eh_{T}^{2p} \left(\sum_{t=1}^{T}g_{t}^{2}\right)^{1/2-p}}{1-2p}\]

Proof.: Similar to the proof of Lemma 21, we have:

\[V_{t} \geq(c-1)h_{t}^{2}+\sum_{j=1}^{t}g_{j}^{2}\] \[\geq\sum_{j=\tau_{i}}^{t}g_{j}^{2}\]

and also:

\[\alpha_{t} \leq\frac{\epsilon}{\left(\sum_{j=1}^{t}g_{j}^{2}/h_{j}^{2} \right)^{p}}\] \[\leq\frac{\epsilon h_{t}^{2p}}{\left(\sum_{j=1}^{t}g_{j}^{2} \right)^{p}}\]

Combining these yields:

\[\frac{\alpha_{t}g_{t}^{2}}{\sqrt{V_{t}}}\leq\frac{\epsilon h_{T}^{2p}g_{t}^{2} }{\left(\sum_{j=1}^{t}g_{j}^{2}\right)^{1/2+p}}\]

Further, by [1] Lemma 4.13 we have:

\[\sum_{t=1}^{T}\frac{g_{t}^{2}}{\left(\sum_{j=1}^{t}g_{j}^{2}\right) ^{1/2+p}} \leq\int_{0}^{\sum_{t=1}^{T}g_{t}^{2}}\frac{dx}{x^{1/2+p}}\] \[\leq\frac{\left(\sum_{t=1}^{T}g_{t}^{2}\right)^{1/2-p}}{1/2-p}\]

from which the conclusion immediately follows. 

## Appendix H Regularized Regret via Full-Matrix Bound With Constraints

In this section, we provide an alternative approach to solving the "epigraph-based regularized regret" game specified by Protocol 3. Our approach actually involves a generic improvement to the class of so-called "full-matrix" regret bounds, and so may be of independent interest.

Specifically, we will provide an algorithm for online learning with "magnitude hints" (Protocol 4) that ensures the regret bound:

\[\sum_{t=1}^{T}(g_{t},w_{t}-w_{\star})\leq O\left(\epsilon h_{T+1}+\sqrt{d\sum _{t=1}^{T}(g_{t},w_{\star})^{2}\log(\|w_{\star}\|T/\epsilon)}\right). \tag{21}\]

This type of bound is sometimes called a "full-matrix" bound as the term inside the square root can be expressed as \(w_{\star}^{T}\Sigma w_{\star}\) where \(\Sigma\) is the matrix of gradient outer products \(\Sigma=\sum_{t=1}^{T}g_{t}g_{t}^{\top}\). Bounds of this form have appeared before in the literature. For the case that \(\mathcal{W}\) is an entire vector space, [16, 18] both provide full-matrix bounds. For the case in which \(\mathcal{W}\) is _not_ an entire vector space, [31] provides to our knowledge the only full-matrix bound. However, their algorithm suffers a suboptimal logarithmic factor: the \(\log(T)\) term appears _outside_ rather than inside the square root. We provide a method that fixes this issue.

However, before delving into the technical details of our approach, let us explain how achieving a full-matrix bound allows us to solve Protocol 3. The argument is nearly immediate: observe that in the 2-d game, we would have \(w_{\star}\mapsto(w_{\star},\psi(w_{\star}))\) and \(g_{t}\mapsto(\tilde{g}_{t},a_{t})\). Then the bound (6) is immediate from (21). So, without further add, let us provide our bound and analysis.

### Full Matrix Algorithm and Analysis

Assume that \(\mathcal{W}\subset\mathbb{R}^{d}\) is a closed convex set that contains the origin within its interior. Further, let \(\Phi_{\mathsf{bar}}\) be a self-concordant barrier for \(\mathcal{W}\) with parameter \(\mu>0\). In this section, we present an algorithm that achieves (21). The algorithm is Follow-The-Regularized-Leader (FTRL) with a specific regularizer we define next.

Regularizers.For \(\Sigma\in\mathbb{R}^{d\times d}\) and \(Z,\sigma,\varepsilon>0\), define the regularizer:

\[\Phi(w;\Sigma,Z,\sigma,\varepsilon)\ =\ \sup_{\lambda\geq 0}\sqrt{w^{\top}( \Sigma+\lambda I)w}\cdot X\Bigg{(}w^{\top}(\Sigma+\lambda I)we^{-\lambda Z} \cdot\frac{\det(\sigma^{-2}\Sigma)}{\varepsilon^{2}}\Bigg{)}, \tag{22}\]

where \(X(\theta)=W\left(\theta\right)^{1/2}-W\left(\theta\right)^{-1/2}\) and \(W\) is the Lambert function; \(W(x)\) is defined as the principal solution to \(W(x)e^{W(x)}=x\).

**Lemma 23**.: _For any \(\Sigma\in\mathbb{R}^{d\times d}\) and \(Z,\varepsilon,\sigma>0\), the Fenchel dual of the function \(\Phi(\cdot;\Sigma,Z,\sigma,\varepsilon)\) in (22) satisfies:_

\[\forall\,G\in\mathbb{R}^{d},\quad\Phi^{\star}(G;\Sigma,Z,\sigma,\varepsilon)\ =\ \inf_{\lambda\geq 0}\frac{\varepsilon\cdot\exp\!\left(\frac{1}{2}G^{\top}(\Sigma+\lambda I)^{-1}G+\frac{\lambda Z}{2}\right)}{\sqrt{\det(\sigma^{-2}\Sigma)}}.\]

Proof.: See [18]. 

Ftrl.We will consider the FTRL algorithm with regularizer \(\Phi(\cdot;\Sigma,Z,\sigma,\varepsilon)+\Phi_{\mathsf{bar}}(\cdot)\), for some choices of \(\Sigma\), \(Z\), \(\sigma\), and \(\varepsilon\). To specify these choices, let

\[\rho(\gamma)=\sqrt{2}\cdot\left(1-e^{\frac{1}{2\gamma}-\frac{1}{2}}\right), \tag{23}\]

for \(\gamma>1\). With this, and given the history of gradients \(g_{1},\ldots,g_{t-1}\) up to round \(t-1\) and parameters \(\gamma,\sigma,\varepsilon>0\) and hint \(h_{t}>0\), the algorithm outputs:

\[\widehat{w}_{t}\in\operatorname*{\text{argmin}}_{w\in\mathbb{R}^{d}}(G_{t-1}, w)+\Psi(-w;V_{t-1},h_{t},\sigma,\varepsilon), \tag{24}\]

where

\[\Psi(w;V,h,\sigma,\varepsilon)\coloneqq\Phi(w;\sigma^{2}I+\gamma V,\rho( \gamma)^{2}/h^{2},\sigma,\varepsilon)+\Phi_{\mathsf{bar}}(-w), \tag{25}\]

and

\[G_{\tau}\coloneqq\sum_{s=1}^{\tau}g_{s},\quad\text{and}\quad V_{\tau} \coloneqq\sum_{s=1}^{\tau}g_{s}g_{s}^{\top}. \tag{26}\]

**Remark 1** (Connection to Matrix-FreeGrad).: We note that without the barrier term \(\Phi_{\mathsf{bar}}\) in (25), the iterates in (24) can be computed in closed-form; in this case, the iterates exactly matches those of the Matrix-FreeGrad algorithm by [18] for _unconstrained_ Online Convex Optimization (the connection to FTRL was not made explicit in [18]). The advantage of adding a barrier \(\Phi_{\mathsf{bar}}\) is that it ensure that the iterates \((\widehat{w}_{t})\) are always in the feasible set without requiring any sophisticated constrained-to-unconstrained reductions that may lead to sub-optimal logarithmic terms in the regret [46] (see Remark 2 in the sequel).

**Lemma 24** (Monotocity of potential).: _Let \(\sigma,\varepsilon>0\) and \(\gamma>1\) be given. For all \(g_{t}\in\mathbb{R}^{d}\) and \(h_{t}>0\) such that \(\left|g_{t}\right|\leq h_{t}\), we have_

\[\langle g_{t},\widehat{w}_{t}\rangle\leq\Psi^{\star}(G_{t-1};V_{t-1},h_{t}, \sigma,\varepsilon)-\Psi^{\star}(G_{t};V_{t},h_{t},\sigma,\varepsilon). \tag{27}\]

_where \(G\mapsto\Psi^{\star}(G;V,h,\sigma,\varepsilon)\) denotes the Fenchel dual of \(w\mapsto\Psi(w;V,h,\sigma,\varepsilon)\)._

The proof of the lemma is in Appendix H.3. By summing (27) over \(t\) and using Fenchel duality, we obtain the following regret bound for the FTRL iterates in (24).

**Theorem 25** (Regret with valid hints).: _Let \(\sigma,\varepsilon>0\) and \(\gamma>1\) be given. The FTRL iterates \((\widehat{w}_{t})\) in (24) in response to any sequence \((g_{t})\) such that \(\left|g_{t}\right|\leq h_{t}\), for all \(t\geq 1\), satisfy: for all \(T\in\mathbb{N}\) and \(w\in\mathrm{int}\ \mathcal{W}\):_

\[\sum_{t=1}^{T}\langle g_{t},w_{t}-w\rangle\leq\varepsilon+\Phi_{\mathsf{bar}}^{ \star}(0)+\Phi_{\mathsf{bar}}(w)+\sqrt{Q_{T}^{w}\ln_{\star}\left(\det(\sigma^{ -2}\Sigma_{T})\cdot Q_{T}^{w}\right)}, \tag{28}\]_where \(\ln_{*}(\cdot)\succeq 0\vee\ln(\cdot)\), \(\Sigma_{T}=\sigma^{2}I+\gamma V_{T}\), and_

\[Q_{T}^{w} \succeq\max\Bigg{\{}w^{\top}\Sigma_{T}w,\frac{1}{2}\Bigg{(}\frac{h_{T}^{2} \left\|w\right\|^{2}}{\rho(\gamma)^{2}}\ln\!\Bigg{(}\mathrm{det}\big{(}\sigma^ {-2}\Sigma_{T}\big{)}\frac{h_{T}^{2}\left\|w\right\|^{2}}{\varepsilon^{2}\rho( \gamma)^{2}}\Bigg{)}+w^{\top}\Sigma_{T}w\Bigg{)}\Bigg{\}}. \tag{29}\]

**Remark 2** (Comparison to previous "full-matrix" bounds in the constrained setting).: We note that by having the \(O(\log T)\) factor in (28) inside the square root, the bound in (28) improves on previous "full-matrix" bounds in the constraint setting [46], which have the log factor outside.

### Implementation Considerations

As stated in Remark 2, if we remove \(\Phi_{\text{bar}}\) from the regularizer, then iterates in (24) match those of Matrix-FreeGrad, which are available in _closed-form_. Unfortunately, in the presence of \(\Phi_{\text{bar}}\) (which ensures that the iterates are always in the feasible set \(\mathcal{W}\)), the iterate \(\widehat{w}_{t}\) in (24) no longer admits a closed-form expression, and computing \(\widehat{w}_{t}\), for \(t\in[T]\), now requires solving a convex optimization problem. This is not ideal from a computational perspective; most first-order OCO algorithms require only \(O(d)\) operation per round. It might be possible (at least in the case where \(\mathcal{W}\) is bounded) to efficiently approximate \((\widehat{w}_{t})\) without solving an optimization problem at each step and without sacrificing the regret by much using _Newton steps_ such as in the recent works of [47, 48, 49]. We leave this investigation for future work.

### Proof of Lemma 24

Proof.: By Lemma 23, we have that for all \(V\) and \(h\), \(\Psi^{*}(\cdot;V,h,\sigma,\varepsilon)\) satisfies

\[\Psi^{*}(G;V,h,\sigma,\varepsilon) =\inf_{u\in\mathbb{R}^{d}}\Phi^{*}(G-u;\gamma V,\rho(\gamma)^{2}/h ^{2},\sigma,\varepsilon)+\Phi_{\text{bar}}^{*}(-u),\] \[=\inf_{\lambda\geq 0,u\in\mathbb{R}^{d}}\frac{\varepsilon\cdot \exp\!\left(\frac{1}{2}\big{(}G-u\big{)}^{\tau}\big{(}\sigma^{2}I+\gamma V+ \lambda I\big{)}^{-1}(G-u)+\frac{\lambda\rho(\gamma)^{2}}{2h^{2}}\right)}{ \sqrt{\mathrm{det}(I+\sigma^{-2}\gamma V)}}+\Phi_{\text{bar}}^{*}(-u). \tag{30}\]

We will use this to prove (27).

Let \((\lambda_{*},u_{*})\in\mathbb{R}_{\geq 0}\times\mathbb{R}^{d}\) be the minimizer in the problem \(\Psi^{*}(G_{t-1};V_{t-1},h_{t},\sigma,\varepsilon)\). With this notation, we have

\[\widehat{w}_{t} =\operatorname*{argmin}_{w\in\mathbb{R}^{d}}(G_{t-1},w)+\Psi(-w;V _{t-1},h_{t}),\] \[=\operatorname*{argmax}_{w\in\mathbb{R}^{d}}(G_{t-1},-w)-\Psi(-w; V_{t-1},h_{t}),\] \[=-\operatorname*{argmax}_{v\in\mathbb{R}^{d}}\left\{(G_{t-1},v)- \Psi(v;V_{t-1},h_{t})\right\},\] \[=-\nabla\Psi^{*}(G_{t-1};V_{t-1},h_{t},\sigma,\varepsilon),\]

and so by Lemma 26,

\[=-\big{(}\sigma^{2}I+\gamma V_{t-1}+\lambda_{*}I\big{)}^{-1}(G_{t-1}-u_{*}) \cdot\Phi^{*}(G_{t-1}-u_{*};\sigma^{2}I+\gamma V_{t-1},\rho(\gamma)^{2}/h_{t} ^{2},\sigma,\varepsilon). \tag{31}\]

Moving forward, we define

\[G_{t-1,*}\coloneqq G_{t-1}-u_{*}\quad\text{and}\quad G_{t,*}\coloneqq G_{t}- u_{*}.\]

To prove the lemmas, it suffices to prove the stronger statement obtained by picking the sub-optimal choice \((\lambda,u)=(\lambda_{*},u_{*})\) for the problem \(\Psi^{*}(G_{t},V_{t},h_{t},\sigma,\varepsilon)\); that is,

\[\{\widehat{w}_{t},g_{t}\}\] \[\leq\frac{\varepsilon\cdot\exp\!\left(\frac{1}{2}G_{t-1,*}^{\top }\big{(}\sigma^{2}I+\gamma V_{t-1}+\lambda_{*}I\big{)}^{-1}G_{t-1,*}+\frac{ \lambda_{*}\rho(\gamma)^{2}}{2h_{t}^{2}}\right)}{\sqrt{\mathrm{det}(I+\sigma^ {-2}\gamma V_{t-1})}}+\Phi_{\text{bar}}^{*}(-u_{*})\] \[\quad-\frac{\varepsilon\cdot\exp\!\left(\frac{1}{2}G_{t,*}^{\top }\big{(}\sigma^{2}I+\gamma V_{t}+\lambda_{*}I\big{)}^{-1}G_{t,*}+\frac{ \lambda_{*}\rho(\gamma)^{2}}{2h_{t}^{2}}\right)}{\sqrt{\mathrm{det}(I+\sigma^ {-2}\gamma V_{t})}}-\Phi_{\text{bar}}^{*}(-u_{*}),\] \[=\Phi^{*}(G_{t-1,*};\sigma^{2}I+\gamma V_{t-1},\rho(\gamma)^{2}/h _{t}^{2},\sigma,\varepsilon)-\Phi^{*}(G_{t,*};\sigma^{2}I+\gamma V_{t},\rho( \gamma)^{2}/h_{t}^{2},\sigma,\varepsilon),\]and so dividing by \(\Phi^{*}(G_{t-1,*};\sigma^{2}I+\gamma V_{t-1},\rho(\gamma)^{2}/h_{t}^{2},\sigma,\varepsilon)\) and using (31), this becomes

\[-g_{t}\cdot\big{(}\sigma^{2}I+\gamma V_{t-1}+\lambda_{*}I\big{)}^{- 1}G_{t-1,*}\] \[\leq\ 1-\frac{\exp\!\left(\frac{1}{2}G_{t,*}^{\top}\big{(}\sigma^{2 }I+\gamma V_{t}+\lambda_{*}I\big{)}^{-1}G_{t,*}+\frac{\lambda_{*}\rho(\gamma)^ {2}}{2h_{t}^{2}}-\frac{1}{2}\ln\det\!\big{(}I+\sigma^{-2}\gamma V_{t}\big{)} \right)}{\exp\!\left(\frac{1}{2}G_{t-1,*}^{\top}\big{(}\sigma^{2}I+\gamma V_{t -1}+\lambda_{*}I\big{)}^{-1}G_{t-1,*}+\frac{\lambda_{*}\rho(\gamma)^{2}}{2h_{ t}^{2}}-\frac{1}{2}\ln\det\!\big{(}I+\sigma^{-2}\gamma V_{t-1}\big{)}\right)}.\]

Let us abbreviate \(\Sigma=\sigma^{2}I+\gamma V_{t-1}+\lambda_{*}I\). The matrix determinant lemma and monotonicity of matrix inverse give

\[\ln\frac{\det\!\big{(}I+\sigma^{-2}\gamma V_{t}\big{)}}{\det\!\big{(}I+\sigma^ {-2}\gamma V_{t-1}\big{)}}\ =\ \ln\!\left(1+\gamma g_{t}^{\top}\big{(}\sigma^{2}I+ \gamma V_{t-1}\big{)}^{-1}g_{t}\right)\ \geq\ \ln\!\left(1+\gamma g_{t}^{\top} \Sigma^{-1}g_{t}\right)\!.\]

Then Sherman-Morrison gives

\[G_{t,*}^{\top}\big{(}\sigma^{2}I+\gamma V_{t}+\lambda_{*}I\big{)}^{-1}G_{t,*}\ =\ G_{t,*}^{\top}\Sigma^{-1}G_{t,*}-\gamma\frac{(g_{t}^{\top}\Sigma^{-1}G_{t,*})^{2}}{1+\gamma g_{t}^{\top}\Sigma^{-1}g_{t}}\]

and splitting off the last round \(G_{t,*}=G_{t-1,*}+g_{t}\) gives

\[G_{t,*}^{\top}\big{(}\sigma^{2}I+\gamma V_{t}+\lambda_{*}I\big{)}^{-1}G_{t,*}\ =\ G_{t-1,*}^{\top}\Sigma^{-1}G_{t-1,*}+\frac{2G_{t-1,*}^{\top}\Sigma^{-1}g_{ t}+g_{t}^{\top}\Sigma^{-1}g_{t}-\gamma(g_{t}^{\top}\Sigma^{-1}G_{t-1,*})^{2}}{1+ \gamma g_{t}^{\top}\Sigma^{-1}g_{t}}.\]

All in all, it suffices to show

\[-g_{t}^{\top}\Sigma^{-1}G_{t-1,*}\ \leq\ 1-\exp\!\left(\frac{2G_{t-1,*}^{\top}\Sigma^{-1}g_{t}+g_{t}^{\top}\Sigma^{-1}g_{t}- \gamma(g_{t}^{\top}\Sigma^{-1}G_{t-1,*})^{2}}{2(1+\gamma g_{t}^{\top}\Sigma^{-1}g_{t})}-\frac{1}{2}\ln\! \left(1+\gamma g_{t}^{\top}\Sigma^{-1}g_{t}\right)\!\right)\!.\]

Introducing scalars \(r=g_{t}^{\top}\Sigma^{-1}G_{t-1,*}\) and \(z=g_{t}^{\top}\Sigma^{-1}g_{t}\), this simplifies to

\[-r\ \leq\ 1-\exp\!\left(\frac{2r+z-\gamma r^{2}}{2(1+\gamma z)}-\frac{1}{2}\ln \!\left(1+\gamma z\right)\right)\]

Being a square, \(z\geq 0\) is positive. In addition, optimality of \(\lambda_{*}\) ensures that \(\big{\|}\Sigma^{-1}G_{t-1,*}\big{\|}=\frac{\rho(\gamma)}{\sqrt{2}h_{t}}\); this follows from the fact that \(\frac{\mathrm{d}}{\mathrm{d}\lambda}\ G_{t-1,*}^{\top}\big{(}\sigma^{2}I+ \gamma V+\lambda I\big{)}^{-1}G_{t-1,*}\big{|}_{\lambda=\lambda_{*}}=\|\Sigma^{-1}G_{t-1,*}\|^{2}\). In combination with \(\|g_{t}\|\leq h_{t}\), we find

\[|r|\leq\rho(\gamma)/\sqrt{2}=1-e^{\frac{1}{2\gamma}-\frac{1}{2}}<1. \tag{32}\]

The above requirement may hence be further reorganized to

\[2r-\gamma r^{2}\ \leq\ -z+(1+\gamma z)(\ln\!\left(1+\gamma z\right)+2\ln\! \left(1+r\right)).\]

The convex right hand side is minimized subject to \(z\geq 0\) at

\[z\ =\ \max\!\left\{0,\frac{e^{\frac{1}{\gamma}-1-2\ln\!\left(1+r\right)}-1}{ \gamma}\right\}\]

so it remains to show

\[2r-\gamma r^{2}\ \leq\ \begin{cases}\frac{1}{\gamma}-(1+r)^{-2}e^{\frac{1}{\gamma}-1},&\text{if $\frac{1}{\gamma}-1\geq 2\ln\!\left(1+r\right)$};\\ 2\ln\!\left(1+r\right),&\text{otherwise}.\end{cases} \tag{33}\]

Note that by (32), we have \(2\log(1+r)\geq\frac{1}{\gamma}-1\), and so the condition in the previous display reduces to the second case; that is,

\[2r-\gamma r^{2}\leq 2\log(1+r),\quad\forall|r|\leq 1-e^{\frac{1}{2\gamma}-\frac{1}{2}}, \tag{34}\]

which is satisfied for the hardest case, where \(r=e^{\frac{1}{2\gamma}-\frac{1}{2}}-1\).

### Proof of Theorem 25

Proof.: Fix \(w\in\mathbb{R}^{d}\). Using that \(\Psi^{*}(G;V,h,\sigma,\varepsilon)\) is decreasing in \(h\), we can telescope (27) in Lemma 24 to obtain

\[\sum_{t=1}^{T}g_{t}^{\top}\widehat{w}_{t}\;\leq\;\Psi^{*}(0;0,h_{1},\sigma, \varepsilon)-\Psi^{*}(G_{T};V_{T},h_{T},\sigma,\varepsilon)\]

By (30), we have \(\Psi^{*}(0;0,h_{1},\sigma,\varepsilon)\leq\varepsilon+\Phi^{*}_{\text{bar}}( \mathbf{0})\), yielding:

\[\sum_{t=1}^{T}g_{t}^{\top}\widehat{w}_{t} \leq\varepsilon+\Phi^{*}_{\text{bar}}(\mathbf{0})-\Psi^{*}(G_{T}; V_{T},h_{T},\sigma,\varepsilon),\] \[\leq\varepsilon+\Phi^{*}_{\text{bar}}(\mathbf{0})+\inf_{u\in \mathbb{R}^{d}}(G_{T},u)+\Psi(-u;V_{T},h_{T},\sigma,\varepsilon),\] \[=\varepsilon+\Phi^{*}_{\text{bar}}(\mathbf{0})+\inf_{u\in \mathbb{R}^{d}}(G_{T},u)+\Phi(-u;\sigma^{2}I+\gamma V_{T},\rho(\gamma)^{2}/h_ {T}^{2},\sigma,\varepsilon)+\Phi_{\text{bar}}(u),\] \[\leq\varepsilon+\Phi^{*}_{\text{bar}}(\mathbf{0})+(G_{T},w)+\Phi (-w;\sigma^{2}I+\gamma V_{T},\rho(\gamma)^{2}/h_{T}^{2},\sigma,\varepsilon)+ \Phi_{\text{bar}}(w),\quad\text{(setting $u=w$)}\] \[=\varepsilon+\Phi^{*}_{\text{bar}}(\mathbf{0})+(G_{T},w)+\sup_{ \lambda\geq 0}\sqrt{w^{\top}(\Sigma_{T}+\lambda I)w}\cdot X\Bigg{(}w^{\top}( \Sigma_{T}+\lambda I)we^{-\lambda Z_{T}}\cdot\frac{\det(\sigma^{-2}\Sigma_{T}) }{\varepsilon^{2}}\Bigg{)}\] \[\quad+\Phi_{\text{bar}}(w), \tag{35}\]

where \(\Sigma_{T}\coloneqq\sigma^{2}I+\gamma V_{T}\) and \(Z_{T}=\rho(\gamma)^{2}/h_{T}^{2}\). Zero derivative of the above objective for \(\lambda\) occurs at

\[\lambda\;=\;\frac{\ln\frac{\left\lVert w\right\rVert^{2}}{Z_{T}}}{2Z_{T}}- \frac{w^{\top}\Sigma_{T}w}{2\left\lVert w\right\rVert^{2}},\]

and hence the optimum for \(\lambda\) is either at that point or at zero, whichever is higher, with the crossover point at \(\frac{\left\lVert w\right\rVert^{2}}{Z_{T}}\ln\frac{\left\lVert w\right\rVert ^{2}}{Z_{T}}=w^{\top}\Sigma_{T}w\). Plugging that in, we find that for \(C\coloneqq\frac{\left\lVert w\right\rVert^{2}}{Z_{T}}\ln\frac{\left\lVert w \right\rVert^{2}}{Z_{T}}\), we have

\[\sup_{\lambda\geq 0}\sqrt{w^{\top}(\Sigma_{T}+\lambda I)w}\cdot X \Bigg{(}w^{\top}(\Sigma_{T}+\lambda I)we^{-\lambda Z_{T}}\cdot\frac{\det( \sigma^{-2}\Sigma_{T})}{\varepsilon^{2}}\Bigg{)}\] \[= \begin{cases}\sqrt{\frac{1}{2}(C+w^{\top}\Sigma_{T}w)}\cdot X \Bigg{(}\frac{1}{2}(C+w^{\top}\Sigma_{T}w)e^{-\frac{\ln\frac{\left\lVert w \right\rVert^{2}}{Z_{T}}}+\frac{Z_{T}w^{\top}\Sigma_{T}w}{2\left\lVert w \right\rVert^{2}}}\cdot\frac{\det(\sigma^{-2}\Sigma_{T})}{\varepsilon^{2}} \Bigg{)},&\text{if $C\geq w^{\top}\Sigma_{T}w$;}\\ \sqrt{w^{\top}\Sigma_{T}w}\cdot X(w^{\top}\Sigma_{T}w\cdot\frac{\det(\sigma^ {-2}\Sigma_{T})}{\varepsilon^{2}}),&\text{otherwise.}\end{cases}\] \[\leq \sqrt{Q_{T}^{w}}\cdot X\Bigg{(}\frac{\det(\sigma^{-2}\Sigma_{T} )}{\varepsilon^{2}}Q_{T}^{w}\Bigg{)}, \tag{36}\]

where \(Q_{T}^{w}=\max\{w^{\top}\Sigma_{T}w,\frac{1}{2}\left(\frac{\left\lVert w \right\rVert^{2}}{Z_{T}}\ln\frac{\left\lVert w\right\rVert^{2}}{Z_{T}}+w^{ \top}\Sigma_{T}w\right)\}\); in the last inequality, we used that \(X(\theta)\) is increasing to drop the exponential in its argument. Combining (36) with (35) and using that \(X(\theta)\leq\sqrt{\ln_{*}(\theta)}\) (see Lemma 27), we obtain the desired bound. 

### Helper Lemmas for Full-Matrix Analysis

**Lemma 26**.: _Let \(\mathcal{W}\in\mathbb{R}^{d}\) and \(\mathcal{Y}\in\mathbb{R}\). Further, let \(f:\mathcal{X}\times\mathcal{Y}\to\mathbb{R}\) be a differentiable function such that for all \(x\in\mathcal{X}\), the problem \(\inf_{y\in\mathcal{Y}}f(x,y)\) has a unique minimizer \(y(x)\). Then,_

\[\nabla_{x}f(x,y(x))=\partial_{x}f(x,y(x)). \tag{37}\]

**Lemma 27**.: _For \(\theta\geq 0\), define \(X(\theta)\coloneqq\sup_{\alpha}\;\alpha-e^{\frac{\alpha^{2}}{2}-\frac{1}{2}\ln\theta}\). Then \(X(\theta)=(W(\theta))^{1/2}-(W(\theta))^{-1/2}=\sqrt{\ln\theta}+o(1)\)._

Proof.: The fact that \(X(\theta)=(W(\theta))^{1/2}-(W(\theta))^{-1/2}\) follows from [50, Lemma 18]. Recall that

\[\sup_{x}\;yx-e^{x}\;=\;y\ln y-y\]Hence

\[X(\theta) = \sup_{\alpha}\;\alpha-e^{\frac{\alpha^{2}}{2}-\frac{1}{2}\ln\theta}\] \[= \sup_{\alpha}\inf_{\eta}\;\alpha-\eta\bigg{(}\frac{\alpha^{2}}{2}- \frac{1}{2}\ln\theta\bigg{)}+\eta\ln\eta-\eta\] \[= \inf_{\eta}\;\frac{1}{2\eta}+\frac{\eta}{2}\ln\theta+\eta\ln\eta-\eta\] \[\leq \min\bigg{\{}\sqrt{\ln\theta}-\frac{1+\frac{1}{2}\ln\ln\theta}{ \sqrt{\ln\theta}},\frac{\sqrt{\theta}}{2}-\frac{1}{\sqrt{\theta}}\bigg{\}}\] \[\leq \sqrt{\ln_{+}\theta}\]

where we plugged in the sub-optimal choices \(\eta=\frac{1}{\sqrt{\ln\theta}}\) (this requires \(\theta\geq 1\)) and \(\eta=\frac{1}{\sqrt{\theta}}\). When we stick in \(\eta=\frac{1}{\sqrt{\ln(e^{-2}+\theta)}}\) we find

\[X(\theta)\;\leq\;\frac{\ln(e^{e^{-2}}+\theta)+\ln\theta-\ln\Big{(}\ln(e^{e^{-2 }}+\theta)\Big{)}-2}{2\sqrt{\ln(e^{e^{-2}}+\theta)}}\;\leq\;\sqrt{\ln(e^{e^{-2 }}+\theta)}\]

Note that \(e^{e^{-2}}=1.14492\). This is less than \(2\), the value of \(\theta\) where \(\sqrt{\theta}/2-1/\sqrt{\theta}\) becomes positive. 

## Appendix I Complete Psuedocode for Regularized 1-Dimensional Learning

In Algorithm 6, we provide a self-contained implementation of an algorithm for regularized online learning (Protocol 2). The algorithm is obtained by combing Algorithm 3 with Algorithm 2.

### Efficient Projections for \(\psi(z)=z^{2}\)

Our algorithms for regularized online learning via epigraphs (Protocol 3) require projections to the set \(\{y\geq\psi(x)\}\). While in general this projection may be expensive, for simple function \(\psi\) of interest, such as \(\psi(z)=z^{2}\), this projection is relatively straightforward. In the following we provide a formula for this projection that is easy to compute (if a little ungainly to look at).

**Proposition 28**.: _Let \(\psi:\mathbb{R}\rightarrow\mathbb{R}\) be given by \(\psi(x)=x^{2}\). Define the norm \(\|(x,y)\|^{2}=hx^{2}+\gamma^{2}y^{2}\), the function \(S(\hat{x},\hat{y})=\inf_{y\geq\psi(x)}\|(x,y)-(\hat{x},\hat{y})\|\), and the projection \(P(\hat{x},\hat{y})=\text{argmin}_{y\geq\psi(x)}\|(x,y)-(\hat{x},\hat{y})\|\). Then for any \(\hat{y}<\psi(\hat{x})\), we have \(P(\hat{x},\hat{y})=(x,y)\) with \(y=x^{2}\) and:_

\[x=\frac{2^{1/3}(G^{2}-2\gamma^{2}\hat{y})}{Z^{1/3}}-\frac{Z^{1/3}}{6\cdot 2^{1 /3}\gamma^{2}}\]

_with_

\[Z=-108G^{2}\gamma^{4}\hat{x}+2\sqrt{2916G^{2}\gamma^{8}\hat{x}^{2}+(6G^{2} \gamma^{2}-12\gamma^{4}\hat{y})^{3}}\]

_Moreover, \(\nabla S(\hat{x},\hat{y})=\bigg{(}\frac{G^{2}(\hat{x}-x)}{\sqrt{G^{2}(x-\hat{ x})^{2}+\gamma^{2}(y)^{2}}},\frac{\gamma^{2}(\hat{y}-y)}{\sqrt{G^{2}(x-\hat{ x})^{2}+\gamma^{2}(\hat{y}-y)^{2}}}\bigg{)}\)_

Proof.: Since the \((x,y)\) is on the boundary of the constraint, we clearly have \(y=x^{2}\). Note that \((x,y)=\text{argmin}_{y\geq\psi(x)}\|(x,y)-(\hat{x},\hat{y})\|^{2}\). Thus, by LaGrange multipliers, we have for some \(\lambda\):

\[2G^{2}(x-\hat{x}) =\lambda\psi^{\prime}(x)=2\lambda x\] \[2\gamma^{2}(y-\hat{y}) =-\lambda\]```
Input: Non-negative convex function \(\psi:\mathbb{R}\rightarrow\mathbb{R}\). Parameters \(\gamma>0\), \(p\in[0,1/2]\), \(\epsilon_{x}>0\) and \(\epsilon_{\psi}>0\)  Initialize \(k=3\). if\(p=1/2\)then  Define constant \(c=3\) else  Define constant \(c=1\) endif for\(t=1\ldots T\)do  Receive \(h_{t}\geq h_{t-1}\in\mathbb{R}\).  Set \(h_{t}^{x}=3h_{t}\).  Set \(h_{t}^{y}=3\gamma\)  Define \(V_{t}^{x}=9h_{t}^{2}+\sum_{i=1}^{t-1}(g_{i}^{x})^{2}\).  Define \(V_{t}^{y}=9\gamma^{2}+\sum_{t=1}^{t-1}(g_{i}^{y})^{2}\) if\(p=1/2\)then  Set \(\alpha_{t}^{x}=\frac{\epsilon}{\sqrt{c+\sum_{i=1}^{t-1}(g_{i}^{x})^{2}/(h_{i}^{ x})^{2}}\log^{2}(c+\sum_{i=1}^{t-1}(g_{i}^{x})^{2}/(h_{i}^{x})^{2})}\)  Set \(\alpha_{t}^{y}=\frac{\psi(\epsilon)}{\sqrt{c+\sum_{i=1}^{t-1}(g_{i}^{y})^{2}/ (h_{i}^{y})^{2}}\log^{2}(c+\sum_{i=1}^{t-1}(g_{i}^{y})^{2}/(h_{i}^{y})^{2})}\) else  Define \(\alpha_{t}^{x}=\frac{\epsilon}{\left(c+\sum_{i=1}^{t-1}(g_{i}^{x})^{2}/(h_{i}^ {x})^{2}\right)^{y}}\)  Define \(\alpha_{t}^{y}=\frac{\psi(\epsilon)}{\left(c+\sum_{i=1}^{t-1}(g_{i}^{x})^{2}/ (h_{i}^{y})^{2}\right)^{y}}\) endif  Define \(\Theta_{t}^{x}=\left\{\begin{array}{ll}\frac{\left(\sum_{i=1}^{t-1}g_{i}^{x }\right)^{2}}{4k^{2}V_{t}^{x}}&\text{if }\left|\sum_{i=1}^{t-1}g_{i}^{x}\right| \leq\frac{2kV_{t}^{x}}{h_{t}^{x}}\\ \frac{\left[\sum_{i=1}^{t-1}g_{i}^{x}\right]}{h_{t}^{x}}-\frac{V_{t}^{x}}{(h_{ t}^{x})^{2}}&\text{otherwise}\end{array}\right.\)  Define \(\Theta_{t}^{y}=\left\{\begin{array}{ll}\frac{\left(\sum_{i=1}^{t-1}g_{i}^{y }\right)^{2}}{4k^{2}V_{t}^{y}}&\text{if }\left|\sum_{i=1}^{t-1}g_{i}^{y} \right|\leq\frac{2kV_{t}^{y}}{h_{t}^{y}}\\ \frac{\left[\sum_{i=1}^{t-1}g_{i}^{y}\right]}{k^{y}}-\frac{V_{t}^{y}}{(h_{t}^{ y})^{2}}&\text{otherwise}\end{array}\right.\)  Set \(\hat{x}_{t}=-\text{sign}\left(\sum_{i=1}^{t-1}g_{i}^{x}\right)\alpha_{t}^{x} \left(\exp(\Theta_{t}^{x})-1\right)\)  Set \(\hat{y}_{t}=-\text{sign}\left(\sum_{i=1}^{t-1}g_{i}^{y}\right)\alpha_{t}^{x} \left(\exp(\Theta_{t}^{y})-1\right)\)  Define the norm \(\|(x,y)\|_{t}^{2}=h_{t}^{2}x^{2}+\gamma^{2}y^{2}\), with dual norm \(\|(g,a)\|_{\star,t}^{2}=\frac{g^{2}}{h_{t}^{2}}+\frac{a^{2}}{\gamma^{2}}\).  Define \(S_{t}(\hat{x},\hat{y})=\inf_{\hat{y}\geq\hat{x})}\|(x,y)-(\hat{x},\hat{y})\|_ {t}\)  Compute \(x_{t},y_{t}=\text{argmin}_{y\geq\psi(x)}\|(x_{t},y_{t})-(\hat{x},\hat{y})\|_ {t}\).  Output \(w_{t}=x_{t}\), receive feedback \(g_{t}\in[-h_{t},h_{t}]\), \(a_{t}\in[0,\gamma]\), such that \(a_{t}=0\) unless \(|g_{t}|=h_{t}\).  Compute \((\delta_{t}^{x},\delta_{t}^{y})=\|g_{t}\|_{\star,t}\cdot\nabla S_{t}(\hat{x}_{t },\hat{y}_{t})\)  Set \(g_{t}^{x}=g_{t}+\delta_{t}^{x}\).  Set \(g_{t}^{y}=a_{t}+\delta_{t}^{y}\). endfor
```

**Algorithm 6** Regularized 1-dimensional learner (Reg) for Protocol 2This implies:

\[x =\frac{G^{2}\hat{x}}{G^{2}-\lambda}\] \[y =\hat{y}-\frac{\lambda}{2\gamma^{2}}\]

Moreover, we also must have \(y=x^{2}\), so that:

\[\frac{G^{4}\hat{x}^{2}}{(G^{2}-\lambda)^{2}} =\hat{y}-\frac{G^{2}}{2\gamma^{2}}+\frac{G^{2}-\lambda}{2\gamma^{2}}\] \[\frac{(G^{2}-\lambda)^{3}}{2\gamma^{2}}+\left(\hat{y}-\frac{G^{2} }{2\gamma^{2}}\right)(G^{2}-\lambda)^{2}-G^{4}\hat{x}^{2} =0\]

This is clearly a cubic equation in \(\lambda\), and so we can apply the cubic formula (via Mathematica) to obtain the following result:

\[\lambda=\frac{2G^{2}}{3}+\frac{2\gamma^{2}\hat{y}}{3}-\frac{2^{5/3}G^{2} \gamma^{2}+2^{11/3}G^{2}\gamma^{4}\hat{y}+2^{11/3}\gamma^{6}\hat{y}^{2}}{Z^{2/ 3}}-\frac{Z^{2/3}}{9\cdot 2^{5/3}\gamma^{2}}\]

where

\[Z=-108G^{2}\gamma^{4}\hat{x}+2\sqrt{2916G^{2}\gamma^{8}\hat{x}^{2}+(6G^{2} \gamma^{2}-12\gamma^{4}\hat{y})^{3}}\]

which yields:

\[x=\frac{2^{1/3}(G^{2}-2\gamma^{2}\hat{y})}{Z^{1/3}}-\frac{Z^{1/3}}{6\cdot 2^{1 /3}\gamma^{2}}\]

and \(y=x^{2}\).

The expression for \(\nabla S(\hat{x},\hat{y})\) follows directly from [16] Theorem 4.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: The main claims do accurately reflect the paper's contribution. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: Yes, see the discussion section. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: We provide a proof-sketch in the main paper and detailed proofs in the appendix. Guidelines: * The answer NA means that the paper does not include theoretical results. * All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced. * All assumptions should be clearly stated or referenced in the statement of any theorems. * The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. * Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. * Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [NA] Justification: [NA] Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [NA] Justification: This paper has only mathematical content. There are no experiments in this paper. Guidelines:

* The answer NA means that paper does not include experiments requiring code.
* Please see the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details.
* While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).
* The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines ([https://nips.cc/public/guides/CodeSubmissionPolicy](https://nips.cc/public/guides/CodeSubmissionPolicy)) for more details.
* The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.
* The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.
* At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).
* Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.

6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [NA] Justification: This paper has only mathematical content. There are no experiments in this paper. Guidelines:

* The answer NA means that the paper does not include experiments.
* The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.
* The full details can be provided either with the code, in appendix, or as supplemental material.

7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [NA] Justification: [NA] Guidelines:

* The answer NA means that the paper does not include experiments.
* The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.
* The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).
* The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)
* The assumptions made should be given (e.g., Normally distributed errors).

* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [NA] Justification: This paper has only mathematical congettent. There are no experiments in this paper. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics [https://neurips.cc/public/EthicsGuidelines?](https://neurips.cc/public/EthicsGuidelines?) Answer: [Yes] Justification: This paper does conform to the code of ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [No] Justification: This paper provides a purely mathematical contribution. As such, it is subject to the standard ethical concerns present for all mathematical papers, but no further ones. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: This paper has only mathematical congett. There are no experiments in this paper. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] Justification: This paper has only mathematical congett. There are no experiments in this paper. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.

* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
13. **New Assets** Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: This paper has only mathematical congent. There are no experiments in this paper. Guidelines: * The answer NA means that the paper does not release new assets. * Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. * The paper should discuss whether and how consent was obtained from people whose asset is used. * At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
14. **Crowdsourcing and Research with Human Subjects** Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: This paper has only mathematical congent. There are no experiments in this paper. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. * According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
15. **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects** Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: This paper has only mathematical congent. There are no experiments in this paper. Guidelines: * The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. * Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.

* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.