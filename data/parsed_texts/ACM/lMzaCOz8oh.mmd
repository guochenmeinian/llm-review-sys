[MISSING_PAGE_FAIL:1]

those items of interest may be mistakenly substituted by small/non-persistent ones, which harms detection accuracy.

(ii) **High update throughput:** Detection schemes should be capable of processing items swiftly to keep pace with high-speed data streams. Recent designs that utilize an external DRAM (Dynamic Random Access Memory) based data structure to record candidate items (Garner et al., 2017; Wang et al., 2018) and handle hash collisions incur excessive memory access overheads and make it impossible to match high-speed line rates. Besides, the update operation should be further harness parallel acceleration techniques, such as SIMD instructions, to further enhance processing speeds.

(iv) **Ease of configuration:** Sketches should be straightforward to set up, without over-reliance on intricate parameter tuning. Strategies such as PIE (Zhu et al., 2018) demand intricate tuning and the detection accuracy is highly sensitive to variations in parameter values, posing challenges when dealing with diverse data streams that have varying distributions.

(v) **Practical deployment:** Data stream processing schemes should be easily implementable on various hardware platforms, including but not limited to Field-Programmable Gate Arrays (FPGA) and programmable switches, which offer the highest processing speed but also present the most stringent design constraints.

These challenges motivate us to harness other statistics and devise Stable-Sketch, a new versatile sketch framework based on _multi-dimensional_ features, which simultaneously achieves _high detection accuracy, memory efficiency, and processing speed_. We recognize that the state of each bucket can be leveraged to identify different item types. _If items stored in a bucket change frequently (indicating the stability of the bucket is low), that bucket more likely stores small-size items that can be discarded quickly; otherwise, it tends to track large items_. Based on this insight, our Stable-Sketch substitutes items recorded in buckets by computing replacement probabilities based on both item information and bucket stability. As a result, the larger the size of an item stored in a bucket and the higher the bucket stability, the harder it will be to replace that item with others. _This strategy also eliminates the need for complex parameter tuning and ensures easy deployment in practical scenarios._ Notice that even though recording the status of buckets in the sketch adds memory overhead, our results will reveal that this can be negligible compared with the achievable improvements in detection accuracy.

### Contributions

To the best of our knowledge, Stable-Sketch is the first approach that utilizes the _bucket stability_ feature for diverse item detection tasks, including heavy hitters, heavy changers, and persistent items. This brings the following key advantages. First, Stable-Sketch has _high memory efficiency_ since it does not rely on additional data structures to hold candidate items and stops redundant hash operations once an item finds an available bucket, thus saving memory to record more items. Second, Stable-Sketch offers _fast processing speeds_ - during the update process, it does not depend on pointers and reduces repetitive hash actions. During the query process, it only needs a scan of all buckets, leading to a short time of returning all heavy/persistent items. Third, Stable-Sketch attains _high detection accuracy_. We provide theoretical proofs of the error bounds of our approach and demonstrate its superiority over state-of-the-art solutions via extensive trace-driven experiments. We further accelerate Stable Sketch's update speed with Single Instruction Multiple Data (SIMD) instructions (Shen et al., 2017). Lastly, we prototype Stable-Sketch with P4 (Zhu et al., 2018) and quantify its overhead, making the case for its _deployment in practice_. The source code of Stable-Sketch is available at (Zhu et al., 2018).

## 2. Problem Statement

We first formalize the definitions of data stream and the item detection tasks of interest, while symbols used frequently are summarized in Appendix A.

**Data Stream:** A data stream \(Q\) consists of a sequential series of items \(f_{1},f_{2},\cdots,f_{i},\cdots\). Each item \(f\) owns a frequency and persistence value denoted by \(V(f)\) and \(P(f)\), respectively.

**Heavy Hitter Detection:** Given a data stream \(Q\) with different items, a heavy hitter is identified within \(Q\) whenever the frequency of that item surpasses a pre-set threshold, defined as \(\partial N\), where \(\theta\) is a user-defined parameter in the (0,1) range and \(N\) represents the total frequency of all items in \(Q\).

**Heavy Changer Detection:** To detect heavy changers, we compare an item \(f\)'s frequency in two consecutive epochs, \(E_{1}\) and \(E_{2}\). Suppose the frequency of \(f\) in these epochs is \(q_{1}\) and \(q_{2}\), respectively. If the absolute difference between \(q_{1}\) and \(q_{2}\) exceeds the established heavy changer threshold \(\phi D\), item \(f\) is classified as a heavy changer, where \(D\) is the total absolute change of all items across two epochs.

**Persistent Item Detection:** A data stream composed of multiple items can be divided into \(G\) equal and contiguous time windows. An item \(f\)'s persistence is quantified by the total number of windows in which it appears. If the persistence of an item is greater than a set threshold \(\phi G\), where \(\phi\) is a parameter in (0,1), the item is categorized as persistent.

## 3. Stable-Sketch Design

In this section, we first discuss the rationale behind our Stable-Sketch design, then delve into its data structure and basic operations. Afterwards, we explain how to deploy Stable-Sketch for different detection tasks, before formally analyzing its performance.

### Rationale

Recall that sketches utilize summary data structures to record item information within a fixed number of buckets. Similar to (Garner et al., 2017; Wang et al., 2018; Wang et al., 2018), we initialize Stable-Sketch as a two-dimensional array with \(m\) rows, in which each row contains \(u\) buckets to record the values of items hashed to these buckets. Compared with existing approaches, the advancements Stable-Sketch brings are two-fold:

(i) Current schemes use a uni-dimensional feature for replacement decisions, mostly replacing items importantly based on their frequency or persistence value, resulting in _many heavy/persistent items being erroneously evicted by non-heavy/persistent ones_. To illustrate this problem, we resort to MV-Sketch (Garner et al., 2017), a state-of-the-art scheme for heavy hitter detection, and three CAIDA datasets (Zhu et al., 2018). More details about the scheme and datasets are in Section 5. We vary the memory size from 16KB to 256KB (Zhu et al., 2018) and measure how many times non-heavy items mistakenly expel heavy items during the update process. As seen in Table 1, the number of wrong replacement events increases dramatically as the memory size decreases.

For instance, when the memory size is tight (16KB), the number of erroneous replacement events are 2,287\(\times\) higher than when having a larger memory (256KB), under the CAIDA 2018 dataset. This indicates that MV-Sketch cannot provide enough protection for heavy items under constrained memory budgets.

To tackle this problem, we explore another powerful metric that we introduce to provide more protection to potential heavy items and prevent them from being effortlessly expelled from buckets. In particular, the item distribution of real data streams is known to be highly skewed (Zhu et al., 2019), while heavy items carry more data than non-heavy ones (Zhu et al., 2019). Therefore, it should take more effort to evict heavy items than non-heavy ones recorded in a bucket. Based on this observation, we harness the status of each bucket to identify the type of items recorded. Specifically, if the items stored in a bucket change frequently, meaning that the bucket has low stability, then the bucket is more likely to track some non-heavy items; otherwise, it indicates that the bucket tends to record heavy items.

To verify this feature, we use MV-Sketch to compare the stability of each bucket under different memory sizes (16KB, 32KB) and datasets. The computation of bucket stability is as follows: when a new item arrives, if the item recorded in the hashed bucket does not change, the stability of the corresponding bucket increases by 1; otherwise, the stability decreases by 1 (not less than 0). As shown in Figure 1, we find that the buckets that track heavy items own larger stability than those that track non-heavy ones. For instance, for the CAIDA 2015 trace, the average bucket stability for heavy items is 1.55\(\times\) and 2.48\(\times\) higher than for non-heavy ones under 16KB and 32KB memory, respectively. These results reveal that the bucket that records heavy items tends to have stronger stability since more attempts are required to replace them.

Therefore, our Stable-Sketch calculates a stochastic decay probability based on multi-dimensional statistics, i.e., _item information and bucket stability_, to decide whether to replace tracked items. As recorded item statistics and bucket stability increase for a bucket, meaning that it potentially tracks a heavy item, the likelihood of this item being successfully replaced by other items decreases, thus improving detection accuracy.

(ii) Besides, recent sketch-based methods like Count-min Sketch (Chen et al., 2019) and MV-Sketch (Chen et al., 2019) hash each item in all rows, and then increment corresponding counters, which harms memory efficiency. In contrast, our Stable-Sketch, gives up repetitive hash operations once a newly arrived item finds an available bucket, to release memory for storing more items, thereby improving memory efficiency.

### Data Structure

The data structure of recent sketches can be categorized into flat (Chen et al., 2019) and hierarchical (Chen et al., 2019; Chen et al., 2019). Hierarchical ones often incorporate multiple layers to enable the tracking of heavy and non-heavy items separately. Despite potential benefits in terms of accuracy, the hierarchical data structure challenges the update speed and practical deployment, especially in programmable switches with strict design constraints. Therefore, in our Stable-sketch design, we harness the conventional flat structure.

We illustrate Stable-Sketch's data structure in Figure 2, which consists of \(m\) rows and \(u\) columns. Each row is associated with a different pairwise-independent hash function \(h_{1},\cdots,h_{m}\). We use \(B\left(i,j\right)\) to denote the bucket at the \(i\)-th row and the \(j\)-th column, where \(1\leq i\leq m\) and \(1\leq j\leq u\). Each bucket contains three fields: \(B\left(i,j\right)\). \(X\) tracks the key of the current candidate item; \(B\left(i,j\right)\). \(V\) stores the statistic of the candidate item, e.g., item frequency or persistence value; and \(B\left(i,j\right)\). \(S\) represents the stability of this bucket. If a new item hashed into the bucket without successfully replacing the already recorded one, the stability of this bucket increases by 1; otherwise, it indicates the newly arrived item occupies this bucket, and the stability decreases by 1. Since each bucket owns a fixed memory size, the number of buckets in each row can be altered based on the pre-allocated memory size and the number of rows.

By default, Stable-Sketch keeps track of an item's key to ensure excellent invertibility. However, in certain cases, the key may be excessively long, and memory resources may be limited. In such scenarios, to further ameliorate the memory utilization of Stable-Sketch, we also propose a variant named Stable-Sketch", in which we record the item's _fingerprint_ instead of the key of the incumbent item in the bucket. The detail of Stable-Sketch" and its performance can be found in Appendix C.5. While there are techniques available for dynamically adjusting the counter size to minimize memory usage (Chen et al., 2019; Chen et al., 2019; Chen et al., 2019), we opt against using them. This is because they typically have a negative impact on the update and query speeds and are usually challenging to deploy on practical hardware platforms such as programmable switches.

### Basic Operations

Stable-Sketch performs two main operations: 1) \(Update\), which maps an arriving item into the sketch, based on multi-dimensional

\begin{table}
\begin{tabular}{c c c c c c} TraceSize & 16KB & 32KB & 64KB & 128KB & 256KB \\ \hline CAIDA 2015 & 392,082 & 161,113 & 33,076 & 4,810 & 909 \\ CAIDA 2016 & 563,005 & 247,301 & 46,097 & 4,742 & 722 \\ CAIDA 2018 & 432,362 & 247,879 & 48,393 & 2,379 & 189 \\ \hline \end{tabular}
\end{table}
Table 1. Number of heavy items being wrongly replaced by non-heavy ones in MV-Sketch, applied to three datasets.

Figure 1. Cumulative Distribution Function (CDF) of bucket stability for (non-)heavy items tracked under different traces and L1 caches, when employing MV-Sketch. Observe how buckets storing heavy items yield higher bucket stability.

Figure 2. Data structure of Stable-Sketch.

information in a probabilistic manner; 2) _Query_, which returns heavy/persistent items whose estimated relevance value is greater than a specific threshold.

```
Input: an item \(f\), hash functions \(h_{1},h_{2},...,h_{m}\), \(min\leftarrow+\infty\)
1Initialization: The counters and item key of each bucket are initialized to 0 and \(null\), respectively.
2for\(i=1\) to \(m\)do
3if\(B(i,h_{i}(f)).K==null\)then
4\(B(i,h_{i}(f)).K\gets f.key\);
5\(B(i,h_{i}(f)).V\gets 1\);
6\(B(i,h_{i}(f)).S\gets 1\);
7return;
8
9elseif\(B(i,h_{i}(f)).K==f.key\)then
10\(B(i,h_{i}(f)).V\gets B(i,h_{i}(f)).V+1\);
11\(B(i,h_{i}(f)).S\gets B(i,h_{i}(f)).S+1\);
12return;
13elseif\(B(i,h_{i}(f)).V<min\)then
14\(min=B(i,h_{i}(f)).V\);
15\(R\gets i;M\gets h_{R}(f.key)\);
16
17if\(rand(0,1)<\frac{1}{B(R,M).V\times B(R,M).S+1}\)then
18\(B(R,M).V\gets B(R,M).V-1\);
19if\(B(R,M).V=0\)then
20\(B(R,M).key\gets f.key\);
21\(B(R,M).V\gets 1\);
22\(B(R,M).S\leftarrow\max[B(R,M).S-1,0]\);
23return;
24
25else
26 Evict the newly arrived item;
27return;
```

**Algorithm 1**Stable-Sketch's Update Procedure

#### 3.3.1. Update

Algorithm 1 gives the pseudo-code for the update process. First, all fields in the data structure are initialized to 0 or \(null\). When a new item \(f\) arrives, Stable-Sketch utilizes the function \(h_{1}\) to hash \(f\) to bucket \(B\left(1,h_{1}(f)\right)\). Then, one of three cases follows:

_Case 1:_ If the bucket \(B\left(1,h_{1}(f)\right)\) is empty, we insert item \(f\) into this bucket and configure \(B\left(1,h_{1}(f)\right).K\) as \(f.key\), \(B\left(1,h_{1}(f)\right).V\) and \(B\left(1,h_{1}(f)\right).S\) as \(\left(1\text{ Lines 3-7}\right)\).

_Case 2:_ If \(B\left(1,h_{1}(f)\right)\) has been occupied by item \(f\), we increase both the value counter \(B\left(1,h_{1}(f)\right).V\) and the stability counter \(B\left(1,h_{1}(f)\right).S\) by \(1\). Otherwise, Stable-Sketch checks the buckets in the next row sequentially with the hash functions \(h_{2},\cdots,h_{m}\). Once item \(f\) finds an available bucket in the \(i\)-th row, the hash operation terminates \(\left(\text{ Lines 8-11}\right)\).

_Case 3:_ Suppose item \(f\) cannot find an available bucket, indicating that it encounters hash collisions in all rows. In this case, Stable-Sketch harnesses a probability-based replacement strategy to decide whether to save or dismiss the current item \(f\). Specifically, Stable-Sketch first selects the bucket with the smallest value counter among \(m\) hashed buckets (Lines 12-14). Note that if multiple buckets own the same smallest value, Stable-Sketch will choose the first among them, denoted as \(B(R,M)\). Then, Stable-Sketch computes a replacement probability \(L(f)\) as \(\frac{1}{B(R,M).V\times B(R,M).S+1}\). This reflects that for an item saved in a bucket, the larger \(B\left(R,M\right).V\) and \(B\left(R,M\right).S\) are, the more challenging it will be for other items to successfully evict the stored one. If a newly arrived item fails to trigger the replacement mechanism, Stable-Sketch will discard this item. Otherwise, Stable-Sketch will decrease \(B\left(R,M\right).V\) by \(1\). If \(B\left(R,M\right).V\) reaches \(0\), Stable-Sketch will update the item key with that of the newly arrived one, decrease \(B\left(R,M\right).S\) by \(1\), and set \(B\left(R,M\right).V\) to \(1\) (Lines 15-21). Compared with probability-based replacement [34], probability-based decay ensures that the estimation error is strictly one-sided, i.e., potentially exhibiting only underestimation. An investigation of the impact of different replacement probabilities expressions \(L(f)\) on the performance of the detection accuracy is available in Appendix C.4.3.

#### 3.3.2. Query

For item queries, Stable-Sketch scans all buckets and if the estimated value \(B\left(i,j\right).V\) of an item \(f\) is greater than a predefined threshold, then \(f\) is considered an item to be found.

### Applying Stable-Sketch to Different Detection Tasks

We deploy Stable-Sketch for three applications: finding heavy hitters, heavy changers, and persistent items. Note that Stable-Sketch can be easily applied also to other tasks, such as finding super-spreaders [28, 46, 47], significant items [48] and bursts [49, 50]. Due to space limitations, we do not include results for these tasks here.

#### 3.4.1. Heavy Hitter Detection

Given that Stable-Sketch can be directly employed for detecting heavy hitters, the update and query processes remain consistent with what has been detailed in Section 3.3. To enhance comprehension of the update operation in Stable-Sketch, we include several illustrative examples, summarized in Figure 3. For these examples, we assume a sketch with three rows, each containing two buckets.

_Case 1:_ When item \(f_{5}\) arrives, it uses the hash function \(h_{1}\) to locate an available bucket in the first row. Given that the hashed bucket is currently empty, we can insert \(f_{5}\) into the sketch and update the structure from \((Null,0,0)\) to \(\left(f_{5},1,1\right)\). As \(f_{5}\) has been successfully inserted, we terminate the hash operation to conserve memory for storing other items and to reduce the update time.

_Case 2:_ When item \(f_{6}\) arrives, it attempts to locate an available bucket by hashing in each row sequentially. Eventually, \(f_{6}\) successfully finds a match in the third row. As a result, both the frequency counter and stability counter are incremented by one, updating the structure from \(\left(f_{6},4,4\right)\) to \(\left(f_{6},5,5\right)\).

_Case 3:_ When item \(f_{7}\) arrives, it experiences hash collisions across all rows in the sketch. Consequently, it searches for the bucket that contains the smallest value counter \(\left(f_{6}\right)\) to initiate a decay operation on the current item. This decision is guided by the probability \(\frac{1}{3\times 3+1}\). If the decay operation succeeds and reduces the value counter to \(0\), item \(f_{7}\) replaces the current item in the bucket. Otherwise, item \(f_{7}\) is discarded.

#### 3.4.2. Heavy Changer Detection

We compare two sketches at the end of two consecutive epochs \(E_{1}\) and \(E_{2}\) to find heavy changers. For each epoch, we construct a Stable-Sketch to record the frequency of each item and the insertion process is the same as in Section 3.3. During the query process, if the frequency difference of item \(f\) is greater than the heavy changer threshold, item \(f\) is viewed as a heavy changer.

#### 3.4.3. Persistent Item Detection

Since the persistence of an item only increases by one at each time window, we add a flag bit (_On_/_Off_) in Stable-Sketch's data structure to remove duplicates (Gan et al., 2017). Status _On_ is representative of an arrived item that has not yet accessed the mapped bucket in this time window, and then Stable-Sketch increments both counters by one and turns the flag to _Off_. At the beginning of each time window, all the flags in buckets are reset to _On_. During the insertion process, Stable-Sketch first finds an available bucket for item \(f\). If this fails, it will find the bucket with the smallest persistence value to conduct the replacement. If the flag bit of the selected bucket is _Off_, signifying that the saved item has arrived in this window, the newly arrived item will abandon the replacement. Otherwise, Stable-Sketch executes the replacement procedure as in Algorithm 1 (Lines 15-24). The query process for reporting persistent items is consistent with Section 3.3.

## 4. Mathematical Analysis

We verify that Stable-Sketch has one-sided error and establish the error bound using heavy hitter detection. Finally, we conduct a detailed empirical study to validate our theoretical results.

### No Over-estimation Error

Theorem 4.1.: _For any given item \(f\), let \(V_{t}(f)\) and \(\hat{V}_{t}(f)\) denote the actual frequency and estimated frequency at a particular time \(t\), respectively. Then \(\hat{V}_{t}(f)\leq V_{t}(f)\)._

Proof.: The detailed proof can be found in Appendix B.1. 

### Error Bound of Stable-Sketch

To derive the error bound, we make an assumption that is generally valid (confirmed in Appendix B.3.2): once a heavy item enters a bucket, it remains in the bucket until the detection task is complete. Then we get the error bound of Stable-Sketch as

Theorem 4.2.: _Given a small positive number \(\beta\) and a heavy item \(f\) with frequency \(V(f)\), the inequality \(\Pr\left[V(f)-\hat{V}(f)\geq\lceil\beta N\rceil\right]\leq\frac{\left[\ln(V(f) )+\infty\right]}{\beta N\ln(S)}\) holds, where \(\varphi\) denotes the Euler-Mascheroni constant, \(S\) denotes the bucket stability that records item \(f\), and \(N\) represents the total number of entries for all items._

Proof.: A comprehensive derivation of the bound is available in Appendix B.2. 

### Empirical Validation

We perform a series of empirical evaluations to validate the accuracy of Theorem 1, assess the plausibility of our assumption, verify the correctness of Theorem 2, and compare our method with existing approaches. For comprehensive information regarding the empirical validation process, please refer to Appendix B.3.

## 5. Experimental Results

To demonstrate the performance of Stable-Sketch, we conduct experiments on a server equipped with an 8-core Intel(R) Xeon(R) W-2123 CPU @ 3.60GHz and 32GB DRAM memory, running Ubuntu 16.04 LTS. Each core possesses an L1 data cache with 32KB memory and a 1024KB L2 cache. All cores share an 8448KB L3 cache.

**Dataset:** We use three real-world datasets for evaluation: 1) CAIDA (Cai et al., 2018): IP traffic traces collected at Equinix-Chicago, specifically CAIDA15, CAIDA16, and CAIDA18 from 2015, 2016, and 2018, respectively, with a 0.45M, 0.64M, and 1.29M items. 2) MAWI (Cai et al., 2018): a dataset by the MAWI group analyzing Japanese wide area networks. We select a 15-minute 2022 trace with approximately 19.58M items. 3) Campus (Cai et al., 2018): gathered from a campus DNS network with over 4000 users during peak hours for 10 days in April-May 2016. We randomly choose a trace from April with 0.87M distinct items.

**Benchmarks:** For detecting _heavy hitters_ and _heavy changers_, we conduct a comparative evaluation of Stable-Sketch against nine existing approaches: (1) _probability-based_ methods including CoCoSketch (Cai et al., 2018), USS (Song et al., 2018), RAP (Song et al., 2018), and PRECISION (Song et al., 2018); (2) _non-probability-based_ methods including MV-Sketch (Chen et al., 2018), Elastic (Song et al., 2018), CMHeap (Song et al., 2018), CountHeap (Song et al., 2018), and Space-Saving (Song et al., 2018). For RAP and PRECISION, the number of arrays is configured as 2 (Song et al., 2018). For MV-Sketch, we set the number of rows to a {7, 56}. The parameters for the rest of the schemes are aligned with (Cai et al., 2018). More details about these benchmarks are discussed in Section 6. We configure the default threshold \(\theta\) as 0.0005, meaning that if the item frequency is over \(\theta N\), it will be identified as a heavy hitter. The threshold of heavy changer detection is consistent with finding heavy hitters (Cai et al., 2018). For _persistent item lookup_, we pick three baselines: Small-Space (SS) (Gan et al., 2018). WavingSketch (Cai et al., 2018), and On-Off Sketch (Gan et al., 2018). Since PIE (Song et al., 2018) only works under large memory allocations, we omit a comparison here. The number of key-value pairs in On-Off Sketch and the number of cells in WavingSketch are both set as 16 (Cai et al., 2018). We divide each dataset into 1,600 time windows (Gan et al., 2018) and set the threshold \(\phi\) to 0.5, indicating that if an item appears over 800 windows, it will be recognized as persistent. Notice that we also _alter the threshold for different detection tasks_ to verify Stable-Sketch's robustness in Appendix C.3.

**Implementation:** We implement Stable-Sketch and other approaches in C++ and use the source-destination address pairs as item keys (64 bits). For all the traffic, we concentrate on the IPv4 items only and adopt MurmurHash (MurmurHash, 1999) to hash these items into the sketch. We fix the number of rows \(m=4\)(Chen et al., 2018; Chen et al., 2018) and adjust \(u\) according to the pre-allocated memory size.

**Metrics:** 1) Precision: the ratio of correctly reported items to all reported ones; 2) Recall: the ratio of correctly reported items to all correct items; 3) F1 score: \(\frac{2\times recall\times precision}{recall\times precision}\); 4) Average Relative Error (ARE): \(\frac{1}{|\Omega|}\sum_{f\in\Omega}\frac{|S(f)-\hat{S}(f)|}{S(f)}\), where \(\Omega\) is the set of true heavy/persistent items reported; 5) Update Throughput: the update speed of the scheme expressed in million operations (insertions) per second (Mops). We conduct each experiment five times and choose median values as in (Cai et al., 2018).

### Detection Accuracy on Different Tasks

#### 5.1.1. Heavy Hitter Detection

Figures 4-5 compare the detection performance of Stable-Sketch with that of the benchmarks

Figure 3. Examples of the update procedure in Stable-Sketch for the heavy hitter detection task.

considered, across three authentic datasets: CAIDA, MAWI, and Campus.

As illustrated in Figure 4, Stable-Sketch consistently achieves the highest F1 score across all settings, demonstrating an average improvement over existing algorithms ranging from 9.45% to 139.81% on the CAIDA 2015, 18.28% to 188.23% on the CAIDA 2016, 12.75% to 542.19% on the CAIDA 2018, 5.19% to 664.62% on the MAWI dataset, and 11.45% to 180.19% on the Campus dataset.

_The remarkable F1 score performance of Stable-Sketch can be attributed to its exceptional precision and commendable recall rates. Due to space constraints, we have relocated the results and analysis of recall and precision to Appendix C.1._ In summary, Stable-Sketch consistently maintains a precision score close to 1 across various memory budgets, outperforming existing approaches (as shown in Figure 14). This high precision is achieved through the use of multidimensional features (item and bucket statistics) and the probabilistic eviction of items stored in buckets. Stable-Sketch effectively prevents heavy hitters from being easily replaced by other items, even with limited available memory (16KB). Furthermore, we observe that for USS and SpaceSaving, precision decreases as memory size increases from 16KB to 128KB. This is due to their aggressive eviction of items stored in buckets, leading to more non-heavy items being incorrectly identified as heavy hitters with larger memory, resulting in reduced precision. RAP and PRECISION make replacement decisions based on probabilities computed from item frequency, which does not offer adequate protection for heavy items in highly skewed data streams, especially with tight L1 memory constraints, resulting in lower precision compared to Stable-Sketch. Figure 15 also demonstrates that Stable-Sketch maintains a commendable recall rate across different traces when compared to the baseline methods.

Additionally, Stable-Sketch demonstrates exceptionally low estimation error, with values close to zero in all memory settings (Figure 5). For example, when compared with RAP, Stable-Sketch reduces the ARE by 1837.63% in CAIDA 2015, 1103.7% in CAIDA 2016, 147.21% in CAIDA 2018, 1001.16% in the MAWI, and 25636.04% in the Campus traces on average.

Furthermore, we extend our evaluation of Stable-Sketch to encompass additional datasets and conduct comparisons with more advanced approaches to assess its performance comprehensively. For a deeper dive into this extended evaluation, please refer to Appendix C.2.

#### 5.1.2. **Heavy Changer Detection**

To illustrate the performance of heavy changer detection, we utilize the CAIDA 2018 trace as an example. In Figure 6(a), we observe that Stable-Sketch achieves significantly higher F1 scores compared to RAP and Elastic, with improvements of 24.83% and 80.57%, respectively. In terms of estimation error, Stable-Sketch outperforms other schemes, as evident from the lowest ARE values shown in Figure 6(b).

#### 5.1.3. **Persistent Item Detection**

Figure 7 provides insights into the F1 score and the ARE of persistent item lookup on the MAWI trace. It is evident that Stable-Sketch consistently maintains its optimality across different memory sizes. In comparison to the recent WavingSketch/On-Off Sketch approaches, Stable-Sketch achieves a remarkable increase in detection accuracy, with average improvements of 5428.75%/2852.76% on the MAWI trace. It is worth noting

Figure 4. Heavy hitter detection F1 score with different approaches, as a function of memory size.

Figure 5. Heavy hitter detection ARE with different approaches, as a function of memory size.

Figure 6. Heavy changer detection performance with different approaches (legend as in Figure 4).

that the performance of baselines considered is notably weaker on the MAWI dataset. This is primarily due to the heavier-tailed distribution in the MAWI dataset, which results in a smaller number of persistent items and increases the detection difficulty. Despite these challenges, Stable-Sketch consistently achieves the highest accuracy, thereby affirming its effectiveness in handling persistent item lookup tasks.

Besides, we also compare our method with the state-of-the-art On-Off Sketch with a memory size in the mega byte range. Specifically, we assess the performance of Stable-Sketch for persistent item lookup using the MAWI dataset, with memory sizes ranging from 1 to 1.3MB. The results reveal that Stable-Sketch achieves an F1 score between 0.981 and 0.991. In contrast, On-Off Sketch method yields F1 scores of 0.013 and 0.75 for the same memory sizes, which demonstrates the superior efficacy of Stable-Sketch.

### Performance in Multiple Cases

#### 5.2.1. Accuracy under different thresholds

To assess the robustness of Stable-Sketch, we vary threshold values for heavy item detection (0.0001 to 0.0021) and persistent item lookup (0.4 to 0.8). These experiments, conducted with CAIDA 2019 and new traces with varying skewness (0.2 and 0.8), consistently demonstrate our scheme's superior performance. Detailed detection accuracy analysis for various threshold settings is available in Appendix C.3.

#### 5.2.2. Ablation Study

In our evaluation, we examine the effectiveness of each component of Stable-Sketch, including the replacement mechanism based on multi-dimensional features and the avoidance of redundant hash operations when an incoming item finds an available bucket. Additionally, we assess the impact of different eviction probability formulations on detection accuracy. For a comprehensive analysis of these components and details, please refer to Appendix C.4.

#### 5.2.3. Stable-Sketch with Fingerprint

To assess the performance of Stable-Sketch with fingerprint, a detailed analysis is provided in Appendix C.5.

### Processing Speed

#### 5.3.1. Update Speed

We now evaluate the update speed of Stable-Sketch, taking heavy hitter and persistent item detection as examples. Figure 8 shows the update speed for different algorithms under the CAIDA 2018 trace. Results on other datasets exhibit similar trends. Observe in Figure 8(a) that Stable-Sketch's throughput surpasses that of all existing schemes for heavy hitter detection, with an improvement of 16.01% on average over MV-Sketch. Since counter-based approaches, such as RAP and SpaceSaving, usually depend on pointers for finding the minimum item to replace, resulting in a lower update speed. As reported in Figure 8(b), the average update throughput of Stable-Sketch is 25.57% higher than that of the state-of-the-art method On-Off Sketch. This stems from two aspects: 1) Stable-Sketch leverages a compact data structure that does not lean on supplementary heaps or Bloom filters (Zhou et al., 2018), which reduces the number of memory accesses; 2) Stable-Sketch abandons hash operations once an item finds an available bucket, mitigating the number of hash operations and guaranteeing a fast update speed.

#### 5.3.2. Query Time

We also compare the query time of several advanced schemes returning all heavy items across different datasets. As shown in Figure 9, since Stable-Sketch is invertible and does not require excessive hash operations during the query process, its query time is smaller than that of existing schemes. In contrast, MV-Sketch requires additional hash operations for query, leading to a longer query time. Stable-Sketch also maintains its good performance when returning persistent items (results omitted due to the space limitation).

### Accelerating the Update Speed with SIMD Instructions

We further accelerate the update speed of Stable-Sketch with SIMD instructions (Shao et al., 2018), allowing us to process sequential operations in parallel. When a new item arrives, we utilize the primitive MurnurHash3_x64_128 to calculate the hash value based on the item key and divide the hash value into \(m\) parts. Afterward, unlike the vanilla Stable-Sketch inspecting each row individually to find an available bucket, we use the SIMD primitive_mm256_cmpeq_epi64 to compare in parallel the newly arrived item's key with items recorded in \(m\) rows. In this manner, Stable-Sketch with SIMD instructions only requires 1 step to find an available bucket for a newly arrived item, mitigating redundant comparison operations.

Figure 8. Update speed with different approaches.

Figure 7. Persistent item detection performance with different approaches, as a function of memory size.

Figure 9. Query time for heavy items (memory size: 32KB).

We compare the update speed with the CAIDA 2016 trace. Observe in Figure 10, where we find that with the aid of SIMD, Stable-Sketch significantly improves the update throughput on average by 78.84% and 46.55% over vanilla Stable-Sketch for the heavy hitter and persistent item detection, respectively, confirming the effectiveness of SIMD instructions. Additionally, it is important to note that as the memory budget expands, it eventually exceeds the capacity of the fastest cache level (L1), necessitating data retrieval from slower caches or main memory. This shift in memory access results in increased latency, reducing the data processing throughput.

### Stable-Sketch Deployment in Practice

Here, we illustrate the practical feasibility of deploying Stable-Sketch on a programmable switch with minimal overhead. Our assessment of resource utilization reveals that Stable-Sketch conserves sufficient resources for other applications, affirming its viability for deployment on commercial hardware. For detailed implementation and evaluation results, please refer to Appendix C.6.

## 6. Related Work

We briefly introduce existing schemes for different detection tasks and highlight their drawbacks, which inspired our design.

**Heavy Item Detection:** Existing approaches can be categorized into counter- and sketch- based (Bauer et al., 2016). Counter-based schemes aim to reduce memory usage by replacing the smallest recorded counter item with the newly arrived one. Space-Saving (Shi et al., 2018) employs multiple counters, updating the corresponding counter when a new item matches an existing one, or evicting the item with the smallest counter value. However, limited memory and hash collisions can lead to incorrect replacements. Unbiased Space Saving (USS) (Shi et al., 2018) builds upon Space-Saving by minimizing variance to achieve unbiased estimation, but it still struggles with lookup accuracy under memory constraints. Random Admission Policy (RAP) (Shi et al., 2018) enhances detection accuracy by probabilistically replacing counters with the smallest value. PRECISION (Shi et al., 2018) employs partial recirculation, either probabilistic or deterministic, for a fraction of packets from unmonitored streams. These schemes are non-invertible, necessitating a full item key space scan to recover heavy items, resulting in high memory access overhead. Additionally, most counter-based methods use pointers for finding the minimal element during updates, leading to low update throughputs.

Unlike counter-based methods, sketch-based approaches hash items into memory entries, summarizing cumulative information for efficient updates and low memory utilization at the expense of bounded errors. Count-min Sketch (Bauer et al., 2016) hashes items into buckets, estimating size based on the minimum bucket value, while Count Sketch (Shi et al., 2018) uses the average bucket value for estimation. Count Sketch Heap extends Count Sketch with a heap to track heavy candidates and their estimated values. However, under small memory sizes, hash collisions can lead to overestimating non-heavy items, reducing lookup precision. These methods are also non-invertible, resulting in slower query speeds. MV-Sketch (Bauer et al., 2016) employs majority voting for invertible heavy item tracking. A-Sketch (Shi et al., 2018) introduces dynamic pre-filtering to identify and aggregate heavy items. Heavykeeper (Bauer et al., 2016) balances space and accuracy using count-with-exponential-decay, actively evicting small items while preserving large ones. Cold Filter (Shi et al., 2018) distinguishes cold and hot items, using a separate structure for hot item frequencies. Loglog Filter (Shi et al., 2018) utilizes register arrays to filter cold items, approximating their sum of frequencies. HeavyGuardian (Haywardt et al., 2018) isolates hot items, maintaining large counters for them and small counters for cold items. Elastic Sketch (Shi et al., 2018) consists of heavy and light parts to manage heavy and non-heavy items separately. CocoSketch (Shi et al., 2018) leverages "power-of-\(d\) choices" (Shi et al., 2018; Shi et al., 2018) and probabilistically replaces items stored in buckets. However, when making replacement decisions only based on item information, heavy items are easily replaced by non-heavy ones with a limited memory.

**Persistent Item Detection:** Recent schemes can be divided into three categories: sample-, coding-, and sketch-based. Sample-based approaches, like Small-Space (SS) (Shi et al., 2018), configure a hash filter to record the occurrence of items based on a sampling rate. However, the sampling rate needs to be low to support small memory usage, amplifying detection errors. Even if sample-based methods try to track only potentially persistent items, they may still record many non-persistent ones, which take up a large portion of the available memory. Coding-based schemes, such as the Persistent items Identification scheme (PIE) (Shi et al., 2018), utilize a compact hash-based structure and Raptor codes to improve memory usage. However, PIE requires encoding and storing all items, regardless of potential persistence. For enhanced detection accuracy and memory efficiency, On-Off sketch (Shi et al., 2018) employs a compact data structure with a state field for each counter, periodically increasing an item's persistence. Nevertheless, this approach may misclassify many non-persistent items as persistent due to its coarse isolation method. WavingSketch (Shi et al., 2018) aims for unbiased estimation and uses a Bloom filter (Shi et al., 2018) for persistent item detection but suffers from severe false positives in cases of limited memory, leading to reduced lookup accuracy.

## 7. Conclusions

In this paper, we introduced Stable-Sketch, a versatile and effective sketch for item lookup, which maintains a fast processing speed and reaches high detection accuracy even with tight memory budgets (L1 cache). Specifically, Stable-Sketch utilizes a probability-based approach to discard items stored in buckets, considering both item and bucket statistics. We conducted extensive experiments on diverse datasets to evaluate the performance of Stable-Sketch with different detection tasks. The experimental results demonstrate that Stable-Sketch outperforms competing schemes, exhibiting superior processing speed and significantly improving the detection accuracy across various detection tasks. Moreover, we illustrated how to speed up our solution with SIMD instructions. Lastly, we demonstrated that it is feasible to deploy our solution in practice.

Figure 10. Update speed comparison w/wo SIMD instructions.

## References

* (1) G. Wang, X. Zhang, S. Tang, H. Zheng, and B. Y. Zhao, "Unsupervised Clickstream Clustering for The Behavior Analysis:" in _Proceedings of ACM CHI_, 2016.
* (2) M. Etzinki, and V. Vatiginathan, "Web Mining for Web Personalization: ACM Transactions on Internet Technology, vol. 3, no. 1, pp. 1:27, 2003.
* (3) P.G. Teodoro, J.D. Verdejo, M.G. Fernandez, and P. Vazquez, "Anomaly-based Network Intrusion Detection: Techniques, Systems and Challenges," Computers & Security, vol. 28, no. 1, pp. 18-28, 2009.
* (4) S. Feghhi and J. D. Jeth, "A Web Traffic Analysis Attack Using Only Timing Information," IEEE Transactions on Information Forensics and Security, vol. 11, no. 8, pp. 1747-1759, 2016.
* (5) R.B. Bast, G. Eininger, R. Friedman, and Y. Kassner, "Heavy Hitters in Streams and Sliding Windows" in _Proceedings of IEEE INFOCOM_, 2016.
* (6) G. Cormode, S. Muthukrishnan, "An Improved Data Stream Summary: The Count-Min Sketch and As Applications," Journal of Algorithms, vol. 55, no. 1, pp. 58-75, 2006.
* (7) L. Tang, Q. Huang, and P.P.C. Lee, "MV-Stketch: A Fast and Compact Invertible Sketch for Heavy Item Detection in Network Data Streams," in _Proceedings of IEEE INFOCOM_, 2019.
* (8) J. Gong, T. Yang, H. Zhang, H. Li, S. Ling, S. Chen, L.Idem, and X. Li, "Heavy-Keep: An Accurate Algorithm for Finding Top-k Erighant Items," in _Proceedings of USENIX ATC_, 2018.
* (9) T. Yang, S. Gao, Z. Sun, Y. Wang, Y. Shen and X. Li, "Diamond Sketch: Accurate Per-flow Measurement for Big Streaming Data," in _IEEE Transactions on Parallel and Distributed Systems_, vol. 30, no. 12, pp. 2650-2662, 2019.
* (10) P. Roy, A. Khan, and G. Aloas, "Augmented Sketch-Faster and More Accurate Stream Processing," in _Proceedings of ACM SIGMOD_, 2016.
* (11) B. Zhao, X. Li, R. Tang, Z. Mei, and W. Wu, "DMS: Adaptive Memory Layout Organization of Sketch Stots for Fast and Accurate Data Stream Processing," in _Proceedings of ACM KDD_, 2021.
* (12) R. B. Bast, G. Eininger, M. Mitzenmacher and S. Vargafik, "SAISA: Self-Adjusting Len Screening Analytics," in _Proceedings of IEEE ICDE_, 2021.
* (13) Q. Xiao, Z. Tang, and S. Chen, "Universal Online Sketch for Tracking Heavy Hitters and Estimating Moments of Data Streams," in _Proceedings of IEEE INFOCOM_, 2020.
* (14) Q. Xiao, H. Wang, and G. Pan, "Accurately Identity Time-decaying Heavy Hitters by Decay-aware Cuckoo Filter along Kicking Path," in _Proceedings of IEEE/ACM IWCS_, 2022.
* (15) Y. Li, R. Miao, C. Kim, and M. Yu, "itemRadar: A Better Neither Retirement for Data Centers," in _Proceedings of USENIX NSDI_, 2016.
* (16) R. Krishnamurthy, S. S. Kim, Y. Zhang, and Y. Chen, "Sketch-based Change Detection: Methods, Evaluation, and Applications," in _Proceedings of ACM Track_, 2003.
* (17) R. Schuyller, Z. Li, Y. Chen, T. Gao, A. Gupta, Y. Zhang, P.A. Dinda, M. Kao, and G. Mennik, "Reversible Stotcher: Enabling Monitoring and Analysis Over High-Speed Data Stream," IEEE/ACM Transactions on Networking, vol. 15, no. 5, pp. 1095-1092, 2020.
* (18) Y. Zhang, J. Li, Y. Liu, Y. Zhang, J. Li, G. Zhang, and B. Cai, "On-Off Sketch: A Fast and Accurate Sketch on Persistence," in _Proceedings of VLDB Endowment_, 2020.
* (19) B. Lahiri, J. Chandrashekar, and S. Tirthapura, "Spare efficient Tracking of Persistent Items in a Massive Data Stream," in _Proceedings of ACM IRDS_, 2011.
* (20) H. Dai, M. Shashade, A.X. Liu, and Y. Zheng, "Findings Frequent Items in Data Streams," in _Proceedings of VLDB Endowment_, 2016.
* (21) T. Yang, J. Gong, H. Zhang, L. Zou, L. Shi, and X. Li, "Heavy-Genaflam: Separate and Guard Hot Items in Data Streams," in _Proceedings of ACM KDD_, 2018.
* (22) J. Li, Z. Li, Y. Xu, S. Jiang, T. Yang, B. Cui, Y. Dai, and G. Zhang, "WawingsMethods: An Unbiased and Generic Sketch for Finding Top-k items in Data Stream," in _Proceedings of ACM KDD_, 2020.
* (23) H. Belloni, "Sponeyline Trade-offs in Hash Coding with Allowable Errors," Communications of the ACM, vol. 13, no. 7, pp. 422-426, 1970.
* (24) T. Benson, A. Alella, and D.A. Maltz, "Network Traffic Characteristics of Data Centers in the Wild," in _Proceedings of ACM SIGCOMM_, 2010.
* (25) J. Zhang, F.R. W., S. Wang, T. Huang, Z. Lin, and Y. Liu, "Load Balancing in Data Center Networks: A Survey," IEEE Communications Surveys & Tutorials, vol. 20, no. 3, pp. 2324-2325, 2018.
* (26) H. Zhang, J. Zhang, W. Bai, K. Chen, and M. Chowdhury, "Resilient Datacenter Load Balancing in the Wild," in _Proceedings of ACM SIGCOMM_, 2017.
* (27) Q. Huang, and P.P.C. Lee, "A Hybrid Local and Distributed Scheduling Design for Accurate and Scalable Heavy Key Detection in Network Data Streams," Computer Networks, vol. 91, no. 1, pp. 1-18, 2015.
* (28) L. Tang, Q. Huang, and P.P.C. Lee, "SpreadSketch: Toward Invertible and Network-Wide Detection of Superspreaders," in _Proceedings of IEEE INFOCOM_, 2020.
* (29) Y. Zhang, Z. Liu, R. Wang, T. Yang, J. Li, R. Zhuo, P. Liu, Z. Zhang, and J. Jang, "Co-Sketch: Tight-Performance Slicped Measured User Another Arbitrary Partial Key Query," in _Proceedings of ACM SIGCOMM_, 2021.
* (30) D. Ting, "Data Setches for Disaggregated Subset Sum and Frequent Item Estimation," in _Proceedings of ACM SIGMOD_, 2018.
* (31) Intel SSE2 Documentation. [https://software.intel.com/en-us/node/683883](https://software.intel.com/en-us/node/683883).
* (32) "Stable-Stetch Repository," [https://github.com/Stable-Stketch/Stable-Stetch](https://github.com/Stable-Stketch/Stable-Stetch)
* (33) A. Metwally, D. Agrawal, and A.E. Abadt, "Efficient Computation of Frequent and Top-k Elements in Data Streams," in _Proceedings of Springer ICDT_, 2005.
* (34) R.B. Bast, X. Chen, G. Eininger, R. Friedman, and Y. Kassner, "Randomized Admission Policy for Efficient Top-k," Frequency, and Volume Estimation," IEEE/ACM Transactions on Networking, vol. 27, no. 4, pp. 1432-1445, 2019.
* (35) R.B. Bast, X. Chen, G. Eininger, and O. Rottenstreuth, "Designing Heavy-Hitter Detection Algorithms for Programmable Switches," IEEE/ACM Transactions on Networking, vol. 28, no. 3, pp. 1172-1185, 2020.
* (36) M. Charikar, K. Chen, and M.F. Colton, "Tinding Frequent Items in Data Streams," in _Proceedings of Springer ICDE_, 2020.
* (37) "MyStetch Repository," [https://github.com/Gure-TLM/W-Stetch](https://github.com/Gure-TLM/W-Stetch):
* (38) J. Hung, W. Zhang, Y. Li, L. Li, Z. Li, and J. Wang, "OnlineSketch: An Efficient and Accurate Sketch for Heavy Flow Detection," in _IEEE/ACM Transactions on Networking_, 2021, doi: 10.1109/TNET-2222.391506.
* (39) T. Tang, J. Jing, P. Liu, Q. Huang, J. Gong, Y. Zhou, R. Miao, X. Li, and S. Uhlig, "Tastic Sketch: Adaptive and Fast Network-wide Measurements," in _Proceedings of ACM SIGCOMM_, 2018.
* (40) Y. Li, P. Wang, X. Yu, Y. Yang, K. Yang, T. Yang, Z. Ma, B. Cui, and S. Uhlig, "LadderFilter: Filtering different items with Small Memory and Time Overhead," in _Proceedings of ACM SIGMOD_, 2023.
* (41) Y. Zhou, T. Yang, J. Jiang, S. Cui, M. Yu, X. Li, and S. Uhlig, "Cold Filter: A Meta-Tearnow Frontier for Faster and More Accurate Stream Processing," in _Proceedings ACM SIGMOD_, 2018.
* (42) P. Jia, P. Wang, J. Zhao, Y. Yuan, J. Tao, and X. Guan, "Logo Filter: Filtering Cdd Items within a Large Range over High Speed Data Streams," in _Proceedings of IEEE ICC_, 2021.
* (43) J. Ye, L. Li, W. Zhang, G. Chen, Y. Shan, Y. Li, W. Li, and J. Huang, "UA-Stketch: An Accurate Approach to Detect Heavy Flow based on Uninterrupted Arrival," in _Proceedings of ACM ICIP_, 2022.
* (44) S. Ghorbani, Z. Yang, P.B. Godfrey, F. Ganjali and A. Firooshakian, "DHILL: Video Load Balancing for Low-latency Data Center Networks," in _Proceedings of ACM SIGCOMM_, 2021.
* (45) M. Mitzenmacher, "The Power of Docues in Randomized Load Balancing," IEEE Transactions on Parallel and Distributed Systems, vol. 12, no. 10, pp. 1094-1004, 2001.
* (46) H. Huang, Y.E. Sun, C. Ma, S. Chen, Y. Zhou, W. Yang, S. Tang, H. Xu, and Y. Qian, "An Efficient \(K\)-Persistent Spread Estimator for Traffic Measurement in High-Speed Networks," IEEE/ACM Transactions on Networking, vol. 28, no. 4, pp. 103-147, 2020.
* (47) Y. Du, H. Huang, Y.E. Sun, S. Chen, G. Gao, X. Wang, and S. Xu, "Short-Term Memory Sampling for Spread Measurement in High-Speed Networks," in _Proceedings of IEEE INFOCOM_, 2000.
* (48) T. Yang, H. Zhang, D. Yang, Y. Huang, and X. Li, "Tinding Significant Items in Data Streams," in _Proceedings of IEEE ICC_, 2019.
* (49) Z. Zhong, S. Yan, Z. Li, D. Tan, T. Yang, and B. Cui, "BurstSketch: Finding Bursts in Data Streams," in _Proceedings of ACM SIGMOD_, 2021.
* (50) R. Ma, Z. Zhong, J. Gua, Z. Li, T. Tang, and B. Cui, "BurstSketch: Finding Bursts in Data Streams," IEEE Transactions on Knowledge and Data Engineering, 2022, doi: 10.1109/TTKDE.2022.232866.
* (51) P. Ernest, "Mathematical Induction: A Pedagogical Discussion," Educational Studies in Mathematics, vol. 15, no. 1, pp. 173-189, 1984.
* (52) The CAIDA Informational Internet Traces," [https://www.co.az.org/data/overview/](https://www.co.az.org/data/overview/).
* (53) "MANW Working Group Traffic Archive," [http://mavi.wide.ad.jp/mavi/](http://mavi.wide.ad.jp/mavi/).
* (54) M. Singh, M. Singh, S. Kaut, "10 Days DNS Network Traffic from April-May, 2016; Mendelay Data, 2016; Mendelay Data, 2016; Van der Vaart, 2016; M. Terlaplace, and A.G. Gorbani, "Toward Developing a Systematic Approach to Generate Benchmark Datasets for Intrusion Detection," Computers and Security, vol. 31, no. 3, pp. 357-374, 2012.
* (55) L. Tang, Q. Huang, and P.P.C. Lee, "A Fast and Compact Invertible Sketch for Network-Wide Hireaw Inner Detection," IEEE/ACM Transactions on Networking, vol. 28, no. 5, pp. 2350-2365, 2020.
* (56) A. Appley, "Mumurthi," [https://sites.google.com/site/mumurthi](https://sites.google.com/site/mumurthi), 2011.
* (57) H. Nankung, Z. Liu, B. Kim, Y. Selar, and P. Sechine, "Steetkink: Enabling Efficient Sketch-based Monitoring on Programmable Switches," in _Proceedings of USENIX NSDI_, 2022.
* (58) P. Bosshart, D. Daly, G. Gibb, I. Izzard, N. McKeown, J. Besford, C. Schleinger, D. Talayco, A. Vahdat, G. Vargheseber, and D. Walker, "Pe: Programming Protocol-Independent Packet Processors," ACM SIGCOMM Computer Communication Review, vol. 44, no. 3, pp. 87-95, 2014.
* (59) Lintel, "Put Stotcher," [https://www.intel.com/content](https://www.intel.com/content)

## Appendix A Definition of Symbols

### The **Number of Iterations**

**Theorem B.1**.: _For any given item \(f\), let \(V_{t}(f)\) and \(\hat{V}_{t}(f)\) denote the actual frequency and estimated frequency at a particular time \(t\), respectively. Then \(\hat{V}_{t}(f)\leq V_{t}(f)\)._

Proof.: At the start of the detection task (\(t=0\)), both \(\hat{V}_{t}(f)\) and \(V_{t}(f)\) are zero, so the theorem holds. Assume that at time \(t-1\), \(\hat{V}_{t-1}(f)\leq V_{t-1}(f)\). At time \(t\), two scenarios are possible: (i) if the incoming item is \(f\) again, then \(\hat{V}_{t}(f)=\hat{V}_{t-1}(f)+1\) and \(V_{t}(f)=V_{t-1}(f)+1\). Hence, \(\hat{V}_{t}(f)\leq V_{t}(f)\) is true; (ii) if an item other than \(f\) arrives, the estimated frequency of item \(f\) either decreases by \(1\) or stays the same, i.e., \(\hat{V}_{t}(f)=\hat{V}_{t-1}(f)-1\) or \(\hat{V}_{t}(f)=\hat{V}_{t-1}(f)\). Given that \(V_{t}(f)=V_{t-1}(f)\), it follows that \(\hat{V}_{t}(f)\leq V_{t}(f)\). Since the claim holds for all scenarios, Theorem B.2 is proven. 

### Error Bound of Stable-Sketch

To derive the error bound, we make an assumption that is generally valid (confirmed in Appendix B.3.2): once a heavy item enters a bucket, it remains in the bucket until the detection task is complete. Then we get the error bound of Stable-Sketch as

**Theorem B.2**.: _Given a small positive number \(\beta\) and a heavy item \(f\) with frequency \(V(f)\), the inequality \(\Pr\left\{V(f)-\hat{V}(f)\geq\lceil\beta N\rceil\right\}\leq\frac{\left\lceil \beta(V(f))+\beta\right\rceil}{\beta\left\lceil\beta N\left\lfloor\beta\right \rceil\right\rceil}\) holds, where \(\varphi\) denotes the Euler-Mascheroni constant, \(S\) denotes the bucket stability that records item \(f\), and \(N\) represents the total number of entries for all items._

Proof.: When an item distinct from \(f\) arrives and maps to the same bucket \(B(i,j)\) as \(f\), the value counter of this bucket undergoes either a decrement of \(1\) or remains unaltered. We use \(G_{i,j}\) to denote the times in which items distinct from \(f\) hash into the same bucket. Consequently, we infer that \(V(f)-G_{i,j}\leq\hat{V}(f)\leq V(f)\), where \(\hat{V}(f)\) is equivalent to \(B(i,j)\).\(V\). We employ a random variable \(D_{i,j,\times}\) to represent the event where the value counter of bucket \(B(i,j)\) decreases by \(1\) upon the arrival of the \(x\)-th item, where \(1\leq x\leq G_{i,j}\). Hence, \(\hat{V}(f)=V(f)-\sum_{x=1}^{G_{i,j}}D_{i,j,\times}\). By applying the Markov inequality in conjunction with a small positive value \(\beta\), we deduce:

\[\Pr\left\{\hat{V}(f)\leq V(f)-\beta N\right\}=\Pr\left\{V(f)-\sum_{x=1}^{G_{i, j}}D_{i,j,\times}\leq V(f)-\beta N\right\}\]

\[=\Pr\left\{\sum_{x=1}^{G_{i,j}}D_{i,j,\times}\geq\beta N\right\}\leq\frac{ \mathbb{E}\left[\sum_{x=1}^{G_{i,j}}D_{i,j,x}\right]}{\beta N}.\]

Assuming that the distribution of packets from all items is uniform, we can derive the following:

\[\mathbb{E}\left[\sum_{x=1}^{G_{i,j}}D_{i,j,x}\right]=\mathbb{E}\left[D_{i,j,x }G_{i,j}\right]=\sum_{G_{i,j}}^{V(f)}p(G_{i,j})\left[G_{i,j}\mathbb{E}(D_{i,j, x}|G_{i,j})\right].\]

Let \(\omega\) denote the final value of the counter in bucket \(B(i,j)\) when the detection task is complete. Under the assumption that the arrival probability of an item is constant, ranging from \(1\) to \(\omega\), we obtain

\[\mathbb{E}(D_{i,j,x}|\omega)=\sum_{V=1}^{\omega}\frac{1}{\omega}\frac{1}{(V \times S)+1}<\sum_{V=1}^{\omega}\frac{1}{\omega}\frac{1}{V\times S},\]

where \(V\) and \(S\) represent the value counter and bucket stability counter of bucket \(B(i,j)\), respectively.

Let \(p(\omega)\) denote the probability that \(\omega\) is any of the values in the \([V(f)-G_{i,j},V(f)]\) range, then

\[\mathbb{E}(D_{i,j,x}|G_{i,j})<\sum_{j=V(f)-G_{i,j}}^{V(f)-1}p( \omega)\sum_{V=1}^{\omega}\frac{1}{\omega}\frac{1}{V\times S}\] \[\leq\sum_{\psi=V(f)-G_{i,j}}^{V(f)-1}p(\omega)\sum_{V=1}^{\omega} \frac{1}{V(f)-G_{i,j}}\frac{1}{V\times S}\] \[\leq\sum_{\psi=V(f)-G_{i,j}}^{V(f)-1}p(\omega)\sum_{V=1}^{V(f)} \frac{1}{V(f)-G_{i,j}}\frac{1}{V\times S}=\frac{1}{V(f)-G_{i,j}}\sum_{V=1}^{V (f)}\frac{1}{V\times S}.\]

Then we get

\[\mathbb{E}\left[\sum_{x=1}^{G_{i,j}}D_{i,j,x}\right]=\mathbb{E} \left[D_{i,j,x}G_{i,j}\right]=\sum_{G_{i,j}}^{V(f)}p(G_{i,j})\left[G_{i,j} \mathbb{E}(D_{i,j,x}|G_{i,j})\right]\] \[\leq\sum_{G_{i,j}=1}^{V(f)-1}p(G_{i,j})\left(\frac{G_{i,j}}{V(f)- G_{i,j}}\sum_{V=1}^{V(f)}\frac{1}{V\times S}\right).\]

Since item \(f\) is a heavy item with a large value, the distribution of \(G_{i,j}\) can be approximated as a Poisson distribution with a mean of \(\frac{N}{N}p(G_{i,j})=\frac{N}{N}e^{-\frac{N}{N}G_{i,j}}\), where \(h\) denotes the number of buckets in each row. Consequently, we can derive the following:

\[\mathbb{E}\left[\sum_{x=1}^{G_{i,j}}D_{i,j,x}\right]\leq\sum_{G_{i,j}=1}^{V(f)- 1}\frac{N}{n}e^{-\frac{N}{N}G_{i,j}}\left(\frac{G_{i,j}}{V(f)-G_{i,j}}\sum_{V=1 }^{V(f)}\frac{1}{V\times S}\right)\]

\[=\sum_{V=1}^{V(f)}\frac{1}{V\times S}\left[\sum_{G_{i,j}=1}^{V(f)}\frac{N}{n}e ^{-\frac{N}{N}G_{i,j}}\left(\frac{G_{i,j}}{V(f)-G_{i,j}}\right)\right.\]

\[+\sum_{G_{i,j}=\frac{V(f)-1}{2}+1}^{V(f)-1}\frac{N}{n}e^{-\frac{N}{N}G_{i,j}} \left(\frac{G_{i,j}}{V(f)-G_{i,j}}\right)\right]\]

\begin{table}
\begin{tabular}{c c} \hline
**Symbol** & **Definition** \\ \hline \(f\) & an item in data stream \(Q\) \\ \(N\) & the total frequency of all items in data stream \(Q\) \\ \(m\) & the number of rows in the sketch \\ \(u\) & the number of buckets in each row \\ \(V(f)\) & frequency of the item \(f\) \\ \(P(f)\) & persistence of the item \(f\) \\ \(G\) & the number of time windows \\ \(L\) & the eviction decay probability \\ \(\theta\) & heavy hitter detection parameter, ranges in (0,1) \\ \(\hat{\psi}\) & heavy changer detection parameter, ranges in (0,1) \\ \(\hat{\phi}\) & persistent item detection parameter, ranges in (0,1) \\ \hline \end{tabular}
\end{table}
Table 2. Summary of frequently used symbols.

\[\leq\sum_{V=1}^{V(f)}\frac{1}{V\times S}\left[\sum_{G_{i,j}=1}^{V(f)} \frac{N}{h}e^{-\frac{N}{h}G_{i,j}}+\sum_{G_{i,j}=1+1}^{V(f)-1}\frac{N}{h}e^{- \frac{N}{h}\frac{V(f)}{2}}\frac{G_{i,j}}{V(f)-G_{i,j}}\right]\] \[\leq\sum_{V=1}^{V(f)}\frac{1}{V\times S}\left[1+\sum_{G_{i,j}= \frac{V(f)-1}{1}}^{V(f)-1}\frac{N}{h}e^{-\frac{N}{h}\frac{V(f)}{2}}\frac{V(f)-1 }{V(f)-(V(f)-1)}\right]\] \[\leq\sum_{V=1}^{V(f)}\frac{1}{V\times S}\left[1+\sum_{G_{i,j}= \frac{V(f)}{2}+1}^{V(f)-1}\frac{N}{h}e^{-\frac{N}{h}\frac{V(f)}{2}}V(f)\right]\] \[\leq\sum_{V=1}^{V(f)}\frac{1}{V\times S}\left[1+V(f)\frac{N}{h}e^{ -\frac{N}{h}\frac{V(f)}{2}}\right].\]

Since \(V(f)\) is a large value, the term \(\frac{N}{h}\frac{V(f)}{2}e^{-\frac{N}{h}\frac{V(f)}{2}}\) tends to 0, and \(\sum_{V=1}^{V(f)}\frac{1}{h}\) can be approximated as \(\ln(V(f))+\varphi\), where \(\varphi\) represents the Euler-Mascheroni constant, approximately 0.577. Hence, we can derive the following:

\[\mathbb{E}\left[\sum_{k=1}^{G_{i,j}}D_{i,j,k}\right]\leq\sum_{V=1}^{V(f)}\frac{ 1}{V\times S}<\frac{1}{\ln(S)}\sum_{V=1}^{V(f)}\frac{1}{V}\approx\frac{1}{\ln( S)}\left[\ln(V(f))+\varphi\right].\]

Finally, we get the estimation error bound as

\[\Pr\left\{V(f)-\hat{V}(f)\geq\left\lceil\beta N\right\rceil\leq \Pr\left\{\hat{V}(f)\leq V(f)-\beta N\right\}\] \[\leq\frac{\mathbb{E}\left[\sum_{x=1}^{G_{i,j}}D_{i,j,x}\right]}{ \beta N}\leq\frac{\left[\ln(V(f))+\varphi\right]}{\beta N\ln(S)}.\]

### Empirical Validation

#### b.3.1. Correctness of Theorem 1

To validate the accuracy of Theorem 1, we employ two traces obtained from the CAIDA 2015 and CAIDA 2018 datasets, comprising 15.85M and 14.96M packets, respectively. The experimental configuration is consistent with the setup in Section 5. Figure 11 presents the real and estimated frequency of heavy items with a memory size of 64KB. It can be observed that there are no overestimation errors, and the estimated frequency closely aligns with the real frequency, thus confirming the high estimation accuracy of Stable-Sketch.

#### b.3.2. Reasonableness of the Assumption

When deriving the error bound, we assume that a heavy item will remain in the bucket once it has entered. However, there are two scenarios where a heavy item may not always stay in the bucket: 1) it may be replaced by non-heavy items, and 2) it may be replaced by other heavy items. To analyze the impact of these scenarios, Figure 12 presents the frequency of occurrence where other items mistakenly evict heavy items during the update process. From the results, we observe that for Stable-Sketch, most incorrect replacement events are caused by non-heavy items. However, the number of wrong replacements is significantly smaller than with existing methods such as MV-Sketch (as shown in Table 1), indicating that Stable-Sketch effectively mitigates the risk of erroneously evicting heavy items from a bucket. Furthermore, we also consider the total number of replacement events during the update process. For example, for the CAIDA 2015 trace with a memory size of 16KB, the total number of replacement events is 340,362. In comparison, the number of wrong replacement events involving heavy items is only a tiny fraction of the overall replacements. This demonstrates that Stable-Sketch has a significantly lower probability of erroneously evicting heavy items from the bucket. Therefore, the assumption of heavy items remaining in a bucket holds in most cases.

In these two exceptional cases, it becomes apparent that additional memory would be required to mitigate hash collisions, otherwise deriving an error bound becomes non-trivial. Fortunately, there are several techniques available to alleviate these limitations. One such technique involves utilizing the hash chain approach (Shen et al., 2018). When a heavy item is evicted from the bucket by other items, we can attempt to relocate it by employing multiple hash operations to find an available bucket instead of discarding it directly. This increases the likelihood of heavy items being recorded in the bucket. However, it is important to note that this method necessitates additional hash operations, thus reducing the update speed. If update speed is not a critical concern for the user, such techniques can be additionally employed to further ameliorate the detection accuracy.

#### b.3.3. Correctness of Theorem 2

Based on the derived error bound, we observe that for a heavy item, the estimation error decreases as its bucket stability increases. _This finding highlights the importance of considering the bucket stability to minimize the estimation error_.

Figure 11. Comparison between the estimated and real frequent of heavy items under different traces.

Figure 12. Number of heavy items being wrongly evicted from a bucket during the update process under different traces.

To validate the accuracy of the derived error bound, we conduct experiments using a CAIDA 2018 trace. We set \(\beta\) to \(2^{-21}\) and vary the memory size from 16KB to 256KB. Note that \(\beta\) is a user-defined parameter, and here the \(2^{-21}\) setting corresponds to a value of 8 for \(\lceil\beta N\rceil\). This means that we calculate the probability of the error between the actual value and the estimated value of the heavy items greater than 8. The results shown in Figure 13 demonstrate that the empirical values are consistently smaller than the corresponding theoretical ones, which validates the accuracy of our theoretical analysis. In practice, different values can be chosen for \(\beta\). We also configure \(\beta\) as \(2^{-20}\) and find that the results are consistent.

#### b.3.4. Comparison with Existing Work

There are alternative methods for heavy item detection, a classic one being the Count-Min Sketch. However, Count-Min Sketch is known to have overestimation errors, whereas the overestimation error of Stable-Sketch is 0. Moreover, Count-Min Sketch records the frequency of all items, whereas our Stable-Sketch focuses on tracking the frequency of potential heavy items. We also compare Stable-Sketch with an advanced probability-based method with underestimation errors, namely HeavyKeeper (Beng et al., 2017). In the _worst-case_ scenario, where the memory size is limited (e.g., 16KB), we observe that the error bound of Stable-Sketch is significantly smaller than that of HeavyKeeper when \(\beta\) is set as \(2^{-21}\) under the CAIDA 2018 trace. To further investigate the robustness of Stable-Sketch, we adjust the value of \(\beta\) to \(2^{-20}\) and find that the error bound for our method is 0.074, while that of HeavyKeeper is 0.572 when the memory size is 16KB. These observations validate the effectiveness of Stable-Sketch.

## Appendix C Evaluation

### Precision and Recall for Heavy Item Detection

As shown in Figure 14, the precision of Stable-Sketch is always around 1 under different memory budgets, which is much higher than that of existing approaches. The reason for this is that with the help of multidimensional features (item and bucket statistics) and the probabilistic eviction of items saved in buckets, Stable-Sketch can effectively prevent heavy hitters from being effortlessly replaced by other items, even when the available memory is small (16KB). We also observe that for USS and SpaceSaving, the precision degrades as the memory size increases from 16KB to 128KB. This is because they aggressively evict items stored in buckets, and the increasing memory size causes more non-heavy items to be incorrectly identified as heavy ones, resulting in reduced precision. RAP and PRECISION make replacement decisions based on probabilities computed by item frequency, which does not provide adequate protection for heavy items in highly skewed data streams, especially under tight L1 memories, resulting in lower precision than that of Stable-Sketch. As observed from Figure 15, Stable-Sketch also maintains commendable recall rate on different traces.

### Stable-Sketch Deep Dive

1) We also evaluate the performance of Stable-Sketch using a synthetic intrusion dataset (Shi et al., 2017). This dataset is specifically designed for intrusion detection evaluation and contains 4.16 million items, simulating various user behaviors. The experimental results demonstrate that Stable-Sketch consistently outperforms the considered baselines, achieving an improvement of 11.48% - 180.19% in identifying heavy items (figure omitted due to the space limitation).

2) In addition, we evaluate Stable-Sketch's detection accuracy against several advanced sketch-based methods for identifying heavy items, such as LadderFilter (Ladder) (Ladder) (Ladder) (Ladder) (Ladder) (Ladder), Loglog Filter (Loglog) (Ladder), A-Sketch (Ladder), UA-Sketch (Ladder), HeavyGuardian (2018), DHS (DHS), and SALSA (Ladder). Ladder Filter (Ladder) is a state-of-the-art scheme that discards approximately infrequent items using multiple LRU queues. Accordingly, we use LadderFilter, Cold Filter, and Loglog Filter with SpaceSaving, as described in (Ladder). UA-Sketch (Ladder) utilizes the uninterrupted arrival counter to probabilistically evict items. SALSA (Ladder) employs dynamic counters that use small counters initially and merges adjacent counters when they overflow. DHS (DHS) employs many fixed-size buckets. When an item in a smaller counter overflows, DHS will reallocate the space in the bucket and move the item to the larger counter to accommodate its increased frequency.

As illustrated in Figure 16, our scheme maintains high accuracy even with a limited memory budget of 16KB. When compared to the state-of-the-art LadderFilter, Stable-Sketch achieves an average improvement of 78.64% in detection accuracy, owing to its efficient replacement strategy based on multi-dimensional features. Additionally, Stable-Sketch outperforms DHS and SALSA, which dynamically resize their counter sizes, with an average improvement in F1 score of 41.6% and 81.47%, respectively. This highlights the effectiveness of Stable-Sketch, even with fixed-size counters, given that the number of heavy items is typically very small in practice.

### Detection with Different Thresholds

To assess the robustness of Stable-Sketch, we set the memory size to 32KB and vary the threshold from 0.0001 to 0.0021 for heavy item detection using a larger public trace (CAIDA 2019) and traces with different levels of skewness (0.2 and 0.8). The CAIDA 2019 trace comprises 1.52M items, while the traces with skewness 0.2 and 0.8 consist of 7.53M and 7.34M items, respectively.

As illustrated in Figures 17(a)-(c), Stable-Sketch consistently outperforms competitive approaches, MV-Sketch and CocoSketch, across various threshold settings. This validates the effectiveness and robustness of Stable-Sketch. In addition, we examine the effects of varying the threshold for persistent item detection (from 0.4 to 0.8). The results presented in Figure 17(d) demonstrate that Stable-Sketch maintains its superiority over the most competitive approach, On-Off Sketch. Furthermore, we observe a decreasing trend in the accuracy of On-Off Sketch as the threshold value increases. This can be attributed to the fact that, as the threshold increases, the number of persistent items decreases. Under tight

Figure 13. Theoretical bound and empirical probability of Stable-Sketch.

memory allocation and excessive hash collisions, the naive replacement strategy employed by On-Off Sketch results in numerous persistent items being erroneously replaced by non-persistent ones, thus leading to a decline in its detection performance.

### Deep Diving into Stable-Sketch's Operation

Stable-Sketch builds on three core design insights: replacing stored items using multi-dimensional information, stopping hash operations on time and evicting items tracked in buckets based on a probability \(L(f)\). Here, we take persistent item lookup as an example and utilize the CAIDA traces to investigate the contribution of each principle to Stable-Sketch's performance.

#### c.4.1. Multi-dimensional Information

We set the memory size to 16KB. Figure 18(a) validates the importance of considering bucket stability. Compared with a Stable-Sketch version focusing on single-dimensional information only (persistence value), Stable-Sketch with stability can deliver more protection to persistent items from being expelled by non-persistent ones under reduced memory sizes, with a reduction of estimation error by 72.82% on average. Though recording bucket stability increases the storage overhead, as shown in Figure 18(b), the update throughput only experiences a slight decrease, meaning that its advantage of guarding persistent items out weights the overhead.

#### c.4.2. Abandoning Redundant Hash Operations

Compared with sketches that map each item to all rows, abandoning hash operations on time can save memory space and thus allows storing more items. As shown in Figure 19, this leads to a 7.35% increase in detection accuracy. Moreover, eliminating redundant hash operations reduces update time, leading to a 17.62% improvement in update throughput.

Figure 16. Heavy hitter detection F1 score with advanced approaches, as a function of memory size (CAIDA 2015).

Figure 17. Detection performance under different thresholds.

Figure 14. Heavy hitter detection precision with different approaches, as a function of memory size.

Figure 15. Heavy hitter detection recall with different approaches, as a function of memory size.

#### c.4.3. Different Replacement Probabilities

Stable-Sketch leverages a default decay probability of \(\frac{1}{\mathbb{B}(R,M),Y*B(R,M),S*1}\) to evict existing items recorded in buckets. Here, we evaluate the impact of different replacement methods on Stable-Sketch's detection performance using the CAIDA 2015 and 2016 traces. Specifically, we examine three forms: 1) Additive denominator (Add) replacement, which replaces the recorded item directly with a probability of \(\frac{1}{\mathbb{B}(R,M),Y*B(R,M),S*1}\); 2) Expo_Multi, which decays the value counter is decreased based on the probability \(\kappa^{B(R,M),Y*B(R,M),S}\) (where \(\kappa\) is a constant set to 1.08 [(8)]); when the value counter reaches 0, the new incoming item replaces the incumbent item tracked in the bucket; and 3) Expo_Add, which decays the value counter with a probability of \(\kappa^{B(R,M),Y*B(R,M),S}\). As listed in Figure 20, we find that using our default replacement probability provides the highest F1 score for Stable-Sketch compared to the other three replacement methods. On average, this default approach exhibits an improvement of 19.92%, 27.5% and 34.31% in terms of F1 score over the Add, Expo_Multi and Expo_Add methods over the CAIDA 2015 trace, respectively.

### Stable-Sketch with Fingerprint

Stable-Sketch tracks an item's key in each bucket, but a longer key (such as 5-tuples instead of source-destination pairs in network task scenarios) can consume valuable memory resources. To optimize memory usage, we propose a variant called Stable-Sketch\({}^{\star}\) that only tracks the item's fingerprint instead of the entire key. Fingerprint \(h_{g}(f)\) of an item \(f\) is a hash value produced by a specific hash function \(h_{g}\). Although it is possible for hash collisions to occur among items, the likelihood of such events is relatively low and can be neglected. If the fingerprint size is set to 32 bits and there are 340 buckets in each row, for a dataset with 1,000,000 items, the probability of fingerprint collisions is \(6.85\times 10^{-7}\), which is considerably low [(21)].

Figure 21 demonstrates the detection accuracy and update speed for heavy item lookup using the CAIDA 2015 trace. The results in Figure 21(a) indicate that using fingerprints improves the recall by 4.83% under tight memory settings (16KB). This is due to the more efficient usage of memory resources, which allows Stable-Sketch to track more items. Precision is not shown since it remains high regardless of whether fingerprints are used or not. Overall, the F1 score is improved by 2.8% with a 16KB memory allocation. However, using fingerprints slows down the update throughput due to the additional hash operation required to obtain the fingerprint value of each item. As shown in Figure 21(b), compared to vanilla Stable-Sketch, Stable-Sketch\({}^{\star}\) sees an average update throughput drop of 3.77%. The query time also increases, since it needs extra hash operations to retrieve items. This fingerprint-based Stable-Sketch\({}^{\star}\) variant provides users with an alternative option, if detection accuracy is to be prioritized. Otherwise, opting for the default Stable-Sketch enables striking a good balance between detection accuracy and update throughput.

### Stable-Sketch Deployment in Practice

In this subsection, we demonstrate that it is feasible to deploy Stable-Sketch in practice with limited overhead. Specifically, we implement Stable-Sketch into a programmable switch with P4 [(59)], a high-level language for programming protocol-independent packet

Figure 19. Accuracy and update speed comparison with different hash methods (C stands for CAIDA).

Figure 20. F1 score with different replacement strategies.

Figure 18. Estimation accuracy and update speed comparison w/wo considering bucket stability (C stands for CAIDA).

processors, and compile it with P4 Studio [60]. Compared to other hardware such as Field Programmable Gate Arrays (FPGAs) [61], programmable switches are renowned for their high processing speeds and strict design constraints. We construct each row as an array of registers. For each row, we use different hash functions to map items, like _crc_16_, _crc_16_, _dect_ and _crc_16_, _dds_110_. For an item that fails to find an available bucket, we resubmit this item once using the _recirculation_ primitive, as the register can only be accessed once during each update process [29, 56]. Then, we test whether this newly arrived item can replace the recorded item based on the value counter and bucket stability. Considering the memory access limitation of the programmable switch, we track the item key and the value of counters into temporary metadata when a hash collision occurs. Then we can find the bucket with the smallest frequency value by comparing these values individually. If the replacement is successful, the key field in the corresponding register will be rewritten with the key of the newly arrived item; otherwise, the switch will discard the new arrival item directly.

Table 3 lists the switch resource usage of Stable-Sketch for heavy hitter detection. The operation of Stable-Sketch is achieved by the match-action pipeline, which requires the crossbar to extract match keys and action inputs from the item header vector and thus consumes 6.81% of match crossbar resources. Due to the hash operation for each item, Stable-Sketch accounts for 3.41% of the hash bits. Each pipeline stage owns SRAM that can be used to maintain state, like counter arrays [58]. Stable-Sketch occupies 3.07% of the total SRAM resources. In addition, the ALU (arithmetic logic unit) can be employed for counter update operations such as counter increment. Stable-Sketch uses 9 ALUs, which takes up 20.46% of the total ALUs. For other types of resources, the maximum demand of Stable-Sketch is no more than 14% of the entire budget. These results confirm that Stable-Sketch leaves adequate resources to be used for other applications, indicating that it is feasible to deploy our solution on commercial hardware, such as programmable switches.

\begin{table}
\begin{tabular}{c c c} \hline Resource & Usage & Percentage \\ \hline Match Crossbars & 96 & 6.81\% \\ Hash Bits & 156 & 3.41\% \\ SRAM (KiB) & 27 & 3.07\% \\ ALUs & 9 & 20.46\% \\ Gateways & 23 & 13.06\% \\ VLIW Instructions & 25 & 7.1\% \\ \hline \end{tabular}
\end{table}
Table 3. Resource usage of Stable-Sketch.