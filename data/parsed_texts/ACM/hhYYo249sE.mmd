# Subgraph Federated Unlearning

Anonymous Author(s)

###### Abstract.

Subgraph federated learning aims to collaboratively train a global model over distributed subgraphs stored in multiple local clients with strict privacy constraints, which is crucial to a wide range of applications such as healthcare, recommendation systems, and financial crime detection. With the increasing emphasis on the "right to be forgotten," the issue of machine unlearning of subgraph federated models has gained significant importance. However, existing federated unlearning approaches largely focused on unstructured data, overlooking the impact of structural dependency and cross-client interferences in graph-based data. To this end, in this paper, we propose ReGEnUnlearn, a subgraph federated unlearning framework for efficient and comprehensive unlearning of multiple target clients. Specifically, we first propose the _Reinforced Federated Policy Sampler_ (RFPS) to learn optimal sampling strategies that minimize the interference among cross-client subgraphs. By interacting with the federated graph sampling environment, the agent learns to selectively forget an optimal subgraph of target clients, thus preserving the global model utility. Moreover, we propose the _Parameter-free Graph Prompt Knowledge Distillation_ (PGPKD) module, which retains the unique graph knowledge contributed by the target clients, thereby facilitating comprehensive unlearning via a tailored gradient ascent objective. Extensive experiments in various federated settings demonstrate ReGEnUnlearn's superiority over existing federated unlearning methods, offering a speedup of 3.6\(\times\) to 9\(\times\) compared to traditional retraining while maintaining model utility within a range of 100\(\%\) - 102\(\%\). The source code is available at [https://anonymous.4open.science/r/Unlearn-F27B/README.md](https://anonymous.4open.science/r/Unlearn-F27B/README.md)

machine unlearning; subgraph federated learning +
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

## 1. Introduction

Subgraph federated learning aims to address the challenges of collaborative learning across distributed subgraphs stored in multiple local systems while adhering to strict privacy regulations [3]. This approach is critical to diverse applications, including healthcare, recommendation systems, and financial crime detection, especially in cross-silo federated learning scenarios [36, 40, 43]. With increasing emphasis on privacy rights, such as the "right to be forgotten [11]," subgraph federated unlearning emerges as a crucial task, aiming to selectively remove specific clients' contributions from the global model. For example, in the context of international banks applying federated learning for financial crime detection, changing privacy laws may compel certain banks to withdraw their data, underscoring the need for effective unlearning mechanisms.

Nevertheless, existing federated unlearning approaches, as discussed in [12, 13, 30, 35, 30], predominantly focus on non-graph data, thus failing to address the complexities in subgraph federated unlearning. For example, VERIFI [10] involves the submission of gradient updates by all clients to the server. The server then amplifies gradients from remaining clients while reducing contributions from the target clients. Halimi _et al._[14] introduce a projected gradient ascent to maximize empirical loss on the target clients. As another example, FedRecover [46] iteratively eliminates contributions from target clients based on historical storage models. However, the above methods primarily focused on erasing the contribution of a target client with unstructured data (_e.g._, image, time series, and text _etc_), largely overlook the impact of structural dependency and cross-client interferences in graph-based data, as depicted in Figure 1. To address this gap, we investigate the subgraph unlearning problem in a federated environment with multiple client participants.

However, it is a non-trivial issue to effectively opt out of the contribution of multiple distributed clients while maintaining the model utility. (1) _Cross-client subgraph interference_. In the federated scenario, the subgraphs held by each client may overlap with each other (_e.g._, common users in multiple banks, patients shared by

Figure 1. (a) Traditional federated unlearning on unstructured data (_e.g._, image, time series, and text _etc_). (b) Subgraph federated unlearning raises additional concerns about erasing structural knowledge and cross-client subgraph overlap.

different hospitals). Simply eliminating contributions of a subgraph in a target client may forget common knowledge encoded in the overlapped subgraph, therefore leading to unexpected performance degradation of the global model, as illustrated in Figure 2(a). One straightforward solution is removing cross-client subgraphs via graph sampling and applying unlearning on the filtered subgraph, as depicted in Figure 2(b). However, due to privacy constraints, both the server and clients have limited access to the identity of cross-client subgraphs. How to eliminate the cross-client interference to guarantee the global model utility is the first challenge. (2) _Diversified structural contribution of each client._ A key benefit of federated learning is to collaboratively train a better global model by absorbing personalized knowledge from each client, _e.g._, rare disease cases in a hospital, exclusive user purchase records in an e-commerce platform. However, removing the unique contribution of a target client from a global graph model requires identifying various knowledge, such as entity attributes, node connectivity, and high-order structural patterns. How to comprehensively unlearn subgraph knowledge of a target client is another challenge.

To address the aforementioned challenges, we introduce the _Reinforced Graph Knowledge Enhancement Subgraph Federated Unlearning (ReGEnUnlearn)_ framework, comprising two key modules. First, the _Reinforced Federated Policy Sampler_ (RFPS) module is proposed to mitigate the interference among cross-client subgraphs. By interacting with the federated graph sampling environment, the agent learns optimal graph sampling strategies that facilitate the removal of cross-client nodes while preserving model utility. Second, a _Parameter-free Graph Prompt Knowledge Distillation_ (PGPKD) module is devised to distill specific graph knowledge from the target clients. This process encodes target clients' unique knowledge into the distilled graph prompts, which can be inserted into the sampled subgraph. In this way, the structural knowledge of a target client can be comprehensively unlearned by optimizing a gradient ascent objective over the prompt-enhanced subgraph.

The contributions of our work are summarized as follows: (1) To our knowledge, this is the first study to investigate subgraph federated unlearning with consideration of multiple target clients. (2) We propose the ReGEnUnlearn framework to comprehensively eliminate multiple target clients while preserving utility. ReGEnUnlearn is agnostic to federated algorithms and can be easily integrated into different subgraph federated scenarios. (3) We conduct comprehensive experiments on four real-world datasets under various subgraph federated settings. The proposed framework demonstrates notable speedups ranging from 3.6\(\times\) to 9\(\times\) compared to traditional retraining while maintaining model utility within a range of 100%-102%.

## 2. Preliminaries

In this section, we provide the background on subgraph federated learning and federated unlearning.

### Subgraph Federated Learning

#### 2.1.1. Notation

We represent the global graph as \(\mathcal{G}=(\mathcal{V},\mathcal{E},\mathcal{X})\), where \(\mathcal{V}\) denotes the node set, \(\mathcal{E}\) represents the edge set, and \(\mathcal{X}\) denotes the node feature set. Each node \(v\in\mathcal{V}\) is associated with its feature \(\mathbf{x}_{v}\in\mathcal{X}\). In the federated learning system, we consider a central server denoted as \(S\) and \(M\) distributed local clients \(C=\{C_{1},\cdots,C_{M}\}\), each possessing a subgraph \(\mathcal{G}_{i}=(\mathcal{V}_{i},\mathcal{E}_{i},\mathcal{X}_{i})\). These entities collaboratively train a global model \(F(\mathbf{w})\), where \(\mathbf{w}\) is the model weights and \(\mathcal{V}=\cup_{i=1}^{M}V_{i}\).

#### 2.1.2. Local Graph Learning

The _Message Passing Neural Network (MPNN)_ is a widely used framework for graph data that can accommodate various Graph Neural Network (GNN) architectures. In the subgraph federated learning, each client has a local GNN model and collaborates with others to train a global model. The local graph learning process consists of the following two phases.

**Message Passing.** For each client \(\mathcal{C}_{i}\), the \(l\)-th layer in MPNN is defined as follows,

\[\mathbf{h}_{j}^{l+1,l}=\mathbf{U}_{\mathbf{w}^{l,i}}(\mathbf{h}_{j}^{L,l}, \mathbf{m}_{j}^{l+1,l}), \tag{1}\]

where \(\mathbf{h}_{j}^{l+1,l}\) represents the node feature vector at layer \(l+1\) for node \(v_{j}\) in client \(\mathcal{C}_{i}\). The term \(\mathbf{m}_{j}^{l+1,l}\) denotes the aggregated message from the neighbors of node \(v_{j}\), and \(\mathbf{U}_{\mathbf{w}^{l,i,l}}\) is a function updating the node feature vector, with \(\mathbf{w}^{l+1,l}\) as the corresponding parameter in the \(l\)-th layer. The computation of the message \(\mathbf{m}_{j}^{l+1,l}\) is define as below,

\[\mathbf{m}_{j}^{l+1,l}=\sum_{v_{k}\in\mathcal{N}(v_{j})}\mathbf{M}_{\mathbf{g} ^{l+1,l}}(\mathbf{h}_{j}^{L,l},\mathbf{h}_{k}^{L,l},\mathbf{\epsilon}_{jk}^{ Lj}), \tag{2}\]

where \(\mathcal{N}(v_{j})\) represents the neighborhood of node \(v_{j}\), \(\mathbf{M}_{\mathbf{g}^{l+1,l}}\) is the function generating the message from node features, and \(\mathbf{\theta}^{l+1,l}\) is the corresponding parameter. \(\mathbf{\epsilon}_{jk}^{L,l}\) denotes message embedding associated with the edge between nodes \(v_{j}\) and \(v_{k}\) in the \(l\)-th layer.

**Readout.** The readout phase computes the final feature for subsequent tasks,

\[\hat{y}_{v_{j}}^{l}=P_{\omega^{l}}(\mathbf{h}_{j}^{L,l}|v_{j}\in\mathcal{V}^{ l}), \tag{3}\]

where \(\hat{y}_{v_{j}}^{l}\) represents the prediction for node \(v_{j}\). The readout function \(P_{\omega^{l}}\) encompasses methods such as mean pooling, where \(\omega^{l}\) is the parameter for the readout function.

Figure 2. (a) Comparison of unlearning on subgraphs with non-overlapping (Non-OL) and overlapping (OL) on the Photo dataset. The subgraph overlapping significantly reduces the model’s utility. (b) Unlearning on optimally sampled subgraph (OS Subgraph) better retains the model utility compared to heuristically sampled subgraph (HS Subgraph).

#### 2.1.3. Subgraph Federated Optimization

The objective of subgraph federated learning is defined as follows,

\[\min_{\mathbf{w}}\sum_{i=1}^{M}p_{i}\mathcal{R}_{i}(\mathcal{T}_{i}(\mathbf{w})), \tag{4}\]

where the term \(p_{i}\) denotes the model aggregation weight, with the constraint that \(\sum_{i=1}^{M}p_{i}=1\). The function \(\mathcal{R}_{i}(\cdot)\) corresponds to the local empirical risk function and is formally expressed as

\[\mathcal{R}_{i}(\mathcal{F}_{i}(\mathbf{w})):=\mathbb{E}_{(\mathcal{G}_{i}, \mathbf{y}_{i})}\big{[}\mathcal{L}(\mathcal{F}_{i}(\mathbf{w};\mathcal{G}_{i} ),\mathcal{Y}_{i})\big{]}, \tag{5}\]

where \(\mathcal{L}(\mathcal{F}_{i}(\mathbf{w};\mathcal{G}_{i}),\mathcal{Y}_{i})):=\frac{1} {|\mathcal{Y}_{i}|}\sum_{\mathbf{w}_{i}\in\mathbf{y}}l(\mathcal{F}_{i}(\mathbf{ w};\mathcal{G}_{i}(n_{i})),y_{\mathbf{q}_{i}})\) is the local loss function, \(\mathcal{F}_{i}(\cdot)\) is the GNN model for client \(C_{i}\).

To optimize the objective function, we consider the classic federated algorithm, FedAvg algorithm (Zhou et al., 2017), for illustration. In each round \(t\), the central server sends the global model \(\mathbf{w}^{t}\) to all local clients. Subsequently, each client performs multi-steps of the Stochastic Gradient Descent (SGD) optimization method to refine their local models. Following this local optimization, the clients transmit their updated local models as \(\mathbf{w}_{t}^{t}\) back to the central server. Finally, the central server aggregates these local models by weights \(p_{i}\) to obtain the next round's global model \(\mathbf{w}^{t+1}=\sum_{i}p_{i}\mathbf{w}_{t}^{t}\). This optimization process iterates over a specified number of \(T\) rounds.

### Federated Unlearning

**Approximate Federated Unlearning.** In this paper, we specifically focus on client-level federated unlearning. In this scenario, multiple clients want to opt out of the federation and eliminate their contribution from the global model. Assume that there are \(N_{t}\) clients who want to opt out of the federation. We refer to these clients as target clients \(T=\{I_{1},\cdots,I_{N_{t}}\}\subseteq C\). Naive retraining methods from scratch are computationally expensive and impractical, especially when confronted with frequent removal requests.

**Objective.** The objective of this paper is to solve approximate federated unlearning, which can eliminate the contribution of the subgraph in target clients while maintaining comparable model utility comparable to full retraining.

**Unlearning Verification.** The backdoor trigger is one of the most widely adopted verification methods for evaluating the performance of federated unlearning methods (Golov et al., 2013; Glorot and Bengio, 2010; Goodfellow et al., 2014). In practical scenarios, target clients utilize their datasets, incorporating a fraction of the data injected with backdoor triggers corresponding to specific target labels. The resulting global model learns the correlation between the trigger patterns and the target labels. By denoting the backdoor trigger as \(g\), a successful trigger would lead the GNN model to classify into the target label,

\[\mathcal{F}_{i}\oplus g(\mathbf{w};\mathcal{G}_{i}(n_{i}))=y_{r}, \tag{6}\]

where \(y_{r}\) represents the target label. A successful unlearning method should disentangle this correlation, resulting in a lower attack success rate.

\[\mathcal{F}_{i}\oplus g(\mathbf{w};\mathcal{G}_{i}(n_{i}))=y_{\mathbf{q}_{i}}, \tag{7}\]

**Threat Model.** This work focuses on semi-honest scenarios, excluding considerations of malicious clients or model replacement attacks. The global model is expected to exhibit robust performance on clean datasets, ensuring that introducing a backdoor trigger does not compromise its overall performance.

## 3. Reinforced Graph Knowledge Enhancement Subgraph Federated Unlearning

**Overview.** Figure 3 illustrates the overall framework of Reinforced Graph Knowledge Enhancement Subgraph Federated Unlearning, which consists of two crucial modules: (1) Reinforced Federated Policy Sampler (RFPS) module aims to mitigate the cross-client interference. (2) Prompt Knowledge Enhancement Graph Distillation (PKEGD) module distills specific graph knowledge from the target clients for comprehensive subgraph unlearning. In particular, the first module RFPS, selectively samples subgraphs for unlearning to guarantee the global model utility. For the second module, PKEGD encodes key graph knowledge to graph prompts, which can be inserted with the sampled subgraph from RFPS. Finally, the global model is optimized via the tailored unlearning loss over the integrated subgraph for multi-client unlearning.

### Reinforced Federated Policy Sampler

Unlearning across multiple clients would significantly decrease the model utility, especially with cross-client node interference. Based on the observation illustrated in Figure 2, the first intuition of our model is unlearning on a sampled subgraph. However, a key challenge is to remove the overlapping subgraph without accessing other clients' data. To address this issue, we propose a Reinforced Federated Policy Sampler, which leverages a reinforcement learning algorithm to enable the agent to determine the optimal policy for sampling a subgraph. The graph sampling process is formulated into a general decision \(\mathcal{M}=\{\mathcal{S}^{(t)},\mathcal{M}^{(t)},\mathcal{P}^{(t)},R\}\) for client \(C_{i}\in C\). Here, \(\mathcal{S}^{(t)}=\{s_{t}^{(t)}\}\) represents the set of states comprising all possible intermediate and final sampled graphs. The set \(\mathcal{A}^{(t)}=\{a_{t}^{(t)}\}\) represents the actions characterizing the sampled graph's behavior at each time step. \(\mathcal{P}^{(t)}\) is the transition dynamics specifying the possible outcomes of carrying out an action. \(R(s_{t}^{(t)})\) is a reward function specifying the reward after reaching the state \(s_{t}^{(t)}\).

**State.** For a client \(C_{i}\in C\), we define the state as all possible sampled graphs. Specifically, each state \(s_{t}\) is represented by a graph \(\mathcal{G}_{i}^{\prime}=(\mathcal{V}_{i}^{\prime},\mathcal{E}_{i}^{\prime}, \mathcal{X}_{i}^{\prime})\), where \(\mathcal{E}^{\prime}=\{(u,w)\mid u,w\in\mathcal{V}^{\prime}\text{ and }(u,w)\in\mathcal{E}\}\), and \(\mathcal{X}_{i}^{\prime}\) represents the corresponding node features.

**Action.** The action space encompasses all possible combinations of selected \(k\) nodes, ranging from the original graph \(\mathcal{G}^{(t)}\). The \(a_{t}^{(t)}=\{0,1\}^{n}\) represents an action, where the \(i\)-th of value \(a_{t}\) indicates whether node node \(v_{i}\) is selected (1) or not (0). Specifically, the action is generated by a policy function \(\pi_{\theta}(a_{t}^{(t)}|s_{t}^{(t)})\), which takes the state and the original graph as input, where \(\theta\) represents the parameters. In particular, the policy network \(\pi_{\theta}(a_{t}^{(t)}|s_{t}^{(t)})\) consists of node embedding and action prediction functions.

**Node Embedding.** To predict actions, the policy network first computes the node embedding of the input graph using the node embedding function \(g_{\theta}(\cdot)\), parameterized with \(\rho\). Specifically, we employ a graph neural network to calculate the node embedding:

\[H^{(l+1)}=\text{AGG}\left(\sigma\left(\tilde{D}^{-\frac{1}{2}}\tilde{E}\tilde{D} ^{\frac{1}{2}}H^{l}W\right)\right), \tag{8}\]where \(H^{(t+1)}\) represents the node features matrix at layer \(l+1\). AGG(-) denotes the aggregation function, \(\sigma\) is the activation function, \(\bar{D}\) is the normalized degree matrix, \(\bar{E}\) is the adjacency matrix, and \(W\) is the learnable weight matrix.

**Action Prediction.** The action \(a_{t}^{(i)}\) is predicted based on two components: the probability-sampling-based action \(a_{P_{t}}^{(i)}\) and the learnable action \(a_{I_{t}}^{(i)}\),

\[a_{t}^{(i)}=\text{CONCAT}(a_{P_{t}}^{(i)},a_{I_{t}}^{(i)}), \tag{9}\]

where CONCAT represents the concatenation function, and \(a_{P_{t}}^{(i)}\sim P_{\phi}\) is a stochastic probability distribution with parameter \(\phi\). The learnable action \(a_{I_{t}}^{(i)}\) is defined by the following equations,

\[a_{I_{t}}^{(i)}=\text{SOFTMAX}(\text{MLP}(\text{CONCAT}(g_{\phi}(s_{t-1}^{(i) }),g_{\phi}(\mathcal{G}_{i})))), \tag{10}\]

where \(\text{SOFTMAX}(\cdot)\) denotes the softmax function. The final sampled graph is denoted as \(\mathcal{G}_{t}^{\prime}=(\mathcal{V}_{t}^{\prime},\mathcal{E}_{t}^{\prime}, \mathcal{X}_{t}^{\prime})\), where \(\mathcal{E}^{\prime}=\{(u,w)\mid u,w\in\mathcal{V}^{\prime}\text{ and }(u,w)\in\mathcal{E}\}\), and \(\mathcal{X}_{t}^{\prime}\) signifies the corresponding node features. The sampled nodes in \(\mathcal{V}_{t}^{\prime}\) are derived from the action \(a_{t}\) and maintain their \(K\)-hop neighborhood \(\mathcal{N}_{K}(v)\).

\[\mathcal{V}_{t}^{\prime}=\{\varphi\mid\varphi\in\mathcal{V}_{t},\varphi\sim a _{t}^{(i)}\}\cup\bigcup_{v\in\mathcal{V}_{t}}\mathcal{N}_{K}(v)\;, \tag{11}\]

where \(\mathcal{N}_{K}(v)\) represents the set of \(K\)-hop neighboring nodes in the original graph \(\mathcal{G}_{i}\). Here, the sampling rate is denoted by \(s=\frac{k}{|\mathcal{V}_{t}|}\) to control the number of sampled nodes.

**Transition.** After taking action \(a_{t}^{(i)}\), the environment undergoes a transition, and the state changes from \(s_{t}^{(i)}\) to \(s_{t+1}^{(i)}\), governed by the transition probability \(P(s_{t+1}^{(i)}|s_{t}^{(i)},a_{t}^{(i)})\).

**Reward Design.** The environment yields a reward \(R(r_{t}^{(i)})\) to assess the action \(a_{t}^{(i)}\) in the state \(s_{t}^{(i)}\) for client \(C_{t}\). The environment aims to assign a positive reward when the sampled graph does not significantly impact the model's utility while preserving unlearning performance. The reward function is designed as follows,

\[R(s_{t}^{(i)})=\begin{cases}\frac{1}{\text{acc}_{0}-\text{acc}_{1}+1}&\text{ if acc}_{1}<\text{acc}_{0}\\ -1&\text{ otherwise}\end{cases}, \tag{12}\]

where \(\text{acc}_{0}\) denotes the client's accuracy on the pre-unlearning model. The \(\text{acc}_{1}\) represents the accuracy post the client's unlearning process. To conduct the unlearning procedure, a gradient ascent is executed on the presently sampled graph \(\mathcal{G}^{\prime}_{t}\) at time \(t\).

**Federated Policy Gradient Training**. The objective of the agent is to train an optimal policy network capable of maximizing the expected reward. The training of the policy network involves defining the overall loss as follows.

\[\mathcal{L}(\theta)=\sum_{t}\mathbb{E}_{\pi_{\theta}(a_{t}^{(i)}|s_{t}^{(i)})} [(r_{t}^{(i)}\nabla\log\pi_{\theta}(a_{t}^{(i)}\mid s_{t}^{(i)})]. \tag{13}\]

The optimization of the policy network utilizes Adam optimizer, which is detailed in Appendix A.

### Parameter-free Graph Prompt Knowledge Distillation

Recent research (Wang et al., 2018; Wang et al., 2018) demonstrates the ability of graph prompts to enhance performance on downstream tasks by leveraging the knowledge from pre-trained models and increasing the expressiveness of downstream graph representations. Graph prompts can serve as a medium for distilling knowledge from pre-trained models (Wang et al., 2018). However, existing graph prompt methods are parameter-extensive, which are computationally expensive to improve downstream tasks (Wang et al., 2018). In this module, we introduce the parameter-free graph prompt to distill subgraph knowledge from the target clients.

#### 3.2.1. Graph Prompt Generation.

We first learn a graph prompt generator \(f_{\phi}(\cdot)\) to derive graph prompts, which comprises three major components: graph prompt token vectorization, graph prompt aggregation, and graph prompts insertion.

**Graph Prompt Token Vectorization.** To derive the graph prompt, we first generate vectorized graph prompt tokens, which can be done via a Multi-Layer Perceptron (MLP),

\[MLP(\mathcal{G}_{t}^{\prime})=\mathcal{G}_{\nu_{q}}^{(i)}, \tag{15}\] \[\mathcal{G}_{\nu_{q}}^{(i)}=(\mathcal{P},\mathcal{S}),\] \[\mathbf{s}_{ij}=\begin{cases}\sigma(\mathbf{p}_{i}\cdot\mathbf{p }_{j})&\sigma(\mathbf{p}_{i}\cdot\mathbf{p}_{j})>\eta\\ 0&otherwise\end{cases}, \tag{14}\]

where \(\mathcal{G}_{\nu_{q}}^{(i)}\) is the graph prompt for node \(\nu_{q}^{\prime}\), \(\mathcal{P}=\{\mathbf{p}_{1},\cdots,\mathbf{p}_{q}\}\) denotes the vectorized tokens. The superscript indicates the index for subgraph \(\mathcal{G}_{t}^{\prime}\). \(\mathcal{S}=\{(\mathbf{p}_{i},\mathbf{p}_{j})|\mathbf{p}_{i},\mathbf{p}_{j}\in \mathcal{P}\}\) denotes the pairwise connected relation among the tokens, \(\mathbf{s}_{ij}\) is the connection relation between token \(\mathbf{p}_{i}\) and \(\mathbf{p}_{j}\). \(\sigma\) is the sigmoid function and \(\eta\) is the hyperparameter serving as a control threshold.

Figure 3. Framework overview.

**Graph Prompt Aggregation.** To integrate the distilled graph prompts with the sampled graph, we initiate the process by aggregating the graph tokens. Let \(f_{\theta}(\mathcal{G}_{\mathcal{V}_{q}^{i}}^{(i)})\) denote a universal aggregation function with parameter \(\varphi\). The initial step involves aggregating the graph prompt tokens by taking into account the similarity among tokens,

\[\mathbf{h}_{i}^{I}=\sigma(\sum_{\mathbf{p}_{j}\in\mathcal{N}(\mathbf{p}_{j})} \mathbf{s}_{ij}\mathbf{W}_{i}\mathbf{h}_{j}^{k-1}), \tag{17}\]

where \(\mathbf{h}_{i}^{I}\) is the embedding of token \(\mathbf{p}_{i}\) at the \(l\)-th layer, and \(\mathbf{W}_{l}\) is the function weights at layer \(l\). The the universal aggregation function parameter \(\varphi\) is defined as \(\{\mathbf{W}_{k}\}_{k=1}^{L}\). \(\mathcal{N}(\mathbf{p}_{j})\) represents the connected relation set of token \(\mathbf{p}_{j}\). Finally, mean global pooling is applied to obtain the final embedding,

\[\mathbf{p}_{i}^{\prime}=\frac{1}{q}\sum_{j=1}^{q}\mathbf{h}_{j}^{(L)}, \tag{18}\]

where \(\mathbf{h}_{j}^{(L)}\) is the feature vector of the token \(\mathbf{p}_{j}\) at final layer \(L\).

**Graph Prompts Insertion.** To incorporate the aggregated graph prompts into the sampled graph \(\mathcal{G}_{i}^{\prime}\), we firstly generate \(N_{q}\) graph prompts \(\{\mathcal{G}_{\mathcal{V}_{j}^{i}}^{(i)}\}_{j=1}^{N_{q}}\). Then, we randomly select \(N_{q}\) nodes from the sampled graph \(\mathcal{G}_{i}^{\prime}\) for insertion. The embedding \(\{\mathbf{p}_{j}^{\prime}\}_{i=1}^{N_{q}}\) of aggregated graph prompt tokens are added to the sampled graph \(\mathcal{G}_{i}^{\prime}\).

\[\mathbf{x}_{i}^{\prime}=\begin{cases}\mathbf{x}_{i}^{\prime}+\mathbf{p}_{i}^{ \prime}&\mathbf{x}_{i}^{\prime}\in\mathcal{T}_{x}\\ \mathbf{x}_{i}^{\prime}&otherwise,\end{cases} \tag{19}\]

where \(\mathcal{T}_{x}=\{\mathbf{x}_{1}^{\prime},\cdots,\mathbf{x}_{q}^{\prime}\}\) denote the sampled nodes feature set.

The final sampled graph inserted with graph prompts is termed knowledge enhancer graph \(\mathcal{G}_{i}^{\prime}=(\mathcal{V}_{i}^{\prime},\mathcal{E}_{i}^{\prime}, \mathcal{\hat{X}}_{i}^{\prime})\), where \(\mathcal{\hat{X}}_{i}^{\prime}=\{\mathbf{x}_{i}^{\prime},\cdots,\mathbf{x}_{q }^{\prime}\}\) is augmented feature set, where \(\mathbf{\hat{x}}_{q}^{\prime}\) is the enhanced target node feature.

#### 3.2.2. Graph Prompt Turning.

The goal of graph prompts turning is that the specific graph knowledge learned from the target client by fine-tuning the task parameters, denoted as \(\omega=\{\{\mathcal{G}_{\mathcal{V}_{j}^{i}}^{(i)}\}_{j=1}^{N_{q}},\{\phi\}\}\). The graph prompts turning loss is defined as follows,

\[\mathcal{L}_{\mathcal{G}_{i}^{\prime}}=l(F_{i}(\mathbf{w};\mathcal{\hat{G}}_{i }^{\prime}),\mathbf{y}_{i}^{\prime}), \tag{20}\]

where \(l(\cdot)\) is the cross-entropy node classification loss, \(\mathbf{y}_{i}^{\prime}\) is the label set for graph \(\mathcal{G}_{i}^{\prime}\). The model weight of the local model \(F_{i}(\mathbf{w})\) in the target client is fixed.

### Gradient Descent Unlearning

Based on the knowledge enhancement graph, the target clients are ready for unlearning. To provide guidance for the unlearning process, we employ the average weights of the remaining models as a constraint on the global model. The final unlearning loss is defined as follows,

\[\begin{split}\mathcal{L}_{u}(\mathcal{F}(\mathbf{w}))& =\sum_{\mathcal{C}_{i}\in\mathcal{I}}\left[-\frac{1}{|\mathcal{V} |}\sum_{u^{\prime}\in\mathcal{V}^{\prime}}\left[l(\mathcal{F}_{i}(\mathbf{w}; \mathcal{\hat{G}}_{i}(u^{\prime})),y_{u^{\prime}})\right]\right.\\ &\quad+\lambda_{u}\cdot\left\|\mathbf{w}_{i}-\mathbf{w}^{*} \right\|^{2}\right],\end{split} \tag{21}\]

where \(\mathbf{w}^{*}=\frac{1}{|\mathcal{C}_{i}|\mathcal{I}}\sum_{i\in\mathcal{C}_{i }\setminus\mathcal{I}}\mathbf{w}_{i}\) is the guided model constraint, and \(\lambda_{u}\) is the constrain parameter. \(l(\cdot)\) is the cross-entropy loss. The final unlearned global model is denoted as \(\mathcal{F}\mathbf{w}_{\mathcal{C}_{i}\setminus\mathcal{I}}(\cdot)\).

We also employ the Adam optimizer to minimize the unlearning loss. After unlearning, the performance of the updated global model may decrease for other clients. To mitigate this issue, the server conducts a few rounds of federated learning involving the remaining clients (Ganin et al., 2016; He et al., 2016; Chen et al., 2017). Empirical studies demonstrate that, in practice, only a few rounds are sufficient to keep the new global model \(\mathbf{w}_{\mathcal{C}\setminus\mathcal{I}}\) up to date. The complete procedure for subgraph federated unlearning is reported in Algorithm 1.

```
Input:Client data \(\{\mathcal{G}_{i}\}_{i=1}^{M}\), pretrained policy sampler \(\pi_{\theta}(\cdot)\), global model \(F(\mathbf{w})\), fine-tuning epoch \(E\) Result:Enhanced compact subgraph \(\mathcal{\hat{G}}_{i}^{\prime}=(\mathcal{V}_{i}^{\prime},\mathcal{E}_{i}^{ \prime},\mathcal{\hat{X}}_{i}^{\prime})\)
1 Use pre-trained policy sampler \(\pi_{\theta}(\cdot)\) to sample the graphs \(\{\mathcal{G}^{\prime}\}_{i=1}^{N_{q}}\) based on Equation 11.;
2foreachtarget client \(C_{i}\in\mathcal{I}\) in paralleldo
3for\(k=1\)to\(E\)do
4 Generate the graph prompts based on Equation 14;
5 Aggregate the tokens embedding based on Equations 17 and 18;
6 Insert the graph tokens based on Equation 19;
7 Compute the prompt enhancement loss by Equation 20;
8 Update \(\omega=\{\{\mathcal{G}_{\mathcal{V}_{j}^{(i)}}^{N_{q}}\}_{j=1}^{N_{q}},\{\varphi\}\}\) using Adam
9 optimization with the gradients of \(\mathcal{L}_{\mathcal{\hat{G}}_{i}^{\prime}}\) ;
10 end for
11
12 end for
13
14 Use Adam optimizer to optimize the unlearning loss based on Equation 21;
15 Return unlearned model \(\mathcal{F}(\mathbf{w}_{\mathcal{C}\setminus\mathcal{I}})\).
```

**Algorithm 1**Reinforced Graph Knowledge Enhancement

## 4. Experiments

In this section, we empirically evaluate the proposed framework and compare it with the state-of-the-art federated unlearning methods. We report the unlearning performance on the real-world dataset. To be more specific, we aim to answer the following research questions.

**RQ 1**: Does the proposed method effectively eliminate contributions from multiple clients compared to state-of-the-art unlearning methods? **RQ 2**: How effective are the proposed components within the unlearning framework? **RQ 3**: How robust is the proposed method concerning changes in hyperparameter values? **RQ 4**: Does the unlearning process compromise the privacy of the clients?

### Environmental Setup

**Datasets.** The distributed subgraph is constructed by partitioning the datasets into a predetermined number of participants. In subgraph federated learning (FL), each client possesses a subgraph asa subset of the original graph. Specifically, we utilize a set of real-world graph datasets, including Cora (Brock et al., 2018), Pubmed (Zhu et al., 2018), Photo (Zhu et al., 2018), and Cs (Brock et al., 2018). In the default setting, the overlapping nodes are set to 0.2. Various overlapping nodes setting experiments is presented in Appendix B.1.

**Evaluation Metrics.** For evaluating the effectiveness of federated unlearning methods, we use the widely acknowledged metrics (Zhu et al., 2018; Li et al., 2018; Li et al., 2018). (1) Attack Success Rate (ASR): The backdoor trigger is employed to evaluate the efficacy of unlearning methods. ASR quantifies the successful classification of manipulated data into the target label (Zhu et al., 2018). A lower ASR signifies heightened proficiency in unlearning. (2) Model Accuracy (MA): We assess the accuracy of the global model after the unlearning process as the model utility.

**Baselines.** We consider the following federated unlearning methods: _Retraining from Scratch_: This approach involves retraining on an initialized model using the data from the remaining clients. _Projected Gradient Ascent (PGA)_(Li et al., 2018): PGA is an unlearning method designed to maximize the empirical loss on the local clients. _EWCSGA_(Zhu et al., 2018): EWCS-SGA combines elastic weight consolidation and stochastic gradient ascent to enable the removal of client's contribution without the need for full model retraining. _Noisy-GD_(Zhu et al., 2018): Noisy-GD is a robust data-deletion method that ensures differential privacy constraints are met. _ULKD_(Zhu et al., 2018): ULKD is a server storage history method used to eliminate target client sharing and improve the model's utility through distillation. In evaluating sampled-based methods, we utilize random sampling and node degree for graph selection. Stochastic Gradient Ascent (SGA) is then applied to eradicate target client information in the sampled graph, denoted as _SGA-Random_ and _SGA-Degree_. _ReGEnUnlearn-Degree_ is the variant of our proposed method by using the vanilla heuristics degree-based graph sampler.

**Implementations Details.** All code is executed within the PyTorch framework. The experiments are carried out on two servers: a Linux CentOS Server equipped with 4 RTX 3090 GPUs and a Linux Ubuntu Server with 1 A800 GPU. The unlearning scenario considered involves the server conducting federated learning training and subsequently receiving \(N_{t}=4\) target clients' requests to opt out of the federation. In the context of federated subgraph learning, there are \(M=10\) clients. The different numbers of target clients are discussed in Sections 4.4. Due to the page limit, the variations in the number of clients are presented in Appendix B.1. For the graph backdoor trigger, we employ the Erdos-Renyi (ER) model to generate the graph trigger, with a trigger size of five, and use the Gaussian distribution for the trigger features. We consider FedAvg as the default federated algorithm. Additionally, we evaluate the effectiveness of the proposed ReGEnUnlearn under more advanced federated algorithms in Appendix B.2. Each experiment is iterated five times to derive average results.

### RQ 1: Main Results

Table 1 presents comprehensive results for the proposed methods and respected baseline models across two metrics. We can make the following observations: the proposed framework's superior performance in ASR across four datasets when compared to all baseline models. In particular, ReGEnUnlearn achieves nearly 100% elimination of multi-client contributions on datasets Cora, Pubmed, and Cs. Furthermore, our proposed framework demonstrates superiority model utility when compared to retraining methods across all four datasets. In specific, ReGEnUnlearn achieves performance levels of 100.66%, 100.69%, 103.47%, and 102.42%, which are directly comparable to retraining methods. We further report the running time of federated unlearning methods in Figure 4 and 5. Specifically, our proposed framework achieves 3.66x, 4.7x, 16.07x, and 9.08x speedup when compared to retraining methods on four datasets.

### RQ 2: Ablation Study

To evaluate the effectiveness of each module within ReGEnUnlearn, we executed an ablation study across four datasets, employing two metrics. Specifically, we investigated the following variants: (1) _ReGEnUnlearn-WoPolicy_ excludes the policy sampler module using the random sampler to replace it: (2) _ReGEnUnlearn-WoPrompt_ excludes the graph prompt empowerment module.

As delineated in Table 2, the following observations across four datasets. Each of the two modules significantly contributes to the overall performance. Notably, the removal of any single module results in performance degradation. Furthermore, our investigation reveals a performance decline when substituting the policy sampler with the vanilla heuristics sampler method, underscoring the tangible benefits of employing a learnable sampling strategy to navigate the graph. Additionally, a performance improvement

Figure 4. Running time on Cora and Pubmed.

Figure 5. Running time on datasets Photo and Cs.

is observed when omitting the graph prompts modules, providing empirical validation for the efficacy of unlearning the contributions of target clients. Overall, the above results verify the effectiveness of the proposed ReGEnUnlearn framework.

### RQ 3 Parameter Analysis

Next, we investigate the parameter sensitivity of our proposed approach. We present findings related to the number of target clients \(N_{I}\), the sampling rate s, and the number of graph tokens \(q\) on the Cora dataset across three metrics. Similar trends are observed across the other three datasets.

First, we vary the value of \(N_{I}\) from 1 to 5, as depicted in Figure 6(a). The observations are summarized as follows. The proposed ReGEnUnlearn framework successfully eliminates all client contributions across the range of target clients. Additionally, an increase in \(K\) initially leads to a rise in subtle MA.

Finally, we vary the number of graph tokens \(q\) within the range of 10 to 50, as depicted in Figure 7(a). Our observations yield the following synthesis: with an increase in \(q\), the ASR exhibits an initial ascent followed by a subsequent descent. Simultaneously, MA maintains a relatively stable profile devoid of pronounced variations.

Overall, adjusting the above hyperparameters induces performance variations within a reasonable range across three metrics, thereby demonstrating the robustness of our approach.

### RQ 4: Privacy Analysis

**Privacy Protection.** In the phase of federated unlearning, the direct uploading of the GCN model by target clients poses potential privacy concerns. The gradients in the model update may inadvertently expose private information to the target clients, as the GCN model gradients inherently encode graph information preferences. To protect the privacy of the target clients, Differential Privacy (DP) can be employed during the unlearning stage.

\[\mathbf{w}_{i}+\mathcal{N}(0,\sigma^{2}\mathbf{I}) \tag{22}\]

\begin{table}
\begin{tabular}{c c c c c} \hline \hline  & \multicolumn{2}{c|}{Cora} & \multicolumn{2}{c}{Pubmed} \\ \hline Methods & Attack Success Rate & Model Accuracy & Attack Success Rate & Model Accuracy & 788 \\ \hline Retrain & 0 & 0.8720 (0.0244) & **0** & 0.8548 (0.0032) & 789 \\ PGA & 0.2 (0.4472) & 0.8594 (0.0532) & 0.2 (0.4) & 0.6621 (0.0203) & 789 \\ SGA-Random & 0.2 (0.4472) & 0.8628 (0.0277) & 0.4 (0.5477) & 0.746 (0.0416) & 761 \\ SGA-Degree & 0.2 (0.4472) & 0.8696 (0.0382) & 0.4343 (0.5211) & 0.7429 (0.0353) & 762 \\ EWC-SGA & 0 & 0.7174 (0.0505) & 0 2 (0.4) & 0.7694 (0.0260) & 763 \\ Noisy-GD & 0.9993 (0.0014) & 0.7430 (0.0578) & 0.9999 (0.0001) & 0.8383 (0.0236) & 764 \\ ULKD & 0 & 0.4029 (0.1808) & 0.3998 (0.4897) & 0.7178 (0.2179) & 765 \\
**ReGEnUnlearn-Degree (Ours)** & 0 & 0.8763 (0.0227) & 0.0159 (0.0283) & **0.8639 (0.0169)** & 766 \\
**ReGEnUnlearn (Ours)** & **0** & **0.8778 (0.0202)** & 0.0027 (0.0048) & 0.8607 (0.014) & 760 \\ \hline \multicolumn{4}{c}{Photo} & \multicolumn{2}{c|}{Cs} & \multicolumn{2}{c}{780} \\ \hline Methods & Attack Success Rate & Model Accuracy & Attack Success Rate & Model Accuracy & 788 \\ \hline Retrain & **0** & 0.7 (0.0751) & 0 & 0.8437 (0.0128) & 789 \\ PGA & 0 & 0.5008 (0.0537) & 0.2 (0.4472) & 0.8379 (0.0680) & 770 \\ SGA-Random & 0.3285 (0.3505) & 0.6287 (0.0600) & 0.2 (0.4472) & 0.8415 (0.0371) & 771 \\ SGA-Degree & 0.2364 (0.1388) & 0.6327 (0.2364) & 0.2 (0.4472) & 0.8494 (0.0191) & 772 \\ EWC-SGA & 0.6914 (0.3908) & 0.7128 (0.0287) & 0.4007 (0.5471) & 0.8505 (0.0287) & 773 \\ Noisy-GD & 1 & 0.6991 (0.0300) & 0.1995 (0.3985) & 0.8650 (0.0045) & 774 \\ ULKD & 0.2 (0.4) & 0.4994 (0.0420) & 0 & 0.3569 (0.1294) & 778 \\
**ReGEnUnlearn-Degree (Ours)** & 0.2629 (0.31) & 0.7229 (0.0431) & 0 & **0.8730 (0.0068)** & 778 \\
**ReGEnUnlearn (Ours)** & 0.1703 (0.1202) & **0.7243 (0.0725)** & **0** & 0.8642 (0.0137) & 777 \\ \hline \hline \end{tabular}
\end{table}
Table 1. Overall Performance of Federated Unlearning

Figure 6. (a) Effect of the number of target clients. (b) Effect of the number of target clients.

Figure 7. (a) Effect of the number of tokens. (b) Effect of the number of \(\epsilon\).

## 5. Related Work

### Subgraph Federated Learning

Recently, researchers have made substantial progress in federated subgraph learning (Wang et al., 2019; Wang et al., 2019; Wang et al., 2019). Various FL frameworks have been designed for graph learning tasks, encompassing recommendation (Wang et al., 2019), graph classification (Wang et al., 2019), and node classification (Wang et al., 2019), among others (Wang et al., 2019; Wang et al., 2019). For instance, Wu _et al._(Wu et al., 2019) introduced a federated framework for privacy-preserving Graph Neural Network (GNN)-based recommendation systems. This framework enables collective training of GNN models from decentralized user data. He _et al._(He et al., 2016) proposed FedGNN, a unified framework applicable to graphs from diverse domains. In federated subgraph learning, a key challenge involves addressing missing link problems. Zhang _et al._(Zhang et al., 2019) introduced FedSegAge+, a subgraph federated unlearning framework that trains neighborhood generators along with FedSage to handle missing links across local subgraphs. Baek _et al._(Baek et al., 2019) presented FedPub, a federated subgraph framework utilizing functional embeddings to construct client relations based on similarity. Another challenge lies in defending against poisoning attacks. Recent studies indicate that federated subgraph systems are vulnerable to backdoor attacks, making them susceptible to graph triggers. For example, Liu _et al._(Liu et al., 2019) formally proposed a federated graph backdoor framework capable of attacking federated graph systems. However, there is a notable absence of attention to privacy issues within the context of machine unlearning. To address this gap, to the best of our knowledge, we are the first to explore subgraph federated unlearning. We introduce ReGEnUnlearn framework for efficient and comprehensive unlearning of multiple target clients.

### Federated Unlearning

Recently, federated unlearning (Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019) has garnered significant research attention. Two scenarios exist in federated unlearning: sample-level federated unlearning (Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019) and client-level federated unlearning (Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019). Sample-level unlearning is a natural extension of the centralized setup. In such settings, FL systems are tasked with requesting the forgetting of a particular category or subset. For example, Wang _et al._(Wang et al., 2019) proposed a federated unlearning framework capable of scrubbing specific categories. Liu _et al._(Liu et al., 2019) proposed a rapid training approach to completely erase data samples from a trained FL model. In client-level federated unlearning, the FL system is tasked with requesting the forgetting of the client's entire contribution in a cross-silo scenario. For instance, Wu _et al._(Wu et al., 2019) propose that the server stores historical local client information. When clients out of the federation, the server eliminates their contributions and uses knowledge distillation to maintain model utility. Halimi _et al._(Halimi et al., 2019) proposed a gradient descent method to unlearn the client's entire contribution. Subgraph federated unlearning primarily occurs in cross-silo scenarios where multiple institutes (e.g., banks and hospitals, _et al._) hold a subgraph and train FL models under strict privacy regulations. Therefore, our primary focus is on considering how to eliminate the entire contributions of multiple clients.

## 6. Conclusions

In this paper, we presented ReGEnUnlearn, a subgraph federated unlearning framework for efficient and comprehensive unlearning of multiple target clients. By sampling the graphs and distilling graph knowledge, the proposed framework improves both model utility and unlearning performance. Specifically, we introduce the _Reinforced Federated Policy Sampler_ (RFPS) to learn optimal sampling strategies that minimize the interference among cross-client subgraphs. By interacting with the federated graph sampling environment, the agent learns to selectively forget an optimal subgraph of target clients, thus preserving the global model utility. Moreover, we propose the _Parameter-free Graph Prompt Knowledge Distillation_ (PGPKD) module, which retains the unique graph knowledge contributed by the target clients, thereby facilitating comprehensive unlearning via a tailored gradient ascent objective. We conduct extensive experiments under diverse federated settings to demonstrate the superiority of the proposed framework over state-of-the-art federated unlearning approaches. It is also worth mentioning that the framework is federated algorithm-agnostic, which means it can be easily adopted in other subgraph federated scenarios. In the future, we plan to apply ReGEnUnlearn other tasks such as federated graph classification and link prediction tasks.

\begin{table}
\begin{tabular}{c c c c c} \hline \hline  & \multicolumn{2}{c}{Cora} & \multicolumn{2}{c}{Pubmed} \\ \hline Methods & Attack Success Rate & Model Accuracy & Attack Success Rate & Model Accuracy \\ \hline ReGEnUnlearn-WoPolicy & 0 & 0.8744 (0.0264) & 0.1293 (0.2574) & 0.7882 (0.0321) \\ ReGEnUnlearn-WoPrompt & 0.6 (0.5477) & 0.8633 (0.0188) & 0.3890 (0.5273) & 0.8264 (0.03324) \\
**ReGEnUnlearn (Ours)** & **0** & **0.8778 (0.0202)** & **0.0027 (0.0048)** & **0.8607 (0.014)** \\ \hline \multicolumn{5}{c}{Photo} & \multicolumn{2}{c}{Cs} \\ \hline Methods & Attack Success Rate & Model Accuracy & Attack Success Rate & Model Accuracy \\ \hline ReGEnUnlearn-WoPolicy & 0.282 (0.3123) & 0.7002 (0.0528) & 0.2 (0.4) & 0.8605 (0.01467) \\ ReGEnUnlearn-WoPrompt & 0.3918 (0.4803) & 0.6212 (0.0960) & 0 & 0.8617 (0.0099) \\
**ReGEnUnlearn (Ours)** & **0.1703 (0.1202)** & **0.7243 (0.0725)** & **0** & **0.8642 (0.0137)** \\ \hline \hline \end{tabular}
\end{table}
Table 2. Ablation Study of Federated Unlearning

## References

* (1)
* Alsadi et al. (2016) Martin Alsadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. 2016. Deep Learning with Differential Privacy (CCS '16). Association for Computing Machinery, New York, NY, USA, 308-318.
* Anabu et al. (2023) Mehdi Anabu, Pushchartsamen Ganesh, Shantam Thakcon, Chi-Heng Lin, Lukasmit Smitrikoek, Ran Liu, Michal Vuko, Peter Velickovic, and I. A. Dyer. 2023. Half-Hop: A graph upsampling approach for slowing down message-passing. In _International Conference on Machine Learning_. PMLR, 1341-1360.
* Back et al. (2023) Jinheen Back, Woerweg Jeong, Jonghao Jin, Jeong Yoon, and Sung Ju Hwang. 2023. Personalized Subgraph Federated Learning. (2023).
* Baek et al. (2023) Jinheen Baek, Woerweg Jeong, Jonghao Jin, Jeong Yoon, and Sung Ju Hwang. 2023. Personalized subgraph federated learning. In _International Conference on Machine Learning_. PMLR, 3349-3415.
* Cao et al. (2023) Xiaoyu Cao, Jinyuan Jia, Zhai Zhang, and Neil Zhenqiang Gong. 2023. Fef-decover: Recovering from poisoning attacks in federated learning using historical information. In _2023 IEEE Symposium on Security and Privacy (SP)_. IEEE, 1366-1383.
* Che et al. (2023) Tianshi Che, Yang Zhou, Zijie Zhang, Lingjian Lyu, Ji Liu, Du Yan, Dejing Dou, and Jun Huan. 2023. Fast Federated Machine Unlearning with Nonlinear Functional Theory. In _Proceedings of the 4th International Conference on Machine Learning_ (Global, Hawaii, USA), 2023. PMLR, Article 169, 28 pages.
* Choruvati and Shah (2023) Ruihav Choruvati and Neid Shah. 2023. Target Unlearning Towards True Data Deletion in Machine Learning (CRL 2). 2023. URL [https://arxiv.org/abs/2304.06495](https://arxiv.org/abs/2304.06495).
* Fraboni et al. (2022) Yuan Fraboni, Richard Vidal, Laetitia Kameni, and Marco Lorenzi. 2022. Sequential Informed Federated Unlearning: Efficient and Provable Client. Unlearning in Federated Optimization. _arXiv preprint arXiv:2211.11655_ (2022).
* Fu et al. (2022) Xingbo Fu, Binichi Zhang, Yushun Dong, Chen Chen, and Junjong Li. 2022. Federated graph machine learning: A survey of concepts, techniques, and applications. _ACM SIGKDD Explorations Newsletter_ 24, 2 (2022), 322-342.
* Gao et al. (2022) Xiangshan Gao, Xingshan Ma, Jingyi Wang, Yucheng Sun, Io Li, Shihong Ji, Peng Cheng, and Jinming Chen. 2022. Fef-Towards verifiable federated unlearning. _arXiv preprint arXiv:22022.12709_ (2022).
* Ginast et al. (2019) Antonio A. Ginast, Melody F. Gunn, Gregory Valiant, and James Zou. 2019. Making AI report fuss Data Deletion in Machine Learning. Curran Associates Inc., Red Hook, NY, USA.
* Guo et al. (2021) Jinu Guo, Ossaldoe Simone, and Joonhyuk Kang. 2021. Bayesian variational federated learning and unlearning in decentralized networks. In _2021 IEEE 22nd International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)_. IEEE, 216-220.
* Gong et al. (2022) Jian Gong, Ossaldoe Simone, and Joonhyuk Kang. 2022. Compressed particle-based federated bayesian learning and unlearning. _IEEE Communications Letters_ 27, 2 (2022), 556-560.
* Hillami et al. (2022) Anita Hillami, Swami Kadhe, Ambrish Rawat, and Nathalie Baracaldo. 2022. Federated Unlearning: How to Efficiently Erase a Client in FL? _CoRR_ abs/2207.05521 (2022). arXiv:2207.05521
* Holli et al. (2022) Anita Hillami, Swami Kadhe, Ambrish Rawat, and Nathalie Baracaldo. 2022. Federated unlearning: How to efficiently erase a client in ff? _arXiv preprint arXiv:2207.05521_ (2022).
* He et al. (2021) Chaoyang He, Keshav Balasubramanian, Emir Coyani, Carl Yang, Han Xie, Lichao Sun, Lifang, Leisong Liangjie Yang, Philip Yi, Yu Rong, et al. 2021. Fedgraphmin: A federated learning system and benchmark for graph neural networks. _arXiv preprint arXiv:2104.07145_ (2021).
* He et al. (2021) Chaoyang He, Emir Coyani, Keshav Balasubramanian, Murali Annavaram, and Salman Avestimehr. 2021. SpreadCNN: Decentralized Multi-Task Federated Learning for Graph Neural Networks on Molecular Data. arXiv:2106.02743 (cs.LG).
* Guan et al. (2023) Guanphao Li, Li Shen, Yan Sun, Yue Tu, Hua Liu, and Dacheng Tao. 2023. Sub-Space based Federated Unlearning. _arXiv preprint arXiv:2302.12488_ (2023).
* Li et al. (2020) Tian Li, Anit Kumar Sahu, Martial Zaheer, Mariar Sanjabi, Ameet Talwalkar, and Virginia Smith. 2020. Federated optimization in heterogeneous networks. _Proceedings of Machine learning and systems_ 2020, 429-450.
* Li et al. (2023) Yuyuan Li, Chaoheng Chen, Xiaolin Zheng, and Jaiming Zhang. 2023. Federated unlearning via active forgetting. _arXiv preprint arXiv:2307.03363_ (2023).
* Lin et al. (2023) Fan Lin, Siqi Li, Yanqso Ning, and Hao Lin. 2023. Bid-FedCNN: A Benchmark for Classification Backdoor Attacks on Federated Graph Neural Network. _arXiv preprint arXiv:2308.1037_ (2023).
* Liu et al. (2021) Gaoyang Liu, Xiaogang Ma, Yang Yang, Chen Wang, and Jangshou Liu. 2021. Federated: Enabling efficient and-level data removal from federated learning models. In _2022 IEEE/ACM 29th International Symposium on Quality of Service (IWQCS)_. IEEE, 1-10.
* Liu et al. (2020) Yang Lin, Zhao Ma, Xinmei Liu, and Jianfeng Ma. 2020. Learn to forget: User-level memorization elimination in federated learning. _arXiv preprint arXiv:2003.10933_ (2020).
* Liu et al. (2022) Yi Liu, Lei Xu, Xingliang Yuan, Cong Wang, and Bo Li. 2022. The right to be forgotten in federated learning: An efficient realization with rapid retraining. In _IEEE INFOCOM 2022-IEEE Conference on Computer Communication_. IEEE, 1749-1758.
* Liu et al. (2023) Ziyue Liu, Yu Jang, Jiyuan Shen, Miriy Peng, Kwok-Yan Lam, and Xingliang Yuan. 2023. A survey on Federated Unlearning Challenges, Methods, and Future Directions. _arXiv preprint arXiv:2310.20485_ (2023).
* Luo et al. (2022) Yi Luo, Guangzhun Luo, Ke Yan, and Ajguo Chen. 2022. Inferring from References with Difference for Semi-Supervised Node Classification on Graphs. _Mathematics_ 10, 8 (2022), 1262.
* McMahan et al. (2017) Brennen McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Aros. 2017. Communication-efficient learning of deep networks from decentralized data. In _Artificial intelligence and statistics_. PMLR, 1273-1282.
* Pan et al. (2023) Chao Pan, Jin Sim, Suzanar Prakash, Vishali Rama, and Olgai Milenkovic. 2023. Machine Unlearning of Federated Clusters. In _The Eleventh International Conference on Learning Representations_. [https://openreview.net/forum?id=Verbyt?Dpa](https://openreview.net/forum?id=Verbyt?Dpa).
* Sen et al. (2008) Pithviraj Sen, Galileo Namats, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. 2008. Collective classification in network data. _AI magazine_ 29, 3 (2008), 93-93.
* Sa and Li (2023) Ningxin Su and Bacchini. 2023. Asynchronous federated unlearning. In _IEEE INFOCOM 2023-IEEE Conference on Computer Communications_. IEEE, 1-10.
* Sun et al. (2023) Xiangguo Sun, Hong Cheng, Jia Li, Bo Liu, and Jihong Guan. 2023. All in One: Multi-Task Computing for Graph Neural Networks. In _Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_ (Long Beach, CA, USA), (KDD '23) Association for Computing Machinery, New York, NY, USA, 220-2131.
* Sun et al. (2023) Xiangguo Sun, Jiawen Zhang, Xixi Wu, Hong Cheng, Yun Xiong, and Jia Li. 2023. Graph Prompt Learning: A Comprehensive Survey and Beyond. _arXiv preprint arXiv:2311.16531_ (2023).
* Yu et al. (2023) Yue Tan, Yilin Liu, Guoliang Long, Jing Jiang, Qinghua Li, and Chengj Zhang. 2023. Federated learning on non-soft graphs via structural knowledge sharing. In _Proceedings of the AAAI conference on artificial intelligence_, Vol. 37, 9933-9961.
* Wang et al. (2002) Junxiao Wang, Song Guo, Xin Xie, and Heng Q. 2022. Federated unlearning via class-discriminative pruning. In _Proceedings of the ACM Web Conference on_. 2022-623-2633.
* Wang et al. (2013) Weiwei Wang, Zhiyi Tian, Chenhan Zhang, An Liu, and Shui Yu. 2013. BFU: Bayesian Federated Unlearning with Parameter Self-Sharing. In _Proceedings of the 2023 ACM Asia Conference on Computer and Communications Security_. 567-578.
* Wang et al. (2002) Zhen Wang, Qiwhi Xiang, Yuexing Liu, Liyue Yao, Yuliang Li, Boih Ding, and Jingzen. 2002. Federated-space-group: Towards a unified, comprehensive and efficient package for federated graph learning. In _Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_. 4110-4120.
* Yu et al. (2022) Chunhua Yu, Fangzhou, Weiwei Wang, Lingjian Lyu, Tao Qi, Yongfeng Huang, and Xing. 2022. A federated graph neural network framework for privacy-preserving personalization. _Nature Communications_ 13, 1 (2022), 907.
* Wu et al. (2002) Leijse Wu, Song Guo, Junxiao Wang, Ziecong Hong, Jie Zhang, and Yachong Ding. 2022. Federated unlearning: Guarantee the right of clients to forget. _IEEE Networks_ 5, 3 (2022), 129-135.
* Xu et al. (2023) Xuansheng Wu, Kaixiang Zhou, Mingxuebin Sun, Xin Wang, and Ninghao Liu. 2023. A survey of graph promoting methoden. techniques, applications, and challenges. _arXiv preprint arXiv:2308.07275_ (2023).
* Wang et al. (2002) Zenghui Wang, Shirui Yan, Pengwen Chen, Guodong Long, Chengqi Zhang, and S. Yu Philip. 2002. A comprehensive survey on graph neural networks. _IEEE transactions on neural networks and learning systems_, 31, 2 (2002), 4-23.
* Xia et al. (2023) Hui Xia, Shu Xiang, Yujiang Liu, and Xiaofeng Liu. 2023. Felt-2. Memory evaluation & erase promoting federated unlearning in dbm. _IEEE Journal on Selected Areas in Communications_ (2023).
* Xie et al. (2021) Han Xie, Jing, Ma, Xiang, and Caii Yang. 2021. Federated graph classification over non-rigid graphs. _Advances in Neural Information Processing Systems_ 34 (2021).
* Tao et al. (2009) Yuhang Tao, Weizhao Jin, Srivatsan Basu, and Carlie Joe-Wong. 2009. Fedgen: Convergence and communication fields for federated training of graph convolutional networks. _arXiv preprint arXiv:2001.12433_ (2002).
* Wu et al. (2023) Wei, Yunhong Li, Fangzhou Wu, Shijie Zhang, Tieke Heng, and Hao Wang. 2023. Federated unlearning on face-free architecture. In _Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining_. 393-401.
* Zhang et al. (2021) Ke Zhang, Carl Yang, Xiaofeng Li, Lichao Sun, and Siu Ming Ying. 2021. Self-gbm Federated learning with missing neighbor generation. _Advances in Neural Information Processing Systems_ 34 (2021), 6671-6682.
* Zhang et al. (2023) Lefeng Zhang, Tianqing Zhang, Huilin Zhang, Peng Xiong, and Wanilei Zhou. 2023. Fedrecovery: Differentially private machine unlearning for federated learning frameworks. _IEEE Transactions on Information Forensics and Security_ (2023).
* Zhang et al. (2022) Yanci Zhang and Han Yu. 2022. Towards Verifiable Federated Learning. In _Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence Organization_. JCAI-22, Lund De Raedt (Ed.), International Joint Conferences on Artificial Intelligence Organization, 5686-5693.

## Appendix A Reinforced Federated Policy Sampler

Unlearning across multiple clients could significantly diminish the model's utility, particularly in the presence of interference from cross-client nodes. The key challenge is how to remove the overlapping subgraph without accessing data from other clients. To tackle this issue, we introduce the Reinforced Federated Policy Sampler. This approach employs a reinforcement learning algorithm, empowering the agent to discern the optimal policy for subgraph sampling. During the federated training stage, the server can execute the Reinforced Federated Policy Sampler Pre-training, facilitating its application in the subsequent unlearning stage. Further details about the algorithm are elucidated in Algorithm 2.

```
Input:Target clients \(\mathcal{I}\), subgraphs \(\{\hat{\mathcal{G}}_{i}\}_{i}^{M}\), local unlearn epoch \(n\). Result:Pre-trained Policy Sampler \(\pi_{\theta}(a_{t}|s_{t})\)
1 Server initializes \(\theta_{:}\)
2for each round \(t=1,2,\cdots\)do
3foreach target client \(C_{i}\in C\) in paralleldo
4for\(j=1\) to \(n\)do
5 Generate the action based on Equation 3.1 ;
6 Obtain the sampled graph based on Equation 11 ;
7 Compute the reward by Equation 12 ;
8 Update the local client
9\(\mathbb{E}_{\pi_{\theta}(a_{t}^{(i)}|s_{t}^{(i)})}\{\{r_{t}^{(i)}\nabla\log\pi_ {\theta}(a_{t}^{(i)}\mid s_{t}^{(i)})\}\) by
10 Adam optimizer ;
11
12 end for
13
14 end for
15
16\(\theta_{t+1}\longleftarrow\sum_{i}\theta_{t+1}^{(i)}\) ;
17
18 end for
19Return \(\theta\) to the server.
```

**Algorithm 2**Reinforced Federated Policy Sampler Pre-training

## Appendix B Further Experiments

The statistical analysis of graph data is presented in Table 3. We extend our investigations by conducting additional experiments across diverse federated learning scenarios, including further parameter analysis and exploration of experiments under more advanced scenarios.

### Further Experiments Parameter Analysis

We further conduct the additional experiments under different parameter settings to evaluate the effect of parameters, including scenarios with different numbers of clients, regularization coefficient, and overlapping rates on dataset Cora.

_Effect of number of clients \(M\)._ We fix the the number of unlearned clients is 4, vary the number of clients from 10 to 30. Figure 8(a) reports the overall results. We have made the following observations. First, it becomes evident that the number of clients exerts negligible influence on unlearning performance. Notably, the ASR remains consistent across different configurations, showing a deviation of 0. Additionally, we increase the value of \(M\), leading to a corresponding rise in the MA with the augmentation of supervised signals.

_Effect of parameter \(\lambda_{u}\)._ We vary the parameter \(\lambda_{u}\) from 0.2 from 1.0. Figure 8(b) reports the results across two metrics. First, we observe that with the increase of \(\lambda_{u}\), the ASR first increases and then decreases. Second, with the increase of parameter \(\lambda_{u}\)

_Effect of overlapping rate._ We systematically vary the overlapping rate within the range of 0.1 to 0.5. The outcomes are illustrated in Figure 9(a), showcasing results across two key metrics. Initially, as the overlapping rate escalates, the ASR consistently maintains a value of 0, underscoring the effectiveness of our proposed method.

\begin{table}
\begin{tabular}{c c c} \hline \hline Methods & Attack Success Rate & Model Accuracy \\ \hline Retrain & 0 & 0.802 (0.0142) & 11.08 \\ PGA & 0.4 (0.5477) & 0.8652 (0.0193) & 12.08 \\ SGA-Random & 0.202 (0.402) & 0.8720 (0.0244) & 11.08 \\ EWC-SCA & 0.4 (0.5477) & 0.6560 (0.1541) & 11.08 \\ Noisy-GD & 1 & 0.4116 (0.1418) & 11.08 \\ ULKD & 1 & 0.8297 (0.0405) & 11.08 \\
**ReGenUnlearn-Degree (Ours)** & 0 & 0.8807 (0.0146) & 11.08 \\
**ReGenUnlearn (Ours)** & **0** & **0.8807 (0.0132)** & 11.08 \\ \hline \hline \end{tabular}
\end{table}
Table 4. Unlearning Experiments under the FexProx

\begin{table}
\begin{tabular}{c c c c} \hline \hline Datasets & \# of Nodes & \# of Edges & \# of Classes \\ \hline Cora & 2,708 & 5,278 & 7 \\ Pubmed & 19,717 & 44,324 & 3 \\ Photo & 7,650 & 238,163 & 8 \\ Cs & 18,333 & 163,788 & 15 \\ \hline \hline \end{tabular}
\end{table}
Table 3. Statistics analysis of the graph datasets.

Figure 8. (a) Effect of number of clients \(M\). (b) Effect of parameter \(\lambda_{u}\)

\begin{table}
\begin{tabular}{c c c} \hline \hline Methods & Attack Success Rate & Model Accuracy \\ \hline Retrain & 0 & 0.8778 (0.0142) & 11.08 \\ PGA & 0.40 (0.5477) & 0.8652 (0.0193) & 12.08 \\ SGA-Random & 0.202 (0.402) & 0.8715 (0.01659) & 11.08 \\ SKA-Degree & 0.42 (0.042) & 0.8720 (0.0244) & 11.08 \\ EWC-SCA & 0.4 (0.5477) & 0.6560 (0.1541) & 11.08 \\ Noisy-GD & 1 & 0.4116 (0.1418) & 11.08 \\
**ReGenUnlearn-Degree (Ours)** & 0 & 0.8807 (0.046) & 11.08 \\
**ReGenUnlearn (Ours)** & **0** & **0.8807 (0.0132)** & 11.08 \\ \hline \hline \end{tabular}
\end{table}
Table 5. Unlearning Experiments under the FedPubFurthermore, a discernible trend emerges where an uptick in the overlapping rate correlates with an increase in the MA, attributable to the concurrent rise in the number of samples.

### Unlearning Experiments under Other Federated Scenarios

We further conduct the experiments on more advanced scenarios on datasets Cora. More specifically, we will conduct further experiments on more advanced federated algorithms and Non-IID Settings.

_Advanced Federated Algorithms._ We investigate federated unlearning scenarios, encompassing both a general federated algorithm (e.g., FedProx [19]) and one tailored for graph scenarios (e.g., FedPub [4]). Table 4-5 reports the overall experimental results across three metrics. We make the following observations. Firstly, our proposed framework successfully eliminates contributions from all clients for both FedProx and FedPub, in stark contrast to retraining methods, where traditional approaches fail to eliminate contributions from the target client. Additionally, we observe a reduction in model utility under more advanced federated algorithms compared to the FedAvg algorithm. For example, our proposed method achieves performance metrics of (100%, 100.76%) in comparison to retraining methods under FedProx and FedPub.

_Non-IID Setting._ To evaluate the effectiveness of subgraph federated unlearning in the Non-IID setting, we conduct additional experiments. Specifically, we utilize the Dirichlet function to partition the participants with a parameter set to 0.3. The results are presented in Table 6, and the following observations can be made. Firstly, unlearning multiple target clients is more challenging under the Non-IID setting, with most baselines struggling to eliminate all client contributions. Additionally, our methods consistently maintain approximately 100.43%, compare with the retraining methods.

\begin{table}
\begin{tabular}{c c c} \hline Methods & Attack Success Rate & Model Accuracy \\ \hline Retrain & 0 & 0.8908 (0.0119) & 1289 \\ PGA & 0.2 (0.4472) & 0.8823 (0.0255) & 1280 \\ SGA-Random & 0.2 (0.4472) & 0.8810 (0.0220) & 1241 \\ SGA-Degree & 0.2 (0.4472) & 0.8871 (0.0164) & 1280 \\ EWC-SCA & 0.2 (0.4472) & 0.6828 (0.1357) & 1280 \\ Noisy-GD & 0.9776 (0.0035) & 0.5733 (0.2095) & 1280 \\ ULKD & 0.6 (0.5477) & 0.2141 (0.1313) & 1280 \\
**ReGEnUnlearn-Degree (Ours)** & 0.1687 (0.3772) & 0.8959 (0.0181) & 1280 \\
**ReGEnUnlearn (Ours)** & **0** & **0.8947 (0.0209)** & 1280 \\ \hline \end{tabular}
\end{table}
Table 6. Unlearning Experiments under Non-IID Setting

Figure 9. (a) Effect of overlapping rate.