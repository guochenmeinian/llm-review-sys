# Making Cloud Spot Instance Interruption Events Visible

Anonymous Author(s)

###### Abstract.

Public cloud computing vendors offer a surplus of computing resources at a cheaper price with a service of spot instance. Despite the possible great cost savings from using spot instances, sudden resource interruption can happen as resource demand changes. To help users estimate cost savings and the possibility of interruption when using spot instances, vendors provide diverse datasets. However, the effectiveness of using the datasets is not quantitatively evaluated yet, and many users still rely on hunch when choosing spot instances. To help users lower the chance of interruption of the spot instance for reliable usage, in this paper, we thoroughly analyze various datasets of the spot instance and present the feasibility for value prediction. Then, to measure how the public datasets reflect real-world spot instance interruption events, we conduct real-world experiments for spot instances of AWS, Azure, and Google Cloud. Combining the dataset analysis, prediction, and real-world spot instance interruption experiment result, we show the feasibility for lowering the possibility of interruption events significantly.

cloud computing, spot instance, interruption modeling, enhancing reliability, spot instance datasets +
Footnote †: ccs: Information systems Web log analysis

+
Footnote †: ccs: Information systems Web log analysis

+
Footnote †: ccs: Information systems Web log analysis

+
Footnote †: ccs: Information systems Web log analysis

+
Footnote †: ccs: Information systems Web log analysis

+
Footnote †: ccs: Information systems Web log analysis

+
Footnote †: ccs: Information systems Web log analysis

+
Footnote †: ccs: Information systems Web log analysis

+
Footnote †: ccs: Information systems Web log analysis

## 1. Introduction

The cloud computing provides compute resources elastically without the burden of system operation overhead and changes the way we consume compute resources. The core success of the cloud computing is owing to its on-demand billing model that allows users to dynamically start and stop instances based on its application needs and pay for what they have actually used. To support elastic resource usage, cloud service providers should prepare abundant resources to meet resource usage spikes. Such a plentiful resource preparation inevitably results in resource wastage when computing demand is low. To encourage instance usage when demand is low, public cloud vendors provide the surplus computing resources at a discounted price which can be more than 90% cheaper than the on-demand price in some cases. The billing model is called spot instances, and they are offered by most public cloud service providers, AWS (Bogu et al., 2017), Azure (Azure, 2017), Google Cloud Platform (GCP) (Alibaba, 2017), Oracle Cloud Preemptible Instances, and IBM Transient Virtual Servers. Due to the cost efficiency of spot instances, they are widely used for diverse applications, such as web server, data processing, and parallel processing batch jobs.

In the early days of spot instance offering, most vendors adopted an auction mechanism where a user sets a bidding price, and a provider sets a spot price. If the bidding price is higher than the spot price, a user gets granted an instance and pays for the spot price, not the bidding price. Based on the compute resource demands, a service provider changes the spot price, and if the spot price becomes higher than the initial bidding price, a spot instances is revoked, which is generally referred to as instance interruption. Such an instance interruption can negatively impact applications' reliability, and users should be prepared for the event. To help users enhance reliability when using spot instances, cloud vendors provide diverse datasets publicly through web. One of the most representative datasets is the spot instance price that presents the spot price at a specific time. Many research was conducted using the spot instance price dataset to analyze the spot price itself (Bogu et al., 2017; 2017; 2017; 2017; 2017; 2017), using the spot instance dataset to enhance reliability for diverse applications (Bogu et al., 2017; 2017; 2017; 2017; 2017; 2017), or suggesting an optimal bidding price using the spot price prediction (Bogu et al., 2017; 2017; 2017; 2017; 2017).

The spot price dataset was a precious source of information when using spot instances reliably especially for AWS, but it changes with the new spot instance operation policy. With the new policy, the advertised spot price does not reflect the spot instance interruption anymore, and the frequency of the data change becomes very low (Bogu et al., 2017; 2017) which greatly degrades the application of the dataset and invalidates the outcome from the prior research. Meanwhile, new data sets of spot instances are released on the web to help users build a reliable resource pool of spot instances (Bogu et al., 2017). The new datasets include the interruption ratio over the prior month dataset provided by Azure and AWS, and the instant availability information provided by AWS. The new datasets can be of great help for spot instance users as they provide the historical interruption ratio and instantaneous availability information. However, thorough investigation of the newly provided datasets has not been conducted yet, and quantitative evaluation about the correlation of the dataset and the spot instance interruption has not been carried out yet. Given that sudden spot instance interruption is a major hurdle when adopting a spot instance as a main compute resource pool, it is crucial to estimate the likelihood of a spot instance to be interrupted at least in the near future. However, predicting future spot instance interruptions or building a statistical model for interruption behavior can be very challenging from outside of cloud service vendors' view.

To quantitatively evaluate and model spot instance interruption events, one should know when the interruption events happen for diverse instance types that are located in global regions and availability zones. The service providers may have such records, but the information is not publicly available. For example, Yang et. al. (Yang et al., 2017) proposed a spot instance interruption prediction model for Azure spot instances by using the internal dataset of interruption records that are not publicly available, and it limits the development of publicly available research outcomes. To model spot instance interruption events without proprietary information, SciSpot (Zhu et al., 2017) and Pham et. al. (Pham et al., 2017) conducted real-world experiments to observe spot instance interruption events by simply running spot instances until an interruption happens for GCP and AWS, respectively. Even after gathering the interruption event experiment results, without knowing the internal mechanism of spot instance operations, it can be challenging to select features that really impact the interruption events. In case of AWS spot instances, the spot price was a good feature for the interruption prediction, but it is not valid anymore after the operation policy change (Zhu et al., 2017; Zhang et al., 2017).

Based on the observation that the prediction and modeling of spot instance interruption events is challenging even with the newly released spot instance datasets available on the web, we first analyze the characteristics of the spot price, prior period interruption ratio, and instant availability dataset that are provided by AWS, Azure, and GCP where applicable. To validate whether the public datasets reflect the real behaviors of spot instance interruptions and compare spot instance reliability of multiple vendors, we conducted spot instance interruption tests for AWS, Azure, and GCP. Based on the public dataset analysis and real-world spot instance interruption experiment result, we argue that precise prediction of instant spot instance availability dataset value can lower the probability of spot instance interruption and confirm the argument quantitatively. Overall, we conclude that spot instances offered by Azure showed the highest reliability followed by GCP and AWS. Though AWS showed the lowest reliability, we find out that the dataset provided by AWS is really helpful to conjecture spot instance reliability. By using a proposed dataset value predictor, the spot instance running time of AWS can increase by 63.2% for initially high score instances and by 168% for instances with initially low score.

In summary, major contributions of this paper is as follow.

* Comparing spot instance reliability of AWS, Azure, and GCP. To the authors' best knowledge, this is the first work to compare the spot instance reliability of multiple vendors.
* Thorough analysis of the new spot instance datasets including price, interruption ratio, and availability, to discover correlations with the spot instance interruptions
* Proposing a spot instance dataset value prediction model to enhance spot instance reliability
* Proposing a general guidance when using spot instances in a multi-cloud environment

Section 2 discusses publicly available spot instance dataset, and Section 3 analyzes various spot instance datasets provided by AWS, Azure, and GCP. Section 4 proposes a model to predict instant availability dataset and evaluates the model quality. Section 5 evaluates how the spot instance dataset distribution is correlated to real interruption behavior and presents the practicality of dataset value prediction to enhance spot instance reliability.

## 2. Cloud Spot Instance and Datasets

When using spot instances, the cost saving ratio over the on-demand instance and the reliability of a spot instance are the most important metric for most users. To help users estimate the benefit and risks when using spot instances, the cloud vendors provide various datasets; the spot instance price dataset from the beginning and the more recent interruption ratio and instant availability information dataset.

### Depreciation of Price Dataset

Since the introduction of the spot instance service in 2009, the spot price dataset is publicly available in the web and triggered many research from various perspectives. Statistical analysis of the spot instance price dataset was performed in a comprehensive way (Bauer et al., 2015; Li et al., 2016; Li et al., 2016; Li et al., 2016; Li et al., 2016; Li et al., 2016; Li et al., 2016; Li et al., 2016; Li et al., 2016). Other works focused on proposing an optimal bidding price to reduce the risk of instance interruption (Li et al., 2016; Li et al., 2016; Li et al., 2016; Li et al., 2016; Li et al., 2016; Li et al., 2016; Li et al., 2016). Another type of work focused on running various applications on spot instances reliably using spot instance price datasets, such as web server (Li et al., 2016), big data processing (Li et al., 2016), deep learning training (Li et al., 2016; Li et al., 2016) and inference (Li et al., 2016), batch processing (Li et al., 2016; Li et al., 2016), and scientific high-performance computing applications (Li et al., 2016). Other works are carried out using a dataset from other vendors, Azure (Yang et al., 2017; Li et al., 2016), GCP (Li et al., 2016; Li et al., 2016), and Alibaba cloud (Li et al., 2016).

One of the reasons that many research was conducted using AWS spot instance and its price dataset is owing to its dynamically changing price patterns, which reflect the spot instance interruption events very well. By comparing the advertised spot price and bidding price, a user can easily conjecture the interruption possibility. However, modeling spot instance interruption using a price dataset becomes impossible since the spot instance operation policy change (Zhu et al., 2017; Zhang et al., 2017). With the new change, the spot price does not change as often as before. More importantly, the spot price does not indicate an instance interruption; though the advertised spot price is lower than a bidding price, an interruption can still happen. The operation policy change makes the AWS spot instances similar to other vendors' spot instances which implies the spot price rarely changes, and it makes most of the previous research that relied on the spot price datasets becomes useless.

### Appreciation of Availability Dataset

As the usefulness of spot price dataset decreases from the perspective of inferring spot instance reliability, the service vendors started to provide new types of datasets related to instance availability. AWS and Azure provide the ratio of interruption of an instance in the prior time frame, e.g., 30 days. The dataset classifies interruption ratios to five categories, less than 5%, between 5% and 10%, between 10% and 15%, between 15% and 20%, and more than 20%. By using the dataset of previous interruption rate, users are expected to infer spot instance's future reliability.

Different from the interruption ratio dataset which simply provides the statistics from the previous period, AWS provides a new data set called Spot Placement Score (SPS). The vendor did not disclose the internal detail of how the score is calculated, but it is known to present a timely spot instance's availability. In the SPS, a type of spot instance is assigned an integer score ranging from one to three; the higher score implies more availability.

## 3. Spot Instance Dataset Characterization

To better understand characteristics of different spot instance datasets, we present empirical analysis result of publicly available spot instance datasets which can be accessed from the web. We could access the spot price dataset of AWS, Azure, and GCP. For the spot instance interruption ratio dataset, we get datasets from AWS and Azure. For instant availability information, we get the AWS SPS dataset. In the analysis, datasets from 1 November 2022 to 31 August 2023 were used.

Figure 1 shows the Cumulative Distribution Function (CDF) of spot instance dataset. Figure 1(a) compares the savings ratio, which is calculated as \((1.0-\frac{SpotPrice}{On-demandPrice})\times 100\), of AWS, Azure, and GCP. Figure 1(b) compare the the prior period's instance interruption ratio of AWS and Azure. Both vendors provide the dataset with values in the range of five categories, and we match each category to a numeric value between 1.0 and 3.0 increments by 0.5. The most frequent interruption ratio of more than 20% is matched to 1.0, and the least value of less than 5% is matched to 3.0. We name the converted value as _interrupt-free score_. Figure 1(c) presents the distribution of the instant availability dataset provided by AWS. We use the SPS dataset with the provided score range. To distinguish vendors, we use yellow-solid, blue-dotted, and green-dashed lines to indicate AWS, Azure, and GCP, respectively. In the figures, the vertical axis shows the distribution, and the horizontal axis shows the score. For all three sub-figures, the large score means the better and more reliable status.

In the figures, it is apparent that AWS has the least cost savings (Figure 1(a)) and a higher spot instance interruption ratio (Figure 1(b)). The GCP provides only the price dataset, and it shows higher median cost savings ratio than AWS. Regarding the interrupt-free score, the median score of AWS is around at 2.5 which means the interruption ratio between 5% and 10%, while that of Azure is around at 3.0, which is less than 5%. Only AWS provides the instant availability information, and we can observe that most of spot instances have been allocated near 3.0 point which is the best score.

Figure 2 shows the temporal change pattern of three spot datasets averaged for all gathered instance types in each sub-figure. Figure 1(a) compare the spot instance savings ratio, and we can observe that regardless of the vendors, savings value rarely changes over time.

Figure 1. Spot instance dataset value distribution from multiple vendors

Figure 2. Spot datasets that have been changed during the observation period

The low frequency of price change of AWS spot instance concurs to the prior work that analyzed the recent AWS spot instance behavior change (Bahdanau et al., 2017; Zhang et al., 2018). Figure 2b presents the temporal change pattern of interrupt-free score. Similar to cost savings, both AWS and Azure do not show noticeable change over time. Figure 2c presents the temporal change pattern of AWS SPS dataset. Different from the cost savings and interruption dataset, the SPS dataset shows a sinusoidal periodic pattern for different days. From the analysis, we can uncover the unique and noticeable change pattern of SPS that intrigues further research and analysis. Please note that the range of vertical axis is different for distinct dataset. We closely observed the pattern of savings and interruption-free score in a small scale but could not find a pattern similar to SPS.

To further analyze the pattern of SPS value change, Figure 3a shows SPS values averaged over an hour of a day. In the analysis, we used globally located resources in multiple regions and used the local time zone of each availability zone. From the figure, we can discover that the SPS is lower in the morning around at 9, 10, and 11. Then, the SPS gradually increases and reaches its maximum at night which is the time that cloud usage is expected to be low. To see if the SPS value change has a weekly pattern, Figure 3b presents the average SPS value by day which is shown in the horizontal axis. We can observe that the SPS value is higher on weekends and lower on week days. Please note that we analyzed the spot price and interruption ratio similarly, but we could not observe a noticeable pattern.

We could observe more frequent and periodic data update pattern of AWS SPS dataset. To further analyze how often spot instance dataset changes, Figure 4 shows the CDF of data change frequency. The vertical axis shows the distribution, and the horizontal axis shows how long a value remains unchanged. The larger value, which is located at the right side of the figure, implies that a value does not change for a longer period of time. In the figure, the distribution of all the datasets are presented. Among them, AWS SPS with a yellow solid line with triangle markers shows the most frequent update compared to other dataset. For cost savings dataset, we assume that a cost saving value has changed when the ratio has increased or decreased more than 3%.

From the various spot instance dataset analysis, we could uncover that spot instances from **Azure and GCP show relatively higher cost savings than AWS**. The **interruption ratio of AWS is higher than that of Azure**. Only the **AWS SPS dataset shows a pattern of daily and hourly change**. The values of **AWS SPS changed frequently**, and the change frequency of other datasets are longer than a day.

## 4. Predicting Spot Instance Dataset Change

When using spot instances, the prediction of future interruption events and probability estimation can be of great help to improve reliability. To achieve the goal, it is important to discover appropriate features that correlate with the interruption events. The analysis of the spot instance dataset reveals that the price and interruption ratio information has little change over time, while the instant availability information of AWS SPS changes often and regularly. Considering the recent research outcomes about spot instance price (Bahdanau et al., 2017; Zhang et al., 2018; Zhang et al., 2018), the spot price information has little correlation with the spot instance interruption. The spot instance interruption ratio presents the prior 30 days of interruption statistics, and it can be far from predicting the future availability. In this context, we propose a model to predict the instant availability dataset expecting that the precise prediction can help to improve spot instance reliability, which will be evaluated later.

### Modeling Instant Availability Dataset

The instant availability dataset prediction model uses the prior period's SPS as input features and predict future SPS values. Formally speaking, the input dataset and features of \(\mathbf{X}\) are composed of \(N\) distinct instance types in different availability zones, which is the unit of the distinct SPS being provided, and \(D\) features which represent an SPS value at different timestamp. Assuming that data collection of SPS dataset occurs with a period of \(p\) minutes, we can use the previous \(D\) collected dataset for training, which means that we use

Figure 4. The CDF of value change frequency. The SPS dataset provided AWS shows the most frequent data update

Figure 3. The change pattern of instant availability dataset shows a strong hourly and daily change pattern

datasets collected in the last \(D\times p\) minutes. Similarly, the target dataset to predict is noted as \(Y\) that has \(N\) distinct instance types and next \(K\) SPS values to predict. \(x_{id}\), where \(i=1:N,d=1:D\), means the \(i\)-th instance type and \(d\)-th index SPS value, and \(y_{ik}\), \(i=1:N,k=1:K\), means the \(i\)-th instance type and \(k\)-th index SPS. The train dataset is defined as follow.

\[\mathcal{D}\triangleq\{(x_{id}\to y_{ik})|(x_{id},y_{ik})\in\{1,2,3\}\} \tag{1}\]

Each value of \(x_{id}\) and \(y_{ik}\) takes one of \(\{1,2,3\}\) that is a possible SPS value. In defining training dataset, we need to decide how many previous measured datasets to use, which is \(D\), and how many future dataset to predict, which is \(K\). Our thorough empirical analysis reveals that the selection of \(D\) and \(K\) do not have much impact to the overall prediction accuracy (Figure 5).

### Accuracy of Availability Dataset Predictor

Using the train dataset, \(\mathcal{D}\), in equation 1, we apply diverse classification models of Linear Regressor (LR) (Zhu et al., 2017), Random Forest (RF) classifier (Zhu et al., 2017), XGBoost (Chen and Guestrin, 2016), Support Vector Classifier (SVC) (Chen and Guestrin, 2016), Prophet (Zhu et al., 2017), and ARIMA (Chen and Guestrin, 2016). Table 1 compares the F1 score for different prediction models to evaluate both precision and recall (Zhu et al., 2017). In the train, we used the SPS dataset from 16 July 2023 to 31 July 2023. For testing, we used the dataset from 1 August 2023 to 6 August 2023 which is exclusive to train dataset period. We divide the test dataset in half and used the prior half period as the model's input. Of the later half dataset, we variate the prediction period, \(k\), to the next \(3,6,12,24,48,72\) hours, and they are shown in the columns.

We can discover that most models show decent prediction quality. Among them, the XGBoost shows the best result, and we use them in the following descriptions.

Figure 5 shows the heatmap of F1-score of a SPS prediction model built by using XGBoost with respect to different input time window (the horizontal axis) and the different output time window (the vertical axis) presented in hours. In the figure, lighter region implies higher F1-score. As we can see from the figure, regardless of the input and output time window, the F1-score shows consistently high scores except when predicting further future (72\(H\)) using only recent values (3\(H\)).

Figure 6 presents the feature importance which is extracted from a built XGBoost model. The vertical axis shows the importance of each feature, and the horizontal axis shows the index of time-series feature. The lower index number implies more recent dataset. As shown in the figure, recent values dominate the feature importance, where till 24 hours takes 79% of total importance.

## 5. Evaluation

This section evaluates the effectiveness of a heuristic to improve the reliability of the spot instance through a detailed analysis of spot instance interruption events. More specifically, we would like to answer the following research questions.

**RQ-1** For spot instances offered by major public vendors, which vendor provides the most reliability with respect to the interruption?

**RQ-2** Of many spot instance datasets, which dataset is most correlated with spot instance interruption?

**RQ-3** Can the prediction of SPS value lower the chance of spot instance interruption?

### Spot Instance Interrupt Analysis

We first compare the interruption behaviors of multiple cloud vendors (**RQ-1**). To examine interruption events, we conducted real-world experiments by running a spot instance until an interruption event happens. We choose 875 distinct instance types in AWS, Azure, and GCP located globally. When choosing arbitrary instance types, we try to distribute evenly for different values in the cost savings, interruption ratio, and instant availability datasets. The

\begin{table}
\begin{tabular}{c c c c c c c} \hline \hline  & 3H & 6H & 12H & 24H & 48H & 72H \\ \hline LR & 0.96 & 0.97 & 0.98 & 0.97 & 0.97 & 0.96 \\ RF & 0.96 & 0.98 & 0.98 & 0.98 & 0.97 & 0.97 \\ XGboost & 0.97 & 0.99 & 0.98 & 0.98 & 0.97 & 0.97 \\ SVC & 0.96 & 0.97 & 0.97 & 0.98 & 0.96 & 0.96 \\ Prophet & 0.96 & 0.96 & 0.97 & 0.98 & 0.97 & 0.97 \\ ARIMA & 0.95 & 0.95 & 0.97 & 0.97 & 0.96 & 0.96 \\ \hline \hline \end{tabular}
\end{table}
Table 1. F1-score of various models for SPS prediction

Figure 5. Heatmap of F1-score for XGBoost for modeling with respect to different input and prediction output time window

Figure 6. The importance of features when building a SPS prediction model

experiments had been conducted for 24 hours for each instance types. When an interruption event happens, we mark the event and keep requesting the spot instance until it fulfills again.

To quantitatively compare the survival rate of the spot instances, the probability that a spot instance remains running, we applied the Kaplan-Meier Estimator [25] which is a non-parametric statistic to estimate the survival rate of a lifetime dataset. It is generally used in the hospital environment to measure the fraction of people who live after treatment or the length of time people remain unemployed after losing a job [33]. Based on the general usage of the statistic, applying it to model spot instance survival probability is well suited. Kaplan-Meier Estimator is calculated as follows.

\[\widehat{S}(t)=\prod_{i:\ t\leq t}\left(\frac{n_{i}-d_{i}}{n_{i}}\right)\]

The survivor function (\(\widehat{S}(t)\)) at time \(t\) is defined as the probability a life time (spot instance running time) is longer than \(t\). \(n_{i}\) is the number of survived individuals (running spot instances) until time \(t_{i}\), and \(d_{i}\) means the number of deaths (spot instance interruption) at time \(t_{i}\).

Figure 7 compares \(\widehat{S}(t)\) of AWS, GCP, and Azure. In the figure, the horizontal axis shows the spot instance running time (survival time), and the vertical axis shows the distribution. The yellow-solid, green-dashed, and blue-dotted lines present the distribution of AWS, GCP, and Azure respectively. From the figure, it is evident that the AWS shows the lowest survival rate followed by GCP and Azure. The median running time of AWS spot instance is 1.2 hours, and over the half of GCP and Azure instance did not experience interruption during the 24 hour experiments. The shortest \(P90\) running time of AWS, GCP, and Azure is 0.02, 0.5, and 5 hours, respectively.

Next, we assess the correlation of various spot instance datasets and the interruption events (**RQ-2**). Figure 8 compares Kaplan-Meier estimator distribution of AWS experiment result grouped by different spot instance dataset. Figure 7(a) compares survival time distribution with respect to different interrupt-free score, and Figure 7(b) compares with respect to SPS scores. For both datasets, the higher score implies the higher availability. The scores of _Low_ (1.0), _Medium_ (2.0), and _High_ (3.0) are presented with solid, dashed, and dotted lines, respectively. From both figures, we can observe that higher score values shows higher survival rate than lower score values. We omit the figures of savings for AWS, Azure, GCP, and interrupt-free score for Azure because they do not show a noticeable pattern as AWS interrupt-free score and SPS do.

So far, we have analyzed the spot instance survival time. Next, we will analyze using a different metric. Figure 9 compares the elapsed time between a spot instance interruption start and the node becomes fulfilled again. The shorter time implies that a spot instance is becomes available again shortly after an interruption happens which means a higher availability. Sub-figures group instances according to the spot instance dataset. In each figure, the yellow-solid, blue-dotted, and green-dashed lines indicate the result from AWS, Azure, and GCP, respectively. In each line, we mark a symbol of \(\triangle\) for _High_ and \(\triangledown\) for _Low_ value after categorization.

The cost savings ratio dataset (Figure 8(a)) does not show a noticeable difference among _High_ and _Low_ values for all AWS, Azure, and GCP. GCP and Azure show a similar latency distribution, while that

Figure 8: Kaplan-Meier Estimator to compare the probability of spot instance survival rate with respect to different spot instance datasets

Figure 7: Kaplan-Meier Estimator analysis to infer the probability of spot instance survival rate. Azure shows the best reliability followed by GCP and AWS.

of AWS shows much less availability than the others. Regarding the interrupt-free score (Figure 8(b)), Azure did not show a different pattern between _High_ and _Low_ values, but AWS shows a distinct pattern that follows the advertised score. The high interrupt-free score of AWS spot instances show faster fulfillment time after an interruption. The instant availability data (Figure 8(c)) shows a noticeable difference between _High_ and _Low_ that the higher SPS value shows much lower latency for a fulfillment after an interruption (higher availability), and it follows the advertised score characteristic very well.

### Effectiveness of Instant Availability Dataset Prediction

We have discovered that the spot instance instant availability dataset provided by AWS SPS dataset is beneficial to model spot instance interruption events and availability. To go one step further and answer **RQ-3** of whether predicting future SPS value can help to increase to predict chances of spot instance interruption, we compare the distribution of spot instance interruption with different values of SPS prediction in Figure 10. The vertical axis shows distribution, and the horizontal axis presents the spot instance running (survival) time. Figure 9(a) presents the life time of spot instances whose SPS value is high (3.0) when a spot instance request is made. The SPS value can change over the course of experiment, and we categorize the predicted SPS values in a bin size of 0.5. The dotted line shows when the average predicted SPS value is 3.0, which means SPS value is expected to remain constant at the high value. A dashed-dotted line indicates when the expected SPS average is higher than 2.5 but lower than 3.0. The other lines are expressed in a similar way. From the figure, we can discover that despite the same initial high SPS value of 3.0, ignorant of future SPS value can significantly hurt the reliability of a spot instance. For instance, the median spot instance survival time when the predicted SPS is high is 22 hours, but that of lower predicted SPS value is 16 hours.

Figure 9(b) shows the survival time of spot instances whose initial SPS value is low, 1.0. Similarly, the SPS can value can fluctuate, and we show the running time by grouping instances by the predicted SPS values. The solid line presents when the SPS value is expected to keep staying low at 1.0, and it shows very short running time. Otherwise, even if the initial SPS value is low, instances with a higher expected SPS values show higher survival time. For instance, the median running time of spot instance whose SPS is expected to be consistently at 1.0 is 0 hours, while that of SPS being expected to be between 2.0 and 2.5 turns out to be about 8 hours. This finding is especially helpful when a user has a limited list of spot instance types, and their initial SPS is low. In that case, the prediction of SPS can greatly improve the reliability of the spot instance, though its current SPS is low.

In summary, we can answer research questions raised before as follow.

**RQ-1** For spot instances offered by major public vendors, which vendor provides the most reliability with respect to the interruption? **Answer** : The spot instance of Azure showed the most reliability followed by GCP and AWS.

**RQ-2** Of many spot instance datasets, which dataset is most correlated with spot instance interruption? **Answer** : AWS SPS dataset shows the highest correlations with the spot instance interruption. The cost savings and interrupt-free score do not show as high correlation as AWS SPS does.

**RQ-3** Can the prediction of SPS value lower the chance of spot instance interruption? **Answer** : Yes, the prediction of SPS dataset can definitely help to increase the spot instance reliability. When the initial SPS value is high, selecting an instance whose predicted value is consistently high can increase the expected spot instance running time by 63.2%. Even when the initial SPS value is low, selecting spot instances with higher expected SPS value can increase the expected spot instance running time by 168%.

Overall, the spot instance datasets offered by Azure and GCP are not really useful when choosing appropriate instance types. However, the spot instance reliability of Azure and GCP is relatively high, and users may experience lower interruption regardless of instance selection. The spot instance offered by AWS shows the most interruptions. However, the spot instance datasets provided by AWS reflects the spot instance interruptions very well. Thus, different from Azure and GCP, when using a spot instance from AWS, users should be more cautious to choose appropriate instance type for reliable execution.

## 6. Related Work

**Characterizing Spot Instance Dataset** : **Modeling and Using Spot Instance Dataset** : From the inception of the spot instance,

Figure 9. A CDF of latency until a request becomes fulfilled for AWS, Azure, and GCP spot instances categorized by different dataset values of High (\(\triangle\)) and Low (\(\triangledown\)). The lower latency implies the higher availability.

the spot price dataset is widely used and analyzed to enhance reliability of spot instances. There were attempts to characterize the price dataset of the spot instance and relate the analysis to the spot instance interruption to decrease chances of interruption (Song et al., 2016; Wang et al., 2016; Wang et al., 2016; Wang et al., 2016; Wang et al., 2016; Wang et al., 2016; Wang et al., 2016; Wang et al., 2016). Using the spot price and analysis result, Ali-Eldin et. al. proposed to deploy a web-server (Bowman et al., 2016), Son et. al. proposed DeepSpotCloud (Song et al., 2016) for DNN training tasks using GPU spot instances located globally. SeeSpotRun (Wang et al., 2016) for Hadoop (Hadoop, 2016) MapReduce (Hadoop, 2016), Flint (Fint et al., 2016) and Tr-Spark (Song et al., 2016) for Apache Spark (Song et al., 2016) are proposed for big-data processing. Online web services (Bowman et al., 2016; Wang et al., 2016), batch processing jobs (Wang et al., 2016; Wang et al., 2016), and parallel processing of independent tasks (Song et al., 2016) while mitigating straggler effect due to transient servers (Bowman et al., 2016) are proposed. The aforementioned work relied on spot price dataset and the work becomes obsolete due to the spot instance operation change (Bowman et al., 2016; Wang et al., 2016). The findings in this paper provide a new opportunity of enhanced spot instance reliability through instant availability dataset prediction without relying on spot price dataset. By selecting spot instances that are likely to be more available in the future by using the dataset prediction module, the application of spot instance can be further expanded.

**Spot Instance Price Prediction** : We showed that predicting the spot instance instant availability dataset is predictable using a machine learning classifier model with decent performance. Before this work, there are attempts to predict spot price value to predict future cost savings and interruption events. Khandelwal et. al (Khandelwal et al., 2016) used the Random Forest, Fabra et. al (Fabra et al., 2016) used a deep neural net model, and Alkhairif et. al (Alkhairif et al., 2016) used various time-series analysis statistical methods for price prediction. Due to the spot price operation policy change (Bowman et al., 2016; Wang et al., 2016), the previous work becomes obsolete, and new approaches, as this paper does, should be provided.

**Analyzing Spot Instance Interruption** : Compared to the analysis of the spot price dataset, the analysis and experiments of spot instance interruption and correlating it with the spot instance dataset were not conducted much. Pham et. al. (Pham et al., 2016) and Lee et. al. (Yang et al., 2016) conducted spot instance interruption experiments for only AWS instances to analyze the interruption pattern. For Azure, Yang et. al. (Yang et al., 2016) proposed a spot instance interruption prediction model based on a Transformer model by using internally available interruption trace of Azure. For GCP, Haugerud et. al. (Haugerud et al., 2016) and Kadupitiya et. al. (Kadupitiya et al., 2016) conducted interruption tests to model the behavior. To the best of the authors' knowledge, this paper is the first work to conduct spot instance interruption experiments for three major vendors of AWS, Azure, and GCP. Comparing the spot instance behavior can greatly help users to choose the most appropriate spot instances in a multi-cloud environment that is deemed to be widely adopted (Hadoop, 2016; Wang et al., 2016; Wang et al., 2016).

## 7. Conclusion

Cloud spot instances provide significant cost savings when using cloud resources with the risk of sudden instance termination. To help users better utilize spot instance, public service vendors provide diverse spot instance datasets, such as price, interruption ratio in the past period, and the instant availability information. Despite the diverse publicly available information, they are neither widely used nor analyzed except the spot price dataset which is really irrelevant to the spot instance interruption and reliability. To handle this issue, this paper thoroughly analyzes characteristics of various spot instance datasets and proposes a model to predict instant availability dataset to enhance reliability. To uncover the relationship of publicly available dataset and the spot instance interruption behavior, we conducted real-world experiments for the spot instance interruptions in the AWS, Azure, and GCP cloud. We discovered that the Azure spot instance shows the highest reliability, followed by GCP and AWS. Though AWS showed the worst reliability, we discovered that the instant availability dataset offered by AWS can be helpful to predict interruption events in the near future which was not possible by using datasets offered by Azure and GCP. Finally, by using the proposed instant availability score prediction, we showed that the median spot instance running time can improve by 63.2% for initially high score instances and by 168% for initially low score spot instances. We believe that our study will enable users to utilize cloud resources more efficiently, ensuring reduced costs and increased reliability, thereby optimizing their overall system performance.

Figure 10. Distribution of spot instance availability when using only the current SPS value and predicted values

## References

* O. Agmon Ben-Yehuda, M. Ben-Yehuda, A. S. Shattere, and D. Tastfir (2013)Desonstructing Amazon EC2 spot Instance pricing. ACM Trans. on Comput.1 (), pp. 3. Article 16 (sep 2013), pp. 20 pages. External Links: ISSN 0001-0708, Document, Link Cited by: SS1, SS2.1.
* A. Ali-Eldin, J. Westin, B. Wang, P. Sharma, and P. Shenoy (2019)SpotWeb: running latency-sensitive distributed web services on transient cloud servers. In Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing, H. A., USA, pp. 1-12. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* S. Alkhurif, K. Lee, and H. Kim (2018)Time-series analysis for price prediction of opportunistic cloud computing resources. In Proceedings of the 7th International Conference on Emerging Databases, W. Lee, W. Choi, S. Jung, and M. Song (Eds.), pp. 221-229. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* P. Ambati, D. Irwin, P. Shenoy, L. Gao, A. Ali-Eldin, and J. Albrecht (2019)Understanding synchronization costs for distributed ml on transient cloud resources. In 2019 IEEE International Conference on Cloud Engineering (IC2), pp. 145-155. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* M. Awad and R. Khanna (2015)Efficient learning machines., pp. 1-430. External Links: ISSN 0001-0708, Document, Link Cited by: SS1, SS2.1.
* M. Baughman, S. Caton, C. Haas, B. Chard, R. Wolski, I. Foster, and K. Chard (2019)Deconstructing the 2017 changes to aw spot market pricing. In Proceedings of the 10th Workshop on Scientific Cloud Computing, H. A., USA, pp.. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* B. Li (2014)Bind. In A., J. H., S. G. Reissel, and G. M. Ljung (Eds.), External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* E. B. Fox, G. M. Jenkins, G. C. Reissel, and G. M. Ljung (2015)Time series analysis: forecasting and control., pp. 5-32. External Links: ISSN 0001-0708, Document, Link Cited by: SS1, SS2.1.
* S. Chasins, A. Cheung, N. Crooks, A. Goldsch, K. Goldberg, J. E. Gonzalez, J. M. L. Jordan, A. D. Joseph, M. Maloney, et al. (2022)The sky above the clouds. arXiv preprint arXiv:2202.07147. Cited by: SS1, SS2.1.
* T. Chen and C. Guestrin (2016)XGBoost: a scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, S. Francisco, C.M., USA, pp. 785-794. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* N. Chohan, C. Castillo, M. Spitzner, M. Staehner, A. Tantawi, and C. Karritz (2010)See spot rban: spot instance for mapreduce workflows. In 2nd USENIX Workshop on Hot Topics in Cloud Computing, H. O., USA, pp. 101-105. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* J. Dean and S. Ghemawat (2004)MapReduce: simplified data processing on large clusters. In Proceedings of the 1st Conference on Symposium on Operating Systems & Implementation, A. V. (Ed.), pp.. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* N. Elkew-Elkew and A. Barker (2018)Location, location: exploring Amazon EC2 spot Instance pricing across geographical regions. In 2018 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, H. S. J. Jonas (Ed.), pp. 370-373. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* S. Elsayed, D. Tidyesses, A. Rashed, L. Schmidt-Thieme, and H. Samer Jomasa (2021)Do we really need deep learning models for time series forecasting?. CoRRabs/2101.02118. External Links: Link, 2101.02118 Cited by: SS1, SS2.1.
* J. Fabra, J. Epeleta, and P. Alvarez (2019)Reducing the price of resource provisioning using gc2 copt instances with prediction models. Future Generation Computer Systems96, pp. 348-367. External Links: ISSN 0016-1677, Document, Link Cited by: SS1, SS2.1.
* Apache Software Foundation (2004)Apache Hadoop. Note: [http://hadoop.apache.org/](http://hadoop.apache.org/) Cited by: SS1, SS2.1.
* W. Guo, K. Chen, Y. Wu, and W. Zheng (2015)Bidding for highly available services with low price in spot instance market. In Proceedings of the 20th International Symposium on High-Performance Parallel and Distributed Computing, O. Orega, USA, pp.. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* H. Haugural, J. Kruger, S. Svensson, and A. Sarvelli (2020)Autonomous provisioning of preemptive instances in Google Cloud for maximum performance per dollar. In 2020 5th International Conference on Cloud Computing, H. Larochelle, T. Dehriggos, and A. M. Lillo (Eds.), pp. 1-8. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* X. He, P. Shenoy, R. Sitaraman, and D. Irwin (2015)Cutting the cost of hosting online services using cloud spot markets. In Proceedings of the 24th International Symposium on High-Performance Parallel and Distributed Computing, O., USA, pp.. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* X. He, P. Shenoy, R. Sitaraman, and D. Irwin (2015)Cutting the cost of hosting online services using cloud spot markets. In Proceedings of the 24th International Symposium on High-Performance Parallel and Distributed Computing, H. A., USA, pp.. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* Y. Huang, S. Ristow, and T. Farhmer (2018)Performance and behavior characterization of Amazon EC2 spot instances. In 2018 IEEE 11th International Conference on Cloud Computing, H. A., USA, pp. 73-81. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* Y. Huang, S. Ristow, and T. Farhmer (2018)Performance and behavior characterization of Amazon EC2 spot instances. In 2018 IEEE 11th International Conference on Cloud Computing, H. A., USA, pp. 73-81. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* S. R. Huang, S. Ristow, and T. Farhmer (2018)Performance and behavior characterization of Amazon EC2 spot instances. In 2018 IEEE 11th International Conference on Cloud Computing, H. A., USA, pp. 73-81. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* S. R. Huang, S. Ristow, and T. Farhmer (2018)Performance and behavior characterization of Amazon EC2 spot instances. In 2018 IEEE 11th International Conference on Cloud Computing, H. A., USA, pp. 445-451. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* S. R. Huang, S. Ristow, and T. Farhmer (2018)Performance and behavior characterization of Amazon EC2 spot instances. In 2018 IEEE 11th International Conference on Cloud Computing, H. A., USA, pp. 73-81. External Links: ISBN 978-1-4503-219-1, Document, Link Cited by: SS1, SS2.1.
* S. R. Huang, S. Ristow, and T.

e4451 cpe.4451.
* [39] D. M. W. Powers. 2011. Evaluation: From precision, recall and f-measure to r.c., informedness, markedness & correlation. _Journal of Machine Learning Technologies_ 2, 1 (2011), 37-63.
* [40] A. Sarah, K. Lee, and H. Kim. 2018. LSTM Model to Forecast Time Series for E2C Cloud Price. In _2018 IEEE 16th Intl Conf on Dependable, Autonomic and Counter Computing, 16th Intl Conf on Pervasive Intelligence and Computing, 4th Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DAC/ProcCom)(DataCom)(CyberSecTech)_. 1085-1088. [https://doi.org/10.1109/DAC/S/ICom/DataCom/CyberSecTech.2018.00067](https://doi.org/10.1109/DAC/S/ICom/DataCom/CyberSecTech.2018.00067).
* [41] Prateek Sharma, Tian Guo, Xin He, David Irwin, and Prashant Shenoy. 2016. Flint: Batch-Interactive Data-Intensive Processing on Transient Servers. In _Proceedings of the Eleventh European Conference on Computer Systems_ (London, United Kingdom) (EuroSys '16). Association for Computing Machinery, New York, NY, USA, Article 15, pages. [https://doi.org/10.1145/209138.209139](https://doi.org/10.1145/209138.209139)
* [42] Prateek Sharma, David Irwin, and Prashant Shenoy. 2016. How Not to Bid the Cloud. In _8th USENIX Workshop on Hot Topics in Cloud Computing (HotCloud 16)_. USENIX Association, Denver, CO. 2016. [https://www.usenix.org/conference/hotcloud/workshop-program/presentation/sharma](https://www.usenix.org/conference/hotcloud/workshop-program/presentation/sharma).
* [43] Suprecht Subramanya, Tian Guo, Prateek Sharma, David Irwin, and Prashant Shenoy. 2015. SpotOn: A Batch Computing Service for the Spot Market. In _Proceedings of the Sixth ACM Symposium on Cloud Computing_ (Kohala Coast, Hawaii) (SoCC '15). Association for Computing Machinery, New York, NY, USA, 329-341. [https://doi.org/10.1145/280677.2806851](https://doi.org/10.1145/280677.2806851)
* [44] Shabie Tang, Jing Yuan, and Xiang-Yang Li. 2012. Towards Optimal Bidding Strategy for Amazon EC2 Cloud Spot Instance. In _2012 IEEE Fifth International Conference on Cloud Computing_, 91-98. [https://doi.org/10.1109/CLOUD.2012.134](https://doi.org/10.1109/CLOUD.2012.134)
* [45] Sean J. Taylor and Benjamin Letham. 2018. Forecasting at Scale. _The American Statistician_ 72, 1 (2018), 37-45. [https://doi.org/10.1080/00031305.2017.3380080](https://doi.org/10.1080/00031305.2017.3380080)
* [46] John Thorpe, Fengshan Zhao, Jonathan Foylson, Yifan Qiao, Zhihao Jia, Minjia Zhang, Ravi Netravali, and Guoqing Harry Xu. 2023. Ramboo: Making Pre-emptible Instances Resilient for Affordable Training of Large DNNs. In _20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)_. USENIX Association, Boston, MA, 497-513. [https://www.usenix.org/conference/nsdi23/presentation/thorpe](https://www.usenix.org/conference/nsdi23/presentation/thorpe)
* [47] Varshney and Y. Simmhan. 2019. AutoBoT: Resilient and Cost-Effective Scheduling of a Bag of Tasks on Spot VMs. _IEEE Transactions on Parallel & Distributed Systems_ 30, 07 (2019), 1512-1527. [https://doi.org/10.1109/TDS.2018.2889851](https://doi.org/10.1109/TDS.2018.2889851)
* [48] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, I. ukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In _Advances in Neural Information Processing Systems_, L. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.), Vol. 30. Curran Associates, Inc. [https://proceedings.neurips.cc/paper/2017/file/3f5ee24537de910610351c48a8aa-Paper.pdf](https://proceedings.neurips.cc/paper/2017/file/3f5ee24537de910610351c48a8aa-Paper.pdf)
* [49] Cheine Wang, Qianlin Liang, and Bhuvun Urgaonkar. 2017. An Empirical Analysis of Amazon EC2 Spot Instance Features Affecting Cost-Effective Resource Procurement. In _Proceedings of the 8th ACM/ESE '08 on International Conference on Performance Engineering_ (L'Aguila, Italy) (_ICPE '17). Association for Computing Machinery, New York, NY, USA, 63-74. [https://doi.org/10.1145/3080207.3030210](https://doi.org/10.1145/3080207.3030210)
* [50] Rich Wolski, John Brevik, Bryan Chard, and Kyle Chard. 2017. Probabilistic Guarantees of Execution Duration for Amazon Spot Instances. In _Proceedings of the International Conference on High Performance Computing, Networking, Storage and Analysis_ (Denver, Colorado) (SC '17). Association for Computing Machinery, New York, NY, USA, Article 18, 11 pages. [https://doi.org/10.1145/316908.3126953](https://doi.org/10.1145/316908.3126953)
* [51] Ying Yan, Yanjie Gao, Yang Chen, Zhongjun Guo, Bole Chen, and Thomas Moscibroda. 2016. Tg-spark: Transient Computing for Big Data Analytics. In _Proceedings of the Seventh ACM Symposium on Cloud Computing_ (Santa Clara, CA, USA) (SoCC '16). Association for Computing Machinery, New York, NY, USA, 484-496. [https://doi.org/10.1145/2897552.289756](https://doi.org/10.1145/2897552.289756)
* [52] Fangkai Yang, Bowen Pang, Jue Zhang, Bo Qiao, Lu Wang, Camille Couturier, Chetan Bansal, Soumya Rami, Si Qin Zhen Ma, Jiaqiu Goiri, Ell Corestin Setland Baladharubram, Victor Rible, Saravan Rajamohan, Qingwei Lin, and Dongmei Zhang. 2022. Spot Virtual Machine Eviction Prediction in Microsoft Cloud. In _Companion Proceedings of the Web Conference 2022_ (Virtual Event, Lyon, France) (WWW '22). Association for Computing Machinery, New York, NY, USA, 152-156. [https://doi.org/10.1145/3487553.3524229](https://doi.org/10.1145/3487553.3524229)
* [53] Fangkai Yang, Lu Wang, Zhenyu Xu, Jue Zhang, Liqin Li, Bo Qiao, Camille Couturier, Chetan Bansal, Soumya Rami, Si Qin Zhen Ma, Ingao Goiri, Ell Corestin, Yany, Victor Rible, Saravan Rajamohan, Qingwei Lin, and Dongmei Zhang. 2023. Snap: Reliable and Low-Cost Computing with Mixture of Spot and On-Demand VMs. In _Proceedings of the 18th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3_ (Vancouver, BC, Canada) (_ASPLOS 2023_). Association for Computing Machinery, New York, NY, USA, 631-643. [https://doi.org/10.1145/35802106.3582028](https://doi.org/10.1145/35802106.3582028)
* [54] Zongheng Yang, Zhangbao Wu, Michael Luo, Wei-Lin Chiang, Romil Bhardwaj, Woosuk Kwon, Siyuan Zhuang, Frank Sifei Luan, Gautam Mittal, Scott Shenker, and Ion Stoica. 2023. SkyPilot: An Intercloud Broker for Sky Computing. In _20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)_. USENIX Association, Boston, MA, 437-455. [https://www.usenix.org/conference/nsdi23/presentation/yang-song-song](https://www.usenix.org/conference/nsdi23/presentation/yang-song-song)
* [55] Murtzan Zafer, Yang Song, and Kang-Won Lee. 2012. Optimal Bids for Spot VMs in a Cloud for Deadline Constrained Jobs. In _2012 IEEE Fifth International Conference on Cloud Computing_. 75-82. [https://doi.org/10.1109/ICOD.2012.59](https://doi.org/10.1109/ICOD.2012.59)
* [56] Matei Zaharia, Mosharul Chowdhury, Tathagata Das, Ankur Dave, Justin Ma, Murphy McCaulvi, Michael J Franklin, Scott Shaffer, and Ion Stoica. 2012. Resilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing. In _Presented as part of the 9th USENIX Symposium on Networked Systems Design and Implementation (NSDI 21)_. USENIX, San Jose, CA, 15-28.
* [57] Chengliang Zhang, Minchen Yu, Wei Wang, and Feng Yan. 2022. Enabling Cost-Effective, SLO-Aware Machine Learning Inference Serving on Public Cloud. _IEEE Transactions on Cloud Computing_ 10, 3 (2022), 1765-1779. [https://doi.org/10.1109/TCC.2020.3006751](https://doi.org/10.1109/TCC.2020.3006751)
* [58] Liang Zheng, Carlee Joe-Wong, Chee Wei Tan, Ming Chiang, and Xinyu Wang. 2015. How to Bid the Cloud. In _Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication_ (London, United Kingdom) (_SIGCOMM '15). Association for Computing Machinery, New York, NY, USA, 71-84. [https://doi.org/10.1145/2789556.2787473](https://doi.org/10.1145/2789556.2787473)
* [59] Amelle Chi Zhou, Jianmin Luo, Zhoubin Ke, Yi Wang, and Rui Mao. 2022. FarSpot: Optimizing Monetary Cost for HPC Applications in the Cloud Spot Market. _IEEE Transactions on Parallel and Distributed Systems_ 33, 11 (2022), 2955-2967. [https://doi.org/10.1109/TPDS.2021.3134644](https://doi.org/10.1109/TPDS.2021.3134644)Further analysis of spot instance datasets

The spot instance instant availability dataset, AWS SPS, provides quite significant insights about the service operation. To further analyze characteristics of the dataset, Figure 11 shows SPS value distribution grouped by different criteria. In the sub-figures, the horizontal axis shows the SPS value, and the vertical axis presents the distribution. Figure (a)a presents the SPS value distribution with respect to the number of CPU cores. The number of cores are grouped into ones with more than 128 cores (solid line with triangle marker) while decreasing the core numbers in half. From the figure, it is evident that the SPS score is inversely proportional to the number of CPU cores. For instance, the median SPS of when there are more than 128 cores is 1.9, while that of one or two CPU cores is 3.0. This results concurs with the spot instance interrupt analysis experiments conducted for GCP ones (Zhou et al., 2017; Zhou et al., 2018).

Figure (b)b groups instance by the suggested category by vendors. We can observe that most categories show a similar pattern except ones in the accelerated computing which is presented with a solid line with round markers. It is understandable situation that recent popularity of deep neural net, which requires significant computing power in the accelerated computing category, caused such lack of idle resource, which is also presented by Lee et. al. (Lee et al., 2018).

## Appendix B Further analysis of SPS prediction model

We demonstrated that AWS SPS dataset is predictable with decent accuracy and recall. In the SPS prediction, we applied multiple models and present the overhead of training and inference in Table 2. When measuring the time, we used SPS dataset gathered between July 24th. and July 31st. 2023. For inference, we used dataset from August 1st. to August. 3rd. In the time measurement, we used a dataset from a single instance type for comparison. We can observe quite difference in training time due to the model's complexity, especially Transformer (Vaswani et al., 2017). We tried various Transformer optimization heuristics. However, considering the huge training overhead and lower prediction quality, it does not seem to be an appropriate approach to deal with time-series dataset, which coincides with the result presented by Elsayed et. al. (Elsayed et al., 2017). The Prophet shows a very short training time with slightly lower prediction quality comparing to XGBoost as presented in Table 1. The train time difference is owing to the fact that XGBoost and other machine learning classifiers build separate models for each different output, which is 432. Meanwhile, Prophet builds a single model based on statistics of train dataset, and the train time did not get impacts from the output time window size. Considering the train and inference can happen off-line, we select XGBoost for the evaluation which shows better prediction quality.

## Appendix C Further analysis of the spot instance availability experiments

Figure 12 presents a distribution of spot instance running time after fulfillment categorized by different dataset. The vertical axis shows the distribution, and the horizontal axis shows a running time without interruption in log-scale. The larger x-axis value (to the right-side) implies more availability. Different sub-figures groups instances to different criteria; cost savings ratio (Figure (a)a), interrupt-free score (Figure (b)b), and instant availability (SPS) score (Figure (c)c). In each figure, the yellow-solid, blue-dotted, and green-dashed lines indicate the result from AWS, Azure, and GCP, respectively. In each line, we mark a symbol of \(\vartriangle\) for _High_ and \(\triangledown\) for _Low_ value after categorization.

From the figure, we can observe that the cost savings ratio (Figure (a)a) does not show noticeable pattern between _High_ and _Low_

Figure 11. SPS score distribution categorized by different criteria. SPS values show a noticeable distribution differences.

\begin{table}
\begin{tabular}{c c c} \hline \hline Model & Train Time & Inference Time \\ \hline LR & 46 & 0.7 \\ RF & 75 & 0.9 \\ XGBoost & 806 & 1.2 \\ SVC & 626 & 15 \\ Prophet & 0.05 & 0.002 \\ ARIMA & 302 & 0.17 \\ Transformer & 2384 & 4.7 \\ \hline \hline \end{tabular}
\end{table}
Table 2. Train and Inference Time (seconds) of a SPS prediction model value for the spot instance running time. This observation concurs with the previous work that the price of the spot instance is not a good indicator for spot instance reliability [6, 21]. We can also observe that Azure shows the longest running time than the other vendors followed by GCP and AWS. For the interrupt-free score (Figure 11(b)), the AWS spot instance shows a noticeable pattern that the higher interruption-free score is more reliable than the lower ones. However, the Azure does not show such a pattern. For the instant availability dataset (Figure 11(c)), which is provided by AWS only (SPS), instances with high scores show much more reliability than lower ones. On average, spot instances with the score of 3 runs for 4.7 hours, while that of score 1 runs only for 1.8 hours.

Figure 12: A CDF of time until an interruption event happens for AWS, Azure, and GCP spot instances categorized by different dataset values of High (\(\triangle\)) and Low (\(\triangledown\)). A graph in the right side means higher availability.