# Leveraging Invariant Principle for Heterophilic Graph Structure Distribution Shifts

Anonymous Author(s)

###### Abstract.

Heterophilic Graph Neural Networks (HGNNs) have shown promising results for semi-supervised learning tasks on graphs. Notably, most real-world heterophilic graphs are composed of a mixture of nodes with different neighbor patterns, exhibiting local node-level homophilic and heterophilic structures. However, existing works are only devoted to designing better unified HGNN backbones for node classification tasks on heterophilic and homophilic graph benchmarks simultaneously, and their analyses of HGNN performance concerning nodes are only based on the determined data distribution without exploring the effect caused by the difference of structural pattern between training and testing nodes. How to learn invariant node representations on heterophilic graphs to handle this structure difference or distribution shifts remains unexplored. In this paper, we first discuss the limitations of previous graph-based invariant learning methods in addressing the heterophilic graph structure distribution shifts from the perspective of data augmentation. Then, we propose **HEI**, a framework capable of generating invariant node representations through incorporating **H**eterophily information, node's estimated neighbor pattern, to infer latent Environments without augmentation, which are then used for Invariant prediction. We provide detailed theoretical guarantees to clarify the reasonability of HEL Extensive experiments on various benchmarks and backbones can also demonstrate the effectiveness and robustness of our method compared with existing state-of-the-art baselines. Our codes can be accessed through HEL.

Graph Representation Learning, Node Classification, Invariant Learning, Distribution Shifts, Heterophily and Homophily +
Footnote â€ : journal: Pattern Recognition

**ACM Reference Format:**

Anonymous Author(s). 2018. Leveraging Invariant Principle for Heterophilic Graph Structure Distribution Shifts. In _Proceedings of Make sure to enter the correct online trip from your rights uniformian email (Conference acronym_ 'XO). ACM, New York, NY, USA, 14 pages. [https://doi.org/XXXXXXXXXXXX](https://doi.org/XXXXXXXXXXXX)

## 1. Introduction

Graph Neural Networks (GNNs) have emerged as prominent approaches for learning graph-structured representations through the aggregation mechanism that effectively combines feature information from neighboring nodes [41]. Previous GNNs primarily dealt with _homophilic graphs_, where connected nodes tend to share similar features and labels [42]. However, growing empirical evidence suggests that these GNNs' performance significantly deteriorates when dealing with _heterophilic graphs_, where most nodes connect with others from different classes, even worse than the traditional neural networks [19]. An appealing way to address this issue is to tailor the heterophily property to GNNs, extending the range of neighborhood aggregation and reorganizing architecture [41], known as the heterophilic GNNs (HGNNs).

_Heterophilic Graph Structure distribution Shift (HGSS): A novel data distribution shift perspective to reconsider existing HGNNs works._ Despite promising, most previous HGNNs assume the nodes share the determined data distribution [18, 19], we argue that there is data distribution disparity among nodes with different neighbor patterns. As illustrated in Figure 1(a1), heterophilic graphs are composed of a mixture of nodes that exhibit local homophilic and heterophilic structures, _i.e._, the nodes have different neighbor patterns [41]. The node's neighbor pattern can be measured by node homophily, representing homophily level by comparing the label between the node and its neighbors. Here, we identify their varying neighbor patterns between train and test nodes as the Heterophilic Graph Structure distribution Shift (Figure 1(a2)). This kind of shift was neglected by previous works but truly affected GNN's performance. As shown in Figure 1(a3), we visualize the HGSS between training and testing nodes on the Squirrel dataset. Compared with test nodes, the train nodes are more prone to be categorized into groups with high homophily, which may yield a test performance degradation. More statistical results on other heterophilic graph datasets can be shown in Figure 5. Notably, though some recent work [27] also discusses homophilic and heterophilic structural patterns, until now they haven't provided a clear technique solution for this problem. Compared with traditional HGNN works that focus on backbone designs, it's extremely urgent to seek solutions from a data distribution perspective to address the HGSS issue.

_Existing graph-based invariant learning methods perform badly for HGSS due to the augmentation-based environment construction strategy._ In the context of general distribution shifts, the technique of invariant learning [30] is increasingly recognized for its efficacy in mitigating these shifts. The foundational approach involves learning node representations to facilitate invariant predictor learning across various constructed environments (Figure 1(b1)), adhering to the Risk Extrapolation (REx) principle [9, 24, 37]. Unfortunately, previous graph-based invariant learning methods may not effectively address the HGSS issue, primarily due to explicit environments that may be ineffective for invariant learning. As illustrated in Figure 1(c1), within HGSS settings, altering the original structure does not consistently affect the node's neighbor patterns. In essence, obtaining optimal and varied environments pertinent to neighbor patterns is challenging. Our observation (Figure 1(c2)) reveals that EERM [37], a pioneering invariant learning approach utilizing environment augmentation to tackle graph distribution shifts in node-leveltasks, does not perform well under HGSS settings. At times, its enhancements are less effective than simply employing the original V-Rex (Hess et al., 2018), which involves randomly distributing the train nodes across various environmental groups. We attribute this phenomenon to the irrational environment construction. According to our analysis, EERM is essentially a node environment-augmented version of V-Rex, _i.e._, the disparity in their performance is solely influenced by the differing strategies in environmental construction. Besides, from the perspective of theory assumption, V-Rex is initially employed to aid model training by calculating the variance of risks introduced by different environments as a form of regularization. The significant improvements by V-Rex also reveal that the nodes of a single input heterophilic graph may reside in distinct environments, considering the variation in neighbor patterns, thus contradicting EERM's prior assumption that all nodes in a graph share the same environment (Song et al., 2019). Based on this insight, our goal is to break away from previous explicit environment augmentation to learn the latent environment partition, which empowers the invariant learning to address the HGSS better.

_HEI: Heterophily-Guided Environment Inference for Invariant Learning._ Recent studies explore the effect of prior knowledge on the environment partition (Zhu et al., 2019; Wang et al., 2020) and subsequently strengthen the importance of the environment inference and extrapolation for model generalization (Wang et al., 2020; Wang et al., 2020). Therefore, our initial step should be to quantify the nodes' neighbor pattern properties related to the HGSS, which are central to the issue at hand. Consequently, a critical question emerges: During the training phase, how can we identify an appropriate metric to estimate the node's neighbor pattern and leverage it to deduce latent environments to manage this HGSS issue? As previously mentioned, node homophily can assess the node's neighbor patterns (Hess et al., 2018). Unfortunately, this requires the actual labels of the node and its neighbors, rendering it inapplicable during the training stage due to the potential unlabeled status of neighbor nodes. To cope with this problem, several evaluation metrics pertinent to nodes' neighbor patterns, including local similarity (Song et al., 2019), post-aggregation similarity (Song et al., 2019), and SimRank (Zhu et al., 2019), have been introduced. These metrics aim to facilitate node representation learning on heterophilic graphs during the training phase. But these studies primarily concentrate on employing these metrics to help select proper neighbors for improved HGNN architectures, while we aim to introduce a novel invariant learning framework-agnostic backbones to separate the spurious features from selected neighbors, tackling the structure distribution shifts. Therefore, we propose HEI, a framework capable of generating invariant node representations through incorporating heterophily information to infer latent environments, as shown in Figure 1 (b2), which are then used for downstream invariant prediction, under heterophilic graph structure distribution shifts. Extensive experiments on various backbones and benchmarks can verify the effectiveness of our proposed method in addressing this neglected HGSS issue.

**Our Contributions:** (i) We highlight an important yet often neglected form of heterophilic graph structure distribution shift, which is orthogonal to most HGNN works that focus on backbone designs; (ii) We propose HEI, a novel graph-based invariant learning framework to tackle the HGSS issue. Unlike previous efforts, our method emphasizes leveraging a node's inherent heterophily information to deduce latent environments without augmentation, thereby significantly improving the generalization and performance of HGNNs; (iii) We demonstrate the effectiveness of HEI on several benchmarks and backbones compared with existing methods.

Figure 1. (a) illustrates the heterophilic graph structure distribution shifts (HGSS), where the figure and histogram show the HGSS and neighbor pattern (measured by node homophily) difference between train and test nodes on the Squirrel dataset; (b) displays the comparison of different environment construction strategies between previous invariant learning works and ours from augmentation; (c) shows that the environment construction of previous methods may be ineffective in addressing the HGSS due to the unchanged neighbor pattern distribution. The experimental results between traditional and graph-based invariant learning methods can support our analysis and verify the superiority of our proposed HEL

## 2. Preliminaries

**Notations.** Given an input graph \(G=(V,X,A)\), we denote \(V\in\{v_{1},...,v_{N}\}\) as the nodes set, \(X\in R^{N\times D}\) as node features and \(A\in\{0,1\}^{N\times N}\) as an adjacency matrix representing whether the nodes connect, where the \(N\) and \(D\) denote the number of nodes and features, respectively. The node labels can be defined as \(Y\in\{0,1\}^{N\times C}\), where C represents the number of classes. For each node \(v\), we use \(A_{\theta}\) and \(X_{\theta}\) to represent its adjacency matrix and node feature.

**Problem Formulation.** We first provide the formulation for the general optimized object of node-level OOD (Out of Distribution) problem on graphs, then recalir the formulation of previous works to help distinguish our work in the next section. From the perspective of data generation, we can get train data (\(G_{train},Y_{train}\)) from train distribution \(p(\mathbf{G},\mathbf{Y})|\mathbf{e}=e\)), the model should handle the test data \((G_{test},Y_{test})\) from a different distribution \(p(\mathbf{G},\mathbf{Y})|\mathbf{e}=e^{\prime})\), varying in different environments \(\mathbf{e}\). Thus, the optimized object of node-level OOD problem on graphs can be formulated as follows:

\[\min_{\omega,0}\max_{\mathbf{e}\in\mathcal{C}}\mathbb{E}_{G}\frac{1}{N}\sum_{ \omega\in V}\mathbb{E}_{\eta:p(\mathbf{y}|\mathbf{x}_{\omega},\omega_{\omega}, \mathbf{x}_{\omega},\mathbf{x}_{\omega},\mathbf{x}_{\omega},\mathbf{x}_{ \omega},\mathbf{x}_{\omega})}I(f_{\omega}\left(f_{\phi}\left(A_{\phi},X_{\phi} \right)\right),y_{\phi}) \tag{1}\]

where the \(\mathcal{E}\) represents the support of environments \(\mathbf{e}\), the \(f_{\omega}\) and \(f_{\phi}\) refer to GNN's classifier and feature extractor respectively and \(I(\cdot)\) is a loss function (e.g. cross entropy). The Eq 1 aims to learn a robust model that minimizes loss across environments as much as possible. Only in this way, can the trained model be likely to adapt to unknown target test distribution well. However, environmental labels for nodes are usually unavailable during the training stage, which inspires many works to seek methods to make use of environmental information to help model training.

**Previous Graph-based Invariant Learning.** To approximate the optimized object of Eq. 1, previous works (Golovin et al., 2013; He et al., 2016; Wang et al., 2017) mainly construct diverse environments by adopting the masking strategy as Figure 1(b). Thus, we conclude previous works from the masking strategy (\(Mask_{\eta}(\cdot)\) parameterized with \(\eta\)). Given an input single graph, we can obtain K augmented graphs as Eq. 2, where each graph corresponds to an environment. The \(\mathbf{K}\) is a pre-defined number of training environments and \(X^{m},A^{m}\), and \(V^{m}\) are corresponding mask versions of feature, adjacency matrix, and node sets.

\[G^{e\gets k}=Mask_{\eta}^{e\gets k}(G)=(X^{m},A^{m},V^{m})_{e \gets k},k=1,2,...,K \tag{2}\]

Then, assisted by these augmented graphs with environment label, the GNN \(f(\cdot)\) parameterized by \((\omega,\Phi)\) can be trained considering environmental information. We can define the ERM (Empirical Risk Minimization) loss in the \(k\)-th environment as the Eq.3, which only calculates the loss on the corresponding augmented \(G^{e\gets k}\).

\[R_{e\gets k}\left(\omega,\Phi\right)=\frac{1}{N}\sum_{\omega\in V^{m}}I \left(f_{\omega}(f_{\phi}\left(A_{\phi},X_{\theta}\right),y_{\phi})\right. \tag{3}\]

Following the principle of Variance Risk Extrapolation (V-Rex) to reduce the risks from different environments, the final training framework can be defined as Eq. 4. Where the \(\lambda\) controls the effect between reducing the average risk and promoting equality of risks.

\[\min_{\omega,\Phi}\max_{\eta}\ \ L\left(\Phi,\omega,\eta\right)=\] \[\sum_{k=1}^{K}R_{e\gets k}(\omega,\Phi)+\lambda V\alpha r \left(R_{e\gets k}(\omega,\Phi),\cdots,R_{e\gets k}(\omega,\Phi)\right) \tag{4}\]

The maximization means that we should optimize the masking strategy (parameter \(\eta\)) to construct sufficient and diverse environments, while the minimization aims to reduce the training loss for the model (parameter \(\omega\) and \(\Phi\)).

**Discussions.** Exactly, previous graph-based invariant learning methods introduce extra augmented graphs to construct nodes' environments while our work only infers nodes' environments on a single input graph. Specifically, there exists a latent assumption for previous works that nodes on a single graph belong to the same environment so we need to construct diverse environments by data augmentation. This assumption arises from the insight that nodes on an input graph come from the same _outer domain-related environments_ (e.g. Financial graphs or Molecular graphs) (Wang et al., 2017). But considering the message-passing mechanism on heterophilic graphs (the ideal aggregation target should be nodes with the same label), the nodes should exist exactly in _inner structure-related environments_. To cope with this issue, as shown in Figure 1(c1), directly utilizing _data augmentation may be ineffective in changing the node's neighbor pattern distribution_ to construct diverse environments for invariant prediction. At the same time, the neighbor pattern difference between train and test has verified that even on a single graph, the nodes may belong to different structure-related environments. These simultaneously inspire us to directly infer node environments on a single graph assisted by the node's neighbor pattern, rather than constructing environments from different augmented graphs, for addressing heterophilic graph structure distribution shift.

## 3. Methodology

In this section, we present the details of the proposed HEL Firstly, on heterophilic graphs, we verify that the similarity can serve as a neighbor pattern indicator and then review existing similarity-based metrics to estimate the neighbor patterns during training stages. Then, we elaborate the framework to jointly learn environment partition and invariant node representation on heterophilic graphs without augmentation, assisted by the estimated neighbor patterns. Finally, we clarify the overall training process of the algorithm and discuss its complexity. Moreover, we provide a detailed theoretical analysis in Appendix A.2 to clarify the details of HEL.

### Neighbor Patterns Estimation

The node homophily is commonly used to evaluate the node's neighbor patterns, representing the node's structural pattern distribution (Golovin et al., 2013). Unfortunately, it needs the true labels of the node and its neighbors, which means they can not be used in the training stage because the neighbor nodes may be just the test nodes without labels for node classification tasks when given an input graph. To cope with it, we aim to utilize the similarity between node features to estimate the node's neighbor pattern.

**Similarity: An Indicator of Neighbor Patterns.** Previous works have shown there exists some relationship between similarity and homophily from the experimental analysis (Chen et al., 2018), it can not be guaranteed to work well without a theory foundation. Thus, we further investigate its effectiveness from the node cluster view and verifythe similarity between nodes can be exploited to approximate the neighbor pattern without the involvement of label information.

For simplicity, we take K-Means as the cluster algorithm. For two nodes \(v\) and \(u\), let \(v\) belong to the cluster centroid \(c_{1}\) and denote the square of the distance between \(v\) and \(u\) as \(\delta=\|u-\phi\|^{2}\), we can get \(c_{1}=\arg\min\|v-c_{i}\|^{2}\), where \(c_{i}\) represent the \(i\)-th cluster centroid. Then the distance between \(u\) and cluster centroid \(c_{1}\) can be acquired as the Eq. 5. Exactly, the neighbor pattern describes the label relationship between the node and its neighbors. From the Eq 5, we can find the smaller \(\delta\), the more likely the \(v\) and \(u\) belong to the same cluster and own the same label. Therefore, the similarity between nodes can be exploited to serve as a neighbor pattern indicator without using label information.

\[\begin{split}&\|u-c_{1}\|^{2}=\|(u-v)+(v-c_{1})\|^{2}\\ &=\|(u-v)\|^{2}+2\|u-v\|\|\log c_{1}+\|b-c_{1}\|^{2}\\ &=\delta+2\sqrt{\delta}\|v-c_{1}\|+\|b-c_{1}\|^{2}\\ &=\left(\|v-c_{1}\|+\sqrt{\delta}\right)^{2}\geq\delta\end{split} \tag{5}\]

**Existing Similarity-based Metrics.** Existing similarity-based metrics on heterophilic graphs can be shown as Eq.6.

\[\text{Similarity}(u,v)=\begin{cases}\text{Sim}(X_{u},X_{u})&\text{ Local Sim}\\ \text{Sim}(\hat{A}_{\phi}X_{u},\hat{A}_{u}X_{u})&\text{Agg Sim}\\ \frac{c}{|\text{NS}(u)||\text{NS}(u)|}\sum\limits_{\begin{subarray}{c}v\in N(u) \\ d^{\prime}\in N(u)\end{subarray}}\text{Sim}(X_{u^{\prime}},X_{u^{\prime}})&\text{ SimRank}\\ \end{cases} \tag{6}\]

where the \(c\in(0,1)\) is a decay factor empirically set to 0.6, the \(NS(v)\) denotes \(v\)'s neighbor set including the nodes connected to \(v\),the \(\hat{A}_{u}\) denotes the aggregation operation on the node \(e\) and the \(Sim\) denote the similarity calculation between two objects. We can observe that the local similarity (Local Sim [(7)] and post-aggregation similarity (Agg-Sim [(26)] respectively calculate the similarity of the original and post-aggregation embedding between two nodes. In contrast, the SimRank [(22)] calculates the similarity between their respective neighbor nodes.

**Estimated Node's Neighbor Pattern.** Thus, as Eq.7, we can obtain the estimated neighbor patterns \(z_{\theta}\) for the node \(v\) during the training stage by averaging the node's similarity with neighbors.

\[z_{\theta}=\frac{1}{|NS(v)|}\sum\limits_{u\in\text{NS}(v)}Similarity(u,v) \tag{7}\]

Notably, we further strengthen our object of using similarity metrics is indeed different from previous HGN works that utilize the similarity metrics((7; 22; 26)) to design backbones. From the perspective of causal analysis shown in Figure 4, when given the neighbors, we aim to separate and weaken the effect of spurious features from full neighbor features by utilizing the estimated neighbor pattern to infer the node's environment for invariant prediction. However, previous HGN works mainly aim to help the node select proper neighbors and then directly utilize full neighbor features as aggregation targets for better HGNN backbone designs. Our work is exactly _orthogonal_ to previous HGNN works.

Figure 2. Illustrations of our framework HEL (a) The neighbor pattern for each train node can be estimated by similarity first and then used for inferring environments without augmentation; (b) Based on the train nodes belonging to different inferred environments, we can train a set of environment-independent GNN classifiers with the shared encoder compared with the base GNN. The shared encoder outputs the representations of nodes in each environment and then forwards them to the base GNN classifier and the environment-independent classifier respectively. By calculating the loss gap between these two different classifiers, an invariance penalty is introduced to improve model generalization.

### HEI: Heterophily-Guided Environment Inference for Invariant Learning

We aim to utilize the estimated neighbor patterns \(Z\in R^{G_{\alpha}}\), which represent the node's heterophily information, as an auxiliary instrument to jointly learn nodes' environment partition and invariant node representation without augmentation. Similar techniques can be also shown in (Brock et al., 2018; Chen et al., 2019) for image classification tasks. Specifically, assisted by the estimated neighbor patterns for nodes, we can train an environment classifier \(\rho(\cdot):R^{G_{\alpha}}\to R^{K}\) that softly assigns the train nodes to \(K\) environments. The \(K\) is a pre-defined number, \(\rho\) is a two-layer MLP and the \(\rho^{(k)}(\cdot)\) is denoted as the \(k\)-th entry of \(\rho(\cdot)\), with \(\rho(Z)\in[0,1]^{K}\) and \(\sum_{k}\rho^{(k)}(Z)=1\). Denote the ERM loss calculated on all train nodes as \(R(\omega,\Phi)\). Then, as shown in Eq. 8, the ERM loss in the \(k\)-th inferred environment can be defined as \(R_{\rho(k)}(\omega,\Phi)\), which only calculates the loss on the nodes belonging to the \(k\)-th environment.

**Overal Framework:** Based on the above analysis, the training framework of HEI can be defined as follows:

\[R_{\rho^{(k)}}(\omega,\Phi)=\frac{1}{N}\sum_{\omega\in\Psi}\rho^{(k)}(z_{ \omega})l\left(f_{\omega}(f_{\theta}(A_{\omega},X_{\theta}),y_{\theta})\right. \tag{8}\]

\[\left.\min_{\omega,\Phi}\max_{\rho(\omega_{1},\cdots,\omega,k)}L( \Phi,\omega_{\alpha},\omega_{1},\cdots,\omega_{K},\rho)=\right.\] \[\left.R(\omega,\Phi)+\lambda\underbrace{\sum_{k=1}^{K}\left[R_{ \rho(k)}(\omega,\Phi)-R_{\rho(k)}(\omega_{\Phi},\Phi)\right]}_{\text{invariance penalty}}\right. \tag{9}\]

Compared with previous graph-based invariant learning methods shown in Eq. 3 and Eq. 4, our framework mainly differs in the maximization process. Thus, we clarify the effectiveness and reasonability of our framework from two aspects: (i) The invariance penalty learning that introduces a set of environment-dependent GNN classifiers \(\{f_{\omega_{k}}\}_{k=1}^{K}\), which are only trained on the data belonging to the inferred environments; (ii) The adaptive environment construction through optimizing the environmental classifier \(\rho(\cdot)\).

**Invariance Penalty Learning.** As shown by Eq.1, the ideal GNN classifier \(f_{\omega}\) is expected to be optimal across all environments. After the environment classifier \(\rho^{(k)}(\cdot)\) assigns the train nodes into k inferred environments, we can adopt the following criterion to check if \(f_{\omega}\) is already optimal in all inferred environments: Take the \(k\)-th environment as an example, we can additionally train an environment-dependent classifier \(f_{\omega_{k}}\) on the train nodes belonging to the \(k\)-th environment. If \(f_{\omega_{k}}\) achieves a smaller loss, it indicates that \(f_{\omega}\) is not optimal in this environment. Moreover, we can further train a set of classifiers \(\{f_{\omega_{k}}\}_{k=1}^{K}\), each one with a respective individual environment, to assess whether \(f_{\omega_{k}}\) is simultaneously optimal in all environments. Notably, all these classifiers share the same encoder \(f_{\theta}\), if \(f_{\theta}\) extracts spurious features that are unstable across the inferred environments, \(R_{\rho^{(k)}}(\omega,\Phi)\) will be larger than \(R_{\rho^{(k)}}(\omega_{k},\Phi)\), resulting in a non-zero invariance penalty, influencing model optimization towards achieving optimality across all environments. In other words, as long as the encoder extracts the invariant feature, the GNN classifier \(f_{\omega}\) and its related environment-dependent classifier \(\{f_{\omega_{k}}\}_{k=1}^{K}\) will have the same prediction across different environments.

**Adaptive Environment Construction.** As shown in Figure 1(c), the effectiveness of previous methods is only influenced by environmental construction strategy. A natural question arises: What is the ideal environment partition for invariant learning to deal with the HOSS? We investigate it from the optimization of environment classifier \(\rho(\cdot)\). Specifically, a good environment partition should construct environments where the spurious features exhibit instability, incurring a large penalty if \(f_{\theta}\) extracts spurious features. In this case, we should maximize the invariance penalty to optimize the partition function \(\rho(\cdot)\) to generate better environments, which is also consistent with the proposed strategy. Though previous works (Chen et al., 2019; Chen et al., 2019; Chen et al., 2019) also adopt the maximization process to construct diverse environments, they just focus on directly optimizing the masking strategy to get augmentation graphs. During the optimization process, these methods lack guidance brought by auxiliary information \(Z\) related to environments, ideal or effective environments are often unavailable in this case. That's why we propose to introduce the environment classifier to infer environments without augmentation, assisted by the \(Z\). Exactly, to make sure the guidance of \(Z\) has a positive impact on constructing diverse and effective environments for the invariant node representation learning, there are also two conditions for \(Z\) from the causal perspective. We will further clarify it in Appendix A.2.

### Training Process and Complexity Analysis

**Training Process:** As shown by Algorithm 1: Given a heterophilic graph input, we first estimate the neighbor patterns for each train node by Eq. 7. Then, based on Eq. 8 and Eq. 9, we aim to learn environment partition and invariant node representation, assisted by the estimated neighbor patterns through a min-max alternativeoptimization. Specifically, maximizing the invariance penalty is devoted to optimizing the environmental classifier to construct as diverse environments as possible to enlarge the loss gap between the base GNN feature encoder and additionally introduced GNN feature encoders. In contrast, the minimization of total loss aims to promote the base GNN to learn invariant representation agnostic neighbor patterns to address the HGSS issues.

**Complexity Analysis:** Given a graph with \(N\) nodes, the average degree is \(d\). GNN with \(l\) layers calculate embeddings in time and space \(\mathcal{O}(Nld^{2})\). HEI assigns N nodes into \(k\) inferred environments \(N_{k=1}+\cdots+N_{e=k}=N\) and executes \(k+1\) classifier computations, where the \(k\) corresponds to the \(k\) environment-independent classifiers, and \(1\) refers to the basic GNN classifier. Denote \(N^{\prime}\) as the average number of nodes belonging to an inferred environment, the overall time complexity is \(\mathcal{O}(Nld^{2}+kN^{\prime}ld^{2})\), which is linear to the scale of the graph. More detailed efficiency studies compared with previous methods can be shown in Experiments.

## 4. Experiments

In this section, we investigate the effectiveness of HEI to answer the following questions.

* **RQ1:** Does HEI outperform state-of-art methods to address the HGSS issue?
* **RQ2:** How robust is the proposed method? Can HEI solve the problem that exists in severe distribution shifts?
* **RQ3:** How do different similarity-based metrics influence the neighbor pattern estimation, so as to further influence the effect of HEI?
* **RQ4:** What is the sensitivity of HEI concerning the pre-defined number of training environments?
* **RQ5:** How efficient is the proposed HEI compared with previous methods?

### Experimental Setup

**Datasets.** We adopt six commonly used heterophilic graph datasets (chameleon, Squirrel, Actor, Penn94, arxiv-year, and twitch-gamer) and three homophilic graph datasets (Cora, CiteSeer and PubMed) to verify the effectiveness of HEI (Gran et al., 2017; Zhang et al., 2018). To make sure the evaluation is stable and reasonable, we utilize the filtered versions of existing datasets to avoid data leakage (Zhu et al., 2018). Notably, considering that we should further split the test datasets to construct different evaluation settings. Those excessive small-scale heterophilic graph datasets, such as Texa, Cornell, and Wisconsin (Yoon et al., 2018), are not fit and chosen for evaluation due to their unstable outcomes. Moreover, considering the nodes on homophilic graphs means there exists a mere structure difference between train and test nodes. We just provide experiments and discussions in the Appendix A.3.

**Settings.** Based on previous dataset splits, we construct two different settings to evaluate the effectiveness and robustness of HEI: **(i) Standard Settings:** We sort the test nodes based on their nodes' homophily values and acquire the median. The part that is higher than the median is defined as the High Hom Test, while the rest is defined as the Low Hom Test. The model is trained on the previous train dataset and evaluated on more fine-grained test groups; **(ii) Simulation Settings where exists severe distribution shifts.**: We sort and split the train and test nodes simultaneously adopting the same strategy of (i). The model is trained on the Low/High Hom Train and evaluated on the High/Low Hom Test.

**Backbones.** To further verify our framework is orthogonal to previous HGNN works that focus on backbone designs, we adapt HEI to two existing SOTA and scalable backbones with different foundations, LINKX (MLP-based) (Gran et al., 2017) and GloGNN++ (GNN-based) (Gran et al., 2017). In this way, our improvements can be attributed to the design that deals with the neglected heterophilic structure distribution shifts.

**Baselines.** Denote the results of the backbone itself as ERM. Our comparable baselines can be categorized into: (i) Reweight-based methods considering structure information: Rende (Chen et al., 2016) and StruRW-Mixup (Zhu et al., 2018); (ii) Invariant Learning methods involving environment inference for node-level distribution shift: SRGNN (Zhu et al., 2018), EEM (Zhu et al., 2018), BAGNN (Gran et al., 2017), FLOOD (Zhu et al., 2018), CaNet (Zhu et al., 2018) and IENE (Zhu et al., 2018) ; (iii) Prototype-based methods for structural distribution shift on the special domain(e.g. graph anomaly detection): GDN (Gran et al., 2017). Notably, though we can utilize estimated neighbor patterns as auxiliary information to infer environments related to HGSS, the true environment label is still unavailable. So we don't compare with those traditional invariant learning methods that rely on the explicit environment labels, e.g. IRM (Chen et al., 2016), V-Rex (Gran et al., 2017) and GroupDRO (Zhu et al., 2018).

### Experimental Results and Analysis

**Handling Distribution Shifts under Standard Settings (RQ1).** We first evaluate the effectiveness of HEI under standard settings, where we follow the previous dataset splits and further evaluate the model on more fine-grained test groups with low and high homophily, respectively. The results can be shown in Table 1 and Table 2. We have the following observations.

On the one hand, _the impact brought by the HGSS is still apparent though we adopted the existing SOTA HGNN backbones._ As shown by the results of ERM in Table 1 and Table 2, for most datasets, there are significant performance gaps between the High Hom Test and Low Hom Test, ranging from 5 to 30 scores. These results further verify the necessity to seek methods from the perspective of data distribution rather than backbone designs to deal with this problem.

On the other hand, _HEI can outperform previous methods in most circumstances._ Specifically, compared with invariant learning methods, though HEI does not augment the training environments, utilizing the estimated neighbor patterns to directly infer latent environments still benefits invariant prediction and improves model generalization on different test distributions related to homophily. In contrast, directly adopting a reweight strategy (Renode and StruRW) or evaluating the difference between the training domain and target domain (SRGNN) without environment augmentation can't acquire superior results than invariant learning methods. This is because these methods need accurate domain knowledge or structure information in advance to help model training. However, for the HGSS issue, the nodes' environments on heterophily graphs are unknown and difficult to split into the invariant and spurious domains, like the GOOD dataset (Gran et al., 2017) which has clear domain and distribution splits. Simultaneously, the neighbor pattern distribution represents more fine-grained label relationships between 

[MISSING_PAGE_FAIL:7]

[MISSING_PAGE_FAIL:8]

## References

* (1)
* Abu-El-Haija et al. (2019) Sami Abu-El-Haija, Bryan Perozzi, Amol Kapoor, Nazanin Alipourfard, Kristina Lerman, Hrayer Hanyunyan, Greg Ver Steeg, and Anna Gahyam. 2019. Multihop: Higher-order graph convolutional architectures via sparsified neighborhood mixing. In _International conference on machine learning_. PMLR, 2:1-29.
* Afrojsky et al. (2019) Martin Afrojsky, Leon Bottou, Ishan Gulrajani, and David Lopez-Paz. 2019. Invariant risk minimization. _arXiv preprint arXiv:1907.02893_ (2019).
* Chang et al. (2020) Shiyu Chang, Yang Zhang, Mo, and Tommi Jaakkola. 2020. Invariant ratio-imbalanced. In _International Conference on Machine Learning_. PMLR, 148:148-1485.
* Chen et al. (2021) Deli Chen, Yankai Lin, Guangxiang Zhao, Xuanheng Ren, Peng Li, Jie Zhou, and Xun Sun. 2021. Topology-imbalance learning for semi-supervised node classification. _Advances in Neural Information Processing Systems_ 34 (2021), 2988-2997.
* Chen et al. (2020) Ming Chen, Zhewei Wei, Zengfeng Huang, Robin Ding, and Yaliang Li. 2020. Simple and deep graph convolutional networks. In _International conference on machine learning_. PMLR, 1725:1735-1736.
* Chen et al. (2023) Yongqiang Chen, Yutao Bian, Kaiwen Zhou, Ringuibai Xie, Bo Han, and James Cheng. 2023. Does Invariant Graph Learning via Environment Augmentation Learn Invariance? _arXiv preprint arXiv:2301.10053_ (2023).
* Chen et al. (2023) Yuhan Chen, Yihong Li, Jing Zhang, Liang Yang, Siyu Qian, Chun Wang, and Xiaohui Cao. 2023. L5CNN: Towards General Graph Neural Network in Node Classification by Local Similarity. _arXiv preprint arXiv:2302.02205_ (2023).
* Chen et al. (2022) Yongqiang Chen, Yongqiang Zhu, Yutao Bian, Han Yang, MA Kaili, Binghui Xie, Tongliang Liu, Bo Han, and James Cheng. 2022. Learning causality invariant representations for out-of-distribution generalization on graphs. _Advances in Neural Information Processing Systems_ 35 (2022), 22313-2248.
* Chen et al. (2022) Zheguyu Chen, Eric Xiao, and Kun Kunu. 2022. Ba-gmn: On learning bias-aware graph neural network. In _2022 IEEE 38th International Conference on Data Engineering (ICDE)_. IEEE, 3012-3024.
* Chen et al. (2020) Eli Chen, Jinhao Peng, Pan Li, and Qileios Mikhailov. 2020. Adaptive universal generalized graph neural network. _arXiv preprint arXiv:2006.07988_ (2020).
* Gao et al. (2023) Yuan Gao, Xiang Wang, Xiangnan He, Zhenguang Liu, Huamin Feng, and Yongdong Zhang. 2023. Alleviating structural distribution shift in graph anomaly detection. In _Proceedings of the sixteenth ACM international conference on web search and data mining_. 357-365.
* Gui et al. (2021) Shmut Gui, Xinr Li, Linel Wang, and Shuiwang Ji. 2021. Good: A graph out-of-distribution benchmark. _Advances in Neural Information Processing Systems_ 35 (2021), 2059-2073.
* He et al. (2022) Dongxia He, Chundong Liang, Huixin Liu, Mingqiang Wen, Pengfei Jiao, and Zhiyong Feng. 2022. Block modeling-guided graph convolutional neural networks. In _Proceedings of the AAAI conference on artificial intelligence_, Vol. 36. 4022-4029.
* Jin et al. (2021) Dis Jin, Zhizhi Yu, Cuiyang Huo, Rui Wang, Xiao Wang, Dongxiang He, and Jiawei Han. 2021. Universal graph convolutional networks. _Advances in Neural Information Processing Systems_ 34 (2021), 10656-10644.
* Jin et al. (2021) Wei Jin, Yifu Der, Tiei Wang, Mo Li, Jing Zhang, and Juliang Tang. 2021. Node similarity preserving graph convolutional networks. In _Proceedings of the 14th ACM international conference on web search and data mining_, 148-156.
* Kroeger et al. (2021) David Kroeger, Hirohian Caballero, Jerome-Ferrat-Jacobson, Amy Zhang, Jonathan Jiang, Dingshan Zhang, Remi Eti and Piot. 2021. Out-of-distribution generalization via risk interpolation (rest). In _International Conference on Machine Learning_. PMLR, 5815-5826.
* Li et al. (2022) Haoyang Li, Ziwei Zhu, Xin Wang, and Wenru Zhu. 2022. Learning invariant graph representations for out-of-distribution generalization. _Advances in Neural Information Processing Systems_ 35 (2022), 11828-11811.
* Li et al. (2022) Xiang Li, Renyu Xu, Yue Cheng, Chihu Shan, Siqiang Luo, Dongdong Li, and Junqi Wang. 2022. Finding global homophily in graph neural networks when meeting heterophily. In _International Conference on Machine Learning_. PMLR, 1324:1326.
* Li et al. (2021) Derek Li, Felix Holme, Xinyu Li, Siqin Linda Huang, Vaishnavi Gupta, Oankar Balaene, and Sesar Nann. 2021. Large scale learning on non-homophily graphs: New benchmark and strong simple models. _Advances in Neural Information Processing Systems_ 34 (2021), 20887-20902.
* Lin et al. (2022) Yong Li, Shengyu Zhu, Lu Tan, and Peng Cui. 2022. ZIN: When and How to Learn Invariance Without Environment Partition? _Advances in Neural Information Processing Systems_ 35 (2022), 24523-24542.
* Liu et al. (2022) Gao Liu, Tong Zhao, Jiaxin Xu, Tongfei Luo, and Meng Jiang. 2022. Graph rationalization with environment-based augmentations. In _Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_. 1069-1078.
* Liu et al. (2023) Haoyu Liu, Ningyi Liao, and Sugina Luo. 2023. SINGA: A simple and Effective Heterophilous Graph Neural Network with Efficient Global Aggregation. _arXiv preprint arXiv:2306.09058_ (2023).
* Lin et al. (2023) Shikin Lin, Tianchun Li, Yongbin Feng, Shan Tran, Han Zhao, Qiang Qiu, and Pan Li. 2023. Structural re-weighting improves graph domain adaptation. In _International Conference on Machine Learning_. PMLR, 21778-21793.
* Lin et al. (2018) Yang Lin, Xiang Ao, Full Feng, Yunhan Ma, Kun Li, Tat-Seng Chua, and Qing. 2023. HOOD: A flexible invariant learning framework for out-of-distribution generalization on graphs. In _Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_. 1548-1558.
* Luan et al. (2021) Siueo Luan, Chenging Hua, Qincheng Liu, Jiaya Zhu, Mingde Zhao, Shuyuan Zhang, Xiao-Wu Chen, and Dixu Precup. 2021. Is heterophily a real night-time for graph neural networks to do node classification? _arXiv preprint arXiv:2106.05641_ (2021).
* Luan et al. (2022) Siueo Luan, Chenging Hua, Qincheng Lu, Jiaya Zhu, Mingde Zhao, Shuyuan Zhang, Xiao-Wu Chen, and Dixu Precup. 2022. Revisiting heterophily for graph neural networks. _Advances in neural information processing systems_ 35 (2022), 1363-1375.
* Ma et al. (2023) Haitao Ma, Zhikai Chen, Wei Jin, Hayu Han, Yao Ma, Tong Zhao, Neil Shah, and Jiliang Tang. 2023. Demaptifying Structural Disparity in Graph Neural Networks: Can One Size Fit All? _arXiv preprint arXiv:2306.08323_ (2023).
* Peng et al. (2020) Hongbin Pei, Bingheu Wei, Kevin Chen-Chuan Chang, Tu Lei, and Bo Yang. 2020. Geom: Gpcnet: Graph convolutional networks. _arXiv preprint arXiv:2002.02827_ (2020).
* Platonov et al. (2010) Olga Platonov, Denis Kuzmedele, Michael Diskin, Anton Babenko, and Liadminla Poshokurtosova. 2010. A critical look at the evaluation of GCNN under heterophily: "Are we really making progress? _arXiv preprint arXiv:2302.11640_ (2010).
* Tong et al. (2019) Yuq Tong, Wenbing Huang, Tingyang Xu, and Junzhou Huang. 2019. Droppede: Towards deep graph convolutional networks on node classification. _arXiv preprint arXiv:1907.10053_ (2019).
* Sugara et al. (2019) Shiori Sugara, Pang Wei Koh, Tatsuunori B Hashimoto, and Percy Liang. 2019. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. _arXiv preprint arXiv:1911.08731_ (2019).
* Suresh et al. (2021) Suheel Suresh, Yunih Bode, Jennifer Neville, Yan Li, and Jianhua Ma. 2021. Breaking the limit of graph neural networks by improving the assortativity of graphs with local mixing patterns. In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_. 1541-1551.
* Liu et al. (2023) Xiaoru Liu, Tom Song, Shengyu Zhu, Chao Qiu, Xiao Yangbin, Peng Cui, and Yuan Q. 2023. Provably invariant learning without domain information. In _International Conference on Machine Learning_. PMLR, 3385-3350.
* Wang et al. (2022) Tao Wang, Di Jin, Rui Wang, Dongxiang He, and Yuxiao Huang. 2022. Powerful graph convolutional networks with adaptive propagation mechanism for homophily and heterophily. In _Proceedings of the AAAI conference on artificial intelligence_, Vol. 36. 4210-4218.
* Wang and Zien (2021) Yuq Wang and Yifu Der. 2021. Tree decomposed graph neural network. In _Proceedings of the 30th ACM international conference on information & knowledge management_. 2020-2049.
* Wu et al. (2024) Qifun Wu, Fangxin Zhao, Junqi Yan, and Junqi Yan. 2024. Graph out-of-distribution generalization via causal intervention. In _Proceedings of the ACM on Web Conference_. 24024 580-5860.
* Wu et al. (2022) Qifun Wu, Hengui Zhang, Junqi Yan, and David Wipf. 2022. Handling distribution shifts on graphs: An invariance perspective. _arXiv preprint arXiv:2202.02406_ (2022).
* Wu et al. (2022) Ying-Xin Wu, Xiang Wang, An Zhang, Xiangnan He, and Tat-Seng Chua. 2022. Discovering invariant rationales for graph neural networks. _arXiv preprint arXiv:2201.12872_ (2022).
* Yang et al. (2024) Haoran Yang, Kaohio Pei, and Kai Yuan. 2024. ISNE: Identifying and Extrapolation the Node Environment for Out-of-Distribution Generalization on Graphs. _arXiv preprint arXiv:2006.07047_ (2024).
* Zhang et al. (2024) Huihin Zhang, Zhengu Chen, Zhen Xiao, Yueyang Wang, and Kunu Kuang. 2024. Discovering Invariant Neighborhood Patterns for Heterophilic Graphs. _arXiv preprint arXiv:2402.06157_ (2024).
* Zheng et al. (2022) Xin Zheng, Yixin Liu, Shuri Pan, Miao Zhang, Di Jin, and Philip S Yu. 2022. Graph neural networks for graphs with heterophily: A survey. _arXiv preprint arXiv:2202.07082_ (2022).
* Zhu et al. (2020) Ziong Zhu, Yiyun Yan, Lingxiao Zhao, Mark Heinmann, Leman Akoglu, and Danil Kostan. 2020. Beyond homophily in graph neural networks: Current limitations and effective designs. _Advances in neural information processing systems_ 33 (2020), 7793-7804.
* Poonmareva et al. (2021) Qi Zhu, Natalia Poonmareva, Jiawei Han, and Bryan Perozzi. 2021. Shift-robust gms: Overcoming the limitations of localized graph training data. _Advances in Neural Information Processing Systems_ 34 (2021), 27965-27977.

## Appendix A Appendix

In this appendix, we provide the details omitted in the main text due to the page limit, offering additional experimental results, analyses, proofs, and discussions.

* A.1: We provide a detailed literature review related to our work and further distinguish our work with these works to clarify our contribution.
* A.2: We provide detailed theoretical analysis from the causal perspective to clarify the reasonability of HEI: Why we can utilize the estimated neighbor pattern to infer environments to address the HGS issue?
* A.3: We provide the full experimental results on small and large-scale datasets adopting LINKX and GloGNN as backbones (4.2 of the main paper).
* A.4: We provide detailed implementation details to reproduce our experiments.

### Related Work

**Graph Neural Networks with Heterophily.** Existing strategies for mitigating graph heterophily issues can be categorized into two groups (Kumar and Barto, 2017): (i) Non-Local Neighbor Extension, aimed at identifying suitable neighbors through mixing High-order information (Bishop, 2006; Lee et al., 2016; Lee et al., 2016) or discovering potential neighbors assisted by various similarity-based metrics (Kumar and Barto, 2017; Lee et al., 2016; Lee et al., 2016; Lee et al., 2016; Lee et al., 2016); (ii) GNN Architecture Refinement, focusing on harnessing information derived from the identified neighbors, through selectively aggregating distinguishable and discriminative node representations, including adapting aggregation scheme (Kumar and Barto, 2017; Lee et al., 2016; Lee et al., 2016), separating Ego-neighbor (Lee et al., 2016; Lee et al., 2016; Lee et al., 2016) and combining inter-layer (Bishop, 2006; Lee et al., 2016).

However, these efforts share the common objective of designing better unified HGNN backbones for node classification tasks on heterophilic and homophilic graph benchmarks simultaneously. Moreover, we also found a recent arxiv paper called INPL (Zhu et al., 2017) that coincides with our work. Though it also mentions the distribution shifts of neighborhood patterns, it still focuses on proposing an adaptive Neighborhood Propagation (ANP) module to _optimize the HGNN backbone or architecture without a thorough analysis of previous graph-based invariant-learning methods_. Different from these works, we instead consider from an identifiable neighbor pattern distribution perspective and propose a novel invariant learning framework that can be integrated with most HGNN backbones to further enhance their performance and generalization.

**Generalization on GNNs.** Many efforts have been devoted to exploring the generalization ability of GNNs. **(i) For graph-level tasks**, it assumes that every graph can be treated as an instance for prediction tasks (Zhu et al., 2017). Many works propose to identify invariant sub-graphs that decide the label Y and spurious sub-graphs related to environments, such as CIGA (Chen et al., 2018), GIL (Zhu et al., 2017), GREA (Zhu et al., 2017), DIR (Zhu et al., 2017) and GALA (Chen et al., 2018) (ii) **However, for node-level tasks that we focus on in this paper**, the nodes are interconnected in a graph as instances in a non-iid data generation way, it is not feasible to transfer graph-level strategies directly. To address this issue, EERM (Zhu et al., 2017) proposes to regard the node's ego-graph with corresponding labels as instances and assume that all nodes in a graph often share the same environment, so it should construct different environments by data augmentation, _e.g._, DropEdge (Zhu et al., 2017). Based on these findings, BA-GNN (Chen et al., 2018), FLOOD (Lee et al., 2016) and IENE (Zhu et al., 2017) inherit this assumption to improve model generalization. Apart from these environments-augmentation methods, the SR-GNN (Zhu et al., 2017) and GDN (Kumar and Barto, 2017) are two works that address distribution shifts on node-level tasks from the domain adaption and prototype learning perspectives respectively. Moreover, Renode (Renode, 2015) and StruRW-Mixup (Zhu et al., 2017) are two reweight-based methods that explore the effect brought by the structure difference between nodes for node classification tasks. We also compare them in experiments.

Unlike these works, we highlight a special variety of structure-related distribution shifts for node classification tasks on heterophilic graphs and propose a novel invariant learning framework adapted to heterophilic graphs without dealing with graph augmentation to address this problem.

### Theoretical Analysis

To help understand our framework well, we first provide the comparison between our work and previous graph-based invariant learning works as shown in Figure 4. Specifically, the definitions of random variables can be defined as follows: We define \(\mathbf{G}\) as a random variable of the input graph, \(\mathbf{A}\) as a random variable of node's neighbor information, \(\mathbf{X}\) as a random variable of node's features, and \(\mathbf{Y}\) as a random variable of node's label vectors. Both node features \(\mathbf{X}\) and node neighbor information \(\mathbf{A}\) consist of invariant predictive information that determines the label Y and the spurious information influenced by latent environments \(\mathbf{e}\). In this case, we can denote \(\mathbf{X}=[\mathbf{X}^{T},\mathbf{X}^{S}]\) and \(\mathbf{A}=[\mathbf{A}^{T},\mathbf{A}^{S}]\).

Then, we provide a more detailed theoretical analysis of our framework from a casual perspective to identify invariant features.

**Causal conditions of \(Z\)**. From the casual perspective, some conditions are also needed for \(Z\) to make sure our framework to address the heterophilic graph structure distribution shifts well (Zhu et al., 2017). Denote the \(H(Y|X,A)\) as the expected loss of an optimal classifier over \((X,A,\) and \(Y)\), we can clarify the reasonability of utilizing the estimated neighbor patterns as \(Z\) auxiliary information to infer environments for invariant prediction based on the following two conditions.

**Condition 1** (Insurance Preserving Condition).: _Given invariant feature \((X^{I}\) and \(A^{I})\) and any function \(\rho(\cdot)\), it holds that_

\[H(Y|(X^{I},A^{I}),\rho(Z))=H(Y|(X^{I},A^{I})). \tag{10}\]

**Condition 2** (Non-invariance Distinguishing Condition).: _For any feature \(X^{SK}\in X^{S}\) or \(A^{SK}\in A^{S}\), there exists a function \(\rho(\cdot)\) and a constant \(C>0\) satisfy:_

\[H(Y|(X^{SK},A^{SK}))-H(Y|(X^{SK},A^{SK}),\rho(Z))\geq C. \tag{11}\]

Condition 1 requires that invariant features \(X^{I}\) and \(A^{I}\) should keep invariant under any environment split obtained by \(\rho(Z)\). Otherwise, if there exists a split where an invariant feature becomes non-invariant, then this feature would introduce a positive penalty as shown in Eq. 9 to further promote the learning of invariant node representation. Exactly, Condition 1 can be met only if \(H(Y|(X^{I},A^{I}),Z)=H(Y|(X^{I},A^{I}))\), which means the auxiliary variable \(Z\) should be d-separated by invariant feature \(X^{I}\) and \(A^{I}\). We provide a detailed proof in the appendix A.2. Exactly, the estimatedneighbor pattern just describes the similarity between the node and its neighbors as Eq. 7, while the label \(Y\) only has the direct causal relationship with \(X^{I}\) and \(A^{I}\) from the causal perspective. This means the Condition 1 can be met by adopting the estimated neighbor pattern as auxiliary information \(Z\) to construct environments.

Condition 2 reveals that for each spurious feature \(X^{S}\) and \(A^{S}\), there exists at least one environment split where this feature demonstrates non-invariance within the split environment. If a spurious feature doesn't cause invariance penalties in all environment splits, it can't be distinguished from true invariant features. As shown in Figure 1(c2), the results of V-Rex are better than ERM, which means even randomly split environments with seeds can have a positive effect on making spurious features produce effective invariance penalty, further promoting the learning of invariant features. It's more likely to construct comparable or better environments than random seeds under the guidance of the estimated neighbor patterns \(Z\). Thus, Condition 2 can also be guaranteed under our defined heterophilic graph structure distribution shift.

**Proof of Meeting Condition 1.** We show that for all \(\rho(\cdot)\), if \(H(Y|X^{I},A^{I}),Z)=H(Y|(X^{I},A^{I}))\) holds, then there will exist that \(H(Y|(X^{I},A^{I}),\rho(Z))=H(Y|(X^{I},A^{I}))\).

On one hand, because \(\rho(Z)\) contains less information than \(Z\), we have

\[H(Y|(X^{I},A^{I}),\rho(Z))\geq H(Y|(X^{I},A^{I}),Z)=H(Y|(X^{I},A^{I})).\]

On the other hand, \((X^{I},A^{I})\) and \(\rho(Z)\) contain more information than \((X^{I},A^{I})\), so we can get

\[H(Y|(X^{I},A^{I}),\rho(Z))\leq H(Y|(X^{I},A^{I})).\]

Thus, we conclude \(H(Y|(X^{I},A^{I}),\rho(Z))=H(Y|(X^{I},A^{I}))\).

**Assumptions and Theorem to Identify Invariant Features.** In particular, our assumption is consistent with previous invariant learning (Zhu et al., 2018). So we provide the previous version to support our framework, where \(X=[X_{0};X_{8}]\), where the \(X_{0}\) refers to the invariant feature and the \(X_{8}\) refers to the spurious feature.

**Assumption 1**.: _For a given feature mask \(\Phi\) and any constant \(\epsilon>0\), there exists \(f\in F\) such that \(E[[(f(\Phi(X)),Y)]\leq H(Y|\Phi(X))+\epsilon\)._

**Assumption 2**.: _If a feature violates the invariance constraint, adding another feature would not make the penalty vanish, i.e., there exists a constant delta \(>0\) so that for spurious feature \(X_{1}\subset X_{8}\) and any feature \(X_{2}\subset X_{7}\),_

\[H(Y|X_{1},X_{2})-H(Y|\rho(Z),X_{1},X_{2})\geq\delta\left(H(Y|X_{1})-H(Y|\rho(Z ),X_{1})\right).\]

**Assumption 3**.: _For any distinct features \(X_{1},X_{2},H(Y|X_{1},X_{2})\leq H(Y|X_{1})-\gamma\) with fixed \(\gamma>0\)._

Exactly, Assumption 1 is a common assumption that requires the function space \(F\) be rich enough such that, given \(\Phi\), there exists \(f\in F\) that can fit \(P(Y|\Phi(X))\) well. Assumption 2 aims to ensure a sufficient positive penalty if a spurious feature is included. Assumption 3 indicates that any feature contains some useful information w.r.t. \(Y\), which cannot be explained by other features. Otherwise, we can simply remove such a feature, as it does not affect prediction.

The theorem to identify invariant features can be defined:

**Theorem 1**.: _Depending on the Assumptions 1-3 and Conditions 1-2, if \(\epsilon<\frac{C\gamma^{S}}{4\gamma+2\delta(1)\gamma}\) and \(\lambda\in\{\frac{H(Y+1)/2\delta C}{\delta C-\epsilon}-\frac{1}{2},\frac{1}{ 4\epsilon}-\frac{1}{2}\}\), then we will have \(\tilde{L}(\Phi_{0})<\tilde{L}(\Phi)\) for all \(\Phi\neq\Phi_{0}\), where \(H(Y)\) denotes the entropy of \(Y\)._

### More Experimental Results

We provide more experimental results to further show the effectiveness of the proposed HEL in addressing heterophilic graph structure distribution shifts.

**RQ2: Additional Experiments on Simulation Settings using GloGNN++ as backbone.** We also conduct experiments under severe distribution shifts using GloGNN++ as the backbone. As shown in Figure 6, our proposed method can acquire superior or comparable results than previous methods to handle graph structure distribution shifts, which further verifies the effectiveness and robustness of our design.

Figure 4. Comparisons between our work and previous graph-based invariant learning works from the causal perspective. Notably, the basic HGNN directly aggregates the selected neighborsâ€™ full features without further separating like the above two types of invariant learning methods.

#### a.4.2. The Effect of Different Similarity matrices as neighbor pattern indicators for HEL

We provide large-scale graph experiments as shown in Table 7 to clarify the details of HEL.

**RQ4: Sensitive analysis.** We provide the experimental results about RQ4 there as shown in Figure 7.

**RQS: Efficiency Studies.** As shown in Table 5, referring to (Kumar et al., 2018), we provide the time(seconds) to train the model until it converges which keeps the stable accuracy score on the validation set. From the results, we can conclude that the extra time cost can be acceptable compared with the backbone itself.

**Experiments on Homophilic Graph Datasets.** Considering the fact that in real-world settings, we can't know whether the input graph is homophilic or heterophilic in advance. Thus, we also provide comparison experiments and discussions for homophilic graphs. As shown in Table 6, from the results, we observe that our method can achieve consistent comparable performance to other baselines. But exactly, the improvements by these methods are all minor compared with the results of ERM. That's because the homophilic graph is not related to our settings. After all, homophilic graph datasets mean the neighbor pattern distribution between the train and test are nearly the same, which is not suitable to clarify our defined distribution shifts. The performance gap between the low home test and the high home test can support our analysis.

### Implementation Details

We provide detailed implementation details for our experiments.

**ERM**, it corresponds to the results of the backbone itself (Kumar et al., 2018; Wang et al., 2018) under our constructed settings.

**SRGNN(Wang et al., 2018)**, Shift-Robust GNN is a framework inspired by domain adaption, which means it needs prior knowledge from the target domain. Specifically, it strives to adapt a biased sample of labeled nodes to more closely conform to the distributional characteristics present in an IID sample of the graph. In our experiments, we utilize the estimated neighbor distribution information to evaluate the distribution of the source domain and target domain. Apart from this, we entirely follow this work to address graph structure distribution shifts on heterophilic graphs.

**Renode(Chen et al., 2019)**, in our experiments, it is an extension of the original Renode, which is a model-agnostic training weight schedule mechanism to cope with topology-imbalance problems for semi-supervised node classification. Specifically, they devise a cosine by annealing mechanism for the training node weights based on their Totoro values. The Totoro values involve topology information and can also integrate with quantity-imbalanced methods as the paper shown. Therefore, this method can also be seen as a baseline which can copy with agnostic distribution shifts. We adopt the same (Yang et al., 2018), reweight strategy as the paper stated, and the Totoro values can also describe the neighbor pattern to a certain extent.

**ERM(Wang et al., 2018)**, Explore-to-Extrapolate Risk Minimization (EERM) is an invariant learning approach that facilitates graph neural networks to leverage invariance principles for prediction. As stated in the paper, EERM resorts to multiple context explorers that are adversarially trained to construct diverse environments with augmentation. Then, following the principle of variance of risks, it

\begin{table}
\begin{tabular}{l c c c c c c} \hline \hline
**Dataset** & \multicolumn{1}{c}{Champion} & \multicolumn{1}{c}{Squirred} & Actor & Penny4 & arXiv-year & twitch-gamer \\ \hline
**1200** & **Nodes** & 2277 & 5201 & 7600 & 41554 & 169343 & 168114 \\
**Edges** & 36011 & 216933 & 29926 & 1362292 & 1166243 & 6797557 \\
**1262** & **Fast** & 2325 & 2089 & 931 & 5 & 128 & 7 \\
**Class** & 5 & 5 & 5 & 2 & 5 & 2 \\
**Edge bom.** & 0.23 & 0.22 & 0.22 & 0.47 & 0.222 & 0.548 \\ \hline \hline \end{tabular}
\end{table}
Table 4. Statistics for our used heterophilic graph datasets.

Figure 5. Statistic of homophily ratio for train and test nodes following previous dataset splits. The nodes are categorized into four groups according to the node-level homophily. Compared with test nodes, the train nodes are more prone to be categorized into groups with high homophily. In other words, in the range with high homophily(from 0.2 to 0.3 and from 0.3 to 1), the sub-train ratio in all train nodes is higher than the sub-test in all test nodes. But in the range with low homophily, there exists a contrary phenomenon.

[MISSING_PAGE_FAIL:13]

utilizes the variance from multiple virtual environments as regularization to help model training. We entirely follow this work to address graph structure distribution shifts on heterophilic graphs.

**BAGNN(Chen et al., 2019)**, Bias-aware(BA) GNN is also a method that deals with agnostic distribution shifts on graphs from the perspective of invariant learning. Specifically, it can be summarized into two steps: the environment clustering module assigns nodes to environments with minimization loss, and the invariant graph learning module learns invariant representation across environments with minimization loss. During the process of environment clustering, it adopts the masking strategy with graph augmentation. We entirely follow this work to address graph structure distribution shifts on heterophilic graphs.

**FLOOD(Chen et al., 2019)**, it is also a flexible invariant learning framework for OOD generalization on graphs. Specifically, it includes two key modules, invariant learning, and bootstrapped learning. The invariant learning modules construct multiple environments from graph data augmentation and learn invariant representation under risk extrapolation. Besides, the bootstrapped learning component is inspired by test time adaptation, which proposes to train a shared graph encoder with the invariant learning part according to the test distribution. We entirely follow this work to address graph structure distribution shifts on heterophilic graphs.

**CaNet(Zhou et al., 2019)**, it is a recently proposed invariant learning framework that integrates an environment estimator with a mixture-of-expert GNN predictor. aiming to train robust GNNs under node-level distribution shifts. Exactly, it holds the findings that the crux of GNNs' failure in OOD generalization lies in the latent confounding bias from the environment and proposes to estimate the pseudo environments for each layer of the GNN network, assisted causal inference. Their defined environments are different from the environment we clarify in the paper, which is just stated from the perspective of feature separation. We entirely follow this work to address graph structure distribution shifts on heterophilic graphs.

**IENE(Zhou et al., 2019)**, it is also a recently proposed invariant learning framework that identifies and extrapolates the node environment for Out-of-Distribution Generalization on graphs. However, for extrapolating topological environments, they still adopt graph augmentation techniques to identify structural invariance, which is indeed different from our strategy for inferring environments. We entirely follow this work to address graph structure distribution shifts on heterophilic graphs.

**StruRW(Zhou et al., 2019)**, it is a structure-reweighting method originally designed for a new type of conditional structure shift (CSS), which is the current Graph domain adaptation approaches are provably suboptimal to deal with. We entirely follow this work to address graph structure distribution shifts on heterophilic graphs.

**GDN(Zhou et al., 2019)**, it is a prototype learning method originally designed for Graph Anomaly Detection. It teases out the anomaly features and mitigates the effect of heterophilic neighbors by devising a dynamically optimized prototype vector to guide the node representation learning under graph structure distribution shift. We entirely follow this work to address graph structure distribution shifts on heterophilic graphs.

**HEI (Ours)**, our training process can be concluded as follows: Given a heterophilic graph input, we first calculate the SimRank for each node in advance. Then, based on Eq. 9, we collectively learn environment partition and invariant representation on heterophilic graphs, assisted by SimRank, to address graph structure distribution shifts on heterophilic graphs. Therefore, we save the processed SimRank values on nodes on the graph in advance and transfer them into tensors for the training. For training details, we should warm up for some epochs to avoid the learned environments in the initial stage that are not effective, which may influence the optimization of models. So at the beginning warm-up stage, we adopt the ERM strategy. After that, we adopt our proposed framework to learn an invariance penalty to improve model performance. For the range of parameters, we first execute experiments using basic backbones to get the best parameters of num-layers and hidden channels on different datasets. Then, we fix the num-layers and hidden channels to adjust other parameters, penalty weight(r)) from \(\{1e-,1e-2,1e-1,1,10,100\}\), learning rate from \(\{1e-2,5e-3,1e-3,5e-4,1e-4\}\) and weight decay from \(\{1e-2,5e-3,1e-3\}\). We also provide parameter sensitivity of environment number \(k\) in the paper. Moreover, the \(\rho\) is a two-layer MLP with the hidden channel from \(\{16,32,64\}\), and its learning rate should be lower than the backbone in our experiments, within the range from \(\{5e-3,1e-3,5e-4,1e-4\}\).

Figure 7. Parameter Sensitivity of environmental numbers \(k\) under Standard Settings.