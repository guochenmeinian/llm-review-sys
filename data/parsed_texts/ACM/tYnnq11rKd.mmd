# Dealing with Noisy Data in Federated Learning: An Incentive Mechanism with Flexible Pricing

###### Abstract.

Federated Learning (FL) has emerged as a promising training framework that enables a server to effectively train a global model by coordinating multiple devices, i.e., clients, without sharing their raw data. Keeping data locally can ensure data privacy, but also makes the server difficult to assess data quality, leading to the noisy data issue. Specifically, for any given taring task, only a portion of each client's data is relevant and beneficial, while the rest may be redundant or noisy. Training with excessive noisy data can degrade performance. Motivated by this, we investigate the limitations of existing studies and develop an incentive mechanism with flexible pricing tailored for noisy data settings. The insight lies in mitigating the impact of noisy data by selecting appropriate clients and incentivizing them to clean their data spontaneously. Further, both rigorous theoretical analysis and extensive simulations compared with state-of-the-art methods have been well-conducted to validate the effectiveness of the proposed mechanism.

Federated learning, noisy data, incentive mechanism +
Footnote †: ccs: Computing methodologies Distributed computing methodologies

+
Footnote †: ccs: Computing methodologies Distributed computing methodologies

+
Footnote †: ccs: Computing methodologies Distributed computing methodologies

+
Footnote †: ccs: Computing methodologies Distributed computing methodologies

+
Footnote †: ccs: Computing methodologies Distributed computing methodologies

+
Footnote †: ccs: Computing methodologies Distributed computing methodologies

+
Footnote †: ccs: Computing methodologies Distributed computing methodologies

+
Footnote †: ccs: Computing methodologies Distributed computing methodologies

+
Footnote †: ccs: Computing methodologies Distributed computing methodologies

+
Footnote †: ccs: Computing methodologies Distributed computing methodologies

## 1. Introduction

In recent years, Federated Learning (FL) has emerged as a promising decentralized training framework. It leverages the power of multiple devices, referred to as clients, to collectively train a global model without sharing clients' local data, thereby ensuring both efficiency and privacy (Krishnamurthy et al., 2018). Consequently, FL has been extensively studied and applied in various fields (Bahdanau et al., 2014; Krizhevsky et al., 2012; Krizhevsky et al., 2012).

Typically, a FL system incorporates two main components: a _server_ and multiple _clients_. The server trains a global model by iteratively coordinating clients over finite rounds. At each round, clients perform local training, produce local models, and communicates them back to the server for aggregation. Throughout this process, raw data remains stored locally on the clients, thereby preserving data privacy. This, however, also prevents the server from assessing the data quality, giving rise to the _noisy data issue_.

More precisely, given a specific task like handwritten digit recognition (Krizhevsky et al., 2012), the printed digits included in each client's local dataset can be regarded as the redundant and noisy data. Evidently, including such noisy data, specifically when it is associated with the same labels as relevant data, will mislead and manipulate the training process unpredictably, significantly degrading the FL performance as depicted in Fig. 1.

This noisy data issue was first proposed and studied by Tuor _et al._(Tuor et al., 2018). They introduced a centralized benchmark model trained on a small, task-specific dataset to select relevant data for each client during local training. In contrast, Nagalapatti _et al._(Nagalapatti et al., 2018) developed FLRD, which allows clients to train their own relevant data selection models, further facilitating local training. Different from these methods (Nagalapatti et al., 2018; Tuor et al., 2018) that focus on the local training phase, Li _et al._(Li et al., 2018) considered the aggregation phase and proposed a learning-based reweighting approach that adjusts the weight for each training sample. However, we argue that existing studies still have notable limitations in practical scenarios, say, they all relied on auxiliary, task-specific datasets to tackle the issue, incurring additional training costs and reduced generality.

Motivated by this, we explore a novel perspective to address the noisy data issue: an incentive mechanism approach. An incentive mechanism typically comprises two phases: the client selection phase that picks clients for local training and the pricing phase that determines payments to compensate clients' expense (Nagalapatti et al., 2018). Its feasibility and effectiveness lie in alleviating the negative impact of noisy data by selecting clients with low noise and high complementarity during the selection phase, and by incentivizing clients to clean their noisy data spontaneously by paying suitably in the pricing phase.

Designing such a mechanism tailored for noisy data issues presents several specific challenges. One essential step before client selection is to detect and measure the noise level of each client for various training tasks. To enhance generality, we avoid relying on prior knowledge, such as the auxiliary datasets used in (Nagalapatti et al., 2018; Tuor et al., 2018). This makes accurately detecting noisy data becomes even more difficult. Thus, the first challenge emerges as _designing a noise detection

Figure 1. Components of defined noise score.

policy that effectively balances the trade-off between accuracy and uncertainty_.

Merely detecting the noise level is insufficient, specifically when detection accuracy cannot be ensured without prior knowledge. To this end, we further tackle the noisy data issue in the client selection phase. In addition to considering the noisy levels of clients, we also focus on leveraging the complementarity between clients to counteract the negative impact of noisy data on local training. Unfortunately, clients' complementarity is unknown in advance, making it challenging to choose appropriate client sets. One possible solution is to iteratively explore and try different client sets over rounds and observe their actual training utility. However, one cannot consistently explore new client sets; it is also important to exploit and choose those client sets that have performed well previously, to facilitate the final training performance. Therefore, _the second challenge is to select low-noise clients while balancing the trade-off between exploration and exploitation_.

After selection, we tend to pay these selected clients for two goals. One is to cover their expense to motivate them join FL, i.e., individual rationality. Another one is further incentivizing clients to clean their noisy data spontaneously. Existing incentive mechanisms can successfully achieve the first goal by paying clients based on their costs, which are submitted by themselves via the reverse-auction framework (Kumar et al., 2017; Liu et al., 2018; Liu et al., 2018). They also ensure clients to submit their true costs rather than lies, i.e., truthfulness. However, these existing mechanisms fail to further achieve the second goal as they cannot accurately control the produced payments. Hence, _the third challenge is to price accurately and flexibly, thereby incentivizing clients to clean their noisy data while enforcing truthfulness_.

To overcome these challenges, we develop a novel Flexible Pricing based Incentive mechanism tailored for Noisy FL settings (FPIN). For the first challenge, FPIN presents a noise detection policy, which allows the server to measure and quantify the noise level of a client based on the discrepancy between its submitted local model and the aggregated global model. This policy merely relies on each client's local model rather than an auxiliary dataset, enhancing generality of FPIN. For the second challenge, FPIN includes a selection policy, which utilizes a combinatorial bandit based online learning method to effectively balances exploring unknown and potential client sets with exploiting low-noise and high-complementarity client sets. Actually, this policy iteratively gains useful knowledge from making mistakes over rounds, ultimately facilitating the training performance. For the third challenge, FPIN contains a pricing policy, which can flexibly and dynamically control the payment produced for selected clients based on their noise levels. This thereby encourages clients to clean their own data while achieving both truthfulness and individual rationality. Finally, FPIN's effectiveness is validated through both theoretical analysis and experimental simulations. Our contributions are summarized as follows:

* **Problem.** As far as we know, we are the first to address the noisy data issue from an incentive prospective. The insight lies in selecting low-noise clients, utilizing complementarity between them, and encouraging them by suitable payments.
* **Method.** We carefully study the impact posed by noise data and develop a Flexible Pricing based Incentive mechanism tailored for Noisy FL settings (FPIN), including a noise detection policy, a client selection policy, and a pricing policy.
* **Analysis.** We provide crucial guarantees of FPIN through theoretical analysis. It includes selection regret bound, truthfulness, individual rationality, noise robustness, and convergence rate of the whole training process.
* **Simulation.** We conduct extensive experimental simulations based on real-world datasets compared with well-known benchmarks. The results align with our theoretical findings and illustrate the effectiveness of FPIN.

The rest of the paper is organized as follows. We review related works in Section 2, introduce the system model, and formulate the analyzed problems in Section 3.We design our framework in Section 4. The effectiveness of the framework is evaluated in Section 5 theoretically and in Section 6 numerically. The paper is concluded in Section 7. Appendices are shown in Section 8.

## 2. Related Work

### Noise in FL

The noisy label problem has been widely analyzed in federated learning to effectively improve the robustness of the system. In the beginning, Tuor et al.(Tuor et al., 2018) proposed a distributed method that uses a small benchmark model to evaluate the relevance of data samples at each client, and then only selects the relevant data to participate in the federated learning process. Unlike previous approaches, FLRD introduced by Nagalapatti et al.(Nagalapatti et al., 2018) allows clients to build their own models for relevant data selection, leading to more efficient local training. Li et al.(Li et al., 2018) introduced FedDiv, which extracts knowledge from all clients to facilitate federated noise filtering. Previous research has mainly focused on the local training phase, emphasizing client-side model optimization while often overlooking the challenges of global model aggregation and the effects of noisy clients on overall performance. Focusing on the aggregation phase, Li et al.(Li et al., 2018) proposed a learning-based weighting approach that modifies the weight assigned to each training sample. Fang et al.(Fang et al., 2018) proposed RIFL that addresses label noise by aligning heterogeneous model feedback using public data, applying a noise-tolerant loss function, and implementing a client confidence reweighting scheme for adaptive collaboration. Nonetheless, we argue that existing studies have considerable limitations in practical contexts, primarily due to its reliance on auxiliary, task-specific datasets to tackle the challenges, leading to higher training costs and diminished applicability.

### Incentive Mechanism in FL

Incentive mechanisms based on game theory, auction theory, and others have been extensively studied in federated learning. Pan et al.(Pan et al., 2018) proposes a new incentive mechanism for graph federated learning, addressing hclientful and delayed agent contributions by introducing an agent valuation function based on gradient alignment and graph diversity. Murhekar et al.(Murhekar et al., 2018) models a collaborative FL framework, introducing a budget-balanced mechanism to maximize agents' welfare, along with a protocol FedRB-BG utilizing best response dynamics. Wu et al.(Wu et al., 2018) presents an incentive-aware algorithm that offers differentiated training-time model rewardsto clients in federated learning, addressing challenges with post-training incentives and ensuring optimal model recovery. Zhang et al.(Zhang et al., 2019) proposed RRAFL, a federated learning incentive mechanism based on reputation and reverse auction, which selects participants through a reputation assessment that indirectly reflects their data quality and reliability. Lu et al.(Lu et al., 2019) presents MAGFL, a Multi-attribute Auction-based Grouped Federated Learning scheme that clusters clients, evaluates group quality, distributes economic rewards, and incorporates Adam operations to accelerate convergence. However, these existing mechanisms cannot further incentivize clients to voluntarily clean their noisy data because they cannot accurately control the payments generated.

## 3. Preliminaries

### Reverse-auction based FL System

We consider a reverse-auction based FL system, including a cloud server that acts as a buyer, denoted by \(\mathcal{S}\), and \(N\) distributed clients as the sellers, denoted by \([N]\). Products are training services that clients can provide for server \(\mathcal{S}\). Each client \(i\in[N]\) maintains a local model denoted by \(w_{i,t}\), where \(t\in[T]\) represents the \(t\)-th round given total \(T\) discrete communication rounds of this system. Also, each client is associated with a local dataset \(\mathcal{D}_{i}=\{(x_{j},y_{j}):j\in[M_{i}]\}\), where \(y_{j}\) is the ground-truth label with respect to \(x_{j}\) and \(M_{i}=|\mathcal{D}_{i}|\). In practical scenarios, there is several noise contained in \(\mathcal{D}_{i}\), i.e., the data irrelevant with the given training task, which is represented by \(\mathcal{D}_{i}^{\prime}\subseteq\mathcal{D}_{i}\), \(\forall i\in[N]\). We then provide the specific workflow of the reverse-auction based FL system.

**Cost submission.** At the beginning of each round \(t\), server \(\mathcal{S}\) solicit costs of all clients for subsequent pricing. Clients then upload their costs, denoted by \(c_{i,t}\), to represent their expense like computational consumption and communication overhead (Lu et al., 2019).

**Client selection.** Receiving costs of clients, server \(\mathcal{S}\) chooses a client set \(I_{t}\) out of total \(N\) clients according to both their costs and previous feedback on training contributions. **Local training.** These selected clients \(I_{t}\) then start local training. The loss of client \(i\) on a specific labeled example \(d=(x,y)\) is denoted as \(f_{i}(w_{i,t},d)\). The average loss over local dataset \(\mathcal{D}_{i}\) is denoted as

\[F_{i}(w_{i,t},\mathcal{D}_{i})=(1/|\mathcal{D}_{i}|)\sum_{d\in\mathcal{D}_{i}} f_{i}(w_{i,t},d) \tag{1}\]

and the local training goal of client \(i\) is to find a model \(w_{i,t}\) that yields an acceptably small average loss,

\[w_{i,t}=\arg\min_{w}F_{i}(w,\mathcal{D}_{i}). \tag{2}\]

**Global aggregation.** Local models \(w_{i,t}\) derived in Eq. 2 are then uploaded by clients in \(I_{t}\) to server \(\mathcal{S}\) and are aggregated to a global model as \(w_{t}=\sum_{i\in I_{t}}p_{i}w_{i,t}\), where the weight \(p_{i}|=|\mathcal{D}_{i}|/\sum_{k\in I_{t}}|\mathcal{D}_{k}|\). This aggregated model \(w_{t}\) is subsequently downloaded to each client. **Payment determination.** Afterward, server \(\mathcal{S}\) determines payments for selected clients based on their costs and contributions, denoted by \(p_{i,t},\forall i\in I_{t}\). After the five phases mentioned above, round \(t\) terminates and the next round \(t+1\) starts. All FL rounds ultimately end as the global model \(w_{T}\) convergences at round \(T\). Therefore, the final training goal of FL is to find a global model \(w_{T}\) such that

\[w_{T}=\arg\min_{w}\sum_{i\in I_{t}}p_{i}F_{i}(w,\mathcal{D}_{i}). \tag{3}\]

We primarily focus on client selection and payment determination phases of the FL system in this paper, which are modeled as follows.

### Selection Model

The insight of the selection phase is to sample clients with both low noise and high contribution to training. We define the noise score \(l_{i}=l(\mathcal{D}_{i})\) to represent noise levels of client \(i\in[N]\) and which will be precisely quantified in subsequent sections. A higher value of \(l_{i}\) indicates a greater noise level. Afterward, to measure clients' contributions to training, the optimal approach is to use their importance \(|\mathcal{D}_{i}|\sqrt{\frac{1}{|\mathcal{D}_{i}|}\sum_{d\in\mathcal{D}_{i}} \|\nabla f_{i}(w_{i,t},d)\|^{2}}\), where \(\nabla f_{i}(w_{i,t},d)\) is the L2-norm of the gradient of a given sample \(d\in\mathcal{D}_{i}\)(Chen et al., 2019). However, this approach is impractical as calculating this importance introduces too much extra computational time. Instead, we utilize a pragmatic variant of this importance to represent the statistical utility inspired by (Chen et al., 2019; Chen et al., 2019). We further consider the noise level and formally define the statistical utility in Definition 1. The insight is a larger gradient norm intuitively yields a higher loss. Also, the selection policy is given in Definition 2.

**Definition 1** (Statistical utility).: _Reflecting both the importance and noise level, the statistical utility of a client \(i\in[N]\) at round \(t\in[T]\) is formally represented by_

\[u_{i,t}=\frac{|\mathcal{D}_{i}|}{l(\mathcal{D}_{i})}\sqrt{\frac{1}{|\mathcal{D} _{i}|}\sum_{d\in\mathcal{D}_{i}}f_{i}(w_{i,t},d)^{2}}. \tag{4}\]

_All statistical utilities of client \(i\) up to round \(t\) can be denoted by a sequence \(U_{i,t}=\{u_{i,t}:i\in I_{t},\tau\in[1:t]\}\), where \(I_{t}\) represents the client set selected at communication round \(\tau\)._

**Definition 2** (Selection Policy).: _Given the cost set \(C_{t}=\{c_{i,t}:i\in[N]\}\), the utility set \(\mathcal{U}_{t}=\{u_{i,t}:i\in[N]\}\), and the cardinality constraint \(K\), a selection policy \(\pi_{s}\) assists server \(S\) in sampling a client set \(I_{t}\) to optimize the global model, i.e., \(\pi_{s}(C_{t},\mathcal{U}_{t},K)=I_{t}\)._

### Pricing Model

In the system, we assume that all clients are rational and selfish (Shen et al., 2019), indicating that each client \(i\in[N]\) may declare a false cost \(c^{\prime}_{i,t}\neq c_{i,t}\) to get more payments. This results in unfair competition among clients, thereby degrading the training performance. To prevent such strategic behaviors, cover clients' expense, and incentivize clients to clean noise, the pricing policy \(\pi_{p}\) should be designed to achieve truthfulness, individual rationality, and noise robustness. Formally, we define the pricing policy in Definition 3 and these properties in Definitions 4-6.

**Definition 3** (Pricing policy).: _The pricing policy \(\pi_{p}\) is utilized by server \(\mathcal{S}\) to determine the payment for each client in \(I_{t}\), i.e., \(\pi_{p}(c_{i,t},C_{-i,t},\mathcal{U}_{t},\kappa)=p_{i,t},\forall i\in I_{t}\), where \(C_{-i,t}=C_{t}\setminus\{c_{i,t}\}\)._

**Definition 4** (Truithfulness).: _The pricing policy \(\pi_{p}\) achieves truthfulness if for any fake cost \(c^{\prime}_{i,t}\in\mathbb{R}\) and \(c^{\prime}_{i,t}\neq c_{i,t}\), it holds that_

\[\pi_{p}(c_{i,t},C_{-i,t},\mathcal{U}_{t},K)\geq\pi_{p}(c^{\prime}_{i,t},C_{-i,t}, \mathcal{U}_{t},K),\forall t\in[T]. \tag{5}\]

_This implies that being truthful is the dominant strategy for clients._

**Definition 5** (Individual rationality).: _The pricing policy \(\pi_{p}\) is individually rational if for any client \(i\in[N]\), it holds that_

\[\pi_{p}(c_{i,t},C_{-i,t},\mathcal{U}_{t},K)\geq c_{i,t},\forall t\in[T]. \tag{6}\]

_This ensures that the payment is sufficient to cover clients' expense._

**Definition 6** (Noise robustness).: _The pricing policy.\(\pi_{p}\) achieves noise robustness in noisy \(\bar{\mathbf{L}}\) if for any client \(i\in[N]\), it holds that_

\[\pi_{p}(c_{i,t},C_{-i,t},\mathcal{U}_{t},K)-c_{i,t}\leq l(\mathcal{D}_{i}), \forall t\in[T]. \tag{7}\]

_This indicates that the client with low noise levels can obtain a better award in addition to the part covering the cost._

### Problem Formulation

The key problem involved in selection and pricing phases is to develop policy \(\pi_{s}\) and policy \(\pi_{p}\). For \(\pi_{s}\), it aims to select clients with high statistical utilities at each round iteratively, further maximizing the expected cumulative utility \(\mathbb{E}[U_{\pi_{s}}(T)]\) over total \(T\) rounds. This problem is referred to as the _noisy client selection problem_, i.e.,

\[\text{Maximize}:\mathbb{E}[U_{\pi_{s}}(T)]=\mathbb{E}[\sum_{t\in[T]}\sum_{i\in[ N]}x_{i,t}u_{i,t}], \tag{8}\]

\[\text{Subject to}: x_{i,t}\in\{0,1\},\forall i\in[N],t\in[T], \tag{9}\]

\[|I_{t}|=K,I_{t}\subseteq[N]. \tag{10}\]

In Eqs. 8 and 9, \(x_{i,t}\) is an binary indicator denoting whether a client \(i\) is selected at round \(t\), where \(1\) for selected and \(0\) for not selected. \(I_{t}\subseteq[N]\) is the client set selected at each round \(t\), i.e., \(x_{i,t}=1,\forall i\in I_{t}\). Eq. 10 indicates the cardinality constraint. It can be observed that maximizing the cumulative utility over \(T\) rounds is substantially equivalent to minimizing its regret \(\mathcal{R}_{\pi_{s}}(T)\), which is defined as the utility difference between policy \(\pi_{s}\) and the optimal policy \(\pi_{s}^{*}\),

\[\mathcal{R}_{\pi_{s}}(T)=w_{\pi_{s}^{*}}(T)-\mathbb{E}[w_{\pi_{s}}(T)], \tag{11}\]

where \(w_{\pi_{s}^{*}}(T)\!=\!\max_{I\subseteq[N],I\!=\!K}\sum_{t\in[T]}\sum_{i\in[N] }u_{i,t}\) is the cumulative utility of consistently selecting the best \(K\)-size client set. For policy \(\pi_{p}\), it aims to pay clients flexibly and accurately in order to achieve truthfulness, individual rationality, and noise robustness. This is referred to as the _flexible pricing problem_.

## 4. Mechanism Design of FPIN

We describe here the details of Flexible Pricing based Incentive mechanism tailored for Noisy FL settings (FPN).

### Noise Level Detection

Accurately detecting the noise levels \(l(\mathcal{D}_{i})\) of each client is crucial for the following selection and pricing phases. However, as we mentioned above, previous studies either rely on auxiliary datasets (Zhou et al., 2017; Zhang et al., 2018) or require all clients to join a pre-training process for noise detection (Zhou et al., 2017), leading to impracticality for FL applications.

We aim to explore a practical approach for identifying clients' noise levels. Pre-simulations reveal that, during the training process, clients with high noise levels consistently exhibit a local model that diverges more significantly from the global model compared to low-noise and clean clients. Based on these findings, we let the noise level \(l(\mathcal{D}_{i})\) for client \(i\) be proportional to the discrepancy of the aggregated global model and the local model. Specifically, \(l(\mathcal{D}_{i})\propto\|w_{t}-w_{i,t}\|^{2}\), where \(\|w_{t}-w_{i,t}\|^{2}\) represents the Euclidean distance between two model parameters \(w_{t}\) and \(w_{i,t}\).

Yet, only the model discrepancy cannot describe the noise level sufficiently. Studies on deep learning have revealed two phases of the model evolution: The former is dimensionality compression that captures underlying data distribution, while the latter is dimensionality expansion that enables the model to fit clean or noisy data (Bishop, 2006; Goodfellow et al., 2016; Goodfellow et al., 2016). Based on this evidence, they demonstrate the effectiveness of using Cross-Entropy (CE) loss to exhibit the data quality between noisy and clean labels. Following this insight, we let the noise level \(l(\mathcal{D}_{i})\) also be proportional to CE loss on each client's local model, i.e., \(l(\mathcal{D}_{i})\propto\mathbb{CE}(y,\tilde{y})\). As shown in Fig. 3, combining the analysis above yields the formal definition of the _noise score_,

\[l(\mathcal{D}_{i})=-\|w_{t}-w_{t,t}\|^{2}\sum_{(x_{i},y_{j})\in\mathcal{D}_{i} }y_{j}\log y_{i}(w_{i,t},x_{j}),\forall i,t. \tag{12}\]

Here, \(y_{i}(\cdot,\cdot)\) represents the learning model kept by client \(i\), which can produce a predicted label \(\hat{y}_{j}\) given a sample data \(x_{j}\). This noise score has been evaluated using various datasets in a noisy FL setting, in which the noise is simulated using Guassian distributions. The results are depicted in Fig. 2, where x-axis represents the actual imposed noise level. It can be observed that the defined noise level \(l(\mathcal{D}_{i})\) precisely aligns with the actual noise level in most cases. This highlights the feasibility and accuracy of \(l(\mathcal{D}_{i})\). Note that, as marked by the red box, only a few cases exhibit inconsistency. However, this is acceptable, as we will further address and mitigate the noise issue in the subsequent phases of FPN.

### Noisy Client Selection

In order to enhance the performance of noisy FL settings, the key in the selection phase is to select as appropriate client sets with low noise and high contributions as possible. To this end, we have proposed in Definition 1 the statistical utility \(u_{i,t}\) that measures both the data quality and noise level of clients. A simple method is to directly select the top-\(K\) clients with the highest value of \(u_{i,t}\). However, this method requires all clients to participate in the local training at each round and produces \(u_{i,t},\forall i\in[N],\forall t\in[T]\) cooperated with Server \(\mathcal{S}\). This is impractical in real-world application scenarios because this method yields too much training cost and communication overhead, especially when total clients are sufficiently large.

As a result, we allow in this paper server \(S\) to select the client set \(I_{t}\) based on clients' previous utilities, like utility mean, instead of the last utility solicited from all clients at the current round. Clients just need to calculate their utilities when selected, thereby reducing a great deal of consumption. However, merely using the utility mean also raises a concern: several potential clients may not be selected all the time due to they does perform well at the former

Figure 3. The components of defined noise score.

Figure 2. An illustration on the relationship between actual noise levels and the defined noise score on various datasets.

rounds. To address this concern, we modify the utility mean by including an additive term as follows:

\[\rho_{i,t}=\bar{u}_{i,L}+e_{i,t}\text{ and }e_{i,t}=\frac{c_{min}+u_{max}}{c_{min}} \sqrt{\frac{(K+1)\ln t}{|U_{i,t-1}|}}. \tag{13}\]

We then formally refer to \(\rho_{i,t}\) as the _modified mean_. Here, \(U_{i,t}\) is the statistical utility sequence presented in Definition 1 and \(|U_{i,t-1}|\) represents the number of times client \(i\) has been selected in the first \(t-1\) rounds. Then, \(\bar{u}_{i,t}=\sum_{u\in U_{i,t},u}1/|U_{i,t-1}|\) is the empirical mean of client \(i\)'s statistical utilities, \(c_{min}=\min_{i\in[N],t\in[T]}\bar{e}_{i,t}\), \(u_{max}=\min_{i\in[N],t\in[T]}\bar{u}_{i,t}\), and \(e_{i,t}\) is the exploration term. We can find that a client's modified mean will gradually increase over rounds if it is not selected consistently, i.e., \(|U_{i,t-1}|\) remains unchanged, until this client is selected. This means term \(e_{i,t}\) performs well in exploring potential clients.

We next provide a detailed description of our mechanism FPIN in Algorithm 1. We begin with initializing the model of each client with \(w_{0}\) and selecting all clients once to update the necessary variables \(u_{i,L}\), \(U_{i,t}\), \(e_{i,t}\), and \(l(\mathcal{D}_{l})\) for the first selection (lines 1-3). In the iterative part (lines 4-17), each communication round \(t>1\) primarily includes three phases. All clients reveal their costs \(c_{i,t}\) to sever \(\mathcal{S}\) at the cost submission phase. Then the top \(K\) clients with the highest value of \(\rho_{i,t}/e_{i,t}\) are selected at the client selection phase. At the local training phase, each selected client \(i\in I_{t}\) trains its local model, updates necessary variables, and uploads \(w_{i,L},u_{i,L}\) to sever \(\mathcal{S}\) (lines 8-13), while other clients \(|N|\)\(l_{t}\) remain unchanged (line 14). At the aggregation phase, server \(\mathcal{S}\) aggregates models from the selected clients using FedAVG (line 15) and communicates the aggregated model \(w_{t}\) back. Finally, server \(\mathcal{S}\) pays each selected client with payment \(p_{i,t}\) decided using pricing policy \(\pi_{p}\) (line 16), which will be described in the following section. These phases above run iteratively until round \(T\), yielding final global model \(w_{T}\).

```
Input: Cardinality constraint \(K\), selected client set \(I_{t}\), cost set \(\mathcal{C}_{i,t}\), utility set \(\mathcal{U}_{t}\), an arbitrary constant \(\theta\) Output: Payment \(p_{k,t}\) for client \(k\in I_{t}\)
1 Compute \(\rho_{i,t},\forall i\in[N]\) based on \(\mathcal{C}_{i,t}\), \(\mathcal{U}_{t}\) according to Eq. 13;
2 Sort clients in descending order with respect to \(\rho_{i,t}/e_{i,t}\);
3 Compute the critical value \(p^{c}_{k,t}\leftarrow\frac{\rho_{k,t}}{\rho_{k,t}}e_{k+1,t}\);
4 Search a client \(j\) satisfying that \(\rho_{j,t}/e_{j,t}<\rho_{k,t}/e_{k,t}\) while\(\rho_{j,t}>\rho_{k,t}\), and let \(p^{\prime}_{k,t}\leftarrow\frac{\rho_{k,t}}{\rho_{j,t}}e_{j,t}\); \(\tau\leftarrow\) 0;
5while\(\rho_{j,t}/e_{j,t}<\rho_{k,t}/e_{k,t}\)do
6foreach client \(i\in[N]\)do\(e_{i,t}\leftarrow\epsilon_{i,t}+\theta\);
7 Sort clients in descending order with respect to \(\rho_{i,t}/e_{i,t}\) again;
8\(\gamma\leftarrow\gamma+1\);
9\(\gamma_{0}\leftarrow\gamma\); \(p^{\prime}_{k,t}\gets p^{\prime}_{k,t}-(\gamma_{0}-1)(1-\frac{\rho_{k,t}} {\rho_{j,t}})\theta\); return\(p_{k,t}=\min(p^{\prime}_{k,t},p^{c}_{k,t})\)
```

**Algorithm 2**Flexible pricing policy, i.e., \(\pi_{p}\)

In this section, we focus on designing a pricing policy \(\pi_{p}\) in FPIN to prevent clients' strategic behaviors, compensate their expense, and incentive them to clean noise spontaneously. The details of \(\pi_{p}\) are described in Algorithm 2. Assuming to determine the payment for client \(k\), we first sort all clients based on their mean-cost ratio \(\rho_{i,t}/e_{i,t}\). Then a classic Myerson's critical value \(p^{c}_{k,t}\) is derived for comparison, where \(\rho_{K+1,t}\) and \(e_{K+1}\) are the modified utility and cost of the \((K+1)\)-th client in the sorted sequence, which is essentially the first client not selected by server \(\mathcal{S}\). Next, we try to search a client \(j\) with a lower mean-cost ratio \(\rho_{j,t}/e_{j,t}\) and a higher modified mean \(\rho_{j,t}\) compared to client \(k\) (line 4). Table 1 illustrates that the success rate of finding such a client is satisfactory. We then initialize a temporary payment \(p^{\prime}_{k,t}\) as \((p_{k,t}/p_{j,t})e_{j,t}\) and a counter \(\gamma\) as 0 for following calculation. When such a client \(j\)'s mean-cost ratio is less than that of client \(k\), Algorithm 2 enters the iterative part (lines 5-8). Here, each client's cost is updated by adding the noise score \(l(\mathcal{D}_{l})\). We then re-sort clients in descending order and update counter \(\gamma\) until client \(j\)'s mean-cost ratio becomes no less than that of client \(k\). Finally, we get client \(k\)'s payment of \(p_{k,t}=\min\{p^{\prime}_{k,t},p^{c}_{k,t}\}\).

\begin{table}
\begin{tabular}{c|c c c c c} \hline \hline \(N\) & \(10^{1}\) & \(10^{2}\) & \(10^{3}\) & \(10^{4}\) & \(10^{5}\) \\ \hline \# find \(j\) & 456 & 785 & 926 & 974 & 992 \\ \hline \# not find \(j\) & 554 & 215 & 74 & 26 & 8 \\ \hline Success rate & 45.6\% & 78.5\% & 92.6\% & 97.4\% & 99.2\% \\ \hline \hline \end{tabular}
\end{table}
Table 1. The frequency of finding client \(j\)

## 5. Theoretical Analysis

In this section, we start by proving the truthfulness, individual rationality, and noise robustness of the pricing policy \(\pi_{p}\) in Theorems 1-3. Next, we provide a convergence analysis of FPIN in Theorem 4.

### Analysis on Pricing

**Theorem 1**.: _The payment determined by \(\pi_{p}\) for each client \(i\in[N]\) achieves asymptotic truthfulness._

Proof.: We begin by proving that the selection policy \(\pi_{s}\) in Algorithm 1 (lines 6-7) is cost-monotonic. A selection policy is considered cost-monotonic (Zhou et al., 2017), when a client is selected based on its mean-cost ratio \(\rho_{i,t}/c_{i,t}\), this client will also be selected with a different mean-cost ratio \(\rho_{i,t}/c^{\prime}_{i,t}\), where \(c^{\prime}_{i,t}<c_{i,t}\). According to Algorithm 1, selecting client \(i\) indicates that \(\rho_{i,t}/c_{i,t}>\rho_{K+1,t}/c_{K+1,t}\), where \(\rho_{K+1,t}\) and \(c_{K+1,t}\) are the modified mean and cost of the \((K+1)\)-th client in the sorted clients. If client \(i\)'s cost is decreased from \(c_{i,t}\) to \(c^{\prime}_{i,t}\), it still holds that \(\rho_{i,t}/c^{\prime}_{i,t}>\rho_{K+1,t}/c_{K+1}\). Thus, the selection policy \(\pi_{s}\) in Algorithm 1 is cost-monotonic. Furthermore, we provide two cases to demonstrate the truthfulness of \(\pi_{s}\).

**Case 1:** When \(\rho_{k,t}=p^{c}_{k,t}\), we prove that \(p^{c}_{k,t}\) ensures truthfulness. Assume that a client \(i\) is selected when it truthfully submits its cost \(c_{i,t}\), yielding a profit of \(\beta=p^{c}_{k,t}-c_{i,t}\). If client \(i\) submits a fake cost \(c^{\prime}_{i,t}\neq c_{i,t}\), there are two possible outcomes with the new mean-cost ratio \(\rho_{i,t}/c^{\prime}_{i,t}\). (1) Client \(i\) is selected, and its profit is still \(\beta^{\prime}_{1}=p^{c}_{i,t}-c_{i,t}\), as client \(i^{\prime}\)'s payment does not rely on its own cost \(c_{i,t}\) according to Algorithm 2. (2) Client \(i\) is not selected, resulting in a profit of \(\beta^{\prime}_{2}=0\). Note that we will prove \(p^{c}_{i,t}-c_{i,t}>0\) in Theorem 2. Therefore, we have \(\beta>\max\{\beta^{\prime}_{1},\beta^{\prime}_{2}\}\), indicating that client \(i\) can maximize its profit by truthfully submitting its cost \(c_{i,t}\).

Similarly, assume that a client \(i\) is not selected when submitting its cost \(c_{i,t}\), truthfully and its profit is \(\beta=0\) now. If client \(i\) declares a fake cost \(c^{\prime}_{i,t}\), there are two possible outcomes. (1) Client \(i\) is not selected, leading to a profit of \(\beta^{\prime}_{1}=0\). (2) Client \(i\) is selected, and its profit is \(\beta^{\prime}_{2}=p^{c}_{i,t}-c_{i,t}\) now. When client \(i\)'s mean-cost ratio changes from \(\rho_{i,t}/c_{i,t}\) to \(\rho_{i,t}/c^{\prime}_{i,t}\), there must be a client whose mean-cost ratio is exceeded by client \(i\). Without loss of generality, we assume that client is \(j\in[N]\), and the following holds

\[\rho_{i,t}/c^{\prime}_{i,t}\geq\rho_{K+1,t}/c_{K+1,t}\geq\rho_{j,t}/c_{j,t}>\rho _{i,t}/c_{i,t}. \tag{14}\]

Then, client \(i\) gets the payment of

\[p^{c}_{i,t}=(\rho_{i,t}/c_{i,t})c_{K+1,t}<(\rho_{K+1,t}/\rho_{K+1,t})c_{i,t}=c _{i,t}. \tag{15}\]

We thus have \(\beta>\max\{\beta^{\prime}_{1},\beta^{\prime}_{2}\}\), meaning client \(i\) achieves maximum profit by truthfully submitting its cost \(c_{i,t}\).

**Case 2:** When \(\rho_{k,t}=p^{c}_{k,t}\), we prove that \(p^{c}_{k,t}\) ensures asymptotic truthfulness. According to Definition 4 and Algorithm 2, a selected client \(i\in I_{t}\) who submits the cost truthful will receive a payment of \(p^{c}_{i,t}\). If client \(i\) is not truthful, the maximum payment it can receive is \(p^{c}_{i,t}\) under the Myerson-based pricing strategy (Shen et al., 2017). Consequently, we say that \(p^{c}_{i,t}-p^{c}_{i,t}=o(p^{c}_{i,t})\) holds since, for any constant \(i\), we can find a constant \(\epsilon=(p^{c}_{i,t}-c_{i,t})/\lambda\) such that \(p^{c}_{i,t}-p^{c}_{i,t}\times\lambda p^{c}_{i,t},\forall p^{c}_{i,t}>\epsilon\). This is because \(p^{c}_{i,t}-p^{c}_{i,t}<p^{c}_{i,t}-c_{i,t}\) due to Eq. 23 in Theorem 3. 

**Theorem 2**.: _The payment determined by \(\pi_{p}\) for each client \(i\in[N]\) achieves individual rationality._

Proof.: Individual rationality indicates that each client \(i\in[N]\) can obtain a payment \(p_{i,t}\) that is no less than its cost \(c_{i,t}\). In line 3 of Algorithm 2, we get the critical value \(p^{c}_{k,t}=(\rho_{k,t}/\rho_{K+1,t})c_{K+1,t}\) for client \(k\). Since client \(k\) is selected among the top \(K\) clients, we have \(\rho_{k,t}/c_{k,t}\geq\rho_{K+1,t}/c_{K+1,t}\). It then follows that the critical value \(p^{c}_{k,t}\geq c_{k,t}\) and we have \(p^{c}_{k,t}>c_{k,t}\) in Eq. 23. Thus, the payment ensures \(p_{k,t}\)\(=\min\{p^{c}_{k,t},p^{c}_{k,t}\}\geq c_{k,t}\), which completes the proof. 

**Theorem 3**.: _The payment determined by \(\pi_{p}\) for each client \(i\in I_{t}\) achieves noise robustness, i.e., \(p_{i,t}<c_{i,t}+\theta\)._

Proof.: As described in Algorithm 2 (line 4), we search a client \(j\) satisfying that \(\rho_{k,t}/c_{k,t}>\rho_{j,t}/c_{j,t}\). Then it holds that

\[p^{c}_{k,t}=(\rho_{k,t}/\rho_{j,t})c_{j,t}>c_{k,t}. \tag{16}\]

We define a function \(h(x)=\frac{\rho_{k,t}}{\rho_{j,t}}(\rho_{j,t}+x\theta)-(c_{k,t}+x\theta)\). Then,

\[h(0)=(\rho_{k,t}/\rho_{j,t})c_{j,t}-c_{k,t}>0, \tag{17}\]

\[h(\eta_{0}-1)=(\rho_{k,t}/\rho_{j,t})(c_{j,t}+\eta_{0})\theta)-(c_{k,t}+(\eta_{0 }-1)\theta)>0, \tag{18}\]

\[h(\eta_{0})=(\rho_{k,t}/\rho_{j,t})(c_{j,t}+\eta_{0})\theta)-(c_{k,t}+\eta_{0}) \leq 0, \tag{19}\]

where \(\eta_{0}\) is the counter that indicates the termination of the while loop in line 5. The inequality in Eq. 17 holds due to Eq. 16, while Eqs. 18-19 hold since, according to Algorithm 2 (line 5), the while loop terminates when \(\rho_{j,t}/(c_{j,t}+\eta_{0})\theta\geq\rho_{k,t}/(c_{k,t}+\eta_{0})\theta\). When \(\gamma=\eta_{0}-1\), the while loop does not terminate, and it holds that \(\rho_{j,t}/(c_{j,t}+\varphi\theta)<\rho_{k,t}/(c_{k,t}+\vartheta)\). According to Eqs. 17-19, it follows

\[h(\eta_{0}-1)=(\rho_{k,t}/\rho_{j,t})c_{j,t}-c_{k,t}-(1-\rho_{k,t}/\rho_{j,t})(\eta _{0}-1)\theta>0, \tag{20}\]

\[h(\eta_{0})=(\rho_{k,t}/\rho_{j,t})c_{j,t}-c_{k,t}-(1-\rho_{k,t}/\rho_{j,t})\eta _{0}\theta\leq 0 \tag{21}\]

Therefore,

\[(1-\frac{\rho_{k,t}}{\rho_{j,t}})(\eta_{0}-1)\theta+c_{k,t}<\frac{\rho_{k,t}}{\rho _{j,t}}c_{j,t}\leq(1-\frac{\rho_{k,t}}{\rho_{j,t}})\eta_{0}\theta+c_{k,t}. \tag{22}\]

Due to the definition of \(p^{\prime}_{k,t}\) in Algorithm 3 (lines 3 and 9), we have

\[c_{k,t}<p^{c}_{k,t}\leq(1-\rho_{k,t}/\rho_{j,t})\theta+c_{k,t}. \tag{23}\]

Since \(\rho_{j,t},\rho_{k,t}>0\) by Eq. 13, we have \(p_{k,t}\leq p^{c}_{k,t}<c_{k,t}+\theta\). By assigning a specific noise score \(\theta\) such that \(\theta\times(1/(2))\), the payment determined by \(\pi_{p}\) can ensure \(p_{k,t}-c_{k,t}<\phi(1/(2))\), in which \(\phi(\cdot)\) is a proportional function. This implies that a client with a lower noise level (i.e., a smaller noise score \(\theta\)) may receive more additional profit, thereby achieving noise robustness. 

### Analysis on Convergence

We provide several assumptions and additional notations motivated by previous studies (Zhou et al., 2017; Zhou et al., 2017) to analyze convergence of FPIN.

**Assumption 1**.: _The objective function \(F_{i}(\cdot),\forall i\in[N]\) is \(k\)-smooth, i.e., given any model pair, \(\nu\) and \(\varphi\), it holds that \(F_{i}(\varphi)\leq F_{i}(w)+(\varphi-w,\forall F_{i}(w))+L\|\varphi-w\|/2\)._

**Assumption 2**.: _The objective function \(F_{i}(\cdot),\forall i\in[N]\) is \(\mu\)-strongly convex, i.e., given any model pair, \(w\) and \(\varphi\), it holds that \(F_{i}(\varphi)\geq F_{i}(w)+(\varphi-w,\forall F_{i}(w))+\mu\|\varphi-w\|/2\)._

**Assumption 3**.: _The objective function \(F_{i}(\cdot),\forall i\in[N]\) is \(\mathcal{L}\)-Lipschitz continuous, i.e., given any model pair, \(w\) and \(\varphi\), it holds that \we define several additional notations to accurately display the FL process. Since every communication round \(t\in[T]\) comprises \(E\) epochs (i.e., the local training phase in lines 7-14 of Algorithm 1 in main paper), we leverage \(\varsigma\in[TE]\) to represent all involved epochs. When \(\varsigma/E\in[T]\), it implies that \(\varsigma\) is the end epoch within a round. The local training phase of each client is re-described as

\[\begin{split}\psi_{i\varsigma}&\leftarrow\text{w}_{ i\varsigma,\varsigma-1}-\eta_{\varsigma-1}\nabla F_{i}(d_{i},w_{i\varsigma-1}), \end{split} \tag{24}\]

\[\begin{split}\psi_{i\varsigma}&\leftarrow\begin{cases} \varphi_{i\varsigma}&\text{if }\varsigma/E\notin[T],\\ \pi_{a}(\{\varphi_{i\varsigma},i\in I_{\varsigma}\})&\text{if }\varsigma/E\in[T].\end{cases}\end{split} \tag{25}\]

Here, \(I_{\varsigma}\) denotes the currently selected client set, i.e., \(I_{t}\) where \(t=\lceil\varsigma/E\rceil-1\). \(\pi_{a}\) is the aggregation policy using FedAvg. We denote the means of \(\varphi_{i\varsigma,\varsigma}\) and \(w_{i\varsigma}\) by \(\hat{\varphi}_{\varsigma}=\sum_{i\in[N]}p_{i}\varphi_{i\varsigma,\varsigma}\) and \(\hat{w}_{\varsigma}=\sum_{i\in[N]}p_{i}w_{i\varsigma}\) like settings in (Gilton et al., 2017). Let \(g_{\varsigma}=\sum_{i\in[N]}p_{i}\nabla F_{i}(d_{i},w_{i\varsigma})\) and \(\hat{g}_{\varsigma}=\sum_{i\in[N]}p_{i}\nabla F_{i}(w_{i\varsigma})\), where \(\nabla F_{i}(w_{i\varsigma})\) is the expected gradient over full data of client \(i\). Let \(w^{*}\) represent the optimal parameter of the global model that maximizes \(F(w^{*})\) in Eq. 2. We then provide Theorem 4 regarding FPIN's convergence rate.

Please refer to Appendix for the convergence analysis of FPIN, i.e., Theorem 4.

## 6. Simulations

### Simulation Settings

**Datasets and Models.** We perform all simulations for this paper using PyTorch on a workstation featuring an NVIDIA GeForce RTX 3090 GPU based on two widely recognized datasets, MNIST and CIFAR-10. We utilize two simple CNN models that incorporate batch normalization layers to implement FPIN. Each model consists of three blocks, with each block comprising a convolutional layer, a batch normalization layer, and a ReLU activation function. We then apply SGD optimizers, exponential decay learning rate schedulers, and cross-entropy loss functions in simulations. We also explore non-IID scenario for FPIN, where client heterogeneity is accurately modeled using the Dirichlet distribution(Krizhevsky et al., 2009). Dir(r) represents the proportions of each class allocated to each client, sampled from the Dirichlet distribution. By default, we distribute the entire dataset evenly among all clients.

**Benchmarks.** We evaluate the effectiveness of FPIN by comparing it with several well-known client selection policies.

1. **FNCL(Liu et al., 2019):** Federated Noisy Client Learning (FNCL) operates by identifying noisy clients through an accurate assessment of data quality and model divergence. To address the data heterogeneity introduced by these noisy clients, FNCL applies a robust layerwise aggregation method, which adaptively aggregates the local models from clients.
2. **Oort(Dong et al., 2019)**: This is promising FL framework that employs a bandit-style strategy for client selection. Oort indirectly enhances the diversity of datasets in FL. We initialize Oort's exploration rate at 0.9, establish its minimum exploration rate at 0.1, and define its decay factor as 0.97.
3. **FedAvg(Liu et al., 2019)**:** FedAvg employs a random policy to selects clients straightforwardly at each round. It performs local training on these selected clients and aggregates clients' local models by weighting their data volume.
4. **Loss and Cost Policy (CLP)** : A variant of the selection policy in FPIN. Considering that clients with low noise scores are beneficial for training, MCP re-designs the selection metric of clients based on two factors: clients' local loss and submitted costs, defined as \(u_{iL}\)=\((1/\text{loss}_{iL}\cdot c_{iL})\).
5. **Minimum Cost Policy (MCP)** : Another variant of FPIN, where the utility only considers the bid as a factor, selecting the client with the minimum bid.

**Parameters.** Specifically, the number of participating clients is set to \(N=40\) and \(K=8\), with a total of \(T=150\) global rounds. SGD is implemented as the local training optimizer with a learning rate of 0.01, a local batch size of 64, and local training epoch \(E=5\) for all datasets. In Gaussian noise distribution with a mean of \(\mu=0.3\) and variance of \(\sigma=0.45\).

### Simulation Results

**Effectiveness Evaluation.** We assess the performance of FPIN in comparison to other baselines in both IID and Non-IID settings, as illustrated in Fig. 4, under the conditions of noisy data from truncated Gaussian distributions. The experimental results demonstrate that FPIN outperforms the other baselines on the CIFAR-10 dataset Compared to other benchmarks, FPIN enhances accuracy by 5% to

Figure 4. The accuracy of various selection policies based on different datasets given both Non-IID and IID scenarios.

Figure 5. The accuracy of various selection policies as the number of selected clients, \(K\), is increased.

18% in the IID scenario and by 15% to 20% in the Non-IID scenario. During the training process, FPIN effectively mitigates the influence of noisy clients' models by accurately distinguishing between noisy and clean clients. The reliability score can effectively assess each client by evaluating the quality of their local model and training loss. Then, FPIN tends to select clients with low noise levels and high quality to enhance the model's performance. On the MNIST dataset, FPIN slightly outperforms other benchmark algorithms. We observe that the global model trained using MCP and MB fails to converge, as evidenced by the instability of their test accuracy curves towards the end of training in the Non-IID scenario. This instability arises because noisy clients steer the collaborative model's updates in a divergent direction during the model aggregation process.

**Selection Evaluation.** As shown in Fig. 4(a) and 4(b), we observe that as the number of selected clients increases, the accuracy of the global model also improves. However, due to differences in the difficulty of the datasets, the accuracy gap after convergence on MNIST is not significant. Oort combines top-k statistical utility sampling with random exploration to select clients. However, it cannot promptly adjust the selected client set, as clients chosen in the previous round have a higher probability of being selected again in the next round. Furthermore, the inherent randomness in client selection for FedAvg, MCP, and even FNCL contributes to the suboptimal performance of the global model. In the presence of noise, while the selection of clients of CLP with low training loss mitigates some of the noise's impact, it also discards potentially valuable clients, namely those with high training loss. Due to the concentrated client selection of CLP, the limited amount of data fitted does not optimize performance.

After applying this process, we classify the clients into high-noise clients and low-noise clients. This method allows us to accurately identify low-noise clients in the subsequent selection phase of federated learning, thereby improving overall efficiency and effectiveness. As shown in Fig. 6, notably the parameter \(\beta\) governs the sensitivity of the noisy clients, and reducing its value may lead to a decrease in the accuracy of detecting these noisy clients. Interestingly, we observed that \(\beta\) exhibited minimal sensitivity in the presence of Gaussian noise.

**Individual Rationality of FPIN.** FP can flexibly determine payments for each winner based on a factor that accounts for the level of client noise. As shown in Fig. 6(a), clients with lower noise levels receive higher payment ceilings, while clients with higher noise levels have payments closer to the \(y=x\) line. Meanwhile, this also indicates that the profit obtained by each client is non-negative. Then, the Cumulative Distribution Function (CDF) of the profits for winners is shown in Fig. 6(b). Our analysis reveals that all profits generated using FPIN are non-negative, indicating that FPIN meets the criteria for individual rationality, as demonstrated in Theorem 4. As the number of selected clients increases, the total profit per round naturally rises.

**Truthfulness of FPIN.** Additionally, we validate the performance in terms of truthfulness. In Fig. 7(a), we observe that as the declared bid increases, the winner continues to be selected, and the FPIN payment increases until it reaches the maximum value, which corresponds to the AUCB payment. However, when the bid exceeds the critical value of 5.87, the winner is no longer selected, meaning no payment is made. Thus a client will not increase its bid since it may make the client not pulled. In Fig. 7(b), we discover that the loser is initially not selected, resulting in a payment of zero. As the bid decreases below 3.72, the loser will be selected. However, the client incurs a negative profit, meaning its payment does not cover the actual cost. Therefore, clients has no incentive to misreport their costs.

## 7. Conclusion

In this paper, we closely investigate a method for detecting the level of noisy data from clients in federated learning and propose a selection strategy that prioritizes clients with low noise and high contribution. Additionally, we develop an accurate and flexible pricing mechanism that incentivizes clients to clean their noisy data while enforcing truthfulness. These approaches form FPIN, with its effectiveness validated through both theoretical analysis and numerical simulations. Simulation results demonstrate that FPIN significantly improves the performance of global model with noisy clients in both homogeneous and heterogeneous federated learning settings, while also ensuring individual rationality and asymptotic truthfulness.

Figure 8. Payments of a winner client (left part) and a loser client (right part) as their submitted cost are varied.

Figure 6. Parameter evaluation of the noise detection in FPIN with Gaussian distribution.

Figure 7. Costs and payments of clients with different noise levels (Left part). CDF of clients’ profits based on increasing numbers of selected clients (right part).

## References

* (1)
* Chen et al. (2019) Pengfei Chen, Ben Ben Liao, Gaungyong Chen, and Shengyu Zhang. 2019. Understanding and utilizing deep neural networks trained with noisy labels. In _Proc. of ICML_. 1003.
* Fang and Wang (2022) Xiuwen Fang and Mang Yang. 2022. Robust federated learning with noisy and heterogeneous clients. In _Proc. of CVPR_. 10072-10081.
* Huang et al. (2024) Wenke Huang, Meng Ye, Zekun Shi, Gaunheng Wan, He Li, Bo Du, and Qiang Yang. 2024. Federated Learning for Generalization, Robustness, Fairness: A Survey and Benchmark. _IEEE Transactions on Pattern Analysis and Machine Intelligence_ (2020), 1-20.
* Jiang et al. (2020) Linhan Jiang, Mingjun Duan, Bingheng He, Yulin Sun, Feihen Yan, Yang Hua, and Tao Song. 2020. GL-Wi-As: A One-shot Federated Learning System on Web 3. 20. _Proc. VLDB Endow._ 17, 2 (2020), 4641-4644.
* Johnson and Guestrin (2018) Tyler B Johnson and Carlos Guestrin. 2018. Training deep models faster with robust, approximate importance sampling. _Proc. of NeurIPS_ 31(5), 2018.
* Katapuoglu and Fucquet (2018) Angelos Katapuoglu and Francois Fucquet. 2018. Not all Samples Are Created Equal: Deep Learning with Importance Sampling. In _Proc. of ICML_. 2525-2534.
* Lai et al. (2021) Fan Lai, Xiangfeng Zhu, Harsha V Madhyastha, and Moshanr Chowdhury. 2021. On-efficient federated learning via guided participant selection. In _Proc. of OSDI_. 19-35.
* Levan et al. (1998) Yann Levan, Bernhard E. Boser, John S. Denker, Dominic Henderson, Richard E. Howard, Wayne E. Hubbard, and Lawrence D. J. Lucki. 1998. Handwritten Digit Recognition with a Back-Propagation Network. In _Proc. of NeurIPS_. 396-404.
* Li et al. (2024) Jichang Li, Gaunbin Li, Hui Cheng, Zicheng Luo, and Yinhou Yu. 2024. FedDiv: Collaborative Noise Filtering for Federated Learning with Noisy Labels. In _Proc. of AAAI_, vol. 338-318, 2024.
* Li et al. (2022) Junyi Li, Jian Pei, and Heng Huang. 2022. Communication-Efficient Robust Federated Learning with Noisy Labels. In _Proc. of ACM SIGKDD_. 914-924.
* Li et al. (2020) Qinbin Li, Bingheng He, and Dawn Song. 2021. Model-contrastive federated learning. In _Proc. of CVPR_. 10713-10722.
* Li et al. (2020) Xing Li, Kauran Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. 2020. On the Convergence of FedAvg on Non-ID Data. In _Proc. of ECL_.
* Li et al. (2024) Yongqi Li, Fan Li, Song Yang, Chun Zhang, Lichunang Zhang, and Yi Wang. 2024. A Cooperative Analysis to Incentivize Communication-Efficient Federated Learning. _IEEE Transactions on Mobile Computing_ 23, 10 (2020), 1075-1090.
* Lu et al. (2020) Renhao Lu, Hongwei Yang, Yang Wang, Hui Feng, Qiong Li, Xiaoxiong Zhong, and Weihle Zhang. 2020. Multi-Attribute Animation-Based Grouped Federated Learning. _IEEE Transactions on Services Computing_ 17, 3 (2020), 1065-1071.
* Ma et al. (2015) Xingjun Ma, Yisen Wang, Michael E Houle, Shuo Zhou, Sarah Erfani, Shutao Xia, Sudhun Vijayekrema, and James Bailey. 2015. Dimensionality-driven learning with noisy labels. In _Proc. of ICML_. 3355-3366.
* McMahan et al. (2017) Brendan McMahan, Lifder Moore, Daniel Ramage, Seth Hampson, and Blake Aguera J Arrossa. 2017. Communication-Efficient Learning of Deep Networks from Decentralized Data. In _Proc. of ASEATS_. 1273-1282.
* Murbaek et al. (2024) Aniket Murbaek, Zhowee Yuan, Shukhar Ray Chaudhury, De Li, and Ruta Mehta. 2024. Incentives in federated Learning: Equilibria, Dynamics, and Mechanisms for Welfare Maximization. In _Proc. of NeurIPS_. 36.
* Murbaek et al. (2024) Aniket Murbaek, Zhowee Yuan, Shukhar Ray Chaudhury, Bo Li, and Ruta Mehta. 2024. Incentives in federated learning: Equilibria, dynamics, and mechanisms for welfare maximization. In _Proc. of NeurIPS_. 363 (2024).
* Myerson (1981) Roger Boyerson. 1981. Optimal auction design. _Mathematics of operations research_. 1, (1981), 56-73.
* Nagulapath et al. (2022) Lebeda Nagulapath, Ruth Sharma Mittal, and Ramsarvi Narayanan. 2022. Is Your Data Relevant?: System selection of Relevant Data for Federated Learning. In _Proc. of AAAI_, vol. 36, 7859-7867.
* Pan et al. (2024) Chengju Pan, Jaredya Xu, Yue Yu, Ziqi Yang, Qinghua Wu, Chunping Wang, Lei Chen, and Yang Yang. 2024. Toward Fair Graph Federated Learning via Incentive Mechanisms. In _Proc. of AAAI_, vol. 18, 14499-14507.
* Roughgarden (2010) Tim Roughgarden. 2010. Algorithmic game theory. _Commun. ACM_ 53, 7 (2010), 78-86.
* U. Stich (2019) Sebastian U. U. Stich. 2019. Local SGD Converges Fast and Communicates Little. In _Proc. of ICML_.
* Uski et al. (2018) Sebastian U. Stich, Jean-Baptiste Condominer, and Martin Jaggi. 2018. Sparsified SGD with Memory. In _Proc. of NeurIPS_, vol. 31.
* Tam et al. (2023) Kairo Tam, Li Li, Bo Han, Chengzheng Xu, and Huawhu Fu. 2023. Federated Noisy Client Learning. _IEEE Transactions on Neural Networks and Learning Systems_ (2023), 1-14.
* Tiffany et al. (2021) Tiffany Tiffany Tiffany Tiffany, Shiqiang Wang, Bong Jun Ko, Changchang Liu, and Kin K Leung. 2021. Overcoming Noisy and Irrelevant Data in Federated Learning. In _Proc. of IEEE KDD_. 5020-5027.
* Wu et al. (2024) Zhuxuan Wu, Mohammad Mohammadi Amini, Ramesh Raskar, and Bryan Kaim Huang Low. 2024. Incentive-Aware Federated Learning with Training-Time Model Rewards. In _Proc. of ECL_.
* Xu et al. (2022) Jingyi Xu, Zikhan Chen, Tony QS Quek, and Kai Fong Ernest Chong. 2022. Fedcorr: Multi-stage federated learning for label noise correction. In _Proc. of IEEE CVPR_. 10184-10193.
* Yuan et al. (2021) Jinliang Yuan, Shangguang Wang, Hongyu Li, Dialang Xu, Yuanchun Li, Mengwei Xu, and Xuanhe Liu. 2021. Towards Energy-efficient Federated Learning via INTS-based Training on Mobile DPS. In _Proc. of ACM WWW_. 2786-2794.
* Zhang et al. (2021) Jingwen Zhang, Yuenhou Wu, and Rong Pan. 2021. Incentive mechanism for horizontal federated learning based on reputation and reverse auction. In _Proc. of WWW_. 947-956.

## Appendix A Appendices

**Theorem 4**.: _Given Assumptions 1-3, the following holds_

\[\mathbb{E}[F(w_{T})]\leq\frac{\mathcal{L}}{TE+\kappa}(\frac{\lambda_{1}+\lambda_{2 }}{4\mu^{2}}+(\kappa+1)\mathcal{C}_{1}), \tag{26}\]

_where \(\kappa=\max\{E,\mathbb{E},\mathbb{I}/\mu-1\}\), \(\lambda_{1}=4L\Gamma(M)+16(E-1)^{2}\mathcal{G}^{2}\), \(\lambda_{2}=(NK^{2}E^{2}\mathcal{G}^{2}+4N^{2}\lambda_{2}^{2}\ln{(1.25/\delta)})/K^{4}\), \(\mathcal{G}\) is a constant defined by (Zhou et al., 2020), and \(\mathcal{C}_{1}=\mathbb{E}[\|\psi_{1}-w^{2}\|^{2}]\). The learning ratio is set to \(\eta_{\xi}=2/(\mu(z+\kappa))\), where \(\varsigma_{\xi}\) represents the \(\varsigma\)-th epoch._

Proof.: The convergence property essentially reflects the discrepancy in objective functions between the realized model \(w\) and the optimal model \(w^{*}\). It is hard to directly obtain this discrepancy, so we analyze the difference between models,

\[\|\psi_{\xi}-w^{*}\|^{2} =\|\hat{w}_{\xi}-\phi_{\xi}+\phi_{\xi}-w^{*}\|^{2}\] \[\leq 2(\|\psi_{\xi}-\phi_{\xi}\|^{2}+\|\phi_{\xi}-w^{*}\|^{2}), \tag{27}\]

where the last inequality holds due to the Cauchy-Schwarz inequality. Afterward, we separately bound \(\|\hat{w}_{\xi}-\phi_{\xi}\|^{2}\) and \(\|\hat{\psi}_{\xi}-w^{*}\|^{2}\) in steps 1-2, and bound Eq. 27 in step 3.

**Step 1**: Bounding \(\|\hat{w}_{\xi}-\phi_{\xi}\|^{2}\). When \(\varsigma/E\notin[T]\), it holds that \(\hat{w}_{\xi}=\hat{\phi}_{\xi}\) due to their definitions. When \(\varsigma/E\in[T]\),

\[\mathbb{E}[\|\hat{w}_{\xi}-\phi_{\xi}\|^{2}]=\mathbb{E}[\|(1/K)\sum_{i \in[N]}\mathbb{I}(i)\sum_{i\in\varsigma}\varphi_{i\xi}-\phi_{\xi}\|^{2}]\] \[=(1/K^{2})\mathbb{E}[\|\sum_{i\in[N]}\mathbb{I}(i\in\varsigma_{ \xi})\|\varphi_{i\xi}-\phi_{\xi}\|^{2}]\] \[\leq(N/K^{2})\sum_{i\in[N]}\Pr\{i\in\varsigma_{\xi}\}\|\varphi_{i \xi}-\phi_{\xi}\|^{2}. \tag{28}\]

The first two equalities follow from definitions of \(\hat{w}_{\xi}\) and \(\phi^{2}\). The first inequality holds also due to the Cauchy-Schwarz inequality, i.e., \(\|\sum_{i\in[N]}(x_{i}-y_{i})\|\leq\sum_{i\in[N]}\|x_{i}-y_{i}\|\). Let \(\varsigma_{0}=\varsigma\)-\(E\). Then epoch \(\varsigma_{0}\) is the communication round recalling that \(\varsigma/E\in[T]\). This implies all clients have the identical model \(w_{\varsigma_{0}}\), \(\forall i\in[N]\). Then,

\[\text{Eq.~{}}28\leq(N/K^{2})\sum_{i\in[N]}\|(\varphi_{i\xi}-\hat{w}_{ \varsigma_{0}})-(\varphi_{\xi}-\hat{w}_{\varsigma_{0}})\|^{2}\] \[\leq(N/K^{2})\sum_{i\in[N]}\|(\varphi_{i\xi}-\hat{w}_{\varsigma_{0}})\|^{2}\] \[=(N/K^{2})\sum_{i\in[N]}2(\|\varphi_{i\xi}-\hat{w}_{\varsigma_{0}}-1)+ \cdots+(\hat{w}_{\varsigma_{0}+1}-\hat{w}_{\varsigma_{0}})\|^{2}\] \[\leq(NE/K^{2})\sum_{i\in[N]}\sum_{i\in[N]}\sum_{i\in[N]}2(\|\eta_{\xi}- \eta_{\xi}\nabla_{i}(x_{i},w_{i\tau-1})\|^{2}, \tag{29}\]

The second inequality holds from \(\mathbb{E}[\|x-\mathbb{E}[x\|^{2}]]\)\(\leq\)\(\mathbb{E}[\|x\|^{2}]\) and the third inequality follows from the Cauchy-Schwarz inequality similarly. Further, due to Theorem 2.2 in [23], the expected squared norm of stochastic gradients is upper bounded by a constant \(\mathcal{G}\), i.e., \(\mathbb{E}[\|\hat{w}_{\xi}-\phi_{\xi}\|^{2}]\leq\mathcal{G

[MISSING_PAGE_EMPTY:10]