# Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models

Anonymous Author(s)

###### Abstract.

Temporal reasoning is a crucial natural language processing (NLP) task, providing a nuanced understanding of time-sensitive contexts within textual data. Although recent advancements in Large Language Models (LLMs) have demonstrated their potential in temporal reasoning, the predominant focus has been on tasks such as temporal expression detection, normalization, and temporal relation extraction. These tasks are primarily designed for the extraction of direct and past temporal cues from given contexts and to engage in simple reasoning processes. A significant gap remains when considering complex reasoning tasks such as event forecasting, which requires multi-step temporal reasoning on events and prediction on the future timestamp. Another notable limitation of existing methods is their incapability to illustrate their reasoning process for explaining their prediction, hindering explainability. In this paper, we introduce the first task of explainable temporal reasoning, to predict an event's occurrence at a future timestamp based on context which requires multiple reasoning over multiple events, and subsequently provide a clear explanation for their prediction. Our task offers a comprehensive evaluation of both the LLMs' complex temporal reasoning ability, the future event prediction ability, and explainability--a critical attribute for AI applications. To support this task, we present the first instruction-tuning dataset of explainable temporal reasoning (ExpTime) with 26k derived from the temporal knowledge graph datasets, using a novel knowledge-graph-instructed-generation strategy. Based on the dataset, we propose the first open-source LLM series TimeLaMA based on the foundation LLM LiMaMA, with the ability of instruction following for explainable temporal reasoning. We compare the performance of our method and a variety of LLMs, where our method achieves the state-of-the-art performance of temporal prediction and explanation generation. We also explore the impact of instruction tuning and different training sizes of instruction-tuning data, highlighting LLM's capabilities and limitations in complex temporal prediction and explanation generation.

## CCS CONCEPTS

* **Computing methodologies Temporal reasoning.**research questions (RQ) to guide our study: 1) **RQ 1**: Can LLMs be effective in predicting future events by considering the context's complex relations among events, and how do they compare with traditional methods? 2) **RQ 2**: What impact does instruction tuning have, particularly when using our new dataset derived from temporal knowledge graphs, on the temporal prediction capabilities of LLMs? 3) **RQ 3**: How effectively can LLMs clarify their prediction and reasoning process, thereby enhancing their transparency in temporal reasoning tasks?

To address these challenges, our study aims to explore LLMs' capabilities in complex temporal reasoning, future event prediction, and, importantly, explainability--an essential aspect of AI applications. We propose the pioneering task of explainable temporal reasoning, aiming to predict the occurrence of future events based on context, demanding reasoning across multiple events, and subsequently, providing a coherent explanation for the prediction. To support this task, we propose the first-of-its-kind multi-source instruction tuning dataset ExpTime, fostering improvement and assessment of LLMs. ExpTime comprises 26k entries, built from a variety of event forecasting datasets and their derived temporal reasoning paths.

Our methodology begins with aggregating data from various recognized datasets, encompassing diverse sources. For each data point, explanations are generated, drawing inspiration from the proven self-instruct approach (Zhu et al., 2017). However, we observed that merely prompting LLMs, such as ChatGPT (Chen et al., 2018), yielded suboptimal results in terms of coherence and accuracy. Recognizing this limitation, we pivoted to a novel Temporal Knowledge Graph-Instructed Generation (GIG) approach. We extract explainable reasoning paths and context from the temporal knowledge graph for each dataset's future event prediction query. We then design prompts to guide LLMs to convert these paths and contexts into coherent explanations. This results in triples of <query, context, answer>, with each answer containing the original prediction and LLM-generated explanation. To ensure the reliability of the dataset, the human evaluation is performed on a subset of the collected data with a carefully designed annotation scheme, evaluating their correctness, completeness, and fluency. We then build a golden-standard testing dataset with human annotation.

Using ExpTime, we propose the TimeLaMA series, an innovative open-source LLM ensemble based on the LiMaA2 (Zhu et al., 2017), using instruction fine-tuning. Specifically, we fine-tune four TimeLaMA models: TimeLaMA-7B, ChatTimeLaMA-7B, TimeLaMA-13B, and ChatTimeLaMA-13B. Our empirical results compare the TemporalLaMA with other LLMs, highlighting its superior performance in terms of temporal prediction and explanation generation. Our experiments demonstrate that with proper instruction tuning using even a small volume of high-quality data, the temporal reasoning capabilities of LLMs can be substantially improved. Model size does not necessarily correlate with performance gains in temporal reasoning when employing instruction tuning under 13 billion parameters.

To encapsulate, our contributions are manifold: 1) We pioneer the first task of explainable temporal reasoning, setting the stage for subsequent research, 2) We introduce ExpTime, the first instruction-tuning dataset to improve and evaluate LLMs' ability of explainable temporal reasoning. 3) We propose a novel knowledge graph-instructed generation (GG) method, for generating explainable temporal reasoning data with LLMs from temporal knowledge graphs, 4) We propose TimeLlaMA, an open-source LLM series tailored for this specific task, achieves SOTA performance, 5) We conduct a holistic evaluation of our method and various LLMs in the realm of temporal reasoning, critically analyze the strengths and limitations of LLMs, providing directions for future research 1.

Footnote 1: We will release our models, datasets, and evaluation metrics to the broader research community.

## 2. Related Work

### Temporal Reasoning in NLP

Based on the level of difficulty, temporal reasoning in NLP can be categorized into three tasks: temporal expression detection and normalization, temporal relation extraction, and event forecasting. The temporal expression detection task aims to detect the phrases in the text that describe the temporal information, such as "yesterday" and "last year" (Zhu et al., 2017). After the detection, the model is required to normalize the temporal expression into a TimeML standard format, such as "2013-01-06". The temporal expression detection and normalization task was first introduced in TempEval-2 (Zhu et al., 2017), where the most successful models are rule-based, such as SUTime and NavyTime (Beng et al., 2018; Chen et al., 2018). The normalization task was further improved by incorporating pre-trained embeddings later (Zhu et al., 2017; Zhu et al., 2017).

When time expressions can be detected, the next level of temporal reasoning is to determine the chronological order of events described in the text, namely temporal relation extraction. The temporal relation extraction task was first introduced in TempEval (Zhu et al., 2017). Initially, this task was tackled by leveraging the sequential neural networks, such as LSTM and RNN, to detect temporal order (Song et al., 2018; Chen et al., 2018; Chen et al., 2018). Later, GNN was introduced to better capture

\begin{table}
\begin{tabular}{l c c c c c c} \hline \hline  & Explanation & Event Forecasting & Model & Multi-hop Reasoning & Instruction Finetuning & Context Infer \\ \hline TEMPLAMA (Song et al., 2018) & ✗ & ✗ & T5 & ✗ & ✗ & ✗ \\ TEMPREASON (Zhu et al., 2017) & ✗ & ✗ & T5 & ✗ & ✗ & ✓ \\ AutoCast (Zhu et al., 2017) & ✗ & ✓ & T5 & ✓ & ✗ & ✗ \\ ExpTime & ✓ & ✓ & LLama2-7b/13b & ✓ & ✓ & ✓ \\ \hline \hline \end{tabular}
\end{table}
Table 1. The comparison between temporal reasoning datasets and corresponding finetuned models. “Context Infer” denotes if inference based on context is required and “multi-hop reasoning” means engaging in multi-step reasoning is required to arrive at the correct answer.

the dependency explicitly between the events and time expressions (Brocker et al., 2015; Chen et al., 2016; Chen et al., 2017). As LLMs become popular, some work also investigated the zero-shot ability of LLM in temporal relation extraction and reported that the zero-shot performance is worse than supervised models (Chen et al., 2016; Chen et al., 2016).

With the acquisition of a chronological order of events, the final level of temporal reasoning is event forecasting. The goal of this task is to determine if a specific event will happen in the future given the context events described in the text (Chen et al., 2016). Some work has designed a dataset to train the model (Chen et al., 2016), in which the model can access the context information through links. However, the exploration of this task is still limited despite the importance of this task.

### Temporal Knowledge Graph Event Forecast

There are two settings in the temporal knowledge graph reasoning (TKGR) task: extrapolation and interpolation. Extrapolation focuses on predicting whether events will occur in future timestamps, while interpolation aims to complete the temporal knowledge graph within a given timespan (Brocker et al., 2015; Chen et al., 2016). Some works also refer to the extrapolation setting as event forecasting in temporal knowledge graph (Chen et al., 2016; Chen et al., 2016). A key difference between event forecasting in NLP and TKG is the input format - NLP uses textual context, whereas TKG relies on graph structure. To enhance explainability, some methods for TKGR produce predictions along with validated reasons. The explainable methods can be roughly summarized into three categories: logic rule-based approach, reinforcement learning-based approach, and attention network-based approach. For example, TLogic mines logic rules from temporal knowledge graphs for forecasting (Chen et al., 2016). Lin et al. proposed graph and logic encoders to incorporate graph information into rules (Chen et al., 2016). In reinforcement learning-based (RL) approaches, Sun et al. used an RL agent to travel on the graph to predict events, explaining the prediction (Sun et al., 2017). Similarly, Li et al. found event clusters and then searched them with an RL agent (Li et al., 2017). Some models expand an initial query graph via attention until the query entity is reached, using the subgraphs as explanations (Li et al., 2017). Jung et al. also used an attention GNN to iteratively propagate towards the target entity (Li et al., 2017). As explainable TGKR models provide structural reasoning steps on the graph, we leveraged the RL-based and logic-based models to instruct the LLM explanation generation to construct the ExpTime dataset.

### Temporal Reasoning in LLM

As growth took place in pre-trained LLMs, a natural question is if LLM is capable of serving as a temporal knowledge base (Li et al., 2017; Chen et al., 2016). The pivotal concept of this task is to understand the context under temporal expression and perform temporal-sensitive reasoning to predict missing entities (Chen et al., 2016). Temporal datasets have been developed to evaluate LLM on temporal understanding, like Custom-News which evaluates if LLMs can predict masked entities given timestamps (Li et al., 2017). Dhingra et al. then proposed TEMPLAMA which emphasizes temporal questions as \((h,r,?,t_{1})\) and \((h,r,?,t_{2})\) where the answers differ due to different timestamps (Li et al., 2017). TemporalWiki addresses temporal misalignment in LLMs similarly (Tang et al., 2017). Tan et al. expanded TEMPLAMA's time range and added more time-unrelated questions (Li et al., 2017).

Some work also further investigated the capability of LLM in the event forecasting task, which is more challenging than temporal-sensitive learning as it requires a full understanding of time and logic. Zhou et al. constructed an Autocast dataset that consists of question-and-answer pairs about future events (Chen et al., 2016). Lee et al. tested the zero-shot event forecasting ability of LLM on a temporal knowledge graph and demonstrated that only through in-context learning, LLMs can achieve comparable performance wrt current supervised TKG methods (Li et al., 2017). Similarly, Xu et al. designed various prompts to query LLM for temporal knowledge graph completion task (Li et al., 2017). This ability was further improved by few-shot abductive reasoning over LLM and temporal knowledge graph (Chen et al., 2016). However, these studies did not evaluate or improve the textual temporal reasoning skills of LLMs. Additionally, the lack of explainability in these LLMs is concerning given their importance in temporal reasoning tasks. To the best of our knowledge, our proposed ExpTime is the first dataset that evaluates and improves the explainability and textual temporal reasoning ability of LLMs.

## 3. Method

The objective of this work is to assess and enhance the complex temporal reasoning capabilities of large language models (LLMs). To accomplish this goal, we propose the explainable event forecasting task for complex temporal reasoning and construct the first dataset of its kind: the Explainable Temporal Event Forecasting (ExpTime) dataset. We benchmark the performance of popular LLMs using this new dataset. We then propose the novel LLM series: TimetLaMA, by instruction finetuning a series of LLma2 models, with the aim of improving the temporal reasoning abilities of LLMs.

### Task Definition

We define the explainable temporal reasoning task as follows: given an input document \(D\) describing events \(\mathcal{E}_{t_{1}-t_{2}}=\{e_{1},e_{2},\cdots,e_{n}\}\) occurring during time interval \(t_{1}\sim t_{2}\), the task is to predict the probability \(P=P(e_{k}|\mathcal{E}_{t_{1}-t_{2}})\) that event \(e_{k}\) will occur at future time \(t_{3}\), where \(t_{3}>t_{2}\geq t_{1}\). Additionally, the LLM must also generate an explanation \(F\) that demonstrates its reasoning for the prediction. Each training instance \(\mathcal{T}_{r}\) for fine-tuning the language model consists of the input document \(D_{i}\), question \(Q_{i}\), prediction answer \(P_{i}\), and explanation \(F_{i}\): \(\mathcal{T}_{r1}=\{D_{i},Q_{i},P_{i},F_{i}\}\).

### Graph-Instruct-Generation: Construct ExpTime Dataset

Recent work has explored using LLMs like ChatGPT to generate datasets by prompting the model to produce answers (Xu et al., 2017). However, directly prompting LLMs to generate temporal reasoning data results in low-quality explanations, as we demonstrate in Section 4.2.2. To address this issue, we propose a novel framework called Temporal Knowledge Graph-instructed Generation (GIG) to produce more coherent and accurate reasoning explanations.

The key insight behind our approach is to leverage temporal knowledge graphs (TKGs), which have been effectively utilized for explainable event forecasting. As illustrated in Figure 1, we first apply explainable TKG reasoning models to generate reasoning paths for a given query about a future event. We then convert these paths into natural language explanations \(F_{i}\) using a two-level prompting technique we developed. Next, we identify relevant context quadruples from the TKG and reasoning paths to construct a context quadruple set, which is transformed into a coherent natural language document \(D_{i}\). Finally, we convert the original query into a question \(Q_{i}\) to produce a complete training instance \(\mathcal{T}r_{i}=\{D_{i},F_{i},P_{i},Q_{i}\}\). In this way, our GIG framework overcomes the limitations of directly prompting LLMs by leveraging structured knowledge in TKGs to generate high-quality explanations. The technical details of each step are provided in the following sections.

**Reasoning Paths Generation.** As discussed in Section 2.2, temporal knowledge graph reasoning models can be categorized into three main types. In this work, we select two popular methods representing the most common approaches: TimeTraveler (Tran et al., 2017), which uses a reinforcement learning-based approach, and TLogic (Song et al., 2017), which employs logic rules. We chose these models because they provide high quality and human-readable reasoning chains, as shown in the following equation:

\[(E_{1},R_{c},E_{m+1},T_{m+1})\leftarrow\wedge_{i=1}^{m}(E_{i},R_{i},E_{i+1},T _{i}) \tag{1}\]

where \(E_{i}\), \(T_{i}\), and \(R_{i}\) are the i-th entity, timestamp, and relation, respectively. For example, Fig. 1 shows that given the query quadruple, the explainable TKGR model generates the following reasoning path:

\[\begin{array}{l}\mathit{Iran}\ \frac{\text{sign formal agreement, 11-06-2014}}{\text{express intent to meet or negotiate, 11-04-2014}}\ \mathit{China}\\ \hline\text{host visit, 11-10-2014}\ \mathit{Barack Obama}\end{array} \tag{2}\]

To leverage the reasoning chains from these models, we take the average confidence scores (or probability values) of the predictions from the two models and select the reasoning paths \(Pa\) with the highest confidence.

**Context Document Generation.** Given a query quadruple \(q_{u}=(e_{1},r,e_{2},t_{i})\), we first extract relevant quadruples from the TKG to form the context quadruple set, and then transform them into natural language sentences. Specifically, to extract relevant information, we obtain quadruples \(q\) that meet two criteria: 1) either entity \(e_{1}\) or \(e_{2}\) from the original query is present in \(q\), and 2) the occurrence time \(t_{q}\) of \(q\) falls within a defined time span from the query time \(t_{i}\) to time \(t_{j}\). Formally, we extract quadruples \(q\) where \((e_{1}\in q\lor e_{2}\in q)\wedge(t_{q}>t_{i}\wedge t_{q}<t_{j})\). We also add the quadruples along the reasoning path \(Pa_{i}\) to the context set.

Once we have the context quadruple set \(\mathcal{Q}\), the next step is to convert \(Q\) into natural language sentences. Prior work such as KELM (Kelm, 2014) and GAP (Garay et al., 2017) have proposed rule-based or pipeline methods, but these cannot generate sufficiently diverse documents from knowledge graphs. Therefore, we designed a prompt to leverage the generative capabilities of ChatGPT to produce more diverse and coherent context documents from \(\mathcal{Q}\). The prompt is defined as follows:

_Please generate a coherent paragraph to describe the following quadruples and the time should be precise to dates: [\(\mathcal{Q}\)]_

In this way, we use the response from ChatGPT as the input document \(D_{i}\) for each training instance \(\mathcal{T}r_{i}\).

**Explanation Generation.** Recall that for each query quadruple \(q_{u}=(e_{1},r,e_{2},t_{i})\), we have obtained the reasoning path \(Pa_{i}\). First, we automatically generate a template-based explanation \(F^{\prime}_{i}\) for each query quadruple \(q_{u}=(e_{1},r,e_{2},t_{i})\) using the corresponding reasoning path \(Pa_{i}\) obtained from the above steps. This explanation template aims to concisely describe the prediction and the reasoning steps in natural language:

_Based on the information provided by the document, it is plausible that \(e_{1}\) will \(r\)\(e_{2}\) in \(t_{i}\). Here are my reasons: \(Pa_{1}\), and \(Pa_{2},\cdots\), therefore, it is plausible that \(e_{1}\) will \(r\)\(e_{2}\) in \(t_{i}\)._

We refer to this as the template synthesized explanation \(F^{\prime}_{i}\).

However, these template-generated explanations \(F^{\prime}_{i}\) may lack coherence or omit critical reasoning details. To improve the quality of explanations, we implement a two-step chain-of-thought (CoT)

Figure 1. The pipeline of generating ExpTime dataset. The pos, neg, and neu denote the positive sample, negative sample, and neutral sample, respectively.

prompting approach using LLMs like ChatGPT. First, we prompt ChatGPT to evaluate the correctness of the template explanation \(F^{\prime}_{i}\) and provide a brief justification, e.g.:

_Given the text, \(F^{\prime}_{i}\), please evaluate the correctness of the prediction..._

We provide detailed prompt in Appendix B.1 for this and all subsequent prompts. If ChatGPT concludes that the explanation \(F^{\prime}_{i}\) is correct, we propose a "polish prompt" to ChatGPT:

_Can you make the text more coherent and readable by expanding the explanation of each reasoning step?_

However, if ChatGPT determines that the template explanation \(F^{\prime}_{i}\) contains flawed reasoning leading to an incorrect prediction, we provide a "revision prompt" asking ChatGPT to correct the flaws by considering additional context quadruple information from \(Q\):

_Please revise... You can add information from the following quadruples... [\(Q\)]_

In this way, the ChatGPT response represents the final, improved explanation \(F_{i}\) for each training instance. This CoT prompting approach allows us to leverage the reasoning and language capabilities of LLMs to enhance the quality of automatically generated explanations.

**Negative and Neutral Samples.** Note that by following the previously introduced steps, we can easily acquire positive training instances, i.e., the prediction is that the event will happen. However, using only positive examples to fine-tune language models can lead to highly skewed and imbalanced training. Therefore, we also propose two methods to generate negative and neutral samples individually.

The negative samples represent counterfactual events that did not occur. For each positive training instance \(\mathcal{T}\tau_{I}=\{D_{i},F_{i},P_{i}\}\), we generate a negative example by replacing the relation \(r_{i}\) in the query quadruple \(q_{u}\) with an opposite relation \(r^{\prime}_{i}\) such that the meaning of \(r^{\prime}_{i}\) should be as opposite as possible to the original one. For example, we replaced (_Africa, Host a visit, Rx Tillicrap, 2018-03-10_) with (_Africa, withdraw visiting horizons, Rx Tillicrap, 2018-03-10_). The resulting negative example quadruple is \(q^{\prime}_{u}=(\mathrm{e}_{1},r^{\prime},e_{2},t_{1})\). In this way, as the original event did actually happen, the newly synthesized event should be highly unlikely to happen. We manually designed 546 opposite relations for all 265 relations in the temporal knowledge graph. Details are illustrated in Appendix C.

Then, similar to the explanation generation, we first generate a simple template synthesized explanation and then query ChatGPT if the synthesized explanation is correct or not. The prompt is designed as follows:

_Given the text, "Based on..., we predict that \(\mathrm{e}_{1}\)\(r^{\prime}\)\(\mathrm{e}_{2}\) will not happen in \(\mathrm{t}_{i}\). We could find the following patterns from the text: \(P_{\mathrm{21}}\), and \(P_{\mathrm{22}}\),\(\cdots\), therefore, it is plausible that \(\mathrm{e}_{1}\) will \(\mathrm{e}_{2}\) in \(\mathrm{t}_{i}\),\(\cdots\), please evaluate the correctness..._

Note that the reasoning path \(Pa\) is still the same as the positive sample. Then we can obtain the explanation result based on the ChatGPT decision by following the exact same "Polish Prompt" or "Revision Prompt".

In neutral training samples, we expect the LLMs to predict "unsure" for the query quadruple because there is no context information in the given document related to the query. Additionally, for explanation, we also expect the LLMs to summarize the document and then demonstrate that there is no related context in the given document. To achieve this goal, we first replace the query quadruple \(q_{u}=(\mathrm{e}_{1},r,\mathrm{e}_{2},t_{i})\) with \(q^{\prime\prime}_{u}=(\mathrm{e}^{\prime}_{1},r,\mathrm{e}^{\prime}_{2},t_{i})\) in the positive training instances, where \(e^{\prime}_{1}\) and \(e^{\prime}_{2}\) are entities that never appear in the context quadruple set \(\mathcal{Q}\). In other words, we ensure the entities in the neutral sample's query do not exist anywhere in the context set \(\mathcal{Q}\). Formally, we have \(e^{\prime}_{1}\notin\mathcal{Q}\wedge e^{\prime}_{2}\notin\mathcal{Q}\). Then we designed the following prompt to query ChatGPT to generate an explanation:

_Given the document "[\(D_{i}\)]", how likely the event that [\(e^{\prime}_{1}\)\(r^{\prime}\)\(e^{\prime}_{2}\)] in [\(\mathrm{t}_{i}\)] would happen? \(\cdots\) if the context is unrelated, summarize the context..._

### Data Statistics and Annotation

We utilize ICEWS14 (Lewis et al., 2015), ICEWS18 (Lewis et al., 2015), and ICEWS0515(Lewis et al., 2015) datasets to generate the proposed dataset, as they are the most popular temporal knowledge graph reasoning datasets. From the three datasets, we extracted 12,229 reasoning paths and therefore generated 12,229 positive samples in the dataset. The detailed statistics of ExpTime are shown in Table. 3.

To further evaluate the quality of our dataset and construct a standardized testing dataset, two experienced annotators independently

\begin{table}
\begin{tabular}{l c c c c} \hline \hline  & Positive & Negative & Neutral & Overall \\ \hline Correct & 0.73 & 0.64 & 0.81 & 0.74 \\ Complete & 0.65 & 0.59 & 0.70 & 0.66 \\ Fluency & 0.98 & 0.97 & 0.98 & 0.98 \\ \hline \hline \end{tabular}
\end{table}
Table 2. Cohen’s Kappa score of human annotation for each criterion under three labels.

Figure 2. The box plots of human annotation for each criterion under positive, negative, neutral, and overall dataset. The dashed line denotes the mean value and the bold line indicates the median value.

evaluated a random sample of 1,200 explanations. The annotators rated each explanation on three criteria: 1) correctness, which assessed whether the prediction and explanation were accurate; 2) completeness, which evaluated if the explanation provided the necessary context to understand the prediction; and 3) fluency, which measured if the explanation was clear and understandable. The annotation guidelines and annotator qualifications are detailed in Appendix A. Cohen's kappa coefficient was calculated to determine inter-rater agreement for each criterion. As shown in Table 2, a high level of agreement was achieved for all criteria. In particular, the annotators demonstrated strong agreement on fluency ratings and agreement was higher overall for samples receiving neutral labels. As illustrated in Fig. 2, most samples received high scores across all three criteria. The strong inter-rater agreement and generally high scores indicate the testing dataset represents a high-quality, standardized sample for evaluation. Low-scoring samples on any of the criteria were excluded.

### TimeLlama

As illustrated in Fig. 3, we present the TimeLlama model series, representing the first LLMs fine-tuned specifically for complex temporal reasoning tasks, namely explainable event forecasting. By instruction tuning the models on datasets requiring the comprehension and synthesis of temporal information, TimeLlama gains an enhanced ability to make logical inferences about the timing, duration, and relations between events. This supports a more accurate prediction of what events may occur next given a historical context. We construct TimeLlama-7b and TimeLlama-13b by finetuning the base Llama-7b and Llama-13b models, respectively. The finetuning process utilizes Flash Attention and DeepSpeed to accelerate training (Han et al., 2017; Wang et al., 2018). Full hyperparameters can be found in Appendix D.2. Additionally, by finetuning the Llama-7b/13b conversational models, we construct ChatTimeLlama-7b and ChatTimeLlama-13b, based on Llama-2-Chat-7b/13b optimized using reinforcement learning from human feedback (RLHF) (Wang et al., 2018).

## 4. Experiments

### Experimental Settings

**Baselines.** We evaluate and compare the following LLMs as the baselines: **Flan T5**(Chen et al., 2017). An instruction-finetuned T5 model based on chain-of-thought data that increased the number of tasks. **BART**(Wang et al., 2018): An encoder-decoder architecture model that is proficient in abstractive dialogue, question answering, and summarization tasks. **MPT-7b**(Wang et al., 2018): A LLM that is optimized for extremely long inputs. The MPT model with 7b parameters fine-tuned for dialogue generation is used in our experiment. **Falcon-7b**(Wang et al., 2018): A LLM that is optimized for faster inference with decoder-only architecture. The 7B dialogue-fine-tuned version is used. **Vicuna-7b**(Wang et al., 2018): A chatbot trained by fine-tuning L1AMA on a dataset collected from ShareGPT. **ChatGPT**(Chen et al., 2017): A chatbot based on GPT-3.5 LLM that is capable of having natural conversations. **Llama2-7b/13b-chat**(Wang et al., 2018): Llama-2 is a collection of open-sourced LLMs that outperform other models in most tasks. The chat-fine-tuned Llama2-7b/13b is used.

**Metrics.** Our evaluation can be roughly divided into automatic and human evaluation. In automatic evaluation, we first report precision, recall, and F1 scores of event predictions. For explanation evaluation, we choose BLEU (Krishna et al., 2015) (unigram, bigram, 3-gram, 4-gram) and ROUGE (Ross et al., 2016) (rouge1, rouge2, rougeL) to compare the explanation generated by the LLMs with the golden explanations in the testing set. Besides the metric-based methods, we also report the BertScore (Krishna et al., 2015) that computes the similarity based on PLMs. We use the same evaluation criteria introduced in Sec. 3.3 for human evaluation, namely correctness, completeness, and fluency.

### Automatic Evaluation Results

#### 4.2.1. Prediction Evaluation.

In Table 4, we present compelling evidence of the substantial enhancements achieved through the fine-tuning of the ChatTimeLlama-7b model. Notably, our finetuned Llama2-7b model surpasses its baseline counterpart across multiple performance metrics. Specifically, we observe impressive F1 gains

Figure 4. The automatic evaluation scores of finetuned Llama2 with various percentages of dataset usage. From left to right: F1 scores of each category, BLEU and ROUGE scores, BERTScore.

Figure 3. The pipeline of finetuning and evaluating TimeLlama series models. GIG Strategy denotes our proposed dataset construction approach.

\begin{table}
\begin{tabular}{c c c c|c c c} \hline \hline  & Pos. & Neg. & Neu. & ICEWS14 & ICEWS18 & 0515 \\ \hline Train & 11703 & 8705 & 5360 & 10327 & 7651 & 7790 \\ Test & 435 & 300 & 266 & 387 & 351 & 263 \\ \hline \hline \end{tabular}
\end{table}
Table 3. The statistics of constructed dataset. Pos., Neg., Neu. denote the number of positive, negative, and neutral samples, respectively.

improvements of 44.0, 32.5, 56.3, and 49.2 across four categories: positive, negative, neutral, and overall. These figures underscore the efficacy of our fine-tuning approach, even in the presence of noise within the training dataset. Notably, this underscores the capacity of LLMs to leverage high-quality generated datasets by instruction-tuning for substantial performance enhancements.

**Bigger LLM is not always better.** Interestingly, increasing the model scale does not necessarily improve performance. Doubling the parameters from Llama2-7b-chat to Llama2-13b-chat yielded

\begin{table}
\begin{tabular}{l c c c c c c c c c c c c c} \hline \hline \multirow{2}{*}{Models} & \multicolumn{4}{c}{Positive} & \multicolumn{4}{c}{Negative} & \multicolumn{4}{c}{Neutral} & \multicolumn{4}{c}{Overall} & \multirow{2}{*}{758} \\ \cline{2-2} \cline{4-14}  & Prec & Recl & F1 & Prec & Recl & F1 & Prec & Recl & F1 & Prec & Recl & F1 \\ \hline Flan T5 & 62.9 & 29.2 & 39.9 & 31.4 & 57.0 & 40.5 & 32.2 & 30.8 & 31.5 & 45.3 & 38.0 & 38.0 & 737 \\ BART & 45.7 & 28.2 & 34.9 & 26.3 & 11.7 & 16.2 & 21.5 & 18.3 & 19.8 & 33.6 & 27.0 & 25.3 & 738 \\ \hline MPT-7b & 48.5 & 64.6 & 55.4 & 39.5 & 35.7 & 37.5 & 25.8 & 14.7 & 18.7 & 39.8 & 42.7 & 40.3 & 798 \\ Falcon-7b & 47.7 & 56.6 & 51.7 & 37.9 & 22.0 & 27.8 & 19.9 & 23.3 & 21.5 & 37.4 & 37.4 & 36.5 & 760 \\ Vicuna-7b & 48.4 & 80.5 & 60.4 & 41.3 & 21.3 & 28.1 & 35.8 & 16.5 & 22.6 & 42.7 & 45.6 & 40.4 & 761 \\ ChatGPT & 90.9 & 39.1 & 54.7 & 29.5 & 31.7 & 30.5 & 30.7 & 56.8 & 39.8 & 56.5 & 41.6 & 43.5 & 762 \\ Llama2-7b-chat & 50.1 & 83.9 & 62.7 & 41.9 & 13.0 & 19.8 & 27.4 & 18.4 & 22.0 & 41.6 & 45.3 & 39.1 & 763 \\ Llama2-13b-chat & 51.3 & 53.8 & 52.5 & 40.0 & 26.0 & 31.5 & 28.0 & 36.8 & 31.8 & 41.7 & 41.0 & 40.7 & 764 \\ \hline TimelLlama-7b & 90.1 & 97.6 & 93.7 & 67.6 & 84.9 & 75.3 & 97.8 & 55.1 & 70.5 & 84.6 & 82.7 & 81.5 & 765 \\ ChatTimelLlama-7b & 91.3 & 99.3 & 95.2 & 68.3 & 86.0 & 76.1 & 98.7 & 55.6 & 71.2 & 86.4 & 83.7 & 83.1 & 766 \\ TimeLlama-13b & 94.6 & **100** & 97.2 & 73.9 & 91.3 & 81.7 & **99.4** & 63.5 & 77.5 & 89.6 & 87.7 & 87.3 & 767 \\ ChatTimelLlama-13b & **96.2** & 99.5 & **97.9** & **75.0** & **94.0** & **83.4** & 98.9 & **65.0** & **78.5** & **90.6** & **88.7** & **88.4** & 768 \\ \hline \hline \end{tabular}
\end{table}
Table 4. The prediction performance of each model on gold temporal reasoning testing set. The overall denotes the weighted average precision, recall, and F1 score.

Figure 5. The box plots of human evaluation for each LLM. The dashed line denotes the mean value and the bold line indicates the median value.

only marginal gains, with Llama2-7b-chat actually outperforming Llama2-13b-chat on the positive class. For instance, Llama2-7b-chat has a 10.2 F1 gain compared with Llama2-13b-chat in the positive category. Another example is the comparison between MPT-B and Flan T5. For instance, when we examined the 'unsure' category, we observed that Flan T5 demonstrated an impressive F1 score of 31.5. It outperforms both MPT-7b and Falcon-7b, which achieved F1 scores of 18.7 and 21.5, respectively.

**ChatGPT performs mediocre in the zero-shot setting.** Notably, even though our dataset is generated by prompting ChatGPT, it is evident that ChatGPT exhibits suboptimal performance when presented with direct prompts, in contrast to our dataset construction approach. To provide a comprehensive view of ChatGPT's performance, we compare it with Vicuna-7b, a model that was not involved in the dataset construction process. The results reveal that ChatGPT achieves an overall F1 score of 43.5, while Vicuna-7b demonstrates a comparable F1 score of 40.4. Furthermore, our fine-tuned model, Llama2-7b-chat, exhibits a substantial 39.6 F1 point improvement over ChatGPT's performance.

#### Explanation Evaluation

In Table 5, we present the automatic evaluation results for the explanation generation. Notably, our fine-tuned variant, ChatTimeLlama-7b, demonstrates remarkable improvements across all key evaluation metrics. For instance, when compared to the baseline Llama2-7b-chat, ChatTimeLlama-7b exhibits substantial enhancements in BLEU, ROUGE, and BertCore scores, with gains of 35.1, 19.3, and 6.4 points, respectively. These results underscore the significant potential for enhancing the explainable temporal reasoning capabilities of LLMs through instruction tuning based on high-quality datasets.

Parallel to our prediction evaluation, our examination of explanation quality yields insightful observations. First, our explanation evaluation results also demonstrate that ChatGPT with direct prompting exhibits limitations in generating coherent reasoning explanations. For example, the BLEU and ROUGE scores of ChatGPT are 31.1 and 37.1 while Llama2-7b-chat can also achieve comparable performance, i.e., 26.8 BLEU score and 38.4 ROUGE score. We include a failure example of ChatGPT in Appendix B.3. Second, the explanation quality of TimeLlama-13b is not better than that of TimeLlama-7b. For example, ChatTimeLlama-7b achieves a 61.9 BLEU score while ChatTimeLlama-13b has 46.3 BLEU. This may be due to overfitting, and lack of grounding where maximizing prediction harms explainability.

Another interesting finding is that even Flan T5 and BART can achieve comparable performance on prediction evaluation, these two LLMs along with MPT-7b produce subpar explanations compared to other LLMs. One possible reason could be the different coverage of their training dataset and the difference between "encoder-decoder" and "decoder" only architecture.

### Human Evaluation Results

To provide an objective assessment of the quality of the generated explanations, two experienced annotators evaluated explanations from four language models: Llama2-7b, TimeLlama2-7b, ChatGPT, and Vicuna-7b. The annotation guidelines and annotator qualifications are detailed in Appendix A. 50 explanations from each model were randomly selected, paired with the corresponding question, and evaluated by the annotators. As shown in Figure 5, the results demonstrate that overall the TimeLlama2-7b model achieved the highest scores across the three assessment criteria. Specifically, all models generated fluent explanations, as indicated by the high fluency scores. Llama2-7b and ChatGPT performed similarly on correctness and completeness. Compared to the baseline Llama2-7b, the TimeLlama2-7b showed significantly improved correctness and completeness, suggesting that finetuning on the high-quality dataset enhanced its ability to provide coherent temporal reasoning explanations. Cohen's kappa coefficients in Appendix A also show a high level of inter-annotator agreement for most model evaluations. In summary, the finetuned Llama2 model generated the highest quality explanations according to the human evaluation, demonstrating the efficacy of finetuning on a curated dataset to improve the explanatory capabilities of language models for temporal reasoning.

### Fractional Data Trains LLM Reasoning Skills

Previous experiments have demonstrated that fine-tuning LLMs on high-quality datasets can significantly improve their ability to provide explainable temporal reasoning. This leads to an investigation of the minimum amount of high-quality data required to improve the explainable temporal reasoning capabilities of LLMs. To test this, 10%, 50%, and 75% of the training samples were randomly selected from the dataset to fine-tune Llama2-7b using the same fine-tuning methodology. Interestingly, Llama2 fine-tuned on reduced amounts of data achieved comparable or better performance on automatic prediction and explanation evaluation metrics in some cases (Fig. 4). For instance, Llama2 fine-tuned on 75% of the dataset attained a higher F1 score for prediction accuracy compared to the full dataset. Moreover, the Llama2 fine-tuned on just 10% of the data obtained similar performance on explanation metrics such as ROUGE score and BERT score versus Llama2 fine-tuned on 75% and the full dataset. These results demonstrate that with guidance from even a small volume of high-quality data, the temporal reasoning and explanation generation skills of LLMs can be substantially enhanced.

## 5. Conclusion

In this work, we propose the first task of explainable temporal reasoning, to predict an event's occurrence at a future timestamp and generate the explanation for their prediction. To support this task, we introduce a novel dataset ExpTime, containing 26k examples derived from temporal knowledge graphs, developed by a novel knowledge-graph-instructed-generation strategy. Based on this dataset, we develop TimeLlama, an open-source LLM series tuned with instructions for temporal reasoning and explanation generation. Experiments demonstrate the SOTA performance of TimeLlama on future event prediction and explanation generation compared to other LLMs. We find the instruction-tuning using high-quality data is critical for improving LLM's temporal reasoning and explainability. We discuss associated ethical considerations and limitations in Appendix F. In the future, we plan to expand the breadth and diversity of our benchmark dataset by incorporating more temporal reasoning tasks.

## References

* (1)
* Agarwal et al. (2021) Ohihin Agarwal, Heming Ge, Siamak Shakeri, and Rani Ali-Rfou. 2021. Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training. In _Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies_. 3554-3565.
* Bobeck et al. (2023) Sebastien Bobeck, Varam Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamat, Peter Lee, Yin Li Lee, Yuanli Li, Scott Lundberg, et al. 2023. Sparks of artificial general intelligence: early experiments with gp4-a. _arXiv preprint arXiv:2303.12712_ (2023).
* Cao et al. (2021) Federico Cao, Yizou Zhou, Yubo Chen, Kang Liu, Jun Zhao, and Wei Bi. 2021. Uncertainty-Aware Self-Training for Semi-Supervised Event Temporal Relation Extraction. In _Proceedings of the 30th ACM International Conference on Information & Knowledge Management_. 2900-2904.
* Chambers (2013) Nathanael Chambers. 2013. Navigme: Event and time ordering from raw text. In _Second Joint Conference on Lexical and Computational Semantics (* SEM)_. Volume 2. _Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013)_. 73-77.
* Chan et al. (2023) Chunki Chan, Jiayang Cheng, Weiqi Wang, Yuxin Jiang, Tianqing Fang, Xin Liu, and Tapasu Song. 2023. Chapter evaluation on sentence level relations: A focus on temporal, causal, and discourse relations. _arXiv preprint arXiv:2304.14872_ (2023).
* Chang and Manning (2012) Angel X Chang and Christopher D Manning. 2012. Stitme: A library for recognizing and normalizing time expressions. In _Live_, Vol. 21. 3735-3740.
* Chen et al. (2021) Wenlu Chen, Xingyi Wang, and Walting Yang Wang. 2021. A Dataset for Answering Time-Sensitive Questions. In _Thirty-Fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Room 2)_.
* Chung et al. (2022) Hyung Wu Chun, Le Hou, Shajie Banerjee, Peter Zoph, Yi Tay, William Fedus, Eric Li, Xuelih Wang, Mostafa Dehghani, Sadhartha Bachna, et al. 2022. Scaling instruction-finetuned language models. _arXiv preprint arXiv:2210.1146_ (2022).
* Colas et al. (2002) Anthony Colas, Mehrdan Alvanhojand, and Daiv Zhe Wang. 2002. GAP: Graph-aware Language Model Framework for Knowledge Graph-to-Text Generation. In _Proceedings of the 29th International Conference on Computational Linguistics_. 5735-5760.
* Du et al. (2022) Titze Du, Dan Fu, Stefano Emmon, Ari Rudra, and Christopher Be. 2022. Flashattention: Text and memory-efficient text attention with i-awareness. _Advances in Neural Information Processing Systems_ 53 (2022), 16344-16359.
* Dhingra et al. (2022) Bhuwen Dhingra, Jeremy R Cole, Julian Martin Eissenschaos, Daniel Gillick, Joao Eisenstein, and William W Cohen. 2022. Time-aware language models as temporal knowledge bases. _Transactions of the Association for Computational Linguistics_ 10 (2022), 257-273.
* Dilsen et al. (2017) Dmitry Dilsen, Timothy Miller, Chen Lin, Steven Bethard, and Guergana Savora. 2017. Neural temporal relation extraction. In _Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2. Short Papers_. 746-751.
* Draf et al. (2005) Michael Draf, Dave M Gabbay, and Lluis Vila. 2005. _Handbook of temporal reasoning in artificial intelligence_. Elsevier.
* Gao et al. (2023) Leo Gao, John Schulman, and Jacob Hilton. 2023. Scaling laws for reward model overoptimization. In _International Conference on Machine Learning_. PMLR, 10835-10866.
* Garcia-Duran et al. (2018) Alberto Garcia-Duran, Sebastian Dumancic, and Mathis Niepert. 2018. Learning Sequence Encoders for Temporal Knowledge Graph Completion. In _Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing_. 4164-4221.
* Han et al. (2021) Zhen Han, Peng Chen, Yunpu Ma, and Volker Tresp. 2021. Explainable Subgraph Reasoning for Forecasting on Temporal Knowledge Graphs. In _International Conference on Learning Representations_. [https://openreview.net/forum?id=pCHq1m/2PU](https://openreview.net/forum?id=pCHq1m/2PU)
* Han et al. (2021) Zhe Han, Zifeng Ding, Yunpu Ma, Yujia Gu, and Volker Tresp. 2021. Learning neural ordinary equations for forecasting future links on temporal knowledge graphs. In _Proceedings of the 2021 conference on empirical methods in natural language processing_. 3532-3546.
* Jang et al. (2022) Joel Jang, Soonghyeon Ye, Changbo Lee, Sabeer Yang, Josepho Shin, Janghoon Tian, Oeyongbun Kim, and Minghua Seo. 2022. TemporalWiki: A Lifelong Benchmark for Training and Evaluating Free-Evolving Language Models. In _Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing_. 6237-6250.
* Jin et al. (2018) Zhen Jia, Abdallah Alguibali, Rahimi Shah Roy, Jannik Struggen, and Gerhard Weikum. 2018. Tresponstein: A benchmark for temporal question answering. In _Companion Proceedings of the The Web Conference 2018_. 1057-1062.
* Jia et al. (2018) Zhen Jia, Abdallah Alguibali, Rahimi Shah Roy, Jannik Struggen, and Gerhard Weikum. 2018. Trequit: Temporal question answering over knowledge bases. In _Proceedings of the 2018 ACM international conference on information and knowledge management_. 1807-1810.
* Jin et al. (2021) Woojeong Jin, Rahul Khanna, Suji Kim, Dong-Ho Lee, Fred Morstatter, Aram Galatyn, and Xiang Ren. 2021. ForecastQA: A Question Answering Challenge for Event Forecasting with Temporal Text Data. In _Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)_. 4636-4650.
* Jin et al. (2020) Woojeong Jin, Meng Qu, Xiem Jin, and Xiang Ren. 2020. Recurrent Event Network: Autoregressive Structure Interfecover Temporal Knowledge Graphs. In _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)_. 6669-6668.
* Jung et al. (2021) Jaehun Jung, Jinhong Jung, and U Kang. 2021. Learning to walk across time for interpretable temporal knowledge graph completion. In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_. 786-795.
* Kipf and Welling (2016) Thomas K Kipf and Max Welling. 2016. Semi-Supervised Classification with Graph Convolutional Networks. In _International Conference on Learning Representations_.
* Laparra et al. (2018) Eggin Laparra, Dongfang Xu, and Steven Bethard. 2018. From characters to time intervals: New paradigms for evaluation and neural parsing of time normalizations. _Transactions of the Association for Computational Linguistics_ 6 (2018), 343-356.
* Lazaroglu et al. (2021) Angelid Lazaroglu, Adul Kuncu, Eitan Gribovakaya, Devang Agrawal, Adam Lita, Taylor Tersi, Miam Gomez, Cyprien de Maos Afanture, Tomas Kocisky, Sebastian Ruder, et al. 2021. Mind the gag: Assessing temporal generalization in neural language models. _Advances in Neural Information Processing Systems_ 34 (2021), 29843-29833.
* Lee et al. (2023) Dong-Ho Lee, Xin Abraham, Woojeong Jin, Fred Morstatter, and Jay Pujara. 2023. Temporal Knowledge Graph Persuoting Without Knowledge Using In Context Learning. _arXiv preprint arXiv:2305.10613_ (2023).
* Loewenberg and Moens (2019) Arthur Loewenberg and Marie-Francine Moens. 2019. A survey on temporal reasoning for temporal information extraction from text. _Journal of Artificial Intelligence Research_ 69 (2019), 341-380.
* Lewis et al. (2020) Mike Lewis, Yishan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelnham Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension. In _Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics_. 7871-7880.
* Li et al. (2023) Xingyuan Li, Liyeng Cheng, Qingyu Tang, Hwee Tung Ng, Shafiq Jid, and Lidong Bing. 2023. Unlocking Temporal Question Answering for Large Language Models Using Code Execution. _arXiv preprint arXiv:2305.1094_ (2023).
* Li et al. (2022) Zixuan Li, Siqing Guan, Jiayen Wei, Pengxin Ju, Yong Zhu, Long Bai, Li Jiefeng Guo, Xueqi Cheng, Zuoqiang Fu, Xian Liu, and Yuqi Cheng. 2022. Complex Evolutional Pattern Learning for Temporal Knowledge Graph Reasoning. In _Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)_. 290-2905.
* Li et al. (2021) Zixuan Li, Xiaolong Jin, Saping Guan, Wei Li, Jiafeng Guo, Yuanhuo Wang, and Xueqi Cheng. 2021. Search from History and Reason for Future: Two-stage Reasoning on Temporal Knowledge Graphs. In _Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)_. 4732-4743.
* Li et al. (2022) Zixuan Li, Xiaolong Jin, Wei Li, Siqing Guan, Jafeng Guo, Huawei Shen, Yuanhuo Wang, and Xueqi Cheng. 2021. Temporal knowledge graph reasoning based on evolutional representation learning. In _Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval_. 408-417.
* Lin et al. (2018) Chen Lin, Timothy Miller, Dmitry Dligoch, Steven Bethard, and Guergana Savora. 2019. A BERT-based universal model for both within and cross-sentence clinical temporal relation extraction. In _Proceedings of the 2nd Clinical Natural Language Processing Workshop_. 65-71.
* Lin (2004) Chin-Yew Lin. 2004. Range: A package for automatic evaluation of summaries. In _Text summarization branches of Text-81_.
* Liu et al. (2023) Qikai Lin, Jun Liu, Rui Ma, Fanghui Xu, and Eric Cambria. 2023. TECHS: Temporal and Logical Graph Networks for Explainable Extrapolation Reasoning. In _Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_. 1281-1299.
* Liu et al. (2022) Yushan Liu, Yunpu Ma, Marcel Hidebrandt, Mitchell Joblin, and Volker Tresp. 2022. Topic Temporal logical rules for emphasizing link forecasting on temporal knowledge graphs. In _Proceedings of the AAAI conference on artificial intelligence_, Vol. 34. 612-6127.
* Mahau et al. (2018) Puneet Mahau, Rajiv Jain, Franck Dernomourt, Vlad Morrain, Quan Hung Tran, and Dhendu Manocha. 2018. Times: document-level temporal relation extraction. In _Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)_. 524-533.
* Moreno et al. (2019) Marcio Moreno, Rodrigo Santos, Wallas Santos, Sandro Fiorini, Reinaldo Silva, and Brento Cerqueira. 2019. Multimedia search and temporal reasoning. In _2019 IEEE/ACL'15th International Conference on Computer and Information Science (ICIS)_. IEEE, 167-172.
* Ring et al. (2017) Qung Ring, Zhi Feng, and Dan Roth. 2017. A Structured Learning Approach to Temporal Relation Extraction. In _Proceedings of the 2017 Conference on EmpiricalMethods in Natural Language Processing_. 1027-1037.
* [140] Long Quayang, Jeffrey Yu, Xu Jiang, Diego Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. _Advances in Neural Information Processing Systems_ 5 (2022), 2770-2774.
* [141] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In _Proceedings of the 40st annual meeting of the Association for Computational Linguistics_. 311-318.
* [142] Guillaume French, Guentin Malatric, Daniel Henslow, Rusananda Cajocaru, Alessandro Cappelli, Itiram Aldoubielli, Brigitte Panneva, Ebbeman Almazzouvel, and Julien Lunay. 2023. The Refined Web dataset for L1MC: outperforming L1MC: outperforming L2023. ecc/2023. ecc/20116.
* [143] Jeff Balacy, Samyan Rajbhandani, Gulraj Rowsae, and Tuqing He. 2020. Deep speech: System optimizations enable training deep learning models with over 100 billion parameters. In _Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_. 3505-3506.
* [144] Aszancan, S Chalkarathari, and Phahakhar. 2021. Question answering over temporal knowledge graphs. In _ACL-IJCNLP 2021-59th Annual Meeting of the Association for Computational Linguistics and the 14th International Joint Conference on Natural Language Processing, Proceedings of the Conference_. Association for Computational Linguistics (ACL), 663-6676.
* [145] Michael Schlicht, Thomas N Kipf, Peter Bloom, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In _The Semantic Web '18th International Conference, ESWC 2018, Heraklina, Crete, Greece_. June 3-7, 2018. _Proceedings 15_. Springer, 593-607.
* [146] Xiaomingu, Shiqo Xue, Kangjun Wang, Zhan Zhou, James T., Jun Zhou, Chehao Tan, and Hongyuan Sun. 2021. Language Models: Language and Language Event Representation by Few-Shot Abductive Reasoning. _arXiv preprint arXiv:2005.16646_ (2023).
* [147] Lei Shu, Liangchen Luo, Jayakumar Hoskere, Yun Zhu, Canoee Liu, Simon Tong, Jindong Chen, and Lei Meng. 2020. Rewrillact: An Instruction-Tuned Large Language Model for Text Rewriting. _arXiv preprint arXiv:2005.15658_ (2023).
* [148] Monika Solanki, Antonio Can, and Huxen Zelan. 2006. Temporal reasoning of reactive web services. _Semantic Web Services, Process and Applications_ (2006), 107-136.
* [149] Hohui Sun, Jiahua Zhong, Yunpu Ma, Zhen Han, and Kun He. 2021. TimTax-eber: Reinforcement Learning for Temporal Knowledge Graph Forecasting. In _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_. 8306-8319.
* [150] Qingyu Tan, Hwee Tong Ng, and Lidong Bing. 2023. Towards Benchmarking and Improving the Temporal Reasoning Cabability of Large Language Models. In _Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_. Association for Computational Linguistics, Toronto, Canada, 14803-14835. [https://doi.org/10.1865/1023.acl-bio.628](https://doi.org/10.1865/1023.acl-bio.628)
* [151] MonsicicM. NLP Team. 2023. _Introducing MPI-7B: A New Standard for Open Source_. Cournichlety Guide LMMs. www.moucail.com/blog/mpf-7b Accessed: 2023-05-05.
* [152] Hugo Torron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahai, Yang-mane Babar, Nikolya Boulagov, Suzma Pariad Burgayas, Shuri Bhosale, et al. 2023. Lluma: 2 Open foundation and fine-tuned chat models. _arXiv preprint arXiv:2307.09283_ (2023).
* [153] Rakhut Trivedi, Hanjun Dai, Yichen Wang, and Le Song. 2017. Know-evolve: Deep temporal reasoning for dynamic knowledge graphs. In _international conference on machine learning_. PMLR, 342-341.
* [154] Marc Verhagen, Robert Gairasanks, Frank Schilder, Mark Hepple, Jessica Moskowicz, and James Patejovsky. 2009. The Temporal challenge: identifying temporal relations in text. _Language Resources and Evaluation_ 3 (2009), 161-179.
* [155] Marc Verhagen, Roser Sauri, Tommas Caselli, and James Patejovsky. 2010. SemEval-2010 Task 13: TemEval-2. In _Proceedings of the 5th international workshop on semantic evaluation_. 57-30.
* [156] Haoyu Wang, Muhao Chen, Hongming Zhang, and Dan Roth. 2020. Joint Constrained Learning for Event-Event Relation Extraction. In _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)_. 696-706.
* [157] Yishong Wang, Yegang Korbi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashish, and Hamannesh Hajishiras. 2022. Self-intractor: Aligning language model with self generated instructions. _arXiv preprint arXiv:2210.05602_ (2022).
* [158] Jason Wei, Ti Tay, Rishi Bombman, Colin Raffel, Tareri Zoph, Sebastian Borgward, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. 2022. Emergent abilities of large language models. _arXiv preprint arXiv:2206.07682_ (2022).
* [159] Dongfang Xu, Egoita Laparra, and Steven Bethard. 2019. Pre-trained contextual-level character embeddings lead to major improvements in time normalization: A detailed analysis. In _Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (* SEM 2019)_. 68-74.
* [160] Wenjie Xu, Ben Liu, Miao Peng, Xu Jia, and Min Peng. 2023. Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion. In _Findings of the Association for Computational Linguistics: ACL 2023_. Association for Computational Linguistics, Toronto, Canada, 7790-7803. [https://doi.org/10.1865/17/2023.findings-ad.v3](https://doi.org/10.1865/17/2023.findings-ad.v3)
* [161] Chenhan Yuan, Quanqian Xie, and Sophia Ananiadou. [n. d.]. Temporal Relation Extraction with Contrastive Prototypical Sampling. _Available at SSRN 462841_ (1n. d.).
* [162] Chenhan Yuan, Quanqian Xie, and Sophia Ananiadou. 2023. Zero-shot Temporal Relation Extraction with ChaffGT. In _The 2Nd Workshop on Biomedical Natural Language Processing and BioNLP-Shand Tanks_. Association for Computational Linguistics, Toronto, Canada, 942-106.
* [163] Zhiang Zhang, Yarshu Kihor, Felix Hu, Kilian Q Weinberger, and Yoav Arti. 2019. BERT: Relevance: Evaluating Text Generation with BERT. In _International Conference on Learning Representations_.
* Temporal Knowledge Base?. In _Findings of the Association for Computational Linguistics: EMNLP 2022_. 22024-2037.
* [165] Liammin Zheng, Wei-li Li, Chang Ying Sheng, Yiyuan Zhuang, Liqianghou Tang, Yuqhao Zhuang, Li, Zhixuan Li, Liqiang Li, Cheng Li, Hua Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Jugling LLM-as-a-judge with MT-Bench and Chatbot Arena. arXiv:2306.50615(cs.CL).
* [166] Andy Zou, Tritan Xiao, Ryan Jiao, Jao Zhou, Martana Manzikin, Richard Li, Dawn Song, Jacob Steinhardt, Ovenin Evans, and Dan Hendrycks. 2022. Forecasting future word events with neural networks. _Advances in Neural Information Processing Systems_ 35 (2022), 22793-27305.

## Appendix A Human Annotation and Evaluation

### Settings

We recruited two Computer Science Ph.D. students with expertise in natural language processing (NLP) to manually annotate the test dataset and evaluate the performance of each model. The annotators were provided with the full sample set for each instance in the test data, consisting of the input document, the question about future events, and the ground truth answer with an explanation. To evaluate model performance, the annotators were also shown the model-generated explanation alongside the complete sample. By having domain experts manually annotate the testing data and compare model outputs, we aimed to robustly assess the ability of each model to provide accurate and logical explanations.

### Annotation Guideline

Here we describe our human annotation guidelines for annotating and evaluating the prediction and explanation quality.

_Overview:_ You will evaluate machine-generated predictions about future events along with explanatory reasoning. The predictions and explanations are based on a given context document. Please rate each answer on a scale of 1 to 3 using the criteria below: _Prediction Accuracy (1-3)_:

* The prediction on whether the event will occur is incorrect. For example, the prediction is that Event X will occur, but Event X does not happen
* The prediction on whether the event will occur is correct but the reasoning is flawed
* The prediction and reasoning are fully accurate and aligned

_Explanation Completeness (1-3)_:

* The explanation does not provide the necessary context/background to support the prediction. (e.g. "This will happen because of past events" with no further details)
* The explanation provides some relevant context but lacks important details
- The explanation comprehensively provides the background needed to understand the prediction
* _Explanation Fluency (1-3):_
* The explanation is unclear or difficult to understand, such as wordy, confusing, or unclear connections between ideas, etc.
* The explanation could be improved stylistically but is reasonably clear
* The explanation is fluent, coherent, and easy to comprehend

### Agreement Level

We present the human evaluation agreement level by using Cohen's Kappa score in this section. Note that the completeness inter-agreement level is relatively lower compared with the other two criteria. The main reason is that the completeness score heavily relies on the annotator's own logic and domain knowledge, which may introduce the annotator bias.

## Appendix B GIG Strategy Examples

### Detailed Prompts

#### b.1.1. Template-generated explanation evaluation prompt

Given the text, \(F_{i}^{\prime}\), please evaluate the correctness of the prediction based on the reasoning steps shown in the text. Answer correct or wrong then explain your decision concisely

#### b.1.2. revision Prompt

Please revise the provided text to ensure the prediction aligns with the reasoning steps. Adjust the flaws accordingly to reflect a correct prediction. Emphasize the importance of a logical progression of reasoning. You can add information from the following quadruples only if it is necessary for making the correct prediction. Finally, make the whole revised text more readable and coherently by expanding the explanation of each reasoning step. [\(\mathcal{Q}\)]

#### b.1.3. negative sample generation prompt

Given the text, "Based on the information provided by the document, we predict that \(e_{1}\)\(r^{\prime}\) e\({}_{2}\) will not happen in \(t_{i}\). We could find the following patterns from the text: \(Pa_{1}\), and \(Pa_{2}\),\(\cdots\), therefore, it is plausible that \(e_{1}\) will \(r\) e\({}_{2}\) in \(t_{i}\)," please evaluate the correctness of the prediction based on the reasoning steps shown in the text. Answer correct or wrong then explain your decision concisely

#### b.1.4. neutral sample generation prompt

Given the document "[\(D_{i}\)]", how likely the event that [\(e_{1}^{\prime}\)\(r\)\(e_{2}^{\prime}\)] in [\(t_{i}\)] would happen? Please note that the context shown in the given document may not be directly related to the event, so your answer should be uncertain. And if the context is unrelated, summarize the context and tell me why you think the context is not related.

### A GIG Workflow Example

To better help readers understand our proposed GIG explainable temporal reasoning dataset construction strategy, we provide a detailed example here to show the workflow of GIG.

First, we identify a query on temporal knowledge graph (_China, host a visit, Barack Obama(7), 2014-11-10)_. Then a reasoning path from explainable temporal knowledge graph reasoning models can be obtained:

\[Iran\xrightarrow{\text{sign formal agreement, 11-06-2014}}Barack Obama \tag{3}\]

. We then extract quadruples/events that happened during the past week of 2014-11-10 that include either China or Barack Obama and name them context quadruples. We also include the quadruples on the reasoning path in the context. The context quadruples are shown in Table. 7 We then generate a very simple natural sentences-format explanation based on the reasoning path:

_Based on the information provided by the document, it is plausible that China will host a visit Barack Obama on 11-10-2014. Here are my reasons: 1: Iran sign formal agreement Barack Obama on 11-06-2014, and 2: Barack Obama express intent to meet or negotiate on 11-04-2014 China. Therefore, it is plausible that China will host a visit Barack Obama on 11-10-2014_

We prompt this explanation and the context quadruples to ChatGPT following the polish or revise prompt. Then ChatGPT-generated explanation can be obtained:

_Yes. Based on the information provided in the document, it is plausible to predict that China will host a visit by Barack Obama on November 10, 2014. Here's a breakdown of the logical progression of reasoning to support this prediction: 1. China has a history of hosting visits by foreign leaders. For instance, China hosted a visit by Michael Sata on January 2nd, 2014. 2. In a reciprocal fashion, following Sata's visit, Michael Sata made a visit to China on the same day of January 2nd, 2014. 3. Later, China also hosted a visit by Barack Obama on March 4th, 2014. Based on these three points, it can be inferred that China has established a pattern of hosting visits by foreign leaders, including both Michael Sata and Barack Obama._

\begin{table}
\begin{tabular}{l c c c} \hline \hline  & Correctness & Completeness & Fluency \\ \hline Llama-7b & 0.73 & 0.47 & 0.98 \\ Finetuned Llama2 & 0.82 & 0.54 & 0.99 \\ ChatGPT & 0.77 & 0.41 & 0.98 \\ Vicuna & 0.74 & 0.50 & 0.97 \\ \hline \hline \end{tabular}
\end{table}
Table 6. Cohen’s Kappa score of human evaluation for each criterion in each LLM.

\begin{table}
\begin{tabular}{l l} \hline \hline  & sign formal agreement, 11-06-2014 \\  & & \\ express intent to meet or negotiate, 11-06-2014 \\  & & \\ host visit, 11-10-2014 \\  & & \\ \hline \hline \end{tabular}
\end{table}
Table 7. The context quadruples for query (_China, host a visit, Barack Obama(7), 2014-11-10)__Therefore, it is logical to conclude that China may host a visit by Barack Obama on November 10th, 2014._

We obtained the answer and explanation in this way.

Then we construct the context document by prompting ChatGPT to generate coherent sentences to describe the context quadruples:

Between November 4th and November 7th, 2014, there were several notable events related to international relations. First, on November 4th, Barack Obama expressed his intent to meet or negotiate with China.... These events indicate a series of significant diplomatic engagements between various countries and key figures during this period.

The input document can be built in this way.

We convert the query into natural language format by injecting the query into a set of diverse question templates:

Given the following document, can we expect that China will host a visit Barack Obama on 2014-11-097 Can you please answer with a yes, no, or unsure first, and then explain your decision?

### Direct Prompting Failure of ChatGPT

In order to directly compare the performance of our approach to that of ChatGPT, we have included an example of a ChatGPT failure case in Table 8. As illustrated, ChatGPT struggled to detect the underlying logic and causal relationships between events described in the provided document. In contrast, our proposed approach was able to successfully predict and reason about the sequence of events. This comparison highlights the challenges of relying solely on direct prompting of large language models like ChatGPT for dataset construction. Our results suggest that a more structured, programmatic approach to dataset creation, like the one proposed in the paper, may be necessary to produce high-quality training data with reliable logical reasoning abilities.

## Appendix C Reverse Relations

As described in the section on negative sample generation, we carefully manually designed inverse relations for all relations present in the original temporal knowledge graph. This ensures that if an event occurs, the inverse event is highly unlikely to occur. Table 9 provides examples of the inverse relations we crafted.

## Appendix D Experiments Background

### IceWS dataset

The ICEWS datasets are built from the Integrated Crisis Early Warning System, which monitors and analyzes world events to identify potential crises. The most popular ICEWS datasets are ICEWS14, ICEWS18, and ICEWS0515. The number denotes the year of the events in each dataset. The statistics of each dataset are shown in Table 10.

### Hyper-parameters

Training hyperparameter details are as follows. A per-device batch size of 2 was utilized with a gradient accumulation step of 16. Optimization was performed with the AdamW algorithm, employing a peak learning rate of 2e-5 and a warm-up ratio of 0.03. The maximum model input length was set to 2048 tokens. DeepSpeed ZeRO stage 3 was enabled for optimization. All models were trained using 4 Nvidia Tesla A100 GPUs, each with 80GB of memory.

## Appendix E Unexplainable Temporal Knowledge Graph Event Forecasting Models

Here we examine methods developed for the temporal knowledge graph event forecasting task, which aim to improve predictive accuracy rather than explainability. Specifically, we review models designed for this forecasting task that do not incorporate explainable components into their architectures. The goal of these models is to enhance predictive correctness on the forecasting benchmark, without considerations for explainability or interpretability. By focusing solely on improving forecasting performance, these methods provide a baseline to compare future work on building explainable forecasting models.

Specifically, in TKG event forecasting, the first effort is Know-evolve, which captures the continuous-time temporal dynamics and predicts future facts by estimating the conditional probability of temporal point process (Selvin and Komodakis, 2016). With the rise of graph neural networks (GNN), Relational-GCN has been introduced into event forecasting to replace temporal point process (Kumar et al., 2017). The two influential RGCN-based methods are RE-NET and RE-GCN, where RE-NET utilized RGCN to encode long-term representations of temporal knowledge graphs by designing an autoregressive event recurrent encoder (Kumar et al., 2017) and RE-GCN proposed to focus on the graph dependency structure (Kumar et al., 2017).

## Appendix F Ethical Considerations and Limitations

In developing this temporal reasoning dataset, care has been taken to ensure appropriate consideration of ethical issues and limitations commonly associated with large language models. The source data has been carefully curated to provide diversity and mitigate biases. Events representing a wide range of demographic groups are included to avoid propagating systemic stereotypes. We acknowledge that, despite best efforts, the dataset may exhibit gaps or contain unintended biases. Finally, we recognize that large language models carry risks of generating harmful, biased, or logically incoherent content through hallucination. Our evaluation methodology takes this into account by prioritizing answer accuracy over fluency. With rigorous design and testing processes, we aim to uphold ethical AI principles while furthering research on temporal reasoning.

[MISSING_PAGE_EMPTY:13]