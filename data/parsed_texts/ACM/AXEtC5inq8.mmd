# NCTM: A Novel Coded Transmission Mechanism for Short Video Deliveries

###### Abstract.

With the rapid popularity of short video applications, a large number of short video transmissions occupy the bandwidth, placing a heavy load on the Internet. Due to the extensive number of short videos and the predominant service for mobile users, traditional approaches (e.g., CDN delivery, edge caching) struggle to achieve the expected performance, leading to a significant number of redundant transmissions. In order to reduce the amount of traffic, we design a Novel Coded Transmission Mechanism (NCTM), which transmits XOR-coded data instead of the original video content. NCTM caches the short videos that users have already watched in user devices, and encodes, broadcasts, and decodes XOR-coded files separately at the server, edge nodes, and clients, with the assistance of cached content. This approach enables NCTM to deliver more short video data given the limited bandwidth. Our extensive trace-driven simulations show how NCTM reduces network load by 3.02%-14.75%, cuts peak traffic by 23.01%, and decreases rebuffering events by 43%-85% in comparison to a CDN-supported scheme and a naive edge caching scheme. Additionally, NCTM also increases the user's buffered video duration by 1.21x-13.53x, ensuring improved playback smoothness.

short video delivery, coded transmission, client-side cache +
Footnote †: ccs: Networks Mobile networks

+
Footnote †: ccs: Networks Mobile networks

+
Footnote †: ccs: Networks Mobile networks

+
Footnote †: ccs: Networks Mobile networks

+
Footnote †: ccs: Networks Mobile networks

## 1. Introduction

Short video applications such as Tiktok (Tiktok, 2016) and YouTube Shorts (Brockman et al., 2017) are rapidly rising in popularity, attracting billions of active users per month (Brockman et al., 2017; Bockman et al., 2017), and consistently topping the best-selling apps lists (Brockman et al., 2017). Taking Tiktok as an example, it had 1.4 billion monthly active users in 2022, and it is predicted to reach 1.8 billion by the end of 2023 (Brockman et al., 2017). Billions of users imply a huge number of video streams. According to TikTok's report (Brockman et al., 2017), globally, 167 million hours of short videos are consumed every minute, putting an enormous pressure on the current Internet infrastructure.

Traditional video transmission solutions maintain videos on the cloud and stream them to users via content delivery networks (CDNs) (Brockman et al., 2017; Bockman et al., 2017). A major weakness of CDN is the huge redundant traffic, causing network pressure and affecting the user viewing experience. Edge caching approaches (Brockman et al., 2017; Bockman et al., 2017; Bockman et al., 2017) can reduce the amount of redundant traffic by caching user-desired contents at edge nodes (Brockman et al., 2017; Bockman et al., 2017; Bockman et al., 2017). However, in short video services, users have different preferences determined by their hobbies, culture, educational backgrounds, lifestyles, etc. Even though videos are rarely watched in groups, they might be popular with other users (Bockman et al., 2017). Therefore, at the edge, it is difficult to identify which are the most popular videos among various ones. As a result, it is difficult for edge nodes to cache adequate user-desired contents due to limitations in cache capability, leading to low caching efficiency (Kumar et al., 2018). According to Nokia's report (Nokia, 2018), the hit rate of edge caching solutions is only 29% for short video delivery. Therefore, edge caching is not always as effective as expected.

Recent studies (Zhu et al., 2018; Wang et al., 2018) have revealed that using client-side caches within a peer-to-peer (P2P) network can significantly reduce bandwidth pressure caused by redundant video transmissions (Zhu et al., 2018). P2P is a promising solution to increase the cache hierarchy and can compensate for the limited edge node capability. However, the majority of short video deliveries are from mobile devices, e.g., 97% of TikTok video deliveries (Brockman et al., 2017). The expensive uploading data bills or the data cap make P2P not a feasible solution. Therefore, we aim to make better use of the client-side cache to compensate for the lack of edge cache capacity, while avoiding the upload traffic costs.

Coded cache (Zhu et al., 2018; Wang et al., 2018; Wang et al., 2018; Wang et al., 2018) could provide a solution. It avoids transmission redundancy by transmitting coded files without incurring additional traffic charges. It is based on merging two separate video files into one coded file at the server and forward it to the destination. The most commonly used encoding approach is XOR-merging (Exclusive OR). After receiving the coded file, the destination device separates the original files by locally cached content prefetched during network idle time. So the coded cache technique requires fewer transmission files to transmit all data. But it also means some contents need to be cached in the destination device before use, and devices need to be active simultaneously to receive the coded files in time. However, in practice, short video applications generally do not allow network usage when they are closed, and the server lacks mechanisms to confirm the apps running status or interact with the users' cache. The above-mentioned problems hinder the practical deployment of the coded cache solution.

In this paper, we propose an innovative **Novel Coded Transmission Mechanism (NCTM)** for efficient short video delivery. With deep insight on the characteristics of short video delivery, NCTM avoids content prefetching or uploading through an effective cooperation between the cloud, edge, and mobile clients. Particularly, NCTM caches videos that the user **has already watched** for subsequent decoding rather than prefetching ones.

As shown in figure 1, the cloud server in NCTM applies XOR operations to combine video files into a single coded file, and sends it to the edge node (coded transmission). Then the edge node broadcasts the coded file to specific mobile clients. The mobile clients will decode the coded file by applying XOR operations with the assistance of previously watched and cached videos. To make sure that the coded file can be successfully decoded, we should divide the clients into multiple groups, ensuring that any two clients

Figure 1. File flows example for NCTMwithin a group have previously watched and cached the files being requested currently by each other (group divided problem). So we introduce a User Cache Table (UCT) and a Transmission Matching Graph (TMG) that record the cache status and explore coded transmission opportunities. Recognizing the similarity between the above-mentioned requirement and the mathematical concepts of "cliques", we model the group divided problem as the clique cover problem (Zhou et al., 2017; Zhang et al., 2018) and propose the novel _Minimum Clique Coverage algorithm_. This algorithm involves multiple linear-time searches to find a relatively optimal solution. Furthermore, we introduce the new _Recommendation Reorder algorithm_, which modifies the playback order by bringing forward videos scheduled for later to create more opportunities for coded transmission. Finally, we propose a _Client-side Cache Update method_ based on the video recommended queue, which is informed by the recommendation system in short video services.

To evaluate the performance of NCTM, we utilized the kuaiRec dataset (Zhou et al., 2017) and collected real user interactions with the Kuaishou app on August 12, 2020, totaling 117,977 records. For each client, edge node, and cloud server, we created separate docker containers (Zhou et al., 2017) to simulate video requests and playback behaviors based on their app usage time. The results show that under sufficient bandwidth, NCTM reduces the average network load by 3.02%-14.75%, and cuts the peak traffic by 23.01%. With limited bandwidth, NCTM reduces 43%-85% of rebuffering events and increases video occupancy in the user's buffer by 1.21x-13.53x. Furthermore, we use the NCTM to assist the edge caching, proving that they are compatible. In addition, we demonstrate that NCTM can achieve real-time performance on the server and provide reference values for the hyperparameters in the proposed approach.

In summary, our contributions are as follows:

* We propose the innovative **NCTM** that sends XOR-coded files and utilizes the client-side cache to store watched videos for file decoding. This approach reduces the network load without data prefetching or uploading.
* We design the _Minimum Clique Coverage algorithm_ and the _Recommendation Reorder algorithm_ to find a relatively optimal solution for the client dividing problem with linear time complexity, which ensures successful decoding for the coded files in coded transmissions. The _Client-side Cache Update method_ based on the video recommended queue is also proposed.
* We devise trace-driven experiments to emulate the NCTM and verify its effectiveness in the reduction of bandwidth consumption, buffer variation, and rebuffering frequency.

The remaining of the paper is structured as follows. In section 2, we summarize the NCTM related work, in section 3, we illustrate the overall structure of NCTM and in section 4, NCTM is described in details. In section 5, the experimental results are presented. Finally, we give a brief conclusion of our work in section 6.

## 2. Related Works

The popularity of short video applications leads to massive video traffic and introduces a significant load on CDNs.

**Edge caching**(Zhou et al., 2017; Zhang et al., 2018) is a key approach to alleviate the CDN load. It utilizes cache-enabled edge servers, such as base stations and smart gateways, to store popular contents, so that these contents can be transmitted directly from the caches instead of from the remote cloud (Zhou et al., 2017). As these cache edges are closer to the users, there is a reduction in the traffic load on the core network. The cache hit rate is an essential metric to evaluate the performance of edge caching. For short video deliveries, (Zhou et al., 2017) proposes to consider the number of views and likes as the popularity basis to choose the edge cache content. Furthermore, (Zhou et al., 2017) takes user preferences into consideration. To achieve a higher hit rate, (Zhou et al., 2017) introduces a multi-agent deep reinforcement learning algorithm where each edge learns its own best policy.

**P2P-CDNs**(Zhou et al., 2017; Zhang et al., 2018; Zhang et al., 2018; Zhang et al., 2018) enables content caching on mobile phones by utilizing wireless channels for cache sharing, also known as P2P sharing. With a P2P approach, users can send their stored content to other users, effectively balancing the upstream and downstream transfers, and increasing the cache hierarchy (Zhou et al., 2017). (Zhou et al., 2017) considers different network environments. High-quality Internet access shares its resources (e.g., bandwidth) with slower or unreliable ones. (Zhou et al., 2018) takes advantage of user social information (friends/ followers), using the friend list to identify additional P2P sharing.

**Coded cache**(Zhou et al., 2017; Zhang et al., 2018; Zhang et al., 2018) utilizes network coding techniques, which aggregate (encode), broadcast, and separate (decode) data messages in the cloud, edge node, and client devices, respectively. This technique results in lower traffic load for data transmission. For example, if user A caches video file \(c_{1}\) and user B caches video file \(c_{2}\), when user A requests video file \(c_{2}\) and user B requests video file \(c_{1}\), the server can transmit a single coded file \(c_{1}\) @ \(c_{2}\) (the symbol @ represents bitwise XOR) instead of two separate files \(c_{1}\) and \(c_{2}\). It can deliver the coded file simultaneously to both users by broadcasting at the edge node, and users can decode it based on their local files (e.g., for user A: \(c_{1}\) @ \(c_{2}\) @ \(c_{1}=c_{2}\)).

The previous works made important contributions in terms of edge caching, P2P-CDNs and coded cache solutions individually, but they have not combined them in an approach that reduces the load for short video deliveries as proposed by NCTM.

## 3. NCTM Architecture and Principle

The overall NCTM architecture is shown in figure 2. The mobile clients cache their watched video files based on their cache capabilities, and the cloud server sends the coded files desired by multiple clients to the edge node. Then the edge node broadcasts the coded file to the mobile clients. These clients decode the coded file based on the cached files to obtain the desired one. To make sure the coded file can be successfully decoded, we need to ensure that all the files involved in the coded file have been cached at the clients, except the desired one. So the challenge lies in finding **how to efficiently and accurately identify the clients with the above

Figure 2. Overall structure of NCTM

cache situation among multiple ones**. We employ the following designs to address this challenge.

The cloud server includes three key modules: **Client Cache Management, Coded Chances Exploration**, and **XOR-encoder**. The Client Cache Management informs the cache status of the client's devices. We design the User Cache Table (UCT) (section 4.1) to record the cached files in clients. Due to the limited cache capability, we specify the corresponding cache update policy (section 4.4). The Coded Chances Exploration module finds the coded transmission opportunities, thus minimizing bandwidth consumption. Since the condition of multivariate-coded transmission is similar to the concept of clique in mathematics, we design the Transmission Matching Graph (TMG) and reduce the chances exploration problem to the clique cover problem (Zhu et al., 2017; Wang et al., 2018) (section 4.1). To solve this NP-Hard problem, we designed the _Minimum Clique Coverage algorithm_ to find a relative optimal solution within linear time complexity (section 4.2). Moreover, based on our observation, switching the playback order of short video can create more coded transmission opportunities, so we further proposed _Recommendation Reorder algorithm_ (section 4.3). File encoder merges several origin video files into one coded file by XOR before transmission.

The edge nodes copy the coded file and broadcast it to clients. Clients decode the coded file and extract the original files, as desired.

## 4. Coded Transmission Mechanism

### Definitions

We assume that there are currently \(N\) short video files, denoted as \(\mathbb{C}=\{C_{1},C_{2},...,C_{N}\}\). Short videos are commonly delivered with an adaptive bitrate paradigm (Zhu et al., 2017; Wang et al., 2018). Now we assume that each short video consists of only one video chunk; this will be generalized to the common case in the next section. Suppose there are \(K\) mobile clients, denoted as \(\mathbb{U}=\{U_{1},U_{2},...,U_{K}\}\). Each client is assigned an independent recommendation queue, storing short videos recommended for this user. We denote \(v_{lj}\) as the \(j\)-th video pushed to the \(i\)-th user (\(v_{lj}\in\mathbb{C}\) determined by the recommendation system). Therefore, for the user \(U_{i}\), the recommendation queue can be denoted as \(V_{i}=\{v_{11},v_{i2},...\}\). At this point, we define the UCT as \(\mathbb{T}=\{t_{ij}\}\), where \(t_{ij}=1\) indicates that user \(U_{i}\) has **watched and cached** video \(C_{j}\), and vice versa (\(i\in[1..K]\), \(j\in[1..N]\)). Thus, for the user \(U_{i}\), all the videos in their client-side cache can be recorded as \(T_{i}=\{C_{j}|t_{ij}=1,j\in[1..N]\}\).

For example, here we assume that user \(U_{a}\) has cached video \(C_{j}\), and user \(U_{b}\) has cached video \(C_{i}\). It can be denoted as \(t_{aj}=1\) and \(t_{bi}=1\), respectively. When the user \(U_{a}\) needs the video \(C_{i}\), and user \(U_{b}\) needs video \(C_{j}\), the coded file \(C_{i}\oplus C_{j}\) can be transmitted. So the condition for coded transmission is that **they have cached the files needed by each other** (e.g., \(t_{aj}=1\), \(t_{bi}=1\)), which is to ensure successful decoding in the user device (e.g., for user \(U_{a}\), \((C_{i}\oplus C_{j})\oplus C_{j}=C_{i}\), where \(C_{j}\) is watched and cached video file of user \(U_{a}\)). This is defined as a binary-coded transmission.

Similarly, here we assume that there are three users \(U_{a},U_{b}\), and \(U_{c}\) who need videos \(C_{i},C_{j}\), and \(C_{k}\), respectively. When \(t_{aj}=t_{ak}=1\), \(t_{bi}=t_{bk}=1\) and \(t_{ci}=t_{ej}=1\), indicating that each user has cached the files needed by the other two users, the coded file \(C_{i}\oplus C_{j}\oplus C_{k}\) can be transmitted. The client devices can also successfully decode the coded file with their cached video files. (e.g., for user \(U_{a}\), decoding can be achieved through \((C_{i}\oplus C_{j}\oplus C_{k})\oplus C_{j}\oplus C_{k}=C_{i}\)). This is defined as a ternary-coded transmission. Similar operations can be generalized to multivariate-coded transmission involving x video files (\(x\geq 2\)).

Clearly, a larger value of \(x\) indicates merging more video files into one coded file, resulting in fewer number of transmissions and less bandwidth consumption. Therefore, we prefer the coded transmission that covers more users. To make sure the client devices can successfully decode, multivariate-coded transmission requires that any two users satisfy the condition for binary-coded transmission. This requirement can be associated with the mathematical concept of "cliques" (a clique is a complete graph where any two nodes are connected by an edge (Zhu et al., 2017)). So we design the TMG as \(\mathbb{G}=(E,D)\) to model the multivariate-coded transmission exploration problem as a graph theory problem. \(D\) is the set of vertices representing the active users currently. If \(d_{i}\in D\), it means the user \(U_{i}\) is **watching videos**, and vice-versa. \(E\) is the set of edges. If \(e_{ij}\in E\), it means there is an edge between nodes \(i\) and \(j\), indicating that users \(U_{i}\) and \(U_{j}\) currently satisfy the **condition for binary-coded transmission**, and vice-versa.

Let us denote the watching video of user \(U_{i}\) as \(v_{i}^{*}\) (\(v_{i}^{*}\in V_{i}\)). In this case, for users \(U_{i}\) and \(U_{j}\), if \(t_{it^{\prime}_{j}}=t_{jt^{\prime}_{i}}=1\), it indicates that they have cached the files desired by each other, binary-coded transmission can be achieved, i.e., \(e_{ij}\in E\). Following this rule, we can construct the \(\mathbb{G}\) with \(K^{\prime}\) nodes, where \(K^{\prime}\) is the number of active users (\(K^{\prime}\leq K\)). In \(\mathsf{TMG}\), if we can find a clique with \(x\) nodes, it means that among these \(x\) users, any two users satisfy the condition for binary-coded transmission, thus satisfying the condition for multivariate coded transmission involving \(x\) users. On the other hand, all user requests need to be fulfilled, so any node in current TMG needs to be covered by a clique (a single node is also considered a clique, we define it as the separate clique). Therefore, the problem can be transformed into finding the **minimum number of cliques** that **cover all nodes** in the TMG. We call this the group divided problem.

Formally, we denote \(\mathbf{R}=\{R_{1},R_{2},...\}\) as all cliques in TMG, where the i-th clique is represented as \(R_{i}=\{d_{x},d_{y},...\}\). We must ensure \(R_{1}\cup R_{2}\cup...=D\) and minimize \(|\mathbf{R}|\). This problem is a classical clique cover problem and has been proven to be NP-hard when the degree of vertices is greater than 6 (Zhu et al., 2017; Wang et al., 2018). Finding an optimal solution requires high complexity. In this paper, we propose the _Minimum Clique Coverage algorithm_, which utilizes the previous result and a single traversal to solve this problem with linear time complexity. The details of this algorithm are presented in section 4.2.

Figure 3. Example of NCM with 6 users and 6 videos

Figure 3 illustrates an example containing \(6\) users and \(6\) videos, and gives intuitive cases of binary-coded transmission and ternary-coded transmission. In the example, two cliques are used to cover the TMG, with \(R_{1}=\{d_{1},d_{2},d_{3},d_{4}\}\) and \(R_{2}=\{d_{5},d_{6}\}\). Therefore, in the coded transmission, two coded files need to be transmitted. \(F_{1}\) merging \(4\) original video files \(C_{6},C_{4},C_{5},C_{3}\) and \(F_{2}\) merging \(2\) video files \(C_{2},C_{1}\). The decoding process will be completed in the client devices with cached video files. In practical deployment, we group users with close geographic proximity and similar playback queues together to perform coded transmission. So the scale of the UCT and the TMG will not be very large. In our experiments, there are 1398 users and 10230 videos, and the storage capacity for the UCT is 202MB, which does not impose a significant load on the server.

### Minimum Clique Coverage algorithm

To ensure smooth video playback, short video transmission uses the adaptive bitrate paradigm. We define a video \(C_{i}\) as composed of multiple video chunks, denoted as \(C_{i}=\{c_{i1},c_{i2},...\}\). Note that the UCT and TMG are dynamically maintained as the videos play.

As shown in figure 4, users \(U_{1}-U_{4}\) have already watched and cached parts of the videos. For example, the user \(U_{1}\) cached the videos \(C_{3},C_{4},C_{5}\), i.e., \(T_{1}=\{C_{3},C_{4},C_{5}\}\). Now let us consider that user \(U_{1}\) is watching video \(C_{6}\), user \(U_{2}\) is watching video \(C_{4}\), i.e., \(v_{1}^{*}=C_{6}\), \(v_{2}^{*}=C_{4}\), and so on. In the previous example, we assumed that all users request videos strictly at the same time. However, in this one, the user request time is different, and there are variations in the duration of the videos. For example, user \(U_{1}\) watches video \(C_{6}\) within the time range of 4-14 seconds, user \(U_{2}\) watches video \(C_{4}\) within the time range of 0-22 seconds, and so on. Therefore, the TMG also changes within different time intervals. The figure depicts the TMGs corresponding to the current 5 intervals. At this point, encoding operations are performed between different video chunks rather than the entire video (for example, at the 8th second, \(c_{63}\oplus c_{45}\oplus c_{51}\) is encoded for transmission). It is evident that the TMG changes only when a user either completes a video playback (e.g., 14th second) or starts watching a new video (e.g., 0th second, 4th second, 8th second, and 18th second). During each time interval, the TMG remains unchanged.

After completing a video playback, the user will leave the current TMG. Since the subgraph of a clique remains a clique, the removal of a node will not break the current clique. In the given example, at the 14th second, user \(U_{1}\) (node \(d_{1}\)) leaves the TMG, but users \(U_{2}\) (node \(d_{2}\)) and \(U_{3}\) (node \(d_{3}\)) can still form a clique. When a user starts playing a new video, a new node is added to TMG, but the cliques formed by all the existing nodes remain unchanged. So we can decide whether the new node can be added to an existing clique (maintaining the same total number of cliques) or the new node forms a separate clique (increasing the total number of cliques by 1). A similar situation can be seen in the example at the 8th second when user \(U_{3}\) joins the TMG as a new node \(d_{3}\). According to the rules, node \(d_{3}\) has edges with nodes \(d_{1}\) and \(d_{2}\), so it can be added to the clique formed by these two nodes, forming a clique with three nodes and achieving ternary-coded transmission.

Therefore, whenever a new request arrives, we need to add a new node to the TMG and try to incorporate this node into existing cliques. We can judge whether the incorporation condition is met by iterating through all existing cliques and checking whether all nodes can connect to the new node. If a suitable clique is found, the new node will be added to this clique, maintaining the existing number of cliques and the coded files to be transmitted unchanged. Otherwise, the new node forms a separate new clique, leading to an increase in both the number of cliques and the coded files to be transmitted.

However, the aforementioned approach often yields poor performance, as shown in figure 5. As new requests from user \(U_{5}\) and \(U_{6}\) arrive at time \(t_{2}\) and \(t_{3}\), new nodes \(d_{5}\) and \(d_{6}\) are added to current TMG. Since they do not have edges connecting to all nodes in the existing clique, they will form new cliques. Clearly, the optimal solution involves only two cliques, but the result at time \(t_{3}\) contains three. To address this issue, we propose a search algorithm with linear time complexity, the _Minimum Cliques Coverage algorithm_, to find a relatively optimal solution based on the previous results. The algorithm includes \(T\) iterations, where \(T\) is a hyperparameter that controls the computational cost. In each iteration, the following steps are executed:

1. Randomly select a node \(d_{i}\) among all separate cliques. We assume that \(d_{i}\) comes from the clique \(R_{x}\).
2. Randomly select an edge \(e_{ij}\) from all the edges connected the node \(d_{i}\). Obviously \(e_{ij}\) connects to node \(d_{j}\). We assume that \(d_{j}\) comes from the clique \(R_{y}\).
3. Let \(d_{j}\) exits the original clique \(R_{y}\) and joins the clique \(R_{x}\) where \(d_{i}\) belongs to. The processed cliques are denoted as \(R_{y}^{{}^{\prime}}\) and \(R_{x}^{{}^{\prime}}\), respectively.
4. Iterate through all the nodes (\(d_{k}\)) from \(R_{y}^{{}^{\prime}}\). Check if there exist nodes that have edge connected to \(d_{i}\) (\(e_{ik}\in E\)).
5. Make these nodes (\(d_{k}\)) exit the original clique \(R_{y}^{{}^{\prime\prime}}\) and join the clique \(R_{x}^{{}^{\prime}}\). The processed cliques are denoted as \(R_{y}^{{}^{\prime\prime}}\) and \(R_{x}^{{}^{\prime\prime}}\), respectively.
6. Iterate through all the remaining separate cliques (\(d_{k}\)). Check if one can be added to the clique \(R_{y}^{{}^{\prime\prime}}\) after excluding some nodes.
7. If such a separate clique exists, node \(d_{k}\) joins the clique \(R_{y}^{{}^{\prime\prime}}\). The processed clique is denoted as \(R_{y}^{{}^{\prime\prime}}\). Now a solution is found and the algorithm terminates. Otherwise, all adjustments are retained and the next iteration starts.

The pseudocode is shown in appendix A, and we prove this algorithm in appendix B. During the iteration, if such a separate

Figure 4. An example of asynchronous user requests

clique is found in Step 7, it means that we successfully merge two separate cliques (\(R_{x},R_{z}\)) and one non-separate clique (\(R_{y}\)) into two non-separate cliques (\(R_{x}^{\prime\prime},R_{y}^{\prime\prime\prime}\)). The total number of cliques and the coded files to be transmitted reduces by one, and the algorithm terminates. Otherwise, we still need to preserve the above operations so that the next iteration can discover more matching opportunities. Figure 6 illustrates an example of the _Minimum Cliques Coverage algorithm_. Here the separate cliques \(R_{3}(d_{4})\) and \(R_{1}(d_{7})\) are merged with the clique \(R_{2}\) containing three nodes \(\{d_{1},d_{2},d_{3}\}\) to form the new clique \(R_{i}^{{}^{\prime\prime}}\) with three nodes \(\{d_{1},d_{2},d_{7}\}\) and the new clique \(R_{2}^{{}^{\prime\prime\prime}}\) with two nodes \(\{d_{3},d_{4}\}\). At this point, the clique \(R_{3}\) disappears.

This algorithm is executed whenever a new request arrives and the newly added node in the TMG cannot join an existing clique (i.e., forming a separate clique). In each round, all nodes are traversed at most three times, resulting in a computational complexity of \(\mathcal{O}(KT)\), where \(K\) is the number of users in the current TMG, and \(T\) is a hyperparameter that controls the number of iterations. We will further explore the time complexity of this algorithm and the impact of \(T\) on the success rate of the search in our experiments.

The major benefit of the above algorithm is that we do not rely on any prior knowledge (such as video popularity or predictions of user viewing behavior). Instead, we dynamically adjust the cliques through the UCT and TMG. This allows us to determine which users currently satisfy the coded transmission conditions. Furthermore, with the assistance of the _Minimum Clique Coverage algorithm_, we utilize the historical results to explore a better solution for the clique cover problem in linear time complexity. This allows us to use fewer cliques, which means fewer coded files to be transmitted, thereby reducing bandwidth consumption.

### Recommendation Reorder algorithm

Based on our observations, the opportunities for coded transmission are related to users currently watching videos. In some cases, playing a video located further in the recommended queue may create more chances for coded transmission than playing the very next video. A typical example is presented in figure 7.

The example contains two users, \(U_{1}\) and \(U_{2}\). User \(U_{1}\) has a recommendation queue \(V_{1}=\{C_{3},C_{4},C_{5},C_{6},C_{1},\ldots\}\), and videos \(C_{3}\), \(C_{4}\) and \(C_{5}\) have been watched and cached in the client device, i.e., \(T_{1}=\{C_{3},C_{4},C_{5}\}\). User \(U_{1}\) is currently watching the video \(C_{6}\), i.e., \(v_{1}^{s}=C_{6}\). Similarly, \(V_{2}=\{C_{6},C_{3},C_{1},C_{4},C_{5},\ldots\}\), and \(T_{2}=\{C_{6},C_{3}\}\). Since the previous video has just ended, no video is being played by user \(U_{2}\). Now we find that if video \(C_{1}\) is played next based on the recommendation queue, since \(t_{11}=0\), NCTM cannot be used between users \(U_{1}\) and \(U_{2}\). However, if video \(C_{4}\) is chosen to be played next (also in the recommendation queue, but not the very next one), we have \(t_{26}=t_{14}=1\), and NCTM can be used. Specifically, if the user \(U_{2}\) chooses video \(C_{1}\) as the next one, there will be no edges connecting to node \(d_{2}\) in the TMG, and the node \(d_{2}\) will inevitably form a separate clique. However, if \(U_{2}\) chooses video \(C_{4}\), in the TMG, the node \(d_{2}\) will have at least one edge. Even if it forms a separate clique, with the _Minimum Clique Coverage algorithm_, it also offers the potential for coded transmission.

For push-playback short videos, there are no content correlations between two consecutive videos. Therefore, changing the playback order of videos without altering their content will not significantly affect the user experience. The above example illustrates that in certain situations, reordering the recommendation queue can create more opportunities for coded transmission. Given that the users might end, skip, or re-watch videos at any time, this makes it difficult to predict users' viewing behaviors. Therefore, we propose the _Recommendation Reorder algorithm_, which focuses on short-term benefits. Whenever a user switches videos, this algorithm will filter the videos that can trigger **NCTM** based on the current UCT and select one based on the recommendation queue. This method does not change the recommendation queue results, but changes the video playback order by prioritizing the ones that enable coded transmission. Thus, it creates more chances for coded transmission. The pseudocode is shown in appendix D. The algorithm considers the next \(G\) videos in the recommendation queue of user \(U_{i}\). For each video, it iterates through all users to determine if the binary-coded transmission can be used. The algorithm can be described as the following process:

1. Traverse the next \(G\) videos in \(V_{i}\), denote as \(C_{j}\).
2. For each \(C_{j}\), traverse all other active users, denote as \(U_{k}\). Check if one satisfies the requirement of binary-coded transmission, i.e., \(t_{kj}=t_{t_{t_{k}^{j}}}=1\).
3. If such a user exists, let \(v_{i}^{s}=C_{j}\). That is, the next video to be played is \(C_{j}\). Otherwise, still play the first video in \(V_{i}\).

Here \(G\) is a hyperparameter that decides the maximum number of look-forward videos as well as limits the computational cost.

Figure 5. Naive solutions often fail to achieve optimal solutions

Figure 6. An example of the Minimum Cliques Coverage algorithm

This algorithm involves two iterations. So the time complexity is referred to \(\mathcal{O}(GK)\), where \(G\) represents the number of next videos considered in the recommendation queue, and \(K\) represents the number of users watching videos. To further prune the search path, we can avoid the case where \(t_{tv_{i}^{*}}=0\) during the first traversal, i.e., excluding the users who are watching the video not cached by user \(U_{i}\). That is because the user \(U_{i}\) can not meet the coded transmission condition whatever the next video is, and it is impossible to change others playing videos.

Currently, most short video applications pre-cache the first video chunk of several subsequent videos in the recommendation queue, to alleviate the stalling and rebuffering issues caused by rapid video switching. For example, TikTok pre-caches the first video chunk of the next five videos (TikTok, 2018). Assuming the application pre-caches the first video chunk of \(P\) subsequent videos, it should ensure \(G\leq P\) to mitigate the risk of increased stalling and rebuffering events.

### Client-side cache update method

As discussed in Section 1, both edge caching and client-side cache have limited storage capabilities. Compared to edge caching, user devices (such as smartphones) may be more restricted. In this section, we will discuss how to perform cache placement/replacement to better cooperate with the _Minimum Clique Coverage algorithm_ and _Recommendation Reorder algorithm_.

We define the maximum storage capacity for user \(U_{i}\) as \(M_{i}\), thus we need to ensure that \(\sum_{C_{j}\in T_{i}}|C_{j}|\leq M_{i}\), where \(T_{i}\) is the cached videos of user \(U_{i}\) and \(|C_{j}|\) represents the file size of video \(C_{j}\). Suppose that after watching video \(C_{k}\), \((\sum_{C_{j}\in T_{i}}|C_{j}|)+|C_{k}|>M_{i}\), indicating that the user \(U_{i}\) cannot store all watched videos on the user device. Therefore, it is necessary to determine which content should be replaced.

For video \(C_{k}\), we cache video files so we can decode the coded files with the assistance of them in the future. Hence, cached videos \(C_{k}\) are only valuable if they are watched by other users later. Using the "push playback" style, a recommendation system can keep track of the video playback list. Therefore, we can estimate the earliest possible time when the video \(C_{k}\) will be used for file decoding. As NCTM mainly focuses on short-term benefits, we prefer the files that can create coded transmission opportunities in the short term and replace those that would take longer to be used.

Formally, we define \(F(C_{k})\) as the earliest occurrence time of video file \(C_{k}\) in the recommendation queue. That is, \(F(C_{k})=\min(j)\)_s.t._\(v_{ij}=C_{k}\)_for all_\(i\in[1..K]\), where we find the smallest \(j\) among all \(K\) users' recommendation queues such that \(v_{ij}=C_{k}\). This is the earliest possible time when the current video could be used for decoding. For the user \(U_{i}\), we can sort the videos in \(T_{i}\) based on \(F(C_{k})\) and replace the videos that would take longer to be used.

Note that from the perspective of the _Recommendation Reorder algorithm_, it can be regarded as \(F^{*}(C_{k})=\max\{1,F(C_{k})-G\}\), where \(G\) is the hyperparameter defined in the algorithm description. This is because the _Recommendation Reorder algorithm_ can look ahead \(G\) videos based on the current recommendation queue, thus this video could potentially be played ahead by up to \(G\) videos. Additionally, when we consider edge cache, if video \(C_{k}\) is cached in the edge cache, it means that requests involving video \(c_{k}\) will not use NCTM and can be regarded as \(F(C_{k})=+\infty\).

### Further considerations

According to our further observations, due to the spatial and temporal densification of of short videos, NCTM exhibits significant potential in practical applications. For the uncompleted watching events, we will consider weighted _TMG_ in our subsequent work to explore more stable coded transmission opportunities. Furthermore, short video playback on mobile devices also exhibits a significant degree of randomness. For instance, users may slide the progress bar to skip some uninteresting scenes, network conditions can affect the video bitrate, and user movements can impact the connection status of edge nodes. We have taken these issues into consideration and discussed them in detail in appendix C.

## 5. Evaluation

### Methodology

We used the **traditional CDN delivery** and **edge cache** (size of 500MB with a LRU update method) approaches for comparison in order to evaluate the performance of NCTM. To replicate the users video-watching behavior, we utilized the kuailee dataset (Zhu et al., 2017) and collected 117,977 real request records from 1,398 users on the Kuaishou app on August 6, 2020, involving 10,230 short videos. To simulate the network conditions, we used the MAWI (Zhu et al., 2017) and FCC18 (Zhu et al., 2018) network traces from August 12, 2020. In the actual implementation, we created separate Docker (Docker, 2020) containers for the server, the edge node, and each user device. Users sent requests to servers via edge nodes according to the real request records mentioned above, in order to replicate the video transmission and playback behaviors. Additionally, we used the Mahimahi network tool (Mahimahi, 2017) to reply the network trace, aiming to closely reproduce the network conditions at that time. In the experiments, we considered two fundamental scenarios: the sufficient bandwidth network and the limited bandwidth network. For the former one, we mainly considered the network bandwidth utilization. For the latter one, we mainly focused on buffer variation and rebuffer events. More detailed settings are shown in appendix F.

### Performance

**Under sufficient bandwidth:** Figure 8 presents the network load variations under high-speed connections (200Mbps) across CDN and edge caching approaches with and without NCTM, as well as a histogram of short video requests distribution. From the results, it can be observed that network load variations are closely related to the request frequency. The Pearson correlation coefficient between network load and request frequency is 0.77. The peak value of requests occurs at around the 29700th second, approximately at 8:15 AM. During this time, there are 118 requests within one minute (with a total of 1398 users), and the network load also reached its peak value. In CDNs delivery mode, the real-time throughput was 69.94 Mb/s without NCTM, while it is 53.84 Mb/s with the assistance of NCTM, cutting peak traffic by 23.01%. Similar results are observed in the edge caching mode, indicating that NCTM can effectively alleviate peak throughput pressure. Figure 9 presents the cumulative distribution function (CDF) of the normalized bandwidth usage. From the results, it can be observed that in CDNs delivery mode, the average network load decreased by 14.06% with NCTM versus no NCTM. In the edge caching mode (with an edge cache size of 500MB), NCTM decreased network load by 13.30% compared to no NCTM. As a result of the change in the order of video playback, there may be a short period of time when NCTM's throughput exceeds that of baselines. From a global perspective, the NCTM is clearly superior to the baseline.

**Limited bandwidth scenario:** Figure 10 shows the distribution of rebuffer events using NCTM in both CDNs delivery mode and the edge caching mode in a limited bandwidth scenario (60Mbps). Figure 11 and 12 show the statistics of rebuffer events and the proportion of rebuffered requests respectively. From the figures, it can be observed that due to the limited bandwidth, in the CDN delivery mode, 73.93% of user requests suffer from rebuffer events. During peak request times, almost all users experience rebuffer events, resulting in a total of 35,726 rebuffer instances. NCTM relieves some of the bandwidth pressure, resulting in a 40.23% reduction in rebuffer events for user requests. This represents a decrease of 33.7% compared to the baseline. Total rebuffer instances decreased by 45.6% to 19,431. Similarly, in the edge caching mode, although rebuffer events have also decreased compared to CDNs delivery, the improvement is limited to users who request popular files. However, with the efficient cooperation of NCTM and edge caching, the number of user requests experiencing rebuffer events has been reduced to only 9.21%, and the total count of rebuffer events has decreased by 80.8% compared to the baseline.

Figure 13 shows the average proportion of rebuffer time across CDN and edge caching approaches with and without NCTM. Figure 14 shows the average buffered video duration during video playback in client devices. It can be concluded that, due to frequent rebuffer events in the CDN delivery mode, the average buffered video duration is only 1.97 seconds. About 45.82% time of video watching is waiting for rebuffering. With NCTM, the average buffered video duration increases by 13.53x to 26.66 seconds, mitigating the effects of fluctuations in network performance. Similarly, in the edge caching mode, the average buffered video duration increases by 1.21x, and the proportion of buffer time decreases to only 5.79%. This optimization significantly improves user experience in limited network bandwidth conditions.

**Dynamic bandwidth scenario:** Figure 15 illustrates the average bandwidth usage in different delivery modes in a scenario where the network bandwidth ranges from 60Mbps to 100Mbps. Results reveal that when the bandwidth is relatively abundant (100Mbps 80Mbps), NCTM reduces the bandwidth usage rate by 3.02%-14.75%. Even in CDNs delivery mode, using NCTM outperforms edge caching mode. Under the constrained bandwidth (70Mbps), NCTM significantly alleviates the bandwidth pressure, reducing the time of full bandwidth occupancy by 15.28%, thereby substantially reducing rebuffering events.

**NCTM assisting edge caching:** To further explore the cooperation between NCTM and edge caching, we analyzed the number of requests in different transmission stages, including the number of hit-edge-cache requests and the number of NCTM requests, as shown in Figure 18. Result indicates that in the early stages, when the response workload of the edge cache is low, LRU can satisfy over 20% of the requests. However, with the video files increasing in the later stages, the edge cache becomes overwhelmed. Due to limited cache accumulation on the client side, NCTM does not occur frequently in the early stages. But in the later stages, as user caches accumulate, a large number of requests (over 25%) can use NCTM to transfer coded files. Therefore, edge caching and NCTM are not only compatible, but they are complementary and further reduce the network load by cooperation.

### Time complexity and hyperparameters

**Time complexity:** We design an experiment to compute the time complexity of NCTM in order to assess NCTM's capability to process the received requests in real-time. Figure 16 illustrates the time complexity of NCTM. Figure 17 illustrates the relationship between the average execution time of NCTM and short video playback latency. The execution time of NCTM primarily includes four distinct components, i.e., cliques traversal, the _Minimum Clique Coverage algorithm_, the _Recommendation Reorder algorithm_, and the XOR encoding. Figure 16 shows four fitting curves, illustrating the actual execution time of the algorithms with different entity counts (\(N\) for time complexity), such as the number of current nodes or cliques. From the results, it can be concluded that both the _Minimum Clique Coverage algorithm_ and the XOR-encoding process show nearly linear growth, consistent with our analysis of time complexity in \(O(N)\) (when \(T=G=5\)). Although the _Recommendation Reorder algorithm_ exhibits a slightly super-linear growth trend, its execution time remains below \(10ms\) even when \(N>10000\). Besides, the average execution time from opening the APP to the start of the first video playback is \(706ms\) (tested with the Chrome browser for Tiktok). Considering that NCTM's execution time is much shorter than the video playback delay, we can conclude that NCTM can process requests in real time for short videos.

**Hyperparameter analysis:** In the _Minimum Clique Coverage algorithm_ and the _Recommendation Reorder algorithm_, we set hyperparameters \(T\) and \(G\) to control the computational cost, respectively. To determine the values of \(T\) and \(G\), we design experiments with values \(\{1,3,5,7,9\}\) and calculated the success rate for finding solutions and execution time under each parameter setting. Results in Figure 19 and figure 20 reveal that both \(T\) and \(G\) exhibit a nearly linear increase in average execution time as their values increase. When \(T=5\), the probability of reducing the number of cliques in the _Minimum Clique Coverage algorithm_ is \(8.11\%\), with an average execution time of \(12.92ms\); when \(G=5\), the probability of finding videos in the _Recommendation Reorder algorithm_ is \(68.25\%\), with an average execution time of \(2.54ms\). As \(T\) and \(G\) further increase, the success rate of finding solutions approaches a plateau, indicating that \(T=5\) and \(G=5\) are relatively optimal values. In practical applications, the parameters can be adjusted according to the server's computing resources.

## 6. Conclusions

As short videos become increasingly common, they put a significant strain on network resources due to the massive amount of data they transmit. Due to the time- and space-intensive nature of short videos, CDNs are faced with considerable bandwidth challenges. Moreover, edge caching and other solutions rely too heavily on predicting popular files. In this paper, we propose NCTM, which employs XOR-encoded files to make effective use of user-side caches, reducing bandwidth consumption and improving transmission efficiency. Trace-driven experiments show that compared to CDNs and edge caching, NCTM reduces bandwidth consumption, rebuffering events, and the reliance on caching popular files, ultimately improving the user experience when watching short videos.

Figure 18. Cooperation between NCTM Figure 19. Average execution time and Figure 20. Average execution time and and edge caching success rate in different \(T\) success rate in different \(G\)

Figure 15. Average bandwidth usage Figure 16. Time complexity of NCTM-Figure 17. Average execution time of NCTM-related algorithm and video request delay

## References

* [1] The official website of tiktok. (2023, Jul 26).
* [2] The official website of YouTube Shorts. (2023, Jul 26).
* [3] TikTok: Thanks a billion! (2023, Jun 24).
* [4] YouTube Shorts Video-Making App Now Receiving 3.5 Billion Daily Views. (2023, Jun 24).
* [5] Top 64 Ti:TkTok Stats You Need to Know in 2023. (2023, Jun 24).
* [6] Ti:TkR Revenue and Usage Statistics (2022). (2023, Jun 24).
* [7] Gang Peng, Cdn: Content distribution network. _arXiv preprint cs/0411069_, 2004.
* [8] Fahca Chen, Peng Li, Dee Zeng, and Song Guo. Edge-assisted short video sharing with guaranteed quality-of-experience. _IEEE Transactions on Cloud Computing_, 2021.
* [9] Sem C. Borst, Varun Gupta, and Anwar Walid. Distributed caching algorithms for content distribution networks. In _Conference on Information Communications_, 2010.
* [10] Hanling Wang, Qing Li, Heyang Sun, Zuozhou Chen, Yingqian Hao, Junkun Peng, Zhenhui Yuan, Junsheng Fu, and Yong Jiang. Values Edge-cloud real-time video analytics via background understanding and subtraction. _IEEE Journal on Selected Areas in Communications_, 41(1):100-106, 2022.
* [11] Ying Chen, Qing Li, Aoyang Zhang, Longhao Zou, Tong Jiang, Zhimin Xu, Junlin Li, and Zhenhui Yuan. Higher quality live streaming under lower uplink bandwidth: an approach of super-resolution based video coding. In _Proceedings of the 31st ACM Workshop on Network and Operating Systems Support for Digital Audio and Video_, pages 74-81, 2021.
* [12] Ju Ren, Deyu Zhang, Silvenu He, Yaoxue Zhang, and Tao Li. A survey on end-edge-cloud orchestrated network computing paradigms: Transparent computing, mobile edge computing, fog computing, and cloudlet. _ACM Computing Surveys (CSUR)_, 36(1):36-39, 2016.
* [13] Yushan Siriwardhana, Pawani Poramblage, Madhusanka Liyanage, and Mika Yiantila. A survey on mobile augmented reality with gg mobile edge computing: Architectures, applications, and technical aspects. _IEEE Communications Surveys & Tutorials_, 23(2):1160-1192, 2021.
* [14] Xiaofei Wang, Jianeng Li, Zhaolong Ning, Qingyang Song, Lei Guo, Sung Guo, and Mohammad S Obaidat. Wireless powered mobile edge computing networks: A survey. _ACM Computing Surveys_, 2023.
* [15] Muhammad Yasir, Sardar Khaliq Yanra, Tahir Masquod, Faisal Rehman, and Saad Mustafa. Copp: Content popularity and user preferences aware content caching framework in mobile edge computing. _Cluster Computing_, 26(1):267-281, 2023.
* [16] Xiaobo Zhou, Zhihui Ke, and Tie Qiu. Recommendation-driven multi-cell cooperative caching: A multi-agent reinforcement learning approach. _IEEE Transactions on Mobile Computing_, 2023.
* [17] Nokia Corporation. Nokia Deepfield Network Intelligence Report: Networks in 2020, 2020.
* [18] Nhn-Ngoc Dao, Anh-Tien Tran, Ngo Hoang Tu, Tran Thien Thanh, Vo Nguyen Quoc Bao, and Sungrace Cho. A contemporary survey on live video streaming from a computation-driven perspective. _ACM Computing Surveys_, 54(10s):1-38, 2022.
* [19] Shiqib Bulkakar and Venkatesh Tamarapalli. An overlay management strategy to improve qos in cdn-p2p live streaming systems. _Peer-to-peer networking and applications_, 13:190-206, 2020.
* [20] Rene Farahani, Abdellan Bendiab, Ekrem Cetinkaya, Christian Timmerer, Roger Zimmermann, and Hermann Hellwagner. Hybrid p2p-cdn architecture for live video streaming: An online learning approach. In _Globecom 2022-2022 IEEE Global Communications Conference_, pages 1911-1917. IEEE, 2022.
* [21] Mohammad Ali Maddah-Ali and Urs Niessen. Fundamental limits of caching. _IEEE Transactions on information theory_, 6(3):286-287, 2014.
* [22] Mohammad Ali Maddah-Ali and Urs Niessen. Decentralized coded caching attains order-optimal memory-rate tradeoff. _IEEE/ACM Transactions On Networking_, 23(4):1020-1040, 2014.
* [23] Urs Niessen and Mohammad Ali Maddah-Ali. Coded caching with nonuniform demands. _IEEE Transactions on Information Theory_, 63(2):1146-1158, 2016.
* [24] Rantin Pedarsani, Mohammad Ali Maddah-Ali, and Urs Niessen. Online coded caching. _IEEE/ACM Transactions on Networking_, 24(2):386-385, 2015.
* [25] Jens Gramm, Jiong Guo, Falk Hoffner, and Rolf Niedermeier. Data reduction and exact algorithms for clique cover. _ACM J. Exp. Algorithmics_, 13, feb 2009.
* [26] Marek Cygan, Marcin Pilipczuk, and Michal Pilipczuk. Known algorithms for edge clique cover are probably optimal. _SIAM Journal on Computing_, 45(1):67-83, 2016.
* [27] Chongming Gao, Shijun Li, Wenqiang Lei, Jiawei Chen, Biao Li, Peng Jiang, Xiangnan He, Jiaxin Mao, and Tat-Seng Chua. Kuaiefer: A fully-observed dataset and insights for evaluating recommender systems. In _Proceedings of the 31st ACM International Conference on Information & Knowledge Management_, pages 540-550, 2022.
* [28] Babak Bashari Rad, Harrison John Bhatti, and Mohammad Ahmadi. An introduction to docker and analysis of its performance. _International Journal of Computer Science and Network Security (ITSCNS)_, 17(3):228, 2017.
* [29] Zheng Chang, Yuman Gu, Zhu Han, Xianfu Chen, and Tapani Ristaniemi. Context-aware data caching for 5g heterogeneous small cells networks. In _2016 IEEE International Conference on Communications (ICC)_, pages 1-6. IEEE, 2016.
* [30] N Golzeri, K Shanmugam, GE Dlmakis, Af Molisci, and Gine. Femtocaching: wireless video content delivery through distributed caching helpers. In _Proc. IEEE INFOCOM_, 2012.
* China_, ACM TURC '19, New York, NY, USA, 2019. Association for Computing Machinery.
* [32] Yu Guan, Xingcong Zhang, and Zongming Guo. Prefaceface: Edge cache admission with user preference learning for video content distribution. _IEEE Transactions on Circuits and Systems for Video Technology_, 31(4):168-1631, 2021.
* IEEE Conference on Computer Communications_, pages 2499-2508, 2020.
* [34] Mingyue Ji, Giuseppe Caire, and Andreas F Molisch. Fundamental limits of distributed caching in d2d wireless networks. In _2013 IEEE Information Theory Workshop (ITW)_, pages 1-5. IEEE, 2013.
* [35] Mingyue Ji, Giuseppe Caire, and Andreas F Molisch. Wireless device-to-device caching networks: Basic principles and system performance. _IEEE Journal on Selected Areas in Communications_, 34(1):176-189, 2015.
* [36] Sepandam D Kamvar, Marin T Schlosser, and Hector Garcia-Molina. The eigentrust algorithm for reputation management in p2p networks. In _Proceedings of the 12th international conference on World Wide Web_, pages 640-651, 2013.
* [37] Alexander Pyattaer, Olga Galimian, Sergey Andreev, Marcos Katz, and Yevgenj Kovchervy. Understanding practical limitations of network coding for assisted proximate communication. _IEEE Journal on Selected Areas in Communications_, 33(2):156-170, 2014.
* [38] Qi Liu. A brief discussion on p2p network file transfer. _Science, education and literature_, (3):182-185, 2016.
* [39] Tang, Ming. Pang, Haitian, Huang, Jianwei, Sun, Lifeng, Gao, and Lin. Optimizations and economics of crowdsourced mobile streaming. _IEEE Communications Magazine: Articles, News, and Events of Interest to Communications Engineers_, 55(5):21-27, 2017.
* [40] T-Teng Hsu and Yao-Min Tung. A social-aware p2p video transmission strategy for multimedia i.e. _IEEE Access_, 8:95574-95584, 2020.
* [41] Thomas Stockhammer. Dynamic adaptive streaming over http- standards and design principles. In _Proceedings of the second annual ACM conference on Multimedia systems_, pages 133-144, 2011.
* [42] Dilip Kumar Krichshappa, Divyashri Bhat, and Michael Zink. Dashing youtube: An analysis of using dash i souolute video service. In _38th Annual IEEE Conference on Local Computer Networks_, pages 407-415. IEEE, 2013.
* [43] Jayme L Szwarcfiter. A survey on clique graphs. _Recent advances in algorithms and combinatorics_, pages 109-136, 2003.
* [44] Zhuqi Li, Ya Xiong Xie, Ravi Netravi, and Kyle Jamieson. Dashlet: Taming swipe uncertainty for robust short video streaming. 2022.
* [45] MAWI Working Group Traffic Archive. (2023, Jul 26).
* [46] Download link for the TCG18 dataset (2023, July 7).
* [47] Ravi Netravi, Anirudh Sivaraman, Samuel Das, Amnesh Goyal, Keith Winstein, James Mickens, and Hari Balakrishnan. Maimahri: accurate {Record-and-Replay} for 1/ITIP). In _2015 USENIX Annual Technical Conference (USENIX ATC 15)_, pages 417-429, 2015.
* [48] Alberto Caprara, Paolo Toth, and Matteo Fischetti. Algorithms for the set covering problem. _Annals of Operations Research_, 98(1-4):353-371, 2000.
* [49] Harry B Lewis. Michael _I. grasper_ and david a-bism. Computers and intractability: a guide to the theory of np-completeness. wfh freeman and company, san francisco1997, x 338 pp. _The Journal of Symbolic Logic_, 42(4):968-500, 1983.
* [50] Maheshan Dasari, Kumara Kalabatiguri, Samir R Das, Aruna Balasubramanian, and Dimitris Samaras. Swift: Adaptive video streaming with layered neural codes. In _19th USENIX Symposium on Networked Systems Design and Implementation (NSDI 22)_, pages 103-118, 2022.
* [51] Yunzhuo Liu, Bo Jiang, Tian Guo, Ramesh K. Sitaraman, Don Towsley, and Xinbing Wang. Grad: Learning for overhead-aware adaptive video streaming with scalable video coding. In _Proceedings of the 28th ACM International Conference on Multimedia_, MM '20, page 349-357, New York, NY, USA, 2020. Association for Computing Machinery.
* [52] The official website of Fiddler. (2023, Jun 30).
* [53] Hongzi Mao, Ravi Netravi, and Mohammad Alizadeh. Neural adaptive video streaming with peniseve. In _the Conference of the ACM Special Interest Group_, 2017.
* [54] Xiaoqi Yin, Abhishek Jindal, Vyas Sekar, and Bruno Sinopoli. A control-theoretic approach for dynamic adaptive video streaming over http. In _Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication_, pages 325-338, 2015.

## Appendix A Pseudocode for minimum clique coverage algorithm

```
0:\(\mathbb{G}=(E,D)\), \(\mathbb{R}\), \(T\)
0:\(\mathbb{R}^{\prime}\)
1:functionmain
2:\(\mathbb{R}^{\prime}=\mathbb{R}\)
3:repeat
4: randomly select \(d_{i}\in D\), s.t. \(d_{i}\in R_{x}\), \(|R_{x}|=1\)
5: randomly select \(e_{ij}\in E\), s.t. \(d_{j}\in R_{y}\), \(|R_{y}|\neq 1\)
6:\(R_{x}^{\prime}=R_{x}\cup\{d_{j}\}\)
7:\(R_{y}^{\prime}=R_{y}-\{d_{j}\}\)
8:for\(d_{k}\in R_{y}^{\prime}\)do
9:if\(e_{ik}\in E\)then
10:\(R_{x}^{\prime\prime}=R_{x}^{\prime}\cup\{d_{k}\}\)
11:\(R_{y}^{\prime\prime}=R_{y}^{\prime}-\{d_{k}\}\)
12:endif
13:endfor
14:for\(d_{k}\) s.t. \(d_{k}\in R_{x}\), \(|R_{x}|=1\)do
15:if\(\nexists\ d_{l}\) s.t. \(d_{l}\in R_{y}^{\prime\prime},e_{kl}\)\(\notin E\)then
16:\(R_{y}^{\prime\prime}=R_{y}^{\prime\prime}\cup\{d_{k}\}\)
17:\(\mathbb{R}^{\prime}=\mathbb{R}^{\prime}\cup\{R_{x}^{\prime\prime},R_{y}^{ \prime\prime}\}\)
18:return\(\mathbb{R}^{\prime}\)
19:endif
20:endfor
21:\(\mathbb{R}^{\prime}=\mathbb{R}^{\prime}-\{R_{x},R_{y}\}\)
22:\(\mathbb{R}^{\prime}=\mathbb{R}^{\prime}\cup\{R_{x}^{\prime\prime},R_{y}^{ \prime\prime}\}\)
23:\(T=T-1\)
24:until\(T=0\)
25:endfunction
```

**Algorithm 1** Minimum Clique Coverage algorithm

## Appendix B Proof of the minimum clique coverage algorithm

In the _Minimum Clique Coverage algorithm_, we randomly select a separate clique in each iteration and search for a solution to reduce the clique number. It's worth noting that although there are situations where the clique number remains unchanged, we still retain all adjustments made during this iteration. Figure 21 explains why we should retain the states. With simple TMG adjustments, larger cliques can be split into smaller ones, creating more opportunities for successful matches. In this example, the clique \(R_{1}=\{d_{1},d_{2},d_{3},d_{4}\}\) is split into smaller clique \(R_{1}^{\prime}=\{d_{2},d_{3},d_{4}\}\) in the first iteration, leading to a successful match in the next iteration. More generally, if we can find several **separate nodes** whose connected edges completely **cover all nodes** of a **non-separate clique**, we can then divide this non-separate clique into several parts putting in the separate cliques.

Formally, we define \(P_{i}\) as the set of pointed nodes for all edges connected to node \(d_{i}\). For example, in the first subgraph of figure 21, \(P_{1}=\{d_{2},d_{3},d_{4},d_{5}\}\), which means node \(d_{1}\) is connected to nodes \(d_{2}\), \(d_{3}\), \(d_{4}\), \(d_{6}\), and \(d_{8}\). We also define \(Q_{i}\) as the set of nodes belonging to the same clique as node \(d_{i}\). For example, in the first subgraph of figure 21, we have \(Q_{1}=R_{1}=\{d_{1},d_{2},d_{3},d_{4}\}\), \(Q_{2}=R_{1}=\{d_{1},d_{2},d_{3},d_{4}\}\), and \(Q_{8}=R_{5}=d_{5}\). If we can find several separate cliques (nodes) \(\{d_{i}\}\), \(\{d_{j}\}\), \(\{d_{k}\}\),... and a non-separate clique \(Q_{x}\) such that \(Q_{x}\subseteq P_{i}\cup P_{j}\cup P_{k}\cup...\), it means the clique \(Q_{x}\) can be divided. For example, in the first subgraph of figure 21, we have \(P_{5}=\{d_{3},d_{4}\}\), \(P_{7}=\{d_{2}\}\), \(P_{8}=\{d_{1}\}\), and thus \(P_{5}\cup P_{7}\cup P_{8}=\{d_{1},d_{2},d_{3},d_{4}\}\). At the same time, we have \(Q_{1}=\{d_{1},d_{2},d_{3},d_{4}\}\), we have \(Q_{1}\subseteq P_{5}\cup P_{7}\cup P_{8}\). In this case, we can reconstruct the cliques \(Q_{1}(R_{1}),Q_{5}(R_{2}),Q_{7}(R_{4}),Q_{8}(R_{5})\) to form cliques \(Q_{5}(R_{2}^{\prime})=\{d_{3},d_{4},d_{5}\}\), \(Q_{7}(R_{4}^{\prime})=\{d_{2},d_{7}\}\), \(Q_{8}(R_{5}^{\prime})=\{d_{1},d_{8}\}\) in the third subgraph. It means we form three non-separate cliques from three separate cliques and one non-separate clique.

This problem is a classic Set Cover Problem (SCP) that involves selecting specific sets and taking their union to cover all elements of a given set (Kang and Johnson, 2018). SCP NP-hard in the strong sense, proven by Garey and Johnson(Garey and Johnson, 2018). In the _Minimum Clique Cover algorithm_, we utilize the characteristics of separate cliques. Each time, we select a separate clique and a non-separate clique, removing **all** nodes that are connected to the separate clique in the non-separate clique. Formally, it can be proven that if \(Q_{x}\subseteq P_{i}\cup P_{j}\cup P_{k}\cup...\), then for any set \(P^{\prime}\), we have \((Q_{x}-P^{\prime})\subseteq((P_{i}\cup P_{j}\cup P_{k}\cup...)-P^{\prime})\). Assuming it is for separate node \(d_{i}\), we have \((Q_{x}-P_{i})\subseteq((P_{i}\cup P_{j}\cup P_{k}\cup...)-P_{i})\subseteq P_{j} \cup P_{k}\cup...\). In other words, in the _Minimum Clique Coverage algorithm_, the SCP problem is broken into multiple subproblems which can be solved linearly. In each search, we use a separate clique to grab parts of a non-separate clique. This process continues until a suitable solution is found or the iteration limit has been reached. In the meanwhile,

Through the above example, we demonstrate that the _Minimum Clique Coverage algorithm_ helps us reach the optimal solution without deteriorating the current situation. Therefore, we should retain all adjustments made during each iteration.

## Appendix C Further considerations in details

**The potential of NCTM:** NCTM requires users to sequentially watch the same videos and access the network through the same edge node (base station) synchronously. This may be unattainable in traditional on-demand video streaming. However, based on our deep insight on recent popular short video services, the spatial and temporal densification of short video delivery can meet this requirement. For a specific video, the number of viewers in a certain province or city can reach 40%, and over 70% of playback occurs within 48 hours after publishing. Videos with a clear regional bias exhibit even more pronounced spatial densification, making NCTM a more desirable choice for significant performance. (For more details, please refer to appendix E).

Figure 21. An example of finding the solution through multi-step iteration search

**Uncompleted watching events:** An uncompleted watching event occurs when the user switches to the next video before finishing the last one. This is very common in short video playbacks. Obviously, the video chunks that are not downloaded before switches will not be saved in the client-side cache. Therefore, in the NCTM, if these video chunks are involved in the coded file, the client can not decode it successfully. We can make the node exit the current clique in TMG, forming a separate clique, this will evidently impair the performance of NCTM (the number of clique increase). A compromise solution approach is to assign a weight \(s_{ij}\) for each edge in the TMG, representing how long the edge between node \(d_{i}\) and \(d_{j}\) can be maintained (how long the coded transmission can be sustained). Next, we denote \(t(R_{i})\) to represent how long the clique \(R_{i}\) can be sustained. In the _Minimum Clique Coverage algorithm_, the problem is transformed into a weighted search problem. Greedy algorithms or heuristic search methods can be used to determine whether to retain the adjustments in each iteration. Figure 22 illustrates the process of the weighted algorithm. This iteration does not result in a decrease in clique number, but it extends their duration significantly. This implies a longer duration for coded transmission.

**Sliding the progress bar:** Sliding the progress bar indicates that the user may skip some uninterested content within one video. This is often accompanied by uncompleted watching events. In the NCTM, when a user slides the video, the edges of the corresponding node in the TMG need to be recalculated (sliding may cause some edges to disappear due to uncompleted watching). The node exits the current clique and then re-runs the _Minimum Clique Cover algorithm_. Furthermore, since NCTM is designed around continuous video playback, if there are missing video chunks in a video, it's recommended to only store the continuous video chunks from the beginning up to the missing portion in the client-side cache. The subsequent video chunks will be rarely used in file decoding.

**Video chunks with different bitrates:** Short videos are usually encoded as video chunks with different bitrates using the adaptive bitrate paradigm. In the NCTM, we treat video chunks with different bitrates as distinct videos. Fortunately, most short video platforms encode videos in only a limited range of bitrates. For instance, TikTok has only three bitrate options (TikTok, 2018). Furthermore, recently researched layered coding schemes (Song et al., 2019; Wang et al., 2020) are more compatible with NCTM. In these schemes, video files of different bit rates are compatible. High-bitrate files can also be used for decoding the coded files involving low-bit rate files.

**User movement:** The user rapid movement implies frequent changes to the connecting base stations, while the user's cache remains the same. In NCTM, due to the involvement of edge nodes (base stations), changing base stations means that the existing coded transmission conditions cease to be satisfied. Any change can be regarded as exiting the original TMG and joining the new TMG with a new identity to explore coded transmission opportunities. However, NCTM is not suitable for situations with frequent handovers between base stations.

## Appendix D Pseudocode for Recommendation Reorder Algorithm

```
0:\(V_{i}\), T, \(G\)
0:\(v_{i}^{*}\)
1:function main
2:\(flag=FALSE\)
3:for\(C_{j}\) in \(V_{i}\) next \(G\) videos do
4:for\(U_{k}\in\mathbb{U}\)do
5:if\(t_{k,j}=1\) and \(t_{t_{k}^{*}}=1\)then
6:\(v_{i}^{*}=C_{j}\)
7:\(flag=TRUE\)
8:endif
9:endfor
10:if\(flag=TRUE\)then
11: break
12:endif
13:endfor
14:if\(flag=FALSE\)then
15:\(v_{i}^{*}=V_{i}\) next video
16:endif
17:return\(v_{i}^{*}\)
18:endfunction
```

**Algorithm 2** Recommendation Reorder algorithm

## Appendix E The Potential of NCTM

NCTM is a mechanism designed for short video delivery. As the transmission and encoding/decoding of coded files require deep cooperation between edge nodes and multiple users, in practice, the users participating in a certain coded transmission should be within the coverage of the same base station. Additionally, they should have similar recommendation queues for short videos and watch them simultaneously. Our analysis of the characteristics of short video playback reveals significant spatial and temporal densification during playback. For a specific video, the number of viewers in a certain province or city can reach 40%, and over 70% of the playback occurs within 12 hours after publishing for some videos.

Based on the data collected from the Tiktok App, we have confirmed that there are significant regional differences in the viewership of videos across different categories. Videos with regional tendencies tend to concentrate their dissemination within specific provinces and cities. Furthermore, the playback time of videos is also concentrated within a short period of time after their release.

Due to the challenge of obtaining user viewing behaviors directly, we utilize the user comment behaviors as a substitute for exploration. Through packet capturing tools like Fiddler (Fiddler, 2018), we capture data packets related to video comments and extract information such as IP location and timestamps. This allows us to obtain

Figure 22. Minimum Clique Coverage algorithm with weight edges in TMGthe distribution of comment IP locations and comment timestamps, reflecting when and where the user watch this video.

Concretely, we captured 100 videos from 25 Tiktok influences. Four representative results are shown in figure 23. These four influencers are science popularizer An Senyao, food explorer Tang Renjie, real estate agent Wu Xinxin, and life enthusiast Qi Zai, with fan counts of 5.061 million, 12.963 million, 0.301 million, and 0.572 million, respectively. An Senyao's video content belongs to the popularization of science, discussing the correlation between ancient Europe and ancient China. The content with no regional bias, so the geographical distribution is quite balanced. The most concentrated place of commentators (from Beijing) accounts for only 9.49%. Tang Renjie's video content belongs to daily life, featuring a restaurant exploration in Changsha, Hunan province. Due to the specific regional information, commentators from Hunan province account for 40.65%. Wu Xinxin's video content belongs to finance, analyzing China's real estate transaction data in May 2023. However, she uses Cantonese, a dialect mainly spoken in southern China, indicating a clear regional bias. As a result, 44.93% of the commentators are from Guangdong province (the primary region where Cantonese is spoken). Qi Zai's video content also belongs to daily life, sharing daily cooking skills. But the video scenes are located in Guangzhou, Guangdong, indicating a certain regional bias. As a result, 41.3% of the users participating in the comments are from Guangdong.

On the other hand, figure 23 also illustrates the histogram of comment timestamp distribution. From the graph, it can be observed that a significant number of comments were created within 12 hours of the video being posted. The highest one (Wuxinxin's video) reached 71.92%. While some videos may become popular later on, they generally reach their peak of popularity within 48 hours. For instance, only 11.23% of the comments are made within the first 12 hours on Qi Zai's video, but it comes to 64.58% at the 48th hour. Furthermore, video content also affects their popularity. For instance, Wu Xinxin's video focuses on the real estate transaction data in May 2023, which possesses strong timeliness, showing stronger time densification. Contrarily, Qi Zai's videos revolve around life skills, which do not emphasize timeliness, resulting in a longer duration of the popularity cycle.

Based on the results, spatial densification is mainly observed in videos that exhibit significant regional bias. There is a large number of video playbacks in a particular area. Videos with strong timeliness display temporal densification. The vast majority of the playback occurs within 48 hours of the video release. These create excellent usage scenarios for NCTM. In practice, we should pay more attention to the videos showing spatial and temporal densification. More frequent video playback implies a greater number of requests available for coded chances exploration which brings more potential improvements to NCTM.

## Appendix F Overall setting of the experiment

**Comparison baselines:** We will compare NCTM with the following approaches. 1) _Traditional CDN delivery:_ CDNs maintain all videos on the cloud servers. Mobile clients send requests to CDNs through base stations and the cloud servers will transmit the desired content to the mobile clients through the same path. 2) _Edge caching:_ The edge nodes (e.g., base stations) cache popular files and use the Least Recently Used (LRU) method to update the content. When a client requests a file cached at the edge node, the edge node will prioritize providing it.

**Entity settings:** The video distribution over mobile networks generally involves three entities, i.e., content distribution servers (cloud servers), base stations (edge nodes), and client devices. After the user opens the app, the server sends a video list generated by the recommendation algorithm to the client. The client device then requests the videos through the base stations. If the video is available in the edge cache (located in the base station), it will be directly sent to the user. Otherwise, the cloud server will send the content to the base station, which will forward it to the user. In the evaluation, we use Docker [28] to simulate the above transmission process. At the beginning of the experiment, we create one Docker for the cloud server and another Docker for the edge node, separately running codes implemented with Python, to serve the clients.

Figure 23: spatial and temporal distribution of four typical influencers

For each client, a new Docker is created during the first 30 seconds before the user starts watching videos, and then simulating the behaviors of requesting video content as well as video playbacks. Once the client completes the session, the corresponding Docker will be deleted. Each Docker has its own port ID to send requests and transmit files via a TCP connection, with bandwidth variations simulated using Mahimahi [47]. The overall system is presented in figure 24.

**Viewing behaviors:** The experiment uses the kuaiRec dataset [27], which is a publicly available dataset released by Kuaishou. All data is collected from real user interaction records on the Kuaishou app, a popular short video app, between July 5 and September 5, 2020. It includes information such as video IDs, user IDs, video duration, video playback timestamps, and so on, thereby representing real user behavior when watching videos. We use the user interaction records from August 6, 2020, as the dataset for the experiment. It includes 117,977 video viewing records from 1,398 users requesting 10,230 video files, during 24 hours. In the experiment, we use the order of watched videos in the dataset as the original recommendation queue. However, due to the _Recommendation Reorder algorithm_, the order and timing of video views by users may not follow the original data, still ensuring video playback completion.

**Network conditions:** The experiment consists of two end-to-end network scenarios, i.e., from the cloud server to the base station (cable network) and from the base station to the end client devices (wireless network). We used the network traces provided by the MAWI Working Group [45] for the wide backbone network to simulate network throughput variations. Specifically, we use the network traces from August 12, 2020, from the main IX link of WIDE to DIX-IE. The network fluctuations ranged from 60Mbps to 200Mbps in mean value, constructing different bandwidth scenarios (abundant bandwidth or limited bandwidth). We also used the FCC18 network traces to simulate network throughput fluctuations from the base station to the end client devices. The FCC18 dataset has been commonly used in previous works [53, 54]. To reflect the differences among clients, the network fluctuations were adjusted to differentiate bandwidth conditions including mean values of 2Mbps, 4Mbps, 6Mbps, and 12Mbps, each with a random variation of up to 5%.

**Video representations:** We use videos downloaded from the TikTok app and choose the corresponding video with a matching duration for each video in the dataset. Following the existing method [44], we divided each video into chunks of 1MB in size (the last chunk may be smaller than 1MB) and stored them on the cloud server. During the transmission process, if NCTM is triggered, these 1MB-sized chunks are XOR-encoded into coded files and transmitted to the clients over the network.

**Evaluation metrics:** NCTM was evaluated in terms of network bandwidth utilization, buffer variation, and rebuffer events. Network bandwidth utilization refers to the amount of bandwidth used between a cloud server and a base station. As a video is played, buffer variation refers to changes in the duration of the buffered content. Rebuffer events occur when video playback is interrupted due to low throughput. Since we consider the limited bandwidth struggles to meet the demands of all users, the coded transmission implemented by NCTM can transmit more data content within the limited bandwidth, thus reducing rebuffering events.

Figure 24. Experimental Overall Structure Design