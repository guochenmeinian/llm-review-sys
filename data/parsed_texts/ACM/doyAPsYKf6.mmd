# Unleashing the Power of Large Language Models for Denoising Recommendation

Anonymous Author(s)

###### Abstract.

Recommender systems are vital for personalizing user experiences, yet they often rely on implicit feedback data that can be noisy and misleading. Existing denoising studies typically involve either incorporating auxiliary information or learning denoising strategies from interaction data. Nonetheless, they face challenges due to the inherent limitations of external knowledge and interaction data, as well as the non-universality of certain predefined assumptions, which hinder their ability to accurately identify noise. Recently, large language models (LLMs) have garnered significant attention due to their extensive world knowledge and powerful reasoning capabilities. Despite this, the potential of LLMs to enhance the denoising process in recommendations remains largely unexplored. In this paper, we introduce LLad, a novel framework that leverages LLMs to improve the denoising process in recommender systems, thereby enhancing overall recommendation performance. Specifically, LLad generates denoising-related knowledge by first enriching semantic insights from observational data through LLMs, facilitating a comprehensive inference of user-item preference knowledge. It then employs a novel Chain-of-Thought (CoT) technique over user-item interaction graphs to uncover relation knowledge pertinent to denoising. Finally, it utilizes the Information Bottleneck (BI) principle to align the denoising knowledge generated by LLMs with the recommendation targets, effectively filtering out both data noise and irrelevant knowledge produced by the LLMs. Empirical results demonstrate the effectiveness of our proposed framework, showcasing its superior performance in denoising and recommendation accuracy. The code is available at [https://anonymous.4open.science/r/LLad-5EE5](https://anonymous.4open.science/r/LLad-5EE5).

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

## 1. Introduction

Recommender systems (Kang et al., 2016; Li et al., 2016; Wang et al., 2017; Wang et al., 2017) have become essential for mitigating information overload and delivering personalized services. High-quality interaction data that accurately reflect user preferences play a crucial role in enhancing the performance of these recommendation models. In the context of limited explicit feedback (Kang et al., 2016; Li et al., 2016), implicit feedback (_e.g._, click, purchase and views) has emerged as a popular alternative due to its abundance and ease of collection (Li et al., 2016; Li et al., 2016). However, implicit feedback data are often noisy and influenced by various incidental factors, which can hinder their ability to accurately represent user preferences (Li et al., 2016; Wang et al., 2017; Wang et al., 2017). For instance, false positive interactions (Li et al., 2016) may arise from users' curiosity-driven clicks or unsatisfactory purchases, while false negative interactions (Li et al., 2016) can result from limited exposure or restricted browsing opportunities.

To tackle the challenge of noisy implicit feedback, denoising has become a significant focus in recommendation research, which can be broadly categorized into two main approaches:

* **Denoising based on side information.** Early studies (Bishop, 1996; Hinton et al., 2006; Goodfellow et al., 2014) utilize user dwell time and gaze patterns to identify noise. Subsequent work incorporates sequence (Zhu et al., 2017) and multi-behavior data (Kang et al., 2016; Wang et al., 2017; Wang et al., 2017) for more effective noise detection. Recent approaches integrate external knowledge graphs (Li et al., 2016; Li et al., 2016; Li et al., 2016) or social graphs (Li et al., 2016); (Li et al., 2016) to better model user preferences. However, these methods can incur high data collection costs, and large-scale graphs may introduce additional noise, such as irrelevant attributes diluting user signals (Li et al., 2016) or simplistic integrations amplifying noise (Li et al., 2016).
* **Denoising driven by interaction data.** These methods utilize data selection and weighting strategies. Selection-based approaches (Kang et al., 2016; Li et al., 2016; Li et al., 2016) identify and filter noisy interactions by analyzing data features or employing decision networks. For example, (Li et al., 2016) introduces an adaptive training strategy, while (Li et al., 2016; Li et al., 2016) develop networks to exclude noisy samples. Reweighting-based methods (Li et al., 2016; Wang et al., 2017) adjust sample weights during training to mitigate noise effects, such as T-CE (Li et al., 2016) which uses training loss for noise identification, BOD (Wang et al., 2017) which leverages interaction-derived priors with a bi-level optimization process.

Despite the effectiveness of interaction data-driven methods, they usually exhibit notable limitations. Firstly, they focus on learning user preferences from interaction data to identify noise. However, limited observational data result in only a partial understanding of user preferences, particularly in recognizing interactions that signal new interests or exploration tendencies (Li et al., 2016; Wang et al., 2017). For instance,

Figure 1. (a) An intuitive example of learning user preferences from observational data. (b) Improvements of our method (red) over existing methods (dark green).

in Figure 1(a), the pink area represents the user's true preference space \(P\), while the green area denotes the observable preference space \(\hat{P}\). The intersection \(P\cap\hat{P}\) reflects the true preferences inferred from observational data. Interactions deemed as noise often consist of data inconsistent with currently learned preferences. For example, if an art enthusiast accidentally clicks on a gardening video, it may be labeled as noise, but it might indicate a latent interest in gardening sketches. Secondly, some studies rely on predefined assumptions (Zhu et al., 2017; Zhang et al., 2018) in the noise identification process. For instance, (Zhu et al., 2017) judging high-loss samples in training as noise, which inadequately captures user preferences and potential associations during noise identification (_e.g.,_ links between fine arts and gardening). Consequently, it will diminish the model's effectiveness in denoising. To enhance the understanding of user preferences, large language models (LLMs) (Golovneel et al., 2013; Zhang et al., 2018; Zhang et al., 2019) present a promising direction due to their extensive world knowledge and reasoning capabilities. Recent studies (Zhu et al., 2017; Zhang et al., 2018) have explored the application of LLMs in recommendation systems to improve the robustness of user representations by incorporating additional semantic and textual information. However, these approaches primarily enhance the semantic richness of representations while they insufficiently leveraging the potential of LLMs for denoising.

To explore the potential of LLMs for denoising in recommendation, we must address several significant challenges.

* **C1: How can LLMs effectively mine information relevant to denoising?** LLMs excel at processing textual information, allowing us to expand and enrich semantic insights that can inform denoising efforts. However, the interactive data represented in the graph structure of users and items contains rich collaborative information that is also valuable for denoising. Unfortunately, LLMs struggle to process this complex graph data effectively.
* **C2: How can we utilize the information generated by LLMs for denoising?** While LLMs can produce additional knowledge for denoising, they may also generate hallucinations (Zhu et al., 2017), making direct application potentially suboptimal. Thus, it is crucial to consider how to constrain the knowledge generated by LLMs to align with the specific prediction targets in recommendations.

To address these challenges, we propose the **L**arge **L**anguage **M**odel-enhanced **R**ecommendation **D**enoiser (LLaRD), a novel framework designed to develop recommendation models that are robust to noisy data. LLaRD consists of two main components: a knowledge generation module and a knowledge-enhanced denoising module. To tackle **C1**, the knowledge generation module leverages LLMs to extract two types of denoising-related knowledge: 1) **Preference knowledge**. Utilizing the inherent world knowledge of LLMs, we enrich the semantic information of the data through the analysis, reasoning, and refinement of text and interaction data. This process extrapolates the scope of observational data and infers user and item preferences more comprehensively. 2) **Relation knowledge**. We implement a novel chain-of-thought (CoT) prompting strategy (Zhu et al., 2017; Zhang et al., 2018; Zhang et al., 2019) over graph structures to expand relation knowledge by iteratively reasoning about connections among users, items, and their neighborhood subgraphs. This approach encourages LLMs to consider key collaborative information hidden within the graph structure, thereby capturing relation knowledge pertinent to denoising. To address **C2**, the knowledge-enhanced denoising module is built upon the Information Bottleneck (IB) (Zhu et al., 2017; Zhang et al., 2018; Zhang et al., 2018). It maximizes the mutual information across denoised data, generated knowledge, and recommendation targets, while minimizing the mutual information between the denoised data and the original data. This mechanism further filters out knowledge irrelevant to denoising from the information generated by LLMs, reducing the integration of irrelevant information, such as hallucinations, and thereby enhancing denoising performance. As illustrated in Figure 1(b), we anticipate that LLMs will improve the learning process of the denoising model, enabling it to more accurately capture the trajectory of true user preferences (orange arrow) and extensively encompass the preference area (pink region). In summary, our approach facilitates enhanced denoising by utilizing LLM-driven insights to improve recommendation performance.

The main contributions of this paper are summarized as follows:

* We identify and address the limitations of existing denoising recommendation methods, proposing a novel application of LLMs' world knowledge and reasoning capabilities to enhance the performance of recommendation models.
* We introduce LLaRD, a framework that integrates knowledge generation and knowledge-enhanced denoising strategies to leverage the capabilities of LLMs for achieving noise-robust recommendation models.
* We validate the effectiveness of LLaRD through extensive experiments on three benchmark datasets and two mainstream backbone models, demonstrating the framework's superior performance in denoising recommendation.

## 2. Preliminaries

### Denoising Recommendation

Let the user set be \(\mathcal{U}=\{u\}\) and the item set be \(\mathcal{I}=\{i\}\), with \(|\mathcal{U}|\) and \(|\mathcal{I}|\) representing the number of users and items, respectively. The interaction matrix is \(\mathbf{R}\in\{0,1\}^{|\mathcal{U}|\times|\mathcal{I}|}\), where \(r_{ui}=1\) indicates that user \(u\) has interacted with item \(i\). Given the interaction data \(\mathcal{D}=\{(u,i,r_{ui})|u\in\mathcal{U},i\in\mathcal{I}\}\), we train a recommendation model \(f\) with parameters \(\theta_{f}\) to predict the likelihood of user interactions with unseen items, formulated as \(\theta_{f}=\arg\min_{\theta_{f}}\mathcal{L}_{rec}(\mathcal{D})\), where \(\mathcal{L}_{rec}\) is the recommendation loss. Using the BPR (Zhu et al., 2017) loss as an example, we have:

\[\mathcal{L}_{rec}=\mathbb{E}_{(u,i,j)-\mathcal{D}}\log(\sigma(f(\mathbf{h}_{u}) ^{\top}f(\mathbf{h}_{i}))-f(\mathbf{h}_{u})^{\top}f(\mathbf{h}_{j})), \tag{1}\]

where \(\mathbf{h}_{u/i}\in\mathbb{R}^{d}\) is the user/item representations, and \(\sigma(\cdot)\) is the sigmoid function. The triple \((u,i,j)\) consists of user \(u\), positive sample \(i\), and negative sample \(j\), sampled pairwise from \(\mathcal{D}\). While \(r_{ui}=1\) typically indicates a positive preference, observed interactions (_e.g.,_ views, clicks, and purchases) may introduce noise that does not accurately reflect true preferences. The denoising recommendation task aims to learn a clean interaction matrix \(\mathbf{R}^{*}\in\{0,1\}^{|\mathcal{U}|\times|\mathcal{I}|}\) representing users' genuine preferences or to derive noise-free representations \(\mathbf{h}_{u/i}^{*}\in\mathbb{R}^{d}\) from the noisy data.

### Information Bottleneck

The Information Bottleneck (IB) (Zhu et al., 2017; Zhang et al., 2018; Zhang et al., 2018) is a powerful framework rooted in information theory, commonly used for representation learning. Its goal is to enhance the robustness of learned representations for downstream tasks by discarding task-irrelevant information from the input data. We give the following definition:

Definition 1 (Information Bottleneck).: _Let \(X\in\mathcal{X}\) and \(Y\in\mathcal{Y}\) be random variables with joint distribution \(p(X,Y)\), where \(X\) contains information relevant to \(Y\). The relevant information is quantified by the mutual information \(I(X;Y)\). The IB framework seeks the most informative yet compressed representation \(Z\) by optimizing the objective: \(\max_{Z}\left\{I(Y;Z),\text{ s.t. }I(X;Z)\leq I_{c}\right\}\), where \(I_{c}\) is the information constraint between \(X\) and \(Z\)._

By introducing a Lagrange multiplier \(\lambda\), the constrained optimization is reformulated as an unconstrained objective: \(\max_{Z}I(Y;Z)-\lambda I(X;Z)\). The IB principle is widely applied to generalization and denoising tasks. Several studies (Zhou et al., 2017; Zhang et al., 2018) employ the Graph Information Bottleneck (GIB) principle to identify stable subgraphs to enhance model generalization, while methods like CGI (Zhou et al., 2017) leverage the IB framework for denoising recommendation.

### Chain-of-Thought Prompting

Chain-of-Thought (CoT) prompting (Zhou et al., 2017; Zhang et al., 2018; Zhang et al., 2018; Zhang et al., 2018) enhances the reasoning capabilities of LLMs by guiding them to generate intermediate reasoning steps structured as \(<\) input, thoughts, output \(>\) instead of directly producing answers. This approach improves both interpretability and accuracy, particularly for tasks requiring multi-step reasoning or logical deductions.

Definition 2 (CoT Prompting).: _CoT prompting directs a language model to produce a sequence of intermediate reasoning steps \(R\) before generating the final output \(Y\), given an input prompt \(X\). Mathematically, this framework models the output \(Y\) as:_

\[p(Y|X)=\sum_{R}p(Y|R,X),p(R|X). \tag{2}\]

_This decomposition transforms complex tasks into manageable subtasks, enhancing the reasoning capabilities of model._

By generating structured reasoning steps, CoT prompting enables more accurate and reliable responses in complex tasks.

## 3. Methodology

In this section, we introduce the Large Language Model-enhanced Recommendation **D**enoiser (LLaRD). As illustrated in Figure 2, it comprises two knowledge generation modules and a denoising module. Below, we provide a detailed overview of each component.

### Preference Knowledge Generation

In this module, we extract semantic preference information from textual data and user-item interactions despite inherent data noise. For example, the Amazon-Book dataset includes descriptions with irrelevant attributes, and reader reviews are often subjective and unstructured, featuring imaginative content, citations, or counterfactual statements. These factors complicate the direct extraction of meaningful preference semantics. To address this issue, we adopt methods from prior studies (Zhou et al., 2017; Zhang et al., 2018), utilizing LLMs for text denoising and preference knowledge reasoning. We design system prompts \(S_{u}\) and \(S_{i}\) for users and items, respectively, and construct configuration texts \(\mathcal{T}_{u}=\{T_{u}^{1},T_{u}^{2},...,T_{u}^{|\mathcal{H}|}\}\) and \(\mathcal{T}_{i}=\{T_{i}^{1},T_{i}^{2},...,T_{i}^{|\mathcal{I}|}\}\) for each user and item as follows:

\[T_{u}^{k}=\text{Item\_title}\parallel\text{Item\_description}\parallel\text{User \_comments}, \tag{3}\]

\[T_{i}^{k}=\text{Item\_title}\parallel\text{Item\_category}\parallel\text{Item \_description}. \tag{4}\]

The reasoning process of profile information is defined as:

\[\mathcal{P}_{u},\mathcal{P}_{i}=\text{LLM}\left([S_{u}\|T_{u}],[S_{i}\|T_{i}] \right), \tag{5}\]

where LLM(\(\cdot\)) denotes the LLM reasoning process, \(\parallel\) denotes the concatenation of the system prompt and configuration texts. \(\mathcal{P}_{u}\) and \(\mathcal{P}_{i}\) denote the profile information for each user and item, respectively. While LLMs effectively refine user preferences and item features, integrating extensive textual knowledge for collaborative analysis across thousands of users and items leads to semantic imprecision and high token inference costs. To mitigate these issues, we propose a keyword condensation technique for each user and item, reducing semantic ambiguity and enabling incremental updates to preference semantics. This approach accommodates the dynamic nature of users and items, ensuring robust and efficient preference extraction. Furthermore, we enhance system prompts by introducing the \(S_{u/i}^{\prime}\) which guides LLMs to refine the keywords of user preferences and item features based on the obtained profile information \(\mathcal{P}_{u}\) and \(\mathcal{P}_{i}\). The keyword generation process is defined as follows:

\[\mathcal{A}_{u},\mathcal{A}_{l}=\text{LLM}\left([S_{u}^{\prime}\|\mathcal{P}_{ u}],[S_{i}^{\prime}\|\mathcal{P}_{i}]\right), \tag{6}\]

where \(\mathcal{A}_{u}=\{A_{u}^{1},A_{u}^{2},...,A_{u}^{|\mathcal{H}|}\}\) and \(\mathcal{A}_{l}=\{A_{i}^{1},A_{i}^{2},...,A_{i}^{|\mathcal{I}|}\}\). We then combine the profile information \(\mathcal{P}_{u/i}\) with keywords \(\mathcal{A}_{u/i}\) to form the preference knowledge \(\mathcal{T}_{u/i}\). The preference knowledge \(\mathcal{T}_{u/i}\) is converted into token sequences, resulting in token embedding matrices \(\mathbf{T}_{u/i}=\{\mathbf{t}_{1},\mathbf{t}_{2},...\}\). These token embeddings are processed through a multi-layer perceptron (MLP) network \(W_{t}\) to generate semantic embeddings for each user and item:

\[\hat{\mathbf{E}}_{u},\hat{\mathbf{E}}_{t}=W_{t}(\text{LLM}([\mathbf{T}_{u}, \mathbf{T}_{i}]))+b. \tag{7}\]

Finally, we encapsulate the obtained preference semantic embeddings \(\hat{\mathbf{E}}_{u}\) and \(\hat{\mathbf{E}}_{t}\) into the preference knowledge \(\mathcal{K}_{p}\) as:

\[\mathcal{K}_{p}=\left\{\hat{\mathbf{E}}_{u}=\{\hat{\mathbf{e}}_{u1},\hat{ \mathbf{e}}_{u2},...\},\hat{\mathbf{E}}_{t}=\{\hat{\mathbf{e}}_{i1},\hat{ \mathbf{e}}_{i2},...\}\right\}. \tag{8}\]

### Relation Knowledge Generation

Previous studies utilizing LLMs to infer user preferences from interaction sequences often struggle to capture multi-hop relationships and long-path dependencies essential for understanding complex interactions. In contrast, our approach leverages the reasoning capabilities of LLMs over graph-structured data. By integrating preference semantics with collaborative information, we enable LLMs to identify associative semantics among multiple interaction nodes. Furthermore, we iteratively infer additional interaction edges to construct a relation knowledge graph, enhancing the graph learning process and improving the denoising of implicit feedback.

#### 3.2.1. **User-Centric CoT Reasoning Framework**

The collaborative information within the user-item interaction graph is invaluable for denoising. However, LLMs often struggle to achieve strong reasoning performance when dealing with complex interconnected data. To address this, we introduce a user-centric CoT reasoning framework. It meticulously designs inputs for multi-hopinteractions within user-centric neighborhoods and analyzes noisy and latent interactions based on semantic associations. By mining associative semantics between multi-hop neighbors through a multi-step reasoning process, we maintain LLM performance despite the complexity and volume of historical data. Additionally, the LLM is required to provide reasoning foundations and explanatory text when inferring potential interaction edges, enhancing the interpretability and transparency of the decision-making mechanisms.

**Step1: Preference Ratings.** We represent the preference of each user for items in their interaction sequence using a three-tier rating system: \(\left\{ {High, Medium, Low} \right\}\). For a user \(u\), given the preference knowledge containing profile information and preference keywords, along with the interaction sequence \(\mathcal{N}_{u}^{(1)}=\{i_{1},i_{2},...\}\) and attribute keywords list \(A_{k}^{k}\) for each item \(i_{k}\), we follow the steps referring the Figure 2 for LLM inference. The output is a rated interaction sequence \(\mathcal{N}_{u}^{Rated}=\{(i_{1},l_{ui_{1}}),(i_{2},l_{u_{2}}),...\}\), where \(i_{k}\) denotes an item interacted with by user \(u\), and \(l_{u_{k}}\in\left\{ {High, Medium, Low} \right\}\) represents the user's preference rating for \(i_{k}\).

**Step2: Noise Identification.** Building on Step 1, we enable the LLM to identify noise among interactions rated as \(Low\), denoted by \(\mathcal{N}_{u(low)}^{(1)}=\{i_{k}\in\mathcal{N}_{u}^{(1)}\mid l_{u_{k}}=Low\}\). The set of noise interactions is defined as:

\[I_{u}^{Noise}=\{i_{k}\in\mathcal{N}_{u(low)}\mid\text{LLM identifies }i_{k}\text{ as noise}\}. \tag{9}\]

Consequently, the noise interaction edges for each user are represented by:

\[\mathcal{E}^{Noise}=\{(u,i_{k})\mid u\in\mathcal{U},i_{k}\in I_{u}^{Noise}\}. \tag{10}\]

By rigorously analyzing the semantic associations between user preferences and item attributes, our approach minimizes the misclassification of interactions that may reflect latent user interests. This sophisticated semantic analysis enables the model to discern and retain interactions that, although rated \(Low\), may indicate emerging or subtle preferences.

**Step3: Collaborative Enhancement.** We perform second-hop neighbor exploration within the neighborhood of user \(u\) to identify users with similar preferences, constructing enhanced collaborative interactions through semantic associations. Utilizing the preference ratings from Step 1, we focus on items rated as \(High\), defined as \(\mathcal{N}_{u(high)}^{(1)}=\{i_{k}\in\mathcal{N}_{u}^{(1)}\mid l_{u_{k}}=High\}\). The set of second-hop neighbors is then determined by: \(\mathcal{N}_{u}^{(2)}=\bigcup_{i_{k}\in\mathcal{N}_{u(high)}}U_{u_{k}}\setminus \{u\}\), where \(U_{u_{k}}\) represents users who have interacted with item \(i_{k}\), \(\bigcup\) represents the union operation, and \(\setminus\{u\}\) ensures that user \(u\) is excluded from their own set of neighbors. Subsequently, we identify collaboratively enhanced users through LLM inference:

\[\mathcal{U}_{u}^{Collab}=\{u_{k}\in\mathcal{N}_{u}^{(2)}\mid\text{LLM identifies }i_{k}\text{ as enhancement}\}. \tag{11}\]

The corresponding set of collaborative enhancement interaction edges for each user is represented as:

\[\mathcal{E}^{Collab}=\{(u,u_{k})\mid u\in\mathcal{U},u_{k}\in\mathcal{U}_{u}^{ Collab}\}. \tag{12}\]

This collaborative enhancement leverages semantic associations to connect users with similar high-preference interactions, thereby enriching the recommendation capability to accurately discern and predict user preferences.

**Step4: Interests Exploration.** In this step, we utilize LLM reasoning to explore interests within the third-hop neighborhood of user \(u\). To prevent an exponential growth of high-order neighbors in the interaction graph, we selectively retain only interaction edges labeled as \(High\), emphasizing their importance in accurately reflecting user preferences. Building on the preference intensities from previous steps and the analysis of first- and second-order neighbors, we infer potential interest interactions among third-order neighbors, defined as: \(\mathcal{N}_{u}^{(3)}=\bigcup_{u_{k}\in\mathcal{N}_{u(high)}^{(2)}}I_{u_{k}} \setminus\mathcal{N}_{u}^{(1)}\). We then identify the set of interest items for user \(u\) as:

\[I_{u}^{Interests}=\{i_{k}\in\mathcal{N}_{u}^{(3)}\mid\text{LLM identifies }i_{k}\text{ as interests}\}. \tag{13}\]

Figure 2. The overview of the proposed LLaRD framework.

The corresponding set of interest interaction edges is represented by:

\[\mathcal{E}^{Interests}=\{(u,i_{k})\mid u\in\mathcal{U},i_{k}\in I_{u}^{Interests}\}. \tag{14}\]

Utilizing our user-centric CoT reasoning framework, we integrated collaborative information from the interaction graph with preference semantics. This integration enabled the identification of potential interactions that accurately reflect users' true preferences and encapsulate associative semantics. Through this multi-step reasoning process, we effectively capture the underlying association semantics, enhancing the ability of discerning and predicting nuanced user preferences and improving recommendation.

#### 3.2.2. Relation Knowledge Construction

To effectively leverage the reasoning results, we construct the above three distinct groups of interaction edges as relation knowledge:

\[\mathcal{K}_{r}=\{\mathcal{E}^{Noise},\mathcal{E}^{Collab},\mathcal{E}^{Interests}\}. \tag{15}\]

Subsequently, we integrate this relation knowledge into the original interaction graph \(\mathcal{G}=(\mathcal{U},\mathcal{I},\mathcal{E})\), where \(\mathcal{U}\) and \(\mathcal{I}\) represent the sets of users and items, respectively, and \(\mathcal{E}=\{(u,i)|u\in\mathcal{U},i\in\mathcal{I},r_{ui}=1\}\) denotes the existing interaction edges. The enriched interaction graph \(\mathcal{G}_{rel}\) is formulated as:

\[\mathcal{G}_{rel}=\left(\mathcal{U},\mathcal{I},(\mathcal{E}\setminus\mathcal{ E}^{Noise})\cup\mathcal{E}^{Collab}\cup\mathcal{E}^{Interests}\right). \tag{16}\]

This enriched graph incorporates the relation knowledge by removing noise interactions and adding collaborative and interest-based interactions. This integration enhances the downstream denoising learning process, enabling more accurate and semantically rich preference extraction.

### Knowledge-enhanced Denoising

After generating denoising knowledge, it is essential to use this to guide the denoising process. To achieve this, we propose a knowledge-enhanced denoising learning approach. As illustrated in the lower half of Figure 2, this approach includes a mask generator and a knowledge-guided information bottleneck framework.

#### 3.3.1. Mask Generator

To effectively capture comprehensive user preferences and latent semantic associations within the graph structure, we incorporate additional injected knowledge. This enhanced understanding facilitates data selection, reweighting, and representation learning, enabling a robust recommendation model even when denoising is limited to observed data. We employ a mask generator to create a learnable mask that distinguishes noisy interaction edges from informative ones in the original interaction data. Specifically, given the interaction graph \(\mathcal{G}=(\mathcal{V},\mathcal{E})\), where \(\mathcal{V}=\mathcal{U}\cup\mathcal{I}\) and \(\mathcal{E}=\{(u,i)|u\in\mathcal{U},i\in\mathcal{I},r_{ui}=1\}\), each edge is associated with a random variable \(q\sim\text{Bernoulli}(\lambda)\). An edge is retained if \(q=1\) and deleted otherwise. We parameterize the Bernoulli parameter \(\lambda\) using a MLP network \(\Phi\) as \(\lambda=\Phi(\mathbf{e}_{u}\|\mathbf{e}_{t})\), where \(\|\) denotes concatenation, and \(\mathbf{e}_{u},\mathbf{e}_{t}\in\mathbb{R}^{d}\) are the embeddings of user \(u\) and item \(i\) from the original interaction graph \(\mathcal{G}\). To enable end-to-end training, we adopt the Gumbel-Softmax reparametrization trick, converting the discrete variable \(q\) into a continuous variable in the range \([0,1]\):

\[q=\sigma((\log\delta-\log(1-\delta)+\lambda_{m})/\tau), \tag{17}\]

where \(\tau\) is the temperature hyperparameter and \(\delta\sim\text{Uniform}(0,1)\). As \(\tau\to 0\), \(q\) approaches a binary value. Finally, we obtain the masked graph \(\mathcal{G}^{\prime}=(\mathcal{U},\mathcal{I},\mathcal{E}^{\prime})\), where \(\mathcal{E}^{\prime}=\{(u,i)\mid(u,i)\in\mathcal{E},q_{m}\to 1\}\). This denoised graph retains only the informative interaction edges deemed relevant by the mask generator, thereby enhancing the downstream denoising learning process.

#### 3.3.2. Knowledge-guided Information Bottleneck for Denoising

Building on the Information Bottleneck (IB) principle, we present an optimization framework for denoising interaction graphs. Our dual objectives are to maximize the retention of user preference information in the denoised graph and to minimize the mutual information between the denoised and original graphs. To comprehensively capture true user preferences, we integrate supervisory signals from interaction data with additional knowledge from LLMs, encompassing both explicit preferences and latent semantic associations. This combined approach effectively guides the denoising process. The optimization objective is formally expressed as:

\[\max_{\mathcal{G}^{\prime}}I(\mathcal{R};\mathcal{G}^{\prime})+\alpha I( \mathcal{K}_{p};\mathcal{K}_{r};\mathcal{G}^{\prime})-\beta I(\mathcal{G}^{ \prime};\mathcal{G}), \tag{18}\]

where \(I(\mathcal{R};\mathcal{G}^{\prime})\) denotes the mutual information between recommendation targets \(\mathcal{R}\) and the denoised graph \(\mathcal{G}^{\prime}\). \(I(\mathcal{K}_{p},\mathcal{K}_{r};\mathcal{G}^{\prime})\) incorporates the mutual information between preference knowledge \(\mathcal{K}_{p}\) relation knowledge \(\mathcal{K}_{r}\), and the denoised graph \(\mathcal{G}^{\prime}\) integrating additional supervisory signals from LLMs. \(I(\mathcal{G}^{\prime};\mathcal{G})\) denotes the mutual information between the denoised graph \(\mathcal{G}^{\prime}\) and the original graph \(\mathcal{G}\) Here, \(\alpha\) and \(\beta\) are the hyperparameters that balance the influence of knowledge integration and noise reduction, respectively. Next, we detail the implementation of each term in Equation (18).

**Term1: Maximizing Mutual Information with Recommendation Information.** The first term aims to maximize information relevant to the recommendation task. We maximizes mutual information with the task-related information within \(\mathcal{G}^{\prime}\) by minimizing the BPR loss:

\[\mathcal{L}_{rec}=\sum_{(u,i,j)\in\mathcal{D}}-\log\sigma(y_{ui}^{\prime}-y_{ ui}^{\prime})\quad y_{ui}^{\prime}=\mathbf{h}_{u}^{\tau_{i}}\mathbf{h}_{i}^{ \prime}, \tag{19}\]

where \(\mathcal{D}=\{(u,i,j)|(u,i)\in\mathcal{D}^{+},(u,j)\in\mathcal{D}^{-}\}\) is the training set, \(\mathbf{h}_{u/i}\) and \(\mathbf{h}_{u/i}^{\prime}\) are the user and item representations after \(L\) GNN layers on \(\mathcal{G}^{\prime}\). Minimizing \(\mathcal{L}_{rec}\) effectively maximizes \(I(\mathcal{R};\mathcal{G}^{\prime})\), ensuring that the denoised graph retains essential preference information from recommendation prediction.

**Term2: Preference & Relation Knowledge Integration.** The second term promotes retaining information in the denoised graph \(\mathcal{G}^{\prime}\) that integrate with both preference knowledge \(\mathcal{K}_{p}\) and relation knowledge \(\mathcal{K}_{r}\). Given the collaborative embeddings \(\mathbf{e}_{u}\) and the preference knowledge embedding \(\mathbf{\tilde{e}}_{u}\) and \(\mathbf{\tilde{e}}_{t}\) from \(\mathcal{K}_{p}\), our optimization objective uses the InfoNCE (Golov et al., 2013) loss to denote:

\[\mathcal{L}_{prf}=\sum_{v\in\mathcal{V}}-\log\frac{\exp(\text{sim}(\mathbf{h}_ {v}^{\prime},\mathbf{\tilde{e}}_{v})/\tau)}{\sum_{v^{\prime}\in\mathcal{V}^{ \prime},v^{\prime}\neq v}\exp(\text{sim}(\mathbf{h}_{v}^{\prime},\mathbf{ \tilde{e}}_{v^{\prime}})/\tau^{\prime})}, \tag{20}\]

which sim(-) is the cosine similarity function, and \(\tau^{\prime}\) is the temperature parameter. \(\mathbf{h}_{v}^{\prime}\) is the final representation on \(\mathcal{G}^{\prime}\) after \(L\) GNN layers, and \(\mathbf{\tilde{e}}_{v}\) are embeddings derived from preference knowledge \(\mathcal{K}_{p}\) Minimizing \(\mathcal{L}_{prf}\) enhances the agreement between \(\mathcal{G}^{\prime}\) and preference knowledge, capturing user preferences within semantic information. For the relation knowledge \(\mathcal{K}_{r}\), we treat the relation knowledge graph \(\mathcal{G}_{rel}\) with embeddings \(\mathbf{E}_{u}=\{\mathbf{\hat{e}}_{u1},\mathbf{\hat{e}}_{u2},...\}\) and \(\mathbf{\hat{e}}_{i}=\{\mathbf{\hat{e}}_{i1},\mathbf{\hat{e}}_{i2},...\}\) as an augmented view of the interaction graph. After \(L\) GNN layers on \(\mathcal{G}_{rel}\), we obtain representation \(\mathbf{\hat{h}}_{u}\) and \(\mathbf{\hat{h}}_{i}\). The optimization objectives is defined as:

\[\mathcal{L}_{rel}=\sum_{\mathbf{e}\in\mathcal{V}}-\log\frac{\exp(\sin(\mathbf{h }_{o}^{\prime},\mathbf{\hat{h}}_{o})/\tau^{\prime})}{\sum_{\mathbf{e}^{\prime} \in\mathcal{V}^{\prime},\mathbf{e}^{\prime}\neq\Phi}\exp(\sin(\mathbf{h}_{o}^{ \prime},\mathbf{\hat{h}}_{\mathbf{e}^{\prime}})/\tau^{\prime})}, \tag{21}\]

where \(\tau^{\prime}\) is the temperature parameter and \(\sin(\cdot)\) is the cosine similarity function. Minimizing \(\mathcal{L}_{rel}\) integrates \(\mathcal{G}^{\prime}\) with relation knowledge \(\mathcal{K}_{r}\), capturing latent semantic associations within the graph structure.

**Term3: Minimizing Mutual Information for Denoising.** The third term facilitates the compression of information in the original interaction graph, filtering out of redundant interactions. Directly minimizing mutual information between two high-dimensional graph representations is computationally intractable. To overcome this, we utilize the Hilbert-Schmidt Independence Criterion (HSC) as an approximation for mutual information between \(\mathcal{G}\) and \(\mathcal{G}^{\prime}\).

First, we select appropriate kernel functions \(k(\cdot)\) and \(m(\cdot)\) for \(\mathcal{G}\) and \(\mathcal{G}^{\prime}\), respectively. For instance, Gaussian kernels are employed:

\[k(\mathbf{h}_{o},\mathbf{h}_{j})=\exp\left(-\frac{\left\|\mathbf{h}_{o}-\mathbf{ h}_{j}\right\|^{2}}{2\sigma_{k}^{2}}\right),\;m(\mathbf{h}_{o}^{\prime}, \mathbf{h}_{j}^{\prime})=\exp\left(-\frac{\left\|\mathbf{h}_{o}^{\prime}- \mathbf{h}_{j}^{\prime}\right\|^{2}}{2\sigma_{m}^{2}}\right), \tag{22}\]

where \(\theta_{k}\) and \(\theta_{m}\) are kernel bandwidth parameter, \(\mathbf{h}\) and \(\mathbf{h}^{\prime}\) are the user/item representation of \(\mathcal{G}\) and \(\mathcal{G}^{\prime}\), respectively. Using these kernel functions, we compute the kernel matrices \(K\) and \(M\) from the \(\mathcal{G}\) and \(\mathcal{G}^{\prime}\):

\[\mathbf{K}=[k(\mathbf{h}_{o},\mathbf{h}_{j})]_{n\times m},\quad\mathbf{M}=[m( \mathbf{h}_{o}^{\prime},\mathbf{h}_{j}^{\prime})]_{n\times m}, \tag{23}\]

where \(n\) is the number of users/items in the graph and \(o,j\in[0,n]\). To center the kernel matrices and remove the mean, we apply the centering matrix \(\mathbf{H}=\mathbf{1}-\frac{1}{n}\mathbf{1}\mathbf{1}^{\top}\), where \(\mathbf{I}_{n}\) is the \(n\times n\) identity matrix and \(\mathbf{1}\) is an \(n\)-dimensional vector of ones. The centralized kernel matrices are \(\mathbf{\hat{K}}=\text{HKH}\) and \(\mathbf{\hat{M}}=\text{HMH}\). Using the centralized matrices \(\mathbf{\hat{K}}\) and \(\mathbf{\hat{M}}\), we compute HSC as an approximation of mutual information between \(\mathcal{G}\) and \(\mathcal{G}^{\prime}\):

\[\text{HSC}(\mathcal{G},\mathcal{G}^{\prime})=\frac{1}{(n-1)^{2}}\text{trace}( \mathbf{\hat{K}}\mathbf{\hat{M}}). \tag{24}\]

The loss term for information compression using HSIC is defined as:

\[\mathcal{L}_{comp}=\text{HSIC}(\mathcal{G},\mathcal{G}^{\prime})=\frac{1}{(n- 1)^{2}}\text{trace}(\mathbf{\hat{K}}\mathbf{\hat{M}}). \tag{25}\]

Minimizing HSIC effectively reduces the mutual information between the original graph \(\mathcal{G}\) and the denoised graph \(\mathcal{G}^{\prime}\), ensuring that \(\mathcal{G}^{\prime}\) retains only the information necessary for the recommendation task, thereby achieving maximum compression and eliminating redundant interactions.

**Model Optimization.** The overall loss function combines the BPR loss, preference & relation knowledge and information compression loss, defined as:

\[\mathcal{L}=\mathcal{L}_{rec}+\alpha(\mathcal{L}_{prf}+\mathcal{L}_{rel})+ \beta\mathcal{L}_{comp}, \tag{26}\]

where \(\alpha\) and \(\beta\) are hyperparameters that balance the contribution of the preference alignment loss and the information compression loss, respectively.

## 4. Experiments

To evaluate the effectiveness of LLaRD, we carry out a series of experiments to address the following **R**esearch **Q**uestions:

* **RQ1:** How does LLaRD perform compared to various state-of-the-art denoising models when applied to different backbones?
* **RQ2:** How can we verify the effectiveness of denoising knowledge mined by LLMs in denoising learning?
* **RQ3:** How effectively can LLaRD help the model acquire robust representations mitigate noise issues?
* **RQ4:** Is LLaRD effective in boosting the performance of cold-start users?

### Experimental Settings

We conduct experiments on three benchmark datasets: Steam, Yelp, and Amazon-Book. We use two backbone models: GMF (Zhou et al., 2017) and LightGCN (Zhou et al., 2017). Our baseline methods consist of instance-level denoising and representation-level denoising. The instance-level method include WBPR (Zhou et al., 2017), T-CE (Zhou et al., 2017), R-CE (Zhou et al., 2017), DeCA (Zhou et al., 2017), SGD (Zhou et al., 2017) and DCF (Zhou et al., 2017). The representation-level method include SGD (Zhou et al., 2017), SimGCL (Zhou et al., 2017) and RLMRec (Zhou et al., 2017). More details of the dataset and implementation are provided in Appendix B.

### Performance Comparison (RQ1)

To evaluate the effectiveness and generalizability of our framework, we compared our proposed LLaRD method with existing denoising baselines across three datasets and two backbone models. The following observations summarize our findings:

* Our proposed LLaRD consistently outperforms mainstream denoising techniques across all three datasets and both backbone models. On average, LLaRD surpasses the second-best model, BOD, by approximately 6.92% when integrated with GMF, and by 11.79% with LightGCN. Although BOD employs a bi-level optimization strategy to extract prior knowledge, it lacks a comprehensive understanding of preferences and mining the relational semantics within interaction samples, resulting in inferior performance compared to our method.
* Against interaction data-driven methods such as T-CE, DeCA, DCF, and SGDL, which are constrained to identifying patterns within observed data and rely on training loss for noise identification, LLaRD demonstrates a substantial performance improvement ranging from 46.1% to 68.53%. This significant enhancement is attributed to our utilization of LLMs to infer user preferences beyond the available interaction data and the application of CoT reasoning to progressively uncover complex semantic associations within the interaction graph, thereby eliminating dependence on predefined assumptions.
* LLaRD outperforms robust representation learning methods by approximately 34.34% to 49.31%. The LLa-enhanced method, RLMRec, also achieves a significant 14.93% improvement over traditional approaches like SGD and SimGCL by aligning user preferences across semantic and collaborative spaces, demonstrating the effectiveness of LLMs in providing task-relevantinformation. However, LLaRD surpasses these methods by not only ensuring robust representations but also addressing data-level denoising. It leverages higher-order associative semantics compared to RLMRec and enhances noise recognition capabilities, resulting in superior performance.

### Ablation Study (RQ2)

To verify the effectiveness of denoising knowledge mined by LLMs and ensure its effective utilization in model learning, we conduct ablation studies to assess the contributions of various components within LLaRD. We design the following four model variants:

* w/o \(\text{MI}_{\text{min}}\): Removes the process of minimizing mutual information between the denoised and original interaction graph.
* w/o \(\text{MI}_{\text{max}}\): Removes the process of maximizing mutual information between the denoised graph and denoising knowledge.
* w/o PK: Removes the integration of preference knowledge in the denoising framework.
* w/o RK: Removes the integration of relation knowledge in the denoising framework.

As shown in Table 2, removing certain components leads to varying degrees of the performance degradation in LLaRD. The most significant decline occurs with the **w/o \(\text{MI}_{\text{min}}\)** variant, demonstrating the effectiveness of our denoising approach based on the information bottleneck principle. Additionally, omitting either preference knowledge (**w/o PK**) or relation knowledge (**w/o RK**) results in performance reductions, highlighting their importance for denoising recommendations. Furthermore, when using the **w/o \(\text{MI}_{\text{max}}\)**, the performance decreases, underscoring the significance of denoising knowledge for model learning.

### Model Benefits Analysis (RQ3 & RQ4)

**Robustness to Noisy Interactions.** To evaluate the robustness of LLaRD to noisy interactions, following previous studies (Zhu et al., 2019; Wang et al., 2020), we conducted experiments by introducing adversarial interaction examples (_i.e._, 5%, 10%, 15%, and 20% negative user-item interactions) into the training set, while keeping the test set unchanged. Figures 3(a) and 3(b) present the results on the Amazon-Book and Steam datasets, respectively. This demonstrates that LLaRD consistently outperforms all baseline methods across all noise levels. Additionally, the performance drop of LLaRD remains relatively

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c c} \hline \hline \multicolumn{2}{c}{**Dataset**} & \multicolumn{4}{c}{**Amazon-Book**} & \multicolumn{4}{c}{**Yelp**} & \multicolumn{4}{c}{**Steam**} \\ \hline
**Backbone** & **Method** & **R@10** & **N@10** & **R@20** & **N@20** & **R@10** & **N@10** & **R@20** & **N@20** & **R@10** & **N@10** & **R@20** & **N@20** \\ \hline \hline \multirow{8}{*}{GMF} & Normal & 0.0506 & 0.0399 & 0.0740 & 0.0463 & 0.0437 & 0.0352 & 0.0787 & 0.0465 & 0.0603 & 0.0512 & 0.0984 & 0.0599 & 768 \\  & WBPR & 0.0513 & 0.0404 & 0.0753 & 0.0477 & 0.0440 & 0.0359 & 0.0793 & 0.0569 & 0.0599 & 0.0505 & 0.0984 & 0.0597 & 784 \\  & R-CE & 0.0664 & 0.0508 & 0.0995 & 0.0615 & 0.0550 & 0.0464 & 0.0894 & 0.0578 & 0.0636 & 0.0536 & 0.1030 & 0.0665 & 782 \\  & T-CE & 0.0679 & 0.0533 & 0.1017 & 0.0604 & 0.0535 & 0.0453 & 0.0871 & 0.0565 & 0.0641 & 0.0536 & 0.1029 & 0.0663 & 763 \\  & DeCA & 0.0814 & 0.0619 & 0.1237 & 0.0710 & 0.0600 & 0.0515 & 0.0981 & 0.0610 & 0.0619 & 0.0677 & 0.0555 & 0.1047 & 0.0676 \\  & SGDL & 0.0975 & 0.0741 & 0.1489 & 0.0902 & 0.0683 & 0.0560 & 0.1098 & 0.0696 & 0.0704 & 0.0582 & 0.1084 & 0.0699 & 764 \\  & RLMRec & 0.0968 & 0.0728 & 0.1483 & 0.0896 & 0.0662 & 0.0548 & 0.1092 & 0.0693 & 0.0810 & 0.0654 & 0.1283 & 0.0811 & 763 \\  & BOD & 0.1009 & 0.0779 & 0.1520 & 0.0944 & 0.0706 & 0.0574 & 0.1126 & 0.0712 & 0.0718 & 0.0596 & 0.1135 & 0.0744 & 764 \\ \hline \multirow{8}{*}{LightGCN} & LLaRD & **0.1083** & **0.0851** & **0.1619** & **0.1027** & **0.0708** & **0.0578** & **0.1135** & **0.0723** & **0.0819** & **0.0657** & **0.1291** & **0.0817** & 768 \\ \cline{2-13}  & Normal & 0.0670 & 0.0495 & 0.1010 & 0.0613 & 0.0539 & 0.0452 & 0.0871 & 0.0566 & 0.0731 & 0.0627 & 0.1170 & 0.0784 & 769 \\  & WBPR & 0.0674 & 0.0496 & 0.1016 & 0.0620 & 0.0539 & 0.0450 & 0.0877 & 0.0571 & 0.0735 & 0.0629 & 0.1165 & 0.0777 & 778 \\  & T-CE & 0.0693 & 0.0530 & 0.1079 & 0.0715 & 0.0585 & 0.0501 & 0.0906 & 0.0612 & 0.0736 & 0.0624 & 0.1133 & 0.0754 & 771 \\  & DCF & 0.0723 & 0.0557 & 0.1112 & 0.0743 & 0.0614 & 0.0524 & 0.0926 & 0.0627 & 0.0768 & 0.0672 & 0.1164 & 0.0771 & 772 \\  & DeCA & 0.0823 & 0.0611 & 0.1291 & 0.0799 & 0.0652 & 0.0576 & 0.1092 & 0.0689 & 0.0827 & 0.0711 & 0.1288 & 0.0882 & 773 \\  & SGL & 0.1018 & 0.0791 & 0.1498 & 0.0949 & 0.0718 & 0.0603 & 0.1171 & 0.0759 & 0.0795 & 0.0671 & 0.1254 & 0.0833 & 773 \\  & SimCL & 0.1109 & 0.0873 & 0.1538 & 0.1013 & 0.0709 & 0.0559 & 0.1146 & 0.0748 & 0.0576 & 0.0471 & 0.0903 & 0.0587 & 774 \\  & SGDL & 0.1135 & 0.0872 & 0.1675 & 0.1054 & 0.0800 & 0.0661 & 0.1323 & 0.0841 & 0.0933 & 0.0769 & 0.1458 & 0.0755 & 775 \\  & RLMRec & 0.1034 & 0.0788 & 0.1600 & 0.0960 & 0.0794 & 0.0652 & 0.1275 & 0.0815 & 0.0926 & 0.0746 & 0.1452 & 0.0924 & 776 \\  & BOD & 0.1244 & 0.0985 & 0.1777 & 0.1131 & 0.0922 & 0.0739 & 0.1432 & 0.0884 & 0.1001 & 0.0802 & 0.1469 & 0.0891 & 777 \\  & LLaRD & **0.1408** & **0.1126** & **0.2028** & **0.1326** & **0.0975** & **0.0809** & **0.1574** & **0.1008** & **0.1054** & **0.0868** & **0.1631** & **0.1059** & 778 \\ \hline \hline \end{tabular}
\end{table}
Table 1. Overall performance comparison of different baselines on the backbone models. Bold numbers indicate the best performance, and underlined numbers indicate the second-best performance. “**R**” and “**N**” stand for Recall and NDCG, respectively.

Figure 3. Impact comparison _ur.t._ noise ratio in added interaction data. The bars display Recall@20, while the curve shows the drop rate in performance.

stable compared to the baselines, highlighting its superior resilience to differing noise intensities. These results indicate that the denoising framework LLaRD effectively identifies and leverages useful patterns even in the presence of significant noise.

**Cold-Start Recommendation.** To evaluate the effectiveness in cold-start scenarios characterized by extremely sparse interaction data, we divide all users into five groups based on their interaction frequency. A lower group ID corresponds to sparser user activity and more severe cold-start issues. We compare LLaRD with various baseline methods across different cold-start levels. As shown in Figure 4, the results clearly indicate that LLaRD consistently outperforms baselines across all cold-start levels. This superior performance is attributed to the ability of LLaRD to derive preference knowledge and relation knowledge from LLMs, thereby enabling effective noise identification and robust modeling of both users and items, even in cold-start scenarios.

## 5. Related Work

**Denoising in Recommendation.** Recommendation typically treat observed interactions as positive and unobserved ones as negative in implicit feedback (Henderson et al., 2015; Chen et al., 2016). However, this approach can incorporate erroneous clicks or biased behaviors, leading to false positives and negatives that degrade user experience (Zhu et al., 2017). Existing denoising methods are generally categorized as follows: **1) Selection-Based Methods**: These methods (Henderson et al., 2015; Chen et al., 2016) filter out noisy feedback while retaining clean data. Early approaches (Chen et al., 2016; Chen et al., 2016) use samplers based on data characteristics, whereas adaptive strategies later identify unreliable instances by detecting significant loss early in training. Recent techniques (Li et al., 2017) employ deep reinforcement learning for effective noise removal. DCF (Chen et al., 2016) uses a dual-correction framework to identify noise through changes in sample loss over time. **2) Re-weighting-Based Methods**: This approach assigns higher weights to informative interactions. Initial methods (Zhu et al., 2017; Chen et al., 2018) utilize training loss to assign lower weights to high-loss samples. Recent works like DeCA (Zhu et al., 2017) and BOD (Wang et al., 2017) have introduced novel evaluation criteria and optimization strategies for more accurate weight learning. **3) Side-Information-Based Methods and Special Strategies**(Chen et al., 2016; Chen et al., 2016): Early approaches (Chen et al., 2016; Chen et al., 2016; Chen et al., 2016) utilize dwell time and annotations to detect noise. (Chen et al., 2016; Chen et al., 2016; Chen et al., 2016) incorporate sequential or multi-behavior data to capture unexpected interactions. (Chen et al., 2016; Chen et al., 2016) have employed knowledge graphs to enhance preference modeling, facilitating denoising frameworks. In addition, there are some studies that learn robust representations by designing special denoising strategies. Early work (Chen et al., 2016; Chen et al., 2016; Chen et al., 2016) employ autoencoders to reduce noise in representations. (Chen et al., 2016; Chen et al., 2016) leverage self-supervised learning on graph-structured data for greater stability. Despite their effectiveness, existing methods rely heavily on observed data and predefined assumptions to model user preferences and distinguish noise. In contrast, our approach leverages LMs to acquire denoising knowledge, extracting inferred preference and relational semantics to capture noise interactions.

**LIMs in Recommendation.** LIMs (Chen et al., 2016; Chen et al., 2016) have emerged as powerful tools for enhancing recommendation by leveraging deep semantic understanding and extensive pre-trained knowledge (Chen et al., 2016; Chen et al., 2016; Chen et al., 2016). Some approaches (Chen et al., 2016; Chen et al., 2016) capture latent preferences by generating textual tokens derived from user and item semantics, effectively modeling user preferences through LIMs' rich semantic capabilities. Other studies (Chen et al., 2016; Chen et al., 2016; Chen et al., 2016; Chen et al., 2016) employ LMs as recommenders by crafting specific instructions and fine-tuning them for recommendation tasks, utilizing their adaptability for tailored functionalities. Additionally, certain research (Chen et al., 2016; Chen et al., 2016) adapts LIMs to downstream tasks using prompts without fine-tuning. For example, (Chen et al., 2016) introduce LIMs as zero-shot conversational recommender systems, while TooIce (Zhu et al., 2017) and RecMind (Zhu et al., 2017) design CoT prompts to enable LIMs to handle complex reasoning within recommendation scenarios. Furthermore, methods (Zhu et al., 2017; Chen et al., 2016; Chen et al., 2016; Chen et al., 2016) generate rich-semantic embeddings and integrate reasoning knowledge into traditional models, improving understanding of user preferences and item features, thereby improving recommendation. Despite advancements in utilizing LIMs for various tasks, exploration in denoising recommendations remains limited. Our approach leverages LIMs to extract denoising-related knowledge, enhancing robustness by addressing noise interactions.

## 6. Conclusion

In this paper, we introduced LLaRD, a novel framework that leverages large language models (LLMs) to enhance the denoising process in recommendation. It improved denoising ability of the model by guiding LIMs to mine and inferred denoising-related knowledge from text and interaction data. Specifically, it first enriched semantic insights via LIMs, enabling a more comprehensive inference of user-item preferences. Then it employed a Chain-of-Thought (CoT) strategy over user-item interaction graphs to uncover relation knowledge relevant to denoising. Finally, the Information Bottleneck (IB) principle effectively aligned the denoised knowledge with recommendation targets. Through extensive empirical evaluations, we demonstrated that LLaRD significantly improves both denoising and recommendation accuracy compared to existing methods. Future work will explore further refinements to the framework and its applicability across diverse recommendation scenarios.

Figure 4. Recommendation performance over different cold-start user groups on Amazon-Book (upper) and Steam (lower) dataset.

Unleashing the Power of Large Language Models for

## References

* (1)
* Bao et al. (2023) Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuil Feng, and Xiangnan He. 2023. Tailored: An effective and efficient tuning framework to align large language model with recommendation. In _Proceedings of the 12th ACM Conference on Recommender Systems_. 1007-1014.
* Blin et al. (2021) Zhi Blin, Shaojin Zhou, Hao Fu, Qihong Yang, Zhenqi Sun, Junjie Tang, Guiquan Liu, Kulul Liu, and Xiaolong Li. 2021. Denoising user-aware memory network for recommendation. In _Proceedings of the 15th ACM Conference on Recommender Systems_. 400-410.
* Buscher et al. (2009) Georg Buscher, Ludger Van Elst, and Andreas Dengel. 2009. Segment-level display time as implicit feedback: a comparison to eye tracking. In _Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval_. 67-74.
* Chen et al. (2024) Jianxin Chen, Chen Shen Qian, Liye Jie Wang, Xiaoqi Ni, and Jieping Ye. 2024. SAC-BC: Exploiting Large Language Models as Skilled Automatic Constructors for Domain Knowledge Graphs. _arXiv preprint arXiv:2404.08811_ (2024).
* Chen et al. (2024) Jiaqi Chen, Wang Wenjie, Chongqing Gao, Peng Wu, Jianxiong Wei, and Qingsong Hua. 2024. Treatment Effect Estimation for User Interest Exploration on Recommender Systems. In _Proceedings of the 10th International ACM SIGIR Conference on Research and Development in Information Retrieval_. 1661-1671.
* Dai et al. (2023) Sinhao Dai, Ningbo Shu, Haiyuan Zhao, Weiqi Zhang, China S Chen, Xiangxiang Sun, Xiao Zhang, and Jun Xu. 2023. Uncovering chatgt5 capabilities in recommender systems. In _Proceedings of the 17th ACM Conference on Recommender Systems_. 1126-1132.
* Ding et al. (2019) Jingta Ding, Guanglu Yu, Xiangnan He, Fuil Feng, Yong Li, and Deep Jin. 2019. Sampf: Sampf: Sampf for bayesian personalized ranking by leveraging view data. _IEEE transactions on knowledge and data engineering_ 33, 2 (2019), 667-681.
* Ellis et al. (2006) Rod Ellis, Shawn Loewen, and Rocaey Erikan. 2006. Implicit and explicit concrete feedback: an acquisition of 2.5 grammer. _Studies in second language acquisition_ 28, 2 (2006), 339-368.
* Fan et al. (2019) Wenjie Fan, Yao Min, Qing Li, Yuan He, Eric Zhao, Bliang Tang, and Dawei Yin. 2019. Graph neural networks for social recommendation. In _the world wide web conference_. 417-426.
* Fu (2010) Xin Fu. 2010. Towards a model of implicit feedback for web search. _Journal of the American Society for Information Science and Technology_ 61, 1 (2010), 30-49.
* Gantner et al. (2012) Zeng Gantner, Lucas Dommach, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2012. Personalized ranking for non-uniformly sampled items. In _Proceedings of KDD Cup 2012_. PMLR, 282-297.
* Guo et al. (2020) Yunjun Gao, Yunhao Du, Yuqiqi Hu, Lu Chen, Xinjun Zhu, Ziquan Fang, and Baihua Zheng. 2020. Self-guided learning to denoise for robust recommendation. In _Proceedings of the 58th International ACM SIGIR Conference on Research and Development in Information Retrieval_. 1412-1422.
* Guo et al. (2023) Yingqiang Guo, Mostafa Rahmani, Athiral Hiraguang, Jose Sepulveda, James Cavene, and Fei Mawr. 2023. Automated data denoising for recommendation. _arXiv preprint arXiv:2305.07000_ (2023).
* Guo et al. (2022) Shile Guo, Shenzhen Qian, Liyein Tu, Yongliang Ge, and Yongfeng Zhang. 2022. Recommendation as language processing (trlp): A unified pretrain, personalized prompt 6. predict paradigm (p5). In _Proceedings of the 16th ACM Conference on Recommender Systems_. 299-315.
* Gutman and Virginian (2010) Michael Gutman and Anpo Virginian. 2010. Noise-contrastive estimation: A new estimation principle for personalized statistical models. In _Proceedings of the thirteenth international conference on artificial intelligence and statistics_. JMLR Workshop and Conference Proceedings, 297-304.
* Han et al. (2024) Yonglong Han, Hao Wang, Brian Wang, Liqan Wu, Zhi Li, Wei Guo, Tong Lu, Defu Lian, and Emheng Chen. 2024. Efficient Noise-Decoding for Multi-Behavior Sequential Recommendation. In _Proceedings of the ACM on Web Conference_. 2024 1397-3306.
* He et al. (2020) Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yonglong Zhang, and Meng Wang. 2020. Lightgcn: Simplifying and powering graph convolution network for recommendation. In _Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval_. 639-648.
* Huang et al. (2024) Zhuangjiang He, Yifan Wang, Yonghui Yang, Poijie Sun, Le Wu, Huoyue Bai, Jiwei Gong, Richang Hong, and Min Zhang. 2024. Double Correction Framework for Denoising Recommendation. _arXiv preprint arXiv:2405.1272_ (2024).
* He et al. (2023) Zhunliu He, Zhoukong Xie, Haib Yan, Hanzaid Skevin Liang, Yess Feng, Bohishustan Majumdar, Nathan Kalas, and Jianian McAuley. 2023. Large language models are asr-shot conversational recommenders. In _Proceedings of the 33rd ACM international conference on information and knowledge management_. 720-730.
* Hu et al. (2008) Yifan Hu, Yohua Koren, and Chris Volinsky. 2008. Collaborative filtering for implicit feedback datasets. In _2008 Eighth IEEE international conference on data mining_. 265-272.
* Juankee et al. (2010) Gawesh Juankee, Martin Stommser, and Patty Kostkova. 2010. Comparison of implicit and explicit feedback from an online music recommendation service. In _proceedings of the 1st international workshop on information heterogeneity and fusion in recommender systems_. 67-51.
* Jiang et al. (2024) Yangjun Jiang, Yuhao Yang, Lianghao Xia, and Chao Huang. 2024. Diffie: Knowledge graph diffusion model for recommendation. In _Proceedings of the 17th ACM International Conference on Web Search and Data Mining_. 313-321.
* Joachims et al. (2017) Thorsten Joachims, Laura Ganaba, Bing Pan, Helene Hembrooke, and Gei Gay. 2017. Accurately interpreting clickthrough data as implicit feedback. In _Acm Sigur Forum_, Vol. 51. A sensor level, NJ, USA, 4-11.
* Khawar et al. (2020) Farah Khawar, Leonard Poon, and Nevin I. Zhang. 2020. Learning the structure of auto-encoding recommendation. In _Proceedings of The Web Conference_. 2020.
* Kieu et al. (2020) Hai-Deng Kieu, Minh Duc Nguyen, Thanh-Soon Nguyen, and Dung D Le. 2020. Keyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations. _arXiv preprint arXiv:2005.1962_ (2020).
* Koren et al. (2009) Yehhao Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization techniques for recommender systems. _Computer_ 42, 8 (2009), 30-37.
* Lang et al. (2018) Dawen Lang, Rahul G Krishna, Matthew D Hoffman, and Tony Jebara. 2018. Variational autoencoders for collaborative filtering. In _Proceedings of the 2018 World wide web conference_. 689-698.
* Liang et al. (2024) Jiayi Liu, Shaojin Zheng, Ziogui Yang, Jiancan Wu, Yancheng Yuan, Xiang Wang, and Xiangnan He. 2024. Lixm: Large language-recommendation assistant. In _Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval_. 1785-1795.
* Liu et al. (2023) Weilin Liu, Xiangyu Zhao, Yeung Yuanhao Zhu, and Wang Wang. 2023. Autodepan: Automatic data instance denoising for recommendations. In _Proceedings of the ACM Web Conference_. 2023 1003-1011.
* Liu et al. (2023) Junling Liu, Chao Liu, Peilin Zhou, Rengie Luo, Kang Zhou, and Yan Zhang. 2023. Is chtspied a good recommender? a preliminary study. _arXiv preprint arXiv:2304.1494_ (2023).
* Nguyen et al. (2019) Dee Tam Nguyen, Chathanya Kumar Mumumadi, Thi Phuong Nhang Ngo, Thi Hoai Phuong Nguyen, Laura Begel, and Thomas Brox. 2019. Self: Learning to filter using tyleb with self-ensembles. _arXiv preprint arXiv:1910.08429_ (2019).
* Pan and Chen (2013) Weike Pan and Li Chen. 2013. Gtop: Groep preference based bayesian personalized ranking for one-class collaborative filtering. In _Twenty-Third International Joint Conference on Artificial Intelligence_.
* Ren et al. (2018) Xubin Ren, Wei Wei, Lianghao Xia, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, and Chao Huang. 2024. Representation learning with large language models for recommendation. In _Proceedings of the ACM on Web Conference_. 2018 3464-3475.
* Rendle et al. (2012) Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2012. BPR: Bayesian personalized ranking from implicit feedback. _arXiv preprint arXiv:12012.0818_ (2012).
* Sharma et al. (2015) Anim Sharma, Jakse M Hoffman, and Duncan J Watts. 2015. Estimating the causal impact of recommendation systems from observational data. In _Proceedings of the Extremal ACM Conference on Economics and Computation_. 453-470.
* Strub et al. (2019) Florian Strub, Jeremie Mary, and Preux Philippe. 2015. Collaborative filtering with stacked denoising autoencoders and sparse inputs. In _NIPS workshop on machine learning for commerce_.
* Sun et al. (2020) Qingwen Sun, Jianxin Li, Hao Peng, Jiu Wang, Xingqheng Fu, Cheng Ji, and Yu Philip. 2020. Graph structure learning with variational information bottleneck. In _Proceedings of the AAAI Conference on Artificial Intelligence_, Vol. 36. 4165-4174.
* Sun et al. (2021) Yatong Sun, Bin Wang, Zhu Sun, and Xiaochuo Yang. 2021. Descovery Data Instance Meter? Enhancing Sequential Recommendation by Eliminating Unreliable Data. In _IJCAI_. 17519-1758.
* Tishby and Zalavsky (2015) Nafta Tishby and Noga Zalavsky. 2015. Deep learning and the information bottleneck principle. In _2015 we informating theory workshop (trlp)_. IEEE 1-5.
* Wang et al. (2004) Shuye Wang, Yonglong Sui, Chao Wang, and Hui Xiong. 2004. Unleashing the Power of Knowledge Graph for Recommendation via Invariant Learning. In _Proceedings of the ACM on Web Conference_. 2004 375-3755.
* Wang et al. (2002) Wenjie Wang, Fuil Feng, Xiangnan He, Xiangyu Zhang, and Tat-Seng Chua. 2002. Denoising implicit feedback for recommendation. In _Proceedings of the 14th ACM international conference on web search and data mining_. 373-381.
* Wang et al. (2002) Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Akanksha Chowdhury, and Denny Zhao. 2002. Self-consistency improves chain of thought reasoning in language models. _arXiv preprint arXiv:2002.1117_ (2022).
* Yang et al. (2023) Yancheng Wang, Ziyan Jiang, Zheng Chen, Fang, Yingqeng Zhou, Runah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingqhe Wang. 2023. Rec-mind: Large language model powered agent for recommendation. _arXiv preprint arXiv:2303.1849_ (2023).
* Wang et al. (2018) Yu Wang, Xin Xia, Zixiqin Meng, Joonen M Jose, Fuli Feng, and Xiangnan He. 2022. Learning robust recommenders through cross-model agreement. In _Proceedings of the ACM Web Conference_. 2022 2015-2020.
* Wang et al. (2003) Zongwei Wang, Min Gao, Wentao Li, Junliang Yu, Linxin Guo, and Hongqhi Yin. 2023. Efficient bi-level optimization for recommendation denoising. In _Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_. 2502-2511.
* Wang et al. (2021) Zias Wang, Qianguan Xu, Zhiyong Yang, Xiaochun Cao, and Qingming Huang. 2021. Implicit feedbacks are not always favorable: Iterative relabeled one-class collaborative filtering against noisy interactions. In _Proceedings of the 29th ACM International Conference on Multimedia_. 3070-3078.

* Wei et al. (2022) Chunyu Wei, Jian Liang, Di Liu, and Fei Wang. 2022. Contrastive graph structure learning via information bottleneck for recommendation. _Advances in Neural Information Processing Systems_ 35 (2022), 2007-20420.
* Wei et al. (2012) Jason Wei, Xuexi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quco V Le, Denny Zhou, et al. 2012. Chain-of-thoight proputignte elicits reasoning in large language models. _Advances in neural information processing systems_ 35 (2022), 2482-24837.
* Wei et al. (2022) Wei Wei, Xuichi Ren, Jishin Tang, Qinyong Wang, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, and Chao Huang. 2022. Lime Large language models with graph augmentation for recommendation. In _Proceedings of the 17th ACM International Conference on Web Search and Data Mining_. 806-815.
* Wenqi et al. (2019) Hongyi Wen, Longqi Yang, and Deborah Estia. 2019. Leveraging soft-click feedback for content recommendations. In _Proceedings of the 13th ACM Conference on Recommender Systems_. 278-286.
* Wu et al. (2021) Jianjun Wu, Xiang Wang, Fuji Feng, Xiangnan He, Liang Chen, Jianxen Lin, and Xing Xie. 2021. Self-supervised graph learning for recommendation. In _SIGIR_. 726-735.
* Wu et al. (2023) Liqiang Wu, Zhi Zheng, Xiaopeng Qin, Hao Wang, Hongqhao Gu, Tingqin Shen, Chun Qin, Chen Zhu, Hangzhou Zhu, Qin Li, et al. 2023. A Survey on Large Language Models for Recommendation. _arXiv preprint arXiv:2303.19860_ (2023).
* Wu et al. (2020) Tailiu Wu, Hongyu Ren, Pan Li, and Jure Leskovec. 2020. Graph information bottleneck. _Advances in Neural Information Processing Systems_ 33 (2020), 20437-2048.
* Wu et al. (2016) Yao Wu, Christopher Dubois, Alice X Zheng, and Martin Este. 2016. Collaborative denoising auto-encoders for top-n recommender systems. In _Proceedings of the ninth ACM international conference on web search and data mining_. 153-162.
* Xu et al. (2012) Yunjia Xu, Weiwei Liu, Jinghao Liu, Xiaolin Chen, Hao Jiang, Jieping Zhu, Bo Chen, Ruining Tang, Weizan Zhang, and Yong Yu. 2012. Towards open-world recommendation with knowledge augmentation from large language models. In _Proceedings of the 18th ACM Conference on Recommender Systems_. 12-22.
* Xia et al. (2024) Yuewei Xia, Ding Wang, Qiang Liu, Liang Wang, Shu Wu, and Xiao-Yu Zhang. 2024. Chain-of-history Reasoning for Temporal Knowledge Graph Forecasting. In _Findings of the Association for Computational Linguistics: ACL_. 2024. 16144-16159.
* Xia et al. (2024) Yu Xia, Rui Wang, Xu Liu, Mingyan Li, Tong Yu, Xiang Chen, Jialian McAuley, and Shuai Li. 2024. Beyond chain-of-thoight: A survey of chain-of-a paradigms for link. _arXiv preprint arXiv:2405.16508_ (2024).
* Xin et al. (2023) Xin Xin, Xiangyu Liu, Rung Wang, Pengfei Ren, Zhumin Chen, Jialuan Lei, Xinli Shi, Hengliano, Joemon J Mase, Maarten de Bijie, et al. 2023. Improving implicit feedback-based recommendation through multi-behavior alignment. In _Proceedings of the 46th international ACM SIGIR conference on research and development in information retrieval_. 932-941.
* Yang et al. (2024) Shenghao Yang, Weihui Meng, Yeiji Sun, Qingxiao Ai, Yujun Liu, Mingchen Cai, and Min Zhang. 2024. Sequential recommendation with latent relations based on large language model. In _Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval_. 335-344.
* Yang et al. (2021) Yonghui Yang, Le Wu, Richang Hong, Kun Zhang, and Meng Wang. 2021. Enhanced graph learning for collaborative filtering via mutual information maximization. In _Proceedings of the sixth international ACM SIGIR conference on research and development in information retrieval_. 71-80.
* Yang et al. (2024) Yonghui Yang, Le Wu, Zhan Wang, Zhuangshuang He, Richang Hong, and Meng Wang. 2024. Graph bottlenecked Social Recommendation. In _Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_. 3353-3362.
* Xu et al. (2023) Jia-Yu Xu, Kan-Peng Ning, Zhen-Hui Liu, Mu-Nan Ning, and Li Yuan. 2023. Llm lies: Hallmotilations are not hugs, but features as adversarial examples. _arXiv preprint arXiv:2303.0410_ (2023).
* Yu et al. (2022) Junliang Yu, Hongqiu Yin, Xia Xia, Tong Chen, Liheun Cui, and Quoc Viet Hung Nguyen. 2022. A graph augmentation necessary? simple graph contrastive learning for recommendation. In _Proceedings of the 36th international ACM SIGIR conference on research and development in information retrieval_. 1294-1303.
* Zhang et al. (2024) An Zhang, Yuxin Chen, Leheng Sheng, Xiang Wang, and Tan-Seng Chua. 2024. On generative agents in recommendation. In _Proceedings of the 47th international ACM SIGIR conference on research and development in Information Retrieval_. 1807-1817.
* Zhang et al. (2023) Chi Zhang, Rui Chen, Xiangyu Zhao, Qilong Han, and Li Li. 2023. Denoising and prompt-tuning for multi-behavior recommendation. In _Proceedings of the ACM Int conference on SIGIR conference on data mining_. 2335-1363.
* Zhang et al. (2024) Chi Zhang, Qilong Han, Hui Chen, Xiangyu Zhao, Hong Tang, and Hongtao Song. 2024. SSDR: SSDR: Self-augmented Sequence Denoising for Sequential Recommendation. _arXiv preprint arXiv:2403.04278_ (2024).
* Zhang et al. (2023) Junjie Zhang, Raubing Xie, Tuppu Hou, Wayne Xin Zhao, Levy Lin, and Ji-Rong Wen. 2023. Recommendation as instruction following: A large language model empowered recommendation approach. _arXiv preprint arXiv:2305.00701_ (2023).
* Zhu et al. (2024) Wei Zhang, Chaoyun Wan, Yonggang Zhang, Yin-ming Cheung, Ximnet Tan, Xu Shen, and Jeping Ye. 2024. Interpreting and Improving Large Language Models in Arithmetic Calculation. _arXiv preprint arXiv:2409.01659_ (2024).
* Zhang et al. (2024) Yang Zhang, Keqin Bao, Ming Yan, Wenjie Wang, Fuli Feng, and Xiangnan He. 2024. Text-like Encoding of Collaborative Information in Large Language Models for Recommendation. _arXiv preprint arXiv:2406.03210_ (2024).
* Zhao et al. (2016) Qian Zhao, Shao Chang, F Maxwell Harper, and Joseph A Konstan. 2016. Gaze prediction for recommender systems. In _Proceedings of the 10th ACM Conference on Recommender Systems_. 131-138.
* Zhao et al. (2024) Yuyue Zhao, Jianwen Wu, Xiang Wang, Wei Yang, Dingxian Wang, and Maarten de Bijie. 2024. Let Me Du for You: Towards L1M Empowered Recommendation via Total Learning. In _Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval_. 1796-1806.
* Zhu et al. (2013) Xiqian Zhu, Yunta Du, Yuwen Mao, Li Chen, Yujia Hu, and Tunjun Gao. 2023. Knowledge-refined Denoising Network for Robust Recommendation. In _Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval_. 362-371.
* Zhu et al. (2013) Li13 Liu, Mingyang Zhang, and Weiwei Liu. 2013.
* Zhu et al. (2013) Li13 Liu, Mingyang Zhang, and Weiwei Liu. 2013.
* Zhu et al. (2013) Li13 Liu, Mingyang Zhang, and Weiwei Liu. 2013.
* Zhu et al. (2013) Li13 Liu, Mingyang Zhang, and Weiwei Liu. 2013. Multi-agent collaborative filtering via mutual information maximization. In _Proceedings of the sixth international ACM SIGIR conference on research and development_. 178-180.
* Zhu et al. (2014) Li13 Liu, Mingyang Zhang, and Weiwei Liu. 2014. Multi-agent collaborative filtering via mutual information maximization. In _Proceedings of the sixth international ACM SIGIR conference on research and development_. 178-180.
* Zhu et al. (2015) Yonghui Zhu, Weiwei Liu, and Weiwei Liu. 2015. Multi-agent collaborative filtering via mutual information maximization. In _Proceedings of the 47th international ACM SIGIR conference on Research and Development_. 178-180.
* Zhu et al. (2015) Wei Zhu, Weiwei Liu, and Weiwei Liu. 2015. Multi-agent collaborative filtering via mutual information maximization. In _Proceedings of the 47th international ACM SIGIR conference on research and development in information retrieval_. 1807-1817.
* Zhu et al. (2023) Chi Zhang, Rui Chen, Xiangyu Zhao, Qilong Han, and Li Li. 2023. Denoising and prompt-tuning for multi-behavior recommendation. In _Proceedings of the ACM Int conference on SIGIR conference on data mining_. 2335-1363.
* Zhang et al. (2024) Chi Zhang, Qilong Han, Hui Chen, Xiangyu Zhao, Hong Tang, and Hongtao Song. 2024. SSDR: Self-augmented Sequence Denoising for Sequential Recommendation. _arXiv preprint arXiv:2403.04278_ (2024).
* Zhang et al. (2023) Junjie Zhang, Raubing Xie, Tuppu Hou, Wayne Xin Zhao, Levy Lin, and Ji-Rong Wen. 2023. Recommendation as instruction following: A large language model empowered recommendation approach. _arXiv preprint arXiv:2305.00701_ (2023).
* Zhang et al. (2024) Wei Zhang, Chaoyun Wan, Yonggang Zhang, Yin-ming Cheung, Ximnet Tan, Xu Shen, and Jeping Ye. 2024. Interpreting and Improving Large Language Models in Arithmetic Calculation. _arXiv preprint arXiv:2409.01659_ (2024).
* Zhang et al. (2024) Yang Zhang, Keqin Bao, Ming Yan, Wenjie Wang, Fuli Feng, and Xiangnan He. 2024. Text-like Encoding of Collaborative Information in Large Language Models for Recommendation. _arXiv preprint arXiv:2406.03210_ (2024).
* Zhao et al. (2016) Qian Zhao, Shao Chang, F Maxwell Harper, and Joseph A Konstan. 2016. Gaze prediction for recommender systems. In _Proceedings of the 10th ACM Conference on Recommender Systems_. 131-138.
* Zhao et al. (2024) Yuyue Zhao, Jianwen Wu, Xiang Wang, Wei Yang, Dingxian Wang, and Maarten de Bijie. 2024. Let Me Du for You: Towards L1M Empowered Recommendation via Total Learning. In _Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval_. 1796-1806.
* Zhu et al. (2023) Xiqian Zhu, Yunta Du, Yuwen Mao, Li Chen, Yujia Hu, and Tunjun Gao. 2023. Knowledge-refined Denoising Network for Robust Recommendation. In _Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval_. 362-371.

## Appendix A Case Study

### More Implementation Details

#### Dataset Details

We conduct experiments on three benchmark datasets: Steam, Yelp, and Amazon-Book. Following the methods of [17, 33], we apply k-core filtering and divide each dataset into training, validation, and testing sets with a 3:1:1 ratio. Additionally, we remove interactions with ratings below 3, except for the Steam dataset, which does not include rating information and is therefore unfiltered. We provide the statistics of experimental datasets in Table 3

#### Evaluation Metrics

To ensure a fair evaluation and minimize bias, we adopt the all-rank protocol, considering all non-interacted items as candidates. We assess performance using Recall@\(N\) and NDCG@\(N\), reporting average values for \(N=10\) and \(N=20\).

#### Baselines and Backbone Models

We conduct experiments using two backbone models.

* **GMF**[26] decomposes the interaction matrix into implicit vectors and computes their element-wise product to capture features.
* **LightGCN**[17] is a widely adopted graph-based recommendation model. To demonstrate the effectiveness of our proposed method, we perform a fair comparison against traditional denoising techniques and state-of-the-art baselines.

Our baseline methods include instance-level denoising methods and representation-level denoising methods.

**Instance-level Denoising.**

* **WBPR**[11] is a sampling-based denoising method that assumes a negative item should be both highly popular and non-interacted.
* **T-CE**[41] is a re-weighting based method with truncated loss and dynamic thresholds during training.
* **R-CE**[41] is a re-weighting based method with reweighted loss and dynamic thresholds during training.
* **DeCA**[44] is a re-weighting based method addressing prediction disagreements of noisy interactions across models.

\begin{table}
\begin{tabular}{l c c c} \hline \hline Statistics & Amazon-Book & Steam & Yelp \\ \hline \# Users & 11,000 & 23,310 & 11,091 \\ \# Items & 9,332 & 5,237 & 11,010 \\ \# Interactions & 120,464 & 316,190 & 166,620 \\ \# Density & 1.2e-3 & 2.6e-4 & 1.4e-4 \\ \hline \hline \end{tabular}
\end{table}
Table 3. Statistics of experimental datasets.

Figure 5. The CoT reasoning case of LLaRD.

* **SGDL**(Kumar et al., 2018) collects clean interactions at training onset, using similarity as a distinguishing criterion.
* **BOD**(Kumar et al., 2018) models denoising as a bi-level optimization problem, extracting prior data information to generate weights.
* **DCF**(Kumar et al., 2018) designs correction strategies for sample dropping and progressive labeling for precise denoising.

**Representation-level Denoising.**

* **SGL**(Kumar et al., 2018) is a self-supervised framework performing graph contrastive learning with multiple views for robust representations.
* **SimGCL**(Kumar et al., 2018) is a self-supervised framework adding uniform noise to embeddings to create contrasting views.
* **RLMRee**(Kumar et al., 2018) utilizes LLMs to capture the complex user behavior semantics, enhancing recommendations through contrastive and generative techniques.

### Hyper-parameter Settings.

To ensure a fair comparison with the baselines, the dimension of representations and MLP is set to 64, and the GNN layer is set to 3, for all base models. The temperature value of contrastive learning from the range of 0.1,..., 0.5. The temperature value of gumbel-max is 0.0001, and the hidden dim of attention is set to 64. During training, all methods are trained with a fixed batch size of 1024.We train all models using the learning rate 1e-3 with Adam optimizer without weight decay. We adopt the early stop technique based on the model's performance on the validation set. To generate the preference knowledge and relation knowledge, we leverage the Qwen model (specifically, qwen-long). For other parameters, we mainly use the official setting from the original paper and open-source code for fair comparisons. To allow for reproducibility, we also provide an anonymous code link of our work: [https://anonymous.4open.science/r/LLaRD-5EE5](https://anonymous.4open.science/r/LLaRD-5EE5).