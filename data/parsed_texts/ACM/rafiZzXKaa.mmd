[MISSING_PAGE_FAIL:1]

such methods have great limitations and will drop their performance under open-world assumptions. These CDSR approaches still rely heavily on overlapping users, with more than 70% of users being common across domains, to establish bridge connections among multiple domains and perform knowledge aggregation and transition processes.

The second challenge arises from an observation in open-world scenarios: Recommender systems frequently engage primarily with active users. In the training phase, some unexposed users who are not exposed to the platform, and thus unbeknownst to the models, may surface in the testing stage. This issue causes a performance drop after adapting from an offline to an online environment [30, 31, 46]. So, the second challenge _is how to alleviate the selection bias of the model in the environment with the data distribution shift?_ CaseQ [46] learns context-specific representations of sequences to capture temporal patterns in various environments. Similarly, DCRec [47] proposes a novel debiasing contrastive learning paradigm to address the popularity bias issue in single-domain recommendation systems. However, these methods overlook the selection bias among the domains that exists in open-world scenarios, leading to biased performance estimation. To address this selection bias, [21] proposes an Inverse-Propensity-Score (IPS) estimator, yet often suffering high variance.

In this paper, we first rethink cross-domain sequential recommendation under open-world assumptions and identify the primary challenges. To address these challenges, we propose an adaptive multi-interest debiasing framework for CDSR, which includes a multi-interest information module and a doubly robust estimator.

**Our contributions are as follows.**

**1)** To our best knowledge, this paper is the first effort addressing the open-world challenges in CSDR. We conduct empirical analysis and show that extending existing CDSR models to the open-world environment yields two primary challenges that used to be overlooked: i) How to construct a model in scenarios where the majority of users are non-overlapping, without relying on overlapping users? and ii) How to eliminate selection bias of the model with the data distribution shift?

**2)** We design an **A**daptive **M**ulti-**I**nterest **D**ebiasing framework for cross-domain sequential recommendation (**AMID**), which could be integrated with most off-the-shelf SDSR methods [12, 38, 17]. It is composed of a multi-interest information module (**MIM**) and a doubly robust estimator (**DRE**). MIM transfers cross-domain information for both overlapping and non-overlapping users, while DRE eliminates selection bias and popularity bias to obtain unbiased performance estimation. Moreover, we provide a theoretical analysis that demonstrates the superiority of DRE in terms of bias and tail bound, compared to the IPS estimator used in [21].

**3)** In order to foster further research in the community, particularly under open-world assumptions, we gathered a real-world financial CDSR dataset from Alipay, called "**MYbank**-**CDR**". As far as we are aware, "MYbank-CDR' is the first publicly available cross-domain financial dataset. The collected dataset "MYbank-CDR' and the source code will be made publicly available upon acceptance.

**4)** We demonstrate that our proposed **AMID**, when integrated with multiple single-domain sequential recommendation models, achieves state-of-the-art results compared to CDR, CDSR and debiasing methods. Additionally, we conduct online experiments to validate the performance of our proposed framework in a real-world CDSR financial platform with millions of daily traffic logs.

## 2. Motivation: Towards Open-World

### CDR

Current CDSR methods conduct their experiments under closed-world assumptions which assume that there exist fully or mostly overlapping users across domains. However, in real-world applications, the number of overlapping users across domains is typically a minority. To validate their performance in the open-world environment, we perform motivational experiments on the Amazon dataset with three single-domain sequential recommendation methods (BERT4Rec [38], GRU4Rec [12] and SASRec [17]) and three cross-domain sequential recommendation methods (Pi-Net [27], DASL [19] and C\({}^{2}\)DSR [2]). Following previous works [45, 24], we vary the overlapping ratio 1 to simulate different CDSR scenarios. We present a plot of the performance of the models from two domains in Fig. 2. In the Movie domain, SASRec (SDSB) achieves the best performance. Similarly, in the Music domain with a 100% overlapping ratio, SASRec (SDSR) outperforms DASL (CDSR). This is attributed to the fact that existing CDSR methods rely on overlapping users to construct their models or transfer information across domains, which leads to a decrease in performance in a partially

Figure 2. Solid lines denote the SDSR methods, while dashed lines denote the CDSR methods. Due to the lack of abundant overlapping users, SASRec (SDSR) outperforms all the CDSR methods in the Movie domain.

overlapping scenario. Hence, this finding serves as a motivating factor for us to design a high-performing CDSR model that can be applied in the open-world environment (_1st challenge_). Furthermore, a counterintuitive phenomenon has been observed, where SDSR methods exhibit a lesser reliance on overlapping users compared to CDSR methods. In an ideal scenario, SDSR methods should exhibit inferior performance compared to CDSR methods when the overlapping user ratio is high. However, experimental results have revealed that the performance gap actually diminishes as the ratio decreases. Surprisingly, when the ratio is small, the performance of a few SDSR methods outperforms CDSR methods, and in some cases, even when the ratio is high.

To analyze the underlying cause for this phenomenon, we try to visualize the distribution shift between the train set and the test set. Figure 6 displays the t-SNE visualization of user embeddings 2 for the train set (blue dots) and the test set (green dots). Training with a 25% proportion simulates the situation where the training data in a real-world scenario may suffer from unseen factors. We observed that the distribution difference at 25% proportion is larger than that at 100% proportion. These visualization results confirm that the distribution shift from training to testing indeed exists in the CDSR scenarios. The distribution shift often occurs in a real-world platform under open-world assumptions. In real-world recommendation systems, users to be exposed are sometimes selected by the recommendation algorithm based on factors such as estimated conversion rates and business rules. During training, only the data of these exposed users are used because their interaction labels are considered meaningful, while the unexposed users are overlooked. However, during the inference stage, estimated conversion scores are required for all users, including the unexposed ones, in order to determine the selection of users to be exposed in the recommendation system. The rating data of these unexposed users are missing not at random (Brocker et al., 2017), leading to selection bias in the CDSR scenario. Therefore, this raises another question: "How can we mitigate data selection bias across multiple domains in the open-world environment?" (_2nd challenge_)

Footnote 2: The trained DASL (Liang et al., 2019) model is used to generate user embeddings.

## 3. Preliminaries

### Problem Definition

In this paper, we consider a partially overlapping CDSR scenario composed of multiple domains \(\mathcal{Z}=\{z_{1},...,z_{|\mathcal{Z}|}\}\). Let \(\mathcal{U}=\{u_{1},...,u_{|\mathcal{U}|}\}\), \(\mathcal{V}=\{v_{1}^{Z_{1}},...,v_{|\mathcal{V}|}^{Z_{2}}\}\) be the user set, item set, rating set. A user who only has historical behaviors in one domain is referred to as a non-overlapping user, while a user with historical behaviors in multiple domains is referred to as an overlapping user. As a certain user, denote \(\mathcal{S}=\{S^{Z_{1}},...,S^{Z_{|\mathcal{Z}|}}\}\) the corresponding sequential behaviours of the users. For example, \(S^{Z_{1}}=\{v_{1},...,v_{T}\}\) represents the single-domain sequence, where \(T\) is a variable length. Given the data \(\mathcal{D}=\mathcal{U}\times\mathcal{V}\), CDSR aims to develop a personalized ranking function that utilizes the past item sequences from multiple domains of a user and predicts the next item (i.e. \(v_{T+1}\)) in each domain that the user is most likely to choose.

Different from conventional cross-domain recommendation (CDR), CDSR methods pay more attention to modeling sequential behavior dependencies. Mathematically, the objective of CDR methods are formulated as follows:

\[\text{argmax}\;\;P^{X}\left(r_{u,v}^{X}=v|U^{X},U^{Y},V^{X}\right),\text{if}\; \;v\in\mathcal{V}^{X}. \tag{1}\]

where \(r_{u,v}\) denotes the prediction from user \(u\) to item \(v\) in domain \(X\). However, the objective of CDSR approaches is to predict the next item for a given user \(u\) based on their interaction sequences:

\[\text{argmax}\;\;P^{X}\left(r_{|S^{X}|_{+1}}^{X}=v|S^{X},S^{Y},U^{X},U^{Y},V^{ X}\right),\text{if}\;\;v\in\mathcal{V}^{X}. \tag{2}\]

### Causal Graph

To tackle the issue of incomplete and insufficient observed information, we construct a causal view and propose an adaptive multi-interest debiasing framework. \(\mathcal{S}_{U}^{Z}\), \(\mathcal{R}_{U}^{Z}\), \(SC^{Z}\), and \(GC\) denote the random variables of the historical event sequence, the observed ratings, the domain-specific confounder, and the general confounder. \(O\), which represents the observed variable of the instance (\(O=1\), observed; \(O=0\), unobserved), is decided by \(O^{Z_{1}}\) and \(O^{Z_{2}}\) commonly. If a user is not observed in either of the two domains, \(O\) is 0; otherwise, it is 1. The SDSR methods focus on learning the specified confounder \(SC^{Z}\) for a given user, while the previous CDSR approaches construct models based on overlapping users to obtain the general confounder \(GC\). The links between \((SC^{Z}\), \(GC)\rightarrow\mathcal{R}_{U}^{Z}\) represent the causal effect of the domain-specific and general confounders on their interaction label. In observational studies (Kang et al., 2019; Wang et al., 2019; Wang et al., 2019), the collected rating data is often unevenly presented, and the variables \(\mathcal{S}_{U}^{Z}\) and \(\mathcal{R}_{U}^{Z}\) can affect the observation \(O\) of a given instance. This mechanism gives rise to selection bias, resulting in an inconsistent

Figure 3. Selection bias can cause a distribution shift in the cross-domain sequential scenario with few overlapping users (control ratio is 25%).

distribution of the observed rating data as compared to the ideal test distribution.

From another perspective, the causal graph depicts two sources of association between the causes \(S\) and the outcome \(R\): (1) the desirable causal effect \(S\rightarrow(SC,GC)\to R\): (2) the collision path \(S\rightarrow O\gets R\) that connects \(S\) and \(R\) through their common (conditioned on) effects \(O=1\). Analyses conditioned on \(O=1\) may generate spurious associations between \(S\) and \(R\). It is important to note that the domains \(Z_{1}\) and \(Z_{2}\) commonly influence the observed variable. Models learned from observed data may be affected by the issue of selection bias. In the open-world environment, this is a critical issue that must be addressed to prevent a drop in online performance.

### Single-domain Sequential Recommendation Methods

In this research, our primary objective is to develop a universal cross-domain structure that can improve the performance of single-domain sequential recommendation models by seamlessly integrating them into comprehensive CDSR models. To achieve this, we first explore the fundamental mechanisms of the single-domain sequential recommendation network.

**Embedding layer.** We map the fixed-length sequence \(S=\{o_{1},...,o_{T}\}\) to a \(d\)-dimensional embedding space, which is achieved through truncation or padding. Besides, a learnable parameter position embedding matrix is utilized to enhance the chronologically ordered information of the sequence. Specially, we get the sequence embedding \(\mathbf{S}_{u}=\{\mathbf{h}^{\prime}_{o_{1}},...,\mathbf{h}^{\prime}_{o_{T}}\} \in\mathbb{R}^{T\times d}\).

**Sequential information encoder.** In the previous single-domain sequential recommendation methods, they designed various sequential information encoders to extract short-/long-term item relationships among the sequence. For example, GRU4Rec (He et al., 2016) designs multiple GRU layers for the sequential recommendation. SASRec (Shen et al., 2017) proposes stacking self-attention blocks with residual connections, while BERT4Rec (Wang et al., 2018) develops the deep bidirectional self-attention to model user behavior sequences. For convenience, we obtain the enhanced sequential embedding via a function \(\mathcal{F}\) which represents their designed sequential information encoder. This process is formulated as \(\mathbf{h}_{o_{1}},...,\mathbf{h}_{o_{T}}=\mathcal{F}(\mathbf{h}^{\prime}_{o_ {1}},...,\mathbf{h}^{\prime}_{o_{T}})\).

## 4. Methodology

### Multi-interest Information Module

In this section, we will introduce our multi-interest information module, which can convert a normal SDSR model into a CDSR model. The module consists of two steps: interest group construction and information propagation. For simplicity, we only include two domains as examples and show the operation on them, but our methods can be applied to multiple domains. Our design is motivated by the goal of creating interest groups by identifying users with similar preferences and sharing information as widely as possible.

**Group construction.** Initially, we compute the group flag by evaluating the similarity between their sequences point-by-point. For instance, consider two sequences \(\mathbf{S}^{Z_{1}}_{u_{i}}\in\mathbb{R}^{T\times d}\) and \(\mathbf{S}^{Z_{2}^{Z}}_{u_{j}}\in\mathbb{R}^{T\times d}\) from users \(u_{i}\) and \(u_{j}\) in different domains. We then determine the group flag among users as follows:

\[\mathbf{a}^{\prime}{}_{ij}=\max\{(\mathbf{S}^{Z_{1}}_{u_{1}}\mathbf{W}_{1})( \mathbf{S}^{Z_{2}^{Z}}_{u_{j}}\mathbf{W}_{2})^{\top}\} \tag{3}\]

where \(\mathbf{W}_{1},\mathbf{W}_{2}\in\mathbb{R}^{d\times d}\) are the transformation matrix. The max function is utilized to find the nearest similarity between user \(u_{i}\) and \(u_{j}\) from \(T\times T\) similarity relations. Last, we get the group flag via the threshold determination where \(\mathbf{a}_{ij}=1\) means the users \(u_{i}\) and \(u_{j}\) are in the same group.

\[\mathbf{a}_{ij}=\left\{\begin{array}{ll}0&,\\ 1&,\\ \end{array}\right.\begin{array}{ll}\mathbf{a}^{\prime}{}_{ij}\leq k\\ \mathbf{a}^{\prime}{}_{ij}\geq k\\ \end{array} \tag{4}\]

**Information propagation.** After constructing the interest groups, the cross-domain information will propagate among the same group. The cross-domain message \(\mathbf{m}_{u_{i}^{Z_{1}}\gets u_{j}^{Z_{2}}}\in\mathbb{R}^{T\times d}\) can be obtained:

\[\mathbf{m}_{u_{i}^{Z_{1}}\gets u_{j}^{Z_{2}}}=\mathbf{a}_{ij}\cdot(S^{Z_ {2}^{Z}}_{u_{j}}\mathbf{W}_{ip}) \tag{5}\]

where \(\mathbf{W}_{ip}\in\mathbb{R}^{d\times d}\) is the trainable parameter to transfer the cross-domain knowledge. When the user has the behaviors in multiple domains, the message from the same user in a different domain (e.g. \(\mathbf{m}_{u_{i}^{Z_{1}}\gets u_{j}^{Z_{2}}}\)) will also be propagated. For the target user (e.g. \(u_{i}^{Z_{2}}\)), we concatenate all the information from other domains along the last dimension to obtain the aggregated message \(\mathbf{m}^{\prime}_{u_{i}^{Z_{1}}}\in\mathbb{R}^{T\times d\times N}\), where \(N\) is the number of the sampled users. We then use transformation matrix \(\mathbf{W}_{C}\in\mathbb{R}^{N\times 1}\) and \(\mathbf{W}_{F}\in\mathbb{R}^{d\times d}\) to fuse the information and get the enhanced sequence representation \(S^{Z_{2}^{Z}}_{u_{i}}\in\mathbb{R}^{2T\times d}\) concatenated with the initial sequence information, where the Squeeze function reduces the dimension of the matrix. For users in other domains, information propagation occurs in a similar manner.

\[S^{\mathbf{a}Z}_{u_{i}}=\text{Concat}(S^{Z}_{u_{i}},\text{Squeeze}(\mathbf{m}^ {\prime}{}_{u_{i}^{Z}}\mathbf{W}_{C}))\mathbf{W}_{F} \tag{6}\]

### Prediction Layer

We construct a prediction layer to estimate the user's \(u_{i}\) preference towards the target item \(u_{k}\) as:

\[\hat{\mathbf{\mu}}^{Z}_{u_{i},\text{RE}}=\sigma(\text{MLPs}(\text{Mean}(S^{Z}_{ u_{i}})||\mathbf{\nu}^{Z}_{k})) \tag{7}\]

where MLPs consist of stacked MLP layers that take as input the concatenation of enhanced sequence embedding and item embedding. The sigmoid function is denoted by \(\sigma\), and the Mean function averages the embedding along the temporal dimension.

### Doubly Robust Estimator for CDSR

In this part, we propose a novel doubly robust estimator, which generalizes the traditional DR estimator (Wang et al., 2018) to the cross-domain sequential scenarios. Suppose \(\hat{\mathbf{R}}^{Z}\in\mathbb{R}^{T\times V^{Z}}\) be a prediction matrix and \(\mathbf{R}^{Z}\in\mathbb{R}^{T\times V^{Z}}\) be a true rating matrix, the prediction inaccuracy \(\mathcal{P}\) and the doubly robust estimator \(\mathcal{E}^{*}_{\text{DR}}\) are defined as:

\[\mathcal{P}=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}}\frac{1}{|\mathcal{D} ^{2}|}\sum_{u,u\in\mathcal{D}^{Z}}e^{Z}_{u,\sigma}. \tag{8}\]

\[\mathcal{E}^{*}_{\text{DR}}=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}} \frac{1}{|\mathcal{D}^{2}|}\sum_{u,u\in\mathcal{D}^{Z}}\left(\hat{\mathbf{\mu} }^{Z}_{u,\sigma}+\frac{\sigma^{Z}_{u,\sigma}\hat{\mathbf{\mu}}^{Z}_{u,\sigma} }{\hat{\mathbf{\mu}}^{Z}_{u,\sigma}}\right). \tag{9}\]where \(\varepsilon^{Z}_{u,\mathbf{v}}=|\mathbf{\tilde{r}}^{Z}_{u,\mathbf{v}}-\mathbf{ \tilde{r}}^{Z}_{u,\mathbf{v}}|\) or \(\varepsilon^{Z}_{u,\mathbf{v}}=(\mathbf{\tilde{r}}^{Z}_{u,\mathbf{v}}-\mathbf{ \tilde{r}}^{Z}_{u,\mathbf{v}})^{2}\) via optional measure metrics for MAE or MSE. The imputation error \(\varepsilon^{Z}_{u,\mathbf{v}}=g_{\phi^{Z}}(\text{Mean}(\mathbf{S}^{Z}_{u})|| \mathbf{y}^{Z}))\) is computed by imputation model which aims to estimate the prediction error \(\varepsilon_{u,\mathbf{v}}\) on the observed data. We also learn the propensity \(\tilde{p}_{u,\mathbf{v}}=g_{\phi^{Z}}(\text{Mean}(\mathbf{S}^{*Z}_{u})|| \mathbf{y}^{Z})\). The imputation model \(g_{\phi^{Z}}\) and the propensity model \(g_{\phi^{Z}}\) are implemented in a multi-task manner. The bias of the estimator is derived as follows.

**Lemma 4.1 (Bias of DR Estimator)**. Given imputation errors \(\hat{\mathbf{E}}^{Z}\) and learned propensities \(\hat{\mathbf{P}}^{Z}\) for all user-item pairs, the bias of the DR estimator in the CDSR task is

\[\text{Bias}(\mathcal{E}^{*}_{DR})=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z }}\left[\frac{1}{|\mathcal{D}^{Z}|}\left|\sum_{u,\mathbf{v}\in\mathcal{D}^{Z} }\Delta^{Z}_{u,\mathbf{v}}\delta^{Z}_{u,\mathbf{v}}\right|\right] \tag{10}\]

where the imputation error \(\delta^{Z}_{u,\mathbf{v}}\) and the learned propensities \(\Delta^{Z}_{u,\mathbf{v}}\) is defined as:

\[\Delta^{Z}_{u,\mathbf{v}}=\frac{\tilde{p}^{Z}_{u,\mathbf{v}}-\mathbf{\tilde{r }}^{Z}_{u,\mathbf{v}}}{\tilde{p}^{Z}_{u,\mathbf{v}}},\ \ \delta^{Z}_{u, \mathbf{v}}=\varepsilon^{Z}_{u,\mathbf{v}}-\varepsilon^{Z}_{u,\mathbf{v}} \tag{11}\]

**Corollary 4.1 (Double Robustness)**. The DR estimator for CDSR is unbiased when either imputed errors \(\hat{\mathbf{E}}^{Z}\) or learned propensities \(\hat{\mathbf{P}}^{Z}\) are accurate for all user-item pairs.

**Lemma 4.2 (Tail Bound of DR Estimator)**. Given imputation errors \(\hat{\mathbf{E}}^{Z}\) and learned propensities \(\hat{\mathbf{P}}^{Z}\), for any prediction matrix \(\hat{\mathbf{R}}^{Z}\), with probability 1-\(\eta\), the deviation of the DR estimator from its expectation has the following tail bound in CDSR task.

\[|\mathcal{E}^{*}_{DR}-\mathbb{E}_{0}|\mathcal{E}^{*}_{DR}||\leq\sqrt{\frac{ \log(\frac{2}{\eta})}{2|\mathcal{Z}|(\sum_{Z\in\mathcal{Z}}|\mathcal{D}^{Z}|)^ {2}}\sum_{Z\in\mathcal{Z}}\left[\frac{1}{|\mathcal{D}^{Z}|}\sum_{u,\mathbf{v} \in\mathcal{D}^{Z}}\left(\frac{\delta^{Z}_{u,\mathbf{v}}}{\tilde{p}^{Z}_{u, \mathbf{v}}}\right)^{2}\right]} \tag{12}\]

**Corollary 4.2 (Tail Bound Comparison)**. Suppose imputed errors \(\hat{\mathbf{E}}^{Z}\) are such that \(0\leq\tilde{\varepsilon}^{Z}_{u,\mathbf{v}}\leq 2\varepsilon^{Z}_{u,\mathbf{v}}\) for each \(u,\mathbf{v}\in\mathcal{D}^{Z}\), then for any learned propensities \(\mathbf{P}\), the tail bound of the proposed estimator will be lower than that of the IPS estimator which is utilized in IPSCDR (Tail and Dornings, 2014). The proof of the lemmas and the corollaries are demonstrated in Appendix A.

### Joint learning

We apply an alternating training for joint learning. In the first step, we train the imputation and prediction models on the observed data by minimizing the proposed hybrid loss in the first step.

(13) \[\mathcal{L}_{e}(\theta,\phi,\psi)= \frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}}\left(\frac{1}{| \mathcal{O}^{Z}|}\sum_{u,\mathbf{v}\in\mathcal{O}^{Z}}\mathbf{e}_{u,\mathbf{v} }+\lambda_{1}\sum_{u,\mathbf{v}\in\mathcal{O}^{Z}}\frac{(\hat{e}_{u,\mathbf{v} }-\hat{e}_{u,\mathbf{v}})^{2}}{\hat{p}_{u,\mathbf{v}}}\right)\] \[+\lambda_{2}||\theta||_{F}^{

[MISSING_PAGE_FAIL:6]

### Performance Comparisons

**Compared Methods.** We compare our method with three classes of baselines: (1) Single-domain sequential recommendation methods, i.e., BERT4Rec (Devlin et al., 2019), GRU4Rec (He et al., 2016) and SASRec (He et al., 2016). (2) Conventional Cross-domain recommendation methods, i.e., STAR (Wang et al., 2019), MAMDR (He et al., 2016), SSCDR (He et al., 2016). (3) Cross-domain sequential recommendation methods, i.e., Pi-Net (Wang et al., 2019), DASL (He et al., 2016) and C\({}^{2}\)DSR (He et al., 2016). (4) Debiased recommendation methods, i.e., DCRec (Wang et al., 2019), CaseQ (He et al., 2016) and IPSCDR (He et al., 2016). A detailed introduction to these baselines can be found in Appendix C.2. As shown in Table 4, our AMID is the most versatile and universal approach which considers propagating cross-domain knowledge for both overlapping users and non-overlapping users and can combine with most off-the-shelf SDSR backbone models. Regarding the debiasing frameworks (He et al., 2016; Wang et al., 2019), our AMID approach can simultaneously alleviate multiple types of bias, especially selection bias, from multiple domains. Additionally, our proposed doubly robust estimator for CDSR has a low variance, which is different from the IPS estimator from IPSCDR (He et al., 2016) with high variance (He et al., 2016).

**Quantitative Results.** Tables 1-2 present the quantitative comparison results on two CDSR tasks with different selection bias magnitudes. A larger \(\mathcal{K}_{u}\) indicates a less biased scenario. The best results of each column are highlighted in boldface, while the second-best results are underlined. As expected, the performance of all models increases with increasing \(\mathcal{K}_{u}\), since more biased scenarios may make it harder for models to converge. Our analysis yields the following insightful findings: (1) In most cases, the debiasing baselines, which eliminate the biases produced in domains, perform better than the CDSR baselines in more biased scenarios (i.e. \(\mathcal{K}_{u}=25\%\)). (2) In a more biased scenario with smaller \(\mathcal{K}_{u}\), our framework achieves more significant performance compared to the second-best models, indicating that our AMID effectively alleviates the bias. (3) Benefiting from the low variance in our estimator, our AMID is more unbiased and performs better than IPSCDR.

**Model Efficiency.** All comparative models are trained and tested on the same machine, which has a single NVIDIA GeForce A100 with 80GB memory and an Intel Core i7-8700K CPU with 646 RAM. Notably, the number of parameters for typical C\({}^{2}\)DSR, SASRec + CaseQ, SASRec + IPSCDR, and SASRec + AMID were of the same order of magnitude, denoted as 0.276M, 0.210M, 0.192M, and 0.193M. The training/testing efficiencies of C\({}^{2}\)DSR, SASRec + CaseQ, SASRec + HSCDR, and SASRec + AMID in processing one batch of samples are 0.130s/0.049s, 0.083s/0.027s, 0.143s/0.045s, and 0.111s/0.032s, respectively. Therefore, our AMID achieves superior performance enhancements in open-world CDSR scenarios while maintaining promising time efficiency.

**Ablation Study.** To better evaluate the effectiveness of each key component in our approach, we conducted an ablation study by comparing it with a variant that only utilized MIM. Notably, we did not include a variant that only employed DRE, as our approach would degrade into an SDSR method in the absence of MIM. However, our variant equipped with only the multi-interest information module (MIM) still achieves state-of-the-art results in most cases. This is because our proposed module can effectively propagate potential interest information among both overlapping and non-overlapping users.

### Online A/B Test

We conduct large-scale online A/B tests on open-world financial CDSR scenarios with partially overlapping users. In the online serving platform, a large number of users participate in one or multiple financial domains, such as purchasing funds, mortgage loans, or discounting bills. Specifically, we selected three popular domains - "Loan," Fund," and "Account" - from the serving platform, with partially overlapping users, as the targets of our online testing. We calculate the average statistics of online traffic logs for one day and present them in Table 5. For the control group, we adopt the current online solution for recommending themes to users, which is a cross-domain sequential recommendation method that utilizes noisy auxiliary behaviors directly. For the experiment group, we setup our method with a mature SDSR approach that has achieved remarkable success in the business. We evaluate the results based on three metrics: the number of users who have been exposed to the service, the number of users who have clicked inside the service, and the conversion rate of the service (denoted by \(\bar{\pi}\) exposure, \(\bar{\pi}\) click, and CVR, respectively). All of the results are reported as the lift compared to the control group and presented in Table 6. In a (78) fourteen-day online A/B test, our method improved the average exposure by 9.65%, the click rate by 5.69%, and the CVR by 1.32% in the three domains.

larger threshold \(k\) (\(0.5\to 0.7\)) leads to better performance, as more related interest information can be transferred. However, when the threshold \(k\) is increased beyond 0.7, the model's performance drops due to noise interference and redundant information. Therefore, to achieve superior performance, we set the threshold \(k\) to 0.7.

**The number of the sampled users.** To explore the impact of the number of sampled users on the multi-interest information module, we conduct ablation experiments varying the number of sampled users from 128 to 1024. Our findings suggest that an increase in the number of sampled users initially improves the recommendation performance, but it eventually declines when the matching neighbors reach 1024. This observation indicates that having too few sampled users would provide insufficient transferred information, while too many sampled users could introduce interference noise and compromise the model's performance. In practice, we select the number of sampled users to be \(512\) as it results in the best performance for our model. More analysis and results can be found in Appendix C.3.

## 6. Related Work

**Conventional cross-domain recommendation** has emerged as a promising solution for mitigating data sparsity and cold-start issues encountered in single-domain recommendation systems. Early CDR studies (Garfinkel et al., 2014; Li et al., 2015) have primarily focused on developing approaches that transfer cross-domain knowledge by relying on overlapping users. However, real-world CDR scenarios often do not satisfy strict overlapping requirements and exhibit only a small fraction of common users across domains. To tackle this challenge, recent methods (Zhou et al., 2017; Li et al., 2015) have proposed a network structure comprising shared and domain-specific networks to effectively capture the unique characteristics and commonalities across all domains simultaneously. While these CDR approaches incorporate valuable information from relevant domains to enhance performance in the target domain, they still encounter difficulties in addressing the contextual sequential dependencies within users' interaction history, which are essential for comprehensive modeling in CDSR tasks.

**Cross-domain sequential recommendation** is designed to improve recommendations for SR tasks that involve items from multiple domains. Pi-Net (Zhu et al., 2017) and PSJNet (Zhu et al., 2018) devise the gating mechanisms to transfer the information among the overlapping users. Similarly, DASL (Liang et al., 2018) designs a dual-attention mechanism to bidirectionally transfer user preferences within the overlapping users. The interaction bipartite graph (Chen et al., 2018; Li et al., 2015) is constructed to propagate the information among users. C\({}^{2}\)DSR (Chen et al., 2018) introduces a contrastive objective combined with GNNs to enhance the representation of user preferences. However, these works construct their cross-domain unit relying on the overlapping users under closed-world assumptions, leading to worse performance in the open-world case.

**Debias for recommender systems** are proposed to alleviate the widespread bias in the user behavior observed data, including the selection bias (Chen et al., 2018; Li et al., 2015), position bias (Garfinkel et al., 2014; Li et al., 2015), exposure bias (Li et al., 2015; Li et al., 2015) and popularity bias (Garfinkel et al., 2014; Li et al., 2015). To address selection bias in RS, two standard approaches have been proposed: the error-imputation-based (EIB) approach and the inverse-propenity-scoring (IPS) approach. The EIB approach (Zhu et al., 2018) estimates the prediction error for missing ratings, while the IPS approach (Zhu et al., 2018; Li et al., 2015) reduces selection bias by optimizing the risk function with the inverse propensity score. Recently, (Li et al., 2015) proposes an IPS estimator for cross-domain scenarios with multiple restrictions. However, EIB methods may have a large bias due to imputation inaccuracy (Chen et al., 2018), and propensity-based methods may suffer from high variance (Zhu et al., 2018), leading to non-optimal results. (Zhu et al., 2018) propose a self-normalized inverse propensity scoring estimator to reduce the variance of the IPS estimator. To design a less biased estimator, the doubly robust model (Zhu et al., 2018) integrates the imputation model with the propensity score for the single-domain recommendation.

## 7. Conclusions and Discussions

In this paper, we conduct a thorough study of existing CDSR methods under open-world assumptions. To overcome the challenges, we devise an adaptive multi-interest dephasing framework that includes a multi-interest information module (MIM) and a doubly robust estimator (DRE) for CDSR. MIM utilizes the user behaviors to build the interest groups and propagate the information among both overlapping and non-overlapping users, while DRE introduces a cross-domain debiasing estimator to reduce the estimation bias in an open-world environment. Besides, we collect a financial industry dataset from Alipay, which includes over one billion users. Extensive offline and online experiments show the remarkable efficacy of our approach, as it outperforms existing methods including CDSR methods and debiasing methods in various evaluation metrics.

**Limitations.** Our MIM constructs interest groups between pairs of domains, which share cross-domain knowledge as widely as possible. In the real-world platform, commercial activities are usually composed of multiple domains. However, constructing all the groups for \(|\mathcal{Z}|\) domains has a time complexity of \(\mathcal{O}(|\mathcal{Z}|^{2})\), which can become quite time-consuming as the number of domains increases. Therefore, it is important to develop more efficient methods for constructing groups among multiple domains in future work.

Figure 6. Impact of the threshold \(k\) and the number of the sampled users.

## References

* (1)
* Abdollahgouri et al. (2017) Himan Abdollahgouri, Robin Burke, and Bamshad Mobasher. 2017. Controlling popularity bias in learning-to-rank recommendation. In _Proceedings of the eleventh ACM conference on recommender systems_. 42-46.
* Cao et al. (2022) Jianqiao Cao, Xin Cao, Jiwei Sheng, Tingwen Li, and Bin Wang. 2022. Contrastive Cross-Domain Sequential Recommendation. In _Proceedings of the 33st ACM International Conference on Information & Knowledge Management_. 138-147.
* Cao et al. (2022) Jiangxia Cao, Jiawei Sheng, Xin Cong, Tingwen Liu, and Bin Wang. 2022. Cross-domain recommendation to cold-start users via variational information bottleneck. In _2022 IEEE 38th International Conference on Data Engineering (ICDE)_. IEEE, 2020-2223.
* Chen et al. (2023) Jiawei Chen, Hanale Dong, Xiang Wang, Fuil Feng, Meng Wang, and Xiangnan He. 2023. Bias and debias in recommender system: A survey and future directions. _ACM Transactions on Information Systems_ 34, 1 (2023), 1-39.
* Chen et al. (2018) Jiawei Chen, Can Wang, Martin Later, Qihua Shi, Yan Peng, and Chun Chen. 2018. Social recommendation with missing net at random data. In _2018 IEEE International Conference on Data Mining (ICDM)_. IEEE, 29-38.
* Cui et al. (2020) Qiang Cui, Tao Wei, Yiefeng Zhang, and Qing Zhang. 2020. HeroGRAPH: A Heterogeneous Graph Framework for Multi-Target Cross-Domain Recommendation. In _IOSR (ICoR)_. _IEEE_.
* Dada et al. (2011) Miklav Dada, John Langford, and Lihong Li. 2011. Doubly robust policy evaluation and learning. _arXiv preprint arXiv:1101.06691_ (2011).
* Glotte et al. (2018) Alexandre Glotte, Clement Calanueres, Thomas Nedelec, Alexandre Abraham, and Simon Dello. 2018. Offline ab testing for recommender systems. In _Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining_. 198-206.
* Guo et al. (2021) Lei Guo, Li Tang, Tong Chen, Lei Zhu, Quoc Viet Hung Nguyen, and Hongzhi Yin. 2021. DA-GCN: A domain-aware attentive graph convolution network for shared-account cross-domain sequential recommendation. _arXiv preprint arXiv:2105.03302_ (2021).
* Heng et al. (2014) Jose Miguel Hernandez-Lobato, Neil Holubly, and Zoubin Ghahramani. 2014. Probabilistic matrix factorization with non-random missing data. In _International conference on machine learning_. PMLR, 1512-1520.
* Hernandez-Lobato et al. (2014) Jose Miguel Hernandez-Lobato, Neil Holubly, and Zoubin Ghahramani. 2014. Probabilistic matrix factorization with non-random missing data. In _International conference on machine learning_.
* Hidasi et al. (2015) Rajas Hidasi, Alexandros Karatzoglou, Lina Baltrunas, and Domonkos Tikk. 2015. Session-based recommendations with recurrent neural networks. _arXiv preprint arXiv:1511.06999_ (2015).
* Hofmann et al. (2013) Katija Hofmann, Anne Schutt, Shimon Whiteson, and Maarten De Rijke. 2013. Reusing historical interaction data for faster online learning to rank for IR. In _Proceedings of the sixth ACM international conference on Web search and data mining_. 183-192.
* Hu et al. (2018) Guangfeng Hu, Yu Zhang, and Qiang Yang. 2018. Conet: Collaborative cross networks for cross-domain recommendation. In _Proceedings of the 27th ACM international conference on information and knowledge management_. 667-676.
* Joachims et al. (2017) Thorsten Joachims, Adith Swaminathan, and Tobias Schnabel. 2017. Unbiased learning-to-rank with biased feedback. In _Proceedings of the tenth ACM international conference on web search and data mining_. 781-789.
* Goodfellow et al. (2016) Geoffrey E. Gordon, K. A. Knap, 2016. Semi-supervised learning for cross-domain recommendation to cold-start users. In _CIKM_.
* Chang and McAuley (2018) Wang Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recommendation. In _2018 IEEE international conference on data mining (ICDM)_. IEEE, 197-206.
* Krichene and Rendle (2020) Waldk Krichene and Steffen Rendle. 2020. On sampled metrics for item recommendation. In _Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining_. 1748-1757.
* Li et al. (2021) Pan Li, Zhichao Jiang, Maofei Qu, Yue Hu, and Alexander Tumblin. 2021. Dual attentive sequential learning for cross-domain click-through rate prediction. In _Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & data mining_. 3172-3180.
* Lu and Tuduilin (2020) Pan Li and Alexander Tuduilin. 2020. Dldcdf: Deep dual transfer cross domain recommendation. In _Proceedings of the 13th International Conference on Web Search and Data Mining_. 331-339.
* Li et al. (2021) Siqing Li, Liyi Yao, Shanhei Xu, Wayne Xin Zhao, Yaliang Li, Tonglei Guo, Bojin Ding, and Ji-feng Wen. 2021. Debiasing learning based cross-domain recommendation. In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_. 3190-3199.
* Liu et al. (2020) Duguang Liu, Pengxiang Cheng, Zhenhua Dong, Xunqing He, Weike Pan, and Zhong Ming. 2020. A general knowledge distillation framework for counterfactual recommendation via uniform data. In _Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval_. 831-840.
* Liu et al. (2020) Meng Liu, Jianjun Li, Gaohui Li, and Peng Pan. 2020. Cross domain recommendation via bi-directional transfer graph collaborative filtering networks. In _Proceedings of the 29th ACM international conference on information & knowledge management_. 885-894.
* Liu et al. (2022) Weiming Liu, Xiaolin Zheng, Jiuie Su, Mengling Hu, Yanchao Tan, and Chaodao Chen. 2022. Exploiting Variational Domain-Invariant User Embedding for Partially Overplayed Cross Domain Recommendation. In _Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval_. 312-321.
* Lu et al. (2021) Lixhao Lu, Yunming Li, Buyong Gao, Shuai Tang, Shuan Wang, Jianchao Li, Tianchao Zhu, Jiuen Li, Zhao Li, and Shriu Yan. 2023. MAMDR: A Model Agnostic Learning Framework for Multi-Domain Recommendation. In _2023 IEEE 39th International Conference on Data Engineering (ICDE)_. IEEE.
* Ma et al. (2022) Muyong Ma, Pengfei Ren, Zhumin Chen, Zhaochun Ren, Lifan Zhao, Peiyu Liu, Jun Ma, and Maarten de Rijke. 2022. Third information flow for cross-domain sequential recommendation. _ACM Transactions on Knowledge Discovery from Data (TKDD)_ 16, 4 (2021), 1-32.
* Ma et al. (2019) Muyong Ma, Pengfei Ren, Yijie Liu, Zimmin Chen, Jun Ma, and Maarten de Rijke. 2019. _nst_: nst-a: parallel information-sharing network for shared-account cross-domain sequential recommendations. In _Proceedings of the 42nd international ACM SIGIR conference on research and development in information retrieval_. 685-694.
* Marlin et al. (2012) Benjamin Marlin, Richard S. Zemel, Sam Roweis, and Malcolm Shaoy. 2012. Collaborative filtering and the missing at random assumption. _UM_ (2012).
* Ouyang et al. (2020) Wentao Ouyang, Xiuong Zhang, Lei Zhao, Jinwei Lu, Yu Zhang, Hang Zou, Zhaojie Liu, and Yanping. 2020. Minet: Mixed interest network for cross-domain click-through rate prediction. In _Proceedings of the 2020 ACM international conference on information & knowledge management_. 2669-2676.
* Peska and Voidas (2020) Ladilav Peska and Peter Voidas. 2020. Off-line vs. On-line Evaluation of Recommender Systems in Small-Commerce. In _Proceedings of the 31st ACM Conference on Hypertext and Social Media_. 291-300.
* Roberts et al. (2020) Margaret F. Roberts, Brandon M Stewart, and Richard A. Nielsen. 2020. Adjusting for confounding with text matching. _American Journal of Political Science_ 64, 4 (2020), 887-903.
* Saoto (2003) Yutsa Saoto. 2003. Asymmetric tri-training for debiasing using non-att-random explicit feedback. In _Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval_. 309-318.
* Sato (2020) Yutsa Sato. 2020. Unbiased pairwise learning from biased implicit feedback. In _Proceedings of the 2020 ACM SIGIR on International Conference on Theory of Information Retrieval_.
* Schnabel et al. (2018) Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, and Thorsten Joachims. 2018. Recommendations as treatments: Debiasing learning and evaluation. In _International conference on machine learning_. PMLR, 1670-1679.
* Sheng et al. (2017) Xiang-Rong et al. Sheng. 2021. One model to serve all: Star topology adaptive recommender for multi-domain ctr prediction. In _CIKM_.
* Stedc (2010) Harald Stedc. 2010. Training and testing of recommender systems on data missing at random. In _Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining_. 713-722.
* Stedc (2013) Harald Stedc. 2013. Evaluation of recommendations: rating prediction and ranking. In _Proceedings of the 7th ACM conference on Recommender systems_.
* Sun et al. (2019) Fetsi Sun, Jun Liu, Jian Wu, Changhua Fu, Xiao Liu, Wenyuan Ou, and Feng Jiang. 2019. BERTBee: Sequential recommendation with bidirectional encoder representations from transformer. In _Proceedings of the 20th ACM international conference on information and knowledge management_. 1441-1450.
* Sun et al. (2021) Wenchao Sun, Mayang Ma, Pengfei Ren, Yijie Liu, Zhumin Chen, Zhaochun Ren, Jun Ma, and Maarten De Rijke. 2021. Parallel Split-Spin Networks for Shared Account Cross-domain Sequential Recommendations. _IEEE Transactions on Knowledge and Data Engineering_ (2021).
* Swaminathan and Joachims (2015) Ashith Swaminathan and Thorsten Joachims. 2015. The self-normalized estimator for counterfactual learning. _advance in neural information processing systems_ 28 (2015).
* Vershynin (2018) Roman Vershynin. 2018. _High-dimensional probability: An introduction with applications in data science_. Vol. 4, Cambridge university press.
* Wang et al. (2019) Xiaojie Wang, Rui Zhang, Ye Sun, and Jianming Q. 2019. Doubly robust joint learning for recommendation on data missing not at random. In _International Conference on Machine Learning_. PMLR, 683-684.
* Wang et al. (2021) Xiaojie Wang, Rui Zhang, Yu Sun, and Jianming Q. 2021. Combating selection biases in recommender systems with few unbiased ratings. In _Proceedings of the 14th ACM International Conference on Web Search and Data Mining_. 427-453.
* Wu et al. (2021) Qifian Wu, Hengxin Zhang, Xiaofeng Gao, Junli Tai, and Hongyuan Zha. 2021. Towards open-world recommendation: An inductive model-based collaborative filtering approach. In _International Conference on Machine Learning_. PMLR, 1329-1339.
* Xu et al. (2023) Weiyang Xu, Shaohui Li, Mingming Ha, Xiaobo Guo, Qiongxin Ma, Xiaolei Liu, Liuxun Chen, and Zhenfeng Zhu. 2023. Neural Node Matching for Multi-Target Cross Domain Recommendation. _arXiv preprint arXiv:23102.69799_ (2023).
* Yang et al. (2022) Cheravica Yang, Qifian Wu, Qingcong Wen, Zhiqiang Zhou, Liang Sun, and Junchi Yan. 2022. Towards out-of-distribution sequential event prediction: A causal treatment. _arXiv preprint arXiv:22110.1305_ (2022).

* Yang et al. (2025) Yuhao Yang, Chao Huang, Lianghao Xia, Chunzhen Huang, Da Luo, and Kangyi Lin. 2025. Debiased Contrastive Learning for Sequential Recommendation. In _The Web Conference 2025: International World Wide Web Conference_.
* Yue et al. (2020) Kun Yue, Jiahui Wang, Xinlai Li, and Kuang Hu. 2020. Representation-based completion of knowledge graph with open-world data. In _2020 36 International Conference on Computer and Communication Systems (ICCCS)_. IEEE, 1-8.
* Zhang et al. (2018) Qian Zhang, Dianshuang Wu, Jie Lu, and Gangquan Zhang. 2018. Cross-domain recommendation with probabilistic knowledge transfer. In _International Conference on Neural Information Processing_. Springer, 208-219.
* Zhao et al. (2017) Li Li Zhao, Simon Jialin Pan, and Qiang Yang. 2017. A unified framework of active transfer learning for cross-agent recommendation. _Artificial Intelligence_ 245 (2017), 38-55.
* Zhao et al. (2020) Wayne Xin Zhao, Junhua Chen, Pengfei Wang, Qi Gu, and Ji-Rong Wen. 2020. Revisiting alternative experimental settings for evaluating top-in item recommendation algorithms. In _Proceedings of the 29th ACM International Conference on Information & Knowledge Management_. 2329-2332.
* Zhu et al. (2020) Feng Zhu, Yan Wang, Chaochao Chen, Guangfeng Liu, Mehmet Orgun, and Jua Wu. 2020. A deep framework for cross-domain and cross-system recommendations. _arXiv preprint arXiv:2009.06215_ (2020).

## Appendix A Appendix A: Proofs of Lemmas and Theorems

**Lemma 4.1** (Bias of DR Estimator).: Given imputation errors \(\hat{\mathbb{E}}^{Z}\) and learned propensities \(\hat{\mathbb{P}}^{Z}\) for all user-item pairs, the bias of the DR estimator in the CDSR task is

\[\text{Bias}(\mathcal{E}^{*}_{DR})=\frac{1}{|\mathcal{Z}|}\sum_{Z \in\mathcal{Z}}\left[\frac{1}{|\mathcal{D}^{Z}|}\Bigg{|}\sum_{u,u\in D^{Z}} \Delta^{Z}_{u,v}\delta^{Z}_{u,v}\Bigg{|}\right] \tag{17}\]

Proof.: According to the definition of the bias, we can derive the bias of the DR estimator for CDSR as follows.

\[\text{Bias}(\mathcal{E}^{*}_{DR}) \tag{18}\] \[=|\mathcal{P}-\mathbb{E}_{0}[\mathcal{E}^{*}_{DR}]|_{i}\] (19) \[=\Bigg{|}\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}}\left[ \frac{1}{|\mathcal{D}^{Z}|}\sum_{u,v\in\mathcal{D}^{Z}}\left(\varepsilon^{Z}_ {u,v}-\varepsilon^{Z}_{u,v}-\frac{p^{Z}_{u,v}\delta^{Z}_{u,v}}{p^{Z}_{u,v}} \right)\right]\Bigg{|},\] (20) \[=\Bigg{|}\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}}\left[ \frac{1}{|\mathcal{D}^{Z}|}\sum_{u,v\in\mathcal{D}^{Z}}\left(\delta^{Z}_{u,v} -\frac{p^{Z}_{u,v}\delta^{Z}_{u,v}}{p^{Z}_{u,v}}\right)\right]\Bigg{|},\] (21) \[=\Bigg{|}\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}}\left[ \frac{1}{|\mathcal{D}^{Z}|}\sum_{u,v\in\mathcal{D}^{Z}}\left(\frac{(\hat{p}^{Z }_{u,v}-\hat{p}^{Z}_{u,v})\delta^{Z}_{u,v}}{\hat{p}^{Z}_{u,v}}\right)\right] \Bigg{|},\] (22) \[=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}}\left[\frac{1}{| \mathcal{D}^{Z}|}\Bigg{|}\sum_{u,v\in\mathcal{D}^{Z}}\Delta^{Z}_{u,v}\delta^{ Z}_{u,v}\Bigg{|}\Bigg{|}\right], \tag{23}\]

which completes the proof. Following the previous works [36, 42], the imputation error \(\delta^{Z}_{u,v}\) and the learned propensities \(\Delta^{Z}_{u,v}\) is defined as:

\[\delta^{Z}_{u,v}=\varepsilon^{Z}_{u,v}-\delta^{Z}_{u,v},\quad\Delta^{Z}_{u,v}= \frac{\theta^{Z}_{u,v}-p^{Z}_{u,v}}{\hat{p}^{Z}_{u,v}} \tag{25}\]

**Corollary 4.1** (Double Robustness).: The DR estimator for CDSR is unbiased when either imputed errors \(\hat{\mathbb{E}}^{Z}\) or learned propensities \(\hat{\mathbb{P}}^{Z}\) are accurate for all user-item pairs.

Proof.: In one respect, when the imputation error is accurate, we have \(\delta^{Z}_{u,v}=0\) for \(u,v\in\mathcal{D}^{Z}\). In this case, the bias of the DR estimator for CDSR is computed by

\[\text{Bias}(\mathcal{E}^{*}_{DR}) \tag{26}\] \[=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}}\left[\frac{1}{| \mathcal{D}^{Z}|}\Bigg{|}\sum_{u,v\in\mathcal{D}^{Z}}\Delta^{Z}_{u,v}\delta^{ Z}_{u,v}\Bigg{|}\right],\] (27) \[=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}}\left[\frac{1}{| \mathcal{D}^{Z}|}\Bigg{|}\sum_{u,v\in\mathcal{D}^{Z}}\Delta^{Z}_{u,v}\cdot 0 \Bigg{|}\right],\] (28) \[=0. \tag{29}\]

In the other respect, when the learned propensities are accurate, we have \(\Delta^{Z}_{u,v}=0\) for \(u,v\in\mathcal{D}^{Z}\). In such case, we can compute the bias of the DR estimator for CDSR by

\[\text{Bias}(\mathcal{E}^{*}_{DR}) \tag{30}\] \[=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}}\left[\frac{1}{| \mathcal{D}^{Z}|}\Bigg{|}\sum_{u,v\in\mathcal{D}^{Z}}\Delta^{Z}_{u,v}\delta^{ Z}_{u,v}\Bigg{|}\right],\] (31) \[=\frac{1}{|\mathcal{Z}|}\sum_{Z\in\mathcal{Z}}\left[\frac{1}{| \mathcal{D}^{Z}|}\Bigg{|}\sum_{u,v\in\mathcal{D}^{Z}}0\cdot\delta^{Z}_{u,v} \Bigg{|}\right],\] (32) \[=0. \tag{33}\]

When either imputed errors or learned propensities are accurate, the bias of the proposed estimator is accurate. The proof is completed. 

**Lemma 4.2** (Tail Bound of DR Estimator).: Given imputation errors \(\hat{\mathbb{E}}^{Z}\) and learned propensities \(\hat{\mathbb{P}}^{Z}\), for any prediction matrix \(\hat{\mathbb{R}}^{Z}\), with probability 1-9, the deviation of the DR estimator from its expectation has the following tail bound in CDSR task.

\[\big{|}\mathcal{E}^{*}_{DR}-\mathbb{E}_{0}\big{|}\mathcal{E}^{*}_{ DR}\big{|}\leq \tag{34}\] \[\sqrt{\frac{\log(\frac{2}{9})}{2|\mathcal{Z}|\sum\limits_{Z\in \mathcal{Z}}|\mathcal{D}^{Z}|^{2}}{2}\sum_{Z\in\mathcal{Z}}\left[\frac{1}{| \mathcal{D}^{Z}|}\sum_{u,v\in\mathcal{D}^{Z}}\left(\frac{\delta^{Z}_{u,v}}{ \hat{p}^{Z}_{u,v}}\right)\right]} \tag{35}\]

Proof.: To avoid cluttering the notation, we introduce a random variable \(\chi^{Z}_{u,v}\) denoted by

\[\chi^{Z}_{u,v}=\hat{e}^{Z}_{u,v}\frac{\phi^{Z}_{u,v}\phi^{Z}_{u,v}}{\hat{p}^{Z}_{u,v}} \tag{36}\]

Considering the observation indicator \(\sigma^{Z}_{u,v}\) follows a Bernoulli distribution with probability \(p^{Z}_{u,v}\), we can obtain the distribution pattern of the random variable \(\chi^{Z}_{u,v}\) as follows.

\[P(\chi^{Z}_{u,v})=\left\{\begin{array}{l}p^{Z}_{u,v}\,,\quad\quad\quad\quad \chi^{Z}_{u,v}=\hat{e}^{Z}_{u,v}+\kappa^{Z}_{u,v}\\ 1-p^{Z}_{u,v}\,,\quad\quad\quad\chi^{Z}_{u,v}=\hat{e}^{Z}_{u,v}\end{array}\right. \tag{37}\]

where \(\kappa^{Z}_{u,v}\) is given by

\[\kappa^{Z}_{u,v}=\frac{\epsilon^{Z}_{u,v}-\epsilon^{Z}_{u,v}}{\hat{p}^{Z}_{u,v}}= \frac{\delta^{Z}_{u,v}}{\hat{p}^{Z}_{u,v}} \tag{38}\]Determining the interval \([\hat{e}^{Z}_{u,o},\hat{e}^{Z}_{u,o}+K^{Z}_{u,o}]\) for the random variable \(K^{Z}_{u,o}\) of size \(K^{Z}_{u,o}\) with probability 1 is a simple process. This is facilitated by the assumption that the observation indicators \(\hat{o}^{Z}_{u,o}\) are independent random variables, which ensures that the random variables \(\kappa^{Z}_{u,o}\) are also independent. The general form of Hoeffding's inequality for bounded random variables [41] can be expressed as 39. Let \(X_{1},\ldots,X_{N}\) be independent random variables. For each \(i\), we assume that \(X_{i}\in[a_{i},b_{i}]\). For any \(\epsilon>0\), we have the inequality

\[P\left(\left|\sum_{i=1}^{N}X_{i}-\sum_{i=1}^{N}\mathbb{E}(X_{i}) \right|\geq\epsilon\right)\leq 2\exp\left(\frac{-2\epsilon^{2}N^{2}}{\sum \limits_{i=1}^{N}(b_{i}-a_{i})^{2}}\right) \tag{39}\]

According to Hoeffding's inequality, for any \(\epsilon>0\), we have the following inequality

\[P\left(\left|\frac{1}{|Z|}\sum_{z\in\mathcal{Z}}\frac{1}{| \mathcal{D}^{2}|}\left[\sum_{u,\alpha\leq\mathcal{D}^{2}}\kappa^{Z}_{u,o} \right]-\frac{1}{|Z|}\sum_{Z\in\mathcal{Z}}\frac{1}{|\mathcal{D}^{2}|}\left[ \sum_{u,\alpha\leq\mathcal{D}^{2}}\mathbb{E}_{\mathbb{O}}(\kappa^{Z}_{u,o}) \right]\right|\geq\epsilon\right) \tag{40}\] \[\leq 2\exp\left(\frac{-2\epsilon^{2}\left[\sum_{Z\in\mathcal{Z}}| \mathcal{D}^{2}\right]^{2}}{\frac{1}{|Z|}\sum_{Z\in\mathcal{Z}}\frac{1}{| \mathcal{D}^{2}|}\sum_{u,\alpha\leq\mathcal{D}^{2}}(\kappa^{Z}_{u,o})^{2}}\right) \tag{41}\]

To solve for \(\epsilon\), one can set the right side of the inequality to be \(\eta\) and proceed with the following steps.

\[\eta=2\exp\left(\frac{-2\epsilon^{2}\left(\sum_{Z\in\mathcal{Z}} \left|D^{2}\right|\right)^{2}}{\frac{1}{|Z|}\sum_{Z\in\mathcal{Z}}\frac{1}{| D^{2}|}\sum_{u,\alpha\leq\mathcal{D}^{2}}(\kappa^{Z}_{u,o})^{2}}\right) \tag{42}\] \[\Longleftrightarrow\log(\frac{\eta}{2})=\frac{-2\epsilon^{2}\left( \sum_{Z\in\mathcal{Z}}|D^{2}\right|\right)^{2}}{\frac{1}{|Z|}\sum_{Z\in \mathcal{Z}}\frac{1}{|D^{2}|}\sum_{u,\alpha\in\mathcal{D}^{2}}(\kappa^{Z}_{u, o})^{2}}\] (43) \[\Longleftrightarrow\epsilon=\sqrt{\frac{\log(\frac{2}{\eta})}{2 |\mathcal{Z}|(\sum_{Z\in\mathcal{Z}}[D^{2}]^{2}}\sum_{Z\in\mathcal{Z}}\left[ \frac{1}{|\mathcal{D}^{2}|}\sum_{u,\alpha\in\mathcal{D}^{2}}(\kappa^{Z}_{u, o})^{2}\right]}\] (44) \[\Longleftrightarrow\epsilon=\sqrt{\frac{\log(\frac{2}{\eta})}{2 |\mathcal{Z}|(\sum_{Z\in\mathcal{Z}}[D^{2}]^{2}}\sum_{Z\in\mathcal{Z}}\left[ \frac{1}{|\mathcal{D}^{2}|}\sum_{u,\alpha\in\mathcal{D}^{2}}\frac{\delta^{Z}_ {u,o}}{\hat{\hat{\hat{\rho}}}^{Z}_{u,o}}\right]} \tag{45}\]

The proof is completed. 

**Corollary 4.2** (**Tail Bound Comparison**).: Suppose imputed errors \(\hat{\mathbf{E}}^{Z}\) are such that \(0\leq\hat{e}^{Z}_{u,o}\leq 2\hat{e}^{Z}_{u,o}\) for each \(u,o\in\mathcal{D}^{Z}\), then for any learned propensities \(\hat{\mathbf{P}}\), the tail bound of the proposed estimator will be lower than that of the IPS estimator which is utilized in IPSCDR [21].

Proof.: We can derive the following inequalities

\[0\leq\hat{e}^{Z}_{u,o}\leq 2\hat{e}^{Z}_{u,o}\text{ for }Z\in \mathcal{Z}\text{ for }u,v\in\mathcal{D}^{Z}\] (46) \[\Longrightarrow\hat{e}^{Z}_{u,o}-\epsilon^{Z}_{u,o}\leq\epsilon^ {Z}_{u,o}\] (47) \[\Longrightarrow(\delta^{Z}_{u,o})^{2}\leq(\epsilon^{Z}_{u,o})^{2}\] (48) \[\Longrightarrow\sqrt{\left[\frac{\delta^{Z}_{u,o}}{\hat{\hat{ \rho}}^{Z}_{u,o}}\right]^{2}}\leq\sqrt{\left(\frac{\hat{e}^{Z}_{u,o}}{\hat{ \hat{\rho}}^{Z}_{u,o}}\right)^{2}}\] (49) \[\Longrightarrow\sqrt{\frac{\log(\This ensured that the embeddings learned by the users/items were representative of their source domain. A non-overlapping ratio \(\mathcal{K}_{u}\) was introduced to control the number of non-overlapping users and simulate different debiased scenarios. For example, in the Amazon "Cloth-Sport" dataset with \(\mathcal{K}_{u}=25\%\), the number of overlapped users in the training set was calculated as (27,519 + 107,984 - 16,377 - 2) * 0.25 * 0.8 = 20,549. The same sampling strategy was applied to the validation set, while the test set was not downsampled. This sampling strategy can simulate the occurrence of selection bias in the open-world environment, where the training set mainly consists of users who are more likely to be selected or exposed, while the test set covers a wider range of users without careful selection. All evaluation metrics used in this study indicate better performance with higher values. Regarding the unseen users in \(\mathcal{D}\), we use the non-overlapping users who were not selected for the observed data as a substitute for unseen users. We remove the actual ratings for the unseen users while retaining their sequences.

**Parameter Settings** To ensure a fair comparison between different approaches, we set the same hyper-parameters for all of them. Specifically, we fixed the embedding dimension to 128, batch size to 512, learning rate to 0.001, and negative sampling number to 1 for training and 199 for validation and testing. We used the Adam optimizer to update all parameters. For the comparison baselines, we adopted the hyper-parameter values reported in the official literature. In the case of SDSR models combined with our model, we did not modify the hyper-parameters of the SDSR models. Additionally, the threshold value to control the group flag \(k\) is set to 0.7 and the size of the sampled users is set to the batch size. We set \(\lambda_{1}=0.01\) and \(\lambda_{23,4,5}=1e^{-4}\). The learning rate for the first step with loss \(\mathcal{L}_{e}\) is \(1e^{-3}\) and the rate for the second step with loss \(\mathcal{L}_{r}\) is \(1e^{-5}\).

### Compared methods

**Single-domain sequential recommendation methods:**

**BERT4Rec**[38] designs a bidirectional self-attention network to model user behavior sequences. To prevent information leakage and optimize the training of the bidirectional model, a Cloze objective is used to predict the randomly masked items in the sequence by considering both their left and right context. The implementation of BERT4Rec in PyTorch can be found at the URL.4.

Footnote 4: [https://github.com/language/bert4Rec-VAE-Pytorch](https://github.com/language/bert4Rec-VAE-Pytorch)

**GRU4Rec**[12] tackles the issue of modeling sparse sequential data while also adapting RNN models to the recommender system. To achieve this, the authors propose a new ranking loss function that is specifically designed for training these models. The implementation of GRU4Rec in PyTorch can be found at the URL.5.

Footnote 5: [https://github.com/language/bert4Rec-pytorch](https://github.com/language/bert4Rec-pytorch)

**SASRec**[17] is a self-attention based sequential model that addresses the challenge of balancing model parsimony and complexity in recommendation systems. By using an attention mechanism, SASRec identifies relevant items in a user's action history and predicts the next item based on relatively few actions, while also capturing long-term semantics like an RNN. This enables SASRec to perform well in both extremely sparse and denser datasets. The implementation of SASRec in PyTorch can be found at the URL.6.

Footnote 6: [https://github.com/language/bert4Rec-pytorch](https://github.com/language/bert4Rec-pytorch)

**Conventional Cross-domain recommendation methods:**

**STAR**[35] aims to train a single model to serve multiple domains by leveraging data from all domains simultaneously. The model captures the unique characteristics of each domain while also modeling the commonalities between different domains. It achieves this by using a network structure consisting of two factorized networks for each domain: one shared network that is common to all domains and one domain-specific network tailored to each domain. The weights of these two networks are combined to generate a unified network. The implementation of Pi-Net in Tensorflow can be found at the URL.7.

Footnote 7: [https://github.com/IRManLuo/MAMDR/tree/master](https://github.com/IRManLuo/MAMDR/tree/master)

**MAMDR**[25] presents a novel model agnostic learning framework called MAMDR for multi-domain recommendation (MDR). It addresses the challenges of varying data distribution and conflicts between domains in MDR. MAMDR incorporates a Domain Negotiation strategy to alleviate conflicts and a Domain Regularization approach to improve parameter generalizability. It can be applied to any model structure for multi-domain recommendation. The work also includes a scalable MDR platform used in Taobao for serving thousands of domains without specialists. In the comparison, we utilize their official implementation in Tensorflow, which can be found at the URL.8.

Footnote 8: [https://github.com/mamwaymp/PNet](https://github.com/mamwaymp/PNet)

**SSCDR**[16] addresses the challenge of inferring preferences for cold-start users based on their preferences observed in other domains. SSCDR proposes a semi-supervised mapping approach that effectively learns the cross-domain relationship even with limited labeled data. It learns latent vectors for users and items in each domain and encodes their interactions as distances. The framework then trains a cross-domain mapping function using both labeled data from overlapping users and unlabeled data from all items. SSCDR also incorporates an effective inference technique that predicts latent vectors for cold-start users by aggregating their neighborhood information.

**Cross-domain sequential recommendation methods:**

**Pi-Net**[27] simultaneously generates recommendations for two domains and shares user behaviors at each timestamp to address the challenges of identifying different user behaviors under the same account and discriminating behaviors from one domain that could improve recommendations in another. By leveraging parallel information sharing, Pi-Net improves recommendation accuracy and efficiency for cross-domain scenarios in the Shared-account Cross-domain Sequential Recommendation task. The implementation of Pi-Net in Tensorflow can be found at the URL.9.

Footnote 9: [https://github.com/lpwdl/DASL](https://github.com/lpwdl/DASL)

**DASL**[19] addresses the limitation of previous cross-domain sequential recommendation models by considering bidirectional latent relations of user preferences across source-target domain pairs, providing enhanced cross-domain CTR predictions for both domains simultaneously. The proposed approach features a dual learning mechanism and includes the dual Embedding and dual Attention components to extract user preferences in both domains and provide cross-domain recommendations through a dual-attention learning mechanism. The implementation of DASL in Tensorflow can be found at the URL.10.

C2DSR[2] enhances recommendation accuracy by addressing the bottleneck of the transferring module and jointly learning single- and cross-domain user preferences through leveraging intra- and inter-sequence item relationships. This approach overcomes the limitations of previous methods and captures precise user preferences. The implementation of C2DSR in PyTorch can be found at the URL 11.

Footnote 11: [https://github.com/cjq6/C2DSR](https://github.com/cjq6/C2DSR)

**Debiasing methods for recommendation:**

**DCRee[47] is a new recommendation paradigm that claims to unify sequential tritter encoding with global collaborative relation modeling. It attempts to address the issues of label shortage and the inability of current contrastive learning methods to tackle popularity bias and disentangle user conformity and real interest. The implementation of DCRee in PyTorch can be found at the URL 12.

Footnote 12: [https://github.com/HkC/DCRee](https://github.com/HkC/DCRee)

**CaseQ[46]** is proposed to alleviate the effects of popularity bias and temporal distribution shift in a single-domain sequential recommendation from training to testing. To achieve this, CaseQ employs a hierarchical branching structure combined with a learning objective based on backdoor adjustment, which enables the learning of context-specific representations. The implementation of CaseQ in PyTorch can be found at the URL 13.

Footnote 13: [https://github.com/cjq6/C2DSR](https://github.com/cjq6/C2DSR)

**IPSCDR[21]** has developed a novel Inverse-Propensity-Score (IPS) estimator that is tailored for cross-domain scenarios. The approach also incorporates three types of restrictions for propensity score learning. By utilizing these methods, IPSCDR effectively alleviates domain biases, including selection bias and popularity bias, when transferring user information between domains. As there is no official code release available, we have reconstructed the code for IPSCDR by adapting a related IPS-based framework. The implementation of the IPS-based framework in PyTorch can be found at the URL 14.

Footnote 14: [https://github.com/amhlheimis/IPS_MF](https://github.com/amhlheimis/IPS_MF)

### Hyperparameter Analysis

**The trade-off parameter \(\lambda_{1}\).** To evaluate the impact of the trade-off parameter \(\lambda_{1}\) in the loss function, we conduct a series of experiments with different values of \(\lambda_{1}=0.001,0.01,0.1\) to search for the optimal value for our AMDI model. The experiments are run five times and the results are reported by mean and variance. From the results in Table 7-8, it can be observed that the SDSR models with \(\lambda=0.01\) achieved the best performance on both the Cloth-Sport and Phone-Elec scenarios with different \(\mathcal{K}_{u}\). Moreover, in the Cloth-Sport scenario, the models with \(\lambda=0.001\) perform better than those with \(\lambda=0.1\), while in the Phone-Elec scenario, the models with \(\lambda=0.1\) perform better than those with \(\lambda=0.001\).

**The threshold \(k\) for the group.** We conduct ablation experiments by varying the threshold \(k\in\{0.5,0.6,0.7,0.8,0.9\}\) to investigate the impact of the threshold \(k\) on constructing interest groups in the multi-interest information module. We measure the average evaluation scores using NDCG(\(610\)) and HR@\(10\) on the Cloth-Sport and Phone-Elec scenarios. Our results show that a larger threshold \(k\) (\(0.5\to 0.7\)) leads to better performance, as more related interest information can be transferred. However, when the threshold \(k\) is increased beyond \(0.7\), the model's performance drops due to noise interference and redundant information. Therefore, to achieve superior performance, we set the threshold \(k\) to \(0.7\).

**The number of the sampled users.** To explore the impact of the number of sampled users on the multi-interest information module, we conduct ablation experiments varying the number of sampled users from \(128\) to \(1024\). We measure the average evaluation scores (NDCG@\(10\) and HR@\(10\)) for both Cloth-Sport and Phone-Elec scenarios, and the results are shown in Figure 8. Our findings suggest that an increase in the number of sampled users initially improves the recommendation performance, but it eventually declines when the matching neighbors reach \(1024\). This observation indicates that having too few sampled users would provide insufficient transferred information, while too many sampled users could introduce interference noise and compromise the model's performance. In practice, we select the number of sampled users to be \(512\) as it results in the best performance for our model.

## Appendix D Potential Societal Impacts

We propose an adaptive multi-interest debiasing framework to enhance the performance of most off-the-shelf SDSR methods. By utilizing our approach, e-commerce companies can recommend more relevant products to users and increase their revenue. Furthermore, our model AMID devises a debiasing framework that attends to minority users and explores their potential interests. As a result, our work promotes fairness in the recommender system and may help mitigate social inequality that may arise from algorithmic biases.

[MISSING_PAGE_FAIL:14]

Figure 8. The results of SASRec+AMID with different number of the sampled users on the Cloth-Sport & Phone-Elec scenarios. 25% and 75% denotes different \(\mathcal{K}_{w}\).

Figure 7. The results of SASRec+AMID with different threshold \(k\) on the Cloth-Sport & Phone-Elec scenarios. 25% and 75% denotes different \(\mathcal{K}_{w}\).