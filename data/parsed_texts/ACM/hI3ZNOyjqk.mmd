# ESANS: Effective and Semantic-Aware Negative Sampling for Large-Scale Retrieval Systems

Anonymous Author(s)

###### Abstract.

Industrial recommendation systems typically involve a two-stage process: retrieval and ranking, which aims to match users with millions of items. In the retrieval stage, classic embedding-based retrieval (EBR) methods depend on effective negative sampling techniques to enhance both performance and efficiency. However, existing techniques often suffer from false negatives, high cost for sampling quality and semantic information deficiency. To address these limitations, we propose Effective and Semantic-Aware Negative Sampling (ESANS), which integrates two key components: Effective Dense Interpolation Strategy (EDIS) and Multimodal Semantic-Aware Clustering (M3AC). EDIS generates virtual samples within the low-dimensional embedding space to improve the diversity and density of the sampling distribution while minimizing computational costs. MSAC refines the negative sampling distribution by hierarchically clustering item representations based on multimodal information (visual, textual, behavioral), ensuring semantic consistency and reducing false negatives. Extensive offline and online experiments demonstrate the superior efficiency and performance of ESANS.

## CCS Concepts

* **Information systems Retrieval models and ranking.**

## 1. Introduction

Recommendation systems have been widely adopted across diverse domains, including online e-commerce, advertising, short video platforms and delivery services [16, 17, 59], due to their effectiveness in mitigating information overload by providing tailored recommendations from large-scale item collections [18, 19]. Industrial recommendation systems typically involve two stages: retrieval and ranking. The retrieval stage is responsible for retrieving thousands of candidate items, whereas the ranking stage predicts the likelihood of user interaction with these candidates. Considering that retrieval tasks can be formulated as identifying the nearest neighbors in a vector space, substantial research has been devoted to developing high-quality representations for both users and items. Collaborative Filtering (CF) methods [8, 24, 42, 45] address this issue by encoding user preference and item representation into low-dimensional embedding space, based on historical interacted information. With the rapid development of deep learning, neural networks have been widely adopted in personalized recommendation systems [5, 20, 55]. Recently, Embedding-Based Retrieval (EBR) methods [3, 12, 30] have demonstrated significantly better performance compared to traditional CF methods, establishing themselves as the dominant approach in recommendation systems. EBR methods encode user and item information into separate embeddings using parallel neural networks, and these embeddings are trained through the strategy of contrastive learning [15, 36, 44].

EBR methods rely heavily on the contrast between positive and negative samples to produce distinguishable representations. The careful selection of negatives is crucial to enhancing the model's ability to differentiate between relevant and irrelevant items, significantly impacting overall retrieval performance. The classic Uniform

Figure 1. Visual diagram of our ESANS compared with other methods. Each method has sampled ten negatives equally.

Negative Sampling (UNS) method [23; 44] randomly selects negatives from the item candidate set, providing efficiency but yielding **low-quality samples**. Following this, additive margin [50] and temperature coefficient [33; 51] adjust the contrastive loss function to mine high-quality negatives from naive negatives sampled by UNS. FairNeg [9] reweights negatives in accordence with item group fairness to provide high-quality samples. Adap-\(\tau\)[4] dynamically adjusts the temperature coefficient for reweighting uniform negatives in accordence with their relevance to user interests. However, these methods fail to introduce more challenging negatives and further expand the scale of sampling which limit the performance of EBR methods. To address this issue, In-batch sampling [7] introduces relatively harder negatives by the in-batch sharing strategy. Airbnb [21] heuristically introduces orders from the same city as harder negatives. MixGCF [27] employs a hop-mixing interpolation technique in Graph Neural Networks (GNNs) to generate virtual hard negatives. However, these methods fail to effectively adjust the difficulty of negatives and distinguish users' potential interests from hard negatives, which may exacerbate the issue of **false negatives** (i.e. items relevant to users' potential interests but incorrectly regarded as negatives). Moreover, existing methods require substantial computational resources to further **improve the sampling quality** (i.e. sufficient hard negatives) [6]. Furthermore, from a contrastive learning perspective, these methods are unable to regulate sampling strategies based on **semantic information** in the real world, rendering the sampling process a black box.

Inspired by recent works in multi-modal learning [35; 40] and vector quantization techniques [47], we propose the Effective and **Semantical-Aware Negative Sampling** (ESANS) to address these challenges in the sampling process. Our method consists of two main components: the first part is Effective Dense Interpolation Strategy (EDIS), and the second part is Multimodal Semantic-Aware Clustering (M3AC). EDIS is devised to generate a sufficient number of virtual samples within the low-dimensional embedding space. More specifically, generating virtual samples among existing negatives creates a more uniform, dense, and diverse sampling distribution. Virtual samples positioned between the positive sample and surrounding negative samples contribute to gradually enhance the discriminatory ability of the neural network. By adjusting the interpolation parameters and strategies, we can control the difficulty of generated negatives and generate sufficient hard negatives. Meanwhile, in contrast to memory banks [22], interpolation within the low-dimensional embedding space leads to minimal computational cost and eliminates the need for extra memory storage.

Nevertheless, EDIS strongly relies on the judicious selection of negative sample anchors. In practice, virtual negative samples generated via interpolation may lack clear semantic information, occasionally producing meaningless samples. For example, interpolating between "iPhone" and "Cola" produces meaningless results, potentially introducing noise. Moreover, interpolating among randomly sampled negative anchors may introduce false negatives, further complicating the training process.

To address these deficiencies, we propose the MSAC method to optimize the sampling space by integrating the real-world semantic information. Firstly, we propose a multimodal-aligned technique to fuse multi-perspective item information from visual, textual and behavioral perspectives. Subsequently, a two-level vector quantized clustering approach is employed to assign semantic representations into multiple secondary clusters. Consequently, we can mitigate the issue of false negatives by selecting hard negatives from the same primary cluster as the positive sample, while ensuring they belong to a different secondary cluster. Additionally, we dynamically calibrate the sampling probabilities for each negative cluster to control the difficulty of negatives and refine the sampling quality. It is worth noting that this calibration is precisely guided by the semantic distance between the cluster centers of positives and negatives. This allows us to adjust the difficulty of the sampling process by increasing the sampling probabilities of clusters that are semantically similar to the positive cluster. Once the MSAC is introduced, EDIS based on semantics can be performed within the well-established semantic clusters. More specifically, we can ensure that the interpolated outcomes remain confined within the convex hull of that cluster. This intrinsic constraint preserves a measurable degree of semantic consistency and "**real-world applicability"** in the interpolated samples. Furthermore, interpolation between positives and hard negatives is also employed to generate additional high-quality hard negatives. Figure 1 shows the comparison between our ESANS and other methods. Our contributions can be summarized as follows:

* We propose a novel and effective sampling approach called ESANS, which provides explicit semantics guidance for interpolation negative sampling. Moreover, ESANS effectively enhances the diversity and richness of negative samples and allows for controllable negative sample difficulty, thereby boosting performance.
* We propose a general multimodal-aligned clustering approach that captures the multi-perspective similarities among candidate items on e-commerce platforms, thereby enabling a more refined semantic description in the interpolation space and eliminating false negative instances in the hard negative sampling process.
* We provide both extensive offline and online experiments to demonstrate the effectiveness and the efficiency of ESANS.

## 2. Related Work

This section presents a brief review of the relevant literature, specifically addressing techniques for negatives re-weighting, heuristic negative sampling, and model-based negative sampling.

**Negatives Re-weighting**. UNS [23; 44] represents the foundational negative sampling method, where negative samples are uniformly drawn from the entire dataset. The simplicity of UNS's algorithmic design provides substantial efficiency gains. Nevertheless, it exhibits notable deficiencies in the quality of negative samples. UMA2 [33] computes the sampling probabilities of random negative samples according to the current model and subsequently employs the Inverse Probability Weighting (IPW) technique to assign loss weights to these negative samples. The method proposed by [43] implements position-weighted approach for negative samples, where the weight is determined by the sample's ranking position. These approaches mimic high-quality negatives from naive negatives sampled by UNS, which fails to introduce more challenging negatives.

**Heuristic Negative Sampling**. Heuristic negative sampling algorithms primarily define the sampling distribution by predefinedheuristic rules. Popularity-biased Negative Sampling (PNS) (Brocker et al., 2017) utilizes item popularity as the sampling probability. Airbnb (Shi et al., 2018) applies personalized negative sampling within the same city, assuming bookings in the same location exhibit similar patterns. While this approach enhances the sampling process, it solely focuses on similarity-based sampling, neglecting sampling bias. CBNS (Shi et al., 2019) employs in-batch negative sampling and expands the negative sample set by incorporating previously trained items. The method (Shi et al., 2019) incorporates estimated item frequency into the batch softmax cross entropy loss to reduce sampling bias within the batch. MNS (Shi et al., 2019) integrates UNS with in-batch negative sampling, adopting a hybrid strategy. While these methods enhance sampling quality, they introduce popularity bias, aggravating the Sample Selection Bias (SSB) issue. Our method enhances sampling quality via a multimodal-aligned clustering algorithm and dense interpolation negative sampling, while also mitigating sampling bias.

**Model-based Negative Sampling.** Model-based negative sampling algorithms are highly effective at selecting high-quality negative samples. Model-based scoring methods are demonstrated by Dynamically Negative Sampling (DNS) (Shi et al., 2019) and ESAM (Eisaman et al., 2019), where the current model scores samples and selects the highest-scoring ones as negative samples. Adversarial learning methods also contribute to sampling improvements. MixGCF (Shi et al., 2019) employs a hop-mixing technique to synthesize hard negative samples by leveraging the user-item graph structure and the aggregation mechanism of Graph Neural Networks (GNNs). IRGAN (Zhou et al., 2019) utilizes two recommendation models, a discriminator and a generator, trained adversarially. AdvIR (Shi et al., 2019) and RNS (Rasmussen, 2006) further optimize IRGAN's structure, improving both efficiency and performance. The Adap-r(Shi et al., 2019) adaptively adjusts the temperature coefficient of the loss function by calculating the loss for each user and the corresponding random negative samples. This method leverages personalized user preferences to effectively identify hard negative samples. FairNeg (Chen et al., 2019) enhances the sampling distribution by fairly sampling from groups and then reweighting based on their relevance to the user. Our method precisely controls the difficulty of negatives, improving sampling quality and eliminating false negatives without increasing the complexity of the retrieval model.

## 3. Methodology

In this section, we formulate the problem and describe our proposed framework specifically, as well as introducing the detailed process of our negative sampling method.

### Problem Formulation

The primary objective of the retrieval stage in industrial recommendation systems is to efficiently retrieve a potentially relevant subset of items from a large item pool \(\hat{I}\) for each user \(u\in\mathcal{U}\). In pursuit of this objective, each instance can be represented by a tuple \((\mathcal{B}_{u},\mathcal{P}_{u},\mathcal{I}_{i})\) where \(\mathcal{B}_{u}\) denotes the sequence of user historical behaviors, \(\mathcal{P}_{u}\) denotes the basic profile of user \(u\), \(\mathcal{I}_{i}\) denotes the information of target item such as item id and category id. In the classical two-tower architecture (Shi et al., 2019) of the EBR models, users and items are separated into two individual encoders to reduce online computational complexity. We can define the user encoder as \(f_{user}\) and the item encoder as \(g_{item}\), so we have:

\[\mathbf{u}_{u} =f_{user}(\mathcal{B}_{u},\mathcal{P}_{u})\] \[\mathbf{v}_{i} =g_{item}(\mathcal{I}_{i}) \tag{1}\]

where \(\mathbf{u}_{u}\in\mathbb{R}^{d_{u}\times 1}\) is the output vector of the user encoder called user embedding, and \(\mathbf{v}_{i}\in\mathbb{R}^{d_{u}\times 1}\) is the output vector of the item encoder called item embedding. \(K\) denotes the dimension of output embeddings. Finally, the relevance of a user-item pair can be estimated by a scoring function:

\[s(\mathbf{u},\mathbf{v})=\mathbf{u}^{\top}\mathbf{v} \tag{2}\]

### Overall Framework

As previously discussed, existing methods fail to balance sampling quality, bias, and efficiency simultaneously. To address these limitations, we designed ESANS, as illustrated in Figure 2. ESANS consists of two main components:

* **Multimodal Semantic-Aware Clustering(MSC)**, which performs hierarchical clustering based on visual, textual, and behavior based representations to optimize the sampling process by integrating semantic information. Our proposed method addresses the limitations of unclear anchor semantics, improves sampling quality, and reduces the risk of introducing false negatives.
* **Effective Dense Interpolation Strategy(EDIS)**, which employs linear interpolation among existing samples within the same semantic cluster to make sure the semantic consistency. Our proposed method works with minimal computational cost, enhances the diversity and richness of negative samples, and facilitates the controllable difficulty of hard negative samples.

### Multimodal Semantic-Aware Clustering

Most existing negative sampling methods tend to ignore the semantic correlations among samples. Against this deficiency, our MSAC is proposed to capture the multi-perspective similarities among items and incorporate explicit semantics into the negative sampling process.

#### 3.3.1. Multimodal-aligned Technique

When users browse items on the e-commerce platform, they primarily perceive items through three views: visual images, descriptive text, and collaborative filtering recommendations. To generate a comprehensive description of items, it is necessary to consider these views concurrently. The visual representations \(\mathcal{R}_{\hat{I}}\) and textual representations \(\mathcal{R}_{\mathcal{T}}\) can be pre-trained by specific encoders (Shi et al., 2018; Zhai et al., 2019) in advance. The behavior-based representations \(\mathcal{R}_{\mathcal{G}}\) can be pretrained using graph representation learned based on a substantial number of user behaviors. Given a mini-batch of N items, we design multimodal-aligned encoders for each view.

\[\mathcal{M}_{\hat{I}} =H_{\hat{I}}(\mathcal{R}_{\hat{I}})\in\mathbb{R}^{N\times d_{m}}\] \[\mathcal{M}_{\mathcal{T}} =H_{\mathcal{T}}(\mathcal{R}_{\mathcal{T}})\in\mathbb{R}^{N\times d _{m}}\] \[\mathcal{M}_{\mathcal{G}} =H_{\mathcal{G}}(\mathcal{R}_{\mathcal{G}})\in\mathbb{R}^{N\times d _{m}} \tag{3}\]

where \(H_{\bullet}\) denotes the encoder of each view, \(\mathcal{M}_{\bullet}\) denotes the output embedding of each view, \(d_{m}\) denotes the output dimension of each multimodal-aligned encoder.

Inspired by the Contrastive Language-Image Pre-training (CLIF) (Shen et al., 2017), We propose a multimodal alignment method to fuse item representations from three perspectives. Given a dataset of \(\mathcal{M}_{\mathbf{t}}\) that consists of a collection of output embeddings \((\mathcal{M}_{I}^{i},\mathcal{M}_{\mathcal{T}}^{i},\mathcal{M}_{\mathcal{G}}^{i} )_{I=1}^{N}\), we contrast congruent and incongruent pairs across any two modalities. For instance, we sample from the joint distribution of image-text models \(\mathbf{x}_{I-\mathcal{T}}\sim\mathsf{P}(\mathcal{M}_{I},\mathcal{M}_{\mathcal{ T}})\) or \(\mathbf{x}_{I-\mathcal{T}}=\{\mathcal{M}_{I}^{i},\mathcal{M}_{\mathcal{T}}^{i}\}\), which we call positive samples. We sample from the product of marginals, \(\mathbf{y}_{I-\mathcal{T}}\sim\mathsf{P}(\mathcal{M}_{I})\mathsf{P}(\mathcal{ M}_{\mathcal{T}})\) or \(\mathbf{y}_{I-\mathcal{T}}=\{\mathcal{M}_{I}^{i},\mathcal{M}_{\mathcal{T}}^{i}\}\), which we call negative samples. Multimodal-aligned encoders are optimized to correctly select a single positive sample \(\mathbf{x}_{I-\mathcal{T}}\) out of the set \(\mathcal{S}=\{\mathbf{x}_{I-\mathcal{T}},\mathbf{y}_{I-\mathcal{T}}^{1},..., \mathbf{y}_{I-\mathcal{T}}^{N-1}\}\) which contains \(N-1\) negative samples:

\[\mathcal{L}_{align}^{I-\mathcal{T}}=-\frac{\mathbb{E}}{S}[log\frac{h( \mathbf{x}_{I-\mathcal{T}})}{h(\mathbf{x}_{I-\mathcal{T}})+\sum_{i=1}^{N-1}h( \mathbf{y}_{I-\mathcal{T}}^{i})}]\] \[\mathcal{L}_{align}^{I-\mathcal{G}}=-\frac{\mathbb{E}}{S}[log\frac{h( \mathbf{x}_{I-\mathcal{G}})}{h(\mathbf{x}_{I-\mathcal{G}})+\sum_{i=1}^{N-1}h( \mathbf{y}_{I-\mathcal{G}}^{i})}]\] \[\mathcal{L}_{align}^{\mathcal{G}-\mathcal{T}}=-\frac{\mathbb{E}}{S}[ log\frac{h(\mathbf{x}_{\mathcal{G}-\mathcal{T}})}{h(\mathbf{x}_{\mathcal{G}-\mathcal{T}})+ \sum_{i=1}^{N-1}h(\mathbf{y}_{\mathcal{G}-\mathcal{T}}^{i})}] \tag{4}\]

where \(h(\cdot)\) is the cosine similarity operation after exponentiation, \(\mathcal{L}_{align}^{I-\mathcal{T}}\) is the alignment loss between visual and textual modals, \(\mathcal{L}_{align}^{I-\mathcal{G}}\) is the alignment loss between visual and behavior-based models, \(\mathcal{L}_{align}^{\mathcal{G}-\mathcal{T}}\) is the alignment loss between behavior-based and textual modals.

#### Vector Quantized Clustering with Cascaded Codebooks

While aligning \(\mathcal{M}_{I},\mathcal{M}_{\mathcal{T}},\mathcal{M}_{\mathcal{G}}\) into the same embedding space, we simultaneously quantize these representations into several clusters with cascaded codebooks, as illustrated in Figure 2. Specifically, the primary codebook is designed to effectively differentiate coarse-level item representations, while the secondary codebook enhances this distinction by refining the differentiation of fine-grained item representations, especially when significant disparities persist among aligned representations across partial modalities.

The _primary codebook_\(C_{p}=\{z_{p}^{k}\}_{k=1}^{K_{p}}\) consists of \(K_{p}\) codewords (Zhu et al., 2017) and the dimension of each codeword is \(d_{m}\). The clustering stage is conducted by calculating the mean of the aligned embeddings:

\[\mathcal{R}_{p}^{i}=\frac{1}{3}(\mathcal{M}_{I}^{i}+\mathcal{M}_{\mathcal{T}}^ {i}+\mathcal{M}_{\mathcal{G}}^{i}) \tag{5}\]

Subsequently \(\mathcal{R}_{p}=\{\mathcal{R}_{p}^{i}\}_{i=1}^{N}\) is quantized by assigning it to the nearest codeword within the primary codebook. We denote that the nearest codeword to \(\mathcal{R}_{p}^{i}\) is \(c_{p}^{i}=\arg\min_{k}\|\mathcal{R}_{p}^{i}-\frac{k}{2}p\|\).

In the _secondary codebook_, we compute the residual between \(\{\mathcal{M}_{I},\mathcal{M}_{\mathcal{T}},\mathcal{M}_{\mathcal{G}}\}\) and the primary corresponding codeword \(z_{p}^{C_{p}}\). These residuals are concatenated to a vector \(\mathcal{R}_{p}^{i}\), which is used to

Figure 2. Our proposed ESANS framework. a) Multimodal-aligned Technique. b) Vector Quantized Clustering with Cascaded Codebooks. c) Semantic-Aware Negative Sampling & Effective Dense Interpolation Strategy (EDIS).

describe the modal-specific information between different items.

\[\mathcal{R}_{s}^{i}=[\mathcal{M}_{T}^{i}-z_{p}^{C_{p}^{i}};\mathcal{M}_{T}^{i}-z_{ p}^{C_{p}^{i}};\mathcal{M}_{G}^{i}-z_{p}^{C_{p}^{i}}] \tag{6}\]

The advantages of using information from three modalities for secondary clustering are illustrated in Figure 3. Similar to the primary clustering, we select the codeword closest to \(\mathcal{R}_{s}=\{\mathcal{R}_{s}^{i}\}_{i=1}^{N}\) from another codebook \(C_{s}=\{z_{s}^{k}\}_{k=1}^{K_{s}}\), where \(K_{s}\) denotes the number of codewords in the secondary codebook. The nearest secondary codeword to \(\mathcal{R}_{s}^{i}\) is recorded as \(C_{s}^{i}=\arg\min_{k}\|\mathcal{R}_{s}^{i}-z_{s}^{k}\|\).

Once we have all cluster indicate for an item, the clustering loss can be defined as:

\[\mathcal{L}_{\text{SQ}}=\sum_{i=1}^{N}\|\mathcal{R}_{p}^{i}-z_{p}^{C_{p}^{i}} \|^{2}+\sum_{i=1}^{N}\|\mathcal{R}_{s}^{i}-z_{s}^{C_{p}^{i}}\|^{2} \tag{7}\]

Finally, the loss function for multimodal-aligned clustering is given by Equation 8:

\[\mathcal{L}=\beta_{1}\mathcal{L}_{align}^{T-\mathcal{T}}+\beta_{2}\mathcal{L} _{align}^{T-\theta}+\beta_{3}\mathcal{L}_{align}^{\theta-\mathcal{T}}+ \mathcal{L}_{\text{SQ}} \tag{8}\]

#### 3.3.3. Semantic-Aware Negative Sampling

Based on the above framework, we divide the whole set of candidate items into multiple semantic clusters. Then we introduce the semantic-aware negative sampling which includes simple negative sampling and hard negative sampling. In simple negative sampling, we select primary clusters for each positive sample based on the following probability formula, ensuring that none of these selected clusters are the same as the primary cluster of the positive sample.

\[\begin{split} Q(C_{p}=i)&=\frac{1}{d(z_{p}^{i},z_{p}^ {i})^{p}},i\neq+\\ P(C_{p}=i)&=\frac{Q(C_{p}=i)}{\sum\limits_{j\neq+}Q(C_{p}=j)} \end{split} \tag{9}\]

where \(d(\cdot,\cdot)\) measures the distance between primary codewords using an inner-product operation, which is subsequently normalized to a range from 0 to 1. \(z_{p}^{n}\) is the primary cluster of the positive sample, \(Q(C_{p}=i)\) is the unnormalized sampling probability of similar primary clusters with \(\gamma\), \(P(c_{p}=i)\) is the normalized sampling probability of primary cluster \(z_{p}^{i}\). Then, we randomly select samples from each cluster which enhances the diversity of negative samples. After being encoded by the item tower (Zhou et al., 2017), the embedding set of simple negative samples can be represented as \(V_{s}\):

\[V_{s}=\{V_{s}^{1},...,V_{s}^{k},...,V_{s}^{m_{c}}\} \tag{10}\]

where \(V_{s}^{k}\) is the embedding set of the simple negative samples in k-th cluster, \(m_{c}\) is the number of selected clusters and \(m_{o}\) is the number of selected samples in each cluster. In this way, we dynamically adjust the difficulty of the simple negatives as well as mitigate group-level sampling biases.

In hard negative sampling strategy, we randomly select partially similar samples within the positive primary cluster. Then, we consider samples in the same secondary cluster as false negatives and remove these samples from the hard negative samples set. The output embedding set of hard negative samples can be represented as \(V_{h}=\{v_{h}^{1},v_{h}^{2},...,v_{h}^{m_{h}}\}\), where \(m_{h}\) is the number of selected samples in the positive primary cluster.

### Effective Dense Interpolation Strategy

By employing our negative sampling process, we obtain negative sample clusters and randomly selected negative sample anchors for each cluster. It's a well-established principle (Bang et al., 2017) that increasing the negative sampling size can enhance the performance of the EBR models. However, the process mentioned above does not guarantee a sufficient sampling size for each cluster. To solve this problem, we propose a parameter-adaptive negative sampling augmentation technique based on the linear interpolation to increase the number of negative samples. The detailed interpolation process is applied to both simple negative samples and hard negative samples, which is illustrated in Figure 2.

#### 3.4.1. Interpolation on Simple Negative Samples

Suppose we select \(n_{o}\) negative anchors (\(2\leq n_{o}\leq m_{o}\)) from the \(k\)-th cluster. The output item embeddings are reordered as \(V_{\text{sk}}=\{v_{\text{sk}}^{1},...,v_{\text{sk}}^{n_{o}}\}\). Each vector in the embedding set is selected once as the anchor vector \(v_{\text{sk}}^{a}\), and generate the virtual negative samples similar to the embedding set by linear interpolation:

\[\begin{split}\tilde{v}_{\text{sk}}^{a}&=\sum_{i=1} ^{n_{o}}a_{i}v_{\text{sk}}^{i}\\ & a_{j}=\frac{d(v_{\text{sk}}^{a},v_{\text{sk}}^{i})^{\eta}}{\sum_ {j=1}^{n_{o}}d(v_{\text{sk}}^{a},v_{\text{sk}}^{i})^{\eta}}\end{split} \tag{11}\]

Figure 3. The visualization of items in the representation space during secondary clustering. Although item 1-3 and item 4-5 have similar mean embeddings, but in each view their embeddings differ significantly, resulting in their assignment to different secondary clusters. By leveraging three modalities, clustering accuracy is significantly enhanced.

[MISSING_PAGE_FAIL:6]

features of these contents have already been extracted using PixelNet, a network proposed concurrently with Pixel-Rec.
* **Industrial Dataset.** We establish the offline dataset by collecting the users' sequential behaviors and feedback logs from Alibaba's international e-commerce platform, Lazada. The dataset comprises four categories, each representing a distinct Southeast Asian country, labeled from #A1 to #A4.

#### Graph Construction

Due to space limitation, the introduction of the behavior-based graph construction is provided in Appendix Section A.

**Baselines.** We compared our ESANS with five representative negative sampling methods based on the classical two-tower architecture. The methods are as follows:

* **UNS**(Zhou et al., 2017; Wang et al., 2018): A widely used negative sampling approach involves randomly selecting instances from a uniform distribution.
* **PNS**(Bianchi et al., 2017): A negative sampling method that adjusts the sampling distribution based on item popularity.
* **Debiased MNS**(Zhu et al., 2017; Wang et al., 2018): A method that integrates UNS with in-batch negative sampling, and introduces a technique to address the oversampling issue of popular items.
* **MixGCF**(Zhu et al., 2017): A method synthesizes hard negatives between negatives and positives in a graph-based model. We adapt this to a two-tower structure to generate virtual hard negatives in the item representation space.
* **FairNeg**(Bianchi et al., 2017): A method that improves item group fairness by adaptively adjusting the distribution of negative samples at the group level.
* **Adap-\(\tau\)(Chen et al., 2018): A method that adjusts the temperature coefficient of the loss function by the embedding similarity between users and corresponding negatives.

**Evaluation Metrics.** For the evaluation metrics in recommendation tasks, we follow (Chen et al., 2018; Chen et al., 2018) and use Recall@K for each group based on the Top-K recommendation results. Finally, the Recall@K is averaged over all users.

**Parameter settings.** We divide users in each public dataset into three subsets: training, validation, and testing, with a ratio of 8:1:1. As for the Industrial Dataset, we set aside the instances from the final day for testing, while using the preceding instances for training. For each user in the training set, we employ their first \(k\) actions to predict the (\(k+1\))-th action. To ensure computational manageability, we limit the length of user behavior sequences to 10 for the Amazon Review dataset, 32 for the Pixel-Rec dataset and 64 for the Industrial dataset. Due to space limitation, additional implementation details are provided in Appendix Section B.

### Performance Comparison (RQ1)

Table 3 summarizes the overall performance of our ESANS as well as the baselines on both industrial and public datasets, with the best results emphasized in bold and the second-best results underlined. It is noteworthy that ESANS consistently outperforms all baseline methods across the aforementioned datasets, achieving an average improvement of up to **15.32%** in recall@50 and **10.73%** in recall@200 compared to its base method UNS. PNS generally outperforms UNS across most datasets, indicating that boosting the sampling possibility for popular items improves sampling quality. However, it is worth noting that PNS does not exceed UNS performance in the #A3 dataset, which might be attributed to the introduced popularity bias. Once the challenge of popularity bias is addressed, the debiased MNS Sampling method outperforms UNS and PNS across all datasets and outperforms other baselines on #A4. MixGC introduces virtual hard negatives by hop-mixing interpolation which achieves similar performance with the debiased MNS and proves the feasibility of hard negatives augmentation. However, the interpolation process fails to consider semantics and yields noisy negatives, so it is outperformed by our method. FairNeg is another work conducted to reduce the sampling bias via adjusting the group-level negative sampling distribution which provides the best recommendation utility on Pixel-Rec and #A2 in all baselines. However, this work determines the groups by the only item attribute view which is not comprehensive and thus is surpassed by our method. Ada-\(\tau\) is proposed to design a learnable \(\tau\), which enables the adaptive adjustment of the difficulty level for negatives. This work outperforms other baseline models on Amazon Elecs. However, Ada-\(\tau\) fails to provide incremental information by deriving more challenging negatives during the training process so that it is beats by our method.

In summary, our method effectively addresses the inherent limitations of these methods and achieves SOTA performance across all datasets in terms of retrieval efficiency. It is worth noting that the MSAC module is actually detached from the training process of DSSM and the EDIS module is only applied to the output of the deep neural network. Therefore, our method does not introduce the additional computational complexity for either offline training and online serving.

### Ablation Study (RQ2)

To investigate the effectiveness of each component in the proposed model, in this subsection, we conduct a series of ablation studies on the \(\pm A2\) industrial datasets as follows:

* **w/o MSAC**, removes the Multimodal Semantic-Aware Clustering before the Interpolation-based negative sampling.
* **w/o EDIS**, removes the Effective Dense Interpolation Strategy employed in both simple negative sampling and hard negative sampling strategies.
* **w/o Multimodal Aligning**, removes the textual and visual modalities and reserves the behavior-based modality for further clustering.
* **w/o Secondary Codebook**, removes the secondary codebook in the Vector Quantized Clustering, thereby invalidating the interpolation-based hard negative sampling.

Table 4 presents the performance of these ablation experiments. Firstly, we can observe that adopting Multimodal-aligned Clustering Algorithm improves recall@50 by **6.41%** and recall@200 by

\begin{table}
\begin{tabular}{c|c|c|c|c} \hline \hline Scenarios & \#A1 & \#A2 & \#A3 & \#A4 \\ \hline \#User & 4,936,611 & 24,931,581 & 17,037,221 & 15,914,765 \\ \#Item & 2,163,338 & 4,268,324 & 2,905,716 & 3,067,253 \\ \#click & 61,579,472 & 336,746,141 & 194,341,806 & 163,611,291 \\ \#Impression & 2,353M & 9,648M & 4,274M & 6,134M \\ \hline \hline \end{tabular}
\end{table}
Table 2. Statistics of the Industrial Dataset.

[MISSING_PAGE_FAIL:8]

## References

* (1)
* Abadi et al. (2016) Martin Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Bert, Xiangyu Chen, Alexander Ivers, Michael L. et al. 2016. Tensorflow: a system for Large-Scale Machine Learning. In _12th USENIX symposium on operating systems design and implementation_ (OSDI 2016). 265-283.
* Bansal et al. (2016) Targett Bansal, David Balshamer, and Andrew McCallum. 2016. Ask the gpu: Multi-task learning for deep text recommendations. In _Proceedings of the 10th ACM Conference on Recommender Systems_.
* Con et al. (2020) Yukon Con, Jianwei Zhang, Xin Zou, Chang Zhou, Hongxia Yang, and Jie Tang. 2020. Controllable multi-interest framework for recommendation. In _Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining_.
* Chen et al. (2023) Jiawei Chen, Junhang Wu, Jianxen Wu, Xueshi Cao, Sheng Zhou, and Xiangpan He. 2023. Adapt-r: A.2. Adityber updating embedding magnitude for recommendation. In _Proceedings of the ACM SIG conference on_. ACM big conference on_.
* Chen et al. (2017) Jingyuan Chen, Hawang Zhang, Xiangxiang Nie, Wei Liu, and Tat-Seng Seng Chua. 2017. Attribute collaborative filtering. Multimedia recommendation with item-and component-level attention. In _Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval_.
* Chen et al. (2020) Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A simple framework for contrastive learning of visual representations. In _International conference on machine learning_.
* Chen et al. (2017) Ting Chen, Yukon Sun, Yue Shi, and Liangqiu Hong. 2017. On sampling strategies for neural network-based collaborative filtering. In _Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining_.
* Chen et al. (2012) Tianqi Chen, Weinan Zhang, Qiuxia Li, Kalong Chen, Zhao Zheng, and Yong Yu. 2012. SVDFeature: a toolkit for feature-based collaborative filtering. _The Journal of Machine Learning Research_ (2012).
* Chen et al. (2023) Xiao Chen, Wenqi Fan, Jingfan Chen, Haochen Liu, Zitao Liu, Zhaoxiang Zhang, and Qing Li. 2023. Fairly adaptive negative sampling for recommendations. In _Proceedings of the ACM Web Conference_.
* Chen et al. (2020) Zhihong Chen, Ron Xiao, Chenliang Li, Gangfeng He, Haoqheun Sun, and Hong Deng. 2020. Exant Discriminative endomar adaptation with non-displayed items to improve long-tail performance. In _Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval_.
* Cheng et al. (2024) Yu Cheng, Yunlong Pan, Jiawei Zhang, Yongxin Niu, Asian Sun, and Fenghui Yuan. 2024. An Image Dataset for Benchmarking Recommender Systems with Box Pricks. In _Proceedings of the 2024 SIAM International Conference on Data Mining_ (SMM).
* Covington et al. (2016) Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In _Proceedings of the 10th ACM conference on recommender systems_.
* Ding et al. (2019) Jingta Ding, Yuhan Quan, Xiangpan He, Yong Li, and Degeng Jin. 2019. Reinforced Negative Sampling for Recommendation with Exponente Data. In _IJCAI_.
* Fan et al. (2022) Lu Fan, Qian Li, Bo Liu, Xiao-Ming Wu, Xiaotong Zhang, Fuyu Lv, Guili Lin, Sen Li, Taiwei Jin, and Kopping Yang. 2022. Modeling user behavior with graph convolution for personalized product search. In _Proceedings of the ACM Web Conference_. 2022.
* Yajer et al. (2019) Wenqi Fan, Yajer Der, Yao Ma, Jianping Wang, Jiliang Tang, and Qing Li. 2019. Deep adversarial social recommendation. In _28th International Joint Conference on Artificial Neural Information Processing_.
* Fan et al. (2021) Wenqi Fan, Yajer Der, Xiangyu Zhao, Yao Ma, Hui Liu, Jianping Wang, Jiliang Tang, and Qing Li. 2021. Attacking black-box recommendations via copying cross-domain user profiles. In _2021 IEEE 37th international conference on data engineering (ICDE)_.
* Fan et al. (2020) Wenqi Fan, Tao Ma, Qing Li, Jianping Wang, Guoyong Cai, Jiliang Tang, and Dawei Yin. 2020. A graph neural network framework for social recommendations. _IEEE Transactions on Knowledge and Data Engineering_ (2020).
* Fan et al. (2020) Wenqi Fan, Yao Ma, Dawei Yin, Jianping Wang, Jiliang Tang, and Qing Li. 2020. Deep social collaborative filtering. In _Proceedings of the 13th ACM Conference on Recommender Systems_.
* Fan et al. (2020) Wenqi Fan, Xiangyu Zhao, Xiao Chen, Jingfan Su, Jingdong Gao, Lin Wang, Qiqiong Liu, Yiq Wang, Han Xu, Li Chen, and Jianq. 2020. A comprehensive survey on trustworthy recommender systems. _arXiv preprint arXiv:2009.1011_ (2020).
* Ge et al. (2020) Sayu Ge, Chuan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2020. Graph enhanced representation learning for news recommendation. In _Proceedings of the web conference_. 2020.
* Grubovic and Cheng (2018) Mikulg Grubovic and Fabian Cheng. 2018. Real-time personalization using em-holding for search ranking at airbnb. In _Proceedings of the 2018 ACM SIGKDD international conference on knowledge discovery & data mining_.
* He et al. (2020) Kaiming He, Haogi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. 2020. Momentum contrast for unsupervised visual representation learning. In _Proceedings of the 22/CVF conference on computer vision and pattern recognition_.
* Kingma et al. (2015) Xiangnan He, Lei Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In _Proceedings of the 26th international conference on world wide web_.
* Hu et al. (2008) Yufan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative filtering for implicit feedback datasets. In _2008 Eighth IEEE international conference on data mining_.
* Huang et al. (2020) Jiu-Ting Huang, Ashish Sharma, Shuying Sun, Li Xia, David Zhang, Philip Pronin, Janan Padmanabhan, Giuseppe Ottaviano, and Linjun Yang. 2020. Embedding-based retrieval in facebook search. In _Proceedings of the 26th ACM SIGKDD international Conference on Knowledge Discovery & Data Mining_.
* Huang et al. (2013) Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In _Proceedings of the 22nd ACM International Conference on Information & Knowledge Management_.
* Huang et al. (2021) Tingjin Huang, Yuxiao Dong, Ming Ding, Zhen Yang, Wemheng Feng, Xinyu Wang, and Jie Tang. 2021. Migf: An improved training method for graph neural network-based recommender systems. In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_.
* Huang et al. (2020) Zhicheng Huang, Zhuoyang Zeng, Bel Liu, Dongmei Fu, and Jianlong Fu. 2020. Pixel-bert: Aligning image pixels with text by deep multi-modal transformers. _arXiv preprint arXiv:2004.00868_ (2020).
* Lee et al. (2022) Doyne Lee, Chihon Kim, Seaboon Kim, Minxu Cho, and Woo-Shi Minu. 2022. Autoregressive image generation using residual quantization. In _Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_.
* Liu et al. (2019) Chae Li, Zhiyuan Liu, Mengping Wu, Yuchi Xu, Hua Zhao, Pipei Huang, Guoliang Kang, Qiwei Chen, Wei Li, and Diku Lee. 2019. Multi-interest network with dynamic routing for recommendation at Tmall. In _Proceedings of the 28th ACM international conference on information and knowledge management_.
* Li et al. (2019) Limuna Harold Li, Marakkar, Yiharu Yin, Che-Jui Hsieh, and Kai-Wei Chang. 2019. Visunbert: A simple and performant baseline for vision and language. _arXiv preprint arXiv:1908.03557_ (2019).
* Lu et al. (2022) Xiaochu Lu, Xin Song, Pengxiu Yuan, Xiao Liuo Lu, and Tu Zhang. 2022. Soft Rarranging Network for Click Through Rate Prediction. _arXiv preprint arXiv:2202.03819_ (2022).
* Lou et al. (2022) Jianchen Lou, Hong Wen, Puyu Lv, Jing Zhang, Tengqi Yuan, and Zhao Li. 2022. Re-weighting negative samples for model-agnostic matching. In _Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval_.
* Ma et al. (2023) Heakai Ma, Ruobing Xie, Lei Liu, Xing Chen, Xia Zhang, Leylin Liu, and Zhe Zhou. 2023. Exploring fake hard negative sample in cross-domain recommendation. In _Proceedings of the 17th ACM Conference on Recommender Systems_.
* Manorot et al. (2018) Muhammad Arslan Manor, Sarah Athanar, Zixing Mann, Zixing Maeng, Preelav Nakov, and Shangsong Liang. 2018. Multidrop Representation Learning: A Survey on Evolution, Petraining and its Applications, Vol. 20. Association for Computing Machinery, New York, NY, USA.
* Mikolov et al. (2013) Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. _Advances in Neural Information Processing Systems_ (2013).
* Nie et al. (2019) Jianmo N, Jiacheng Li, and Julian McAuley. 2019. Istitovin recommendations using distantly-labeled reviews and fine-grained aspects. In _Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP)_.
* Park and Chang (2019) Dee Hoon Park and Y Liang. 2019. Adversarial sampling and training for semi-supervised information retrieval. In _The World Wide Web Conference_.
* Pereyra et al. (2017) Gabriel Pereyra, George Tucker, Jan Chorowski, Lukasz Kaiser, and Geoffrey Hinton. 2017. Regularizing neural networks by penalizing confident output distributions. _arXiv preprint arXiv:1702.06385_ (2017).
* Radford et al. (2021) Zhe Radford, Jong Wook Kim, Chris Hallacy, Alijus Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Savary, Amanda Askell, Pamela Mishkin, Jack Clark, et al. 2021. Learning transferable visual models from mutual language supervision. In _International conference on machine learning_.
* Niemers (2019) N Reimers. 2019. Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. _EMNLP_ (2019).
* Rendle (2010) Steffen Rendle. 2010. Factorization machines. In _2010 IEEE International conference on data mining_.
* Rendle and Freudenthaler (2014) Steffen Rendle and Christoph Freudenthaler. 2014. Improving pairwise learning for item recommendation from implicit feedback. In _Proceedings of the 7th ACM international conference on Web search and data mining_.
* Rendle et al. (2012) Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thienen. 2016. Brlx: Bayesian personalized ranking from implicit feedback. _arXiv preprint arXiv:1205.2018_ (2012).
* Savor et al. (2011) Badif Savor, George Kappas, Joseph Konstan, and John Riedl. 2011. Item-based collaborative filtering recommendation algorithms. In _Proceedings of the 10th international conference on World Wide Web_.
* Tang et al. (2022) Yong Tang, Wentao Bai, Guilin Li, Xialong Liu, and Yu Zhang. 2022. CBOLers: towards a customizable loss for retrieval models in recommender systems. In _Proceedings of the 31st ACM International Conference on Information & Knowledge Management_.
* Van Den Oord et al. (2017) Aaron Van Den Oord, Oriol Vinyals, et al. 2017. Neural discrete representation learning. _Advances in Neural Information Processing Systems_ (2017).
* Vgsel et al. (2016) Christophe Van Gysel, Maarten de Rijke, and Evangelos Kanoulas. 2016. Learning latent vector spaces for product search. In _Proceedings of the 28th ACM international on conference on information and knowledge management_.

* [49] Christophe Van Gysel, Maarten de Rijke, and Evangelos Kanoulas. 2017. Semantic entity retrieval toolkit. _arXiv preprint arXiv:1706.07577_ (2017).
* [50] Feng Wang, Jian Cheng, Weiyang Liu, and Haijun Liu. 2018. Additive margin softmax for face verification. _IEEE Signal Processing Letters_ (2018).
* [51] Feng Wang and Hauping Liu. 2011. Understanding the behaviour of contrastive loss. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition_.
* [52] Hao Wang, Naiyan Wang, and Di-Yan Yeung. 2015. Collaborative deep learning for recommender systems. In _Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining_.
* [53] Jun Wang, Lantao Tu, Weinan Zhang, Yu Gong, Tinghui Xu, Benyou Wang, Peng Zhang, and Dell Zhang. 2017. Irgen: A minimax game for unifying generative and discriminative information retrieval models. In _Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval_.
* [54] Jurgen Wang, Jieming Zhu, and Xiuqiang He. 2021. Cross-batch negative sampling for training two-text recommenders. In _Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval_.
* [55] Yiwei Wei, Xiang Wang, Liqiang Nie, Xiangnan He, Richang Hong, and Tat-Seng Chua. 2019. MMGCN: Multi-modal graph convolution network for personalized recommendation of micro-video. In _Proceedings of the 27th ACM international conference on multimedia_.
* [56] Ji Yang, Xiuqiu, Diedery Alsing, Liechu Tang, Yang Li, Simon Xiaoming Wang, Tahai Xu, and Ed H Chi. 2020. Mixed negative sampling for learning two-tower neural networks in recommendations. In _Companion proceedings of the web conference_.
* [57] Xingyu Yi, Jieming Liu, Hanong, Derek Zhiyuan Cheng, Lukasz Heldt, Aditree Kumbleek, Zhe Zhao, Li Wei, and Ed Chi. 2019. Sampling-bias-corrected neural modeling for large corpus item recommendations. In _Proceedings of the 12th ACM conference on recommender systems_.
* [58] Weinan Zhang, Tianqi Chen, Jun Wang, and Jong Yu. 2013. Optimizing top-n collaborative filtering via dynamic negative item sampling. In _Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval_.
* [59] Xiangyu Zhao, Haochen Liu, Wenqi Fan, Hui Liu, Jiliang Tang, and Chong Wang. 2021. Autobox: Automated loss function search in recommendations. In _Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining_.
* [60] Xin Zhou, Hongyu Zhou, Yong Liu, Zhiwei Zeng, Chunyan Miao, Pengwei Wang, Yuan You, and Feijun Jiang. 2023. Bootstrap latent representations for multi-modal recommendation. In _Proceedings of the ACM Web Conference 2023_.

## Appendix A Graph Construction

For each dataset, we pretrain a heterogeneous graph network [32] based on user behaviors. The types of graph nodes include user, item, and its side information (brand / category / price features for Amazon Review dataset, tag / statistical features for Pixel-Rec dataset and brand / shop / category for industrial datasets). The graph edges include: 1) user-item edge. If user \(u\) clicks item \(i\), there is an edge between \(u\) and \(i\). 2) user-side information edge. If user \(u\) clicks an item with side information \(v\) (e.g., shop), there is an edge between \(u\) and \(v\). 3) item-item edge. If item \(i\) and item \(j\) are adjacent in user behavior sequence and the time interval between item \(i\) and item \(j\) is within 60 seconds, there is an edge between \(i\) and \(j\). 4) item-side information edge. If item \(i\) has a side info \(v\), there is an edge between \(i\) and \(v\).

## Appendix B Parameter Settings

In this section, we elaborate on the parameter settings for the implementation of our algorithm. The training process is implemented using a distributed TensorFlow[1] platform, consisting of 10 parameter servers and 40 workers with 12 CPUs per worker. In the negative sampling process, for each in-batch positive sample, we randomly select \(m_{c}=2\) clusters and then draw \(m_{n}=5\) negative samples from each of these clusters. In contrast, the baseline model selects 10 negative samples randomly for each positive sample. These negatives are sampled based on an online sampling framework in the training process and shared across the batch. Additionally, the interpolation coefficient \(\lambda\) of hard negatives is set to 0.1 for a harder interpolation and -0.1 for a easier interpolation. The rest of the hyperparameters settings are demonstrated in Table 5.

\begin{table}
\begin{tabular}{c|c} Hyper-parameter & Choice \\ \hline \(B\) & 512 & 1128 \\ \(\tau\) & 0.05 & 1208 \\ \(d_{k}\) & 64 & 1180 \\ \(d_{m}\) & 512 & 1131 \\ \(K_{p}\) & 300 & 1132 \\ \(K_{s}\) & 15 & 1138 \\ \(\beta_{1}\) & 2.0 & 1136 \\ \(\beta_{2}\) & 2.0 & 1138 \\ \(\beta_{3}\) & 2.0 & 1136 \\ \(\eta\) & 0.6 & 1137 \\ Optimizer & Adam & 1138 \\ Learning rate & 0.0002 & 1139 \\ Amazon modal emb size & Img: 4096, Text:384, Graph:128 & 1180 \\ PixelRec modal emb size & Img: 1024, Text:1024, Graph:1024 & 1130 \\ \#A1-\#A4 modal emb size & Img: 1024, Text:1024, Graph:1024 & 1130 \\ \hline \end{tabular}
\end{table}
Table 5. Hyper-parameter settings of Our ESANS.