[MISSING_PAGE_FAIL:1]

according to the current optimization context; and 2) optimizing the model based on this identified distribution. However, transferring this appealing technique to GNN-based recommendation poses two primary challenges:

**Challenge 1**: Current DRO methods are mainly applied in data with Euclidean structures (_e.g._, images(Wang et al., 2017; Wang et al., 2017; Wang et al., 2017; Wang et al., 2017), sentences(Wang et al., 2017)). Adapting them to manage graph-structured data remains an an open problem. More critically, the effect of graph structure is tangled with the complex graph neural networks, complicating the derivation of the hardest distribution within DRO.

**Challenge 2**: Another challenge arises from the typically sparse nature of recommendation data(Wang et al., 2017). With nodes often having limited neighbors, the feasible distribution family for DRO is inherently constrained, which might dampen its robustness and overall performance(Wang et al., 2017).

To bridge these gaps, we propose DR-GNN, a novel method that seamlessly integrates DRO into GNN-based recommendation. To address the first challenge, we harness insights from graph filtering theories(Golovin et al., 2011), recasting the GNN into an equivalent graph smoothing regularizer that penalizes the distance between adjacent nodes' embeddings. Through this perspective, we incorporate DRO into this regularizer, enhancing the GNN's robustness against shifts existing in neighbor distributions. For the second challenge, we propose a strategy to augment the observed neighbor distribution with slight perturbations. Notably, while DR-GNN does introduce intricate nested optimization, meticulous simplification ensures its implementation remains easy and efficient -- primarily drawing from similar nodes as new neighbors and adjusting edge weights according to embedding distances. Our rigorous theoretical analysis proves that if the divergence between training and testing distributions is bounded, the robustness of DR-GNN can be guaranteed.

Our contributions are summarized as follows:

* Exploring the less-explored task of GNN-based recommendation with distribution shift, and revealing the limitations and inadequacies of existing methods.
* Proposing a new GNN-based method DR-GNN for OOD recommendation, which seamlessly integrate DRO in GNN-based methods.
* Conducting extensive experiments to validate the superiority of the proposed method against three types of distribution shift (_i.e._, popularity shift, temporal shift and exposure shift).

## 2. Preliminary

In this section, we present the background of Graph-based Recommender System and Distributionally Robust Optimization.

### GNN-based Recommender Systems

Given a data of user-item interactions \(\mathcal{D}=\{u,i,r_{u,i}\mid u\in\mathcal{U},i\in I\}\), where \(\mathcal{U}\) denotes the set of users, \(\mathcal{I}\) denotes the set of items, and \(r_{u,i}=\{0,1\}\) indicates whether user \(u\) has interacted with item \(i\). We can represent user-item interaction data in the form of a bipartite graph \(\mathcal{G}=(\mathcal{V},\mathcal{E})\) where \(\mathcal{V}=\mathcal{U}\cup\mathcal{I}\) denotes the user/item nodes and \(\mathcal{E}\) denotes the edge set representing the interactions between users and items. Let \(A\in\mathbb{E}\left[\langle\mathcal{U}|+|I\rangle\right]\times\left[\langle \mathcal{U}|+|I\rangle\right]\) denote the adjacency matrix of graph \(\mathcal{G}\), where \(\Lambda_{u,i}=1\) if \(r_{ui}=1\), and \(\Lambda_{u,i}=0\) otherwise. Let \(N(u)=\{i\in I|\Lambda_{u,i}=1\}\) represents the item set that the user \(u\) has interacted with. We also define \(P_{u}\) as the distribution of the neighbors of \(u\), a uniform distribution over neighbors. Let \(d_{u}\) represent the degree of user \(u\). The goal of GNN-based RS is to learn high-quality embeddings from the graph \(\mathcal{G}\) and accordingly make accurate recommendations.

**LightGCN.** As a representative GNN-based recommendation methods, LightGCN learns user/item representations following the general message passing of GNNs. Nevertheless, it removes feature transformation and non-linear activations, as they tend to increase overfitting risks without enhancing performance. Let denote the embeddings of users and items as \(\mathbb{E}\in\mathbb{R}^{(|\mathcal{U}|+|I|)\times c}\) ( \(c\) is the dimension of representations). In LightGCN, the final embeddings were obtained via \(K\)-th propagation layers, which can be abstracted as:

\[\mathbb{E}^{(k)}=\widetilde{\mathbb{A}}\mathbb{E}^{(k-1)}, \tag{1}\]

where \(\mathbb{E}^{(k)}\) denotes the embeddings after \(k\)-th propagation layers and \(\widetilde{\Lambda}=\left(D^{-\frac{1}{2}}AD^{-\frac{1}{2}}\right)\) denotes as the normalized adjacency matrix. \(D\) is the diagonal node degree matrix. The notation \(\mathbb{L}\) denote the Laplacian matrix of graph \(\mathcal{G}\), _i.e._, \(\mathbb{L}=I-\widetilde{\Lambda}\).

To facilitate understanding, considering the prominence and widespread application of LightGCN, we simply take it as the backbone for analysis.

### Distributionally Robust Optimization

The machine learning model's success is based on the IID assumption, _i.e._, training data and testing data are drawn from the same distribution. However, the assumption fails to hold in many real-world applications, leading a sharp drop in performance. Distributionally Robust Optimization (DRO) addresses the issue by considering the uncertainty of the distribution. Specifically, instead of focusing on performance under a single observed data distribution, DRO aims to ensure that the model performs well across a range of potential data distributions. It first identifies the worst distribution(_i.e._,

Figure 1. The performance comparison of MF (Golovin et al., 2011) and LightGCN (Golovin et al., 2011) under both in-distribution (IID) and out-of-distribution (OOD) testing scenarios. For the OOD testing, here we introduce popularity shift in Yelp2018 and temporal shift in Movielens-1M. More details about experimental setting refer to section 4.

the loss function is maximized under the expectation of the worst-case distribution) in the family of distributions within a predefined range around the empirical data distribution, and then optimizes the objective function under that distribution, thereby ensuring the robustness of the model under unfavorable conditions. Formally, DRO is solved in a bi-level optimization via playing the min-max game on the objective function \(\mathcal{L}(x;\theta)\), in which \(x\) represents the data variable and \(\theta\) represents the model parameter to be optimized. The optimization objective of DRO is as follows:

\[\begin{split}&\hat{\theta}=\operatorname*{argmin}_{\theta}\left\{ \underset{P\in\mathbb{D}}{\max}\mathbb{E}_{x\sim P}\big{[}\mathcal{L}(x;\theta )\big{]}\right\}\\ &\mathbb{P}=\{P\in\mathbb{D}:D\left(P,P_{\theta}\right)\leq\eta\} \end{split} \tag{2}\]

where \(\mathbb{D}\) denotes the set of all distributions, \(\eta\) denotes robust radius. The _uncertainty set_\(\mathbb{P}\) is composed of all distributions within the robust radius distance from \(P_{\theta}\), and DRO tried to identify _the worst-case distribution_\(P^{*}\) from a family of eligible distributions \(\mathbb{P}\) by maximization. The function \(D(.,.)\) measures the distance between two distributions _e.g._, KL-divergence.

## 3. Methods

In this section, we detail the proposed DR-GNN (subsection 3.1.83.2), followed by the theoretical analyses to demonstrate its robustness (subsection 3.3). Finally, we discuss the connections our DR-GNN with existing methods (subsection 3.4). The schematic diagram of DR-GNN is depicted in Figure 4.

### Distributionally Robust GNN

It is highly challenging to directly apply DRO in GNN-based recommendation methods, as the graph structure is tangled with the complex GNN procedure. To tackle this problem, we draw inspiration from graph filtering theories(Golov et al., 2013) and recast the GNN into an equivalent graph smoothing regularizer.

**LightGCN as a Graph Smoothness Regularizer.** By analyzing LightGCN from the graph signal filtering perspective, we have the following important lemma:

**Lemma 1**.: _Performing graph aggregation in LightGCN is equivalent to optimizing the following graph smoothness regularizer using gradient descent with appropriate learning rate:_

\[\mathcal{L}_{smooth} =\frac{1}{2}\sum_{u}\mathbb{E}_{\theta\sim P_{u}}\left[d_{u}g(u, v;\theta)\right] \tag{3}\]

_Here, \(g(u,v;\theta)\) signifies the Fibonacci norm between the normalized embeddings, with \(\theta\) representing the model parameters. \(P_{u}\) denotes the distribution of the neighbor nodes of \(u\)._

The proof can be found in Appendix A.1. This lemma clearly elucidates the effect of the graph neural network - graph aggregation tend to draw the embeddings of neighbors closer. Moreover, the impact of distribution shifts on GNN are highlighted. Taking the popularity shift (_a.k.a._ popularity bias) as an example, user representations may become excessively aligned with popular items, thereby exacerbating the Matthew effect, as demonstrated in(Golov et al., 2013). For the convenience of subsequent analysis, we denote \(\mathcal{L}_{smooth}(u)=\mathbb{E}_{\theta\sim P_{u}}[d_{u}g(u,v;\theta)]\) as the smoothness regularizer on the specific node \(u\).

**Leveraging DRO in the Regularizer.** Holding the view of GNN as a regularizer, we further introduce DR-GNN, a model that incorporates DRO to enhance its robustness against distribution shifts. Following the definition of DRO Eq.(2), the objective function of the proposed DR-GNN can be formulated as:

\[\begin{split}\min_{\theta}\mathcal{L}_{DRO\_smooth}(u)& =\min_{\theta}\max_{P}\mathbb{E}_{\theta\sim P}\left[d_{u}g(u,v; \theta)\right]\\ &\text{s.t. }D_{KL}(P,P_{u})\leq\eta\end{split} \tag{4}\]

DR-GNN engages in a min-max optimization: 1) it identifies the most difficult distribution over a set of potential distributions. It is defined in the vicinity of the observed neighbor distribution subject to the constraint \(D_{KL}(P,P_{u})\leq\eta\); 2) Subsequently, the model's optimization is performed on this identified hardest distribution instead of original observed distribution. This strategy intrinsically incorporates potential distribution shifts during training, thereby naturally exhibits better robustness against distribution shifts. We will further validate this point in both theoretical analyses (Section 3.3) and empirical experiments (Section 4).

**Efficient Implementation.** Despite the promise, the objective of DR-GNN involves the complex nested optimization, which may incur heavily computational overhead. Fortunately, it can be largely simplified with the following lemma:

**Lemma 2**.: _The bi-level optimization problem of Eq.(5) can be transformed into optimizing:_

\[\min_{\theta}\mathcal{L}_{DRO\_smooth}(u)=\min_{\theta}\mathbb{E}_{\theta\sim P _{u}}\left[d_{u}g(u,v;\theta)\right] \tag{5}\]

_where \(\alpha\) represents the optimal Lagrange coefficient of the constraint \(D_{KL}(Q,P_{u})\leq\eta\), which can be regarded as a surrogate parameter of \(\eta\). The worst-case distribution \(P_{u}^{*}\) can be calculated as following_

\[P_{u}^{*}(o)=P_{u}(o)\frac{\exp\left(g(u,v;\theta)/\alpha\right)}{\mathbb{E}_ {\theta\sim P_{u}}\left[\exp(g(u,v;\theta)/\alpha)\right]} \tag{6}\]

The proof is placed in the appendix A.2. This lemma provides a close-formed expression of the most difficult distribution, greatly simplifying the implementation of DR-GNN. Specifically, modifications to the distribution of neighboring nodes can be simply realized

Figure 2. Illustration of how DR-GNN augments LightGCN: it gives edge weights during graph aggregation and introduces new nodes as neighbors.

through the alteration of edge weights within the graph. Formally, the normalized adjacency matrix of the graph \(\widetilde{\Lambda}\) is transformed into \(\widetilde{\Lambda}^{\prime}\) and

\[\widetilde{\Lambda}^{\prime}_{ij}=\frac{\exp{(g(i,j;\theta)/\alpha)}}{\sum_{k \in N(i)}\exp{(g(i,k;\theta)/\alpha)}}\widetilde{\Lambda}_{ij} \tag{8}\]

The adjusted normalized adjacency matrix \(\widetilde{\Lambda}^{\prime}\), characterized by modified weights, is subsequently utilized to execute the aggregation operation pertaining to the graph. Given the equivalence between the GNN and the regularizer, this can be integrated during graph aggregation, necessitating only minor adjustments to the edge weights. In practice, we may suffer numerical instability due to the introduce of \(\exp(.)\) in weights. To counteract this, we suggest to introduce the embedding normalization via \(L2\) norm in calculating the weights, empirically yielding more stable results.

### Graph Edge-Addition Strategy

Applying DRO in GNN-based recommendation incurs another challenge: Particularly, in DRO, all potential distributions \(P\) should share the same support as the original distribution \(P_{u}\), otherwise the KL-divergence would become infinite. This inherently implies that the support of \(P\) would be restricted to the neighboring nodes, excluding the vast pool of non-neighboring nodes. The situation exacerbates given the typically sparse nature of recommendation data - most users may only have interactions with a handful of items. This significantly limits the flexibility and scope of potential distributions, increasing the risk of missing testing distribution and thereby undermining model robustness.

To address aforementioned issue, we propose a strategy called Graph Edge-Addition(GEA) that introduces slight perturbations \(p_{u}^{add}\) in \(P_{u}\) to expand its support. \(p_{u}^{add}\) is defined over the support of all item set such that those non-neighboring nodes can be utilized for training better and robust embeddings. Formally, The objective of DR-GNN is improved as:

\[\begin{split}\mathcal{L}_{DRO\_smooth}(u)=\max_{P}\min_{P_{u}^{ new}}\mathbb{E}_{u\sim P}\left[d_{u}g(u,v;\theta)\right]\\ \text{s.t.}\quad D_{KL}(P,p_{u}^{new})\leq\eta\end{split} \tag{9}\]

where the new distribution \(p_{u}^{new}\) is defined as \(p_{u}^{new}=yP_{u}+(1-\gamma)p_{u}^{add}\), with \(\gamma\) serving as a hyperparameter that controls the magnitude of the perturbations. Remarkably, we adjust \(P_{u}\) towards minimization of regularizer rather than maximization. This is premised on the belief that a non-neighboring item, which exhibits greater similarity to user \(u\), is more likely to be favored by the user. Such items are potentially useful in refining user embeddings.

The introduce of \(p_{u}^{add}\) mitigates the inherent shortcomings of DRO in sparse recommendation datasets. It extends the range of potential distributions and harnesses the abundant information from non-neighboring nodes. Practically, the minimization optimization on \(p_{u}^{new}\) can be formulated into finding the items minimizing \(g(u,v;\theta)\). However, it can be computationally expensive, as it requires traversing over all nodes. To mitigate computational complexity, we employ a strategy of random sampling. Specifically, we select a subset of nodes randomly to form a candidate set, and then confine the traversal operation solely to this subset.

### Theoretical Analyses

In this subsection, we provide a theoretical analysis to demonstrate the robustness of DR-GNN to distribution shift. For any user \(u\), let \(p_{u}^{add}\) denotes \(u\)'s ideal neighbor distribution used for model testing and the corresponding smoothness regularizer for node \(u\) can be written as \(\mathcal{L}_{ideal}(u;\theta)=\mathbb{E}_{u\sim p_{u}^{add}}\left[d_{u}g(u,v; \theta)\right]\).

**Theorem 3.1**.: _Let \(\widetilde{\mathcal{L}}_{DRO\_smooth}(u;\theta)\) serve as the estimation for \(\mathcal{L}_{DRO\_smooth}(u;\theta)\). If \(D_{KL}(P_{u}^{ideal},P_{u})\leq\eta\), then we have that with probability at least \(1-\delta\):_

\[\mathcal{L}_{ideal}(u;\theta)\leq\widetilde{\mathcal{L}}_{DRO\_smooth}(u; \theta)+\mathcal{B}(q,d_{u},\delta) \tag{10}\]

_where \(\mathcal{B}(q,d_{u},\delta)=\sqrt{\frac{g_{u}g_{u}(\frac{1}{d_{u}})+8\log\frac{ \delta}{\delta}}{d_{u}}}\) and \(q\) is the Vapnik Chern-vonenkis dimension of the hypothesis space of parameter \(\theta\)._

The proof is presented in appendix A.3. Theorem 3.1 exhibits that the ideal loss is upper bound by empirical DRO loss if a sufficiently large data size is employed. At this point, we provide the theoretical guarantee for the resistance to distribution shift capability of DR-GNN.

### Discussions

**The connection with APDA(Sen et al., 2017).** Interestingly, the edge weights introduced in our DR-GNN is highly similar with APDA. The key distinction lies in our choice to use initial embeddings for weight calculation, while APDA uses embeddings with multi-layer aggregation. This seemingly minor difference leads to a pronounced performance disparity in favor of DR-GNN over APDA in our experiments. The reason behind this is the theoretical grounding of our approach. Specifically, DR-GNN is derived from the theoretical-sound DRO framework, while APDA's design is predominantly heuristic and lacks a solid theoretical base.

Furthermore, our framework offers theoretical insights into several heuristic settings found in APDA:

Our framework also gives a theoretical explanations of many heretical settings used in APDA: 1) Operations such as the exponential function and symmetric normalization, which are adopted heuristically in APDA, can be indeed derived to the DRO objective. 2) APDA also heuristically employs a hyperparamter \(\alpha\) to modulate the magnitude of the value in \(\exp()\)1. In the context of DR-GNN, this \(\alpha\) finds its theoretical counterpart \(-\alpha\) serves as a Lagrange multiplier, acting as a surrogate hyperparameter to control the robust radius. We will discuss in depth the role of \(\alpha\) and its relationship with the degree of distribution shift in section4.3.

Footnote 1: It’s worth noting that this was not explicitly mentioned in their paper but was clearly implemented in their codes.

**The connection with Attention Mechanism(Sen et al., 2017).** The attention mechanism has been adopted by recent work like Graph Attention Network (GAT) (Sen et al., 2017) to determine the edge weights. These weights in GAT, similar to ours, are predicated on node embeddings. However, there's a stark difference: while GAT employs a learnable non-linear layer to ascertain the weights, the weights in our DR-GNN are derived directly from DRO.

Despite the success of the attention mechanism across various domains, it underperforms in GNN-based recommendation. The primary reason lies in the sparsity and the lack of rich features of recommendation data. It heavily hinders the effective training of the attention function. This limitation is evident in our experimental results: GAT demonstrates suboptimal performance, while our DR-GNN exhibits effectiveness.

**The connection with GraphDA(Chen et al., 2019)** GraphDA is a method that enhances the adjacency matrix of a graph. This method initially pretrains a graph encoder to obtain the user/item embeddings following several iterations of graph convolution. Subsequently, the graph is reconstructed based on the similarity between these embeddings. This process facilitates denoising for active users and augmentating for inactive users. With the enhanced graph adjacency matrix, GraphDA retrains a randomly initialized graph encoder. Contrasting with GraphDA, the edge-adding operation in DR-GNN also reconstructs a new adjacency matrix, but with different motivations. The primary objective of GraphDA's graph enhancement is to equalize the number of neighbors for each node. This is achieved by denoising users with an excess of neighbors in the original data and augmenting users with a paucity of neighbors. Furthermore, GraphDA preemptively introduces edges between user-to-user and item-to-item to enable long-distance message passing. However, the integration of the GAE module aims to broaden the support of neighbor distribution. This expansion subsequently expand the uncertainty set of DRO, thereby endowing the model with enhanced generalization capabilities.

## 4. Experiments

We aim to answer the following research questions:

* **RQ1:** How does DR-GNN perform compared with existing methods under various distribution shifts?
* **RQ2:** What are the impacts of the components (e.g., DRO on neighbour nodes, GEA) on DR-GNN?
* **RQ3:** How does the parameter \(\alpha\) impacts DR-GNN?

**Datasets.** The experiments are conducted under three prevalent distribution shift scenarios: popularity shift, temporal shift, and exposure shift. Thus, eight datasets are employed for testing, namely Gowalla, Douban, AmazonBook, Yelp2018, Movielens-1M, Food, Coat, and Yahoo. For the popularity shift setting, we re-divide the train and test set of the dataset based on item popularity. The test set was designed in such a way that the popularity of all items approximated a uniform distribution, while a long-tail distribution was preserved within the training set. For the datasets under the temporal shift setting, we took the most recent 20% of interaction data from each user as the test set, and the earliest 60% of interaction data as the training set. Table 5 in appendix A.3 shows the statistics of each processed dataset.

**Baselines.** We use the conventional LightGCN as backbone and BPR loss for all the baselines. The methods compared in the study fall into several categories:

* **Methods against distribution shifts in Recommendation System(InvCF(Zhou et al., 2019), BOD(Wang et al., 2019))** InvCF is the SOTA method on addressing the popularity shift through invariant learning. BOD achieves data denoising through bi-level optimization. Meanwhile, we acknowledge that there are some other methods to address the COD problem, including CausPref(Zhou et al., 2019), COR(Yang et al., 2019), HIRL(Wang et al., 2019), and InvPref(Wang et al., 2019). However, these methods require additional information that is not available in our dataset and hence cannot be tested. Certain methods among these necessitate pre-partitioned environmental datasets(Wang et al., 2019), others demand prior semantic information about users and items(Zhou et al., 2019; Wang et al., 2019), and some necessitate the assignment of environmental variables for each interaction, thereby rendering the strategy of random negative sampling inapplicable(Wang et al., 2019).
* **Graph contrastive learning methods(LightGCCL(Chen et al., 2019), SGL(Zhou et al., 2019))**. The methods use the contrastive learning on the graph and has been proven to alleviate the prevalent popularity bias.
* **Reconstructing the adjacency matrix methods(APDA(Wang et al., 2019), GAT(Wang et al., 2019), GraphDA(Chen et al., 2019))** Such methods reconstruct the adjacency matrix of the graph by adjusting edge weights or reconstructing the edges between nodes according to certain rules. Moreover, APDA and GAT can experience memory overflow issues on datasets with a large number of interactions. This is because GAT needs to calculate weights for each edge and perform backpropagation, while APDA needs to calculate weights for each layer of aggregation operations.

We used the source code provided in the original papers and searched for optimal hyperparameters for all comparison methods according to the instructions in the original papers.

**Evaluation Metrics.** Three commonly used metrics--Precision@_K_, Recall@_K_, and Normalized Discounted Cumulative Gain(NDCG@_K_) -- are used to assess the quality of the recommendations, with \(K\) being set by default at 20.

Further experimental details are presented in the appendixA.5.

### Performance Comparison (RQ1 and RQ2)

In this section, we analyze the superior of DR-GNN under different distribution shift setting as compared with other baselines.

#### 4.1.1. Evaluations on Popularity Shift Setting

Table 1 reports the comparison of performance on all the baselines under popularity shift. The majority of comparative methodologies fail to consistently yield satisfactory results across a variety of datasets, including algorithms specifically designed for popularity shift, such as APDA and InvCF. The improvement of APDA compared to LightGCN is quite limited, indicating that its heuristic dynamic edge weight adjustment algorithm cannot handle popularity shift well.

Figure 3. t-SNE Visualization on Douban. DR-GNN ensures that the representations of hot items and cold items are almost distributed in the same space.

Meanwhile, GAT, which also dynamically adjusts edge weights, performs much worse than LightGCN, suggesting that the attention mechanism may inadvertently intensify the impact of distribution shift. Our proposed method, DR-GNN, consistently and significantly surpasses the state-of-the-art benchmarks across all popularity shift datasets. The robustness of DR-GNN is ascribed to the incorporation of uncertainty inherent in observed data distributions by DRO. This feature enables the model to perform optimally under various environments, rather than solely relying on training data.

**Visualization Results.** As shown in Figure 3, to better understand how DR-GNN handles distribution shift, we perform t-SNE visualization(Maaten and Hinton, 2008) of the item embeddings on the Douban dataset. According to the ranking results of item popularity, the top 5% most popular items are selected as hot items and the bottom 5% as cold items. It can be observed that in the representations learned by LightGCN, there is a clear gap between hot items and cold items, while both are distributed in the same space in the representations learned by DR-GNN. This suggests that DR-GNN eliminate the impact of distribution shift caused by popularity shift.

#### 4.1.2. Evaluations on Temporal Shift Setting

Temporal bias takes into account changes in user interests over time. It is more complex than the distribution shift caused by popularity, as it encompasses factors beyond popularity alone. We simulate temporal bias by dividing training and test sets for each user according to the timestamp of the interaction. Dataset Food and Movielens-1M are used in this setting.

In the context of the temporal shift setting, we noticed that on the Movielens-1M dataset, although APDA performed better than DR-GNN, the improvement is not significant, and its performance was relatively unstable, evidenced by its inferior performance compared to LightGCN on the Food dataset. Similar observations were made for GraphDA. Compared to most other benchmark methods, DR-GNN continues to consistently deliver good performance.

#### 4.1.3. Evaluations on Exposure Shift Setting

In practical contexts, users are typically exposed to a limited subset of items, thereby neglecting a significant majority. This phenomenon named "exposure bias" suggests that the absence of user interaction with specific items does not unequivocally signify their disinterest. Consequently, in real-world datasets, the patterns of missing user interaction records are not randomly distributed, but rather, they are "missing-not-at-random". Here we conduct experiments on widely used missing-complete-at-random datasets: Yahoo and Coat.

\begin{table}
\begin{tabular}{l|c c c|c c c|c c c|c c c} \hline  & & \multicolumn{3}{c|}{Gowalla} & \multicolumn{3}{c|}{Douban} & \multicolumn{3}{c|}{Amazon-Book} & \multicolumn{3}{c}{Yelp2018} \\ \hline  & NDCG & Precision & Recall & NDCG & Precision & Recall & NDCG & Precision & Recall & NDCG & Precision & Recall \\ \hline LightGCN(SIGIR20) & 0.0369 & 0.0170 & 0.0563 & 0.0792 & 0.0510 & 0.0723 & 0.0227 & 0.0129 & 0.0278 & 0.0136 & 0.0060 & 0.0221 & 685 \\ LightGCL(CLR23) & 0.0380 & 0.0177 & 0.0593 & 0.0746 & 0.0464 & 0.0721 & 0.0243 & 0.0137 & 0.0305 & 0.0136 & 0.0061 & 0.0227 & 686 \\ SoftS(SIGIR21) & 0.0381 & 0.0173 & 0.0595 & 0.0773 & 0.0493 & 0.0716 & 0.0232 & 0.0131 & 0.0296 & 0.0143 & 0.0063 & 0.0242 & 647 \\ InvCF(WWW23) & 0.0399 & 0.0181 & 0.0636 & 0.0740 & 0.0459 & 0.0725 & 0.0210 & 0.0118 & 0.0268 & 0.0144 & 0.0062 & 0.0243 & 649 \\ BOD(KDD23) & 0.0361 & 0.0169 & 0.0556 & 0.0815 & 0.0559 & 0.0686 & 0.0253 & 0.0141 & 0.0315 & 0.0145 & 0.0061 & 0.0253 & 690 \\ APDA(SIGIR23) & 0.0367 & 0.0168 & 0.0579 & OOM & OOM & OOM & OOM & OOM & OOM & OOM & 600 & 61 \\ GAT(ICLR18) & 0.0227 & 0.0104 & 0.0334 & OOM & OOM & OOM & OOM & OOM & OOM & OOM & OOM & 622 \\ GraphDA(SIGIR23) & 0.0341 & 0.0166 & 0.0570 & 0.0892 & 0.0596 & 0.0808 & 0.0199 & 0.0113 & 0.0262 & 0.0140 & 0.0059 & 0.0243 & 633 \\ DR-GNN & **0.0517** & **0.0238** & **0.0774** & **0.1044** & **0.0704** & **0.0905** & **0.0327** & **0.0183** & **0.0102** & **0.0193** & **0.0086** & **0.0322** & 648 \\ \hline \end{tabular}
\end{table}
Table 1. The performance comparison on popularity shift datasets using LightGCN backbone. The best result is bolded and the runner-up is underlined. OOM stands for out of memory.

\begin{table}
\begin{tabular}{l|c c c|c c c} \hline  & \multicolumn{3}{c|}{Coat} & \multicolumn{3}{c}{Yahoo} \\ \hline  & NDCG & Precision & Recall & NDCG & Precision & Recall \\ \hline LightGCN & 0.0802 & 0.0243 & 0.1576 & 0.0736 & 0.0118 & 0.1504 \\ LightGCL & 0.0839 & 0.0243 & 0.1577 & 0.0734 & 0.0118 & 0.1476 & 0.0547 \\ SGL & 0.0839 & 0.0245 & 0.1631 & 0.0740 & 0.0122 & 0.1548 \\ InvCF & 0.0842 & 0.0241 & 0.1668 & 0.0742 & 0.0122 & 0.1539 & 667 \\ BOD & 0.0817 & 0.0219 & 0.1542 & **0.0816** & 0.0115 & 0.1481 & 647 \\ APDA & 0.0821 & 0.0243 & 0.1706 & 0.0756 & 0.0124 & 0.1588 & 648 \\ GAT & 0.0836 & 0.0243 & 0.1633 & 0.0722 & 0.0119 & 0.1500 & 649 \\ GraphDA & 0.0847 & 0.0245 & 0.1641 & 0.0748 & 0.0117 & 0.1528 & 670 \\ DR-GNN & **0.0874** & **0.0255** & **0.1744** & 0.0774 & **0.0126** & **0.1624** & 6121 \\ \hline \end{tabular}
\end{table}
Table 2. The performance comparison on temporal shift datasets using LightGCN backbone. The best result is bolded and the runner-up is underlined.

\begin{table}
\begin{tabular}{l|c c c|c c c} \hline  & \multicolumn{3}{c|}{Coat} & \multicolumn{3}{c}{Yahoo} \\ \hline  & NDCG & Precision & Recall & NDCG & Precision & Recall \\ \hline LightGCN & 0.0802 & 0.0243 & 0.1576 & 0.0736 & 0.0118 & 0.1504 \\ LightGCL & 0.0839 & 0.0243 & 0.1577 & 0.0734 & 0.0118 & 0.1476 \\ SGL & 0.0839 & 0.0245 & 0.1631 & 0.0740 & 0.0122 & 0.1548 \\ InvCF & 0.0842 & 0.0241 & 0.1668 & 0.0742 & 0.0122 & 0.1539 \\ BOD & 0.0817 & 0.0219 & 0.1542 & **0.0816** & 0.0115 & 0.1481 & 647 \\ APDA & 0.0821 & 0.0243 & 0.1706 & 0.0756 & 0.0124 & 0.1588 & 648 \\ GAT & 0.0836 & 0.0243 & 0.1633 & 0.0722 & 0.0119 & 0.1500 & 649 \\ GraphDA & 0.0847 & 0.0245 & 0.1641 & 0.0748 & 0.0117 & 0.1528 & 670 \\ DR-GNN & **0.0874** & **0.0255** & **0.1744** & 0.0774 & **0.0126** & **0.1624** & 6121 \\ \hline \end{tabular}
\end{table}
Table 3. The performance comparison on exposure shift datasets using LightGCN backbone. The best result is bolded and the runner-up is underlined.

According to table 3, DR-GNN can also handle distribution shift caused by exposure bias well. Besides, we noticed that on the Yahoo dataset, BOD's NDCG metric surpasses other comparison methods, but it is weaker than LightGCN in terms of Precision and Recall metrics. We believe this might be due to BOD's weight adjustment strategy overfitting to certain interactions, causing them to rank higher, which leads the recommendation model to concentrate too much on a few highly relevant results. Furthermore, BOD's performance on the coat dataset is only slightly better than LightGCN, indicating that its performance is not stable.

The experiments under the aforementioned three settings demonstrate that our method can handle different types of distribution shifts.

### Ablation Study (RQ3)

We conducted an ablation study to investigate the effects of different modules in DR-GNN, including the DRO and GEA modules. We compared the DR-GNN with its two variants "DR-GNN w/o DRO" and "DR-GNN w/o GEA" based on whether the DRO and GEA modules were enabled. The results in Table 4 demonstrate that the use of DRO for graph aggregation operations can significantly enhance the model's performance, and GEA further improves the model's effectiveness. Surprisingly, we also found that the simple use of GEA could also yield some gains. This may be attributed to the additional edges introduced by GEA, which have accelerated the convergence of smoothness regularization. The ablation study highlights the fact that all modules in DR-GNN can boost the model's learning.

### Role of the parameter \(\alpha\) (RQ4)

The parameter \(\alpha\) in Eq.(7) plays an important role in the DRO. Based on the previous derivation, the role of \(\alpha\) is to control the size of uncertainty set. A smaller \(\alpha\) indicates a larger uncertainty set for optimizing. However, an excessively large search space can easily lead to model overfitting. As \(\alpha\) tends towards zero, DRO will excessively amplify the weight of the node with the maximum smooth regularization loss, which can easily lead to overfitting to the meaningless distribution. When \(\alpha\) is infinitely large, the worst-case distribution tends towards a uniform distribution. At this point, DR-GNN without GEA is equivalent to LightGCN. Therefore, \(\alpha\) is an important hyperparameter that needs to be carefully tuned. Different values need to be set depending on the degree of distribution shift in the dataset. Empirically, we search for \(\alpha\) within the range of \([0,1]\).

Besides, we empirically verified the relationship between the optimal \(\alpha\) and the degree of distribution shift on the popularity shift dataset. We utilize the KL-divergence between item frequencies as a metric to measure the degree of distribution shift between the training and testing sets, and then tried to train the model by tuning different \(\alpha\) parameters. Figure 4(a) shows the NDCG performance of DR-GNN with different \(\alpha\) under varying degrees of popularity shift in different datasets. It can be observed that either excessively large or small \(\alpha\) can impact the performance, and the optimal value varies across different datasets. In Figure 4(b), we further quantified the distribution shift using KL divergence. It was found that datasets with a larger degree of shift require a smaller optimal \(\alpha\), as they necessitate a larger uncertainty set. This corresponds to our previous explanation.

## 5. Related Work

### GNN-based Recommender System

In recent years, graph-based recommendation systems have attracted extensive attention and research. Such systems leverage the structure of graphs to discover and infer user preferences and interests, thereby providing more personalized and accurate recommendations. Compared to the traditional collaborative filtering method that only use first order information of node, the GNN can capture higher order signal in the interactions by aggregating the information from neighboring nodes. LightGCN(Li et al., 2019) simplify the original stucture of GCN(Li et al., 2019) by dropping the feature transformation nonlinear activation and self-connection. NIA-GCN(Zhou et al., 2019) improves the aggregation way in the GCN. They use PNA aggregator to model more complex interactions in the graph data.

Contrastive learning has also been extensively applied in graph-based recommendation models. SGL(Wang et al., 2019) applies data augmentation to graph-structured data through node dropout, edge dropout and random walk, and constructs the positive and negative pairs using the different views of the nodes' embedding. Other CL-based recommenders mainly improve the way of augmenting the graph.

\begin{table}
\begin{tabular}{l|l|c c c} \hline \hline Dataset & Method & NDCG & Precision & Recall \\ \hline \multirow{4}{*}{Gowalla} & LightGCN & 0.0369 & 0.0170 & 0.0563 \\  & DR-GNN w/o DRO & 0.0391 & 0.0174 & 0.0583 \\  & DR-GNN w/o GEA & 0.0494 & 0.0231 & 0.0761 \\  & DR-GNN & **0.0517** & **0.0238** & **0.0774** \\ \hline \multirow{4}{*}{Yelp2018} & LightGCN & 0.0136 & 0.0060 & 0.0221 \\  & DR-GNN w/o DRO & 0.0161 & 0.0070 & 0.0265 \\ \cline{1-1}  & DR-GNN w/o GEA & 0.0182 & 0.0081 & 0.0305 \\ \cline{1-1}  & DR-GNN & **0.0193** & **0.0086** & **0.0322** \\ \hline \hline \end{tabular}
\end{table}
Table 4. Ablation Study on Gowalla and Yelp2018

Figure 4. Analysis of the role of \(\alpha\). (a) Left: The performance of DR-GNN in terms of NDCG across different \(\alpha\) on three datasets with varying degrees of distribution shift. (b) Right: The relationship between the degree of distribution shift and the optimal \(\alpha\).

LightGCL(Chen et al., 2019) uses SVD to generate new graph structures, which emphasizes the important signal in the user/item interactions. SimGCL(Shi et al., 2019) and XSimGCL(Xu et al., 2019) uses the random noise-based data augmentation on embeddings avoiding the popularity bias by making features more uniformly distributed.

Some methods are designed to target the OOD problem on GNN-based recommendation models. APDA(Zhou et al., 2019) dynamically adjusts the edge weights of the graph, reducing the impact of popular items while amplifying the influence of unpopular items. GraphDA(Chen et al., 2019) reconstructs the adjacency matrix of the graph through a pre-trained encoder, thereby achieving signal augmentation and denoising within the graph. RGCF(Chen et al., 2019) improves graph structure learning by identifying more reliable message-passing interactions, while simultaneously maintaining the diversity of the enhanced data.

Despite these efforts, the aforementioned methods can only address specific types of OOD problems, that is, they only focus on the distribution shift resulting from certain specific factors, such as noise and popularity bias, hence are not generic. Moreover, these methods are mostly based on heuristic rule design and lack theoretical guarantees.

### OOD in Recommender System

When training models, it is a common assumption that test data originates from the same distribution as the training data. However, in real-world scenarios, models may encounter test data that deviates from the distribution of the training data - a phenomenon known as Out-of-Distribution. The presence of OOD data can potentially precipitate a degradation in the model's performance. There are many methods used to solve the OOD problem in recommender systems.

One category of methodologies endeavors to alleviate the impact of distribution shift through the identification of invariant components within embeddings. InvCF(Shi et al., 2019) effectively mitigates the impact of popularity shifts by incorporating an auxiliary classifier that formulates recommendations predicated on popularity. InvPref(Shi et al., 2019) and HIRL(Luo et al., 2019) seperate the dataset into multiple environments by attributing an environment variable to each interaction and then leverage invariant learning to automatically identify elements that remain constant irrespective of the environment. Some of the works employ causal learning in addressing the OOD problem. COR(Zhou et al., 2019) uses causal graph modeling and counterfactual reasoning to address the effect of out-of-date interactions. CausPref(Shi et al., 2019) utilizes a differentiable causal graph learning approach to obtain the invariant user preferences. Other works, such as BOD(Wang et al., 2019) applies bi-level optimization to ascertain the weight for each interaction to negate the effects of noisy interactions.

However, the kind of works are not specifically designed for GNN-based recommender system and thus fail to address the impact of distribution shifts on the structure of the graph models themselves.

### Distributionally Robust Optimization

Distributionally Robust Optimization is a method for addressing OOD problems. The primary goal of DRO is to find a solution that is not only optimal for the given data distribution but also robust against variations in the data distribution, i.e. the family of distributions consisting of all distributions within a certain distance from the current data distribution. Many measures of distribution distance are used in DRO, including KL-divergence(Krizhevsky et al., 2009), Wasserstein-distance(Srivastava et al., 2014), MMD distance(Munroul et al., 2016). It has been found that DRO tends to induce model overfitting to the noisy samples(Shi et al., 2019) and GroupDRO(Shi et al., 2019) was introduced to address this issue.

DRO has also been applied in the field of RS. S-DRO(Shi et al., 2019) categorizes users into different groups based on the popularity of the items they interact with, and then employs group DRO to improve long-term fairness for disadvantaged subgroups. DROS(Shi et al., 2019) applies DRO to sequential recommendation tasks to address the OOD problem in the streaming of recommendation data. These methods are not used on GNN-based RS.

Some research has explored the application of DRO on GNN(Chen et al., 2019; Chen et al., 2019; Chen et al., 2019). On one hand, these methods fundamentally aim to address distributional shifts caused by noise in node embeddings, which is distinct from our approach that considers distributional shifts within the graph's topological structure. On the other hand, these methods are not applied in recommendation systems and do not take into account the challenges posed by the unique characteristics of recommendation datasets when applying DRO.

## 6. Conclusion

This paper proposes an method DR-GNN, which introduces DRO into the aggregation operation of GNN, to solve the problem of existing graph-based recommendation systems being easily affected by distribution shift. Based on comparative experiments under multiple datasets and settings, as well as visualization studies on real datasets, DR-GNN has been proven to effectively solve the distribution shift problem, enhancing the robustness of graph models.

A direction worthy of exploration in future work is the application of DRO based on other distance metrics, such as the Wasserstein distance, MMD distance, etc., to address some of the shortcomings of the KL divergence-based DRO discussed in this paper. We believe that DR-GNN could provide a new perspective for future work aimed at enhancing graph-based RS robustness.

## References

* R. van den Berg, T. N. Kipf, and M. Welling (2017)Graph convolutional matrix completion. arXiv preprint arXiv:1706.02283. Cited by: SS1.
* A. Blumez, A. Ehrenfeucht, D. Hausler, and M. K. Warmuth (1989)Learning to detect and quantify the graph-theoretic dimension. Journal of the ACM (JACM)36 (4), pp. 929-965. Cited by: SS1.
* X. Cai, C. Huang, L. Xia, and X. Ren (2023)LightGCL: simple yet effective graph contrastive learning for recommendation. Note: [https://doi.org/10.48550/arXiv:2302.08391v1](https://doi.org/10.48550/arXiv:2302.08391v1) arXiv:2302.08191 [cs] External Links: Link Cited by: SS1.
* C. Chen, C. Huang, C. Tang, and Y. Yuan (2019)Chall-motive similarity embedding for recommender systems. In The World Wide Web Conference, pp. 2637-2643. Cited by: SS1.
* J. Chen, C. Dong, Y. Wang, F. Feng, M. Wang, and X. He (2023)Blair and debias in recommender systems: a survey and future directions. ACM Transactions on Information Systems 31 (3), pp. 1-39. Cited by: SS1.
* S. Chen, K. Ding, and S. Zhu (2023)Uncertainty-aware robust learning on noisy graphs. arXiv preprint arXiv:2306.02102. Cited by: SS1.
* W. Fan, Y. Ma, Q. Li, L. Liu, D. Tang, and D. Yin (2019)Graph neural networks for social recommendation. In The world wide web conference on Internet of Things, pp. 417-426. Cited by: SS1.
* Z. Fan, K. Xu, Z. Dong, H. Peng, J. Zhang, and P. S. Yu (2023)Graph collaborative signals denoising and augmentation for recommendation. In Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR '23, New York, NY, USA, pp. 2037-2041. External Links: ISBN 978-1-4503-3599-1, Link, Document Cited by: SS1.

* Gao et al. (2023) Chongming Gao, Kexin Huang, Jiawei Chen, Yuan Zhang, Shao Li, Peng Jiang, Shiqi Wang, Zhong Zhang, and Xiangnan He. 2023. Alleviating Matthew Effect of Offline Reinforcement Learning in Interactive Recommendation. _arXiv preprint arXiv:2307.04571_ (2023).
* He et al. (2020) Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. 2020. DebtGCN: Simplifying and Powering Graph Convolution Network for Recommendation. [https://doi.org/10.48550/arXiv:2002.02126](https://doi.org/10.48550/arXiv:2002.02126) [cs].
* He et al. (2017) Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In _Proceedings of the 26th international conference on world wide web_. 173-182.
* He et al. (2016) Xiangnan He, Hanwang Zhang, Min-Yen Kan, and Tat-Seng Chua. 2016. Fast matrix factorization for online recommendation with unified feedback. In _Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval_. 549-558.
* He et al. (2022) Yue He, Zizun Wang, Peng Cui, Hao Zou, Tufeng Zhang, Qiang Cui, and Yong Jiang. 2022. CusRF: Causal Preference Learning for Out-of-Distribution Recommendation. In _Proceedings of the ACM Web Conference_. 4022-410-421. [https://doi.org/10.1145/348547.311990](https://doi.org/10.1145/348547.311990) arXiv:2203.03984 [cs].
* He et al. (2022) Yue He, Zizun Wang, Peng Cui, Hao Zou, Tufeng Zhang, Qiang Cui, and Yong Jiang. 2022. Cusper: Causal preference learning for out-of-distribution recommendation. In _Proceedings of the ACM Web Conference_. 2022-410-421.
* Hu and Hong (2013) Zhaolin Hu and J. L. Jeff Hong. 2013. Kullback-Leibler divergence constrained distributionally robust optimization. _Available at Optimization Online_ 1, 2 (2013), 9.
* Kipf and Welling (2016) Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. _arXiv preprint arXiv:1609.02077_ (2016).
* Koren et al. (2009) Yudan Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization techniques for recommender systems. _Computer_ 42, 8 (2009), 30-37.
* Ma et al. (2021) Yao Ma, Xiaomi Liu, Tong Zhao, Yoren Li, Jiang Tang, and Neil Shah. 2021. A unified view on graph neural networks as graph signal denoising. In _Proceedings of the 30th ACM International Conference on Information & Knowledge Management_. 1202-1211.
* Martin and S Zemel (2000) Benjamin M Martin and Richard S Zemel. 2000. Collaborative prediction and ranking with non-random missing data. In _Proceedings of the third ACM conference on Recommender systems_. 5-12.
* Nikolopoulos and Karypisu (2019) Adamusan N Nikolopoulos and George Karypisu. 2019. Rewalk: Nearly uncoupled random walks for top-n recommendation. In _Proceedings of the twelfth ACM international conference on web search and data mining_. 150-158.
* Oren et al. (2019) Yonatan Oren, Shioi Sugawa, Tatsunori Hashimoto, and Percy Liang. 2019. Distributionally robust language modeling. _arXiv preprint arXiv:1908.02060_ (2019).
* Sadeghi et al. (2021) Alireza Sadeghi, Meng Ma, Bingcong Li, and Georgios B Giannakis. 2021. Distributionally robust semi-supervised learning over graphs. _arXiv preprint arXiv:2110.10382_ (2021).
* Sagawa et al. (2019) Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. 2019. Distributionally robust neural networks for group shifts: On the importance of regularization for word-case generalization. _arXiv preprint arXiv:1911.08731_ (2019).
* Schnabel et al. (2016) Tobias Schnabel, Adibi Swaminathan, Ahudeep Singh, Navin Chandak, and Thorsten Joachims. 2016. Recommendations as treatments: Debiasing learning and evaluation. In _international conference on machine learning_. PMLR, 1670-1679.
* Shafiezenadeh et al. (2015) Saerosh Shafiezenadeh, Eryram M Mohapifar Esfahani, and Daniel Kuhn. 2015. Distributionally robust logistic regression. _Advances in Neural Information Processing Systems_ 28 (2015).
* Sinha et al. (2017) Anna Sinha, Hongcook Namikong, Riccardo Vojfi, and John Duchi. 2017. Certifying some distributional robustness with principled adversarial training. _arXiv preprint arXiv:1701.10571_ (2017).
* Song et al. (2019) Weiqing Song, Zhixing Yao, Tian Wang, Laurent Charlin, Ming Zhang, and Jian Tang. 2019. Session-based social recommendation via dynamic graph attention networks. In _Proceedings of the Twelfth ACM international conference on web search and data mining_. 555-563.
* Stah and Jegelka (2014) Matthew Stah and Stefanie Jegelka. 2014. Distributionally robust optimization and generalization in kernel methods. _Advances in Neural Information Processing Systems_ 32 (2019).
* Sun et al. (2021) Jiaming Sun, Yingqi Zhang, Wei Guo, Huifeng Guo, Baiming Tang, Xinqiang He, Chen Ma, and Mark Coutes. 2020. Neighbor interaction aware graph convolution networks for recommendation. In _Proceedings of the 43rd international ACM SIGIR conference on research and development in information retrieval_. 1289-1298.
* Tan et al. (2020) Changpin Tan, Yeung Xie, Yain Liang, Nun Yang, and Wayne Xin Zhao. 2020. Learning to denoise unreliable interactions for graph collaborative filtering. In _Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval_. 122-132.
* Van der Maaten and Hinton (2008) Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. _Journal of machine learning research_ 9, 11 (2008).
* Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. _Advances in neural information processing systems_ 30 (2017).
* Velickovic et al. (2017) Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriano Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. _arXiv preprint arXiv:1710.10903_ (2017).
* Vojfi et al. (2018) Riccardo Vojfi, Hongwei Namkoong, Oana Sener, John Duchi, Vittorio Murino, and Silvio Savarese. 2018. Generalizing to unseen domains via adversarial data augmentation. _Advances in neural information processing systems_ 31 (2018).
* Wang et al. (2022) Serena Wang, Hatzikinska Narasimhan, Yichen Zhou, Sara Hooker, Michal L Litzksaki, and Aditya Krishna Memon. 2022. Robust distillation for worst-class performance. _arXiv preprint arXiv:22006.04979_ (2022).
* Wang et al. (2022) Wenjie Wang, Xinyu Liu, Fall Feng, Xiangnan He, Min Lin, and Tat-Seng Chua. 2022. Causal representation learning out-of-distribution recommendation. In _Proceedings of the ACM Web Conference_. 2022-3567-3571.
* Wang et al. (2019) Xiang Wang, Xiangnan He, Yisun Cao, Meng Liu, and Tat-Seng Chua. 2019. Kgat: Knowledge graph attention network for recommendation. In _Proceedings of the 28th ACM SIGKDD international conference on knowledge discovery & data mining_. 596-598.
* Wang et al. (2021) Zongwei Wang, Min Gao, Wentao Li, Junliang Yu, Lixin Guo, and Hongshi Yin. 2021. Efficient Bi-Level Optimization for Recommendation Denoising. [http://arxiv.org/abs/2102.10321v22v122v1220.12](http://arxiv.org/abs/2102.10321v22v122v1220.12) [cs].
* Wang et al. (2022) Zinu Wang, Yue He, Jiahao Liu, Wenchuo Zou, Philip S. Yu, and Peng Cui. 2022. Invariant Preference Learning for General Debiasing in Recommendation. In _Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_. ACM, Washington DC USA, 1969-1978. [https://doi.org/10.1145/336467.336393499](https://doi.org/10.1145/336467.336393499)
* Wen et al. (2022) Hongyi Wen, Xinyang Yi, Tiansheng Yao, Jiaxi Tang, Lichan Hong, and Ed H Chi. 2022. Distributionally-robust Recommendations for Improving Word-case User Experience. In _Proceedings of the ACM Web Conference_. 2022-3564-3610.
* Wang et al. (2021) Jiancan Wu, Xiang Wang, Yuli Feng, Xiangnan He, Liang Chen, Jianyuan Lian, and Xing Xie. 2021. Self-supervised Graph Learning for Recommendation. In _Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval_. 726-735. [https://doi.org/10.1145/3404835.3462802.xiv100785](https://doi.org/10.1145/3404835.3462802.xiv100785) [cs].
* Yang et al. (2023) Zheng, Xiangnan He, Jinqiang Zhang, Jiancan Wu, Xin Xu, Jianquen Chen, and Xiang Wang. 2023. A Generic Learning Framework for Sequential Recommendation with Distribution Shifts. In _Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval_.
* Yu et al. (1988) Junliang Yu, Xia Xia, Tong Cheng, Liheu Cui, Nguyen Quoc Viet Hung, and Hongshi Yin. 2023. XslimCL: Towards Extremely Simple End-Centrative Learning for Recommendation. [https://doi.org/10.48550/arXiv:2209.02544](https://doi.org/10.48550/arXiv:2209.02544) [cs].
* Yu et al. (2020) Juliang Yu, Hongyi Yin, Xin Xia, Tong Chen, Liheu Cui, and Quoc Viet Hung. 2022. Are graph augmentations necessary? simple graph contrastive learning for recommendation. In _Proceedings of the 43th international ACM SIGIR conference on research and development in information retrieval_. 1294-1303.
* Yu and Qin (2020) Wenhui Yu and Zheng Qin. 2000. Graph convolutional network for recommendation with low-pass collaborative filters. In _International Conference on Machine Learning_. PMLR, 1096-10965.
* Zhai et al. (2021) Rutmin Zhai, Chen Dan, Zico Kolter, and Pradeep Ravikumar. 2021. Doro: Distributional and outlier robust optimization. In _International Conference on Machine Learning_. PMLR, 12345-12555.
* Zhang et al. (2023) An Zhang, Jingyuan Zheng, Xiang Wang, Luchende Yuan, and Tat-Seng Chua. 2023. Invariant Collaborative Filtering to Popularity Distribution Shift. In _Proceedings of the ACM Web Conference_. 2023 ACM, Austin TX, USA, 1240-1251. [https://doi.org/10.1145/345507.353461](https://doi.org/10.1145/345507.353461)
* Zhang et al. (2021) Xiang Zhang, Yinqi Xu, Qinghe Liu, Zhicheng Liu, Jian Lu, and Qiao Wang. 2021. Robust graph learning under Wasserstein uncertainty. _arXiv preprint arXiv:2105.04292_ (2021).
* Xu et al. (2020) Yongfeng Zhang, Xiu Chen, et al. 2020. Explainable recommendation: A survey and new perspectives. _Foundations and Trends in Information Retrieval_ 14, 1 (2020), 1-101.
* Zhang et al. (2013) Zeyang, Heyang Guo, Hao Yang, and Xu Chen. 2023. Hierarchical Invariant Learning for Domain Generalization Recommendation. In _Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining_. 3470-3479.
* Zhao et al. (2022) Wayne Xin Zhao, Yipeng Hong, Xinyu Pan, Chen Yang, Zeyu Zhang, Zhan Lin, Jingxang Zhang, Shuqing Bian, Jiala Tang, Wenqi Sun, et al. 2022. Reclude 26. Networks a more up-to-date recommendation library. In _Proceedings of the 31st ACM International Conference on Information & Knowledge Management_. 10422-4726.
* Zhou et al. (2023) Hiaxi Zhou, Hao Chen, Junnan Dong, Daochen Ziza, Chuang Zhou, and Xiao Huang. 2023. Adaptive Popularity Debiasing Aggregator for Graph Collaborative Filtering. In _Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval_. ACM, Taipi Taiwan, 7-17. [https://doi.org/10.1145/3539618.35961635](https://doi.org/10.1145/3539618.35961635)

## Appendix A Appendices

### The proof of Lemma 1

Proof.: Eq.(3) can be written as follows,

\[\mathcal{L}_{smooth}=\frac{1}{2}\sum_{u}\sum_{\in\mathcal{N}(u)}\left\|\frac{ \mathbb{E}_{u}}{\sqrt{d_{u}}}-\frac{\mathbb{E}_{p}}{\sqrt{d_{u}}}\right\|_{F}^ {2}=\text{tr}\left(\mathbb{E}^{T}\text{LE}\right) \tag{11}\]

We first compute the derivative of the Eq.(11)

\[\frac{\partial\mathcal{L}}{\partial\mathbb{E}}=2c\text{LE}=2c\mathbb{E}-2c \widetilde{\Lambda}\mathbb{E} \tag{12}\]

In order to minimize Eq.(11) we take multi-step gradient descent. The \(k\)-th step is as follows:

\[\mathbb{E}^{(k)} \leftarrow\mathbb{E}^{(k-1)}-b\cdot\frac{\partial\mathcal{L}}{ \partial\mathbb{E}}\bigg{|}_{\mathbb{E}=\mathbb{E}^{(k-1)}}\] \[=(1-2bc)E^{(k-1)}+2bc\widetilde{\Lambda}\mathbb{E}^{(k-1)} \tag{13}\]

When we set the learning rate \(b\) as \(\frac{1}{2c}\), we have the following iterative steps:

\[\mathbb{E}^{(k)}\leftarrow\widetilde{\Lambda}\mathbb{E}^{(k-1)} \tag{14}\]

which is equivalent to one-step aggregation operation in LightGCN. Thus the multilayer aggregation operation is equivalent to minimizing the smoothness regularization with a multi-step gradient descent algorithm. 

### The proof of Lemma 2

In this section we show the derivation of a multi-layer optimization problem in DRO converted to a single-layer optimization problem. The original DRO question is as follows,

\[\min_{\theta}\mathcal{L}_{DRO\_smooth}(u) =\min_{\theta}\max_{\mathbb{E}_{\theta\sim P}}\left[d_{u}g(u,v; \theta)\right]\] \[\text{s.t.}\ D_{KL}(P,P_{u})\leq\eta \tag{15}\]

Given that the presence of \(d_{u}\) as a constant does not affect optimization, we will omit it in our discussion, leading to the following form of optimization problem,

\[\max_{P}\mathbb{E}_{\theta\sim P}\left[g(u,v;\theta)\right]\] \[\text{s.t.}\ D_{KL}(P,P_{u})\leq\eta \tag{16}\]

We focus on how to eliminate the inner maximisation optimisation problem and the distributional constraint term. Assume \(L(j)=\mathcal{O}(j)/P_{u}(j)\) and define a convex function \(\phi(x)=x\log x-x+1\). Then the divergence \(D_{KL}(Q,P_{u})\) can be written as \(\mathbb{E}_{P_{u}}[\phi(L)]\). The inner layer maximization optimization problem can be reformulated as follow:

\[\text{s.t.}\ \mathbb{E}_{P_{u}}[\phi(L)]\leq\eta,\mathbb{E}_{P_{u}}[L ]=1 \tag{17}\]

As a convex optimization problem, we use the Lagrangian function to solve it:

\[\min_{\alpha\geq 0,\beta}\sum_{L}\mathbb{E}_{\theta\sim P_{u}}\left[g (u,v;\theta)L\right]-\alpha(\mathbb{E}_{P_{u}}[\phi(L)]-\eta)+\beta(\mathbb{E }_{P_{u}}[L]-1)\] \[=\min_{\alpha\geq 0,\beta}\left\{\alpha\eta-\beta+\alpha\mathbb{E}_{ \theta\sim P_{u}}\left[\max_{L}\left(\frac{g(u,v;\theta)+\beta}{\alpha}L-\phi (L)\right)\right]\right\} \tag{18}\]

Notice that \(\max_{L}\left(\frac{g(u,v;\theta)+\beta}{\alpha}L-\phi(L)\right)=\phi^{*}( \frac{g(u,v;\theta)+\beta}{\alpha})\) is the convex conjugate function of \(\phi(x)\) and we have \(\phi^{*}(x)=e^{x}-1\). \(L(v)=e^{\frac{g(u,v;\theta)+\beta}{\alpha}}\) when the maximum value is obtained.

\[\min_{\alpha\geq 0,\beta}\left\{\alpha\eta-\beta+\alpha\mathbb{E}_{ \theta\sim P_{u}}\left[\max_{L}\left(\frac{g(u,v;\theta)+\beta}{\alpha}L-\phi (L)\right)\right]\right\}\] \[=\min_{\alpha\geq 0,\beta}\left\{\alpha\eta-\beta+\alpha\mathbb{E}_{ \theta\sim P_{u}}\left[e^{\frac{g(u,v;\theta)+\beta}{\alpha}}-1\right]\right\}\] \[=\min_{\alpha\geq 0}\left\{\alpha\eta+\alpha\log\mathbb{E}_{ \theta\sim P_{u}}\left[e^{\frac{g(u,v;\theta)}{\alpha}}\right]\right\} \tag{19}\]

where \(\beta=-\alpha\log\mathbb{E}_{\theta\sim P_{u}}\left[e^{\frac{g(u,v;\theta)}{ \alpha}}\right]\) and \(L(v)=\frac{g(u,v;\theta)}{\alpha}\).

When the minimum value is obtained. We consider the Lagrange multiplier \(\alpha\) as a hyperparameter related to the robustness radius to obtain the final unconstrained single-layer optimization problem.

\[\min_{\theta}\mathcal{L}_{DRO\_smooth}(u)=\min_{\theta}\left\{\alpha\eta+ \alpha\log\mathbb{E}_{\theta\sim P_{u}}\exp\left(\frac{g(u,v;\theta)}{\alpha} \right)\right\} \tag{20}\]

where the worst-case distribution

\[P_{u}^{*}(u)=P_{u}(u)\frac{\exp\left(g(u,v;\theta)/\alpha\right)}{\mathbb{E}_{ w\sim P_{u}}\left[\exp\left(g(u,w;\theta)/\alpha\right)\right]} \tag{21}\]

### The proof of Theorem 3.1

Proof.:

\[\mathcal{L}_{ideal}(u;\theta) =\mathbb{E}_{\theta\sim P_{u}^{ideal}}\left[d_{u}g(u,v;\theta)\right]\] \[\leq\mathcal{L}_{DRO\_smooth}(u;\theta)\] \[\leq\widetilde{\mathcal{L}}_{DRO\_smooth}(u;\theta)+\mathcal{B}(q, d_{u},\delta) \tag{22}\]

It is obvious that the first inequality holds, because as long as \(p_{u}^{ideal}\) exists in the uncertainty set, the \(\mathcal{L}_{DRO\_smooth}(u;\theta)\) must be greater than the ideal loss \(\mathcal{L}_{ideal}(u;\theta)\). The second inequality follows from the relationship between empirical error and expected error[2]. 

### Dataset statistics

The statistics of each dataset used in the experiment are shown in Table 5, which lists the number of users, items, interactions, and sparsity of the dataset. The brief introductions of all datasets are as follows:

* **Gowalla(Gowalla, 2018)**. Gowalla is the check-in dataset obtained from Gowalla2.

Footnote 2: [https://www.gowalla.com/](https://www.gowalla.com/)

* **Douban(Doban, 2018)**. This dataset is collected from a popular review website Douban3 in China. We transform explicit data into implicit using the same method as applied in Movielens.

Footnote 3: [https://www.douban.com/](https://www.douban.com/)

* **Amazon-Book(Doban, 2018)**. The Amazon-Book dataset is a comprehensive collection of data that primarily focuses on book reviews from the Amazon platform4. This dataset is often used in research, particularly in the field of recommendation systems.

Footnote 4: [https://www.amazon.com/](https://www.amazon.com/)

* **Yelp2018(Gowalla, 2018)**. Yelp20185 is from the 2018 edition of the Yelp challenge, containing Yelp's business reviews and user data.

* **Movielens-1M****(**M****(**2015**)****)** **Movielens is the widely used dataset from**(****)** **and is collected from MovieLens**6**. We use the version of 1M. We transform explicit data to implicit feedback by treating all user-item ratings as positive interactions.**
* **Food****(**2015**)****. Food datasets contain recipe details and reviews from Food.com(formerly GeniusKitchen**)**7**. Data includes cooking recipes and review texts.**
* **Coat****(**2019**)**** **& Yahoo****(**2014**)****. These two datasets are obtained from the Yahoo music and Coat shopping recommendation service, respectively. Both datasets contain a training set of biased rating data collecting from the normal user interactions and a test set of unbiased rating data containing user ratings on randomly selected items. The rating data are translated to implicit feedback,**_i.e._**, the rating larger than 3 is regarded as positive.**

Footnote 6: [https://movielens.org/](https://movielens.org/)

Footnote 7: [https://ceweuch.ucsd.edu/jmcauley/datasets.html#foodcom](https://ceweuch.ucsd.edu/jmcauley/datasets.html#foodcom)

### Parameter Settings.

For a fair comparison, the embedding size is fixed to 32 and layer num is set as 3 for all comparison methods. TPE-based Bayesian optimiser is used to search for the optimal hyperparameters. Specifically, as for DR-GNN, the learning rate is tuned from \(\{0.1,0.01\}\) and the coefficient of \(L_{2}\) regularization term \(\lambda\) is tuned from \(\{0.0,1.0,0.1,...,1e-6\}\). The \(\tau\) in BPR loss is searched from \(\{0.1,0.2,...,1.0\}\). The \(\alpha\) in DRO is search from \((0,1)\). The coefficient \(\gamma\) in GEA is search from \(\{0.1,0.2,0.3,0.4,0.5\}\).

We utilize the all-ranking strategy, in which all items, excluding the positive ones from the training set, are ranked by the recommendation model for each user.