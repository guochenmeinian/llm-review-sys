# UnifiedSSR: A Unified Framework of Sequential Search and Recommendation

Anonymous Author(s)

Submission Id: 647

###### Abstract.

In this work, we propose a Unified framework of Sequential Search and Recommendation (UnifiedSSR) for joint learning of user behavior history in both search and recommendation scenarios. Specifically, we consider user-interacted products in the recommendation scenario, user-interacted products and user-issued queries in the search scenario as three distinct types of user behaviors. We propose a dual-branch network to encode the pair of interacted product history and issued query history in the search scenario in parallel. This allows for cross-scenario modeling by deactivating the query branch for the recommendation scenario. Through the parameter sharing between dual branches, as well as between product branches in two scenarios, we incorporate cross-view and cross-scenario associations of user behaviors, providing a comprehensive understanding of user behavior patterns. To further enhance user behavior modeling by capturing the underlying dynamic intent, an intent-oriented Session Modeling module is designed for inferring intent-oriented semantic sessions from the contextual information in behavior sequences. In particular, we consider self-supervised learning signals from two perspectives for intent-oriented semantic session locating, which encourages session discrimination within each behavior sequence and session alignment between dual behavior sequences. Extensive experiments on three public datasets demonstrate that UnifiedSSR consistently outperforms state-of-the-art methods for both search and recommendation.

2018

Personalized Search and Recommendation; Sequential User Behavior Modeling; Multi-Task Learning; Joint Learning; E-Commerce 2018 acmcopyright ACM SIGS '18, Honolulu, HI, USA 978-1-4503-XXXX-18/06

2

## 1. Introduction

On e-commerce platforms, users typically interact with products in two major scenarios, _i.e._, search and recommendation. Users can either interact directly with products listed on the recommendation page, or issue a query in the search box and then proceed to interact with products displayed on the search result page. For a long time, search and recommendation have been regarded as two separate research scenarios, each becoming increasingly prevalent in real-world applications. Recommendation engines mine user preferences from behavior history to suggest personalized products (Gupta et al., 2017; Wang et al., 2018), while search engines assist users in finding specific products based on their queries (Han et al., 2017; Wang et al., 2018). A key distinction between the search and recommendation scenarios lies in the fact that users provide explicit queries for search, whereas no query is present for recommendation. Nevertheless, in both scenarios, the goal of the models is to generate a personalized ranked list of products, which satisfies the personalized needs of users and alleviates information overload. Despite the recent success achieved by studies in each individual scenario, they still face challenges related to limited representation capabilities and data sparsity issues (Wang et al., 2018; Wang et al., 2018).

Figure 1 depicts an overview of the connections between the search and recommendation in an integrated system, where the user set, product set, and vocabulary are shared. Despite the use of different techniques in search and recommendation engines, the two scenarios are closely related, and therefore, learning in one scenario may potentially benefit the other. In this sense, leveraging user behavior data from both scenarios to construct a unified model holds the potential for mutual enhancement in user modeling. The joint learning of a unified model helps alleviate data sparsity issues while simultaneously improving model performance in both scenarios, eventually contributing to the overall user satisfaction.

Pioneering studies (Shi et al., 2016; Wang et al., 2018; Wang et al., 2018) have demonstrated the superiority of unified models over single-scenario models in both search and recommendation. However, these methods either simply combine individual models for the two tasks through a joint loss function (Wang et al., 2018; Wang et al., 2018), ignoring the correlation of user behaviors in both scenarios, or they treat user behaviors in the recommendation scenario as special cases in the search scenario with empty queries (Shi et al., 2016; Wang et al., 2018) overlooking the inherent differences between user behaviors in the two scenarios. Different from these approaches, in this work, we aim to construct a unified model that effectively leverages the commonalities and differences across user behaviors in both search and recommendation. To achieve this, the following two challenges should be considered:

**Challenge 1: Cross-scenario and cross-view user behavior modeling**. Users engage in three distinct behavior types across scenarios: (a) _interacting with products_ in the recommendation scenario, (b) _issuing queries_ and then (c) _interacting with products_ in the search scenario. In the recommendation scenario, users interact with products without a clear intent, whereas they interact withproducts driven by a specific intent in the search scenario. Consequently, the product interaction histories in these two scenarios may exhibit different distributions. Thus, it is important to account for the commonalities and differences in cross-scenario product interactions to construct a unified model. Furthermore, in the search scenario, users explicitly express their intent through natural language queries, and then selectively interact with products from search results. The pair of issued query and interacted product can be regarded as two views on user intent. The issued query provides more informative insights into user intent but is more difficult to learn due to its unstructured nature. On the contrary, the interacted product is easier to model but may not always be reliable due to exposure bias (Zhou et al., 2017). Hence, it is also crucial to consider the commonalities and differences in cross-view user behaviors.

**Challenge 2: Joint dynamic user intent modeling.** Another significant challenge lies in uncovering the underlying user intent behind each interaction in a long history sequence. Since user intent evolves over time, users engage in a series of consecutive behaviors driven by specific or broad intent, after which that intent may drift or even abruptly change for various reasons (Brocker et al., 2017). Discovering and aggregating semantic sessions resulting from distinct intents is beneficial for enhancing user intent understanding in user behavior modeling. However, how to effectively locate the intent-oriented sessions with variable lengths remains unexplored.

To address the aforementioned challenges, we propose a Unified framework of Sequential Search and Recommendation (UnifiedSSR) for joint learning of user behavior history in both search and recommendation scenarios. First, we propose a dual-branch network to encode the pair of interacted product history and issued query history in the search scenario, and deactivate the query branch to adapt to the recommendation scenario. Through the parameter sharing between dual branches, as well as between product branches in two scenarios, our unified model effectively shares information cross-scenario (_i.e._, search and recommendation scenarios) and cross-view (_i.e._, interacted products and issued queries in the search scenario), resulting in a comprehensive understanding of user behavior patterns. Second, in order to enhance user behavior modeling by leveraging dynamic user intent, an Intent-oriented Session Modeling module is designed that discovers intent-oriented semantic sessions based on the contextual information in behavior sequences. In particular, we utilize two self-supervised learning signals based on similarity measurements for intent-oriented semantic session discovery: (1) Sessions resulting from different user intents within each behavior sequence should be distinguished from each other. Therefore, we facilitate the distinction between adjacent intent-oriented sessions in each behavior sequence. (2) When a user interacts with a product after issuing a query, this pair of interacted product and issued query driven by a common intent should align with each other. Consequently, we promote the alignment of the pair of interacted product session and issued query session guided by the same intent in dual behavior sequences.

Our contributions in this work can be summarized as follows:

* We propose a new Unified framework for Sequential Search and Recommendation (UnifiedSSR), which employs a dual-branch architecture with shared parameters to enable the joint learning of cross-scenario cross-view user behaviors.
* We design an Intent-oriented Session Modeling module to enhance user behavior modeling by capturing the dynamic user intent. Particularly, two self-supervised learning signals are leveraged that encourage intent-oriented session discrimination within each behavior sequence and intent-oriented session alignment between dual behavior sequences.
* We conduct extensive experiments on three public datasets. The experimental results demonstrate that UnifiedSSR outperforms state-of-the-art joint models and scenario-specific models in both search and recommendation scenarios.

## 2. Related Work

Recent years have witnessed significant success of research in each individual domain of search (Brocker et al., 2017; Wang et al., 2018; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019) and recommendation (Chen et al., 2019; Wang et al., 2019; Wang et al., 2019), leading to a substantial amount of outstanding work. However, to the best of our knowledge, rarely have efforts been dedicated to joint modeling of search and recommendation. We broadly classify these pioneering studies into two categories: search data enhanced recommender systems (Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019) and multi-scenario unified models (Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019). Search data enhanced recommender systems treat user behaviors in the search scenario as complementary information to boost the recommendation performance. For instance, NRHUB (Wang et al., 2019) utilized a hierarchical attention-based multi-view encoder to learn unified representations of users from their heterogeneous behaviors, including search query behaviors. Query-SeqRec (Wang et al., 2019) directly constructed query-aware heterogeneous sequences that contain both query interactions and item interactions, based on which the next interacted item is predicted. IV4Rec (Wang et al., 2019) leveraged search queries as instrumental variables to decompose and reconstruct user and item embeddings in a causal learning manner. SESRec (Wang et al., 2019) disentangled similar and dissimilar representations

Figure 1. An overview of the system architecture for the integrated personalized search and recommendation within an e-commerce platform, where the user set, product set, and vocabulary are shared. Note that side information such as user profiles and product metadata has been excluded for simplicity.

[MISSING_PAGE_FAIL:3]

length (\(T+1\)), we compute the sequence embedding matrix \(\mathbf{E}_{s}^{q}\) in a similar manner, _i.e._, \(\mathbf{E}_{s}^{q}=[\mathbf{e}_{1}^{q}+\mathbf{e}^{q};\mathbf{e}_{2}^{q}+\mathbf{ e}^{q};\ldots;\mathbf{e}_{T+1}^{q}+\mathbf{e}^{q}]+\mathbf{P}\in\mathbb{R}(T +1)\times d\). For clarity, we denote the embedding matrices of the product sequence in the recommendation scenario, the product and query sequences in the search scenario as \(\mathbf{E}_{r}^{p}\), \(\mathbf{E}_{s}^{p}\), \(\mathbf{E}_{s}^{q}\), respectively.

### Siamese Encoder

In the search scenario, the user-issued query and user-interacted product at each timestep are different types of behaviors driven by a common user intent. In order to encode these two behavior sequences while leveraging their common and unique characteristics, we propose a Siamese Encoder with shared parameters that takes two sequences as pairs to be encoded in parallel. The Siamese Encoder encodes correlations both within and between the product sequence and query sequence in the search scenario, while encodes correlations within the product sequence in the recommendation scenario. As such, the Siamese Encoder is capable of learning a comprehensive representation of sequential user behavior patterns.

Inspired by the encoder layer in the vanilla Transformer (Vaswani et al., 2017), the Siamese Encoder layer is designed to contain three sub-layers, _i.e._, the Multi-head Self-Attention (MSA), Multi-head Cross-Attention (MCA), and Feed-Forward Network (FFN).

We briefly review the Multi-head Attention (MA) mechanism with the scaled dot-product attention, which can be described as follows:

\[\text{MA}(\mathbf{Q},\mathbf{K},\mathbf{V})=\text{Concat}([\text{Attn}_{1}; \text{Attn}_{2};\cdots;\text{Attn}_{h}])\mathbf{W}^{O},\] \[\text{Attn}_{i}(\mathbf{W}_{i}^{O},\mathbf{K}\mathbf{W}_{i}^{K}, \mathbf{V}\mathbf{W}_{i}^{V})=\text{softmax}(\frac{(\mathbf{W}_{i}^{O})( \mathbf{K}\mathbf{W}_{i}^{K})^{T}}{\sqrt{d_{h}}})(\mathbf{V}\mathbf{W}_{i}^{V}). \tag{2}\]

The projection matrices \(\mathbf{W}_{i}^{Q}\in\mathbb{R}^{d\times d_{h}}\), \(\mathbf{W}_{i}^{K}\in\mathbb{R}^{d\times d_{h}}\), \(\mathbf{W}_{i}^{V}\in\mathbb{R}^{d\times d_{h}}\), \(\mathbf{W}^{O}\in\mathbb{R}^{d\times d}\) are learnable parameters, where \(h\) is the number of attention heads, and \(d_{h}=d/h\).

In the case of the product branch in the search scenario, the multi-head self-attention operation focuses on the correlation within the sequence, which takes the embedding matrix \(\mathbf{E}_{s}^{p}\) as the input of MA, _i.e._, \(\mathbf{Q}=\mathbf{K}=\mathbf{V}=\mathbf{E}_{s}^{p}\). Then, the multi-head cross-attention is followed to encode the correlation across two sequences. Specifically, the multi-head cross-attention take both \(\mathbf{E}_{s}^{p}\) and \(\mathbf{E}_{s}^{q}\) as input of MA, _i.e._, \(\mathbf{Q}=\mathbf{E}_{s}^{p}\), \(\mathbf{K}=\mathbf{V}=\mathbf{E}_{s}^{q}\).

After encoding the intra- and inter-correlations of sequences, a position-wise feed-forward network is then applied, consisting of two linear transformations with a ReLU activation in between.

The Siamese Encoder layer comprehensively encodes the contextual information in dual behavior sequences, producing contextual representation matrices \(\mathbf{H}_{s}^{p}\) and \(\mathbf{H}_{s}^{q}\) for the product and query sequences, respectively. This can be summarized as follows:

\[\mathbf{H}_{s}^{p}=\text{MSA}(\mathbf{E}_{s}^{p},\mathbf{E}_{s}^ {p},\mathbf{H}_{s}^{p}),\mathbf{\hat{H}}_{s}^{q}=\text{MSA}(\mathbf{E}_{s}^{q},\mathbf{E}_{s}^{q},\mathbf{E}_{s}^{q}),\] \[\mathbf{H}_{s}^{p}=\text{FNN}(\text{MCA}(\mathbf{H}_{s}^{p}, \mathbf{H}_{s}^{q},\mathbf{H}_{s}^{q})),\] \[\mathbf{H}_{s}^{q}=\text{FNN}(\text{MCA}(\mathbf{H}_{s}^{q}, \mathbf{H}_{s}^{q},\mathbf{H}_{s}^{q})), \tag{3}\]

where MSA(\(\cdot\)), MCA(\(\cdot\)), FFN(\(\cdot\)) denote the aforementioned three sub-layers. Note that we also adopt the residual connection (He et al., 2016), layer normalization (He et al., 2016), and dropout regularization (Srivastava et al., 2014) to enhance the network structure following (Srivastava et al., 2014; Vaswani et al., 2017).

For the recommendation scenario where user-issued queries are absent, the Siamese Encoder layer can be adapted by deactivating the query branch. As such, the multi-head cross-attention becomes equivalent to the multi-head self-attention, and the contextual representation matrix of the product sequence is derived as:

\[\mathbf{\hat{H}}_{r}^{p}=\text{MSA}(\mathbf{E}_{r}^{p},\mathbf{E}_{r}^{p}, \mathbf{E}_{r}^{p}),\mathbf{H}_{r}^{p}=\text{FNN}(\text{MCA}(\mathbf{\hat{H}}_ {r}^{p},\mathbf{\hat{H}}_{r}^{p},\mathbf{\hat{H}}_{r}^{p})). \tag{4}\]

After being encoded by the Siamese Encoder composed of a stack of \(L\) identical layers, we obtain the contextual representation matrices for the product and query sequences in the search scenario, denoted as \(\mathbf{H}_{s}^{p}\) and \(\mathbf{H}_{s}^{q}\), and for the product sequence in the recommendation scenario, represented as \(\mathbf{H}_{r}^{p}\). Here the superscript

Figure 2. An overview of the proposed UnifiedSSR framework. (a) presents the architecture of UnifiedSSR with query branch deactivated for recommendation (left) and with entire dual branches for search (right). The information sharing mechanism is two-fold: cross-scenario parameter sharing for learning user-interacted products in two scenarios, cross-view parameter sharing for learning user-interacted products and user-issued queries in the search scenario. (b) illustrates the structure of the Siamese Encoder layer. (c) demonstrates the complete Intent-oriented Session Modeling in the search scenario.

(\(L\)) indicating the number of Siamese Encoder layers is omitted for simplicity.

### Intent-oriented Session Modeling

Leveraging the inherent user intent associated with each interaction could potentially improve the user behavior modeling. In most cases, however, there is no labeled data explicitly revealing the intent for each interaction. Since user intent evolves over time, users engage in a series of consecutive behaviors driven by one intent, followed by another series of consecutive behaviors under a different intent. Accordingly, we propose an Intent-oriented Session Modeling module, which captures user intent by locating and aggregating intent-oriented semantic sessions based on the contextual information in behavior sequences, so as to achieve intent-enhanced user behavior modeling. In particular, a self-supervised learning loss based on similarity measurements is designed to guide the intent-oriented session discovery. In this section, we mainly use the search scenario as an example to introduce the Intent-oriented Session Modeling module, so we omit the subscript \(s/r\) distinguishing search and recommendation scenarios to simplify the notation.

#### 3.5.1. Intent-oriented Session Extraction

In the case of the product sequence, it is first uniformly divided into \(N\) non-overlapping sessions. Let \(\mathbf{x}=[x_{1},x_{2},\ldots,x_{N}]\) represent central locations of sessions in the sequence \(S_{P}\), where \(x_{i}\) denotes the central location of the \(i\)-th session. The session location ranges are initialized as \((\mathbf{x}-\frac{1}{2N},\mathbf{x}+\frac{1}{2N})\), thereby the sequence representation matrix can be sliced into chunks as \(\mathbf{H}^{p}=[\mathbf{H}^{p}_{\mathbf{x}_{i}},\mathbf{H}^{p}_{\mathbf{y}_{i} },\ldots,\mathbf{H}^{p}_{N}]\). In order to locate intent-oriented sessions, we make the session location ranges learnable, which can be inferred from the contextual representation matrix of the behavior sequence. In particular, inspired by (Bang et al., 2017) for semantic patch learning in vision tasks, we predict offsets \(\Delta\mathbf{x}\) of central locations and lengths \(\mathbf{s}\) based on the contextual representation matrix \(\mathbf{H}^{p}\) as follows:

\[\Delta\mathbf{x}=\text{Tanh}(f(\mathbf{H}^{p})), \tag{5}\] \[\mathbf{s}=\text{ReLU}(\text{Tanh}(f(\mathbf{H}^{p})+\mathbf{b})),\]

where \(f(\cdot)\) denotes the transformation that deduces the offset and length from the sequence representation matrix. We implement the transformation as a concatenation of mean pooling for each chunked representation matrix, followed by a linear transformation with a ReLU activation in between, which can be written as:

\[f(\mathbf{H}^{p})=\text{ReLU}(\text{Concat}[\text{Mean}(\mathbf{H}^{p}_{ \mathbf{x}_{i}});\ldots;\text{Mean}(\mathbf{H}^{p}_{N})])\mathbf{W}. \tag{6}\]

Accordingly, the \(i\)-th intent-oriented session is updated to be located in \((x_{i}+\Delta x_{i}-s_{i},x_{i}+\Delta x_{i}+s_{i})\). In this way, we can fully exploit the context to identify semantic sessions. We use \((\text{x}^{\text{left}},\text{x}^{\text{right}})\) to denote the overall learned session ranges. After locating \(N\) sessions in the product sequence, we then aggregate the interaction representations within each session, represented as \(\{I^{p}_{i}\mid 1\leq i\leq N\}\), where \(\hat{I}^{p}_{i}=\{\mathbf{H}^{p}_{i}\mid x^{\text{left}}_{i}\leq j<x^{\text{ right}}_{i}\}\). As such, the session representation matrix \(\mathbf{I}^{p}\in\mathbb{R}^{N\times d}\) can be derived by applying mean pooling to its containing interaction representations as follows:

\[\mathbf{I}^{p}=\text{Concat}([\text{Mean}(I^{p}_{1});\text{Mean}(I^{p}_{2}); \ldots;\text{Mean}(I^{p}_{N})]), \tag{7}\]

where the \(i\)-th row in \(\mathbf{I}^{p}\) represents the \(i\)-th intent-oriented session representation.

The representation of each interaction \(\mathbf{H}^{p}_{i}\) is enhanced by integrating intent-oriented session representations as follows:

\[\mathbf{F}^{p}_{t}=\mathbf{H}^{p}_{t}+\sum_{i=1}^{N}\mathbf{I}^{p}_{t}\cdot[ \mathbf{H}^{p}_{t}\in\hat{I}^{p}_{i}], \tag{8}\]

where \([\hat{I}]\) is an indicator function that returns 1 when the condition holds, and 0 otherwise.

Analogously, the representation matrix of the query sequence in the search scenario is also enhanced by aggregating intent-oriented session representations. Ultimately, we obtain the intent-enhanced contextual representation matrices \(\mathbf{F}^{p}_{t}\) for the product sequence in the recommendation scenario, \(\mathbf{F}^{p}_{s}\) and \(\mathbf{F}^{q}_{s}\) for product and query sequences, respectively.

#### 3.5.2. Self-supervised Intent-oriented Session Discovery

To further guide the intent-oriented session discovery, we consider two aspects of self-supervised signals: (1) Different user intents within a behavior sequence should lead to distinguishable sessions. Therefore, we encourage the representations of adjacent intent-oriented sessions within a sequence to be dissimilar to maintain discrimination. (2) A pair of product session and query session in dual behavior sequences driven by a common user intent should align with each other. Hence, we encourage the representations of corresponding intent-oriented sessions between two sequences to be similar to achieve alignment.

Accordingly, given session representation matrices \(\mathbf{I}^{p}\) and \(\mathbf{I}^{q}\) of product and query sequences in the search scenario, the self-supervised learning loss is defined as:

\[\mathcal{L}_{\text{s}sl}=\sum_{i=1}^{N-1}\left(\text{Sim}(\mathbf{I}^{p}_{i}, \mathbf{I}^{p}_{i+1})+\text{Sim}(\mathbf{I}^{q}_{i},\mathbf{I}^{q}_{i+1}) \right)-\sum_{i=1}^{N}\text{Sim}(\mathbf{I}^{p}_{i},\mathbf{I}^{q}_{i}), \tag{9}\]

where \(\text{Sim}(\cdot,\cdot)\) is the cosine similarity function. In Equation (9), the first term aims to minimize the similarity between adjacent semantic sessions to encourage the session discrimination within each of the two sequences, while the second term is designed to maximize the similarity between corresponding semantic sessions in two sequences to encourage the session alignment between two sequences.

As for the recommendation scenario with solely product interactions, the self-supervised learning loss simplifies to \(\mathcal{L}_{\text{s}sl}=\sum_{i=1}^{N-1}\text{Sim}(\mathbf{I}^{p}_{i},\mathbf{ I}^{p}_{i+1})\), guided by the first signal.

### Task-specific Predictor

After the contextual information encoding and intent-oriented session enhancement, we obtain the behavior representations of each user as \(\mathbf{f}^{p}_{t}\in\mathbb{R}^{d}\), \(\mathbf{f}^{p}_{t}\in\mathbb{R}^{d}\), \(\mathbf{f}^{q}_{t}\in\mathbb{R}^{d}\), corresponding to the last timestep of the representation matrices \(\mathbf{F}^{p}_{t},\mathbf{F}^{p}_{t},\mathbf{F}^{q}_{t}\) of the product sequence in the recommendation scenario, product and query sequences in the search scenario, respectively. For the final prediction, two task-specific predictors are employed for search and recommendation tasks, respectively.

In the recommendation scenario, we adopt the widely used inner product (Bang et al., 2017; Wang et al., 2018) to calculate the predicted score of the next interacted product \(p\) as follows:

\[\hat{y}_{u,p}=\mathbf{f}^{p}_{t^{\prime}}\cdot\mathbf{e}^{p}, \tag{10}\]where \(\mathbf{e}^{p}\) is the embedding of product \(p\) from the product embedding matrix \(\mathbf{M}^{p}\).

Similarly, in the search scenario, we separately calculate the inner products for a given product \(p\) with each of the two behavior representations, which are weighted and summed to derive the overall predicted score as follows:

\[\hat{y}_{u,p}=\left(w\mathbf{f}_{s}^{p}+(1-w)I_{s}^{q}\right)\cdot\mathbf{e}^{ p}, \tag{11}\]

where the balancing weight \(w\) is a learnable parameter.

### Model Optimization

We adopt the binary cross-entropy loss (Hinton et al., 2015) to supervise the final prediction for both tasks as follows:

\[\mathcal{L}_{predict}=-\left[\log\sigma(\hat{y}_{u,p})+\sum_{p^{-}\in\mathcal{ P}_{neg}}\log(1-\sigma(\hat{y}_{u,p^{-}}))\right], \tag{12}\]

where \(\sigma(\cdot)\) is the sigmoid function, \(\mathcal{P}_{neg}\) denotes the set of randomly sampled negative products paired with each ground-truth \(p\).

The prediction and intent-oriented session discovery objectives are jointly optimized, forming the overall loss function as follows:

\[\mathcal{L}_{joint}=\mathcal{L}_{predict}+\alpha\cdot\mathcal{L}_{ssl}, \tag{13}\]

where \(\alpha\) is a hyper-parameter that controls the weight of self-supervised learning loss for intent-oriented session discovery.

One of the core ideas behind UnifiedSSR is the integration of cross-scenario data to train a unified model, capitalizing on the commonalities and dependencies between search and recommendation scenarios. However, it is essential for the unified model not only to capture general patterns across scenarios but also to be tailored to specific tasks, ultimately leading to improved performance and robustness in both tasks. Accordingly, we adopt a training paradigm that consists of two stages: (1) _multi-task joint pre-training_ and (2) _task-specific fine-tuning_. In particular, the entire framework is initially pretrained by alternately using data from two scenarios. Subsequently, for each task, the pretrained model is then finetuned individually using a small amount of task-specific data. As such, the model not only benefits from comprehensively training on cross-scenario data but also can be easily adapted to specific tasks.

## 4. Experiments

### Experimental Settings

#### 4.1.1. Datasets

To evaluate the performance of UnifiedSSR in both search and recommendation scenarios, we conduct experiments on three publicly available datasets: JDesearch dataset (Hinton et al., 2015), two subsets of Amazon review dataset (Krishna et al., 2016), which are Clothing Shoes and Jewelry subset (referred to as Amazon-CL) and Electronics subset (referred to as Amazon-EL).

**JDesearch Dataset**: This dataset is a personalized product search dataset consisting of real user queries and user-product interactions collected from \(\mathcal{J}\)_com_, one of the most popular Chinese e-commerce platforms. The dataset contains products belonging to various categories, interactions from diverse channels including search and recommendation, and all data have been anonymized. We extract the product interactions without corresponding queries from user behavior logs to serve as recommendation data, with the remaining records treated as search data.

**Amazon Review Dataset**: This is a well-known dataset in recommender systems (Hinton et al., 2015; Wang et al., 2016), containing product reviews and metadata from _Amazon.com_. It is also the most commonly used public dataset in product search, featuring simulated queries derived from product metadata (Krishna et al., 2016; Krishna et al., 2016). We equally split the interaction history of each user into recommendation data and search data. Inspired by Gysel _et al._(Gysel et al., 2016), we use product categories, titles and brands to generate queries. Additionally, to introduce personalization into simulated queries, we extract keywords from user reviews based on TF-IDF, which are combined with product attributes to form the ultimate queries.

For each dataset, we filter out users and products with fewer than 10 interactions. The maximum sequence length of search and recommendation history is set to 100. Longer sequences are divided into non-overlapping subsequences. For both search and recommendation data, the sequences of each user are chronologically ordered and divided into subsets for multi-task joint learning and task-specific learning in an 8:2 ratio. The multi-task joint learning set is used for model pre-training, while the task-specific learning set is further split into training, validation, and test sets. In particular, the most recent interaction is reserved for testing, the second most recent interaction for validation, and all remaining interactions for training. The statistics of three datasets are summarized in Table 1.

#### 4.1.2. Baselines

We compare the proposed UnifiedSSR with search models, recommendation models and joint models, as follows:

**Search Models**: (1) **HEM**(Chen et al., 2016) jointly learns different level embeddings of users, queries, products by maximizing the likelihood of observed user-query-product triplets to perform personalized product search. (2) **ZAM**(Chen et al., 2016) constructs query-dependent user embeddings based on an attention mechanism, introducing a zero vector in the attention operator to achieve differentiated personalization. (3) **CAMI**(Krishna et al., 2016) builds upon the knowledge graph embedding method (Chen et al., 2016), leveraging the category information to disentangle and aggregate diverse interest embeddings of users.

**Recommendation Models**: (1) **GRU4Rec**(Krishna et al., 2016) applies recurrent neural networks to model user interacted item sequences for session-based recommendation. (2) **SASRee**(Hinton et al., 2015) directly implements the Transformer (Vaswani et al., 2017) encoder stacks with single-head self-attention mechanism for sequential recommendation. (3) **FMLP-Rec**(Wang et al., 2016) adopts all-MLP architecture derived from Transformer, where the attention mechanism is replaced with frequency-domain learnable filters.

**Joint Models**: (1) **JSR**(Wang et al., 2016) simultaneously learns two MLP-based models for retrieval and recommendation, based on a shared item

\begin{table}
\begin{tabular}{l c c c} \hline \hline  & JDesarch & Amazon-CL & Amazon-EL \\ \hline \#Users & 131,701 & 323,714 & 192,586 \\ \#Products & 411,566 & 393,214 & 180,446 \\ \#QueryWords & 139,610 & 209,057 & 224,652 \\ \#Interactions & 161,010,41 & 5,385,648 & 756,077 \\ \#Samples-S & 126,179 & 162,023 & 96,529 \\ \#Samples-R & 174,348 & 162,023 & 96,529 \\ \hline \hline \end{tabular}
\end{table}
Table 1. Statistics of Datasetsset and a joint loss function. (2) **JSR-Seq** is our extension of JSR, where the simple MLPs are replaced with our proposed sequential encoders. Note that the encoders share the same architecture but have separate parameters. (3) **SSERC**e (Shi et al., 2017) employs Transformers to individually encode search and recommendation behaviors of users, disentangling similar and dissimilar representations between two behaviors to enhance recommendations. We integrate query embeddings into the prediction layer to adapt it to the search task. Considering the two-stage training strategy adopted for our proposed UnifiedSSR, for a fair comparison, the above baselines utilized all available data for training, including both aforementioned pre-training and fine-tuning data. We also evaluate the performance of the proposed model end-to-end trained with task-specific data, represented as **UnifiedSSR-R** and **UnifiedSSR-S**, respectively. Besides, all methods share the same validation and test sets.

#### 4.1.3. Evaluation Metrics

To evaluate the performance on both search and recommendation, we adopt two widely used evaluation protocols, Hit Ratio (HR) and Normalized Discounted Cumulative Gain (NDCG). Following the common strategy (Shi et al., 2017; Liu et al., 2018), for each test sequence, all evaluated models predict the scores of 100 candidate products and the top-\(K\) products with the highest scores form the final ranked list. HR(\(\varnothing K\) measures whether the ground-truth product is present on the top-\(K\) ranked list, while NDCG@\(K\) further emphasizes the position of the hit by assigning higher weights to hits at proper ranks. We set \(K=\{5,10\}\) and report the average metrics for all samples in the test set.

#### 4.1.4. Implementation Details

We implement the compared methods following the original settings. The embedding dimension \(d\) is set to 32 for Amazon datasets and 64 for the JDesearch dataset, and the hidden dimension in feed-forward networks is set to twice the embedding dimension. The number of Siamese Encoder layers \(L\) and the number of sessions \(N\) are set to \((2,2)\) for Amazon datasets and \((3,4)\) for the JDesearch dataset. The effects of \(d\), \(L\), \(N\) are discussed in Appendix A. The weight \(\alpha\) assigned to the self-supervised learning loss is set to 0.1, given the results shown in Section 4.3.1. Following (Shi et al., 2017), we train the model using the Adam optimizer (Kingma and Ba, 2014) and the warmup-and-decay learning rate schedule. We initialize model parameters using the Xavier initialization (Goodfellow et al., 2014). For all models, we employ the default configuration of 100 training epochs and the mini-batch size of 128. Our model is implemented in PyTorch and publicly available1.

Footnote 1: (Anonymized) [https://anonymous.depen.science/r/UnifiedSSR](https://anonymous.depen.science/r/UnifiedSSR).

### Performance Comparison

We compare UnifiedSSR with search and joint models in the search scenario, and with recommendation and joint models in the recommendation scenario. From the performance comparison shown in Table 2, we have the following observations:

* UnifiedSSR achieves the best performance over all baselines in both search and recommendation scenarios across three datasets. This confirms that the proposed UnifiedSSR effectively addresses the challenges of cross-scenario cross-view user behavior modeling and dynamic user intent discovery, resulting in enhanced capabilities in both two scenarios.
* Joint models consistently outperform scenario-specific models on both scenarios, except that SESRec performs slightly worse than FMLP-Rec for recommendation on Amazon-EL. This suggests that joint models have an advantage over scenario-specific models but require the effective incorporation of inherent correlations across scenarios.
* UnifiedSSR-S and UnifiedSSR-R yield competitive performance in their respective scenarios, highlighting the capacity of the designed model architecture for single-scenario user behavior learning. Moreover, UnifiedSSR outperforms UnifiedSSR-S and UnifiedSSR-R in most cases, demonstrating the significance of cross-scenario information sharing during multi-task joint pre-training.

### Study of UnifiedSSR

#### 4.3.1. Impact of Self-Supervised Learning Loss

As introduced in Section 3.5, the hyper-parameter \(\alpha\) in Equation (13) controls the weight of the self-supervised learning loss during training, which guides the intent-oriented session discovery for user intent understanding. To explore the influence of \(\alpha\) on the performance of UnifiedSSR, we compare the performance of \(\alpha\) over the range of \([0,0.5]\) at intervals of \(0.1\). From the results on Amazon-CL shown in Figure 3, we can see that the performance of UnifiedSSR improves as \(\alpha\) increases from 0 to 0.1. The performance improvement demonstrates that guided by the self-supervised learning objective, the Intent-oriented Session Modeling module effectively locates and aggregates the intent-oriented semantic sessions, contributing to the dynamic user intent understanding. Besides, the performance becomes worse than \(\alpha=0\) when \(\alpha\geq 0.2\) for search and \(\alpha\geq 0.4\) for recommendation. This suggests that excessively focusing on intent-oriented session modeling may constrain the capacity for representation learning of user behaviors, leading to a decrease in performance.

#### 4.3.2. Ablation Study

To investigate how the various designs impact the performance of UnifiedSSR, we conduct an ablation study considering the following variants: (1) **UnifiedSSR w/o FT**: The model solely undergoes multi-task joint pre-training without any subsequent task-specific fine-tuning. (2) **UnifiedSSR w/o CA**: The multi-head cross-attention sub-layer in the Siamese Encoder layer that encodes the correlation between dual behavior sequences is removed. (3) **UnifiedSSR w/o SE (a)**: The encoder in two branches for the search task share the same architecture but have separate parameters. (4) **UnifiedSSR w/o SE (b)**: The encoder in the product

Figure 3. Performance comparison on Amazon-CL with different settings of self-supervised learning loss weights (\(\alpha\)).

branch in two tasks share the same architecture but have separate parameters. (5) **UnifiedSSR** w/o **ISM (a)**: Instead of learning to extract intent-oriented sessions, the sequences are split into \(N\) sessions based on largest (\(N-1\)) time intervals. (6) **UnifiedSSR** w/o **ISM (b)**: The Intent-oriented Session Modeling module for intent-oriented session enhancement is removed.

Table 3 illustrates the experimental results comparing UnifiedSSR and its variants in terms of HR@10 and NDCG@10 on Amazon-CL. From Table 3, we have the following observations:

* UnifiedSSR w/o FT exhibits a reasonable performance drop in both scenarios compared to UnifiedSSR, yet it can still achieve competitive performance with baselines solely through pretraining. This validates the robust representation capability of UnifiedSSR based on multi-task joint learning.
* UnifiedSSR w/o CA, w/o SE (a), w/o SE (a) reduce the extent of information sharing from different perspectives. The performance decreases in these variants indicate the importance of cross-scenario cross-view information sharing for joint learning of user behaviors in both search and recommendation.
* UnifiedSSR w/o ISM (a) performs better than UnifiedSSR w/o ISM (b) in both scenarios. The difference between these two variants is that the former enhances behavior sequence modeling with time-interval based sessions while the latter does not use any session information. UnifiedSSR further outperforms UnifiedSSR w/o ISM (a), verifying that UnifiedSSR effectively leverages dynamic user intent through intent-oriented session modeling, thereby enhancing the model performance in both scenarios.

## 5. Conclusions

In this work, we proposed a unified framework for joint learning of user behaviors in both search and recommendation scenarios. Specifically, UnifiedSSR adopted the dual-branch architecture that encodes the pair of product history and query history in parallel in the search scenario, and deactivates the query branch to adapt to the recommendation scenario. UnifiedSSR effectively shared information cross-scenario (_i.e._, search and recommendation scenarios) and cross-view (_i.e._, interacted products and issued queries in the search scenario), while simultaneously modeling the dynamic user intent through the intent-oriented session discovery guided by two self-supervised learning signals. Extensive experiments on three public datasets demonstrated the effectiveness of UnifiedSSR.

\begin{table}
\begin{tabular}{l c c c c c c c c c c c c} \hline \hline  & \multicolumn{4}{c}{JDsearch} & \multicolumn{4}{c}{Amazon-CL} & \multicolumn{4}{c}{Amazon-EL} \\ \cline{2-13}  & HR@5 & HR@10 & NDCG@5 & NDCG@10 & HR@5 & HR@10 & NDCG@5 & NDCG@10 & HR@5 & HR@10 & NDCG@5 & NDCG@10 \\ \hline \multicolumn{13}{l}{_Search Scenario_} \\ \hline HELM & 0.5432 & 0.7590 & 0.2781 & 0.3441 & 0.5504 & 0.6448 & 0.3006 & 0.3298 & 0.5354 & 0.6638 & 0.2864 & 0.3259 \\ ZAM & 0.5547 & 0.7664 & 0.2853 & 0.3501 & 0.5866 & 0.6751 & 0.3238 & 0.3510 & 0.5727 & 0.6931 & 0.3080 & 0.3451 & 0.577 \\ CAMI & 0.3911 & 0.5051 & 0.2929 & 0.3299 & 0.6594 & 0.7539 & 0.5274 & 0.5582 & 0.7118 & 0.7992 & 0.5384 & 0.5669 & 0.578 \\ JSR & 0.8099 & 0.8543 & 0.7347 & 0.7490 & 0.7506 & 0.8060 & 0.6571 & 0.6752 & 0.8197 & 0.8647 & 0.7309 & 0.7455 & 0.7455 \\ JSR-Seq & 0.856 & 0.8781 & 0.8209 & 0.8270 & 0.7565 & 0.7785 & 0.7023 & 0.7088 & 0.8333 & 0.8529 & 0.7980 & 0.8029 & 0.8029 & 0.8029 & 0.8029 \\ SESRec & 0.8809 & 0.9267 & 0.7865 & 0.8019 & 0.7974 & 0.8455 & 0.6977 & 0.7115 & 0.8875 & 0.9125 & 0.8041 & 0.8111 & 0.8111 & 0.8111 \\ \hline UnifiedSSR-S & 0.9332 & 0.9510 & 0.8856 & 0.8911 & 0.8435 & 0.8784 & **0.7782** & **0.7898** & **0.9091** & **0.9340** & **0.8557** & **0.8628** & 0.822 & 0.822 \\ UnifiedSSR & **0.9551** & **0.9723** & **0.9005** & **0.9057** & **0.8582** & **0.8992** & 0.7757 & 0.7894 & 0.8998 & 0.9304 & 0.8286 & 0.8386 & 0.8386 & 0.8383 & 0.8435 & 0.8462 & 0.8462 & 0.8462 \\ \hline \multicolumn{13}{l}{_Improv._} & 8.43\% & 4.93\% & 9.69\% & 9.51\% & 7.62\% & 6.33\% & 11.17\% & 10.94\% & 1.39\% & 1.96\% & 3.04\% & 3.39\% & 0.8462 & 0.855 & 0.8462 & 0.

[MISSING_PAGE_FAIL:9]

## Appendix A Parameter analysis

### Impact of Embedding Dimension

We conduct experiments to analyze the impact of the embedding dimension (_i.e._, \(d\)) in UnifiedSSR. As an example, in the Amazon-CL dataset, we vary \(d\) from \(16\) to \(80\) in increments of \(16\). Figure 4 illustrates the experimental results _w.r.t._ NDCG@10 on two tasks. Based on Figure 4, we can observe a significant drop in performance when \(d=16\) for both tasks, indicating that it is insufficient to encode the contextual information. As the embedding dimension increases, the performance first exhibits substantial improvement, followed by a gradual stabilization and occasional slight declines. Considering the trade-off between cost and performance, we set the default \(d=32\) for Amazon datasets and \(d=64\) for the JDsearch dataset.

### Impact of Siamese Encoder Layer Number

The Siamese Encoder encodes the correlations both within each behavior sequence and across dual behavior sequences. The encoded representations at all positions in both sequences are essentially projected into a common space, where similar behavior patterns are close to each other. Here we analyze how the number of Siamese Encoder layers (\(i.e.,L\)) impacts the model performance in two scenarios. To achieve this, we conduct experiments with varying settings of \(L\) ranging from \(1\) to \(4\). Figure 5 illustrates the performance comparison on Amazon-CL. We observe that the performance consistently peaks at \(L=2\) on both search and recommendation tasks, followed by a gradual decline as \(L\) increases. This decline may be attributed to the overfitting problem. Based on the experimental results, we set \(L=2\) as the default for Amazon datasets and \(L=3\) for the JDsearch dataset, where the model performs best.

### Impact of Session Number

The number of sessions \(N\) plays a crucial role in UnifiedSSR. When \(N\) is set too large, it becomes challenging to locate semantic sessions with shorter initial lengths. Conversely, if \(N\) is set too small, sessions with longer initial lengths are more likely to include interactions with low correlation, thereby introducing unwanted noises. Therefore, here we investigate how the number of sessions \(N\) affects the performance of UnifiedSSR. In particular, we vary \(N\) within the range \([1,5]\) and present the results in Figure 6. We can observe that the model performance steadily improves in the search task as \(N\) increases, while the performance reaches its peak at \(N=2\) in the recommendation task. One possible reason for the different performance trends between the two scenarios is that, without an explicit query, user intent in the recommendation scenario tends to be ambiguous, resulting in less distinguishable intent-oriented sessions, and thus higher values of \(N\) may unnecessarily capture semantically meaningless sessions, undermining the performance. Based on the experimental results, we set default \(N=2\) for Amazon datasets and \(N=4\) for the JDsearch dataset.