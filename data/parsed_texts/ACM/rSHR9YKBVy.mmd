[MISSING_PAGE_FAIL:1]

likely to be fairly homogeneous. But now suppose that we aim to maximize the probability the user likes at least one recommended movie--accounting for a "unit consumption constraint". Now, recommending only comedy movies is suboptimal. If the user is in the mood for action, they will be left without any options; meanwhile, it is not beneficial to recommend many additional comedy movies, since the user only cares that they have a single good movie to watch. In this way, accounting for consumption constraints intuitively induces diverse recommendations.

#### A model of recommendations

To make this intuition precise--that user utility is aligned with diversity--and to understand when and to what extent it holds, we need to analyze the diversity of accuracy- and utility-maximizing recommendations. (From here on, utility refers to a measure that accounts for capacity constraints.) A primary contribution of our work is a stylized-but-rich model of recommendations that is analytically tractable in this respect.

In our model, items of varying quality belong to discrete types, and each user has a probability distribution over types. In a given session, the user is in the mood for one of these types, where the type is drawn from the distribution. (Uncertainty of a user's mood can arise either due to genuine stochasticity, or limitations in the recommender's inferential abilities.) This model lends itself to an interpretable measure of diversity, where a set of recommendations is diverse if it represents items from many types roughly equally.

We derive results in an asymptotic regime where the number of recommendations grows large, obtaining precise characterizations of accuracy- and utility-maximizing recommendations as a function of model parameters that control the quality of items within and across types. We show in computational experiments that our theoretical findings hold more generally.

#### Diminishing returns drive our results and proof technique

Our results connect the composition of recommendation sets with the rate of diminishing returns when recommending more items of a given type (with respect to accuracy or utility). With large diminishing returns in one type, after recommending a few items of that type, a recommender becomes incentivized to recommend from other types. Roughly speaking, utility induces sharper diminishing returns than accuracy, and thus more diversity. The key steps in our proofs are to (1) precisely characterize the asymptotic behavior of these diminishing returns under different parameterizations of our model, and (2) to show how this behavior determines the asymptotic representation of item types in optimal recommendations.

#### Overview of results

In a basic setting (Theorem 1), the model confirms our intuition in a striking way. In this setting, accuracy-maximizing recommendations are completely homogeneous (representing only items from one type); yet, by accounting for consumption constraints, utility-maximizing recommendations are completely diverse (representing each type with equal proportion) in the limit. This uncovers a surprising fact--that even if the user prefers one type with higher probability than another, the optimal set of recommendations may contain an equal proportion of each.

In a more general setting (Theorems 2a and 2b), we consider differences in item quality within and across types, accounting for the idiosyncratic properties of recommendation settings.

Theorem 2a shows that accuracy-maximizing recommendations become more diverse when item quality decays at a faster rate (i.e., the recommender quickly begins to run out of "good options"). This accords with our conceptual understanding that larger diminishing returns induces more diversity. However, when this rate of decay is "reasonable" (in a sense made precise in Section 3.2), accuracy-maximizing recommendations remain relatively homogeneous--roughly speaking, they represent types "less than proportionally."

Theorem 2b shows that utility-maximizing recommendations are generally diverse. More specifically, however, we show that when there is no decay in item quality, representation of a type varies _inversely_ with the quality of items within that type. This holds empirically whenever the rate of decay is small. While perhaps counterintuitive, this is explained by the need to recommend more items from such a type to ensure that the user likes at least one. We isolate this case in Corollary 3, which we call the "milk and ice cream theorem," since it helps explains the paradoxical empirical fact that while consumers are more likely to buy milk, grocery stores devote much more aisle space to ice cream.

When the rate of decay is "severe," Theorems 2a and 2b collectively show that accuracy- and utility-maximizing recommendations coincide, and are diverse.

#### Implications

Our results lay out the specific ways in which diversity supports user utility, and thus inform how diversity should be incorporated into recommender systems. In particular:

* Maximizing user utility--properly conceived as incorporating consumption constraints--is often aligned with showing users a diverse set of items. Thus, to the extent that real-world systems do not show diverse recommendation sets, our results suggest that they are also failing to optimize user utility. Notably, this is true even before considering other ways in which diversity factors into utility (e.g., an intrinsic preference for diversity).
* Our results suggest principled approaches to diversify recommendations in a way that also optimizes utility. In particular, our results show that when users have consumption constraints, the relative likelihood a user prefers a specific type of item does not asymptotically affect the optimal representation of that item. Therefore, systems should recommend items relatively equally from a user's possible set of interests--even the niche interests.
* When the platform can estimate quality within a type (how often consumers like a specific ice cream flavor, conditional on wanting ice cream), the platform should recommend _more_ items from types in which individual items are _less likely_ to be satisfactory.

#### Paper Outline

In Section 2, we introduce our model. In Section 3, we introduce our theoretical results, first in a basic setting (Section 3.1) and then in a general setting (Section 3.2). In Section 4, we give an overview of our proof technique, sketching how we are able to derive our asymptotic results. In Section 5, we test our theoretical predictions in a range of computational experiments. In particular, we conduct a semi-synthetic experiment in which items and user preferences lie in a continuous space as estimated via matrix factorization, relaxing the assumption that there are a finite number of item and preference types. In Section 6, we conclude. Full proofs and an extended related work are left to the appendix.

## 2. Model

### Specifying a recommendation setting

A recommender is tasked with recommending a fixed number of items to a user. There are \(m\) types of items, and each item belongs to exactly one type. At recommendation time, a user prefers exactly one of these \(m\) types of items. In our exposition, we will treat \(m\) as fixed and omit notation that depends on \(m\).

Types are indexed by \([m]=\{1,2,\cdots,m\}\) and we let a user's type preference be given by a random variable \(T\), such that \(\Pr[T=t]=p_{t}\) (so that \(\sum_{i=1}^{m}p_{t}=1\)). When a user prefers type \(t\) (i.e., \(T=t\)), they only like items of type \(t\). We assume that there are an arbitrarily large number items of each type, and that conditional on \(T=t\), a user likes the \(i\)-th item of type \(t\) independently with probability \(q_{t,i}\). Without loss of generality, we let \(q_{t,1}\geq q_{t,2}\geq\cdots\).

Formally, we let the random variable \(V_{t,i}\) indicate if the user likes the \(i\)-th item of type \(t\), so that

\[\Pr[V_{t,i}=1] =\Pr[T=t]\Pr[V_{t,i}\,|\,T=t] \tag{1}\] \[=p_{t}q_{t,i}. \tag{2}\]

Note that the random variables \(V_{t,i}\) are independent conditional on \(T\). A **recommendation setting** is thus characterized by:

1. **type probabilities**\(p_{1},p_{2},\cdots,p_{t}\);
2. **conditional item probabilities**\(q_{t,1},q_{t,2},\cdots\) for \(t\in[m]\).

In what follows, we assume that a recommendation setting is specified, and will omit dependencies of certain quantities on the recommendation setting.

Remark: Under standard measures of accuracy, like we consider here, items have binary value. However, it is possible to consider a setup in which values can be distributed according to arbitrary distributions. We provide such a setup in Appendix C, and give the analog of Theorem 1 in this setting.)

### Choosing a set of recommendations

We now focus on the task of selecting \(n\) items to recommend. In this case, a set of recommendations can be identified by an ordered tuple \(S=(n_{1},n_{2},\cdots,n_{m})\), where the recommender recommends the \(i\)-th item of type \(t\) for all \(t\in[m]\) and \(i\in[n_{t}]\). In other words, \(S\) represents the set of recommendations with the top \(n_{t}\) items from each type.1 We will let \(S_{n}:=\left\{(n_{1},n_{2},\cdots,n_{m})\in\mathbb{Z}_{t=0}^{m}:\sum_{t=1}^{m} n_{t}=n\right\}\) denote the set of recommendation sets of size \(n\).

Footnote 1: In what follows, it will be clear that the recommender should only recommend the top items from each type. For example, the recommender would never recommend the first, second, and fourth item of a type, but not the third.

We consider two objectives by which to optimize a set of recommendations \(S=(n_{1},n_{2},\cdots,n_{m})\in S_{n}\):

* **Accuracy**: The expected proportion of items in \(S\) that the user likes, given by \[\operatorname{acc}(S):= \mathbb{E}\left[\frac{1}{n}\sum_{t=1}^{m}\sum_{t=1}^{n_{t}}V_{t,i}\right]\] (3) \[= \sum_{t=1}^{m}p_{t}\sum_{t=1}^{n_{t}}q_{t,i}.\] (4) acc is the standard notion of accuracy commonly used to evaluate machine learning models. By the linearity of expectation, it is maximized by selecting the items with the highest \(\mathbb{E}[V_{t,i}]=p_{t}q_{t,i}\)--i.e., the individual items the user is most likely to like.
* **Utility** (w/ unit consumption constraint): The probability that a user likes at least one item in \(S\), given by \[\operatorname{util}(S) =\Pr\left[V_{t,i}=1\text{ for some }t\in[m],i\in[n_{t}]\right]\] (5) \[= 1-\sum_{t=1}^{m}p_{t}\sum_{i=1}^{n_{t}}\left(1-q_{t,i}\right).\] (6) \(\operatorname{util}_{11}\) aligns with a user's satisfaction when they only intend to use one of the recommended items, as is common. In this case--e.g., when the goal is to find one restaurant to dine at, one movie to watch, or one website to visit--what matters is if the user likes at least one recommended item.

In our analysis, we characterize the accuracy- and utility-maximizing recommendation sets, given by the following notation.

**Definition 1** (\(S_{n}\) and \(S_{n,1}\)).: Given a specified recommendation setting, we let \(S_{n}\) and \(S_{n,1}\) denote the recommendation sets of size \(n\) that maximize acc and \(\operatorname{util}_{11}\), respectively;2

Footnote 2: It is sometimes possible for multiple sets of recommendations to maximize these objectives. In this case, our results hold when selecting any of these sets.

\[S_{n} =\operatorname*{arg\,max}_{S\in S_{n}}\operatorname{acc}(S) \tag{7}\] \[S_{n,1} =\operatorname*{arg\,max}_{S\in S_{n}}\operatorname{util}_{11}(S). \tag{8}\]

To understand the diversity of \(S_{n}\) and \(S_{n,1}\), we consider how well-represented items of each type are.

**Definition 2** (Representation).: For \(S=(n_{1},n_{2},\cdots,n_{m})\), define

\[r_{t}(S)=\frac{n_{t}}{\sum_{u=1}^{m}n_{u}}, \tag{9}\]

the _representation_ of type \(t\) in \(S\).

Intuitively, sets with relatively equal representation across types are more diverse. In the following section, we will characterize--in terms of the type probabilities and conditional item probabilities--\(r_{t}(S_{n})\) and \(r_{t}(S_{n,1})\) across several regimes.

## 3. Results

We now introduce our theoretical results, which characterize the composition of the accuracy- and utility-maximizing sets \(S_{n}\) and \(S_{n,1}\). We begin in Section 3.1 by considering a basic setting that starkly contrasts the objectives acc and \(\operatorname{util}_{11}\); the first has a strong trade-off with diversity, while the second is entirely aligned with diversity. In Section 3.2, we characterize the representation of item types, \(r_{t}(S_{n})\) and \(r_{t}(S_{n,1})\), in a significantly more general setting, where we focus on the effects of different properties of the recommendation setting (i.e., providing comparative statics).

### A Basic Setting

We start with a simple case of our model where we let the type probabilities \(p_{1},p_{2},\cdots,p_{m}\) vary but hold the conditional item probabilities \(q_{t,i}=q\) fixed for some \(q\in(0,1)\). This setting provides a clear illustration of the drastic effect incorporating a consumption constraint can have.

To provide a concrete backdrop, suppose that there are \(m\) types of movie genres. Then the probability a user is in the mood for genre \(t\) is \(p_{t}\). These type probabilities \(p_{t}\) can vary, so that a user is more likely to be in the mood for some genres than others. Conditional on a user being in the mood for any genre \(t\), any movie in that genre is liked by the user independently with probability \(q\).

**Theorem 1**.: _Given type probabilities \(p_{1},p_{2},\cdots,p_{m}\) and conditional item probabilities \(q_{t,i}=q\),_

\[r_{t}(S_{n}) =\mathbbm{1}_{\{t=\arg\max_{t}p_{t}\}} \tag{10}\] \[\lim_{n\to\infty}r_{t}(S_{n,1}) =\frac{1}{m}. \tag{11}\]

This result conveys a strong dichotomy. (10) says that recommendations maximizing acc contains exclusively items from the genre the user is most likely to prefer, \(\arg\max_{t}p_{t}\). This reflects the empirical existence of an accuracy-diversity trade-off: the accuracy-maximizing set of recommendations is fully homogeneous.

Meanwhile, (11) says that the set of recommendations that maximizes utility with a unit consumption constraint is fully diverse. Specifically, as the number of recommended items \(n\) grows large, the recommender should recommend an equal proportion of items from each genre.3 In this way, accounting for a user's consumption constraint dissolves the apparent accuracy-diversity trade-off; maximizing the probability a user likes _at least one_ recommended movie is fully aligned with recommending a diverse set of movies. We now take a moment to convey the intuition behind Theorem 1. \(S_{n}\) maximizes acc, which is equivalent to maximizing the expected number of recommended items the user likes. By linearity of expectation, this is achieved when recommending the individual items the user likes with the highest probability. The probability a user likes any item in genre \(t\) is equal to \(p_{t}q\). Therefore, the recommender should only recommend items from genre \(\arg\max_{t}p_{t}\).

Footnote 3: In fact, one can show that \(r_{t}(S_{n,1})=\frac{1}{m}+O\left(\frac{1}{n}\right)\), giving a relatively fast rate of convergence.

When the objective is to instead maximize util1, the probability a user likes at least one item, recommending items from only one type is suboptimal. After recommending, say, many action movies, the probability the user is in the mood for action but does not like _any_ of the recommended action movies is small (\(p_{t}(1-q)^{n_{t}}\)), where \(n_{t}\) is the number of recommended action movies). At this point, recommending more action movies has diminishing returns, and one should hedge for the possibility that the user is in the mood for a different genre.

A surprising insight of Theorem 1 is that the type probabilities \(p_{t}\) do not play any role asymptotically for \(S_{n,1}\); even when a user watches more action than romance, the optimal set of recommendations represents the genres equally. To give some intuition, let \(X\) be the event that a user does not like _any_ recommended item. For an optimal set of recommendations \(S\), \(\Pr[X\,|\,T=t]=p_{t}q^{n_{t}}\) should equalized across \(t\); otherwise, there would be an incentive to recommend more items from a type where this probability is higher. If \(p_{1}>p_{2}\), \(\Pr[X\,|\,T=1]=\Pr[X\,|\,T=2]\) when recommending only a constant number \(\log_{q}\frac{p_{t}}{p_{2}}\) more items from type 1 than type 2. So asymptotically, the proportion of items recommended from each type is equal. Representation thus quickly converges to this asymptotic value as \(n\) increases; this is illustrated in one case in Figure 1.

### A General Setting

We turn to a more general case where we consider heterogeneous conditional item probabilities and analyze comparative statics. Again, we consider arbitrary type probabilities \(p_{1},p_{2},\cdots,p_{m}\). Now, we parameterize conditional item probabilities in the following way:

\[q_{t,i}=q_{t}(i+\beta)^{-\alpha}, \tag{12}\]

for \(\alpha,\beta\geq 0\). This parameterization models heterogeneity of conditional item probabilities both within and across types. Some comments on the parameters \(\alpha,\beta\), and \((q_{1},q_{2},\cdots,q_{t})\):

* \(\alpha\) is the _rate of decay_ of item quality within a type. When \(\alpha>1\), this rate is extreme in the following sense: even if a user were recommended an infinite number of items in their preferred type, they (1) would only like a constant number of the items in expectation, and (2) with positive probability, would not like _any_ of the recommended items.4 Therefore, when the recommender has a reasonable "supply" of items, \(\alpha\leq 1\) is realistic. Footnote 4: Both facts both down to the convergence of \(\sum_{i=1}^{m}t^{-\alpha}\) when \(\alpha>1\).
* \(\beta\) parameterizes the initial steepness, with higher \(\beta\) corresponding to lower initial steepness. \(\beta\) does not end up appearing in our estimates.
* \(q_{1},q_{2},\cdots,q_{m}\) are the _relative type qualities_. If \(q_{t}>q_{t^{\prime}}\), then \(q_{t,i}>q_{t^{\prime},i}\) for all \(i\). Users can be less likely to like items of a certain type, even conditioned on preferring that type. This has

Figure 1. An illustration of Theorem 1. Even while a user prefers type 1 much more often than type 2, as the number of recommendations increases, utility-maximizing recommendations (red) represent both types roughly equally. Meanwhile, accuracy-maximizing recommendations (blue) remain fully homogeneous throughout.

two equivalent interpretations: the user is more picky when they prefer type \(t^{\prime}\), or the recommender has lower quality or more niche items in type \(t^{\prime}\).

We now give two main results, Theorem 2.A and Theorem 2.B which characterize \(r_{t}(S_{n})\) and \(r_{t}(S_{n,1})\) in terms of these parameters.

**Theorem 2.A** (Accuracy-maximizing recommendations).: _Given type probabilities \(p_{1},p_{2},\cdots,p_{m}\) and conditional item probabilities \(q_{t,i}:=q_{t}(i+\beta)^{-\alpha}\),_

\[\lim_{n\to\infty}r_{t}(S_{n})=\frac{(p_{t}q_{t})^{1/\alpha}}{\sum_{u=1}^{m}( p_{u}q_{u})^{1/\alpha}} \tag{13}\]

The key takeaway from Theorem 2.A is that accuracy-maximizing recommendations are more diverse when \(\alpha\) is larger, i.e., when the quality of items in a type decays faster. Intuitively, this means that a recommender quickly runs out of high-quality items in a type, and thus benefits more from recommending items from other types. On the other hand, with small \(\alpha\), the recommender has access to many high-quality items within each type.

Let us consider three cases of Theorem 1 to understand the functional form in (24):

* As \(\alpha\to 0\), and if \(\arg\max_{t}p_{t}q_{t}\) is unique,5

Footnote 5: If there are multiple types with the maximum type probability, one may check that in the limit, an equal proportion of items are recommended from these types, and a zero proportion from other types.

\[\lim_{n\to\infty}r_{t}(S_{n})\to\mathds{1}_{\{t=\arg\max_{s}p_{t}q_{t}\}}, \tag{14}\]

meaning that only the type with highest type probability is recommended.

* For \(\alpha=1\),

\[\lim_{n\to\infty}r_{t}(S_{n})\propto p_{t}q_{t}, \tag{15}\]

meaning that a type is recommended in proportion to the probability a user likes items in that type.

* For \(\alpha\to\infty\),

\[\lim_{n\to\infty}r_{t}(S_{n})\to\frac{1}{m}, \tag{16}\]

meaning that an equal proportion of items from each type are recommended.

As \(\alpha\) ranges from \(0\) to \(\infty\), the amount of diversity in \(S_{n}\) smoothly interpolates from maximal homogeneity to proportional representation to maximal diversity. Notably, when \(\alpha\leq 1\), diversity is in the range between homogeneity and proportional representation. This suggests that in practice, the accuracy-diversity trade-off is particularly severe when the recommender has access to many high quality items of a type.

We next turn to utility-maximizing recommendations \(S_{n,1}\), which account for a unit consumption constraint.

**Theorem 2.B** (Utility-maximizing recommendations).: _Given type probabilities \(p_{1},p_{2},\cdots,p_{m}\) and conditional item probabilities \(q_{t,i}=q_{t}(i+\beta)^{-\alpha}\),_

\[\lim_{n\to\infty}r_{t}(S_{n,1})=\begin{cases}\frac{\left(\log\frac{1}{1-q_{t} }\right)^{-1}}{\sum_{u=1}^{m}\left(\log\frac{1}{1-q_{u}}\right)^{-1}}&\alpha= 0\\ \lim_{n\to\infty}r_{t}(S_{n,1})=\frac{(p_{t}q_{t})^{1/\alpha}}{\sum_{u=1}^{m}( p_{u}q_{u})^{1/\alpha}}&\alpha>1\end{cases}. \tag{17}\]

The representation exhibits phase change at \(\alpha=1\). As mentioned in our discussion of the parameters, we expect \(\alpha>1\) represents an "extreme setting." We thus focus on the case \(\alpha=0\), which we

\begin{table}
\begin{tabular}{c l} \hline \hline \(p_{t}\) & a _type probability_; a user prefers type \(t\) with probability \(p_{t}\) \\ \hline \multirow{4}{*}{\(q_{t,i}\)} & a _conditional item probability_; conditional on preferring type \(t\), a user likes the \(i\)-th item of type \(t\) with probability \(q_{t,i}\); in our general setting, we parameterize \(q_{t,i}\) as \(q_{t,i}=q_{t}(i+\beta)^{-\alpha}\) \\ \hline \(\alpha\) & the _rate of decay_ of item quality within a type \\ \hline \multirow{4}{*}{\(q_{t}\)} & a _relative type quality_; \(q_{t}\) determines the relative quality of items in \(t\) compared to other types \\ \hline \multirow{4}{*}{\(S_{n}\)} & the set of \(n\) recommendations that maximizes acc, the expected proportion of items a user likes \\ \hline \multirow{4}{*}{\(S_{n,1}\)} & the set of \(n\) recommendations that maximizes \(\mathsf{util}_{1}\), the probability a user likes at least one item \\ \cline{2-2}  & \(r_{t}\left(S\right)\) & the proportion of items in \(S\) of type \(t\) \\ \hline \hline \end{tabular}
\end{table}
Table 1. Key notation in our model pull out as its own result. (Note also that Theorem 1 is obtained by taking \(q_{1}=q_{2}=\cdots=q_{m}\) and \(\alpha=0\).)

Corollary 3 (The "milk and ice cream theorem").: _Given type probabilities \(p_{1},p_{2},\cdots,p_{m}\) and conditional item probabilities \(q_{t,t}=q_{t}(i+\beta)^{-\alpha}\), when \(\alpha=1\),_

\[\lim_{n\to\infty}r_{t}(S_{n,1})=\frac{\left(\log\frac{1}{1-q_{n}}\right)^{-1}}{ \sum_{u=1}^{m}\left(\log\frac{1}{1-q_{u}}\right)^{-1}}, \tag{18}\]

_meaning that \(r_{t}(S_{n,1})\) is larger for types \(t\) with lower \(q_{t}\)._

The corollary's name references a paradoxical fact of grocery stores: that even while a customer is much more likely to buy milk than ice cream, significantly more aisle space is devoted to ice cream. The paradox can be resolved by the corollary in the following way. Let milk be type \(1\) and ice cream be type \(2\). A customer is more likely to purchase milk than ice cream, so \(p_{1}>p_{2}\). However, the probability a given carton of ice cream will satisfy a customer trying to purchase milk is lower than the probability that a given bottle of milk will satisfy a customer trying to purchase milk.6 This means that \(q_{1}>q_{2}\). Corollary 3 reveals that more items should be recommended from the type with lower \(q\)-and, in fact, that \(p_{t}\) is asymptotically irrelevant.

Footnote 6: We note that this fact is complicated by customers’ increasingly diversified tastes for—and the increased availability of—different types of plant-based mlles (Steiner, 2018).

Corollary 3 demonstrates a broader insight into recommendations when the user has consumption constraints. Rather than focusing on type probabilities, it is more important to consider the conditional item values _within a type_--in particular, to recommend more items from types with low conditional item values. A good set of recommendations covers its bases across all possible preferences of the user, and "covering" a type requires more items when items in that type have low conditional item probabilities.

Computational experiments suggest that behavior remains similar when \(\alpha\) is small but larger than \(0\) (see Figure 2). However, Theorem 2.B shows that the behavior of \(S_{n,1}\) changes when \(\alpha>1\). In fact, referring back to Theorem 2.A, we have that in this regime,

\[\lim_{n\to\infty}r_{t}(S_{n})=\lim_{n\to\infty}r_{t}(S_{n,1})=\frac{(p_{t}q_{t })^{1/\alpha}}{\sum_{u=1}^{m}(p_{u}q_{u})^{1/\alpha}}. \tag{19}\]

So when \(\alpha>1\), both \(S_{n}\) and \(S_{n,1}\) become more diverse as \(\alpha\) increases. To provide rough intuition for this equality, note that for large \(\alpha\), it is unlikely that a user will like more than one item in each type. Therefore, maximizing the likelihood a user likes at least one item \((\operatorname{util}_{1})\) is roughly equivalent to maximizing the total number of recommended items a user likes (acc).

### Summary of results

To summarize our theoretical results, while accuracy can exhibit a strong trade-off with diversity (especially when the rate of decay \(\alpha\) is relatively small), our measure of utility that accounts for the capacity constraints of users does not exhibit a trade-off with diversity in the settings we study. This is exhibited in computational results shown in Figure 3, which shows how accuracy and utility vary as the level of diversity increases.

## 4. Proof technique

We now provide an overview of our proof technique. We begin with some high-level intuition, from which our formal approach will deviate somewhat. The basic idea is that maximizing functions

Figure 3. In three settings with varying \(\alpha\), we plot how accuracy and utility trade off with diversity. We consider sets \(S\) with \(n=100\) items ranging from complete homogeneity (only type \(1\) recommended), to proportional representation (\(r_{t}(S)=p_{t}\)) to complete diversity (\(r_{t}(S)=\frac{1}{m}\)), and plot \(\operatorname{acc}(S)\) and \(\operatorname{util}_{1}(S)\). Notice that in all of the plots, \(\operatorname{util}_{1}\) is aligned with diversity, while \(\operatorname{acc}(S)\) exhibits a strong trade-off with diversity when \(\alpha=0\), which becomes less severe for larger \(\alpha\). These results agree with the predictions of Theorem 2.A and Theorem 2.B.

of the form

\[\sum_{t=1}^{m}\lambda_{t}h(z_{t}), \tag{20}\]

subject to the constraint \((z_{1},\cdots,z_{m})\in\mathcal{S}^{n}\) is tractable when \(f\) is simple (a monomial, for instance). For example, rough speaking, it is possible to solve

\[\lambda_{1}h^{\prime}(x_{1})=\lambda_{2}h^{\prime}(x_{2})=\cdots=\lambda_{m}h^ {\prime}(x_{m}), \tag{21}\]

and show that the integer-valued optimum must be near the real-valued optimum. While the objectives acc and \(\texttt{util}_{1}\) do not take the exact form as above, we show that there are choices of \(\lambda_{t}\) such that the objectives evaluate to

\[\sum_{t=1}^{m}\lambda_{t}h_{t}(z_{t}), \tag{22}\]

where even while \(h_{t}(z_{t})\) may be complicated,

\[\lim_{t\to\infty}\frac{h_{t}(z)}{h(z)}=1 \tag{23}\]

for a simple function \(h\). We can then show that, under some reasonable assumptions on \(h\), the solution to (23) is approximated by that of (20) in the limit as \(n\to\infty\).

We now outline how this method can be used to prove Theorem 2.A when \(\alpha<1\) (the result is the same for \(\alpha=1\) and \(\alpha>1\), but these cases require separate analysis). Consider type probabilities \(p_{1},p_{2},\cdots,p_{m}\) and conditional item probabilities \(q_{t,i}\coloneqq q_{t}(i+\beta)^{-\alpha}\). Then we would like to show that

\[\lim_{t\to\infty}r_{t}(S_{n})=\frac{(p_{t}q_{t})^{1/\alpha}}{\sum_{t=1}^{m}(p _{t}q_{t})^{1/\alpha}} \tag{24}\]

Then \(S_{n}=(z_{1}^{(n)},z_{2}^{(n)},\cdots,z_{n}^{(n)})\in\mathcal{S}^{n}\) maximizes

\[\sum_{t=1}^{m}p_{t}\sum_{i=1}^{z_{t}}q_{t,i}=\sum_{t=1}^{m}p_{t}\sum_{i=1}^{z _{t}}q_{t}(i+\beta)^{-\alpha}=\sum_{t=1}^{m}\lambda_{t}h_{t}(z_{t}) \tag{25}\]

over \((z_{1},z_{2},\cdots,z_{m})\in\mathcal{S}^{n}\), where

\[\lambda_{t}=\frac{p_{t}q_{t}}{1-\alpha},\qquad h_{t}(z)\coloneqq(1-\alpha)\sum _{i=1}^{z}(i+\beta)^{-\alpha}. \tag{26}\]

We then show that

\[\lim_{z\to\infty}\frac{h_{t}(z)}{h(z)}=1 \tag{27}\]

where \(h(z)=z^{1-\alpha}\). The result follows by using the following lemma, which is a subcase of Lemma A.1 in the appendix.

Lemma 1.: _Let \(h(z)=z^{\sigma}\) for \(\sigma\in(0,1)\). For \(t\in[m]\), suppose \(h_{t}:\mathcal{Z}_{20}\to\mathbb{R}\) is monotonically increasing and strictly concave, and that_

\[\lim_{z\to\infty}\frac{h_{t}(z)}{h(z)}=1. \tag{28}\]

_Let_

\[S^{(n)}=(z_{1}^{(n)},z_{2}^{(n)},\cdots,z_{m}^{(n)})\in\operatorname*{arg\, max}_{(z_{1},\cdots,z_{m})\in\mathcal{S}^{n}}\sum_{t=1}^{m}\lambda_{t}h_{t}(z_{t}). \tag{29}\]

_Then_

\[\lim_{n\to\infty}r_{t}(S^{(n)})=\frac{\lambda_{t}^{\frac{1}{1-\alpha}}}{\sum_ {u=1}^{m}\lambda_{u}^{\frac{1}{1-\alpha}}}. \tag{30}\]

Taking \(\sigma=1-\alpha\), we can apply the lemma to show that

\[\lim_{n\to\infty}r_{t}(S_{n})=\frac{\left(\frac{p_{t}q_{t}}{1-\alpha}\right)^ {1/\alpha}}{\sum_{u=1}^{m}\left(\frac{p_{t}q_{t}}{1-\alpha}\right)^{1/\alpha} }=\frac{(p_{t}q_{t})^{1/\alpha}}{\sum_{u=1}^{m}(p_{t}q_{t})^{1/\alpha}}. \tag{31}\]

## 5. Computational Experiments

We present results from a range of computational experiments, showing that our theoretical results generalize to practical settings.

### Finite number of recommendations and beyond unit consumption constraints

We first focus on experiments in which \(n\) is finite, ranging from small to moderate. We also relax the assumption that users have _unit_ consumption constraints and consider varying rates of decay \(\alpha<1\). Consider the following more general version of utility corresponding to a consumption constraint of \(k\):

\[\texttt{util}_{k}(S)\coloneqq\mathbb{E}\left[\max\left\{\sum_{t\in[m],i\in[n _{i}]}V_{t,i},\quad k\right\}\right], \tag{32}\]

the value of the top \(k\) items that a user likes. Accordingly, let

\[S_{nk}\coloneqq\operatorname*{arg\,max}_{S\in\mathcal{S}_{n}}\texttt{util}_{ k}(S), \tag{33}\]

where we recall that \(\mathcal{S}_{n}\) is the set of all possible recommendation sets with \(n\) items. Notice that our previous definitions of \(\texttt{util}_{1}\) and \(S_{n,1}\) agree with this more general definition. (Indeed, when \(k=1\), (32) reduces to the probability \(V_{t,i}=1\) for at least one item.)

Also notice that \(S_{n,n}\) maximizes the total number of items the user likes, and thus coincides with the accuracy-maximizing set \(S_{n}\). We would expect our theoretical results about \(\lim_{n\to\infty}r_{t}(S_{n,1})\) to be more accurate when \(k\) is small, and to diverge from empirics when \(k\) grows closer to \(n\).

Here, we focus on a recommendation setting where there are two item types with \(p_{1}=0.7\) and \(p_{2}=0.3\). We let \(q_{t,i}=q_{t}(i+\beta)^{-\alpha}\) where we fix \(q_{t}=0.5\) and \(\beta=1\), and only consider \(\alpha<1\). We focus on the case \(\alpha<1\) since it constitutes a reasonable rate of decay. We compare our empirical results to the estimate given by Theorem 2.B, which tells us that when \(\alpha=0\),

\[\lim_{n\to\infty}r_{1}(S_{n,1})=\frac{1}{2}, \tag{34}\]

meaning that both types are equally represented. We evaluate how far empirical estimates of \(r_{1}(S_{n,k})\) deviate from this prediction when \(\alpha\in\{0,0.2,0.5,0.9\}\) and \(n\) and \(k\) vary. Results are shown in Table 2. We observe that \(r_{1}(S_{n,k})\) is near \(0.5\) whenever \(\frac{k}{n}\) is relatively small and \(\alpha\) is smaller. This suggests that our findings are robust when the consumption constraint \(k\) is small in terms of \(n\) (i.e., users only use a relatively small proportion of recommended items at a given time), and when the quality of items in a type does not decay significantly, i.e., there are many high-quality items per type.

Empirically, our results suggest that the theoretical estimate for \(\alpha=0\) is accurate for small \(\alpha\), but begins to deteriorate as \(\alpha\) approaches \(1\). (This is also corroborated by Figure 2, in which representation begins to change before reaching \(\alpha=1\).)We provide additional computational experiments in different settings in the appendix, as well as details for how we determine the empirically objective-maximizing recommendations.

### Continuous Items and User Preferences

We now depart from our assumption that user preferences and items fall into discrete types, and instead represent both by embeddings on the unit \(d\)-dimensional sphere \(S^{d}\). Given a user preference \(t\in S^{d}\) and an item \(v\in S^{d}\), we let the value of item \(v\) be equal to the dot product \(\max(t\cdot v,0)\). Thus, items that are closer to a user's true preference have higher value and items cannot have negative value. For a set of \(n\) recommendations, we again let accuracy measure the average value of recommended items and utility measure the value of the best-recommended item (that of the highest value). We then compare the performance of an accuracy-maximizing set of recommendations with a heuristically constructed set of diverse recommendations. Our results are plotted in Figure 4. In alignment with our general findings, the accuracy-maximizing set of recommendations is homogeneous, while a diverse set of recommendations improves user utility.

Specifically, we use 10-dimensional embeddings trained using interaction data from GoodReads between 1000 users and 200 books. Embeddings are normalized to lie on \(S^{10}\). We assume user preferences are drawn uniformly from the set of books they have interacted with (since these represent the range of interests the user has). We limit our experiments to the 206 users with at least 20 total interactions. For each user, we consider a "train set" of 10 of the user's past interactions. We then select \(n\) of the 190 remaining books to recommend. The accuracy-maximizing set is chosen to maximize accuracy when user preferences are assumed to be drawn from the train set. The diverse set is chosen by choosing the closest items to each of the books in the train set (thus, covering the full range of user interests). We evaluate recommendations by randomly drawing a user preference from the books they have interacted with that were not already included in the train set. Additional details for our experiment are given in the appendix.

## 6. Conclusion

We introduced and analyzed a model of recommendations that reconciles the apparent accuracy-diversity trade-off. In particular, we showed that accuracy is misaligned with user utility, because it does not consider the consumption constraints of users. By accounting for these consumption constraints, we found that user utility is in fact aligned with and supported by diversity. As a consequence, navigating the accuracy-diversity trade-off can be viewed as a way of incorporating diversity to help align accuracy with the more fundamental goal of user utility. Our results provide insight into how diversity can be incorporated in this manner.

\begin{table}
\begin{tabular}{c c c c c c c c c c c c c c c c c c c}  & \multicolumn{4}{c}{\(r_{1}(S_{n,k})\)**when \((p_{1},p_{2})=(0.7,0.3)\) and \(q_{t,i}=0.5(i+1)^{-\alpha}\)**.**} \\ \hline \hline \multirow{3}{*}{\(n\)} & \multicolumn{4}{c}{\(\alpha=0\)} & \multicolumn{4}{c}{\(\alpha=0.2\)} & \multicolumn{4}{c}{\(\alpha=0.5\)} & \multicolumn{4}{c}{\(\alpha=0.9\)} \\ \cline{2-15}  & \(k=1\) & \(k=2\) & \(k=5\) & \(k=10\) & \(k=1\) & \(k=2\) & \(k=5\) & \(k=10\) & \(k=1\) & \(k=2\) & \(k=5\) & \(k=10\) & \(k=1\) & \(k=2\) & \(k=5\) & \(k=10\) \\ \hline
10 & 0.6 & 0.6 & 1.0 & 1.0 & 0.6 & 0.6 & 1.0 & 0.6 & 0.6 & 1.0 & 0.6 & 0.7 & 0.9 & 0.9 & 0.7 & 0.7 & 0.8 & 0.8 & 0.8 \\
20 & 0.55 & 0.55 & 0.6 & 1.0 & 0.55 & 0.6 & 0.7 & 1.0 & 0.6 & 0.65 & 0.8 & 0.95 & 0.65 & 0.7 & 0.75 & 0.8 & 0.77 \\
50 & 0.52 & 0.48 & 0.52 & 0.54 & 0.52 & 0.56 & 0.54 & 0.66 & 0.56 & 0.58 & 0.64 & 0.86 & 0.64 & 0.62 & 0.78 & 0.76 \\
100 & 0.5 & 0.49 & 0.49 & 0.49 & 0.52 & 0.49 & 0.49 & 0.53 & 0.55 & 0.56 & 0.57 & 0.76 & 0.63 & 0.62 & 0.7 & 0.78 \\ \hline \hline \end{tabular}
\end{table}
Table 2. Empirical estimates of \(r_{1}(S_{n,k})\) based on \(5000\) iterations for each setting (i.e., entry in table) for each possible set of recommendations. These can be compared with our theoretical result showing that \(\lim_{n\rightarrow\infty}r_{1}(S_{n,1})=0.5\) for \(\alpha=0\). Blue indicates especially close to the result for \(r_{1}(S_{n,k})\), and red indicates cases that deviate from the theoretical result. The result is most applicable when \(k\) is small compared to \(n\) and when \(\alpha\) is smaller. Note also that \(S_{n,k}\) is relatively diverse in all cases when \(n\) is large compared to \(k\), and with small \(\alpha\) (i.e., there are many high-quality items per type).

Figure 4. Book recommendations that maximize accuracy on a train set are more accurate in evaluation, but also achieve less utility and diversity as compared to a heuristically-chosen diverse set. Here, accuracy is the average value of recommended items, utility is the maximum value of recommended items, and diversity is the average cosine distance between recommendations. The numbers plotted are averages over 100 trials for each of the 206 users we evaluated.

## References

* (1)
* Abdollahagouri et al. (2023) Himan Abdollahagouri, Zahra Nazari, Alex Gain, Clay Gibson, Maria Dimmakopoulou, J Andreetto, Benjamin Carterette, Mounila Lalmas, and Tracy Jorba. 2023. Calibrated Recommendations as a Minimum-Cost Flow Problem. _Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining_ (2023).
* Adamavicius and Kwon (2012) Gediminas Adamavicius and YoungOik Kwon. 2012. Improving Aggregate Recommendation Diversity Using Ranking-Based Techniques. _IEEE Transactions on Knowledge and Data Engineering_ 24 (2012), 899-911.
* Agrawal et al. (2009) Rakesh Agrawal, Srevin Golayton, Alan Halverson, and Samuel Jeong. 2009. Preserving Search Results. In _Proceedings of the Second ACM international Conference on Web Search and Data Mining_ (Barcelona, Spain) (WSDM '09). Association for Computing Machinery, New York, NY, USA, 5-14. [https://doi.org/10.1145/14987559.1498766](https://doi.org/10.1145/14987559.1498766)
* Alexandriais et al. (2015) Georgios Alexandriais, Georgios Solis, and Andreas Stufgolynski. 2015. Accuracy Versus Novelty in Recommender Systems: A Nonuniform Random Walk Approach. In _Recommender and Search in Social Networks_.

* Anderson et al. (2002) Ashton Anderson, Lucas Maystre, Ian Anderson, Rishadh Khutor, and Mounia Lalmas. 2002. Algorithmic Effects on the Diversity of Consumption on Spotify, In _Proceedings of 7th Web Conference on_ 2002 (Triesi, Taiwan) (WWW '20). Association for Computing Machinery, New York, NY, USA, 1255-1265. [https://doi.org/10.1145/3606233800314](https://doi.org/10.1145/3606233800314)
* Arikan et al. (2015) Arikan Arikan, Bashahav Kveton, Silbene Berkovsky, and Zheng Wen. 2015. Optimal Greedy Diversity for Recommendation. In _International Joint Conference on Artificial Intelligence_.
* Bertsimas and Misic (2015) Dimitris Bertsimas and Veliov V Mistic. 2015. Data-driven assortment optimization. _Management Science_ 1 (2015), 1-35.
* Brown and Agarwal (2022) William Brown and Arpit Agarwal. 2022. Diversified Recommendations for Agents with Adaptive Preference. In _Advances in Neural Information Processing Systems_. Alice H. Oh, Akdish Agarwal, Danielle Leghtaya, and Kyunghyun Cho (Eds.). [https://openreview.net/forum?id=VuNTF1F9P](https://openreview.net/forum?id=VuNTF1F9P)
* Carbonell and Goldstein (1998) Jaime Carbonell and Jude Goldstein. 1998. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In _Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval_. 385-386.
* Chen et al. (2022) Qinyi Chen, Negin Golrezaei, Fransicas Susan, and Ely Baskor. 2022. Fair assortment planning. _arXiv preprint arXiv:2208.07347_ (2022).
* Berceran (2021) Maurizio Ferrari Dacrezzi. 2021. Demonstrating the Equivalence of List Based and Aggregate Metrics to Measure the Diversity of Recommendations (Student Abstract). _Proceedings of the AAAI Conference on Artificial Intelligence_ (2021).
* Davis et al. (2014) James Mario Davis, Guillemo Gallego, and Huseyin Topalba. 2014. Assortment Optimization Under Variants of the Nested Logit Model. _Oper. Res._ 62 (2014), 250-273.
* Hossain et al. (2021) Otmar H Hossain, Omar Mouschuki, Guillemo Gallego, Vincei Gudeval, Salah Ilani, Samir, Sungo Kim, Ali Subligan, and Jingchen Wu. 2021. Joint assortment and inventory planning for heavy tailed demand. _Columbia Business School Research Paper Workshop_ (2021).
* Hossain and Topalbaq (2022) Omar H Hossain and Huseyin Topalbaq. 2022. Joint assortment optimization and customization under a mixture of multinomial logit models: On the value of personalized assortments. _Operations Research_ (2022).
* Eskandanian and Mobasher (2020) Farad Eskandanian and Barnhard Mobasher. 2020. Using Stable Matching to Optimize the Balance between Accuracy and Diversity in Recommendation. _Proceedings of the 28th ACM Conference on User Modeling, Adaptation and Personalization_ (2020).
* Fernandez-Tobias et al. (2016) Ignacio Fernandez-Tobias, Paolo Tomeo, Ivan Cantador, T. D. Nois, and Eugenio Di Sciascio. 2016. Accuracy and Diversity in COS-domain Recommendations for Cold-start Users with Positive-only Feedback. _Proceedings of the 10th ACM Conference on Recommender Systems_ (2016).
* Gallego and Topalbaq (2014) Guillemo Gallego and Huseyin Topalbaq. 2014. Constrained assortment optimization for the nested logit model. _Management Science_ 60, 10 (2014), 2583-2601.
* Gimpel et al. (2013) Krein Gimpel, Dhru Batra, Chris Dyer, and Gregory Shakhnarovich. 2013. A systematic exploration of diversity in machine translation. In _Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing_. 1100-111.
* Gogna and Majumdar (2017) Anupris Gogna and Angabhi Majumdar. 2017. Balancing accuracy and diversity in recommendations using matrix completion framework. _Knowl. Based Syst._ 125 (2017), 83-95.
* Goldberg (2014) David Goldberg. 2014. Diversity in Search. (2014).
* Guo et al. (2021) Wenshao Guo, Karl Krauth, Michael Jordan, and Nikhil Garg. 2021. The stereotyping problem in collaboratively filtered recommender systems. In _Equity and Access in Algorithms, Mechanisms, and Optimization_. 1-10.
* He (2022) Xiaoyun He. 2022. Does Utilizing Online Social Relations Improve the Diversity of Personalized Recommendations? _Int. J. Strategy, Decs._ 85, 13 (2022), 1-15.
* Hong and Page (2004) Lu Hong and Scott E Page. 2004. Groups of diverse problem solvers can outperform groups of high-ability problem solvers. _Proceedings of the National Academy of Sciences_ 101, 46 (2004), 16385-16389.
* Hou and Lin (2020) Zhigeng Hou and Jing Lin. 2020. A Two-phase Evolutionary Algorithm for Solving the Accuracy-diversity Delorma in Recommendation. _2020 IEEE Congress on Evolutionary Computation_ (CEC) (2020), 1-8.
* Isfuchi et al. (2021) Elvin Isfuchi, Matteo Pocchiai, and Alan Izaquila. 2021. Accuracy-diversity trade-off in recommender systems via graph convolutions. _Inf. Process. Manag._ 58 (2021), 102659.
* Jagabathula (2014) Srikanth Jagabathula. 2014. Assortment optimization under general choice. _Available at SSRN 521831_ (2014).
* Javari and Jalili (2015) Amin Javari and Mahali Jalili. 2015. A probabilistic model to resolve diversity-accuracy challenge of recommendation systems. _Knowledge and Information Systems_ 44 (2015), 609-627.
* Kleinberg and Raghavan (2018) Jon Kleinberg and Munirsh Raghavan. 2018. Selection problems in the presence of implicit bias. _arXiv preprint arXiv:1801.08353_ (2018).
* Kleinberg et al. (2018) Jon Kleinberg, Emily Raghavan, and Varela Rao. 2018. Team performance with test scores. _ACM Transactions on Economics and Computation_ (TEC) 6, 3-4 (2018), 1-26.
* Kleinberg et al. (2023) Jon Kleinberg, Emily Raghavan, and Varela Rao. 2023. Calibrated Recommendations for Users with Denying Attention. _ArXiv_ abs/2302.03239 (2023).
* Kolk and Fisher (2007) A Girshank Kolk and Marshall I. Fisher. 2007. Demand estimation and assortment optimization under subdistribution: Methodology and application. _Operations Research_ 55, 6 (2007), 1001-10217. University in recommender systems-A survey. _Knowledge-based systems_ 123 (2017), 154-162.
* Kim et al. (2021) Jeryeong Kim, Il Young Choi, and Qingdong Li. 2021. Customer Satisfaction of Recommender-System: Examining Accuracy and Diversity in Several Types of Recommendation Approaches. _Sustainability_ 13 (2021), 6165.
* Li et al. (2017) Emamad Li, Dominic Kowal, Markus Reitz-Mans, Valentiv Satheesh, and E. Lee. 2017. Beyond Accuracy Optimization: On the Value of Item Embeddings for Student Job Recommendations. _ArXiv_ abs/1710.07262 (2017).
* Liu et al. (2012) Jianguo Liu, Kervati Shi, and Qiang Guo. 2012. Solving the accuracy-diversity dilemma via directed random walks. _Physical review. E, Statistical, nonlinear, and self metric physics_ 81 (2012), 016113.
* Medvedev et al. (2019) Nam Medvedev, Taylor Gordon, and Hostin Wu. 2019. Powered by AI: Instagram's Explore recommender system. (2019).
* (2008) Scott Page. 2008. The Difference. Princeton University Press.
* Park and Han (2013) Sung-Hyuk Park and Sung FI Han. 2013. From Accuracy to Diversity in Product Recommendation: Relationship Between Diversity and Customer Retention. _International Journal of Electronic Commerce_ 18 (2013), 51 -72.
* Patra et al. (2022) Gourah K Patra, Lorenzo Poczura, Laura Mitchell, Quijeng Zhang, Meike Zehlike, and Nikhil Garg. 2022. Fair ranking: a critical review, challenges, and future directions. In _2022 ACM Conference on Fairness, Accountability, and Transparency_. 1992-1924.
* Fundel et al. (2017) Brie Fundel, Thilo Haas, and Abraham Bernstein. 2017. Fewer Flops at the Top: Accuracy, Diversity, and Regularization in Two-Class Collaborative Filtering. _Proceedings of the Eleventh ACM Conference on Recommender Systems_ (2017).
* Petersen (2022) Victoria Petersen. 2022. Have We Reched Peak Plant Milk? Not Even Close. _The New York Times_ (2022). [https://www.nytimes.com/2022/02/28/dining/plant-based-multi.html](https://www.nytimes.com/2022/02/28/dining/plant-based-multi.html)
* Rasa and Ding (2021) Sinan Rasa and Chen Ding. 2021. Deep Neural Network to Traided Between Accuracy and Diversity in a News Recommender System. _IEEE International Conference on Big Data_ (Big Data) (2021), 5246-5256.
* Rendle (2012) Steffen Rendle. 2012. Factorization Machines with libFM. _ACM Trans. Intell. Syst._ 104 (2012), 3, Article 57 (May 2012), 2 pages.
* Rodolle et al. (2021) Kiri Rodolle, Hemank Lamba, and Rayad Ghani. 2021. Empirical observation of negligible fairness-accuracy trade-offs in machine learning for public policy. _Nature Machine Intelligence_ 3, 10 (2021), 896-904.
* Schmeidtenborg et al. (2010) Patr Rusmevichientong, Zuo-Jun Ma, Shen, and David B Shmoys. 2010. Dynamic assortment optimization with a multinomial logit choice model and capacity constraint. _Operations research_ 58, 6 (2010), 1666-1808.
* Ruuschiettenborg et al. (2014) Paul Ruuschiettenborg, David Shmoys, Chason Tong, and Huseyin Topalbaq. 2014. Assortment optimization under the multinomial logit model with random choice parameters. _Prolation and Operations Management_ 23, 11 (2014), 2023-2039.
* Su et al. (2022) Joao Su, Varela Oueiro Marinaho, Ana Rita Magalhaes, Tingo Lacerda, and Diogo Goncalves. 2022. Diversity Vs Relevance: A Practical Multi-objective Study in Luxury Fashion Recommendations. _Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval_ (2022).
* Seymann et al. (2021) Sinan Seymann, Himan Abdollahagouri, and Edward C. Malthhouse. 2021. A Constrained Optimization Approach for Calibrated Recommendations. _Proceedings of the 15th ACM Conference on Recommender Systems_ (2021).
* Seymann and McAuley (2018) Harald Seok. 2018. Calibrated recommendations. In _Proceedings of the 12th ACM conference on recommender systems_, 154-162.
* Wang and McAuley (2018) Mengting Wang and Julian J. McAuley. 2018. Item recommendation on monom-ton behavior chains. In _Proceedings of the 12th ACM Conference on Recommender Systems, RecSys 2018, Vancouver, BC, Canada, October 2-7, 2018_. Sola, Texas, Michael D. Ekstrand, Xavier Amatriain, and John O'Tonovan (Eds.). ACM, 86-94.

[https://doi.org/10.1145/3240232.3240369](https://doi.org/10.1145/3240232.3240369)
* [405] Shenggu Wu, Huaizhou Kou, Chao Lv, Wanli Huang, Lianyong Qi, and Hongya Wang. 2020, Service Recommendation with High Accuracy and Diversity. _Wirel. Commun._, Mo. Comput._, 2020 (2020), 8828992:1-882892:10.
* [406] Meike Zehilie, Ke Xing, Yang Jin, Julia Stoyanovich. 2021. Fairness in ranking: A survey. _arXiv preprint arXiv:2103.14000_ (2021).
* [407] Mi Zhang and Neil J. Hurley. 2008. Avoiding monotony: improving the diversity of recommendation lists. In _ACM Conference on Recommender Systems_.

* [409]

## Appendix A Extended Related Work

Our work sits at the intersection of two broad sets of work. On the one hand are arguments that diversity is key to achieving efficiency. On the other are those that cast diversity as in conflict with efficiency or accuracy, but perhaps that diversity should nevertheless be pursued as an axiomatic good.

Broadly, our work seeks to understand this tension by sharply characterizing the _amount_ of diversity in efficient solutions, as a function of key setting characteristics: user utilities and consumption constraints, and uncertainty in the item quality distribution. In particular, our results characterize _in what settings_ the intuition regarding diversity being efficient holds, and in what settings they may be in conflict.

_The (efficiency) benefits of diversity._ The importance of diversity for efficiency is an old idea present across many fields; Page (1998) synthesizes the conceptual and empirical arguments in support of this principle. Hong and Page (1998) develop a model in which a randomly selected team of problem solvers outperforms a team of the individually best-performing agents, due to diversity in problem solving perspective (Kleinberg and Raghu (2000) show that, in some settings, there exist _tests_ under which selecting the best-performing agents again becomes optimal). Kleinberg and Raghavan (2001) show that constraints promoting diversity can improve efficiency when they work to counteract a decision-maker's biases. Agrawal et al. (2009) develop an algorithm to diversify search results, to minimize the risk of user dissatisfaction. We are particularly influenced by the work of Steck (2000), who presents the intuition that recommendations should be _calibrated_: "When a user has watched, say, 70 romance movies and 30 action movies, then it is reasonable to expect the personalized list of recommended movies to be comprised of about 70% romance and 30% action movies as well." Guo et al. (2011) show that collaborative filtering-based recommendations may not be able to effectively show users such a diverse set of content, harming efficiency.

More broadly, researchers studying various combinatorial optimization problems may find it obvious that homogeneous solutions can be sub-optimal; indeed, in classical problems like _maximum coverage_, redundancy is undesirable.

Our work particularly is intimately connected to the large literature on assortment optimization (Bradley, 1998; Kleinberg and Raghu, 2000; Kleinberg and Raghu, 2000; Kleinberg et al., 2001; Kleinberg et al., 2002; Kleinberg et al., 2003; Kleinberg et al., 2004; Kleinberg et al., 2005; Kleinberg et al., 2006; Kleinberg et al., 2007). That literature also considers consumption-constrained consumer item selections based on an intermediary's recommendations (e.g., that customers picks one item according to a multinomial choice model). The literature primarily devises _approximation algorithms_ to find the optimal recommendation ("assortment") as a function of the consumer's choice model, platform objective, and the item distribution. In other words, an implicit premise of this literature is that the naive approach of presenting the items with highest individual expected values is sub-optimal, i.e., that optimal assortments are not completely 'homogeneous.' On the other hand, optimal assortments are not necessarily diverse; roughly speaking, the results of El Housni and Topaloglu (1998) imply that a standard assortment approach (Mixed MNL) might produce solutions that are not "diverse" enough to satisfy multiple customer types, and so there is benefit to personalize to each type.78 Our work contributes to this literature by (a) examining the implicit premise that optimal assortments are not homogeneous (i.e., when is the naive9 approach sufficient?); and (b) showing the characteristics under which optimal assortments are not diverse.

Footnote 78: We thank the authors for highlighting this connection to us.

_Diversity and fairness as a contrast to efficiency and accuracy._ On the other hand, many works start with the premise that--although diversity may conflict with efficiency or accuracy--it is an axiomatic good that should be pursued. For example, diversity is often considered to be inherently desirable from a fairness perspective and user satisfaction perspective. As a result, there is a wide body of work devoted to optimizing for various metrics of diversity. A common approach (taken, for example, in Carbonell and Goldstein (2000) and Gimpel et al. (2000)) is to consider an objective function that balances a weighted measure of "accuracy" or "relevance" with a measure of diversity. More recently, Brown and Agarwal (2009) consider set recommendation for an agent with adaptive preferences, to ensure that consumption over time is diverse. Numerous metrics for diversity have been proposed--we refer the reader to Kunaver and Pozrl (2000) for a survey. Similarly, the fair ranking and recommendation literature (see Patro et al. (2009) and Zehlike et al. (2009) for recent surveys) considers metrics and methods for fairness in such problems. On the other hand, empirical work has demonstrated that such tradeoffs may be small in practice (Kunaver and Pozrl, 2009). Such formulations imply that there is a tension between diversity and measures of accuracy.

## Appendix B Details on Computational Experiments / Additional Experiments

We provide additional details about the experiments we conduct in Section 5.

### Finite number of recommendations and beyond unit consumption constraints

We explain how we computed empirically optimal sets in 5.1. For each recommendation setting, we determine the set that maximizes \(\mathsf{util}_{k}\) by manually computing

\[\max\left\{\sum_{t\in\llbracket 2,t\in\llbracket n_{i}\rrbracket}V_{t,i,\cdot},\quad k\right\} \tag{35}\]

for sets with all possible combinations of item type representations. Specifically, in computing \(S_{n,k}\), we consider the sets of the form \((i,n-i)\) for \(i\in\{0,1,\cdots,n\}\). For each of these sets \(S\), we compute \(\mathsf{util}_{k}(S)\) directly, and take the average over \(5000\) iterations. We then choose the

[MISSING_PAGE_FAIL:12]

We constructed two sets of recommendations for each user given the training set \(V_{\text{train}}\): the accuracy-maximizing set \(S_{n}\) and a diverse set \(S_{\text{diverse}}\). We construct these sets as follows.

\[S_{n}\]

 is the set that maximizes average accuracy when user preferences are drawn from the train set: \[\frac{1}{10}\sum_{\eta_{\text{pref}}\in\mathcal{E}_{\text{train}}^{\prime}}\frac {1}{n}\sum_{\eta\in S_{n}}u(\eta,\text{pref}).\] (39)

Computationally, we can determine this set \(S\) by choosing the \(n\) individual embeddings \(\imath\) in \(V^{\prime}\) that maximize

\[\frac{1}{10}\sum_{\eta_{\text{pref}}\in\mathcal{E}_{\text{train}}^{\prime}}u( \imath,\upsilon_{\text{pref}}). \tag{40}\]

We choose \(S_{\text{diverse}}\) using a heuristic method. We iterate over items in the train set, and select the closest item to the train set in terms of cosine distance that has not yet been selected. At iteration \(i\in[n]\), we let \(\upsilon_{\text{pref}}\) be the \(i\) (mod 10)-th item in \(V_{\text{train}}\) and \(S_{\text{diverse},i-1}\) be the set of \(i-1\) items selected so far. Then we construct \(S_{\text{diverse},i}\) by adding the item in \(V^{\prime}\) that maximizes

\[\imath\cdot\upsilon_{\text{pref}} \tag{41}\]

to the set \(S_{\text{diverse},i-1}\), where \(S_{\text{diverse},0}=\emptyset\). We then choose \(S_{\text{diverse}}=S_{\text{diverse},n}\).

To evaluate the diversity of a set \(S\) of \(n\) recommendations, we use the average cosine distance between embeddings:

\[\frac{1}{\binom{n}{2}}\sum_{\alpha,\sigma^{\prime}\in S}1-\imath\cdot\upsilon ^{\prime}. \tag{42}\]

The results we report are averages over all users and over 100 independently drawn training sets for each user.

## Appendix C A Setup with item values from general distributions

In this section, we consider a model in which items can have values distributed arbitrarily over \(\mathbb{R}\). In such a model, there are once again \(m\) types of items indexed by \([m]=\{1,2,\cdots,m\}\). A user prefers exactly one type of item, preferring type \(t\in[m]\) with probability \(p_{t}\). As before, \(p_{t}\) give **probabilities**.

Now, the value of the \(i\)-th item of type \(t\) is a random variable \(X_{i}^{(t)}\) if the user prefers type \(t\) and \(0\) otherwise (so its expected value is \(p_{t}\mathbb{E}[X_{i}^{(t)}]\)). We refer to \(X_{i}^{(t)}\) as a **conditional item value** (the value of an item conditional on the user preferring the item's type). Conditional item values are independent conditional on the user's preference. The case when \(X_{i}^{(t)}\) is Bernoulli corresponds to our main setup.

Once specifying the type probabilities and conditional item values, we again define \(S_{n}\) as the accuracy-maximizing set of recommendations, that which maximizes the expected total value of recommended items. We let \(S_{n,k}\) be the set of recommendations that maximizes the expected value of the top \(k\) recommended items, thus corresponding to a consumption constraint of \(k\).

Recall that \(r_{t}(S)\) gives the proportion of items in \(S\) that are of type \(t\). To succinctly introduce our main result in this setting--an analog to Theorem 1--we introduce the following way to measure diversity.

**Definition 3** (\(\gamma\)-homogeneity).: A set \(S\) is \(\mathbf{\gamma}\)**-homogeneous** if for all \(t\in[m]\),

\[r_{t}(S)=\frac{p_{t}^{\gamma}}{\sum_{i=1}^{m}p_{t}^{\gamma}}. \tag{43}\]

\(\gamma\)-homogeneity captures several intuitive notions of diversity, using \(p_{1},\cdots,p_{m}\) as a benchmark:

* When \(\gamma=0\), \(r_{t}(S)=\frac{1}{m}\). There is "equal representation."
* When \(\gamma=1\), \(r_{t}(S)=p_{t}\). There is "proportional representation," where an item type is represented in proportion to its likelihood.
* When \(\gamma=\infty\), \(r_{t}(S)=1\) for \(t=\arg\max_{i\in[m]}p_{t}\) and \(r_{t}(S)=0\) otherwise. There is "complete homogeneity," where only the highest-likelihood item type is represented.

A smaller \(\gamma\) corresponds to more diversity, with \(\gamma\leq 1\) indicating _at least proportional_ representation. In practice, it is challenging to show that individual sets are \(\gamma\)-homogeneous; for one, since sets have an integer number of items from each type, it is typically impossible to obtain the exact ratios in (43). Instead, we will give primarily asymptotic results, showing that as \(n\) grows large, the optimal set \(S_{n,k}\) approaches \(\gamma\)-homogeneity. Formally, we define \(\gamma\)-homogeneity over sequences of sets:

**Definition 4** (\(\gamma\)-homogeneity for set sequences).: A sequence of sets \(\{S_{n}\}_{n=1}^{\infty}\) is \(\mathbf{\gamma}\)**-homogeneous** if for all \(t\in[m]\),

\[\lim_{n\rightarrow\infty}r_{t}(S_{n})=\frac{p_{t}^{\gamma}}{\sum_{i=1}^{m}p_{ i}^{\gamma}}. \tag{44}\]

We can then state our result as follows.

**Theorem 4**.: _Suppose \(X_{i}^{(t)}\overset{\text{iid}}{\sim}\mathcal{D}\) where \(\mathcal{D}\) has finite mean. Then the following statements hold._1. _[Finite Discrete]__]__If_ \(\mathcal{D}\) _is a finite discrete distribution,_ \(\{S_{n,k}\}_{n=1}^{\infty}\) _is_ \(0\)_-homogeneous._
2. _[Bounded]__]_ _If_ \(\mathcal{D}\) _has support bounded from above by_ \(M\) _with_ \(pdf_{\mathcal{D}}\) _satisfying_ 1999
3. \[\lim_{x\to M}\frac{f_{\mathcal{D}}(x)}{(M-x)^{\beta-1}}=c\] (45) _for some_ \(\beta,c>0\)_, then_ \(\{S_{n,k}\}_{n=1}^{\infty}\) _is_ \(\frac{\beta}{\beta+1}\)_-homogeneous._ 1999
4. _[This pdf class contains beta distributions, including the uniform distribution.)_ 1999
5. _[Exponential tail]__]_ _If_ \(\mathcal{D}=\operatorname{Exp}(\lambda)\) _for_ \(\lambda>0\)_, then_ \(\{S_{n,k}\}_{n=1}^{\infty}\) _is_ \(1\)_-homogeneous._ 1999
6. _[Heavy tail]__]_ _If_ \(\mathcal{D}=\operatorname{Pareto}(\alpha)\) _for_ \(\alpha>1\)_, then_ \(\{S_{n,k}\}_{n=1}^{\infty}\) _is_ \(\frac{\alpha}{\alpha-1}\)_-homogeneous._ 1999
7. _Additionally,_
8. \(S_{n}\) _contains only items of type_ \(t=\arg\max_{t\in[m]}p_{t}\)_._

As Table 5 illustrates, the theorem shows how for fixed \(k\), the diversity of optimal solutions depends on the tail behavior of \(\mathcal{D}\). In fact, we can obtain \(\gamma\)-homogeneity for any \(\gamma\):

**Corollary 5**.: _For any \(\gamma\geq 0\), there exists \(\mathcal{D}\) such that when \(X_{i}^{(t)}\overset{\text{id}}{\sim}\mathcal{D}\) and \(k\) is fixed, \(\{S_{n,k}\}_{n=1}^{\infty}\) is \(y\)-homogeneous._

Intuitively, heavy-tailed distributions (part (iv)) induce less diverse recommendations since the marginal returns of recommending more items from the same type remains high: drawing more samples from a heavy-tailed distribution produces ever-increasing item values. This contrasts with bounded distributions like the uniform distribution (part (ii)), where once an item has close to the maximum value, additional draws of that type will not further improve the utility significantly.

Part (i) of the theorem includes Theorem 1 as a subcase when \(\mathcal{D}\) is Bernoulli. We prove Theorem 4 in appendix E.

## Appendix D Main Proofs

### A central lemma: connecting diminishing returns to diversity

Let \(\mathbb{Z}_{\geq 0}\) denote the set of non-negative integers and \(z_{n}\subset\mathbb{Z}_{\geq 0}^{m}\) denote the set of \(m\)-tuples whose elements sum to \(n\). We will say that a function \(h:\mathbb{Z}_{\geq 0}\to\mathbb{R}\) is _strictly concave_ if \(h_{t}(z+1)-h_{t}(z)<h_{t}(z)-h_{t}(z-1)\) for all \(a\).

**Lemma D.1**.: _Consider an integer \(m\) and \(p_{1},p_{2},\cdots,p_{m}\geq 0\). Let \(h:\mathbb{Z}_{\geq 0}\rightarrow\mathbb{R}\) be monotonically increasing. For each positive integer \(n\), choose \((z_{1}^{(n)},\cdots,z_{m}^{(n)})\) such that_

\[(z_{1}^{(n)},\cdots,z_{m}^{(n)})\in\underset{(z_{1},\cdots,z_{m})\in\mathbb{Z} _{n}}{\arg\max}\sum_{t=1}^{m}\lambda_{t}h_{t}(z_{t}), \tag{46}\]

_and define_

\[r_{t}^{(n)}=\frac{z_{t}^{(n)}}{n}. \tag{47}\]

_Then the following statements hold._

1. _Suppose there exist constants_ \(A,B>0\) _and_ \(\sigma<0\) _such that_ \[\lim_{a\rightarrow\infty}\frac{\log(A-h_{t}(z))}{Bz^{\sigma}}=1.\] (48) _Then_ \[\lim_{n\rightarrow\infty}r_{t}^{(n)}=\frac{1}{m}.\] (49)
2. _Suppose there exist constants_ \(A_{1},A_{2},\cdots,A_{m},B>0\) _and_ \(\sigma<0\) _such that_ \[\lim_{a\rightarrow\infty}\frac{A_{t}-h_{t}(z)}{Bz^{\sigma}}=1.\] (50) _Then_ \[\lim_{n\rightarrow\infty}r_{t}^{(n)}=\frac{\lambda_{t}^{\frac{1}{1-\sigma}}}{ \sum_{t=1}^{m}\lambda_{t}^{\frac{1}{1-\sigma}}}.\] (51)
3. _Suppose_ \(h\) _is strictly concave, and that there exist constants_ \(B,C>0\) _such that_ \[\lim_{a\rightarrow\infty}h_{t}(z)-B\log a-C=0.\] (52) _Then_ \[\lim_{n\rightarrow\infty}r_{t}^{(n)}=\lambda_{t}.\] (53)
4. _Suppose_ \(h\) _is strictly concave, and that there exist constants_ \(B>0\) _and_ \(0<\sigma<1\) _such that_ \[\lim_{a\rightarrow\infty}\frac{h_{t}(z)}{Bz^{\sigma}}=1.\] (54) _Then_ \[\lim_{n\rightarrow\infty}r_{t}^{(n)}=\frac{\lambda_{t}^{\frac{1}{1-\sigma}}}{ \sum_{t=1}^{m}\lambda_{t}^{\frac{1}{1-\sigma}}}.\] (55)

We spend the remainder of the section proving Lemma D.1. A useful first step is to show that in each of parts (i)-(iv), we have that

\[\lim_{n\rightarrow\infty}z_{t}^{(n)}=\infty \tag{56}\]

for each \(t\in[m]\), allowing us to use the asymptotic assumptions in the lemma's statement.

Assume for the sake of contradiction that there exists \(t\in[m]\) and an integer \(d\) such that for any integer \(N\) there exists \(n>N\) for which \(z_{t}^{(n)}<d\). Since \(h\) is strictly increasing and \(d\) is finite, there exists \(\delta>0\) such that

\[h_{t}(z+1)-h_{t}(z)>\delta \tag{57}\]

for all \(a<d\). Also, there exists an integer \(N^{\prime}\) such that for all \(a>N^{\prime}\),

\[h_{t}(z)-h_{t}(z-1)<\delta\cdot\min_{t\in[m]}\frac{\lambda_{t}}{\lambda_{t}}. \tag{58}\]

(58) holds in parts (i)-(ii) because \(h\) is monotonically increasing and is upper bounded by \(A\), and in parts (iii)-(iv) because \(h\) is strictly concave.

Now consider \(N=N^{\prime}m\). Then there exists \(n>N\) such that \(z_{t}^{(n)}<d\). Since \(\sum_{t=1}^{m}z_{t}^{(n)}=n>N^{\prime}m\), there exists \(t^{\prime}\in[m]\) such that \(z_{t^{\prime}}^{(n)}>N^{\prime}\). Thus,

\[p_{t^{\prime}}h_{t}(z_{t^{\prime}}^{(n)})-p_{t^{\prime}}h_{t}(z_{t^{\prime}}^{ (n)}-1)<\lambda_{t}\delta<\lambda_{t}h_{t}(z_{t}^{(n)}+1)-\lambda_{t}h_{t}(z_ {t}^{(n)}), \tag{59}\]

which implies that the switch \(z_{t}^{(n)}\to z_{t}^{(n)}+1,z_{t^{\prime}}^{(n)}\to z_{t^{\prime}}^{(n)}-1\) increases

\[\sum_{t=1}^{m}\lambda_{t}h_{t}(z_{t}^{(n)}), \tag{60}\]

[MISSING_PAGE_FAIL:16]

for each \(t\in[m]\). Then observe that

\[\lim_{n\to\infty}\frac{\sum_{t=1}^{m}\lambda_{t}(A_{t}-h_{t}(z_{t}^{(n)}))}{\sum_{t =1}^{m}\lambda_{t}(A_{t}-h_{t}(\tilde{z}_{t}^{(n)}))}=\frac{\sum_{t=1}^{m} \lambda_{t}(A_{t}-h_{t}(z_{t}^{(n)}))}{\sum_{t=1}^{m}\lambda_{t}(A_{t}-h_{t}( \tilde{z}_{t}^{(n)}))}\cdot\lim_{n\to\infty}\frac{\sum_{t=1}^{m}\lambda_{t}(Bz_{ t}^{(n)})^{\sigma}}{\sum_{t=1}^{m}\lambda_{t}(A_{t}-h_{t}(z_{t}^{(n)}))}\cdot\lim_{n\to \infty}\frac{\sum_{t=1}^{m}\lambda_{t}(A_{t}-h_{t}(z_{t}^{(n)}))}{\sum_{t=1}^{m }\lambda_{t}B(\tilde{z}_{t}^{(n)})^{\sigma}} \tag{75}\] \[=\lim_{n\to\infty}\frac{\sum_{t=1}^{m}\lambda_{t}(A_{t}-h_{t}(z_{t }^{(n)}))}{\sum_{t=1}^{m}\lambda_{t}(A_{t}-h_{t}(\tilde{z}_{t}^{(n)}))}\cdot \frac{\sum_{t=1}^{m}\lambda_{t}B(z_{t}^{(n)})^{\sigma}}{\sum_{t=1}^{m}\lambda_{ t}(A_{t}-h_{t}(z_{t}^{(n)}))}\cdot\frac{\sum_{t=1}^{m}\lambda_{t}(A_{t}-h_{t}( \tilde{z}_{t}^{(n)}))}{\sum_{t=1}^{m}\lambda_{t}B(\tilde{z}_{t}^{(n)})^{\sigma}}\] (76) \[=\lim_{n\to\infty}\frac{\sum_{t=1}^{m}\lambda_{t}B(z_{t}^{(n)})^{ \sigma}}{\sum_{t=1}^{m}\lambda_{t}B(\tilde{z}_{t}^{(n)})^{\sigma}}\] (77) \[=\frac{\sum_{t=1}^{m}\lambda_{t}r_{t}^{\sigma}}{\sum_{t=1}^{m} \lambda_{t}^{\sigma}\tilde{r}_{t}^{\sigma}}>1, \tag{78}\]

where (75) follows from the latter two limits being equal to \(1\), (76) follows from the product rule for limits, and (78) follows from the observation that for \(\sigma<0\)

\[\sum_{t=1}^{m}\lambda_{t}x_{t}^{\sigma}, \tag{79}\]

subject to the constraint \(\sum_{t=1}^{m}x_{t}=1\) for \(x_{t}\geq 0\) has a unique minimum at \((x_{1},\cdots,x_{m})=(\widehat{r}_{1},\cdots,\widehat{r}_{m})\). This is direct, for example, by using Lagrange multipliers. (78) implies that

\[\lim_{n\to\infty}\frac{\sum_{t=1}^{m}\lambda_{t}h_{t}(z_{t}^{(n)})}{\sum_{t=1} ^{m}\lambda_{t}h_{t}(\tilde{z}_{t}^{(n)})}<1. \tag{80}\]

It follows that for \(n\) sufficiently large, \(\sum_{t=1}^{m}\lambda_{t}h_{t}(z_{t}^{(n)})<\sum_{t=1}^{m}\lambda_{t}h_{t}( \tilde{z}_{t}^{(n)})\), as desired.
* In this part, \(h\) is strictly concave, and there exist constants \(B,C>0\) such that \[\lim_{n\to\infty}h_{t}(z)-B\log a-C=0.\] (81)

We set \(\widehat{r}_{t}:=\lambda_{t}\) for each \(t\in[m]\). Then observe that

\[\lim_{n\to\infty}\sum_{t=1}^{m}\lambda_{t}h_{t}(z_{t}^{(n)})-\sum_{t=1}^{m} \lambda_{t}h_{t}(\tilde{z}_{t}^{(n)}) \tag{82}\] \[=\lim_{n\to\infty}\sum_{t=1}^{m}\lambda_{t}B\log z_{t}^{(n)}-\sum _{t=1}^{m}\lambda_{t}B\log\tilde{z}_{t}^{(n)}\] (83) \[=B\log n+B\sum_{t=1}^{m}\lambda_{t}\log r_{t}-B\log n-B\sum_{t=1} ^{m}\lambda_{t}\log\widehat{r}_{t}\] (84) \[<0. \tag{85}\]

The final inequality here follows from the observation that

\[\sum_{t=1}^{m}\lambda_{t}\log x_{t}, \tag{86}\]

subject to the constraint \(\sum_{t=1}^{m}x_{t}=1\) for \(x_{t}>0\) has a unique minimum at \((x_{1},\cdots,x_{m})=(\widehat{r}_{1},\cdots,\widehat{r}_{m})\). This is direct, for example, by using Lagrange multipliers.

It follows that for \(n\) sufficiently large, \(\sum_{t=1}^{m}\lambda_{t}h_{t}(x_{t}^{(n)})<\sum_{t=1}^{m}\lambda_{t}h_{t}( \tilde{z}_{t}^{(n)})\), as desired.
* In this part, \(h\) is strictly concave, and there exist constants \(B>0\) and \(0<\sigma<1\) such that \[\lim_{a\to\infty}\frac{h_{t}(z)}{Bz^{\sigma}}=1.\] (87)

We set

\[\widehat{r}_{t}=\frac{\lambda_{t}^{\frac{1}{1-\sigma}}}{\sum_{t=1}^{m}\lambda_ {t}^{\frac{1}{1-\sigma}}} \tag{88}\]

for each \(t\in[m]\). Then observe that

\[\lim_{n\to\infty}\frac{\sum_{t=1}^{m}\lambda_{t}h_{t}(z_{t}^{(n)})}{\sum_{t=1}^ {m}\lambda_{t}h_{t}(\tilde{z}_{t}^{(n)})}=\lim_{n\to\infty}\frac{\sum_{t=1}^{m} \lambda_{t}B(z_{t}^{(n)})^{\sigma}}{\sum_{t=1}^{m}\lambda_{t}B(\tilde{z}_{t}^{( n)})^{\sigma}}=\frac{\sum_{t=1}^{m}\lambda_{t}r_{t}^{\sigma}}{\sum_{t=1}^{m} \lambda_{t}\tilde{r}_{t}^{\sigma}}<1. \tag{89}\]The first equality is a consequence of the asymptotic assumption on \(h\) and the product rule for limits (as in part (ii). The final inequality here follows from the observation that for \(\sigma>0\),

\[\sum_{t=1}^{m}\lambda_{t}x_{t}^{\sigma}, \tag{90}\]

subject to the constraint \(\sum_{t=1}^{m}x_{t}=1\) for \(x_{t}>0\) has a unique maximum at \((x_{1},\cdots,x_{m})=(\widehat{r}_{1},\cdots,\widehat{r}_{m})\). This is direct, for example, by using Lagrange multipliers.

It follows that for \(n\) sufficiently large, \(\sum_{t=1}^{m}\lambda_{t}h_{t}(z_{t}^{(n)})<\sum_{t=1}^{m}\lambda_{t}h_{t}( \widehat{z}_{t}^{(n)})\), as desired.

### Proof of Theorem 2.A

We prove Theorem 2.A, where we are interested in the accuracy-maximizing set of recommendations. For recommendations \(S=(z_{1},z_{2},\cdots,z_{m})\), we have that

\[\sum_{t=1}^{m}\lambda_{t}h_{t}(z_{t}), \tag{91}\]

where

\[\lambda_{t}=p_{t}q_{t} \tag{92}\]

\[h_{t}(z)=\sum_{t=1}^{a}(i+\beta)^{-\alpha}. \tag{93}\]

We consider three cases: \(0<\alpha<1,\alpha=1\), and \(\alpha>1\).

_Case 1:_\(0<\alpha<1\). For \(0<\alpha<1\), observe that

\[\sum_{t=1}^{a}(i+\beta)^{-\alpha}<\int_{d}^{z+\beta}x^{-\alpha}\,dx =\left[\frac{1}{1-\alpha}x^{1-\alpha}\right]_{d}^{z+\beta} \tag{94}\] \[=\frac{1}{1-\alpha}(z+\beta)^{1-\alpha}-\frac{1}{1-\alpha}d^{1-\alpha} \tag{95}\]

and

\[\sum_{t=1}^{a}(i+\beta)^{-\alpha}>\int_{\beta+1}^{z+\beta+1}x^{- \alpha}\,dx =\left[\frac{1}{1-\alpha}x^{1-\alpha}\right]_{\beta+1}^{z+\beta+1} \tag{96}\] \[=\frac{1}{1-\alpha}(z+\beta+1)^{1-\alpha}-\frac{1}{1-\alpha}( \beta+1)^{1-\alpha}. \tag{97}\]

It follows that

\[\lim_{a\to\infty}\frac{h_{t}(z)}{z^{1-\alpha}}=\frac{1}{1-\alpha}, \tag{98}\]

and the result in this case follows by applying Lemma D.1(iv).

_Case 2:_\(\alpha=1\). Now for \(\alpha=1\), we have that

\[\sum_{t=1}^{\alpha}(i+\beta)^{-\alpha}=c\sum_{t=\beta+1}^{2+\beta}\frac{1}{i}. \tag{99}\]

\[\lim_{a\to\infty}h_{t}(z)-c\log a+c\gamma-c\sum_{t=1}^{d}\frac{1}{i}=0, \tag{100}\]

where \(\gamma\) is the Euler-Mascheroni constant The result in this case follows by applying Lemma D.1(iii).

_Case 3:_\(\alpha>1\). Finally, for \(\alpha>1\), we have that

\[\sum_{t=1}^{\infty}(i+\beta)^{-\alpha}=S \tag{101}\]

for some finite \(S\). Then note that

\[\sum_{t=1}^{a}(i+\beta)^{-\alpha}=S-\sum_{t=\alpha+1}^{\infty}(i+\beta)^{- \alpha}. \tag{102}\]

[MISSING_PAGE_FAIL:19]

Subject to the constraint \(\sum_{t=1}^{m}x_{t}=n,g(x_{1},\cdots,x_{m})\) is maximized exactly when

\[\frac{\partial g}{\partial x_{1}}=\frac{\partial g}{\partial x_{2}}=\cdots=\frac {\partial g}{\partial x_{m}}. \tag{115}\]

We have

\[\frac{\partial g}{\partial x_{t}}=-p_{t}(1-q_{t})^{x_{t}}\log(1-q_{t}). \tag{116}\]

Solving \(\partial g/\partial x_{t}=\partial g/\partial x_{j}\) gives

\[p_{i}(1-q_{t})^{x_{t}}\log(1-q_{i})=p_{j}(1-q_{j})^{x_{j}}\log(1-q_{j}) \tag{117}\]

\[\implies\log p_{i}+x_{i}\log(1-q_{i})+\log\log(1-q_{i})=\log p_{j}+x_{j}\log(1 -q_{j})+\log\log(1-q_{j}) \tag{118}\]

It follows that \(z_{t}\propto\frac{1}{\log(1-q_{t})}\) for all \(t\), where we have applied Lemma D.2. 

#### d.3.2 Case when \(\alpha>1\)

We now consider the case \(\alpha>1\). Given recommendations \(S=(z_{1},z_{2},\cdots,z_{m})\) we have that

\[\mathsf{util}_{11}(S)=\sum_{t=1}^{m}\lambda_{t}h_{t}(z_{t}), \tag{119}\]

where we set

\[\lambda_{t} =p_{t}q_{t} \tag{120}\] \[h_{t}(z) =\frac{1-\prod_{i=1}^{z}(1-q_{t}(i+\beta)^{-\alpha})}{q_{t}}. \tag{121}\]

It suffices now to show the desired asymptotic properties for \(h\) depending on \(\alpha\), and applying Lemma D.1.

Note that

\[\prod_{i=\beta+1}^{\infty}(1-q_{i}i^{-\alpha})=S_{t} \tag{122}\]

for a finite constant \(S_{t}\).

We note the following fact, which will be helpful in our analysis:

\[1-x>e^{-x-x^{2}}\quad\text{for }0<x<\frac{1}{2}. \tag{123}\]

We have that

\[\prod_{i=z+\beta+1}^{\infty}(1-q_{i}i^{-\alpha}) <\prod_{i=z+\beta+1}^{\infty}e^{-q_{i}i^{-\alpha}} \tag{124}\] \[=\exp\left[\sum_{i=z+\beta+1}^{\infty}-q_{i}i^{-\alpha}\right]\] (125) \[<\exp\left[\int_{z+\beta+1}^{\infty}-q_{i}x^{-\alpha}\,dx\right]\] (126) \[=\exp\left[-\left[\frac{q_{i}x^{1-\alpha}}{1-\alpha}\right]_{z+ \beta+1}^{\infty}\right]\] (127) \[=\exp\left[-\frac{q_{t}}{1-\alpha}(z+\beta+1)^{1-\alpha}\right] \tag{128}\]

Therefore,

\[\prod_{i=1}^{z+\beta}(1-q_{i}i^{-\alpha})=\frac{S_{t}}{\prod_{i=z+\beta+1}^{ \infty}}(1-q_{i}i^{-\alpha})>S_{t}/\exp\left[-\frac{q_{t}}{1-\alpha}(z+\beta+ 1)^{1-\alpha}\right]. \tag{129}\]

[MISSING_PAGE_EMPTY:21]

## Appendix E Proof of Theorem 4 (General Distributions)

We now turn to the proofs of Theorem 4(i)-(iv). (Part (v) is clear.) In each of these parts, we consider a set of recommendations with \(a_{t}\) items of type \(t\) for each \(t\in[m]\). Then observe that the expected total value of the \(k\) highest value recommended items is equal to

\[\sum_{t=1}^{m}p_{t}h_{t}(a_{t}), \tag{144}\]

for

\[h:\mathbb{Z}_{\geq 0}\to\mathbb{R},\quad h:a\mapsto\mathbb{E}\left[\operatorname{ top}_{k}\{X_{1},\cdots,X_{a}^{\text{iid}}\mathcal{D}\}\right], \tag{145}\]

where \(\operatorname{top}_{k}\) evaluates the sum of the \(k\) highest values in a set. Intuitively, conditional on a user preferring type \(t\), the top \(k\) items are just the top \(k\) items recommended of type \(t\). The sum of their values, conditioned on the user preferring type \(t\), is simply the sum of the \(k\) highest values among \(a\) random draws from \(\mathcal{D}\). Clearly, \(h\) here is monotonically increasing.

Then, with Lemma D.1 in hand, parts (i)-(iv) reduces to showing the following:

1. If \(\mathcal{D}\) is a finite discrete distribution, there exist constants \(A,B>0\) and \(\sigma>0\) such that (146) \[\lim_{a\to\infty}\frac{\log(A-h(a))}{Ba^{\sigma}}=1.\]
2. If \(\mathcal{D}\) has support bounded from above by \(M\) with pdf \(f_{\mathcal{D}}\) satisfying (147) \[\lim_{x\to M}\frac{f_{\mathcal{D}}(x)}{(M-x)^{B-1}}=c\]

for some \(\beta,c>0\), then there exist constants \(A,B>0\) such that (148) \[\lim_{a\to\infty}\frac{A-h(a)}{Ba^{-\frac{1}{\beta}}}=1.\]
3. If \(\mathcal{D}=\operatorname{Exp}(\lambda)\) for \(\lambda>0\), then \(h\) is strictly concave and there exists a constant \(B>0\) such that (149) \[\lim_{a\to\infty}\frac{h(a)}{B\log a}=1.\]
4. If \(\mathcal{D}=\operatorname{Pareto}(\alpha)\) for \(\alpha>1\), then \(h\) is strictly concave and there exists a constant \(B>0\) such that (150) \[\lim_{a\to\infty}\frac{h(a)}{Ba^{\frac{1}{\alpha}}}=1.\]

The following identity, mentioned in 27, will be useful for parts (ii)-(iv).

**Proposition 6**.: _For \(X_{i}^{(t)}\stackrel{{\text{iid}}}{{=}}\mathcal{D}\),_

\[h(a)=\sum_{i=1}^{\min\{k,a\}}\mu_{\mathcal{D}}(a-i+1,a). \tag{151}\]

Recall that \(\mu_{\mathcal{D}}(i,a)\) is the expected value of the \(i\)-th order statistic of \(a\) random variables drawn i.i.d. from \(\mathcal{D}\).

Proof.: Let \(Y_{k,n}\) be the \(k\)-th order statistic of \(n\) random variables distributed i.i.d. from \(\mathcal{D}\). Then (152) \[\operatorname{top}_{k}\{X_{1}^{(t)},\cdots,X_{a}^{(t)}\}=\sum_{i=1}^{\min\{k,a \}}Y_{a-i+1,a}.\]

SoProof:: Suppose \(\mathcal{D}\) has support \(\{x_{1},\cdots,x_{r}\}\) with \(x_{1}>\cdots>x_{r}\) such that for \(X\sim\mathcal{D},\Pr[X=x_{1}]=q\). Now consider a set of recommendations with \(a_{t}\) items of type \(t\) for each \(t\in[m]\). Then consider \(X_{1},\cdots,X_{a}\stackrel{{\text{iid}}}{{=}}\mathcal{D}\). Let \(E\) be the event that at least \(k\) of \(X_{1},\cdots,X_{a}\) equal \(x_{1}\). Then,

\[h(a) \geq\mathbb{E}[\text{top}_{k}\{X_{1},\cdots,X_{a}\}|E]\cdot\Pr[E] \tag{154}\] \[=x_{1}k\cdot\left(1-\sum_{j=0}^{k-1}\binom{a}{j}(1-q)^{a-j}q^{j}\right)\] (155) \[\geq x_{1}k(1-a^{k}(1-q)^{a-k+1}) \tag{156}\]

for all \(a>2\). Now let \(E^{\prime}\) be the event that at least one of \(X_{1},\cdots,X_{a}\) equals \(x_{1}\). Then,

\[h(a) =\mathbb{E}[\text{top}_{k}\{X_{1},\cdots,X_{a}\}|E^{\prime}]\cdot \Pr[E^{\prime}]+\mathbb{E}[\text{top}_{k}\{X_{1},\cdots,X_{a}\}|\overline{E^{ \prime}}]\cdot(1-\Pr[E^{\prime}]) \tag{157}\] \[\leq x_{1}k(1-(1-q)^{a})+x_{2}k(1-q)^{a}\] (158) \[=x_{1}k(1-(1-\frac{x_{2}}{x_{1}})(1-q)^{a}). \tag{159}\]

Now note that for \(A=x_{1}k\), we have that

\[x_{1}k(1-\frac{x_{2}}{x_{1}})(1-q)^{a} \leq A-h(a)\leq x_{1}ka^{k}(1-q)^{a-k+1} \tag{160}\] \[\log(x_{1}k(1-\frac{x_{2}}{x_{1}})(1-q)^{a}) \leq\log(A-h(a))\leq\log(x_{1}ka^{k}(1-q)^{a-k+1})\] (161) \[\log(x_{1}k)+\log(1-\frac{x_{2}}{x_{1}})+a\log(1-q)\leq\log(A-h(a ))\leq\log(x_{1}k)+k\log(a)+(a-k+1)\log(1-q). \tag{162}\]

It follows that for \(B=\log(1-q)\),

\[\lim_{a\to\infty}\frac{\log(A-h(a))}{Ba}=1, \tag{163}\]

as desired. The result follows from Lemma D.1(i).

Proof:: First recall from Proposition 6 that

\[h(a)=\sum_{i=1}^{\min\{k,a\}}\mu_{\mathcal{D}}(a-i+1,a). \tag{164}\]

We will show that

\[\lim_{a\to\infty}\frac{Mk-h(a)}{Ba^{-\frac{1}{2}}}=1 \tag{165}\]

for a constant \(B>0\). Theorem 4(ii) then follows immediately by applying Lemma D.1(ii) with \(\sigma=-\frac{1}{B}\).

Consider a probability distribution \(\mathcal{D}^{\prime}\) with pdf \(g_{X}(x)=f_{X}(M-x)\) and cdf \(G_{X}(x)\). Then

\[\mu_{\mathcal{D}}(a-i+1,a)=M-\mu_{\mathcal{D}^{\prime}}(i,a), \tag{166}\]

which implies that

\[Mk-\sum_{i=1}^{k}\mu_{\mathcal{D}}(a-i+1,a)=\sum_{i=1}^{k}\mu_{\mathcal{D}^{ \prime}}(i,a) \tag{167}\]

Since

\[\mu_{\mathcal{D}^{\prime}}(i,a)=\sum_{j=0}^{i-1}\int_{0}^{\infty}\binom{a}{j} G_{X}(x)^{j}(1-G_{X}(x))^{a-j}\,dx, \tag{168}\]

it remains to show that for all fixed \(j\),

\[\lim_{a\to\infty}\frac{\int_{0}^{\infty}\binom{a}{j}G_{X}(x)^{j}(1-G_{X}(x))^ {a-j}\,dx}{a^{-\frac{1}{B}}}=B \tag{169}\]

for some constant \(B\) (that can vary depending on \(j\)). Verifying (169) comprises the bulk of the technical work of the proof, and we isolate it in the following lemma.

**Lemma E.1**.: _For \(\beta>0\),_

\[\int_{0}^{\infty}\binom{a}{j}G_{X}(x)^{j}(1-G_{X}(x))^{a-j}\,dx\propto a^{- \frac{1}{B}}. \tag{170}\]Proof.: We have that

\[\lim_{x\to 0^{+}}\frac{g_{X}(x)}{cx^{\beta-1}}=\lim_{x\to M}\frac{f_{X}(x)}{c(M-x)^{ \beta-1}}=1 \tag{171}\]

for a positive constant \(c\). So for all \(\epsilon>0\) there exists \(\delta>0\) such that

\[(1-\epsilon)cx^{\beta-1}\leq g_{X}(x)\leq(1+\epsilon)cx^{\beta-1} \tag{172}\]

for all \(x<\delta\). Now note that \(g_{X}(x)\leq(1+\epsilon)cx^{\beta-1}\) implies that

\[G_{X}(x)=\int_{0}^{x}g_{X}(u)\,du\leq(1+\epsilon)\int_{0}^{x}cu^{\beta-1}\,du =(1+\epsilon)\frac{c}{\beta}x^{\beta}. \tag{173}\]

Likewise, \(g_{X}(x)\geq(1-\epsilon)cx^{\beta-1}\) implies that

\[G_{X}(x)=\int_{0}^{x}g_{X}(u)\,du\geq(1-\epsilon)\int_{0}^{x}cu^{\beta-1}\,du =(1-\epsilon)\frac{c}{\beta}x^{\beta}. \tag{174}\]

Now write

\[a^{\frac{1}{2}}\int_{0}^{\infty}\binom{a}{j}G_{X}(x)^{j}(1-G_{X }(x))^{\alpha-j}\,dx \tag{175}\] \[=a^{\frac{1}{2}}\int_{0}^{\delta}\binom{a}{j}G_{X}(x)^{j}(1-G_{X }(x))^{\alpha-j}\,dx+a^{\frac{1}{2}}\int_{\delta}^{\infty}\binom{a}{j}G_{X}(x) ^{j}(1-G_{X}(x))^{\alpha-j}\,dx. \tag{176}\]

We will analyze these two integral separately. It will turn out that the second integral vanishes as \(a\) grows. 

#### The first integral

We have that

\[a^{\frac{1}{2}}\int_{0}^{\delta}\binom{a}{j}G_{X}(x)^{j}(1-G_{X} (x))^{\alpha-j}\,dx \tag{177}\] \[\leq a^{\frac{1}{2}}\int_{0}^{\delta}\binom{a}{j}(1+\epsilon)^{j} \left(\frac{c}{\beta}\right)^{j}x^{\beta j}(1-(1-\epsilon)\frac{c}{\beta}\beta )^{\alpha-j}\,dx\] (178) \[=\int_{0}^{\delta a^{\frac{1}{2}}}\binom{a}{j}(1+\epsilon)^{j} \left(\frac{c}{\beta}\right)^{j}\left(\frac{x}{a^{\frac{1}{2}}}\right)^{\beta j }\left(1-(1-\epsilon)\frac{c}{\beta}\left(\frac{x}{a^{\frac{1}{2}}}\right)^{ \beta-j}\,dx\] (179) \[=\int_{0}^{\delta a^{\frac{1}{2}}}\binom{a}{j}(1+\epsilon)^{j} \left(\frac{c}{\beta}\right)^{j}\frac{x^{\beta j}}{a^{j}}\left(1-(1-\epsilon) \frac{c}{\beta}\frac{x}{a}\right)^{\alpha-j}\,dx. \tag{180}\]

Then

\[\int_{0}^{\delta a^{\frac{1}{2}}}\binom{a}{j}(1+\epsilon)^{j} \left(\frac{c}{\beta}\right)^{j}\frac{x^{\beta j}}{a^{j}}\left(1-(1-\epsilon) \frac{c}{\beta}\frac{x}{a}\right)^{\alpha-j}\,dx=\int_{0}^{\infty}\phi_{a}(x) \,dx, \tag{181}\]

where

\[\phi_{a}(x):=\begin{cases}\binom{a}{j}(1+\epsilon)^{j}\left(\frac{c}{\beta} \right)^{j}\frac{x^{\beta j}}{a^{j}}\left(1-(1-\epsilon)\frac{c}{\beta}\frac{ x}{a}\right)^{\alpha-j}\,dx&\text{for }0\leq x\leq\delta a^{\frac{1}{2}}\\ 0&\text{for }x>\delta a^{\frac{1}{2}}.\end{cases} \tag{182}\]

We have that

\[\lim_{\alpha\to\infty}\phi_{a}(x)=\frac{1}{j!}(1+\epsilon)^{j}\left(\frac{c}{ \beta}\right)^{j}x^{\beta j}e^{-(1-\epsilon)\frac{c}{\beta}x^{\beta}} \tag{183}\]

and

\[\phi_{a}(x)\leq\frac{1}{j!}(1+\epsilon)^{j}\left(\frac{c}{\beta}\right)^{j}x^ {\beta j}e^{-(1-\epsilon)\frac{c}{\beta}x^{\beta}}(1-(1-\epsilon)\frac{c}{ \beta}e^{\beta})^{-j}=C(j,\epsilon)x^{\beta j}e^{-(1-\epsilon)}\hat{x}^{\beta} \tag{184}\]

for a constant \(C(j,\epsilon)\) independent of \(a\). Now note that \(\int_{0}^{\infty}x^{\beta j}e^{-(1-\epsilon)\frac{c}{\beta}x^{\beta}}<\infty\). It follows from the dominated convergence theorem that

\[\lim_{\alpha\to\infty}\int_{0}^{\infty}\phi_{a}(x)\,dx=\int_{0}^{\infty}\lim_{ \alpha\to\infty}\phi_{a}(x)\,dx=\int_{0}^{\infty}\frac{1}{j!}(1+\epsilon)^{j} \left(\frac{c}{\beta}\right)^{j}x^{\beta j}e^{-(1-\epsilon)\frac{c}{\beta}x^{ \beta}}\,dx<\infty. \tag{185}\]

Therefore, for \(a\) sufficiently large,

\[\int_{0}^{\delta}\binom{a}{j}G_{X}(x)^{j}(1-G_{X}(x))^{\alpha-j}\,dx\leq a^{- \frac{1}{2}}(1+\epsilon)\int_{0}^{\infty}\frac{1}{j!}(1+\epsilon)^{j}\left( \frac{c}{\beta}\right)^{j}x^{\beta j}e^{-(1-\epsilon)\frac{c}{\beta}x^{\beta}} \,dx. \tag{186}\]Analogously, we can show that for \(a\) sufficiently large,

\[\int_{0}^{\delta}\binom{a}{j}c_{X}(x)^{j}(1-G_{X}(x))^{a-j}\,dx\geq a^{-\frac{1}{ j}}(1-\epsilon)\int_{0}^{\infty}\frac{1}{j!}(1-\epsilon)^{j}\left(\frac{c}{ \beta}\right)^{j}x^{\beta j}e^{-(1+\epsilon)}\bar{\bar{\bar{\bar{\beta}}}}x^{ \beta}\,dx. \tag{187}\]

Now observe that

\[\lim_{\epsilon\to 0^{+}}(1+\epsilon)\int_{0}^{\infty}\frac{1}{j!}(1+ \epsilon)^{j}\left(\frac{c}{\beta}\right)^{j}x^{\beta j}e^{-(1-\epsilon)}\frac{ \bar{\bar{\bar{\beta}}}}x^{\beta}\,dx \tag{188}\] \[=\int_{0}^{\infty}\frac{1}{j!}\left(\frac{c}{\beta}\right)^{j}x^{ \beta j}e^{-\frac{\bar{\bar{\bar{\beta}}}}{\bar{\bar{\bar{\bar{\beta}}}}}x^{ \beta}}\,dx\] (189) \[=\lim_{\epsilon\to 0^{+}}(1-\epsilon)\int_{0}^{\infty}\frac{1}{j!}(1- \epsilon)^{j}\left(\frac{c}{\beta}\right)^{j}x^{\beta j}e^{-(1+\epsilon)}\bar{ \bar{\bar{\bar{\beta}}}}x^{\beta}\,dx, \tag{190}\]

where we once again apply the dominated convergence theorem. It follows that

\[\lim_{a\to\infty}\frac{\int_{0}^{\delta}\binom{a}{j}G_{X}(x)^{j}(1-G_{X}(x))^{ a-j}\,dx}{a^{-\frac{1}{j}}}=\int_{0}^{\infty}\frac{1}{j!}\left(\frac{c}{\beta} \right)^{j}x^{\beta j}e^{-\frac{\bar{\bar{\bar{\beta}}}}{\bar{\bar{\bar{\bar{ \beta}}}}}x^{\beta}}\,dx. \tag{191}\]

#### The second integral

We now analyze

\[a^{\frac{1}{j}}\int_{\delta}^{\infty}\binom{a}{j}G_{X}(x)^{j}(1-G_{X}(x))^{a-j }\,dx. \tag{192}\]

Observe that

\[a^{\frac{1}{j}}\int_{\delta}^{\infty}\binom{a}{j}G_{X}(x)^{j}(1- G_{X}(x))^{a-j}\,dx <a^{\frac{1}{j}}\binom{a}{j}\int_{\delta}^{\infty}(1-G_{X}(x))^{a-j }\,dx \tag{193}\] \[<a^{\frac{1}{j}}\binom{a}{j}(1-G_{X}(\delta))^{a-j}\int_{\delta}^ {\infty}1-G_{X}(x)\,dx\] (194) \[<a^{\frac{1}{j}}\binom{a}{j}(1-G_{X}(\delta))^{a-j}\bar{\bar{\bar {\beta}}}[X]. \tag{195}\]

Thus,

\[\lim_{a\to\infty}\frac{\int_{\delta}^{\infty}\binom{a}{j}G_{X}(x)^{j}(1-G_{X}( x))^{a-j}\,dx}{a^{\frac{1}{j}}}=0. \tag{196}\]

Combining (191) and (196) gives us that

\[\int_{0}^{\infty}\binom{a}{j}G_{X}(x)^{j}(1-G_{X}(x))^{a-j}\,dx\propto a^{- \frac{1}{j}}, \tag{197}\]

as desired.

#### Proof of Theorem 4(iii)

Recall again that

\[h(a):=\sum_{i=1}^{\min\{ka\}}\mu_{\mathcal{D}}(a-i+1,a). \tag{198}\]

We show that \(h\) is strictly concave and

\[\lim_{a\to\infty}h(a)-B\log a-C=0 \tag{199}\]

for constants \(B,C>0\). Both of these facts follow directly from the lemma below. Theorem 4(iii) then follows immediately by applying Lemma D.1(iii).

**Lemma E.2**.: _For \(\mathcal{D}\) an exponential distribution with rate parameter \(\lambda\), so that \(f_{X}(x)=\lambda e^{-\lambda x}\) for \(\lambda>0\),_

\[\lim_{a\to\infty}\mu_{\mathcal{D}}(a-i,a)-\log a-B(j)=0 \tag{200}\]

_for a constant \(B(j)>0\). Moreover, \(\mu_{\mathcal{D}}(a-i,a)\) is strictly concave._

Proof.: For an exponential distribution with rate parameter \(\lambda\), it is well known that

\[\mu_{\mathcal{D}}(a-i,a)=\sum_{j=i+1}^{a}\frac{1}{\lambda n}. \tag{201}\]It is clear, then, that \(\mu_{\mathcal{D}}(a-i,a)\) is strictly concave. (201) is equal to

\[\frac{1}{\lambda}\left(\log n+y+\epsilon(a)-\sum_{j=1}^{i}\frac{1}{j}\right), \tag{202}\]

where \(\gamma\) is the Euler-Mascheroni constant and \(\lim_{a\rightarrow\infty}\epsilon(a)=0\), from which (200) follows. 

Proof:: Recall again that

\[h(a)\coloneqq\sum_{i=1}^{\min\{k,a\}}\mu_{\mathcal{D}}(a-i+1,a). \tag{203}\]

Then it suffices to show that \(h\) is strictly concave and

\[\lim_{a\rightarrow\infty}\frac{h(a)}{Ba^{\frac{1}{a}}}=1 \tag{204}\]

for a constant \(B>0\). Both of these facts follow directly from the lemma below. Theorem 4(iv) then follows immediately by applying Lemma D.1(iv).

**Lemma E.3**.: _For \(\mathcal{D}\) a Pareto distribution with \(pdff_{\mathcal{K}}(x)=x^{-\alpha-1}\) for \(\alpha>1\),_

\[\lim_{a\rightarrow\infty}\frac{\mu_{\mathcal{D}}(a-i,a)}{a^{\frac{1}{a}}}=C \tag{205}\]

_for a constant \(C>0\). Moreover, \(\mu_{\mathcal{D}}(a-i,a)\) is strictly concave._

Proof:: The result follows directly from Lemmas D.10 and D.11 in [29], where it is shown (in our notation) that

\[\lim_{a\rightarrow\infty}\frac{\mu_{\mathcal{D}}(a,a)}{a^{\frac{1}{a}}}= \Gamma\left(\frac{a-1}{a}\right) \tag{206}\]

and

\[\mu_{\mathcal{D}}(a-i,a)=\sum_{j=1}^{i}\left(1-\frac{1}{j\alpha}\right)\mu_{ \mathcal{D}}(a,a). \tag{207}\]

Thus,

\[\lim_{a\rightarrow\infty}\frac{\sum_{i=1}^{k}\mu_{\mathcal{D}}(a-i+1,a)}{B\log a }=1 \tag{208}\]

for a constant \(B\). Also, note that \(\mu_{\mathcal{D}}(a-i,a)\) is a constant multiple of \(\mu_{\mathcal{D}}(a,a)\), and that \(\mu_{\mathcal{D}}(a,a)\) is strictly concave, since the mean of the largest order statistic of a distribution is strictly concave in sample size. Thus, \(\mu_{\mathcal{D}}(a-i,a)\) is strictly concave.

[MISSING_PAGE_POST]