# Robust Decision Aggregation with Second-order Information

Anonymous Author(s)

Submission Id: 419

###### Abstract.

We consider a decision aggregation problem with two experts who each make a binary recommendation after observing a private signal about an unknown binary world state. An agent, who does not know the joint information structure between signals and states, sees the experts' recommendations and aims to match the action with the true state. Under the scenario, we study whether supplemented additionally with second-order information (each expert's forecast on the other's recommendation) could enable a better aggregation.

We adopt a minimax regret framework to evaluate the aggregator's performance, by comparing it to an omniscient benchmark that knows the joint information structure. With general information structures, we show that second-order information provides no benefit - no aggregator can improve over a trivial aggregator, which always follows the first expert's recommendation. However, positive results emerge when we assume experts' signals are conditionally independent given the world state. When the aggregator is deterministic, we present a robust aggregator that leverages second-order information, which can significantly outperform counterparts without it. Second, when two experts are homogeneous, by adding a non-degenerate assumption on the signals, we demonstrate that random aggregators using second-order information can surpass optimal ones without it. In the remaining settings, the second-order information is not beneficial. We also extend the above results to the setting when the aggregator's utility function is more general.

Decision Aggregation, Second-order Information, Robust Aggregation 1

## 1. Introduction

Two marketing experts at a company are providing advice on whether to launch a new product now or delay the launch to next year. The unknown binary world state is whether the market has a high demand for the product now or a low demand currently. Each expert can recommend "launch now" or "delay launch" as the optimal action. If the action matches the true demand (launch now when high demand, or delay when low demand), the utility of the company is \(+1\). If mismatched, the utility is \(-1\).

The agent takes the experts' recommendations into consideration and outputs an aggregated decision. If both experts recommend the same action, the agent can follow this consensus recommendation. When they suggest opposite actions, the aggregator may follow the expert who has superior past accuracy. However, in the one-shot setting, the aggregator would fall into a dilemma without access to performance history. Like the above motivating example, similar dilemmas universally exist in other scenarios, e.g., when a patient faces different diagnoses from two doctors, when an investor faces diverse opinions on a startup company, and when an editor faces conflicting recommendations from two referees.

Now, let us ask each expert to provide a prediction about their peer's recommendation, called the second-order setting. Back to our motivating example, for instance, the first expert recommends "launch now" and predicts her peer recommends "launch now" with a probability of 0.4, and the second expert recommends "delay launch" and predicts her peer recommends "launch now" with a probability of 0.2. Our question is - _by having each expert additionally provide a prediction about their peer's recommendation, can we better aggregate their recommendations?_

A series of works have demonstrated the benefit of the additional second-order information in the information aggregation problem. The most closed setting is considered by Prelec et al. (2018), proving that second-order information enhances aggregation given a sufficiently large group size. However, the value of second-order information remains less explored for smaller expert groups.

In particular, prior analyses considered settings where second-order information identifies the true world state, even absent prior data. However, with only two experts, the information often cannot unambiguously determine the state. In such a case, we adopt a robust aggregation paradigm to evaluate the aggregator performance against an omniscient benchmark. The paradigm is introduced by Arieli et al. (2018). The omniscient agent observes the experts' private signals and knows the true joint distribution between signals and states. This allows a perfect aggregation to output the optimal recommendation. In contrast, we focus on aggregators who only know the family of possible information structures, not the exact structure itself. The goal is to identify an aggregation rule with minimum regret compared to the omniscient benchmark. Here, regret is defined as the worst-case difference between the benchmark's expected utility and the aggregator's expected utility among all information structures.

Under the robust aggregation paradigm, we will identify the optimal aggregator that only uses the experts' first-order recommendations; and the optimal aggregator that uses both the first-orderrecommendations and second-order predictions. By comparing the regret achieved by the optimal aggregators with and without second-order predictions, we can quantify the value of the additional higher-order information for robust aggregation.

### Summary of Results

As indicated by the motivating example, our primary focus lies in the scenario where two experts are asked to provide recommendations for binary actions after observing a binary signal, with the agent aiming to align the action with a binary world state.

_General information structures._ We initially make no assumption on the underlying information structure, allowing for the possibility of a strong conditional correlation between the signals observed by the two experts. In this context, we present a negative result, demonstrating that no random aggregator can ensure a regret below 0.5, even when equipped with second-order information (Theorem 3.1). Further, this regret can be guaranteed by a trivial aggregator that consistently follows the first expert's recommendation (Theorem 3.3). Consequently, the second-order information does not provide any assistance in constructing a robust aggregator under these circumstances.

_Conditionally independent information structures._ Subsequently, we narrow our focus to conditionally independent information structures to reveal the power of second-order information. Here, conditionally independent information structures mean that two experts' signals are independent conditioning on the world state. We start with no additional assumptions, allowing for heterogeneous experts. We then consider homogeneous experts, meaning that two experts have an identical marginal signal distribution. Building on this, we further assume non-degenerate signals, i.e., experts recommend different actions after seeing distinct signals. On the aggregator side, we consider two kinds: (1) deterministic aggregators that output a fixed action, and (2) random aggregators that output a random action according to a probability distribution over actions.

Two key positive results emerge. First, for deterministic aggregators, significant improvements occur in the general conditionally independent setting. Second, for random aggregators, we demonstrate that second-order information enables lower regret guarantees under the assumptions of homogeneous experts with non-degenerate signals. The remainder of the results are negative, i.e., second-order information cannot enhance the robustness of the aggregator. All results are presented in Table 1. We now discuss these results in more detail.

_1. Heterogeneous experts._ We first consider the general scenario where two experts can be heterogeneous. In this context, with respect to deterministic aggregators, we present a positive result. We construct an aggregator that adheres to the more "informative" expert when two experts' recommendations split. For a better understanding, the more "informative" expert has better accuracy in predicting the other's recommendation1. We show that such an aggregator guarantees a regret of \(1/3\approx 0.3333\), which is the most robust deterministic aggregator with second-order information (Theorems 4.3 and 4.4). Furthermore, it is essential to note that no aggregator can guarantee a regret lower than 0.5 without second-order information. This highlights the substantial assistance offered by second-order information (Theorem 4.1).

Footnote 1: Here accuracy is measured by the distance between the prediction and recommendation. For instance, predicting 0.7 is more accurate than predicting 0.6 for actual recommended action 1.

However, considering random strategies, second-order information proves to be redundant in terms of robustness. In particular, no aggregator equipped with second-order information can ensure a regret of less than 0.25 (Theorem 4.5); while such a regret can also be achieved by a simple aggregator that uniformly chooses an action in cases of different recommendations (Theorem 4.6).

To summarize, when facing heterogeneous experts, under the robust aggregation paradigm, (1) when the aggregator is deterministic, second-order information can significantly enhance its decision-making capabilities; (2) when the aggregator can be random, second-order information is not beneficial to the regret.

_2. Homogeneous experts._ We also investigate the scenarios where two experts are homogeneous. We show that without further assumption, neither deterministic aggregators (Theorems 5.2 and 5.4) nor random aggregators (Theorems 5.5 and 5.6) can derive benefits from second-order information. This is due to a special case where both experts always recommend the same action, rendering the second-order information useless. We show that such a case is the worst one, and could lead to a tight regret lower bound of \(3-2\sqrt{2}\approx 0.1716\).

_3. Homogeneous experts with non-degenerate signals._ To avoid the above special case, we focus on the information structures where experts will recommend different actions when observing different signals. In this setting, we encounter a negative outcome considering deterministic strategies: no aggregator with second-order information can surpass the performance of the follow-the-first-expert aggregator, which guarantees a regret of \(3-2\sqrt{2}\) (Theorem 5.4 and Corollary 6.2). Notably, when facing homogeneous experts, this aggregator is equivalent to the uniform aggregator, which uniformly chooses an action when two recommendations conflict.

However, when considering random aggregators, we provide two aggregators leveraging second-order information that give better performance. The first aggregator follows a similar principle to the robust deterministic aggregator when dealing with heterogeneous experts, i.e., granting more weight to the expert with more accurate predictions. This aggregator guarantees a regret of 0.1682 (Theorem 6.10). The second aggregator, derived from the online learning algorithm proposed by Guo et al. (2019), guarantees an even lower regret of 0.1673 (Theorem 6.11). Both of these aggregators outperform the uniform aggregator with a regret of \(3-2\sqrt{2}\approx 0.1716\), which is already optimal without second-order information (Theorem 6.5). This positive result aligns with the findings in Prelec et al. (2019), which highlights that second-order information can enable the aggregator to achieve no regret when confronted with infinite experts. In our investigation, we extend this positive outcome to the case of two experts. We also establish a lower bound of \(1/6\approx 0.1667\) for aggregators with second-order information (Theorem 6.7).

_Extension: general utility functions with homogeneous experts._ In Section 7 and Appendix A, we also extend the above findings for homogeneous experts to encompass general utility functions, where the agent's objective goes beyond aligning actions with states. We first perform a reduction to allow us to focus solely on the ratio of the utility gap between adopting two actions when the state is 0 and when the state is 1. We observe that the results for random aggregators mirror those in the previous setting. Without further assumptions, the previous negative outcome still holds when both experts always advocate an identical action, resulting in high regret for all aggregators. However, when we introduce the non-degenerate signal assumption, we demonstrate that second-order information enhances aggregators' robustness with different ratios. These findings underscore the significance of second-order information for a wide range of utility functions.

### Related Work

Our work focuses on decision aggregation, a subset of the broader field of information aggregation. A significant portion of information aggregation literature focuses on forecast aggregation. This body of work explores various methodologies, including simple techniques like averaging (Garfinkel and Goyal, 2016), median averaging (Garfinkel and Goyal, 2016), and their respective modifications (Garfinkel and Goyal, 2016; Goyal, 2016; Goyal, 2016). These studies showcase the efficacy of straightforward aggregation rules, such as averaging or random dictating (Garfinkel and Goyal, 2016; Goyal, 2016; Goyal, 2016; Goyal, 2016), mirroring some of our findings. Furthermore, there exists a body of literature on decision aggregation, such as De Oliveira et al. (2016), Arieil et al. (2016), and Prelec et al. (2016), which closely align with our work.

The most closely related paper is Prelec et al. (2016), as it also examines the role of second-order information in decision aggregation. The key distinction from our setting is their focus on infinite, homogeneous experts. Leveraging second-order information, they develop an aggregator that identifies the true world state, i.e., has no regret compared to the omniscient agent. In contrast, we focus on two heterogeneous experts, representing a small expert group. We demonstrate that for such settings, regret is unavoidable even with second-order information. Further, we characterize cases where second-order information does not help reduce regret. Our regret analysis and findings on the limitations of small heterogeneous groups add new insights into decision aggregation with second-order information.

We adopt a regret-based minimax paradigm in our analysis. While De Oliveira et al. (2016) also employ a minimax approach, they use a loss-based framework and show the optimal aggregator simply follows the best expert. In contrast, we evaluate aggregator performance in comparison to an omniscient benchmark using a regret formulation. This regret-based robust paradigm follows the approach of Arieli et al. (2016), which studied forecast aggregation under Blackwell-ordered and conditionally independent structures. Additional works employing the regret-based approach include Babichenko and Garber (2016), which explores partial-evidence information structures within a repeated game context, and Guo et al. (2016), which proposes an algorithmic framework for robust forecast aggregation.

Our model focuses on the setting where the aggregator does not have access to the exact information structure. Many other works also consider settings with ambiguity but differ in the knowledge they assume the aggregator possesses. For instance, both De Oliveira et al. (2016) and Arieil et al. (2016) assume that the aggregator possesses knowledge of the marginal distribution of each expert's signal and aim to enhance the robustness of correlations based on this information. This consideration is also prevalent in (Garfinkel and Goyal, 2016; Goyal, 2016; Goyal, 2016). In contrast, our work assumes that the aggregator is ignorant about the full information structure and solely has access to the experts' outputs and the set to which the information structure belongs. This approach aligns with Arieli et al. (2016), Kong (2016), and Prelec et al. (2016). Moreover, Arieli et al. (2016) characterize the set of identifiable information structures and introduce a scheme that uniquely identifies the state of nature in finite cases.

We study whether second-order information improves the performance of the decision aggregator. A substantial body of literature also explores the benefit of second-order information. Prelec (2016) started the exploration and introduced a framework wherein agents provide both their answers and predictions for a single multi-choice question. Building upon this foundation, subsequent works have delved into the design of aggregators utilizing second-order information. Among these, the "surprisingly popular" approach, initially introduced by Prelec et al. (2016) and subsequently developed by researchers such as Palley and Soll (2016), Palley and Satopaa (2016), and Chen et al. (2016), have garnered significant attention.

Furthermore, Kong (2016) employs second-order and even higher-order information in forecast aggregation, particularly in scenarios featuring two experts who are either Blackwell-ordered or receive signals that are conditionally independent and identically distributed. Wang et al. (2016), Martinia et al. (2016), and Wilkening et al. (2016) have designed prediction-aided forecast aggregators and

\begin{table}
\begin{tabular}{l c c c c c} \hline \hline \multicolumn{1}{c}{Regret lower/upper bound\({}^{\ddagger}\)} & Deterministic & Helps? & Random & Helps? \\ \hline \multirow{2}{*}{Heterogeneous} & 1st\({}^{\dagger}\) & 0.5 & \multirow{2}{*}{Yes} & 0.25 & \multirow{2}{*}{No} & 296 \\ \cline{2-2} \cline{5-6}  & 2nd\({}^{\dagger}\) & 0.3333\({}^{\ddagger}\) & & 0.25 & 0.25 & \\ \hline \multirow{2}{*}{Homogeneous} & 1st & 0.1716\({}^{\ddagger}\) & \multirow{2}{*}{No} & 0.1716 & \multirow{2}{*}{No} & 297 \\ \cline{2-2} \cline{5-6}  & 2nd & 0.1716 & & 0.1716 & & \\ \hline \multirow{2}{*}{Homogeneous \& Non-degenerate} & 1st & 0.1716 & \multirow{2}{*}{No} & 0.1716 & \multirow{2}{*}{Yes} & 299 \\ \cline{2-2} \cline{5-6}  & 2nd & 0.1716 & & & \([0.1667,0.1673]\)\({}^{\ddagger}\) & \\ \hline \hline \end{tabular}

* \({}^{*}\)When the entry is a single value, it means the lower/upper bound coincides at the value; when the entry is an interval, the endpoints of the interval respectively represent the lower/upper bound.
* \({}^{\dagger}\) ist: only using first-order recommendations, 2nd: also using second-order predictions.
* 2\(\sqrt{2}\), 0.1667 = 1/6, 0.1673 is a numerically rounded estimate.

\end{table}
Table 1. An overview of our main results.

conducted experimental analyses to showcase their effectiveness and potential in real-world applications.

In addition to decision aggregation and forecast aggregation, the utilization of second-order information finds application in many other domains. For instance, Kong et al. (Kong et al., 2016) focus on open-response questions and ask agents what they think other people will answer. They use the information to rank the answers without any prior knowledge. Also, Hosseini et al. (Hosseini et al., 2013) and Schoenebeck and Tao (Schoenebeck and Tao, 2017) employ a similar framework to rank a predefined set of candidates. In the context of election forecasting, Rothschild and Wolters (Rothschild and Wolters, 2016) utilize voters' expectations regarding other people's votes to provide more accurate predictions of election outcomes.

## 2. Problem Statement

A company is deciding whether to launch a new product now (action 1) or delay it until next year (action 0). There are two marketing experts, expert 1 and expert 2, providing recommendations to the company's CEO (the agent). There are two possible world states about the current demand, high (state 1) and low (state 0), and we use \(\omega\in\Omega=\{0,1\}\) to denote the unknown true state. Let \(a\in A=\{0,1\}\) denote the action adopted by the CEO. If the action matches the true demand (launch now with high demand or delay with low demand), the CEO's utility is \(+1\). Otherwise, the CEO's utility is \(-1\).

Each expert \(i\in\{1,2\}\) receives a private signal \(S_{i}\in S=\{L,H\}\) about the demand, where an \(L\) signal implies a lower likelihood of the high demand state than \(\pi\) if signal. The realization of \(S_{i}\) is \(s_{i}\). An information structure \(\pi\in\Delta(\Omega\times\mathbb{S}^{2})\) is a joint distribution of the state and two private signals \(S_{1},S_{2}\), which encodes the correlation between the true state and private signals. Here, \(\Delta(\cdot)\) stands for the set of all distributions on the support. The information structure is shared by both experts. Thus, the prior of the world state \(\mu=\pi(\omega=1)\in[0,1]\) is also known to both experts. For simplicity, we rewrite the key parameters of any specific information structure in the rest of this paper. Let

\[k_{1} \coloneqq\pi(S_{1}=L\mid\omega=1),\quad l_{1} \coloneqq\pi(S_{1}=L\mid\omega=0);\] \[k_{2} \coloneqq\pi(S_{2}=L\mid\omega=1),\quad l_{2} \coloneqq\pi(S_{2}=L\mid\omega=0).\]

denote the signal probabilities and the posteriors are written as

\[b_{1L} \coloneqq\pi(\omega=1\mid S_{1}=L)\leq b_{1H} \coloneqq\pi(\omega=1\mid S_{1}=H);\] \[b_{2L} \coloneqq\pi(\omega=1\mid S_{2}=L)\leq b_{2H} \coloneqq\pi(\omega=1\mid S_{2}=H).\]

Here, \(\pi(S_{1}=L\mid\omega=1)\) stands for the probability that \(S_{1}=L\) conditioning on \(\omega=1\). Similar meanings hold for similar notations. Note that \(b_{1L}\leq b_{1H}\) and \(b_{2L}\leq b_{2H}\) hold since an \(L\) signal indicates a lower likelihood of the high demand state 1.

The experts observe their private signals and compute posteriors on the demand state. They recommend "launch now" (action 1) if the posterior on the high demand \(\geq 0.5\) and "delay launch" (action 0) otherwise. We assume that experts report truthfully. Such incentive compatibility can be guaranteed by rewarding the experts later with the revelation of the true state.

The CEO aims to aggregate the expert recommendations into an optimal product launch decision but lacks knowledge of the underlying information structure. Formally, the CEO observes the recommendations \(a_{1},a_{2}\in A=\{0,1\}\) from the two marketing experts. The CEO's aggregator outputs a final decision, which may be deterministic (denoted by \(f^{d}:A^{2}\to A\)) or randomized (denoted by \(f^{r}:A^{2}\to A(A)\)). Here \(\Delta\) means its output is a random action following a probability distribution.

_Benchmark and regret._ We compare the aggregator to an omniscient agent who knows the true information structure \(\pi\) and observes the realized signals \(s_{1},s_{2}\). The benchmark's output is

\[a^{*}(s_{1},s_{2},\pi)\coloneqq\phi(\pi(\omega=1\mid S_{1}=s_{1},S_{2}=s_{2})),\]

where \(\phi(b)\coloneqq\mathbb{1}\left\{b\geq 0.5\right\}\). \(\mathbb{1}\left\{\cdot\right\}\) is the indicator which is valued 1 when the inner condition is true and 0 otherwise.

The loss of any aggregator regarding information structure \(\pi\) is defined by the benchmark's expected utility subtracted by the aggregator's expected utility:

\[L(f,\pi)=\mathbb{E}\left[\mathbb{1}\left\{a^{*}(s_{1},s_{2},\pi)=\omega\right\} -\mathbb{1}\left\{f(a_{1}(s_{1}),a_{2}(s_{2}))=\omega\right\}\right].\]

Here, the expectation is taken on the world state \(\omega\), experts' private signal realizations \(s_{1},s_{2}\), and the randomness of the aggregator's output, if it is random.

_Second-order information._ Each expert, denoted as \(i\), is also asked to provide a prediction, \(p_{i}\in[0,1]\), for the probability that the other expert recommends action 1. This is represented as follows:

\[p_{1} \coloneqq\mathbb{E}_{\pi_{1}}[\phi(b_{2})=1\mid S_{1}=s_{1}]\] \[=\sum_{s_{2}}\pi(S_{2}=s_{2}\mid S_{1}=s_{1})\phi(\pi(\omega=1 \mid S_{2}=s_{2})),\]

and \(p_{2}\) is defined analogously. The CEO aims to find an aggregator that can effectively incorporate this additional second-order information. Such an aggregator is denoted as \(f:A^{2}\times[0,1]^{2}\to\Delta(A)\) or \(A\). We distinguish between deterministic aggregators \(f^{d}\) with deterministic outputs, and randomized aggregators \(f^{r}\) that output probability distributions over actions.

Given the information structure \(\pi\), the loss of any aggregator equipped with second-order information is defined as follows:

\[L(f,\pi)\coloneqq\mathbb{E}\left[\mathbb{1}\left\{a^{*}(s_{1},s_{2},\pi)=\omega \right\}-\mathbb{1}\left\{f(a_{1},a_{2},p_{1},p_{2})=\omega\right\}\right].\]

Here, \(a_{1},a_{2},p_{1},p_{2}\) are abbreviations for \(a_{1}(s_{1}),a_{2}(s_{2}),p_{1}(s_{1}),p_{2}(s_{1})\), respectively. Again, the expectation is taken on the state \(\omega\), experts' private signal realizations \(s_{1},s_{2}\), and the randomness of the aggregator's output, if it is random.

_Robust aggregation._ As the CEO lacks knowledge of the exact information structure, her goal is to design an aggregator that performs well across all possible information structures within the family \(P\). To model such robustness, we define the _regret_ of a deterministic aggregator \(f\) as the worst-case loss across all information structures in \(P\):

\[L_{P}(f)\coloneqq\max_{\pi\in P}L(f,\pi).\]

This work considers different sets of information structures to capture various real-world scenarios. For each of these information structure family \(P\), our objective is to identify the best aggregators \(f\), both with and without second-order information, that minimize the regret \(L_{P}(f)\). We denote the set of all deterministic aggregators without second-order information as \(F_{+1}\), and the set of deterministic aggregators with second-order information as \(F_{+2}\). Formally,we address the following optimization problems:

\[\min_{f^{d}\in F_{\pm 1}}L_{P}(f^{d}) =\min_{f^{e}\in F_{\pm 1}}\max_{\pi\in P}L(f^{d},\pi),\] \[\min_{f^{d}\in F_{\pm 2}}L_{P}(f^{d}) =\min_{f^{e}\in F_{\pm 2}}\max_{\pi\in P}L(f^{d},\pi),\] \[f^{e}\min_{\pi\in\Delta(F_{\pm 1})}L_{P}(f^{f}) =\min_{f^{e}\in\Delta(F_{\pm 1})}\max_{\pi\in P}L(f^{f},\pi),\] \[\min_{f^{e}\in\Delta(F_{\pm 2})}L_{P}(f^{f}) =\min_{f^{e}\in\Delta(F_{\pm 2})}\max_{\pi\in P}L(f^{f},\pi).\]

We further study whether the inclusion of second-order information leads to a strict decrease in regret for the agent. In other words, we examine for different family \(P\) whether the following two values \(<0\):

\[\min_{f^{d}\in F_{\pm 2}}L_{P}(f^{d}) -\min_{f^{d}\in F_{\pm 1}}L_{P}(f^{d}),\] \[f^{e}\min_{\pi\in\Delta(F_{\pm 2})}L_{P}(f^{f}) -f^{e}\min_{\pi\in\Delta(F_{\pm 1})}L_{P}(f^{f}).\]

## 3. Warm-Up: General Information Structures

As a warm-up, this section examines the information structure family \(\mathtt{ALL}\), which contains all information structures that encode the correlation between the state and two signals. Missing proofs of this section can be found in Appendix B. We start by presenting a universal lower bound.

**Theorem 3.1**.: _For every random aggregator \(f^{e}(a_{1},a_{2},p_{1},p_{2})\in\Delta(F_{\pm 2})\), \(L_{\mathtt{ALL}}(f^{e})\geq 0.5\)._

To prove the above lower bound, we adapt Yao's principle (Yao, 2017) to our setting, establishing a connection between the expected regret of any random aggregator and the best aggregator for any distribution over information structures. The lemma below will be invoked repeatedly in the subsequent sections.

**Lemma 3.2** (Yao's principle (Yao, 2017)).: _In any aggregator family \(F\) and information structure family \(P\), for any random aggregator \(f^{e}\in\Delta(F)\) and any distribution \(D\in\Delta(P)\),_

\[\min_{f^{d}\in F}\mathbb{E}_{\pi\sim D}[L(f^{d},\pi)]\leq\max_{\pi\in P}\mathbb{ E}_{f^{d}\sim f^{e}}[L(f^{d},\pi)].\]

We now present a deterministic aggregator in \(F_{\pm 1}\) that achieves for \(\mathtt{ALL}\) the lowest regret among all aggregators in \(\Delta(F_{\pm 2})\), which we refer to as the follow-the-first-expert aggregator.

_The follow-the-first-expert aggregator._ The aggregator is characterized by unconditionally adhering to the recommended action of expert 1, irrespective of expert 2's advice. This aggregator can be mathematically expressed as \(f_{fffe}(a_{1},a_{2})=a_{1}\). We have the following regret guarantee for \(f_{fffe}\).

**Theorem 3.3**.: \(L_{\mathtt{ALL}}(f_{fffe})=0.5\)_._

Since \(f_{fffe}\) is optimal among all aggregators in \(\Delta(F_{\pm 2})\) and is itself in \(F_{\pm 1}\), we conclude that the agent cannot reach a lower regret when two experts have conditional correlations even by using a random strategy or incorporating second-order information. We therefore turn our focus to conditionally independent information structures in the following sections.

## 4. Heterogeneous Experts

We now come to consider conditionally independent information structures and make no additional assumptions on experts, allowing them to be heterogeneous. Specifically, a conditionally independent information structure ensures that two experts' signals are independent given the state. The set of all conditionally independent information structures is referred to as \(\mathtt{CL}\). Missing proofs of this section can be found in Appendix C.

### Deterministic Aggregators

We first establish the following lower bound for deterministic aggregators.

**Theorem 4.1**.: _For every deterministic aggregator \(f^{d}(a_{1},a_{2})\in F_{\pm 1}\), \(L_{\mathtt{CL}}(f^{d})\geq 0.5\)._

We now revisit the follow-the-first-expert aggregator introduced in Section 3. Since \(\mathtt{CL}\subset\mathtt{ALL}\), as a corollary of Theorems 3.3 and 4.1, within \(\mathtt{CL}\), this aggregator is still the optimal among all deterministic aggregators.

**Corollary 4.2**.: \(L_{\mathtt{CL}}(f_{fffe})=0.5\)_._

We proceed to establish a lower bound for deterministic aggregators equipped with second-order information, which notably falls far below the lower bound for deterministic aggregators lacking second-order information.

**Theorem 4.3**.: _For every deterministic aggregator \(f^{d}(a_{1},a_{2},p_{1},p_{2})\in F_{\pm 2}\), \(L_{\mathtt{CL}}(f^{d})\geq 1/3\approx 0.3333\)._

To further establish the effect of second-order information in this setting, we now introduce a robust "threshold aggregator". Remarkably, within \(\mathtt{CL}\), \(f_{thr}\) attains the lowest regret among all deterministic aggregators in \(F_{\pm 2}\). This observation underscores the potential of prediction knowledge in enabling an agent without randomness to achieve a lower regret in \(\mathtt{CL}\).

_The threshold aggregator._ This aggregator follows experts' recommendations if the experts agree. When the experts disagree, it compares the sum of their predictions to \(1\). If the predictions sum to less than \(1\), it chooses action \(1\). Otherwise, it chooses action \(0\). Concretely, we have

\[f_{thr}(a_{1},a_{2},p_{1},p_{2})=\begin{cases}a_{1}&a_{1}=a_{2}\\ 1&a_{1}\neq a_{2},p_{1}+p_{2}\leq 1\\ 0&a_{1}\neq a_{2},p_{1}+p_{2}>1\end{cases}.\]

The aggregator tends to trust the expert who makes a more accurate prediction. From another perspective, it is equivalent to the "surprisingly popular" approach proposed by Prelee et al. (Prelee et al., 2019). When \(p_{1}+p_{2}\leq 1\), the answer \(1\) is more popular than predicted. Conversely, when \(p_{1}+p_{2}>1\), the answer \(0\) is the surprisingly popular one. We demonstrate that the threshold aggregator has a regret of \(1/3\).

**Theorem 4.4**.: \(L_{\mathtt{CL}}(f_{thr})=1/3\)_._

In summary, the threshold aggregator resolves the experts' disagreement based on who can predict the other more accurately.

While there still exists a gap compared with the omniscient benchmark, using second-order information already significantly improves the aggregator's performance versus relying solely on raw recommendations.

### Random Aggregators

For random aggregators, we first establish that it is impossible to ensure a regret below 0.25 even when utilizing second-order information.

**Theorem 4.5**.: _For every random aggregator \(f^{\tau}(a_{1},a_{2},p_{1},p_{2})\in\Delta(F_{\neq 2})\), \(L_{\rm CI}(f^{\tau})\geq 0.25\)._

We now introduce a random aggregator that does not require predictive information yet still guarantees tight regret. We refer to the aggregator as the uniform aggregator. It can be seen as a random version of the follow-the-first-expert aggregator.

_The uniform aggregator._ The uniform aggregator outputs the recommendations of experts when they agree; when they disagree, the aggregator uniformly selects an action. In other words, the uniform aggregator can be expressed as

\[f_{\mathit{uni}}(a_{1},a_{2})=\begin{cases}a_{1}&a_{1}=a_{2}\\ 0.5&a_{1}\neq a_{2}\end{cases}.\]

Here, when \(f_{\mathit{uni}}\) outputs 0.5, it means choosing action 1 with probability 0.5. A similar interpretation also holds for random aggregators to be introduced later.

**Theorem 4.6**.: \(L_{\rm CI}(f_{\mathit{uni}})=0.25\)_._

## 5. Homogeneous Experts

In the above results for random aggregators, an important reason why the predictions are useless is that, in the worst cases, they do not assist the agent in distinguishing the omniscient report from the ignorant one, thus the aggregator can only choose the uniform strategy at best. However, the benchmark, aided by the information structure, is always able to identify the more informed expert. As a result, there exists a substantial utility gap between the agent and the benchmark, irrespective of the agent possessing knowledge of the prediction.

In this section, we assume that the two experts are homogeneous, which means their marginal signal distribution is the same. Intuitively, the knowledge of prediction may help the agent identify the representative signal that includes the information of the real state. Formally, we take the following assumption in this section.

**Assumption 5.1** (Homogeneous experts).: _The two experts are homogeneous. In other words, \(k_{1}=k_{2}=k\), \(l_{1}=l_{2}=l\), \(b_{1L}=b_{2L}=b_{L}\) and \(b_{1H}=b_{2H}=b_{H}\)._

We then focus on the set of all conditionally independent information structures with homogeneous experts, which is referred to as HCI. All missing proofs of this section are deferred to Appendix D.

### Deterministic Aggregators

To begin, we establish a lower bound for deterministic aggregators, demonstrating that no deterministic aggregator in \(F_{\neq 2}\) can achieve a regret less than \(3-2\sqrt{2}\approx 0.1716\).

**Theorem 5.2**.: _For every deterministic aggregator \(f^{d}(a_{1},a_{2},p_{1},p_{2})\in F_{\neq 2}\), \(L_{\rm HCI}(f^{d})\geq 3-2\sqrt{2}\)._

Interestingly, the threshold aggregator, which is optimal with heterogeneous experts, achieves suboptimal performance in the homogeneous setting, still giving a regret of \(1/3\).

**Theorem 5.3**.: \(L_{\rm HCI}(f_{\mathit{thr}})=1/3\)_._

Nevertheless, the follow-the-first-expert aggregator can guarantee a lower regret. Moreover, \(f_{\mathit{rf}\neq e}\) achieves the lowest regret among all deterministic aggregators in \(F_{\neq 2}\) regarding HCI. This also indicates that knowledge of prediction cannot help the agent without randomness attain a lower regret in HCI.

**Theorem 5.4**.: \(L_{\rm HCI}(f_{\mathit{fffe}})=3-2\sqrt{2}\)_._

### Random Aggregators

For random aggregators utilizing second-order information, we first show that their regret lower bound in HCI is \(3-2\sqrt{2}\).

**Theorem 5.5**.: _For every random aggregator \(f^{\tau}(a_{1},a_{2},p_{1},p_{2})\in\Delta(F_{\neq 2})\), \(L_{\rm HCI}(f^{\tau})\geq 3-2\sqrt{2}\)._

As an intuition of the proof, we provide an information structure in which the aggregator always observes the input \((1,1,1,1)\), which means the best strategy is to adopt action 1 all the time. However, when two signals are both \(L\), the benchmark's posterior is less than 1. Therefore, no aggregator can avoid such a difference, leading to an unavoidable regret of \(3-2\sqrt{2}\).

We then show that the uniform aggregator is optimal with a tight regret of \(3-2\sqrt{2}\). We notice here that since experts are homogeneous, the uniform aggregator is equivalent to the follow-the-first-expert-aggregator.

**Theorem 5.6**.: \(L_{\rm HCI}(f_{\mathit{uni}})=3-2\sqrt{2}\)_._

Thus, surprisingly, the second-order information offers no help under the robust paradigm even if we assume experts are homogeneous. This motivates an additional natural assumption that we will introduce in the following section.

## 6. Homogeneous Experts with Non-Degenerate Signals

According to the proof of Theorem 5.5, when experts' recommended actions do not vary with their observed signals, the predictions contain no useful information and thus cannot aid the agent in achieving lower regret. In this section, alongside assuming expert homogeneity, we further assume the experts will recommend different actions when observing different signals, specifically that \(b_{L}<1/2\leq b_{H}\).

**Assumption 6.1** (Homogeneous experts with non-degenerate signals).: _Two experts are homogeneous. Also, they recommend different actions when observing different signals. In other words, \(b_{L}<1/2\leq b_{H}\)._

This section studies the set of all possible conditionally independent information structures satisfying Assumption 6.1, denoted by NHI. Missing proofs of this section can be found in Appendix E.

### Deterministic Aggregators

For deterministic aggregators, we notice that all results we establish in Section 5 still work for the information structure family \(\mathsf{NII}\), with no changes in the proof. To summarize, we have the following corollaries.

**Corollary 6.2**.: _For every deterministic aggregator \(f^{d}(a_{1},a_{2},p_{1},p_{2})\in F_{42}\), \(I_{\mathsf{NII}}(f^{d})\geq 3-2\sqrt{2}\approx 0.1716\)._

**Corollary 6.3**.: \(I_{\mathsf{NII}}(f_{thr})=1/3\)_._

**Corollary 6.4**.: \(I_{\mathsf{NII}}(f_{fffe})=3-2\sqrt{2}\)_._

### Random Aggregators

We first establish the lower bound for random aggregators in \(\Lambda(F_{\mathsf{+1}})\). As with \(\mathsf{ROI}\), no random aggregator without second-order information can guarantee a regret less than \(3-2\sqrt{2}\) for the worst case over \(\mathsf{NII}\).

**Theorem 6.5**.: _For every random aggregator \(f^{r}(a_{1},a_{2})\in\Lambda(F_{\mathsf{+1}})\), \(I_{\mathsf{NII}}(f^{r})\geq 3-2\sqrt{2}\)._

Since the uniform aggregator guarantees a regret of \(3-2\sqrt{2}\) for any information structure in \(\mathsf{ROI}\) by Theorem 5.6, it guarantees at least this regret against all structures in \(\mathsf{NII}\subset\mathsf{ROI}\). Thus, the aggregator is also optimal in this setting.

**Corollary 6.6**.: \(I_{\mathsf{NII}}(f_{uni})=3-2\sqrt{2}\)_._

We then come to consider aggregators utilizing second-order information, starting by establishing a lower bound, which is slightly smaller than that for random aggregators without second-order information.

**Theorem 6.7**.: _For every random aggregator \(f^{r}(a_{1},a_{2},p_{1},p_{2})\in\Lambda(F_{\mathsf{+2}})\), \(I_{\mathsf{NII}}(f^{r})\geq 1/6\approx 0.1667\)._

To reduce the search space, we now study the characteristics of a robust random aggregator in \(\Lambda(F_{\mathsf{+2}})\), aiming to achieve a low regret regarding information structures in \(\mathsf{NII}\). First, we present a lemma showing that when two experts split in recommendation, the expert with recommendation \(1\) always has a no less prediction value than the other expert.

**Lemma 6.8**.: _Suppose \(a_{1}=1\) and \(a_{2}=0\), then \(p_{1}\geq p_{2}\)._

Hence, it suffices for us to consider the scenario that \(p_{1}\geq p_{2}\) when \(a_{1}=1\) and \(a_{2}=0\). To add to this, we also have the following results:

**Proposition 6.9**.: _There exists a random aggregator \(f^{r}\) that achieves the lowest regret among all random aggregators in \(\Delta(F_{\mathsf{+2}})\) regarding \(\mathsf{NII}\) that satisfies the following for any \(a_{1},a_{2}\in\{0,1\}\), \(p_{1},p_{2},p\in[0,1]\):_

1. \(f^{r}(1,1,p_{1},p_{2})=1\) _and_ \(f^{r}(0,0,p_{1},p_{2})=0\)_._
2. \(f^{r}(a_{1},a_{2},p_{1},p_{2})=f^{r}(a_{2},a_{1},p_{2},p_{1})\)_._
3. \(f^{r}(a_{1},a_{2},p_{1},p_{2})+f^{r}(1-a_{1},1-a_{2},1-p_{1},1-p_{2})=1\)_._
4. _when_ \(a_{1}\neq a_{2}\)_,_ \(f^{r}(a_{1},a_{2},p_{1}-p)=0.5\)_._

The intuition behind (a) is that when the experts' recommendations agree, the agent straightforwardly takes that action. This follows directly from the information structure definition. (b) means that the agent treats the two experts equally. (c) shows the equivalence of the two states. At last, (d) indicates that when two experts' predictions deviate from each other's true recommendations by the same amount, the aggregator shows no inclination toward either action. These three properties are proved by constructing another aggregator for any optimal one with the same regret guarantee, and then linearly combining them.

We now introduce a random aggregator, referred to as the "big-lor" radial aggregator, that satisfies the criteria in Proposition 6.9. Moreover, \(f_{bir}\) attains a lower regret over \(\mathsf{NII}\) compared to random aggregators without second-order information. This shows that predictive knowledge can help agents achieve better performance.

#### The bipolar radial aggregator

This aggregator follows the recommendation when the experts agree. When recommendations differ, it treats the experts equally and chooses based on how much their predictions deviate. Specifically, it fixes a center point (\(0.6,0.4\)) on the \(p_{1}\)-\(p_{2}\) graph, outputs \(0.5\) around this center, and moves toward the extremes as the distance increases. This aggregator tends to trust the expert who predicts the other's action more accurately. Formally, when \(a_{1}=1,a_{2}=0\), the aggregator is:

\[f_{bir}(1,0,p_{1},p_{2})=\] (78) \[\begin{cases}\min\{1,(p_{1}-0.6)^{2}+(p_{2}-0.4)^{2}+0.5\},&p_{1}+p_ {2}<0.98\\ \max\{0,0.5-(p_{1}-0.6)^{2}-(p_{2}-0.4)^{2}\},&p_{1}+p_{2}>1.02\\ 0.5,&\text{otherwise}\end{cases}\] \[\text{These parameters are set via experimentation. The case that }a_{1}=0,a_{2}=1\) is symmetric. We show the contour graph of the aggregator in the case of \(a_{1}=1,a_{2}=0\) in Figure 1(a).

**Theorem 6.10**.: \(I_{\mathsf{NII}}(f_{bir})\approx 0.1682\)_._

Theorem 6.10 leaves a gap between the upper and lower bound in the context of worst-case scenarios within \(\mathsf{NII}\). Although closing this gap is challenging, we can enhance the upper bound by employing a more intricate aggregator derived from the algorithm introduced by Guo et al. (2018), which views robust aggregation as a zero-sum game between nature and the aggregator and enables online learning techniques to solve the game effectively.

#### The aggregator from the online learning algorithm

As suggested by Proposition 6.9, this aggregator follows experts' recommendation when they agree. When they disagree, the aggregator treats the two experts equally and selects an action based on their predictions. Specifically, the algorithm learns an aggregator on discretized points \((p_{1},p_{2})\) where \(p_{1}\) and \(p_{2}\) are multiples of \(0.1\), and uses linear interpolation to give the output at other points. We present a contour graph of the algorithmic aggregator when \(a_{1}=1\) and \(a_{2}=0\) in Figure 1(b).

**Theorem 6.11**.: \(I_{\mathsf{NII}}(f_{didy})\approx 0.1673\)_._

The bipolar radial aggregator in Figure 1(a) provides an intuitive and symmetrical way to weigh expert recommendations based on prediction accuracy and satisfies Proposition 6.9. The algorithmic aggregator in Figure 1(b) always favors action \(0\) in conflicts, which may seem unintuitive. However, its regret guarantee can be mirrored by an aggregator always favoring action \(1\) instead. Specifically, according to Proposition 6.9 and the linearity of theloss function, defining \(f_{alg}^{\circ}\) as the mirror that flips predictions and outputs \(f_{alg}^{\circ}(a_{1},a_{2},p_{1},p_{2})=1-f_{alg}(1-a_{2},1-a_{1},1-p_{2},1-p_{1})\) guarantees the same regret \(0.1673\). We present the contour graph of this aggregator when \(a_{1}=1\) and \(a_{2}=0\) in Figure 1(c). Therefore, to have a low regret, we can either favor action \(0\) or favor action \(1\) when the experts disagree, as long as the tendency varies with the predictions. Furthermore, we can observe a common pattern: medium values at the center and extreme values on both sides. These unexpected findings illustrate the intricacy of second-order information's role and complexity in small expert groups.

## 7. Extension: general utility functions with homogeneous experts

This section extends the setting to general utility functions. We no longer assume that the agent's goal is to match the action with the correct state. Instead, we consider a more general scenario where the agent's utility is determined by both the state and the action taken, captured by a utility function \(u:A\times\Omega\to R\).

Same as the original setting, the two experts will each recommend their preferred action \(a_{1},a_{2}\) according to the utility function and provide prediction \(p_{1},p_{2}\) about the probability of the other expert recommending action \(1\). We further assume these two experts are homogeneous (Assumption 5.1). We still explore two layers of information: one where the agent can observe both recommended actions and predictions, and the other where the agent can only observe the recommended actions.

We also assume that \(u(0,0)>u(1,0)\) and \(u(1,1)>u(0,1)\), otherwise one action is dominated by another and the problem is trivial. Let the utility gap of two actions when the state \(a\) be \(\Delta u_{0}\coloneqq u(0,0)-u(1,0)\) and the gap when the state is \(1\) be \(\Delta u_{1}\coloneqq u(1,1)-u(0,1)\). Also, we introduce their ratio as \(t\coloneqq\Delta u_{1}/\Delta u_{0}\). Apparently, \(t=1\) in our original setting.

Note that the recommended action is still a threshold function of the posterior, parameterized by \(t\), that is

\[a_{i}=\phi^{I}(b_{i}) =\mathbb{1}\left\{b_{i}\geq\frac{u(0,0)-u(1,0)}{u(0,0)-u(1,0)+u(1, 1)-u(0,1)}\right\}\] \[=\mathbb{1}\left\{b_{i}\geq\frac{1}{t+1}\right\}.\]

The action of the benchmark when observing signals \((s_{1},s_{2})\) regarding information structure \(\pi\) should be \(a^{*}\coloneqq\phi^{I}(\pi(\omega=1\mid S_{1}=s_{1},S_{2}=s_{2}))\).

We focus on random aggregators. The regret of any random aggregator \(f^{\prime}\) with second-order information regarding information structure \(\pi\) can be defined as

\[L(f^{\prime},\pi,u) \coloneqq\mathbb{E}_{\pi,f^{\prime}(\cdot)}[u(a^{*},\omega)-u(f^ {\prime}(a_{1},a_{2},p_{1},p_{2}),\omega)].\]

The regret of any random aggregator without second-order information is similar:

\[L(f^{\prime},\pi,u) \coloneqq\mathbb{E}_{\pi,f^{\prime}(\cdot)}[u(a^{*},\omega)-u(f^ {\prime}(a_{1},a_{2}),\omega)].\]

Here the randomness comes from the information structure \(\pi\) and the output of random aggregator \(f^{\prime}\).

Building upon the preceding results, we start by establishing negative outcomes for possibly degenerate signals. We then focus on non-degenerate signals as Section 6 and introduce robust aggregators with second-order information, tailored to different utility ratios, demonstrating that second-order information empowers the agent to achieve lower regret across many utility functions. Due to the space limit, we defer the details to Appendix A.

## 8. Conclusion and discussion

In this work, we study the benefit of second-order information in decision aggregation with two experts. Specifically, we investigate binary actions, binary states, and binary signals, examining the optimal deterministic and random aggregators, both with and without second-order information. Our research provides insight into the crucial question about the effectiveness of second-order information in mitigating regret, with various underlying assumptions. Furthermore, we extend our findings to encompass more general utility functions, thereby broadening our results' applicability scope. Future research directions of this work include conducting real-world experiments, exploring the scenario with more experts, and considering more complex signal settings.

## References

* (1)
* Aireli et al. (2018) Itai Aireli, Yakov Babichenko, and Ram Smorodinsky. 2018. Robust forecast aggregation. _Proceedings of the National Academy of Sciences_ 115, 52 (2018), 12135-12143.
* Aireli et al. (2020) Itai Aireli, Yakov Babichenko, and Ram Smorodinsky. 2020. Identifiable information structures. _Games and Economic Behavior_ 120 (2020), 16-27.
* Aireli et al. (2023) Itai Aireli, Yakov Babichenko, Itahol Talgam-Cohen, and Konstantin Zabarayivi. 2023. University of Illinois's Hospital's* Clement and Winkler (1986) Robert T Clemen and Robert L Winkler. 1986. Combining economic forecasts. _Journal of Business & Economic Statistics_ 4, 1 (1986), 39-46.
* Oliveira et al. (2021) Henrique De Oliveira, Yukhu Ishii, and Xiao Lin. 2021. Robust merging of information. _arXiv preprint arXiv:2106.00088_ (2021).
* DiGroot (1974) Morris DiGroot. 1974. Reaching consensus. _Journal of the American Statistical association_ 69, 345 (1974), 118-121.
* Guo et al. (2023) Yongdong Guo, Jason D. Hartling, Zhiluan Huang, Yquing Kong, Anant Shah, and Fangji T. Yu. 2023. Algorithmic Robust Forecast Aggregation. (2023).
* He and Li (2002) Wei He and Jiangfan Li. 2002. Correlation-robust auction design. _Journal of Economic Theory_ 200 (2002), 105403.
* Hossein et al. (2021) Had Hossein, Deehuayak Mandal, Nisarg Shah, and Kevin Shi. 2021. Surprisingly Popular Voting Recovers Ranking, Surprisingly! _arXiv preprint arXiv:2105.09386_ (2021).
* Iso and Winkler (2008) Victor Richmond R Jose and Robert L Winkler. 2008. Simple robust averages of forecasts: Some empirical results. _International journal of forecasting_ 24, 1 (2008), 163-169.
* Hong (2023) Yuqing Hong. 2023. Peer Expectation in Robust Forecast Aggregation: The Possibility/Impactivity. (2023).
* Kong et al. (2022) Yuqing Kong, Yunqi Li, Yubo Zhang, Zhiluan Huang, and Junhao Wu. 2022. Eliciting thinking hierarchy without a prior. _Advances in Neural Information Processing Systems_ 352 (2022), 13329-13341.
* Larrick et al. (2012) Richard P Larrick, Albert M Tamas, and Jack R Solt. 2012. The social psychology of the wisdom of crowds. In _Social judgment and decision making_. Psychology Press, 227-242.
* Levy and Razin (2022) Gailt Levy and Ronny Razin. 2022. Combining forecasts in the presence of ambiguity over correlation structures. _Journal of Economic Theory_ 199 (2022), 105075.
* Martinele et al. (2020) Marcelin Martinele, Tom Wilkening, and Piers DL Howe. 2020. Using meta-predictions to identify experts in the crowd when past performance is unknown. _Pisa_ 15, 4 (2020), e025208.
* Neyman and Roughgarden (2022) Eric Neyman and Tim Roughgarden. 2022. Are you smartet than a random expert? The robust aggregation of substitutable signals. In _Proceedings of the 23rd ACM Conference on Economics and Computation_, 990-1012.
* Palley and Astoria (2023) Asa Palley and Vila A Astoria. 2023. Boosting the wisdom of crowds within a single judgment problem: Weighted averaging based on peer predictions. _Management Science_ (2023).
* Palley and Soll (2019) Aga R Palley and Jack B Soll. 2019. Extracting the wisdom of crowds when information is shared. _Management Science_ 65, 5 (2019), 2291-2309.
* Peele et al. (2009) Drazen Peele, Leonardo A. Bayesian truth serum for subjective data. _science_ 306, 595 (2009), 462-466.
* Peele et al. (2017) Drazen Peele, H Sebastian Seung, and John McCoy. 2017. A solution to the single-question crowd wisdom problem. _Nature_ 514, 763 (2017), 532-535.
* Rangan and Geming (2010) Roopeish Rangan and Timm Geming. 2010. Combining probability forecasts. _Journal of the Royal Statistical Society Series B: Statistical Methodology_ 72, 1 (2010), 71-91.
* Rothschild and Wolfers (2011) David M Rothschild and Justin Wolfers. 2011. Forecasting elections: Voter intentions versus expectations. _Available at SSRN 18644_ (2011).
* Schoenbeck and Zuo (2021) Grant Schoenbeck and Bisonani Tou. 2021. Wisdom of the crowd voting: Truthful aggregation of voter information preferences. _Advances in Neural Information Processing Systems_ 34 (2021), 1872-1883.
* Stock and Watson (2004) James H Stock and Mark W Watson. 2004. Combination forecasts of output growth in a seven-country data set. _Journal of forecasting_ 23, 6 (2004), 405-430.
* Wang et al. (2012) Juntao Wang, Yang Liu, and Yiling Chen. 2012. Forecast aggregation via peer prediction. In _Proceedings of the AAAI Conference on Human Computation and Crowdsourcing_, Vol. 931-1142.
* Wilkenine et al. (2022) Tom Wilkenine, Marcelin Martinele, and Piers DL Howe. 2022. Hidden experts in the crowd. Using meta-predictions to leverage expertise in single-question prediction problems. _Management Science_ 6, 1 (2022), 487-505.
* Xin (1977) Andrew Chi-Chin Yao. 1977. Probabilistic computations: Toward a unified measure of complexity. In _18th Annual Symposium on Foundations of Computer Science (grs 1977)_. IEEE Computer Society, 222-227.

## Appendix A Details in Section 7 - General Utility Functions with Homogeneous Experts

We follow the framework in Section 7. Now, we consider a special utility function that satisfies \(u^{t}(0,1)=u^{t}(1,0)=0\), \(u^{t}(0,0)=1\), and \(u^{t}(1,1)=t\), and define the regret function facing this utility function:

\[L^{t}(f^{r},\pi) \coloneqq\mathbb{E}_{\pi,f^{r}(\cdot)}\big{[}u^{t}(a^{s},o)-u^{t} (f^{r}(a_{1},a_{2},p_{1},p_{2}),\omega)\big{]}. \tag{101}\] \[L^{t}(f^{r},\pi) \coloneqq\mathbb{E}_{\pi,f^{r}(\cdot)}\big{[}u^{t}(a^{s},o)-u^{t }(f^{r}(a_{1},a_{2}),\omega)\big{]}.\]

We then show that for all general utility functions with the utility gap ratio \(t\), the problem is identical to the one with utility function \(u^{t}\).

**Proposition A.1**.: _For any utility function \(u\) with the utility gap \(\Delta u_{1},\Delta u_{0}\) and ratio \(t\), \(L(f^{r},\pi,u)=\Delta u_{0}\cdot L^{t}(f^{r},\pi)\) holds for any random aggregator \(f^{r}\) and information structure \(\pi\)._

Therefore, we only consider the utility functions of this special utility family in the rest of this section. Under the utility function \(u^{t}\), the regret of random aggregator \(f^{r}\) regarding information structure family \(P\) is defined as:

\[L^{t}_{p}(f^{r})\coloneqq\max_{\pi\in P}L^{t}(f^{r},\pi).\]

As suggested, we focus on random aggregators in this part. Missing proofs of this section can be found in Appendix F.

### A Negative Result: Predictions are Useless in General

We begin by presenting the lower bound for the regret of any random aggregator equipped with second-order information. Notably, the expressions differ slightly depending on whether \(t\) is greater than \(1\) or less than \(1\).

**Theorem A.2**.: _For any \(t\geq 1\) and random aggregator \(f^{r}(a_{1},a_{2},p_{1},p_{2})\in\Delta(F_{t2})\), \(L^{t}_{\mathsf{ROI}}(f^{r})\geq(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{ 1}}{{t}}})^{2}\)._

**Theorem A.3**.: _For any \(t\leq 1\) and random aggregator \(f^{r}(a_{1},a_{2},p_{1},p_{2})\in\Delta(F_{t2})\), \(L^{t}_{\mathsf{ROI}}(f^{r})\geq(\sqrt{t+\nicefrac{{1}}{{t}}}-t)^{2}\)._

The proofs of Theorems A.2 and A.3 can be easily extended from the proof of Theorem 5.5, so we omit them here and defer them to Appendix F.2 and F.3.

_The prob-\(p\) aggregator._ The prob-\(p\) aggregator follows the recommendations of experts when they agree. In cases where they disagree, the aggregator selects action \(1\) with probability \(p\) and action \(0\) with probability \(1-p\). In mathematical terms, the prob-\(p\) aggregator can be expressed as

\[f_{P}(a_{1},a_{2})=\begin{cases}a_{1}&a_{1}=a_{2}\\ p&a_{1}\neq a_{2}\end{cases}.\]

Also, this aggregator can be seen as a generalization of the uniform aggregator (\(p=0.5\)) we introduced earlier. We have the following two positive results.

**Theorem A.4**.: _For any \(t\geq 1\), and \(p\in[0.5,(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1}}{{t}}})^{2}/(2( \sqrt{t+\nicefrac{{1}}{{t}}}-t)^{2})]\), \(L^{t}_{\mathsf{ROI}}(f_{P})=(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1} }{{t}}})^{2}\)._

**Theorem A.5**.: _For any \(t\leq 1\), and \(p\in[1-(\sqrt{t+\nicefrac{{1}}{{t}}}-t)^{2}/(2(\sqrt{1+\nicefrac{{1}}{{t}}}- \sqrt{\nicefrac{{1}}{{t}}})^{2}),0.5]\), \(L^{t}_{\mathsf{ROI}}(f_{P})=(\sqrt{t+\nicefrac{{1}}{{t}}}-t)^{2}\)._

The techniques used to analyze the aggregator's regret in Theorems A.4 and A.5 parallel those employed in the proof of Theorem 5.6. These are deferred to Appendix F.4 and F.5. We also notice from the above two theorems that the uniform aggregator (\(p=0.5\)) guarantees the lowest regret among aggregators without second-order information for any utility function.

### Non-Degenerate Signals: Predictions are Useful

Similarly, following the exploration in Section 6, we now extend our analysis to encompass non-degenerate signals. We begin by establishing a lower bound for random aggregators lacking second-order information.

**Theorem A.6**.: _For every random aggregator \(f^{r}(a_{1},a_{2})\in\Delta(F_{t1})\),_

\[L_{\mathsf{MRI}}(f^{r}) \geq\frac{2\left(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1} }{{t}}}\right)^{2}(\sqrt{t+\nicefrac{{1}}{{t}}}-t)^{2}}{(\sqrt{t+\nicefrac{{1} }{{t}}}-t)^{2}+\left(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1}}{{t}}} \right)^{2}}.\]

We proceed to demonstrate that for any utility function, there exists a specific value of \(p\) such that the prob-\(p\) aggregator attains the lowest regret among all aggregators without second-order information in \(\mathsf{NH}\).

**Theorem A.7**.: _For any \(t\),_

\[L^{t}_{\mathsf{NHI}}(f_{P}) =\frac{2\left(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1}}{ {t}}}\right)^{2}(\sqrt{t+\nicefrac{{1}}{{t}}}-t)^{2}}{(\sqrt{t+\nicefrac{{1}}{ {t}}}-t)^{2}+\left(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1}}{{t}}} \right)^{2}}\]\[p=\frac{\left(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1}}{{t}}}\right)^{2}}{ \left(\sqrt{t+\nicefrac{{1}}{{t}}}-t\right)^{2}+\left(\sqrt{1+\nicefrac{{1}}{{t}} -\sqrt{\nicefrac{{1}}{{t}}}}\right)^{2}}.\]

Regarding aggregators with second-order information, we demonstrate that they are capable of achieving a lower regret, akin to the scenario of \(t=1\). On this side, we present a series of aggregators derived from the online learning algorithm discussed in Guo et al. [11] for varying \(t\) in Figure 2. To analyze their regrets, we use the same method as we prove Theorem 6.11 and present the results in Table 2. Here, note that Lemma 6.8 and Proposition 6.9(a)(b) still work for general functions; thus we only draw the upper-left triangle cases with \(a_{1}=1\), \(a_{2}=0\), and \(p_{1}\geq p_{2}\). The case of \(f(0,1,p_{1},p_{2})\) with \(p_{2}\geq p_{1}\) is symmetric.

Our findings reveal that, across all six ratios, aggregators utilizing second-order information exhibit significant improvements over the best aggregators without this additional information. Furthermore, similar to the aggregator for ratio 1 in Figure 1(b), their output distribution still spans the range between 0 and a value below 1, and this upper bound increases as the ratio grows. Additionally, the point with the

\begin{table}
\begin{tabular}{c c c c} \hline \hline \multirow{2}{*}{Ratio} & \multicolumn{3}{c}{Regret of aggregators} \\ \cline{2-4}  & In Theorem A.7 & In Figure 2 \\ \hline
0.1 & 0.0330 & 0.0233 & 1284 \\
0.2 & 0.0591 & 0.0432 & 1285 \\
0.5 & 0.1152 & 0.0956 & 1286 \\
119 & 1 & 0.1716 & 0.1673 \\
2.00 & 2 & 0.2304 & 0.1927 \\
2.01 & 5 & 0.2954 & 0.2157 \\
10.0 & 0.3300 & 0.2293 & 1280 \\ \hline \hline \end{tabular}
\end{table}
Table 2. Comparison between the regrets of the best aggregators without second-order information and our aggregators with second-order information.

Figure 2. Contour graphs of different aggregators for general utility functions when the first expert recommends 1 and the second expert recommends 0. Colder to hotter shades represent the range of \(f(1,0,p_{1},p_{2})\) from 0 to 1. \(f(0,1,p_{1},p_{2})=f(1,0,p_{2},p_{1})\).

highest output value gradually moves from the center toward the edge that corresponds to the expert with less prediction accuracy when recommending 0.

We should also notice that when \(t\geq 1\), the regret of any aggregator facing the ratio \(t\) instance is \(t\) times the regret of its mirror (defined in Section 6) facing the ratio \(1/t\) instance. Therefore, by Proposition A.1 given any robust aggregator against ratio \(t\), we can naturally construct a robust aggregator against the ratio \(1/t\). These aggregators collectively highlight the potential of second-order information in reducing regret in worst-case scenarios within NHI.

## Appendix B Missing Proofs in Section 3

### Proof of Theorem 3.1

By Lemma 3.2, to bound the expected regret of any random aggregator in \(\Delta(F_{\pm 2})\), it suffices to analyze the expected regret of the deterministic aggregator in \(F_{\pm 2}\) relative to the same benchmark, where information structures are drawn from a carefully selected distribution. We now give a distribution \(D\in\Delta(\mathsf{ALL})\) over two information structures, regarding which any aggregator in \(F_{\pm 2}\) cannot achieve a regret below \(1/2\). These two information structures are as follows:

\[\begin{array}{c}\hline\mu_{1}=1/2&\pi_{1}(s_{1},s_{2}\mid o=1)\\ \hline(L,L)&0\\ (L,H)&1/2-\epsilon&0\\ (H,L)&1/2-\epsilon&0\\ (H,H)&2\epsilon&1/2-\epsilon\\ \hline\end{array}\]

Note that each of them has a marginal distribution

\[\mu=\frac{1}{2},\pi(s=L\mid\omega=1)=\frac{1}{2}-\epsilon,\pi(s=H\mid\omega=0) =\frac{1}{2}+\epsilon.\]

Therefore, when observing signal \(L\), the expert will recommend action 0; when observing signal \(H\), the expert will recommend action 1. In the following discussion, we consider \(\epsilon\) as a small positive number less than \(1/2\).

In the first information structure, two experts always see the same signal when the real state is 0, which means \((H,H)\) happens with probability \(1/2-\epsilon\) and \((L,L)\) happens with probability \(1/2+\epsilon\). When the real state is 1, two experts see different signals most of the time. In detail, \((H,L),(L,H)\) each happens with probability \(1/2-\epsilon\) and \((H,H)\) happens with probability \(2\epsilon\).

In the second information structure, \((H,H)\) happens with probability \(1/2+\epsilon\), and \((L,L)\) happens with probability \(1/2-\epsilon\) when the real state is 1. When the real state is 0, \((H,L),(L,H)\) each happens with probability \(1/2-\epsilon\), and \((L,L)\) happens with probability \(2\epsilon\).

Notice that inputs \((1,0,1/2+\epsilon,1/2-\epsilon)\) and \((0,1,1/2-\epsilon,1/2+\epsilon)\) each happens with probability \(1/4-\epsilon/2\) in both information structures. However, the real state behind these inputs is 1 in the first information structure but 0 in the second. Also, inputs \((1,1,1/2+\epsilon,1/2+\epsilon)\) and \((0,0,1/2-\epsilon,1/2-\epsilon)\) are with real state 0 most of the time in the first information structure and with real state 1 most of the time in the second one.

Now consider the distribution that the real information structure can be the first or the second one with equal probability. The optimal aggregator in \(F_{\pm 2}\) is independent of the specific outputs generated by \((1,0,1/2+\epsilon,1/2-\epsilon)\) and \((0,1,1/2-\epsilon,1/2+\epsilon)\). Also, the optimal aggregator outputs 1 for \((1,1,1/2+\epsilon,1/2+\epsilon)\) and outputs 0 for \((1,1,1/2+\epsilon,1/2+\epsilon)\). However, the benchmark can always identify the more possible state according to the knowledge of the real information structure. Thus, the relative regret of any aggregator in \(F_{\pm 2}\) regarding this distribution of information structures is at least

\[\frac{1}{2}\times 2\times(\frac{1}{4}-\frac{\epsilon}{2})\times(1-0)+2\times \frac{1}{2}\times(\frac{1}{4}-\frac{\epsilon}{2}-\frac{\epsilon}{2})\times(1- 0)=\frac{1}{2}-\frac{3\epsilon}{2}.\]

Since \(\epsilon\) can be arbitrarily small, the theorem holds.

### Proof of Theorem 3.3

Since the first expert's probability of recommending a bad action is \(\min\{\mu,1-\mu\}\) without additional information, and this probability decreases when the signal provides useful state information, the aggregator's regret from always following the first expert is bounded above by \(\min\{\mu,1-\mu\}\leq 1/2\). Combining this with the lower bound from Theorem 3.1 establishes that \(L_{\mathsf{ALL}}(f_{fffe})=1/2\).

## Appendix C Missing Proofs in Section 4

### Proof of Theorem 4.1

We now present two information structures in \(\mathsf{CI}\) and demonstrate that for any deterministic aggregator in \(F_{\pm 1}\), there exists an input that will inevitably result in a regret of 0.5 for one of these information structures, regardless of the output of the deterministic aggregator for that input. These two information structures are as follows:

[MISSING_PAGE_FAIL:13]

To compute the maximum regret of \(f_{thr}\), we now consider all possible seven different cases of \(\pi\). Here, notice that \(k_{1}\leq l_{1}\) and \(k_{2}\leq l_{2}\) hold due to Lemma C.1. In each of the cases, the corresponding program with strictly bounded Lipschitz continuity is solved by Wolfram Mathematica. This is the same for other positive results with similar proof.

_Case 1: \(\mu k_{1}>(1-\mu)l_{1},\mu k_{2}>(1-\mu)l_{2}\)._ In this case, we have \(a_{1}(s)=1\) for all \(i=1,2\) and \(s=L,H\), and the aggregator always chooses action \(1\). Meanwhile, we notice in this case that

\[\pi(\omega=1\mid S_{1}=L,S_{2}=H)=\frac{\mu k_{1}(1-k_{2})}{\mu k_{1}(1-k_{2}) +(1-\mu)l_{1}(1-l_{2})}\geq\frac{1}{2},\]

\[\pi(\omega=1\mid S_{1}=H,S_{2}=L)=\frac{\mu(1-k_{1})k_{2}}{\mu(1-k_{1})k_{2}+( 1-\mu)(1-l_{1})l_{2}}\geq\frac{1}{2},\]

\[\pi(\omega=1\mid S_{1}=H,S_{2}=H)=\frac{\mu(1-k_{1})(1-k_{2})}{\mu(1-k_{1})(1- k_{2})+(1-\mu)(1-l_{1})(1-l_{2})}\geq\frac{1}{2}.\]

Therefore, the only possible difference between the threshold aggregator and the benchmark is under the condition that \(S_{1}=S_{2}=L\), and the regret is bounded by the following program:

\[\max -\mu k_{1}k_{2}+(1-\mu)l_{1}l_{2},\] s.t. \[\mu k_{1}k_{2}\leq(1-\mu)l_{1}l_{2},\] \[\mu k_{1}\geq(1-\mu)l_{1},\mu k_{2}\geq(1-\mu)l_{2},\] \[0\leq k_{1}\leq l_{1}\leq 1,0\leq k_{2}\leq l_{2}\leq 1,0\leq \mu\leq 1.\]

And the optimum of the above is \(3-2\sqrt{2}\approx 0.1716\), which is reached when \(\mu=\sqrt{2}/2,k_{1}=k_{2}=\sqrt{2}-1,l_{1}=l_{2}=1\).

_Case 2: \(\mu(1-k_{1})<(1-\mu)(1-l_{1}),\mu(1-k_{2})<(1-\mu)(1-l_{2})\)._ This case is equivalent to Case 1 by substituting \(\mu\) with \(1-\mu\) and \(k_{1}\) with \(1-l_{i}\) for \(i=1,2\). Thus, they have the same optimum \(3-2\sqrt{2}\).

_Case 3: \(\mu k_{1}\leq(1-\mu)l_{1},\mu(1-k_{1})\geq(1-\mu)(1-l_{1}),\mu(1-k_{2})<(1-\mu) (1-l_{2})\)._ In this case, we have \(a_{1}(L)=0,a_{1}(H)=1\), and \(a_{2}(L)=a_{2}(H)=0\). We also observe that

\[\pi(\omega=1\mid S_{1}=L,S_{2}=L)=\frac{\mu k_{1}k_{2}}{\mu k_{1}k_{2}+(1-\mu) l_{1}l_{2}}\leq\frac{1}{2}.\]

\[\pi(\omega=1\mid S_{1}=L,S_{2}=H)=\frac{\mu k_{1}(1-k_{2})}{\mu k_{1}(1-k_{2})+ (1-\mu)l_{1}(1-l_{2})}\leq\frac{1}{2}.\]

Thus, the threshold aggregator matches the benchmark when \(S_{1}=L\). On the other hand, when \(S_{1}=H\), there is a split between two experts, with peer predictions \(p_{1}=0,p_{2}<1\). Hence, our threshold aggregator would choose action \(1\). We further have

\[\pi(\omega=1\mid S_{1}=H,S_{2}=H)=\frac{\mu(1-k_{1})(1-k_{2})}{(1-k_{1})(1-k_{ 2})+(1-\mu)(1-l_{1})(1-l_{2})}\geq\frac{1}{2},\]

As a result, the regret only comes from the circumstance that \(S_{1}=H,S_{2}=L\), and the regret is bounded by the following program:

\[\max -\mu(1-k_{1})k_{2}+(1-\mu)(1-l_{1})l_{2},\] s.t. \[\mu(1-k_{1})k_{2}\leq(1-\mu)(1-l_{1})l_{2},\] \[\mu k_{1}\leq(1-\mu)l_{1},\mu(1-k_{1})\geq(1-\mu)(1-l_{1}),\mu(1-k _{2})\leq(1-\mu)(1-l_{2}),\] \[0\leq k_{1}\leq l_{1}\leq 1,0\leq k_{2}\leq l_{2}\leq 1,0\leq \mu\leq 1.\]

The above program has a maximum value of \(3-2\sqrt{2}\) when \(\mu=1-\sqrt{2}/2,k_{1}=k_{2}=0,l_{1}=l_{2}=2-\sqrt{2}\).

_Case 4: \(\mu k_{1}\leq(1-\mu)l_{1},\mu(1-k_{1})\geq(1-\mu)(1-l_{1}),\mu k_{2}>(1-\mu)l _{2}\)._ This case is equivalent to Case 3 only by substituting \(\mu\) with \(1-\mu\), \(k_{1}\) with \(1-l_{i}\) for \(i=1,2\), and they have the same optimum \(3-2\sqrt{2}\).

_Case 5: \(\mu(1-k_{1})<(1-\mu)(1-l_{1}),\mu k_{2}\leq(1-\mu)l_{2},\mu(1-k_{2})\geq(1-\mu) (1-l_{2})\)._ This case is equivalent to Case 3 by swapping the order of two experts, and we omit it.

_Case 6: \(\mu k_{1}>(1-\mu)l_{1},\mu k_{2}\leq(1-\mu)l_{2},\mu(1-k_{2})\geq(1-\mu)(1-l_{ 2})\)._ This case is equivalent to Case 4 by swapping the order of two experts, and we omit it.

[MISSING_PAGE_FAIL:15]

1. \(k_{1}=0,l_{2}=1\). In this case, the program's upper bound becomes: \[\max \left(\mu k_{2}-(1-\mu)(1-l_{1})\right)^{+},\] s.t. \[p_{1}^{-}+p_{2}^{-}\geq 1,\] (1802) \[\mu\geq(1-\mu)(1-l_{1}),\mu k_{2}\leq 1-\mu,\] (1803) \[0\leq l_{1}\leq 1,0\leq k_{2}\leq 1,0\leq\mu\leq 1.\] (1804)

And the optimum value is \(1/3\), reached at \(\mu=2/3,k_{2}=0.5,l_{1}=1\).
2. \((1-l_{1}-l_{2})(1-\mu)+(1-k_{1}-k_{2})\mu=0\). Under this condition, we achieve that \(p_{1}^{-}+p_{2}^{-}=1\) holds as well, which is a contradiction.

Thus, we conclude for Case 7 that the maximum regret is \(1/3\).

Synthesizing all 7 cases, we achieve that \(L(f_{thr})\leq 1/3\). Combining with the lower bound in Theorem 4.3, we finish the proof of \(L(f_{thr})=1/3\).

### Proof of Theorem 4.5

We also prove by Lemma 3.2. To bound the expected regret of any random aggregator in \(\Delta(F_{\pm 2})\), it suffices to analyze the expected regret of the deterministic aggregator in \(F_{\pm 2}\) relative to the same benchmark, where information structures are drawn from a carefully selected distribution.

We then give a distribution \(D\in\Delta(\mathbb{C}\mathbb{I})\) over two conditionally independent information structures, regarding which any aggregator in \(F_{\pm 2}\) cannot achieve a regret below \(1/4\).

\[\begin{array}{ccc}\mu_{1}=0.5&\pi_{1}(s=L\mid\omega=1)&\pi_{1}(s=L\mid\omega =0)\\ \hline\text{Expert 1}&0&1\\ \text{Expert 2}&0.5-\epsilon&0.5+\epsilon\\ \end{array}\qquad\begin{array}{ccc}\mu_{2}=0.5&\pi_{2}(s=L\mid\omega=1)& \pi_{2}(s=L\mid\omega=0)\\ \hline\text{Expert 1}&0.5-\epsilon&0.5+\epsilon\\ \text{Expert 2}&0&1\\ \end{array} \tag{180}\]

The first information structure has parameters \((\mu,k_{1},k_{2},l_{1},l_{2})=(0.5,0.5-\epsilon,1,0.5+\epsilon)\) and leads to the posterior \((b_{1L},b_{2L},b_{1H},b_{2H})=(0,0.5-\epsilon,1,0.5+\epsilon)\). Again, we suppose \(\epsilon\) is a small positive number that is less than \(0.5\). In this information structure, the first expert is omniscient since it can determine the real state completely from the signal it received, while the second expert is nearly ignorant when \(\epsilon\) is close to \(0\).

The second information structure is symmetric with the first information structure, with \((\mu,k_{1},k_{2},l_{1},l_{2})=(0.5,0.5-\epsilon,0,0.5+\epsilon,1)\) and posteriors \((b_{1L},b_{2L},b_{1H},b_{2H})=(0.5-\epsilon,0,0.5+\epsilon,1)\). In this information structure, the first expert is nearly ignorant when \(\epsilon\) is close to \(0\), and the second expert is omniscient.

Now consider the distribution that the real information can be the first or the second one with equal probability, which means the more informed expert is chosen to be expert \(1\) or expert \(2\) with equal probability. Consider the case when two experts receive different signals. When \((s_{1},s_{2})=(L,H)\), the agent always observes the input \((a_{1},a_{2},p_{1},p_{2})=(0,1,0.5-\epsilon,0.5+\epsilon)\) regardless of the real information structure; and when \((s_{1},s_{2})=(H,L)\), the agent always observes \((a_{1},a_{2},p_{1},p_{2})=(1,0,0.5+\epsilon,0.5-\epsilon)\). Since the agent does not know who the omniscient expert is, The optimal aggregator in \(F_{\pm 2}\) is independent of the specific outputs generated by these inputs. However, the benchmark can always identify the omniscient expert according to the knowledge of the real information structure. Thus, the relative regret of any aggregator in \(F_{\pm 2}\) regarding this distribution of information structures is at least

\[2\times\frac{1}{2}\times\frac{1}{2}\times(\frac{1}{2}-\epsilon)\times(1-0)= \frac{1}{4}-\epsilon. \tag{181}\]

Since \(\epsilon\) can be arbitrarily small, any aggregator in \(F_{\pm 2}\) cannot guarantee a regret of less than \(0.25\) regarding this distribution of information structures, which implies the theorem.

### Proof of Theorem 4.6

Similar to the proof of Theorem 4.4, to compute the maximum loss of \(f_{\text{{min}}}\), we now consider all seven possible different cases of \(\pi\).

_Case 1: \(\mu k_{1}>(1-\mu)l_{1},\mu k_{2}>(1-\mu)l_{2}\)._ In this case, we have \(a_{i}(s)=1\) for all \(i=1,2\) and \(s=L,H\), and the uniform aggregator always chooses action \(1\). Meanwhile, we notice in this case that

\[\pi(\omega=1\mid S_{1}=L,S_{2}=H) =\frac{\mu k_{1}(1-k_{2})}{\mu k_{1}(1-k_{2})+(1-\mu)l_{1}(1-l_{2 })}\geq\frac{1}{2}, \tag{182}\] \[\pi(\omega=1\mid S_{1}=H,S_{2}=L) =\frac{\mu(1-k_{1})k_{2}}{\mu(1-k_{1})k_{2}+(1-\mu)(1-l_{1})l_{ 2}}\geq\frac{1}{2},\] (183) \[\pi(\omega=1\mid S_{1}=H,S_{2}=H) =\frac{\mu(1-k_{1})(1-k_{2})}{\mu(1-k_{1})(1-k_{2})+(1-\mu)(1-l_{ 1})(1-l_{2})}\geq\frac{1}{2}. \tag{184}\]Therefore, the only possible difference between the uniform aggregator and the benchmark is under the condition that \(S_{1}=S_{2}=L\), and the regret is bounded by the following program:

\[\max -\mu k_{1}k_{2}+(1-\mu)l_{1}l_{2},\] s.t. \[\mu k_{1}k_{2}\leq(1-\mu)l_{1}l_{2}, \tag{191}\] \[\mu k_{1}\geq(1-\mu)l_{1},\mu k_{2}\geq(1-\mu)l_{2},\] (192) \[0\leq k_{1}\leq l_{1}\leq 1,0\leq k_{2}\leq l_{2}\leq 1,0\leq\mu \leq 1.\]

And the optimum of the above is \(3-2\sqrt{2}\approx 0.1716\), which is reached when \(\mu=\sqrt{2}/2,k_{1}=k_{2}=\sqrt{2}-1,l_{1}=l_{2}=1\).

_Case \(2\): \(\mu(1-k_{1})<(1-\mu)(1-l_{1}),\mu(1-k_{2})<(1-\mu)(1-l_{2})\)._ This case is equivalent to Case 1 by substituting \(\mu\) with \(1-\mu\) and \(k_{i}\) with \(1-l_{i}\) for \(i=1,2\). Thus, they have the same optimum \(3-2\sqrt{2}\).

_Case \(3\): \(\mu k_{1}\leq(1-\mu)l_{1},\mu(1-k_{1})\geq(1-\mu)(1-l_{1}),\mu(1-k_{2})<(1-\mu )(1-l_{2})\)._ In this case, we have \(a_{1}(L)=0,a_{1}(H)=1\), and \(a_{2}(L)=a_{2}(H)=0\). We also observe that

\[\pi(\omega=1\mid S_{1}=L,S_{2}=L)=\frac{\mu k_{1}k_{2}}{\mu k_{1}k_{2}+(1-\mu) l_{1}l_{2}}\leq\frac{1}{2}, \tag{193}\] \[\pi(\omega=1\mid S_{1}=L,S_{2}=H)=\frac{\mu k_{1}(1-k_{2})}{\mu k _{1}(1-k_{2})+(1-\mu)l_{1}(1-l_{2})}\leq\frac{1}{2}. \tag{194}\]

Thus, the uniform aggregator matches the benchmark when \(S_{1}=L\). On the other hand, when \(S_{1}=H\), there is a split between two experts. Hence, our uniform aggregator would choose action \(0.5\). We further have

\[\pi(\omega=1\mid S_{1}=H,S_{2}=H)=\frac{\mu(1-k_{1})(1-k_{2})}{\mu(1-k_{1})(1 -k_{2})+(1-\mu)(1-l_{1})(1-l_{2})}\geq\frac{1}{2}. \tag{195}\]

As a result, the benchmark will adopt action \(1\) when \(S_{1}=H,S_{2}=H\). But the action of benchmark when \(S_{1}=H,S_{2}=L\) is unsure. The regret is bounded by the following program:

\[\max \frac{1}{2}|\mu(1-k_{1})k_{2}-(1-\mu)(1-l_{1})l_{2}|+\frac{1}{2} (\mu(1-k_{1})(1-k_{2})-(1-\mu)(1-l_{1})(1-l_{2})), \tag{196}\] \[\mu k_{1}\leq(1-\mu)l_{1},\mu(1-k_{1})\geq(1-\mu)(1-l_{1}),\mu(1- k_{2})\leq(1-\mu)(1-l_{2}),\] (197) \[0\leq k_{1}\leq l_{1}\leq 1,0\leq k_{2}\leq l_{2}\leq 1,0\leq\mu \leq 1.\]

The above program has a maximum value of \(0.25\) when \(\mu=0.5,k_{1}=0,k_{2}=0.5,l_{1}=1\) and \(l_{2}=0.5\).

_Case \(4\): \(\mu k_{1}\leq(1-\mu)l_{1},\mu(1-k_{1})\geq(1-\mu)(1-l_{1}),\mu k_{2}>(1-\mu)l_ {2}\)._ This case is equivalent to Case 3 by substituting \(\mu\) with \(1-\mu\) and \(k_{i}\) with \(1-l_{i}\) for \(i=1,2\), and they have the same optimum \(1/4\).

_Case \(5\): \(\mu(1-k_{1})<(1-\mu)(1-l_{1}),\mu k_{2}\leq(1-\mu)l_{2},\mu(1-k_{2})\geq(1-\mu )(1-l_{2})\)._ This case is equivalent to Case 3 by swapping the order of two experts, and we omit it.

_Case \(6\): \(\mu k_{1}>(1-\mu)l_{1},\mu k_{2}\leq(1-\mu)l_{2},\mu(1-k_{2})\geq(1-\mu)(1-l_ {2})\)._ This case is equivalent to Case 4 by swapping the order of two experts, and we omit it.

_Case \(7\): \(\mu k_{1}\leq(1-\mu)l_{1},\mu(1-k_{1})\geq(1-\mu)(1-l_{1}),\mu k_{2}\leq(1-\mu )l_{2},\mu(1-k_{2})\geq(1-\mu)(1-l_{2})\)._ We have \(a_{1}(L)=a_{2}(L)=0\) and \(a_{1}(H)=a_{2}(H)=1\). Meanwhile,

\[\pi(\omega=1\mid S_{1}=L,S_{2}=L)=\frac{\mu k_{1}

## Appendix D Missing Proofs in Section 5

### Proof of Theorem 5.2

We now give two carefully selected information structures in \(\mathsf{HOI}\) and demonstrate that no deterministic aggregator in \(F_{+2}\) can guarantee a regret less than \(3-2\sqrt{2}\) regarding both information structures.

\[\begin{array}{c c c}\hline\mu_{1}=1-\sqrt{2}/2&\pi_{1}(s=L\mid\omega=1)&\pi_{1 }(s=L\mid\omega=0)\\ \hline\text{Experts}&0&2-\sqrt{2}\\ \hline\end{array}\]

For the first information structure, we set \((\mu,k,l)=(1-\sqrt{2}/2,0,2-\sqrt{2})\), which leads to the posterior \((b_{L},b_{H})=(0,1/2)\). In this information structure, both experts demonstrate absolute certainty in determining the state when they observe the signal \(L\). However, when they observe the signal \(H\), neither expert exhibits a preference or inclination towards either state. Therefore, they will recommend action \(0\) when observing \(L\) and action \(1\) when observing \(H\).

For the second information structure, we let \((\mu,k,l)=(\sqrt{2}/2,3\sqrt{2}-4,2\sqrt{2}-2)\), leading to the posterior \((b_{L},b_{H})=(\sqrt{2}-1,\sqrt{2}-1/2)\). In this information structure, both experts hold partial knowledge about the state. Also, they will recommend action \(0\) when observing \(L\) and action \(1\) when observing \(H\).

Notice that inputs \((1,0,\sqrt{2}/2,\sqrt{2}-1)\) and \((0,1,\sqrt{2}-1,\sqrt{2}/2)\) appear under both information structures. However, in the first information structure, these inputs only occur when the real state is \(1\), and each happens with probability \(3-2\sqrt{2}\). In the second information structure, with probability \(17\sqrt{2}-24\), each input happens with the real state \(0\). Also, with probability \(27-19\sqrt{2}\), each input happens with the real state \(1\). Therefore, if the deterministic aggregator outputs \(0\) for both inputs, it will cause a regret of \(102-72\sqrt{2}\approx 0.1766\geq 3-2\sqrt{2}\approx 0.1716\) in the second information structure. If it outputs \(1\) for both inputs, it will cause a regret of \(6-4\sqrt{2}\approx 0.3431\) in the first information structure. If it outputs \(1\) for one of the inputs and \(0\) for another, it will cause a regret of \(3-2\sqrt{2}\). Therefore, no deterministic aggregator can guarantee a regret of less than \(3-2\sqrt{2}\) regarding both information structures above, which implies the theorem.

### Proof of Theorem 5.4

Since the experts are homogeneous, the follow-the-first-expert is equivalent to the uniform aggregator regarding any information structure in \(\mathsf{HOI}\). Therefore, \(\mathsf{LH_{01}}(f_{f\prime fe})=3-2\sqrt{2}\) by Theorem 5.6.

### Proof of Theorem 5.5

We here give a special information structure in \(\mathsf{HOI}\), regarding which any aggregator in \(\Delta(F_{+2})\) cannot achieve a regret below \(3-2\sqrt{2}\), which implies the lower bound.

\[\begin{array}{c c}\hline\mu_{1}=\sqrt{2}/2&\pi_{1}(s=L\mid\omega=1)&\pi_{1 }(s=L\mid\omega=0)\\ \hline\text{Experts}&\sqrt{2}-1&1\\ \hline\end{array}\]

For the information structure, we set \((\mu,k,l)=(\sqrt{2}/2,\sqrt{2}-1,1)\), which leads to the posterior \((b_{L},b_{H})=(1/2,1)\). In this information structure, two experts always recommend action \(1\) regardless of the realized signal.

Thus, the agent always observes the input \((1,1,1,1)\) and can only give the same action output regardless of the realized signal. Since the prior is larger than \(1/2\), the optimal aggregator in \(\Delta(F_{+2})\) should output \(1\) for this input. However, when \((s_{1},s_{2})=(L,L)\), the benchmark will adopt the action \(0\), which leads to the relative regret of any aggregator in \(\Delta(F_{+2})\) regarding this information structure at least

\[(1-\frac{\sqrt{2}}{2})\times(1-0)+\frac{\sqrt{2}}{2}\times(\sqrt{2}-1)^{2} \times(0-1)=3-2\sqrt{2},\]

which implies the theorem.

### Proof of Theorem 5.6

Similar to previous proofs, to compute the maximum regret of \(f_{uni}\), we now consider all possible three different cases of \(\pi\). Again, we recall that \(k_{1}\leq l_{1}\) and \(k_{2}\leq l_{2}\) hold by Lemma C.1.

[MISSING_PAGE_FAIL:19]

does not know which the more informed signal is, the optimal aggregator in \(F_{\epsilon 1}\) is independent of the specific outputs generated by these inputs. However, the benchmark can always identify the more informed signal according to the knowledge of the real information structure. Thus, the relative regret of any aggregator in \(F_{\epsilon 1}\) against this distribution of information structures is at least

\[\frac{1}{2}\times 2\times\frac{\sqrt{2}}{2}\times(\sqrt{2}-1-\epsilon)\times(2- \sqrt{2}+\epsilon)\times(1-0)=3-2\sqrt{2}-(\frac{3\sqrt{2}}{2}-2)\epsilon-\frac {\sqrt{2}}{2}\epsilon^{2}.\]

Since \(\epsilon\) can be arbitrarily small, no aggregator in \(F_{\epsilon 1}\) can guarantee a lower regret than \(3-2\sqrt{2}\) regarding this distribution of information structures. This finishes the proof.

### Proof of Theorem 6.7

Again, we use Lemma 3.2, and now give a distribution \(D\in\Delta(\text{NHI})\) over two information structures in NHI, regarding which any aggregator in \(F_{\epsilon 1}\) cannot achieve a regret below \(1/6\approx 0.1667\).

\[\begin{array}{c}\hline\mu_{1}=3/4-\epsilon&\pi_{1}(s=L\mid\omega=1)\\ \hline\text{Experts}&1/3-8\epsilon/(9-12\epsilon)\\ \hline\text{Experts}&2/3+8\epsilon/(9-12\epsilon)\\ \hline\end{array}\]

For the first information structure, we set \((\mu,k,l)=(3/4-\epsilon,1/3-8\epsilon/(9-12\epsilon),1)\), which leads to the posterior \((b_{L},b_{H})=((3-4\epsilon-8\epsilon^{2})/(3-4\epsilon))/(6+8\epsilon-8(3 \epsilon-4\epsilon^{2})/(3-4\epsilon)),1)\). \(\epsilon<1/4\). In this information structure, the experts know exactly the state when observing signal \(I\). However, when observing signal \(L\), it is hard for them to clarify the state when \(\epsilon\) is close to \(0\).

The second information structure is symmetric with the first one. We take \((\mu,k,l)=(1/4+\epsilon,0,2/3+8\epsilon/(9-12\epsilon))\) and \((b_{L},b_{H})=(0,(3+12\epsilon)/(6+8\epsilon-8(3\epsilon-4\epsilon^{2})/(3-4 \epsilon)))\). In this information structure, the experts are clear about the state when observing signal \(L\). However, when observing signal \(H\), they are uncertain about the state when \(\epsilon\) is close to \(0\).

Now consider the distribution that the real information can be the first or the second one with equal probability, i.e., the more informed signal is \(L\) or \(H\) with equal probability. Consider the case when two experts receive different signals. When \((s_{1},s_{2})=(L,H)\), the agent always observes the input \((a_{1},a_{2})=(0,1,1/3-8\epsilon/(9-12\epsilon),2/3+8\epsilon/(9-12\epsilon))\) regardless of the real information structure. Instead, when \((s_{1},s_{2})=(H,L)\), the agent always observes the input \((a_{1},a_{2})=(1,0,2/3+8\epsilon/(9-12\epsilon),1/3-8\epsilon/(9-12\epsilon))\). Similar to the proof of Theorem 6.5, since the agent does not know which the more informed signal is, the optimal aggregator in \(F_{\epsilon 2}\) is independent of the specific outputs generated by these inputs. However, the benchmark can always identify the more informed signal according to the knowledge of the real information structure. Consequently, the relative regret of any aggregator in \(F_{\epsilon 2}\) against this distribution of information structures is at least

\[\frac{1}{2}\times 2\times(\frac{3}{4}-\epsilon)\times(\frac{1}{3}-\frac{8 \epsilon}{9-12\epsilon})\times(\frac{2}{3}+\frac{8\epsilon}{9-12\epsilon}) \times(1-0)=\frac{1}{6}-\frac{2\epsilon}{9}-\frac{18\epsilon-32\epsilon^{2}} {9(3-4\epsilon)^{2}}.\]

Since \(\epsilon\) can be arbitrarily small, no aggregator in \(F_{\epsilon 2}\) can guarantee a lower regret than \(1/6\approx 0.1667\) by Lemma 3.2.

### Proof of Lemma 6.8

Notice that the prediction of the expert who recommends action \(0\) is

\[\frac{\mu k(1-k)+(1-\mu)(1-l)}{\mu k+(1-\mu)l},\]

which is referred to as \(p^{0}\). On the other hand, the prediction of the expert who recommends action \(1\) is

\[\frac{\mu(1-k)^{2}+(1-\mu)(1-l)^{2}}{\mu(1-k)+(1-\mu)(1-l)},\]

which is referred to as \(p^{1}\). Thus, \(p^{1}\geq p^{0}\) naturally holds, and the equality happens when \(k=l\).

### Proof of Proposition 6.9

For proof of (a), by Lemma C.1, \(k\leq l\) holds. For every information structure in NHI, we have \(a_{1}(H)=a_{2}(H)=1\) and \(a_{1}(L)=a_{2}(L)=0\), which implies \(\mu k<(1-\mu)l\) and \(\mu(1-k)\geq(1-\mu)(1-l)\). Therefore, \(\mu k^{2}<(1-\mu)l^{2}\) and \(\mu(1-k)^{2}\geq(1-\mu)(1-l)^{2}\) holds. When \(a_{1}=a_{2}=1\), two experts must observe signal \(H\), and the benchmark will obtain a posterior higher than \(1/2\). In this way, the best strategy for the aggregator is to adopt action \(1\). The proof is similar when \(a_{1}=a_{2}=0\).

For proof of (b), we notice that there must exist a random aggregator \(f\) that achieves the lowest regret and satisfies (a), and from there, construct another random strategy aggregator \(f^{\prime}\): \(f^{\prime}(a_{1},a_{2},p_{1},p_{2})=f(a_{2},a_{1},p_{2},p_{1})\) for any input \((a_{1},a_{2},p_{1},p_{2})\). Since two experts are homogeneous, we have

\[L(f,\pi) =\sum_{\omega_{1},\mathbf{s}_{1},\mathbf{s}_{2}}\pi(\omega,s_{1},s_{ 2})(u(\phi(\pi(\omega=1\mid s_{1},s_{2})),\omega)-f(a_{1}(s_{1}),a_{2}(s_{2}),p _{1}(s_{1}),p_{2}(s_{2}))u(1,\omega) \tag{231}\] \[\quad-(1-f(a_{1}(s_{1}),a_{2}(s_{2}),p_{1}(s_{1}),p_{2}(s_{2}))u(0, \omega))\] \[\quad=\sum_{\omega_{1},\mathbf{s}_{2}}\pi(\omega,s_{2},s_{1})(u( \phi(\pi(\omega=1\mid s_{2},s_{1})),\omega)-f(a_{1}(s_{1}),a_{2}(s_{2}),p_{1}( s_{1}),p_{2}(s_{2}))u(1,\omega)\] \[\quad-(1-f(a_{1}(s_{1}),a_{2}(s_{2}),p_{1}(s_{1}),p_{2}(s_{2}))u(0, \omega))\] \[\quad=\sum_{\omega_{1},\mathbf{s}_{2}}\pi(\omega,s_{2},s_{1})(u( \phi(\pi(\omega=1\mid s_{2},s_{1})),\omega)-f^{\prime}(a_{1}(s_{2}),a_{2}(s_{1} ),p_{1}(s_{2}),p_{2}(s_{1}))u(1,\omega)\] \[\quad-(1-f^{\prime}(a_{1}(s_{2}),a_{2}(s_{1}),p_{1}(s_{2}),p_{2}( s_{1}))u(0,\omega))\] \[\quad=L(f^{\prime},\pi).\]

Therefore, \(f\) and \(f^{\prime}\) achieve the same regret regarding any information structure, which implies \(f^{\prime}\) is also the best random aggregator. Further, notice that the loss function is linear of \(f\), thus

\[L\left(\frac{f+f^{\prime}}{2},\pi\right)=\frac{1}{2}L(f,\pi)+\frac{1}{2}L(f^{ \prime},\pi),\]

which implies \((f+f^{\prime})/2\) also achieves the lowest regret. Since \((f+f^{\prime})/2\) satisfies (b), we finish the proof of (b).

For proof of (c), now that there must exist a random aggregator \(f\) that achieves the lowest regret and satisfies (a) and (b), we construct another random strategy aggregator \(f^{\circ}\): \(f^{\circ}(a_{1},a_{2},p_{1},p_{2})=1-f(1-a_{1},1-a_{2},1-p_{1},1-p_{2})=1-f(1 -a_{2},1-a_{1},1-p_{2},1-p_{1})\) for any input \((a_{1},a_{2},p_{1},p_{2})\). Also, for any information structure \(\pi\), we can construct information structure \(\pi^{\circ}\) by substituting \(\mu,k,l\) with \(1-\mu,1-l,1-k\). We obtain

\[L(f,\pi) =\sum_{\omega_{1},\mathbf{s}_{1},\mathbf{s}_{2}}\pi(\omega,s_{1},\mathbf{s}_{2})(u(\phi(\pi(\omega=1\mid s_{1},s_{2})),\omega)-f(a_{1}(s_{1}), a_{2}(s_{2}),p_{1}(s_{1}),p_{2}(s_{2}))u(1,\omega) \tag{234}\] \[\quad-(1-f(a_{1}(s_{1}),a_{2}(s_{2}),p_{1}(s_{1}),p_{2}(s_{2}))u( 0,\omega))\] \[=\sum_{\omega_{1},\mathbf{s}_{2}}\pi^{\circ}(1-\omega,\mathbf{s} _{1},\mathbf{s}_{2})(u(\phi(\pi(\omega=1\mid s_{1},s_{2})),1-\omega)-f^{\circ}( a_{1}(s_{1}),a_{2}(s_{2}),p_{1}(s_{1}),p_{2}(s_{2}))u(1,1-\omega)\] \[\quad-(1-f^{\circ}(a_{1}(s_{1}),a_{2}(s_{2}),p_{1}(s_{1}),p_{2}( s_{2}))u(0,1-\omega))\] \[\quad=L(f^{\circ},\pi^{\circ}),\]

where \(\xi\) represents the complement signal of \(s\). Therefore, \(f\) and \(f^{\circ}\) achieve the same regret, which implies \(f^{\circ}\) also attains the lowest regret. Thus,

\[L\left(\frac{f+f^{\circ}}{2},\pi\right)=\frac{1}{2}L(f,\pi)+\frac{1}{2}L(f^{ \circ},\pi),\]

which implies \((f+f^{\circ})/2\) is also the optimal random aggregator. Since \((f+f^{\circ})/2\) satisfies (c), we finish the proof of (c).

At last, (d) holds naturally by (b) and (c).

### Proof of Theorem 6.10

To compute the maximum regret of \(f_{\text{H}\tau}\), we now consider all possible cases of \(\pi\) under the conditions. Here, besides the conditions that \(k_{1}\leq l_{1}\) and \(k_{2}\leq l_{2}\) as given by Lemma C.1, from the definition of NHI, we also know that \(\mu k<(1-\mu)l\) and \(\mu(1-k)\geq(1-\mu)(1-l)\).

Further, when \(S_{1}=S_{2}=L\), two experts both recommend action \(0\), so our aggregator adopts action \(0\), which is the same as the benchmark. When \(S_{1}=S_{2}=H\), the aggregator and the benchmark both take action \(1\). Therefore, no regret will be caused when \(S_{1}=S_{2}\).

When two experts observe different signals and recommend different actions, it is without loss of generality to assume that \(a_{1}=1,a_{2}=0\) due to the symmetry of the aggregator and information structures. Therefore, we have

\[p_{1}=\frac{\mu(1-k)^{2}+(1-\mu)(1-l)^{2}}{\mu(1-k)+(1-\mu)(1-l)},\quad p_{2}= \frac{\mu k(1-k)+(1-\mu)l(1-l)}{\mu k+(1-\mu)l}.\]

and \(p_{1}\geq p_{2}\) always holds.

_Case 1: \(p_{1}+p_{2}<0.98\)._ The aggregator outputs \(\min\{1,(p_{1}-0.6)^{2}+(p_{2}-0.4)^{2}+0.5\}\) in this case; however, the benchmark's output is unsure. Therefore, the regret is bounded by the two programs below:

\[\max ((1-\mu)|(1-l)-\mu k(1-k))\min\{1,(p_{1}-0.6)^{2}+(p_{2}-0.4)^{2}+0.5\},\] s.t. \[\mu k(1-k)\leq(1-\mu)|(1-l),\mu k\leq(1-\mu)|,\mu(1-k)\geq(1-\mu)(1 -l)\] \[0\leq k\leq l\leq 1,0\leq\mu\leq 1,\] \[p_{1}+p_{2}\leq 0.98.\] \[\max (\mu k(1-k)-(1-\mu)|(1-l))(1-\min\{1,(p_{1}-0.6)^{2}+(p_{2}-0.4)^{2 }+0.5\}),\] \[\text{s.t.} \mu k^{(}1-k)\geq(1-\mu)|(1-l),\mu k\leq(1-\mu)|,\mu(1-k)\geq(1- \mu)(1-l)\] \[0\leq k\leq l\leq 1,0\leq\mu\leq 1,\] \[p_{1}+p_{2}\leq 0.98.\]

The first program achieves the maximized value of \(0.08407\) when \(\mu=0.2424,k=0,l=0.68\). The second program achieves the maximized value of \(0.08402\) when \(\mu=0.7175,k=0.3938,l=1\). Therefore, the maximum regret in this case is \(0.0841\).

_Case 2: \(p_{1}+p_{2}>1.02\)._ The aggregator outputs \(\max\{0,0.5-(p_{1}-0.6)^{2}-(p_{2}-0.4)^{2}+0.5\}\) in this case, however the benchmark's output is unsure. Therefore, the regret is bounded by the two programs below:

\[\max ((1-\mu)|(1-l)-\mu k(1-k))\max\{0,0.5-(p_{1}-0.6)^{2}-(p_{2}-0.4)^{2}\},\] s.t. \[\mu k(1-k)\leq(1-\mu)|(1-l),\mu k\leq(1-\mu)|,\mu(1-k)\geq(1-\mu)(1 -l)\] \[0\leq k\leq l\leq 1,0\leq\mu\leq 1,\] \[p_{1}+p_{2}\geq 1.02.\]

\[\max (\mu k(1-k)-(1-\mu)|(1-l))(1-\max\{0,0.5-(p_{1}-0.6)^{2}-(p_{2}-0.4)^{2}\}),\] s.t. \[\mu k^{(}1-k)\geq(1-\mu)|(1-l),\mu k\leq(1-\mu)|,\mu(1-k)\geq(1- \mu)(1-l)\] \[0\leq k\leq l\leq 1,0\leq\mu\leq 1,\] \[p_{1}+p_{2}\geq 1.02.\]

The first program achieves the maximized value of \(0.08402\) when \(\mu=0.2825,k=0,l=0.6062\). The second program achieves the maximized value of \(0.08078\) when \(\mu=0.7575,k=0.32,l=1\). Therefore, the maximum regret in this case is \(0.08402\).

_Case 3: \(0.98\leq p_{1}+p_{2}\leq 1.02\)._ In this case, the aggregator outputs \(0.5\); however, the benchmark's output is unsure. Therefore, the regret is bounded by the two programs below:

\[\max 0.5((1-\mu)|(1-l)-\mu k(1-k)),\] s.t. \[\mu k(1-k)\leq(1-\mu)|(1-l),\mu k\leq(1-\mu)|,\mu(1-k)\geq(1-\mu)(1 -l)\] \[0\leq k\leq l\leq 1,0\leq\mu\leq 1,\] \[0.98\leq p_{1}+p_{2}\leq 1.02.\]

The first program achieves the maximized value of \(0.08409\) when \(\mu=0.2746,k=0.3467,l=1\). Therefore, the maximum regret in this case is \(0.08409\).

Synthesizing all three cases, we obtain that \(L_{\text{shift}}(J_{\text{shift}})\leq 2\times 0.0841=0.1682\). Also, when \(\mu=0.7426,k=0.3467,l=1\), the regret of the aggregator regarding this information structure is \(0.1682\), which implies the result.

### Proof of Theorem 6.11

To compute the maximum regret of \(f_{\text{al}g}\), we now consider all possible cases of \(\pi\), under the conditions as pointed out by the proof of Theorem 6.10. Further, it suffices to consider the scenario with \(a_{1}=1,a_{2}=0\).

[MISSING_PAGE_FAIL:23]

\(\epsilon\) here is a small positive number less than \(1-\sqrt{t}(\sqrt{t+1}-\sqrt{t})\). In this information structure, two experts always recommend action \(0\) regardless of the realized signal.

Therefore, the agent always observes the input \((0,0,0,0)\) and can only give the same action output regardless of the realized signal. Since the prior is smaller than \(1/(t+1)\), the optimal aggregator in \(\Delta(F_{t+2})\) should output \(0\) for this input. However, when \((s_{1},s_{2})=(H,H)\), the benchmark will adopt the action \(1\), which leads to the relative regret of any aggregator in \(\Delta(F_{t+2})\) regarding this information structure at least

\[(1-\frac{t}{\sqrt{t+1}})\times(t-0)+\frac{t}{\sqrt{t+1}}\times\left(\frac{t( \sqrt{t+1}-\sqrt{t})}{\sqrt{t}}+\epsilon\right)^{2}\times(0-1)=(\sqrt{t+t^{2} }-t)^{2}-2t\sqrt{t+1}(\sqrt{t^{2}+t}-1)\epsilon-\frac{t}{\sqrt{t+1}}\epsilon^{ 2}.\]

Since \(\epsilon\) can be arbitrarily small, no aggregator in \(\Delta(F_{t+2})\) can guarantee a lower regret than \((\sqrt{t+t^{2}}-t)^{2}\), which implies the theorem.

### Proof of Theorem a.4

To compute the maximum regret of \(f_{p}\), we now consider all possible three different cases of \(\pi\), under the conditions \(k_{1}\leq l_{1}\) and \(k_{2}\leq l_{2}\) given by Lemma C.1.

_Case 1: \(t\mu k>(1-\mu)l\)._ In this case, we have \(a_{i}(s)=1\) for all \(i=1,2\) and \(s=L,H\). The aggregator always chooses action \(1\). Also, we can obtain

\[\pi(\omega=1\mid S_{1}=L,S_{2}=H) =\frac{\mu k(1-k)}{\mu k(1-k)+(1-\mu)l(1-l)}\geq\frac{1}{t+1},\] \[\pi(\omega=1\mid S_{1}=H,S_{2}=L) =\frac{\mu(1-k)k}{\mu(1-k)k+(1-\mu)(1-yl)}\geq\frac{1}{t+1},\] \[\pi(\omega=1\mid S_{1}=H,S_{2}=H) =\frac{\mu(1-k)(1-k)}{\mu(1-k)(1-k)+(1-\mu)(1-l)(1-l)}\geq\frac{1 }{t+1}.\]

Therefore, the only possible difference between the aggregator and the benchmark is under the condition that \(S_{1}=S_{2}=L\), and the regret is bounded by the following program:

\[\max -t\mu k^{2}+(1-\mu)l^{2},\] s.t. \[t\mu k^{2}\leq(1-\mu)l^{2},t\mu k\geq(1-\mu)l\] \[0\leq k\leq l\leq 1,0\leq\mu\leq 1.\]

We can bound the maximum value of the program as follows:

\[-t\mu k^{2}+(1-\mu)l^{2} \leq l^{2}\left(1-\mu-\frac{(1-\mu)^{2}}{t\mu}\right)\] \[\leq 1-\mu-\frac{(1-\mu)^{2}}{t\mu}\] \[=1+\frac{2}{t}-(1+\frac{1}{t})\mu-\frac{1}{t\mu}\] \[\leq 1+\frac{2}{t}-2\sqrt{\frac{1}{t}(\frac{1}{t}+1)},\]

which takes equality at \(\mu=\sqrt{l/t+1},k=\frac{\sqrt{t+1}-1}{t},l=1\). Since the above value satisfies the constraints, the optimum of the above program is \((\sqrt{1+1/t}-\sqrt{l/t})^{2}\).

_Case 2: \(t\mu(1-k)<(1-\mu)(1-l)\)._ Similarly, the regret is bounded by the following program:

\[\max t\mu(1-k)^{2}-(1-\mu)(1-l)^{2},\] s.t. \[t\mu(1-k)^{2} \geq(1-\mu)(1-l)^{2},t\mu(1-k)\leq(1-\mu)(1-l)\] \[0\leq k\leq l\leq 1,0\leq\mu\leq 1.\]

We bound the maximum value of the program similarly as the above and obtain that the maximum value is \((\sqrt{t+t^{2}}-t)^{2}\) when \(\mu=1-\sqrt{l/1+t},k=0,l=1-\frac{t(\sqrt{t+1}-\sqrt{t})}{\sqrt{t}}\).

_Case 3: \(tpk\leq(1-\mu)l,t\mu(1-k)\geq(1-\mu)(1-l)\)._ We have \(a_{1}(L)=a_{2}(L)=0\) and \(a_{1}(H)=a_{2}(H)=1\). Meanwhile,

\[\pi(\omega=1\mid S_{1}=L,S_{2}=L)=\frac{\mu k^{2}}{\mu k^{2}+(1-\mu)l^{2}}\leq \frac{1}{t+1}.\]

\[\pi(\omega=1\mid S_{1}=H,S_{2}=H)=\frac{\mu(1-k)^{2}}{\mu(1-k)^{2}+(1-\mu)(1-l) ^{2}}\geq\frac{1}{t+1}.\]

Thus, the aggregator agrees with the benchmark when \(S_{1}=S_{2}\). On the other hand, when \(S_{1}\neq S_{2}\), there is a split between two experts. Hence, our prob-\(p\) aggregator will adopt action \(p\). Also, the action of the benchmark is unsure. The following two programs bound the regret:

\[\max 2\left(\mu(1-k)k-(1-\mu)(1-l)l\right)(1-f),\] s.t. \[t\mu k(1-k)\geq(1-\mu)l(1-l),\]

\[t\mu k\leq(1-\mu)l,t\mu(1-k)\geq(1-\mu)(1-l),\]

\[0\leq k\leq l\leq 1,0\leq\mu\leq 1.\]

and

\[\max 2\left(-t\mu(1-k)k+(1-\mu)(1-l)l\right)f,\] s.t. \[t\mu k(1-k)\leq(1-\mu)l(1-l),\]

\[t\mu k\leq(1-\mu)l,t\mu(1-k)\geq(1-\mu)(1-l),\]

\[0\leq k\leq l\leq 1,0\leq\mu\leq 1.\]

For the first program, we bound the maximum value as follows:

\[2(t\mu k(1-k)-(1-\mu)l(1-l))(1-p) \leq 2t\mu k(1-k)(1-p)\] \[\leq 2tk(1-k)\frac{1}{tk+1}(1-p)\] \[=2(1-p)\left(-k+(1+\frac{1}{t})-\frac{1+\frac{1}{t}}{tk+1}\right)\]

\[\leq 2(1-p)\left(\sqrt{1+\frac{1}{t}}-\sqrt{\frac{1}{t}}\right)^{2},\]

which takes equality at \(\mu=\sqrt{l/t+1},k=\frac{\sqrt{1+t}-1}{t},l=1\). Since the above value satisfies the constraints, the optimum of the above program is \(2(1-p)\left(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1}}{{t}}}\right)^{2}\).

Similarly, the maximum value of the second program is \(2p(\sqrt{t+t^{2}}-t)^{2}\) when \(\mu=1-\sqrt{\nicefrac{{1}}{{1+t}}},k=0,l=1-\frac{t(\sqrt{t+1}-\sqrt{t})}{ \sqrt{t}}\).

We also have that \(\left(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1}}{{t}}}\right)^{2}\geq( \sqrt{t+t^{2}}-t)^{2}\) for any \(t\geq 1\) and \(\left(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1}}{{t}}}\right)^{2}\leq( \sqrt{t+t^{2}}-t)^{2}\) for any \(t\leq 1\). Synthesizing all three cases, we achieve that \(L(f_{p})\leq\left(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1}}{{t}}} \right)^{2}\) for any \(p\in\left[0.5,\frac{\left(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1}}{{t }}}\right)^{2}}{2(\sqrt{t+t^{2}}-t)^{2}}\right]\). Combining with Theorem A.2, we finish the proof.

### Proof of Theorem a.5

Similar to the proof in Theorem A.4, the problem can be divided into three cases, and the solution is the same as above. Synthesizing all three cases, we achieve that \(L^{t}_{\text{HOT}}(f_{p})\leq(\sqrt{t+t^{2}}-t)^{2}\) for any \(p\in\left[1-\frac{(\sqrt{t+t^{2}}-t)^{2}}{2\left(\sqrt{1+\nicefrac{{1}}{{t}} }-\sqrt{\nicefrac{{1}}{{t}}}\right)^{2}},0.5\right]\). Combining with Theorem A.3, we finish the proof.

### Proof of Theorem a.6

By Lemma 3.2, we now give a distribution \(D\in\Delta(\mathsf{NII})\) over two information structures in \(\mathsf{NII}\), regarding which any aggregator in \(F_{+1}\) cannot achieve a regret below \(\frac{2\left(\sqrt{1+\nicefrac{{1}}{{t}}}-\sqrt{\nicefrac{{1}}{{t}}}\right)^{ 2}(\sqrt{t+t^{2}}-t)^{2}}{(\sqrt{t+t^{2}}-t)^{2}+\left(\sqrt{\nicefrac{{1}}{{t }}}-\sqrt{\nicefrac{{1}}{{t}}}\right)^{2}}\).

\[\frac{\mu_{1}=\sqrt{\nicefrac{{1}}{{t+1}}}}{\pi_{1}(s=L\mid\omega=1)}\quad\pi_ {1}(s=L\mid\omega=0)\]

\[\text{Experts}\quad(\sqrt{t+1}-1)/t-\epsilon\quad\quad 1\]

[MISSING_PAGE_EMPTY:26]

[MISSING_PAGE_EMPTY:27]