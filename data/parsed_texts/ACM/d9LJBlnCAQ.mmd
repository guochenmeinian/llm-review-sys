Passage: Ensuring Completeness and Responsiveness of Public SPARQL Endpoints with SPARQL Continuation Queries

Anonymous Author(s)

###### Abstract.

Being able to query online public knowledge graphs such as Wikidata or DBpedia is extremely valuable. However, these queries can be interrupted due to the fair use policies enforced by SPARQL endpoint providers, leading to incomplete results. While these policies help maintain the responsiveness of public SPARQL endpoints, they compromise the completeness of query results, which limits the feasibility of various downstream tasks. Ideally, we should not have to choose between completeness and responsiveness. To address this issue, we introduce and formalize the concept of _SPARQL continuation queries_. When a SPARQL endpoint interrupts a query, it returns partial results along with a SPARQL continuation query to retrieve the remaining results. If the continuation query is also interrupted, the process repeats, generating further continuation queries until the complete results are obtained. In our experimentation, we show that our continuation server passage ensures completeness and responsiveness while delivering high performance.

**ACM Reference Format:**

Anonymous Author(s). 2024. passage: Ensuring Completeness and Responsiveness of Public SPARQL Endpoints with SPARQL Continuation Queries. In. ACM, New York, NY, USA. 12 pages. [https://doi.org/10.1145/mmmmnn.nnnn](https://doi.org/10.1145/mmmmnn.nnnn)

## 1. Introduction

**Context and motivation:** Linked Open Data (LOD) principles have led to the publication of billions of RDF triples (Kang et al., 2016; Wang et al., 2016). The ability to query online public SPARQL endpoints such as Wikidata or DBpedia is extremely valuable. However, SPARQL queries are often too long or complex, which violates the fair use policy applied by public SPARQL endpoint providers (Bauer et al., 2016). While these policies are mandatory to ensure service responsiveness, they compromise the completeness of query results, wasting resources to compute incomplete queries.

To illustrate, consider the query Q1 of Figure 1 that retrieves the women leading cities in Europe. This query times out on Wikidata after 60 seconds, returning only partial results. The partial results of Q1 remain useless for answering the query. When completeness is not ensured, many downstream tasks, such as processing aggregate queries (Kang et al., 2016), creating portals (Kang et al., 2016), indexing (Kang et al., 2016), or computing summaries for federation engines (Kang et al., 2016), cannot be performed.

**Related works:** Different approaches have been proposed to ensure both completeness and responsiveness: Linked Data Fragments (LDF) (Kang et al., 2016; Wang et al., 2016) and variants (Kang et al., 2016; Wang et al., 2016), web preemption principle (Kang et al., 2016), Smart-KG (Chen et al., 2016) or WiseKG (Chen et al., 2016). All these approaches deliver different trade-offs in terms of performance but raise two important issues: the execution time of a single query can be seriously impacted compared to current SPARQL engines, and more importantly, they are not compliant with SPARQL endpoints, which is a strong limitation for adoption. The research question is how to provide a SPARQL endpoint able to deliver completeness, responsiveness, and high performance.

**Approach and contributions:** Inspired by the concept of continuations in programming languages and web (Kang et al., 2016; Wang et al., 2016), we introduce the notion of _SPARQL continuation queries_. The idea is simple: when a SPARQL endpoint server reaches its time quota, it returns partial results along with a SPARQL query designed to return missing results, i.e., a continuation query. If the user wants to obtain missing results, she sends the continuation query to the SPARQL server, which may return partial results and another continuation query. The complete results of the original query are obtained by combining the partial results from all continuation queries. To the best of our knowledge, this is the first proposal to combine responsiveness, completeness, and compliance with the SPARQL standard. The contributions of this paper are as follows:

* We introduce and formalize the concept of _continuation queries_ and define the continuation query problem.
* We propose passage as a solution to the continuation query problem. We provide a formal framework that models partial executions and continuous evaluations. We prove its correctness and termination, and we analyze its complexity.
* We developed a SPARQL query engine built on the Blazegraph storage system, capable of executing core SPARQL queries with continuations. The remaining SPARQL operators are executed through the Comunica smart client (Sen et al., 2016).
* We compare the performance of passage against state-of-the-art SPARQL engines on the Wikidata benchmark (Bauer et al., 2016). Experimental results show that passage achieves performance comparable to Blazegraph and outperforms Apache Jena while ensuring completeness and responsiveness.

This paper is organized as follows: Section 2 defines the continuation query problem. Section 3 presents passage, our approach

Figure 1. The Query \(Q_{1}\) about women leading cities in Europe times out after 60 seconds on Wikidata.

for solving the continuation query problem. Section 4 reviews the state-of-the-art SPARQL query engines that ensure both responsiveness and completeness. Section 5 presents our experimental results. Section 6 concludes and outlines future work.

## 2. The Continuation Query Problem

We assume that the reader is familiar with RDF and core SPARQL (Gan et al., 2015; Wang et al., 2016), i.e. triple patterns, basic graph patterns, joins, unions, filters, and optionals. SPARQL evaluation semantics are detailed in (Gan et al., 2015; Wang et al., 2016). In short, the evaluation of a SPARQL query \(Q\) over a graph \(G\) is defined as a function \(\llbracket Q\rrbracket_{G}\) which returns a bag of mappings.

The key idea of our approach is quite simple: when a SPARQL endpoint has to interrupt a query, instead of only returning partial results, it also returns a continuation query that can compute missing results.

**Definition 2.1** (Continuation query).: Let \(\left\|Q\right\|_{G}\) be a partial evaluation function of \(Q\) over \(G\), i.e., it returns partial results. The SPARQL continuation query \(Q_{c}\) of \(\left\|Q\right\|_{G}\) returns the missing results of \(Q\) over \(G\): \(\left\llbracket Q\right\|_{G}=\left\|Q\right\|_{G}\Leftrightarrow\left\|Q_{c} \right\|_{G}\).

**Problem 1** (Continuation queries).: _As continuation queries might be longer than allowed by time quotas, the problem is: how to compute a finite sequence of continuation queries \(Q_{c}^{1},\ldots,Q_{c}^{n}\), where \(Q_{c}^{i+1}\) is the continuation query of \(Q_{c}^{i}\), and \(Q_{c}^{i}\) the continuation query of \(Q_{c}\), such that it provides correct and complete results: \(\llbracket Q\rrbracket_{G}=\left\|Q\right\|_{G}\underset{1\leq i\leq n}{ \cup}\left\|Q_{c}^{i}\right\|_{G}\)._

## 3. passage: SPARQL Continuation Queries

passage overhauls the notion of partial evaluation to include continuation queries that allow retrieving the remaining results of a partial evaluation.

Like the traditional SPARQL evaluation (Gan et al., 2015; Wang et al., 2016), the _continous evaluation_ of a query \(Q\) over a graph \(G\) includes an additional parameter: a bag of mappings \(Q\) that represents intermediate results (also called environment (Gan et al., 2015)). Initially, \(\Omega\) is a singleton set containing the empty mapping \(\mu_{0}\) with an empty domain that is compatible with any mapping. Therefore, \(\left\langle Q\right\rangle_{G}^{\mu_{0}}\) corresponds to the evaluation of the query without restrictions \(\llbracket Q\rrbracket_{G}\).

**Definition 3.1** (Continuous evaluation \(\left\langle Q\right\rangle_{G}^{0}\)).: The _continuous_ evaluation of a query \(Q\) over a graph \(G\) with a bag of mappings \(\Omega\) as an environment, denoted \(\left\langle Q\right\rangle_{G}^{0}\), returns \(\left\langle\Omega_{p},Q_{c}\right\rangle\). \(\Omega_{p}\) is a partial query result, i.e., a bag of solution mappings compatible with \(\Omega\) (\(\Omega_{p}\subset\Omega\twoheadrightarrow\llbracket Q\rrbracket_{G}\)) and \(Q_{c}\) is \(Q\)'s continuation query, such that \(\Omega\twoheadrightarrow\llbracket Q\rrbracket_{G}=\Omega_{p}\Leftrightarrow \llbracket Q_{c}\rrbracket_{G}\).

### Requirement

The rewriting rules that create continuation queries of passage rely on the assumption that the evaluation of a triple pattern is deterministic and returns a list of mappings: \(\llbracket tp\rrbracket_{G}^{\mu}=\left[\mu_{1},\ldots\mu_{out}\left[\mu_{q} \right]_{G}\rightleftarrow\mu)\). While this constraint on triple pattern evaluations is stronger than SPARQL's (Brand et al., 2015), many SPARQL engines such as Blazegraph or Apache Jena rely on data structures such as B-Trees that already return such a list of elements deterministically.

With this assumption, the evaluation of a _Slice_ of triple pattern also becomes deterministic and returns a list of mappings. Then, a solution to the _continuation queries problem_ for triple patterns consists of evaluating disjoint slices of the triple pattern and concatenate their lists of solution mappings as: \(\llbracket tp\rrbracket_{G}^{0}=\left[\mathit{Slice}(\mathit{tp},0,\mathit{i}) \right]_{G}^{L}\cdot\llbracket Slice(\mathit{tp},i,\mathit{card}(\llbracket tp \rrbracket_{G}\bowtie\mu)-\mathit{i})\rrbracket_{G}^{H}\) where \(0\leq i<\mathit{card}(\llbracket tp\rrbracket_{G}\bowtie\mu)\).

### Core SPARQL Evaluation

Core SPARQL includes triple patterns, joins, unions, optionals, and filters (Wang et al., 2016). However, the specification of the evaluation for SPARQL continuation queries starts with the empty case, allowing simplification of logical plans:

**Definition 3.2** (Empty continuation \(\llbracket P\rrbracket_{G}^{0}\) and \(\{\}\{\}_{G}^{\Omega}\)).: Let \(P\) be a graph pattern, and \(\Omega\) be a bag of mappings, the evaluation of:

* an empty environment is \(\left\langle P\right\rangle_{G}^{0}=(\emptyset,\{\})\);
* an empty graph pattern is \(\{\}\!\!\left\{\!\left\{\!\left\{\!\left\{\!\right\}\right\}\right\}\!\!\right\} \!\!\right\rangle_{G}^{2}=(\Omega,\{\})\).

The smallest unit of core SPARQL is the triple pattern, whose evaluation produces mappings. The continuation query requires the offset \(\mathit{Slice}(P,\mathit{offset},\mathit{limit})\), which we simplify to \(\mathit{Slice}(P,\mathit{offset})\) when the _limit_ equals the remaining the number of results.

**Definition 3.3** (Triple pattern evaluation \(\{tp\rrbracket_{G}^{\Omega}\)).: Let a triple pattern evaluation \(\llbracket tp\rrbracket_{G}^{\Omega}=\left[\mu_{1},\ldots\mu_{k}\right]\) where \(k=\mathit{card}(\llbracket tp\rrbracket_{G}\bowtie\mu)\) and \(\mathsf{i}\), \(0\leq i\leq k\), a point when the _continuous_ evaluation of \(\mathit{tp}\) with environment \(\mu\) can be stopped. The _continuous_ evaluation of a triple pattern \(\mathit{tp}\) with an environment \(\mu\) is defined as:

\[\langle tp\rrbracket_{G}^{\mu}=(\{\!\!\left\{\!\left\{\!\left\{\!\mu_{1}, \ldots\mu_{i}\right\}\!\!\right\}\!\!\right\}\!\!\!\mathit{slice}(\mathit{extend}( \mu,\mathit{tp}),i)\!\!_Example 3.6_.: To illustrate, let us consider the Graph \(G_{ex}\) of Figure 2 that contains 6 triples, 3 triples of which are about humans: wd:H1, wd:H2, and wd:H3. An end-user wants to enumerate all human beings in the graph with the SPARQL query:

```
SELECT*WHERE{'humanwd:P31wd:Q5}#getallhumanbeings
```

The _continuous_ evaluation of this query \(\{\{p\}_{G}^{n}\}\) where \(tp=(\textit{Thuman}\)wdt:P31wd:Q5)may be interrupted at any point between 1 and \(card(tp)=3\). For example, being interrupted after the first mapping we obtain:

\[\{\{p\}_{G}^{n} =(\{\{\{\{\{\{\textit{Thuman}\to wd:H1\}\}\},\textit{Slicet}(\textit{Extend}(\mu_{0},tp),1)\}\}\] \[=(\{\{\{\{\{\textit{Thuman}\to wd:H1\}\}\},\textit{Slicet}(\textit{tp},1)\}\}\]

The end-user receives a first partial result (?_human_\(\to\)wd:H1), along with the continuation query that corresponds to the following SPARQL query:

```
SELECT*WHERE{'humanwdt:P31wd:Q5}orensert1#skipfirstresult
```

To retrieve missing results, the end-user sends back this regular SPARQL query. It is designed to skip the first produced result thanks to the offset clause. Again, the continuous evaluation stops after having computed one mapping, resulting in:

\[\{\textit{Slice}(\textit{tp},1)\}_{G}^{n} =(\{\{\{\{\textit{Thuman}\to wd:H2\}\}\},\textit{Slice}(\textit{tp},2)\}\]

The end-user receives a second partial result \(\{\textit{Thuman}\to\)wd:H2\}\) with a SPARQL continuation query corresponding to:

```
SELECT*WHERE{'humanwdt:P31wd:Q5}orensert2#skiptopresults
```

The end-user sends back this SPARQL query designed to skip the two first results. When the continuous evaluation stops again after having produced one mapping, the result is:

\[\{\textit{Slice}(\textit{tp},1)\}_{G}^{n} =(\{\{\{\{\{\textit{Thuman}\to wd:H3\}\}\},\textit{Slice}(\textit{tp},3)\}\] \[=(\{\{\{\{\{\{\{\{\textit{Thuman}\to wd:H3\}\}\}\},\{\}\{\}\}\}\}\}\),\{\{\}\}\]

The continuation query becomes the empty graph pattern, since the offset reached the cardinality of the triple pattern. When the end-user receives the third result, she acknowledges that she got correct and complete results since the last continuation query is empty.

The solution of the continuation queries problem has not been computed beforehand, but it is obtained from the partial executions completed within the allowed time quota. For this example, the sequence of continuation queries is _Slice(tp,1)_, _Slice(tp,2)_, {.} The partial evaluation of these queries provides the two solutions that complete the partial evaluation of _tp_.

Core SPARQL includes conjunctive queries with the join operator between two graph patterns. Since the results of one side depends on the results of the other side, we devise a general rule for environments with multiple mappings as the union of the evaluations over every mapping:

\[(\mathbb{P})_{G}^{\Omega}=(\Omega_{h}\uplus\Omega_{t},\textit{Union}(Q_{h},Q_{t} ))\ \textsc{where}\begin{cases}\Omega\doteq\mu\uplus\Omega_{o}\\ \{\{p\}_{G}^{n}\}=(\Omega_{t},Q_{t})\\ \end{cases}\]

The evaluation of a join operator can be stopped at any point during the evaluation of its operands. For clarity, let us assume that the left operand is evaluated first, with the resulting mappings passed as the environment to the right operand. Both operands could be stopped. In this case, the continuation query of a join operator includes the remaining evaluation of its left operand (which still needs to be operated with the right operand ) and the remaining evaluation of the right operand with the new environment.

_Definition 3.7_ (_Join evaluation_\(\{\textit{Join}(P_{t},P_{r})\}_{G}^{n}\)).: The _continuous_ evaluation of a join between two graph patterns \(P_{t}\) and \(P_{r}\) with environment \(\mu\) is:

\[\{\textit{Join}(P_{t},P_{r})\}_{G}^{n}=(\Omega_{lr},Q_{c})\ \textsc{where} \begin{cases}\{\{p\}_{G}^{n}\}=(\Omega_{l},Q_{l})\\ \{\{p\}_{G}^{n}\}=(\Omega_{lr},Q_{lr})\\ \end{cases}\]

The SPARQL continuation query of a conjunctive query includes a union, therefore, we define the continuous evaluation of disjunctions. The continuation query of a union operator unions solution mappings and continuation queries of both operands:

_Definition 3.8_ (_Union evaluation_\(\{\textit{Union}(P_{t},P_{r})\}_{G}^{n}\)).: The _continuous_ evaluation of a union between two graph patterns \(P_{t}\) and \(P_{r}\) with a mapping \(\mu\) as environment is:

\[\{\textit{Union}(P_{t},P_{r})\}_{G}^{n}=(\Omega_{l}\uplus\Omega_{r},Q_{c})\ \textsc{where} \begin{cases}\{\{p\}_{P}^{n}\}=(\Omega_{r},Q_{r})\\ \{\{p\}_{G}^{n}\}=(\Omega_{r},Q_{r})\\ Q_{c}=Union(Q_{l},Q_{r})\\ \end{cases}\]

We consider the evaluation of basic graph patterns (BGPs) as an instance of a join evaluation where \(P_{t}\) is the first triple pattern and \(P_{r}\) corresponds to the remaining triple patterns.

_Example 3.9_.: To illustrate the evaluation of conjunctive queries, let us consider the Graph \(G_{ex}\) of Figure 2. An end-user wants to retrieve all human beings along with their occupations - a query \(Q_{kpq}\) that times out after 60 seconds on the Wikidata public SPARQL endpoint:

```
SELECT*WHERE{'humanwdt:P31wd:Q5}#tp:allhumanbeings
```

The continuous evaluation of the query \(\textit{Join}(\textit{tp}_{t},\textit{tp}_{2})\) where \(\textit{tp}_{1}=(\textit{Thumanwdt:P31wd:Q5})\) and \(\textit{tp}_{2}=(\textit{Thumanwdt:P106}\ \textit{speccaption})\) is \(\{\textit{Join}(\textit{tp}_{1},\textit{tp}_{2})\}_{G}^{n}\). Assuming an interruption after having read the first mapping of \(\textit{tp}_{1}\), the resulting continuous evaluation is:

\[\{\textit{Join}(\textit{Join}(\textit{tp}_{1},\textit{tp}_{2})\}_{G}^{n}=( \textit{0},\textit{Union}(\textit{Join}(\textit{Slice}(\textit{tp}_{1}),1), \textit{tp}_{2}),\]

The end-user receives no results yet, with a SPARQL continuation query corresponding to:

``` SELECT*WHERE{

[MISSING_PAGE_FAIL:4]

[MISSING_PAGE_FAIL:5]

a smart client can process queries between TPF or SPF and download a partition of triples from the server for processing on a smart client. Using pre-defined and compressed partitions of triples can significantly reduce the data transfer between an LDF server and a smart client.

While using pre-defined partitions is an effective optimization technique that can be used by any smart client, it is difficult to integrate into a standard SPARQL.

Web preemptionSaGe suspends SPARQL queries after a quantum of time to return partial results with a saved physical plan (Bartos et al., 2018; Kiefer et al., 2019; Kiefer et al., 2019). The physical plan can be reloaded by the server, allowing it to restart from where it had been stopped. SaGe ensures responsiveness and completeness for BGPs, some aggregate queries(Kiefer et al., 2019), and a subset of property path queries(Kiefer et al., 2019). However, SaGe is not compliant with the SPARQL endpoint standard. It requires to extend the interface of the server for re-loading saved plans.

In Passage, saved plan are replaced by continuation queries that are just regular SPARQL queries. When a saved plan is encoded and compressed, a continuation query is just human readable. When a new server interface is required to reload saved plan, a continuation query is just executed as new SPARQL query, maybe with a plan different from its previous query. Compared to SaGe, continuation queries are defined in a formal framework allowing to express the continuation problem, proving its correctness, its termination and computing space complexities. Web preemption is defined at the physical level, continuation queries are defined at the logical level.

## 5. Experiments Study

This experimental study aims to answer three questions empirically:

1. What is the difference in execution time between Passage with quotas and Passage without quotas?
2. What are the average size and number of generated continuation queries?
3. How does the execution time of queries with Passage compare to that of representative SPARQL engines?

Passage is implemented in Java on top of Blazegraph's storage and supports core SPARQL operators. To ensure logarithmic access times to triple patterns by offset, we rely on the augmented balanced trees index of Blazegraph2. Additionally, we extended the smart client Comunica (Sanchez-Gonzalez et al., 2018) to decompose queries for Passage, i.e., SPARQL operators not supported by Passage are executed within Comunica. The code for reproducible experiments is publicly available on GitHub at: [https://anonymous.4open.science/r/passage-experiments-C0D3](https://anonymous.4open.science/r/passage-experiments-C0D3).

Footnote 2: [https://github.com/blazegraph/database/wiki/BTreeGuide](https://github.com/blazegraph/database/wiki/BTreeGuide)

### Experimental Setup

**Datasets:** We use the WDBench (Bartos et al., 2018), a real-world large dataset extracted from Wikidata containing around 1.25 billion triples.

**Queries:** We focus on basic graph pattern queries (BGPs) and optional queries (OPTs) from WDBench that fail to complete within a 60-second timeout on Blazegraph, as those terminating within 60 seconds are considered to be adequately handled by current SPARQL engines. Specifically, we randomly selected 49 BGPs and 38 OPTs, which take between one to five minutes to execute on Blazegraph using a single vCPU core with 54 GB of RAM. The selected BGPs contain 2 to 6 triple patterns, while the OPTs contain 2 to 1 triple patterns.

**Approaches:** We compare the following approaches:

* passageWe run passage query engine the Blazegraph storage without a timeout and with a 60-second timeout, denoted passage and passage-60s, respectively. The 60 seconds was chosen to comply with Wikidata's fair-use policy.
* Blazegraph: We run Blazegraph (v 2.1.4), a high-performance SPARQL engine currently serving Wikidata, without any quota or limitations.
* Apache Jena: A popular open-source framework for building Semantic Web and Linked Data applications3. Jena (v 5.1.0) runs with its TBB2 data storage, and we set its query execution timeout to 10 minutes. Footnote 3: [https://jena.apache.org/](https://jena.apache.org/)
* SaGe (Kiefer et al., 2019): A SPARQL query engine based on Web Preemption. We run the SaGe query engine without a time quantum and with a 60-second time quantum, denoted SaGe and SaGe-60s, respectively. The data is stored in read-only HDT files (Kiefer et al., 2019).

We did not include TPF (Kiefer et al., 2019) or bTPF (Kiefer et al., 2019) as they are already outperformed by SaGe (Kiefer et al., 2019). Similarly, we excluded Smart-KG (Kiefer et al., 2019) and WiseKG (Kiefer et al., 2019) because they require pre-computing partitions of triples for query processing. Serving partitions of triples is not part of the SPARQL endpoint protocol and is irrelevant in our context.

**Hardware Configuration:** We run all the servers on a local cloud instance with Ubuntu 20.04.4.LTS, an AMD EPYC 7513-Core processor with 16 vCPUs allocated to the VM, 1 TB SSD, and 64 GB of RAM. To ensure a fair resource distribution among the different approaches, we conducted experiments using two different

\begin{table}
\begin{tabular}{l c c c c c c} \hline \hline  & \multicolumn{3}{c}{**IoVCPU**} & \multicolumn{3}{c}{**4vCPU**} \\ \cline{2-7}  & **Total** & **BGPs** & **OPTs** & **Total** & **BGPs** & **OPTs** \\ \hline
**Blazegraph** & 238.86 & 141.17 & 97.69 & 89.21 & 51.49 & 37.72 \\
**Apache Jena** & 610.06 & 347.76 & 262.30 & 611.41 & 347.41 & 264.00 \\
**SaGe** & 407.12 & 277.92 & 129.20 & 409.11 & 278.83 & 130.28 \\
**Passage** & **143.72** & **86.58** & 57.14 & 130.52 & 79.96 & 50.56 \\
**Safe Gos** & 413.81 & 279.02 & 134.79 & 413.17 & 278.65 & 134.52 \\
**Passage** & **60s** & **145.30** & **87.38** & 57.92 & 132.24 & 80.94 & 51.30 \\
**Passage** & & & & & & \\ \hline \hline \end{tabular}
\end{table}
Table 1. Average total execution time (min) for BGPs and OPTs queries with different CPU configurations. Total represents the sum of execution times of both BGPs and OPTs.

\begin{table}
\begin{tabular}{l c c c c} \hline \hline  & \multicolumn{2}{c}{**BGPs**} & \multicolumn{2}{c}{**OPTs**} \\ \cline{2-5}  & **size** & **\#TO/Total** & **size** & **\#TO/Total** \\ \hline
**SaGe 60s** & 1.18\&KB & 5.177/**292.67** & 1.927/**2**/**3** & 3.070/**152.67** \\ \hline
**passage 60s** & 0.821\&KB & **1.492/**62.67** & 0.827/**3** & **1.556/**41.67** \\ \hline
**SaGe 60s** & 1.16\&KB & 5.197/**296** & 1.929/**3** & 3.044/**153.67** \\ \hline
**passage 60s** & 0.780\&KB & 1.390/**57** & 0.649/**3** & 1.372/**30.33** \\ \hline \hline \end{tabular}
\end{table}
Table 2. Average size of continuation queries or saved plans, and average number of continuation queries (#TO) for Passage 60s or average number of suspended plans for SaGe 60s.

configurations: one with a single virtual CPU (t\(\times\)CPU) and another with four virtual CPUs (4vCPU), both with 54 GB of RAM allocated to the virtual machine. The 1vCPU setup servers as a fair baseline for all engines, particularly those that do not utilize parallelism, ensuring no engine gains an unfair advantage from multi-threading. The 4vCPU setup allows us to evaluate the potential improvement from increased computational resources and parallel processing.

**Evaluation Metrics:** We always ensure that our approach passage produces complete results using Blazergraph's results as ground truth. Presented results correspond to the average obtained of three successive executions of the queries workloads. We measure:

* Total workload execution time: is the total time the engine takes to execute queries workload and get complete results.
* Number of continuation queries: is the number of continuations for each query.
* Size of continuation queries: is the size of a continuation query in kilobytes.

### Experimental Results

_What is the difference in execution time between passage with quotas and passage without quotas?_

Table 1 presents the average execution time for different query workloads across the two vCPU configurations, comparing various approaches. The difference in execution time between passage-60s and passage for 1vCPU is 1.58 minutes. The total number of generated continuation queries is approximately 104 (as shown in Table 2). By dividing the 1.58 minutes overhead by 104, we find the overhead per continuation query to be nearly 900ms.

Applying the same analysis for SaGe and SaGe-60s, the overhead for interrupting queries in the t\(\times\)CPU setup amounts to 6.69 minutes over 413 minutes of execution. The total number of interruptions for SaGe-60s for this workload is approximately 589, resulting in an overhead of about 681 milliseconds per interruption in SaGe, which is slightly less than that of passage-60s. Compared to SaGe, the continuation queries in passage-60s require parsing and optimization, which explains the slight difference in time per interruption. However, re-optimizing continuation queries may lead to better execution plans, representing a good trade-off in performance.

_What are the average size and number of generated continuation queries?_

Table 2 presents the average size and number of continuation queries for BGPs and OPTs queries across different configurations. For passage-60s, regardless of the configuration, the average number of continuation queries remains low, always fewer than 2. In

Figure 4. Execution time for OPTs queries group by number of triple patterns in the query with 1vCPU.

Figure 3. Execution time for BGPs queries group by number of triple patterns in the query with 1vCPU.

contrast, SaGe-60s generates more saved plans; for instance, it generates an average of 5 for BGPs queries. As passage-60s is faster than SaGe-60s, passage-60s is less interrupted than SaGe-60s.

Regarding query size, passage-60s consistently produces small query sizes, averaging around 0.8 KB, irrespective of the workload or configuration. In comparison with SaGe-60s, the size of the suspended plans are larger than the size of continuation queries of passage-60s, whatever the setup.

_How does the execution time of queries with passage compare to that of representative SPARQL engines?_

Table 1 presents the performance of passage-60s with SaGe-60s, Blazegraph, and Apache Jena. The quota of 60s applies only to passage-60s and SaGe-60s, which ensure both completeness and responsiveness. Blazegraph and Apache Jena execute the workload without interruption, i.e., without quota. While they ensure the completeness, they do not guarantee the responsiveness.

On the 1vCPU configuration, passage-60s is the fastest engine for BGPs and OPTs queries. It is slightly faster than Blazegraph but approximately 3 times faster than Sage-60s and 4 times faster than Jena. On the 4vCPU configuration, Blazegraph is the best-performing engine. Blazegraph implements intra-query parallelism and takes advantage of the 4vCPU while other engines continue to use mainly 1vCPU. JENA and SaGe-60s have very similar execution time with 1vCPU, passage-60s execution time is slightly improved.

For further detail, Figures 3, and 4 illustrate execution time per query for 1vCPU for BGPs and OPTs queries, respectively. In these figures, queries are grouped by the number of triple patterns labeled along the x-axis, while the y-axis shows the average execution time through 3 runs in minutes, ranging from zero to ten. The queries are ordered by Blazegraph's execution time within each group. Red "t" marks appear above some bars, indicating those queries timed out on the engine. The horizontal red line at 1min represents the quota of 60s.

Figure 3 presents the result for BGPs queries. Blazegraph executes a query within 1min and 5min. Jena's execution times are significantly higher for many queries than other engines, with frequent timeouts at 10 minutes (12 out of 49 queries), likely due to join order. SaGe-60s can terminate all the workload queries except query 646 due to poor join ordering.

In contrast, our engine, passage-60s, delivers good overall performance with an average execution time of 106.02 seconds and only one timeout on a complex query (q646). This is also caused by the join order; after fixing the join order, the execution time dropped drastically from over 10 min to just 3 seconds. While Jena outperforms passage in a few isolated cases, these are exceptions due to specific join orders.

For OPTs queries in Figure 4, Jena times out after 10 min on nearly half of the workload (17 queries out of 38), though it occasionally performs better than passage-60s on 2 queries due to efficient join order. passage consistently outperforms all other engines, with an average execution time of 90.21 seconds, completing 13 queries in less than 60 seconds.

The detailed results for 4vCPU are available in Appendix D.

Overall, we observe that passage consistently delivers high performance in the same order of magnitude as Blazegraph while ensuring results completeness and responsiveness.

## 6. Conclusion and Future Work

In this paper, we introduced the concept of SPARQL continuation query to enable public SPARQL endpoints to achieve completeness, responsiveness and performance without wasting computation resources. When query execution reaches the timeout, the endpoint interrupts it, returns partial results along with a continuation query that efficiently represents the missing results in a SPARQL-compliant format. To support continuations, passage relies on two key assumptions: (1) Triple pattern evaluations must return an ordered list of mappings, a condition easily met when RDF triples are indexed by traditional B-trees. (2) Each partial evaluation of a continuation query must ensure progress, meaning it processes at least one scan of any triple pattern of the query. This requires efficient access to an offset in the triple patterns, a feature already supported in Blazegraph storage and HDT. With these two requirements in place, any SPARQL engine can be transformed into a continuous SPARQL engine capable of providing completeness, responsiveness, and robust performance, as demonstrated in our experiments.

For future work, we plan to work on intra-query parallelism for continuations queries to speed up the execution of core SPARQL queries. Additionally, we plan to support more SPARQL clauses such as count, group by, and distinct, gradually deporting smart clients operations to servers to enhance performance.

## References

* (1)
* Abeble et al. (2020) Christian Abeble, Ilkcan Keles, Gabriela Montroy, and Katja Rose. 2020. Star Pattern Enginomics: Accessing Knowledge Graphs through Star Pattern. _CoRR_ abs/2002.09172 (2020), arXiv:2002.09172 [https://arxiv.org/abs/2002.09172](https://arxiv.org/abs/2002.09172)
* 18th International Conference, ESWC 2021, Virtual Event, June 9-10, 2021, Proceedings__(Lecture Notes in Computer Science, Vol. 12731)_. Ruben Verbegh, Kaija Hoe, Heida Paulehtein, Pierre-Antoine Champin, Maria-Malkhoya, Oscar Corchu, Peter Ritaokoski, and Melvinah Alam (Eds.), Springer, 57-72. [https://doi.org/10.1007/978-3-030-7385-4_4](https://doi.org/10.1007/978-3-030-7385-4_4)
* ISWC 2022
- 21st International Semantic Web Conference, Virtual Event, October 23-22, Springer-Verlag, Berlin, Heidelberg, 147-173.
* ISWC 2013
- 21st International Semantic Web Conference, Sydney, NSW, Australia, October 22-22, 2013, Proceedings__Part I (Lecture Notes in Computer Science, Vol. 8219)_. Springer, 277-293. [https://doi.org/10.1007/978-3-040-1138-4_18](https://doi.org/10.1007/978-3-040-1138-4_18)
* ISWC 2014
- 31th International Semantic Web Conference, Ringdale, Italy, October 19-23, 2014 Proceedings__Part II (Lecture Notes in Computer Science, Vol. 897)_. Springer, 390-406. [https://doi.org/10.1007/978-3-3-319-1195-1_25](https://doi.org/10.1007/978-3-3-319-1195-1_25)
* Azzam et al. (2021) Amr Azzam, Christian Abeble, Gabriela Montroy, Ilkcan Keles, Axel Poulers, and Katja Rose. 2021. WieRock22021. Virtual Event /1145

[MISSING_PAGE_FAIL:9]

(Case 3) \(\left\|\mathit{LeftJoin}(\{\},P_{r})\right\|_{G}=\emptyset\) and \(\mathit{LeftJoin}(\{\},P_{r})_{c}=\mathit{LeftJoin}(\{\},P_{r_{c}})\) given that \(\left[P_{c}\right]_{G}^{\alpha}=\emptyset\uplus\left[P_{r_{c}}\right]_{G}\);

\(\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}=\left[\text{Definition }3.10\right]\)

\(\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}\uplus\left[\mathit{LeftJoin}( \{\},P_{r})_{c}\right]_{G}\)

\(=\left\{\text{Case 3}\right\}\)

\(\emptyset\uplus\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}\)

\(=\left\{\text{definitions of }\mathit{LeftJoin}\text{ and }\mathit{Extend}\right\}\)

\(\left\{\mu\uplus\left[P_{r_{c}}\right]_{G}\right\}\)

\(=\left\{\text{Case 3 and inductive hypothesis}\right\}\)

\(\left[\mathit{\mu}\uplus\left[P_{r}\right]_{G}\right.\)

(Case 4) \(\left\|\mathit{LeftJoin}(\{\},P_{r})\right\|_{G}=\Omega_{r}\) and \(\mathit{LeftJoin}(\{\},P_{r})_{c}=P_{r_{c}}\) with \(\left[P_{r}\right]_{G}^{\alpha}=\Omega_{r}\uplus\left[P_{r_{c}}\right]_{G}\) and \(\left[\Omega_{r}\right]>0\):

\(\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}=\left[\text{Definition }3.10\right]\)

\(\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}\uplus\left[\mathit{LeftJoin}( \{\},P_{r})_{c}\right]_{G}\)

\(=\left\{\text{Case 4 and inductive hypothesis}\right\}\)

\(\left[P_{r}\right]_{G}^{\alpha}=\left\{\text{by }\left[P_{r}\right]_{G}^{\alpha}\right\}\)

\(=\left\{\text{by }\left[P_{r}\right]_{G}^{\alpha}\right\}\)

\(\left[\mu\right]\uplus\left[P_{r}\right]_{G}\)

\(=\left\{\text{inductive hypothesis}\right\}\)

\(\left[\mu\right]\uplus\left[P_{r}\right]_{G}\)

Given that we have proved for each of the four cases that

\(\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}\uplus\left[\mathit{LeftJoin}( \{\},P_{r})\right]_{G}=\left\{\mu\uplus\left[P_{r}\right]_{G}^{\alpha}\right\}\)

shown that \(Q_{c}=\mathit{LeftJoin}(\{\},P_{r})\) satisfies \(\left[Q_{c}\right]_{G}=\Omega_{r}^{\alpha+1}\uplus\left[Q_{c}^{\alpha+1}\right]_ {G}\)

For the inductive case \(Q_{c}=\mathit{LeftJoin}(P_{r},P_{r})\), the inductive hypothesis is: \(\left[P_{r}\right]_{G}^{\alpha}=\Omega_{r}\uplus\left[P_{r}\right]_{G}\) and \(\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}^{\alpha}=\Omega_{r}\uplus\left[ \mathit{LeftJoin}(\{\},P_{r})_{c}\right]_{G}^{\alpha}\). Therefore:

\(\left[\mathit{Col}_{G}\uplus\left[P_{r}\right]_{G}\right.\)

\(=\left\{\text{Definition }3.10\right\}\)

\(\Omega_{tr}\uplus\left[\mathit{Union}(\mathit{LeftJoin}(\{P_{r}\},P_{r}), \mathit{Extend}(\Omega_{r}\mathit{LeftJoin}(\{\},P_{r})_{c})\right]_{G}\)

\(=\left\{\text{definitions of }\mathit{Union}\text{, }\mathit{LeftJoin}\text{, and }\mathit{Extend}\right\}\)

\(\Omega_{tr}\uplus\left[P_{r}\right]_{G}\uplus\left[P_{r}\right]_{G}\uplus \left[\mathit{LeftJoin}(\{\},P_{r})_{c}\right]_{G}\)

The values of \(\Omega_{tr}\) and \(\mathit{LeftJoin}(\{\},P_{r})_{c}\) follow the four cases detailed for \(\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}\), so we shall split \(\Omega_{t}\) into four bags \(\Omega_{1}\ldots\Omega_{4}\) where each of these bags includes all the \(\mu\)s that fall into each of those four cases:

For \(\Omega_{1}:\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}^{\Omega_{1}}=\Omega_{1} \uplus\left[\{\}\right]_{G}\);

For \(\Omega_{2}:\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}^{\Omega_{2}}=\Omega_{2} \uplus\left[\{\}\right]_{G}\),

\(\left[\Omega_{2}\uplus\left[P_{r}\right]_{G}^{\Omega_{2}}=\Omega_{2}\uplus \left[\{\}\right]_{G}\uplus\left[P_{r}\right]_{G}\right.\)

\(\left.\left[\Omega_{2}\uplus\left[P_{r}\right]_{G}^{\Omega_{2}}=\emptyset\uplus \left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}^{\Omega_{2}}\right.\)

For \(\Omega_{3}:\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}^{\Omega_{3}}=\emptyset\uplus \left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}\);

For \(\Omega_{4}:\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}^{\Omega_{4}}=\Omega_{r} \uplus\left[P_{r}\right]_{G}^{\Omega_{4}}\)

\(\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}^{\Omega_{4}}=\Omega_{r}\uplus \left[P_{r}\right]_{G}\)

\(\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}^{\Omega_{4}}=\left[\mathit{LeftJoin}(\{\},P_{r})\right]_{G}\uplus \left[P_{r}\right]_{G}\)

\(=\left\{\text{definition of }\mathit{LeftJoin}\right\}\)

\(\Omega_{t}\uplus\left[\{\}\right]_{G}\uplus\left[P_{t}\right]_{G}\uplus\left[P_{t}\right]_{G}\)

\(=\left\{\text{evaluation of }\{\}\text{ and distributivity}\right\}\)

\(\left(\Omega_{t}\uplus\left[P_{t}\right]_{G}\right)\uplus\left[P_{r}\right]_{G}\)

\(=\left\{\text{inductive hypotheses}\right\}\)

\(\left[P_{t}\right]_{G}\uplus\left[P_{r}\right]_{G}\)

Given that we have proved

\(\left[\mathit{LeftJoin}(P_{r},P_{r})\right]_{G}\uplus\left[\mathit{LeftJoin}(P_{r},P_{r})\right]_{G}=\left[P_{t}\right]_{G}\uplus\left[P_{r}\right]_{G}\), we have shown that \(Q_{c}^{\alpha}=\mathit{LeftJoin}(P_{r},P_{r})\) satisfies

\(\left[\Omega_{c}^{\alpha}\right]_{G}=\Omega_{c}^{\alpha+1}\uplus\left[Q_{c}^{ \alpha+1}\right]_{G}\)

The inductive cases \(Q=\mathit{Union}(P_{r},P_{r})\), \(Q=\mathit{Extend}(\mu,P)\), and \(Q=\mathit{Filter}(E,P)\) are similar as they depend only on the continuation query of their operands and therefore, we detail only the first one.

For the inductive hypothesis is: \(\left[P_{I}\right]_{G}^{\alpha}=Q_{u}\uplus\left[\mathit{LeftJoin}(P_{r},P_{r})\right]_{G}\) and \(\left[P_{G}\right]_{G}^{\alpha}=\Omega_{r}\uplus\left[P_{r}\right]_{G}\). Therefore:

\(\left[\mathbb{Q}_{u}\right]_{G}^{\alpha}\)

\(=\left[\text{Definition }3.8\right]\)

\(\Omega_{t}\uplus\Omega_{r}\uplus\left[\mathit{Union}(P_{k},P_{r})\right]_{G}\)

\(=\left\{\text{definitions of }\mathit{Union}\right\}\)

\(\Omega_{t}\uplus\Omega_{r}\uplus\left[\mathit{P_{k}}\right]_{G}\uplus\left[P_{r}\right]_{G}\uplus\left[P_{r}\right]_{G}\)

\(=\left\{\text{hypothesis inductive}\right\}\)

\(\left[\mathbb{P}_{t}\right]_{G}^{\alpha}\uplus\left[\mathbb{P}_{t}\right]_{G}^{\alpha}\)

Therefore \(Q_{c}^{\alpha}=\mathit{Union}(P_{r},P_{r})\) satisfies \(\left[Q_{c}^{\alpha}\right]_{G}=\Omega_{c}^{\alpha+1}\uplus\left[Q_{c}^{\alpha+1}\right]_{G}\)

As we have shown that \(\left[Q_{c}^{\alpha}\right]_{G}=\Omega_{c}^{\alpha+1}\uplus\left[Q_{c}^{\alpha+1}\right]_{G}\) is satisfied in the base case and the inductive cases, we have completed the proof of Theorem 3.13.

## Appendix B Proof of Termination

Proof.: Given \(Q=Q_{c}^{\alpha}\) and \(Q_{c}^{\alpha+1}\) the continuation query of \(Q_{c}^{i}\), the sequence of continuation queries \(Q_{c}^{i}\ldots Q_{c}^{\alpha}\) is finite if the space explored by \(Q_{c}^{i+1}\) is strictly smaller than the space explored by \(Q_{c}^{i}\). Given the definition of continuation queries, this condition does not hold in general, but only for executions were each partial execution is able to make some progress in the evaluation of the query.

We must prove that the space explored does not increase over continuations, i.e., \(\mathit{space}(Q_{c}^{i+1})\leq\mathit{space}(Q_{c}^{i})\), then identify the restrictions needed to ensure that an execution makes progress.

First, we define the space explored by a graph pattern as follows:

\[space(tp) =card([tp|_{G})\] \[space(Slice(Extend(\mu,tp),i)) =max(card([tp|_{G}\bowtie\mu)-i,0)\] \[space(Join(P_{i},P_{r})) =space(P_{i})\cdot space(P_{r})\] \[space(LeftJoin(P_{i},P_{r})) =space(Join(P_{i},P_{r}))\] \[space(Union(P_{i},P_{r})) =space(P_{i})+space(P_{r})\] \[space(Filter(E,P)) =space(P)\] \[space(Extend(Q,P)) =(1/(2+|\Omega|))\cdot space(P)\]

For the base case, \(Q_{i}\) is a triple pattern _tp_, its continuation query is \(Slice(Extend(\mu,tp),i)\). This continuation query explores a smaller space when \(i\) is greater than zero and the same space when \(i\) is zero.

The inductive cases \(Join(P_{i},P_{r})\) and \(LeftJoin(P_{i},P_{r})\) are similar and we detail only the first one. We have as inductive hypothesis that \(space(P_{k})\leq space(P_{i})\) and \(space(P_{r})\leq space(P_{r})\). For a conjunctive query \(Q_{j}=join(P_{i},P_{r})\), where the continuation query \(Q_{k}=Union(Join(P_{k},P_{r}),Extend(Q_{k},P_{r_{k}}))\). By definitions of the respective space for \(Union\), \(Join\), and \(Extend\):

\[space(Q_{k})=space(P_{k})\cdot space(P_{r})+(1/(2+|\Omega|))\cdot space(P_{r})\]

For \(space(Q_{k})\) to be smaller than \(space(P_{i})\cdot space(P_{r})\), we identify a restriction: \(space(P_{k})\) must be at most \(space(P_{i})-1\). Therefore:

\[space(P_{k})\cdot space(P_{r})+(1/(2+|\Omega|))\cdot space(P_{r})\] \[\leq \{\text{constraint}\}\] \[(space(P_{i})-1)\cdot space(Pr)+(1/(2+|\Omega|))\cdot space(P_{r})\] \[= \{\text{arithmetic}\}\] \[space(P_{i})\cdot space(P_{r})-space(P_{r})+(1/(2+|\Omega|))\cdot space (P_{r})\]

For this space to be smaller than \(space(P_{i})\cdot space(P_{r})\), it is sufficient that \((1/(2+|\Omega|))\cdot space(P_{r_{r}})<space(P_{r})\) and this follows from the inductive hypothesis.

The inductive cases \(Union(P_{i},P_{r})\), \(Filter(E,P)\), and \(Extend(\mu,P)\) are similar and we detail only the first one. The continuation query of \(Union(P_{i},P_{r})\) is \(Union(P_{k},P_{r})\).

\[space(Union(P_{k},P_{r}))=space(P_{k})+space(P_{r_{c}})\]

For this space to be smaller than the space explored by \(Union(P_{i},P_{r})\) at least one of \(space(P_{k})<space(P_{i})\) or \(space(P_{r_{c}})<space(P_{r})\) must hold.

The overall restriction we need to impose to obtain a finite sequence of continuation queries is that the partial evaluation of at least one triple pattern in \(Q_{c}^{i}\) has progressed by returning at least one mapping. If \(Q_{c}^{i}\) is a join or optional, for these operands their left operand must have progressed. This last restriction is due to the way the join and optional are formalized, where the solution mappings from the left operand are injected into the right operand. 

## Appendix C Proof of Query Size

Theorem 3.15 states that there is a bound on the number of triple patterns in a continuation query, i.e., the size of \(Q_{c}\), the continuation query of \(Q\) satisfies \(size(Q_{c})=O(\frac{size(Q)\cdot(size(Q)+1)}{2})\) given that \(\Omega\) the bag of environment mappings used in \(Q_{c}\) to pass solution mappings from the left operand to the right operands is at most 1.

Proof.: We must prove that, \(size(Q_{c})\leq c\cdot\frac{size(Q)\cdot(size(Q)+1)}{2}\) for some constant \(c\).

First, we define the size of a graph pattern as follows:

\[size(tp) =1\] \[size(Slice(Extend(\mu,tp),i)) =\begin{cases}1\text{ }1\text{ }1\text{ }i<[[tp]_{G}\bowtie\mu] \\ 0

[MISSING_PAGE_EMPTY:12]