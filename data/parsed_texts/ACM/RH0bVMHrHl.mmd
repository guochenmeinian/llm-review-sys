# Mirror Gradient: Towards Robust Multimodal Recommender Systems via Exploring Flat Local Minima

Anonymous Author(s)

###### Abstract.

Multimodal recommender systems utilize various types of information to model user preferences and item features, helping users discover items aligned with their interests. The integration of multimodal information mitigates the inherent challenges in recommender systems, e.g., the data sparsity problem and cold-start issues. However, it simultaneously magnifies certain risks from multimodal information inputs, such as information adjustment risk and inherent noise risk. These risks pose crucial challenges to the robustness of recommendation models. In this paper, we analyze multimodal recommender systems from the novel perspective of _flat local minima_ and propose a concise yet effective gradient strategy called Mirror Gradient (MG). This strategy can implicitly enhance the model's robustness during the optimization process, mitigating instability risks arising from multimodal information inputs. We also provide strong theoretical evidence and conduct extensive empirical experiments to show the superiority of MG across various multimodal recommendation models and benchmarks. Furthermore, we find that the proposed MG can complement existing robust training methods and be easily extended to diverse advanced recommendation models, making it a promising new and fundamental paradigm for training multimodal recommender systems.

Recommender systems, Multimodal, Flat local minima, Robust +
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

## 1. Introduction

**Relevance to the Web and to the track.** Recommender systems play a crucial role in helping users navigate the wealth of choices on the web and discover suitable items or online services. In fact, the integration of deep learning techniques into recommender systems has become widespread (Hardt et al., 2016; Liu et al., 2016; Wang et al., 2017; Wang et al., 2017). These techniques leverage historical user-item interactions to model user preferences, thereby facilitating the personalized recommendation of items. In recent years, with the emergence of rich multimodal content information encompassing texts, images, and videos, multimodal recommender systems (Wang et al., 2017; Wang et al., 2017) alleviate challenges (Wang et al., 2017) such as data sparsity and cold start. However, incorporating multimodal information into recommender systems also increases some inevitable risks about the input distribution shift.

The first risk is **inherent noise risk** which always appears in the training phase. Some previous works (Wang et al., 2017; Wang et al., 2017) show that the performance of recommender systems encounters substantial challenges when confronted with input containing some noise in multimodal information. These noises are intrinsic, such as subpar image quality of items or the presence of a significant number of irrelevant or error information in items' features. These factors contribute to inherent noise introduced to the model's input, and the introduction of multimodal data in multimodal recommender systems makes mitigating inherent noise risk more challenging. Another risk is **information adjustment risk**. After the recommender system has been trained based on multimodal data, it is well-known that multimodal data is prone to frequent adjustments. For example, merchants need to keep pace with trends or promotional activities to tailor keywords for items, and the descriptive images of items must be adjusted in line with iterative updates. This implies that in practical scenarios, the multimodal information within recommender systems often undergoes frequent modifications. A straightforward solution to address this risk is to update the model with the latest dataset, but as the volume of data increases, the cost of iterating the model significantly escalates, especially in multimodal recommender systems. In summary, these two risks pose a significant challenge (Wang et al., 2017; Wang et al., 2017; Wang et al., 2017; Wang et al., 2017) to multimodal recommender systems. Fig. 1 is **an e-commerce case** to illustrate the effect of the risks. On one hand, during the training phase of recommender systems, inherent noise exists in multimodal features such as the text, which is intrinsic and has a potentially negative effect in the inference phase. On the other hand, during the inference phase of recommender systems, the multimodal feature as shown in Fig. 1 of the bedysuit is edited due to promotional activities and the emphasis on the

Figure 1. An illustrative example of multimodal risks. Merchants add popular tags (e.g., “ins style”) and broad keywords (e.g., “suit”) to the text of the bedysuit to increase the likelihood of the item being recommended. At the same time, merchants dynamically change the item’s visual features in real-time due to Women’s Day marketing campaigns and the emphasis on the superiority of the item’s material. These actions make it difficult for the recommender system to accurately determine the target user for the current item, leading to incorrect recommendations for young girls.

item's material. These two risks confuse the recommender system resulting in incorrect recommendations, which will be explicitly and quantitatively assessed in Section 6.

To mitigate the aforementioned risks of information adjustment and inherent noise, the necessity for building a more robust multimodal recommender system becomes apparent. For enhancing the robustness, prior efforts (Bang et al., 2017; Li et al., 2017) have chiefly employed adversarial training techniques. These methods improve the robustness of multimodal recommender systems by explicitly countering noise at input during the training phase. Different from them, in this paper, we first rethink the robustness of multimodal recommender systems from the loss landscape perspective by considering the _flat local minima_ of multimodal recommendation models. Then, we propose a concise yet effective training strategy named Mirror Gradient (MG) for implicitly improving system robustness.

Specifically, we can first present an intuitive insight into why a recommender system should consider the flat local minima, which are located in large weight space regions with very similar low loss values (Li et al., 2017). In Fig. 2, \(\ell_{o}\) represents the original loss landscape, which is associated with the model's parameters, architecture, data distribution, etc. When the system's inputs face shifts in data distribution due to risks like information adjustment or inherent noise, \(\ell_{o}\) (transparent surface) also shifts to \(\ell_{s}\) (opaque surface). If the model's parameters are optimized to a sharp local minimum \(\theta_{b}\), the error caused by this shift \(|\ell_{s}(\theta_{b})-\ell_{0}(\theta_{b})|\) may be significantly larger than \(|\ell_{s}(\theta_{a})-\ell_{0}(\theta_{a})|\) of flat local minima \(\theta_{a}\). This indicates that the system is not robust while the parameters are in sharp local minima. Therefore, we should strive to guide the learnable parameters of a multimodal recommender system towards flat local minima during training to enhance the model's robustness against potential risks of input distribution shifts.

To this end, we propose a concise gradient strategy MG that inverses the gradient signs appropriately during training to make the multimodal recommendation models approach flat local minima easier compared to models with normal training. Additionally, we conduct extensive experiments and analysis to validate the effectiveness of MG across various datasets and systems empirically. To elaborate our MG strategy, we first model it formally and then analyze how it improves the model's robustness by driving the parameters towards flat local minima implicitly from a theoretical perspective. The visualization method from Li et al. (2017) supports our theoretical analysis and shows that MG indeed can help the model achieve flatter minima. Besides, we also empirically verify that MG is versatile, as it is compatible with most optimizers and other adversarial training-based robust recommendation methods. In summary, our contributions are threefold:

* We analyze the robustness of multimodal recommender systems from the perspective of flat local minima.
* From the perspective of flat local minima, we propose Mirror Gradient (MG), a concise yet effective gradient strategy that guides recommender system models toward flat local minima, enhancing model robustness. We also provide theoretical evidence for its effectiveness.
* Extensive experiments demonstrate the efficacy and versatility of MG. We also discuss the limitations of MG.

## 2. Related Works

**Multimodal Recommender Systems.** Traditional recommender systems (Li et al., 2017; Li et al., 2017; Li et al., 2017) model the interaction between users and items, relying on extensive user-item interaction data to ensure accurate recommendations. In the presence of diverse multimodal information, multimodal recommender systems (Li et al., 2017; Li et al., 2017; Li et al., 2017) leverage supplementary multimodal information to complement historical user-item interactions, mitigating challenges like data sparsity (Zhu et al., 2018) and cold start (Li et al., 2017; Li et al., 2017) in the recommendation. Early researchers often employed collaborative filter (Li et al., 2017; Li et al., 2017) or matrix factorization (Li et al., 2017) for multimodal recommendation modeling. Recently, many works (Li et al., 2017; Li et al., 2017) employ graph neural networks for multimodal recommender systems, with self-supervised learning (Li et al., 2017; Li et al., 2017) also gaining traction in this domain.

**Robust Recommender Systems.** Recent studies (Li et al., 2017; Li et al., 2017) have shed light on the vulnerability of recommender systems, highlighting how disturbances introduced by noise can significantly undermine the accuracy of recommendations. In pursuit of bolstering the robustness of recommender systems, a multitude of efforts (Li et al., 2017; Li et al., 2017; Li et al., 2017; Li et al., 2017) have focused on adversarial training. This approach, which operates under the premise that each instance may serve as a potential target for attacks (Li et al., 2017), introduces controlled perturbations to either the input data or model parameters to enhance robustness. However, most existing studies have overlooked the potential risks arising from information adjustment in multimodal recommender systems.

**Flat Local Minima.** Flat local minima have been consistently linked to the favorable generalization capabilities of deep neural networks (Li et al., 2017; Li et al., 2017; Li et al., 2017; Li et al., 2017; Li et al., 2017). In the wake of this insight, numerous researchers have surfaced, exemplified by works such as Du

Figure 2. Illustration of flat local minima. When the distribution of the inputs shifts, for example, facing the risks of inherent noise and information adjustment, the loss landscape \(\ell_{o}\) of the recommender system also shifts (to \(\ell_{s}\)) accordingly. The parameters \(\theta_{a}\) located in flat local minima are more robust compared to \(\theta_{b}\) in sharp local minima.

et al. (2017), Zhao et al. (2019), Zhuang et al. (2019), which strive to enhance model performance through exploring flat local minima. Specifically, Foret et al. (2010) introduces a novel approach named Sharpness-Aware Optimization (SAM), wherein the optimization process hinges on addressing a mini-max problem to achieve an optimal sharpness value. Kwon et al. (2018), on the other hand, proposes a scale-invariant variant of SAM, named ASAM, bolstered by an adaptive radius mechanism aimed at augmenting training stability. Moreover, Mi et al. (2019) innovatively delve into the realm of sparse perturbation with their SSAM (Sparse Sharpness-Aware Minima) approach, strategically focusing on perturbations that encapsulate the most critical yet sparse dimensions of the problem space.

## 3. Preliminary

### Multimodal Recommender Systems.

Considering a set of users \(\mathcal{U}=\{u_{1},u_{2},...,u_{|}\mathcal{U}\}\), and a set of items \(\mathcal{I}=\{i_{1},i_{2},...,i_{|}\}\), each user \(u\in\mathcal{U}\) is associated with an item set \(\mathcal{I}_{u}\subseteq\mathcal{I}\) about which \(u\) has expressed explicit positive feedback. Besides, each item \(i\in\mathcal{I}\) has multimodal information denoted by visual features \(v_{i}\in\mathcal{V}\) and textual features \(t_{i}\in\mathcal{T}\) in this paper. Then given a multimodal recommendation model denoted as \(\mathbf{R}(\cdot)\),

\[y_{u,i}=\mathbf{R}(u,i_{v},t_{i},\mathcal{I}_{u}\mid\Theta), \tag{1}\]

where \(\Theta\) represents the model parameters of \(\mathbf{R}(\cdot)\), and score \(y_{u,i}\) signifies the preference of user \(u\) towards item \(i\). A higher score suggests that item \(i\) is more suitable to be recommended to user \(u\).

**Loss Function of Recommender Systems.** Most works (Grover et al., 2010; Zhao et al., 2019) optimize the model parameters \(\Theta\) of multimodal recommender systems using Bayesian personalized ranking loss (Zhuang et al., 2019). This optimization seeks to ensure that \(y_{u,i}\), where \(i\in\mathcal{I}_{u}\), is greater than \(y_{u,i^{\prime}}\) when \(i^{{}^{\prime}}\notin\mathcal{I}_{u}\), thus promoting positive interactions while discouraging negatives ones. Additionally, some recommender systems introduce supplementary losses (Zhuang et al., 2019; Zhao et al., 2019) to enhance their performance. We adopt the unified notation \(L_{\mathbf{R}}(\cdot)\) to represent those losses.

## 4. Methodology

In this section, we first elaborate on the algorithm of the proposed MG. Then, we introduce the theoretical insight of MG.

### Mirror Gradient

MG is a concise and easily implementable approach that enhances the gradient of the model during the optimization process of recommender systems. This enhancement is equivalent to adding a regularization term to improve the system's robustness on input. The proposed MG consists of two phases in each training epoch: Normal Training and Mirror Training.

During Normal Training, the conventional gradient descent is applied to the loss function \(L_{\mathbf{R}}(\cdot)\) with the current learnable parameters \(\Theta_{t-1}\), as follows:

\[\Theta_{t}=\Theta_{t-1}-\eta\nabla_{\Theta}L_{\mathbf{R}}(\Theta_{t-1}), \tag{2}\]

where \(\eta\) represents the learning rate. As shown in the Algorithm 1, we use an interval \(\beta\) to control the effect of MG on each training epoch. After updating per \(\beta-1\) iterations using Eq. (2), we employ the Mirror Training strategy to update the parameter \(\Theta_{t-1}\) as follows:

\[\left\{\begin{aligned} \Theta_{t}^{\prime}&=\Theta_{t-1}- \alpha_{1}\eta\nabla_{\Theta}L_{\mathbf{R}}(\Theta_{t-1}),\\ \Theta_{t}&=\Theta_{t}^{\prime}+\alpha_{2}\eta\nabla_{ \Theta}L_{\mathbf{R}}(\Theta_{t}).\end{aligned}\right. \tag{3}\]

Here, in order to control the relative size of updates introduced by mirror training, we introduce two positive scaling coefficients, \(\alpha_{1}\) and \(\alpha_{2}\), with \(\alpha_{1}>\alpha_{2}\).

Although the MG we proposed is highly simple, it possesses a strong theoretical insight and remarkable versatility. This enables consistent performance improvements across a wide array of experimental scenarios. Furthermore, in Section 6, we demonstrate the compatibility of MG with various optimizers and existing robust recommender system techniques. Moreover, it can achieve superior performance compared to some conventional optimization strategies about flat local minima.

### Theoretical Insight of MG

In this part, we introduce Lemma 4.1 and Theorem 4.2 which can help us analyze how MG helps the model's parameters tend towards flat local minima from a theoretical perspective, thereby enhancing the input robustness of the recommender system.

Lemma 4.1.(Zhuang et al., 2019; Zhao et al., 2019) Consider a neural network \(f(x)\) with \(L\) layers and learnable parameters \(\theta\). \(h_{i},1\leq i\leq L\), denotes the feature map from \(i\) to layer. For any scalar function \(g\) of \(h_{L}\), we have

\[\|\nabla_{\theta}g(x)\|_{2}^{2}\cdot\sum_{j=1}^{L}O(\frac{1+\|h_{1}\|_{2}^{2}}{ \|\nabla_{\theta}x_{h}\|_{2}^{2}})\leq\|\nabla_{\theta}g_{\theta}(x)\|_{2}^{2}. \tag{4}\]

Theorem 4.2. Mirror Training in Eq. (3) is equal to introducing an implicit regularization term \(\|\nabla_{\Theta}L_{\mathbf{R}}(\Theta)\|_{2}^{2}\) to the original optimization objective \(L_{\mathbf{R}}(\Theta)\).

Proof.: In Mirror Training, we have

\[\Theta_{t} =\Theta_{t}^{\prime}+\alpha_{2}\eta\nabla_{\Theta}L_{\mathbf{R}} (\Theta_{t}^{\prime})\] \[=\Theta_{t-1}-\alpha_{1}\eta\nabla_{\Theta}L_{\mathbf{R}}(\Theta_{t -1})\] \[\quad+\alpha_{2}\eta\nabla_{\Theta}L_{\mathbf{R}}(\Theta_{t-1}- \alpha_{1}\eta\nabla_{\Theta}L_{\mathbf{R}}(\Theta_{t-1})). \tag{5}\]Next, since \(\eta\) is small, we can use Taylor expansion for estimating \(\nabla_{\Theta}L_{\text{R}}(\Theta_{t-1}-\alpha_{1}\eta\nabla_{\Theta}L_{\text{R}} (\Theta_{t-1}))\), and we have

\[\Theta_{t} \approx\Theta_{t-1}-\alpha_{1}\eta\nabla_{\Theta}L_{\text{R}}( \Theta_{t-1})+\alpha_{2}\eta\nabla_{\Theta}L_{\text{R}}(\Theta_{t-1})\] \[\quad-\alpha_{1}\alpha_{2}\eta^{2}\nabla_{\Theta}^{2}L_{\text{R}} (\Theta_{t-1})^{\top}\nabla_{\Theta}L_{\text{R}}(\Theta_{t-1})\] \[=\Theta_{t-1}-(\alpha_{1}-\alpha_{2})\eta\nabla_{\Theta}L_{\text{R}} (\Theta_{t-1})\] \[\quad-\frac{1}{2}\cdot\alpha_{1}\alpha_{2}\eta^{2}\nabla_{\Theta} \|\nabla_{\Theta}L_{\text{R}}(\Theta_{t-1})\|_{2}^{2}. \tag{6}\]

Therefore, from Eq. (6), we can find that the equivalent objective function for Mirror Training \(L_{M}\) is

\[L_{M}=(\alpha_{1}-\alpha_{2})\underbrace{L_{\text{R}}(\Theta)}_{\text{main term}}\ast \alpha_{1}\alpha_{2}\eta}_{\text{regularization term}}\times\underbrace{\|\nabla_{\Theta}L_{\text{R}}(\Theta_{t-1})\|_{2}^{2}}_{\text{regularization term}} \tag{7}\]

where \(\alpha_{1}\alpha_{2}\eta>0\) and \(\alpha_{1}-\alpha_{2}>0\). 

The essence of MG, as revealed in Theorem 4.2, lies in the addition of a regularization term concerning gradient magnitude to the original objective function \(L_{\text{R}}(\Theta)\) implicitly. It's worth noting that the magnitude of gradients near flat local minima is quite small. And since \(\alpha_{1}\alpha_{2}\eta>0\), Eq. (6) requires that the norm of gradient \(\|\nabla_{\Theta}L_{\text{R}}(\Theta)\|_{2}^{2}\) should be sufficiently small, i.e., MG will lead the model's parameters towards flatter minima. Furthermore, from Lemma 4.1 and Eq.(7), let the scalar function is \(L_{\text{R}}\) in recommender system, we have

\[L_{M} \geq\alpha_{1}\alpha_{2}\eta\cdot\|\nabla_{\Theta}L_{\text{R}}( \Theta_{t-1})\|_{2}^{2}\] \[\geq\alpha_{1}\alpha_{2}\eta\cdot\sum_{j=1}^{L}O(\frac{1+\|h_{i} \|_{2}^{2}}{\|\nabla_{x}h_{i}\|_{2}^{2}})\cdot\underbrace{\|\nabla_{x}L_{ \text{R}}\|_{2}^{2}}_{\text{robustness term}}. \tag{8}\]

In general, \((1+\|h_{i}\|_{2}^{2})/(\|\nabla_{x}h_{i}\|_{2}^{2})\) is bounded and positive. Taking BM3 on the Baby as an example, its value is around 96.16 with the well-trained system. Therefore, from Eq. (8) and Eq. (7), we can infer that MG also aims to minimize the impact of inputs on the loss, \(\|\nabla_{x}L_{\text{R}}\|_{2}^{2}\), while enhancing the model's robustness against input perturbations.

Furthermore, although Eq. (7) reveals that our proposed MG is equivalent to adding a regularization term \(\|\nabla_{\Theta}L_{\text{R}}(\Theta_{t-1})\|_{2}^{2}\) during the optimization process of recommender systems, we do not recommend directly including this term in the loss function. On one hand, computing this term requires the prior calculation of the gradient \(\nabla_{\Theta}L_{\text{R}}(\Theta_{t-1})\), implying additional computational overhead during inference and not easy to implement. On the other hand, this kind of explicit loss term is not conducive to optimization and generally results in relatively poor performance (Gulrajani et al., 2017). In fact, our proposed MG is an implicit optimization of the additional regularization term shown in Eq. (7). It is also straightforward to implement. Hence, MG possesses greater practical applicability and potential.

## 5. Experiments

In this section, we present our experimental setup and empirical results.

### Experimental Settings

**Datasets.** The dataset statistics have been summarized in Table 1. We primarily employ four multimodal datasets from Amazon (Xiong et al., 2017), including Baby, Sports, Clothing, and Electronics. These datasets comprise textual and visual features in the form of item descriptions and images. Our data preprocessing methodology follows the approach outlined in Zhou et al. (2017). Furthermore, we utilize the dataset Pinterest to assess the compatibility of Mirror Gradient with adversarial training methods in alignment with the official implementation of the adversarial training baseline AMR (Xiong et al., 2017).

**Metrics.** For the evaluation of recommendation performance, we pay attention to top-5 accuracy as recommendations in the top positions of rank lists are more important (Xiong et al., 2017), and adopt four widely used metrics (Zhou et al., 2017; Zhou et al., 2017; Zhou et al., 2017; Zhang et al., 2017) including recall (REC), precision (PREC), mean average precision (MAP), and normalized discounted cumulative gain (NDCG). These four evaluation metrics are chosen because they each focus on different crucial aspects. REC measures whether the system captures a user's potential areas of interest, PREC gauges the accuracy of recommendations, MAP focuses on the average accuracy of rankings, and NDCG emphasizes the quality

\begin{table}
\begin{tabular}{l c c c c} \hline \hline Dataset & \# Users & \# Items & \# Interactions & Sparsity (Xiong et al., 2017) \\ \hline Pinterest & 3,226 & 4,998 & 9,844 & 99.94\% (Xiong et al., 2017) \\ Baby & 19,445 & 7,050 & 160,792 & 99.88\% (Xiong et al., 2017) \\ Sports & 35,598 & 18,357 & 296,337 & 99.95\% (Xiong et al., 2017) \\ Clothing & 39,387 & 23,033 & 237,488 & 99.97\% (Xiong et al., 2017) \\ Electronics & 192,403 & 63,001 & 1,689,188 & 99.99\% (Xiong et al., 2017) \\ \hline \hline \end{tabular}
\end{table}
Table 1. Statistics of datasets. These datasets comprise textual and visual features in the form of item descriptions and images.

\begin{table}
\begin{tabular}{l c c c c} \hline \hline Model & REC & PREC & MAP & NDCG (Xiong et al., 2017) \\ \hline VBPR & 0.0182 & 0.0042 & 0.0098 & 0.0122 \\ VBPR + MG & 0.0203 & 0.0046 & 0.0110 & 0.0136 \\ \hline Improv. & 11.54\% & 9.52\% & 12.24\% & 11.48\% (Xiong et al., 2017) \\ \hline \hline MMGCN & 0.0140 & 0.0033 & 0.0075 & 0.0094 \\ MMGCN + MG & 0.0157 & 0.0036 & 0.0084 & 0.0106 \\ \hline Improv. & 12.14\% & 9.09\% & 12.00\% & 12.77\% (Xiong et al., 2017) \\ \hline GCNN & 0.0226 & 0.0051 & 0.0126 & 0.0155 \\ GRCN + MG & 0.0250 & 0.0057 & 0.0139 & 0.0171 \\ \hline Improv. & 10.62\% & 11.76\% & 10.32\% & 10.32\% (Xiong et al., 2017) \\ \hline DualGNN & 0.0238 & 0.0054 & 0.0132 & 0.0162 \\ DualGNN + MG & 0.0249 & 0.0056 & 0.0139 & 0.0170 \\ Improv. & 4.62\% & 3.70\% & 5.30\% & 4.94\% (Xiong et al., 2017) \\ \hline \hline BM3 & 0.0280 & 0.0062 & 0.0157 & 0.0192 \\ BM3 + MG & 0.0285 & 0.0063 & 0.0159 & 0.0195 \\ Improv. & 1.79\% & 1.61\% & 1.27\% & 1.56\% (Xiong et al., 2017) \\ \hline FREEDOM & 0.0252 & 0.0056 & 0.0139 & 0.0171 \\ FREEDOM + MG & 0.0260 & 0.0058 & 0.0144 & 0.0176 \\ Improv. & 3.17\% & 3.57\% & 3.60\% & 2.92\% (Xiong et al., 2017) \\ \hline \hline \multicolumn{4}{l}{**Avg. Improv.**} & **7.31\%** & **6.54\%** & **7.46\%** & **7.33\%** \\ \hline \hline \end{tabular}
\end{table}
Table 2. Top-5 recommendation performance of baselines with or without MG on Electronics. ‘Improv.’ indicates the relative enhancement of MG compared to the baseline. ‘Avg. Improv.’ represents the average improvement.

of rankings. These metrics complement each other and collectively provide a comprehensive evaluation, aiding in a holistic understanding of the recommender system's performance. Additionally, when comparing against the adversarial training method AMR (Shi et al., 2018), we apply the hits ratio (HR) in alignment with the evaluation approach used in the original AMR paper. The choice of HR serves the purpose of maintaining consistency and comparability with established benchmarks, allowing for a direct comparison of our results with those reported in the paper. All the above-cited metrics range from 0 to 1, the closer to 1 the better.
* **Baselines.** We extensively examine MG's performance across a variety of multimodal recommendation models, encompassing matrix factorization (VBPR (Verbik et al., 2015), graph neural networks (MMGCN (Shi et al., 2018), GRCN (Shi et al., 2018), DualGNN (Shi et al., 2018), FREEDOM (Shi et al., 2018), DRAGON (Shi et al., 2018)), self-supervised learning (SLMRec (Shi et al., 2018), BM3 (Shi et al., 2018)), as well as non-multimodal models(LayerGCN (Shi et al., 2018), SelfCF (Shi et al., 2018)). We utilize AMR (Shi et al., 2018) as our foundational adversarial training method, given its widespread popularity in the field. Additionally, we compare our MG with flat local minima approach SSAM (Shi et al., 2018), as it represents a leading-edge, versatile solution for addressing flat local minima.
* **Implementation Details.** We retain the standard settings for all baselines. Following the settings of some current works in multimodal recommender systems (Shi et al., 2018; Shi et al., 2018; Shi et al., 2018), we perform a grid search on hyperparameters \(\alpha_{1}\) and \(\alpha_{2}\), and set \(\beta\) to 3. Unless otherwise specified, Adam (Kingma and Ba, 2014) serves as the chosen optimizer. The training and evaluation of all models is conducted using the RTX3090 GPU.

### Overall Performance

**Observation #1:** MG can enhance the performance of diverse multimodal recommender systems consistently.** As shown in Table 3, we conduct an extensive evaluation of MG across eight baseline models using three distinct datasets. Our experimental findings unequivocally illustrate that it is difficult to overlook the enhancements in the performance of multimodal recommender systems with MG across all evaluation metrics. Remarkably, the most substantial improvement is observed in the case of VBPR training on the dataset Clothing, resulting in an impressive performance enhancement of over 20%. To summarize, MG we propose excels at

\begin{table}
\begin{tabular}{l c c c c c c c c c c c c} \hline \hline \multirow{2}{*}{Model} & \multicolumn{4}{c}{Baby} & \multicolumn{4}{c}{Sports} & \multicolumn{4}{c}{Clothing} \\ \cline{2-13}  & REC & PREC & MAP & NDCG & REC & PREC & MAP & NDCG & REC & PREC & MAP & NDCG \\ \hline VBPR & 0.0265 & 0.0059 & 0.0134 & 0.0170 & 0.0353 & 0.0079 & 0.0189 & 0.0235 & 0.0186 & 0.0039 & 0.0103 & 0.0124 \\ VBPR + MG & 0.0273 & 0.0061 & 0.0149 & 0.0184 & 0.0375 & 0.0084 & 0.0203 & 0.0251 & 0.0230 & 0.0048 & 0.0129 & 0.0155 \\ Improv. & 3.02\% & 3.39\% & 11.19\% & 8.24\% & 6.23\% & 6.33\% & 7.41\% & 6.81\% & 23.66\% & 23.08\% & 25.24\% & 25.00\% \\ \hline MMGCN & 0.0240 & 0.0053 & 0.0130 & 0.0160 & 0.0216 & 0.0049 & 0.0114 & 0.0143 & 0.0130 & 0.0028 & 0.0073 & 0.0088 \\ MMGCN + MG & 0.0269 & 0.0060 & 0.0139 & 0.0175 & 0.0241 & 0.0054 & 0.0126 & 0.0158 & 0.0153 & 0.0032 & 0.0081 & 0.0100 \\ \hline Improv. & 12.08\% & 13.21\% & 6.92\% & 9.38\% & 11.57\% & 10.20\% & 10.53\% & 10.49\% & 17.69\% & 14.29\% & 10.96\% & 13.64\% \\ \hline GRCN & 0.0336 & 0.0074 & 0.0182 & 0.0225 & 0.0360 & 0.0080 & 0.0196 & 0.0241 & 0.0269 & 0.0056 & 0.0140 & 0.0173 \\ GRCN + MG & 0.0354 & 0.0078 & 0.0186 & 0.0232 & 0.0383 & 0.0086 & 0.0207 & 0.0256 & 0.0276 & 0.0058 & 0.0146 & 0.0179 \\ Improv. & 5.36\% & 5.41\% & 2.20\% & 3.11\% & 6.39\% & 7.50\% & 5.61\% & 6.22\% & 2.60\% & 3.57\% & 4.29\

[MISSING_PAGE_FAIL:6]

range \([-100,100]\), and init noise \(n_{1},n_{2}\) from the standard normal distribution. \(n_{1},n_{2}\) have the same shape as \(p\). We then update the model's parameters to \((p+mn_{1}+nn_{2})\) and calculate the corresponding loss values, simulating the shift of the loss landscape as depicted in Fig. 2. By employing this methodology, we can generate training loss landscapes as illustrated in Fig. 3. The flatter the training loss landscape, the flatter the local minima to which the current model converges. Notably, the landscapes associated with MG demonstrate a flatter topography when compared to those of the baseline approaches and prominently encompass an area characterized by low loss (depicted in blue). These visualization results show that MG can make multimodal recommender system approach flatter minima. Moreover, from the visualization results, the loss landscape associated with FREEDOM appears flatter compared to that of BM3. This indicates that FREEDOM may be more robust to noise, aligning with the observations in Table 4.

**Convergence Speed of MG (RQ4).** In this part, we visualize the training loss of both widely used and leading-stage models to confirm MG's superior convergence. Following the training configuration outlined by Zhou et al. (2019), we set the maximum number of epochs to 1000 while implementing an early stopping strategy. Subsequently, we visualize the progression of the loss value for multiple multimodal recommendation models before and after the application of MG, as shown in Fig. 4. Noticeably, MG often leads the models to meet the termination criteria with fewer training iterations and achieve a smaller final training loss value.

**Comparing with Sharpness-aware Minimization (RQ5).** Recently, several general smoothing methods (Zhou et al., 2019; Li et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019) about flat local minima have been proposed. In this section, we compare these methods with MG in multimodal recommender systems. Specifically, we apply the recent method SSAM (Wang et al., 2019) to the multimodal recommendation model DRAGON on the dataset Baby, and the results are laid out in Table 7. The experimental results show that MG outperforms both SSAM-F, which draws upon fisher information, and SSAM-D, which capitalizes on the principles of dynamic sparse training mask (Wang et al., 2019). These experiments suggest the MG's inherent advantage of identifying flat local minima compared with other minimization methods in the scenario of multimodal recommender systems.

**Compatibility with Various Optimizers (RQ6).** As a gradient method, it is necessary for MG to adapt to various optimizers. Therefore, in this part, we evaluate the performance of MG on the dataset Baby under various optimizers and baselines as illustrated in Table 6. The optimizers include Adam (Kingma and Ba, 2014), SGD (Goodfellow et al., 2014; He et al., 2016), RMSprop (Kingma and Ba, 2014), and Adagrad (Abadi et al., 2014). Here, we choose the classic multimodal recommender system GRCN and the latest state-of-the-art multimodal recommender system DRAGON as baselines. Despite the considerable performance fluctuations observed among baselines under different optimizers, MG consistently delivers a noticeable enhancement in recommendation accuracy. This consistency highlights the stable performance of MG across a range of optimizers.

\begin{table}
\begin{tabular}{c|c c c c c|c c c c c} \hline \hline Optimizer & Model & REC & PREC & MAP & NDCG & Model & REC & PREC & MAP & NDCG & 758 \\ \hline \multirow{4}{*}{Adam} & GRCN & 0.0336 & 0.0074 & 0.0182 & 0.0225 & DRAGON & 0.0374 & 0.0082 & 0.0202 & 0.0249 & 758 \\  & GRCN + MG & 0.0354 & 0.0078 & 0.0186 & 0.0232 & DRAGON + MG & 0.0419 & 0.0092 & 0.0219 & 0.0273 & 757 \\  & Improv. & 5.36\% & 5.41\% & 2.20\% & 3.11\% & Improv. & 12.03\% & 12.20\% & 8.42\% & 9.64\% & 759 \\ \hline \multirow{4}{*}{SGD} & GRCN & 0.0013 & 0.0003 & 0.0005 & 0.0007 & DRAGON & 0.0182 & 0.0040 & 0.0093 & 0.0118 & 760 \\  & GRCN + MG & 0.0014 & 0.0003 & 0.0006 & 0.0008 & DRAGON + MG & 0.0188 & 0.0041 & 0.0097 & 0.0122 & 761 \\  & Improv. & 7.69\% & 0.00\% & 20.00\% & 14.29\% & Improv. & 3.30\% & 2.50\% & 4.30\% & 3.39\% & 762 \\ \hline \multirow{4}{*}{RMSprop} & GRCN & 0.0338 & 0.0074 & 0.0184 & 0.0227 & DRAGON & 0.0367 & 0.0081 & 0.0198 & 0.0245 & 764 \\  & GroCN + MG & 0.0345 & 0.0076 & 0.0187 & 0.0231 & DRAGON + MG & 0.0391 & 0.0087 & 0.0201 & 0.0253 & 765 \\  & Improv. & 2.03\% & 2.63\% & 1.60\% & 1.73\% & Improv. & 6.54\% & 7.41\% & 1.52\% & 3.27\% & 766 \\ \hline \multirow{4}{*}{Adagrad} & GRCN & 0.0283 & 0.0063 & 0.0152 & 0.0189 & DRAGON & 0.0393 & 0.0086 & 0.0215 & 0.0264 & 767 \\  & GRCN + MG & 0.0286 & 0.0064 & 0.0154 & 0.0191 & DRAGON + MG & 0.0408 & 0.0090 & 0.0216 & 0.0269 & 768 \\ \cline{1-1}  & Improv. & 1.06\% & 1.59\% & 1.32\% & 1.06\% & Improv. & 3.82\% & 4.65\% & 0.47\% & 1.89\% & 769 \\ \hline \hline \end{tabular}
\end{table}
Table 6. Top-5 recommendation performance of GRCN and DRAGON with or without MG on Baby. ‘Improv.’ indicates the relative enhancement of MG compared to the baselines.

Figure 4. Convergence of MG on the dataset Baby.

[MISSING_PAGE_FAIL:8]

## References

* (1)
* Boelm et al. (2022) Kevin M Boelm, Pegah Khosarov, Rami Vanguri, Jianjiong Gao, and Sohra P Shah. 2022. Hanning multidimensional data integration to advance precision oncology. _Nature Reviews Cancer_ 22, 2 (2), 2114-126.
* Bottou (2012) Lion Bottou. 2012. Stochastic gradient descent tricks. In _Neural Networks: Tricks of the Trade_. Second Edition. Springer, 421-436.
* Chen and Li (2019) Huiyuan Chen and Jing Li. 2019. Adversarial tensor factorization for context-aware recommendation. In _Proceedings of the 13th ACM Conference on Recommender Systems_. 363-367.
* Chen et al. (2002) Jiawei Chen, Hande Dong, Xiang Wang, Fui Feng, Meng Wang, and Xiangnan Zhou. 2002. Bias and della in recommender system: A survey and future directions. _ACM Transactions on Information Systems_ 41, 3 (2002), 1-39.
* Deldjo et al. (2021) Yashar Deldjo, Tommaso N Itoh, and Felice Mention Mermi. 2021. A survey on adversarial recommender systems: from attack/deline strategies to generative adversarial networks. _ACM Computing Surveys (CSUR)_ 2, 2 (2021), 1-38.
* Dietwin (2021) Benoitet di Diberin. 2021. The Geometric Ocan's Razor Implicit in Deep Learning. _arXiv preprint arXiv:2111.15900_ (2021).
* Du et al. (2021) Jiawei Du, Hanslyn Van, Jasish Feng, Joey Tsimay Zhou, Liangli Zhen, Rick Singer Mong, and Vincent T Tan. 2021. Efficient sharpness-aware minimization for improved training of neural networks. _arXiv preprint arXiv:2110.03141_ (2021).
* Du et al. (2018) Yahu Du, Meng Fang, Jingfeng Yi, Chang Xu, Jun Cheng, and Daeheng Tao. 2018. Enhancing the robustness of neural collaborative filtering systems under malicious attacks. _IEEE Transactions on Multimedia_ 21, 3 (2018), 555-565.
* Duh et al. (2011) John Duh, Elad Hazan, and Yoru Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. _Journal of machine learning research_ 12, 7 (2011).
* Feer et al. (2020) Pierre Feer, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur. 2020. Sharpness-aware minimization for efficiently improving generalization. _arXiv preprint arXiv:2001.04124_ (2020).
* Gao et al. (2022) Chen Gao, Xiang Wang, Xiangnan He, and Yong Li. 2022. Graph neural networks for recommender system. In _Proceedings of the Fifteenth ACM International Conference on Web Search and Data Mining_. 1623-1625.
* Graves (2013) Alex Graves. 2013. Generating sequences with recurrent neural networks. _arXiv preprint arXiv:1308.0889_ (2013).
* He et al. (2023) Bowei He, Xu He, Yingqiu Zhang, Ruiming Tang, and Chen Ma. 2023. Dynamically Expandable Graph Convolution for Streaming Recommendation. _arXiv preprint arXiv:2303.1170_ (2023).
* He et al. (2019) Haowei He, Gao Huang, and Yang Yuan. 2019. Asymmetric valleys: Beyond sharp and flat local minima. _Advances in neural information processing systems_ 32 (2019).
* He and McAuley (2016) Ruining He and Julian McAuley. 2016. VPRP: visual bayesian personalized ranking from implicit feedback. In _Proceedings of the AAAI Conference on artificial intelligence_, Vol. 30.
* He et al. (2020) Xiangnan He, Yuan Deng, Xiang Wang, Yan Li, Yonglong Zhang, and Meng Wang. 2020. Lightgcn: Simplifying and powering graph convolution network for recommendation. In _Proceedings of the 13rd International ACM SIGIR conference on research and development in Information Retrieval_. 693-648.
* Hochreiter and Schmidhuber (1994) Sepp Hochreiter and Jurgen Schmidhuber. 1994. Simplifying neural nets by discovering flat minima. _Advances in neural information processing systems_ 7 (1994).
* Hochreiter and Schmidhuber (1997) Sepp Hochreiter and Jurgen Schmidhuber. 1997. Flat minima. _Neural computation_ 9, 1 (1997), 1-42.
* Huang et al. (2021) Zhongshan Huang, Mingqi Liang, Sennwei Liang, and Wei He. 2021. AlterSGD: Finding flat minima for Continual Learning by Alternative Training. _arXiv preprint arXiv:2107.0580_ (2021).
* Huang et al. (2021) Zhongshan Huang, Weng Shao, Xiaogang Wang, Liang Lin, and Ping Luo. 2021. Rethinking the pruning criteria for convolutional neural network. _Advances in Neural Information Processing Systems_ 34 (2021), 16305-16318.
* Kadhou et al. (2022) Jean Kadhou, Lingliu Li, Ricardo Silva, and Just J Kusner. 2022. When do flat minima optimizers work: _Advances in Neural Information Processing Systems_ 35 (2022), 1637-1655.
* Kingma and Ba (2014) Deiederik P. Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. _arXiv preprint arXiv:1412.6080_ (2014).
* Kwon et al. (2021) Jungmin Kwon, Jeongpe Kim, Hyunse Park, and In Kwon Choi. 2021. Asam: Adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks. In _International Conference on Machine Learning_. PMLR, 5905-5914.
* Lam et al. (2008) Xuan Nhat Lam, Thue Vu, Trong Duc Le, and Anh Duc Duong. 2008. Addressing cold-start problem in recommendation systems. In _Proceedings of the 2nd international conference on Ubiquitous information management and communication_. 208-211.
* Li et al. (2018) Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein. 2018. Visualizing the loss landscape of neural nets. _Advances in neural information processing systems_ 31 (2018).
* Li et al. (2023) Inman Li, Dongpu Li, Skylio Savaree, and Steven Hoi. 2023. Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models. _arXiv preprint arXiv:2301.12597_ (2023).
* Li et al. (2020) Ruini Li, Xian Wu, and Wei Wang. 2020. Adversarial learning to compare: Self-attentive prospective customer recommendation in location based social networks. In _Proceedings of the 15th International Conference on Web Search and Data Mining_. 349-357.
* Malletta et al. (2023) Daniele Malletta, Giandominetco Cornacchia, Claudio Pomo, and Tommaso Di Noia. 2023. Disentangling the Performance Puzzle of Multimodal-aware Recommender Systems. In _Futl/Spo KDD (CECIR Workshop Proceedings, Vol. 3450). CEUR-N-95_.
* McAuley et al. (2015) Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. 2015. Image-based recommendations on styles and substitutes. In _Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval_. 43-52.
* Ng et al. (2022) Peng Ma, Li Shen, Tianhe Ren, Tiyi Zhou, Xiaohuan Sun, Rongrong Ji, and Daeheng Tao. 2022. Make sharpness-aware minimization stronger: A sparsified perturbation approach. _Advances in Neural Information Processing Systems_ 35 (2022), 30596-3062.
* Wang et al. (2002) Juan, Nizenha Huang, Yang Hu, and Chen Lin. 2022. A two-stage embedding model for recommendation with multimodal auxiliary information. _Information Sciences_ 28 (2022), 22-37.
* Rendle et al. (2012) Steffen Rendle, Christoph Freudenthaler, Zeno Gunter, and Lars Schmidt-Thieme. 2012. BRF: Bayesian personalized ranking from implicit feedback. _arXiv preprint arXiv:1205.1248_ (2012).
* Salah et al. (2020) Aghiles Salah, Quc-Tun Tuong, and Hady W Luu. 2020. Corrasc: A comparative framework for multimodal recommender systems. _The Journal of Machine Learning Research_ 21, 1 (2020), 3803-3807.
* Schena et al. (2002) Andrew Schena, Alexandria Popescu, Lyle H Umgar, and David M Pennock. 2002. Methods and metrics for cold-start recommendation. In _Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval_. 253-260.
* Shi et al. (2002) Guangyuan Shi, Jiaxin Chen, Wenlong Zhang, Li-Ming Zhu, and Xiao-Ming. Wu. 2021. Overcoming catastrophic forgetting in incremental few-shot learning by finding flat minima. _Advances in neural information processing systems_ 34 (2021), 6747-6761.
* Shi et al. (2018) Jagiela Ski, Chaochen Chen, Weiming Lin, Fei Wu, Xiaolin Zheng, and Haoming Lyu. 2018. Enhancing Hierarchy-Aware Graph Networks with Deep Dual Clustering for Session-based Recommendation. In _Proceedings of the ACM Web Conference_. 2023. 165-176.
* Sutskever et al. (2013) Ilya Sutskever, James Martens, Georg Dahl, and Geoffrey Hinton. 2013. On the importance of initialization and momentum in deep learning. In _International conference on machine learning_. PMLR, 1139-1147.
* Tang et al. (2018) Justin Tang, Xiaoyu Du, Xiangfan He, Ziejie Yuan, Qi Tian, and Tat-Seng Chua. 2018. Adversarial training towards robust multimedia recommender system. _IEEE Transactions on Knowledge and Data Engineering_ 32, 3 (2018), 855-867.
* Tang and Wang (2018) Jiaxi Tang and Ke Wang. 2018. Ranking distillation: Learning compact ranking models with high performance for recommender system. In _Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining_. 2289-2298.
* Xiaohua et al. (2012) Zhailin Tu, Xiaohua Liu, Tewei Xu, Xiang Wang, Liang Yang, Xiangnan Huang, and Tat-Seng Chua. 2012. Self-supervised learning for multimedia recommendation. _IEEE Transactions on Multimedia_ (2022).
* Wang et al. (2015) Hao Wang, Naiyan Wang, and Qin-Yan Yeung. 2015. Collaborative deep learning for recommender systems. In _Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining_. 1255-1244.
* Wang et al. (2021) Qian Wang, Yiwen Wei, Jhajun Yin, Jianlong Yu, Xuqiang Song, and Liqiang Nie. 2021. Dualplan: Dual graph neural network for multimedia recommendation. _IEEE Transactions on Multimedia_ (2021).
* Yuwei et al. (2020) Yuwei Wei, Xiang Wang, Liqiang Nie, Xiangnan He, and Tat-Seng Chua. 2020. Graph-refined convolutional network for multimedia recommendation with implicit feedback. In _Proceedings of the 26th ACM international conference on multimedia_. 3541-3549.
* Wang et al. (2011) Yiwen Wei, Xiang Wang, Liqiang Nie, Xiangnan He, Richang Hong, and Tat-Seng Chua. 2011. M360C: Multi-modal graph convolution network for personalized recommendation of micro-video. In _Proceedings of the 27th ACM international conference on multimedia_. 1437-1445.
* Chen et al. (2021) Chenwang Wu, Defu Liu, Yong Ge, Zhihao Zhu, Enhong Chen, and Senchao Yuan. 2021. Fight fire with fire: Towards robust recommender systems via adversarial poisoning training. In _Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval_. 1074-1083.
* Wu et al. (2022) Yuwei Wu, Yan Xiong, Yao Zhang, Yizhu Jiao, Jiawei Zhang, Yongping, and Philip S Yu. 2023. Contex: Learning Consensus Behind Interactions for Group Recommendation. In _Proceedings of the ACM Web Conference_. 2023. 240-250.
* Zhang et al. (2016) Fuheng Zhang, Nicholas Jang Yuan, Defu Liu, Xing Xie, and Wei-Ying Ma. 2016. Collaborative knowledge base embedding for recommender systems. In _Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining_. 353-362.
* Yang et al. (2022) Lingziang Yang, Yong Li, Xin Zhou, Chunyuan Miao, Guosui Wang, and Haihong Tang. 2022. Diffusion-based graph contrastive learning for recommendation withimplicit feedback. In _International Conference on Database Systems for Advanced Applications_. Springer, 232-247.
* [49] Yang Zhan, Hao Zhang, and Xinyuan Hu. 2022. Penalizing gradient norm for efficiently improving generalization in deep learning. In _International Conference on Machine Learning_. PMLR, 2008:26922.
* [50] Hongyu Zhou, Xin Zhou, and Zhiqi Shen. 2023. Enhancing Dyadic Relations with Homogeneous Graphs for Multimodal Recommendation. _arXiv preprint arXiv:2201.1207_ (2023).
* [51] Hongyu Zhou, Xin Zhou, Zhiwei Zeng, Lingxi Zhang, and Zhiqi Shen. 2023. A Comprehensive Survey on Multimodal Recommender Systems: Taxonomy, Evaluation, and Future Directions. _arXiv preprint arXiv:2302.04473_ (2023).
* [52] Xin Zhou. 2022. A rule for top graphs: Preparing and denoising graph structures for multimodal recommendation. _arXiv preprint arXiv:2211.06824_ (2022).
* [53] Xin Zhou, Donghui Lin, and Toru Ishida. 2016. Evaluating reputation of web services under rating scarcity. In _2016 IEEE International Conference on Services Computing (SCC)_. IEEE, 211-218.
* [54] Xin Zhou, Donghui Lin, Yong Liu, and Chunyan Miao. 2023. Layer-refined graph convolutional networks for recommendation. In _2023 IEEE 25th International Conference on Data Engineering (ICDE)_. IEEE, 1247-1259.
* [55] Xin Zhou, Xin Sun, Yong Liu, Zi Zhang, and Chunyan Miao. 2023. Self-A simple framework for self-supervised collaborative filtering. _ACM Transactions on Recommender Systems_. 1, 2 (2023), 1-25.
* [56] Xin Zhou, Hongyu Zhou, Yong Liu, Zhiwei Zeng, Chunyan Miao, Pengwei Wang, Yuan You, and Feijun Jiang. 2023. Bootstrap latent representations for multi-modal recommendation. In _Proceedings of the ACM Web Conference_. 2023. 845-854.
* [57] Juntaing Zhuang, Boqing Gong, Lianghe Yuan, Yin Cui, Hartwig Adam, Nicha Dvorne, Sekhar Tetikonda, James Duncan, and Ting Liu. 2022. Surrogate gnp minimization improves sharpness-aware training. _arXiv preprint arXiv:2203.08045_ (2022).
* [58]

[MISSING_PAGE_FAIL:11]