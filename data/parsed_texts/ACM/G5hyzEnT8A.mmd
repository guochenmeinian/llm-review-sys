# A Multifaceted Look at Starlink Performance

Anonymous Author(s)

###### Abstract.

In recent years, Low-Earth Orbit (LEO) mega-constellations have emerged as a promising network technology and have ushered in a new era for democratizing Internet access. The Starlink network from SpaceX stands out as the only consumer-facing LEO network with over 2M+ customers and more than 4000 operational satellites. In this paper, we conduct the first-of-its-kind extensive multi-faceted analysis of Starlink network performance leveraging several measurement sources. First, based on 19.2M crowdsourced M-Lab speed test measurements from 34 countries since 2021, we analyze Starlink global performance relative to terrestrial cellular networks. Second, we examine Starlink's ability to support real-time web-based latency and bandwidth-critical applications by analyzing the performance of (i) Zoom video conferencing, and (ii) Luna cloud gaming, comparing it to 5G and terrestrial fiber. Third, we orchestrate targeted measurements from Starlink-enabled RIPE Atlas probes to shed light on the last-mile Starlink access and other factors affecting its performance globally. Finally, we conduct controlled experiments from Starlink dishes in two countries and analyze the impact of globally synchronized "15-second reconfiguration intervals" of the links that cause substantial latency and throughput variations. Our unique analysis provides revealing insights on global Starlink functionality and paints the most comprehensive picture of the LEO network's operation to date.

## 1. Introduction

Over the past two decades, the Internet's reach has grown rapidly, driven by innovations and investments in wireless access (Zhou et al., 2017; Wang et al., 2018; Wang et al., 2018) (both cellular and WiFi) and fiber backhaul deployment that has interconnected the globe (Bauer et al., 2018; Wang et al., 2018; Wang et al., 2018; Wang et al., 2018; Wang et al., 2018). Yet, the emergence of Low-Earth Orbit (LEO) satellite networking, spearheaded by ventures like Starlink (Solarlink, 2018), OneWeb (Web, 2018), and Kuiper (Bauer et al., 2018), is poised to revolutionize global connectivity. LEO networks consist of mega-constellations with thousands of satellites orbiting at 300-2000 km altitudes, offering ubiquitous _low latency_ coverage worldwide. Consequently, these networks are morphing into "global ISPs" capable of challenging existing Internet monopolies (Solarlink, 2018), bridging connectivity gaps in remote regions (Solarlink, 2018; Wang et al., 2018), and providing support in disaster-struck regions with impaired terrestrial infrastructure (Solarlink, 2018).

_Starlink_ from SpaceX stands out with its expansive fleet of 4000 satellites catering to 2M+ subscribers across 63 countries (Solarlink, 2018; Wang et al., 2018). The LEO operator plans to further amplify its coverage and quality of service (QoS) by launching \(\approx\) 42,000 additional satellites in the coming years (Solarlink, 2018). However, despite significant global interest and the potential to impact the existing Internet ecosystem, only limited explorations have been made within the research community to understand Starlink's performance. The challenge stems from a lack of global vantage points required to accurately gauge the network's performance since factors such as orbital coverage, density of ground infrastructure, etc., can impact connectivity across regions. Initial studies have resorted to measurements from a handful of geographical locations (Solarlink, 2018; Wang et al., 2018; Wang et al., 2018) or extrapolated global performance through simulations (Solarlink, 2018) and emulations (Solarlink, 2018). However, the community agrees on the limited scope of such studies and has made open calls to establish a global LEO measurement testbed to address this challenge (Solarlink, 2018; Wang et al., 2018; Wang et al., 2018). Some researchers have navigated around this hurdle by exploring alternative measurement methods, e.g., by targeting exposed services behind user terminals (Zhou et al., 2017) or by mining speed test reports shared on social media platforms, such as Reddit (Reddit, 2018). While innovative, we argue that these techniques are insufficient to uncover the intricacies affecting the network, specifically its capability to support web applications.

This paper addresses this knowledge gap and provides the first comprehensive multi-faceted measurement study on Starlink. Our work is distinct from previous works in several ways. Firstly, we examine the global evolution of the network since 2021 by analyzing the M-Lab speed test measurements (Wang et al., 2018) from 34 countries (largest so far). We complement our investigation through active measurements over 98 RIPE Atlas (Solarlink, 2018) probes in 21 countries and conduct high-resolution experiments over controlled terminals in two European countries to investigate real-time web application performance and factors impacting Starlink's last-mile access. Specifically, we make the following contributions.

**(1)** We present a longitudinal study of global Starlink latency and throughput performance from M-Lab users in SS4. Our analysis, incorporating \(\approx\) 19.2 M samples, reveals that Starlink performs competitively to terrestrial cellular networks. However, its performance varies globally due to infrastructure deployment differences, and is dependent on the density and closeness of ground stations and Point-of-Presence (PoP). We also observe signs of _bufferbloating_ as Starlink's latency increases by several factors under traffic load.

**(2)** We assess and compare the performance of real-time web applications, specifically Zoom video conferencing and Amazon Luna cloud gaming, to terrestrial networks (SS5). We find that, under optimal conditions, Starlink is capable of supporting such applications, matching the performance over cellular; however, we do observe some artifacts due to the network's periodic reconfigurations.

**(3)** We perform targeted measurements from Starlink RIPE Atlas (Solarlink, 2018) probes and leverage their diverse locations to characterize the satellite last-mile "bent-pipe" performance (SS6.1). We find that the "bent-pipe" latency within the dense 53' shell remains consistent worldwide (\(\approx\) 40 ms), and is significantly lower to yet incomplete 70' and 97.6' orbits. We also find evidence of Starlink inter-satellite links (ISLs) connecting remote regions, showcasing superior performance to terrestrial paths in our case study.

**(4)** Our high-frequency measurements from terminals in two European countries confirm that Starlink performs network reconfigurations every 15s, leading to noticeable latency and throughput degradations at sub-second granularity. By correlating data from our terminals, one covered by 53' and the other restricted to 70' and 97.6' connectivity, we find that the reconfigurations are globally synchronized events and likely independent of satellite handovers.

Leveraging multi-dimensional, global, and controlled high resolution measurements, our findings distinctively advance the state-of-the-art by illuminating Starlink's global performance and the

## 2. Background

Starlink is a LEO satellite network operated by SpaceX that aims to provide global Internet coverage through a fleet of satellites flying at \(\approx\) 500 km above the Earth's surface. The majority of Starlink's operational 4000 satellites lie within the 53's shell, which only covers parts of the globe (see Figure 1). The 70' and 97.6' orbits allow serving regions near the poles. These other shells however have fewer satellites (see Appendix A, Table 2 for constellation details).

Figure 2 shows the cross-section of Starlink end-to-end connectivity. To access the Internet over the Starlink network, end-users require a dish, a.k.a. "Dishy"1, that communicates with satellites visible above 25's of elevation through phased-array antennas using Ku-band (shown as User Link (UL)). Starlink satellites, equipped with multiple antennas subdivided into beams, can connect to multiple terminals simultaneously (Hendy et al., 2016) and relay all connections to a ground station (GS) on a Ka-band link (shown in green). The connection forms a direct "bent-pipe" in case the terminal and GS lie within a single satellite's coverage cone; otherwise, the satellites can relay within space to reach far-off GSs via laser inter-satellite links (ISLs), forming an "extended bent-pipe". Note that not all Starlink satellites are ISL-capable and it is difficult to effectively estimate ISL usage as Starlink satellites have no user visibility at IP layer and, therefore, do not show up in traceroutes.

Footnote 1: We use “Dishy” and “user terminal” interchangeably in the paper.

Finally, the GSs relay traffic from satellites to Starlink point-of-presence (PoP) through a wired connection, which routes it to the destination server via terrestrial Internet (Berg et al., 2016). The public availability of GS deployment information differs across countries. No official source exists, so we rely on crowdsourced data for the geolocations of GSs and PoPs (Sanderson, 2016), which is also shown in Figure 1.

## 3. Measurement Methodology

### Global Measurements

_Measurement Lab (M-Lab)_ M-Lab (Marcourt et al., 2016) is an open-source project that allows users to perform end-to-end throughput and latency speed tests from their devices to 500+ servers in 60+ metropolitan areas (Sanderson, 2016). Google offers M-Lab measurements when a user searches for "speed test" (Sanderson, 2016), serving as the primary source of measurement initiations (Marcourt et al., 2016; Sanderson, 2016; Sanderson, 2016). At its core, M-Lab uses the Network Diagnostic Tool (NDT) (Sanderson, 2016), which measures uplink and downlink performance using a single 10 s WebSocket TCP connection. The platform also records fine-grained transport-level metrics (tcp_info), including goodput, round-trip time (RTT) and losses, along with IP, Autonomous System Number (ASN), and geolocation of both the end-user device and the selected M-Lab server. We identify measurements from the Starlink clients via their ASN (AS14593). The M-Lab dataset includes samples from 59 out of 63 countries where Starlink is operational. We restrict our analysis to ndT measurements, which use TCP BBR and countries with _at least 1000 measurements_, resulting in 19.2 M M-Lab measurement samples from 34 countries. Our analysis chronicles the global Starlink operation from its inception, as the first measurement samples in our dataset are dated to June 2021, which is closely aligned with the launch of Starlink v1.0 & v1.5 satellites (Sanderson, 2016). We find that the M-Lab server selection algorithm assigns the geographically closest server to the estimated client location (Sanderson, 2016), which might not always be optimal for Starlink, given its PoP-centered architecture. While we examine such artifacts by contrasting the M-Lab and RIPE Atlas results (86.1), we approached our analysis with caution, particularly when examining fine-grained region-specific insights.

_RIPE Atlas._ RIPE Atlas is a measurement platform that the networking research community commonly employs for conducting measurements (Sanderson, 2016). The platform comprises thousands of hardware and software probes scattered globally, enabling users to carry out active network measurements such as ping, traceroute, and DNS resolution to their chosen endpoints. In our study, we utilized 98 Starlink RIPE Atlas probes across 21 countries (see Figure 3). Our measurement targets were 145 data centers from _seven_ major cloud providers - Amazon EC2, Google, Microsoft, Digital Ocean, Alibaba, Amazon Lightsail, and Oracle (see Appendix B). The chosen operators represent the global cloud market (Sanderson, 2016; Sanderson, 2016; Sanderson, 2016) and ensure that our endpoints are close to Starlink Pops, which are usually co-located with Internet eXchange Point (IXP) or data center facilities (Sanderson, 2016; Sanderson, 2016). We perform ICMP traceroutes from Atlas probes to endpoints situated on the same or neighboring continent. We extract and track per-hop latencies between Starlink probe terminal-to-GS (identified by static 100.64.0.1 address), GS-to-PoP (172.16/12 address) and PoP-to-endpoint at 2 s intervals (Sanderson, 2016). Additionally, to improve PoP geolocations, we extract semantic location embeddings in reverse DNS PTR entry,

Figure 1. Orbits of three Starlink inclinations and crowdsourced Ground Station (GS) and Point-of-Presence (PoP) locations (Sanderson, 2016). Shaded regions depict Starlink’s service area.

Figure 2. Starlink follows “bent-pipe” connectivity as traffic traverses the client-side terminal, one or more satellites via inter-sat links (ISLs), nearest ground station (GS), ingressing with the terrestrial Internet via a point-of-presence (PoP).

e.g. tata-level3-seattle2.level3.net [(35)]. Our measurements over _ten_ months (Dec 2022 to Sept 2023) resulted in \(\approx\) 1.8 M samples.

### Real-time Web Application Measurements

#### 3.2.1. Zoom Video Conferencing

We experimented with Zoom videoconferencing [(74)] due to its popularity in the Internet ecosystem [(12)] as well as latency and bandwidth-critical operational requirements. We set up a call between two parties, one using a server with access to an unobstructed Starlink dish and high-speed terrestrial fiber over 1 Gbps Ethernet. The other end was on an AWS machine located close to the assigned Starlink PoP. We set up virtual cameras and microphones on both machines, which were fed by a pre-recorded video of a person talking, resulting in bidirectional transmission. Both machines were time-synchronized to local stratum-1 NTP servers and we recorded (and analyzed) Zoom QoS leveraging the open-source toolchain from [(42)] that yields sub-second metrics.

#### Cloud Gaming

We also experiment with cloud gaming due to its demanding high throughput and low delay requirements [(43)]. We leverage the automated system by Ibql et al. [(18)] to evaluate the performance of playing the racing game "The Crew" on the Amazon Luna [(2)] platform. The measurements are based on a customized streaming client that records end-to-end information about media streams, such as frame and bitrate. The system also utilizes a bot that executes in-game actions at pre-defined intervals that trigger a predictable and immediate visual response. In post-processing, their analysis system detects the visual response and computes the _game delay_ as the time passed since the input action was triggered. Amazon Luna serves games at a resolution of up to 1920\(\times\)1080 at 60 FPS and adaptively reduces the resolution to, e.g., 1280\(\times\)720. We ran the game streaming client on the same machine as the Zoom measurements, additionally setting up a 5G modem to compare Starlink against cellular network. Similar to Zoom, the Luna game server was on AWS server close to our Starlink PoP (\(\approx\) 1 ms RTT).

#### 3.2.2. Satisfiable

A significant limitation of our global measurements is their lack of sub-second visibility, which is essential for understanding the intricacies of Starlink network behavior. To allow us to obtain microscopic understanding, we orchestrated a set of precise, tailored, and controlled experiments, utilizing two Starlink terminals as vantage points (VPs) situated in two European countries. One connects to the 53" shell while the other, deployed in a high latitude location, can be shielded to confine its communication to the 70" and 97.6" orbits (see Figure 4). We placed a metal sheeting2 barrier at the Southfacing angle of the terminal, which obstructed its view from the 53" inclinations. We verify with external satellite trackers [(28; 54)] that the terminal only received connectivity from satellites in 97" or 70" inclinations, which resulted in brief _connectivity windows_ followed by periods of no service. We performed experiments using the Isochronous Round-Trip Tester (irtt) [(52)] and iperf [(17)] tools. The irtt setup records RTTs at high resolutions (3 ms interval) by transmitting small UDP packets. The irtt servers were deployed on cloud VMs in close proximity to the assigned Starlink PoP of both VPs (within 1 ms) - minimizing the influence of terrestrial path on our measurements. We used iperf to measure both uplink and downlink throughput and record performance at 100 ms granularity. Simultaneously, we polled the gRPC service on each terminal [(61)] every second to obtain the connection status information.

Footnote 2: Metal sheeting was chosen due to its ability to act as a Faraday shield, blocking the RF emissions from satellites.

## 4. Global Starlink Performance

We use the minimum RTT (minRTT) reported during nd7 tests to the closest M-Lab server globally to quantify the baseline network performance. This metric is not affected by queuing delays prevalent during throughput measurements which results in elevated latencies. To put the Starlink latency into context, we select speedtests originating from terrestrial serving-ISPs to capture mobile network traffic. We filter measurements from devices connected to the top-3 mobile network operators (MNOs) in each country (see Appendix C for details). Note that our criterion results in a mix of wired and wireless access networks since M-Lab does not provide a way to distinguish between the two. Our endpoint selection remains the same for both Starlink and terrestrial networks (see SS3.1).

#### Global View

Figure 5 shows that, for a majority of countries, clients using terrestrial ISPs experience better latencies over Starlink. While the median latency of Starlink hovers around 40-50 ms in most countries, this distribution varies significantly across geographical regions. For instance, in Colombia, Starlink clients report better latencies than those utilizing established terrestrial networks. Conversely, in Manila (The Philippines), Starlink's performance is notably inferior (Figure 6). The uneven distribution of GSs and PoPs (Figure 1) may explain the latency differences; the USA, which experiences significantly lower latencies, also boasts a robust ground infrastructure. Similar trends are seen in Kenya and Mozambique, where the closest PoP is located in Nigeria.

Figure 4. Field-of-view experiment setup. Dishy, deployed at a high latitude location, is obstructed by a metal shielding, which restricts its connectivity to the 70° and 97.6° orbits.

Figure 3. Overview of global Starlink measurements in this study. Heatmap denotes M-Lab speedtest measurement densities. Starlink RIPE Atlas probes are shown as red circles.

_Well-Provisioned Regions._ Even though a significant portion of global Starlink measurement samples originate from Seattle (\(\approx 10\%\)), the region shows consistently low latencies, with the 75th percentile well below 50 ms (Figure 6). Contributing factors can be dense GS availability or internal service prioritization for Starlink's headquarters. However, we observe that Starlink performance is fairly consistent across the USA, confirming that Seattle is not an anomaly but the norm (see Figure 21a in Appendix D). This result highlights the LEO network's potential to bridge Internet access disparities, which significantly affects the quality of terrestrial Internet in the USA (Song et al., 2018; Zhang et al., 2019). Europe is also relatively well covered with GSs but hosts only three PoPs that are in the UK, Germany, and Spain. Proximity to the nearest PoP correlates strongly with minRTT performance in Figure 7 - Dublin, London, and Berlin exhibit latencies comparable to the US, while for Rome and Paris, the 75th percentile is \(\approx 20\) ms longer. Unlike US, Starlink in EU has significantly longer tail latencies, often surpassing 100 ms.

_Under-Provisioned Regions._ Starlink's superior performance in Colombia hints at its potential for connecting under-provisioned regions. However, Figure 6 shows that Starlink in South America (SA) trails significantly behind the US and Europe, with the 75th percentile exceeding 100 ms and tail at 200 ms. We observe similar performances in Oceania (see Figure 21b in Appendix D). By extracting the share of satellite vs. terrestrial path (from PoP to M-Lab servers, see Figure 18 in Appendix D)3, we find that the majority of SA Starlink latency comes from the bent-pipe. In contrast, latencies from Mexico and Africa (except Nigeria) show significant terrestrial influence, which we allude to non-optimal PoP assignments by Starlink routing policies.

Footnote 3: We subtract the latency to the Starlink PoP reported by M-Lab’s reverse traceroutes from the end-to-end TCP minRTT.

We observed an interesting impact of ground infrastructure deployment in the Philippines, where a local PoP was deployed in May 2023. Prior to this, Starlink traffic from the Philippines was directed to the nearest Japanese PoP, traversing long submarine links to reach the geographically closest M-Lab server in-country - evident from Figure 19 in Appendix D which shows additional 50-70 ms RTT incurred by Philippine users to reach in-country vs. Japanese M-Lab servers. However, post-May 2023, the latencies to

Figure 8. RTT inflation (maxRTT) during M-Lab speedtests over Starlink: (a) download, (b) upload traffic.

Figure 7. Distributions of M-Lab minRTTs from select cities in Europe and South America, respectively.

average goodputs. Given its high measurement density at this location, this trend might be attributable to Starlink's internal throttling or load-balancing policies aimed at preventing congestion on the shared network infrastructure (Safania et al., 2017). We also find that over the past 17 months, Starlink goodputs have stabilized rather than increased, with almost all geographical regions demonstrating similar performance (shown in Figure 23 in Appendix D).

_Takeaway \(\pi 1\)_ -- Starlink exhibits competitive performance to terrestrial ISPs on a global scale, especially in regions with dense GS and PoP deployment. However, noticeable degradation is observable in regions with limited ground infrastructure. Our results further confirm that Starlink is affected by bufferbloat. Over the past 17 months, Starlink appears to be optimizing for consistent global performance, albeit with a slight reduction in goodput, likely due to the increasing subscriber base.

## 5. Real-Time Application Performance

While the global Starlink performance in SS4 is promising for supporting web-based applications, it does not accurately capture the potential impact of minute network changes caused by routing, satellite switches, bufferbloating, etc., on application performance. Real-time web applications are known to be sensitive to such fluctuations (Boon and Amazon Luna, 2010; Safania et al., 2017; Safania et al., 2017). In this section, we examine the performance of Zoom and Amazon Luna cloud gaming over Starlink (see SS3.2 for details). This allows us to assess the suitability of the LEO network to meet the requirements of the majority of real-time Internet-based applications, as both applications impose a strict latency control loop. Cloud gaming necessitates high downlink bandwidth, while Zoom utilizes uplink and downlink capacity simultaneously.

_Zoom Video Conferencing._ Figure 10 shows samples from Zoom calls conducted over a high-speed terrestrial network and over Starlink. The total uplink throughput over Starlink is slightly higher, which we trace to FEC (Forward Error Correction) packets that are frequently sent in addition to raw video data (on average 146+-99 Kbps vs. 2+-2 Kbps over terrestrial). The frame rate, inferred from the packets received by the Zoom peer, does not meaningfully differ between the two networks (\(\approx\) 27 FPS). Note that, since Zoom does not saturate the available uplink and downlink capacity, it should not be impacted by bufferbloating. Yet, we observe a slightly higher loss rate over LEO, which the application combats by proactively utilizing FEC. The uplink one-way delay (OWD) over Starlink is higher and more variable compared to the terrestrial connection (on average 52+-14 ms vs. 27+-7 ms). All observations also apply to the downlink except that Starlink's downlink latency (35+-11 ms) is similar to the terrestrial connection (32+-7 ms). Our analysis broadly agrees with (Safania et al., 2017) but our packet-level insight reveals bitrate functions partly caused by FEC. Further, our Starlink connection was more reliable and we did not experience second-long outages.

Interestingly, we observe that the Starlink OWD often noticeably shifts at interval points that occur at 15 s increments. Further investigation reveals the cause to be the Starlink _reconfiguration interval_, which, as reported in FCC filings (Safania et al., 2017), is the time-step at which the satellite paths are reallocated to the users. Other recent work also reports periodic link degradations at 15 s boundaries in their experiments, with RTT spikes and packet losses of several orders (Safania et al., 2017; Safania et al., 2017; Safania et al., 2017). We explore the impact of reconfiguration intervals and other Starlink-internal actions on network performance in SS6.

_Amazon Luna Cloud Gaming._ Table 1 shows 150 minutes of cloud gaming performance over terrestrial, 5G cellular, and Starlink networks. Overall, all networks realized close to 60 FPS playback rate at consistently high bitrate (\(\approx\) 20 Mbps). Starlink lies in between the better-performing terrestrial and cellular in terms of bitrate fluctuations, frame drops and freezes4. Starlink exhibits the highest

\begin{table}
\begin{tabular}{l r r r} \hline \hline  & Terrestrial & Cellular & Starlink \\ \hline Idle RTT (ms) & 9 & 46 & 40 \\ Throughput (Mbps) & 1000 & 150 & 220 \\ \hline Frames-per-second & 59\(\pm\)1.51 & 59\(\pm\)1.68 & 59\(\pm\)1.63 & 27 \\ Bitrate (Mbps) & 23.08\(\pm\)0.38 & 22.82\(\pm\)2.42 & 22.81\(\pm\)2.16 & 52 \\ Time at 1080p (\%) & 100 & 94.11 & 99.45 & 29 \\ Freezes (ms/min) & 0\(\pm\)0 & 0.42\(\pm\)20.34 & 0\(\pm\)11.94 & 33 \\ Inter-frame (ms) & 17\(\pm\)3.65 & 18\(\pm\)11.1 & 16\(\pm\)6.76 & 51 \\ \hline Game delay (ms) & 133.53\(\pm\)19.79 & 165.82\(\pm\)23.55 & 167.13\(\pm\)23.12 & 52 \\ RTT (ms) & 11\(\pm\)11.41 & 39\(\pm\)1.76 & 50\(\pm\)16.28 & 53 \\ Jitter buffer (ms) & 15\(\pm\)3.27 & 12\(\pm\)1.33 & 15\(\pm\)3.35 & 53 \\ \hline \hline \end{tabular}
\end{table}
Table 1. The game metrics are aggregated over 150 minutes of playtime per connection. Values denote median\(\pm\)SD and the worst performer is highlighted.

Figure 11. Cloud gaming over 5G (left) and Starlink (right). Vertical dashed lines show Starlink reconfiguration intervals.

Figure 10. Uplink Zoom video traffic over a terrestrial network (left) and Starlink (right). Vertical dashed lines show Starlink reconfiguration intervals.

Figure 9. Distribution of median (a) download and (b) upload goodput over Starlink from selected cities globally.

game delay, i.e., the delay experienced by the player between issuing a command and witnessing its effect. Specifically, the wired network delivers the visual response about 2 frames (\(\approx 33\) ms) earlier than both 5G and Starlink. While examining the gaming performance over time, we observe occasional drops to \(<20\) FPS over Starlink (see Figure 11), that coincide with Starlink's reconfiguration interval. These fluctuations are only visible at sub-second granularity and, hence, are not reflected in global performance analysis (SS4).

Despite these variations, Starlink's performance remains competitive with 5G, highlighting its potential to deliver real-time application support, especially in regions with less mature cellular infrastructure. Note, however, that our Starlink terminal was set up without obstructions and the weather conditions during measurements were favorable to its operation (Sarlink, 2017). Different conditions, especially mobility, may change the relative performance of Starlink and cellular, which we plan to explore further in the near future.

_Takeaway_\(\approx\)2 -- Starlink is competitive with the current 5G deployment for supporting demanding real-time applications. We also observe that Starlink experiences regular performance changes every 15s linked to its reconfiguration interval period. While these internal black-box parameters do influence performance to a certain extent, application-specific corrective measures, like FEC, are effective in mitigating these artifacts.

## 6. Dissecting the Bent-Pipe

We now attempt to uncover Starlink's behind-the-scenes operations and their impact on network performance. We follow a two-pronged approach to undertake this challenge. Our longitudinal traceroute measurements over RIPE Atlas accurately isolate the bent-pipe (terminal-to-PoP) global performance, allowing us to correlate it with parameters like ground station deployment, satellite availability, etc. (SS6.1). We then perform high-frequency, high-resolution experiments over Starlink terminals deployed in two EU countries to zoom in on bent-pipe operation and highlight traffic engineering signatures that may impact application performance (SS6.2).

### Global Bent-Pipe Performance

_Starlink vs. Cellular Last-mile_ We contrast our end-to-end M-Lab and real-time application analysis by comparing the Starlink bent-pipe latencies from RIPE Atlas traceroutes to cellular wireless last-mile (device-to-ISP network) access. Given the underrepresentation of cellular probes in RIPE Atlas, we augment our dataset with recent comprehensive measurements from Dang et al. (2018), which leveraged 115,000 cellular devices over the Speedchecker platform to analyze the performance of cellular networks worldwide. Figure 12 presents a comparative analysis of both networks across countries common in both datasets. Consistent with our previous findings, we find that the Starlink bent-pipe latencies fall within 36-48 ms, with the median hovering around 40 ms for almost all countries. Similarly, we find consistent cellular last-mile latencies across all countries, but almost 1.5\(\times\) less than Starlink. Recent investigations (Sarlink, 2017) report similar access latencies over WiFi and cellular networks. The bent-pipe latencies also corroborate our estimations in SS4 that the terminal-PoP path is the dominant contributor to the end-to-end latency. Out of the 21 countries with Starlink-enabled RIPE Atlas probes, the only exceptions where the bent-pipe latency is significantly higher (\(\approx\) 100 ms) are the Virgin Islands (US), Reunion Islands (FR), and Falkland Islands (UK). Correlating with Figure 3, we find that Starlink neither has a GS nor a PoP in these regions, which may result in traffic routing over ISLs to far-off GS leading to longer bent-pipe latencies.

_Impact of Ground Infrastructure._ We extend our analysis by exploring the correlation between the distance from Starlink users to the GS and bent-pipe latencies. Recall that we rely on crowd-sourced data (Sarlink, 2017) for geolocating Starlink ground infrastructure since these are not officially publicly disclosed. We deduce through our traceroutes that Starlink directs its subscribers to the nearest GS relative to the PoP, as the GS-PoP latencies are \(\approx 5\) ms almost globally (see Figure 22 in Appendix D - sole exceptions being US and Canada with 7-8 ms, likely due to abundant availability of GSs and PoPs resulting in more complex routing). Figure 13 shows the correlation of reported bent-pipe latency with the terminal-GS distance. Each point in the plot denotes at least 1000 measurements. We observe a directly proportional relationship as bent-pipe latencies tend to increase with increasing distance to the GS. Furthermore, we find that the predominant distance between GS and the user terminal is \(\leq\) 1200 km, which is also the approximate coverage area width of a single satellite from 500 km altitude (Brockman et al., 2016) - suggesting that these connections are likely using direct bent-pipe, either without or with short ISL paths. Few terminals, specifically in Reunion, Falkland and the Virgin Islands, connect to GSs significantly farther away, possible only via long ISL chains, the impact of which we analyse further as a case study below.

_Case Study: Reunion Island._ The majority of Starlink satellites (starting from v1.5 deployed in 2021) are equipped with ISLs (Sarlink, 2017), and reports from SpaceX suggest active utilization of these links (Sarlink, 2017). Recent studies also agree with the use of ISLs (Sarlink, 2017), but point out inefficiencies in space routing (Sarlink, 2017). Nonetheless, the invisibility of satellite hops in traceroutes poses a challenge in accurately assessing the latency impact of ISLs. As such, we focus on a probe in Reunion Island (RU), which connects to the Internet via Frankfurt PoP (\(\approx\) 9000 km). Figure 14 segments the bent-pipe RTT between

Figure 12. Last-mile latencies for different countries. “Starlink” denotes satellite bent-pipe over RIPE Atlas while “Cellular” wireless access from Speedchecker (2017).

Figure 13. Correlation between Starlink bent-pipe latency and Dishy-GS distance. Red line denotes linear regression fit.

the user terminal (Dishy) to GS (non-terrestrial), and from GS to the PoP (terrestrial). For comparison, we also plot the RTTs from a probe within Germany (DE) connecting to the same PoP (\(\approx 500\) km, in red). The vertical lines represent the median RTT over terrestrial infrastructure from both probe locations to the PoP. Firstly, we observe minimal GS-PoP latency for both locations, verifying that the RU satellite link is using ISLs. Secondly, in RU, Starlink shows significant latency improvement over fiber (\(\approx 60\) ms). This is because the island has limited connectivity with two submarine cables routing traffic 10,000 km away, either in Asia or South America (Santzik et al., 2018). Starlink provides a better option by avoiding the terrestrial route altogether, directly connecting RU users to the dense backbone infrastructure in EU (Brocker et al., 2018). However, since the bent-pipe incurs at least 30-40 ms latency in the best-case, Starlink is less attractive in regions with robust terrestrial network infrastructure (also evident from the DE probe where fiber achieves better latencies).

_Impact of Serving Orbit._ Recall that the majority of Starlink satellites are deployed in the 53' inclination (see Table 2 in Appendix A). Consequently, network performance for clients located outside this orbit's range may vary widely as they are serviced by fewer satellites in \(70^{\circ}\) and \(97.6^{\circ}\) orbits. Figure 15 contrasts the bent-pipe latencies of probe in Alaska (61.5685N, 149.0125W) ["A"] to probes within 53' orbit. Despite dense GS availability, the bent-pipe latencies for Alaska are significantly higher (\(\approx 2\times\)). The Swedish probe ["B"] at 59.6395N is at the boundary of 53' orbit but still exhibits comparable latency to Canada, UK, and Germany. Furthermore, the Alaslan probe experiences intermittent connectivity, attributed to the infrequent passing of satellite clusters within the \(70^{\circ}\) and \(97.6^{\circ}\) orbits. These findings indicate substantial discrepancies in Starlink's performance across geographical regions, which may evolve for the better as more satellites are launched in these orbits. Nevertheless, we leverage the sparse availability of satellites at the higher latitude to further dissect the bent-pipe operations in SS6.2.

_Takeaway \(\approx\)3_ - The Starlink "bent-pipe" accounts for (on average) 40 ms of latency almost consistently globally. In certain cases where ISLs are being used, the latencies might escalate yet still outshine traditional terrestrial networks when bridging remote regions. The satellite link yields stable latencies, provided that the client is served by the dense 53' orbit.

### Controlled Experiments

We now investigate the cause of periodic disruptions to real-time applications (SS5). Specifically, we perform high-resolution measurements to gain insights into Starlink network operation.

_Global Scheduling._ We performed simultaneous iRTT measurements from two countries that are sufficiently geographically removed that both cannot be connected to the same serving satellite. We also verify that both terminals are assigned different PoPs located within their country. The resulting RTTs, shown in Figure 16a, vary in a consistent pattern, being comparatively stable within each Starlink reconfiguration interval but potentially changing significantly between intervals. Moreover, the time-wise alignment of reconfiguration intervals for both vantage points indicates that Starlink operates on a globally coordinated schedule, rather than on a per-Dishy or per-satellite basis. These results are in line with other recent studies (Santzik et al., 2018), which also hint that Starlink utilizes a global network controller. Previous studies (Santzik et al., 2018) have noticed drops in downlink throughput every 15s but have not correlated these with the reconfiguration intervals. We also observe throughput drops on both downlink and uplink, shown in Figure 16b, that occur at the reconfiguration interval boundaries. Similar to the RTT, the throughput typically remains relatively consistent within an interval, but can experience sudden changes between interval transitions. These also corroborate the periodic performance degradation in our real-time application experiments.

_Disproving Satellite Handoff Hypothesis._ Previous works have suggested satellite or beam changes at reconfiguration interval boundaries to be the root-cause of network degradation (Santzik et al., 2018; Santzik et al., 2018; Santzik et al., 2018). To investigate this hypothesis, we deliberately obstructed the field-of-view of our high latitude Dishy to prevent it from connecting to the dense 53' orbital shell (see SS3.3 for details). The restriction curtailed the number of candidate (potentially connectable) satellites to 13%. This limitation led to intermittent connectivity, characterized by brief connectivity windows with long service downlines. By synchronizing the timings of each connectivity window with the overhead positions of candidate satellites (from CelesTrak (2018) and other sources (CelesTrak, 2018)), we identify several windows where the terminal can be served only by a single satellite. Figure 16c (upper) shows RTTs from one such window. The fact that there is significant RTT variance between intervals invalidates the hypothesis that the changes in RTT are caused by satellite handovers (considering a single candidate satellite during the observed period, leaving no room for hand-off occurrences). Separately, we perform the same experiment but focus on (both uplink and downlink) throughput. Similar to RTT, we also witness throughput drops at interval boundaries even when only one candidate satellite is visible.

_Scheduling Updates._ Figure 16c (lower) shows the distribution of start and end times of the connectivity windows during our restricted field-of-view experiments. We observed a strong correlation between connectivity end times and reconfiguration interval

Figure 14. Bent-pipe RTT segments from Reunion Island (yellow) vs. Germany (red) connecting to Germany PoP. Vertical lines show latency over Atlas probes connected via fiber from both locations to the Frankfurt server (PoP location).

Figure 15. Bent-pipe latencies for “A” (in Alaska) covered by the 70’ and 97.6’ while the rest (Sweden “B”, Canada “C”, UK “D”, and Germany “E”) are also covered by 53’.

(RI) boundary, which is not seen with start times5. The result hints at internal network scheduling changes at reconfiguration interval boundaries, i.e., Starlink assigns its terminals new satellites (or frequencies) every 15s. We hypothesize that with an obstructed view, the scheduler cannot find better alternatives in the 70' and 97.6' orbits, resulting in connectivity loss at the end of the window.

Footnote 5: The fact that many appear to end is after the boundary is an artifact of the limited (per-second) granularity of the gRPC data and that the gRPC timestamps originate from the client making the gRPC requests rather than the user terminal.

_Analysis Summary._ Putting together our various observations, we theorize that Starlink relies on a global scheduler that re-allocates the user-satellite(s)-GS path every 15s. An FCC filing from Starlink implies this behavior (Gilton et al., 2016) and recent studies also suggest that the LEO operator performs periodic load balancing at reconfiguration boundaries, reconnecting all active clients to satellites (Zhou et al., 2016; Zhou et al., 2016). The theory also explains our observed RTT and throughput changes when only a single candidate satellite is in view. It is plausible that Starlink may have rescheduled the terminal to the same satellite but with reallocated frequency and routing resources. Regardless, these reconfigurations result in brief sub-second connection disruptions, which may become more noticeable at the application-layer as the number of subscribers on the network increases over time.

_Takeaway \(\neq\)4_ -- Starlink uses 15s-long reconfiguration intervals to globally schedule and manage the network. Such intervals cause latency/throughput variations at the interval boundaries. Handoffs between satellites are not the sole cause of these effects. Indeed, our findings hint at a scheduling system reallocating resources for connections once every reconfiguration interval.

## 7. Related Work

LEO satellites have become a subject of extensive research in recent years, with a particular focus on advancing the performance of various systems and technologies. Starlink, the posterchild of LEO networks, continues to grow in its maturity and reach with \(>2\)M subscribers as of September 2023 (Selig et al., 2020). Despite its growing popularity, there has been limited exploration into measuring Starlink's performance so far. Existing studies either have a narrow scope, employing only a few vantage points (Gilton et al., 2016; Gilton et al., 2016; Gilton et al., 2016) or focus on broad application-level operation (Zhou et al., 2016; Gilton et al., 2016) without investigating root-causes. Ma et al. (2016) embarked on a journey across Canada with four dishes to scrutinize various factors, such as temperature and weather, that might influence Starlink's performance.

A few endeavors have attempted to unveil the operations of Starlink's black-box network. Pan et al. (Pan et al., 2016) revealed the operator's internal network topology from traceroutees, whereas Tanveer et al. (Tanveer et al., 2016) spotlighted a potential global network controller. The absence of global measurement sites poses a predominant challenge hampering a comprehensive understanding of Starlink's performance. As we show in this work, Starlink's performance varies geographically due to differing internal configurations and ground infrastructure availability. Some researchers have devised innovative methods to combat this. For example, Izhikevich et al. (Izhikevich et al., 2016) conducted measurements towards exposed services behind the Starlink user terminal, while Taneja et al. (Taneja et al., 2016) mined social media platforms like Reddit to gauge the LEO network's performance. Our study not only corroborates and extends existing findings but also stands as the most extensive examination to date. Our approach - anchored in detailed insights from 34 countries, leveraging 19.2 million crowdsourced M-Lab measurements, 2.9 million active RIPE Atlas measurements, and two controlled terminals connecting to different Starlink orbits - provides a deeper understanding of the Starlink "bent-pipe" and overall performance.

## 8. Conclusions

Despite its potential as a "global ISP" capable of challenging the state of global Internet connectivity, there have been limited performance evaluations of Starlink to date. We conducted a multi-faceted investigation of Starlink, providing insights from a global perspective down to internal network operations. Globally, our analysis showed that Starlink is comparable to cellular for supporting real-time applications (in our case Zoom and Luna cloud gaming), though this varies based on proximity to ground infrastructure. Our case study shows Starlink inter-satellite connections helping remote users achieve better Internet service than terrestrial networks. However, at sub-second granularity, Starlink exhibits performance variations, likely due to periodic internal network reconfigurations at 15s intervals. We find that the reconfigurations are synchronized globally and are not caused only by satellite handovers. As such, this first-of-its-kind study is a step towards a clearer understanding of Starlink's operations and performance as it continues to evolve.

Figure 16. (left, a) iRTT latencies with Dishys in two countries connected to different ground infrastructure; (middle, b) Maximum uplink and downlink throughput over a 195-second (13 interval) period; (right, c) (upper) RTTs for a connectivity window where the Dishy was connected to only a single satellite; (lower) Probability distribution of the time between the connectivity window start / end and the previous reconfiguration interval (RI). Vertical dashed lines show Starlink reconfiguration intervals.

## References

* (1)
* Adams (2012) Richelle Adams. 2012. Active queue management: A survey. _IEEE communications surveys & tutorials_ 15. 3 (2012), 1425-1476.
* Amazon (2003) Amazon. 2003. Lucas Local Gaming. [https://luna.amazon.com/](https://luna.amazon.com/).
* IEEE Conference on Computer Communications_. 79-88. [https://doi.org/10.1109/NICCOM.2000.1955428](https://doi.org/10.1109/NICCOM.2000.1955428).
* Boyle (2019) Alan Boyle. 2019. Amazon to offer broadband access from orbit with 32,356-statile freiot: Superior completion. [http://www.ecsociety.com/2019/amazon-project-tauper-broadband-satellite-](http://www.ecsociety.com/2019/amazon-project-tauper-broadband-satellite-). Accessed: 2023-05-26.
* Amazon (2020) CARIDA. 2020. ASEM Website. [http://arxmak.csidep.org/](http://arxmak.csidep.org/). Accessed: 2023-10.
* Calaj (2021) Shkolen Calaj. 2021. The parameters comparison of the 'Starlink' LEO satellites constellation for different orbital shells. _Frontiers in Communications and Networks_ 2021 (2021), 634905.
* Cao (2021) Case. 2021-00002. 2021. Application of 'Starlink's Services. [https://pcx.fsp/pect/2021-00002/kezips/edge40dallaws/com/10/2021/01581-Application_](https://pcx.fsp/pect/2021-00002/kezips/edge40dallaws/com/10/2021/01581-Application_).
* Dang et al. (2021) J. Dang, Marcos Varvelo, Peng Hao, and Sart Mukherjee. 2021. Can we See the Nov? A Measurement Study of Zoom, Wbres, and Meet. In _Proceedings of the 21st ACM Intract Measurement Conference_ (Virtual Event) (MNC '21) Association for Computing Machinery, New York, NY, USA, 216-228. [https://doi.org/10.1145/3487552.3487847](https://doi.org/10.1145/3487552.3487847)
* Chin et al. (2003) Yi-Ching Chin, Randich Schinker, Abhishek Rajhdashukam, Ethan Katz-Based, and Ramesh Govind. 2003. Are we Hope Trap Avorsion in a Better Internet. In _Proceedings of the 2003 Internet Measurement Conference_ (Tokyo, Japan) (MNC '15) Association for Computing Machinery, New York, NY, USA, 17 pages. [https://doi.org/10.1145/2815675.2815719](https://doi.org/10.1145/2815675.2815719)
* Corneos et al. (2021) Lorenzo Corneos, Maximilen Eder, Nittlour Mohan, Aleksandar Zarodowski, Suzan Belyan, Walter Wong, Per Gunningberg, Jussi Rangasharju, and Jog Ott. 2021. Surrounded by the Cloud: A Comprehensive Cloud Reachability Study. In _Proceedings of the Web Conference_ 2021 (Sublan, Slovenia) (WWW '21) Association for Computing Machinery, New York, NY, USA, 295-304. [https://doi.org/10.1145/3482318.348458](https://doi.org/10.1145/3482318.348458)
* Dang et al. (2021) The Khang Dang, Nittlour Mohan, Lorenzo Corneos, Aleksandar Zarodowski, Jing Cui, and Jussi Rangasharju. 2021. Cloud with a Chance of Short Trick: Analyzing Cloud Convertibility in the Internet. In _Proceedings of the 21st ACM Intract Measurement Conference_ (Virtual Event) (MNC '21) Association for Computing Machinery, New York, NY, USA, 27-29. [https://doi.org/10.1145/3487552.348754](https://doi.org/10.1145/3487552.348754)
* Feldman et al. (2020) Anja Feldmann, Oliver Gasser, Franziska Liichlan, Enric Payi, Ingmar Poese, Christoph Dietterl, Daniel Wagner, Matthias Weichtmuller, Ivan Taylor, Nancy Collins-Rodriguez, Christopher Phelidt, and Georgio Smaragakakis. 2020. The Lookdown Effect: Implications of the COVID-19 Pandemic on Internet Traffic. In _Proceedings of the ACM Internet Measurement Conference_ (Virtual Event, USA) (MNC '20) Association for Computing Machinery, New York, NY, USA, 18-18. [https://doi.org/10.1145/3482318.3482685](https://doi.org/10.1145/3482318.3482685)
* Garcia et al. (2023) Johan Garcia, Simon Sundberg, Giuseppe Caso, and Anna Brunstrom. 2023. Multi-Timescale Evaluation of Starlink Throughput. In _Proceedings of the 1st ACM Workshop on LEO Networking and Communication_ (Madrid, Spain) (LEO-NET '23) Association for Computing Machinery, New York, NY, USA, 31-36. [https://doi.org/10.1145/3482404.3461108](https://doi.org/10.1145/3482404.3461108)
* Gall et al. (2022) Phillipa Gall, Christophe Diot, Li Yi Ohlen, Matt Mathis, and Stephen Soltesz. 2022. M-Lab User Initiated Internet Data for the Research Community. SIGCOMM Comput. Forum, Ser. 52, 1 (mar 2022), 34-37. [https://doi.org/10.1145/352230.3523236](https://doi.org/10.1145/352230.3523236)
* Garcia et al. (2017) Carlo Augusto Garcia, Natale Patricia, Martin Klapper, and Maurizio Canoni. 2017. Mitigating congestion and bufferload on satellite networks through a rate-based AOM. In _2017 IEEE International Conference on Communications (OCC)_. 1-6. [https://doi.org/10.1109/ICDC.2017.7996706](https://doi.org/10.1109/ICDC.2017.7996706)
* Insider (2023) Business Insider. 2023. _Everything we know about Flow Much's Starlink satellites and future internet_. [https://www.businessinsider.com/elon-mask-starlink-](https://www.businessinsider.com/elon-mask-starlink-) satellites-interestAccessed: 2023-10-12.
* Iperl (2023) Iperl. 2023. Iperf / iperfs. [http://perfs.fr/](http://perfs.fr/).
* Bashah et al. (2021) Hassan Bashah, Ayresha Khalid, and Muhammad Shahzad. 2021. Dissecting Cloud Gaming Performance with DEC_. Proc. ACM Meas. Anal. Comput. Syst. 5, 3, Article 31 (dec 2021), 7 pages. [https://doi.org/10.1145/3491043](https://doi.org/10.1145/3491043)
* Iyervan V. Iyer et al. (2022) Ramakrishna Akella, Chen Chen, Phillip E Barber, and Peter J. Worters. 2022. System and method of providing a medium access control schedule. US Patent 11,540,301.
* Izhikevich et al. (2023) Izhikevich, Madan Tran, Katherine Ehlebrecht, Gautam Akwite, and Zarik Plummerz. 2023. Democrising LEO Satellite Network Measurement: arXiv:2306.07449 (cs.NI)
* Jain et al. (2022) Ashish Jain, Derpan Patra, Peijing Xu, Justine Sherry, and Phillipa Gill. 2022. The Ukrainian Internet under Attack: An NDT Perspective. In _Proceedings of the 22nd ACM Internet Measurement Conference_ (NEC, France) (IBC '22). Association for Computing Machinery, New York, NY, USA, 166-178. [https://doi.org/10.1145/3517745.356149](https://doi.org/10.1145/3517745.356149)
* Jayarnik (2023) Amthia Jayarnik and the Russia-Ukraine War: A Case of Commercial Technology and Public Purpose? [https://www.bollefercenter.org/publication/starlink-and-russia-utraine-war-case-commercial-technology/and-public-purpose](https://www.bollefercenter.org/publication/starlink-and-russia-utraine-war-case-commercial-technology/and-public-purpose).
* Jian et al. (2020) Yuling Jian, Mohit Agarwal, Shyam Krishnan Venkateswaran, Yuchen Liu, Douglas M. Houlsen, and Radiumothy Straham. 2020. WiMove: Toward Infrastructure Mobility in MmWave WIP. In _Proceedings of the 18th ACM Symposium on Mobility Management and Wireless Access_ (Allicante, Spain) (Mobi-Wic '20). Association for Computing Machinery, New York, NY, USA, 11-20. [https://doi.org/10.1145/3416102.3426425](https://doi.org/10.1145/3416102.3426425)
* Jiang et al. (2012) Jing, Zeyin Luo, Ziogong Wang, Kyungh Lee, and Injong Rhee. 2012. Understanding Bufferbind in Cellular Networks. In _Proceedings of the 2012 ACM SIGCOMM Workshop on Cellular Networks: Operations, Challenges, and Future Design_ (Helminki, Finland) (_Gellular '11st_). Association for Computing Machinery, New York, NY, USA, 1-6. [https://doi.org/10.1145/2242268.2342470](https://doi.org/10.1145/2242268.2342470)
* Sun et al. (2020) Yuchen Sun, Sandravian Ranganathan, Gaensh Ananthananyananan, Junchen Jiang, Vanella N. Padmanabhan, Manuel Schroder, Matt Calder, and Arvind Krishnamurthy. 2020. Ifforming in on Wile-Alex Lattices in a Global Cloud Provider. In _Proceedings of the ACM Special Interest Group on Data Communication_ (Beijing, China) (_SIGCOMM '2020_). Association for Computing Machinery, New York, NY, USA, 19. [https://doi.org/10.1145/3310423.3243073](https://doi.org/10.1145/3310423.3243073)
* Kasem et al. (2002) Mohamed M. Kasem, Aravindh Raman, Diego Perino, and Nishanth Satury. 2002. A browser-Side View of Starlink Connectivity. In _Proceedings of the 22nd ACM Internet Measurement Conference_ (NEC '22). Association for Computing Machinery, New York, NY, USA, 151-158. [https://doi.org/10.1145/3517745.3516457](https://doi.org/10.1145/3517745.3516457)
* Kasaing et al. (2002) Simon Kasning, Deborah Bhattacher, Andrei Baptista Aguna, Jens Eirk Sastre, and Ashik Singh. 2002. Exploring the Internet from Space with Hypersutia. In _Proceedings of the ACM Internet Measurement Conference_ (Virtual Event), USA (MNC '20). Association for Computing Machinery, New York, NY, USA, 214-229. [https://doi.org/10.1145/3439394.342635](https://doi.org/10.1145/3439394.342635)
* Kabs (2003) Dr. Ts. Skos. 2003. _ClearTuck_. [https://cleartuck.org/](https://cleartuck.org/). Accessed: 2023-10-12.
* Krebs (2021) Gunther Krebs. 2021. Starlink Block v1.0. [https://space.sbrocket.de/doc_sdat/starlink-v1-0.htm](https://space.sbrocket.de/doc_sdat/starlink-v1-0.htm).
* Lag (1988) Measurement Lab. 2023. M-Lab Locate API v2. [https://www.measurementlab.net/de/doc/v2-v2](https://www.measurementlab.net/de/doc/v2-v2).
* Lag (2013) Measurement Lab. 2023. M-Lab to the Cloud. [https://www.measurementlab.net/](https://www.measurementlab.net/).
* Lag (2020) Zelafi, Heavli, H., Vartiago Deng, Qian Wu, Jun Liu, Yuanjie Li, Jihuo Li, Lixin Liu, Weisen Lin, and Jianping Wu. 2023. Starburst: Engineering Research to Evaluate Furnish Integrated Space and Terrestrial Networks. In _20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)_. USENIX Association, Boston, MA, 1309-1324. [https://www.usenix.org/conference/nsdas2/presentation/ia-api](https://www.usenix.org/conference/nsdas2/presentation/ia-api)
* Lag (2010) Ang Li, Xiaowei Yang, Siskundan Kandula, and Ming Zhang. 2010. Cloud-Compressing Public Cloud Providers. In _Proceedings of the 40th ACM SIGCOMM Conference on Internet Measurement_ (Mobure, Australia) (_IMC '10). Association for Computing Machinery, New York, NY, USA, 14 pages. [https://doi.org/10.1145/187914.1879145](https://doi.org/10.1145/187914.1879145)
* Lucide et al. (2012) Matthew Lucide, Bradley Huffaker, Alexander Marzler, Zachary Bischof, Marzantre Fleder, and K Collf. 2012. Learning to Extract Geographic Information from Internet Router Infostances. In _Proceedings of the 17th International Conference on Emerging Networking EXperiments_ (Wireless Personal, Germany) (_CoNEXT '21). Association for Computing Machinery, New York, NY, USA, 404-405. [https://doi.org/10.1145/348958.3449489](https://doi.org/10.1145/348958.3449489)
* Lopez et al. (2012) Melia Lopez, Sebastian Rung, Damaged, Ignacio Rodriguez, and Preben Mogensen. 2012. An Empirical Analysis of Multi-Centricity between SC Terrestrial and IDS-Stellite Networks. In _2012 IEEE GLOBECOM Workshop_ (GC '12). IEEE, 1115-1120. [https://doi.org/10.1109/C.WKUSENSS6602.2021.0008532](https://doi.org/10.1109/C.WKUSENSS6602.2021.0008532)
* Ma et al. (2012) Sami Ma, Yi Ching Chen, Haoyan Zhao, Chong Chen, Xiaodong Ma, and Jiangshuemi Liu. 2022.1-22.8. Network Characteristics of LEO Satellite Constellations: A Starlink-Based Measurement from End Users. (2022-12-28). arXiv:2212.1597 [cs.NI].
* Ma et al. (2012) Tarun Maangl, Udit Paul, Apti Gupta, Nicole P. Marwell, and Nick Feamster. 2022. Internet In theory in Chicago: Aeption, Affordability, and Availability. In _2012 IEEE SENIX_. [https://doi.org/10.1239/smas18290](https://doi.org/10.1239/smas18290).
* Ma (2002) Jonathan C. McDowell. 2002. 2002. _Jonathan's Space. StarlinkStatistics. [https://planet.589.org/content/full/](https://planet.589.org/content/full/). Accessed

[MISSING_PAGE_FAIL:10]

[MISSING_PAGE_FAIL:11]

Figure 21 shows the distribution of the minimum RTT (minRTT) during M-Lab measurements from selected cities in North America and Oceania. It complements Figure 7 that depicts selected cities in Europe and South America. Starlink's performance in North America varies only little between different cities and the latencies are low when compared globally. In Oceania, tests from Auckland and Perth exhibit a similarly low minRTT - a PoP and GSs are nearby both cities. Sydney's minRTT performance has recently (2023/06) improved, as shown in Figure 23a.

## Appendix E Global view of bent-pipe operation

Figure 22 provides additional information about the Starlink last-mile performance analysis presented in SS6.1. The figure shows the latency between Starlink ground stations (GSs) and Points of Presentes (PoPs) on a world map grouped by country. It is apparent that the latencies are similar all over the world (\(\leq\) 6 ms) except in North America (\(\geq\) 6 ms). The anomaly correlates with the dense deployment of GSs and PoPs.

## Appendix F Targeted measurement challenges

Some of the measurements required for Section 6.2 required collection of data during time when Dishy received only patchy connectivity. We discovered that both irtt and iperf did not handle the interrupted nature of the connection well: iperf in particular relies on a separate TCP connection to act as the control plane. Both behaved unpredictably and unreliably on a link that has connectivity only for brief windows. Accordingly, for these experiments, we replaced irtt with piping which we set to send only a single ICMP packet with a 200 ms timeout. We then ran it in a loop.

We were unable to find a suitable replacement for iperf, and therefore relied upon a manual approach. When we detected the start of a connectivity window iperf was started. Once the connectivity window had passed, we stopped the experiment and restarted the iperf server. Restarting the iperf server was necessary to ensure that subsequent iperf tests could connect (iperf3 permits only a single active connection to a server, and a loss of connectivity mid-way through an experiment can leave the server in a state where it believes an experiment is ongoing when it has in fact concluded). Automatically restarting the iperf server at the iperf.

and of each connectivity window was not possible because the Starlink-connected computer, now without an Internet connection, could not signal to the remote iperf server.

An additional challenge caused by the interrupted nature of the connection was not discovered until towards the end of the targeted measurement period. The unstable connection prevented the clock on the computer connected to the Dishy from synchronising over NTP, resulting in it drifting by several seconds duration of the experiment setup. Accordingly, when the absolute timestamps of the recorded data have been analysed, they have first been adjusted to account for the time slip. The gRPC data was collected by a separate computer that did not suffer from clock drift.

Figure 21. The distribution of the minimum RTT (minRTT) during M-Lab measurements from selected cities in North America (a) and Oceania (b).

Figure 22. Global latencies from GSs to PoPs as measured from RIPE Atlas probes.

Figure 23: Evolution of Starlink aggregate goodput ((a), (b)) and minimum RTT (e) during download measurements from cities in South America, North America, Europe, and Australia in the last 12 months.

\begin{table}
\begin{tabular}{c c c c} \hline \hline
**Country** & **Mobile Operator** & **ASN** & **AS Rank [5]** \\ \hline \multirow{3}{*}{Kenya} & Safaricom & AS33771 & 841 & 1869 \\  & Airtel Kenya & AS36926 & 976 & 1569 \\  & Telkom Kenya & AS12455 & 4566 & 1870 \\ \hline Martinique & Digiel & AS48252 & 3508 & 1871 \\ \hline \multirow{3}{*}{Mexico} & AT\&T & AS28469 & 5558 & 1573 \\  & Telcel & AS28403 & 15443 & 1574 \\ \hline \multirow{3}{*}{Mozambique} & Movitel & AS37342 & 12294 & 1539 \\  & mCel & AS36945 & 21048 & 1555 \\ \hline \multirow{3}{*}{Netherlands} & KPN & AS1136 & 747 & 1377 \\  & T-Mobile & AS50266 & 1268 & 1578 \\  & Tele2 & AS13127 & 1413 & 1579 \\ \hline \multirow{3}{*}{New Zealand} & 2degrees & AS9790 & 250 & 1890 \\  & Vodafone & AS9900 & 1924 & 1811 \\  & Spark & AS4771 & 3913 & 1828 \\ \hline \multirow{3}{*}{Nigeria} & MTN & AS29465 & 885 & 1883 \\  & Airtel & AS36873 & 1167 & 1886 \\  & Glo & AS328309 & 23694 & 1885 \\ \hline \multirow{3}{*}{Norway} & Telenor & AS2119 & 255 & 1886 \\  & NextGenTel AS & AS15659 & 4570 & 1887 \\  & TELIA NORGE AS & AS152929 & 7314 & 1588 \\ \hline \multirow{3}{*}{Peru} & Movitar & AS6147 & 1735 & 1580 \\  & Claro & AS12252 & 1741 & 1900 \\  & Entel & AS21575 & 2276 & 1901 \\ \hline \multirow{3}{*}{Philippines} & Globe Telecom & AS13219 & 11910 & 1920 \\  & Smart Communications & AS10139 & 12101 & 1903 \\ \hline \multirow{3}{*}{Poland} & Orange Polska & AS5617 & 136 & 159 \\  & T-Mobile Poland & AS1212 & 175 & 159 \\ \hline \multirow{3}{*}{Portugal} & NOS & AS2860 & 809 & 1997 \\  & MEO & AS15525 & 1329 & 1908 \\  & Vodafone & AS12353 & 1592 & 1908 \\ \hline \multirow{3}{*}{Puerto Rico} & Claro & AS10396 & 1088 & 1609 \\  & Liberty & AS14638 & 1242 & 1602 \\  & T-Mobile & AS21928 & 5435 & 1602 \\ \hline Saint Barthelemy & Digiel & AS3215 & 204 & 1035 \\ \hline \multirow{3}{*}{Spain} & Orange & AS12479 & 332 & 1605 \\  & Vodafone & AS12430 & 358 & 1605 \\  & Movistar & AS3352 & 382 & 1606 \\ \hline \multirow{3}{*}{Sweden} & Tele2 Sweden & AS1257 & 195 & 1407 \\  & Telain Company & AS3301 & 387 & 1608 \\  & Telenor Sweden & AS8642 & 6529 & 1609 \\ \hline \multirow{3}{*}{United Kingdom} & O2 & AS5089 & 505 & 1610 \\  & Vodafone & AS5378 & 5443 & 1611 \\  & EE & AS12576 & 11745 & 1622 \\ \hline \multirow{3}{*}{United States} & T-Mobile & AS21928 & 5435 & 1633 \\  & AT\&T Mobility LLC & AS20057 & 7191 & 1644 \\ \cline{1-1}  & Verizon & AS22394 & 11784 & 163 \\ \hline \hline \end{tabular}
\end{table}
Table 4. The selection of top-3 terrestrial MNOs (mobile network operators) for countries with Starlink M-Lab measurements.