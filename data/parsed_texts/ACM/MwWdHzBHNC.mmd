# Fine-tuning Games:

Bargaining and Adaptation for General-Purpose Models

###### Abstract.

Major advances in Machine Learning (ML) and Artificial Intelligence (AI) increasingly take the form of developing and releasing general-purpose models. These models are designed to be adapted by other businesses and agencies to perform a particular, domain-specific function. This process has become known as _adaptation_ or _fine-tuning_. This paper offers a model of the fine-tuning process where a Generalist brings the technological product (here an ML model) to a certain level of performance, and one or more Domain-specialist(s) adapts it for use in a particular domain. Both entities are profit-seeking and incur costs when they invest in the technology, and they must reach a bargaining agreement on how to share the revenue for the technology to reach the market. For a relatively general class of cost and revenue functions, we characterize the conditions under which the fine-tuning game yields a profit-sharing solution. We observe that any potential domain-specialization will either _contribute, free-ride, or abstain_ in their uptake of the technology, and we provide conditions yielding these different strategies. We show how methods based on bargaining solutions and sub-game perfect equilibria provide insights into the strategic behavior of firms in these types of interactions, and we find that profit-sharing can still arise even when one firm has significantly higher costs than another. We also provide methods for identifying Pareto-optimal bargaining arrangements for a general set of utility functions.

**ACM Reference Format:**

2018. Fine-tuning Games: Bargaining and Adaptation for General-Purpose Models. In _Proceedings of Ghatz sure to enter the correct conference title from your rights recommendation call (Conference account)_. ACM, New York, NY, USA, 15 pages. [https://doi.org/XXXXXXXXXXXX](https://doi.org/XXXXXXXXXXXX)

1
Footnote 1: [https://doi.org/XXXXXXXXXXXX](https://doi.org/XXXXXXXXXXXX)

2
Footnote 2: [https://doi.org/XXXXXXXXXXXX](https://doi.org/XXXXXXXXXXXX)

3
Footnote 3: [https://doi.org/XXXXXXXXXXXX](https://doi.org/XXXXXXXXXXXX)

## 1. Introduction

Generative machine-learning (ML) models have garnered a great deal of excitement because they are considered to be _general purpose_(Bargaining and Ross, 2016; Goodfellow et al., 2016; Goodfellow et al., 2016; Goodfellow et al., 2016; Goodfellow et al., 2016). Some have referred to these technologies as _foundation models_(Goodfellow et al., 2016; Goodfellow et al., 2016) because they are designed as massive, centralized models that support potentially many downstream uses. For example, Bommasani et al.(Bommasani et al., 2016) write, "a foundation model is itself incomplete but serves as the common basis from which many task-specific models are built via adaptation."

There is palpable excitement about these technologies. But to turn their potential into actual use and impact, one needs to specialize and tweak the technology to particular application domains. This process takes various names, including _adaptation_(Kirkpatrick et al., 2017) and, in some contexts, _fine-tuning_(Kirkpatrick et al., 2017; Goodfellow et al., 2016; Goodfellow et al., 2016).

Notably, the process of fine-tuning a technology involves multiple parties. Technology teams developing ML and Artificial Intelligence (AI) technologies rely on outside entities to adapt, tweak, transfer, and integrate the general-purpose model. This dynamic suggests a latent strategic interaction between producers of a foundational, general-purpose technology and specialists considering whether and how to adopt the technology in a particular context. Understanding this interaction is necessary to study the social and economic consequences of introducing the technology.

This paper brings methods from economic theory to model and analyze the fine-tuning process. We put forward a model of fine-tuning where the interaction between two agents, a generalist and a specialist, determines how they'll bring a general-purpose technology to market (Figure 1). The result of this interaction is a domain-adapted product that offers a certain level of _performance_ to consumers, in exchange for a certain level of surplus revenue for the producers. Crucially, the producers must decide how to distribute the surplus, and engage in a bargaining process to do so. An immediate intuition might be to divide this surplus based on contribution to the technology -- however, this is one of many potential bargaining solutions, each with different implications for the technology's performance and the distribution of utility. For example, splitting based on contribution can yield a worse-performing technology compared to other bargaining arrangements.

Through this analysis, we discover several general principles that apply not just to today's generative machine learning technologies, but to a potentially wide swath of models that exhibit a similar structure -- i.e., developed for general use and adapted to one or more domains. Thus, even as these technologies improve and develop, our proposed model of fine-tuning may continue to describe how they may be adapted for real-world use(s).

Further, as we'll discuss, some of our findings apply to other general-purpose technologies outside machine learning context. For example, cloud computing infrastructure enables a number of consumer-facing services that use web hosting, database services, and other on-demand computing resources. Additive manufacturing (e.g., 3D printing) requires the production of a general-purpose technology that other entities use to create valuable products in particular domains. Digital marketplaces, too, are general market-making technologies that enable specialists (vendors) to sell goods, subject to a bargaining agreement over surplus.

Our main conceptual contribution is modeling the fine-tuning process as a combination of 1) a **multi-stage game** and \(2)\)**a bargaining process** between a general-purpose technology producer and one or more domain specialist(s). Both players bargain over how to share revenue, and each takes a turn contributing to the technology's performance before it reaches the market. Within the set of Pareto-optimal bargaining agreements, we introduce a number of _bargaining solutions_ that represent potential arrangementsfor how entities involved in AI's development should distribute profit and effort. These bargaining solutions can be thought of as normative proposals for how to appropriately distribute welfare.

A significant, high-level take-away from our analysis is a characterization of the specialist fine-tuning strategy for any particular domain. We find that any potential adaptor of a technology falls into one of three groups: **Contributors,** who invest effort before selling the technology; **Free-riders,** who sell the technology without investing any additional effort; and **Abstainers,** who do not enter any fine-tuning agreement and opt not to bring the technology to their particular domain. It turns out, using only marginal information about a domain (0th- and 1st-order approximations of cost and revenue), it is possible to reliably determine which strategy the adaptor will take for a notably broad set of scenarios and cost and revenue functions (Section 4.1).

Our analysis consists in deriving the subgame perfect equilibrium strategies, identifying the set of Pareto-optimal bargaining agreements, and then solving for various bargaining solutions proposed by economists. Even in the presence of significant cost differentials, we find bargaining leads to profit-sharing agreements because specialists can leverage their power to exit the deal, reducing the reach of the technology - or, in the case of one specialist, preventing the technology from being produced altogether. For fine-tuning games with a somewhat general set of cost and revenue functions, we develop a method for identifying Pareto-optimal bargains. We find that the Pareto-optimal set is a single interval when there is only one specialist, but may be multiple disjoint intervals in the multi-specialist generalization. The potentially disjoint set arises in cases with multiple specialists because a bargaining deal might be reached with some subset of domain specialists while others abstain.

Some have suggested that scholarship on AI and data-driven technologies focuses predominantly on the technical developments without situating these developments in political economy (though notable exceptions exist) (Bahdanbakhsh and McGaan, 2015; Ghambakhsh and McGaan, 2015; Ghambakhsh and McGaan, 2015; Ghambakhsh et al., 2016; Ghambakhsh et al., 2017). We propose a model that accounts for the different interests and interactions involved in the development of new, general-purpose AI technology. Our model enables analysis on how these interactions affect market outcomes like performance in practice. Understanding these interactions may also inform future regulation of harms when they arise from generative machine-learning technologies.

### Related Work

**Existing approaches to fine-tuning.** Fine-tuning a base model (e.g., a language model (Ghambakhsh and McGaan, 2015)) often consists of several steps: (1) gathering and processing domain-specific data, (2) choosing and adjusting the base model's architecture (including number of layers (Song et al., 2016) and parameters (Song et al., 2016)) and the appropriate objective function (Ghambakhsh and McGaan, 2015), (3) Updating the model parameters using techniques like gradient descent or transfer learning, and (4) evaluating the resulting model and refining if necessary. Fine-tuning is an instance of the broader concept of transfer learning (Song et al., 2016).

**Existing economic models of general-purpose technology production.** Several lines of work in growth economics address the development and diffusion of general-purpose technologies (or GPTS). See (Ghambakhsh and McGaan, 2015) for a survey and (Ghambakhsh and McGaan, 2015) for a historic account of electricity and IT as GPTS with major impacts on the US economy. Scholars have examined the effects of factors such as knowledge accumulation, entrepreneurial activity, network effects, and sectoral interactions on the creation of GPTS (Ghambakhsh and McGaan, 2015). The model presented here abstracts away the forces giving rise to the creation of general-purpose technologies, such as LLMs, in the first place, and instead focuses on the later-stage decision of when (or at what performance level) to release the GPT to market for domain-specialization.

Some have suggested that general-purpose technologies create the need for new business models that describe their impact on individual sectors (Ghambakhsh and McGaan, 2015). Gambardella and McGahan (Ghambakhsh and McGaan, 2015) proposed a similar model of domain adaptation for general-purpose technology that is based on revenue sharing -- however, they do not use bargaining or multi-stage strategy to describe how the technology is developed and brought to market. Our notion of _performance_ as it relates to model technologies is inspired by economic models of product innovation (Ghambakhsh and McGaan, 2015; Ghambakhsh and McGaan, 2015).

A related--but distinct--body of work is referred to as the hold-up problem (Song et al., 2016). In this literature, two (or more) agents negotiate over an _incomplete_ contract and distribute surplus (Ghambakhsh and McGaan, 2015). In these models, after an initial agreement, players are able to re-negotiate and alter parts of the contract, yielding shifts in strategy.

## 2. A Model of Fine-Tuning

In this section, we put forward a model of fine-tuning a data-driven technology for use in a domain-specific context. The technology is developed in two steps: First, a general-purpose producer develops a technology up to a certain level of performance. Then, a domain-specific producer decides whether to adopt the technology, and how

Figure 1. An illustration of the fine-tuning game. In the first step, players bargain over the revenue-sharing agreement \(\delta\). In this example, they agree that G will receive \(80\%\) of the revenue and D will receive \(20\%\). In the second step, \(G\) develops the technology to performance level \(\alpha_{0}=21\). In the third step, \(D\) ‘fine-tunes’ the technology to \(\alpha_{1}=25\). If the players collectively receive revenue of \(25\), they’d share so that \(G\) receives \(20\) and \(D\) receives \(5\).

much to invest in the technology to further improve its performance beyond the general-purpose baseline. After these steps, the two entities share a payout.

**Generalist.** Player \(G\) (for General-purpose producer) is the first to invest in the technology's performance, and brings the performance level to \(\alpha_{0}\in\mathbb{R}\). \(G\) is motivated to invest in the technology because, ultimately, the technology's performance level determines the revenue \(G\) earns.

**Domain Specialist.** After investing in the technology, \(G\) can offer the technology to a domain-specialist, denoted \(D\), who fine-tunes the model to their specific use case. If \(D\) and \(G\) enter an agreement, \(D\) will invest in improving the technology's performance from \(\alpha_{0}\) to \(\alpha_{1}\in\mathbb{R}\).

**Revenue and costs.** The technology's _performance_, \(\alpha_{1}\), determines the total revenue that can be gained from fine-tuning the technology in that domain. In particular, we assume there is a monotonic function \(r:\mathbb{R}^{+}\rightarrow\mathbb{R}^{+}\) such that \(r(\alpha_{1})\) is the total revenue generated by performance level \(\alpha_{1}\). Unless otherwise specified, we assume \(r(\cdot)\) is the identity function, that is, the total revenue brought by technology is \(\alpha_{1}\). The cost associated with producing \(\alpha_{1}\) requires considering the two steps involved with developing the technology: general production and fine-tuning. We say that \(G\) faces cost function \(\phi_{0}(\alpha_{0}):\mathbb{R}^{+}\rightarrow\mathbb{R}^{+}\) to produce a general technology at performance-level \(\alpha_{0}\). \(D\) faces cost function \(\phi_{1}(\alpha_{1};\alpha_{0}):\mathbb{R}^{+}\rightarrow\mathbb{R}^{+}\) to bring the technology from performance \(\alpha_{0}\) to performance \(\alpha_{1}\). We assume these cost functions are publicly known. Unless otherwise specified, we also assume \(r(0)=0\), \(\phi_{0}(0)=0\), and \(\phi_{1}(\alpha_{1}=\alpha_{0};\alpha_{0})=0\), meaning that not investing in the technology is free and brings in zero revenue.

**The fine-tuning game.** The players are \(G\) and \(D\). In deciding whether to purchase the technology, \(D\) negotiates revenue sharing with \(G\). \(G\) and \(D\) share revenue \(r(\alpha_{1})\) according to a bargaining parameter \(\delta\in[0,1]\). At the end of the game, \(G\) receives \(\delta r(\alpha_{1})\) in revenue, and \(D\) receives \((1-\delta)r(\alpha_{1})\). The model fine-tuning game consists in each player deciding their level of investment and collectively bargaining to decide \(\delta\). The game proceeds as follows:

1. \(G\) and \(D\) negotiate bargaining coefficient \(\delta\in[0,1]\).
2. \(G\) invests in a general-purpose technology, subject to cost \(\phi_{0}(\alpha_{0})\), yielding performance-level \(\alpha_{0}\).
3. \(D\) fine-tunes the technology, subject to cost \(\phi_{1}(\alpha_{1};\alpha_{0})\), yielding performance-level \(\alpha_{1}\).

The steps of the game are illustrated in Figure 1. Players earn the following utilities, defined as revenue share minus cost:

\[U_{G}(\delta)\coloneqq\delta r(\alpha_{1})-\phi_{0}(\alpha_{0}), \tag{1}\]

\[U_{D}(\delta)\coloneqq(1-\delta)r(\alpha_{1})-\phi_{1}(\alpha_{1};\alpha_{0}). \tag{2}\]

If the players do not agree to a feasible bargain \(\delta\in[0,1]\), then the bargaining outcome is referred to as _disagreement_. In this scenario, the generalist receives \(d_{0}\) and the specialist receives \(d_{1}\). We assume, unless otherwise specified, that the disagreement scenario is described by \(d_{0}=d_{1}=0\).1

Footnote 1: It could be the case that a general-purpose technology producer receives positive payout even if the specialist obtains from a bargain. This case is, essentially, a second partial for bringing a general technology to market. We discuss this possibility further in the multi-specialist generalization of our model (Section 4).

### Primer on Bargaining Games

Bargaining games are a potentially useful method for computer science research. In this section we include a primer on these methods before demonstrating their use in our model.

A bargain is a process for identifying joint agreements between two or more agents on how to share payoff. The _Bargaining Problem_, formalized by (Bergamini et al., 2017), consists of two players that must jointly decide how to share surplus profit. The problem consists of a set of feasible agreements and a 'disagreement' alternative, which specifies the utilities players receive if they do not come to an agreement.

Bargaining solutions are established ways to select among candidate agreements on how to share surplus. Different bargaining solutions, proposed over the years by mathematicians and economists, aim to satisfy certain desiderata like fairness, Pareto optimality, and utility-maximization. Typically, solving for bargaining solutions consists in defining some measure of _joint utility_ between players (e.g. take the sum, product, or minimum of the players' utilities). The feasible, Pareto-optimal solution that maximizes this joint utility is known as a _bargaining solution_.

Bargaining solutions are normative: they provide guidelines for how surplus payoffs should be distributed. Solutions are inspired by moral theories like utilitarianism (which aims to maximize the sum of utilities) and gatifanirism (which aims to maximize the worst-off agent). We demonstrate the use of bargaining solutions in the subsequent sections.

### Pareto-Optimal Bargains

Our model of the fine-tuning process unfolds in two stages: the first stage is a bargain where the players must jointly agree on \(\delta\), and the second stage is a sequential game where the players make decisions individually in order (i.e., \(G\) moves first and \(D\) moves second). In order to derive solutions, it is important to define _Pareto domination_ and _Pareto efficiency_. Once we've defined a few preliminary qualities, we'll state our first finding deriving the set of Pareto-optimal solutions for a general set of cost and revenue functions.

Definition 2.1 (Pareto-dominant agreements).: _A bargaining agreement \(\delta_{i}\)**Pareto-dominates** an alternative agreement \(\delta_{j}\neq\delta_{i}\) iff at least one player gains utility by switching from \(\delta_{j}\) to \(\delta_{i}\), and no players lose utility._

Definition 2.2 (Pareto-optimal agreements).: _A **Pareto-optimal agreement** is one where no alternative agreement would improve the utility of one player without decreasing the utility of the other player. In other words, it is an agreement that is not Pareto-dominated by any other agreement._

Definition 2.3 (Strictly Unimodal Function).: _A function \(f:\mathbb{R}\rightarrow\mathbb{R}\) is called a **strictly unimodal function** over a real domain \(x\in\mathbb{D}\) if there exists some value \(m\in\mathbb{D}\) such that \(f\) is strictly increasing \(\forall x\leq m\) and \(f\) is strictly decreasing \(\forall x\geq m\)._

When reasoning about how two agents can jointly reach an agreement, it is useful to start by considering the scenario where one player is _all-powerful_, meaning the bargain is determined solely to maximize one player's utility. The formal definition of this sort of bargaining arrangement is provided below.

**Definition 2.4** (Powerful-P solution).: _For a given fine-tuning game player \(P\in\{G,D\}\), the powerful-P solution is the revenue-sharing agreement \(\delta^{\textit{powerful}P}\in[0,1]\) that maximizes \(P\)'s utility:_

\[\delta^{\textit{powerful}P}=argmax_{\delta\in[0,1]}U_{P}(\delta).\]

### Focus on Unimodal Utilities

We are now in a position to state our first theorem, which characterizes the Pareto-optimal solutions to any fine-tuning game with strictly unimodal utility functions.

**Theorem 2.1**.: _Consider a fine-tuning game where players bargain over a parameter \(\delta\). If the players' utilities are strictly unimodal functions of \(\delta\), the set of Pareto-optimal agreements is the interval between their optima \(\{\delta^{\textit{powerful}P}\},\delta^{\textit{powerful}G}\}\), where both players' utilities are greater than the disagreement scenario. If no such interval exists, then disagreement is Pareto-optimal._

The proof is provided in Appendix 6. To provide some intuition for the proof, consider the range of agreements \(\delta\) between the point which maximizes one player's utility (say, \(\delta^{\textit{powerful}P}\)) and the point which maximizes the other \((\delta^{\textit{powerful}G})\). Agreements within this range exhibit a trade-off between the two utilities. Agreements outside this range, however, leave both players worse-off than, e.g., the nearest powerful-P solution, so they are Pareto-dominated. This intuition is illustrated in Figure 2.

Theorem 2.1 applies to a notably broad set of utility functions. To illustrate some of these forms, and for ease of reference, we provide the following immediate corollary:

**Corollary 2.1**.: _If \(U_{D}\) is either strictly increasing, strictly decreasing, or strictly concave in \(\delta\), and \(U_{G}\) is either strictly increasing, strictly decreasing, or strictly concave in \(\delta\), then the set of Pareto-optimal agreements is the interval between their optima \(\{\delta^{\textit{powerful}D},\delta^{\textit{powerful}G}\}\), where both players' utilities are greater than the disagreement scenario. If no such interval exists, then disagreement is Pareto-optimal._

Notice this follows immediately from Theorem 2.1 because any strictly increasing, strictly decreasing or strictly concave function on the interval \(\delta\in[0,1]\) is strictly unimodal on the same interval.

Equipped with the theorem above, solving the fine-tuning game consists of the following steps: (**1**) Use backward induction to solve for \(D\) and \(G\)'s strategies, represented by \(\alpha_{1}^{*}\) and \(\alpha_{0}^{*}\), in terms of \(\delta\). (2) Find the set of Pareto-optimal bargaining agreements \(\delta\) between the powerful-D and powerful-G solutions. (**3**) Within the Pareto set, solve for bargaining agreements that maximize some joint function of the players' utilities.

## 3. Analysis for Polynomial Costs

Our model applies to general cost and revenue functions, and in Section 4 we provide results at this general level. But to understand how the central parameters of the model interact in closed form, it is also useful to study instantiations of the model with specific functional forms. Accordingly, we show in this section how to solve the model with a set of polynomial cost functions as a paradigmatic instance of convex cost functions, where the marginal costs increase as the technology is improved. Following this, we show how to draw conclusions about the model with general costs.

Thus, in this section, cost functions take the following polynomial function forms:

\[\phi_{0}(\alpha_{0})=c_{0}\alpha_{0}^{k_{0}}, \tag{3}\]

\[\phi_{1}(\alpha_{1};\alpha_{0}):=c_{1}(\alpha_{1}-\alpha_{0})^{k_{1}}. \tag{4}\]

Here, \(c_{0},c_{1}>0\) since costs should increase with investment, and \(k_{0},k_{1}>1\), meaning that an incremental improvement grows costlier at higher levels of performance. We will continue to assume that \(r(\alpha_{1})=\alpha_{1}\) throughout this section's analysis.

First (3.1), we derive the subgame perfect equilibrium strategies \(\alpha_{0}^{*},\alpha_{1}^{*}\) for fixed \(\delta\). Second (3.2), we find the set of Pareto-optimal revenue-sharing schemes \(\delta^{\textit{Pareto}}\). Reaching a revenue-sharing agreement \(\delta^{*}\in\delta^{\textit{Pareto}}\) is modeled as a bargaining problem because the players must decide how to share surplus utility. So, third (3.3), we define five potential bargaining solutions: Best-performing-model, Vertical Monopoly, Egalitarian, Nash Bargaining Solution, and Klaai-Smorodinsky. Where possible, we derive closed-form expressions for these solutions. We end by discussing the implications of these different revenue-sharing schemes.

### Subgame Perfect Equilibrium for a Given \(\delta\)

We use backward induction to determine the fine-tuning game's subgame perfect equilibrium (which we will refer to as a'solution' or 'equilibrium'). Fixing the outcome of the initial negotiation, \(\delta\), it is possible establish the following closed-form solution:

**Theorem 3.1**.: _For a fixed \(\delta\), the sub-game perfect equilibrium of the fine-tuning game with polynomial costs yields the following best-response strategies:_

\[\alpha_{0}^{*}=\left(\frac{\delta}{k_{0}c_{0}}\right)^{\frac{1}{k_{0}-1}},\ \ \alpha_{1}^{*}=\left(\frac{\delta}{k_{0}c_{0}}\right)^{\frac{1}{k_{0}-1}}+\left(\frac{1-\delta}{k_{1}c_{1}}\right)^{\frac{1}{k_{1}-1}}.\]

A proof of the above result is provided in Appendix 7. Notice that the domain-specific performance, \(\alpha_{1}^{*}\), is equal to the general-purpose performance, \(\alpha_{0}^{*}\), plus a term, \((\frac{1-\delta}{k_{1}c_{1}})^{\frac{1}{k_{1}-1}}\), independent of the \(G\)'s choice over \(\alpha_{0}^{*}\). This is because the cost of marginal improvements for \(D\) only depends on the _difference_\((\alpha_{1}-\alpha_{0})\), and is not affected by a large or small initial investment by \(G\). Though we assume, in this section, that \(D\)'s cost is defined solely in terms of marginal improvement, Appendix 7.9 and Section 4 contain findings that generalize beyond this assumption.

As an immediate corollary of Theorem 3.1, we derive players' utilities as a function of \(\delta\) alone.

Figure 2. Example to illustrate Theorem 2.1. For two strictly unimodal, positive utility functions over a bargaining parameter \(\delta\), the set of Pareto–optimal bargaining agreements is the interval between their optima.

**Corollary 3.1**.: _For a fixed bargaining parameter \(\delta\), the players' utilities are as follows_

\[U_{G}(\delta)=\left(\frac{1}{k_{0G}}\right)^{\frac{1}{k_{0}-1}}\left(1-\frac{1}{ k_{0}}\right)\delta^{\frac{k_{0}}{k_{0}-1}}+\left(\frac{1}{k_{1C1}}\right)^{\frac{1 }{k_{1}-1}}\delta(1-\delta)^{\frac{1}{k_{1}-1}},\]

\[U_{D}(\delta)=\left(\frac{1}{k_{1C1}}\right)^{\frac{1}{k_{1}-1}}\left(1-\frac{1 }{k_{1}}\right)\left(1-\delta\right)^{\frac{k_{1}}{k_{1}-1}}+\left(\frac{1}{k _{0G0}}\right)^{\frac{1}{k_{0}-1}}\left(1-\delta\right)\delta^{\frac{1}{k_{0}- 1}}.\]

In order to determine the set of Pareto-optimal agreements, we first find that the utility functions derived above are strictly unimodal for all \(c_{0},c_{1}\) and \(k_{0},k_{1}\geq 2\).

**Proposition 3.1**.: _In the fine-tuning game with polynomial costs, if \(k_{0},k_{1}\geq 2\), then \(U_{G}\) and \(U_{D}\) are strictly unimodal functions of \(\delta\in[0,1]\)._

The above findings are proven in Appendix 7.3. They suggest that a general set of cost functions yield strictly unimodal utility curves. The set of Pareto-optimal solutions to these games can therefore be identified using Theorem 2.1. It is easy to show that the strict unimodality finding further generalizes to linear combinations of polynomial terms of the form provided in Equations 3 and 4, so long as all exponents are greater than or equal to 2. However, when the condition is not met and \(k_{0},k_{1}<2\), numerical simulations suggest that there are counter-examples to the strict unimodality property. When the strict unimodality property does not hold, it is still possible to analyze players' strategies--for example, our analysis in Section 4.1 and Appendix 7.9 stands even in cases where utility functions that are not unimodal in \(\delta\).

Solving the powerful-\(G\), powerful-\(D\), vertical monopoly or other bargaining solutions consists in maximizing players' utilities either separately or combined into a joint utility. This is possible once parameters are specified; however, we cannot produce a closed-form expression for the general polynomial case because doing so would require solving for the zeroes of a polynomial of high degree. Therefore, for the remainder of this section, we will demonstrate the solution steps using parameter values \(k_{0},k_{1}=2\). We call this the case of _quadratic costs_. We choose the quadratic case for clarity and exposition, though we note that other solutions with other parameter values can be calculated using analogous steps.

### Pareto-optimal Agreements on \(\delta\)

We've derived both players' optimal strategies for fixed \(\delta\). Now, we consider the process where players agree on a particular value of \(\delta\). Since both players must enter an agreement in order for the technology to be viable, the determination of \(\delta\) is a two-player bargaining game. We start by solving for the set of Pareto-optimal bargaining agreements, which is the interval between the 'powerful-player' solutions, defined below.

#### 3.2.1. Powerful-Player Solutions

As we showed in Theorem 2.1, identifying the 'powerful-player' agreements is important for characterizing the set of Pareto-optimal bargaining solutions. Thus, we begin this section of analysis by solving for the powerful-\(G\) and powerful-\(D\) solutions (as defined in Definition 2.4).

**Proposition 3.2** (Powerful-\(G\) Solution).: _The Powerful-\(G\) solution to the model fine-tuning game with quadratic costs is as follows:_

\[g^{Powerful\,G}=\begin{cases}\frac{c_{0}}{2c_{0}-c_{1}}&\text{ for }c_{1}<c_{0},\\ 1&\text{ for }c_{1}\geq c_{0}.\end{cases}\]

**Proposition 3.3** (Powerful-\(D\) Solution).: _The Powerful-\(D\) solution to the model fine-tuning game with quadratic costs is as follows:_

\[g^{Powerful\,D}=\begin{cases}0&\text{ for }c_{1}<c_{0},\\ \frac{c_{1}-c_{0}}{2c_{1}-c_{0}}&\text{ for }c_{1}\geq c_{0}.\end{cases}\]

Now, using Theorem 2.1 and Proposition 3.1, we can define the set of Pareto-optimal solutions as:

\[\delta^{Parrio}\in\left\{\delta:\delta\leq\delta^{Powerful\,G}\cap\delta\geq \delta^{Powerful\,D}\right\}.\]

A visual representation of these solutions for the fine-tuning game with quadratic costs is given in Figure 4.

### Bargaining Solutions to Specify \(\delta\)

If neither player dominates in a bargain, how do they decide how to share surplus profit? Solutions to bargaining problems tend to find an agreement that maximizes some joint utility function or satisfies certain desirable properties. In this section, we define the various bargaining solutions that the two players could plausibly arrive at within the set of Pareto-optimal solutions. These solutions mostly use a joint utility function to guide the bargaining agreement, as depicted in Figure 3. A visual representation of the bargaining solutions is provided in Figure 4. Definitions and closed-form solutions are provided below, and the proofs and steps yielding the solutions are included in Appendix 7.

**Solution that maximizes the technology's performance.** The first solution we propose presumes the joint goal of the two players is to collectively produce a technology with maximum performance \(\alpha_{1}^{*}\). There are a few ways to think of this quantity: It is the performance of the technology, and, equivalently, it is also the amount of revenue the two players collect. Though we do not formally specify a social welfare function, the technological performance can be thought of as the total utility offered to society by firms \(G\) and \(D\).

**Definition 3.1** (Maximum-performance solution).: _For the fine-tuning game, the maximum-performance bargaining solution is the feasible revenue-sharing agreement \(\delta^{max\cdot\alpha_{1}^{*}}\in[0,1]\) that maximizes the technology's performance \(\alpha_{1}^{*}\delta^{max\cdot\alpha_{1}^{*}}=argmax_{\delta\in[0,1]}\alpha_{1} ^{*}\)._

**Proposition 3.4** (Maximum-\(\alpha_{1}^{*}\) Solution).: _A bargaining solution that maximizes the technology's performance is given by:_

\[\delta^{Max\cdot\alpha_{1}^{*}}=\begin{cases}0&\text{ for }c_{1}<c_{0},\\ 1&\text{ for }c_{1}\geq c_{0}.\end{cases}\]

**Vertical Monopoly Solution.** A perhaps intuitive approach to bargaining is to choose a revenue-sharing agreement that maximizes the sum of utilities \(U_{G}+U_{D}\). This solution imagines that the two players are jointly controlled by a single entity who simply wishes to maximize the sum of utility. This solution is known as either the'vertical monopoly' solution or the 'utilitarian' solution.

**Definition 3.2** (Vertical Monopoly Solution).: _For the fine-tuning game, the Vertical Monopoly (or 'Utilitarian') Solution is the feasible revenue-sharing agreement \(\delta^{\text{IM}}\in[0,1]\) that maximizes the sum of the players' utilities. \(\delta^{\text{VM}}=argmax_{\delta\in[0,1]}\) (\(U_{G}(\delta)+U_{D}(\delta)\))._

**Proposition 3.5** (Vertical Monopoly Solution).: _The Vertical Monopoly Bargaining Solution to the fine-tuning game with quadratic costs is as follows:_

\[\delta^{\text{Vertical Monopoly}}=\frac{c_{1}}{c_{1}+c_{0}}.\]

**Egalitarian Bargaining Solution.** An alternative bargaining approach tries to help the worst-off player. This bargaining solutions is known as the 'egalitarian' solution.

**Definition 3.3** (Equitarian Bargaining Solution).: _For the fine-tuning game, the Egalitarian Bargaining Solution is the feasible revenue-sharing agreement \(\delta^{\text{Egal}}\in[0,1]\) that maximizes the minimum of players' utilities: \(\delta^{\text{Egal}}=argmax_{\delta\in[0,1]}\) (\(min_{p\in\{G,D\}}\) (\(U_{P}(\delta)\)))._

**Proposition 3.6** (Gaglitarian Bargaining Solution to the fine-tuning game with quadratic costs).: _The Egalitarian Bargaining Solution to the fine-tuning game with quadratic costs is:_

\[\delta^{\text{Egal}}=\frac{-\sqrt{c_{0}^{2}-c_{0}c_{1}+c_{1}^{2}}-c_{1}+2c_{0} }{3(c_{0}-c_{1})}.\]

**Nash Bargaining Solution.** The Nash Bargaining solution maximizes the product between the two players' utilities. This arrangement satisfies a number of desiderata, originally laid out by (Kalai and Smorodinsky, 2018).

**Definition 3.4** (Nash Bargaining Solution).: _For the fine-tuning game, the Nash Bargaining Solution is the feasible revenue-sharing agreement \(\delta^{\text{NBS}}\in[0,1]\) that maximizes the product of the players' utilities: \(\delta^{\text{NBS}}=argmax_{\delta\in[0,1]}\) (\(U_{G}(\delta)\ast U_{D}(\delta)\))._

Though a closed-form solution for quadratic functions is possible, it involves solving the roots of a cubic function and yields a solution that is clunky and uninterpretable. Therefore, we refer the reader to our numerical findings on this solution, which are depicted in Figures 3 and 4.

**Kalai-Smorodinsky Bargaining Solution.** Another solution suggested in economic literature is known as the 'Kalai-Smorodinsky' bargaining solution. This solution equalizes the ratio of maximal gains. More formally:

**Definition 3.5** (Kalai-Smorodinsky Bargaining Solution).: _For the fine-tuning game, the Kalai-Smorodinsky Bargaining Solution ((Nash)).: Solution ((Nash)) is the feasible revenue-sharing agreement \(\delta^{\text{KSBS}}\in[0,1]\) that satisfies the following relation:_

\[\frac{U_{G}(\delta^{\text{KSBS}})}{\max_{\delta\in\delta^{\text{Eginous}}}U_{G} (\delta)}=\frac{U_{D}(\delta^{\text{KSBS}})}{\max_{\delta\in\delta^{\text{Eginous}}}U_{D} (\delta)}.\]

Notice the denominators in the above equation are simply the utilities associated with the powerful-G and powerful-D solutions. Despite this simplifying step, the closed form Kalai-Smorodinsky solution is clunky and uninterpretable, so we omit it from this paper. We refer the reader to our numerical findings on this solution, which are depicted in Figure 4.

### Discussion on Bargaining Solutions

Above we solve for a number of bargaining solutions revealing different possible configurations of fine-tuning arrangements. The general technology-producer and the domain specialist each have different optimal arrangements, between which any agreement is Pareto-optimal in the case of polynomial costs.

The first notable take-away is that players do not necessarily opt to maximize their own share of the profit. Even if one player has full control over the bargaining solution, depending on the relative cost of production, they may benefit from a profit-sharing agreement in order to encourage investment by the other player. If bargaining is conceptualized as splitting a pie, one player prefers to code some portion of the pie if it means the entire pie grows to a size that justifies profit-sharing. This phenomenon arises in real-world settings. For instance, Apple allows third party developers to build software on iPhones. Opening up the tasks of application development to third parties improves consumer experience such that consumers are willing to purchase apps or other capabilities within apps. This additional revenue is then shared between Apple and the developer, leaving Apple with higher profits and a better product. Revenue sharing arises, often, because doing so is lucrative.

Profit-sharing is present even when both players have exceedingly different costs of production (i.e., when \(c_{i}\) approaches \(0\) or \(\infty\)). In these limiting instances, we find that the Nash bargaining solution, Kalai-Smorodinski, and Egalitarian solutions all suggest profit-sharing. Only the Utilitarian solution--which models the two players as a vertical monopoly that is centrally controlled--yields the intuitively performance-optimal bargain, where the player with

Figure 3. Various joint-utility functions for finding bargaining solutions. Gray regions are \(\delta\) values that are not Pareto-optimal and therefore not candidate bargaining solutions. Color bar scales are defined assuming \(c_{0}=1\).

lower costs receives the entire profit. However, the vertical monopoly solution is not always performance-optimal. It underperforms the KSBS when the players face similar costs (\(\sim 0.5<\frac{c_{1}}{c_{0}}<2.5\)).

The bargaining solutions are neither binding rules nor descriptive observations; instead, they are _normative_. Identifying joint utility functions can help guide agents towards decisions that serve collective interests. For example, utilitarian and egalitarian solutions offer different visions for the appropriate distribution of welfare. In the same vein, specifying and committing to a social _welfare function_ would allow us to identify a bargaining solution that might be referred to as'socially optimal'. Unsurprisingly, however, specifying social interests in a single function is a difficult undertaking. In any given context, all the relevant interests, requirements, and aims must be accounted for. In our present case, a social welfare function would need to balance the interests of (at least 1) the technology's producers 2) consumers who value performance and 3) other external stakeholders. The procedure demonstrated in this section (and generalized in the coming sections) provides a road map for a social welfare analysis of the deployment of general-purpose models. Such an analysis might uncover how fine-tuning processes can be configured to serve collective, societal interests.

## 4. Multiple Domain Specialists

So far, we've modeled the fine-tuning process as a two-player game between a generalist and a specialist. However, an important feature of general-purpose AI models is that they can be developed without fully anticipating the set of possible downstream use-cases. To capture the possibly many use-cases for general-purpose models, in this section, we generalize our model to the case where \(n\geq 1\) domain specialists adapt the technology.

**The multi-specialist fine-tuning game.** Consider a game with \(n\geq 1\) specialists. The players are \(G\), \(D_{1}\), \(D_{2}\),...,\(D_{n}\) and we'll use \(i\) to index the specialists. \(G\) develops a technology to general performance \(\alpha_{0}\), after which domain specialist \(D_{i}\) specializes the technology to reach performance \(\alpha_{i}\) in their domain. \(G\) and \(D_{i}\) share revenue \(r_{i}(\alpha_{i})\) according to bargaining parameter \(\delta\in[0,1]\). The bargaining parameter is fixed, which captures common scenarios where the generalist simply has to set a certain pricing agreement for model access. In other words, \(G\) cannot price discriminate depending on domain \(i\). The game proceeds as follows:

* Players collectively bargain to decide \(\delta\in[0,1]\).2 Footnote 2: In cases with multiple domain specialists, the bargain over \(\delta\) is a multi-player bargaining game. We arrive at bargaining solutions for games with more than two players through a similar process to the two-player case, where a joint utility function is specified and then optimized. For more on collective welfare-driven decisions, see (Fischer, 2018).
* \(G\) invests in a general-purpose technology yielding performance level \(\alpha_{0}\) and subject to cost \(\phi_{0}(\alpha_{0})\).
* Each specialist \(D_{i}\) may fine-tune the technology by choosing a performance level \(\alpha_{i}\) subject to cost \(\phi_{i}(\alpha_{i};\alpha_{0})\).

Players' utilities are defined as revenue share minus cost:

\[U_{G}(\delta)=\sum_{i}\delta r_{1}(\alpha_{i})-\phi_{0}(\alpha_{0}),U_{D_{i}} (\delta):=(1-\delta)r_{1}(\alpha_{i})-\phi_{i}(\alpha_{i};\alpha_{0}).\]

If the general-purpose producer does not agree to a feasible bargain \(\delta\in[0,1]\), then all players receive 0 utility. If any particular specialist does not agree to a feasible bargain, this does not preclude other specialists from reaching a deal. Note that some general-purpose technologies might be marketed directly to consumers by the generalist, meaning that reaching a deal with an individual specialist is not, necessarily, needed for \(G\) to receive revenue. We believe this scenario can be captured by an additional specialist engaged in a vertical monopoly agreement with \(G\).

### Domain Specialists' Equilibrium Strategies

When there are potentially many domains where a technology may prove useful or marketable, different strategies around investment levels and fine-tuning can arise. In some domains, a technology may be adopted 'as-is' without significant additional investment or specialization. In other domains, it might be in everyone's interest for a technology to receive significant investment and specialization. Finally, in some domains, a technology might not be viable for any use at all. In this section, we explore the different sorts of cooperation (or non-cooperation) that might arise in domains with different characteristics. Our next general finding is a theorem on the different regimes of domain-specialist strategies, depending on particular attributes of revenue and cost functions.

First, we'll offer a set of relevant definitions to help characterize the different possible regimes of strategies for the specialist. Then, we'll state the formal theorem.

Definition 4.1 (Contributor).: _A domain specialist \(D_{i}\) is a **contributor** at the profit-sharing agreement \(\delta\) if, given the generalist optimal investment \(\alpha_{0}\) at \(\delta\), \(D_{i}\)'s optimal strategy is to bring the technology to performance \(\alpha_{i}^{*}>\alpha_{0}\)._

Definition 4.2 (Free-rider).: _A domain specialist \(D_{i}\) is a **fre-rider** at the profit-sharing agreement \(\delta\) if, given the generalist optimal investment \(\alpha_{0}\) at \(\delta\), \(D_{i}\)'s optimal strategy is to enter the deal without improving its performance, so \(\alpha_{i}^{*}=\alpha_{0}\)._

Definition 4.3 (Arstaneer).: _A domain specialist \(D_{i}\) is an **abstainer** at the profit-sharing agreement \(\delta\) if, given the generalist optimal investment \(\alpha_{0}\) at \(\delta\), \(D_{i}\)'s optimal strategy is to exit the deal and opt for disagreement._

Notice that any specialist with any cost and revenue function is inevitably either a contributor, free-rider, or abstainer. These

Figure 4. Bargaining agreements for the fine-tuning game with quadratic costs (i.e., the polynomial cost game where \(k_{0}=k_{1}=2\)). Most bargaining solutions suggest revenue sharing, even where one player faces much higher costs.

three regimes span the possible strategies for \(D_{1}\) in the fine-tuning game. Below, we outline conditions that characterize a specialist's strategy depending on their domain's cost and revenue \(\{r,\phi_{i}\}\).

**Theorem 4.1**.: _Say a generalist has produced a general-purpose technology operating at performance \(a_{0}\) and available at profit-sharing parameter \(\delta\). For any specialist with utility unimodal in \(a_{i}\), the following conditions characterize their strategy, shown in Table 1._

* _"Fixed Costs Under Control"_ (_FCUC_)_. At zero investment (\(a_{i}=a_{0}\)), the domain specialist is cut so is less than its share of the revenue. Formally, \(r_{i}(a_{0})>\frac{1}{1-\delta}\phi_{i}(a_{0})\).
* _"Marginally Profitable Investment"_ (_MPI_)_. At zero investment (\(a_{i}=a_{0}\)), a marginal investment from the domain specialist \(i\) increases its revenue share more than its costs. Formally, \(r^{\prime}_{i}(a_{0})>\frac{1}{1-\delta}\phi^{\prime}_{i}(a_{0})\).

A proof of the above theorem is provided in Appendix 8.1. The requirement that specialist utility is unimodal in \(a_{i}\) is, in our view, quite natural and broad. It covers three possible scenarios: 1) specialist utility is increasing with investment, 2) specialist utility is decreasing with investment, or 3) specialist utility increases with investment up to a certain point, beyond which any further investment is not cost-justified.

It is important to note that the three'regimes' defined in this section can describe a specialist's strategy in either the 1-specialist or multi-specialist fine-tuning game. In the 1-specialist case, the potential strategies describe counter-factuals that depend on the particular cost and revenue functions of the specialist. In the multi-specialist game, all of these regimes are ways of grouping domains and all can exist simultaneously.

One scenario portrayed in Table 1 does not determine cleanly which regime the specialist falls into. In the scenario labeled with an asterisk (*), fixed costs are not under control but it is marginally profitable to invest in the technology. At zero investment, the technology is not ready to bring to market profitably, and it is unclear only from the marginal return on an initial investment whether it is worthwhile for the specialist to invest. In this case, the technology is potentially viable with some non-zero effort spend or, alternatively, not viable for the domain at any level of investment. More information would be needed to conclude whether the specialist would contribute. In particular, if \((1-\delta)r_{i}(a_{i})-\phi_{i}(a_{i})\) has positive real roots (above \(a_{0}\)), then we'd conclude the technology is viable.

An illustration of Theorem 4.1 is provided in Figure 5. The indeterminate case contains two possible scenarios, one where the specialist would abstain and one where the specialist would contribute. A neat feature of this result is that these behaviors about particular domain adaptations depend only on attributes about the domain around \(a_{i}=a_{0}\). It uses only \(\text{oth}\)- and \(1\text{st}\)-order approximations of \(\left.U_{D_{i}}\right|_{a_{i}=a_{0}}\), when the domain has invested no effort.

This theorem perhaps explains why technologies see significant uptake in some domains and not others. It could, potentially, help identify domains that are particularly likely or unlikely to adopt a general purpose technology. It also may explain why some technologies are re-sold without additional investment while others require significant fine-tuning.

## 5. Conclusion

Our model provides a starting point for considering the different interests and choices involved in the development of general-purpose models. By putting forward this model, we attempt to invoke the political economy of the development of general AI technologies. These technologies are produced by a number of entities with different interests, and may potentially affect many individuals. This paper models agents' different interests explicitly, and proposes methods for weighing between them in light of societal values.

The work suggests a number of interesting directions for further research. One direction is to identify further general existence results for bargaining solutions with general functions in this model. More broadly, we also believe that formalizing the societal interests involved in AI regulation is an important direction; such a formalism would need to build on an underlying model that contains the economic interests of the firms producing the AI technology. Our model may therefore help form the foundation for such work.

\begin{table}
\begin{tabular}{c|c|c} \hline \hline \({}^{\ast}\)_FCUC_\({}^{\ast}\) & \({}^{\ast}\)_MPI_\({}^{\ast}\) & _Type of Specialist_ \\ \hline \(T\) & \(T\) & _Contributor_ \\ \hline \(T\) & \(F\) & _Free-rider_ \\ \(F\) & \(T\) & _Contributor or Abstainer_\({}^{\ast}\) \\ \(F\) & \(F\) & _Abstainer_ \\ \hline \hline \end{tabular}
\end{table}
Table 1. Types of specialists. In the third case (*), more information is needed to conclude whether the specialist contributes or abstains.

Figure 5. Examples illustrating Theorem 4.1. When fixed costs are under control and investment is marginally profitable (upper left quadrant), the domain specialist will contribute to the technology. When fixed costs are under control but investment is not marginally profitable (upper right), the domain specialist will free-ride. When fixed costs are too high and investment is marginally costly (lower right), the domain specialist will not bring the technology to market. Finally, when the fixed costs are too high but investment yields marginal returns (lower left), the domain specialist might abstain or contribute, depending on whether revenue sufficiently exceeds cost at any level of investment.

## References

* (1)
* Abbe et al. (2020) Reditet Abbe, Solon Barocas, Jon Kleinberg, Karen Levy, Manih Raghavan, and David G Robinson. 2020. Radio for computing in social change. In _Proceedings of the 2020 conference on fairness, accountability, and transparency_, 252-260.
* Bonmassani et al. (2021) Rusin Bonmassani, Derev A Hudson, Elsan Adeli, Russ Altman, Simran Arora, Sydney O'Arya, Michael S Bernstein, Jaenette Bohg, Antonio Boschi, Emma Brunskill, et al. 2021. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.02758 (2021).
* Bonmassani et al. (2023) Robin Bonmassani, Dharan Soyub, Thomas I Liao, Kathleen A Cereal, and Percy Liang. 2023. Ecosystem Graphs: The Social Footprint of Foundation Models. _arXiv preprint arXiv:2303.15772_ (2023).
* Brevanan (2010) Timothy Brevanan. 2010. General purpose technologies. _Handbook of the Economics of Innovation_ (2010), 761-791.
* Brevani and Pasquale (2020) Benedetto Brevani and Frank Pasquale. 2020. Revisiting the Black Box Society by Rethinking the political economy of big data. _2020._ 2059127093514 pages.
* Cobbe et al. (2023) Jennifer Cobbe, Michael S Vedra, and Janinder J Siza. Understanding accountability in algorithmic supply chains. In _Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency_, 1186-1197.
* Cooper (1984) Robert G Cooper. 1984. The strategy-performance link in product innovation. _KBG Management_ 44. (1984), 247-259.
* Crafti et al. (2021) Nicholas Crafti, Elizabeth J. 2021. Artificial intelligence as a general-purpose technology: an historical perspective. _Oxford Review of Economic Policy_ 37, 3 (2021).
* Elsundou et al. (2023) Tyrus Elsundou, San Marming, Pamela Mishkin, and Daniel Fock. 2023. Gpts are gpts: An early look at the labor market impact potential of large language models. _arXiv preprint arXiv:2301.10103_ (2023).
* Feli et al. (2022) Nanyi Feli, Zhihua Yan, Xiao Gao, Guoning Yang, Yuqi Huo, Jingyuan Wen, Hao Lu, Ruihua Song, Xin Gao, Tao Xiang, et al. 2022. Towards artificial general intelligence via a multifunction validation model. _Nature Communications_ 13. 1 (2022), 3094.
* Gambardella and McGaan (2010) Alfonso Gambardella and Anita M McGaan. 2010. Business-model innovation: General purpose technologies and their implications for industry structure. _Long range learning_ 42, 2-3 (2010), 262-271.
* Goldfarb et al. (2023) Ari Goldfarb, Hieda Taka, and Fredonta Todorakis. 2023. Could machine learning be a general purpose technology? a comparison of emerging technologies using data from online job positions. _Research Policy_ 2, 1 (2023), 104635.
* Gundogan et al. (2020) Belix Gundogan, Jingfei Li, Anelia Conneau, and Yetsyanov. 2020. Supervised contrastive learning for pre-trained language model fine-tuning. _arXiv preprint arXiv:2011.04183_ (2020).
* Hart and Moore (1988) Oliver Hart and John Moore. 1988. Incomplete contracts and renegotiation. _Econometrica: Journal of the Econometric Society_ (1988), 755-785.
* Hebrem (1998) Elsundou. 1998. _General purpose technologies and economic growth_. MIT press.
* Howard and Ruder (2018) Jeremy Howard and Sebastian Ruder. 2018. Universal language model fine-tuning for text classification. _arXiv preprint arXiv:1801.06146_ (2018).
* Ivanovic and Bonan (2005) Boyan Ivanovic and Peter L. Bonan. 2005. General purpose technologies. In _Handbook of economic growth_. Vol. 1. Elsevier, 1183-1224.
* Kalai and Smorodinsky (1975) Zhik Kalai and Meir Smorodinsky. 1975. Other solutions to Nau's bargaining problem. _Econometrica: Journal of the Econometric Society_ (1975), 513-518.
* Kumar et al. (2022) Ananya Kumar, Aditi Raghavan, Robie Jones, Tengyu Ma, and Percy Liang. 2022. Fine-tuning can distort pretrained features and underperform out-of-distribution. _arXiv preprint arXiv:2202.10845_ (2022).
* Gjency et al. (2005) Richard Gjency, Kenneth I. Czaviev, and Clifford T Bekar. 2005. Economic transformation: general purpose technologies and long-term economic growth. _Oup Oxford_.
* Nash (1950) John F Nash. 1950. The bargaining problem. _Econometrica: Journal of the econometric society_ (1950), 155-162.
* Ouyang et al. (2022) Long Ouyang, Jeffrey Wu, Xu Jiang, Dingo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandlin Agarwal, Katarina Sharma, Alex Ray, et al. 2022. Thinking language models to follow instructions with human feedback. _Advances in Neural Information Processing Systems_ 35 (2022), 22730-22740.
* Pan et al. (2020) Xudong Pan, Mi Zhang, Shouling Ji, and Min Yang. 2020. Privacy risks of general-purpose language models. In _2020 IEEE Symposium on Security and Privacy (SP)_. IEEE, 1314-1331.
* Perera et al. (2019) Matthew E Perera, Sebastian Ruder, and Noah A Smith. 2019. To tune or not to tune? adapting pretrained representations to diverse tasks. _arXiv preprint arXiv:1903.0587_ (2019).
* Rogerson (1992) William P Rogerson. 1992. Contextual solutions to the hold-up problem. _The Review of Economic Studies_ 59, 9 (1992), 777-787.
* Smal et al. (2020) Victor Sohl, Thomas Wolf, and Alexander Rush. 2020. Movement pruning: Adaptive sparsity by fine-tuning. _Advances in Neural Information Processing Systems_ 33 (2020), 203878-20389.
* Sen (2018) Amarty Sen. 2018. _Collective choice and social welfare_. Harvard University Press.
* Takahashi et al. (2016) Nima Takahashi, Jae Y Shin, Suryakanth R Gurudu, R Todd Hurst, Christopher B Kenskl, Michael B Gotway, and Jianming Liang. 2016. Convolutional neural networks for medical image analysis: Full training of fine tuning? _IEEE transactions on medical imaging_ 35, 5 (2016), 1299-1312.
* Trajenberg (2018) Manuel Trajenberg. 2018. _AI as the next GPT: a Political-Economy Perspective_. Technical Report. National Bureau of Economic Research.
* Visseni and Moore (1993) Rviy Visseni and Michael Moore. 1993. Product liability, research and development, and innovation. _Journal of Political Economy_ 101, 1 (1993), 161-184.
* Wang et al. (2017) Yu-Xiong Wang, Dereva Ramanan, and Martial Herbert. 2017. Growing a brain: Fine-tuning by increasing model capacity. In _Proceedings of the IEEE conference on Computer Vision and Pattern Recognition_. 2017-2180.
* Wei et al. (2022) Jason Wei, Yi Y. Rishi Romansani, Colin Raffel, Barret Zoph, Sebastian Borgward, Dani Yogatama, Maarten Rosma, Demay Zhou, Donald Metzler, et al. 2022. Emergent abilities of large language models. _arXiv preprint arXiv:2202.07082_ (2022).
* Widder and Naffas (2023) David Gray Widder and Dawn Naffas. 2023. Dislocated accountabilities in the "A19 study chain": Modularity and developers' notions of responsibility. _Big Data Society_ 10, 1 (2023), 203595127317620.
* Zhang et al. (2020) Timiy Zhang, Felix Wu, Arzo Kakiya, Kilian Q Weinberger, and Yoav Arti. 2020. Revisiting few-sample BERT fine-tuning. _arXiv preprint arXiv:2006.05987_ (2020).
* Zhuang et al. (2020) Fruhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu Zhu, Hui Xiong, and Qing He. 2020. A comprehensive survey on transfer learning. _Proc. IEEE_ 109, 1 (2020), 43-76.

## 6. Section 2 Materials

### Pareto set characterization and Theorem 2.1

Proof of Theorem 2.1.: Consider three non-overlapping intervals that collectively span the feasible set \(\delta\in[0,1]\). These intervals are:

1. \(0\leq\delta<\min(\beta^{\text{Powerful}}D,\beta^{\text{Powerful}}G)\)
2. \(\min(\beta^{\text{Powerful}}D,\beta^{\text{Powerful}}G)\leq\delta\leq\max( \beta^{\text{Powerful}}D,\beta^{\text{Powerful}}G)\)
3. \(\max(\beta^{\text{Powerful}}D,\beta^{\text{Powerful}}G)<\delta\leq 1\)

We will characterize each of these intervals in turn, finding that intervals (1) and (3) are always Pareto dominated, and interval (2) is characterized by a trade-off in utilities.

1. Within interval (1), the domain is characterized by \(\delta<\min(\beta^{\text{Powerful}}D,\beta^{\text{Powerful}}G)\Rightarrow \delta<\beta^{\text{Powerful}}D\) and \(\delta<\beta^{\text{Powerful}}G\). By the definition of a strictly unimodal function (2.3), this means that both utility functions \(\{U_{D},U_{G}\}\) are strictly increasing over interval 1. Thus, there exists some quantity \(\varepsilon>0\) such that, for any value \(\delta\) in interval (1), \(U_{D}(\delta+\varepsilon)>U_{D}(\delta)\) and \(U_{G}(\delta+\varepsilon)>U_{G}(\delta)\). Thus, every potential agreement in interval (1) is Pareto-dominated.
2. Within interval (2), the domain is characterized by \(\min(\beta^{\text{Powerful}}D,\beta^{\text{Powerful}}G)\leq\delta\), and also \(\delta\leq\max(\beta^{\text{Powerful}}D,\beta^{\text{Powerful}}G)\). If \(\beta^{\text{Powerful}}D=\beta^{\text{Powerful}}G\), then the value \(\delta=\beta^{\text{Powerful}}D=\beta^{\text{Powerful}}G\) is the unique Pareto-optimal agreement because it is optimal for both players. Otherwise if \(\beta^{\text{Powerful}}D\neq\beta^{\text{Powerful}}G\), then interval (2) can be characterized as follows: For one player \(P\in\{G,D\}\), the utility \(U_{P}\) one utility function is strictly decreasing because \(\delta\geq\beta^{\text{Powerful}}P\) and \(U_{P}(\delta)\) is a strictly unimodal function. For the other player \(\{G,D\}\setminus P\), the utility \(U_{\{G,D\}\setminus P}\) is strictly increasing because \(\delta\leq\beta^{\text{Powerful}}\{G,D\}\setminus P\) and \(U_{\{G,D\}\setminus P}(\delta)\) is a strictly unimodal function. Since one player's utility is strictly increasing and the other's is strictly decreasing, any perturbation of \(\delta\) within interval (2) constitutes a utility gain for one player and a utility loss for the other. For any value of \(\delta\) within this interval, if both players' utilities exceed the disagreement payoff (i.e., positive utility), then \(\delta\) is Pareto-optimal.
3. Within interval (3), the domain is characterized by \(\delta>\max(\beta^{\text{Powerful}}D,\beta^{\text{Powerful}}G)\Rightarrow\delta> \beta^{\text{Powerful}}D\) and \(\delta>\beta^{\text{Powerful}}G\). By the definition of a strictly unimodal function (2.3), this means that both utility functions \(\{U_{D},U_{G}\}\) are strictly decreasing over interval (3). Thus, there exists some quantity \(\epsilon>0\) such that, for any value \(\delta\) in interval (3), \(U_{D}(\delta-\epsilon)>U_{D}(\delta)\) and \(U_{G}(\delta-\epsilon)>U_{G}(\delta)\). Thus, every potential agreement in interval (3) is Pareto-dominated.

Thus interval (2) is Pareto-efficient among the set of feasible bargaining agreements. 

## 7. Section 3 Materials

### Subgame perfect equilibrium findings

Proof of Theorem 3.1.: We solve the game using backward induction as follows:

First, starting with the last stage (3), we solve for \(\alpha_{1}^{*}\) given \(\alpha_{0},\delta,\epsilon_{1}\):

\[\alpha_{1}^{*}=\operatorname*{argmax}_{\alpha_{1}}U_{D}(\alpha_ {1},\alpha,\delta) \tag{5}\] \[\Rightarrow \left.\frac{\partial U_{D}}{\partial\alpha_{1}}\right|_{\alpha_{ 1}=\alpha_{1}^{*}}=0\] \[\Rightarrow \left.\frac{\partial}{\partial\alpha_{1}}\left((1-\delta)\alpha_ {1}-\epsilon_{1}(\alpha_{1}-\alpha_{0})^{k_{1}}\right)\right|_{\alpha_{1}= \alpha_{1}^{*}}=0\] \[\Rightarrow \left((1-\delta)-k_{1}\epsilon_{1}(\alpha_{1}^{*}-\alpha_{0})^{k _{1}-1}=0\right.\] \[\Rightarrow \left.a_{1}^{*}=\alpha_{0}+\left(\frac{1-\delta}{k_{1}\epsilon_{ 1}}\right)^{\frac{1}{k_{1}-1}}.\right.\]

Note that \(\frac{\partial^{2}U_{D}}{\partial\alpha_{1}^{*}}=-k_{1}(k_{1}-1)\epsilon_{1}( \alpha_{1}-\alpha_{0})^{k_{1}-2}\). This quantity is negative as long as \(k>1\), which is assumed. Thus, the \(\alpha_{1}^{*}\) derived above yields a global maximum of \(U_{D}\).

Second, knowing \(D\)'s choice of \(\alpha_{1}^{*}\) above, we solve for \(\alpha_{0}^{*}\) as follows:

\[\alpha_{0}^{*}=\operatorname*{argmax}_{\alpha_{0}}U_{G}(\alpha_{ 0},\delta)\] \[\Rightarrow \left.\frac{\partial U_{G}}{\partial\alpha_{0}}\right|_{\alpha_{ 0}=\alpha_{0}^{*}}=0\] \[\Rightarrow \left.\frac{\partial}{\partial\alpha_{0}}\left(\delta\alpha_{1}^{*}- \alpha_{0}\alpha_{0}^{k_{1}}\right)\right|_{\alpha_{0}=\alpha_{0}^{*}}=0\] \[\Rightarrow \left.\frac{\partial}{\partial\alpha_{0}}\left(\delta\alpha_{0}+ \left(\frac{1-\delta}{k_{1}\epsilon_{1}}\right)^{\frac{1}{k_{1}-1}}-\epsilon_{0} \alpha_{0}^{k_{0}}\right)\right|_{\alpha_{0}=\alpha_{0}^{*}}=0\] \[\Rightarrow \left.\frac{\partial}{\partial\alpha_{0}}\left(\delta\alpha_{0}+ \left[\text{const}\right]-\epsilon_{0}\alpha_{0}^{k_{0}}\right)\right|_{\alpha_{0 }=\alpha_{0}^{*}}=0\] \[\Rightarrow \delta-k_{0}\epsilon_{0}(\alpha_{0}^{*})^{k_{0}-1}=0\] \[\Rightarrow \alpha_{0}^{*}=\left(\frac{\delta}{k_{0}\epsilon_{0}}\right)^{\frac{1} {k_{0}-1}}.\]

The second derivative \(\frac{\partial^{2}U_{G}}{\partial\alpha_{0}^{*}}=-k_{0}(k_{0}-1)\epsilon_{0}( \alpha_{0})^{k_{0}-2}\). This quantity is negative as long as \(k>1\), which is assumed. Thus, the value of \(\alpha_{0}^{*}\) derived above yields a global maximum of \(U_{G}\).

Finally, plugging in \(\alpha_{0}^{*}=\left(\frac{\delta}{k_{0}\epsilon_{0}}\right)^{\frac{1}{k_{0}-1}}\) into Equation 5, we obtain the following expression for \(\alpha_{1}^{*}\) as a function of \(\delta\) only:

\[\alpha_{1}^{*}=\left(\frac{\delta}{k_{0}\epsilon_{0}}\right)^{\frac{1}{k_{0}-1}}+ \left(\frac{1-\delta}{k_{1}\epsilon_{1}}\right)^{\frac{1}{k_{1}-1}}.\]

This finishes the proof.

### Utilities as a function of \(\delta\)

Proof of Corollary 3.1.: Plugging the formulas from Theorem 3.1 into Equation 1, we obtain:

\[U_{G}= \delta\alpha_{1}-\phi_{0}(\alpha_{0})\] \[= \delta\left(\left(\frac{\delta}{k_{0}c_{0}}\right)^{\frac{1}{k_{0 }-1}}+\left(\frac{1-\delta}{k_{1}c_{1}}\right)^{\frac{1}{k_{1}-1}}\right)-c_{0 }\left(\left(\frac{\delta}{k_{0}c_{0}}\right)^{\frac{1}{k_{0}-1}}\right)^{k_{0}}\] \[= \delta\left(\frac{\delta}{k_{0}c_{0}}\right)^{\frac{1}{k_{0}-1}}+ \delta\left(\frac{1-\delta}{k_{1}c_{1}}\right)^{\frac{1}{k_{1}-1}}-c_{0}\left( \frac{\delta}{k_{0}c_{0}}\right)^{\frac{k_{0}}{k_{0}-1}}\] \[= \left(\left(\frac{1}{k_{0}c_{0}}\right)^{\frac{1}{k_{0}-1}}-c_{0} \left(\frac{1}{k_{0}c_{0}}\right)^{\frac{k_{0}}{k_{0}-1}}\right)\delta^{\frac {k_{0}}{k_{0}-1}}\] \[+\left(\frac{1}{k_{1}c_{1}}\right)^{\frac{1}{k_{1}-1}}\delta(1- \delta)^{\frac{1}{k_{1}-1}}\] \[= \left(\frac{1}{k_{0}c_{0}}\right)^{\frac{1}{k_{0}-1}}\left(1- \frac{1}{k_{0}}\right)\delta^{\frac{k_{0}}{k_{0}-1}}+\left(\frac{1}{k_{1}c_{1 }}\right)^{\frac{1}{k_{1}-1}}\delta(1-\delta)^{\frac{1}{k_{1}-1}}.\]

Plugging the formulas from Theorem 3.1 into Equation 2, we obtain:

\[U_{D}= (1-\delta)\alpha_{1}-\phi_{i}(\alpha_{1};\alpha_{0})\] \[= (1-\delta)\left[\left(\frac{\delta}{k_{0}c_{0}}\right)^{\frac{1}{ k_{0}-1}}+\left(\frac{1-\delta}{k_{1}c_{1}}\right)^{\frac{1}{k_{1}-1}}\right]\] \[-c_{1}\left(\frac{\delta}{k_{0}c_{0}}\right)^{\frac{1}{k_{0}-1}}+ \left(\frac{1-\delta}{k_{1}c_{1}}\right)^{\frac{1}{k_{1}-1}}-\left(\frac{ \delta}{k_{0}c_{0}}\right)^{\frac{1}{k_{0}-1}}\right]^{k_{1}}\] \[= (1-\delta)\left(\frac{\delta}{k_{0}c_{0}}\right)^{\frac{1}{k_{0}- 1}}+(1-\delta)\left(\frac{1-\delta}{k_{1}c_{1}}\right)^{\frac{1}{k_{1}-1}}\] \[-c_{1}\left(\frac{1-\delta}{k_{1}c_{1}}\right)^{\frac{k_{1}}{k_{1 }-1}}\] \[= \left(\frac{1}{k_{0}c_{0}}\right)^{\frac{1}{k_{0}-1}}(1-\delta)^{ \frac{1}{k_{0}-1}}+\left(\frac{1}{k_{1}c_{1}}\right)^{\frac{1}{k_{1}-1}}(1- \delta)^{\frac{k_{1}}{k_{1}-1}}\] \[-\left(\frac{1}{k_{1}c_{1}}\right)^{\frac{1}{k_{1}-1}}\left(\frac {1}{k_{1}}\right)(1-\delta)^{\frac{k_{1}}{k_{1}-1}}\] \[= \left(\frac{1}{k_{1}c_{1}}\right)^{\frac{1}{k_{1}-1}}\left(1- \frac{1}{k_{1}}\right)(1-\delta)^{\frac{k_{1}}{k_{1}-1}}+\left(\frac{1}{k_{0}c _{0}}\right)^{\frac{1}{k_{0}-1}}(1-\delta)\delta^{\frac{1}{k_{0}-1}}.\]

### Utilities are stricly unimodal functions of \(\delta\)

Proof of Proposition 3.1.: We'll start by proving \(U_{G}\) is strictly unimodal, and then extend the results to \(U_{D}\).

**Beginning with \(U_{G}\)**: The proof relies on the following Lemma:

**Lemma 7.1**.: _A differentiable continuous function (\(\delta\)) is strictly unimodal over \(\delta\in[a,b]\) if the following conditions are met: **i)**\(f^{\prime}(a)>0\), **ii)**\(f^{\prime}\) is concave over the domain._

Proof of Lemma 7.1.: By the definition of strict unimodality, we can conclude a function \(f(\delta)\) is strictly unimodal over an interval \([a,b]\) if one of the following properties hold: 1) \(f^{\prime}(\delta)>0\)\(\forall\)\(\delta\in[0,1]\), meaning the function is strictly increasing over the interval, or 2) For some value \(c\in(a,b)\), the function is strictly increasing for values \([a,c)\) and strictly decreasing for values \((c,b]\). Notice that, so long as condition (**i**) holds (i.e., the function starts out strictly increasing at \(a\)), the function is strictly unimodal as long as its derivative crosses the \(f^{\prime}=0\) axis at _no more than one_ point in \([a,b]\). So, the remainder of the proof finds a contradiction when we assume conditions (**i**) and (**ii**) and that there are two values in \((a,b)\) for which \(f^{\prime}=0\).

Consider the curve \(f^{\prime}=\frac{df}{d\delta}\). We specify a point on this curve using \(\{(x,y)|x=\delta,y=\frac{df}{d\delta}\}\). Given condition (**i**), There is some point \(x_{0}=(a,p)\) where \(p>0\) and \(x_{0}\in\frac{df}{d\delta}\). Assume for the sake of contradiction that there are two points \(x_{1}=(q,0),x_{2}=(r,0)\) where \(x_{1},x_{2}\in\frac{df}{d\delta}\) and \(a<q<r<b\) (without loss of generality). We can plug these three points into the definition of concavity and find our contradiction: First, notice \(l=\frac{q-a}{r-a}\in(0,1)\) because \(a<q<r\). Next, plugging in the definition of concavity:

\[\frac{df}{d\delta}((1-l)a+lr) \geq (1-l)\frac{df}{d\delta}(a)+l\frac{df}{d\delta}(r)\] \[\frac{df}{d\delta}\left(\left(1-\frac{q-a}{r-a}\right)a+\frac{q-a }{r-a}\right) \geq \left(1-\frac{q-a}{r-a}\right)[p]+\frac{q-a}{r-a}[0]\] \[\frac{df}{d\delta}\left(a-\frac{q-a}{r-a}a+\frac{q-a}{r-a}\right) \geq p-\frac{q-a}{r-a}p\] \[\frac{df}{d\delta}\left(a+(r-a)\frac{q-a}{r-a}\right) \geq p-\frac{q-a}{r-a}p\] \[\frac{df}{d\delta}\left(a+(r-a)\frac{q-a}{r-a}\right) \geq p-\frac{q-a}{r-a}p\] \[\frac{df}{d\delta}\left(a+(q-a)\right) \geq p-\frac{q-a}{r-a}p\] \[\frac{df}{d\delta}\left(q\right) \geq p-\frac{q-a}{r-a}p\] \[0 \geq p-\frac{q-a}{r-a}p>0.\]

Hence the contradiction: We know \(p-\frac{q-a}{r-a}p>0\) is strictly greater than \(0\) because \(p>0\) and \(l\in(0,1)\). Thus a function characterized by conditions (**i**) and (**ii**) cannot contain these three points. This concludes Lemma 7.1's proof: If \(f^{\prime}\) is concave, and starts positive at \(a\), it must cross the axis at most once meaning \(f\) is unimodal.

Figure 6. Illustration of the proof for Lemma 7.1. If the derivative of a function \(f\) is positive at \(a\) and concave, it cannot cross the axis more than 1 time, meaning \(f\) is strictly unimodal.

Now, we prove the utilities are unimodal by showing that \(U_{G}(\delta)\) satisfies both conditions in Lemma 7.1 for the domain \(\delta\in[0,1]\).

We first differentiate \(U_{G}\) with respect to \(\delta\).

\[\frac{\partial U_{G}}{\partial\delta} = \frac{\partial}{\partial\delta}\left[\left(\frac{1}{k_{1}-1} \right)^{\frac{1}{k_{1}-1}}\left(1-\frac{1}{k_{0}}\right)\delta^{\frac{k_{0}}{ k_{1}}}+\left(\frac{1}{k_{1}\varepsilon_{1}}\right)^{\frac{1}{k_{1}-1}}\delta(1- \delta)^{\frac{1}{k_{1}-1}}\right]\] \[= \frac{\partial}{\partial\delta}\left[A\delta^{\frac{k_{0}}{k_{1}-1 }}+B\delta(1-\delta)^{\frac{1}{k_{1}-1}}\right],\]

where \(A:=\left(\frac{1}{k_{0}\varepsilon_{0}}\right)^{\frac{1}{k_{0}-1}}\left(1- \frac{1}{k_{0}}\right)>0\) and \(B:=\left(\frac{1}{k_{1}\varepsilon_{1}}\right)^{\frac{1}{k_{1}-1}}>0\). \(A\) is positive as long as \(k_{0}>1\) and \(c_{0}>0\), which is given. \(B\) is positive as long as \(k_{1}>1\) and \(c_{1}>0\), which is given. Continuing:

\[= A\left(\frac{k_{0}}{k_{0}-1}\right)\delta^{\frac{1}{k_{0}-1}}\] \[+B\left[-\delta\left(\frac{1}{k_{1}-1}\right)(1-\delta)^{\frac{1 }{k_{1}-1}-1}+(1-\delta)^{\frac{1}{k_{1}-1}}\right]\] \[= A\left(\frac{k_{0}}{k_{0}-1}\right)\delta^{\frac{1}{k_{0}-1}}+ \frac{(1-\delta)^{\frac{1}{k_{1}-1}-1}}{k_{1}-1}\left[-\delta+(k_{1}-1)(1- \delta)\right]\] \[= A\left(\frac{k_{0}}{k_{0}-1}\right)\delta^{\frac{1}{k_{0}-1}}+ \frac{(1-\delta)^{\frac{1}{k_{1}-1}-1}}{k_{1}-1}\left[k_{1}-k_{1}\delta-1+ \delta-\delta\right]\] \[= A\left(\frac{k_{0}}{k_{0}-1}\right)\delta^{\frac{1}{k_{0}-1}}+ \frac{(1-\delta)^{\frac{1}{k_{1}-1}-1}}{k_{1}-1}\left[k_{1}(1-\delta)-1\right]\] \[\frac{\partial U_{G}}{\partial\delta} = A\left(\frac{k_{0}}{k_{0}-1}\right)\delta^{\frac{1}{k_{0}-1}}+B \left(\frac{k_{1}}{k_{1}-1}\right)(1-\delta)^{\frac{1}{k_{1}-1}}\] \[-B\left(\frac{1}{k_{1}-1}\right)(1-\delta)^{\frac{1}{k_{1}-1}-1}.\]

Now we can show the first condition (a) in Lemma 7.1 holds:

\[\frac{\partial U_{G}}{\partial\delta}\bigg{|}_{\delta=0}=[0]+B\left(\frac{k_{1 }}{k_{1}-1}\right)-B\left(\frac{1}{k_{1}-1}\right)=B\left(\frac{k_{1}-1}{k_{1 }-1}\right)=B>0.\]

To show the second condition (b) in Lemma 7.1 holds, we perform the second-derivative test, which requires differentiating the function two more times:

\[\frac{\partial^{3}U_{G}}{\partial\delta^{3}} = A\left(\frac{k_{0}}{k_{0}-1}\right)\left(\frac{1}{k_{0}-1} \right)\left(\frac{1}{k_{0}-1}-1\right)\delta^{\frac{1}{k_{0}-1}-2}\] \[+B\left(\frac{k_{0}}{k_{1}-1}\right)\left(\frac{k_{1}-1}{k_{1}-1 }\right)\left(\frac{1}{k_{1}-1}-1\right)(1-\delta)^{\frac{1}{k_{1}-1}-2}\] \[-B\left(\frac{1}{k_{1}-1}\right)\left(\frac{1}{k_{1}-1}-1\right) \left(\frac{1}{k_{1}-1}-2\right)(1-\delta)^{\frac{1}{k_{1}-1}-3}.\]

The above expression is never positive. First, notice all three coefficients are less than or equal to zero:

* \(A(\frac{k_{0}}{k_{0}-1})(\frac{k_{0}}{k_{0}-1})(\frac{1}{k_{0}-1}-1)\) is the product of one negative and otherwise non-negative numbers: Given \(k_{0}\geq 2\), observe \(A>0\), \((\frac{k_{0}}{k_{0}-1})>0\), \((\frac{1}{k_{0}-1})>0\), \((\frac{1}{k_{0}-1}-1)\leq 0\).
* \(B(\frac{k_{0}}{k_{0}-1})(\frac{1}{k_{0}-1})(\frac{1}{k_{1}-1}-1)\) is the product of one negative and otherwise non-negative numbers: Given \(k_{1}\geq 2\), observe \(B>0\), \((\frac{k_{0}}{k_{1}-1})>0\), \((\frac{1}{k_{1}-1})>0\), \((\frac{1}{k_{1}-1}-1)\leq 0\).
* \(-B(\frac{1}{k_{1}-1})(\frac{1}{k_{1}-1}-1)(\frac{1}{k_{1}-1}-2)\) is the product of three negative and otherwise non-negative numbers: Given \(k_{1}\geq 2\), observe \(-B<0\), \((\frac{1}{k_{1}-1})>0\), \((\frac{1}{k_{1}-1}-1)\leq 0\).
* \(B(\frac{1}{k_{1}-1})(\frac{1}{k_{1}-1}-1)(\frac{1}{k_{1}-1}-2)\) is the product of three negative and otherwise non-negative numbers: Given \(k_{1}\geq 2\), observe \(-B<0\), \((\frac{1}{k_{1}-1})>0\), \((\frac{1}{k_{1}-1}-1)\leq 0\).

Second, notice all three expressions of \(\delta\) are defined and positive on the interval \((0,1)\):

* \(\delta^{\frac{1}{k_{0}-1}-2}\) is positive and defined \(\forall\delta>0\).
* \((1-\delta)^{\frac{1}{k_{1}-1}-2}\) is positive and defined \(\forall\delta<1\).
* \((1-\delta)^{\frac{1}{k_{1}-1}-3}\) is positive and defined \(\forall\delta<1\).

Every term in our derived expression for \(\frac{\partial^{3}U_{G}}{\partial U_{G}}\) is non-positive. Thus the function \(\frac{\partial U_{G}}{\partial U_{G}}\) is concave satisfying condition (b) in Lemma 7.1. This completes the proof that \(U_{G}\) is unimodal.

**Moving on to \(U_{D}\)**: Notice the formulation of \(U_{G}\) in Corollary 3.1 is almost exactly the same functional form as \(U_{D}\). If we define a variable \(\gamma=(1-\delta)\), we can use the identical proof completed above to show \(U_{D}\) is unimodal in \(\gamma\). Since we prove immodulability on the interval \([0,1]\), a function defined over \(\gamma\in[0,1]\) is simply a function of \(\delta\in[0,1]\) reflected over the vertical line \(\delta=0.5\). A transform that reflects a univariate function over the vertical line passing through the midpoint of its domain preserves strict unimodality. 

### Powerful-G Bargaining Solution

Proof of Proposition 3.2.: The powerful-\(G\) solution is the solution \(\delta^{\textit{Powerful}\,G}\) that maximizes \(U_{G}\) over the feasible set of \(\delta\in[0,1]\):

\[\delta^{\textit{Powerful}\,G}=\operatorname*{argmax}_{\delta}U_{G}\] \[\Rightarrow \frac{\partial U_{G}}{\partial\delta}=0\] \[\Rightarrow \frac{\partial}{\delta}\left[\frac{\delta^{2}}{\delta^{2}}+\frac{ \delta}{\delta c_{1}}-\frac{\delta^{2}}{2c_{1}}\right]=0\quad\textit{Corr.~{}3.1}\] \[\Rightarrow \frac{\delta}{2c_{0}}+\frac{1}{2c_{1}}-\frac{\delta}{c_{1}}=0\] \[\Rightarrow \delta\left(\frac{1}{2c_{0}}-\frac{1}{c_{1}}\right)=-\frac{1}{2c_{1}}\] \[\Rightarrow \delta=-\frac{1}{2c_{1}}\left(\frac{c_{1}-2c_{0}}{2c_{1}c_{0}}\right)^{ -1}\] \[\Rightarrow \delta=\frac{1}{2c_{0}}-\frac{1}{c_{1}}.\]

The second partial derivative \(\frac{\partial^{3}U_{G}}{\partial c_{0}}=\frac{1}{2c_{0}}-\frac{1}{c_{1}}\), which is negative as long as \(0<\frac{c_{1}}{c_{0}}<2\). Since there is only one root, the derived equation is a global maximum for \(0<c_{1}<2c_{0}\). However, notice that the derived expression is only feasible for the values \(c_{1}\leq c_{0}\), since the value \(\delta\) must be in the range \([0,1]\) (Specialist would not take a negative share of the profit). Thus, \(\delta^{\textit{Powerful}\,G}=\frac{1}{2-c_{1}}\) for \(0<c_{1}<c_{0}\).

The remainder of the proof will show that, for \(c_{1}\geq c_{0}\), within the feasible set \(0\leq\delta\leq 1\), \(\delta=1\) maximizes \(U_{G}\). We'll do so by showing that the partial derivative \(\frac{\partial U_{G}}{\partial\delta}\) is non-negative for all \(c_{1}\geq c_{0}\) and \(0\leq\delta\leq 1\). Assume for sake of contradiction:

[MISSING_PAGE_FAIL:13]

must inevitably trade off one player's utility for the other's, meaning any alternative solution would yield a lower utility for at least one player.

So, setting the utilities equal we get:

\[U_{G}(\delta)=U_{D}(\delta)\] \[\frac{\delta^{2}}{4c_{0}}+\frac{\delta}{2c_{1}}-\frac{\delta^{2}}{ 2c_{1}}=\frac{1}{4c_{1}}+\frac{\delta}{2c_{0}}-\frac{\delta}{2c_{1}}+\frac{ \delta^{2}}{4c_{1}}-\frac{\delta^{2}}{2c_{0}}\quad\text{Corr.~{}\ref{cor:2}}\] \[\delta^{2}(3c_{1}-3c_{0})+\delta(4c_{0}-2c_{1})-c_{0}=0\]

Plugging into the quadratic formula, we get two candidate solutions:

\[g^{\text{Eggl.}}\overset{?}{=}\left\{\frac{\sqrt{c_{0}^{2}-c_{0}c_{1}+c_{1}^{ 2}}-c_{1}+2c_{0}}{3(c_{0}-c_{1})},\frac{-\sqrt{c_{0}^{2}-c_{0}c_{1}+c_{1}^{2}} -c_{1}+2c_{0}}{3(c_{0}-c_{1})}\right\}\]

Notice that the first of these solutions, for \(c_{0},c_{1}>0\), is not in the feasible set \(0\leq\delta\leq 1\). Thus, the Egalitarian solution is given by:

\[g^{\text{Eggl.}}=\frac{-\sqrt{c_{0}^{2}-c_{0}c_{1}+c_{1}^{2}}-c_{1}+2c_{0}}{3 (c_{0}-c_{1})}.\]

### One-player findings for general revenue and costs

The fine-tuning game may be defined for any cost and revenue functions \(\phi_{0},\phi_{1},r\). We demonstrate in Section 3 that closed-form solutions are attainable for certain polynomial function forms. In this section, we provide _general_ results that suggest the existence of solutions for a broad set of cost and revenue functions. We put forward an existence finding that suggests meaningful cooperation (profit sharing agreement without free-riding) is viable in a swath of fine-tuning games. Our result is that for any non-decreasing cost and revenue functions, as long as \(r^{\prime}(0)>\lambda_{0}\phi_{0}^{\prime}(0)\) and \(\lambda_{1}\phi_{1}^{\prime}(a_{0})\) where \(\lambda_{0},\lambda_{1}\geq 2\), there exists a profit-sharing solution that (a) Pareto-dominates disagreement and (b) does not lead to free-riding.

Before we state the theorem formally, we have to define free riding for the fine-tuning game:

**Definition 7.1** (Free riding).: _A solution to the fine-tuning game \(\delta_{i}\in[0,1]\) exhibits **free riding** if at least one player receives profit without investing any effort in improving the technology. That is, either \(a_{0}=0\) or \(a_{1}=a_{0}\)._

The formal theorem statement is below:

**Theorem 7.1** (Revenue sharing solution for the fine-tuning game).: _Consider any fine-tuning game where \(r(a_{1}),\phi_{0}(a_{0})\), and \(\phi_{1}(a_{1})\) are non-decreasing. If the following two marginal conditions are met:_

* _Condition_ \(1:r^{\prime}(0)>\lambda_{0}\phi_{0}^{\prime}(0)\) _where_ \(\lambda_{0}\geq 2\)_,_
* _Condition_ \(2:r^{\prime}(a_{0})>\lambda_{1}\phi_{1}^{\prime}(a_{0})\) _where_ \(\lambda_{1}\geq 2\)_,_

_Then there exists a solution \(\delta^{*}\) to the fine-tuning game with the following properties: (A) Players share revenue \(0<\delta^{*}<1\). (B) Players do not free ride. (C) \(\delta^{*}\) Pareto-dominates disagreement._

Proof of Theorem 7.1.: We prove this theorem via a sequence of Lemmas.

**Lemma 7.2**.: \(ff^{\prime}(0)>\lambda_{0}\phi_{0}^{\prime}(0)\) _for a constant \(\lambda_{0}\geq 2\), then there exists a set \(A^{*}\subseteq(0,1)\) such that \(\frac{1}{2}\in A^{*}\) and for all \(\delta\in A^{*},a_{0}^{*}(\delta)>0\), \(U_{G}(\delta)>0\)._

Let's presume \(\delta^{*}=\frac{1}{2}\). If we can show that this solution yields \(a_{0}^{*}>0\), then this means the generalist's utility is greater than \(0\) for investing some non-zero effort spend. \(a_{0}^{*}\) is the value of \(a_{0}\) that maximizes \(U_{G}\), so if \(U_{G}\) has positive slope at \(a_{0}=0\), then \(a_{0}^{*}>0\).

Notice that this positive-utility outcome is met as long as \(\left.\frac{dU_{G}}{\lambda_{0}\lambda_{0}}\right|_{a_{0}=0}>0\). This condition would necessarily mean that there exists some positive \(a_{0}>0\) which maximizes \(U_{G}\). So, formally:

\[r^{\prime}(0)>2\phi_{0}^{\prime}(0)\] \[\frac{1}{2}r^{\prime}(0)-\phi_{0}^{\prime}(0)>0\] \[\frac{\partial}{\partial a_{0}}\left(\delta r-\phi_{0}\right) \bigg{|}_{a_{0}=0}>0\] \[\left.\frac{\partial U_{G}}{\partial a_{0}}\right|_{a_{0}=0}>0.\]

Notice that this inequality is met as long as \(r^{\prime}(0)>\lambda_{0}\phi_{0}^{\prime}(0)\) where \(\lambda_{0}>2\). Thus, there is a non-empty set \(A^{*}\) of solutions with \(\frac{1}{2}\in A^{*}\) that yield positive \(a_{0}\) and positive \(U_{G}\).

**Lemma 7.3**.: \(ff^{\prime}(a_{0})>\lambda_{1}\phi_{1}^{\prime}(a_{0})\) _for a constant \(\lambda_{1}\geq 2\), then there exists a set \(B^{*}\subseteq(0,1)\) such that \(\frac{1}{2}\in B^{*}\) and for all \(\delta\in B^{*}\), \(a_{1}^{*}(\delta)>a_{0}^{*},U_{D}(\delta)>0\)._

Let's presume \(\delta^{*}=\frac{1}{2}\). If we can show that this solution yields \(a_{1}^{*}>a_{0}^{*}\), then this means the domain specialist's utility is greater than \(0\) for investing some non-zero effort spend. \(a_{1}^{*}\) is the value of \(a_{1}\) that maximizes \(U_{D}\), so if \(U_{D}\) has positive slope at \(a_{1}=a_{0}^{*}\), then \(a_{1}^{*}>a_{0}^{*}\).

Notice that this positive-utility outcome is met as long as

\[\left.\frac{dU_{D}}{\partial a_{1}}\right|_{a_{1}=a_{0}^{*}}>0\] - this condition would necessarily mean that there exists some \(\alpha_{1}^{*}>a_{0}^{*}\) which maximizes \(U_{D}\). So, formally:

\[r^{\prime}(a_{0})>2\phi_{1}^{\prime}(a_{0})\] \[\frac{1}{2}r^{\prime}(a_{0})-\phi_{1}^{\prime}(a_{0})>0\] \[\left.\frac{\partial}{\alpha a_{1}}\left((1-\delta)r-\phi_{1} \right)\bigg{|}_{a_{1}=a_{0}}>0\right.\] \[\left.\frac{\partial U_{D}}{\partial a_{1}}\right|_{a_{1}=a_{0} }>0.\]

Notice that this inequality is met as long as \(r^{\prime}(a_{0})>\lambda_{1}\phi_{1}^{\prime}(a_{0})\) where \(\lambda_{1}\geq 2\). Thus, there is a non-empty set \(B^{*}\) of solutions with \(\frac{1}{2}\in B^{*}\) that yield \(\alpha_{1}^{*}>\alpha_{0}^{*}\) and positive \(U_{D}\).

**Corollary 7.1**.: \(A^{*}\cap B^{*}\) _is a non-empty set where any solution \(\delta^{*}\in A^{*}\cap B^{*}\) satisfies the three properties: \(0<\delta_{i}<1;0<\alpha_{0}^{*}<a_{1}^{*}\); and \(U_{D},U_{G}>0\)._

This Corollary follows from the findings that have already been shown in the former Lemmas.

First, \(A^{*}\cap B^{*}\) is non-empty because \(\frac{1}{2}\in A^{*}\) (as shown in Lemma 7.2) and \(\frac{1}{2}\in B^{*}\) (as shown in Lemma 7.3) so it follows that \(\frac{1}{2}\in A^{*}\cap B^{*}\).

The three properties are each met for the following reasons:

1. Property 1 (\(0<\delta^{*}<1\)) is met because \(\frac{1}{2}\in A^{*}\cap B^{*}\) and \(0<\frac{1}{2}<1\) so the existence finding is satisfied for a non-extreme value of \(\delta\). This means, for \(\delta^{*}\in A^{*}\cap B^{*}\), players share revenue.
2. Property 2 (\(0<\alpha_{0}^{*}<\alpha_{1}^{*}\)) is met because any solution in \(A^{*}\) yields \(\alpha_{0}^{*}>0\) (as shown in Lemma 7.2) and any solution in \(B^{*}\) yields \(\alpha_{1}^{*}>\alpha_{0}^{*}\) (as shown in Lemma 7.3). This means, for \(\delta^{*}\in A^{*}\cap B^{*}\), players do not free-ride (they both act to improve the technology).
3. Property 3 (\(U_{G},U_{D}>0\)) is met because any solution in \(A^{*}\) yields \(U_{G}>0\) (as shown in Lemma 7.2) and any solution in \(B^{*}\) yields \(U_{D}>0\) (as shown in Lemma 7.3). This means any solution \(\delta^{*}\in A^{*}\cap B^{*}\) yields positive utility for both players, which Pareto-dominates the disagreement scenario in which both players have zero utility.

The intuition for the above proof is that, as long as it is marginally profitable for both players to invest some finite positive amount of effort, then both players have positive utility (Pareto-dominating the disagreement alternative), neither player free rides, and both receive some profit.

This theorem perhaps helps explain why real-world situations arise where two different entities collaboratively invest in technologies. Cooperation is advantageous in a wide variety of fine-tuning scenarios. In the next section, we will further generalize our findings to a new set of games, for which the above theorems may be adapted.

## 8. Section 5 Materials

### Theorem on the Three Specialist Regimes

Proof of Theorem 4.1.: We prove this theorem in a sequence of Lemmas. The proof follows for any given specialist \(D_{i}\) and revenue-sharing parameter \(\delta\).

**Lemma 8.1**.: _If fixed costs are under control, meaning \(r_{i}(\alpha_{0})>\frac{1}{1-\delta}\phi_{i}(\alpha_{0})\), then \(D_{i}\) will not abstain - instead, \(D_{i}\) would always prefer to free-ride._

If \(r_{i}(\alpha_{0})>\frac{1}{1-\delta}\phi_{i}(\alpha_{0})\), then \(\left.U_{D_{i}}\right|_{\alpha_{i}=\alpha_{0}}=r_{i}(\alpha_{0})-\frac{1}{1- \delta}\phi_{i}(\alpha_{0})\) is simply the RHS minus the LHS of the inequality. This means \(U_{D_{i}}\) must be positive at \(\alpha_{i}=\alpha_{0}\). Thus, as long as fixed costs are under control, the specialist prefers free-riding to abstaining.

**Lemma 8.2**.: _If fixed costs are not under control, meaning \(r_{i}(\alpha_{0})<\frac{1}{1-\delta}\phi_{i}(\alpha_{0})\), then \(D_{i}\) will not free-ride - instead, \(D_{i}\) would always prefer to abstain._

If \(r_{i}(\alpha_{0})<\frac{1}{1-\delta}\phi_{i}(\alpha_{0})\), then \(\left.U_{D_{i}}\right|_{\alpha_{i}=\alpha_{0}}=r_{i}(\alpha_{0})-\frac{1}{1- \delta}\phi_{i}(\alpha_{0})\) is simply the RHS minus the LHS of the inequality. This means \(U_{D_{i}}\) must be negative at \(\alpha_{i}=\alpha_{0}\). Thus, as long as fixed costs are not under control, the specialist prefers abstaining to free-riding.

**Lemma 8.3**.: _If it is marginally profitable to invest in the technology, meaning \(r^{\prime}_{i}(\alpha_{0})>\frac{1}{1-\delta}\phi^{\prime}_{i}(\alpha_{0})\), then \(D_{i}\) will not free-ride - instead, \(D_{i}\) would always prefer to contribute._

If \(r^{\prime}_{i}(\alpha_{0})>\frac{1}{1-\delta}\phi^{\prime}_{i}(\alpha_{0})\), then \(\left.\frac{\partial U_{D_{i}}}{\partial\alpha_{i}}\right|_{\alpha_{i}=\alpha _{0}}=r^{\prime}_{i}(\alpha_{0})-\frac{1}{1-\delta}\phi^{\prime}_{i}(\alpha_ {0})\) is simply the RHS minus the LHS of the inequality. This means \(U_{D_{i}}\) is increasing at \(\alpha_{i}=\alpha_{0}\). Thus, as long as it is marginally profitable to improve the technology, the specialist prefers contributing to free-riding.

**Lemma 8.4**.: _If it is marginally costly to invest in the technology, meaning \(r^{\prime}_{i}(\alpha_{0})<\frac{1}{1-\delta}\phi^{\prime}_{i}(\alpha_{0})\), then \(D_{i}\) will not contribute - instead, \(D_{i}\) would always prefer to free-ride._

If \(r^{\prime}_{i}(\alpha_{0})<\frac{1}{1-\delta}\phi^{\prime}_{i}(\alpha_{0})\), then \(\left.\frac{\partial U_{D_{i}}}{\partial\alpha_{i}}\right|_{\alpha_{i}=\alpha _{0}}=r^{\prime}_{i}(\alpha_{0})-\frac{1}{1-\delta}\phi^{\prime}_{i}(\alpha_ {0})\) is simply the RHS minus the LHS of the inequality. This means \(U_{D_{i}}\) is decreasing at \(\alpha_{i}=\alpha_{0}\). Thus, as long as it is marginally costly to improve the technology, the specialist prefers free-riding to contributing.

Taken together, we can conclude the following about combinations of conditions:

* Fixed costs under control, marginally profitable investment: A-F, F-C (Lemmas 8.1 and 8.3). Thus the specialist would contribute.
* Fixed costs under control, marginally costly: A-F, C-F (Lemmas 8.1 and 8.4). Thus the specialist would free-ride.
* Fixed costs not under control, marginally profitable: F-A, F-C (Lemmas 8.2 and 8.3). Thus the specialist would either abstain or contribute.
* Fixed costs not under control, marginally costly: F-A, C-F (Lemmas 8.2 and 8.4). Thus the specialist would abstain.

Above, the short-hand notation 'A', 'F', and 'C' refer to the strategies of abstaining, free-riding, and contributing, respectively. The optimal strategies follow from the two marginal conditions. This completes the proof.