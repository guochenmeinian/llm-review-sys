# Domain Re-Modulation for Few-Shot Generative Domain Adaptation

Yi Wu, Ziqiang Li

University of Science and Technology of China

Equal Contribution.This work was performed when Ziqiang Li was visiting JD Explore Academy as a research intern.Corresponding Author.

Chaoyue Wang, Heliang Zheng, Shanshan Zhao

JD Explore Academy

Bin Li

University of Science and Technology of China

Equal Contribution.This work was performed when Ziqiang Li was visiting JD Explore Academy as a research intern.

Dacheng Tao

JD Explore Academy

###### Abstract

In this study, we delve into the task of few-shot Generative Domain Adaptation (GDA), which involves transferring a pre-trained generator from one domain to a new domain using only a few reference images. Inspired by the way human brains acquire knowledge in new domains, we present an innovative generator structure called **Domain Re-Modulation (DoRM)**. DoRM not only meets the criteria of _high quality_, _large synthesis diversity_, and _cross-domain consistency_, which were achieved by previous research in GDA, but also incorporates _memory_ and _domain association_, akin to how human brains operate. Specifically, DoRM freezes the source generator and introduces new mapping and affine modules (M&A modules) to capture the attributes of the target domain during GDA. This process resembles the formation of new synapses in human brains. Consequently, a linearly combinable domain shift occurs in the style space. By incorporating multiple new M&A modules, the generator gains the capability to perform high-fidelity multi-domain and hybrid-domain generation. Moreover, to maintain cross-domain consistency more effectively, we introduce a similarity-based structure loss. This loss aligns the auto-correlation map of the target image with its corresponding auto-correlation map of the source image during training. Through extensive experiments, we demonstrate the superior performance of our DoRM and similarity-based structure loss in few-shot GDA, both quantitatively and qualitatively. Code will be available at [https://github.com/wuyi2020/DoRM](https://github.com/wuyi2020/DoRM).

## 1 Introduction

Domain adaptation aims to bridge the domain gap and transfer knowledge to mitigate the limitations imposed by a lack of extensive labeled data [8; 40; 51]. Recent research has explored the field of few-shot Generative Domain Adaptation (GDA), which aims to achieve realistic and diverse generation with only a few training images [29; 32; 34; 43; 47; 59; 31; 42; 23; 62]. Particularly, thepurpose of few-shot GDA4 is to transfer a generator pre-trained on the source domain to the target domain using a few reference images.

Existing few-shot GDA works primarily focus on three properties: _(i) High quality_ and _(ii) Large diversity_, where the adapted generator can synthesize high quality and diverse images in the target domain and _(iii) Cross-domain consistency_, where the adapted images and their corresponding source images should be consistent in terms of domain-sharing attributes, such as pose and identity. A majority of them update the entire generator with regularization techniques including GAN inversion [55; 47; 63], Contrastive-Language-Image-Pretraining (CLIP) [10; 55; 63], and consistency loss [32; 47; 59] to achieve large diversity and cross-domain consistency of adaptation. However, updating the entire generator imposes limitations on its ability to synthesize multiple target domains. In contrast, the human brain employs a more efficient approach to learn from new domains by forming new proteins, allowing for the retention and integration of knowledge from multiple domains. This creative capacity enables humans to explore previously unseen domains.

Drawing inspiration from human learning processes, we propose a novel generator structure called **Domain Re-Modulation (DoRM)** based on StyleGAN2 . DoRM not only fulfills three essential properties of few-shot GDA but also introduces two new capabilities: _(iv) Memory_, enabling the generator to retain knowledge from previously learned domains when generating images in new domains, and _(v) Domain Association_, allowing the generator to integrate multiple learned domains and synthesize hybrid domains not encountered during training. As depicted in Figure 1, DoRM freezes the pre-trained source generator and introduces new mapping and affine modules (M&A modules) to achieve the necessary domain shift in the style space. This approach enables DoRM to perform high-fidelity generation across multiple domains by selectively activating different M&A modules, which significantly reduces the required storage space. Moreover, as StyleGAN's style space is a linear subspace [36; 24; 45], the domain shift obtained through DoRM is linearly combinable. Consequently, DoRM can synthesize images in hybrid domains not present in the training dataset by simultaneously activating multiple M&A modules. To further enhance cross-domain consistency, we introduce a similarity-based structure loss denoted as \(L_{ss}\). Specifically, we leverage the CLIP image

Figure 1: **Left**: Framework of our DoRM. Given a generator of StyleGAN2 structure pre-trained on a source domain (components in the white dotted blocks), we can realize multi-domain generation and hybrid-domain generation by activating the corresponding trained M&A modules (components in the colourful solid blocks). **Right**: Multi-domain generation (right top) and hybrid-domain generation (right bottom). For instance, by activating the trained M&A modules of Baby and Sketch domains, hybrid-domain (Sketch-Baby domain) generation has been realized easily.

encoder  to extract intermediate tokens from the target image and its corresponding source image. We then enforce consistency between the auto-correlation maps of these tokens, ensuring improved alignment between target and source images.

We conducted extensive experiments on few-shot GDA involving various source and target domains. Our experiments, both quantitative and qualitative, highlight the competitive performance of our method compared to state-of-the-art approaches in 10-shot GDA. We achieved remarkable results in terms of quality, diversity, and cross-domain consistency. Notably, our proposed DoRM stands out by demonstrating exceptional performance in hybrid-domain generation, a hard task that previous methods have not accomplished well. The key contributions of this work can be summarized as follows:

* We introduce DoRM, a novel generator structure for few-shot generative domain adaptation, inspired by the learning mechanism of human brains. DoRM not only excels in synthesizing high-quality, diverse, and cross-domain consistent images, but also integrating memory and domain association capabilities that remain relatively unexplored in the field. Notably, our approach is one of the very few that encompasses all five desired properties of GDA.
* Additionally, we propose a novel consistency loss called similarity-based structure loss, which further enhances cross-domain consistency in our approach.
* Through comprehensive evaluations, our proposed method outperforms existing competitors across various settings, showcasing its superior performance.

## 2 Related Work

### Generative Adversarial Networks

Deep learning has made remarkable achievements in various fields [46; 44; 22]. Among them, generative adversarial networks [11; 37; 28] play a two-player adversarial game, where the generator aims to synthesize realistic images to fool the discriminator, while the discriminator learns how to distinguish the synthesized images from real ones. Previous works [16; 2; 53; 18; 19] have significantly improved the synthesis capability on high-resolution datasets. Style-based methods [18; 19; 35] remain the state-of-the-art unconditional GANs owing to their unique architecture. However, GANs training requires a large number of training images, or severe discriminator overfitting can occur [26; 27]. To alleviate this issue and improve training stability, various data augmentation techniques [57; 15; 17; 60; 25] and regularization technologies [26; 48; 39; 14] have been introduced. Among these, Adaptive Discriminator Augmentation (ADA) is an adaptive strategy that controls the strength of augmentations and has shown remarkable performance, becoming the default operation in data-efficient GANs. Tseng _et al._ proposed a regularization scheme to modulate the discriminator's prediction, mitigating discriminator overfitting. However, most of these techniques fail in the extremely small (e.g., 10) training data regime.

### Few-shot Generative Domain Adaptation

Previous works in few-shot GDA mainly have primarily focused on three essential properties: _High quality_, _Large diversity_, and _Cross-domain consistency_. Some studies have fine-tuned the entire generator using regularization techniques. For example, [32; 47] introduced a consistency loss based on Kullback-Leibler (KL) divergence to preserve the relative similarities and differences between instances, inheriting diversity and maintaining consistency during adaptation. The contrastive term [12; 5] has also been employed to construct consistency loss in . In addition, leveraging the semantic power of large Contrastive-Language-Image-Pretraining (CLIP)  models, [10; 55; 63] proposed to define the domain-gap direction in CLIP embedding space, guiding the optimization of the generator. Furthermore, GAN inversion [7; 38] technique has been widely used in few-shot GDA to meet different purposes, such as exploring the domain-sharing attributes [55; 63], and compressing the latent space to a subspace to relax the cross-domain alignment . Compared to optimizing the entire generator, some studies  only update the crucial part of the generator. Moreover, some work  adds a lightweight attribute adaptor and attribute classifier before the frozen generator and after the frozen discriminator, respectively. The proposed method achieves remarkable performance in synthesis quality and diversity but lacks cross-domain consistency.

Furthermore, [20; 1] share the similar idea with us of incorporating multi-domain generation capabilities into a single generator. However, these methods employ multiplicative modulation, which is indeed different with ours. Specifically, HyperDomainNet  adopts a solitary modulation parameter, primarily a scale (\(\)), to adjust the weights of the convolutional layer, influencing the "s" space of StyleGAN. In this setup, the scale parameter remains constant for all images within a target domain. Formally, HyperDomainNet's architecture is represented as \(w s_{i}\), where \(w\) and \(s_{i}\) denote the convolutional weight and style code of the source StyleGAN2, respectively. However, the introduction of this all-encompassing scale parameter can potentially restrict the generator's learning capacity. Especially in scenarios with significant domain gaps between target and source domains, HyperDomainNet's performance may decline. Furthermore, the non-linear combinability of the scale modulation parameter impedes its ability to achieve robust domain association. Among the approaches closest to our DoRM, DynaGAN  introduces two modulation parameters--shift (\( s\)) and scale (\(\))--to the convolutional weights affecting StyleGAN's "s" space. DynaGAN's architecture can be defined as \(w(s_{i}+ s)\). Similar to HyperDomainNet, the non-linear combinability of the scale modulation parameter impedes its ability to achieve robust domain association. In contrast, our DoRM solely embraces a sample-specific domain shift denoted as \( s_{i}\), formalized as \(w(s_{i}+ s_{i})\). This distinct design substantially enhances the generator's learning potential, enabling adaptation to a diverse spectrum of target domains, even in the presence of considerable domain gaps. Notably, the sample-specific domain shift proves sufficient for both few-shot and one-shot GDA, eliminating the necessity for an additional domain scale parameter. This streamlined approach not only fosters domain association but has been effectively demonstrated. Additionally, although  defines and addresses a related task called Domain Expansion and domain composition (referred to as memory and domain association in our paper), it inadvertently curtails the source domain's generative capacity, amplifying the intricacies and temporal requisites of domain adaptation. As depicted in the experimental results,  encounters challenges when faced with substantial domain gaps between source and target domains. Evidently, its performance is compromised, as evidenced in instances such as adapting to the 10-shot generation context of the Sketch dataset and the one-shot generation context of the "elsa" dataset.

Figure 2: Our framework (**DoRM**) is based on StyleGAN2. In the Synthesis network \(g()\) (gray blocks), the source affines \(A_{s}\) and the source mapping \(f_{s}\) constitute the pre-trained source generator on a source domain. To achieve generative domain Adaptation, we incorporate a new target mapping \(f_{t}\) and target affines \(A_{t}\). During training, we only optimize the parameters of the solid yellow blocks.

Approach

In this section, we present our generator structure, DoRM (Section 3.1), which takes inspiration from the way human brains learn new knowledge in different domains. DoRM excels in generating high-quality, diverse images while maintaining strong cross-domain consistency in few-shot GDA. Additionally, it possesses the unique ability to integrate multiple learned domains, allowing for the synthesis of images in hybrid domains that were not present in the training dataset. To address the issue of discriminator overfitting, we freeze the backbone of the source discriminator and introduce a target domain classifier (Section 3.2). Furthermore, we propose a novel similarity-based structure loss, denoted as \(L_{ss}\) (Section 3.3), to enhance the maintenance of cross-domain consistency. Finally, we introduce the overall training loss in Section 3.4.

### Domain Re-modulation Structure of Generator

**StyleGAN2.** Our method is applied to a pre-trained StyleGAN2 . Unlike general GANs that directly feed latent code to the generator, StyleGAN2  employs a non-linear mapping network \(f()\) to transform the latent space \(\) into an intermediate latent space \(\). The latent code (\(w\)) is transformed into the style code (\(s\)) through a learned affine transformation \(A\). Finally, the style code is inserted into the synthesis network \(g()\) through the modulation component at each convolution layer.

**Domain Re-modulation of Generator.** To equip the generator with memory and inherit the semantic information (_e.g._, glasses, gender, ages) from the source domain, we propose DoRM, illustrated in Figure 2. We freeze the given StyleGAN2 model pre-trained on the source domain and employ a new mapping network \(f_{t}\) and new affine transformation \(A_{t}\) (M&A module) to build \(_{t}\) space and \(_{t}\) space, respectively. Through the new M&A module, we obtain domain shift as well as the target style codes. The added \(f_{t}\) and \(A_{t}\) have the same architecture as \(f_{s}\) and \(A_{s}\), respectively, and are initialized by \(f_{s}\) and \(A_{s}\). Accordingly, each layer of the synthesis network is controlled by source and target style codes. Given a latent code \(z\) sampled from Normal distribution \(\) (\(z\)),

\[w_{t}=f_{t}(z)_{t}, w_{s}=f_{s}(z)_{s}, \]

where \(_{t}\) and \(_{s}\) contain information from the target domain and source domain, respectively. Transformed by their own learned affine layers (Eq. 2), the information in these two domains represents their respective styles and is combined into general styles \(s\) (Eq. 3) to control the synthesis network together:

\[s_{t}=A_{t}(w_{t}), s_{s}=A_{s}(w_{s}), \]

\[s= s_{t}+(1-)s_{s}, \]

where \(\) is a hyper-parameter that controls the strength of the domain shift. In GDA, it tends to reuse various factors like pose, content, structure, _etc._ from the source domain and learns the most distinguishable characteristics of the target domain. To preserve variation factors as much as possible in the source domain, \(\) is set to a relatively small value (More analyses can be found in Section A.1). The combined style code \(s\) modulates the convolution weights through \(w^{}_{i}=s w_{i}\), where \(w^{}_{i}\) is the modulated weights. Then, demodulation is employed to eliminate the influence of the style code \(s\) from the statistics of the convolution's output feature maps, which has been formalized as \(w^{}_{i}=_{i}}{\|w^{}\|_{2}}\), where \(\|w^{}\|_{2}\) represents the L2-Norm function.

### Target Domain Classifier

In GANs training, the discriminator typically distinguishes the training images from the generated images. However, in few-shot GDA, where there are extremely few training images, the discriminator can easily overfit to the training images, leading to severe model collapse in the generator. In this work, we treat the discriminator as a target domain classifier that measures the probability of the images belonging to the target domain. Defining the target domain by only a few training images is ambitious, so we desire the discriminator to extract the most representative feature of training images that portray the target domain. Inspired by , we reuse and fix the feature extractor \(d()\) of the pre-trained source discriminator to inherit its strong feature extraction capability. Additionally, we introduce a target domain classifier \(()\) on the top of the feature extractor \(d()\). We use a two-layer multi-layer perceptron (MLP) as the target domain classifier \(()\) and the target domain classifier \(()\), and it is updated from scratch, which outperforms directly fine-tuning the final layer of the original discriminator, especially for large domain-gap GDA. Given an image \(x\), the discriminator measures the probability that the image belongs to the target domain using \(p=(d(x))\).

### Similarity-based Structure Loss

To explicitly model the cross-domain consistency in generative domain adaptation, we propose a novel similarity-based structure loss called \(L_{ss}\). Our intuition is that the auto-correlation maps of the source image and its corresponding target image should be consistent during generative domain adaptation. To achieve this, we extract the intermediate tokens \(F_{A}\) and \(F_{B}\) of the source image \(I_{A}\) and its corresponding target image \(I_{B}\) from the k-th layer pf the CLIP image encoder. These tokens are denoted by \(F_{A}=F_{A}^{1},,F_{A}^{n}\) and \(F_{B}=F_{B}^{1},,F_{B}^{n}\), respectively. We define the auto-correlation maps as \(M_{A}=^{1}}{|F_{A}^{1}|}}{|F_{A}|}\) and \(M_{B}=^{2}}{|F_{B}^{1}|}}{|F_{B}|}\), where \(_{A}^{i,j}=^{i}}^ {j}}}{^{i}}^{j}}}\) and \(_{B}^{i,j}=^{i}}^ {j}}}{^{i}}^{i}}}\). The \(L_{ss}\) is then defined as the L2 norm of the difference between \(M_{A}\) and \(M_{B}\):

\[L_{ss}=}_{i=1}^{n}_{j=1}^{n}||M_{A}^{i,j}-M_{B}^{i,j}||, \]

where \(||||\) is the L2 norm function.

### Overall Training Loss

Our overall training loss includes original adversarial training loss in StyleGAN2 and the similarity-based structure loss \(L_{ss}\):

\[_{G} =-E_{z p(z)}[log(D(G(z)))]+_{ss}_{ss}, \] \[_{D} =-E_{z p(z)}[log(1-D(G(z)))]-E_{x_{t}}[log(D(x ))],\]

where \(_{t}\) is the training dataset. In our experiments, we set \(_{ss}=10\).

## 4 Experiments

We begin by introducing the experimental settings of our method, which encompass implementation, datasets, and metrics (Section 4.1). Next, we apply our method to various 10-shot datasets, showcasing its performance in Section 4.2. Section 4.3 explores the capabilities of domain association among multiple domains. Furthermore, we conduct ablation studies (Section 4.4 and Section A.1) to assess the impact of both the similarity-based structure loss and the generator structure. Additionally, we provide the user study in Section A.4 and demonstrate the applicability of our DoRM to one-shot GDA in Section A.3.

### Experiments Settings

**Implementation.** We adopt the pre-trained StyleGAN2  on FFHQ  as our source model, and our training parameters and settings follow StyleGAN2-ADA . Due to the small amount of training data, we set the batch size to 4, and we terminate the training process after the discriminator has processed 100K real samples. Our implementation is based on the official implementation of StyleGAN2-ADA.

**Datasets.** Following previous literature [32; 59], we use FFHQ  with resolution \(256 256\) as the source domain. In 10-shot GDA, we evaluate our method on multiple target datasets, including Sketches , FFHQ-Babies , FFHQ-Sunglasses , Face-Caricatures, Face paintings by Amedeo Modigliani, Face paintings by Raphael, and Face paintings by Otto Dix . All the training datasets are shown in Section A.2.

**Metrics.** Following [59; 32], we use Frechet Inception Distance (FID)  as the metric to evaluate the synthesis quality and diversity simultaneously. Additionally, we adopt intra-cluster LPIPS (intra-LPIPS) [59; 32] based on LPIPS  to measure the synthesis diversity. Specifically, we synthesize 1000 images and then assign each of the synthesized images to the \(k\) training images with the lowestLPIPS distance, forming k clusters. We calculate the average LPIPS distance within each cluster and then average over all the clusters. Furthermore, we report the identity (ID) similarity  predicted by the Arcface  to measure the preservation of identity information, which is a metric to measure the cross-domain consistency.

### 10-shot Generative Domain Adaptation

**Qualitative comparison.** In 10-shot GDA, following the previous studies , we sample 10 training images from the target domain to transfer the pre-trained generator. Figure 3 shows the results of 10-shot GDA with different methods. We observe severe generator overfitting in the FreezeD . GenDA  shows high quality and diverse synthesis but fails to maintain cross-domain consistency. CDC  and RSSA  improve the cross-domain consistency, but the synthesis quality is unsatisfactory. AdAM  also increases the synthesis diversity but fails in synthesis quality. By contrast, our method preserves all the domain-sharing attributes from the source domain by freezing the original generator and acquires the domain shift through new concurrent network components. Our method shows appealing synthesis quality and diversity while maintaining better cross-domain consistency than previous methods. More qualitative results can be found in Section A.2, Section A.5, and Section A.6.

**Quantitative comparison.** We use Frechet Inception Distance (FID) to evaluate synthesis quality and diversity (lower is better). In 10-shot GDA, to better reflect the synthesis diversity, we use the Intra-LPIPS to measure the synthesis diversity (higher means better synthesis diversity). Additionally, we measure cross-domain consistency using Identify similarity (ID)  (higher is better). Table 1 summarizes the three evaluation metrics for 10-shot GDA over different target domains. FreezeD  and GenDA  struggle to maintain cross-domain consistency. CDC , RSSA , DCL  and AdAM  improve the synthesis diversity and cross-domain consistency but fails in the synthesis quality (as seen in Figure 3), leading to unsatisfactory FID scores. Our method outperforms all these methods on the different target domains, achieving not only better synthesis diversity and cross-domain consistency (higher Identity score and Intra-LPIPS) but also better synthesis quality (lower FID score).

### Multi-domain and Hybrid-domain Generation

**Multi-domain generation.** Our proposed DoRM utilizes a novel approach by learning and retaining knowledge of new domains through the formation and update of new M&A modules, instead of updating the entire generator. This unique characteristic enables our DoRM, with a single generator, to generate images across multiple domains (as depicted in the top part of Figure 4). In contrast to previous methods [32; 47; 59; 58] that require updating the entire generator for few-shot GDA, limiting its capability into single domain generation, our DoRM offers significant storage space savings in multi-domain generation. As shown in Table 2, our method's models are about \(3\) smaller than previous methods  on 10-domain generation.

**Hybrid-domain generation.** In contrast to previous methods [32; 59; 55] that fine-tune the entire generator, our DoRM achieves an effective linear domain shift through the update of new M&A

  Datasets &  &  &  \\  Method & FID & I-LPIPS & ID & FID & I-LPIPS & ID & FID & I-LPIPS & ID \\  minegan & 98.23 & 0.514 & 0.132 & 68.91 & 0.42 & 0.171 & 64.34 & 0.40 & 0.092 \\ FreezeD & 110.92 & 0.346 & 0.037 & 51.29 & 0.337 & 0.030 & 46.54 & 0.325 & 0.010 \\ GenDA & 47.05 & 0.556 & 0.029 & 22.62 & 0.548 & 0.004 & **31.97** & 0.407 & 0.011 \\ CDC & 74.39 & 0.573 & 0.326 & 42.13 & 0.562 & 0.318 & 45.67 & 0.453 & 0.214 \\ RSSA & 77.77 & 0.576 & 0.314 & 70.41 & 0.563 & 0.307 & 63.44 & 0.480 & 0.296 \\ DCL & 52.56 & 0.582 & - & 38.01 & - & - & 37.90 & 0.486 & - \\ AdAM & 48.83 & 0.590 & 0.249 & 28.03 & 0.592 & 0.306 & 55.74 & 0.495 & 0.198 \\ 
**DoRM** & **30.31** & **0.623** & **0.445** & **17.31** & **0.644** & **0.389** & 40.05 & **0.502** & **0.365** \\  

Table 1: **Quantitative evaluation on 10-shot GDA**. All the source generators are pre-trained on FFHQ. The target domains include Sketches, FFHQ-Baby and FFHQ-Sunglasses. Evaluation metrics include FID, Intra-LPIPS (I-LPIPS), and Identify similarity (ID). Noting that Sketches dataset only contains about 300 images, the large synthesis diversity will harm to the FID score.

modules. By learning multiple M&A modules that store the knowledge of various training domains, DoRM not only enables multi-domain generation but also facilitates the synthesis of images in hybrid domains not present in the training data (as depicted in the bottom left part of Figure 4). For comparison, we conduct hybrid-domain generation experiments using CDC . In CDC, the domain shift between the source and target domain generators is obtained by subtracting their corresponding parameters. Similar to our DoRM, CDC achieves hybrid-domain generation by combining multiple domain shifts, adding the parameters of each shift to the source domain generator. However, as illustrated in Figure 4, CDC exhibits unsatisfactory synthesis quality in hybrid-domain generation. In contrast, the images synthesized by DoRM not only inherit domain-sharing attributes such as pose, gender, and identity, but also seamlessly blend domain-specific attributes. Furthermore, we extensively explore domain association among multiple domains using our proposed DoRM in Figure 5. The results demonstrate that DoRM efficiently integrates diverse domains to generate high-quality

Figure 3: **Qualitative comparison on 10-shot GDA. The source domain is FFHQ, and the target domains include Sketches and FFHQ-Babies. We compare our method with FreezeD, GenDA, CDC, RSSA and AdAM. Feeding the same latent code \(z\) into the source generator and the target generator, we obtain the corresponding images in the source and target domains. Our method shows better cross-domain consistency and synthesis quality than the other methods.**

images in hybrid domains not present in the training data. In this case, our proposed DoRM has the ability to generate creative outputs in previously unseen domains by incorporating knowledge learned from other domains, similar to how humans can draw on past experiences to generate novel ideas. To the best of our knowledge, **our proposed DoRM is the first method to achieve efficient domain association in this manner**. Additional visualizations of hybrid domain generation can be found in Section A.6.

### Ablation Study

We conduct ablation studies to evaluate the impact of our proposed DoRM generator structure and similarity-based structure loss. As shown in Figure 6, the images synthesized by baseline (which simply fine-tunes the StyleGAN2 generator with adversarial loss ) exhibit severe overfitting to the training images. By contrast, fine-tuning our DoRM structure generator with adversarial loss yields better synthesis diversity than the baseline. Moreover, when we optimize our DoRM generator structure with both adversarial loss and similarity-based structure loss, the synthesis images exhibit appealing quality and diversity, while maintain high cross-domain consistency, which indicates the proposed loss effectively preserves cross-domain consistency in few-shot GDA. More ablation studies on the network component of our DoRM are presented in Section A.1.

## 5 Limitation and Conclusion

**Limitation.** i) Although our method can achieve appealing results on the few-shot GDA across different target domains, however, the strength of domain shift \(\) currently needs to be manually adjusted. Furthermore, since the various depth layers capture different semantic attributes, equipping each layer with an appropriate \(\) may help to further improve synthesis quality. ii) The current

  Model Size & 2-domain & 5-domain & 10-domain \\  CDC  & 48M & 120M & 240M \\  Ours & **30M** & **54M** & **84M** \\  

Table 2: **Storage Comparison.** The number of generator parameters required to realize different multi-domain generations.

Figure 4: **Qualitative results on multi-domain and hybrid-domain generation.** The top part shows the multi-domain generation of our methods on three target domains. The bottom part illustrates the comparison on hybrid-domain generation between our proposed DoRM (bottom left) and CDC  (bottom right). The source generator is pre-trained on FFHQ . The adopted M&A modules in our DoRM are trained in Section 4.2.

manuscripts only simply combines the M&A modules of different target domains and activate them at the same time to realize the domain association. To further improve the performance of the domain association, not only combining the trained target M&A modules but also employing a new M&A module and additional consistency loss is a better method to blend the target domains.

**Conclusion.** In this paper, we present DoRM, a novel generator structure inspired by the learning and storage mechanisms of the human brain, specifically designed for few-shot GDA. Our DoRM is characterized by its simplicity and efficiency. Additionally, we introduce a novel similarity-based structure loss to ensure cross-domain consistency in the few-shot GDA. Through extensive qualitative and quantitative evaluations, we demonstrate the superiority of our method over existing approaches in terms of synthesis quality, diversity, and cross-domain consistency. Importantly, akin to the human brain, our DoRM exhibits memory and the ability to integrate knowledge from different domains, enabling the generation of images in novel hybrid domains not encountered during training.

Figure 5: **Domain association between different domains by our DoRM. The first row and the first column show the 10-shot GDA results on different target domains. By simply combining the corresponding pretrained M&A modules in 10-shot GDA, DoRM can integrate the domains and synthesize the high-quality images in the hybrid domains.**

Figure 6: **Ablation study on DoRM and \(L_{ss}\). The training images are 10-shot sketches.**

Acknowledgments

The work was supported in part by the National Natural Science Foundation of China under Grands U19B2044 and 61836011.