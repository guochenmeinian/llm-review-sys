# [MISSING_PAGE_FAIL:1]

[MISSING_PAGE_FAIL:1]

to unveil the subsequent assortment in the cascade. This cycle continues until either an assortment receives a click from the user or the agent depletes the pre-selected assortments.

The cascading assortment bandit problem is the strict generalization of both the cascading bandits model and the assortment bandits model. It is also a generalization of the simple multi-armed bandit problem. That is, if \(K=1\) and \(M=1\), the problem is the simple multi-armed bandit. If \(K>1\) and \(M=1\), the problem corresponds to the cascading bandit. If \(K=1\) and \(M>1\), we recover the assortment bandit problem. The illustrations on comparisons between the cascading assortment bandit and the other combinatorial bandits are presented in Figure 

In order to accommodate the generalization of the interactive model across items and assortments, we also incorporate the feature information of items and parametrization of a click model in the cascading assortment bandit model. Hence, we name the model as **cascading contextual assortment bandit** (see Section 2.2 for the formal definition of the problem setting).1 Under this newly proposed combinatorial bandit model, we posit the following question:

_Can we design a provably efficient algorithm for cascading contextual assortment bandits?_

To address the question at hand, we first have to overcome the technical challenges inherent in each special case of our problem setting: the cascading contextual bandit and the contextual assortment bandit. Firstly, in the cascading contextual bandit , a longstanding issue has been the suboptimal dependence on the cascade length, \(K\). Intuitively, one would expect that as \(K\) increases in the cascading model, the regret should either diminish or at least remain constant; performance deterioration should not occur. However, all existing regret bounds for cascading contextual bandits scale proportionally to \(K\). This finding is not just counter-intuitive, but also suboptimal (for further discussions, refer to Section 2.4). As a result, (i) **eradicating the suboptimal dependence on cascade length**\(K\) has been recognized as an open problem, even within the cascading contextual bandit setting 

Further, in the context of assortment bandits, there is a widely recognized suboptimal dependence on the problem-specific constant \(\), as demonstrated in the existing assortment bandit literature . This problem-specific constant \(\) (in Assumption 4.2) represents the curvature of the multinomial logit (MNL) function. Recent studies  have demonstrated an improved dependence on \(\), albeit only multiplied by logarithmic factors. However, this improvement comes at the expense of an increased dependence on the assortment size \(M\), a conclusion that is both counter-intuitive and suboptimal. Thus, (ii) **decreasing the \(\) dependence without escalating the dependence on \(M\)** still poses an unresolved issue. While addressing either of the two challenges (i) and (ii) can be daunting individually, tackling both issues simultaneously poses an even greater challenge in both our algorithm design and regret analysis.

Figure 1: Comparisons between the cascading assortment bandit and the other combinatorial bandits. The cascading assortment bandit subsumes the multi-armed bandit (\(K=1,M=1\)), the cascading bandit (\(K>1,M=1\)), and the assortment bandit (\(K=1,M>1\)).

To this end, we design novel upper confidence bound (UCB) algorithms for contextual cascading assortment bandits, tackling both technical challenges. We show that our proposed algorithms achieve provable guarantees on regret performances overcoming the longstanding technical challenges. Our regret bounds show sharper results than those of the existing contextual cascading bandits or assortment bandits. We corroborate our theoretical claims through numerical experiments, thus ensuring that both our newly proposed bandit framework and the proposed algorithms establish provable efficiency and practical applicability.

Our main contributions are summarized as follows.

* We formulate a general combinatorial bandit model, named _cascading contextual assortment bandit_ that encompasses the existing cascading bandits and assortment bandits. This novel problem setting is observed in many practical applications.
* We first propose a UCB bandit algorithm UCB-CCA for the cascading contextual assortment bandit and establish the \(T\)-step regret upper-bound of \(}(d)\) (in Theorem 4.3). This regret bound is tighter than the existing bounds for cascading contextual bandits, where we not only remove the longstanding, unnecessary dependence on \(K\) but also establish the result without dependence on \(M\).
* While UCB-CCA is an efficient algorithm achieving both the statistical efficiency and practical performances (shown in Section 7), its regret bound includes dependence on the inverse of a problem-dependent constant \(\), which can be potentially large in the worst case. To improve the dependence on \(\), we propose our second algorithm UCB-CCA+, which exploits a new Bernstein-type concentration result, taking into account the effects of the local curvature of the MNL model. We prove that UCB-CCA+ achieves \(}(d)\) without the dependence on \(\) in the leading term (only scaling with logarithmic factors), hence significantly improving the regret of UCB-CCA without increasing the other dependencies. Hence, we successfully solve the two technical challenges (i) and (ii) mentioned above.
* As an independent contribution, we prove that a greedy algorithm for the cascading assortment optimization problem gives a 0.5 approximation of the optimal solution (discussed in Section 8). To our best knowledge, this is the first rigorous result showing the approximation guarantee even for the contextual cascading bandit problem, instead of simply assuming access to an approximation optimization oracle.
* We evaluate our proposed methods in numerical experiments and show that the practical performances support our theoretical claims. Hence, our proposed algorithms along with our newly proposed bandit model establish provable efficiency and practical applicability.

   Algorithm & Context & Cascade & Assortment & Click Model & Regret Bound \\  CombCascade  & \(\) & \(\) & \(\) & \(\) & \(}()\) \\ C\({}^{3}\)-UCB  & \(\) & \(\) & \(\) & Linear & \(}(d)\) \\ EE-MNL  & \(\) & \(\) & \(\) & MNL & \(}()\) \\ TS-MNL  & \(\) & \(\) & \(\) & MNL & \(}(d^{3/2})\) \\ UCB-MNL  & \(\) & \(\) & \(\) & MNL & \(}(d)\) \\ LinTS-Cascade  & \(\) & \(\) & \(\) & Linear & \(}(d^{3/2}K)\) \\ CascadeWOFUL  & \(\) & \(\) & \(\) & Linear & \(}(T+dTK})\) \\ VAC\({}^{2}\)-UCB  & \(\) & \(\) & \(\) & Linear & \(}(d)\) \\  UCB-CCA (Algorithm  & \(\) & \(\) & \(\) & MNL & \(}(d)\) \\ UCB-CCA+ (Algorithm  & \(\) & \(\) & MNL & \(}(d)\) \\   

Table 1: Comparisons of algorithms for contextual cascade and assortment bandits as well as for cascading contextual assortment bandits. \(N\) is the number of ground items, \(K\) is a length of cascade, \(d\) is a dimension of feature vectors and \(T\) is total rounds. \(\) is a problem-dependent parameter for the MNL model. See Appendix 0.A for more discussions.

Preliminaries

### Notation

Define \([n]\) as a set of positive integers from \(1\) to \(n\). Let \(||\) be the length of a sequence or the cardinality of a set. For a vector \(x^{d}\), we denote the \(_{2}\)-norm of \(x\) as \(||x||_{2}\) and the \(V\)-weighted norm of \(x\) for a positive-definite matrix \(V\) as \(||x||_{V}=Vx}\). The determinant and trace of a matrix \(V\) are \((V)\) and \((V)\), respectively. \(_{}(V)\) denotes the minimum eigenvalue of a matrix \(V\).

### Cascading Contextual Assortment Bandit Problem

Consider \([N]\), a set of \(N\) items. Let \(\) be a set of candidate assortments of items with size \(M\), i.e., \(:=\{A[N]:|A|=M\}\). A cascade \(S\) is an ordered sequence of \(K\) assortments chosen from \(\) where all the items in these \(K\) assortments are distinct. Then, the set of all feasible cascades \(\) can be defined as follows.

\[:=S\!=\!A_{1},...,A_{K} A_{k} k[K],_{k=1}^{K}A_{k}=}\]

At round \(t\), feature vectors \(\{x_{ti}^{d},i[N]\}\) for every item are revealed to the decision-making agent. Each feature vector \(x_{ti}\) may contain the contextual information of the user at round \(t\) and the item \(i\). After observing this contextual information, at round \(t\), the agent recommends a cascade \(S_{t}=(A_{tk})_{k[K]}\) to the user, where \(A_{tk}\) represents the \(k\)-th assortment of the cascade at round \(t\). The user scans the assortments in \(S_{t}\) one by one. If the items in \(A_{tk}\) do not attract the user, the user moves on to the next assortment \(A_{t,k+1}\). The user stops at the \(O_{t}\)-th assortment when the user is attracted by an item in the \(O_{t}\)-th assortment and clicks on the item.

After the user clicks on the item, the agent observes a sequence of user choices \(y_{t}=(y_{tk})_{k[O_{t}]}\) where a binary vector \(y_{tk}=(y_{tk0},y_{tk1},...,y_{tkM})\) represents user choices on assortment \(A_{tk}\). Let \(y_{tkm}=1\) if the \(m\)-th item \(i_{m}\) in \(A_{tk}\) is clicked by the user, and \(y_{tkm}=0\) for items that are not clicked on. For each assortment, there is an _outside option_. That is, there is a probability that the user may not click any of the items in \(A_{tk}\). If the user does not choose any items, \(y_{tk0}=1\) and \(y_{tkm}=0\) for all \(m[M]\). The user choice for each assortment is given by the multinomial logit (MNL) choice model . For this MNL model, there is an _unknown_ time-invariant parameter \(^{*}^{d}\). We define the true weight of item \(i\) in round \(t\) as \(w_{ti}^{*} x_{ti}^{}^{*}\). Also, we let the vector representation of the weights be defined as \(w_{t}^{*}(w_{ti}^{*})_{i[N]}\) for convenience.

Under this model, the user's click probability of the \(m\)-th item in \(A_{tk}\) and the probability of the outside option in \(A_{tk}\) is given respectively by

\[p_{t}(i_{m}|A_{tk},w_{t}^{*})=}^{*})}{1+_{j A_{tk}} (w_{tj}^{*})} p_{t}(i_{0}|A_{tk},w_{t}^{*})= {1+_{j A_{tk}}(w_{tj}^{*})}\]

where item \(i_{0}\) represents the outside option. The user choice \(y_{tk}\) is sampled from the multinomial distribution, \(y_{tk}1,p_{t}(i_{m}|A_{tk},w_{t}^{*})_{m=0 }^{M}}\), where the argument \(1\) indicates that \(y_{tk}\) is a single-trial sample. Hence, \(_{m=1}^{M}y_{tkm}\) is always 1. Also, we denote measurement noise as \(_{tkm} y_{tkm}-p_{t}(i_{m}|A_{tk},w_{t}^{*})\). Since \(_{tkm}\) is bounded in \(\), \(_{tkm}\) is \(^{2}\)-sub-Gaussian with \(^{2}=1/4\). It is important to note that \(_{tkm}\) across items in the same assortment is not independent due to the substitution effect in the MNL model.

The expected reward function of a combinatorial action \(S_{t}\) based on \(w_{t}^{*}\) is given by

\[f(S_{t},w_{t}^{*})=_{k=1}^{K}\{_{k=1}^{k-1}p_{t}(i_{0}|A_{tk},w_ {t}^{*})\}_{i A_{tk}}p_{t}(i|A_{tk},w_{t}^{*})=1-_{k=1}^{|S_ {t}|}p_{t}(i_{0}|A_{tk},w_{t}^{*}).\]

The formulation above is also known as the cascade model with disjunctive objective, where the user stops at the _first attractive_ item .

### \(\)-Approximation Oracle and \(\)-Regret

The exact combinatorial optimization to compute an optimal cascade of assortments can be computationally expensive. Therefore, we allow for approximate optimization. We assume that the 

[MISSING_PAGE_FAIL:5]

```
0: confidence radius \(_{t}\) and ridge penalty parameter \( 1\)
1:for\(t=1,,T\)do
2: Observe \(x_{ti}\) for all \(i[N]\)
3: Compute \(u_{ti}=x_{ti}^{}_{t-1}+_{t-1}||x_{ti}||_{V_{t-1}^{-1}}\) for all \(i[N]\)
4: Compute a candidate cascade \(S_{t}^{}(A_{tk}^{})_{k[K]}=^{}(u_ {t})\)
5: Find optimistic exposure assortment index \(k^{*}\) in \((k^{*},i^{*})=}{}| |x_{ti}||_{V_{t-1}^{-1}}\)
6: Optimistic exposure swap \(S_{t}(A_{tk})_{k[K]}\) where \(A_{tk}:=A_{tk}^{}& k=1\\ A_{t1}^{}& k=k^{*}\\ A_{tk}^{}&\)
7: Offer \(S_{t}\), and observe user feedback \(O_{t}\) and \(y_{t}=(y_{tk})_{k[O_{t}]}\)
8: Update \(V_{t} V_{t-1}+_{k=1}^{O_{t}}_{i A_{tk}}x_{ti}x_{ti}^{}\)
9: Compute the regularized MLE \(_{t}\) by solving \(_{}[_{t}()+||||_{2}^{2} ]=\)
10:endfor
```

**Algorithm 1**UCB-CCA

## 3 Algorithm: Ucb-Cca

### Upper Confidence Bounds and Confidence Set

UCB-CCA utilizes the upper confidence bounds (UCB) technique  to compute an optimistic action based on optimistic estimates of each item's weight, \(u_{ti}=x_{ti}^{}_{t-1}+_{t-1}()||x_{ti}||_{V_{t-1} ^{-1}}\) for all \(i[N]\). The confidence radius \(_{t}()\) is specified to maintain a high-probability confidence set \(C_{t}()\) for the unknown parameter \(^{*}\), although the algorithm does not explicitly compute \(C_{t}()\).

\[C_{t}():=\{^{d}:||_{t}-||_{V_ {t}}_{t}()\}.\]

Setting a proper confidence radius \(_{t}()\) can guarantee that \(^{*}\) lies within the confidence set with probability \(1-\). On the event that \(^{*} C_{t}()\), the UCB weight \(u_{ti}\) serves as an upper bound of a true weight \(w_{ti}^{*}:=x_{ti}^{}^{*}\) for every item \(i[N]\). We denote the UCB weight vector as \(u_{t}=(u_{ti})_{i[N]}\) for convenience.

### Optimistic Exposure Swapping

A distinctive element of UCB-CCA is what we call _optimistic exposure swapping_, a procedure crucial for eliminating dependence on the worst-case scanning probability, as elaborated in Section 2.4.2. This technique strategically positions the assortment containing the item with the highest uncertainty among the top \(MK\) items in the first slot of the cascade of assortments.

In each round \(t\), the \(\)-approximate oracle \(^{}(u_{t})\) outputs a _candidate_ cascade \(S_{t}^{}\), determined by the UCB weights \(u_{t}\). It is important to note that \(S_{t}^{}\) is not immediately presented to the user. Instead, after \(S_{t}^{}\) is derived using the optimization oracle \(^{}(u_{t})\), the algorithm identifies the index \(k^{*}\) of an assortment that includes the item with the largest \(||x_{ti}||_{V_{t-1}^{-1}}^{}\) in \(S_{t}^{}\).

Subsequently, the algorithm swaps the positions: the assortment \(A_{tk^{*}}^{}\) is moved to the top of \(S_{t}\), becoming \(A_{t1}\), and the initially top assortment \(A_{t1}^{}\) in \(S_{t}^{}\) is relocated to the \(k^{*}\)-th position of \(S_{t}\), now \(A_{tk^{*}}\). The positions of the other assortments remain the same, that is, \(A_{tk}=A_{tk}^{}\) for all \(k[K]\{1,k^{*}\}\). This procedure is viable as the expected reward is unaffected by the display order of assortments in the cascade, as shown in Lemma 4.5

### Regularized Maximum Likelihood Estimation

UCB-CCA computes a regularized maximum likelihood estimate of the unknown parameter \(^{*}\). The negative log-likelihood is given by \(_{t}()=-_{=1}^{t-1}_{k=1}^{O_{}}_{m=0}^{M}y_{ km } p_{}(i_{m}|A_{ k},w_{})\), where 

[MISSING_PAGE_FAIL:7]

Eliminating the dependence on \(p^{*}\) is another key element of our analysis. To this end, we first show that the order of assortments in the cascade model with the disjunctive objective does not affect the expected reward. We formalize this property in the following lemma.

**Lemma 4.5**.: _Let \(p_{k}\) be the probability that the user clicks on any item in \(A_{k}\). Given a collection of assortments \(\{A_{1},,A_{K}\}\) with probabilities \(\{p_{1},,p_{K}\}\), their order of display does not matter. Further, for every permutation \(:[K][K]\), we have_

\[_{k[K]}p_{k}_{<k}(1-p_{})=1-_{k[K]}(1-p_{k}) =_{k[K]}p_{^{-1}(k)}_{<k}(1-p_{^{-1}()} ).\]

Consolidating these key results, we proceed to bound the cumulative regret. We begin by leveraging the monotonicity of the expected reward function and the definition of the \(\)-approximate optimization oracle to bound the cumulative regret.

\[^{}(T)[_{t=1}^{T}f(S_{t}, u_{t})-f(S_{t},w_{t}^{*})] C_{K}[_{t=1}^{T}_{A _{tk} S_{t}}_{i A_{tk}}(u_{ti}-w_{ti}^{*})]\] \[ 2C_{K}[_{T}_{t=1}^{T}_{A_{tk}  S_{t}}_{i A_{tk}}||x_{ti}||_{V_{t-1}^{-1}}]=2C_{K} [_{T}_{t=1}^{T}_{k[O_{t}]}_{i A_{tk}}||x_{ti}||_{V _{t-1}^{-1}}]. \]

The second inequality is from Lemma4.4 letting \(C_{K}:=(K/(K+1))^{K+1}\). The third inequality is given by the concentration of the UCB weights (see LemmaB.3). Note that the assortment including the item with the largest value of \(||x_{ti}||_{V_{t}^{-1}}\) is always examined by the user since it is included in the first assortment of \(S_{t}\) by the optimistic exposure swapping technique as described in Section3.2. Note that a change in the order of assortments incurred by the optimistic exposure swapping does not affect the expected reward which is shown in Lemma4.5. Hence, for every round \(t[T]\), we obtain

\[_{A_{tk} S_{t}}_{i A_{tk}}||x_{ti}||_{V_{t-1}^{-1}}=_{k[O _{t}]}_{i A_{tk}}||x_{ti}||_{V_{t-1}^{-1}}. \]

Therefore, the last equality in Eq.4 is given by Eq.5. Then, we can apply the maximal version of elliptical potential lemma (see LemmaB.8) to bound the cumulative regret.

## 5 Improved Dependence on \(\)

While UCB-CCA achieves the regret bound of \(}(d)\) improving dependence on \(K\), the bound includes the problem-dependent constant \(\). This implies a potential risk of the regret bound becoming large when \(\) becomes very small. In order to circumvent this challenge, we propose a new _optimism in the face of uncertainty (OFU)_ algorithm, UCB-CCA+, which exhibits a regret bound that is independent of \(\) in the leading term. The pseudocode of UCB-CCA+ is detailed in Algorithm2.

### Algorithm: Ucb-CCA+

#### 5.1.1 Confidence Set

UCB-CCA+ computes a regularized MLE \(_{t}\), following the same procedure described in Section3.3. Then, the algorithm constructs a new confidence set centered around \(_{t}\) utilizing a Bernstein-type tail inequality for self-normalized martingales . Nevertheless, a simple adaptation of the previous approaches may incur increased dependence on \(M\). Hence, a more intricate analysis and refined algorithmic strategy are imperative to effectively address this challenge.

First, we define \(g_{t}()_{=1}^{t}_{k[O_{}]}_{i A_{ k }}p_{}(i|A_{ k},w_{})x_{ i}+_{t}\) where \(w_{t}=(w_{ti})_{i[N]}\) and \(w_{ti}=x_{ti}^{}\). We also denote the partial derivative of \(p_{t}(i|A_{tk},w_{t})\) with respect to \(w_{ti}\) as \(_{t}(i|A_{ k},w_{}) p_{t}(i|A_{tk},w_{t})p_{t}(i_{0}|A _{tk},w_{t})\). Additionally, we define the new design matrix containing local information, denoted as \(H_{t}()_{=1}^{t}_{k[O_{}]}_{i A_{  k}}_{}(i|A_{ k},w_{})x_{ i}x_{ i}^{}+ _{t}I_{d}\), and, for convenience, \(H_{t}_{=1}^{t}_{k[O_{}]}_{i A_{ k}} _{}(i|A_{ k},w_{}^{*})x_{ i}x_{ i}^{}+_ {t}I_{d}\). Then, the algorithm constructs a confidence set as below:

\[B_{t}():=\{^{d}:||g_{t}(_{t})-g_{t}( )||_{H_{t}^{-1}()}_{t}()\} \]where the confidence radius \(_{t}()\) is suitably specified to ensure that the true parameter \(^{*}\) lies in the confidence set \(B_{t}()\) with high probability. On the event of \(^{*} B_{t}()\), The following lemma bounds the weighted \(_{2}\)-norm of the difference between \(\) and \(^{*}\).

**Lemma 5.1**.: _Suppose \(^{*} B_{t}()\). Then, for any \( B_{t}()\), we have \(||-^{*}||_{H_{t}} 6_{t}()\)._

#### 5.1.2 Doubly Optimistic Exposure Swapping

UCB-CCA+ still faces the challenge outlined in Section 2.4.2. The complication is exacerbated for UCB-CCA+ as the algorithm concurrently updates two gram matrices, \(H_{t}\) and \(V_{t}\), which only contain the information of the observed items. Building upon the technique of optimistic exposure swapping detailed in Section 3.2 in each round \(t\), UCB-CCA+ assigns the assortment \(L_{t,H}\) -- containing the item with the largest uncertainty with respect to \(H_{t-1}\) among the top \(KM\) items -- to the first slot of cascade \(S_{t}\). Similarly, the algorithm places \(L_{t,V}\) -- with the item that has the largest uncertainty with respect to \(V_{t-1}\) -- in the second slot of \(S_{t}\).

### Regret Analysis of Ucb-CCA+

**Theorem 5.2** (Regret upper bound of Ucb-CCA+).: _Suppose Assumptions [_4.1_]and[_4.2_]hold, and we run UCB-CCA+ for total \(T\) rounds with \( 1\) and \(_{t}()}}{2}+}}+KM_{t}/d)^{d/2}_{t}^{-d/2} }{}+}} 2\) with \(=}\). Then, the regret of UCB-CCA+ is upper-bounded by_

\[^{}(T) C_{1}_{T}())}+}{}_{T}()^{2}d(1+ )\]

_where \(C_{1}=36\) and \(C_{2}=216(1+Me)\)._

**Discussion of Theorem 5.2**. Theorem 5.2 establishes the regret bound of \(}d\). The leading term of the regret bound is independent of \(\). Although the second term exhibits dependence on \(\), the term only scales logarithmically in \(T\), whose comparative effect diminishes as \(t\) increases compared to the leading term. Hence, the worst-case regret guarantee of UCB-CCA+ improves from that of UCB-CCA. The comprehensive proof of Theorem 5.2 is provided in the appendix.

## 6 Approximation Algorithm for Optimal Combinatorial Action

In this section, we show that computing the optimal cascade is, in general, a weakly NP-hard problem and give a (fast) polynomial time algorithm that the agent can use to compute a \(0.5\)-approximation to the optimal cascade for any weight \(w\). We assume that the MNL weights are given and consider the problem of finding the cascade that maximizes the expected reward. This is an optimization problem on selecting a sequence of \(K\) assortments with size \(M\) each from a ground set of \(N\) items. The number of feasible cascades is \(O^{K}\). In fact, we establish the following hardness result.

**Lemma 6.1**.: _For general \(M\), the optimization problem is weakly NP-hard even for \(K=2\)._

The hardness of our problem follows from the hardness result of  for a related setting of unconstrained cascade optimization where the size of each assortment can be arbitrary. In light of this hardness, we turn our attention to finding fast approximation algorithms for the problem. While there has been a lot of recent work on the unconstrained cascade optimization problem (see  and the references therein), none of the previous algorithms apply to our constrained setting (where the size of each assortment is \(M\)).

We consider the following greedy approach for the problem. Consider arbitrary weights at round \(t\), i.e. \(w_{t}=(w_{tt})_{i[N]}\), is given. We order the items in \([N]\) in decreasing order of given weights and consider the following cascade of assortments.

\[D_{1}=\{1,2,...,M\},D_{2}=\{M+1,M+2,...,2M\},,D_{K}=\{(K-1)M+1,,KM\}\]

We call these assortments "decreasing order assortments". Let \(\) denote the value of the optimal solution to the problem. We establish that showing these assortments in any possible sequences gives a good approximation to the problem.

**Lemma 6.2**.: _Let \(\) denote the overall click probability in the optimal solution. The decreasing order assortments \(D_{1},...,D_{K}\), shown in any order, have overall click probability at least \(0.5\,\)._

We present the proof in Appendix E. We also show that our algorithm is optimal for \(M=1\), which captures the classic cascade optimization problem.

## 7 Numerical Experiments

In this section, we evaluate the performances of our proposed algorithms \(\) and \(\) in numerical experiments and compare their performances with the existing combinatorial bandit algorithms \(\) and \(^{3}\)-\(\). For simulations, we generate a random sample of the unknown time-invariant parameter \(^{*}\) from \((0,1)\) at the beginning of the simulation. We sample \(N\) feature vectors from \((0,1)\) in each round \(t\). At each round \(t\), the oracle computes a sequence of assortments in decreasing order, forming a cascade \(S_{t}\) based on given \(w_{t}\). We assess the cumulative regret of \(\), \(\), \(\), and \(^{3}\)-\(\). Note that a user's choice for \(\) and \(\) is determined by the MNL logit choice model, whereas \(^{3}\)-\(\) utilizes a linear model and \(\) is a non-contextual model. Figure 2 and Figure 2 indicate that both \(\) and \(\) significantly outperform \(^{3}\)-\(\) and \(\). We also observe that \(\) shows a slight performance advantage over \(\), although the difference is not statistically significant. While \(\) has a sharper worst-case regret guarantee, \(\) can provide favorable practical performances, with simpler implementation and computational efficiency.