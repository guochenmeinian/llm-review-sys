# Towards a fuller understanding of neurons with Clustered Compositional Explanations

Biagio La Rosa

Sapienza University of Rome

Rome, IT 00185

larosa@diag.uniroma1.it &Leilani H. Gilpin

University of California, Santa Cruz

Santa Cruz, CA 95060

lgilpin@ucsc.edu Roberto Capobianco

Sony AI

Schieren, CH 8952

roberto.capobianco@sony.com

###### Abstract

Compositional Explanations  is a method for identifying logical formulas of concepts that approximate the neurons' behavior. However, these explanations are linked to the small spectrum of neuron activations (i.e., the highest ones) used to check the alignment, thus lacking completeness. In this paper, we propose a generalization, called _Clustered Compositional Explanations_, that combines Compositional Explanations with clustering and a novel search heuristic to approximate a broader spectrum of the neuron behavior. We define and address the problems connected to the application of these methods to multiple ranges of activations, analyze the insights retrievable by using our algorithm, and propose desiderata qualities that can be used to study the explanations returned by different algorithms.

## 1 Introduction

Explainable AI (XAI) promises to foster trust  and understanding in AI systems. This is particularly important for deep learning (DL) models, which are not understandable. By using XAI methods, we may be able to interpret and better understand the underlying DL processes . Indeed, it is still unclear what kind of knowledge these models learn and how they are able to achieve high performance across many different tasks.

This paper focuses on the methods that explain what neurons learn during the training process. Most of these approaches adopt the idea of investigating what kind of information overstimulates a neuron. For example, generative approaches iteratively change the input features to maximize the neuron's activation  or dataset-based approaches select samples where the neuron activates the most . Among them, we are interested in methods that use concepts to explain neurons' behavior. The seminal work of the area is Network Dissection (NetDissect) . NetDissect proposes to use a dataset annotated with concepts to probe the neuron and select, as an explanation, the concept whose annotations are aligned (i.e., overlap) the most with the highest activations. While initially proposed for quantifying the latent space's interpretability, NetDissect has been extensively used for describing and understanding the concepts recognized by neurons .

Compositional Explanations  (CoEx) generalize NetDissect by extracting logical formulas in place of single concepts, using a beam search over the formulas space. While in principle, these algorithms could be applied to any activation, the current literature  focuses only on the exceptionally high activations (i.e., activations above the 0.005 percentile). We argue that using anarbitrarily high value for the threshold gives us only a partial view of the concepts recognized by a neuron. For example, when these algorithms are used to compare the interpretability of latent space, they can flag as uninterpretable a latent space that is interpretable at lower activations, or vice-versa. When used for downstream tasks  the results of these techniques can easily mislead users, mining their trust into explainability . Moreover, in preliminary experiments, we observe that the network uses multiple ranges of activations in the decision process (Appendix E) and that threshold variations lead to different explanations and that the lowest and highest activations react differently to the variation, being associated with different categories of explanations (Figure 2 and Appendix F), thus suggesting that current approaches provide a partial view.

ContributionsThis paper contributes a generalization of CoEx at different activation ranges. Our insights provide a more detailed description of the neurons behavior. In order to illuminate this problem, we mathematically describe and mitigate the issues connected to the computation of explanations for a broader range of activations. We propose an algorithm (_Clustered Compositional Explanations_), heuristic (_MMESH_), and qualities ready to be used to study and analyze the returned explanations. In detail, we: (i) propose a faster algorithm to compute compositional explanations based on a heuristic; (ii) provide an analysis of a wider spectrum of activations by clustering them and applying our algorithm to the clusters; (iii) extract and discuss the novel insights on image data retrieved from our analysis, namely the presence of _unspecialized activations_ and the phenomenon of _progressive specialization_; (iv) collect and identify desirable qualities for this kind of explanation; we also propose three novel ones: sample coverage, activation coverage, and label masking. The code is available at [https://github.com/RRLGroup/Clustered-Compositional-Explanations](https://github.com/RRLGroup/Clustered-Compositional-Explanations).

The manuscript is organized as follows: Section 2 describes related work; Section 3 describes our proposed generalization and desiderata properties; Section 4 analyzes and discusses the proposed generalization and insights retrievable by it. The code will be released upon acceptance.

## 2 Related Work

According to the recent surveys on the topic of explaining individual neurons , we can distinguish between feature synthesis and dataset-based approaches. The former aims at generating

Figure 1: Compositionality captured at different ranges (right side) by unit #1. The left side includes five randomly extracted images inside the range and the labels assigned by our algorithm. Figure 2: Threshold impact on the category of the returned labels. We can observe that lowering the threshold penalizes some label categories and rewards others. Moreover, given the same threshold, the results change if we apply the threshold starting from the highest activations (left) or lowest activations (right).

inputs that maximally (or minimally) activate a neuron [37; 26; 11] either using DNNs [33; 35] or iterative algorithms [11; 37]. Despite their popularity, these methods face several challenges: the abstraction of the output; they can encode few patterns [34; 37]; the process is stochastic and thus one can get two different visualizations for the same neuron . These problems are addressed by dataset-based approaches, which take a different route and are more effective in helping users .

Dataset-based approaches select samples from a dataset where the activation of a neuron is above a given threshold . The advantage is that, by simply looking at the selected samples, one can infer the multiple features detected by the neuron, avoiding the problem of diversity and abstraction. However, the samples-selection can lead to different problems. For example, it becomes difficult to distinguish between causal and merely correlated factors (e.g., is the neuron recognizing only planes or planes into the sky?), and the returned explanations depend on the used dataset .

The first problem can be mitigated by looking at concepts instead of entire samples. A concept is a set of semantically related features annotated in a sample. In this case, one can probe for a specific concept to find the neurons responsible for detecting it [8; 10; 18; 1; 31] or fix the neuron and select the concepts where the neuron returns the highest activations [16; 2; 4; 30]. Our work can be placed in dataset-based approaches of the second category. Among them, the work of Bau et al. [2; 4] proposes to select the concept whose annotations are the most aligned to the neuron's activations. To capture more facets of the same activations, Mu and Andreas  propose to select logical formulas of concepts instead of a single one using a beam search that extracts the best-aligned formula. The process to extract the logical formulas can be modified to include more operators , ontologies , or to impose constraints [16; 27]. Our work generalizes both of these works by associating logical formulas with multiple activation ranges per neuron. With respect to these works, our proposed method uses a heuristic search in place of an exhaustive search, uses clustering to compute thresholds instead of using a fixed ad-hoc threshold, and considers multiple intervals of activations and thus the full spectrum of the neuron's activations.

Finally, the problem of dataset dependency has been the focus of recent work, which propose to get natural language explanations by using captioning methods  or multimodal models . With respect to this set of approaches, our paper can be considered orthogonal, since the clustering mechanism and the analysis of a wider range of activation can be used as a starting point for these works. We leave the investigation of this direction for future research.

Most of the works described in this section use the intersection over union score [2; 4; 30; 27] and its variants [28; 16] to quantitatively test the quality of the returned explanations. The idea is that if a method discovers a different set of explanations with a higher score, then it discovers more effective directions on the interpretability of the unit. Other metrics used in literature are usually tailored to properties of the proposed methods ( ), the goal of the extension () or they are used to verify properties of the models ). To contribute to the analysis of these explanations, we collect two quantitative metrics from the literature, and we propose three additional ones that are general enough to be applied to any dataset-based approach similar to NetDissect and CoEx. While each of them gives us some information, we argue that only by looking at all of them simultaneously one can have a clear view of the difference between explanations returned by different approaches.

## 3 Algorithm

This section describes our proposed Clustered Compositional Explanations and the heuristic used for making the algorithm practically feasible. Additionally, it describes the desiderata properties of the output of these algorithms. Below, we introduce the terminology used in the rest of the paper:

* \(\): a dataset annotated with concepts \(C\);
* \(^{l}\): the set of logical connections \(L\) of arity \(l\) that can be built between concepts of \(\);
* \(L_{}^{l-1}\) and \(L_{}^{1}\) denotes the left side and the right side of a label of arity \(i\) obtained by adding an atomic term to the label at each step, respectively;
* \(S(x,L)\): a function that returns the binary mask of the input \(x\) for the label \(L\);
* \(A^{k}(x)\): the activation map of the \(k\) neuron when the input is the sample \(x\); 1* \(M_{[_{1},_{2}]}(x)\): the function that returns a binary mask of the activation \(A^{k}(x)\), setting to 0 all the values smaller than \(_{1}\) or greater than \(_{2}\);
* \(n_{s}\): the maximum size of the segmentation;
* \((x,L)\): a function that masks the input \(x\) by keeping only the features connected to the label \(L\) visible;
* \(IMS_{[_{1},_{2}]}(x,L)\): the intersection size between the label mask \(S(x,L)\) and the neuron's activation mask \(M_{[_{1},_{2}]}(x)\) computed over the activation range \((_{1},_{2})\).

Moreover, we represent a binary mask as the set of the indices of its elements equal to 1. Thus \(M_{[_{1},_{2}]}(x,L)\) can be represented by the cardinality \(|M_{[_{1},_{2}]}(x,L)|\).

### Clustered Compositional Explanations

Clustered Compositional Explanations generalize CoEx  and NetDissect  by computing explanations on multiple intervals of activation thresholds. We begin the description by recalling the objective of NetDissect  and CoEx .

NetDissect  extracts the single concept whose masks overlap the most with the binary activation mask. Network Dissection uses a single threshold (\(^{top}\)) to compute the activation mask. Conventionally, \(^{top}\) is set to the top 0.005 quantiles for each unit k, i.e., \(^{top}\) is determined such that \(P(a_{i}^{top})=0.005,\  a_{i} A^{k}()\). Therefore, the objective can be written as:

\[C^{best}=*{arg\,max}_{C^{1}}IoU( ^{1},^{top},,) \]

NetDissect proposes an exhaustive search over the full search space of all the concepts in order to select the best explanation.

CoEx Algorithm generalizes the NetDissect algorithm by considering logical formulas of arity \(n\) in place of single concepts. Therefore, the objective is changed to:

\[L^{best}=*{arg\,max}_{L^{n}}IoU( ^{n},^{top},,) \]

When the number of concepts or the dataset size is large enough, the computation of an exhaustive search becomes prohibitive. To solve the issue, Mu et al.  propose to use a beam search of size \(b\). At each step \(i\), only the \(b\) best labels of arity \(i\) are used as bases for computing labels of arity \(i+1\). The first beam is selected among the labels associated with the best scores computed by NetDissect. Ignoring for simplicity the time needed to compute the masks for the labels, it is clear that the CoEx algorithm needs at least \((n-1) b\) times the time needed for running NetDissect.

Clustered Compositional Explanationsgeneralizes CoEx by returning a set of logical formulas by identifying \(n_{cls}\) clusters into the activations of the \(k\) neuron and computing the logical formula that better describes each cluster (i.e., the one that maximizes the IoU score) (Figure 1). Specifically, the algorithm finds the solution to the objective

\[L^{best}=\{*{arg\,max}_{L^{n}}IoU(L, _{i},_{j},),[_{i},_{j}] \} \]

where

\[IoU(L,_{1},_{2},)=}|M_{[_{1},_{2}]}(x) S(x,L)|}{_{x }|M_{[_{1},_{2}]}(x) S(x,L)|} \]

and

\[=\{[min(Cls),max(Cls)], Cls Clustering(A^{k} ())\} \]

\(Clustering(A^{k}())\) returns \(n_{cls}\) disjoint clusters of the non-zero activations of the \(k\) neuron over the whole dataset, and \(T\) is the set of thresholds computed by selecting the minimum and maximum activation inside each cluster. When setting \(T=[^{top},]\), the objective is equivalent to the CoEx algorithm (eq. (2)), while by setting \(T=[^{top},]\) and \(L^{n}\), one can obtain the NetDissect objective (eq. (1)). The CoEx algorithm extracts compositional explanations by iteratively applying NetDissect to a beam search tree of width \(b\) and deepness \((n-1)\). Thus, since the algorithm applies CoEx on \(n_{cls}\) clusters, the vanilla implementation would require \(n_{cls}(n-1) b\) times the computation time of NetDissect. Even employing a parallelization of the computation over units, the base required time and some practical problems2 arising from the wider considered ranges make the application of the CoEx algorithm practically unfeasible when dealing with multiple clusters.

Min-Max Extension per Sample HeuristicTo solve this problem, we propose a beam search guided by a novel, admissible heuristic. Specifically, we propose the _Min-Max Extension per Sample Heuristic_ (**MMESH**). Given a sample \(x\), a neuron \(k\), and a label \(L^{i}\), the heuristic estimates the IoU score by combining the following information: the size of the label mask on the sample \(S(x,L)\); the coordinates to identify the smallest possible extension of the concept on the sample (i.e., the longest contiguous segment including only concept elements); the coordinates to identify the largest possible extension of the concept on the sample \(maxExt(x,L)\); the size of the intersection between the label's terms mask and the neuron's activation on the sample \(IMS(x,t) t L\).

The first three pieces of information are computed and collected directly from the concept dataset, while the intersection size is collected during the execution of the first step of CoEx for all \(L^{1}\) and before expanding the best labels in the current beam for all their terms \(t^{i-1}\). Note that the shape of the coordinates depends on the data type of the concept dataset. In our case (image data), \(minExt(x,L)\) and \(maxExt(x,L)\) correspond to the top left and bottom right corners of the largest inscribed rectangle inside the polygon and the largest rectangle patch applied to cover the polygon drawn from the concept's segmentation (i.e., _bounding box_), respectively (Figure 3). MMESH provides an estimation for logical formulas connected by OR, AND, and AND NOT operators and their specialization , which are the most used operators .

Specifically, the heuristic uses the best-case scenarios for the intersection and the worst-case scenario enhanced by the coordinates for the label's mask to estimate the IoU score. In formulas:

\[ IoU(L,_{1},_{2},)& =}{}=} }}{_{x}}}=\\ &=}}{_{x}|M_{[_{1}, _{2}]}(x)|+_{x}||-}} \]

where

\[_{x}=\{ min(|IMS_{[_{1},_{2}] }(x,L_{})|+|IMS_{[_{1},_{2}]}(x,L_{})|,|M(x)|)& op=OR\\ min(|IMS_{[_{1},_{2}]}(x,L_{})|,|IMS_{[_{1},_{2}]}(x,L_{})|)& op=AND\\ min(|IMS_{[_{1},_{2}]}(x,L_{})|,|M_{[_{1},_{2}]}(x)|-|IMS_{[_{1},_{2}]}(x,L_{})|)& op=AND \ NOT. \]

Figure 4: Visualization of activations associated with different clusters. Activations are visualized from the lowest (left, Cluster 1) to the highest ones (right, Cluster 5).

Figure 3: Visualization of information used by MMESH: the size of the concept mask (white), size of the intersection (yellow), minimum extension (red bounding box), maximum extension (blue bounding box).

\[=\{max(|S(x,L_{})|,|S(x,L_{ })|, L_{})}),&op=OR\\ max(MinOver(L),I_{x})&op=AND\\ max(|S(x,L_{})|-MaxOver(L),I_{x})&op=AND\ NOT. \]

In the previous formulas, \(op\) is the logical connector of the formula, \(L_{}^{i-1}\) denotes one of the best labels retrieved in the current beam, \(L_{}^{1}\) denotes the candidate term to be connected through \(op\) to the label as the right side, \(MaxOver(L)\) is a function that returns the maximum possible overlap between the largest segments marked by the coordinates \(maxExt(x,L_{})\) and \(maxExt(x,L_{})\), \(MinOver(L)\) is a function that returns the minimum possible overlap between the smallest segments marked by the coordinates \(minExt(x,L_{})\) and \(minExt(x,L_{})\), and \(S(x,L_{} L_{})=|S(x,L_{})|+|S(x,L_{ })|-MaxOver(L))\).

Since \(_{x}\) must be an overestimation of \(I\), eq. (7) corresponds to the best-case scenario for OR labels (i.e., disjoint masks) and eq. (8) and eq. (9) correspond to the best-case scenario for fully overlapping masks in the case of AND and AND NOT labels. Conversely, since \(\) must underestimate the real label's mask and thus cover the worst-case scenario, it assumes fully overlapping maps for OR labels and disjoint maps for AND and AND NOT operators. Note that in the case of AND and AND NOT, the coordinates for the label's mask (i.e., minimum possible overlapping between polygons generated by the coordinates) help us to avoid setting it \(\) to 0. We prove that this heuristic is admissible (Appendix A.1); thus, the heuristic search is guaranteed to find the optimal formula inside the beam.

### Desiderata Qualities

This section describes a set of statistics and metrics that can be used to describe the qualities of the returned explanations. As mentioned in the previous sections, compositional explanations are commonly analyzed by looking at their IoU score. However, IoU can be artificially increased by increasing the formula's length [30; 27]. Conversely, we promote the simultaneous usage of a set of metrics to have the full view of the efficacy of a method, since each of them has its weak spot when taken in isolation. Additional and alternative statistics are listed in Appendix D.

Intersection Over UnionThe metric optimized by the approaches considered in this paper. It measures the alignment between labels' annotations and activation maps (eq. (4)). Given the activation range \((_{1},_{2})\), a higher IoU means the algorithm can better capture the pre-existent alignment .

Detection AccuracyThe percentage of masks of the label \(L\) overlapping with the neuron activation inside the activation range \((_{1},_{2})\). A value closer to one means that most of the label's masks are usually recognized by the neuron in that activation range.

\[DetAcc(L,_{1},_{2},)=}|M_{[ _{1},_{2}]}(x) S(x,L)|}{_{x}|(S(x,L)|} \]

Samples CoverageThe percentage of samples satisfying the label where the neuron activation is inside the activation range \((_{1},_{2})\). A value closer to one means that the neuron usually recognizes the concept using that activation range.

\[SampleCov(L,_{1},_{2},)=:|M_{[ _{1},_{2}]}(x) S(x,L)|>0\}|}{|\{x:|(S(x,L)|>0\}|} \]

Activation CoverageThe percentage of neuron activations inside the activation range \((_{1},_{2})\) overlapping with the label's annotations. A value closer to one means that the label captures most of the behavior of this type of activation (i.e., there is a strong mapping).

\[ActCov(L,_{1},_{2},)=}|M_{[ _{1},_{2}]}(x) S(x,L)|}{_{x}|M_{[_{1}, _{2}]}(x)|} \]Explanation CoverageThe percentage of dataset samples covered by the explanations, i.e., samples that satisfy the explanation's label and where the neuron fires inside the activation range \((_{1},_{2})\). A value closer to one means that the neuron fires at the given activation range when the input includes the explanation's label. Thus, there is a strong correlation between the label and the activation range.

\[ExplCov(L,_{1},_{2},)=:|M_{[_ {1},_{2}]}(x) S(x,L)|>0\}|}{|\{x:|M_{[_{1},_{2} ]}(x)|>0\}|} \]

Label MaskingThe cosine similarity computed by comparing the neuron's activations when the model is fed by using the full input \(x\) and the masked input \((x,L)\). A high score indicates a strong connection between the label and the activation range. Note that we only keep track of the changes in the regions identified by the activation range \(_{1},_{2}\).

\[LabMask(L,_{1},_{2},)=}Cosine Sim(M_{[_{1},_{2}]}^{k}(x)A^{k}((x,L)),M_{[_{1},_{2}]} ^{k}(x)A^{k}(x))}{|\{x:|M_{[_{1},_{2}]}(x)|>0\}|} \]

## 4 Analysis

### Setup

For the experiments in this section, we follow the same setup of Mu and Andreas  with the addition of the set of thresholds used to compute the activation ranges. We fix the length of the explanation to 3, as commonly done in the current literature [28; 27]. For space reasons, in almost all the experiments in this section, we report the results using the last layer of ResNet18  as a base model and Ade20k [44; 46] as a concept dataset. However, the claims hold across different architectures and concept datasets, as reported in Appendix B. We use K-Means as a clustering algorithm and fix the number of clusters to five. The choice of K-Means is motivated by the need for a fast clustering algorithm that aggregates activations associated with a shared semantic and that can be applied to a large quantity of data (see Appendix G for further details about the choice of the clustering algorithm). The number has been set to five because a higher number of clusters returns almost the same labels but repeated over more clusters, and, on average, the scores are lower (Appendix C).

### Heuristic Effectiveness

This section compares the number of labels for which the algorithm computes the true IoU (_visited states_) needed by the vanilla CoEx algorithm, our heuristic, and alternative heuristics.

We select and test three heuristics using different amounts of the needed information to estimate the IoU score: the vanilla CoEx algorithm where no heuristics are used (_CoEx_); a heuristic that uses only the size of the label masks per sample (_Areas_); the _Coordinates-Free Heuristic_ (_CFH_), an ablated version of our proposed heuristic that does not estimate the size of the label's mask; and our proposed heuristic (_MMESH_). Refer to Appendix A.2 for further details about the baselines.

Table 1 compares the average number of states visited during the computation of the baselines and our MMESH. The results are computed over 100 randomly selected units fixing \(T=[^{top},]\) as

   Heuristic &  & Visited States \\  CoEx & - & - & \(39656 12659\) \\ + Areas & - & ✓ & \(23602 3420\) \\ + CFH & ✓ & ✓ & \(5990 3066\) \\ + MMESH & ✓ & ✓ & \(129 712\) \\   

Table 1: Avg. and standard deviation of visited states per unit. Results are computed for 100 randomly extracted units.

[MISSING_PAGE_FAIL:8]

behave similarly to Cluster 5, but progressively improve the Sample Coverage, IoU, and Explanation Coverage. Therefore, the insight extracted for Cluster 5 holds also for them and, as we discuss in the next section, it is connected to the property of specialization.

In summary, extracting compositional explanations at different and wider activation ranges maintains or improves the same qualities of the returned explanations. Additionally, the combination and analysis of different qualities simultaneously allow us to extract a bigger view of the compositionality of neuron activations, providing hints ready to be exploited by further analyses.

### Neurons Compositionality

In this section, starting from the results reported in the previous section, we analyze the compositionality of neurons at a wider range of activation.

Unspecialized Activations.As previously discussed, Cluster 1 and Cluster 2 are associated with a high Sample Coverage, meaning that they almost cover the full dataset. Therefore, the labels should be present in almost all the samples. By inspecting the labels, we observe that they are often a union of colors (i.e., Black OR Blue OR Grey) or a mix of colors and general concepts (i.e., Black OR Blue OR Sky), and few labels are repeated over the whole range of neurons. While the first observation can suggest that they recognize general concepts or colors, the second one goes in the opposite direction. To investigate the phenomenon, we applied our algorithm on untrained networks, finding that all the clusters are associated with these kinds of labels in this case. Thus, these labels represent the _default labels_ to which the algorithm converges when the activations are random. We call the activations ranges associated with such labels _unspecialized_, meaning that neurons do not recognize specific concepts or purposely ignore the concepts covered by the activation. By analyzing the clusters from one to five, we found (Table 3) that Cluster 1 is almost always associated with unspecialized

    & ReLU & Cluster 1 & Cluster 2 & Cluster 3 & Cluster 4 & Cluster 5 \\   & Yes & 0.93 & 0.37 & 0.01 & 0.00 & 0.00 \\  & No & 0.05 & 0.60 & 0.95 & 0.30 & 0.05 \\  & Yes & 0.00 & 0.03 & 0.01 & 0.01 & 0.00 \\  & No & 0.05 & 0.12 & 0.02 & 0.17 & 0.02 \\   

Table 3: Percentage of unspecialized and weakly specialized activation ranges in ResNet18 (ReLU Yes) and DenseNet161(ReLU No) over 128 randomly extracted units.

Figure 5: Examples of specialization (left) and polysemy (right). Neuron #455 (left) recognizes streets in more and more specific contexts through the clusters. Neuron #368 (right) recognizes unrelated concepts among different activation ranges (windmill, closet, amusement park).

activations and Cluster 2 half of the time. This phenomenon can also be partial, meaning that the first part of the label is assigned to a default label, but the last part converges on a different concept. In this case, we call these activation ranges _weakly specialized_. They are rare, especially in ReLU networks, and usually appear only in the clusters near the unspecialized ones. We hypothesize that they are a side effect of the clustering algorithm, and a future clustering algorithm tailored to extracting the best activation ranges could reduce their number. Table 3 also shows a similar behavior of ReLU and non-ReLU networks when the activations are close to 0. In ReLU layers, activations are stored in Cluster 1, and they are unspecialized 93% of the time. This percentage becomes smaller when we approach the higher clusters. We can observe a similar behavior in the case of the layer without ReLU. In this case, since the activations can assume negative values, the activations close to zero are stored in the middle clusters, and thus, Cluster 3 includes unspecialized activations 95% of the time. And again, when we move far away from zero, the percentage starts to decrease, as in the ReLU layers.

Progressive Specialization.Progressive specialization is a phenomenon we observe in association with ReLU layers, where lower activations recognize more general concepts (e.g., building, sky, etc.), and higher ones progressively detect more complex objects. The phenomenon is similar to the one observed by Zhou et al. , in which the lower layers of a neural network detect more abstract concepts while the latest detect the most complex and specific ones. In the case of image data, this phenomenon seems to be also spatially aligned, meaning that lower activations capture external elements surrounding the objects detected by higher activations (Figure 4). The specialization property highlighted by Mu and Andreas  is an example of specialization (Figure 5).

Activation PolysemyFollowing Mu and Andreas , we manually inspected 128 randomly extracted units to analyze the relations among concepts inside the returned labels and among activation ranges. A _polysemic_ neuron is the one that fires for unrelated concepts . Mu and Andreas  found that 31% of neurons are polysemic in the highest activation ranges. We explore the polysemy considering the full range of activations, meaning that a neuron is considered non-polysemic only if all the labels associated with the clusters are related. While, as expected, the number of polysemic neurons is much larger (~85%), it is interesting to note that ~15% of neurons fire for related concepts at any activation range, meaning that they are _highly specialized_.4

## 5 Limitations and Future Work

This paper presented a first step towards a fuller understanding of neurons compositionality. We introduced Clustered Compositional Explanation, an algorithm that clusters the activations and then applies the CoEx algorithm guided by heuristics to them. Using our algorithm, we found and analyzed novel phenomena connected to the neuron's activations, such as the unspecialization of the lowest activations in ReLU networks and the progressive specialization. Despite the progress, there are some limitations of the current design. First, the labels returned by our algorithm are deeply connected to the activation ranges identified by the clustering algorithm. Therefore, future work could analyze the differences among different clustering algorithms or develop a novel one tailored to the given task. The extracted insights refer to the image data case. While the heuristic and the approach are domain agnostic, the application on a different domain could extract different kinds of insights, thus limiting or confirming the generality of the findings of Section 4.4. We hypothesized that looking at the scores of each cluster can uncover a deeper understanding of the behavior of different activation ranges. However, an interesting direction could be the development of weighting mechanisms to weight the contribution of each cluster to the final averaged scores, which is desirable when the number of clusters is high and looking and comparing individual cluster can become problematic. Finally, the specific labels returned by these algorithms are linked to the concept dataset used to probe the neurons, as observed by Ramaswamy et al. . While the general insights hold even when changing the dataset (Appendix B.2), we do not address the problem of returning the same specific labels across different datasets. Other than mitigating the above-mentioned limitations, future work could also explore the application of the heuristic to study the optimality of the returned explanations, or the application of clusters on recent methods for reducing the dependency on the concepts datasets .