# Bayesian Sequential Batch Design in Functional Data

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Many longitudinal studies are hindered by noisy observations sampled at irregular and sparse time points. In handling such data and optimizing the design of a study, most of the existing functional data analysis focuses on the frequentist approach that bears the uncertainty of model parameter estimation. While the Bayesian approach as an alternative takes into account the uncertainty, little attention has been given to sequential batch designs that enable information update and cost efficiency. To fill the gap, we propose a Bayesian hierarchical model with Gaussian processes which allows us to propose a new form of the utility function based on the Shannon information between posterior predictive distributions. The proposed procedure sequentially identifies optimal designs for new subject batches, opening a new way for incorporating the Bayesian approach in finding the optimal design and enhancing model estimation and the quality of analysis with sparse data.

## 1 Introduction

Many of the longitudinal studies suffer from noisy observations. It is often the case that only a small number of irregularly spaced observations can be taken for each subject, making it a sparse dataset for the subsequent analysis (Zeger and Diggle, 1994; Brumback and Rice, 1998; Guo, 2004; Yao et al., 2005). In light of this issue, functional data analysis (FDA) has been developed as one of the most popular methods to handle such data and enhance the quality of estimation. In particular, as the sparse observations can only provide limited information for recovering the underlying trajectory, FDA offers an effective way to optimize the design of a study by judiciously selecting optimal time points for taking observations.

Existing FDA literature has mostly focused on rather a frequentist approach that considers the "best guess" of parameters to find an optimal design (Ji and Muller, 2017; Park et al., 2018; Rha et al., 2020). However, this approach oftentimes bears uncertainty of the model parameter estimation and can possibly hinder the quality of analysis. A Bayesian approach, on the other hand, takes into account this uncertainty and conducts the analysis based on a prior distribution of the parameters (Chaloner and Verdinelli, 1995). Specifically, a Bayesian hierarchical model assumes a common mean function for the underlying subject trajectories, enabling us to borrow the strength of all observations across subjects to recover the trajectories. (Yang et al., 2016)

Ryan et al. (2015) proposed the fully Bayesian static design for mixed effect model to determine sampling time points for precise estimation of the model parameters. Nevertheless, the static design uses the same design throughout the experimental process without accounting for any incoming information that may be collected during the experiment (Ryan et al., 2016). In this regard, a sequential design may offer more efficient and flexible design schemes as it updates the optimal design at each stage with new information provided from the previous stages. (Chaloner, 1986; Muller et al., 2007). Yet scant work has been done on constructing Bayesian hierarchical models

[MISSING_PAGE_FAIL:2]

Utility Function and Optimal Sequential Batch Design

Conventional sequential design approach adopts one-step-look-ahead method that only considers the next subject, which is often not optimal. Static design approach determines the optimal design in a holistic view but uses the same fixed protocol throughout the experiments. To combine the best of two worlds, we adopt a sequential batch scheme. We consider the problem of multistage design that sequentially finds optimal sampling times for a new batch of subjects based on the information obtained from observations of existing subjects from previous stages. For demonstration purposes, we only display the utility function for one future stage. However, by including new observations with the obtained optimal design at the current stage, one is able to update the optimal design criterion and acquire new optimal designs for all future stages in a sequential manner.

For the experiments, we assume that observations can be taken on an equally-spaced common grid that has \(T_{0}\) time points. Yet, for each subject, only \(k(<T_{0})\) observations can be taken. Before stage \(1\), we assume that an experiment is already conducted and observations \(_{0}=\{_{1}(_{i}),,_{N}(_{i})\}\) for \(N\) subjects are taken based on a fixed design \(_{0}=\{_{1},,_{N}\}\). Suppose we are now at stage \(1\) and we are to recruit a new batch of \(M(>1)\) subjects and take observations \(_{1}=\{_{N+1}(_{i}),,_{N+M}(_{i})\}\) from these subjects according to a design \(_{1}=\{_{N+1},,_{N+M}\}\). Here, we consider the batch size \(M\) and the number of observations per subject \(k\) to be fixed. Our attempt is to find the optimal design \(_{1}\) that achieves two goals: (1) the newly-added observations based on \(_{1}\) should provide more information to update the posterior mean function so as to improve the recovery of underlying trajectories \(_{0}\) for the existing subjects \(1,,N\); (2) the observations based on \(_{1}\) should also provide sufficient information for the estimation of new batch of subject trajectories.

Specifically, when recovering the trajectories of existing and new subjects, we focus on the trajectory values at unobserved time points, denoted by \(^{c}\). We would like to compare the posterior predictive distributions \(p(^{c}_{0},^{c}_{1}|_{0})\) of \(^{c}_{0}\) and \(^{c}_{1}\) given the information from existing subjects to the posterior predictive distributions \(p(^{c}_{0},^{c}_{1}|_{0},_{1,_{1}})\) of \(^{c}_{0}\) and \(^{c}_{1}\) given the information from existing subjects and the new batch of subjects. That is, we would like to maximize the improvement in prediction of \(^{c}\) before and after including the new batch of subjects.

We consider an information-based approach and measure the improvement by Kullback-Leibler (KL) divergence, which is a classic metric in information theory that measures the difference between two distributions. Therefore, we propose the following utility function as the optimal design criterion:

\[U(_{1},_{0})=D_{KL}(p_{1}||p_{0})=(}{p_{0} })dp_{1}, \]

where we denote by \(p_{0}=p(^{c}_{0},^{c}_{1}|_{0})\) and \(p_{1}=p(^{c}_{0},^{c}_{1}|_{0},_{1,_{1}})\), which are both multivariate normal distributions under our model framework.

To evaluate the above utility function, we consider a combination of implementing the predictive formula of Gaussian process and using empirical Bayes procedure for the rest of model parameters to obtain a closed-form solution for the utility function. Concerning the page limit, we refer the readers to Appendix A for the detailed derivation. This closed-form solution facilitates computational efficiency by avoiding the evaluation of intractable marginal likelihood in the utility function as commonly seen in many optimal Bayesian design problems.

## 4 Computation

Because of the closed-form solution of the utility function in Section 3, it is easy to evaluate the utility function with a given design. Yet, the design space remains large as we are exploring optimal designs for a batch of subjects simultaneously. Therefore, we implement a simulated annealing (SA) algorithm (Van Laarhoven et al., 1987) that enables efficient exploration of large and complex design spaces and easy implementation. Specifically, the SA algorithm is used at every stage such that it incorporates existing and new information from all previous and current stages and finds optimal design for the next stage in a sequential manner.

The SA algorithm starts with an initial "temperature" \(T_{initial}\) and a randomly generated design \(_{initial}\). The "energy" \(e\) of this design is then computed based on the utility function defined in Equation (2). Then the algorithm generates another candidate design \(_{test}\) from the "neighborhood"of \(_{initial}\) and calculates its energy \(e_{test}\). If the difference between two energies \( e=e-e_{test} 0\), the candidate design \(_{test}\) is accepted and the algorithm will continue to compare it to other neighborhood designs. At the current temperature \(T\), if \( e>0\), the candidate design is accepted with a probability of \(\). This process is repeated until no further improvements can be made within a maximum number of iterations. Then the temperature will be lowered according to a "cooling schedule" and the whole procedure will be repeated again. Finally, we follow the approach proposed by Aragon et al. (1991) to terminate the algorithm if the acceptance probability is smaller than some threshold \(P_{threshold}\).

In the algorithm, a number of parameters, initial temperature, cooling schedule, neighborhood of a design, maximum number of iterations, and acceptance threshold, require initial values. Nevertheless, as the SA algorithm is a heuristic algorithm, the parameter values heavily depend on the problem settings and experiment setup. Therefore, we also set the parameter values in a heuristic way so as to be able to adapt to different scenarios. Based on suggestions in Van Laarhoven et al. (1987), we set the initial temperature \(T_{initial}\) to be \( e/(0.7)\) so that the initial acceptance probability for designs with \( e>0\) is 0.6. This is to limit the time spent at high temperatures. The cooling schedule is an exponential decaying function of the temperature \(T_{new}=0.95 T_{old}\).

For the neighborhood of a design, there are many choices, such as changing only one time point for one subject in the batch or changing one set of time points for one subject in the batch. However, the candidate set for the former can easily increase exponentially with different time grid and observation sizes and it is also suspected that a single time point can make much difference on the trajectory recovery of all subjects. Thus, considering computation efficiency, we define the neighborhood of a design by changing one set time points from one subject in the batch. Here we propose to set the maximum number of iterations to be 10 and the acceptance threshold to be \(0.2\), as suggested in Aragon et al. (1991). As noted before, since the SA algorithm is a heuristic approach that is contingent upon a specific problem, empirical tuning on the initial parameters is necessary when conducting different experiments. A pseudo code that illustrates the structure of the algorithm can be found in Appendix B.

## 5 Discussion

To handle the noisy observations in many fields such as longitudinal studies, extant FDA literature mostly adopts rather a frequentist approach and bears the uncertainty of parameter estimation. As an alternative to improve the quality of model estimation, a Bayesian approach naturally takes into account the uncertainty in estimation and produces posterior predictive distribution. In this study, we adopt a Bayesian hierarchical model of Gaussian processes for the underlying trajectories, which enables us to obtain the trajectory predictive distributions with closed-form expressions at reduced computational cost. We propose an optimal Bayesian sequential batch design scheme that sequentially finds optimal design for a batch of subjects based on the information obtained from all previous and current stages. Specifically, its sequential feature helps update the optimal design criterion with new information at each stage, whereas its batch feature controls for a small number of stages and maintains the overall cost effectiveness. Combining these two features, this scheme is designed to improve the trajectory recovery of current subjects and achieve accurate estimation of future subject trajectories. Finally, in the optimization step, we implement a simulated annealing algorithm that takes in empirically-tuned parameters and outputs a final design with computational efficiency.

Further refinement of this study can be done by altering the assumptions made in our analysis. Particularly in the design setup, we assume that the batch size \(M\) of the optimal design is small. This is established as \(M\) should not be too large to only have too few updates on the design optimality criterion. Nonetheless, in practice, \(M\) is often contingent upon the size of the initial data set and the number of design stages. The interactions between these factors may change the optimal size of the batch. To account for this, there are two potential approaches to find the optimal \(M\). One is to iteratively test different values of \(M\) from 1 to the existing subject size \(N\). Yet additional consideration will need to be put in to reduce its computational expensiveness. Another is to include \(M\) as a random variable and incorporate it inside the utility function. That is, the optimal design and the optimal batch size are obtained in each stage.