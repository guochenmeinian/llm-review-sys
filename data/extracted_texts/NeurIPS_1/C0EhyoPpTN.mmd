# Inferring stochastic low-rank recurrent neural networks from neural data

Matthijs Pals

A Erdem Sagtekin

Felix Pei

Manuel Gloeckler

Jakob H Macke

###### Abstract

A central aim in computational neuroscience is to relate the activity of large populations of neurons to an underlying dynamical system. Models of these neural dynamics should ideally be both interpretable and fit the observed data well. Low-rank recurrent neural networks (RNNs) exhibit such interpretability by having tractable dynamics. However, it is unclear how to best fit low-rank RNNs to data consisting of noisy observations of an underlying stochastic system. Here, we propose to fit stochastic low-rank RNNs with variational sequential Monte Carlo methods. We validate our method on several datasets consisting of both continuous and spiking neural data, where we obtain lower dimensional latent dynamics than current state of the art methods. Additionally, for low-rank models with piecewise-linear nonlinearities, we show how to efficiently identify all fixed points in polynomial rather than exponential cost in the number of units, making analysis of the inferred dynamics tractable for large RNNs. Our method both elucidates the dynamical systems underlying experimental recordings and provides a generative model whose trajectories match observed variability.

## 1 Introduction

A common goal of many scientific fields is to extract the dynamical systems underlying noisy experimental observations. In particular, in neuroscience, much work is devoted to understanding the coordinated firing of neurons as being implemented through underlying dynamical systems . Recurrent neural networks (RNNs) constitute a common model-class of neural dynamics  which can be reverse-engineered to form hypotheses about neural computations . As a result, several recent research directions have centered on interpretable or analytically tractable RNN architectures. In particular, RNNs with low-rank structure  admit a direct mapping between high-dimensional population activity and an underlying low-dimensional dynamical system. RNNs with piecewise-linear activations  are tractable, as they have fixed points and cycles that can be accessed analytically.

To serve as useful models of brain activity, it is important that models also capture the observed brain activity, including trial-to-trial variability. Many methods that fit RNNs to data are restricted to RNNs with deterministic transitions . It is unlikely that, in general, all variability in the data can be explained by variability in the RNNs initial state. Thus, adopting stochastic transitions is imperative. While probabilistic sequence models are used effectively in neuroscience , they have so far largely consisted of state space models without an obvious mechanistic interpretation .

Here, we demonstrate that we can fit large stochastic RNNs to noisy high-dimensional data. First, we show that, by combining variational sequential Monte Carlo methods [33; 34; 35] with low-rank RNNs, we can efficiently fit stochastic RNNs with many units by learning the underlying low-dimensional dynamical system. The resulting RNNs are generative models of neural data that can be used to sample trajectories of arbitrary length, and also allow for conditional generation with (both time-varying and stationary) inputs. Second, we show that, for low-rank networks with piecewise-linear activation functions, the resulting dynamics can be efficiently analyzed: In particular, we show how _all_ fix points can be found with a polynomial cost in the number of units -- dramatically more efficient than the exponential cost in the general case.

We first validate our method using several teacher-student setups and show that we recover both the ground truth dynamics and stochasticity. We then fit our model to several real-world datasets, spanning both spiking and continuous data, where we obtain a generative model which needs lower dimensional latent dynamics than current state of the art methods. We also demonstrate how in our low-rank RNNs fixed points can be efficiently inferred -- potentially at a lower cost than approximate methods , while additionally coming with the guarantee that _all_ fixed points are found.

## 2 Theory and methods

### Low-rank RNNs

#### 2.1.1 Access to the low-dimensional dynamics underlying large networks

Our goal is to infer recurrent neural network models of the form

\[}{dt}=-(t)+((t))+ _{}(t), \]

with neuron activity \((t)^{N}\), time-constant \(_{>0}\), recurrent weights \(^{N N}\), element-wise nonlinearity \(\), an \(R\) dimensional white noise process \((t)\) and \(_{}^{N R}\). In particular, we are interested in the case where the weight matrix \(\) has rank \(R N\), i.e., it can be written as \(=^{}\), with \(,^{N R}\) ([18; 19; 20; 21]). Assuming that \((0)\) lies in the subspace spanned by the columns of \(\) and \(_{}=_{}\), with \(_{}^{R R}\), we can rewrite Eq. 1 as an equivalent \(R\) dimensional system,

\[}{dt}=-(t)+^{}((t))+_{}(t), \]

where we can switch between Eq. 1 and Eq. 2 by means of linear projection, \((t)=(^{})^{-1}^{} (t)\) and \((t)=(t)\). Note that we can directly extend these equations to include input, representing, e.g., experimental stimuli or context. Even if these stimuli are time-varying, \(\) will be constrained to the span of the input weights and \(\). By including input to the RNN, we can use the fit models for conditional generation (see Supplement C.2).

Figure 1: Our goal is to obtain generative models from which we can sample realistic neural data while having a tractable underlying dynamical system. We achieve this by fitting stochastic low-rank RNNs with variational sequential Monte Carlo.

#### 2.1.2 Low-rank RNNs as state space models

We consider nonlinear latent dynamical systems with observations \(_{t}\):

\[p(_{1:T},_{1:T}) =p(_{1})_{t=2}^{T}p(_{t}_{t -1})_{t=1}^{T}p(_{t}_{t}),\] \[p(_{t}_{t-1}) =(F(_{t-1}),_{}),\ p(_{1})=(_{_{1}},_{_{1}}),\] \[p(_{t}_{t-1}) =G(_{t}),\]

where the transition distribution is parameterised by discretising a low-rank RNN with timestep \(_{t}\), we have mean \(F(_{t})=a_{t}+}^{}(_{t})\), with \(a=1-}{}\) and \(}=}{}\), and covariance \(_{}\) (see Supplement C.1). The specific form of the observation function \(G\), depends on the data-modality, e.g., here we use a Poisson distribution for count observations. This formulation allows one to keep the one-to-one correspondence between RNN units (or a subset of those) and recorded data neurons, (as was desired in previous work, e.g., [10; 11; 12; 36]). For example, assuming Gaussian observation noise, we can simply use that \(_{t}=_{t}\) and define \(G=(_{t},_{})\).

Once we learn \(p(_{1:T},_{1:T})\), we can use the obtained RNN as a generative model to sample trajectories, and reverse engineer the underlying dynamics to gain insight in the data generation process. Given the sequential structure of the RNN, we can do model learning by using variational sequential Monte Carlo (also called Particle Filtering) methods [33; 34; 35].

### Model learning with variational sequential Monte Carlo

#### 2.2.1 Sequential Monte Carlo

Sequential Monte Carlo (SMC) can be used to approximate sequences of distributions, such as those generated by our RNN, with a set of \(K\) trajectories of latents \(_{1:T}\) (commonly called particles) . As we do not have direct access to the posterior \((_{t}_{1:t})\), we instead sample from a proposal distribution \(r\), and adjust for the discrepancy between the proposal and target posterior distribution using importance weights. Thus, a crucial choice when doing SMC is picking the right proposal distribution \(r\), from which we can sample latents conditioned on the previous latent \(_{t-1}\) and observed data \(_{1:T}\), or a subset of those. Given initial samples \(_{1}^{1:K} r\) and corresponding importance weights \(_{1}^{1:K}\) (as defined below) SMC progresses by repeatedly executing the following steps:

\[resample a_{t-1}^{k}(a_{t-1}^{k}_{t-1}^{k}),\] \[propose _{t}^{k} r(_{t}^{k}_{t}, _{t-1}^{a_{t-1}^{k}}),\] \[reweight w_{t}^{k}=_{t},_{t}^{k}_{t -1}^{a_{t-1}^{k}})}{r(_{t}^{k}_{t},_{t-1}^{a _{t-1}^{k}})},\]

with \(_{t}^{k}=^{k}}{_{j=1}^{K}w_{t}^{j}}\). Here, the resampling step avoids most of the weights from concentrating on very few particles. Using SMC, we obtain, at time \(t\), a filtering approximation to the posterior,

\[q_{}(_{1:t}_{1:t})=_{k=1}^{K}_{t}^{k}(_{1:t}^{k}). \]

The unnormalised weights give an unbiased estimate to the marginal likelihood,

\[(_{1:T})=_{t=1}^{T}_{k=1}^{K}w_{t}^{k}. \]

We now detail how we pick the proposal distribution \(r\). For linear Gaussian observations \(G=(_{t},_{})\), we set \(r(_{t}_{t},_{t-1})=p(_{t} _{t},_{t-1})\), as this is available in closed form and is optimal (in the sense that it minimises the variance of the importance weights )

\[r(_{t}_{t},_{t-1})=((- )F(_{t-1})+_{t},_{ }) \]with \(\) the Kalman Gain: \(=_{}^{}_{}^{-1}\), and \(_{}=(_{}^{-1}+^{}_{ }^{-1})^{-1}\) (or equivalently \(=_{}^{}(_{}^{}+_{})^{-1}\), and \(_{}=(-)_{}\)). For non-linear observations, we can not invert the observation process in closed form, so we instead jointly optimize a parameterized 'encoding' distribution \(e(_{t}_{t-t^{}:t})\) (as in a variational autoencoder ). In particular, we assume \(e\) to be a multivariate normal with diagonal covariance, which we parameterize by a causal convolutional neural network, such that each latent is conditioned on the \(t^{}\) latest observations (although sometimes non-causal encoders can be advantageous, see Supplement B.5). We then use the following proposal:

\[r(_{t}_{t-1},_{t-t^{}:t}) e( _{t}_{t-t^{}:t})p(_{t}_{ t-1}), \]

where we now also assume \(p(_{t}_{t-1})\) has a diagonal covariance matrix.

#### 2.2.2 Relationship to Generalised Teacher Forcing

In our approach, the mean of the proposal distribution at time \(t\) is a linear combination between the RNN predicted state \(F(_{t-1})\) and a data-inferred state \(}_{t}\). A recent study obtained state-of-the art results for reconstructing dynamical systems by fitting deterministic RNNs with a method called Generalised Teacher Forcing (GTF), which similarly linearly interpolates between a data-inferred and an RNN predicted state at every time-step ; the model propagates forward in time as \(_{t}=(1-)F(_{t-1})+}_{t}\). Hess et al.  showed that by choosing the appropriate \(\), one can completely avoid exploding gradients, while still allowing backpropagation through time, and thus obtaining long-term stable solutions . The optimal \(\) can be picked based on the maximum Lyaponur exponent of the system (a measure of how fast trajectories diverge in a chaotic system).

By including the RNN in the proposal distribution, we similarly to GTF allow backpropagation through time through the sampled trajectories. The linear combination is given by \(=(_{}^{-1}+^{}_{}^{ -1})^{-1}^{}_{}^{-1}\) in Eq. 5, and similarly in Eq. 6 by \(=(_{}^{-1}+_{}_{t}}^{-1})^{-1} _{}_{t}}^{-1}\), where \(_{}_{t}}\) is the predicted variance of the encoding network. Thus, instead of interpolating based on an estimate of how chaotic the system is, our approach combines RNN and data inferred states adaptively (every time step, if Eq. 6 is used) based on how relatively noisy the transition distribution is with respect to the data-inferred states at time \(t\), analogous to, e.g., the gain of a Kalman filter. In the formulation of GTF of Hess et al. , an invertable observation model is required. By learning an encoder that predicts a distribution over latents, our method naturally extends to models with non-invertable (e.g., Poisson) observations.

#### 2.2.3 Variational objective

We can fit our RNNs to data by using SMC to specify a variational objective . In variational inference, we specify a family of parameterized distributions \(Q\), and optimize those parameters such that a divergence (usually the \(\) divergence) between the variational distribution \(q(_{1:T}) Q\) and the true posterior \(p(_{1:T}_{1:T})\) is minimized. We do this by maximising a lower bound (\(\)) to the log likelihood \(p(_{1:T})\). In particular, we can use Eq. 4 to specify the \(\) objective 

\[=_{q_{}(_{1:T}^{1:K},a_{1:T-1}^{1:K }_{1:T})}[(_{1:T})], \]

with \(q_{}\) the sampling distribution:

\[q_{}(_{1:T}^{1:K},a_{1:T-1}^{1:K}_{1:T})= _{k=1}^{K}r(_{1}^{k}_{1})_{k=1}^{K}_{t=2 }^{T}r(_{t}^{k}_{t-1}^{a_{t-1}^{k}}_{t}) (a_{t-1}^{k}_{t-1}^{k}).\]

During each training iteration, we run SMC, using the closed form optimal proposal (Eq. 5) if observations are linear Gaussian, otherwise the proposal includes a parameterised encoder (Eq. 6). We can then use the resulting unnormalised importance weights (Eq. 4) to estimate the \(\), which we maximise with backpropagation (through time). As suggested in previous studies , we use biased gradients during optimization by dropping high-variance terms arising from the resampling.

### Finding fixed points in piecewise-linear low-rank RNNs

After having learned our model, we can gain insight into the mechanisms underlying the data generation process by reverse engineering the learned dynamics , e.g., by calculating their fixed points. Here, we show that the fixed points can be found analytically and efficiently for low-rank networks with piecewise-linear activation functions. This class of activation functions \((_{i})=_{d}^{D}_{i}^{(d)}(_{i }-_{i}^{(d)},0)\) includes, e.g., the standard \(\) (\((_{i})=(_{i}-_{i},0)\)) or the 'clipped' variant (\((_{i})=(_{i}+_{i},0)-( _{i},0)\))  which we used in all experiments with real-world data here.

Naively, the cost of finding all fixed points piecewise-linear networks scales _exponentially_ with the number of units in the networks: we would have to solve \((D+1)^{N}\) systems of \(N\) equations . If networks are low rank, it is straightforward to show that we can reduce this cost to solving \((D+1)^{N}\) systems of \(R\) equations (See Supplement A.1). In addition, however, we show that the computational cost can be greatly reduced further: One can find _all_ fixed points in a cost that is _polynomial_ instead of _exponential_ in the number of units:

**Proposition 1**.: Assume Eq. 1, with \(\) of rank \(R\) and piecewise-linear activations \(\). For fixed rank \(R\) and fixed number of basis functions \(D\), we can find all fixed points in the absence of noise, that is all \(\) for which \(}{dt}=0\), by solving at most \((N^{R})\) linear systems of \(R\) equations.

Proof.: See Supplement A.1.

Sketch.: Assuming \(D=1\), activations \(=(0,_{i}-_{i})\); \(N\) units will partition the full phase space into \(2^{N}\) regions in which the dynamics are linear (2 units, 4 regions in Fig. 2). We can thus, in principle, solve for all fixed points by solving all corresponding linear systems of equations . If dynamics are confined to the \(R\)-dimensional subspace spanned by the columns of \(\), only a subset of the linear regions (3 in Fig. 2) can be reached. Each unit partitions the space spanned by the columns of \(\) with a hyperplane (pink points in Fig. 2). The amount of linear regions in \(\), becomes equivalent to 'how many regions can we create in \(R\)-dimensional space with \(N\) hyperplanes? Using Zaslavsky's theorem , we can show that this at most \(_{r=0}^{R}(N^{R})\) (for fixed \(R\)).

## 3 Empirical Results

### RNNs recover ground truth dynamics in student-teacher setups

We validated our method using several student-teacher setups (Fig. 3; additional statistics in Fig. S4). We first trained a 'teacher' RNN, with the weight matrix constrained to rank 2, to oscillate. We then simulated multiple trajectories with a high level of stochasticity in the latent dynamics (Fig. 3**a**, top left) and additional additive Gaussian observation noise (Fig. 3**a**, top right) on the observed neuron activity (\(_{i}(_{i},_{y}^{2})\), with \(=\)). A second'student' RNN was then fit to the data drawn from the teacher, and both recovered the true latent dynamical system, as well as the right level of stochasticity (Fig. 3**a**, bottom; Fig. 3**d**).

We also verified that we can obtain covariance matrices \(_{}\) that are numerically close to the ground truth, for teacher networks with various levels of noise (Fig. S5). When using the bootstrap proposal (i.e., sampling from the prior; \(r=p(_{t}_{t-1})\)), or too few particles, the right level of stochasticity is not obtained, indicating that the use of multiple particles and a proposal that conditions on observed data is indeed beneficial.

Given that neurons emit action potentials, which are commonly approximated as discrete events, we repeated the initial teacher-student experiment with Poisson observations generated according to \(_{i}((_{i}_{ i}-_{i}))\). The student RNN again recovers the oscillatory latent dynamics. Note that because of the affine transformation in the observation model, the inferred dynamics can be scaled and translated with respect to the teacher model. To verify that samples from our inferred model follow the same distribution as samples from the teacher model, we computed several statistics, which all show a close match (Fig. 3**e**; Fig. S4).

In our final teacher-student setups, we verified the ability to recover dynamics when there are known stimuli or contexts. In particular, we trained a rank-2 RNN on a task where, at each trial, it receives a transient pulse input corresponding to a particular angle \(\) (given as \((),()\)), and is asked to provide output matching the input after stimulus offset. The teacher RNN learns to perform the task by using an approximate ring attractor - which the student RNN accurately infers (Fig. 3**c**). Here, we inferred all fixed points by making use of Proposition 1. To demonstrate that our method also works when inputs are strongly time-varying, we included an additional setup where the teacher network was asked to report the sign of the mean of a noisy stimulus (Fig. S6).

Figure 2: Proof sketch.

### Stochasticity allows recovering low-dimensional latents underlying EEG data

After validating our model on a toy example, we went on to several challenging real-world datasets. We first used an EEG dataset [42; 43] with 64 channels containing one minute of continuous data sampled at 160 Hz (Fig. 4). This dataset was recently used in a study where generalized teacher forcing (GTF) was used to fit deterministic RNNs with low-rank structure . The GTF method obtains state-of-the-art results on several dynamical systems reconstruction tasks. It outperformed SINDy , neural differential equations , Long-Expressive-Memory , and other methods, while using a smaller latent dynamical system.

Here we show that using a stochastic RNN with SMC instead of a deterministic RNN with GTF, we can decrease the latent dimensionality even further, from 16 to just 3 latents, while matching the original reconstruction accuracy (Table 1). We hypothesize this is because the data can be

Figure 4: Example ground truth EEG [42; 43] and (unconditionally) generated traces by our model. Shown are 5/64 EEG channels.

Figure 3: RNNs recover dynamics in teacher-student setups. **a)** Example ground truth latent trajectory and phase plane of low-rank RNN trained to oscillate (top left) and noisy observations of neuron activity (top right; 6/20 shown). A second low-rank RNN trained on the activity of the first recovers ground truth dynamics. **b)** Same set-up, but with Poisson observations. **c)** The teacher network was trained on a task where it has to provide an output corresponding to 8 different angles depending on an input cue. The student network, when given the same input during fitting, recovers the approximate ring attractor. **d)** Mean (\( 1\)SD) autocorrelation of the latents of the models from panel **a**, show the oscillation frequency is captured, as well as the decorrelation due to recurrent noise. The scale of the observed rates also agrees between student and teacher. **e)** Mean rates and ISI between student and teacher units of panel **b** match. **f)** Example rate distribution of one unit of the teacher and student RNN (of panel **c)**, after onset of the 8 different stimuli.

well explained by stochastic transitions with simple underlying dynamics as opposed to complex deterministic chaos.

We evaluated samples from our RNN with two measures which were used in previous work , one KL divergence-based measure between the states (\(D_{}\)), and one measure over time, based on the power spectra of generated and inferred dynamics (\(D_{H}\); see Supplement D.3.3). Unlike Hess et al. , who applied smoothing, we optimized our models directly on the raw EEG data. We also fit stochastic full-rank RNNs with variational SMC, however these models tend to have worse performance on this task, while also being less interpretable (Fig. S7).

### Interpretable latent dynamics underlying spikes recorded from rat hippocampus

We next investigated how well our model can capture the distribution of non-continuous time series. In particular, we used publicly available electrophysiological recordings from the hippocampus of rats running to drops of water or pieces of food [47; 48]. We binned the spiking data into 10ms bins and fit a rank-3 RNN to \(\)850 s of data. Samples generated by running the fit RNN autonomously closely matched the statistics of the recordings (Fig. 5**a**-**c**). Previous investigations into this dataset have examined the relationship between spikes and theta (5-10 Hz) oscillations in the local field potential (), and found that units were locked to the LFP rhythm, with the relativ

   Dataset & Method & \(D_{}\) & \(D_{H}\) & dim & \(||\) \\  EEG & GTF  & \(2.1 0.2\) & \(0.11 0.01\) & 16 & \(17952\) \\  & adaptive GTF  & \(2.4 0.2\) & \(0.13 0.01\) & 16 & \(17952\) \\  & SMC (ours) & \(2.1 0.1\) & \(0.11 0.01\) & \(3\) & \(3920\) \\   

Table 1: Lower dimensional latent dynamics than SOTA at same sample quality. We report median \(\) median absolute deviation over \(20\) independent training runs, ‘dim’ refers to the dimensionality of the model’s underlying dynamics and \(||\) denotes the total number of _trainable_ parameters. Values for GTF taken from Hess et al. .

Figure 5: RNNs reproduce the stationary distribution of spiking data. **a)** We fit a rank-3 RNN to spike data recorded from rat hippocampus [47; 48] (left), and generate new samples from the RNN (right). **b)** Single neuron statistics. Mean rates and means of interspike interval (ISI) distributions of a long trajectory of data generated by the RNN (gen) match those of a held-out set of data (test). As a reference we additionally computed the same statistics between the train and test set. **c)** Population level statistics. We plot the pairwise correlations between all neurons for generated data against the pairwise correlations in the test data. **d)** The corresponding latents generated by running the RNN look visually similar to the local field potential (LFP). **e)** The peak in the power spectrum matches between latents and LFP. **f)** The posterior latents show coherence with the LFP. As a reference, we compute the coherence between the LFP and the latents generated by the RNN.

subregions from which the units were recorded. The latents generated by the RNN are visually similar to the average local field potential (Fig. 5**d**) and match its power spectrum (Fig. 5**e**). While the model was solely trained on the spikes, the posterior latents (Eq. 3) have a clear phase relationship with the LFP, as evidenced by a high coherence between the posterior latents and LFP. In contrast, and as expected, latents from running the RNN are not correlated with the LFP (Fig. 5**f**). The correspondence between generated latents and LFP was absent when we use a related method for fitting RNNs (with deterministic transitions) to neural data (LFADS ; Fig. S8). Using the bootstrap proposal also led to lower-quality samples (Fig. S9).

Units in rat hippocampus have been shown to code for position, e.g., through place cells , which tend to fire if the animal is at a specific location. To further investigate how well we can model recordings from the hippocampus, we fit a rank-4 RNN to an additional set of recordings of rats running on a linear track  (Fig. S10). As in Zhou and Wei , we first focus only on the spikes recorded while the rat is moving, which we bin into 25 ms bins. The RNN again accurately reconstructs the distribution of spikes and again has latent oscillations. Here the frequency at which power peaks is slightly higher than that of the LFP, potentially related to phase precession (). While solely trained on spikes, the posterior latents also allowed us to predict the position of the rats with reasonable accuracy (\(R^{2}=0.79 0.05\) mean \(\) SD, \(N=4\) RNNs; Fig. 6). We also fit rank-12 RNNs to around 15 minutes of recording (again with 25 ms bins), which includes long intermediate periods where the rat is stationary. Here our generative model learns to have higher theta power during running bouts, in line with the data (Fig. S11).

### Extracting stimulus-conditioned dynamics in monkey reaching task

Figure 6: Posterior latents of our model (fit solely spikes) can be used to predict rat position.

Figure 7: Inferred and generated dynamics from the model fit to macaque spiking activity during a reaching task. **a)** Latent states inferred from the macaque spiking data prior to movement initiation (‘pre-movement’) and during movement execution (‘movement’), colored by the intended reach target. **b)** Reach trajectories decoded from model-inferred neural activity. **c)** Dissimilarity matrices computed across the seven conditions (i.e., the seven colors in **a**, **b)** for per-neuron mean firing rate and ISI. We generate neural activity from the model by providing the same conditioning stimuli as in the real data. Then, for each statistic, we compute and show the correlation distance between conditions in the real data (left) and model-generated data (right). **d**, **e)** Same as **a**, **b**, but with latent activity and behavioral predictions generated from the model with conditioning inputs including directions not seen in the real data (e.g., lime green). For clarity, we show only a subset of conditions in the decoded reaches.

We further investigated how well we can recover stimulus-conditioned dynamics. We applied our method to spiking activity recorded from the motor and premotor cortices of a macaque performing a delayed reaching task. This type of data has been popular for investigating neural dynamics underlying the control of movement  and evaluating neuroscientific latent variable models . We first validated the ability of our method to obtain a sensible posterior by evaluating it on the Neural Latents Benchmark  (Supplement B.5, Table S2).

We then went on to a set-up where we explicitly conditioned our model on external context. For simplicity, we constrained our experiment to trials with straight reach trajectories in the data. We fit a rank-5 model to these data while conditioning the RNN dynamics on the target position by providing the target position as input. Our model was able to infer single-trial latent dynamics and neuron firing rates that predict reach velocity with high accuracy at lower latent dimensionalities than models without inputs (Fig. 7**b**, \(R^{2}=0.90\) for this model, see Table S3 for additional statistics).

We examined the posterior latents inferred by the model and found that our model recovers structured and interpretable latent dynamics. Before movement onset, latent states corresponded to the intended reach targets, which were near the edges of a rectangular screen (Fig. 7**a**, left), in line with . During the movement period, the latents followed parallel curved trajectories that preserve target information (Fig. 7**a**, right) and can be decoded to predict monkey reach behavior (Fig. 7**b**).

We then generated neural data from the RNN conditioned on stimulus input. Again, the distribution of spikes is well-captured (Fig. S12). We additionally evaluated whether the model faithfully captures differences in spiking statistics across the seven reach directions, finding reasonable correspondence in dissimilarities between conditions in the generated and the real data (Fig. 7**c**). Finally, we simulated our trained RNN with conditioning inputs, including reach directions not present in the data, and found that the structured latent space recovered by the model enables realistic generalization to unseen reach conditions (Fig. 7**d**, **e**, lime green condition).

### Searching for fixed points

In Proposition 1, we derived a bound on the number of systems of equations one has to solve in order to find _all_ fixed points in piecewise-linear low-rank RNNs. Recently, an approximate algorithm for finding fixed points in piecewise-linear networks was proposed . Here, we perform an exploration into how this compares to our analytic method by searching for fixed points of the RNN in Fig. 3**c** (top). For the same number of matrix inverses computed by our analytic method, the approximate method generally does not find all 17 fixed points (Fig. 8). We note, however, that (unlike ours) the convergence of the approximate method depends on the dynamics of the RNN, and as a result, there are theoretical scenarios where the approximate method can be shown to be faster. Yet we empirically also found scenarios where the approximate methods failed to converge within the time-frame of our experiments (Fig. S13).

Our analytic method relies on the insight that only a subset of all linear subregions formed by the piecewise-linear activations can be reached in low-rank networks. For networks with moderate rank, the cost of searching through all of the subregions might still be too high. We can, however, hugely reduce the search space of the approximate method  (from \((D+1)^{N}\) to \(_{r=0}^{R}D^{r}{N r}\)), at an upfront cost (Supplement B.7; orange line in Fig. 8).

Figure 8: Comparison of our analytic method (star) and the approximate method proposed in Eisenmann et al.  (blue) for finding the fixed points of the teacher RNN in Fig. 3**c**. We can also use Proposition 1 to constrain the search space of the approximate method (orange). Error bars denote the minimum and maximum amount of fixed points found over 20 independent runs of the algorithm.

Discussion

Here we proposed to fit low-rank RNNs to neural data using variational sequential Monte Carlo. The resulting RNNs are generative models with tractable underlying dynamics, from which we can sample long, stable trajectories of realistic data. We validated our method on several teacher-student setups and demonstrated the effectiveness of our method on multiple challenging real-world examples, where we generally needed a latent dynamical system with very few dimensions to accurately model the data. Besides our empirical results, we obtained a theoretical bound on the cost of finding fixed points for RNNs with piecewise-linear activation functions when they are also low-rank.

Adding stochastic transitions to low-rank RNNs can potentially hugely reduce the rank required to accurately model observed data, as demonstrated here with a network fit to EEG data where we could reduce the dimensionality from 16 to just 3. While many methods that fit RNNs to neural data (e.g., [6; 7; 8; 10; 11; 12]) assume deterministic transitions, there is a rich literature concentrating on probabilistic sequence models in neuroscience (e.g., [28; 29; 30; 31; 32]). In particular, a recent work termed FINDR  uses variational inference (but not SMC), to similarly find very low-dimensional dynamical systems underlying neural data. These stochastic dynamical systems were parameterized using neural differential equations . While Eq. 2 can be seen as a neural differential equation with one hidden layer, our particular formulation allows us to find its fixed-points effectively and map back to a regular, mechanistically interpretable RNN (Eq. 1) after fitting, which enables additional investigations into neural population dynamics [20; 21; 18; 22].

We here -- similar to FINDR (and ) -- did not use the adjoint method as is typical in the neural differential equation literature, but rather a simple Euler-Maruyama discretisation scheme and standard backpropagation through time. However, one could investigate how we can integrate our approach with variational approaches that use adjoint methods when fitting latent neural SDEs [58; 59] as well as with filtering approaches for continuous time systems . This could be especially relevant for irregularly sampled time-series.

The reason we can do the mapping between a low-rank RNN (Eq. 1) and a latent dynamical system (Eq. 2) crucially relies on our assumption that samples from the recurrent noise process are correlated, such that they lie within the column-space of \(\). Valente et al.  showed that for linear low-rank RNNs arbitrary covariances in the full \(N\) dimensional space can be used, when increasing the dimensionality of the latent dynamics to twice the rank \(R\) (to the column space of both \(\) and \(\)), this however does not generalise to our non-linear setting. We do expect correlated recurrent noise to be appropriate for modeling stochasticity arising from unobserved inputs or from partial observations  --additionally, correlated noise constituted a pragmatic choice that allows building an _stochastic_ model that can allow for trial-by-trial variability while maintaining the tractability of low-rank deterministic RNNs.

Still, future work can investigate training networks with more relaxed assumptions on the recurrent noise models, including extensions to non-Gaussian noise-processes. The latter could be of particular interest if more biologically plausible (i.e., spiking) neurons were used in the recurrence [62; 36].

Our results also open up further avenues to explore questions in neuroscience. The relation between LFP and spike (phase) in the hippocampus has been of great interest [47; 54; 63; 64]. While we performed some preliminary investigation into the relation between the inferred latents and the local field potential, further studies could perform a systematic investigation into their relation, for instance, by using a multi-modal setup , or to investigate multi-region temporal relationships and interactions .

Taken together, by inferring low-rank RNNs with variational SMC, we obtained generative models of neural data whose trajectories match observed variability, and whose underlying latent dynamics are tractable.

## Code availability

Code to reproduce our results is available at [https://github.com/mackelab/smc_rnns](https://github.com/mackelab/smc_rnns).