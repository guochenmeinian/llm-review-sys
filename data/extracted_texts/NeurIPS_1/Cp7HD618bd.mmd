# A Metalearned Neural Circuit for

Nonparametric Bayesian Inference

Jake C. Snell

Department of Computer Science

Princeton University

jsnell@princeton.edu &Gianluca M. Bencomo

Department of Computer Science

Princeton University

gb5435@princeton.edu &Thomas L. Griffiths

Department of Computer Science

Department of Psychology

Princeton University

tomg@princeton.edu

###### Abstract

Most applications of machine learning to classification assume a closed set of balanced classes. This is at odds with the real world, where class occurrence statistics often follow a long-tailed power-law distribution, rarely revealing the entire problem domain in a single sample. Nonparametric Bayesian models naturally capture this phenomenon, but have significant practical barriers to widespread adoption, namely implementation complexity and computational inefficiency. To address this, we present a method for extracting the inductive bias from a nonparametric Bayesian model and transferring it to an artificial neural network. By simulating data with a nonparametric Bayesian prior, we can metalearn a sequence model that performs inference over an unlimited set of classes. After training, this "neural circuit" has distilled the corresponding inductive bias and can successfully perform sequential inference over an open set of classes. Our experimental results show that the metalearned neural circuit achieves comparable or better performance than particle filter-based methods that explicitly perform Bayesian nonparametric inference while being faster and simpler to use.

## 1 Introduction

Standard machine learning approaches to classification assume that the set of possible classes is known _a priori_. Classification in this setting thus involves selecting the most appropriate class label from a closed set. However, this is not the case for human learners. Imagine European explorers in Australia seeing a kangaroo for the first time. Rather than trying to classify this observation into an existing class - is it a deer or a rabbit? - they recognized that a new class needs to be created. Although this is easy for humans, current machine learning systems struggle to identify novel classes and use them in predictions .

Bayesian statistics offers an elegant solution to the problem of novel classes: define a model in a way that does not make a commitment to an upper bound on the number of classes. This idea is expressed in nonparametric Bayesian models, namely the Dirichlet process mixture model (DPMM) . In this model, a new data point is assumed to be generated from an existing class with probability proportional to the number of previous observations from that class and from a new class with a probability proportional to \(\), a hyperparameter of the model. This makes it possible to both postulatethat a new datapoint might come from a new class and capture long-tailed distributions of class frequency commonly found in real-world classification problems.

Despite their elegance, nonparametric Bayesian models have fallen out of favor in machine learning, as they are difficult to reconcile with the current focus on large-scale models defined over complex objects such as images. The scalability of non-parametric Bayesian models is limited due to the high computational cost of Bayesian inference, typically requiring the use of sampling algorithms such as Markov chain Monte Carlo  or particle filters . Applying these models to complex objects requires creativity in defining generative models that are sufficiently expressive without making inference intractable. Furthermore, most standard Bayesian inference algorithms are not designed to perform sequential inference, instead assuming that all data are presented in a single batch.

In this paper we pursue a different approach to inference in nonparametric Bayesian models: training a recurrent neural network (RNN) to approximate the posterior distribution over classes from a DPMM. We formulate this problem as one of _metalearning_, repeatedly sampling a sequence of class memberships and observations from the DPMM and training the model to predict the class of each observation conditioned on the class labels of those preceding it. The resulting _neural circuit_ (Figure 1) internalizes the inductive bias of the nonparametric Bayesian model used to generate the training tasks. It can then be used as a component in deep neural networks, extending nonparametric Bayesian methods to complex objects such as images.

Our approach combines the elegance of Bayesian nonparametric models with the predictive power of deep learning in a principled and practical manner. The discriminative nature of the RNN allows it to classify complex inputs without making the restrictive distributional assumptions required by standard Bayesian inference algorithms. Since RNNs are sequence models, the neural circuit can efficiently make predictions for a sequence of observations as each successive predictive distribution is computed in constant time. We apply our neural circuit to a challenging open-set image classification tasks from the ImageNet  and iNaturalist  datasets and show it achieves excellent predictive performance at a fraction of the computational cost of standard DPMM inference algorithms.

## 2 Background

Consider the task of a learner classifying objects in a new environment. The learner encounters a sequence of items \(_{1},_{2},,_{T}\). After an item \(_{t}\) is observed, the learner attempts to predict its class label. The learner is then presented with the true class label \(z_{t}\), updates internal representations as necessary, and repeats the procedure for timestep \(t+1\). The predictive distribution over the entire sequence of labels \(z_{1:T}=z_{1},,z_{T}\) can be written as

\[p(z_{1:T}|_{1:T})=p(z_{1}|_{1})_{t=2}^{T}p(z_{t}| _{1:t},z_{1:t-1}). \]

We first review Dirichlet process mixture models, which provide a framework for expressing (1) as posterior inference over \(z_{1:T}\) without restricting the labels to belong to a closed set. We then

Figure 1: Our proposed nonparametric inference network first internalizes the desired nonparametric Bayesian prior via metalearning a recurrent neural network (RNN) to model its posterior distribution over class assignments. Afterwards, the metalearned RNN, or _neural circuit_, has captured the corresponding inductive bias and can be used to perform sequential inference over a potentially unbounded number of classes.

review the particle filter of Fearnhead , which provides a method for sequentially computing the predictive distribution through the use of weighted particles representing assignments of class labels.

### Dirichlet Process Mixture Models

The nonparametric Bayesian solution to the prediction task presented above involves infinite mixture models, the most notable of which is the Dirichlet process mixture model (DPMM) [3; 22; 47]. There are two components to the DPMM: a distribution over class memberships and a class-conditional distribution over observations. In this model, observations are generated from latent classes, where the distribution over classes places no limit on the number of classes. The joint probability follows a Markov process on \(z_{1:T}\) and assumes class-conditional independence for \(_{1:T}\):

\[p(z_{1:T},_{1:T})=p(z_{1})p(_{1}|z_{1})_{t=2}^{T}p(z_ {t}|z_{1:t-1})p(_{t}|z_{t}). \]

The conditional distribution on class memberships \(p(z_{t}|z_{1:t-1})\) is relatively simple:

\[p(z_{t}=k z_{1:t-1})\{n_{k}&k\\ &k,. \]

where \(n_{k}\) denotes the number of occurrences of class \(k\) in \(z_{1},,z_{t-1}\), and by convention the value of \(k\) for a new class is taken to be one greater than the number of classes observed so far. This process is known as the Chinese restaurant process (CRP) .

The conditional distribution over observations is \(p(_{t} z_{t}=k)=g(_{t}|_{k})\), where \(g(|)\) is some probability function with parameter \(\). Each \(_{k}\) is in turn distributed according to a shared prior \((_{k})\) for \(k=1,2,\). The predictive distribution over class assignments (1) can be derived by a simple application of Bayes' rule to the joint distribution (2).

Direct computation of the posterior in a DPMM is intractable, and therefore several methods have been developed to perform approximate inference using methods such as MCMC  and variational inference . However, these methods typically assume that all observations are presented simultaneously and do not attempt to handle the sequential nature inherent to our problem formulation.

### Particle Filter for the DPMM

One notable method that _does_ aim to perform sequential inference of class labels in the DPMM is the particle filter proposed by Fearnhead . Particle filters maintain a set of weighted particles at each timestep that approximate the posterior distribution over latent variables [14; 19]. At each timestep, a particle filter propagates a set of particles forward in time by first sampling a new set of states from a transition distribution and then assigning weights according to a potential function chosen such that the set of weighted particles approximates the target posterior distribution.

In order to make inference tractable in the DPMM setting, Fearnhead  assumes that \(g(|)\) belongs to the exponential family and \(()\) is the corresponding conjugate prior. In this case, it is possible to marginalize over \(\) when computing the posterior predictive distribution for a class. Suppose that \(_{i} g(_{i}|)\) for \(i=1,,n+1\). Since the posterior \(p(|x_{1:n})\) has the same form as the conjugate prior \(()\), there exists a closed form expression for the posterior predictive distribution

\[p(_{n+1}|_{1:n})= p(_{n+1}|)p(|_{1:n})\,d. \]

Each particle in the method of Fearnhead  represents an entire trajectory of class labels up to the current timestep. Suppose that after \(t\) timesteps there are \(J\) particles \(z_{1:t}^{(j)}\) each with weight \(w_{j} 0\) for \(j=1,,J\) such that \(_{j=1}^{J}w_{j}=1\). For each particle, the transition distribution is:

\[p(z_{t+1}=k_{1:t+1},z_{1:t}^{(j)})\,p(z_{t+1}=k|z_{1:t}^{ (j)})p(_{t+1}|_{1:t},z_{1:t}^{(j)},z_{t+1}=k), \]

where the likelihood term \(p(_{t+1}|_{1:t},z_{1:t}^{(j)},z_{t+1}=k)\) can be computed in closed form according to (4). If \(k\) represents a new class, this will be the prior predictive probability instead.

Two major shortcomings of the particle filter are that it makes restrictive distributional assumptions (the class conditional distribution needs to be exponential family) and requires many particles in order to sufficiently approximate the posterior. In the next section, we present our metalearned neural circuit which is aimed at addressing these issues.

Metalearning a Neural Circuit

We propose a novel amortized inference approach for class inference in the DPMM, based on metalearning a recurrent neural network (RNN) to predict class memberships. By applying metalearning to tasks defined by sampling data from a DPMM, the RNN can effectively internalize the corresponding inductive bias in a reusable neural network, hence the name _neural circuit_.

Our approach is inspired in part by the observation that the updates of the particle filter in Section 2.2 can be implemented by accumulating sufficient statistics of observations. Recall that an exponential family distribution and its conjugate prior can be expressed in terms of natural parameters \(\):

\[p() =h()\{,() -A()\} \] \[p(,) =\{,- A()-B( ,)\}, \]

where \(()\) are the sufficient statistics and \(A()\) is the log normalizer. The posterior after observing \(_{1:n}\) is of the same form as the prior, namely \(p(^{},^{})\) where

\[^{}=+_{i=1}^{n}(_{i}) ^{}=+n. \]

From this perspective, the particle filter can be implemented by first initializing the representation of each class to be \(,\). Then the sufficient statistics \((_{t})\) for each observation are extracted and used to update the corresponding class's \(\) after the true label is revealed.

An analogous computation is carried out by a recurrent network, which given some input \(_{t}\) and previous hidden state \(_{t-1}\), computes an updated hidden representation \(_{t}\) and an output \(_{t}\):

\[_{t},_{t}_{}(_{t},_{t-1}) \]

The differences with respect to the particle filter are twofold: the representation of each cluster is no longer separate but shared in \(_{t}\), and the representations are learnable end-to-end.

We also recognize that the output \(_{t}\) can be the basis for predicting the current class label, and \(_{t}\) can be made to capture the updated current state of all classes simultaneously. To predict the current class label, the RNN's output \(_{t}\) is mapped to a provisional logit \(_{t}\) using a learnable weight matrix \(\) and bias vector \(\). The logits are then additively masked by \(_{t}\), which preserves the logit as long as predicting the corresponding class would be valid (i.e. the class label is at most one greater than any previously seen class label). The input to the RNN at each timestep is the concatenation of the current observation \(_{t}\) and a one-hot representation of the previous label \(z_{t-1}\) (all zeros when \(t=1\)). The predictive distribution is therefore defined to be:

\[p_{}(z_{t}|_{1:t},z_{1:t-1}) =(_{t}+_{t}) \] \[_{t} =_{t}+\] \[m_{tk} =\{0&k 1+ z_{1:t-1}\\ -&,.\] \[_{t},_{t} _{}([_{t},(z_{t-1})],_{t-1}),\]

where \(\{,,\}\) are learnable parameters.

In order to learn these weights, we turn to metalearning. In metalearning, a system is presented with a set of tasks sampled from a distribution over tasks. The goal is to leverage the shared structure of these tasks not only to become better at solving each individual task but also to solve future tasks better, effectively "learning to learn" [4; 8; 30; 56]. This is done by estimating a set of hyperparameters shared across tasks. In our case, these are the weights of the neural circuit, which we metalearn by minimizing negative log-likelihood of item-label sequences generated by a DPMM.

Let \(z_{1:T}\) be generated according to a CRP (3) and \(_{t} z_{t}=k\) be generated according to some (possibly unknown) distribution \(g(_{t}|_{k})\) for \(t=1,,T\). Let \(\) denote this joint distribution over \((z_{1:T},_{1:T})\). We define

\[^{*}=_{}_{(z_{1:T},_{1:T}) }[-_{t=1}^{T} p_{}(z_{t}| _{1:t},z_{1:t-1})], \]where the minimization is performed via a gradient-based optimization procedure. This metalearning approach can be applied equally well whether the the form of the class-conditional distributions is known or not, since all that is required are samples from the joint distribution. If the class-conditional distribution is unknown, it is taken to be the empirical distribution constructed from a dataset by placing an evenly-weighted point mass on each sample within a class.

Relationship to Amortized InferenceOur method can be viewed as a form of amortized inference, wherein a function (e.g. represented by a deep neural network) is learned to directly map from inputs to an approximate posterior distribution over latent variables [35; 49]. Amortized inference is similar to discriminative classification in that it directly maps from inputs to class labels, but it can also be viewed as approximate Bayesian inference within the generative modeling framework. Networks trained to perform amortized inference are sensitive to the choice of prior, since different priors will lead to different posteriors, the KL-divergence to which will be minimized during learning. In a similar fashion, our method is also affected by the choice of DPMM prior as different priors change the distribution over sequence that the neural circuit is trained on.

Relationship to MetalearningA variety of methods have been used to learn shared hyperparameters to solve a set of related tasks problem for deep neural networks [2; 24; 48; 53; 63], but our approach is most similar to those in which a recurrent neural network is trained to perform multiple tasks [20; 65]. This approach is more typically used in reinforcement learning, defining a system that learns a global meta-policy that supports efficient learning on specific tasks. The resulting RNNs have been shown to encode information equivalent to a Bayesian posterior distribution , making them a good candidate for metalearning amortized Bayesian inference.

## 4 Experiments

We apply the neural circuit on three data settings: a synthetic dataset where the form of the DPMM is known, sequences of labels generated from a CRP on ImageNet , and sequences sampled directly from the long-tailed iNaturalist 2018 species classification dataset . The goal of our experiments is to compare both the predictive performance and computational efficiency of the neural circuit to standard sequential inference techniques for the DPMM.

Our main experimental point of comparison is the particle filter of Fearnhead  discussed in Section 2.2. For a non-Bayesian baseline, we compare to a softmax-based classifier that augments the distribution over \(K\) known classes at time \(t\) with an additional logit representing the possibility of a new class. The logit representing the new class is derived using the maximum entropy principle  by introducing the constraint that the marginal probability that \(z_{t}\) is a new class be equal to \(/(t-1+)\) (please refer to Appendix B for more details). We refer to this baseline as "Softmax + Energy."

We consider two main evaluation scenarios. The first, referred as the _sequential observation setting_, measures the quality of a model's predictions when the true class label is provided after each prediction. We report the average predictive negative log-likelihood (NLL) averaged across timesteps and corresponding perplexity. The second setting quantifies how well the model predicts when there is no feedback about the true class labels (we refer to this as the _fully unobserved setting_). We compare the maximum a posteriori (MAP) prediction of the model against the true sequence of class labels using standard clustering metrics, including the adjusted Rand index (ARI)  and adjusted mutual information score (AMI) . In both settings, we compare computational efficiency by evaluating the wall clock compute time per sequence to make predictions. Please refer to Appendix D for additional experimental details.

### Modeling Synthetic Data from a DPMM

We first evaluate performance of the neural circuit on a synthetically generated DPMM dataset. Our aim is to determine whether the neural circuit can match performance of the particle filter when the class-conditional distributions belong to the exponential family with a known prior. Specifically, we use a normal-inverse-gamma prior and Gaussian class conditional distributions with unknown mean and variance. For each dimension \(d=1,,D\), the form of the class-conditional distribution is:

\[_{d}^{2}^{-1}(a,b)_{d}(m,_{d}^{ 2}/) x_{d}(_{d},_{d}^{2}),\]where \(m\), \(\), \(a\), and \(b\) are known hyperparameters. We set the length of the sequences to \(T=100\) and chose \(D=2\), \(m=0\), \(=0.01\), and \(==2\). Several sequences drawn from this distribution are shown in Figure 2. We directly set the hyperparameters of the particle filter to their true values.

The results of our evaluation can be found in Table 1. The Softmax + Energy baseline is significantly slower than the other methods due to solving for weights after each timestep. Although its NLL is better than the CRP, the average perplexity is worse due to the presence of some sequences where NLL is quite poor. These sequences are accentuated due to exponentiation in the formula for computing perplexity. We find that although the particle filter performs best on negative log-likelihood, the neural circuit provides better clusterings in the fully unobserved setting. We hypothesize this is due to the particle filter's insufficient exploration of the posterior over labelings stemming from its reliance on particles. We also find that neural circuit inference is roughly \(5\) faster than the particle filter in the sequential observation setting and roughly \(10\) faster in the fully unobserved setting.

### Open-set Classification on ImageNet-CRP

Next we consider a challenging open-set image classification task where the input features are activations from a ResNet . Our goal is to determine whether the neural circuit can effectively scale up to a high dimensional space where the form of the class-conditional distribution is unknown.

We downloaded the weights of a pretrained ResNet-18 from TIMM  and extracted the 512-dimensional penultimate layer activations from the entire ILSVRC 2012 dataset . We split the 1,000 classes into 500 reserved for training (meta-train classes) and 500 for testing (meta-test classes). We generate sequences by sampling \(z_{1:N}\) from a CRP with \(=1.0\), assigning each distinct value of \(z_{n}\) to a class uniformly at random, and then sampling the corresponding observation \(x_{n}\) uniformly from the images belonging to that class. We call this data-generating procedure ImageNet-CRP.

We metalearn the neural circuit with the same architecture and optimization procedure as in Section 4.1. For the particle filter, additional care needs to be taken to model the sparse nonnegative ResNet features that are produced by a ReLU activation. We modeled this using a hurdle  model with log-normal distribution over nonegative values. This model posits a log-normal distribution over the nonnegative values and a point mass at zero:

\[x_{d}_{d} y_{d}_{d}(_{d},_{d}^{2}) y_{d}(p_{d}) \]

    &  &  &  \\  Method & NLL (\(\)) & Perp. (\(\)) & ARI (\(\)) & AMI (\(\)) & Seq. Obs. (\(\)) & Fully Unobs. (\(\)) \\  CRP & 1.006 & 2.978 & 0.010 & 0.010 & **0.019** & **0.179** \\ Softmax + Energy & 0.929 & 24.742 & 0.388 & 0.392 & 1679.716 & 1691.403 \\ Particle Filter & **0.048** & **1.053** & 0.769 & 0.814 & 1.617 & 4.432 \\ Neural Circuit & 0.076 & 1.086 & **0.921** & **0.928** & 0.059 & 0.421 \\   

Table 1: Results on two-dimensional data synthesized from a DPMM. Evaluation computed as average over 10,000 held-out sequences of length 100. Negative log-likelihoods are expressed in nats per timestep.

Figure 2: Visualization of sample synthetic sequences generated from the normal-inverse-prior used in Section 4.1. Classes are sampled from a Chinese restaurant process (CRP) with \(=1.0\) and sequences consist of 100 timesteps. Clusters colored by true class label.

It can be shown (see Appendix A for details) that \(x_{d}\) can be expressed as being drawn from exponential family with a Beta prior on the hurdle probability \(p_{d}\) and a normal-inverse-gamma prior on the log-normal parameters \(_{d}\) and \(_{d}^{2}\). We apply this exponential family model independently to each of the 512 dimensions. Since the optimal hyperparameters for the particle filter are _a priori_ unknown, we metalearn the hyperparameters of the conjugate prior using the same minibatch setup as the neural circuit and Adam with learning rate of \(0.1\). Note that gradient estimation with respect to the hyperparameters is possible in the particle filter since the NLL of a sequence with sequential observations can be computed without the use of particles.

The results of this experiment are show in Table 2. Despite the effort to adapt the particle filter to this setting by carefully selecting the exponential family model, the neural circuit outperforms the particle filter by a large margin, both in terms of predictive performance and computational efficiency. Here, fully unobserved inference in the neural circuit is over \(100\) faster than the particle filter, since exponential family inference in the particle filter must be performed separately over each of the 512 dimensions. As expected, predictive performance of the neural circuit drops when evaluating on novel classes drawn from the meta-test set, as these novel classes represent patterns of activations the circuit has not encountered during metalearning. However, the neural circuit still significantly outperforms the particle filter even in this difficult setting. Importantly, the architecture and training procedure of the neural circuit is identical to our setup in the experiment with synthetic data (Section 4.1), which speaks to the versatility of our method.

### Robustness to Distribution Shift: Open-set Classification on iNaturalist 2018

In order to test the robustness of our neural circuits to a strong form of distribution shift, we apply circuits trained using ImageNet-CRP to open-set classification on the long-tailed iNaturalist 2018 dataset . iNaturalist consists of 437,513 images, each having labels at 7 taxonomic levels: kingdom, phylum, class, order, family, genus, and species. We therefore consider 7 versions of the task, each treating a different taxonomic level as the class label. This setting represents a distribution

    &  &  &  \\  Method & NLL (\(\)) & ARI (\(\)) & NLL (\(\)) & ARI (\(\)) & Seq. Obs. (\(\)) & Fully Unobs. (\(\)) \\  CRP & 1.005 & 0.010 & 1.003 & 0.009 & **0.019** & **0.185** \\ Softmax + Energy & 3.196 & 0.006 & 3.471 & 0.004 & 1883.066 & 1907.395 \\ Particle Filter & 0.848 & 0.070 & 0.933 & 0.048 & 2.407 & 73.896 \\ Neural Circuit & **0.255** & **0.749** & **0.680** & **0.271** & 0.067 & 0.412 \\   

Table 2: Results on Imagenet-CRP with ResNet-18 activations as features. Evaluation computed as average over 10,000 held-out sequences of length 100. Negative log-likelihoods are expressed in nats per timestep.

Figure 3: Diagrammatic representation of generating a Chinese restaurant process (CRP) using image data. At every sequence step \(t\), a class is sampled according to a CRP and then an image from that class is sampled without replacement.

shift not only in the images but also in the label statistics (though long-tailed, they are no longer drawn from a CRP).

Due to the fine-grained nature of iNaturalist 2018, for this section we modify the training of the neural circuits on ImageNet-CRP in several ways. First, we extlnd the sequence length to 500 during metalearning. The lower levels of the taxonomy have a large number of classes, meaning that the expected number of images per class is low for sequences of length 100. Second, we train a range of neural circuits, each with a different value of \(\{1,2,5,10,20,50,100,200\}\). This is because the coarser levels of the taxonomy may be better represented by low values of \(\) and the finer levels better represented by large values of \(\). Third, we use an ImageNet class split of 350 meta-train, 350 meta-validation, and 300 meta-test in order to mitigate the potential risk of overfitting.

Our baseline is a CRP with \(\) tuned to provide the best performance on that task. For each taxonomic level, we evaluate the neural circuit trained with the \(\) most similar to the CRP-tuned oracle \(\). This is meant to emulate the setting in which a learner has only a rough estimate of the level of diversity expected when encountering a new environment. In order to help bridge the input distribution shift, we also apply an affine transformation and ReLU activation on top of the ResNet-18 features extracted from iNaturalist. The weights of this layer are trained using a small number (\(n=10\)) of training sequences and early stopping is performed on the basis of validation sequences (\(n=10\)). The weights of the neural circuit remain frozen. A neural circuit that performs better than the CRP means that transfer from ImageNet-CRP to iNaturalist has successfully occurred. We construct test sequences from iNaturalist by sampling 1,000 randomly permuted sequences of length 100.

Our results (Table 3) show that positive transfer indeed occurs for three of the seven levels, indicating that the neural circuit is able to successfully transfer to novel open-set classification tasks in spite of distribution shift in both label and image statistics. Interestingly, the levels at which the neural circuit performs best are the higher levels, which there are likely to be multiple images per category.

We additionally perform an analysis to examine the effect of mismatch in \(\) between meta-train and meta-test. Our results (see Appendix C.2) indicate that for low-moderate levels of \(\), it may be beneficial to train on \(\) slightly higher than anticipated, whereas for larger values of \(\), it is best to match these statistics at meta-train time.

## 5 Related Work

Approximate solutions for nonparametric Bayesian models have historically used Markov chain Monte Carlo (MCMC)  or variational inference , with examples including Gaussian processes , Indian-Buffet processes [18; 59], and the Dirichlet process models we consider here [9; 47]. These approaches, however, assume a batch setting that is not efficient for sequential inference. Inference can be made more efficient in sequential settings by considering online variational inference with fixed update costs  or various forms of variational particle filtering [37; 42; 52]. However,

    &  &  \\  Taxonomy & Tuned \(\) & NLL & Pretrained \(\) & Min. NLL & Mean NLL & Max. NLL \\  Kingdom & 0.6 & 0.70 & 1 & **0.37** & **0.42** & **0.55** \\ Phylum & 2.1 & 1.30 & 2 & **0.80** & **0.84** & **0.88** \\ Class & 5.3 & 1.82 & 5 & **1.27** & **1.31** & **1.35** \\ Order & 33.1 & **2.24** & 20 & 2.15 & 2.28 & 2.49 \\ Family & 144.5 & **1.56** & 100 & 1.58 & 1.62 & 1.74 \\ Genus & 758.6 & **0.53** & 200 & 0.58 & 0.59 & 0.60 \\ Species & 1584.9 & **0.28** & 200 & 0.38 & 0.39 & 0.40 \\   

Table 3: Dataset transfer from ImageNet-CRP to iNaturalist 2018. The \(\) of the CRP baseline is tuned to provide optimal performance, whereas the neural circuit \(\) is selected within \(\{1,2,5,10,20,50,100,200\}\) to be closest to the tuned CRP \(\). Evaluation is performed on 1,000 randomly permuted sequences of length 100 from iNaturalist 2018 at each of 7 taxonomic levels. The average NLL per timestep is reported in terms of minimum, mean, and maximum across 5 runs with different random seeds. Best results are highlighted in bold.

overly restrictive distributional assumptions (e.g. exponential family) can hinder performance when working with complex feature spaces such as neural network representations.

Amortized inference [35; 49] is better suited to complex problem domains since it learns a function that maps directly from inputs to an approximate posterior distribution, effectively amortizing the cost of variational inference. Several works have considered amortized inference over Dirichlet priors [21; 34; 43], Gaussian process priors , and nested Chinese Restaurant Process priors . Similar to the classic approaches mentioned above, these methods belong to the family of batch inference solutions. Sequential variational autoencoders [15; 25; 28; 38] offer an online solution but none of these approaches are suitable for sequential inference in a DPMM.

Our neural circuit approach offers a scalable solution to sequential nonparametric Bayesian inference in a DPMM. We do so by using metalearning to incorporate the inductive bias of a nonparametric Bayesian model into the learned network rather explicitly instantiating such a model. This is reminiscent of previous metalearning approaches that train with "episodes"  to learn a general prior distribution over weight initializations [24; 27], languages , or supervised regression and classification problems . Similarly, our method can be viewed as learning an implicit application of Bayes' rule in a sequential setting  where meta-learning defines Bayesian updates over complicated distributional assumptions . We use sequences of observations and labels that can also be viewed as a kind of episode, but our goal is different: we aim to perform sequential inference over an unbounded number of classes. Compared to the previously mentioned approaches using variational inference or amortized inference, we leverage metalearning to directly learn a distribution over class labels rather than jointly learning encoder and decoder networks to maximize a variational lower bound on the log likelihood of the observations.

Related to our aims, the goal of open set recognition (OSR) is, broadly speaking, to detect previously unseen classes while accurately predicting known classes . Several early approaches to OSR focus solely on detecting previously unseen classes, either using traditional machine learning methods [12; 13; 32; 55; 68] and, more recently, creating neural networks with open-set capabilities [7; 17; 57]. Bendale and Boult  first treated OSR as an incremental learning problem by using extracted image features to perform metric learning over known classes initially, and performing incremental class learning thereafter. This method employs thresholded distances from the nearest class mean as its decision function. Rudd et al.  advanced this approach by introducing distributional information into the thresholding process. Both methods rely on large datasets of known classes.  introduced a metalearning formulation of OSR based on thresholding prototypical embeddings  to address this limitation. Similarly, Willes et al.  proposed a method called FLOWR that combines prototypical embeddings with Bayesian nonparametric class priors. These methods operate in the sequential observation setting, observing the true class label after every prediction, and explicitly learn a metric space end-to-end instead of performing inference over arbitrary input features (including possibly representations extracted from a pretrained network) as we do. The particle filter baselines  we compare against closely resemble a variant of FLOWR modified for our setting.

## 6 Conclusion

We have proposed neural circuits for sequential nonparametric Bayesian inference: metalearning a recurrent neural network to capture the inductive bias of a DPMM that generates the training sequences. Our approach outperforms particle filter baselines in predictive performance while being more computationally efficient. Neural circuits are simple to implement and flexible enough to handle complex inputs with minimal modifications to their training procedure and architecture. In future work, we plan to use the neural circuit approach to capture inductive biases of more complex nonparametric Bayesian models with richer latent spaces.

Two limitations of our neural circuit approach are i) the difficulty of metalearning as \(\), and ii) misspecification of the base distribution when there is a mismatch between the data generating distribution of meta-train and meta-test sets. Classical DPMMs specify these quantities explicitly, making modeling assumptions easier to identify and reason about. The process of meta-learning - learning the model itself from data - brings about different challenges. Care should be taken when deploying the model in scenarios where the diversity in labels differs greatly from metalearning. Additionally, large \(\) values may be difficult to learn due to the infrequency of repeated class instancesin meta-training sequences. In future work we plan to explore how these challenges can be addressed through curriculum learning.

Neural circuits are broadly applicable to the growing use of foundation models and pre-trained networks. They bridge the gap between Bayesian nonparametric methods, which often make more appropriate assumptions for real-world scenarios, and the powerful representations of neural networks. This integration allows existing neural networks to be adapted for tasks such as open-set recognition within a principled and efficient Bayesian framework, without the need to retrain the base model. We anticipate that this approach can be used in a wide range of settings to be able to deploy interpretable models with more explicit inductive biases build on top of expressive representations for complex datasets.