# Only Strict Saddles in the Energy Landscape of Predictive Coding Networks?

Francesco Innocenti

School of Engineering and Informatics

University of Sussex

F.Innocenti@sussex.ac.uk

&El Mehdi Achour

RWTH Aachen University

Aachen, Germany

achour@mathc.rwth-aachen.de

Ryan Singh

School of Engineering and Informatics

University of Sussex

rs773@sussex.ac.uk

&Christopher L. Buckley

School of Engineering and Informatics

University of Sussex

VERSES

c.l.buckley@sussex.ac.uk

###### Abstract

Predictive coding (PC) is an energy-based learning algorithm that performs iterative inference over network activities before updating weights. Recent work suggests that PC can converge in fewer learning steps than backpropagation thanks to its inference procedure. However, these advantages are not always observed, and the impact of PC inference on learning is not theoretically well understood. To address this gap, we study the geometry of the PC weight landscape at the inference equilibrium of the network activities. For deep linear networks, we first show that the equilibrated PC energy is equal to a rescaled mean squared error loss with a weight-dependent rescaling. We then prove that many highly degenerate (non-strict) saddles of the loss including the origin become much easier to escape (strict) in the equilibrated energy. Experiments on both linear and non-linear networks strongly validate our theory and further suggest that all the saddles of the equilibrated energy are strict. Overall, this work shows that PC inference makes the loss landscape of feedforward networks more benign and robust to vanishing gradients, while also highlighting the fundamental challenge of scaling PC to very deep models.

## 1 Introduction

Originating as a general principle of brain function, predictive coding (PC) has in recent years been developed into a local learning algorithm that could provide a biologically plausible alternative to backpropagation (BP) . Deep neural networks (DNNs) trained with PC have shown comparable performance to BP on standard small-to-medium machine learning tasks, including classification, generation and memory association . PC networks (PCNs) are also highly versatile, allowing for arbitrary computational graphs , hybrid and causal inference , and temporal prediction .

In contrast to BP, and similar to other energy-based algorithms [e.g. 49, 38], PC performs iterative (approximately Bayesian) inference over network activities before weight updates. This has been recently described as a fundamentally different principle of credit assignment for learning in the brain called "prospective configuration" , where weights follow activities (rather than the other way around). While the inference process key to PC incurs an additional computational cost, it has been suggested to provide many benefits for learning including faster convergence . However,these speed-ups are not consistently observed across datasets, models and optimisers , and the impact of PC inference on learning more generally is not theoretically well understood (see SSA.2.1).

To address this gap, we study the geometry of the effective landscape on which PC learns: _the weight landscape at the inference equilibrium of the network activities_ (defined in SS2.2). Our theory considers deep linear networks (DLNs), the standard model for theoretical studies of the loss landscape (see SSA.2). Despite being able to learn only linear representations, DLNs have non-convex loss landscapes with non-linear learning dynamics that have proved to be a useful model for understanding non-linear networks [e.g. 48]. In contrast to previous theories of PC [3; 2; 18], we do not make any additional assumptions or approximations (see SSA.2), and we empirically verify that our linear theory holds for non-linear networks.

For DLNs, we first show that, at the inference equilibrium, the PC energy is equal to a rescaled mean squared error (MSE) loss with a non-trivial, weight-dependent rescaling (Theorem 1). We then compare saddle points of the loss, which have been recently characterised [23; 1], to those of the equilibrated energy. Such saddles, which are ubiquitous in the loss landscape of neural networks [11; 1], can be of two main types: "strict", where the Hessian is indefinite (Def. 1); and "non-strict", where an escape direction is found in higher-order derivatives [15; 23; 1]. Non-strict saddles are particularly problematic for first-order methods like (stochastic) gradient descent (SGD) since they are by definition at least second-order critical points. While SGD can be exponentially slowed in the vicinity of strict saddles , it can effectively get stuck in non-strict ones [47; 7] (see SSA.2 for a review). This is the phenomenon of vanishing gradients viewed from a landscape perspective [39; 6].

By contrast, here we prove that many non-strict saddles of the MSE loss, specifically saddles of rank zero, become strict in the equilibrated energy of any DLN (Theorems 2 & 3). These saddles include the origin, whose degeneracy (i.e. flatness) in the loss grows with the number of hidden layers. Our theoretical results are strongly validated by experiments on both linear and non-linear networks, and additional experiments suggest that other (higher-rank) non-strict saddles of the loss are strict in the equilibrated energy. Based on these results, we conjecture that all the saddles of the equilibrated energy are strict. Overall, this work suggests that PC inference makes the loss landscape more benign and robust to vanishing gradients, while also highlighting the fundamental challenge of speeding up PC inference on deeper networks.

The rest of the paper is structured as follows. After introducing the setup (SS2), we present our theoretical results for DLNs (SS3), including some illustrative examples and thorough empirical verifications of each result. We then report experiments on non-linear networks supporting our theory and more general conjecture (SS4). We conclude by discussing the implications and limitations of our work, as well as potential future directions (SS5). Appendix A includes a review of related work, derivations, experiment details and supplementary results. Code to reproduce all the experiments is available at [https://github.com/francesco-innocenti/pc-saddles](https://github.com/francesco-innocenti/pc-saddles).

### Summary of contributions

* We derive an exact solution for the PC energy of DLNs at the inference equilibrium (Theorem 1), which turns out to be a rescaled MSE loss with a weight-dependent rescaling. This corrects a previous mistake in the literature that the MSE loss is equal to the output energy  (which holds only at the feedforward pass) and enables further studies of the PC energy landscape. We find an excellent match between our theory and experiment (Figure 1).
* Based on this result, we prove that, in contrast to the MSE, the origin of the equilibrated energy of DLNs is a strict saddle independent of network depth. We provide an explicit characterisation of the Hessian at the origin of the equilibrated energy (Theorem 2), which is perfectly validated by experiments on linear networks (Figures 3, 4 & 8).
* We further prove that other non-strict saddles of the MSE than the origin, specifically saddles of rank zero, become strict in the equilibrated energy of DLNs (Theorem 3). We provide an empirical verification of one of these saddles as an example (Figures 9 & 10).
* We empirically show that our linear theory holds for non-linear networks, including convolutional architectures, trained on standard image classification tasks. In particular, when initialised close to non-strict saddles of the MSE covered by Theorem 3, we find that SGD on the equilibrated energy escapes much faster than on the loss given the same learning rate (Figures 5 & 12). In contrast to BP, PC exhibits no vanishing gradients (Figure 11).

* We perform additional experiments, again on both linear and non-linear networks, showing that PC quickly escapes other (higher-rank) non-strict saddles of the MSE that we do not address theoretically (Figure 6), supporting our conjecture that all the saddles of the equilibrated energy are strict.

## 2 Preliminaries

Notation.We use the following shorthand \(_{k}=_{k}_{}\) for \(,k 1,,L\), denoting the total product of weight matrices as \(_{L:1}=_{L}_{1}\). \(_{n}\) is the \(n n\) identity matrix, while \(_{n}\) denotes either the \(n\)-zero vector or the \(n n\) null matrix, and \(n\) will be omitted when clear from context. \(||||\) denotes the \(_{2}\) norm, and \(\) is the Kronecker product between two matrices. We will consider the gradient and Hessian of an objective \(f\) only with respect to the network weights \(\) and sometimes abbreviate them as \(_{f}_{}f\) and \(_{f}_{}^{2}f\), respectively, omitting the independent variable for simplicity. The largest and smallest eigenvalues of the Hessian are \(_{}(_{f})\) and \(_{}(_{f})\), with \(}_{}\) and \(}_{}\) as their associated eigenvectors. See SSA.1 for more general notation.

**Definition 1**.: _Strict saddle._ Following  and later work, any critical point \(^{*}\) of \(f()\) where \(_{f}(^{*})=\) is defined as a strict saddle when the Hessian at that point has at least one negative eigenvalue, \(_{}(_{f}(^{*}))<0\). Any other critical point with a positive semi-definite Hessian and at least one negative eigenvalue in a higher-order derivative is said to be a non-strict saddle.

### Deep Linear Networks (DLNs)

We consider DLNs with one or more hidden layers \(H=L-1 1\) defining the linear mapping \(_{L:1}:^{d_{x}}^{d_{y}}\) where \(_{}^{n_{} n_{-1}}\), with layer widths \(\{n_{}\}_{=0}^{L}\) and input and output dimensions \(n_{0}=d_{x},n_{L}=d_{y}\). We ignore biases for simplicity. The standard MSE loss for DLNs can then be written as

\[=_{i=1}^{N}||_{i}-_{L:1} _{i}||^{2}, \]

for a dataset of \(N\) examples \(\{(_{i},_{i})\}_{i=1}^{N}\) where \(^{d_{x}}\), \(^{d_{y}}\). The total number of weights is given by \(p=_{=1}^{L}n_{}n_{-1}\), and we will denote the set of all network parameters as \((_{1},,_{L}) ^{p}\). For brevity, we will often refer to the MSE loss as simply the loss.

### Predictive coding (PC)

DNNs trained with PC typically assume a hierarchical Gaussian model with identity covariances, so we will adopt this formulation for linear fully connected layers \(_{}(_{}_{-1}, _{})\) where the mean activity of each layer \(_{}\) is a linear function of the previous layer. Under some other common assumptions about the generative model, we can derive an energy function, often referred to as the variational free energy, which is a sum of squared prediction errors across layers :

\[=_{i=1}^{N}_{=1}^{L}||_{,i}- _{}_{-1,i}||^{2}. \]

Note that this objective defines an energy for every neuron, highlighting the locality of the algorithm. To train a PCN, the last layer is clamped to some data, \(_{L,i}_{i}\), which could be a label for classification or an image for generation. In a supervised task, the first layer is also fixed to some input, \(_{0,i}_{i}\). The energy (Eq. 2) is then minimised in two phases, first w.r.t. the activities (inference) and then w.r.t. the weights (learning):

\[}_{}-}{_{}}(}) }_{}-}{_{}} \]

where we omit the data index \(i\) for simplicity. In practice, the inference dynamics (Eq. 3) are often run to convergence until \(_{} 0\), before performing a weight (e.g. GD) update (Eq. 4). Importantly, the effective weight landscape on which PC learns is therefore the energy at the inference equilibrium \(|_{}()\), which we will refer to as the equilibrated energy or sometimes simply the energy.

## 3 Theoretical results

### Equilibrated energy as rescaled MSE

As explained in SS2.2, the weights of a PCN are typically updated once the activities have converged to an equilibrium. The equilibrated energy \(|_{/=0}()\), which we will abbreviate as \(^{*}()\), is therefore the effective learning landscape navigated by PC and the object we are interested in studying. It turns out that we can derive a closed-form solution for the equilibrated energy of DLNs, which will be the basis of our subsequent results.

**Theorem 1** (Equilibrated energy of DLNs).: _For any DLN parameterised by \((_{1},,_{L})\) with input and output \((_{i},_{i})\), the PC energy (Eq. 2) at the exact inference equilibrium \(/=\) is the following rescaled MSE loss (see SSA.3.2 for derivation)_

\[^{*}=_{i=1}^{N}(_{i}-_{L:1} _{i})^{T}^{-1}(_{i}-_{L:1} _{i}) \]

_where the rescaling is \(=_{d_{y}}+_{=2}^{L}(_{L:})(_{L:})^{T}\)._

The proof relies on unfolding the hierarchical Gaussian model assumed by PC to work out the full, implicit generative model of the output, and the rescaling \(\) comes from the variance modelled by PC at each layer (see SSA.3.2 for details). Figure 1 shows an excellent empirical validation of the theory.

Intuitively, the PC inference process (Eq. 3) can then be thought of as reshaping the (MSE) loss landscape to take some layer-wise, weight-dependent variance into account. This immediately raises the question: how does the equilibrated energy landscape \(^{*}()\) differ from the loss landscape \(()\)? Is the rescaling--and so the layer variance modelled by PC--useful for learning? Below we provide a partial positive answer to this question by comparing the saddle point geometry of the two objectives.

### Analysis of the origin saddle (\(=\))

Here we prove that, in contrast to the MSE loss, the origin of the equilibrated energy (Eq. 5, where all the weights are zero, \(=\)) is a strict saddle (Def. 1) for DLNs of any depth. To do so, we derive an explicit expression for the Hessian at the origin of the equilibrated energy. For intuitive

Figure 1: **Empirical verification of the theoretical equilibrated energy of deep linear networks (Theorem 1). For different datasets, we plot the energy (Eq. 2) at the numerical inference equilibrium \(|_{/ 0}\) for DLNs with different number of hidden layers \(H\{2,5,10\}\) (see SSA.4 for more details), observing an excellent match with the theoretical prediction (Eq. 5).**comparison, we first briefly recall the known results that, at the origin, the loss Hessian is indefinite for one-hidden-layer networks and zero for any deeper network (see SSA.3.1 for a re-derivation)

\[_{}(=)=&- }_{}_{n_{1}}\\ -_{n_{1}}}_{}&,&H=1\\ \\ _{p},&H>1, \]

where following previous works \(}_{}_{i}^{N}_{i}_{i}^{T}\) is the empirical input-output covariance. One-hidden-layer networks \(H=1\) are a special case where the origin saddle of the loss is strict (Def. 1) and was studied in detail by  (see left panel of Figure 2 for an example). For deeper networks \(H>1\), the saddle is non-strict as first shown by :

\[_{}(_{}(= ))<0,&H=1\\ \\ _{}(_{}(=))=0,&H>1 . \]

More specifically, the origin saddle of the loss is of order \(H\)1, becoming increasingly degenerate (flat) and harder to escape with depth, especially for first-order methods like SGD (see middle and right panels of Figure 2).

By contrast, now we show that the origin saddle of the equilibrated energy is strict for DLNs of any number of hidden layers. Figure 2 shows a few toy examples illustrating the result. In brief, we

Figure 2: **Toy examples illustrating the (Theorem 2) result that the saddle at the origin of the equilibrated energy is strict independent of network depth.** We plot the MSE loss \(()\) (_top_) and equilibrated energy landscape \(^{*}()\) (_middle_) around the origin for 3 linear networks trained with SGD on a toy problem (see SSA.4 for details). We also show the training losses for a representative run with initialisation close to the origin (_bottom_). For the one-dimensional networks, we visualise the landscape around the origin as well as the SGD updates. For the wide network, we project the landscape onto the maximum and minimum eigenvectors of the Hessian, following . Note that in this case the projection of the loss is flat because the Hessian at the origin is zero for \(H>1\) (Eq. 6).

observe that, when initialised close to the origin saddle, SGD takes increasingly more time to escape from the loss than the energy as a function of depth (for the same learning rate). Now we state the result more formally. The Hessian at the origin of the equilibrated energy turns out to be (see SSA.3.3 for derivation)

\[_{^{*}}(=)=[ &-}_{}_{n _{1}}\\ -_{n_{1}}}_{}&-}_{} I_{n_{L-1}}],&H=1\\ [&&\\ &&\\ &&-}_{} I_{n_{L-1}} ],&H>1, \]

where \(}_{}_{i}^{N}_{i}_{i}^{T}\) is the empirical output covariance. We see that, in contrast to the loss Hessian (Eq. 6), the energy Hessian has a non-zero last diagonal block given by \(^{2}^{*}/_{L}^{2}\), for any number of hidden layers \(H\). It is then straightforward to show that the energy Hessian has always negative eigenvalues, since the output covariance is positive definite.

**Theorem 2** (Strictness of origin saddle of the equilibrated energy).: _The Hessian at the origin of the equilibrated energy (Eq. 5) for any DLN has at least one negative eigenvalue (see SSA.3.3 for proof)_

\[_{min}(_{^{*}}(=))<0, H  1. \]

Figures 3 & 4 show a perfect match between the theoretical (Eq. 8) and numerical Hessian at the origin of the equilibrated energy, which we computed for a range of DLNs on a random batch of toy as well as more realistic datasets.

Figure 3: **Empirical verification of the Hessian at the origin of the equilibrated energy for DLNs tested on toy data.** We show the Hessian and its eigenspectrum at the origin of the MSE loss (_top_) and equilibrated energy (_middle_) for DLNs with Gaussian target \(=-\) where \((1,0.1)\) (see SSA.4 for details). Note that purple bars show overlapping loss and energy Hessian eigendensity. In the right panel, we vary one of the output dimensions to be \(y_{2}=x_{2}\). We confirm the strictness of the origin saddle in the equilibrated energy and observe an excellent numerical validation of our theoretical Hessian (Eq. 8). Figure 8 shows the same results for one-dimensional networks, and Figure 4 shows similar results for more realistic datasets.

Theorem 2 proves that the origin is a strict saddle of the equilibrated energy for DLNs of any depth. This is in stark contrast to the MSE loss where it is only true for one-hidden-layer networks \(H=1\) (Eq. 7). The result predicts that, near the origin, (S)GD should escape the saddle faster on the equilibrated energy than on the loss given the same learning rate, and increasingly so as a function of depth. Figure 2 confirms this prediction for some toy linear networks, and Figures 5 & 6 in SS4 clearly show that it holds for non-linear networks as well.

### Analysis of other saddles

Is the origin a special case where the equilibrated energy has an easier-to-escape saddle than the loss? Or is this result pointing to something more general? Here we consider a specific type of non-strict saddle of the loss (of which the origin is one) and show that indeed they also become strict in the equilibrated energy. We address other saddle types experimentally in SS4 and leave their theoretical study for future work.

Specifically, we consider saddles of rank zero, which for the MSE can be identified as critical points where the product of weight matrices is zero \(_{L:1}=\). For the equilibrated energy (Eq. 5), we consider the critical points \(^{*}(_{L}=,_{L-1:1}=)\), since the last weight matrix needs to be null in order for the energy gradient to be zero (see SSA.3.3 for an explanation). It turns out that at these critical points there exists a direction of negative curvature.

**Theorem 3** (Strictness of zero-rank saddles of the equilibrated energy).: _Consider the set of critical points of the equilibrated energy (Eq. 5) \(^{*}(_{L}=,_{L-1:1}=)\) where \(_{^{*}}(^{*})=\). The Hessian at these points has at least one negative eigenvalue (see SSA.3.6 for proof)_

\[(_{^{*}}(^{*}))<0 . \]

Note that Theorem 2 can now be seen as a corollary of Theorem 3, although for the origin we derived the full Hessian. This result also stands in contrast to the (MSE) loss, where many of the considered critical points (specifically when 3 or more weight matrices are zero) are non-strict saddles as proved by . The prediction is again that, in the vicinity of any of these saddles, PC should escape faster than BP with (S)GD given the same learning rate. For space reasons, the subsequent experiments focus only the origin as an example of a saddle covered by Theorem 3 (and Theorem 2), but SSA.5 includes an empirical validation of another (zero-rank) strict saddle of the equilibrated energy (Figures 9, 10 & 12). Our code also makes it relatively easy to test for other saddles.

Figure 4: **Empirical verification of the Hessian eigenspectrum at the origin of the equilibrated energy for DLNs tested on more realistic datasets. This shows similar results to Figure 3 for the more realistic datasets MNIST and MNIST-1D  (see §A.4 for details). We again find a perfect match between theory and experiment for DLNs with different number of hidden layers \(H\{1,2,4\}\), confirming the strictness of the origin saddle of the equilibrated energy.**

Experiments

Here we report experiments on linear and non-linear networks supporting our theoretical results as well as more general conjecture that all the saddles of the equilibrated energy are strict. In all the experiments, we trained networks with BP and PC using (S)GD with the same learning rate, since the goal is to test our theory of the saddle geometry of the equilibrated energy landscape. Code to reproduce all the results is available at [https://github.com/francesco-innocenti/pc-saddles](https://github.com/francesco-innocenti/pc-saddles).

First, we compared the training loss (MSE) dynamics of linear and non-linear networks, including convolutional architectures, on standard image classification tasks with SGD initialised close to the origin (see SSA.4 for details). For computational reasons, we did not run the BP-trained networks to convergence, underscoring the point that the origin saddle of the loss is highly degenerate and particularly hard to escape for first-order methods like SGD. In all cases, we observe that PC escapes the origin saddle substantially faster than BP (Figure 5), and Figure 11 shows that PC exhibits no vanishing gradients. We find practically the same results when initialising close to another non-strict saddle of the loss covered by Theorem 3 (Figure 12). These findings support our theoretical results beyond the linear case.

From Figure 5, we also observe a second plateau in the loss dynamics of PCNs, suggesting a saddle of higher rank (presumably rank 1). This is consistent with the saddle-to-saddle dynamics described for DLNs by , where for small initialisation GD transitions through a sequence of saddles, each representing a solution of increasing rank.

To explicitly test for higher-rank, non-strict saddles of the loss that we did not study theoretically, we replicated one of the experiments by [19, cf. Figure 1] on a matrix completion task. In particular, networks were trained to fit a rank-3 matrix, which meant that starting near origin GD visited 3 saddles (of successive rank 0, 1 and 2) before converging to a rank-3 solution as shown in Figure 6. We find that, when initialised near any of the saddles visited by BP, PC escapes quickly and does not show vanishing gradients (Figure 6), supporting the conjecture that all the saddles of the equilibrated energy are strict.

Figure 5: **PC escapes the origin saddle much faster than BP with SGD on non-linear networks.** We plot the training loss (MSE) for a representative run of BP and PC for linear and non-linear networks trained on standard image classification tasks (see §A.4 for details). All networks were initialised close to the origin with scale \(=5e^{-3}\)), and trained with SGD and learning rate \(=1e^{-3}\). The networks trained on MNIST and Fashion-MNIST had 5 fully connected layers, while those trained on CIFAR-10 had a convolutional architecture. See Figure 11 for the corresponding weight gradient norms during training. Results were consistent across different random seeds.

## 5 Discussion

In summary, we took a first step in characterising the effective landscape on which PC learns--the energy landscape at the inference equilibrium. For DLNs, we first showed that the equilibrated energy is equal to a rescaled MSE loss with a weight-dependent rescaling (Theorem 1). This result corrects a previous mistake in the literature that the MSE loss is equal to the output energy  and that the total energy (Eq. 2) can therefore be decomposed into the loss and the other (hidden) energies (a relationship that only holds at the feedforward activity values). As we expand on below, Eq. 5 also enables further studies of the PC learning landscape.

We then proved that many non-strict saddle points of the MSE loss, specifically zero-rank saddles, become strict in the equilibrated energy of any DLN (Theorems 2 & 3). These saddles include the origin, making PC effectively more robust to vanishing gradients (Figures 6 & 11). We thoroughly validated our theory with experiments on both linear and non-linear architectures, and provided empirical support for the strictness of higher-rank saddles of the equilibrated energy. Based on these results, we conjecture that all the saddles of the equilibrated energy are strict. Overall, the PC inference process can therefore be interpreted as making the loss landscape more benign.

### Implications

Our work goes significantly beyond existing theories of PC in terms of both explanatory and predictive power. Most previous works make non-standard assumptions or loose approximations that result in non-specific experimental predictions. For example, the interpretation of PC as implicit GD by  holds only for small batch sizes and specific layerwise rescalings of the activities and parameter learning rates. ( generalised this result to remove the activity rescalings but not the learning rate ones.) By contrast, linearity is the only major assumption made our theory, and we empirically verify that all the results hold for non-linear networks. Similarly, both  and  make second-order approximations of the energy to argue that PC makes use of Hessian information. However, our results clearly show that PC can leverage much higher-order information, turning highly degenerate, \(H\)-order saddles into strict (first-order) ones.

Previous theories have also struggled to explain why faster learning convergence with PC is not always observed depending on the task, model and optimiser . Our landscape analysis, while incomplete (more on this below), acknowledges these factors and their interplay, helping to explain inconsistent findings and predict when speed-ups can and cannot be expected. All things being equal, PC should converge faster on deep and _narrow_ networks (though perhaps not too deep as we discuss below), since the distance between the origin saddle and standard initialisations scales with the network width . This likely explains the speed-up reported by  on a narrow (\(n_{}=64\)

Figure 6: **PC quickly escapes higher-rank saddles visited by BP with GD on a matrix completion task.** We plot the training loss (_top_) and corresponding weight gradient norms of the loss (BP) and equilibrated energy (PC) (_bottom_) for networks (\(H=3\), \(n_{}=100\)) trained with full-batch GD to fit a random rank-3 matrix as studied by . BP-trained networks were initialised near the origin with scale \(=5e^{-3}\), while PCNs were initialised at each saddle visited by BP (see §A.4 for details). Results were consistent across different random seeds.

15-layer fully connected network. However, in practice all things are not equal, and everything from not reaching an inference equilibrium to different datasets, architectures and optimisers all interact to determine convergence. This raises the question of whether minimising the equilibrated energy could be faster than the loss or lead to better performance, which we return to below.

More broadly, our landscape theory closely relates to the work of , who showed that learning in linear physical systems with equilibrium propagation  has beneficial effects on the activity (rather than weight) Hessian. Studying these connections--and more generally the benefits of inference for learning in energy-based systems--could be an interesting future direction.

Our work has also implications for theories of credit assignment in the brain. In particular, our results put the recent principle of prospective configuration  for energy-based learning on a more solid theoretical footing, showing that PC inference can indeed facilitate learning by using high-order information. At the same time, they suggest that the claim of universally faster learning convergence with PC may have been overstated .

### Limitations

We conclude by addressing the main limitations of our work. First, the strictness of the energy saddles we studied holds, by derivation, only at the exact inference equilibrium. We note that one does not need to reach equilibrium to improve the degeneracy of the loss saddles, and in this sense PC could be seen as a resource. However, in practice PC inference requires increasingly more iterations to converge on deeper networks, which aligns with our landscape theory since the loss saddles become more and more degenerate with depth. Our results therefore highlight the fundamental challenge of speeding up PC inference on deeper models if its benefits for learning are to be realised on large-scale tasks .

Even if this challenge is overcome, there seem to be two interlinked questions that ultimately matter for the practical training of deep networks. First, are there conditions under which the equilibrated energy can be minimised faster than the loss in a more compute- or memory-efficient manner, with at least equal performance? Optimisation tools such as Adam  and skip connections , for example, help to deal with the origin saddle at an increased memory cost. Could this trade off with the compute cost of PC inference? Characterising the inference cost of PC more formally would be a useful step in this direction.

Second, could there be scenarios where PC is slower or less efficient but at the benefit of significantly better performance? This is a hard question to address since we are far from having a theory of generalisation in deep learning . Given our origin saddle result (Theorem 2), however, it is interesting to note that on problems where a low-rank bias is useful (e.g. matrix completion, Figure 6), GD with small initialisations can converge to better-generalising solutions compared to standard initialisation .

Finally, understanding the overall convergence behaviour of PC would also require characterising other critical points of the equilibrated energy, especially its minima . Our work, and Eq. 5 in particular, enables this. In SSA.3.7, we present a preliminary investigation showing that, for linear chains, the global minima of the equilibrated energy are _flatter_ than those of the MSE loss. This result potentially explains the common observation that PC convergence tends to slow down towards the end of training, but we leave its full implications for future work.