# Structured Learning of

Compositional Sequential Interventions

Jialin Yu\({}^{1}\) Andreas Koukorinis\({}^{1}\) Nicolo Colombo\({}^{2}\) Yuchen Zhu\({}^{1}\) Ricardo Silva\({}^{1}\)

\({}^{1}\)University College London

\({}^{2}\)Royal Holloway, University of London

###### Abstract

We consider sequential treatment regimes where each unit is exposed to combinations of interventions over time. When interventions are described by qualitative labels, such as "close schools for a month due to a pandemic" or "promote this podcast to this user during this week", it is unclear which appropriate structural assumptions allow us to generalize behavioral predictions to previously unseen combinations of interventions. Standard black-box approaches mapping sequences of categorical variables to outputs are applicable, but they rely on poorly understood assumptions on how reliable generalization can be obtained, and may underperform under sparse sequences, temporal variability, and large action spaces. To approach that, we pose an explicit model for _composition_, that is, how the effect of sequential interventions can be isolated into modules, clarifying which data conditions allow for the identification of their combined effect at different units and time steps. We show the identification properties of our compositional model, inspired by advances in causal matrix factorization methods. Our focus is on predictive models for novel compositions of interventions instead of matrix completion tasks and causal effect estimation. We compare our approach to flexible but generic black-box models to illustrate how structure aids prediction in sparse data conditions.

## 1 Contribution

Many causal inference questions involve a treatment sequence that varies over time. In the (discrete) time-varying scenario, an _unit_\(n\) is exposed to a sequence \(D^{1}_{n},D^{2}_{n},D^{3}_{n},\) of _actions_, or _treatments_, potentially controllable by an external agent [22, Ch. 19] intervening on them. Each \(D^{t}_{n}\) can be interpreted as a cause of the subsequent behavior \(X^{t}_{n},X^{t+1}_{n},\), and its modeling amenable to the tools of causal inference [e.g., 35, 36, 31, 17, 11, 49]. For instance, each \(D^{t}_{n}\) can take values in the space of particular drug dosages which can be given to an in-patient, or combinations of items to be promoted to a user of a recommender system. Here, patients and users are the units, and \(X^{t}_{n}\) denotes a measure of their state or behavior under time \(t\). Dependencies can result in a dense causal graph, as in Fig. 1. Further background on this classical problem is provided in Appendix A.

Figure 1: Within unit \(n\), actions \(D^{t}_{n}\) interact with (latent) random effect parameters \(_{n}\) to produce behavior \(X^{t}_{n}\) represented as a dense graphical model with square vertices denoting interventions \((d^{1:t}_{n})\). Further assumptions will be required for the identifiability of the impact of interventions and their combination, including how temporal impact takes shape and the number of independent units of observation.

**Scope.** We introduce _an approach to predict the effects of actions within a combinatorial and sparse space of categorical intervention sequences_. That is, for an unit \(n\) and given past behavioral sequence \(X_{n}^{1:t-1}:=[X_{n}^{1},,X_{n}^{t-1}]\), manipulable variables \(D_{n}^{1:t-1}:=[D_{n}^{1},,D_{n}^{t-1}]\) and time-fixed covariates \(Z_{n}\), we predict future behavior \(X_{n}^{t},X_{n}^{t+1},,X_{n}^{t+}\) under the (partially hypothetical) interventional regime \((d_{n}^{1:t+})\). The latter denotes controlling the action variables by external intervention . For mean-squared error losses, prediction means learning \([X_{n}^{t+} x_{n}^{1:t-1},z_{n},(d_{n}^{1:t+ })]\), \(0\). We consider the case where sequential ignorability holds, by randomization or adjustment , in order to focus on predictive guarantees for previously unseen action sequences.

Challenge.Much of the sequential intervention literature in AI and statistics considers generic black-box or parametric models1 to map sequences \(D_{n}^{1:t}:=[D_{n}^{1},D_{n}^{2},,D_{n}^{t}]\) to behavior \(X_{n}^{t}\) and beyond, sometimes exploiting strong Markovian assumptions or short sequences and small action spaces . An unstructured black-box for sequences, such as recurrent neural networks and their variants [e.g. 23, 13, 45], can learn to map a sequence to a prediction. This is less suitable when actions are categorical and _sparse_, in the sense that most entries correspond to some baseline category of "no changes". That is, there is no obvious choice of smoothing or interpolation criteria to generalize from seen to unseen strings \(D_{n}^{1:T}\), with the practical assumption being that we observe enough variability to reliably perform this interpolation. There is an increased awareness of problems posed by large discrete spaces among pre-treatment covariates , which is of a different nature as losses can be minimized with respect to an existing natural distribution, as opposed to the interventional problem where the action variables are allowed to be chosen and so sparsity conditions can easily result in very atypical test cases of interest. Several papers address large intervention spaces (mostly for non-sequential problems) without particular concerns about non-smooth, combinatorial identifiability . A few more recent papers address explicit assumptions of identifiability directly in combinatorial categorical spaces by sparse regression  or energy functions , but without a longitudinal component. More classically, tools like the do-calculus  and their extensions  can be used with directed acyclic graphs (DAGs) to infer combinatorial effects, although they often restrict each manipulated variable to directly affect only a small set of variables (e.g. ). With strong assumptions and computational cost, this may include latent variables . Alternative representation learning ideas for carefully extrapolating to unseen interventions are presented by  in the non-sequential, non-combinatorial, setting.

In this paper, we consider the conservative problem of _identification guarantees_ for the effect of sequential combinations of interventions which may never have co-occurred jointly in training data, _formalizing assumptions_ that allow for the transfer and recombination of information learned across units. These are not of the same nature as identifiability of causal effects from observational data  or causal discovery , but of _causal extrapolation_: even in the randomized (or unconfounded) regime, it is not a given that the distribution under a particular regime \((d_{n}^{1:t})\) can be reliably inferred from limited past combinations of action sequences without an explicit structure on the causal generative model. We will consider the case where actions imply _non-stationary transitions_: once unit \(n\) is exposed to \(D_{n}^{t}=d_{n}^{t}\), then \(X_{n}^{t+}\) will have transition dynamics that can be affected not only by the choice of \(d_{n}^{t}\) but also the difference \(\), resulting in dense dependency structures such as the one in Figure 1. As multiple treatments are applied to the same unit \(n\), there will be a _composition_ of effects that will depend not only on the labels of the actions, but also on the order by which they take place. If a substantive number of choices of treatments at time \(t\) is available, a large dataset may have no two sequences \(D_{n}^{1:T}\) and \(D_{n^{}}^{1:T}\) taking the same values, even when considering only the unique treatment values applied to \(n\) and \(n^{}\), regardless of ordering and time stamps.

Problem statement.Let each individual unit \(n\) be described by time-invariant features \(Z_{n}\) and a pair of time-series \((X_{n}^{1:T},D_{n}^{1:T})\). Here, \(V^{t_{1}:t_{2}}\) denotes a slice of a discrete-time time-series of variables \(V^{t}\) from \(t_{1}\) to \(t_{2}\), inclusive. That observations for all units stop at time \(T\) is not a requirement, but just a way of simplifying presentation. Each \(D_{n}^{t}\) is a categorical action variable which, when under external control, represents a potential _intervention_, encoded by values in \(\). We assume data is available under a sequentially ignorable selection of actions , either by randomization or consequences of an adjustment. \(D_{n}^{t}\) describes a (possibly hypothetical) intervention which causes changes to the distribution of \(X_{n}^{t:}\). The special value \(D_{n}^{t}=0\) denotes an "idle" or "default" treatment level that can be interpreted as "no intervention". We are given a training set of units\((Z_{n},X_{n}^{1:T},D_{n}^{1:T})\). The goal is to predict future sequence of behavior \(X_{n*}\) for a (training or test) unit \(n^{}\) under a hypothetical intervention sequence \((d_{n}^{1:T+})\). This process takes place under the stable unit treatment value assumption (SUTVA) , meaning that action variables \(D_{n}^{t}\) only affect unit \(n\).

Each intervention on \(D_{n}^{t}\) is allowed to have an impact on the whole future series \(t,t+1,t+2,\). It can correspond to an instantaneous shock ("give five dollars of credit at time \(t\)") or an action that takes place over an extended period of time ("promote this podcast from time \(t\) to time \(t+5\)"): we just assume the meaning to be directly encoded within arbitrary category labels \(0,1,2,3,\). In a real-world scenario where a same action can be applied more than once, different symbols in \(\) should be used for each instance (e.g., 1 arbitrarily standing for "give five dollars", and 2 for "give five dollars a second time" and so on).

In Section 2, we provide an account of what we mean by compositionality of interventions, with explicit assumptions for identifiability. In Section 3, we describe an algorithm for likelihood-based learning, along with approaches for predictive uncertainty quantification. Further related work is covered in Section 4 before we perform experiments in Section 5, highlighting the shortcomings of black-box alternatives.

## 2 A Structural Approach for Intervention Composition

For simplicity, we will assume scalar behavioral measurements \(X_{n}^{t}\), as the multivariate case readily follows. Consider the following conditional mean model for the regime \((d_{n}^{1:t})\),

\[[X_{n}^{t} x_{n}^{1:t-1},z_{n},(d_{n}^{1:t})]=(_ {n}^{t})^{}(_{n}_{n}^{t})=_{l=1}^{r}_{nl}^{t} _{nl}_{nl}^{t}, \]

where \(\) is the elementwise product, with \(_{n}^{t}\), \(_{n}\) and \(_{n}^{t}\) defined below. We postpone explaining the motivation for this structure to Section 2.1. First, we describe this structure in more detail.

Using \(p()\) to denote generic probability mass/density functions for random variables given by context, assume \(p(x_{n}^{t}(d_{n}^{1:t^{}}))=p(x_{n}^{t}(d _{n}^{1:t}))\) for any \(t^{} t\) (future interventions do not affect the past), and \(p(z_{n}(d_{n}^{1:t}))=p(z_{n})\) for all \(t\). We do not explicitly condition on \(D_{n}^{1:t}\) in most of our notation, adopting a convention where intervention indices \((d_{n}^{1:t^{}})\) are always in agreement with the (implicit) corresponding observed \(D_{n}^{1:t}=d_{n}^{1:t}\). We define \(_{nl}^{t}:=_{l}(x_{n}^{1:t-1},z_{n})\) as evaluations of basis functions \(_{l}()\). For now, we will assume such \(_{l}()\) functions to be known. Each unit \(n\) has individual-level coefficients \(_{n}\). Causal impact, as attributed to \((d_{n}^{1:t})\), is given by

\[_{nl}^{t}:=_{t^{}=1}^{t}_{l}(d_{n}^{t^{}},t^{}, t), \]

where function \(_{l}(d,t^{},t)\) captures a trajectory in time for the effect of \(D_{n}^{t^{}}=d\), for \(t^{}<t\). Compositionality will be described in the sequel in two ways: first, as a way of combining the effects of actions in a type of recursive functional composition (_compositional recursion_); second, by interpreting this function composition at time \(t\) in terms of an operator warping a baseline unit-level feature vector \(_{n}\) with an interventional-level embedding vector \((d_{n}^{t},t,t)\) (_compositional warping_).

Effect families.We consider two variants for \(()\). The first is a _time-bounded_ variant which, for \(d>0\), defines \(_{l}(d,t^{},t):=w_{dl,t-t^{}}\), where \(w_{dl,t-t^{}}\) is a free parameter for \(0 t-t^{}<k_{d}\), otherwise \(w_{dl,t-t^{}}=w_{dl,k_{d}-1}\). The intuition is that the effect of intervention level \(d\) has no shape constraints but it cannot affect the past and it must settle to a constant after a chosen time window hyperparameter \(k_{d}>0\). The default level \(d=0\) has no effect and no free parameters, with \(_{l}(0,t^{},t)=1\). The second variant is motivated by real-world phenomena where causal impacts diminish their influence over time and result in a new equilibrium . We consider a _time-unbounded_ shape with exponential decay, parameterized as

\[_{l}(d,t^{},t):=(w_{1dl})^{t-t^{}} w_{2dl}+w_{3dl}, \]

where \(()\) is the sigmoid function, so that \(0<(w_{1d})<1\). As \(t\) grows, \((w_{1d})^{t-t^{}}\) goes to 0. \(w_{3d}\) is the stationary contribution of an intervention at level \(d\). In particular, for \(d=0\), we define \(w_{10l}=w_{20l}=0\) and \(w_{30l}=1\), while for \(d>0\) we have that \(w_{1dl}\), \(w_{2dl}\) and \(w_{3dl}\) are free parameters to be learned. Let us interpret the previous \(k_{d}\) hyperparameter as the _dimensionality of intervention level \(d\)_. As the model of Eq. (3) is given by vectors \(w_{1d},w_{2d},w_{3d}\), we here define \(k_{d}=3\).

### Representation Power: Compositional Recursion and and Compositional Warping

Eq. (1) is reminiscent of tensor factorization and its uses in causal modeling , where the primary motivation comes from the imputation of missing potential outcomes  taking place on a pre-determined period in the past. From a predictive perspective, it can be motivated from known results in functional analysis (such as Proposition 1 of ) that allows us to represent a function \(f(x)\) by first partitioning its input into \((x_{a},x_{b})\) and controlling the approximation error given by an inner product of vector-valued functions,

\[f(x_{a},x_{b}) f_{a}^{}(x_{a})f_{b}(x_{b}), \]

which we call _the factorization trick_. In practice, we choose the dimensionality of such vectors \(\{f_{a}(),\)\(f_{b}()\}\) by a data-driven approach. Although those results apply typically to smooth functions with continuous inputs (such as the Taylor series approximation, which relies on vectors of monomials with coefficients constructed from derivatives), discrete inputs such as \(D_{n}^{1:T}\), at a fixed dimensionality \(T\), can be separated from the other inputs as

\[f(n,d^{1:T},x^{1:T},z):=f_{d}^{}(d^{1:T})f_{nxz}(n,x^{1:T},z). \]

Here, similarly to classical ANOVA models, \(f_{d}()\) is a one-hot encoding vector for the entire (exponentially sized) space of possible \(d_{n}^{1:T}\) trajectories. That is, \(f_{d}()\) is binary with exactly one non-zero entry, corresponding to which of the possible trajectories \(d_{n}^{1:T}\) took place. The codomain of \(f_{nxz}(,,)\) must be a set of vectors of corresponding (exponential in \(T\)) length.

In what follows, we will start from the premise of further partitioning \(f(n,d^{1:T},x^{1:T},z):=[X_{n}^{T+1} x_{n}^{1:T},z_{n},(d_{n}^{1:T})]\) by applying the factorization trick of Eq. (4) repeatedly, justifying the generality of the right-hand side (RHS) of Eq. (1). We will accomplish this by first introducing more structure into the respective \(f_{d}(d^{1:T})\), based on a recursive composition of functions. We will then show in Proposition 1 how the RHS of Eq. (1) follows. We also provide a complementary theoretical result in Proposition 2 which, by assuming a bounded \(T\), describes the choice of dimensionality in the application of Eq. (4) as controlling a formal approximation error for a general class of functions.

Main results: factorization trick with compositional recursion.As we do not want to restrict ourselves to fixed \(T\) (and \(N\)), not to mention an exponential cost of representation, we will resort to fixed-dimensionality embeddings of sequences and identities. In particular, we design \(f_{d}(d^{1:t})\) to have a finite and tractable output dimensionality \(r_{g}\) for all \(t\). Inspired by sequential hidden representation models such as recurrent neural networks, for each entry \(l 1,2,,r_{g}\) in the output of \(f_{d}()\), we define \(f_{dl}(d^{1:t})\) via the following recursive definition:

\[f_{dl}(d^{1:t})&:=&g_{l}(d^{1:t},t,t),\\ g_{l}(d^{1:t^{}},t^{},t)&:=&h_{l}(g_{l}(d^{1:t^{}-1},t^{ }-1,t),d^{t^{}},t^{},t),\ \ \ \ \ 0<t^{} t,\\ h_{l}(v,d,t^{},t)&:=&h_{l_{1}}(v)^{}h_{l_{2}}(d,t^{},t).  \]

The base case for \(t^{}=0\) is \(g_{l}(d^{1:0},0,t) 1\) for all \(t\), with \(d^{1:0}\) undefined. Moreover, we define \(h_{l}(v,0,t^{},t) v\) for any \((v,t^{},t)\) - that is, intervention level \(D_{n}^{t^{}}=0\) does nothing.

In order to define \(h_{l}(v,d,t^{},t)\) for \(d>0\), we will apply the same trick of splitting the input into two subsets, and defining a vector representation on each. The representational choice \(h_{l}(v,d,t^{},t):=h_{l_{1}}(v)^{}h_{l_{2}}(d,t^{},t)\) requires a choice of dimensionality \(r_{h_{l}}\) for the inner vectors \(h_{l_{1}},h_{l_{2}}\). Recursively applying (6) in this product form can still be done relatively efficiently, but choosing \(r_{h_{l}}=1\) for all \(l\) simplifies matters. Finally, we apply the factorization trick one last time to define \(f_{nxz}(n,x^{1:T},z)\) within Eq. (5) to get to a factorization form analogous to Eq. (1). More formally:

**Proposition 1**: _Let_ **(i)**_\(f(n,d^{1:T},x^{1:T},z):=f_{d}^{}(d^{1:T})f_{nxz}(n,x^{1:T},z)\), where function sequences \(f_{d}(d^{1:T})\) and \(f_{nxz}(n,x^{1:T},z)\) are defined for all \(T^{+}\) and have codomain \(^{r_{g}}\);_ **(ii)**_\(f_{dl}(d^{1:T})\) be given as in Eq. (6) with \(r_{h_{l}}=1\);_ **(iii)** _the \(l\)-th entry of \(f_{nxz}(n,x^{1:T},z)\) be given by \(f_{nxl}(n,x^{1:T},z):=u_{l}(n)^{}v_{l}(x^{1:T},z)\), where both \(u_{l}()\) and \(v_{l}(,)\) have codomain \(^{r_{g^{}}}\);_ **(iv)**_\(v_{l}(x^{1:t},z)\) be defined analogously to \(f_{dl}(d^{1:t})\) as in Eq. (6), carrying out the fixed-size \(z\) as an extra argument. Then there exists some integer \(r\) and three functions \(a,b\) and \(c\) with codomain \(^{r}\) so that \(f(n,d^{1:T},x^{1:T},z)=_{l=1}^{r}a_{l}(x^{1:T},z) b_{l}(n) c_{ l}(d^{1:T},T)\). Moreover \(c_{l}(d^{1:T},T)=_{t=1}^{T}m_{l}(d^{t},t,T)\) for some function \(m_{l}:^{3}\)._Proofs of this and next results are given in Appendix B. The above shows that if we start with an assumption that the ground truth function takes some desired form, then there is some finite \(r\) for which our combination of basis functions can parameterize the ground truth function for arbitrary \(T\), analogous to Eq. (1), where \((a,b,c)\) plays the role of \((,,)\). On the other hand, we show a companion result below: that if we hold \(T\) fixed, there is some fixed value for \(r\), which depends polynomially on \(T\), such that any measurable ground truth function can be approximated by our combination with some appropriate choice of basis functions.

**Proposition 2**: _Given a fixed value of \(T\), suppose we have a measurable function \(f:_{t=2}^{T}^{1:t-1}_{t=1}^{T}^{t} ^{d}\), \(t T\), where \(^{1:t-1}\) and \(\) are compact, \(^{t}\) is finite. Let \(_{t=2}^{T}^{1:t-1}\) and let \(_{t=1}^{T}^{t}\). For \(d=1,,d_{max}\), let \(m_{d}:_{t=1}^{T}^{t}\{1,,T\}\) with \(m_{d}()=t\) if \( t\ s.t.\ _{t=1}=d\) else \(0\). Then, for any \(>0\), there exist \(r=O(T^{d_{max}+1})\) and measurable functions \(_{l}:^{1:t-1}^{d}\) and \(_{ld^{}}:^{t}\), and real numbers \(_{l}\), such that_

\[sup_{_{t=2}^{T}^{1:t-1},_{t =1}^{T}^{*},z}|f(,,z)-_ {l=1}^{r}_{l}(,z)_{l}_{d=1}^{d_{max}}_ {ld^{}}(m_{d^{}}())|. \]

Notes.The theoretical results above are reminiscent of the line of work on matrix factorization (e.g., Appendix A of ). Eq. (1) and Eq. (2) are motivated by the success of approaches for representation learning of sequences, which assume that we can compile all the necessary information from the past using a current finite representation at any time step \(t\). However, Propositions 1 and 2 further imply that, for \(f(n,d^{1:T},x^{1:T},z):=[X_{n}^{T} x_{n}^{1:T-1},z_{n},(d_{n}^{1:T})]\), the representation of functions in a multilinear combination of adaptive factors (Eq. (1)) is motivated by more fundamental results in functional analysis. Our assumption that no value of \(d\) (other than the baseline 0) can be used more than once has mostly an empirical motivation, as this would imply unrealistic assumptions about the same intervention having the same effect when applied multiple times. Ultimately, we assume that the factors \(h_{l_{2}}(d,t^{},t)\) leading to Eq. (2) are time-translation invariant, being a function of \(d\) and \(t-t^{}\) only. While it is possible to generalize beyond translation invariant models, as done in the synthetic controls literature  that inspired causal matrix factorization ideas [7; 3; 4], this would complicate matters further by requiring a fourth factor into the summation term of Eq. (1) encoding absolute time. Models for time-series forecasting with parameter drifts can be tapped into and integrated with our model family, but we leave these out as future work.

Interpretation: compositional warping.At the start of the process, where all units are assumed to be at their "natural" state (assuming \(D_{n}^{1}=0\)), we can interpret \(_{n}^{1}:=_{n}\) as a finite basis representation, with respect to \(_{n}^{1}\), of \([X_{n}^{1} Z_{n},(d_{n}^{1}=0)]=(_{n}^{1}) _{n}^{1}\). Each \(_{nl}^{1}\) can be seen as a latent feature of unit \(n\). Effect vector \(_{n}^{t}\) defines a _warping_ of \(_{n}^{t-1}\) that describes how treatments affect the behaviour of an individual in feature space, with the resulting \(_{n}^{t}:=_{n}^{t-1}_{n}^{t}\). The modifier \(_{n}^{t}\) can be interpreted as reverting, suppressing or promoting particular latent features that are assumed to encode all information necessary to reconstruct the conditional expectation of \(X_{n}^{t}\) from the chosen basis (notice that intervention level 0 implies \(_{n}^{t}=_{n}^{t-1}\) since we define \(_{l}(0,t^{},t)=1\)). This presents a sequential warping view of compositionality of interventions. Our framing also conveniently reduces the problem of identifiability of conditional effects to the problem of identifying baseline vectors \(_{n}\) and warp function embeddings \(_{l}(d,t^{},t)\), as we will see next.

### Identification and Data Assumptions

Assume for now that functions \(\) are known. As commonly done in the matrix factorization literature, assume also that we have access to some moments of the distribution. In particular, for given \(N\) data points and \(T\) time points, we have access to \([X_{n}^{t} x_{n}^{1:t-1},z_{n},(d_{n}^{1:t})]\). We will impose conditions on the realizations of \(X_{n}^{1:T}\) and values chosen for \(d_{n}^{1:n}\), as well as values of \(N\) and \(T\) as a function of \(r\), in order to identify each \(_{n}\) and the parameters of \(_{l}(d,t^{},t)\) for all intervention levels \(d\) of interest. The theoretical results presented, which describe how parameters are identifiable from _population_ expectations and _known function spaces_ determined by a prescribed basis \(\) of _known and finite dimensionality_\(r\), will then provide the foundation for a practical learning algorithm in the sequel.

**Assumption 1**: _For a given individual \(n\), we assume there is an initial period \(T_{0_{n}} r\) with "no interventions" i.e., \(D_{n}^{t}=0\) for all \(1 t T_{0_{n}}\)._

**Assumption 2**: _Let \(A_{n}\) be a \((T_{0_{n}}-1) r\) matrix, each row \(t=1,2,,T_{0_{n}}-1\) is given by \(_{n}(x_{n}^{1:t},z_{n})^{}\) realizations under regime \((d_{n}^{1:t})\). Let \(A_{n}\) be full rank with left pseudo-inverse \(A_{n}^{+}\)._

The first assumption can be interpreted as allowing for a "burn-in" period for unit \(n\) under only the default action. The second assumption ensures enough diversity among realized features \(_{n}\) so that a least-squares projection can be invoked to identify \(_{n}\), as formalized in the following proposition.

**Proposition 3**: _Let \(b_{n}\) be a \((T_{0_{n}}-1) 1\) vector with entries \([X_{n}^{t+1} x_{n}^{1:t},z_{n},(d_{n}^{1:t+1})]\). Under Assumptions 1 and 2, \(_{n}\) is identifiable from \(A_{n}\) and \(b_{n}\)._

The next assumption is the requirement that any action level \(d\) of interest is carried out across a large enough number of units. Moreover, they must be sufficiently separated in time from follow-up non-default action levels so that their parameters can be identified. Assumption 4 is a counterpart to Assumption 2, ensuring linear independence of feature trajectories.

**Assumption 3**: _For a given intervention level \(d\), assume \(_{l}(d,t^{},t) 0\) for all \(l,t,t^{}\) and that there is at least one time index \(t\), and one set \(_{d}\) containing all units \(n\) where \(d_{n}^{t+1}=d\), such that: (i) \(N_{d}:=|_{d}| r\); (ii) \( n_{d},d_{n}^{t+2}==d_{n}^{t+k_{d}-1}=0\), where \(k_{d}\) is the dimensionality of the intervention level \(d\)._

**Assumption 4**: _Let \(n_{1},n_{2},,n_{Nd}\) index the elements of a set of units \(_{d}\). For \(t^{}=1,2,,k_{d}-1\), let \(A_{dt^{}}\) be a \(N_{d} r\) matrix where each row \(i=1,,N_{d}\) is given by \(_{n_{i}}(x_{n_{i}}^{1:t+t^{}-1},z_{n_{i}})^{}\) realized under regime \((d_{n_{i}}^{1:t+t^{}-1})\). We assume that each \(A_{dt^{}}\) is full rank with left pseudo-inverse \(A_{dt^{}}^{+}\)._

This leads to the main result of this section:

**Theorem 1**: _Assume we have a dataset of \(N\) units and \(T\) time points \((d_{n}^{1:T},x_{n}^{1:T},z_{n})\) generated by a model partially specified by Eq. (1). Assume also knowledge of the conditional expectations \([X_{n}^{t} x_{n}^{t-1},z_{n},(d_{n}^{1:t})]\) and basis functions \(_{l}(,)\) for all \(l=1,2,,r\) and all \(1 n N\) and \(1 t T\). Then, under Assumptions 1-4 applied to all individuals and all intervention levels \(d\) that appear in our dataset, we have that all \(_{n}\) and all \(_{l}(d,,)\) are identifiable._

Notice that nothing above requires prior knowledge of all intervention levels which will exist, and could be applied on a rolling basis as new interventions are invented. There is no need for all units to start synchronously at \(t=1\): the framing of the theory assumes so to simplify presentation, with the only requirement being that each unit is given a "burn-in" period of at least \(T_{0}\) steps and that each new intervention level \(d\) is applied to at least \(r\) units which have not been perturbed recently by relatively novel interventions. Ultimately, the gap between a novel intervention level and the next one should be sufficiently large according to the complexity of the model, as indexed by \(r\). This makes explicit that we do not get free identification: the more complex the domain requirements, the more information we need, both in terms of the time waited and the number of observations.

## 3 Algorithm and Statistical Inference

This section introduces a learning algorithm, as well as ways of quantifying uncertainty in prediction. We also allow for the learning of adaptive basis functions \(\). As Eq. (1) does not define a generative model, which will be necessary for multiple-steps-ahead prediction, for the remainder of this section we will assume the likelihood implied by \(X_{n}^{t} x_{n}^{1:t-1},z_{n},(d_{n}^{1:t})(f(x_ {n}^{1:t-1},z_{n},d_{n}^{1:t}),^{2})\). Here, the conditional mean \(f(,,)\) is given by Eq. (1). As \(^{2}\) is not affected by \(D\), it can be easily shown to not require further identification results. In general, if parameters in our likelihood are implied by a finite set of estimating equations, we can parameterize it in the multilinear form analogous to (1) and repeat the analysis of the previous section. In practice, the functionals (such as the conditional expectations of \(X_{t}\)) used in an estimating equation are unknown. Matrix factorization methods can be used directly by first applying a smoothing method to the data to get plug-in estimates of these functionals , but we will adopt instead a likelihood-based approach.

### Algorithm: CSI-VAE

We treat each \(_{n}\) as a random effects vector, giving each entry \(_{nl}\) an independent zero-mean Gaussian prior with variance \(_{}^{2}\). Along with all hyperparameters, we optimize the (marginal) loglikelihood by gradient-based optimization. With a Gaussian likelihood, the posterior and filtering distribution of each \(_{n}\) can be computed in closed form, but in our implementation we used a black-box amortized variational inference framework [27; 30; 34] anyway that can be readily put together without specialized formulas and is easily adaptable to other likelihoods. We use a mean-field Gaussian approximation with posterior mean and variances produced by a gated recurrent unit (GRU) model  composed with a multilayer perceptron (MLP). Therefore, the approximate posterior at \(t\) time steps follows from \(_{q,,n}:=(_{_{B},1}(d_{n}^{1:t},x_{n}^{1:t},z_{ n})),\) and \(_{q,,n}:=(_{_{B},2}(d_{n}^{1:t},x_{n}^{1 :t},z_{n})).\) Prediction for \(X_{n}^{t+1:t+}\) is done by sampling \(M\) trajectories, where for each trajectory we first sample a new \(_{n}\) from the mean-field Gaussian approximation. We set each forward \(_{n}^{t+i}\) to be the corresponding marginal Monte Carlo average. Each basis vector \(_{n}^{t}\) is parameterized via another GRU model such that \(_{n}^{t}:=(_{}(x_{n}^{1:t-1},z_{n})).\) Although the theory in the previous section relies on known basis functions, we could train this GRU up to a threshold time point of \(T_{0}\) and freeze it from that point, each \(_{n}\) being defined as the unit-level coefficient vector under this basis. In practice, we found that doing end-to-end learning provides a modest improvement, and this will be the preferred approach in the experiments. We do find that it is sometimes more stable to condition only up to time \(T_{0}\) for the computation of the variational posterior of \(\). Hence, we adopt this pipeline for any results reported in this paper, unless otherwise specified. We call our method _Compositional Sequential Intervention Variational Autoencoder (CSI-VAE)_.

### Distribution-free Uncertainty Quantification

Conformal prediction (CP) [46; 19] provides prediction intervals with coverage guarantees. The intervals are computed using a calibration set of labeled samples and include the future samples with non-asymptotic lower-bounded probability. We consider Split Conformal Prediction in two setups.

1. **Hold-out predictions.** We have a set of _historical users_, \(n=1,,N\), whose behavior has been observed until time \(t+\). The task is to predict the behaviour at time \(t+\) of a _new user_, \(n=N+1\), who has been observed up to time \(t\), i.e. to predict \(X_{N+1}^{t+}\) given \(X_{N+1}^{1:t}\) and \(D_{N+1}^{1:t}\). If we assume we have used the history of the new user \(X_{n}^{1:t}\), \(n=1,,N+1\), to train the model, calibration and test samples are exchangeable.
2. **Next-intervention predictions.** We have observed the behavior of _all users_, \(n=1,,N+1\), up to time \(t\) and aim to predict the effects of the next intervention, which happens at time \(t+1\) for all users, i.e. \(D_{n}^{t+1} 0\), holding \(D_{n}^{t+2:t+}=0\). The task is to predict \(X_{n}^{t+}\) under \((d_{n}^{1:t+})\) for \(n=1,,N+1\), but in what follows we will drop the explicit \(()\) indexing to keep notation lighter, referring explicitly to past observed \(D^{1:t}\) only (as its sampling distribution matters), and assuming sequential ignorability by assumption or randomization. Calibration and test are _not exchangeable_, because i) the joint distribution after time \(t\), \(P_{T}(X_{n}^{t+},X_{n}^{1:t},D_{n}^{1:t})\) may be different from the one before time \(t\), \(P_{C}(X_{n}^{t^{}+},X_{n}^{1:t^{}},D_{n}^{1:t^{}})\), \(t^{}<t-\) and ii) we only used \(X_{n}^{t^{}},D_{n}^{t^{}}\), \(t^{}=1, t\), for training.

CP algorithms are applied on top of given point-prediction models, where we will use \(\) to denote the cross-sectional sample space of any \(X_{t}\). In our case, the underlying model is \(f\), which predicts the expected user behaviour at time \(t+\) given the user history up to time \(t\), i.e. \(_{n}^{t+}:=f(D_{n}^{1:t},X_{n}^{1:t},Z_{n})[X_{n} ^{t+} D_{n}^{1:t},X_{n}^{1:t},Z_{n},(D^{1:t},d^{t+1 },0^{t+2:t+})]\) for a chosen implicit \(d^{t+1}\) and with \(0^{t+2:t+}\) denoting the default action 0 being taken at \(t+2,,t+\).

**Setup 1.** Calibration and test scores, \(\{S_{n}=|X_{n}^{t+}-f(D_{n}^{1:t},X_{n}^{1:t},Z_{n})|\}_{n=1}^{N}\) and \(S_{N+1}=|X_{N+1}^{t+}-f(D_{N+1}^{1:t},X_{N+1}^{1:t},Z_{n})|\) are exchangeable, i.e. \((S_{1},,S_{N}+1)=(S_{(1)}, ,S_{(N+1)})\) where \(\) is any permutation of \(\{1,,N+1\}\). The Quantile Lemma, e.g. Lemma 1 of , implies the prediction interval

\[C=\{x,|x-_{N+1}^{t+}|_{}\} \]

\[_{}=_{q}\{_{n=1}^{N}(|X_{n}^{t+}- ^{t+}| q) n_{}\}, n_{}=(1+N )(1-)\]

is _valid_ in the sense it obeys

\[(X_{N+1}^{t+} C) 1-, \]

where the probability is over the calibration and test samples.

Setup 2.The prediction intervals defined in (8) may not be valid, i.e. (9) may not hold, because the calibration and test samples, \(S_{n}^{t^{}}=|X_{n}^{t^{}+}-f(D_{n}^{1:t^{}},X_{n}^{1:t^{ }},Z_{n})|\) with \(t^{} t\) and \(t^{}>t\), \(n=1,,N\), are not exchangeable. Theorem 2 provides a bound on the coverage gap, i.e. a measure of violation of (9), under the assumption that the distribution shift is controlled by a perturbation parameter, \(>0\).

**Theorem 2**: _Assume we have \(N\) calibration samples,_

\[S_{n}^{t^{}}=|X_{n}^{t^{}}-f(D_{n}^{1:t_{n}},X_{n}^{1:t_{n}},Z_{n} )|, t^{}=t_{n}+<t, n=1,,N \]

_where \(t_{n}\) is the time user \(n\) experienced the last intervention before \(t\). Assume there exists \(>0\) such that, for all \(n\),_

\[p_{T}(S_{n}^{t+})=(1-)p_{C}(S_{n}^{t+})+  p_{}(S_{n}^{t+}), \]

_where \(p_{T}\) and \(p_{C}\) are the (unknown) densities of the test and calibration distributions, \(p_{}\) is a bounded arbitrary shift density, and \(p_{min}=_{n=1,,N}p_{C}(S_{n}^{t^{}})>0\). Then,_

\[(X_{N+1}^{t+} C) 1- -}. \]

In the proof, we use the likelihood-ratio-weighting approach of  to obtain the empirical test distribution from the calibration samples and bound its quantile from below. The statement follows from standard inequalities on the mean and variance of the \(\)-perturbed distribution. We prefer this approach to conformal prediction adaptive models for time series, e.g.  or , for two reasons: i) adaptive schemes have asymptotic coverage guarantees that can not be used to estimate the uncertainty on a single time step and ii) optimized density estimates are a byproduct of our prediction model.

## 4 Further Related Work

 leverages Bayesian structural time-series models to estimate causal effects, and motivates our exponential decay model in Eq. (3). Unlike , who focus on single interventions, our model explicitly addresses the complexity arising from sequential interventions, taking a more detailed perspective on the dynamic interplay of treatments over time. Several approaches for conformal prediction in causal inference have emerged in recent years (e.g., 44, 28), including matrix completion  and synthetic controls . Our focus has not been on individual nor average treatment effects, but directly on expected potential outcomes, similarly to the work on causal matrix completion [7; 3; 4; 42]. Unlike the matrix completion literature, we focused on prediction problems, out-of-sample for both units and time steps. Moreover, the matrix completion literature is usually framed in terms of _marginal_ expectations \([X_{n}^{t}(d)]\), as opposed to conditional expectations (notice that  considers covariates, but those are included as part of the generative model). Marginal models have some advantages when modeling multiple-step-ahead effects , but they also involve complex computational considerations that we leave for future work. Compositionality based on additivity instead of the factorization trick is discussed by e.g. , but additivity lacks the connection to an explicit principle for universal function approximation. Finally, there is a rich literature on confounding adjustment where exogeneity of \(D_{n}^{t}\) cannot be assumed, see  for a textbook treatment. We can rely on standard approaches of sequential ignorability  to justify our method in the absence of randomization.

## 5 Experiments

We run a number of synthetic and semi-synthetic experiments to evaluate the performance of the CSI-VAE approach. In this section, we summarize our experimental set-up and main results. The code for reproducing all results and figures is available online2. In Appendix C, we provide a detailed description of the datasets and models. In Appendix D, we present further analysis and more results. Finally, in Appendix E, we present an illustration of uncertainty quantification results.

**Datasets and oracular simulators.** The first step to assess intervention predictions is to build a set of proper ground truth test beds, where we can control different levels of combinations of interventions. We build two sets of oracular simulators. (1) The **Fully-synthetic** simulator is constructed primarily based on random models following our parameterization in Section 2. (2) The **Semi-synthetic** simulator is constructed based on a real-world dataset from Spotify3 which aims to predict skip behavior of users based on their past interaction history. See details in Appendix C. For each type of simulator, we generate \(5\) different versions with different random seeds. From simulator (1), we construct a simulated dataset of size \(50,000\), containing \(5\) different interventions happening to the units at any time after an initial burn-in period of \(T_{0}=10\), although only maximum \(3\) of these can be observed for any given unit. We set \(r=5\) as the true dimensionality of the model. For simulator (2), we construct simulated datasets of size \(3,000\), again containing \(5\) different interventions, an initial period \(T_{0}=25\), a maximum of \(3\) different interventions per unit, and \(r=10\). The task is to predict outcomes for interventions not applied yet within any given unit (i.e., at least from the \(2\) options left). In simulator (2), parameters \(\) and \(\) are learned from real-world data. Interventions are artificial, but inspired by the process of showing different proportions of track types to an user in a Spotify-like environment. For both setups, we use a data ratio of \(0.7,0.1,0.2\) for training, validation and test, respectively. We report the final results in Table 1 with another constructed holdout set (\(5,000\) points for the fully-synthetic case, and \(1,000\) for the semi-synthetic one).

Compared models.We implemented three variations: (1) **CSI-VAE-1** follows exactly our setup in Section 2; (2) **CSI-VAE-2** can be considered as an ablation study, which relaxes the product form of Eq. (1) and replace it with a black-box MLP applied directly to \((_{n}^{t},_{n},_{n}^{t})\) (and hence may not guarantee identifiability); (3) **CSI-VAE-3** is another ablation study, where the equation for \(\) (Eq. (2)) is replaced by a black-box function taking the sequence of actions \(D\) as a standard time-series. We compare our model against: (1) **GRU-0**, a black-box gated recurrent unit (GRU, ) composed with a MLP, using only the past history of \(X_{n}^{1:t}\) and \(Z_{n}\); (2) **GRU-1**, another GRU composed with a MLP that takes into account also the latest intervention \(D_{n}^{t}\); and (3) **GRU-2**, which uses not only \(D_{n}^{t}\) but also the entire past history \(D_{n}^{1:t}\) just like CSI-VAE. In general, GRU-2 can be considered as a very strong and generic black-box baseline model. In addition, we conduct experiments comparing other popular black-box baseline models: (4) **LSTM**, ; and (5) **Transformer**, . For those, we use the same input setup as in the case of the GRU-2 model.

Results.Each experiment was repeated 5 times, using Adam  at a learning rate of 0.01, with 50 epochs in the fully-synthetic case and 100 for the semi-synthetic, which was enough for convergence. We selected the best iteration point based on a small holdout set. The main results are presented in Tables 1 and 2, which show the superiority of our model against strong baselines. We also observed

    &  &  \\  Model & T+1 & T+2 & T+3 & T+4 & T+5 & T+1 & T+2 & T+3 & T+4 & T+5 \\  CSI-VAE-1 & \(36.53\) & \(41.46\) & \(41.73\) & \(41.12\) & \(41.32\) & \(68.23\) & \(82.94\) & \(83.53\) & \(81.97\) & \(79.63\) \\ CSI-VAE-2 & \(97.80\) & \(118.25\) & \(117.79\) & \(127.25\) & \(135.03\) & \(253.85\) & \(312.53\) & \(305.08\) & \(303.68\) & \(302.83\) \\ CSI-VAE-3 & \(138.78\) & \(164.02\) & \(141.71\) & \(132.59\) & \(125.55\) & \(757.94\) & \(937.07\) & \(800.55\) & \(704.66\) & \(634.72\) \\  GRU-0 & \(229.72\) & \(269.66\) & \(220.95\) & \(208.30\) & \(188.43\) & \(215.4that the identifiability results and compositional interactions of intervention effects are both critical, as evidenced by the drop in performance for CSI-VAE 2 and 3 in Table 1.

In Appendix D, we provide the following further experiments: (1) different choices of \(r\) (summary: using \(r\) less than the true value gracefully underfits, while there is evidence of some overfitting for choices of \(r\) which overshoot the true value -- mitigated by regularization); (2) different sizes of the training data (summary: even with more data provided, our model consistently outperforms the black-box models by a significant margin; we show that a generic black-box cannot solve this problem by simply feeding in more data); and (3) a demonstration of conformal prediction that allow us to better calibrate the predictive coverage compared to vanilla model-based prediction.

## 6 Conclusion

We introduced an approach for predictions of sequences under hypothetically controlled actions, with a careful accounting of when extrapolation to unseen sequences of controls is warranted.

**Findings.** Embeddings are important given sparse categorical sequential data . However, large combinatorial interventional problems benefit from models that carefully lay down conditions for the identification of such embeddings. Naive sequential models, however flexible, cannot fully do the heavy lifting of generalizing in the absence of structure. Information has to come from somewhere.

**Limitations.** Unlike the traditional synthetic control literature , we assume a model for time effects based on autoregression and truncated or parametric time/intervention interactions. While it is possible to empirically evaluate the predictive abilities of the model using a validation sample, high-stakes applications (such as major interventions to counteract the effect of a pandemic) should take into consideration that uncontrolled distribution shifts may take place, and careful modeling of such shifts should be added to any analytical pipeline to avoid damaging societal implications.

**Future work.** Besides allowing for an explicit parameterization of drifts, accounting for unmeasured confounding that may take place among past actions and states is necessary to increase the applicability of the method. Moreover, when each action level \(d\) is itself a combination of cross-sectional actions, causal energy-based models such as  can be combined with the compositional factorization idea to also generalize to previously unseen cross-sectional combinations of actions.

Figure 2: **Top**: 5-run evaluation of test mean squared error on the fully-synthetic (left) and semi-synthetic cases (case). CSI-3 was removed on the right due to very high errors. **Bottom**: how errors change as training sizes are increased, CSI-1 vs. GRU-2 (left: fully-synthetic, right: semi-synthetic).