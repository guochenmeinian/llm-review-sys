# Follow Hamiltonian Leader: An Efficient Energy-Guided Sampling Method

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Our research underscores the value of leveraging zeroth-order information for addressing sampling challenges, particularly when first-order data is unreliable or unavailable. In light of this, we have developed a novel parallel sampling method that incorporates a leader-guiding mechanism. This mechanism forges connections between multiple sampling instances via a selected leader, enhancing both the efficiency and effectiveness of the entire sampling process. Our experimental results demonstrate that our method markedly expedites the exploration of the target distribution and produces superior quality outcomes compared to traditional sampling techniques. Furthermore, our method also shows greater resilience against the detrimental impacts of corrupted gradients as intended.

## 1 Introduction

Score-based generative models [35; 26; 36; 20] introduce a novel approach to generative modeling that revolves around the estimation and sampling of the Stein score [26; 36]. The score represents the gradient of the log-density function \(_{x}(x)\) evaluated at the input data point \(x\). This type of approach usually relies on effectively training a deep neural network to accurately estimate the score. The estimated score is then utilized to navigate the sampling process, ultimately resulting in the production of high-quality data samples that closely match the areas of high density in the original distribution.

In our research, we investigate the sampling of a probability distribution given by \((x) e^{-U(x)}\), where \(U(x)\) is the energy function. In the context of energy-based score-matching generative models, the objective often involves sampling the modes in areas of high probability density. An approach as suggested in [36; 20], is to smooth the original distribution by convolving \((x)\) with an isotropic Gaussian distribution of variance \(^{2}\), yielding \(_{}(x)=(x^{})(x;x^{},^{2}I)\,dx^ {}\). By gradually decreasing the variance \(\), \(_{}(x)\) recovers the original distribution \((x)\).

Typically, the sampling of score-based approaches are integrated with numerical SDE solvers , for example, the Euler-Maruyama solver, as well as Monte Carlo Markov Chain (MCMC) techniques like Langevin Dynamics . Furthermore, there is a notable similarity between score-based sampling algorithms and first-order optimization algorithms. Efforts have been made to merge these two methodologies, particularly from a perspective of sampling [42; 10; 28; 9; 44]. All these methods primarily concentrates on first-order information \(_{x}U(x)\) to improve performance, while typically treating the zeroth-order information \(U(x)\) merely as a basis for rejecting samples [18; 32; 29].

We argue that incorporating zeroth-order information can significantly enhance the algorithm's overall effectiveness, particularly in instances where the first-order information is compromised. To address this, we draw inspiration from parallel tempering , a simulation method commonly used to identify the lowest energy state in systems of interacting particles. The fundamental principle ofparallel tempering involves operating multiple sampling replicas simultaneously, each at a different temperature level. These temperatures typically range from low, where the system is prone to being trapped in local minima, to high, which facilitates the system's ability to surmount energy barriers and more thoroughly explore the energy landscape.

Drawing inspiration from this concept, we extend the Hamiltonian Monte Carlo (HMC) framework  and introduce a novel algorithm that concurrently runs multiple replicas, sampling at both high and low Hamiltonian energy levels. Moreover, this methodology combines both zeroth and first order information from various chains, hence enhancing the effectiveness of sampling approaches. The experimental findings demonstrate the efficacy of our approach in scenarios where relying solely on first-order knowledge is insufficient. These findings illustrate the capacity of incorporating zeroth-order information to greatly enhance the efficiency and accuracy of sampling operations in energy-based score-matching algorithms.

## 2 Background

### Hamiltonian Monte Carlo

The primary purpose of MCMC is to construct a Markov chain that matches its equilibrium distribution to the target distribution. One of the most popular MCMC methods is Langevin Monte Carlo [17; 32], which proposes samples in a Metropolis-Hastings  framework for more efficient state space exploration. Another advanced method is HMC [29; 11; 2], which incorporates an auxiliary variable \(p\) and employs Hamiltonian dynamics to facilitate the sampling process. The Hamiltonian function is structured as a composite of potential energy \(U(x)\) and kinetic energy \(K(p)\), defined as follows:

\[H(x,p)=U(x)+K(p), \]

where \(x\) represents the position of a particle and \(p\) denotes its momentum. Kinetic energy \(K(p)\) is commonly formulated as \(K(p)=p^{T}M^{-1}p\), where \(M\) corresponds to the mass matrix. For simplicity, we assume in this paper that the mass matrix \(M\) is equal to the identity matrix \(I\). The joint distribution of position and momentum conforms to the canonical distribution:

\[(x,p)=e^{-H(x,p)}/Z, \]

where \(Z= e^{-H(x,p)}\ dxdp\). Samples from \((x)\) can then be obtained by marginalizing \(p\) from \((x,p)\), which further requires \(_{p}(x,p)\ dp=\). In the HMC algorithm, proposals are generated by simulating Hamiltonian dynamics and then subjected to a Metropolis criterion to determine their acceptance or rejection. A commonly employed numerical method for solving these equations is the _Leapfrog_ integrator .

Recent progress in HMC techniques has focused on increasing their adaptability and applicability in a variety of contexts. Such developments include the NUTS sampler , which features an automatic mechanism for adjusting the number of simulation steps. The Riemann manifold HMC  leverages Riemannian geometry to modify the mass matrix \(M\), making use of curvature information to improve sampling efficiency. Additionally, Stochastic Gradient Hamiltonian Monte Carlo [11; 27] investigates a stochastic gradient approach within the HMC framework. Our contribution is distinct from these methods and can be easily integrated with them.

### Energy-based score-matching model

Probabilistic models often require normalization, which can become infeasible when dealing with high-dimensional data [25; 13]. Since the exact probabilities of less probable alternatives become less crucial as long as they remain relatively lower, rather than solely predicting the most probable outcome, models can be structured to interpret relationships between variables via an energy function. Within the context of generative models, these energy-based models (EBMs) are devised to assign higher energy values to regions of lower probability and lower energy values to regions of higher probability.

Score matching [22; 36] is a method used in statistical modeling and machine learning to estimate a probability distribution or a probability density function from observed data. It is particularly useful when direct estimation of the probability distribution is challenging, especially in high-dimensional spaces. In score matching, the goal is to find an approximation to the probability density function (PDF) of a dataset by estimating the score function, also known as the gradient of the log-density.

The score function represents the derivative of the log PDF with respect to the data. By matching the estimated score function to the observed data, one can indirectly estimate the underlying probability distribution.

A relationship between EBMs and score matching can be established by training EBMs through denoising score matching . The training objective is described below:

\[_{(x)(e;0,T)}-_{x} U_{}x+_{2}^{2}\,. \]

\(U_{}\) is typically represented as a neural network, with \(\) denoting its parameters. Minimizing this objective ensures that \(_{x}U_{}(x)=-_{x}_{}(x)\) and thus \(e^{-U_{}(x)}\) shall be proportional to \(_{}(x)\).

## 3 Motivation

In our work, we assume to have access to both the gradient information \(_{x}U(x)\) as well as the energy information \(U(x)\). In certain scenarios, gradients may yield information that is either of limited or potentially detrimental. Our research examines situations where gradients are compromised, highlighting the importance of zeroth-order information, often associated with energy-based sampling.

We concentrate on showcasing the strengths of our method in three types of challenging but common scenarios, summarized as _instability_, _metastability_ and _pseudo-stability_. Instability refers to a state in which a system lacks equilibrium or steadiness, often leading to unpredictable or erratic behavior. Metastability describes a condition where a system appears stable over a short period but is not in its most stable state, and it can transition to a more stable state under certain conditions. Pseudo-stability, on the other hand, denotes a situation where a system seems stable but is actually in an incorrect, suboptimal, or misleadingly stable state.

**Instability.** In high-dimensional spaces, sampling algorithms may struggle to converge in the presence of a complex probability distribution. This instability can arise in situations where the local Hessian matrix is ill-conditioned or spectrum of the local Hessian matrix is exceptionally large. Such conditions often lead to inaccuracies or instabilities in numerical calculations, potentially causing the convergence process to fail. The samples generated could substantially diverge from the true mode, resulting in subpar sample quality. However, employing an anchor point can enhance the stability of convergence, as demonstrated in Figure 1.

**Metastability.** Particles are prone to getting stuck in local minima when the gradients are not informative. For example, on the saddle point or a pleaute loss landscape. As a result, simulations frequently end up in a state of intermediate energy, which is different from the system's lowest energy state. This scenario is illustrated in Figure 2.

**Pseudo-Stability.** Certain situations may present a divergence between the gradient information and the ground truth. This divergence can hinder algorithms from accurately converging to the appropriate modes. In these instances, it becomes essential to incorporate energy information to rectify inaccuracies that arise from solely depending on gradients. An example of misleading gradients could be observed in Figure 3.

## 4 Algorithm

Many sampling methods typically rely on independent Markov chains, which can lead to the issues mentioned in Section 3. Taking inspiration from , our approach involves the utilization of multiple replicas. This approach

Figure 1: A good _anchor point_ could help improve convergence even if the gradient is _unexpectedly disturbed_ from _original gradient_ to the _disturbed gradient_, getting closer to the optimal point.

Figure 3: There is a potential for particles to unintentionally follow the gradient flow towards these regions of high energy. A more comprehensive description could be found at Section 5.1.3.

Figure 2: To enhance exploratory capabilities, itâ€™s important to encourage particle to explore the landscape.

enables us to implicitly encourage greater exploration among multiple particles while simultaneously preserving the optimal outcomes for exploitation purposes. We will elaborate on how our algorithm can be employed to tackle these challenges.

Firstly, we introduce a modified version of the leapfrog method, called the _Elastic Leapfrog_ (eLeapfrog). In this approach, additional elastic forces are applied between each particle and a _leader_, incorporating an extra elastic energy term into the traditional Hamiltonian function. This modification aims to prevent particles from straying significantly from each other, thereby promoting local exploitation. We then divide the particles into groups and designate the particle with the lowest energy as the leader. Moreover, when combined with the eLeapfrog method, this approach encourages other particles to explore around the leader, efficiently addressing the problem of **instability**.

Due to the properties of HMC, introducing such an extra elastic energy term when pulling the particles towards the leader implicitly incorporates this energy into the momentum, thereby increasing the search ability of each particle. As a result, non-leading particles gain more energy for exploration, while the leading particle is more likely to concentrate on local exploitation. This approach helps mitigate the issue of **metastability**.

Finally, we integrate these techniques to present our complete _Follow Hamiltonian Leader_ (FHL) algorithm. The FHL algorithm capitalizes on both first-order and zeroth-order information while significantly improving the efficiency of space sampling compared to traditional sequential sampling methods. This enhanced approach fosters convergence towards the lowest energy states and increases the likelihood of escaping states with **pseudo stability**.

### Elastic Leapfrog

To improve the efficiency of sampling, we integrate an elastic force component into the conventional leapfrog technique. This enhancement aims to dynamically guide particles towards a leading particle, facilitating their movement and improve their exploration ability. The method could be treated like temporarily storing potential energy within an elastic spring, which is then converted into kinetic energy. By adding extra elastic force, we could define the energy of elastic HMC as:

\[H_{e}(x,p;)=U_{e}(x;)+K(p)=) ]}_{U_{e}(x,)}+K(p), \]

where \(E(x;)\) is the extra elastic energy imposed by Elastic Leapfrog and is defined as \(E(x;)= x-_{2}^{2}\). Our approach enables particles to efficiently navigate the sample space, guided by the leader. This local exploration strategy, though similar to concepts in [46; 7; 8; 40], is uniquely tailored for application in the realm of sampling.

### Leader Pulling

Next, we introduce our _leader pulling_ method. Initially, we represent the \(i^{th}\) particle inside a group as \(x^{i}\) and select a leader based on a their energies \(U(x^{i})\). The motivation is that we encourage each particle \(x^{i}\) to be guided towards a chosen leader. The leader is chosen as the one of minimum energy and thus its index is \(l=_{i}U(x^{i})\). The objective function for a group of \(n\) particles is:

\[U_{e}(x^{1},,x^{n};x^{l})=_{i=1}^{n}U(x^{i})+}{2} \|x^{i}-x^{l}\|_{2}^{2}, \]

where \(^{i}=(-U(x^{i}))/_{j}(-U(x^{j}))\) and \(^{i}=(^{l}-^{i})/(^{l}+^{i})\). The specifics of the _Elastic Leapfrog_ algorithm combined with leader pulling technique are detailed in Algorithm 1.

### Follow Hamiltonian Leader

Incorporating zeroth-order information (i.e., function values rather than derivatives) serves two key purposes. Firstly, it provides a search direction that accelerates convergence and helps mitigate issues arising from corrupted first-order information (i.e., gradient inaccuracies), thereby speeding up the optimization process. Second, it helps ensure that we are sampling from the correct underlying distribution by properly accepting or rejecting the proposal.

To ensure that the sampling method maintains detailed balance--a requirement for most sampling algorithms--we evaluate the joint distribution of a group of particles. This evaluation determines whether to accept or reject a proposed move for the whole group, thereby preserving the integrity of the sampling process. This adaptation results in the creation of our algorithm FHL, extensively elucidated in Algorithm 2.

```
Input: A collection of positions \(\{x^{i}\}_{i=1}^{n}^{n d}\), learning rate \(>0\), pulling strength \( 0\), number of steps \(L\). for\(t=1,2,,T\)do  # Run sampling in parallel for\(i=1,,n\)do  Randomly sample the momentum \(p_{t-1}^{i}(0,I)\) \(x_{}^{i},p_{}^{i}\)eLeapfrog (\(x_{t-1}^{i},p_{t-1}^{i},,,L\)) endfor  Sample a random variable \(u(0,1)\) if\(u<_{i=1}^{n}(H(x_{}^{i},p_{}^{i})-H(x_{t-1}^{i},p _{t-1}^{i}))\)then for\(i=1,,n\)do\(x_{t}^{i} x_{}^{i},\ p_{t}^{i} p_{}^{i}\)endfor else for\(i=1,,n\)do\(x_{t}^{i} x_{t-1}^{i},\ p_{t}^{i} p_{t-1}^{i}\)endfor endfor Output:\(X_{T}=\{x_{T}^{i}\}_{i=1}^{n}^{n d}\)
```

**Algorithm 2** Follow Hamiltonian Leader

## 5 Experiment

In this section, we showcase the efficacy of incorporating zeroth-order information, specifically energy information, into our proposed method to improve the sampling process. We focus on demonstrating the advantages of our approach in addressing the benefits of our approach in handling three distinct adversarial gradient scenarios, as outlined in Section 3. To evaluate our method on the performance of the concerned questions, we conduct a comparative analysis against the following baseline algorithms:

* **LMC (Langevin Monte Carlo)**: An MCMC method as described in  that uses Langevin dynamics to sample from probability distributions. It is also known as the Metropolis-adjusted Langevin algorithm.
* **HMC (Hamiltonian Monte Carlo)**: An MCMC algorithm that employs Hamiltonian dynamics for more efficient traversal of the state space, leading to better exploration and sampling from complex distributions [29; 11; 2].
* **U-LMC (Unadjusted Langevin Dynamics)**: A variation of LMC without the Metropolis correction, referred to [32; 1; 42].

* [leftmargin=*]
* **U-HMC (Unadjusted Hamiltonian Monte Carlo)**: A form of HMC that excludes the Metropolis correction step, as in .

### Motivating Examples

We report on results addressing the challenges identified as _instability_, _metastability_, and _pseudo-stability_. Our findings lead us to conclude that the FTH method consistently outperforms other approaches in all scenarios examined. Detailed discussions and further analyses of these findings will be presented in the following subsections.

In our experiment, we simultaneously execute sampling with \(N\) particles, each completing a total of \(T\) sampling steps. For the FTH method, these particles are divided into \(N/n\) groups, with each group containing \(n\) particles. Throughout all experiments, we set \(n\) to \(4\). For hyperparameter search, we select step sizes \(=\{0.002,0.0002,0.005,0.0005\}\) for all methods and number of leapfrog steps \(L=\{4,8,16\}\) for HMC-type methods.

#### 5.1.1 Instability

In our sampling process, we focus on efficiently directing particles to high probability density regions, thereby avoiding unproductive exploration in regions with low probability. When sampling from a single image, our goal becomes attaining the global optima, aligning this objective with those found in optimization tasks.

For our experiment, we chose an image resembling the _GitHub_ logo ([https://github.com/logos](https://github.com/logos)), converted it into a vector format, and use this as the mean of a multivariate Gaussian distribution. The covariance matrix for this distribution, represented by \(\), is diagonal. The variance for each dimension of the distribution is randomly determined by a uniform distribution within the range of \((0.25,1.25)\). We carry out two similar but different types of experiments:

In the first experiment, we focus on sampling from the original distribution. This distribution is described mathematically as \(e^{-U(x)}(,)\), with \(U(x)\) being the energy function that characterizes the system.

For the energy-based score-matching model, we employ a ResNet  architecture with \(6\) layers of a hidden dimension of \(256\). The results of the sampling process are detailed in Figure 4, where the main objective is to assess the particles' capacity for effective convergence to the mode of the distribution. In the first scenario, \(U(x)\) represents a convex function, whereas in the second scenario, \(U_{}(x)\) is presumed to be non-convex. The findings demonstrate that our approach, FHL, surpasses other baseline methods in both situations.

Figure 4: Sample from a Gaussian distribution \((,)\) where \(^{d}\) corresponds to the clean image. For each method, we plot the lowest-energy particle (in terms of \(U(x)\) among all particles in \(X_{T}\)). The upper-left image represents a direct sample from the distribution \((,)\); The lower-left image is generated by performing HMC sampling for \(T\) steps on the function \(U_{}(x)\), with an initial point set to \(x_{0}=\).

#### 5.1.2 Metastability

Our research explores the concept of metastability, which arises in specific scenarios. Metastability refers to a state of intermediate energy in a dynamic system, differing from its lowest energy state. We examine an extreme scenario where gradients are entirely absent, and sampling methods only get access to the energy information about the distribution.

In Figure 5, it's evident that in this particular situation, we enforce the gradient to be _near zero_, resulting in all sampling methods, except FHL and LMC, behaving almost like random sampling. Nevertheless, owing to the leader pulling strategy, FHL retains its ability to locate the mode much faster.

#### 5.1.3 Pseudo-stability

This section highlights the phenomenon showcased in Figure 3. Here, particles can become ensnared by gradient flows and be coerced into pseudo-stable regions. Despite the eventual recovery of the correct distribution by the sampling method, the convergence process can be exceptionally sluggish.

To elaborate, we examine a scenario where the samplers solely depend on gradients from \( Q\), while the energy function \(P\) remains deliberately undisclosed. The distributions \(P\) and \(Q\) are:

* \(Q[(_{1},I)+(_{ 2},I)+(_{3},I)+(_{4},I)]\)
* \(P[(_{1},I)+(_{ 2},I)]\)

where \(_{1}=[-2,0]\), \(_{2}=\), \(_{3}=\) and \(_{4}=[0,-2]\).

From Figure 6 we can see that FTH does not only capture the modes more quickly compared to the other methods but also successfully get out of the trap of the pseudo-stable regions.

Our study addresses the challenges of instability, metastability, and pseudo-stability, demonstrating that the FTH method consistently outperforms other approaches across various scenarios. Through illustrative experiments, we show that FTH rapidly captures modes and effectively escapes pseudo-stable regions, even when gradients are entirely absent. This superior performance is attributed to FTH's unique leader pulling strategy, which directs particles efficiently to high-probability density regions, thereby avoiding unproductive exploration in low-probability areas.

In the following section, we will illustrate the advantages of FTH in more general applications, particularly for energy-based (score-matching) models.

Figure 5: Plot of \(N=256\) particles of \(X_{T}\) on \(d=2\) starting from random initialization \((0,4 I)\). The target distribution is \((,I)\). Energy State corresponds to the target density \(\). The baseline methods U-LMC,LMC,U-HMC,HMC and our proposed method FHL generate \(X_{T}\) after \(T=1000\) steps. There are no gradient flows and the samplers are only able to sample by the energy information.

Figure 6: Plot of \(N=256\) particles of \(X_{T}\) for a \(2\)-mode Gaussian mixture model on \(d=2\) starting from random initialization \((0,4 I)\). Energy State corresponds to the target density \(\). The baseline methods U-LMC,LMC,U-HMC,HMC and our proposed method FHL generate \(X_{T}\) after \(T=200\) steps.

### Energy-Based Generative Model

Energy-based models (EBMs) offer significant advantages for sampling because they naturally provide energy information that can be utilized to guide the sampling process. In an EBM, the energy function assigns lower energy values to more probable configurations, enabling the sampler to more effectively navigate the probability landscape and generate high-quality samples. This makes EBMs a powerful tool in scenarios where precise sampling is essential.

We investigate a scenario where energy functions guide the sampling process. We use the generative model outlined in  and adopt a conditional generation method that leverages classifier-derived gradients for sampling. The classifier's output is considered as the energy for guided sampling. The common classification tasks involving \(C\) classes are often solved by using a neural network \(f_{}:^{d}^{C}\), which maps each input data point \(x^{d}\) to \(C\)-categorical outputs. The output are then used to define a categorical distribution of class \(y\) through a _softmax_ function:

\[p_{}(y x)=(x)[y])}{_{y^{}}(f_{ }(x)[y^{}])},\]

where \(f_{}(x)[y]\) represents the \(y\)-th component of \(f_{}(x)\), corresponding to the logit for class \(y\). Once the classifier is trained, \(p^{}_{}(y x)=(f_{}(x)[y])\) could be used to sample for a specific class \(y\).

We compare FTH with the standard HMC method using a limited number of sampling steps, consistently accepting new proposals based on the potential energy during sampling. It is evident that FTH produces higher-quality images than HMC. Additionally, our experiments reveal that FTH tends to generate sharper images compared to the other method. This can be attributed to the assumption that the classifier focuses on the object's features rather than the entire image. As a result, when the prediction probability is high, the features that increase confidence become more prominent, while unrelated background elements are filtered out.

### Energy-Based Score-Matching Models

As indicated in , when two diffusion models are combined into a product model \(q^{}(x) q^{1}(x)q^{2}(x)\), problems can arise if the model reversing the diffusion uses a score estimate derived by simply adding the score estimates of the two independent models. We use energy-based score-matching models to illustrate this issue. It is important to note that such inconsistencies typically involve the composition of two or more diffusion models.

Figure 7: Sample from joint energy model by different classes (**Left:** HMC; **Right:** FTH).

#### 5.3.1 Synthetic Dataset

We first show an example of composing two distributions \(p_{1}(x)\) and \(p_{2}(x)\), as illustrated in the left column of Figure 8. The results show that FTH demonstrates a strong ability to converge to the correct composition, with less particles fall out of the high-density region compared to others.

#### 5.3.2 CLEVR Dataset

We use CLEVR dataset from  for our generation and sampling tasks. The energy model is adopted from , and we employ different samplers for generation. The dataset includes three classes: _cube_, _sphere_, and _cylinder_. We explore scenarios where we first sample from only _one_ category and then from _two_ categories.

In the first experiment, there is no composition of models. As depicted in Figure 9, it is evident that FTH effectively generates the desired image without any extraneous shapes, whereas both MALA and HMC generate additional shapes.

In the second experiment, we combine two independent diffusion models, each trained separately to generate _sphere_ and _cylinder_. As shown in Figure 10, it is clear that FTH excels at producing high-quality images with almost no overlapping between objects, accurately rendering the intended shapes in a pristine manner. In contrast, the other methods generate the undesired shape _cube_. Additionally, FTH exhibits less noise, indicating greater stability for sampling.

## 6 Conclusion

In this study, we first recognize the significance of incorporating zeroth-order information into the sampling process, highlighting the common limitations faced by conventional sampling methods. These limitations include unstable sampling outcomes frequently associated with energy-based score-matching models, the potential metastability arising from the multi-modal nature of the energy function, and errors in gradient computation stemming from the complex structure of the compositional distribution. Subsequently, we present an innovative approach that leverages parallel HMC sampling to address the issues. Building upon HMC, we incorporate energy modulation techniques to enhance the sampling process. Through this approach, our method is able to systematically reduce the potential energy, leading to substantial advantages in practical implementations of sampling.

Figure 8: Compose sampling with DDPM.

Figure 10: Generation of _sphere_ and _cylinder_. The zoomed images could be found at Figure 20.

Figure 9: Generation of _cube_. The zoomed images could be found at Figure 19.