# MG-ViT: A Multi-Granularity Method for Compact and Efficient Vision Transformers

Yu Zhang\({}^{1}\)  Yepeng Liu\({}^{2}\)  Duoqian Miao\({}^{1}\)1  Qi Zhang\({}^{1}\)  Yiwei Shi\({}^{3}\)  Liang Hu\({}^{1}\)

\({}^{1}\)Tongji University \({}^{2}\)University of Florida \({}^{3}\)University of Bristol

###### Abstract

Vision Transformer (ViT) faces obstacles in wide application due to its huge computational cost. Almost all existing studies on compressing ViT adopt the manner of splitting an image with a single granularity, with very few exploration of splitting an image with multi-granularity. As we know, important information often randomly concentrate in few regions of an image, necessitating multi-granularity attention allocation to an image. Enlightened by this, we introduce the multi-granularity strategy to compress ViT, which is simple but effective. We propose a two-stage multi-granularity framework, MG-ViT, to balance ViT's performance and computational cost. In single-granularity inference stage, an input image is split into a small number of patches for simple inference. If necessary, multi-granularity inference stage will be instigated, where the important patches are further subsplit into multi-finer-grained patches for subsequent inference. Moreover, prior studies on compression only for classification, while we extend the multi-granularity strategy to hierarchical ViT for downstream tasks such as detection and segmentation. Extensive experiments Prove the effectiveness of the multi-granularity strategy. For instance, on ImageNet, without any loss of performance, MG-ViT reduces 47% FLOPs of LV-ViT-S and 56% FLOPs of DeiT-S.

## 1 Introduction

Transformer  has gained tremendous achievements in computer vision. Despite the excellent performance of Convolutional Neural Networks (CNN) in computer vision tasks [2; 3; 4; 5], due to ViT's superior ability to capture global information and long-range interactions, ViT  outperforms CNN in various tasks [7; 8; 9; 10; 11]. However, the impressive performance of ViT comes at the cost of its huge computational overhead. Therefore, more researches focus on ViT compression for greater efficiency. Since the computational cost of ViT increases quadratically with the number of tokens, minimizing the number of tokens is crucial in compressing ViT.

Notable investigations have adopted various methods to compress ViT. DynamicViT  reduces token number by pruning redundant tokens, EViT  merges redundant tokens into one token. DVT  utilizes the particular and dynamic patch splitting manner (e.g., 4\(\)4, 7\(\)7, etc.) for each image, based on its complexity, rather than following the official manner of 14\(\)14. Although DVT innovatively considers the differences in complexity between images, it still uses single granularity to split one image. As we all know, images often contain a lot of redundancy, with important semantic information randomly concentrated in a few regions. Therefore, it is imperative to consider the complexity and semantic density diversities across various regions of the image: different regions of an image should be assigned attention with multiple granularities. We initiate our exploration by observing the foundational task, classification, and we have 3 intriguing observations:

**Observation 1**: Most images can be correctly recognized by splitting them into a small number of patches, as has been analogously observed in research . Training a DeiT-S  with the \(4 4\) patch splitting manner can achieve 63.4% accuracy at a computational cost of 0.45G FLOPs. Although splitting an image to \(7 7\) patches and \(14 14\) patches can enhance the accuracy by 9.8% and 16.4%, the computation cost will also increase by 2.4\(\) and 10.2\(\). How to substantially improve the accuracy with a low growth rate of FLOPs is a subject worth contemplating.

**Observation 2**: The classification accuracy is mainly affected by the several critical tokens, and subsplitting patches into finer patches is more beneficial to classification. We split each image into \(14 14\) patches and rank tokens from high to low based on their class attention scores. The 196 tokens (patches) are equally divided into head, middle, and tail groups, and respectively input into DeiT-S to measure the accuracy of each group (Fig.1(a)). Then, subsplitting the patches in the head group expands the quantity to \(4\) and \(9\), their accuracy is measured (Fig.1(b)). It is illustrated that head tokens ensure the base of classification accuracy, and finer tokens lead to higher accuracy.

**Observation 3**: All information matters, and proper handling of tokens with low important information content (IIC) contributes to avoiding partial loss of accuracy. We treat the bottom 50% tokens as lower IIC tokens based on class attention score rank (CASR), and create 4 input groups for all tokens. The results in Fig.1(c) suggest that retaining lower IIC tokens can maintain accuracy. This is because lower IIC tokens contain complementary information to higher IIC tokens, which helps bridge the accuracy gap with the baseline. The dissimilarities among lower IIC tokens should be considered, necessitating a hierarchical processing. Performance improvement is from complementary information, certain lower IIC tokens make the higher contribution. If they are merged with other lower IIC tokens, the gain of performance improvement may be diluted.

Thus far, we can identify two sound reasons for utilizing the multi-granularity strategy to compress ViT. Firstly, as aforementioned, due to the distinctiveness of important information distribution in images, it is imperative to assign multi-granular attention to an image. Secondly, guided by our observations, we can consider multi-granularity as an intermediate state between full fine-grained and full coarse-grained. Full fine-grained stage represents stronger performance, while full coarse-grained stage represents less computation. Therefore, multi-granularity can naturally be used to balance performance and computational cost.

We propose MG-ViT: a multi-granularity framework for compressing ViT, which automatically splits an image into multi-granularity patches, as shown in Figure 2. MG-ViT consists of two parts: Single-Granularity Inference Stage (SGIS) and Multi-Granularity Inference Stage (MGIS), related to Observation 1. In SGIS, a small number of tokens are used for classification inference. Should a prediction confident enough ensue, the inference terminates immediately; otherwise, MGIS will be

   Manner & \(14 14\) & \(7 7\) & \(4 4\) \\  Accuracy & 79.8\% & 73.2\% & 63.4\% \\ FLOPs & 4.60G & 1.10G & 0.45G \\   

Table 1: Accuracy and FLOPs of DeiT-S on ImageNet in different splitting manner.

Figure 1: The classification accuracy of the tokens from different groups in each layer of DeiT-S. (c) 4 input groups: 1#: Only higher IIC tokens (top50%). 2#: Merging lower IIC tokens into one token and together with higher IIC tokens. 3#: According to CASR, merging every 50% of lower IIC tokens into one token (2 in total) and together with higher IIC tokens, 4#: According to CASR, merging every 25% of lower IIC tokens into one token (4 in total) and together with higher IIC tokens.

Figure 2: Example for MG-ViT.

triggered. In MGIS, We put forward three innovative methods. The first is multi-granularity patch subsplitting, related to Observation 2. All patches are divided into head, middle and tail groups based on CASR in SGIS, head and middle patches are subsplit, resulting in tokens with multiple information granularity that are input into ViT. The second is the three-way decision slimming, which can streamline ViT softly. Simply put, based on CASR, tokens are divided into three groups: positive, boundary, and negative. Boundary and negative tokens are respectively merged by different rules to reduce their numbers. The third is the token match-merge scheme for boundary tokens, related to Observation 3. The second and third methods are packaged as Plug-and-Play Slimming Module (PPSM) against the huge increase in computational cost caused by patch subsplitting. After PPSM, all tokens are fed into the next layer of ViT to continue inference.

Due to that ViT only outputs a single-scale feature representation and lacks the capability to handle multi-scale variations, it possesses significant deficiencies in downstream tasks. In order to adapt multi-granularity strategy to various downstream tasks, we extend the MG-ViT framework to hierarchical ViT. Unlike ViT, hierarchical ViT aggregates tokens within rectangular areas. However, patch subsplitting results in patches (tokens) with multiple scales interleaved in the image, making it challenging to seamlessly enclose them within regular rectangular areas. To address this issue, we introduce a proxy token of the same scale for each head or middle patch to represent itself. Additionally, each proxy token engages in attention calculations with its corresponding fine tokens or medium tokens to represent the subsplitting of the head or middle patch it stands for. Following the aggregation methodology of PVT , Hierarchical MG-ViT can perform downstream tasks.

MG-ViT is a dynamic and versatile framework that can be applied to most ViT models. We select LV-ViT  and DeiT  to assess the performance of MG-ViT on ImageNet . The experiments demonstrate that MG-ViT can balance performance and computation cost greatly, thereby significantly improving the efficiency of ViT. Moreover, while ensuring performance, MG-ViT reduces 47% FLOPs of LV-ViT and 56% FLOPs of DeiT. We also conduct simple experiments in object detection and semantic segmentation on the MS-COCO  and ADE20K  datasets, respectively. The results show that Hierarchical MG-ViT effectively reduces computational overhead without significant performance loss, demonstrating the feasibility of extending multi-granularity strategy to the Hierarchical ViT structure.

## 2 Related Work

**Vision Transformer.** ViT  achieves a great breakthrough in the image classification task by redesigning the Transformer structure, completely igniting researchers' passion for exploring the ViT further. Later on, ViT is modified to hierarchical structure for various downstream tasks [21; 8; 22; 23].

**ViT and Hierarchical ViT.** ViT is a series of ViT models that adhere to the vanilla ViT design principles,such as DeiT  and LV-ViT. They only output a single-scale feature representation and lack the capability to handle multi-scale variations, making them typically suitable for classification tasks. Hierarchical ViT is a series of ViT models that incorporate a hierarchical structure to aggregate tokens layer by layer, enabling them to better handle multi-scale information and well-suited for various downstream tasks. Swin-Transformer  and PVT [16; 25] are representative architectures of hierarchical ViT.

**ViT compression.** ViT and hierarchical ViT can both enhance efficiency. Hierarchical ViT primarily achieves efficiency by improving interaction rules among tokens, whereas ViT mainly relies on compression. ViT compression primarily aims to optimize ViT structures in a flexible and automated manner, developing a dynamic and efficient ViT where each image undergoes an individual computational process based on its unique features, all while minimizing computational costs without sacrificing performance. There are many classic ViT compression works, such as DynamicViT , PS-ViT , Evo-ViT , and so on [13; 14; 28; 29; 30; 31; 32; 33].

## 3 Multi-Granularity Vision Transformer

### Overview

Figure 3 illustrates the overall framework of MG-ViT. For each image, SGIS must be executed. In SGIS, the image is split into a small number of patches. These 2D patches are embedded into 1D

tokens and fed into ViT for straightforward inference. The obtained class prediction will be evaluated against predetermined criteria (threshold). If the class prediction is acceptable, the inference can be terminated immediately, and the class prediction can be output as the final classification result. If the class prediction is unacceptable, MGIS will be executed.

In MGIS, according to the IIC of each patch (referring to CASR), all patches are proportionally divided into three groups: head, middle and tail. Head and middle patches are further subsplit. As head patches with high IIC are the most crucial for classification, they require subsplitting with fine granularity, and eventually are subsplit into fine patches with fine-grained information. Middle patches with middle IIC are more crucial for classification but less than head patches. Whence, they require subsplitting with medium granularity, being subsplit into medium patches with medium-grained information. Tail patches, maintain their coarse granularity and serve as coarse patches. All patches undergo patch embedding and feature reuse to generate multi-granularity tokens which are input into ViT for inference, prediction, and output. Considering that patch subsplitting leads to a huge increase in computational cost, Plug-and-Play Slimming Module (PPSM) is introduced in certain layers of ViT to reduce computational cost. The three-way decision slimming lies here. According to CASR, we divide all tokens into three groups: positive, boundary and negative, aiming to realize soft slimming of ViT. Positive tokens remain unchanged. Among boundary tokens, similar tokens are matched and merged based on our proposed token match-marge scheme (more details in Section 3.3.2), resulting in fewer new tokens. Negative tokens are merged into one token by weights. In this way, the number of tokens is reduced, accomplishing ViT soft slimming.

### Single-Granularity Inference Stage (SGIS)

In SGIS, the standard ViT is employed. Formally, for an input image \(\), it is first split into patches \(P=[p^{1},p^{2},...,p^{N}]\) where \(N\) is the number of patches. In patch embedding, patches are mapped into \(C\)-dimension token embeddings via linear projection. Additionally, a learnable token embedding \(x^{0}\), referred to as a class token, is appended to the sequence of token embeddings to represent image \(\) for class prediction. After position embedding \(E_{pos}\), the input token sequence for ViT in SGIS is:

\[X=[x^{0},x^{1},...,x^{N}]+E_{pos} \]

where \(x^{i}^{C}\), present a token embedding of the \(i\)-th patch if \(i>0\), and \(E_{pos}^{(N+1) C}\).

A ViT consists of \(L\) layers, each layer comprises a self-attention (SA) module and a feed-forward network (FFN). In SA of the \(l\)-th layer, the self-attention _Attention_(\(Q_{l},K_{l},V_{l}\)) is computed as follows:

\[_{l}=(K_{l}^{T}}{})=[a_{l}^{0},a_ {l}^{1},...,a_{l}^{N}], 28.452756pt(Q_{l},K_{l},V_{l} )=_{l}V_{l}, \]

where \(Q_{l},K_{l},V_{l}^{(N+1) C}\), are query, key and value matrices of \(l\)-th layer respectively and obtained through linear projection for \(X_{l-1}\). \(_{l}\) is attention map of \(l\)-th layer, and the first row of attention map \(a_{l}^{0}\) represent class attention in \(l\)-th layer.

Ulteriorly, the processes of SA and FFN in the \(l\)-th layer are as follows:

\[X_{l-1}^{{}^{}}=(X_{l-1})+X_{l-1}, 28.452756ptX_{l}=(X_{l-1}^{{}^{}})+X_{l-1}^{{}^{}}. \]

Figure 3: The overall framework of MG-ViT.

After consecutive computation of \(L\) layers, class token \(x_{L}^{0}\) from the \(L\)-th layer is input into the classifier \(\) to obtain class prediction distribution \(D^{S}\):

\[D^{S}=(x_{L}^{0})=[d_{1}^{S},d_{2}^{S},...,d_{M}^{S}], \]

where \(S\) indicates SGIS, \(M\) denotes the class number, up to this point, the class prediction of image \(\) is the largest entry of \(D^{S}\), i.e., \(argmax_{j}d_{j}^{S}\).

**Threshold for judgment.** If the value of \(max_{j}d_{j}^{S}\) for input image \(\) is large enough, it indicates that the class prediction in SGIS is acceptable, and the classification result can be generated. Therefore, the inference can be terminated immediately, saving computational cost. In order to use \(max_{j}d_{j}^{S}\) to determine whether to terminate the inference, we introduce a threshold \(\): if \(max_{j}d_{j}^{S}>\), the inference is terminated immediately, and the class prediction is output as the classification result. If \(max_{j}d_{j}^{S}<\), The image is transitioned to MGIS for consecutive inference.

### Multi-Granularity Inference Stage (MGIS)

#### 3.3.1 Generation of Multi-Granularity Tokens

To bridge the ViTs of two stages, we perform multi-granularity patch subsplitting and feature reuse to generate tokens with multi-grained information as the input for the ViT in MGIS.

**Multi-granularity patch subsplitting.** Since \(max_{j}d_{j}^{S}\) of image \(\) is less than \(\), further inference is required. As mentioned above, in MGIS, image \(\) needs to be subsplit with multiple different granularities, and features of patches in SGIS need to be reused. These operations require to be instructed by IIC of patches (tokens) in SGIS, as patches with different IIC will be divided into different groups. Thus, the key now lies in how to identify the IIC of patches.

According to Equation 2, class token \(y^{0}\) can be represented by class attention \(a^{0}\) as:

\[y^{0}=(K^{T}}{}})=a^{0} V, \]

as we all known, class token \(y^{0}\) represents the entire image \(\) as input to produce the class prediction in classifier \(\). As \(V=[v^{0},v^{1},...,v^{N}]\), where \(v^{i}\) is the value of the \(i\)-th token if \(i>0\). The class token \(y^{0}\) is obtained by integrating the value of each token using \(a^{0}\) as the corresponding weights. In other words, \(a^{0}\) determines the amount of information from each token that enters the class token \(y^{0}\) for classification. Therefore, we can use class attention \(a^{0}\) to measure the contribution of each token to the class prediction, thence, we identify IIC according to CASR. However, if we only use CASR originating from the class attention of a certain layer to divide patches, patches of each group will be more random and unfixed, lacking overall consistency. Therefore, the flow of information across layers must also be considered. Thus, we come up with the global class attention instead of only using class attention of a certain layer to identify IIC of patches. The global class attention \(_{l}\) in the \(l\)-th block is as following:

\[_{l}=_{l-1}+(1-) a_{l} \]

where \(=0.98\). In Fig.1(a), we can observe that the classification accuracy of all groups exhibits intense fluctuation in shallow layers. It is evident that class attention is unstable in shallow layers. Therefore, the global class attention calculation starts from the 3-rd layer. We use CASR rooted from global class attention in the last layer \(_{L}\) to identify IIC of patches.

According to \(_{L}\), all patches are divided into three groups: head, middle, and tail. The numbers of head, tail and middle patches, denoted by \(N_{h}\), \(N_{t}\), and \(N_{m}\) are given by:

\[N_{h}= N r_{h}+0.5, 14.226378ptN_{t}= N r_ {t}+0.5, 14.226378ptN_{m}=N-N_{h}-N_{t}, \]

where \(r_{h}\) and \(r_{t}\) represent the number rate of head and tail patches respectively.

Head and middle patches need to be subsplit. Since head patches have high IIC, each is subsplit into \(3 3\) fine patches. Middle patches with middle IIC, each is subsplit into \(2 2\) medium patches. Each tail patch is considered as a coarse patch and remains unchanged. After patch subsplitting, the input token sequence is denoted as follows:

\[=[^{0},^{1},...,^{K}]+_{pos}, \]where \(K\) represents the total number of patches after patch subsplitting.

**Feature reuse.** Patch subsplitting disrupts the integrity of head and middle patches, resulting in a lack of correlation among fine or medium patches which are severally subsplit from the same head or middle patch. To address this issue, we incorporate Feature Reuse module from DVT  to inject the original information of head or middle patches into new fine or medium patches. It is advantageous to enhance feature representation of each patch and strengthen the interconnectivity among them.

Figure 4 demonstrates the Feature Reuse module. Tokens (except class token) output by the ViT of SGIS are taken as input and divided based on their IIC. As head and middle patches need to be subsplit in MGIS, we individually upsample head and middle tokens, so that the number of new tokens obtained by upsampling is the same as the number of new patches obtained by subsplitting. Different from the module in DVT , considering that tail tokens remain unchanged in MGIS, we utilize zero padding to handle them. Finally, all tokens are flattened and sorted according to their position in image \(\). The token sequence \(X^{FR}\) output by Feature Reuse is obtained as follows:

\[X^{FR}=(x_{L}^{1},...,x_{L}^{N}). \]

Specially, \(X^{FR}^{N C^{}}\). Due to concatenation expanding the dimension of multi-granularity tokens to 2\(\), resulting in a 4\(\) increase in computational cost (detailed analysis in Appendix), we set a MLP in the module to realize dimension reduction: \(MLP(^{C}^{C^{}})\). The value of \(C^{}\) is small, thereby increasing the dimension of multi-granularity tokens from \(C\) to \(C+C^{}\), but still much smaller than \(2C\), which helps save computational cost.

The generated multi-granularity token sequence \(^{(N+1)(C^{}+C)}\), which is input to ViT in MGIS for inference, slimming and output, is denoted as:

\[=Concat(,X^{FR})=[^{0},^{1},...,^{N}] \]

#### 3.3.2 Plug-and-Play Slimming Module (PPSM)

Most existing ViT slimming methods, such as DynamicViT, PS-ViT, adopt token pruning, undermining the information integrity of the image and is not beneficial for classification. Therefore, we select token merging, which diminishes the number of tokens while preserving information.

**Three-way decision slimming.** Most existing ViT slimming methods belong to hard slimming, which divides tokens into non-redundant and redundant groups based on a certain criterion and reduces the number of redundant tokens to streamline ViT. Nevertheless, tokens in the middle part of CASH are arduous to distinguish as non-redundant or redundant during the inference. Mistakenly identifying non-redundant tokens as redundant and performing slimming will lead to a degradation of ViT's performance. Considering that three-way decision model establishes a buffer zone, i.e., boundary, between positive and negative, it can aid in more appropriately handling tokens situated in the middle position of CASH. Therefore, we employ three-way decision mechanism to realize soft slimming for ViT.

Three-way decision  is a decision mechanism in rough set [35; 36] that partitions a set into positive, negative, and boundary domains, with elements in each domain subject to positive, negative, and boundary rules, respectively. By setting the proportion of elements in positive and negative domains to \(r_{pos}\) and \(r_{neg}\), all tokens inputted into PPSM are divided into positive, negative and boundary domains. Positive tokens adhere to the positive rule: maintain unchanged. Boundary tokens adhere to boundary rule, which refers to the token match-merge scheme we proposed. Negative tokens adhere to the negative rule: all are merged into one token by weights.

**Token match-merge scheme.** As discussed in Observation 3, dissimilarities among lower IIC tokens should be considered, necessitating a hierarchical processing. Thus, we employ the token

Figure 4: Feature Reuse module.

Figure 5: The process of token match-merge.

match-merge scheme among boundary tokens to guide the match-merge process of similar boundary tokens, aiming to reduce the number of tokens while maintaining accuracy to the best possible extent. We measure the similarity between two tokens by computing the cosine similarity of their value vectors. \(v^{a},v^{b}^{C}\), present the value vectors of tokens \(a\) and \(b\), and the cosine similarity \(cos()\) is expressed as follows:

\[cos()=^{C+C^{}}(v_{i}^{a} v_{i}^{b})}{^{C+C^{}}(v_{i}^{a})^{2}}^{C+C^{}} (v_{i}^{b})^{2}}} \]

The token match-merge scheme is demonstrated in Figure 5. Step1. Divide tokens at odd positions in CASR into Group A and those at even positions into Group B. Step2. Find the most similar token in set B for each token in set A by calculating cosine similarity. Step3. Put similar tokens together to complete the match. Step4. Merge the similar tokens by weights to reduce the number of tokens.

### Training Mehtod

During the training of MG-ViT, setting \(=1\) makes MGIS be executed for every input image. Like knowledge distillation , our goal is to make the outputs of SGIS more similar to MGIS. Thus ViT in SGIS can have a stronger ability in classification. The training loss about ground-truth label \(gt\) is:

\[loss=CE(D^{M},gt)+KL(D^{S},D^{M}), \]

where \(CE(,)\) and \(KL(,)\) represent cross entropy loss and Kullback-Leibler divergence.

## 4 Hierarchical Multi-Granularity Vision Transformer

### Key Issue of Extension

Almost all classic ViT compression works, such as Dynamic ViT , PS-ViT , EViT , only focus on classification. Why not extend their methods to hierachical ViT to execute downstream tasks like detection and segmentation? We analyze two reasons. The first reason is structural limitation. For instance, plain ViT only provides a single-scale feature representation, lacks the ability to handle multi-scale variation, and lacks image-related priors. While there are a few works that still employ plain ViT for downstream tasks, such as ViTDet , ViT-Adapter , SegViT [40; 41], they achieve this by integrating well-designed modules, which could be considered as individual research contributions. The second reason is method challenges. Most classic ViT compressions, as mentioned above, heavily rely on pruning or merging, which can be challenging to adapt to downstream tasks. Although we also employ pruning and merging methods, they serve as auxiliary means to reduce computational costs. The core of this paper - multi-granularity strategy - can be applied in hierarchical ViT for downstream tasks.

The key to extending multi-granularity strategy to hierarchical ViT lies in addressing the non-uniform issue of multi-grained patch scales. Subsplitting head and middle patches into \(3 3\) fine patches and \(2 2\) medium patches results in patches with multiple scales interweaving in an image, making it difficult to seamlessly enclose patches in a conventional window when using Swin Transformer. Therefore, in this paper, we propose proxy tokens to unify scales.

### Introducing Proxy Tokens for Unifying Scales

Similar to MG-ViT, Hierarchical MG-ViT also employs a two-stage framework. In SGIS, 2D image \(^{H W}\) is split into patches \(P^{ s^{2}}\), where \((H,W)\) donates the resolution of image \(\)

Figure 6: The overall framework of Hierarchical MG-ViT.

and \(s\) presents the patch size. The token sequence generated by \(P\) embedding is:

\[T_{ori}=[t^{1}_{ori},t^{2}_{ori},...,t^{}}}_{ori}], \]

where \(T_{ori}^{} C_{1}}\), \(ori\) is a simplified representation of "origin". IIC of \(P\) is identified in SGIS. In MGIS, we assume that \(P^{i}^{s s}\) is a patch that requires subsplitting, which will be subsplit into \(\) fine patches:

\[P^{i}=[p^{i,1},p^{i,2},...,p^{i,^{2}}], \]

where \(\) is the manner of subsplitting (\(3 3\) or \(2 2\)), \(p^{i,j}\) present the \(j\)-th fine or medium patch subsplit from the \(i\)-th head or middle patch if \(i>0\), and \(j>0\).

Then the finer token sequence \(T^{i}_{ori}^{^{2} C_{1}}\) originated from the embedding of these finer patches is denoted as:

\[T^{i}_{ori}=[t^{i,1}_{ori},t^{i,2}_{ori},...,t^{i,^{2}}_{ori}]. \]

We introduce a proxy token \(t^{i}_{pro}^{C_{1}}\) for this group of finer tokens to compose the new sequence \(T^{i}=[T^{i}_{ori},t^{i}_{pro}]\). The computing procedure of a Transformer layer for this group can be summarized as follows:

\[T^{i^{}}=SA(T^{i})+T^{i}, 14.226378ptT^{i^{}}=MLP(T^{i^{ }})+T^{i^{}}. \]

To generalization, We provide an optional proxy token set \(T_{pro}\) and its mask vector \(m\) for each image, where \(T_{pro}^{} C_{1}}\) and \(m^{}}\). Thus, the unified scale token sequence \(T^{{}^{}}\) before feature reuse can be denoted as:

\[T^{{}^{}}=(-m) T_{ori}+m T^{{}^{}}_{pro}. \]

After feature reuse, the token sequence is input into the pyramid-structured hierarchical ViT, through PVT stages 2, 3, and 4, feature maps reshape to \( C_{2}\), \( C_{3}\) and \( C_{4}\). In this way, various downstream tasks can be performed.

### Architectural Details

We develop two variants of Hierarchical MG-ViT based on PVT-Small: Hierarchical MG-ViT-A and Hierarchical MG-ViT-R. Hierarchical MG-ViT-A adds a Transformer layer with proxy tokens between stage 1 and stage 2 of PVT-Small. Hierarchical MG-ViT-R maintains the same capacity as PVT-Small but replaces one of the original Transformer layers in stage 1 with a Transformer layer introducing proxy tokens. Please refer to the appendix for architectural details.

### Discussions

**Performance upgrade.** Since our proposed method is plug-and-play and does not significantly alter the structure of the hierarchical ViT, methods aimed at improving the performance of hierarchical ViT, such as using relative position biases and overlapping patch embedding, are all effective. However, we haven't optimize Hierarchical MG-ViT for the best performance, as our goal was to explore the potential of extending the multi-granularity strategy from compressing plain ViT to hierarchical ViT for various downstream tasks. In the future, we will delve deeper into performance enhancements for Hierarchical MG-ViT.

**Plain ViT \(vs.\) hierarchical ViT.** Which ViT structure is superior? Plain ViT inherently has limitations when it comes to handling dense tasks. In order to utilize a general ViT for a variety of tasks, many new ViTs are designed based on hierarchical structures. However, we do not consider hierarchical ViT to be superior; both plain ViT and hierarchical ViT have their strengths and weaknesses. As for detection tasks, a multitude of ViTs built upon the hierarchical structure continue to remain the most competitively poised model. However, models like ViTDet , which are based on plain ViT, also demonstrate that hierarchical ViTs such as Swin-T and PVT are not the only efficient ways to accomplish visual tasks. As for segmentation tasks, what surprised us is that SegViTv2 , built upon the Plain ViT, has achieved state-of-the-art results. As for classification tasks, a variety of plain ViT models, with MG-ViT as a representative, exhibit a big performance advantage over hierarchical ViT. Moreover, multi-granularity strategy boost performance more effectively in plain structures than in hierarchical structures. This is because hierarchical ViT involves token merging, which significantly diminishes the advantages of multi-granularity in feature representation. Regarding the question of which ViT structure is superior, we believe that it necessitates deliberation in the context of varying tasks and distinct constraints.

## 5 Experiments

### Backbones, Datasets and Evaluation Metrics.

We built MG-ViT based on DeiT-S and LV-ViT-S and evaluated its performance on the benchmark ImageNet . To quantitatively compare performance, we report the Top-1 accuracy (Acc.), the number of floating-point operations (FLOPs), and throughput (TP). Moreover, we developed Hierarchical MG-ViT based on PVT-Small and evaluated its performance in object detection and semantic segmentation on the benchmark datasets MS-COCO2017  and ADE20K . We reported metrics such as box average precision (\(AP^{b}\)), mean intersection over union (mIoU) and the number of parameters (#Params). All metrics are measured on a single NVIDIA RTX 3090 GPU.

### Main Results

**Comparison to backbones.** Table 2 presents the comparison results between MG-ViT and backbones with different values of threshold \(\). It can be observed that Without any performance degradation, the computational cost of MG-ViT is significantly reduced. Moreover, when all images execute MGIS, the performance of ViT is improved, which can be attributed to subsplitting patches with multiple different granularities.

**Comparison to baselines.** In Figure 7, we compare MG-ViT with 3 baselines: DynamicViT, EViT, and DVT. These models are chosen as representatives of 3 type methods: token pruning, token merging, and dynamic design of token format. With the same setting, MG-ViT outperforms baselines.

**Comparison to other ViT compressing methods.** In order to demonstrate the effectiveness of our dynamic framework, MG-ViT, in compressing ViT, we present a comparison of MG-ViT with various ViT compressing methods in Table 3. We visualize their accuracy, FLOPs, and throughput in Appendix. The results show that our method for compressing ViT based on the multi-granularity strategy, MG-ViT, is highly competitive when using DeiT-S and LV-ViT-S as backbones.

**Comparison to other efficient ViTs.** In Figure 8, we compare MG-ViT and various efficient ViTs [44; 45; 46; 47; 48; 49; 50; 51; 52; 53; 25; 54; 55; 56; 57; 58; 59; 60; 61; 62; 63; 64]. It can be observed that MG-ViT is competitive even among different backbones and other ViT variants.

   Model & \(\) & Acc.(\%) & FLOPs(G) & TP(img./s) \\  DeiT-S & - & 79.8 & 4.6 & 1341 \\  MG-ViT & 0.49 & 79.8(+0.0) & 2.0(-56\%) & 2404(+1.79\(\)) \\ MG-ViT & 0.73 & 80.8(+1.0) & 2.4(-48\%) & 2054(+1.53\(\)) \\ MG-ViT & 1 & 81.0(+1.2) & 3.9(-15\%) & 1591(+1.11 \(\)) \\  LV-ViT-S & - & 83.3 & 6.6 & 989 \\  MG-ViT & 0.60 & 83.3(+0.0) & 3.5(-47\%) & 1749(+1.77\(\)) \\ MG-ViT & 0.73 & 83.7(+0.4) & 3.8(-42\%) & 1683(+1.70\(\)) \\ MG-ViT & 1 & 83.8(+0.5) & 5.6(-15\%) & 1233(+1.25\(\)) \\   

Table 2: Comparison between MG-ViT and backbones

    & LV-ViT-S & & & DeiT-S & \\  Model & FLOPs(G) & Acc.(\%) & TP(img/s) & Model & FLOPs(G) & Acc.(\%) & TP(img/s) \\  Baseline & 6.6 & 83.3 & 989 & Baseline & 4.6 & 79.8 & 1341 \\ PS-ViT & 4.7 & 82.4 & - & IA-REPI & 3.3 & 79.1 & 1597 \\ eTPS & **3.8** & 82.5 & 1665 & DV & **2.4** & 79.3 & 1485 \\ EViT & 4.7 & 83.0 & 1447 & DynamicViT & 2.9 & 79.3 & 1774 \\ DynamicViT & 4.6 & 83.0 & 1302 & Evo-ViT & 2.9 & 79.4 & 1863 \\ SPViT & 4.3 & 83.1 & 1518 & ATS & 2.9 & 79.7 & 1531 \\ SiT & 4.0 & 83.4 & 1280 & STViT & 3.2 & 80.6 & 1928 \\ CF-ViT & 4.0 & 83.5 & **1711** & CF-ViT & 2.6 & 80.7 & **2096** \\
**MG-ViT** & **3.8** & **83.7** & 1683 & **MG-ViT** & **2.4** & **80.8** & 2054 \\   

Table 3: Comparison between MG-ViT and other ViT compressing methods.

**Object detection and semantic segmentation.** We adopt the same implementation details as PVT-Small and conduct preliminary experiments on Hierarchical MG-ViT's performance in object detection and semantic segmentation tasks to represent its capability for executing downstream tasks. As shown in Table 4 and Table 5, extending the multi-granularity strategy to the hierarchical structure is beneficial for enhancing ViT's performance and serves as a nice attempt to slim hierarchical ViT.

## 6 Conclusion

MG-ViT, the two-stage dynamic framework based on the strategy we proposed, achieves a well-balanced trade-off between performance and computational cost. Within this novel framework, we contribute four new methods. Firstly, we subsplit patches with multiple different granularities, resulting in generating multi-granularity tokens with various levels of information, which enhances the capacity of ViT in feature representation, leading to performance improvement. Secondly, we introduce a three-way decision mechanism to achieve soft slimming of ViT. Thirdly, we propose the token match-merge scheme to guide the match-merge of boundary tokens, reducing their quantity. The second and third methods are reflected in our proposed PPSM. Fourthly, we extend multi-granularity strategy to hierarchical ViT for various downstream tasks, demonstrating that our method can also be applied to hierarchical structures for compressing, and we will explore this further in the future.