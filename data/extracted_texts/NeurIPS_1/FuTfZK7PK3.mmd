# The Power of Extrapolation in Federated Learning

Hanmin Li

GenAI Center of Excellence

KAUST, Saudi Arabia

hanmin.li@kaust.edu.sa &Kirill Acharya

GenAI Center of Excellence

KAUST, Saudi Arabia

acharya.kk@phystech.edu &Peter Richtarik

GenAI Center of Excellence

KAUST, Saudi Arabia

peter.richtarik@kaust.edu.sa

Kirill was a student at MIPT during his internship at KAUST.

###### Abstract

We propose and study several server-extrapolation strategies for enhancing the theoretical and empirical convergence properties of the popular federated learning optimizer FedProx. While it has long been known that some form of extrapolation can help in the practice of FL, only a handful of works provide any theoretical guarantees. The phenomenon seems elusive, and our current theoretical understanding remains severely incomplete. In our work, we focus on smooth convex or strongly convex problems in the interpolation regime. In particular, we propose Extrapolated FedProx (FedExProx), and study three extrapolation strategies: a constant strategy (depending on various smoothness parameters and the number of participating devices), and two smoothness-adaptive strategies; one based on the notion of gradient diversity (FedExProx-GraDS), and the other one based on the stochastic Polyak stepsize (FedExProx-StoPS). Our theory is corroborated with carefully constructed numerical experiments.

## 1 Introduction

Federated learning (FL) is a distributed training approach for machine learning models, where multiple clients collaborate under the guidance of a central server to optimize a loss function . This method allows clients to contribute to model training while keeping their data private, as it avoids the need for direct data sharing. Often, federated optimization is formulated as the minimization of a finite-sum objective function,

\[_{x^{d}}\{f(x):=_{i=1}^{n}f_{i}(x)\}, \]

where each \(f_{i}:^{d}\) is the empirical risk of model \(x\) associated with the \(i\)-th client. The federated averaging method (FedAvg) is among the most favored strategies for addressing federated learning problems, as proposed by McMahan et al. , Mangasarian and Solodov . In FedAvg, the server initiates an iteration by selecting a subset of clients for participation in a given round. Each chosen client then proceeds with local training, employing gradient-based techniques like gradient descent (GD) or stochastic gradient descent (SGD) with random reshuffling, as discussed by Bubeck et al. , Gower et al. , Moulines and Bach , Sadiev et al. .

Li et al. (2020) proposed replacing the local training of each client via SGD in FedAvg with the computation of a proximal term, resulting in the FedProx algorithm.

\[x_{k+1}=_{i=1}^{n}_{ f_{i}}(x_{k}), \]

where \(>0\) is the step size, and the proximal operator is defined as

\[_{ f_{i}}(x):=_{z^{d}}\{ f_{i}(z)+\|z-x\|^{2}\}.\]

Contrary to gradient-based methods like GD and SGD, algorithms based on proximal operation, such as proximal point method (PPM) (Rockafellar, 1976; Parikh et al., 2014) and stochastic proximal point methods (SPPM) (Asi and Duchi, 2019; Bertsekas, 2011; Khaled and Jin, 2022; Patrascu and Necoara, 2018; Richtarik and Takac, 2020) benefit from stability against inaccuracies in learning rate specification (Ryu and Boyd, 2014). Indeed, for GD and SGD, a step size that is excessively large can result in divergence of the algorithm, whereas a step size that is too small can significantly deteriorate the convergence rate of the algorithm. PPM was formally introduced and popularized by the seminal paper of Rockafellar (1976) to solve the variational inequality problems. In practice, the stochastic variant SPPM is more frequently used.

It is known that the proximal operator applied to a proper, closed and convex function can be viewed as the projection to some level set of the same function depending on the value of \(\). In particular, if we let each \(f_{i}\) be the indicator function of a nonempty closed convex set \(_{i}\), then \(_{ f_{i}}()\) becomes the projection \(_{_{i}}()\) onto the set \(_{i}\). In this case, FedProx in (2) becomes the parallel projection method for convex feasibility problem (Censor et al., 2001, 2012; Combettes, 1997a; Necoara et al., 2019), if we additionally assume

\[:=_{i=1}^{n}_{i}.\]

A well known fact about the parallel projection method is that its empirical efficiency can often be improved by extrapolation (Combettes, 1997a; Necoara et al., 2019). This involves moving further along the line that connects the last iterate \(x_{k}\) and the average projection point, resulting in the iteration

\[x_{k+1}=x_{k}+_{k}(_{i=1}^{n}_{_{i}} (x_{k})-x_{k}), \]

where \(_{k} 1\) defines extrapolation level. Despite the various heuristic rules proposed over the years for setting \(_{k}\)(Bauschke et al., 2006; Censor et al., 2001; Combettes, 1997b), which have demonstrated satisfactory practical performance, it was only recently that the theoretical foundation explaining the success of extrapolation techniques for solving convex feasibility problems was unveiled by Necoara et al. (2019), where the authors considered randomized version of (3) named Randomized Projection Method (RPM). The practical success of extrapolation has spurred numerous extensions of existing algorithms. Notably, Jhunjhunwala et al. (2023) combined FedAvg with extrapolation, resulting in FedExP, leveraging insights from an effective heuristic rule (Combettes, 1997b) for setting \(_{k}\) as follows:

\[_{k}=^{n}\|x_{k}-_{_{i}}(x_{k}) \|^{2}}{\|_{i=1}^{n}(x_{k}-_{_{i}}(x_{k}) )\|^{2}}. \]

However, the authors did not consider the case of a constant extrapolation parameter, nor did they disclose the relationship between the extrapolation parameter and the stepsize of SGD. The extrapolation parameter can be viewed as a server side stepsize in the context of federated learning, its effectiveness was discussed by Malinovsky et al. (2023).

In the field of fixed point methods, extrapolation is also known as over-relaxation (Rechardson, 1911). It is a technique used to effectively accelerate the convergence of fixed point methods, including gradient algorithms and proximal splitting algorithms (Iutzeler and Hendrickx, 2019; Condat et al., 2023).

### Contributions

Our paper contributes in the following ways; for the notations used please refer to Appendix A.

* Based on the insights gained from the convex feasibility problem, we extend FedProx to its extrapolated counterpart FedExProx for both convex and strongly1 convex interpolation problems (See Table 1). By optimally setting the constant extrapolation parameter, we obtain iteration complexity \(((1+ L_{})}{})^{2}\) in the convex case and \(((1+ L_{})}{}( ))\) in the strongly convex case, when all the clients participate in the training (full participation). We reveal the dependence of the optimal extrapolation parameter on smoothness, indicating that simply averaging the iterates from local training on the server is suboptimal. Instead, extrapolation should be applied to achieve faster convergence. Specifically, compared to FedProx with the same step size \(\), our method is always at least \(2+}}+ L_{}\) times better in terms of iteration complexity, see Remark 5. * Our method, FedExProx, improves upon the worst-case iteration complexity \(((1+ L_{})}{})\) of FedExP (Jhunjhunwala et al., 2023) to \(((1+ L_{})}{})\) (See Table 2). The improvement could lead to acceleration up to a factor of \(n\), see Remark 6. Furthermore, we extend FedExProx to client partial participation setting, showing the dependence of optimal extrapolation parameter on \(\) which is the number of clients participating in the training and the benefits of a larger \(\). In particular, we show that compared to the single client setting, with complexity \((}}{})\), the full participation version enjoys a speed-up up to a factor of \(n\), see Remark 7.
* Our theory uncovers the relationship between the extrapolation parameter and the step size in typical gradient-type methods, leveraging the power of the Moreau envelope. We also recover RPM of Necoara et al. (2019) as a special case in our analysis (see Remark 12), and show that the heuristic outlined in (4), is in fact a step size based on gradient diversity (Horvath et al., 2022; Yin et al., 2018) for the Moreau envelopes of client functions.
* Building on the insights from Horvath et al. (2022), we propose two adaptive rules for determining the extrapolation parameter: based on gradient diversity (FedExProx-GraDS), and the stochastic Polyak step size (FedExProx-StoPS) (Horvath et al., 2022; Loizou et al., 2021). The proposed methods eliminate reliance on the unknown smoothness constant and exhibit "semi-adaptivity", meaning the algorithm converges with any local step size \(\) and by selecting a sufficiently large \(\), we ensure that we lose at most a factor of \(2\) in iteration complexity.
* We validate our theory with numerical experiments. Numerical evidence suggests that FedExProx achieves a \(2\) or higher speed-up in terms of iteration complexity compared to FedProx and improved performance compared to FedExP. The framework and the plots are included in the Appendix.

### Related work

Stochastic gradient descent.SGD(Robbins and Monro, 1951; Ghadimi and Lan, 2013; Gower et al., 2019; Gorbunov et al., 2020) stands as a cornerstone algorithm utilized across the fields of machine learning. In its simplest form, the algorithm is written as \(x_{k+1}=x_{k}- g(x_{k}),\) where \(>0\) is a scalar step size, \(g(x_{k})\) represents a stochastic estimator of the true gradient \( f(x_{k})\). We recover GD when \(g(x_{k})= f(x_{k})\). The evolution of SGD has been marked by significant advancements since its introduction by Robbins and Monro (1951), leading to various adaptations like stochastic batch gradient descent (Nemirovski et al., 2009) and compressed gradient descent (Alistarh et al., 2017; Khirriat et al., 2018). Gower et al. (2019) presented a framework for analyzing SGD with arbitrary sampling strategies in the convex setting based on expected smoothness, which was later extended by Gorbunov et al. (2020) to the case of local SGD. While many methods have been crafted to leverage the stochastic nature of \(g(x_{k})\), substantial research efforts are also dedicated to finding abetter stepsize. An illustration of this is the coordinate-wise adaptive step size Adagrad(Duchi et al., 2011). Another approach involves employing matrix step size, as demonstrated by Safaryan et al. (2021), Li et al. (2023, 2024). Our analysis builds on the theory of SGD mainly adapted from Gower et al. (2019) with additional consideration on the upper bound of the step size.

Stochastic proximal point method.PPM was first introduced by Rockafellar (1976) to address the problems of variational inequalities at its inception. Its transition to stochastic case, motivated by the need to efficiently solve large scale optimization problems, results in SPPM. It is often assumed that the proximity operator can be computed efficiently for the algorithm to be practical. Over the years, SPPM has been the subject of extensive research, as documented by Bertsekas (2011), Bianchi (2016),

    & Features & FedExP & RPMa  & FedExProx \\   Does not require interpolation regime & ✓ & ✗ & ✗ \\ Does not require convexityb & ✓ & ✗ & ✗ \\ Acceleration in the strongly convex settingc & ✗ & ✓ & ✓ \\ Does not require smoothnessd & ✗ & ✓ & ✓ \\ Allows for partial participation of clientse & ✗ & ✓ & ✓ \\ Works with constant extrapolation parameter & ✗ & ✓ & ✓ \\ Smoothness and partial participation influence extrapolation & ✗ & ✓ & ✓ \\ Semi-adaptivityf & ✗ & — & ✓ \\   

* RPM refers to the randomized projection method of Necoara et al. (2019). Our method includes it as a special case, see Remark 12
* Convexity: local objective \(f_{i}\) is convex, which is the indicator function of the convex set \(_{i}\) in RPM.
* The strong convexity pertains to \(f\), and for RPM, it indicates that the linear regularity condition is satisfied.
* Smoothness: \(f_{i}\) is \(L_{i}\)-smooth. Our algorithm also applies in the non-smooth case; see Appendix F.2.
* Jhunjhunwala et al. (2023) provides no convergence guarantee for client partial participation setting.
* The concept of “semi-adaptivity” is explained in Remark 9.

Table 1: General comparison of FedExP, RPM and FedExProx in terms of conditions and convergence. Each entry indicates whether the method has the corresponding feature (✓) or not (✗). We use the sign “—” where a feature is not applicable to the corresponding method.

    &  \\ 
**Method** & **General Case** & **Best Case** & **Worst Case** \\   FedExP & \(_{}}}{{_{k=0}^{K-1}_{k,P}}}\)a  & \(_{}}}{{_{k=0}^{K-1}_{k,P}}}\) & \(L_{}}}{{_{k=0}^{K}()}}\) \\ FedProx & \()}}{{(2- L_{})}}K\)b  & \(L_{}/}}{{(2- L_{})}}\)c  & \(L_{}/}}{{ L_{}}}\)(2-\( L_{}\))c  \\ FedExProx (New) & \(}}{{(1+ L_{})}}\)/\(}}{{ L_{}}}\)c  & \(L_{}/}}{{ L_{}}}\)(2-\( L_{}\))c  & \(L_{}/}}{{ L_{}}}\)(2-\( L_{}\))c [FOOTNOTE:c]Footnote c: See Remark 11 for a lower bound of \(_{k,S}\), using which we can rewrite the rate as \((1+ L_{})}{K}\).

Patrascu and Necoara (2018). Unlike traditional gradient-based methods, SPPM is more robust to inaccuracies in learning rate specifications, as demonstrated by Ryu and Boyd (2014). Asi and Duchi (2019) studied APROX, which includes SPPM as the special case using the full proximal model; APROX was later extended into minibatch case by Asi et al. (2020). However, this extension was based on model averaging rather than iterate averaging. The convergence rate of SPPM has been analyzed in various contexts by Khaled and Jin (2022), Ryu and Boyd (2014), Yuan and Li (2022), revealing that its performance does not surpass that of SGD in non-convex regimes.

Projection onto convex sets.The projection method originated from efforts to solve systems of linear equations or linear inequalities (Kaczmarz, 1937; Von Neumann, 1949; Motzkin and Schoenberg, 1954). Subsequently, it was generalized to address the convex feasibility problem (Combettes, 1997b). Typically, the method involves projecting onto a set \(_{i}\), where \(i\) is determined through sampling or other strategies. A particularly relevant method to our paper is the parallel projection method, in which individual projections onto the sets are performed in parallel, and their results are averaged in order to produce the next iterate. It is well-established experimentally that the parallel projection method can be accelerated through extrapolation, with numerous successful heuristics having been proposed to adaptively set the extrapolation parameter (Bauschke et al., 2006; Pierra, 1984). However, only recently a theory was proposed by Necoara et al. (2019) to explain this phenomenon. Necoara et al. (2019) introduced stochastic reformulations of the convex feasibility problem and revealed how the optimal extrapolation parameter depends on the smoothness of the setting and the size of the minibatch. A better result under a linear regularity condition, which is connected to strong convexity, was also obtained. However, the explanation provided by Necoara et al. (2019) was not satisfactory, as it failed to clarify why adaptive rules based on gradient diversity are effective.

Moreau envelope.The concept of the Moreau envelope, also known as Moreau-Yosida regularization, was first introduced by Moreau (1965) as a mathematical tool for handling non-smooth functions. A particularly relevant property of the Moreau envelope is that executing proximal minimization algorithms on the original objective is equivalent to applying gradient methods to its Moreau envelope (Ryu and Boyd, 2014). Based on this observation, Davis and Drusvyatskiy (2019) conducted an analysis of several methods, including SPPM for weakly convex and Lipschitz functions. The properties of the Moreau envelope and its applications have been thoroughly investigated in many works including Jourani et al. (2014), Planiden and Wang (2016, 2019). Beyond its role in proximal minimization algorithms, the Moreau envelope has been utilized in the contexts of personalized federated learning (T Dinh et al., 2020) and meta-learning (Mishchenko et al., 2023).

Adaptive step size.One of the most crucial hyperparameters in training machine learning models with gradient-based methods is the step size. For GD and SGD, determining the step size often depends on the smoothness parameter, which is typically unknown, posing challenges in practical step size selection. There has been a growing interest in adaptive step sizes, leading to the development of numerous adaptive methods that enable real-time computation of the step size. Examples include Adagrad (Duchi et al., 2011), RMSProp(Hinton et al., 201.), and ADAM(Kingma and Ba, 2015). Recently, several studies have attempted to extend the Polyak step size beyond deterministic settings, leading to the development of the stochastic Polyak step size (Richtarik and Takac, 2020; Horvath et al., 2022; Loizou et al., 2021; Orvieto et al., 2022). Gradient diversity, first introduced by Yin et al. (2018), was subsequently analyzed theoretically by Horvath et al. (2022).

## 2 Preliminaries

We now introduce the several definitions and assumptions that are used throughout the paper.

**Definition 1** (Proximity operator).: _The proximity operator of an extended-real-valued function \(:^{d}\{+\}\) with step size \(>0\) is defined as_

\[_{}(x):=_{z^{d}} \{(z)+\|z-x\|^{2}\}.\]

It is known that for a proper, closed and convex function \(\), the minimizer of \((z)+\|z-x\|^{2}\) exists and is unique. Throughout this paper, we assume that the proximal operators are evaluated exactly, with no approximation or inexactness.

**Definition 2** (Moreau envelope).: _The Moreau envelope of an extended-real-valued function \(:^{d}\{+\}\) with step size \(>0\) is defined as_

\[M_{}^{}(x):=_{z^{d}}\{(z)+\|z-x\|^{2}\}.\]

The following assumptions are used in our analysis. We use the notation \([n]\) for the set \(\{1,,n\}\).

**Assumption 1** (Differentiability).: _The function \(f_{i}\) in (1) is differentiable for all \(i[n]\)._

**Assumption 2** (Interpolation regime).: _There exists \(x_{}^{d}\) such that \( f_{i}(x_{})=0\) for all \(i[n]\)._

Note that Assumption 2 indicates that each \(f_{i}\) and \(f\) are lower bounded. In this paper, we focus on cases where the interpolation regime holds. This assumption often holds in modern deep learning which are overparameterized where the number of parameters greatly exceeds the number of data points, as justified by Arora et al. (2019); Montanari and Zhong (2022). Our motivation for this assumption partly arises from the convex feasibility problem (Combettes, 1997a; Necoara et al., 2019), wherein the intersection \(\) is presumed nonempty. This is equivalent to assuming that the interpolation regime holds when \(f_{i}\) is the indicator function of the nonempty closed convex set \(_{i}\). Further motivations derived from the proof for this assumption will be discussed later.

**Assumption 3** (Convexity).: _The function \(f_{i}:^{d}\) is convex for all \(i[n]\). This means that for each \(f_{i}\),_

\[0 f_{i}(x)-f_{i}(y)- f_{i}(y),x-y,  x,y^{d}. \]

**Assumption 4** (Smoothness).: _Function \(f_{i}:^{d}\) is \(L_{i}\)-smooth, \(L_{i}>0\) for all \(i[n]\). This means that for each \(f_{i}\),_

\[f_{i}(x)-f_{i}(y)- f_{i}(y),x-y} {2}\|x-y\|^{2}, x,y^{d}. \]

_We will use \(L_{}\) to denote \(_{i[n]}L_{i}\)._

It is important to note that the smoothness assumption here is not necessary to obtain a convergence result, see Appendix F.2 for the detail. We introduce this assumption to highlight how the optimal extrapolation parameter depends on smoothness if it is present. The following strong convexity assumption is introduced that, if adopted, enables us to achieve better results.

**Assumption 5** (Strong convexity).: _The function \(f\) is \(\)-strongly convex, \(>0\). That is_

\[f(x)-f(y)- f(y),x-y\|x-y \|^{2}, x,y^{d}.\]

We first present our algorithm FedExProx as Algorithm 1. In the subsequent sections, we first present the theory in the stochastic setting for FedExProx with a fixed extrapolation parameter in Section 3. Then we proceed to adaptive versions of our algorithm which eliminates the dependence on the unknown smoothness constant in Section 4.

Constant extrapolation

In order to demonstrate the convergence result of our algorithm in the stochastic setting, we use \(\)-nice sampling as the way of selecting clients for partial participation. This refers to that in each iteration, the server samples a set \(S_{k}\{1,2,,n\}\) uniformly at random from all subsets of size \(\). We want to emphasize that the sampling strategy here is merely an example, it is possible to use other client sampling strategies.

**Theorem 1**.: _Suppose Assumption 1 (Differentiability), Assumption 2 (Interpolation regime), Assumption 3 (Convexity) and Assumption 4 (Smoothness) hold. If we use a fixed extrapolation parameter \(_{k}=(0,})\) and any step size \(0<<+\), then the average iterate of Algorithm 1 satisfies_

\[[f(_{K})]- f C(,, )-x_{}\|^{2}}{K},\]

_where \(K\) is the number of iteration, \(_{K}\) is sampled uniformly at random from the first \(K\) iterates \(\{x_{0},x_{1},,x_{K-1}\}\), \(C(,,)\) is defined as_

\[C(,,):=}{(2 - L_{,})} L_{,}:= }{1+ L_{}}+L_{},\]

_where \(L_{}=_{i}L_{i}\), \(L_{}\) is the smoothness constant of \(M^{}(x):=_{i=1}^{n}M_{f_{i}}^{}(x)\). If we fix \(\) and \(\) the optimal constant extrapolation parameter is given by \(_{,}:=}>1\), which results in the following convergence guarantee:_

\[[f(_{K})]- f C(,,_{, })-x_{}\|^{2}}{K}=L_{,}( 1+ L_{})-x_{}\|^{2}}{K}.\]

The proof of this theorem relies on the reformulation of the update rule in (7), using the identity \( M_{f_{i}}^{}(x)=(x- {prox}_{ f_{i}}(x))\) given in Lemma 2, which holds for any \(x^{d}\), into the following form:

\[x_{k+1}=x_{k}-_{k}_{i S_{k}} M _{f_{i}}^{}(x_{k}). \]

We can then apply our modified theory for SGD given in Theorem 3, which is adapted from Gower et al. (2019), to obtain function value suboptimality in terms of \(M^{}(x)\). The results are then translated back to function value suboptimality in terms of \(f\). Note that (8) unveils the connection between the step size of gradient type methods and extrapolation parameter in our case.

**Remark 1**.: _Theorem 1 provides convergence guarantee for Algorithm 1 in the convex case. If in addition, we assume Assumption 5 (Strong convexity) holds, the rate can be improved and we obtain linear convergence. See Corollary 1 for the details._

**Remark 2**.: _Theorem 1 indicates convergence for any \(0<<+\). Indeed, as it is proved by Lemma 7, we have \(C(,,_{,})=L_{,}(1+ L _{}) L_{}\) holds for any \(0<<+\). In cases where there exists at least one \(L_{i}<L_{}\), we have \(C(,,_{,})<L_{}\)._

**Remark 3**.: _One may question the necessity of the interpolation regime assumption. This assumption is crucial to our analysis. Besides allowing us to revisit the convex feasibility problem setting, it also guarantees that \(M^{}(x)\) has the same set of minimizers as \(f(x)\) as illustrated by Lemma 8. It also allows us to improve the upper bound on the step size by a factor of \(2\) in the SGD theory, which is demonstrated in Theorem 3 in the Appendix._

**Remark 4**.: _From the reformulation presented in (8), we see the best extrapolation parameter is obtained when \(_{k}\) is the best step size for SGD running on global objective \(M^{}(x)\). Since the best step size is affected by the smoothness and the minibatch size, so is the best extrapolation parameter._

We can also compare our algorithm with FedProx in the convex overparameterized regime.

**Remark 5**.: _Our algorithm includes FedProx as a special case when \(=1\). To recover its result, we simply plug in \(=1\), the resulting condition number is \(C(,,1)=}{(2- L_{,})}\). Compared to FedProx, Algorithm 1 with the same \(>0\) demonstrates superior performance, with the acceleration factor being quantified by_

\[)} 2+ }+ L_{} 4.\]_See Lemma 14 for the proof. This suggests that the approach of the server averaging all iterates following local computation is suboptimal._

In the following paragraphs, we study some special cases,

Full participation caseFor the full participation case (\(=n\)), using definition from Theorem 1

\[_{,n}=}>1, L_{,n}=L_{},  C(,n,_{,n})=L_{}(1+ L_{ }) L_{}. \]

In this case, we can compare our method with FedExP in the convex overparameterized setting.

**Remark 6**.: _Assume the conditions in Theorem 1 hold, the worst case iteration complexity of FedExP is given by \((}{})\), while for Algorithm 1, it is \(()}{})\). As suggested by Lemma 7, Algorithm 1 has a better iteration complexity (\(C(,n,_{,n})<L_{}\)) whenever there exists \(L_{i} L_{}\) for some \(i[n]\), and the acceleration could reach up to a factor of \(n\) as suggested by Example 1. In general, the speed-up in the worst case is quantified by_

\[}{1+ L_{}}(_{i=1}^{n}}{1+ L_{i}})^{-1}}{C(,n,_{ ,n})} n}{1+ L_{}}( {1}{n}_{i=1}^{n}}{1+ L_{i}})^{-1}.\]

Single client caseFor the single client case (\(=1\)), using definition from Theorem 1

\[_{,1}=1+}>1, L_{,1}=}{1+ L_{}}, C(,1,_{,1})=L_{ }.\]

**Remark 7**.: _Compared with full and partial client participation, the following relations hold for any \([n]\),_

\[C(,n,_{,n}) C(,,_{,}) C(,1,_{,1}) _{,1}_{,}_{,n}, [n].\]

_Since the iteration complexity of FedExProx is given by \(()}{ })\), the above inequalities tell us a larger client minibatch size \(\) leads to a larger extrapolation and a better iteration complexity. Specifically, Lemma 7 suggests the improvement over the single client case could be as much as a factor of \(n\) (\(C(,n,_{,n})=C(,1,_{ ,1})\)) as suggested by Example 1._

## 4 Adaptive extrapolation

Observe that in Theorem 1, in order to determine the optimal extrapolation, we require the knowledge of \(L_{,}\), which is typically unknown. Although theoretically it suggests that simply averaging the iterates may result in suboptimal performance, in practice, this implication is less significant. To address this issue, we introduced two variants of FedExProx, based on gradient diversity and stochastic Polyak step size, given their relation to the extrapolation parameter in our cases.

**Theorem 2**.: _Suppose Assumption 1 (Differentiability), Assumption 2 (Interpolation regime), Assumption 3 (Convexity) and Assumption 4 (Smoothness) hold._

1. _(_FedExProx-GradS_): If we are using_ \(_{k}=_{k,G}\)_, where_ \[_{k,G}:=_{i=1}^{n}\|x_{k}-_{ f _{i}}(x_{k})\|^{2}}{\|_{i=1}^{n}(x _{k}-_{ f_{i}}(x_{k}))\|^{2}} 1,\] (10) _then the iterates of Algorithm_ 1 _with_ \(=n\) _satisfy_ \[[f(_{K})]- f}{2+  L_{}}(+L_{})-x_{}\|^{2}}{_{k=0}^{K-1}_{k,G}},\] _where_ \(_{K}\) _is chosen randomly from the first_ \(K\) _iterates_ \(\{x_{0},x_{1},...,x_{K-1}\}\) _with probabilities_ \(p_{k}=}}{{_{k=0}^{K-1}_{k,G}}}\)_.__._
2. _(FedExProx-StoPS): If we are using_ \(_{k}=_{k,S}\)_, where,_ \[_{k,S}:=_{i=1}^{n}(M_{f_{i}}^{}(x_{k} )- M_{f_{i}}^{})}{\|_{i=1}^{n}  M_{f_{i}}^{}(x_{k})\|^{2}}},\] (11) _then the iterates of Algorithm_ 1 _with_ \(=n\) _satisfy_ \[[f(_{K})]- f(+L_{ })-x_{}\|^{2}}{_{k=0}^{K-1}_ {k,S}},\] (12) _where_ \(_{K}\) _is chosen randomly from the first_ \(K\) _iterates_ \(\{x_{0},x_{1},...,x_{K-1}\}\) _with probabilities_ \(p_{k}=}}{{_{k=0}^{K-1}_{k,S}}}\)_._

Theorem 2 describes the convergence in the full participation setting. However, we can also extend it to the stochastic setting by implementing a stochastic version of these adaptive step size rules for gradient-based methods (Horvath et al., 2022; Loizou et al., 2021). See Theorem 5 in the Appendix for the details.

**Remark 8**.: _In fact, the adaptive rule based on gradient diversity can be improved by using \(}{1+ L_{}}\) instead of \(\) as the maximum of local smoothness constant of Moreau envelops, resulting in the extrapolation,_

\[_{k}=_{k,G}^{}:=}{ L_{}} _{i=1}^{n}\|x_{k}-_{ f_{i}} (x_{k})\|^{2}}{\|_{i=1}^{n}(x_{k}- _{ f_{i}}(x_{k}))\|^{2}}. \]

_One can obtain a slightly better convergence guarantee than the FedExProx-GraDS case in Theorem 2, see Corollary 2 in the Appendix. However, the requires the knowledge of \(L_{}\) in order to compute \(}{ L_{}}\)._

**Remark 9**.: _Note that, compared to classical gradient-based methods, FedExProx-GraDS benefits from "semi-adaptivity". This refers to the fact that the algorithm converges for any choice of \(>0\). Although a smaller \(\) hinders convergence, setting it to at least \(}\) limits the worsening of the convergence to a factor of \(2\)._

**Remark 10**.: _Compared to FedExProx with the optimal constant extrapolation parameter, we gain "semi-adaptivity" here by using the gradient diversity based extrapolation. However, this results in losing the favorable dependence of convergence on \(L_{}\) and instead establishes a dependence on \(L_{}\)._

**Remark 11**.: _For FedExProx-StoPS, as it is suggested by Lemma 20, the convergence depends on the favorable smoothness constant \(L_{}\), rather than on \(L_{}\). However, this comes at the price of having to know the minimum of each individual Moreau envelope._

For a detailed discussion of the adaptive variants of FedExProx, we refer the readers to Appendix F.5. Since one of our starting points is the RPM by Necoara et al. (2019) to solve the convex feasibility problem with non-smooth local objectives, we have also adapted our method to non-smooth cases, as detailed in Theorem 4 in the Appendix. We also provided a discussion of our method in the non-interpolated setting and in the non-convex setting in Appendix F.

Finally, we support our findings with experiments, see Figure 1 for a simple experiment confirming that FedExProx indeed has a better iteration complexity than FedProx. For more details on the experiments, we refer the readers to Appendix I in the Appendix. Notice that in practice, each local proximity operator can be solved using different oracles. Clients may use GD or SGD to solve the local problem to a certain accuracy. The complexity of this subroutine depends on the local stepsize. If \(\) is large, the local problem becomes harder to solve because we aim to minimize the local objective itself. Conversely, if it is small, the problem is easier since we do not stray far from the current iterate. As the choice of subroutine affects local computation complexity, comparing it directly with FedExP becomes complicated. Therefore, we compare the iteration complexity (number of communication rounds) of the two algorithms, assuming efficient local computations are carried out by the clients.

## 5 Conclusion

### Limitations

Our analysis of FedExProx serves as an initial step in adding extrapolation to FedProx, which currently relies on the suboptimal practice of the server merely averaging the iterates. While we discuss the behavior of our algorithm in non-interpolated and non-convex scenarios, our analysis only validates the effectiveness of extrapolation under the interpolation regime assumption.

### Future Work

As we have just mentioned, extending our method and analysis beyond interpolation and convex regime is intriguing. In this case, new techniques may be needed for variance reduction. It is also interesting to investigate whether extrapolation can be applied together with client-specific personalization.