# Transferring disentangled representations: bridging the gap between synthetic and real images

Jacopo Dapueto Nicoletta Nocet Francesca Odone

jacopo.dapueto@edu.unige.it

{nicoletta.noceti,francesca.odone}@unige.it

MaLGa-DIBRIS, Universita degli studi di Genova, Genova, Italy

###### Abstract

Developing meaningful and efficient representations that separate the fundamental structure of the data generation mechanism is crucial in representation learning. However, Disentangled Representation Learning has not fully shown its potential on real images, because of correlated generative factors, their resolution and limited access to ground truth labels. Specifically on the latter, we investigate the possibility of leveraging synthetic data to learn general-purpose disentangled representations applicable to real data, discussing the effect of fine-tuning and what properties of disentanglement are preserved after the transfer. We provide an extensive empirical study to address these issues. In addition, we propose a new _interpretable_ intervention-based metric, to measure the quality of factors encoding in the representation. Our results indicate that some level of disentanglement, transferring a representation from synthetic to real data, is possible and effective.

## 1 Introduction

Developing meaningful, reusable and efficient representations is a critical step in representation learning . Disentangled Representation Learning (DRL)  aims to learn models that can identify and disentangle underlying Factors of Variation (FoVs), hidden in the observable data. These models encode them in an interpretable and compact shape , independently from the task at hand . Moreover, DRL enhances explainability, robustness, and generalization capacity across various applications . Disentangled representations have been shown useful for various downstream tasks, such as FoVs prediction , image generation  and translation , fair classification , abstract reasoning , domain adaptation , and out-of-distribution (OOD) generalization .

While all the abovementioned methods may rely on different definitions of disentanglement (see just as examples ), and in this sense a comprehensive comparison is hard, they usually share the observation that some level of supervision on the FoVs is beneficial for disentanglement. However, labelling every single factor to achieve fully supervised disentanglement is costly or even unfeasible . For this reason, DRL has been mostly validated on synthetic or simulated data, usually acquired on purpose , and there is a limited understanding of the potential of DRL to address general-purpose representation tasks, as well as the specific challenges of the real world (e.g. the presence of clutter and occlusion, correlation between factors , etc.). Such challenges may prevent the model from learning perfectly disentangled representations .

In this work, we propose the adoption of Disentangled Representation (DR) transfer to deal with complex realistic/real dataset. DL transferring was explored in , where Source models learnt in an unsupervised manner were transferred to a Target dataset, by transferring hyperparameters. The authors observed a limited effectiveness in the direct transfer of representations. Instead, Dittadi et al.  found out that disentangled representation can help in OOD generalization from a simulated to a smaller real dataset. In both cases, the study involved very specific types of dataset, built to emulatethe real one in every detail. Recently, Fumero et al.  addressed disentanglement in real data without the need for FoVs annotation, leveraging the knowledge extracted from a diversified set of supervised tasks to learn a common disentangled representation to be transferred to real settings. We follow a different direction, setting up a very straightforward and generalizable procedure: we resort to a weakly supervised approach [41; 25; 26] to learn DRs on Source datasets where the FoVs are known and annotated, to then transfer (with no supervision) such representation to a Target dataset where the FoVs are not known or available. Our final aim is to consider real datasets as a Target, while synthetic data (where FoVs annotation is easy to obtain) can be employed as a Source.

The paper presents three main contributions: **(1) a novel metric** to assess the quality of disentanglement, which is _interpretable_, classifier-free and informative on the structure of the latent representation; **(2) a DR transfer methodology** to Target datasets without FoV annotation; **(3) an extensive experimental analysis** that considers different (Source, Target) pairs and quantitatively assesses the expressiveness of the learnt DR on Target of different nature (including the case where the gap between Source and Target is large), taking into consideration the main expected properties of disentangled representation. We discuss the role of fine-tuning and the need to reason on the distance between Source and Target datasets.

The paper is organized as follows. In Section 2, we propose and discuss our new intervention-based metric, OMES. In Section 3.3, we introduce our transfer approach to DRL, and provide a thorough analysis of different types of transfer scenarios (synthetic to synthetic, synthetic to real, real to real). Section 5 is left to the conclusions.

## 2 Evaluating the quality of disentanglement

### Background

While there is no universally accepted definition of disentanglement, there is common agreement on the properties that a DR should have [12; 54; 66; 1; 57; 2]:

**Modularity**: : A factor influences only a portion of the representation space, and only this factor influences this subspace. This is achievable if the FoV are independent, meaning that a variation in one FoV does not affect others.
**Compactness**: : The subset of the representation space affected by a FoV should be as small as possible (ideally, only one dimension). This property is also called _completeness_ in .
**Explicitness**: : DR should explicitly describe the factors, thus it should favour FoVs classification.

The taxonomy presented in  groups all metrics in three families (see a summary in Table 6 in App.): **Intervention-based** metrics compare codes by intervention, either creating subsets of data in which one or more factors are kept constant (_BetaVAE_ and _FactorVAE_), or in which only one factor is varying (_RF-VAE_), and predicting which factors were involved in the intervention; **Predictor-based** metrics use regressors or classifiers to predict factors from DR (_DC1 Disentanglement_ and _SAP_) or intervened subsets (_BetaVAE_, _FactorVAE_ and _RF-VAE_); **Information-based** metrics leverage information theory principles, such as mutual information, to quantify factor-DR relationships (_Mutual Information Gap (MIG)_[8; 12], _MED_, _Modularity_ and _InfoMEC_).

Intervention-based metrics have the advantage of providing control over the factor and the corresponding representation. However, they are all based on classifiers, thus they depend on method, hyperparameter settings and model capacity. The latter consideration can be extended to all Predictor-based metrics. On the other hand, Information-based methods are mainly ground on the computation of Mutual Information, which is dependent on an estimator and its parameters [51; 7].

Motivated by these limitations, we introduce in the next section a new metric, to the best of our knowledge, the _first_ classifier-free intervention-based metric.

### Our metric: OMES

OMES (_Overlap Multiple Encoding Scores_) is an intervention-based metric measuring the quality of factor encoding in the representation while providing information about its structure: we measure _modularity_, analyzing how the FoVs overlap, and _compactness_, detecting and quantifying how a factor is encoded in the dimensions of the representation.

```
0: matrix \(S\), FoV index \(j\)
0:\(S^{m n}\)
1: scores \(\) ZEROS(m)
2:for\(h=1\) to \(m\)do\(\) dimension \(h\)
3:\(i_{S}\) ZEROS(\(n\)); \(i_{S}[j]\) = 1
4: scores[\(h\)] = 1 -MAE(\(i_{S}\), \(S[h,:]\))
5:endfor
6:return POOLING(scores)
```

**Algorithm 2** Overlap score of FoV \(j\): **OS**

Given an image \(X\), with \(\) its mapping into a \(d-\)dimensional latent disentangled space, \((X)=r\), \(r^{d}\). We discard dimensions whose empirical standard deviation is extremely small (\(<0.05\)), meaning that the dimensions are inactive .This leaves us with a subset of \(m d\) active dimensions, to which we will refer in the following.

Let \(D\) be a dataset formed by image pairs, \(D=\{(X_{i}^{1},X_{i}^{2},k_{i})\}_{i=1}^{N}\), where \(X_{i}^{1},X_{i}^{2}\) are two images that differ for only the FoV \(k_{i}\).

OMES requires computing a weighted _association_ matrix \(S\) between the dimensions of the representation and the FoVs, with higher association values if the factor is encoded in a certain dimension (see Algorithm 1): we consider the representations of the image pairs in dataset \(D\), obtaining \(D_{}\). In matrix notation we may write it as \(D_{}=[^{1},^{2},]\), where the pair \(^{1}\) and \(^{2}\) are \(N m\)-dimensional matrices with each row \(i\) is the representation of the \(i\)-th image pair \((X_{i}^{1})=r_{i}^{1}\) and \((X_{i}^{2})=r_{i}^{2}\) respectively. For each FoV \(k\) we extract the rows of \(D_{}\) such that the \(i\)-th entry of vector \(\) is \(k_{i}=k\), we call this set \(D_{}^{k}\). Each entry \(S[h,j]\) of the association matrix relates a dimension \(h\) of the estimated disentangled representation with a FoV \(j\). Its value is in the range \(\) with elements close to \(1\) corresponding to a dimension that effectively captures the variations of a FoV. The association is based on a correlation analysis: since the samples from \(D_{}^{k}\) are paired to differ only for the FoV \(k\), we expect a good representation _not to correlate_ where such FoV is encoded. To ease interpretability, we transform the obtained values (see Algorithm 1, line 6) so that high values denote a strong association between dimension and FoV.

When the model exhibits perfect disentanglement, each row and column of the association matrix \(S\) present just one element with a high association, corresponding to the only dimension where the factor is encoded. We thus measure the level of disentanglement through similarity with an ideal array, where the association matrix shows all 0s but in the positions of the correct associations, where there are 1s.

```
0: matrix \(S\), FoV index \(j\)
0:\(S^{m n}\)
1: scores \(\) ZEROS(m)
2:for\(h=1\) to \(m\)do\(\) dimension \(h\)
3:\(i_{S}\) ZEROS(\(m\)); \(i_{S}[h]\) = 1
4: scores[\(h\)] = 1 -MAE(\(i_{S}\), \(S[h,:]\))
5:endfor
6:return POOLING(scores)
```

**Algorithm 3** Encoding score of FoV \(j\): **MES**

We rely on the above considerations to derive our metric as a linear combination of two main contributions. The _Overlap Score_ (OS) penalizes the overlap of different FoVs in the same dimensions (Algorithm 2 -- in this case, each row of \(S\), associated with a dimension, is compared with the ideal array) and hence measures Modularity, while the _Multiple Encoding Score_ (MES) penalizes the encoding of the same factor into different dimensions (Algorithm 3 -- in this case each column of \(S\) corresponding to a FoV is compared with the ideal array) measuring Compactness. In both algorithms, we derive a vector summarizing the contribution of all dimensions for the FoV.

The final score in \(\) (higher values meaning higher disentanglement) can be obtained with a pooling (either MAX or AVERAGE) on the vector. The OMES metric is computed as

\[OMES(S)=_{j=1}^{n}\;(S,j)+(1-)\;(S,j). \]

With \(=0\), OMES only measures the Compactness of the representation (MES component); with \(=1\), instead, our metric measures the Modularity only (with OS). Values of \(\) in the interval \((0,1)\) can be used to balance the importance of both contributions.

**Relation with existing metrics.** To the best of our knowledge, the only metrics capturing more than one property are DCI  and the very recent InfoMEC . Differently from DCI, our metric is intervention-based with no influence on the choice of the specific classifier that may inevitably impact the results, as observed in . With respect to InfoMEC, that must be applied to quantized latent codes, our metric is more general and accepts continuous latents.

OMES is based on the intervention of the FoVs, thus we require the FoV to be (at least partially) known: in particular, samples are coupled so that they differ in one FoV only. In this, OMES differs from existing intervention-based metrics [24; 27] in which the intervention is the opposite (samples have only one FoV in common). Our pairing requires less supervision, and it is usually easier to obtain during data acquisition (for instance, from videos ). In addition, it has been shown that this type of pairing provides more guarantees on disentanglement properties [60; 41].

Finally, compared to Information-based methods, we exploit Correlation instead of Mutual Information, hence we do not need its estimation that can be sensitive to parameters choice (e.g. granularity of the discretization ) and choice of estimator [51; 7].

### OMES assessment

We now analyze OMES, extending previous studies on the unsupervised  and weakly supervised  setting. As for the _unsupervised case_, we exploit available 5400 trained models from  (3 datasets, 6 values for \(\), 50 random seeds, 6 unsupervised methods:\(\)-VAE , FactorVAE , \(\)-TCVAE , DIP-VAE-I , DIP-VAE-II, AnnealedVAE ); in this section we report an analysis on Noisy-dSprites, the remaining 2 benchmarks can be found in the Appendix B.1 and B.2. Instead, for the _weakly supervised case_ trained models are not available, so we reproduce the models as in  training them on Shapes3D and on other datasets that can be found in Appendix B.3.

**OMES interpretation.** The metric, by construction, allows us to compute the overall score and a score for each FoV separately: we can thus interpret the effect of hyperparameters on the single FoV, and evaluate the FoV separately in each dimension of the representation. Moreover, by inspecting the metric at a factor level, we may identify uneven behaviours (e.g. models performing similarly on average but for different contributions from the factors).

Fig. 1 (Left) shows the metric scores for different values of \(\) keeping the different FoV separated: the FoVs less affected by reconstruction (e.g. PosX and PosY) exhibit an increasing disentanglement score as \(\) grows. On the other hand, Shape and Orientation present a maximum value around \(=6\) and then decrease because they are more susceptible to the reconstruction quality, which degrades for larger values of \(\). In Fig. 1 (Center Left) an association matrix \(S\) is generated from one

Figure 1: Dataset _Noisy-dSprites_: **Left:** Scores of the proposed metric for each FoV, \(\) is fixed to 0.5. **Center Left:** Association matrix of an unsupervised model (\(=6\)). **Center Right:** Association matrix of a weakly-supervised model. **Right:** Scores of synthetic Association matrices simulating underfitting, partial disentanglement and almost perfect disentanglement.

of the unsupervised models (\(\)-VAE) trained with \(=6\): Shape and Orientation are encoded in the same dimension (overlapping) and produce lower values because of the reconstruction, while PosX and PosY are encoded in multiple dimensions and mostly overlapping. Scale does not seem to be well represented. In Fig. 1 (Center Right) we report the association matrix obtained by a weakly-supervised model (Ada-GVAE): the factors PosX, PosY and Scale are disentangled while Shape and Orientation are encoded in the representation with high intensity in different dimensions, with overlaps. Fig.1 (Right) shows OMES values (\(=0.5\)) computed over synthetic association matrices \(S\), obtained by perturbing the ideal (diagonal) one. The perturbation aims to simulate 3 scenarios: noisy matrices where the disentanglement can be more or less strongly derived; models exhibiting partial disentanglement; models with no disentanglement. As it can be appreciated, the metric score nicely reflects the disentanglement intensity.

**Agreement of OMES with other disentanglement metrics.** We extend the analysis in . The rank-correlation (e.g. Fig. 2 (Left)) between the previously proposed metrics and our OMES (for \(=0.5\)) shows that the latter has a high level of correlation with MIG and DCI, but mild correlation with BetaVAE, FactorVAE (OMES is based on the opposite intervention type), and Modularity. This is consistent on all benchmarks. We show in Fig. 2 (Center) the score distribution of the metrics, computed on the whole set of models. We observe OMES produces a wider range of values with respect to MIG and DCI: our metric looks more descriptive, similarly to BetaVAE and FactorVAE.

**Agreement with performance metrics.** Similarly to , we consider the more informative weakly-supervised setting and discuss the rank correlation between our metric and performance evaluations (ELBO, reconstruction loss, and test error of FoVs classifier). Our analysis, reported in Fig. 2 (right) shows that OMES performs similarly to DCI, negatively correlated with the Reconstruction loss, and positively with the ELBO. It also correlates with the performances of GBT10000 (the classifier we will use in the experiments) while it mildly does with MLP10000. This empirical evidence is in line with what was observed in . _The correlation with the classification score is a sign that OMES is able to capture the property of expliciteness of the representation, although it is not directly measured by our metric._ It is worth mentioning the correlation of OMES with the performance metrics is more stable than what is obtained by other metrics across different datasets (see the Appendix B.3).

## 3 Transferring disentangled representations

Fully unsupervised disentangled representation learning has been shown unsatisfactory in many scenarios . However, annotating the FoVs can be a very critical and uncertain process. In this section, we propose a general-purpose methodology for transferring disentangled representations learned from supervised synthetic or simulated data to an unsupervised dataset (in terms of the FoVs). This approach allows us to evaluate the effectiveness of disentangled representations transfer, and its potential in real-world applications.

### Our methodology and research questions

Most of the focus in learning disentangled representations has been on synthetic datasets whose ground truth factors exhibit perfect independence by design . Instead, real-world

Figure 2: **Left: Rank-correlation between metrics of models trained on _Noisy-dSprites_. Center: Scores distribution of the metrics on Noisy-dSprites. Right: Rank correlations (Spearman) of ELBO, reconstruction loss, and the test accuracy of a GBT and a MLP classifier trained on 10,000 labelled data points with disentanglement metrics. In all plots OMES is computed with \(=0.5\).**

scenarios present several challenges that we want to investigate in our analysis.

We consider \(\)-VAE models with weakly supervised learning specifically we adopted Ada-GVAE , for its simplicity and its sampling strategy similar to our metric, on a _Source_ Dataset, using pairs of images that differ in \(\) factors of variation. We set \(=1\) as it was shown to lead to higher disentanglement . Following , we vary the parameter \(\) in \(\{1,2\}\), sufficient to achieve high disentanglement with weak supervision [11; 41].

We evaluate the quality of the disentanglement in a transfer learning scenario, assessing the transferability of the disentangled representation on a _Target_ Dataset, with the final aim of targeting real scenarios. The evaluation we report considers our metric OMES, as well as DCI and MIG, the most widely used metrics in the literature [50; 18; 17; 14; 69; 25; 45]. Moreover, in accordance to [40; 41; 11], we evaluate the quality of the disentanglement also in terms of accuracy w.r.t. a downstream classification task, with a classifier per FoV. We evaluate the latter in two modalities: (1) Considering the entire representation and (2) Selecting with OMES the dimension of the representation that best encodes the FoVs. Our analysis addresses three main research questions:

**Q1 -** _How well does disentanglement transfer, and how much does it depend on the distance between Source and Target Dataset?_

We will consider different transfer learning scenarios (syn2syn, syn2real, real2real) and pairs (_Source, Target_) datasets with different distances.

**Q2 -** _Which properties of a DR are preserved on the Target Dataset?_

We will discuss _Explicitness_ of the representation (through FoV classification), _Compactness_ (analysing the component MES of OMES, the MIG metric, as well as the performances of the one-dimensional representation), _Modularity_ (relying on the OS component of OMES and on DCI).

**Q3 -** _How effective is fine-tuning on the disentanglement?_

We will consider the performances of the FoVs classification, the compactness and the modularity on the _Target dataset_ before and after fine-tuning.

### Datasets

In our analysis, we consider both synthetic and real datasets offering different challenges, a summary of their properties is in Tab. 1. Some of the datasets are _DRL-compliant_, meaning that there is full independence between the FoVs (this is reported in column _Indepencence_), and FoVs appear in all their possible combinations. This is easy to achieve if the dataset is specifically tailored for DRL, but it can not be easily obtained in general.

**dSprites** is a dataset of 2D shapes generated from 5 ground truth FoVs: Shape, Scale, Rotation, x and y Positions. Variants of the dataset have been proposed: in **Noisy-dSprites** the background is filled with uniform noise; **Color-dSprites** includes Color as an additional FoV; **Noisy-Color-dSprites** adds uniform noise to the latter. We refer to them as: **N-dSprites, C-dSprites** and **N-C-dSprites.

**Shapes3D**** is a dataset of 3D shapes, generated from 6 ground truth FoVs: Floor colour, Wall colour, Object colour, Scale, Shape and Orientation. It is characterized by the presence of _Occlusions_.

**Isaac3D** is a synthetic dataset of a 3D scene of a kitchen where a robot arm is holding objects in a variety of configurations. It is characterized by 9 _real-world complex_ FoVs, including robot movements, camera height, environmental conditions (e.g. lighting).

  
**Dataset** & **Real** & **3D** & **Occlusions** & **\#FoV** & **Independence** & 
 **Complete** \\ **annotation** \\  & **Resolution** & **\#Images** \\  dSprites & ✗ & ✗ & ✗ & 5 & ✓ & ✓ & \(64 64\) & 737K \\ Noisy-dSprites & ✗ & ✗ & ✗ & 5 & ✓ & ✓ & \(64 64\) & 737K \\ Color-dSprites & ✗ & ✗ & ✗ & 6 & ✓ & ✓ & \(64 64\) & 4.4M \\ Noisy-Color-dSprites & ✗ & ✗ & ✗ & 6 & ✓ & ✓ & \(64 64\) & 4.4M \\ Shapes3D & ✗ & ✓ & ✓ & 6 & ✓ & ✓ & \(64 64\) & 480K \\ Isaac3D & ✗ & ✓ & ✓ & 9 & ✓ & ✓ & \(128 128\) & 737K \\ Coill00-Augmented & ✓ & ✓ & 4 & ✓ & ✓ & \(128 128\) & 1.1M \\ RGB-D Objects & ✓ & ✓ & ✓ & 3* & ✗ & ✗ & \(256 256\) & 35K \\   

Table 1: Summary of the datasets and their properties. * in the \(\#FoV\) refers to the possible presence of hidden factors.

There are few real datasets available specifically meant for DRL.  is a collection of datasets covering the transitions from simulated to real data, which is, however, not fully available at the moment.  is not appropriate for our analysis since the real data section is very small compared to the complexity of the task. We consider instead real benchmarks proposed for classification tasks, chosen to reflect some of the real-world challenges but possessing some "semantic connection" with the synthetic dataset we refer to, e.g. in terms of the expected FoVs. This allows us to reason on the potential of transferability. Example images are in Appendix C.1.

**Coil** is derived from Coil100 . The original dataset contains 7200 real color images of 100 objects. The objects were placed on a motorized turntable against a black background. The turntable was rotated to vary object pose w.r.t. a fixed camera, producing self-occlusions and 2D silhouette changes. We augment the original dataset with two additional FoV, a planar rotation (9 angles) and a scaling (18 values). Therefore, we identify 4 FoV (Objects, Pose, Rotation and Scale) that, by construction, are independent. To consider in our analysis a real dataset visually related to dSprite, we derived a binary version of Coil, called **Coil(bin)**, by applying Otsu's thresholding .

**RGBD-Objects** is a dataset of 300 common household objects acquired by a RGB-D camera. The objects are organized into 51 Categories and a varying number of _instances_ for each category. For each object, 3 video sequences have been acquired with different camera heights (Elevation) so that the object is viewed from different angles while rotating (Pose). Then, images have been cropped so that the object is always in a central position. For our experiments, we used a subset with one object instance per category to make it semantically similar to Coil100 but with the additional complexity of variability in the background, presence of occlusions and clutter. Hence, we control 3 FoVs (Category, Elevation, Pose), but other factors are _hidden or not annotated_ (e.g. Background, Illumination, etc.) due to a realistic acquisition protocol. We refer to RGBD-Objects as **RGBD**. We also use a variant of the dataset, including depth maps only, referred to as **RGBD(depth)**.

### Experimental analysis

**Implementation details.** We trained 20 different models (10 random seeds \(\) 2 values of \(\)) for each _Source_ dataset. We adopted the same training strategy as in  (see Appendix C.2). As for FoVs classification, following [11; 41], we consider Gradient Boosted Trees (GBT)  and a Multilayer Perceptron (MLP)  with 2 hidden layers of size 256. Since the specific choice of a classifier is not crucial for our analysis, here we report GBT, MLP can be found in Appendix C.7. Fine-tuning to the _Target_ dataset of the VAE models is unsupervised and it is carried out for 50k steps.

**Tables description.** The tables group different experiments based on the _Target_ dataset. For each FoV, we report under the name the number of values the factor can assume (i.e. its _granularity_). The tables report the average classification performance over the 20 models, before and after fine-tuning. The latter is reported in parenthesis in terms of gain or loss w.r.t. the performance before the fine-tuning. _All_ is the average performance of all FoVs.

The column _Pruned_ highlights the two different representation modalities: if the classifier is trained on the whole representation (\(\)), or using only one dimension, i.e. the one showing the strongest encoding of a certain FoV according to the OMES metric (\(\)). As already mentioned, a good performance of the former is an indication of explicitness, while the latter is a positive sign of compactness. Tables also report metrics assessing Modularity (our MES and DCI) and Compactness (our OS and MIG).

Note that we exploit the interpretability of OMES in the transfer learning process to select the most representative dimension of the representation for the classification (the "Pruned" columns).

**(1) Synthetic to synthetic.** As a baseline, we consider the case in which both _Source_ and _Target_ datasets are synthetic and we have access to the annotation of the FoVs, they are DRL-compliant. If Source and Target have the same FoVs (S=dSprites with T=Noisy-dSprites or S=Color-dSprites with T=Noisy-Color-dSprites, see Table 2) we observe that pruning the representation to just one dimension maintains, on average, stable performances. This shows that the _compactness_ of the representation is preserved for the Target dataset, both before and after fine-tuning.

Fine-tuning allows for improved performance in terms of _explicitness_ preserving the remaining properties of the representation, also in the case of the pruned representation. The Orientation FoV is difficult in these datasets as it suffers from reconstruction errors. We increase complexity by adding a new FoV to the Target dataset (S=dSprite with T=Color-dSprite, see Table 2).

All FoVs in common between Source and Target are effectively classified, again except Orientation. As for the new FoV (Color), we report lower performances, but we can appreciate a significant improvement with fine-tuning if we exploit a global representation. Instead, we observe a lower improvement with the pruned representation, suggesting that the new factor is not encoded in one single dimension.

To further increase the distance between Source and Target, we consider pairs for which the semantics of the FoVs are the same, but they are different in appearance, granularity, and composition (S=Color-dSprrite with T=Shapes3D, see Table 3): we can observe that even without fine-tuning, the latent representation allows the classification of the dominant FoVs of the dataset, i.e. Floor Hue and Wall Hue, also when focusing on a single dimension. Fine-tuning positively affects the average classification accuracy, especially when using the whole representation.

We finally reason on the gap between Source and Target datasets in terms of complexity. When the Source is simpler than the Target but still they have some FoVs in common, possibly with different appearances, (e.g. S=Shapes3D, T=Isaac3D, Table 9 and Table 10) we can appreciate the effectiveness of transfer and fine-tuning for all metrics. Conversely, when the Source is much more complex than the Target (e.g. when S=Isaac3D, T=Shapes3D) one could expect the richness in the Source to be directly transferrable to the simpler Target. However, we observe that the finetuning is still beneficial for all the disentanglement metrics. This can be explained by the "domain" dependence of VAE models.

Discussion. Disentanglement transfers well between synthetic datasets with the same FoVs, w.r.t. all the properties. If the Target includes new FoVs, fine-tuning is necessary for the new FoV, but also for the entire representation, as compactness and modularity are partially degraded by the new FoV. When the Source and Target become significantly different, fine-tuning is also beneficial. We can conclude that when both Source and Target are synthetic and DRL-compliant, the properties of disentangled representation are preserved before and after fine-tuning, especially when the datasets have FoVs in common even though they have different appearance.

**(2) Synthetic to Real.** We now analyse the potential of transferring a disentangled representation from an appropriately generated Synthetic Source (DRL-compliant) to a Real Target. We first consider Real

    &  &  &  &  &  \\   & & & **Color** & **Shape** & **Scale** & **Orientation** & **Pock** & **PostV** & **Dual** & **Our** & **Our** & **Our** & **Our** & **Our** \\  & & & **Color** & **(3)** & **(6)** & **(40)** & **(32)** & **(32)** & **All** & **Our** & **Our** & **Our** & **Our** & **Our** \\   &  & ✗ & & 61.1 & 47.1 & 6.7 & 17.8 & 17.1 & 30.0 &  &  &  &  &  \\  & & & & (11.2) & (12.0) & (17.5) & (27.9) & (28.1) & (14.7) & & & & & \\  & & & & (4.21) & 4.7 & 3.8 & 14.3 & 14.3 & 25.8 &  &  &  &  &  \\  & & & & (4.66) & (6.83) & (4.35) & (42.5) & (22.0) & (12.0) & & & & & \\   & & & & 30.8 & 94.2 & 86.9 & 43.8 & 75.7 & 65.7 &  &  &  &  &  \\  & & & (45.4) & (-1.9) & (+0.5) & (-4.2) & (-5.1) & (-5.3) & (+3.2) & & & & & \\  & & & & 26.2 & 76.7 & 77.0 & 71.1 & 74.9 & 74.6 &  &  &  &  &  &  \\  & & & (46.8) & (47.6) & (42.4) & (41.0) & (-4.1) & (-4.3) & (-40.7) & & & & & \\   &  &  & ✗ & & 30.4 & 71.6 & 25.8 & 27.9 & 30.0 &  &  &  &  &  &  \\  & & & (46.2) & (7.3) & (16.8) & (-0.9) & (+19.7) & (+20.2) & (+21.7) & & & & & \\    & & & & 29.1 & 39.3 & 25.3 & 2.6 & 6.0 & 5.3 & 17.9 &  &  &  &  &  \\  & & & (45.23) & (+45.3) & (+41.2) & (-0.4) & (+7.1) & (+7.4) & (+13.8) & & & & \\   

Table 2: Quantitative evaluation of transferred disentangled models using the dSprites family of datasets. We transfer from a Source (ST) to a Target Dataset (TD). We report the average classification accuracy obtained with GBT on the full and the pruned representations (see text). The last columns on the right report a comparison between disentanglement metrics, including MES and OS.

    &  &  &  &  &  \\   & & & **Floor Hue** & **Wall Hue** & **Object Hue** & **Scale** & **Shape** & **Orientation** & **Pock** & **All** & **Our** & **Our** & **Our** & **Our** & **Our** & **Our** \\  & & & **(10)** & **(10)** & **(10)** & **(0)** & **(4)** & **(15)** & **All** & **Our** & **Our** & **Our** & **Our** & **Our** \\   & ✗ & & 78.0 & 89.3 & 43.6 & 25.4 & 55.5 & 35.3 &  &  &  &  &  &  &  &  &  &  \\  & & & (+14.1) & (+13.1) & (+25.6) & (+9.6) & (+18.6) & (+0.8) & (+13.6) & & & & & \\  & & & (63.5) & (+95.5) & 28.5 & 23.3 & 43.6 & 25.4 & 40.0 & (+0.6) & (+9.0) & (+1.1) & (-0.4) \\  & & & (2.0) & (+42.9) & (+13.7) & (+44.4) & (+11.4) & (+0.8) & (+5.1) & & & & \\   &  & ✗ & & 79.4 & 46.8 & 80.1 & 53.7 & 9.88 &  &  &  &  &  &  &  &  &  \\  & & & (+8.0) & (+12.5) & (+8.0) & (+10.8) & (+5.2) & (+5.1) & (+6.2) & & & & & \\  & & & (60.6) & 52.34 & 30.2 & 25.3 & 44.0 & 29.4 & 40.3 & (+0.8) & (+7.4) & (+2.1) & (-1.4) \\  & & & (5.8) & (+13.2) & (+12.1) &

[MISSING_PAGE_FAIL:9]

(limited) benefit in Modularity and Compactness. If the Target incorporates unknown hidden factors, as we may expect to happen in the real world, Modularity and Compactness transfer worse, and the benefit of fine-tuning is limited.

**(3) Real to Real.** We conclude by discussing the possibility of transferring from a DRL-compliant real dataset to another real one. As a first task, we consider as a Source a simplified version of the Target (specifically, S=Coil-binary, with T=Coil): the source should encode the factors not related to RGB, while the finetuning should improve the disentanglement and the explicitness of the representation. However, this is not the case with Coil100, whose representations degrade the Modularity, and the finetuning only affects the entire representation.

We then consider a larger variation between Real Source and Real Target (specifically, S=Coil with T=RGBD-Object, see Table 5): we obtain similar results to those of Color-dSprites as Source Dataset (comparable Explicitness), with a reduction on the performances obtained by the pruned representation. Notice that adopting the binary Coil as a Source causes only a limited reduction in Explicitness, and this was somewhat unexpected as we have a large gap in complexity between Source and Target. Our experiments did not consider RGBD-Objects acting as a Source dataset, not being DRL-compliant.

Discussion. Using a real DRL-compliant dataset as a Source, we do not appreciate any benefit. Fine-tuning is not particularly effective. At the same time, we notice that some level of disentanglement transfer can be observed.

## 4 Limitations

A limitation of our current work is the adoption of a specific family of approaches (VAE-based). The generalization of our finding to more recent vector-based approaches (e.g. [71; 62; 48; 36]) needs further investigation. However, each family of approaches for disentanglement learning _follows specific paradigms that may require tailored designs for transfer learning_. In other words, while the general transfer methodology is still applicable, it might need proper tuning to perform optimally depending on the particular learning approach.

## 5 Conclusions

In this paper, we discussed the potential of transferring a Disentangled Representation as a strategy to address disentanglement in real data. We learned the representation from a Source Dataset in a weakly supervised manner and transfered it to a Target Dataset, where supervision on the FoVs was difficult or impossible to obtain. We identified three main scientific questions, summarised in Section 3.2, which we recall to draw conclusions on our study. Starting from question **Q2**, on the properties of disentangled representations that are preserved after transferring, we may conclude Explicitness is usually well maintained, while Modularity and Compactness are reduced as we move from synthetic to real. More precisely, we appreciate a degradation in the global metrics (such as OS and ME), while on the compactness through the analysis of the 1-dimensional pruned representations, we notice that some FoV may transfer very well.

As for **Q3**, we may observe that fine-tuning is almost always beneficial, and it never causes any harm. **Q1**, a much wider question discussing under what circumstances transfer is effective, leads us to conclude that some structural similarity between Source and Target datasets is necessary, including similar ranges/granularity of variations of related factors. A quantification of the similarity among datasets is still under investigation; _the results of our study suggest one could design synthetic data to capture/disentangle specific factors of interest_.

Future directions. Currently, we are exploring quantitative methods to assess the distance between Source and Target datasets. In the near future will target more specific applications, such as biomedical image classification or action recognition from videos, to discuss and relate the general results we are reporting in this paper to more specific and challenging domains.