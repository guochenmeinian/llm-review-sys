# Learning and Collusion in Multi-unit Auctions+

Footnote â€ : Authors are listed in alphabetical order. This work was done in part while the authors were visiting the Simons Institute for the Theory of Computing. Simina was supported in part by NSF CAREER grant CCF-2238372.

Simina Branzei

Purdue University

Mahsa Derakhshan

Northeastern University

Negin Golrezaei

MIT

Yanjun Han

New York University

###### Abstract

In a carbon auction, licenses for CO2 emissions are allocated among multiple interested players. Inspired by this setting, we consider repeated multi-unit auctions with uniform pricing, which are widely used in practice. Our contribution is to analyze these auctions in both the offline and online settings, by designing efficient bidding algorithms with low regret and giving regret lower bounds. We also analyze the quality of the equilibria in two main variants of the auction, finding that one variant is susceptible to collusion among the bidders while the other is not.

## 1 Introduction

In a multi-unit auction, a seller brings multiple identical units of a good to a group of players (buyers) interested in purchasing the items. Due to the complexity and depth of the model, the multi-unit auction has been explored in a significant volume of research  and recommended as a lens to the entire field of algorithmic mechanism design . The prior literature has often focused on understanding the equilibria of the auction under various solution concepts and designing revenue or welfare maximizing one-shot mechanisms.

We consider the setting where each player \(i\) has a value \(v_{i,j}\) for receiving a \(j\)-th unit in their bundle, which is reported to the auctioneer in the form of a bid \(b_{i,j}\). After receiving the bids, the auctioneer computes a price \(p\) per unit, then sorts the bids in descending order and allocates the \(j\)-th unit to the player that submitted the \(j\)-th highest bid, charging them \(p\) for the unit. The price \(p\) is set so that all units are sold and the resulting allocation has the property that each player gets their favorite bundle given their preferences.

This allocation rule represents the well-known _Walrasian mechanism_ in the multi-unit setting: compute the market (aka competitive or Walrasian) equilibrium with respect to the reported valuations. The template for the mechanism is: elicit the valuations from the buyers and then assign a set of prices to the goods such that when each buyer takes their favorite bundle of goods at the given prices, the market clears, i.e. all goods are sold and there is no excessive demand for any good (see, e.g., ). Due to the strong fairness and efficiency properties of the market equilibrium, the resulting allocation is envy-free with respect to the reported valuations. A strand of research concentrated on achieving fair pricing in auctions, which often involves setting uniform prices for identical units .

Repeated auctions take place in many real world settings, such as when allocating licenses for carbon (CO2 emissions) , ads on online platforms , U.S. Treasury notes to investors or trade exchanges over the internet . Repeated mechanisms often give rise to complex patterns of behavior. For example, the bidders may use the past transaction prices as a way of discovering the valuations of the competing bidders, or engage in collusion using bid rotation

[MISSING_PAGE_FAIL:2]

**Example 1**.: _Let \(K=3\) and \(n=2\). Suppose the valuations are \(_{1}=(5,2)\) and \(_{2}=(4,1)\). If the players submit bids \(_{1}=(2,1)\) and \(_{2}=(3,2)\), the bid are sorted in the order \((b_{2,1},b_{1,1},b_{2,2},b_{1,2})\). Then the allocation is \(x_{1}=1\) and \(x_{2}=2\)._

* _Under the_ \(K\)_-th price auction, the price is set to_ \(p=b_{2,2}=2\)_. The utilities of the players are_ \(u_{1}()=V_{1}(1)-p=5-2=3\) _and_ \(u_{2}()=V_{2}(2)-2 p=(4+1)-2 2=1\)_._
* _Under the_ \((K+1)\)_-st price auction, the price is set to_ \(p=b_{1,2}=1\)_. The utilities of the players are_ \(u_{1}()=V_{1}(1)-p=5-1=4\) _and_ \(u_{2}()=V_{2}(2)-2 p=(4+1)-2 1=3\)_._

**Repeated setting.** We consider a repeated setting, where the auction is run multiple times among the same set of players, who can adjust their bids based on the outcomes from previous rounds.

Formally, in each round \(t=1,2,,T\), the next steps take place:

* The auctioneer announces \(K\) units for sale. Each player \(i[n]\) submits bid vector \(^{t}_{i}=(b^{t}_{i,1},,b^{t}_{i,K})\) privately to the auctioneer, where \(b^{t}_{i,j}\) is player \(i\)'s bid for a \(j\)-th unit at time \(t\). Then the auctioneer runs the auction with bids \(^{t}=(^{t}_{1},,^{t}_{n})\) and reveals information (feedback) about the outcome to the players. We consider two feedback models for the information revealed at the end of round \(t\):
* _Full information:_ All the bids \(^{t}\) are public knowledge.
* _Bandit feedback:_ The price \(p(^{t})\) is the only public knowledge; additionally, each player \(i\) privately learns their own allocation \(x_{i}(^{t})\).

Thus the allocation at time \(t\) solely depends on the bids submitted by players in round \(t\), excluding any prior rounds. 3

### Our Results

The next sections summarize our results for both the \(K\)-th and \((K+1)\)-st price variants.

#### 1.2.1 Offline Setting

In the offline setting, we are given a player \(i\) with valuation \(_{i}\) and a history \(H_{-i}=(^{1}_{-i},,^{T}_{-i})\) containing the bids submitted by the other players in past auctions. Here we restrict the bidding space to a discrete domain \(=\{k k\}\), for some \(>0\).

The goal is to find a fixed bid vector \(^{*}_{i}=(b^{*}_{i,1},,b^{*}_{i,K})\) that maximizes player \(i\)'s cumulative utility on the data set given by the history \(H_{-i}\), that is, \(^{*}_{i}=_{^{K}}\ _{t=1}^{T}u_{i}( ,^{t}_{-i})\,.\)

The offline problem is challenging because the decision (bid) space is exponentially large and hence naively experimenting with every possible bid vector leads to impractical algorithms.

We overcome this challenge by relying on the structural properties of the offline problem. At a high level, we carefully design a weighted directed acyclic graph (DAG) and identify a bijective map between paths from source to sink in the graph and bid profiles of player \(i\). Since a maximum weight path in a DAG can be found in polynomial time, this yields a polynomial time algorithm for computing an optimum bid vector.

**Theorem 1** (informal).: _Computing an optimum bid vector for one player in the offline setting is equivalent to finding a maximum-weight path in a DAG and can be solved in polynomial time._

Theorem 1 applies to both versions of the auction, with \(K\)-th and \((K+1)\)-st highest price.

#### 1.2.2 Online Setting

In the online setting, the players run learning algorithms to update their bids as they participate in the auction over time. The first scenario we consider is that of full information feedback, where at the end of each round \(t\) the auctioneer makes public all the bids \(^{t}\) submitted in that round.

Building on the offline analysis, we design an efficient online learning algorithm for bidding, which guarantees low regret for each player using it. The main idea is to run multiplicative weight updates, where the experts are paths in the DAG from the offline setting. Each such path corresponds to a bid profile for the learner. A challenge is that the number of paths in the graph (and so experts) is exponential. Nevertheless, we can achieve a polynomial runtime by representing the experts implicitly, using a type of weight pushing algorithm based on the method of path kernels .

**Theorem 2** (Full information feedback, upper bound).: _For each player \(i\) and time horizon \(T\), there is an algorithm for bidding in the repeated auction with full information feedback that runs in time \(O(T^{2})\) and guarantees the player's regret is bounded by \(O(v_{i,1} T})\)._

To the best of our knowledge, our paper is the first to connect the path kernel setting with auctions and obtain efficient algorithms for learning in auctions via this connection.

We also consider bandit feedback, which limits the amount of information the players learn about each other: at the end of each round the auctioneer announces publicly only the resulting price, and then privately tells each player their allocation. Bandit feedback could be relevant for reducing the amount of collusion among the players in repeated auction environments .

**Theorem 3** (Bandit feedback, upper bound).: _For each player \(i\) and time horizon \(T\), there is an algorithm for bidding in the repeated auction with bandit feedback that runs in \(O(KT+K^{-5/4}T^{7/4})\) and guarantees the player's regret is bounded by \(O(v_{i,1}\{K^{7} T},KT\})\)._

Although our bidding policy is similar to the EXP3-type algorithm in , and our computational efficiency relies on the path kernel methods in , a major difference is that our edge weights are _heterogeneous_, i.e. the weights of different edges could be of different scales. To circumvent this issue, we need to use a different estimator for the weight under bandit feedback which in turn also changes the technical analysis.

We complement the upper bounds with the following regret lower bound, where the construction of the hard instance relies heavily on the specific structure of our auction format.

**Theorem 4** (Lower bound, full information and bandit feedback).: _Let \(K 2\). Suppose the auction is run for \(T\) rounds. Then for each strategy of player \(i\), under both full information and bandit feedback, there exists a bid sequence \(\{_{t-i}^{T}\}_{t=1}^{T}\) by the other players such that the expected regret of player \(i\) is at least \(c v_{i,1}K\), where \(c>0\) is an absolute constant._

Theorems 2, 3, and 4 apply to both variants of the auction (with \(K\)-th and \((K+1)\)-st highest price).

#### 1.2.3 Equilibrium Analysis

We also analyze the quality of the Nash equilibria reached in the worst case in the static version of the auction, as they naturally apply to the empirical distribution of joint actions when the players use sub-linear regret learning algorithms.

The \((K+1)\)-st price auction has been observed to have low or even zero revenue equilibria . With \(n>K\) hungry players, the next phenomena occur:

* _in the \((K+1)\)-st price auction:_ every allocation \(\) that allocates all the units can be implemented in a pure Nash equilibrium \(\) with price \(\), for every small enough \( 0\).
* _in the \(K\)-th price auction:_ no pure Nash equilibrium with arbitrarily low price exists.

Our contribution is to show that the zero-price equilibria of the \((K+1)\)-st highest price auction are very stable. We do this by considering the core solution concept, which models how groups of players can coordinate.

In our setting, a strategy profile is _core-stable_ if no group \(S\) of players can deviate by simultaneously changing their strategies such that each player in \(S\) weakly improves their utility _and_ the improvement is strict for at least one player in \(S\). The players outside \(S\) are assumed to have neutral reactions to the deviation, that is, they keep their strategy profiles unchanged. This is consistent with the Nash equilibrium solution concept, where only the deviating player changes their strategy.

A body of literature studied the core in auctions when the auctioneer can collude together with the bidders (see, e.g., ). However, as is standard in mechanism design, it is also meaningful to consider the scenario where the auctioneer sets the auction format and then the bidders can strategize and potentially collude among themselves, without the auctioneer; this setting is our focus.

First, we consider the core without transfers, where a strategy profile is simply a bid profile \(\).

**Theorem 5** (Core without transfers).: _Consider \(K\) units and \(n>K\) hungry players. The core without transfers of the \((K+1)\)-st auction can be characterized as follows:_

* _every bid profile_ \(\) _that is core-stable has price zero (i.e._ \(p()=0\)_);_
* _for every allocation_ \(\)_, there is a core-stable bid profile_ \(\) _with price zero that implements_ \(\) _(i.e._ \(()=\) _and_ \(p()=0\)_)._

If a bid profile \(\) is core-stable, then it is also a Nash equilibrium, for the simple reason that if no group of players can deviate simultaneously from \(\), then the group consisting of one player cannot find an improving deviation either. Thus Theorem 5 says that the equilibria with price zero are the only ones that remain stable when also allowing deviations by groups of players. Moreover, the theorem also says there are many inefficient core-stable equilibria, all with price zero.

Second, we also consider the core with transfers, where the players can make monetary transfers to each other. A strategy profile in this setting is given by a pair \((,)\), where \(\) is a bid profile and \(\) is a profile of monetary transfers, such that \(t_{i,j} 0\) is the monetary transfer (payment) of player \(i\) to player \(j\) (e.g., player \(i\) could pay player \(j\) so that \(j\) keeps its bids low).

**Theorem 6** (Core with transfers).: _Consider \(K\) units and \(n>K\) hungry players. The core with transfers of the \((K+1)\)-st auction can be characterized as follows._

* _Let_ \((,)\) _be an arbitrary tuple of bids and transfers that is core stable. Then the allocation_ \(()\) _maximizes social welfare, the price is zero (i.e._ \(p()=0\)_), and there are no transfers between the players (i.e._ \(=0\)_)._

To see why Theorem 6 holds, if the price is positive at some strategy profile, the players with "highest values" can pay the other players to lower their bids. When the price reaches zero, they can start withdrawing the payments. Thus the only strategy profiles in the core with transfers are those where the players with "highest values" win and pay zero. The difference from Theorem 5 is that transfers allow the players with highest values to force getting their desired items at price zero, which they cannot enforce without transfers. Nevertheless, even without transfers, the price remains zero.

Remarks on collusion.Given that the zero price equilibria of the \((K+1)\)-st price auction are very stable and easy to find, one can expect they can be determined by the bidders, for example in settings with few bidders who know each other. These equilibria can be easily implemented in repeated settings once the bidders agree on their strategies.

Strikingly, these zero price equilibria have in fact been observed empirically in repeated auctions for fishing quotas in the Faroe Islands, where even inexperienced bidders were able to collude and enforce them; see details in . In the carbon setting, the Northeast US auction is based on the \((K+1)\)-st price format  and has very low prices as well.

In contrast, the \(K\)-th price auction format does not have any Nash equilibria with price zero, let alone core-stable ones. Thus the \(K\)-th price auction format may be preferable to the \((K+1)\)-st price auction in settings with high stakes, such as selling rights for carbon emissions. Another remedy, also discussed in , is to make the number of units a random variable.

## 2 Related Work

Our work is related to the rich literature on combinatorial auctions (e.g., ) and more specifically auctions for identical goods, which are widely used in practice in various settings: Treasury Auctions , Procurement Auctions , Wholesale Electricity Markets , Carbon Auctions . The two most prevalent multi-unit auctions are uniform price auctions and pay-as-bid auctions that are widely studied in the literature either empirically (e.g., ) or theoretically under the classical Bayesian setting (e.g., ). In particular, there have been several studies that aim to compare uniform price auctions versus pay-as-bid auctions (e.g.,) in terms of revenue and welfare under Nash equilibria, and the possibility of collusion. Our work contributes to this literature by studying uniform price auctions the angle of designing bidding algorithms for the players.

Designing learning algorithms in auctions has attracted significant attention in recent years. Several papers study the problem of designing learning/bandit algorithms to optimize reserve prices in auctions over time (e.g., ). There are papers that have focused on designing bandit algorithms to optimize bidding strategies in single-unit second price and first price auctions (e.g., ). Prior to our work, such problem was not studied for multi-unit uniform-price auctions.

Leveraging structural information in designing bandit algorithms has been the topic of the rich literature, which includes linear reward structures , Lipschitz reward structures , convex reward distribution structure , and combinatorial structures . Our work is closest to the works that aim to exploit combinatorial structures. Within this literature, several papers leverage DP-based or MDP-based structures (e.g., ).

The multi-unit auction setting was studied in a large body of literature on auctions , where the focus has been on designing truthful auctions with good approximations to some desired objective, such as the social welfare or the revenue.

Uniform pricing represents a type of fair pricing, since when everyone gets charged the same price per unit, no bidder envies another bidder's allocation. Fairness is an important property that is at odds with maximizing revenue, since for the purpose of improving revenue the auctioneer is better off charging higher prices to the buyers that show more interest in the goods. However, there is evidence that buyers are unhappy with discriminatory prices (see, e.g., ), which led to a body of literature focused on designing fair auction mechanisms . Collusion in auctions was also studied both experimentally and theoretically in various models (e.g., ).

## 3 Offline Setting

In the offline setting, we are given a player \(i\) with valuation \(_{i}\) and a history \(H_{-i}=(_{-i}^{1},,_{-i}^{T})\) with the bids of other players in rounds \(1\) through \(T\). We assume the bids are restricted to a discrete domain \(=\{k k\}\), for some \(>0\). The goal is to find an optimum fixed bid vector in hindsight: \(_{i}^{*}=_{^{K}}_{t=1}^{T}u _{i}(,_{-i}^{t}),\) where we recall that \(u_{i}(,_{-i}^{t})\) is the utility of player \(i\) at the bid profile \((,_{-i}^{t})\). We will see the maximum in the definition of \(_{i}^{*}\) is well defined since there is an optimum bid vector \(\) with entries at most \(\) above the maximum historical bid.

For any \(>0\), the optimal solution on the discrete domain \(\) also yields an \(( K)\)-optimal strategy on the continuous domain. The offline problem we study here has some resemblance to the problems studied in . There, the goal is to optimize reserve prices in VCG auctions while having access to a dataset of historical bids.4

To design a polynomial time algorithm for solving the offline problem, we define a set \(_{i}\) of "candidate" bids for player \(i\), which has polynomial size in the history, player \(i\)'s valuation, and \(1/\):

\[_{i}=\{0\}\{b_{j,k}^{t} j[n]\{ i\},k[K]\}\{b_{j,k}^{t}+ j[n]\{i\},k [K]\}. \]

**Observation 1**.: _Player \(i\) has an optimum bid vector \(=(_{1},,_{K})^{K}\) with \(_{j}_{i}\) for all \(j[K]\), where \(_{i}\) is defined in equation (1)._

The proof of Observation 1 is simple and deferred to Appendix A. Next we construct a directed acyclic graph (DAG) \(G_{i}\) that will be used to compute an optimum bid vector for player \(i\).

**Definition 1** (The graph \(G_{i}\)).: _Given valuation \(_{i}\) of a player \(i\), history \(H_{-i}=(_{-i}^{1},,_{-i}^{T})\), \(>0\), and set \(_{i}\) from (1), define a graph \(G_{i}\) with the following features._

**Vertices**.: _Create a vertex_ \(z_{s,j}\) _for each_ \(s_{i}\) _and_ \(j[K]\)_. We say vertex_ \(z_{s,j}\) _is in layer_ \(j\)_. Add source_ \(z_{-}\) _and sink_ \(z_{+}\)_._
**Edges**.: _For each index_ \(j[K-1]\) _and pair of bids_ \(r,s_{i}\) _with_ \(r s\)_, create a directed edge from vertex_ \(z_{r,j}\) _to vertex_ \(z_{s,j+1}\)_. Moreover, add edges from source_ \(z_{-}\) _to each node in layer_ \(1\) _and from each node in layer_ \(K\) _to the sink_ \(z_{+}\)_._
**Edge weights**.: _For each edge_ \(e=(z_{r,j},z_{s,j+1})\) _or_ \(e=(z_{r,K},z_{+})\)_, let_ \(=(_{1},,_{K})_{i}^{K}\) _be a bid vector with_ \(_{j}=r\) _and_ \(_{j+1}=s\) _(we define_ \(s=0\) _if_ \(j=K\)_). For each_ \(t[T]\)_, let_ \(^{t}=(,^{t}_{-i})\)_. Define the weight of edge_ \(e\) _as_

\[w_{e}=_{t=1}^{T}_{\{z_{i}:(^{t}) j\}} (v_{i,j}-r)+j_{\{z_{i}(^{t})>j\}}(r -s)+_{\{z_{i}(^{t})=j\}}(r-p(^{t}) ),\] (2) _recalling that_ \[p(^{t})\] _and_ \[(^{t})\] _are the price and allocation at_ \[^{t}\] _, respectively_ 5_. The edges incoming from_ \[z_{-}\] _have weight zero._ 
A pictorial illustration of the graph \(G_{i}\) is displayed in Figure 1.

At a first glance, it may seem as though the weight \(w_{e}\) of an edge \(e\) depends on the whole bid vector \(\) since we use the value of \(x_{i}(^{t})\) in its definition. However, this is not the case. Meaning that, this formula gives us the same value for any choice of \(\) that satisfies \(_{j}=r\) and \(_{j+1}=s\). This is due to the fact that the values of variables \(_{\{x_{i}(^{t})\}}\), \(_{\{x_{i}(^{t})>j\}}\), and \(_{\{x_{i}(^{t})=j\}}\) can be determined only knowing the values of \(_{j+1}\) and \(_{j}\) (without knowing the rest of the vector \(\)).

We will show that computing an optimum strategy for the player is equivalent to finding a maximum-weight path in the DAG \(G_{i}\) from Definition 1.

**Theorem 1** (formal version).: _Suppose we are given a number \(n\) of players, number \(K\) of units, valuation \(_{i}\) of player \(i\), discretization level \(>0\), and bid history \(H_{-i}=(^{1}_{-i},,^{T}_{-i})\) by players other than \(i\). Then an optimum bid vector for player \(i\) can be computed in polynomial time in the input parameters._

The proof of Theorem 1 is in Appendix A, together with the other omitted proofs of this section.

At a high level, for any bid vector \(\), we first write the cumulative utility of player \(i\) when playing \(\) while the others play according to \(^{t}_{-i}\). Then observe the cummulative utility can be rewritten as a sum of \(K\) terms, so that each term only depends on \(j\), \(_{j}\), and \(_{j+1}\). Create a layered DAG as in Definition 1, where the weight of edge \((_{j},j)\) to \((_{j+1},j+1)\) is the \(j\)-th term of the sum above, with special handling for edges involving the source or the sink. The entire graph can be computed in polynomial time.

Then the proof shows there is a bijection between the set of bid vectors of the player and the set of paths from the source to the sink in the graph. Thus the solution to the offline problem is obtained by computing a maximum weight path in the graph and returning the corresponding bid vector.

The algorithm for the offline problem is summarized in the next figure.

Figure 1: Example of DAG as in Definition 1. Here, we have \(K=4\) units and the set of candidate bids for player \(i\) is \(_{i}=\{0,1,2\}\). The graph has a source \(z_{-}\), a sink \(z_{+}\), and nodes \(z_{r,j}\) for all \(r_{i}\) and \(j\). Edges are of the form \((z_{r,j},z_{s,j+1})\) for all \(j<4\) and \(r,s_{i}\) with \(r s\). There are also edges from the source \(z_{-}\) to nodes \(z_{j,1}\) and from nodes \(z_{j,4}\) to the sink \(z_{+}\)\(\)\(j_{i}\).

**Input:** Player \(i\) with valuation \(_{i}=(v_{i,1},,v_{i,K})\), a history \(H_{-i}=(^{1}_{-i},,^{T}_{-i})\) of bids submitted by players other than \(i\), and a grid \(=\{k k\}\) with allowed bid values.

**Output:**\(^{*}_{i}=_{^{K}}_{t=1}^{T}u_{ i}(,^{t}_{-i})\).

* Compute set \(_{i}\) as defined in equation (1). By Observation 1, player \(i\) has an optimum bid vector \(^{*}_{i}\) with \(b^{*}_{i,j}_{i}\) for each \(j[K]\).
* Construct directed acyclic graph \(G_{i}\) as in Definition 1. By Theorem 1, there is a bijective map between paths from the source to the sink in \(G_{i}\) and bid vectors \(_{i}\) of player \(i\).
* Compute a maximum-weight path in graph \(G_{i}\) and output the corresponding bid vector.

```
algorithm1: Optimum Strategy for the Offline Problem.
```

## 4 Online Setting

In the online setting, we consider the repeated auction where in each round \(t\) the auctioneer announces \(K\) units for sale. Then the players privately submit the bids \(^{t}\) and the auctioneer computes the outcome. At the end of round \(t\), the auctioneer gives _full information_ or _bandit_ feedback. The information available to player \(i\) at the beginning of each round \(t\) is the history:

\(H^{t-1}_{i}=(^{1}_{i},,^{t-1}_{i}) H^{t-1}_{-i}\), where 6

\[H^{t-1}_{-i}=^{1}_{-i},,^{t-1}_{ -i}&,\\ p(^{1}),,p(^{t-1})&. \]

A pure _strategy_ for player \(i\) at time \(t\) is a function \(^{t}_{i}:H^{t-1}_{i}^{K}\), where \(H^{t-1}_{i}\) is the history available to player \(i\) at the beginning of round \(t\). Thus the pure strategy tells player \(i\) what bid vector to submit next given the information observed by the player about the previous rounds. A mixed strategy is a probability distribution over the set of pure strategies. Consequently, the bid vector \(^{t}_{i}\) submitted by player \(i\) at time \(t\) is the realization of the mixed strategy \(^{t}_{i}(H^{t-1}_{i})\). We denote by \(_{i}=(^{1}_{i},,^{T}_{i})\) the overall strategy of player \(i\) over the entire time horizon.

Regret.From now on we fix an arbitrary player \(i\). Given a bidding strategy \(_{i}\) of player \(i\), the regret of the player is defined with respect to a history \(H^{T}_{-i}\) of bids by other players:

\[_{i}(_{i},H^{T}_{-i})=_{ ^{K}_{i}} _{t=1}^{T}_{j=1}^{K}v_{i,j}-p(, ^{t}_{-i})_{\{x_{i}(, ^{t}_{-i}) j\}}\] \[-_{t=1}^{T}_{^{t}_{i}^{t}_{i}(H^{t- 1}_{i})}[_{j=1}^{K}v_{i,j}-p(^{t}) _{\{x_{i}(^{t}) j\}}]\,. \]

For the purpose of equipping player \(i\) with a bidding algorithm, we will think of the other players as adversarial, and aim to achieve small regret regardless of \(H^{T}_{-i}\). A way to interpret the regret is that player \(i\) is competing against an oracle that (a) has the perfect knowledge of the history of bids, but (b) is restricted to submit a time-invariant bid \(\). The regret quantifies how much worse player \(i\) does compared to the oracle.

Before studying the feedback models in greater detail, we replace the set \(_{i}\) of candidate bids for player \(i\) from equation (1) of the offline section by a coarser set \(_{}=\{,2,, v_{i,1}/ \}\).

### Full information

In the full information scenario, at the end of each round \(t\) the auctioneer announces the bids \(^{t}\) submitted by the players in round \(t\). We define a graph \(G^{t}\) that forms the basis of the learningalgorithm for the player. The graph \(G^{t}\) is the same as in the offline setting (Definition 1), except for the next differences:

* The vertex \(z_{s,j}\) is indexed by \(s_{e}\), instead of \(_{i}\);
* The edge weights are based only on the current round \(t\), rather than the sum over all rounds in the offline setting. More specifically, for edge \(e=(z_{r,j},z_{s,j+1})\) or \(e=(z_{r,K},z_{+})\), set \[w^{t}(e)=_{\{x_{i}(^{t}) j\}}(v_{i,j}-r)+j _{\{x_{i}(^{t})>j\}}(r-s)+_{ \{x_{i}(^{t})=j\}}(r-p(^{t}))\,.\] (4) The formal definition is deferred to Definition 2 in Appendix B. This DAG structure enables us to formulate the learning problem as an online maximum weight path problem, and therefore treat each path as an expert and apply online learning algorithms to compete with the best expert. Theorem 2 shows such an algorithm (Algorithm 2) works for both \(K\)-th and \((K+1)\)-st price auctions.

```
Input: time horizon \(T\), valuation \(_{i}=(v_{i,1},,v_{i,K})\) of the player \(i\) Output: bid vectors \((^{t}_{i},,^{T}_{i})\).  Set the resolution parameter \(=v_{i,1}\), and learning rate \(=/(v_{i,1})\). For every \(t=1,,T\): * Construct a graph \(G^{t}\) as in Definition 2, initially without weights on the edges. * If \(t=1\): for each edge \(e\), initialize an edge probability as \[^{1}(e)=1/|_{e}|&e=(z_{-},z_{r,1});\\ 1/|\{r^{}_{e} r^{} r\}|&e=(z_{r,j},z_{s,j+1}),r  s;\\ 1&e=(z_{r,K},z_{+}).\] * If \(t 2\): * starting from \(^{t-1}(z_{+})=1\), recursively compute in the bottom-up order \[^{t-1}(u)=_{v:e=(u,v) E}^{t-1}(e)( w^{t-1}( e))^{t-1}(v), u V(G^{t});\] * for each edge \(e\), update the edge probability \[^{t}(e)=^{t-1}(e)( w^{t-1}(e)) {^{t-1}(v)}{^{t-1}(u)},e=(u,v) E(G^{t})\,.\] (5) * For \(j=1,2,,K\): sample \(b^{t}_{i,j}^{t}(z_{b^{t}_{i,j-1},j-1},)\), where \(z_{b^{t}_{i,0},0}:=z_{-}\). * The player observes \(^{t}_{-i}\), and sets the edge weights \(w^{t}(e)\) in \(G^{t}\) according to (4).
```

### Bandit feedback

The next theorem presents an upper bound on the regret under the bandit feedback. Similar to the full-information case, the algorithm we design works for both the \(K\)-th and \((K+1)\)-st price auctions.

**Theorem 3**.: _For each player \(i\) and time horizon \(T,\) there is an algorithm for bidding in the repeated auction with bandit feedback that runs in \(O(KT+K^{-5/4}T^{7/4})\) and guarantees the player's regret is bounded by \(O(v_{i,1}\{K^{7} T},KT\})\)._

We describe the algorithm below, while the proof of the theorem can be found in Appendix B.

The bidding strategy and its efficient implementation are the same as those in the proof of Theorem 2, with the only difference as follows. Under bandit feedback, we are not able to compute \(w^{t}(e)\) for every edge \(e\) at the end of time \(t\); instead, we are able to compute \(w^{t}(e)\) for every edge on the chosen path \(^{t}\) at time \(t\). This observation motivates us to use the next unbiased estimator \(^{t}(e)\):

\[^{t}(e)=(e)-(e)-w^{t}(e)}{p^{t}(e)} _{\{e^{t}\}},p^{t}(e)=_{:e }P^{t}(), \]

where \(P^{t}\) is the player's action distribution over paths, and for each edge \(e\):

\[(e)=v_{i,1}-r+j(r-s)&e=(z_{r,j},z_{s,j+1}); \\ v_{i,1}-r+Kr&e=(z_{r,K},z_{+});\\ 0&e=(z_{-},z_{r,1}).\]

The resulting algorithm is exactly the same as Algorithm 2, with the only difference being that all \(w^{t}\) are replaced by \(^{t}\), with an additional step (6) for the computation of \(^{t}\).

The regret analysis will appear similar to that in , but a key difference is that we no longer have \(w^{t}(e) v_{i,1}\) for every edge \(e\) in our setting. Instead, we apply an edge-dependent upper bound \(w^{t}(e)(e)\), and use the property that \(_{e}(e) Kv_{i,1}\) for every path \(\) from source to sink.

### Regret lower bounds

The following theorem establishes an \((K)\) lower bound on the minimax regret of a single bidder in the full information scenario. Clearly the same lower bound also holds for bandit feedback.

**Theorem 4** (restated, formal).: _Let \(K 2\). For any policy \(_{i}\) used by player \(i\), there exists a bid sequence \(\{^{t}_{-i}\}_{t=1}^{T}\) for the other players such that the expected regret in (3) satisfies \([_{i}(_{i},\{^{t}_{-i}\}_{t=1}^{T}) ] cv_{i,1}K,\) where \(c>0\) is an absolute constant._

The proof of Theorem 4 is in Appendix B. The idea is to employ the celebrated Le Cam's two-point method, but the construction of the hard instance is rather delicate to reflect the regret dependence on \(K\). We also remark that this regret lower bound still exhibits a gap compared with the current upper bound in Theorem 2, while it seems hard to extend the current two-point construction to Fano-type lower bound arguments. It is an outstanding question to close this gap.

## 5 Concluding Remarks

Several open questions arise from this work. For example, is the regret \((K)\) in both the full information and bandit setting? In the full information setting, the challenge in obtaining an algorithm with regret \(O(K)\) is that the expert distribution is not a product distribution over the layers, but rather only close to a product. Furthermore, how does offline and online learning take place in repeated auctions when the units are not identical, the valuations do not necessarily exhibit diminishing returns, or the pricing rule is different (e.g. in the first price setting)?