# Improving Robustness of 3D Point Cloud Recognition from a Fourier Perspective

Yibo Miao\({}^{1,2}\), Yinpeng Dong\({}^{3,6}\), Jinlai Zhang\({}^{4}\), Lijia Yu\({}^{5}\), Xiao Yang\({}^{3}\), Xiao-Shan Gao\({}^{1,2}\)

\({}^{1}\) KLMM, Academy of Mathematics and Systems Science,

Chinese Academy of Sciences, Beijing 100190, China

\({}^{2}\) University of Chinese Academy of Sciences, Beijing 100049, China

\({}^{3}\) Tsinghua University, Beijing 100084, China

\({}^{4}\) Changsha University of Science and Technology, Changsha 410114, China

\({}^{5}\) Institute of Software, Chinese Academy of Sciences, Beijing 100190, China \({}^{6}\) RealAI

miaoyibo@amss.ac.cn, dongyinpeng@tsinghua.edu.cn, xgao@mmrc.iss.ac.cn

Corresponding authors.

###### Abstract

Although 3D point cloud recognition has achieved substantial progress on standard benchmarks, the typical models are vulnerable to point cloud corruptions, leading to security threats in real-world applications. To improve the corruption robustness, various data augmentation methods have been studied, but they are mainly limited to the spatial domain. As the point cloud has low information density and significant spatial redundancy, it is challenging to analyze the effects of corruptions. In this paper, we focus on the frequency domain to observe the underlying structure of point clouds and their corruptions. Through graph Fourier transform (GFT), we observe a correlation between the corruption robustness of point cloud recognition models and their sensitivity to different frequency bands, which is measured by the GFT spectrum of the model's Jacobian matrix. To reduce the sensitivity and improve the corruption robustness, we propose Frequency Adversarial Training (FAT) that adopts frequency-domain adversarial examples as data augmentation to train robust point cloud recognition models against corruptions. Theoretically, we provide a guarantee of FAT on its out-of-distribution generalization performance. Empirically, we conducted extensive experiments with various network architectures to validate the effectiveness of FAT, which achieves the new state-of-the-art results.

## 1 Introduction

3D point cloud recognition based on deep neural networks (DNNs)  has achieved unprecedented performance on typical benchmarks , which assume that the data are independently and identically distributed. However, in practical scenarios, point clouds suffer from severe corruptions (e.g., noise, density change, transformation) due to sensor imprecision and scene complexity . When the testing distribution is different from the training distribution caused by corruption, point cloud recognition models have significant performance degradation , indicating that they lack the robustness of human visual system , while also raising concerns about safety and reliability of these models. As deep 3D point cloud recognition has been increasingly deployed in safety-critical applications, such as autonomous driving , robotics , and medical image processing , it is of crucial importance to improve the robustness of 3D point cloud recognition models to out-of-distribution (OOD) point cloud data induced by corruptions .

To improve the corruption robustness, the most effective approaches to date are based on carefully designed data augmentation techniques [41; 51]. Inspired by 2D image augmentations [85; 89], some methods blend two point clouds for data augmentation using shortest-path interpolation (e.g., PointMixup ), random blending (e.g., PointCutMix-R ), and rigid transformation (e.g., RSMix , PointCutMix-K ). PointWOLF  enriches data diversity by applying non-rigid deformation to object parts. WOLFMix  deforms objects first and then rigidly blends two deformed objects. Although these data augmentation techniques improve the corruption robustness to some extent, they are all based on spatial-domain transformations. Raw point clouds in the spatial domain have low information density and heavy spatial redundancy , making it challenging to analyze which specific information is corrupted. To address this challenge, we shift our attention from the spatial domain to the frequency domain to analyze the underlying structure of point clouds that is not easily observable from the raw point clouds. In the frequency domain, point clouds are compactly represented, facilitating a better understanding of low-level distortions that are free of high-level semantics.

To design robust models, the first step is to understand how corruption is represented in the frequency domain. We achieve this by transforming the raw point clouds and the corresponding corruptions into compact representations in the frequency domain using the graph Fourier transform (GFT) . By visualizing the transformed signals, we observe that different corruptions affect varying frequency bands, as shown in Fig. 1(a). Motivated by the differences, we investigate the relationship between the corruption robustness of various point cloud recognition models and their sensitivity to different frequency bands . To measure the sensitivity, we design **novel metric based on GFT spectrum of the Jacobian matrix** of the model, as shown in Fig. 3. Our key insight is that our proposed **high/low frequency sensitivity metric is negatively correlated with the model's robustness under high/low frequency corruptions**, as shown in Fig. 1(b). This correlation emphasizes the importance of the model's sensitivity to high and low frequencies for corruption robustness. However, it is still challenging to simultaneously reduce the sensitivity of point cloud recognition models to both high and low frequencies.

To address this issue, we propose **Frequency Adversarial Training (FAT)** to improve the corruption robustness of 3D point cloud recognition models. FAT trains a model with adversarial examples that add perturbations to the frequency-domain representations of point clouds. Intuitively, a model robust to worst-case perturbations should be more resistant to real-world corruptions [72; 80]. We provide **a theoretical analysis that demonstrates the effectiveness of FAT in ensuring OOD generalization of the model**, as shown in Theorem 1. To eliminate potential performance degradation due to mutual interference between high and low frequency signals, we utilize the AdvProp training framework , based on which we use three separate batch normalization (BN) statistics for clean samples, high-frequency adversarial samples, and low-frequency adversarial samples, respectively.

We conducted extensive experiments to validate the effectiveness of our approach in improving the robustness of point cloud recognition models under common corruptions [41; 51]. With various

Figure 1: **(a):** The graph frequency-domain representations of “Jitter” and “Rotate” in ModelNet-C . “Jitter” has higher power in the high-frequency region, while “Rotate” has higher power in the low-frequency region. **(b):** The relationship between the corruption robustness (measured by mean overall accuracy (mOA) ) of various models and the sensitivity to high/low frequency bands. Our proposed high/low frequency sensitivity metric is negatively correlated with the model’s robustness under high/low frequency corruptions.

network architectures, our method improves the corruption robustness by a large margin. By integrating our approach with previous data augmentation techniques, we achieve the new state-of-the-art performance.

## 2 Related work

**Deep learning on 3D point clouds.** Deep 3D point cloud recognition [16; 35; 38; 55; 70; 73; 79] has emerged in recent years as a prominent research area with diverse applications in several fields such as 3D object classification [46; 83; 86], 3D scene segmentation [20; 64; 75], and 3D object detection in autonomous driving [77; 95]. One of the pioneering works is PointNet , which employs a multilayer perceptron to learn point features and utilizes a max-pool module to aggregate them efficiently. Many subsequent works [13; 30; 36; 78] improve upon PointNet. Several approaches focus on designing special convolutions on 3D domains [26; 31; 56] or developing graph neural networks [14; 44; 65] to improve point cloud recognition, such as DGCNN  which builds a dynamic graph for point cloud data. Recently, drawing inspiration from research in the frequency domain [4; 49; 61; 81], GDANet  introduces a geometry-disentangle module to dynamically separate point clouds into the contour and flat parts of 3D objects, thereby capturing complementary 3D geometric semantics. PCT  uses Transformer to improve point cloud learning. Additionally, there is a growing discussion on point cloud augmentation, including mix-based augmentations [7; 90], deformation-based augmentations , and auto-augmentations .

**Robustness in 3D point cloud recognition.** Following the previous studies on robustness in the 2D image domain [53; 3; 15; 19; 32; 42; 59; 9; 82], several works [18; 50; 52; 63; 69; 34; 97] have explored the robustness of 3D point cloud classifiers. Concerning adversarial robustness, Xiang et al.  first demonstrate that point cloud recognition is vulnerable to adversarial point generation attacks. Further research [21; 28; 29; 57; 91; 2] has employed gradient-based point perturbation attacks. Some defensive techniques are proposed, such as input randomization [12; 93] and geometry-aware framework  to defend against such vulnerabilities. Sun et al. [47; 48] have studied the effectiveness of adversarial training and pre-training on self-supervised tasks in enhancing robustness. In terms of corruption robustness, some works have studied the problem using invariant feature extraction , and adaptive sampling . Recently, two benchmarks [41; 51] are developed for the robustness of 3D point cloud recognition under corruptions and demonstrate the effectiveness of data augmentation. However, unlike the existing spatial-domain data augmentation techniques [22; 25], in this paper, we focus on the frequency domain and propose Frequency Adversarial Training (FAT) to improve the model's out-of-distribution generalization ability.

## 3 Methodology

The existing 3D point cloud recognition models exhibit significant performance degradation under point cloud corruptions [41; 51]. Although data augmentation techniques have shown the effectiveness in improving robustness, they are typically based on spatial-domain transformations, which suffer from low information density and heavy spatial redundancy of the raw point clouds. Consequently, it is difficult to analyze which specific information has been lost due to corruptions within the spatial domain. To address this challenge, we shift our focus to the frequency domain, which enables us to analyze the underlying structure of point clouds.

In the following, we first provide the background knowledge of graph Fourier transform (GFT) in Sec. 3.1, then analyze the point cloud corruptions in the frequency domain in Sec. 3.2, and investigate the relationship between the model's corruption robustness and sensitivity to frequency changes in Sec. 3.3. Based on the analyses, we propose a Frequency Adversarial Training (FAT) method detailed in Sec. 3.4 with a theoretical analysis to guarantee its effectiveness in Sec. 3.5.

### Graph Fourier transform

Images are typically transformed and recovered in the frequency domain with the 2D discrete Fourier transform (DFT) and inverse DFT . Unlike images, although 3D point clouds are highly structured, they reside on irregular domains without an ordering of points, hindering the deployment of traditional Fourier transforms. However, graphs provide a natural and accurate representation of irregular point clouds. Once a graph is constructed to represent the point cloud, the graph Fourier transform (GFT)  can compactly transform it into the frequency domain.

Given a point cloud \(:=\{_{i}\}_{i=1}^{n}^{n 3}\) of \(n\) points, where \(_{i}\) denotes the xyz coordinates of a point, we construct a directed graph \(=\{,,\}\) to represent it. The graph consists of a vertex set \(\), an edge set \(\) connecting the vertices, and an adjacency matrix \(\). The entry \(w_{i,j}\) in the adjacency matrix represents the weight of the edge from vertices \(i\) to \(j\), which is used to capture the similarity between adjacent vertices. Here, we construct a weighted \(k\)-nearest neighbor graph (i.e., each vertex is only connected to its \(k\)-nearest neighbors) using the Euclidean distance \(d_{ij}=\|_{i}-_{j}\|_{2}\) between vertices \(i\) and \(j\), and the weight of the edge is \(w_{i,j}=e^{-d_{ij}^{2}}\).

After constructing the graph representation of the point cloud, we focus on the combinatorial graph Laplacian , defined as \(:=-\), where \(\) is a diagonal matrix with the \(i\)-th diagonal entry \(d_{i,i}=_{j=1}^{n}w_{i,j}\) representing the degree of the \(i\)-th node. \(\) is symmetric and positive semi-definite, and can be eigen-decomposed as \(=^{}\), where \(=[_{1},...,_{n}]\) is an orthogonal matrix containing the eigenvectors \(_{i}\), and \(=(_{1},...,_{n})\) is a diagonal matrix containing the eigenvalues. The eigenvalues are sorted in ascending order, representing frequencies from low to high. For a point cloud \(\), the graph Fourier transform (GFT) can be applied to transform it into a compact representation in the frequency domain: \(}=G():=^{}\). The low-frequency components represent the coarse shape of the point cloud, while the high-frequency components represent the fine details. The inverse graph Fourier transform (IGFT) can be used to recover the point cloud in the spatial domain as \(=G^{-1}(}):=}\).

### Analyzing point cloud corruptions in the frequency domain

We employ GFT to transform point clouds and their corruptions into compact representations in the frequency domain, allowing us to analyze the underlying structures of these low-level distortions that are hardly observable in the spatial domain. For raw point clouds, we transform them to the frequency-domain representations and calculate \(_{}[|G()|]\) by averaging over all validation point clouds in ModelNet40 . For each corruption type in ModelNet-C , we calculate \(_{}[|G(()-)|]\) similarly, where \(\) denotes the corruption function. As the input point clouds have three spatial axes \((x,y,z)\), we take the average over these channels. In Fig. 2, we visualize the graph frequency-domain representations of raw point clouds and the corruptions in ModelNet-C. We can see that the raw point clouds have higher power in the low-frequency region, while the corruption "Jitter" leads to higher power in the high-frequency region. For corruptions such as "Rotate" and "Scale", the corrupted power is concentrated more on the low-frequency components. The results demonstrate that different corruptions of point clouds affect different frequency bands.

### Relationship between corruption robustness and sensitivity to frequency bands

Motivated by the different effects of corruptions on varying frequency bands observed in the graph frequency-domain representations, we investigate the relationship between the corruption robustness of 3D point cloud recognition models and their sensitivity to different frequency bands.

Figure 2: The leftmost image displays the graph frequency-domain representation of the raw point clouds. To estimate the expected value of \(_{}[|G()|]\), we average over all validation point clouds in ModelNet40 . The frequencies are arranged from left to right in ascending order. The other seven images display the graph frequency-domain representations of each corruption in ModelNet-C . The raw point clouds exhibit higher power in the low-frequency region. The corruption “Jitter” has much higher power in the high-frequency region. The power of corruptions such as “Rotate” and “Scale” is concentrated on the low-frequency components.

To measure the sensitivity of a model on different frequency bands, we propose to perform graph Fourier transform (GFT) on the Jacobian matrix of the model's output loss with respect to its input point cloud. Intuitively, the Jacobian matrix represents how the model's output changes with small variations in its input point cloud, revealing its sensitivity to different points in the spatial domain . With GFT, we can obtain the frequency-domain representation of the Jacobian matrix, which reveals the model's sensitivity to different frequency bands of input. If a model's Jacobian matrix has a high proportion of low/high frequency components, it will be sensitive to low/high frequency bands.

Fig. 3 illustrates the computation of the frequency-domain Jacobian matrix for a single point cloud. Specifically, given an input point cloud \(\), a classification model \(h\), and a standard cross-entropy loss function \(_{h}\) for the classification task, the Jacobian matrix \(():=_{}_{h}\) of the loss with respect to the input point cloud can be calculated. We then perform GFT on \(()\) to obtain its frequency-domain representation, denoted as \(()}=^{}()\) in a compact form, using the original point cloud's neighborhood relations and feature vector matrix. Since the input point cloud has three axis channels \((x,y,z)\), we take the average of these channels and normalize the result. We measure the model's sensitivity to input perturbations in the low-frequency band by summing the squares of the amplitudes of the first \(\) frequencies of the Jacobian matrix's graph Fourier spectrum. The sensitivity to high-frequency perturbations is measured by summing the squares of the amplitudes of the remaining \(1024-\) frequencies. A higher value of the metric indicates greater sensitivity to perturbations in that frequency band.

We can now measure the importance of the sensitivity to different frequency bands of point cloud recognition models on their corruption robustness. First, we measure and establish the relationship between sensitivity to high/low frequency bands of different point cloud models and their accuracy under high/low frequency corruptions. As illustrated in Fig. 1(b), our proposed frequency sensitivity metrics are negatively correlated with the corruption robustness. Therefore, point cloud models that are less sensitive to high/low frequency bands exhibit better robustness to high/low frequency corruptions. This correlation indicates that the sensitivity of models to different frequency bands affects their corruption robustness, providing insights for further improving the robustness of point cloud recognition models.

### Frequency adversarial training

The above analyses highlight the importance of the sensitivity of point cloud recognition models to high and low frequencies on their corruption robustness. However, reducing the sensitivity of point cloud models to both high and low frequencies is still challenging. To address this problem, we propose **Frequency Adversarial Training (FAT)** to improve the corruption robustness of point cloud recognition models using adversarial examples in the frequency domain. Intuitively, a model trained to be robust to worst-case adversarial perturbations should be naturally robust to real-world corruptions [72; 80], as also theoretically demonstrated in Sec. 3.5.

To simultaneously reduce the sensitivity of point cloud recognition models to high and low frequencies, we generate high-frequency adversarial examples and low-frequency adversarial examples, which are added to the training set. We generate high-frequency adversarial examples that alter the details of

Figure 3: An illustration of computing the Fourier spectrum of the Jacobian matrix for a single input point cloud. First, the Jacobian matrix for the input point cloud is computed. The gradient value of the output loss is visualized for each point. A higher gradient value (skewed to red) indicates that the model is more sensitive to changes at that point. Next, we utilize Graph Fourier Transform (GFT) on the Jacobian matrix to obtain a compact representation and measure its sensitivity in the Fourier domain. Finally, by examining the sensitivity measurement of different point cloud models in different frequency bands, we construct a relationship diagram with natural robustness.

the point clouds, and low-frequency adversarial examples that change the rough shapes of the point clouds. To prevent the mutual interference of high-frequency and low-frequency adversarial examples that may lead to a decrease in model performance, we adopt the AdvProp training framework , where clean samples, high-frequency adversarial samples, and low-frequency adversarial samples are separately processed using three batch normalizations during adversarial training. Specifically, for an input point cloud \(\) with the ground-truth label \(y\), our optimization objective is

\[_{}_{(,y) }_{h}(,,y)&+ _{_{h}_{h}}_{h}(,G^{-1}(G ()+_{h}),y)\\ &+_{_{l}_{l}}_{h}(,G ^{-1}(G()+_{l}),y), \]

where \(\) is the underlying data distribution, \(_{h}\) is the loss function, \(\) is the network parameter, \(_{h}\) and \(_{l}\) are high-frequency and low-frequency adversarial perturbations, and \(_{h}\) and \(_{l}\) are the high-frequency and low-frequency perturbation ranges, respectively.

### Theoretical analysis

To verify the claim that a model robust to frequency-domain worst-case perturbations should be more resistant to real-world corruptions, we provide a theoretical analysis that demonstrates the effectiveness of FAT in ensuring OOD generalization of the model.

Suppose \((x,y)\) is a pair of training sample \(x\) and its label \(y\). The loss on \((x,y)\) with model parameter \(\) is \((,(x,y))\), where \((,(x,y))\) is continuous and differentiable for both \(\) and \((x,y)\). We let \(f(x):=(,(x,y))\) for simplicity. Let \(\) and \(^{-1}\) denote the Fourier transform and inverse Fourier transform, respectively. The norm \(\|\|_{p}\) denotes the \(_{p}\)-norm. We have the following theorem:

**Theorem 1**.: _If \(f\) satisfies that: \(f(x)[0,M]\) for all \(x\), \(|f(^{-1}((x)+))-f(x)|\) for all \(x\) and \(\|\|_{p}\), then for any distribution \(P_{o}\) and \(P_{a}\) satisfying that \(Was^{p}(P_{o},P_{a}):=(_{u(P_{o},P_{a})}_{(x,z) u}[\| (x)-(z)\|_{p}^{p}])^{1/p}\), where \(<\), then, with probability \(1-\), we have:_

\[_{z P_{o}}[f(z)]-_{i=1}^{m}f(x_{i}) (1-}{ p}-})+ {^{p}}{ p}M+4M}, \]

_where \(\{x_{i}\}_{i=1}^{m}\) are i.i.d. samples from \(P_{a}\)._

**Remark 1**.: _Intuitively, OOD corresponds to the shifted distribution \(P_{o}\) that approaches the training distribution \(P_{a}\). Thus \(Was^{p}(P_{o},P_{a})\) defines OOD from the perspective of measuring the distance between distributions. \(_{z P_{o}}[f(z)]-_{i=1}^{m}f(x_{i})\) represents the OOD generalization error of the model. \(|f(^{-1}((x)+))-f(x)|\) and \(\|\|_{p}\) indicate that the model is robust under frequency-domain perturbations. The bound (2) implies that models that are adversarially robust in the frequency-domain have smaller generalization bounds on OOD data._

The proof of Theorem 1 is deferred to Appendix A. Thus, the frequency-domain adversarial robustness of the model guarantees the generalization on OOD data. We have the following observations:

* The right-hand side of Eq. (2) implies that models that are more robust to frequency domain adversarial samples (i.e., larger \(\) and smaller \(\)) have smaller OOD generalization bounds and thus perform better on OOD data.
* For Eq. (2), a larger number of training samples \(m\) leads to a smaller OOD generalization bound. This indicates that more training samples can compensate for the degradation of generalization performance.

## 4 Experiments

In this section, we first detail the experimental settings in Sec. 4.1, then present the main results in Sec. 4.2 to show the effectiveness of our method. We further integrate our method with other data augmentation techniques in Sec. 4.3 and perform ablation studies in Sec. 4.4.

### Experimental setup

**Dataset.** To validate the effectiveness of our FAT method in enhancing the corruption robustness of 3D point cloud recognition models, we train all models on the standard ModelNet40 training set . In addition to reporting the performance of the models on the original ModelNet40 validation set, we also evaluate the corruption robustness on ModelNet-C  in the main paper and ModelNet40-C  in Appendix B. The ModelNet40 dataset  contains 12,311 CAD models with 40 common object categories in the real world. We use the official split , where 9,843 examples are used for training and the remaining 2,468 examples are used for testing. The ModelNet-C dataset  is designed for measuring the network robustness to common point cloud corruptions. It consists of 7 different corruption types, including "Scale", "Jitter", "Rotate", "Drop Global", "Drop Local", "Add Global", and "Add Local". Each type of corruption has five severity levels. ModelNet40-C  is a similar dataset with 15 corruptions, which will be detailed in Appendix B.

**Model architectures.** Following , we select four representative model architectures: PointNet , DGCNN , PCT , and GDANet . These models represent different architectural designs and have been widely applied in 3D visual tasks.

**Evaluation metrics.** To measure the corruption robustness of different methods, we follow  and use the mean corruption error (mCE) as the main evaluation metric. We adopt the official baseline DGCNN and first compute the corruption error (CE) for a given corruption type \(i\) by averaging over 5 severity levels: \(_{i}=^{S}(1-_{i,l})}{_{i=1}^{S}(1- _{i,l}^{})}\), where \(_{i,l}\) is the overall accuracy on a corruption test set \(i\) at severity level \(l\), and \(_{i,l}^{}\) is the overall accuracy of the baseline. Then, we average over the 7 corruption types to compute the mean corruption error: \(=_{i=1}^{N}_{i}\). In addition, we also report the clean overall accuracy (OA), the corruption overall accuracy (mOA), and the relative mCE (RmCE) following . Due to space constraints, we provide the definition of RmCE and report mOA and RmCE in Appendix B.

**Implementation details.** For each method, we train 250 epochs using the smooth cross-entropy loss  and Adam optimizer , and select the best performant model for further evaluation. We follow the DGCNN protocol . For our method, we set \(k=30\) for the \(k\)-nearest neighbor graph and \(=100\) for dividing high-frequency and low-frequency . We use PGD  and AOF  to generate high-frequency adversarial examples and low-frequency adversarial examples, respectively. We constrain \(_{h}\) and \(_{l}\) by 0.3 and 0.5, respectively. For more detailed training settings, please refer to Appendix B.

    & Method & OA \(\) & **mCE \(\)** & Rotate & Jitter & Scale & Drop-G & Drop-L & Add-G & Add-L \\   & Vanilla Training & 0.926 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 \\  & Adv Training & 0.925 & 0.926 & 1.019 & 0.582 & 1.043 & 0.996 & 1.101 & 0.871 & 0.869 \\  & DUP Defense & 0.906 & 0.905 & 1.112 & 0.902 & 1.181 & 1.048 & 1.483 & 0.285 & 0.327 \\  & FAT (Ours) & 0.925 & **0.825** & 0.898 & 0.453 & 0.989 & 0.931 & 0.971 & 0.773 & 0.760 \\   & Vanilla Training & 0.907 & 1.422 & 1.902 & 0.642 & 1.266 & 0.500 & 1.072 & 2.980 & 1.593 \\  & Adv Training & 0.904 & 1.372 & 1.851 & 0.563 & 1.287 & 0.448 & 1.077 & 2.888 & 1.487 \\  & DUP Defense & 0.876 & 1.246 & 2.088 & 0.668 & 1.649 & 0.802 & 1.396 & 0.966 & 1.153 \\  & FAT (Ours) & 0.902 & **1.237** & 1.553 & 0.370 & 1.606 & 0.448 & 1.097 & 2.583 & 1.004 \\   & Vanilla Training & 0.930 & 0.925 & 1.042 & 0.870 & 0.872 & 0.528 & 1.000 & 0.780 & 1.385 \\  & Adv Training & 0.919 & 0.976 & 1.042 & 0.389 & 1.074 & 0.911 & 1.193 & 1.108 & 1.116 \\  & DUP Defense & 0.919 & 0.925 & 1.112 & 0.699 & 1.043 & 0.738 & 1.261 & 0.410 & 1.215 \\  & FAT (Ours) & 0.920 & **0.907** & 1.009 & 0.345 & 1.085 & 0.843 & 1.237 & 0.912 & 0.920 \\   & Vanilla Training & 0.934 & 0.892 & 0.981 & 0.839 & 0.830 & 0.794 & 0.894 & 0.871 & 1.036 \\  & Adv Training & 0.926 & 0.960 & 1.112 & 0.506 & 1.032 & 0.927 & 1.140 & 1.064 & 0.938 \\   & DUP Defense & 0.915 & 0.897 & 1.140 & 0.788 & 1.064 & 0.698 & 1.179 & 0.427 & 0.985 \\   & FAT (Ours) & 0.928 & **0.850** & 1.167 & 0.408 & 0.926 & 0.794 & 1.111 & 0.654 & 0.887 \\   

Table 1: Quantitative results of vanilla training, adversarial training, DUP Defense and our proposed Frequency Adversarial Training (FAT) on the ModelNet-C test set. Our proposed FAT outperforms all other methods in terms of mean corruption error (mCE), which demonstrates the effectiveness of FAT for improving corruption robustness.

### Main results

In this section, following [41; 51], we compare our proposed Frequency Adversarial Training (FAT) method with vanilla training, adversarial training and DUP Defense  on the ModelNet-C test set, demonstrating the effectiveness of FAT in enhancing corruption robustness. Table 1 presents a comparative analysis of different methods based on mean corruption error (mCE), clean overall accuracy (OA), and corruption error (CE) for each corruption type.

As shown in Table 1, our proposed Frequency Adversarial Training (FAT) outperforms all other methods in terms of mean corruption error (mCE), while exhibiting comparable performance in terms of overall accuracy (OA). The improvement in corruption robustness across the four different model architectures demonstrates the generalizability/universality of our method across different architectures. In Fig. 4, we visualize the sensitivity maps based on Jacobian matrices of Frequency Adversarial Training (FAT) and vanilla training under four different model architectures. FAT reduces the sensitivity of the model across different frequency bands.

It is noteworthy that GDANet introduces a geometry-disentangle module to dynamically disentangle point clouds into the contour and flat part of 3D objects, capturing complementary 3D geometric semantics. In contrast, FAT does not modify the network architecture to focus on the frequency domain but instead employs adversarial training in the frequency domain. As shown in Table 1, the two methods are complementary and synergistic, leading to improved model robustness. We report the performance of different methods in terms of overall corruption accuracy (mOA) and relative mCE (RmCE) in Appendix B, where the improvement in robustness of FAT is also significant under these metrics. The comparisons in Table 1 and Appendix B confirm that our proposed FAT enhances the OOD generalization ability of the model.

### Data augmentation

To further validate the effectiveness of our proposed Frequency Adversarial Training (FAT), following , we investigate the performance of FAT in combination with different data augmentation strategies, including RSMix , PointWOLF , and WOLFMix . These strategies respectively represent mix-based augmentation, deformation-based augmentation, and a combination of both mix-based and deformation-based augmentation. RSMix involves rigidly blending two point clouds using a transformation. PointWOLF enriches data diversity by applying non-rigid deformations to object parts. WOLFMix, designed based on PointWOLF and RSMix, first deforms the objects and then rigidly blends two deformed objects. When combining the data augmentation strategies, we first perform data augmentation on the input point cloud and then generate adversarial examples. For mix-based augmentation, we perform untargeted adversarial attacks on both labels being mixed to generate the adversarial examples.

In Table 2, we show the performance of FAT when integrated with different data augmentation strategies in terms of mean corruption error (mCE), clean overall accuracy (OA), and corruption error (CE) for each corruption type. Compared with a single data augmentation strategy, the combination of FAT and data augmentation strategies achieves a better mCE, which is attributed to the complementary and compatible information from both the spatial and frequency domains. The improvement in corruption robustness under three different data augmentation strategies demonstrates the generalization capability of our proposed method. As shown in Table 2, training GDANet with the combination of our proposed FAT with WOLFMix achieves a new state-of-the-art performance, with an impressive 0.537 mCE.

Figure 4: Visualization of the sensitivity maps based on Jacobian matrices of Frequency Adversarial Training (FAT) and vanilla training under four different model architectures. FAT reduces the model sensitivity to different frequency bands, thereby enhancing their robustness to corruptions.

### Ablation study

In this section, we conduct ablation study among our proposed Frequency Adversarial Training (FAT), as well as FAT variants: FAT w/o low-frequency, FAT w/o high-frequency, FAT w/o frequency-division, and FAT w/o Advprop. FAT w/o low-frequency generates only high-frequency adversarial samples, while FAT w/o high-frequency generates only low-frequency adversarial samples. FAT w/o frequency-division randomly generates adversarial samples within a certain frequency range, without dividing the high and low frequency bands. FAT w/o Advprop does not use the AdvProp training framework . We compare these methods in Table 3 based on mean corruption error (mCE), clean overall accuracy (OA), and corruption error (CE) measurements for each corruption type.

Compared with other methods, FAT w/o low-frequency has a lower mCE for high-frequency corruptions such as "Jitter", while FAT w/o high-frequency has a lower mCE for low-frequency corruptions such as "scale". As discussed in Sec. 3.3, this is because adversarial training on high/low frequencies reduces the high/low frequency sensitivity, thus improving robustness to high/low-frequency corruptions. The performance of FAT w/o frequency-division falls between FAT w/o low-frequency and FAT w/o high-frequency. Although FAT w/o Advprop has a better mCE, its clean overall accuracy (OA) is worse than the other methods due to mutual interference between samples from different distributions, which may cause potential performance degradation. Compared with these methods, FAT achieves the lowest mCE, showing the effectiveness of our algorithm. More experimental results can be found in Appendix B.

    & Method & OA \(\) & **mCE \(\)** & Rotate & Jitter & Scale & Drop-G & Drop-L & Add-G & Add-L \\   & Vanilla Training & 0.907 & 1.422 & 1.902 & 0.642 & 1.266 & 0.500 & 1.072 & 2.980 & 1.593 \\  & RSMix & 0.902 & 1.276 & 1.372 & 0.532 & 2.234 & 0.593 & 1.145 & 2.241 & 0.815 \\  & RSMix+FAT (Ours) & 0.904 & **1.084** & 1.340 & 0.389 & 1.670 & 0.415 & 0.899 & 2.241 & 0.636 \\  & PointWOLF & 0.902 & 1.311 & 0.912 & 0.633 & 2.128 & 0.754 & 1.575 & 2.210 & 0.964 \\  & PointWOLF+FAT (Ours) & 0.902 & **0.993** & 0.558 & 0.487 & 1.372 & 0.589 & 1.411 & 1.759 & 0.775 \\  & WOLFMix & 0.880 & 1.149 & 0.986 & 0.560 & 2.096 & 0.605 & 1.155 & 1.854 & 0.789 \\  & WOLFMix+FAT (Ours) & 0.882 & **0.945** & 0.726 & 0.491 & 1.691 & 0.520 & 1.048 & 1.498 & 0.644 \\   & Vanilla Training & 0.930 & 0.925 & 1.042 & 0.870 & 0.872 & 0.528 & 1.000 & 0.780 & 1.385 \\  & RSMix & 0.925 & 0.660 & 1.116 & 0.614 & 1.106 & 0.488 & 0.522 & 0.302 & 0.473 \\  & RSMix+FAT (Ours) & 0.925 & **0.604** & 1.093 & 0.354 & 1.106 & 0.427 & 0.531 & 0.308 & 0.411 \\  & PointWOLF & 0.923 & 0.846 & 0.428 & 0.788 & 0.979 & 0.504 & 1.130 & 1.040 & 1.051 \\  & PointWOLF+FAT (Ours) & 0.923 & **0.785** & 0.465 & 0.415 & 1.096 & 0.556 & 1.217 & 0.953 & 0.796 \\  & WOLFMix & 0.922 & 0.585 & 0.442 & 0.788 & 0.989 & 0.444 & 0.546 & 0.319 & 0.564 \\  & WOLFMix+FAT (Ours) & 0.920 & **0.570** & 0.572 & 0.326 & 1.351 & 0.444 & 0.560 & 0.325 & 0.415 \\   & Vanilla Training & 0.934 & 0.892 & 0.981 & 0.839 & 0.830 & 0.794 & 0.894 & 0.871 & 1.036 \\  & RSMix & 0.927 & 0.680 & 1.205 & 0.873 & 1.000 & 0.484 & 0.531 & 0.281 & 0.385 \\  & RSMix+FAT (Ours) & 0.929 & **0.617** & 1.153 & 0.427 & 1.021 & 0.504 & 0.531 & 0.285 & 0.396 \\  & PointWOLF & 0.919 & 0.870 & 0.405 & 1.111 & 0.915 & 1.032 & 1.121 & 0.688 & 0.815 \\  & PointWOLF+FAT (Ours) & 0.925 & **0.807** & 0.428 & 0.522 & 0.915 & 0.831 & 1.159 & 1.058 & 0.735 \\  & WOLFMix & 0.920 & 0.601 & 0.428 & 0.937 & 0.968 & 0.540 & 0.589 & 0.298 & 0.444 \\  & WOLFMix+FAT (Ours) & 0.930 & **0.537** & 0.530 & 0.418 & 1.138 & 0.460 & 0.527 & 0.281 & 0.404 \\   

Table 2: Quantitative results of combining FAT with different data augmentation strategies on the ModelNet-C test set. Compared with a single data augmentation strategy, the combination of FAT and different data augmentation strategies achieves a better mCE. Training GDANet with the combination of our proposed FAT with WOLFMix achieves the new state-of-the-art performance, with an impressive **0.537 mCE**.

    & Method & OA \(\) & **mCE \(\)** & Rotate & Jitter & Scale & Drop-G & Drop-L & Add-G & Add-L \\   & Vanilla Training & 0.907 & 1.422 & 1.902 & 0.642 & 1.266 & 0.500 & 1.072 & 2.980 & 1.593 \\  & FAT w/o low-frequency & 0.890 & 1.306 & 1.614 & 0.373 & 1.734 & 0.504 & 1.193 & 2.627 & 1.098 \\  & FAT w/o high-frequency & 0.906 & 1.317 & 1.702 & 0.519 & 1.234 & 0.452 & 1.043 & 2.851 & 1.415 \\  & FAT w/o frequency-division & 0.904 & 1.310 & 1.679 & 0.516 & 1.351 & 0.444 & 1.106 & 2.817 & 1.255 \\  & FAT w/o Advprop & 0.885 & 1.263 & 1.470 & 0.411 & 1.926 & 0.500 & 1.164 & 2.461 & 0.909 \\  & FAT & 0.902 & **1.237** & 1.553 & 0.370 & 1.606 & 0.448 & 1.097 & 2.583 & 1.004 \\   

Table 3: Quantitative results of FAT and its variants. FAT w/o low-frequency has a lower mCE for high-frequency corruptions such as “Jitter”, while FAT w/o high-frequency has a lower mCE for low-frequency corruptions such as “scale”. FAT w/o Advprop has a higher mCE but much worse OA. Compared with these methods, FAT achieves the lowest mCE.

Conclusion

In this paper, we study the robustness of 3D point cloud recognition models under common corruptions. We focus on the frequency domain to analyze the underlying structure of point clouds and common corruptions. Through graph Fourier transform (GFT), we identify a correlation between the corruption robustness and the model sensitivity to different frequency bands. Motivated by the analysis, we propose Frequency Adversarial Training (FAT), an adversarial training method based on frequency-domain adversarial examples to improve the corruption robustness of 3D point cloud recognition models. Extensive experiments demonstrate that the proposed method significantly improves the corruption robustness of various point cloud models, and can be integrated with other data augmentation techniques to achieve the state-of-the-art performance.

**Limitation and broader impact.** A limitation of our proposed method is that it reduces the clean accuracy a bit, e.g., FAT reduces the clean accuracy of DGCNN by 0.1%, PointNet by 0.5%, PCT by 1.0%, and GDANet by 0.6%. This may be caused by the inherent trade-off between accuracy and robustness . Additionally, despite the complexity in implementation, FAT does not affect the efficiency of model inference, ensuring unhindered deployment of well-trained models in practical applications. The robustness of 3D point cloud recognition under corruptions is a severe problem towards safe and reliable 3D perception. Our work proposes an effective method to solve this issue, which does not have any negative social impact.