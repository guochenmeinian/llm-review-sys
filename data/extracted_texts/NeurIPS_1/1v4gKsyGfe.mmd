# Understanding Linear Probing then Fine-tuning

Language Models from NTK Perspective

 Akiyoshi Tomihiari

The University of Tokyo

tomiharig.ecc.u-tokyo.ac.jp &Issei Sato

The University of Tokyo

sato@g.ecc.u-tokyo.ac.jp

###### Abstract

The two-stage fine-tuning (FT) method, linear probing (LP) then fine-tuning (LP-FT), outperforms linear probing and FT alone. This holds true for both in-distribution (ID) and out-of-distribution (OOD) data. One key reason for its success is the preservation of pre-trained features, achieved by obtaining a near-optimal linear head during LP. However, despite the widespread use of large language models, there has been limited exploration of more complex architectures such as Transformers. In this paper, we analyze the training dynamics of LP-FT for classification tasks on the basis of the neural tangent kernel (NTK) theory. Our analysis decomposes the NTK matrix into two components. This decomposition highlights the importance of the linear head norm alongside the prediction accuracy at the start of the FT stage. We also observe a significant increase in the linear head norm during LP, which stems from training with the cross-entropy (CE) loss. This increase in the linear head norm effectively reduces changes in learned features. Furthermore, we find that this increased norm can adversely affect model calibration, which can be corrected using temperature scaling. Additionally, we extend our analysis with the NTK to the low-rank adaptation (LoRA) method and validate its effectiveness. Our experiments using a Transformer-based model on multiple natural language processing datasets confirm our theoretical analysis. Our study demonstrates the effectiveness of LP-FT for fine-tuning language models. Code is available at [https://github.com/tom4649/lp-ft_ntk](https://github.com/tom4649/lp-ft_ntk).

## 1 Introduction

Fine-tuning pre-trained models for new tasks is a common practice across various fields. However, simply fine-tuning the entire model can lead to overfitting on training data, which may negatively impact generalization and out-of-distribution (OOD) performance . To address this, the two-stage approach known as linear probing then fine-tuning (LP-FT)  has demonstrated high performance on both in-distribution (ID) and OOD data. Initially, linear probing (LP) optimizes only the linear head of the model, after which fine-tuning (FT) updates the entire model, including the feature extractor and the linear head. This method has been extensively analyzed and enhanced .

The feature distortion theory, introduced by Kumar et al. , explains the effectiveness of LP-FT on the basis of a theoretical analysis with a two-layer linear model. This theory suggests that LP-FT minimizes changes to pre-trained features by starting FT with an already optimized linear head from LP. However, our understanding of LP-FT, particularly when applied to complex architectures such as Transformers , remains incomplete. Thus, it is crucial to further explore the training dynamics of LP-FT in more complex models than the two-layer linear model.

In this paper, we apply the neural tangent kernel (NTK) theory  to clarify the mechanisms underlying LP-FT, focusing on the training dynamics of classification models. The NTK is a theoretical tool that analyzes training dynamics by applying a first-order approximationto changes in the model outputs with respect to its parameters. Therefore, the NTK is suited for analyzing feature changes during FT dynamics (Wei et al., 2022; Malladi et al., 2023). Our analysis reveals that after LP, both more accurate predictions and increased norms of the linear head compared to their initial values contribute to minimizing feature changes. We then identify a significant increase in the linear head norm during LP from the analysis of training with cross-entropy (CE) loss, which contributes to small feature changes in the FT stage. On the other hand, we found that this increase in the linear head norm can worsen calibration, causing predicted probabilities to deviate from actual probabilities, which can be corrected with temperature scaling (Guo et al., 2017). Furthermore, we extend our analysis based on the NTK to the low-rank adaptation (LoRA) method (Hu et al., 2022), a parameter-efficient fine-tuning strategy, and validate its effectiveness.

Our contributions are summarized as follows:

* We show that both accurate predictions and increased norms of the linear head during LP reduce feature changes in LP-FT within the NTK regime (Section 4), which is consistent with the feature distortion theory. (Corollary 4.3).
* We find that norms of the linear head significantly affect the balance of the NTK matrix components and influence the training dynamics of FT (Proposition 4.1).
* We also highlight that increased linear head norms can negatively affect model calibration, and this can be fixed with temperature scaling.
* We extend our analysis based on the NTK to the LoRA method and provide a theoretical validation of its efficacy (Proposition 4.4).

## 2 Related work

Lp-FTFT and LP are well-established transfer learning techniques with extensive empirical and theoretical studies (Zhuang et al., 2020; Kornblith et al., 2019; Tripuraneni et al., 2020). Kumar et al. (2022) analyzed the effectiveness of these techniques using a two-layer linear model. Then, they proposed LP-FT that is a combined approach of LP then FT. Building on this study, subsequent studies have explored LP-FT in more detail. Trivedi et al. (2023) investigated LP-FT through the lens of safety objectives, proposing modifications to mitigate simplicity bias. Ren et al. (2023) analyzed LP-FT from the perspective of the initial discrepancy between predicted and actual probabilities, emphasizing the importance of the number of probing epochs during LP. Ha et al. (2024) further improved LP-FT by aligning batch normalization layers with the target domain. Kirichenko et al. (2023) highlighted the challenge that models depend on spurious features and proposed last-layer retraining as a cost-effective strategy to improve model robustness.

Other FT methodsVarious FT strategies other than LP-FT have been proposed, including two-stage approaches (Zhang et al., 2020), regularization-based techniques (Jiang et al., 2019), and parameter-efficient fine-tuning methods (Houlsby et al., 2019; He et al., 2022). One prominent example of a parameter-efficient method is LoRA, proposed by Hu et al. (2022). This approach draws inspiration from the concept of intrinsic dimensions (Aghajanyan et al., 2021), suggesting that data can be effectively represented in a lower-dimensional space. Zeng and Lee (2024) explored the expressive power of LoRA, and Jang et al. (2024) provided a theoretical analysis of its convergence properties. However, challenges remain in parameter-efficient FT methods, including potential instability issues identified by Chen et al. (2022).

Neural tangent kernel (NTK)The NTK, which was first introduced by Jacot et al. (2018), has become a valuable tool for analyzing the training dynamics of neural networks. Studies by Lee et al. (2019) and Arora et al. (2019) used the NTK to gain insights into how networks learn. Building on this foundation, Wei et al. (2022) introduced the concept of the empirical NTK, which extends the application of NTK to FT scenarios. This approach replaces the randomly initialized parameters in the standard NTK with the parameters of the pre-trained models. Further expanding on the empirical NTK, Malladi et al. (2023) conducted a theoretical and experimental investigation and found that prompt-based fine-tuning exhibits behavior consistent with the predictions of the kernel framework. Jang et al. (2024) extended this perspective to analyze LoRA.

Preliminary

In this section, we provide an overview of the FT methods used in this paper, followed by a brief explanation of the NTK.

Lp-FtIn standard FT, the parameters of the linear head, weight \(\) and bias \(\), are initialized with random values. In contrast, in LP-FT, LP is conducted before the FT stage, and the FT stage is started with the obtained parameters. The performance of LP-FT is higher than that of LP and FT on both ID and OOD data (Kumar et al., 2022). The original LP-FT paper (Kumar et al., 2022) explains the reason behind it as the feature distortion theory: the success of LP-FT stems from the minimal feature changes because of starting the FT stage with the linear head parameters which are close to the optimal solution. We analyze the training process of LP-FT throughout this paper.

LoRALoRA(Hu et al., 2022) introduces trainable rank decomposition matrices into each layer of the Transformer architecture. This approach, inspired by the concept of "intrinsic dimensions" from Aghajanyan et al. (2021), constrains updates to pre-trained weight matrices via low-rank decomposition. The update of a pre-trained weight matrix \(_{}^{q s}\) is approximated by \(+=}+^{}^{}\), where \(^{}^{q r}\) and \(^{}^{r s}\) are the only matrices optimized during fine-tuning. Here, \(r(q,s)\) represents the small intrinsic rank of the weight matrix, reflecting the low-rank approximation. The standard initialization of \(^{}\) and \(^{}\) is \(^{}=O\) and \(^{}\) is drawn from a normal distribution with mean 0.

Neural tangent kernel (NTK)Jacot et al. (2018) introduced the NTK, which captures the training dynamics over time. They demonstrated that in the infinite width limit, the NTK remains constant. In this limit, training dynamics are governed by a linear model derived from a first-order Taylor expansion around the initial parameters of the network, known as the linearized or NTK regime (Lee et al., 2019). For networks with finite width, this limiting kernel depends on the initialization parameters and is known as the empirical NTK (Wei et al., 2022). Although the empirical NTK differs from the infinite width limit, it is valuable for analyzing the local training dynamics of models (Ren et al., 2022; Fort et al., 2020; Mohamadi and Sutherland, 2023; Wei et al., 2022; Jang et al., 2024), and has been used in FT (Ren et al., 2023; Malladi et al., 2023).

## 4 Analysis of LP-FT from NTK perspective

The original analysis of LP-FT by Kumar et al. (2022) is based on a two-layer linear model and proposes the feature distortion theory, which suggests that minimal changes in pre-trained features are the reason behind the robust performance of LP-FT. In this section, we use the NTK theory to analyze LP-FT to better understand the training dynamics of LP-FT in complex models like Transformers. After introducing the notation, we discuss the increase in the classifier weight norm during training, followed by the training dynamics in the NTK regime. We then extend our analysis to the LoRA method. These analyses suggest the LP-FT reduces feature distortion with the increased norm of the classifier weight and the near-optimal prediction after LP.

### Notation

Let \(=\{_{1},,_{N}\}^{d}\) represent the training samples, paired with labels from the set \(=\{y_{1},,y_{N}\}\{1,2,,C\}\), where \(d\), \(C\), and \(N\) denote the dimensions of the input space, the number of classes, and the number of training samples, respectively. This forms a training dataset \(\{(_{1},y_{1}),,(_{N},y_{N})_{i},y_{i }\}\), and we use \(^{d}\) to denote both a training and a test sample. We denote the \(k\)-th element of vector \(\) as \([]_{k}\). We use the Euclidean norm \(\|\|\) for vectors and the Frobenius norm \(\|\|_{F}\) for matrices. \(,\) denotes the inner product of two vectors. \(_{k}\) represents the one-hot vector for class \(k\), and \(_{C}\) is the identity matrix of size \(C\).

The model function, denoted as \((;):^{C}\), is parameterized by a set of parameters \(\), and sometimes abbreviated as \(()\). The model includes a linear head, also referred to as the classifier, which consists of a weight matrix \(\) and a bias vector \(\). The feature extractor is denoted by \(():^{h}^{C}\), where \(h\) represents the hidden dimension. The output of the model is given by \(()=()+\). Parameters for a function \(g()\) and matrix \(\) are sometimes denoted as \(^{g}\) and \(^{A}\), respectively. Subscripts represent iteration or epoch, so \(_{t}()\) denotes the model at time \(t\).

With the loss function \(:^{C}\), the training objective is to minimize the empirical risk \(L():=L((;))=_{i=1}^{N}((_ {i};),y_{i})\). We use the CE loss, \(((),y)=-([_{}(())]_{y})\), where \(_{}:^{C}^{C}\) is the softmax function with its \(k\)-th element given by \([_{}(())]_{k}=()]_{k}) }{_{k^{}}([()]_{k^{}})}\).

### Training dynamics in the NTK regime

We use the NTK (Jacot et al., 2018), more specifically the empirical NTK (Wei et al., 2022; Malladi et al., 2023), to analyze the training dynamics of both FT and LP-FT. The empirical NTK, defined as the NTK with the parameters at the start of training, is a valuable tool for understanding the neural network training process, particularly in the context of FT (Wei et al., 2022; Malladi et al., 2023; Ren et al., 2023). The empirical NTK applies a first-order approximation to changes in model outputs with respect to its parameters, so this is expected to capture changes in features.

To investigate the feature distortion theory in FT and LP-FT, we decomposed the updates into the following two parts. The part influenced by feature updates, unique to FT and absent in LP, is termed the _FT-effective_ component of the NTK matrix, represented as \((,_{i})\). In contrast, the part not influenced by feature updates, common to both FT and LP, determined by the pre-trained model, is termed the _pre-train-effective_ component, represented as \((,_{i})\). This decomposition highlights the distinct training dynamics of LP-FT in the NTK regime in the following proposition.

**Proposition 4.1** (FT in the NTK regime).: _The NTK of a model \(()=()+\), denoted by \(^{}\), can be decomposed as:_

\[^{}(,_{i})=(,_{i})+(, {x}_{i}),\]

_where the pre-train-effective component \((,_{i})\) and the FT-effective component \((,_{i})\) are defined using the classifier weight matrix \(_{0}\) and the feature extractor \(_{0}\) at starting point of training as:_

\[(,_{i}):=(_{0}(),_{0}( _{i})+1)_{C},\]

\[(,_{i}):=_{0}_{0}()}{ }_{0}(_{i})^{}}{ ^{}}^{}_{0}^{}.\]

_Consequently, assuming that one-epoch training within the NTK regime approximates FT, the logits and feature vectors for a sample \(\) after FT, denoted as \(^{}()\) and \(^{}()\), to the starting point of training, \(_{0}()\) and \(_{0}()\), can be expressed as:_

\[^{}()-_{0}()=_{i=1}^{N}(( ,_{i})+(,_{i}))_{i}, \]

\[^{}()-_{0}()=_{i=1}^{N}^ {}(,_{i})_{0}^{}_{i}, \]

_where \(^{}\) is the NTK matrix of the feature extractor \(\), \(_{i}:=_{y_{i}}-_{}(_{0}(_{i}))\) represents the difference between the one-hot label for the class \(y_{i}\) and the predicted probability, and \(\) is the learning rate._

The proof of this proposition is included in the Appendix (Appendix A.2.1). In our decomposition of the NTK matrix, the pre-train-effective component \((,_{i})\) is a diagonal matrix and remains unchanged after LP, while the FT-effective component \((,_{i})\) is not a diagonal matrix and does change after LP, resulting in distinct characteristics for these components. The Frobenius norm of the classifier weight matrix, \(\|_{0}\|_{F}\), influences the balance between the pre-train-effective and FT-effective components because it affects only the FT-effective component. This indicates that the classifier weight norm \(\|_{0}\|_{F}\) has a significant impact on the training dynamics of FT.

Hypothesis on reduced feature changes in LP-FTThe above proposition provides insights into why LP-FT causes fewer feature changes compared to FT:

1. The impact of the classifier weight norm \(\|_{0}\|_{F}\) differs in the equations: it affects feature changes linearly (2) and affects logits quadratically (1). This implies that a higher norm can result in significant logit updates with relatively minor changes to the feature extractor, reducing feature changes in LP-FT compared with FT due to the increased classifier weight norm after LP.

2. The magnitude of changes in both features and logits ((1) and (2)), is proportional to \(_{i}\), the difference between the predicted probability and the one-hot label. This suggests that feature changes are less pronounced in LP-FT than in FT since the difference \(_{i}\) is smaller after LP.
3. The learning rate \(\), typically smaller in LP-FT than in FT (Kumar et al., 2022; Ren et al., 2023; Ha et al., 2024), helps moderate the direct influence of large classifier weight norms.

Prior studies (Kumar et al., 2022; Ren et al., 2023) have suggested that reduced feature changes in LP-FT stem from the near-optimal linear head obtained during LP. However, our analysis reveals that feature changes in LP-FT are also influenced by the classifier weight norm \(_{0}\) after LP. Our analysis focusing on classifier weight norms provides a new perspective on the training dynamics of LP-FT, highlighting the importance of the classifier weight norm in reducing feature distortion.

### Derivation of Lemma a.3 from Kumar et al. in the NTK regime

The analysis presented in the original LP-FT paper by Kumar et al. (Kumar et al., 2022) operates within a framework where the feature extractor is a linear function. We define this framework in our context as follows:

**Definition 4.2** (Linear model (Kumar et al., 2022)).: A linear model is defined as \(_{}():=+\), where \(^{C h}\) is the classifier weight matrix and \(^{h d}\) is the weight matrix of the feature extractor.

The linear model is a model whose feature extractor \(\) is a linear transformation. In this setting, we derive a corollary from Proposition 4.1 in our context, which is the pivotal lemma in the original LP-FT analysis (Kumar et al., 2022):

**Corollary 4.3** (Lemma A.3 from Kumar et al. in the NTK regime).: _Within the context of the linear model (Definition 4.2), for any sample \(()^{}\), the orthogonal complement of the subspace spanned by the training sample set \(\), the features after FT remain unchanged, expressed as:_

\[^{FT}()=_{0}(),\]

_where \(^{FT}()\) and \(_{0}()\) denote the feature vectors after and before FT, respectively._

This corollary shows that feature vectors for the samples in the orthogonal complement of training sample subspace are not updated. Therefore, given that pre-trained features have characteristics beneficial to downstream tasks, significant feature changes in FT, dependent on small training samples in LP, lead to poor generalization and OOD performance. The proof of this lemma can be found in the Appendix (Appendix A.2.2).

### Increase in the classifier weight norm

The analysis in the previous section suggests that the classifier weight norm affects both feature changes and logits. On the basis of this insight, we examine classifier weight norms during training. Figure 1 shows that classifier weight norms consistently increase over time for LP, standard FT, and LoRA. As the training proceeds, norms of classifier bias and logits increases, while training loss decreases. Notably, LP shows a significantly larger increase in the norm compared to FT and LoRA.

Figure 1: Increase in classifier weight norms during training on the RTE dataset. (a) and (b) show the increase of the both accuracy and classifier weight norms with training. (c) shows classifier weights norms after training.

Consider the transpose of the \(k\)-th row of matrix \(\) denoted as \(_{k}^{h}\) for \(1 k C\), where \(C\) is the number of classes. Let \(_{ki}\) represent the angle between \((_{i})\) and \(_{k}\), which expands \(_{k},(_{i})\) to \(\|_{k}\|\|(_{i})\|_{ki}\). The probability that class \(k\) is chosen for sample \(_{i}\) is given by the softmax function \([_{}((_{i}))]_{k}=_{k},(_{i}))}{_{k^{}}( _{k^{}},(_{i}))}\). Consequently, with the CE loss for an input \(_{i}\) classified into class \(y_{i}\) defined as \(((_{i}),y_{i})=-([_{}((_{i}))]_{y_{i}})\), we have the following partial derivatives:

\[(_{i}),y_{i})}{_{ki}}= [_{}((_{i}))]_{k}\|_{k}\|\| (_{i})\|&k y_{i},\\ -(1-[_{}((_{i}))]_{y_{i}}\|\|_ {y_{i}}\|\|(_{i})\|&k=y_{i},\]

where the derivative with respect to \(_{yi,i}\) is negative and positive for \(k y_{i}\). As training progresses, \(_{yi,i}\) tends to increase towards positivity, while \(_{ki}\) for \(k y_{i}\) tends to become negative for each \(i\). The derivative with respect to \(\|_{k}\|\) is given by:

\[)}{\|_{k}\|}=_{i=1}^{N} (_{k y_{i}}[_{}((_{i}) )]_{k}\|(_{i})\|_{ki}-_{k=y_{i}}(1-[_{}((_{i}))]_{y_{i}})\|(_{i}) \|_{y_{i},i}). \]

Therefore, with adequate training and \(_{ki}<0\) and \(_{y_{i},i}>0\), the derivative with respect to \(\|_{k}\|\) is likely to become negative for each class \(k\). The training of the model proceeds so that the empirical risk \(L\) decreases, so the norm \(\|_{k}\|\) tends to increase. This finding aligns with prior studies (Soudry et al., 2018; Kim and Kim, 2020).

Remark: increase in classifier weight norms is more pronounced in LP than in FTIn FT, particularly within an overparameterized setting, the model \(\) may achieve perfect classification on the training dataset. That is, \([_{}((_{i}))]_{k}\) becomes close to \(0\) for \(k y_{i}\) and \(1\) for \(k=y_{i}\). In this scenario, the derivative in Eq. (3) becomes close to zero, or the training itself is finished. Conversely, perfect classification is typically unattainable in LP unless the training dataset is linearly separable, so the derivative continues to be negative. In addition, while all parameters are updated in FT, only the classifier is optimized in LP, so the change in the classifier weight needs to be larger in LP than in FT to achieve the same classification performance. Consequently, the classifier weight norm tends to increase more significantly in LP than in FT, as shown in Figure 1 (c).

### Training process of LoRA

We extend our analysis based on the NTK to the training process of LoRA. We follow the linear model setting as in Definition 4.2 and analyze the training dynamics of LoRA in the NTK regime.

**Proposition 4.4** (LoRA approximates FT).: _Consider the linear model setting (Definition 4.2) and let \(^{}\) and \(^{}\) be the models obtained via one-epoch training with LoRA and standard FT in the NTK regime. Let \(r\) denote the rank of the LoRA hyperparameter, and \(^{2}\) represent the variance of the low-rank weight matrix initialization. Assume the input samples \(\) satisfy \(\|\| c\). Then, for each sample pair \(_{i},_{j}\), the pre-train-effective components of the NTK matrix for LoRA and FT, \(^{}(_{i},_{j})\) and \(^{}(_{i},_{j})\), are identical:_

\[^{}(_{i},_{j})=^{}(_{i}, {x}_{j}).\]

_Moreover, with at least \(1-4(-(^{2}-^{3})r/4)\) probability, their FT-effective components, \(^{}(_{i},_{j})\) and \(^{}(_{i},_{j})\), satisfy:_

\[\|^{}(_{i},_{j})-^{2}r^{}( _{i},_{j})\| c\|_{0}_{0}^{}\|.\]

This proposition suggests that with high probability, the only difference of the NTK matrix between LoRA and standard FT is a scalar factor of the FT-effective component in the NTK matrix, and the scalar factor depends on the hyperparameters of LoRA. This implies that when the hyperparameters of LoRA are set appropriately, LoRA training is similar to standard FT training. This is consistent with the analysis by Malladi et al. (2023), where the NTK matrix of LoRA and standard FT are close to each other. It is important to note that the proposition is also valid for LP-FT and LP-LoRA (LP then LoRA). The proof of this proposition is included in the Appendix (Appendix A.2.3).

### Discussion

An increased norm of the classifier weight reduces feature distortion and enhances the contribution of the FT-effective component of the NTK matrix during training. As a result, a higher classifier weight norm in LP-FT can be advantageous. However, since the increased norm is dependent on LP training, its optimality is not guaranteed. Specifically, during test time, although the increased classifier weight norm does not influence accuracy, it affects the calibration of the model. Calibration is defined as the alignment between the predicted probabilities and the actual probabilities (Guo et al., 2017). An excessively high classifier weight norm can lead to overconfident predictions, which might be detrimental in practical applications. Consequently, there is potential for refining LP-FT by adjusting the classifier weight norm to enhance calibration.

Tuning the norm of the classifier after training can be effectively equated to applying temperature scaling (Guo et al., 2017) at test time. Temperature scaling adjusts the output logits with a temperature parameter \(T\), thereby improving model calibration. Specifically, temperature scaling with parameter \(T\), expressed as \(()/T=}{T}()+}{T}\), can be viewed as scaling the norm of classifier weight \(\) and bias \(\) by the temperature parameter \(T\).

## 5 Numerical evaluation with transformer models

In this section, we numerically justify the following aspects obtained from our analysis:

* The changes in features during training are smaller in LP-FT than in FT, and the norms of the classifier significantly increase during LP (Section 5.2).
* The FT-effective component of the NTK matrix more effectively captures the input data than the pre-train-effective component (Section 5.3) and is more pronounced in LP-FT than FT.
* A large classifier weight norm reduces the feature change during training, and its negative effects on calibration can be improved by temperature scaling (Section 5.4).

Details on the datasets, setup, and additional results, including performance evaluations for the experimental and practical application, are available in the Appendix (Appendices A.3 and A.4).

### Setup

Datasets and modelsWe used a total of \(13\) classification datasets from various benchmarks: SuperGLUE (Wang et al., 2019), GLUE (Wang et al., 2018), BOSS (Yuan et al., 2023), and PubMed \(20\)k RCT (Demoncourt and Lee, 2017). The breakdown of the datasets is as follows: five datasets from SuperGLUE (BoolQ, CB, RTE, WiC, and WSC), three datasets from GLUE (CoLA, MRPC, and SST-2), four datasets from BOSS (Amazon, Dynasent, SemEval, and SST-5), and PubMed \(20\)k RCT. Following experimental settings in studies that analyze FT dynamics from NTK perspectives (Malladi et al., 2023; Jang et al., 2024) and the study with similar settings Chen et al. (2022), we employed the RoBERTa-base model (Liu et al., 2020) as our Transformer-based model.

    &  &  \\   & CS(F) & Diff(F) & FDR(F) & Norm(C) & CS(F) & Diff(F) & FDR(F) & Norm(C) \\  Pre-trained & \(0.997\) & \(-\) & \(8.14 10^{4}\) & \(9.51 10^{-1}\) & \(0.996\) & \(-\) & \(8.59 10^{4}\) & \(7.76 10^{-1}\) \\ LP & \(0.997\) & \(-\) & \(8.14 10^{4}\) & \(2.48 10^{4}\) & \(0.996\) & \(-\) & \(8.59 10^{4}\) & \(3.10 10^{1}\) \\ FT & \(0.336\) & \(2.21 10^{1}\) & \(7.39 10^{8}\) & \(9.60 10^{-1}\) & \(0.260\) & \(2.16 10^{1}\) & \(1.42 10^{4}\) & \(7.84 10^{-1}\) \\ LoRA & \(0.499\) & \(1.92 10^{1}\) & \(8.91 10^{6}\) & \(1.43 10^{0}\) & \(0.759\) & \(1.06 10^{4}\) & \(2.97 10^{3}\) & \(1.21 10^{0}\) \\ LP-FT & \(0.804\) & \(1.20 10^{1}\) & \(6.47 10^{6}\) & \(2.48 10^{1}\) & \(0.942\) & \(4.70 10^{0}\) & \(1.57 10^{2}\) & \(3.10 10^{1}\) \\ LP-LoRA & \(0.837\) & \(9.08 10^{9}\) & \(2.10 10^{6}\) & \(2.49 10^{1}\) & \(0.924\) & \(4.63 10^{9}\) & \(2.06 10^{1}\) & \(3.10 10^{1}\) \\   

Table 1: Changes in features (F) and classifier (C) norms on the CB and RTE datasets. CS, Diff, FDR, and Norm represent the cosine similarity between features, the difference in norms from the pre-trained model, Fisher\({}^{}\) s discriminant ratio, and the norm, respectively. After LP-FT, Diff(F) is smaller compared to FT, while preserving the high CS(F) and low FDR(F) of the pre-trained features. In contrast, Norm(C) is significantly larger after LP and LP-FT than both the pre-trained model and after FT. This trend is also observed when training with LoRA.

Implementation and trainingWe used the Transformers library (Wolf et al., 2020) and AdapterHub (Pfeiffer et al., 2020) for our implementation. Our training protocol followed the experimental setup described by Chen et al. (2022). Hyperparameter tuning, especially for learning rates during the FT stage of LP-FT, was conducted through a grid search based on the validation set performance. For LP, we used logistic regression with L2 regularization on pre-trained features.

### Small feature changes during LP-FT and significant norm increase during LP

LP-FT achieves notable performance with Transformer-based language models, outperforming standard FT in both ID and OOD settings, as detailed in Appendix (Appendices A.4.1 and A.4.3). To understand the underlying reasons for these results and validate small feature changes suggested by our analysis (Section 4.2), we analyzed changes in both the classifier and the features.

According to statistics presented in Table 1, the features after LP-FT demonstrate smaller changes from those of the pre-trained model than FT. Consequently, LP-FT preserves high cosine similarity among its features and exhibits a low Fisher's discriminant ratio (FDR) (Fisher, 1936), which assesses linear separability. Conversely, the classifier norms after LP and LP-FT are substantially larger than those of the pre-trained model and after FT, suggesting a significant increase in classifier weights during LP. A similar trend is observed in training with LoRA.

### Kernel analysis

We examined the overall NTK matrix and its pre-train-effective and FT-effective components to understand their properties. Kernel regression was performed on the train and test sets to evaluate the performance of each kernel matrix.

Analysis of NTK matrix components and effectiveness of LP-FTIn Table 2, the FT-effective component of the NTK matrix for LP-FT shows a higher rank and greater kernel regression accuracy compared to the pre-train-effective component, and the overall NTK matrix has intermediate properties. Additionally, the FT-effective component contributes more significantly to the overall kernel in LP-FT than in FT, as indicated by a higher FT Ratio. This ratio, calculated as the average of \(\|_{i=1}^{N}(,_{i})_{i}\|/\|_{i=1}^{N} ((,_{i})+(,_{i}))_{i}\|\) for the train set samples, reflects the enhanced influence of the FT-effective component in LP-FT than in FT. These results suggest that the NTK matrix of LP-FT better captures input data through the increased influence of the FT-effective component.

Similarities between LoRA and FTThe ranks of the FT-effective components in LoRA and FT (or LP-LoRA and LP-FT) are similar, as indicated in Table 2. Their distributions of singular values normalized by the maximum singular value, also closely align, as shown in Figure 2. These results suggest that the FT-effective components of the NTK matrix in FT and LoRA differ only by a scalar factor. This consistency demonstrates that our analysis (Section 4.2), originally based on a two-layer linear model, is applicable to more complex Transformer-based models.

   Method & Kernel & Rank & FN(\( 10^{3}\)) & Acc (train/test) & FT Ratio \\  - & Pre-train \& E & 18 & 51.0 & 87.11/79.17 & - \\  FT & FT E & 608 & 13.9 & 84.74/79.76 & 0.1987 \\  & NTK & 210 & 64.9 & 84.74/79.76 & 0.1987 \\  LoRA & FT E & 500 & 0.0226 & 86.22/79.17 & 0.0004 \\  & NTK & 20 & 51.0 & 92.15/84.52 & 0.0004 \\  LP-FT & FT E & 344 & 7250 & 100.00/86.31 & 1.0000 \\  & NTK & 344 & 7280 & 100.00/86.31 & 1.0000 \\  LP-LoRA & FT E & 307 & 15.1 & 94.96/85.71 & - \\  & NTK & 188 & 62.6 & 95.11/85.71 & 1.0137 \\   

Table 2: Kernel statistics on the CB dataset. FN, Acc, and FT Ratio denote the Frobenius norm, kernel regression accuracy, and contribution of the FT-effective component, respectively. Pre-train E and FT E refer to the pre-train-effective and FT-effective components of the NTK matrix.

Figure 2: Singular value distribution normalized by the maximum value on the CB dataset, showing the common pre-train-effective component (Pre-train E) and the FT-effective components for each training option.

### Analysis of classifier weight norms and temperature scaling

We experimentally verified significant effects of classifier weight norms in training (Section 4.2) and at test time (Section 4.6) in the following.

Effects of classifier weight norms in trainingWe scaled the classifier weight norms at the start of the FT stage of LP-FT. The results, shown in Figure 3, indicate that larger classifier weight norms almost monotonically lead to smaller feature differences in both FT and LP-FT. Notably, LP-FT consistently shows smaller feature differences than FT, particularly when the classifier weight norms are large, validating our analysis that larger classifier weight norms reduce feature changes.

Temperature scaling at test timeWe implemented temperature scaling at test time, which is equivalent to adjusting the classifier weight norms, as discussed in Section 4.6. We optimized the temperature parameters on the validation sets based on CE loss, following the methodology suggested by Guo et al. (2017). Table 3 presents the results on the RTE datasets. We assessed the expected calibration error (ECE) and maximum calibration error (MCE) (Naeini et al., 2015), which quantify the absolute differences between predicted and actual probabilities, with lower values indicating better calibration. These results show that the improvements in calibration with temperature scaling are the largest in LP-FT for both ECE and MCE, with notably substantial improvements in MCE. This suggests that large classifier weight norms contribute to poor calibration of LP-FT, which can be effectively mitigated through temperature scaling. These results highlight the effectiveness of refining LP-FT by temperature scaling.

## 6 Conclusion

In this paper, we explored the LP-FT training dynamics in complex classification models using the NTK to analyze feature changes. Our analysis identified classifier weight norms at the start of the FT stage as a key factor influencing FT dynamics. These norms balance the NTK matrix components and help reduce feature changes. Our findings support the existing feature distortion theory from an NTK perspective and emphasize the role of classifier weight norms alongside prediction accuracy. We also found that increases in classifier weight norms, characteristic of training with CE loss, may negatively impact model calibration, and this can be mitigated by temperature scaling. Additionally, the approximation effectiveness of LoRA is theoretically validated in terms of the similarity of the NTK matrix components. Empirical experiments with Transformer-based language models supported our theoretical insights, validating our understanding of the NTK, feature changes, and the benefits of temperature scaling. Overall, our study substantiates the efficacy of LP-FT as a robust method for adapting pre-trained complex models while preserving their well-trained features.

Figure 3: Feature differences on SST-5 (OOD). Solid lines show mean values; shaded areas represent standard errors. Dashed vertical lines indicate the classifier weight norm after training. This figure validates our analysis that larger classifier weight norms reduce feature changes.

   Metric & Method & w/o TS & w/TS & Imp. \\   & FT & \(21.16\) & \(5.13\) & \(16.03\) \\  & LP-FT & \(21.72\) & \(5.48\) & \(\) \\  & LoRA & \(11.92\) & \(6.17\) & \(5.76\) \\  & LP-LoRA & \(18.14\) & \(5.72\) & \(12.42\) \\   & FT & \(53.11\) & \(25.87\) & \(27.24\) \\  & LP-FT & \(63.95\) & \(13.94\) & \(\) \\  & LoRA & \(25.04\) & \(13.75\) & \(11.29\) \\  & LP-LoRA & \(40.46\) & \(18.82\) & \(21.63\) \\   

Table 3: ECE and MCE with temperature scaling on the test set of the RTE dataset. w/o TS and w/ TS denote without and with temperature scaling, respectively, and Imp. represents the improvement because of temperature scaling. We bold the best improvements. This table shows that poor calibration of LP-FT can be effectively mitigated through temperature scaling.

LimitationsThe main limitation of our study is that it is based on the NTK regime, which might not fully capture the training dynamics. Additionally, we consider just one epoch of gradient descent in FT, which may not effectively represent the overall training. In our experiments, we specifically focused on validating the effectiveness of LP-FT on language models. Therefore, areas other than natural language processing are outside the scope of our experiments.