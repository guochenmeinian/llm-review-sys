# Replicability in Learning: Geometric Partitions and Sperner-KKM Lemma

Jason Vander Woude

Sandia National Laboratories

jasonvwoude@gmail.com &Peter Dixon

University of Toronto, Mississauga

tooplark@gmail.com &A. Pavan

Iowa State University

pavan@cs.iastate.edu &Jamie Radcliffe

University of Nebraska-Lincoln

jamie.radcliffe@unl.edu &N. V. Vinodchandran

University of Nebraska-Lincoln

vinod@unl.edu

###### Abstract

This paper studies replicability in machine learning tasks from a geometric viewpoint. Recent works have revealed the role of geometric partitions and Sperner's lemma (and its variations) in designing replicable learning algorithms and in establishing impossibility results.

A partition \(\) of \(^{d}\) is called a \((k,)\)-secluded partition if for every \(^{d}\), an \(\)-radius ball (with respect to the \(_{}\) norm) centered at \(\) intersects at most \(k\) members of \(\). In relation to replicable learning, the parameter \(k\) is closely related to the _list complexity_, and the parameter \(\) is related to the sample complexity of the replicable learner. Construction of secluded partitions with better parameters (small \(k\) and large \(\)) will lead to replicable learning algorithms with small list and sample complexities.

Motivated by this connection, we undertake a comprehensive study of secluded partitions and establish near-optimal relationships between \(k\) and \(\).

1. We show that for any \((k,)\)-secluded partition where each member has at most unit measure, it must be that \(k(1+2)^{d}\), and consequently, for the interesting regime \(k[2^{d}]\) it must be that \((k)}{d}\).
2. To complement this upper bound on \(\), we show that for each \(d\) and for each viable \(k[2^{d}]\), a construction of a \((k,)\)-secluded (unit cube) partition with \((k)}{d}(d+1)}\). This establishes the optimality of \(\) within a logarithmic factor.
3. Finally, we adapt our proof techniques to obtain a new "neighborhood" variant of the cubical KKM lemma (or cubical Sperner's lemma): For any coloring of \(^{d}\) in which no color is used on opposing faces, it holds for each \((0,]\) that there is a point where the open \(\)-radius \(_{}\)-ball intersects at least \((1+)^{d}\) colors. While the classical Sperner/KKM lemma guarantees the existence of a point that is "adjacent" to points with \((d+1)\) distinct colors, the neighborhood version guarantees the existence of a small neighborhood with exponentially many points with distinct colors.

## 1 Introduction

Can we design learning algorithms that are replicable? Typically, learning algorithms observe samples from an unknown distribution and output a hypothesis. Since different runs of a learning algorithmmay observe different samples, the algorithm may output different hypotheses on different runs, making standard learning algorithms _non-replicable_. Several recent works have been investigating various notions of replicability in learning algorithms. Intuitively, a replicable learning algorithm should output the same canonical hypothesis, on multiple runs (with high probability). However, it has been observed that such an ideal notion of replicability may not be achievable even in simple learning tasks such as learning one-dimensional thresholds. This led to relaxed definitions of replicability including \(\)-replicability , stability , global-stability , and list-replicability .

A significant insight that emerged form these works is the profound connection between geometry and algorithmic replicability [17; 13; 31; 12]. These works use geometric partitions to design replicable algorithms and employ (variants of) Sperner/KKM lemma, including Poincare-Miranda and Borsuk-Ulam theorems, to obtain lower bound results. In particular, in , the authors use the notion of _secluded partitions_ of \(^{d}\) to design replicable learning algorithms with small list complexity. The works of [13; 12; 17] used Sperner/KKM, Poincare-Miranda and Borsuk-Ulam theorems to obtain lower bounds on list complexity and stability parameters for various learning tasks.

Motivated by these connections we undertake an in-depth investigation into _secluded partitions_. Our first contribution is a comprehensive understanding of the optimality of secluded partition constructions. Our second contribution is the discovery of a new neighborhood variant of the Sperner/KKM lemma.

Secluded partitions have found applications beyond replicable learning including deterministic rounding, pseudodeterministic algorithms, and quantum computaion [44; 7]. Moreover, the notion of secluded partitions is simple and natural and is rooted in the works of Lebesgue and Brouwer [36; 8]. Thus, our investigation of secluded partitions should be seen as a fundamental endeavor.

The applicability of the Sperner/KKM lemma, and other equivalent results such as Brouwer's fixed point theorem, the Poincare-Miranda theorem, and the Lebesgue covering theorem is not just limited to the area of replicable algorithms. These lemmas and their variants have found numerous applications in various contexts: distributed and parallel computing [2; 4; 39; 28; 42; 6], communication complexity [21; 11], computational complexity [25; 35; 40; 16], algorithmic game theory [14; 15], and fair-division [37; 38; 5]. We expect that the neighborhood variant we established will also be useful in computer science applications.

## 2 Preliminaries

A learning algorithm is _\(k\)-list replicable_ if the output of the learning algorithm belongs to a list \(\) consisting of at most \(k\) good hypotheses with high probability. Below is a more formal definition from .

Let \(\) be a domain over which a family of distributions \(\) are defined, let \(\) be a set (representing hypotheses), and \(:[0,)\) be an error function. A learning algorithm on input \(,\) observes \(m\) samples from a distribution \(D\) and learns a hypothesis \(h\) with a small error \((D,h)\).

**Definition 2.1** (List Replicability).: _Let \(k\), \((0,)\), and \(\). A learning algorithm \(A\) is \((k,,)\)-list replicable if there exists \(n\) such that for every \(D\), there exists a list \(L\) of size at most \(k\) such that for all \(h L\), \((D,h)\), and_

\[_{s D^{n}}[A(s,,) L] 1-.\]

_For \(k\), we call \(A\)\(k\)-list replicable if for all \((0,)\) and \((0,1]\), \(A\) is \((k,,)\)-list replicable. We say that \(n\) is the sample complexity of \(A\) and \(k\) is the list complexity of \(A\)._

The above definition captures the ideas over multiple runs of the learning algorithm, we may see at most \(k\) different hypotheses. Note that the ideal scenario is when \(k=1\). A generic goal is to design list replicable algorithms with small list and sample complexities. The work of  designed list-replicable algorithms for various learning tasks including a general theorem that any concept class that is learnable with \(k\) non-adaptive statistical queries has a \(k+1\)-list replicable algorithm.

A key ingredient in their list replicable algorithms is the geometric notion of secluded partitions that we define next. Given a point \(^{d}\), let \(_{}(,)\) (\(B^{}_{}(,)\)) denote the closed (respectively, open) \(\)-ball around \(\) in the \(_{}\) norm.

**Definition 2.2** ().: _A partition \(\) of \(^{d}\) is called a \((k,)\)-secluded partition if for every \(^{d}\), the ball \(_{}(,)\) intersects at most \(k\) members of \(\). The parameters \(k\) and \(\) are called the degree and tolerance respectively._

**Remark.** To avoid trivial partitions where each point is a partition member or the entire \(^{d}\) is a single partition member, all the partitions considered in this work have non-zero, bounded measure partition members.

It is easy to see that the standard grid partition of \(^{d}\) with unit cubes is \((2^{d},)\)-secluded. The following result  improves the degree parameter substantially.

**Theorem 2.3**.: _There is a \((d+1,)\)-secluded partition where each partition member is a unit cube._

Sperner/KKM Lemma, Poincare-Miranda Theorem, and Borsuk-Ulam Theorem can be viewed as _fixed point theorems_ and are known to be equivalent to each other (in the sense that any of these theorems can be derived from the other theorem). We state the Sperner/KKM Lemma below. First we introduce the necessary definitions and notation.

Recall that a \(d\)-dimensional cube is the set \(^{d}\). For a set of colors \(C\), a coloring is a mapping \(:^{d} C\). For a color \(c C\), let \(X_{c}\) denote the set of points assigned color \(c\) by \(\). That is, \(X_{c}=^{-1}(c)\). _A coloring \(\) is a Sperner/KKM coloring if no two points from opposite faces of the cube gets the same color._ That is, for every \(c C\) the set \(X_{c}\) has the property that for each coordinate \(i[d]\), the projection \(_{i}(X_{c})=\{x_{i}: X_{c}\}\) does not contain both \(0\) and \(1\).

**Theorem 2.4** (Sperner/KKM).: _Given a valid Sperner/KKM coloring of \(^{d}\) by finitely many colors, there exists a point in the closure of at least \(d+1\) different colors._

## 3 Our Contributions

This section provides an overview of the results established in this work.

**Secluded Partitions and replicability.** The relationship between replicability and partitions can be best abstracted by considering \(d\)-coin bias estimation problem : given \(d\) coins with unknown biases, estimate the biases of each coin within an additive error of \(\). The work of  showed that a \((k,)\)-partition of \(^{d}\) yields a \(k\)-list replicable algorithm for this task. They used a known construction of \((d+1,)\)-secluded partition of \(^{d}\) from Theorem 2.3to obtain a \(d+1\)-list replicable algorithm for this task. However, there is a _cost_ to replicability. The sample complexity of the replicable algorithm blows up by a factor of \(O(d^{2})\) (compared to the sample complexity of the non-replicable algorithm). In general a \((k,)\)-secluded partition gives rise to a \(k\)-list replicable algorithm whose sample complexity blows up by a factor of \(O(})\) (compared to the "non-replicable" algorithms).

Thus constructions of secluded partitions with low-degree (\(k\)) and high tolerance (\(\)), will lead to list replicable algorithms with _low list and sample complexities_. It is also known that the degree parameter \(k\) must be at least \(d+1\). This leads to the following fundamental questions: Can we design secluded partitions that substantially improve the tolerance with little or no degradation of the degree? For example, consider the \((d+1,)\)-secluded partition from Theorem 2.3. Can we improve this and construct a \((d+1,())\)-secluded partition? Or can we loosen the degree requirement from \(k=d+1\) to \(k(d)\) in favor of improving the tolerance from \(()\) to \(()\)? Our first contribution is the following upper bound result on the tolerance parameter.

**Theorem 3.1**.: _Let \(d\), \([0,)\), and \(\) a partition of \(^{d}\) such that every member has outer Lebesgue measure at most \(1\). Then there exists some \(^{d}\) such that \(B^{}_{}(,)\) intersects at least \((1+2)^{d}\) members of \(\). Thus, if \(\) is a \((k,)\)-secluded partition, then \(k(1+2)^{d}\). Consequently, if \(k 2^{d}\), then it must be that \((k)}{d}\)._

This result shows that even if one relaxes \(k(d)\), \( O()\). This shows that the \((d+1,)\)-secluded partition construction is near optimal in terms of the tolerance parameter, for degree \(d+1\). Stated in terms of replicability, this result implies one can not hope to design list-replicable algorithms with improved sample complexity using a secluded partitions approach.

Our second result is a construction of secluded partitions for various choices of the degree parameter \(k\) with tolerance parameter \(\) almost matching the bound from Theorem 3.1. Until this work, we knewof secluded partitions for only two choices of the degree parameter \(k\): the standard grid partition of \(^{d}\) that is \((2^{d},)\)-secluded and the \((d+1,)\) partition from Theorem 2.3. We did not know secluded partition constructions for other choices of \(k\). Our second main contribution is the construction of near-optimal secluded partitions for all choices of \(k\).

**Theorem 3.2**.: _Let \(d\) and \(k[2^{d}][d]\). Then there exists a \((k,)\)-secluded unit cube partition of \(^{d}\) with \((k)}{8d_{4}(d+1)}\)._

Note that by Theorem 3.1, \(k}{d}\) and the above construction achieves \((k)}{8d_{4}(d+1)}\). Thus this construction is optimal up to log factors. As a corollary of this construction, we obtain a smooth tradeoff between list and sample complexities for the problem of estimating the bias of \(d\)-coins

**Corollary 3.3**.: _For the \(d\)-coin bias estimation problem, there exists a \(k\)-list replicable algorithm with sample complexity \(^{2}d}{^{2}^{2}k}\), for any \(k[2^{d}][d]\), per coin._

For example, if we allow \(k=2^{}\), then the sample complexity is \((})\), per coin.

Sperner/KKM Lemma and replicability.While the geometric tool of secluded partitions has been used to design list replicable algorithms, interestingly works that establish lower bounds on the list complexity of replicable algorithms [17; 13; 12] employ geometric/topological tools such as Sperner/KKM Lemma, Poincare-Miranda Theorem, and Borsuk-Ulam Theorem. For example, the work  used Sperner/KKM lemma to establish a lower bound of \(d+1\) on the list complexity for the problem of estimating the bias of \(d\) coins as well as for the \(d\)-dimensional threshold learning problem. The work of  used Poincare-Miranda Theorem to establish a lower bound on the list complexity of classes with VC-Dimension \(d\). As our third contribution, we generalize the Sperner/KKM Lemma and obtain a neighborhood variant.

**Theorem 3.4** (Neighborhood Sperner/KKM Lemma).: _Given a Sperner/KKM coloring of \(^{d}\), for any \((0,]\), there exists a point \(^{d}\) such that \(B_{}^{}(,)\) contains at least \((1+)^{d}\) points with distinct colors._

Sperner/KKM Lemma(Lemma 2.4) states that in valid coloring of the \(d\)-dimensional hypercube, there is a point \(\) whose closure has at least \(d+1\) colors. That is, for every \(>0\), the \(\)-ball around \(\) intersects at least \(d+1\) colors. Our theorem is a quantitative generalization of this result. It states that the \(\)-ball around \(\) intersects exponentially many colors--at least \((1+)^{d}\) many colors.

## 4 Related Work

One of the first works that studied replicability in the context of learning algorithms is the seminal work of Bun, Livny, and Moran ; they used the term _global stability_ to capture this notion. A learning algorithm \(A\) to be \((n,)\)-_globally stable_ with respect to a distribution \(D\) if there is a hypothesis \(h\) such that \(_{S D^{n}}(A(S)=h)\), here \(\) is called the _stability parameter_. They used the notion of stability, combined with the work of , to obtain the equivalence between online learnability and differentially private PAC learnability. Ghazi, Kumar and Manurangsi  generalized the notion of stability to pseudo-global stability and list-global stability. Impagliazzo, Lei, Pitassi, and Sorrell  introduced the notion of \(\)-replicability and designed replicable algorithms for various learning tasks. One of their replicable algorithms uses a partition/tiling known as "foams tiling" . Dixon, Pavan, Vander Woude and Vinodchandran  studied the notions of _list replicability_ and _certificate replicability_ as a measure of the degree of (non)-replicability. Chase, Moran and Yehudayof  related the notions list complexity and stability. They established that a learning task has list complexity \(k\) if and only if its stability parameter is \(1/k\). They also established lower bounds the list-complexity (upper bound on the stability) on the PAC-learnability of classes with bounded VC-dimension. In , the authors use Borsuk-Ulam theorem to establish impossibility results for replicable agnostic PAC learning.

In the context of randomized algorithms, the notion of replicability is studied under the terminology _pseudodeterminism_. This notion was introduced by Gat and Goldwasser  and has been extended to notions called multi-pseudodeterminism  and influential-bit algorithms . The study of replicability in the context of learning has been receiving growing attention over the past few yearsand researchers have been investigating this notion under various scenarios. The notion of replicability in the context of stochastic bandits and reinforcement learning has been studied in [19; 33; 18], and the work of  studies replicability for optimization problems. Other very recent works include those reported in [9; 29; 32]. A notion that is related to replicability is that of reproducibility. The article by  distinguishes these two notions.

## 5 Proof Sketches of Main Results

The main technical tools that we use come from measure theory and the geometry of numbers and include generalized Brunn-Minkowski Inequality and ideas from the standard proof of Blichfeldt's theorem. The generalized Brunn-Minkowski inequality gives a lower bound on the measure of a Minkowski sum of sets (\(A+B=\{+ A, B\}\)) based on the measures of those sets. We use the following version of the statement from [22, Equation 11]. Here \(m(A)\) is the Lebesgue measure of a set \(A^{d}\).

**Theorem 5.1** (Generalized Brunn-Minkowski Inequality).: _Let \(d\) and \(A,B^{d}\) be Lebesgue measurable such that \(A+B\) is also Lebesgue measurable. Then_

\[m(A+B)[m(A)^{}+m(B)^{}]^{d}.\]

A common technique in the proof of Blichfeldt's theorem is to use an averaging argument to show that if a set \(A\) is covered by a large family of other sets, then some point in \(A\) is covered many times.

### Proof Sketch of Theorem 3.1

We present the high-level ideas and the intuition behind the proof of Theorem 3.1. In the appendix, we provide a complete proof. Figure 1 serves as a visual.

The goal is to find some point \(^{d}\) such that \(B^{}_{}(,)\) intersects at least \((1+2)^{d}\) members of the partition. Instead of directly trying to establish this, we take a critical change of perspective: for any \(^{d}\) and \(X\) (or really any \(X^{d}\)), it holds that \(B^{}_{}(,) X\) if and only if \(_{ X}B^{}_{}(,)\). Thus, what we do is to "replace" every member \(X\) of the partition with the enlarged set \(_{ X}B^{}_{}(,)\) and try to find a point \(\) that belongs to at least \((1+2)^{d}\) of these enlarged sets. To achieve this, we take inspiration from a common proof of Blichfeldt's theorem--specifically, the following result which says that if we have a collection of sets \(A_{1},A_{2},A_{3},\) which are subsets of another set \(S\), then there is a point in \(S\) occurring in multiple \(A_{i}\)s provided together the \(A_{i}\)s have enough volume/measure. We can in fact give a lower bound on the number of \(A_{i}\)s to which such a point belongs to. The following is the formal claim of this known result.

**Proposition 5.1** (Continuous Multi-Pigeonhole Principle).: _Let \(d\) and \(S^{d}\) be bounded and measurable. Let \(\) be a family of measurable subsets of \(S\), and let \(k=m(A)}{m(S)}\). Then if \(k<\), there exists \( S\) such that \(\) belongs to at least \(k\) members of \(\). (And if \(k=\), then for any \(n\) there exists \(^{(n)} S\) such that \(^{(n)}\) belongs to at least \(n\) members of \(\).)_

There is an immediate issue we have to deal with to be able to use Proposition 5.1 for our application. We would like to take \(\) to be the indexed collection of enlarged partition members: \(=\{_{ X}B^{}_{}(,)\}_{X}\), but then all we know is that each of these is a subset of \(S=^{d}\) which is not bounded. This is a simple enough issue to deal with using a standard measure theory technique of considering instead a sequence \(S_{1},S_{2},S_{3},\) of sets which _are_ bounded and get larger and larger so that \(_{n=1}^{}S_{n}=^{d}\); we work with each of these sets individually and then try to use a limiting argument to pass the result back to \(S=^{d}\). Specifically, we will take \(S_{n}=[-n,n]^{d}\) as illustrated in the first two panes of Figure 1. The third pane of Figure 1 illustrates that we will specifically consider the partition of \(S_{n}\) induced by \(\) which we denote by \(_{n}\). That is, the induced partition \(_{n}\) is the set \(\{X S_{n} XX S_{n}\}\). Then for each \(S_{n}\) we consider a collection \(_{n}\) of the enlarged members of the induced partition: \(_{n}=\{A_{Y}\}_{Y_{n}}\) where \(A_{Y}}}{{=}}_{ Y}B^{ }_{}(,)\). Note that each \(A_{Y}\) is a subset of \(S^{}_{n}}}{{=}}[-(n+),n+ ]^{d}\) as in the fourth pane of Figure 1.

However, there remains one other issue to deal with to utilize Proposition 5.1--for each \(n\), we have to have some lower bound on the expression \(_{n}}m(A_{Y})}{m(S_{n}^{})}\). We know that \(m(S_{n}^{})=(2(n+))^{d}\), and using the fact that \(_{n}\) is a partition of \(S_{n}=[-n,n]^{d}\), we have the following if \(_{n}\) is countable1 (meaning finite or countably infinite):

\[_{A_{Y}_{n}}m(A_{Y})_{Y_{n}}m(Y)=m (_{Y_{n}}Y)=m(S_{n}),\]

but this is not nearly good enough, because it just gives

\[_{n}}m(A)}{m(S_{n}^{})} )}{m(S_{n}^{})} }{(2(n+))^{d}}=( )^{d}=1\]

whereas we want it \((1+2)^{d}\). Basically, this lower bound is not good because we did not account for the fact that each \(A_{Y}_{n}\) is enlarged from \(Y_{n}\). Thus, we want some way to give for each \(Y_{n}\), a lower bound on the measure of the enlarged set \(A_{Y}\). One might observe that enlarging with an \(\)-ball looks something like scaling by a factor of \(1+\), and since the Lebesgue measure (i.e. typical notion of volume/measure in \(^{d}\)) has the property that scaling by \((1+)\) increases the measure by a factor of \((1+)^{d}\), we might be able to show that the enlarged version of each member increases by a factor of \((1+)^{d}\) (which is basically what we are looking to get).

Figure 1: Pane 1: A partition of \(^{2}\). Pane 2: We consider only members of the partition which intersect \([-n,n]^{2}\). Pane 3: The partition that \(\) induces on \([-n,n]^{2}\). Pane 4: We enlarge each member by placing an \(\)-ball at each point of the member. These enlarged elements are still contained within \([-(n+),n+]^{2}\). Pane 5: The sum of areas of the expanded members is “significantly” more than the area of \([-(n+),n+]^{2}\).

This intuition holds, though the actual reason is not related to scaling, and is dependent on the members having measure at most \(1\). Rather, we use a specialized adaption of Theorem 5.1 to show that

\[m(A_{Y}) m(Y)(1+2)^{d} \]

holds. Now that we have dealt with both issues that arise with trying to apply Proposition 5.1, we can consider a fixed \(n\) and can continue. We proceed in two cases: (1) the interesting case in which \(_{n}\) has only countably many members, and (2) the nearly trivial case in which the partition \(_{n}\) contains uncountably many members. In case (1) we have

\[_{n}}m(A_{Y})}{m(S_{n}^ {})} =_{n}}m(A_{Y})}{m(S_{n}^{ })}\] (Re-index) \[_{n}}[m(Y)(1 +2)^{d}]}{m(S_{n}^{})}\] ( Equation 1) \[=_{Y _{n}}m(Y)}{m(S_{n}^{})}\] (Linearity of summation) \[= m(_{Y _{n}}Y)}{m(S_{n}^{})}\] (Countable additivity of measures) \[= m(S_{n})}{m(S_{n}^{ })}\] ( \[S_{n}=_{Y_{n}}Y\] ) \[=(1+2)^{d}()^{d}\] ( \[)}{m(S_{n}^{})}=()^{d}\] as above)

Since (for fixed \(d\) and \(\)) we have \(_{n}()^{d}=1\), then \(_{n}(1+2)^{d}() ^{d}=(1+2)^{d}\), so because there is a ceiling involved, we can take \(N\) to be large enough that \((1+2)^{d}()^{d} =(1+2)^{d}\), so by Proposition 5.1, there is a point \( S_{n}^{}\) that is contained in at least \((1+2)^{d}\) many sets in \(_{N}\), and by our change of perspective, this point \(\) has the property that \(B_{}^{}(,)\) intersects at least \((1+2)^{d}\) many members of \(\).

In case (2) where some \(_{N}\) contains uncountably many members, then we completely ignore the lower bound for \(m(A_{Y})\) in Equation 1 because it might be that lots of members \(Y\) (possibly all of them) have measure \(0\), and so that bound only tells us that \(m(A_{Y}) 0\). Instead, we note that \(Y\) is at least non-empty, so contains at least one point \(\), and thus \(A_{Y} B_{}^{}(,)=_{i=1}^{d}[y_{i}- ,y_{i}+]\), and so \(m(A_{Y})(2)^{d}\). Thus, \(_{N}}m(A_{Y})}{m(S_{N}^{})} =\), so by Proposition 5.1, there is a point \( S_{N}^{}\) that is contained in at least \((1+2)^{d}\) many sets in \(_{N}\), and by our change of perspective, this point \(\) has the property that \(B_{}^{}(,)\) intersects at least \((1+2)^{d}\) many members of \(\).

### Proof of Theorem 3.2

The partitions that we construct, to establish Theorem 3.2, are of a very natural form: we build a partition of a large dimension \(d\) space, by splitting up the coordinates into smaller sets, and separately partitioning each set of coordinates. In the end, the smaller partitions will be known partition constructions from Theorem 2.3. We will define the construction very generically. We need the observation that if a partition is \((k,)\)-secluded, then we can _increase_\(k\) to \(k^{}\) and _decrease_\(\) to \(^{}\) and the partition is trivially \((k^{},^{})\)-secluded. We refer to this property as the "monotonicity" property.

**Definition 5.2** (Partition Product).: _Let \(d_{1},,d_{n}\) and \(_{1},,_{n}\) be partitions of \(^{d_{1}},,^{d_{n}}\) respectively. Letting \(d=_{i=1}^{n}d_{n}\), we define the product partition of \(^{d}\) as_

\[_{i=1}^{n}_{i}}}{{=}} \{_{i=1}^{n}X_{i} X_{i}_{i}\}\]_where \(_{i=1}^{n}X_{i}\) is viewed as a subset of \(^{d}\)._

We specifically stated that \(_{i=1}^{n}X_{i}\) is viewed as a subset of \(^{d}\), because technically it is a subset of \(_{i=1}^{n}^{d_{i}}\), but this is naturally isomorphic to \(^{d}=^{_{i=1}^{n}d_{i}}\). For example, technically, if \(d_{1}=d_{2}=d_{3}=2\), then the elements of \(_{i=1}^{n}^{d_{i}}\) are of the form \( x_{1},x_{2}, x_{3},x_{4}, x_{5},x_{ 6}\), but this is trivially isomorphic to \(^{6}\) by instead considering the element as \( x_{1},x_{2},x_{3},x_{4},x_{5},x_{6}\).

We can now show that if we take a product of partitions, and we have a guarantee for each \(_{i}\) that it is \((k_{i},_{i})\)-secluded, then we can guarantee the product partition is \((k,)\)-secluded where \(k\) is the product of the \(k_{i}\)'s and \(\) is the minimum of the \(_{i}\)'s.

**Proposition 5.2** (Product Partition Exclusion Guarantees).: _Let \(n\). For each index \(i[n]\), let \(d_{i},k_{i}\), \(_{i}(0,)\) and \(_{i}\) be a \((k_{i},_{i})\)-secluded partition of \(^{d_{i}}\). Then the product partition \(=_{i=1}^{n}_{i}\) is a \((k,)\)-secluded partition of \(^{d}\) where \(d=_{i=1}^{n}d_{i}\), and \(k=_{i=1}^{n}k_{i}\), and \(=_{i[n]}_{i}\)._

Proof Sketch.: The basic idea is that for any point \(^{d}\), we consider how many members of \(\) intersect \(_{}()\). Conceptually we think of \(\) as a sequence \(^{(i)}_{i=1}^{n}\) of \(n\) points where the \(i\)th point \(^{(i)}\) belongs to \(^{d_{i}}\). Because we are working with the \(_{}\) norm (that is the norm used by the definition of secluded), the \(\) ball around \(\) is the product of the \(\) balls around each \(^{(i)}\) which is smaller than the product of \(_{i}\) balls around each \(^{(i)}\) because we chose \(\) as the minimum size. Thus, if the \(\) ball around \(\) intersects a member \(X\) of the partition \(\), then conceptually viewing \(X\) as a sequence \( X_{i}_{i=1}^{n}\) where \(X_{i}\) is a member of \(_{i}\), it must be for each \(i[n]\) that the \(\) ball around \(^{(i)}\) intersects \(X_{i}\) (and thus so does the \(_{i}\) ball since \(_{i}\)). This means (for each \(i[n]\)) that \(X_{i}\) is one of at most \(k_{i}\) members of \(_{i}\) because at most \(k_{i}\) members of \(_{i}\) intersect the \(_{i}\) ball around \(^{(i)}\) (by definition of \(_{i}\) being \((k_{i},_{i})\)-secluded). Thus \(X\) is one of at most \(_{i=1}^{n}k_{i}=k\) members of \(\). That is, there are at most \(k\) members of \(\) that intersect the \(\) ball around \(\) which is the definition of \(\) being \((k,)\)-secluded. 

Utilizing the construction above, we will now take the unit cube partition from Theorem 2.3 for each \(^{d_{i}}\) and take their product to obtain a new partition. Since the dimension of each \(d_{i}\) is smaller than the dimension \(d\), this allows us to get a larger value of \(_{i}\) for each partition, and thus a larger value of \(\) for the partition of \(^{d}\) than if we had used one of the original partitions. The price we pay for this is that the value of \(k\) also increases.

We establish the following lemma.

**Lemma 5.3**.: _Let \(d\) and \(d^{}[d]\).There exists a \((k,)\)-secluded unit cube partition of \(^{d}\) where \(k=(d^{}+1)^{}}\) and \(=}\)._

Proof.: Let \(n=}\). By , let \(^{}\) be a \((d^{}+1,1/2d^{})\)-secluded unit cube partition of \(^{d^{}}\). By Proposition 5.2\(=_{i=1}^{n}^{}\) is a \((k,)\)-secluded unit cube partition of \(^{n d^{}}\) where \(k=(d^{}+1)^{n}\) and \(=}\). Since \(n d^{}=} d^{} d\), this trivially (by ignoring extra coordinates) gives a partition of \(^{d}\) with these same properties which completes the proof. 

Finally, we are ready to prove Theorem 3.2.

Proof.: Let \(d^{}[d]\) be the minimum integer such that \((d^{}+1)^{}} k\) and let \(=}\). By Lemma 5.3 and monotonicity, let \(\) be a \((k,)\)-secluded unit cube partition of \(^{d}\). Now we prove the bound on \(\) in two cases: either \(d^{}=1\) or \(d^{} 2\).

In the case that \(d^{}=1\), then \(=\) and \(k(d^{}+1)^{}}=2^{d}\) and by hypothesis \(k 2^{d}\), so we have equality and we conclude that

\[(k)}{4d_{4}(d+1)}=(d+1)}=(d+1)}}=\]

which proves the bound on \(\) in the first case.

In the other case, we have \(d d^{} 2\). Let \(d^{}=d^{}-1>0\) and \(=}\). Note that

\[=}{2d^{}}=-1}{d^{}}=1-} 1-=\]

so \(\). By our choice of \(d^{}\) and because \(d^{}<d^{}\), it must be that \(k(d^{}+1)^{}}\). Noting that \(}}+1=}{d^{}}}\), we have

\[k(d^{}+1)^{}}(d^{ }+1)^{}}=(d^{}+1)^{4d }(d^{}+1)^{8d}(d+1)^{8d}\]

By taking the logarithm of each side and solving for \(\), we obtain the desired result that \((k)}{8d_{4}(d+1)}\).

### Proof Discussion of Theorem 3.4

Interestingly, the proof of the neighborhood Sperner/KKM lemma relies on the techniques developed to prove Theorem 3.1: for each color \(c C\), let \(X_{c}\) be the set of points that are colored \(c\). We union an \(\)-ball at each point in \(X_{c}\), to obtain an enlarged version \(A_{X_{c}}\) of \(X_{c}\). Now, as before, by the Continuous Pigeonhole Principle (Corollary 5.1 ), there is a point that belongs to many of the enlarged sets (and so the ball located at that point intersects many of the original color sets). However, there are some additional issues that arise on the unit cube that don't arise in \(^{d}\).

In the discussion in the proof sketch of Theorem 3.1, the enlarged set was not contained in the original region (denoted \(S_{n}\)) and we needed to consider a larger region (denote \(S^{}_{n}\)) to contain them. In \(^{d}\) we could deal with this via a limiting argument so that the ratio of the volume change \(m(S_{n})/m(S^{}_{n})\) tends to \(1\) (i.e. it became negligible when ceilings were involved). If one enlarges every color in a unit cube \([-,]^{d}\) in the same way, the measure of each color is guaranteed to increase by a factor of \((1+2)^{d}\) as before, but also the smallest set that contains all of these enlargements is the unit cube \([--,+]^{d}\) which increased in measure by a factor of \((1+2)^{d}\) compared to the original cube, so nothing has been gained! Obviously, there will be an overlap of the enlargements, but the bounds given by the generalized Brunn-Minkowsi inequality tell us no additional information.

We resolve this by employing a trick of first extending the coloring directly to \([--,+]^{d}\) in a natural way that ensures each color is bounded away from the boundary so that we can perform an enlargement which is non-uniform (it enlarges only toward one of the \(2^{d}\) orthants) and still have the enlarged color set contained in \([--,+]^{d}\). This means we end up knowing that each modified color has increased in measure by at least a factor of \((1+)^{d}\) and that the modified containing region has not changed in measure at all.

## 6 Conclusion and Open Questions

This work is a comprehensive study of secluded partitions. Prior to this work, it was known that the \((d+1,O())\)-secluded partitions of  were optimal in regards to the degree parameter (\(k=d+1\)). However, it was unknown if they were optimal in the tolerance parameter \(\) for this choice of \(k\). The present work showed that these constructions are optimal in \(\) up to a logarithmic factors. Furthermore, they remain optimal within a logarithmic factor even if we allow the degree \(k\) to be polynomial in the dimension \(d\). We also constructed secluded partitions, optimal up to logarithmic factors, for all \(k\) between \(d+1\) and \(2^{d}\).

This work raises a few open problems. At first glance, it might seem to complete the study of secluded partitions; however, it only establishes near-matching bounds for the \(_{}\) norm. In Appendix A.8, we present upper bounds on \(\) in terms of \(k\) for \(_{p}\) norms, but no known constructions approach these bounds. Developing near-optimal partitions for other norms and exploring their applications to replicability would be an intriguing direction for future research

In replicable algorithm design, there appears to be a _cost_ to achieve replicability--sample complexity blow-up. This work showed that this blow-up in sample complexity is unavoidable in list replicability if one uses secluded partitions method. Can we establish a generic lower bound on the sample complexity of list replicable learning algorithms?While Theorem 3.4 gives a new "neighborhood" variant of the Sperner/KKM lemma, the color bound of \((1+)^{d}\) is not tight for small \(\) because the standard cubical Sperner/KKM lemma (2.4) shows that even for arbitrarily small \(\), the color bound is at least \(d+1\). A compelling research goal is to improve on Theorem 3.4 so that the standard cubical Sperner/KKM lemma follows as a special case. Finally, finding applications of the neighborhood Sperner/KKM lemma is an interesting research direction.

## 7 Acknowledgements

We thank the anonymous reviewers for their valuable suggestions, which improved the presentation of this paper. Vinodchandran's work is partly supported by NSF grants 2130608, 2342244, and a UNL Grand Challenges Grant. Pavan's work is supported in part by NSF grants 2130536 and 2342245. Jason Vander Woude's contributions were made during his time at University of Nebraska, Lincoln and was partly supported by NSF grant 2130608.