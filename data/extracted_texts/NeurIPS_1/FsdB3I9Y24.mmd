# Constrained Synthesis with Projected Diffusion Models

Jacob K. Christopher

University of Virginia

csk4sr@virginia.edu &Stephen Baek

University of Virginia

baek@virginia.edu &Ferdinando Fioretto

University of Virginia

fioretto@virginia.edu

###### Abstract

This paper introduces an approach to endow generative diffusion processes the ability to satisfy and certify compliance with constraints and physical principles. The proposed method recast the traditional sampling process of generative diffusion models as a constrained optimization problem, steering the generated data distribution to remain within a specified region to ensure adherence to the given constraints. These capabilities are validated on applications featuring both convex and challenging, non-convex, constraints as well as ordinary differential equations, in domains spanning from synthesizing new materials with precise morphometric properties, generating physics-informed motion, optimizing paths in planning scenarios, and human motion synthesis.

## 1 Introduction

Generative diffusion models excel at robustly synthesizing content from raw noise through a sequential denoising process . They have revolutionized high-fidelity creation of complex data, and their applications have rapidly expanded beyond mere image synthesis, finding relevance in areas such as engineering , automation , chemistry , and medical analysis . However, although diffusion models excel at generating content that is coherent and aligns closely with the original data distribution, their direct application in scenarios requiring stringent adherence to predefined criteria poses significant challenges. Particularly the use of diffusion models in scientific and engineering domains where the generated data needs to not only resemble real-world examples but also rigorously comply with established specifications and physical laws remains an open challenge.

Given these limitations, one might consider training a diffusion model on a dataset that already adheres to specific constraints. However, even with "feasible" training data, this approach does not guarantee adherence to desired criteria due to the stochastic nature of the diffusion process. Furthermore, there are frequent scenarios where the training data must be altered to generate outputs that align with specific properties, potentially not present in the original data. This issue often leads to a distribution shift further exacerbating the inability of generative models to produce "valid" data. As we will show in a real-world experiment (SS6.1), this challenge is particularly acute in scientific and engineering domains, where training data is often sparse and confined to specific distributions, yet the synthesized outputs are required to meet stringent properties or precise standards .

This paper addresses these challenges and introduces _Projected Diffusion Models_ (PDM), a novel approach that recast the traditional sampling strategy in diffusion processes as a constrained-optimization problem. This perspective allows us to apply traditional techniques from constraint optimization to the sampling process. In this work, the problem is solved by iteratively projecting the diffusion sampling process onto arbitrary constraint sets, ensuring that the generated data adheres strictly to imposed constraints or physical principles. We provide theoretical support for PDM's capability to not only certify adherence to the constraints but also to optimize the generative model's original objective of replicating the true data distribution. This alignment is a significant advantage of PDM, yielding state-of-the-art FID scores while maintaining strict compliance with the imposed constraints.

**Contributions.** In summary, this paper makes the following key contributions: **(1)** It introduces PDM, a new framework that augments diffusion-based synthesis with arbitrary constraints in order to generate content with high fidelity that also adheres to the imposed specifications. The paper elucidates the theoretical foundation that connects the reverse diffusion process to an optimization problem, facilitating the direct incorporation of constraints into the reverse process of score-based diffusion models. **(2)** Extensive experiments across various domains demonstrate PDM's effectiveness. These include adherence to morphometric properties in real-world material science experiments, physics-informed motion governed by ordinary differential equations, trajectory optimization in motion planning, and constrained human motion synthesis, showcasing PDM's ability to produce content that adheres to both complex constraints and physical principles. **(3)** We further show that PDM is able to generate out-of-distribution samples that meet stringent constraints, even in scenarios with extremely sparse training data and when the training data does not satisfy the required constraints. **(4)** Finally, we provide a theoretical basis elucidating the ability of PDM to generate highly accurate content while ensuring constraint compliance, underpinning the practical implications of this approach.

## 2 Preliminaries: Diffusion models

Diffusion-based generative models [14; 24] expand a data distribution, whose samples are denoted \(_{0}\), through a Markov chain parameterization \(\{_{t}\}_{t=1}^{T}\), defining a Gaussian diffusion process \(p(_{0})= p(_{T})_{t=1}^{T}p(_{t-1}|_{t})d {x}_{1:T}\).

In the _forward process_, the data is incrementally perturbed towards a Gaussian distribution. This process is represented by the transition kernel \(q(_{t}|_{t-1})=(_{t};}_{t -1},_{t})\) for some \(0<_{t}<1\), where the \(\)-schedule \(\{_{t}\}_{t=1}^{T}\) is chosen so that the final distribution \(p(_{T})\) is nearly Gaussian. The diffusion time \(t\) allows an analytical expression for variable \(_{t}\) represented by \(_{t}(_{0},)=}_{0}+}\), where \((,)\) is a noise term, and \(_{t}=_{i=1}^{t}(1-_{i})\). This process is used to train a neural network \(_{}(_{t},t)\), called the _denoiser_, which implicitly approximates the underlying data distribution by learning to remove noise added throughout the forward process. The training objective minimizes the error between the actual noise \(\) and the predicted noise \(_{}(_{t}(_{0},),t)\) via the loss function:

\[_{}\ }_{t[1,T],\ p(_{0}),( ;,)}[\|-_{}(_{t}(_{0},),t)\|^{2}]. \]

The _reverse process_ uses the trained denoiser, \(_{}(_{t},t)\), to convert random noise \(p(_{T})\) iteratively into realistic data from distribution \(p(_{0})\). Practically, \(_{}\) predicts a single step in the denoising process that can be used during sampling to reverse the diffusion process by approximating the transition \(p(_{t-1}|_{t})\) at each step \(t\).

**Score-based models**[25; 26], while also operating on the principle of gradually adding and removing noise, focus on directly modeling the gradient (score) of the log probability of the data distribution at various noise levels. The score function \(_{_{t}} p(_{t})\) identifies the direction and magnitude of the greatest increase in data density at each noise level. The training aims to optimize a neural network \(_{}(_{t},t)\) to approximate this score function, minimizing the difference between the estimated and true scores of the perturbed data:

\[_{}\ }_{t[1,T],p(_{0}),q(_{t}| _{0})}(1-_{t})[\|_{}(_{t},t)- _{_{t}} q(_{t}|_{0})\|^{2}], \]

where \(q(_{t}|_{0})=(_{t};}_{0},(1 -_{t}))\) defines a distribution of perturbed data \(_{t}\), generated from the training data, which becomes increasingly noisy as \(t\) approach \(T\). This paper considers score-based models.

## 3 Related work and limitations

While diffusion models are highly effective in producing content that closely mirrors the original data distribution, the stochastic nature of their outputs act as an impediment when specifications or constraints need to be imposed on the generated outputs. In an attempt to address this issue, two main approaches could be adopted: (1) model conditioning and (2) post-processing corrections.

**Model conditioning** aims to control generation by augmenting the diffusion process via a conditioning variable \(\) to transform the denoising process via classifier-free guidance:

\[_{}}}{{=}} _{}(_{t},t,)+(1-)_{}(_{t},t,),\]

where \((0,1)\) is the _guidance scale_ and \(\) is a null vector representing non-conditioning. These methods have been shown effective in capturing properties of physical design , positional awareness , and motion dynamics . However, while conditioning may be effective to influence the generation process, it lacks the rigor to ensure adherence to specific constraints. This results in generated outputs that, despite being plausible, may not be accurate or reliable. Figure 1 (red colors) illustrates this issue on a physics-informed motion experiment (detailed in SS6.4). The figure reports the distance of the model outputs to feasible solutions, showcasing the constraint violations identified in a conditional model's outputs. Notably, the model, conditioned on labels corresponding to positional constraints, fails to generate outputs that adhere to these constraints, resulting in outputs that lack meaningful physical interpretation.

Additionally, conditioning in diffusion models often requires training supplementary classification and regression models, a process fraught with its own set of challenges. This approach demands the acquisition of extra labeled data, which can be impractical or unfeasible in specific scenarios. For instance, our experimental analysis will demonstrate a situation in material science discovery where the target property is well-defined, but the original data distribution fails to embody this property. This scenario is common in scientific applications, where data may not naturally align with desired outcomes or properties .

**Post-processing correction.** An alternative approach involves applying post-processing steps to correct deviations from desired constraints in the generated samples. This correction is typically implemented in the last noise removal stage, \(s_{}(_{1},1)\). Some approaches have augmented this process to use optimization solvers to impose constraints on synthesized samples [10; 19; 21]. However these approaches present two main limitations. First, their objective does not align with optimizing the score function. This inherently positions the diffusion model's role as ancillary, with the final synthesized data often resulting in a significant divergence from the learned (and original) data distributions, as we will demonstrate in SS6. Second, these methods are reliant on a limited and problem specific class of objectives and constraints, such as specific trajectory "constraints" or shortest path objectives which can be integrated as a post-processing step [10; 21].

**Other methods.** Some methods explored modifying either diffusion training or inference to adhere to desired properties. For instance, the methods in  and , support simple linear or convex sets, respectively. Similarly, Fishman et al. [7; 8] focus on predictive tasks within convex polytope, which are however confined to approximations by simple geometries like L2-balls. While important contributions, these approaches prove insufficient for the complex constraints present in many real-world tasks. Conversely, in the domain of image sampling, Lou and Ermon  and Saharia et al.  introduce methods like reflections and clipping to control numerical errors and maintain pixel values within the standard  range during the reverse diffusion process. These techniques, while enhancing sampling accuracy, do not address broader constraint satisfaction challenges.

To overcome these gaps and handle arbitrary constraints, our approach casts the reverse diffusion process to a constraint optimization problem that is then solved throught repeated projection steps.

## 4 Constrained generative diffusion

This section establishes a theoretical framework that connects the reverse diffusion process as an optimization problem. This perspective facilitates the incorporation of constraints directly into the process, resulting in the constrained optimization formulation presented in Equation (6).

The application of the reverse diffusion process of score-based models is characterized by iteratively transforming the initial noisy samples \(_{T}\) back to a data sample \(_{0}\) following the learned data distribution \(q(_{0})\). This transformation is achieved by iteratively updating the sample using the

Figure 1: Sampling steps failing to converge to feasible solutions in conditional models (red) while minimizing the constraint divergence to \(0\) under PDM (blue).

estimated score function \(_{_{t}} q(_{t}|_{0})\), where \(q(_{t}|_{0})\) is the data distribution at time \(t\). At each time step \(t\), starting from \(_{t}^{0}\), the process performs \(M\) iterations of _Stochastic Gradient Langevin Dynamics_ (SGLD) :

\[_{t}^{i+1}=_{t}^{i}+_{t}_{_{t}^{i}} q( _{t}^{i}|_{0})+}, \]

where \(\) is standard normal, \(_{t}>0\) is the step size, and \(_{_{t}^{i}} q(_{t}^{i}|_{0})\) is approximated by the learned score function \(_{}(_{t},t)\).

### Casting the reverse process as an optimization problem

First note that SGLD is derived from discretizing the continuous-time Langevin dynamics, which are governed by the stochastic differential equation:

\[d(t)= q((t))\,dt+\,d(t), \]

where \((t)\) is standard Brownian motion. Under appropriate conditions, the stationary distribution of this process is \(q(_{t})\), implying that samples generated by Langevin dynamics will, over time, be distributed according to \(q(_{t})\). In practice, these dynamics are simulated using a discrete-time approximation, leading to the SGLD update in Equation (3). Therein the noise term \(}\,_{t}^{i}\) allows the algorithm to explore the probability landscape and avoid becoming trapped in local maxima.

Next notice that, as detailed in [30; 31], under some regularity conditions this iterative SGLD algorithm converges toward a stationary point, bounded by \(}{^{1/4}^{2}}(1/)\), where, \(^{2}\) represents the variance schedule, \(^{*}\) denotes the uniform spectral gap of the Langevin diffusion, and \(d\) is the dimensionality of the problem. Thus, as the reverse diffusion process progresses towards \(T 0\), and the variance schedule decreases, the stochastic component becomes negligible, and SGLD transitions toward deterministic gradient ascent on \( q(_{t})\). In the limit of vanishing noise, the update rule simplifies to:

\[_{t}^{i+1}=_{t}^{i}+_{t}_{} q(_{t}^{i }|_{0}), \]

which is standard gradient ascent aiming to maximize \( q(_{t})\). This allow us to view the reverse diffusion process as an optimization problem minimizing the negative log-likelihood of the data distribution \(q(_{t}|_{0})\) at each time step \(t\).

In traditional score-based models, at any point throughout the reverse process, \(_{t}\) is _unconstrained_. When these samples are required to satisfy some constraints, the objective remains unchanged, but the solution to this optimization must fall within a feasible region \(\), and thus the optimization problem formulation becomes:

\[_{T},,_{1}}{} _{t=T,,1}- q(_{t}|_{0})\] (6a) s.t.: \[_{T},,_{0}. \]

Operationally, the negative log likelihood is minimized at each step of the reverse Markov chain, as the process transitions from \(_{T}\) to \(_{0}\). In this regard, and importantly, the objective of the PDM's reverse sampling process is aligned with that of traditional score-based diffusion models.

### Constrained guidance through iterative projections

The score network \(_{}(_{t},t)\) directly estimates the first-order derivatives of Equation (6a), providing the necessary gradients for iterative gradient-based updates defined in Equation (3). In the presence of constraints (6b), however, an alternative iterative method is necessary to guarantee feasibility. PDM models a projected guidance approach to provide this constraint-aware optimization process.

First, we define the projection operator, \(_{}\), as a constrained optimization problem,

\[_{}()=}{} \,||-||_{2}^{2}, \]

that finds the nearest feasible point to the input \(\). The _cost of the projection_\(||-||_{2}^{2}\) represents the distance between the closest feasible point and the original input.

[MISSING_PAGE_FAIL:5]

through traditional, unprojected methods. Together with the next results, it will allow us to show that PDM samples converge to the point of maximum likelihood that also satisfy the imposed constraints.

The theoretical insight provided by Theorem 5.2 provides an explanation for the observed discrepancy between the constraint violations induced by the conditional model and PDM, as in Figure 1.

**Corollary 5.3**.: _For arbitrary small \(>0\), there exist \(t\) and \(\) such that:_

\[((_{}(_{t}^{i})),) .\]

The above result uses the fact that the step size \(_{t}\) is strictly decreasing and converges to zero, given sufficiently large \(T\), and that the size of each update step \(\) decreases with \(_{t}\). As the step size shrinks, the gradients and noise reduce in size. Hence, \(((_{}(_{t}^{i}))\) approaches zero with \(t\), as illustrated in Figure 1 (right). This diminishing error implies that the projections gradually steer the sample into the feasible subdistribution of \(p(_{0})\), effectively aligning with the specified constraints.

Feasibility guarantees.PDM provides feasibility guarantees when solving convex constraints. This assurance is integral in sensitive settings, such as material analysis (Section 6.1), plausible motion synthesis (Section 6.2), and physics-based simulations (Section 6.4), where strict adherence to the constraint set is necessary.

**Corollary 5.4**.: _PDM provides feasibility guarantees for convex constraint sets, for arbitrary density functions \(_{_{t}} p(_{t})\)._

## 6 Experiments

We compare PDM against three methodologies, each employing state-of-the-art specialized methods tailored to the various applications tested:: **(1)**_Conditional diffusion models_ (_Cond_)  are the state-of-the-art methods for generative sampling subject to a series of specifications. While conditional diffusion models offer a way to guide the generation process towards satisfying certain constraints, they do not provide compliance guarantees. **(2)** To encourage constraints satisfaction, we additionally compare to conditional models with a post-processing projection step (_Cond_+), emulating the post-processing approaches of [10; 21] in various domains presented next. Finally, **(3)** we use a score-based model identical to our implementation but with a single post-processing projection operation (_Post_+) performed at the last sampling step. Additional details are provided in SC.

The performance of these models are evaluated by the _feasibility_ and _accuracy_ of the generated samples. Feasibility is assessed by the degree and rate at which constraints are satisfied, expressly, the percentage of samples which satisfy the constraints with a given error tolerance. Accuracy is measured by the FID score, a standard metric in synthetic sample evaluation. To demonstrate the broad applicability of our approach, our experimental settings have been selected to exhibit:

**1.** Behavior in low data regimes and with original distribution violating constraints (SS6.1), as part of a real-world material science experiment.
**2.** Behavior on 3-dimensional sequence generation with physical constraints (SS6.2).
**3.** Behavior on complex non-convex constraints (SS6.3).
**4.** Behavior on ODEs and under constraints outside the training distribution. (SS6.4).

### Constrained materials (low data regimes and constraint-violating distributions)

The first setting focuses on a _real-world_ application in material science, conducted as part of an experiment to expedite the discovery of structure-property linkages (please see SSC for extensive additional details). From a sparse, uniform collection of microstructure materials, we aim to generate new structures with desired, previously unobserved porosity levels.

There are two key challenges in this setting: **(1) Data sparsity:** A critical factor in this setting is the cost of producing training data. Our dataset, obtained from the authors of , consists of \(64 64\) image patches subsampled from a \(3,000 3,000\) pixel microscopic image, with pixel values scaled to \([-1,1]\). These patches are upscaled to \(256 256\) for model training. **(2) Out-of-distribution constraints:** Constraints on the generated material's porosity, defined by pixels below a threshold representing damage, are far from those observed in the original dataset.

Previous work demonstrated the use of conditional GANs [5; 11] to material generation, but these studies failed to impose verifiable constraints on desired properties. To establish a conditional baseline (denoted as Cond), we implement a conditional diffusion model, following the state-of-the-art approach by Chun et al. , conditioning the sampling on porosity measurements. Figure 2 reports the constraint violations achieved by this model. The plot depicts the frequency of constraint satisfaction (y-axis) as a function of the error tolerance (x-axis), in percentage. Observe that this state-of-the-art model struggles to adhere to the imposed constraints.

In contrast, PDM ensures both _exact_ constraint satisfaction and identical image quality to the conditional model, which is significant given the complexity of the original data distribution. Figure 3 visualizes the outputs and FID scores obtained by our proposed model compared to various baselines. The constraint correction step applied by Post\({}^{+}\) and Cond\({}^{+}\) leads to a noticeable decrease in image quality, evident both visually and in the FID scores, rendering the generated images unsuitable for this application context. Additionally, we find that PDM outperforms Cond in generating microstructures that resemble those in the ground truth data (see SSE.1). _These results are significant: the ability to precisely control morphological parameters in synthetic microstructures has broad impact in material synthesis, addressing critical challenges in data collection and property specification._

### 3D human motion (dynamic motion and physical principles)

Next we focus on dynamic motion generation adhering to strict physical principles using the challenging HumanML3D dataset . This benchmark employs three-dimensional figures across a fourth dimension of time to simulate motion. Thus, the main challenges here are generating 3D figures **(1) including a temporal component**, while **(2) ensuring they neither penetrate the floor nor float in the air**, as proposed by Yuan et al. . Previous studies have seen physical law violations in motion diffusion models, with none achieving zero-tolerance results . We next demonstrate PDM's capability to overcome these limitations.

First, we remark that previous approaches, such as , relies on a computationally demanding physics simulators to transform diffusion model predictions into "physically-plausible" actions, using a motion imitation policy trained via proximal policy optimization. This simulator is crucial to produce realistic results and dramatically alters the diffusion model's outputs. In contrast, and remarkably, PDM does not require such a simulator. and inherently satisfies the non-penetration and non-floating constraints without external assistance, showing zero violations. For comparison, the best outcomes reported in  ranged from 0.918 to 0.998 for penetration violations and 2.601 to 3.173 for floating violations (see SSE.2 for more details).

Additionally, to more accurately assess the abilities of a diffusion model in the absences of physics simulator, we evaluate a conditional model with the same architecture as the PDM model, adapted from MotionDiffuse . Results visualized in Figure 4 demonstrate that PDM achieves outputs on

Figure 3: Porosity constrained microstructure visualization at varying of the imposed porosity constraint amounts (P) and FID scores.

Figure 2: Conditional diffusion model (_Cond_): Frequency of porosity constraint satisfaction (y-axis) within an error tolerance (x-axis) over 100 runs.

par with state-of-the-art FID scores. Additionally, _the use of projections here is guaranteed to provide exact constraint satisfaction_, as we will elaborate further in SS5.

### Constrained trajectories (nonconvex constraints)

The next experiment showcase the ability of PDM to handle nonconvex constraints. Path planning is a classic optimization problem which is integral to finding smooth, collision-free paths in autonomous systems. This setting consists of minimizing the path length while avoiding path intersection with various obstacles in a given topography. Recent research has demonstrated the use of diffusion models for these motion planning objectives . In this task, the diffusion model predicts a series of points, \(p_{0},p_{1},,p_{N}\), where each pair of consecutive points represents a line segment. The start and end points for this path are determined pseudo-randomly for each problem instance, with the topography remaining constant across different instances. Additionally, the problem presents obstacles at inference time (shown in red on Figure 5), that were not present during training, rendering a portion of the training data infeasible, and thus testing the generalization of these methods. The performance is evaluated on two sets of maps adapted from Carvalho et al., shown in Figure 5. The main challenge in this setting is the **non-convex nature of the contraints**.

To circumvent the challenge of guaranteeing collision-free paths, previous methods have relied on sampling large batches of trajectories, selecting a feasible solution if available . We use the state-of-the-art _Motion Planning Diffusion_ as a conditional model baseline for this experiment and the associated datasets to train each of the models. For the Cond\({}^{+}\) model, we emulate the approach proposed by Power et al. , using the conditional diffusion model to generate initial points for an optimization solver. In this setting, the projection operator used by PDM is non-convex, and the implementation uses an interior point method . While the feasible region is non-convex, our approach _never report unfeasible solutions_ as the distance from the learned distribution decreases, unlike other methods. In contrast, using the same method for a single post-processing projection (Post\({}^{+}\)) does not enhance the feasibility of solutions compared to the unconstrained conditional model (Cond), highlighting the limitations of these single corrections in managing local infeasibilities. These observations are consistent with the analysis of Figure 1.

Figure 5 visually demonstrates that PDM can identify a feasible path with just a single sample. This capability marks a significant advance over existing state-of-the-art motion planning methods with diffusion models, as it eliminates the necessity of multiple inference attempts, which greatly affects the efficiency in generating feasible solutions. The experimental results (Table 6) demonstrate the effectiveness of PDM in handling complex, non-convex constraints in terms of success percentage for single trajectories generated (top) and path length (bottom). Notices how, both the Cond and Cond\({}^{+}\)

Figure 4: _PDM_ (left, FID: 0.71) and conditional (_Cond_) (right, FID: 0.63) generation.

Figure 5: Constrained trajectories synthetized by PDM on two topographies (Tp1, left and Tp2, right).

Figure 6: Constrained trajectories evaluation on success percentage (**S**) for a single run (higher the better, top) and path length, **PL**, (lower the better, bottom).

models fall short in finding feasible trajectories, taking shortcuts resulting in collisions. At the same time, notice how all methods find comparable path length within the reported error tolerances. _These results are significant: they show that PDM can not only handle complex, non-convex constraints, but also produce results that are on par with state-of-the-art models in solution optimality._

### Physics-informed motion (ODEs and out-of-distribution constraints)

Finally, we show the applicability of PDM in generating video frames adhering to physical principles. In this task, the goal is to generate frames depicting an object accelerating due to gravity. The object's position in a given frame is governed by

\[_{t}=_{t-1}+(_{t}+(0.5_{t}}{ t})) \] \[_{t+1}=_{t}}{ t}+_{t}}{ t}, \]

where \(\) is the object position, \(\) is the velocity, and \(t\) is the frame number. This positional information can be directly integrated into the constraint set of PDM, with constraint violations quantified by the pixel distance from their true position. In our experiment, the training data is based _solely_ on earth's gravity and we test the model to simulate gravitational forces from the moon and other planets, in addition to earth. Thus there are two challenges in this setting **(1) satifying ODEs** describing our physical principle and **(2) generalize to out-of-distribution constraints**.

Figure 7 (left) shows randomly selected generated samples, with ground-truth images provided for reference. The subsequent rows display outputs from PDM, post-processing projection (Post), and conditional post-processing (Cond\({}^{+}\)). For this setting, we used a state-of-the-art masked conditional video diffusion model, following Voleti et al. . Samples generated by conditional diffusion models are not directly shown in the figure, as the white object outline in the Cond\({}^{+}\) frames shows where the Cond model originally positioned the object. Notice that, without constraint projections, the score-based generative model produce samples that align with the original data arbitrarily place the object within the frame (white ball outlines in the 3rd column). Post-processing repositions the object accurately but significantly reduces image quality. Similarly, Cond\({}^{+}\) shows inaccuracies in the conditional model's object positioning, as indicated by the white outline in the 4th column. These deviations from the desired constraints are quantitatively shown in Figure 8 (light red bars), which depicts the proportion of samples adhering to the object's behavior constraints across varying error tolerance levels. Notably, this approach fails to produce _any viable sample within a zero-tolerance error margin_. In contrast, PDM generates frames that exactly satisfy the positional constraints, with FID scores comparable to those of Cond. Using the model proposed by Song et al.  further narrows this gap (see SSD).

Next, Figure 7 (right) shows the behavior of the models in settings where the training data does not include any feasible data points. Here we adjust the governing equation (12) to reflect the moon's gravitational pull. Remarkably, PDM not only synthesizes high-quality images but also ensures no constraint violations (0-tolerance). This stands in contrasts to other methods, that show increasedconstraint violations in out-of-distribution contexts, as shown by the dark red bars in Figure 8. _PDM can be adapted to handle complex governing equations using ODEs and can be guarantee satisfaction of out-of-distribution constraints with no decrease in sample quality._

## 7 Discussion and limitations

In many scientific and engineering domains and safety-critical applications, constraint satisfaction guarantees are a critical requirement. It is however important to acknowledge the existence of an inherent trade-off, particularly in computational overhead. In applications where inference time is a critical factor, it may be practical to adjust the time step \(t\) at which iterative projections begin, which guides a trade-off between the FID score associated with the starting point of iterative projections and the computational cost of projecting throughout the remaining iterations (SSF). Other avenues to improve efficiency also exists, from the adoption of specialized solvers within the application domain of interest to the adoption of warm-start strategies for iterative solvers. The latter, in particular, relies exploiting solutions computed in previous iterations of the sampling step and was found to be a practical strategy to substantially decrease the projections overhead.

We also note the absence of constraints in the forward process. As illustrated empirically, it is unnecessary for the training data to contain any feasible points. We hold that this not only applies to the final distribution but to the interim distributions as well. Furthermore, by projecting perturbed samples, the cost of the projection results in divergence from the distribution that is being learned. Hence, we conjecture that incorporating constraints into the forward process will not only increase computational cost of model training but also decrease the FID scores of the generated samples.

Finally, while this study provides a framework for imposing constraints on diffusion models, the representation of complex constraints for multi-task large scale models remains an open challenge. This paper motivates future work for adapting optimization techniques to such settings, where constraints ensuring accuracy in task completion and safety in model outputs bear transformative potential to broaden the application of generative models in many scientific and engineering fields.

## 8 Conclusions

This paper was motivated by a significant challenge in the application of diffusion models in contexts requiring strict adherence to constraints and physical principles. It presented Projected Diffusion Models (PDM), an approach that recasts the score-based diffusion sampling process as a constrained optimization process that can be solved via the application of repeated projections. Experiments in domains ranging from physical-informed motion for video generation governed by ordinary differentiable equations, trajectory optimization in motion planning, and adherence to morphometric properties in generative material science processes illustrate the ability of PDM to generate content of high-fidelity that also adheres to complex non-convex constraints as well as physical principles.

## 9 Acknowledgments

This research is partially supported by NSF grants 2334936, 2334448, and NSF CAREER Award 2401285. Fioretto is also supported by an Amazon Research Award and a Google Research Scholar Award. The authors acknowledge Research Computing at the University of Virginia for providing computational resources that have contributed to the results reported within this paper. The views and conclusions of this work are those of the authors only.

#### Authors Contributions

JC and FF formulated the research question, designed the methodology, developed the theoretical analysis, and wrote the manuscript. Moreover, JC contributed to developing the code and performed the experimental analysis. SB acquired the data for the micro-structure experiment, formulated the desired properties for such experiment, and participated in the interpretation of the results.