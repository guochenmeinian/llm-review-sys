# Optimal Multiclass U-Calibration Error and Beyond

Haipeng Luo

University of Southern California

haipengl@usc.edu

&Spandan Senapati

University of Southern California

ssenapat@usc.edu

Author ordering is alphabetical.

Vatsal Sharan

University of Southern California

vsharan@usc.edu

###### Abstract

We consider the problem of _online multiclass U-calibration_, where a forecaster aims to make sequential distributional predictions over \(K\) classes with low _U-calibration error_, that is, low regret with respect to _all_ bounded proper losses simultaneously. Kleinberg et al. (2023) developed an algorithm with U-calibration error \((K)\) after \(T\) rounds and raised the open question of what the optimal bound is. We resolve this question by showing that the optimal U-calibration error is \(()\) -- we start with a simple observation that the Follow-the-Perturbed-Leader algorithm of Daskalakis and Syrgkanis (2016) achieves this upper bound, followed by a matching lower bound constructed with a specific proper loss (which, as a side result, also proves the optimality of the algorithm of Daskalakis and Syrgkanis (2016) in the context of online learning against an adversary with finite choices). We also strengthen our results under natural assumptions on the loss functions, including \(( T)\) U-calibration error for Lipschitz proper losses, \(( T)\) U-calibration error for a certain class of decomposable proper losses, U-calibration error bounds for proper losses with a low covering number, and others.

## 1 Introduction

We consider the fundamental problem of making sequential probabilistic predictions over an outcome (e.g., predicting the probability of tomorrow's weather being sunny, cloudy, or rainy). Specifically, at each time \(t=1,,T\), a forecaster/learner predicts \(_{t}_{K}\), where \(_{K}\) denotes the probability simplex over \(K\) outcomes. At the same time, an adversary decides the true outcome, encoded by a one-hot vector \(_{t}:=\{_{1},,_{K}\}\), where \(_{i}\) denotes the \(i\)-th standard basis vector of \(^{K}\). The forecaster observes \(_{t}\) at the end of time \(t\).

A popular approach to measure the performance of a forecaster is to measure her _regret_ against the best fixed prediction in hindsight. Fixing some loss function \(_{K}\), the regret of the forecaster's predictions with respect to \(\) is defined as \(_{}=_{t=1}^{T}(_{t},_{t})-_{ _{K}}_{t=1}^{T}(,_{t})\). Perhaps the most common class of loss functions to evaluate a forecaster are _proper_ loss functions. A loss function is proper if \(_{}[(,)]_{ }[(^{},)]\) for all \(,^{}_{K}\). Hence proper loss functions incentivize the forecaster to predict the true probability of the outcome (to the best of their knowledge). We will focus on proper loss functions in this work.

Note, however, that regret is measured with respect to a specific loss function \(\). It is unclear which proper loss one should minimize over for the specific application at hand -- and there could evenbe multiple applications with different loss functions which use the forecasters's prediction. Could it be possible for a forecaster to simultaneously enjoy low regret with respect to all proper loss functions? This questions was raised in the interesting recent work of Kleinberg et al. (2023). They propose the notion of _U-calibration error_\(_{}[_{ }_{}]\) (and a weaker version _pseudo U-calibration error_\(_{}_{}[ _{}]\)) for a family of proper loss functions \(\). A forecaster with low U-calibration error thus enjoys good performance with respect to _all_ loss functions in \(\) simultaneously. Unless explicitly mentioned, we shall let \(\) denote the set of all bounded (in \([-1,1]\)) proper losses (as in Kleinberg et al. (2023)), and drop the subscript in \(_{}\) and \(_{}\) for convenience.

The simplest way to get low U-calibration error is via the classical notion of low _calibration error_(Dawid, 1982), defined as \(_{_{K}}\|_{i:_{i}=}( -_{t})\|_{1}\). Intuitively, a forecaster with low calibration error guarantees that whenever she makes a prediction \(\), the empirical distribution of the true outcome is indeed close to \(\). Kleinberg et al. (2023) prove that \(=()\) and thus a well-calibrated forecaster must have small U-calibration error. However, getting low calibration error is difficult and faces known barriers: the best existing upper bound on \(\) is \((T^{})\)(Blum et al., 2008), and there is a \((T^{0.528})\) lower bound (for \(K=2\)) (Qiao and Valiant, 2021). Therefore, a natural question to ask is if it is possible to side-step calibration and directly get low U-calibration error. Kleinberg et al. (2023) answer this in the affirmative, and show that there exist simple and efficient algorithms with \(=()\) for \(K=2\) and \(=(K)\) for general \(K\). This provides a strong decision-theoretic motivation for considering U-calibration error as opposed to calibration error; we refer the reader to Kleinberg et al. (2023) for further discussion.

Following up Kleinberg et al. (2023), this paper addresses the following question that was left open in their work: _"What is the minimax optimal multiclass U-calibration error?"_ We give a complete answer to this question (regarding \(\)) by showing matching upper and lower bounds. Moreover, we identify several broad sub-classes of proper losses for which much smaller U-calibration error is possible. Concretely, our contributions are as follows.

### Contributions and Technical Overview

First, we show that the minimax optimal value of \(\) is \(()\):

* In Section 3.1, we start by showing that a simple modification to the noise distribution of the Follow-the-Perturbed-Leader (FTPL) algorithm of Kleinberg et al. (2023) improves their \(=(K)\) bound to \(()\). In fact, our algorithm coincides with that of Daskalakis and Syrgkanis (2016) designed for an online learning setting with a fixed loss function and an adversary with only finite choices. The reason that it works for any proper losses simultaneously in our problem is because for any set of outcomes, the empirical risk minimizer with respect to any proper loss is always the average of the outcomes (_c.f._ property (1)).
* We then show in Section 3.2 that there exists one particular proper loss \(\) such that any algorithm has to suffer \(_{}=()\) in the worst case, hence implying \(=()\). While our proof follows a standard randomized argument, the novelty lies in the construction of the proper loss and the use of an anti-concentration inequality to bound the expected loss of the benchmark. We remark that, as a side result, our lower bound also implies the optimality of the FTPL algorithm of Daskalakis and Syrgkanis (2016) in their setting, which is unknown before to our knowledge.

While Kleinberg et al. (2023) only consider \(\) for general \(K\), we take a step forward and further study the stronger measure \(\) (recall \(\)). We start by showing an upper bound on \(_{^{}}\) for the same FTPL algorithm and for any loss class \(^{}\) with a finite covering number. Then, we consider an even simpler algorithm, Follow-the-Leader (FTL), which is deterministic and makes \(\) and \(\) trivially equal, and identify two broad classes of loss functions where FTL achieves logarithmic U-calibration error, an exponential improvement over the worst case:

* In Section 4.1, we show that for the class \(_{G}\) of \(G\)-Lipschitz bounded proper losses (which includes standard losses such as the squared loss and spherical loss), FTL ensures \(_{_{G}}=_{_{G}}=( G T)\). We further show that all algorithms must suffer \(_{_{G}}=( T)\). While we prove this lower bound using the standard squared loss that is known to admit \(( T)\) regret in many onlinelearning settings (e.g., Abernethy et al. (2008)), to our knowledge it has not been studied in our setting where the learner's decision set is a simplex and the adversary has finite choices. Indeed, our proof is also substantially different from Abernethy et al. (2008) and is one of the most technical contributions of our work.
* Next, in Section 4.2, we identify a class \(_{dec}\) of losses that are decomposable over the \(K\) outcomes and additionally satisfy some mild regularity conditions, and show that FTL again achieves \(==( T)\) (ignoring other dependence). This class includes losses induced by a certain family of Tsallis entropy that are not Lipschitz. The key idea of our proof is to show that even though the loss might not be Lipschitz, its gradient grows at a controlled rate.
* Given these positive results on FTL, one might wonder whether FTL is generally a good algorithm for any proper losses. We answer this question in the negative in Section 4.3 by showing that there exists a bounded proper loss such that the regret of FTL is \((T)\). This highlights the need of using FTPL if one cares about all proper losses (or at least losses not in \(_{G}\) or \(_{dec}\)).

### Related Work

For calibration, Foster and Vohra (1998) proposed the first algorithm for the binary setting with an (expected) \((T^{})\) calibration error (see also Blum and Mansour (2007) and Hart (2022) for a different proof of the result). In the multiclass setting, Blum et al. (2008) have shown an \((T^{})\) calibration error. Several works have studied other variants of calibration error, such as the most recently proposed Distance to Calibration (Blasiok et al., 2023; Qiao and Zheng, 2024; Arunachaleswaran et al., 2024); see the references therein for other earlier variants.

A recent research trend, initiated by Gopalan et al. (2022), has centered around the concept of simultaneous loss minimization, also known as _omnipediction_. Garg et al. (2024) study an online adversarial version of it, and U-calibration can be seen as a special non-contextual case of their setting with only proper losses considered. Their results, however, are not applicable here due to multiple reasons: for example, they consider only the binary case (\(K=2\)), and their algorithm is either only designed for Lipschitz convex loss functions or computationally inefficient. We also note that omniprediction has been shown to have a surprising connection with multicalibration (Hebert-Johnson et al., 2018), a multi-group fairness notion, making it an increasingly important topic (Gopalan et al., 2022; Blasiok et al., 2024; Gopalan et al., 2023a, b).

## 2 Preliminaries

Notation:We use lowercase bold alphabets to denote vectors. \(\), \(_{ 0}\) denote the set of positive, non-negative integers respectively. For any \(m\), \([m]\) denotes the index set \(\{1,,m\}\). We use \(_{K}\) to denote the \((K-1)\)-dimensional simplex, i.e., \(_{K}\{^{K} p_{i} 0,_{i=1}^{K}p_{i }=1\}\). The \(i\)-th standard basis vector (dimension inferred from the context) is denoted by \(_{i}\), and we use \(\) to represent the set \(\{_{1},,_{K}\}\) of all basis vectors of \(^{K}\). By default, \(\|\|\) denotes the \(_{2}\) norm.

Proper Losses:Throughout the paper, we consider the class of bounded proper losses \(\{:_{K}[-1,1]\}\) or a subset of it. We emphasize that convexity (in the first argument) is never needed in our results. As mentioned, a loss \(\) is proper if predicting the true distribution from which the outcome is sampled from gives the smallest loss in expectation, that is, \(_{}[(,)]_{ }[(^{},)]\) for all \(,^{}_{K}\).

For a proper loss \(\), we refer to \((,)\) as its _bivariate_ form. The _univariate_ form of \(\) is defined as \(()_{}[(,)]\). It turns out that a loss is proper only if its univariate form is concave. Moreover, one can construct a proper loss using a concave univariate form based on the following characterization lemma.

**Lemma 1** (Theorem 2 of Gneiting and Raftery (2007)).: _A loss \(:_{K}\) is proper if and only if there exists a concave function \(f\) such that \((,)=f()+_{},-\) for all \(_{K},\), where \(_{}\) denotes a subgradient of \(f\) at \(\). Also, \(f\) is the univariate form of \(\)._

We provide several examples of proper losses below:* The spherical loss is \((,)=-,}{\|\|}\), which is \(\)-Lipschitz (Proposition B.1) but _non-convex_ in \(\). Its univariate form is \(()=-\|\|\).
* The squared loss (also known as the Brier score) is \((,)=\|-\|^{2}\), which is clearly \(2\)-Lipschitz and convex in \(\). Its univariate form is \(()=1-\|\|^{2}\).
* Generalizing the squared loss, we consider the univariate form \(()=-_{K}_{i=1}^{K}p_{i}^{}\) for \(>1\) and some constant \(_{K}>0\), which is the Tsallis entropy and is concave. The induced proper loss is \((,)=_{K}(-1)_{i=1}^{K}p_{i}^{}- {c}_{K}_{i=1}^{K}p_{i}^{-1}y_{i}\), which is _not Lipschitz_ for \((1,2)\).*

Footnote *: Here, the scaling constant \(_{K}\) is such that \((,)[-1,1]\).

The following fact is critical for U-calibration: for any \(n\) and a sequence of outcomes \(_{1},,_{n}\), the _mean forecaster_ is always the empirical risk minimizer for any proper loss \(\): (the proof is by definition and included in Appendix B for completeness):

\[_{j=1}^{n}_{j}*{argmin}_{p_{K}} _{j=1}^{n}(,_{j}). \]

Problem Setting:As mentioned, the problem we study follows the following protocol: at each time \(t=1,,T\), a forecaster predicts a distribution \(_{t}_{K}\) over \(K\) possible outcomes, and at the same time, an adversary decides the true outcome encoded by a one-hot vector \(_{t}\), which is revealed to the forecaster at the end of time \(t\).

For a fixed proper loss function \(\), the regret of the forecaster is defined as: \(_{}_{t=1}^{T}(_{t},_{t})-_{ _{K}}_{t=1}^{T}(,_{t})\), which, according to property (1), can be written as \(_{t=1}^{T}(_{t},_{t})-_{t=1}^{T}(, _{t})\) where \(_{t=1}^{T}_{t}\) is simply the empirical average of all outcomes.

Our goal is to ensure low regret against a class of proper losses simultaneously. We define U-calibration error as \(_{}=[_{}_{}]\) and pseudo U-calibration error as \(_{}=_{}[_{}]\) for a family of loss functions \(\). Unless explicitly mentioned, \(\) denotes the set of all bounded (in \([-1,1]\)) proper losses and is dropped from the subscripts for convenience.

Oblivious Adversary versus Adaptive Adversary:As is standard in online learning, an oblivious adversary decides all outcomes \(_{1},,_{T}\) ahead of the time with the knowledge of the forecaster's algorithm (but not her random seeds), while an adaptive adversary decides each \(_{t}\) with the knowledge of past forecasts \(_{1},,_{t-1}\). Except for one result (upper bound on \(\) for a class with low-covering number), all our upper bounds hold for the stronger adaptive adversary, and all our lower bounds hold for the weaker oblivious adversary (which makes the lower bounds stronger).

## 3 Optimal U-calibration Error

In this section, we prove that the minimax optimal pseudo U-calibration error is \(()\).

### Algorithm

As mentioned, our algorithm makes a simple change to the noise distribution of the FTPL algorithm of Kleinberg et al. (2023) and in fact coincides with the algorithm of Daskalakis and Syrgkanis (2016) designed for a different setting. To this end, we start by reviewing their setting and algorithm. Specifically, Daskalakis and Syrgkanis (2016) consider the following online learning problem: at each time \(t[T]\), a learner chooses an action \(_{t}\) for some action set \(\); at the same time, an adversary selects an outcome \(_{t}\) from a finite set \(\{}_{1},,}_{K}\}\) of size \(K\); finally, the learner observes \(_{t}\) and incurs loss \(h(_{t},_{t})\) for some arbitrary loss function \(h:[-1,1]\) that is fixed and known to the learner. Daskalakis and Syrgkanis (2016) propose the following FTPL algorithm: at each time \(t\), randomly generate a set of hallucinated outcomes, where the number of each possible outcome \(}_{i}\) for \(i[K]\) follows independently a geometric distribution with parameter \(\), and then output the empirical risk minimizer using both the true outcomes and the hallucinated outcomes as the final action \(_{t}\). Formally, \(_{t}*{argmin}_{}_{i=1}^{K}Y_{t,i }h(,}_{i})\) where \(Y_{t,i}=|\{s<t_{s}=}_{i}\}|+m_{t,i}\)and \(m_{t,i}\) is an i.i.d. sample of a geometric distribution with parameter \(\). This simple algorithm enjoys the following regret guarantee.

**Theorem 1** (Appendix F.3 of Daskalakis and Syrgkanis (2016)).: _The FTPL algorithm described above satisfies the following regret bound: \([_{t=1}^{T}h(_{t},_{t})-_{ }_{t=1}^{T}h(,_{t})] 4,\) where the expectation is taken over the randomness of both the algorithm and the adversary._

Now we are ready to discuss how to apply their algorithm to our multiclass U-calibration problem. Naturally, we take \(=_{K}\) and \(=\). What \(h\) should we use when we care about all proper losses? It turns out that this does not matter (an observation made by Kleinberg et al. (2023) already): according to property (1), the mean forecaster taking into account both the true outcomes and the hallucinated ones (that is, \(p_{t,i}=Y_{t,i}/_{k=1}^{K}Y_{t,k}\)) is a solution of \(*{argmin}_{_{K}}_{i=1}^{K}Y_{t,i}h(, {e}_{i})\) for _any_ proper loss \(h\)! This immediately leads to the following result.

**Corollary 1**.: _Algorithm 1 ensures \( 4\) against any adaptive adversary._

We remark that the only difference of Algorithm 1 compared to that of Kleinberg et al. (2023) is that \(m_{t,i}\) is sampled from a geometric distribution instead of a uniform distribution in \(\{0,1,,\}\). Using such noises that are skewed towards smaller values leads to better trade-off between the stability of the algorithm and the expected noise range, which is the key to improve the regret bound from \((K)\) to \(()\).

### Lower Bound

We now complement the upper bound of the previous section with a matching lower bound. Similar to the Multi-Armed Bandit problem, the regime of interest is \(T=(K)\).

**Theorem 2**.: _There exists a proper loss \(\) with range \([-1,1]\) such that the following holds: for any online algorithm \(\), there exists a choice of \(_{1},,_{T}\) by an oblivious adversary such that the expected regret \([_{}]\) of \(\) is \(()\) when \(T 12K\)._

We defer to the proof to Appendix C and highlight the key ideas and novelty here. First, the proper loss we use to prove the lower bound takes the following univariate form \(()=-_{i=1}^{K}|p_{i}-|\), which is in fact a direct generalization of the so-called "V-shaped loss" studied in Kleinberg et al. (2023) for the binary case. More specifically, they show that in the binary case, V-shaped losses are the "hardest" in the sense that low regret with respect to all V-shaped losses directly implies low regret with respect to all proper losses (that is, low U-calibration error). On the other hand, they also prove that this is _not true_ for the general multiclass case. Despite this fact, here, we show that V-shaped loss is still the "hardest" in the multiclass case in a different sense: it is the hardest loss for any algorithm with \(=()\).

With this loss function, we then follow a standard probabilistic argument and consider a randomized oblivious adversary that samples \(_{1},,_{T}\) i.i.d. from the uniform distribution over \(\). For such an adversary, we argue the following: (a) the expected loss incurred by \(\) is non-negative, i.e., \([_{t=1}^{T}(_{t},_{t})] 0\), where the expectation is taken over \(_{1},,_{T}\) and any internal randomness in \(\); (b) the expected loss incurred by the benchmark is bounded as \([_{_{K}}_{t=1}^{T}(,_{t })]-c\) for some universal positive constant \(c\), where the expectation is over \(_{1},,_{T}\). Together, this implies that the expected regret of \(\) is at least \(c\) in this randomized environment, which further implies that there must exist one particular sequence of \(_{1},,_{T}\) such that the expectedregret of ALG is at least \(c\), finishing the proof. We remark that our proof for (b) is novel and based on an anti-concentration inequality for Bernoulli random variables (Lemma A.4).

We discuss some immediate implications of Theorem 2 below. First, it implies that in the online learning setting of Daskalakis and Syrgkanis (2016) where the adversary has only \(K\) choices (formally defined in Section 3.1), without further assumptions on the loss function, their FTPL algorithm is _minimax optimal_. To our knowledge this is unknown before.

Second, since \(=_{}[}_{}][ }_{^{}}]\) for any \(^{}\), Theorem 2 immediately implies a \(()\) lower bound on the pseudo multiclass U-calibration error. In fact, since \(\), the same lower bound holds for the actual U-calibration error.

**Corollary 2**.: _For any online forecasting algorithm, there exists an oblivious adversary such that \(=()\)._

### From \(\) to \(\)

We now make an attempt to bound the U-calibration error \(\) of Algorithm 1 for an oblivious adversary. Specifically, since the perturbations are sampled every round and the adversary is oblivious, using Hoeffding's inequality it is straightforward to show that for a fixed \(\) and a fixed \((0,1)\), the regret of Algorithm 1 with respect to \(\) satisfies \(_{} 4+}{{}} )}\) with probability at least \(1-\) (see Hutter et al. (2005, Section 9) or Lemma D.1). Therefore, for a finite subset \(^{}\) of \(\), taking a union bound over all \(^{}\) gives \(_{^{}}}_{} 4+^{}|}}{{}})}\) with probability at least \(1-\). Picking \(=1/T\) and using the boundedness of losses, we obtain \(_{^{}} 2+4+^{}|)}\). In Appendix D, we generalize this simple argument to any infinite subset \(^{}\) of \(\) with a finite \(\)-covering number \(M(^{},;\|.\|_{})\) and prove for any \(>0\),

\[_{^{}} 2+4 T+4+^{},;\|.\|_{}) )}. \]

Using this bound, we now give a concrete example of a simple parameterized family \(^{}\) for which \(_{^{}}=(+)\). Consider the parameterized class

\[^{}=\{_{1}(,)+(1-)_{2}(,)|\},\]

where \(_{1}(,),_{2}(,)\) are two fixed bounded and proper losses. It is straightforward to verify that \(_{}(,)_{1}(,)+(1-) _{2}(,)\), therefore \(^{}\).

To obtain an \((0,1)\) cover for \(^{}\), we consider the set \(\{0,,,1-,1\}\) which partitions the interval \(\) to \(\) smaller intervals each of length \(\). For each \(\), let \(c_{}\) denote the closest point to \(\) (break ties arbitrarily). Clearly, \(|-c_{}|\). Next, consider the function \(g_{}(,) c_{}_{1}(,)+(1-c_{ })_{2}(,)\). The class \(\{g_{}(,)|\}\) is clearly a \(2\) cover of \(^{}\) with size \(\). Thus, \(M(^{},;\|.\|_{})=()\). It then follows from (2) that

\[_{^{}}=( T++ )})=(+)\]

on choosing \(=\). On the other hand, in subsection 4.3 we shall argue that for this class with a specific example of \(_{2}\), FTL suffers linear U-calibration error (that is, \(_{^{}}=(T)\)).

## 4 Improved Bounds for Important Sub-Classes

In this section, we show that it is possible to go beyond the \(()\) U-calibration error for several broad sub-classes of \(\) that include important and common proper losses. These results are achieved by an extremely simple algorithm called Follow-the-Leader (FTL), which at time \(t>1\) forecasts*

Footnote *: The forecast at time \(t=1\) can be arbitrary.

\[_{t}=_{s=1}^{t-1}_{t}*{argmin}_{ _{K}}_{s=1}^{t-1}(,_{s}), \]that is, the average of the past outcomes. For notational convenience, we define \(_{t}=_{s=1}^{t}_{s}\) so that FTL predicts \(_{t}=_{t-1}}{t-1}\), with \(_{t-1,i}\) being the count of outcome \(i\) before time \(t\).

Importantly, since FTL is a deterministic algorithm, it's \(\) and \(\) are always trivially the same. Moreover, there is also no distinction between an oblivious adversary and an adaptive adversary because of this deterministic nature.

### Proper Lipschitz Losses

In this section, we show that \(( T)\) is the minimax optimal bound for \(\) and \(\) for Lipschitz proper losses. Specifically, we consider the following class of \(G\)-Lipschitz proper losses

\[_{G}\{|(, )-(^{},)| G\|-^{}\|,,^{}_{K},\}.\]

As discussed in Section 2, the two common proper losses, squared loss and spherical loss, are both in \(_{G}\) for some \(G\). Note that the class of \(_{G}\) is rich since according to Lemma 1 it corresponds to the class of concave univariate forms that are Lipschitz and smooth (see Lemma B.2). We now show that FTL enjoys logarithmic U-calibration error with respect to \(_{G}\).

**Theorem 3**.: _The regret of FTL for learning any \(_{G}\) is at most \(2+2G T\). Consequently, FTL ensures \(_{_{G}}=_{_{G}}=(G  T)\)._

Proof.: Using the standard Be-the-Leader lemma (see e.g., (Orabona, 2019, Lemma 1.2)) that says \(_{t=1}^{T}(_{t+1},_{t})_{_{K}}_ {t=1}^{T}(,_{t})\), the regret of FTL can be bounded as

\[_{} 2+_{t=2}^{T}(_{t},_{t})-(_{t+1},_{t}) 2+G_{t=2}^{T}\|_{t}-_{t+1} \|,\]

where the second inequality is because \(_{G}\). Next, since \(_{t}=_{t-1}}{t-1}\) and \(_{t+1}=_{t}}{t}\), we obtain

\[_{} 2+G_{t=2}^{T}\|_{t-1}}{t-1}- _{t}}{t}\|=2+G_{t=2}^{T}\|_{t-1}}{t(t-1 )}-_{t}}{t}\| 2+2G_{t=2}^{T},\]

where the equality follows since \(_{t}=_{t-1}+_{t}\) and the last inequality follows from the triangle inequality and \(\|_{t-1}\|\|_{t-1}\|_{1}=t-1\). Finally, since \(_{t=2}^{T}_{1}^{T}dz= T\), we obtain \(_{} 2+2G T\), which completes the proof. 

A closer look at the proof reveals that global Lipschitzness over the entire simplex \(_{K}\) is in fact not necessary. This is because, for example, in the term \((_{t},_{i})-(_{t+1},_{i})\) for some \(i[K]\), by the definition of FTL the corresponding coordinates \(p_{t,i}\) and \(p_{t+1,i}\) are almost always at least \(1/T\), with only one exception which is when \(t\) is the first time we have \(_{t}=_{i}\) and which we can ignore since the regret incurred is at most a constant. This means that having local Lipschitzness in a certain region is enough; see Lemma E.1 for details. Note that the loss induced by the Tsallis entropy (mentioned in Section 2) is exactly one such example where global Lipschitzness does not hold but local Lipschitzness does. We defer the concrete discussion of the regret bounds of FTL on this example to Section 4.2 (where yet another different analysis is introduced).

In the rest of this subsection, we argue that no algorithm can guarantee regret better than \(( T)\) for one particular Lipschitz proper loss, making FTL minimax optimal for this class.

**Theorem 4**.: _There exists a proper Lipschitz loss \(\) such that: for any algorithm \(\), there exists a choice of \(_{1},,_{T}\) by an oblivious adversary such that the expected regret of \(\) is \(( T)\)._

The loss we use in this lower bound is simply the squared loss \((,)=\|-\|^{2}\) with \(K=2\). While squared loss is known to admit \(( T)\) regret in other online learning problems such as that from Abernethy et al. (2008), as far as we know there is no study on our setting where the decision set is the simplex and the adversary has only finite choices. It turns out that this variation brings significant technical challenges, and our proof is substantially different from that of Abernethy et al. (2008). We defer the details to Appendix F and discuss the key steps below.

Step 1:Since squared loss is convex in \(\), by standard arguments it suffices to consider deterministic algorithms only (see Lemma F.1). Moreover, for deterministic algorithms, there is no difference between an oblivious adversary and an adaptive adversary so that the minimax regret can be written as

\[=_{_{1}_{K}}_{_{1} }_{_{T}_{K}}_{_{T} }[_{t=1}^{T}(_{t},_{t})-_{_{K}} _{t=1}^{T}(,_{t})].\]

To solve this, further define \(_{,r}\) recursively as \(_{,r}=_{_{K}}_{} _{+,r-1}+(,)\) with \(_{,0}=-_{_{K}}_{i=1}^{K}n_{i}( {p},_{i})\), so that \(\) is simply \(_{,T}\).

Step 2:Using the minimax theorem, we further show that \(_{,r}=_{_{K}}_{i=1}^{K}q_{i} _{+_{i},r-1}+()\) where the univariate form \(()\) is \(1-^{2}\) (as mentioned in Section 2). Recall that we consider only the binary case \(K=2\), so it is straightforward to give an analytical form of the solution to the maximization over \(_{K}\). Specifically, writing \(_{,r}=_{(n_{1},n_{2}),r}\) as \(_{n_{1},n_{2},r}\) to make notation concise, we show

\[_{n_{1},n_{2},r}=_{2}&_{1}-_{2}<-2,\\ _{1}-_{2})^{2}}{8}+_{1}+_{2}}{2}+&-2_{1}-_{2} 2,\\ _{1}&_{1}-_{2}>2,\]

where \(_{1}\) and \(_{2}\) are shorthands for \(_{n_{1}+1,n_{2},r-1}\) and \(_{n_{1},n_{2}+1,r-1}\) respectively. Next, by an induction on \(r\) we show that for all valid \(n_{1},n_{2},r\) it holds that \(-2_{1}-_{2} 2\) (Lemma F.2), therefore \(_{n_{1},n_{2},r}\) is always equal to \(_{1}-_{2})^{2}}{8}+_{1}+_{2}}{2}+\).

Step 3:By an induction on \(r\) again, we show that \(_{n_{1},n_{2},r}\) exhibits a special structure of the form

\[_{n_{1},n_{2},r}=-n_{2})^{2}}{2} u_{r}-n_{2}}{T}+v_{r},\]

where \(\{u_{r}\}_{r=0}^{T}\) and \(\{v_{r}\}_{r=0}^{T}\) are recursively defined via \(u_{r+1}=u_{r}+(u_{r}+)^{2}\) and \(v_{r+1}=}{2}+v_{r}+-\) with \(u_{0}=v_{0}=0\) (Lemma F.3). Since \(=_{0,0,T}=v_{T}\), it remains to show \(v_{T}=( T)\), which is done via two technical lemmas F.4 and F.5.

### Decomposable Losses

Next, we consider another sub-class of proper losses that are not necessarily Lipschitz. Instead, their univariate form is decomposable over the \(K\) outcomes and additionally satisfies a mild regularity condition. Specifically, we define the following class

\[_{}\{\ |\ ()_{i=1}^{K}_{i}(p_{i})_{i}(0,1)\ \}.\]

Both the squared loss and its generalization via Tsallis entropy discussed in Section 2 are clearly in this class \(_{}\), with the latter being non-Lipschitz when \((1,2)\). The spherical loss, however, is not decomposable and thus not in \(_{}\). We now show that FTL achieves logarithmic regret against any \(_{}\) (see Appendix G for the full proof).

**Theorem 5**.: _The regret of FTL for learning any \(_{}\) is at most \(2K+(K+1)_{}(1+ T)\) for some universal constant \(_{}\) which only depends on \(\) and \(K\). Consequently, FTL ensures \(_{_{}}=_{_{ }}=((_{_{}}_{ })K T)\)._

Proof Sketch.: We start by showing a certain controlled growth rate of the second derivative of the univariate form (see Appendix H for the proof).

**Lemma 2**.: _For a function \(f\) that is concave, Lipschitz, and bounded over \(\) and twice continuously differentiable over \((0,1)\), there exists a constant \(c>0\) such that \( f^{}(p) c(, )\) for all \(p(0,1)\)._Note that according to Lemma 1, each \(_{i}\) must be concave, Lipschitz, and bounded, for the induced loss to be proper and bounded. Therefore, using Lemma 2, there exists a constant \(c_{i}>0\) such that \(|_{i}^{}(p)| c_{i}(,)\) for each \(i\). The rest of the proof in fact only relies on this property; in other words, the regret bound holds even if one replaces the twice continuous differentiability condition with this (weaker) property.

More specifically, for each \(i[K]\), let \(_{i}\{t_{i,1},,t_{i,k_{i}}\}[T]\) be the subset of rounds where the true outcome is \(i\) (which could be empty). Then, using the Be-the-Leader lemma again and trivially bounding the regret by its maximum value for the (at most \(K\)) rounds when an outcome appears for the first time, we obtain

\[_{} 2K+_{i=1}^{K}_{t_{i}\{t _{i,1}\}}_{t},_{i})-(_{t+1},_{i})}{ _{t,i}}\,.\]

By using the characterization result in Lemma 1, we then express \((_{t},_{i})\) and \((_{t+1},_{i})\) in terms of the univariate forms \((_{t}),(_{t+1})\), and their respective gradients \((_{t}),(_{t+1})\). Next, using the concavity of \(_{i}\), the Mean Value Theorem, and Lemma 2, we argue that

\[_{t,i}_{j=1}^{K}_{,j}|p_{t+1,j}-p_{t,j}| (},}), \]

for some \(_{t}\) that is a convex combination of \(_{t}\) and \(_{t+1}\), and constant \(_{,i}=_{K} c_{i}\) (\(_{K}\) is the scaling constant such that \(()=_{K}_{i=1}^{K}_{i}(p_{i})\)). To bound (4), we consider the terms \(-p_{t,j}|}{_{t,j}}\) and \(-p_{t,j}|}{1-_{t,j}}\) individually and find that they are always bounded by either \(}\) or \(\) according to the update rule of FTL. Thus, we obtain

\[_{} 2K+_{}(_{1}+_{2}),_{1}=_{i=1}^{K}_{t_{i}\{t_{i,1}\}}},_{2}=_{i=1}^{K}_{t_{i}\{t_{i,1}\}},\]

and \(_{}=_{i=1}^{K}_{,i}\). Finally, direct calculation shows \(_{1} K(1+ T)\) and \(_{2} 1+ T\), which finishes the proof. 

To showcase the usefulness of this result, we go back to the Tsallis entropy example.

**Corollary 3**.: _For any loss \(\) with univariate form \(()=-_{K}_{i=1}^{K}p_{i}^{}\) for \((1,2)\) (the constant \(_{K}\) is such that the loss has range \([-1,1]\)), FTL ensures \(_{}=(_{K}(-1)K^{2} T)\)._

Proof.: As mentioned, our proof of Theorem 5 only relies on Lemma 2, and it is straightforward to verify that for the loss considered here, one can take the constant \(c\) in Lemma 2 to be \((-1)\), and thus the regret of FTL is \((K_{} T)\) with \(_{}=K_{K}(-1)\). 

On the other hand, if one were to use the proof based on local Lipschitzness (mentioned in Section 4.1 and discussed in Appendix E), one would only obtain a regret bound of order \((K+_{K}(-1)T^{2-} T)\), which is much worse (especially for small \(\)). Finally, we remark that for \( 2\), the bivariate form is Lipschitz, and thus FTL also ensures logarithmic regret according to Theorem 3.

### FTL Cannot Handle General Proper Losses

Despite yielding improved regret for Lipschitz and other special classes of proper losses, unfortunately, FTL is not a good algorithm in general when dealing with proper losses, as shown below.

**Theorem 6**.: _There exists a proper loss \(\) and a choice of \(_{1},,_{T}\) by an oblivious adversary such that the regret \(_{}\) of FTL is \((T)\)._

Proof.: The loss we consider is in fact the same V-shaped loss used in the proof of Theorem 2 that shows all algorithms must suffer \(()\) regret. Here, we show that FTL even suffers linear regret for this loss. Specifically, it suffices to consider the binary case \(K=2\) and the univariate form \(()=-(|p_{1}-|+|p_{2}-|)\). Using Lemma 1, we obtain the following bivariate form:

\[(,_{1})=-(p_{1}-), (,_{2})=-(p_{2}- ),\]

where the sign function is defined as \((x)=1\) if \(x>0\); \(-1\) if \(x<0\); \(0\) if \(x=0\). Therefore, \((,_{1})\) is equal to \(\) if \(p_{1}<\); \(0\) if \(p_{1}=\); \(-\) if \(p_{1}\). Similarly, \((,_{2})\) is equal to \(-\) if \(p_{1}\); \(0\) if \(p_{1}=\); \(\) if \(p_{1}\). Let \(T\) be even and \(_{t}=_{1}\) if \(t\) is odd, and \(_{2}\) otherwise. For such a sequence \(_{1},,_{T}\), the benchmark selects \(=_{t=1}^{T}_{t}=[,]\) and incurs \(0\) cost. On the other hand, FTL chooses \(_{t}=[,]\) when \(t\) is odd, and \(_{t}=[,]\) otherwise. Thus, the regret of FTL is \(_{}=_{t=2}^{T}(_{t},_{2})=\). This completes the proof. 

Consider the parametrized class in subsection 3.3, let \(K=2\), \(_{2}(,)\) correspond to the V-shaped loss in Theorem 6, and consider any \(_{1}(,)\). It follows from Theorem 6 that \(_{_{}}=(T)\) when \(=0\), therefore \(_{^{}}=_{}_{_ {}}=(T)\), whereas Algorithm 1 ensures \(_{^{}}=()\).

## 5 Conclusion and Future Directions

In this paper, we give complete answers to various questions regarding the minimax optimal bounds on multiclass U-calibration error, a notion of simultaneous loss minimization proposed by (Kleinberg et al., 2023) for the fundamental problem of making online forecasts on unknown outcomes. We not only improve their \(=(K)\) upper bound and show that the minimax pseudo U-calibration error is \(()\), but also further show that logarithmic U-calibration error can be achieved by an extremely simple algorithm for several important classes of proper losses.

There are many interesting future directions, including 1) understanding the optimal bound on the actual U-calibration error UCal, 2) generalizing the results to losses that are not necessarily proper, and 3) studying the contextual case and developing more efficient algorithms with better bounds compared to those in the recent work of Garg et al. (2024).