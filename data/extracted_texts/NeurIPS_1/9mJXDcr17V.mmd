# Beyond Invariance: Test-Time Label-Shift Adaptation

for Addressing "Spurious" Correlations

Qingyao Sun

Cornell University

qs234@cornell.edu

Work done as a master's student at the University of Chicago.

&Kevin Murphy

Google DeepMind

kpmurphy@google.com

&Sayna Ebrahimi

Google Cloud AI Research

saynae@google.com

&Alexander D'Amour

Google DeepMind

alexdamour@google.com

###### Abstract

Changes in the data distribution at test time can have deleterious effects on the performance of predictive models \(p(y|x)\). We consider situations where there are additional meta-data labels (such as group labels), denoted by \(z\), that can account for such changes in the distribution. In particular, we assume that the prior distribution \(p(y,z)\), which models the dependence between the class label \(y\) and the "nuisance" factors \(z\), may change across domains, either due to a change in the correlation between these terms, or a change in one of their marginals. However, we assume that the generative model for features \(p(x|y,z)\) is invariant across domains. We note that this corresponds to an expanded version of the widely used "label shift" assumption, where the labels now also include the nuisance factors \(z\). Based on this observation, we propose a test-time label shift correction that adapts to changes in the joint distribution \(p(y,z)\) using EM applied to unlabeled samples from the target domain distribution, \(p_{t}(x)\). Importantly, we are able to avoid fitting a generative model \(p(x|y,z)\), and merely need to reweight the outputs of a discriminative model \(p_{s}(y,z|x)\) trained on the source distribution. We evaluate our method, which we call "Test-Time Label-Shift Adaptation" (TTLSA), on several standard image and text datasets, as well as the CheXpert chest X-ray dataset, and show that it improves performance over methods that target invariance to changes in the distribution, as well as baseline empirical risk minimization methods. Code for reproducing experiments is available at [https://github.com/nalzok/test-time-label-shift](https://github.com/nalzok/test-time-label-shift).

## 1 Introduction

Machine learning systems are known to be sensitive to so-called "spurious correlations" (Geirhos et al., 2020; Wiles et al., 2022; Arjovsky et al., 2019) between irrelevant features of the inputs and the predicted output label. These features and their associated correlations are called "spurious" because they are expected to change across real-world distribution shifts. As a result, models that rely on such spurious correlations often have worse performance when they are deployed on a _target domain_ that is distinct from the _source domain_ on which they were trained (Geirhos et al., 2020; Izmailov et al., 2022). For example, Jabbour et al. (2020) show that neural networks trained to recognize conditions like pneumonia from chest X-rays can learn to rely on features that are predictive of patient demographics rather than the medical condition itself. When the correlation between demographicfactors and the condition change (e.g., when the model is deployed on a different patient population), the performance of such models suffers.

To address this issue, recent work has focused on learning predictors that are invariant to changes in spurious correlations across source and target domains, either using data from multiple environments (e.g., Arjovsky et al., 2019), or data where the labels for the nuisance factors are available at training time (Veitch et al., 2021; Makar et al., 2022; Puli et al., 2022; Makino et al., 2022).

However, "spurious" correlations can sometimes provide valuable prior information for examples where the input is ambiguous. Consider the example of calculating the probability that a patient has a particular disease given a positive test. It is well known that the underlying prevalence of the disease (i.e., prior probability it is present) in the patient population is highly informative for making this diagnosis; even if the test is highly sensitive and specific, the patient's probability of having the disease given a positive test may be low if the disease is rare given that patient's background (see, e.g., Bours, 2021). A similar logic applies in many prediction problems: if we can predict, say, patient demographics from the input, and the prevalence of the target label differs between demographic groups in the current patient population, then the demographic-relevant spurious features provide prior information that supplements the information in the target-relevant features of the input. Thus, if a model could be adjusted to use spurious features optimally in downstream target domains, it could substantially out-perform invariant predictors, as we show in this paper.2

Motivated by the above, in this paper we propose a test-time approach for optimally adapting to distribution shifts which arise due to changes in the underlying joint prior between the class labels \(y\) and the nuisance labels \(z\). We can view these changes as due to a hidden common cause \(u\), such as the location of a specific hospital. Thus we assume \(p_{s}(u) p_{t}(u)\), where \(p_{s}\) is the source distribution, and \(p_{t}\) is the target distribution. Consequently, \(p_{i}(y,z)=_{u}p(y,z|u)p_{i}(u)\) will change across domains \(i\). However, we assume that the generative model of the features is invariant across domains, so \(p_{i}( y,z)=p( y,z)\). See Figure 1 for an illustration of our modeling assumptions.

The key observation behind our method is that our assumptions are equivalent to the standard "label shift assumption", except it is defined with respect to an expanded label \(m=(y,z)\), which we call the meta-label. We call this the "expanded label shift assumption". This lets use existing label shift techniques, such as Alexandari et al. (2020), Lipton et al. (2018), Garg et al. (2020), to adapt our model using a small sample of _unlabeled_ data \(\{_{n} p_{t}()\}\) from the target domain to adjust for the shift in the prior over meta-labels, as we discuss in Section 3.2. Importantly, although our approach relies on the assumption that \(p( y,z)\) is preserved across distribution shifts, it is based on learning a _discriminative_ base model \(p_{s}(y,z,|\,)\), which we adjust to the target distribution \(p_{t}(y)\), as we explain in Section 3.1. Thus we do not need to fit a generative model to the data. We do need access to labeled examples of the confounding factor \(z\) at training time, but such data is often collected anyway (albeit in limited quantities) especially for protected attributes. Additionally, because it operates at test-time, our method does not require retraining to adapt the base model to multiple target domains. We therefore call our approach Test-Time Label Shift Adaptation (TTLSA).

We evaluate TTLSA on various standard image and text classification benchmarks, as well as the CheXpert chest X-ray dataset. We show that in shifted target domains TTLSA outperforms ERM (empirical risk minimization, which often uses spurious features inappropriately in target domains), as well as methods that train invariant classifiers (which ignore spurious features). Note, however,

Figure 1: Modeling assumptions. \(U\) is a hidden confounder that induces a spurious correlation between the label \(Y\) and other causal factors \(Z\), which together generate the features \(X\). The distribution of \(U\) can change between target and source domains, but the distribution of \(X\) given \(Y,Z\) is fixed.

that it has been shown that no single adaptation method can work under all forms of distribution shift (Veitch et al., 2021; Kaur et al., 2022). Our assumptions capture certain kinds of shift, but certainly not all. In particular, our method is unlikely to help with the kinds of problems studied in the domain adaptation literature, where there is covariate shift (i.e., a change from \(p_{s}()\) to \(p_{t}()\)) which is not captured by a change in the distribution over the causal factors \((y,z)\).

## 2 Related work

Spurious correlations, invariant learning, and worst-group performanceSpurious correlations have mostly been studied in the domain generalization literature (see e.g., (Koh et al., 2020; Gulrajani and Lopez-Paz, 2021)), in which a model is expected to generalize (i.e., achieve acceptable performance) in a target domain without access to any data from that target domain. In this problem setup, building predictors based on the principle of invariance or minimax optimality with respect to spurious correlation shifts is a natural approach.

Many of these methods make the same modeling assumptions as we do (shown in Figure 1); this is often referred to as an anti-causal prediction setting, since the labels cause (generate) the features rather than vice versa (Schoelkopf et al., 2012; Veitch et al., 2021; Makar et al., 2022; Puli et al., 2022; Zheng and Makar, 2022). These methods use the fact that an invariant predictor will satisfy certain conditional independencies, and employ regularizers that encourage the desired conditional independence. A related line of work tries to minimize the worst-case loss across groups (values of \(m=(y,z)\)) using distributionally robust optimization (see, e.g., Sagawa et al., 2020; Liu et al., 2021; Nam et al., 2022; Lokhande et al., 2022)). Recently, Idrissi et al. (2022) showed empirically that the "SUBG" method, which uses ERM on a group-balanced version of the data achieved by subsampling, can be an effective approach to learning worst-group-robust predictors in this setting.

Unsupervised domain adaptation and label shiftIn the Unsupervised Domain Adaptation (UDA) literature, we assume that unlabeled data from the target domain is available, either at training or test time. To make optimality guarantees, UDA methods require assumptions about the structure of the distribution shift. Methods are often categorized into whether they require a covariate shift assumption (i.e., that the discriminative distribution \(p(y)\) is preserved (see, e.g., Shimodaira, 2000)), or a label shift assumption (i.e., that generative distribution \(p( y)\) is preserved (Lipton et al., 2018; Garg et al., 2020)).

In the setting of Figure 1, neither the standard covariate shift nor label shift assumptions hold; however, the label shift assumption does hold with respect to the meta-label \(m=(y,z)\). Our primary contribution is to show that label shift adaptation techniques, such as Alexandari et al. (2020), when applied with respect to the meta-label, can also be used to adapt to changes due to spurious correlations.

Interestingly, in the "purely spurious" setting described in Makar et al. (2022), which is a special case of Figure 1, we can obtain a risk-invariant model as a special case, by adapting to a target distribution for which \(p_{t}(y,z)=p_{s}(y)p_{s}(z)\)(Veitch et al., 2021; Makar and D'Amour, 2022). 3 Based on this observation, we show that logit adjustment (Menon et al., 2021), a set of test- and training-time methods developed for long-tail learning, can be repurposed to do invariant learning when applied to the meta-label \(m=(y,z)\).

Methods using the expanded label shift assumptionThe "generative multi-task learning" or GMTL method of Makino et al. (2022) makes the same expanded label shift assumption that we do. However, instead of estimating \(p_{t}(y,z)\) from unsupervised target data, they instead assume that there is some value \(\) such that \(p_{t}(y,z)=p_{s}(y,z)^{1-}\). They state that choosing \(\) is an open problem, and therefore they report results for a range of possible \(\)'s. By contrast, we provide a way to estimate \(p_{t}(y,z)\), and we do not restrict it to have the above functional form.

In Jiang and Veitch (2022), they propose a method called Anti-Causal Transportable and Invariant Representation or "ACTIC" which also makes the same expanded label shift assumption that we do, and further relaxes the assumption that \(Z\) is observed during source training. However, they require access to examples from multiple source distributions, which they use to learn a domain invariant classifier. Furthermore, then require labeled \((x,y)\) examples to adapt their classifier at test time.

Test time adaptationThere is a growing Test Time Adaptation (TTA) literature that explores strategies for adapting a trained model at test time using unlabeled data from the target domain. These methods are based on various heuristics to adapt discriminative models without specifying strong assumptions on the distribution shift structure. For example, TENT (Wang et al., 2021) uses entropy minimization to update the batch normalization layers of a CNN, and MEMO (Zhang et al., 2021) uses ensembles of predictions for different augmentations of a test sample. Most of the TTA literature has focused on models that work on images (e.g., by leveraging data augmentation), so these techniques cannot be applied to embeddings or other forms of input. By contrast, our method can be applied to any classifier, even non-neural ones, such as random forests. For a more comprehensive review of TTA methods, see (Liang et al., 2023).

## 3 Test-Time Label Shift Adaptation

Our aim is to construct a Bayes optimal predictor for the target distribution, \(f_{t}()\), using a large labeled dataset from the source distribution, \(_{s}^{xyz}=\{(_{n},y_{n},z_{n}) p_{s}(,y,z)\}\), and a small unlabeled dataset from the target distribution, \(_{t}^{x}=\{_{n} p_{t}()\}\). The optimal prediction for the class label in the target domain is given by

\[f_{t}()= _{y}p_{t}(y|)=_{y}_{z}p_{t}(y,z|). \]

where the joint posterior over the class label \(y\) and the nuisance factor \(z\) is given by

\[p_{t}(y,z|) p_{t}(|y,z)p_{t}(y,z)=p_{s}(|y,z)p_{t}(y,z) \]

where the first step follows from Bayes' rule, and the second step follows from our causal stability assumption that \(p_{t}(|y,z)=p_{s}(|y,z)=p(|y,z)\).

The first key insight of our method is that we can use the EM algorithm (or other optimization methods) to estimate \(p_{t}(y,z)\) by maximizing the likelihood of the unlabeled target dataset, as explained in Section 3.2. The second key insight is that we can estimate the likelihood \(p(|y,z)\) up to a constant of proportionality by fitting a discriminative model on the source dataset, and then dividing out by the source prior:

\[p_{s}(|y,z)(y,z|)}{p_{s}(y,z)} \]

This is known as the "scaled likelihood trick" (Renals et al., 1994), and avoids us having to fit a generative model. We can estimate \(p_{s}(y,z|)\) using any supervised learning method. However, to get good performance in practice, we need to ensure the probabilities are calibrated, as we explain in Section 3.1. Finally, we can estimate the source prior \(p_{s}(y,z)\) just by counting how often each \((y,z)\) combination occurs in \(_{s}^{xyz}\) and then normalizing. Combining Equation (2) with Equation (3) we can compute the posterior distribution over augmented labels from the unlabeled target data as follows:

\[p_{t}(y,z|)(y,z|)}{p_{s}(y,z)}p_{t}(y,z). \]

We can then compute \(f_{t}()\) using (1). In summary, our TTLSA method consists of the following two steps:

1. **Train on source.** Train a model \(p_{s}(y,z|)\) using supervised learning (and calibration) applied to \(_{s}^{xyz}\), as explained in Section 3.1. Also estimate \(p_{s}(y,z)\) from \(_{s}^{xyz}\) by counting.
2. **Adapt to target.** Estimate \(p_{t}(y,z)\) using EM applied to \(_{t}^{x}\), as explained in Section 3.2. Then compute \(p_{t}(y,z|)\) using (2) and \(f_{t}()\) using (1).

We discuss these steps in more detail below.

### Fit model to source distribution

In the first step, we fit a discriminative classifier \(p_{s}(y,z|)\) on the source dataset. This is just like a standard classification problem, except we use an augmented output space, consisting of the class label \(y\) and group label \(z\); we denote this joint label by \(m:=(y,z)\).

CalibrationOur adaptation procedure crucially relies on the fact that the output of the classifier, \(p_{s}(m|)\), can be interpreted as calibrated probabilities. Since modern neural networks are often uncalibrated (see, e.g., Guo et al., 2017), we have found it important to perform an explicit calibration step. (See the supplementary for an ablation study where we omit the calibration step.) Specifically, we follow Alexandari et al. (2020) and use their "bias corrected temperature scaling" (BCTS) method, which is a generalization of Platt scaling to the multi-class case. In particular, let \(l()\) be the vector of \(M\) logits. We then modify \(p_{s}(m|)\) as follows:

\[p_{s}(m|)()_{m}}{T}+b_{m}) \]

where \(T 0\) is a learned temperature parameter, and \(b_{m}\) is a learned bias. This calibration is done after the source classifier is trained using a labeled validation set from the source distribution.

Logit adjustmentThe calibration method is a post-hoc method. However, if the source distribution has a "shortcut", based on spurious correlations between \(z\) and \(y\), the discriminative model may exploit this by overfitting to it. The resulting model will not learn robust features, and will therefore be hard to adapt, even if we use calibration. To tackle this, we take inspiration from Proposition 1 of Makar et al. (2022), which showed that a classifier that is trained on the unconfounded or balanced distribution \(p_{b}\), such that \(p_{b}(y,z)=p_{s}(y)p_{s}(z)\), will not learn any "shortcut" between the confounding factor \(z\) and the target label \(y\). Such a model will therefore have a risk which is invariant to changes in the \(p(z|y)\) distribution, and, in "purely spurious" anti-causal settings (a special case of Figure 1, see footnote 3), they showed that this is indeed the optimal one among all risk-invariant predictors (see discussion in Section 2). If both marginals are uniform, then \(p_{b}(y,z) 1\), so the corresponding balanced version of the source distribution becomes \(p_{b}(m|)(m|)}{p_{s}(m)}\), which in log space becomes \((p_{b}(m|))(p_{s}(m|))-(p_{s}(m))\). We train our classifier to maximize this balanced objective; this is known as "logit adjustment" (Menon et al., 2021). After fitting, we can recover the classifier for the original source distribution using \(p_{s}(y,z|) p_{b}(y,z|)p_{s}(y,z)\). Finally we apply calibration to \(p_{s}(y,z|)\), as explained above. (Note that when the marginals are not uniform, one can apply a similar adjustment, subtracting off \((p_{s}(y,z)/(p_{s}(y)p_{s}(z))\).)

### Adapt model to target distribution

Given some unlabeled samples from the target distribution, \(^{x}_{t}=\{_{n} p_{t}():n=1:N\}\), our goal is to estimate the new prior, \(p_{t}(y,z)=p_{t}(m)=_{m}\). This is a standard subroutine in label shift adaptation methods (Lipton et al., 2018; Garg et al., 2020); our innovation is to do this with respect to the meta-label \(m\). Here, we use an EM approach (Alexandari et al., 2020), and maximize the log likelihood of the unlabeled data, \((;,)=_{_{n}} p_{t}(_{n };,)\), wrt \(\), where

\[p_{t}(;,)=(_{m}_{m}p_{t}(|m; {}))=(_{m}_{m}(m|;)}{p _{s}(m;)})+ \]

where \(\) are the parameters estimated from the source distribution. This objective is a sum of logs of a linear function of \(\), and is maximized subject to the affine constraints \(_{m} 0\) and \(_{m=1}^{M}_{m}=1\). Thus, under weak conditions on the ratios \(p_{s}(m|;)/p_{s}(m;)\) (these implied when \(\) contains some information that can discriminate between levels of \(m\)) the problem is concave, with a unique global optimum, implying the parameters are identifiable (Alexandari et al., 2020).

A simple way to compute this optimum is to use EM, which automatically satisfies the constraints. Let \(_{m}^{j}\) be the estimate of \(_{m}\) at iteration \(j\). We initialize with \(_{m}^{0}=p_{s}(m)\) and run the followingiterative procedure below:

\[p_{t}(m|_{n};^{j},)  p_{t}(_{n}|m;)_{m}^{j}(m|;)}{p_{s}(m;)}_{m}^{j} \] \[_{m}^{j+1} =_{n=1}^{N}p_{t}(m|_{n};^{j},) \]

We then set \(p_{t}(m)=_{m}^{J}\). We can also modify this to compute a MAP estimate, instead of the MLE, by using a Dirichlet prior. See the supplementary for a detailed derivation.

After estimating \(p_{t}(y,z)\) on \(_{t}^{x}\), we can compute \(p_{t}(y,z|)\) for the examples in \(_{t}^{x}\) using Equation (4).

## 4 Experiments

In this section, we provide an experimental comparison of our method with various baseline methods on a variety of datasets. In particular, we compare the following methods:

**ERM**: This corresponds to training a model on the source distribution, and then applying the same model to the target distribution without any adaptation, i.e., we assume \(p_{t}(y|)=p_{s}(y|)\).
**gDRO**: The group DRO method of (Sagawa et al., 2020) is designed to optimize the performance of the worst performing group. (We only use this method for the worst-group benchmarks in Section 4.3.)
**SUBG**: The "SUBG" method of (Idrissi et al., 2022) subsamples the data so there is an equal number of examples in each group \(m=(y,z)\), then trains a classifier by standard ERM. This is a simpler alternative to gDRO yet often achieves comparable performance.
**LA**: This is our logit adjustment method of Section 3.1, which approximates a domain invariant classifier by targeting a uniform prior on the source domain, thus avoid overfitting to spurious correlations.
**TTLSA**: This is our EM method of Section 3.2 that adapts the LA-based classifier using unlabeled data.
**Oracle**: This is similar to TTLSA, but we replace the EM procedure with the ground truth target meta-label prior \(p_{t}(y,z)\). This gives an upper bound on performance. (We only use this for the CMNIST experiments in Section 4.1 and the CheXpert experiments in Section 4.2, where we artificially control the degree of distribution shift.)

### Colored MNIST

In this section, we apply our method to the Colored MNIST dataset (Arjovsky et al., 2019; Gulrajani and Lopez-Paz, 2021).

Figure 2: Test set AUC performance on (a) Colored MNIST and (b) CheXpert as we vary the correlation between \(y\) and \(z\) in the target distribution. The vertical dotted line marks the source distribution. There are three performance regimes: (1) the unadapted ERM model (blue line) degrades smoothly under shift; (2) the invariant models (yellow, green, and red lines) have flat performance; and (3) the adapted models (purple and brown lines) out-perform invariant models, yielding a U-shape.

DatasetWe construct the dataset in a manner similar to (Arjovsky et al., 2019; Gulrajani and Lopez-Paz, 2021). Specifically, we create a binary classification problem, where label \(y=0\) corresponds to digits 0-4, and \(y=1\) corresponds to 5-9. We then sample a random color \(z\{0,1\}\), corresponding to red or green, for each image, with a probability that depends on the target distribution. See the supplementary material for a visualizaiton of this dataset. Since the color is easier to recognize than the shape, color can act as a "shortcut" to predicting the class label, even though this is not a robust (domain invariant) feature.

We create a set of 21 target distributions \(p_{}=(1-)p_{0}+ p_{1}\), where \(\{0,0.05,,0.95,1.0\}\), and \(p_{0}(y,z)\) and \(p_{1}(y,z)\) are two anchor distributions in which \(y\) and \(z\) are correlated and anti-correlated, respectively (see Table 1). By changing \(\), we can control the dependence between \(y\) and \(z\). We train the classifier on a source domain exhibiting a strong spurious correlation (we choose \(=0.05\)), and then apply the model to each target domain, \(p_{}\), for \(\{0,0.05,,0.95,1.0\}\). We measure performance using Area Under the ROC curve (AUC).

Training procedureDuring training, we fit a LeNet CNN on the training set by using \(m=(y,z)\) as the label. We use AdamW with a batch size of 64 and a learning rate of \(10^{-3}\) for a maximum of 5000 epochs, and run calibration for a maximum of 1000 epochs with the same learning rate and batch size on a 10% holdout set. However, training typically terminates much earlier since we also calculate the exponential moving average of the validation loss with a decay rate of 0.1, and stop early when the smoothed validation loss does not decrease for 5 consecutive epochs. During evaluation, we infer the target label prior for each target distribution using EM applied to an unlabeled test set of size 64 or 512, and we then predict the class labels on this test set. Finally we repeat this across all the unlabeled minibatches in the target distribution, and report the overall AUC.

ResultsFigure 1(a) shows our results, with error bars showing standard error of the mean across 4 trials. There are three main groups of curves. (1) The ERM model (black line) shows performance that gets steadily worse as the target distribution shifts away from the source. (2) The invariant models (SUBG in dashed orange and logit adjustment in solid red) are approximately constant across domains, as expected. (In this experiment, we see that logit adjustment outperforms SUBG.) 3) Our adaptive TTLSA models (blue curves), corresponding to TTLSA with 64 or 512 samples and the oracle method, all show a U-shaped curve, which is an upper bound on all the other curves. In particular, we see that the U-shaped curve is tangent to the invariant line when the target distribution is unconfounded (\(=0.5\)); in that case, there is no prior information from \(p_{t}(y,z)\) to exploit. However, in all other target domains, the adapted prior information improves performance. As we increase the size of the unlabeled target dataset, we see that the performance of TTLSA approaches that of the oracle. To illustrate the fact that our method can also be applied to non-neural net classifiers we also applied TTLSA on top a gradient boosted tree classifier. The results (shown in the supplementary) are qualitatively similar to those in Figure 1(a).

### CheXpert

Next, we apply our method to the problem of disease classification using chest X-rays based on the CheXpert (Irvin et al., 2019) dataset. Chest X-rays are a particularly relevant application area for our method because sensitive attributes, such as patient sex or self-reported race, can be readily predicted from chest X-rays (Gichoya et al., 2022). Recent work, e.g., Jabbour et al. (2020) and Makar et al. (2022), has confirmed the potential for classifiers to exploit these features as spurious features.

DatasetCheXpert has 224,316 chest radiographs of 65,240 patients. See the supplementary material for a visualizaiton of this dataset. Each image is associated with 14 disease labels derived

  & &  & &  \\  & & 0 & 1 & & 0 & 1 \\  y & 0 & 0.5 & 0 & & 0 & 0.5 \\
1 & 0 & 0.5 & & 0 & 0.5 & 0 \\ 

Table 1: The two “anchor” distributions, reflecting total positive and negative correlation between the class label \(y\) and the confounding factor \(z\). Left: \(p_{0}\). Right: \(p_{1}\). From these distributions, we can create a family of target distributions \(p_{}= p_{0}+(1-)p_{1}\).

from radiology reports, and 3 potentially confounding attributes (age, sex, and race), as listed in the supplementary. We binarized the attributes as in Jabbour et al. (2020), taking age to be 0 if below the median and 1 if above, and sex to be 0 if female and 1 if male. As for the class labels, we define class 0 as "negative" (corresponding to no evidence of a disease), and class 1 as "positive" (representing the presence of a disease); images labeled "uncertain" for the attribute of interest are discarded. Following (Glocker et al., 2022), we focus on predicting the label \(y\) = "Pleural Effusion" and use sex as the confounding variable \(z\). See Figure 4 for some samples from the dataset. For the input features \(\), we either work with the raw gray-scale images, rescaled to size \(224 224\), or we work with 1376-dim feature embeddings derived from the pretrained CXR model (Sellergren et al., 2022). This embedding model was pre-trained on a large set of weakly labeled X-rays from the USA and India. Note, however, that the pre-training dataset for CXR is distinct from the CheXpert dataset we use in our experiments.

To compare performance under distribution shift, we created a set of 21 distributions, \(p_{}=(1-)p_{0}+ p_{1}\), where \(\{0,0.05,,0.95,1.0\}\) as before. We train using \(=0.05\), representing a strong spurious correlation at training time, and test with all 21 values. The test images are distinct from the training, and each test distribution has 512 samples in total. Each patient may have multiple images associated with them, but there is no patient overlap in the training and test distributions.

Training procedureWhen working with embeddings, we use a linear logistic regression model, following Sellergren et al. (2022), due to its simplicity and its good performance. To train this, we use AdamW with a batch size of 64 and a learning rate of \(10^{-3}\) for a maximum of 5000 epochs, and run calibration for a maximum of 1000 epochs with the same learning rate and batch size on a 10% holdout set. However, training typically terminates much earlier since we also calculate the exponential moving average of the validation loss with a decay rate of 0.1, and stop early when the smoothed validation loss does not decrease for 5 consecutive epochs. When working with pixels, we use a CNN. See the supplementary for details.

ResultsOur results for the embedding version of the data are shown in Figure 2b. The trends are essentially the same as in the colored MNIST case. In particular, we see that our TTLSA method outperforms the invariant baselines, and both adaptive and invariant methods outperform ERM. These results for the pixel version of the data are shown in Appendix C.3 in the supplementary. We find that the relative performance of the methods is similar to the embedding case, but the absolute performance for all methods is better when using embeddings, as was previously shown in Sellergren et al. (2022).

DiscussionGlocker et al. (2022) point out that embeddings derived from X-ray classification models may contain information about sensitive attributes \(z\), such as sex and age. We confirmed this result, and were able to classify sex with an accuracy of over 95% just using logistic regression on the CXR embeddings, as shown in Table 3. Glocker et al. (2022) argue that this may be harmful, since it can cause bias in the predictions of the primary label \(y\) of interest (disease status). As a counterpoint, our results also show that, if we can predict both \(z\) and \(y\) from the embeddings, this information can be used to make optimal adjustments for target populations featuring very different demographic makeups, in ways that can be beneficial for all groups. However, our results also confirm such information does need to be handled with care.

### Worst-group vision and text benchmark datasets

In this section, we apply our method to four benchmark datasets that were first introduced in the group DRO paper (Sagawa et al., 2020), and have since been widely used in the literature on group robustness (see, e.g. Idrissi et al., 2022, on data balancing). The four datasets are as follows.

**CelebA**: Introduced in (Liu et al., 2015), this is an image dataset of celebrity faces. The class label \(y\) is hair color (blond / not-blond) and the group / attribute label \(z\) is sex (male / female).
**Waterbirds**: Introduced in (Wah et al., 2011; Sagawa et al., 2020), this is an image dataset of birds synthetically pasted onto two different kinds of backgrounds. The class label \(y\) is bird type (land bird or water bird), and the group / attribute label \(z\) is background type (land or water).

**MultNLI**: Introduced in [Williams et al., 2018], this is a dataset of sentence pairs, \((s_{1},s_{2}),\) where the goal is to predict if \(s_{1}\) entails \(s_{2}.\) The class label \(y\) corresponds to entailment, contradiction or neutral, and the group / attribute label \(z\) indicates presence / absence of negation words.
**CivilComments (CC)**: Introduced in [Borkan et al., 2019], This is a dataset of sentences from online forums. The class label \(y\) represents if the comment is toxic or not, and the group/attribute label \(z\) represents whether the content is related to a minority group (such as LGBT) or not.

Training procedureWe use the code and hyper-parameters specified in Idrissi et al.  for the ERM, gDRO, and SUBG baselines. We also use these same hyper-parameter values as ERM when fitting our own model TTLSA, which is trained to predict the augmented labels \(m=(y,z)\) using logit adjustment. We run the experiments on sixteen Nvidia A100 40GB GPUs. Depending on the dataset and method used, each experiment takes somewhere between 1 hour and 10 hours on an A100. In total, the experiments took 415 GPU hours.

For each method, for worst-group accuracy evaluations, we tune the model using worst-group accuracy in a validation set, whereas for average accuracy evaluations, we tune the model using average validation set accuracy. For worst-group evaluations, we use the LA baseline, without adjusting to the test set distribution. This effectively targets a balanced group distribution, similar to SUBG. For average target accuracy evaluations, we use the full TTLSA method with test-time EM adjustment.

ResultsWe summarize our results in Table 2. We report the worst group and average group accuracy, averaged across 4 replication runs. Our worst group numbers for the baseline methods are within error bars for those reported in Idrissi et al. .4 The Idrissi et al.  paper does not report average group performance, but we computed these results by modifying their code.

Overall, the results show that TTLSA offers a unified approach to achieve a variety of robustness objectives. In terms of average group accuracy, we find that the performance of TTLSA relative to ERM depends on the nature of the shift. For CelebA and MultiNLI, there is no significant distribution shift, so TTLSA is similar to ERM, as expected. For Waterbirds, the majority class in the source becomes much less common in the target (reflecting the fact that the rare combinations of waterbirds on land and land-birds on water become more frequent). TTLSA is able to adapt to this, and outperforms ERM. For CivilComments, the majority class becomes even more common in the target distribution. Although TTLSA can adapt to this change, it cannot match the fact that ERM has been "rewarded" for learning a representation that is optimized for a single majority class. In terms of worst-group accuracy, the unadapted LA baseline (which is a special case of TTLSA where we do not use EM adaptation) achieves competitive performance to the dedicated gDRO and SUBG methods.

## 5 Conclusions and future work

We have shown that adapting to changes in the nuisance factors \(Z\) can give better results than using classifiers that are designed to be invariant to such changes. However, a central weakness of our approach is that it requires that the generative distribution \(p(|y,z)\) be preserved across domains. This assumption becomes more plausible the more factors of variation are included in \(Z\). However, as \(Z\) becomes high dimensional, each step of our TTLSA method, as well as access to appropriate

 Data & \(m_{s}\) & \(m_{t}\) & ERM & gDRO & SUBG & LA/TTLSA \\  CelebA & 0.44 & 0.49 & 80.35 (1.46) /**95.35**(0.03) & **87.36**(0.47) / 94.58 (0.07) & **87.10**(1.26) / 93.44 (0.19) & 84.72 (0.58) / **95.55**(0.09) \\ Waterbirds & 0.73 & 0.39 & 85.78 (0.24) / 93.19 (0.16) & 87.98 (0.86) / 93.06 (0.62) & **88.87**(0.14) / 93.48 (0.11) & **88.38**(0.36) / **95.23**(0.34) \\ MultiNLI & 0.49 & 68.60 (0.40) / **87.20**(0.27) & **76.79**(1.24) / 81.16 (0.07) & 67.89 (0.91) / 72.15 (0.25) & **78.33**(1.45) / **82.60**(0.40) \\ CC & 0.55 & 0.65 & 68.16 (1.03) / **88.00**(0.03) & **79.66**(0.17) / 84.46 (0.43) & 76.56 (0.25) / 79.56 (0.77) & **79.27**(1.17) / 85.03 (0.71) \\ 

Table 2: Accuracy of the worst / average \((y,z)\) group on the benchmark datasets. We define \(m_{s}=(_{s})\) and \(m_{t}=(_{t})\) as the maximum probability of a \((y,z)\) group in the source and target distributions. The difference between these values reflects the degree of distribution shift.

data, becomes more challenging. In this vein, another weakness is that we require access to labeled examples of \(Z\) during training. In the future, we would like to relax this assumption, potentially by using semi-supervised methods (c.f., Sohoni et al., 2021; Lokhande et al., 2022; Nam et al., 2022) that combine small fully labeled datasets with large partially labeled datasets.5 We also plan to explore the use of fully unsupervised estimates of the confounding factors \(Z\), based on generative models, or by leveraging multiple source domains, similar to (Jiang and Veitch, 2022).