# Scaling transformer neural networks for skillful and reliable medium-range weather forecasting

Tung Nguyen1 Rohan Shah1,2 Hritik Bansal1 Troy Arcomano3 Romit Maulik3,4 Veerabhadra Kotamarthi3 Ian Foster3 Sandeep Madireddy3 Aditya Grover1

1UCLA 2CMU 3Argonne National Laboratory 4Penn State University

###### Abstract

Weather forecasting is a fundamental problem for anticipating and mitigating the impacts of climate change. Recently, data-driven approaches for weather forecasting based on deep learning have shown great promise, achieving accuracies that are competitive with operational systems. However, those methods often employ complex, customized architectures without sufficient ablation analysis, making it difficult to understand what truly contributes to their success. Here we introduce Stormer, a simple transformer model that achieves state-of-the-art performance on weather forecasting with minimal changes to the standard transformer backbone. We identify the key components of Stormer through careful empirical analyses, including weather-specific embedding, randomized dynamics forecast, and pressure-weighted loss. At the core of Stormer is a randomized forecasting objective that trains the model to forecast the weather dynamics over varying time intervals. During inference, this allows us to produce multiple forecasts for a target lead time and combine them to obtain better forecast accuracy. On WeatherBench 2, Stormer performs competitively at short to medium-range forecasts and outperforms current methods beyond 7 days, while requiring orders-of-magnitude less training data and compute. Additionally, we demonstrate Stormer's favorable scaling properties, showing consistent improvements with increases in model size and training tokens. Code and checkpoints are available at [https://github.com/tung-nd/stormer](https://github.com/tung-nd/stormer).

Figure 1: Illustration of an example \(5\)-day forecast of near-surface wind speed (color-fill) and mean sea level pressure (contours). On December 31, 2020, an extratropical cyclone impacted Alaska setting a new North Pacific low-pressure record. We evaluate the ability of Stormer to predict this record-breaking event 5 days in advance. Using initial conditions from 0000 UTC, 26 December 2011, Stormer successfully forecasts the location and strength of this extreme event with great accuracy.

Introduction

Weather forecasting is a fundamental problem for science and society. With increasing concerns about climate change, accurate weather forecasting helps prepare and recover from the effects of natural disasters and extreme weather events, while serving as an important tool for researchers to better understand the atmosphere. Traditionally, atmospheric scientists have relied on numerical weather prediction (NWP) models . These models utilize systems of differential equations describing fluid flow and thermodynamics, which can be integrated over time to obtain future forecasts [29; 2]. Despite their widespread use, NWP models suffer from many challenges, such as parameterization errors of important small-scale physical processes, including cloud physics and radiation . Numerical methods also incur high computation costs due to the complexity of integrating a large system of differential equations, especially when modeling at fine spatial and temporal resolutions. Furthermore, NWP forecast accuracy does not improve with more data, as the models rely on the expertise of climate scientists to refine equations, parameterizations, and algorithms .

To address the above challenges of NWP models, there has been an increasing interest in data-driven approaches based on deep learning for weather forecasting [11; 42; 48]. The key idea involves training deep neural networks to predict future weather conditions using historical data, such as the ERA5 reanalysis dataset [16; 17; 40; 41]. Once trained, these models can produce forecasts in a few seconds, as opposed to the hours required by typical NWP models. Because of the similar spatial structure between weather data and natural images, early works in this space attempted to adopt standard vision architectures such as ResNet [39; 8] and UNet  for weather forecasting, but their performances lagged behind those of numerical models. However, significant improvements have been made in recent years due to better model architectures and training recipes, and increasing data and compute [22; 35; 32; 3; 26; 5; 7]. Pangu-Weather , a 3D Earth-Specific Transformer model trained on 0.25\({}^{}\) data (721\(\)1440 grids), was the first model to outperform operational IFS . Shortly after, GraphCast  scaled up the graph neural network architecture proposed by Keisler  to 0.25\({}^{}\) data and showed improvements over Pangu-Weather. Despite impressive forecast accuracy, existing methods often involve highly customized neural network architectures with minimal ablation studies, making it difficult to identify which components contribute to their success. For example, it is unclear what the benefits of 3D Earth-Specific Transformer over a standard Transformer are, and how critical the multi-mesh message-passing in GraphCast is to its performance. A deeper understanding, and ideally a simplification, of these existing approaches is essential for future progress in the field. Furthermore, establishing a common framework would facilitate the development of foundation models for weather and climate that extend beyond weather forecasting .

In this paper, we show that a simple architecture with a proper training recipe can achieve state-of-the-art performance. We start with a standard vision transformer (ViT) architecture, and through extensive ablation studies, identify the three key components to the performance of the model: (1) a weather-specific embedding layer that transforms the input data to a sequence of tokens by modeling the interactions among atmospheric variables; (2) a randomized dynamics forecasting objective that trains the model to predict the weather dynamics at random intervals; and (3) a pressure-weighted loss that weights variables at different pressure levels in the loss function to approximate the density at each pressure level. During inference, our proposed randomized dynamics forecasting objective allows a single model to produce multiple forecasts for a specified lead time by using different combinations of the intervals for which the model was trained. For example, one can obtain a 3-day forecast by rolling out the 6-hour predictions 12 times or 12-hour predictions 6 times. Combining these forecasts leads to significant accuracy improvements, especially for long lead times. We evaluate our proposed method, namely **S**calable **t**ransformers for weather forecasting (Stormer), on WeatherBench 2 , a widely used benchmark for data-driven weather forecasting. Stormer achieves competitive forecast accuracy of key atmospheric variables for 1-7 days and outperforms the state-of-the-art beyond 7 days. Notably, Stormer achieves this performance by training on more than 5\(\) lower-resolution data and orders-of-magnitude fewer GPU hours compared to the baselines. Finally, our scaling analysis shows that the performance of Stormer improves consistently with increases in model capacity and data size, demonstrating the potential for further improvements.

## 2 Background and Preliminaries

Given a dataset \(=\{X_{i}\}_{i=1}^{N}\) of historical weather data, the task of global weather forecasting is to forecast future weather conditions \(X_{T}^{V H W}\) given initial conditions \(X_{0}^{V H W}\)in which \(T\) is the target lead time, e.g., 7 days; \(V\) is the number of input and output atmospheric variables, such as temperature and humidity; and \(H W\) is the spatial resolution of the data, which depends on how densely we grid the globe. This formulation is similar to many image-to-image tasks in computer vision such as segmentation or video frame prediction. However, unlike the RGB channels in natural images, weather data can contain up to \(100\)s of channels. These channels represent actual physical variables that can be unbounded in values and follow complex laws governed by atmospheric physics. Therefore, the ability to model the spatial and temporal correlations between these variables is crucial to forecasting.

There are three major approaches to data-driven weather forecasting. The first and simplest is _direct forecasting_, which trains the model to directly output future weather \(_{T}=f_{}(X_{0})\) for each target lead time \(T\). Most early works in the field adopt this approach [11; 42; 48; 39; 8; 49]. Since the weather is a chaotic system, forecasting the future directly for large \(T\) is challenging, which may explain the poor performances of these early models. Moreover, direct forecasting requires training one neural network for each lead time, which can be computationally expensive when the number of target lead times increases. To avoid the latter issue, _continuous forecasting_ uses \(T\) as an additional input: \(_{T}=f_{}(X_{0},T)\), allowing a single model to produce forecasts at any target lead time after training. MetNet [43; 12; 1] employed the continuous approach for nowcasting at different lead times up to \(24\) hours, WeatherBench  considered continuous forecasting as one of the baselines, and ClimaX  used this approach for pretraining. However, since this approach still attempts to forecast future weather directly, it suffers from the same challenging problem of forecasting the chaotic weather in one step. Finally, _iterative forecasting_ trains the model to produce forecasts at a small interval \(_{ t}=f_{}(X_{0})\), in which \( t\) is typically from 6 to 24 hours. To produce longer-horizon forecasts, we roll out the model by iteratively feeding its predictions back in as input. This is a common paradigm in both traditional NWP systems and the two state-of-the-art deep learning methods, Pangu-Weather and GraphCast. One drawback of this approach is error accumulation when the number of rollout steps increases, which can be mitigated by a multi-step loss function [22; 26; 5; 7]. In iterative forecasting, one can forecast either the weather conditions \(X_{ t}\) or the weather dynamics \(_{ t}=X_{ t}-X_{0}\), and \(X_{ t}\) can be recovered by adding the predicted dynamics to the initial conditions. In this work, we adopt the latter approach, which we refer to as _iterative dynamics forecasting_. We show empirically that our approach achieves superior performance relative to the former approach in Section 4.2. Figure 2 summarizes these different approaches.

## 3 Methodology

We introduce Stormer, a skillful method for weather forecasting, and show that a simple architecture can achieve competitive forecast performances with a well-designed framework. We first present the overall training and inference procedure of Stormer, then describe the model architecture we use in practice. Section 4.2 empirically demonstrates the importance of each component of Stormer.

Figure 2: Different approaches to weather forecasting. Direct and continuous methods output forecasts directly, but continuous forecasting is adaptable to various lead times by conditioning on \(T\). Iterative forecasting generates forecasts at small intervals \( t\), which are rolled out for the final forecast. Our proposed randomized iterative forecasting combines continuous and iterative methods.

### Training

We adopt the iterative approach for Stormer, and train the model to forecast the weather dynamics \(_{ t}=X_{ t}-X_{0}\), which is the difference between two consecutive weather conditions, \(X_{0}\) and \(X_{ t}\), across the time interval \( t\). A common practice in previous works [22; 26] is to use a small fixed value of \( t\) such as 6 hours. However, as we show in Figure 2(a), while small intervals tend to work well for short lead times, larger intervals excel at longer lead times (beyond 7 days) due to less error accumulation. Therefore, having a model that can produce forecasts at different intervals and combine them in an effective manner has the potential to improve the performance of single-interval models. This motivates our _randomized dynamics forecasting objective_, which trains Stormer to forecast the dynamics at random intervals \( t\) by conditioning on \( t\):

\[()=_{ t P( t),(X_{0},X_{ t}) }[||f_{}(X_{0}, t)-_{ t}||_{2}^{2 }], \]

in which \(P( t)\) is the distribution of the random interval. In our experiments, unless otherwise specified, \(P( t)\) is a uniform distribution over three values \( t\{6,12,24\}\). These three time intervals play an important role in atmospheric dynamics. The 6 and 12-hour values help to encourage the model to learn and resolve the diurnal cycle (day-night cycle), one of the most important oscillations in the atmosphere driving short-term dynamics (e.g., temperature over the course of a day). The 24-hour value filters the effects of the diurnal cycle and allows the model to learn longer, synoptic-scale dynamics which are particularly important for medium-range weather forecasting .

From a practical standpoint, this randomized objective provides two benefits. First, randomizing \( t\) enlarges the training data, serving as data augmentation. Second, it allows a single trained model to generate various forecasts for a specified lead time \(T\) by creating different combinations of intervals \( t\) that sum to \(T\). For example, to forecast 7 days ahead, one could use 12-hour forecasts 14 times or 24-hour forecasts 7 times. Our experiments show that combining these forecasts is crucial for achieving good accuracy, especially for longer lead times. While both our approach and the continuous approach use the time interval as an additional input, we perform iterative forecasting instead of direct forecasting. This avoids the challenge of directly modeling chaotic weather and offers more flexibility for combining different intervals at test time.

#### 3.1.1 Pressure-weighted loss

Due to the large number of variables being predicted, we use a physics-based weighting function to weigh variables near the surface higher. Since each variable lies on a specific pressure level, we can use pressure as a proxy for the density of the atmosphere at each level. This weighting allows the model to prioritize near-surface variables, which are important for weather forecasting and have the most societal impact. The final objective function that we use for training is:

\[()=[_{v=1}^{V}_{i=1}^{H} _{j=1}^{W}w(v)L(i)(_{ t}^{vij}-_{ t}^{ vij})^{2}]. \]

The expectation is over \( t,X_{0}\), and \(X_{ t}\) which we omit for notational simplicity. In this equation, \(w(v)\) is the weight of variable \(v\), and \(L(i)\) is the latitude-weighting factor commonly used in previous

Figure 3: Preliminary results on forecasting surface temperature that led to the design choices of Stormer: (a) Different intervals are better at different lead times, (b) Weather-specific embedding is superior to standard ViT embedding, and (c) Adaptive layer norm outperforms additive embedding.

works to account for the non-uniformity when we grid the spherical globe [40; 22; 35; 32; 3; 26]. The pressure-weighted loss was first introduced by GraphCast , and we show that it also helps with a different architecture.

#### 3.1.2 Multi-step finetuning

To produce forecasts at a lead time beyond the training intervals, we roll out the model several times. Since the model's forecasts are fed back as input, the forecast error accumulates as we roll out more steps. To alleviate this issue, we finetune the model on a multi-step loss function. Specifically, for each gradient step, we roll out the model \(K\) times, and average the objective (2) over the \(K\) steps:

\[()=[_{k=1}^{K}_{v=1}^{ V}_{i=1}^{H}_{j=1}^{W}w(v)L(i)(_{k t}^{vij}- _{k t}^{vij})^{2}]. \]

In practice, we implement a three-phase training procedure for Stormer. In the first phase, we train the model to perform single-step forecasting, which is equivalent to optimizing the objective in (2). In the second and third phases, we finetune the trained model from the preceding phase with \(K\) = 4 and \(K\) = 8, respectively. We use the same sampled value of the interval \( t\) for all \(K\) steps. We tried randomizing \( t\) at each rollout step, but found that doing so destabilized training as the loss value at each step is of different magnitudes, hurting the final performance of the model. Multi-step finetuning was used in FourCastNet  and also adopted in more recent works [22; 26].

### Inference

At test time, Stormer can produce forecasts at any time interval \( t\) used during training. Thus the model can generate multiple forecasts for a target lead time \(T\) by creating different combinations of \( t\) that sum to \(T\). We consider two inference strategies for generating forecasts:

**Homogeneous**: In this strategy, we only consider homogeneous combinations of \( t\), i.e., combinations with just one value of \( t\). For example, for \(T\) = 24 we consider [6; 6; 6; 6], [12; 12], and .

**Best \(m\) in \(n\)**: We generate \(n\) different, possibly heterogeneous combinations of \( t\), validate each combination, and pick \(m\) combinations with the lowest validation losses for testing.

The two strategies offer a trade-off between efficiency and expressivity. The homogeneous strategy only requires running three combinations for each lead time \(T\), while best \(m\) in \(n\) provides greater expressivity. Upon determining these combinations and executing the model rollouts, we obtain the final forecast by averaging the individual predictions. This approach achieves a similar effect to ensembling in NWP, where multiple forecasts are generated by running NWP models with different perturbed versions of the initial condition . As target lead times extend beyond 5-7 days and individual forecasts begin to diverge due to the chaotic nature of the atmosphere, averaging these forecasts is a Monte Carlo integration approach to handle this sensitivity to initial conditions and the uncertainty in the analyses used as initial conditions . We note that our inference strategy is distinguished from that used in Pangu-Weather: while Pangu-Weather trains a separate model for each time interval \( t\), we train a single model for all \( t\) values by conditioning on \( t\). Additionally, while Pangu-Weather relies on a single combination of intervals to minimize rollout steps, our method improves forecast accuracy by averaging multiple forecasts derived from diverse combinations.

### Model architecture

We instantiate the framework in Section 3.1 with a simple Transformer -based architecture. Due to the similarity of weather forecasting to various dense prediction tasks in computer vision, one might consider applying Vision Transformer (ViT)  for this task. However, weather data is distinct from natural images, primarily due to its significantly higher number of input channels, representing atmospheric variables with intricate physical relationships. For example, the wind fields are closely related to the gradient and shape of the geopotential field, and redistribute moisture and heat around the globe. Effectively modeling these interactions is critical to forecast accuracy.

### Weather-specific embedding

The standard patch embedding module in ViT, which uses a linear layer for embedding all input channels within a patch into a vector, may not sufficiently capture the complex interactions among input atmospheric variables. Therefore, we adopt for our architecture a weather-specific embedding module, consisting of two components, _variable tokenization_ and _variable aggregation_.

**Variable tokenization** Given an input of shape \(V H W\), variable tokenization linearly embeds each variable independently to a sequence of shape \((H/p)(W/p) D\), in which \(p\) is the patch size and \(D\) is the hidden dimension. We then concatenate the output of all variables, resulting in a sequence of shape \((H/p)(W/p) V D\).

**Variable aggregation** We employ a single-layer cross-attention mechanism with a learnable query vector to aggregate information across variables. This module operates over the variable dimension on the output of the tokenization stage to produce a sequence of shape \((H/p)(W/p) D\). This module offers two primary advantages. First, it reduces the sequence length by a factor of \(V\), significantly alleviating the computational cost as we use transformer to process the sequence. Second, unlike standard patch embedding, the cross-attention layer allows the models to learn non-linear relationships among input variables, enhancing the model's capacity to capture complex physical interactions. We present the complete implementation details of the weather-specific embedding in Section B.

Figure 2(b) shows the superior performance of weather-specific embedding to standard patch embedding at all lead times from 1 to 10 days. A similar weather-specific embedding module was introduced by ClimaX  to improve the model's flexibility when handling diverse data sources with heterogeneous input variables. We show that this specialized embedding module outperforms the standard patch embedding even when trained on a single dataset, due to its ability to model interactions between atmospheric variables through cross-attention effectively.

#### 3.4.1 Stormer Transformer block

Following weather-specific embedding, the tokens are processed by a stack of transformer blocks . In addition to the input \(X_{0}\), the block also needs to process the time interval \( t\). We do this by replacing the standard layer normalization module used in transformer blocks with adaptive layer normalization (adaLN) . In adaLN, instead of learning the scale and shift parameters \(\) and \(\) as independent parameters of the network, we regress them with an one-layer MLP from the embedding of \( t\). Compared to ClimaX  which only adds the lead time embedding to the tokens before the first attention layer, adaLN is applied to every transformer block, thus amplifying the conditioning signal. Figure 2(c) shows the consistent improvement of adaLN over the additive lead time embedding used in ClimaX. Adaptive layer norm was widely used in both GANs [21; 4] and Diffusion [9; 36] to condition on additional inputs such as time steps or class labels. Figure 7 illustrates Stormer's architecture. We refer to  for illustrations of the weather-specific embedding block.

## 4 Experiments

We compare Stormer with state-of-the-art weather forecasting methods, and conduct extensive ablation analyses to understand the importance of each component in Stormer. We also study Stormer scalability by varying model size and the number of training tokens. We conduct all experiments on WeatherBench 2 (WB2) , a standard benchmark for data-driven weather forecasting.

**Data:** We train and evaluate Stormer on the ERA5 dataset from WB2, which is the curated version of the ERA5 reanalysis data provided by ECMWF . In its raw form, ERA5 contains hourly data from 1979 to the current time at 0.25\({}^{}\) (721\(\)1440 grids) resolution, with different atmospheric variables spanning 137 pressure levels plus the Earth's surface. WB2 downsamples this data to 6-hourly with 13 pressure levels and provides different spatial resolutions. In this work, we use the 1.40625\({}^{}\) (128\(\)256 grids) data. We use four surface-level variables - 2-meter temperature (T2m), 10-meter U and V components of wind (U10 and V10), and Mean sea-level pressure (MSLP), and five atmospheric variables - Geopotential (Z), Temperature (T), U and V components of wind (U and V), and Specific humidity (Q), each at \(13\) pressure levels {\(50\), \(100\), \(150\), \(200\), \(250\), \(300\), \(400\), \(500\), \(600\), \(700\), \(850\), \(925\), \(1000\)}. We use 1979 to 2018 for training, 2019 for validation, and 2020 for testing.

**Stormer architecture:** For the main comparison in Section 4.1, we report the results of our largest Stormer model with 24 transformer blocks, 1024 hidden dimensions, and a patch size of 2, which is equivalent to ViT-L except for the smaller patch size. We vary the model size and patch size in the scaling analysis. For the remaining experiments, we report the performance of the same model as for the main result, but with a larger patch size of 4 for faster training.

**Training:** For the main result in Section 4.1, we train Stormer in three phases, as described in Section 3.1.2. We train the model for 100 epochs for the first phase, 20 epochs for the second, and 20 epochs for the third. We perform early stopping on the validation loss aggregated across all variables, and evaluate the best checkpoint of the final phase on the test set. For the remaining experiments, we only train Stormer for the first phase due to computational constraints.

**Evaluation:** We evaluate Stormer and two deep learning baselines on forecasting nine key variables: T2m, U10, V10, MSLP, Z500, T850, Q700, U850, and V850. These variables are also used to report the headline scores in WB2. For each variable, we evaluate the forecast accuracy at lead times from 1 to 14 days, using the latitude-weighted root-mean-square error (RMSE) metric. For the main results, we use best \(m\) in \(n\) inference for rolling out Stormer as it yields the best result, with \(m\) = 32 and \(n\) = 128 chosen randomly from all possible combinations. For the remaining experiments, we use homogeneous inference for faster evaluations. We provide results on the non-ensemble version of Stormer, probabilistic metrics with IC perturbations, a comparison between two inference strategies, and additional ablation studies in Appendix C.

### Comparison with State-of-the-art models

We compare the forecast performance of Stormer with Pangu-Weather  and GraphCast , two leading deep learning methods for weather forecasting. Pangu-Weather employs a 3D Earth-Specific Transformer architecture trained on the same variables as Stormer, but with hourly data and a higher spatial resolution of 0.25\({}^{}\). GraphCast is a graph neural network that was trained on 6-hourly ERA5 data at 0.25\({}^{}\), using 37 pressure levels for the atmospheric variables, and two additional variables,

Figure 4: Global forecast results of Stormer and the baselines. We show the latitude-weighted RMSE for select variables. Stormer is on par or outperforms the baselines for the shown variables. During the later portion of the forecasts, Stormer gains \( 1\) day of forecast skill with respect to climatology compared to the next best deep learning model. We note that Stormer was trained on much lower resolution data (1.40625\({}^{}\)) compared to Pangu-Weather (0.25\({}^{}\)) and GraphCast (0.25\({}^{}\)).

total precipitation and vertical wind speed. Both Pangu-Weather and GraphCast are iterative methods. GraphCast operates at 6-hour intervals, while Pangu-Weather uses four distinct models for 1-, 3-, 6-, and 24-hour intervals, and combines them to produce forecasts for specific lead times. We include Climatology as a simple baseline. We also compare Stormer with IFS HRES, the state-of-the-art numerical forecasting system, and IFS ENS (mean), which is the ensemble version of IFS. Since WB2 does not provide forecasts of these numerical models beyond \(10\) days, we defer the comparison against these models to Appendix C.1.

**Results:** Figure 4 evaluates different methods on forecasting nine key weather variables at lead times from \(1\) to \(14\) days. For short-range, 1-\(5\) day forecasts, Stormer's accuracy is on par with or exceeds that of Pangu-Weather, but lags slightly behind GraphCast. _At longer lead times, Stormer excels, consistently outperforming both Pangu-Weather and GraphCast from day 6 onwards by a large margin._ Moreover, the performance gap increases as we increase the lead time. At \(14\) day forecasts, Stormer performs better than GraphCast by \(10\%-20\%\) across all \(9\) key variables. Stormer is also the only model in this comparison that performs better than Climatology at long lead times, while other methods approach or even do worse than this simple baseline. The model's superior performance at long lead times is attributed to the use of randomized dynamics training, which improves forecast accuracy by averaging out multiple forecasts, especially when individual forecasts begin to diverge.

Moreover, we also note that Stormer achieves this performance with much less compute and training data compared to the two deep learning baselines. We train Stormer on 6-hourly data of 1.40625\({}^{}\) with 13 pressure levels, which is approximately 190\(\) less data than Pangu-Weather's hourly data at 0.25\({}^{}\) and 90\(\) less than that used for GraphCast, which also uses 6-hourly data but at a 0.25\({}^{}\) resolution with 37 pressure levels. The training of Stormer was completed in under 24 hours on 128 A100 GPUs. In contrast, Pangu-Weather took 60 days to train four models on 192 V100 GPUs, and GraphCast required 28 days on 32 TPUv4 devices. This training efficiency will facilitate future works that build upon our proposed framework.

### Ablation studies

We analyze the significance of individual elements within Stormer by systematically omitting one component at a time and observing the difference in performance.

**Impact of randomized forecasts:** We evaluate the effectiveness of our proposed randomized iterative forecasting approach. Figure 4(a) compares the forecast accuracy on surface temperature of Stormer and three models trained with different values of \( t\). Stormer consistently outperforms all single-interval models at all lead times, and the performance gap widens as the lead time increases. We attribute this result to the ability of Stormer to produce multiple forecasts and combine them to improve accuracy. We note that Stormer achieves this improvement with no computational overhead compared to the single-interval models, as the different models share the same architecture and were trained for the same duration.

**Impact of pressure-weighted loss:** Figure 4(b) shows the superior performance of Stormer when trained with the pressure-weighted loss. Intuitively, the weighting factor prioritizes variables that are nearer to the surface, as these variables are more important for weather forecasting and climate science.

Figure 5: Ablation studies showing the importance of different components in Stormer: (a) Randomized forecasting, (b) Pressure-weighted loss, and (c) Dynamics forecasting.

**Dynamics vs. absolute forecasts:** We justify our decision to forecast the dynamics \(_{ t}\) by comparing with a counterpart that forecasts \(X_{ t}\). Figure 4(c) shows that forecasting the changes in weather conditions (dynamics) is consistently more accurate than predicting complete weather states. One possible explanation for this result is that it is simpler for the model to predict the changes between two consecutive weather conditions than the entire state of the weather; thus, the model can focus on learning the most significant signal, enhancing forecast accuracy.

### Scaling analysis

We examine Stormer's scalability in terms of model size and training tokens. We evaluate three variants - Stormer-S, Stormer-B, and Stormer-L, with parameter counts similar to ViT-S, ViT-B, and ViT-L, respectively. To understand the impact of training token count, we vary the patch size from \(2\) to \(16\), quadrupling the training tokens each time the patch size is halved. Figure 6 shows a significant improvement in forecast accuracy with larger models, and the performance gap widens with increased lead time. Since we do not perform multi-step fine-tuning for these models, minor performance differences at short intervals may magnify over time. While multi-step fine-tuning could potentially reduce this gap, it is unlikely to eliminate it entirely. Reducing the patch size also improves the performance of the model consistently. From a practical view, smaller patches mean more tokens and consequently more training data. From a climate perspective, smaller patches capture finer weather details and processes not evident in larger patches, allowing the model to more effectively capture physical dynamics that drive weather patterns.

## 5 Related Work

**Deterministic weather forecasting** Deep learning offers a promising approach to weather forecasting due to its fast inference and high expressivity. Early efforts [11; 42; 48] attempted training simple architectures on small weather datasets. To facilitate progress, WeatherBench  provided standard datasets and benchmarks, leading to subsequent works that trained Resnet  and UNet architectures  for weather forecasting. These works showed the potential of deep learning but still displayed inferior accuracy to numerical systems. However, significant improvements have been made in the last few years. Keisler  proposed a graph neural network (GNN) that performs iterative forecasting with \(6\)-hour intervals, performing comparably with some NWP models. FourCastNet  trained an adaptive Fourier neural operator and was the first neural network to run on \(0.25^{}\) data. Pangu-Weather , with its 3D Earth-Specific Transformer design, trained on high-resolution data, surpassed the benchmark IFS model. Following this, GraphCast  scaled up Keisler's GNN architecture to \(0.25^{}\), achieving even better results than Pangu-Weather. FuXi  was a subsequent work that trained a SwinV2  on \(0.25^{}\) data and showed improvements over GraphCast at long lead times. However, FuXi requires finetuning multiple models specialized for different time ranges, increasing model complexity and computation. FengWu  was a concurrent work with FuXi that also focused on improving long-horizon forecasts, but has not revealed complete model architecture and training details. ClimODE  introduced physical inductive biases to provide better interpretability but was empirically inferior to existing methods.

**Probabilistic weather forecasting** In addition to high accuracy, a desired ability of a weather forecasting model is to quantify forecast uncertainty. One common approach to achieve this is to combine an existing architecture with a probabilistic loss function. Gencast  was one of the first

Figure 6: Stormer improves consistently with larger models (left) and smaller patch sizes (right).

works in this direction, combining the Graphcast architecture with a diffusion objective [18; 21], followed by Graph-EFM , which combined a hierarchical variant of Graphcast with the VAE objective . This approach allows the model to generate multiple forecasts and estimate uncertainty after training. In an orthogonal approach, NeuralGCM  proposed a hybrid forecasting system that combined a differentiable dynamical core with ML components for end-to-end training. The dynamical core allows the method to leverage powerful general circulation models and generate forecast ensembles via IC perturbations similar to NWP. However, the dynamical core in NeuralGCM is more computationally expensive than forward-passing a neural network and can limit the method's performance with an imperfect circulation model.

## 6 Conclusion and Future Work

This work proposes Stormer, a simple yet effective deep learning model for weather forecasting. We demonstrate that a standard vision architecture can achieve competitive results with a carefully designed training recipe. Our novel approach, randomized iterative forecasting, trains the model to forecast at different time intervals, enabling it to produce and combine multiple forecasts for each target lead time for better accuracy. Experiments show Stormer's competitive accuracy in short-range forecasts and exceptional performance beyond 7 days, all with significantly less data and computing resources. Future research could explore using multiple forecasts to quantify uncertainty, randomizing other model components like input variables to increase variability and accuracy, and evaluating Stormer on higher-resolution data and larger model sizes due to its favorable scaling properties.

## 7 Acknowledgments

AG acknowledges support from Google, Cisco, and Meta. SM is supported by the U.S. Department of Energy, Office of Science, Advanced Scientific Computing Research, through the SciDAC-RAPIDS2 institute under Contract DE-AC02-06CH11357. RM and VK are supported under a Laboratory Directed Research and Development (LDRD) Program at Argonne National Laboratory, through U.S. Department of Energy (DOE) contract DE-AC02-06CH11357. TA is supported by the Global Change Fellowship in the Environmental Science Division at Argonne National Laboratory (grant no. LDRD 2023-0236). RM acknowledges support from DOE-FOA-2493: "Data intensive scientific machine learning". An award for computer time was provided by the U.S. Department of Energy's (DOE) Innovative and Novel Computational Impact on Theory and Experiment (INCITE) Program and Argonne Leadership Computing Facility Director's discretionary award. This research used resources from the Argonne Leadership Computing Facility, a U.S. DOE Office of Science user facility at Argonne National Laboratory, which is supported by the Office of Science of the U.S. DOE under Contract No. DE-AC02-06CH11357.