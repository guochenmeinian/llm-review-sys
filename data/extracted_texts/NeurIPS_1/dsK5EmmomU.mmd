# Assemblage: Automatic Binary Dataset Construction for Machine Learning

Chang Liu\({}^{1}\), Rebecca Saul\({}^{2}\), Yifhao Sun\({}^{1}\), Edward Raff\({}^{2,3}\),

**Maya Fuchs\({}^{2}\)**, **Townsend Southard Pantano\({}^{1}\)**, **James Holt\({}^{4}\)**, **Kristopher Micinski\({}^{1}\)**

\({}^{1}\)Syracuse University,\({}^{2}\)Booz Allen Hamilton,

\({}^{3}\) University of Maryland, Baltimore County, \({}^{4}\)Laboratory for Physical Sciences

cliu57@syr.edu, Saul_Rebecca@bah.com, ysun@syr.edu, Raff_Edward@bah.com,

fuchs_maya@bah.com, tgsoutha@syr.edu, holt@lps.umd.edu, kkmicins@syr.edu

Equal contributions

###### Abstract

Binary code is pervasive, and binary analysis is a key task in reverse engineering, malware classification, and vulnerability discovery. Unfortunately, while there exist large corpora of malicious binaries, obtaining high-quality corpora of benign binaries for modern systems has proven challenging (e.g., due to licensing issues). Consequently, machine learning based pipelines for binary analysis utilize either costly commercial corpora (e.g., VirusTotal) or open-source binaries (e.g., coreutils) available in limited quantities. To address these issues, we present Assemblage: an extensible distributed system that crawls, configures, and builds Windows PE binaries to obtain high-quality binary corpora suitable for training state-of-the-art models in binary analysis. We have run Assemblage on AWS over the past year, producing 890k Windows PE and 428k Linux ELF binaries across 29 configurations. Assemblage is designed to be both reproducible and extensible, enabling users to publish "recipes" for their datasets, and facilitating the extraction of a wide array of features. We evaluated Assemblage by using its data to train modern learning-based pipelines for compiler provenance and binary function similarity. Our results illustrate the practical need for robust corpora of high-quality Windows PE binaries in training modern learning-based binary analyses. Assemblage code is open sourced under the MIT license, and the dataset can be downloaded from [https://assemblage-dataset.net/](https://assemblage-dataset.net/).

## 1 Introduction

Binary analysis, the task of understanding and analyzing an executable binary program, is extraordinarily labor-intensive. Practitioners often spend hours to weeks manually analyzing a single program . The development of automated binary analysis tools has also proven to be extremely labor-intensive. Historically, such tools have relied on careful and judicious software engineering efforts to handle all corner cases, or used SAT solvers and similar data structures to resolve as many conditions as possible . Given this high human effort, it is unsurprising that an increasing number of binary analysis methods use machine learning to help automate such efforts. This includes low-level tasks such as function disassembly , and high-level tasks like malware detection  or variable name identification [14; 39] which leverage these lower-level results.

However, significant issues in data availability have hampered the development of machine learning-based binary analysis for decades [1; 56]. Disassembly and decompilation require a mapping between the original true source or assembly code and the corresponding bytes of binary instructions, butit is non-trivial to collect and maintain such a mapping. Malware detection requires access to a collection of "benign" programs to train on, but can not be legally distributed due to copyright and license concerns. The situation is particularly bad for Windows Portable Executable (PE) binaries: while Windows is the most frequent target of malware, modern binary analysis systems train almost exclusively on Linux ELF binaries. Toolchain identification requires knowledge of the entire compilation process and of a variety of compiler settings that are simply not recorded in the original file. Binary function similarity requires having a ground truth of functions that are semantically equivalent but written or compiled differently; most existing models rely on coding competition data that does not reflect the diversity of real-world code. The ad-hoc approaches taken by prior works to tackle these issues further complicate the reproducibility of these methods due to the infrastructure challenges in setting up an environment to build the same tools and perform complex data pre-processing [25; 47; 54; 55]. Moreover, authors often do not have the necessary licenses or do not make the code publicly available for others to extend the work.

We introduce Assemblage, a tool that makes significant progress towards overcoming these challenges. Assemblage is a framework for crawling code hosting platforms, downloading open-source projects, compiling them with multiple different compiler versions and settings, and recording the necessary information to reconstruct byte-level mappings from the output back to the source code. By using open-source code targets from GitHub, we obtain greater diversity in programs, resolve licensing/distribution issues, and provide detailed ground truth to support all the aforementioned research areas. This alleviates the concerns with non-semantic preserving modifications  and the exorbitantly expensive cost and more limited diversity of binary re-writing [11; 68]. Assemblage is designed to be extensible so that additional sources of code, compilers, and feature extractors can be added for further functionality. Assemblage datasets can be further distributed as "recipes," a list of repositories and settings so that issues with mixed-license repositories (e.g., GPL and BSD) do not make a binary-based distribution unlicensable. Finally, we have designed and tested the system to ensure the reproducibility of datasets built by Assemblage.

Our contributions include:

**(1)** Assemblage, a cloud-based distributed system carefully engineered to automatically construct diverse corpora of high-quality Windows PE binaries while ensuring compliance with licensing and terms of service.

**(2)** The Assemblage dataset, consisting of Windows and Linux binaries with a total of 29 different combinations of CPU architecture, optimization level, compiler, compiler version, and other compiler flags.

**(3)** Three case studies that demonstrate Assemblage's application to (a) compiler provenance detection, (b) function similarity identification and (c) function boundary identification. Our case studies demonstrate the need for Assemblage's rich features, particularly for corpuses of Windows PE binaries.

## 2 Related Work

The PE Binary Availability CrisisSome prior works have looked at crawling open-source repositories to build datasets [10; 23; 43; 61] and leverage various build systems (such as DIRTY, XDA, and DIRE) . Unfortunately, all these prior works focus on Linux binaries and build systems due to their ease of use. We found that nearly half of the transformer-based models rely on executables from standard Linux packages such as _coreutils_, _binutils_, _diffutils_, _findutils_, _busybox_, _libcurl_ and _openssl_. With only one recent transformer-based model even testing on Windows PE Wu et al. . The heavy Linux reliance [15; 28; 31; 62] and use of ubiquitous libraries [3; 17; 30; 36; 47] is problematic since most malware is Windows PE, and these utilities do not reflect the breadth of code types in the wild. Work that does focus on Windows data is almost exclusively distributed in a pre-processed and featurized form, forgoing the original binaries due to licensing issues [4; 27; 41; 53; 60; 72; 73], or purely malware and lacks any source-binary mappings [34; 58].

The lack of datasets with available source-to-binary mapping is also a major impediment to current research trends in the binary analysis space. Lessons/models from Natural Language Processing in developing BERT  and GPT  have shown that both architecture and data scaling are key factors to improved results [12; 67]. While many works are building base binary models that can be fine-tuned to perform a wide variety of tasks , they predominantly use datasets that are too small or not diverse, as shown in Table 1 with a median of 3.7k binaries per LLM based model. Wang et al.  and Zhu et al.  are trained with the BinaryCorp dataset, which, at 48,130 (Linux) binaries, the largest prior work that still lacks Windows binaries, is not sufficiently diverse in binary behavior (as our results will show), and short of the 890k Windows PE and 428k Linux ELF binaries Assemblage provides. This is also true of works that tackle specific downstream tasks, including binary code similarity detection , compiler provenance identification , vulnerability detection , and malware detection .

Modern Efforts in Binary Analysis Ignore WindowsWith the increasing use of binary analysis in security-relevant settings, the absence of publicly available corpora of benign Windows binaries is a critical concern. The difficulty of obtaining Windows PE data in academic literature is prevalent in related domains like malware detection that rely on small datasets , effect sizes , and label noise , which generally depend on VirusShare and VirusTotal for data. An examination of files uploaded to VirusShare in 2023 indicates that 40.38% of the roughly 1.8 million malware samples are Windows binaries, whereas less than one percent are ELF binaries .2 Given the prevalence of Windows executables, and the fact that Windows accounts for roughly seventy percent of global operating system market share , it is troubling that nearly all the recent literature on machine learning approaches to binary analysis uses Linux binaries as training data. This is especially worrying because, as we demonstrate in Section 4, models trained on Linux binaries do not necessarily generalize to the Windows domain. Therefore, in order to produce useful machine learning models for binary analysis, it is necessary at a minimum to test, and likely necessary to train, these models on Windows data.

    &  **Binaries** \\ **(\#)** \\  } &  **Available** \\ **data format** \\  } &  **Functions** \\ **(\#, K)** \\  } &  **Projects** \\ **(\#)** \\  } &  &  &  \\   & & & & **L** & **W** & **G** & **C** & **M** & **MD** & **CP** & **FS** & **FN** & **DC** \\  SPEC &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\ CPU2006  & & & & & & & & & & & & & \\ Ubuntu &  &  &  &  &  &  &  &  &  &  &  &  \\ Dataset & & & & & & & & & & & & & \\ PF & & 2,132 & N/A & 1,362 & 5 & ✓ & ✓ & ✓ & & & ✓ & \\ PSI & 188, 253 & N/A & U & 14,000 & ✓ & U & U & & ✓ & & \\ Nero & 542 & Binaries & U & U & ✓ & U & U & U & & ✓ & \\ DIRE & 164,632 & Binaries & 3,196 & U & ✓ & U & U & ✓ & ✓ & & \\ BinKit & 243,128 & Binaries & 75,231 & 51 & ✓ & ✓ & ✓ & ✓ & ✓ & & \\ Passell & 552 & Binaries & 150 & 15 & ✓ & ✓ & ✓ & ✓ & & \\ DIRT & 75,656 & Binaries & 998 & U & ✓ & ✓ & & ✓ & & ✓ & \\ BinaryCorp & 48,130 & Binaries & 25,877 & 9,819 & ✓ & ✓ & ✓ & ✓ & ✓ & \\ -26M & & & & & & & & & & ✓ & ✓ & \\ BinBench & 1,127,479 & Binaries & 4,408 & U & ✓ & ✓ & ✓ & & ✓ & ✓ & \\ LLM4- & & & & & & & & & & & \\ Decompile & & U & Binaries & U & 164 & ✓ & ✓ & & & & & ✓ \\
**Assemblage** & **1,536,171** & 
 **Binaries** \\ **+PDB** \\  & **783,694** & **220,792** & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ \\   

Table 1: Comparison between Assemblage and related datasets. Prior datasets are often restricted in availability, do not have source-binary mappings, and are limited in platforms/toolchains, making it difficult to train and test for the diversity of real-world applications for binary analysis. Column names are abbreviated as; N/A: not available. L: Linux. W: Windows. G: GCC. C: Clang. M: MSVC. MD: malware detection. CP: compiler provenance. FS: function similarity. FN: function name/type recovery. DC: decompilation. PTY: The dataset is proprietary and for commercial license use. U: undisclosed or unknown.

The Assemblage Dataset

### Dataset Generation Pipeline

The overview of Assemblage is illustrated in Figure 2 and Figure 2. The grey area indicated in Figure 2 shows Assemblage's workflow, and it is implemented as a distributed system running on multiple servers for scalability. We also release the codes along with the dataset, and provides development and deployment documentation for it, more details are enclosed in our supplemental materials. First, the crawler begins by either sending queries to GitHub API to discover new repositories or crawl existing webpage hosting projects to obtain source codes. Then, source codes are cloned and modified to assign compiler flags such as optimization level and CPU architecture. On Windows, Assemblage uses the Microsoft Visual Studio tool chain, incorporating a set of automation scripts to overcome Visual Studio's reliance on GUI-based user interfaces; while on Linux, workers are implemented for both GCC and Clang, using Docker to facilitate flexible and isolated deployment. After compiling is completed, all files will be collected to extract information (e.g., function address, source codes, comments) and stored in files. The last step is to compress all files for storage.

### Dataset Details and Distribution

890k Windows-GitHub PE DatasetWe constructed a dataset of 890K Windows PE binaries as follows: starting from 4.6 million crawled GitHub repositories dating from 2008 to 2023, we discarded repositories that had fewer than 10 files, were smaller than 50KB in size, lacked a README.md file containing the string "Visual Studio", or lacked a solution file supporting Microsoft Visual Studio tool chains. We were left with 179,548 repositories, from which Assemblage was then able to build and store binaries using our Microsoft Visual Studio tool chains. Build configurations varied in toolchain version (Visual Studio 2015, 2017, 2019, and 2022), optimization level (0d, 01, 02, 0x), CPU architecture, and Debug/Release mode. In sum, we ended up with 847,856 executable (.exe) files and 43,507 dynamically-linked library (.dll) files, along with PDB files for each binary. In total, we accumulated 2TB worth of data, of which the executables (.exe and.dll files) took 200GB. To conform with ethical data distribution practices, we recorded license information from crawled repositories when available.

We measured our dataset along a variety of dimensions to demonstrate its quality and diversity. Figure 3 shows a histogram of sizes of binaries from our (a) Windows binaries from GitHub, (b) vcpkg and (c) Linux binaries from GitHub corpora.

Our Windows-GitHub binaries were the smallest overall, with an average size of 143KB. Manual inspection revealed many student projects, basic utilities, and starter codes in our GitHub dataset. However, in absolute terms, our Windows-GitHub dataset still contains a substantial number of large binaries, including 26,549 binaries \(\) 0.5MB. Note that compiling random Windows projects is non-trivial due to a lack of standardization; more details are provided in Appendix B.

We also inspected the function information corresponding to our Windows-GitHub PE dataset. We found that out of 252M functions, there are 14M unique function names, and 138M unique function hashes. Assemblage was also able to store source code for 17M functions in its SQL database. We also observed significant variation in the number of functions per binary, which we illustrate in Figure 4. Finally, we examined the relationship between a binary's size and the functions it contains. Counter-intuitively, the number of functions in a binary is not correlated with the size of that binary, as these variables have a Pearson correlation coefficient of 0.22. Furthermore, the size of functions within a binary has a 0.49 correlation coefficient to the binary size, but no correlation to the number of functions in the binary. We unexpectedly conclude that binary size doesn't have a strong correlation with either the number of functions nor the average function size in a binary. Moreover, the existence of function-level information provides insights into the behavior patterns of specific compilers. For example, in 2017 Visual Studio implemented stack-based buffer protection by inserting security cookies, and we can locate more than 744k __security_init_cookie functions with 151k unique hashes. These function level information provided by Assemblage presents valuable data for not only machine learning research but also a potential application to a wide range of research areas like security and binary analysis.

25k Windows vcpkg DatasetUpon examining our Windows-GitHub dataset, we observed that only 4.7% of the corpus consisted of library files. To address this deficiency and provide coverage of Windows' statically-linked and dynamically-linked libraries, we adapted Assemblage to build binaries from vcpkg , a dataset of 2,185 actively-developed, well-maintained, and widely-used packages. vcpkg consists of many commonly used and permissively licensed C++ libraries, including graphics and UI-related libraries.

Our vcpkg worker takes advantage of the native commands of vcpkg, and we modified the package manager's original build script to pass custom variables and flags to its compiler. In this way, we harvested a diverse Windows PE library corpus from vcpkg, comprising 24905 binaries, along with their pdb files, from 2078 different projects. Only 110 of these projects are also present in our Windows-GitHub dataset, demonstrating the added diversity that is present in our vcpkg dataset. Similarly to the Windows-GitHub dataset, vcpkg binaries were built using 4 different versions of the Microsoft Visual Studio toolchain, as well as with 4 optimization levels (-O{d,1,2,3}).

Finally, as illustrated in Fig. 4, the size of the binaries in our vcpkg dataset is larger than the size of those in our Windows-GitHub dataset. The vcpkg binaries were 2124 KB on average, compared to 143KB for Windows-Github binaries, with a small number (roughly 500) of vcpkg binaries \(\) 10 MB.

Proof-of-Concept Linux DatasetMotivated by the scarcity of corpora of benign Windows PE binaries, we have focused our efforts on building such executables. However, to ensure Assemblage's API was sufficiently expressive, we also added several Linux builders. Our prototype Linux crawler traverses GitHub and searches for Makefiles to identify potential Linux ELF projects. Among 4 million crawled repositories, Assemblage recognized 367,207 repositories that include a Makefile. We created 8 build configurations, using GCC (-O{0,1,2,Z}) and Clang (-O{0,1,2,3}).

Similar to what we did when building our Windows PE database, we deployed Assemblage to AWS with the same coordinator, but with workers on different EC2 instances. In sum, Assemblage generated 428,884 Linux binaries from 30,856 GitHub repositories. The histogram of the file size distribution of our Linux ELF dataset is shown in Figure 4, the composition of compiler and optimization level of the dataset is presented in Table 5, and the overall dataset size is recorded in Table 1. Interestingly, we observe a much higher frequency of licensed repositories in our Linux- GitHub dataset; nearly half of our Linux-GitHub binaries have licenses, compared to only 11% of our Windows-GitHub binaries.

Generally, our Linux builder failed more often than our Windows PE builder (a success rate of 7% compared to the 30% on Windows), but produced larger files in the projects that it did build. Though it is natural to be concerned about build failures during the dataset creation process, these errors are not introduced by Assemblage, as we simply use regular expression to substitute the compiler flags stored in the Make files, then call make to start the building. Indeed, a manual inspection confirmed that most of the build errors resulted from errors in the repository's source code or Make file.

In addition to the GitHub crawler, we also built a proof-of-concept crawler and builder that leverages the Arch User Repository (AUR) for source code. Users can set the configuration by providing custom makepkg.conf for each project. While the AUR repositories are well maintained by the community and open-sourced, due to the rate limits and ethical concerns, we did not deploy builders to generate a large scale dataset from AUR. However, our proof-of-concept crawler demonstrates that Assemblage can be configured to work with a variety of package managers.

Assemblage Dataset Distribution FormatWe only release the binaries built from repositories that clearly state their license, and a typical Assemblage dataset consists of both (a) an SQLite database of metadata and (b) an archive of binaries (either as a.tar or manually via the Amazon S3 interface). The SQL database provides a logical specification of a collection of binary files, currently.exes and.dlls. The user queries the SQLite database to perform application-specific feature extraction (e.g., identifying pairs of sibling functions for triplet learning), and often feeds the binaries into a machine learning framework such as TensorFlow, PyTorch, or Keras.

The SQLite database consists of four primary tables: binaries, functions, rvas, and lines (illustrated Figure 5). The binaries table retains a reference of each binary's configuration used during compilation, e.g. platform, build mode, compiler version, and optimization, and assigns each binary a unique identifier for further reference. We also register additional information about each executable including the file name, the location of the project on GitHub, the project's license, and the size of the binary in this table. Using the binaries table, researchers can curate subsets of the dataset to meet their training needs, e.g. by selecting only binaries of a certain size or with a certain license.

To provide function-level details and minimize the need to distribute PDB files (since, as we saw earlier, PDB files can take up 90+% of dataset space), the functions, rvas and lines tables reference the primary key for each binary stored in binaries table to relate functions and binaries. The functions tables offers a high-level overview of functions, presenting a hash of the function's bytes and the function name, whereas the rvas and lines tables provide lower-level function details. Specifically, the rvas table documents the relation between each function and its relative virtual address when the binary is loaded into memory. On the other hand, the lines table illustrates the mapping of each source code line to the precise byte address located in the compiled binary. The dataset also provides the relation between binaries and their corresponding PDB files in a pdbbs table, in case researchers want to make use of those files for further binary analysis.

Figure 5: Dataset database and usage

Figure 5 shows the information that is available about a single binary within a Assemblage dataset. As an example, we query the database for a binary called butler.exe, which has the unique identifier 184456.

In the binaries table, we get basic facts about the executable, including the compiler version (Visual Studio 2017), build mode (Release), optimization flag (O2), and associated license (MIT). In the functions table, we can see that this binary has 568 functions; in particular, we focus on one function called tinyxml2::StrPair::SetStr, uniquely identified by the tag 51629995. We use this unique identifier to query the lines and rvas tables for further information about this function. In the lines table, we can see the source code corresponding to this function, such as the line if (*(pu + 0) == TIXML_UTF_LEAD_0. From the rvas table, we learn that this function will be loaded into the relative addresses from Ox6460 to Ox644A. Thus, this example demonstrates how all the information needed to do binary analysis with corpuses of Assemblage executables is available in the accompanying Assemblage SQLite database.

**Ethical Concerns** It is natural to be concerned about the presence of malware in any corpus of binary executables. Assemblage builds sources from GitHub, which prohibits malware and allows users to report suspected malware to its community discussion board. Currently, Assemblage does not independently check for malware; we are looking to add malware scanning, following the model pioneered by EMBER , in the next iteration of the tool. In addition, the public GitHub repository links are included in our metadata (we do not provide author-level metadata, but plan to distribute this in the future in normalized form), which links the binary data to the author's GitHub profile. Our public datasets include only those repositories for which permissive licenses may be obtained; we facilitate archiving corpora of unlicensed repositories by distributing "recipes."

## 4 Benchmarks

In this section, we demonstrate the utility of Assemblage for a variety of machine learning tasks. Three widely-regarded machine learning approaches to binary analysis problems are evaluated under their original protocols, baring the minimum possible changes to support/read Windows PE files over the original Linux files: a LightGBM model for compiler provenance identification , a graph neural network (GNN) for binary function similarity detection , and a BERT-based transformer network for understanding binary files, fine-tuned on the task of binary function similarity detection . These experiments broadly show that the strong results of prior literature do not yet generalize to Windows and more diverse compilation settings, and that Assemblage provides the data to further explore these topics (amongst others).

Experiments were run on an Ubuntu 22.04 server equipped with an AMD EPYC 7713P@1.9Ghz 64-Core Processor and 512GB of RAM.

### Compiler Provenance

Compiler provenance inference is the task of determining the compiler configuration used to build a binary, including compiler version, build flags, and compiler passes. We trained a state-of-the-art provenance learning model PassTell  on a combination of data, mixing the authors' original Linux dataset with Windows PE binaries obtained from Assemblage. We first used Assemblage to build a dataset of Windows binaries that complemented the Linux binaries studied in the original PassTell paper. We attempted to build each of the 15 source projects selected by Du et al. , but due to differences between the Linux and Windows platforms and their respective compiler infrastructures, some projects could not be rebuilt. In total, we collected 127 binaries, which we proceeded to preprocess via the same protocol as the original paper. Though the PassTell authors used objdump, a linear disassembler, to extract function bytes, we found higher success rates with IDA Pro, augmented with the PDB files collected by Assemblage, to accurately handle the significant number (5%) of discontiguous functions present in Windows binaries. Following disassembly, we masked operands and literals in the same manner as Du et al. , and balanced the training data by compiler toolchain, version, and optimization level.

We evaluate PassTell twice, once using the aforementioned mix of original Linux and new Windows PEs and a second time using only Windows PEs. The confusion matrix in Figure 6 shows that the PassTell approach over-fits the original Linux models (top left diagonal), but has greater difficulty with the Windows PE files (bottom right). To determine if this is a capacity issue, we re-evaluate on only the Windows PEs to reduce the number of classes and make the ML problem easier, but Figure 7 shows that PassTell still struggles on Windows PEs with \( 58\%\) accuracy. The observation of PassTell's performance on Windows data indicates the limits of training models on small binary datasets lacking diversity. While the approach put forth by Du et al.  seemed promising when applied to a small Linux dataset, extending the work to Windows data from Assemblage revealed serious shortcomings. This underscores the utility of Assemblage as a tool for machine learning researchers in the binary analysis space.

### Binary Function Similarity

Next, we used Assemblage to evaluate how well a graph neural network (GNN) trained on Linux data generalizes to Windows binaries.

We conducted these experiments on the GNN developed by Li et al.  for binary function similarity detection, as implemented and open-sourced by Marcelli et al. .3

   Task &  Windows/ \\ Linux \\  &  Linux/ \\ Windows \\  &  Linux/ \\ Linux \\  & 
 Windows/ \\ Windows \\  \\  arch & 0.50 & — & 0.97 & — \\ bit & 0.70 & — & 0.99 & — \\ comp & 0.63 & — & 0.80 & — \\ opt & 0.72 & 0.62 & 0.88 & 0.89 \\ ver & 0.82 & 0.64 & 0.98 & 0.84 \\ XA & 0.48 & — & 0.86 & — \\ XC & 0.63 & — & 0.86 & — \\ XC+XB & 0.61 & — & 0.87 & — \\ XM & 0.54 & 0.61 & 0.87 & 0.86 \\   

Table 2: AUC scores evaluating binary function similarity model generalization between the Linux and Windows domains. Column names indicate train/test platform.

We made only one change to their data processing pipeline -- instead of removing singleton functions, we allowed them to stay in the dataset and be part of negative pairs, as they can still provide a training signal to the model this way and improved performance in a small-scale test.

Using Assemblage and Marcelli et al. 's protocol, we end up with 1.78 million functions for triplet learning. Negative pairs consist of two different functions, whereas positive pairs consist of functions originating from the same source code, but differing in one or more of the following: architecture, bitness, compiler, compiler version, and optimization. Many tasks/pairs that make sense in Linux (e.g., ARM vs. PowerPC and endianness changes) are not widely applicable in Windows PE code bases, and so can not be evaluated in this context. For this reason, Table 2 shows Linux evaluation results on the left side, the original results in Linux/Linux column, and Windows evaluation results on the right for the viable tests. Irrespective, we see that despite the cross-platform/functional goals of Marcelli et al. , the dichotomy in Windows PEs and more diverse datasets results in dramatically lower performance. The GNN model trained on Assemblage Windows data shows that, despite using the same code and sophisticated disassembly tools, the gap in performance is non-trivial and an open problem for future study.

A second experiment using the BERT  based jTrans  is considered. jTrans uses masked language modeling and a novel task, jump target prediction, in its pre-training phase. Despite the jump target prediction code released by Wang et al.  requiring Linux specific tooling, all information needed to run their fine-tuning was already in Assemblage's SQLite database. Otherwise, we precisely followed the script released by the jTrans authors to create a training and validation set.

We randomly selected 72,000 Windows PE binaries and 23,000 Linux ELF binaries from Assemblage's dataset, processed them, and separated them into training and validation sets for Windows and Linux, respectively. For both the Windows and Linux datasets, using the hyperparameter settings recommended by the jTrans authors, we ran fine-tuning for 50 epochs, at which point the Mean Reciprocal Rank (MRR) over the training set became stable. Table 3 shows a notable difference between the reported MRR scores on Linux (0.83) and Windows (0.52) data, even with fine-tuning. Because the authors have not released their code for pre-training, we could not conduct any further investigation into the impact of the pre-training step. However, it is significant that jTrans and jTrans-zero (jTrans without fine-tuning) both perform worse on the larger, more diverse Assemblage data than they do on their original training corpuses. This demonstrates the value that Assemblage brings to researchers, who can leverage its datasets to conduct experiments on more challenging and more realistic data.

### Binary Function Identification

Finding functions within a binary is non-trivial due to the complexity of inverting compiler behaviors, as well as the general difficulty of disassembly as its own requisite task . This is often assumed to be solvable with \(\)99% \(F_{1}\) scores for ML based function boundary detection  or that professional reverse engineering tools like IDA are sufficiently accurate . Assemblage allows us to quantify the accuracy of these tools on a more diverse collection of data

    &  &  &  \\  & & & (w/PDBs) \\  WinPE & 0.75 & 0.47 & 0.79 \\  vcpkg & 0.81 & 0.86 & 0.86 \\   

Table 4: F-1 scores of XDA and IDA on Windows PE binary function boundary identification

   Training Epochs & 1 & 20 & 50 \\  Fine-tune \& Evaluate on Windows & 0.17 & 0.52 & 0.52 \\  Fine-tune \& Evaluate on Linux & 0.83 & 0.83 & 0.83 \\  Fine-tune \& Evaluate on Linux (BinaryCorp-26M) & 0.82 & - & 0.98 \\   

Table 3: Reproducing jTrans on Assemblage Windows and Linux datasets, measuring in MRR (higher is better).

Windows data4. We randomly selected around 2000 Windows PE binaries from Assemblage that better reflect "wild" code, and 2500 vcpkg binaries that are closer to the limited Windows PE binaries often considered in prior works. As seen in Table 4, significant room for improvement still exists for ML-based methods like XDA , and do provide real value over existing rules-based methods like IDA. Even when IDA is given debug information (PDB files), its performance is not sufficient to discount in results, analysis, and real-world deployment.

## 5 Conclusion

At first blush, binary analysis fits into a common application pattern of deep learning: an inversion problem where the compiler's process of converting source code into binary files is the easy generating pass, and machine learning methods are used to learn the inversion from binary back to source code. ML research in binary analysis has thus exploded, but has often not translated to practice due to a gap between "in-the-lab" code and "in-the-wild" binaries. Assemblage helps to mitigate this gap and provides an extensible system that can generate the data needed to push this needed research into the Windows domain, which has the greatest need and the least data/study. This has been shown for three subdomains of binary analysis of compiler provenance, function similarity, and function identification. In each case, we see Assemblage makes it easy to set up experiments following existing methods, obtain new results, identify areas for improvement, and ultimately stable Assemblage's general purpose utility for binary analysis research.