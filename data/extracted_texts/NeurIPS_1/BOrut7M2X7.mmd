# Divide-and-Conquer Posterior Sampling for Denoising Diffusion Priors

Yazid Janati\({}^{*,1}\) Badr Moufad\({}^{*,1}\)

**Alain Durmus\({}^{1}\) Eric Moulines\({}^{1,3}\) Jimmy Olsson\({}^{2}\) \({}^{1}\)** CMAP, Ecole polytechnique \({}^{2}\) KTH Royal Institute of Technology \({}^{3}\) MBZUAI

* Equal contributionCorresponding authors: {yazid.janati,badr.moufad}@polytechnique.edu

###### Abstract

Recent advancements in solving Bayesian inverse problems have spotlighted denoising diffusion models (DDMs) as effective priors. Although these have great potential, DDM priors yield complex posterior distributions that are challenging to sample. Existing approaches to posterior sampling in this context address this problem either by retraining model-specific components, leading to stiff and cumbersome methods, or by introducing approximations with uncontrolled errors that affect the accuracy of the produced samples. We present an innovative framework, divide-and-conquer posterior sampling, which leverages the inherent structure of DDMs to construct a sequence of intermediate posteriors that guide the produced samples to the target posterior. Our method significantly reduces the approximation error associated with current techniques without the need for retraining. We demonstrate the versatility and effectiveness of our approach for a wide range of Bayesian inverse problems. The code is available at [https://github.com/Badr-MOUFD/dcps](https://github.com/Badr-MOUFD/dcps)

## 1 Introduction

Many problems in machine learning can be formulated as inverse problems, such as superresolution, deblurring, and inpainting, to name but a few. They all have the same goal, namely to recover a signal of interest from an indirect observation. One line of research addresses these problems through the lens of the Bayesian framework by specifying two components: a prior distribution, which embodies the specification of the signal, and a likelihood that describes the law of the observation conditionally on the signal. Once these elements are specified, the inverse problem is solved by sampling from the posterior distribution, which, after including the observation, contains all available information about the signal and thus about its uncertainty as well . The importance of the specification of the prior in solving Bayesian ill-posed inverse problems is paramount. In the last decade, the success of priors based on deep generative models has fundamentally changed the field of linear inverse problems . Recently, denoising diffusion probabilistic models (DDMs) have received special attention. Thanks to their ability to learn complex and multimodal data distributions, DDM represent the state-of-the-art in many generative modeling tasks, _e.g._ image generation , super-resolution , and inpainting .

Popular methods to sample from posterior distribution include Markov chain Monte Carlo (MCMC) and variational inference; see  and the references therein. These methods are iterative schemes that require an explicit procedure to evaluate pointwise the prior distribution and often its (Stein) score function  in order to compute acceptance ratios and construct efficient proposals. Whilesampling from the DDM priors is straightforward, posterior sampling is usually challenging since the intractability of the posterior density and its score make them computationally prohibitive and thus invalidate all conventional simulation methods. Although approximations exist, their associated iterative sampling schemes can be computationally intensive and exhibit high sensitivity to the choice of hyperparameters; see _e.g._.

This paper proposes the Divide-and-Conquer Posterior Sampler (DCPS), a novel approach to posterior sampling in Bayesian inverse problems with DDM priors. Thanks to the Markov property of the data-generating backward diffusion, the posterior can be expressed as the marginal distribution of a Feynman-Kac (FK) path measure , whose length corresponds to the number of diffusion steps and whose user-defined potentials serve to bias the dynamics of the data-generating backward diffusion to align with the likelihood of the observation. Besides, for a given choice of potentials, the FK path law becomes Markovian, making it possible to express the posterior as the marginal of a time-reversed inhomogeneous Markov chain.

This approach is tempting, yet, the backward Markov decomposition remains difficult to apply in practice as these specific potential functions are difficult to approximate, especially when the number of diffusion steps is large. We tackle this problem with a divide-and-conquer approach. More precisely, instead of targeting the given posterior by a single simulation run through the full backward decomposition, our proposed scheme targets backward a sequence \((_{k_{}})_{=0}^{L}\) of distributions along the path measure leading to the target posterior distribution (section 3). These distributions are induced by a sequence of increasingly complex potentials and converge to the target distribution. Starting with a sample from \(_{k_{+1}}\), a draw from \(_{k_{}}\) is formed by a combination of Langevin iterations and the simulation of an inhomogeneous Markov chain. In other words, \(_{k_{}}\) is expressed as the final marginal distribution of a time-reversed inhomogeneous Markov chain of moderate length \(k_{+1}-k_{}^{*}\) with an initial distribution \(_{k_{+1}}^{}\). This chain, whose transition densities are intractable, is approximately sampled using Gaussian variational inference. The rationale behind our approach stems from the observation that the Gaussian approximation error can be reduced by shortening the length of the intermediate FK path measures (_i.e._, by increasing \(L\)); a result that we show in Proposition A.1. We finally illustrate that our algorithm can provide high-quality solutions to Bayesian inverse problems involving a variety of datasets and tasks.

To sum up our contribution, we

* show that the existing approximations of the Markovian backward decomposition can be improved using a bridge-kernel smoothing technique
* design a novel divide-and-conquer sampling approach that enables efficient bias-reduced sampling from the posterior, and illustrate its performance on several Bayesian inverse problems including inpainting, outpainting, Poisson imaging, and JPEG dequantization,
* propose a new technique to efficiently generate approximate samples from the backward decomposition using Gaussian variational inference.

Notation.For \((m,n)^{2}\) such that \(m<n\), we let \( m,n:=\{m,,n\}\). We use \((x;,)\) to denote the density at \(x\) of a Gaussian distribution with mean \(\) and covariance matrix \(\). \(I_{d}\) is the \(d\)-dimensional identity matrix and \(_{a}\) denotes the Dirac mass at \(a\). \(W_{2}\) denotes the Wasserstein distance of order 2. We use uppercase for random variables and lowercase for their realizations.

## 2 Posterior sampling with DDM prior

DDM priors.We provide a brief overview of DDMs . Suppose we can access an empirical sample from some data distribution \(p_{}\) defined on \(^{d_{x}}\). For \(n\) large enough and \(k 0,n\), define the distribution \(q_{k}(x_{k}):= p_{}(x_{0})\,q_{k|0}(x_{k}|x_{0})x_{0}\) with \(q_{k|0}(x_{k}|x_{0}):=(x_{k};}x_{0},(1-_{k})I _{d_{x}})\), where \((_{k})_{k=0}^{n}\) is a decreasing sequence with \(_{0}=1\) and \(_{n}\) approximately equals zero. The probability density \(q_{k}\) corresponds to the marginal distribution at time \(k\) of an auto-regressive process on \(^{d_{x}}\) given by \(X_{k+1}=/_{k}}X_{k}+/_{k}} _{k+1}\), with \(X_{0} p_{}\) and \((_{k})_{k=0}^{n}\) being a sequence of i.i.d. \(d_{x}\)-dimensional standard Gaussians.

DDMs leverage parametric approximations \(^{}_{0|k}\) of the mappings \(x_{k} x_{0}\,q_{0|k}(x_{0}|x_{k})x_{0}\), where \(q_{0|k}(x_{0}|x_{k}) p_{}(x_{0})q_{k|0}(x_{k}|x_{0})\) is the conditional distribution of \(X_{0}\) given \(X_{k}=x_{k}\). Eachis defined as \(^{}_{0|k}(x_{k}):=(x_{k}-}^{}_{k }(x_{k}))/}\), where \(^{}_{k}\) is a noise predictor network trained by minimizing a denoising objective; see (46, Eq. (5)) and Appendix A for details. Following (15, Section 4.2), \(^{}_{k}\) also provides an estimate of the score \( q_{k}(x_{k})\) given by \(^{}_{k}(x_{k}):=-x_{k}-}^{ }_{0|k}(x_{k})/(1-_{k})\). We denote by \(^{}\) the minimizer of the denoising objective. Having access to \(^{}\), we can define a generative model for \(p_{}\) by adopting the denoising diffusion probabilistic model (DDPM) framework of . As long as \(n\) is large enough, \(q_{n}\) can be confused with a multivariate standard Gaussian. Define the _bridge kernel_\(q_{k|0,k+1}(x_{k}|x_{0},x_{k+1}) q_{k|0}(x_{k}|x_{0})q_{k+1|k}(x_{k+1} |x_{k})\) which is a Gaussian distribution with mean \(_{k|0,k+1}(x_{0},x_{k+1})\) and diagonal covariance \(^{2}_{k|k+1}I_{d_{x}}\) defined in Appendix A.1. Define the generative model for \(p_{}\) as

\[p^{^{}}_{0:n}(x_{0:n})=p_{n}(x_{n})_{k=0}^{n-1}p^{^{ }}_{k|k+1}(x_{k}|x_{k+1})\,, \]

where for every \(k 1,n-1\), the backward transitions are

\[p^{^{}}_{k|k+1}(x_{k}|x_{k+1}):=q_{k|0,k+1}(x_{k}|^{^{ }}_{0|k+1}(x_{k+1}),x_{k+1})\,, \]

with \(p^{^{}}_{0|1}(|x_{1}):=_{^{^{}}_{0|1}(x _{1})}\) and \(p_{n}(x_{n})=(x_{n};0,I_{d_{x}})\). In the following, we assume that we have access to a pre-trained DDM and omit the superscript \(^{}\) from the notation, writing simply \(p\) and \(_{0|k}\) when referring to the generative model and the denoiser, respectively. In addition, we denote by \(p_{k}\) the \(k\)-th marginal of \(p_{0:n}\) and write, for all \((,m) 0,n^{2}\) such that \(<m\), \(p_{|m}(x_{}|x_{m}):=_{k=}^{m-1}p_{k|k+1}(x_{k}|x_{k+1})\).

Posterior sampling.Let \(g_{0}\) be a nonnegative function on \(^{d_{x}}\). When solving Bayesian inverse problems, \(g_{0}\) is taken as the likelihood of the signal given the observation specified using the forward model (see the next section). Our objective is to sample from the posterior distribution

\[_{0}(x_{0}):=g_{0}(x_{0})\,p_{0}(x_{0})/\;, \]

where \(:= g_{0}(x_{0})\,p_{0}(x_{0})x_{0}\) is the normalizing constant and the prior \(p_{0}\) is the marginal of (2.1) w.r.t. \(x_{0}\), in which case the posterior (2.3) can be expressed as

\[_{0}(x_{0})=} g_{0}(x_{0})_{k=0}^{n-1}p_{k|k+1 }(x_{k}|x_{k+1})\,p_{n}(x_{n})\,x_{1:n}\,.\]

Thus, Equation (2.3) can be interpreted as the marginal of a time-reversed FK (Feynman-Kac) model with a non-trivial potential only for \(k=0\); see  for a comprehensive introduction to FK models. In this work, we twist, without modifying the law of the FK model, the backward transitions \(p_{k|k+1}\) by artificial positive potentials \((g_{k})_{k=0}^{n}\), each being a function on \(^{d_{x}}\), and write

\[_{0}(x_{0})=} g_{n}(x_{n})\,p_{n}(x_{n})_{k=0} ^{n-1}(x_{k})}{g_{k+1}(x_{k+1})}\,p_{k|k+1}(x_{k}|x_{k+1})\,x_{1:n}\,. \]

This allows the posterior of interest to be expressed as the time-zero marginal of an FK model with initial distribution \(p_{n}\), Markov transition kernels \((p_{k|k+1})_{n=0}^{n-1}\), and \((g_{k})_{k=0}^{n}\).

Recent works that aim to sample from the posterior (2.3) generally employ the FK representation (2.4). These studies, however, adopt varying auxiliary potentials . FK models can be effectively sampled using sequential Monte Carlo (SMC) methods; see, _e.g._, . SMC methods sequentially propagate weighted samples, whose associated weighted empirical distributions target the flow of the FK marginal distributions. The effectiveness of this technique depends heavily on the choice of intermediate potentials \((g_{k})_{k=1}^{n}\), as discussed in . However, SMC methods require a number of samples proportional and often exponential in the dimensionality of the problems hence limiting their application in these setups due to the resulting probability memory cost . On the other hand, reducing the number of samples makes them vulnerable to mode collapse.

In the following, we will focus on a particular choice of potential functions \((g_{k})_{k=1}^{n}\) for which the posterior \(_{0}\) can be expressed as the time-zero marginal distribution of a time-reversed Markov chain. The transition densities of this chain are obtained by twisting the transition densities of the generative model with the considered potential functions. More precisely, define, for all \(k\)the potentials \(g_{k}^{}(x_{k}):= g_{0}(x_{0})\,p_{0|k}(x_{0}|x_{k})\,x_{0}\). Note that these potentials satisfy the recursion \(g_{k+1}^{}(x_{k+1})= g_{k}^{}(x_{k})\,p_{k|k+1}(x_{k}|x_{k+1})\, x_{k}\). Builing upon that, define the Markov transitions

\[_{k|k+1}(x_{k}|x_{k+1}):=^{}(x_{k})}{g_{k+1}^{}(x_{k+1} )}\,p_{k|k+1}(x_{k}|x_{k+1}), \]

allowing the posterior (2.4) to be rewritten as

\[_{0}(x_{0})=_{n}(x_{n})_{k=0}^{n-1}_{k|k+1}(x_{k}|x_{k+1})\, x_{1:n}\,,_{n}(x_{n})=g_{n}^{}(x_{n})p_{n}(x_{n})/ . \]

In other words, the distribution \(_{0}\) is the time-zero marginal of a Markov model with transition densities \((_{k|k+1})_{k=n-1}^{0}\) and initial distribution \(_{n}\). According to this decomposition, a sample \(X_{0}^{}\) from the posterior (2.3) can be obtained by sampling \(X_{n}^{}_{n}\) and then, recursively sampling \(X_{k}^{}_{k|k+1}(|X_{k+1}^{})\) from \(k=n-1\) till \(k=0\). In practice, however, neither the Markov transition densities \(_{k|k+1}\) nor the probability density function \(_{n}\) are tractable. The main challenge in estimating \(_{k|k+1}\) stems essentially from the intractability of the potential \(g_{k}^{}(x_{k})\) as it involves computing an expectation under the high-cost sampling distribution \(p_{0|k}(|x_{k})\).

Recent works have focused on developing tractable approximations of \(p_{0|k}(|x_{k})\). For the _Diffusion Posterior Sampling_ (DPS) algorithm , the point mass approximation \(_{_{0|k}(x_{k})}\) of \(p_{0|k}(|x_{k})\) results in the estimate \(_{x_{k}} g_{0}(_{0|k}(x_{k}))\) of \(_{x_{k}} g_{k}^{}(x_{k})\). Then, given a sample \(X_{k+1}\), an approximate sample \(X_{k}\) from \(_{k|k+1}(|X_{k+1})\) is obtained by first sampling \(_{k} p_{k|k+1}(|X_{k+1})\) and then setting

\[X_{k}=_{k}+_{x_{k+1}} g_{0}(_{0|k+1}(x_{k+1}))| _{x_{k+1}=X_{k+1}}\,, \]

where \(>0\) is a tuning parameter. As noted in [48; 7; 4], the DPS updates (2.7) do not lead to an accurate approximation of the posterior \(_{0}\) even in the simplest examples; see also Section 4. Alternatively,  proposed the _Pseudoinverse-Guided Diffusion Model_ (IIGDM), which uses a Gaussian approximation of \(p_{0|k}(|x_{k})\) with mean \(_{0|k}(x_{k})\) and diagonal covariance matrix set to \((1-_{k})I_{d_{x}}\), which corresponds to the covariance of \(q_{0|k}(|x_{k})\) if \(p_{}\) had been a standard Gaussian; see [47, Appendix 1.3]. More recently, [17; 4] proposed to approximate the exact KL projection of \(p_{0|k}(x_{0}|x_{k})\) onto the space of Gaussian distributions by noting that both its mean and covariance matrix can be estimated using \(_{0|k}(x_{k})\) and its Jacobian matrix. We discuss in more depth the related works in Appendix B.

## 3 The DCPS algorithm

Smoothing the DPS approximation.The bias of the DPS updates (2.7) stems from the point mass approximation of the conditional distribution \(p_{0|k}(|x_{k})\). This approximation becomes more accurate as \(k\) tends to zero and is crude otherwise. We aim here to mitigate the resulting approximation errors. A core result that we leverage in this paper is that for any \((k,) 0,n^{2}\) such that \(<k\), we can construct an estimate \(_{|k}(|x_{k})\) of \(p_{|k}(|x_{k})\) that bears a smaller approximation error than the estimate \(_{_{0|k}(x_{k})}\) relatively to \(p_{0|k}(|x_{k})\). Formally, let \(_{0|k}(|x_{k})\) denote any approximation of \(p_{0|k}(|x_{k})\), such as that of the DPS or IIGDM, and define the approximation of \(p_{|k}(|x_{k})\)

\[_{|k}(x_{}|x_{k}):= q_{|0,k}(x_{}|x_{0},x_{k})_{0|k}(x_{0}|x_{k})\,x_{0}\,, \]

where \(q_{|0,k}(x_{}|x_{0},x_{k})\) is defined in (A.4). We then have the following result.

**Proposition 3.1** (informal).: _Let \(k 1,n\). For all \( 0,k-1\) and \(x_{k}^{d_{x}}\),_

\[W_{2}(_{|k}(|x_{k}),p_{|k}(|x_{k}))}(1-_{k}/_{})}{(1-_{k})}W_{2}(_{0|k }(|x_{k}),p_{0|k}(|x_{k}))\,. \]

The proof is postponed to Appendix A.3. Note that the ratio in the right-hand-side of (3.2) is less than \(1\) and decreases as \(\) increases. As an illustration, using the DPS approximation of \(p_{0|k}(|x_{k})\), we find that \(_{|k}(x_{}|x_{k})=q_{|0,k}(x_{}|_{0|k}(x_{k}),x_{k})\) improves upon DPS in terms of approximation error.

This observation prompts to consider DPS-like approximations on shorter time intervals; instead of approximating expectations under \(p_{0|k}(|x_{k})\), such as the potential \(g_{k}^{}(x_{k})\), we should transform our initial sampling problem so that we only have to estimate expectations under \(p_{|k}(|x_{k})\) for any \(\) such that the difference \(k-\) is small. This motivates the _blocking approach_ introduced next.

Intermediate posteriors.We approach the original problem of sampling from \(_{0}\) via a series of simpler, _intermediate_ posterior sampling problems of increasing difficulty. More precisely, let us consider the intermediate posteriors defined as

\[_{k_{}}(x_{k_{}}):=g_{k_{}}(x_{k_{}})p_{k_{}}(x_{k_{ }})_{k_{}},_{k_{ }}:= g_{k_{}}(x_{k_{}})p_{k_{}}(x_{k_{}})\,x _{k_{}}, \]

where \((g_{k_{}})_{=1}^{L}\) are potential functions designed by the user and \((k_{})_{=0}^{L}\) is an increasing sequence in \( 0,n\) such that \(k_{0}=0\) and \(k_{L}=n\). Here, \(L\) is typically much smaller than \(n\). To obtain an approximate sample from \(_{0}=_{k_{0}}\), the DCPS algorithm recursively uses an approximate sample \(X_{k_{+1}}\) from \(_{k_{+1}}\) to obtain an approximate sample \(X_{k_{}}\) from \(_{k_{}}\). Indeed, mirroring (2.6) it holds

\[_{k_{}}(x_{k_{}})=_{k_{+1}}^{}(x_{k_{+1}})_ {m=k_{}}^{k_{+1}-1}_{m|m+1}^{}(x_{m}|x_{m+1})\,x_{k_{ }+1:k_{+1}}\,, \]

where for \(m k_{},k_{+1}-1\),

\[_{k_{+1}}^{}(x_{k_{+1}}) :=g_{k_{+1}}^{,}(x_{k_{+1}})p_{k_{+1}}(x_{k_{ +1}})_{k_{}}\,,\] \[_{m|m+1}^{}(x_{m}|x_{m+1}) :=g_{m}^{,}(x_{m})p_{m|m+1}(x_{m}|x_{m+1})g_{m+1}^ {,}(x_{m+1})\]

and for \(m k_{}+1,k_{+1}\),

\[g_{m}^{,}(x_{m}):= g_{k_{}}(x_{k_{}})p_{k_{}|m}(x_{k_ {}}|x_{m})\,x_{k_{}}\,. \]

We emphasize that the initial distribution \(_{k_{+1}}^{}\) in (3.4) is _different_ from the posterior \(_{k_{+1}}\) as the former involves the user-defined potential whereas the latter the intractable one. The main advantage of our approach lies in the fact that, unlike the potentials in the transition densities (2.5), which involve expectations under \(p_{0|k}(|x_{k})\), the potentials (3.5) are given by expectations under the distributions \(p_{k_{}|m}(|x_{m})\), which are easier to approximate in the light of Proposition 3.1. In the sequel, we use this approximation for the estimation of the potentials (3.5); this yields approximate potentials

\[_{m}^{,}(x_{m}):= g_{k_{}}(x_{k_{}})_{k_{ }|m}(x_{k_{}}|x_{m})\,x_{k_{}}\,, m k _{}+1,k_{+1}\,, \]

which serve as a substitute for the intractable \(g_{m}^{,}\). Let us now summarize how our algorithm works. Starting from a sample \(X_{k_{+1}}\), which is approximately distributed according to \(_{k_{+1}}\), the next sample \(X_{k_{}}\) is generated in the next two steps:

1. Perform Langevin Monte Carlo steps initialized at \(X_{k_{+1}}\) and targeting \(_{k_{+1}}^{}\), yielding \(X_{k_{+1}}^{}\).
2. Simulate a Markov chain \((X_{j})_{j=k_{+1}}^{k_{}}\) initialized with \(X_{k_{+1}}=X_{k_{+1}}^{}\) and whose transition from \(X_{j+1}\) to \(X_{j}\) is the minimizer of \[(_{j|j+1}^{}(|X_{j+1})_{j|j+1}^{ }(|X_{j+1})),\] (3.7) where \(_{j|j+1}^{}\) is a mean-field Gaussian approximation with parameters \(:=(,)^{d_{}}_{>0} ^{d_{}}\). \(X_{j}\) is drawn from \(_{j|j+1}^{_{j}(X_{j+1})}(|X_{j+1})\), where \(_{j}(X_{j+1})\) is a minimizer of the proxy of (3.7).

In the following, we elaborate more on Step 1 and Step 2 and discuss the choice of the intermediate potentials. The pseudo-code of the DCPS algorithm is in Algorithm 1.

Sampling the initial distribution.In order to perform **Step 1**, we use the discretized Langevin dynamics  with the estimate \(_{k_{+1}}^{,}+_{k_{+1}}\) of the score \(_{k_{+1}}^{}\). This estimate results from the use of \(_{k_{+1}}\) as an approximation of \( p_{k_{+1}}\) in combination with the approximate potential (3.6). We then obtain the approximate sample \(X_{k_{+1}}^{}\) of \(_{k_{+1}}\) by running \(M\) steps of the tamed unadjusted Langevin (TULA) scheme ; see Algorithm 1. Here, the intractability of the involved densities hinder the usage of the Metropolis-Hastings corrections to reduce the inherent bias of the Langevin algorithm.

Sampling the transitions.We now turn to Step 2. Given \(X_{j+1}\), we optimize the following estimate of Equation (3.7), where we simply replace \(g_{j}^{,}\) by the approximation (3.6):

\[-_{j}^{,}(x_{j})_{j|j+1}^{}(x_{j}|x_{j+1}) \,x_{j}+(_{j|j+1}^{}(|x_{j+1}) p _{j|j+1}(|x_{j+1}))\,.\]

Letting \(_{j|j+1}^{}(x_{j}|x_{j+1})=(x_{j};_{j},(^{_{j}}))\), where the variational parameters \(_{j},_{j}\) are in \(_{d_{x}}\), the previous estimate yields the objective

\[_{j}(_{j},_{j};x_{j+1}):=- _{j}^{,}_{j}+^{ _{j}/2}Z)\\ +_{j}-_{j|j+1}(x_{j+1})\|^{2}}{2_{j|j+1 }^{2}}-_{i=1}^{d_{x}}(_{j,i}-^{_{j,i}}}{_{j|j+1}^{2}})\,, \]

where \(Z\) is \(d_{x}\)-dimensional standard Gaussian and \(_{j|j+1}(x_{j+1})\) is the mean of (2.2). Note here that we have used the reparameterization trick  and the closed-form expression of the KL divergence between two multivariate Gaussian distributions. We optimize the previous objective using a few steps of SGD by estimating the first term on the r.h.s. with a single sample as in . For each \(j[\![k_{},k_{+1}-1]\!]\), we use \(_{j|j+1}\) and \(_{j|j+1}^{2}\) as initialization for \(_{j}\) and \(_{j}\).

Intermediate potentials.Here, we give general guidelines to choose the user-defined potentials \((g_{k_{}})_{=1}^{L}\). Our design choice is to rescale the input and then anneal the initial potential \(g_{0}\). Therefore, we suggest

\[g_{k_{}}(x)=g_{0}(}})^{_{k_{}}}\,, \]

where \(_{k_{}},_{k_{}}>0\) are tunable parameters. This design choice is inspired from the tempering sampling scheme  which uses the principle of progressively moving an intial distribution to the targeted one. We provide some examples in the case of Bayesian inverse problems where the unobserved signal and the observation are modelled jointly as a realization of \((X,Y) p(y|x)p_{0}(x)\), where \(p(y|x)\) is the conditional density of \(Y\) given \(X=x\). In this case, the posterior \(_{0}\) of \(X\) given \(Y=y\) is given by (2.3) with \(g_{0}(x)=p(y|x)\).

_Linear inverse problems with Gaussian noise._ In this case, \(g_{0}(x)=(y;Ax,_{y}^{2}I_{d_{y}})\), where \(A^{d_{y} d_{x}}\). Popular applications in image processing include super-resolution, inpainting, outpainting, and deblurring. We use (3.9) with \((_{k_{}},_{k_{}})=(}},_{k_{}})\),

\[g_{k_{}}(x)=(}}y;Ax,_{y}^{2}I_{d_{y }})\,, \]

which corresponds to the likelihood of \(x\) given the _pseudo observation_\(}}y\) under the same linear observation model that defines \(g_{0}\). This choice of \(g_{k_{}}\) enables exact computation of (3.6) and allows information on the observation \(y\) to be taken into account early in the denoising process.

_Low-count (or shot-noise) Poisson denoising._ In a Poisson model for an image, the grey levels of the image pixels are modelled as Poisson-distributed random variables. More specifically, let \(A^{d_{y} d_{x}}\) be a matrix with nonnegative entries and \(x^{C H W}\), where \(C\) is the number of channels and \(H\) the height and \(W\) the width. For every \(i[\![1,d_{y}]\!]\), \(Y_{i}\) is Poisson-distributed with mean \((Ax)_{i}\), and the likelihood of \(x\) given the observation is therefore given by \(x_{j=1}^{d_{y}}( Ax)_{j}^{_{j}}^{-( Ax)_ {j}}/y_{j}!\) where \(>0\) is the rate. Following  we consider as likelihood its normal approximation, _i.e._\(g_{0}=_{j=1}^{d_{y}}(y_{j};(Ax)_{j},y_{j})\). This model is relevant for many tasks such as low-count photon imaging and computed tomography (CT) reconstruction . We use (3.9) with \(_{k_{}}=_{k_{}}=}}\):

\[g_{k_{}}(x)=_{j=1}^{d_{y}}(}}y_{j}; (Ax)_{j},}}y_{j})\,. \]

_JPEG dequantization._ JPEG  is a ubiquitous method for lossy compression of images. Use \(h_{q}\) to denote the JPEG encoding function with _quality factor_\(q[\!\!]\), where a small \(q\) is associated with high compression. Denote by \(h_{q}^{}\) the JPEG decoding function that returns an image in RGB space with a certain loss of detail, depending on the degree of compression \(q\), compared to the original image. Since we require the potential to be differentiable almost everywhere, we use the differentiable approximation of JPEG developed in , which replaces the rounding function used in the quantization matrix with a differentiable approximation that has non-zero derivatives almost everywhere. In this case, \(g_{0}(x)=(h_{q}^{}(y);h_{q}^{}(h_{q}(x)),_{y}^{2} I_{d_{y}})\), where \(y\) is in YCbCr space. Combining this with Equation (3.9) with \((_{k_{}},_{k_{}})=(_{k_{}},_{k_{}})\) and assuming that the composition \(h_{q}^{} h_{q}\) is a homogenious map, the intermediate potentials are \(g_{k_{}}(x)=(}}\,h_{q}^{}(y);h_{q}^ {}(h_{q}(x)),_{y}^{2}I_{d_{x}})\,.\)

## 4 Experiments

In this section, we demonstrate the performance of DCPS and compare it with DPS , IIGDM , DDRM , RedDiff, and MCGDiff on several Bayesian inverse problems. We also benchmark our algorithm against DiffPIR , DDNM , FPS , and SDA  but we defer the results to the Appendix C.5.

First, we consider a simple toy experiment in which the posterior distribution is available in closed form. Next, we apply our algorithm to superresolution (SR \(4\) and 16\(\)), inpainting and outpainting tasks with Gaussian and Poisson noise, and JPEG dequantization. For these imaging experiments, we use the FFHQ256  and ImageNet256  datasets and the publicly available pre-trained models of  and . Finally, we benchmark our method on a trajectory inpainting task using the pedestrian dataset UCY for which we have trained a Diffusion model. All details can be found in Appendix C.1.

Gaussian mixture.We first evaluate the accuracy of DCPS on a linear inverse problem with a Gaussian mixture (GM) prior, for which the posterior can be explicitly computed: it is also a Gaussian mixture whose means, covariance matrices, and weights are in a closed form; see Appendix C.2. In this case, the predictor \(^{^{}}_{0|k}\) is available in a closed form; see Appendix C.2 for more details. We consider a Gaussian mixture prior with \(25\) components in dimensions \(d_{x}=10\) and \(d_{x}=100\). The potential is \(g_{0}(x)=(y;Ax,_{y}^{2}I_{d_{y}})\) with \(d_{y}=1\) and \(A\) is a \(1 d_{x}\) vector. The results are averaged over \(30\) randomly generated replicates of the measurement model \((y,A,_{y}^{2})\) and the mixture weights. Then, for each pair of prior distribution and measurement model, we generate \(N_{s}=2000\) samples with each algorithm and compare them with \(N_{s}\) samples from the true posterior distribution using the sliced Wasserstein (SW) distance. For DCPS, we used \(L=3\) blocks and \(K=2\) gradient steps, respectively, and compared two configurations, denoted by DCPS\({}_{50}\) and DCPS\({}_{500}\), of the algorithm with \(M=50\) and \(M=500\) Langevin steps, respectively. See Algorithm 1. The results are reported in Table 1. It is worthwhile to note that DCPS outperforms all baselines except for MCGDiff. However, by increasing the number of Langevin steps, its performance closely matches that of MCGDiff.

Imaging experiment.Table 2 reports the results for the linear inverse problems with Gaussian noise with two noise variance levels \(_{y}=0.05\) and \(_{y}=0.3\), Table 3 for the JPEG dequantization problem with \(_{y}=10^{-3}\), \(\{2,8\}\), and Table 6 for the Poisson denoising task with rate \(=0.1\). For all tasks and datasets, we use the same parameters for DCPS and therefore do not perform any task or dataset-specific tuning. We use \(L=3\), \(K=2\) gradient steps, and \(M=5\) Langevin steps. To ensure a fair comparison with DPS and IIGDM  we use 300 DDPM steps for DCPS and \(1000\) steps for both DPS and IIGDM, which ensures that all the algorithms have the same runtime and memory footprint; see Table 4. For MCGDiff, which has a large memory requirement, we use \(N=32\) particles in the SMC sampling step and then randomly draw one sample from the resulting particle approximation of the posterior. Finally, for DDRM we use 200 diffusion steps and for RedDiff we use \(1000\) gradient steps and the parameters recommended in the original paper. We provide the implementation details for all algorithms in Appendix C.1.

    & \(d_{x}=10,d_{y}=1\) & \(d_{x}=100,d_{y}=1\) \\  DCPS\({}_{50}\) & \(2.91 0.74\) & \(4.04 1.00\) \\ DCPS\({}_{500}\) & \( 0.68\) & \( 0.95\) \\ DPS & \(5.80 0.75\) & \(5.68 0.73\) \\ DDM & \(3.77 0.96\) & \(5.70 0.78\) \\ IIGDM & \(4.23 0.90\) & \(4.61 0.68\) \\ RedDiff & \(6.36 1.27\) & \(7.47 0.87\) \\ MCGDiff & \( 0.75\) & \( 0.71\) \\   

Table 1: 95% confidence interval for the SW on the GM experiment.

Figure 1: First two dimensions of samples (in red) from each algorithm on the 25 component Gaussian mixture posterior sampling problem with \((d_{x},d_{y})=(100,1)\). The true posterior samples are given in blue.

For the JPEG dequantization task, we use \(_{y}=10^{-3}\) and \(=0.1\). We only benchmark our method against IIGDM and RedDiff, since MCGDiff and DDRM do not handle non-linear inverse problems. We did not include DPS in our benchmark because we have not managed to find a suitable choice of hyperparameters to achieve reasonable results. Finally, for the Poisson-shot noise case, we compare against DPS. We use the step size for super-resolution recommended in the original paper [see 10, Appendix D.1], and found, via a grid search, that the same value is also effective for the other tasks.

Evaluation.As shown in Table 2, DCPS outperforms the other baselines on 13 out of 16 tasks and has the best average performance. In particular, it compares favorably with IIGDM and DPS, its closest competitors, while exhibiting the same runtime and memory requirements; see Table 4, where we give the average runtime and memory usage for each algorithm. The memory consumption is measured by how many samples each algorithm can generate in parallel on a single 48GB L40S NVIDIA GPU for the Diffusion model trained on FFHQ . We emphasize that DCPS is more robust to larger noise levels than IIGDM and RedDiff, as evidenced by the large increase in the LPIPS value for these algorithms in the case \(_{y}=0.3\). On the JPEG dequantization task (Table 3), DCPS also shows better performance than these algorithms and even more so for the high compression level (\(=2\)). On the Poisson-shot noise tasks, DCPS outperforms DPS by a significant margin; see Table 6. Finally, we display various reconstructions obtained with each algorithm. More specifically, we have generated 4 samples each, with the same seed. Figure 2 displays the first sample and the remaining ones are deferred to Appendix D. For MCGDiff we show 4 random samples of the same particle filter. Due to the collapse of the particle filter in very large dimensions , they are all similar. Surprisingly, the samples produced by DDRM and RedDiff for the outpainting tasks also show striking similarities, although the samples have been drawn independently.

   Dataset / \(_{y}\) & Task & DCPS & DDRM & DPS & IIGDM & RedDiff & MCGDiff \\   & Half & **0.20** & 0.25 & 0.24 & 0.26 & 0.28 & 0.36 \\  & Center & **0.05** & 0.06 & 0.07 & 0.19 & 0.12 & 0.24 \\  & SR \(\) & **0.09** & 0.18 & 0.09 & 0.33 & 0.36 & 0.15 \\  & SR \(16\) & **0.23** & 0.36 & 0.24 & 0.44 & 0.51 & 0.32 \\   & Half & **0.25** & 0.30 & 0.31 & 0.64 & 0.76 & 0.80 \\  & Center & **0.10** & 0.13 & 0.11 & 0.62 & 0.75 & 0.55 \\  & SR \(4\) & 0.21 & 0.26 & **0.19** & 0.77 & 0.77 & 0.65 \\  & SR \(16\) & **0.35** & 0.41 & 0.43 & 0.64 & 0.74 & 0.52 \\   & Half & **0.35** & 0.40 & 0.44 & 0.38 & 0.44 & 0.83 \\  & Center & 0.18 & **0.14** & 0.31 & 0.29 & 0.22 & 0.45 \\  & SR \(4\) & **0.24** & 0.38 & 0.41 & 0.78 & 0.56 & 1.32 \\  & SR \(16\) & **0.44** & 0.72 & 0.50 & 0.60 & 0.83 & 1.33 \\   & Half & **0.40** & 0.46 & 0.48 & 0.82 & 0.76 & 0.86 \\  & Center & **0.24** & 0.25 & 0.40 & 0.68 & 0.71 & 0.47 \\  & SR \(4\) & **0.43** & 0.50 & 0.42 & 0.87 & 0.83 & 1.31 \\  & SR \(16\) & 0.72 & 0.77 & **0.57** & 0.72 & 0.92 & 0.67 \\   

Table 2: Mean LPIPS value on different tasks. Lower is better.

   Dataset & Task & DCPS & IIGDM & RedDiff \\   & \(=2\) & **0.20** & 0.37 & 0.32 \\  & \(=8\) & **0.08** & 0.15 & 0.18 \\   & \(=2\) & **0.44** & 0.93 & 0.50 \\  & \(=8\) & **0.24** & 0.95 & 0.31 \\   

Table 3: Mean LPIPS value on JPEG dequantization.

Figure 2: Sample images for inpainting with center, half, expand masks and for Super Resolution with \(4\) and \(16\) factors. On the left: FFHQ dataset and on the right ImageNet dataset.

[MISSING_PAGE_FAIL:9]

principled method for estimating the backward kernels. DCPS applies to various relevant inverse problems and is competitive with existing methods.

Limitations and future directions.Our method has some limitations that shed light on opportunities for further development and refinement. First, the intermediate potentials that we considered were specifically designed for each problem, meaning our method is not universally applicable to all inverse problems. For instance, our approach can not be applied to for linear inverse problems using latent diffusion models  since there is no clear choice of intermediate potentials. Therefore, in our opinion, deriving a learning procedure that is capable to automatically design effective intermediate potentials applicable to any \(g_{0}\) is an important research direction. Moreover, there is an aspect of the choice of the intermediate potentials and the number of blocks \(L\) that remains to be understood properly. Indeed, while our backward approximations reduce the local approximation errors w.r.t. DPS and IIGDM; nonetheless DCPS requires appropriate intermediate potentials in order to perform well. DCPS can still provide decent performance with _irrelevant_ intermediate potentials as long as the number of Langevin steps, in-between the blocks, is large enough. Finally, although our method provides decent results with the same computational cost as DPS and IIGDM, it remains slower than RedDiff and DDRM which which do not compute vector-jacobian product over the denoiser. Therefore, overcoming this bottleneck when optimizing the KL objective would be a significant improvement for our method.

Acknowledgments.The work of Y.J. and B.M. has been supported by Technology Innovation Institute (TII), project Fed2Learn. The work of Eric Moulines has been partly funded by the European Union (ERC-2022-SYG-OCEAN-101071601). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council Executive Agency. Neither the European Union nor the granting authority can be held responsible for them.