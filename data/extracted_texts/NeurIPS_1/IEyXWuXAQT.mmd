# Learning via Surrogate PAC-Bayes

Antoine Picard-Weibel

Inria & SUEZ, France

antoine.picard.ext@suez.com

&Roman Moscoviz

SUEZ, France

roman.moscoviz@suez.com

Centre International de Recherche Sur l'Eau et l'Environnement.

Benjamin Guedj

Inria and University College London, France and United Kingdom

benjamin.guedj@inria.fr

###### Abstract

PAC-Bayes learning is a comprehensive setting for (i) studying the generalisation ability of learning algorithms and (ii) deriving new learning algorithms by optimising a generalisation bound. However, optimising generalisation bounds might not always be viable for tractable or computational reasons, or both. For example, iteratively querying the empirical risk might prove computationally expensive. In response, we introduce a novel principled strategy for building an iterative learning algorithm via the optimisation of a sequence of surrogate training objectives, inherited from PAC-Bayes generalisation bounds. The key argument is to replace the empirical risk (seen as a function of hypotheses) in the generalisation bound by its projection onto a constructible low dimensional functional space: these projections can be queried much more efficiently than the initial risk. On top of providing that generic recipe for learning via surrogate PAC-Bayes bounds, we (i) contribute theoretical results establishing that iteratively optimising our surrogates implies the optimisation of the original generalisation bounds, (ii) instantiate this strategy to the framework of meta-learning, introducing a meta-objective offering a closed form expression for meta-gradient, (iii) illustrate our approach with numerical experiments inspired by an industrial biochemical problem.

## 1 Introduction

Generalisation is arguably one of the central problems in machine learning. Among the different techniques to study generalisation, PAC-Bayes has gained considerable traction over the past decade, as evidenced by the surge in publications. We refer to the seminal works of Shawe-Taylor and Williamson (1997); McAllester (1999); Catoni (2004, 2007) and to the recent surveys and monographs from Guedj (2019); Hellstrom et al. (2023); Alquier (2024) for a thorough overview of the field.

One appealing feature is that PAC-Bayes learning is a comprehensive setting for (i) studying the generalisation ability of learning algorithms and (ii) deriving new learning algorithms by optimising a PAC-Bayes generalisation bound. This is the strategy pursued in a number of recent works, among which Germain et al. (2009); Biggs and Guedj (2021); Germain et al. (2015); Viallard et al. (2023); Zantedeschi et al. (2021); Rivasplata et al. (2019); Perez-Ortiz et al. (2021); Zhou et al. (2019).

We now regard this strategy of substituting a generalisation bound to more classical training objectives as established, and we focus here on the computational aspect of this strategy. Indeed, optimising generalisation bounds might not always be viable for tractable or computational reasons, or both.

Most PAC-Bayes bounds do not admit a close form minima formulation; moreover, such bounds involve expectations and divergence terms which in general settings can not be evaluated in closed form and thus require the use of approximation methods such as Monte-Carlo sampling (see amongst others Seldin and Tishby (2010); Dziugaite and Roy (2017); Neyshabur et al. (2017); Mhammendi et al. (2019)). Such approximation methods can prove computationally intensive, notably if the empirical risk, whose expectation is optimised in the bound, is hard to query. Picard-Weibel et al. (2024) reports that such queries proved to be the main computational bottleneck when optimising a PAC-Bayes bound in a bio-chemical model calibration task. More generally, models whose predictions require solving stiff ordinary differential equations (ODE) or partial differential equations (PDE), such as naturally occurs in physics or biology inspired problems, result in empirical risks whose query can be computationally expensive, in practice all but making numerous iterative computations of PAC-Bayes objective's gradients impracticable.

In response to the aforementioned difficulties for optimising PAC-Bayes generalisation bounds in practice, we introduce a novel principled strategy designed to mitigate the computational cost of querying the empirical risk, **S**urrogate **PAC**-Bayes Learning (SuPAC, see algorithm 1). We build a learning algorithm which iteratively optimises a sequence of surrogate training objectives in which the empirical risk is replaced by a proxy. This proxy is built as the orthogonal projection of the true empirical risk on a functional vector space of finite dimension, which we conjecture can be queried much more efficiently than the initial risk. A key motivation is that such surrogate objectives can offer adequate approximations of the true objective valid much further away than the linear approximation offered by the gradient, and enable larger optimisation steps. This effectively decouples the complexity of querying the empirical risk and optimising PAC-Bayes objectives.

Our contributions.We list below our four main contributions, spanning theory, algorithmic, application to meta-learning and numerical experiments.

1. We provide a generic recipe for learning via surrogate PAC-Bayes bounds, which we believe is of practical interest for machine learning tasks involving computationally intensive models with moderate dimension (_e.g._ physics models with less than few hundred parameters),
2. contribute theoretical results establishing that iteratively optimising our surrogates implies the optimisation of the original generalisation bounds. This is established by Theorem 1 and further developed in Corollary 1 and Theorem 2,
3. instantiate this strategy to the framework of meta-learning, introducing a meta-objective with a closed form expression for meta-gradient,
4. illustrate our approach with numerical experiments inspired by an industrial biochemical setting using an anaerobic digestion model.

Outline.The paper is organised as follows: in Section 2 we set the stage and introduce our generic framework. In Section 3, we construct functional approximation spaces and establish generic guarantees for our framework. In Section 4, we focus on Catoni's bound (Catoni, 2007) and describe a practical implementation of our framework. In Section 5, we investigate how our surrogate PAC-Bayes minimisation strategy can be used in meta-learning settings. Numerical experiments are described in Section 6. Future prospects are discussed in Section 7. The manuscript closes with an appendix in which we gather (i) technical proofs in Appendix A, (ii) implementation details in Appendix B.

## 2 A generic surrogate framework

Consider a measurable space \(\) of predictors, denote \(\) the set of all probability distributions on \(\), and \(()\) the set of measurable real valued functions. For a probability distribution \(\), let \(^{1}()\) (resp. \(^{2}()\)) denote the set of integrable (resp. square integrable) functions with respect to \(\). For a \(f^{1}()\), \([f]\) denotes the mean of \(f\) with respect to \(\) (the notation is extended for functions outputting vectors), while for functions in \(^{2}()\), \(_{}[f]\) denotes the variance of \(f\) (resp. covariance).

A PAC-Bayes bound, denoted PB, can generically be summarised as a real valued function of four variables: a generic distribution \(\), a prior distribution \(_{}\), an empirical risk function \(R\), and other factors which we regroup as \(\) (_e.g._ the confidence level, the PAC-Bayes temperature, the size of the dataset). A PAC-Bayes theorem states that, under given assumptions on the data generation mechanisms and risk, the average risk function \(=[R]\) satisfies for some function \(q\)

\[[,\ [] (,R,_{},)] 1-q(), \]

where the probability is taken on the data generation mechanism. Due to the bound holding simultaneously for all distributions with high probability, it notably holds with high probability on the minimiser of the bound, hence the PAC-Bayes minimisation task

\[_{}(,R,_{},). \]

We consider a restriction of this minimisation task on a subset \(\) of all probability distributions. Such a restriction might be justified by various considerations, including storage of the calibrated distribution, simplification of the minimisation task or even expert knowledge (Alquier et al., 2016; Dziugaite and Roy, 2017; Picard-Weibel et al., 2024). However, even this simplified minimisation problem might prove computationally difficult for Gradient Descent (GD) based algorithm. This is especially the case when evaluating the empirical risk is costly, _e.g._ when the prediction model involves solving stiff ODEs or PDEs. As PAC-Bayes bounds depend on the \(\)-mean of the empirical risk, each gradient estimation rely on numerous new evaluations of the empirical risk. For ODEs \(=F(S,t,x)\) where \(F\) is very sensitive with respect to \(S\), numerous evaluations of \(F\) are required to obtain adequate numerical solutions in a given range \([t_{0},t_{1}]\). These evaluations must moreover be performed iteratively, and hence can not be parallelized. Moreover, implementing the ODE solver in a way to benefit from GPU speed up when simulating for multiple parameters \(x\)s simultaneously might not be practicable, since most ODE solver use a varying step size which will depend on \(x\). This will result in typically long model calls which can not be massively parallelised. To overcome this difficulty, we introduce the Surrogate PAC-Bayes bound learning framework (SuPAC), which is based on alternatively building and solving surrogate problems. It is designed to reduce the number of calls to the risk - and consequently, in our ODE example, to the ODE solver.

Formally, we consider an approximation algorithm \(:()()\) in conjunction with an approximate solving algorithm \(:()\). Informally, F constructs a proxy of the empirical risk valid for the current posterior estimation \(\); while Solve updates the posterior estimation by solving the resulting surrogate objective (Algorithm 1).

```
0: PB, \(_{0}\), \(_{}\), \(R()\) \(_{0}\) while not converged do \(f(,R)\) \((_{},,f)\) endwhile
```

**Algorithm 1** Surrogate PAC-Bayes Learning framework (SuPAC)

Algorithm 1 offers a lot of leeway for building surrogates (_e.g._, iteratively refining an ODE or PDE solver, tailor-made surrogates for physical models, polynomial approximations) as well as solving the surrogate problem. For such a framework to be practicable, two conditions should apply: the construction of the surrogate and approximate solving should be faster than solving the initial problem, and the algorithm's result should tend to diminish the PAC-Bayes bound. Intuitively, the choice of the approximation mechanisms plays a critical role; indeed, the more precise the approxima-task to be close to the true minimiser, but the harder the approximation task and the surrogate construction task.

## 3 Constructing surrogate function spaces

A core contribution of the present work is to show that for generic PAC-Bayes bounds and generic probability families \(\) of dimension \(d\), \(^{2}()\) orthogonal projection of the true score on a functional vector space of dimension \(d+1\) is sufficient to obtain convergence guarantees.

A few assumptions on the PAC-Bayes bounds, the risk \(R\) and the probability family \(\) are required.

**Assumptions**.:
1. \(=\{_{},\}\) _is a parametric set indexed by an open subset_ \(^{d}\)_;_
2. \(\)_,_ \(_{}\) _is absolutely continuous with respect to_ \(_{}\) _and_ \(}{d_{}}(x)=((,x))\) _with_ \((,x)\) _differentiable for all_ \(x\)* \(\), \( N_{}\) _a neighbourhood of_ \(\) _such that_ \(x_{ N_{}}_{}(,x)  L^{2}(_{})\)_;_
* \(R_{}\!L^{2}(_{})\)_;_
* _There exists_ \(}\) _such that_ \((_{},R,_{},)=}( ,_{}[R],_{},)\) (i.e._ \(\)_'s dependence on the empirical risk is limited to the posterior average of the empirical risk). Moreover,_ \(}\) _is differentiable with respect to its two first arguments._

We emphasise that these assumptions are valid for essentially all PAC-Bayes bounds, most risks, and for a wide variety of probability distributions, and are thus rather more technical than restrictive. Although the second assumption rules out probability distributions whose support is not included in the prior support, we remark that such distributions usually yield vacuous PAC-Bayes bounds due to penalisation terms (_e.g._, vacuous Kullback-Leibler divergence), and as such are already ruled out. Most standard family of distributions, including Gaussian mixtures, satisfy (\(A_{1}\)) to (\(A_{3}\)) for adequate parameterizations. The fourth assumption is automatically satisfied for all bounded risks, which is a typical assumption of PAC-Bayes bounds, but also allows for unbounded risks provided that they are square integrable (_e.g._ polynomials if \(\) span Gaussian would satisfy (\(A_{4}\))). The last assumption is satisfied by most PAC-Bayes bound, _e.g._ those of McAllester (1999), Maurer (2004).

Since \(\) is parameterized by \(\), we will abuse notations for functions of \(\) and write \(G():=G(_{})\). For a given \(\), the functional vector space \(_{}:=f_{,C}:x_{} (,x)+C^{d},C}\) provides a natural approximation space of dimension \(d+1\). We are now in a position to state our main approximation result.

**Theorem 1**.: _Under assumptions (\(A_{1}\)) to (\(A_{5}\)), replacing the empirical risk \(R\) by the proxy risk_

\[f^{R,}:=_{f_{}}_{}[(R-f)^{2}]\]

_leaves the gradient of the objective \(\) invariant, i. e._

\[_{1}(,R,_{},)=_{1}(,f^{R,},_{},).\]

_This result also holds if the approximation space \(_{}\) is replaced by \(_{}+:=\{f+g f_{},\}\) for any set \( L^{2}(_{})\)._

Proof.: Assumptions (\(A_{3}\)) and (\(A_{4}\)) allow differentiating \(_{}[R]=[_{}}{ }R]\) under the integral sign (see Theorem 6.28 in Klenke (2020)), yielding \(_{}[R]=_{}[R_{}]\). As such, the derivative of \(}(,_{}[R],_{},)\) with respect to \(\) equals \(_{1}}(,_{}[R],_{ },)+_{2}}(,_{}[R],_{},)_{}[R_{}]\).

As the only dependence on the gradient with respect to \(R\) is on the value of \([R]\) at which the derivative is evaluated and on the vector \(_{}[R_{}]\), it follows that \(_{}\) is not modified by replacing \(R\) by a function \(f L^{2}(_{})\) satisfying the following linear system:

\[_{}[R_{}]&=_{}[f_{ }],\\ _{}[R]&=_{}[f]. \]

By construction of \(_{}\), the linear system (3) is satisfied if and only if \((f-R)_{}^{}\), where \(A^{}\) denotes the orthogonal complement of \(A\) in \(^{2}(_{})\). Hence for any set \(^{2}(_{})\), the orthogonal projection of \(R\) on \(}=_{}+\) satisfies the linear system (3). Noticing that the orthogonal projection \(f^{R,}\) of \(R\) on space \(}\) satisfies \(f^{R,}=_{f}}_{}[(R-f)^{2}]\) ends the proof. 

Informally, Theorem 1 guarantees that if searching for a PAC-Bayes posterior in a space of size \(d\), adequately projecting the score on a space of dimension at most \(d+1\) preserves the immediate surrounding of the PAC-Bayes objective. If the approximation built at \(\) maintains near optimal performance for a large neighbourhood of \(\), this surrogate task provides a valid approximation of the true task for a wide range of distributions, and offers approximate solutions \(\) much further away than the range of validity of the objective's gradient.

The extension of the result for \(_{}+\) implies that proxy score functions combining a known, simplified model with a learnt correction term can be used. For \(=\{h\}\), it implies that the result holds if the approximation space consists of a fixed user defined proxy and a correction term. This can have direct practical implications in settings where efficient, natural proxy are available; the learnt corrective term would presumably be smaller, and hence the approximation's validity larger.

A direct consequence of Theorem 1 is a fixed point characterisation of the minima of the PAC-Bayes objective for instances of Algorithm 1 using GD based surrogate solver (see proof in Appendix A.1):

**Corollary 1**.: _Under assumptions (\(A_{1}\)) to (\(A_{5}\)), the minimiser \(\) of the original PAC-Bayes bound is a fixed point of any instance of Algorithm 1 such that:_

* _the approximation function is_ \(F(_{},R):=_{f_{}}_{}[(R-f)^{2}]\)_,_
* _the surrogate solving Solve strategy is any (corrected) gradient descent strategy starting at the current_ \(\)_, using update steps of form_ \(()=-M(,,f,)_{}( ,f,_{},)\)_, where_ \(M\) _stands for any function returning an endomorphism, for any number of steps, any convergence criteria._

It should be stressed that Corollary 1 does not imply that Algorithm 1 improves on GD. Corollary 1 only guarantees that replacing the score by a low dimensional approximation is harmless locally. Informally, if the approximation built at \(\) maintains near optimal performance for a large neighbourhood of \(\), this surrogate task provides a valid approximation of the objective for this wide radius, and can construct approximate solutions \(\) much further away than the range of validity of the gradient. SuPAC decouples the variations of the bound due to the evolution of \(\) and \(f^{,R}\); such a decoupling is particularly interesting if the approximation \(f^{,R}\) is stable.

## 4 Exponential family and Catoni's bound

### Closed form surrogate solution and fixed point property

Theorem 1 involves approximation of the empirical risk through orthogonal projection on a local functional vector space \(_{}\) of dimension at most \(d+1\). A setting of particular interest concerns families of probabilities such that the space \(_{}\) does not depend on \(\). Exponential families, _i.e._ family of distributions of the form

\[_{T}=\{_{}}{d_{}}=(  T-g()+h)\},\]

are a well studied class of probability family which satisfy this property (and essentially the only such class if \(\) is connected and the likelihood smooth, see Theorem 3 in Appendix A.3). The approximation space can be written as \(=\{f_{C,}:= T+C\}\). Without loss of generality, we assume that functions \((1,T_{1},,T_{d})\) are linearly independent.

Exponential families define a tractable, yet flexible class of probability families, spanning from simple, fixed variance distributions to multimodal distributions (Cobb et al., 1983). They englobe most familiar distribution families such as multivariate Gaussians, Beta and Gamma (Brown, 1986). The approximation space they generate can equally vary. For Gaussian distributions, we remark that \(\) covers quadratic forms.

We now focus on the celebrated PAC-Bayes bound from Catoni (Catoni, 2007; Alquier, 2024),

\[_{}(,_{},R,(,,n,C))=[R]+ (,_{})+}{8 n}-( ), \]

where \((,)=[}{}]\) is the Kullback-Leibler divergence and \(\) is the PAC-Bayes temperature. Catoni's bound holds with probability \(1-\) if \(0 R C\). Due to its particular form, minimising the bound amounts to minimising the simpler objective \(_{,}:=[R]+(,_{})\).

For simplicity, we will assume that \(_{}=_{_{}}\). In this setting, _(A1)_, _(A2)_ and _(A4)_ are automatically verified. A key incentive to use Catoni's bound is that the surrogate objective can be solved in closed form; for risks of form \(f_{,C}\), if the prior belongs to the exponential family, the minimiser of Catoni's bound on \(\) belongs to \(\), and it follows that

\[_{}_{}(_{},_{_{}},f_{ ,C})=():=_{p}-^{-1},\]provided that \(_{p}-^{-1}\) (if not, Catoni's bound does not admit a minima) (see Lemma 2.2, and Corollary 2.3 in Alquier (2024)). Since the posterior distribution does not depend on the constant term \(C\) we will note \(f_{}\) for any \(f_{,C}\).

We can here use the exact solution of the surrogate PAC-Bayes bound rather than have to minimise the bound through GD. The following lemma (proved in Appendix A.2) bridges the gap by showing that the update rule using the closed form solution can be interpreted as a corrected GD step:

**Lemma 1**.: _Consider an exponential family \(:=\{_{}\}\) with sufficient statistic \(T\). Noting \(:=\{f_{}:x T(x)+C^{d},C \}\), let \(f_{}\). Then for any prior parameter \(_{p}\), for any parameter \(\), the mapping \(():=_{p}-^{-1}\) satisfies:_

\[=-^{-1}I()^{-1}_{}_{}(,_{p},f_{},)+,\]

_where \(I()\) denotes Fisher's information matrix._

A direct consequence of Lemma 1 is that Corollary 1 applies when using the exact solver for the surrogate Catoni task. Since Fisher's information is positive, it follows that the update direction \(-\) always diminishes the bound locally. We summarise these results in the following theorem.

**Theorem 2**.: _The minimiser of Catoni's PAC-Bayes objective on an exponential family is a fixed point of Algorithm 1 with approximation function_

\[F(_{},R):=_{f}_{}[(R-f)^{2}],\]

_and surrogate solver_

\[(_{},,f_{}):=_{p}-^{-1}= _{}_{}(,_{},f_{}, ).\]

_Moreover, for all \(\),_

\[_{}((_{},,F( ,R))-) 0.\]

As noted above, the solution of the surrogate task must belong to \(\) to define a probability distribution. There is however no guarantee that such is the case for any approximated risk. For instance, if the risk is estimated close to a local maxima by a quadratic function, the resulting surrogate task might not have a minima, and hence the resulting \(()\) might fail to be a probability distribution, causing the algorithm to break. Another difficulty lies in solving the approximation task. Involving an integral of a function of the risk, the objective theoretically requires evaluations of the risk at all predictors. We show in the next section how both these issues can be solved in practice.

### Framework implementation: SuPAC-CE

Following Theorem 2, we propose an algorithm, SuPAC-CE ([https://github.com/APicardWeibel/surpbayes](https://github.com/APicardWeibel/surpbayes)), designed to efficiently find the minimiser of Catoni's bound on Exponential families.

#### 4.2.1 Implementing the approximation

As the surrogate PAC-Bayes bound is solved using a closed form expression, the computational bottleneck of Algorithm 1 is the approximation task of computing \(()=_{^{d}}_{}[(f_{}-R-_{}[f_ {}-R])^{2}]\). Due to the form of \(f_{}\), this is formally a least square weighted linear approximation problem with infinite number of observations, whose solution can be explicitly written as \(=_{}[T]^{-1}[R(T-[T])]\). This solution can be approximated using a finite number of function evaluations \(R(x_{i})\), replacing the probability \(\) by an empirical counterpart \(_{}=_{i=1}^{N}_{i}_{x_{i}}\).

Different choices of \((x_{i},_{i})\) can be considered. A first approach consists in drawing i.i.d. samples from \(_{}\) and considering uniform weights. This guarantees that the approximated objective is unbiased. A main shortcoming of this approach, however, is that it disregards all previous risk evaluations at each step. Corrections of the form \(_{}}{_{}}\) can be used to salvage samples drawn from \(_{}\), all the while guaranteeing unbiased approximated objective. This however can drastically increase the variance, and thus might not be practical.

We advocate a _generation agnostic_ approach for the weighing process, which treats all available risk evaluations in a like manner. We assume that \(\) is a metric space. For all predictors \((x_{i})_{i[1,N]}\) whose risk \(R(x_{i})\) is known, target weights \(}\) are defined as the probability given to the Voronoi cell \(_{i}\) by distribution \(_{}\). This target weight can be approximated using Monte Carlo simulations and solving nearest neighbour in \((x_{i})_{i[1,N]}\) tasks. The distance used for the Voronoi cell can depend on the distribution \(_{}\) -(_e.g._ Mahalanobis distance for Gaussian exponential families). This approach requires, if the empirical distribution \(_{i}_{x_{i}}\) is to form an adequate approximation of the distribution \(_{}\), some queries from to \(_{}\). The stack of function evaluation is hence appended at each approximation step by evaluating samples from \(_{}\). As this weight computation can bring some overhead, it is only appropriate when risk queries are the main computational bottleneck.

#### 4.2.2 Boundary issues

PAC-Bayes bounds typically hold for empirical risk functions satisfying moment bounds (with respect to the data generation mechanism) or boundedness conditions (the latter being usually required for Catoni's bound). Such assumptions might no longer be met for the approximated risks. A consequence is that the minimiser of the surrogate task might not exist. For instance, a local quadratic approximation of the score near a local maxima can induce a surrogate task whose minima is \(-\).

To ensure that for any score approximation \(f_{,C}\), the surrogate solver always define a probability distribution, two regularisation hyperparameters \(_{}\) and \(_{}\) are introduced. \(_{}_{+}+\) determines the maximum step size allowed between two successive posterior estimation, measured in Kullback-Leibler divergence. \(_{}]0,1]\) acts as a dampening hyperparameter. The corrected update rule is changed to \(_{c}()=(()-)+\) with \(\) the highest \(_{}\) such that \((_{c},)_{}\). Such \(\) can be easily obtained through a Newton scheme or dichotomy, noticing that it is defined through \(f()=C\) for a non decreasing function \(f\).

This modification does not impact the fixed point property of Theorem 2. Moreover, if the empirical risk \(R\) belongs to \(\), choosing \(_{}<\), \(_{}=1\) results in convergence in a finite number of steps (resp. exponential convergence for \(_{}<1\)) (see Appendix A.4).

**Remark 4.1**.: While SuPAC-CE is designed to optimize Catoni's PAC-Bayes bound (4), it can serve as a work engine for the minimisation of other PAC-Bayes bounds. For instance, Proposition 2.1 from Germain et al. (2015) implies that Maureer-Langford-Seeger's bound (MLS bound, Maurer (2004), Langford and Seeger (2001) can be rewritten as

\[_{}=_{>0}\{_{,}}{ n}-)}{1-(-1/( n))}\}.\]

As such, the minimisation of MLS bound could be performed by alternatively minimizing Catoni's objective at fixed temperature using SuPAC-CE and solving on the temperature at fixed posterior. The generation agnostic weighing approach moreover implies that re-optimising Catoni's objective after a small change of temperature can be done with few new risk queries (see the strategy developed in Section 5). This strategy is further detailed in Appendix C.

## 5 Surrogate Catoni in a Meta-Learning framework

Both the Bayes and PAC-Bayes framework offer a natural connection with Meta-Learning, as both involve a natural inductive bias in the form of the prior. Previous work which studied Meta-Learning for PAC-Bayes include Pentina and Lampert (2014), Amit and Meir (2018), Rothfuss et al. (2023), Zakerinia et al. (2024). The aim of PAC-Bayes Meta-Learning is the construction, from a sample of independent train tasks, of a prior yielding optimal generalisation bounds on new unknown test tasks. Such optimisation of the prior brings two benefits: tighter generalisation bounds (smaller penalisation); and simplified PAC-Bayes learning task (better initial guess). For PAC-Bayes meta learning, a natural training objective can be derived from the minimised PAC-Bayes bounds obtained for each task. This defines the following meta training objective, analogue to an empirical risk at the meta level:

\[M(_{})=_{i}_{}(_{i},R_{i}, _{},_{i}), \]where \(_{i}\) denotes the task posterior and is a function of \(R_{i}\), \(_{p}\) and \(_{i}\). The objective defined in Equation (5) departs from previous formulations which typically involve a further penalisation term at the meta level. We advance two justifications for this simplification. First, the extra penalisation term involves divergence terms between a meta prior and meta posterior (both distributions on probability distributions) which in practice make the bound vacuous and thus of limited practical interest. Second, PAC-Bayes theory already offers guarantees on the generalisation performances of each test task, limiting the need to assess the generalisation performance at the meta level. Arguably, the task specific bound provided by using PAC-Bayes as inner algorithm is more informative than the "mean" task bound offered by a meta PAC-Bayes algorithm (when PAC-Bayes learning is used both as inner algorithm and meta training algorithm).

We consider that assumptions (\(A_{1}\)) to (\(A_{5}\)) hold, and also these further mild assumptions: the prior is looked for in \(\), i.e \(=_{_{p}}\); the PAC-Bayes bound PB is differentiable w.r.t. \(_{p}\). Then, noting \(_{i}\) the posterior parameter for each task, a simplification of the meta gradient occurs:

\[ M(_{p})=_{_{p}}(_{i}(_{ p}),R_{i},_{p},_{i})=_{3}(_{i},R_{i}, _{p},_{i}). \]

Remarkably, the knowledge of the derivative of \(_{i}\) with respect to \(_{p}\) is not required to compute the meta gradient. This is due to \(_{1}\) being \(0\) when evaluated for the prior posterior. We stress that such a simplification is specific to our meta-learning objective. It does not occur in meta-learning strategies such as MAML (Finn et al., 2017), where the performance of each task is assessed on a test set. In the context of PAC-Bayes, such reliance on test sets can be optimistically replaced by the PAC-Bayes bounds, which give test guarantees with high probability. It is unclear whether such a simplification occurs in previous PAC-Bayes Meta Learning objectives from the literature, as these involve distributions on priors rather than a single prior.

A key consequence is that training the meta learning algorithm is as hard as cycling all the Bayesian optimisation tasks. In a nutshell, meta learning is as hard as re optimising the bound for a new prior.

SuPAC-CE brings two main benefits when used in conjunction with meta-learning. First, by improving the optimisation efficiency for a given prior, SuPAC-CE speeds up the meta-learning procedure. Second, the "generation agnostic" weighing approach implies that risk revaluations from previous optimisation procedures can be reused. As a consequence, re optimisation of a PAC-Bayes bound for a new prior can conceivably be performed with few risk queries, bringing an additional speed-up. Moreover, the setting considered for SuPAC-CE enjoys an analytical expression for meta-gradients, \( M(_{p})=_{i}_{i}( g(_{i})- g( _{p}))\) which can be efficiently evaluated.

## 6 Experiments

SuPAC-CE was assessed on the learning task described by Picard-Weibel et al. (2024). A PAC-Bayes bound is minimised on Gaussian distributions with block diagonal covariance in order to calibrate 30 parameters of a biological inspired numerical model describing anaerobic digestion processes, ADM1 (Batstone et al., 2002). This model relies on solving a stiff ODE to predict the evolution of the states, and is therefore quite computationally intensive (about 3 seconds per model query in our experiments).

We compared SuPAC-CE to standard GD on a synthetic dataset from Picard-Weibel et al. (2024), using the same family of distributions and risk function. For SuPAC-CE, 160 risk queries where performed for the initial step, and 32 for all further step. A maximal budget of 9600 empirical risk queries was fixed; hyperparameters for the GD were selected after evaluating a grid on the first 1600 queries. Mean risks were assessed at test time by resampling new predictors from the posterior. The PAC-Bayes temperature was set to \(0.002\). Training procedures were repeated 20 times.

The performance of the sequence of posteriors were compared by aligning the number of empirical risk queries. Indeed, the main motivation of SuPAC-CE is the setting when querying the empirical risk is computationally expensive, and can be assumed to be the computational bottleneck. This is indeed the case for the anaerobic digestion example considered here. At equal number of risk queries, SuPAC-CE required an extra 3.5% processing time compared to gradient descent, mainly caused by the weighing process.

SuPAC-CE proved significantly more efficient at minimising the bound than GD (see Figure 0(a)). The average performance of our algorithm proved better after 1800 queries than the best performance obtained after the full 9600 queries for GD. The experiments also indicate that our procedure offers much higher stability compared to GD, both during training and between the training duplicates. This could be attributed to the "generation agnostic" weighing approach, which relies on all previous risk evaluations at each step and is thus more stable. On the other hand, the noisy gradients estimates have some probability of leading to problematic steps during GD, leading to sharp increase in the objective. In our experiments, 4 out of 20 GD procedures thus led to a worse performance than the one obtained by a single optimisation step of SuPAC-CE. The posterior distributions constructed through SuPAC-CE obtained an average empirical risk of \(0.102 0.003\), similar to the \(0.101\) value reported in Picard-Weibel et al. (2024). The resulting PAC-Bayes bound proved also similar (\(0.121 0.004\) vs. \(0.122\)). Thus SuPAC-CE constructed as good a posterior as Picard-Weibel et al. (2024), but twenty times faster.

Further assessments of SuPAC-CE's performance for other hyperparameters values and comparison to Nesterov accelerated GD were also conducted. SuPAC-CE proved to have a stable behaviour for a wide range of hyperparameters value (\(0.25 a_{} 0.75\), \(0.5_{} 2\)), with instabilities starting to appear for \(_{}>5\), and speed decrease for \(_{}<0.1\). Nesterov acceleration, requiring some iterations to build up momentum, proved unable to compete with SuPAC-CE's almost instantaneous optimisation. Results for these experiments can be found in Appendix B.

Preliminary experiments were also performed for the meta-learning objective described in Section 5. To facilitate the evaluation of the learnt meta priors, wholly synthetic risk functions were used in this case, and PAC-Bayes objective minimised on Gaussian distributions. The risk functions considered were bounded, smooth functions of \(^{8}\), achieving their global minima at \(x_{0}(_{0},_{0})\). \(_{0}\) was chosen so that \(\|_{0}\|=2\), and \(_{0}\) such that only two of its eigenvalues are higher than \(0.05^{2}\) (drawn at random between \((-1)\) and \((1)\)). Such choices ensure that the original prior distribution, \((0,I_{k})\), can be improved upon both by shifting its mass centre and adjusting its covariance. The performance of the meta-learning algorithm was assessed for two temperatures, \(=0.1\) and \(=0.01\). Meta training was performed using stochastic gradient descent. The sequence of prior thus constructed was evaluated on a further 40 test tasks, each time restarting the optimisation procedure from scratch, and evaluating the final score on \(10^{4}\) draws from the posterior.

The meta-learning algorithm was able to satisfactorily reduce the objective, from an initial average generalisation bound of 0.61 (resp. 0.14) to 0.24 (resp. 0.050) after 150 gradient steps for \(=0.1\) (resp. \(=0.01\)). Most of the meta-objective reduction takes place during the early phase of training, with the first 15 steps amounting to more than 80 % of the objective decrease. For both temperatures

Figure 1: Experiments results. Figure 0(a) compares the optimisation performance of our algorithm SuPAC-CE with gradient descent approaches on an biochemical calibration task. Optimisation procedures were repeated 20 times; median performance and quantiles 0.2 and 0.8 are represented. Figure 0(b) investigates train and test performance of the meta-learning approach of Section 5. Mean test performance, as well as quantiles 0.2 and 0.8 for the sequence of built prior is assessed on 40 tasks and compared to the train performance. SuPAC-CE reduced the PAC-Bayes objective to \(0.121 0.004\) (avg. risk of posterior of \(0.102 0.003\)).

tested, the average performance on the test tasks followed the objective decrease throughout training, even though the number of queries per optimisation was minimal after the first meta step (less than 40), supporting both our meta-learning objective and the use of SuPAC-CE.

Full implementation details on the experiments can be found in Appendix B and in the source code ().

## 7 Discussion

The present work shows that it is possible to locally decouple the complexity related to querying the empirical risk and the minimisation of a PAC-Bayes bound. A main motivation for such decoupling is that the approximated risk function defines a non linear surrogate objective which might be valid (_i.e._ close to the original objective) for a wider range of probabilities than the linear approximations offered by the gradients. As a consequence, the surrogate bound solution can be reasonably allowed to be much further away from the current posterior estimation than is the case for GD. A key implementation difficulty remains picking the range of validity, _i.e._ how far away from the current posterior the surrogate solver can be allowed to choose a distribution. Such a choice, formalised in the selection of an adequate surrogate solving algorithm, is analogue to the choice of a step size in gradient descent procedures, and balances the stability and speed of the procedure. Automating the selection of the surrogate validity range offers an exciting prospect for the framework.

The Voronoi cell weighing approach used to solve the approximation problem is equivalent to replacing the empirical risk function by a 1-nearest neighbour trained predictor, and approximating this predictor. Variants following this two step approximation approach could be worth investigating. Notably, an interesting perspective would be to approximate the empirical risk through Gaussian processes, taking inspiration from Gaussian Optimisation. This would notably track the uncertainty on the approximate risk on extrapolated values, which could drive the choice of new predictors to evaluate and improve on the current random draws.

A key restriction of the present work is that our surrogate PAC-Bayes framework is only practicable when the dimension of the predictor space and of the probability family are small (_i.e._ less than a few hundreds). This is due to two factors; first of all, the larger the dimension of the probability family, the larger becomes the approximation space, and hence the more empirical risk evaluations are required. Notably, at least \(d+1\) evaluations of the empirical risk are required for probability families of dimension \(d\). The second factor is that the "generation agnostic" weighing approach described in Section 4.2.1 is unlikely to give adequate performances if \(\) is high dimensional. This effectively rules out deep learning settings, which have been recently the main focus of the PAC-Bayes community. Still, we believe that PAC-Bayes learning offers meaningful prospects for a wide range of physics, biology or medical inspired problems which involve few parameters and expensive model computations, and therefore can be efficiently trained using our framework. Concrete fields of application of SuPAC-CE include, but are not limited to, fluid dynamics simulations with dimension reduction (Callaham et al., 2021), metabolic models for microbial communities (Cerk et al., 2024) and greenhouse gas emission inverse problems (Nalini et al., 2022). We remark that, as of now, PAC-Bayes has not been much used outside of the learning community. While this can be vastly attributed to a lack of awareness of PAC-Bayes theory outside of the learning community, the use of PAC-Bayes was also hampered by the fact that previous PAC-Bayes algorithm required a prohibitive number of simulations and hence computation time. We believe SuPAC-CE is a game changer in that respect, due to its focus on limiting the number of risk queries, and readily usable implementation, and we hope that this can be leveraged in different disciplines.

Conclusion.We introduced a generic framework for minimising PAC-Bayes bounds designed to tackle computationally intensive empirical risks for low to moderate dimensional problems such as naturally arise in physical models. We established that our optimisation strategy was theoretically well supported. We instantiated this framework for the optimisation of bounds on exponential family, and considered how this implementation could interact with meta-learning. Preliminary experiments showed that our framework could significantly reduce the number of empirical risks queries when calibrating a biochemical model, thus opening exciting new fields of applications for PAC-Bayes.