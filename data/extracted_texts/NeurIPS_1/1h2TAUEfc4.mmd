# Exact Verification of ReLU Neural Control Barrier Functions

Hongchao Zhang

Electrical & Systems Engineering

Washington University in St. Louis

St. Louis, MO 63130

hongchao@wustl.edu

&Junlin Wu

Computer Science & Engineering

Washington University in St. Louis

St. Louis, MO 63130

junlin.wu@wustl.edu

&Yevgeniy Vorobeychik

Computer Science & Engineering

Washington University in St. Louis

St. Louis, MO 63130

yvorobeychik@wustl.edu

&Andrew Clark

Electrical & Systems Engineering

Washington University in St. Louis

St. Louis, MO 63130

andrewclark@wustl.edu

###### Abstract

Control Barrier Functions (CBFs) are a popular approach for safe control of nonlinear systems. In CBF-based control, the desired safety properties of the system are mapped to nonnegativity of a CBF, and the control input is chosen to ensure that the CBF remains nonnegative for all time. Recently, machine learning methods that represent CBFs as neural networks (neural control barrier functions, or NCBFs) have shown great promise due to the universal representability of neural networks. However, verifying that a learned CBF guarantees safety remains a challenging research problem. This paper presents novel exact conditions and algorithms for verifying safety of feedforward NCBFs with ReLU activation functions. The key challenge in doing so is that, due to the piecewise linearity of the ReLU function, the NCBF will be nondifferentiable at certain points, thus invalidating traditional safety verification methods that assume a smooth barrier function. We resolve this issue by leveraging a generalization of Nagumo's theorem for proving invariance of sets with nonsmooth boundaries to derive necessary and sufficient conditions for safety. Based on this condition, we propose an algorithm for safety verification of NCBFs that first decomposes the NCBF into piecewise linear segments and then solves a nonlinear program to verify safety of each segment as well as the intersections of the linear segments. We mitigate the complexity by only considering the boundary of the safe region and by pruning the segments with Interval Bound Propagation (IBP) and linear relaxation. We evaluate our approach through numerical studies with comparison to state-of-the-art SMT-based methods. Our code is available at [https://github.com/HongchaoZhang-HZ/exactverif-reluncbf-nips23](https://github.com/HongchaoZhang-HZ/exactverif-reluncbf-nips23).

## 1 Introduction

Safety is a critical property for autonomous systems, including unmanned ground, aerial, and space vehicles  and robotic manipulators . The importance of safety has motivated extensive research into verification and synthesis of safe control strategies . Control barrier function (CBF)-based algorithms  ensure safety by constructing a CBF that is nonnegative if the system is safe and synthesizing a control policy that ensures that the CBF is nonnegative for all time. Control barrier functions provide a high degree of flexibility, since any control policy that satisfies the control barrier function constraint is provably safe, and have been demonstrated in applications includingrobotic manipulation , vehicle cruise control  and space exploration . Recently, CBFs that are parametrized by neural networks (_neural control barrier functions_ or NCBFs)  have been proposed. This novel class of NCBFs is promising due to the universal representability of neural networks (enabling the encoding of complex safety constraints) and the efficiency of learning algorithms, with a comparison in Section A.15 exemplifying numerical difference. However, safety verification of NCBF-based control remains a challenging research problem.

In this paper, we consider the problem of verifying safety of NCBF-based control for nonlinear continuous-time systems. We focus on NCBFs represented by feedforward neural networks with ReLU activation due to their fast convergence in training shown in Section A.16 and widespread use in the safe control literature . The key challenge for this class of NCBFs is that most methodologies for safety verification are based on proving that the derivative of the barrier function is nonnegative at the boundary of the safe region, and hence the barrier function remains nonnegative for all time. Since the ReLU activation function is not continuously differentiable, this approach is inapplicable. We resolve this challenge and derive exact safety conditions for ReLU NCBFs by leveraging a generalization of Nagumo's theorem for proving invariance of sets with nonsmooth boundaries. Based on these conditions, we propose a new class of NCBF-based control policies that do not require the control policy and NCBF to be jointly trained, thus improving flexibility and tunability of the controller design. Our safety conditions also incorporate linear constraints on the control input, which may arise due to limits on actuation.

We propose an algorithm to verify that an NCBF satisfies our derived safety conditions, implying that any control policy that is constrained by the NCBF will be safe. Our approach first decomposes the NCBF into piecewise linear segments. In order to mitigate the complexity of this stage, we show that it suffices to consider linear segments at the boundary of the safe region, and further over-approximate the segments using Interval Bound Propagation and linear relaxation. After decomposing the NCBF, we verify safety by solving a set of nonlinear programs, which check the safety criteria on each linear segment as well as at intersections of the segments. We evaluate our approach through numerical studies, in which we verify NCBFs with our proposed approach and compare to state-of-the-art Satisfiability Modulo Theory (SMT) based methods.

**Related Work** Energy-based methods have been proposed to guarantee safety by ensuring that a particular energy function remains nonnegative. Barrier certificates for safe control were first proposed in . More recently, CBFs have emerged as promising approaches to safe control, due to their compatibility with a wide variety of control laws . Sum-of-squares (SOS) optimization and other techniques derived from algebraic geometry have been widely used for safety verification of polynomial barrier functions . However, SOS-based approaches for polynomial CBFs cannot be applied directly to NCBF verification, since activation functions used in neural networks are not polynomial and may be non-differentiable.

Neural barrier certificate  and NCBFs  have been proposed to describe complex safety constraints that cannot be encoded polynomials. Current work, including SMT-based methods  and mixed integer programs , verify safety by constructing a nominal control policy and proving that it satisfies the NCBF constraints. However, as we show in Section 5, the reliance on a particular control policy may lead to false negatives during safety verification. Another related body of work deals with the problem of verifying neural networks including SMT , output reachable set verification , polynomial approximations of the barrier function , verify input/output relationships  and ReLU neural networks focused verification . These methods, however, are not directly applicable to the problem of NCBF verification, which requires joint consideration of the neural network and the underlying nonlinear system dynamics. Methods based on input/output relationship can verify by encode dynamics and control policy with neural networks. However, with approximating error introduced, these methods are not directly applicable for exact verification. Piecewise linear approximations of ReLU neural networks have been used to develop tractable safety verification algorithms using linear  and SOS programming . These approaches leads to sound and incomplete verification algorithms and have only be applied for discrete-time systems, whereas the present paper proposes exact verification algorithms for continuous-time systems.

**Organization** The remainder of the paper is organized as follows. Section 2 gives the system model and background on neural networks and notation. Section 3 presents the problem formulation and exact conditions for safety. Section 4 presents our approach to verifying that an NCBF satisfies the safety conditions. Section 5 contains simulation results. Section 6 concludes the paper.

## 2 Model and Preliminaries

In this section, we first present the system model and definition of safety. We then give background and notations of feedforward neural networks.

### System Model and Safety Definition

We consider a continuous-time nonlinear control-affine system with state \(x(t)^{n}\), control input \(u(t)^{m}\), and dynamics

\[(t)=f(x(t))+g(x(t))u(t), \]

where \(f:^{n}^{n}\) and \(g:^{n}^{n m}\) are known functions. A control policy is a function \(:^{n}\) that maps a state \(x\) to a control input \(u\).

Safety of dynamical systems requires \(x(t)\) to remain in a given region \(\), which we denote as the safe region. We assume the safe region is given by \(=\{x:h(x) 0\}\), for some function \(h:\). Safety is related to the property of positive invariance, which we define as follows.

**Definition 1**.: _A set \(^{n}\) is positive invariant under dynamics (1) and control policy \(\) if \(x(0)\) and \(u(t)=(x(t))\  t 0\) imply that \(x(t)\) for all \(t 0\)._

We define a control policy \(\) to be _safe_ if there is a set \(\) such that (i) \(\) and (ii) \(\) is positive invariant under dynamics (1) and control policy \(\).

One approach to designing safe control policies is to choose a function \(b:^{n}\), denoted as a _Control Barrier Function (CBF)_, and let \(=\{x:b(x) 0\}\). In the case where \(b\) is continuously differentiable, the following result can be used to guarantee positive invariance of \(\).

**Theorem 1** ().: _Suppose that \(b\) is a CBF, \(b(x(0)) 0\), and \(u(t)\) satisfies_

\[(f(x)+g(x)u)-(b(x)). \]

_for all \(t\), where \(:\) is a strictly increasing function with \((0)=0\). Then the set \(=\{x:b(x) 0\}\) is positive invariant._

Theorem 1 implies that, if \(b\) is a CBF, then adding (2) as a constraint on the control at each time step suffices to guarantee safety.

Recently, Neural Control Barrier Functions (NCBFs), in which the function \(b\) is encoded by a neural network, have been proposed [12; 13; 14]. The advantage of NCBFs arises from the universal representability of neural networks, which allows them to realize a wide variety of safety constraints.

### Neural Network Background and Notation

We give notations to describe a neural network (NN) with \(L\) layers and \(M_{i}\) neurons in the \(i\)-th layer. We let the input to the NN be denoted \(x\), the output at the \(j\)-th neuron of the \(i\)-th layer be denoted \(z_{ij}\), and the output of the network be denoted \(y\). We let \(_{i}\) denote the vector of neuron outputs at the \(i\)-th layer. The outputs are computed as

\[z_{ij}=\{(W_{ij}^{T}x+r_{ij}),&i=1\\ (W_{ij}^{T}_{i-1}+r_{ij}),&i\{2,,L-1\} .,\ \ y=^{T}_{L}+ \]

where \(:\) is the activation function. The input to the function \(\) is the _pre-activation input_ to the neuron, and is given by \(W_{1j}^{T}x+r_{1j}\) for the \(j\)-th neuron at the first layer and \(W_{1j}^{T}_{i-1}+r_{ij}\) for the \(j\)-th neuron at the \(i\)-th hidden layer. \(W_{ij}\) has dimensionality \(n 1\) for \(i=1\) and \(M_{i-1} 1\) for \(i>1\). \(W_{i}\) is an \(n M_{i}\) matrix. In this paper, we assume that \(\) is the ReLU function \(ReLU(z)=\{0,z\}\). The output of the network is given by \(y=^{T}_{L}+\), where \(^{M_{L}}\) and \(\). The \(j\)-th neuron at the \(i\)-th layer is _activated_ by a particular input \(x\) if its pre-activation input is nonnegative, _inactivated_ if the pre-activation input is nonpositive, and _unstable_ if the pre-activation input is zero.

A set of neurons \(=(S_{1},,S_{L})\), with \(S_{i}\{1,,M_{i}\}\) denoting a subset of neurons at the \(i\)-th layer, is activated by \(x\) if all of the neurons in \(\) are activated by \(x\) and all the neurons not in \(\) are inactivated by \(x\). A set of neurons \(=(T_{1},,T_{L})\) with \(T_{i}\{1,,M_{i}\}\) is unstable by \(x\) if all of the neurons in \(\) are unstable by \(x\).

For a given set \(\), if \(\) is activated by \(x\), then the pre-activation input to each neuron and the overall output of the network are affine in \(x\), with the affine mapping determined by \(\) as follows. For the first layer, we define

\[_{1j}()=\{W_{1j},&j S_{1}\\ 0,&._{1j}()=\{ r_{1j},&j S_{1}\\ 0,&. \]

so that the output of the \(j\)-th neuron at the first layer is \(_{1j}()^{T}x+_{1j}()\). We recursively define \(_{ij}()\) and \(_{ij}()\) by letting \(_{i}()\) be a matrix with columns \(_{i1}(),,_{iM_{i}}()\) and

\[_{ij}()=\{_{i-1}( )W_{ij},&j S_{i}\\ 0,&._{ij}()=\{ W_{i}^{T}_{i-1}()+r_{ij},&j S_{i},\\ 0,&. \]

where \(}_{i}()\) is the vector with elements \(_{ij}()\), \(j=1,,M_{i}\).

We define \(()=}_{L}()\) and \(()=^{T}}_{L}()+\). Based on these notations, when an input \(x\) activates the set \(\), \(z_{ij}=_{ij}()^{T}x+_{ij}()\) and \(y=()^{T}x+()\).

**Lemma 1**.: _Let \(}()\) denote the set of inputs \(x\) that activate a particular set of neurons \(\), and let \(}_{0}()\) be equal to the identity matrix, and \(}_{0}\) to be zero vector. Then_

\[}()=_{i=1}^{L}( _{j S_{i}}\{x:W_{ij}^{T}(}_{i-1}()^{T}x+}_{i-1})+r_{ij} 0\}.\\ ._{j S_{i}}\{x:W_{ij}^{T}(}_{i-1}()^{T}x+}_{i-1})+r_{ij} 0 \}). \]

A proof can be found in the supplementary material. Note that in (6), a particular input \(x\) could belong to multiple activation regions \(}()\). This is because if the \(j\)-th neuron at the \(i\)-th layer is unstable, then both \((S_{1},,S_{i}\{j\},,S_{L})\) and \((S_{1},,S_{i}\{j\},,S_{L})\) can be regarded as activated by \(x\). We let \((x)\{:x}()\}\) and let \((x)\) denote the set of unstable neurons produced by input \(x\). Given a collection of activation sets \(_{1},,_{r}\), we let

\[(_{1},,_{r})=(_{l=1}^{r} _{l})(_{l=1}^{r}_{l}).\]

The set \((_{1},,_{r})\) is equal to the set of neurons that must be unstable in order for an input \(x\) to belong to \(}(_{1})}( _{r})\).

## 3 Problem Formulation and Safety Conditions

In this section, we first formally define the problem, and then give necessary and sufficient conditions for verifying NCBFs.

### Problem Formulation

We consider a feedforward neural network (NN) \(b:\) with ReLU activation function. Since \(b\) is not continuously differentiable due to the piecewise linearity of the ReLU function, the guarantees of Theorem 1 cannot be applied directly. Our overall goal will be to derive analogous conditions to (2) for ReLU-NCBFs, and then ensure that any control policy \(\) that satisfies the conditions will be safe with \(=\{x:b(x) 0\}\).

**Problem 1**.: _Given a nonlinear continuous-time system (1), a neural network function \(b:\), a set of admissible control inputs \(=\{u:Au c\}\) for given matrix \(A^{p m}\) and vector \(c^{p}\), and a safe set \(=\{x:h(x) 0\}\), determine whether (i) \(\) and (ii) there exists a control policy \(\) such that \(\) is positive invariant under dynamics (1) and control policy \(\)._

### Exact Conditions for Safety

When a CBF \(b(x)\) is continuously differentiable, ensuring that (2) is satisfied is equivalent to verifying that there is no \(x\) satisfying \(b(x)=0\), \(g(x)=0\), and \(f(x)<0\). When \(b\) is represented by a ReLU neural network, however, \(b\) will not be differentiable when the input \(x\) leads to neurons having zero pre-activation input, i.e., when \((x)\). Although the set of \(x\) with \((x)\) has measure zero, such points can nonetheless cause safety violations as illustrated by the following example.

**Example:** Let \(x(t)^{2}\) and suppose the dynamics of \(x\) are given by

\[_{1}(t)&=&x_{1}+u\\ _{2}(t)&=&-x_{1}+5x_{2} f(x)=( 1&0\\ -1&5)x,\;g(x)=(1\\ 0)\]

Suppose that \(=^{m}\), the safe region \(=\{x:x_{1}^{2}+x_{2}^{2} 9\}\), and the candidate CBF is given by \(b(x)=1-||x||_{1}\). This CBF can be realized by a neural network with a single layer (\(L=1\)) with four neurons (\(M_{1}=4\)), weights \(W_{11}=(1\,0)^{T}\), \(W_{12}=(-1\,0)^{T}\), \(W_{13}=(0\,1)^{T}\), \(W_{14}=(0\,\,-1)^{T}\), \(r_{1j}=0\) for \(j=1,,4\), \(_{j}=-1\) for \(j=1,,4\), and \(=1\). We observe that \(=\{x:b(x) 0\}\). Furthermore, whenever \(\) exists, we have \(\{(1\,1),(1\,\,-1),(-1\,1),(-1\,\,-1)\}\), each of which satisfies \(g(x) 0\). On the other hand, the set \(\) is not positive invariant. If \(x_{2}(0)>\), then \(|x_{1}(0)| 1\) implies that \(_{2}(0)>0\), and indeed, \(x_{2}(t)\) will continue to increase until \(x(t)\). More details about this example can be found in Section A.17.

Fundamentally, this safety violation occurs because at \(x=(0\,\,1)^{T}\), we have \(b(x)=0\), \((x)=\{(1,1),(1,2)\}\) (i.e., the preactivation input to the first and second neurons in the hidden layer is zero), creating a discontinuity in the slope of \(b(x)\). For \(x^{}\) in the neighborhood of \((0\,\,1)^{T}\), the value of \((x^{})g(x^{})\) will be either \(1\) or \(-1\). Since there is no single control input that satisfies (2) for both values of \(g(x^{})\), it is impossible to ensure safety of the system in the neighborhood of \((0\,\,1)^{T}\).

The following lemma addresses this issue by giving exact and general conditions for a NCBF with ReLU activation function to satisfy positive invariance. We let \(\) denote the boundary of the set \(\).

**Lemma 2**.: _The set \(\) is positive invariant under control policy \(\) if and only if, for all \(x\), there exist \((x)\) such that_

\[(}_{i-1}()W_{ij})^{T}(f(x)+g(x)( x))  0(i,j)(x) \] \[(}_{i-1}()W_{ij})^{T}(f(x)+g(x)( x))  0(i,j)(x)\] (8) \[()^{T}(f(x)+g(x)(x))  0 \]

The proof is based on the generalized Nagumo's Theorem  and a novel characterization of the Clarke tangent cone to \(\), and can be found in the supplementary material due to space constraints. Intuitively, conditions (7)-(9) can be interpreted as follows. Condition (9) is similar to (2) when the gradient is given by \(()\), i.e., when \(x\) is in the interior of the activation region defined by \(\). Eq. (7)-(8) can be interpreted as choosing the control input to ensure that \(x\) remains in the activation region of \(\) (i.e., \(}()\)).

Lemma 2 can be used to construct NCBF-based safe control policies, analogous to control policies based on continuously differentiable CBFs. Formally, given a nominal control policy \(_{nom}\), at each time \(t\), we can choose \(u(t)\) by solving the optimization problem

\[_{(x),u}&||u-_{nom}(x(t))||_{2 }^{2}\\ &()^{T}(f(x)+g(x)(x))-(b(x))\\ &u,(7),(8) \]

where \(\) satisfies the same conditions as in Theorem 1. This problem can be solved by decomposing (10) into \(|(x)|\) quadratic programs (one for each \(\)) and then selecting the value of \(u\) that minimizes the objective function across all of the QPs. In particular, if \((x)\) is a singleton, then the constraints on (10) reduce to Eq. (2).

We then give an equivalent condition for \(b(x)\) to be an NCBF. As a preliminary, we say that a collection of activation sets \(_{1},,_{r}\) is _complete_ if for any \(^{}\{_{1},,_{r}\}\), we have \(}(_{1})}( _{r})}(^{})=\).

**Proposition 1**.: _The function \(b\) is a valid CBF iff the following two properties hold:_

1. _For all activation sets_ \(_{1},,_{r}\) _with_ \(\{_{1},,_{r}\}\) _complete and any_ \(x\) _satisfying_ \(b(x)=0\) _and_ \[x(_{l=1}^{r}}(_{l})),\] (11) _there exist_ \(l\{1,,r\}\) _and_ \(u\) _such that_ \[(}_{i-1}(_{l})W_{ij})^{T}(f(x)+g(x)u)  0 (i,j)(_{1},,_{r}) _{l}\] (12) \[(}_{i-1}(_{l})W_{ij})^{T}(f(x)+g(x)u)  0 (i,j)(_{1},,_{r}) _{l}\] (13) \[(_{l})^{T}(f(x)+g(x)u)  0\] (14)
2. _For all activation sets_ \(\)_, we have_ \[(}())=\] (15)

The proof can be found in the supplementary material. We refer to any \(x\) that fails to meet at least one of conditions (i) and (ii) of Proposition 1 as a safety counterexample.

## 4 Verification Algorithm

The preceding proposition motivates our overall approach to verifying NCBFs, consisting of the following steps. **(Step 1)** We conduct coarser-to-finer search by discretizing the state space into hyper-cubes and use linear relaxation based perturbation analysis (LiRPA) to identify grid squares that intersect the boundary \(\{x:b(x)=0\}\). **(Step 2)** We enumerate all possible activation sets within each hyper-cube using Interval Bound Propagation (IBP). We then identify the activation sets and intersections that satisfy \(b(x)=0\) using linear programming. **(Step 3)** For each activation set and intersection of activation sets, we verify the conditions of Proposition 1. In what follows, we describe each step in detail.

### Enumeration of Activation Set Boundaries

We next present the approach to enumerate activation sets of a given ReLU NCBF that intersect the safety boundary, \(b(x)=0\). Our approach first conducts a coarse-grained search that over-approximates the collection of activation sets that intersect with the safety boundary. We then prune this collection to remove activation sets that cannot be realized. Specifically, we first identify regions that contain \(b(x)=0\), then enumerate all possible activation sets within the region and finally identify the sets that intersect the safety boundaries.

We first discretize the given state space \(\) into hyper-cubes. We compute lower and upper bounds of \(b(x)\) on each hyper-cube, denoted \(b_{l}\) and \(b_{u}\) respectively, with linear relaxation based perturbation analysis (LiRPA), i.e., auto LiRPA . For each hyper-cube \(B\), we determine \(B\) contains \(b(x)=0\) (red squares in Fig 1) if criteria \(sgn(b_{l}) sgn(b_{u}) 0\) holds, where \(sgn(*)\) is the sign function. For each \(B\) contains \(b(x)=0\), we utilize IBP to over-approximate unstable neurons. Details on this IBP procedure can be found in Section A.7. Let \(}\) denote the over-approximated collection of activation

Figure 1: Illustration of proposed coarser-to-finer searching method. Hyper-cubes that intersect the safety boundaries are marked in red. When all possible activation sets are listed, we can identify exact activation set and intersections.

sets computed by IBP. Note that \(}\) may not intersect with \(b(x)=0\). As shown in Fig. 1, we let \(\) denote the collection of activation sets \(}\) that satisfy

\[()^{T}x+() =0\] \[(}_{i-1}()W_{ij})^{T}x+_ {ij}()  0\;(i,j) \] \[(}_{i-1}()W_{ij})^{T}x+_{ij}()  0\;(i,j)\]

for some \(x B\). The activation set boundaries indicate unstable neurons, which need to be verified separately. Hence, we search for intersections as follows, where \(2^{}\) denotes the set of subsets of \(\).

\[=\{Z 2^{}:(_{ Z} }())\{x:b(x)=0\}\}\]

### Verifying Safety of Each Activation Set

With the activation sets enumerated, the following result gives an equivalent condition for verifying that there is no safety counterexample in the interior of \(}()\) for a given activation set \(\).

**Lemma 3**.: _There is no safety counterexample in the set \(}()_{^{} }}()\) if and only if:_

1. _There do not exist_ \(x\) _and_ \(y^{p+1}\) _satisfying (a)_ \(x(}())\)_, (b)_ \(b(x)=0\)_, (c)_ \(y 0\)_, (d)_ \(y^{T}(-()^{T}g(x)\\ A)=0\)_, and (e)_ \(y^{T}(()^{T}f(x)\\ c)<0\)_._
2. _There does not exist_ \(x\) _with_ \(b(x)=0\)_,_ \(x(}())\)_, and_ \(h(x)<0\)_._

The proof can be found in the supplementary material. Conditions 1 and 2 of Lemma 3 can be verified by solving nonlinear programs (see supplementary material for the formulations of these nonlinear programs). Such nonlinear programs are solved for each activation set \(\) in the collection \(\) computed during the enumeration phase. The following corollary describes the special case where there are no constraints on the control, i.e., \(=^{m}\).

**Corollary 1**.: _If \(=^{m}\), then there is no safety counterexample in the set \(}()_{^{} }}(^{})\) if and only if (1) there does not exist \(x\) satisfying \(x(}())\), \(b(x)=0\), \(()^{T}g(x)=0\), and \(()^{T}f(x)<0\) and (2) there does not exist \(x\) with \(b(x)=0\), \(x(}())\), and \(h(x)<0\)._

Under the conditions of Corollary 1, the complexity of the verification problem can be reduced. If \(g(x)\) is a constant matrix \(G\), then safety is automatically guaranteed if \(()^{T}G 0\). If \(f(x)\) is linear in \(x\) as well, then verification can be performed via a linear program.

### Verification of Activation Set Intersections

With the activation set boundaries enumerated, we now describe an approach for verifying safety of intersections between activation sets.

**Lemma 4**.: _Suppose that the sets \(_{1},,_{r}\) satisfy condition (ii) of Lemma 3. There is no safety counterexample in the set_

\[}(_{1})}( _{r})_{S^{}\{_{1},, _{r}\}}}(^{})\]

_if and only if there do not exist \(x\) and \(y_{1},,y_{r}^{T+p+1}\), where \(T=|(_{1},,_{r})|\), satisfying (a) \(x(}(_{1})) (}(_{r}))\), (b) \(b(x)=0\), (c) \(y_{l} 0\; l\), (d) \( l=1,,r\), \(y_{l}^{T}_{l}(_{1},,_{r}(x))=0\), where \(_{l}(_{1},,_{r},x)\) is a \((T+p+1) m\) matrix_

\[_{l}(_{1},,_{r},x)( []{c}-(}_{i-1}(_{l})W_{ij})^{T}g(x):(i,j) (_{1},,_{r})_{l}\\ (}_{i-1}(_{l})W_{ij})^{T}g(x):(i,j)(_{1},,_{r})_{l}\\ -W(_{l})^{T}g(x)\\ A) \]_and (e) \( l=1,,r\), \(y_{l}^{T}_{l}(_{1},,_{r},x)<0\), where \(_{l}(_{1},,_{r},x)^{T+p+1}\) is given by_

\[_{l}(_{1},,_{r},x)( []{c}(}_{i-1}(_{l})W_{ij})^{T}f(x):(i,j) (_{1},,_{r})_{l}\\ -(}_{i-1}(_{l})W_{ij})^{T}f(x):(i,j)(_{1},,_{r})_{l}\\ }(_{l})^{T}f(x)\\ c) \]

The proof can be found in the supplementary material. The verification problem can be mapped to solving a nonlinear program. This nonlinear program is solved for each \((_{1},,_{r})\), where \(\) is computed during the enumeration phase. Note that, if \(g(x)\) is constant, then the constraints of the nonlinear program are linear, and if \(f(x)\) is linear then the problem reduces to solving a system of linear and bilinear inequalities. Furthermore, if \(f(x)\) can be bounded over \(x}(_{1})} (_{r})\) and \(b(x)=0\), then this bound can be used to derive a linear relaxation to the objective function of (27), thus relaxing the nonlinear program to a linear program.

The complexity of this approach can also be reduced by utilizing sufficient conditions for safety that are easier to check. For instance, if there exists \(u\) such that \(()^{T}(f(x)+g(x)u) 0\) for all \((x)\), then the criteria of Lemma 4 are satisfied. In particular, if \(()^{T}f(x) 0\) for all \((x)\), then the conditions are satisfied with \(u=0\). The following result is a straightforward consequence of Proposition 1, Lemma 3, and Lemma 4.

**Theorem 2**.: _Suppose that the conditions of Lemma 3 are satisfied for each \(\) and the conditions of Lemma 4 are satisfied for each \(\{_{1},,_{r}\}\). Then the NCBF \(b\) satisfies the conditions of Problem 1._

## 5 Experiments

In this section, we evaluate our proposed method to verify neural control barrier functions on three systems, namely Darboux, obstacle avoidance and spacecraft rendezvous. The experiments run on a 64-bit Windows PC with Intel i7-12700 processor, 32GB RAM and NVIDIA GeForce RTX 3080 GPU. We include experiment details in the supplement.

### Experiment Setup

**Darboux:** We consider the Darboux system , a nonlinear open-loop polynomial system that has been widely used as a benchmark for constructing barrier certificates. The dynamic model is given in the supplement. We obtain the trained NCBF by following the method proposed in .

**Obstacle Avoidance (OA):** We evaluate our proposed method on a controlled system . We consider an Unmanned Aerial Vehicles (UAVs) avoiding collision with a tree trunk. We model the system as a Dubins-style  aircraft model. The system state consists of 2-D position and aircraft yaw rate \(x:=[x_{1},x_{2},]^{T}\). We let \(u\) denote the control input to manipulate yaw rate and the dynamics defined in the supplement. We train the NCBF via the method proposed in  with \(v\) assumed to be \(1\) and the control law \(u\) designed as \(u=_{nom}(x)=-+3+x_{2}-}{0.5x_{1}^{ +}+x_{2}^{-}}\).

**Spacecraft Rendezvous (SR):** We evaluate our approach on a spacecraft rendezvous problem from . A station-keeping controller is required to keep the "chaser" satellite within a certain relative distance to the "target" satellite. The state of the chaser is expressed relative to the target using linearized Clohessy-Wiltshire-Hill equations, with state \(x=[p_{x},p_{y},p_{z},v_{x},v_{y},v_{z}]^{T}\), control input \(u=[u_{x},u_{y},u_{z}]^{T}\) and dynamics defined in the supplement. We train the NCBF as in .

**hi-ord\({}_{}\):** We evaluate our approach on an eight-dimensional system that first appeared in  to evaluate the scalability of proposed verification method.

### Experiment Results

We first verify that \(\) in the Darboux and obstacle avoidance scenarios. We trained four \(1\) hidden layer NCBFs with \(20\), \(5\), \(32\), \(10\) neurons, respectively. NCBF (a) and (c) completed training, (b) terminated after \(3\) epochs and (d) terminated after \(5\) epochs. Our verification algorithm identifies safety violations. NCBF (a) and (c) pass the verification while NCBF (b) and (d) fail. As shown in Fig. (a)a, the fully-trained NCBF (a) separates the safe and unsafe regions while the NCBF (b) with unfinished training has a boundary that intersects the unsafe region in Fig. (b)b. As shown in Fig. (d)d, the 2-D projection with \(=-0.5\) of NCBF (d) shows its boundary overlap the unsafe region.

We next verify the positive invariance of \(\). All NCBFs for Darboux pass feasibility verification with run-time presented in Table 1. We compare the run-time of proposed verification with SMT-based approaches using translator proposed in  and SMT solver dReal  and Z3 . The proposed method can verify NCBFs with more ReLU neurons while SMT-based verifier return nothing.

All of the generated NCBFs for obstacle avoidance and spacecraft rendezvous passed the verification. The run-times are presented in Table 2. We find that the activation set sizes grow with the size of neural network and the state dimension \(n\). We conjecture that this growth rate could be reduced by using tighter approximations for the activated sets.

A key feature of our approach is that the verification process does not depend on the control policy \(\), but rather we verify that any \(\) satisfying (7)-(9) for all \(x\) is safe. This improves flexibility while reducing false negatives in safety verification, as we illustrate in the following example. The NCBF for obstacle avoidance with one hidden layer and \(32\) neurons fails the SMT-based verification using dReal given nominal controller \(_{nom}\). The counter example is at the point \((-0.20,0,-0.73)\). At this point, we have \(b(x)=0.0033\), \(f(x)=0.0095\), which satisfies the sufficient conditions for safety in Lemma 2. However, the nominal controller yields \((f(x)+g(x)u)=-1.30\) and hence

  Case & n & NN Architecture & \(N\) & \(t_{e}\) & \(t_{v}\) & \(T\) & \(T_{dReal}\) & \(T_{Z3}\) \\   & 2 & 2-20-\(\)-1 & 13 & 0.39 & 0.04 & 0.43 & 0.36 & 3hrs \\  & 2 & 2-32-\(\)-1 & 20 & 0.23 & 0.03 & 0.27 & 1.27 & 3hrs \\  & 2 & 2-64-\(\)-1 & 47 & 1.89 & 0.13 & 2.02 & 3hrs & 3hrs \\  & 2 & 2-96-\(\)-1 & 63 & 4.17 & 0.14 & 4.31 & 3hrs & 3hrs \\  & 2 & 2-128-\(\)-1 & 65 & 4.77 & 0.03 & 4.90 & 3hrs & 3hrs \\  & 2 & 2-512-\(\)-1 & 258 & 33.44 & 0.61 & 34.05 & 3hrs & 3hrs \\  & 2 & 2-1024-\(\)-1 & 548 & 107.63 & 0.81 & 108.44 & 3hrs & 3hrs \\   & 2 & 2-10-\(\)-10-\(\)-1 & 4 & 0.42 & 0.05 & 0.47 & 7.70 & 15.81 \\  & 2 & 2-16-\(\)-16-\(\)-1 & 26 & 2.13 & 0.11 & 2.23 & 3hrs & 3hrs \\  & 2 & 2-32-\(\)-32-\(\)-1 & 58 & 8.35 & 6.28 & 14.64 & 3hrs & 3hrs \\  & 2 & 2-48-\(\)-48-\(\)-1 & 58 & 13.69 & 0.19 & 13.88 & 3hrs & 3hrs \\  & 2 & 2-64-\(\)-64-\(\)-1 & 102 & 31.30 & 0.47 & 31.77 & 3hrs & 3hrs \\  & 2 & 2-256-\(\)-256-\(\)-1 & 402 & 319.81 & 1.92 & 321.73 & 3hrs & 3hrs \\  & 2 & 2-512-\(\)-512-\(\)-1 & 1150 & 619.10 & 0.75 & 619.85 & 3hrs & 3hrs \\  _{}\)} & 8 & 8-8-\(\)-1 & 98 & 3.70 & 0.02 & 3.72 & 3hrs & 3hrs \\  & 8 & 8-16-\(\)-1 & 37 & 35.05 & 0.0 & 35.05 & 3hrs & 3hrs \\  

Table 1: Comparison of verification run-time of NCBF in seconds. The table contains the dimension \(n\), network architecture with \(\) denoting ReLU, the number of activation sets \(N\) and run-time of proposed method including time of enumerating, verification and total run-time denoted as \(t_{e}\), \(t_{v}\) and \(T\), respectively. We compare with the run-time of dReal (\(T_{dReal}\)) and Z3 (\(T_{Z3}\)).

Figure 2: Comparison of NCBFs that pass and fail the proposed verification. We show \(0\)-level set boundary in blue, initial region in green and the unsafe region in red. (a) and (b) visualize NCBFs for Darboux. (c) and (d) shows projection of NCBFs for Obstacle Avoidance.

fails verification. Hence, by following a safe control policy of the form (10) with the learned value of \(b\) and nominal policy \(_{nom}\), we can retain the performance of \(_{nom}\) while still ensuring safety.

The computational complexity of our approach will be determined by several factors including the dimension of the state, the number of layers, the number of neurons in each layer, and the geometry of the \(0\)-level set of the NCBF. As shown in Table 2, the dimension of the system plays the most important role.

## 6 Conclusion

This paper studied the problem of verifying safety of a nonlinear control system using a NCBF represented by a feed-forward neural network with ReLU activation function. We leveraged a generalization of Nagumo's theorem for proving invariance of sets with nonsmooth boundaries to derive necessary and sufficient conditions for safety. The exact safety conditions addressed the issue that ReLU NCBFs will be nondifferentiable at certain points, thus invalidating traditional safety verification methods. Based on this condition, we proposed an algorithm for safety verification of NCBFs that first decomposes the NCBF into piecewise linear segments and then solves a nonlinear program to verify safety of each segment as well as the intersections of the linear segments. We mitigated the complexity by only considering the boundary of the safe region and pruning the segments with IBP and LiRPA. We evaluated our approach through numerical studies with comparison to state-of-the-art SMT-based methods. Future extensions of this work could include improving scalability for higher-dimensional systems and deeper neural networks, as well as other activation functions.