# Persistent Homology for High-dimensional Data

Based on Spectral Methods

 Sebastian Damrich\({}^{}\)   Philipp Berens\({}^{}{}^{}\)   Dmitry Kobak\({}^{}{}^{@sectionsign}\)

\({}^{}\) Hertie Institute for AI in Brain Health, University of Tubingen, Germany

\({}^{}\) Tubingen AI Center, Germany

\({}^{@sectionsign}\) IWR, Heidelberg University, Germany

{sebastian.damrich,philipp.berens,dmitry.kobak}@uni-tuebingen.de

###### Abstract

Persistent homology is a popular computational tool for analyzing the topology of point clouds, such as the presence of loops or voids. However, many real-world datasets with low intrinsic dimensionality reside in an ambient space of much higher dimensionality. We show that in this case traditional persistent homology becomes very sensitive to noise and fails to detect the correct topology. The same holds true for existing refinements of persistent homology. As a remedy, we find that spectral distances on the \(k\)-nearest-neighbor graph of the data, such as diffusion distance and effective resistance, allow to detect the correct topology even in the presence of high-dimensional noise. Moreover, we derive a novel closed-form formula for effective resistance, and describe its relation to diffusion distances. Finally, we apply these methods to high-dimensional single-cell RNA-sequencing data and show that spectral distances allow robust detection of cell cycle loops.

## 1 Introduction

Algebraic topology can describe the shape of a continuous manifold. In particular, it can detect if a manifold has holes, using its so-called homology groups . For example, a cup has a single one-dimensional hole, or _loop_ (its handle), whereas a football has a single two-dimensional hole, or _void_ (its hollow interior). These global topological properties are often helpful for understanding an object's overall structure. However, real-world datasets are typically given as point clouds, a discrete set of points sampled from an underlying manifold. In this setting, true homologies are trivial, as there is one connected component per point and no holes whatsoever; instead, _persistent homology_ can be used to find holes in point clouds and to assign an importance score called _persistence_ to each . Holes with high persistence are indicative of holes in the underlying manifold. Persistence homology has been successfully applied in machine learning pipelines, for instance for gait recognition , instance segmentation , and protein binding , as well as for neural network analysis .

Persistent homology works well for low-dimensional data  but we find that it has difficulties in high dimensionality. If data points are sampled from a low-dimensional manifold embedded in a high-dimensional ambient space (_manifold hypothesis_), then the measurement noise typically affects all ambient dimensions. In this setting, traditional persistent homology is not robust against even low levels of noise. On a dataset as simple as a circle in \(^{50}\), persistent homology based on the Euclidean distance between noisy points can fail to identify the correct loop as a clear outlier in the persistence diagram (Figure 1). The aim of our work is to find alternatives to traditional persistent homology that can robustly detect the correct topology despite high-dimensional noise.

We were inspired by visualization methods \(t\)-SNE  and UMAP  that are able to depict the loop in the same noisy dataset (Figure 1d,e). They approximate the data manifold by the \(k\)-nearest-neighbor (\(k\)NN) graph . Therefore, we suggest to use persistent homology with spectraldistances on this \(k\)NN graph, such as the effective resistance  and the diffusion distance . Effective resistance successfully identified the correct loop in the above toy example (Figure 1). We also found spectral distances to outperform other distances in detecting the correct topology of several synthetic datasets as well as finding the cell cycles in single-cell RNA-sequencing data.

Our contributions are:

1. an analysis of the failure modes of persistent homology for noisy high-dimensional data;
2. a closed-form expression for effective resistance, explaining its relation to diffusion distances;
3. a synthetic benchmark, with spectral distances outperforming state-of-the-art alternatives;
4. an application to a range of single-cell RNA-sequencing datasets with ground-truth cycles.

Our code is available at [https://github.com/berenslab/eff-ph/tree/neurips2024](https://github.com/berenslab/eff-ph/tree/neurips2024).

## 2 Related work

Persistent homology has long been known to be sensitive to outliers  and several extensions have been proposed to make it more robust. One recurring idea is to replace the Euclidean distance with a different distance matrix, before running persistent homology. Bendich et al.  suggested to use diffusion distances , but their empirical validation was limited to a single dataset in 2D. Anai et al.  suggested to use the distance-to-measure (DTM)  and Fernandez et al.  proposed to use Fermat distances . Vishwanath et al.  introduced persistent homology based on robust kernel density estimation, an approach that itself becomes challenging in high dimensionality. All of these works focused on low-dimensional datasets (\(<\)10D, mostly 2D or 3D), while our work specifically addresses the challenges of persistent homology in high dimensionality.

The concurrent work of Hiraoka et al.  is the most relevant related work. Their treatment of the curse of dimensionality of persistent homology is mostly theoretical, while ours has an empirical focus. The two works are thus complementary to each other. Hiraoka et al.'s theoretical description of the curse of dimensionality is similar to ours (Appendix B) in that it analyses how distance concentration with high-dimensional noise impairs persistent homology, but is more general. Practically, Hiraoka et al. propose normalized PCA to mitigate the curse of dimensionality. However, this approach assumes the true dimensionality of the data to be known, which is not realistic in real-world applications, and performs worse than our suggestions (Appendix C).

Below, we recommend using effective resistance and diffusion distances for persistent homology in high-dimensional spaces. Both of these distances, as well as the shortest path distance, have been used in combination with persistent homology to analyze the topology of graph data [62; 37; 1; 77; 11; 55]. Shortest paths on the \(k\)NN graph were also used by Naitzat et al.  and Fernandez et al. . Motivated by the performance of UMAP  for dimensionality reduction, Gardner et al.  and Hermansen et al.  used UMAP affinities to define distances for persistent homology.

Figure 1: **a.** 2D PCA of a noisy circle (\(=0.25\), radius 1) in \(^{50}\). Overlaid are representative cycles of the most persistent loops. **b.** Persistence diagrams using Euclidean distance and the effective resistance. **c.** Loop detection scores of persistent homology using effective resistance and Euclidean distance. **d, e.** UMAP and \(t\)-SNE embeddings of the same data, showing the loop structure in 2D.

Effective resistance is a well-established graph distance [24; 29]. A correction, more appropriate for large graphs, was suggested by von Luxburg et al. [81; 83]. When speaking of _effective resistance_, we mean this corrected version, if not otherwise stated. It has not yet been combined with persistent homology. Conceptually similar diffusion distances  have been used in single-cell RNA-sequencing data analysis, for dimensionality reduction , trajectory inference , feature extraction , and hierarchical clustering, similar to 0D persistent homology [9; 46].

Persistent homology has been applied to single-cell RNA-sequencing data, but only the concurrent work of Flores-Bautista and Thomson  applies it directly to the high-dimensional data. Wang et al.  used a Witness complex on a PCA of the data. Other works applied persistent homology to a derived graph, e.g., a gene regulator network  or a Mapper graph [73; 68]. In other biological contexts, persistent homology has also been applied to a low-dimensional representation of the data: 3D projection of cytometry data , 6D PCA of hippocampal spiking data , and 3D PHATE embedding of calcium signaling . Several recent applications of persistent homology only computed 0D features (i.e. clusters) [37; 45; 61], which amounts to doing single linkage clustering . Here we only investigate the detection of higher-dimensional (1D and 2D) holes with persistent homology. The dimensionality of the data itself, however, is typically much higher.

## 3 Background: persistent homology

Persistent homology computes topological invariants of a space at different scales. For point clouds, the different scales are typically given by growing a ball around each point (Figure 2a), and letting the radius \(\) grow from 0 to infinity. For each value of \(\), homology groups of the union of all balls are computed to find the holes, and holes that _persist_ for longer time periods are considered more prominent. At \( 0\), there are no holes as the balls are non-overlapping, while at \(\) there are no holes as all the balls merge together.

To keep the computation tractable, instead of the union of growing balls, persistent homology operates on a so-called _filtered simplicial complex_ (Figure 2a). A simplicial complex is a hypergraph containing points as nodes, edges between nodes, triangles bounded by edges, and so forth. These building blocks are called _simplices_. At each time \(\), the complex encodes all intersections between the balls and suffices to find the holes. The complexes at smaller \(\) values are nested within the complexes at larger \(\) values, and together form a filtered simplicial complex, with \(\) being the filtration time. In this work, we only use the Vietoris-Rips complex, which includes an \(n\)-simplex \((v_{0},v_{1},,v_{n})\) at filtration time \(\) if the distances between all pairs \(v_{i},v_{j}\) are at most \(\). Therefore, to build a Vietoris-Rips complex, it suffices to provide pairwise distances between all pairs of points. We compute persistent homology via the ripser package  to which we pass a distance matrix.

Persistent homology consists of a set of holes for each dimension. We limit ourselves to loops and voids. Each hole has associated birth and death times \((_{b},_{d})\), i.e., the first and last filtration value \(\) at which that hole exists. Their difference \(p=_{d}-_{b}\) is called the _persistence_ of the hole and quantifies its prominence. The birth and death times can be visualized as a scatter plot (Figure 2b), known as the _persistence diagram_. Points far from the diagonal have high persistence. This process is illustrated in Figure 2 for a noisy sample of \(n=10\) points from a circle \(S^{1}^{2}\). At \(_{1}\), a small spurious loop is formed thanks to the inclusion of the dotted edge, but it dies soon afterwards. The ground-truth loop is formed at \(_{2}\) and dies at \(_{3}\), once the hole is completely filled in by triangles. Both loops (one-dimensional holes) found in this dataset are shown in the persistence diagram.

Figure 2: **a.** Persistent homology applied to a noisy circle (\(n=10\)) in 2D tracks appearing and disappearing holes as balls grow around each datapoint. Dotted lines show the graph edges that lead to the birth / death of two loops (Section 3). **b.** The corresponding persistence diagram with two detected 1D holes (loops). Our _hole detection score_ measures the gap in persistence between the first and the second detected holes (Section 7).

## 4 The curse of dimensionality for persistent homology

While persistent homology is robust to small changes in point positions , the curse of dimensionality can still severely hurt its performance. To illustrate, we consider the same toy setting as in Figure 1: we sample points from \(S^{1}^{d}\), and add Gaussian noise of standard deviation \(\) to each ambient coordinate. When \(d=2\), higher noise does not affect the birth times but leads to lower death times (Figure 3a), because some points get distorted to the middle of the circle and the hole fills up at earlier \(\). When we increase the ambient dimensionality to \(d=20\), higher noise leads to later birth times (Figure 3b) because in higher dimensionality distances get dominated by the noise dimensions rather than by the circular structure. Indeed, in Corollary B.5 we prove that for any two points \(x_{i},x_{j}^{d}\) and two isotropic, multivariate normal noise vectors \(_{1},_{2}(,^{2}_{d})\) the ratio \(\|_{1}-_{2}\|/\|x_{i}+_{1}-(x_{2}+ _{2})\| 1\) in probability as \(d\). Finally, for \(d=50\) both the birth _and_ the death times increase with \(\) (Figure 3c, Corollary B.7) and the ground-truth hole disappears in the cloud of spurious holes. Applying MDS to the Euclidean distances obtained with \(d=50\) and \(=0.25\) yields a 2D layout with almost no visible hole, because all distances have become similar (Figure 3d). See the concurrent work of Hiraoka et al.  for a more detailed treatment.

Therefore, the failure modes of persistent homology differ between low- and high-dimensional spaces. While in low dimensions, persistent homology is susceptible to outlier points in the middle of the circle, in high dimensions, there are no points in the middle of the circle; instead, all distances become too similar, hiding the true loops. See Appendix N for more details on the effect of outliers.

## 5 Spectral distances are more robust

Many modern manifold learning and dimensionality reduction methods rely on the \(k\)-nearest-neighbor (\(k\)NN) graph of the data. This works well because, although distances become increasingly similar in high-dimensional spaces, nearest neighbors still carry information about the data manifold. To make persistent homology overcome high-dimensional noise, we therefore suggest to rely on the symmetric \(k\)NN graph, which contains edge \(ij\) if node \(i\) is among the \(k\) nearest neighbors of \(j\) or vice versa. A natural choice is to use its geodesics, but, as we show below, this does not work well, likely because a single graph edge across a circle can destroy the corresponding feature too early. Instead, we propose to use spectral methods, such as the effective resistance or diffusion distance. Both methods rely on random walks and thus incorporate information from all edges.

For a connected graph \(G\) with \(n\) nodes, e.g., the symmetric \(k\)NN graph, let \(A\) be its symmetric, \(n n\) adjacency matrix with elements \(a_{ij}=1\) if edge \(ij\) exits in \(G\) and \(a_{ij}=0\) otherwise. The degree matrix \(D\) is defined by \(D=\{d_{i}\}\), where \(d_{i}=_{j=1}^{n}a_{ij}\) are the node degrees. We define \((G)=_{i=1}^{n}d_{i}\). Let \(H_{ij}\) be the _hitting time_ from node \(i\) to \(j\), i.e., the average number of edges it takes a random walker, that starts at node \(i\) randomly moving along edges, to reach node \(j\). The naive effective resistance is defined as \(^{}_{ij}=(H_{ij}+H_{ji})/(G)\). This version is known to be unsuitable for large graphs (Figure S20) because it reduces to \(^{}_{ij} 1/d_{i}+1/d_{j}\). Therefore, we used von Luxburg et al. 's corrected version

\[d^{}_{ij}=^{}_{ij}-1/d_{i}-1/d_{j}+2a_{ij}/(d_{i }d_{j})-a_{ii}/d_{i}^{2}-a_{jj}/d_{j}^{2}. \]

Figure 3: \(\). Persistence diagrams of a noisy circle in different ambient dimensionality and with different amount of noise. Ideally, there should be one feature (point) with high persistence, corresponding to the circle. But for high noise and dimensionality that feature vanishes into the noise cloud near the diagonal. \(\). Multidimensional scaling of Euclidean, effective resistance, and diffusion distances for a noisy circle in \(^{50}\). Color indicates the distance to the highlighted point.

Diffusion distances also rely on random walks. The random walk transition matrix is given by \(P=D^{-1}A\). Then \(P_{i,.}^{t}\), the \(i\)-th row of \(P^{t}\), holds the probability distribution over nodes after \(t\) steps of a random walker starting at node \(i\). The diffusion distance is then defined as

\[d_{ij}(t)=()}\|(P_{i,.}^{t}-P_{j,.}^{t})D^{-}\|. \]

There are many possible random walks between nodes \(i\) and \(j\) if they both reside in the same densely connected region of the graph, while it is unlikely for a random walker to cross between sparsely connected regions. As a result, both effective resistance and diffusion distance are small between parts of the graph that are densely connected and are robust against single stray edges (Figure 4). This makes spectral distances on the \(k\)NN graph the ideal input to persistent homology for detecting the topology of data in high-dimensional spaces. Indeed, the MDS embedding of the effective resistance and of the diffusion distance of the circle in ambient \(^{50}\) both clearly show the circular structure (Figure 3e,f).

## 6 Relation between spectral distances

We show in Section 7 that spectral methods excel as input distances to persistent homology for high-dimensional data. But first, we explain the relationships between them. Laplacian Eigenmaps distance and diffusion distance can be written as Euclidean distances in data representations given by appropriately scaled eigenvectors of the graph Laplacian. In this section, we derive a similar closed-form formula for effective resistance and show that effective resistance aggregates all but the most local diffusion distances.

Let \(A^{}=D^{-}AD^{-}\) and \(L^{}=I-A^{}\) be the symmetrically normalized adjacency and Laplacian matrix. We denote the eigenvectors of \(L^{}\) by \(u_{1},,u_{n}\) and their eigenvalues by \(_{1},,_{n}\) in increasing order. For a connected graph, \(_{1}=0\) and \(u_{1}=D^{}(1,,1)^{}/(G)}\).

The \(\)-dimensional Laplacian Eigenmaps embedding is given by the first \(\) nontrivial eigenvectors:

\[d_{ij}^{}()=\|e_{i}^{}()-e_{j}^{ }()\|,e_{i}^{}()=(u_{2,i},,u_{( +1),i}). \]

The diffusion distance after \(t\) diffusion steps is given by 

\[d_{ij}^{}(t)=(G)}\|e_{i}^{}(t)-e_{j}^{ }(t)\|,e_{i}^{}(t)=(1-_{2})^{t}u_ {2,i},,(1-_{n})^{t}u_{n,i}}{}}. \]

The original uncorrected version of effective resistance is given by 

\[_{ij}^{}=\|_{i}^{}-_{j}^{ {eff}}\|^{2},_{i}^{}=u_{2,i}/},,u_{n,i}/ }/}. \]

In Appendix F we prove that the corrected effective resistance  can also be written in this form:

**Proposition 6.1**.: _The corrected effective resistance distance can be computed by_

\[d_{ij}^{}=\|e_{i}^{}-e_{j}^{}\|^{2},e_{i}^{}=(}{}}u_{2,i},,}{}}u_{n,i})}. \]

Figure 4: Robustness of effective resistance. We sampled \(n=1\,000\) points from a noisy circle in 2D with Gaussian noise of standard deviation \(=0.1\), constructed the unweighted symmetric \(15\)-NN graph, and optionally added 10 random edges (thick lines). Node colors indicate the graph distance from the fat black dot. **a.** The geodesic distance is severely affected by the random edges. **b.** The effective resistance distance is robust to them.

It has been known  that the uncorrected effective resistance can be written in terms of diffusion distances as \(d_{ij}^{}=_{t=0}^{}d_{ij}^{}(t/2)^{2}/(G)\), see Proposition G.1. Here, based on Proposition 6.1, we derive a similar result for the corrected effective resistance (proof in Appendix G):

**Corollary 6.2**.: _If \(G\) is connected and not bipartite, we have_

\[d_{ij}^{}=_{t=2}^{}d_{ij}^{}(t/2)^{2}/(G)_{ij}^{}-d_{ij}^{}=d_{ij}^{}(0)^{2}+d_{ij}^{}(1/2)^{2}/(G). \]

In words, the corrected effective resistance combines all diffusion distances, save for those with the shortest diffusion time. These most local diffusion distances form exactly the correction from naive to corrected effective resistance. While the effective resistance is a _squared_ Euclidean distance, omitting the square amounts to taking the square root of all birth and death times, maintaining the loop detection performance of effective resistance (Figure S20). Therefore, the main difference between the spectral methods is in to how they decay eigenvectors based on the corresponding eigenvalues.

The naive effective resistance decays the eigenvectors with \(1/}\), which is much slower than diffusion distances' \((1-_{i})^{t}\) for \(t\). Corrected effective resistance shows intermediate behavior (Figure 5b). When represented as a sum over diffusion distances, it contains all diffusion distances with \(t 1\), making it decay slower than diffusion distances with \(t=8\) or \(64\), but does not contain the non-decaying \(t=0\) term, so it decays faster than its naive version. The correction matters little for \(S^{1}^{50}\) in the absence of noise, when the first eigenvalues are much smaller than the rest and dominate the embedding (Figure 5a,c) but becomes important as the noise and consequently the low eigenvalues increase (Figure 5a,d,e). As the noise increases, the decay for diffusion distances gets closer to a step function preserving only the first two non-constant eigenvectors, sufficient for the circular structure. In contrast, Laplacian Eigenmaps needs the number of components as input (Figure 5c - e).1

## 7 Spectral distances find holes in high-dimensional spaces

High-dimensional data is ubiquitous, but traditional persistent homology can fail to detect its topology. Here, we benchmark the performance of various distances as input to persistent homology.

Distance measuresWe examined twelve distances as input to persistent homology, beyond the Euclidean distance. Full definitions are given in Appendix I. First, there are some state-of-the-art approaches for persistent homology in the presence of noise and outliers. Fermat distances  aim to exaggerate large over small distances to incorporate the density of the data. Distance-to-measure (DTM)  aims for outlier robustness by combining the Euclidean distance with the distances from each point to its \(k\) nearest neighbors, which are high for outliers. Similarly, the core distance used in the HDBSCAN algorithm  raises each Euclidean distance at least to the distance between

Figure 5: **a.** Eigenvalue spectra of the \(k\)NN graph Laplacian for the noisy circle in ambient \(^{50}\) for noise levels \(=\{0.0,0.1,0.25\}\). **b.** Decay of eigenvector contribution based on the eigenvalue for effective resistance, diffusion distances and DPT. **c – e.** Relative contribution of each eigenvector for eff. resistance, diffusion distance, Laplacian Eigenmaps, and DPT for various noise levels (Section 6).

incident points and their \(k\)-th nearest neighbors. We evaluate these methods here with respect to Gaussian noise in high-dimensional ambient space, a different noise model than the one for which these methods were designed. Second, we consider some non-spectral graph distances. The geodesic distance on the \(k\)NN graph was popularized by Isomap  and used for persistent homology by Naitzat et al. . Following Gardner et al.  we used distances based on UMAP affinities, and also experimented with \(t\)-SNE affinities. Third, we computed \(t\)-SNE and UMAP embeddings and used distances in the 2D embedding space. Finally, we explored methods using the spectral decomposition of the \(k\)NN graph Laplacian, see Section 6: effective resistance, diffusion distance, and the distance in Laplacian Eigenmaps' embedding space.

All methods come with hyperparameters. We report the results for the best hyperparameter setting on each dataset (Appendix K) but found spectral methods to be robust to these choices (Appendix L).

Performance scoreThe output of persistent homology is a persistence diagram showing birth and death times for all detected holes. It may be difficult to decide whether this procedure has actually detected a hole in the data, or not. Ideally, for a dataset with \(m\) ground-truth holes, the persistence diagram should have \(m\) points with high persistence while all other points should have low persistence and lie close to the diagonal. Therefore, for \(m\) ground-truth features, our _hole detection score_\(s_{m}\) is the relative gap between the persistences \(p_{m}\) and \(p_{m+1}\) of the \(m\)-th and \((m+1)\)-th most persistent features: \(s_{m}=(p_{m}-p_{m+1})/p_{m}\). This corresponds to the visual gap between them in the persistence diagram (Figure 2b). Rieck and Leitte  as well as Smith and Kurlin  used similar quantities to find important features. We prove a continuity property of \(s_{m}\) in Appendix D and consider alternative scores in Appendix E.

In addition, we set \(s_{m}=0\) if all features in the persistence diagram have very low death-to-birth ratios \(_{d}/_{b}<1.25\). This handles situations with very few detected holes that die very quickly after being born, which otherwise can have spuriously high \(s_{m}\) values. This was done everywhere apart from the qualitative Figures 1, 9 and in Figure S25. We call this heuristic _thresholding_.

Note that the number of ground-truth topological features was used only for evaluation. We report the mean over three random seeds; shading and error bars indicate the standard deviation.

### Synthetic benchmark

Benchmark setupIn our synthetic benchmark, we evaluated the performance of various distance measures in conjunction with persistent homology on five manifolds: a circle, a pair of linked circles, the eyeglasses dataset (a circle squeezed nearly to a figure eight) , the sphere, and the torus. The radii of the circles, the sphere, and the torus' tube were set to \(1\), the bottleneck of the eyeglasses was \(0.7\), and the torus' tube followed a circle of radius \(2\). In each case, we uniformly sampled \(n=1\,000\) points from the manifold, mapped them isometrically to \(^{d}\) for \(d\), and then added isotropic Gaussian noise sampled from \((,^{2}_{d})\) for \([0,0.35]\). More details can be found in Appendix J. For each resulting dataset, we computed persistent homology for loops and, for the sphere and the torus, also for voids. We never computed holes of dimension \(3\) or higher.

Figure 6: Loop detection score for persistent homology with various distances on a noisy circle in \(^{50}\). The best hyperparameter setting for each distance is shown. Methods are grouped into panels for visual clarity. Recommended methods in **bold**.

Results on synthetic dataOn the circle dataset in \(^{50}\), persistent homology with all distance metrics found the correct hole when the noise level \(\) was very low (Figure 6). However, as the amount of noise increased, the performance of Euclidean distance quickly deteriorated, reaching zero score at \( 0.2\). Most other distances outperformed the Euclidean distance, at least in the low noise regime. Fermat distance did not have any effect, and neither did DTM distance, which collapsed at \( 0.15\) due to our thresholding (Figure 6a). Geodesics, UMAP/\(t\)-SNE graph, and core distance offered only a modest improvement over Euclidean (Figure 6b) highlighting that many \(k\)NN-graph-based distances cannot handle high-dimensional noise. In contrast, embedding-based distances performed very well on the circle (Figure 6c), but have obvious limitations: for example, a 2D embedding cannot possibly have a void. UMAP with higher embedding dimension struggled with loop detection on surfaces and the torus' void (Appendix O). Finally, all spectral methods (effective resistance, diffusion, and Laplacian Eigenmaps) showed similarly excellent performance (Figure 6d).

In line with these results, spectral methods outperformed other methods across most synthetic datasets in \(^{50}\) (Figure 7). DTM collapsed earlier than Euclidean but detected loops on the torus for low noise levels best by a small margin. Fermat distance typically had little effect and provided a benefit over Euclidean only on the eyeglasses and the sphere. Spectral distances outperformed all other methods on all datasets apart from the torus, where effective resistance was on par with Euclidean but diffusion performed poorly. On a more densely sampled torus, all methods performed better and the spectral methods again outperformed the others (Figure S31). On all other datasets diffusion distance slightly outperformed effective resistance for large \(\). Reassuringly, all methods passed the negative control and did not find any persistent loops on the sphere (Figure 7c).

As discussed in Section 4, persistent homology with Euclidean distances deteriorates with increasing ambient dimensionality. Using the circle data in \(^{d}\), we found that if the noise level was fixed at \(=0.25\), no persistent loop was found using Euclidean distances for \(d 30\) (Figure 8). In the same setting, DTM deteriorated even more quickly than Euclidean distances. In contrast, effective resistance and diffusion distance were robust against both the high noise level and the large ambient dimension (Figure 8a,c - e). See Figure S1 for an extended analysis.

Figure 8: **a.** Loop detection score of various methods on a noisy circle depending on the ambient dimensionality. Noise \(=0.25\). **b–e.** Heat maps for \([0,0.35]\) and \(d\).

Figure 7: Loop detection score for selected methods on synthetic datasets in ambient \(^{50}\). More experimental results can be found in Figures S23 – S33. Recommended methods in **bold**.

### Detecting cycles in single-cell data

We applied our methods to six single-cell RNA-sequencing datasets: Malaria , Neuroscience and Hippocampus from , HeLa2 , Neural IPCs , and Pancreas . Single-cell RNA-sequencing data consists of expression levels for thousands of genes in individual cells, so the data is high-dimensional and notoriously noisy. Importantly, all selected datasets are known to contain circular structures, usually corresponding to the cell division cycle during which gene expression levels cyclically change. As a result, we know how many loops to expect in each dataset and can therefore use them as a real-world benchmark of various distances for persistent homology. In each case, we followed preprocessing pipelines from prior publications leading to representations with \(10\) to \(5\,156\) dimensions. We downsampled datasets with more than \(4\,000\) cells to \(n=1\,000\) (Appendix J).

The Malaria dataset is expected to contain two cycles: the parasite replication cycle in red blood cells, and the parasite transmission cycle between human and mosquito hosts. Following Howick et al. , we based all computations for this dataset (and all derived distances) on the correlation distance instead of the Euclidean distance. Persistent homology based on the correlation distance itself failed to correctly identify the two ground-truth cycles and DTM produced representatives that only roughly approximate the two ground truth cycles (Figure 9a,b). Both effective resistance and diffusion distance successfully uncovered both cycles with \(s_{2}>0.9\) (Figure 9c,d).

Across all six datasets, the detection scores were higher for spectral methods than for their competitors (Figure 10). Furthermore, we manually investigated representative loops for all considered methods on all datasets and found several cases where the most persistent loop(s) was/were likely not correct (hatched bars in Figure 10). Overall, we found that the spectral methods, and in particular effective resistance, could reliably find the correct loops with high detection score. Persistent homology based on the \(t\)-SNE and UMAP embeddings worked on average better than traditional persistent homology, Fermat distances, and DTM, but worse than the spectral methods.

## 8 Limitations and future work

In the real-world applications, it was important to look at representatives of detected holes as some holes were persistent, but arguably incorrect. That said, each homology class has many different

Figure 10: Loop detection scores on six high-dimensional scRNA-seq datasets. Hatched bars indicate implausible representatives. See Figure S34 for detection scores for different hyperparameter values. Recommended methods in **bold**.

Figure 9: Malaria dataset. **a–d.** Representatives of the two most persistent loops overlaid on UMAP embedding (top) and persistence diagrams (bottom) using four methods. Biology dictates that there should be two loops (in warm colors and in cold colors) connected as in a figure eight.

representative cycles, making interpretation difficult. Given ground-truth cycles, an automatic procedure for evaluating cycle correctness remains an interesting research question.

Persistent homology can only detect topology, which is often a useful global level of abstraction. However, it may therefore fail to distinguish some non-isomorphic point clouds . There exist dedicated measures for detecting isometry .

Dimensionality reduction methods are designed to handle high-dimensional data. \(t\)-SNE and UMAP indeed performed well on many datasets, but on average worse than spectral distances on the real data. Moreover, UMAP struggled with the surface of the 3D toy datasets and the torus' void (Appendix O). Finally, they require the choice of an embedding dimension and are known to produce artifacts , e.g., leading to poor scores in the noiseless setting in Figures S17, S22. In contrast, spectral distances on the symmetric \(k\)NN graph worked well without a low-dimensional embedding (Section 7).

Using effective resistance or diffusion distances is easy in practice as their computation time \(O(n^{3})\) is dwarfed by that of the persistent homology (Table S5), which scales as \((n^{3(+1)})\) for \(n\) points and topological holes of dimension \(\). This high complexity of persistent homology aggravates other problems of high-dimensional datasets as dense sampling in high-dimensional space would require a prohibitively large sample size (recall that spectral methods needed a high sampling density for good performance on some of our datasets such as the torus). Combining persistent homology with non-Euclidean distance measures could mitigate this problem via the approach of Bendich et al. , who performed subsampling after computation of the distance matrix. This is a particularly attractive avenue for future research.

Both effective resistance and diffusion distances require the choice of hyperparameters. However, effective resistance only needs a single hyperparameter: the number of \(k\)NN neighbors. For this reason and due to its greater outlier resistance (Appendix N), we tend to recommend effective resistance over diffusion distances, but a principled criterion when to use which of the two is still missing.

Moreover, we do not have a theoretical proof that spectral distances mitigate the curse of dimensionality. Such a proof may be achieved in the future taking inspiration from the stability results in  and, more generally, spectral perturbation theory.

Our empirical results focus on benchmarking which distances identify the correct topology in the presence of high-dimensional noise. Therefore, we only considered datasets with known ground-truth topology. The next step will be to use spectral distances to detect non-trivial topology in real-world exploratory contexts.

High-dimensional data and thus application areas for our improved topology detection pipeline are becoming ubiquitous. Within biology, we see possible applications for our method in other single-cell omics modalities, population genomics, or neural activity data . Beyond biology, we believe that our approach can improve the topological analysis of artificial neural network activations , and in general be used to detect topology of any high-dimensional data, e.g. in the climate sciences, in astronomical measurements, or wearable sensor data.

## 9 Conclusion

In this work we asked how to use persistent homology on high-dimensional noisy datasets which are very common in real-world applications even if the intrinsic data dimensionality is low. We found spectral methods to be the optimal approach. We demonstrated that, as the dimensionality of the data increases, the main problem for persistent homology shifts from handling outliers to handling noise dimensions (Section 4). We used a synthetic benchmark to show that traditional persistent homology and many of its existing extensions struggle to find the correct topology in this setting. Our main finding is that spectral methods based on the \(k\)NN graph, such as the effective resistance and diffusion distances, still work well (Section 7.1). Furthermore, we view it as an advantage that we found existing methods that are able to handle the important problem of high-dimensional noise. We derived an expression for effective resistance based on the eigendecomposition of the graph Laplacian, and demonstrated that it combines all but the most local diffusion distances (Section 6). Finally, we showed that spectral distances outperform all competitors on single-cell data (Section 7.2).