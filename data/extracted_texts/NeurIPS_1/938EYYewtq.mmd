# Global Distortions from Local Rewards: Neural Coding Strategies in Path-Integrating Neural Systems

Francisco Acosta

Department of Physics

UC Santa Barbara

facosta@ucsb.edu

&Fatih Dinc

CNC Program

Stanford University

&William T. Redman

Applied Physics Laboratory

Johns Hopkins University

Manu Madhav

Biomedical Engineering

University of British Columbia

&David Klindt

NeuroAI

CSHL

&Nina Miolane

Electrical & Computer Engineering

UC Santa Barbara

###### Abstract

Grid cells in the mammalian brain are fundamental to spatial navigation, and therefore crucial to how animals perceive and interact with their environment. Traditionally, grid cells are thought support path integration through highly symmetric hexagonal lattice firing patterns. However, recent findings show that their firing patterns become distorted in the presence of significant spatial landmarks such as rewarded locations. This introduces a novel perspective of dynamic, subjective, and action-relevant interactions between spatial representations and environmental cues. Here, we propose a practical and theoretical framework to quantify and explain these interactions. To this end, we train path-integrating recurrent neural networks (piRNNs) on a spatial navigation task, whose goal is to predict the agent's position with a special focus on rewarded locations. Grid-like neurons naturally emerge from the training of piRNNs, which allows us to investigate how the two aspects of the task, space and reward, are integrated in their firing patterns. We find that geometry, but not topology, of the grid cell population code becomes distorted. Surprisingly, these distortions are global in the firing patterns of the grid cells despite local changes in the reward. Our results indicate that after training with location-specific reward information, the preserved representational topology supports successful path integration, whereas the emergent heterogeneity in individual responses due to global distortions may encode dynamically changing environmental cues. By bridging the gap between computational models and the biological reality of spatial navigation under reward information, we offer new insights into how neural systems prioritize environmental landmarks in their spatial navigation code.

## 1 Introduction

MotivationNeuroscientists describe computations in the brain by jointly considering the firing activity of a population of \(N\) neurons in _neural state space_\(^{N}\). In this space, each basis vector corresponds to one neuron, one point summarizes the activity of all neurons at a given instant, and a trajectory in neural state space describes the time evolution of the firing of all neurons. Across many brain regions and modalities, these trajectories have been observed to be mostly constrained to a lower dimensional manifold within the state space: the _neural manifold_ (see Figure 1 right). Such manifolds have been observed in the motor cortex , the hippocampus , visual cortex , head direction circuit , and grid cells in the entorhinal cortex . Characterizing the geometric properties of neural manifolds including their dimension, topology, and curvature enables a wholistic understanding of multi-neuron activity through time, and a quantified approach to describe computations in the brain .

Grid cells are neurons in the medial entorhinal cortex (MEC) which exhibit activity patterns characterized by hexagonal lattices across space  (see firing field on Figure 1). Grid cells can be grouped into distinct subpopulations called _modules_, specified by the spatial period of their hexagonal lattice . The neural manifold corresponding to neurons in a grid cell module has been shown to form a 2D torus in the high-dimensional state space . The traditional view in neuroscience is that grid cells support _path integration_ --the process used by an animal to keep track of its position by integrating its past position and current speed --by providing a global metric for physical space. However, recent experiments suggest that grid cell lattices become distorted in the presence of relevant landmarks, such as rewards [15; 16; 17]. In other words: grid cell activity might not reflect true physical distances but instead underlies a metric for subjective action-relevant space . While the distortion of grid cell activity has been reported qualitatively, it remains to be described quantitatively.

ContributionsWe propose a practical and theoretical framework to quantify and explain the distortion of grid cell neural manifolds under task-relevant reward information. We apply this framework to compare computational and biological neural systems performing spatial navigation.

Our technical contributions are:

1. We adapt the training of biologically-inspired RNNs performing path integration (piRNNs)  to account for spatial rewards via a new saliency loss term.
2. We introduce a methodology to quantify the deformation of grid cells' firing fields and neural manifolds in two scenarios --absence and presence of rewards and describe the topological changes in the grid cell module tori after training with reward.
3. We illustrate the implicit regularization achieved by fixing the readout weights, which retains the existing toroidal topology of the neural manifolds during reward training.

Our conceptual contributions are:

1. We quantify the introduction of reward in spatial navigation tasks by linking the geometric distortions of grid cells' responses and corresponding distortions of their neural manifolds.
2. In piRNNs, we link the emergent distortions of the individual hexagonal responses to geometric deformations of the neural manifold.
3. We provide evidence suggesting that grid cells may be involved in continual learning.

After reward training, the toroidal topology continue support successful path integration, while geometric deformations of the neural --corresponding to global distortions in the individual responses --may represent local, dynamic environmental cues, such as reward information. This dual representation allows the grid cell modules to maintain their foundational navigation capabilities while adapting to new environmental variables.

Figure 1: **Path integrating Neural Systems.** Left: an artificial agent explores its 2D environment traveling along the path \(x_{t}\) shown in black. Middle: the agent’s velocity \(v_{t}\) is given as input to neurons in a path-integrating recurrent neural network (piRNN) or grid cells in the mammalian brain . The agent maintains a representation of its movement across multiple grid cell modules. This representation is linearly decoded onto place cells, providing an estimate of the agent’s new position \(_{t+1}\). Right: Each grid cell has a firing field that is a hexagonal lattice. Together, grid cells’ activity within a grid cell module forms a 2D torus [9; 20].

Background & Related Works

### Neuroscience of Spatial Navigation

**Path integration** is the process by which animals use self-motion cues including information from the vestibular system and proprioception to integrate their past movements and positions, allowing them to maintain an estimate of their position. Theoretical models have explored mechanisms by which path integration can be performed by neural networks in the mammalian brain , most notably through networks of place cells and grid cells .

**Place cells** are a functional class of neurons found in the hippocampus , a region of the brain implicated in memory and spatial navigation. The neural activity of place cells is believed to represent the animal's current physical location in space, thereby creating a "cognitive map" .

**Grid cells** are a functional class of neurons found in the medial entorhinal cortex  whose spatial firing pattern form a hexagonal lattice covering their 2D environment in open field settings. Many works [25; 26; 27] show that grid cells play an important role in _path integration_, by integrating self-motion information sending neuronal signals to their downstream place cells.

The **grid cell firing field** can be described by three parameters: (1) _spacing_, or distance between lattice points, (2) _orientation_ of the lattice relative to a reference direction, and (3) _phase_, or the lattice offset relative to a reference point. A **grid cell module** consists of grid cells with the same spacing and orientation but varying phases . Each module is known to form a neural manifold with the topology of the 2D torus \(^{2}\).

### RNNs for Spatial Navigation

Biologically-inspired, computational models of place cells and grid cells have emerged in recent years. Specifically, recurrent neural networks trained to perform path integration (piRNNs) of artificial agents have been shown to exhibit artificial neurons that behave like biological grid cells [28; 29; 30; 19; 31; 32]. This paradigm allows for systematic exploration of phenomena observed in neural circuits involved in spatial navigation, such as hippocampal remapping . Below, we introduce the piRNN framework of spatial navigation from .

Let \(x^{2}\) denote the agent's position, \( x^{2}\) the displacement in unit time, \(v\) the velocity, \(r(x)^{N}\) be the activity of \(N\) grid cells, \((x)^{P}\) be the activity of \(P\) place cells; \(r_{i}(x)\) and \(_{p}(x)\) being the activity of the \(i^{ th}\) grid cell and \(p^{ th}\) place cell, respectively --see Figure 1 (left). The grid cell activity \(r(x)\) for each module forms a toroidal _neural manifold_ embedded in the _neural state space_\(^{N}\): see torus on Figure 1 (right).

**Place cells in piRNNs:** As done in the literature , we model place cell activity \(\) as a linear readout of the activities, \(r\), of the piRNN neurons. The position estimate \(\) is decoded from \(\) as:

\[^{t}=Qr^{t},\;\;_{t}=*{arg\,max}_{p P}^{t}_{p}, \]

where \(Q^{P N}\) is the place cell readout matrix. The architecture is illustrated in Figure 1. Previous work has shown that the piRNN neurons, \(r\), become grid cells after training .

Path integration by piRNNs:The piRNN is trained to perform path-integration and correctly infer the spatial position. Its goal is to learn the place cell readout matrix \(Q\), the neural representation \((r(x), x)\), its recurrent weight matrix \(W^{N N}\), and its input weight matrix \(U mathbbR^{2 N}\) via minimization of the loss function \(\). The loss \(\) used by Xu et al.  is:

\[=_{}+_{}+ _{}+_{}. \]

The error on the prediction of the spatial position is written as \(_{}=_{x, x}[L_{}]\) where:

\[L_{}=_{t=1}^{T}\|(x+ x_{1}++ x_{t} )-Qr(x+ x_{1}++ x_{t})\|^{2}. \]

We refer to Sec. S3 for details on the other terms: \(_{}\), \(_{}\), \(_{}\).

## 3 Theory of Deformations: From Firing Fields to Neural Manifolds

Recent experimental evidence in animals and our own experiments on piRNNs reveal that grid cell firing fields get distorted after introducing a reward in the agent's spatial environment. Here, we propose a theory to relate deformations of the firing fields (see Figure 1 middle) to deformations of the corresponding neural manifolds (see Figure 1 right) during path-integration with spatially localized rewards. We first present the general theory of deformations. Then, we illustrate it with two scenarios observed in practice: (i) smoothing of firing fields (diffused units) observed in our piRNN experiments as described in Section 4, and (ii) attraction of firing fields (attracted units) observed in .

### General Theory

Deformation of firing fieldsConsider one grid cell \(i\) with firing field \(x r_{i}(x)\) over the environment \(^{2}\) (Figure 1 middle). In line with experimental observations, we assume that the introduction of a reward, modeled by the _saliency map_\(s(x)\), deforms the firing field of the grid cell (see Figure 2). We model this deformation as a diffeomorphism \(:^{2}^{2}\) of the environment.

We further assume that every grid cell \(i\) has a constant _firing energy budget_, in that: \(_{x^{2}}r_{i}(x)dx\) is constant. Putting this together, introducing a reward in the environment yields a new firing field for grid cell \(i\) written as:

\[r_{i}^{}(x)=|^{}(x)|.r_{i}(x)x^{2}, \]

where \(^{}\) is the Jacobian of \(\), \(|^{}(x)|\) represents a change in volume induced by the deformation \(\), and "." denotes scalar multiplication. This formulation deforms the shapes of the firing fields, and modifies their amplitudes in order to keep the firing energy budget constant. This statement is made precise in the proposition below.

**Proposition 1**.: _The deformation of the grid cell firing fields \(r_{i}\) by \(\) given by \(r_{i}*=r_{i}^{}\) defines a right group action of the group of diffeomorphisms over the space of firing fields. The firing energy budget is an invariant of this group action._

The definition of group action and the proof are given in Appendix S1. Here, we do not specify a formula for \(\). Instead, we suppose that \(\) can be estimated from experiments with piRNNs or animals performing path-integration tasks without and with rewards.

Figure 2: **Geometry of grid cell module tori is changed by presence of salient features in the environment.****A.** An agent (for us, a piRNN) is trained to perform path integration in its 2D environment with uniform spatial saliency. Canonical grid cells develop hexagonal lattice responses (rate maps) across \(M\) modules. The population activity of a single grid cell module forms a torus in neural state space. **B.** The same agent undergoes a second phase of training, with its environment now containing rewards (areas of high importance, or _saliency_). We model this saliency by modifying the loss of our piRNN to prioritize accurate position decoding near rewards. Its grid cells adjust their individual responses, which we link to geometric deformations of the neural tori.

Deformation of neural manifoldThe deformation of each firing field via \(\) induces a deformation of the associated neural manifold: the torus associated to a given grid cell module changes shape in neural state space \(^{N}\) (see Figure 2 right). Before deformation, the torus neural manifold can be represented by the parameterized surface \(x R(x)=[r_{1}(x),...,r_{N}(x)]^{T}\), where the periodicity of the firing fields means that the function \(R\) is not necessarily injective: one point on the manifold surface may correspond to several locations \(x\)'s. Introducing a reward in the environment yields a new neural manifold written as:

\[R^{}(x)=|^{}(x)|.R(x)^{N}x^{2}. \]

In what follows, we consider that \(R\) is injective, or we restrict \(R\) to its domain of injectivity. In this context, we can predict some geometric properties of the deformed neural manifold, as given in the proposition below.

**Proposition 2**.: _The deformation of the neural manifold \(R\) by \(\) given by \(R*=R^{}\) defines a right group action of the group of diffeomorphisms over the space of neural manifolds. The barycenter and the topology of the manifold are invariants of this group action, provided that the firing fields are regular._

Figure 3: **Relating firing fields to neural manifolds across deformations in synthetic grid cells. We investigate how deformations away from perfect hexagonal symmetry in the firing fields of synthetic grid cells affects the geometry of the toroidal neural manifold. From left to right. Original units. The original hexagonal grid cells show clear signatures of toroidal topology, as indicated by the presence of 2 loops in the first homology group (H1) and 1 void in the second homology group (H2). We show 2D projections using principal components analysis (PCA) and multidimensional scaling (MDS) to serve as baselines against which to compare the manifolds of deformed grid cells. PCA projections are consistent with a “flat” torus geometry. Diffused units. Diffused units created from convolution of the original grid cells with a Gaussian kernel maintain toroidal topology, but PCA and MDS show that the size of the neural manifold is reduced as predicted by theory. Attracted units. Inspired by experimental evidence from  we created attracted units from synthetic grid cells by applying a diffeomorphism to the 2D environment. While manifold size is unchanged, PCA projections suggest the torus becomes more curved in neural state space. Toroidal topology is preserved. Band units. We created a synthetic module with \(17\%\) of original grid units replaced with band units of same spatial scale, with uniformly distributed orientations. The geometry and topology of the resulting manifold are largely unchanged.**

See Appendix S1 for the proof. Next, we consider deformations of the firing fields that have appeared empirically, either in our piRNN experiments or in animal experiments.

### Diffused Units: Smoothing of Firing Fields

We show how smoothing of the firing fields of the grid cells, observed empirically in Section 4 impacts neural manifolds in neural state space.

**Conjecture 1** (Reduction hypothesis).: The smoothing of the firing fields by a Gaussian filter reduces the size \(S\) of the neural manifold \(R\), where the size is defined as: \(S=_{x^{2}}\|R(x)\|\).

The size of the neural manifold becomes, after introduction of reward and deformation by \(\):

\[S^{}=_{x^{2}}\|_{u^{2}}G(x-u)R(u)du\|, \]

where \(G\) represents the Gaussian filter used for smoothing. When a function \(\|R\|\) is convolved with a Gaussian filter, the resulting function is smoother than \(\|R\|\). The convolution effectively averages the values of \(\|R\|\) over the neighborhood defined by the Gaussian, which reduces the peaks of \(\|R\|\). This is because the convolution is essentially a weighted average. Consequently, via such a deformation of the firing fields, the resulting manifold will be smaller.

Testing the Reduction HypothesisIn practice in our experiments, we perform principal component analysis and other dimension reduction techniques to compare the sizes of the neural manifolds before and after the deformation produced by the introduction of reward.

### Attracted Units: Displacements of Firing Fields' Centers

We show how the attraction of the grid cells' firing field centers to reward locations, observed in experiments in  and simulated with exaggeration in Figure 3, impacts the neural manifold in state space.

**Conjecture 2**.: Attracting the centers of the firing fields to a region of the environment expands the corresponding region of the neural manifold, provided that the firing rates are regular enough.

Indeed, the diffeormorphism \(\) that represents this deformation displaces volume elements of the environment, placing more volume in the center. Therefore, the term \(|^{}(x)|\) that measures volume changes will be high next to the center of the environment. The region of the neural manifold corresponding to the center of the environment will therefore be magnified.

We include a more detailed discussion on the link between rate map distortions and neural manifold geometry in Section S2.

We illustrated several synthetic grid cell modules to demonstrate how various types of common grid cell firing field deformations affect the geometry of the toroidal neural manifold, summarized in Fig. 3. Global deformations such as the emergence of diffusive units with less crisp hexagonal firing patterns, attracted units with distance-based scaling, and the addition of band-like cells to a group of grid cells did not change the toroidal topology of the modules. Moreover, as predicted by Conjecture 1, the diffused units reduced the size of the manifold. Overall, global distortions can be added to the grid modules without destroying the existing toroidal topology of the neural manifold subserving the spatial navigation. As we show in the next section, such patterns emerge as a result of the dynamic integration of environmental information during the piRNN training. This process enables the networks to simultaneously solve path integration and represent environmental cues effectively.

## 4 Empirical Results

In this section, we test the theoretical global distortions introduced in the previous section by training piRNNs to perform path integration while enforcing higher accuracy in positional decoding near salient locations to model the presence of local rewards. We first introduce the multi-phase training procedure with non-uniform saliency. Then we discuss the effects of saliency training on the toroidal topology of the neural manifold, and examine the emergent distortions in the grid cell firing fields. Finally, we confirm our theoretical prediction from the previous section regarding how diffused units lead to a reduction in manifold size.

### Training piRNNs with Non-Uniform Spatial Saliency

We investigate how the representations learned by piRNNs change through multiple phases of training incorporating spatial saliency into the objective. We begin by pretraining the piRNN model introduced in , which learned representations with a large fraction of units (\(>\) 70%) classified as grid cells, based on the widely-used gridness score . These representations exhibit a high degree of hexagonal periodicity at different scales, correspondong to distinct grid cell modules. We employed a procedure inspired by  to identify the grid cell modules (see Fig. S3).

After this initial pretraining phase, we modified the loss to imitate the non-uniform saliency across the environment that is characteristic of animals exploring their environments in more naturalistic settings  that may contain rewards. This stands in contrast to the highly uniform "open field" settings typically used in experiments, where neurons with a high degree of hexagonal periodicity are commonly found, as shown in Fig. 2. We add a kernel \((1+s(x))\) multiplying the loss term in Eq. 3 that differentially weights the penalty of incorrect self-position estimation across different locations in the environment, thus quantifying the notion of spatial "saliency". The new loss \(^{s}_{}\), which modifies Eq. 3, reads

\[^{s}_{}=_{x, x}[(1+s(x))L_{}]. \]

In our experiments, we parameterize \(s(x)\) with a Gaussian of width \(_{*}\) centered at \(x_{*}\):

\[s(x)=s_{0}((-\|x-x_{*}\|^{2}/2_{*}^{2})/^{2}}), \]

and we set \(x_{*}=0\) and \(_{*}=0.05L\), where \(L\) is the length of the square environment.

### Saliency during the training may respect or destroy the toroidal topology

We performed the second phase of training with the saliency loss in two ways. First, we allowed all connections, including the readouts from the piRNN units to the place cells, to be learned. In this case, we consistently observed a change in the topology of the grid modules, where the toroidal structure underlying the grid cells was destroyed (Fig. 4**A,C**), though the firing rates showed qualitatively similar patterns to the grid cells (Fig. S4).

As a next experiment, during the second phase of training we froze the readout weights from the RNN to the place cells and observed that the grid cell module toroidal topology was preserved (Fig. 4**A,B**). Therefore, freezing the readout may be seen as an implicit regularization that enabled continual learning in the grid cell population. By preserving the toroidal topology of the neural manifold,

Figure 4: **Toroidal topology is preserved after saliency training when place cell read-out is frozen. For grid cell module 7, we project the neural activity to 6 dimensions using PCA, and perform persistent homology. We show the 20 most persistent features for homology dimension 1 (loops) and homology dimension 2 (voids). Gray bars are 20 most persistent features from 10 random shuffles of the data. **A. The** population activity of module 7 of the pretrained RNN (before saliency training) has Betti numbers (1,2,1), consistent with toroidal topology. **B.** The population activity of module 7 of the RNN after saliency training retains toroidal topology, if place cell read-out is frozen (only grid representations are allowed to change). **C.** The toroidal topology is destroyed after saliency training if place cell read-out is allowed to change.

the system leverages its previously learned representational structure subserving successful spatial navigation while encoding a dynamic environmental variable, _i.e._, the saliency. Therefore, for the rest of our experiments, we fine-tuned the piRNNs with frozen readout weights.

### Saliency-tuned piRNNs develop diverse set of distorted tuning features

In our experiments, we found that following the saliency training phase (with the modified loss term \(_{error}^{s}\)), the piRNNs developed neurons with a more heterogeneous set of spatial tuning properties, as illustrated in Fig. 5. Specifically, we observed the emergence of diffused and band units, as predicted by our theoretical framework in Section 3. Interestingly, we did not observe the attractive distortions predicted in Fig. 3.

An important aspect of these distortions is that they are global, whereas the reward was localized at the origin. Given that place cells average the input from multiple grid cells through their readouts, it is possible that global distortions in the grid cells facilitate local changes in the final output. For example, the ring units may arise because the reward information is rotationally symmetric, eliminating the need to retain angle information and creating the secondary ring structures shown in Fig. 5**A**. Additionally, if the center of the environment needs to be represented preferentially over the rest of the space, it makes sense for the representation of places outside the origin to become less crisp to conserve, _e.g._, a firing rate budget. This could be achieved by a convolution in the firing rates, leading to the diffused units observed in Fig. 5**B**. Finally, grid cells can be described as a summation of a few band cells in different orientations. If these bands cover all angles, the result can approximate a place cell in the origin, making the band units, observed in Fig. 5**C**, a mutually synergistic solution for both representing spatial navigation and the reward information (located at the origin).

As the final test, we focused on modules that showed increased levels of diffused units and tested the reduction hypothesis presented in Conjecture 1, which suggests that the emergence of diffused units should decrease the overall size of the manifold. As expected, the diffusing units did not change the topology of the module, and resulted in a geometrical reduction in size (Fig. 6).

Figure 5: **Saliency-tuned piRNNs develop diverse set of tuning features observed in neuroscience.****A.** Across multiple modules, we observe the emergence of many units characterized by _rings_ of high activity. **B.** We also observe the emergence of _diffused_ units which are active almost everywhere. **C.** Finally, we find many units develop _band_ structures.

Figure 6: **Diffused units lead to reduction in the manifold size.** When we analyzed a module with many emergent diffused units after the saliency training, we observed that the topology of the module was preserved. However, the size of the manifold was reduced in line with our Conjecture 1.

Overall, our results suggest that the global distortion mechanisms allow the grid cells to retain their spatial navigation capabilities while adapting to the localized reward signals. This balance can enable the piRNNs to maintain navigation functionality and incorporate new environmental cues effectively.

## 5 Discussion

**Local reward leads to global changes in the firing rates:** When we trained the piRNNs with local rewards, encouraging the network to represent specific places more accurately, we observed distinct global changes in the firing profiles of grid cells. In our experiments with piRNNs, we observed diffused and banded patterns, as well as units with secondary local ring-like structures similar to those observed in human studies , but not the attracted firing patterns.

**No attracted neurons emerged in reward-modulated piRNNs:** To our initial surprise, we did not observe the kind of local "magnification" or deformations suggested by the interepretations of previous rodent experiments from  in any of our experiments. Instead, we observed global changes in the firing fields. Therefore, we present _in silico_ evidence that challenges the conventional interpretation that reward modulation results in local magnification of the grid cell lattice as too simplistic an explanation. Indeed, because grid cells provide a global code for space, we propose that reward modulation should result in global deformations of spatial responses in MEC, as observed in our piRNN experiments.

The appearance of diffused units suggests that multiplying the loss function by a local reward signal in the navigation space causes convolution in grid cell firing patterns, indicating a duality between grid cell firing patterns and changes in the reward function, akin to the Fourier Transform. The emergence of banded units aligns with representations of the origin, as the Fourier transform of a square wave is a periodic function with most of its mass centered at the origin. The ring units' emergence is also consistent with the reward being centered, leading to a trade-off in representing angles for better distance representation to the reward. Notably, local changes in the reward function caused global changes in grid cell firing patterns, reinforcing the concept of this duality.

**Dynamical interactions lead to distorted units:** Previous studies have shown that units with banded firing rates emerge during reorganization . Additionally, research has demonstrated that banded units and grid cells can coexist, with the same cells behaving as either depending on the environment or the task . A common finding across these studies, which is consistent with our results here, is that grid cells transform into banded or other unit types with different symmetries, likely influenced by the complexity of the action rather than the properties of the navigated space.

**Distorted grid cells emerge with frozen readouts, otherwise complex reorganization ensues:** The fact that the toroidal topological structure is destroyed when readouts are allowed to change supports our hypothesis that the distortions observed in grid cell firing fields are related to the network's efforts to adapt to a changing environment, such as the introduction of a reward, without completely reorganizing itself. Complete reorganization might minimize a loss function associated with the reward's location but would fail to generalize to changing environmental conditions, such as the introduction of subsequent phases of training with different saliency distributions.

We conjecture that the distortions observed in our experiments, and regularly reported in neural data [37; 36; 35; 15], signal continual learning. These distortions are expected to vary from environment to environment and task to task. This suggests that grid cells can exhibit significant flexibility, dynamically adjusting to new tasks and conditions while maintaining overall functionality. Hence, although their toroidal neural manifold topology supports navigation, global distortions may facilitate the dynamic encoding of localized environmental cues.

## 6 Conclusion

Prior work with grid cells has primarily focused on their contribution to spatial navigation. Recent studies have also considered local changes in grid cell firing patterns, such as attractions to reward positions . In this work, by analyzing how piRNNs handle these tasks simultaneously, we tested whether global distortions emerge on grid cell firing patterns and how they affect their functionality and their adaptability in representing complex environmental cues. Overall, our theoretical and experimental findings suggested a nuanced view: the hexagonal grid structures facilitate the decoding of spatial locations, while global, not necessarily local, distortions in the grid cell geometry can dynamically encode environmental cues relevant to specific actions, highlighting the flexibility of grid cells in adapting to various environmental contexts and tasks .

Though grid cells were not traditionally considered in the context of continual learning, our results implicate their involvement in these paradigms. Additionally, studies of spatially structured, periodic, and global rewards should illuminate the duality in the dynamic representation of environmental cues by grid cells, which may allow building towards a theoretical understanding of the duality between local rewards and global distortions we observed in this work.