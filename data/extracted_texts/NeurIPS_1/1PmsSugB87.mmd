# Evidential Stochastic Differential Equations for Time-Aware Sequential Recommendation

Krishna Prasad Neupane, Ervine Zheng, Qi Yu

Rochester Institute of Technology

{kpn3569,mx25733,qi.yu}@rit.edu

Corresponding author

###### Abstract

Sequential recommender systems are designed to capture users' evolving interests over time. Existing methods typically assume a uniform time interval among consecutive user interactions and may not capture users' continuously evolving behavior in the short and long term. In reality, the actual time intervals of user interactions vary dramatically. Consequently, as the time interval between interactions increases, so does the uncertainty in user behavior. Intuitively, it is beneficial to establish a correlation between the interaction time interval and the model uncertainty to provide effective recommendations. To this end, we formulate a novel Evidential Neural Stochastic Differential Equation (E-NSDE) to seamlessly integrate NSDE and evidential learning for effective time-aware sequential recommendations. The NSDE enables the model to learn users' fine-grained time-evolving behavior by capturing continuous user representation while evidential learning quantifies both aleatoric and epistemic uncertainties considering interaction time interval to provide model confidence during prediction. Furthermore, we derive a mathematical relationship between the interaction time interval and model uncertainty to guide the learning process. Experiments on real-world data demonstrate the effectiveness of the proposed method compared to the SOTA methods.

## 1 Introduction

Recommender systems have been used in various domains, such as e-commerce, entertainment, education, health care, social media, and many more . In these domains, users' interests and behaviors dynamically evolve over time. Therefore, capturing users' evolving behavior plays an essential role in effective recommendations. Various sequential recommendation models  have been proposed accordingly. They mainly leverage the user's historical sequential interactions and aim to predict the next item that a user likes to interact with. These methods usually assume a uniform time interval of user interactions. However, in reality, the actual time interval between two consecutive interactions may vary dramatically, and a large time interval may be accompanied by a change in users' preferences.

The unrealistic assumption of a uniform interaction interval could significantly impact the model's capability to capture users' continuously evolving behavior and subsequently hurt the recommendation performance. Table 1 provides an illustrative example of the issues as outlined above. In this example, we follow the standard sequential recommendation similar to  by predicting the next item considering

    &  &  \\   & & **BERT4Rec** & **E-NSDE** \\  \(6\) 7 & 44 & 4 & **4** \\ \(13\) 14 & 623,591 & 24 & **16** \\ \(116 117\) & 62 & 6 & **3** \\ \(150 151\) & 896,291 & 56 & **18** \\   

Table 1: Impact of interaction intervalother 100 negative items from the item pool. We select a random user from the Movielens-100K dataset and provide recommended ranking results together with the interaction time intervals in the sequence. The recommendation performance for a sequential model BERT4Rec  deteriorates significantly when the gap between the consecutive interactions becomes large. For example, when the next interaction occurs soon after the first one, BERT4Rec usually ranks the ground-truth item in a top-10 list. However, for a much larger interval, the ground-truth item drops out of the top-20 or even the top-50 recommendation list.

Neural Ordinary Differential Equations (NODE) have been recently introduced that map the existing discrete neural networks to a continuous model , which can naturally capture users' continuously evolving preferences. However, one key limitation of these NODE models is the lack of uncertainty quantification capability, which is essential to understand user behavior when recommending the next item, especially when learning from extremely sparse user interactions given a large item space. Intuitively, the uncertainty of user behavior should increase along with the length of the interval since the last active interaction. For example, if the user has no activity for a long time, the user's prior interest tends to decrease. As a result, we become more uncertain about the user's preference. At the same time, a high uncertainty also presents a unique opportunity to effectively explore the item space by providing a diverse recommendation list to the users so that they may be attracted to a new category of items to keep them in the system.

Uncertainty can serve as a useful guidance to the recommender system to adapt to users' changing preferences and explore new items effectively. Table 2 further highlights the limitation of an existing ODE-based sequential recommendation method GRU-ODE , where recommended genres come from frequently watched 'Drama' and 'Romance' movies in the past. This issue becomes even worse when the interaction gap becomes large (_i.e.,_ the fourth row of the GRU-ODE model), and the recommended genres significantly deviate from the ground truth. The recommendation list again concentrates on the same 'Drama' and 'Romance' genres, which are misaligned with the user's long-term interests. It is evident that conducting a more effective exploration is crucial to uncover the long-term and varied interests of users, aiming to optimize potential future benefits.

To address this critical gap as outlined above, we propose uncertainty augmented Neural Stochastic Differential Equations (NSDE) and integrate it into a novel sequential recommendation model. NSDE is a variant of NODE that adds Brownian motion terms to incorporate stochasticity via a diffusion function. NSDE has been successfully applied in other fields, such as computer vision . It provides an effective means to capture users' continuously changing behavior, and also model the noise via stochasticity in user and item representations. However, recommender systems involve uncertainty from multiple sources: uncertainty caused by evolving user preferences and uncertainty arising from user-item interactions. While the standard NSDE can naturally capture the former, it is not designed to cover the latter. To this end, we further incorporate evidential deep learning (EDL)  to gather evidence from user-item interactions and systematically capture uncertainty from multiple sources. Table 3 summarizes the key differences between the proposed model and existing relevant models.

The proposed E-NSDE seamlessly integrates an NSDE module and an EDL module, where the former is responsible for learning user and item representations over time and the latter utilizes these rich representations to identify important and diverse items that the model needs to learn to capture users' actual behavior with the help of uncertainty-aware exploration. Table 2 shows that E-NSDE places a pronounced emphasis on a wider array of genres, and a substantial portion of these manage

  
**Model** & **Interval (Seconds)** & **Epistemic uncertainty** & **Ground-truth genre** & **Recommended genre** \\   & 44 & N/A & [\({}^{}\), \({}^{}\)] & [\({}^{}\), \({}^{}\)] \\  & 623.91 & N/A & [\({}^{}\), \({}^{}\), \({}^{}\)] & [\({}^{}\), \({}^{}\)] \\  & 62 & N/A & [\({}^{}\), \({}^{}\), \({}^{}\)] & [\({}^{}\), \({}^{}\), \({}^{}\)] \\  & 896,291 & N/A & [\({}^{}\), \({}^{}\)] & [\({}^{}\), \({}^{}\)] \\   & 44 & 0.4016 & [\({}^{}\), \({}^{}\)] & [\({}^{}\), \({}^{}\), \({}^{}\)] \\  & 623.591 & 0.6725 & [\({}^{}\), \({}^{}\), \({}^{}\)] & [\({}^{}\), \({}^{}\), \({}^{}\), \({}^{}\)] \\  & 62 & 0.4463 & [\({}^{}\), \({}^{}\), \({}^{}\)] & [\({}^{}\), \({}^{}\)] \\  & 896,291 & 0.7104 & [\({}^{}\), \({}^{}\)] & [\({}^{}\), \({}^{}\), \({}^{}\)] \\   

Table 2: Epistemic uncertainty and recommended movie genres for a random user considering sequential interaction intervals

  
**Key functions** & **Sequential** & **NODE** & **NSDE** & **E-NSDE** \\  Varied interval & ✗ & ✓ & ✓ & ✓ \\ Uncertainty in preference & ✗ & ✗ & ✓ \\ Uncertainty in interaction & ✗ & ✗ & ✓ \\   

Table 3: Comparison of related recommendation modelsto capture sustained interest over the long term. In each sequence, E-NSDE attempts to provide diverse genres as shown in the first row ('Thriller') and second row ('Sci_Fi') of the E-NSDE result. When there is a long time interval, the model can leverage this opportunity guided by its predicted epistemic uncertainty and recommend a novel genre ('Crime') to explore the diverse items that can help to capture the user's long-term interest. The ability to quantify time-aware uncertainty also allows E-NSDE to outperform SOTA sequential recommendation models as shown in Table 1.

As a key innovation, we connect NSDE-based user-item representation learning with EDL using a monotonic network to provide an evidence-guided recommendation to capture time-sensitive rating prediction augmented with uncertainty estimation. Intuitively, the model's uncertainty of a user's interest should increase with respect to the time interval since the last observed user-item interaction. To model time-sensitive uncertainty, we integrate EDL using an uncertainty-aware regression model to infer evidential distributions that allow us to quantify both aleatoric and epistemic uncertainties. Similarly, the monotonic network captures the underlying constraint of monotonicity between the time interval and the predicted uncertainty: a longer time interval leads to a higher uncertainty. With accurately estimated uncertainty, the proposed framework effectively explores user preference from a large item space. The main contribution of this paper is fourfold:

* a novel recommendation model that integrates neural stochastic differential equations with evidential learning for time-aware uncertainty quantification for effective sequential recommendations,
* leveraging interaction and time-guided evidential uncertainty to maximize information gain through exploration of a large item pool,
* a monotonic network to ensure a positive correlation between interaction gap and uncertainty,
* an end-to-end integrated training process with seamless integration of NSDE and EDL modules.

To assess the feasibility of our method in comparison with existing state-of-the-art methods, we perform a wide range of experiments on publicly available real-world datasets. We also conduct ablation and case studies to analyze the effectiveness and interpretability of our method.

## 2 Related Work

In this section, we provide existing works most relevant to our proposed approach. Some additional related works are discussed in the Appendix.

**Sequential recommendation models.** Sequential models utilize users' historical interactions to capture users' preferences over time. Tang et al. utilized a CNN architecture to capture union level and point level contributions . Kang et al. leveraged transformer-based user representation to better capture their interest . Sun et al. utilized a bidirectional encoder for sequential recommendation . Similarly, Zhou et al.  have leveraged auxiliary self-supervised objectives to learn correlation among attributes, items, sub-sequences, and sequences by utilizing mutual information maximization. Recently, contrastive learning has been used in sequential recommendation [40; 43] to learn high-quality user representation leveraging different forms of data augmentation strategies. Recently, SAR  has leveraged an actor-critic network, where the action is generated as adaptive sequence length to better represent the user's sequential pattern. Similarly, ResAct  utilizes residual actor-network to reconstruct policy that is close but better than online policy more efficiently in sequential recommendation. However, most existing sequential models are inadequate to capture long-term users' preferences, which is a critical gap that the proposed work aims to address.

**NODE based recommender systems.** Neural ODE solvers have recently been introduced into recommender systems [9; 36]. For example, the learnable time ODE-based collaborative filtering  redesigns linear graph convolution networks on top of the NODE that learns the optimal architecture and smooth ODE solutions for effective collaborative filtering. Similarly,  utilizes meta-learning enhanced neural ODE for citywide next POI Recommendation. It models city-invariant and city-specified information separately to achieve accurate citywide next POI recommendation. As discussed earlier, standard NODE models do not explicitly capture uncertainty, which is critical for a recommendation model to explore a large item space to capture user's long-term preference.

## 3 Preliminaries

**Problem formulation.** The input to a recommendation model include a user set (\(U\)) and item set (\(I\)), respectively. We represent a user as \(u_{t} U\) and item as \(i_{t} I\) at time \(t\). In a sequential recommendation setting, users' interactions are organized in the chronological order and we use \((i_{0},i_{1},...,i_{t-1},i_{t})^{}\) to represent interaction sequences for user \(u\) at time \(t\). We perform recommendation and uncertainty quantification for each user using a function:

\[f_{}(u_{t},i_{t})=\{_{(u_{t},i_{t})},_{(u_{t},i_{t})},_ {(u_{t},i_{t})},_{(u_{t},i_{t})}\}\]

where \(_{(u_{t},i_{t})}\) is the recommendation score for item \(i\) assigned by user \(u\), \(_{(u_{t},i_{t})}\) and \(_{(u_{t},i_{t})}\) are the model evidence, and \(_{(u_{t},i_{t})}\) is a total uncertainty arising from the user-item interaction at time \(t\).

**Evidential learning.** Evidential learning is an evidence acquisition process where every training sample adds support to learn a higher order evidential distribution [33; 1]. Given that the target \(y_{n}\) is drawn i.i.d. from a Gaussian distribution with unknown mean and variance \((,^{2})\) the model evidence can be introduced by further placing a prior distribution on \((,^{2})\). Placing a Gaussian prior on the unknown mean and the Inverse-Gamma prior on the unknown variance, the posterior of \((,^{2})\) is the Normal-Inverse-Gamma (NIG) distribution. The Gaussian and the Inverse-Gamma priors are chosen to ensure conjugacy:

\[p(y_{n}|,^{2})=(,^{2}),\ p(|,^{2} ^{-1})=(,^{2}^{-1}),\ p(^{2}|,) =(,)\]

where \((z|,)=}{()}( )^{+1}(-)\) with \(()\) being a gamma function; \(=(,,,)\) are parameters of the corresponding prior distributions. The posterior of \((,^{2})\) follows a Normal Inverse-Gamma (NIG):

\[p(,^{2}|)=}{() }}(})^{+1}\{- }{2^{2}}\}\]

Given a NIG posterior, one can derive the mean (\([]\)), aleatoric (\([^{2}]\)) and epistemic (\([]\)) uncertainty as:

\[[]=,\ [^{2}]=,\ []= \]

**Neural ordinary differential equations (NODE).** Ordinary Differential Equations (ODEs) are used to model continuous-time hidden dynamics in neural networks  that can be defined as:

\[dh_{t}=f_{}(h_{t},t)t, h_{0}^{d} \]

where \(f()\) is a neural network with parameter \(\) and \(h_{0}\) is an initial value. Leveraging Eq (2) and integrating these dynamics forward, one can compute \((t_{i+1})\) from \((t_{i})\) by solving the following Riemann integral problem:

\[(t_{i+1})=(t_{i})+_{t_{i}}^{t_{i+1}}f((t_{i} ),t;)dt \]

**Neural stochastic differential equations (NSDE).** We could view Stochastic Differential Equations (SDE) as an ODE with infinitesimal noise added throughout time:

\[dh_{t}=f_{}(h_{t},t)dt+g_{}(h_{t},t)dB_{t} \]

where \(f(.)\) and \(g(.)\) are drift and diffusion functions respectively, \(B_{t}\) is a Brownian motion. Similar to NODE, we are also able to compute the forward dynamics of NSDE i.e. \((T)\) from initial value \((t_{0})\) integrating Eq (4) as:

\[h(T)=h(t_{0})+_{t_{0}}^{T}f(h(t),t;)dt+_{t_{0}}^{T}g(h(t),t;) dB_{t} \]

## 4 Time-Aware Sequential Recommendations

**Overview.** We propose a novel time-aware sequential recommendation model as shown in Figure 1. The model leverages 1) NSDE to capture continuous time-evolving user dynamics and 2) an evidential module to capture uncertainty in user-item interactions and also to provide uncertainty-aware exploration that takes into consideration the interaction interval. The NSDE module takes the initial representations of users and items as inputs, and uses the interaction time gap to generate refined user and item representations. Subsequently, these improved user and item representations are fed into the EDL module. The rating network then generates a rating score, while the monotonic network produces evidential parameters that incorporate the interaction time gap, establishing a direct link to the model's predicted uncertainty. Our approach adheres to the conventional sequential training strategy and incorporates supervised signals derived from evidential learning. We delve into detailed discussions in the subsequent sections.

### NSDE Based User and Item Representations

The NSDE includes two key components: drift and diffusion functions. The drift component captures the system's evolving nature, and the diffusion component captures its stochasticity. The proposed NSDE for recommender system advances contemporary sequential models from the following aspects: 1) existing methods require partitioning the time into uniform intervals to support model training and inference, while NSDE removes this requirement, providing additional flexibility; 2) the existing methods largely negate stochasticity in the system, but the NSDE incorporates it into the form of inherent noise. The above issues suggest a better fit of the NSDE into sequential recommendation and essentially support generating richer user and item representations. This is because SDE can capture users' continuously evolving preferences over time, while previous discrete sequential and deterministic ODE methods cannot. The fine-grained user representation (based on NSDE formulation) can be written following (5):

\[u(T)=u(t_{0})+_{t_{0}}^{T}f(u(t),t;)dt+_{t_{0}}^{T}g(u(t),t;) dB_{t} \]

where \(u(t_{0})\) is the user's initial representation which aggregates a set of initially interacted items: \(u(t_{0})=(i_{1}..i_{k})\) and \(T\) is the final time.

In the setting of recommender systems, the drift component naturally encodes the evolution of the user's preference, while the diffusion component captures inherent noise that occurs when the user interacts with the environment. In particular, we leverage the diffusion function with Brownian motion to capture the user's inherent noise over each interaction. This term is crucial in SDE to capture stochasticity in the system. By capturing stochasticity, we incorporate the impact of noisy user-item interactions. As it includes the Brownian motion for stochasticity, we relate this in recommender systems to incorporate noise considering the time interval of interaction. We first provide the standard definition and properties of the Brownian motion and then present its applicability in the recommendation setting.

**Definition 1** (Standard Brownian Motion).: _A standard Brownian motion \(B_{t}\) is a stochastic process that satisfies the following properties: a) \(B_{t}-B_{s}\) is normally distributed with zero mean and \((t-s)\) variance: \((0,t-s)\) for all \(t s 0\); b) For every pair of disjoint time intervals \([t_{1},t_{2}]\) and \([t_{3},t_{4}]\), with \(t_{1}<t_{2} t_{3} t_{4}\), the increments \(B_{t_{2}}-B_{t_{1}}\) and \(B_{t_{4}}-B_{t_{3}}\) are independent random variables._

**Theorem 1**.: _For user representation defined by the Brownian motion in Eq.(6), with two adjacent timestamps of interaction denoted as \(t_{2}\) and \(t_{1}\), a larger interaction time interval (\(t_{2}-t_{1}\)) guarantees a higher uncertainty of user representation._

Given Theorem 1, the final term in Eq. (6) captures the user's time deviation and its impact in increasing large variance or noise in the system. Further, the first term captures the user's initial representation with some interactions, and the second drift component provides the user's evolving

Figure 1: Overview of E-NSDE framework, which includes user and item NSDE modules to generate the final user and item representation and an EDL module to provide an uncertainty-aware prediction.

interest. Considering all of these three components, the SDE solver captures the user's richer representation over time. Similarly, NSDE-based item representation processes can be formulated as:

\[i(T)=i(t_{0})+_{t_{0}}^{T}f(i(t),t;)dt+_{t_{0}}^{T}g(i(t),t;)dB _{t} \]

where, \(i(t_{0})\) represents item's initial representation

### Evidential Module

We leverage an evidential learning technique to provide an uncertainty-aware model prediction for effective recommendations. The evidential module consists of two key networks: Rating Network and Monotonic Network.

**Rating Network.** The rating network utilizes the fine-grained user \(u_{t}\) and item \(i_{t}\) representations from the NSDE and predicts the score \(_{(u_{t},i_{t})}\) of the corresponding user item interactions. We adopt an evidential loss as the marginal likelihood while computing the predicted loss. This includes the negative log-likelihood (\(^{NLL}[f_{}]\)) to maximize the marginal likelihood and an evidential regularizer (\(^{R}[f_{}]\)) to impose a high penalty on the predicted error with low uncertainty (i.e., high confidence). We first formulate the negative log-likelihood, given by

\[^{NLL}[f_{}(u_{t},i_{t})]=-(p(r_{(u_{t},i_{t})}|(u_{t},i_{t})) \]

where, \((u_{t},i_{t})=(_{(u_{t},i_{t})},_{(u_{t},i_{t})},_{( u_{t},i_{t})},_{(u_{t},i_{t})})\) are model parameters at time t, and \(p(r_{(u_{t},i_{t})}|(u_{t},i_{t}))\)= \(St(r_{(u_{t},i_{t})};_{(u_{t},i_{t})},,i_{t})}(1+_{ (u_{t},i_{t})})}{_{(u_{t},i_{t})}_{(u_{t},i_{t})}},2_{(u_{t},i_{ t})})\) is a student t-distribution acquired after placing a NIG evidential prior on Gaussian likelihood function. We formalize our own evidence regularizer, which considers epistemic uncertainty to penalize confidently predicted errors. We multiply the predicted error with the inverse epistemic uncertainty that scales up the error, which encourages high inverse epistemic uncertainty when the predicted evidence is high (and vice-versa). Conversely, it will be less penalized if the prediction is close to the target score:

\[^{R}[f_{}(u_{t},i_{t})]= |r_{(u_{t},i_{t})}-_{(u_{t},i_{t})}|.[,i_{t})}(_{(u_{t},i_{t})}-1)}{_{(u_{t},i_{t})}}] \]

The regularized EDL loss for each sequential update is:

\[_{EDL}(u_{t},i_{t})=^{NLL}[f_{}(u_{t},i_{t})]+ ^{R}[f_{}(u_{t},i_{t})] \]

where \(\) is a regularization coefficient.

Monotonic Network.We adopt the concept of a monotonic network  in the context of building the relationship between the interaction time gap and model uncertainty. Intuitively, the monotonic network is designed in such a way that the increase in input, i.e., time interval (\( t\)), increases the output, i.e., the variance of the predicted rating. The variance or epistemic uncertainty is computed as given by Eq (1). For this, the nominator term, i.e., total uncertainty \(_{(u_{t},i_{t})}\) should need to be increased with the increase in \( t\), and the denominator terms, i.e., pseudo-observations \(\) and \(\) should need to be decreased with the increase in \( t\). We theoretically show this intuition in the following theoretical section and show a mathematical relation. We maintain this by performing exponential transformation of the network weights as: \(=)}\), where \(_{init}\) is the network's initial weight. To ensure \(\) to monotonically increase, we assign all positive weights to the network layers. Similarly, to ensure \(\) and \(\) to monotonically decrease, we assign negative weights to the last layer and positive weights to other layers of the network. We update the network utilizing the total loss similar to the rating network.

**Lemma 1** (Monotonic increase of total uncertainty \(\)).: _Let the total uncertainty of user-item interaction \(_{(u_{t},i_{t})}\) be the output of the evidential monotonic network with weights \(=)}\). Given a time interval \( t\), the output of the network is guaranteed to monotonically increase._

**Lemma 2** (Monotonic decrease of pseudo-observations \(\) and \(\)).: _Let \( t\) be the increased time interval \( t\), weights \(W_{L}\) of the last layer be negative, and weights \(W_{0,,L-1}\) for other layers be positive, the output i.e., pseudo-observations \(_{(u_{t},i_{t})}\), and \(_{(u_{t},i_{t})}\) of the evidential monotonic network decreases monotonically._

**Theorem 2**.: _(Increased time interval \( t\) results in increased in epistemic uncertainty \(Var[]\)). Given the monotonic network formulated by Lemmas 1 and 2, an increase of the input time interval (\( t\)) of the evidential monotonic network guarantees an increase of the output epistemic uncertainty \(Var[]\)._

Proof.: The epistemic uncertainty equation from Eq (1):

\[_{(u_{t},i_{t})}=[]=,i_{t})}}{_{ (u_{t},i_{t})}(_{(u_{t},i_{t})}-1)}\]

Given the increase \(_{(u_{t},i_{t})}\) from Lemma 1 and decrease in \(_{(u_{t},i_{t})}\) and \(_{(u_{t},i_{t})}\) from Lemma 2 the nominator of the epistemic uncertainty increases, and the denominator decreases. This proves that the increase in the time interval (\( t\)) increases the epistemic uncertainty \([]\) of the evidential monotonic network. We enforce the constraints on \((_{(u_{t},i_{t})},_{(u_{t},i_{t})},_{(u_{t},i_{t})})\) with a softplus activation and adding 1 to \(_{(u_{t},i_{t})}\) since \(_{(u_{t},i_{t})}>1\)). 

**Interpreting hyper-parameters.** Besides serving as the parameters of the evidential prior distributions, the hyper-parameters \((_{(u_{t},i_{t})},_{(u_{t},i_{t})},_{(u_{t},i_{t})})\) offer very intuitive meanings. First, both \(_{(u_{t},i_{t})}\) and \(_{(u_{t},i_{t})}\) are essentially the 'pseudo' prior observations, and their posterior can be treated as the _evidence_ to support a prediction. In the context of the recommendation, their relation with time interval is inverse, because the large time gap causes a decrease in the number of pseudo items, as mentioned in Lemma 2. Second, the \(_{(u_{t},i_{t})}\) hyperparameter combines total uncertainty from pseudo samples and observed data. Lemma 1 shows that an increase in time interval will result in an increase in the uncertainty (due to a smaller number of pseudo and interacted items to the user), and therefore, the model will be less confident in providing an accurate prediction.

**Weighted Bayesian personalized ranking (WBPR) loss.** To leverage the effective exploration for the long-term, we formulate weighted BPR loss which is computed from non-interacted (_i.e.,_ negative) items, \(j_{t}_{t}\) that are similar to the user's future interacted items. We first select similar negative items from the user non-interacted item pool and then leverage cosine similarity with future positive item embeddings. Further, the model provides uncertainty-aware predicted rating score for those negative items leveraging both rating and monotonic network output as:

\[_{(u_{t},j_{t})}=_{(u_{t},j_{t})}+_{(u_{t},j_{t})} \]

where \(j_{t}\) represents non-interacted items at time t and \(\) is scalar to control the influence of epistemic uncertainty. We then compute weight coefficients based on uncertainty-aware predicted scores with cosine similarity \(()\) as:

\[w_{(i_{t},j_{t})}=[()],_{(u_{t},j_{t})}>\\ [(,)],\]

where \(,\) are future and negative item embedding, respectively. We then formulate weighted BPR loss utilizing a negative log-likelihood function as:

\[_{}(u_{t},i_{t})=_{(u_{t},i_{t},j_{t} _{t})}w_{(i_{t},j_{t})}\{-[(_{(i_{t},j_{t})})]\} \]

where \(_{(i_{t},j_{t})}=_{(u_{t},i_{t})}-_{(u_{t},j_{t})}\), \(()\) is the sigmoid.

**Remark.** The intuition behind this weighted BPR formulation is to learn effective exploration by providing higher weight to the non-interacted items which are quite similar to user future positive items so that model can learn quickly a diverse range of evolving behavior to benefit the future.

The overall loss of the end-to-end model training is obtained by combining the EDL and WBPR loss:

\[(u_{t},i_{t})=_{}(u_{t},i_{t})+_{}(u_{t},i_{t}) \]

where \(\) represents the balancing factor between EDL and WBPR loss. Training and inference details are provided in Appendix D.

## 5 Experiments

**Experimental setup.** Our experiment setting of sequential recommendation is based on next-item recommendation tasks, which was used in . We first split users by 70% into train and 30% intest. For each user, we leverage the fixed sequence length and hold out the next item of the behavior sequence as the target item. We follow the standard strategy in  for easy and fair evaluation. We leverage the actual time of interactions (in UNIX timestamp) to provide user preference evolution.

**Datasets and baselines.** We conduct extensive experiments on four real-world datasets that contain explicit ratings: _Movielens-100K_, _Movielens-1M_, _Netflix_, and _Amazon Book_.

* **Movielens-100K2**: This dataset contains 100,000 explicit ratings on a scale of (1-5) from 943 users on 1,682 movies. Each user at least rated 20 movies from September 19, 1997 through April 22, 1998. * **Movielens-1M3**: This dataset includes 1M explicit feedback (i.e. ratings) made by 6,040 anonymous users on 3,900 distinct movies from 04/2000 to 02/2003.
* **Netflix**: This dataset has around 100 million interactions, 480,000 users, and nearly 18,000 movies rated between 1998 to 2005. We pre-processed the dataset and selected 6,042 users with user-item interactions from 01/2002 to 12/2005.
* **Amazon Book**: This data set contains 2,984,108 ratings applied to 91,599 books by 52,643 users with at least ten interactions in each user sequence

For comparisons, we include a comprehensive list of SOTA baselines from diverse groups, including _Dynamic models:_ timeSVD++  and CKF ; _Sequential models:_ CASER , SASRec , BERT4Rec , \(S^{3}\)-Rec, CL4SRec , SAR , and ResAct ; _Graph-based models:_ NGCF and LightGCN; _ODE-based models:_ LT-OCF  and GRU-ODE .

**Evaluation metrics.** To evaluate the proposed and baseline recommendation models, we follow the sequential recommendation setup similar to . We consider one ground truth item in each sequential recommendation. We use two standard metrics to measure the recommendation performance.

* **Precision@N (P@N)**: It is the fraction of the top-\(N\) items recommended in each sequence to the user. We reported the average overall sequence precision value as the final precision. Further, due to only one ground truth in the target, the P@N is equivalent to Recall@N.
* **nDCG@N** : Normalized Discounted Cumulative Gain (nDCG) measures ranking quality, considering the relevant items within the top-\(N\) of the ranking list in each recommendation.

For more details about datasets, and implementation please refer to the Appendix.

**Recommendation performance comparison.** Table 4 summarizes the recommendation performance from all models for four real-world datasets. The proposed model benefits from both the SDE module, which continuously captures user evolving preferences, and the evidential module, which estimates prediction confidence, and thus achieves better results in all four datasets. The dynamic models achieve less ideal performance due to their focus on discrete-term user interest and inability to provide continuous user preference. Graph-based methods take advantage of recently interacted items and have shown better performance than traditional dynamic methods. However, they may not be good enough to capture user sequential interest. Further, sequential methods benefit from sequential learning and have promising results. However, they do not consider the time component in the recommendation and are less effective than the proposed method. ODE-based methods have

    &  &  &  &  &  \\   & & **P05** & **aDCC@S** & **P05** & **aDCC@S** & **P05** & **aDCC@S** & **P05** & **aDCC@S** \\   & timeSVD++ & 0.342\(\)0.015 & 0.342\(\)0.013 & 0.397\(\)0.016 & 0.3508\(\)0.013 & 0.375\(\)0.016 & 0.329\(\)0.013 & 0.380\(\)0.014 & 0.312\(\)0.012 & 0.312\(\)0.012 \\  & & CSF & 0.391\(\)0.017 & 0.362\(\)0.010 & 0.379\(\)0.016 & 0.355\(\)0.015 & 0.360\(\)0.017 & 0.386\(\)0.014 & 0.382\(\)0.016 & 0.312\(\)0.015 \\   & NGCF & 0.3899\(\)0.014 & 0.366\(\)0.022 & 0.3978\(\)0.016 & 0.3587\(\)0.018 & 0.3574\(\)0.015 & 0.3167\(\)0.017 & 0.3574\(\)0.012 & 0.3321\(\)0.011 \\  & LightGCN & 0.410\(\)0.0014 & 0.3702\(\)0.013 & 0.4028\(\)0.017 & 0.3423\(\)0.015 & 0.367\(\)0.013 & 0.3234\(\)0.016 & 0.3783\(\)0.013 & 0.3382\(\)0.012 \\   & CASER & 0.409\(\)0.0012 & 0.363\(\)0.014 & 0.4021\(\)0.014 & 0.368\(\)0.016 & 0.368\(\)0.013 & 0.312\(\)0.012 & 0.3722\(\)0.012 & 0.314\(\)0.014 & 0.3445\(\)0.012 \\  & SASRec & 0.410\(\)0.0013 & 0.3740\(\)0.011 & 0.412\(\)0.015 & 0.378\(\)0.017 & 0.3740\(\)0.012 & 0.3257\(\)0.014 & 0.3312\(\)0.014 & 0.3445\(\)0.012 \\  & **BERT4Rec** & 0.414\(\)0.0014 & 0.3781\(\)0.011 & 0.4163\(\)0.012 & 0.3788\(\)0.017 & 0.3798\(\)0.013 & 0.3293\(\)0.013 & 0.3846\(\)0.013 & 0.3450\(\)0.013 \\  & **51-Rec** & 0.421\(\)0.0012 & 0.3758\(\)0.014 & 0.4143\(\)0.013 & 0.3715\(\)0.014 & 0.3786\(\)0.010 & 0.3274\(\)0.013 & 0.3752\(\)0.014 & 0.3350\(\)0.012 \\  & **CL4SRec** & 0.421\(\)0.0016 & 0.3821\(\)0.010 & 0.2456\(\)0.013 & 0.3378\(\)0.015 & 0.3834\(\)0.016 & 0.3385\(\)0.012 & 0.3858\(\)0.014 & 0.3313\(\)0.011 \\  & SAR & 0.403\(\)0.0012 & 0.3741\(\)0.012 & 0.4023\(\)0.014 & 0.3747\(\)0.014 & 0.3711\(\)0.012 & 0.3234\(\)0.013 & 0.3858\(\)0.012 & 0.3320\(\)0.014 \\  & ResAct & 0.403\(\)0.0014 & 0.3988\(\)0.012 & 0.2386\(\)0.014 & 0.344\(\)0.014 & 0.3867\(\)0.014 & 0.3369\(\)0.011 & 0.3368\(\)0.013 & 0.3347\(\)0.013 \\   & LT-OCF & 0.4267\(\)0.013 & 0.375\(\)0.015 & 0.4141\(\)0.016 & 0.367\(\)0.014 & 0.384\(\)0.012 & 0.3313\(\)0.011 & 0.341\(\)0.014 & 0.346\(\)0.012 \\  & GRU-ODE & 0.4398\(\)0.0014 & 0.3902\(\)0.017 & 0.4275\(\)0.013 & 0.3792\(\)0.012 & 0.3994\(\)0.013 & 0.3417\(\)0.015 & 0.3365\(\)0.014 & 0.3455\(\)0.012 \\  
**Proposed** & **E-NNDE** & **0.4715\(\)0.015** & **0.4122\(\)0.033** & **0.4581\(\)0.0011** & **0.392\(\)0.016** & **0.479\(\)0.013** & **0.473\(\)0.015** & **0.4021\(\)0.014** & **0.3621\(\)0.012** \\   

Table 4: Recommendation performance comparison shown a clear advantage due to their focus on capturing users' continuous behavior over time, but they cannot estimate model confidence on predictions and hence have lower performance value than the proposed method. We provided a detailed plot of precision and nDCG @5 in Figure 2 considering test users in each training epoch. Further, we report the precision and NDCG @10 and @20 as the increased top-\(N\) metric (_i.e., \(N=10,20\)_) for several baselines in the appendix. The results show the proposed model is consistently outperforming other baselines.

Uncertainty vs. Interaction gapWe further investigate the impact of the user-item interaction gap and the corresponding uncertainty in providing important and diverse items. Table 5 (a) shows the proposed E-NSDE model provides diverse (_i.e.,_ "Thriller' and 'Sci_Fi') movies for the larger interaction time gap \( t=896,291\) seconds that help to capture the future interest of the user. On the other hand, the existing GRU-ODE model recommends only popular genres like 'Drama' and fails to explore others adequately. We further provided the simulation results of 5 users considering increasing time intervals: \(\{10^{2},10^{3},10^{4},10^{5},10^{6},10^{7}\}\) in seconds with random item interactions on those timestamps and the corresponding predicted uncertainty in Figure 3. The total uncertainty \(\) monotonically increases with the time intervals which shows that E-NSDE effectively captures user's uncertainty coming from longer interaction gaps.

Effectiveness of explorationTo demonstrate the effectiveness of the uncertainty-based exploration, we measure the diversity of the recommended items. We consider three commonly used diversity measures: Gini index (\(G\)), Coverage (\(C\)), and Novelty (\(N\)):

* **Gini index** can be calculated by leveraging the different genres as categories for each recommended top \(K\) items in a sequence: \(G=1-_{c=1}^{C}P(c)^{2}\), where \(C\) is the number of categories and \(P(c),c[1,C]\) is the probability for each category.
* **Coverage** represents the number of categories that are included in the recommendation list. For the recommended top \(K\) items, we compute item coverage as: \(C=/\).
* **Novelty** is defined by the ratio of recommended items from new categories not interacted by the user. It is computed as : \(N=\ /K\).

Table 5: (a) Diverse recommendations by E-NSDE; (b) Ablation of key componentsTable 6 shows that E-NSDE recommends more diverse items based on all three evaluation metrics as compared with the two competitive baselines thanks to its uncertainty-guided exploration strategy.

Ablation study.We conduct an ablation study and details are summarized below:

* _Impact of key components._ We evaluate the impact of each key component in the proposed E-NSDE. Table 5 (b) shows each component contributes to improved recommendation performance.
* _Evidential regularization parameter._ One of the key hyperparameters of the _E-NSDE_ model is the regularizer constant (\(\)) for the evidential learning. We cross-validated this parameter with empirical results of the model for the different \(\) values in two datasets as shown in Table 7. From the table, our model achieves the best performance in both datasets with \(=0.001\).
* _Embedding dimension._ We generate user and item embeddings using the embedding network. We perform a grid search for the embedding dimension (\(d\)) of the user and item representation in _E-NSDE_ model as shown in Figure 3(a). From the plot, it shows that E-NSDE has the best performance with \(d=64\).
* _Balancing factors._ We leverage grid search on uncertainty-aware ranking factor \(\), and WBPR loss balancing factor \(\) on three datasets as shown in Figure 3(b) and Figure 3(c), respectively. The figure shows a clear advantage with \(=0.01\), which indicates that the uncertainty-aware exploration component takes an effective role in providing the best performance for our proposed E-NSED model. Similarly, for \(\) balancing factor integrated overall loss has the best performance when it is equal to \(0.001\).

## 6 Conclusion

We propose a novel evidential stochastic differential equations (E-NSDE) model for the time-aware sequential recommendations. E-NSDE seamlessly integrates an NSDE module and an EDL module to capture users' continuously evolving behavior and model predictive uncertainty at the same time. Our proposed model effectively leverages the interaction time gap and provides uncertainty-aware recommendations with diverse items to the user. Further, we theoretically derive mathematical relationships between the interaction time gap and model uncertainty to enhance the learning process, as demonstrated in our extensive experiments on multiple real-world datasets.

    &  &  &  \\   & MovieLens-1M & Netflix & MovieLens-1M & Netflix & MovieLens-1M & Netflix \\ 
**BERT4Rec** & 0.6845 & 0.6926 & 0.4103 & 0.3718 & 0.1434 & 0.1752 \\ GRU-ODE & 0.6632 & 0.6784 & 0.4142 & 0.3812 & 0.1482 & 0.1866 \\ 
**E-NSDE** & **0.7413** & **0.7811** & **0.4416** & **0.4026** & **0.2402** & **0.2236** \\   

Table 6: Gini index, coverage, and novelty comparisons

Figure 4: Average nDCG@5 plot for different embedding sizes, and balancing factors

    &  &  \\   & **P@5** & **nDCG@5** & **P@5** & **nDCG@5** \\ 
0 & 0.4236 & 0.3786 & 0.4022 & 0.3574 \\
0.0001 & 0.4412 & 0.3914 & 0.4134 & 0.3615 \\
**0.001** & **0.4551** & **0.3982** & **0.4194** & **0.3637** \\
0.01 & 0.4518 & 0.3942 & 0.4096 & 0.3605 \\
0.1 & 0.4224 & 0.3756 & 0

#### Acknowledgments

This research was supported in part by an NSF IIS award IIS-1814450. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agency. We would like to thank the anonymous reviewers for their constructive comments.