# Few-shot Generation via Recalling Brain-Inspired Episodic-Semantic Memory

Zhibin Duan, Zhiyi Lv, Chaojie Wang, Bo Chen,

National Laboratory of Radar Signal Processing

Xidian University, Xi'an, Shaanxi 710071, China

xd_zhibin@163.com, xd_silly@163.com, bchen@mail.xidian.edu.cn

Bo An

Nanyang Technological University &Mingyuan Zhou

The University of Texas at Austin

Equal ContributionCorresponding Author

###### Abstract

Aimed at adapting a generative model to a novel generation task with only a few given data samples, the capability of few-shot generation is crucial for many real-world applications with limited data, _e.g._, artistic domains. Instead of training from scratch, recent works tend to leverage the prior knowledge stored in previous datasets, which is quite similar to the memory mechanism of human intelligence, but few of these works directly imitate the memory-recall mechanism that humans make good use of in accomplishing creative tasks, _e.g._, painting and writing. Inspired by the memory mechanism of human brain, in this work, we carefully design a variational structured memory module (VSM), which can simultaneously store both episodic and semantic memories to assist existing generative models efficiently recall these memories during sample generation. Meanwhile, we introduce a bionic memory updating strategy for the conversion between episodic and semantic memories, which can also model the uncertainty during conversion. Then, we combine the developed VSM with various generative models under the Bayesian framework, and evaluate these memory-augmented generative models with few-shot generation tasks, demonstrating the effectiveness of our methods.

## 1 Introduction

A remarkable capability of human intelligence is its ability to quickly grasp the concepts of new objects that it has never encountered before . Essentially, this rapid adaptation is achieved by utilizing the past memories stored in the human brain, which can greatly improve the efficiency of later learning . Unlike human brain, existing machine learning methods often require to be trained on a large amount of data when facing new tasks, motivating the research interests on few-shot learning that aim at efficiently solving these unseen tasks with only a few given data samples . While there have been promising processes for few-shot adaptation on classification tasks, less work has been done on few-shot generation , which is mainly due to the challenging nature of learning the generative process with only a few samples in an unsupervised manner .

For existing deep neural networks, to improve their abilities of few-shot adaptation, one of the most effective methods is to introduce an augmented memory module, which can store the memory of past experiences to adapt the model to a new task quickly . However, the most widely used memory mechanism in exisiting works is short-term  with limited capacity, which focuses on thecollection of personal experience related to a particular place or time. To remove the limitation of short-term memory, Zhen et al.  introduce the concept of semantic memory, which allows the storage of general conceptual information into meta-learning to acquire long-term knowledge for few-shot learning. Although these memory modules have separately achieved attractive progress in few-shot learning [1; 2; 19; 20], there is little work to explore a memory mechanism to organically combine the semantic and episodic memories, and further apply it on few-shot generation tasks.

Inspired by the memory mechanism of the human brain, where both episodic and semantic memory work together to help humans understand the world around us and also accomplish creative tasks, in this work, we first develop a variational structured memory module (VSM), which can simultaneously store both episodic and semantic memories to improve the few-shot generation capability of the generative models. Then, we design two important processes in VSM: 1) structured memory recall, which retrieves the relevant information of previous tasks from VSM to be applied on current task; 2) structured memory update, which continuously collects data information from training tasks and gradually consolidates the structured memories stored in VSM. Finally, we combine VSM with a branch of few-shot latent variable models, specifically neural statistician (NS) , and develop a series of memory-augmented latent variable models for few-shot generation.

The main contributions of this paper can be summarized as follows:

* Inspired by the memory mechanisms of the human brain, we develope a novel variational structured memory module (VSM) that can concurrently store both episodic and semantic memories, effectively aiding generative models in memory recall during sample generation.
* Meanwhile, we introduce a bionic memory updating strategy for the conversion between episodic and semantic memories stored in VSM, where episodic memory can provide detailed episodes that will be converted later and stored in semantic memory.
* Through incorporating VSM with NS, we develop a novel hierarchical memory-augmented neural statistician (HMNS), whose generative process can be specified with VAE or diffusion model, leading to VSM-VAE and VSM-Diffusion, respectively.
* Extensive experiments demonstrate that our developed VSM-VAE and VSM-Diffusion can achieve promising generative performance on few-shot generation tasks.

## 2 Related work

**Few-Shot Latent Variable Models:** For few-shot generation, a series of latent variable models based on NS  have been developed [9; 10; 11; 12], which can be further improved by adopting a non-parametric formulation for the context , introducing a hierarchical learnable aggregation for the input set , increasing expressivity for the conditional prior , or exploring supervision . Specifically, NS  introduces a context constant variable to specify the summary statistics of a dataset, which provides a shared prior for these samples within the same dataset, contributing to handling new datasets at test time; GMN  defines a variational model to learn a per-sample context-aware latent variable. Distinct from previous works, our method introduces a memory module to collect historical datasets information to inference the context of a new dataset.

**Memory-Augmented Neural Networks:** It has been shown that augmenting existing neural networks with an external memory module can improve their capability of few-shot learning . Specifically, these memory-augmented neural networks mainly collect the information stored in the support set of the current task [6; 15; 16], which will be wiped form episode to episode  instead of maintaining long-term information that has been shown to be crucial for effectively learning new unseen tasks. For instance, variational semantic memory  is proposed to accumulate and store the semantic information from previous tasks for the inference of the prototypes of new tasks. Distinct from previous methods only constructing semantic memory for the prototype network, in this paper, we develop a structured memory module to store the historical information at both the episodic and semantic sides, which can largely enhance the model's capability of few-shot generation.

## 3 Memory-Augmented Neural Statistician

### Preliminary

**Few-shot Generation**: Few-shot generation  borrows a similar setting of few-shot learning  but for a more challenging task to generate objects given only a few samples of that object at test time. Specifically, given a set of training datasets \(D_{old}=\{D_{i}\}_{i=1}^{N}\), where each dataset \(D_{i}=\{_{ij}\}_{j=1}^{J_{i}}\) consists of \(J_{i}\) data samples, the goal of few-shot generation is to train a generative model \(p_{}()\) that is trained on given datasets \(D_{old}\) but can be quickly adapted to a new unseen task given only a few data samples collected from a new dataset \(D_{}\).

### Memory-Augmented Neural Statistician

Through incorporating memory mechanism with few-shot latent variable models, specifically NS  in Figure 1(a), in this paper, we develop a novel memory-augmented NS (MNS) for few-shot generation.

**Generative Process of MNS:** The design of MNS aims at introducing a memory module to store and update the data information at various semantic levels, which can be recalled when facing a new generative task. As shown in Figure 1(c), the generative process of hierarchical MNS is formulated as:

\[p_{}(D_{old})= _{i=1}^{N}_{j=1}^{J_{i}}p_{}( _{i,j}\,|\,_{i,j},_{i},_{i}) \] \[_{i=1}^{N}_{j=1}^{J_{i}}p_{}(_{i,j}\,|\, {c}_{i})_{i=1}^{N}p_{}(_{i}\,|\,_{i})_{i=1}^{N}p( _{i})d_{i,j}\,d_{i}\,d_{i}.\]

To clarify the meanings of \(_{i,j}\), \(_{i}\), and \(_{i}\): \(_{i,j}\) denotes the per-sample latent variables of the \(j\)th sample in dataset \(D_{i}\), \(_{i}\) denotes the task-specific context variable of dataset \(D_{i}\), whose detailed definition can be found in , and \(_{i}\) denotes the task-specific memory variable, which stores the data information of previous tasks that will be adapted to the new task.

### Variants of Hierarchical Memory-Augmented Neural Statistician

Through specifying the generative process of HMNS and replacing its memory module with the variational structured memory (VSM) as described in Section 4, we can obtain a series of model

Figure 1: The generative process of (a) neural statistician (NS), (b) hierarchical neural statistician (HNS), (c) memory-augmented variational autoencoder (VSM-VAE), and (d) memory-augmented difussion model (VSM-Diffusion), where \(_{i,j}\) denotes the observed data sample, \(_{i,j}^{(l)}\) is the latent variable at the \(l\)-th hidden layer, and \(_{i}^{(l)}\) and \(_{i}^{(l)}\) are the context variable and memory variable of dataset \(D_{i}\), respectively. More details can be found in Section 3.2.

[MISSING_PAGE_FAIL:4]

where the backward diffusion process is consistent with that of conditional diffusion model [24; 25], formulated as

\[p_{}(_{i,j}\,|\,\{_{i,j}^{(l)}\}_{l=1}^{L},_{i})=p_{ }(_{i,j}\,|\,_{i,j}^{(1)},_{i})_{l=1}^{L-1}p_{ }(_{i,j}^{(l)}\,|\,_{i,j}^{(l+1)},_{i})p_{}(_{i,j}^{(L)}). \]

**Training objective of VSM-Diffusion:** For VSM-Diffusion, the training objective is derived from maximizing the evidence lower bound (ELBO) of a set of training datasets \(\{D_{i}\}_{i=1}^{N}\), which is consistent with Eq. (5). Similar to regular DDPMs, the first term can be decomposed into a summation of \(L\) terms, each of which can be computed independently, and can be estimated as

\[_{Q}[ p_{}(D_{i}\,|\,_{i},_{i})] =\!_{j=1}^{J_{i}}_{Q}[-(_{i,j},\{ x_{i,j}^{(l)}\}_{l=1}^{L}|-)}{q_{}(\{x_{i,j}^{(l)}\}_{l=1}^{L}\,|\,_{i,j})} ]\!=\!_{j=1}^{J_{i}}L_{j,0}+_{t=2}^{L}L_{j,l-1}+L_{j,L},\]

where \(L_{L}\) is a fixed constant, \(L_{0}\) is the expectation of likelihood term and the intermediate term \(L_{l-1}\) can be formulated as

\[L_{j,l-1}=_{q_{}x_{i,j}^{(l)}|_{i,j}}[ (x_{i,j}^{(l-1)}\,\,|\,x_{i,j}^{(l)},_{i,j})}{p_{ }(x_{i,j}^{(l-1)}\,|\,x_{i,j}^{(l)},_{i})}]. \]

## 4 Variational Structured Memory

In this section, we will introduce the storage architecture of VSM in Section 4.1, equipped with the mechanism of memory recall and update in Sections 4.2 and 4.3, respectively. The basic intuition of VSM is inspired by the memory mechanism in the human brain: 1) there are two advanced forms of memory in the human brain: semantic memory allows the storage of general conceptual information and episodic memory allows the collection of detailed episodes; 2) episodic memory can provide detailed episodes that will be converted into conceptual information and stored in semantic memory. The structured memories stored in VSM will be recalled to infer the posterior of task-specific memory, formulated as:

\[q_{}(_{i}\,|\,D_{i},) \]

which will be used in the inference process of either VSM-VAE or VSM-Diffusion.

### Structured Memory Storage

As shown in Figure 7, there are \(N\) blocks (categories) in the VSM module, denoted as \(=\{_{n}\}_{n=1}^{N}\), and each memory block \(_{n}\) consists of both semantic memory \(_{n}^{(s)}\) and episodic memory \(_{n}^{(e)}\).

**Semantic Memory Storage:** The semantic memory in the human brain can provide conceptual information for quickly learning concepts of new object categories by seeing only a few data samples. Following Zhen et al. , for each block (category) of semantic memory in VSM, we try to store the conceptual information by averaging the latent representations of data samples belonging to this category, contributing to lightweight storage and fast lookup. To model the uncertainty, we model the \(n\)-th block (category) of semantic memory with a Gaussian distribution, formulated as:

\[^{(s)}=\{_{n}^{(s)}\}_{n=1}^{N},_{n}^{(s)}= (_{n},(_{n})), \]

where \(_{n},_{n}^{d}\) denotes the \(d\)-dimensional mean and variance vectors, respectively.

**Episodic Memory Storage:** Distinct from semantic memory allowing the storage of general conceptual information, episodic memory tends to focus on storing more detailed and vivid experiences or episodes. The design of episodic memory is inspired by previous works [26; 27; 28; 29; 30], and the main idea is to employ a query memory module to collect a subset of representative data samples for each block (category) in VSM. Specifically, the \(n\)-th block (category) of episodic memory is a set of \(T\) embedding vectors of data samples:

\[^{(e)}=\{_{n}^{(e)}\}_{n=1}^{N},_{n}^{(e)}= \{_{n,t}^{(e)}\}_{t=1}^{T}, \]

where \(T\) is the storage limit of each block (category) of episodic memory, and the dimension of \(_{n,t}^{(e)}^{d}\) is the same as the latent representations of data samples.

### Structured Memory Recall

Given a query dataset \(D_{i}=\{x_{i,j}\}_{j=1}^{J_{i}}\), which can be treated as a new dataset \(D_{new}\) for previous tasks, the mechanism of memory recall aims at effectively using the memory module to quickly adapt a model trained on previous tasks to a new unseen task. The workflow of structured memory recall in VSM has been depicted in Figure 7, which includes both the recalls of semantic memory \(^{(s)}\) and episodic memory \(^{(e)}\), resulting in two kinds of task-specific memories, denoted as \(_{i}^{(s)}\) and \(_{i}^{(e)}\) respectively.

**Semantic Memory Recall:** For a new few-shot generation task on the dataset \(D_{i}\) (\(D_{new}\)), the memory recall in VSM will first select the top-K relevant blocks (categories) of semantic memory as the candidates, denoted as \(\{_{k}^{(s)}\}_{k=1}^{K}\), and then use an attention mechanism to aggregate these candidates into a task-specific semantic memory \(_{i}^{(s)}\), where the attention weight of \(n\)-th can be calculated as

\[g(_{n}^{(s)},\,_{i})=(_{n}-_{i})^{2}/\,2_{n}{}^{2}, \]

where \(g()\) can be treated as a similarity function, and \(_{i}\) indicates the semantic representation of dataset \(D_{i}\) and can be obtained by averaging the latent representations of data samples in \(D_{i}\).

Then, with the top-K relevant blocks of semantic memory \(\{_{k}^{(s)}\}_{k=1}^{K}\) in hand, we can further aggregate these candidates with their attention weights, formulated as:

\[_{i}^{(s)}=_{k=1}^{K}_{i,k} _{k}^{(s)},\,_{i,k}=_{k}^ {(s)},_{i})}{_{k=1}^{K}g(_{k}^ {(s)},_{i})},\,\,_{k}^{(s)}( _{k},(_{k})), \]

where \(_{i}^{(s)}^{d}\) has gathered the relevant information from the semantic memory \(^{(s)}\) for the generation task on dataset \(D_{i}\).

**Episodic Memory Recall:** After selecting the top-K relevant blocks of semantic memory \(\{_{k}^{(s)}\}_{k=1}^{K}\), we can further dive into recalling episodic memory, which is more specific and detailed. In practice, each block of episodic memory contains \(T\) embedding vectors of data samples \(_{k}^{(e)}=\{_{k,t}^{(e)}\}_{t=1}^{T}\), and we can finally obtain \(K*T\) embedding vectors of data samples. After that, following a similar process of recalling episodic memory, we can further aggregate these obtained embedding vectors with their attention weights as

\[_{i}^{(e)}=_{k=1}^{K}_{t=1}^{T} _{i,k,t}_{k,t}^{(e)},_{ i,k,t}=_{k,t}^{(e)},_{i})}{ _{k=1}^{K}_{t=1}^{T}g(_{k,t}^{(e)}, _{i})}, \]

where \(g()\) and \(_{i}\) have been defined in Eq. (13), and the obtained \(_{i}^{(e)}^{d}\) has gathered the relevant information from the episodic memory \(^{(e)}\) for the generation task on dataset \(D_{i}\).

Figure 2: The workflow of memory recall mechanism in variational structured memory (VSM) module \(\), which stores both semantic memory \(^{(s)}\) and episodic memory \(^{(e)}\).

### Structured Memory Update and Consolidation

**Semantic Memory Update:** Inspired by the characteristics of human memory [31; 32; 33], we develop a novel semantic memory update mechanism that considers the data information from previous semantic memory \(^{(s)}\), episodic memory \(^{(e)}\), and new task \(D_{i}\). Specifically, the semantic memory module is empty at the beginning of learning, and each unseen block (category) \(_{n}^{(s)}\) will be initialized with the mean and variance of the latent representations of data samples, which is collected from the current task \(D_{i}\) and belongs to \(n\)-th category. For those seen categories, their semantic memory can be updated with the data sample from the current task \(D_{i}\) using self-attention mechanism.

Following Zhen et al. , we construct a graph with respect to the memory \(_{n}^{(s)}\) for updating, which consists of latent representations of \(J_{n}\) data samples that belongs to \(n\)-th category and \(T\) data samples stored in episodic memory \(_{n}^{(e)}\), denoted as \(H_{n}=\{_{n,1},_{n,2},,_{n,J_{n}},_{n,1}^{(e )},,_{n,T}^{(e)}\}\). The mean of the semantic memory \(_{n}^{(s)}\) can be updated as:

\[_{_{n}^{(s)}}^{new}_{ _{n}^{(s)}}^{old}+(1-)\,}_{_{n}^{(s)}}, \;}_{_{n}^{(s)}}=_{j=1}^{J_{n}+T}_{n,j}H_{n,j}, \;_{n,j}=_{n}^{(s)},H_{n,j})}{_{j=1}^{J_ {n}+T}g(_{n}^{(s)},H_{n,j})}, \]

where \((0,1)\) is a hyperparameter; \(_{n,j}\) indicates the attention weight between \(j\)-th node features and the source node \(_{n}^{(s)}\); \(g()\) is the similarity function defined in Eq. (13). This operation allows the useful information to be retained in memory while erasing less relevant or trivial information.

After that, we employ the incremental update strategy of the Gaussian distribution  to update the variance of semantic memory \(_{n}^{(s)}\) as follows:

\[_{_{n}^{(s)}}^{new}[ _{_{n}^{(s)}}^{old}+(_{_{n}^{(s)}}^{new }-_{_{n}^{(s)}}^{old})^{2}]+(1-)[_{H_{n}}^{new}+(_{_{n}^{(s)}}^{new}-_{n})^{2}], \]

where \(_{n}\) and \(_{H_{n}}^{2}\) are the mean and variance of the set of node features \(H_{n}\), respectively.

**Episodic Memory Update:** Inspired by the fact that it is difficult for a person to forget those things he/she often recalls (and vice versa), we design a frequency-based episodic memory update stragy. Typically, for each data sample \(_{n,t}^{(e)}\) stored in episodic memory \(_{n}^{(e)}\), we use a frequency matrix, denoted as \(C_{_{n,t}^{(e)}}\), to record how many times \(_{n,t}^{(e)}\) was recalled during training. Then, for updating \(_{n}^{(e)}=\{_{n,t}^{(e)}\}_{t=1}\), if the current episodic memory block has not been filled yet, we will directly append the latent representation of a new data sample to the \(_{n}^{(e)}\) when a new task arrives; Otherwise, we will update \(_{n}^{(e)}\) by replacing the least used data sample in the block if its capability exceeds the limit \(T\). We note that the frequency matrix \(C_{_{n,t}^{(e)}}\) will be reset as the zero matrix after each update of episodic memory. The detailed memory updating process algorithm can be found in Appendix A.

## 5 Experiments

### Experimental setup

**Datasets:** The experiments are conducted on five widely used benchmark datasets of various sizes, including binarized Omniglot , MNIST , DOUBLE-MNIST , CelebA  and FS-CIFAR100 . The split of training/testing set (also known as background-evaluation split) follows Lake et al. , in which scenario all the samples at test time are from new classes. We resize all the images of binary datasets to 28x28, FS-Cifar100 to 32x32, and CelebA to 64x64.

**Baselines:** 1) For VAE-based models, we utilize NS-related models, specifically focusing on two NS variants: Convolutional Neural Statistician (CNS), where the latent space is shaped with convolutions at a given resolution; Set-Context-Hierarchical-Aggregation-Variational-Autoencoder (SCHA-VAE) , which employs an additional hierarchy over the context latent variable \(c\). The CNS and SCHA-VAE can be naturally extended under the framework of VSM-VAE, leading to VSM-CNS and VSM-SCHA, respectively. Meanwhile, we create several variants by fusing either semantic memory or episodic memory with CNS or SCHA-VAE, as appropriate, to further demonstrate the efficacy of the proposed variational structured memory; 2) For Diffusion-based models, we consider bothunconditional and conditional diffusion models as baselines, where we use the DDPM  as the unconditional baseline and other three conditional diffusion models: VDDPM, where the context \(c\) is a latent variable and the dataset \(D\) is generated conditioned on \(c\); VFSDM , another variational diffusion model where employees a different way to extract and aggregate set-information using ViT : stack all the samples on the channel dimension; sDDPM adapting ideas in Sinha et al.  without contrastive learning, where a ViT encoder splits the image in patches and processes them jointly.

**Model Settings:** The details about model settings can be found in Appendix B.

### Quantitative experiment

**VAE-based models**: To evaluate the generative properties of VAE-based models, we use the evidence lower bound (ELBO) to approximate the log marginal likelihood with 1000 importance samples (NLL). Our qualitative experiments are performed on Omniglot, DOUBLE-MNIST, MNIST, and FS-Cifar100. The outcomes of the experiment are displayed in Table 2. It is clear that VSM-CNS/VSM-SCHA can achieve significant improvements over its baseline models, proving that VSM could be a promising mechanism for few-shot generation. Additionally, by incorporating either semantic or episodic memory into CNS/SCHA-VAE, the resulting models can also achieve better performance, proving both memory types can improve the model performance of few-shot generation.

**Diffusion-based models:** As exhibited in Table 5, we employ the metrics below to assess the generative capacity of diffusion-based models, including: FID  for sample quality, sFID  to capture spatial relationships, and Precision and Recall  for measuring variety and mode coverage. From the results, VSM-Diffusion beats the other unconditional and conditional baselines on both two datasets, demonstrating the effectiveness of VSM on few-shot generation.

    &  &  &  &  \\  & NELBO & NLL & NELBO & NLL & NELBO & NLL & NELBO(pd) & NLL(pd) \\  VAE & 101.5 & 95.9 & 74.3 & 69.2 & 125.1 & 105.1 & - & - \\ NS & 96.6 & 92.4 & 67.3 & 60.2 & 118.7 & 101.2 & - & - \\ CNS & 92.9 & 89.7 & 66.5 & 54.3 & 114.1 & 90.4 & 9.79 & 9.803 \\ CNS+Semantic & 84.4 & 72.4 & 56.7 & 50.2 & 107.3 & 88.5 & 9.952 & 9.745 \\ CNS+ Episodic & 83.9 & 71.8 & 54.3 & 51.1 & 97.8 & 80.3 & 9.946 & 9.741 \\ VSM-CNS(our) & 81.1 & 68.2 & 47.8 & 40.6 & 92.9 & 77.0 & **9.872** & **9.711** \\  SCIUA-VAE & 89.4 & 85.8 & 68.1 & 53.3 & 114.7 & 88.5 & 10.364 & 10.338 \\ SCHA+Semantic & 81.5 & 66.8 & 53.7 & 48.9 & 98.5 & 77.7 & 10.317 & 10.215 \\ SCHA+ Episodic & 82.5 & 63.4 & 53.0 & 47.2 & 95.3 & 79.1 & 10.292 & 10.176 \\ VSM-SCHA(our) & **74.0** & **56.8** & **42.4** & **36.5** & **89.9** & **68.2** & 10.219 & 10.041 \\   

Table 1: Few-shot generative evaluation of VAE-based models on various datasets with the set size 5, including Omniglot, Double-Mnist, FS-Cifar100, and Mnist (trained on Omniglot and tested on Mnist.). For all datasets, we set the episodic memory size of all methods to 5 and the semantic memory size to be the same as the number of categories appearing in training data.

    &  &  \\   & FID \(\) & sFID \(\) & P \(\) & R \(\) & FID \(\) & sFID \(\) & P \(\) & R \(\) \\  DDPM & 62.84 & 28.91 & 0.58 & 0.40 & 14.02 & 27.46 & 0.71 & 0.39 \\ sDDPM & 45.50 & 29.87 & 0.54 & 0.46 & 12.87 & 26.44 & 0.72 & 0.37 \\ vDDPM & 62.58 & 27.50 & 0.58 & 0.41 & 13.01 & 26.24 & **0.73** & 0.39 \\ vFSDM & 63.73 & 28.85 & 0.58 & 0.38 & 13.52 & 27.75 & 0.71 & 0.38 \\  VSM-vFSDM(our) & **44.11** & **23.11** & **0.59** & **0.46** & **12.27** & **25.79** & 0.72 & **0.40** \\  FSDM & 35.07 & 20.95 & 0.62 & 0.53 & 10.11 & 24.58 & 0.73 & 0.39 \\ VSM-FSDM(our) & **33.21** & **18.32** & **0.68** & **0.61** & **9.25** & **23.21** & **0.77** & **0.43** \\   

Table 2: Few-shot generative evaluation of diffusion-based models on various datasets with the set size 5, including FS-Cifar100 and Celeba. (FID: Frechet score; sFID: spatial FID; P: precision; R: recall.)

### Qualitative experiment

**Few-shot image generation:** The generation results of VSM-Diffusion are exhibited in Figure 3. From the results, we can find that our memory-augmented models can generate class-specific samples through successfully extracting content information and realistic classes that are both complicated and varied. Limited by pages, additional few-shot generative experimental results on Omniglot, CelebA, and FS-Cifar100 can be found in Appendix C.2.

**Memory visualization:** To further verify the effectiveness of the proposed VSM, we conduct experiments of memory visualization here. For instance, given a new set, as shown in Figure 4(a), the images of recalled semantic memory corresponding to the class are shown in Figure 4(b), and the images of recalled episode memory are shown in Figure 4(c). The visualization results demonstrate that VSM can recall related image classes and samples to the query set in an effective way.

Figure 4: (a) Query Set; (b) Recalled blocks (categories) of semantic memory, each of which is represented by the images of corresponding category; (c) Recalled samples of episodic memory.

Figure 5: Few-shot generative evaluation of VAE-based models on various datasets with different episodic memory sizes.

    &  &  &  \\  & NELBO & NLL & NELBO & NLL & NELBO & NLL \\  W/o Episodic memory & 75.4 & 58.2 & 45.3 & 40.1 & 91.1 & 69.5 \\ W/o Frequency-based & 74.8 & 58.2 & 42.9 & 37.7 & 91.7 & 70.6 \\ 
**Combined strategy** & **74.0** & **56.7** & **42.4** & **36.5** & **89.9** & **68.2** \\   

Table 3: Ablation study on the update strategy of variational structured memory (VSM).

Figure 3: Visualization of few-shot generative samples using a VSM-Diffusion with the set size 5. The query set and generative samples on the left side are from FS-Cifar100, while those on the right side are from Celeba.

### Ablation study

**Effect of memory size:** To investigate the affect of memory size in episodic memory, we use the VSM-SCHA model as a typical example. We train a model on Omniglot data, and evaluate it with the Omniglot, DOUBLE-MNIST, and MNIST datasets for unknown classes. The size of the episodic memory is raised from 0 to 10. The results in Figure 5 show that the model performance improves with the increase of episodic memory size, further demonstrating the importance of episodic memory in few-shot generation tasks. We note that the developed variational structured memory will reduce to variational semantic memory  when the episodic memory size is adjusted to 0.

**Effect of memory update process:** We conduct two variants of VSM-SCHA to investigate the benefits of the proposed structured memory update strategy. For the first variant, its semantic memory update strategy does not consider episodic memory, denoted as _W/o Episodic memory_; For the second variant, its episodic memory update strategy does not employ a frequency-based strategy but uses a first-in, first-out queue-based memory update method, denoted as _W/o Frequency-based_. The experiment results in Table 3 can verify the effectiveness of the proposed memory update strategy.

## 6 Conclusion

In this study, we develop a novel variational structured memory module that can concurrently retain generic semantic structure about a category and specific information about a sample, the former being achieved by semantic memory and the latter being caught by episodic memory. Meanwhile, we introduce a bionic memory updating strategy for the conversion between episodic and semantic memories stored in VSM, where episodic memory can provide context information that will later be transferred and stored in semantic memory. Through incorporating VSM with few-shot latent variable models, we develop a novel hierarchical memory-augmented neural statistician (HMNS), whose generative process can be specified with a VAE or diffusion model, leading to VSM-VAE and VSM-Diffusion. Extensive experiments demonstrate that our developed VSM-VAE and VSM-Diffusion can achieve promising performance on few-shot generation tasks.