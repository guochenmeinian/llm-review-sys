# Language-Driven Interactive Traffic Trajectory Generation

Junkai Xia\({}^{1,3}\)  Chenxin Xu\({}^{1,3}\)  Qingyao Xu\({}^{1,3}\)  Yanfeng Wang\({}^{1,2}\)  Siheng Chen\({}^{1,2,3}\)

\({}^{1}\)Shanghai Jiao Tong University \({}^{2}\)Shanghai AI Laboratory

\({}^{3}\) Multi-Agent Governance & Intelligence Crew (MAGIC)

These authors contributed equally to this work.Corresponding author.

###### Abstract

Realistic trajectory generation with natural language control is pivotal for advancing autonomous vehicle technology. However, previous methods focus on individual traffic participant trajectory generation, thus failing to account for the complexity of interactive traffic dynamics. In this work, we propose InteractTraj, the first language-driven traffic trajectory generator that can generate interactive traffic trajectories. InteractTraj interprets abstract trajectory descriptions into concrete formatted interaction-aware numerical codes and learns a mapping between these formatted codes and the final interactive trajectories. To interpret language descriptions, we propose a language-to-code encoder with a novel interaction-aware encoding strategy. To produce interactive traffic trajectories, we propose a code-to-trajectory decoder with interaction-aware feature aggregation that synergizes vehicle interactions with the environmental map and the vehicle moves. Extensive experiments show our method demonstrates superior performance over previous SoTA methods, offering a more realistic generation of interactive traffic trajectories with high controllability via diverse natural language commands. Our code is available at [https://github.com/X1a-jk/InteractTraj](https://github.com/X1a-jk/InteractTraj)

## 1 Introduction

Driving simulations are increasingly vital in the development of autonomous driving . By projecting real-world scenarios into virtual environments, driving simulation enables the generation of driving data in diverse conditions at a significantly reduced cost, especially in safety-critical scenarios. Trajectory data, representing the driving behaviors of traffic vehicles, serves as a key part of the driving simulation. This paper focuses on the generation of traffic trajectories.

One of the most critical aspects of trajectory generation is _controllability_, which involves generating highly realistic trajectory data tailored to specific user needs. Several works have been proposed to prompt a controllable traffic trajectory generation. TrafficGen  enables the generation of traffic scenarios conditioned on a blank map with controllable vehicle numbers. CTG  allows users to control desired properties of trajectories using signal temporal logic at test time like reaching a goal or following a speed limit by a guide sampling in the diffusion process. However, given that these control signals are pre-defined, their flexibility is inherently limited.

With the rise of large language models, researchers have begun to use human natural language to achieve a more flexible and user-friendly control. A representative work is LCTGen , which leverages a large language model to transform text descriptions into structured representations, followed by a transformer-based decoder to generate corresponding scenarios. However, this work exclusively focuses on individual traffic participant trajectory generation, disregarding the _interactions_ between multiple trajectories. Such interactions, crucial for replicating the dynamic, involve thecomplex interplay between various participants' movements and decisions. The absence of interaction modeling causes limited controllability in trajectory generation. For instance, traffic jams, involving many vehicles, cannot be accurately generated. Yet, generating these scenarios is essential as they highlight the vehicles' capabilities to respond to real-world challenges.

To achieve more realistic and controllable trajectory generations, in this work, we propose InteractTraj, a novel generator that generates interactive traffic trajectories from natural language descriptions. The key design rationale of InteractTraj is to interpret abstract trajectory descriptions into concrete formatted interaction-aware numerical codes and to learn a mapping between these formatted codes and the final interactive trajectories. Specifically, InteractTraj consists of two modules: an LLM-based language-to-code encoder and a code-to-trajectory decoder. 1) To interpret user language commands, the language-to-code encoder utilizes a novel _interaction-aware encoding strategy_, which uses an LLM with interaction-aware prompts to convert language commands into three types of numerical codes, including interaction, vehicle and map codes. As the core to model interactive relationships of vehicles, the interaction codes consist of key factors, including relative position and relative distance. These factors are designed to be discrete to have semantic meanings that correspond to LLM and are formed in series to model the temporal continuity of interactions. 2) To produce interactive traffic trajectories, the code-to-trajectory decoder employs a novel two-step _interaction-aware aggregation strategy_ that integrates code information. This approach synergizes vehicle interactions with environmental map data, thereby using these interactions to enrich the realism and coherence of vehicle trajectories. Compared to previous work , which generates independent traffic trajectories, InteractTraj is capable of generating realistic and interactive traffic trajectories with enhanced controllability through language commands.

We conduct extensive experiments on the Waymo Open Motion Dataset(WOMD) and nuPlan and show that InteractTraj can generate realistic interactive traffic trajectories with high controllability through various natural languages. Our method achieves SoTA performance with an improvement of 15.4%/18.7% on average ADE/FDE over previous methods on WOMD, and 17.1%/20.4% on average ADE/FDE on nuPlan. Our method also achieves a more realistic generation under different user commands including vehicle interactive actions of overtaking, merging, yielding and following. We conduct user studies showing our method has \(47.5\%\) higher average user preference compared to the baseline method. We summarize our contributions as follows:

\(\) We propose InteractTraj, the first language-driven traffic trajectory generator that can generate interactive traffic trajectories. The core idea of InteractTraj is to bridge abstract trajectory descriptions and generated trajectories with formatted interaction-aware numerical codes.

\(\) We design a novel interaction interpretation mechanism with LLM in the language-to-code encoder and a two-step feature aggregation to fuse interaction information for more coherent generation in the code-to-trajectory decoder.

\(\) We conduct extensive experiments and show that InteractTraj is capable of generating realistic interactive traffic trajectories with high controllability through various natural languages.

## 2 Related Work

### Traffic Trajectory Generation

Traffic trajectory generation is crucial in intelligent transportation systems, producing all agents' trajectories in a scene from provided maps or historical data. Traditionally, rule-based methods [8; 1; 9; 2; 10; 3; 11] employed heuristic models to encode traffic rules like lane-keeping and following the leading vehicle but lack diversity and realism due to fixed rule patterns. Recently, learning-based methods [12; 13; 14; 15] have emerged to generate more realistic traffic trajectories by learning from

Figure 1: Overview of InteractTraj. InteractTraj uses a series of semantic interaction-aware numerical codes to depict interactive trajectories. An LLM-based language-to-code encoder converts language descriptions into numerical codes, which are then transformed into interactive trajectories by a code-to-trajectory decoder.

real-world data. However, these methods usually face challenges with controllability, unable to fulfill specific requirements like instructing a vehicle to turn left, and they rely on past trajectories that are expensive and difficult to obtain. There is growing interest in controllable trajectory generation [4; 6; 16; 7], focusing on customizing trajectories to meet diverse user requirements. TrafficGen  generates a specific number of vehicles and their trajectories on a blank map. CTG  uses a loss function to guide trajectory generation according to user controls. influenced by LLMs, language-driven traffic scenario generation is emerging. CTG++  employs LLM to convert user queries into a loss function for realistic, controllable generation. While CTG and CTG++ require costly past trajectories, limiting their practical deployment, LCTGen  generates scenarios purely from language descriptions using an LLM-based interpreter and a transformer-based generator. However, these methods lack interaction awareness and struggle with complex text descriptions. Our approach addresses these issues with interaction-aware code representation and refined vehicle behavior control.

### Motion Prediction

Motion prediction and trajectory generation are closely related concepts in the field of autonomous systems and robotics since both approaches aim to anticipate the future state of agents. Motion prediction models are often used as backbones to convert latent states into agent trajectories as part of the generated scenarios, allowing for the simulation of realistic traffic scenarios. Early methods [17; 18; 19] utilize various physics-based kinematic models for modeling agent behaviors and predicting trajectories. With the development of deep learning and neural networks, RNN and LSTM-based structures are applied for trajectory prediction [20; 21; 22; 23; 24] due to their proficiency in processing sequential data. To handle more complex trajectory prediction tasks where multiple agents are involved, models in recent years have also incorporated methods such as diffusion or transformer [25; 26; 27; 28] to achieve more accurate results. [29; 30; 31; 32; 33] achieve better results on multi-agent motion prediction tasks by focusing on interaction and relational reasoning. Trajectory generation facilitates the creation of realistic scenarios, acting as supplementary data for the development and evaluation of prediction models.

### Large Language Models and Their Multimodal Applications

Recent years have seen dramatic advancement in the development of Large Language Models (LLMs) [34; 35; 36; 37; 38; 39; 40] such as ChatGPT  and GPT-4 . The success of LLMs triggers a boom in multimodal tasks that require comprehensive understanding across multiple modalities, including text [42; 43; 44; 45; 46], audio [47; 48; 49; 50], motion [51; 52; 53; 54; 55] and so on. Notable examples including DALL-E  and Sora . DALL-E  treats text and image tokens as a unified data stream, generating realistic images from text input. Sora  demonstrates the ability to create long, realistic, and imaginative videos from text descriptions. In this work, we focus on language-driven trajectory generation. Inspired by , our method uses GPT-4  as the language encoder to leverage the deep traffic scene understanding and reasoning capabilities of LLMs. We design an interaction-aware code and prompt GPT-4 to convert language input into these codes, which contain detailed information about interactions, vehicles and map.

## 3 Problem Statement

Language-driven traffic trajectory generation aims to create realistic trajectories of traffic participants over a period of time according to language descriptions. Given a language description \(L\), our goal is to propose a scenario generation model \(()\) so that the generated corresponding traffic trajectories \(=(L)\) are realistic and match with the language description. Here \(=[_{1},_{2},,_{N}] ^{N T 2}\) represents the trajectory of \(N\) vehicles over \(T\) timesteps, where \(_{i}=[s_{i}^{1},s_{i}^{2},,s_{i}^{T}]^{T 2 }, i\{1,,N\}\), and \(s_{i}^{t}^{2}\) denotes the 2D positions of vehicle \(i\) at the \(t\)-th timestep.

## 4 Methodology

### Architecture Overview

InteractTraj is a language-guided interactive traffic trajectory generation framework that generates realistic vehicle trajectories based on natural language descriptions. The core idea of InteractTraj is to use a series of semantic numerical codes to depict interactive trajectories and learn a transformation between these codes and the interactive trajectories, see Figure 1 for a sketch. InteractTraj consists of two parts: an LLM-based language-to-code encoder and a code-to-trajectory decoder. The language-to-code encoder is designed to interpret language commands and turn the commands into three typesof numerical codes, including interaction codes, vehicle codes and map codes. The code-to-trajectory decoder then transforms these codes to produce interactive traffic trajectories.

Mathematically, given the language description \(L\), InteractTraj generates the traffic trajectories \(}\) by

\[,,=(L),}= (,,), \]

where \(()\) represents the language-to-code encoder and \(()\) represents the code-to-trajectory decoder. \(\) is the map codes representing the environment map information, \(\) is the vehicle codes representing the vehicle's individual driving information and \(\) is the interaction codes representing the vehicle interaction information. We illustrate the detailed structures of these codes in the following.

### Language-to-Code Encoder

The language-to-code module, \(()\), distills essential information from input natural language descriptions and transforms this information into interaction-aware numerical codes. This transformation leverages large language models, such as GPT-4 . The whole language-to-code encoder incorporates two key designs: the structure of the interaction-aware numerical codes and the tailored prompts for the large language model. The numerical codes are comprised of three components: interaction codes, vehicle codes, and map codes. To depict vehicle interactions concretely, we design the format of the interaction codes with the relative factors modeling. To interpret the abstract interaction-aware descriptions into the code format, we design prompts with interaction descriptions to assist the LLM.

**Interaction codes I.** Interaction codes encapsulate vehicle interactive relationships. The core idea is that spatial relationships and changes between vehicles significantly affect their perception and reactions, revealing their interactions. To capture high-level actions and interaction tendencies, we resample the vehicle attributes at regular intervals across \(T\) timesteps. We denote \(\) as the set of timesteps of the resampling process. To effectively model these interactive relationships, the designed interaction codes consist of two key factors, relative distance and relative direction, motivated by the representation of polar coordinates. Formally, the interaction codes are denoted by \(=[(p_{j}^{t},q_{j}^{t})]_{j\{1,,N\},t}\), where \(p_{j}^{t}\)/\(d_{j}^{t}\) is the relative direction/distance of \(j\)th vehicle with the ego interacted vehicle at the \(t\)-th sampling timestep. To enrich the interaction code with semantic meanings, we discretize the relative direction/distance. Specifically, we divide the surrounding space centered by ego vehicle into six regions: front, rear, left front, left rear, right front and right rear. The relative direction \(p_{j}^{t}\) of agent \(j\) can thus be represented by the index of the region in which agent \(j\) is located at time \(t\). The relative distance \(d_{j}^{t}\) is also discretized by dividing with a fixed interval and then rounding down. This discrete code representation with semantic meanings facilitates the use of LLM to link code values with corresponding language commands.

**Vehicle codes V.** The vehicle codes contain the information of vehicle individual driving states. To describe the vehicle driving states, the vehicle codes consist of two components on different trajectory scales: the global trend and the detailed movement. Formally, the vehicle codes are denoted by \(=[r_{i};_{i}]_{i\{1,,N\}}\), where \(r_{i}\) is the trajectory type of agent \(i\) modeling trajectory global trend and \(_{i}\) is the vehicle states of agent \(i\) modeling detailed movement. Specifically, we categorize the trajectory type into stop, straight ahead, left turn, right turn, left change lane, and right change lane. \(r_{i}\) is the category index. Trajectory states \(_{i}=[o_{i},q_{i},[v_{i}^{t}]_{t}]\), contain the initial orientation \(o_{i}\), initial position \(q_{i}\), and the discrete speeds \([v_{i}^{t}]_{t}\) of agent \(i\) at sampled timesteps.

**Map codes m.** The map codes contain the information on key map features. We adopt the representation \(^{6}\) similar to , which represents the number of lanes in each of the four

Figure 2: Sketch of interaction-aware prompt and numerical codes.

directions, the distance between ego vehicle and the intersection, and the lane index of the ego vehicle, respectively.

**LLM prompts.** Given a language description \(L\), we utilize carefully designed interaction-aware prompts to help the large language model analyze the descriptions and extract interact-related information, enabling it to generate corresponding interaction-aware numerical codes that align with the language description. The prompt mainly incorporates three key components: \(1)\) [interaction prompt] interaction prompt defines the format of interaction code, explains some key interaction events to help with the better understanding of the scenarios and informs LLM to interpret the possible interaction behaviors inferred in the descriptions and output the corresponding interaction codes \(I\) of all the vehicles involved by analyzing the vehicles' relative distance and position relationships. \(2)\) [vehicle prompt] vehicle prompt defines the format of vehicle code and explains driving rules to make the generated scenarios more realistic, such as the need to slow down when turning, etc. \(3)\) [map prompt] map prompt defines the format of map code and make LLM analyze whether intersections or roundabouts are involved and decides the number of lanes of all directions according to the number of vehicles and their orientations to fill out the map codes. Figure 2 presents a sketch of LLM prompts and an example of numerical codes and see the appendix for a full prompt.

### Code-to-Trajectory Decoder

With the interaction-aware codes from the encoder, the code-to-trajectory decoder \(()\) generates vehicle trajectories by aggregating and decoding information between vehicles and interactions. In the decoder, we propose a key design of two-step interaction-aware feature aggregation, which synergizes vehicle interactions with environmental map data, thereby using these interactions to enrich the realism and coherence of vehicle trajectories.

Given the map codes \(\), the vehicle codes \(\) and interaction codes \(\) from the encoder, the overall decoding process can be formulated as

\[_{},_{},_{}= _{}(,,),\ }_{}=_{}(_{}, _{},_{}),\ }=_{ }(}_{}), \]

where \(_{}()\) denotes a feature extraction module, \(_{}()\) denotes an attention-based feature aggregation module, \(_{}()\) denotes the generation head module for obtaining vehicle attributes and trajectories, and \(_{},_{},_{}\) are the map lane features, vehicle features and the interaction features, respectively. \(}_{}\) denotes the fused features for vehicles and \(}\) is the generated trajectory.

**Feature extraction \(_{}()\).** The feature extraction module \(_{}()\) transforms the numerical codes into initial embeddings for subsequent calculation. For map codes, we retrieve a map \(M\) that best fits map code \(\) from the pre-defined map dataset, which is the same as . The map \(M^{N_{L} N_{A}}\) consisting of \(N_{L}\) lanes with their \(N_{A}\) attributes, is then passed to the multi-context gating(MCG) blocks  obtaining map features \(_{}^{N_{L} D_{L}}\) by aggregating neighboring lane information, where \(D_{L}\) is the dimension of each lane feature. For the vehicle codes and interaction codes, we apply MLPs with a position encoding layer for each to obtain their higher-dimensional latent features, that is, \(_{}=_{}(()) ^{N D_{V}}\), \(_{}=_{}(()) ^{N D_{I}}\), where \(()\) is the position encoding function, \(D_{V}\) and \(D_{I}\) are the dimensions of extracted vehicle and interaction features.

**Feature aggregation \(_{}()\).** The feature aggregation module aims to fuse the map features and interaction features into vehicle features for subsequent trajectory generation. Based on the intuition that the vehicle interactions are constrained by the road structure and the vehicle states are affected by both the road structure and vehicle interactions, we apply a two-step feature aggregation strategy. First,

Figure 3: The architecture of code-to-trajectory decoder. The decoder generates vehicle trajectories by fusing and decoding information between vehicles and interactions.

we fuse the map feature into the interaction feature and the vehicle feature respectively by multi-head cross-attention operations, that is, \(_{}^{}=_{}(_{}, _{},_{})\), \(_{}^{}=_{}(_{}, _{},_{})\), where \((q,k,v)\) denotes the multi-head cross-attention functions with query \(q\), key \(k\), value \(v\), \(_{}^{}\) and \(_{}^{}\) are the interaction features and the vehicle features after aggregation. Second, we fuse the interaction feature into the vehicle feature to obtain the final vehicle feature, that is, \(}_{}=_{}(_{} ^{},_{}^{},_{}^{})\). The final vehicle feature contains both the interaction and map information, which can be manipulated for further trajectory generation.

**Generation head \(_{}()\).** The generation head aims to generate vehicle' states and trajectories based on vehicle features. For agent \(i\) with agent feature \(}_{,}\) and the trajectory type \(r_{i}\) in the vehicle codes, we generate its trajectory positions \(_{i}\) through a series of MLP heads. For different trajectory types, we assign different MLP heads. Formally, the generation process is formulated as

\[}_{i}=_{,r_{i}}(}_{ ,}), \]

where \(_{,r_{i}}\) denotes the assigned \(r_{i}\)th heading MLP. We finally assemble all the trajectories \(}=[}_{1},}_{2},, }_{N}]\) together with the map \(M\) as output for the scenario generation.

### Training

**Generating training samples.** Due to the lack of data directly matching linguistic descriptions with traffic scenarios, we cannot directly optimize the model under ground-truth trajectory supervision using language inputs. As an alternative, we extract map, vehicle, and interaction codes directly from ground-truth trajectories to train the decoder's scenario reduction capability, During the training process, for a ground-truth scenario \(S\) derived from real-world datasets, we re-generate the scene by

\[,,=(),\ }= (,,), \]

where \(()\) extracts information from the ground-truth vehicle trajectories to fulfill the codes, including the obtainment and discretization of vehicle speeds, their positions and distances relative to the ego vehicle, and the classification of their trajectory types. The specific computational rules will be mentioned in the appendix. We thus train the decoder \(()\) by minimizing the gap between \(S\) and \(\).

**Loss.** We apply a MSE loss \(_{}()\) to minimize differences between generated and ground-truth vehicle trajectories. Furthermore, to enhance the network's sensitivity to trajectory interactions, we additionally supervise the relative distances with the ego vehicle among vehicle trajectories with another MSE loss \(_{}()\). For the \(i\)th vehicle, the relative distance at last timestep is \(_{i}=_{i}^{T}-_{1}^{T}\). Formally, the final loss of InteractTraj is presented as

\[=(_{i=1}^{N}_{}(_{i},}_{i})+_{i=1}^{N}_{}( _{i},}_{i})). \]

### Discussion

Compared to previous representative traffic trajectory generation method, including CTG , CTG++ , TrafficGen  and LCTGen , our method is the first language-conditioned interactive trajectory generation method. (1) At the task level, CTG and CTG++ generate traffic trajectories within the need of vehicles' past trajectory observations. The necessity of collecting past trajectories significantly increases the data generation costs, imposing an extra burden. TrafficGen generates traffic trajectories by only taking a map as input to produce a scenario, resulting in a lack of controllability over the generated trajectories. LCTGen and our methods are specifically designed to generate traffic trajectories based on language conditions, which not only achieves high controllability but also reduces dependency on extensive data sets. (2) Under the same task, compared to LCTGen, our technical novelty comes from two aspects. First and foremost, we propose the interaction codes, corresponding LLM prompts, and interaction-aware feature aggregation which serve as the key to generating interaction-aware traffic trajectories. In contrast, LCTGen does not account for vehicle interactions during trajectory generation. Second, within the vehicle codes, we incorporate a mixed-scale design that both addresses the global type and the detailed movement of vehicle trajectory, which allows the generated trajectories to align with high-level intentions as well as precise positional changes. Conversely, LCTGen only considers the local detailed movement, leading to potential discrepancies between the language descriptions and generation at the high-level trend, such as receiving descriptions to turn left but generating a right turn.

## 5 Experiments

### Dataset and Baseline

We use two datasets, Waymo Open Motion Dataset (WOMD) [59; 60] and nuPlan , which both provide real-world vehicle trajectories and corresponding lane maps. We compare our method against two state-of-the-art controllable trajectory generation baselines, TrafficGen  and LCTGen . Please refer to the appendix for details on the datasets and the choice of baselines.

### Experimental Setup

In the language-to-code encoder, we sample the vehicles' trajectories at 1-second (10 timesteps) intervals to get a \(||=5\) timesteps set. In the code-to-trajectory decoder, the vehicle features \(D_{V}\) and interaction features \(D_{I}\) are set to \(256\). During the training process, we train the decoder using the AdamW optimizer  with an initial learning rate of \(3^{-4}\). See more details in the appendix.

### Evaluation Metric

Given ground-truth trajectories, we quantify the realism of generated trajectories with 6 metrics: 1) mean average displacement error(mADE); 2) minimum average displacement error(minADE); 3) mean final displacement error(mFDE); 4) minimum final displacement error(minFDE); 5) scenario collision rate(SCR); 6) Hausdorff distance(HD). Detailed formulations of these metrics are provided in the appendix.

### Reconstruction-based Evaluation

Since the dataset contains only trajectories and not language-trajectory pairs, we evaluate our methods and baselines quantitatively through a reconstruction approach. For all methods, we generate conditional codes or inputs directly from the ground-truth trajectory instead of the LLM, and then reconstruct the trajectories to assess alignment with the input conditions.

**Quantitative results on all scenarios.** We first evaluate our generated trajectories by comparing them to ground-truth trajectories on the whole dataset. Table 1 compares the performance of InteractTraj with two baseline methods on reconstruction. Since previous methods lack interaction-aware input design, we add one more ablated version of InteractTraj without the interaction code, to have a comparison with the same input information, noted as InteractTraj(w/o \(\)). We see that i) our method significantly outperforms previous methods across all the metrics, indicating it generates more realistic

   Dataset & Method & mADE \(\) & minADE \(\) & mFDE \(\) & minFDE \(\) & SCR \(\) & HD \(\) \\   & TrafficGen & 9.531 & 1.440 & 20.106 & 3.690 & 0.086 & 5.733 \\  & LCTGen & 1.262 & 0.224 & 2.696 & 0.463 & 0.072 & 1.295 \\  & InteractTraj(w/o I) & 1.205 & 0.207 & 2.479 & 0.346 & 0.090 & 1.210 \\  & **InteractTraj** & **1.067** & **0.181** & **2.190** & **0.320** & **0.070** & **1.076** \\   & TrafficGen & 9.418 & 1.416 & 19.686 & 3.627 & 0.082 & 5.874 \\  & LCTGen & 1.161 & 0.218 & 2.497 & 0.448 & 0.074 & 1.301 \\   & InteractTraj(w/o I) & 1.108 & 0.181 & 2.277 & 0.323 & 0.070 & 1.150 \\   & **InteractTraj** & **0.962** & **0.160** & **1.987** & **0.321** & **0.067** & **1.129** \\   

Table 1: Evaluation on trajectory generation realism under WOMD and nuPlan datasets. \(\) indicates lower is better. InteractTraj significantly improves trajectory realism.

Figure 4: Comparison of model performances under different settings on WOMD. Lower is better. InteractTraj generates more realistic interactive trajectories for different types. ST: straight forward, LT: left turn, RT: right turn, LC: left lane change, RC: right lane change and AVG: average performance.

scenarios with vehicle interactions. Specifically, our method reduces the mADE/mFDE/HD by 15.4%/18.7%/16.9% compared to SoTA methods; ii) The ablated InteractTraj(w/o **I**) still outperforms previous models, showing the effectiveness of our vehicle code design.

**Quantitative results on scenarios on different interaction types.** To evaluate the performance of model generation on scenarios with trajectory interaction, we test the model on the representative interactive scenarios. The scenarios are mainly categorized into four types according to vehicle interaction: overtaking, converging, yielding and following. Figure 3(a) shows the method comparison on all types of interactive scenarios with LCTGen. We see that for all types of interactions, InteractTraj significantly reduces the mADE and mFDE, showing a powerful capability to generate realistic interactive trajectories by interaction-aware coding design.

**Quantitative results on scenarios on different trajectory types.** To evaluate the performance of model generation on different individual driving trajectories, we categorize trajectories of the test set into six types according to individual actions: straight, stop, turn left, turn right, left change lanes, left, right change lanes, see detailed rules in the appendix. According to individual action types, we divide the test set and report the average reconstruction performance on every set. Figure 3(b) shows that InteractTraj's generation results are closer to the ground truth than LCTGen, reflecting we generate trajectories more aligned with language descriptions across different individual driving actions.

It is important to note that the ultimate goal of our method is to generate traffic trajectories from language commands. Previous methods  exhibit limitations in that they fail to address the interaction information encoded within languages. Consequently, in the reconstruction-based evaluation, these methods inherently lack interaction information in their inputs. In contrast, our method is capable of incorporating interaction during the generation process, which represents a significant advantage. As a result, our inputs for reconstruction-based evaluation contain more comprehensive information, enabling more realistic and effective trajectory generation.

### Language-Conditioned Evaluation

In this section, we compare end-to-end our method with previous methods by analyzing trajectories generated from language descriptions. Given the absence of specific ground-truth trajectories for certain language commands, we employ qualitative evaluation and user studies for assessment.

**Qualitative results.** We compare our model to LCTGen, which also transforms language input into traffic scenarios. We evaluate our methods with that of baseline methods qualitatively given

Figure 5: Comparison of model performances under different interaction types. InteractTraj generates trajectories that better align with language descriptions by performing the right vehicle interactions.

Figure 6: Results of the user study for overall and interaction performances.

language commands containing different interaction descriptions. Figure 5 provides visualizations of representative user language commands including four types of interaction: vehicle overtaking, vehicle merging, vehicle yielding, and vehicle following. We see that compared to previous work, the scenarios generated by InteractTraj better align with language descriptions with the help of interaction-aware code representation, while the previous method can not perform the corresponding interactive action since it generates trajectories of each agent independently.

**Generalisation capability analysis.** Our model demonstrates the ability to generate compliant scenarios even when handling less common or emergent interaction types as shown in the left part of Figure 7. We test interaction scenarios not mentioned explicitly in the prompt, including uncommon cases of parallel driving (Figure 6(a)), platooning (Figure 6(b)), and pulling over (Figure 6(c)). The results show that our method can effectively interpret and translate these less common interaction types, producing scenarios that align with expected behaviors without retraining. This is primarily due to the robust generalization capacity of the LLM used in our encoding process. The decoding process is also equipped with strong generalization abilities due to extensive training with massive numerical codes, which would translate these codes into trajectories and generate compliant scenarios.

In addressing the potential ambiguities in language descriptions, our approach leverages the reasoning capabilities of LLM without introducing additional prioritized proximity. Ambiguities typically arise in two main forms: unclear references to objects and contradictions within the language instructions.

1) For cases where the object reference is ambiguous, the LLM interprets the linguistic input and converts it into numerical codes that correspond to one of the plausible meanings. As illustrated in Figure 6(d), the LLM assigns the label "the car behind" to a randomly selected vehicle. However, when the description is more specific, such as "the car behind ego car" (Figure 6(e)), the LLM accurately resolves the reference and appropriately handles the description.

2) For cases where there are self-contradictory language requirements, the LLM generates scenarios that partially align with the instructions. For instance, as shown in Figure 6(f), the instruction presents an inherent contradiction. The LLM resolves this by prioritizing one part of the instruction while disregarding the other. To better tackle language ambiguity, a potential solution involves introducing LLM-human interaction to iteratively verify language descriptions.

**Controllability analysis.** In Figure 8, it is evident that each generated scenario adheres to the provided linguistic descriptions when there are variations in the details. This highlights the strong controllability of InteractTraj in accurately manipulating vehicle behaviors, ensuring that the generated scenarios align with user-specified control commands. The precision is achieved through the LLM's robustness in understanding and applying detailed instructions based on different linguistic inputs.

**User study.** We conduct two user studies on WOMD to qualitatively assess the language-conditioned traffic scenario generation capabilities of InteractTraj from two perspectives: 1) overall generation performance and 2) vehicle interaction performance. GPT-4 is used to generate descriptions of different interaction types as input language descriptions, see appendix for the details.

In the first user study, each user is given forty language commands and corresponding trajectories generated by models and is asked to choose the one trajectory that better fits the language description. Figure 5(a) shows the results of users' preferences for scenarios generated by LCTGen and InteractTraj. We see that i) for each interaction type, significantly more users prefer scenarios generated by InteractTraj over those produced by LCTGen; ii) on average, \(73.7\%\) responses are more favorable to the scenarios generated by InteractTraj, and our model achieves at least \(66.9\%\) support on all

Figure 7: Visual analysis for model’s performance when dealing with less common interaction types and language ambiguities.

sub-categories. This reflects that InteractTraj has a stronger capability at generating interactive trajectories than LCTGen, and excels in representing interaction aspects of language descriptions.

The second user study contains fifty questions covering different interaction types, and users are asked to answer whether the scenarios generated fulfill the corresponding textual descriptions. The results are shown in Figure 5(b). We see that i) for each interaction type, significantly more users consider the scenarios generated by InteractTraj to fulfill the requirements given by language descriptions; ii) on average, \(72.4\%\) positive responses consider that InteractTraj generates scenarios with required interactions, while LCTGen only have \(31.5\%\) positive responses in average. This reflects that InteractTraj effectively extracts the interaction information in the descriptions, and generates sufficiently satisfying traffic scenarios.

### Ablation Study

**Effect of proposed code and network design.** We conduct the ablation study based on the reconstruction evaluation to evaluate the effectiveness of proposed designs, including a) the addition of whole interaction codes (IC); b) the relative distance in interaction codes (RD); c) the relative position in interaction codes (RP); d) the relative distance loss \(_{}\). Table 2 presents the results. We see that all designs are beneficial to a more realistic trajectory generation.

**Effect of the setting of hyper-parameters.** We conduct an ablation study of the granularity of the discretization of the relative distances and relative positions, specifically including e), f) the interval gap used for discretizing relative distances; g), h) the number of areas used for discretizing relative distances, as shown in Table 3. We see that our current parameter choices achieve the best results.

## 6 Conclusion

We propose InteractTraj, a novel interaction-aware language-guided traffic scenario generation model. Our core idea is to convert language descriptions into multi-level codes and generate trajectories by attention-based information aggregation. Experiments show that InteractTraj effectively reproduces real-life scenario distribution and generates scenarios aligned with language description.

**Limitations and future work.** This work focuses on generating trajectories of only vehicles and the generation of maps is limited by the map library. In the future, we plan to extend the work to more types of traffic participants and more flexible map generation. We also plan to apply the generated traffic scenarios to the training of autonomous driving systems by expanding the motion dataset.

## 7 Acknowledgment

This research is supported by NSFC under Grant 62171276 and the Science and Technology Commission of Shanghai Municipal under Grant 21511100900, 22511106101, and 22DZ2229005. Special thanks to Lightwheel AI for the support.

  Model & IC & RD & RP & \(_{}\) & mADE \(\) & mFDE \(\) & SCR \(\) \\  (a) & & ✓ & ✓ & ✓ & 1.205 & 2.479 & 0.346 \\ (b) & ✓ & & ✓ & ✓ & 1.167 & 2.442 & 0.084 \\ (c) & ✓ & ✓ & & ✓ & 1.194 & 2.475 & 0.080 \\ (d) & ✓ & ✓ & ✓ & & 1.165 & 2.446 & 0.080 \\ 
**Ours** & ✓ & ✓ & ✓ & ✓ & **1.067** & **2.190** & **0.070** \\  

Table 2: Ablation study on proposed code and network designs evaluated on WOMD. All designs are beneficial.

Figure 8: Visualization results for model’s controllability

  Model & Gap & Areas & mADE \(\) & mFDE \(\) & SCR \(\) \\  (e) & 10 & 6 & 1.087 & 2.228 & 0.074 \\ (f) & 20 & 6 & 1.117 & 2.299 & 0.070 \\ (g) & 15 & 4 & 1.237 & 2.810 & 0.071 \\ (h) & 15 & 8 & 1.069 & 2.190 & 0.071 \\ 
**Ours** & 15 & 6 & **1.067** & **2.190** & **0.070** \\  

Table 3: Ablation study on the granularity of the discretization of the interaction codes on WOMD.