# MAG-GNN: Reinforcement Learning Boosted Graph Neural Network

Lecheng Kong\({}^{1}\)  Jiarui Feng\({}^{1}\)  Hao Liu\({}^{1}\)  Dacheng Tao\({}^{2}\)

Yixin Chen\({}^{1}\)  Muhan Zhang\({}^{3}\)

{jerry.kong, feng.jiarui, liuhao, ychen25}@wustl.edu,

dacheng.tao@gmail.com, muhan@pku.edu.cn

\({}^{1}\)Washington University in St. Louis \({}^{2}\)JD Explore Academy \({}^{3}\)Peking University

###### Abstract

While Graph Neural Networks (GNNs) recently became powerful tools in graph learning tasks, considerable efforts have been spent on improving GNNs' structural encoding ability. A particular line of work proposed subgraph GNNs that use subgraph information to improve GNNs' expressivity and achieved great success. However, such effectivity sacrifices the efficiency of GNNs by enumerating all possible subgraphs. In this paper, we analyze the necessity of complete subgraph enumeration and show that a model can achieve a comparable level of expressivity by considering a small subset of the subgraphs. We then formulate the identification of the optimal subset as a combinatorial optimization problem and propose Magnetic Graph Neural Network (MAG-GNN), a reinforcement learning (RL) boosted GNN, to solve the problem. Starting with a candidate subgraph set, MAG-GNN employs an RL agent to iteratively update the subgraphs to locate the most expressive set for prediction. This reduces the exponential complexity of subgraph enumeration to the constant complexity of a subgraph search algorithm while keeping good expressivity. We conduct extensive experiments on many datasets, showing that MAG-GNN achieves competitive performance to state-of-the-art methods and even outperforms many subgraph GNNs. We also demonstrate that MAG-GNN effectively reduces the running time of subgraph GNNs.

## 1 Introduction

Recent advances in Graph Neural Networks (GNNs) greatly assist the rapid development of many areas, including drug discovery , recommender systems , and autonomous driving . The power of GNNs has primarily been attributed to their Message-Passing Paradigm . Message-Passing Paradigm simulates a 1-dimensional Weisfeiler-Lehman (1-WL) algorithm for graph isomorphism testing. Such a simulation allows GNN to encode rich structural information. In many fields, structural information is crucial to determine the properties of a graph.

However, as Xu _et al._ pointed out, GNN's structure encoding capability, or its expressivity, is also upper-bounded by the 1-WL test. Specifically, a message-passing neural network (MPNN) cannot recognize many substructures like cycles and paths and fails to properly learn and distinguish regular graphs. Meanwhile, these substructures are significant in areas including chemistry and biology. To overcome this limitation, considerable effort was spent on investigating more-expressive GNNs. A famous line of work is _subgraph GNNs_. Subgraph GNNs extract rooted subgraphs around every node in the graph and apply MPNN onto the subgraphs to obtain subgraph representations. The subgraph representations are summarized to form the final representation of the graph. Such an approach is theoretically proved to be more expressive than MPNN and achieved superior empirical results. Later work found that subgraph GNNs are still bounded by the 3-dimensional WL test (3-WL) .

higher expressivity? For example, an MPNN fails to distinguish graphs A and B in Figure 1, as they are 2-regular graphs with identical 1-hop subtrees. Meanwhile, a subgraph GNN will see different subgraphs around nodes in the two graphs. These subgraphs are distinguishable by MPNN, allowing a subgraph GNN to differentiate between graphs A and B. However, we can observe that many subgraphs from the same graph are identical. Specifically, graph A has two types of subgraphs, while graph B only has triangle subgraphs. As a result, locating a non-triangle subgraph in the top graph enables us to run MPNN once on it to discern the difference between the two graphs. On the contrary, a subgraph GNN takes eight extra MPNN runs for the remaining nodes. This graph pair shows that we can obtain discriminating power equal to that of a subgraph GNN without enumerating all subgraphs. We also include advanced examples with more complex structures in Section 3.

Therefore, we propose Magnetic Graph Neural Network (MAG-GNN), a reinforcement learning (RL) based method, to leverage this property and locate the discriminative subgraphs effectively. Specifically, we start with a candidate set of subgraphs randomly selected from all rooted subgraphs. The root node features of each subgraph are initialized uniquely. In every step, each target subgraph in the candidate set is substituted by a new subgraph with more distinguishing power. MAG-GNN achieves this by mapping each target subgraph to a Q-Table, representing the expected reward of replacing the target subgraph with another potential subgraph. It then selects the subgraph that maximizes the reward. MAG-GNN repeats the process until it identifies the set of subgraphs with the highest distinguishing power. The resulting subgraph set is then passed to a prediction GNN for downstream tasks. MAG-GNN reduces subgraph GNN's exponentially complex enumeration procedure to an RL searching process with constant steps. This potently constrains the computational cost while keeping the expressivity.

We conduct extensive experiments on synthetic and real-world graph datasets and show that MAG-GNN achieves competitive performance to state-of-the-art (SOTA) methods and even outperforms subgraph GNNs on many datasets with a shorter runtime. Our work shows that partial subgraph information is sufficient for good expressivity, and MAG-GNN smartly locates expressive subgraphs and achieves the same goal with better efficiency.

## 2 Preliminaries

A graph can be represented as \(G=\{V,E,X\}\), where \(V\) is the set of nodes and \(E V V\) is the set of edges. Let \(V(G)\) and \(E(G)\) represent the node and edge sets of \(G\), respectively. Nodes are associated with features \(X=\{_{v}| v V\}\). An MPNN \(g\) can be decomposed into \(T\) layers of COMBINE and AGGREGATE functions. Each layer uses the COMBINE function to update the current node embedding from its previous embedding and the AGGREGATE function to process the node's neighbor embeddings. Formally,

\[_{v}^{(t)}=^{(t)}(\{\{_{u}^{(t-1)},u(v)\}\}),_{v}^{(t)}=^{(t)}(_{v}^{(t)},_ {v}^{(t-1)}) \]

where \(_{v}^{(t)}\) is the node representation after \(t\) iterations, \(_{v}^{(0)}=_{v}\), \((v)\) is the set of direct neighbors of \(v\), \(_{u}^{(t)}\) is the message embedding. \(_{v}^{(T)}\) is used to form node, edge, and graph-level representations. We use \(H=g(G)\) to denote the generated node embeddings of MPNN. MPNN's variants differ mainly by their AGGREGATE and COMBINE functions but are all bounded by 1-WL in expressivity.

This paper adopts the following formulation for subgraph GNNs. For a graph \(G\), a subgraph GNN first enumerates all \(k\)-order node tuples \(\{| V^{k}(G)\}\) and creates \(|V^{k}(G)|\) copies of the graph. A

Figure 1: Comparison of two simple graphs.

graph associated with node tuple \(\) is represented by \(G()\). Node-rooted subgraph GNNs adopt a 1-order policy and have \(O(V(G))\) graphs; edge-rooted subgraph GNNs adopt a 2-order policy and have \(O(V^{2}(G))\) graphs. Note that we are not taking exact subgraphs here, so we need to mark the node tuples on the copied graphs to maintain the subgraph effect. Specifically,

\[[X()]_{l,p}=c^{+}&=[]_{j}$ and $p=j$}\\ c^{-}& V^{k}(G), \]

\(X()^{|V| k}\) and \(G()=\{V,E,X X()\}\), where \(\) means row-wise concatenation. We use square brackets to index into a sequence. All entries in \(X()\) are labeled as \(c^{-}\) except those appearing at corresponding positions of the node tuple. An MPNN \(g\) is applied to every graph, and we use a pooling function to obtain the collective embedding of the graph:

\[f_{s}(G)=R^{(P)}(\{g(G())| V^{k}(G)\}), P\{G,N\}. \]

\(f_{s}(G)\) can be a vector of graph representation if \(R^{(P)}\) is a graph-level pooling function (\(P\) equals \(G\)) or a matrix of node representations if \(R^{(P)}\) is node-level (\(P\) equals \(N\)). This essentially implements \(k\)-dimensional ordered subgraph GNN (\(k\)-OSAN) defined in  and captures most of the popular subgraph GNNs, including NGNN and ID-GNN. Furthermore, the expressivity of subgraph GNNs increases with larger values of \(k\). Since node tuples, node-marked graphs, and subgraphs refer to the same thing, we use these terms interchangeably.

**The Weisfeiler-Lehman hierarchy (WL hierarchy).** The \(k\)-dimensional Weisfeiler-Lehman algorithm is vital in graph isomorphism testing. Earlier work established the hierarchy where the \((k+1)\)-WL test is more expressive than the \(k\)-WL test . Xu _et al._ and Morris _et al._ connected GNN expressivity to the WL test and proved that MPNN is bounded by the 1-WL test. Later work discovered that all node-rooted subgraphs are bounded by 3-WL expressivity , which cannot identify strongly regular graphs and structures like 4-cycles. Qian _et al._ introduced \(k\)-dimensional ordered-subgraph WL (\(k\)-OSWL) hierarchy which is comparable to the \(k\)-WL test.

**Deep Q-learning (DQN).** DQN  is a robust RL framework that uses a deep neural network to approximate the Q-values, representing the expected rewards for a specific action in a given state. Accumulating sufficient experience with the environment, DQN can make decisions in intricate state spaces. For a detailed introduction to DQN, please refer to Appendix B.

## 3 Motivation

Figure 2 shows that while an MPNN encodes rooted subtrees, a subgraph GNN encodes rooted subgraphs around each node. This allows subgraph GNN to differentiate more graphs at the cost of \(O(|V|)\) MPNN runs. Meanwhile, subgraph GNNs are still bounded by 3-WL tests. Hence, we may need at least 2-node-tuple-rooted (e.g., edge-rooted) subgraph GNNs, requiring \(O(|V^{2}|)\) MPNN runs to obtain better expressivity. In fact, the required complexity of subgraph GNNs to break beyond \(k\)-WL expressivity grows exponentially with \(k\). The high computational cost of high expressivity models prevents them from being widely applied to real-world datasets. A natural question is, _can we consider only a small subset of all the subgraphs to obtain similar expressivity_, just like in Figure 2, where one subgraph is as powerful as the collective information of all subgraphs? This leads us to the following experiment.

We focus on the SR25 dataset. It contains 15 different strongly-regular graphs with the same configuration, each of 25 nodes. The goal is to do multi-class classification to distinguish all pairs of graphs. Since node-rooted subgraph GNNs are upper-bounded by 3-WL and 3-WL cannot distinguish any strongly regular graphs with the same configuration, node-rooted subgraph GNNs will generate identical representations for the 15 graphs while performing 25 MPNN runs each. 2-node-tuple subgraph GNNs have expressivity beyond 3-WL and can distinguish any pair of graphs from the dataset, but it takes 625 MPNN runs.

Figure 2: Sorted scores.

To test if every subgraph is required, we train an MPNN on _randomly sampled_ 2-node-marked graphs to minimize the expected loss to label \(y\) of the unmarked graph \(G\),

\[_{g_{p}}_{}[((f_{r}(G,)),y)],  f_{r}(G,)=R^{(G)}(g_{p}(G())), V^{2}(G), \]

where \(\) is the loss function, MLP is a multi-layer perceptron, \(g_{p}\) is an MPNN, and \(R^{(G)}\) pools the node representations to graph representations. Unlike 2-node-tuple-rooted subgraph GNNs that run the MPNN \(|V^{2}|\) times for each graph, this model runs the MPNN exactly once. During testing, for each of the 15 graphs, we randomly sample one 2-node-marked graph for classification. We perform ten independent tests, and the average test accuracy is 66.8%. Using 2-node-marked graphs, with only one GNN run, it already outperforms node-rooted subgraph GNNs that fail on this dataset. More interestingly, for each graph \(G\), we can sort the classification score of its \(|V^{2}|\) possible node-marked graphs and plot them in Figure 2 (C14 and C15 are the plots for 14-th and 15-th graphs in the dataset). Note that the horizontal axis is not the number of subgraphs; it is the index of subgraphs after sorting by their _individual_ classification scores. We see that each original graph has many marked graphs with a classification score close to one. That means even in one of the most difficult datasets, we still can find particular node-marked graphs that uniquely distinguish the original graph from others. Moreover, unlike the example in Figure 1 with only two types of subgraphs, these marked graphs fall into many different isomorphism groups, meaning that the same observation holds in more complex graphs and can be applied to a wide range of graph classes. We prove that such a phenomenon exists in most regular graphs, which cannot be distinguished by MPNNs (proof in Appendix A).

**Theorem 1**.: _Let \(G_{1}\) and \(G_{2}\) be two graphs uniformly sampled from all \(n\)-node, \(r\)-regular graphs where \(3 r<\). Given an injective pooling function \(R^{(G)}\) and an MPNN \(g_{p}\) of 1-WL expressivity, with a probability of at least \(1-o(1)\), there exists a node (tuple) \( V(G)\) whose corresponding node marked graph's embedding, \(f_{r}(G_{1},)\), is different from any node marked graph's embedding in \(G_{2}\)._

These observations show that by finding discriminative subgraphs effectively, we only need to apply MPNN to a much smaller subset of the large complete subgraph set to get a close level of expressivity.

## 4 Magnetic graph neural network

We formulate the problem of finding the most discriminative subgraphs as a combinatorial optimization problem. Given a budget of \(m\) as the number of subgraphs, \(k\) as the order of node tuples, and \(g_{p}\) an MPNN that embeds individual subgraphs, we minimize the following individual loss to graph \(G\),

\[_{U=(_{1},...,_{m})(V^{k}(G))^{m}} ((f_{p}(G,U)),) \] \[f_{p}(G,U)=R^{(P)}(\{g_{p}(G())| U\}),\]

Note that this formulation resembles that of subgraph GNNs in Equation (3); we are only substituting \(V^{k}\) with \(U\) to reduce the number of MPNN runs. Witnessing the great success of deep RL in combinatorial optimization, we adopt Deep Q-learning (DQN) to our setting. We introduce each component of our DQN framework as follows.

**State Space:** For graph \(G\), a state is \(m=|U|\) node tuples, their corresponding node-marked graphs, and a \(m\)-by-\(w\) matrix \(W\) to record the state of \(m\) node tuples. Our framework should generalize to arbitrary graphs. Hence, a state \(s\) is defined as,

\[s=(G,U,W)=(G,(_{1},...,_{m}),W),s S=(^{k})^{m}(^{m w}) \]

\(S\) is the state space, \(\) is the set of all graphs, and \(^{k}\) is the set of all possible \(k\) node tuples of \(\). To generate the initial state during training, we sample one graph \(G\) from the training set and randomly sample \(m\) node tuples from \(V^{k}(G)\). The state matrix \(W\) is initialized to \(\). The expressivity grows as \(k\) grows. Generally, MAG-GNN with larger \(k\) produces more unique graph embeddings, which is harder to train but might require smaller \(m\) and fewer RL steps to represent the graph, leading to better inference time. However, for some datasets, such expressivity is excessive and poses great challenges to training. A smaller \(k\) can reduce the sample space and stabilize training in this case.

**Action Space:** We define one RL agent action as selecting one index from one node tuple and replacing the node on that index with another node in the graph. This replaces the node-markedgraph corresponding to the original node tuple with the one corresponding to the modified node tuple. Specifically, an action \(a_{i,j,l}\) on state \(s=(G,U,W)\) does the following on \(U\):

\[U^{}=a_{i,j,l}(U)=(_{1}...,_{i-1},v^{}_{i},_{i+1},..._{m}),^{}_{i}=([_{i}]_{1},...,[_{i}]_{j-1},v_{l}, [_{i}]_{j+1},...[_{i}]_{k}) \]

The agent selects a target node tuple \(_{i}\), whose \(j\)-th node is replaced with node \(v_{l} V\). \(W\) is then updated by an arbitrary state update function \(W^{}=f_{W}(s,U^{})\) depending on the old state and new node tuples. The update function \(f_{W}\) is not necessarily trainable (e.g., It can simply be a pooling function on embeddings of the marked nodes over states). The next state is \(s^{}=(G,U^{},W^{})\). The action space is then \(A=[m][k]\). Actions only change the node tuple while keeping the graph structure, and the state matrix serves as a tracker of past states and actions. Unlike stochastic RL systems, our RL actions have deterministic outcomes.

The intuition behind the design of the action space is that it limits the number of actions for each node tuple to \(O(m|V|k)\), which is linear in the number of nodes, and \(k\) is usually small (\(k=2\) is already more expressive than most subgraph GNNs). We can further reduce the action space to \(O(|V|k)\) if the agent does not need to select the update target but uses a Q-network to do Equation (7) on a given \(_{i}\). In such a case, we either sequentially or simultaneously update all node tuples. Since the agent learns to be stationary when a node tuple should not be updated, we do not lose the power of our agent by the reduction. The overall action space design allows efficient computation of Q-values. We include a detailed discussion on the action space and alternative designs in Appendix C.1.

**Reward:** In Section 3, we show that a proper node-marked graph significantly boosts the expressivity. Hence, an optimal reward choice is the increased expressivity from the action. However, expressivity is itself vaguely defined, and we can hardly quantify it. Instead, since the relevant improvement in expressivity should affect the objective value, we choose the objective value improvement as the instant reward. Specifically, let \(s=(G,U,W)\) be the current state and let \(s^{}=(G,U^{},W^{})=a(s)\) be the outcome state of action \(a\), the reward \(r\) is

\[r(s,a,s^{})=((f_{p}(G,U)),)-( {MLP}(f_{p}(G,U^{})),) \]

This reward correlates the action directly with the objective function, allowing our RL agent to be task-dependent and more flexible for different levels of tasks.

**Q-Network:** Because our state includes graphs, we require an equivariant Q-network to output consistent Q-tables for actions. Hence, we choose MPNN to parameterize the Q-network. Specifically, for current state \(s=(G,U,W)\) and the target node tuple \( U\), we have the Q-table as,

\[[Q(s,)]_{l}=([g_{rl}(G())]_{l}_{ U}R^ {(G)}(g_{rl}(G())) R^{(W)}(W)) \]

Row \(l\) in the Q-table is computed by the embedding of node \(v_{l}\) in the node-marked graph by an MPNN \(g_{rl}\), the current overall graph representation across all node tuples, and the state matrix \(W\) summarized by a pooling function \(R^{(W)}\). \([Q]_{l,j}\) represents the expected reward of replacing the node on index \(j\) of node tuple \(\) with node \(v_{l}\). The best action \(a_{j,l}\) is then chosen by,

\[*{arg\,max}_{j,l}[Q(s,)]_{l,j} \]

Note that because we assign different initial embeddings based on the node tuple, the MPNN distinguishes otherwise indistinguishable graphs.

Figure 3: MAG-GNNâ€™s pipeline. An RL agent iteratively updates node tuples for better expressivity.

As demonstrated in Figure 3, our agent starts with a set of random node tuples and their corresponding subgraphs. In each step, the agent uses an MPNN-parameterized Q-network to update one slot in one node tuple such that the new node tuple set results in a better objective value. The agent repeats for a fixed number of steps \(t\) to find discriminative subgraphs. We do not assign a terminal state during training. Instead, the Q-Network will learn to be stationary when all other action decreases the objective value. This process is like throwing iron balls (marked nodes) into a magnetic field (geometry of the graph) and computing the force that the balls receive along with the interactions among balls (Q-network). We learn to move the balls and reason about the magnetic field's properties. Hence, we dub our method Magnetic GNN (MAG-GNN). To show the effectiveness of our method in locating discriminative node tuples, we prove the following theorem (proof in Appendix A).

**Theorem 2**.: _There is a MAG-GNN whose action is more powerful in identifying discriminative node tuples than random actions._

MAG-GNN is at least as powerful as random actions since we can adopt a uniform-output MPNN for the MAG-GNN, yielding random actions. The superiority proof identifies cases where MAG-GNN requires fewer steps to locate the discriminative node tuples. The overall inference complexity is the number of MPNN runs, \(O(mtT|V^{2}|)\). A more detailed complexity analysis is in Appendix D.

Some previous works also realize the complexity limitation of subgraph GNNs and propose sampling-based methods, and we discuss their relationship to MAG-GNN. PF-GNN  uses particle-filtering to sample from canonical labeling tree. MAG-GNN and PF-GNN do not overlap exactly. However, we show that using the same resampling process, MAG-GNN captures PF-GNN (Appendix A).

**Theorem 3**.: _MAG-GNN captures PF-GNN using the same resampling method in PF-GNN._

k-OSAN  proposes a data-driven subgraph sampling strategy to find informative subgraphs by another MPNN. This strategy reduces to random sampling when the graph requires higher expressivity (e.g., regular graphs) and has no features because the MPNN will generate the same embedding for all nodes and hence cannot identify subgraphs that most benefit the prediction like MAG-GNN can. MAG-GNN does not solely depend on the data and finds more expressive subgraphs even without node features. Moreover, sampled subgraphs in previous methods are essentially independent. In contrast, MAG-GNN also models their correlation using RL. This allows MAG-GNN to obtain better expressivity with fewer samples and better consistency (More discussions in Appendix C.3).

### Training MAG-GNN

With the state and action space, reward, and Q-network defined, we can use any DQN techniques to train the RL agent. However, to evaluate the framework's capability, we select the basic Experience Replay method  to train the Q-network. MAG-GNN essentially consists of two systems, an RL agent and a prediction MPNN. Making them coordinate is more critical to the method. The most natural way to train our system is first to train \(g_{p}\), as introduced in Section 3 with random node tuples. We then use \(g_{p}\) as part of \(f_{p}\), the marked-graphs encoder, and treat \(f_{p}\) as the fixed environment to train our Q-network. The advantage of the paradigm is that the environment is stable. Consequently, all experiences stored in the memory have the correct reward value for the action. This encourages stability and fast convergence during RL training. We term this paradigm ORD for ordered training.

However, not all \(g_{p}\) trained from random node tuples are _good_. When we train \(g_{p}\) for the ZINC dataset and evaluate all node-marked graphs to as in Section 3. The average standard deviation among all scores of node-marked graphs is \(\)\(0.003\), and the average difference between the worst and best score is \(\)\(0.007\). Hence, the maximal improvement is minimal if we use this MPNN as the environment. Intuitively, when the graph has informative initial features, \(X\), like those in the ZINC dataset, the MPNN quickly recognizes patterns from these features while gradually learning to ignore node marking features \(X(_{i})\), as not all node markings carry helpful information. In such cases, we need to adjust \(g_{p}\) while the RL agents become more powerful in finding discriminative subgraphs.

One way is to train the RL agent and \(g_{p}\) simultaneously. Concretely, we sample a state \(s\), run the RL agent \(t\) steps to update it to state \(s^{t}\), and train \(g_{p}\) on the marked graphs of \(s^{t}\). Then, in the same step, the RL agent samples a different state and treats the current \(g_{p}\) as the environment to generate experience. Lastly, the RL agent is optimized on the sampled previous experiences. Because we adjust \(g_{p}\) to capture node tuple information better, the score standard deviation of the node-marked ZINC graphs is kept at \(\)\(0.036\). We term this paradigm SIMUL. Compared to ORD, SIMUL makesthe RL agent more difficult to train when \(g_{p}\) evolves rapidly. Nevertheless, we observe that as \(g_{p}\) gradually becomes stable, the RL agent can still learn effective policies.

One of the critical goals of MAG-GNN is to identify complex structural information that MPNN cannot. Hence, instead of training the agent on real-world datasets from scratch, we can transfer the knowledge from synthetic expressivity data to real-world data. As mentioned above, training MAG-GNN on graphs with features is difficult. Alternatively, we first use the ORD paradigm to train the agent on expressivity data without node features such as SR25. On these datasets, \(g_{p}\) relies on the node markings to make correct predictions. We then fix the RL agent and only use the output state from the agent to train a new \(g_{p}\) for the actual tasks, such as ZINC graph regression. Using this paradigm, we only need to train one MAG-GNN with good expressivity and adapt it to different tasks without worrying about overfitting and the aforementioned stability issue, we name this paradigm PRE. We experimented with different schemes in Section 6.

## 5 Related work

**More expressive GNNs.** A substantial amount of work strive to improve the expressivity of GNNs. They can be classified into the following categories: (1) Just like MPNN simulates the 1-WL test, **Higher-order GNNs** design GNNs to simulate higher-order WL tests. They include k-GNN , RingGNN , and PPGN . These methods perform message passing on node tuples and have complexity that grows exponentially with \(k\) and hence does not scale well to large graphs. (2) Realizing the symmetry-breaking power of subgraphs, **Subgraph GNNs**, including NGNN , GNN-AK , KPGNN , and ID-GNN , use MPNNs to encode subgraphs instead of subtrees around graph nodes. Later works, like I\({}^{2}\)-GNN , further use 2-order(edge) subgraph information to improve the expressivity of subgraph GNNs beyond 3-WL. Recent works, such as OSAN  and SUN , unify subgraph GNNs into the WL hierarchy, showing improvement in expressivity for subgraph GNNs also requires exponentially more subgraphs. (3) **Substrcuture counting** methods, including GSN  and MotifNet , employ substructure counting in GNNs. They count predefined substructures undetectable by the 1-WL test as features for MPNN to break its expressivity limit. However, the design of the relevant substructures usually requires human expertise. (4) Many previous works also realize the complexity issue of more expressive GNNs and strive to reduce it. SetGNN  proposes to reduce node tuple to set and thus reduce the number of nodes in message passing. GDBNN  designs geodesic pooling functions to have strong expressivity without running MPNN multiple times. (5) **Non-equivariant GNNs.** Abboud _et al._ proves the universality of MPNN with randomly initialized node features, but due to the large search space, such expressivity is hardly achieved. DropGNN  randomly drops out nodes from the graph to break symmetries in graphs. PF-GNN  implements a neural version of canonical labeling and uses particle filtering to sample branches in the labeling process. OSAN  proposes to use input features to select important subgraphs. Agent-based GNN  initializes multiple agents on a graph without the message-passing paradigm to iteratively update node embeddings. MAG-GNN also falls into this category.

**Reinforcement Learning and GNN.** There has been a considerable effort to combine RL and GNN. Most work is on application. GraphNAS  uses GNN to encode neural architecture and use reinforcement learning to search for the best network. Wang _et al._ uses GNN to model circuits and RL to adjust the transistor parameters. On graph learning, most works use RL to optimize particular parameters in GNN. For example, SUGAR  uses Q-learning to learn the best top-k subgraphs for aggregations; Policy-GNN  learns to pick the best number of hops to aggregate node features. GPA  uses Deep Q-learning to locate the valuable nodes in active search. These works leverage the node feature to improve the empirical performance but fail to identify graphs with symmetries, while MAG-GNN has good expressivity without node features. To the best of our knowledge, our work is the first to apply reinforcement learning to the graph expressivity problem.

## 6 Experimental results

In the experiment 1, we answer the following questions: **Q1**: Does MAG-GNN have good expressivity, and is the RL agent output more expressive than random ones? **Q2**: MAG-GNN is graph-level;can the expressivity generalize to node-level tasks? **Q3**: How is the RL method's performance on real-world datasets? **Q4**: Does MAG-GNN have the claimed computational advantages?

For the experiment, we update all node tuples simultaneously as it allows more parallelizable computation. More experiment and dataset details can be found in Appendix F.

### Discriminative power

**Dataset.**To answer **Q1**, we use synthetic datasets (Accuracy) to test the expressivity of models. (1) EXP contains 600 pairs of non-isomorphic graphs that cannot be distinguished by 1-WL/2-WL bounded GNN. The task is to differentiate all pairs. (2) SR25 contains 15 strongly regular graphs with the same configuration and cannot be distinguished by 3-WL bounded GNN. (3) CSL contains 150 circular skip link graphs in 10 isomorphism classes. (4) BREC contains 400 pairs of synthetic graphs to test the fine-grained expressivity of GNNs (Appendix E). We use the ORD training scheme.

**Results.** We compare to MPNN , Random Node Marked (RNM) GNN with the same hyperparameter search space as MAG-GNN, subgraph GNNs[35; 15; 36; 37], and Non-equivariant GNNs  as baselines. Table 1 shows that MAG-GNN achieved a perfect score on all datasets, which verifies our observation and theory. Note that subgraph GNNs like NGNN take at least \(|V|\) MPNN runs, while MAG-GNN takes constant times of MPNN runs. However, MAG-GNN successfully distinguished all strongly regular graphs in SR25, which NGNN failed. RNI, despite being universal, is challenging to train and can only make random guesses on SR25. Compared to the RNM approach, MAG-GNN finds more representative subgraphs for the SR25 dataset and performs better. Figure 4 shows a graph in the EXP dataset. We observe that MAG-GNN moves the initial node marking on the same component to different components, allowing better structure learning. Another example of strongly regular graphs is in Appendix E. In Figure 5, we also plot the performance of MAG-GNN against the number of MAG-GNN search steps when we only use one node tuple of size two. We see that node tuples from MAG-GNN are significantly more expressive than random node tuples (step 0). On EXP and CSL datasets, MAG-GNN can achieve perfect scores in one or two steps, whereas in SR25, it takes six steps but with a consistent performance increase over steps. We plot the reward curve during training in Appendix E.

### Node-level tasks.

**Datasets.** To answer **Q2**, we adopt the synthetic cycle counting dataset, CYCLE (MAE), in Zhao _et al._. The task is to count the number of (3,4,5,6)-cycles on each node. MPNN cannot count these structures. Node-rooted GNN can count (3,4)-cycles, while only models with expressivity beyond 3-WL can count all cycles. We use the ORD training scheme.

    & EXP & CSL & SR25 \\  GIN  & 50.0 & 10.0 & 6.7 \\ RNI  & 99.7 & 16.0 & 6.7 \\ NGNN  & 100 & 10.0 & 6.7 \\ GNNAK+  & 100 & 100 & 6.7 \\ SSWL+  & 100 & 100 & 6.7 \\ RNM & 100 & 100 & 93.8 \\ \({}^{2}\)GNN  & 100 & 100 & 100 \\ MAG-GNN & 100 & 100 & 100 \\   

Table 1: Synthetic results. (\(\))

Figure 4: Initial Random Node Marking (Left). MAG-GNN generated markings. (Right)

Figure 5: Performance versus the number of RL steps.

[MISSING_PAGE_FAIL:9]

OGBG-MOLHIV dataset. We observe that 1-WL bounded methods PNA also achieves good results on the datasets, meaning that the critical factor determining the performance on this dataset is likely the implementation of the base GNN but not the expressivity. MAG-GNN is highly adaptable to any base GNN, potentially improving MAG-GNN's performance further. We leave this to future work.

We use the PRE training scheme to conduct transfer learning tasks on ZINC, ZINC-FULL, and OGBG-MOLHIV datasets. We pre-train the expressivity datasets shown on the left column of Table 3 and train the attached MPNN head using the datasets on the top row. We see that pretraining consistently brings performance improvement to all datasets. Models pre-trained on CYCLE are generally better than the one pretrained on SR25, possibly due to the abundance of cycles in molecular graphs.

### Runtime comparison

We conducted runtime analysis on previously mentioned datasets. Since it is difficult to match the number of parameters for all models strictly, we fixed the number of GNN layers to five and the embedding dimension to 100. We set a 1 GB memory budget for all models and measured their inference time on the test datasets. We use \(m=2\) and \(T=2\) for MAG-GNN. The results in Table 4 show that MAG-GNN is more efficient than all subgraph GNNs and is significantly faster than the edge-rooted subgraph GNN, I\({}^{2}\)GNN. NGNN achieves comparable efficiency to MAG-GNN because it takes a fixed-hop subgraph around nodes, reducing the subgraph size. However, MAG-GNN outperforms NGNN on most targets with its better expressivity.

**Limitations.** Despite the training schemes in Section 4.1, MAG-GNN is harder to train. Also, MAG-GNN's design for node-level tasks might not be proper. This motivates research on extending MAG-GNN to node-level or even edge-level tasks. We discuss this further in Appendix C.4.

## 7 Conclusions

In this work, we closely examine one popular GNN paradigm, subgraph GNN, and discover that a small subset of subgraphs is sufficient for obtaining high expressivity. We then design MAG-GNN, which uses RL to locate such a subset, and propose different schemes to train the RL agent effectively. Experimental results show that MAG-GNN achieved very competitive performance to subgraph GNNs with significantly less inference time. This opens up new pathways to design efficient GNNs.

**Acknowledgement.** Lecheng Kong, Jiarui Feng, Hao Liu, and Yixin Chen are supported by NSF grant CBE-2225809. Muhan Zhang is partially supported by the National Natural Science Foundation of China (62276003) and Alibaba Innovative Research Program.

    & \# Params & ZINC (\(\)) & ZINC-FULL (\(\)) & OGBG-MOLHIV (\(\)) \\  GIN & - & 0.163\(\)0.004 & 0.088\(\)0.002 & 77.07\(\)1.49 \\ PNA & - & 0.188\(\)0.004 & - & 79.05\(\)1.32 \\ k-OSAN & - & 0.155\(\)0.004 & - & - \\ PF-GNN & - & 0.122\(\)0.010 & - & 80.15\(\)0.68 \\ RNM & 453k & 0.128\(\)0.027 & 0.062\(\)0.004 & 76.79\(\)0.94 \\ GSN & - & 0.115\(\)0.012 & - & 78.80\(\)0.82 \\ CIN & 100k & 0.079\(\)0.006 & **0.022\(\)**0.002 & **80.94\(\)**0.57 \\ NGNN & 500k & 0.111\(\)0.003 & 0.029\(\)0.001 & 78.34\(\)1.86 \\ GNAK+ & 500k & 0.080\(\)0.001 & - & 79.61\(\)1.19 \\ SUN & 526k & 0.083\(\)0.003 & - & 80.03\(\)0.55 \\ KPGNN & 489k & 0.093\(\)0.007 & - & - \\ I\({}^{2}\)GNN & - & 0.083\(\)0.001 & 0.023\(\)0.001 & 78.68\(\)0.93 \\ SSWL+ & 387k & **0.070\(\)**0.005 & **0.022\(\)**0.002 & 79.58\(\)0.35 \\  MAG-GNN & 496k & 0.106\(\)0.014 & 0.030\(\)0.002 & 77.12\(\)1.13 \\ MAG-GNN-PRE & 496k & 0.096\(\)0.009 & 0.023\(\)0.002 & 78.30\(\)1.08 \\   

Table 6: Molecular datasets results.(\(\))