# Back to the Continuous Attractor

Abel Sagodi, Guillermo Martin-Sanchez, Piotr Sokol, Il Memming Park

Champalimaud Centre for the Unknown

Champalimaud Foundation, Lisbon, Portugal

{abel.sagodi,guillermo.martin,memming.park}@research.fchampalimaud.org

piotr.sokol@protonmail.com

###### Abstract

Continuous attractors offer a unique class of solutions for storing continuous-valued variables in recurrent system states for indefinitely long time intervals. Unfortunately, continuous attractors suffer from severe structural instability in general--they are destroyed by most infinitesimal changes of the dynamical law that defines them. This fragility limits their utility especially in biological systems as their recurrent dynamics are subject to constant perturbations. We observe that the bifurcations from continuous attractors in theoretical neuroscience models display various structurally stable forms. Although their asymptotic behaviors to maintain memory are categorically distinct, their finite-time behaviors are similar. We build on the persistent manifold theory to explain the commonalities between bifurcations from and approximations of continuous attractors. Fast-slow decomposition analysis uncovers the existence of a persistent slow manifold that survives the seemingly destructive bifurcation, relating the flow within the manifold to the size of the perturbation. Moreover, this allows the bounding of the memory error of these approximations of continuous attractors. Finally, we train recurrent neural networks on analog memory tasks to support the appearance of these systems as solutions and their generalization capabilities. Therefore, we conclude that continuous attractors are _functionally robust_ and remain useful as a universal analogy for understanding analog memory.

## 1 Introduction

Biological systems exhibit robust behaviors that require neural information processing of analog variables such as intensity, direction, and distance. Virtually all neural models of working memory for continuous-valued information rely on persistent internal representations through recurrent dynamics. The continuous attractor structure in their recurrent dynamics has been a pivotal theoretical tool due to their ability to maintain activity patterns indefinitely through neural population states . They are hypothesized to be the neural mechanism for the maintenance of eye positions, heading direction, self-location, target location, sensory evidence, working memory, and decision variables, to name a few . Observations of persistent neural activity across many brain areas, organisms, and tasks have corroborated the existence of continuous attractors .

Despite their widespread adoption as models of analog memory, continuous attractors are brittle mathematical objects, casting significant doubts on their ontological value and hence suitability in accurately representing biological functions. Even the smallest arbitrary change in recurrent dynamics can be problematic, destroying the continuum of fixed points essential for continuous-valued working memory. In neuroscience, this vulnerability is well-known and often referred to as the "fine-tuning problem" . There are two primary sources of perturbations in the recurrent network dynamics: (1) the stochastic nature of online learning signals that act via synaptic plasticity, and (2) spontaneous fluctuations in synaptic weights . Thus, additional mechanisms are necessary to compensate for the degradation in particular implementations, by bringing the short-term behavior closer to thatof a continuous attractor [16; 23; 24; 25; 26; 27; 28; 29]. However, we lack the theoretical basis to understand how much this matters in practice, i.e. what are the effects of different levels of degradation on memory. This is fundamental to justify relying on the brittle concept of continuous attractors for understanding biological analog working memory.

In this study, we explore perturbations and approximations of continuous attractors in the space of dynamical models. We first report on the differences and similarities between the various structurally stable dynamics in the vicinity of continuous attractors in the space of dynamical systems models. Our analysis reveals the presence of a "ghost" continuous attractor (a.k.a. slow manifold) in all of them (Sec. 2). By assuming normal hyperbolicity we separate the time scales to obtain a decomposition of the dynamics by separating out the fast flow normal to and the slow flow within the slow manifold. We derive theoretical results that ensure the existence of a slow manifold and determine its closeness to a continuous attractor (Sec. 3). We explore task-trained recurrent neural networks (RNNs) to show that these systems appear naturally as solutions to the task (Sec. 4) and that their generalization capabilities can easily be studied as the distance to the continuous attractor (Sec. 5). The proposed decomposition applied to theoretical models and task-trained RNNs reveals a "universal motif" of analog memory mechanism with various potential topologies. This leads to the connection of different systems with different topologies as **approximate continuous attractors** (Sec. 6). Our theory guarantees that systems close to a continuous attractor (in the space of vector fields) will have similar behavior to it, implying that the concept of continuous attractors remains a crucial framework for understanding the neural computation underlying analog memory (Sec. 3.4).

## 2 A critique of pure continuous attractors

We will first lay out a number of observations about the dynamics of bifurcations and approximations of continuous attractors used in theoretical neuroscience. Ordinary differential equations (ODEs) are commonly used to describe the dynamical laws governing the temporal evolution of firing rates or latent population states . In this framework, neural systems are viewed as implementing the continuous time evolution of neural states to perform computations. We will consider a continuous attractor as a mechanism that implements analog memory computation: carrying a particular memory representation over time. To define it formally, let \((t)^{d}\) denote the neural state, and \(}=()\) represent its dynamics. Let \(^{d}\) be a manifold. We say \(\) is a continuous attractor, if (1) every state on the manifold is a fixed point, \(,()=0\), and (2) the fixed points are marginally stable tangent to the manifold and stable normal to the manifold. In other words, the continuous attractor is a continuum of equilibrium points such that the neural state near the manifold is attracted to it, and on the manifold, the state does not move. Marginal stability implies that continuous systems are _structurally unstable_, meaning that small perturbations or variations in the system's parameters lead to significant changes in the system's behavior or stability [30; 31; 32; 33]. We will now study some examples of continuous attractors and how perturbations change their dynamics.

### Motivating example: bounded line attractor

As an illustrative example, we can construct a line attractor (a continuous attractor with a line manifold) as follows:

\[}=-+[+]_{+} \]

where \(=[0,-1;-1,0]\) and \(=[1;1]\), and \([]_{+}=(0,)\) is the threshold nonlinearity per unit. We get \(}=0\) on the \(x_{1}=-x_{2}+1\) line segment in the first quadrant as the manifold (Fig. 1A, left; black line). Linearization of the fixed points on the manifold exhibits two eigenvalues, \(0\) and \(-2\); the \(0\) eigenvalue allows the continuum of fixed points, while \(-2\) makes the flow normal to the manifold attractive (Fig. 1A, left; flow field).

In general, continuous attractors are not only structurally unstable , they bifurcate almost certainly for an _arbitrary_ perturbation of \(\). In this example, small changes to the parameters \((,)\) perturb the eigenvalues and any to the \(0\) eigenvalue destroys the continuous attractor: it bifurcates to either a single stable fixed point (Fig. 1A, top) or two stable fixed points separated with a saddle-node in between (Fig. 1A, bottom). However, interestingly, after bifurcation, continuous attractors seemingly tend to leave a "ghost" manifold topologically equivalent to the original continuous attractor (note the slow speed). Furthermore, the flow after the bifurcation is contained in the ghost manifold, i.e., it is an invariant manifold. This phenomenon, wherein a continuous attractor is approximated by a manifold within the neural space along which the drift occurs at a very slow pace, has previously been discussed [35; 36; 37].

### Theoretical models of ring attractors

For circular variables such as the goal-direction (e.g. for navigation [38; 39] and working memory for communication in bees ) or head direction, the temporal integration, and working memory functions are naturally solved by a ring attractor (continuous attractor with a ring topology) [417; 42; 43; 44; 45; 46; 47; 48; 49]. Other examples include integration of evidence for continuous perceptual judgments, e.g. a hunting predator that needs to compute the net direction of motion of a large group of prey . In this section, we investigate the bifurcations of various implementations of continuous attractors. Continuous attractor network models of the head direction are based on the interactions of neurons that (anatomically) form a ring-like overlapping neighbor connectivity [51; 52; 53; 54; 55; 56; 57]. Similarly to the line attractor, the ring attractor bifurcates with almost any perturbation to the network dynamics. However, the resulting dynamics continue to follow a familiar pattern: they remain confined to a ghost manifold that closely approximates the original continuous attractor.

**Piecewise-linear ring attractor model of the central complex:** Firstly, we discuss perturbations of a continuous ring attractor recently proposed as a model for the head direction representation in fruit flies . This model is composed of \(N\) heading-tuned neurons with preferred headings \(_{j}\{{2 i/N}\}_{i=1 N}\) radians (Sec. S3.2). For sufficiently strong local excitation (given by the parameter \(J_{E}\)) and broad inhibition (\(J_{I}\)), this network will generate a stable bump of activity corresponding to the head direction. This continuum of fixed points forms a \(N\)-sided polygon.

We evaluate the effect of parametric perturbations of the form \(+\) with \(_{i,j}(0,}{{100}})\) on a network of size \(N=6\) (forming an hexagon, see also Sec. S3). We found that the continuum of fixed points can collapse to between 2 and 12 isolated fixed points (Fig. 2A). As far as we know, this bifurcation from a ring of equilibria to a saddle and node has not been described previously in the literature. The probability of each type of bifurcation was numerically estimated (Sec. S3.2). Surprisingly, the number of fixed points is maintained throughout a range of perturbation sizes and hence depends only on the direction of the perturbation (Fig. S8).

**Bump attractor model:** A well-established approach to form a ring attractor in the limit of large network is with a connection matrix \(W\) with entries that follow a circular Gaussian function of \(i-j\)[58; 60; 61; 62] (Sec. S3.3). This type of ring attractor network can support a stable "activity bump" that can move around the ring of nonlinear neurons in correspondence with changes in head direction . For finite-sized networks, the dynamics are constrained to an attractive invariant ring, covered with \(N\) stable fixed points for a network of size \(N\) (Fig. 2B). For such networks the number of fixed points can change with the size of the perturbation (Fig. S8).

Figure 1: The critical weakness of continuous attractors is their inherent brittleness as they are rare in the parameter space, i.e., infinitesimal changes in parameters destroy the continuous attractor implemented in RNNs [5; 16]. Some of the structure seems to remain; there is an invariant manifold that is topologically equivalent to the original continuous attractor. (**A**) Phase portraits for the bounded line attractor (Eq. (1)). Under perturbation of parameters, it bifurcates to systems without the continuous attractor. (**B**) The low-rank ring attractor approximation (Sec. (S3.4)). Different topologies exist for different realizations of a low-rank attractor: different numbers of fixed points (4, 8, 12), or a limit cycle (right bottom). Yet, they all share the existence of a ring invariant set.

**Low-rank ring attractor model:** Low-rank networks can be used to approximate ring attractors [64; 65]. In the limit of infinite-size networks, one can construct a ring attractor through a rank 2 network by constraining the overlap of the right- and left-connectivity vectors (see Sec. S3.4). However, in simulations of finite-size networks with this constraint, the dynamics instead always converge to a small number of stable fixed points arranged on a ring (Fig. 1B).

**Embedding Manifolds with Population-level Jacobians:** Approximate ring attractors can be constructed by constraining the connectivity so that the networks Jacobian satisfies certain requirements for a ring attractor to exist  (see Sec. S3.5). The models constructed with this method also can contain an invariant ring manifold on which the dynamics contain stable and saddle fixed points (Fig. 2C). It has been observed that approximate continuous attractor emerge in networks trained on sampled points with other methods as well .

**Similarity between all bifurcations and approximations of continuous attractors:** In all discussed models of ring attractors, we verify that they suffer from the fine-tuning problem. However, importantly, we also observe in all the systems the existence of ghosts of the continuous attractor (either through bifurcation or from finite-size effects) in the form of an _attractive invariant manifold_. Therefore, while they are not strictly a continuous attractor in the mathematical sense, they are _approximate_ ring attractors in the sense that the fixed points and connecting orbits still form a circle.

Is this lawful degradation a universal phenomenon? And if so, how does it relate to the size of the perturbation? And what are the implications for the memory performance of these approximations? (Sec. 3). Do these approximations appear as natural solutions to the memory storage problem? (Sec. 4). And if so, how well do they generalize to longer time requirements? (Sec. 5). Finally, are continuous attractors in practice still useful as an idealized model of how animals represent continuous variables? (Sec. 6).

## 3 Theory of Approximate Continuous Attractors

In this section, we theoretically answer in an implementation-agnostic manner the degradation questions posed from the exploration. To do so, we apply invariant manifold theory to continuous attractor models and translate the results for the neuroscience audience (see also Sec. S1).

### Persistent Manifold Theorem

First, we argue that the lawful degradation into a system with a slow manifold is universally guaranteed (as long as the perturbation is small, and the continuous attractor was normally hyperbolic). Let \(l\) be the intrinsic dimension of the manifold of equilibria that defines the continuous attractor. Given a perturbation \(()\) to the ODE that induces a bifurcation,

\[}=()+\,() \]

Figure 2: Perturbations of different implementations and approximations of ring attractors lead to bifurcations that all leave the ring invariant manifold intact. For each model, the network dynamics is constrained to a ring manifold with stable fixed points (green) and saddle nodes (red). (A) Perturbations to Noorman et al. . The ring attractor can be perturbed in systems with an even number of fixed points (FPs) up to \(2N\) (stable and saddle points are paired). (B) Perturbations to a tanh approximation of a ring attractor Seeholzer et al. . (C) Different Embedding Manifolds with Population-level Jacobians (EMPJ) approximations of a ring attractor .

where \(\|()\|_{}=1\) and \(>0\) is the bifurcation parameter, we can reparameterize the dynamics around the manifold with coordinates \(^{l}\) and the remaining ambient space with \(^{d-l}\). To describe an arbitrary bifurcation of interest, we introduce a sufficiently smooth function \(\) and \(\), such that the following system is equivalent to the original ODE:

\[} =(,,) \] \[} =\ (,,) \]

where \(=0\) gives the condition for the continuous attractor \(}=\). We denote the corresponding manifold of \(l\) dimensions as \(_{0}\{(,)(, ,0)=\}\).

We say the flow around the manifold is _normally hyperbolic_, if the flow normal to the manifold is hyperbolic, i.e. the Jacobians \(_{}\) evaluated at any point on the \(_{0}\) has \(d-l\) eigenvalues with their real part uniformly bounded away from zero, and \(_{}\) has \(l\) eigenvalues with zero real part. More specifically, for continuous attractors, the real parts of the eigenvalues of \(_{}\) are strictly negative, representing sufficiently strong attractive flow toward the manifold. Equivalently, for the ODE, \(}=()\), the variational system is of constant rank and has exactly \((d-l)\) eigenvalues with negative real parts uniformly away from zero and \(l\) eigenvalues with zero real parts everywhere along the continuous attractor.

For any parameterization \(\), \(>0\) induces a bifurcation of the continuous attractor. What can we say about the fate of the perturbed system? The continuous dependence theorem67 says that the trajectories will change continuously as a function of \(\) without a guarantee on how quickly they change. However, the topological structure and the asymptotic behavior of trajectories change discontinuously due to the bifurcation. Yet, surprisingly, there is a strong connection in the geometry due to Fenichel's theorem68.* We informally present a special case due to Jones 73:

Footnote *: The Persistent Manifold Theorem has been successfully applied previously in neuroscience , for example to reduce the dimensionality of the Hodgkin-Huxley model .

Footnote †: See Eldering 74 for results of persistence of noncompact invariant manifolds.

**Theorem 1** (Persistent Manifold).: _Let \(_{0}\) be a connected, compact+, normally hyperbolic manifold of equilibria originating from a sufficiently smooth ODE. For a sufficiently small perturbation \(>0\), there exists a manifold \(_{}\) diffeomorphic to \(_{0}\) and invariant under the flow of Eq. (3)-(4)._

Footnote †: As a technical note, for the theory to apply to a continuous piecewise-linear system, it is required that the invariant manifold is globally attracting 75, which is also the case for the BLA (see also  for a discussion of geometric singular perturbation theory for piecewise linear dynamical systems). Therefore, we consider systems that are at least continuous, but some extra conditions apply if a system is not differentiable.

The manifold \(_{}\) is called the _slow manifold_ which is no longer necessarily a continuum of equilibria. However, the invariance implies that trajectories remain within the manifold except potentially at the boundary. Furthermore, the non-zero flow on the slow manifold is slow and given in the \( 0\) limit as \(}{}=(c^{}( ),,0)\) where \(= t\) is a rescaled time and \(c^{}()\) parameterizes the \(l\) dimensional slow manifold. In addition, the stable manifold of \(_{0}\) is similarly persistent 73, implying that the manifold \(_{}\) remains attractive. Finally, the persisting invariant manifold is very close in space to the original continuous attractor (see also Theorem 3).

These conditions are met for the examples in Fig. 1 (see Sec. S2.1 for the corresponding fast-slow reparametrization8).As the theory predicts, it bifurcates into a 1-dimensional slow manifold (Fig. 1, dark-colored regions) that contains fixed points and connecting orbits and is overall still attractive. Furthermore, Fenichel's Persistent Manifold theorem explains the bifurcation structure of the theoretical models discussed in Sec. 2.2. Because continuous ring attractors are bounded, they persist as an invariant manifold and remain attractive under small perturbations 78.

Figure 3: Persistent manifold theorem applied to compact continuous attractor guarantees the flow on the slow manifold \(_{}\) is invariant and continues to be attractive. The dashed line is a trajectory “trapped” in the slow manifold (which has the same topology as the continuous attractor).

### Fast-slow decomposition and the revival of continuous attractors

Consider a behaviorally relevant timescale for working memory, for example, roughly up to a few tens of seconds. If the relevant dynamical system is orders of magnitude slower, for example, 1000 sec or longer, its effect is too slow to have a practical impact on the behavior. This clear gap in the fast and slow time scales can be recast as _normal hyperbolicity_ of the slow manifold by relaxing the zero real part to a separation of time scales (reciprocal of eigenvalues or Lyapunov exponents). In other words, the attractive flow normal to the manifold needs to be uniformly faster than the flow on the slow manifold. By taking the limit of the slow flow on the manifold to arbitrarily long time constant (i.e., to zero flow), we achieve the reversal of the persistent manifold theorem.

**Proposition 1** (Revival of continuous attractor).: _Let \(_{}\) be a connected, compact, attractive, normally hyperbolic slow manifold (as parametrized by Eq. (3)-(4)). Let the uniform norm of the flow tangent to the manifold be \(\|}\|_{}=\). There exists a perturbation with uniform norm at most \(\) that induces a bifurcation to a continuous attractor manifold._

An explicit perturbation is derived in Sec. S5.1. This makes the uniform norm of the vector field on a (slow) manifold a useful measure of the distance of an approximation to a continuous attractor. Prop. 1 can be extended to the case where the invariant manifold has additional dynamics to which the output mapping is invariant (see Theorem 7). These systems can be perturbed onto a decomposable system where one of the subsystems has a slow flow.

### Relevance of dynamics on the memory performance of the slow manifold

Third, we relate the flow of the manifold (and, through Prop. 1, the _size_ of the perturbation) to the memory error of the approximation in short-time scale. We also discuss the implications of the theoretical insights on the memory error in the asymptotic time scale.

In the short-time scale the memory performance is bounded by the uniform norm of the flow tangent to the manifold. Let \(_{0}\), and \(=()|_{}\) be the vector field restricted to the manifold (following the notation in Eq. 2). The average deviation from the initial memory \(_{0}\) over time is bounded linearly (derivation in Sec. S6):

\[\,}_{}(t, _{0})-_{0}\,_{0} t\| \|_{} \]

Note that this bound is the worst case and tighter for sufficiently small \(t 0\). Furthermore, for compact invariant manifolds the error is bounded by the diameter of the manifold and hence this bound becomes irrelevant for \(t\) large.

While the uniform norm gives insight on the short-time scale behavior of the perturbed ODE, we expect that working memory tasks generalize to longer durations . The long-time scale behavior on the slow manifold is dominated by the stability structure, i.e., the topology of the dynamics. Although we have seen numerous topologies in Sec. 2, the Persistent Manifold Theorem says that this variability is fundamentally limited, especially in low dimensions (see for more details Sec. S4). This is especially relevant as previous works have identified a low-dimensional organization of neural activity to explain the brain's ability to adapt behavioral responses to changing stimuli and environments . For a ring attractor, this implies that the stability structure of the invariant manifold is either (1) composed of an equal number of stable fixed points and saddle nodes, placed alternatingly and with connecting orbits, or (2) a limit cycle. These different stability structures have different generalization properties (see Sec. 5). In more complex scenarios, such as two-dimensional attractors, fixed points can coexist with limit cycles, creating a rich tapestry of possible attractors.

### Implications on experimental neuroscience

Animal behavior exhibits strong resilience to changes in their neural dynamics, such as the continuous fluctuations in the synapses or slight variations in neuromodulator levels or temperature. Hence, any theoretical model of neural or cognitive function that requires fine-tuning, such as the continuous attractor model for analog working memory, raises concerns, as they are seemingly biologically irrelevant. This challenge is further compounded by the structural constraints imposed by the connectome, which defines the network's architecture and limits the possible configurations of synaptic and circuit dynamics . Moreover, unbiased data-driven models of time series data and task-trained recurrent network models cannot recover such continuous attractor theories precisely. Our theory shows that this apparent fragility is not as devastating as previously thought: despite the "qualitative differences" in the phase portrait, the "effective behavior" of the system can be arbitrarilyclose, especially in the behaviorally relevant time scales. We show that as long as the attractive flow to the memory representation manifold is fast and the flow on the manifold is sufficiently slow, it represents an **approximate continuous attractor**8. Furthermore, our theory bounds the error in working memory incurred over time for such approximate continuous attractors. Therefore, the concept of continuous attractors remains a crucial framework for understanding the neural computation underlying analog memory, even if the ideal continuous attractor is never observed in practice. Experimental observations that indicate the slowly changing population representations during the "delay periods" where working memory is presumably required, do not necessarily contradict the continuous attractor hypothesis. Perturbative experiments can further measure the attractive nature of the manifold and their causal role through manipulating the memory content.

## 4 Numerical Experiments on Task-optimized Recurrent Networks

While our theory describes the abundance of approximate continuous attractors in the vicinity of a continuous attractor, it does not imply that there are no approximate solutions away from continuous attractors. In this section, we use task-optimized RNNs as a means to search for plausible solutions for analog memory for a circular variable. We train a diverse set of RNNs, and then identify the solution type of trained RNNs to gain insights into its performance, error patterns, generalization capabilities, and, ultimately, proximity to a continuous attractor.

Understanding the implemented computation in neural systems in terms of dynamical systems is a well-established practice . Researchers have analyzed task-optimized RNNs through nonlinear dynamical systems analysis  and to compare those artificial networks to biological circuits . Previously, systematic analysis of the variability in network dynamics has been surveyed in vanilla RNNs, and variations in dynamical solutions over architecture and nonlinearity have been quantified . Furthermore, working memory mechanisms in RNNs had tendencies to find sequential or persistent representations through training depending on the task specification . We therefore investigated to what extent training RNNs on a task uniquely determines the low-dimensional dynamics, independent of neural architectures. We see that all the solutions have a slow invariant manifold, making all of them an instantiation of approximate continuous attractors.

### Model Architectures and Training Procedure

Building upon prior work, which has shown their capabilities on such tasks, we trained RNNs to either (1) estimate head direction through integration of angular velocity  (Fig. 4A1) or (2) perform a memory-guided saccade task for targets on a circle  (Fig. 4A2, details in Sec. S7.1 and see Sec. S7.3 for how RNNs relate to Eq. 2). We numerically minimized the mean squared error loss \(L_{}\) between the network output and the target output. For each activation function and each network architecture (vanilla RNN with ReLU, tanh, and rectified tanh activation functions, LSTM, and GRU), we trained 10 networks per hidden size: 64, 128, and 256 with (hidden) state noise.

### Numerical Fast-Slow Decomposition

For each trained network, we find the slow manifold by integrating the autonomous dynamics, then selecting the parts of the trajectories that have speed slower than a threshold (Sec. S7.9.1). We identify the points on the invariant manifold from the simulated trajectories that are projected closest to a set of points in the output space relevant to the task after convergence, i.e. on the target ring. We parametrize the one-dimensional invariant manifold by fitting a cubic spline with periodic boundary constraints to these points (black line in Fig. 4B & C). Normal hyperbolicity is measured by a gap in the timescales of the system (the eigenvalue spectrum of the linearization along points on the invariant manifold, Fig. 4E and F).

We find the fixed points on the invariant ring by identifying regions where the direction of the flow flips (Sec. S7.6.3). Stable fixed points are identified where the flow directions are both pointing towards this flip point, while saddle nodes are identified where they are pointing away (Fig. 4B & C.)

### Variations in the Topologies of the Slow Manifold Solutions

To understand what solutions the RNNs found to solve the task, we investigate their memory mechanism. For this, we dissect the dynamics of RNNs by segregating time scales to delineate the rapid flow normal to the slow manifold, and the flow on the manifold (Sec. S7.6.3). All solutionsinvolve a slow manifold with the same topology as the relevant variable in the task. The different solutions are different in their asymptotic dynamics (Fig. 4). The most often found solution is of the type _fixed point ring manifold_ (Fig. 4B and C). These solutions are consistent with observations that persistent activity relies on discrete attractors . Less commonly found topologies includes the slow torus around a repulsive ring invariant manifold (Fig. 4D). This solution in turn is consistent with both observations of the possibility of using non-constant dynamics for memory storage  and neuronal circuits underlying persistent representations despite time-varying activity . All stability structures (fixed points and limit cycles) are mapped close to the target output circle (Figs. S15, S19, S20). We also verify the normal hyperbolicity of the trained networks shown in Fig. 4B and C. The largest eigenvalue of the Jacobian fluctuates around zero (the invariant manifold is not a continuous attractor), but it is removed from the second largest (Fig. 4E & F).

### Universality amongst Good Solutions

The fixed point topologies show a lot of variation across networks (Fig. 4B,C, Fig. 5 and Fig. S20), much like the systems next to continuous attractors (Fig. 1 and Fig. 2). Previously, it has been observed that fixed point analysis has a major limitation, namely, that the number of fixed points must be equal across compared networks . Our methodology effectively addresses and overcomes this limitation. The universal structure of continuous attractor approximations as slow invariant manifolds allows us to connect different topologies as **approximate continuous attractors** (Sec. 3.3). For results on LSTMs and GRUs and a higher dimensional task, see Sec. S7.7 and Sec. S7.9, respectively.

## 5 Generalization Analysis

In this section, we use task-trained RNNs to study the relationship between dynamics and generalization capabilities. When neuroscientists study neural computations in animals, tasks have finite durations, leaving it unclear whether animals learn the intended computation or a finite-time approximation. The same issue applies to trained neural networks. We will explore whether the networks possess the necessary memory for perfect recall or only perform the task within the timescale of their training.

Figure 4: Slow manifold approximation of different trained networks on the memory-guided saccade and angular velocity integration tasks. (A1) Output of an example trajectory on the angular velocity integration task. (A2) Output of example trajectories on the memory-guided saccade task. (B) An example fixed-point type solution to the memory-guided saccade task. Circles indicate fixed points of the system (filled for stable, empty for saddle) and the decoded angular value on the output ring is indicated with the color according to A1. (C) An example of a found solution to the angular velocity integration task. (D) An example slow-torus type solution to the memory-guided saccade task. The colored curves indicate stable limit cycles of the system. (E+F) The eigenvalue spectra for the trained networks in B and C show a gap between the first two largest eigenvalues.

The two possible approximations of a ring attractor, a limit cycle or a fixed point ring manifold (Sec. 3.3), exhibit markedly distinct generalization characteristics. Approximating the system as a limit cycle results in a memory trace that gradually diminishes over time (c.f. Park et al. ). Conversely, the alternative approximation's memory states are contingent upon the quantity and positioning of stable fixed points within the system. We describe in detail the generalization properties of the trained networksP on the angular velocity integration task at two different time scales: asymptotic and finite time.

Footnote ¶: We tested all networks with a validation set and took a cutoff for the normalized MSE for the networks we consider for the analysis at -20 dB (Fig. 5B).

**Finite time:** Along with the angular velocity integration component of the task, the trained networks learn to store a memory of an angular variable. We assess the performance of the network to store the memory of the angle over time. The networks typically perform well on the timescale on which they have been trained, \(T_{1}=256\) time steps (Fig. 5C). The memory error for \(T_{1}\) is, as theoretically predicted (Eq. 5, see Prop. 2), bounded by the uniform norm of the vector field on the invariant manifold, and therefore by the distance to a continuous attractor (Prop. 1, Fig. 5A, Sec. S7.6.3 & S6).

**Asymptotic time:** Looking beyond the finite timescale provides valuable insights into the network's ability to store information. For the asymptotic time scale, we capture the asymptotic behavior of the system by identifying to what part of the state space the system evolves to in the limit \(t\) (see also Sec.S7.6.2). For a one-dimensional system, this will either be fixed points or a limit cycle. For the fixed-point type solution, the maximal error is given by the maximal distance to the next fixed point, while for a limit cycle, this will always be \(\). We calculate the _average fixed point distance_ by taking the average of the inter-fixed-point interval for each neighboring pair of fixed points.

We can also quantify the loss of information. Assuming a uniform distribution over the angles, we define the _memory capacity_ as the negative conditional entropy of the continuous memory given the asymptotic state, i.e. the stable fixed points (see Sec. S7.6.2 and Eq. 68).

Figure 5: Temporal generalization validates theoretical predictions regardless of implementation detail. (A) Average accumulated angular error versus the maximum flow on the manifold (Eq. 5), shown for finite time (task duration that the networks were trained on, \(T_{1}\); filled markers) and at asymptotic time (hollow markers). (B) Normalized validation loss of all trained networks. (C) Average error and theoretical upper bound over time for two selected networks (corresponding to arrows in panel D). (D) Average asymptotic error is roughly inversely proportional to the number of fixed points. (E) Memory capacity is predictive of the average error.

**Error Accumulation in Neural Networks:** The mean accumulated error at the time at which the task was trained has an exponential relationship with the number of fixed points (Fig. 5A). Furthermore, this error is bounded by the mean distance between stable and unstable fixed points (red dots in Fig. 5D). This is another indication that the networks rely on a ring invariant manifold to implement the task. Networks with different numbers of fixed points might have the same performance on the finite time scale (bounded by \(T_{1}\|\|_{}\)) but have vastly different generalization properties because they differ in the number of fixed points (Fig. 5C).

## 6 Approximate Slow Manifolds are near Continuous Attractors

In Sec. 2.2, we presented a theory of approximate solutions in the neighborhood of continuous attractors. When are approximate solutions to the analog working memory problem near a continuous attractor? We posit that there are four conditions (see for more detail Sec. S5.3): **(C1)** sufficiently smooth approximate bijection between neural activity and memory content, **(C2)** the speed of drift of memory content is bounded, **(C3)** robustness against state (S-type) noise, and **(C4)** robustness against dynamical (D-type) noise . The correspondence implied by **(C1)** translates to the existence of a manifold in the neural activity space with the same topology as the memory content.1 Persistence **(C2)** requires that the flow on the manifold is slow and bounded. S-type robustness **(C3)** implies non-expansive flow, i.e., non-positive Lyapunov exponents. Along with D-type robustness **(C4)**, it implies the manifold is "attractive", and normally hyperbolic (see also Sec. S5.3.1).

If these four conditions hold, for example for task-trained RNNs, there exists a smooth function with a uniform norm matching the slowness on the manifold such that when added, the slow manifold becomes a continuous attractor (Prop. 1 and Theorem 7, see also Sec. S5.4). For the RNN experiments, we added state-noise while training using stochastic gradient descent, satisfying **(C3)** and **(C4)**. We have also verified that **(C2)** holds (Fig. 5A). Although the stochastic optimization cannot lead to _the_ continuous attractor solution, it gets to the neighborhood where all approximate solutions share the same main feature: having a subsystem that has a slow flow.

## 7 Discussion

Continuous attractors are highly prone to bifurcation under arbitrary perturbations unless they exist in special parametric forms. This sensitivity to perturbations has traditionally made them seem unsuitable for modeling neural computation in noisy biological systems, according to conventional views on robustness. Nevertheless, we demonstrate that continuous attractors can exhibit functional robustness, making them a crucial concept in explaining the neural computation underlying analog memory. We show that approximations of analog memory (i.e., theoretical models that satisfy conditions **(C1)**-**(C4)**) must possess slow manifold dynamics, placing them near continuous attractors within the space of dynamical systems. This implies that both biological systems and artificial neural networks only need to be near a continuous attractor to effectively solve problems in a manner similar to the ideal theoretical model, on behaviorally relevant timescales.

Although we expressed our theory in a non-parametric manner with an arbitrary perturbation \(()\), we can easily extend it to particular parametric forms such as biophysical models or an RNN using a sensitivity of the flow to the parameters (e.g. synaptic weight). Our theory can be applied to latent dynamical systems estimated from neural recordings . As a framework, it can abstract out the details in imperfect dynamical implementations, however, it is an open problem to directly recover the continuous attractor from neural recordings or extend it to other ideal computational motifs.

LimitationsAlthough, we only explicitly describe the topology and dimensionality of the identified invariant manifolds for a representative set, the results indicate that most solutions have a ring invariant manifold with a slow flow. Our numerical analysis relies on identifying a time scale separation from simulated trajectories. If the separation of time scales is too small, it may inadvertently identify parts of the state space that are only forward invariant (i.e., transient). However, this did not pose a problem in our analysis of the trained RNNs, which is unsurprising, as the separation is guaranteed by state noise robustness (due to injected state noise during training).

The possible solutions that the networks can find are restricted by having a linear output mapping. In Park et al. , an alternative dynamical solution using oscillators (or quasi-periodic toroidal attractor) was described, however, a nonlinear readout may be necessary.

## Code Availability

The code for this project is publicly available at [https://github.com/cathiplab/back_to_the_continuous_attractor](https://github.com/cathiplab/back_to_the_continuous_attractor).