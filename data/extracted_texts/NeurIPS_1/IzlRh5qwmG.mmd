# Swap Agnostic Learning,

or Characterizing Omniprediction via Multicalibration

 Parikshit Gopalan

Apple, Inc.

&Michael P. Kim

UC Berkeley

&Omer Reingold

Stanford University

###### Abstract

We introduce and study Swap Agnostic Learning. The problem can be phrased as a game between a _predictor_ and an _adversary_: first, the predictor selects a hypothesis \(h\); then, the adversary plays in response, and for each level set of the predictor \(\{x:h(x)=v\}\) selects a loss-minimizing hypothesis \(c_{v}\); the predictor wins if \(p\) competes with the adaptive adversary's loss. Despite the strength of the adversary, our main result demonstrates the feasibility Swap Agnostic Learning for any convex loss. Somewhat surprisingly, the result follows by proving an _equivalence_ between Swap Agnostic Learning and swap variants of the recent notions Omniprediction  and Multicalibration . Beyond this equivalence, we establish further connections to the literature on Outcome Indistinguishability [6; 14], revealing a unified notion of OI that captures all existing notions of omniprediction and multicalibration.

## 1 Introduction

Since its inception as an extension to Valiant's PAC framework [30; 19; 23], Agnostic Learning has been the central problem of supervised learning theory. Agnostic learning frames the task of supervised learning through loss minimization: given a loss function \(\), a hypothesis class \(\), and \( 0\), a predictor \(h\) is an agnostic learner if it achieves loss that competes with the minimal achievable within the hypothesis class.

\[[(,h())]_{c}\ [(,c())]+ \]

While the agnostic learning paradigm has been remarkably successful, in recent years, researchers have investigated alternative learning paradigms to address concerns of the modern prediction pipeline, including fairness and robustness. The work of  introduced _multicalibration_ as a new paradigm for learning fair predictors. Multicalibration asserts fairness as a first-order goal, requiring that predictions appear calibrated even conditioned on membership in one of a potentially-huge collection of subgroups \(\) of the domain.1 As a solution concept, multicalibration can be achieved efficiently using a weak learner for \(\) to identify subgroups where predictions are miscalibrated. In contrast to agnostic learning, multicalibration does not make reference to minimizing any loss.

Yet, it turns out that there are surprising connections between multicalibration and agnostic learning. This connection was first discovered in the work of , who introduced the notion of _omnipediction_ as a new solution concept in supervised learning. Intuitively, an omnipredictor is a single predictor that provides the agnostic learning guarantee for many losses simultaneously. More formally, for a collection of loss functions \(\) and a hypothesis class \(\), a predictor is an omnipredictor if _for any loss in the collection \(\)_, the predictions achieve loss that competes with the minimal achievablewithin the hypothesis class.2 The main result of  demonstrates that multicalibrated predictors are omnipredictors for \(_{}\) the class of all convex loss functions. In other words, the multicalibration framework is capable of guaranteeing agnostic learning in a very strong sense: learning a single multicalibrated predictor gives an agnostic learner, for every target convex loss \(_{}\). The results of  stand in contrast to the convential wisdom that optimizing predictions for different loss functions requires a separate training procedure for each loss.

On the surface, multicalibration seems like a fundamentally different approach to supervised learning than agnostic learning. The implication of omniprediction from multicalibration, however, suggests a deeper connection between the notions. In fact, follow-up work of  gave new constructions of omnipredictors (for different loss classes \(\)), similarly deriving the guarantees from variants of multicalibration. To summarize the state of the art, we have constructions of omnipredictors of various flavors, and all such constructions rely on some variant of multicalibration. While multicalibration suffices to guarantee omniprediction, a glaring question remains in the development of this theory: _Is multicalibration necessary for omniprediction?_ We investigate this question, exploring the connections between agnostic learning, notions of omniprediction, and multicalibration.

Our Contributions.In this work, we provide a new perspective that unifies these seemingly-incomparable paradigms for supervised learning. Key to this perspective, we introduce a new learning task, which we call Swap Agnostic Learning. This _swap_ variant of agnostic learning is inspired by the notion of swap regret in the online learning literature , where the learner must achieve vanishing regret, not simply overall, but even conditioned on their decisions. While swap agnostic learning is a natural extension, at first glance, it is a considerably stronger goal than standard agnostic learning. Nevertheless, our work demonstrates an efficient algorithm for swap agnostic learning for any convex loss function, leveraging only a weak agnostic learner for the hypothesis class. The algorithm follows by discovering a surprising connection: swap agnostic learning and swap variants of omniprediction and multicalibration are actually equivalent. In other words, once we move to swap variants, multicalibration _is_ necessary for omniprediction, and even for agnostic learning. We show how the original multicalibration algorithm of  actually guarantees the stronger goal of "swap multicalibration" (and thus, swap omniprediction and swap agnostic learning). Our results provide an exact characterization of these swap learning notions, as well as relationships between other learning desiderata explored in recent works .

Our motivation for introducing Swap Agnostic Learning comes from trying to understand the relationship between (standard) multicalibration and omniprediction. Prior work shows that multicalibration implies (convex) omniprediction, but leaves open the question of whether omniprediction implies multicalibration. The present work sheds new light on this question, suggesting that the answer is no: standard omniprediction does not imply multicalibration. The answer to this question comes by introducing the idea of Swap Learning, in the agnostic learning/omniprediction setting, as well as in multicalibration. Importantly, for multicalibration, Swap multicalibration and Standard multicalibration are essentially the same notion. Claim 2.9, as well as our analysis of prior algorithms for multicalibration, shows that standard multicalibration is already strong enough to capture the swap variant. The distinction (definitionally and algorithmically) between swap and standard multicalibration is minimal: our results suggest that one should really think of them as a single notion of multicalibration. For agnostic learning and omniprediction, however, Swap Learning is much stronger than Standard Learning. We prove separations between swap and standard omniprediction in Appendix B. The separations are summarized in figure 1. This tells us that (swap) multicalibration is equivalent to the stronger notion of swap omniprediction, which is provably stronger than standard omniprediction.

Organization.We continue the manuscript with formal setup and definitions of Swap Agnostic Learning, Swap Omniprediction, and Swap Multicalibration. Then, in our main result, we prove the equivalence of these notions. This equivalence suggests an efficient algorithm for Swap Agnostic Learning. We conclude with an overview of our other results, as well as related work and discussion. Throughout the manuscript, we include formal definitions of key notions and proofs of essential claims. We introduce the notion os swap loss OI which generalizes omniprediction in Section. InSection B, we dicuss the relation and show separatiosn between various notions of omniprediction. All omitted proofs of formal claims are included in the Appendix.

## 2 Formal Setup: Swap Notions of Supervised Learning

We work in the _agnostic_ learning setting, where we assume a data distribution \((,)\) supported on \(\{0,1\}\). The objects of study in agnostic learning are real-valued hypotheses \(h:\). Omniprediction and multicalibration study the special case of predictors \(:\) that map domain elements to probabilities. We denote the Bayes optimal predictor as \(p^{*}(x)=[=1|=x]\). As is standard in agnostic learning, we make no assumptions about the complexity of \(p^{*}:\). While, in principle, predictors and hypotheses may take on continuous values in \(\), we restrict our attention to functions supported on finitely-many values. We let \(()\) denote the set of values taken on by \((x)\).

Given a hypothesis \(h:\), it will be useful to imagine drawing samples from \(\) in two steps: first, we sample a prediction \(\) according to the distribution of \(h()\) under \(\); then, we draw the random variables \((,)\) according to the conditional distribution \(|h()=\). Accordingly, let \(_{h}\) denote the distribution of \(h()\) where \(\).

### Swap Agnostic Learning

Swap agnostic learning is defined with respect to a loss function \(:\{0,1\}\) and a hypothesis class \(\{c:\}\) and can be viewed as a game with two participants. The _predictor_ plays first and selects a hypothesis \(h:\). The _adversary_ plays in response: for each level set \(\{x:h(x)=v\}\), the adversary may choose a separate loss-minimizing hypothesis \(c_{v}\).

**Definition 2.1** (Swap Agnostic Learning).: _For a loss function \(\), hypothesis class \(\), and error \( 0\), a hypothesis \(h\) is a \((,,)\)-swap agnostic learner if_

\[[(,h())] _{h}}{}}[_{c_{v}}~{} [(,c_{v}() h()=] ]+. \]

We borrow nomenclature from online learning: a predictor using a swap agnostic learner \(h\) has no incentive to "swap" any of their fixed predictions \(h()=v\) to predict according to \(c_{v}\). Contrasting the requirement in (2) to that of agnostic learning in (1), we have switched the order of quantifiers, such that the minimization is taken after the expectation over the choice of \(h()=\). Swap agnostic learning strengthens standard agnostic learning, where the predictor only competes against the single best hypothesis \(c\).

Indeed, swap agnostic learning seems to be a much more stringent condition. Provided the class \(\) contains all constant functions, the adversary can simply imitate the predictor when \(h(x)=v\) by choosing \(c_{v}(x)=v\). For such \(\), (2) implies that imitation is the best strategy for the adversary.

### Swap Omniprediction

As in [15; 14], we observe that for any loss function \(\) and known distribution on outcomes \((p)\) for \(p\), there is an optimal action \(k_{}(p)\) that minimizes the expected loss \(\). Formally, we define the optimal post-processing of predictions by the function \(k_{}:\), which specifies the action that minimizes the expected loss.3

\[k_{}(p)=*{arg\,min}_{t} (p)}{}}[(,t)]. \]

This observation is particularly powerful because the function \(k_{}\) is given by a simple, univariate optimization that can be used as a data-free post-processing procedure on top of a predictor \(\).

We recall the original notion of omniprediction proposed by , which requires a predictor to yield an agnostic learner simultaneously for every loss in a collection \(\). Concretely, omniprediction requires that the function \(h_{}=k_{}\) is an \((,,)\)-agnostic learner for every \(\).

**Definition 2.2** (Omnipedictor, ).: _For a collection of loss functions \(\), a hypothesis class \(\), and error \(>0\), a predictor \(:\) is an \((,,)\)-omnipedictor if for every \(\),_

\[[(,k_{}(())]_{c }\ [(,c())]+. \]

We propose a strengthened notion of Swap Omniprediction, where the adversary may choose both the loss \(_{v}\) and hypothesis \(c_{v}\) based on the prediction \((x)=v\).

**Definition 2.3** (Swap Omnipredictor).: _For a collection of loss functions \(\), a hypothesis class \(\), and error \(>0\), a predictor \(:\) is a \((,,)\)-swap omnipredictor if for any assignment of loss functions \(\{_{v}\}_{v()}\),_

\[_{}}{}[[ _{}(,k_{_{}}(v))()=]]_{}}{ }[_{c_{v}}\ [_{}( ,c_{v}())()=]]+. \]

Swap omniprediction gives the adversary considerable power. For instance, the special case where we restrict the adversary's choice of losses to be constant, \(_{v}=\), realizes swap agnostic learning for \(\).

**Claim 2.4**.: _If \(\) is \(a\ (,,)\)-swap omnipredictor, it is a \((,,)\)-swap agnostic learner for every \(\), and hence a \((,,)\)-omnipedictor._

Analogous to the standard notions, swap omniprediction implies swap agnostic learning for every \(\); however, swap omniprediction gives an even stronger guarantee since the adversary's loss \(_{v}\) may be chosen in response to the prediction \(()=v\).

### Swap Multicalibration

Multicalibration was introduced in the work of  as a notion of algorithmic fairness following , but has since seen broad application across many learning applications (e.g., ). Informally, multicalibration requires predictions to appear calibrated, not simply overall, but also when we restrict our attention to subgroups within some broad collection \(\). The formulation below appears in .

**Definition 2.5** (Multicalibration, ).: _For a hypothesis class \(\) and \( 0\), a predictor \(:\) is \((,)\)-multicalibrated if_

\[_{c}\ _{}}{ }[c()(-) ()=]. \]

When \(c:\{0,1\}\) is Boolean (and has sufficiently large measure), this definition says that conditioned on \(c()=1\), the calibration violation is small, recovering the definition in .

Swap Multicalibration strengthens multicalibration, extending the pseudorandomness perspective on multicalibration developed in . Swap multicalibration requires that for the typical prediction \(_{}\), no hypothesis in \(c_{v}\) achieves good correlation with the residual labels \(-\) over \(\) conditioned on \(()=\).

**Definition 2.6** (Swap Multicalibration).: _For a hypothesis class \(\) and \( 0\), a predictor \(:\) is \((,)\)-swap multicalibrated if_

\[_{}}{}[_{c_{v} }\ [c_{v}()(-) ()=]\ ]. \]

Again, the difference between swap and standard multicalibration is in the order of quantifiers. The standard definition requires that for every \(c\), the correlation \(|\ _{_{}}[c()(-)]|\) achieved in small in expectation over \(_{}\). Swap multicalibration considers the maximum of \(|\ _{_{}}[c()(-)]|\) over all \(c\) for each fixing of \(=v\) and requires this to be small in expectation over \(_{}\). It follows that swap multicalibration implies standard multicalibration.

**Claim 2.7**.: _If \(\) is \((,)\)-swap multicalibrated, it is \((,)\)-multicalibrated._

While swap multicalibration is nominally a stronger notion that than standard multicalibration, the complexity of achieving swap multicalibration is essentially the same as multicalibration. We show that starting from a \((,)\)-multicalibrated predictor \(\), by suitably discretizing its values, we obtain a predictor that is close to \(\) and \((,^{})\)-swap multicalibrated, with some degradation in the value of \(^{}\)

**Definition 2.8**.: _Let \(\) so that \(m=1/\). Define \(B_{j}=[(j-1),j)\) for \(j[m-1]\) and \(B_{m}=[1-,1]\). Define the predictor \(_{}\) where for every \(x\) such that \((x) B_{j}\), \(_{}(x)=j\)._

**Claim 2.9**.: _Let \(:\) be a \((,)\)-multicalibrated. For any \(\) where \(1/\), the predictor \(_{}\) is \((,2+)\)-swap multicalibrated, and \(_{x}|(x)-_{}(x)|\)._

While the bound of the theorem is valid for all \(\), the swap multicalibration guarantee is only meaningful when \(()\). Thus, by discretizing a \((,)\)-multicalibrated predictor, we obtain a \((,O(^{1/3}))\)-swap multicalibrated predictor. While this generic transformation suffers a polynomial loss in the accuracy parameter, such a loss may not be algorithmically necessary. As we argue in Lemma 3.8, known algorithms for achieving multicalibration [20; 15] actually guarantee swap multicalibration without any modification.

## 3 An equivalence: swap agnostic learning, omniprediction, multicalibration

Our main result is an equivalence between swap agnostic learning, swap omniprediction, and swap multicalibration. Concretely, this equivalence shows that swap agnostic learning for the squared error is sufficient to guarantee swap omniprediction for all (nice) convex loss functions. We begin with some preliminaries, then formally state and prove the equivalence. We conclude the section by showing how to use the existing framework for learning multicalibrated predictors to achieve swap agnostic learning for any convex loss.

Nice loss functions.For a loss function \(:\{0,1\}\), we extend \(\) linearly to allow the first argument to take values in the range \(p\) as:

\[(p,t)=}_{(p)}[(, t)]=p(1,t)+(1-p)(0,t).\]

We say the loss function is _convex_ if for \(y\{0,1\}\), \((y,t)\) is a convex function of \(t\). By linearity, this convexity property holds for \((p,t)\) for all \(p\).

As in , for a loss \(\), we define the partial difference function \(:\) as

\[(t)=(1,t)-(0,t).\]

We define a class of "nice" loss functions, which obey a minimal set of boundedness and Lipschitzness conditions.

**Definition 3.1**.: _For a constant \(B>0\), a loss function is \(B\)-nice if there exists an interval \(I_{}\) such that the following conditions hold:_

1. _(Optimality) If_ \(_{}: I_{}\) _denotes projection onto the interval_ \(I_{}\)_, then_ \((p,_{}(t))(p,t)\) _for all_ \(t\) _and_ \(p\)_._
2. _(Lipschitzness) For_ \(y\{0,1\}\) _and_ \(t I_{}\)_,_ \((y,t)\) _is_ \(1\)_-Lipschitz as a function of_ \(t\)_._
3. _(Bounded difference) For_ \(t I_{}\)_,_ \(|(t)| B\)_._

_The class of all \(B\)-nice loss functions by \((B)\). The subset of \(B\)-nice convex loss functions is denoted by \(_{}}(B)\)._

Bounded loss functions generalize the idea of loss functions defined over a fixed interval of \(\) (by optimality) and of bounded output range (by bounded difference). By optimality of nice loss functions, we may assume \(k_{}: I_{}\) since we do not increase the loss by projection onto \(I_{}\). Indeed, for convex losses \(\), the natural choice for \(I_{}\) is to take the interval \([k_{}(0),k_{}(1)]\). The bounded difference condition implies that \(\) is Lipschitz in its first argument, a property that will be useful.

**Lemma 3.2**.: _For every \((B)\) and \(t_{0} I_{}\), the function \((p,t_{0})\) is \(B\)-Lipschitz as a function of \(p\)._

Concept classes.For a concept class of functions \(:\{c:\}\), we assume that \(\) is closed under negation, and it contains the constant functions \(0\) and \(1\). Denoting \(\|\|_{}=|c(x)|\) over \(c,x\), we say that \(\) is bounded if \(\|c\|_{} 1\). For \(W^{+}\), let \((,W)\) be all functions that can be expressed as a (\(W\)-sparse) linear combination of base concepts from \(\),

\[c_{w}(x)=_{c}w_{c} c(x),\ _{c}|w_{c}|  W.\]Note that for bounded \(\), the norm of linear combinations scales gracefully with the sparsity, \(\|(,W)\|_{} W\). We define \(()\) to be the set of all linear combinations with no restriction on the weights of the coefficients.

Notation.To simplify notation, we use the following shorthand for the data distribution \(\) conditioned on \(()=v\). For each \(v()\), let \(|_{v}\) denote the conditional distribution \(|()=v\). Combined with earlier notation, the distribution \(|_{}\) for \(_{}\) is simply the data distribution \(\). We also use the notation \(((),)=(v,y)\) to indicate \(()=v\) and \(=y\).

### Statement of Main Result

**Theorem 3.3**.: _Let \(\) be a predictor, \(\) be a bounded hypothesis class, and \(_{}}(B)\) be the class of \(B\)-nice convex loss functions. The following properties are equivalent:4_

1. \(\) _is_ \((,_{1})\)_-swap multiclibrated._
2. \(\) _is an_ \((_{}}(B),(,W),O((W+B) _{2}))\)_-swap omnipredictor, for all_ \(W 1,B 0\)_._
3. \(\) _is an_ \((_{2},(,2),_{3})\)_-swap agnostic learner._

In preparation for proving the theorem, we establish some preliminary results. We define a function \(:()[-1,1]\) which measures the maximum correlation between \(c\) and \(-v\), conditioned on a prediction value \(v()\). Let

\[(v)=|_{c_{v}}*{}_{ |_{v}}[c_{v}()(-v)]|.\]

Using this notation, \((,_{0})\)-swap multiclibration can be written as

\[*{}_{_{}}[( )]_{0}.\]

We observe that swap multicalibration is closed under bounded linear combinations of \(\), like with standard multicalibration.

**Claim 3.4**.: _For every \(h(,W)\) and \(v()\), we have_

\[_{h(,W)}|*{}_ {}[h()(-v)|()=v]| W (v).\]

_Let \(p_{v}^{*}=[|()=v]\). Then_

\[|p_{v}^{*}-v|(v). \]

Equation (8) follows since \(1\).

**Claim 3.5**.: _For \(h(,w)\), \(v()\) and \(y\{0,1\}\), define the following conditional expectations:_

\[(h:v) =[h()|()=v]\] \[(h:v,y) =[h()|((),)=(v,y )].\]

_Then for each \(y\{0,1\}\)_

\[[=y|()=v]|(h:v,y)-(h:v)|( W+1)(v). \]

Next we show the following lemma, which shows that one can replace \(h()\) by the constant \(_{}((h:v)))\) without a large increase in the loss.

**Lemma 3.6**.: _For all \(h(,W)\), \(v()\) and loss \(_{}}(B)\), we have_

\[*{}_{|_{v}}[(,_{}((h: v))]*{}_{|_{v}}[(,h( ))]+2(W+1)(v). \]In the interest of space, we defer the proof of the Lemma to the Appendix.

Next we compare \(_{}((h:v))\) with \(k_{}(v)\). It is clear that the latter is better for minimizing loss when \((v)\), by definition. We need to compare the losses when \((p_{v}^{*})\). But \(p_{v}^{*}\) and \(v\) are at most \((v)\) apart by Equation (8). Hence, by using Lipschitzness, one can infer that \(k_{}(v)\) is better than \(_{}((h:v))\) and hence \(h()\). This is formalized in the following lemma and its proof.

**Lemma 3.7**.: _For all \(v()\), \(_{}(B)\) and \(h(,W)\), we have_

\[}_{|_{v}}[(,k_{}( ()))]}_{|_{v}}[( ,h())]+2(W+B+1)(v). \]

Proof.: By the definition of \(k_{}\), \(k_{}(v)\) minimizes expected loss when \((v)\), so

\[(v,k_{}(v))(v,_{}((h:v)) \]

On the other hand,

\[}_{|_{v}}[(,t)]=(p_ {v}^{*},t),p_{v}^{*}=}_{|_{v}} [].\]

Thus our goal is compare the losses \((p_{v}^{*},t)\) for \(t=k_{}(v)\) and \(t=_{}((h:v))\). Hence, applying Lemma 3.2 gives

\[(p_{v}^{*},k_{}(v)) (v,k_{}(v))+(v)B\] \[-(p_{v}^{*},_{}((h:v)) -(v,_{}((h:v))+(v)B\]

Subtracting these inequalities and then using Equation (12) gives

\[(p_{v}^{*},k_{}(v))-(p_{v}^{*},_{}((h:v)) (v,k_{}(v))-(v,_{}((h:v))+2B(v) \] \[ 2(v)B. \]

We can now write

\[}_{|_{v}}[(,k_{ }(v))] =(p_{v}^{*},k_{}(v))\] \[(p_{v}^{*},_{}((h:v))+2(v)B\] (by Equation ( 14 ) \[=}_{|_{v}}[(,_{}( (h:v)))]+2(v)B\] \[}_{|_{v}}[(, h())]+2(W+1)(v)+2B(v).\] (by Equation ( 10 ))

We now complete the proof of Theorem 3.3.

Proof of Theorem 3.3.: (1) \(\) (2) Fix a \((,_{1})\)-swap multicalibrated predictor \(\). Fix a choice of loss functions \(\{_{v}_{}\}_{v(f)}\) and hypotheses \(\{h_{v}\}_{v(f)}\). For each \(v\), we apply Equation (11) with the loss \(=_{v}\), hypothesis \(h=h_{v}\) to get

\[}_{|_{v}}[_{v}(,k_{_{v}}(v ))]}_{|_{v}}[_{v}(,h _{v}())]+2(W+B+1)(v).\]

We now take expectations over \(_{}\), and use the \(}[()]_{1}\) to derive the desired implication.

(2) \(\) (3) with \(_{3}=7_{2}\) because \(_{2}\) is a \(1/2\)-nice loss function, so we plug in \(B=1/2\) and \(W=2\) into claim (2).

It remains to prove that \(()()\). We show the contrapositive, that if \(\) is not \(_{1}\) multicalibrated, then \(f=\) is not a \((_{2},(,2),_{3})\)-swap agnostic learner. By the definition of multicalibration, for every \(v()\), there exist \(c_{v}\) such that

\[}_{|_{v}}[c_{v}()( -())] =(v)\] \[}_{_{}}[( )] _{1}.\]

By negating \(c_{v}\) if needed, we may assume \((v) 0\) for all \(v\). We now define the updated hypothesis \(h^{}\) where

\[h^{}(x)=v+(v)c_{v}(x)x^{-1}(v)\]A standard calculation (included in the Appendix) shows that

\[}_{|_{}}[(-v)^{2}]-}_{|_{}}[(-h^{}())^{2}] (v)^{2}.\]

Taking expectation over \(_{}\), we have

\[}_{_{}}(}_{ |_{}}[(-v)^{2}]-}_{|_{}}[(-h^{}())^{2}])}_{_{}}[()^{2}]}_{_{}}[()]^{2}_{1}^{2}.\]

It remains to show that \(v+_{v}c_{v}(x)(,2)\). Note that

\[_{v}=}_{|_{}}[c()( -v)v]|c()|(|y-(x)| 1\]

since \(c(),y-v[-1,1]\). Hence \(h^{}(x)=w_{1} 1+w_{2}c(v)\) where \(|w_{1}|+|w_{2}| 2\). This contradicts the definition of an \((_{2},(,2),_{3})\)-swap agnostic learner if \(_{3}<_{1}^{2}\). 

### An algorithm for Swap Agnostic Learning

The equivalence from Theorem 3.3 suggests an immediate strategy for obtaining a swap agnostic learner. First, learn a swap multicalibrated predictor; then, return the predictor, post-processed to an optimal hypothesis according to \(\). While the \(\) algorithm of  was designed to guarantee multicalibration, we observe that, in fact, it actually guarantees swap multicalibration.

**Lemma 3.8**.: _Suppose the collection \(\) has a weak agnostic learner, \(\). For any \(>0\), \(\) makes at most \((1/)\) calls to \(_{}\), and returns a \((,)\)-swap multicalibrated predictor._

Weak agnostic learning is a basic supervised learning primitive used in boosting algorithms. Through the connection to boosting, weak agnostic learning is polynomial-time equivalent to agnostic learning, and inherits its data-efficiency (scaling with the VC-dimension of \(\)), but also its worst-case computational hardness . Importantly, however, \(\) reduces the problem of swap multicalibration (and thus, swap agnostic learning) to a standard agnostic learning task. We review \(\) weak agnostic learning formally in the Appendix.

In all, we can combine the \(\) algorithm for a class \(\) with a specific loss \(\) to obtain a \((,)\)-swap agnostic learner.

**Corollary 3.9** (Informal).: _For any (nice) convex loss \(\), hypothesis class \(\), and \(>0\), Algorithm 1 returns a \((,,)\)-swap agnostic learner from a sample of \(m()(1/)\) data points drawn from \(\), after making \((1/)\) calls to weak agnostic learner for \(\)._

## 4 Beyond Swap Agnostic Learning: Swap Loss Outcome Indistinguishability

In this we introduce a unified notion of Swap Loss Outcome Indistinguishability, which captures all of the other notions of mutlicalibration and omniprediction defined so far. The notion builds on a line of work due to [6; 7], which propose the notion of _Outcome Indistinguishability_ (OI) as a solution concept for supervised learning based on computational indistinguishability. In fact, the main result of  is an equivalence between OI and multicalibration. Despite the fact that OI is really multicalibration in disguise, the perspective has proved to be a useful technical perspective.

Key to this section is the prior work of . This work proposes a new variant of OI, called _Loss OI_. The main result of  derives novel omniprediction guarantees from loss OI. Further, they show how to achieve loss OI using only calibration and multiaccuracy over a class of functions derived from the loss class \(\) and hypothesis class \(\). As we'll see, this class plays a role in the study of swap loss OI: swap loss OI is equivalent to multicalibration over the augmented class.

Additional Preliminaries.Intuitively, OI requires that outcomes sampled from the predictive model \(\) are indistinguishable from Nature's outcomes. Formally, we use \((,^{*})\) to denote a sample from the true joint distribution over \(\{0,1\}\). Then, given a predictor \(\), we associate it with the random variable with \([}|x]=(x)\), i.e., where \(}|x((x))\). The variable \(}\) can be viewed as \(^{*}\)simulation of Nature's label \(^{*}\). In this section, we use \(\) to denote the joint distribution \((,^{*},})\), where \([^{*}|x]=p^{*}(x)\) and \([}|x]=(x)\). While the joint distribution of \((^{*},})\) is not important to us, for simplicity we assume they are independent given \(=x\).

### Swap Loss OI

The notion of loss outcome indistinguishability was introduced in the recent work of  with the motivation of understanding omniprediction from the perspective of outcome indistinguishability . Loss OI gives a strengthening of omniprediction. It requires predictors \(\) to fool a family \(\) of statistical tests \(u:\{0,1\}\) that take a point \(\), a prediction \(()\) and a label \(\{0,1\}\) as their arguments. The goal is distinguish between the scenarios where \(=^{*}\) is generated by _nature_ versus where \(=}\) is a simulation of nature according to the predictor \(\). Formally, we require that for every \(u\),

\[[u(,(),^{*})]_{ }[u(,(),})].\]

Loss OI specializes this to a specific family of tests arising in the analysis of omnipredictors.

**Definition 4.1** (Loss OI, ).: _For a collection of loss functions \(\), hypothesis class \(\), and \( 0\), define the family of tests \((,)=\{u_{,c}\}_{,c }\) where_

\[u_{,c}(x,v,y)=(y,k_{}(v))-(y,c(x)). \]

_A predictor \(:\) is \((,,)\)-loss OI if for every \(u(,)\), it holds that_

\[|,^{*})}{}[u( ,(),^{*})]-, })()}{}[u(, (),})]|. \]

 show that loss-OI implies omniprediction.

**Lemma 4.2** (Proposition 4.5, ).: _If the predictor \(\) is \((,,)\)-loss OI, then it is an \((,,)\)-omnipredictor._

Indeed, if the expected value of \(u\) is nonpositive for all \(u(,)\), then \(\) must achieve loss competitive with all \(c\). The argument leverages the fact that \(u\) must be nonpositive when \(}(())\)--after all, in this world \(\) is the Bayes optimal. By indistinguishability, \(\) must also be optimal in the world where outcomes are drawn as \(^{*}\). The converse, however, is not always true.

Next, we introduce swap loss OI, which allows the choice of distinguisher to depend on the predicted value.

**Definition 4.3** (Swap Loss OI).: _For a collection of loss functions \(\), hypothesis class \(\) and \( 0\), for an assignment of loss functions \(\{_{v}\}_{v()}\) and hypotheses \(\{h_{v}\}_{v()}\), denote \(u_{v}=u_{_{v},c_{v}}(,)\). A predictor \(\) is \((,,)\)-swap loss OI if for all such assignments,_

\[_{}}{}|}{}[u_{}(,,^ {*})-u_{}(,,})]|.\]

The notion generalizes both swap omniprediction and loss-OI simultaneously.

**Lemma 4.4**.: _If the predictor \(\) satisfies \((,,)\)-swap loss OI, then_

* _it is an_ \((,,)\)_-swap omnipredictor._
* _it is_ \((,,)\)_-loss OI._

This Section continues as Section A in the Appendix, where we show the following characterization of loss OI.

**Theorem 4.5**.: _Let \(\) be a family of nice loss functions containing the squared loss. For any hypothesis class \(\), a predictor satisfies \((,)\)-swap loss OI if and only if it is \(()\)-swap multicalibrated, where \(=\{ c\}_{ ,c}\)._Related Work and Discussion

Independent concurrent work.The notion of strict multicalibration was defined in independent work of . They connect this and other multigroup fairness definitions to various versions of the Szemeredi regularity lemma  and its weaker version due to Frieze and Kannan , following . Their notions bears important similarities to swap multicalibration, but it is different. Like swap multicalibration, strict multicalibration involves switching the order of expectations and max. But they require a statistical closeness guarantee, whereas we only require a _first order guarantee_, that \(c()\) be uncorrelated with \(-\) conditioned on \(\).

The independent work of  relates multicalibration to real-valued boosting ot minimize \(_{2}\) loss. The implication that \((_{2},)\) swap-agnostic learning implies multicalibration follows from Part(1) of Theorem 3.2 in their paper. They prove that a violation of multicalibration leads to a better strategy for the adversary in the \((_{2},)\)-swap minimization game. They do not consider the notion of swap multicalibration, so their result is not a tight characterization unlike ours.

Multi-group fairness and regret minimization.Notions of multi-group fairness were introduced in the work of  and , following . The flagship notion of multicalibration has been extended to several other settings including multiclass predictions , real-valued labels , online learning  and importance weights . Alternate definitions and extensions of the standard notions of multicalibration have been proposed in . Multicalibration has also proved to have unexpected connections to many other domains, including computational indistinguishability , domain adaptation , and boosting .

Our notions of swap loss minimization and swap omniprediction are inspired by notions of swap regret minimization in online learning . The classic results of  relate calibration and swap regret, whereas  show a generic way to convert a low external regret algorithm to ones with low internal and swap regret. The study of online learning and regret minimization is extensive, with deep connections to calibration and equilibria in game theory, we refer the readers to  for comprehensive surveys. Recent work has established rich connections between online learning and regret minimization on one hand, and multigroup fairness notions on the other. Multicalibration has been considered in the online setting by , while  relate multigroup fairness to questions in online learning.

Conclusion.Our work adds a new and significant connection in the theory of agnostic learning and multi-group fairness. This theoretical work relies on a few basic assumptions, including access to a representative unbiased data source and a weak agnostic learner for the collection \(\). These assumptions, while standard in the supervised learning literature, should be interrogated before applying mutal calibration as a notion of fairness in a practical setting.

Perhaps the most interesting aspect of our work is the connections it draws across different areas of learning theory. In particular, by borrowing the notion of swapping from online learning, we uncover surprisingly-powerful, but feasible solution concepts for supervised learning. The equivalence we draw between swap agnostic learning for the squared error and multicalibration with swap omniprediction _for all convex losses_ highlights the power of simple goals like squared error minimization and calibration.

Our work gives a complete characterization of the notions we study at the "upper end" of strength (i.e., swap variants). A fascinating outstanding question to address in future research is whether there is a similar characterization of _standard_ omniprediction in terms of multi-group fairness notions.

Acknowledgements.Omer Reingold is supported by the Simons Foundation Collaboration on the Theory of Algorithmic Fairness, the Simons Foundation investigator award 689988 and Sloan Foundation grant 2020-13941.