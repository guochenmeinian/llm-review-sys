# Score-Optimal Diffusion Schedules

Christopher Williams

Department of Statistics

University of Oxford

&Andrew Campbell

Department of Statistics

University of Oxford

&Arnaud Doucet

Department of Statistics

University of Oxford

&Saifuddin Syed

Department of Statistics

University of Oxford

{williams,campbell,doucet,saifuddin.syed}@stats.ox.ac.uk

###### Abstract

Denoising diffusion models (DDMs) offer a flexible framework for sampling from high dimensional data distributions. DDMs generate a path of probability distributions interpolating between a reference Gaussian distribution and a data distribution by incrementally injecting noise into the data. To numerically simulate the sampling process, a discretisation schedule from the reference back towards clean data must be chosen. An appropriate discretisation schedule is crucial to obtain high quality samples. However, beyond hand crafted heuristics, a general method for choosing this schedule remains elusive. This paper presents a novel algorithm for adaptively selecting an optimal discretisation schedule with respect to a cost that we derive. Our cost measures the work done by the simulation procedure to transport samples from one point in the diffusion path to the next. Our method does not require hyperparameter tuning and adapts to the dynamics and geometry of the diffusion path. Our algorithm only involves the evaluation of the estimated Stein score, making it scalable to existing pre-trained models at inference time and online during training. We find that our learned schedule recovers performant schedules previously only discovered through manual search and obtains competitive FID scores on image datasets.

## 1 Introduction

Denoising Diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2021) or DDMs are state-of-the-art generative models. They are formulated through considering a forward noising process that interpolates from the target to a reference Gaussian distribution by gradually introducing noise into an empirical data distribution. Simulating the time reversal of this process then produces samples from the data distribution. Specifically, we evolve data distribution \(p_{0}\) through the _forward diffusion_ process on time interval \(\), described by

\[X_{t}=f(t)X_{t}t+g(t)W_{t}, X_{0} p_{ 0}, \]

with drift \(f(t)X_{t}\), diffusion coefficient \(g(t)\) and Brownian noise increment \(W_{t}\). The coefficients \(f(t)\) and \(g(t)\) are chosen such that at time \(t=1\) the distribution of \(X_{1}\) is very close to a reference Gaussian distribution \(p_{1}\) in distribution. A sample starting at \(p_{0}\) and following Equation (1) until time \(t\) will be distributed according to \(p_{t}\) which is a mollified version of the data distribution

\[p_{t}(x_{t})=_{X_{0}}p_{0}(x_{0})p_{t|0}(x_{t}|x_{0})x_{0}, p _{t|0}(x_{t}|x_{0})=(x_{t};s(t)x_{0},^{2}(t)I). \]The parameters \(s(t)\) and \(^{2}(t)\) define the _noising schedule_. They can be found in closed form in terms of \(f(t)\) and \(g(t)\)(Karras et al., 2022). To obtain samples from \(p_{0}\), we can reverse the dynamics of the forward diffusion in Equation (1) to obtain the _backward diffusion_,

\[X_{t}=(f(t)X_{t}-g(t)^{2}_{x} p_{t}(X_{t})) t+g(t)_{t}, X_{1} p_{1}. \]

By simulating Equation (3) backwards in time, we evolve reference samples \(X_{1} p_{1}\) from \(t=1\) to \(t=0\) to obtain samples that are terminally distributed according to the data distribution \(p_{0}\). To simulate Equation (3) numerically, we must decide upon a discretisation of time, \(=\{t_{i}\}_{i=0}^{T}\) with \(t_{T}=1\), \(t_{0}=0\), which we refer to as the _discretisation schedule_. For a given noising schedule, it is important to select an appropriate discretisation schedule such that (3) can be simulated accurately, i.e. \(p_{t_{i}}\) and \(p_{t_{i-1}}\) should not differ significantly. In this paper, we derive a methodology to compute an optimal discretisation schedule.

Prior work has often joined together the choice of noising schedule and discretisation schedule. A uniform splitting of time would be chosen, \(t_{i}=i/T\), with the noising schedule dictating the change between \(p_{t_{i}}\) and \(p_{t_{i-1}}\). Two prominent examples have the form \(s(t)=(t)}\), \(^{2}(t)=1-(t)\) with the _linear schedule_ introduced by Ho et al. (2020) having \((t)=1--_{0}^{t}(s)s\) with linear \((t)=_{}+t(_{}-_{})\). Alternatively, Nichol and Dhariwal (2021) introduce the _cosine schedule_ with \((t)=f(t)/f(0)\), \(f(t)=^{2}\) for \(=0.008\). Karras et al. (2022) refines this approach by splitting the choice of noising schedule from that of the discretisation schedule, however, picking the discretisation schedule is still a matter of hyperparameter tuning.

A good discretisation schedule can drastically impact the efficiency of the training and inference of the generative model, but unfortunately can be difficult to select for complex target distributions. For example, for a distribution supported on the Cantor set (Figure 1, left), the default linear schedule fails entirely to capture the modes of the data distribution (Figure 1, middle). However, our optimised schedule learned using Algorithm 1 recovers these modes (Figure 1, right). Without such an automatic algorithm, finding performant discretisation schedules often reduces to an expensive and laborious hyperparameter sweep.

We devise a method for selecting a discretisation schedule that yields high-quality samples from \(p_{0}\). Our key contribution is defining an appropriate notion of cost incurred when simulating from one step in the diffusion path to the next. We then choose our discretisation schedule to minimise the total cost incurred when simulating the entire path from \(p_{1}\) to \(p_{0}\). Our cost purely depends on the distributional shifts along the diffusion path and assumes perfect score estimation, hence, we refer to our schedules as _score-optimal diffusion schedules_. The resulting algorithm is cheap to compute, easy to implement and requires no hyperparameter search. Our algorithm can be applied to find discretisation schedules for sampling pre-trained models as well as performed online during DDM training. We demonstrate our proposed method on highly complex 1D distributions and show our method scales to high dimensional image data where it recovers previously known performant discretisation schedules discovered only through manual hyperparameter search. To the best of our knowledge, this is the first online data-dependent adaptive discretisation schedule tuning algorithm.

Figure 1: Density estimates of the mollified Cantor distribution (left) using a DDM with schedule \(=\{t_{i}\}_{i=0}^{100}\) generated with \(100\) linearly spaces discretisation times \(t_{i}=i/100\) (middle), compared to the optimised schedule \(^{*}=\{t_{i}^{*}\}_{i=0}^{50}\) with \(50\) discretisation times \(t_{i}^{*}\) generated by Algorithm 1 (right). The eight modes present in our true mollified distribution are shown in grey on each plot.

The Cost of Traversing the Diffusion Path

To derive our optimal discretisation schedule, we first need to derive a notion of cost of traversing from our reference distribution \(p_{1}\) to the data distribution \(p_{0}\) through each intermediate distribution \(p_{t}\), referred to as the diffusion path. We will then later find the discretisation schedule that minimises the total cost of traversing this path. Our notion of cost is based on the idea that while integrating Equation (3) from time \(t\) to \(t^{}\) will always take you from \(p_{t}\) to \(p_{t^{}}\), the simulation step will need to do more work to make sure the samples are distributed according to \(p_{t^{}}\) if \(p_{t}\) and \(p_{t^{}}\) are very different distributions rather than if they are close. In the following, we will make this intuition precise.

### Predictor/Corrector Decomposition of the Diffusion Update

To begin, let \(=^{d}\) and \(()\) be the space of Lebesgue probability measures on \(\) with smooth densities. For \(t\), define the diffusion path \(p_{t}()\) as the law of \(X_{t}\) satisfying the forward diffusion Equation (1) initialised at the data distribution \(X_{0} p_{0}\), or equivalently the law of the \(X_{t}\) satisfying the backward diffusion Equation (3) initialised at the reference distribution \(X_{1} p_{1}\).

Given a sample \(X_{t} p_{t}\), a sample \(X_{t^{}} p_{t^{}}\) can be generated by integrating the backward diffusion Equation (3). In Song et al. (2021), it was shown that we can further decompose the backward diffusion Equation (3) at time \(t\) into a deterministic flow governed by the probability flow ODE, and the stochastic flow driven by Langevin dynamics targeting \(p_{t}\),

\[X_{t}=f(t)X_{t}-g(t)^{2} p _{t}(X_{t})t}_{}+g(t)^{2} p_{t}(X_{t})t+g(t)_{t}}_{}. \]

This decomposition into a deterministic flow and a correction will help us derive our cost in Section 2.2 by analysing the work done by the correction to keep the samples on the diffusion path. Here, we will first expand upon this decomposition by defining a hypothetical two-step sampling procedure that could be used to sample the DDM. It consists of: (1) a _predictor step_ that generates a deterministic prediction of \(X_{t^{}}\) and (2) _a corrector step_ that uses Langevin dynamics targeting \(p_{t^{}}\) to correct any accrued error. Note we are not advocating for the implementation of such a procedure, only that by imagining simulating with this hypothetical predictor-corrector algorithm, it will be helpful for our theoretical derivation of a cost intrinsically linked to the sampling of DDMs. The two stages of the predictor-corrector algorithm are rigorously defined as follows.

**Definition 2.1**.: _A predictor for \(t,t^{}\) is a smooth bijective mapping \(F_{t,t^{}}:\), such that \( F_{t,t^{}} 0\), and the predicted distribution is the pushforward of \(p_{t}\) by \(F_{t,t^{}}\) denoted \(F_{t,t^{}}^{}p_{t}\)._

**Definition 2.2**.: _A corrector for \(t,[0,)\) is a one-parameter family Markov transition kernel \(L_{t,}:()\) such that \(Z_{} L_{t,}(z,z_{})\) is the law of Langevin dynamics stationary distribution \(p_{t}\) at time \(\), initialised at \(z\), and running at speed \(v(t)>0\),_

\[Z_{0}=z,Z_{}=v(t) p_{t}(Z_{})+ W_{}. \]

The corrector map \(L_{t,}\) is specified through an integration time \(\) and time-dependent speed \(v(t)\). We assume \(\) is fixed and we will describe the appropriate choice of \(v(t)\) in Section 3.3. The predictor-corrector algorithm, given \(X_{t} p_{t}\), first applies the predictor \(Z_{0}=F_{t,t^{}}(X_{t})\) and then uses the corrector to drive the predicted samples towards \(p_{t^{}}\),

\[ Z_{0}=F_{t,t^{}}(X_{t})  X_{t^{},} L_{t^{},}(Z_{0},x_{}). \]

In general, \(Z_{0}\) will not be a sample from \(p_{t^{}}\) exactly because \(F_{t,t^{}}\) may not be a perfect transport from \(p_{t}\) to \(p_{t^{}}\). In Section 2.2, assessing the work done by \(L_{t^{},}\) to drive the \(Z_{0}\) towards \(p_{t^{}}\) will be key in deriving our cost. Our cost will then depend upon the specific choice for \(F_{t,t^{}}\). Two natural choices for \(F_{t,t^{}}\) are apparent. Setting \(F_{t,t^{}}\) to the identity means our hypothetical sampling algorithm reduces to the annealed Langevin algorithm for DDMs introduced by Song and Ermon (2019). The second natural choice is to set \(F_{t,t^{}}\) to the integrator of the probability flow ODE (Song et al., 2021).

**Example 2.1** (Annealed Langevin).: The predictor step is trivial when the predictor map is the identity \(F_{t,t^{}}(x)=x\). In such a case, the predicted state reduces to the initial state, \(F_{t,t^{}}(X_{t})=X_{t} p_{t}\). The work done by the corrector step will then be related to the full discrepancy between \(p_{t}\) and \(p_{t^{}}\) because the predictor provides no help in transporting the sample.

**Example 2.2** (Probability Flow ODE).: The predictor step is optimal when \(F_{t,t^{}}\) is a transport from \(p_{t}\) to \(p_{t^{}}\). In such a case, the predicted state produces a sample from the target distribution, \(F_{t,t^{}}(X_{t}) p_{t^{}}\), and so the corrector step would have to perform no work. An optimal predictor map \(F_{t,t^{}}\) can be obtained by integrating the probability flow ODE from time \(t,t^{}\),

\[x_{t}}{t}=f(t)x_{t}-g(t)^{2} p_ {t}(x_{t}). \]

Practical algorithms numerically integrate Equation (7), e.g. an Euler step with \( t=t^{}-t\),

\[F_{t,t^{}}(x)=x+f(t)x-g(t)^{2} p_{t}(x)  t. \]

In such a case, the work done by the corrector depends on the error in the probability flow integrator.

### The Incremental Cost of Correction

We now focus on deriving a cost related to the work done by the corrector step in the predictor-corrector algorithm. Later, in Section 3, we will find the discretisation schedule that minimises the total cost. To derive the cost, we will analyse the movement of \(Z_{0}\) under the corrector step's dynamics \(L_{t^{},}(Z_{0},x_{})\). This requires some care because even if \(Z_{0}\) is already at stationarity, i.e. perfectly distributed according to \(p_{t^{}}\), applying the Langevin correction step will still result in movement of \(Z_{0}\) due to the stochasticity of the update. However, the computed _work_ done by the correction step in this case should be \(0\). To correctly assign the _work_ done, we will compare two processes. The first is the trajectory of Langevin dynamics, \(_{}\), defined by the corrector \(L_{t^{},}\) initialised at \(Z_{0}=F_{t,t^{}}(X_{t})\) targeting \(p_{t^{}}\). The second is a virtual coupled Langevin dynamics \(_{}\) initialised at \(F_{t,t^{}}(X_{t})\), driven by the same noise and speed but targeting the stationary distribution of the predictor \(F_{t,t^{}}^{}p_{t}\),

\[Z_{0} =F_{t,t^{}}(X_{t}),Z_{}=v(t^{})  p_{t^{}}(Z_{})+)} W_{}, \] \[_{0} =F_{t,t^{}}(X_{t}),_{}=v(t^{ }) F_{t,t^{}}^{}p_{t}(_{}) +)}W_{}. \]

Notably, \(Z_{}}{{=}}X_{t^{},}\) and \(_{}}{{=}}F_{t,t^{}}(X_{t})\) share the same law as the corrected sample and predicted sample respectively. Since \(Z_{}\) and \(_{}\) are coupled to have the same noise, the difference in their trajectory, \(Z_{}-_{}\), isolates the change in corrector dynamics due to discrepancy between \(F_{t,t^{}}^{}p_{t}\) and \(p_{t^{}}\). If \(F_{t,t^{}}^{}p_{t}\) is very different to \(p_{t^{}}\), then \(Z_{}-_{}\) will be large, signifying the corrector is needing to do lots of work to push the distribution of \(Z\) towards the target \(p_{t^{}}\). Conversely, if \(F_{t,t^{}}^{}p_{t}=p_{t^{}}\), then \(Z_{}-_{}=0\) and no work is done. For small \(\), \((Z_{}-Z_{0})/\) is the initial velocity of \(Z\) under the \(p_{t^{}}\) corrector dynamics, and similarly for \((_{}-Z_{0})/\). We can then define the _incremental cost_\((t,t^{})\) by taking limits as \( 0^{+}\), measuring the expected \(L^{2}\) norm \(\|\|\) of the difference,

\[(t,t^{})=_{ 0^{+}}^{-2}} [\|(Z_{}-Z_{0})-(_{}-Z_{0})\|^{2}]= _{ 0^{+}}^{-2}}[\|Z_{}- _{}\|^{2}]. \]

We can approximate \(Z_{}-_{}\) using an Euler step, noting that the coupled noise terms cancel,

\[Z_{}-_{}= v(t^{})( p_{t^{}}(Z_{t,t^ {}})- F_{t,t^{}}^{}p_{t}(Z_{t,t^{}}))+o(). \]

By substituting Equation (12) in Equation (11), we have

\[(t,t^{})=v(t^{})^{2}[\| p _{t^{}}(Z_{0})- F_{t,t^{}}^{}p_{t}(Z_{0})\| ^{2}]=v(t^{})^{2}D(p_{t^{}}\|F_{t,t^{}}^{}p_{t}), \]

where \(D(p\|q)=_{X q}[\| p(X)- q(X)\|^{2}]\) is a statistical divergence on \(p,q()\), measuring the \(L^{2}\) distance between the scores of \(q\) and \(p\) with respect \(q\). \(D(p\|q)\) is referred to as the Stein divergence or the Fisher divergence; see e.g. (Johnson, 2004). For a given choice of \(v(t)\) and \(F_{t,t^{}}\) we now have a cost measuring the change from \(p_{t}\) to \(p_{t^{}}\). This cost is intrinsically linked with the effort performed by a DDM sampling algorithm because it is derived through considering the work done by a hypothetical predictor-corrector style update. We note, however, that this general cost can be used to obtain discretisation schedules for use in any style of DDM sampler.

### Corrector and Predictor Optimised Cost

By inverting \(Z_{0}=F_{t,t^{}}(X_{t})\), we can express Equation (13) in terms of an expectation with respect to the reference sample \(X_{t} p_{t}\), and the score of \(G_{t,t^{}}:_{+}\), the incremental weight function associated with the transport \(F_{t,t^{}}\) from the Sequential Monte Carlo literature (Arbel et al., 2021),

\[(t,t^{})=v(t^{})^{2}[\| G_{ t,t^{}}(X_{t})\|^{2}], G_{t,t^{}}(x)=}(F_{t,t^{}}(x))}{p_{t}(x)}| F_{t,t^{}}(x) |. \]

In most cases, it is infeasible to efficiently compute the Jacobian correction in Equation (14). When \(F_{t,t^{}}(x)=x\) is the identity map corresponding to the corrector optimised update from Example 2.1 Equation (14) reduces a rescaled Stein discrepancy between \(p_{t}\) and \(p_{t^{}}\), and \(G_{t,t}(x)=p_{t^{}}(x)/p_{t}(x)\) reduces to the likelihood-ratio between \(p_{t^{}}\) and \(p_{t}\). We will refer to this case as the _corrector-optimised cost_ denoted \(_{c}(t,t^{})\), to distinguished it from the _predictor-optimised cost_\(_{p}(t,t^{})\) derived above, where when relevant, we will use subscripts \(c\) and \(p\) to distinguish between the two:

\[_{c}(t,t^{})=v(t^{})^{2}D(p_{t^{}}\|p_{t}), _{p}(t,t^{})=v(t^{})^{2}D(p_{t^{}}\|F_{t,t^{ }}^{}p_{t}). \]

The corrector-optimised cost \(_{c}(t,t^{})\) provides meaningful information during the update from reference \(p_{t}\) to the target \(p_{t^{}}\). It is worth computing even when the predictor-optimised cost \(_{p}(t,t^{})\) is accessible. \(_{c}(t,t^{})\) measures the change between the reference and target distribution independent of the predictor, whereas \(_{p}(t,t^{})\) measures the residual error between the predictor and target. Notably, \(_{c}(t,t^{})\) encodes information about the incremental geometry of the diffusion path, whereas \(_{p}(t,t^{})\) quantifies information about the incremental efficiency of the predictor. Generally, one does not dominate the other, but if the predictor is well-tuned and the predictor flows samples \(X_{t} p_{t}\) towards \(p_{t^{}}\), we would expect \(_{p}(t,t^{})_{c}(t,t^{})\).

For deriving our optimal discretisation schedule, we require a notion of how \((t,t^{})\) increases with small increases in \(t^{}\) i.e. knowing local changes in incremental cost. In Section 3, we use this _local cost_ to assign _distances_ to schedules through time, enabling us to find the best schedule. We derive the desired local cost in Theorem 2.1, see Appendix A for a PDE and geometric interpretation.

**Theorem 2.1**.: _Suppose \(p_{t}(x),F_{t,t^{}}(x),v(t)\) and \(G_{t,t^{}}(x)\) are three-times continuously differentiable in \(t,t^{},x\) and let \(_{t}(x)=}F_{t,t^{}}(x) _{t^{}=t}\) and \(_{t}(x)=}G_{t,t^{}}(x) _{t^{}=t}\). Suppose the following hold: (1) for all \(x,t\), \(F_{t,t}(x)=x\) and (2) there exists \(V:\) such that for all \(x\) and \(t\), \(\|_{t}(x)\|^{2} V(x)\) and \(_{t}_{X_{t} p_{t}}[V(X_{t})]<\). Then for all \(t\), we have \((t,t^{})=(t) t^{2}+O( t^{3})\), where_

\[(t)=v(t)^{2}_{X_{t} p_{t}}[\|_{t}(X _{t})\|^{2}],_{t}= p_ {t}+ p_{t}_{t}+_{t}. \]

Theorem 2.1 shows that, under regularity assumptions, then the incremental cost is \((t,t^{})(t) t^{2}\) is locally quadratic and controlled by the local cost \((t)\). The \((t)\) measures the sensitivity of the incremental cost \((t,t^{})\) to moving samples along the diffusion path to \(t^{} t\). Notably, \((t)=0\) if and only if the predictor satisfies the continuity equation, \(p_{t}+(p_{t}_{t})=0\).

## 3 Score-Optimal Schedules

Given a discretisation schedule \(=(t_{i})_{i=0}^{T}\) satisfying \(0=t_{0}<<t_{T}=1\), our hypothetical predictor-corrector algorithm recursively uses the predictor and corrector maps to generate a sequence \((X_{i})_{i=0}^{T}\) starting at \(X_{T} p_{1}\) such that the terminal state \(X_{0}\) approximates samples from \(p_{0}\),

\[X_{i} L_{t_{i},}(F_{t_{i+1},t_{i}}(X_{i+1}),x_{i}). \]

We want to identify a discretisation schedule that maximises the efficiency of this iterative procedure. This is not generally possible due to the potential complex interactions that arise from the accrued errors. To simplify our analysis, we make the following assumption.

**Assumption 3.1**.: _For all \(t,t^{}\), if \(X_{t} p_{t}\) and \(X_{t^{},}=L_{t^{},}(F_{t,t^{}}(X_{t}),x_{ })\), then \(X_{t^{},} p_{t^{}}\)._

Assumption 3.1 is reasonable if, in our hypothetical corrector steps, \(\) is set sufficiently large such that the Langevin correction converges to stationarity. We find in our experiments that even if theschedules derived under Assumption 3.1 are used in sampling algorithms for which Assumption 3.1 does not hold, we still obtain high quality samples. Equipped with Assumption 3.1, we can measure the efficiency of the path update through total accumulated cost \(=_{i=1}^{T}(t_{i+1},t_{i})\), which we will use as our objective to optimise \(\). In this section, we will identify the optimal schedule \(^{*}\) minimising the cost \(\) by considering an infinitely dense limit. We will then provide a tuning procedure amenable to online schedule optimisation during training. Finally, we will discuss a suitable choice for \(v(t)\), the velocity of our hypothetical corrector steps, as well as related work.

### Diffusion Schedule Path Length and Energy

Let \(:\) be a strictly increasing, differentiable function such that \((0)=0\) and \((1)=1\). We will say \(\) is generated by \(\) if \(t_{i}=(i/T)\) for all \(i=0,,T\). The schedule generator \(\) dictates how fast our samples move through their diffusion path. Since every schedule \(\) of size \(T\) is generated by some \(\), optimising \(\) is equivalent to finding a generator \(\) minimising \((,T)\), the total cost accumulated by the schedule of size \(T\) generated by \(\). By Jensen's inequality, we have \((,T)(,T)^{2}/T\), where for \(t_{i}=(i/T)\),

\[(,T):=_{i=1}^{T}(t_{i+1},t_{i}), (,T)=_{i=1}^{T}(t_{i+1},t_{i})}. \]

As we later prove in Theorem 3.1, in the dense schedule limit as \(T\), the cost \((,T)\) and its lower bound \((,T)\) are controlled by the _energy_\(E()\) and _length_\(\) respectively where,

\[E()=_{0}^{1}((s))(s)^{2}s, =_{0}^{1}t. \]

The intuition for why \(E()\) is an energy, and \(\) a length can be gained by first conceptualising the diffusion time \(t\) as a spatial variable rescaled by the metric \((t)\) defined by our cost \(\). We have \(\) and \(\) are position and velocity, respectively. Integrating the speed \(_{0}^{1}(s)s=_{0}^{1} t\) along a curve \((s)\) obtains the "length" \(\), whilst integrating a speed squared, \(_{0}^{1}((s))(s)^{2}s\) obtains a "kinetic energy" \(E()\). Note that the length is an invariant of the schedule, whereas the kinetic energy is not. The length \(\) measures the intrinsic difficulty of traversing the diffusion path according to the cost independent of \(\), whereas \(E()\) measures the efficiency of how the path was traversed using \(\). This geometric intuition hints at the solution to the optimal scheduling problem. The optimal \(\) should travel on a geodesic path from \(p_{1}\) to \(p_{0}\), at a constant speed with respect to metric \(\). For this optimal \(\), we then have the kinetic energy being equal to the square of length between \(p_{1}\) and \(p_{0}\). Theorem 3.1 makes the previous discussion precise.

**Theorem 3.1**.: _Suppose the assumptions of Theorem 2.1 hold. For all schedule generators \(\),_

\[_{T}T(,T)=E(),_{T} (,T)=. \]

_Moreover, \(E()^{2}\), with equality if and only if \(^{*}\) satisfies,_

\[^{*}(s)=^{-1}( s),(t)=_{0}^{t}u. \]

Notably independent of the choice of \(\), as \(T\), the cost \((,T) E()/T\). This implies that the cost decays to zero at a linear rate, proportional to \(E()\) and \((,T)^{2}/T\) independent of \(\). Equation (21) provides an explicit formula for the optimal schedule generator that minimises the dense limit of the total cost and obtains the lower bound \(E(^{*})=^{2}\). The intuition for the formula \(^{*}(s)=^{-1}( s)\) is that this implies \((^{*}(s))= s\) meaning say \(10\%\) of the way through the optimal schedule, we should have traversed \(10\%\) of the way along the distance between \(p_{1}\) and \(p_{0}\) i.e. \(0.1\). This relation holds for constant speed straight lines, meaning \(^{*}\) is the optimal schedule. For a finite \(T\), Theorem 2.1 implies the optimal schedule \(^{*}=\{t_{i}^{*}\}_{i=0}^{T}\) generated by \(^{*}\) ensures the incremental cost is constant \((t_{i+1}^{*},t_{i}^{*})^{2}/T^{2}\) for all \(i=0,,T-1\).

Our geometric intuition in the language of differential geometry is that the diffusion path \(=\{p_{t}\}_{t}\) is Riemannian manifold with metric \(\) endowed by the incremental cost \((t,t^{})\). The schedule generator defines a curve \(s p_{(s)}\) reparametrising the diffusion path between \(p_{0}\) and \(p_{1}\). Theorem 3.1 shows that \(^{*}\) is the geodesic of length \(\) in \(\) between \(p_{1}\) and \(p_{0}\) that traverses the diffusion path at a constant speed \((s))}^{*}(s)=\) with respect to \(\) and minimises the cost.

### Estimation of Score-Optimal Schedules

Given a schedule \(=\{t_{i}\}_{i=0}^{T}\) and estimates of the incremental cost \((t_{i+1},t_{i})\), Algorithm 1 adapts Algorithm 3 from Syed et al. (2021) to estimate the optimal schedule \(^{*}=\{t_{i}^{*}\}_{i=0}^{T}\) generated by \(^{*}\). We can use Algorithm 1 to refine the schedule for a pre-trained DDM or learn the schedule jointly with the score function. For this joint procedure, we detail in Appendix B.1 how function evaluations can be reused to estimate the cost to minimise computational overhead. For \(_{c}(t,t^{})\) we need only evaluate \( p_{t}(X_{t})\) and \( p_{t^{}}(X_{t})\) both available through our model's score estimate. Computing \(_{p}(t,t^{})\) is more challenging since there are Hessian terms that arise in Equation (14). Under the assumption that the step size \( t>0\) is sufficiently small, we can approximate \(| F_{t,t^{}}(X_{t})|\) through Proposition B.1. This approximation only requires us to compute the gradient trace of the Jacobian of our predicted score. With computational cost proportionate to the computational effort for computing the first derivative. Using a Hutchinson trace (Hutchinson, 1989) like estimator in Proposition B.1, we compute this quantity memory-efficiently in high dimensions, requiring only standard auto-differentiation back-propagation.

### Choice of Velocity Scaling

Recall that our cost is derived by considering a Langevin dynamics step with velocity \(v(t)\). This velocity should be selected so that Langevin dynamics explores the same proportion of our distribution at varying times throughout our diffusion path. Thus, \(v(t)\) should be on the same scale as the spread of the target, \(p_{t}\). Commonly used noising schedules have \(s(t) 1\), and our data distribution is normalised so the scale of \(p_{t}\) is on the order of \((t)\). We therefore set \(v(t)=(t)\). This results in a \((t^{})\)-weighted divergence for our incremental cost \((t,t^{})=(t^{})^{2}D(p_{t^{}}||p_{t})\). This can be compared to the weighted denoising score matching loss used to train DDMs (Song et al., 2021), which is also a squared norm of score differences: \((t)_{X_{0},X_{t}}[\|s_{}(X_{t},t)- p_{t |}(X_{t}|X_{0})\|^{2}]\) for some weighting function \((t)\) chosen to equalise the magnitude of the cost over the path. In Song et al. (2021), \((t) 1/[\| p_{t|0}(X_{t}|X_{0})\|^{2}]\) was chosen, which, as we show in Appendix B.3, is \((t)^{2}(t)\). This choice of velocity scaling provides an alternative perspective on this commonly used weighting of squared norms of score differences.

```
1:Schedule \(=\{t_{i}\}_{i=0}^{T}\), incremental costs \(\{(t_{i+1},t_{i})\}_{i=0}^{T-1}\)
2:\((t_{i})=_{j=0}^{i-1}(t_{j+1},t_{j})}, i =0, T\)\(\) Equation (21);
3:\(=(t_{T})\)\(\)\(\) in Equation (19)
4:\(^{-1}()=(\{((t_{0}),t_{0}), ,((t_{T}),t_{T})\})\); \(\) E.g. Fritsch and Carlson (1980)
5:\(t_{i}^{*}=^{-1}(), i=0,,T\)\(\) Equation (21)
6:Return:\(^{*}=\{t_{i}^{*}\}_{i=0}^{T}\)
```

**Algorithm 1**UpdateSchedule

### Related Work

Previous works have devised algorithms and heuristics for designing noising and discretisation schedules. The DDM training objective is invariant to the noising schedule shape, as demonstrated by Kingma et al. (2021), necessitating auxiliary costs and objectives for schedule design. Uniform steps in the signal-to-noise ratio, \()/(t_{i}))}\), are used by Lu et al. (2022), but this ignores the target distribution's geometry. Watson et al. (2021) optimise the schedule by differentiating through sampling to maximise quality, but GPU memory constraints necessitate gradient rematerialisation. We avoid this with a simulation-free cost. Closely related to our work is Sabour et al. (2024), who minimise a pathwise KL-divergence between discretised and continuous processes. They require multi-stage optimisation with early stopping to prevent over-optimisation of their objective which would otherwise result in worse schedules. Amongst the wider literature, various strategies for discretisation schedule tuning have been proposed. Das et al. (2023) derive an equally spaced schedule using the Fisher metric but assume Gaussian data. Santos et al. (2023) assign time points proportional to the Fisher information of \(p_{t|0}(x_{t} x_{0})\), ignoring the true target distribution. Xue et al. (2024) derive a schedule to control ODE simulation error, but their cost depends only on the ODE solver, and not on the data distribution.

Computational Experiments

### Sampling the Mollified Cantor Distribution

The Cantor distribution (Cantor, 1884) lacks a Lebesgue density, with its cumulative distribution function represented by the Devil's staircase and its support being the Cantor set, forming a challenging 1-D test example. When mollified with Gaussian noise, it becomes absolutely continuous and possesses a Stein score. We mollify by running a diffusion with the linear schedule for time \(t=10^{-5}\). With this mollification, our data density has eight pronounced peaks. We train a one-dimensional DDM for 150,000 iterations using both a fixed linear schedule and our optimisation algorithm Algorithm 2 initialised at the linear schedule. We find that the non-data-specific default schedule fails to capture these modes, whilst our adaptive method faithfully reproduces the data distribution. In Figure 7 we show the complexity of the learned score which displays a self-similar fractal structure.

### Adaptive Schedule Learning for Bimodal Example

We train a DDM on a simple bimodal Gaussian distribution. When the variance of the target bimodal Gaussian is low, it becomes difficult to adequately sample from the target distribution. In our instance, the standard Gaussian reference from the diffusion is given, and the target is the density \(p_{0}(x)=p_{}(x)+p_{}(x)\), where \(p_{}\) and \(p_{}\) are normal distributions with means \(-6\) and \(6\), respectively, and a common variance \(^{2}=0.1^{2}\).

We learn two diffusion models, one using the linear schedule, and the other using a schedule that is learned online during training. We compute the likelihood of the samples generated from either model during training, which is possible in this example because the true probability density is known. It can be seen in Figure 2 that when the schedule is learned during training, the likelihood evaluation increases and the true score error decreases, in contrast to the linear schedule that remains constant, or worsens, in this regard during training.

### Scalable Schedule Learning Diffusion

Here we demonstrate that jointly learning the schedule and score using our online training methodology (Algorithm 2) scales to high-dimensional data and converges to a stable solution. We train DDMs on CIFAR-10 and MNIST initialised at the cosine schedule using the codebase from Nichol and Dhariwal (2021). In Figure 3 (left), we show the incremental costs \((t_{j+1},t_{j})}\) for the cosine schedule and our learned schedule, finding that the increments approximately equalise over the diffusion path as expected by the discussion in Section 3.1. Figure 3 (right) shows the learned schedule spends more time at high-frequency details, we visualise a sampling trajectory in Figure 11.

Figure 2: Comparison of Linear and Learned Schedules over Training Iterations for the bimodal example. Each point corresponds to 500 training iterations.

### Sampling Pre-Trained Models

In this experiment we demonstrate that our algorithm can recover performant schedules for large image models used in practice and our schedules generate high quality samples. We use the pre-trained models from Karras et al. (2022), whose DDM is parameterised such that the forward noising distribution is of the form \(p_{t|0}(x_{t}|x_{0})=(x_{t};x_{0},_{t}^{2}I)\). The scheduling problem then reduces to deciding on a stepping scheme through \(\{_{i}\}_{i=1}^{N}\), \(_{N}=0\). Karras et al. (2022) suggest a polynomial based schedule with a parameter \(\) that controls the curvature of the schedule

\[_{i<N}=(_{}^{}+ _{}^{}-_{}^{})^{ }_{N}=0. \]

   Schedule & CIFAR-10 & FFHQ & AFHQv2 & ImageNet \\  Eq (22) \(=3\) & \(5.47\) & \(2.80\) & \(\) & \(1.46\) \\ Eq (22) \(=7\) & \(\) & \(2.46\) & \(\) & \(\) \\ LogLinear (Lu et al., 2022) & \(2.05\) & \(\) & \(2.06\) & \(1.45\) \\ Convex Schedule & \(22.1\) & \(2.43\) & \(2.48\) & \(1.64\) \\  Corrector optimised & \(1.99\) & \(2.46\) & \(\) & \(1.44\) \\ Predictor optimised & \(1.99\) & \(2.48\) & \(\) & - \\   

Table 1: Sample quality measured by Fréchet Inception Distance (FID) versus schedule on CIFAR10 (\(32 32\)), FFHQ, AFHQv2, ImageNet (\(64 64\)). Pretrained models are used from Karras et al. (2022). All FIDs are calculated using 50000 samples. We highlight the best FID in **bold**. The ImageNet model lacks second-order differentiation, so no predictor optimised schedule is shown.

Figure 4: (**Left**) Costs associated with different schedule choices for the CIFAR10 dataset. Schedules are ordered from lowest FID to highest FID. We compare our Corrector-optimised (CO) cost and Predictor-optimised (PO) cost versus the Kullback-Leibler Upper Bound (KLUB) from Sabour et al. (2024). The minimum value for each cost is highlighted in **bold**. Note low cost is associated with low FID for our cost and not for the KLUB. (**Right**) Visualisation of schedules during generative sampling with \(100\) timesteps. “rho=3” and “rho=7” refer to Eq 22 with \(=3\) and \(=7\) respectively. LogLinear from Lu et al. (2022) and a convex schedule are also shown. We show our cost optimised schedules for CIFAR10 both using the corrector optimised cost and the predictor optimised cost.

Figure 3: (**Left**) Incremental costs \((t_{j+1},t_{j})}\) for the cosine schedule and our online adaptive algorithm. Higher learning rates enforce equalisation of costs more quickly. (**Right**) Progression of the learned schedule during 40k training iterations, depicted through the standard-deviation \(_{t}}\).

A lower \(\) value results in steps near \(_{}\) being shortened and steps near \(_{}\) being lengthened. Through analysing the truncation error for sampling in Karras et al. (2022), they find that setting \(=3\) approximately equalises this error, however it is found empirically that \(=7\) results in better sample quality. We also compare against a schedule that takes uniform steps in \(\) space Lu et al. (2022) which we refer to as the LogLinear schedule and a schedule that takes a convex shape in log space. Schedule visualisations are provided in Figure 4 (right).

We sampled the pre-trained models using these schedules and computed the sample quality using FID. We use the same number of schedule steps (18 for CIFAR10, 40 for FFHQ and AFHQv2, 256 for ImageNet) and solver (Heun second order) as Karras et al. (2022). Our results are shown in Figure 4. Our optimised schedules are able to achieve competitive FID to the best performing \(=7\) schedule hand-tuned in Karras et al. (2022). This is expected as our schedules take a similar shape to the \(=7\) schedule as shown in Figure 4 (right). Therefore, our method provides an entirely automatic and hyperparameter free algorithm to recover this performant schedule that was previously only discovered through trial-and-error.

We further analyse how the number of discretisation points, \(T\), used during sampling affects the quality of generated samples for different schedules. We report our results on CIFAR10 in Table 2. Notably, the FID decreases with \(T\) for all schedules and achieves comparable FID once \(T\) is large enough. However, when \(T\) is small, only the optimised schedules maintain stable performance. This empirically demonstrates an optimised schedule can improve the sampling efficiency by allowing for coarser discretisations and, hence, faster sampling, as predicted by Theorem 3.1. We observe an identical trend for sFID in Table 3 in the Appendix C.2.

We also compare corrector optimised schedules to predictor optimised schedules in Table 1. They provide similar performance so, on image datasets, we encourage the use of the cheaper to compute corrector optimised schedule. Finally, in Figure 4 (left), we report the raw values of our corrector optimised costs and compare these costs to the values of the objective introduced in Sabour et al. (2024). Both algorithms aim to find schedules that minimise these costs and therefore it is desirable for low values of cost to be associated with good sample quality (i.e. low FID). We find that low values of our cost correlate much more closely with low FID than the objective introduced by Sabour et al. (2024). Indeed, Sabour et al. (2024) introduce a bespoke multi-stage optimisation for their cost because they found over-optimising their objective can lead to worse schedules which is explained by the objective not correlating well with FID. We further find that our predictor optimised costs are lower than the corrector optimised costs which is to be expected as the predictor reduces the work done by the corrector and thus reduces the incremental cost. The overall shape of schedule, however, between the corrector optimised and predictor optimised costs is similar.

## 5 Discussion

We have introduced a method for selecting an optimal DDM discretisation schedule by minimising a cost linked to the work done in transporting samples along the diffusion path. Our algorithm is computationally cheap and does not require hyperparameter tuning. Our learned schedule achieves competitive FID scores. Regarding limitations, the computation of \(_{p}\) can be computationally expensive due the calculation of second derivatives, however, in Section 4.4 we found \(_{c}\) to provide a cheap and performant alternative. Furthermore, our theory is derived assuming perfect score estimation. Future work can expand on the geometric interpretation of the diffusion path and links to information geometry to further refine the DDM methodology.

   \# points, \(T\) & **10** & **20** & **30** & **50** & **100** \\  CO (ours) & **2.46** & \(2.02\) & **2.04** & \(2.06\) & \(2.07\) \\ \(=3\) & \(50.75\) & \(3.92\) & \(2.09\) & **2.01** & **2.05** \\ \(=7\) & \(2.70\) & **2.00** & \(2.06\) & \(2.05\) & \(2.07\) \\ \(=100\) & \(3.09\) & \(2.06\) & \(2.05\) & \(2.06\) & \(2.07\) \\   

Table 2: Comparison of FID across different amounts of discretisation points for different schedules on CIFAR10. CO stands for our corrector optimised schedule.