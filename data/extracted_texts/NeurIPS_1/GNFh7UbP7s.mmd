# Efficient Local Unlearning for Gaussian Processes

with Out-of-Distribution Data

 Juliusz Ziomek

University of Oxford

{firstname}@robots.ox.ac.uk

&Ilija Bogunovic

University College London

###### Abstract

Gaussian Processes (GPs) offer robust uncertainty estimates crucial for data-efficient applications like Black-box Optimization or Model Predictive Control. However, when the underlying function changes, previously gathered data can mislead predictions, impacting performance. Instead of indiscriminately removing all data points (or a large fraction) after detecting a change, the goal is to efficiently identify and remove only the obsolete data points, a process we refer to as unlearning in GPs. Leveraging the model's uncertainty estimates, we transform the unlearning problem into one of maximizing variance (nearly reverting to GP prior values) at detected change points by selectively removing the most informative training points. Though the exact solution to this problem is NP-hard, we propose an efficient algorithm that approximates the optimal solution while significantly reducing computational complexity. This algorithm utilizes novel fast _reverse update_ equations for GP models, enabling linear-time sequential computation of the posterior variance function with removed training points.We test the performance of our unlearning procedure across various tasks, including Model Predictive Control, Transfer Bayesian Optimization, and Time-Varying Bayesian Optimization. Our approach offers a comprehensive solution for handling out-of-distribution issues in GP modeling, _significantly_ outperforming baseline methods.

## 1 Introduction

Gaussian Processes (GPs)  are a class of models used to estimate a function over a domain of interest based on limited observations of that function's values. Because of good uncertainty estimates, GPs found applications in domains, where the agent needs to be data-efficient and actively query for new data points, such as Black-box Optimisation or Model Predictive Control. However, if the target function is non-stationary or undergoes a one-time change, some previously gathered data may become obsolete. This out-of-distribution data can mislead the model, resulting in incorrect predictions and reduced task performance. One naive solution to this problem is to remove all data points once we realize the function we wish to model has changed. However, this approach can be very wasteful, especially if the change occurs in only a small domain region, leaving much of the training data still valid. Instead, by observing discrepancies between model predictions and actual observed values, we can pinpoint the obsolete data points that influenced those erroneous predictions and remove them from the training set. Given that GPs provide uncertainty estimates, this problem can be reframed as removing training points to maximize the GP variance at the points where we detected function changes. We refer to this process as _local unlearning_ in GPs and address this specific problem setting.

Identifying a small number of data points to remove is, unfortunately, an NP-hard problem . It requires considering all possible combinations of training points to remove in order to find the one that maximizes the variance at desired points. Combined with the cubic complexity of fitting a GPmodel, this makes the exact solution computationally infeasible. However, in this paper, we present an _efficient_ algorithm that approximates the solution in a fraction of the time required for an exact combinatorial search. We derive _fast reverse update equations_ for GPs, allowing us to compute the variance function with a given training point removed at a computational cost that is only linear in the number of training points. We provide a performance guarantee for this algorithm and state its time complexity. We then demonstrate how the algorithm can address distribution shifts in Model Predictive Control tasks, Transfer Bayesian Optimization, and Time-Varying Bayesian Optimization.

**Related Work:** The problem of transferring data between tasks using Gaussian Processes has also been extensively explored in the context of Multi-Task GPs [3; 9; 13] and transfer Bayesian Optimization (BO) [14; 17]. These studies typically assume that the training tasks share similarities with the target task. Our work tackles an issue in which some previously gathered data may be misspecified, shifting our focus from data transfer to effectively performing unlearning.

Efficient forward posterior updates in Gaussian Processes are commonly employed, especially in sequential Bayesian optimization (see, e.g., Appendix F in ). However, to the best of our knowledge, there is limited understanding regarding efficient reverse updates in GPs (i.e., computing posterior updates after removing observations).  introduced a method for computing the downgraded Cholesky matrix that scales quadratically with the number of observations. While downgrading the Cholesky matrix allows for predictive variance calculations at any point, our equations provide a time complexity advantage when predictive variance is needed only at a limited number of fixed points.

## 2 Efficient unlearning

Assume a problem setting when we use the GP model with the posterior predictive variance function defined as \(_{}^{2}(x)=k(x,x)-_{}^{T}(_{}+^{2}I_{||})^{-1}_{}\), where \(_{}^{T}\) with elements \((_{})_{i}=k(x,x_{i})\) and \(_{}^{T T}\) with entries \((_{})_{i,j}=k(x_{i},x_{j})\). Let \(\) be a set of points in a input domain \(\) for which we detected anomalies. We thus aim for our uncertainty estimate at those points to revert (almost) to its prior state, as though no learning had occurred. However, we note that for typically used kernels, such as RBF or Matern, for any two points in the input domain \(x,x^{}\) we have that \(k(x,x^{})>0\). As a result, if we want to revert variance exactly to the prior, we need to remove all of the training points. As such, we instead wish to be \(\)-close to the prior variance. We define this concept formally below.

**Definition 2.1**.: _For a specified unlearning set \(\) and unlearning precision \(>0\), let \(_{}^{2}(x)\) represent the model's current estimate based on the complete dataset \(\). The goal of unlearning generating is to select a set of points subset \(\) to remove to produce a new estimate of posterior variance \(_{}^{2}(x)\), such that:_

\[_{}||\  u \ _{}^{2}(u)_{ }^{2}(u)-,\]

_where \(_{}^{2}(x)\) corresponds to the prior GP variance._

Note that the optimisation constraint can also be written in an equivalent form: \(g_{}()=g_{,}\), where the following function

\[g_{}()=_{u}(\{_{ }^{2}(u),_{}^{2}(u)-\}- \{_{}^{2}(u),_{}^{2}(u)-\}) \]

is the _variance gain_ function and \(g_{,}=_{u}\{_{}^{2 }(u)--_{}^{2}(u),0\}\) is the maximum variance gain. Notice that we can think about \(g_{,}\) as a type of loss function. The quantity \(g_{,}\) tells us how what is the maximum variance gain we can still achieve after we have already removed a set of points \(\). Ideally, after we remove the chosen set of points, we would like this quantity to be as small as possible. However, solving this problem is, in general, NP-hard, which means the exact solution requires combinatorial time complexity. We will show how the solution to this problem can be efficiently approximated with a greedy algorithm. Such a greedy algorithm at each timestep will remove the point \(\) that produces greatest variance increase, i.e. \(_{x}g_{} (\{x\})\). However, to compute \(g_{}(\{x\})\) efficiently, we need to derive fast downgrade equations, which we do next.

Assuming we have access to the model matrix \(^{}=(K_{}+^{2}I_{||})^{-1}\) for datapoints in \(\), we will now show how one can quickly compute the variance function for the model with a datapointremoved. We also show how the model matrix \(^{}\) itself can be efficiently downgraded, once we decide on the point we want to remove at a given iteration. Without the loss of generality, we will assume the point we want to remove is the last point with an index of \(T\). We now present equations allowing for fast computations of reverse updates in a GP.

\[^{2}_{\{x_{T}\}}(u) =^{2}_{}(u)+}_{T,T} }(^{T}_{}^{}_{T,1:T})^{2} \] \[^{\{x_{T}\}} =^{}_{1:T-1,1:T-1}-}_{ 1:T-1,T}^{}_{T,1:T-1}}{^{}_{T,T}}, \]

where \(^{}_{T,1:T}\) is the \(T\)th column of \(^{}\) corresponding to point \(x_{T}\) and \(^{}_{T,T}\) is the \(T\)th diagonal entry in \(^{}\). We derive those equations in Appendix B. We now propose our efficient GP unlearning procedure in Algorithm 1. At each iteration of the while loop, the Algorithm (greedily) removes the point that produces the highest increase in variance. To find that point, the Algorithm iterates through all points by the for loop in lines 4-7. In line 5, the Algorithm uses fast reverse updates for the GP to measure the variance value at a given point in \(\) given that the point in question is removed.

```
0: unlearning set \(\), Training Data Points \(\), Unlearning precision \(\), Stopping criterion \(\), Mean and Variance of Original Model \(_{}()\), \(^{2}_{}()\), Inverted Model Matrix \(^{}\)
1: Initialise set for removed points \(=\)
2:while\(g_{,}> g_{,}\)do
3: For each \(u\) compute \(^{2}_{}(x)=k(x,x)-^{T}_{ }(_{} +^{2}I_{||})^{-1}_{ }\)
4:for each datapoint \(x\)do
5: For each \(u\) compute \(^{2}_{(\{x\})}(u)\) given \(^{2}_{}(u)\) by using Equation 2
6: Use \(^{2}_{}(u)\) to compute \(g_{}(\{x\})\) and store it
7:endfor
8: Find the next point to remove \(x=_{x}g_{}(\{x\})\)
9: Compute new inverted model matrix \(^{(\{x\})}\) given the old \(^{}\) using Equation 3
10: Compute \(g_{(\{x\}),}=g_{ ,}-g_{}(\{x\})\)
11: Add this point to the set of removed points \(:=\{x\}\)
12:endwhile
```

**Algorithm 1** Efficient unlearning algorithm

In Appendix D we show that the running time of Algorithm 1 is \((||^{4}|||^{}|)\). Additionally we have the following result (which we prove in Appendix C) on the performance of the algorithm.

**Theorem 2.2**.: _Assume the variance decrease function \(F_{x}():=^{2}_{}(x)-^{2}_{s}(x)\) is submodular. Let \(_{}\) be the set of points removed by the greedy algorithm until a \(\)-approximation to the optimal solution can be found, that is \(g_{_{},} g_{ ^{},}\). We then have that:_

\[|_{}||^{}|,\]

_where \(^{}\) is the optimal solution to problem statement in Definition 2.1._

The assumption of submodularity of \(F_{x}()\) is standard  and prior work established conditions that guarantee it. As such, we see that a greedy algorithm can achieve \(1-\) of the maximum possible variance gain while removing only \(\) more points than the exact algorithm. We now proceed to show how our algorithm can be applied in practical problem settings.

## 3 Experiments

We implemented our experiments in Python. We share our code via the following _anonymised_ link1. See details of each experiment in Appendix A. On each experiment, we classify an observation as an anomaly if it lies outside of the \(95\)% confidence interval.

### Time varying Bayesian Optimisation

We perform time-varying Bayesian Optimisation on the Intel Research Dataset 2. The dataset consists of temperature recordings gathered over 50 sensors placed in the Intel office in Berkeley. Our goal is to select the sensor with the highest temperature at each timestep and the regret is the difference between the highest and selected temperature. We show results in Figure 2. The baselines, we compared against are keeping all points (Keep All) and sliding window (SW) algorithms  with windows sizes of 5 and 10. We can see that after around iteration 40 all other methods start to underperform compared to unlearning and at around iteration 80 they suffer a drastic jump in the average regret values. Inspecting the number of points kept by unlearning at each iteration, we see that our algorithm removes almost all datapoints around iteration 40 and after that almost all new points are kept. This would imply that the underlying function experienced a change around that iteration and after that remained relatively stable. The SW algorithms appear to be suffering from catastrophic forgetting, whereas the baseline keeping all of the points is using obsolete data from before the function change.

### Transfer Bayesian Optimisation

Next, we consider the problem of transferring data from one BO problem to another, we describe the details in Appendix A. We show the results in Figure 2 As baselines, we use the TAF method of , as well as the two state-of-the-art Multi-Task GP baselines proposed by , namely WSGP and SHGP. We can see that utilising prior data gives a head start to the method, compared to optimising the hyperparameters from scratch. However, the method that simply keeps all data points quickly gets stuck at a sub-optimal solution and eventually gets outperformed by the optimiser that does not use prior data. On the other hand, our unlearning algorithm is able to converge to the same optimum as the freshly initialised optimiser, but much faster. Inspecting the number of points kept by the unlearning algorithm, we see that it removes most of the points except for 10-20, which seem crucial to the completion of the task. TAF method is unable to converge within the number of iterations tried, whereas WSGP and SHGP converge to similar solutions as unlearning, but at a slower pace.

### Model Predictive Control with Domain Shifts

We consider two control problems that experience a domain shift. The first one is a modification of the cart pole problem, where after a number of iterations half of the ground becomes frozen, increasing the breaking distance. The second problem is rusty pendulum, where at some point the bearings become rusty and the maximum torque that can be applied on one side of the pendulum is reduced. We show the average returns on both problems after the change occurred in Figure 2(a)

Figure 1: Results on the Time-Varying BO experiments on the Intel Reserach Dataset. Left subplot shows average regret at each iteration for all algorithms and the right plot shows the number of points that the unlearning algorithm kept (i.e. have not removed) against the iteration. Shaded areas are standard erros over six seeds.

and 3b. Two baselines we compare against are keeping all data points (Keep All) and removing all data after the change has occurred (From Scratch). On the Frozen Cartpole problem, we see that the unlearning algorithm does not get stuck at the suboptimal return values, unlike the algorithm keeping all points. At the same time, in early iterations, its return is much higher than the algorithm learning from scratch. On the Rusty Pendulum problem, within the training episodes, the unlearning algorithm reaches optimal return faster than learning from scratch and is more stable than the strategy keeping all points.

## 4 Conclusions

Within this paper, we addressed the important problem of local unlearning in GP, necessitated by domain shifts in the underlying function we wish to model. We developed an efficient approximation to the otherwise computationally expensive problem and showed how it can be applied to a number of real-world problems involving GPs. One limitation of our work is that we only considered standard GP models. When dealing with large of datapoints, a typical practice is to switch to sparse GP . Extending our framework to deal with sparse models constitutes an exciting direction for future work.