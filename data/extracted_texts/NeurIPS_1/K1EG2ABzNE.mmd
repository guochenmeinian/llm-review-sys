# Image Reconstruction Via Autoencoding Sequential Deep Image Prior

Ismail R. Alkhouri\({}^{*}\)\({}^{1,2}\), Shijun Liang\({}^{*}\)\({}^{3}\),

**Evan Bell\({}^{1}\)**, **Qing Qu\({}^{2}\)**, **Rongrong Wang\({}^{1,4}\)**, **Saiprasad Ravishankar\({}^{1,3}\)**

\({}^{1}\)Department of Computational Mathematics, Science, & Engineering, Michigan State University

\({}^{2}\)Department of Electrical Engineering & Computer Science, University of Michigan - Ann Arbor

\({}^{3}\)Department of Biomedical Engineering, Michigan State University

\({}^{4}\)Department of Mathematics, Michigan State University

{alkhour3,liangs16,belleval,wangron6,ravisha3}@msu.edu

{ismail,qingqu}@umich.edu

Equal contribution.

###### Abstract

Recently, Deep Image Prior (DIP) has emerged as an effective unsupervised one-shot learner, delivering competitive results across various image recovery problems. This method only requires the noisy measurements and a forward operator, relying solely on deep networks initialized with random noise to learn and restore the structure of the data. However, DIP is notorious for its vulnerability to overfitting due to the overparameterization of the network. Building upon insights into the impact of the DIP input and drawing inspiration from the gradual denoising process in cutting-edge diffusion models, we introduce Autoencoding Sequential DIP (aSeqDIP) for image reconstruction. This method progressively denoises and reconstructs the image through a sequential optimization of network weights. This is achieved using an input-adaptive DIP objective, combined with an autoencoding regularization term. Compared to diffusion models, our method does not require training data and outperforms other DIP-based methods in mitigating noise overfitting while maintaining a similar number of parameter updates as Vanilla DIP. Through extensive experiments, we validate the effectiveness of our method in various image reconstruction tasks, such as MRI and CT reconstruction, as well as in image restoration tasks like image denoising, inpainting, and non-linear deblurring. Our code is available at the GitHub repository aSeqDIP.

## 1 Introduction

Inverse imaging problems arise across various real-world applications . These include tasks such as image denoising , image deblurring , restoring missing portions of images  (in-painting), super-resolution , magnetic resonance imaging (MRI) , and reconstructing X-ray computed tomography (CT) scans . The common challenge in these scenarios is the reconstruction of images from limited and/or corrupted measurements.

Recently, a plethora of Deep Neural Network (DNN) techniques have emerged to solve inverse imaging problems, including supervised models that are trained to process measurements and generate estimates approximating the true image . Generative model, such as Diffusion models (DMs) , have shown state-of-the-art (SOTA) performance in various imaging inverse problems such as the works in . However, training diffusion models is not only computationally expensive but also demands a significant amount of clean (or fully-sampled) data points , limitingtheir application to data-limited or data-corrupted tasks such as in medical imaging (MRI and CT). To address this challenge, previous DM-based MRI and CT methods typically fine-tune pre-trained DMs (trained on natural images) using limited fully-sampled data points, which are not as readily available as natural images [14; 15]. As such, there is a pressing need to develop methods that can alleviate the reliance on large, clean datasets and/or pre-trained models.

One well-known method is Deep Image Prior (DIP) , which does not require pre-trained models and relies on the parameters of an architecture (e.g., U-Net ). DIP finds a solution without needing any data other than the limited/corrupted task-specific measurements and the forward operator. DIP has shown competitive reconstruction/restoration results in inverse imaging problems such as MRI  and image denoising . However, DIP (and most of its variants) suffer from the problem of overfitting.

In this paper, we introduce Autoencoding Sequential DIP (aSeqDIP) to mitigate noise overfitting artifacts. Our approach comprises a sequential update of network weights. A significant advantage of our approach, in contrast to DM-based methods, is its ability to operate without the need for training data or pre-trained models, thus fitting into the framework of _dataless_ training . Notably, the total number of parameter updates in aSeqDIP remains equivalent to that of Vanilla DIP . Furthermore, unlike a recent work , aSeqDIP eliminates the need for gradient-based input updates.

Contributions:
* Building upon an insight about the impact of the DIP network input, we introduce Autoencoding Sequential DIP (aSeqDIP), which incorporates a U-Net architecture whose weights are updated sequentially. These updates are based on objective functions that consist of (_i_) an input-adaptive data consistency term and (_ii_) an autoencoding regularization term used for noise overfitting mitigation.
* Our extensive experimental evaluations, in terms of standard image reconstruction metrics and required run-time, highlight the superior (or competitive) performance of aSeqDIP compared to DIP-based and leading DM-based methods for the tasks of MRI and CT reconstruction, denoising, in-painting, and non-linear deblurring.

Organization:In Section 2, we provide an overview of the considered tasks, and review recent advancements in both DIP-based and DM-based methods. Section 3 introduces our approach, aSeqDIP. Our experimental results are presented in Section 4, followed by discussions on conclusions and future directions in Section 5.

## 2 Preliminaries & Related Work

### The Image Reconstruction Problem

Image reconstruction tasks can be defined as recovering an image \(^{*}^{n}\) from measurements \(^{m}\), where \(m n\), governed by the forward operator \(\). For multi-coil MRI, the forward operator is \(=\), where \(\) denotes coil-wise undersampling, \(\) is the coil-by-coil Fourier transform, and \(\) represents the sensitivity encoding with multiple coils2. For CT, a simplified forward operator will be used to study the sparse-views setting: \(=\), where \(\) is an undersampling operator that selects specific projection views or angles, and \(\) denotes the radon transform  (corresponding to parallel-beam geometry in CT). For both MRI and CT with limited acquired data (done to accelerate scan or reduce X-ray dose, etc.), the condition \(m<n\) applies.

For the denoising task, the forward operator is the identity matrix, whereas for in-painting, it is equivalent to applying a binary mask element-wise that masks corrupted or missing pixels. For deblurring, the non-linear forward operator is the neural network approximated kernel in . Next, we review prior arts within the context of DIP-based and DM-based methods.

### Related Work

DIP-based Methods:Deep Image Prior (DIP) was first introduced by . The authors demonstrated that the architecture of a generator network alone is capable of capturing a significant amount of low-level image statistics even before any learning takes place. Specifically, the DIP image reconstruction is obtained through the minimization of the following objective:

\[=*{argmin}_{}\;\|f_{}()-\|_{2}^{2}\,,}=f_{}()\,, \]

where \(}\) is the reconstructed image, and \(\) corresponds to the parameters of network \(f:^{n}^{n}\), which is typically implemented using a U-Net architecture . The input to the network, \(^{n}\), is randomly chosen and remains fixed throughout the optimization process. While standard DIP was shown to perform well in many tasks, selecting the number of iterations to optimize objective (1) poses a challenge as the network would eventually fit the noise present in \(\) or could fit to undesired images based on the null space of \(\).

To mitigate the problem of noise overfitting, previous studies considered different approaches such as regularization, early stopping (ES), and network pruning . For regularization-based methods, the work in  enhanced the standard DIP by introducing a total variation (TV) regularization term for denoising and deblurring tasks, whereas the study in  proposed combining DIP with stochastic gradient Langevin dynamics (SGLD) . The authors in  use running variance as the criterion for ES, whereas the authors of  propose combining self-validation and training to apply ES.

The input to the standard DIP (or Vanilla DIP) network is a random noise vector that, in most works, remains fixed during the optimization. Nevertheless, other works, such as those in  and , have explored cases where the input contains some structure of the ground truth. The approach employed in reference-guided DIP (Ref-Guided DIP)  follows the same objective as standard DIP in (1). However, instead of using a fixed random noise vector as input, it utilizes a reference image closely resembling the one undergoing reconstruction. This method was applied to the task of MRI. This methodology proves particularly effective when datasets comprising structurally similar data points are available. The reference required here makes this method a data-dependent approach.

Inspired by the departure from using a random fixed input, the authors in  recently introduced Self-Guided DIP. Unlike Ref-Guided DIP , a prior image that closely resembles the unknown (to be estimated) image is not needed, and the optimization occurs simultaneously with respect to both the input and the parameters of the network. Specifically, Self-Guided DIP employs the following objective:

\[,}=*{argmin}_{,}\| _{}[f_{}(+)]- \|_{2}^{2}+\|_{}[f_{}(+)]- \|_{2}^{2}\,, \]

where \(\) is random noise, and \(\) is a regularization parameter. The first (resp. second) term is used for data consistency (resp. denoising regularization) and final reconstruction is obtained as \(}=_{}[f_{}(}+)]\). aSeqDIP is different from Self-Guided DIP as our method does not require gradient-based updates for the input, making it computationally less expensive. Self-Guided DIP has demonstrated superior performance compared to Vanilla DIP, TV-DIP, and SGLD-DIP, thus serving as a primary baseline for comparison.

DM-based Methods:In recent years, there has been an abundance of DM-based methods proposed to address inverse imaging problems [14; 15; 16; 31; 32; 33]. A well-known method for natural images is Diffusion Posterior sampling (DPS) . DPS incorporates a gradient step into the reverse sampling process of pre-trained DMs, ensuring data consistency and enabling sampling from the conditional distribution. In the context of image reconstruction and restoration tasks, numerous diffusion-based approaches have emerged, as evidenced by works such as [34; 35; 36]. Notably, the authors in  and  introduced a SOTA DM-based approach for addressing the MRI and CT reconstruction inverse problems, respectively. They propose incorporating the predictor-corrector sampling algorithm  for data consistency, akin to DPS, thereby facilitating the sampling from a conditional distribution.

One clear distinction between aSeqDIP and DM-based methods is that our approach does not necessitate pre-trained models. For our experiments in MRI, CT, and denoising (as well as in-painting and deblurring) tasks, we will utilize Score-MRI , Manifold Constrained Gradient (MCG) , and DPS , respectively, as DM-based baselines.

Autoencoding Sequential DIP

In this section, we begin by investigating the impact of the input on DIP. Then, we introduce our method, aSeqDIP. We note that while we consider linear and non-linear inverse problems, in our formulations, we use a linear forward model to simplify notation.

### Motivation of aSeqDIP: The Impact of the Network Input in Vanilla DIP

Here, we aim to address the question: _How does employing a noisy version of the ground truth image, which retains some structure of the ground truth, as the fixed input to the Vanilla DIP objective in (1), affect performance?_ To investigate, we conduct the following experiment.

Consider the MRI task defined as \(^{*}\). Let the input to the standard DIP objective in (1) be denoted as \(=^{*}+\), where \((,^{2})\). Here, \(\) controls the magnitude of the perturbations added to the ground truth image, indicating that a larger \(\) results in a greater deviation between \(\) and \(^{*}\). We optimize (1) for various values of \(\), recording the best possible PSNR compared to the ground truth, i.e., prior to the start of the noise overfitting decay.

Figure 1 displays the average results for 8 images. Notably, for all images, a closer similarity of the DIP network input to \(^{*}\), as indicated by \(\), corresponds to higher reconstruction quality, measured by PSNR. Larger variance in the standard Gaussian distribution corresponds to larger additive perturbations even for the case of \(^{*}=\) (the red curve). We conjecture that this still leads to larger distances from the ground truth and hence worse performance.

Based on this discussion, a notable insight emerges:

The proximity of the DIP network input to the ground truth correlates with the quality of the reconstruction. This promotes the question: _Can we develop an input-adaptive DIP method that mitigates noise overfitting?_

We proceed to address this question by proposing our method, which we refer to as Autoencoding Sequential DIP (aSeqDIP). In Appendix A, we provide a case study and theory on the impact of the DIP network input through the lens of the Neural Tangent Kernel in residual networks. The onset of severe noise overfitting therein is delayed for better inputs (Appendix A.2).

### The Proposed aSeqDIP Algorithm

Consider that we have a U-Net architecture defined by \(f:^{n}^{n}\) whose weights are given by \(_{k}\), where \(k[K]\), and \([K]:=\{1,,K\}\). Each set of parameters in \(f_{_{k}}\) takes an input \(_{k}\) and outputs \(f_{_{k}}(_{k})\). Based on the insight from the previous subsection, we initially set \(_{0}\) to \(\) (resp. \(^{H}\)) for denoising, in-painting, and deblurring (resp. MRI and CT). The initialization of \(_{1}\) follows the same initialization as any other DIP-based method. The parameters in \(f_{_{k}}\), and the input, \(_{k}\), are then updated sequentially through

\[_{k}*{argmin}_{_{k}}\|f_{_{k}}( _{k-1})-\|_{2}^{2}+\|f_{_{k}}(_{k-1}) -_{k-1}\|_{2}^{2}\,, \]

\[_{k} f_{_{k}}(_{k-1})\,, \]

where \(_{+}\) is a regularization parameter, and the initialization of \(_{k}\) is the optimized \(_{k-1}\) in (3). The final reconstruction is given as:

\[}=_{K}=f_{_{K}}(_{K-1})\,. \]

The proposed procedure outlined in (3) and (4) consists of two key components. First, the optimization of each set of weights in \(f_{_{k}}\) using an objective that consists of the data consistency term and the

Figure 1: Average best possible PSNR values (in dB) obtained from standard DIP in (1) for 8 MRI (with 4x acceleration factor) scans (y-axis), where the network input \(\) is either a perturbed version of the ground truth or pure noise. The noise is a zero-mean additive Gaussian noise with strength determined by \(\) (x-axis).

second autoencoding term that aims to alleviate noise overfitting. Second, the update of the input, \(_{k}\), after optimizing each set of weights \(f_{_{k}}\), so that our method is _input-adaptive_.

Algorithm 1 presents the procedure of our proposed approach. As inputs, the algorithm takes \(\), \(\), \(K\), \(N\), \(\), and the learning rate \(\). Apart from the measurements and the forward operator, the remaining parameters are considered hyper-parameters, typical in most DIP-based methods. The parameters in \(f_{_{k}}\) are set to \(_{k-1}\) (step 2) and subsequently optimized for \(N\) iterations using a gradient-based optimizer, such as gradient descent (as depicted in Algorithm 1) or Adam . A block diagram of our proposed aSeqDIP method is presented in Figure 2.

In the following remarks, we provide insights into our proposed aSeqDIP method.

**Remark 3.1** (Differences from Vanilla DIP ).: Assume that the iterates of (3) and (4) converge, i.e., as \(k\), \(_{k}^{*}\) and \(_{k}^{*}\). Then, according to (4), for a continuous mapping \(f\), we have \(^{*}=f_{^{*}}(^{*})\). Substituting this into (3) in the limit, we get \(^{*}=\{*{argmin}_{}\|f_{}(^{*}) -\|_{2}^{2}\;:\;f_{}(^{*})=^{*}\}\), which corresponds to the minimizer of

\[_{}\|f_{}()-\|_{2}^{2} s.t. =f_{}(). \]

The limit points of aSeqDIP correspond to the solution of a constrained version of the Vanilla DIP objective in (1). The constraint enforces additional prior that could alleviate overfitting. While its not straightforward to use a gradient-based algorithm for (6) given the hard constraint, the aSeqDIP scheme's limit points nevertheless minimize (6). Furthermore, aSeqDIP automatically estimates the network input by a sequential feed forward process without needing expensive updates. The main point is to show that aSeqDIP is solving the optimization problem in (6), which is different than Vanilla DIP in (1).

**Remark 3.2** (Differences from Self-Guided DIP ).: While both aSeqDIP and Self-Guided DIP  update the input and network parameters simultaneously, there exist fundamental differences. Firstly, Self-Guided DIP solves the optimization problem in (2) which does not strictly enforce the auto-encoder constraint \(=f_{}()\) as in (6). Secondly, aSeqDIP only requires a network forward pass to update \(\), resulting in significantly fewer computations as will further be demonstrated in our experimental results. Thirdly, the second term in the aSeqDIP objective does not require computing the expectation, as it is an auto-encoder rather than a denoiser that results in higher resistance to noise overfitting. Lastly, our method does not require initializing \(\) randomly and generating random vectors (\(\) in (2)). The selection of \(\) introduces an additional hyper-parameter that we avoid, focusing solely

Figure 2: Illustrative block diagram of the proposed aSeqDIP procedure. Each trapezoidal corresponds to the updates of \(f_{_{k}}\) that takes \(_{k-1}\) as input and is initialized with the optimized parameters \(_{k-1}\) for \(k\{2,,K\}\) or randomly for \(k=1\). The optimization for each set of weights takes place based on (3) and is run for \(N\) steps. The final reconstruction is \(f_{_{K}}(_{K-1})\).

on selecting \(NK\) (total number of iterations) and \(\) (regularization strength), which are necessary in most DIP-based methods.

**Remark 3.3** (Computational Requirements).: The computational requirements of aSeqDIP are determined by two factors: (_i_) the \(NK\) gradient-based parameter updates, and (_ii_) the number of function evaluations necessary for updating \(\), which is \(K\). In our experiments, we have found that setting \(N=2\) and \(K=2000\) is generally sufficient. This configuration makes aSeqDIP nearly as efficient as Vanilla DIP.

**Remark 3.4** (Relationship to DMs).: aSeqDIP bears resemblance to the reverse process in DMs due to their shared gradual denoising steps. However, despite these similarities, several distinctions emerge. Firstly, unlike the DM network, aSeqDIP does not require encoding a scalar representing time \(t\). Secondly, and perhaps most significantly, aSeqDIP operates without requiring any training data or pre-trained networks. Thirdly, aSeqDIP operates in a truly sequential manner in terms of time, whereas in DMs, whether it's training (e.g., denoising score matching ) or sampling, the prevalent technique involves sampling from time \(t\) (uniform distribution), which allows for non-sequential time points.

Figure 3 illustrates how different approaches compare to aSeqDIP.

#### 3.2.1 Mitigating Noise Overfitting in aSeqDIP

In DIP-based approaches, noise overfitting occurs as the network attempts to fit its output to the noisy or subsampled measurements, \(\), as \(k\) increases during training. However, the specific value of \(k\) at which this PSNR decay begins is uncertain and varies across tasks and even among images within the same task and distribution. In aSeqDIP, when the output of network \(f_{_{k}}\) improves compared to that of \(f_{_{k-1}}\), the autoencoder term enforces similarity between the input and output of the network, thus delaying the onset of noise overfitting decay. This occurs because we are not only enforcing the network output to be measurement-consistent, but also enforcing that the output and input become similar. Consequently, as \(k\) increases, noise fitting is delayed, and utilizing the autoencoder provides regularization against noise overfitting. In Section 4, we will demonstrate how the proposed autoencoding term effectively regulates noise overfitting.

One might expect that incorporating the autoencoder could negatively impact reconstruction quality. However, empirical observations reveal that not only is noise overfitting delayed with the autoencoder term, but also image reconstruction quality is enhanced. To further support this statement, in Appendix B, we investigate whether a trained autoencoder on clean images can act as a reconstructor at testing time by optimizing the input.

Figure 3: **An overview of differences between aSeqDIP and prior arts in terms of data dependency, network architecture(s), and procedural requisites. ‘Data-Dependency’ here indicates whether a method depend on a prior reference image or pre-trained models.**

## 4 Experimental Results

### Settings, Datasets, and Baselines

In our experiments, we consider five tasks: MRI reconstruction from undersampled measurements, sparse-view CT image reconstruction, denoising, non-linear deblurring and in-painting. For MRI, we use the fastMRI dataset3. The forward model is \(^{*}\). The multi-coil data is obtained using \(15\) coils and is cropped to a resolution of \(320 320\) pixels. To simulate undersampling of the MRI k-space, we use a Cartesian mask with 4x and 8x accelerations. Sensitivity maps for the coils are obtained using the BART toolbox . For CT, we use the AAPM dataset4. For parallel beam CT, the input image with \(512 512\) pixels is transformed into its sinogram representation using a Radon transform (the operator \(\)). The forward model assuming a monoenergetic source and no scatter, noise is \(y_{i}=I_{0}e^{-[^{*}]_{i}}\), with \(I_{0}\) denoting the number of incident photons per ray (assumed to be \(1\) for simplicity) and \(i\) indexing the \(i\)th measurement or detector pixel. We use the post-log measurements for reconstruction. We use a full set of \(180\) projection angles and simulate two different sparse view acquisition scenarios (with equispaced angles). Specifically, we created cases with 18 and 30 angles/views. The image resolution is kept at a fixed size.

For the tasks of denoising, in-painting, and non-linear deblurring, we use the CBSD68 dataset5. For each task, we use \(20\) measurements/corrupted images. To evaluate the reconstruction quality, we use the Peak Signal to Noise Ratio (PSNR), and the Structural SIMilarity (SSIM) index . For experimental settings and baselines, see Table 1 and its caption. Note that we consider data-dependent and data-independent baselines as shown in the third and fourth columns of Table 1. All the experiments are conducted on a single RTX5000 GPU machine. Further implementation details are provided in Appendix C.6.

For the proposed aSeqDIP method in Algorithm 1, we use the Adam optimizer with learning rate of \(=0.0001\). Furthermore, the regularization parameter is set to \(=1\) following the ablation study in Appendix C.4. We select \(N=2\) and \(K=2000\) following the ablation study in Appendix C.5.

### Impact of the Autoencoding term on Noise Overfitting

In this subsection, we showcase the impact of the proposed autoencoding regularization in aSeqDIP on noise or null space (nuisance) overfitting.

We conducted experiments using \(20\) MRI scans and \(20\) CT scans, considering two cases of aSeqDIP as outlined in Algorithm 1. The first case sets \(=1\), consistent with the remainder of the paper,

  
**Task** & **Setting** & **Data-independent baselines** & **Data-dependent baselines** \\   MRI & \(\{4,8\}\) & Vanilla DIP , ES-DIP , & Ref-Guided DIP  \\  & & TV-DIP , Self-Guided DIP  & Score-MRI  \\  CT & views \(\{18,30\}\) & Vanilla DIP , Self-Guided DIP , & Ref-Guided DIP  \\  & & Filter Back Projection (FBP)  & MCG  \\  Denoising & \(_{}\{15,30\}\) & Vanilla DIP , ES-DIP , Self-Guided DIP , & DPS  \\  & & TV-DIP , Rethinking-DIP , SGLD-DIP  & \\  In-painting & \(\{0.1,0.25\}\) & Vanilla DIP , ES-DIP , Self-Guided DIP , & DPS  \\  & & SGD-DIP , TV-DIP  & & DPS  \\  Deblurring & BKSE  & Self-Guided DIP  & DPS  \\   

Table 1: Tasks, settings, and baselines considered in our experiments. For MRI, we consider two Acceleration (Ax) factors, 4x and 8x, that determine the subsampling of the measurements. For 2D CT (parallel beam geometry), we use two sparse view settings: \(18\) and \(30\) views. For denoising, we perturb the ground truth images using two noise levels determined by \(_{}\). In in-painting, we use two hole-to-image area ratios (HIAR), \(0.1\) and \(0.25\). For non-linear deblurring, we use the Blurring Kernel Space Exploring (BKSE) setting , described in Equations (56) to (59) of . Each baseline that utilizes pre-trained models or a reference image is considered data-dependent. Further details are provided in Appendix C.6.

while the second case sets \(=0\), effectively disabling the autoencoding regularization term in (3). Additionally, for comparison, we report results for Vanilla DIP and Self-Guided DIP. The average PSNR results for these cases are depicted in Figure 4.

As observed, when the autoencoder term is disabled in aSeqDIP (blue dashed lines), noise overfitting in MRI, akin to Self-Guided DIP, begins after nearly 1600 iterations. For CT, we note that aSeqDIP without regularization starts noise overfitting at around iteration 3800, whereas Self-Guided DIP experiences PSNR decay earlier, after approximately 1250 iterations. Importantly, when the autoencoding term is utilized (blue solid lines), not only does the decay in noise overfitting not commence until after iteration 4000, but the reconstruction quality (measured by PSNR) also improves.

As expected, PSNR decay in Vanilla DIP begins early, at around iteration 500 and 750 for MRI and CT, respectively. In Appendix C.4, we provide an ablation study to better show the impact of the value of \(\) in aSeqDIP.

### Main Results

Here, we present our primary results regarding the reconstruction quality, measured by PSNR and SSIM, as well as the associated run-time. Table 2 presents the results for the considered tasks in this paper. Column \(3\) indicates whether the baselines depend on prior data or pre-trained models. The last three columns provide the PSNR, SSIM, and run-time results where the arrows indicate favorable results. For PSNR and SSIM, the settings correspond to the second column of Table 1. The black (resp. blue) text corresponds to the first (resp. second) setting. Values after the \(\) sign indicate standard deviation. Subsequently, we offer observations on the main results.

Compared to data-independent methods, i.e., the baselines that do not depend on a reference image or pre-trained models, aSeqDIP demonstrates improved PSNR and SSIM scores. For example, aSeqDIP, apart from Self-Guided DIP, shows nearly a 1dB improvement for MRI 8X acceleration compared to conventional methods. For the task of 30-views CT, aSeqDIP reports SSIM score of 0.92 which is 5% more than the second best, which is Self-Guided DIP with SSIM of 0.872. Although improvements against Self-Guided DIP are generally marginal in terms of reconstruction quality, our method proves to be 2X faster for MRI and CT reconstruction and requires 1 minute less than Self-Guided DIP for denoising and in-painting. This speed-up is attributed to updating the input using one forward pass of the trained network at each iteration \(k\), instead of computing gradients with respect to the input for the update. Compared to Vanilla DIP, our method, on average, only requires an additional 30 to 60 seconds. When compared to ES-DIP , our method requires longer time, but on average achieves better reconstruction results across three tasks and different settings.

In comparison to data-dependent methods such as Score-MRI and MCG, our approach not only yields the best PSNR and SSIM but also requires reduced run-time, all without requiring any training data or pre-trained models. For instance, on average, aSeqDIP achieves nearly a 2dB improvement in 30-views CT compared to MCG while being 2X faster. In comparison to DPS, on average, our method report higher SSIM. Our method requires slightly less run-time on average but enhances the PSNR by approximately 0.6dB for both denoising and in-painting. Notably, our method is an optimization-based approach, whereas DM-based methods only require function evaluations. However, the generally larger run-time reported for DM-based methods is due to the necessity of

Figure 4: Average PSNR results w.r.t. iteration \(i\) of \(20\) MRI (with 4x) scans (_left_) and 20 CT (with 18 views) scans (_right_) to show the impact of the proposed autoencoding regularization term on noise overfitting in aSeqDIP. Furthermore, average results of Vanilla DIP and Self-Guided DIP are also reported for comparison. For aSeqDIP, iteration \(i[NK]\), where \(N=2\). Vertical lines approximately indicate the start of the PSNR decay for every case. In Appendix C.1, we include the PSNR curves of aSeqDIP and other DIP-based methods for the task of denoising.

running a large number of reverse sampling steps. When compared to Ref-Guided DIP, our method achieves higher PSNR and SSIM results without the need for any prior (or reference image) image.

### Visualizations

Figure 5 shows reconstructed images for the five considered tasks using aSeqDIP and the other baselines. Each row corresponds to a task. The first column displays the ground truth (GT) image whereas the second column shows the degraded image. Column 3 to the column before last present the reconstructed images by the baselines, while the last column shows the reconstructed images by aSeqDIP. PSNR values are provided at the bottom of each reconstructed image.

As observed, aSeqDIP achieves the highest PSNR scores. Additionally, the top right green boxes, which show the difference between the central region of the reconstructed and GT images, indicate that for MRI and CT, our method visually exhibits the least difference, making it the closest to the GT.

A similar observation is seen for the denoising task for the zoomed in bottom box. For inpainting, we note that aSeqDIP introduces the fewest unwanted artifacts as observed in the clouds (for DPS), and the left wing of the plane. While aSeqDIP contains artifacts for the task of Deblurring when compared to DPS, the latter generates a perceptually different image when compared to the GT. Similar observation are noticed with the additional visualizations provided in Appendix C.7.

    &  & **Data** & **PSNR** (dB) (\(\)) & **SSIM \(\) (\(\)) & **Run-time** (\(\)) \\  & & **Independency** & (Setting 1, Setting 2) & (Setting 1, Setting 2) & (minutes) \\   & Score-MRI & \(\) & (31.51\(\)0.45, 29.61\(\)0.44) & (0.891\(\)0.012, 0.862\(\)0.014) & 6.2\(\)0.12 \\  & Ref-Guided DIP & \(\) & (33.17\(\)0.27, 20.32\(\)0.24) & (0.912\(\)0.021, 0.873\(\)0.016) & 2.5\(\)0.2 \\  & TV-DIP & \(\) & (30.52\(\)0.25, 32.20\(\)0.37) & (0.872\(\)0.022, 0.852\(\)0.022) & 2.5\(\)0.1 \\  & ES-DIP & \(\) & (31.02\(\)0.34, 29.44\(\)0.45) & (0.882\(\)0.031, 0.858\(\)0.028) & 1.5\(\)0.34 \\  & Vanilla DIP & \(\) & (30.21\(\)0.42, 28.75\(\)0.33) & (0.865\(\)0.02, 0.842\(\)0.022) & **1.5\(\)0.12** \\  & Self-Guided DIP & \(\) & (33.62\(\)0.39, 30.75\(\)0.25) & (0.922\(\)0.008, 0.874\(\)0.006) & 4.5\(\)0.67 \\  & aSeqDIP (Ours) & \(\) & **(34.08\(\)0.41, 31.34\(\)0.47)** & **(0.929\(\)0.008, 0.887\(\)0.009)** & 2.2\(\)0.12 \\   & MCG & \(\) & (32.82\(\)0.52, 31.35\(\)0.49) & (0.912\(\)0.08, 0.852\(\)0.09) & 6.4\(\)0.2 \\  & FBP & \(\) & (22.92\(\)0.22, 19.52\(\)0.32) & (0.75\(\)0.021, 0.68\(\)0.023) & **0.2\(\)0.01** \\  & Ref-Guided DIP & \(\) & (31.21\(\)0.24, 28.31\(\)0.42) & (0.892\(\)0.023, 0.842\(\)0.021) & 2.5\(\)0.42 \\  & Vanilla DIP & \(\) & (26.21\(\)0.12, 24.31\(\)0.34) & (0.791\(\)0.021, 0.772\(\)0.012) & 1.5\(\)0.21 \\  & Self-Guided DIP & \(\) & (33.95\(\)0.32, 31.95\(\)0.32) & (0.918\(\)0.02, 0.872\(\)0.031) & 4.5\(\)0.56 \\  & aSeqDIP (Ours) & \(\) & **(34.88\(\)0.36, 30.99\(\)0.39)** & **(0.941\(\)0.026, 0.92\(\)0.022)** & 2.2\(\)0.42 \\   & DPS & \(\) & (31.02\(\)0.25, 28.2\(\)0.31) & (0.912\(\)0.02, 0.882\(\)0.021) & 2.5\(\)0.17 \\  & Vanilla DIP & \(\) & (30.48\(\)0.28, 27.84\(\)0.32) & (0.905\(\)0.021, 0.871\(\)0.030) & **1.5\(\)0.22** \\  & SGLD DIP & \(\) & (30.58\(\)0.34, 28.12\(\)0.42) & (0.908\(\)0.021, 0.877\(\)0.017) & 3.2\(\)0.24

## 5 Conclusions & Future Work

In this paper, we introduced Autoencoding Sequential Deep Image Prior (aSeqDIP), a new unsupervised image recovery algorithm. Notably, aSeqDIP operates without the need of pre-trained models, relying solely on a sequential update of network parameters. These parameters are optimized using an input-adaptive data consistency objective combined with autoencoding regularization, effectively mitigating noise overfitting. Our experimental results across various tasks highlight the competitive performance of the proposed algorithm, matching (or outperforming) diffusion-based methods in terms of reconstruction quality and required run time, all without the need for pre-trained models.

For future directions, we aim to explore the applicability of aSeqDIP to other image recovery problems, thereby expanding its versatility and potential impact across diverse domains. Additionally, we are interested in investigating the integration of a network input update mechanism to dynamically adjust the autoencoding regularization parameter and the number of gradient updates per iteration.