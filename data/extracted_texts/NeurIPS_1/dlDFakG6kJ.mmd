# Sample Complexity of Forecast Aggregation

Tao Lin

Harvard University

Cambridge, MA 02138

tlin@g.harvard.edu &Yiling Chen

Harvard University

Cambridge, MA 02138

yiling@seas.harvard.edu

###### Abstract

We consider a Bayesian forecast aggregation model where \(n\) experts, after observing private signals about an unknown binary event, report their posterior beliefs about the event to a principal, who then aggregates the reports into a single prediction for the event. The signals of the experts and the outcome of the event follow a joint distribution that is unknown to the principal, but the principal has access to i.i.d. "samples" from the distribution, where each sample is a tuple of the experts' reports (not signals) and the realization of the event. Using these samples, the principal aims to find an \(\)-approximately optimal aggregator, where optimality is measured in terms of the expected squared distance between the aggregated prediction and the realization of the event. We show that the sample complexity of this problem is at least \((m^{n-2}/)\) for arbitrary discrete distributions, where \(m\) is the size of each expert's signal space. This sample complexity grows exponentially in the number of experts \(n\). But, if the experts' signals are independent conditioned on the realization of the event, then the sample complexity is significantly reduced, to \((1/^{2})\), which does not depend on \(n\). Our results can be generalized to non-binary events. The proof of our results uses a reduction from the distribution learning problem and reveals the fact that forecast aggregation is almost as difficult as distribution learning.

## 1 Introduction

Suppose you want to know whether it will rain tomorrow. A Google search on "weather" returns 40% probability of raining. The weather forecasting app on your phone shows 85%. And one of your friends, who is an expert in meteorology, predicts 65%. How do you aggregate these different predictions into a single, accurate prediction? This problem is called _forecast aggregation_ or _forecast combination_. It has innumerable applications in fields ranging from economics, statistics, operations research, to machine learning, decision theory, and of course, climate science.

A straightforward solution to forecast aggregation is to take the (unweighted) average of all experts' forecasts. Simple as it is, unweighted average performs surprisingly well in practice, as observed by many forecast aggregation works from 1960s to 2020s (e.g., ). Naturally, when past data of expert forecasts and event outcomes (e.g., historical weather forecasts and outcomes) are available, one may hope to leverage on such data to learn more accurate aggregators. While adjusting the weights of experts in averaging according to their individual historical accuracy has led to improved accuracy for the aggregated prediction , interestingly, more sophisticated data-driven methods  were often outperformed by the unweighted average. The dominance of simple aggregators over more sophisticated data-driven methods is observed so often in empirical applications that it is termed "the forecast combination puzzle" [44, p.428].

There are many potential explanations for the forecast combination puzzle . In some scenarios, the past events are different from the future events in fundamental ways (e.g., geopoliticalforecasting) and hence past data may not be informative in predicting the future. Another widely accepted conjecture is that the amount of past data is not large enough for a data-intensive method to perform well. Indeed, the sample sizes in many empirical forecast aggregation works are small under today's "big-data" standard (24 in , 69 in , 87 in , 100 in ). However, there are aggregation settings where future events are arguably similar to past events and we do have abundant data -- for instance, the forecasting of weather, stock prices , and some forecasting competitions on Kaggle1. Such settings are well-suited for data-driven methods. It is hence tempting to ask _how many_ data are needed for data-driven aggregators to achieve high accuracy in these settings.

In this paper, we initiate the study of _sample complexity of forecast aggregation_, building upon a standard Bayesian forecasting model . In this model, there are \(n\) experts who observe private signals about an unknown binary event and make posterior predictions about the event. The experts' signals and the event are jointly distributed according to some underlying unknown distribution (information structure) \(P\), which determines the optimal way to aggregate the experts' predictions. With sample access to the unknown distribution \(P\), we ask the following question:

_How many samples do we need to approximately learn the optimal aggregator?_

Our model favors the use of data-driven aggregation methods because historical tasks are i.i.d. as future tasks. We show that however, even in this benign model, optimal aggregation in general needs _exponentially many_ samples. One may thus expect that data-driven methods can hardly perform well in more realistic and non-i.i.d. scenarios. Nevertheless, for some special, yet interesting, families of information structures, the sample complexity of forecast aggregation is significantly lower.

Main results(1) If \(P\) can be an arbitrary discrete distribution, then at least \((m^{n-2}/)\) samples are needed, and \((m^{n}/^{2})\) samples are sufficient, to learn an \(\)-optimal aggregator with high probability, where \(m\) is the number of signals an expert can possibly observe.2 (2) If the experts' signals are conditionally independent, then the sample complexity is exponentially reduced and surprisingly does not depend on the number of experts or the number of signals: \((1/^{2})\) samples are sufficient, and \((1/)\) samples are necessary, to learn an \(\)-optimal aggregator with high probability.

Main techniquesThe main technical part of our paper is to prove the \((m^{n-2}/)\) lower bound on the sample complexity of forecast aggregation for the general case, via a reduction from the _distribution learning_ problem. It is known that learning a discrete distribution with support size \(|S|\) in total variation distance \(\) requires \((|S|/^{2})\) samples. By reducing distribution learning to forecast aggregation, we obtain the lower bound on the sample complexity of the latter problem. This reduction is highly nontrivial. To do this reduction we define a new distribution learning problem that is different from the one in the literature, which is of independent interest. This reduction also reveals an interesting fact: learning to aggregate optimally on some distribution is almost as difficult as learning the distribution itself. This is a little surprising because one might initially think that aggregation should be easier than distribution learning - we show that this is not the case.

Structure of the paperWe discuss related works in Section 1.1. Section 2 introduces our model. Section 3 includes some preliminaries, including the distribution learning problem, which we will use in the proof. Section 4 studies the sample complexity for general distributions. Section 5 focuses on the conditional independence case. Section 6 summarizes how our results can be generalized to non-binary (multi-outcome) events. Section 7 concludes and discusses future directions.

### Related Works

Data-driven aggregationData-driven approaches to forecast aggregation date back to perhaps the first paper on forecast aggregation  and have been a standard practice in the literature (see, e.g., surveys  and more recent works ). Many of these works focus on specific weighted average aggregators like _linear pooling_ (weighted arithmetic mean)  and _logarithmic pooling_ (normalized weighted geometric mean) , and the goal is to estimate the optimal weights from data. However, those weighted average aggregators are not necessarily the optimal (_Bayesian_) aggregator unless the underlying information structure satisfies some strict conditions (e.g., experts' forecasts are equal to the true probability of the event plus normally distributed noises ). Our work aims to understand the sample complexity of Bayesian aggregation, namely how many samples are needed to approximate the Bayesian aggregator.

Our work is closely related to a recent work  on Bayesian aggregation via _online learning_. For the case of conditionally independent experts,  shows that the Bayesian aggregator can be approximated with \(=(})\) regret. By an online-to-batch conversion, this implies a \(T=(}{^{2}})\) sample complexity upper bound for the batch learning setting. Our paper studies the batch learning setting. For the conditional independence case, we obtain an improved bound of \((})\).

Robust forecast aggregationRecent works on "robust forecast aggregation"  also study information aggregation problems where the principal does not know the underlying information structure. They take a worst-case approach, assuming that the information structure is chosen adversarially. This often leads to negative results: e.g., a bad approximation ratio  or a degenerate maximin aggregator that solely relies on a random expert's opinion . In contrast, we assume sample access to the unknown information structure. Our sample complexity approach is orthogonal and complementary to the robust forecast aggregation approach.

Sample complexity of mechanism designOur work may remind the reader of a long line of research on the sample complexity of revenue maximization in mechanism design (e.g., ). In particular,  gives a general framework to bound the sample complexity for mechanism design problems that satisfy a "strong monotonicity" property, but this property is not satisfied by our forecast aggregation problem. A key observation from this line of works is that the number of samples needed to learn an \(\)-optimal auction for \(n 1\) independent bidders is increasing in \(n\), because when there are more bidders, although we can obtain higher revenue, the optimal auction benchmark is also improved. We see a similar phenomenon that the sample complexity of forecast aggregation increases with the number of experts in the general case, but not in the case where experts are conditionally independent.

## 2 Model

### Forecast Aggregation

There are \(n 2\) experts and one principal. The principal wants to predict the probability that a binary event \(=\{0,1\}\) happens (\(=1\)), based on information provided by the experts. For example, \(\) may represent whether it will rain tomorrow. We present binary events to simplify notations. All our results can be generalized to multi-outcome events with \(||>2\) (see Section 6). We also refer to \(\) as "the state of the world". Each expert \(i=1,,n\) observes some private signal \(s_{i}_{i}\) that is correlated with \(\), where \(_{i}\) denotes the space of all possible signals of expert \(i\). We assume for now that \(_{i}\) is finite, with size \(|_{i}|=m\). We relax this assumption in Section 5 where we consider conditionally independent signals. Let \(}=_{1}_{n}\) be the joint signal space of all experts; \(|}|=m^{n}\). Let \(P\) be a distribution over \(}\), namely, a joint distribution of signals \(=(s_{1},,s_{n})\) and event \(\). Since the space \(}\) is discrete, we can use \(P()\) to denote the probability: \(P(,)=_{P}[,]\). Signals of different experts can be correlated conditioned on \(\). We assume that each expert \(i\) knows the marginal joint distribution of their own signal \(s_{i}\) and \(\), \(P(s_{i},)\). Neither any expert nor the principal knows the entire distribution \(P\). Each expert \(i\) reports to the principal a forecast (or prediction) \(r_{i}\) for the event \(\), which is equal to the conditional probability of \(=1\) given their signal \(s_{i}\):3

\[r_{i}=P(=1 s_{i})=|=1)}{P(=1)P( s_{i}|=1)+P(=0)P(s_{i}|=0)}. \]

We note that \(r_{i}\) depends on \(s_{i}\) and \(P\), but not on \(\) or other experts' signals \(_{-i}\). Let \(=(r_{1},,r_{n})^{n}\) denote the reports (joint report) of all experts. We sometimes use \(_{-i}\) to denote the reports of all experts except \(i\). The principal aggregates the experts' reports \(\) into a single forecast \(f()\) using some _aggregation function_, or _aggregator_, \(f:^{n}\). We measure the performance of an aggregator by the mean squared loss:

\[L_{P}(f)=_{P}|f()-|^{2}. \]

The notation \(_{P}[]\) makes it explicit that the expectation is over the random draw of \((,) P\) followed by letting \(r_{i}=P(=1\,|\,s_{i})\). We omit \(P\) and write \([]\) when it is clear from the context.

Let \(f^{*}\) be the optimal aggregator with respect to \(P\), which minimizes \(L_{P}(f)\):

\[f^{*}=*{argmin}_{f:^{n}}L_{P}(f)=*{ argmin}_{f:^{n}}_{P}|f()-|^{2}. \]

We have the following characterization of \(f^{*}\) and \(L_{P}(f)\): \(f^{*}\) is equal to the Bayesian aggregator, which computes the posterior probability of \(=1\) given all the reports \(=(r_{1},,r_{n})\). And the difference between the loss of \(f\) and the loss of \(f^{*}\) is equal to their expected squared difference.

**Lemma 2.1**.: _The optimal aggregator \(f^{*}\) and any aggregator \(f\) satisfy:_

* \(f^{*}()=P(=1\,|\,)\)_, for almost every_ \(\)_._
* \(L_{P}(f)-L_{P}(f^{*})=_{P}|f()-f^{*}()|^{2}\)_._

An aggregator \(f\) is _\(\)-optimal_ (with respect to \(P\)) if \(L_{P}(f) L_{P}(f^{*})+\). By Lemma 2.1, this is equivalent to \(_{P}|f()-f^{*}()|^{2}\). For an \(\)-optimal \(f\), we also say it \(\)-approximates \(f^{*}\).

**Definition 2.2**.: _An aggregator \(f\) is \(\)-optimal (with respect to \(P\)) if \(_{P}|f()-f^{*}()|^{2}\)._

Discussion of the benchmark \(f^{*}\)Our benchmark, the Bayesian aggregator \(f^{*}\), is common in the forecast aggregation literature (e.g., ). It is stronger than the typical "best expert" benchmark in no-regret learning (e.g., ), but weaker than the "omniscient" aggregator that has access to the experts' _signals_: \(f_{}()=P(=1\,|\,)\). If there is a one-to-one mapping between signals \(\) and reports \(\), then \(f_{}\) and \(f^{*}\) are the same. Otherwise, \(f_{}\) could be much stronger than \(f^{*}\) and an \(\)-approximation to \(f_{}\) using experts' reports only is not always possible.4 In contrast, an \(\)-approximation to \(f^{*}\) is always achievable (in fact, achieved by \(f^{*}\) itself). The difference between \(f^{*}\) and \(f_{}\) is known as the difference between "aggregating forecasts" and "aggregating information sets" in the literature [27, p.198-199], [26, p.168-169], [45, p.143].

### Sample Complexity of Forecast Aggregation

The principal has access to \(T\) i.i.d. samples of forecasts and event realizations drawn from the underlying unknown distribution \(P\):

\[S_{T}=(^{(1)},^{(1)}),,(^{(T)},^{(T)}) },(^{(t)},^{(t)}) P, r_{i}^{(t)}=P(=1\ |\ s_{i}^{(t)}). \]

Here, we implicitly regard \(P\) as a distribution over \((,)\) instead of \((,)\). The principal uses samples \(S_{T}\) to learn an aggregator \(=_{S_{T}}\), in order to approximate \(f^{*}\). Our main question is:

_How many samples are necessary and sufficient for finding an \(\)-optimal aggregator \(\)_

_(with probability at least \(1-\) over the random draw of samples)?_

The answer to the above question depends on the family of distributions we are interested in. Let \(\) denote a family of distributions over \(}\). It could be the set of all distributions over \(}\), or in Section 5 we will only consider distributions where the signals are independent conditioned on \(\). We define the sample complexity of forecast aggregation, with respect to \(\), formally:

**Definition 2.3**.: _The sample complexity of forecast aggregation (with respect to \(\)) is the minimum function \(T_{}(,)\) of \(,(0,1)\), such that: if \(T T_{}(,)\), then for any distribution \(P\), with probability at least \(1-\) over the random draw of \(T\) samples \(S_{T}\) from \(P\) (and over the randomness of the learning procedure if it is randomized), we can obtain an aggregator \(=_{S_{T}}\) satisfying \(_{P}[|()-f^{*}()|^{2}]\)._The principal is assumed to know the family of distributions \(\) but not the specific distribution \(P\). There should be at least two different distributions in \(\). Otherwise, the principal knows what the distribution is and there is no need for learning.

## 3 Preliminaries

In this section, we briefly introduce some notions that will be used in our analysis of the sample complexity of forecast aggregation, including some definitions of distances between distributions, the distribution learning problem, and the distinguishing distributions problem.

Distances between distributionsWe recall two distance metrics for discrete distributions: the _total variation distance_ and the _(squared) Hellinger distance_.

**Definition 3.1**.: _Let \(D_{1},D_{2}\) be two distributions on a discrete space \(\)._

* _The_ total variation distance between__\(D_{1}\) and__\(D_{2}\) _is_ \(d_{}(D_{1},D_{2})=_{x}D_{1}(x)-D _{2}(x)\)_._
* _The_ squared Hellinger distance _between_ \(D_{1}\) _and_ \(D_{2}\) _is_ \(d_{}^{2}(D_{1},D_{2})\;=\;_{x} (x)}-(x)}^{2}=\;1-_{x}(x)D_{2}(x)}\)_._

The total variation distance has the following well-known property that upper bounds the difference between the expected values of a function on two distributions:

**Fact 3.2**.: _For any function \(h:\), \(|_{x D_{1}}h(x)-_{x D_{2}}h(x)| d_{ }(D_{1},D_{2})\)._

In Appendix A we give some properties of the Hellinger distance that will be used in the proofs.

Distribution learning in total variation distanceOur analysis of the sample complexity of the forecast aggregation problem will leverage on the sample complexity of another learning problem: _learning discrete distributions in total variation distance_. We review this problem below.

Let \(\) be a family of distributions over \(\). The _sample complexity of learning distributions in \(\) within total variation distance \(\)_ is the minimum function \(T_{}^{}(,)\), such that: if \(T T_{}^{}(,)\), then for any distribution \(D\), with probability at least \(1-\) over the random draw of \(T\) samples from \(D\), we can obtain (from the \(T\) samples) a distribution \(\) such that \(d_{}(,D)\).

**Proposition 3.3** (e.g., ).: _Let \(_{}\) be the set of all distributions over \(\). Then, \(T_{_{}}^{}(,)= |+(1/)}{^{2}}\). In particular, the upper bound can be achieved by using the empirical estimate \(_{}\) (which is the uniform distribution over the \(T\) samples). The lower bound holds regardless of what learning algorithm is used._

Distinguishing distributionsAnother learning problem that we will leverage on is the problem of _distinguishing (two) distributions_: given samples from a distribution randomly chosen from \(\{D_{1},D_{2}\}\), we are to guess whether the samples are from \(D_{1}\) or \(D_{2}\). The sample complexity of distinguishing distributions is characterized by the squared Hellinger distance. It is known that at least \(T=}^{2}(D_{1},D_{2})} \) samples are needed to distinguish two distributions with probability at least \(1-\). See Appendix A for a formal statement of this result.

## 4 Sample Complexity for General Distributions

In this section we characterize the sample complexity of forecast aggregation for general distributions \(P\). We give an exponential (in the number of experts, \(n\)) upper bound and an exponential lower bound on the sample complexity, as follows:

**Theorem 4.1**.: _Let \(_{}\) be the set of all distributions over \(}\), with \(|}|=m^{n}\). Suppose \(n 2\). The sample complexity of forecast aggregation with respect to \(_{}\) is_

\[O+(1/)}{^{2}}\;\;T_{ _{}}(,)\;\;+(1/)}{}. \]

This theorem is for \(n 2\). When there is only one expert (\(n=1\)), there is no need to learn to aggregate because the optimal "aggregator" \(f^{*}\) simply outputs the forecast given by the only expert: \(f^{*}(r_{1})=P(=1\,|\,r_{1})=P(=1\,|\,s_{1})=r_{1}\). The sample complexity is \(0\) in this case.

There is a gap in the dependency on \(\) in the upper bound and the lower bound in Theorem 4.1. We conjecture that the tight dependency on \(\) should be \(\) (so the lower bound is tight). See Section 7 for a detailed discussion of this conjecture, where we show that the dependency on \(\) in the upper bound can be improved to \(\) for a large family of distributions.

### Proof of the Upper Bound

In this subsection we prove the \(O+(1/)}{^{2}}\) upper bound in Theorem 4.1. This is a direct corollary of the distribution learning result introduced in Section 3.

We regard \(P\) as a distribution over \(\) and \(\) instead of over \(\) and \(\). Then \(P\) is a discrete distribution with support size at most \(2m^{n}\) because each possible report \(r_{i}\) corresponds to some discrete signal \(s_{i}\) in \(_{i}\). Let \(_{}\) be the empirical distribution of reports and event realizations: \(_{}=(^{(1)},^{(1)}), ,(^{(T)},^{(T)})}\). By Proposition 3.3, with probability at least \(1-\) over the random draw of \(T=O+(1/)}{^{2}}\) samples, we have \(d_{}(_{},P)\). According to Fact 3.2, and by the definition of \(L_{P}(f)\), we have: for any aggregator \(f:^{n}\),

Therefore, if we pick the empirically optimal aggregator \(_{}=_{f}L_{_{}}(f)\), we get

\[L_{P}(_{}) L_{_{}}(_{})+ L_{_{}}(f^{*})+ L_{P}( f^{*})+2,\]

which means that \(_{}\) is a \(2\)-optimal aggregator for \(P\).

### Proof of the Lower Bound

In this subsection we prove the \(+(1/)}{}\) lower bound in Theorem 4.1. The main idea is a reduction from the distribution learning problem (defined in Section 3) for a specific family \(\) of distributions over the joint signal space \(}=_{1}_{n}\). We construct a corresponding family of distributions \(=\{P_{D}:D\}\) for the forecast aggregation problem, such that, if we can obtain an \(\)-optimal aggregator \(\) for \(P_{D}\), then we can convert \(\) into a distribution \(\) such that \(d_{}(,D) O()\). We then prove that learning \(\) within total variation distance \(_{}=O()\) requires \(+(1/)}{^{2}_{}} =+(1/)}{}\) samples. This gives the sample complexity lower bound for the forecast aggregation problem for \(\) (and hence \(_{}\)).

We will need a family of distributions \(\) that satisfies the following three properties:

**Definition 4.2**.: _We say a family of distributions \(\) satisfies_

1. \(B\)-uniformly bounded_, if:_ \(D()}|}=}\), \(}\)_,_ \( D\)_, where_ \(B 1\) _is a constant._
2. _same marginal across distributions, if: for any_ \(D,D^{}\)_, any_ \(i\)_, any_ \(s_{i}_{i}\)_,_ \(D(s_{i})=D^{}(s_{i})\)_._
3. _distinct marginals across signals, if: for any_ \(D\)_, any_ \(i\)_, any_ \(s_{i} s^{}_{i}_{i}\)_,_ \(D(s_{i}) D(s^{}_{i})\)_._

How do we construct the family \(\)? For each distribution \(D\), we construct distribution \(P_{D}\) as follows: the marginal distribution of \(\) is \(\{0,1\}\), i.e., \(P_{D}(=0)=P_{D}(=1)=\); conditioning on \(=0\), the joint signal \(\) is uniformly distributed: \(P_{D}(=0)=}|}=}\), \(}\); conditioning on \(=1\), the joint signal is distributed according to \(D\): \(P_{D}(=1)=D()\), \(}\). The family \(\) is \(\{P_{D}:D\}\).

We show that if we can obtain \(\)-optimal aggregators for distributions in \(\), then we can learn the distributions in \(\) within total variation distance \((1+B)^{2}\), and thus the sample complexity of the former is lower bounded by the sample complexity of the latter:

**Lemma 4.3**.: _Let \(\) be a family of distributions that satisfies the three properties in Definition 4.2. Let \(=\{P_{D}:D\}\) be defined above. Then, \(T_{}(,) T_{}^{}( 1+B)^{2},\,\)._Proof sketch of Lemma 4.3.: The full proof is in Appendix E.1. We give a sketch here. According to the definition of \(P_{D}\), by Bayes' rule, we have

\[P_{D}(=1)=P_{D}(|=1 )}{P_{D}(|=0)+P_{D}(| =1)}=)}{}+D()}. \]

The "distinct marginals across signals" property in Definition 4.2 ensures that there is a one-to-one mapping between signal \(s_{i}\) and report \(r_{i}=P_{D}(=1\!\!s_{i})\), and hence a one-to-one mapping between joint signal \(\) and joint report \(\). So, the Bayesian aggregator \(f^{*}\) satisfies \(f^{*}()=P_{D}(=1\!\!)=P_{D}(=1\! \!)=)}{1/m^{n}+D()}\). This gives

\[D()=}()}{1-f^{*}( )}. \]

Suppose we have obtained an \(\)-optimal aggregator \(\) for \(P_{D}\), \(_{P_{D}}|()-f^{*}()|^{2} \), then we convert \(\) into \(\) by letting \(()=})}{1-f( )}\). The total variation distance between \(\) and \(D\) is:

\[d_{}(,D)=_{}}()-D()}}{{=}}_{}}}()}{1-f()}- ()}{1-f^{*}()}. \]

The "\(B\)-uniformly bounded" property in Definition 4.2 ensures \(D()=O(})\), which has two consequences: (1) \(P_{D}()=O(})\); (2) \(f^{*}()=O(1)\), which implies \(()}{1-f()}-( )}{1-f^{*}()}=O|( {r})-f^{*}()|\) due to Lipschitz property of the function \(\) for \(x=O(1)\). These two consequences imply

\[d_{}(,D) =O_{}}}()-f^{*}()=O _{}}P_{D}() ()-f^{*}()\] \[=O|()-f^{*}( )|}}{{}}O|()-f^{*}()|^{2}} =O().\]

So, we obtain \(d_{}(,D) O()=(1+B)^{2}\).

There is a subtlety, however: In the distribution learning problem we are given samples from \(D\), which are _signals_\(\{^{(t)}\}_{t=1}^{T}\). We need to convert them into the corresponding _reports_\(\{^{(t)}\}_{t=1}^{T}\) as the samples for the forecast aggregation problem. To do this we need to know \(P_{D}\) or \(D\), _which we do not know._ So, we make use of the "same marginal across distributions" property in Definition 4.2 here: because all the distributions \(D\) have the same marginal probability \(D(s_{i})=D^{}(s_{i})\) (but possibly different joint probabilities \(D() D^{}()\)), we are able to compute the report

\[r_{i}^{(t)}=P_{D}(=1 s_{i}^{(t)})=P_{D}(s_{i}^{(t) }|=1)}{P_{D}(s_{i}^{(t)}|=0)+P_{D}(s_{i}^{(t )}|=1)}=^{(t)})}{+D(s_{i}^{(t)})}\]

separately for each expert \(i\) without knowing \(D\), since we know what the family \(\) is. This allows us to reduce the distribution learning problem for \(\) to the forecast aggregation problem for \(\). 

Then, we find a family of distributions \(\) that satisfies the three properties in Definition 4.2 and requires many samples to learn.

**Proposition 4.4**.: _There exists a family of distributions \(\) that satisfies the three properties in Definition 4.2 (with \(B=e+\)) and requires \(T_{}^{}(_{},)= +(1/)}{e_{}^{2}}\) samples to learn._

The above sample complexity is smaller than the \(}|+(1/)}{e_{}^ {2}}\) lower bound in Proposition 3.3 because we are restricting to a smaller set of distributions than the set of all distributions over \(}\). The proof of Proposition 4.4 is analogous to a textbook proof of Proposition 3.3, which uses reductions from the distinguishing distributions problem. See details in Appendix E.2.

Finishing the proof of Theorem 4.1:By Lemma 4.3 and Proposition 4.4, plugging in \(_{}=(1+B)^{2}\) with \(B=e+\), we obtain the lower bound on the sample complexity of forecast aggregation for \(\) (and hence for \(_{}\)):

\[T_{}(,)\,\,T_{}^{}(1 +B)^{2},\,\,=\,+ (1/)}{((1+B)^{2})^{2}}\,=\, +(1/)}{}.\]Sample Complexity for Conditionally Independent Distributions

Section 4 proved that learning \(\)-optimal aggregators for all discrete distributions needs exponentially many samples. As shown in the proof, this large sample complexity is because the experts' signals can be arbitrarily correlated conditioned on the event \(\). Accurate estimation of such correlation requires many samples. So, in this section we restrict attentions to the case where the experts' signals are conditionally independent. It turns out that an \(\)-optimal aggregator can be learned using only \(O(})\) samples in this case, which does not depend on \(n\). The assumption of discrete signal space can be relaxed here. We also investigate two special and interesting families of conditionally independent distributions that admit an even smaller sample complexity of \(O()\).

### General Conditionally Independent Distributions

Let \(P\) be a conditionally independent distributions over \(}\), namely, \(P(\,|\,)=_{i=1}^{n}P(s_{i}\,|\,)\) for all \(}\), for \(\{0,1\}\). Here, \(_{i}\) can be a continuous space, in which case, \(P(\,|\,)\) represents a density function. We introduce some additional notations. Let \(p=P(=1)\) be the prior probability of \(=1\). For technical convenience we assume \(p(0,1)\). Define

\[==(0,+). \]

We will be working with ratios like "\(}{1-r_{i}}\)" and "\(\)" a lot in this section. We will use the following characterization of the optimal aggregator \(f^{*}\) for conditionally independent distributions:

**Lemma 5.1** ().: _For conditionally independent distribution \(P\), given signals \(=(s_{i})_{i=1}^{n}\), with corresponding reports \(=(r_{i})_{i=1}^{n}\) where \(r_{i}=P(=1|s_{i})\), the posterior probability of \(=1\) is:_

\[f^{*}()=P(=1\;|\;)=P(=1\;|\; )=_{i=1}^{n}}{r_{i}}}. \]

_(Define \(f^{*}()=0\) if \(^{n-1}_{i=1}^{n}}{r_{i}}=+\).)_

Lemma 5.1 implies that one way to learn \(f^{*}\) is to simply learn the value of \(\). If we can learn \(\) with accuracy \(}{n}\), then we can learn \(^{n-1}\) with accuracy \(\) and obtain an \(\) that is \(\)-close to \(f^{*}\) for every possible input \(^{n}\). However, by standard concentration inequalities, learning \(\) with accuracy \(}{n}\) requires \((}{})\) samples, which is larger than the \((})\) bound we will prove. The key is that we do not actually need \(()\) to be close to \(f^{*}()\) for _every_\(_{+}^{n}\); we only need the _expectation_\(|()-f^{*}()|^{2} \). This allows us to prove a smaller sample complexity bound, using a pseudo-dimension argument.

The main result of this section is that the sample complexity of forecast aggregation with respect to all conditionally independent distributions is between \(()\) and \(O(})\):

**Theorem 5.2**.: _Let \(_{}\) be the set of all conditionally independent distributions over \(}\). Suppose \(n 2\). The sample complexity of forecast aggregation with respect to \(_{}\) is_

\[O}\; \;T_{_{}}(,)\;\; . \]

We provide the main ideas of the proof of Theorem 5.2 here. The upper bound \(O(})\) is a corollary of our theorem for multi-outcome events (Theorem C.1), so we only give a sketch here. We note that, according to Lemma 5.1, the optimal aggregator has the form \(f^{*}()=_{i=1}^{n}}{r_{i}}}\).

We consider the class of aggregators \(=f^{}:f^{}()=_{i=1}^{n}}{r_{i}}}}\) parameterized by \((0,+)\). The class of loss functions \(=g^{}:g^{}(,)=|f^{}( )-|^{2}}\) associated with \(\) has _pseudo-dimension_\(()=O(1)\). By the known result (e.g., ) that the pseudo-dimension gives a sample complexity upper bound on the uniform convergence of a class of functions, we conclude that the empirically optimal aggregator in \(\) must be \(O()\)-optimal on the true distribution (with probability at least \(1-\)), given \(O}(()+)=O(} )\) samples.

We prove the \(()\) lower bound by a reduction from the distinguishing distributions problem (introduced in Section 3). We construct two conditionally independent distributions \(P^{1},P^{2}\) over the space \(}\) that differ by \(d_{}^{2}(P^{1},P^{2})=O()\) in squared Hellinger distance. Specifically, \(P^{1}\) has prior \(P^{1}(=1)=0.5-O()+O(}{n})\) and \(P^{2}\) has prior \(P^{2}(=1)=0.5-O()-O(}{n})\); the conditional distributions of each signal, \(P^{1}(s_{i}\,|\,)\) and \(P^{2}(s_{i}\,|\,)\), differ by \(O()\) in squared Hellinger distance; taking the product of \(n\) signals, \(P^{1}(\,|\,)\) and \(P^{2}(\,|\,)\) differ by \(O()\). The distinguishing distributions problem asks: given \(T\) samples from either \(P^{1}\) or \(P^{2}\), tell which distribution the samples come from. We show that, if we can solve the forecast aggregation problem, namely, \(\)-approximate \(f^{*}()=_{i=1}^{n}}{r_{i}}}\), then we can estimate \(\) with accuracy \(O(}{n})\), and hence distinguish \(P^{1}\) and \(P^{2}\). But distinguishing \(P^{1}\) and \(P^{2}\) requires \((}^{2}(P^{1},P^{2})})=( )\) samples. This gives the lower bound we claimed. See details in Appendix F.1.

### Strongly and Weakly Informative Experts

While the sample complexity of forecast aggregation for general conditionally independent distributions is \(O(})\), under further assumptions this bound can be improved. In particular, we find two special yet natural families of conditionally independent distributions that admit \(O()\) sample complexity. In these two cases, the experts are either "very informative" or "very noninformative". Roughly speaking, an expert is "very informative" if the conditional distributions of the expert's signal under event \(=0\) and \(=1\) are significantly different, so the expert's prediction \(r_{i}\) is away from the prior \(p\). An expert is "very non-informative" if the opposite is true. Intuitively, an expert being informative should help aggregation and hence reduce the sample complexity. Interestingly though, we show that even if the experts are non-informative the sample complexity of forecast aggregation can also be reduced. See details in Appendix B.

## 6 Extension: Multi-Outcome Events

Our main results regarding the sample complexity of forecast aggregation for binary events (Theorems 4.1 and 5.2) can be generalized to multi-outcome events with \(||>2\). We prove that: for general distributions, the sample complexity is \((}{})=(+(1/ )}{}) T_{}(,) O(+(1/)}{^{2}})=(}{ ^{2}})\); for conditionally independent distributions, the sample complexity is \(()=() T_{_{}}(,) O( }+})=(})\). See Appendix C for details.

## 7 Conclusion and Discussion

In this work, we showed an exponential gap between the sample complexity of forecast aggregation for general distributions, \((}{})\), and conditionally independent distributions, \((})\). This gap is due to the need of estimating the conditional correlation between experts in the general case, which is not needed in the conditional independence case. Notably, the bound \((})\) for conditionally independent distributions does not depend on the number of experts.

We discuss the dependency of the sample complexity on \(\) and other directions for future works:

The dependency on \(\)An open question left by our work is the dependency of the sample complexity on the parameter \(\). We conjecture that the tight dependency should be \(\) (so our lower bounds are tight). This is supported by the following evidence:

**Theorem 7.1**.: _For the case of \(||=2\) and for general distributions, if the distribution \(P\) has a minimum joint probability \(_{(,)}}P(,)>}\) for some \(c>0\), then the sample complexity of forecast aggregation is at most \(O}{c}(n m+)= }{c}\).5_

In particular, this theorem can be applied to distributions that are close to uniform, where \(P(,)}|}=}\), giving a bound of \((}{})\). Notably, the set of distributions we constructed in the proof of the \((}{})\) lower bound in Theorem 4.1 are also close to uniform. This means that close-to-uniform distributions have a tight sample complexity bound of the form \(\), not \(}\). Moreover, since close-to-uniform distributions are the "most difficult" distributions to learn in the distribution learning problem, it is likely that they are also the most difficult distributions for the forecast aggregation problem, and therefore the tight sample complexity of forecast aggregation should be determined by the sample complexity for those distributions, which is \(\).

Other future directions
* _The middle ground between fully correlated experts and conditionally independent experts:_ An example is the _partial evidence model_ in . Applying 's results, one can show that the sample complexity of forecast aggregation in the partial evidence model is at most \(}{^{2}}\).6 Giving a lower bound for the partial evidence model and exploring other intermediate models is open. * _Weaker benchmark:_ Since the Bayesian aggregator needs exponentially many samples to approximate, can we find a weaker yet meaningful benchmark with a small sample complexity?
* _Samples vs experts:_ In reality, obtaining samples of experts' historical forecasts can be difficult, while recruiting experts is easy. Can we achieve better aggregation by recruiting more experts instead of collecting more samples? How many experts do we need?
* _Eliciting more information:_ Previous works on information elicitation and aggregation have noticed that better aggregation can be achieved by eliciting more information than agents' own predictions, for example, also eliciting each agent's prediction about other agents' predictions (e.g., ). One can ask whether and how eliciting more information can help to reduce the sample complexity of information aggregation.
* _Continuous distributions:_ In our model the random variable \(\) to be predicted is discrete. One can study a setting where \(\) is a continuous random variable and the experts report, e.g., the means of their posterior beliefs about \(\). The results for continuous random variables might be very different from the results in this work.
* _Other loss functions:_ We focused on the squared loss \(|f()-|^{2}\) due to its popularity in machine learning problems and its useful property that the difference between the squared losses of any aggregator and the optimal aggregator is equal to their expected squared difference (Lemma 2.1). Alternatively, one can consider other loss functions like the logarithmic loss \([(f())+(1-)(1-f())]\) and the absolute loss \([|f()-|]\). There might be some technical challenges in the analysis of sample complexity for those loss functions, though: e.g., the logarithmic loss can be unbounded  and the absolute loss does not enjoy a property like Lemma 2.1.