# Biologically Inspired Learning Model for

Instructed Vision

 Roy Abel

Weizmann Institute of Science

roy.abel@weizmann.ac.il &Shimon Ullman

Weizmann Institute of Science

shimon.ullman@weizmann.ac.il

###### Abstract

As part of the effort to understand how the brain learns, ongoing research seeks to combine biological knowledge with current artificial intelligence (AI) modeling in an attempt to find an efficient biologically plausible learning scheme. Current models often use a cortical-like combination of bottom-up (BU) and top-down (TD) processing, where the TD part carries feedback signals for learning. However, in the visual cortex, the TD pathway plays a second major role in visual attention, by guiding the visual process toward locations and tasks of interest. A biological model should therefore integrate both learning and visual guidance. We introduce a model that uses a cortical-like combination of BU and TD processing that naturally integrates the two major functions of the TD stream. This integration is achieved through an appropriate connectivity pattern between the BU and TD streams, a novel processing cycle that uses the TD stream twice, and a 'Counter-Hebb' learning mechanism that operates across both streams. We show that the 'Counter-Hebb' mechanism can provide an exact backpropagation synaptic modification. Additionally, our model can effectively guide the visual stream to perform a task of interest, achieving competitive performance on standard multi-task learning benchmarks compared to AI models. The successful combination of learning and visual guidance could provide a new view on combining BU and TD processing in human vision and suggests possible directions for both biologically plausible models and artificial instructed models, such as vision-language models (VLMs).

## 1 Introduction

Understanding how the human brain learns has been a longstanding pursuit in both neuroscience and artificial intelligence (AI). An extensive research area at this intersection is the development of biologically plausible models of cortical learning, particularly in visual processes (Lee et al., 2015; Lillicrap et al., 2016; Scellier and Bengio, 2017; Whittington and Bogacz, 2017; Bozkurt et al., 2024). While the ultimate goal is to develop a detailed biological model, current research primarily focuses on potential schemes for modifying synaptic weights during learning, including how these modifications are determined and how they propagate through the cortical network (the credit assignment problem) (Whittington and Bogacz, 2019).

Biologically plausible learning models typically incorporate a combination of feedforward (bottom-up) and feedback (top-down) pathways, with the top-down (TD) stream playing a central role in the learning process, similar to the structure of the human cortex (Lillicrap et al., 2020; Song et al., 2021). However, a key distinction between these models and the cortex is that, while most biological models primarily use the TD stream to propagate feedback signals, in the cortex, the TD stream also plays a crucial role in perception by directing attention (Manita et al., 2015).

Top-down attention is an essential part of human vision and has been extensively studied in human physiology, anatomy, and psychophysics (Treisman and Gelade, 1980; Itti and Koch, 2001; Carrasco,2011]. Studies indicate that the TD stream directs visual processes toward selected locations and tasks, actively shaping the neural activity in the bottom-up (BU) stream and creating task-dependent representations in the cortex [Gilbert and Li, 2013, Harel et al., 2014]. Consequently, current biologically plausible models have been criticized for not involving the TD stream in ongoing visual processes [Lillicrap et al., 2020], and the challenge of incorporating the TD stream into feedforward BU processing remains an open research question [Zagha, 2020, Kreiman and Serre, 2020].

Our work addresses this gap and, to our knowledge, introduces the first biologically plausible learning model where the TD stream not only carries feedback signals but also performs visual guidance. This model tackles two key challenges that must be addressed together: first, _attention guidance_, understanding how the TD stream guides BU neural processing, and second, _learning_, determining synaptic modifications and solving the credit assignment problem in this guided processing context.

The dual role of the TD component in our model, involving both attention guidance and learning, may offer a more accurate depiction of bi-directional cortical processing and learning compared to existing models. For learning, we suggest a 'Counter-Hebb' mechanism, a modification of classical Hebbian learning [Hebb, 2005]. We show that this model can approximate the backpropagation (BP) synaptic modification [Rumelhart et al., 1986], and can provide an exact equivalence to BP under a symmetry assumption. Regarding its biological plausibility, we address the weight symmetry problem between forward and backward paths and use local synaptic updates dependent only on neurons associated with the modified synapse. Moreover, our method offers a possible solution to the long-standing challenge of integrating the TD stream into ongoing visual processing [Zagha, 2020, Kreiman and Serre, 2020, Lillicrap et al., 2020]. In the context of guidance, we demonstrate that the TD stream can be used both for learning and for directing the BU stream to perform tasks of interest by selecting a sparse, task-specific sub-network within the full BU network. We further show that this model achieves competitive results on standard multi-task learning benchmarks.

Beyond brain-related aspects, it is noteworthy that the integration of guidance is becoming a central aspect in recent AI models, particularly in Large Language Models (LLMs) and Vision-Language Models (VLMs). A fundamental characteristic of VLMs, similar to the brain, is their ability to focus on specific tasks of interest [Huang et al., 2023, Liu et al., 2024]. In these models, guidance is achieved through instructions that propagate through a language stream, which interacts with a visual component, allowing the model to dynamically adjust its attention to focus on the particular visual elements relevant to the task. This represents a significant shift from earlier computer vision models, where outputs relied exclusively on visual input and task instructions were implicitly embedded in the model design, with each task handled by a separate model. The parallel between AI advancements and brain modeling may deepen our understanding of the human brain and inspire the development of more advanced, human-like AI systems.

The key contributions of our work include:

* We propose the first biologically motivated learning model for instructed vision.
* We present a unified feedback mechanism that combines error propagation for synaptic learning with Top-Down attention to guide visual processing based on instructions.
* We suggest a Counter-Hebb learning procedure as a possible local synaptic modification that can perform exact backpropagation learning.

The code for reproducing the experiments and creating BU-TD models for guided models is available at [https://github.com/royabel/Top-Down-Networks](https://github.com/royabel/Top-Down-Networks).

## 2 Related work

The fields of brain modeling and AI have fruitful interactions going in both directions [Yamins and DiCarlo, 2016, Bowers, 2017, Yildirim et al., 2019]. Particularly, the study of biologically plausible learning models aims to deepen our understanding of the learning mechanisms in the human brain and enhance learning techniques for artificial neural network models. While artificial models primarily employ the backpropagation (BP) algorithm for learning [Rumelhart et al., 1986], a direct implementation of BP in biological models is generally considered biologically implausible [Whittington and Bogacz, 2019, Lillicrap et al., 2020]. Nevertheless, the integration of BP with biological principles, such as Hebb's plasticity rule [Hebb, 2005], has inspired the development of diverse biologically plausible learning approaches.

These learning methods are often compared to learning with BP, aiming to achieve similar performance in a more biologically plausible way. For instance, Equilibrium Propagation methods (Scellier and Bengio, 2017) suggest updating synaptic weights once the model reaches a stable equilibrium state under a given input. Equilibrium Propagation methods have been shown to produce weight updates equivalent to those in BP under specific conditions (Ernould et al., 2019), and approximate BP in other cases (Millidge et al., 2020). The Predictive Coding approach suggests that in visual processing, feedback connections carry predictions of neural activities, whereas feedforward streams carry the residual errors between these predictions and the actual neural activities (Rao and Ballard, 1999). It has been shown that using predictive coding to train a neural network in a supervised learning setting can yield parameter updates that closely approximate those produced by backpropagation (Whittington and Bogacz, 2017; Millidge et al., 2022a). While subsequent works have further developed these methods (Song et al., 2020; Salvatori et al., 2022), the introduced modifications have faced criticism for reducing their biological plausibility (Rosenbaum, 2022; Golkar et al., 2022).

Among biologically plausible approaches, Feedback Alignment and Target Propagation approaches are the most similar to our method. Like backpropagation, these approaches involve a forward (BU) stream that generates predictions from an input signal, followed by a backward (TD) stream that propagates feedback. While BP propagates gradients backward using the same weights as the forward path, feedback alignment methods propose propagating gradient-like signals through the TD stream with a separate set of weights, removing the symmetric weight structure of BP (Lillicrap et al., 2016; Nokland, 2016; Song et al., 2021). Recent findings show that lateral connections between feedforward and feedback streams can self-assemble and adapt, enhancing the biological plausibility of these approaches (Liao et al., 2024). The target propagation methods suggest propagating backward targets for the forward path instead of gradients (Bengio, 2014; Lee et al., 2015; Meulemans et al., 2020). Both feedback alignment and target propagation methods can approximate the BP update under specific conditions (Akrout et al., 2019; Ahmad et al., 2020; Ernould et al., 2022). Nevertheless, current models lack the extensive BU-TD interactions observed in the brain, which are essential for guiding attention in visual processes (Harel et al., 2014; Manita et al., 2015; Lillicrap et al., 2020).

### Guided visual processing

Human cortical processing uses a combination of bottom-up (BU) and top-down (TD) processing streams. In the visual brain, the BU stream proceeds from low-level sensory regions to high-level, more cognitive areas, while in the TD stream processing flows in the opposite direction (Dehaene et al., 2021). In human vision, the TD stream is involved in TD attention, guiding the visual process and directing it toward tasks of interest (Goddard et al., 2022; Shahdloo et al., 2022). For example, at the physiological level, it has been shown, in behaving primate studies, that given the same image, but with different tasks, the activation along the BU stream changes, modulated by TD activation, to focus on the instructed task (Gilbert and Li, 2013).

The ability to guide visual processing to extract specific aspects of the image is essential because a single image encompasses a wealth of information regarding objects, their parts and sub-parts, their properties, and inter-relations. Consequently, for complex images, it becomes difficult to extract and represent all the possibly meaningful information through a single visual representation (Huang et al., 2023). There are two approaches to address this challenge: one is to employ specialized models, each tailored to specific visual tasks, and the other is to develop general-purpose vision models that can selectively focus on relevant visual information

Empirical studies in artificial models have demonstrated that guiding the model's attention to selected locations or tasks offers advantages over non-guided, pure BU models (Tsotsos, 2021; Pang et al., 2021; Ullman et al., 2023). Furthermore, as opposed to earlier computer vision models, which relied solely on visual inputs without guidance, recent Vision Language Models (VLMs) have integrated instruction guidance mechanisms into their visual processing (Bai et al., 2023; Zhu et al., 2023; Liu et al., 2024; Dai et al., 2024). The processing of visual information in VLMs integrates a language stream that interacts with a visual stream and guides it to perform selected tasks. As a result, these models have been shown to have high generalization and zero-shot capabilities. The importance of guidance mechanisms in both the human cortex and AI models highlights the need for biologically inspired learning models that incorporate these mechanisms to neuroscience implications and potential advancements of artificial models. While our focus in this paper centers on vision, it is worth noting that our method can be applied to guided processing in other domains as well.

The bottom-up top-down model

This section introduces the proposed structure of the Bottom-Up (BU) and Top-Down (TD) networks. A BU network with \(L\) hidden layers is a function that maps an input vector \(x h_{0}\) to an output vector \(y\), such that for each layer \(0 l<L\): the hidden values are defined to be:

\[h_{l+1}(f_{l+1}(h_{0},h_{1},...,h_{l})) \]

The functions \(f_{l}\) are linear, and the activation function \(\) is an element-wise function that may be non-linear. To predict an output, we use a prediction head \(H_{pred}\), which is a small network, typically one to two layers, that maps the last hidden layer \(h_{L}\) to the predicted output: \(y=H_{pred}(h_{L})\).

For a given BU network, we define a symmetric TD network (denoted with upper bars) as the reverse-architecture network, that maps an input vector \(\) to an output vector \(_{0}\). The TD network is constructed based on the BU architecture as follows: The input (e.g. the prediction error) \(\) is mapped to the top-level hidden layer \(_{L}\) of the TD network via the TD prediction head: \(_{L}=_{pred}()\), and then for every \(0 l<L\):

\[_{l}(_{l+1}(_{L},_{L-1},...,_{l+1})) \]

The TD network satisfies two conditions. First, we restrict \(_{l}\) for each \(l\) so that \(h_{l}\) and \(_{l}\) will have the same size (the same number of neurons). This allows us to define pairs of corresponding neurons, assigning each BU neuron \(h_{l,i}\) in layer \(l\) a 'counter neuron' \(_{l,i}\) in the TD network. We also use the following notation for simplicity: \( h\). Additionally, we restrict \(_{l}\) to have the same connectivity structure as \(f_{l}\), but with the opposite direction: each pair of TD neurons is linked if and only if a link exists between their corresponding BU counter neurons. For example, given a fully connected layer \(h_{l}=f_{l}(h_{l-1})=W_{l}h_{l-1}\), the corresponding TD layer \(_{l}\) is defined to be also a fully connected layer \(_{l-1}=_{l}(_{l})=_{l}_{l}\) such that the shape of the TD weights matrix \(_{l}\) is equal to the shape of the transposed BU weights matrix \(W_{l}{}^{T}\).

### Activation functions and biases

The activation functions \(\), \(\), may be any element-wise functions. In this work, we focus on two functions. The first is ReLU which is commonly used for neural networks \(ReLU(x) x I_{\{x>0\}}\).

The second is the Gated Linear Unit (GaLU) (Fiat et al., 2019), which, in our model, leverages lateral connectivity between the BU and TD streams by gating neurons' activity based on the activation of their counter neurons.

\[GaLU(x) GaLU(x,) x I_{\{>0\}}= x&>0\\ 0& 0 \]

Where \(\) is the counter neuron of \(x\) (either a BU or a TD neuron), and \(I\) is an indicator function.

GaLU introduces bidirectional lateral connectivity between the BU and TD networks by temporarily turning off neurons based on the values of their counter neurons. As a result, each network can effectively guide its counterpart to operate on a specific partial sub-network.

In this paper, we omit bias terms to simplify the model. Nevertheless, biases can be implicitly expressed using the above notations by having additional neurons and weights, as commonly practiced (Lee et al., 2015; Ahmad et al., 2020). In addition, we allow two modes of biases. The first is the standard bias mechanism, in which biases contribute to the output. The second mode is 'bias-blocking' (Akrout et al., 2019) in which all bias terms are zeroed.

## 4 Counter-Hebbian learning

In this section, we formulate the Counter-Hebb learning. The Counter-Hebb (CH) rule updates each synapse based on the activities of its pre-synaptic neuron and its post-synaptic counter neuron. Consider a given weights matrix \(W\) such that \(b=Wa\). The \((i,j)\)-th entry in that matrix, \(W^{(t)}_{ij}\), represents the strength of the synapse connecting the pre-synaptic neuron \(a_{j}\) to the post-synaptic neuron \(b_{i}\) at time \(t\). Then the update rule is:

\[ W^{(t+1)}_{ij} W^{(t+1)}_{ij}-W^{(t)}_{ij}= a_{j} _{i} \]

[MISSING_PAGE_FAIL:5]

symmetric, as the value of the weights will be dominant by the values of the updates. Additionally, at any point during the training, if the BU and TD weights are symmetric, they will maintain this symmetry during the entire learning.

Given symmetric BU and TD weights, under the following standard conditions: 1) The BU network uses ReLU non-linearity 2) The error function computes the negative gradients of a loss function \(L\) with respect to the BU output, for example, \(error(y,)=-y\) for Mean Squared Error loss 3) The TD network uses GaLU non-linearity and bias-blocking mode (see Section 3.1). Then the TD backward step in Algorithm 1 is mathematically equivalent to the backward computation of the BP algorithm . As a result, in this configuration, Counter-Hebb learning effectively replicates the exact BP update, performing similarly to BP and preserving its mathematical properties. Moreover, relaxing the symmetry constraint under the above conditions results in a learning algorithm that approximates BP in the non-symmetric case. For a detailed explanation of this equivalence and approximation see A.1. Like some previous models, the CH has the desired property, as a biological model, of locality: the synaptic modifications are determined entirely by the activation values of neurons directly associated with the synapse.

## 5 Instruction-based learning

In the previous section, we described how the TD network can be used for learning a pure BU model. In this section, we describe how the model performs visual guidance. The TD network in our model can guide the BU network to perform multiple tasks by selecting a sub-network for each learned task (where sub-networks can overlap). In this setting, the objective is to predict an output \(y\) given an input \(x\) and a task \(t\). To accommodate this, the model has one additional head, resulting in two heads: a prediction head, and an instruction head. Each head consists of two parts: one for the BU network and the other for the TD network, preserving the symmetrical structure and lateral connectivity of the BU-TD core, see A.2 for more details on the heads.

The prediction head \(H_{pred}\), of one linear layer, is responsible for generating predictions and providing feedback, as discussed in section 3. The instruction head, \(H_{instruct}\), employs a 2-layer MLP for specifying the selected task, projecting instructional information to the visual space (and vice versa), similarly to instruction processing in VLMs. More specifically, the instruction head takes a task representation \(t\) as input and maps it to the top-level TD layer \(_{L}\). We use one-hot encoding for representing the tasks, however, more complex embedding could also be explored, such as a projection from an LLM. Note that in our experiments, we allow only one head to participate in each pass of the model (either the prediction or instruction head), refer to Fig 2 for an illustration of how the two heads are utilized in learning instruction-based models.

The instruction-based learning algorithm is shown in Algorithm 2. This algorithm consists of two passes for prediction (a TD followed by BU) followed by an additional TD pass for the learning, thereby extending Algorithm 1 by adding an instruction-processing step that selects a task-specific sub-network. Given a task \(t\), the TD instruction head is used to propagate the task representation along the TD network. Since each task activates different patterns, the activated neurons (i.e., with activation value larger than \(0\)) define a task-dependent sub-network. By running the BU network with GaLU activation, the BU computation is gated to propagate the input \(x\) along the corresponding BU sub-network. In this manner, the resulting algorithm learns for each task a different predictor which is conditioned on the task, resembling a modular architecture where different modules are dedicated to each task. See Fig 2 for a visualization of this guided process.

```
1:Input: data \(x\), ground truth label \(\)
2:Forward: \(y=BU(x)\)
3:Compute error: \(e=error(y,)\)
4:Backward: \(=TD(e)\)
5:Counter-Hebb Update: update \(W\) and \(\)
```

**Algorithm 1** Counter-Hebb Learning

Extending upon the results of section 4.1, with the constraint of symmetric BU and TD weights, both BP and CH learning produce identical updates within this guided learning framework, despite using the TD stream twice, see A.1 for more details. This equivalence provides mathematical guarantees to learning guided vision using a single TD network for both guidance and learning. Furthermore, symmetric weights have computational advantages. It enables extending standard BU architectures to instruction-based models without any additional parameters. For a given BU network, a complementary symmetric TD network can be constructed, sharing the same BU parameters. This TD network can guide the BU process of the original network to perform a given instruction.

## 6 Empirical results

In this section, we evaluate our BU-TD model, learned via Counter-Hebbian learning, in two settings: 1) unguided visual processing, to show that CH learning is capable of learning vision models 2) guided visual processing, to evaluate the ability of our model to guide the visual process according to instructions. Our goal is not to improve upon state-of-the-art models, but to show that the model, with a single top-down pathway for both error and instruction propagation, is comparable with current AI models, and capable of performing well two different functions: learning and directing attention.

### Unguided visual processing

In the unguided experiments, we evaluate the performance of the Counter-Hebb learning on standard image classification benchmarks: MNIST , Fashion-MNIST ,

Figure 2: The instruction-based learning algorithm. The three columns represent three passes of our model (left to right): \(TD BU TD\), where the first two passes provide a prediction output given an image and a task, and the last TD pass (in green frame) is used for learning. In _inference_, The BU visual process is guided by the TD network according to the given task. More specifically, The TD network propagates instruction signals downward followed by a guided BU process of the input image to compute predictions. By applying ReLU non-linearity, the input task selectively activates a subset of neurons (i.e. non-zero values), composing a sub-network within the full network. The BU network then processes an input image using a composition of ReLU and GaLU. The GaLU function (dashed arrows) gates the BU computation to operate only on the selected sub-network that was activated by the task. For _learning_, the same TD network is then reused to propagate prediction error signals with GaLU exclusively (no ReLU). Finally, the ’Counter-Hebb’ learning rule adjusts both networks’ weights based on the activation values of their neurons. Therefore, in contrast with standard models, the entire computation, including the learning, is carried out by neurons in the network, and no additional computation is used for learning (e.g. backpropagation)

and CIFAR10 (Krizhevsky et al., 2009). We followed the same experiments as Bozkurt et al. (2024) and used two-layer fully connected networks, with a hidden layer of size 500 for both MNIST and Fashion-MNIST datasets and size 1,000 for CIFAR10. Further details including the full set of hyperparameters can be found in Appendix A.4.2. We compare CH learning using the Cross-Entropy loss with backpropagation and other biological learning methods.

We examine two settings of CH learning, one where the BU and TD weights are initialized with symmetrical values, denoted as 'Sym Init', and the other where the weights are initialized differently, referred to as 'Asym Init'. The results, shown in Table 1, empirically validate that CH learning is equivalent to BP in the symmetric case, and approximates BP in the asymmetric case. Moreover, CH learning achieves comparable or superior performance compared with other biological methods. We further show the robustness of CH on other architectures and settings, such as convolutional networks, loss functions, and regularization. The results and additional information regarding these experiments can be found in Appendix A.4.2.

### Guided visual processing

In the guided experiments, we evaluate our model on two common multi-task learning (MTL) benchmarks. Since current biological methods are not capable of guided processing, we compare CH with non-biological state-of-the-art optimization methods as reported by Kurin et al. (2022), replicating their setup and using their reported results.

**The Multi-MNIST** dataset contains images of two overlaid digits, where the task indicates whether to classify the left or the right digit. Similar to the baselines, our BU network employs a simple architecture composed of two convolutional layers followed by a single fully-connected layer, with ReLU non-linearity, along with an additional fully-connected linear layer as the decoder (prediction head). To adapt this architecture to the BU-TD structure, we replace all max-pool layers with strided convolution layers, that perform a similar function as proposed by (Ayachi et al., 2020). Since the BU-TD model uses only sparse sub-networks within the full network, we increased the number of channels in each convolution layer, however, the actual network size is effectively smaller compared with the baselines, see Appendix A.6 for an analysis of the actual size of the sub-networks.

**The CelebA** dataset is a more challenging large-scale benchmark, comprising head shots of celebrities, along with the indication of the presence or absence of 40 different attributes. Each task is a binary classification problem for an attribute. As done in previous work (Kurin et al., 2022), we employ a ResNet-18 (He et al., 2016) architecture (without the final layer) with batch normalization layers (Ioffe and Szegedy, 2015), and a linear decoder. Additionally, we remove the last average pooling layer to support the symmetric BU-TD structure.

Unlike the baselines, we do not use any learning 'tricks' such as dropout layers, regularization, or early stopping. Additionally, while the baseline models require a separate decoder (prediction head) for each task, our BU-TD model can use a single shared decoder for all tasks. Further details,

   Method & MNIST & Fashion MNIST & CIFAR10 \\  CIM (2024) & 97.71 \(\) 0.1 & 88.14 \(\) 0.3 & 51.86 \(\) 0.3 \\ EP (2017) & 97.61 \(\) 0.1 & 88.06 \(\) 0.7 & 49.28 \(\) 0.5 \\ CSM (2021) & 98.08 \(\) 0.1 & 88.73 \(\) 0.2 & 40.79 \\ PC (2017) & 98.17 \(\) 0.2 & 89.31 \(\) 0.4 & - \\ PC-Nudge (2022b) & 97.71 \(\) 0.1 & 88.49 \(\) 0.3 & 48.58 \(\) 0.7 \\ FA (2016) & 97.95 \(\) 0.08 & 88.38 \(\) 0.9 & 52.37 \(\) 0.4 \\ BP & 98.27 \(\) 0.03 & 89.41 \(\) 0.2 & 53.96 \(\) 0.3 \\  BP (ours) & 98.33 \(\) 0.04 & 89.94 \(\) 0.2 & 55.47 \(\) 0.3 \\ CH Sym Init & 98.34 \(\) 0.06 & 89.99 \(\) 0.2 & 55.54 \(\) 0.3 \\ CH Asym Init & 98.17 \(\) 0.06 & 89.27 \(\) 0.1 & 54.28 \(\) 0.2 \\   

Table 1: Unguided learning results: mean and standard deviation of the test accuracy (in percentages) across 10 runs. The proposed CH learning algorithm is compared with BP and other biological state-of-the-art methods. The baseline results were taken from Bozkurt et al. (2024).

including exact architectures, hyper-parameters, and additional experiments with a single decoder, and varied network sizes, are provided in A.4.

The results, presented in Table 2, show that the proposed model successfully incorporates the two different TD functions, directing attention, and learning. The BU-TD model can achieve competitive performance compared with leading non-biological state-of-the-art methods. The proposed method may offer additional useful computational properties, such as compactness, see A.6.

### Weight symmetry

Weight symmetry poses a significant challenge in biological learning models, as copying the same weights across different locations is unrealistic in the brain, referred to as the 'weight transport' problem Grossberg (1987). Therefore, unlike backpropagation, biological models use different weights for feedforward and feedback streams. In this section, we further explore the effect of deviation from weight symmetry on the model performance, focusing on both symmetry in the initialization of the weights, and symmetry in the subsequent updates. We use below the terms'symmetric model' for models with symmetric weight initialization, 'asymmetric models' for weights initialized far from symmetry, and 'weak symmetric' for models initialized symmetrically (or nearly symmetric), but are subject to noisy, asymmetric updates. See A.5 for more details and additional experiments.

The results, presented in Table 3 and A.5, demonstrate that initial weight symmetry is more critical for approximating backpropagation performance than gradually converging to symmetry later in the learning process. The experiments show that performance degradation in the asymmetric case becomes more pronounced as task complexity and model size increase, even with weight decay applied to ensure convergence to symmetry. The results also show that our model demonstrates better scalability with asymmetric weights compared with some alternative methods, such as feedback alignment. In contrast, in the weak symmetric case, where weights do not maintain symmetry due to noise in updates, performance consistently remains nearly identical to standard back-propagation across all experiments. These results indicate that exact weight symmetry is not mandatory for backpropagation approximation. We hypothesize that Counter-Hebb learning, like backpropagation, depends on proper weight initialization to achieve optimal results, in addition to weight symmetry. By the time that symmetry of the weights is obtained, the weights may drift from their optimal initialization. This case will be similar to starting the standard backpropagation from non-optimal initialization conditions, leading in both cases to suboptimal performance. For more details regarding the effects of asymmetry see A.5.1.

## 7 Limitations

There are two directions that should be improved in the current model, one regarding performance and the second concerning biological aspects. In the asymmetric case, similar to other biologically inspired methods (Ernoult et al., 2022), we observe increasing performance gaps as task and model complexity

   Method & Multi-MNIST & CelebA \\  BP (Unit. Scal. (2022)) & 94.76 \(\) 0.44 & 90.90 \(\) 0.08 \\ IMTL (2021) & 94.87 \(\) 0.25 & 90.93 \(\) 0.08 \\ MGDA (2018) & 94.78 \(\) 0.20 & 90.22 \(\) 0.10 \\ GradDrop (2020) & 93.47 \(\) 1.30 & 90.98 \(\) 0.03 \\ PCGrad (2020) & 94.79 \(\) 0.36 & 90.93 \(\) 0.11 \\ RLW Diri. (2021) & 94.30 \(\) 0.30 & 90.99 \(\) 0.08 \\ RLW Norm. (2021) & 93.99 \(\) 0.89 & 90.95 \(\) 0.10 \\  CH Asym Init & 88.92 \(\) 2.15 & 79.25 \(\) 1.63 \\ CH Sym Init & 94.20 \(\) 0.30 & 89.69 \(\) 0.12 \\   

Table 2: Guided processing results: mean and 95% confidence interval of the avg. task test accuracy (in percentages) across 10 runs for _Multi-MNIST_ and 5 runs for _CelebA_. The proposed CH learning algorithm is compared with non-biological state-of-the-art methods, as reported in Kurin et al..

increase. However, the learning parameters, including the weight initialization scheme, have been carefully optimized for backpropagation (symmetric weights) over the years. Therefore, examining the effects of tuning parameters in the asymmetric case could improve performance. On the biological side, the plausibility of the model should be further explored. The main issue we identify (in ours and other models) is that propagating error signals along the TD stream requires the representation of both positive and negative values in neuronal activity [Lillicrap et al., 2020]. Following initial work, we suggest that this could be obtained by 'on' and 'off' channels [Ringach, 2004], where negative values in the 'on' channel are represented by positive values in the complementary 'off' channel.

## 8 Discussion

In this paper, we proposed the first biologically-motivated learning model for instructed visual processing. Similar to the visual cortex, it uses a bottom-up (BU) top-down (TD) structure, which, unlike previous learning models, uses the TD stream in ongoing visual processing by directing attention, e.g. to tasks and locations of interest.

Modeling guided visual learning is challenging since the prediction of the model depends on both the BU processing of the image and the task selected by a top-down instruction. The error signal needs, therefore, to propagate through both the BU and TD pathways, and at the same time the network is required to preserve the neural activations from the prediction phase since they determine the required changes in synaptic weights (Fig. 1). These requirements place significant constraints on the structure of the model network, however, our model meets the requirements and, as supported by mathematical foundations and empirical experiments, succeeds in learning guided vision for multiple tasks. Since the cortex performs similar guided vision, the proposed model may suggest a sketch model for the combination of the BU and TD streams in the visual cortex. Furthermore, the model shares a similar general structure with VLMs, in the sense of using two parallel streams, a visual one together with a more cognitive one. Since the human brain excels at combining visual and cognitive information in visual perception, the combination of instructed VLMs with principles from human BU-TD processing can offer a promising direction for future studies.

The model also suggests a Counter-Hebbian learning process in addition to the classical Hebb rule, where synapses are modified by combining a pre-synaptic signal with a signal coming from the appropriate counter stream. The existence of CH learning may be tested biologically by the controlled activation of selected layers. For example, cortical layer 3B receives feedforward connections from layer 4 while feedback connections arrive to layer 2/3A [Markov et al., 2014]. The counter-Hebbian model predicts that it may be possible to modify the forward synapses from layer 4 to layer 3B by simultaneous activation of the two inputs.

Counter-Hebb learning provides new directions for addressing the weight symmetry problem in biological learning models. Our findings indicate that exact weight symmetry is not crucial for achieving performance comparable to backpropagation and performance is more significantly influenced by the choice of weight initialization than by the precise symmetry in the weights. This suggests that discussions around biological feasibility in learning models should focus on obtaining nearly symmetric weights at initialization, rather than starting with asymmetric weights and relying on convergence to symmetry.

   Method & Train Accuracy & Test Accuracy \\  CH Symmetric (BP) & 100.00 \(\) 0.00 & 72.06 \(\) 0.69 \\ CH Asymmetric & 99.70 \(\) 0.15 & 61.58 \(\) 0.79 \\ CH Asymmetric + WD & 99.77 \(\) 0.18 & 62.05 \(\) 1.03 \\ CH Weak Symmetric & 100.00 \(\) 0.00 & 71.98 \(\) 0.17 \\ Feedback Alignment & 22.79 \(\) 1.90 & 23.11 \(\) 2.01 \\   

Table 3: Comparing different weight asymmetry settings: mean accuracy and 95% confidence interval (in percentages) across 5 runs evaluated on CIFAR10 using ResNet18.