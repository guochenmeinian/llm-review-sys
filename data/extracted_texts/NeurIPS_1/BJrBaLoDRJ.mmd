# A robust inlier identification algorithm for point cloud registration via \(\ell_{0}\)-minimization

# A robust inlier identification algorithm for point cloud registration via \(_{0}\)-minimization

Yinuo Jiang\({}^{1}\)

Xiuchuan Tang\({}^{2}\)

Equal contribution.

Cheng Cheng\({}^{1}\)

Ye Yuan\({}^{1}\)

\({}^{1}\)School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, China

\({}^{2}\)Department of Automation, Tsinghua University, China

{jiangyinuo,c_cheng,yye}@hust.edu.cn; tangxiuchuan@mail.tsinghua.edu.cn

[https://github.com/HAIRLAB/inlier-identification-via-10](https://github.com/HAIRLAB/inlier-identification-via-10)

Equal contribution.

###### Abstract

Correspondences in point cloud registration are prone to outliers, significantly reducing registration accuracy and highlighting the need for precise inlier identification. In this paper, we propose a robust inlier identification algorithm for point cloud registration by reformulating the conventional registration problem as an alignment error \(_{0}\)-minimization problem. The \(_{0}\)-minimization problem is formulated for each local set, where those local sets are built on a compatibility graph of input correspondences. To resolve the \(_{0}\)-minimization, we develop a novel two-stage decoupling strategy, which first decouples the alignment error into a rotation fitting error and a translation fitting error. Second, null-space matrices are employed to decouple inlier identification from the estimation of rotation and translation respectively, thereby applying Bayes Theorem to \(_{0}\)-minimization problems and solving for fitting errors. Correspondences with the smallest errors are identified as inliers to generate a transformation hypothesis for each local set. The best hypothesis is selected to perform registration. We demonstrate that the proposed inlier identification algorithm is robust under high outlier ratios and noise through experiments. Extensive results on the KITTI, 3DMatch, and 3DLoMatch datasets demonstrate that our method achieves state-of-the-art performance compared to both traditional and learning-based methods in various indoor and outdoor scenes.

## 1 Introduction

Point cloud registration is a fundamental task in vision and robotics, playing an important role in many applications such as 3D perception and reconstruction, simultaneous localization and mapping (SLAM), and autonomous driving . It aims to align two partially overlapping point clouds by estimating a rigid transformation between them. A common registration pipeline involves extracting features through 3D local descriptors, establishing correspondences based on feature matching, and estimating the rigid transformation . However, due to the less effectiveness of 3D local descriptors in feature extraction , correspondences established through feature matching are prone to outliers, resulting in inaccurate registration.

Recent works in point could registration with outliers can generally be categorized into three groups: learning-based, geometry-only, and optimization-based methods. Learning-based methods use networks to estimate confidence for correspondences and select those with high confidence for transformation estimation. These networks, however, are typically trained on specific scenarios, leading to limited generalization for outlier removal across various datasets . Geometry-only methods [6; 45], such as SC\({}^{2}\)-PCR  and MAC , filter out outliers using geometric relations between correspondences. Such methods [6; 45] rely on effective geometric features and may not produce acceptable inlier ratios in complex scenes or noisy environments .

On the other hand, optimization-based methods [4; 5; 18; 40; 46] solve the registration problem by formulating some non-convex objectives . The Branch-and-Bound (BnB) algorithm is widely used to solve non-convex objectives [4; 5; 40] due to its ability to guarantee global optimality. However, the efficiency of BnB is affected by the dimensions of search space and the bounds on objectives , which may lead to worst-case exponential time [18; 39]. An alternative approach is to relax the non-convex registration problem into a convex semidefinite program [3; 39]. However, semidefinite relaxation is computationally expensive and may introduce outliers or noise, leading to poor estimation results. Therefore, achieving robust and efficient registration in scenarios with high outlier ratios and noise remains a challenging problem.

To address these challenges, we propose a robust inlier identification algorithm for point cloud registration, which reformulates the conventional registration problem as an alignment error \(_{0}\)-minimization problem. More specifically, we define the alignment error and formulate an \(_{0}\)-minimization problem for each local set, where these sets are built from the compatibility graph of input correspondences. To resolve the non-convex \(_{0}\)-minimization problem effectively, we design a two-stage decoupling strategy. First, the alignment error is decoupled into a rotation fitting error and a translation fitting error by calculating the relative positions between points. This decoupling results in two fitting error \(_{0}\)-minimization problems with respect to rotation and translation, respectively. Second, null-spaces are introduced to remove rotation or translation from the constraints of fitting error \(_{0}\)-minimization problems, thereby decoupling inlier identification from the estimation of rotation or translation. The final decoupled \(_{0}\)-minimization problems are solved for fitting errors through Bayes Theorem. For each local set, correspondences with the smallest errors are identified as inliers to generate a transformation hypothesis. The best hypothesis is selected to perform registration.

To the best of our knowledge, we are the first to propose a \(_{0}\)-norm based approach to solve the registration problem. We experimentally demonstrate that the proposed algorithm is robust to high outlier ratios and noise, and is efficient with varying numbers of correspondences. Extensive results on the KITTI, 3DMatch, and 3DLoMatch datasets also demonstrate that our method achieves the highest registration accuracy while being competitive in time efficiency compared to state-of-the-art methods. In summary, our main contributions are as follows:

* A novel robust inlier identification algorithm is proposed by reformulating the conventional registration as an alignment error \(_{0}\)-minimization problem, which can effectively identify inliers and perform accurate registration under high outlier ratios and noise.
* A two-stage decoupling strategy is designed for the proposed \(_{0}\)-minimization problem. This strategy first decouples rotation and translation, and then decouples inlier identification from rotation or translation estimation.
* A robust Bayesian-based approach is proposed to solve the decoupled \(_{0}\)-minimization problem and identify inliers, enhancing the algorithm's performance on noisy data.

## 2 Related Work

**3D local descriptors.** Early handcrafted descriptors like PFH  and FPFH  mainly represent local features by encoding geometric histograms . More recent works attempt to encode 3D local descriptors in a data-driven way. FCGF  extracts features through a fully convolutional neural network. Predator  applies an attention mechanism to extract salient points in overlapping regions of point clouds. 3DMatch  and 3DSmoothNet  build a Siamese deep learning architecture for extracting local information. Although these feature descriptors achieve significant performance improvements, it is difficult to establish correspondences that are completely free of outliers . Therefore, robust registration is very important for accurate registration.

**Learning-based methods.** Inspired by the success of deep learning in 3D perception [34; 32; 37; 29], recent works have adopted learning networks for point cloud registration [1; 8; 19; 20; 44]. Deep

[MISSING_PAGE_FAIL:3]

an inlier (_i.e.,_ it satisfies \(|_{k_{i}}+-_{k_{i}}|_{k_{i}}\) with the Gaussian noise \(_{k_{i}}\)), \(_{k_{i}}\) should ideally be a zero vector. Consequently, the indices of zero vectors in the solution \(_{k}^{}\) of Eq. (2) correspond to the inlier indices in the \(k\)-th set. The formulations for other local sets are defined in a similar way.

A key insight into our approach is the use of \(_{0}\) norm to optimize alignment errors. This is based on the principle that only inliers can be fitted by the same transformation , and the optimal transformation is estimated as the one that fits the largest number of inlier correspondences. Therefore, our optimization objective is to maximize the count of zero vectors in the alignment error. Compared to the common formulations for point cloud registration , such as consensus maximization [5; 7] and truncated least-squares , our formulation reduces the impact of outliers through \(_{0}\) norm. The focus of this norm is to minimize the number of non-zero vectors rather than their magnitudes, thereby enhancing the robustness of our method to outliers and noise.

### Two-stage Decoupling Strategy

To resolve the proposed \(_{0}\)-minimization problem, we design a two-stage decoupling strategy. The solution process is described for the \(k\)-th local set and similarly applied to other local sets.

**Decoupling the alignment error into rotation and translation fitting errors.** Simultaneously estimating the rigid transformation with 6 degrees of freedom (DOF) is time-consuming due to the high-dimensional parameter space [5; 39]. To effectively resolve the \(_{0}\)-minimization problem proposed in Eq. (2) for each local set, we decouple the 6-DOF transformation into 3-DOF rotation and 3-DOF translation by computing the relative positions between point pairs. For any two given points \(_{k_{i}}\) and \(_{k_{j}}\) in the \(k\)-th local set, the translation vector \(_{k}\) cancels out in the subtraction :

\[_{k_{j}}-_{k_{i}}=_{k}(_{k_{j}}- _{k_{i}})+(_{k_{j}}-_{k_{i}})+ (_{k_{j}}-_{k_{i}})\,. \]

Based on Eq. (3), we define \(}_{k_{ij}}=_{k_{j}}-_{k_{i}}\) and \(}_{k_{ij}}=_{k_{j}}-_{k_{i}}\) as the relative positions. \(}_{k_{ij}}=_{k_{j}}-_{k_{i}}\) represents the rotation fitting error to minimize, unaffected by translation. \(_{k_{ij}}=_{k_{j}}-_{k_{i}}\) is the Gaussian noise. If both the \(i\)-th and \(j\)-th correspondences are inliers, \(}_{k_{ij}}\) should ideally be a zero vector. Therefore, the rotation fitting error \(}_{k_{ij}}\) for the correspondence pair \(_{k_{i}}=(_{k_{i}},_{k_{i}})\) and \(_{k_{j}}=(_{k_{j}},_{k_{j}})\) is formulated as:

\[}_{k_{ij}}=}_{k_{ij}}-_{k}}_{k_{ij}}-_{k_{ij}}\,. \]

Figure 1: **Pipeline of our method.** 1. Define alignment errors and formulate the \(_{0}\)-minimization problem for each local set. 2. Decouple alignment error into rotation and translation fitting errors and decouple inlier identification from the estimation of rotation or translation through the Bayes Theorem. 3. Select the best hypothesis for registration.

Having decoupled rotation from translation, we can now formulate the \(_{0}\)-minimization problem for the rotation fitting error \(}_{k}\) in the \(k\)-th local set, focusing on the 3-DOF rotation \(_{k}\):

\[}_{k}^{*} =_{}_{k}}\|}_{k}\|_{_{0}}\,,\] (5) subject to: \[}_{k}=}_{k}-}_{k} _{k}-}_{k}\,,\]

where \(}_{k}^{ 3}\) and \(}_{k}^{ 3}\) are relative positions between all point pairs in \(_{k}\) and \(_{k}\), respectively. Here, \(=(N_{2}-1)}{2}\) is the number of relative point pairs in a local set. The Gaussian noise \(}_{k}\) is modeled as \((0,_{R})\), where \(_{R}\) indicates the variance.

Once obtaining the rotation estimate \(_{k}^{*}\) by solving Eq. (5), we can substitute it back into Eq. (2) to estimate the translation. The \(_{0}\)-minimization problem for the translation fitting error \(}_{k}\) is formulated as follows, focusing on the 3-DOF translation \(_{k}\):

\[}_{k}^{*} =_{}_{k}}\|}_{k}\|_{_{0}}\,,\] (6) subject to: \[}_{k}=_{k}-_{k}_{k}^{*} -_{k}^{T}-_{k}\,,\]

where \(_{k}\) is modeled as \((0,_{t})\), where \(_{t}\) indicates the variance of Gaussian noise. The translation \(_{k}^{*}\) is estimated by solving Eq. (6).

**Decoupling rotation estimation from \(_{0}\)-minimization.** Optimizing the estimation of rotation while simultaneously identifying inliers is a chicken-and-egg problem, because reliable identification of inliers depends on the precise rotation estimation (as shown in Eq. (5)). To address this, we further decouple inlier identification from the estimation of rotation. The inliers that can be fitted by the same rotation are identified through Bayes Theorem and used for the subsequent rotation estimation.

We incorporate a robust Bayesian approach to solve Eq. (5), improving the algorithm's robustness to noisy data . The key step is to define a null-space matrix \(}_{k}\), whose rows form a basis for the left null space of \(}_{k}\). By left-multiplying each term in the constraint of Eq. (5) with \(}_{k}\), the component associated with the rotation \(_{k}\) is eliminated:

\[}_{k}}_{k}=}_{k}}_{k}-}_{k}}_{k}\,, \]

where \(}_{k}}_{k}\) represents the transformed rotation fitting error. Given that \(}_{k}\) is Gaussian noise and the left-multiplication by \(}_{k}\) is a linear operation, \(}_{k}}_{k}\) also follows a Gaussian distribution with a covariance matrix of \(_{R}}_{k}}_{k}^{T}\). The likelihood is formulated as:

\[P(}}_{k}}_{k})=(}_{k}}_{k},_{R}}_{k}) [-}\|(}_{k}-}_{k}}_{k})^{T}}_{k}^{-1}(}}_{k}-}_{k}}_{k})\|_{F}^{2}]\,, \]

where \(}}_{k}=}_{k}}_{k}\) and \(}_{k}}_{k}^{T}=}_{k}\). Based on the Bayes Theorem and Maximum A Posteriori (MAP) estimate, the unconstrained optimization for rotation fitting error \(_{0}\)-minimization in Eq. (5) is redefined as:

\[_{}_{k}}\|(}}_{k}-}}_{k})^{T}}_{k}^{-1}(}}_{k}-}_{k}}_{k})\|_{F}^{2 }+_{R}\|}_{k}\|_{_{0}}^{2}\,, \]

where \(_{R}\) is the regularization parameter that trades off the fitting error and model complexity. However, since the formulation incorporating the \(_{0}\) norm is known to be computationally expensive, we use the following convex relaxation:

\[_{}_{k}}\|(}}_{k}-}}_{k})^{T}}_{k}^{-1}(}}_{k}-}_{k}}_{k})\|_{F}^{2 }+_{R}\|}_{k}\|_{F}^{2}\,, \]

where \(\|\|_{F}\) is the Frobenius norm (\(F\) norm), which is both differentiable and convex. To find the optimal solution, we set the gradient of the objective function with respect to \(}_{k}\) to zero:

\[-}_{k}^{T}}_{k}^{-1}(}}_{k} -}_{k}}_{k})+2_{R}}_{ k}=0\,. \]

The optimal explicit solution \(}_{k}^{*}\) can be directly calculated as:

\[}_{k}^{*}=(}_{k}^{T}}_{k}^{-1} }_{k}+2_{R})_{k}^{-1}}_{ k}^{T}}_{k}^{-1}}_{k}\,. \]Based on \(}_{k}^{*}\), we identify top-\(K_{R}\) correspondences with minimal rotation fitting error for accurate rotation estimation. These correspondences, indexed by \(_{R}\), provide the basis for estimating rotation from the SVD decomposition of the matrix \(H=U V^{T}^{3 3}\). For the \(k\)-th local set, the rotation hypothesis is estimated as [5; 2]:

\[H=_{(i,j)_{R}}}_{k_{i}}}_{k_{j} }^{T}\,,\ \ _{k}^{*}=U(1,1,(UV^{T} ))V\,. \]

Decoupling translation estimation from \(_{0}\)-minimization.Employing a strategy similar to that used for rotation estimation, we utilize a null-space matrix \(_{k}\) that satisfies \(_{k}=\) to isolate the translation. By applying \(_{k}\) to the transpose of the constraint in Eq. (6), we eliminate the components associated with translation \(_{k}\):

\[_{k}}_{k}^{T}=_{k}(_{k }-_{k}_{k}^{*})^{T}-_{k}_{k}^ {T}\,. \]

Incorporating the Bayes Theorem, we formulate the following convex relaxation for the unconstrained optimization problem:

\[_{}_{k}}\|(_{k}-_ {k}}_{k}^{T})^{T}_{k}^{-1}(_{k}-_{k}}_{k}^{T})\|_{F}^{2}+_{t}\|}_{k}\|_{F}^{2}\,, \]

where \(_{k}=_{k}(_{k}^{T}-(_{k}_{k}^{*})^{T})\) and \(_{k}=_{k}_{k}^{T}\). The explicit solution \(}_{k}^{*}\) is obtained by solving the gradient of the objective function with respect to \(}_{k}\):

\[}_{k}^{*}=((2_{t}+_{k}^{T} _{k}^{-1}_{k})^{-1}_{k}^{T}_{k}^{-1}_{k})^{T}\,, \]

where \(\) denotes the identity matrix. Using \(}_{k}^{*}\), top-\(K_{t}\) correspondences with the smallest errors are identified as inliers for translation estimation. Their index set is denoted as \(_{t}\). The translation hypothesis \(_{k}^{*}\) for the \(k\)-th local set is estimated based on these inliers \((_{k_{i}},_{k_{j}})\), with \((i,j)_{t}\).

### Hypothesis Selection

Finally, we evaluate and select the best estimation from the transformation hypotheses computed for all local sets:

\[(^{*},^{*})=_{_{k_{i}}^{*}_{k }^{*}}_{i=1}^{N}[\|_{k}^{*}_{i}+_ {k}^{*}-_{i}\|_{2}<]\,, \]

where \(N_{c}\) is the number of input initial correspondences and \(\) is a predefined error threshold. For each transformation hypothesis, we quantify its effectiveness by counting the number of correspondences that satisfy the constraints within \(\). The transformation with the highest inlier count is selected for registration.

## 4 Experiments

### Datasets and Experimental Setup

**Synthetic dataset.** We evaluate the accuracy, robustness, and efficiency of our algorithm using the Bunny point cloud from the Stanford 3D Scan Repository . Similar to [5; 39], the Bunny model is downsampled to \(N_{c}\) points and resized to fit a \(^{3}\) cube, creating the source point cloud \(\). To generate the target point cloud \(\), a random transformation \((,)\) is applied to \(\) and then Gaussian noise \(_{i}(0,^{2}_{3})\) is added. A pair of the original and moved points defines an inlier. The inliers are contaminated with outliers generated by random transformations.

**Outdoor scenes.** For evaluations on outdoor scenes, we conduct experiments on the KITTI dataset . Following [5; 6], we use \(555\) pairs of point clouds from scenes \(8\) to \(10\) for testing. We construct a \(30\)cm voxel grid to downsample point clouds and form correspondences using handcrafted FPFH  and learned FCGF  descriptors.

**Indoor scenes.** We conduct experiments on the 3DMatch dataset  to evaluate performance on indoor scenes. Following [5; 6; 45], we use RGB-D scans from \(8\) real indoor scenes for testing. The point clouds are downsampled using a 5cm voxel grid. We use the hand-crafted FPFH  along with two learned descriptors, FCGF  and 3DSmoothNet , for feature extraction. To evaluate our method in more challenging scenarios, we conduct experiments on 3DLoMatch  (overlap rate between scenes \(<30\%\)). Following , the Predator descriptor  is used in 3DLoMatch.

**Evaluation criteria.** Following , we use the rotation error (RE), translation error (TE), and registration recall (RR) as evaluation metrics. The registration is considered successful when the \( 15^{}\), \( 30\)cm on 3DMatch & 3DLoMatch datasets, and \( 5^{}\), \( 60\)cm on KITTI dataset. Average RE and TE are computed only on the successfully registered pairs .

**Implementation details.** We implement our method in PyTorch . All the experiments are conducted on a machine with an Intel Xeon Gold 6134 CPU and a single NVIDIA GTX3090.

### Evaluation on Synthetic Dataset

**Robustness to outliers.** We evaluate the robustness to outliers by increasing the outlier ratio from \(10\%\) to \(90\%\). The Bunny point cloud is downsampled to \(N_{c}=500\). We add zero-mean Gaussian noise with a standard deviation set to \(=0.01\). For each outlier ratio, we conduct \(50\) independent trials and report the average rotation error (RE) and translation error (TE). We compare our method with state-of-the-art traditional methods . As shown in the first row of Fig. 2, the rotation and translation errors of FGR  increase sharply as the proportion of outliers increases. RANSAC  and GORE  start failing at an outlier ratio of \(60\%\). Our method remains robust to outliers up to \(90\%\) and produces more accurate estimates than all other methods. We further

Figure 3: **Robustness to noise.** Comparison results with  as the noise standard deviation increases from \(0.01\) to \(0.09\) on the Bunny dataset .

Figure 2: **Robustness to outliers.** The first row compares the rotation and translation errors as the outlier ratio increases from \(10\%\) to \(90\%\) on the Bunny dataset , while the second row focuses on the scenarios of extreme outliers, _i.e.,_ the outlier ratio varies from \(91\%\) to \(99\%\). Our method demonstrates to be more robust to outliers compared to other methods .

compare the performance of different methods under extreme outlier ratios, _i.e.,_ when the outlier ratio increases from \(91\%\) to \(99\%\). The second row of Fig. 2 shows that even with outlier ratios as high as \(99\%\), our method continues to perform well, consistently producing lower transformation errors than other methods.

**Robustness to noise.** We further evaluate the robustness against Gaussian noise with different variances. As the noise standard deviation increases from \(=0.01\) to \(=0.1\), the geometric structure of the Bunny model is completely destroyed  (refer to Appendix A.5). Fig. 3 shows the comparison results as \(\) increases from \(0.01\) to \(0.09\). When the noise variance reaches \(0.03\), the translation errors of geometric-only method MAC  significantly increase. Both FGR  and RANSAC  show large rotation errors when \(\) increases to \(0.05\). In contrast, our method achieves the lowest rotation and translation errors under high noise, demonstrating its robustness to noise.

**Efficiency and accuracy.** We increase the number of correspondences \(N_{c}\) from \(250\) to \(5000\) to compare efficiency and accuracy. We set the noise standard deviation \(\) to \(0.01\) and the outlier ratio to \(50\%\). The comparison results are shown in Fig. 4(a). As the number of correspondences increases, the running time of GORE  and TEASER++  increases significantly. Notably, when \(N_{c}\) grows to \(2500\), the running time of GORE is about \(10^{4}\) times longer than that of our method. Our method solves the \(_{0}\)-minimization problems with explicit solutions, significantly enhancing efficiency through parallel matrix computations and GPU execution. The curves of FGR, RANSAC, MAC, and our method in Fig. 4(a) are flat and difficult to visually distinguish, indicating the efficiency of these methods. However, as shown in Appendix A.6, our method outperforms FGR , RANSAC , and MAC  in registration accuracy. Therefore, our inlier identification algorithm via \(_{0}\)-minimization is efficient while maintaining high accuracy.

**Effectiveness of the two-stage decoupling strategy.** We evaluate the effectiveness of the two-stage decoupling strategy (TDS) by formulating the \(_{0}\)-minimization problem directly on the Bunny data instead of local sets and estimating the final rotation and translation. Specifically, we set \(N_{c}=100\) and \(=0.01\). As shown in Fig. 4(b), we compare the TDS with optimization-based

    &  &  &  \\  & RR(\%)\(\) & RE(\({}^{}\))\(\) & TE(cm)\(\) & RR(\%)\(\) & RE(\({}^{}\))\(\) & TE(cm)\(\) &  \\  _i) Traditional_ & & & & & & & & \\ FGR  & \(5.23\) & \(0.86\) & \(43.84\) & \(89.54\) & \(0.46\) & \(25.72\) & \(3.88\) \\ RANSAC  & \(74.41\) & \(1.55\) & \(30.20\) & \(80.36\) & \(0.73\) & \(26.79\) & \(5.43\) \\ TEASER++  & \(91.17\) & \(1.03\) & \(17.98\) & \(95.51\) & \(0.33\) & \(22.38\) & \(0.03\) \\ SC\({}^{2}\)-PCR  & \(99.46\) & \(0.35\) & \(7.87\) & \(98.02\) & \(0.33\) & \(20.69\) & \(0.31\) \\ MAC  & \(97.66\) & \(0.41\) & \(8.61\) & \(97.84\) & \(0.34\) & \(19.34\) & \(3.29\) \\ TR-DE  & \(96.76\) & \(0.90\) & \(15.63\) & \(\) & \(0.38\) & \(\) & - \\ TEAR  & \(99.10\) & \(0.39\) & \(8.62\) & - & - & - & - \\  _ii) Deep learned_ & & & & & & & & \\ DGR  & \(77.12\) & \(1.64\) & \(33.10\) & \(96.90\) & \(0.34\) & \(21.70\) & \(2.29\) \\ PointDSC  & \(98.92\) & \(0.38\) & \(8.35\) & \(97.84\) & \(0.33\) & \(20.32\) & \(0.45\) \\ VBReg  & \(98.92\) & \(0.45\) & \(8.41\) & \(98.02\) & \(0.32\) & \(20.91\) & \(0.24\) \\  Ours & \(\) & \(\) & \(\) & \(\) & \(\) & \(20.73\) & \(0.54\) \\   

Table 1: Comparison results on KITTI dataset  using the FPFH  and FCGF  descriptors.

Figure 4: **Efficiency and effectiveness.** The experiment results on the Bunny dataset . (a) Efficiency comparison with other methods  with respect to the number of correspondences. (b) Comparison of the proposed two-stage decoupling strategy (TDS) with optimization-based methods at an outlier ratio of \(90\%\).

methods [4; 12; 39; 46] at an outlier ratio of \(90\%\). Our TDS achieves the highest registration accuracy, demonstrating its inlier identification capability. Additional competitive results as the outlier ratio increases from \(0\%\) to \(90\%\) are provided in Appendix A.7.

### Evaluation on Outdoor Scenes

To evaluate our algorithm on real outdoor scenes, we conduct experiments on the KITTI dataset . The comparison results with state-of-the-art traditional [5; 6; 12; 18; 39; 45; 46] and learning-based [1; 8; 19] methods are reported in Table 1. We first use the FPFH  descriptor to generate initial correspondences. As shown in the left column of Table 2, our method outperforms traditional and learning-based methods on all metrics. For the most important criterion of registration recall (RR), our method improves by about \(2\%\) over the nearest competitor MAC . Following , the average RE and TE are only calculated on successfully registered pairs, which makes methods with high registration recall more likely to have larger average errors. Nonetheless, our method still achieves the best results on RE and TE. Besides, we report the comparison results with the FCGF  descriptor in the right column of Table 2. Our method achieves the highest RR and the lowest RE due to its effective inlier identification algorithm. The superior performance demonstrates the ability of our method to align sparse and non-uniformly distributed data in outdoor scenes. In addition to its high accuracy, our method also achieves comparable efficiency, making it highly competitive for practical applications. The visualizations of registration results on KITTI are provided in Appendix A.12.

### Evaluation on Indoor Scenes

We further conduct experiments on the 3DMatch  and 3DLoMatch  datasets to evaluate the performance in real indoor scenes. The comparison results are reported in Table 2 and Table 3.

**Combined with FPFH, FCGF, and 3DSmoothNet descriptors.** As shown in the left column of Table 2, compared to both traditional and learning-based methods, our method achieves the highest RR with the handcrafted FPFH  descriptor. The middle column of Table 2 reports the comparison results with the learned FCGF  descriptor. Our method achieves the lowest RE and TE. Compared to SC\({}^{2}\)-PCR , our method improves the RR, RE, and TE by \(0.13\%\), \(0.97\%\), and \(0.77\%\) respectively,

    &  &  &  &  \\  & RR(\%) & RE(\%) & TE(cm) & RR(\%) & TE(cm) & TE(cm) & RR(\%) & TE(cm) & TE(cm) & & \\  _i) Traditional_ & & & & & & & & & & & \\ FGR  & \(40.91\) & \(4.96\) & \(10.25\) & \(78.93\) & \(2.90\) & \(8.41\) & \(73.26\) & \(2.51\) & \(7.45\) & \(0.89\) \\ RANSAC  & \(66.10\) & \(3.95\) & \(11.03\) & \(91.44\) & \(2.69\) & \(8.38\) & \(92.30\) & \(2.59\) & \(7.91\) & \(2.86\) \\ TEASER+  & \(75.48\) & \(2.48\) & \(7.31\) & \(85.71\) & \(2.73\) & \(8.66\) & \(92.05\) & \(2.23\) & \(6.62\) & \(0.03\) \\ SC\({}^{2}\)-PCR  & \(83.90\) & \(2.12\) & \(6.69\) & \(93.16\) & \(2.06\) & \(6.53\) & \(94.82\) & \(1.76\) & \(5.98\) & \(0.12\) \\ MAC  & \(83.90\) & \(\) & \(6.80\) & \(\) & \(\) & \(6.54\) & \(94.57\) & \(2.21\) & \(6.52\) & \(5.54\) \\ TR-DE  & - & - & - & - & - & - & \(91.37\) & \(2.71\) & \(7.62\) & - \\ TEAR  & - & - & - & - & - & - & \(94.52\) & \(2.06\) & \(6.55\) & - \\  _ii) Deep learned_ & & & & & & & & & & \\ DOR  & \(32.84\) & \(2.45\) & \(7.53\) & \(88.85\) & \(2.28\) & \(7.02\) & - & - & - & \(1.53\) \\ PointDSC  & \(72.95\) & \(2.18\) & \(\) & \(91.87\) & \(2.10\) & \(6.54\) & \(93.65\) & \(2.17\) & \(6.75\) & \(0.10\) \\ VBBReg  & \(82.57\) & \(2.14\) & \(6.77\) & \(93.53\) & \(\) & \(6.49\) & \(37.09\) & \(6.15\) & \(15.65\) & \(0.20\) \\  Ours & \(\) & \(2.12\) & \(6.64\) & \(93.28\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(0.36\) \\   

Table 2: Comparisons results on 3DMatch  using FPFH, FCGF, and 3DSmoothNet descriptors.

Figure 5: **Qualitative comparisons with other methods.** Qualitative comparisons on the 3DMatch (the first row) and 3DLoMatch (the second row) datasets.

which benefit from our \(_{0}\)-minimization formulation for inlier identification. Since TR-DE  and TEAR  have not made their code or results for FPFH and FCGF publicly available, their results are excluded in the left and middle columns of Table 2. Following , we also compare the registration accuracy using the learned 3DSmoothNet  to extract features. The results in the right column of Table 2 show that our method outperforms all other methods across all evaluation metrics, demonstrating the robustness of our method to different local descriptors. We show the results of qualitative comparisons in Fig. 5 and Appendix A.12. Methods such as MAC may fail in scenes with ambiguous features or limited overlap. Our algorithm still achieves satisfactory alignment and is close to the ground truth.

**Robust to lower overlap ratios.** Furthermore, we report results for a more challenging dataset: 3DLoMatch  (overlap rate < \(30\%\)). Following , we use the Predator  descriptor to generate the initial correspondences. We compare the registration recall (RR) under different numbers of correspondences. As shown in Table 3, the proposed method improves the average RR by \(7\%\) over TR-DE , demonstrating the effectiveness of our method in dealing with low-overlap scenarios. In Fig. 6, we compare the output inlier ratio with traditional methods  in the low overlap scenario. Our method is more effective with more correct predicted inliers.

## 5 Conclusion

In this paper, we propose a robust inlier identification algorithm by reformulating the conventional registration problem as an alignment error \(_{0}\)-minimization problem. For each local set, we resolve the \(_{0}\)-minimization problem using a designed two-stage decoupling strategy. First, the alignment error is decoupled to a rotation fitting error and a translation fitting error, formulating two decoupled \(_{0}\)-minimization problems. Second, null-space matrices are introduced to decouple the inlier identification from the estimation of rotation or translation respectively, there by applying a robust Bayesian approach to decoupled \(_{0}\)-minimization problems and solving for fitting errors. Correspondences with the smallest errors are identified as inliers to generate a transformation hypothesis for each local set. We experimentally demonstrate that the proposed algorithm is robust to high outlier ratios and noise. Extensive results on the KITTI, 3DMatch, and 3DLoMatch datasets also demonstrate that our method achieves state-of-the-art registration accuracy while being comparable in efficiency in both indoor and outdoor scenes. Limitations and broader impact are discussed in Appendix A.10.

## 6 Acknowledgements

This work was supported by the National Natural Science Foundation of China (Grant numbers 92167201, 52188102, 62373160).

Figure 6: **Comparison results on output inlier ratio. We compare the predicted inlier counts of correct and incorrect correspondences in 3DLoMatch . The first column provides the ground truth alignment, which shows that overlap is very limited. The significantly larger inlier ratio can be observed from the incorrect (red lines) and correct (green lines) correspondences.**

   & \(5000\) & \(2500\) & \(1000\) & \(500\) & \(250\) \\   \\  FGR  & \(36.4\) & \(38.2\) & \(39.7\) & \(39.6\) & \(38.0\) \\ RANSAC  & \(62.3\) & \(62.8\) & \(62.4\) & \(61.5\) & \(58.2\) \\ TEASER++  & \(62.9\) & \(62.6\) & \(61.9\) & \(59.0\) & \(56.7\) \\ SC\({}^{2}\)-PCR  & \(68.9\) & \(68.4\) & \(68.7\) & \(67.1\) & \(64.9\) \\ MAC  & \(69.4\) & \(69.3\) & \(68.4\) & \(67.7\) & \(64.6\) \\ TR-DE  & \(64.0\) & \(64.8\) & \(61.7\) & \(58.8\) & \(56.5\) \\ PointSDC  & \(68.1\) & \(67.3\) & \(66.5\) & \(63.4\) & \(60.5\) \\ VBReg  & \(\) & \(\) & \(68.7\) & \(66.4\) & \(63.0\) \\  Ours & \(\) & \(\) & \(\) & \(\) & \(\) \\  

Table 3: Registration rate on the 3DLoMatch dataset  with different number of correspondences.