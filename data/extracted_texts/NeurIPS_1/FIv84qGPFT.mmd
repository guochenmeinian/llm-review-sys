# Pseudo-Likelihood Inference

Theo Gruner \({}^{1,2}\) Boris Belousov \({}^{3}\) Fabio Muratore \({}^{4}\)

Daniel Palenicek \({}^{1,2}\) Jan Peters \({}^{1,2,3,5}\)

\({}^{1}\) Intelligent Autonomous Systems Group, Technical University of Darmstadt

\({}^{2}\) hessian.AI \({}^{3}\) German Research Center for AI (DFKI)

\({}^{4}\) Bosch Center for Artificial Intelligence \({}^{5}\) Centre for Cognitive Science

theo_sunao.gruner@tu-darmstadt.de

###### Abstract

Simulation-Based Inference (SBI) is a common name for an emerging family of approaches that infer the model parameters when the likelihood is intractable. Existing SBI methods either approximate the likelihood, such as Approximate Bayesian Computation (ABC), or directly model the posterior, such as Sequential Neural Posterior Estimation (SNPE). While ABC is efficient on low-dimensional problems, on higher-dimensional tasks, it is generally outperformed by SNPE which leverages function approximation. In this paper, we propose Pseudo-Likelihood Inference (PLI), a new method that brings neural approximation into ABC, making it competitive on challenging Bayesian system identification tasks. By utilizing integral probability metrics, we introduce a smooth likelihood kernel with an adaptive bandwidth that is updated based on information-theoretic trust regions. Thanks to this formulation, our method (i) allows for optimizing neural posteriors via gradient descent, (ii) does not rely on summary statistics, and (iii) enables multiple observations as input. In comparison to SNPE, it leads to improved performance when more data is available. The effectiveness of PLI is evaluated on four classical SBI benchmark tasks and on a highly dynamic physical system, showing particular advantages on stochastic simulations and multi-modal posterior landscapes.

## 1 Introduction

Parametric stochastic simulators are a well-established tool for predicting the behavior of real-world phenomena. These statistical models find widespread use in various scientific fields such as physics, economics, biology, ecology, computer science, and robotics, where they help to gain knowledge about the underlying stochastic processes  or generate additional data for subsequent downstream tasks . In both cases, the practitioner seeks to explain the observations as accurately as possible while incorporating all available information. The output of such a simulator is largely determined by its parameters and their values. When estimating these parameters using Bayesian inference, given observations from a physical system, which are inevitably subject to measurement noise, we obtain a distribution over values instead of a point estimate. Additionally, there might be several parameter configurations yielding the same observation, hence rendering the resulting distribution to be multi-modal. Moreover, the likelihood function might be unknown or too expensive to evaluate for many practical use cases. The combination of these difficulties makes obtaining a posterior distribution over simulator parameters challenging for state-of-the-art inference methods, both regarding effectiveness and efficiency.

SBI approaches address the issue of intractable likelihoods by using (stochastic) simulators as forward models to generate observations from proposal distributions over parameters. The approaches are also often called _likelihood-free_, which can be easily misunderstood since some of them directly approximate the likelihood . ABC is a family of SBI methods that approximate the posterior witha set of weighted particles which are obtained from Monte Carlo simulations and updated based on an empirical estimation of the intractable likelihood . For an ABC approach to work well, three criteria have to be fulfilled: (i) the likelihood kernel is capable of measuring the similarity of observations meaningfully, (ii) the proposal distribution samples close to the posterior, (iii) the decision-making rule balances between accepting a sufficient amount of samples from the proposal and steering inference towards the posterior distribution. Constructing a suitable likelihood kernel often means tailoring summary statistics to the problem at hand. However, recent advances promise to replace this heuristic-based process by employing Integral Probability Metrics (IPMs) to measure statistical distances in observation space [3; 16; 17]. While these methods significantly increase the required number of simulations, approximations of the statistical distances [25; 8] can be computed in parallel, hence facilitating the parallelization of the whole inference pipeline. Following up on the shortcomings of ABC, the family of SNPE approaches provide Bayesian inference methods that leverage conditional neural density estimators to approximate the posterior [40; 24; 41; 19]. The benchmarking study of Lueckmann et al.  concludes that, generally, SNPE approaches are to be preferred over ABC as they are superior in terms of expressibility and accuracy across a wide range of benchmarking tasks. However, it is important to point out that the analysis of the posterior inference has solely been reported for single observations. These single-sample scenarios favor SNPE in high dimensions since ABC relies on summary statistics to evaluate the likelihood. Therefore, it remains an open question whether SNPE methods can transfer their benefits to settings where the (approximated) posterior is conditioned on multiple observations at once.

Contributions.By deriving the ABC posterior from a constrained variational inference objective, we introduce a novel SBI method called Pseudo-Likelihood Inference (PLI). Our formulation allows for approximating the posterior with neural density estimators. PLI updates this posterior from pseudo-likelihoods which are exponentially transformed statistical distances computed using IPMs. To further remove heuristics from the inference process, we derive an adaptive bandwidth update of PLI's likelihood kernel that bounds the loss of information based on information-geometric trust-region principles. This way, PLI can update its neural posterior solely given observations from a (stochastic) black-box simulator. Moreover, the usage of IPMs enables PLI to simultaneously condition on a variable number of observations, while SNPE methods need to concatenate them and, therefore, degrade when the number of observations increases. We compare PLI against ABC and one SNPE method on two SBI benchmarking tasks as well as a highly dynamical double pendulum task. For both, ABC and PLI, we investigate two IPMs: the Maximum Mean Discrepancy (MMD) and the Wasserstein distance. Motivated by recent benchmarking results, we chose Automatic Posterior Transformation (APT)  to represent SNPE approaches. Our experiments investigate the dependency of the trained density estimator's performance on the number of observations, where performance is measured in observation as well as in parameter space. We show the merits and disadvantages of all methods and conclude with concrete recommendations.

## 2 Bayesian inference with intractable likelihoods

The objective of Bayesian inference is to find the posterior parameter distribution \(p(|_{1:N}^{})\) given a set of reference data points \(_{1:N}^{}\) which are assumed to be drawn from the likelihood model \(p(|)\). Given a prior belief over the parameters \(p()\), the posterior is expressed via Bayes' rule

\[p(|_{1:N}^{}) p(_{1:N}^{ }|)\;p(). \]

In the following, we describe SBI methodologies that aim to approximate the posterior (1) when the likelihood is given by a simulator model, from which only sampling is possible, \(_{1:M} p(|)\) but evaluating the likelihood is infeasible.

### Approximate Bayesian computation

ABC methods perform Bayesian inference without explicitly computing the likelihood function \(p(_{1:N}^{}|)= p(_{1:N}^{}|_{1:M},)p(_{1:M}|)\;_{1:M}\). Instead, they approximate it

\[_{}(_{1:N}^{}|) K_ {}(D(_{1:N}^{},_{1:M}))\;p(\(^{}_{1:N}\) and the simulated data \(_{1:M}\) based on a distance measure \(D\), the kernel type \(K\), and the kernel bandwidth \(\). The uniform kernel \(_{\{D(^{}_{1:N},_{1:M})\}}\) (see Table A.1) has emerged as the default kernel choice of many ABC methods [49; 15; 30; 31]. In this case, the bandwidth represents a rejection threshold that assigns zero probability to all parameters whose simulations lie outside of the \(\)-ball in terms of the distance \(D\). The uniform kernel exhibits the favorable characteristic of converging to the likelihood in the limit 

\[_{ 0}_{}(^{}_{1:N}|)= _{\{^{}_{1:N}\}}(_{1:M})p(_{1:M}| )_{1:M}=p(^{}_{1:N}|). \]

Once the approximate likelihood (2) is obtained, ABC draws samples from the approximate posterior

\[_{}(|^{}_{1:N})_{}( ^{}_{1:N}|)\;p(). \]

There exist multiple ways of implementing this sampling procedure. In rejection ABC , the simplest form, proposal parameters are drawn from the prior distribution \(p()\) and are accepted if the simulated data falls close to the true data, as measured by the kernel function. While rejection ABC yields a simple algorithm with desirable convergence properties, finding posterior samples for small bandwidths \(\) in high dimensions often becomes computationally infeasible . Therefore, the research on ABC focuses on three directions of improvement: (i) replacing the prior with a sequentially updated proposal distribution \(_{t}()\) to reduce the search space during sampling, (ii) adapting the bandwidth \(\) to draw samples with an appropriate acceptance rate, and (iii) finding sufficient statistics to represent the simulated output in low dimensions . MCMC-ABC  and SMC-ABC [47; 51; 15; 31] build upon sampling strategies based on Markov Chain Monte Carlo (MCMC) and Sequential Monte Carlo (SMC) to sequentially update the proposal distribution. MCMC-ABC does not allow for an adaptive bandwidth, and thus, SMC sampling strategies have evolved as the leading ABC methods for these cases .

### Sequential Monte Carlo ABC

SMC-ABC builds on SMC samplers introduced by Del Moral et al. . Fundamentally, SMC-ABC approximates the posterior distribution through a sequence of intermediate _target posterior_ distributions \(_{_{t}}(|^{}_{1:N})\) (4) that are characterized by an adaptable bandwidth parameter \(_{t}\), where \(t\) denotes the inference time. Furthermore, SMC-ABC uses importance sampling from a sequentially updated proposal distribution \(_{t}()\) to improve the sample efficiency. The proposal distribution is represented by an empircal distribution \(_{t}()=1/M_{i=0}^{M}_{^{(i)}}()\) that is defined through a set of particles \(\{^{(i)}_{t}\}\). Importance sampling then enables the approximation of the target posterior \(_{_{t}}(|^{}_{1:N})\) from the proposal distribution

\[_{_{t}}(|^{}_{1:N}) q_{t}( )=_{i=1}^{M}W^{(i)}_{t}_{^{(i)}_{t}}(); W^{(i)} _{t}=_{_{t}}(^{(i)}_{t}|^{}_{1:N})} {_{t}(^{(i)})}. \]

Here, \(W_{t}\) are the weights between the target posterior and the proposal distribution. SMC-ABC methods follow three steps to carry out inference for the next target posterior \(_{_{t+1}}(|^{}_{1:N})\): (i) A new bandwidth \(_{t+1}\) of the target posterior \(_{_{t+1}}(^{}_{1:N}|)\) is estimated. Typically, the update is based on heuristics, such as the Effective Sample Size (ESS)  to ensure that the particle variance does not degrade. (ii) New proposal particles \(^{(i)}_{t}\) are sampled from a forward Markov kernel \(^{(i)}_{t+1} K_{t}(^{(i)}_{t-1},^{(i)}_{t})\) to stay close to the target posterior of the next iteration \(_{_{t+1}}(|^{}_{1:N})\). (iii) The weights of the particles are adjusted based on approximations of (5). As the weight update is typically numerically intractable , different SMC-ABC methods [15; 30; 31] have been introduced which propose approximations to the optimal weight update. We refer to Appendix B for a more detailed explanation of SMC-ABC and its different approaches.

## 3 Pseudo-likelihood inference

The proposed PLI methodology, summarized in Figure 1, generalizes the ABC approaches by introducing exponential likelihood kernels with adaptive bandwidth updates, which are motivated from a Variational Inference (VI) perspective.

### Exponential likelihood kernels

PLI adopts the view of SMC-ABC on approximating a smoothed target posterior \(p_{t}(|_{1:N}^{})\), in the following denoted by \(_{t}()\), by formulating the following constrained VI problem for each inference step \(t\),

\[_{t}()=*{argmin}_{()()} (()\ ||\ p(|_{1:N}^{}) ), \] \[ (()\ ||\ _{t-1}()).\]

The optimization is balanced between fitting the posterior distribution \(p(|_{1:N}^{})\) and constraining the information loss between two inference steps \(_{t-1}()\) and \(_{t}()\). The loss of information is incorporated as a trust-region constraint with the bound \(>0\) in the space of probability distributions \(()\) through the Kullback-Leibler (KL) divergence \((()\ ||\ _{t-1}())\).

**Theorem 1**.: _The optimal target distribution \(_{t}()\) in the optimization problem (6) is given by_

\[_{t}()()}{_{t-1}()})^{ }}p(_{1:N}^{}|)^{} }\ _{t-1}() \]

_where \(_{t}>0\) is a dual Lagrangian variable corresponding to the trust-region constraint._

Proof.: See Appendix A.1. 

The temperature parameter \(_{t}\) plays the role of an adaptive step size that controls the update step from \(_{t-1}()\) to \(_{t}()\). In the limit of small step sizes \(_{t} 0\) at convergence, the target posterior (7) turns into the true posterior \(_{t}() p()p(_{1:N}^{}|)\). In the spirit of ABC-based methods, we approximate the intractable likelihood \(p(_{1:N}^{}|)\) with a Gibbs distribution \((_{1:N}^{}|)\), which we call _pseudo-likelihood_, and which is based on a discrepancy measure between the empirical data distribution \(p^{}()=1/N_{i}_{_{i}^{}}()\) and the simulator likelihood \(p(|)\)

\[(_{1:N}^{}|):=)}(- (),p(|))}{2}). \]

Here, \(Z()\) is the normalization constant, and \(>0\) is a bandwidth parameter that controls the sharpness of the approximation. When the KL divergence is used as the discrepancy measure \(D\), we recover the true likelihood, as the following lemma states.

Figure 1: Schematic overview of the introduced iterative Pseudo-Likelihood Inference (PLI) approach. (top) Based on samples drawn from the simulator, the pseudo-likelihood (8) is evaluated based on the discrepancy between the empirical data-generating and likelihood distributions. The bar chart shows how the pseudo-likelihood evaluation changes for different bandwidths. (bottom) The evaluation of the pseudo-likelihood is used to estimate a target posterior \(_{t}\) under trust-region constraints that moves from the prior distribution to the final posterior.

**Lemma 1**.: _When \(D=\) and \(2=1/N\) in (8), the pseudo-likelihood \((_{1:N}^{*}|)\) equals the true likelihood \(p(_{1:N}^{*}|)\)._

Proof.: Since \((p^{*}()\,\|\,p(|))=-[p^{*}(x) ]-N^{-1} p(_{1:N}^{*}|)\), then provided \(2=1/N\), the exponential in (8) is given by \((-N(p^{*}()\,\|\,p(|))) p( _{1:N}^{*}|)\) and \(Z()\) is a constant. 

However, the KL divergence is intractable in SBI because we cannot evaluate the likelihood. Therefore, we propose replacing the KL divergence with Integral Probability Metrics (IPMs), such as the MMD and the Wasserstein distance, which can be evaluated on distribution samples. Although theoretical analysis is less straightforward in these cases, some results have been obtained in prior works. Consistency and robustness of an MMD-based posterior estimator were shown by Cherief-Abdellatif and Alquier  and Wasserstein-based exponential kernels were studied by De Plaen et al. . In this paper, we focus on a practical instantiation of pseudo-likelihood inference, which can accommodate a variety of divergence functions and obtain superior empirical results by leveraging neural posterior approximators and adaptive step-size updates. The following subsections introduce the key components that constitute our method.

### Bandwidth adaptation from trust-region principles

The Lagrangian parameter \(_{t}\) has a particularly interesting property. From (7), we see that pulling \(_{t}\) into the pseudo-likelihood (2), yields a _time-dependent tempered pseudo-likelihood_

\[_{t}(_{1:N}^{*}|):=Z()^{1+_{t}}(-(2 _{t})^{-1}D(p^{*}(),p(|))=(_{1:N}^{*}|)^{}}\,. \]

Here, we introduce the adaptive bandwidth \(_{t}=(1+_{t})\) that approaches \(\) in the limit \(_{t} 0\). The dual formulation of the stochastic search problem (6) leads to a tractable solution for the optimal Lagrangian parameter \(_{t}\), and hence an optimal bandwidth \(_{t}\) (see Appendix A.1 for more details).

\[g(_{t})=-_{t}-(1+_{t})_{_{t-1}()} [()}{_{t-1}()})^{}}\,_{t}(_{1:N}^{*}|)]. \]

While we obtain the primal optimal point in closed form (7) to obtain the optimal dual variable \(_{t}\), we need to resort to numerical optimization of the Lagrangian dual objective. The optimal bandwidth parameter \(_{t}\), that is obtained by maximizing (10), can be seen as an information-bounded trust region update to move the pseudo-likelihood towards the likelihood. In the early inference stages, the proposal prior \(p_{t-1}()\) is typically uninformative, and thus the information loss is moderate even if \(p_{t}()\) moves far away from \(p_{t-1}()\). In the later inference steps, the proposal distribution is typically pronounced, and small deviations may lead to significant information loss. This intuition suggests that the bandwidth \(_{t}\) should decay over iterations, and indeed Figure 2 shows that \(_{t}\) quickly decays towards zero over a range of values of \(\) on the Gaussian location task (Sec. C.2). The exact decay schedule of \(_{t}\) is problem-dependent. Therefore, it is convenient to set an information-loss bound \(\) and obtain an adaptive bandwidth schedule by optimizing the dual (10) rather than pre-specifying a decay schedule by hand for each problem.

### Approximate Bayesian inference with pseudo-likelihoods

Pseudo-Likelihood Inference (PLI) is a sequential SBI methodology based on approximating the target posterior \(_{t}()\) (7). It is closely tied to SMC-ABC by (i) sequentially approximating the target posteriors, (ii) sequentially adapting the bandwidth parameter, and (iii) sequentially updating the proposal distribution for higher sample efficiency. Instead of representing the posterior through a set of weighted particles, the PLI formulation allows for various powerful neural density estimators.

A parameterized density model \(q_{}()\) is trained to approximate the PLI posterior (7) using the m-projection \(_{}(_{t}()\,\|\,q_{}())\), which results in the Weighted Maximum Likelihood (WML) objective with parameter samples drawn from the proposal prior \(^{(k)}_{t-1}(^{(k)})\)

\[_{}\,_{k=1}^{K}w^{(k)} q_{}(^{(k)} ); w^{(k)}=(^{(k)})}{_{t-1}(^{(k)})} )^{}}\,_{t}(_{1:N}^{*}|^{( k)}). \]

Figure 2: Bandwidth \(_{t}\) recorded for different \(\) on the Gaussian location task. The bandwidth is monotonically decreasing over iterations.

Thus, we derive a practical PLI algorithm by leveraging this empirical WML objective. Further details on the objective derivation are described in Appendix A.2. Our proposed PLI Algorithm 1 consists of four main steps. First, in lines 4-8, training pairs from the proposal and simulator are drawn, and the discrepancy measure \(D(_{1:N}^{},_{1:M})\) between the observations and the simulations is evaluated for each \(^{(k)}\). We follow Gretton et al. (2018) to approximate the MMD between two discrete probability measures, whereas we make use of the entropy regularized optimal transport formulation to approximate the Wasserstein distance (Brockman and Sridharan, 2016) (see Appendix C.1). Both versions facilitate parallelization on the GPU. Second, in line 9, the optimal bandwidth under trust region constraint is estimated, and the tempered pseudo-likelihood is evaluated. by maximizing the dual (10). Third, in line 11, the parameterized density estimator \(q_{_{t}}()\) is trained to approximate the target posterior \(_{t}()\) via the m-projection (11). Note that the expectation w.r.t. the proposal distribution \(_{t-1}()\) enables gradient descent on the \(q_{_{t}}\) estimator without requiring a differentiable simulator. Fourth, in line 12, we set the current posterior approximation \(q_{_{t}}()\) as the proposal \(_{t}()\) for the next inference step, thus leveraging bootstrapping of the density estimator. While we restrict the analysis in this paper to the m-projection, we note that the i-projection can also be employed, as shown in Appendix A.3.

Normalization.The normalization term \(Z()\) in the definition of the pseudo-likelihood (8) requires taking an integral over the reference data \(_{1:N}^{}\), which is infeasible in practice. When the KL divergence is used in the kernel, \(Z()\) does not depend on \(\), as shown in Lemma 1. While in general, the dependence on \(\) cannot be neglected, its influence on the weights in (10) and (11) may be negligible, provided the relative ranking of the samples is not affected significantly. In Appendix A.4, we provide an ablation study on low-dimensional problems where the integral over \(_{1:N}^{}\) can be approximated by sampling. We observed that, even though the ranking correlation of the weights \(w^{(k)}\) in (11) is different with and without estimating \(Z()\), the final posterior is not affected. Therefore, in the subsequent experiments, we treat it as a constant, as in the ideal case of the KL divergence. Nevertheless, this is a point where our practical implementation does not follow the theoretical derivation strictly, and this issue should be addressed in future work.

```
1:input: reference data \(_{1:N}^{}\), prior \(p()\), stochastic simulator \(p(|)\), IPM \(D(,)\), posterior approximator \(q_{}()\), max. iter. \(T\)
2:initialize proposal prior \(_{0}()=p()\)
3:for\(t\) in \(1:T\)do
4: sample parameters \(^{(1:K)}_{t-1}()\)
5:for each \(^{(k)}\)do
6: simulate data \(_{1:M}^{(k)} p(|^{(k)})\)
7: compute IPM \(s^{(k)}=D(_{1:M}^{(k)},_{1:N}^{})\)
8:endfor
9:update \(_{t}\) by maximizing the dual (10)
10: evaluate \(_{t}(_{1:N}^{}|^{(k)})\) (9)
11: fit \(q_{_{t}}()\) by WML (11)
12: set new proposal prior \(_{t}()=q_{_{t}}()\)
13:endfor
14:output: approximate posterior \(q_{_{T}}()\)
```

**Algorithm 1** Pseudo-Likelihood Inference (PLI)

## 4 Experiments

We compare the PLI framework against SMC-ABC (Han et al., 2018) and APT (Shi et al., 2019) on five diverse tasks. Our implementation is based on Wasserstein-ABC (Brockman and Sridharan, 2016), but instead of the employed r-hit kernel (Shi et al., 2019), our implementation is based on population Monte Carlo (Algorithm 3 (Shi et al., 2019)) because we observed improved performance in preliminary studies. A summary of the different ABC methods is given in Appendix B and Table A.1. APT was chosen as the representative for the class of SNPE algorithms. We leverage Neural Spline Flows (NSFs) (Han et al., 2018) as density estimators for both PLI and APT. Both neural flow configurations share the same base network architecture, but for APT, the conditional flow is augmented with an embedding network (Appendix C). All experiments are implemented in JAX (Brockman and Sridharan, 2016), and each ran on a single Nvidia RTX 3090.1 To make the experiments comparable, the simulation budgets of PLI and APT were fixed to 5000 samples per inference step over 20 episodes, while ABC ran for 200 episodes on 1000 particles.

### Evaluation metrics

The model is compared against the reference posterior samples \(^{}\) when available. We also quantify the methods' performances based on their realizations by computing the Wasserstein distance and the MMD. The comparison is carried out on \(10\,000\) samples each. Furthermore, we use Posterior Predictive Checks (PPCs) to evaluate the predictive capabilities of the posterior models in the observation space \(_{q(|_{1:N}^{})}[D( _{1:N}^{},_{1:M})]\). Due to the computational limits, the PPCs are carried out on \(1000\) simulations against the reference data. Lueckmann et al.  also report results with classifier-based tests and the kernelized Stein-discrepancy. However, since benchmarking is not our focus, we restrict the analysis to comparing with the Wasserstein and MMD.

### Tasks

We evaluate PLI on four common benchmarking tasks within the SBI community : Gaussian Location, a Gaussian Mixture Model, Simple-Likelihood Complex-Posterior, and SIR. Further, we add a system identification task on a Furuta pendulum representing a highly dynamic continuous control system. The tasks' specifications are listed in Appendix C. For each task, we conduct experiments for different numbers of available reference observations \(N=\{1,2,5,10,20,50,1000\}\). The reference observations are simulated based on a pre-defined ground-truth parameter \(^{}\). Although PLI and ABC can cope with varying numbers of observations \(N\) and numbers of simulations per parameter \(M\), we choose \(N=M\) for all experiments since it is required by APT. In the following paragraphs, we first discuss the results of the benchmarking tasks and present a separate discussion for the Furuta pendulum. Figure 3 gives a quantitative overview of the benchmarking tasks compared to the reference posteriors, while Figure C.1 in the Appendix complements the study by showing the posterior predictive performances.

Benchmarking tasks.Each benchmarking task presents different challenges that must be addressed by the SBI methods. In Gaussian Location, the task is to infer a uni-modal 10-dimensional Gaussian distribution. Gaussian Mixture Model and SLCP feature multi-modal posteriors that require flexible density estimators. SIR is a well-known epidemiological model that features 10-dimensional data of the dynamical system. All methods generally depict a reoccurring behavior on the different benchmarking tasks, as shown in Figure 3. For fewer observations (\(N 20\)), APT matches the reference posterior better than the other approaches, whereas ABC and PLI match the posterior data better with increasing \(N\). In particular, PLI consistently improves with an increasing number of reference samples. The influence of \(N\) on the shape of the posterior is further visualized in Figure C.2, which compares the posterior approximations of all methods for \(N=2\) and \(N=100\) reference observations. For the SLCP task, ABC struggles to capture the multi-modality of the SLCP task. This effect is further illustrated when comparing Figures C.3 and C.4, which allow for a qualitative

Figure 3: Evaluation of the posterior performance on five different tasks. We report the mean and 95% ci over 10 random seeds, each carried out using \(N\) data points for conditioning. We compare samples from the approximate posterior \( q(|_{1:N}^{})\) against reference posterior samples using MMD and the Wasserstein distance. No posterior samples were available for the Furuta pendulum. Therefore, the performance is evaluated in the observation space. Lower values are better for all metrics. PLI is the preferred method for conditioning on multiple observations due to its steady improvement with increasing \(N\). ABC performs better than PLI on Gaussian Location and Gaussian Mixture tasks but lags in more complex tasks. APT excels with few observations but degrades as \(N\) increases.

assessment of the posterior approximations. On SIR, PLI variants show significantly improved performance compared to the other baselines. Generally, we find that ABC and PLI perform better with MMD than with Wasserstein distance. This observation can be attributed to the Wasserstein distance not scaling well to high dimensions, which has been reported by recent studies [17; 16].

Furuta pendulum.The Furuta pendulum is an inverted double pendulum setup . While the system's dynamics are inherently deterministic, small perturbations of the initial state around its unstable equilibrium point lead to highly diverse trajectories. The observation space is \(T 6\) dimensional, where \(T\) is the number of time steps per trajectory. We set the sampling frequency of the simulation to \(100\,\) and the duration to \(1\), resulting in 600-dimensional observations. No reference posterior is available for this task; thus, the analysis is restricted to quantifying the observed data. Given the similarity of the Wasserstein distance and the MMD in parameter and observation space on the previous tasks, we argue that a comparison based on PPCs, i.e., \(_{2}^{2}(_{1:N}^{*},_{1:M})\) and \(^{2}(_{1:N}^{*},_{1:M})\), is sufficient. In Figure 3, the Wasserstein PPC and MMD PPC exhibit divergent behaviors, with the former indicating enhanced performance as reference observations increase, in contrast to the moderate improvement suggested by MMD. Therefore, we evaluate the models' predictive performances on the deterministic system by synchronizing the initial states of the reference data and the simulations in Figure 4. This modification ensures that the similarity between two rollouts can be evaluated by the accumulated error \(=_{i}|x_{i}^{*}-x_{i}|\). While all approaches perform better with more reference observations, MMD-PLI matches the reference dynamics best. Additionally, MMD is favored here, as MMD-based PLI and ABC outperform their Wasserstein counterparts, with both the MMD PPC plot and error plot showcasing congruent trends for \(N 20\). The appended posterior plots in Figures 5 and 6 reveal that for \(N=2\), all methods are widely spread over the prior region, yet converge to the ground truth. However, APT cannot recover the ground truth for \(N 100\), whereas PLI and ABC center around the ground truth.

## 5 Related work

In the previous sections, we have seen that PLI is algorithmically similar to ABC methods with SMC samplers. Therefore, approximating the likelihood by the empirical pseudo-likelihood (2) enables

Figure 4: Empirical and quantitative evaluation on the Furuta pendulum. (top) Snapshots of the posterior evolution on the \(g-m_{p}\) plane on the Furuta pendulum for \(N=1000\). (bottom) Predictive performance of the learned MMD-PLI posterior for the angular rotation \(_{r}\). The stochasticity of the simulator is removed by synchronizing the initial state between the reference and predicted simulations. Thus, the only discrepancies between trajectories are due to the model not capturing the dynamics parameters of the system. After the inference has been completed (step 20), the predictive simulator (\(\) MMD-PLI) can completely recover the ground truth dynamics (\(\) Reference). (right) Evaluation of the mean accumulated error over 1000 trajectories with synchronized initial states between the simulation and the reference trajectory. All approaches improve with rising \(N\) while PLI with MMD matches the reference data best.

drawing from the rich toolbox of existing approximate inference algorithms. This section introduces related research fields and shows how PLI fits among them.

Sequential neural density estimation.With the enriched class of neural density estimators, amortized SBI methods have received increasing interest in recent years. Similar to ABC, synthetic samples from the simulator are used to approximate the posterior. Sequential neural density estimation methods can be further classified into methods that directly train a posterior estimator , a neural likelihood , or a neural ratio estimator . All methods have in common that they do not rely on an approximation of the posterior model but are optimized solely on pairs of parameter samples from a proposal distribution \(^{(k)} p_{t}()\) and its corresponding simulation \(^{(k)} p(|^{(k)})\). We note that the original papers have only reported posteriors conditioned on a single observation \(\). While technically, these methods can incorporate multiple data points, this requires either stacking multiple observations or falling back to summary statistics. As noted in , neural likelihood estimators can sidestep these requirements by evaluating the log-likelihood of single observations and carrying out MCMC sampling on the joint log-likelihood. Yet, leveraging the neural likelihood restricts the evaluation of the posterior.

Summary statistics.ABC has commonly relied on reducing the dimensionality of the raw observations with summary statistics . These summaries must be carefully chosen and are often task-specific, restricting the general applicability of ABC. Recent additions to ABC methods report on replacing summary statistics with statistical distances . While direct comparison of the raw data suffers from the curse of dimensionality, comparing the observations through empirical measures sidesteps this issue . Bernton et al.  report on augmenting the likelihood kernel with the Wasserstein distance, while Park et al.  leverage the kernelized approximation of the MMD . Other contributions include the Cramer-von-Mises distance  and the energy distance . While statistical distances are appealing due to their general applicability, Drovandi and Frazier  conclude that they are limited by their high computational requirements. Approaches proposed for automated summary design include ABC with indirect inference, which utilizes an auxiliary model to evaluate data summaries .

Particle mirror descent.A posterior updating similar to ours (7) has been derived in Particle Mirror Descent (PMD) . PMD tackles particle depletion by incorporating the proposal distribution of the previous round into the optimization process. Furthermore, the authors show that the proposed method converges to the posterior given \(m\) posterior samples by \((1/)\). Our version can be seen as extending their approach to the case of intractable likelihoods. We extend PMD to neural density estimators using samples from the proposal posterior (7) as a training set.

Geometric path and likelihood tempering.Rewriting the optimal posterior (7) reveals a close relation of the optimal PLI posterior (4) and the geometric path formulation [6, p. 335], \(_{t}()_{t-1}^{1-}()\ p(_{1:N}^{ },)^{}.\) The optimal posterior moves from the proposal distribution \(_{t}()\) at inference time \(t\) to the target posterior \(_{t}(|_{1:N}^{}) p(_{1:N}^{}, )\) along the geometric path that is parameterized by \(\). The formulation differentiates from likelihood tempering in SMC samplers  by leveraging the proposal instead of the prior distribution. Note, however, that for \(t=0\), the proposal mimics the prior, and thus the PLI geometric path has the same boundary values as in classical likelihood tempering. While the tempered posterior cannot be applied to SMC samplers due to its dependence on the proposal distribution, the geometric path formulation based on the prior distribution gives rise to sequential annealing ABC .

Generalized variational inference.Introduced by Knoblauch et al. , Generalized Variational Inference (GVI) is an extension of the standard variational inference framework that starts from the optimization view of Bayes' rule and generalizes it by considering different losses, divergences, and variational families. Therefore, various Bayesian inference methods can be seen as instantiations of GVI with different choices of these three parameters. In particular, ABC and PLI can be seen as GVI with the choices \(P(K_{}(_{1:N}^{},_{1:M}),, ())\) since they employ a likelihood kernel as a loss. Crucially, specifying a different loss function instead of the typical log-likelihood can be shown to add robustness against model misspecification . PAC-Bayes  can be seen as a generalization of ABC as it covers the whole space of possible loss functions \(l(_{1:N}^{},)\). The PAC-Bayesian theory provides a broad array of risk bounds for generalized Bayesian learning methods.

Conclusion

We propose Pseudo-Likelihood Inference (PLI), a new addition to the toolbox of SBI methods. PLI is targeted for Bayesian inference tasks in which the posterior is conditioned on multiple observations simultaneously. For that, we derive a softened ABC posterior from a constrained variational inference problem and leverage IPMs between the empirical observations to assess the intractable likelihood. The derived posterior formulation enables the learning of flexible neural density estimators from black-box simulators, extending the range of applicability for ABC methods. Our experiments assess how well PLI, ABC, and SNPE perform based on their generative power when given varying amounts of reference observations as a condition. Given few observations, SNPE-based methods perform better than ABC and PLI, which rely on statistical distances. However, when more data is available, ABC and PLI methods perform better. When the posterior distribution is simple, ABC is efficient at reproducing it using fast particle updates. However, PLI is a better option for complex posterior distributions because of its more adaptable neural density estimator. Additionally, PLI evaluates the posterior probability, which is useful in downstream tasks that require uncertainty quantification.

Limitations.In PLI, the computational cost is distributed among three main computations: the simulation, the summary statistics estimation, and the normalizing flow training. While the computational effort is large for every computation, PLI leverages parallelization on GPUs for all three computations. In the provided experiments, the training process of the neural model takes the main computational budget, while simulation and summary statistics are negligible. On a Nvidia RTX 3090, ABC typically runs 2-10 min, while PLI and SNPE take 60-90 min, depending on the task. Simpler models however, such as multivariate Gaussian or GMM, reduce the computation time to the simulation. Furthermore, we would like to express that high-fidelity simulators might increase the simulation time significantly, making the simulation the most costly operation within the inference pipeline. Instead of utilizing IPMs, one could exploit adversarial strategies to approximate the KL divergence, as explored by Mescheder et al.  and Santana and Hernandez-Lobato .