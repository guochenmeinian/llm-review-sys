# [MISSING_PAGE_FAIL:1]

[MISSING_PAGE_FAIL:1]

The desired statistics should strike a balance: including too many activations leads to the curse of dimensionality, while including too few fails to capture enough information. Our approach is to select the _minimal sufficient_ statistics of the main components on the computational graph leading to the likelihood function. These anchoring statistics define the computational path of the likelihood function, which we term the _Likelihood Path (LPath) Principle_.

Under imperfect likelihood estimation, there is more information in the computational path leading to the marginal likelihood function \(p_{}()\). Information can be optimally extracted by the _minimal sufficient statistics_ of the individual components of the factorization of the likelihood function.

Although the LPath principle has independent interest in representation learning and can be applied to other DGMs, this work focuses on a thorough case study of applying the LPath principle to the OOD detection problem using Gaussian VAEs. We take the sufficient statistics of the VAE encoder and decoder as key statistics for our two-stage algorithm, achieving SOTA performance on common benchmarks (Table 1). Compared to other SOTA methods, we used a much smaller model (DC-VAEs from Xiao et al. (2020)'s architecture) with a parameter count of **3M**, compared to **44M** for Glow in DoSE (Morningstar et al., 2021) and **46M** for the diffusion model (Liu et al., 2023). We believe this "achieving more with less" phenomenon demonstrates our method's potential.

To summarize, our main contributions are:

**Empirical contribution:** We achieved SOTA unsupervised OOD detection performance on common benchmarks (Table 1) using a much smaller model compared to other SOTA methods, addressing RQ1.

**Methodological contribution:** We proposed the LPath Principle, which generalizes the classical likelihood principle1 for instance-dependent inference (e.g., OOD detection) under imperfect density estimation, addressing RQ2.

## 2 Inference, Fast and Slow

In this section, we reinterpret VAEs from the perspective of fast and slow weights. We begin by clearly distinguishing between likelihood evaluation and parameter inference procedures, as this distinction will be important throughout the paper.

Inferential ProcedureGiven training data \(_{}=\{_{i}\}_{i=1}^{N}\) and a density model \(p_{}=p_{}\) parameterized by \(\), we train \(p_{}\) on \(_{}\) to obtain \(p_{_{}}\). This is an _inferential procedure_, transferring knowledge from \(_{}\) to the trained parameters \(_{}\):

\[(_{},p_{})_{}, \]

where \(\) is the parameter space.

Evaluation ProcedureSuppose we have a new sample \(\); we can compute the likelihood of \(\) under the trained model \(p_{}\). This is an _evaluation procedure_, assessing \(\) using the knowledge gained from training:

\[(,_{}) p_{_{}}( ). \]

This typically occurs during test-time likelihood evaluation, after training is completed. However, direct application of this likelihood evaluation can assign higher likelihoods to OOD data than to ID data (Nalisnick et al., 2018).

While the evaluation procedure returns a scalar, the inferential procedure outputs a density model or parameters that characterize a model.

### VAEs Background

We next concrete examples of conditional distributions parameterized by encoder \(q_{}()\) and decoder \(p_{}()\) neural networks, as well as the prior. We choose Gaussian VAEs for illustration because they are widely used and have very simple _minimal sufficient statistics_. If the reader is unfamiliar with VAEs, see a more basic refresher of VAEs in Appendix A.

In our setup, the prior distribution is a standard Gaussian distribution:

\[p()=(=,=). \]

The encoder is a Gaussian distribution parameterized by an encoder neural network with parameters \(\):

\[(_{}(),_{}( )) =_{}(), \] \[q_{}() =(_{}(),(_{}^{2}())). \]

Here, \((_{}(),_{}())\) are the _instance-dependent latent parameters_ for the latent code \(\). This inference occurs for every sample \(\) and is the key property we aim to exploit.

The decoder is also a Gaussian distribution parameterized by a decoder neural network with parameters \(\):

\[(_{}(),_{}( )) =_{}(), \] \[p_{}() =(_{}(),(_{}^{2}())). \]

Here, \(\) is sampled from the encoder distribution \(q_{}()\). The pair \((_{}(),_{}())\) represents the _instance-dependent observable parameters_ for reconstructing the observation \(\). The reconstruction error is given by \(\|-_{}()\|\), measuring the difference between the original input and its reconstruction.

### VAE Reinterpreted: The Fast and Slow Weights Perspective

Consider Gaussian VAE learning. Given training data \(_{}=\{_{i}\}_{i=1}^{N}\), we train an encoder \(q_{}()\) and a decoder \(p_{}()\):

\[q_{}() =(_{}( ;),(_{}^{2}(;))), \] \[p_{}() =(_{}(; ),(_{}^{2}(;))). \]

After training, the knowledge in \(_{}\) is transferred to \(_{}=(_{})\) and \(_{}=(_{})\). This is the first inferential procedure:

\[(_{},q_{},p_{})(_{},_{})(,). \]

At test time, when a new observation \(_{}\) is given, the encoder and decoder Gaussian parameters are inferred depending on \(_{}\). This is the second inferential procedure:

\[(_{},_{},_{})(_{}(_{};_{ }),_{}(_{};_{}),_{}(_{};_{}),_{}(_{};_{}))\,. \]

There are two kinds of parameters involved. The parameters \(_{}\) and \(_{}\) do not change after training--they are the _slow weights_. The quantities \(_{}(_{};_{}), _{}(_{};_{})\), \(_{}(_{};_{}), _{}(_{};_{})\) are instance-dependent and are considered the _fast weights_(Hinton & Plaut, 1987; Ba et al., 2016). From this perspective, the second inferential procedure uses knowledge both from \(_{}\) (slow weights) and the test-time instance \(_{}\) (fast weights).

In the next section, we detail how to use these fast weights \(T(,)=(_{}(),_{ }(),_{}(),_{ }())\) for OOD detection.

## 3 OOD Detection with Fast and Slow Weights

In this section, we reinterpret a classical prior OOD detection method from the slow weight perspective and introduce our method from the fast weight perspective. We then detail our algorithm. In the next section, we provide a thorough analysis of our method's statistical and combinatorial foundations.

### OOD Detection with VAE Slow Weights

#### Reinterpreting the Likelihood Regret Method

The likelihood regret method for OOD detection (Xiao et al., 2020) can be reinterpreted as detecting OOD samples using the information update in slow weights. At a high level, after obtaining \(_{}\) from training, they fine-tune VAEs by maximizing likelihood on a test sample \(_{}\) to get \(_{}\), and track the following likelihood regret:

\[ p(_{}_{})- p(_{ }_{}). \]

In other words, their work involves two inferential procedures. First, \((_{},p_{})_{}\); second, \((_{},_{},p_{}) _{}\), where they do not maximize \(p_{}\) jointly on \((_{},_{})\), but sequentially on \(_{}\) first and \(_{}\) next. However, likelihood regret is empirically outperformed by alternative approaches (Morningstar et al., 2021) which did not involve any fine-tuning. This is probably because training neural networks on one sample is challenging. Optimizing for a few iterations changes \(_{}\) very little, while training for many iterations results in overfitting quickly. Furthermore, in streaming OOD detection, such computational overhead is formidable.

#### OOD Detection with VAE Fast Weights

Given that OOD detection with slow weights induces formidable computational overhead during test time and poses optimization challenges, we propose to perform OOD detection with fast weights. In Section 2, we reinterpreted the encoder and decoder means and variances as the fast weights of the VAE: \(T(,)=(_{}(), _{}(),_{}( ),_{}())\). However, these remain high-dimensional. This not only increases computational time but can also cause issues for the second-stage statistical algorithm (Maciejewski et al., 2022). We address this problem by taking the L2 norm of \(T(,)\):

\[u() =\|-}\|_{2}=\|-_{}(_{}())\|_{2}, \] \[v() =\|_{}()\|_{2},\] (14) \[w() =\|_{}()\|_{2},\] (15) \[s() =\|_{}(_{}())\|_{2}. \]

Note that in Eq. 13, instead of taking \(\|_{}(_{}())\|_{2}\), we compute \(\|-_{}(_{}( ))\|_{2}\). This is because \(\|_{}(_{}())\|_{2}\) could be unnormalized in magnitude compared to other statistics, causing problems in the second-stage classical density estimation algorithm. Thus, we normalize it by taking the reconstruction error, which should be close to zero due to the VAE optimization objective. While VAE optimization should already be driving Eqs. 14-16 to a small value.

#### The LPath Algorithm for Fast Weights OOD Detection

We use Eqs. 13-16 as the scoring metrics for our OOD detection algorithm. We call it the Likelihood Path (LPath) algorithm because it is based on minimal sufficient statistics of the individual components of the factorization of the likelihood function; we provide a detailed description and analysis in Section 4.3.

Our algorithm is detailed in Algorithm 1. It first trains a VAE and extracts statistics in Eqs. 13-16 in the first stage (**neural feature extraction**). Then it fits a classical statistical density estimation algorithm (COPOD (Li et al., 2020) or MD (Lee et al., 2018; Maciejewski et al., 2022)) in the second stage (**classical density estimation**).

Our algorithm can be used with a single VAE model (LPath-1M) or a pair of two models (LPath-2M). For LPath-1M, we use the same VAE to extract all of \(u(),v(),w(),s()\). When used with a pair of two models (LPath-2M), we train two VAEs: one with a very high latent dimension (e.g., 1000) and another with a very low dimension (e.g., 1 or 2). In the second stage, we extract the following statistics: \((u()_{},v()_{},w()_{},s()_{})\), where \(u()_{}\), \(s()_{}\) are taken from the low-dimensional VAE and \(v()_{}\), \(w()_{}\) from the high-dimensional VAE. Appendix D.1.2 explains the reasoning behind this combination.

```
1:Input:\(_{} P_{}\) of size \(n_{} n_{}\), \(_{} P_{} P_{}\)
2:Stage 1 Training: From high-dim dataset to low-dim minimal sufficient statistics
3:Train VAE on \(_{}\)\(\) Normal training using SGD/Adam
4:for\(_{}\)do
5: Compute and record \(T()=(u(),v(),w(),s())\)\(\) As in Eqs. 13-15
6:endfor
7:Create new dataset \(_{}\) of size \(n_{} 4\) consisting of the minimal sufficient statistics \(T()\) for Stage 2 Training
8:Stage 2 Training: From low-dim minimal sufficient statistics to OOD scoring
9:Select classical OOD scoring algorithm \(_{}\) (e.g., COPOD (Li et al., 2020) or MD (Lee et al., 2018))
10:Train \(A_{}\) on \(_{}\) to get \(_{}\)\(\) Classical OOD training
11:Inference Stage: OOD Scoring
12:for\(_{}_{}\)do
13: Compute \(T(_{})=(u(_{}),v(_{}),w(_{}),s(_{}))\) from trained VAE
14: Compute OOD score \(S(_{})=_{}(T( _{}))\)
15:endfor
16:Output:\(S(_{})\), an OOD score for each \(_{}\)
```

**Algorithm 1** Training and Inference: From high-dimensional data to OOD scoring

## 4 The Likelihood Path Principle

In this section, we provide an in-depth analysis of how we arrived at our selected \(T(,)=(_{}(),_{}(),_{}(), _{}())\), the fundamental challenge for this problem, and how to have a general principle to select such statistics not just for VAEs but for other DGMs.

Recall RQ2: How do we select key statistics for the classical density estimation algorithm?

The goal is to overcome the challenge of dimensionality: If the dimensionality is too high, we might suffer from the curse of dimensionality, but if the dimensionality is too low, we might capture insufficient information to make effective inference. How do we find the sweet spot?

The key idea is our proposed Likelihood Path (LPath) Principle:

Under imperfect likelihood estimation, there is more information in the computational path leading to the marginal likelihood function \(p_{}()\). Information can be optimally extracted by the _minimal sufficient statistics_ of the individual components of the factorization of the likelihood function.

The LPath Principle is a general-purpose principle to select such statistics, and our analysis could also be used to select such statistics for other DGMs; we leave that for future work.

We will start by reviewing the Likelihood Principle and Sufficiency Principle that form the statistical foundation of our proposed LPath Principle.

### The Likelihood Principle

The maximum likelihood estimation (MLE) approach to unsupervised learning focuses on finding parameters \(\) to maximize the likelihood \(():=p()\) given training data \(\), so that we transfer information from \(\) to \(\). MLE is a special case of the _likelihood principle_(Berger and Wolpert, 1988):

The _likelihood principle_ states that all the evidence in an observed sample \(\) relevant to model parameters is contained in the likelihood function \(()\).

MLE satisfies the likelihood principle because inferring the most likely parameter depends only on \(()\). Many OOD detection works (Nalisnick et al., 2019; Xiao et al., 2020) satisfy this principle as well.

_In summary, the likelihood principle postulates that \(()\) (as a function of \(\)) tells us everything about \(\). If we make our decisions (e.g., OOD detection) based only on the likelihood function, our decision satisfies the likelihood principle._

### The Sufficiency Principle

While the likelihood principle suggests that all information is contained in \(()\), it is a complex function and does not directly tell us what statistics to include for RQ2. To better process such overwhelming information, we seek to reduce our selection to the simplest set that still contains sufficient information about \(()\). How do we formalize such information trimming in the context of unsupervised learning?

* The information reduction procedure \(T\) should be a function of \(\), a _statistic_.
* \(T\) should be _sufficient_ for describing \(p()\) or \(\): \(p( T(),)=p( T())\).
* \(T\) should be _minimal_: \(F(T)\) is no longer sufficient for \(\), for any non-invertible function \(F\).

_In summary, a minimal sufficient statistic \(T\) tells us everything about \(\) that we can possibly learn from observing \(\), and if we attempt to trim \(T\) further by any irreversible process, we would lose some information for inferring \(()\)\({}^{2}\)._

Alternatively, we can view sufficient statistics from an information-theoretic perspective. Let I denote the mutual information. \(T()\) is sufficient for \(\) if:

\[(;T())=(;). \]

In other words, the data processing inequality \((;T())(;)\) becomes an equality if \(T\) is sufficient. This is useful for answering RQ2. Given a new sample \(\), the encoder and decoder neural nets would produce millions of activations, all of which could be useful for OOD detection. However, this is clearly overwhelming. The minimal sufficient statistic \(T()\) gives us the set of statistics that cannot be reduced further without losing some information.

The standard Gaussian VAE's encoder and decoder parameterizations by sample mean vectors and sample covariance matrices (Eqs. 4 and 6) are _minimal sufficient statistics_(Wasserman, 2006). Here, minimal sufficient statistics represent two **optimal** conditions for inference: They are _sufficient_ because once \((_{}(),_{}())\) and \((_{}(),_{}())\) are known, the conditional likelihood functions can be defined. They are _minimal_ because any other parameterization of a Gaussian will involve no fewer parameters.

### Likelihood Path Principle

Our proposed LPath principle states that:

Under imperfect likelihood estimation, there is more information in the computational path leading to the marginal likelihood function \(p_{}()\). Information can be optimally extracted by the _minimal sufficient statistics_ of the individual components of the factorization of the likelihood function.

For VAEs, this entails applying the _likelihood principle_ twice in the VAE's encoder and decoder conditional distributions and tracking their _minimal sufficient statistics_: \(T(,)=(_{}(),_{ }(),_{}(),_{ }())\).

Recall the VAE formulation:

\[\\ \\ } p_{}()[ ()p( )}{q_{}()}] []{l}\\ } \]

While it is not obvious how to apply likelihood and sufficiency principles to the VAE's marginal likelihood \(p_{}()\), we can apply them to the Gaussian VAE's encoder \(q_{}()\), prior \(p()\), and decoder \(p_{}()\), which completely characterize \(p_{}()\).

Let us make the above precise in our VAE's LPath. Consider the following Markov chain when we estimate the marginal likelihood of a sample \(\):

\[ q_{}(),p(), p_{}() p_{}( ). \]

The data processing inequality from information theory says:

\[(;(q_{}(),p(),p_{ }()))(;p_{}()). \]

When density estimation is perfect, the above inequality becomes an equality. In practical cases, perfect learning never happens. Mathematically, our LPath principle thus states:

\[(;(q_{}(),p(), p_{}()))>(;p_{}( )). \]

In a nutshell, _the central theme in our work is to exploit the gap in Inequality 21_.

The chain of information reduction for OOD inference and detection is summarized by Figure 1:

In the first column of Figure 1, it is hard to define a metric in the visible space to distinguish \(_{}\) and \(_{}\), even though they contain the most evidence. In the second column, we compare them by comparing their corresponding likelihood functions, suggested by the likelihood principle. The third column compares their maximum likelihood inferences. The last column suggests that it suffices to know the sufficient statistics \(T\) to obtain \(_{}\), which completes the information reduction chain.

### Combinatorial Cancellation

We analyzed the LPath Principle for OOD detection from the statistical perspective. We can gain more concrete insights on why the LPath Principle works if we take a combinatorial perspective, which can act as an empirical method to select statistics, answering RQ2. The key insight is that factors in the likelihood function risk **getting canceled** in the likelihood itself, and the signals they contain for OOD detection will be drowned out. This is how information is lost in Eq. 21. To address this, we could separate each factor out and capture the signal they contain with their sufficient statistics, arriving at our LPath Principle.

In the case of VAEs, the encoder and decoder contain complementary information for OOD detection, but they could be canceled out in \( p_{}()\). Recall the VAE's likelihood estimation:

\[ p_{}()[}( )p()}{q_{}()}].\]

The decoder's conditional likelihood \(p_{}()\) being too large and prior \(p()\) (evaluated at samples from the encoder \(q_{}()\)) being too small both suggest \(\) could be an anomaly, but their scalar product can be well-ranged, which drowns out the signal for OOD discovery. A more concrete interpretation of this cancellation phenomenon from the pixel texture vs. semantics perspective can be found in Appendix C.

For \(_{}\) and \(_{}\), we would anticipate different likelihood paths. This difference can be detected by their corresponding sufficient statistics: \(T(_{},_{})=(_{}( _{}),_{}(_{}),_{}(_{}),_{}(_ {}))\) and \(T(_{},_{})=(_{}( _{}),_{}(_{}), _{}(_{}),_{}( _{}))\). In other words, a new sample may be considered as ID if its sufficient statistics are similar to \(T(_{},_{})\) for some \(_{} P_{}\) (because the encoder and decoder distributions are completely characterized by \(T\)).

Figure 1: Left to right shows the information reduction via the likelihood principle (LP), maximum likelihood estimation (MLE), and sufficiency principle (SP). \(T\) denotes sufficient statistics. The top and bottom rows contrast inferences between \(_{}\) and \(_{}\).

## 5 Experiments

We compare our methods with state-of-the-art OOD detection methods (Kirichenko et al., 2020; Xiao et al., 2020; Havtorn et al., 2021; Morningstar et al., 2021; Bergamin et al., 2022; Liu et al., 2023; Graham et al., 2023), under the unsupervised, single batch, no data inductive bias assumption setting.

Following the convention in those methods, we have conducted experiments with a number of common benchmarks, including CIFAR10 (Krizhevsky & Hinton, 2009), SVHN (Netzer et al., 2011), CIFAR100 (Krizhevsky & Hinton, 2009), MNIST (LeCun et al., 1998), FashionMNIST (FMNIST) (Xiao et al., 2017), and their horizontally flipped and vertically flipped variants.

Experimental Results.Table 1 show that our methods surpass or are on par with the state-of-the-art (SOTA). Because our setting assumes no access to labels, batches of test data, or any inductive bias on the dataset, OOD datasets like Hflip and Vflip become very challenging. Most prior methods achieved only near-chance AUROC on Vflip and Hflip for CIFAR10 and SVHN as ID data. This is expected because horizontally flipped CIFAR10 or SVHN differs from the in-distribution only by one latent dimension. Even so, our methods still managed to surpass prior SOTA in some cases, though only marginally. More experimental details, including various ablation studies, are in Appendix D, E.

Achieving More with Less.This improvement is more significant given that we only used a very small VAE architecture. Compared to other SOTA methods, we used a much smaller model (DC-VAEs from (Xiao et al., 2020)'s architecture) with a parameter count of **3M**, compared to **44M** for Glow (Kingma & Dhariwal, 2018) in DoSE (Morningstar et al., 2021) and **46M** for the diffusion model (Rombach et al., 2022; Liu et al., 2023). Specifically, our method clearly exceeds other VAE-based methods (Xiao et al., 2020; Havtorn et al., 2021), and is the only VAE-based method that is competitive against bigger models. DoSE (Morningstar et al., 2021) conducted experiments on VAEs with five carefully chosen statistics. They reported their MNIST/FMNIST results on their VAEs and used Glow on more difficult datasets like CIFAR/SVHN. We assume the reason is that Glow performed better on more complex datasets. Our methods surpass their Glow-based results, which should, in turn, be better than their method applied to VAEs. On one hand, Glow's likelihood is arguably much better estimated than our small DC-VAE model. On the other hand, their statistics appear to be more sophisticated. However, our simple method manages to surpass their scores. This showcases the efficiency and effectiveness of our method.

## 6 Conclusion

We presented the Likelihood Path Principle applied to unsupervised, one-sample OOD detection. We provided in-depth analyses from the neural (fast-slow weights), statistical (likelihood and sufficiency principles), and combinatorial (cancellation effect) perspectives. Our method is principled and supported by SOTA results. In future work, we plan to adapt our principles and techniques to more powerful DGMs, such as Glow or diffusion models.

     } &   } &  &  &  &  \\  & & **OOD** & **SVHN** & **CLAR100** & **Hflip** & **Vflip** & **CLAR100** & **Hflip** & **Vflip** & **MNIST** & **Hflip** & **Vflip** \\   ELBO & \(0.08\) & \(0.54\) & \(0.5\) & \(0.56\) & **0.99** & \(0.5\) & \(0.5\) & \(0.87\) & \(0.63\) & \(0.83\) & **1.20** & \(0.59\) & \(0.6\) \\  LR (Xiao et al., 2020) & \(0.88\) & N/A & N/A & N/A & \(0.92\) & N/A & N/A & \(0.99\) & N/A & N/A & N/A & N/A & N/A \\  RVA (Hinton et al., 2021) & \(0.89\) & N/A & N/A & N/A & **0.99** & N/A & N/A & N/A & \(0.98\) & N/A & N/A & **1.20** & N/A & N/A \\  DoSE (Mordesz et al., 2021) & \(0.97\) & \(0.57\) & \(0.51\) & \(0.53\) & **0.99** & \(0.22\) & \(0.51\) & **1.40** & \(0.06\) & \(0.69\) & \(0.75\) & **1.20** & **0.81** & \(0.83\) \\  Fishee (Regina et al., 2021) & \(0.87\) & \(0.50\) & N/A & N/A & N/A & N/A & N/A & \(0.96\) & N/A & N/A & N/A & N/A & N/A \\  DPM(Liu et al., 2023) & \(0.98\) & N/A & \(0.51\) & \(0.63\) & **0.99** & \(0.42\) & **0.58** & \(0.97\) & \(0.65\) & **0.89** & N/A & N/A & N/A & N/A \\  LMD (Graham et al., 2023) & \(0.99\) & \(0.61\) & N/A & N/A & \(0.91\) & N/A & N/A & N/A & \(0.99\) & N/A & N/A & **1.20** & N/A & N/A \\  LPAH-1M-COPD (Oma) & \(0.99\) & \(0.62\) & \(0.53\) & \(0.61\) & **0.89** & \(0.55\) & \(0.56\) & **1.00** & **0.65** & \(0.81\) & **1.09** & \(0.65\) & **0.87** \\  LPAH-2M-COPD (Oma) & \(0.98\) & \(0.62\) & \(0.53\) & \(0.61\) & **0.99** & \(0.55\) & \(0.56\) & **0.87** & \(0.87\) & **1.00** & \(0.77\) & \(0.78\) \\  LPAH-NM-MD (Oma) & \(0.99\) & \(0.58\) & \(0.52\) & \(0.60\) & \(0.95\) & \(0.52\) & \(0.52\) & \(0.97\) & \(0.63\) & \(0.82\) & **1.00** & \(0.75\) & \(0.76\) \\   

Table 1: AUROC of OOD Detection with different ID and OOD datasets. LPath-1M is LPath with one model, LPath-2M is LPath with two models.