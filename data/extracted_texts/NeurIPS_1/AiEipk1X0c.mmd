# A Deep Instance Generative Framework for

MILP Solvers Under Limited Data Availability

Zijie Geng1, Xijun Li1,2, Jie Wang1,3, Xiao Li1, Yongdong Zhang1, Feng Wu1

1University of Science and Technology of China

2Noah's Ark Lab, Huawei

3Institute of Artificial Intelligence, Hefei Comprehensive National Science Center

{ustcgzj,lixijun,xiao_li}@mail.ustc.edu.cn

{jiewangx,zhyd73,fengwu}@ustc.edu.cn

Corresponding author.

###### Abstract

In the past few years, there has been an explosive surge in the use of machine learning (ML) techniques to address combinatorial optimization (CO) problems, especially mixed-integer linear programs (MILPs). Despite the achievements, the limited availability of real-world instances often leads to sub-optimal decisions and biased solver assessments, which motivates a suite of synthetic MILP instance generation techniques. However, existing methods either rely heavily on expert-designed formulations or struggle to capture the rich features of real-world instances. To tackle this problem, we propose G2MILP, _the first_ deep generative framework for MILP instances. Specifically, G2MILP represents MILP instances as bipartite graphs, and applies a masked variational autoencoder to iteratively corrupt and replace parts of the original graphs to generate new ones. The appealing feature of G2MILP is that it can learn to generate novel and realistic MILP instances without prior expert-designed formulations, while preserving the structures and computational hardness of real-world datasets, simultaneously. Thus the generated instances can facilitate downstream tasks for enhancing MILP solvers under limited data availability. We design a suite of benchmarks to evaluate the quality of the generated MILP instances. Experiments demonstrate that our method can produce instances that closely resemble real-world datasets in terms of both structures and computational hardness. The deliverables are released at [https://miralab-ustc.github.io/L20-G2MILP](https://miralab-ustc.github.io/L20-G2MILP).

## 1 Introduction

Mixed-integer linear programming (MILP)--a powerful and versatile modeling technique for many real-world problems--lies at the core of combinatorial optimization (CO) research and is widely adopted in various industrial optimization scenarios, such as scheduling , planning , and portfolio . While MILPs are \(\)-hard problems , machine learning (ML) techniques have recently emerged as a powerful approach for either solving them directly or assisting the solving process . Notable successes include  for node selection,  for branching decision, and  for cut selection, etc.

Despite the achievements, the limited availability of real-world instances, due to labor-intensive data collection and proprietary issues, remains a critical challenge to the research community . Developing practical MILP solvers usually requires as many instances as possible to identify issues through white-box testing . Moreover, machine learning methods for improving MILP solvers often suffer from sub-optimal decisions and biased assessments under limited data availability, thuscompromising their generalization to unseen problems . These challenges motivate a suite of synthetic MILP instance generation techniques, which fall into two categories. Some methods rely heavily on expert-designed formulations for specific problems, such as Traveling Salesman Problems (TSPs)  or Set Covering problems . However, these methods cannot cover real-world applications where domain-specific expertise or access to the combinatorial structures, due to proprietary issues, is limited. Other methods construct general MILP instances by sampling from an encoding space that controls a few specific statistics . However, these methods often struggle to capture the rich features and the underlying combinatorial structures, resulting in an unsatisfactory alignment with real-world instances.

Developing a deep learning (DL)-based MILP instance generator is a promising approach to address this challenge. Such a generator can actively learn from real-world instances and generate new ones without expert-designed formulations. The generated instances can simulate realistic scenarios, cover more cases, significantly enrich the datasets, and thereby enhance the development of MILP solvers at a relatively low cost. Moreover, this approach has promising technical prospects for understanding the problem space, searching for challenging cases, and learning representations, which we will discuss further in Section 5. While similar techniques have been widely studied for Boolean satisfiability (SAT) problems , the development of DL-based MILP instance generators remains a complete blank due to higher technical difficulties, i.e., it involves not only the intrinsic combinatorial structure preservation but also high-precision numerical prediction. This paper aims to lay the foundation for the development of such generators and further empower MILP solver development under limited data availability.

In this paper, we propose G2MILP, which is _the first_ deep generative framework for MILP instances. We represent MILP instances as weighted bipartite graphs, where variables and constraints are vertices, and non-zero coefficients are edges. With this representation, we can use graph neural networks (GNNs) to effectively capture essential features of MILP instances [8; 18]. Using this representation, we recast the original task as a graph generation problem. However, generating such complex graphs from scratch can be computationally expensive and may destroy the intrinsic combinatorial structures of the problems . To address this issue, we propose a masked variational autoencoder (VAE) paradigm inspired by masked language models (MLM) [20; 21] and VAE theories [22; 23; 24]. The proposed paradigm iteratively corrupts and replaces parts of the original graphs using sampled latent vectors. This approach allows for controlling the degree to which we change the original instances, thus balancing the novelty and the preservation of structures and hardness of the generated instances. To implement the complicated generation steps, we design a decoder consisting of four modules that work cooperatively to determine multiple components of new instances, involving both structure and numerical prediction tasks simultaneously.

We then design a suite of benchmarks to evaluate the quality of generated MILP instances. First, we measure the structural distributional similarity between the generated samples and the input training instances using multiple structural statistics. Second, we solve the instances using the advanced solver Gurobi , and we report the solving time and the numbers of branching nodes of the instances, which directly indicate their computational hardness [19; 25]. Our experiments demonstrate that G2MILP is the very first method capable of generating instances that closely resemble the training sets in terms of both structures and computational hardness. Furthermore, we show that G2MILP is able to adjust the trade-off between the novelty and the preservation of structures and hardness of the generated instances. Third, we conduct a downstream task, the optimal value prediction task, to demonstrate the potential of generated instances in enhancing MILP solvers. The results show that using the generated instances to enrich the training sets reduces the prediction error by over \(20\%\) on several datasets. The deliverables are released at [https://miralab-ustc.github.io/L20-G2MILP](https://miralab-ustc.github.io/L20-G2MILP).

## 2 Related Work

Machine Learning for MILPMachine learning (ML) techniques, due to its capability of capturing rich features from data, has shown impressive potential in addressing combinatorial optimization (CO) problems [26; 27; 28], especially MILP problems . Some works apply ML models to directly predict the solutions for MILPs [29; 30; 31]. Others attempt to incorporate ML models into heuristic components in modern solvers [7; 9; 32; 33]. Gasse et al.  proposed to represent MILP instances as bipartite graphs, and use graph neural networks (GNNs) to capture features for branching decisions. Ourproposed generative framework can produce novel instances to enrich the datasets, which promises to enhance the existing ML methods that require large amounts of i.i.d. training data.

MILP Instance GenerationMany previous works have made efforts to generate synthetic MILP instances for developing and testing solvers. Existing methods fall into two categories. The first category focuses on using mathematical formulations to generate instances for specific combinatorial optimization problems such as TSP , set covering , and mixed-integer knapsack . The second category aims to generate general MILP instances. Bowly  proposed a framework to generate feasible and bounded MILP instances by sampling from an encoding space that controls a few specific statistics, e.g., density, node degrees, and coefficient mean. However, the aforementioned methods either rely heavily on expert-designed formulations or struggle to capture the rich features of real-world instances. G2MILP tackles these two issues simultaneously by employing deep learning techniques to actively generate instances that resemble real-world problems, and it provides a versatile solution to the data limitation challenge. In , we further extend G2MILP to learn to generate challenging MILP instance.

Deep Graph GenerationA plethora of literature has investigated deep learning models for graph generation , including auto-regressive methods , varational autoencoders (VAEs) , and generative diffusion models . These models have been widely used in various fields  such as molecule design [21; 40; 41] and social network generation [42; 43]. G2SAT , the first deep learning method for SAT instance generation, has received much research attention [19; 44]. Nevertheless, it is non-trivial to adopt G2SAT to MILP instance generation (see Appendix C.1), as G2SAT does not consider the high-precision numerical prediction, which is one of the fundamental challenges in MILP instance generation. In this paper, we propose G2MILP--the first deep generative framework designed for general MILP instances--and we hope to open up a new research direction for the research community.

## 3 Methodology

In this section, we present our G2MILP framework. First, in Section 3.1, we describe the approach to representing MILP instances as bipartite graphs. Then, in Section 3.2, we derive the masked variational autoencoder (VAE) generative paradigm. In Section 3.3, we provide details on the implementation of the model framework. Finally, in Section 3.4, we explain the training and inference processes. The model overview is in Figure 1. More implementation details can be found in Appendix A. The code is released at [https://github.com/MIRALab-USTC/L20-G2MILP](https://github.com/MIRALab-USTC/L20-G2MILP).

### Data Representation

A mixed-linear programming (MILP) problem takes the form of:

\[_{^{n}}^{},\, {x},\,,\,x_{j},\, j , \]

where \(^{n},^{m n},^{m },(\{-\})^{n},(\{+\} )^{n}\), and the index set \(\{1,2,,n\}\) includes those indices \(j\) where \(x_{j}\) is constrained to be an integer.

To represent each MILP instance, we construct a weighted bipartite graph \(=(,)\) as follows [18; 29].

* The constraint vertex set \(=\{v_{1},,v_{m}\}\), where each \(v_{i}\) corresponds to the \(i^{}\) constraint in Equation 1. The vertex feature \(_{i}\) of \(v_{i}\) is described by the bias term, i.e., \(_{i}=(b_{i})\).
* The variable vertex set \(=\{w_{1},,w_{n}\}\), where each \(w_{j}\) corresponds to the \(j^{}\) variable in Equation 1. The vertex feature \(_{j}\) of \(w_{j}\) is a \(9\)-dimensional vector that contains information of the objective coefficient \(c_{j}\), the variable type, and the bounds \(l_{j},u_{j}\).
* The edge set \(=\{e_{ij}\}\), where an edge \(e_{ij}\) connects a constraint vertex \(v_{i}\) and a variable vertex \(w_{j}\). The edge feature \(_{ij}\) is described by the coefficient, i.e., \(_{ij}=(a_{ij})\), and there is no edge between \(v_{i}\) and \(w_{j}\) if \(a_{ij}=0\).

As described above, each MILP instance is represented as a weighted bipartite graph, equipped with a tuple of feature matrices \((,,)\), where \(,,\) denote stacks of vertex features \(_{i}\), \(_{j}\) and edge features \(_{ij}\), respectively. Such a representation contains all information of the original MILP instance . We use the off-the-shelf observation function provided by Ecole  to build the bipartite graphs from MILP instances. We then apply a graph neural network (GNN) to obtain the node representations \(_{v_{i}}^{}\) and \(_{w_{i}}^{}\), also denoted as \(_{w_{i}}\) and \(_{w_{j}}\) for simplicity. More details on the data representation can be found in Appendix A.1.

### Masked VAE Paradigm

We then introduce our proposed masked VAE paradigm. For the ease of understanding, we provide an intuitive explanation here, and delay the mathematical derivation to Appendix A.2.

Given a graph \(\) drawn from a dataset \(\), we corrupt it through a masking process, denoted by \(}(}|)\). We aim to build a parameterized generator \(p_{}(}|})\) that can generate new instances \(}\) from the corrupted graph \(}\). We train the generator by maximizing the log-likelihood \( p_{}(|})= p_{}( }=|})\) of reconstructing \(\) given \(}\). Therefore, the optimization objective is:

\[*{arg\,max}_{}_{} _{}(}|)}  p_{}(|}). \]

To model the randomness in the generation process and produce diverse instances, we follow the standard VAE framework [22; 23] to introduce a latent variable \(=(_{v_{1}},,_{v_{m}},_{w_{1}},, _{w_{m}})\), which contains the latent vectors for all vertices. During training, the latent vectors are sampled from a posterior distribution given by a parameterized encoder \(q_{}\), while during inference, they are independently sampled from a prior distribution such as a standard Gaussian distribution. The decoder \(p_{}\) in the masked VAE framework generates new instances from the masked graph \(}\) together with the sampled latent variable \(\).

Figure 1: Overview of G2MLP. **(a) Masking Process \((}|)\).** Given a MILP instance, which is represented as a bipartite graph \(\), we randomly label a constraint vertex \(\) as [mask] to obtain the masked graph \(}\). **(b) Encoder \(q_{}(|)\)**. The encoder is GNN\({}_{}\) followed by two networks, \(_{}\) and \(_{}\), for resampling. During training, we use the encoder to obtain the latent vectors \(_{v_{i}}\) and \(_{w_{j}}\) for all vertices. **(c) Decoder \(p_{}(|},)\)**. We use GNN\({}_{}\) to obtain the node features \(_{}\) and \(_{w_{j}}\). Then four modules work cooperatively to reconstruct the original graph \(\) based on the node features and the latent vectors. They sequentially determine \(\) the bias terms, \(\) the degrees, \(\) the logits, and \(\) the weights. During inference, the model is decoder-only, and we draw the latent vectors from a standard Guassian distribution to introduce randomness. We repeat the above mask-and-generate process several times so as to produce new instances.

The evidence lower bound (ELBO), also known as the variational lower bound, is a lower bound estimator of the log-likelihood, and is what we actually optimize during training, because it is more tractable. We can derive the ELBO as:

\[ p_{}(|})_{  q_{}(|)}[ p_{}(|},)]-D_{}[q_{}( |)\|p_{}()], \]

where \(p_{}()\) is the prior distribution of \(\) and is usually taken as the standard Gaussian \((,)\), and \(D_{}[\,\,\|\,\,]\) denotes the KL divergence. Therefore, we formulate the loss function as:

\[=_{}_{}(}|)}[_{  q_{}(|)}[- p_{}(|},)]}_{_{}}+}[q_{}(| )\|(,)]}_{_{}}]. \]

In the formula: (1) the first term \(_{}\) is the reconstruction loss, which urges the decoder to rebuild the input data according to the masked data and the latent variables. (2) The second term \(_{}\) is used to regularize the posterior distribution in the latent space to approach a standard Gaussian distribution, so that we can sample \(\) from the distribution when inference. (3) \(\) is a hyperparameter to control the weight of regularization, which is critical in training a VAE model .

### Model Implementation

To implement Equation 4, we need to instantiate the masking process \((}|)\), the encoder \(q_{}(|)\), and the decoder \(p_{}(|},)\), respectively.

Masking ProcessFor simplicity, we uniformly sample a constraint vertex \(()\) and mask it and its adjacent edges, while keeping the variable vertices unchanged. Specifically, we label the vertex \(\) with a special [mask] token, and add virtual edges that link \(\) with each variable vertex. The vertex \(\) and the virtual edges are assigned special embeddings to distinguish them from the others. We further discuss on the masking scheme in Appendix C.2.

EncoderThe encoder \(q_{}(|)\) is implemented as:

\[q_{}(|)=_{u}q_ {}(_{u}|), q_{}(_{u}| )=(_{}(_{u}^{}),_{ }(_{u}^{})), \]

where \(_{u}^{}\) is the node representation of \(u\) obtained by a GNN\({}_{}\), \(\) denotes the Gaussian distribution, and \(\) and \(\) output the mean and the log variance, respectively.

DecoderThe decode \(p_{}\) aims to reconstruct \(\) during training. We apply a GNN\({}_{}\) to obtain the node representations \(_{u}^{}}\), denoted as \(_{u}\) for simplicity. To rebuild the masked constraint vertex \(\), the decoder sequentially determines: 1 the bias \(b_{}\) (i.e., the right-hand side of the constraint), 2 the degree \(d_{}\) of \(\) (i.e., the number of variables involved in the constraint), 3 the logits \(_{,u}\) for all variable vertices \(u\) to indicate whether they are connected with \(\) (i.e., whether the variables are in the constraint), and 4 the weights \(e_{,u}\) of the edges (i.e., the coefficients of the variables in the constraint). The decoder is then formulated as:

\[p_{}(|},)=p_{}(b_ {}|},) p_{}(d_{}|},)_{u}p_{}( _{,u}|},,d_{})_ {u:_{,u}=1}p_{}(e_{,u}| },). \]

Therefore, we implement the decoder as four cooperative modules: 1 Bias Predictor, 2 Degree Predictor, 3 Logits Predictor, and 4 Weights Predictor.

1 Bias PredictorFor effective prediction, we incorporate the prior of simple statistics of the dataset--the minimum \(\) and the maximum \(\) of the bias terms that occur in the dataset--into the predictor. Specifically, we normalize the bias \(b_{}\) to \(\) via \(b_{}^{*}=(b_{}-)/(-)\). To predict \(b_{}^{*}\), we use one MLP that takes the node representation \(_{}\) and the latent vector \(_{}\) of \(\) as inputs:

\[_{}^{*}=(_{}^{}( [_{},_{}])), \]

where \(()\) is the sigmoid function used to restrict the outputs. We use the mean squared error (MSE) loss to train the predictor. At inference time, we apply the inverse transformation to obtain the predicted bias values: \(_{}=+(-)_{ }^{*}\).1Degree PredictorWe find that the constraint degrees are crucial to the graph structures and significantly affect the combinatorial properties. Therefore, we use the Degree Predictor to determine coarse-grained degree structure, and then use the Logits Predictor to determine the fine-grained connection details. Similarly to Bias Predictor, we normalize the degree \(d_{}\) to \(d_{}^{*}=(d_{}-)/(-)\), where \(\) and \(\) are the minimum and maximum degrees in the dataset, respectively. We use one MLP to predict \(d_{}^{*}\):

\[_{}^{*}=(_{}^{}([ _{},_{}])). \]

We use MSE loss for training, and round the predicted degree to the nearest integer \(_{}\) for inference.

\(\) Logits PredictorTo predict the logits \(_{,u}\) indicating whether a variable vertex \(u\) is connected with \(\), we use one MLP that takes the representation \(_{u}\) and the latent vector \(_{u}\) of \(u\) as inputs:

\[_{,u}^{}=(_{}^{ }([_{u},_{u}])). \]

We use binary cross-entropy (BCE) loss to train the logistical regression module. As positive samples (i.e., variables connected with a constraint) are often scarce, we use one negative sample for each positive sample during training. The loss function is:

\[_{}=-_{(,u) p_{}} [(_{,u}^{})]-_{ (,u) p_{}}[(1-_{,u}^ {})], \]

where \(p_{}\) and \(p_{}\) denote the distributions over positive and negative samples, respectively. At inference time, we connect \(_{}\) variable vertices with the top logits to \(\), i.e.,

\[_{,u}=1,u(\{_{,u}^{}|u\},_{}),\\ 0,. \]

\(\) Weights PredictorFinally, we use one MLP to predict the normalized weights \(e_{,u}^{*}\) for nodes \(u\) that are connected with \(\):

\[_{,u}^{*}=(_{}^{}([_{u},_{u}])). \]

The training and inference procedures are similar to those of Bias Predictor.

### Training and Inference

During training, we use the original graph \(\) to provide supervision signals for the decoder, guiding it to reconstruct \(\) from the masked \(}\) and the encoded \(\). As described above, the decoder involves four modules, each optimized by a prediction task. The first term in Equation 4, i.e., the reconstruction loss, is written as

\[_{}=_{}, {}}||}[_{i=1}^ {4}_{i}_{i}(,|,})], \]

where \(_{i}(,|,})\) (\(i=1,2,3,4\)) are loss functions for the four prediction tasks, respectively, and \(_{i}\) are hyperparameters.

During inference, we discard the encoder and sample \(\) from a standard Gaussian distribution, which introduces randomness to enable the model to generate novel instances. We iteratively mask one constraint vertex in the bipartite graph and replace it with a generated one. We define a hyperparameter \(\) to adjust the ratio of iterations to the number of constraints, i.e., \(N_{}=||\). Naturally, a larger value of \(\) results in instances that are more novel, while a smaller value of \(\) yields instances that exhibit better similarity to the training set. For further details of training and inference procedures, please refer to Appendix A.3.

## 4 Experiments

### Setup

We conduct extensive experiments to demonstrate the effectiveness of our model. More experimental details can be found in Appendix B. Additional results are in Appendix C.

BenchmarkingTo evaluate the quality of the generated MILP instances, we design three benchmarks so as to answer the following research questions. (1) How well can the generated instances preserve the graph structures of the training set? (2) How closely do the generated instances resemble the computational hardness of real-world instances? (3) How effectively do they facilitate downstream tasks to improve solver performance?

I. Structural Distributional SimilarityWe consider \(11\) classical statistics to represent features of the instances , including coefficient density, node degrees, graph clustering, graph modularity, etc. In line with a widely used graph generation benchmark , we compute the Jensen-Shannon (JS) divergence  for each statistic to measure the distributional similarity between the generated instances and the training set. We then standardize the metrics into similarity scores that range from \(0\) to \(1\). The computing details can be found in Appendix B.3.

II. Computational HardnessThe computational hardness is another critical metric to assess the quality of the generated instances. We draw an analogy from the SAT generation community, where though many progresses achieved, it is widely acknowledged that the generated SAT instances differs significantly from real-world ones in the computational hardness , and this issue remains inadequately addressed. In our work, we make efforts to mitigate this problem, even in the context of MILP generation, a more challenging task. To this end, we leverage the state-of-the-art solver Gurobi  to solve the instances, and we report the solving time and the numbers of branching nodes during the solving process, which can directly reflect the computational hardness of instances .

III. Downstream TaskWe consider two downstream tasks to examine the the potential benefits of the generated instances in practical applications. We employ G2MILP to generate new instances and augment the original datasets, and then evaluate whether the enriched datasets can improve the performance of the downstream tasks. The considered tasks include predicting the optimal values of the MILP problem, as discussed in Chen et al. , and applying a predict-and-search framework for solving MILPs, as proposed by Han et al. .

DatasetsWe consider four different datasets of various sizes. (1) _Large datasets._ We evaluate the model's capability of learning data distributions using two well-known synthetic MILP datasets: Maximum Independent Set (MIS)  and Set Covering . We follow previous works  to artificially generate \(1000\) instances for each of them. (2) _Medium dataset._ Mixed-integer Knapsack (MIK) is a widely used dataset , which consists of \(80\) training instances and \(10\) test instances. We use this dataset to evaluate the model's performance both on the distribution learning benchmarks and the downstream task. (3) _Small dataset._ We construct a small subset of MIPLIB 2017  by collecting a group of problems called Nurse Scheduling problems. This dataset comes from real-world scenarios and consists of only \(4\) instances, \(2\) for training and \(2\) for test, respectively. Since the statistics are meaningless for such an extremely small dataset, we use it only to demonstrate the effectiveness of generated instances in facilitating downstream tasks.

BaselinesG2MILP is the first deep learning generative framework for MILP isntances, and thus, we do not have any learning-based models for comparison purpose. Therefore, we compare G2MILP with a heuristic MILP instance generator, namely Bowly . Bowly can create feasible and bounded MILP instances while controlling some specific statistical features such as coefficient density and coefficient mean. We set all the controllable parameters to match the corresponding statistics of the training set, allowing Bowly to imitate the training set to some extent. We also consider a useful baseline, namely Random, to demonstrate the effectiveness of deep neural networks in G2MILP. Random employs the same generation procedure as G2MILP, but replaces all neural networks in the decoder with random generators. We set the masking ratio \(\) for Random and G2MILP to \(0.01\), \(0.05\), and \(0.1\) to show how this hyperparameter helps balance the novelty and similarity.

### Quantitative Results

I. Structural Distributional SimilarityWe present the structural distributional similarity scores between each pair of datasets in Table 1. The results indicate that our designed metric is reasonable in the sense that datasets obtain high scores with themselves and low

    & MIS & SetCover & MIK \\  MIS & 0.998 & 0.182 & 0.042 \\ SetCover & - & 1.000 & 0.128 \\ MIK & - & - & 0.997 \\   

Table 1: Structural similarity scores between each pair of datasets. Higher is better.

scores with different domains. Table 2 shows the similarity scores between generated instances and the corresponding training sets. We generate \(1000\) instances for each dataset to compute the similarity scores. The results suggest that G2MILP closely fits the data distribution, while Bowly, which relies on heuristic rules to control the statistical features, falls short of our expectations. Furthermore, we observe that G2MILP outperforms Random, indicating that deep learning contributes to the model's performance. As expected, a higher masking ratio \(\) results in generating more novel instances but reduces their similarity to the training sets.

II. Computational HardnessWe report the average solving time and numbers of branching nodes in Table 3 and Table 4, respectively. The results indicate that instances generated by Bowly are relatively easy, and the hardness of those generated by Random is inconclusive. In contrast, G2MILP is capable of preserving the computational hardness of the original training sets. Notably, even without imposing rules to guarantee the feasibility and boundedness of generated instances, G2MILP automatically learns from the data and produces feasible and bounded instances.

III. Downstream TaskFirst, we follow Chen et al.  to construct a GNN model for predicting the optimal values of MILP problems. We train a predictive GNN model on the training set. After that, we employ \(20\) generated instances to augment the training data, and then train another predictive

    & & MIS & SetCover & MIK \\   & 16.09 & 838.56 & 175.35 \\   & 0.00 (100.0\%) & 0.00 (100.0\%) & 0.00 (100.0\%) \\   & Random & 20.60 (28.1\%) & **838.51 (0.0\%)** & 0.81 (99.5\%) \\   & G2MILP & **15.03 (6.6\%)** & 876.09 (4.4\%) & **262.25 (14.7\%)** \\   & Random & 76.22 (373.7\%) & 765.30 (8.7\%) & 0.00 (100\%) \\   & G2MILP & **10.58 (34.2\%)** & **874.46 (4.3\%)** & **235.35 (34.2\%)** \\   & Random & 484.47 (2911.2\%) & 731.14 (12.8\%) & 0.00 (100\%) \\   & G2MILP & **4.61 (71.3\%)** & **876.92 (4.6\%)** & **140.06 (20.1\%)** \\   

Table 4: Average numbers of branching nodes of instances solved by Gurobi. \(\) is the masking ratio. Numbers in the parentheses are relative errors with respect to the training sets (lower is better).

    & & MIS & SetCover & MIK \\   & 0.349 \(\) 0.05 & 2.344\(\) 0.13 & 0.198\(\) 0.04 \\   & 0.007\(\) 0.00 (97.9\%) & 0.048\(\) 0.00 (97.9\%) & 0.001\(\) 0.00 (99.8\%) \\   & Random & 0.311\(\) 0.05 (10.8\%) & 2.044\(\) 0.19 (12.8\%) & 0.008\(\) 0.00 (96.1\%) \\   & G2MILP & **0.354\(\) 0.06 (1.5\%)** & **2.360\(\) 0.18 (0.8\%)** & **0.169\(\) 0.07 (14.7\%)** \\   & Random & 0.569\(\) 0.09 (63.0\%) & 2.010\(\) 0.11 (14.3\%) & 0.004\(\) 0.00 (97.9\%) \\   & G2MILP & **0.292\(\) 0.07 (16.3\%)** & **2.533\(\) 0.15 (8.1\%)** & **0.129\(\) 0.05 (35.1\%)** \\   & Random & 2.367\(\) 0.35 (578.2\%) & 1.988\(\) 0.17 (15.2\%) & 0.005\(\) 0.00 (97.6\%) \\   & G2MILP & **0.214\(\) 0.05 (38.7\%)** & **2.108\(\) 0.21 (10.0\%)** & **0.072\(\) 0.02 (63.9\%)** \\   

Table 3: Average solving time (s) of instances solved by Gurobi (mean \(\) std). \(\) is the masking ratio. Numbers in the parentheses are relative errors with respect to the training sets (lower is better).

model using the enriched dataset. We use the prediction mean squared error (MSE) to assess the resulting models, and we present the MSE relative to the default model trained on the original training sets in Figure 2. For the MIK dataset, instances generated by Bowly introduce numerical issues so that Ecole and SCIP fail to read them. For the Nurse Scheduling dataset, Random fails to generate feasible instances. Notably, G2MILP is the only method that demonstrates performance improvement on both datasets, reducing the MSE by \(73.7\%\) and \(24.3\%\), respectively. The detailed results are in Table 8 in Appendix B.4. Then, we conduct experiments on the neural solver, i.e., the predict-and-search framework proposed by Han et al. , which employs a model to predict a solution and then uses solvers to search for the optimal solutions in a trust region. The results are in Table 9 in Appendix B.4.

### Analysis

Masking ProcessWe conduct extensive comparative experiments on different implementations of the masking process. First, we implement different versions of G2MILP, which enable us to mask and modify either constraints, variables, or both. Second, we investigate different orders of masking constraints, including uniformly sampling and sampling according to the vertex indices. Third, we analyze the effect of the masking ratio \(\) on similarity scores and downstream task performance improvements. The experimental results are in Appendix C.2.

Size of DatasetWe conduct experiments on different sizes of the original datasets and different ratio of generated instances to original ones on MIS. Results are in Table 15 in Appendix C.4. The results show that G2MILP yields performance improvements across datasets of varying sizes.

VisualizationWe visualize the instance representations for MIK in Figure 3. Specifically, we use the G2MILP encoder to obtain the instance representations, and then apply t-SNE dimensionality reduction  for visualization. We observe that the generated instances, while closely resembling the training set, contribute to a broader and more continuous exploration of the problem space, thereby enhancing model robustness and generalization. Additionally, by increasing the masking ratio \(\), we can effectively explore a wider problem space beyond the confines of the training sets. For comparison with the baseline, we present the visualization of instances generated by Random in Figure 5 in Appendix C.5.

Figure 3: The t-SNE visualization of MILP instance representations for MIK. Each point represents an instance. Red points are from the training set and blue points are instances generated by G2MILP.

Figure 2: Results of the optimal value prediction task. Bars indicate the relative MSE to the model trained on the original training sets, and lines represent the relative performance improvement.

## 5 Limitations, Future Avenues, and Conclusions

LimitationsIn this paper, we develop G2MILP by iteratively corrupting and replacing the constraints vertices. We also investigate different implementations of the masking process. However, more versatile masking schemes should be explored. Moreover, employing more sophisticated designs would enable us to control critical properties such as feasibility of the instances. We intend to develop a more versatile and powerful generator in our future work.

Future AvenuesWe open up new avenues for research on DL-based MILP instance generative models. In addition to producing new instances to enrich the datasets, this research has many other promising technical implications . (1) Such a generator will assist researchers to gain insights into different data domains and the explored space of MILP instances. (2) Based on a generative model, we can establish an adversarial framework, where the generator aims to identify challenging cases for the solver, thus automatically enhancing the solver's ability to handle complex scenarios. (3) Training a generative model involves learning the data distribution and deriving representations through unsupervised learning. Consequently, it is possible to develop a pre-trained model based on a generative model, which can benefit downstream tasks across various domains. We believe that this paper serves as an entrance for the aforementioned routes, and we expect further efforts in this field.

ConclusionsIn this paper, we propose G2MILP, which to the best of our knowledge is the first deep generative framework for MILP instances. It can learn to generate MILP instances without prior expert-designed formulations, while preserving the structures and computational hardness, simultaneously. Thus the generated instances can enhance MILP solvers under limited data availability. This work opens up new avenues for research on DL-based MILP instance generative models.