# On the Computational Landscape of

Replicable Learning

Alkis Kalavasis

Yale University

alvertos.kalavasis@yale.edu

&Amin Karbasi

Yale University

amin.karbasi@yale.edu

&Grigoris Velegkas

Yale University

grigoris.velegkas@yale.edu

&Felix Zhou

Yale University

felix.zhou@yale.edu

###### Abstract

We study computational aspects of algorithmic replicability, a notion of stability introduced by Impagliazzo, Lei, Pitassi, and Sorrell (2022). Motivated by a recent line of work that established strong _statistical_ connections between replicability and other notions of learnability such as online learning, private learning, and SQ learning, we aim to understand better the _computational_ connections between replicability and these learning paradigms. Our first result shows that there is a concept class that is efficiently replicably PAC learnable, but, under standard cryptographic assumptions, no efficient online learner exists for this class. Subsequently, we design an efficient replicable learner for PAC learning parities when the marginal distribution is far from uniform, making progress on a question posed by Impagliazzo et al. (2022). To obtain this result, we design a replicable lifting framework inspired by Blanc, Lange, Malik, and Tan (2023) that transforms in a black-box manner efficient replicable PAC learners under the uniform marginal distribution over the Boolean hypercube to replicable PAC learners under any marginal distribution, with sample and time complexity that depends on a certain measure of the complexity of the distribution. Finally, we show that any pure DP learner can be transformed to a replicable one in time polynomial in the accuracy, confidence parameters and exponential in the representation dimension of the underlying hypothesis class.

## 1 Introduction

The replicability crisis is omnipresent in many scientific disciplines including biology, chemistry, and, importantly, AI (Baker, 2016; Pineau et al., 2019). A recent article that appeared in Nature (Ball, 2023) explains how the reproducibility crisis witnessed in AI has a cascading effect across many other scientific areas due to its widespread applications in other fields, like medicine. Thus, a pressing task is to design a formal framework through which we can argue about the replicability of experiments in ML. Such an attempt was initiated recently by the pioneering work of Impagliazzo et al. (2022), who proposed a definition of replicability as a property of learning algorithms.

**Definition 1.1** (Replicable Algorithm; Impagliazzo et al., 2022).: _Let \(\) be a distribution over random strings. A learning algorithm \(\) is \(n\)-sample \(\)-replicable under distribution \(\) if for two independent sets \(S,S^{}^{n}\) it holds that \(_{S,S^{}^{n},r}[(S,r) (S^{},r)]\). We will say that \(\) is replicable if the above holds uniformly over all distributions \(\)._

We emphasize that the random string \(r\) is shared across the two executions and this aspect of the definition is crucial in designing algorithms that have the same output under two different i.i.d. inputs. Indeed, both Dixon et al. (2023) and Chase et al. (2023) demonstrated learning tasks for which thereare no algorithms that satisfy this strong notion of replicability when the randomness is not shared across executions. This shared random string models the random seed of a learning algorithm in practice, and sharing internal randomness can be easily implemented by sharing said random seed.

Closer to our work, Impagliazzo et al. (2022), Ghazi et al. (2021), Bun et al. (2023), Kalavasis et al. (2023) established strong _statistical_ connections between replicability and other notions of algorithmic stability and learning paradigms such as differential privacy (DP), statistical queries (SQ), and online learning. Although several of these works provided various _computational_ results, these connections are not as well understood as the statistical ones.

### Our Contributions

In this work, we aim to shed further light on the aforementioned _computational_ connections. In particular, we provide both negative and positive results. Negative results are manifested through _computational separations_ while positive results are presented through _computational transformations_, as we will see shortly. We emphasize that whenever we work within the PAC learning framework we consider the _realizable_ setting.

Replicability & Online Learning.The results of Ghazi et al. (2021), Bun et al. (2023), Kalavasis et al. (2023) established a statistical connection between replicability and online learning. In particular, in the context of PAC learning, these works essentially show that replicable PAC learning is statistically equivalent to online learning since learnability in both settings is characterized by the finiteness of the Littlestone dimension of the underlying concept class. From the above, the first natural question is the following:

Q1. _How does replicability computationally relate to online learning?_

We show that under standard cryptographic assumptions, efficient replicability is separated from efficient online learning.

**Theorem 1.2** (Informal, see Theorem 2.1).: _Assuming the existence of one-way functions, there is a concept class that is replicably PAC learnable in polynomial time, but is not efficiently online learnable by any no-regret algorithm._

In order to prove the above result, we provide an efficient replicable PAC learner for the concept class of _One-Way Sequences_\(\) over \(\{0,1\}^{d}\), introduced by Blum (1994). This algorithm, which relies on a novel replicable subroutine for quantile estimation (cf. Theorem B.6), combined with the cryptographic hardness result of Bun (2020) for online learnability, gives the desired computational separation. For further details, we refer to Section 2.

Replicability & SQ.The Statistical Query (SQ) framework is an expressive model of statistical learning introduced by Kearns (1998). This model of learning is a restricted class of algorithms that is only permitted indirect access to samples through approximations of certain carefully chosen functions of the data (statistical queries). The motivation behind the introduction of the SQ framework was to capture a large class of noise-resistant learning algorithms. As such, any SQ algorithm enjoys some inherent stability properties. Since replicability also captures some notion of algorithmic stability, it is meaningful to ask:

Q2. _How does replicability computationally relate to SQ learning?_

For some background about the SQ framework, we refer the reader to Appendix C.2. A manifestation of the intuitive connection between SQ and replicability can be found in one of the main results of Impagliazzo et al. (2022), which states that any efficient SQ algorithm can be efficiently made replicable. In this paper, we investigate the other direction of this connection.

A particularly interesting computational separation between (distribution-specific) replicability and SQ learning was noticed by Impagliazzo et al. (2022), in the context of realizable binary classification: if we consider the uniform distribution \(\) over the Boolean hypercube \(\{0,1\}^{d}\), then the concept class of parities is SQ-hard to learn under \(\)(Kearns, 1998) but admits an efficient PAC learner that is replicable under \(\). Indeed, with high probability over the random draw of the data, Gaussian elimination, which is the standard algorithm for PAC learning parities under \(\), gives a _unique_ solution and, as a result, is replicable.

Based on this observation, Impagliazzo et al. (2022) posed as an interesting question whether parities are efficiently learnable by a replicable learner under other marginal distributions, for which Gaussian elimination is "unstable", i.e., it fails to give a unique solution (see e.g., Proposition C.4).

Transforming Distribution-Specific Replicable Learners.Inspired by the question of Impagliazzo et al. (2022), we ask the following more general question for realizable binary classification:

Q3. _For a class \(\{0,1\}^{}\) and marginal distributions \(_{1},_{2}\) over \(\), how does replicable PAC learnability of \(\) under \(_{1}\) and under \(_{2}\) relate to one another computationally?_

Our main result is a general black-box transformation from a replicable PAC learner under the uniform distribution over \(=\{0,1\}^{d}\) to a replicable PAC learner under some unknown marginal distribution \(\). The runtime of the transformation depends on the _decision tree complexity_ of the distribution \(\), a complexity measure that comes from the recent work of Blanc et al. (2023) and is defined as follows:

**Definition 1.3** (Decision Tree Complexity; Blanc et al., 2023).: _The decision tree complexity of a distribution \(\) over \(\{0,1\}^{d}\) is the smallest integer \(\) such that its probability mass function (pmf) can be computed by a depth-\(\) decision tree (cf. Definition D.1)._

A _decision tree_ (cf. Definition D.1) \(T:\{0,1\}^{d}\) is a binary tree whose internal nodes query a particular coordinate \(x_{i},i[d]\) (descending left if \(x_{i}=0\) and right otherwise) and whose leaves are labelled by real values. Each \(x\{0,1\}^{d}\) follows a unique root-to-leaf path based on the queried coordinate of internal nodes, and its value \(T(x)\) is the value stored at the root. For some \(\) over the Boolean hypercube, we say \(\) is _computed by a decision tree \(T\) of depth \(\)_ if, for any \(x\{0,1\}^{d}\), it holds that \((x)=T(x)\).

As an example, note that the uniform distribution requires depth \(=1\) since its pmf is constant while a distribution whose pmf takes \(2^{d}\) different values requires depth \(=d\). However, various natural (structured) distributions have tree complexity much smaller than \(d\). Importantly, the running time overhead of our lifting approach scales proportionally to the decision tree complexity of \(\) and hence can be used to obtain novel efficient replicable PAC learners.

Our replicable lifting framework informally states the following:

**Theorem 1.4** (Informal, see Theorem 3.2).: _Let \(=\{0,1\}^{d}\) and \(m=(d)\). Consider a concept class \(\{0,1\}^{}\) and assume that \(\) is a PAC learner for \(\) that is \(m\)-sample replicable under the uniform distribution and runs in time \((m)\). Then, for some (unknown) monotone1 distribution \(\) with decision tree complexity \(\), there exists an algorithm \(^{}\) that is a PAC learner for \(\) that is \((m)^{}\)-sample replicable under \(\) and runs in time \(((m)^{})\)._

This implies for instance that for \(=O(1)\), the blowup is polynomial in the runtime of the uniform learner while if \(=O( d)\), the running time is quasi-polynomial in \(d\). We note that our result can also be extended to general (non-monotone) distributions \(\) if we assume access to a _(subcube) conditional sampling oracle_. For formal details, we refer the reader to Section 3.

As an application of this framework, we show how to black-box transform replicable learners for parities that work under the uniform distribution to replicable learners that work under some other unknown distribution \(\), where the sample complexity and running time of the transformation depends on the decision tree complexity of \(\). This result is hence related to the question of Impagliazzo et al. (2022) since we can design distributions \(\) over \(\{0,1\}^{d}\) with small decision tree complexity for which Gaussian elimination fails to be replicable. We refer to Section 4 for the formal statement.

**Corollary 1.5** (Informal, see Corollary 4.3 and Theorem C.5).: _Let \(=\{0,1\}^{d}\) and \(m=(d)\). Then, for any (unknown) monotone distribution \(\) with decision tree complexity \(\), there exists a PAC learner for parities that is \((m)^{}\)-sample replicable under \(\) and runs in time \(((m)^{})\)._

_Moreover, for any \(m^{}=m^{(1)}\), there exists some monotone distribution \(\) over \(\{0,1\}^{d}\) with decision tree complexity \(=(1)\) so that Gaussian elimination, with input \(m^{}\) labeled examples, fails to PAC learn parities replicably under \(\) with constant probability._Replicability & Privacy.Returning to the works of Ghazi et al. (2021); Bun et al. (2023); Kalavasis et al. (2023), it is known that replicable PAC learning is statistically equivalent to approximate differentially private PAC learning. We hence ask:

### Q4. How does replicability computationally relate to private learning?

The recent work of Bun et al. (2023) provided a computational separation between _approximate_ differential privacy and replicability. In particular, they showed that a replicable learner can be efficiently transformed into an approximately differentially private one, but the other direction is hard under standard cryptographic assumptions. To be more specific, they provided a concept class that is efficiently learnable by an approximate DP learner, but not efficiently learnable by a replicable learner, assuming the existence of one-way functions. Based on this hardness result, we ask whether we can transform a _pure_ DP algorithm into a replicable one. We show the following result.

**Theorem 1.6** (Informal; see Theorem 5.2).: _Let \(_{XY}\) be a distribution on \(\{0,1\}\) that is realizable with respect to some concept class \(\). Let \(\) be an efficient pure DP learner for \(\). Then, there is a replicable learner \(^{}\) for \(\) that runs in time polynomial with respect to the error, confidence, and replicability parameters but exponential in the representation dimension2 of \(\)._

We reiterate that this transformation is efficient with respect to the correctness, confidence and replicability parameters \(,,\), but _it could be inefficient_ with respect to some parameter that captures the complexity of the underlying concept class \(\) (such as the representation dimension of the class, e.g., the margin parameter in the case of large-margin halfspaces). To the best of our knowledge, the same holds for the transformation of a pure DP learner to an online learner of Gonen et al. (2019) and it would be interesting to show that this is unavoidable.

The Computational Landscape of Stability.Our work studies several computational aspects of replicability and its connections with other stability notions such as online learning, SQ learning, and differential privacy. Combining our results with the prior works of Blum et al. (2005); Gonen et al. (2019); Ghazi et al. (2021); Impagliazzo et al. (2022); Bun et al. (2023); Kalavasis et al. (2023) yields the current computational landscape of stability depicted below.

The computational landscape of "stable" learning depicted in Figure 1.1 is a byproduct of the following results connecting (i) replicability, (ii) approximate DP, (iii) pure DP, (iv) online learning, and, (v) statistical queries.

**Black-Box Transformations.**

1. Pure DP can be efficiently3 transformed to Online . 2. Replicability can be efficiently transformed to Approximate DP .
3. SQ can be efficiently transformed to Approximate DP .4 4. SQ can be efficiently transformed to Approximate DP .4 5. SQ can be efficiently transformed to Replicable .
6. Pure DP can be efficiently5 transformed to Replicable (this work, Theorem 5.2).

Caveats of Transformations.The transformations from pure \(\)-DP learners to replicable and online learners may incur exponential computation time in the _representation dimension_ of the underlying hypothesis class.

Regarding the approximate DP reduction to replicability: The transformation provided by Bun et al.  uses correlation, which necessitates that the output space of the algorithm is finite. To be more precise, based on , there is an efficient transformation from approximate DP to perfectly generalizing algorithms. Next, the authors use correlated sampling to obtain a replicable learner as follows. Given a perfectly generalizing algorithm \(A\) and sample \(S\), the correlated sampling strategy is applied to the distribution of outputs of \(A(S)\). Hence, the output space of \(A\) should be finite. In the PAC learning setting, to ensure that the algorithm has finite output space, one sufficient condition is that the domain \(\) is finite. The correlated sampling step can be explicitly implemented via rejection sampling from the output space of \(A\). The acceptance probability is controlled by the probability mass function of \(A(S)\). As a result, in general, it is not computationally efficient. For instance, if the finite input space to the correlated sampling strategy is \(\{0,1\}^{d}\), then the runtime of the algorithm could be \((d)\), since the acceptance probability is exponentially small in the dimension in the worst case.

For the specific case of PAC learning, there is another transformation from approximate DP to replicability that holds for countable domains \(\) that was proposed by Kalavasis et al. , but this approach goes through the Littlestone dimension of the class and might not even be computable in its general form.

Separations.There is a concept class that can be learned efficiently

1. by a replicable PAC learner (this work, Theorem 2.1), but not an efficient online one under OWF
2. ;
3. by an approximate DP PAC learner, but not an efficient online one under OWF ;
4. by an online learner, but not an efficient approximate DP PAC one under cryptographic assumptions6; 
Figure 1.1: The computational landscape of stability. A green double arrow (\(\)) from tail to head indicates that an efficient learner for a task in the setting of the arrow tail can be black-box transformed into an efficient learner for the same task in the setting of the arrow head. Meanwhile, an orange dashed double arrow (\(==\)) from tail to head indicates that an efficient learner for a task in the tail setting can be black-box transformed into an efficient learner for the same task in the head setting, under some additional assumptions. Finally, a red slashed single arrow (\(\)) from tail to head indicates that there is a learning task for which an efficient learner exists in the setting of the arrow tail but no efficient learner can exist in the setting of the arrow head, possibly under some cryptographic assumptions.

5. by an approximate DP PAC learner, but not an efficient replicable one under OWF [Bun et al., 2023].

### Related Work

**Replicability.** Pioneered by Impagliazzo et al. , there has been a growing interest from the learning theory community in studying replicability as an algorithmic property. Esfandiari et al.  studied replicable algorithms in the context of multi-armed bandits and clustering. Later, Eaton et al. , Karbasi et al.  studied replicability in the context of Reinforcement Learning (RL) and designed algorithms that achieve various notions of replicability. Recently, Bun et al.  established statistical equivalences and separations between replicability and other notions of algorithmic stability such as differential privacy when the domain of the learning problem is finite and provided some computational and statistical hardness results to obtain these equivalences, under cryptographic assumptions. Subsequently, Kalavasis et al.  proposed a relaxation of the replicability definition of Impagliazzo et al. , showed its statistical equivalence to the notion of replicability for countable domains7 and extended some of the equivalences from Bun et al.  to countable domains. Chase et al. , Dixon et al.  proposed a notion of _list-replicability_, where the randomness is not shared across the executions of the algorithm, but the outputs are required to belong to a list of small cardinality instead of being identical. Both of these works developed algorithms that work in the _realizable_ setting, and later Chase et al.  showed that, surprisingly, it is impossible to design list-replicable learning algorithms for infinite classes in the _agnostic_ setting. Recently, Moran et al.  established even more statistical connections between replicability and other notions of stability, by dividing them into two categories consisting of distribution-dependent and distribution-independent definitions. Recent work by Kalavasis et al.  studies replicable algorithms for large-margin halfspaces.

Computational Separations & Transformations in Stability.The seminal result of Blum  illustrated a computational separation between PAC and online learning. Later, Bun  obtained a similar separation between private PAC and online learning. More recently, Bun et al.  showed that there exists a concept class that admits an efficient approximate DP learner but not an efficient replicable one, assuming the existence of OWFs. Contributing to this line of work, our Theorem 2.1 is of similar flavor.

Shifting our attention to SQ learning, there is an intuitive similarity between learning from noisy examples and private learning: algorithms for both problems must be robust to small variations in the data (see also Blum et al. ). Parities are a canonical SQ-hard problem, meaning that no efficient SQ algorithm for this class exists. Kasiviswanathan et al.  designed an efficient private learner for learning parities, which dispels the similarity between learning with noise and private learning. Georgiev and Hopkins  showed that while polynomial-time private algorithms for learning parities are known, the failure probability of any such algorithm must be larger than what can be achieved in exponential time, or else \(=\). Finally, recent work by Bun et al.  gives a concept class that admits an online learner running in polynomial time with a polynomial mistake bound, but for which there is no computationally efficient approximate differentially private PAC learner, under cryptographic assumptions.

Moving on to transformations, our Theorem 1.4 builds upon the result of Blanc et al.  who designed a framework that transforms computationally efficient algorithms under uniform marginal distributions, to algorithms that work under some other distribution, where the complexity of the transformation scales with some particular notion of distance between the two distributions. Essentially, our result can be viewed as a replicable framework of the same flavor, with a small additional computational and statistical overhead that scales with the replicability parameter. Finally, our approach to transform a pure DP learner into a replicable learner (cf. Theorem 1.6) is inspired by Gonen et al. , who provided a transformation from pure DP learners to online learners.

### Notation

In general, we use \(\) to denote an algorithm. For unsupervised problems, we usually denote by \(\) the distribution over input examples. In the case of supervised problems, we use \(\) to denote the concept class in question, \(\) to denote the marginal distribution of the feature domain \(\), and \(_{}\) to refer to the joint distribution over labeled examples \((x,y)\). Throughout our work, we use \(,\) to refer to the error and failure probability parameters of the algorithm, \(,\) to denote the approximate DP parameters, and \(\) for the replicability parameter. In most cases, the feature domain \(\) is a subset of a high-dimensional space and we use \(d\) to denote the dimension of that space.

## 2 Efficient Replicability and Online Learning

Our first main result shows that replicability and online learning are _not_ computationally equivalent, assuming the existence of one-way functions. This hardness result is based on a construction from Blum (1994), who defined a concept class denoted by \(\), which is efficiently PAC learnable but not online learnable in polynomial time, assuming the existence of one-way functions. Blum's construction builds upon the Goldreich-Goldwasser-Micali pseudorandom function generator (Goldreich et al., 1986) to define families of "one-way" labeled sequences \((_{1},b_{1}),,(_{r},b_{r})\{0,1\}^{d}\{0,1\}\), for some \(r=((d))\). These string-label pairs can be efficiently computed in the forward direction, but are hard to compute in the reverse direction. Specifically, for any \(i<j\), it is easy to compute \(_{j},b_{j}\) given \(_{i}\). On the other hand, it is hard to compute \(_{i},b_{i}\) given \(_{j}\).

The essence of the difficulty in the online setting is that an adversary can present to the learner the sequence in reverse order, i.e., \(_{r},_{r-1},,_{1}\). Then, the labels \(b_{i}\) are not predictable by a polynomial time learner. However, in the PAC setting, for any distribution over the sequence \(\{(_{i},b_{i})\}_{i[r]}\), a learner which is given \(n\) labeled examples can identify the string \(_{i^{*}}\) with smallest index \(i^{*}\) in the sample. Then, it can perfectly and efficiently predict the label of any string that comes after it. This approximately amounts to a \((1-}{{n}})\) fraction of the underlying population.

It is not hard to see that the PAC learner for \(\) is not replicable, since the minimum index of a sample can vary wildly between samples. The high-level idea of our approach to making the algorithm replicable is to show that we can replicably identify an _approximate_ minimum index and output the hypothesis that (efficiently) forward computes from that index. Our main result, proven in Appendix B, is as follows.

**Theorem 2.1**.: _Let \(d\). The following hold:_

1. _[_20_]_ _Assuming the existence of one-way functions, the concept class_ \(\) _with input domain_ \(\{0,1\}^{d}\) _cannot be learned by an efficient no-regret algorithm, i.e., an algorithm that for some_ \(>0\) _achieves expected regret_ \([R_{T}](d) T^{1-}\) _using time_ \((d,T)\) _in every iteration._8__ 2. _(Theorem B.7) The concept class_ \(\) _with input domain_ \(\{0,1\}^{d}\) _can be learned by a_ \(\)_-replicable_ \((,)\)_-PAC learner with sample complexity_ \(m=(d,}{{}},}{{}}, (}{{}}))\) _and_ \((m)\) _running time._

## 3 Lifting Replicable Uniform Learners

In this section, we present our replicable lifting framework in further detail. First, we will need the following technical definition.

**Definition 3.1** (Closed under Restrictions).: _A concept class \(\) of functions \(f:\{0,1\}^{d}\{0,1\}\) is closed under restrictions if, for any \(f,i[d]\) and \(b\{0,1\}\), the restriction \(f_{i=b}\) remains in \(\), where \(f_{i=b}(x)=f(x_{1},...,x_{i-1},b,x_{i+1},...,x_{d})\) for any \(x\{0,1\}^{d}\)._

Our replicable lifting result works for concept classes that satisfy the closedness under restrictions property. Also, recall that a distribution \(\) over \(\{0,1\}^{d}\) is _monotone_ (Definition D.4) if whenever \(x y\) (\(x\) is greater than \(y\) in the partial ordering of the poset), it holds \((x)(y)\). Our algorithm for lifting replicable uniform learners to replicable learners under some unknown distribution \(\) is presented in Theorem 3.2. This lifting approach is inspired by the work of Blanc et al. (2023), who designed the non-replicable variant of this transformation. We note that our algorithm, similar to the algorithm of Blanc et al. (2023), only requires sample access to \(\) for monotone distributions, while, for arbitrary non-monotone probability measures, our algorithm requires access to a _conditional sampling oracle_ (cf. Definition D.5). Our replicable lifting theorem reads as follows.

**Theorem 3.2** (Lifting Replicable Uniform Learners).: _Consider a concept class \(\) of functions \(f:\{0,1\}^{d}\{0,1\}\) closed under restrictions. Suppose we are given black-box access to an algorithm such that for any \(^{},^{},^{}(0,1)\), given \((d,}{{^{}}},}{{^ {}}},(}{{^{}}}))\) samples from \(\),_

1. _[label=()]_
2. _is_ \(^{}\)_-replicable with respect to the uniform distribution_ \(\)_,_
3. _PAC learns_ \(\) _under the uniform distribution to accuracy_ \(^{}\) _and confidence_ \(^{}\)_, and,_
4. _terminates in time_ \((d,}{{^{}}},}{{^ {}}},(}{{^{}}}))\)_Let \(,(0,1)\) and \((0,}{{3}})\). For \(m=(d,}{{}},}{{}},( }{{}}))\) and \(M=(d,}{{}},}{{}},( }{{}}))^{O()}\), the following cases hold:_

1. _If_ \(\) _is a monotone distribution over_ \(\{0,1\}^{d}\) _representable by a depth-_\(\) _decision tree, there is an algorithm that draws_ \(M\) _samples from_ \(\)_, is_ \(\)_-replicable with respect to_ \(\)_, PAC learns_ \(\) _under_ \(\) _with accuracy_ \(\) _and confidence_ \(\)_, and terminates in_ \((M)\) _time._
2. _If_ \(\) _is an arbitrary distribution over_ \(\{0,1\}^{d}\) _representable by a depth-_\(\) _decision tree, there is an algorithm that draws_ \(M\) _labeled examples as well as_ \(M\) _conditional samples (cf. Definition_ D.5_) from_ \(\)_, is_ \(\)_-replicable with respect to_ \(\)_, PAC learns_ \(\) _with respect to_ \(\) _with accuracy_ \(\) _and confidence_ \(\)_, and terminates in_ \((M)\) _time._

The high-level idea of the reduction proceeds as follows. Let us consider the realizable PAC setting, i.e., the labels are consistent with some \(f^{*}\). Let us assume black-box access to a replicable uniform learner \(^{}_{}\) for \(\) and access to i.i.d. samples of the form \((x,f^{*}(x))\), where \(x\). Our goal is to (efficiently) obtain an algorithm \(^{}_{}\) that achieves small misclassification error with respect to the unknown distribution \(\) and target \(f^{*}\) and is also replicable under \(\). The promise is that \(\) has a decision tree representation of depth \(\).9

The first step is to draw enough samples \((x,f^{*}(x)),x\), and compute the decision tree representation of \(\). This is an unsupervised learning task and it only uses the feature vectors of the training set. We design a replicable algorithm for this step (cf. Theorem E.7), which could be of independent interest. The next observation is crucial: any discrete distribution on \(\{0,1\}^{d}\) can be expressed as a mixture of uniform distributions conditioned on non-overlapping sub-cubes. To see this, notice that any root-to-leaf path in the estimated decision tree representation corresponds to a sub-cube of \(\{0,1\}^{d}\) and, conditioned on this path, the remaining coordinates follow a uniform law. Hence, after an appropriate re-sampling procedure, one can employ the black-box replicable learner \(^{}_{}\) to any one of the leaves \(t\) of the tree decomposition of \(\) and obtain a classifier \(f_{t}\). For this step, the fact that \(\) is closed under restrictions is crucial. Intuitively, if we wish to implement this idea in a replicable manner and need overall replicability parameter \(\), it suffices to use the uniform replicable algorithm in each leaf with parameter \(O(}{{2^{}}})\) since we make at most \(2^{}\) calls to the uniform PAC learner (the decision tree complexity of the target is \(\)). Finally, given a test example \(x\), one computes the leaf \(t\) that corresponds to the sub-cube that \(x\) falls into and uses the (replicable) output \(f_{t}\) of the associated uniform PAC learner to guess the correct label.

For the formal analysis, we refer to Appendix D and Appendix E.

## 4 Efficient Replicability and SQ Learning: Parities

In this section, we provide an application of the general lifting framework we described in Section 3. One of the main results of the seminal work of Impagliazzo et al. (2022) is that any SQ algorithm can be made replicable. This result allows a great collection of tasks to be solved replicably since the SQ framework is known to be highly expressive (Kearns, 1998).

The primary motivation of this section comes from the question of Impagliazzo et al. (2022) on whether the class of parities can be PAC learned by an efficient replicable algorithm when the marginal distribution \(\) is not uniform over \(\{0,1\}^{d}\). Let us define our concept class of interest.10

**Definition 4.1** (Affine Parities).: _Let \(S[d]\) be some subset of \([d]\) and \(b\{0,1\}\) a bias term. Define \(f_{S,b}:\{0,1\}^{d}\{0,1\}\) to be the biased parity of the bits in \(S\), namely \(f_{S,b}(x)=b+_{i S}x_{i}\). The concept class of affine parities over \(\{0,1\}^{d}\) is the set \(=\{f_{S,b}:S[d],b\{0,1\}\}\). For any distribution \(\) over \(\{0,1\}^{d}\), we consider the supervised learning problem AffParity, where the learner observes i.i.d. samples of the form \((x,f^{*}(x))\), where \(x\) and \(f^{*}\)._

As observed by Impagliazzo et al. (2022), there is a replicable algorithm for PAC learning parities (i.e., the subclass Parity obtained by setting \(b=0\) in AffParity) under the uniform distribution: draw roughly \(O(d)\) samples so that with high probability the dataset will contain a basis. Then, in two distinct executions, the sets that standard Gaussian elimination outputs will be the same. A similar approach works for the class of affine parities and is described below.

**Lemma 4.2**.: _The concept class of affine parities \(\) over \(\{0,1\}^{d}\) admits a \(\)-replicable algorithm that perfectly learns any concept with respect to the uniform distribution \(\) with probability of success at least \(1-\). The algorithm has \(O((d,}{{}}))\) sample and time complexity._

The algorithm that attains the guarantees of Lemma 4.2 is a simple adaptation of the Gaussian elimination for learning standard parities. We provide the pseudocode in Algorithm C.1 and defer the proof of correctness to Appendix C.1.

Application of Theorem 3.2Since the class of affine parities over \(\{0,1\}^{d}\) is closed under restrictions (cf. Lemma C.8) and there is a learner for this class under uniform marginals that is replicable and efficient (cf. Lemma 4.2), we can obtain an algorithm that replicably PAC learns the class \(\) under more general distributions. In particular, the following result is an immediate application of our lifting framework.

**Corollary 4.3**.: _Let \(,(0,1)\) and \((0,}{{3}})\). Let \(=\{0,1\}^{d}\). For \(M=(d,}{{}},}{{}}, }{{}})^{O()}\), the following cases hold:_

1. _[label=()]_
2. _For any (unknown) monotone distribution_ \(\) _over_ \(\) _with decision tree complexity_ \(\)_, there exists an algorithm that is a_ \(\)_-replicable learner for the concept class_ \(\) _under_ \(\)_, and requires_ \(M\) _samples and running time_ \((M)\) _to get accuracy_ \(\) _and confidence_ \(\)_._
3. _For any distribution_ \(\) _over_ \(\) _with decision tree complexity_ \(\)_, there exists an algorithm that is a_ \(\)_-replicable learner for the concept class_ \(\) _under_ \(\)_, and requires_ \(M\) _labeled examples,_ \(M\) _conditional samples from_ \(\) _and running time_ \((M)\) _to get accuracy_ \(\) _and confidence_ \(\)_._

Back to the Question of Impagliazzo et al. (2022).Impagliazzo et al. (2022) raised the question of when parities over \(\{0,1\}^{d}\) can be efficiently PAC learned by a replicable algorithm under some marginal distribution \(\) that is not uniform or, more broadly, that causes Gaussian elimination to be non-replicable. Our Corollary 4.3 makes progress on this question. First, we note that in our setting, we do not require knowledge of \(\). Second, one can design examples of (monotone) distributions for which our lifting framework produces a replicable polynomial time PAC learner but naive Gaussian elimination11 fails to be replicable with constant probability (cf. Theorem C.5). Note that even PAC learning parities for the distribution described in Theorem C.5 is SQ-hard. We believe that our lifting framework can be seen as a systematic way of bypassing some instabilities arising from the algebraic structure of standard Gaussian elimination.

As a final remark, we note that one could potentially design much more complicated (still monotone) distributions than the one of Theorem C.5, where even various adaptations of Gaussian elimination (e.g., pre-processing of the dataset, data deletion) would fail to be replicable but our lifting framework would guarantee replicability (and efficiency, provided small decision tree complexity). On the other hand, it is not evident whether parity learning remains SQ-hard under these "harder" distributions.

## 5 Efficient Replicability and Private Learning

In this section, we study connections between efficient DP learnability and efficient replicable learnability of a concept class. As we mentioned in the introduction, Bun et al. (2023) and subsequently Kalavasis et al. (2023) established a _statistical_ equivalence between approximate DP learnability and replicable learnability of a concept class when the domain is finite (Bun et al., 2023) or countable (Kalavasis et al., 2023). Moreover, Bun et al. (2023) showed that this equivalence does not hold when one takes into account the computational complexity of these tasks.

**Proposition 5.1** (Section 4.1 in Bun et al. (2023)).: _There exists a class that is efficiently PAC learnable by an approximate DP algorithm but, assuming one-way functions exist, it cannot be learned efficiently by a replicable algorithm._

We remark that there is an efficient converse transformation, i.e., a computationally efficient transformation from a replicable learner to an approximate DP learner (Bun et al., 2023). Inspired by Gonen et al. (2019), we ask whether one can transform a _pure_ DP learner to a replicable one. Our main result, proven in Appendix F, is the following.

**Theorem 5.2** (From Pure DP Learner to Replicable Learner).: _Let \(\) be some input domain, \(=\{0,1\}\), and \(_{}\) be a distribution on \(\) that is realizable with respect to some concept class \(\). Let \(\) be a pure DP learner that, for any \(,,(0,1)\), needs\((}{{}},}{{}}, (}{{}}),())\) _i.i.d. samples from \(_{XY}\) and \((m)\) running time to output a hypothesis that has error at most \(\), with probability \(1-\) in an \(\)-DP way. Then, for any \(^{},,^{}(0,1)\) there is a \(\)-replicable learner \(^{}\) that outputs a hypothesis with error at most \(^{}\) with probability at least \(1-^{}\) and requires \((}{{^{}}},}{{}}, (}{{^{}}}),())\) i.i.d. samples from \(_{XY}\) and \((}{{^{}}},}{{}}, (}{{^{}}}))(())\) running time._

In the above, we denote by \(()\) some dimension that describes the complexity of the concept class \(\) that arises in the sample complexity of our pure DP learner. A natural candidate is the _representation dimension_(Kasiviswanathan et al., 2011). As we alluded to before, this transformation is efficient with respect to the parameters \(,,\). On the other side, the sample complexity is polynomial in the representation dimension but the running time is exponential. We leave as an open question if it is possible to avoid this dependence.

We remark that in principle, one could use the reduction from Bun et al. (2023). The catch is that this reduction is based on correlated sampling so it requires i) the output space of the algorithm to be finite and ii) even under finite output spaces, it needs exponential time in the size of that space.

## 6 Conclusion

In this work, we have studied the computational aspects of replicability and several connections to other important notions in learning theory including online learning, SQ learning, and DP PAC learning. We believe that there are several interesting questions left open from our work. First, it would be interesting to see if there is a computationally efficient transformation from online learners to replicable learners. Then, it would be important to derive replicable learners from pure DP learners which are efficient with respect to the complexity of the underlying concept class. Regarding parities, it is still open whether we can design efficient replicable algorithms for _every_ distribution \(\).