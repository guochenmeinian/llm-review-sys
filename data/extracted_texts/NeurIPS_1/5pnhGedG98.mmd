# Scalable and Effective Arithmetic Tree Generation

for Adder and Multiplier Designs

 Yao Lai\({}^{1}\), Jinxin Liu\({}^{3}\), David Z. Pan\({}^{2}\), Ping Luo\({}^{1}\)

\({}^{1}\)The University of Hong Kong, \({}^{2}\)The University of Texas at Austin,

\({}^{3}\)Zhejiang University

###### Abstract

Across a wide range of hardware scenarios, the computational efficiency and physical size of the arithmetic units significantly influence the speed and footprint of the overall hardware system. Nevertheless, the effectiveness of prior arithmetic design techniques proves inadequate, as they do not sufficiently optimize speed and area, resulting in increased latency and larger module size. To boost computing performance, this work focuses on the two most common and fundamental arithmetic modules, adders and multipliers. We cast the design tasks as single-player tree generation games, leveraging reinforcement learning techniques to optimize their arithmetic tree structures. This tree generation formulation allows us to efficiently navigate the vast search space and discover superior arithmetic designs that improve computational efficiency and hardware size within just a few hours. Our proposed method, **ArithTreeRL**, achieves significant improvements for both adders and multipliers. For adders, our approach discovers designs of 128-bit adders that achieve Pareto optimality in theoretical metrics. Compared with PrefixRL, it reduces delay and size by up to 26% and 30%, respectively. For multipliers, compared to RL-MUL, our method enhances speed and reduces size by as much as 49% and 45%. Additionally, ArithTreeRL's flexibility and scalability enable seamless integration into 7nm technology. We believe our work will offer valuable insights into hardware design, further accelerating speed and reducing size through the refined search space and our tree generation methodologies. Codes are released at github.com/laiyao1/ArithmeticTree.

## 1 Introduction

Since the inception of computers, researchers have striven to boost computing speed and decrease hardware size. High computing speed is essential for a wide range of real-world applications, such as artificial intelligence , high-performance computing , and high-frequency trading , particularly for the recent applications of large language models like GPT . Concurrently, the demand for smaller hardware has escalated due to the growth of wearable devices and IoT technology .

Hardware specialists have steadily miniaturized CMOS technology  to boost processor speeds and shrink chip sizes. However, as CMOS technology's scaling nears its fundamental physical limits , further miniaturization poses significant challenges. Therefore, exploring innovative circuit design has emerged as a vital alternative to drive performance enhancement and area reduction. Among the family of arithmetic modules for hardware architectures, adders and multipliers constitute two essential modules, playing a critical role in various computational operations. For example, basic addition and multiplication operations compute all convolution and fully connected layersof deep learning models. Performance analysis of the ResNet model  reveals that the convolution operation, consisting solely of addition and multiplication, constitutes 98.4% of the overall GPU execution time during model inference. Under Amdahl's Law , an enhancement of 30% in addition and multiplication operation speeds could result in a 29% improvement in inference speed. Intriguingly, this improvement is comparable to the speedup typically seen with a generational upgrade in semiconductor process technology [10; 11]. Thus, designing more efficient and compact adders and multipliers is crucial for the overall advancement of hardware design.

Numerous arithmetic module design methods have been proposed in recent years. These techniques generally fall into one of three main categories: human-based [12; 13], optimization-based [14; 15; 16], and learning-based [17; 18; 19]. However, these methods either demand significant hardware expertise or get trapped in local optimal due to the vast design search space for adders and multipliers modules. For human-based methods, hardware experts have crafted a variety of arithmetic modules, such as the Sklansky adder  and the Wallace multiplier . Nevertheless, designing new structures becomes increasingly challenging for humans as input bits increase. Optimization-based methods, like bottom-up enumerate search [14; 15] and integer linear programming , can enhance the quality of arithmetic designs by exploring a wider variety of structures. Despite their potential, the extensive search space poses a challenge, necessitating manually defined assumptions to limit the search scope for feasible computation. For example, Ma et al.  assumed the existence of semi-regular structures in adders, which may lead to locally optimal solutions. While learning-based approaches have emerged as a promising tool for automating hardware design in recent years [17; 18; 19], navigating the vast design space to find the optimal solution for arithmetic modules remains a formidable challenge. For example, the two primary components of an \(N\)-bit multiplier, the compressor tree and the prefix tree, have approximately \(O(2^{N^{2}})\) and \(O(2^{4N^{2}})\) design space , respectively. Consequently, the search space of a simple 16-bit multiplier is already comparable to that of the Go game (\(3^{361}\)) . Meanwhile, such learning-based approaches also fail to consider the joint optimization of different components within arithmetic hardware [17; 18], thus easily leading to degenerated hardware with undesired performance bottleneck.

To resolve the above limitations and boost the performance, we formulate the arithmetic adder and multiplier design problems as two single-player tree generation games, AddGame and MultGame, respectively, as shown in Fig. 1a. The key insight is that by reframing the design problems into interactive tree generation games, we harness the power of progressive optimization algorithms, allowing us to explore the intricate design space of arithmetic units dynamically. Starting from an initial prefix tree, the player in AddGame sequentially modifies cells in the prefix tree, in the same spirit as tactical movements in board games. Our MultGame contains two parts, specifically for designing the compressor tree and the prefix tree of multipliers. The compressor tree design involves the player compressing all partial products with different compressors, similar to a match game. In contrast, the prefix tree design follows the same rules as the AddGame. Unlike the default design process depicted in Fig. 2a, the tree structures discovered in games are converted into specific Verilog codes , as illustrated in Fig. 2b. We demonstrate that the delay and area of arithmetic modules can be largely decreased by substituting the default designs with our discovered tree structures.

Figure 1: **(a) ArithTreeRL framework. Two agents optimize prefix and compressor trees, respectively, modeling the tasks as AddGame for adders and MultGame for multipliers. (b) Prefix tree. (c) Compressor tree. Different tree structures lead to different qualities of adder and multiplier designs.**

We propose **ArithTreeRL** (Arithmetic Tree Reinforcement Learning), a novel approach that utilizes customized reinforcement learning agents for optimizing arithmetic tree structures. In practical implementation, ArithTreeRL employs two distinct agents tailored to the specific characteristics of prefix and compressor tree optimization. For the prefix tree, appearing in both AddGame and MultGame, we utilize a Monte-Carlo Tree Search (MCTS)  agent to efficiently explore the large action space while preserving previous exploration experience. For the compressor tree, exclusive to MultGame, we take a Proximal Policy Optimization (PPO)  agent due to its superior exploration efficiency. To capture the global design for multiplier designs, we also designed an optimization curriculum as depicted in Fig. 1, iteratively running MCTS and PPO agents to refine the prefix and compressor trees.

This paper has three main **contributions**. Firstly, we model the arithmetic module design tasks as single-player tree generation games, _i.e.,_ AddGame and MultGame, which inherit the well-established RL capabilities for complex decision-making tasks (arithmetic tree optimization). Secondly, we propose a co-designed framework that integrates prefix and compressor tree modules, enabling the discovery of optimal combinations that lead to global optimal multipliers. Thirdly, our experiments reveal that our designed 128-bit Pareto-optimal adders outperform the latest theoretical designs. Also, our designed adders achieved up to 26% and 30% reductions in delay and area compared to PrefixRL , and multipliers offer 33% and 45% improvements over RL-MUL  in the same metrics. These designs are ready for direct integration into synthesis tools, offering significant industrial benefits, and are flexible and scalable enough to be seamlessly adopted into 7nm technology.

## 2 Preliminaries

**Adder Design.** An \(N\)-bit adder can be constructed by cascading \(N\)\(1\)-bit adders. However, this approach results in an \(O(N)\) delay due to the sequential propagation of the carry signal from the lower bit to the higher bit. To address this issue, prefix adders have been proposed [25; 26]. Prefix adders are designed based on the principles of addition, with a focus on reusing and parallelizing intermediate signal bits. These signal bits can be divided into two categories: propagation bits \(p_{i}=a_{i} b_{i}\) and generation bits \(g_{i}=a_{i} b_{i}\), where \(a_{i},b_{i}\{0,1\},i\{1,2,,N\}\) represent the addends at the \(i\)-th bit, and '\(\)' and '\(\)' denote the logic XOR and AND operations, respectively . These propagation and generation signals can be defined at both the individual bit level and across a range of bits. For an individual bit with index \(i\), they are denoted by \(P_{i:i}=p_{i}\) and \(G_{i:i}=g_{i}\). When considering a range of bits, this range is treated as an interval identified by a tuple \((i,j)\). Within each such interval, we have a single propagation signal \(P_{i:j}=_{k=i}^{j}p_{k}\) and a single generation signal \(G_{i:j}=g_{j}+_{k=i}^{j-1}P_{k:j} g_{k}\), where '\(+\)' represents the logic OR operation. Note that the computation of \(P_{i:j}\) and \(G_{i:j}\) is influenced solely by the input bits from position \(i\) to \(j\). The \((N+1)\) outputs of the adder can be calculated from the signal bits with the initial condition \(G_{1:0}=0\) by \(c_{N+1}=g_{N}+p_{N} G_{1:N}\) and \(s_{i}=p_{i} G_{1:i-1}\), where \(c_{N+1}\) is the carry-out bit and \(s_{i}\) is the \(i\)-th sum bit.

The prefix adder design aims to optimize a hierarchical tree structure that generates all intervals \((1,i)\) from the initial intervals \((i,i)\), as shown in Fig. 1b. Signal bits for two adjacent intervals, \((i,k)\) and

Figure 2: **Comparison of design processes.****(a) Default design process.** The synthesis tool automatically generates a default multiplier when using multiplication commands (x*y) in Verilog HDL code. **(b) Enhanced design process in ArithTreeRL.** ArithTreeRL discovers an optimized multiplier structure and generates specialized Verilog HDL code for this improved structure, reducing delay and area after synthesis.

\((k+1,j)\), can be merged to form the larger interval \((i,j)\) by the computations \(P_{i:j}=P_{i:k} P_{k+1:j}\) and \(G_{i:j}=G_{i:k} P_{k+1:j}+G_{k+1:j}\). This merging process generates a prefix tree where each cell represents an \((i,j)\) interval with two signal bits. If an interval results from merging two others, its corresponding cell is the child node in the tree, and the merged intervals are its parent node. For example, the \((5,8)\) cell is the child node of the \((5,6)\) and \((7,8)\) cells because it derived from them. A key advantage of this structure is that cells with no dependencies can be computed in parallel. Different tree structures can result in adders with varying delays and areas. When evaluating the theoretical quality of the prefix adder, We can use level (tree height) and size (number of cells) as theoretical metrics to substitute for practical metrics like delay and area.

**Multiplier Design.** An \(N\)-bit multiplier carries out the multiplication of two \(N\)-bit multiplicands, which can be regarded as the cumulative addition of \(N\) addends, involving a total of \(N^{2}\) bits. Each addend represents a partial product with different powers of two weights, illustrated in Fig. (b)b. Multipliers can be easily achieved by cascading (\(N-1\)) \(N\)-bit adders or using a single \(N\)-bit adder (\(N-1\)) times. However, both result in a large area or high delay. To mitigate this, the \(N^{2}\) bits in the partial products can be added simultaneously by \(1\)-bit adders, which can also be seen as a bit compression process because the number of bits gradually decreases. The compression process halts when the number of bits for each binary digit is reduced to two or fewer before feeding into a downstream adder, as illustrated in Fig. (c)c. The process generates a compressor tree, describing a compression mechanism that merges \(N^{2}\) bits into fewer bits by compressors such as half and full adders. Introducing an additional carry-in input distinguishes a full adder from a half adder, as shown in Fig. (b)b, which affects the latency and area. The difference is crucial when configuring the compressor tree in multipliers to optimize for delays and area requirements. Upon completing the compression, the remaining bits are processed by a \(2N\)-bit prefix adder, designed to yield the globally optimal multiplier. In summary, adder and multiplier design tasks can be interpreted as a tree-based structural generation process to optimize hardware metrics while maintaining functionality.

## 3 Our Approach

We use reinforcement learning to solve the tree generation for adder and multiplier designs. The environments are modeled as single-player tree generation games: AddGame for adder design and MultGame for multipliers, as illustrated in Fig. (a)a. Considering differences among the games, such as action space, we propose two types of agents: one by MCTS  and another by PPO .

### AddGame

AddGame is modeled for designing prefix trees in adders and multipliers, as shown in Fig. 3. In this game, the player modifies the structures of given initial prefix trees by basic actions to optimize the adders' metrics. The state of the game is denoted as \(s\), corresponding to the current prefix tree. In our evaluation, each state \(s\) is assessed on two theoretical metrics, level and size, and two practical metrics, delay and area. The player always chooses one action from two kinds of actions: (1) delete a cell \((i,j)\), (2) add a cell \((i,j)\), which \((i,j)\) is the cell index as shown in Fig. (b)b. A cell \((i,j)\)\((i<j)\) can be deleted if the prefix tree does not have the cell \((i,k)\) subject to \(k>j\) and \(i>1\), and all deletable cells are marked in red in Fig. 3 and 5. A cell \((i,j)\) can be added if it does not exist in the prefix tree. All positions where cells can be added are marked with '\(\)'. A legalization operation  is always executed after one action to guarantee the feasibility of the prefix tree as Fig. 3. The game aims to maximize the performance score \(R(s)\) of the adder \(s\). This score is determined by a weighted combination of delay and area (using level and size when optimizing theoretical metrics).

Given the large action space, the agent for playing AddGame is based on an improved MCTS method, which has demonstrated its effectiveness in numerous game tasks [21; 29; 30]. Starting from the prefix trees in human-designed adders, the MCTS agent continuously cycles through four phases: _selection_, _expansion_, _simulation_, and _backpropagation_, and gradually builds a search tree in this process. Each node in the search tree represents one prefix tree.

In the _selection_ phase, the agent selects the child node with state \(s\) that has the highest score \(W(s)\), continuing until it encounters a node that has not been fully expanded. The scores for evaluating nodes are computed by the Upper Confidence bounds applied to Trees (UCT) , keeping the balance between exploration and exploitation. In the search tree, each node with the state \(s\) stores a visit count \(N(s)\) and an action value \(V(s)\). The visit count \(N(s)\) records the number of visits to the node \(s\). The action value \(V(s)\) is the weighted sum of the best performance score \( R\) and average performance score \(\) of all its descendant nodes, which can be formalized as:

\[V(s)=(1-) D(s)}R(s^{})/|D(s)|}_{ {avg performance score}}+ D(s)}R(s^{})}_{ } \]

where \(D(s)\) represents all descendant nodes of the node \(s\) (including \(s\) itself), _i.e.,_ all generated adders by a sequence of actions from adder \(s\). \(||\) gives the number of nodes. \(R(s^{})\) indicates the performance score of the adder of the state \(s^{}\), which is defined as \(-\)Delay \(-\)Area or \(-\)Size. \(\) and \(\) are sum weights.

We define the node score \(W(s)\) with the state \(s\) as follows:

\[W(s)=N(P(s))}{N(s)}}+cV(s) \]

where \(P(s)\) is the parent node of \(s\), \(N()\) is visit count function, and \(c\) is an adjustable parameter.

In the _expansion_ phase, a random action is chosen from the unexplored actions available at the node identified in the selection phase and executed. It expands the search tree by adding a new node corresponding to the result after that action. In the _simulation_ phase, a sequence of actions is taken until the performance scores of adders can no longer be improved (in theoretical metrics optimization) or the simulation exceeds the maximum steps (in practical metrics optimization). In the _backpropagation_ phase, the last state \(s\) reached in the simulation phase is evaluated to get a performance score \(R(s)\), which is then backpropagated to update the scores of all preceding nodes in the search tree.

**Pruning.** To enhance efficiency, we implement pruning techniques to avoid the exploration of unnecessary sub-trees. When optimizing theoretical metrics, we restrict modifications to delete cell actions, as adding cells does not improve the design outcome. Furthermore, we impose an upper limit on the level metric to prevent the creation of structures with excessively high complexity. This upper limit, denoted as \(L\), is set for each MCTS search and is gradually relaxed with each search iteration.

**Two-level Retrieval.** We adopt a two-level retrieval strategy to balance synthesis accuracy and computational efficiency. We divide the search into two stages because the full synthesis flow is highly accurate but time-consuming. A faster yet marginally less simulating accurate synthesis flow is employed in the first stage, eliminating the time-intensive steps such as routing. Only the top \(K\) adders identified in the first stage undergo full synthesis in the second stage.

### MultGame

MultGame consists of two parts for jointly designing compressor and prefix trees in multipliers, as shown in Fig. 1. The part focused on the prefix tree design is identical to that in AddGame. Meanwhile, the part focused on the compressor tree design involves continually merging bits in partial products through compression actions, as depicted in Fig. 4. This process is similar to some match games like '2048' , where items are merged in a specific way to achieve high scores.

The compressor tree is built from scratch instead of starting from existing solutions for more design flexibility. The game state \(s_{t}\) at step \(t\) is represented by a vector representing the current compressor tree status. The player chooses one of two actions: (1) using a half adder or (2) using a full adder to

Figure 3: **Method for designing prefix trees with MCTS.** Four phases in the search process are executed iteratively, gradually building a search tree.

compress bits at the action digit, which is defined as the lowest digit containing more than two bits, as indicated in Fig. 4a. Half and full adders compress two or three bits in the \(k\)-th digit and generate a carry-out bit in the (\(k+1\))-th digit and a sum bit in the \(k\)-th digit. Rough delays for all bits are estimated, assuming a one-unit delay for all basic logic gates, as shown in the dots of Fig. 4a. To minimize the increase in total delay, the bits with the lowest estimated delays are selected as inputs for the adders. The game terminates at step \(T\) when all digits have two or fewer bits. A reward \(r_{T}\) is computed through the synthesis tools as the negative of the delay, denoted \(r_{T}=-\)delay. Moreover, a penalty term \(-p\) is also applied to \(r_{t}\) if the action \(a_{t-1}\) uses a half adder, where \(1 t T\). This penalty reflects that a full adder accepts three input bits (two addend bits and a carry-in bit) and produces two output bits (a sum bit and a carry-out bit), effectively reducing the bit count. In contrast, a half adder only processes two addend bits and outputs two bits, thus not contributing to a reduction in bit count. A half adder's lack of bit count reduction can lead to more adder modules, increasing the overall module area.

We train an RL agent with policy and value networks using the PPO method. Both networks are built by multi-layer perceptions (MLPs)  with three layers. The inputs comprise pre-defined features as Table 1, including action digit, max delay, number of half adders, eligible action type, and the estimated delays of bits. The policy and value networks contain \((64,16,2)\) and \((64,8,1)\) neurons in each layer. The last layer of the policy network is connected to a Softmax activation function  for choosing actions.

When training, the objective function can be defined as follows for maximizing the game's cumulative reward:

\[J()=_{_{}}G_{T}\ =_{_{}}_{i=0}^{T}^{i}r_{t} \]

  
**Feature** & **Size** & **Description** \\  Action digit & 1 & Digit for action. \\ Max delay & 1 & Maximum estimated delay value of all bits. \\ Number of half adders & 1 & Number of added half adders in action digit. \\ Mask for action & 2 & The mask for ensuring valid action. \\ Delay of action bits & 3 & The delays of bits for action. \\   

Table 1: **State features for policy and value network.**

Figure 4: **Designing compressor trees with PPO.** Three representations are illustrated. **(a) Dot notation.** Each dot represents an output bit, with the number inside indicating the estimated delay for selecting adder input bits. The agent’s actions involve adding full or half adders to compress the bits until each binary digit contains no more than two bits. The final reward, \(r_{T}\), is defined as the inverse of the delay, encouraging designs with lower delays. **(b) Binary bit notation.** 0/1 are values of bits for the example multiplication. **(c) Logic gate notation.** The actual logic gate circuit design for each state.

where \(=(s_{0},a_{0},s_{1},r_{1},a_{1},...,a_{T-1},s_{T},r_{T})\) is a trajectory from the game episode, and \(_{}\) denotes the policy parameterized by \(\). \(G_{T}\) refers to the cumulative discounted reward from step 0 to step \(T\). The discount factor \(\) adjusts the emphasis between immediate and future rewards. When implementing the PPO, the objective function for optimizing the policy network can be formalized as:

\[L()=}_{t}r_{t}()_{t},\; (r_{t}(),1-,1+)_{t} \]

where \(}_{t}[]\) indicates the empirical average over a finite batch of samples, and \(r_{t}()\) denotes the probability ratio \((a_{t}|s_{a})}{_{_{}}(a_{t}|s_{t})}\). Here, \(_{}\) is the policy network parameters before the update. \(_{t}=G_{t}-_{t}\) is an estimation of the advantage function at step \(t\), and \(_{t}\) is the value estimated by the value network. \((,1-,1+)\) is the function restricting results to the interval \([1-,1+]\).

Simultaneously, the value network with parameters \(\) is updated by optimizing the following objective function \(L()=}_{t}(G_{t},_{t})\), where smooth\(\_()\) is the smooth L1 loss function .

**Synthesis Acceleration.** In RL-MUL , running synthesis tools proved to be a bottleneck, especially for scaling to multipliers with higher bit-widths. To address this, our enhancements to the synthesis flow yield a 10x speedup in reward computation without sacrificing accuracy. These modifications facilitate the design of multipliers up to \(64\)-bit, expanding from the \(16\)-bit limit in RL-MUL. Enhancements include activating the fast mode in the logical synthesis script and adopting direct code template-based generation of Verilog HDL code from our search results, moving away from the time-consuming EasyMAC  tool.

**Co-design Framework.** As shown in Fig. 1, we developed a joint design approach to optimize the multiplier's two primary components: the prefix and compressor trees. Our method involves an iterative process where each round involves optimizing the compressor tree with a fixed prefix tree and searching for an ideal prefix tree that aligns with the optimized compressor. This alternating optimization continues until the computational iterations conclude.

## 4 Experiments

We use the logic synthesis tool Yosys 0.27  and the physical synthesis tool OpenROAD 2.0  with Nangate45  and ASAP7  libraries to implement experiments. Both synthesis tools are open-sourced for result reproduction. All experiments are run on one GeForce RTX 3090 GPU and one AMD Ryzen 9 5950X 16-core CPU. Detailed settings are in Appendix A.3 and A.5. All designed modules have successfully undergone functional verification.

### Adder Design

**Theoretical Evaluation.** As illustrated in Fig. 0(b), prefix tree structures define the technology-independent theoretical metrics of level and size. Empirically, optimizing the level usually presents more challenges than size. Therefore, we set the search objective when optimizing theoretical metrics to find the optimal size for each specified upper bound level \(L\). We begin our search with the Sklansky adder , which has a theoretical minimum level of \(_{2}N\). Starting with \(L\) set at this minimum, we incrementally increase it for each new iteration, using the smallest prefix tree identified in the previous round as the initial state. We limited the number of steps to \(4 10^{5}\) for each search iteration. For baselines, the results were obtained directly from the respective original publications. Table 2 shows that our method surpasses the state-of-the-art designs in . Some discovered adder structures are presented in Fig. 5. Despite the exponentially growing search space, our MCTS method can enhance 128-bit adders, surpassing the designs from optimization-based methods. Notably, guided by Snir's theoretical lower bound for size at a given level , we were the first to discover an optimal 128-bit adder with 10 levels and a size of 244.

**Practical Evaluation.** Practical metrics, including the delay and area of hardware modules, are computed through synthesis tools for evaluation. We run \(1000\) full syntheses for adders in each method to ensure a fair comparison. Our ArithTreeRL method begins each search from one of three adders: Sklansky , Brent-Kung , and ripple-carry . A two-level retrieval strategy is implemented by dividing the search into two stages: (1) 5000 fast syntheses. (2) 500 full syntheses with the top 500 adders selected from the first stage. Efficiency tests show that one full flow's computational load equals 10 fast flows. Thus, the proposed strategy achieves the same computational volume with 1000 full flows. The state-of-the-art method PrefixRL  is implemented with optimal settings. In our results in Fig. 6, each prefix adder is represented by a 2D point based on its delay and area. It shows the significant improvement achieved when our two-level retrieval strategy is used in the PrefixRL method due to efficiency improvements that facilitate exploring an expanded sample corpus. Moreover, employing the MCTS method can lead to the discovery of more superior adders because this method effectively navigates through problems with vast state spaces, utilizing information stored during the search process. Overall, our approach can reduce the delay or area of adders by up to 26% and 30%, respectively, compared with PrefixRL, while maintaining the computational amount.

**Visualization.** The scores of the first actions after 400 search steps when optimizing the theoretical metrics are visualized as heatmaps in Fig. 7. In the selection phase, the action with the highest score is chosen. For example, the first action for the 8-bit adder is to delete the \((5,7)\) cell with the highest score because this reduces the size of the adder. On the contrary, the action with the lowest score is to add the \((4,7)\) cell because it augments both size and level.

  
**Input Bit** & **Level** & **Theory Size Bound** & **Sklassy Size** & **Area Heuristic** & **Best Known Size** & **ArithTreeRL** \\ 
64 & 6 & 120 & 192 & 169 & **167** & **167** \\
64 & 7 & 119 & - & 138 & **126** & **126** \\
64 & 8 & 118 & - & 120 & **118** & **118** \\
64 & 9 & 117 & - & **117** & **117** & **117** \\
64 & 10 & 116 & - & **116** & **116** & **116** \\ 
128 & 7 & 247 & 448 & 375 & **364** & **364** \\
128 & 8 & 246 & - & 304 & 276 & **273** \\
128 & 9 & 245 & - & 284 & 250 & **248** \\
128 & 10 & 244 & - & 257 & 245 & **244** \\   

Table 2: **Comparisons of discovered adders in size and area.** Smaller sizes are preferable.

Figure 5: **Some first discovered prefix trees for 128-bit adders with the smallest sizes.**

Figure 6: **Comparison of adders in delay and area.** Each point represents one adder and line segments connect Pareto-optimal adders. ‘PrefixRL (2-level retr.)’ is the raw PrefixRL method improved by our two-level retrieval strategy. Sklassky, Brent-Kung, and Kogge-Stone refer to human-designed adders. ArithTreeRL can significantly improve the delay and area, particularly for high-bit adders. Furthermore, it can discover adders with minimal delays. Our two-level retrieval strategy can effectively find superior designs.

**Accuracy of Fast Flow.** The time-consuming routing phase is removed in the fast flow of the two-level strategy. To evaluate the impact of this simplification, we tested the simulation accuracy of the fast flow against the full flow. The results in Table 3 indicate that the fast flow can still achieve an utterly accurate area estimation and over 95% accurate delay. Therefore, the fast synthesis flow can help improve efficiency without significantly losing accuracy.

### Multiplier Design

**Practical Evaluation.** Given the lack of a commonly adopted theoretical metric for multipliers, we use practical metrics for evaluation. Our multiplier design utilizes a co-design framework with three iterative search rounds, incorporating 900 steps for the compressor tree and 100 for the prefix tree each round. This yields 3000 steps, consistent with the search steps of other baseline methods in our experiments. As shown in Fig. 8 and Appendix Fig. 14, we compared the effectiveness of our method with several baselines, including the human-designed Wallace multiplier , optimization-based methods including GOML  and SA , the default multiplier given in the synthesis tool, and the learning-based method RL-MUL . In our evaluation, we assessed the multipliers' performance by adjusting the expected delay parameter in the synthesis process. Subsequently, the resulting areas of each multiplier at different delays are depicted as a segmented line. Consistent with the RL-MUL  assessment approach, each method selects an optimal multiplier for comparison. Results for Wallace , GOML , SA , and RL-MUL  in 8/16 bits are referenced from the RL-MUL work. RL-MUL method is reproduced and tested in 32/64 bits. The results show that the co-design method, ArithTreeRL, outperforms the synthesis tool's baselines and default multipliers. This is because of the co-design framework, the restructured MultGame, and the improved synthesis flow. It can achieve second-best results even when only optimizing the compressor tree. Compared with the state-of-the-art RL-MUL method, our method can reduce the delay by up to 33% and the area by 45%. Furthermore, our method can reduce the delay of the default multipliers used in the Yosys tool  by up to 16% and the area by 35%. We also report the delays and areas in Table 4. Our method consistently achieves minimal delays for the delay minimization. When optimizing for a trade-off (delay \(+\) 0.001area), our approach achieves optimal or comparable results. Also, The multipliers designed by 45nm technology are compatible with the 7nm  without any modifications.

**Efficiency.** Due to the time-consuming nature of the full synthesis flow, we developed a synthesis flow that is over 10x faster while maintaining high simulation accuracy for adder design, as discussed in the method. The efficiency is shown in Fig. 9a. Additionally, we optimized the logic synthesis and HDL code generation processes in the synthesis flow for multiplier design. According to Fig. 9b, our improved fast flow can accelerate the process up to 20x.

## 5 Conclusion

Designing adder and multiplier modules is a fundamental and crucial task in computer science. We first model this task as a tree-generation process, conceptualizing it as a sequential decision-making

   Bits of adders & 32 & 64 & 128 \\  Delay Acc. (\%) & 96.11\(\)0.86 & 95.82\(\)1.12 & 95.34\(\)2.60 \\ Area Acc. (\%) & 100.00\(\)0.00 & 100.00\(\)0.00 & 100.00\(\)0.00 \\   

Table 3: **Accuracy of fast synthesis flow.**

Figure 7: **Heatmap for first action scores.** The actions with the highest and lowest scores are marked.

game. Then, we propose a reinforcement learning method to solve it, facilitating a scalable and efficient search for globally optimal designs. Through extensive experiments, our approach achieves state-of-the-art performance for adders and multipliers in terms of delay and area within the same computational resources. Moreover, our method has demonstrated transferability, as the designs we discovered can be applied to more advanced technology processes. This enhancement in basic arithmetic modules optimizes hardware performance and size, showing significant potential for boosting computationally intensive fields.

**Limitations.** This paper focuses exclusively on designing and optimizing adder and multiplier modules, which are fundamental components in computational systems. It does not explore other basic elements, such as exponentiation or more complex arithmetic units. However, our method is naturally extendable to other arithmetic operations, such as exponentiation. Future research could explore these extensions to unlock further designs across various hardware components.

   &  &  &  &  &  \\  Objective & Method & area & delay & area & delay & area & delay & area & delay \\   & RL-MUL & 496 & 0.7089 & 2271 & 1.1330 & 8767 & 2.0150 & 34810 & 2.6771 \\  & PPO w/ raw flow & 496 & 0.6921 & 2259 & 1.1277 & 8788 & 1.9437 & 34810 & 2.6355 \\  & Default & 555 & 0.6203 & 2499 & 0.8908 & 10657 & 1.0745 & 42128 & 1.3498 \\  & PPO & 692 & 0.5180 & 2551 & 0.7932 & 11329 & 0.9960 & 42377 & 1.2424 \\  & ArtifTreeRL & 714 & **0.4905** & 2955 & **0.7138** & 11460 & **0.9685** & 39436 & **1.2401** \\   & RL-MUL & 388 & 0.7691 & 1695 & 1.2668 & 7033 & 2.1932 & 28616 & 2.8891 \\  & PPO w/ raw flow & 388 & 0.7618 & 1687 & 1.2268 & 7036 & 2.0945 & 28669 & 2.8928 \\  & Default & **367** & 0.6837 & 1590 & 0.9997 & 6685 & 1.4170 & 26871 & 1.9403 \\  & PPO & 377 & 0.6558 & 1568 & 1.0135 & 6581 & 1.3856 & 26088 & 1.7941 \\  & ArtifTreeRL & 384 & **0.6420** & **1566** & **0.9487** & **6469** & **1.3262** & **26087** & **1.7038** \\  

Table 4: **Numerical comparison of multipliers in delay (ns) and area (\(^{2}\)), (45nm)**

Figure 8: **Comparison of multipliers. The designs were tested in 45nm and 7nm. Each segmented line represents the performance of one multiplier under different timing constraints. ‘Method (our flow)’ are methods with our improved flow. The ‘Default’ multipliers are those generated by the synthesis tool by default. ‘ArithTreeRL’ is our co-design method combining PPO and MCTS, while ‘PPO (our)’ optimizes only the compressor tree. We apply 45nm designs to the 7nm library without modifications, showcasing the transferability.**

Figure 9: **Design flow time consumption. (average of 1000 runs)**