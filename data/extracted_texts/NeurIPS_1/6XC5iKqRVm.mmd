# DELTA: Diverse Client Sampling for Fasting Federated Learning

Lin Wang\({}^{1,2}\), Yongxin Guo\({}^{1,2}\), Tao Lin\({}^{4,5}\), Xiaoying Tang\({}^{1,2,3}\)

\({}^{1}\)School of Science and Engineering, The Chinese University of Hong Kong (Shenzhen)

\({}^{2}\)The Shenzhen Institute of Artificial Intelligence and Robotics for Society

\({}^{3}\)The Guangdong Provincial Key Laboratory of Future Networks of Intelligence

\({}^{4}\)Research Center for Industries of the Future, Westlake University

\({}^{5}\)School of Engineering, Westlake University.

Corresponding author.

###### Abstract

Partial client participation has been widely adopted in Federated Learning (FL) to reduce the communication burden efficiently. However, an inadequate client sampling scheme can lead to the selection of unrepresentative subsets, resulting in significant variance in model updates and slowed convergence. Existing sampling methods are either biased or can be further optimized for faster convergence. In this paper, we present DELTA, an unbiased sampling scheme designed to alleviate these issues. DELTA characterizes the effects of client diversity and local variance, and samples representative clients with valuable information for global model updates. In addition, DELTA is a proven optimal unbiased sampling scheme that minimizes variance caused by partial client participation and outperforms other unbiased sampling schemes in terms of convergence. Furthermore, to address full-client gradient dependence, we provide a practical version of DELTA depending on the available clients' information, and also analyze its convergence. Our results are validated through experiments on both synthetic and real-world datasets.

## 1 Introduction

Federated Learning (FL) is a distributed learning paradigm that allows a group of clients to collaborate with a central server to train a model. Edge clients can perform local updates without sharing their data, which helps to protect their privacy. However, communication can be a bottleneck in FL, as edge devices often have limited bandwidth and connection availability . To reduce the communication burden, only a subset of clients are typically selected for training. However, an improper client sampling strategy, such as uniform client sampling used in FedAvg , can worsen the effects of data heterogeneity in FL. This is because the randomly selected unrepresentative subsets can increase the variance introduced by client sampling and slow down convergence.

Existing sampling strategies can be broadly classified into two categories: biased and unbiased. Unbiased sampling is important because it can preserve the optimization objective. However, only a few unbiased sampling strategies have been proposed in FL, such as multinomial distribution (MD) sampling and cluster sampling. Specifically, cluster sampling can include clustering based on sample size and clustering based on similarity. Unfortunately, these sampling methods often suffer from slow convergence, large variance, and computation overhead issues .

To accelerate the convergence of FL with partial client participation, Importance Sampling (IS), an unbiased sampling strategy, has been proposed in recent literature . IS selects clients with a large gradient norm, as shown in Figure 1. Another sampling method shown in Figure 1 iscluster-based IS, which first clusters clients according to the gradient norm and then uses IS to select clients with a large gradient norm within each cluster.

Though IS and cluster-based IS have their advantages, **1) IS could be inefficient because it can result in the transfer of excessive similar updates from the clients to the server.** This problem has been pointed out in recent works [52; 63], and efforts are being made to address it. One approach is to use cluster-based IS, which groups similar clients together. This can help, but **2) cluster-based IS has its drawbacks in terms of convergence speed and clustering effect**. Figure 2 illustrates that both of these sampling methods can perform poorly at times. Specifically, compared with cluster-based IS, IS cannot fully utilize the diversity of gradients, leading to redundant sampling and a lack of substantial improvement in accuracy [52; 2]. While the inclusion of clients from small gradient groups in cluster-based IS leads to slow convergence as it approaches convergence, as shown by experimental results in Figure 6 and 7 in Appendix B.2. Furthermore, the clustering algorithm's performance tends to vary when applied to different client sets with varying parameter configurations, such as different numbers of clusters, as observed in prior works [52; 51; 56].

To address the limitations of IS and cluster-based IS, namely excessive similar updates and poor convergence performance, we propose a novel sampling method for Federated Learning termed **DivErse cLienT sAmpling** (DELTA). Compared to IS and cluster-based IS methods, DELTA tends to select clients with diverse gradients, as shown in Figure 1. This allows DELTA to utilize the advantages of a large gradient norm for convergence acceleration while also overcoming the issue of gradient similarity.

Additionally, we propose practical algorithms for DELTA and IS that rely on accessible information from partial clients, addressing the limitations of existing analysis based on full client gradients [35; 5]. We also provide convergence rates for these algorithms. We replace uniform client sampling with DELTA in FedAvg, referred to as **FedDELTA**, and replace uniform client sampling with IS in FedAvg, referred to as **FedIS**. Their practical versions are denoted as **FedPracDELTA** and **FedPracIS**.

Toy Example and Motivation.We present a toy example to illustrate our motivation, where each client has a regression model. The detailed settings of each model and the calculation of each sampling algorithm's gradient are provided in Appendix B.1. Figure 3 shows that IS deviates from the ideal global model when aggregating gradients from clients with large norms. This motivates us to consider the correlation between local and global gradients in addition to gradient norms when sampling clients. _Compared to IS, DELTA selects clients with large gradient diversities, which exploits the clients' information of both gradient norms and directions, resulting in a closer alignment to the ideal global model._

Our contributions.In this paper, we propose an efficient unbiased sampling scheme in the sense that (i) It effectively addresses the issue of excessive similar gradients without the need for additional clustering, while taking advantage of the accelerated convergence of gradient-norm-based IS and (ii) it is provable better than uniform sampling or gradient norm-based sampling. The sampling scheme is versatile and can be easily integrated with other optimization techniques, such as momentum, to improve convergence further.

As our key contributions,

Figure 1: **Client selection illustration of different methods. IS (left) selects high-gradient clients but faces redundant sampling issues. Cluster-based IS (mid) addresses redundancy, but using small gradients for updating continuously can slow down convergence. In contrast, DELTA (right) selects diverse clients with significant gradients without clustering operations.**

Figure 2: **Comparison of the convergence performance for different sampling methods. In this example, we use a logistic regression model on non-iid MNIST data and sample 10 out of 200 clients. We run 500 communication rounds and report the average of the best 10 accuracies at 100, 300, and 500 rounds. This shows the accuracy performance from the initial training state to convergence.**

* We present DELTA, an unbiased FL sampling scheme based on gradient diversity and local variance. Our refined analysis shows that FedDELTA surpasses the state-of-the-art FedAvg in convergence rate by eliminating the \((}{{T^{2/3}}})\) term and a \(_{G}^{2}\)-related term of \((}{{T^{1/2}}})\).
* We present a novel theoretical analysis of nonconvex FedIS, which yields a superior convergence rate compared to existing works while relying on a more lenient assumption. Moreover, our analysis eliminates the \((}{{T^{2/3}}})\) term of the convergence rate, in contrast to FedAvg.
* We present a practical algorithm for DELTA in partial participation settings, utilizing available information to mitigate the reliance on full gradients. We prove that the convergence rates of these practical algorithms can attain the same order as the theoretical optimal sampling probabilities for DELTA and IS.

## 2 Related Work

Client sampling in federated learning (FL) can be categorized into unbiased and biased methods . Unbiased methods, including multinomial sampling and importance sampling [30; 5; 49], ensure that the expected client aggregation is equivalent to the deterministic global aggregation when all clients participate. Unlike unbiased sampling, which has received comparatively little attention, biased sampling has been extensively examined in the context of federated learning, such as selecting clients with higher loss  or larger updates . Recently, cluster-based client selection, which involves grouping clients into clusters and sampling from these clusters, has been proposed to sample diverse clients and reduce variance [41; 12; 52]. Nevertheless,the clustering will require extra communication and computational resources. The proposed DELTA algorithm can be seen as a muted version of a diverse client clustering algorithm without clustering operation.

While recent works [57; 28] have achieved comparable convergence rates to ours using variance reduction techniques, it is worth noting that these techniques are orthogonal to ours and can be easily integrated with our approach. Although  achieved the same convergence rate as ours, but their method requires dependent sampling and mixing participation conditions, which can lead to security problems and exceed the communication capacity of the server. In contrast, our method avoids these issues by not relying on such conditions.

A more comprehensive discussion of the related work can be found in Appendix A.

## 3 Theoretical Analysis and An Improved FL Sampling Strategy

This section presents FL preliminaries and analyzes sampling algorithms, including the convergence rate of nonconvex FedIS in Section 3.2, improved convergence analysis for FL sampling in Section 3.3, and proposal and convergence rate of the DELTA sampling algorithm in Section 3.4.

In FL, the objective of the global model is a sum-structured optimization problem:

\[f^{*}=_{x^{d}}[f(x)_{i=1}^{m}w_{i}F_{i}(x) ]\,, \]

where \(F_{i}(x)=_{_{i} D_{i}}[F_{i}(x,_{i})]\) represents the local objective function of client \(i\) over data distribution \(D_{i}\), and \(_{i}\) means the sampled data of client \(i\). \(m\) is the total number of clients and \(w_{i}\) represents the weight of client \(i\). With partial client participation, FedAvg randomly selects \(|S_{t}|=n\) clients (\(n m\)) to communicate and update model. Then the loss function of actual participating users in each round can be expressed as:

\[f_{S_{t}}(x_{t})=_{i S_{t}}F_{i}(x_{t})\,. \]

Figure 3: **Model update comparison: The closer to the ideal global update (black arrow), the better the sampling algorithm is. The small window shows the projection of 3 clients’ functions \(F_{1},F_{2},F_{3}\) in the X-Y plane, where \( F_{1}=(2,2), F_{2}=(4,1), F_{3}=(6,-3)\) at \((1,1)\). The enlarged image shows the aggregated gradients of FedAvg, IS, DELTA and ideal global gradient. Each algorithm samples two out of three clients: FedIS tends to select Client 2 and 3 with largest gradient norms, DELTA tends to select Client 1 and 3 with the largest gradient diversity and FedAvg is more likely to select Client 1 and 2 compared to IS and DELTA. The complete gradient illustration with clients’ gradient is shown in Figure 5 in Appendix.**

For ease of theoretical analysis, we make the following commonly used assumptions:

**Assumption 1** (L-Smooth).: _There exists a constant \(L>0\), such that \(\| F_{i}(x)- F_{i}(y)\| L\|x-y\|, x, y^{d}\), and \(i=1,2,,m\)._

**Assumption 2** (Unbiased Local Gradient Estimator and Local Variance).: _Let \(_{t}^{i}\) be a random local data sample in the round \(t\) at client \(i\): \([ F_{i}(x_{t},_{t}^{i})]= F_{i}(x_{t}),  i[m]\). The function \(F_{i}(x_{t},_{t}^{i})\) has a bounded local variance of \(_{L,i}>0\), satisfying \([\| F_{i}(x_{t},_{t}^{i})- F_{i}(x_{t}) \|^{2}]=_{L,i}^{2}_{L}^{2}\)._

**Assumption 3** (Bound Dissimilarity).: _There exists constants \(_{G} 0\) and \(A 0\) such that \(\| F_{i}(x)\|^{2}(A^{2}+1)\| f(x)\|^{2}+_{G}^{2}\). When all local loss functions are identical, \(A^{2}=0\) and \(_{G}^{2}=0\)._

The above assumptions are commonly used in both non-convex optimization and FL literature, see e.g. [21; 27; 60].

We notice that Assumption 3 can be further relaxed by Assumption 2 of . We also provide Proposition C.4 in Appendix C to show all our convergence analysis, including Theorem 3.1,3.5 and Corollary 4.1,4.2 can be easily extended to the relaxed assumption while keeping the order of convergence rate unchanged.

### Convergence Analysis of FedIS

As discussed in the introduction, IS faces an excessive gradient similarity problem, necessitating the development of a novel diversity sampling method. Prior to delving into the specifics of our new sampling strategy, we first present the convergence rate of FL under standard IS analysis in this section; this analysis itself is not well explored, particularly in the nonconvex setting. The complete FedIS algorithm is provided in Algorithm 2 of Appendix D, which differs from DELTA only in sampling probability (line 2) by using \(p_{i}\|_{k=0}^{K-1}g_{t,k}^{i}\|\).

**Theorem 3.1** (Convergence rate of FedIS).: _Let constant local and global learning rates \(_{L}\) and \(\) be chosen as such that \(_{L}<min(1/(8LK),C)\), where \(C\) is obtained from the condition that \(-10L^{2}K^{2}(A^{2}+1)_{L}^{2}-_{K}(A^{2}+1)}{2 }_{L}>0\),and \( 1/(_{L}L)\). In particular, suppose \(_{L}=(KL})\) and \(=()\), under Assumptions 1-3, the expected gradient norm of FedIS algorithm 2 will be bounded as follows:_

\[_{t[T]}\| f(x_{t})\|^{2}(-f^{*}}{})+( ^{2}+K_{G}^{2}}{})+(}{T} )}_{}+(}{T}). \]

   Algorithm & Convexity & Partial Worker & Unbiasedness & Convergence rate & Assumption \\  SGD & S/N & ✓ & ✓ & \(^{2}}{_{L,i}^{2}}+^{2}}{_{L,i}^{2}} +}\) & \(_{L,i}\) bound \\ 
**FedDE1TA** & N & ✓ & ✓ & \(^{2}+_{G}^{2}}{_{G}^{2}}+^{2}}\) & Assumption 3 \\
**FedPre-DELTA** & N & ✓ & ✓ & \(^{2}+_{G}^{2}}{_{G}^{2}}+^{2}}\) & Assumption 3 and Assumption 4 \\ 
**FedIS** (ours) & N & ✓ & ✓ & \(^{2}+_{G}^{2}}{_{G}^{2}}+^{2}}\) & Assumption 3 \\ FedIS (others)  & N & ✓ & ✓ & \(^{2}+_{G}^{2}+_{G}^{2}}{_{G}^{2}+_{G}^ {2}}+^{2}}\) & Assumption 3 and \(\) Assumption \\
**FedPostS** (ours) & N & ✓ & ✓ & \(^{2}+_{G}^{2}+_{G}^{2}}{_{G}^{2}+_{G}^ {2}}+^{2}}\) & \(G\) bound \\ 
**FedAvg** & N & ✓ & ✓ & \(^{2}+_{G}^{2}+_{G}^{2}}{_{G}^{2}+_{G}^ {2}}+^{2}+_{G}^{2}}\) & Assumption 3 and Assumption 4 \\  FedAvg  & N & ✓ & ✓ & \(^{2}+_{G}^{2}+_{G}^{2}}{_{G}^{2}+_{G}^ {2}}\) & \(G\) bound \\ DuFL  & S & ✓ & ✓ & \(^{2}+_{G}^{2}}{_{G}^{2}+_{G}^{2}}+^{2}}\) & Assumption 3 \\ Power-of-Choice  & S & ✓ & \(\) & \(^{2}+_{G}^{2}}{_{G}^{2}+_{G}^{2}}\) & Heterogeneity Gap \\ FedAvg  & N & \(\) & ✓ & \(^{2}}{_{G}^{2}+_{G}^{2}(_{G}^{2})}\) & \(_{G}\) bound \\ Arbitrary Sampling & N & & \(^{2}+_{G}^{2}}{_{G}^{2}+_{G}^{2}}+^{2}}\) & Assumption 3 \\   

* \(M^{2}=_{L}^{2}+4K_{G}\), \(}{_{G}^{2}+_{G}^{2}}\), \(}{_{G}^{2}+_{G}^{2}}+4K_{G}^{2}\), \(}{_{G}^{2}+_{G}^{2}}=4K_{G}^{2}\), \(}{_{G}^{2}+K_{G}^{2}}\).

_where \(T\) is the total communication round, \(K\) is the total local epoch times, \(f^{0}=f(x_{0})\), \(f^{*}=f(x_{*})\), \(M=_{L}^{2}+4K_{G}^{2}\) and the expectation is over the local dataset samples among clients._

The FedIS sampling probability \(p_{i}^{t}\) is determined by minimizing the variance of convergence with respect to \(p_{i}^{t}\). The variance term \(\) is:

\[=^{2}KL^{2}}{2}M^{2}+L}{2m}_{L}^{2} +}{2nK}\ (^{t}}_{i}^{t}), \]

where \((}{{(mpt)}}_{i}^{t})\) is called _update variance_. By optimizing the update variance, we get the sampling probability FedIS:

\[p_{i}^{t}=_{i}^{t}\|}{_{j=1}^{n}\|_{j}^{t}\|}\,, \]

where \(_{i}^{t}=_{k=0}^{K-1} F_{i}(x_{k,t}^{i},_{k,t}^{i})\) is the sum of the gradient updates of multiple local updates. The proof details of Theorem 3.1 and derivation of sampling probability FedIS are detailed in Appendix D and Appendix F.1.

**Remark 3.2** (Explanation for the convergence rate).: _It is worth mentioning that although a few works provide the convergence upper bound of FL with gradient-based sampling, several limitations exist in these analyses and results: 1)  analyzed FL with IS using a strongly convex condition, whereas we extended the analysis to the non-convex analysis of FedIS  and FedAvg, 2) Our analysis results, compared to the very recent non-convex analysis of FedIS  and FedAvg, remove the term \((T^{-})\), although all these works choose a learning rate of \((T^{-})\). Thus, our result achieves a tighter convergence rate when we use \((1/T+1/T^{2/3})\) (provided by ) as our lower bound of convergence (see Table 1). The comparison results in Table 1 reveal that even when \(_{G}\) is large and becomes a dependency term for convergence rate, FedIS (ours) is still better than FedAvg and FedIS (others) since our result reduces the coefficient of \(_{G}\) in the dominant term \((T^{-})\)._

**Remark 3.3** (Novelty of our FedIS analysis).: _Despite the existence of existing convergence analysis of partial participant FL , including FedIS that builds on this analysis , none of them take full advantage of the nature of unbiased sampling, and thus yield an imprecise upper bound on convergence. To tighten the FedIS upper bound, we first derive a tighter convergence upper bound for unbiased sampling FL. By adopting uniform sampling for unbiased probability, we achieve a tighter FedAvg convergence rate. Leveraging this derived bound, we optimize convergence variance using IS._

Compared with existing unbiased sampling FL works, including FedAvg and FedIS (others), our analysis on FedIS entails: (1) **A tighter Local Update Bound Lemma:** We establish Lemma C.3 using Assumption 3, diverging from the stronger assumption \(\| F_{i}(x_{t}))- f(x_{t})\|^{2}_{G}^{2}\) (used in ), and the derived Lemma C.3 achieves a tighter upper bound than other works (Lemma 4 in , Lemma 2 in ). (2) **A tighter upper bound on aggregated model updates \(E\|_{t}\|^{2}\):** By fully utilizing the nature of unbiased sampling, we convert the bound analysis of \(A_{2}=E\|_{t}\|^{2}\) equally to a bound analysis of participant variance \(V(^{t}}_{i}^{t})\) and aggregated model update with full user participation. In contrast, instead of exploring the property the unbiased sampling,  repeats to use Lemma 4 and  uses Lemma 2 for bound \(A_{2}\). This inequality transform imposes a loose upper bound for \(A_{2}\), resulting in a convergence variance term determined by \(_{L}^{3}\), which reacts to the rate order being \((T^{-})\). (3) **Relying on a more lenient assumption:** Beyond the aforementioned analytical improvement, our IS analysis obviates the necessity for unusual assumptions in other FedIS analysis such as Mix Participation  and \(\)-Assumption .

**Remark 3.4** (Extending FedIS to practical algorithm).: _The existing analysis of IS algorithms  relies on information from full clients, which is not available in partial participation FL. We propose a practical algorithm for FedIS that only uses information from available clients and provide its convergence rate in Corollary 4.1 in Section 4._Despite its success in reducing the variance term in the convergence rate, FedIS is far from optimal due to issues with high gradient similarity and the potential for further minimizing the variance term (i.e., the global variance \(_{G}\) and local variance \(_{L}\) in \(\)). In the next section, we will discuss how to address this challenging variance term.

### An Improved Convergence Analysis for FedDELTA

FedIS and FedDELTA have different approaches to analyzing objectives, with FedIS analyzing the global objective and FedDELTA analyzing a surrogate objective \((x)\) (cf. (7)). This leads to different convergence variance and sampling probabilities between the two methods. A flowchart (Figure 8 in Appendix E) has been included to illustrate the differences between FedIS and FedDELTA.

The limitations of FedIS.As shown in Figure 1, IS may have excessive similar gradient selection. The variance \(\) in (4) reveals that the standard IS strategy can only control the update variance \((^{1}/}})}}{{_{t}^{d}}}\), leaving other terms in \(\), namely \(_{L}\) and \(_{G}\), untouched. Therefore, the standard IS is ineffective at addressing the excessive similar gradient selection problem, motivating the need for a new sampling strategy to address the issue of \(_{L}\) and \(_{G}\).

The decomposition of the global objective.As inspired by the proof of Theorem 3.1 as well as the corresponding Lemma C.1 (stated in Appendix) proposed for unbiased sampling, the gradient of global objective can be decomposed into the gradient of surrogate objective \((x_{t})\) and update gap,

\[\| f(x_{t})\|^{2}=_{S_{t}}(x _{t})^{2}+_{t}^{2}\,, \]

where \(_{t}=_{S_{t}}(x_{t})- f(x_{t})\) is the update gap.

Intuitively, the surrogate objective represents the practical objective of the participating clients in each round, while the update gap \(_{t}\) represents the distance between partial client participation and full client participation. The convergence behavior of the update gap \(_{t}^{2}\) is analogous to the update variance in \(\), and the convergence of the surrogate objective \(_{S_{t}}(x_{t})^{2}\) depends on the other variance terms in \(\), namely the local variance and global variance.

Minimizing the surrogate objective allows us to further reduce the variance of convergence, and we will focus on analyzing surrogate objective below. We first formulate the surrogate objective with an arbitrary unbiased sampling probability.

Surrogate objective formulation.The expression of the surrogate objective relies on the property of IS. In particular, IS aims to substitute the original sampling distribution \(p(z)\) with another arbitrary sampling distribution \(q(z)\) while keeping the expectation unchanged: \(_{q(z)}[F_{i}(z)]=_{p(z)}[q_{i}(z)/p_{i}(z )F_{i}(z)]\). According to the Monte Carlo method, when \(q(z)\) follows the uniform distribution, we can estimate \(_{q(z)}[F_{i}(z)]\) by \(}{{m}}_{i=1}^{m}F_{i}(z)\) and \(_{p(z)}[q_{i}(z)/p_{i}(z)F_{i}(z)]\) by \(}{{n}}_{i S_{t}}}{{mp_{i}}}F_{i}(z)\), where \(m\) and \(|S_{t}|=n\) are the sample sizes.

Based on IS property, we formulate the surrogate objective:

\[_{S_{t}}(x_{t})=_{i S_{t}}^{ }}F_{i}(x_{t})\,, \]

where \(m\) is the total number of clients, \(|S_{t}|=n\) is the number of participating clients in each round, and \(p_{t}^{}\) is the probability that client \(i\) is selected at round \(t\).

As noted in Lemma C.2 in the appendix, we have:2:

\[_{t[T]}\| f(x_{t})\|^{2}=_{t[T]}\| (x_{t})\|^{2}+\|_{t}^{2}\|_{t[T]}2 \|(x_{t})\|^{2}\,. \]

Then the convergence rate of the global objective can be formulated as follows:

**Theorem 3.5** (Convergence upper bound of FedDELTA).: _Under Assumption 1-3 and let local and global learning rates \(\) and \(_{L}\) satisfy \(_{L}<}{{(2L}}_{l=1}^{m} {mp_{l}^{}}}\)) and \(_{L}}{{KL}}\), the minimal gradient norm will be bounded as below:_

\[_{t[T]}\| f(x_{t})\|^{2} -f^{*}}{c_{L}K^{T}}+\,, \]_where \(f^{0}=f(x_{0})\), \(f^{*}=f(x_{*})\), \(c\) is a constant, and the expectation is over the local dataset samples among all workers. The combination of variance \(\) represents combinations of local variance and client gradient diversity._

We derive the convergence rates for both sampling with replacement and sampling without replacement. For sampling without replacement:

\[=K_{1}^{2}}{2mn}_{i=1}^{m}^{t}}( _{L,i}^{2}+4K_{G,i,t}^{2})+}{2n}_{i=1}^{m} p_{i}^{t}}_{L,i}^{2}\,. \]

For sampling with replacement,

\[=K_{2}^{2}}{2m^{2}}_{i=1}^{m}^{t} }(_{L,i}^{2}+4K_{G,i,t}^{2})+}{2n}_{i=1}^{m} p_{i}^{t}}_{L,i}^{2}\,, \]

where \(_{G,i,t}=\| F_{i}(x_{t})- f(x_{t})\|\) and let \(_{G}\) be a upper bound for all \(i\), i.e., \(_{G,i,t}_{G}\). The proof details of Theorem 3.5 can be found in Appendix E.

**Remark 3.6** (The novelty of DELTA analysis).: _IS focuses on minimizing \(V(^{t}}_{i}^{t})\) in convergence variance \(\) (Eq. (4)), while leaving other terms like \(_{L}\) and \(_{G}\) unreduced. Unlike IS roles to reduce the update gap, we propose analyzing the surrogate objective for additional variance reduction._

_Compared with FedIS, our analysis of DELTA entails: **Focusing on surrogate objective, introducing a novel Lemma and bound:** _(1) we decompose global objective convergence into surrogate objective and update gap (6). For surrogate objective analysis, we introduce Lemma E.8 to bound local updates. (2) leveraging the unique surrogate objective expression and Lemma E.8, we link sampling probability with local variance and gradient diversity, deriving novel upper bounds for \(A_{1}\) and \(A_{2}\). (3) by connecting update gap's convergence behavior to surrogate objective through Definition E.1 and Lemma C.2, along with (6), we establish \(\) as the new global objective convergence variance._

_Optimizing convergence variance through novel \(\): FedIS aims to reduce the update variance term \(V(^{t})}_{i}^{t})\) in \(\), while FedDELTA aims to minimize the entire convergence variance \(\), which is composed of both gradient diversity and local variance. By minimizing \(\), we get the sampling method DELTA, which further reduces the variance terms of \(\) that cannot be minimized through IS._

### Proposed Sampling Strategy: DELTA

The expression of the convergence upper bound suggests that utilizing sampling to optimize the convergence variance can accelerate the convergence. Hence, we can formulate an optimization problem that minimizes the variance \(\) with respect to the proposed sampling probability \(p_{i}^{t}\):

\[_{p_{i}^{t}}_{i=1}^{m}p_{i}^{t}=1\,, \]

where \(\) is a linear combination of local variance \(_{L,i}\) and gradient diversity \(_{G,i,t}\) (cf. Theorem 3.5).

**Corollary 3.7** (Optimal sampling probability of DELTA).: _By solving the above optimization problem, the optimal sampling probability is determined as follows:_

\[p_{i}^{t}=_{G,i,t}^{2}+_{2}_{L,i}^{2}}}{ _{j=1}^{m}_{G,j,t}^{2}+_{2}_{L,j}^{2}}}\,, \]

_where \(_{1}\) and \(_{2}\) are constants defined as \(_{1}=20K^{2}L_{L}\) and \(_{2}=5KL_{L}+\)._

**Remark 3.8**.: _We note that a tension exists between the optimal sampling probability (13) and the setting of partial participation for FL. Thus, we also provide a practical implementation version for DELTA and analyze its convergence in Section 4. In particular, we will show that the convergence rate of the practical implementation version keeps the same order with a coefficient difference._

**Corollary 3.9** (Convergence rate of FedDELTA).: _Let \(_{L}=(})\), \(=()\) and substitute the optimal sampling probability (13) back to \(\). Then for sufficiently large T, the expected norm of DELTA algorithm 1 satisfies:_

\[_{t[T]}\| f(x_{t})\|^{2}(^{0}-f^{*}}{})+(^{2}}{})+(^{2}+4K _{G}^{2}}{KT})}_{$}}. \]

**Difference between FedDELTA and FedIS.** The primary distinction between FedDELTA and FedIS lies in the difference between \(\) and \(\). FedIS aims to decrease the update variance term \((1/(m_{t}^{*})_{t}^{*})\) in \(\), while FedDELTA aims to reduce the entire quantity \(\), which is composed of both gradient diversity and local variance. By minimizing \(\), we can further reduce the terms of \(\) that cannot be minimized through FedIS. This leads to different expressions for the optimal sampling probability. The difference between the two resulting update gradients is discussed in Figure 3. Additionally, as seen in Table 1, FedDELTA achieves a superior convergence rate of \((G^{2}/^{2})\) compared to other unbiased sampling algorithms.

**Compare DELTA with uniform sampling.** According to the Cauchy-Schwarz inequality, DELTA is at least better than uniform sampling by reducing variance: \(_{}}{_{}}=^ {m}(_{L}^{2}+_{2}_{G,i,t}^{2}})^{2}}{( _{i=1}^{m}_{L}^{2}+_{2}_{G,i,t}^{2}} )} 1\,.\)

This implies that DELTA does reduce the variance, especially when \(^{m}_{L}^{2}+_{2}_{G,i,t }^{2}})^{2}}{_{i=1}^{m}(_{L}^{2}+_{2} _{G,i,t}^{2}})} m\).

**The significance of DELTA.** (1) DELTA is the first unbiased sampling algorithm, to the best of our knowledge, that considers both gradient diversity and local variance in sampling, accelerating convergence. (2) Developing DELTA inspires an improved convergence analysis by focusing on the surrogate objective, leading to a superior convergence rate for FL. (3) Moreover, DELTA can be seen as an unbiased version with the complete theoretical justification for the existing heuristic or biased diversity sampling algorithm of FL, such as .

## 4 FedPracDELTA and FedPracIS: The Practical Algorithms

The gradient-norm-based sampling method necessitates the calculation of the full gradient in every iteration [10; 70]. However, acquiring each client's gradient in advance is generally impractical in FL. To overcome this obstacle, we leverage the gradient from the previous participated round to estimate the gradient of the current round, thus reducing computational resources .

For FedPracIS, at round 0, all probabilities are set to \(}{{m}}\). Then, during the \(i_{th}\) iteration, once participating clients \(i S_{t}\) have sent the server their updated gradients, the sampling probabilities are updated as follows:

\[p_{i,t+1}^{*}=_{i,t}\|}{_{i S_{t}}\|_{i,t}\|}(1- _{i S_{t}^{c}}p_{i,t}^{*})\,, \]

where the multiplicative factor ensures that all probabilities sum to 1. The FedPracIS algorithm is shown in Algorithm 2 of Appendix D.

For FedPracDELTA, we use the average of the latest participated clients' gradients to approximate the true gradient of the global model. For local variance, it is obtained by the local gradient's variance over local batches. Specifically, \(_{G,i,t}=\|_{i,t}-(x_{t})\|\), where \((x_{t})=_{i S_{t}}_{i,t}= _{i S_{t}}_{k=0}^{K-1} F_{i}(x_{k,t}^{i},_{k,t}^{i})\) and \(_{L,i}^{2}=_{b B}(_{i,t}^{b}- _{b B}_{i,t}^{b})^{2}\), where \(b B\) is the local data batch. Then the sampling probabilities are updated as follows:

\[p_{i,t+1}^{*}=_{G,i,t}^{2}+_{2}_{L,i}^ {2}}}{_{i S_{t}}_{G,i,t}^{2}+_{2}_{L, i}^{2}}}(1-_{j S_{t}^{c}}p_{i,t}^{*})\,. \]

The FedPracDELTA algorithm is shown in Algorithm 1. Specifically, for \(\), the default value is 0.5, whereas \(_{G}\) and \(_{L}\) can be implemented by computing the locally obtained gradients.

**Assumption 4** (Local gradient norm bound).: _The gradients \( F_{i}(x)\) are uniformly upper bounded (by a constant \(G>0\)) \(\| F_{i}(x)\|^{2} G^{2}, i\)._

Assumption 4 is a general assumption in IS community to bound the gradient norm [70; 10; 23], and it is also used in the FL community to analyze convergence [2; 68]. This assumption tells us a useful fact that will be used later: \(\| F_{i}(x_{t,k},_{t,k})/ F_{i}(x_{s,k},_{s,k})\| U\). While, for DELTA, the assumption used is a more relaxed version of Assumption 4, namely, \(\| F_{i}(x)- f(x)\|^{2} G^{2}\) (further details are provided in Appendix G).

**Corollary 4.1** (Convergence rate of FedPracIS).: _Under Assumption 1-4, the expected norm of FedPracIS will be bounded as follows:_

\[_{t}E\| f(x_{t})\|^{2}(-t^{*}}{ })+(^{2}}{})+ (}{T})+(_ {L,t}^{2}}{^{2}}), \]

[MISSING_PAGE_FAIL:9]

CIFAR-10, FEMNIST, and CelebA. Additionally, on the natural federated dataset LEAF (FEMNIST and CelebA), our results demonstrate that both FedPracDELTA and FedPracIS exhibit substantial improvements over FedAvg. Figure 14(b) in Appendix H.3 illustrates the superior convergence of FedPracDELTA, showcasing the accuracy curves of sampling algorithms on FEMNIST.

Table 3 demonstrates that when compatible with momentum or proximal regularization, our method keeps its superiority in convergence.We combine various optimization methods such as proximal regularization , momentum , and VARP  with sampling algorithms to assess their performance on FEMNIST and FashionMNIST. Additional results for proximal and momentum on CIFAR-10, and for VARP on FashionMNIST, are available in Table 4 and Table 5 in Appendix H.3.

Ablation studies.We also provide ablation studies of heterogeneity \(\) in Table 9 and the impact of the number of sampled clients on accuracy in Figure 15 in Appendix H.3.

## 6 Conclusions, Limitations, and Future Works

This work studies the unbiased client sampling strategy to accelerate the convergence speed of FL by leveraging diverse clients. To address the prevalent issue of full-client gradient dependence in gradient-based FL , we extend the theoretical algorithm DELTA to a practical version that utilizes information from the available clients.

Nevertheless, addressing the backdoor attack defense issue remains crucial in sampling algorithms. Furthermore, there is still significant room for developing an efficient and effective practical algorithm for gradient-based sampling methods. We will prioritize this as a future research direction.

## 7 Acknowledgement

This work is supported in part by the National Natural Science Foundation of China under Grant No. 62001412, in part by the funding from Shenzhen Institute of Artificial Intelligence and Robotics for Society, in part by the Shenzhen Key Lab of Crowd Intelligence Empowered Low-Carbon Energy Network (Grant No. ZDSYS20220606100601002), and in part by the Guangdong Provincial Key Laboratory of Future Networks of Intelligence (Grant No. 2022B1212010001). This work is also supported in part by the Research Center for Industries of the Future (RCIF) at Westlake University, and Westlake Education Foundation.

    &  &  \\   & Acc (\%) & Rounds for 70\% & Time (s) for 70\% & Acc (\%) & Rounds for 54\% & Time (s) for 54\% \\  FedAvg & 70.35\(\)0.51 & 426 (1.0\(\)) & 1795.12 (1.0\(\)) & 54.28\(\)0.29 & 338 (1.0\(\)) & 3283.14 (1.0\(\)) \\ Cluster-based IS & 71.21 \(\)0.24 & 362 (1.17\(\)) & 1547.41 (1.16\(\)) & 54.83\(\)0.02 & 323 (1.05\(\)) & 3188.54 (1.03\(\)) \\ FedPracIS & 71.69\(\)0.43 & 404 (1.05\(\)) & 1719.26 (1.04\(\)) & 55.05\(\)0.27 & 313 (1.08\(\)) & 3085.05 (1.06\(\)) \\ FedPracDELTA & **72.10\(\)**0.49 & **322 (1.32\(\))** & **1372.33 (1.31\(\))** & **55.20\(\)**0.26 & **303 (1.12\(\))** & **2989.98 (1.1\(\))** \\  Algorithm &  &  \\   & Acc (\%) & Rounds for 70\% & Time (s) for 70\% & Acc (\%) & Rounds for 85\% & Time (s) for 85\% \\  FedAvg & 71.82\(\)0.93 & 164 (1.0\(\)) & 330.02 (1.0\(\)) & 85.92\(\)0.89 & 420 (1.0\(\)) & 3439.81 (1.0\(\)) \\ Cluster-based IS & 70.42\(\)0.66 & 215 (0.76\(\)) & 453.56 (0.73\(\)) & 86.77\(\)0.11 & 395 (1.06\(\)) & 3474.50 (1.01\(\)) \\ FedPracIS & 80.11\(\)0.29 & 110 (1.51\(\)) & 223.27 (1.48\(\)) & 88.12\(\)0.71 & 327 (1.28\(\)) & 2746.82 (1.25\(\)) \\ FedPracDELTA & **81.44\(\)**0.28 & **98 (1.67\(\))** & **198.95 (1.66\(\))** & **89.67 \(\)**0.56 & **306 (1.37\(\))** & **2607.12 (1.32\(\))** \\   

Table 2: **Performance of algorithms over various datasets.** We run 500 communication rounds on FashionMNIST, CIFAR-10, FEMNIST, and CelebA for each algorithm. We report the mean of maximum 5 accuracies for test datasets and the average number of communication rounds and time to reach the threshold accuracy.

    &  &  &  &  \\   & Acc (\%) & Rounds for 80\% & Acc (\%) & Rounds for 80\% & Acc (\%) & Rounds for 80\% \\  FedAvg & 71.82\(\)0.35 & 164 (70\%) & 70.42\(\)0.66 & 215 (67\%) & 80.11\(\)0.59 & 110 (64\%) & **81.44\(\)**0.28 & **98 (10\%)** \\ FedAvg = momentum & 80.86\(\)0.97 & 268 & 80.86\(\)0.93 & 281 & 81.80\(\)0.55 & 246 & **82.58\(\)**0.44 & **200** \\ FedAvg = proximal & 81.44 \(\)0.34 & 313 & 80.88 \(\)0.30 & 326 & 81.28\(\)0.25 & 289 & **82.54 \(\)**0.57 & **248** \\   

Table 3: **Performance of sampling algorithms integration with other optimization methods on FEMNIST, PracIS and PracDELTA are the sampling methods of Algorithm FedPracIS and FedPracDELTA, respectively, using the sampling probabilities defined in equations (15) and (16). For proximal and momentum methods, we use the default hyperparameter setting \(=0.01\) and \(=0.9\).**