# Deep Optimal Transport: A Practical Algorithm for Photo-realistic Image Restoration

Theo J. Adrai

Technion-Israel Institute of Technology

Computer Science

theoad@cs.technion.ac.il

Guy Ohayon

Technion-Israel Institute of Technology

Computer Science

ohayonguy@cs.technion.ac.il

Michael Elad

Technion-Israel Institute of Technology

Computer Science

elad@cs.technion.ac.il

Tomer Michaeli

Technion-Israel Institute of Technology

Electrical Engineering

tomer.m@ee.technion.ac.il

###### Abstract

We propose an image restoration algorithm that can control the perceptual quality and/or the mean square error (MSE) of any pre-trained model, trading one over the other at test time. Our algorithm is few-shot: Given about a dozen images restored by the model, it can significantly improve the perceptual quality and/or the MSE of the model for newly restored images without further training. Our approach is motivated by a recent theoretical result that links between the minimum MSE (MMSE) predictor and the predictor that minimizes the MSE under a perfect perceptual quality constraint. Specifically, it has been shown that the latter can be obtained by optimally transporting the output of the former, such that its distribution matches the source data. Thus, to improve the perceptual quality of a predictor that was originally trained to minimize MSE, we approximate the optimal transport by a linear transformation in the latent space of a variational auto-encoder, which we compute in closed-form using empirical means and covariances. Going beyond the theory, we find that applying the same procedure on models that were initially trained to achieve high perceptual quality, typically improves their perceptual quality even further. And by interpolating the results with the original output of the model, we can improve their MSE on the expense of perceptual quality. We illustrate our method on a variety of degradations applied to general content images of arbitrary dimensions.

## 1 Introduction

Many image restoration algorithms aim to recover a clean source image from its degraded version. The performance of such algorithms is often evaluated in terms of their average _distortion_, which measures the discrepancy between restored images and their corresponding clean sources, as well as _perceptual quality_, which refers to the extent to which restored images resemble natural images. The work in  exposed a fundamental trade-off between distortion and perceptual quality, where the latter is measured using a _perceptual index_ that quantifies the statistical divergence between the distribution of restored images and the distribution of natural images. The

Figure 1: The \(_{2}\)-MSE trade-off .

trade-off curve reveals the predictor that achieves the lowest possible distortion, denoted as \(}\), while maintaining perfect perceptual quality (refer to fig. 1).

Following the methodology introduced by , it has become common practice to compare restoration methods on the perception-distortion (PD) plane, with many methods aiming to reach the elusive \(}\) point. In this paper, we present a practical approach to approximate the \(}\) predictor where distortion is measured using the MSE and perceptual quality is measured by the Wasserstein-2 distance (\(_{2}\) ) between the distributions of restored and real images. Our approach is based on the recent work  which demonstrated that the \(}\) predictor can be obtained using _optimal transport_ (OT) from the output distribution of the MMSE predictor to the distribution of natural images. By applying an optimal transport plan to an MMSE restoration resulting from a degraded image, we can produce \(}\) estimations by transporting the MMSE restored estimate.

Although progress has been made in finding OT plans between image distributions [4; 5; 6], it remains challenging task, particularly for high-dimensional distributions. Therefore, we propose an approximation method for the \(}\) estimator by performing transportation in the latent space of a pre-trained auto-encoder. A similar strategy was successfully employed in the context of image generation in , showing effectiveness in reducing complexity and preserving details.

Inspired by the style transfer literature [8; 9; 10], we assume that the latent representations follow a Multivariate Gaussian (MVG) distribution. Thus, by considering the first and second-order statistics of the embedded MMSE estimates and embedded natural images, we can compute the well-known closed form solution of the OT operator between two Gaussians. To further reduce complexity, we make additional assumptions about the structure of the latent covariance matrices, enabling the computation of the OT operator with as few as 10 _unpaired_ MMSE restored and clean samples. This approach leads to a few-shot algorithm that significantly enhances visual quality.

Interestingly, our method can even improve the visual quality of generative models that were trained to achieve high perceptual quality in the first place (see fig. 2). Furthermore, by adjusting a single interpolation parameter, we can trade off perception for distortion, resulting in marginal improvements in the distortion performance of some regression models that were trained to prioritize source fidelity. We demonstrate the improved photo-realism of our approach on a variety of tasks and models, including GAN and diffusion-based methods, using high-resolution (_e.g._, \(512^{2}\) px) general-content images with arbitrary aspect ratios. 1

## 2 Related Work

Throughout the paper, we distinguish between two kinds of restoration algorithms: distortion and perception focused. The former category includes traditional methods that minimize distortion (e.g.,

Figure 2: Our few-shot algorithm improves the visual quality of any estimator at test time. For example, we can improve the photo-realism of DDRM  even further.

[MISSING_PAGE_FAIL:3]

### Wasserstein-2 MSE tradeoff

We build upon the problem setting introduced in [1; 2] to establish our analysis. We consider the following scenario: \(^{n}\) represents a source natural image, \(^{m}\) represents its degraded version, and we assume that the posterior \(p_{|}(|y)\) is non-degenerate for almost any \(y\). Our objective is to construct an estimator \(}\) that predicts \(\) given \(\). A valid estimator \(}\) should be independent of \(\) given \(\). Finally, \(p_{}\), \(p_{^{*}}\) and \(p_{}_{0}}\) denote the probability distributions associated with the random variables \(\), \(^{*}\) and \(}_{0}\), respectively.

Let \(^{*}=[|]\) denote the MMSE estimator that achieves the minimal MSE, _i.e._, \((,^{*})=D_{}\). Additionally, let \(}_{0}\) denote the \(}\) estimator, which among all estimators satisfying \(_{2}(p_{},p_{}_{0}})=0\), attains the minimal MSE, namely, \((,}_{0})=D_{}\) (refer to fig. 1). Notably, as discussed in , these estimators have a compelling property: their joint distribution \(p_{}_{0},^{*}}\) is an optimal transport plan between \(^{*}\) and \(\), characterized by the following optimization problem:

\[p_{_{0},^{*}}*{arg\,min}_{p_{_{ 1},_{2}}(p_{},p_{^{*}})}[\|_{1}-_{2}\|_{2}^{2}]. \]

In other words, finding \(}_{0}\) is equivalent to finding an optimal transport plan from \(^{*}\) to \(\). Then, the \(}\) estimator is simply \(}_{0}=_{p_{^{*}} p_{ }}(^{*})\).

This estimator is particularly useful as it allows to obtain any point on the perception-distortion function through a naive linear interpolation with the MMSE estimator. Specifically, we can define the interpolated estimator \(}_{P}\) as follows:

\[}_{P}=(1-)}_{0}+^{*}, \]

where \(0 1\) is an interpolation constant  that depends on the perceptual index of \(^{*}\) and the desired perceptual index \(0 P=_{2}(,}_{P})\) (refer to fig. 1).

## 4 Method

We start by describing the general flow of our proposed algorithm, and then move to elaborate on each of its components.

Theoretically speaking, our algorithm, combined with any given MMSE estimator, is an approximation of the \(}\) estimator. In practice, however, it can be combined with any type of estimator and potentially improve its perceptual quality. I.e., it can be combined with an estimator that optimizes

Figure 3: Trading perception and distortion using out-of-the-box predictors, wrapped with our method. Using eq. (4) with \(\) we interpolate a given predictor (orange) and our improved \(}\) estimation (green), to approximate the PD FID-MSE function (blue curve). With \([-1,0]\) we extrapolate outside of the PD curve (light gray), beyond the theory-inspired area, to further improve performance.

distortion (e.g., SwinIR ) and improve its perceptual quality at the expense of distortion, or it can be combined with an estimator that optimizes perceptual quality (e.g., DDRM ) and improve its perceptual quality even further. As a result, our algorithm is agnostic to the type of degradation. To clarify, our algorithm is not really a restoration algorithm by itself, but rather a wrapper which can potentially improve the perceptual quality of any given estimator.

### The algorithm

The main goal of our algorithm is to approximate the optimal transport plan between \(p_{}}\) and \(p_{}\), namely, \(_{p_{} p_{}}\), where \(}\) is a given estimator. Theoretically, with such an operator, one could optimally transport \(}\) such that, with minimal loss in MSE performance, the transported estimator would attain perfect perceptual quality. Computing \(_{p_{} p_{}}\) for high dimensional distributions is a difficult task, involving complex (often adversarial) optimization (see discussion in section 2). To solve this, we perform several assumptions and approximations that allow us to efficiently compute a closed form transport operator that approximates \(_{p_{} p_{}}\). The flow of the algorithm is presented in fig. 4, and goes as follows:

**Encoding**: In the training stage we encode \(N\) natural images \(\{x^{(i)}\}_{i=1}^{N}\) and \(N\) restored samples \(\{^{(i)}\}_{i=1}^{N}\) (unpaired) into their latent representations, \(\{x_{e}^{(i)}\}_{i=1}^{N}\) and \(\{_{e}^{(i)}\}_{i=1}^{N}\), respectively. The size of each image sample is denoted by \((3,H,W)\), where \(H\) and \(W\) are the height and width, respectively, and the size of their latent representation is denoted by \((c,H_{e},W_{e})\). In the inference stage we perform the same process but only on a single estimate \(\), resulting again in a latent representation of size \((c,H_{e},W_{e})\)

**Unfold**: From each latent representation we extract all the overlapping patches of size \((c,p,p)\), where \(p\) is the height and width of each patch.

**Flatten each patch and aggregate**: We flatten all the extracted patches to obtain 1-dimensional vectors of size \(cp^{2}\), which we assume to come from a MVG distribution. In the training stage we compute their empirical mean and covariance matrix (aggregating over the \(N\) dimension), and compute the optimal transport in closed-form \(_{p_{_{e}} p_{_{e}}}^{}\) using eq. (2).

Figure 4: With a pre-trained VAE, we estimate the first and second order statistics of the latent patches of natural images and the restorations of some given estimator. At inference time, we use the closed-form OT eq. (2) operator between MVG distributions to transport the latent representation of a given restored sample, which, after decoding, increases the visual quality of the restored sample. For a fully detailed explanation of the algorithm, see section 4.

**Matmul and unflatten**: We apply the pre-computed transport operator using a simple matrix-vector multiplication on the flattened version of the patches extracted from the latent representation \(_{e}\). We then reshape each vector to the original patch size \((c,p,p)\) (unflatten).

**Fold**: We rearrange the transported patches back to the original size of the latent representation (reversing the unfold operation). Since the patches overlap, we simply average the shared pixels.

**Decoding**: To produce our final enhanced estimation \(_{0}\), we decode the transported latent image back to the pixel space using the decoder of the VAE.

Together, the inference steps form an end-to-end approximation of the desired transport operator \(_{p_{k} p_{}}\). In appendix B we elaborate on the choices and practical considerations of our algorithm.

## 5 Experiments

In all of our experiments we use the encoder and decoder of the VAE  from stable-diffusion .

**The pre-trained models we evaluate:** We apply our latent transport method (described in section 4) on SwinIR , Restormer  and Swin2SR , all of which attempted to minimize average pixel distortion using a supervised regression loss on paired image samples. Additionally, we apply our algorithm on models that are trained to achieve high perceptual quality, and show that we can improve their visual quality even further. As such, we tested two benchmark models in high perceptual quality image restoration: ESRGAN , a GAN-based method, and DDRM , a diffusion-based method. Beyond our original goal to improve perceptual quality, we demonstrate that we can also traverse the \(_{2}\) -MSE tradeoff using any restoration model (e.g., SwinIR, ESRGAN). To do so, we pick any of the aforementioned algorithms and apply our method to improve its perceptual quality, leading to a new estimator. We then interpolate the original algorithm and its improved version using eq. (4), adjusting \(\) to traverse the tradeoff. To clarify, we plug the original algorithm as \(^{*}\) in eq. (4) (instead of the theoretical MMSE estimator), and plug our improved version as \(}_{0}\) (instead of the theoretical \(}\) estimator).

**Restoration tasks:** We showcase our algorithm on Single-Image Super-Resolution (SISR), denoising of Additive White Gaussian Noise (AWGN), JPEG  decompression, Noisy Super-Resolution (NSR) and Compressed Super-Resolution (CSR). Training and inference of our algorithm are performed on each restoration model separately, and the evaluation is performed on the restoration task that corresponds to the given model.

**Transport operator computation:** The transport operator is computed using two disjoint sets of 10 randomly picked images from the ImageNet  dataset train split. The first set is used to approximate the predictor's latent statistics (\(_{}_{e}}\), \(_{}_{e}}\)): we degrade each image according to the restoration task the predictor is intended to solve, compute the 10 restored outputs, embed the results and compute the embeddings' statistics. The second set is embedded into the latent representation without further modification and serves to approximate the natural image latent statistics (\(_{_{e}}\), \(_{_{e}}\)).

**Metrics:** In addition to Peak Signal-to-Noise Ratio (PSNR), we evaluate distortion performance with Structural Similarity Index Measure (SSIM)  and Learned Perceptual Image Patch Similarity (LPIPS) , both of which suit better for natural image comparison .

Nonetheless, LPIPS remains by definition a _distortion_ (full-reference) measure: it is non-negative and zero when the two images are identical . Interestingly, the original perception-distortion paper  already classified the VGG loss  - the ancestor of LPIPS - to be a distortion, on which the tradeoff exists (but is less severe).

Therefore, to evaluate perceptual quality, we use the Inception Score (IS) , the Frechet Inception Distance (FID)  and the Kernel Inception Distance (KID)  following popular image restoration papers .

**Data sets:** It is impractical to perform a serious quantitative evaluation of the perception-distortion tradeoff on real-world datasets (e.g., SIDD, DND, RealSR), which have too few samples to compute FID. Hence, for all models except DDRM  and Swin2SR , we report the performance on the 50,000 validation samples of ImageNet  following . Because of its computational complexity, DDRM  reported its performance on a subset of a 1000 ImageNet  validation samples. For Swin2SR , we use the official DIV2K  restored samples provided by the authors.

Although our algorithm can be applied to images with arbitrary aspect ratios, all the tested models were trained on square images. Thus, we resize the samples to \(512 512\) pixels following the pre-processing procedure of DDRM . Finally, we conduct the qualitative evaluation on popular samples from DIV2K or Set14.

### Quantitative results

As reported in table 1, our algorithm can trade perceptual quality for distortion (and vice versa) at test time. We sometimes even manage to improve the pre-trained predictor's PSNR, even of regression models like SwinIR and Swin2SR. When using \( 0\), we systematically improve the predictor's perceptual performance (FID, KID, IS), even for estimators which were designed to achieve photo-realism in the first place, e.g., ESRGAN and DDRM. On Non-Local-Means (NLM) , an older, non deep-learning denoising algorithm, our method marginally improves all metrics.

While, in theory, our procedure to traverse the perception distortion tradeoff should only include values of \(\) in the range \(\) (see eq. (4)), we also tried to use values outside of this range. As shown in fig. 3, with \([-1,0]\) we can obtain even better PD curves, and sometimes improve the perceptual quality and/or the distortion of the methods even further. For instance, the PD curve of Swin2SR obtained using \(\) is strictly better than the one obtained using \(\). This deviation from the theory can be explained by the implementation choices discussed in section 4; We perform the transport in the latent space - not the pixel space. Additionally, we use FID as perceptual index to measure visual quality when the theory presented in section 3.2 only talks about the Wasserstein-2 distance. In practice, the sharpened details that appear in \(}_{0}\) and not in \(^{*}\) are either amplified when \([-1,0]\) or subtracted (instead of being added) to \(^{*}\) when \(\). We leave the formal analysis of this interesting phenomenon for future research.

**Choosing the right value of \(\)**: Like any other hyper-parameter, \(\) can improve the performance with some tuning when approaching a new task or a new data set (refer to table 1). We argue that the few-shot nature of our algorithm makes this tuning actually practical: \(\) does not need to be set before performing some expensive training. Once \(}_{=0}\) is computed, any \(}_{}\) can be obtained thanks to eq. (4) without additional cost. In any case, as reported in table 1, \(=0\) consistently improves perceptual quality for all the tasks and models considered (as expected from the theory). We consider it to be a satisfying default choice, so manually adjusting \(\) is not a great concern.

### Qualitative results

Qualitative results on arbitrary image sizes and aspect ratios are shown in fig. 5. Using our method, we observe a consistent improvement of photo-realism when transporting existing restoration algorithms using our method. Hence, the qualitative results align with the quantitative perceptual performance gains.

### Training details & ablation study

All the results presented in figs. 3 and 5 and table 1 were obtained using the same hyper-parameters. We used the "f8-ft-MSE" fine-tuned version of stable-diffusion's VAE from Hugging-Face's diffusers library . For the training stage we use 20 randomly-drawn images from the ImageNet training set (10 images which we use as the natural images set, and 10 images which we degrade and then restore with the estimator). We used a patch-size of \(p=3\) in the latent space.

Thanks to its simplicity, for each restoration task, our few-shot algorithm requires just a single GPU, and a few seconds for both training and inference.

We turn to detail some considerations about practical aspects of our algorithm which we empirically evaluate on the popular SISR\({}_{ 4}\) task for the ESRGAN estimator.

**Patch size**: We experiment with increasing patch-sizes when unfolding the latent image (see appendix B.2). \(p=\{3,5\}\) yielded the best PSNR and FID. Smaller patch size (\(p=1\)) resulted in worse FID and bigger size \(7 p 15\) yielded slightly worse PSNR.

**Training size**: As discussed in appendix B.4, each image contributes thousands of samples to the computation of the OT operator. Still, we expect the empirical statistics estimation to benefit from a larger sample size \(S\). To confirm this, we repeated the visual enhancement experiments while varying the number of training samples. Surprisingly, we observe no change in the performance of the evaluated metrics for \(S=\{10^{5},10^{4},10^{3},10^{2}\}\), i.e., approximating the distribution statistics with 100 samples is as good as using 100,000 samples, and this is true regardless of the chosen patch size. Moreover, when With \(S=10\), then only for small patch sizes of \(p 5\) we observe no performance drop compared to using a larger sample size. This suggests that our method can be successfully deployed in few-shot settings, where the number of available samples is small.

**Paired vs. unpaired samples**: Surprisingly, using paired images to compute the distribution parameters yielded better PSNR but worse FID. We suspect that using paired updates induces a bias which results in worse covariance estimation.

**Transporting the degraded measurement directly**: Applying our algorithm on the degraded input directly led to insufficient results as we see in appendix B.7.

**Re-applying the algorithm another time on \(}_{0}\)**: This is actually an interesting idea we tested on super-resolution when conducting our evaluations. As a matter of fact, the performance does not improve (it even degrades a bit) when applying the algorithm another time. The explanation is quite simple: After transporting once the test images using the VAE, their latent distribution aligns with that of the natural images. Hence, transporting another time does nothing (the transport operator is

    & &  &  \\   & & PSNR \(\) & SSIM \(\) & LPIPS \(\) & FID \(\) & IS \(\) & KID\( 10^{3}\) \\  Task & \(\) & \(\) & 1 & 0 & 0 & 240.53\(\)4.42 & 0 \\  & \((())\) & 27.10 & 0.81 & 0.13 & 0.24 & 234.71\(\)4.04 & 0.02\(\)0.07 \\  _{ 4}\)} & SwinIR  & 28.10 & **0.84** & **0.24** & 2.54 & 201.52\(\)4.85 & 1.24\(\)0.24 \\  & \(}_{0.9}\) & **28.15** & **0.84** & **0.24** & 2.80 & 198.69\(\)2.97 & 1.38\(\)0.24 \\  & \(}_{-0.2}\) & 25.08 & 0.77 & 0.25 & **1.19** & **216.74\(\)**4.26 & **0.38\(\)**0.89 \\  & \(}_{0}\) & 25.48 & 0.78 & 0.23 & 1.39 & 214.63\(\)5.50 & 0.69\(\)0.23 \\  _{q=10}\)} & SwinIR  & **29.68** & **0.86** & **0.30** & 8.95 & 161.73\(\)3.36 & **6.52\(\)**0.77 \\  & \(}_{1.1}\) & 29.58 & **0.86** & **0.30** & 8.36 & 166.50\(\)3.12 & 6.08\(\)0.75 \\  & \(}_{-0.2}\) & 23.74 & 0.76 & 0.31 & **7.56** & **166.65\(\)**3.58 & **5.68\(\)**0.83 \\  & \(}_{0}\) & 24.84 & 0.78 & 0.30 & **8.14** & **163.14\(\)**3.93 & **6.15\(\)**0.77 \\  _{=50}\)} & Restormer  & **30.18** & **0.86** & 0.26 & 5.21 & 178.62\(\)2.83 & 3.29\(\)0.56 \\  & \(}_{1.1}\) & 30.09 & **0.86** & **0.25** & 4.63 & 183.36\(\)3.20 & 2.61\(\)1.53 \\  & \(}_{1.7}\) & 27.26 & 0.82 & **0.25the identity matrix). We are only left with the reconstruction error introduced by the encoding and decoding of the images, which deteriorates the MSE performance.

**Does the selection on the training data have an impact on the performance of restoration?**: Our experiments showed that the class of images does not have a significant impact on the performance (e.g. one could use images of cars to improve images of dogs). However the resolution of images does play a significant role in attaining the best performance. I.e., to transport 512x512 images, it is best to use training images of the same resolution. This drawback is somewhat mitigated by the few-shot nature of the algorithm.

## 6 Discussion

**Limitations**: The pre-trained VAE used for the purpose of our experiments exhibits a rate of \(R=48\) on \(512^{2}\) images which inevitably translates into sub-optimal distortion performance . Thus, the distortion performance of our estimates are bounded by that of the pre-trained VAE. I.e., even encoding and decoding a completely clean and natural image does not yield result in perfect

Figure 5: Our method (third column from the left) notably improves the results of several benchmark predictors (second column from the left) on various degradations.

reconstruction. Most notably, the VAE sometimes fails to reconstruct human faces, as well as text images, and such a weaknesses affects our algorithm as well (see fig. 6).

Finally, it has been recently shown that the posterior sampler is the only estimator attaining perfect perceptual quality while producing outputs that are perfectly consistent with the degraded input . As such, \(}\) cannot hope for consistent restorations.

**Potential impact**: Instead of using sophisticated and data-hungry generative models, we show it is possible to obtain photo-realistic results using simple tools like MMSE estimators and VAEs. We hope our few-shot algorithm will inspire other simple and practical image restoration methods.

**Potential misuse**: Our algorithm aims at improving the perceptual quality of existing algorithms. However, when using a biased training set, this could potentially cause bias in the enhanced restoration as well. This could potentially harm the results of medical image diagnosis, for example.

## Acknoledgements

This research was partially supported by the Council For Higher Education - Planning and Budgeting Committee.

Figure 6: Our method’s reconstruction capabilities are bounded by that of the VAE. Our algorithm is not able to preserve complex visual structures such as face identity (top row) or text (middle row).