# MuSe-GNN: Learning Unified Gene Representation

From Multimodal Biological Graph Data

 Tianyu Liu

Yale University

tianyu.liu@yale.edu

&Yuge Wang

Yale University

yuge.wang@yale.edu

&Rex Ying

Yale University

rex.ying@yale.edu

&Hongyu Zhao*

Yale University

hongyu.zhao@yale.edu

*: Corresponding author

###### Abstract

Discovering genes with similar functions across diverse biomedical contexts poses a significant challenge in gene representation learning due to data heterogeneity. In this study, we resolve this problem by introducing a novel model called Multimodal Similarity Learning Graph Neural Network, which combines Multimodal Machine Learning and Deep Graph Neural Networks to learn gene representations from single-cell sequencing and spatial transcriptomic data. Leveraging 82 training datasets from 10 tissues, three sequencing techniques, and three species, we create informative graph structures for model training and gene representations generation, while incorporating regularization with weighted similarity learning and contrastive learning to learn cross-data gene-gene relationships. This novel design ensures that we can offer gene representations containing functional similarity across different contexts in a joint space. Comprehensive benchmarking analysis shows our model's capacity to effectively capture gene function similarity across multiple modalities, outperforming state-of-the-art methods in gene representation learning by up to 97.5%. Moreover, we employ bioinformatics tools in conjunction with gene representations to uncover pathway enrichment, regulation causal networks, and functions of disease-associated or dosage-sensitive genes. Therefore, our model efficiently produces unified gene representations for the analysis of gene functions, tissue functions, diseases, and species evolution.

## 1 Introduction

Progress in biological technology has broadened the variety of biological data, facilitating the examination of intricate biological systems. A prime example of such technology is single-cell sequencing, which allows for the comprehensive characterization of genetic information within individual cells . This technology provides access to the full range of a cell's transcriptomics, epigenomics and proteomics information, including gene expression (scRNA-seq) , chromatin accessibility (scATAC-seq) , methylation  and anti-bodies . By sequencing cells from the same tissue at various time points, we can gain insight into patterns of cellular activity over time . Moreover, spatial information of cellular activity represents an equally vital, additional dimension. Such data are defined as spatial data. All of these data are known as multi-omics data, and integrating multi-omics data for combined analysis poses a significant challenge.

However, the traditional idea of multi-omics data integration known as using cells as anchors  is only partially suitable because of the following two challenges. 1. Different omicsdata pose their own challenges. For example, the unit of observation of the spatial transcriptomic data is different from other single-cell data, as a single spatial location contains mixed information (see the left part of Figure 1 a) from various cells  and it is not appropriate to generate spatial clusters based on gene expression similarity . Current research  also indicates that chromosome accessibility feature is not a powerful predictor for gene expression at the cell level. 2. The vast data volume in atlas-level studies challenges high-performance computing, risking out-of-memory or time-out errors . With nearly 37.2 trillion cells in the human body , comprehensive analysis is computationally infeasible. 3. Batch effects may adversely impact analysis results  by introducing noise. Consequently, an efficient and powerful method focusing on multi-omics and multi-tissue data (referred to as multimodal biological data) analysis is urgently needed to address these challenges.

Acknowledging the difficulties arising from the cell-oriented viewpoint, prior work shifted focus to the gene perspective. Using gene sets as a summary of expression profiles, based on natural selection during the species evolution, may provide a more robust anchor . Protein-coding genes are also thought to interact with drugs , which are more relevant to diseases and drug discovery. Gene2vec  is a method inspired by Word2vec , which learns gene representations by generating skip-gram pairs from the co-expression network. Recently, the Gene-based data Integration and ANalysis Technique (GIANT)  has been developed, based on Node2vec  and OhmNet , to learn gene representations from both single-cell and spatial datasets. However, as shown in Figure 1 (b), significant functional clustering for genes from different datasets but the same tissue was not observed based on the gene embeddings from these two models, because these methods do not infer the similarity of associated genes from different multimodal data. Additionally, they did not offer metrics to quantitatively evaluate the performance of gene embeddings compared to baseline models.

Here we introduce a novel model called **Mul**timodal **S**imilarity **L**earning **G**raph **N**eural **N**etwork (MuSe-GNN) 2 for multimodal biological data integration from a gene-centric perspective. The overall workflow of MuSe-GNN is depicted in Figure 1 (a). Figure 1 (b) shows MuSe-GNN's superior ability to learn functional similarity among genes across datasets by suitable model structure and novel loss function, comparing to GIANT and Gene2vec. MuSe-GNN utilizes weight-sharing Graph Neural Networks (GNNs) to encode genes from different modalities into a shared space regularized by the similarity learning strategy and the contrastive learning strategy. At the single-graph level, the design of graph neural networks ensures that MuSe-GNN can learn the neighbor information in each co-expression network, thus preserving the gene function similarity. At the cross-data level, the similarity learning strategy ensures that MuSe-GNN can integrate genes with similar functions into a common group, while the contrastive learning strategy helps distinguish genes with different functions. Furthermore, MuSe-GNN utilizes more robust co-expression networks for training and applies dimensionality reduction  to high-dimensional data .

To the best of our knowledge, this is the first paper in gene representation learning that combines the Multimodal Machine Learning (MMML) concept  with deep GNNs  design. Both approaches are prevalent in state-of-the-art (SOTA) machine learning research, inspiring us to apply them to the joint analysis of large-scale multimodal biological datasets 3. As application examples, we first used the gene embeddings generated by MuSe-GNN to investigate crucial biological processes and causal networks for gene regulation in the human body. We also applied our model to analyze COVID and cancer datasets, aiming to unveil potential disease resistance mechanisms or complications based on specific differentially co-expressed genes. Lastly, we used gene embeddings from MuSe-GNN to improve the prediction accuracy for gene functions. Here genes are co-expressed means genes are connected with the same edge.

Given the lack of explicit metrics to evaluate gene embeddings, we proposed six metrics inspired by the batch effect correction problem  in single-cell data analysis. We evaluated our model using real-world biological datasets from one technique, and the benchmarking results demonstrated MuSe-GNN's significant improvement from **20.1%** to **97.5%** in comprehensive assessment. To summarize the advantages of our model, MuSe-GNN addresses the outlined problem about cross-data gene similarity learning and offers four major contributions: 1. Providing an effective representation learning approach for multi-structure biological data. 2. Integrating genes from different omics and tissue data into a joint space while preserving biological information. 3. Identifying co-locatedgenes with similar functions. 4. Inferring specialized causal networks of genes and the relationships between genes and biological pathways or between genes and diseases.

## 2 Related work

**Co-expression Network Analysis.** While direct attempts at joint analysis of gene functions across modalities are limited, there is relevant research in identifying correlation networks based on a single dataset. WGCNA  is a representative method that employs hierarchical clustering to identify gene modules with shared functions. However, as an early tool, WGCNA has restricted functionality. Its inference of co-expression networks necessitates more rigorous methods, and it cannot be directly applied to the analysis of multimodal biological data.

**Network Based Biological Representation Learning.** Apart from directly generating gene co-expression networks, learning quantitative gene representations in a lower dimensional space may better describe gene-gene relationships and facilitate downstream analyses. Gene2vec generates gene embeddings based on the co-expression network from a given database. However, it disregards the expression profile information and is based on the old Gene Expression Omnibus (GEO) up until 2017 . GIANT leverages Node2vec  and OhmNet  to learn gene representations from both single-cell and spatial datasets by constructing graphs and hypergraphs for training. However, this approach still over-compresses multimodal biological datasets by removing expression profiles. Moreover, their co-expression networks created by Pearson correlation have a high false positive rate . Additionally, some of the datasets used by GIANT are of low quality (see Appendix A). There are also methods sharing a similar objective of learning embeddings from other datasets. GSS  aims to learn a set of general representations for all genes from bulk-seq datasets  using Principal Component Analysis (PCA) and clustering analysis. However, it is for bulk-seq data and cannot be directly applied to single-cell datasets from different tissues. Gemini  focuses on integrating different protein function networks, with graph nodes representing proteins rather than genes.

**Graph Transformer.** In the deep learning domain, Transformer [95; 100] is one of the most successful models, leveraging seq2seq structure design, multi-head self-attention design, and position encoding design. Many researchers have sought to incorporate the advantages of Transformer to graph structure learning. TransformConv  introduces a multi-head attention mechanism to the graph version of supervised classification tasks and achieved significant improvements. MAGNA  considers higher-level hop relationships in graph data to enhance node classification capabilities. Graphomer  demonstrates the positive impact of the Transformer structure on various tasks

Figure 1: The workflow of MuSe-GNN, the visualization of gene embeddings, and the problems of two existing methods, GIANT and Gene2vec. **(a)** The process of learning gene embeddings by MuSe-GNN. Here we highlight the difference between single-cell data and spatial data, and the major applications of gene embeddings. Each spot from single-cell data represents one cell, while each spot from spatial data represents a mixture of cells. **(b)** UMAPs  for the gene embeddings of MuSe-GNN, Gene2vec and GIANT. They are colored by datasets. Based on UMAPs we can conclude that both Gene2vec and GIANT failed to learn the gene similarity based on the datasets from the same tissue, while MuSe-GNN produces meaningful embeddings agnostic to datasets.

using data from the Open Graph Benchmark Large-Scale Challenge , which is further extended by GraphomerGD . Recently, GPS  proposes a general Graph Transformer (GT) model by considering additional encoding types. Transformer architecture also contributes solutions to several biological questions . scBERT  generates gene and cell embeddings using pre-training to improve the accuracy of cell type annotations. The substantial impact of these efforts highlights the crucial contribution of the Transformer architecture to graph data learning.

## 3 Methods

In the following sections of introducing MuSe-GNN, we will elaborate on our distinct approaches for graph construction that utilize multimodal biological data, followed by an explanation of our weight-sharing network architecture and the elements of the final loss function.

### Preliminaries

**GNN.** GNNs aim to learn the graph representation of nodes (features) for data with a graph structure. Modern GNNs iteratively update the representation of a node by aggregating the representations of its \(k\)-order neighbors (\(k 1\)) and combining them with the current representation. As described in , considering a graph \(G=\{V,E\}\) with nodes \(V=\{v_{1},v_{2},...,v_{n}\}\), the AGGREGATE-COMBINE update for node \(v_{i}\) is defined as:

\[a_{i}^{(l+1)}=^{(l+1)}(\{h_{j}^{(l)}:j(v_{i})\});h_{i}^{(l+1)}=^{(l+1)} (h_{i}^{(l)},a_{i}^{(l+1)}), \]

where \((v_{i})\) represents the neighbors of node \(v_{i}\) in the given graph, and \(h_{i}^{(l)}\) and \(h_{i}^{(l+1)}\) represent the node representation before and after updating, respectively.

**Problem Definition.** We address the gene embeddings generation task by handling multimodal biological datasets, denoted as \(=(\{V_{i},E_{i}\})_{i=1}^{T}\). Our goal is to construct a model \((,)\), designed to yield gene embeddings set \(=\{e_{1},...,e_{T}\}=(,)\). In this context, \(\) represents the input, \(\) represents the parameters, and \(\) represents the output. In other words, we aim to harmonize gene information from diverse modalities within a unified projection space, thereby generating consolidated gene representations.

### Graph construction

Before constructing gene graphs, our first contribution involves the selection of highly variable genes (HVGs) for each dataset. These HVGs constitute a group of genes with high variance that can represent the biological functions of given expression profiles. Moreover, considering co-expression networks is important for gene representation learning because it allows us to characterize gene-gene relationships. As sequencing depth, or the total counts of each cell, often serves as a confounding factor in the co-expression networks inference , we employ two unique methodologies, scTransform  and CS-CORE , to process scRNA-seq and scATAC-seq data, thus creating gene expression profiles and co-expression networks unaffected by sequencing depth. For spatial transcriptomic data, our focus is on genes displaying spatial expression patterns. We use SPARK-X  to identify such genes and then apply scTransform and CS-CORE. For detailed algorithmic information regarding these methods, please see Appendix B. Additionally, we demonstrate the immunity of CS-CORE to batch effects when estimating gene-gene correlations in Appendix C. In all our generated graphs (equivalent to co-expression datasets), nodes represent **genes** and edges represent **co-expression** relation of genes.

### Cross-Graph Transformer

To capitalize on the strengths of the Transformer model during our training process, we integrate a graph neural network featuring a multi-head self-attention design , called TransformerConv, to incorporate co-expression information and generate gene embeddings. Details of TransformerConv can be found in Appendix B.4. Incorporating multimodal information can estimate more accurate gene embeddings, supported by Appendix D. The cross-graph transformer can efficiently learn gene embeddings containing gene functions across different graphs, advocated by the comparison of different network structure choices in Appendix E.1.

**Weight sharing.** Given the variability among multimodal biological datasets, we employ a weight-sharing mechanism to ensure that our model learns shared information across different graphs, representing a novel approach for learning cross-graph relationships. We also highlight the importance of weight-sharing design in Appendix E.1.

**Datasets & Modalities Graph Transformer.** Drawing inspiration from the hard weight-sharing procedure , we not only employ dataset-specific Graph Transformer (GT) layers \(L_{1},L_{2},...,L_{n}\) for each graph (\(G_{1},G_{2},...,G_{n}\)) from the same modality \(m\), but also connect all these dataset-specific layers to a set of shared GT layers, denoted as \(D_{m}\). This design showcases our novel approach to incorporating weight-sharing into the GT framework. The forward process of MuSe-GNN, given dataset \(i\) with network parameter \(_{*}\), is defined as follows:

\[X_{i}^{}=D_{m}(L_{i}(G_{i};_{L_{i}});_{D_{m}}). \]

**Datasets Decoder.** Here we propose a dataset-specific decoder structure based on Multi-layer Perceptrons (MLP). This decoder model is crucial in reconstructing the co-expression relationships among different genes, showcasing our inventive use of MLP for this purpose. Given a graph \(G_{i}\) and its corresponding gene embedding \(e_{i}\), the decoding process of MuSe-GNN, with network parameter \(_{dec,i}\), is defined as follows:

\[E_{rec}=(e_{i}e_{i}^{T};_{dec,i}), \]

where \(E_{rec}\) represents the reconstructed co-expression network.

### Graph Reconstruction Loss (\(_{}\))

Within a single graph, we implement a loss function inspired by the Graph Auto-encoder (GAE) . This function is designed to preserve two key aspects: 1. the similarity among genes sharing common functions, and 2. the distinctions among genes with differing functions. This innovative use of a GAE-inspired loss function constitutes a significant contribution to the methodological design. For a graph \(G_{i}=\{V_{i},E_{i}\}\), the loss function for edge reconstruction is defined as:

\[& e_{i}=(\{V_{i},E_{i}\};_{ enc})=D_{m}(L_{i}(G_{i};_{L_{i}});_{D_{m}}),\\ & E_{rec}=(e_{i}e_{i}^{T};_{dec,i});E_{ rec}^{}=(E_{rec});E_{i}^{}=(E_{i}),\\ &_{}=-^{}|}_{t=1} ^{|E_{rec}^{}|}[E_{i}^{}[t] E_{rec}^{}[t]+(1-E_ {i}^{}[t])(1-E_{rec}^{}[t])], \]

where EncoderGNN and DecoderMlp represent the encoder and decoder parts of our model, respectively. \(_{}\) denotes the computation of binary cross entropy loss (BCELoss) for the given input data. \(E_{rec}\) is the reconstructed adjacency matrix and \(|E_{rec}^{}|\) is the length of its flatten version. Further justification of the model design can be found in Appendix F.

Figure 2: The overall model architecture and the design of loss functions for MuSe-GNN. The color of nodes in the green block represents common/different genes across two datasets. The brown block represents the network architecture of MuSe-GNN, and the blue block represents different loss function components of MuSe-GNN. The color gradients of the left two matrices represent different gene expression levels.

### Weighted-similarity Learning (\(_{}\))

To integrate shared biological information across graphs from disparate datasets, we fuse the reconstruction loss of the input graph structure with a cosine similarity learning loss. In this process, we treat common HVGs between each pair of datasets as anchors. Our aim is to maximize the cosine similarity (\((,)=}{|| ||_{2}:||||_{2}}\)) for each common HVG across two arbitrary datasets (represented by the yellow blocks in Figure 2), utilizing their gene embeddings. However, in practice, different common HVGs may have different levels of functional similarity in two datasets, which is hard to be directly quantified. Consequently, we employ the shared community score as an indirect measurement, which is incorporated as a weight for the cosine similarity of different common HVG pairs within the final loss function. Considering two graphs \(G_{i}=\{V_{i},E_{i}\}\) and \(G_{j}=\{V_{j},E_{j}\}\), and one of their shared genes \(g\), we identify the co-expressed genes of the given gene \(g\) in both datasets, denoted as \(N_{ig}\) and \(N_{jg}\). Thus, the weight \(_{ijg}\) for gene \(g\) can be expressed as follows:

\[_{ijg}= N_{jg}|}{|N_{ig} N_{jg}|}. \]

We can iterate over all shared genes from 1 to \(n\) between these two graphs, ultimately yielding a vector as \(_{ij}=[_{ij1},..,_{ijn}]\). This vector encapsulates the community similarity between the two graphs across all common HVGs. We can then modify the cosine similarity of various gene pairs by first multiplying this vector with cosine similarities and then summing the resultant values across all genes. The negation of the outcome is our final weighted similarity loss, denoted as \(_{}\). The ablation test for weighed similarity loss can be found in Appendix E.1. More detailed explanations and evidence supporting this design in multimodal conditions can be found in Appendix G.

### Self-supervised Graph Contrastive Learning (\(_{}\))

Specifically, when integrating multimodal biological data, we employ the contrastive learning strategy  to ensure that functionally similar genes are clustered together as closely as possible, while functionally different genes are separated apart from each other. We utilize Information Noise Contrastive Estimation (InfoNCE) as a part of our loss function to maximize the mutual information between the anchor genes and genes with the same functions. This loss is applicable to different genes in two arbitrary graphs during the training process. In general, if we represent the embeddings of \(N\) genes as \(_{N}=\{e_{1},...,e_{N}\}\), InfoNCE is designed to minimize:

\[_{}=-[ /)}{_{i=0}^{K}(e k_{i}/)}], \]

where samples \(\{k_{0},k_{1},k_{2}...\}\) compose a set of gene embeddings known as keys of one dictionary and \(e\) is a query gene embedding. \(k_{+}\) represents a positive sample of \(e\) and \(k_{i}\) denotes a negative sample of \(e\). Equation 6 can be interpreted as a log loss of a \((K+1)\)-way Softmax classifier, which attempts to classify \(e\) as \(k_{+}\). \(\) is a temperature parameter. \(\) is set to 0.07 referenced in MoCo .

### Final Loss Function

In summary, the training objective of MuSe-GNN for graph \(i\) comprises three components:

\[_{e_{i},e_{j}}&_{}(_{i}(e_{i}e_{i}^{T}),E_{i})-[(e_{i}[ _{ij}],e_{j}[_{ij}])_{ij}^{T}]\\ &+_{c}_{}(e_{i}[_{i}]  e_{j}[_{j}],e_{i}[_{(i)}] e _{j}[_{(j)}]), \]

where \(_{ij}\) denotes the index set for common HVGs, \(_{i}\) represents the index set for different HVGs in graph \(i\), and \(_{(i)}\) indicates the index set for neighbors of \(_{i}\) in graph \(i\). To expedite the training process and conserve memory usage, we sample graph \(j\) for each graph \(i\) during model training. We also employ multi-thread programming to accelerate the index set extraction process. \(_{c}\) is the weight for InfoNCE loss. All of the components in MuSe-GNN are supported by ablation experiments in Appendix E.1. Details of hyper-parameter tuning can be found in Appendix E.2.

## 4 Experiments

**Datasets & Embeddings generation.** Information on the different datasets used for different experiments is included at the beginning of each paragraph. The training algorithm of our modelis outlined in Algorithm 1. We stored the gene embeddings in the AnnData structure provided by Scanpy . To identify groups of genes with similar functions, we applied the Leiden clustering algorithm  to the obtained gene embeddings. Details can be found in Appendix E.4.

**Evaluation metrics.** For the benchmarking process, we used six metrics: edge AUC (AUC) , common genes ASW (ASW) , common genes graph connectivity (GC) , common genes iLISI (iLISI) , common genes ratio (CGR), and neighbors overlap (NO) to provide a comprehensive comparison. Detailed descriptions of these metrics can be found in Appendix H. We computed the metrics for the different methods and calculated the average rank (Avg Rank \(\)). Moreover, to evaluate the model performance improvement, we applied min-max scaling to every metric across different models and computed the average score (Avg Score \(\)).

**Baselines.** We selected eight models as competitors for MuSe-GNN. The first group of methods stems from previous work on learning embeddings for biomedical data, including Principal Component Analysis (PCA)  used by GSS, Gene2vec, GIANT (the SOTA model for gene representation learning), Weight-sharing Multi-layer Auto-encoder (WSMAE) used by  and scBERT (the SOTA model with pre-training for cell type annotation). The second group of methods comprises common unsupervised learning baseline models, including GAE, VGAE  and Masked Auto-encoder (MAE) (the SOTA model for self-supervised learning) . MuSe-GNN, GIANT, GAE, VGAE, WSMAE and MAE have training parameter sizes between 52.5 and 349 M, and all models are tuned to their best performance. Details are shown in Appendix E.2.

**Biological applications.** For the pathway analysis, we used Gene Ontology Enrichment Analysis (GOEA)  to identify specific biological pathways enriched in distinct gene clusters with common functions. Moreover, we used Ingenuity Pathway Analysis (IPA)  to extract biological information from the genes within various clusters, including causal networks  and sets of diseases and biological functions. Biological pathways refer to processes identified based on the co-occurrence of genes within a particular cluster. The causal network depicts the relationships between regulatory genes and their target genes. Disease and biological function sets facilitate the discovery of key processes and complications associated with specific diseases. Using gene embeddings also improves the performance of models for gene function prediction. To visualize gene embeddings in a low-dimensional space, we utilized Uniform Manifold Approximation and Projection (UMAP) .

### Benchmarking Analysis

We executed each method 10 times by using the same setting of seeds to show the statistical significance based on datasets across different tissues. The performance comparison of nine gene embedding methods is presented in Tables 1 and 14. Based on these two tables, MuSe-GNN outperformed its competitors in terms of both average ranks and average scores across all the tissues. Based on Table 1, for major tissues, such as heart and lung, MuSe-GNN's performance was 20.1% higher than the second-best method and 97.5% higher than the second-best method in heart and lung tissue, respectively. According to Appendix E.3, MuSe-GNN's stability was also demonstrated through various metrics by comparing standard deviations, including AUC, GC, and NO. In contrast, methods such as Gene2vec, GAE, VGAE, MAE and scBERT exhibited significant instability in their evaluation results for kidney or thymus. Consequently, we concluded that MuSe-GNN is the best performing model for learning gene representation based on datasets from different tissues, making it applicable to learn gene embeddings from diverse multimodal biological data.

### Analysis of Gene Embeddings from Multimodal Biological Data

In Figure 3, we displayed the integration results for multimodal biological data from Humans. Figure 3 (a) and (b) demonstrated that MuSe-GNN could successfully integrate genes from different modalities into a co-embedded space, allowing us to identify functional groups using the Leiden algorithm shown in Figure 3 (c). Furthermore, Figure 3 (d) revealed that most of the clusters in (c) were shared across different modalities. We also identified three significant functional groups in Figure 3 (a): the nervous system (predominantly composed of the cerebrum and cerebellum ), the cardiovascular system (mainly composed of heart, lung, and kidney ), and the immunology system (primarily consisting of spleen, liver, and peripheral blood mononuclear cells (PBMC) ). All systems are important in regulating the life activities of the body. We also uncovered a pre-epigenetics group (mainly consisting of scATAC-seq data without imprinting, modification, or editing), emphasizing the biological gap existing in multi-omics and the importance of post-transcriptional regulation.

Using GOEA, we could identify significant pathways enriched by different co-embedded gene clusters. For instance, Figure 3 (d) displayed the top 5 pathways in an immunology system cluster. The rank was calculated based on the negative logarithm of the false discovery rate. Since all top pathways were related to immunological defense and response, it further supported the accuracy of our embeddings in representing gene functions. For our analysis of shared transcription factors and major pathways across all the tissues, please refer to Appendix I. For our analysis of multi-species gene embeddings, please refer to Appendix J.

### Analysis of Gene Embeddings for Diseases

We generated gene embeddings for human pancreas cells from samples with and without SARS-CoV-2 infection, as depicted in Figure 4 (a) and (b). We identified specific genes from COVID samples that did not align with control samples, which piqued our interest. These genes, highlighted by a red circle in Figure 4 (c), could be interpreted as differentially functional genes in diseased cells.

We conducted GOEA for the genes of interest and discovered a close relationship among these gene enrichment results and the top 5 pathways associated with immune activity. These results are displayed in Figure 4 (d). For the genes within our target cluster, we utilized IPA to identify the Entrez name of these genes, and 90.3% (122/135) genes in our cluster are related to immunoglobulin.

   Methods & Heart & Lung & Liver & Kidney & Thymus & Spleen & Pancress & Cerebrum & Cerebellum & PBMC \\  PCA & 0.52 & 0.48 & 0.56 & 0.47 & 0.56 & 0.60 & 0.51 & 0.62 & 0.53 & 0.51 \\ Gene2vec & 0.40 & 0.37 & 0.33 & 0.29 & 0.21 & 0.31 & 0.24 & 0.27 & 0.31 & 0.19 \\ GIANT & 0.50 & 0.40 & 0.33 & 0.38 & 0.58 & 0.33 & 0.56 & 0.29 & 0.28 & 0.28 \\ WSMAE & 0.50 & 0.47 & 0.54 & 0.46 & 0.57 & 0.53 & 0.52 & 0.55 & 0.59 &We could also infer the causal relationship existing in the gene regulatory activity of the immune system. For example, Figure 4 (e) showed a causal network inferred by IPA based on our genes cluster. PARP16, as an enzyme, can regulate ERN1 and EIF2AK3, and certain pathways are also related to this causal network. Moreover, we also showed the relation between the set of genes and Disease & Bio functions in Figure 4 (f). We identified top related Diseases & Bio functions ranked by negative logarithm of p-value, and all of these diseases could be interpreted as complications that may arise from new coronavirus infection . Our extra analyses for lung cancer data can be found in Appendix K.

Figure 4: Gene embeddings from COVID samples and healthy samples. **(a)** represents the UMAPs of gene embeddings colored by functional groups. **(b)** represents the UMAPs of gene embeddings colored by datasets. **(c)** represents the gene embeddings colored by the conditions, and the red circle reflects the differential co-expression genes. **(d)** shows the top6 pathways related to the genes in the special cluster discovered by GOEA. **(e)** represents the causal network existing in the special cluster discovered by IPA. **(f)** represents the top diseases & biological functions discovered by IPA.

Figure 3: Gene representation learning results for multimodal biological data. **(a)** represents the UMAPs of gene embeddings colored by tissue type and highlighted by biological system. **(b)** represents the UMAPs of gene embeddings colored by omics type. **(c)** represents the UMAPs of gene embeddings colored by common function groups. **(d)** is a Sankey plot  to show the overlap of different modalities in the same clusters. **(e)** shows the top5 pathways related to the genes in the special cluster discovered by GOEA. The bubble plots in this paper were created based on ggplot2 .

### Analysis of Gene Embeddings for Gene Function Prediction.

Here we intend to predict the dosage-sensitivity of genes related to genetic diagnosis (as dosage-sensitive or not) . We used MuSe-GNN to generate gene embeddings for different datasets based on an unsupervised learning framework and utilized the gene embeddings as training dataset to predict the function of genes based on k-NN classifier. k-NN classifier is a very naive model and can reflect the contribution of gene embeddings in the prediction task.

In this task, we evaluated the performance of MuSe-GNN based on the dataset used in Geneformer [90; 31], comparing it to the prediction results based on raw data or Geneformer (total supervised learning). As shown in Table 2, the prediction accuracy based on gene emebddings from MuSe-GNN is the highest one. Moreover, the performance of gene embeddings from MuSe-GNN is better than Geneformer, which is a totally supervised learning model. Such finding proves the advantages of MuSe-GNN in the application of gene function prediction task. Further application analysis can be found in Appendix L.

## 5 Conclusion

In this paper, we introduce MuSe-GNN, a model based on Multimodal Machine Learning and Deep Graph Neural Networks, for learning gene embeddings from multi-context sequencing profiles. Through experiments on various multimodal biological datasets, we demonstrate that MuSe-GNN outperforms current gene embedding learning models across different metrics and can effectively learn the functional similarity of genes across tissues and techniques. Moreover, we performed various biological analyses using the learned gene embeddings, leveraging the capabilities of GOEA and IPA, such as identifying significant pathways, detecting diseases, and inferring causal networks. Our model can also contribute to the study of the pathogenic mechanisms of diseases like COVID and lung cancer, and improve the prediction performance for gene functions. Overall, the gene representations learned by MuSe-GNN are highly versatile and can be applied to different analysis frameworks.

At present, MuSe-GNN does not accept graphs with nodes other than genes as input. In the future, we plan to explore more efficient approaches for training large models related to Multimodal Machine Learning and extend MuSe-GNN to a more general version capable of handling a broader range of multimodal biological data.

## 6 Acknowledgements

This research was supported in part by NIH R01 GM134005, R56 AG074015, and NSF grant DMS 1902903 to H.Z. We appreciate the comments, feedback, and suggestions from Chang Su, Zichun Xu, Xinning Shan, Yuhan Xie, Mingze Dong, and Maria Brbic.