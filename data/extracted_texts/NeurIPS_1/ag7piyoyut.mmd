# Incorporating Surrogate Gradient Norm to Improve Offline Optimization Techniques

Manh Cuong Dao, Phi Le Nguyen

Hanoi University of Science and Technology

Cuong.DM242249M@sis.hust.edu.vn,lenp@soict.hust.edu.vn

Thao Nguyen Truong

National Institute of Advanced Industrial Science and Technology

nguyen.truong@aist.go.jp

Trong Nghia Hoang

Washington State University

trongghia.hoang@wsu.edu

Corresponding authors: Manh Cuong Dao, Trong Nghia Hoang.

###### Abstract

Offline optimization has recently emerged as an increasingly popular approach to mitigate the prohibitively expensive cost of online experimentation. The key idea is to learn a surrogate of the black-box function that underlines the target experiment using a static (offline) dataset of its previous input-output queries. Such an approach is, however, fraught with an out-of-distribution issue where the learned surrogate becomes inaccurate outside the offline data regimes. To mitigate this, existing offline optimizers have proposed numerous conditioning techniques to prevent the learned surrogate from being too erratic. Nonetheless, such conditioning strategies are often specific to particular surrogate or search models, which might not generalize to a different model choice. This motivates us to develop a model-agnostic approach instead, which incorporates a notion of model sharpness into the training loss of the surrogate as a regularizer. Our approach is supported by a new theoretical analysis demonstrating that reducing surrogate sharpness on the offline dataset provably reduces its generalized sharpness on unseen data. Our analysis extends existing theories from bounding generalized prediction loss (on unseen data) with loss sharpness to bounding the worst-case generalized surrogate sharpness with its empirical estimate on training data, providing a new perspective on sharpness regularization. Our extensive experimentation on a diverse range of optimization tasks also shows that reducing surrogate sharpness often leads to significant improvement, marking (up to) a noticeable \(9.6\%\) performance boost. Our code is publicly available at [https://github.com/cuong-dm/IGNITE](https://github.com/cuong-dm/IGNITE).

## 1 Introduction

A central task in numerous scientific disciplines is to optimize for some material configuration that maximizes a certain utility metric. Previously, this would incur an expensive and repetitive experiment process that requires a huge amount of human-labor. To bypass such inefficiencies, a data-driven approach  has recently been adopted. Instead of laboring on a new set of expensive on-demand experimentation for each new optimization task, we can leverage past experimentation data to build a parametric model that predicts the outcome of the experiments themselves. Its parameters are tuned to fit past experimental data and then fixed while optimizing for the best input.

However, in most applications, offline data is rarely representative of the entire input space. As a result, the surrogate model's prediction is often not accurate outside the offline data regime, potentially overestimating the outputs at sub-optimal input candidates. To mitigate this, existing offline optimizers have introduced numerous regularizing strategies for either the surrogate or the search models. For example,  and  regularize their surrogate models so that their predictions at inputs outside the offline data regime are pushed down or pushed towards a constant value. Alternatively,  and  restrict their search models to regions having certain domain-specific properties under which sampled inputs probably have high performance.

These strategies therefore depend on the specifics of either the surrogate- or the search procedures to characterize the out-of-distribution regions or the desirable domain-specific properties. Consequently, their regularization might not extend to out-of-distribution regions which are not sufficiently specified. For example, COMs  uses an ad-hoc specification that characterizes the out-of-distribution region in terms of inputs that are reached during the first few iterations of gradient ascent on an un-regularized surrogate. This only characterizes a local sub-region of a broader out-of-distribution data regime.

To mitigate such limitations in the regularizing behaviors of prior work, we instead aim to investigate a more generic approach that is independent of the specifics of the search or surrogate procedures. For instance, instead of regularizing the behavior of the model on certain input regions, we could impose constraints on the geometries of its loss landscape such as requiring it to be in a parameter regime that uniformly produces low loss values . Such regularizing strategies can, therefore, be incorporated into existing offline optimizers as an additional regularizer to improve their performance. To substantiate this idea, we have made the following technical contributions:

**1.** We develop a model-agnostic regularizer (for surrogate training) based on a notion of model sharpness2. This is characterized in terms of the surrogate's maximum output change under low-energy parameter perturbation (i.e., norm-bound perturbation) (Section 3.1). Intuitively, suppose a surrogate's prediction does not change substantially within a perturbation neighborhood (i.e., via adding perturbation to its parameters) that contains the oracle, its predictions are likely to be close to those of the oracle (see Fig. 1). As such, minimizing this sharpness measure can help suppress the erratic behavior of the surrogate model at out-of-distribution input.

**2.** We adopt a practical approximation that interestingly reduces the above surrogate sharpness measurement to a function of the surrogate's gradient norm. The surrogate training can then be augmented into a constrained optimization task whose constraint imposes a user-specified threshold on the surrogate's gradient norm. We can then solve it to acquire the optimally regularized surrogate using existing constrained optimization solvers. The high-level pseudo-code of our proposed algorithms which incorporate surrogate gradient norms to improve existing offline optimization techniques (**IGNITE**) is detailed in Algorithm 1 (Section 3.2).

**3.** We develop a detailed theoretical analysis to show that reducing surrogate sharpness on the offline dataset provably reduces its generalized sharpness on unseen data. Our analysis extends existing theories  from bounding generalized prediction loss (on unseen data) with loss sharpness to bounding the worst-case generalized surrogate sharpness with its empirical estimate on training data, providing a new perspective on sharpness regularization (Section 4).

**4.** We demonstrate empirically that incorporating the proposed model-agnostic regularizer into existing offline optimizers as an additional conditioning component often results in significant improvement over existing offline optimizers in most cases. This sets the first step towards a new, synergistic research direction in offline optimization that can potentially support and complement both existing and future work (Section 5).

For interested readers, a concise review of existing literature is also provided in Section 2.

## 2 Problem Definition and Related Works

In this section, we will concisely review the preliminaries of offline optimization. Section 2.1 provides a mathematical formulation of offline optimization, and Section 2.2 summarizes prior works.

### Problem Definition

Offline optimization is a computational approach to a variety of material engineering tasks that aim to find a material construction or design that maximizes certain desirable properties. Mathematically, we assume that there is an oracle function \(g()\) that maps from a material design \(\) to an overall utility \(z=g()\) of its property measurements; and we need to find its maxima:

\[_{*}  *{arg\,max}_{}\,g()\;. \]

However, the key challenge here is that \(g()\) is inaccessible. Instead, we only have access to an offline dataset of observations \(=\{(_{i},z_{i})\}_{i=1}^{n}\) where \(z_{i}=g(_{i})\), which denote the past input-output queries extracted from \(g()\) in previous experiments. A direct approach to this problem is to learn a surrogate \(g(;_{*})\) of \(g()\) via fitting its parameter \(_{*}\) to the offline dataset,

\[_{*}  *{arg\,min}_{}_{ }()  *{arg\,min}_{}_{i=1}^{n} g(_{i};),\;z_{i}\;, \]

where \(\) denotes a parameter candidate of the surrogate and \((g(;),z)\) denotes the prediction loss of \(g(.;)\) on \(\) if its oracle output is \(z\). The (oracle) maxima of \(g()\) is then approximated via,

\[_{*}  *{arg\,max}_{}\;g(;_{*})\;. \]

Suppose the surrogate \(g(;_{*})\)'s prediction is sufficiently accurate over the entire input space, solving Eq. (3) is all we need. However, in most cases, \(g(;_{*})\) often predicts erratically outside the offline data regime, which in turn misleads the optimization towards sub-optimal candidates. To mitigate this, numerous surrogate or search regularizers have been proposed, as summarized next.

### Related Works

Most existing offline optimization methods have focused on regularizing either the search or the (surrogate) training procedures. The main focus is to either (1) avoid exploring input regions where the surrogate's prediction is not reliable or (2) regularize the prediction behavior of the surrogate at out-of-distribution input regimes. For example, to regularize the surrogate's prediction,  uses input candidates found during the first few iterations of gradient updates on un-regularized models to characterize the out-of-distribution regime. The surrogate can then be re-trained with an additional regularizer that penalizes high-value predictions at those sampled input candidates.

Alternatively,  maximizes the normalized data likelihood to reduce prediction uncertainty, which also helps suppress erratic prediction at out-of-distribution regime. Existing techniques in model pre-training and adaptation  or transfer learning via co-teaching  can also be leveraged to enforce criteria of local smoothness that encodes a preference for conservative prediction to avoid overestimating the oracle output. Otherwise, to regularize the search procedure,  and  focus instead on learning a generative model of input candidate conditioned their oracle performance. Input candidates that likely achieve high performance can then be synthesized via conditioning the generative procedure on high-value oracle output.  characterizes such conditioned distribution via an adversarial zero-sum game.  learns a direct inverse mapping from the performance output to the input design using conditional generative adversarial network .

Despite their reported successes, these approaches are still limited by their ad-hoc characterization of the out-of-distribution regime. As discussed previously in Section 1, the existing characterization of out-of-distribution input is often based on the specifics of either the surrogate or the search procedures, which are not guaranteed to sufficiently characterize the entire out-of-distribution data regime. This motivates us to develop a more generic out-of-distribution characterization (Section 3) that is external to both the search and surrogate models. Such an approach can be readily incorporated into most existing offline optimizers to boost their performance (Section 5).

## 3 Surrogate Regularization with Sharpness Constraint

This section introduces an additional constraint that transforms the original surrogate optimization in Eq. (2) (Section 3.1) into a constrained optimization problem (COP). The constraint imposesa user-specified upper-bound on the sharpness of the surrogate. Our proposed formulation draws inspiration from a prior work  that aims to minimize the sharpness of the loss function to improve generalization. However, unlike the original work in , where the sharpness concept is applied to the loss function, we adapt it for the surrogate's prediction. We find it more suitable since offline optimization's search procedure operates on the surrogate landscape instead of the loss landscape. Moreover, while minimizing loss sharpness  can ensure low error for single predictions in the OOD regime, errors may accumulate over consecutive predictions in a gradient-based search. Our insight in Section 3.1 (Fig. 1) suggests that such error accumulation can be mitigated by keeping the surrogate sharpness small during training. Furthermore, we show that the sharpness can be practically approximated in terms of the surrogate's gradient norm, which is more tractable. This allows for direct adoption of existing constrained optimization algorithms  to effectively solve for the desired optimally regularized surrogate (Section 3.2).

### Surrogate Sharpness

Suppose the oracle lies within the parametric family of the surrogate, there must exist a perturbation neighborhood of the surrogate's parameters that contains the oracle. That is, the oracle can be obtained by adding to the surrogate's parameters a noise vector in this neighborhood. Now, suppose the predictions do not change substantially across the models (including both the oracle and surrogate) in the perturbation neighborhood; the surrogate's predictions (and optimizers) must be close to those of the oracle (see Fig. 1). Motivated by this insight, we consider a potential approach to mitigate the erratic prediction of the surrogate, which is to ensure that its worst-case prediction change across the perturbation neighborhood is sufficiently small. This is formalized below:

\[_{}()  _{\|\|_{2}\ \ }|}{ }g(;+)-}{}g(;) |\, \]

where \(\|\|_{2}\) denotes the \(_{2}\)-norm, and \(>0\) bounds the maximum norm of the perturbation, which defines the perturbation neighborhood and can be selected via hyper-parameter tuning (see Section 5.1 and Appendix G.4). To ease the notation, we will omit the subscript and use \(\|\|\) to consistently denote the \(_{2}\) norm in the rest of this manuscript. We will also refer to \(_{}()\) in Eq. (4) as the generalized surrogate sharpness, which can be used to regularize surrogate training,

\[_{*}  _{}_{}() _{}()\ \ \ \ ^{}\, \]

where \(^{}\) is a user-specified threshold. Solving Eq. (5) is non-trivial since \(_{}()\) is neither tractable nor differentiable. To sidestep this, we leverage a theoretical result that will be established later in Section 4, which (informally) states that with high confidence, the generalized surrogate sharpness

Figure 1: (a) Illustration of surrogate sharpness; (b) Illustration of surrogate sharpness-based offline optimization: Consider two surrogate parameters \(_{1}\) and \(_{2}\) where \(_{1}\) has a smaller sharpness than \(_{2}\). This means the predictions of the models in the perturbation neighborhood of \(_{1}\) will vary less than those of the models in the perturbation neighborhood of \(_{2}\). As such, if both neighborhoods contain the oracle, the prediction error \(d_{1}\) of \(_{1}\) is potentially smaller than the prediction error \(d_{2}\) of \(_{2}\). Consequently, the optimal value of \(g(;_{1})\) is closer to the oracle optimal value than \(g(;_{2})\)’s.

\(_{}()\) can be approximated with its empirical estimate \(_{}()\) in Eq. (16),

\[_{}()  ( G()+^{2}_{}) (_{}()\;+\;()n\|\|^{2}}{n}}) )\;, \]

where \(G()\) and \(_{}\) denote the norm of the expected (parameter) gradient of the surrogate at \(\), and the largest eigenvalue of the (parameter) Hessian of the surrogate's expected prediction,

\[G()  \|}_{} _{}g(;)\| _{}\;\;_{}_{}(_{ _{}}^{2}\!\!}_{}g(;))\;. \]

When \(n\) is sufficiently large, \((()(n\|\|^{2})/n)^{}\) will be negligibly small. Then, suppose within the search region for \(\) (see Assumption 2), \(G()\) is bounded by a constant \(G\), we can enforce \(_{}()^{}=( G+(1/2)^ {2}_{})\) via constraining instead \(_{}()\),

\[_{*}  _{}_{}()_{}()\;\;\; \;\;. \]

To mitigate the non-differentiability of \(_{}()\), we further propose a practical approximation which reduces \(_{}()\) to a function of the surrogate's gradient norm \(\|_{}g(;)\|\), which is differentiable, allowing the above COP to be solved effectively with existing constrained optimization algorithms. This is discussed in the next section.

**Remark.** Eq. (4) is similar in spirit to the notion of loss sharpness  in which the same perturbation model is used to characterize the sharpness or sensitivity of the loss function, \(|_{}(+)-_{} ()|\), to small changes \(\|\|\) in the model weights \(\). Our work, however, sets a direct focus on the sensitivity or sharpness of the surrogate's prediction - Eq. (4) - which results in a better surrogate regularizer, leading to better empirical performance (see Section 5.3). It also requires a significant and non-trivial adaptation of the theories presented in , as detailed later in Section 4.

### Practical Algorithms

Let \(h(+)}_{ }[g(;+)]\) and \(h()}_{}[g( ;)]\). The surrogate sharpness can be approximated via the first-order Taylor expansion of \(h(+)\) at \(\):

\[_{}() = _{\|\|_{2}}|}_{}g(;+)- }_{}g(; )| \] \[= _{\|\|_{2}}h(+)-h()\;\;\;_{\|\|_{2}} _{}h()^{}\;,\]

Using the Cauchy-Schwartz inequality on the right-hand side of the above and noting that \(\) can be selected to make the equality happens,

\[_{}()  _{\|\|_{2}}|_{}h( )^{}|\;\;=\;\;_{\|\|_{2}} \|_{}h()\|\| \|\;\;=\;\;\|_{}h()\|\;. \]

Using the above approximation, the COP in Eq. (8) can be rewritten as

\[_{*}  _{}_{}()\|_{}h()\| \;\;\;\;\;. \]

which can be solved via optimizing the corresponding Lagrangian,

\[_{*} = _{}(,)\; \;\;\;(,)\;\;\; _{}()\;\;+\;\;(\|_{ }h()\|-)\;, \]

with \(>0\) denotes the Lagrange multiplier. This can be solved via our approach below.

**IGNITE.** We can optimize for both \(\) and \(\) using the basic differential multiplier method (BDMM) , which simultaneously gradient ascent for \(\) and gradient descent for \(\), resulting in the following update rules:

\[^{t+1} = ^{t}\;\;-\;\;_{}(_{}_{}^{t}\;\;+\;\; ^{t}_{}_{}h ^{t})\;, \] \[^{t+1} = ^{t}\;\;+\;\;_{}(\| _{}h(^{t})\|-)\;, \]where \(^{t}\) represents the surrogate's parameter estimate at iteration \(t\), \(^{t}\) is the Lagrange multiplier estimate at iteration \(t\), \(_{}\) is the step size for updating \(\), and \(_{}\) is the step size for updating \(\). We name this method **IGNITE**. We also conduct grid search to select the optimal value for \(\), as mentioned in Section 5.1.

**Remark.** As an alternative approach, we can also treat \(\) as a hyper-parameter and optimize for \(\) using gradient descent; we call this method **IGNITE-2**. The detailed algorithms, hyper-parameter selection, and experimental results of **IGNITE-2** are reported in Appendix G.2.

Both of the above methods require differentiating \(\|_{}h()\|\) with respect to \(\), which involves computing the expensive Hessian of \(h()\). Fortunately, this expensive computation can be avoided by using the gradient approximation technique detailed in Appendix F. To summarize, we provide a complete pseudo-code of **IGNITE** in Algorithm 1 whose steps \(3\)-\(8\) implement the approximation in Eq. (84) and Eq. (85) of Appendix F.

```
0: offline data \(=\{(_{i},z_{i})\}_{i=1}^{n}\); initial surrogate \(g(;^{(0)})\); no. of iterations \(T\); batch size \(m\); Lagrange multiplier \(\); perturbation radius \(\) and scalar \(r\); step sizes \(_{}\) and \(_{}\); threshold \(\).
1: Initialize \(^{(1)}^{(0)}\) and \(^{(1)}\)
2:for\(t 1:T\)do
3: Sample \(=\{(_{i},z_{i})\}_{i=1}^{m}\)
4: Compute \(_{i}=g(_{i};^{(t)})\) for \(i[m]\)
5: Compute \(g_{1}=m^{-1}_{i=1}^{m}_{}(_{i},z_{i})\)
6: Compute \(g_{2}=m^{-1}_{i=1}^{m}_{}_{i}\)
7: Compute \(}=^{(t)}+r g_{2}/\|g_{2}\|\)
8: Compute \(g_{3}=m^{-1}_{i=1}^{m}_{}g(_{i};})\)
9: Compute \(g^{(t)}=g_{1}+^{(t)} r^{-1}(g_{3}-g_{2})\)
10: Update \(^{(t+1)}^{(t)}-_{}g^{(t)}\)
11: Update \(^{(t+1)}^{(t)}+_{}(\|g_{2}\|-)\)
12:endfor
13:return learned surrogate \(^{(T+1)}\)
```

**Algorithm 1**IGNITE

## 4 Theoretical Analysis

In this section, we will provide a detailed theoretical analysis to substantiate our earlier (informal) statement in Eq. (6) that with high confidence, reducing the empirical sharpness \(_{}()\) on the offline data will also reduce its generalized sharpness \(_{}()\). We will show that this is true (see Theorem 1) under certain choices and mild assumptions of the surrogate model (see Assumptions 1 and 2).

**Assumption 1**.: The output of the above surrogate function \(g(;)\) is bounded within \(\).

**Assumption 2**.: \(_{}_{}^{2}[g(;)]>0\) for all \(\|\|\) for some \(>0\).

We note that the specific bound within \(\) in Assumption 1 is meant to ease the technical presentation of our theoretical analysis. Otherwise, it can be extended straightforwardly to any bounded functions. Furthermore, we also show below that it is indeed possible to find a non-trivial surrogate function that is bounded and satisfies Assumption 2.

**Theorem 1**.: _There exists \(>0\) and \(_{+}\), and a non-linear function \(r(;)\) such that,_

\[g(;)  r(;_{+})+-_{+} ^{}_{}r;_{+}+ -_{+}^{}_{}^{2}r;_{+}-_{+} \]

_satisfies Assumption 2 and is bounded on \(\{\|\|\}\). Detailed derivation of this theorem is deferred to Appendix A._

For such surrogate functions, their generalized sharpness can be upper-bound by a function of their empirical sharpness on the offline data. As detailed below, the bound depends on both the size of the surrogate \(()\) and the number \(n\) of offline data points.

**Theorem 2**.: _For any \(>0\), \(m=()\) and \(2/(m_{})^{2}>0\) with \(_{}\) being defined in Assumption 2, the following holds simultaneously for all \(g(.;)\) for which Assumption 2 is met,_

\[_{}() m_{}}2G() +_{}^{2}\] \[(_{}()+}(m(1+\|^{2}}{m^{2}}(1+})^{2})+P(n,m,))^{}) \]

_with probability at least \(1-\) over the random choice of the offline dataset, and with \(P(n,m,)=2(n/)+4(8n+4m)\). Detailed derivation of this theorem is deferred to Appendix E._

**Proof Sketch.** For clarity, we will provide below a proof sketch of Theorem 2, which highlights the key steps in our derivation. Due to limited space, the specific of each step is deferred to the Appendix E. First, we note that

\[_{}() = \] \[_{}() = \]

A relation between \(_{}()\) and \(_{}()\) can then be derived in three steps:

**1.** Upper-bound \(_{(0,^{2})}[F_{ }(+)]\) with a function of \(_{(0,^{2})}[F_{ }(+)]\). This can be achieved via a direct application of the PAC-Bayes bound  which views the perturbed model \(+\) as a random hypothesis sampled from the posterior \((,^{2})\) - see Appendix B.

**2.** Upper-bound \(_{(0,^{2})}[F_{ }(+)]\) with a function of \(_{}()\). This can be achieved using a similar proving technique adopted from  - see Appendix C.

**3.** Find \(>0\) such that \(_{}()\) can be upper-bounded with \(_{(0,^{2})}[F_{ }(+)]\) where \(\) is a small scaling factor. To achieve this, we will find the lower-bound for \(_{(0,^{2})}[F_{ }(+)]\) using the Taylor remainder theorem to expand it around \(\), which can be lower-bounded using the minimum eigenvalue of its Hessian at \(\). Using the same approach, we can upper-bound \(_{}()\) with the maximum eigenvalue of the same Hessian - see Appendix D.

Finally, we set \(\) so that the upper-bound of \(_{}()\) is smaller than the multiplication of \(\) with the lower-bound of \([F_{}(+)]\). To tighten the bound, we choose the smallest possible value of \(\) such that the bound still holds. Lining up the results of the above steps then shows that \(_{}()\) can then be bounded with a function of \(_{}()\). See Appendix E for a complete derivation.

**Remark.** Note that Theorem 2 is more general than its informal statement in Eq. (6), which can be reproduced by choosing \(^{2}=2/(m_{})\) in Eq. (16) to make the bound tightest.

## 5 Experiments

This section evaluates the efficacy of our proposed method **IGNITE** in improving state-of-the-art offline optimizers. We describe our experiment settings in Section 5.1 and report detailed empirical results in Section 5.2. We also provide additional ablation studies of our method in Section 5.3.

### Benchmarks, Baselines, and Evaluation

**Benchmark Tasks.** Our explorations focus on four real-world tasks from Design-Bench3, covering both discrete (**TF-Bind-8** and **TF-Bind-10**) and continuous domains (**Ant Morphology** and **D'Kitty Morphology**).

**Baselines.** We meticulously curated a diverse set of 11 widely acknowledged offline optimizers for comparative analysis. This ensemble comprises **BO-qEI**, **CbAS**, **RoMA**, **ICT**,

**CMA-ES**, **COMs**, **MINs**, **REINFORCE**, and three variations of gradient ascent (**GA**, **ENS-MIN**, **ENS-MEAN**), corresponding to vanilla gradient ascent, the min ensemble of gradient ascent, and the mean ensemble of gradient ascent, respectively.

**Evaluation Protocol.** To ensure a comprehensive assessment, we follow the methodology in . Each method generates \(128\) optimized design candidates evaluated by the oracle function. The candidates' performances are ranked, and the \(50\)-th, \(75\)-th, and \(100\)-th percentile levels are recorded. All results are averaged over \(16\) independent runs to ensure reliability.

**Hyper-parameter Configuration.** For each baseline algorithm, we carefully configure optimal hyper-parameters as outlined in . Our method **IGNITE** introduces five additional hyper-parameters: \(\), \(\), \(r\), \(_{}\), and \(\). The hyper-parameter \(\), an initial value for the regularizer coefficient, is set to \(0.01\) through a grid search within \(\{0.0001,0.001,0.01\}\). The hyper-parameters \(\) and \(r\) are chosen from \(\{0.01,0.05,0.1,0.2\}\), with \(\) set to 0.05 and \(r\) set to 0.05 for **IGNITE**. Additionally, **IGNITE** uses \(_{}=1e-3\) and \(=0.1\), which are determined via the experiments in Section 5.3.

### Results and Discussion

In this section, we presented the percentage improvement over baseline performance attained by **IGNITE** when it is applied to existing baselines. We have evaluated this at the \(50\)-th, \(80\)-th, and \(100\)-th percentile levels. However, due to limited space, we only report results of the \(100\)-th percentile level in the main text. The other results are instead deferred to Appendix G.3.

**Results on Continuous Tasks:** The first two columns of Table 1 show that out of \(22\) cases involving \(11\) baseline algorithms across \(2\) tasks, the **IGNITE** regularizer enhances baseline performance in \(18\) cases, with improvements reaching up to \(9.6\%\). In only \(1\) out of \(22\) instances **IGNITE** slightly decreases performance by \(0.2\%\), which is negligible. Even in cases where performance is not improved, **IGNITE** reduces the variance in results from \(0.2\%\) to \(0.1\%\) for the **CMA-ES** baseline on the **D'Kitty Morphology** task. Additionally, **IGNITE** helps establish new state-of-the-art (SOTA)

    &  &  &  &  \\  &  &  &  &  &  \\   \(\)**(best)** & \(0.565\) & \(0.884\) & \(0.565\) & \(0.884\) & \(0.565\) & \(0.884\) & \\   & Base & \(0.255 0.036\) & \(0.546 0.208\) & \(0.929 0.043\) & \(0.635 0.028\) & \\  & **IGNITE** & \(0.282 0.021\) & \(+2.7\%\) & \(0.642 0.160\) & \(+9.6\%\) & \(0.944 0.030\) & \(+1.5\%\) & \(0.670 0.060\) & \(+3.5\%\) \\   & Base & \(0.303 0.027\) & \(0.881 0.016\) & \(0.980 0.016\) & \(0.651 0.033\) & \\  & **IGNITE** & \(0.320 0.044\) & \(+1.7\%\) & \(0.886 0.017\) & \(+0.5\%\) & \(0.985 0.010\) & \(+0.5\%\) & \(0.653 0.043\) & \(+0.2\%\) \\   & Base & \(0.376 0.060\) & \(0.888 0.010\) & \(0.985 0.009\) & \(0.649 0.036\) & \\  & **IGNITE** & \(0.435 0.058\) & \(+5.9\%\) & \(0.896 0.013\) & \(+0.8\%\) & \(0.987 0.007\) & \(+0.2\%\) & \(0.662 0.091\) & \(+1.3\%\) \\   & Base & \(0.385 0.067\) & \(0.889 0.014\) & \(0.980 0.012\) & \(0.681 0.095\) & \\  & **IGNITE** & \(0.468 0.062\) & \(+8.3\%\) & \(0.897 0.010\) & \(+0.8\%\) & \(0.986 0.010\) & \(+0.6\%\) & \(0.705 0.118\) & \(+2.4\%\) \\   & Base & \(0.854 0.042\) & \(0.895 0.012\) & \(0.919 0.044\) & \(0.635 0.041\) & \\  & **IGNITE** & \(0.859 0.039\) & \(+0.5\%\) & \(0.900 0.015\) & \(+0.5\%\) & \(0.921 0.042\) & \(+0.2\%\) & \(0.652 0.055\) & \(+1.7\%\) \\   & Base & \(0.905 0.023\) & \(0.944 0.008\) & \(0.892 0.046\) & \(0.643 0.062\) & \\  & **IGNITE** & \(0.911 0.024\) & \(+0.6\%\) & \(0.945 0.007\) & \(+0.1\%\) & \(0.930 0.041\) & \(+3.8\%\) & \(0.647 0.058\) & \(+0.4\%\) \\   & Base & \(0.569 0.086\) & \(0.821 0.019\) & \(0.665 0.000\) & \(0.550 0.008\) & \\  & **IGNITE** & \(0.615 0.085\) & \(+4.6\%\) & \(0.834 0.012\) & \(+1.3\%\) & \(0.665 0.000\) & \(+0.0\%\) & \(0.553 0.000\) & \(+0.3\%\) \\   & Base & \(0.897 0.031\) & \(0.931 0.013\) & \(0.955 0.030\) & \(0.645 0.038\) & \\  & **IGNITE** & \(0.901 0.030\) & \(+0.4\%\) & \(0.934 0.010\) & \(+0.3\%\) & \(0.952 0.043\) & \(-0.3\%\) & \(0.638 0.053\) & \(-0.7\%\) \\   & Base & \(1.955 1.484\) & \(0.724 0.002\) & \(0.928 0.040\) & \(0.668 0.035\) & \\  & **IGNITE** & \(1.957 1.910\) & \(+0.2\%\) & \(0.724 0.001\) & \(+0.0\%\) & \(0.927 0.043\) & \(-0.1\%\) & \(0.673 0.044\) & \(+0.5\%\) \\   & Base & \(0.812 0.000\) & \(0.896 0.000\) & \(0.787 0.112\) & \(0.628 0.000\) & \\  & **IGNITE** & \(0.812 0.000\) & \(+0.0\%\) & \(0.896 0.000\) & \(+0.0\%\) & \(0.843 0.109\) & \(+5.6\%\) & \(0.628 0.000\) & \(+0.0\%\) \\   & Base & \(0.937 0.023\) & \(0.946 0.014\) & \(0.892 0.055\) & \(0.647 0.025\) & \\  & **IGNITE** & \(0.935 0.032\) & \(-0.2\%\) & \(0.962 0.018\) & \(+1.6\%\) & \(0.923 0.038\) & \(+3.1\%\) & \(0.652 0.074\) & \(+0.5\%\) \\   

Table 1: The percentage improvement in performance achieved by **IGNITE** across all tasks and baseline algorithms at the **100th percentile** level is presented. **Gain** signifies the percentage gain over the baseline performance (Base).

performances in both tasks. For example, in the **Ant Morphology** task, it raises the SOTA baseline **CMA-ES** from \(195.5\%\) to \(195.7\%\). In the **D'Kitty Morphology** task, **IGNITE** achieves a new SOTA of \(96.2\%\) with the **ICT** baseline.

**Results on Discrete Tasks:** The last two columns of Table 1 show the impact of the **IGNITE** regularizer on the performance of baseline algorithms in two discrete domains (**TF-BIND-8** and **TF-BIND-10**). Similar to the continuous tasks, **IGNITE** significantly enhances baseline performance in most cases (\(17\) out of \(22\)), with improvements of up to \(5.6\%\). There are only \(3\) instances where integrating **IGNITE** results in a minor performance decrease of up to \(0.7\%\), which is negligible. Additionally, in certain instances, **IGNITE** not only improves baseline performance but also establishes new state-of-the-art (SOTA) results. For example, on **TF-BIND-8** and **TF-BIND-10**, the original SOTA performances of \(98.5\%\) and \(68.1\%\) achieved by **ENS-MEAN** and **ENS-MIN**, respectively, are elevated to \(98.7\%\) and \(70.5\%\) with the addition of **IGNITE**, setting new SOTA records.

In summary, **IGNITE** consistently maintains a high probability of \(91\%\) (\(40\) out of \(44\)) of not degrading baseline performance. There is a high likelihood (\(79.55\%\) = \(35\) out of \(44\) cases) of improving baseline performance, with an average improvement of approximately \(1.91\%\) and a notable peak improvement of \(9.6\%\). Conversely, **IGNITE** also exhibits a relatively low probability (\(9.09\%\) = 4 out of \(44\) cases) of decreasing performance, with an average degradation of approximately \(0.3\%\) and a minor peak degradation of \(0.7\%\).Additionally, there is a minor probability (\(11.36\%\) = \(5\) out of \(44\) cases) of maintaining baseline performance.

### Ablation Experiments

In this section, we conduct additional experiments to assess the sensitivity of two representative baselines, **COMs** and **GA**, when regularized with **IGNITE**, to variations in hyper-parameters \(\) and \(_{}\). Additionally, we perform experiments to compare the efficacy of **IGNITE** with other commonly used regularization methods.

**Changing threshold \(\).** We assess the performance enhancement of **COMs** and **GA** when regularized with **IGNITE** using various values of \(\) from the set \(\{0.01,0.05,0.1,0.2,0.3,0.4,0.5\}\). A high \(\) value may result in a surrogate that is overly sharp, potentially hampering the search process and hindering the discovery of optimal designs. Figure 2(a) demonstrates that excessively high \(\) values lead to negative improvements. Conversely, excessively low \(\) values may cause the regularizer to dominate the original loss, resulting in a surrogate that is not well-fitted to the offline data. Negative improvements are observed with \(=0.01\) and \(0.05\) in Figure 2(a). As a result, we determine \(=0.1\) as the optimal value based on these observations.

**Changing step size \(_{}\).** The step size \(_{}\) controls the rate at which \(\) is updated during the optimization process. It's essential to choose an appropriate step size, avoiding it being either too large or too small. Figure 2(b) demonstrates that an \(_{}\) value of \(1e-3\) yields optimal results.

    &  &  &  &  \\  & & & **Bind 8** & & **Bind 10** \\    & **2.7\%** & **9.6\%** & **1.5\%** & **3.5\%** \\
**REINE** & SAM & 1.1\% & 7.9\% & 1.1\% & 0.2\% \\
**ORCE** & L1-Reg. & 1.0\% & 5.2\% & 1.0\% & 0.3\% \\  & L2-Reg. & 1.0\% & 4.2\% & 0.9\% & 0.1\% \\   & **IGNITE** & **1.7\%** & **0.5\%** & **0.5\%** & 0.2\% \\  & SAM & 0.7\% & -1.3\% & 0.2\% & **1.1\%** \\  & L1-Reg. & 1.0\% & 0.0\% & 0.1\% & -0.8\% \\  & L2-Reg. & 1.1\% & -0.7\% & 0.2\% & -0.4\% \\   

Table 2: Percentage improvement over the baseline of **IGNITE**, SAM , and L1, L2 regularization across all tasks.

Figure 2: The percentage improvement in performance achieved by **IGNITE** across different algorithms (**COMS** and **GA**) and tasks (**ANT** and **TF10**) in the changes of (a) threshold \(\) and (b) step size \(_{}\).

**Comparing IGNITE with other regularization methods.** We conduct a comparative experiment to assess the performance improvement achieved by using the **IGNITE** regularizer compared to other regularizers, including L1, L2, and SAM  (where SAM is considered as a loss sharpness regularization with a coefficient equal to 1). Table 2 presents the results obtained on two baseline algorithms, **REINFORCE** and **GA**, across four tasks. Overall, **IGNITE** outperforms the other regularizers in most cases, with the largest difference compared to the second best being \(3.2\%\) with **REINFORCE** on the **TF-BIND-10** task. Additionally, **IGNITE** achieves positive improvements in all cases. Conversely, while the simple regularizers L1 and L2 help boost performance with **REINFORCE**, they lead to performance degradation with **GA**. SAM outperforms **IGNITE** with the **GA** baseline on the **TF-BIND-10** task and shows notable improvement with **REINFORCE** on the **D'Kitty** task, though its integration with **GA** leads to a performance drop. Furthermore, we show that **IGNITE** also outperforms SAM when integrating with **CBAS** and **B0-qEI** in Appendix H.

**Surrogate sharpness on unseen data before and after using IGNITE.** We also conduct an experiment measuring the sharpness of the surrogate model, approximated by \(\|_{}h()\|\) as defined in Eq. (10), with and without **IGNITE**. This sharpness is computed on unseen data points which are, specifically, the design candidates generated by the **GA** and **REINFORCE** baselines. By testing on these unseen candidates, we simulate the out-of-distribution (OOD) conditions that are critical in assessing generalization in optimization tasks. Table 3 reports these surrogate sharpness measurements for some baselines with and without using the **IGNITE** regularizer. The results demonstrate consistently that the **IGNITE** regularizer helps reduce the surrogate sharpness on unseen data, as anticipated. This reduction indicates that **IGNITE** is effective in smoothing the surrogate model's landscape, leading to better and more stable generalized performance.

**Results on tasks with noisy data.** To demonstrate **IGNITE**'s robust performance in scenarios with noisy oracle, we conducted additional experiments using the **GA** and **REINFORCE** baselines on two benchmark tasks with particularly noisy oracles: **Superconductor** and **Chembl**. For each baseline, we compared its achieved performance with and without the regularizing effect of **IGNITE**, as shown in Table 4. Across both tasks, **IGNITE** helps improve the baseline performance substantially, achieving up to a \(2.1\%\) increase for **REINFORCE** on the **Superconductor** task, highlighting **IGNITE**'s ability to enhance performance robustness even in settings with noisy oracles.

## 6 Conclusion

This paper introduces the concept of generalized surrogate sharpness in offline optimization, resulting in the development of a new regularization technique, **IGNITE**. Our theoretical analysis demonstrates that reducing surrogate sharpness on an offline dataset provably decreases its generalized sharpness on unseen data. Empirically, **IGNITE** consistently maintains a high probability (\(91\%\)) of not degrading baseline performance and a \(79.55\%\) likelihood of improving it, with a peak improvement of \(9.6\%\). Additionally, we believe that our novel technique can be adapted to related domains such as robust optimization (RO) and reinforcement learning (RL), suggesting potential future research directions.