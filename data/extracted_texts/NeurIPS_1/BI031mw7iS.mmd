# Flow: Per-instance Personalized Federated Learning

Kunjal Panchal

College of Information and Computer Sciences

University of Massachusetts, Amherst

Amherst, MA 01003

kpanchal@umass.edu

&Sunav Choudhary

Adobe Research

Bangalore, India

schoudha@adobe.com

Nisarg Parikh

Khoury College of Computer Sciences

Northeastern University

Boston, MA 02115

parikh.nis@northeastern.edu

&Lijun Zhang, Hui Guan

College of Information and Computer Sciences

University of Massachusetts, Amherst

Amherst, MA 01003

{lijunzhang, huiguan}@umass.edu

###### Abstract

Federated learning (FL) suffers from data heterogeneity, where the diverse data distributions across clients make it challenging to train a single global model effectively. Existing personalization approaches aim to address the data heterogeneity issue by creating a personalized model for each client from the global model that fits their local data distribution. However, these personalized models may achieve lower accuracy than the global model in some clients, resulting in limited performance improvement compared to that without personalization. To overcome this limitation, we propose a per-instance personalization FL algorithm _Flow_. _Flow_ creates dynamic personalized models that are adaptive not only to each client's data distributions but also to each client's data instances. The personalized model allows each instance to dynamically determine whether it prefers the local parameters or its global counterpart to make correct predictions, thereby improving clients' accuracy. We provide theoretical analysis on the convergence of _Flow_ and empirically demonstrate the superiority of _Flow_ in improving clients' accuracy compared to state-of-the-art personalization approaches on both vision and language-based tasks. The source code is available on GitHub 1.

## 1 Introduction

Federated Learning (FL) is a distributed machine learning paradigm that enables edge devices, known as "clients", which collaboratively train a machine learning model called a "global model" . However, because the server, which is the FL training orchestrator, does not have access to or knowledge of client data distributions, it poses a challenge of statistical heterogeneity . This heterogeneity hinders the server's ability to train an ML model on a large quantity and variety of data and also impacts the client's ability to benefit from a generalizable model without sharing any information about its data. To address this challenge, personalization has been studied  to improve prediction performance. Recent literature consistently demonstrates that personalized models achieve higher prediction performance than the global model aggregated over clients . These approaches typically create a personalized model specific to each client's data distribution, and thus we refer to them as "per-client personalization".

However, we have identified two factors that limit the performance improvement of existing per-client personalization approaches in terms of clients' accuracy. First, as reported in the evaluation in Sec. 5, we found that personalized models can achieve lower accuracy than the global model on up to 31% clients, causing limited improvement in accuracy averaged across all clients. Second, even if personalized models achieve higher accuracy on a client compared to the global model, they can still produce incorrect predictions on up to 11% of data instances on clients that could be correctly handled by the global model, causing limited accuracy improvement from personalization on that client. These observations reveal a significant drawback of existing per-client personalization approaches: _each client's personalized model is a static network that cannot accommodate the heterogeneity of the local client's data instances._ As a result, every data instance on a client is constrained to use its personalized model for prediction, even though some instances could benefit from the better generalizability of the global model.

To overcome the above limitation, this paper proposes a per-instance and per-client personalized FL algorithm _Flow_ via dynamic routing to improve clients' accuracy. _Flow_ creates _dynamic_ personalized models that are adaptive to each client's individual data instances (per-instance) as well as their data distribution (per-client). In a FL round of _Flow_, each client has both the global model parameters that are shared across clients and the local model parameters that are adapted to the local data distribution of the client by fine-tuning the global model parameters. _Flow_ creates a dynamic personalized model per client that consists of local and global model components and a dynamic routing module. The dynamic routing module allows each data instance on a client to determine whether it prefers the local model parameters or their global model counterparts to make correct predictions, thereby improving the personalized model's accuracy on the client compared to that of a local model or a global model. At the same time, through dynamic routing, _Flow_ could identify instances in each client that agree with the global data distribution to further improve the performance of the global model, offering a good _starting point_ for any new client to personalize from. Since _Flow_ is a client-side personalization approach, it can work with server-side optimization methods like FedYogi.

We theoretically analyze how dynamic routing affects the convergence of the global model and personalized model in _Flow_ and also empirically demonstrate the effectiveness of _Flow_ in improving clients' accuracy compared to state-of-the-art personalization approaches on cross-device language and vision tasks. For the newly joined clients, the global model from _Flow_ achieves 2.81% (Stackoverflow), 3.46% (Shakespeare), and 0.95%-1.41% (CIFAR10) better accuracy on the global model against its best performing baselines respectively. After personalization, the dynamic personalized model from _Flow_ sees improvements of 3.79% (Stackoverflow), 2.25% (Shakespeare), and 3.28%-4.58% (CIFAR10) against the best performing baselines. Our in-depth analysis shows that _Flow_ achieves the highest percentage of clients who benefit from personalization compared to all baselines and reduces the number of instances that are misclassified by the personalized model but correctly classified by the global model, contributing to the better personalized accuracy from _Flow_.

We summarize the contributions as follows:

* We propose a per-instance and per-client personalization approach _Flow_ that creates personalized models via dynamic routing, which improves both the performance of the personalized model and the generalizability of the global model.
* We derive convergence analysis for both global and personalized models, showing how the routing policy influences convergence rates based on the across- and within- client heterogeneity.
* We empirically evaluate the superiority of _Flow_ in both generalization and personalized accuracy on various vision and language tasks in cross-device FL settings.

## 2 Related Work

**Personalized Federated Learning.** Personalization in FL has been explored primarily on client-level granularity. APFL  interpolates client-specific local model weights with the global model weights which are sent by the server. Meanwhile, _Flow_ is an intermediate-output interpolation method and also includes a dynamic policy to interpolate at instance-level granularity. We note that Dapper interpolates the client dataset with a global dataset, which is impractical for the cross-device use cases FL focused on in this paper. Regularization is another popular way of creating a personalized model. It encourages a personalized model of each client to be close to the global model as exploredin Ditto and pFedMe. Finetuning partial or entire global model to get the personalized model has been studied in LGFedAvg, which finetunes and personalizes the feature extractor and globally shares the classifier head, FedBabu which freezes the classifier head and only updates and aggregates the feature extractor, and FedRep which finetunes and personalizes the classifier head and globally shares the feature extractor. Learning personalized representations of the global model has been explored in FEDHN where a central hypernetwork model is trained to generate a personalized model for each client. PartialFed makes a layer-wise choice between global and local models to create a personalized model, but it sends the personalized models back to the server in lieu of a separate global model. This method has limitations in terms of training the base global model (on which the personalized model would be based) with FedAvg, which has been observed to be insufficient against non-iid data. Besides, the strategy does not create a dynamic personalized model during inference. None of the above work has explored instance-level personalization.

Personalized models from previous work knnPer exhibits per-instance personalization behavior. The personalized model of a client makes a prediction based on features extracted from the global model from an instance as well as features from the instance's nearest neighbors. However, knnPer trains the global model parameters in the same way as FedAvg, which has been shown to perform poorly in heterogeneous data settings. In contrast, _Flow_'s dynamic routing mechanism results in a global model with better-generalized performance amidst heterogeneous instances, which ultimately leads to a higher boost in the performance of personalized models as well.

**Dynamic Routing.** Motivated by saving compute effort for "easy to predict" instances, instance-level dynamic routing has been a matter of discussion in works related to early exiting , layer skipping , and multi-branching . SkimRNN explored temporal dynamic routing where depending on the input instance, a trained policy can determine whether to skim through the instance with a smaller RNN layer (which just updates the hidden states partially), or read the instance with a standard (bigger) RNN layer (updating the entire hidden state). Our work is motivated by the question of _Depending on the models' utility and instances' heterogeneity, which route to pick?_. This can be achieved by using a routing policy to dynamically pick from two versions of a model, which are equivalent in terms of computational cost but different in terms of the data they are trained on.

## 3 Our Approach

We introduce _Flow_, a per-instance and per-client personalization method that dynamically determines when to use a client's local parameters and when to use the global parameters based on the input instance. Table 1 summarizes the notation used in this paper.

Algorithm 1 describes the workflow of _Flow_. During each FL round, the server samples \(M\) participating clients with a sampling rate of \(p\). Upon receiving the global model \(w_{g}\) and policy parameters \(_{g}\) (Line 3), each participating client personalizes and trains \(w_{g}\) in five major stages: (1) Split the training dataset into two halves: \(_{m,}\) and \(_{m,g}\) (Line 6). \(_{m,}\) will be used to update the parameters in the local model parameters while \(_{m,g}\) will be used to train the parameters in the global model and a routing module. (2) Derive the local parameters \(w_{}\) by finetuning the global parameters \(w_{g}\) for \(K_{1}\) epochs with \(_{m,}\) (Line 7). (3) Construct a _dynamic personalized model_\(w_{p,m}\) by integrating the local versions of the global parameters \(w_{g,m}\) and policy parameters \(_{g,m}\), and the local parameters \(w_{}\). Here, the routing policy \(_{g}\) determines whether the execution path of an instance should use \(w_{}\) or \(w_{g}\). (4) Train the routing policy \(_{g,m}\) and the local version of the global parameters \(w_{g,m}\) alternatively for \(K_{2}\) epochs (Lines 9-10) with \(_{m,g}\). Although \(K_{1}\) and \(K_{2}\) can be different, we later use \(K\) to denote both \(K_{1}\) and \(K_{2}\) for ease of theoretical analysis. (5) Send the local version of the global model parameters \(w_{g,m}\) and the policy parameters \(_{g,m}\) back to the server for aggregation (Line 14). Aggregation strategies are orthogonal to this work and we adopt FedAvg.

   \(K\) & \#Epochs for training \\ \(M\) & Total number of sampled clients \\ \(m\) & Client index \([M]\) \\ \(\) & Set of available clients \\ \(p\) & Client sampling rate \\ \(_{}\) & Local learning rate \\ \(w_{g}\) & Global model \\ \(_{g}\) & Policy module \\ \(w_{g,m}\) & Local version of the global model \\ \(w_{,m}\) & Local model of \(m^{th}\) client \\ \(w_{p,m}\) & Personalized model of \(m^{th}\) client \\ \(_{m}\) & Data distribution of \(m^{th}\) client \\   

Table 1: NotationsNext, we discuss the design of the _dynamic personalized model_\(w_{p}\) in detail. Figure 1 illustrates the design of \(w_{p}\). In _Flow_, \(w_{p}\) is made of three components, the local model \(w_{}\) and global model \(w_{g}\) and the routing module \(_{g}\) that selects the execution of local or global model layers for each data instance.

Local Parameters.We use _finetuning_ to get the local parameters \(w_{,m}^{(r)}\) in the \(r\)-th round since finetuning has proven to be a less complex yet very effective method of personalization . Given a global model of the previous round, \(w_{g,m}^{(r)}\), we finetune it for \(K\) epochs to get \(w_{,m}^{(r)}\). This local model would be reflective of the client's data distribution \(_{m}\). Note that we use one half of the dataset to get \(w_{,m}^{(r)}\) and reserve the other half of the training dataset for updating the global model and the policy (i.e., the routing module) parameters. This is to make sure that the policy parameters, which would decide between local and global layers based on each input instance, are not overfitted in favor of the local parameters. In Figure 1, the local parameters are shaded green, denoted by \(w_{}\). The update rule for \(w_{,m}^{(r)}\) is:

\[w_{,m}^{(r,K)} w_{,m}^{(r,0)}-_{}_{k=1}^{K}  f_{m}(w_{,m}^{(r,0)};_{m,}),w_{,m}^{(r,0)}:=w _{g}^{(r)}. \]

Routing Module.The routing module is a model with fully connected layers, shown as \(_{}\) in Figure 1. After each layer \(_{}\), the model has early exits denoted as \(_{}\) which outputs a probability of choosing the layer in the global model \(w_{g}\) or the local model \(w_{}\). This probability at layer \(j[L]\) is computed as,

\[^{(j)}=[_{0}^{(j)},_{1}^{(j)}]=( _{}^{(j)}(_{}^{(j)}()))^{2} x_{m}&j=0;\\ _{}^{(j-1)}() \]

where \(_{0}^{(j)}\) and \(_{1}^{(j)}\) are the probability of picking the global parameter \(w_{g,m}^{(j)}\) and the local parameter \(w_{,m}^{(j)}\) respectively.

In order to train the routing parameters, we compute the training loss based on the output of the personalized model \(w_{p,m}^{(r)}\), which averages the global model's output and local model's output weighted by \(^{(j)}\), for each layer \(j[L]\):

\[w_{p,m}^{(j)}()_{0}^{(j)} w_{g,m}^{(j)}()+_{1}^{(j)} w_{,m}^{(j)}() x_{m}&j=0;\\  w_{p,m}^{(j-1)}()& \]

Figure 1: Illustration of the dynamic personalized model design proposed by _Flow_.

Let \(f_{m}()\) denote the loss function on client \(m\). Using the above personalized model \(w^{(r)}_{p,m}\), _Flow_ updates the policy parameters as follows,

\[^{(r+1)}_{g,m}^{(r)}_{g,m}-_{}_{^{(r)}_{g,m} }[f_{m}(w^{(r)}_{p,m};w^{(r)}_{g},_{m,g})-_{j[ L]}(^{(j)}_{0})], \]

where \(-_{j[L]}(^{(j)}_{0})\) is a regularization term that encourages the global model to learn on heterogeneous instances to improve the global model's generalizability.

Global Parameters.Global parameters \(w_{g}\) are trained alternatively with the routing parameters \(_{g}\). _Flow_ updates the global parameters as follows,

\[w^{(r+1)}_{g,m} w^{(r)}_{g,m}-_{}_{w^{(r)}_{g,m}}f_{m} (w^{(r)}_{p,m};^{(r+1)}_{g,m},_{m,g}) \]

The goal of the alternative training is for the instances that are characterized better by the global data distribution to get diverted to the global model and the rest of the instances that are captured better by the local data distribution routed to the local model. This improves the stability of the global model compared to approaches like APFL or knnPer which still use the global model trained on all the instances, regardless of the level of heterogeneity. The effectiveness of the alternative training is validated empirically and discussed in Appendix D.2.

Soft versus Hard Policy.During training, we use soft policy where the probability in Equation 2 ranges over \(\) to update the parameters in the global model and the routing module. But during inference, we use a discrete version of the policy \((^{(j)})\{0,1\}^{2}\) for \(^{(j)}\) in Eq. 3. The rationale behind this is twofold: (a) Using hard policy saves compute resources during inference by executing either the global or the local layer for an instance instead of both. (b) Our empirical evaluation shows negligible difference in performance of personalized models with soft and hard policies during the inference.

The dynamic nature of the personalized model in _Flow_ introduces additional storage and computational overhead compared to the canonical method FedAvg with Fine Tuning (called FedAvgFT). However, compared to other state-of-the-art personalization methods such as Ditto and APFL, _Flow_ requires similar or even less storage and computational overhead. Detailed analysis and comparison with baselines is in Appendix C.

## 4 Theoretical Analysis

In this section, we give convergence bounds for the global model \(w_{g}\) and the personalized model \(w_{p}\) of an arbitrary client \(m\) in smooth non-convex cases. The bounds for strong and general convex cases are available in Appendix E, Sections E.3 and E.5. To derive the bounds, we adopt two commonly used assumptions in FL convergence analysis from AFO (Assumption 2, ) and SCAFFOLD (Assumption 1, ): (1) We assume local variance between a client's expected and true gradient is \(_{}\)-bounded. (2) We also assume that the dissimilarity between aggregated gradients of local expected risk and the true global gradient is \((G,B)\)-bounded, where both \(G\) and \(B\) are constants capturing the extent of gradient dissimilarities. A detailed description is in Appendix E.2.

Now we present the bounds on the norm of expected global (and local) risks on global (and personalized) models respectively, at \(R\)-th (last) round. The proofs are in Appendix Sections E.3 and E.5.

**Theorem 4.1** (Convergence of the Global Model).: _If each client's objective function \(f_{m}\) (and hence the global objective function \(F\)) satisfies \(\)-smoothness, \(_{}\)-bounded local gradient variance, \((G,B)\)-dissimilarity assumptions, using the learning rate \(_{} BK^{2}}\) for non-convex case] in Flow, then the following convergence holds:_

\[_{r=1}^{R}\| F(w^{(r)}_{g}) \|^{2}^{2}_{0}R}[[ F(w^{(1)}_{g})]-[F(w^{(R+1)}_{g})]]\] \[+^ {2}}{2BM^{2}_{0}K}+^{2}_{1}G^{2}}{ ^{2}_{0}B^{2}R}+^{2}}{B^{2}KR}.\]Discussion.Here, \(_{0}^{2}\) (and \(_{1}^{2}\)) are the probability of picking the global (and local) weights averaged over all instances sampled from the global data distribution. Given a fixed \(_{0}^{2}\) and \(_{1}^{2}\), a larger \(G\) increases the bound, indicating slower convergence of the global model due to higher heterogeneity. We made two additional observations on the convergence of _Flow_ depending on \(_{0}^{2}\) in the bound.

One the one hand, when \(_{0}^{2} 1\), _Flow_ matches the linear (strong convex) and sub-linear (general convex and non-convex) convergence rates of FedAvg . Specifically, \(_{0}^{2}=1\) results in convergence rate of \((1/R^{2})\) (strong convex), \((1/R^{2/3})\) (general convex), and \((1/R)\) (non-convex). When \(_{0}^{2}=1\), which also indicates \(_{1}^{2}=0\), the local parameters do not influence global model updates since all instances on a client will be routed to the global model and their gradients solely depend on the global model parameters. _Flow_ degrades to FedAvg in this case in terms of the convergence of the global model.

On the other hand, when \(_{0}^{2} 0\) indicating all instances are likely to be routed to the local model, the bound goes to infinity. It is because the global model parameters won't get updated and thus won't be able to converge. This observation validates the necessity of the regularization term in Eq. 4 to encourage instances to pick global model parameters.

Now we present the convergence bounds of the personalized model for the \(m\)-th client. The bound uses a definition of gradient diversity (noted as \(_{m}\)) to quantify the diversity of a client's gradient with respect to the global aggregated gradient, following the prior work . Higher diversity implies higher heterogeneity of the client.

**Theorem 4.2** (Convergence of the Personalized Model).: _If each client's objective function \(f_{m}\) satisfies \(\)-smoothness, \(_{t}\)-bounded local gradient variance, \((G,B)\)-dissimilarity assumptions, and using the learning rate \(_{}}\) [for non-convex case] in Flow, then the following convergence holds:_

\[_{r=1}^{R} \| f_{m}(w_{p,m}^{(r,K)})\|^{2} ([f_{m}(w_{p,m}^{(1,K)})]-[f_{m}(w_{p,m}^{(R,K)})])\] \[+(}{R^{2}K^{2}}(_{}^ {2}+(_{m}^{_{g}}+}}{M})K) (G^{2}+_{1,m}^{2}G^{2}}{_{0,m}^{2}R}))\]

Discussion.The theorem implies two main properties of the personalized models in _Flow_. First, for all convex and non-convex cases, the convergence rate of the personalized model in _Flow_ is affected by the routing policy through the ratio \(_{1,m}^{2}G^{2}/_{0,m}^{2}\). We know that a higher value of the gradient dissimilarity constant \(G\), indicates higher heterogeneity between the aggregated and expected global model. The ratio of \(_{1,m}^{2}/_{0,m}^{2}\) would be higher for a heterogeneous client, since the client would get a higher probability of picking the local route (\(_{1,m}^{2} 1\)). The higher \(G\) and \(_{1,m}^{2}\) results in slower convergence. On the contrary, a homogeneous client would benefit from a low value of \(_{1,m}^{2}/_{0,m}^{2}\), which would offset the high value of \(G\). Hence a homogeneous client's personalized model would converge faster than the one of a heterogeneous client. Second, we observe that gradient diversity of the policy model, \(_{m}^{_{g}}\), linearly affects the personalized model's convergence. Since the policy model is also globally aggregated, a heterogeneous client would have a high \(_{m}^{_{g}}\) and need more epochs per round to converge.

## 5 Experiments and Results

We empirically evaluate the performance of _Flow_ against various personalization approaches for five non-iid vision and language tasks in terms of clients' accuracy.

**Datasets, Tasks, and Models.** We have experiments on two language and three vision tasks. The first three datasets which are described below represent real-world heterogeneous data where each author or user is one client. (a) **Stackoverflow** dataset is used for the next word prediction task, using a model with 1 LSTM and 2 subsequent fully connected layers. (b) **Shakespeare** dataset is for the next character prediction task, using a 2 layer LSTM + 1 layer fully connected model. (c) **EMNIST** dataset is for 62-class image classification, which uses 2 CNN layers followed by 2 fully-connected layers. The models for the above three datasets have been described in . The next two datasets are federated and artificially heterogeneous versions of CIFAR10/100datasets. (d-e) **CIFAR10/100** datasets are for 10- and 100-class image classification tasks with ResNet18  model. Both CIFAR10/100 have two heterogeneous versions each: 0.1-Dirichlet is _more_ heterogeneous, and 0.6-Dirichlet is _less_ heterogeneous. Details about the datasets and the hyperparameters are in Appendix B.

**Baselines and Metrics.** We compare _Flow_ with the following baselines: the classic FL algorithms FedAvg, state-of-the-art personalized FL approaches including FedAvgFT (FedAvg + Finetuning) , PartialFed, APFL , FedRep, LGFedAvg, Ditto, HypCluster, and knnPer, and the Local baseline which trains a local model on each client's dataset without any collaboration. We use the adaptive version of PartialFed as it shows better performance compared to the alternatives in . We evaluate _Flow_ and these baselines in terms of **generalized accuracy** and **personalized accuracy**, which correspond to the accuracy of the global model and the personalized model on clients' test data split.

We use Flower  library to implement _Flow_ and all its baselines. We use an NVidia 2080ti GPU to run all the experiments with 3 runs for each. The random seeds used are 0, 44, and 56. We do not observe significant difference in results using other random seeds (see results in Appendix D.4).

### Performance Comparison

**Generalized and Personalized Accuracy.** The performance of _Flow_ and its baselines are reported in Table 2 for four datasets. Note that the local baseline has only personalized accuracy as it doesn't create a global model collaboratively. The FedAvg has only generalized accuracy as it doesn't personalize the global model for each client. Since PartialFed is a stateful approach, we are unable to run it on the cross-device datasets (Stackoverflow, Shakespeare, EMNIST). Results for the rest of the datasets and their variance across 3 different runs are reported in Appendix D.

Overall, _Flow_ achieves 1.11-3.46% higher generalized accuracy and 1.33-4.58% higher personalized accuracy over the best performing baseline. In particular, _Flow_ outperforms knNPer, another per-instance per-client personalization approach, by 1.66-6.64% and 1.33-6.97% in generalized and personalized accuracy metrics respectively. knNPer allows each instance to personalize the prediction of the global model based on its k-higher, the better).

We see improvements in generalized accuracy of _Flow_ because of the fact that the global model in _Flow_ is trained based on the instances which align more with the global distribution. We see improvements in personalized accuracy due to the limitation of the per-client approaches where some instances being correctly classified by the global model are incorrect on the personalized model. We next give insights on why _Flow_ achieves better performance in person

   Datasets & Stackoverflow & Shakespeare & CIFAR10 (0.1) & CIFAR10 (0.6) \\   Baselines & \(Acc_{g}\) & \(Acc_{p}\) & \(Acc_{g}\) & \(Acc_{p}\) & \(Acc_{g}\) & \(Acc_{p}\) & \(Acc_{g}\) & \(Acc_{p}\) \\   Local & - & 15.93\% & - & 18.70\% & - & 49.78\% & - & 62.74\% \\ FedAvg & 23.15\% & - & 52.00\% & - & 60.98\% & - & 67.50\% \\ FedAvgFT & 23.83\% & 24.41\% & 52.12\% & 53.68\% & 61.23\% & 73.03\% & 68.19\% & 72.21\% \\ knnPer & - & - & - & - & - & - & 69.52\% & 70.14\% \\ PartialFed & - & - & - & - & - & - & 65.73\% & 26.69\% & 70.38\% \\ APFL & 22.96\% & 25.70\% & 52.38\% & 53.64\% & 62.87\% & 72.86\% & 69.53\% & 72.53\% \\ Dirty & 22.59\% & 24.36\% & 52.44\% & 53.95\% & 62.06\% & 72.06\% & 68.12\% & 70.31\% \\ FedRep & 18.92\% & 21.04\% & 46.71\% & 50.09\% & 64.85\% & 68.62\% & 69.77\% & 63.61\% \\ LGFedAvg & 22.61\% & 24.03\% & 51.08\% & 51.43\% & 56.63\% & 73.19\% & 67.48\% & 68.94\% \\ HypCluster & 23.75\% & 22.43\% & 51.92\% & 52.74\% & 63.64\% & 71.55\% & 65.44\% & 72.40\% \\ _Flow_ (Ours) & **26.64\%** & **29.49\%** & **59.90\%** & **56.20\%** & **62.66\%** & **76.47\%** & **70.88\%** & **77.11\%** \\   

Table 2: Generalized (\(Acc_{g}\)) and Personalized (\(Acc_{p}\)) accuracy (the higher, the better) for _Flow_ and baselines.

    & Stackoverflow & Shakespeare & CIFAR10 (0.1) & CIFAR10 (0.6) \\  FedAvgFT & 79.26\% & 79.00\% & 97.18\% & 99.33\% \\ knnPer & 82.73\% & 68.87\% & 90.00\% & 90.00\% \\ PartialFed & - & - & 88.30\% & 84.80\% \\ APL & 69.66\% & 79.22\% & 87.48\% & 90.63\% \\ Dirty & 74.59\% & 73.74\% & 90.52\% & 89.61\% \\ FedRep & 91.53\% & 79.78\% & 92.30\% & 84.64\% \\ LGFedAvg & 83.47\% & 88.43\% & 88.41\% & 89.59\% \\ HypCluster & 80.46\% & 74.84\% & 95.11\% & 98.18\% \\ _Flow_ (Ours) & **92.74\%** & **89.77\%** & **98.30\%** & **99.62\%** \\   

Table 3: % of clients for which \(Acc_{p}>Acc_{g}\) (the higher, the better).

**Percentage of Clients Benefiting from Personalization.** The goal of personalization is to achieve higher prediction accuracy in each client by creating a per-client personalized model from the global model. We can thus measure the effectiveness of personalization by computing the percentage of clients for which the personalized model achieves higher task accuracy than the global model. The higher the percentage is, the better (or more effective) the personalization approach is.

Table 3 reports the results. We observed that _Flow_ achieves the highest percentage of clients who benefit from personalization compared to all personalization baselines, echoing the better personalized accuracy from _Flow_. The percentage of clients who prefer personalized models can be as low as 68.87% (KnnPer on Shakespeare), which means personalization hurts up to 31% of clients' accuracy, as mentioned in the introduction. As a contrast, _Flow_ improves the percentage of clients benefiting from personalization to 89.77%-99.62% because each instance, in a client, has a choice between the global model parameters and the local model parameters and can choose the one that better fits it. Note that the comparison is in favor of the baselines since _Flow_ also achieves better generalized accuracy, which makes it even harder for personalized models to further improve prediction accuracy.

**Breakdown of Correctly Classified Instances.** Figure 3 further shows the breakdown of the percentage of instances that are (a) correctly classified by the global model but not the personalized model (noted as **global-only**, colored in yellow ), (b) correctly classified by the personalized model but not the local model (noted as **personalized-only**, colored in blue ), and (c) correctly classified by both models (noted as **both-correct**, colored in green  in _Flow_ and baselines on Stackoverflow. The percentage of instances in y-axis is averaged over the test splits of all clients.

Overall, _Flow_ increases the **both-correct** bars compared to all the baselines, which are the instances that contribute to the generalized performance of the global model. This explains the better generalized accuracy of _Flow_. _Flow_ also increases the **personalized-only** bars and decreases the **global-only** bars, which correspond to the heterogeneous instances that prefer personalized models instead of the global model. This further explains the better personalized accuracy of _Flow_. Notably, for Stackoverflow dataset, existing personalization approaches still result in up to 4.74-7.93% of instances incorrectly classified by the personalized model but correctly by the global model. _Flow_ reduces it to 1.12-2.42%. Similarly for the CIFAR10 (0.6) dataset, as mentioned in the introduction, we notice up to 11.4% of instances falling under the global-only category, which _Flow_ reduces to 2.55%. It echoes the aforementioned effectiveness of personalization in _Flow_. The instance-wise accuracy breakdown for the rest of the datasets is detailed in Appendix D, Figure 10.

**Analysis of Routing Decisions.** We further analyze the behavior of routing decisions for instances of a client that fall in the above three cases, **global-only**, **personalized-only**, and **both-correct**. Figure 3 shows the per-layer routing policies of the dynamic personalized model from _Flow_ on Stackoverflow. For instances that fall into each category, we average the policy value from Eq. 2 and report the statistics on the probability of picking the global parameters for each layer. The statistics for the rest of the datasets are detailed in Appendix D.

For instances that are correctly classified by \(w_{g}\) but not by \(w_{p}\) (**global-only**), we see a clear trend of the routing parameters getting more confident about picking the global parameters. As a contrast,for instances that are correctly classified by \(w_{p}\) but not by \(w_{g}\) (**personalized-only**), we see the trend of routing policy being more confident in picking the local parameters. For instances that can be correctly classified by both models (**both-correct**), the routing policy still prefers the global parameters over local parameters. This is due to the regularization term in Eq. 4, which encourages instances to pick the global model over the local model in order to improve the generalizability of the global model. Our ablation study in the next section demonstrates the importance of regularization.

### Ablation Studies

Here we highlight some results of three ablation studies on regularization, per-instance personalization, dynamic routing, and hard policies during inference. More results are in Appendix D.

**Regularization.** The regularization term in Eq. 4 promotes the global model layers whenever possible. It helps boost the generalized performance of the global model, which in turn also produces better personalized models. We use the results on the Stackoverflow dataset in Figure 3(a) to illustrate the importance of regularization. At the end of the training, we get 26.64% \(\) 0.23% generalized accuracy with regularization, compared to 24.16% \(\) 0.34% without regularization, and 29.49% \(\) 0.28% personalized accuracy with regularization, compared to 27.59% \(\) 0.36% without regularization. The importance of regularization in the policy update rule is also highlighted in Theorem 4.1, which states that only picking local route does not lead to global model convergence; the regularization term can encourage the global model to converge faster.

**Per-instance Personalization.** The dynamic personalized model in _Flow_ allows each instance to choose between the local model and global model layers. To verify this per-instance personalization design, we create two _variants_ of _Flow_, named "Per-Instance" _Flow_ (pi-Flow) where both paths of a dynamic model are global models, and "Per-Client" _Flow_ (pc-Flow) which is simply FedAvgFT. Compared to the personalized accuracy of per instance and per client _Flow_ (29.49% \(\) 0.28%), pi-Flow and pc-Flow achieve \(26.31\% 0.19\%\) and \(24.41\% 0.26\%\) respectively on Stackoverflow dataset, as shown in Figure 3(b). The results demonstrate the effectiveness of the per-instance personalization design in _Flow_.

**Dynamic Routing.** This ablation study aims to learn whether dynamically interpolating global and local routes has any advantages over fixing the routing policy throughout the training. In Figure 3(c), we compare the validation accuracy curves of dynamic routing in _Flow_ and dynamic routing with instance-agnostic static routing during the training phase. We observe that (a) For the case of fixed policy of \(_{0}=0.25\), the validation accuracy has bad performance due to the fixed policy only choosing the local route. This is due to using hard policy during inference, and (b) The cases of fixed policy \(_{0}[0.50,0.75,1.00]\) will only pick the global route during inference, which are also outperformed by the dynamic routing variant. With dynamic routing, the choice between local and global parameters depends on each instance during inference.

**Soft versus Hard Decisions during Inference.** We did not use soft decisions during inference since it only negligibly improves the accuracy of _Flow_. The test accuracies after personalization for _Flow_ on Stackoverflow with hard decisions are 29.49% \(\) 0.28%, while with soft decisions, we observed 29.57% \(\) 0.22%. The rest of the datasets show a similar trend (see Appendix D, Table 8).

Figure 4: Ablation studies on Stackoverflow dataset.

Conclusion

This paper proposed _Flow_, a per-instance and per-client personalization method to address the statistical heterogeneity issue in Federated Learning. _Flow_ is motivated by the observation that the personalized models from existing personalized approaches achieve lower accuracy in a significant portion of clients compared to the global model. To overcome this limitation, _Flow_ creates dynamic personalized models with a routing policy that allow instances on each client to choose between global and local parameters to improve clients' accuracy. We derived error bounds for global and personalized models of _Flow_, showing how the routing policy affects the rate of convergence. The theoretical analysis validates our empirical observations related to clients preferring either a global or a local route based on the heterogeneity of individual instances. Extensive evaluation on both vision and language-based prediction tasks demonstrates the effectiveness of _Flow_ in improving both the generalized and personalized accuracy.