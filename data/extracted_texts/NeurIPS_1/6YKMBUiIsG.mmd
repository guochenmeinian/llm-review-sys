# Inevitable Trade-off between Watermark Strength and Speculative Sampling Efficiency for Language Models

Inevitable Trade-off between Watermark Strength and Speculative Sampling Efficiency for Language Models

Zhengmian Hu, Heng Huang

Department of Computer Science

University of Maryland

College Park, MD 20742

huzhengmian@gmail.com,heng@umd.edu

###### Abstract

Large language models are probabilistic models, and the process of generating content is essentially sampling from the output distribution of the language model. Existing watermarking techniques inject watermarks into the generated content without altering the output quality. On the other hand, existing acceleration techniques, specifically speculative sampling, leverage a draft model to speed up the sampling process while preserving the output distribution. However, there is no known method to simultaneously accelerate the sampling process and inject watermarks into the generated content. In this paper, we investigate this direction and find that the integration of watermarking and acceleration is non-trivial. We prove a no-go theorem, which states that it is impossible to simultaneously maintain the highest watermark strength and the highest sampling efficiency. Furthermore, we propose two methods that maintain either the sampling efficiency or the watermark strength, but not both. Our work provides a rigorous theoretical foundation for understanding the inherent trade-off between watermark strength and sampling efficiency in accelerating the generation of watermarked tokens for large language models. We also conduct numerical experiments to validate our theoretical findings and demonstrate the effectiveness of the proposed methods.

## 1 Introduction

Large language models (LLMs) have demonstrated remarkable performance in various natural language processing tasks, enabling a wide range of applications such as chatbots , content generation , code generation , and more. However, the high training and inference costs of LLMs pose significant challenges. The substantial computational resources along with the high latency during inference can negatively impact user experience and limit their potential applications.

To address the issue of high inference costs, speculative sampling  has emerged as a promising approach. This technique leverages a smaller, faster draft model to generate candidate results, which are then validated and corrected by a larger, more accurate target model. Compared with other acceleration methods such as knowledge distillation, model quantization, and model pruning, the key advantage of speculative sampling is that it can significantly reduce inference latency without compromising the quality of the generated content.

In addition to the challenge of high inference costs, protecting the intellectual property rights of LLMs generated content has become increasingly important. Digital watermarking techniques  have been proposed to embed watermark information into the generated content, enabling the tracking of model usage. Unbiased watermarking schemes  have been developed to ensure that the watermarking process does not affect the quality of the generated content.

A natural question arises: can we leverage speculative sampling to accelerate the generation of watermarked content? To address this question, we propose a general framework called the _two reweight framework_, which allows for the integration of unbiased watermarking and speculative sampling techniques while guaranteeing an unchanged output distribution. The main innovation of our framework lies in the simultaneous reweighting of both the target model and the draft model, which improves the sampling efficiency compared to naively applying speculative sampling to a watermarked target model.

To evaluate the effectiveness of our framework, we consider two key metrics: watermark strength and acceleration performance. A fundamental question is whether it is possible to achieve both strong watermarking and efficient speculative sampling simultaneously. Specifically, we aim to answer the following question:

_Can we obtain the same watermark strength as in the case without acceleration while maintaining the same sampling efficiency as in the case without watermarking?_

Surprisingly, we got a negative answer to this question. We prove a no-go theorem, which states that under the _two reweight framework_, it is impossible to simultaneously maintain both the watermark strength and the sampling efficiency when the vocabulary size is greater than two. This result highlights the inherent trade-off between watermarking and acceleration in the context of large language models.

To better explore the trade-offs between these two objectives, we propose two practical algorithms within the _two reweight framework_. The first algorithm focuses on maintaining the watermark strength, while the second algorithm aims to maintain the sampling efficiency.

The main contributions of this paper are as follows:

* We propose the _two reweight framework_, a general framework that allows for the integration of unbiased watermarking and speculative sampling techniques while ensuring an unchanged output distribution.
* We prove a no-go theorem, which states that under the _two reweight framework_, it is impossible to simultaneously maintain both the watermark strength and the sampling efficiency when the vocabulary size is greater than two.
* We propose two practical algorithms within the _two reweight framework_ that focus on maintaining either the watermark strength or the sampling efficiency, providing insights into the achievable trade-offs.

Figure 1: Taxonomy of watermarking and speculative sampling trade-offs in language models. The ideal case of maintaining both watermark strength and sampling efficiency is proven to be impossible by the no-go theorem. The proposed algorithms focus on maintaining either watermark strength or sampling efficiency.

To the best of our knowledge, this work represents the first exploration of the intersection between unbiased watermarking and speculative sampling, introducing a novel framework, a significant no-go theorem, and pioneering practical algorithms.

## 2 Preliminary

In this section, we will introduce the basic concepts and notations used throughout the paper, and provide a brief overview of watermarking and speculative sampling techniques for large language models.

A language model defines a probability distribution over sequences of tokens from a vocabulary set \(\). It assigns a probability \(P(x_{n+1}|x_{1},x_{2},...,x_{n})\) to the next token \(x_{n+1}\) given the context of previous tokens \(x_{1},x_{2},...,x_{n}\). We use \(_{}\) to denote the set of all possible probability distributions over the vocabulary \(\).

Following Hu et al. , we define a watermarking scheme as a tuple \((,P_{E},R)\), where \(\) is a set of watermark codes, \(P_{E}\) is a probability distribution over \(\), and \(R:_{}_{}\) is a reweighting function that maps a watermark code \(E\) and a probability distribution \(P_{}\) to a watermarked distribution \(R_{E}(P)_{}\). We focus on unbiased watermarking schemes that satisfy \(_{E P_{E}}[R_{E}(P)]=P\) for all \(P_{}\), unless explicitly stated otherwise.

To generate a watermarked token \(x\), we first compute a watermark code \(E P_{E}\) based on the context, and then sample the token from the watermarked distribution, i.e., \(x R_{E}(P)\). The entropy of the distribution \(P\) determines the maximum amount of watermark that can be injected. For a distribution \(P\) with high entropy, the divergence between the watermarked distribution \(R_{E}(P)\) and the original distribution \(P\) can be larger, allowing for more watermark information to be injected.

The presence of the watermark can be detected by statistical tests. The pivotal quantity used in these tests is often referred to as the watermark score. A higher watermark score implies a more detectable watermark. The log likelihood ratio (LLR) is the most powerful score for detecting watermarks in the absence of any perturbations. However, in practice, more robust scores such as the maximin-LLR or likelihood-agnostic scores are often used. In this paper, we consider two specific watermark scores: the maximin-LLR score, which is described in detail in , and the U score, which is a likelihood-agnostic score that can be defined for both DeltaGumbel reweight and Gamma reweight schemes. The details of the U score, DeltaGumbel reweight and Gamma reweight are provided in Appendix D.

The P-value can be computed by considering the absence of a watermark as the null hypothesis. For a score \(S\) with a known moment-generating function (MGF), the P-value can be upper bounded using the Chernoff bound:

\[P_{}(S)_{ 0}[e^{ S}] -. \]

Speculative sampling [16; 5] is a technique for accelerating the generation of tokens from a target model \(P\) by leveraging a faster draft model \(Q\). The key idea is to first sample a draft token \(\) from the draft model \(Q\), and then accept or reject it based on the ratio of the target and draft probabilities. If the draft token is rejected, a new token is sampled from a residual distribution proportional to the difference between the target and draft probabilities. Formally, the speculative sampling process generates a token \(x\) as follows:

\[(x=j|=i)=(1,)&i=j,\\ +P(j)-Q(j))+}{_{x}(Q(i)-P(z))+}&i j, \]

where \((x)_{+}=(0,x)\). The design of the speculative process ensures that the final distribution of the generated token \(x\) matches the target distribution \(P\). The efficiency of speculative sampling can be measured by the overlap probability \((P,Q)=_{t}(P(t),Q(t))\), which is the probability of accepting the draft token in each step. The overlap probability is related to the total variation distance between \(P\) and \(Q\) by \((P,Q)=1-(P,Q)\). Such a speculative sampling process can be applied multiple times to generate and verify multiple draft tokens in one step.

Due to space limitations, we have moved the discussion of other related works to the Appendix A.

Two Reweight Framework for Accelerated Generation of Watermarked Tokens

In this section, we propose a novel framework called the _two reweight framework_ for accelerating the generation of watermarked tokens based on speculative sampling techniques. The motivation behind this non-trivial framework is that naively applying speculative sampling to a watermarked target distribution \(R_{E}(P)\) may significantly reduce the overlap probability \((R_{E}(P),Q)\) with the draft distribution \(Q\), leading to a small sampling efficiency.

The key innovation of the _two reweight framework_ is to apply a separate reweighting function \(R^{}\) to the draft distribution \(Q\), using the same watermark code \(E\) as the one used for reweighting the target distribution. By doing so, we aim to increase the overlap probability between the watermarked target distribution \(R_{E}(P)\) and the watermarked draft distribution \(R^{}_{E}(Q)\), i.e., \((R_{E}(P),R^{}_{E}(Q))\), thus improving the sampling efficiency.

Formally, we define the watermarked draft distribution using another reweighting function \((,P_{E},R^{})\), where \(R^{}:_{}_{}\) is a function that maps a watermark code \(E\) and a draft distribution \(Q_{}\) to a watermarked draft distribution \(R^{}_{E}(Q)_{}\). The framework itself does not require the watermarked draft distribution to be unbiased, i.e., \(_{E P_{E}}[R^{}_{E}(Q)]=Q\) for all \(Q_{}\). However, we will see later that this unbiasedness property naturally emerges when we require the final output distribution to be unbiased and aim to improve the sampling efficiency (Lemma 3).

To generate a watermarked token, we first sample a draft token \(\) from the watermarked draft distribution, i.e., \( R^{}_{E}(Q)\) or equivalently \((=i)=R^{}_{E}(Q)(i)\) for all \(i\). Then, we perform certain speculative sampling based on the draft token to obtain the generated token \(x\). The speculative process is defined by a conditional probability distribution \(A(j|i)\) for all \(i,j\), where \(A(|i)_{}\) for each \(i\). The design of \(A\) can depend on the target distribution \(P\), the draft distribution \(Q\), and the watermark code \(E\). The probability of generating a token \(x=j\) given a draft token \(=i\) is given by \((x=j|=i)=A(j|i)\).

The distribution of the generated token, which we call the generation distribution, can be computed as follows:

\[(x=j)=_{i}(x=j|=i)( =i)=_{i}A(j|i)R^{}_{E}(Q)(i)=(A R^{}_{E }(Q))(j). \]

We denote the generation distribution by \(_{E}(P)=A R^{}_{E}(Q)\).

To ensure that the _two reweight framework_ produces an unbiased output distribution, we require that for all \(P_{}\):

\[_{E P_{E}}[_{E}(P)]=P. \]

## 4 No-go Theorem

Despite the potential of the _two reweight framework_, we present a no-go theorem that shows the impossibility of simultaneously maintaining the watermark strength and sampling efficiency when the vocabulary size is greater than two.

**Theorem 1** (No-go Theorem).: _When the vocabulary size \(||>2\), there do not exist non-trivial reweighting functions \(R:_{}_{}\) and \(R^{}:_{}_{}\), and a speculative process \(A(j|i)\) such that for all \(P,Q_{}\):_

1. _The watermark strength is maintained:_ \(_{E}(P)=R_{E}(P)\)_._
2. _The sampling efficiency is maintained:_ \((P,Q)=_{E P_{E}}[_{i}A(i|i)R^{}_{E}(Q) (i)]\)_._

**Remark 2** (Condition for maintaining the watermark strength).: _The condition \(_{E}(P)=R_{E}(P)\) in Theorem 1 ensures that the watermark strength is maintained by keeping the average watermark score unchanged, i.e.,_

\[_{E P_{E}}_{t R_{E}(P)}[Score(t,E)]}_ {w:=}=_{E P_{E}}_{t_{E}( P)}[Score(t,E)]}_{w^{}:=}, \]_where \(Score(t,E)\) is an arbitrary function that measures the watermark strength._

_Strictly speaking, to ensure that the watermark strength remains unchanged, we only need to require \(w=w^{}\), and the condition \(_{E}(P)=R_{E}(P)\) is a sufficient condition. However, due to the large design space of scoring functions, if we want to maintain \(w=w^{}\) for every possible score, then \(_{E}(P)=R_{E}(P)\) becomes a necessary condition._

_On the other hand, for a fixed scoring function and a specific \(R_{E}\), it is possible that \(_{E}(P) R_{E}(P)\) while \(w=w^{}\) or even \(w<w^{}\). In other words, the condition \(_{E}(P)=R_{E}(P)\) is not always necessary for maintaining the watermark strength for a specific scoring function and reweighting function._

The proof of the no-go theorem relies on the following two lemmas, which reveal the connections between maintaining the sampling efficiency, maintaining the watermark strength, and the properties of the reweighting functions.

**Lemma 3** (Maintaining Sampling Efficiency Implies Unbiased Watermarked Draft Model).: _If for all \(P,Q_{}\), we have_

\[(P,Q)=_{E P_{E}}[_{i}A(i|i)R^{}_{E }(Q)(i)],\]

_then \(_{E P_{E}}[R^{}_{E}(Q)]=Q\) for all \(Q_{}\)._

**Lemma 4** (Maintaining Watermark Strength and Sampling Efficiency Implies Same Reweight Function).: _Under the two reweight framework, if for all \(P,Q_{}\), we have_

\[(P,Q)=_{E P_{E}}[_{i}A(i|i)R^{}_{E }(Q)(i)],_{E}(P)=R_{E}(P),\]

_then \(R^{}_{E}(Q)=R_{E}(Q)\) for all \(Q_{}\)._

The proofs of these lemmas are deferred to Appendix B. With these lemmas, we can now prove the no-go theorem.

Proof of Theorem 1.: According to Lemma 4, maintaining both the watermark strength and sampling efficiency under the _two reweight framework_ implies that \(R^{}_{E}(Q)=R_{E}(Q)\) for all \(Q_{}\). Therefore, we have

\[(P,Q)_{E P_{E}}[(R_{E}(P),R_{E}(Q))]. \]

To see this, note that

\[R_{E}(P)(i)=_{E}(P)(i)=_{j}A(i|j)R_{E}(Q)(j) A (i|i)R_{E}(Q)(i),\] \[R_{E}(Q)(i) A(i|i)R_{E}(Q)(i),\] \[A(i|i)R_{E}(Q)(i)(R_{E}(Q)(i),R_{E}(P)(i)).\]

Summing over \(i\), we get

\[_{i}A(i|i)R_{E}(Q)(i)_{i}(R_{E}(Q)(i),R_{E}(P)(i))=(R_{E }(Q),R_{E}(P)).\]

Taking the expectation over \(E\), we obtain Equation (6).

Recall that \((P,Q)=1-(P,Q)\), where \((P,Q)\) denotes the total variation distance between \(P\) and \(Q\). Therefore, Equation (6) is equivalent to

\[(P,Q)_{E P_{E}}[(R_{E}(P), R_{E}(Q))]. \]

Viewing \(P,Q_{}\) as \(n\)-dimensional vectors, where \(n=||\), we can express the total variation distance as

\[2(P,Q)=_{u[-1,1]^{n}} u,P-Q, \]

[MISSING_PAGE_FAIL:6]

we conclude that \(R_{E}(P)=P\) almost surely for random \(E\), which means that the reweighting function \(R_{E}\) is trivial.

Therefore, when the vocabulary size \(||>2\), it is impossible to simultaneously maintain the watermark strength and sampling efficiency using non-trivial reweighting functions under the _two reweight framework_. 

## 5 Algorithms for Maintaining Watermark Strength or Sampling Efficiency

```
Given draft sequence length \(K\), prompt \(x_{1},,x_{n}\), target model \(P(|)\), draft model \(Q(|)\), code history \(cch\) as a list of context code, context code function \(cc:^{*} C\), watermark code generation function \(:C Z\), reweighting functions \(R:_{}_{}\), and key for watermark \(z Z\). Initialize draft context code history \( cch\). for\(t=1:K+1\)do  Compute context code \(c_{t}=cc(x_{1},,x_{n},_{1},,_{t-1})\), watermark code \(E_{t}=(c_{t},z)\).  Check skipped \(skipped_{t}=&c_{t},\\ &c_{t}.\) Set \(+[c_{t}]\). if\(t=K+1\)then Exit for loop. endif  Compute distribution \(Q_{t}()=Q(|x_{1},,x_{n},_{1},,_{t-1})\).  Let \(_{t}=Q_{t}&skipped_{t}=,\\ R_{E_{t}}(Q_{t})&skipped_{t}=.\) Sample draft token \(_{t}_{t}\). endfor for\(t=1:K+1\)in paralleldo  Compute distribution \(P_{t}()=P(|x_{1},,x_{n},_{1},,_{t-1})\).  Let \(_{t}=P_{t}&skipped_{t}=,\\ R_{E_{t}}(P_{t})&skipped_{t}=.\) endfor  Initialize empty output list: \(out[]\). Let \((_{t},_{t})=(_{t},_{t })&,\\ (P_{t},Q_{t})&.\) for\(t=1:K\)do  Set \(cch cch+[c_{t}]\). Sample \(r U\) from a uniform distribution. if\(r<(1,_{t}(_{t})}{_{t}(_{t})})\)then Set \(out out+[_{t}]\). else  Sample \(x_{n+t}(_{t}-_{t})_{+}\). Set \(out out+[x_{n+t}]\). Exit for loop. endif endfor if\(out=[_{1},,_{K}]\)then  Set \(cch cch+[c_{K+1}]\). Sample \(x_{n+K+1}_{K+1}\). Set \(out out+[x_{n+K+1}]\). endif  Return \(out\) as generated tokens, and \(cch\) as context code history.
```

**Algorithm 1** Maintaining Watermark Strength or Sampling Efficiency

In this section, we present two algorithms that aim to maintain either the watermark strength or the sampling efficiency under the _two reweight framework_. In light of the no-go theorem (Theorem 1), which precludes the simultaneous maintenance of watermark strength and sampling efficiency, these algorithms provide deeper insights into the trade-offs between the two objectives.

### Maintaining Watermark Strength

To maintain the watermark strength, we choose the reweight function for draft distribution to be the same as the reweight function for the target distribution, i.e., \(R^{}_{E}(Q)=R_{E}(Q)\). The speculative process is designed as follows:

\[A(j|i)=(1,(P)(i)}{R_{E}(Q)(i)})&i=j,\\ (P)(i)}{R_{E}(Q)(i)})_{+}(R_{E}(P)(j)-R_{E}(Q)(j))_{+}}{ _{z}(R_{E}(Q)(z)-R_{E}(P)(z))_{+}}&i j. \]

**Theorem 5** (Maintaining Watermark Strength).: _Under the two reweight framework, if \(R^{}_{E}(Q)=R_{E}(Q)\) and the speculative process \(A(j|i)\) is defined as in Equation (20), then the watermark strength is maintained, i.e., \(_{E}(P)=R_{E}(P)\). Moreover, the generation distribution is unbiased, i.e., \(_{E P_{E}}[_{E}(P)]=P\) for all \(P_{}\)._

Intuitively, this algorithm applies the same reweighting function \(R_{E}\) to both the draft distribution \(Q\) and the target distribution \(P\), and then performs speculative sampling based on the reweighted distributions \(R_{E}(Q)\) and \(R_{E}(P)\) as draft and target distribution.

### Maintaining Sampling Efficiency

To maintain the sampling efficiency, we again choose the reweight function for draft distribution to be the same as the reweight function for the target distribution, i.e., \(R^{}_{E}(Q)=R_{E}(Q)\). However, the speculative process is designed differently:

\[A(j|i)=(1,)&i=j,\\ )_{+}(P(j)-Q(j))_{+}}{_{i}(Q(z)-P(z))_{ +}}&i j. \]

**Theorem 6** (Maintaining Sampling Efficiency).: _Under the two reweight framework, if \(R^{}_{E}(Q)=R_{E}(Q)\) and the speculative process \(A(j|i)\) is defined as in Equation (21), then the sampling efficiency is maintained, i.e., \((P,Q)=_{E P_{E}}[_{i}A(i|i)R^{}_{E}(Q)(i)]\). Moreover, the generation distribution is unbiased, i.e., \(_{E P_{E}}[_{E}(P)]=P\) for all \(P_{}\)._

Intuitively, this algorithm generates a watermarked draft token using the watermarked draft distribution \(R_{E}(Q)\), and then performs the standard speculative sampling process using the original distributions \(Q\) and \(P\) as draft and target distribution.

### Algorithms

The pseudo code for the two methods described in the previous sections is provided in Algorithm 1. This pseudo code applies the methods in previous sections for multiple times in each step, and also considers the context code history to ensure unbiasedness for the whole sequence. For reference, similar pseudo code for basic sampling, vanilla speculative sampling and vanilla unbiased watermarking is provided in Algorithms 2 to 4.

**Remark 7** (Context code history).: _According to , the context code history is crucial for ensuring the unbiasedness of the entire generated sequence. In both algorithms, all accepted draft tokens' context codes need to be preserved in the context code history. Additionally, when a draft token is rejected, its context code should also be preserved because the newly generated random token after rejection, i.e. \(x_{n+t}\), is not independent of the rejected random draft token \(_{t}\). By preserving the right context code history, we ensures that not only the distribution of a single token, but also the distribution of the entire generated sequence is unbiased. During computing watermark score for detection, a context code history is also necessary so that each context code only contributes to the watermark score once._

## 6 Experiments

To verify that Algorithm 1 can indeed maintain either the watermark strength or the sampling efficiency as claimed, we test different methods on a text summarization task on cnn_dailymail dataset  using the Llama-7b model  as the target model and the Llama-68m model  as the draft model.

We measure the sampling efficiency by the number of accepted tokens in the \(out\) list of Algorithm 1, and report the Average Accepted Tokens Per Step (AATPS). A higher AATPS indicates a higher sampling efficiency.

To measure the watermark strength, we compute the log P-value. For likelihood-based scores, the computation follows the method in . For likelihood-agnostic scores, we use U score with the Chernoff bound in Equation (1), where \(\) is optimized numerically. We test the watermark strengthfor both the DeltaGumbel reweight and the Gamma reweight schemes. The Average Negative Log P-value Per Token (ANLPPT) is reported, with a higher value indicating a stronger watermark.

The results are shown in Figure 2. We compare the performance of Basic Sampling, Vanilla Unbiased Watermark (VUW), Vanilla Speculative Sampling (VSpS), Maintain Watermark Strength (MWS), and Maintain Sampling Efficiency (MSE).

We also measure the Per Token Time (PTT) in millisecond to evaluate the wall-time latency and verify that Algorithm 1 can indeed achieve acceleration compared to the vanilla unbiased watermark method. The Log Perplexity (LOGPPL) is computed to verify that all algorithms produce the same output distribution and do not affect the quality of the language model output. The raw data for these additional metrics are provided in Table 1 in the appendix due to space constraints.

We also conduct additional experiments using different models and tasks. In addition to the Llama-7b model, we test the Llama-13b model  as the target model, with Llama-68m  as the draft model. Besides the text summarization task, we also evaluate the methods on an open-ended text generation task. The results of these additional experiments are provided in Appendix H. The total computational cost for reproducing all the experiments in this paper is approximately 1200 A6000 GPU hours.

Figure 2: Comparison of different methods. The x-axis shows the Average Accepted Tokens Per Step (AATPS) as a measure of speculative sampling efficiency, while y-axis shows the Average Negative Log P-value Per Token (ANLPPT) as a measure of watermark strength. The P-value is computed based on either a likelihood-based test using the maximin-LLR score (left) or a likelihood-agnostic test using the U score (right). Watermarking is performed using either the DeltaGumbel reweight (top) or the Gamma reweight (bottom). Error bars represent \(3\) confidence intervals1.

The experimental results in Figure 2 and Appendix H support the following findings:

* Algorithm 1 can indeed maintain either the watermark strength or the sampling efficiency as claimed. The MWS method achieves the same watermark strength as the VUW method, while the MSE method achieves the same sampling efficiency as the VSpS method.
* Algorithm 1 can indeed accelerate the generation process compared to the vanilla unbiased watermark method. Both the MWS and MSE methods achieve lower PTT than the VUW method, as shown in Table 1.
* MWS method has only marginal sampling efficiency gap compared to VSpS, while maintain the watermark strength as VUW method, making it highly practical.
* All algorithms produce the same output distribution and do not affect the quality of the language model output, as evidenced by the similar LOGPPL values across all methods in Table 1.
* The above findings are consistent across different draft sequence length (\(K=1,2,3,4\)), different models (Llama-7b and Llama-13b), different tasks (text summarization and open-ended text generation), different reweight schemes (DeltaGumbel and Gamma), and different watermark detection methods (likelihood-based and likelihood-agnostic). Our extensive experiments validate the generality of the findings.

In summary, our experimental results validate the theoretical findings and demonstrate the effectiveness of the proposed Algorithm 1.

## 7 Conclusion

Our work provides a rigorous theoretical foundation for understanding the trade-off between watermark strength and sampling efficiency in the context of accelerated generation of watermarked tokens from large language models. We prove a no-go theorem, showing that non-trivial trade-offs are inevitable when the vocabulary size is greater than two. To explore these trade-offs, we design algorithms that prioritize either watermark strength or sampling efficiency. Our findings contribute to the development of methods for protecting the intellectual property of language models while leveraging the efficiency of speculative sampling techniques.